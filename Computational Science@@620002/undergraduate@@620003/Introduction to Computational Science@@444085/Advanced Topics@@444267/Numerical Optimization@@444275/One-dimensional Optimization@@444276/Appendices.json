{"hands_on_practices": [{"introduction": "Before implementing any algorithm, a deep understanding of its theoretical underpinnings is essential. This first exercise guides you through deconstructing the Golden-Section Search from first principles [@problem_id:3166848]. You will prove the key property of unimodality for a sample function, derive the famous golden ratio constant that governs the search, and calculate the number of iterations required to achieve a desired precision, all without writing a single line of code.", "problem": "Consider the function $f(x) = \\exp(-x^{2})$ on the closed interval $[-3,3]$. You will locate its global maximum by minimizing $g(x) = -f(x)$ using Golden-Section Search (GSS), defined as a bracketing search method that places two interior points so that, after one function evaluation is discarded, the remaining interval retains the same internal ratio and reuses one previously evaluated point.\n\nTasks:\n- Without using derivatives, argue from the definitions of unimodality and the monotonicity of $\\exp(-x^{2})$ in $|x|$ that $g(x)$ is unimodal on $[-3,3]$ with a unique minimum attained at a single point in the interval.\n- From the defining self-similarity property of Golden-Section Search (no formulas are provided; derive from first principles), determine the constant factor by which the bracketing interval length contracts on each iteration.\n- Using that contraction factor and the initial interval length, determine the smallest integer number of iterations $N$ required so that the final bracket length is at most $2 \\times 10^{-6}$, which guarantees that any point returned from the bracket (for example, its midpoint) differs from the true maximizer by at most $10^{-6}$ in absolute value.\n\nReport only the integer $N$ as your final answer. No rounding instruction is necessary because $N$ is an integer.", "solution": "The problem is assessed to be valid as it is scientifically grounded in computational mathematics, well-posed with a unique solution, and objectively stated. It presents a standard application of the Golden-Section Search algorithm without any logical contradictions or missing information.\n\nThe solution is presented in three parts as requested by the problem statement.\n\n**Part 1: Unimodality of $g(x)$**\n\nA function $h(x)$ is defined as strictly unimodal on an interval $[a,b]$ if there exists a unique point $x^* \\in [a,b]$ at which the function attains its unique minimum (or maximum), and the function is strictly monotonic on either side of $x^*$. We are asked to minimize $g(x) = -\\exp(-x^2)$ on the interval $[-3,3]$. This is equivalent to maximizing the function $f(x) = \\exp(-x^2)$ on the same interval. We must show, without using derivatives, that $g(x)$ is strictly unimodal on $[-3,3]$.\n\nLet's analyze the behavior of the component functions.\n1.  The function $u(x) = x^2$ is strictly decreasing for $x \\in [-3, 0]$ and strictly increasing for $x \\in [0, 3]$. It achieves its unique minimum on this interval at $x=0$.\n2.  The function $v(x) = -u(x) = -x^2$ will have the opposite monotonicity. It is strictly increasing for $x \\in [-3, 0]$ and strictly decreasing for $x \\in [0, 3]$. It achieves its unique maximum on this interval at $x=0$.\n3.  The exponential function, $f(x) = \\exp(v(x)) = \\exp(-x^2)$, is a strictly monotonically increasing function of its argument. Therefore, the monotonicity of $f(x)$ is identical to the monotonicity of its exponent, $v(x)=-x^2$. Consequently, $f(x)$ is strictly increasing on $[-3, 0]$ and strictly decreasing on $[0, 3]$. This means $f(x)$ has a unique maximum at $x=0$.\n4.  The function to be minimized is $g(x) = -f(x) = -\\exp(-x^2)$. Multiplication by $-1$ inverts the monotonicity. Thus, $g(x)$ is strictly decreasing on $[-3, 0]$ and strictly increasing on $[0, 3]$.\n\nAccording to the definition, a function that is strictly decreasing to a unique minimum and then strictly increasing is strictly unimodal. The function $g(x)$ exhibits this behavior on $[-3,3]$, with its unique minimum occurring at the point $x=0$, which is within the interval. This completes the argument for the unimodality of $g(x)$ on $[-3,3]$.\n\n**Part 2: Derivation of the Contraction Factor**\n\nThe Golden-Section Search (GSS) algorithm reduces the length of the bracketing interval by a constant factor in each iteration. Let this contraction factor be $\\rho \\in (0,1)$.\n\nLet the bracketing interval at iteration $k$ be $[a_k, b_k]$ with length $L_k = b_k - a_k$. Two interior points, $x_{k,1}$ and $x_{k,2}$, are chosen within the interval such that $a_k < x_{k,1} < x_{k,2} < b_k$. The placement of these points is symmetric in the sense that the new interval length is the same regardless of which end of the original interval is discarded. This new length is $L_{k+1} = \\rho L_k$.\nThis implies that the length of the sub-interval $[a_k, x_{k,2}]$ must be equal to the length of the sub-interval $[x_{k,1}, b_k]$.\n$$x_{k,2} - a_k = b_k - x_{k,1} = \\rho L_k$$\nFrom this, we can express the positions of the interior points:\n$$x_{k,2} = a_k + \\rho L_k$$\n$$x_{k,1} = b_k - \\rho L_k = (a_k + L_k) - \\rho L_k = a_k + (1-\\rho)L_k$$\nFor the points to be ordered correctly ($x_{k,1} < x_{k,2}$), we must have $1-\\rho < \\rho$, which implies $1 < 2\\rho$, or $\\rho > \\frac{1}{2}$.\n\nThe defining property of GSS is that one of the interior points from iteration $k$ can be reused in iteration $k+1$. Let's assume after evaluating the function at $x_{k,1}$ and $x_{k,2}$, we find that the minimum lies in the interval $[a_k, x_{k,2}]$. The new interval is $[a_{k+1}, b_{k+1}] = [a_k, x_{k,2}]$. The length of this new interval is $L_{k+1} = x_{k,2} - a_k = \\rho L_k$. The point $x_{k,1}$ is contained within this new interval.\n\nFor iteration $k+1$, we need to choose two new interior points, $x_{k+1,1}$ and $x_{k+1,2}$, within $[a_{k+1}, b_{k+1}]$. According to the same rule, they must be located at:\n$$x_{k+1,1} = a_{k+1} + (1-\\rho)L_{k+1} = a_k + (1-\\rho)(\\rho L_k)$$\n$$x_{k+1,2} = a_{k+1} + \\rho L_{k+1} = a_k + \\rho(\\rho L_k) = a_k + \\rho^2 L_k$$\n\nThe self-similarity or point-reuse principle requires that the old point $x_{k,1}$ must coincide with one of the new points, $x_{k+1,1}$ or $x_{k+1,2}$. The old point is $x_{k,1} = a_k + (1-\\rho)L_k$.\nBy symmetry, the other case (where the new interval is $[x_{k,1}, b_k]$) will result in the same condition.\nLet's check the two possibilities for matching points:\n1.  $x_{k,1} = x_{k+1,1}$: $a_k + (1-\\rho)L_k = a_k + (1-\\rho)\\rho L_k$. Since $L_k \\neq 0$ and $\\rho \\neq 1$, we can simplify to $1 = \\rho$. This contradicts the requirement that $\\rho < 1$.\n2.  $x_{k,1} = x_{k+1,2}$: $a_k + (1-\\rho)L_k = a_k + \\rho^2 L_k$. This simplifies to $1-\\rho = \\rho^2$.\n\nRearranging this gives the quadratic equation:\n$$\\rho^2 + \\rho - 1 = 0$$\nUsing the quadratic formula to solve for $\\rho$:\n$$\\rho = \\frac{-1 \\pm \\sqrt{1^2 - 4(1)(-1)}}{2(1)} = \\frac{-1 \\pm \\sqrt{5}}{2}$$\nSince the contraction factor $\\rho$ must be a positive value (it's a ratio of lengths), we must take the positive root:\n$$\\rho = \\frac{\\sqrt{5}-1}{2}$$\nThis value is the reciprocal of the golden ratio, $\\phi = \\frac{1+\\sqrt{5}}{2}$, often denoted as $\\frac{1}{\\phi}$. Its approximate value is $0.618034$.\n\n**Part 3: Minimum Number of Iterations**\n\nThe initial interval is $[-3, 3]$, so its length is $L_0 = 3 - (-3) = 6$.\nThe length of the interval after $N$ iterations is given by $L_N = \\rho^N L_0$.\nThe problem requires that the final bracket length $L_N$ be at most $2 \\times 10^{-6}$. So we must find the smallest integer $N$ that satisfies the inequality:\n$$L_N \\le 2 \\times 10^{-6}$$\nSubstituting the expressions for $L_N$ and the values of $L_0$ and $\\rho$:\n$$\\left(\\frac{\\sqrt{5}-1}{2}\\right)^N (6) \\le 2 \\times 10^{-6}$$\nDivide by $6$:\n$$\\left(\\frac{\\sqrt{5}-1}{2}\\right)^N \\le \\frac{2 \\times 10^{-6}}{6} = \\frac{1}{3} \\times 10^{-6}$$\nTo solve for $N$, we take the natural logarithm of both sides. Since $\\ln(x)$ is an increasing function, the direction of the inequality is preserved.\n$$N \\ln\\left(\\frac{\\sqrt{5}-1}{2}\\right) \\le \\ln\\left(\\frac{1}{3} \\times 10^{-6}\\right)$$\nThe term $\\frac{\\sqrt{5}-1}{2} \\approx 0.618$ is less than $1$, so its logarithm is negative. When we divide by this negative number, we must reverse the inequality sign:\n$$N \\ge \\frac{\\ln\\left(\\frac{1}{3} \\times 10^{-6}\\right)}{\\ln\\left(\\frac{\\sqrt{5}-1}{2}\\right)}$$\nLet's evaluate the numerator and denominator:\n$$ \\ln\\left(\\frac{1}{3} \\times 10^{-6}\\right) = \\ln(1) - \\ln(3) - \\ln(10^6) = -\\ln(3) - 6\\ln(10) $$\nThe denominator can be expressed using the golden ratio $\\phi = \\frac{1+\\sqrt{5}}{2}$ as $\\ln\\left(\\frac{1}{\\phi}\\right) = -\\ln(\\phi)$.\n$$ N \\ge \\frac{-\\ln(3) - 6\\ln(10)}{-\\ln(\\phi)} = \\frac{\\ln(3) + 6\\ln(10)}{\\ln\\left(\\frac{1+\\sqrt{5}}{2}\\right)} $$\nUsing numerical values for the logarithms:\n$$ \\ln(3) \\approx 1.09861 $$\n$$ \\ln(10) \\approx 2.30259 $$\n$$ \\ln\\left(\\frac{1+\\sqrt{5}}{2}\\right) \\approx \\ln(1.618034) \\approx 0.48121 $$\nSubstituting these values:\n$$ N \\ge \\frac{1.09861 + 6(2.30259)}{0.48121} = \\frac{1.09861 + 13.81554}{0.48121} = \\frac{14.91415}{0.48121} \\approx 30.993 $$\nSince the number of iterations $N$ must be an integer, we must take the smallest integer greater than or equal to $30.993$.\n$$ N = 31 $$", "answer": "$$\\boxed{31}$$", "id": "3166848"}, {"introduction": "With a solid theoretical foundation, the next step is to translate concepts into a functional algorithm. This practice focuses on implementing the Golden-Section Search and testing its behavior on a variety of functions [@problem_id:3166878]. By running your code against different scenarios, including one where an initial evaluation point lands exactly on the minimizer, you will gain practical insights into the algorithm's fixed convergence rate and robust performance.", "problem": "You are to design and implement an algorithm for one-dimensional minimization using Golden-section search (GSS), starting from first principles. The fundamental base to use is the definition of a unimodal function on a closed interval and the requirement that the sample points be chosen to preserve self-similarity of the search interval so that one function value can be reused at each iteration. A continuous unimodal function has exactly one local minimum on an interval, and shrinking the interval while preserving a fixed ratio between successive interval lengths enables systematic convergence to the minimum. Your task is to derive the point-placement rule that achieves this invariance, implement the resulting algorithm, and quantify how quickly convergence is detected when the initial interior points are favorably placed.\n\nImplement Golden-section search for minimizing a continuous unimodal function $f(x)$ on an interval $[a,b]$. The algorithm must:\n- Initialize two interior evaluation points in $[a,b]$, reusing one function evaluation after each interval shrink.\n- At each iteration, shrink the interval to the subinterval that contains the minimizer, determined by comparing the function values at the interior points.\n- Terminate when the interval length is less than or equal to a prescribed tolerance $\\varepsilon$.\n- Return three quantities: the number of iterations $n$ until termination, the final approximation $x^\\star$ to the minimizer, and the function value $f(x^\\star)$.\n\nCreate a special test case to align one of the initial interior points exactly with the minimizer at the start. Consider the function $f(x) = (x - \\tau)^2$ on the interval $[0,1]$, where $\\tau$ is the golden ratio conjugate $\\tau = (\\sqrt{5} - 1)/2 \\approx 0.618$. Because the initial interior points in Golden-section search are placed at $x_1 = b - \\tau (b-a)$ and $x_2 = a + \\tau (b-a)$, one of them equals $x^\\star = \\tau$ on $[0,1]$. Verify how quickly the algorithm detects convergence by measuring the iteration count $n$ for a stringent tolerance $\\varepsilon$.\n\nYour program must implement Golden-section search from these principles and apply it to the following test suite. For each test case, return a list of the form $[n, x^\\star, f(x^\\star)]$ and aggregate the results in a single list printed on one line, as specified below.\n\nTest suite:\n- Case $1$ (aligned interior point): $f_1(x) = (x - \\tau)^2$, interval $[0,1]$, tolerance $\\varepsilon = 10^{-8}$.\n- Case $2$ (symmetric but not aligned): $f_2(x) = (x - 0.5)^2$, interval $[0,1]$, tolerance $\\varepsilon = 10^{-8}$.\n- Case $3$ (minimum at the endpoint): $f_3(x) = x^2$, interval $[0,1]$, tolerance $\\varepsilon = 10^{-8}$.\n- Case $4$ (tiny initial bracket around the minimizer): $f_4(x) = (x - \\tau)^2$, interval $[\\tau - 10^{-12}, \\tau + 10^{-12}]$, tolerance $\\varepsilon = 10^{-9}$.\n- Case $5$ (smooth strictly convex, wider interval): $f_5(x) = \\mathrm{e}^{x} + \\mathrm{e}^{-x}$, interval $[-1,2]$, tolerance $\\varepsilon = 10^{-8}$.\n\nFinal output format:\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (e.g., $[result_1,result_2,\\dots]$).\n- For each case, output the list $[n, x^\\star, f(x^\\star)]$ where $n$ is an integer, and both $x^\\star$ and $f(x^\\star)$ are floating-point numbers rounded to $10$ decimal places.\n- The order of results must match the order of the test suite above.\n- Angles are not involved; no angle unit is required. No physical units are involved.", "solution": "The problem requires the design and implementation of the Golden-Section Search (GSS) algorithm from first principles for minimizing a continuous unimodal function $f(x)$ on a closed interval $[a,b]$.\n\n### Principle and Derivation of the Golden-Section Search\n\nA function $f(x)$ is unimodal on an interval $[a,b]$ if there is a unique value $x^\\star \\in [a,b]$ where $f(x)$ has its minimum, and for any two points $x_1 < x_2$ in the interval, if $x_2 < x^\\star$ then $f(x_1) > f(x_2)$, and if $x_1 > x^\\star$ then $f(x_1) < f(x_2)$. In simpler terms, the function is strictly decreasing to the left of the minimum and strictly increasing to the right.\n\nThe core of the Golden-Section Search is to iteratively shrink the interval $[a,b]$ while ensuring the minimum $x^\\star$ remains within the shrinking interval. To do this, we sample the function at two interior points, $x_1$ and $x_2$, such that $a < x_1 < x_2 < b$.\n\nBy comparing the function values $f(x_1)$ and $f(x_2)$, we can discard a portion of the interval:\n1.  If $f(x_1) < f(x_2)$, the minimum cannot be in the subinterval $(x_2, b]$, because if it were, then both $x_1$ and $x_2$ would be to the left of the minimum, which by the definition of unimodality would imply $f(x_1) > f(x_2)$, a contradiction. Therefore, the new search interval must be $[a, x_2]$.\n2.  If $f(x_1) \\geq f(x_2)$, the minimum cannot be in the subinterval $[a, x_1)$, because if it were, both $x_1$ and $x_2$ would be to the right of the minimum, implying $f(x_1) < f(x_2)$, a contradiction. Therefore, the new search interval must be $[x_1, b]$.\n\nThe key to efficiency is to choose the locations of $x_1$ and $x_2$ in a way that allows one of the points (and its corresponding function evaluation) to be reused in the next iteration. This is achieved by placing the points symmetrically and maintaining a constant ratio of interval reduction at each step.\n\nLet the length of the interval at step $k$ be $L_k = b_k - a_k$. We wish to reduce the length by a constant factor $\\tau$ at each step, i.e., $L_{k+1} = \\tau L_k$. Let's define the placement of the interior points relative to the interval length. We choose a parameter $\\tau \\in (1/2, 1)$ and place the points symmetrically from the ends of the interval:\n$x_{1,k} = b_k - \\tau(b_k - a_k)$\n$x_{2,k} = a_k + \\tau(b_k - a_k)$\n\nNote that because $\\tau > 1/2$, we have $a_k < x_{1,k} < x_{2,k} < b_k$, as required.\n\nNow, consider the case where $f(x_{1,k}) < f(x_{2,k})$. The new interval is $[a_{k+1}, b_{k+1}] = [a_k, x_{2,k}]$.\nThe length of this new interval is $L_{k+1} = x_{2,k} - a_k = \\tau(b_k - a_k) = \\tau L_k$. This is consistent with our goal of constant-ratio reduction.\nThe new interval $[a_{k+1}, b_{k+1}]$ contains one of the old interior points, $x_{1,k}$. For the next iteration, we need two new interior points, $x_{1,k+1}$ and $x_{2,k+1}$, defined by the same rule:\n$x_{1,k+1} = b_{k+1} - \\tau L_{k+1} = x_{2,k} - \\tau(\\tau L_k) = (a_k + \\tau L_k) - \\tau^2 L_k = a_k + (\\tau - \\tau^2)L_k$.\n$x_{2,k+1} = a_{k+1} + \\tau L_{k+1} = a_k + \\tau(\\tau L_k) = a_k + \\tau^2 L_k$.\n\nFor one function evaluation to be reused, the old point $x_{1,k}$ must coincide with one of the new points, $x_{1,k+1}$ or $x_{2,k+1}$.\nThe position of the old point is $x_{1,k} = b_k - \\tau L_k = (a_k+L_k) - \\tau L_k = a_k + (1-\\tau)L_k$.\nComparing this with the new points, we can enforce the condition $x_{1,k} = x_{2,k+1}$ (by inspection, these are the two points closer to the center of their respective intervals). This gives the equation:\n$a_k + (1-\\tau)L_k = a_k + \\tau^2 L_k$\n$1 - \\tau = \\tau^2$\n$\\tau^2 + \\tau - 1 = 0$\n\nSolving this quadratic equation for the positive root gives:\n$\\tau = \\frac{-1 + \\sqrt{1^2 - 4(1)(-1)}}{2(1)} = \\frac{\\sqrt{5} - 1}{2}$\n\nThis value, approximately $0.618034$, is the golden ratio conjugate, often denoted $\\phi^{-1}$ or simply $\\tau$. A symmetric argument for the case $f(x_{1,k}) \\geq f(x_{2,k})$ shows that the old point $x_{2,k}$ becomes the new point $x_{1,k+1}$.\n\nThus, by choosing $\\tau = (\\sqrt{5} - 1)/2$, we guarantee that at each step, the interval length is reduced by a factor of $\\tau$, and one function evaluation can be reused.\n\n### Algorithm Implementation\n\nThe algorithm proceeds as follows:\n1.  **Initialization**: Given $f(x)$, $[a,b]$, and tolerance $\\varepsilon$. Define $\\tau = (\\sqrt{5}-1)/2$. Calculate the initial interior points $x_1 = b - \\tau(b-a)$ and $x_2 = a + \\tau(b-a)$, and evaluate $f_1 = f(x_1)$ and $f_2 = f(x_2)$. Initialize an iteration counter $n=0$.\n2.  **Iteration**: While the interval length $(b-a) > \\varepsilon$:\n    a. Increment $n$.\n    b. If $f_1 < f_2$:\n        i. The new interval is $[a, x_2]$. Set $b = x_2$.\n        ii. The old $x_1$ becomes the new $x_2$. Set $x_2 = x_1$ and $f_2 = f_1$.\n        iii. Calculate the new $x_1 = b - \\tau(b-a)$ and evaluate $f_1 = f(x_1)$.\n    c. Else ($f_1 \\geq f_2$):\n        i. The new interval is $[x_1, b]$. Set $a = x_1$.\n        ii. The old $x_2$ becomes the new $x_1$. Set $x_1 = x_2$ and $f_1 = f_2$.\n        iii. Calculate the new $x_2 = a + \\tau(b-a)$ and evaluate $f_2 = f(x_2)$.\n3.  **Termination**: When the loop terminates, the minimizer $x^\\star$ is within the final interval $[a,b]$. The best estimate for the minimizer is the midpoint of this interval, $x^\\star = (a+b)/2$.\n4.  **Return**: Return the number of iterations $n$, the final approximation $x^\\star$, and the function value $f(x^\\star)$.\n\n### Analysis of the Special Test Case (Case 1)\n\nFor the function $f_1(x) = (x - \\tau)^2$ on $[0,1]$, the true minimum is at $x^\\star = \\tau$.\nThe initial interval is $[a_0, b_0] = [0,1]$. The initial interior points are:\n$x_{1,0} = 1 - \\tau(1-0) = 1-\\tau$\n$x_{2,0} = 0 + \\tau(1-0) = \\tau$\nOne of the initial points, $x_{2,0}$, coincides exactly with the true minimizer. Consequently, $f(x_{2,0}) = (\\tau - \\tau)^2 = 0$. The other point gives $f(x_{1,0}) = ((1-\\tau) - \\tau)^2 = (1-2\\tau)^2 > 0$.\n\nSince $f(x_{1,0}) > f(x_{2,0})$, the algorithm sets the new interval to $[a_1, b_1] = [x_{1,0}, b_0] = [1-\\tau, 1]$.\nThe algorithm proceeds by shrinking the interval around the point with the lower function value. At every subsequent iteration, one of the interior points will be exactly $\\tau$, and its function value will be $0$. The algorithm will always choose the subinterval containing $\\tau$.\n\nHowever, the question of \"how quickly convergence is detected\" is answered by examining the termination criterion: $(b-a) \\leq \\varepsilon$. The algorithm's rate of convergence is determined solely by the interval reduction factor $\\tau$. The length of the interval after $n$ iterations is $L_n = \\tau^n L_0$. The number of iterations required to meet the tolerance is found by solving $\\tau^n L_0 \\leq \\varepsilon$, which gives $n \\geq \\log(\\varepsilon/L_0) / \\log(\\tau)$. For $L_0=1$ and $\\varepsilon=10^{-8}$, this requires $n \\geq \\log(10^{-8})/\\log(\\tau) \\approx 38.28$, meaning $n=39$ iterations.\n\nThe favorable placement of an initial point at the exact minimum does not alter the number of iterations required for convergence. The algorithm has no mechanism to \"detect\" that it has found the minimum value; it only terminates based on interval width. This demonstrates a key property of Golden-section search: it has a guaranteed, but fixed, linear convergence rate, independent of the function's specific behavior beyond unimodality. In contrast, an algorithm using derivative information (like Newton's method) could converge much faster in such a scenario.\n\nThe exception to this is Case 4, where the initial interval $[\\tau - 10^{-12}, \\tau + 10^{-12}]$ has a length of $2 \\times 10^{-12}$, which is already smaller than the tolerance $\\varepsilon = 10^{-9}$. In this case, the termination condition is met before the first iteration, and the algorithm correctly returns $n=0$.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to run the test suite for Golden-section search.\n    \"\"\"\n\n    def золотой_раздел(f, a, b, tol):\n        \"\"\"\n        Implements the Golden-section search algorithm.\n        \n        Args:\n            f: The unimodal function to minimize.\n            a: The lower bound of the interval.\n            b: The upper bound of the interval.\n            tol: The tolerance for the interval length.\n            \n        Returns:\n            A list containing [n, x_star, f_x_star]:\n            - n: Number of iterations.\n            - x_star: The approximation of the minimizer.\n            - f_x_star: The function value at the approximation.\n        \"\"\"\n        # The golden ratio conjugate\n        tau = (np.sqrt(5) - 1) / 2\n\n        # Initial interior points\n        x1 = b - tau * (b - a)\n        x2 = a + tau * (b - a)\n\n        # Initial function evaluations\n        f1 = f(x1)\n        f2 = f(x2)\n\n        n = 0\n        while (b - a) > tol:\n            n += 1\n            if f1 < f2:\n                # The minimum is in [a, x2]\n                b = x2\n                x2 = x1\n                f2 = f1\n                x1 = b - tau * (b - a)\n                f1 = f(x1)\n            else:\n                # The minimum is in [x1, b]\n                a = x1\n                x1 = x2\n                f1 = f2\n                x2 = a + tau * (b - a)\n                f2 = f(x2)\n        \n        # The final approximation is the midpoint of the last interval.\n        x_star = (a + b) / 2\n        f_x_star = f(x_star)\n        \n        return [n, x_star, f_x_star]\n\n    # Define constants and test functions\n    tau_val = (np.sqrt(5) - 1) / 2\n\n    def f1(x):\n        return (x - tau_val)**2\n\n    def f2(x):\n        return (x - 0.5)**2\n\n    def f3(x):\n        return x**2\n\n    def f4(x):\n        return (x - tau_val)**2\n\n    def f5(x):\n        return np.exp(x) + np.exp(-x)\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        (f1, 0.0, 1.0, 1e-8),\n        (f2, 0.0, 1.0, 1e-8),\n        (f3, 0.0, 1.0, 1e-8),\n        (f4, tau_val - 1e-12, tau_val + 1e-12, 1e-9),\n        (f5, -1.0, 2.0, 1e-8),\n    ]\n\n    results = []\n    for case in test_cases:\n        func, a, b, tol = case\n        n, x_star, f_x_star = золотой_раздел(func, a, b, tol)\n        \n        # Format the result as a string with required precision\n        result_str = f\"[{n},{x_star:.10f},{f_x_star:.10f}]\"\n        results.append(result_str)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(results)}]\")\n\nsolve()\n```", "id": "3166878"}, {"introduction": "Numerical methods are powerful because they can be adapted to contexts beyond their original design. This advanced exercise challenges you to modify the Golden-Section Search, a continuous optimization algorithm, for a discrete (integer) domain [@problem_id:3166898]. Success requires carefully designing a rounding strategy for the interior points that preserves the algorithm's bracketing invariant and guarantees convergence, a crucial skill for problems in fields like logistics and resource allocation.", "problem": "You are asked to design, analyze, and implement a discrete variant of one-dimensional golden-section search suitable for integer-domain, unimodal objective functions. Consider the integer domain $[0,1000]$ and let $f(x)$ be unimodal on the integers, meaning there exists at least one integer $x^\\star$ such that $f$ is nonincreasing on $\\{0,1,\\dots,x^\\star\\}$ and nondecreasing on $\\{x^\\star,\\dots,1000\\}$. Your task is to adapt the golden-section search so that each iteration selects and evaluates two distinct interior integers derived from the continuous golden-section points, and updates a bracketing interval that is guaranteed to shrink toward a minimizer. The core requirement is to define a rounding strategy that maps the continuous interior points to integers without breaking the bracketing invariants or convergence.\n\nStarting from fundamental definitions, you must:\n- Use the principle of a bracketing search for a unimodal function on a closed interval, which maintains an interval $[a,b]$ known to contain a minimizer.\n- Use the idea of interior points based on a constant partition ratio (originating from the golden-section principle) to reduce the number of function evaluations across iterations.\n- Devise an integer-mapping rule that takes the real-valued interior points and produces two distinct integers strictly inside the current bracket $[a,b]$ (that is, $a < P < Q < b$) while ensuring that:\n  1) The interval length in integers strictly decreases by at least $1$ at each iteration.\n  2) The unimodal minimizer on the integers remains in the bracket after each update.\n  3) If $f(P) = f(Q)$ at any iteration, the update rule must ensure that, when multiple integer minimizers exist, the algorithm ultimately returns the smallest minimizer (that is, the smallest integer $x$ that achieves the minimal value).\n\nImplementation requirements:\n- The implementation must not evaluate $f(x)$ for any $x$ outside $[0,1000]$.\n- Terminate when the integer bracket has length at most $2$ and then choose the minimizer by direct inspection of all integer points remaining in the bracket.\n- The program must handle plateaus (a flat bottom), strict unimodality, and boundary minima, and must be robust with respect to the integer rounding of interior points.\n\nTest suite:\nImplement your algorithm and apply it to the following five unimodal test functions on the domain $\\{0,1,\\dots,1000\\}$:\n\n- Case $1$: $f_1(x) = (x - 321.7)^2$.\n- Case $2$: $f_2(x) = |x - 250| + 0.001\\,x$.\n- Case $3$: $f_3(x) = \\max\\{|x - 700| - 2,\\,0\\}$.\n- Case $4$: $f_4(x) = x^2$.\n- Case $5$: $f_5(x) = \\begin{cases} 2\\,(873 - x), & x \\le 873 \\\\ 3\\,(x - 873), & x \\ge 873 \\end{cases}$.\n\nFor each case, compute the integer $x^\\star \\in \\{0,1,\\dots,1000\\}$ that minimizes $f(x)$, with the convention that if multiple integers achieve the same minimal value, you must return the smallest such integer.\n\nFinal output format:\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (for example, in the form \"[r1,r2,r3,r4,r5]\"). Each entry must be the integer minimizer for the corresponding case, in the order of the cases listed above. No additional text should be printed.", "solution": "The problem requires the design and implementation of a discrete one-dimensional optimization algorithm, specifically an adaptation of the golden-section search for unimodal functions over an integer domain. The solution must be robust, convergent, and handle specific tie-breaking rules.\n\nThe fundamental principle is that of a bracketing search. For a unimodal function $f(x)$ on a closed integer interval $[a, b]$, we know a minimizer $x^\\star$ lies within this bracket. The goal is to iteratively shrink the bracket $[a, b]$ while ensuring $x^\\star$ remains within it. This is achieved by evaluating the function at two distinct interior points, $P$ and $Q$, such that $a < P < Q < b$.\n\nThe update rules for the bracket are derived from the definition of unimodality.\nLet $f$ be a function that is nonincreasing up to a minimizer $x^\\star$ and nondecreasing thereafter.\n1. If $f(P) < f(Q)$, the minimizer $x^\\star$ cannot be in the interval $(Q, b]$. The function value at $Q$ is higher than at $P$, and since the function is nondecreasing to the right of $x^\\star$, any minimizer must be to the left of $Q$. Thus, the new bracket becomes $[a, Q]$.\n2. If $f(P) > f(Q)$, the minimizer $x^\\star$ cannot be in the interval $[a, P)$. The function value at $P$ is higher than at $Q$. Since the function is nonincreasing to the left of $x^\\star$, any minimizer must be to the right of $P$. Thus, the new bracket becomes $[P, b]$.\n3. If $f(P) = f(Q)$, the minimizer(s) could lie in a plateau between $P$ and $Q$. The problem requires finding the smallest integer minimizer. To ensure we do not discard the leftmost minimizer, we must keep the left portion of the domain under consideration. Therefore, this case is handled like the first one: the new bracket becomes $[a, Q]$.\n\nCombining these, the update logic is: if $f(P) \\le f(Q)$, the new bracket is $[a, Q]$; otherwise, the new bracket is $[P, b]$.\n\nThe core of the task is to select the integer points $P$ and $Q$. The golden-section search for continuous domains places these points using the golden ratio conjugate, $\\psi = (\\sqrt{5}-1)/2 \\approx 0.618$. The points are located at $a + (1-\\psi)(b-a)$ and $a + \\psi(b-a)$. For an integer domain $[a, b]$ of length $L = b-a$, the continuous analogues are $p_{cont} = b - \\psi L$ and $q_{cont} = a + \\psi L$.\n\nA naive rounding of these continuous points to integers can fail. The distance between them is $q_{cont} - p_{cont} = L(2\\psi - 1) = L(\\sqrt{5}-2) \\approx 0.236 L$. If this distance is less than $1$, rounding can map both to the same integer, violating the $P < Q$ requirement. This occurs for small $L$, for example, if $L=4$, $p_{cont} \\approx a+1.528$ and $q_{cont} \\approx a+2.472$, which can both round to $a+2$.\n\nTo create a robust integer point selection strategy, we define the following procedure for any interval $[a,b]$ with length $b-a > 2$:\n1. Calculate the ideal interior points $Q = \\text{round}(a + \\psi (b-a))$ and $P = \\text{round}(b - \\psi (b-a))$. We use standard rounding (round half to nearest even).\n2. Check for collision. If $P \\ge Q$, we enforce distinctness by setting $P = Q - 1$. This correction is necessary for certain small interval lengths.\n3. This rule guarantees $a < P < Q < b$. For an interval length $L = b-a \\ge 3$, the point $q_{cont} = a + \\psi L$ is greater than $a + 3\\psi \\approx a + 1.854$. After rounding, $Q \\ge a+2$. Therefore, the corrected point $P = Q - 1$ will be at least $a+1$, satisfying $P > a$. Symmetrically, $Q < b$ is also guaranteed. The interval length $b-a$ is guaranteed to shrink by at least $1$ in each iteration, ensuring convergence.\n\nThe search algorithm proceeds as follows:\n1. Initialize the bracket $[a, b]$ to the full domain, i.e., $[0, 1000]$.\n2. Loop while the number of integers in the bracket, $b-a+1$, is greater than $3$ (or, equivalently, while $b-a > 2$).\n   a. Calculate the integer interior points $P$ and $Q$ using the robust rule described above.\n   b. Evaluate $f(P)$ and $f(Q)$.\n   c. If $f(P) \\le f(Q)$, update $b = Q$.\n   d. If $f(P) > f(Q)$, update $a = P$.\n3. Once the loop terminates ($b-a \\le 2$), the minimizer is contained in the small final bracket $[a, b]$. A final exhaustive search is performed over the integers $\\{a, a+1, \\dots, b\\}$ to find the $x$ that minimizes $f(x)$. If multiple integers yield the same minimum value, the smallest such integer is chosen, satisfying the problem's tie-breaking requirement.\n\nThis complete algorithm correctly adapts the golden-section search to an integer domain, ensuring convergence to the smallest integer minimizer while satisfying all specified constraints.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the problem by implementing a discrete golden-section search for\n    the five specified test cases and printing the results.\n    \"\"\"\n\n    def golden_section_integer_search(f, a, b):\n        \"\"\"\n        Performs a golden-section search for a unimodal function on an\n        integer domain.\n\n        Args:\n            f: The unimodal objective function.\n            a: The lower bound of the integer interval.\n            b: The upper bound of the integer interval.\n\n        Returns:\n            The integer x that minimizes f(x) in [a, b]. If multiple\n            minimizers exist, the smallest is returned.\n        \"\"\"\n        psi = (np.sqrt(5) - 1) / 2  # Golden-ratio conjugate\n\n        # Main loop to shrink the bracketing interval\n        while (b - a) > 2:\n            L = b - a\n            \n            # Calculate integer interior points based on the golden ratio\n            # np.round rounds to the nearest even number for .5 cases\n            q_val = a + psi * L\n            p_val = b - psi * L\n            Q = int(np.round(q_val))\n            P = int(np.round(p_val))\n\n            # Robustness check: ensure interior points are distinct.\n            # This can happen for small integer interval lengths where rounding\n            # causes the two points to collide.\n            if P >= Q:\n                P = Q - 1\n            \n            # Evaluate the function at the interior points\n            fP = f(P)\n            fQ = f(Q)\n\n            # Update the bracket based on the function values.\n            # The rule f(P) <= f(Q) ensures that for plateaus (flat minima),\n            # the algorithm favors the left side, eventually finding the\n            # smallest integer minimizer.\n            if fP <= fQ:\n                b = Q\n            else:\n                a = P\n\n        # Termination: when b-a <= 2, the bracket is small enough.\n        # Perform a final exhaustive search on the remaining candidates.\n        min_val = f(a)\n        min_x = a\n        for x in range(a + 1, b + 1):\n            val = f(x)\n            # In case of a tie in value, the smaller x is kept.\n            if val < min_val:\n                min_val = val\n                min_x = x\n        \n        return min_x\n\n    # Define the five test functions as per the problem statement.\n    f1 = lambda x: (x - 321.7)**2\n    f2 = lambda x: np.abs(x - 250) + 0.001 * x\n    f3 = lambda x: np.maximum(np.abs(x - 700) - 2, 0)\n    f4 = lambda x: x**2\n    \n    def f5(x):\n        if x <= 873:\n            return 2 * (873 - x)\n        else:\n            return 3 * (x - 873)\n\n    test_cases = [f1, f2, f3, f4, f5]\n    initial_a, initial_b = 0, 1000\n\n    results = []\n    for f in test_cases:\n        result = golden_section_integer_search(f, initial_a, initial_b)\n        results.append(result)\n\n    # Print the final result in the specified format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "3166898"}]}