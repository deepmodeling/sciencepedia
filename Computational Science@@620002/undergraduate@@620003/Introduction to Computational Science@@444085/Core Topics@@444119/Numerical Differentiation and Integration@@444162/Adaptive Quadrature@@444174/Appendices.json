{"hands_on_practices": [{"introduction": "The most effective way to grasp the elegance of adaptive quadrature is to construct it from fundamental principles. This first practice challenges you to do just that, using the simple trapezoidal rule as a foundation. By comparing a coarse integral estimate with a more refined one, you will derive the error-estimation logic that is the engine of adaptivity, gaining a core understanding of how these algorithms intelligently focus their effort. [@problem_id:3284319]", "problem": "You are tasked with building a principled, self-contained program that implements an adaptive numerical integration scheme grounded in first principles for the trapezoidal rule. The core objective is to approximate the definite integral $\\int_{a}^{b} f(x)\\,dx$ for a series of test functions using an adaptive refinement strategy that estimates local error by comparing the trapezoidal approximation on the whole interval and the sum of trapezoidal approximations on its two halves.\n\nBegin from the definition of the definite integral as the limit of Riemann sums and the construction of the linear interpolant of $f(x)$ between $x=a$ and $x=b$. The trapezoidal rule for a single interval arises by integrating this linear interpolant over $[a,b]$. Your algorithm must:\n- On any subinterval $[a,b]$ with width $h=b-a$, compute the trapezoidal approximation on the whole interval and the combined trapezoidal approximation on its two halves $[a,m]$ and $[m,b]$ with $m=(a+b)/2$.\n- Use only the comparison between these two approximations (the whole interval versus the sum over two halves) to design a local error estimator, deduced from sound reasoning about how the local truncation error scales with interval width when the interval is halved. Do not assume or use any shortcut formulas not derived from this error-scaling reasoning.\n- Accept a subinterval if the estimated local error is below a prescribed tolerance, optionally using a bias-reduced corrected estimate derived from the same error-scaling principle; otherwise, split the interval and recurse on each half.\n- Ensure termination through a maximum recursion depth parameter $D_{\\max}$ and handle degenerate intervals with $a=b$ correctly.\n\nAngle units for any trigonometric function must be radians. There are no physical units in this problem. All numeric tolerances in the test suite are absolute tolerances.\n\nImplement your program to evaluate the following test suite. For each test case, compute the integral approximation using your adaptive trapezoidal scheme with the given tolerance, and aggregate the results into a single line of output in the specified format.\n\nTest Suite:\n1. $f(x)=\\sin(x)$ on $[0,\\pi]$ with tolerance $10^{-12}$.\n2. $f(x)=e^{-x^{2}}$ on $[0,1]$ with tolerance $10^{-12}$.\n3. $f(x)=\\dfrac{1}{1+x^{2}}$ on $[-5,5]$ with tolerance $10^{-10}$.\n4. $f(x)=|x|$ on $[-1,1]$ with tolerance $10^{-10}$.\n5. $f(x)=\\dfrac{\\sin(100x)}{1+x^{2}}$ on $[0,1]$ with tolerance $10^{-8}$.\n6. $f(x)=5$ on $[2,5]$ with tolerance $10^{-12}$.\n7. $f(x)=\\sin(x)$ on $[1,1]$ (zero-length interval) with tolerance $10^{-12}$.\n\nDesign for coverage:\n- The first case is a smooth periodic function over one full period.\n- The second case has a bell-shaped integrand with rapidly decaying tails within the interval.\n- The third case tests rational integrands over a symmetric large interval.\n- The fourth case tests a non-differentiable integrand at the midpoint.\n- The fifth case is oscillatory with moderate damping.\n- The sixth case is constant and should terminate immediately.\n- The seventh case is a boundary case with zero-length interval.\n\nFinal Output Format:\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, with no additional whitespace or text. For example: \"[r1,r2,r3,r4,r5,r6,r7]\". Each $r_{i}$ must be a floating-point number representing the integral approximation for the corresponding test case, computed by your adaptive trapezoidal method.", "solution": "The problem requires the development of an adaptive numerical integration scheme based on the trapezoidal rule. The core of the task is to derive an error estimation and refinement strategy from first principles, specifically by comparing a coarse approximation on an interval with a more refined one.\n\n### Principle-Based Derivation\n\nLet the definite integral to be approximated be $I = \\int_{a}^{b} f(x)\\,dx$.\n\n**1. The Trapezoidal Rule from First Principles**\n\nThe trapezoidal rule approximates the integrand $f(x)$ with a linear polynomial $p_1(x)$ that interpolates the function at the endpoints of the interval $[a, b]$. The coordinates of these points are $(a, f(a))$ and $(b, f(b))$. The linear interpolant is given by:\n$$p_1(x) = f(a) + \\frac{f(b) - f(a)}{b-a}(x - a)$$\nThe integral of this linear polynomial over the interval $[a, b]$ provides the trapezoidal approximation, denoted as $T(a,b)$. Let $h = b - a$ be the width of the interval.\n$$T(a,b) = \\int_{a}^{b} p_1(x) \\,dx = \\int_{a}^{b} \\left( f(a) + \\frac{f(b) - f(a)}{h}(x - a) \\right) \\,dx$$\n$$= \\left[ f(a)x + \\frac{f(b) - f(a)}{h} \\left( \\frac{x^2}{2} - ax \\right) \\right]_{a}^{b}$$\n$$= f(a)(b-a) + \\frac{f(b) - f(a)}{h} \\left( \\left(\\frac{b^2}{2} - ab\\right) - \\left(\\frac{a^2}{2} - a^2\\right) \\right)$$\n$$= f(a)h + \\frac{f(b) - f(a)}{h} \\left( \\frac{b^2 - 2ab + a^2}{2} \\right) = f(a)h + \\frac{f(b) - f(a)}{h} \\frac{(b-a)^2}{2}$$\n$$= f(a)h + (f(b) - f(a))\\frac{h}{2} = \\frac{h}{2}(2f(a) + f(b) - f(a)) = \\frac{h}{2}(f(a) + f(b))$$\nThis is the single-panel trapezoidal rule. Let's call this coarse approximation $S_1$.\n$$S_1 = \\frac{h}{2}(f(a) + f(b))$$\n\n**2. Error Estimation via Refinement**\n\nTo estimate the error, we compare $S_1$ with a more accurate approximation, $S_2$, obtained by splitting the interval $[a, b]$ into two subintervals of equal width, $[a, m]$ and $[m, b]$, where $m = (a+b)/2$. The width of each subinterval is $h/2$. The approximation $S_2$ is the sum of the trapezoidal rule applied to each subinterval:\n$$S_2 = T(a, m) + T(m, b) = \\frac{h/2}{2}(f(a) + f(m)) + \\frac{h/2}{2}(f(m) + f(b))$$\n$$S_2 = \\frac{h}{4}(f(a) + 2f(m) + f(b))$$\n\nThe local truncation error for the trapezoidal rule on an interval of width $w$ is given by $E(w) = -\\frac{w^3}{12}f''(\\xi)$ for some $\\xi$ in the interval, assuming $f$ is twice continuously differentiable. This shows that the error is proportional to the cube of the interval width, i.e., $E(w) \\approx Cw^3$.\n\nThe true integral $I$ can be related to our approximations $S_1$ and $S_2$ as follows:\n$I = S_1 + E(h) \\approx S_1 + Ch^3$\n$I = S_2 + E(h/2) + E(h/2) \\approx S_2 + 2C(h/2)^3 = S_2 + \\frac{Ch^3}{4}$\n\nWe now have a system of two equations for the two unknowns, $I$ and $C$:\n$I - S_1 \\approx Ch^3$\n$I - S_2 \\approx \\frac{Ch^3}{4}$\n\nSubtracting the second equation from the first yields:\n$(I - S_2) - (I - S_1) \\approx \\frac{Ch^3}{4} - Ch^3 \\implies S_1 - S_2 \\approx -\\frac{3}{4}Ch^3$\n\nThis allows us to express the unknown term $Ch^3$ in terms of our computed quantities $S_1$ and $S_2$:\n$Ch^3 \\approx \\frac{4}{3}(S_2 - S_1)$\n\nThe error in the more accurate approximation, $E_2 = I - S_2$, can now be estimated.\n$E_2 \\approx \\frac{Ch^3}{4} \\approx \\frac{1}{4} \\left( \\frac{4}{3}(S_2 - S_1) \\right) = \\frac{1}{3}(S_2 - S_1)$\n\nThe absolute local error for the refined approximation $S_2$ can thus be estimated as:\n$$\\text{err} \\approx \\frac{1}{3}|S_2 - S_1|$$\nThis estimator is derived solely from the comparison of the two approximations and the scaling property of the local error, as required.\n\n**3. Adaptive Algorithm and Bias Reduction**\n\nThe adaptive algorithm proceeds recursively. For a given interval $[a, b]$ and an absolute tolerance $\\tau$:\n1.  Calculate $S_1$, $S_2$, and the error estimate $\\text{err} = \\frac{1}{3}|S_2 - S_1|$.\n2.  If $\\text{err} < \\tau$, the interval is considered adequately approximated. The process for this branch terminates.\n3.  If $\\text{err} \\ge \\tau$, the interval is split into $[a, m]$ and $[m, b]$. The algorithm is then called recursively on each subinterval, with the tolerance budget split accordingly, typically $\\tau/2$ for each. The results from the recursive calls are summed.\n\nThe problem mentions using a \"bias-reduced corrected estimate\". This is an application of Richardson extrapolation. A better estimate for the true integral $I$ can be obtained by correcting $S_2$ with our error estimate $E_2$:\n$$I \\approx S_2 + E_2 \\approx S_2 + \\frac{1}{3}(S_2 - S_1) = \\frac{4S_2 - S_1}{3}$$\nThis corrected value is, in fact, Simpson's rule for the interval $[a,b]$:\n$$\\frac{4}{3} \\left( \\frac{h}{4}(f(a) + 2f(m) + f(b)) \\right) - \\frac{1}{3} \\left( \\frac{h}{2}(f(a) + f(b)) \\right) = \\frac{h}{3}(f(a) + 2f(m) + f(b)) - \\frac{h}{6}(f(a) + f(b))$$\n$$= \\frac{h}{6} (2f(a) + 4f(m) + 2f(b) - f(a) - f(b)) = \\frac{h}{6}(f(a) + 4f(m) + f(b))$$\nWhen an interval is accepted (i.e., $\\text{err} < \\tau$), returning this higher-order Simpson's rule approximation provides a more accurate result for the same number of function evaluations.\n\n**4. Implementation Structure and Termination**\n\nThe algorithm is implemented as a recursive function. A wrapper function initializes the process.\n- **Base Cases for Recursion:**\n    1.  If $a = b$, the integral is $0$.\n    2.  A maximum recursion depth, $D_{\\max}$, is imposed to guarantee termination, even if the tolerance criterion is never met (e.g., for certain pathological functions or insufficient floating-point precision). If this depth is reached, the current best estimate for the subinterval is returned.\n\n- **Recursive Step:**\n    An internal function, `_adaptive_trapezoid(f, a, b, tol, fa, fb, depth)`, will perform the main logic. Passing `fa=f(a)` and `fb=f(b)` as arguments avoids redundant function evaluations at shared endpoints between parent and child intervals. If the error criterion is not met, it makes two recursive calls:\n    `_adaptive_trapezoid(f, a, m, tol/2, fa, fm, depth+1) + _adaptive_trapezoid(f, m, b, tol/2, fm, fb, depth+1)`\n    where $m=(a+b)/2$ and $fm=f(m)$. This structure efficiently and robustly implements the adaptive integration scheme.", "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to solve the adaptive integration problem for the given test suite.\n    \"\"\"\n\n    MAX_DEPTH = 50\n\n    def _adaptive_trapezoid(f, a, b, tol, fa, fb, depth):\n        \"\"\"\n        Recursive helper function for adaptive trapezoidal integration.\n\n        This function approximates the integral of f(x) from a to b. It estimates\n        the error by comparing a one-panel trapezoid rule with a two-panel rule.\n        If the error is too large, it recursively calls itself on the two halves\n        of the interval.\n\n        Args:\n            f (callable): The function to integrate.\n            a (float): The start of the integration interval.\n            b (float): The end of the integration interval.\n            tol (float): The absolute tolerance for this subinterval.\n            fa (float): The value of f(a), passed to avoid re-computation.\n            fb (float): The value of f(b), passed to avoid re-computation.\n            depth (int): The current recursion depth.\n\n        Returns:\n            float: The approximated integral value for the interval [a, b].\n        \"\"\"\n        # Base case 1: Zero-length interval\n        if a == b:\n            return 0.0\n\n        # Base case 2: Maximum recursion depth reached\n        if depth > MAX_DEPTH:\n            # Reached depth limit, return best available coarse estimate.\n            # A warning could be printed here in a real application.\n            h = b - a\n            return (h / 2.0) * (fa + fb)\n\n        h = b - a\n        m = (a + b) / 2.0\n        fm = f(m)\n\n        # S1: Coarse approximation (1 trapezoid over [a,b])\n        s1 = (h / 2.0) * (fa + fb)\n\n        # S2: Finer approximation (2 trapezoids over [a,m] and [m,b])\n        s2 = (h / 4.0) * (fa + 2.0 * fm + fb)\n\n        # Estimate the error of the more accurate approximation, S2.\n        # This is derived from Richardson extrapolation, where error(S2) ~ (S2-S1)/3\n        error_estimate = abs(s2 - s1) / 3.0\n\n        if error_estimate < tol:\n            # Error is within tolerance. Return the bias-reduced (Simpson's rule) value.\n            # This is S2 + error_estimate, which is more accurate.\n            return s2 + (s2 - s1) / 3.0\n        else:\n            # Error is too large. Split the interval and recurse.\n            # The tolerance is split between the two sub-intervals.\n            left_integral = _adaptive_trapezoid(f, a, m, tol / 2.0, fa, fm, depth + 1)\n            right_integral = _adaptive_trapezoid(f, m, b, tol / 2.0, fm, fb, depth + 1)\n            return left_integral + right_integral\n\n    def adaptive_integrator(f, a, b, tol):\n        \"\"\"\n        Wrapper function to start the adaptive integration process.\n        \"\"\"\n        # Initial call to the recursive helper function.\n        # Pre-calculates f(a) and f(b) for efficiency.\n        return _adaptive_trapezoid(f, a, b, tol, f(a), f(b), 0)\n\n    # Test Suite Definition\n    test_cases = [\n        {'func': lambda x: np.sin(x), 'interval': (0, np.pi), 'tol': 1e-12},\n        {'func': lambda x: np.exp(-x**2), 'interval': (0, 1), 'tol': 1e-12},\n        {'func': lambda x: 1.0 / (1.0 + x**2), 'interval': (-5, 5), 'tol': 1e-10},\n        {'func': lambda x: np.abs(x), 'interval': (-1, 1), 'tol': 1e-10},\n        {'func': lambda x: np.sin(100 * x) / (1.0 + x**2), 'interval': (0, 1), 'tol': 1e-8},\n        {'func': lambda x: 5.0, 'interval': (2, 5), 'tol': 1e-12}, # Use 5.0 to ensure float\n        {'func': lambda x: np.sin(x), 'interval': (1, 1), 'tol': 1e-12},\n    ]\n\n    results = []\n    for case in test_cases:\n        f = case['func']\n        a, b = case['interval']\n        tol = case['tol']\n        \n        # Handle the zero-length interval case explicitly in the wrapper for clarity,\n        # although the recursion also handles it.\n        if a == b:\n            result = 0.0\n        else:\n            result = adaptive_integrator(f, a, b, tol)\n        \n        results.append(result)\n\n    # Format the final output string exactly as required.\n    # The repr() function provides a high-precision string representation of floats.\n    print(f\"[{','.join(map(repr, results))}]\")\n\nsolve()\n\n```", "id": "3284319"}, {"introduction": "While theoretically sound, simple numerical algorithms can fail when faced with real-world complexities like discontinuities. This practice explores such a failure mode, where an adaptive integrator can become trapped in an infinite refinement loop. You will engineer a robust solution by implementing a stopping criterion tied to the physical limits of floating-point arithmetic, a crucial step in transforming a textbook algorithm into a reliable scientific tool. [@problem_id:3203393]", "problem": "You are to design and implement an error-controlled adaptive quadrature algorithm that is robust in the presence of a jump discontinuity by introducing a principled stopping criterion tied to floating-point resolution. The context is the numerical approximation of a definite integral of a bounded function over a closed interval. The foundational base for this task consists of: (i) the definition of the Riemann integral as the limit of Riemann sums for a bounded function on a closed interval, (ii) interpolation-based composite quadrature rules derived from polynomial interpolation on equally spaced nodes, and (iii) the properties of floating-point arithmetic in double precision, particularly the concept of machine epsilon.\n\nTask requirements:\n- Implement an adaptive panel-refinement quadrature based on polynomial interpolation at three nodes per panel. Your recursion must be guided by an error indicator computed by comparing a single panel with its two child panels. Do not hard-code a maximum recursion depth; your method must be controlled by a numerical error tolerance and the robust stopping criterion described below.\n- Construct and use a robust stopping criterion that prevents unbounded refinement near a discontinuity by enforcing a minimum panel width tied to double-precision machine epsilon. Let the double-precision machine epsilon be denoted by $\\varepsilon_{\\mathrm{mach}}$, obtained programmatically. Define the minimum panel width as\n$$\nh_{\\min} \\;=\\; \\beta \\cdot \\max\\!\\big(1,\\lvert a \\rvert,\\lvert b \\rvert\\big) \\cdot \\varepsilon_{\\mathrm{mach}},\n$$\nwith $\\beta = 256$, where $[a,b]$ is the current panel. If a panel of width $h$ satisfies $h \\le h_{\\min}$, you must terminate refinement on that panel and accept the child-panel approximation without further subdivision. Additionally, if due to floating-point resolution the midpoint equals either endpoint, refinement must also be terminated on that panel.\n- Integrand: use the Heaviside step function shifted to the discontinuity at $x=\\frac{1}{2}$,\n$$\nf(x) = H(x - 0.5) = \n\\begin{cases}\n0, & x < 0.5,\\\\\n0, & x = 0.5,\\\\\n1, & x > 0.5,\n\\end{cases}\n$$\nwhere the value at the discontinuity is set to $0$ to force nontrivial refinement behavior.\n- Error tolerance: denote the user-specified tolerance by $\\tau$ and enforce it in the adaptive recursion via the child-versus-parent panel comparison. Your algorithm should return both the numerical integral approximation and a boolean indicator stating whether the minimum-width cap was triggered at least once during the recursion for that integral evaluation.\n\nTest suite:\nEvaluate the integral of $f(x)$ over each of the following intervals and tolerances:\n1. $[0,1]$ with $\\tau = 10^{-8}$.\n2. $[0,1]$ with $\\tau = 10^{-20}$.\n3. $[0,0.49]$ with $\\tau = 10^{-8}$.\n4. $[0.51,1]$ with $\\tau = 10^{-8}$.\n\nAnswer specification:\n- For each test case, return two outputs: the approximated integral value (a float) and the boolean indicator (true if the minimum-width cap was triggered, false otherwise).\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, in the order:\n$$\n[\\text{I}_1,\\text{C}_1,\\text{I}_2,\\text{C}_2,\\text{I}_3,\\text{C}_3,\\text{I}_4,\\text{C}_4],\n$$\nwhere $\\text{I}_k$ is the integral approximation (float) and $\\text{C}_k$ is the cap-trigger indicator (boolean) for test case $k$.\nNo physical units are involved, and no angles appear; all quantities are dimensionless.", "solution": "The problem statement is assessed to be valid. It is a well-posed, scientifically grounded problem in the field of numerical analysis. It provides a complete and consistent set of requirements for designing and implementing an adaptive quadrature algorithm with a robust stopping criterion for handling a function with a jump discontinuity. All parameters, the function to be integrated, and the test cases are specified unambiguously.\n\nThe solution is developed by synthesizing principles of numerical integration, error estimation, and floating-point arithmetic. The algorithm is a recursive, adaptive quadrature method based on Simpson's rule, augmented with a stopping criterion that ensures termination in the presence of discontinuities by respecting the limits of double-precision floating-point resolution.\n\nThe core components of the algorithm are as follows:\n\n1.  **Base Quadrature Rule: Simpson's Rule**\n    The problem specifies a quadrature rule based on polynomial interpolation at three nodes per panel. For a panel $[a, b]$, the standard choice of nodes is the endpoints $a$, $b$, and the midpoint $m = (a+b)/2$. The unique quadratic polynomial interpolating the function $f(x)$ at these points, $(a, f(a))$, $(m, f(m))$, and $(b, f(b))$, is integrated exactly to yield Simpson's rule. The approximation of the integral of $f(x)$ over $[a, b]$, denoted $S(a,b)$, is given by:\n    $$\n    S(a, b) = \\frac{b-a}{6} \\left( f(a) + 4f\\left(\\frac{a+b}{2}\\right) + f(b) \\right)\n    $$\n    Simpson's rule is exact for polynomials of degree up to $3$.\n\n2.  **Adaptive Refinement with Error Estimation**\n    The principle of adaptive quadrature is to refine panels only where the function is \"difficult\" to integrate, i.e., where the estimated integration error is large. This is achieved through a recursive process. For a given panel $[a, b]$, we compute a coarse approximation, $I_{parent} = S(a, b)$. We then subdivide the panel at its midpoint $m = (a+b)/2$ into two child panels, $[a, m]$ and $[m, b]$. A more refined approximation, $I_{children}$, is computed by summing the Simpson's rule results on each child panel:\n    $$\n    I_{children} = S(a, m) + S(m, b)\n    $$\n    The error of the coarse approximation, $S(a,b)$, is of order $\\mathcal{O}((b-a)^5)$, while the error of the refined approximation, $I_{children}$, is of order $\\mathcal{O}((m-a)^5 + (b-m)^5) = \\mathcal{O}(2 \\cdot (\\frac{b-a}{2})^5) = \\frac{1}{16}\\mathcal{O}((b-a)^5)$. This implies that the error of the refined approximation is approximately $1/16$ of the error of the coarse one. The difference between the two computed values can thus be used to estimate the error of the more accurate approximation, $I_{children}$:\n    $$\n    E_{children} \\approx \\frac{1}{15} |I_{children} - I_{parent}|\n    $$\n    The refinement is terminated for the panel $[a,b]$ if this estimated error is within a specified tolerance, $\\tau_{panel}$. A common strategy, which we adopt, is to check if $|I_{children} - I_{parent}| < 15 \\cdot \\tau_{panel}$. The global tolerance for the entire integration domain, denoted $\\tau$, is distributed to sub-panels. For bisection, a simple and effective method is to allocate half of the parent's tolerance to each child, so at each level of recursion for a panel, its tolerance is halved for its children.\n\n3.  **Robust Stopping Criterion for Discontinuities**\n    For a function with a jump discontinuity, like the specified Heaviside function $f(x) = H(x - 0.5)$, the error near the discontinuity at $x=0.5$ does not decrease at the expected rate with panel refinement. The error estimate will consistently fail the tolerance check, leading to unbounded recursion as the algorithm attempts to resolve the jump. To guarantee termination, a robust stopping criterion based on the limits of floating-point arithmetic is necessary. The specified criterion has two components, checked at the beginning of each recursive step for a panel $[a, b]$ of width $h=b-a$:\n    \n    a. **Minimum Panel Width ($h_{min}$)**: Refinement is halted if the panel width $h$ becomes smaller than a prescribed minimum, $h_{min}$. This minimum is defined relative to the scale of the interval endpoints and the machine precision, $\\varepsilon_{\\mathrm{mach}}$ (the smallest number such that $1.0 + \\varepsilon_{\\mathrm{mach}} > 1.0$ in floating-point arithmetic).\n    $$\n    h_{\\min} = \\beta \\cdot \\max(1, |a|, |b|) \\cdot \\varepsilon_{\\mathrm{mach}}\n    $$\n    With the given parameter $\\beta=256$, this establishes a floor for panel width, preventing infinite subdivision. If $h \\le h_{min}$, we cease recursion.\n\n    b. **Floating-Point Resolution Limit**: As $a$ and $b$ become very close, their midpoint $m = (a+b)/2$ may be computationally indistinguishable from $a$ or $b$. If $m=a$ or $m=b$, further subdivision is mathematically impossible in the given floating-point system. This condition serves as a fundamental backstop.\n\n    If either of these conditions is met, refinement on the current panel is terminated, and the refined approximation, $I_{children}$, is accepted as the result for that panel. A boolean flag is returned to indicate that this special termination was triggered.\n\n4.  **Algorithm Synthesis**\n    The complete algorithm is implemented as a recursive function. A main entry function, `adaptive_quadrature(func, a, b, tol)`, sets up the initial panel and tolerance and calls a recursive helper function.\n    The recursive helper, `_recursive_quad(func, a, b, tol_sub, ...)`, performs the following steps for its given panel:\n    i. Check the robust stopping criterion. If met, return the child-panel approximation $I_{children}$ and a `true` flag.\n    ii. Compute the parent $I_{parent}$ and child $I_{children}$ approximations.\n    iii. Calculate the error estimate $|I_{children} - I_{parent}|$.\n    iv. If the error is within the panel's tolerance ($< 15 \\cdot \\tau_{sub}$), return $I_{children}$ and a `false` flag.\n    v. Otherwise, recursively call the function for the two child-panels, $[a, m]$ and $[m, b]$, each with half the tolerance, $\\tau_{sub}/2$.\n    vi. Sum the integral results from the two child calls. The `cap_triggered` status is the logical OR of the statuses from the child calls, ensuring that if the cap is triggered in any sub-problem, the final result reflects this.\n\nThis design correctly implements all requirements, providing a robust numerical integrator capable of handling the specified test cases, including the challenging scenario of a very small tolerance on an interval containing a discontinuity, which is designed to specifically test the stopping criterion.", "answer": "```python\nimport numpy as np\n\n# A global constant for double-precision machine epsilon is defined for convenience.\n_EPS = np.finfo(float).eps\n\ndef f(x: float) -> float:\n    \"\"\"\n    Implements the integrand f(x) = H(x - 0.5), a Heaviside step function.\n    The value at the discontinuity x=0.5 is explicitly defined as 0.\n    \"\"\"\n    if x < 0.5:\n        return 0.0\n    elif x > 0.5:\n        return 1.0\n    else:  # x == 0.5\n        return 0.0\n\ndef _recursive_quad(func, a, b, tol, fa, fm, fb, I_panel):\n    \"\"\"\n    Recursive helper function for the adaptive quadrature algorithm.\n\n    This function performs one step of the adaptive refinement. It checks stopping criteria,\n    estimates error, and decides whether to accept the current approximation or to\n    recurse on sub-panels.\n\n    Args:\n        func: The function to integrate.\n        a, b: The endpoints of the current panel.\n        tol: The error tolerance for the current panel.\n        fa, fm, fb: Pre-computed function values at a, m=(a+b)/2, and b.\n        I_panel: The Simpson's rule approximation on the parent panel [a, b].\n\n    Returns:\n        A tuple (integral_value, cap_triggered), where integral_value is the\n        numerical approximation of the integral on [a, b], and cap_triggered\n        is a boolean indicating if the robust stopping criterion was met.\n    \"\"\"\n    h = b - a\n    m = (a + b) / 2.0\n\n    # 1. Robust Stopping Criterion\n    # This prevents unbounded recursion near discontinuities.\n    h_min = 256.0 * max(1.0, abs(a), abs(b)) * _EPS\n    cap_triggered_this_level = (h <= h_min) or (m == a) or (m == b)\n\n    # 2. Compute Refined Approximation\n    # Subdivide the panel and apply Simpson's rule to each child.\n    ml = (a + m) / 2.0\n    mr = (m + b) / 2.0\n    fml = func(ml)\n    fmr = func(mr)\n\n    # Simpson's rule over child panels [a, m] and [m, b]\n    # Note: width of each child panel is h/2. The (h/2)/6 factor is (b-a)/12.\n    I_left = (h / 12.0) * (fa + 4.0 * fml + fm)\n    I_right = (h / 12.0) * (fm + 4.0 * fmr + fb)\n    I_children = I_left + I_right\n\n    if cap_triggered_this_level:\n        # If the panel is too small, accept the child approximation and terminate.\n        return I_children, True\n\n    # 3. Error Estimation and Recursion Decision\n    error_est = abs(I_children - I_panel)\n\n    # The error in the refined sum (I_children) is approx. 1/15 of the difference.\n    # We stop if the estimated error is less than the allocated tolerance.\n    # The check is written as `error_est < 15 * tol` for numerical stability.\n    if error_est < 15.0 * tol:\n        # The problem asks to accept the child-panel approximation.\n        # A more advanced version would add a correction term: I_children + error_est / 15.0\n        return I_children, False\n    else:\n        # If error is too large, recurse on the two child panels.\n        # The tolerance is distributed (halved for each child).\n        tol_sub = tol / 2.0\n        integral_left, cap_left = _recursive_quad(func, a, m, tol_sub, fa, fml, fm, I_left)\n        integral_right, cap_right = _recursive_quad(func, m, b, tol_sub, fm, fmr, fb, I_right)\n\n        # Combine results and propagate the cap_triggered flag.\n        return integral_left + integral_right, cap_left or cap_right\n\ndef adaptive_quadrature(func, a, b, tol):\n    \"\"\"\n    Top-level function for error-controlled adaptive quadrature.\n\n    Args:\n        func: The function to integrate.\n        a, b: The overall integration interval [a, b].\n        tol: The absolute error tolerance for the entire interval.\n\n    Returns:\n        A tuple (integral_value, cap_triggered).\n    \"\"\"\n    h = b - a\n    if h == 0.0:\n        return 0.0, False\n    \n    m = (a + b) / 2.0\n    fa, fm, fb = func(a), func(m), func(b)\n\n    # Initial Simpson's rule approximation over the whole interval [a, b]\n    I_panel = h / 6.0 * (fa + 4.0 * fm + fb)\n\n    return _recursive_quad(func, a, b, tol, fa, fm, fb, I_panel)\n\ndef solve():\n    \"\"\"\n    Executes the test suite and prints the final answer in the specified format.\n    \"\"\"\n    test_cases = [\n        (0.0, 1.0, 1e-8),    # Case 1: Standard run with discontinuity\n        (0.0, 1.0, 1e-20),   # Case 2: Tiny tolerance, should trigger h_min cap\n        (0.0, 0.49, 1e-8),   # Case 3: Smooth region (f(x)=0)\n        (0.51, 1.0, 1e-8)    # Case 4: Smooth region (f(x)=1)\n    ]\n\n    results = []\n    for a, b, tol in test_cases:\n        integral, cap_triggered = adaptive_quadrature(f, a, b, tol)\n        results.append(integral)\n        # Format boolean as lowercase 'true'/'false' string as per problem implications\n        results.append(str(cap_triggered).lower())\n\n    # Format the final output as a single comma-separated list in brackets.\n    output_str = \",\".join(map(str, results))\n    print(f\"[{output_str}]\")\n\nsolve()\n```", "id": "3203393"}, {"introduction": "To solve large-scale scientific problems, efficiency is paramount, and parallelism is a key strategy for achieving it. The recursive, divide-and-conquer nature of adaptive quadrature is perfectly suited for parallel execution. This exercise guides you through a simulation of a parallel implementation, using worker threads and a shared task queue to understand how these complex integration tasks can be distributed for significant speedups. [@problem_id:2153050]", "problem": "Consider a parallel adaptive quadrature algorithm designed to approximate the definite integral of a function $f(x)$. The algorithm uses two worker threads, T1 and T2, which retrieve tasks from a shared work queue. The work queue is structured as a Last-In, First-Out (LIFO) stack. Each item in the queue is a tuple `(interval, tolerance)`, representing a sub-problem.\n\nThe algorithm is tasked with approximating the integral of the function $f(x) = x^{2}\\exp(-x)$ over the initial interval $[0, 5]$ with a total initial tolerance of $\\epsilon_{total} = 0.01$.\n\nThe core of the adaptive algorithm for an interval $[a, b]$ with a given tolerance $\\epsilon_{interval}$ is as follows:\n1.  Calculate a coarse approximation using Simpson's rule: $S(a,b) = \\frac{b-a}{6}\\left[f(a) + 4f\\left(\\frac{a+b}{2}\\right) + f(b)\\right]$.\n2.  Let $m = (a+b)/2$. Calculate a more refined approximation by summing the Simpson's rule results over the two sub-intervals: $I_{refined} = S(a,m) + S(m,b)$.\n3.  Estimate the error as $E = |I_{refined} - S(a,b)|$.\n4.  If $E < \\epsilon_{interval}$, the interval is considered \"accepted\". The value $I_{refined}$ is added to a global total, and processing for this interval is complete.\n5.  If $E \\geq \\epsilon_{interval}$, the interval is \"rejected\". The problem is subdivided by adding two new work items to the top of the LIFO stack: first `([m, b], \\epsilon_{interval}/2)` is pushed, and then `([a, m], \\epsilon_{interval}/2)` is pushed.\n\nThe parallel execution follows these rules:\n- The process starts with a single item in the work queue: `([0, 5], 0.01)`.\n- The simulation proceeds in discrete time steps.\n- At the beginning of a step, any idle thread attempts to pop an item from the work queue. If an item is successfully popped, the thread becomes busy for the duration of that step.\n- A busy thread performs the error-checking procedure described above. By the end of the step, if the interval was accepted, the thread becomes idle. If the interval was rejected, the thread pushes the two new sub-problems onto the stack and then becomes idle.\n- Thread T1 is available to take work at the beginning of Step 1. Thread T2 is available to take work at the beginning of Step 2. If both threads attempt to pop from the queue in the same step, assume T1's pop action occurs before T2's.\n\nYour task is to trace this parallel process. Determine the sum of the lengths of all intervals remaining in the work queue at the end of the step in which the second interval is accepted.\n\nRound your final answer to four significant figures.", "solution": "The problem asks for the sum of the lengths of intervals in the shared work queue at the end of the step where the second interval's integral approximation is accepted. We must trace the state of the system step by step.\n\nThe function is $f(x) = x^2\\exp(-x)$. The initial task is `(interval=[0, 5], tolerance=0.01)`. The work queue is a LIFO stack. Let $Q$ denote the queue.\n\nThe initial state is:\n- $Q = [([0, 5], 0.01)]$ (top of stack is on the right)\n- Accepted intervals count: 0\n\n**Step 1:**\n- T1 is available and idle. T2 is not yet available.\n- T1 pops `([0, 5], 0.01)`. The queue $Q$ becomes empty.\n- T1 processes the interval $[0, 5]$ with $\\epsilon = 0.01$. Let $I_0 = [0, 5]$.\n- Let $a=0, b=5, m=2.5$.\n- We calculate $f(0)=0, f(2.5) \\approx 0.51303, f(5) \\approx 0.16845$.\n- $S(0, 5) = \\frac{5-0}{6}[f(0) + 4f(2.5) + f(5)] \\approx \\frac{5}{6}[0 + 4(0.51303) + 0.16845] \\approx 1.85048$.\n- Next, we need $I_{refined} = S(0, 2.5) + S(2.5, 5)$.\n- For $S(0, 2.5)$: $m_1 = 1.25$. $f(1.25) \\approx 0.44766$.\n- $S(0, 2.5) = \\frac{2.5}{6}[f(0) + 4f(1.25) + f(2.5)] \\approx \\frac{2.5}{6}[0 + 4(0.44766) + 0.51303] \\approx 0.95987$.\n- For $S(2.5, 5)$: $m_2 = 3.75$. $f(3.75) \\approx 0.33072$.\n- $S(2.5, 5) = \\frac{2.5}{6}[f(2.5) + 4f(3.75) + f(5)] \\approx \\frac{2.5}{6}[0.51303 + 4(0.33072) + 0.16845] \\approx 0.83515$.\n- $I_{refined} = 0.95987 + 0.83515 = 1.79502$.\n- The error is $E = |1.79502 - 1.85048| = 0.05546$.\n- We check if $E < \\epsilon$: $0.05546 < 0.01$ is false. The interval is rejected.\n- T1 pushes two new tasks with $\\epsilon' = 0.01/2 = 0.005$.\n- Push 1 (right sub-interval): `([2.5, 5], 0.005)`.\n- Push 2 (left sub-interval): `([0, 2.5], 0.005)`.\n- At the end of Step 1, T1 becomes idle. The queue is $Q = [([2.5, 5], 0.005), ([0, 2.5], 0.005)]$.\n\n**Step 2:**\n- T1 and T2 are both available and idle.\n- T1 pops first: `([0, 2.5], 0.005)`.\n- T2 pops next: `([2.5, 5], 0.005)`.\n- The queue $Q$ becomes empty. Both threads are busy.\n- **T1 processes $[0, 2.5]$ with $\\epsilon = 0.005$**:\n  - We already know $S(0, 2.5) \\approx 0.95987$. We need to refine it.\n  - $S(0, 1.25) \\approx 0.26749$ (using $f(0.625) \\approx 0.20907$).\n  - $S(1.25, 2.5) \\approx 0.64944$ (using $f(1.875) \\approx 0.53915$).\n  - $I_{refined} = 0.26749 + 0.64944 = 0.91693$.\n  - Error $E_1 = |0.91693 - 0.95987| = 0.04294$.\n  - $0.04294 < 0.005$ is false. T1 rejects the interval.\n- **T2 processes $[2.5, 5]$ with $\\epsilon = 0.005$**:\n  - We know $S(2.5, 5) \\approx 0.83515$. We refine it.\n  - $S(2.5, 3.75) \\approx 0.53323$ (using $f(3.125) \\approx 0.42894$).\n  - $S(3.75, 5) \\approx 0.30474$ (using $f(4.375) \\approx 0.24089$).\n  - $I_{refined} = 0.53323 + 0.30474 = 0.83797$.\n  - Error $E_2 = |0.83797 - 0.83515| = 0.00282$.\n  - $0.00282 < 0.005$ is true. T2 accepts the interval. This is the **first** accepted interval.\n- At the end of Step 2:\n  - T1 (rejected) pushes two new tasks with $\\epsilon' = 0.005/2 = 0.0025$: `([1.25, 2.5], 0.0025)` then `([0, 1.25], 0.0025)`.\n  - T2 (accepted) does not push. It adds its result to the global sum and becomes idle.\n  - The queue is $Q = [([1.25, 2.5], 0.0025), ([0, 1.25], 0.0025)]$.\n  - Accepted intervals count: 1.\n\n**Step 3:**\n- We are looking for the second accepted interval. We continue.\n- T1 and T2 are both available and idle.\n- T1 pops first: `([0, 1.25], 0.0025)`.\n- T2 pops next: `([1.25, 2.5], 0.0025)`.\n- The queue $Q$ becomes empty. Both threads are busy.\n- **T1 processes $[0, 1.25]$ with $\\epsilon = 0.0025$**:\n  - We know $S(0, 1.25) \\approx 0.26749$. We refine it.\n  - $S(0, 0.625) \\approx 0.05155$ (using $f(0.3125) \\approx 0.07144$).\n  - $S(0.625, 1.25) \\approx 0.21184$ (using $f(0.9375) \\approx 0.34424$).\n  - $I_{refined} = 0.05155 + 0.21184 = 0.26339$.\n  - Error $E_1 = |0.26339 - 0.26749| = 0.0041$.\n  - $0.0041 < 0.0025$ is false. T1 rejects the interval.\n- **T2 processes $[1.25, 2.5]$ with $\\epsilon = 0.0025$**:\n  - We know $S(1.25, 2.5) \\approx 0.64944$. We refine it.\n  - $S(1.25, 1.875) \\approx 0.31601$ (using $f(1.5625) \\approx 0.51172$).\n  - $S(1.875, 2.5) \\approx 0.33330$ (using $f(2.1875) \\approx 0.53688$).\n  - $I_{refined} = 0.31601 + 0.33330 = 0.64931$.\n  - Error $E_2 = |0.64931 - 0.64944| = 0.00013$.\n  - $0.00013 < 0.0025$ is true. T2 accepts the interval. This is the **second** accepted interval.\n- The end of Step 3 is the moment specified in the question.\n- At the end of Step 3:\n  - T1 (rejected) pushes two new tasks with $\\epsilon' = 0.0025/2 = 0.00125$: `([0.625, 1.25], 0.00125)` then `([0, 0.625], 0.00125)`.\n  - T2 (accepted) does not push and becomes idle.\n  - The final state of the queue is $Q = [([0.625, 1.25], 0.00125), ([0, 0.625], 0.00125)]$.\n\nThe question asks for the sum of the lengths of all intervals remaining in the work queue.\nThe intervals in the queue are:\n1.  $[0, 0.625]$\n2.  $[0.625, 1.25]$\n\nThe lengths of these intervals are:\n- Length of $[0, 0.625]$ is $0.625 - 0 = 0.625$.\n- Length of $[0.625, 1.25]$ is $1.25 - 0.625 = 0.625$.\n\nThe sum of the lengths is $0.625 + 0.625 = 1.25$.\n\nThe problem requires rounding the final answer to four significant figures.\n$1.25$ expressed with four significant figures is $1.250$.", "answer": "$$\\boxed{1.250}$$", "id": "2153050"}]}