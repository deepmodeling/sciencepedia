{"hands_on_practices": [{"introduction": "Before we can programmatically control numerical error, we must first understand its mathematical origins and behavior. This practice [@problem_id:3125390] provides a foundational exercise in the theory of numerical integration. You will derive and compare two distinct forms of the global error bound for composite Simpson's rule: a 'worst-case' bound based on the maximum value ($L^\\infty$ norm) of the function's fourth derivative, and an 'average' bound based on the root-mean-square value ($L^2$ norm). By comparing these bounds for a specific oscillatory function, you will gain insight into when one type of error analysis might be more informative than another.", "problem": "Let $Q_{S,m}(f)$ denote the composite Simpson quadrature applied to a function $f$ on the interval $[0,1]$ using $m$ equal subintervals, where $m$ is an even positive integer and the mesh width is $h = 1/m$. Consider the quadrature error functional $E_m(f) = \\int_{0}^{1} f(x)\\,dx - Q_{S,m}(f)$. Your tasks are:\n\n- Using Taylor’s theorem with integral remainder and the fact that Simpson’s rule is exact for all polynomials of degree up to $3$, derive a global error bound of the form $|E_m(f)| \\leq C_{\\infty}\\, h^{4} \\, \\sup_{x \\in [0,1]} |f^{(4)}(x)|$ for some explicit constant $C_{\\infty} > 0$ that does not depend on $f$ or $m$.\n\n- Using the Peano kernel theorem for quadrature rules of order $4$ and the Cauchy–Schwarz inequality, derive an average-based global error bound of the form $|E_m(f)| \\leq C_{2}\\, h^{4}\\, \\|f^{(4)}\\|_{L^{2}(0,1)}$, where $\\|g\\|_{L^{2}(0,1)} = \\left(\\int_{0}^{1} |g(x)|^{2}\\,dx\\right)^{1/2}$ denotes the Lebesgue square-integrable space ($L^{2}$) norm on $[0,1]$. Determine the explicit constant $C_{2} > 0$ that does not depend on $f$ or $m$.\n\n- Specialize both bounds to $f(x) = \\sin(10x)$ on $[0,1]$. Compute the explicit constants multiplying $h^{4}$ in both bounds, and form the ratio $R$ defined as\n$R = \\dfrac{\\text{(average-based $L^{2}$ bound on $|E_m(f)|$)}}{\\text{(supremum-based bound on $|E_m(f)|$)}}.$\nGive $R$ as a single simplified analytic expression in terms of elementary constants and functions. Conclude which bound is tighter for this $f$ by comparing $R$ to $1$. Your final reported quantity must be the expression for $R$. No numerical rounding is required. Express angles in radians.", "solution": "The user-provided problem is a standard exercise in numerical analysis concerning error bounds for composite quadrature rules. It is scientifically grounded, well-posed, objective, and contains all necessary information. The problem is valid.\n\nThe problem asks for the derivation and comparison of two types of error bounds for the composite Simpson's rule. Let's address each part sequentially.\n\n**Part 1: Supremum-based ($L^{\\infty}$) Error Bound**\n\nThe composite Simpson's rule $Q_{S,m}(f)$ approximates a definite integral $\\int_{0}^{1} f(x)\\,dx$ by dividing the interval $[0,1]$ into $m$ equal subintervals of width $h = 1/m$. Since Simpson's rule is applied over pairs of subintervals, $m$ is an even integer. Let $m=2n$. We apply the basic Simpson's rule over the $n$ intervals $[x_{2i}, x_{2i+2}]$ for $i=0, 1, \\dots, n-1$, where $x_j = jh$. The width of each such interval is $2h$.\n\nThe error of the composite rule is the sum of the local errors on each interval $[x_{2i}, x_{2i+2}]$:\n$$E_m(f) = \\int_{0}^{1} f(x)\\,dx - Q_{S,m}(f) = \\sum_{i=0}^{n-1} \\left( \\int_{x_{2i}}^{x_{2i+2}} f(x)\\,dx - \\frac{h}{3}[f(x_{2i}) + 4f(x_{2i+1}) + f(x_{2i+2})] \\right)$$\nThe error for the basic Simpson's rule on an interval $[a, b]$ is given by $E_{[a,b]}(f) = -\\frac{(b-a)^5}{2880} f^{(4)}(\\eta)$ for some $\\eta \\in (a, b)$, provided $f \\in C^4([a,b])$. This formula is derived using the fact that the rule is exact for polynomials of degree up to $3$. For one of our subintervals $[x_{2i}, x_{2i+2}]$, the length is $b-a = 2h$. The local error is therefore:\n$$E_i(f) = -\\frac{(2h)^5}{2880} f^{(4)}(\\eta_i) = -\\frac{32h^5}{2880} f^{(4)}(\\eta_i) = -\\frac{h^5}{90} f^{(4)}(\\eta_i)$$\nfor some $\\eta_i \\in (x_{2i}, x_{2i+2})$.\n\nThe total error is the sum of these $n = m/2$ local errors:\n$$E_m(f) = \\sum_{i=0}^{n-1} \\left(-\\frac{h^5}{90} f^{(4)}(\\eta_i)\\right) = -\\frac{h^5}{90} \\sum_{i=0}^{m/2-1} f^{(4)}(\\eta_i)$$\nTaking the absolute value, we get:\n$$|E_m(f)| = \\left| -\\frac{h^5}{90} \\sum_{i=0}^{m/2-1} f^{(4)}(\\eta_i) \\right| \\leq \\frac{h^5}{90} \\sum_{i=0}^{m/2-1} |f^{(4)}(\\eta_i)|$$\nBy bounding each $|f^{(4)}(\\eta_i)|$ by the supremum of $|f^{(4)}(x)|$ over the entire interval $[0,1]$, we have:\n$$|E_m(f)| \\leq \\frac{h^5}{90} \\sum_{i=0}^{m/2-1} \\sup_{x \\in [0,1]} |f^{(4)}(x)|$$\nThe sum has $n = m/2$ identical terms:\n$$|E_m(f)| \\leq \\frac{m}{2} \\frac{h^5}{90} \\sup_{x \\in [0,1]} |f^{(4)}(x)|$$\nSubstituting $m = 1/h$:\n$$|E_m(f)| \\leq \\frac{1}{2h} \\frac{h^5}{90} \\sup_{x \\in [0,1]} |f^{(4)}(x)| = \\frac{h^4}{180} \\sup_{x \\in [0,1]} |f^{(4)}(x)|$$\nThis is the desired error bound. The constant is $C_{\\infty} = \\frac{1}{180}$.\n\n**Part 2: Average-based ($L^{2}$) Error Bound**\n\nFor a quadrature rule of order $4$ (exact for polynomials of degree $3$), the Peano kernel theorem states that the error functional $E_m(f)$ can be expressed as:\n$$E_m(f) = \\int_{0}^{1} K_m(t) f^{(4)}(t)\\,dt$$\nwhere $K_m(t) = E_{m,x}\\left[\\frac{(x-t)_+^3}{3!}\\right]$ is the Peano kernel for the composite rule. By the Cauchy-Schwarz inequality:\n$$|E_m(f)| \\leq \\left( \\int_{0}^{1} |K_m(t)|^2\\,dt \\right)^{1/2} \\left( \\int_{0}^{1} |f^{(4)}(t)|^2\\,dt \\right)^{1/2} = \\|K_m\\|_{L^2(0,1)} \\|f^{(4)}\\|_{L^2(0,1)}$$\nThe composite kernel $K_m(t)$ is the juxtaposition of $n=m/2$ translated local kernels. The integral of its square is the sum of the integrals of the squares of the local kernels:\n$$\\|K_m\\|_{L^2(0,1)}^2 = \\int_{0}^{1} |K_m(t)|^2\\,dt = \\sum_{i=0}^{n-1} \\int_{x_{2i}}^{x_{2i+2}} |K_i(t)|^2\\,dt$$\nwhere $K_i(t)$ is the local kernel on $[x_{2i}, x_{2i+2}]$. By translation invariance, this simplifies to:\n$$\\|K_m\\|_{L^2(0,1)}^2 = n \\int_{-h}^{h} |K_{loc}(t)|^2\\,dt$$\nwhere $K_{loc}(t)$ is the Peano kernel for the basic Simpson's rule on $[-h, h]$. For $t \\in [0,h]$, the kernel is $K_{loc}(t) = -\\frac{(h-t)^3(h+3t)}{72}$. Since $K_{loc}(t)$ is an even function, we have:\n$$\\int_{-h}^{h} |K_{loc}(t)|^2\\,dt = 2 \\int_{0}^{h} \\left(-\\frac{(h-t)^3(h+3t)}{72}\\right)^2\\,dt = \\frac{2}{72^2} \\int_{0}^{h} (h-t)^6 (h+3t)^2\\,dt$$\nLet $u = h-t$, so $t = h-u$ and $dt = -du$. The integral becomes:\n$$\\int_{h}^{0} u^6 (h+3(h-u))^2 (-du) = \\int_{0}^{h} u^6 (4h-3u)^2\\,du = \\int_{0}^{h} (16h^2u^6 - 24hu^7 + 9u^8)\\,du$$\n$$= \\left[ \\frac{16h^2u^7}{7} - \\frac{24hu^8}{8} + \\frac{9u^9}{9} \\right]_0^h = \\frac{16}{7}h^9 - 3h^9 + h^9 = \\left(\\frac{16}{7}-2\\right)h^9 = \\frac{2}{7}h^9$$\nThus, $\\int_{-h}^{h} |K_{loc}(t)|^2\\,dt = \\frac{2}{72^2} \\cdot \\frac{2}{7}h^9 = \\frac{4}{5184 \\cdot 7}h^9 = \\frac{1}{9072}h^9$.\nNow we compute the squared $L^2$-norm of the composite kernel, using $n=m/2=1/(2h)$:\n$$\\|K_m\\|_{L^2(0,1)}^2 = n \\frac{h^9}{9072} = \\frac{1}{2h} \\frac{h^9}{9072} = \\frac{h^8}{18144}$$\nTaking the square root:\n$$\\|K_m\\|_{L^2(0,1)} = \\sqrt{\\frac{h^8}{18144}} = \\frac{h^4}{\\sqrt{18144}} = \\frac{h^4}{\\sqrt{36^2 \\cdot 14}} = \\frac{h^4}{36\\sqrt{14}}$$\nThe error bound is $|E_m(f)| \\leq \\frac{h^4}{36\\sqrt{14}} \\|f^{(4)}\\|_{L^2(0,1)}$. The constant is $C_2 = \\frac{1}{36\\sqrt{14}}$.\n\n**Part 3: Specialization and Ratio Calculation**\n\nLet $f(x) = \\sin(10x)$. We need its fourth derivative:\n$f'(x) = 10\\cos(10x)$, $f''(x) = -100\\sin(10x)$, $f'''(x) = -1000\\cos(10x)$, $f^{(4)}(x) = 10000\\sin(10x) = 10^4\\sin(10x)$.\n\nThe supremum-based bound requires $\\sup_{x \\in [0,1]} |f^{(4)}(x)|$.\n$$\\sup_{x \\in [0,1]} |10^4\\sin(10x)| = 10^4 \\sup_{x \\in [0,1]} |\\sin(10x)|$$\nThe argument $10x$ ranges from $0$ to $10$ radians. Since $10 > \\pi/2$, the supremum is $1$.\n$$\\sup_{x \\in [0,1]} |f^{(4)}(x)| = 10^4$$\nThe supremum-based error bound is $|E_m(f)| \\leq \\frac{1}{180} h^4 \\cdot 10^4 = \\frac{500}{9} h^4$.\n\nThe average-based bound requires $\\|f^{(4)}\\|_{L^2(0,1)}$.\n$$\\|f^{(4)}\\|_{L^2(0,1)}^2 = \\int_{0}^{1} (10^4\\sin(10x))^2\\,dx = 10^8 \\int_{0}^{1} \\sin^2(10x)\\,dx$$\nUsing $\\sin^2(\\theta) = \\frac{1-\\cos(2\\theta)}{2}$:\n$$\\int_{0}^{1} \\sin^2(10x)\\,dx = \\int_{0}^{1} \\frac{1-\\cos(20x)}{2}\\,dx = \\frac{1}{2}\\left[x - \\frac{\\sin(20x)}{20}\\right]_0^1 = \\frac{1}{2} - \\frac{\\sin(20)}{40}$$\nSo, $\\|f^{(4)}\\|_{L^2(0,1)} = \\sqrt{10^8 \\left(\\frac{1}{2} - \\frac{\\sin(20)}{40}\\right)} = 10^4 \\sqrt{\\frac{1}{2} - \\frac{\\sin(20)}{40}}$.\nThe average-based error bound is $|E_m(f)| \\leq \\frac{h^4}{36\\sqrt{14}} \\cdot 10^4 \\sqrt{\\frac{1}{2} - \\frac{\\sin(20)}{40}}$.\n\nThe ratio $R$ is defined as the average-based bound divided by the supremum-based bound:\n$$R = \\frac{\\left( \\frac{h^4}{36\\sqrt{14}} \\cdot 10^4 \\sqrt{\\frac{1}{2} - \\frac{\\sin(20)}{40}} \\right)}{\\left( \\frac{1}{180} h^4 \\cdot 10^4 \\right)}$$\nThe terms $h^4$ and $10^4$ cancel out:\n$$R = \\frac{180}{36\\sqrt{14}} \\sqrt{\\frac{1}{2} - \\frac{\\sin(20)}{40}} = \\frac{5}{\\sqrt{14}} \\sqrt{\\frac{20 - \\sin(20)}{40}}$$\n$$R = \\frac{5}{\\sqrt{14}\\sqrt{40}} \\sqrt{20 - \\sin(20)} = \\frac{5}{\\sqrt{560}} \\sqrt{20 - \\sin(20)}$$\nSince $\\sqrt{560} = \\sqrt{16 \\cdot 35} = 4\\sqrt{35}$, we have:\n$$R = \\frac{5}{4\\sqrt{35}} \\sqrt{20 - \\sin(20)}$$\nTo determine which bound is tighter, we compare $R$ to $1$.\n$$R^2 = \\frac{25}{16 \\cdot 35} (20 - \\sin(20)) = \\frac{5}{112} (20 - \\sin(20))$$\nSince $|\\sin(20)| \\leq 1$, we have $19 \\leq 20 - \\sin(20) \\leq 21$.\n$R^2 \\leq \\frac{5}{112}(21) = \\frac{105}{112} < 1$.\nSince $R > 0$, we have $R < 1$. This means the average-based ($L^2$) bound is tighter for this function $f(x) = \\sin(10x)$.", "answer": "$$\\boxed{\\frac{5}{4\\sqrt{35}}\\sqrt{20 - \\sin(20)}}$$", "id": "3125390"}, {"introduction": "Theoretical error bounds, while insightful, often depend on higher-order derivatives of the function which may be unknown or expensive to compute. Therefore, practical algorithms rely on *a posteriori* error estimates that use only computed function values. This exercise [@problem_id:3125467] dives into this practical reality by comparing two common estimation strategies: a two-step Richardson extrapolation technique and a simpler embedded method. Through a carefully constructed example, you will discover that not all estimators are created equal and see how a seemingly plausible approach can fail, underscoring the need for robust error estimation in automated numerical routines.", "problem": "Consider the definite integral of a smooth function $f(x)$ on $[0,1]$ and the use of composite rules on a uniform grid. You will compare two approaches to estimating the error of composite Simpson’s rule: (i) a two-step estimate based on computing composite Simpson on step sizes $h$ and $h/2$, and (ii) an embedded estimate formed by taking differences of nested rules computed on the same grid (here, the composite Simpson and composite trapezoidal rules). Work with the specific quartic polynomial\n$$\nf(x) \\;=\\; \\frac{16}{3}\\left(\\left(x-\\frac{1}{2}\\right)^{2} - \\frac{1}{16}\\right)\\left(-8\\left(x-\\frac{1}{2}\\right)^{2} + 3\\right),\n$$\nwhich is symmetric about $x=\\frac{1}{2}$, satisfies $f(0)=1$, $f\\!\\left(\\frac{1}{4}\\right)=0$, $f\\!\\left(\\frac{1}{2}\\right)=-1$, $f\\!\\left(\\frac{3}{4}\\right)=0$, and $f(1)=1$, and is not identically zero on $[0,1]$.\n\nLet $h=\\frac{1}{4}$ (so there are $N=4$ subintervals) and let $h/2=\\frac{1}{8}$ (so there are $N=8$ subintervals). Denote by $S(h)$ and $S(h/2)$ the corresponding composite Simpson approximations, and by $T(h)$ and $T(h/2)$ the corresponding composite trapezoidal approximations. Let $I=\\int_{0}^{1}f(x)\\,dx$ denote the exact integral.\n\nYou should use the first principles that define the composite trapezoidal rule (endpoints with weight $1$ and interior nodes with weight $2$ scaled by $\\frac{h}{2}$) and the composite Simpson rule (alternating weights $4$ and $2$ on odd and even interior nodes, respectively, with endpoints weight $1$ scaled by $\\frac{h}{3}$), together with the fact that for sufficiently smooth $f$ the leading-order global error of composite Simpson scales like $h^4$.\n\nWhich of the following statements is correct for this $f$ and these grids?\n\nA. On the coarse grid $h=\\frac{1}{4}$, the embedded difference $\\lvert S(h)-T(h)\\rvert$ equals $0$ and would incorrectly suggest negligible error, whereas the two-step estimate based on $h$ and $h/2$ exactly matches the true error $\\lvert I-S(h/2)\\rvert=\\frac{1}{720}$.\n\nB. On the refined grid $h/2=\\frac{1}{8}$, the embedded difference $\\lvert S(h/2)-T(h/2)\\rvert$ equals the true error $\\lvert I-S(h/2)\\rvert$, and the two-step estimate is $0$.\n\nC. Both the embedded difference and the two-step estimate are $0$ because composite Simpson is exact for quartic polynomials on a uniform grid.\n\nD. The two-step estimate equals $\\frac{1}{192}$ while the coarse-grid embedded difference equals $\\frac{1}{720}$, so the embedded estimate is more reliable in this case.", "solution": "The problem statement is a valid exercise in numerical analysis. It is self-contained, with a clearly defined function, integration interval, numerical methods, and grid parameters. The stated properties of the function are mathematically consistent with its definition, and the question is well-posed. We may proceed with the solution.\n\nThe primary task is to compute several numerical approximations of the integral $I = \\int_{0}^{1} f(x) \\, dx$ and compare different error estimates. The function is given by\n$$f(x) = -\\frac{128}{3}\\left(x-\\frac{1}{2}\\right)^4 + \\frac{56}{3}\\left(x-\\frac{1}{2}\\right)^2 - 1$$\nThis is a quartic polynomial. It is an even function with respect to the point $x=\\frac{1}{2}$. The problem specifies two uniform grids on $[0,1]$: a coarse grid with step size $h=\\frac{1}{4}$ ($N=4$ subintervals) and a refined grid with step size $h/2=\\frac{1}{8}$ ($N=8$ subintervals).\n\nFirst, we evaluate the function $f(x)$ at the necessary grid points.\nThe coarse grid points are $\\{0, \\frac{1}{4}, \\frac{1}{2}, \\frac{3}{4}, 1\\}$. From the problem statement, we have:\n$f(0) = 1$\n$f(\\frac{1}{4}) = 0$\n$f(\\frac{1}{2}) = -1$\n$f(\\frac{3}{4}) = 0$\n$f(1) = 1$\n\nThe fine grid points are $\\{0, \\frac{1}{8}, \\frac{1}{4}, \\frac{3}{8}, \\frac{1}{2}, \\frac{5}{8}, \\frac{3}{4}, \\frac{7}{8}, 1\\}$. We need to compute the function values at the new points: $\\frac{1}{8}, \\frac{3}{8}, \\frac{5}{8}, \\frac{7}{8}$.\nFor $x=\\frac{1}{8}$, $x-\\frac{1}{2} = -\\frac{3}{8}$.\n$f(\\frac{1}{8}) = -\\frac{128}{3}(-\\frac{3}{8})^4 + \\frac{56}{3}(-\\frac{3}{8})^2 - 1 = -\\frac{128}{3}\\frac{81}{4096} + \\frac{56}{3}\\frac{9}{64} - 1 = -\\frac{27}{32} + \\frac{63}{24} - 1 = \\frac{-27+84-32}{32} = \\frac{25}{32}$.\nFor $x=\\frac{3}{8}$, $x-\\frac{1}{2} = -\\frac{1}{8}$.\n$f(\\frac{3}{8}) = -\\frac{128}{3}(-\\frac{1}{8})^4 + \\frac{56}{3}(-\\frac{1}{8})^2 - 1 = -\\frac{128}{3}\\frac{1}{4096} + \\frac{56}{3}\\frac{1}{64} - 1 = -\\frac{1}{96} + \\frac{7}{24} - 1 = \\frac{-1+28-96}{96} = -\\frac{69}{96} = -\\frac{23}{32}$.\nBy symmetry, $f(\\frac{7}{8}) = f(\\frac{1}{8}) = \\frac{25}{32}$ and $f(\\frac{5}{8}) = f(\\frac{3}{8}) = -\\frac{23}{32}$.\n\nNext, we calculate the integral approximations.\n**Composite Trapezoidal Rule:** $T_N = h \\left( \\frac{f(x_0)+f(x_N)}{2} + \\sum_{i=1}^{N-1} f(x_i) \\right)$.\nFor $h=\\frac{1}{4}$ ($N=4$):\n$$T(h) = T(1/4) = \\frac{1}{4} \\left( \\frac{f(0)+f(1)}{2} + f(1/4)+f(1/2)+f(3/4) \\right) = \\frac{1}{4} \\left( \\frac{1+1}{2} + 0 - 1 + 0 \\right) = 0$$\nFor $h/2=\\frac{1}{8}$ ($N=8$):\n$$T(h/2) = T(1/8) = \\frac{1}{8} \\left( \\frac{f(0)+f(1)}{2} + \\sum_{i=1}^{7} f(x_i) \\right)$$\nThe sum is $f(\\frac{1}{8}) + f(\\frac{1}{4}) + f(\\frac{3}{8}) + f(\\frac{1}{2}) + f(\\frac{5}{8}) + f(\\frac{3}{4}) + f(\\frac{7}{8}) = \\frac{25}{32} + 0 - \\frac{23}{32} - 1 - \\frac{23}{32} + 0 + \\frac{25}{32} = \\frac{4}{32} - 1 = -\\frac{7}{8}$.\n$$T(1/8) = \\frac{1}{8} \\left( 1 - \\frac{7}{8} \\right) = \\frac{1}{8} \\cdot \\frac{1}{8} = \\frac{1}{64}$$\n\n**Composite Simpson's Rule:** $S_N = \\frac{h}{3} \\left( f(x_0) + 4\\sum_{i=1}^{N/2} f(x_{2i-1}) + 2\\sum_{i=1}^{N/2-1} f(x_{2i}) + f(x_N) \\right)$.\nFor $h=\\frac{1}{4}$ ($N=4$):\n$$S(h) = S(1/4) = \\frac{1/4}{3} \\left( f(0) + 4f(1/4) + 2f(1/2) + 4f(3/4) + f(1) \\right) = \\frac{1}{12} \\left( 1 + 4(0) + 2(-1) + 4(0) + 1 \\right) = 0$$\nFor $h/2=\\frac{1}{8}$ ($N=8$):\n$$S(h/2) = S(1/8) = \\frac{1/8}{3} \\left( f(0) + 4(f_{1/8}+f_{3/8}+f_{5/8}+f_{7/8}) + 2(f_{1/4}+f_{1/2}+f_{3/4}) + f(1) \\right)$$\nThe sum over odd-indexed interior points is $2(f(\\frac{1}{8})+f(\\frac{3}{8})) = 2(\\frac{25}{32}-\\frac{23}{32}) = 2(\\frac{2}{32}) = \\frac{1}{8}$.\nThe sum over even-indexed interior points is $0 - 1 + 0 = -1$.\n$$S(1/8) = \\frac{1}{24} \\left( 1 + 4(\\frac{1}{8}) + 2(-1) + 1 \\right) = \\frac{1}{24} \\left( 1 + \\frac{1}{2} - 2 + 1 \\right) = \\frac{1}{24} \\cdot \\frac{1}{2} = \\frac{1}{48}$$\n\nNow we compute the exact integral $I$. Let $u = x-\\frac{1}{2}$, so $dx = du$.\n$$I = \\int_{-1/2}^{1/2} \\left( -\\frac{128}{3}u^4 + \\frac{56}{3}u^2 - 1 \\right) du = 2 \\int_{0}^{1/2} \\left( -\\frac{128}{3}u^4 + \\frac{56}{3}u^2 - 1 \\right) du$$\n$$I = 2 \\left[ -\\frac{128}{15}u^5 + \\frac{56}{9}u^3 - u \\right]_0^{1/2} = 2 \\left( -\\frac{128}{15}(\\frac{1}{32}) + \\frac{56}{9}(\\frac{1}{8}) - \\frac{1}{2} \\right)$$\n$$I = 2 \\left( -\\frac{4}{15} + \\frac{7}{9} - \\frac{1}{2} \\right) = 2 \\left( \\frac{-24+70-45}{90} \\right) = 2 \\left( \\frac{1}{90} \\right) = \\frac{1}{45}$$\n\nWe now evaluate the error estimates and true errors.\n**True error for $S(h/2)$:**\n$$\\lvert I - S(h/2)\\rvert = \\left\\lvert \\frac{1}{45} - \\frac{1}{48} \\right\\rvert = \\left\\lvert \\frac{16 - 15}{720} \\right\\rvert = \\frac{1}{720}$$\n**Two-step estimate:** For Simpson's rule, a method of order $p=4$, the error estimate for the refined result $S(h/2)$ is given by Richardson extrapolation:\n$$E_{2S} = \\frac{S(h/2) - S(h)}{2^p - 1} = \\frac{S(1/8) - S(1/4)}{2^4 - 1} = \\frac{1/48 - 0}{15} = \\frac{1}{48 \\times 15} = \\frac{1}{720}$$\nThis estimate is based on the assumption that the error is of the form $E(h) \\approx C h^4$. For a quartic polynomial, $f^{(4)}(x)$ is a constant, and the error formula for composite Simpson's rule, $E_S(h) = -\\frac{b-a}{180} h^4 f^{(4)}(\\xi)$, becomes exact: $E_S(h) = C h^4$. This is why the two-step estimate exactly matches the true error.\n\n**Embedded difference estimate:**\nOn the coarse grid ($h=\\frac{1}{4}$):\n$$\\lvert S(h) - T(h) \\rvert = \\lvert S(1/4) - T(1/4) \\rvert = \\lvert 0 - 0 \\rvert = 0$$\nOn the refined grid ($h/2=\\frac{1}{8}$):\n$$\\lvert S(h/2) - T(h/2) \\rvert = \\lvert S(1/8) - T(1/8) \\rvert = \\left\\lvert \\frac{1}{48} - \\frac{1}{64} \\right\\rvert = \\left\\lvert \\frac{4 - 3}{192} \\right\\rvert = \\frac{1}{192}$$\n\nWe can now evaluate each statement.\n\n**A. On the coarse grid $h=\\frac{1}{4}$, the embedded difference $\\lvert S(h)-T(h)\\rvert$ equals $0$ and would incorrectly suggest negligible error, whereas the two-step estimate based on $h$ and $h/2$ exactly matches the true error $\\lvert I-S(h/2)\\rvert=\\frac{1}{720}$.**\n- The coarse-grid embedded difference $\\lvert S(1/4)-T(1/4)\\rvert$ is indeed $0$.\n- This estimate of $0$ is a poor indicator of the true error of $S(1/4)$, which is $\\lvert I-S(1/4) \\rvert = \\lvert \\frac{1}{45} - 0 \\rvert = \\frac{1}{45}$. So it \"incorrectly suggest[s] negligible error.\"\n- The two-step estimate is $\\frac{1}{720}$.\n- The true error $\\lvert I-S(h/2)\\rvert$ is $\\frac{1}{720}$.\n- The two-step estimate exactly matches the true error.\nEvery part of this statement is correct.\n\n**B. On the refined grid $h/2=\\frac{1}{8}$, the embedded difference $\\lvert S(h/2)-T(h/2)\\rvert$ equals the true error $\\lvert I-S(h/2)\\rvert$, and the two-step estimate is $0$.**\n- The embedded difference on the refined grid is $\\frac{1}{192}$. The true error is $\\frac{1}{720}$. These are not equal. The first clause is false.\n- The two-step estimate is $\\frac{1}{720}$, not $0$. The second clause is false.\nThis statement is **Incorrect**.\n\n**C. Both the embedded difference and the two-step estimate are $0$ because composite Simpson is exact for quartic polynomials on a uniform grid.**\n- The coarse-grid embedded difference is $0$, but the refined-grid embedded difference is $\\frac{1}{192}$, and the two-step estimate is $\\frac{1}{720}$. The claim \"Both ... are $0$\" is false.\n- The reasoning \"because composite Simpson is exact for quartic polynomials\" is false. Composite Simpson's rule is exact for polynomials of degree at most $3$, as its error term depends on the fourth derivative, which is zero for cubics but non-zero for quartics.\nThis statement is **Incorrect**.\n\n**D. The two-step estimate equals $\\frac{1}{192}$ while the coarse-grid embedded difference equals $\\frac{1}{720}$, so the embedded estimate is more reliable in this case.**\n- The two-step estimate is $\\frac{1}{720}$, not $\\frac{1}{192}$.\n- The coarse-grid embedded difference is $0$, not $\\frac{1}{720}$.\nThe values stated are incorrect.\nThis statement is **Incorrect**.\n\nBased on the analysis, only statement A is correct.", "answer": "$$\\boxed{A}$$", "id": "3125467"}, {"introduction": "The ultimate goal of error analysis is to build algorithms that automatically deliver a result with a guaranteed accuracy. This final practice [@problem_id:3125400] is the capstone of this chapter, guiding you to synthesize the preceding concepts into a complete adaptive quadrature algorithm. You will implement a routine that uses the robust error estimation technique from our previous practice to recursively refine the integration grid. A key feature of this exercise is the implementation of a sophisticated mixed absolute/relative error tolerance, a technique used in professional-grade software to ensure reliability for a wide range of functions, including those whose integrals are close to zero.", "problem": "You are to design and implement a complete, runnable program that constructs an adaptive composite quadrature rule for a one-dimensional definite integral. The goal is to control a mixed error target that combines an absolute error tolerance and a relative error tolerance, where the relative error is defined with respect to the integral of the absolute value of the integrand. Specifically, you must estimate the integral of the function $f$ and, concurrently, estimate the integral of the absolute value $\\lvert f \\rvert$, so that panels with small $\\lvert f \\rvert$ do not dominate the relative error requirement due to absolute tolerances.\n\nStarting from fundamental definitions of a definite integral $\\int_a^b f(x)\\,dx$ and composite quadrature rules formed by subdividing the interval $[a,b]$ into panels, you must construct an adaptive algorithm that:\n- Subdivides panels recursively based on a local error estimate derived from principled arguments consistent with Taylor expansion and asymptotic truncation error of composite rules.\n- Assigns a local acceptance threshold per panel that mixes an absolute budget and a relative budget, where the absolute budget is distributed proportionally to the panel length inside $[a,b]$ and the relative budget in a panel is proportional to the panel’s local estimate of $\\int \\lvert f \\rvert$. This design ensures that panels with small $\\lvert f \\rvert$ are not forced to excessively refine due to relative error constraints and instead use the absolute budget.\n- Aggregates accepted panels to produce a global approximation of $\\int_a^b f(x)\\,dx$ and a global approximation of $\\int_a^b \\lvert f(x) \\rvert\\,dx$.\n\nDefine the global acceptance criterion in mixed form with given absolute tolerance $t_{\\mathrm{abs}}$ and relative tolerance $t_{\\mathrm{rel}}$ as requiring the absolute error of $\\int_a^b f(x)\\,dx$ to be less than or equal to $t_{\\mathrm{abs}} + t_{\\mathrm{rel}} \\int_a^b \\lvert f(x) \\rvert\\,dx$. You must verify the result against a high-accuracy reference computed independently. All trigonometric functions in this problem use radians.\n\nYour program must implement:\n- An adaptive composite rule with local error estimation and a local acceptance threshold that includes both an absolute-budget term proportional to the panel length $(b-a)$ within the total length $(B-A)$ and a relative-budget term proportional to the panel’s local estimate of $\\int \\lvert f \\rvert$.\n- Concurrent estimation of both $\\int f$ and $\\int \\lvert f \\rvert$ in every panel using a consistent quadrature stencil, so that the relative tolerance applies meaningfully to the magnitude of the integral rather than its signed value alone.\n\nTest Suite:\nFor each test case below, compute the numerical approximation $I_{\\mathrm{num}}$ to $\\int_a^b f(x)\\,dx$ using your adaptive method, compute a high-accuracy reference $I_{\\mathrm{ref}}$ and $A_{\\mathrm{ref}} = \\int_a^b \\lvert f(x) \\rvert\\,dx$, and then output a boolean indicating whether the mixed acceptance criterion $\\lvert I_{\\mathrm{ref}} - I_{\\mathrm{num}} \\rvert \\le t_{\\mathrm{abs}} + t_{\\mathrm{rel}} A_{\\mathrm{ref}}$ is satisfied.\n\nThe required angle unit for any trigonometric function is radians.\n\nUse the following test cases, each specified by $(f, a, b, t_{\\mathrm{abs}}, t_{\\mathrm{rel}})$:\n\n- Case $1$: $f(x) = \\sin(x)$, $a=0$, $b=2\\pi$, $t_{\\mathrm{abs}} = 10^{-10}$, $t_{\\mathrm{rel}} = 10^{-6}$.\n- Case $2$: $f(x) = \\sin(50 x)$, $a=0$, $b=1$, $t_{\\mathrm{abs}} = 10^{-9}$, $t_{\\mathrm{rel}} = 5\\cdot 10^{-4}$.\n- Case $3$: $f(x) = x - 0.5$, $a=0$, $b=1$, $t_{\\mathrm{abs}} = 10^{-10}$, $t_{\\mathrm{rel}} = 10^{-6}$.\n- Case $4$: $f(x) = e^{-100 (x-0.5)^2} \\cos(10 x)$, $a=0$, $b=1$, $t_{\\mathrm{abs}} = 10^{-10}$, $t_{\\mathrm{rel}} = 10^{-6}$.\n\nFinal Output Format:\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (e.g., $[r_1,r_2,r_3,r_4]$), where each $r_i$ is a boolean for the corresponding test case indicating whether the mixed criterion was satisfied. No additional text should be printed.", "solution": "The problem of numerically approximating a definite integral, $I = \\int_a^b f(x)\\,dx$, is a fundamental task in computational science. While simple composite rules like the trapezoidal or Simpson's rule are effective for well-behaved functions on a uniform grid, they can be highly inefficient for functions with varying degrees of smoothness across the integration domain. An adaptive quadrature algorithm addresses this by selectively refining the integration grid, placing more computational effort in regions where the function is complex and fewer in regions where it is smooth.\n\nThe core of an adaptive algorithm is a local error estimation procedure and a corresponding acceptance criterion. We will construct our method based on the well-established Simpson's quadrature rule and a Richardson extrapolation-based error estimate.\n\n**1. Base Quadrature Rule and Error Estimation**\n\nFor a single panel $[c,d]$ of width $h = d-c$, Simpson's rule provides an estimate of the integral:\n$$ S(f, c, d) = \\frac{h}{6} \\left[ f(c) + 4f\\left(\\frac{c+d}{2}\\right) + f(d) \\right] $$\nThe local truncation error of this rule is known from Taylor series analysis to be $E_S \\approx C h^5 f^{(4)}(\\xi)$ for some constant $C$ and some $\\xi \\in (c,d)$. The error is of order $O(h^5)$.\n\nTo estimate this error without knowing the derivatives of $f(x)$, we compare two approximations of the integral over $[c,d]$ with different accuracies.\nLet $S_1$ be the coarse estimate using one application of Simpson's rule over the full panel $[c,d]$.\nLet $S_2$ be the fine estimate obtained by subdividing the panel into two halves, $[c,m]$ and $[m,d]$ where $m=(c+d)/2$, and summing their respective Simpson's rule results: $S_2 = S(f, c, m) + S(f, m, d)$.\n\nThe error of the coarse rule $S_1$ (with step $h$) is $E_1 \\approx C h^5 f^{(4)}(\\xi_1)$.\nThe error of the finer rule $S_2$ is the sum of errors from two panels of step $h/2$, so $E_2 \\approx 2 \\times C (h/2)^5 f^{(4)}(\\xi_2) = \\frac{1}{16} C h^5 f^{(4)}(\\xi_2)$.\nAssuming $f^{(4)}(x)$ is slowly varying over the panel, we have $E_1 \\approx 16 E_2$.\nThe true integral $I$ can be written as $I = S_1 + E_1$ and $I = S_2 + E_2$.\nSubtracting these gives $S_2 - S_1 = E_1 - E_2 \\approx 15 E_2$.\nThus, the absolute error in the more accurate estimate, $S_2$, can be estimated as:\n$$ E_{S_2} \\approx \\frac{|S_2 - S_1|}{15} $$\nFurthermore, we can obtain an even better estimate for the integral itself by applying Richardson extrapolation. The improved estimate, which corresponds to Boole's rule, is:\n$$ I_{\\text{panel}} \\approx S_2 + E_2 = S_2 + \\frac{S_2 - S_1}{15} $$\nThis higher-order estimate will be used for panels that are accepted.\n\n**2. Mixed Error Criterion and Local Tolerance**\n\nA standard relative error criterion $\\frac{|I_{\\text{num}}-I_{\\text{ref}}|}{|I_{\\text{ref}}|} \\le t_{\\text{rel}}$ is problematic when the true integral $I_{\\text{ref}}$ is close to zero. The proposed mixed error criterion avoids this by using the integral of the absolute value of the function as the basis for the relative tolerance:\n$$ |I_{\\text{num}} - I_{\\text{ref}}| \\le t_{\\text{abs}} + t_{\\text{rel}} \\int_a^b |f(x)|\\,dx $$\nTo achieve this global error target, we must distribute the tolerance budget among the local panels. For a panel $[c,d]$ of width $h=d-c$ within the total interval $[A,B]$ of width $W=B-A$, we define a local tolerance $\\tau$ by partitioning the global absolute and relative budgets as specified:\n- The absolute tolerance budget $t_{\\text{abs}}$ is distributed proportionally to the panel width: $t_{\\text{abs}} \\frac{h}{W}$.\n- The relative tolerance budget is made proportional to the magnitude of the integral on the panel. We use our numerical estimate for $\\int_c^d |f(x)|\\,dx$, let's call it $A_{\\text{panel}}$, for this purpose. The contribution is $t_{\\text{rel}} A_{\\text{panel}}$.\n\nThe local tolerance for the panel is the sum of these two parts:\n$$ \\tau_{\\text{panel}} = t_{\\text{abs}} \\frac{h}{W} + t_{\\text{rel}} A_{\\text{panel}} $$\nA panel is accepted if its estimated error in the integral of $f(x)$, which is $|S_{2,f} - S_{1,f}|/15$, is less than or equal to this local tolerance.\n\n**3. The Adaptive Algorithm**\n\nThe overall algorithm proceeds as follows, using a stack to manage panels for subdivision and avoid deep recursion.\n\n1.  Initialize total integral estimates for $f$ and $|f|$ to zero: $I_{\\text{total}} = 0$, $A_{\\text{total}} = 0$.\n2.  Push the initial panel, $(a, b)$, onto a stack.\n3.  While the stack is not empty:\n    a. Pop a panel $(c, d)$.\n    b. Concurrently compute the coarse ($S_1$) and fine ($S_2$) integral estimates for both $f(x)$ and $|f(x)|$ over this panel. This requires evaluating the functions at $5$ points.\n    c. Estimate the error for the integral of $f$: $E_f = |S_{2,f} - S_{1,f}|/15$.\n    d. The estimate for the integral of $|f|$ on the panel is $A_{\\text{panel}} = S_{2,|f|} + (S_{2,|f|} - S_{1,|f|})/15$. Since $|f(x)| \\ge 0$, we ensure $A_{\\text{panel}} \\ge 0$.\n    e. Calculate the local tolerance $\\tau_{\\text{panel}} = t_{\\text{abs}} \\frac{d-c}{b-a} + t_{\\text{rel}} A_{\\text{panel}}$.\n    f. If $E_f \\le \\tau_{\\text{panel}}$ (or if the panel is smaller than a machine-precision threshold), accept the panel. Add its improved integral estimates, $I_{\\text{panel},f}$ and $A_{\\text{panel}}$, to the respective total sums $I_{\\text{total}}$ and $A_{\\text{total}}$.\n    g. If the panel is not accepted, subdivide it at its midpoint $m=(c+d)/2$ and push the two new sub-panels, $(c, m)$ and $(m, d)$, onto the stack for further processing.\n4.  The final result is the accumulated sum $I_{\\text{total}}$. This procedure concentrates computational effort on complex regions of the function while efficiently processing smoother regions, all while adhering to a robust mixed error criterion.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy import integrate\n\ndef adaptive_quadrature(f, a, b, t_abs, t_rel):\n    \"\"\"\n    Computes the definite integral of f from a to b using an adaptive\n    composite quadrature rule based on Simpson's method and a mixed\n    error tolerance.\n    \"\"\"\n    # A small number to prevent division by zero or infinite loops for tiny intervals.\n    MIN_INTERVAL_WIDTH = 1e-15\n\n    # Wrapper for the absolute value of the function\n    abs_f = lambda x: np.abs(f(x))\n\n    # Storing tuple of (c, d) for each panel to be processed\n    panel_stack = [(a, b)]\n\n    total_integral_f = 0.0\n    total_width = b - a\n\n    # Max iteration guard to prevent potential infinite loops on pathological functions\n    max_panels = 100000\n    panel_count = 0\n\n    while panel_stack and panel_count < max_panels:\n        panel_count += 1\n        c, d = panel_stack.pop()\n        h = d - c\n\n        # If panel is too small, accept it and its contribution is likely negligible anyway.\n        if h < MIN_INTERVAL_WIDTH:\n            # Use a simple rule for this tiny interval\n            m = c + h / 2.0\n            total_integral_f += (h / 6.0) * (f(c) + 4.0 * f(m) + f(d))\n            continue\n\n        # 5 points for Simpson's rule comparison (1 coarse, 2 fine)\n        x0, x1, x2, x3, x4 = c, c + h * 0.25, c + h * 0.5, c + h * 0.75, d\n\n        # Evaluations for f\n        f_vals = np.array([f(x0), f(x1), f(x2), f(x3), f(x4)])\n        # Evaluations for |f|\n        abs_f_vals = np.abs(f_vals)\n\n        # Coarse estimate (S1) for f over [c, d]\n        s1_f = (h / 6.0) * (f_vals[0] + 4.0 * f_vals[2] + f_vals[4])\n        # Fine estimate (S2) for f over [c, d]\n        s2_f = (h / 12.0) * (f_vals[0] + 4.0 * f_vals[1] + 2.0 * f_vals[2] + 4.0 * f_vals[3] + f_vals[4])\n\n        # Coarse estimate (S1) for |f|\n        s1_absf = (h / 6.0) * (abs_f_vals[0] + 4.0 * abs_f_vals[2] + abs_f_vals[4])\n        # Fine estimate (S2) for |f|\n        s2_absf = (h / 12.0) * (abs_f_vals[0] + 4.0 * abs_f_vals[1] + 2.0 * abs_f_vals[2] + 4.0 * abs_f_vals[3] + abs_f_vals[4])\n\n        # Error estimate for the integral of f\n        error_f = np.abs(s2_f - s1_f) / 15.0\n\n        # Boole's rule estimate for the integral of |f| on the panel\n        # Ensure it's non-negative as it's used for tolerance scaling.\n        integral_absf_panel = s2_absf + (s2_absf - s1_absf) / 15.0\n        integral_absf_panel = np.maximum(0, integral_absf_panel)\n\n        # Local tolerance for the panel\n        local_tolerance = t_abs * (h / total_width) + t_rel * integral_absf_panel\n        \n        # If error is acceptable, add improved estimate to total and continue\n        if error_f <= local_tolerance:\n            # Boole's rule (Richardson extrapolation) gives a more accurate result\n            integral_f_panel = s2_f + (s2_f - s1_f) / 15.0\n            total_integral_f += integral_f_panel\n        else:\n            # Subdivide panel and push halves to stack\n            m = x2\n            panel_stack.append((c, m))\n            panel_stack.append((m, d))\n\n    return total_integral_f\n\ndef solve():\n    \"\"\"\n    Main function to run the test suite and print the results.\n    \"\"\"\n    test_cases = [\n        (lambda x: np.sin(x), 0, 2 * np.pi, 1e-10, 1e-6),\n        (lambda x: np.sin(50 * x), 0, 1, 1e-9, 5e-4),\n        (lambda x: x - 0.5, 0, 1, 1e-10, 1e-6),\n        (lambda x: np.exp(-100 * (x-0.5)**2) * np.cos(10 * x), 0, 1, 1e-10, 1e-6),\n    ]\n\n    results = []\n    for f, a, b, t_abs, t_rel in test_cases:\n        # Calculate numerical integral using our implemented method\n        I_num = adaptive_quadrature(f, a, b, t_abs, t_rel)\n\n        # Calculate high-accuracy reference values using scipy.integrate.quad\n        I_ref, _ = integrate.quad(f, a, b, epsabs=1e-14, epsrel=1e-14)\n        abs_f = lambda x: np.abs(f(x))\n        A_ref, _ = integrate.quad(abs_f, a, b, epsabs=1e-14, epsrel=1e-14)\n\n        # Check if the mixed error criterion is satisfied\n        actual_error = np.abs(I_ref - I_num)\n        allowed_error = t_abs + t_rel * A_ref\n        \n        results.append(actual_error <= allowed_error)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "3125400"}]}