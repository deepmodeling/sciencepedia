{"hands_on_practices": [{"introduction": "The cornerstone of working with orthogonal polynomials is understanding how they are constructed. This exercise guides you through the fundamental Gram-Schmidt process to build the first two orthogonal polynomials on a general interval $[a, b]$. Mastering this hands-on calculation solidifies the concept of an inner product and provides a concrete understanding of what it means for functions to be orthogonal [@problem_id:2192753].", "problem": "Consider the vector space of real-valued polynomials defined on a general interval $[a, b]$, where $a$ and $b$ are real constants with $a < b$. This space is equipped with an inner product defined for any two polynomials $f(x)$ and $g(x)$ as:\n$$\n\\langle f, g \\rangle = \\int_a^b f(x)g(x) \\, dx\n$$\nStarting with the basis $\\{v_0(x) = 1, v_1(x) = x\\}$ for the subspace of polynomials of degree at most one, construct a set of two orthogonal polynomials $\\{p_0(x), p_1(x)\\}$. The constructed polynomials must satisfy the following conditions:\n1.  The set $\\{p_0(x), p_1(x)\\}$ forms an orthogonal basis for the subspace spanned by $\\{1, x\\}$, meaning $\\langle p_0, p_1 \\rangle = 0$.\n2.  Both $p_0(x)$ and $p_1(x)$ are monic polynomials. A polynomial is monic if its leading coefficient (the coefficient of the highest power of $x$) is 1. For a constant polynomial $c$, it is considered monic if $c=1$.\n\nExpress your answer as a pair of polynomials $(p_0(x), p_1(x))$ in a row matrix.", "solution": "We are given the inner product on polynomials over $[a,b]$ defined by $\\langle f, g \\rangle = \\int_{a}^{b} f(x)g(x)\\,dx$ and the starting basis $\\{v_{0}(x), v_{1}(x)\\} = \\{1, x\\}$ for the subspace of degree at most one. We will use the Gram-Schmidt process while enforcing the monic requirement.\n\nFirst, take $p_{0}(x)$ from $v_{0}(x)=1$. Since a constant polynomial is monic if and only if it equals $1$, we set\n$$\np_{0}(x) = 1.\n$$\n\nNext, orthogonalize $v_{1}(x)=x$ against $p_{0}(x)$:\n$$\nu_{1}(x) = v_{1}(x) - \\frac{\\langle v_{1}, p_{0} \\rangle}{\\langle p_{0}, p_{0} \\rangle} p_{0}(x).\n$$\nCompute the required inner products:\n$$\n\\langle v_{1}, p_{0} \\rangle = \\int_{a}^{b} x \\cdot 1 \\, dx = \\frac{b^{2} - a^{2}}{2},\n\\qquad\n\\langle p_{0}, p_{0} \\rangle = \\int_{a}^{b} 1 \\cdot 1 \\, dx = b - a.\n$$\nHence\n$$\n\\frac{\\langle v_{1}, p_{0} \\rangle}{\\langle p_{0}, p_{0} \\rangle} = \\frac{\\frac{b^{2} - a^{2}}{2}}{b - a} = \\frac{a + b}{2}.\n$$\nTherefore,\n$$\nu_{1}(x) = x - \\frac{a + b}{2}.\n$$\nThis polynomial is already monic (its leading coefficient is $1$), so we set\n$$\np_{1}(x) = x - \\frac{a + b}{2}.\n$$\n\nVerify orthogonality:\n$$\n\\langle p_{0}, p_{1} \\rangle = \\int_{a}^{b} 1 \\cdot \\left(x - \\frac{a + b}{2}\\right) dx\n= \\left[\\frac{x^{2}}{2} - \\frac{a + b}{2}x\\right]_{a}^{b}\n= \\frac{b^{2} - a^{2}}{2} - \\frac{a + b}{2}(b - a) = 0,\n$$\nsince $b^{2} - a^{2} = (b - a)(a + b)$. Thus $\\{p_{0}, p_{1}\\}$ is an orthogonal set, and both polynomials are monic.\n\nHence, an orthogonal monic basis for the subspace spanned by $\\{1,x\\}$ is\n$$\np_{0}(x) = 1, \\qquad p_{1}(x) = x - \\frac{a + b}{2}.\n$$", "answer": "$$\\boxed{\\begin{pmatrix} 1 & x - \\frac{a+b}{2} \\end{pmatrix}}$$", "id": "2192753"}, {"introduction": "While the Gram-Schmidt process is fundamental, a more efficient and numerically stable method for generating orthogonal polynomials is the three-term recurrence relation, especially when dealing with discrete data points from an experiment. This practice challenges you to compute the coefficients for such a recurrence, bridging the gap between continuous theory and discrete data-fitting applications [@problem_id:2192741]. This approach is central to many advanced algorithms in scientific computing.", "problem": "In the numerical analysis of experimental data, it is often advantageous to work with a basis of functions that are orthogonal with respect to the data points. Consider a set of four experimental measurements at coordinates $\\{x_i\\} = \\{0, 1, 3, 6\\}$. We are interested in generating a sequence of monic polynomials $\\{p_k(x)\\}_{k=0}^\\infty$ that are orthogonal with respect to a discrete inner product.\n\nThe inner product of two real-valued functions, $f(x)$ and $g(x)$, over this set of points is defined as:\n$$ \\langle f, g \\rangle = \\sum_{i=1}^{4} f(x_i) g(x_i) $$\nThe sequence of orthogonal monic polynomials is generated by the three-term recurrence relation:\n$$ p_{k+1}(x) = (x - \\alpha_k) p_k(x) - \\beta_k p_{k-1}(x) $$\nfor $k \\ge 0$, with the initial conditions defined as $p_0(x) = 1$ and $p_{-1}(x) = 0$.\n\nYour task is to determine the exact value of the recurrence coefficient $\\alpha_1$. Express your final answer as a fraction in simplest form.", "solution": "We use the given discrete inner product\n$$\\langle f, g \\rangle = \\sum_{i=1}^{4} f(x_{i}) g(x_{i}), \\quad \\{x_{i}\\}=\\{0,1,3,6\\},$$\nand the monic three-term recurrence\n$$p_{k+1}(x)=(x-\\alpha_{k})p_{k}(x)-\\beta_{k}p_{k-1}(x), \\quad p_{0}(x)=1,\\; p_{-1}(x)=0.$$\n\nFor monic orthogonal polynomials, taking the inner product of the recurrence with $p_{k}$ yields\n$$\\langle p_{k+1},p_{k}\\rangle=\\langle (x-\\alpha_{k})p_{k},p_{k}\\rangle-\\beta_{k}\\langle p_{k-1},p_{k}\\rangle.$$\nBy orthogonality, $\\langle p_{k+1},p_{k}\\rangle=0$ and $\\langle p_{k-1},p_{k}\\rangle=0$, hence\n$$0=\\langle x p_{k},p_{k}\\rangle-\\alpha_{k}\\langle p_{k},p_{k}\\rangle,$$\nso\n$$\\alpha_{k}=\\frac{\\langle x p_{k},p_{k}\\rangle}{\\langle p_{k},p_{k}\\rangle}.$$\n\nFirst, compute $\\alpha_{0}$:\n$$\\alpha_{0}=\\frac{\\langle x p_{0},p_{0}\\rangle}{\\langle p_{0},p_{0}\\rangle}\n=\\frac{\\sum_{i=1}^{4} x_{i}}{\\sum_{i=1}^{4} 1}\n=\\frac{0+1+3+6}{4}\n=\\frac{10}{4}\n=\\frac{5}{2}.$$\nThus\n$$p_{1}(x)=x-\\alpha_{0}=x-\\frac{5}{2}.$$\n\nNow compute $\\alpha_{1}$ using\n$$\\alpha_{1}=\\frac{\\langle x p_{1},p_{1}\\rangle}{\\langle p_{1},p_{1}\\rangle}\n=\\frac{\\sum_{i=1}^{4} x_{i}\\,p_{1}(x_{i})^{2}}{\\sum_{i=1}^{4} p_{1}(x_{i})^{2}}.$$\nEvaluate $p_{1}(x)$ at the data points:\n$$p_{1}(0)=-\\frac{5}{2},\\quad p_{1}(1)=-\\frac{3}{2},\\quad p_{1}(3)=\\frac{1}{2},\\quad p_{1}(6)=\\frac{7}{2}.$$\nSquares:\n$$p_{1}(0)^{2}=\\frac{25}{4},\\quad p_{1}(1)^{2}=\\frac{9}{4},\\quad p_{1}(3)^{2}=\\frac{1}{4},\\quad p_{1}(6)^{2}=\\frac{49}{4}.$$\nDenominator:\n$$\\langle p_{1},p_{1}\\rangle=\\frac{25}{4}+\\frac{9}{4}+\\frac{1}{4}+\\frac{49}{4}=\\frac{84}{4}=21.$$\nNumerator:\n$$\\langle x p_{1},p_{1}\\rangle=0\\cdot\\frac{25}{4}+1\\cdot\\frac{9}{4}+3\\cdot\\frac{1}{4}+6\\cdot\\frac{49}{4}\n=\\frac{9}{4}+\\frac{3}{4}+\\frac{294}{4}=\\frac{306}{4}=\\frac{153}{2}.$$\nTherefore\n$$\\alpha_{1}=\\frac{\\frac{153}{2}}{21}=\\frac{153}{42}=\\frac{51}{14}.$$\nThis fraction is already in simplest form.", "answer": "$$\\boxed{\\frac{51}{14}}$$", "id": "2192741"}, {"introduction": "With the tools to construct orthogonal polynomials, we can now apply them to solve sophisticated approximation problems. This advanced practice explores the power and limitations of using a Legendre polynomial basis to approximate a function with a sharp discontinuity [@problem_id:3260453]. By implementing a numerical solution, you will gain firsthand insight into the behavior of orthogonal series near discontinuities, a classic phenomenon with important implications in signal processing and numerical analysis.", "problem": "Consider the square-integrable function space $L^2([-1,1])$ with the standard inner product $\\langle g,h\\rangle = \\int_{-1}^{1} g(x)\\,h(x)\\,\\mathrm{d}x$. Let $P_n(x)$ denote the $n$th Legendre polynomial, which forms an orthogonal basis of $L^2([-1,1])$ when restricted to polynomials and weighted by $1$ on $[-1,1]$. Define the function $f(x) = \\operatorname{sgn}(x)$ with the convention $f(0)=0$.\n\nYour task is to construct the least-squares (orthogonal) projection of $f$ onto the span of $\\{P_0,P_1,\\dots,P_N\\}$, that is, find coefficients $a_0,a_1,\\dots,a_N$ such that the polynomial\n$$\nS_N(x) = \\sum_{n=0}^{N} a_n\\,P_n(x)\n$$\nminimizes the $L^2([-1,1])$ error $\\int_{-1}^{1} \\left(S_N(x)-f(x)\\right)^2 \\,\\mathrm{d}x$ and is characterized by the orthogonality of the residual to the basis, namely $\\langle f-S_N,P_k\\rangle = 0$ for each integer $k$ with $0\\le k\\le N$.\n\nStarting from the fundamental definitions above and the orthogonality of the Legendre polynomials, derive a computationally stable method to obtain the coefficients $a_n$ as functions of $N$. Then, for each test case described below, evaluate the following four quantities:\n- $S_N(0)$,\n- $S_N(\\varepsilon) - 1$,\n- $S_N(-\\varepsilon) + 1$,\n- the squared $L^2([-1,1])$ error $\\int_{-1}^{1} \\left(S_N(x)-f(x)\\right)^2 \\,\\mathrm{d}x$.\n\nThese quantities collectively expose how the orthogonal projection captures the jump discontinuity at $x=0$ and the oscillatory behavior near $x=0$ (including overshoot and undershoot).\n\nYour program must implement the computation of $S_N(x)$ using the Legendre basis implied by the least-squares projection and must evaluate Legendre polynomials in a numerically stable way on $[-1,1]$.\n\nUse the following test suite, where each test case is a pair $(N,\\varepsilon)$ with $N$ a nonnegative integer and $\\varepsilon>0$ a small number:\n- Test case $1$: $N=1$, $\\varepsilon=10^{-2}$,\n- Test case $2$: $N=7$, $\\varepsilon=10^{-3}$,\n- Test case $3$: $N=31$, $\\varepsilon=10^{-4}$,\n- Test case $4$: $N=2$, $\\varepsilon=10^{-3}$.\n\nFor each test case, produce a list of four floating-point numbers in the order specified above. Aggregate the four test-case results into a single list in the same order as given, so the final output is a list of lists.\n\nFinal output format: Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, with each test case represented by its own four-element list, for example:\n$$\n\\text{[[r_{1,1},r_{1,2},r_{1,3},r_{1,4}],[r_{2,1},r_{2,2},r_{2,3},r_{2,4}],[r_{3,1},r_{3,2},r_{3,3},r_{3,4}],[r_{4,1},r_{4,2},r_{4,3},r_{4,4}]]}\n$$\nAll numbers and symbols in this problem refer to purely mathematical quantities; no physical units are involved. Angles, if any, must be in radians, but none are required here.", "solution": "The problem requires the construction and analysis of the least-squares polynomial approximation of the signum function, $f(x) = \\operatorname{sgn}(x)$, in the space $L^2([-1,1])$. The approximation, denoted $S_N(x)$, is the orthogonal projection of $f(x)$ onto the subspace spanned by the first $N+1$ Legendre polynomials, $\\{P_0, P_1, \\dots, P_N\\}$.\n\nThe projection $S_N(x)$ is a polynomial of degree at most $N$ given by the expansion\n$$\nS_N(x) = \\sum_{n=0}^{N} a_n\\,P_n(x)\n$$\nThe coefficients $a_n$ are chosen to minimize the mean squared error, $\\int_{-1}^{1} (f(x) - S_N(x))^2 \\,\\mathrm{d}x$. A fundamental result of approximation theory in Hilbert spaces states that this minimum is achieved when the error vector $f-S_N$ is orthogonal to the subspace of approximation. This gives the orthogonality conditions:\n$$\n\\langle f - S_N, P_k \\rangle = 0 \\quad \\text{for } k = 0, 1, \\dots, N\n$$\nwhere the inner product is $\\langle g, h \\rangle = \\int_{-1}^{1} g(x)h(x)\\,\\mathrm{d}x$. By the linearity of the inner product and the orthogonality of Legendre polynomials, $\\langle P_n, P_k \\rangle = 0$ for $n \\neq k$, we can solve for each coefficient $a_k$ independently:\n$$\n\\langle f, P_k \\rangle - \\langle \\sum_{n=0}^{N} a_n P_n, P_k \\rangle = 0 \\implies \\langle f, P_k \\rangle - a_k \\langle P_k, P_k \\rangle = 0\n$$\nThis yields the standard formula for the Fourier-Legendre coefficients:\n$$\na_k = \\frac{\\langle f, P_k \\rangle}{\\langle P_k, P_k \\rangle}\n$$\nThe denominator is the squared norm of the $k$-th Legendre polynomial, a standard result:\n$$\n\\langle P_k, P_k \\rangle = \\int_{-1}^{1} P_k(x)^2 \\,\\mathrm{d}x = \\frac{2}{2k+1}\n$$\nThe numerator requires an integral involving our specific function $f(x) = \\operatorname{sgn}(x)$.\n$$\n\\langle f, P_k \\rangle = \\int_{-1}^{1} \\operatorname{sgn}(x) P_k(x) \\,\\mathrm{d}x = \\int_{-1}^{0} (-1)P_k(x)\\,\\mathrm{d}x + \\int_{0}^{1} (1)P_k(x)\\,\\mathrm{d}x\n$$\nLegendre polynomials have a definite parity, $P_k(-x) = (-1)^k P_k(x)$. The function $f(x) = \\operatorname{sgn}(x)$ is an odd function. The product $\\operatorname{sgn}(x)P_k(x)$ is an odd function if $P_k(x)$ is even (i.e., $k$ is even), and an even function if $P_k(x)$ is odd (i.e., $k$ is odd).\nIf $k$ is even, the integrand is odd, and its integral over the symmetric interval $[-1, 1]$ is zero. Thus, $\\langle f, P_k \\rangle = 0$ for all even $k$. Consequently, all even-indexed coefficients $a_{2m}$ are zero. This reflects the fact that the best polynomial approximation of an odd function by Legendre basis functions will itself be an odd function, composed only of odd-indexed (and thus odd) Legendre polynomials.\nIf $k$ is odd, the integrand is even, so the integral from $-1$ to $1$ is twice the integral from $0$ to $1$.\n$$\n\\langle f, P_k \\rangle = 2 \\int_{0}^{1} P_k(x)\\,\\mathrm{d}x \\quad \\text{for odd } k\n$$\nThe coefficient $a_k$ for odd $k$ is therefore:\n$$\na_k = \\frac{2 \\int_{0}^{1} P_k(x)\\,\\mathrm{d}x}{2/(2k+1)} = (2k+1) \\int_{0}^{1} P_k(x)\\,\\mathrm{d}x\n$$\nTo evaluate the integral in a stable manner, we use the identity for derivatives of Legendre polynomials:\n$$\n(2k+1)P_k(x) = P'_{k+1}(x) - P'_{k-1}(x) \\quad \\text{for } k \\ge 1\n$$\nIntegrating both sides from $0$ to $1$:\n$$\n(2k+1)\\int_{0}^{1} P_k(x)\\,\\mathrm{d}x = \\int_{0}^{1} \\left(P'_{k+1}(x) - P'_{k-1}(x)\\right)\\,\\mathrm{d}x = [P_{k+1}(x) - P_{k-1}(x)]_{0}^{1}\n$$\n$$\n= (P_{k+1}(1) - P_{k-1}(1)) - (P_{k+1}(0) - P_{k-1}(0))\n$$\nUsing the property $P_n(1)=1$ for all $n$, the first term vanishes: $P_{k+1}(1) - P_{k-1}(1) = 1-1=0$. This gives us a simple expression for the integral in terms of polynomial values at $x=0$:\n$$\n(2k+1)\\int_{0}^{1} P_k(x)\\,\\mathrm{d}x = -(P_{k+1}(0) - P_{k-1}(0))\n$$\nSubstituting this back into our formula for $a_k$ (for odd $k \\ge 1$) yields a remarkably simple result:\n$$\na_k = P_{k-1}(0) - P_{k+1}(0)\n$$\nTo compute this, we need the values of Legendre polynomials at $x=0$. Since $k$ is odd, $k-1$ and $k+1$ are even. The values $P_n(0)$ for odd $n$ are zero. For even $n$, they can be computed efficiently using the three-term recurrence relation for Legendre polynomials evaluated at $x=0$:\n$$\n(n+1)P_{n+1}(0) = -nP_{n-1}(0) \\quad \\text{with } P_0(0)=1\n$$\nThis recurrence is numerically stable. Let $k = 2m+1$ be an odd index. Then $a_{2m+1} = P_{2m}(0) - P_{2m+2}(0)$. We pre-compute $P_{2j}(0)$ for $j=0, 1, \\dots, \\lfloor(N+1)/2\\rfloor$ and then find the coefficients $a_n$.\n\nWith the coefficients determined, we evaluate the four required quantities for each test case $(N, \\varepsilon)$:\n\n1.  $S_N(0) = \\sum_{n=0}^{N} a_n P_n(0)$. Since $a_n=0$ for even $n$ and $P_n(0)=0$ for odd $n$, every term in the sum is zero. Thus, $S_N(0)=0$.\n\n2.  $S_N(\\varepsilon) - 1$. We compute $S_N(\\varepsilon) = \\sum_{n=0}^N a_n P_n(\\varepsilon)$ and subtract $1$. The evaluation of the sum is performed by generating the values $P_n(\\varepsilon)$ using the standard three-term recurrence relation $(n+1)P_{n+1}(x) = (2n+1)xP_n(x) - nP_{n-1}(x)$ with $P_0(x)=1, P_1(x)=x$. This forward evaluation is numerically stable for $x \\in [-1,1]$.\n\n3.  $S_N(-\\varepsilon) + 1$. Since $S_N(x)$ is a sum of odd polynomials, it is an odd function, satisfying $S_N(-x) = -S_N(x)$. Therefore, $S_N(-\\varepsilon) + 1 = -S_N(\\varepsilon) + 1 = -(S_N(\\varepsilon) - 1)$. This value is simply the negative of the previous one.\n\n4.  The squared $L^2([-1,1])$ error, $E^2 = \\int_{-1}^{1} (f(x) - S_N(x))^2 \\,\\mathrm{d}x$. By the Pythagorean theorem in Hilbert spaces (or Parseval's identity), this error can be computed without numerical integration:\n    $$\n    E^2 = \\langle f, f \\rangle - \\langle S_N, S_N \\rangle\n    $$\n    We have $\\langle f,f \\rangle = \\int_{-1}^{1} (\\operatorname{sgn}(x))^2 \\,\\mathrm{d}x = \\int_{-1}^{1} 1\\,\\mathrm{d}x = 2$. By orthogonality of the Legendre basis, $\\langle S_N, S_N \\rangle = \\sum_{n=0}^{N} a_n^2 \\langle P_n, P_n \\rangle$.\n    The final expression for the error is:\n    $$\n    E^2 = 2 - \\sum_{n=0}^{N} a_n^2 \\frac{2}{2n+1}\n    $$\n    This formula uses the pre-computed coefficients $a_n$ and is computationally efficient and stable.\n\nThe implementation will follow these derived formulas.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the problem of finding the least-squares polynomial approximation\n    of the signum function and evaluating several related quantities.\n    \"\"\"\n\n    def compute_coeffs(N):\n        \"\"\"\n        Computes the coefficients a_n for the Legendre series expansion of sgn(x).\n        a_n is non-zero only for odd n.\n        a_{2m+1} = P_{2m}(0) - P_{2m+2}(0).\n        \"\"\"\n        # Max index for m such that n=2m+1 <= N is m <= (N-1)/2.\n        # To compute a_n, we need P_{n+1}(0), so max index for P_2m(0) is m = (N+1)//2.\n        max_m = (N + 1) // 2\n        \n        # p_even_at_0[m] will store P_{2m}(0)\n        p_even_at_0 = np.zeros(max_m + 1)\n        if max_m >= 0:\n            p_even_at_0[0] = 1.0  # P_0(0)\n        \n        # Use recurrence (2m)P_{2m}(0) = -(2m-1)P_{2m-2}(0)\n        for m in range(1, max_m + 1):\n            p_even_at_0[m] = - (2 * m - 1) / (2 * m) * p_even_at_0[m - 1]\n\n        coeffs = np.zeros(N + 1)\n        \n        # Compute a_n for odd n = 2m+1\n        for m in range((N - 1) // 2 + 1):\n            n = 2 * m + 1\n            coeffs[n] = p_even_at_0[m] - p_even_at_0[m + 1]\n            \n        return coeffs\n\n    def evaluate_SN(coeffs, N, x):\n        \"\"\"\n        Evaluates the polynomial S_N(x) = sum_{n=0 to N} a_n P_n(x)\n        using the three-term recurrence for P_n(x).\n        \"\"\"\n        if N < 0:\n            return 0.0\n        \n        if N == 0:\n            return coeffs[0] # which is 0 for this problem\n\n        # Use forward recurrence to compute P_n(x) and sum S_N(x)\n        p_prev = 1.0  # P_0(x)\n        p_curr = x    # P_1(x)\n        \n        sum_val = coeffs[0] * p_prev\n        if N >= 1:\n            sum_val += coeffs[1] * p_curr\n            \n        for n in range(1, N):\n            p_next = ((2 * n + 1) * x * p_curr - n * p_prev) / (n + 1)\n            sum_val += coeffs[n + 1] * p_next\n            p_prev = p_curr\n            p_curr = p_next\n            \n        return sum_val\n\n    def compute_error_sq(coeffs, N):\n        \"\"\"\n        Computes the squared L2 error using Parseval's identity.\n        E^2 = ||f||^2 - ||S_N||^2 = 2 - sum(a_n^2 * ||P_n||^2).\n        \"\"\"\n        sum_sq = 0.0\n        for n in range(N + 1):\n            if coeffs[n] != 0:\n                norm_sq_Pn = 2.0 / (2 * n + 1)\n                sum_sq += coeffs[n]**2 * norm_sq_Pn\n        # ||f||^2 for f=sgn(x) on [-1,1] is integral of 1, which is 2.\n        return 2.0 - sum_sq\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        (1, 1e-2),\n        (7, 1e-3),\n        (31, 1e-4),\n        (2, 1e-3)\n    ]\n\n    results_list = []\n    for N, eps in test_cases:\n        coeffs = compute_coeffs(N)\n        \n        # 1. S_N(0)\n        # S_N is a sum of odd Legendre polynomials, so S_N(0)=0.\n        val_at_0 = 0.0\n        \n        # 2. S_N(eps) - 1\n        val_at_eps = evaluate_SN(coeffs, N, eps)\n        overshoot = val_at_eps - 1.0\n        \n        # 3. S_N(-eps) + 1\n        # S_N is an odd function, so S_N(-eps) = -S_N(eps)\n        # S_N(-eps) + 1 = -S_N(eps) + 1 = -(S_N(eps) - 1)\n        undershoot = -overshoot\n        \n        # 4. Squared L2 error\n        error_sq = compute_error_sq(coeffs, N)\n        \n        case_result = [val_at_0, overshoot, undershoot, error_sq]\n        results_list.append(f\"[{','.join(map(str, case_result))}]\")\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(results_list)}]\")\n\nsolve()\n```", "id": "3260453"}]}