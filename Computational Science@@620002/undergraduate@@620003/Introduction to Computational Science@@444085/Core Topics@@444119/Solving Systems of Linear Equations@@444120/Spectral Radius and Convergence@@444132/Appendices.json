{"hands_on_practices": [{"introduction": "In numerical analysis, simple rules are often used to quickly assess whether an iterative method will converge. This exercise challenges you to critically examine one such rule—Strict Diagonal Dominance (SDD)—in the context of the Jacobi method. By working through a concrete counterexample [@problem_id:3219053], you will demonstrate that while SDD is a *sufficient* condition for convergence, it is not *necessary*, reinforcing that the spectral radius remains the ultimate arbiter.", "problem": "Consider the question of whether Strict Diagonal Dominance (SDD) by rows is necessary for the convergence of the Jacobi iterative method. Starting only from the core definitions of the Jacobi method and spectral radius, analyze the following concrete matrix as a potential counterexample:\n$$\nA \\;=\\; \\begin{pmatrix}\n1  -2  0 \\\\\n0  1  -2 \\\\\n0  0  1\n\\end{pmatrix}.\n$$\nTasks:\n- First, verify that $A$ is not strictly diagonally dominant by rows (SDD).\n- Using only the fundamental definition of the Jacobi iteration based on the diagonal and off-diagonal splitting of $A$, derive the Jacobi iteration matrix and determine its spectral radius. Explain how this implies convergence or divergence of the Jacobi method for this $A$.\n- Conclude whether SDD is a necessary condition for Jacobi convergence and justify your conclusion by reference to this matrix.\n\nReport as your final answer the exact value of the spectral radius of the Jacobi iteration matrix for $A$. No rounding is required. The final answer must be a single real number.", "solution": "The problem requires an analysis of the necessity of Strict Diagonal Dominance (SDD) for the convergence of the Jacobi iterative method, using a specific matrix as a potential counterexample. The analysis will proceed in three steps as requested: verification of the matrix's non-SDD property, derivation of the Jacobi iteration matrix and its spectral radius to assess convergence, and a final conclusion on the necessity of the SDD condition.\n\nFirst, we validate that the given matrix $A$ is not strictly diagonally dominant by rows. The matrix is:\n$$\nA = \\begin{pmatrix}\n1  -2  0 \\\\\n0  1  -2 \\\\\n0  0  1\n\\end{pmatrix}\n$$\nA matrix $M$ with entries $m_{ij}$ is strictly diagonally dominant by rows if the absolute value of each diagonal element is greater than the sum of the absolute values of the off-diagonal elements in its row. That is, for all rows $i$, the condition $|m_{ii}| > \\sum_{j \\neq i} |m_{ij}|$ must hold. Let's examine this condition for matrix $A$.\n\nFor row $i=1$: The diagonal element is $a_{11} = 1$. The sum of the absolute values of the off-diagonal elements is $|a_{12}| + |a_{13}| = |-2| + |0| = 2$. The condition is $|1| > 2$, which simplifies to $1 > 2$. This is false.\n\nFor row $i=2$: The diagonal element is $a_{22} = 1$. The sum of the absolute values of the off-diagonal elements is $|a_{21}| + |a_{23}| = |0| + |-2| = 2$. The condition is $|1| > 2$, which is $1 > 2$. This is also false.\n\nFor row $i=3$: The diagonal element is $a_{33} = 1$. The sum of the absolute values of the off-diagonal elements is $|a_{31}| + |a_{32}| = |0| + |0| = 0$. The condition is $|1| > 0$, which is $1 > 0$. This is true.\n\nSince the condition for strict diagonal dominance fails for rows $1$ and $2$, the matrix $A$ is not strictly diagonally dominant by rows.\n\nSecond, we derive the Jacobi iteration matrix $T_J$ and its spectral radius $\\rho(T_J)$. The Jacobi method for solving a linear system $Ax=b$ is based on the splitting of the matrix $A$ into its diagonal ($D$), strictly lower triangular ($L$), and strictly upper triangular ($U$) components, such that $A = D + L + U$. The iterative scheme is given by $Dx^{(k+1)} = -(L+U)x^{(k)} + b$. This can be rewritten as $x^{(k+1)} = -D^{-1}(L+U)x^{(k)} + D^{-1}b$. The Jacobi iteration matrix is thus defined as $T_J = -D^{-1}(L+U)$.\n\nFor our matrix $A$:\nThe diagonal component is $D = \\begin{pmatrix} 1  0  0 \\\\ 0  1  0 \\\\ 0  0  1 \\end{pmatrix} = I$, the identity matrix.\nThe strictly lower triangular component is $L = \\begin{pmatrix} 0  0  0 \\\\ 0  0  0 \\\\ 0  0  0 \\end{pmatrix}$, the zero matrix.\nThe strictly upper triangular component is $U = \\begin{pmatrix} 0  -2  0 \\\\ 0  0  -2 \\\\ 0  0  0 \\end{pmatrix}$.\n\nThe inverse of the diagonal matrix $D$ is $D^{-1} = I^{-1} = I$.\nNow we can construct the Jacobi iteration matrix $T_J$:\n$$\nT_J = -D^{-1}(L+U) = -I\\left(\\begin{pmatrix} 0  0  0 \\\\ 0  0  0 \\\\ 0  0  0 \\end{pmatrix} + \\begin{pmatrix} 0  -2  0 \\\\ 0  0  -2 \\\\ 0  0  0 \\end{pmatrix}\\right) = -\\begin{pmatrix} 0  -2  0 \\\\ 0  0  -2 \\\\ 0  0  0 \\end{pmatrix} = \\begin{pmatrix} 0  2  0 \\\\ 0  0  2 \\\\ 0  0  0 \\end{pmatrix}\n$$\nThe convergence of the Jacobi method is determined by the spectral radius of $T_J$, denoted $\\rho(T_J)$, which is the maximum absolute value of its eigenvalues. The eigenvalues $\\lambda$ are the roots of the characteristic equation $\\det(T_J - \\lambda I) = 0$.\n$$\nT_J - \\lambda I = \\begin{pmatrix} 0-\\lambda  2  0 \\\\ 0  0-\\lambda  2 \\\\ 0  0  0-\\lambda \\end{pmatrix} = \\begin{pmatrix} -\\lambda  2  0 \\\\ 0  -\\lambda  2 \\\\ 0  0  -\\lambda \\end{pmatrix}\n$$\nThe determinant of this upper triangular matrix is the product of its diagonal entries:\n$$\n\\det(T_J - \\lambda I) = (-\\lambda)(-\\lambda)(-\\lambda) = -\\lambda^3\n$$\nSetting the characteristic polynomial to zero, we get $-\\lambda^3 = 0$, which yields a single eigenvalue $\\lambda = 0$ with an algebraic multiplicity of $3$. The set of eigenvalues is $\\{\\lambda_1, \\lambda_2, \\lambda_3\\} = \\{0, 0, 0\\}$.\n\nThe spectral radius is the maximum of the absolute values of the eigenvalues:\n$$\n\\rho(T_J) = \\max\\{|0|, |0|, |0|\\} = 0\n$$\nA necessary and sufficient condition for the convergence of an iterative method for any initial guess is that the spectral radius of its iteration matrix must be strictly less than $1$. Here, we have $\\rho(T_J) = 0$, and since $0  1$, the Jacobi method for a system with coefficient matrix $A$ is guaranteed to converge.\n\nFinally, we conclude whether SDD is a necessary condition for Jacobi convergence. A condition is necessary if its absence implies the absence of the outcome. In this context, if SDD were necessary for Jacobi convergence, then any matrix for which Jacobi converges must be SDD. Our analysis provides a direct counterexample to this statement. We have demonstrated that:\n1. The matrix $A$ is not strictly diagonally dominant.\n2. The Jacobi method for matrix $A$ converges, as its spectral radius is $0$.\n\nBecause the Jacobi method converges for a matrix that is not strictly diagonally dominant, we conclude that strict diagonal dominance is not a necessary condition for the convergence of the Jacobi method. It is, however, a well-known sufficient condition.", "answer": "$$\\boxed{0}$$", "id": "3219053"}, {"introduction": "While the spectral radius criterion is exact, computing eigenvalues can be difficult for large or complex matrices. This practice introduces a powerful analytical tool, the Gershgorin Circle Theorem, which allows us to estimate the location of eigenvalues without calculating them directly. By using Gershgorin discs to bound the spectral radius of an iteration matrix [@problem_id:3196449], you will gain hands-on experience in deriving sufficient conditions for convergence and visualizing how matrix entries constrain its spectrum.", "problem": "Consider the linear fixed-point iteration $x^{k+1} = T x^{k} + c$ for a square matrix $T \\in \\mathbb{R}^{3 \\times 3}$ and a constant vector $c \\in \\mathbb{R}^{3}$. The spectral radius $\\rho(T)$ is defined as the maximum of the absolute values of the eigenvalues of $T$. The Gershgorin Circle Theorem states that every eigenvalue of a matrix lies within at least one of its Gershgorin discs, which are constructed from the matrix rows. Assume $T(\\alpha)$ is the tridiagonal matrix\n$$\nT(\\alpha) = \\begin{pmatrix}\n\\frac{3}{5}  \\alpha  0 \\\\\n\\alpha  \\frac{3}{5}  \\alpha \\\\\n0  \\alpha  \\frac{3}{5}\n\\end{pmatrix},\n$$\nwhere $\\alpha \\geq 0$ is a parameter.\n\nUsing only foundational definitions and the Gershgorin Circle Theorem, derive a bound on the eigenvalue locations of $T(\\alpha)$ in the complex plane, obtain from this bound a sufficient condition for convergence of the iteration $x^{k+1} = T x^{k} + c$ for all initial vectors, and identify the borderline value of $\\alpha$ at which the Gershgorin discs are tangent to the unit circle $|z|=1$. Provide reasoning that connects the spectral radius bound to convergence and explain the status of convergence at the borderline value of $\\alpha$ based on Gershgorin discs.\n\nReport the critical value of $\\alpha$ at which the Gershgorin discs just touch the unit circle as your final answer. No rounding is required.", "solution": "The convergence of the linear fixed-point iteration $x^{k+1} = T x^{k} + c$ for any initial vector $x^0$ is guaranteed if and only if the spectral radius of the iteration matrix $T$ is strictly less than one, i.e., $\\rho(T)  1$. We will use the Gershgorin Circle Theorem to find an upper bound for the spectral radius of the matrix $T(\\alpha)$ and thereby establish a sufficient condition for convergence.\n\nThe Gershgorin Circle Theorem states that every eigenvalue of a square matrix $A = (a_{ij})$ lies within at least one of the Gershgorin discs $D_i$ in the complex plane, where for each row $i$, the disc $D_i$ is centered at the diagonal element $a_{ii}$ and has a radius $R_i$ equal to the sum of the absolute values of the off-diagonal elements in that row:\n$$ D_i = \\{z \\in \\mathbb{C} : |z - a_{ii}| \\leq R_i\\}, \\quad \\text{where} \\quad R_i = \\sum_{j \\neq i} |a_{ij}| $$\nThe set of all eigenvalues, the spectrum $\\sigma(A)$, is contained in the union of these discs: $\\sigma(A) \\subseteq \\bigcup_i D_i$.\n\nFor the given matrix $T(\\alpha)$:\n$$\nT(\\alpha) = \\begin{pmatrix}\n\\frac{3}{5}  \\alpha  0 \\\\\n\\alpha  \\frac{3}{5}  \\alpha \\\\\n0  \\alpha  \\frac{3}{5}\n\\end{pmatrix}\n$$\nwith $\\alpha \\geq 0$, we define the Gershgorin discs:\n\n1.  For the first row ($i=1$): The center is $a_{11} = \\frac{3}{5}$. The radius is $R_1 = |a_{12}| + |a_{13}| = |\\alpha| + |0| = \\alpha$, since $\\alpha \\geq 0$. The disc is $D_1 = \\{z \\in \\mathbb{C} : |z - \\frac{3}{5}| \\leq \\alpha\\}$.\n\n2.  For the second row ($i=2$): The center is $a_{22} = \\frac{3}{5}$. The radius is $R_2 = |a_{21}| + |a_{23}| = |\\alpha| + |\\alpha| = 2\\alpha$. The disc is $D_2 = \\{z \\in \\mathbb{C} : |z - \\frac{3}{5}| \\leq 2\\alpha\\}$.\n\n3.  For the third row ($i=3$): The center is $a_{33} = \\frac{3}{5}$. The radius is $R_3 = |a_{31}| + |a_{32}| = |0| + |\\alpha| = \\alpha$. The disc is $D_3 = \\{z \\in \\mathbb{C} : |z - \\frac{3}{5}| \\leq \\alpha\\}$.\n\nThe discs $D_1$ and $D_3$ are identical. Since $\\alpha \\geq 0$, we have $2\\alpha \\geq \\alpha$, which implies that the radius of $D_2$ is greater than or equal to the radius of $D_1$ and $D_3$. As all three discs share the same center, $D_1 \\subseteq D_2$ and $D_3 \\subseteq D_2$. Therefore, the union of the three discs is simply the largest disc, $D_2$:\n$$ \\bigcup_{i=1}^3 D_i = D_2 = \\{z \\in \\mathbb{C} : |z - \\frac{3}{5}| \\leq 2\\alpha \\} $$\nThis implies that all eigenvalues $\\lambda$ of $T(\\alpha)$ must lie within this disc. This provides the requested bound on the eigenvalue locations.\n\nThe spectral radius $\\rho(T(\\alpha))$ is the maximum modulus of its eigenvalues. Since all eigenvalues lie in $D_2$, the spectral radius is bounded by the maximum possible modulus of any point $z$ in $D_2$:\n$$ \\rho(T(\\alpha)) = \\max_{\\lambda \\in \\sigma(T(\\alpha))} |\\lambda| \\leq \\max_{z \\in D_2} |z| $$\nThe disc $D_2$ is centered at the real number $\\frac{3}{5}$ with radius $2\\alpha$. The point in this disc with the maximum modulus lies on its boundary along the positive real axis. This point is $z_{max} = \\frac{3}{5} + 2\\alpha$. Thus, we have an upper bound for the spectral radius:\n$$ \\rho(T(\\alpha)) \\leq \\frac{3}{5} + 2\\alpha $$\nA sufficient condition for the convergence of the iteration is $\\rho(T(\\alpha))  1$. Using our bound, a sufficient condition is:\n$$ \\frac{3}{5} + 2\\alpha  1 $$\n$$ 2\\alpha  1 - \\frac{3}{5} $$\n$$ 2\\alpha  \\frac{2}{5} $$\n$$ \\alpha  \\frac{1}{5} $$\nCombined with the given constraint $\\alpha \\geq 0$, a sufficient condition for convergence is $0 \\leq \\alpha  \\frac{1}{5}$.\n\nThe borderline value of $\\alpha$ is where the Gershgorin discs are tangent to the unit circle $|z|=1$. Since the union of the discs is $D_2$, this corresponds to the point in $D_2$ farthest from the origin having a modulus of $1$. This occurs when the upper bound for the spectral radius equals $1$:\n$$ \\frac{3}{5} + 2\\alpha = 1 $$\nSolving for $\\alpha$ gives the critical value:\n$$ 2\\alpha = \\frac{2}{5} \\implies \\alpha = \\frac{1}{5} $$\nAt this borderline value, $\\alpha = \\frac{1}{5}$, the bound on the spectral radius derived from the Gershgorin theorem is $\\rho(T(\\frac{1}{5})) \\leq 1$. The theorem only provides an inclusion region for the eigenvalues. It does not guarantee that an eigenvalue actually lies on the boundary of this region. The strict condition for convergence is $\\rho(T)  1$. The condition $\\rho(T) \\leq 1$ is not sufficient to guarantee convergence. An eigenvalue with modulus $1$ might exist, which could lead to divergence or non-convergent oscillation. Therefore, based on the information provided by the Gershgorin discs alone, convergence at the borderline value $\\alpha = \\frac{1}{5}$ is not guaranteed; the status is inconclusive.\n\nThe question asks for the critical value of $\\alpha$ at which the Gershgorin discs touch the unit circle. This is the value we have calculated.", "answer": "$$\n\\boxed{\\frac{1}{5}}\n$$", "id": "3196449"}, {"introduction": "The ultimate test of a numerical method lies in its implementation. This hands-on coding exercise [@problem_id:3196496] bridges theory and practice by having you computationally explore the link between a matrix's structure and the convergence of the Jacobi iteration. By systematically constructing a family of matrices and calculating the spectral radius, you will gain a practical intuition for how properties like bandwidth and diagonal values directly influence convergence behavior.", "problem": "You are asked to implement and analyze the Jacobi iteration for a family of banded matrices and to connect the sparsity pattern (specifically, the bandwidth) to convergence via the spectral radius. Work in purely mathematical terms, and base your reasoning on core definitions and well-tested facts. The Jacobi method for solving the linear system $A x = b$ uses the matrix splitting $A = D + L + U$, where $D$ is the diagonal of $A$, $L$ is the strictly lower-triangular part, and $U$ is the strictly upper-triangular part. The Jacobi iteration can be written as $x^{(k+1)} = T x^{(k)} + D^{-1} b$, where the iteration matrix $T$ is $T = -D^{-1} (L+U)$. The spectral radius $\\rho(T)$ is defined as the maximum modulus of the eigenvalues of $T$, and for stationary iterations the convergence for any initial vector is guaranteed if and only if $\\rho(T)  1$.\n\nConstruct the following symmetric, banded test matrices $A \\in \\mathbb{R}^{n \\times n}$ parameterized by the dimension $n$, a half-bandwidth $w$, and a scalar shift $s$. For indices $i,j \\in \\{1,2,\\dots,n\\}$ define\n$$\nA_{i j} =\n\\begin{cases}\nc_0,  \\text{if } i=j,\\\\\n-1,  \\text{if } 1 \\le |i-j| \\le w,\\\\\n0,  \\text{otherwise},\n\\end{cases}\n\\quad\\text{with}\\quad c_0 = 2w + s \\neq 0.\n$$\nFor each test matrix, construct the Jacobi iteration matrix\n$$\nT = -D^{-1}(L+U),\n$$\nwhere $D = \\mathrm{diag}(A)$, $L$ is the strictly lower-triangular part of $A$, and $U$ is the strictly upper-triangular part of $A$. Compute the spectral radius $\\rho(T)$ and use it to decide convergence for arbitrary initial vectors under the Jacobi iteration. No physical units are involved. All angles, if any, are irrelevant here.\n\nYour program must compute, for each test case, the following results:\n- The spectral radius $\\rho(T)$ as a floating-point number rounded to six decimal places.\n- A boolean indicating convergence, defined as $true$ if $\\rho(T)  1$ and $false$ otherwise.\n\nUse the following test suite, where each tuple is $(n,w,s)$:\n- Test $1$: $(12, 1, 1)$.\n- Test $2$: $(20, 2, 1)$.\n- Test $3$: $(50, 5, 1)$.\n- Test $4$: $(30, 0, 2)$.\n- Test $5$: $(20, 4, -7)$.\n- Test $6$: $(18, 3, 0)$.\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets. Each test case's result must be a two-element list of the form $[\\rho(T), \\text{boolean}]$, for example,\n$$\n[[0.500000,\\text{True}],[0.750000,\\text{False}],\\dots].\n$$", "solution": "The problem requires the analysis of the Jacobi iteration for a specified family of matrices. The convergence of this iterative method is determined by the spectral radius of the Jacobi iteration matrix.\n\nFirst, we formalize the construction of the Jacobi iteration matrix $T$. The linear system is $A x = b$. The Jacobi method is based on the splitting of the matrix $A$ into its diagonal ($D$), strictly lower-triangular ($L$), and strictly upper-triangular ($U$) parts, such that $A = D + L + U$. The iteration is given by $x^{(k+1)} = T x^{(k)} + c$, where the iteration matrix is $T = -D^{-1}(L+U)$ and $c=D^{-1}b$.\n\nThe problem defines the matrix $A \\in \\mathbb{R}^{n \\times n}$ with parameters $n$ (dimension), $w$ (half-bandwidth), and $s$ (scalar shift). Its elements $A_{ij}$ are given by:\n$$\nA_{i j} =\n\\begin{cases}\nc_0,  \\text{if } i=j,\\\\\n-1,  \\text{if } 1 \\le |i-j| \\le w,\\\\\n0,  \\text{otherwise},\n\\end{cases}\n$$\nwith the diagonal element $c_0 = 2w + s$. The problem states that $c_0 \\neq 0$, which ensures the diagonal matrix $D$ is invertible.\n\nFrom this definition of $A$, its components are:\n- $D$ is a diagonal matrix with all diagonal entries equal to $c_0$. Thus, $D = c_0 I$, where $I$ is the identity matrix.\n- $D^{-1}$ is also a diagonal matrix with all diagonal entries equal to $1/c_0$. Thus, $D^{-1} = (1/c_0) I$.\n- The sum of the strictly lower and upper triangular parts, $L+U$, is simply $A - D$. This matrix has zeros on its main diagonal and the same off-diagonal elements as $A$.\n\nNow, we can express the iteration matrix $T$ as:\n$$\nT = -D^{-1}(L+U) = - (1/c_0) I (A - c_0 I) = - (1/c_0) (A - c_0 I) = -A/c_0 + I\n$$\nLet's examine the elements $T_{ij}$ of the matrix $T$:\n- For the diagonal elements ($i=j$): $T_{ii} = -A_{ii}/c_0 + 1 = -c_0/c_0 + 1 = -1 + 1 = 0$.\n- For the off-diagonal elements ($i \\neq j$): $T_{ij} = -A_{ij}/c_0 + 0 = -A_{ij}/c_0$.\n\nSubstituting the definition of $A_{ij}$ for $i \\neq j$:\n$$\nT_{i j} =\n\\begin{cases}\n0,  \\text{if } i=j,\\\\\n-(-1)/c_0,  \\text{if } 1 \\le |i-j| \\le w,\\\\\n-0/c_0,  \\text{otherwise}.\n\\end{cases}\n=\n\\begin{cases}\n0,  \\text{if } i=j,\\\\\n1/c_0,  \\text{if } 1 \\le |i-j| \\le w,\\\\\n0,  \\text{otherwise}.\n\\end{cases}\n$$\nSo, for each test case $(n, w, s)$, we first calculate $c_0 = 2w + s$ and then construct the $n \\times n$ matrix $T$ with zeros on the diagonal and the value $1/c_0$ on the $w$ super-diagonals and $w$ sub-diagonals.\n\nThe convergence of the Jacobi method for any initial vector is guaranteed if and only if the spectral radius of the iteration matrix, $\\rho(T)$, is strictly less than $1$. The spectral radius is defined as the maximum absolute value of the eigenvalues of $T$, i.e., $\\rho(T) = \\max_k |\\lambda_k|$, where $\\lambda_k$ are the eigenvalues of $T$.\n\nThe algorithmic procedure to solve the problem for each test case is as follows:\n1.  Given the parameters $n$, $w$, and $s$, calculate $c_0 = 2w + s$.\n2.  Construct the $n \\times n$ matrix $T$ according to the derived structure. This matrix is real and symmetric.\n3.  Numerically compute the eigenvalues of $T$. Given that $T$ is symmetric, a specialized algorithm like that provided by `numpy.linalg.eigvalsh` can be used for efficiency and numerical stability.\n4.  Calculate the spectral radius $\\rho(T)$ by finding the maximum of the absolute values of the computed eigenvalues.\n5.  Determine convergence by checking if $\\rho(T)  1$. The result is a boolean value (`True` for convergence, `False` otherwise).\n6.  Format the computed spectral radius as a floating-point number rounded to six decimal places and pair it with the convergence boolean. This process is repeated for all provided test cases.", "answer": "[[0.647287,True],[0.781307,True],[0.903845,True],[0.000000,True],[3.863703,False],[0.984091,True]]", "id": "3196496"}]}