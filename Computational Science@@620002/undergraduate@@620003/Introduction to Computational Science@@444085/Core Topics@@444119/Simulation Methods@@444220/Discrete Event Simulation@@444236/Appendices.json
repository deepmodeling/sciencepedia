{"hands_on_practices": [{"introduction": "Many real-world systems, from elevators to data processing pipelines, serve customers in batches rather than one by one. This exercise challenges you to build a discrete event simulation of a single-server queue with batch service from the ground up [@problem_id:3119935]. You will implement the complete event-scheduling logic to model this system and practice computing fundamental performance metrics like system throughput and average customer waiting time.", "problem": "You are to design and implement a Discrete Event Simulation (DES) of a single-server queue with bulk service, known as a Markovian arrivals/Markovian service/one server ($M/M/1$) queue with maximum batch size. In this system, arrivals form a Poisson process with rate $\\lambda$ and service times are exponentially distributed with rate $\\mu$ per batch. The server can start a service that simultaneously serves up to $b$ customers at once; the batch size selected at service start is the minimum of the current queue length and the maximum batch size $b$. The service time for a batch does not depend on the batch size. Customers wait in a First-In First-Out (FIFO) queue.\n\nStarting from core definitions, you must implement an event-scheduling discrete event simulation that models the following rules:\n\n- Arrivals occur according to a Poisson process with rate $\\lambda$; interarrival times are independent and exponentially distributed with mean $1/\\lambda$.\n- When the server is idle and the queue is nonempty, service starts immediately on a batch of size $k = \\min(b, q)$, where $q$ is the current queue length. All $k$ customers in the batch start service at the same instant and depart together after a single exponentially distributed service time with mean $1/\\mu$.\n- While a batch is in service, incoming arrivals join the queue and will be served in a future batch after the current service completes.\n- The waiting time of a customer is defined as the time from arrival to the start of service. Throughput is defined as the number of customers departing within the simulation horizon divided by the simulation horizon length.\n\nYour simulation must use next-event time advance: at any step, the next event is the minimum of the next arrival time and the next service completion time. The simulation must run from time $t=0$ up to a finite horizon $T$, starting with an empty queue and an idle server. You must report the following performance measures over the run:\n- The throughput $\\tau$, defined as $D/T$, where $D$ is the number of customers who complete service by time $T$.\n- The mean waiting time $\\overline{W}$ over all customers who start service by time $T$.\n\nImportant modeling notes:\n- Assume the service time distribution of a batch is $\\text{Exponential}(\\mu)$, independent of how many customers are in the batch.\n- For reproducibility, each test case must use a specified pseudo-random seed.\n- If no customer starts service within the horizon, define $\\overline{W}$ as $\\mathrm{NaN}$ (not-a-number) and $\\tau$ as $0$.\n\nBase definitions to use:\n- Poisson process: arrivals have independent, stationary increments; interarrival times are independent exponential random variables with parameter $\\lambda$.\n- Exponential distribution with parameter $\\alpha$: a nonnegative random variable with memoryless property and mean $1/\\alpha$.\n- FIFO discipline: customers are served in nondecreasing order of their arrival times.\n\nImplement a complete, runnable program that computes $\\tau$ and $\\overline{W}$ for the following test suite, where each parameter set is $(\\lambda, \\mu, b, T, \\text{seed})$:\n\n- Test 1: $(\\lambda=0.8, \\mu=1.0, b=2, T=20000, \\text{seed}=1)$, a stable case with moderate load.\n- Test 2: $(\\lambda=2.0, \\mu=1.0, b=2, T=20000, \\text{seed}=2)$, a boundary-load case near the nominal capacity $\\mu \\cdot b$.\n- Test 3: $(\\lambda=1.5, \\mu=1.0, b=1, T=20000, \\text{seed}=3)$, a classic single-customer batch overloaded case (serves one at a time).\n- Test 4: $(\\lambda=0.9, \\mu=1.0, b=4, T=20000, \\text{seed}=4)$, a stable case with larger batch capacity.\n- Test 5: $(\\lambda=3.0, \\mu=0.5, b=10, T=20000, \\text{seed}=5)$, a stable high-load case with large batch capacity.\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets. Each test case contributes a pair $[\\tau,\\overline{W}]$, with both values printed as decimal floats rounded to six digits after the decimal point. The final format must be:\n$$\\big[ [\\tau_1,\\overline{W}_1], [\\tau_2,\\overline{W}_2], [\\tau_3,\\overline{W}_3], [\\tau_4,\\overline{W}_4], [\\tau_5,\\overline{W}_5] \\big]$$\nwhere the order corresponds to Tests 1 through 5. Throughput $\\tau$ must be in customers per unit time, and the waiting time $\\overline{W}$ must be in the same time unit as $T$.", "solution": "The problem requires the design and implementation of a discrete event simulation for a single-server queue with batch service, specifically a model categorized as $M/M/1$ with a maximum batch size $b$. The simulation must be constructed using a next-event time advance mechanism and will be used to estimate system performance metrics. The problem is scientifically grounded, well-posed, and provides all necessary parameters for a reproducible simulation.\n\n### 1. Conceptual Framework of Discrete Event Simulation (DES)\n\nA discrete event simulation models a system's evolution over time as a sequence of instantaneous events that alter the system's state. The fundamental components of this simulation are:\n\n-   **State Variables**: A minimal set of variables that completely describe the system at any point in time. For this problem, the state is defined by the number of customers waiting in the queue, $q$, and the status of the server (idle or busy). To calculate individual customer waiting times, we must also store the arrival time of each waiting customer.\n-   **Simulation Clock ($t_{sim}$)**: A variable that tracks the current time within the simulation. Time advances in discrete jumps from one event to the next.\n-   **Events**: Instantaneous occurrences that trigger a change in the system's state. In this model, there are two event types: a customer **Arrival** and a batch **Service Completion** (which corresponds to a departure of multiple customers).\n-   **Event Scheduling**: A mechanism to manage future events. Given that there are only two types of future events to track (the next arrival and the potential next service completion), we can use two variables, $t_A$ and $t_D$, to store their scheduled times. The event with the minimum scheduled time is the next one to occur.\n\n### 2. State Variables and Statistical Accumulators\n\nThe simulation dynamically maintains the following variables to track the system state and compute final metrics:\n\n-   **Simulation Clock**: $t_{sim}$\n-   **Queue of Arrival Times**: $Q_{times}$, a First-In-First-Out (FIFO) data structure holding the arrival times of customers currently waiting for service. Its length corresponds to the queue length, $q = |Q_{times}|$.\n-   **Server Status**: $S$, a binary indicator where $S=0$ denotes an idle server and $S=1$ denotes a busy server.\n-   **Next Arrival Time**: $t_A$, the scheduled time for the next customer arrival.\n-   **Next Departure Time**: $t_D$, the scheduled time for the current batch's service completion. It is set to infinity ($\\infty$) when the server is idle.\n-   **Batch Size in Service**: $k_{service}$, the number of customers in the batch currently being served.\n\nTo compute the required performance measures, the following statistical accumulators are updated throughout the simulation:\n\n-   $N_D$: The total count of customers who have departed (completed service).\n-   $N_S$: The total count of customers who have started service.\n-   $W_{tot}$: The cumulative sum of waiting times for all customers who have started service.\n\n### 3. Simulation Algorithm: Next-Event Time Advance\n\nThe simulation executes a main loop that repeatedly advances the clock to the next scheduled event time, processes the event, and updates the system state. The process starts at $t_{sim}=0$ and continues until the next event time would exceed the simulation horizon $T$.\n\n#### Initialization (at $t_{sim}=0$)\n\n1.  Set the simulation clock $t_{sim} = 0$.\n2.  Initialize the system state: the queue $Q_{times}$ is empty, and the server is idle ($S=0$).\n3.  Initialize statistical accumulators: $N_D = 0$, $N_S = 0$, and $W_{tot} = 0$.\n4.  Initialize server variables: $k_{service}=0$.\n5.  Seed the pseudo-random number generator for reproducibility.\n6.  Schedule the first arrival: Generate an inter-arrival time $\\Delta t_A$ from an exponential distribution with rate $\\lambda$ (mean $1/\\lambda$) using the formula $\\Delta t_A = -\\frac{1}{\\lambda}\\ln(U)$, where $U$ is a random variate from a Uniform$(0,1)$ distribution. Set the first arrival time to $t_A = \\Delta t_A$.\n7.  Set the next departure time to infinity, $t_D = \\infty$, as the server is initially idle.\n\n#### Simulation Main Loop\n\nThe loop proceeds as follows:\n\n1.  **Determine Next Event**: Identify the time of the next event, $t_{next} = \\min(t_A, t_D)$.\n2.  **Check Termination Condition**: If $t_{next} > T$, the simulation horizon has been passed, so the loop terminates.\n3.  **Advance Clock**: Update the simulation clock to the next event time: $t_{sim} = t_{next}$.\n4.  **Process Event**:\n    -   **If $t_{sim}$ is an Arrival Time ($t_{sim} = t_A$):**\n        a. A new customer arrives. Add their arrival time, $t_{sim}$, to the queue $Q_{times}$.\n        b. Schedule the next arrival. Generate a new inter-arrival time $\\Delta t_A \\sim \\text{Exponential}(\\lambda)$ and set the new arrival time $t_A = t_{sim} + \\Delta t_A$.\n    -   **If $t_{sim}$ is a Departure Time ($t_{sim} = t_D$):**\n        a. The batch of size $k_{service}$ completes service. Increment the total departed count: $N_D \\leftarrow N_D + k_{service}$.\n        b. The server becomes free. Set $S=0$ and reset the next departure time to $t_D = \\infty$.\n\n5.  **Check for New Service Start**: This logic is executed after any event.\n    -   If the server is idle ($S=0$) and the queue is not empty ($|Q_{times}|>0$):\n        a. The server becomes busy: set $S=1$.\n        b. Determine the batch size for this service instance: $k = \\min(b, |Q_{times}|)$.\n        c. Record the size of the batch now in service: $k_{service} = k$.\n        d. For each of the $k$ customers at the front of the queue:\n           i. Dequeue their arrival time, $t_{arr}$, from $Q_{times}$.\n           ii. Calculate their waiting time: $W_i = t_{sim} - t_{arr}$.\n           iii. Add this to the total waiting time: $W_{tot} \\leftarrow W_{tot} + W_i$.\n        e. Increment the count of customers who have started service by the batch size: $N_S \\leftarrow N_S + k$.\n        f. Schedule the service completion for this new batch. Generate a service time $\\Delta t_S \\sim \\text{Exponential}(\\mu)$ and set the departure time $t_D = t_{sim} + \\Delta t_S$.\n\n#### Final Calculations\n\nAfter the simulation loop terminates, the performance metrics are computed:\n\n1.  **Throughput ($\\tau$)**: Defined as the rate of customers completing service. It is calculated as $\\tau = N_D / T$. If no customers departed, $N_D=0$ and thus $\\tau=0$.\n2.  **Mean Waiting Time ($\\overline{W}$)**: Averaged over all customers who started service by time $T$.\n    -   If $N_S > 0$, the mean waiting time is $\\overline{W} = W_{tot} / N_S$.\n    -   If $N_S = 0$, no customers started service. In this case, $\\overline{W}$ is defined as Not-a-Number ($\\mathrm{NaN}$).\n\nThis rigorous, event-driven approach ensures that the system's dynamics are accurately modeled according to the specified rules.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom collections import deque\n\ndef run_simulation(lambda_rate, mu_rate, b, T, seed):\n    \"\"\"\n    Runs a discrete event simulation of a single-server queue with bulk service.\n\n    Args:\n        lambda_rate (float): Arrival rate (Poisson process).\n        mu_rate (float): Service rate per batch (Exponential distribution).\n        b (int): Maximum batch size.\n        T (float): Simulation time horizon.\n        seed (int): Seed for the pseudo-random number generator.\n\n    Returns:\n        tuple[float, float]: A tuple containing the calculated throughput (tau)\n                             and mean waiting time (W_mean).\n    \"\"\"\n    rng = np.random.default_rng(seed)\n\n    # State variables\n    t_sim = 0.0\n    queue_arrival_times = deque()\n    server_busy = False\n\n    # Event times\n    t_arrival = rng.exponential(scale=1.0 / lambda_rate)\n    t_departure = float('inf')\n\n    # Statistical accumulators\n    departed_count = 0\n    started_service_count = 0\n    wait_time_sum = 0.0\n    \n    # Variable to store the size of the batch currently in service\n    batch_size_in_service = 0\n\n    while True:\n        # Determine the next event time\n        if t_arrival = t_departure:\n            is_arrival_event = True\n            next_event_time = t_arrival\n        else:\n            is_arrival_event = False\n            next_event_time = t_departure\n\n        # Check termination condition\n        if next_event_time > T:\n            break\n        \n        t_sim = next_event_time\n\n        if is_arrival_event:\n            # --- Process Arrival Event ---\n            queue_arrival_times.append(t_sim)\n            # Schedule the next arrival\n            t_arrival = t_sim + rng.exponential(scale=1.0 / lambda_rate)\n        else:\n            # --- Process Departure Event ---\n            departed_count += batch_size_in_service\n            server_busy = False\n            t_departure = float('inf')\n            batch_size_in_service = 0\n\n        # --- Check for new Service Start (after any event) ---\n        if not server_busy and len(queue_arrival_times) > 0:\n            server_busy = True\n            \n            # Determine batch size\n            batch_k = min(b, len(queue_arrival_times))\n            batch_size_in_service = batch_k\n            \n            # Process customers starting service\n            for _ in range(batch_k):\n                arrival_t = queue_arrival_times.popleft()\n                wait_time_sum += (t_sim - arrival_t)\n            \n            started_service_count += batch_k\n            \n            # Schedule the departure for this batch\n            service_time = rng.exponential(scale=1.0 / mu_rate)\n            t_departure = t_sim + service_time\n    \n    # --- Final Calculations after loop termination ---\n    tau = departed_count / T\n\n    if started_service_count > 0:\n        W_mean = wait_time_sum / started_service_count\n    else:\n        # As per problem spec, if no customer starts service, W is NaN.\n        # tau will naturally be 0 in this case as departed_count is 0.\n        W_mean = float('nan')\n\n    return tau, W_mean\n\ndef solve():\n    \"\"\"\n    Defines test cases, runs the simulation for each, and prints the formatted results.\n    \"\"\"\n    test_cases = [\n        # (lambda_rate, mu_rate, b, T, seed)\n        (0.8, 1.0, 2, 20000, 1),  # Test 1\n        (2.0, 1.0, 2, 20000, 2),  # Test 2\n        (1.5, 1.0, 1, 20000, 3),  # Test 3\n        (0.9, 1.0, 4, 20000, 4),  # Test 4\n        (3.0, 0.5, 10, 20000, 5)  # Test 5\n    ]\n\n    results = []\n    for case in test_cases:\n        tau, W_mean = run_simulation(*case)\n        \n        # Format results to six decimal places, handling NaN for waiting time.\n        tau_str = f\"{tau:.6f}\"\n        if np.isnan(W_mean):\n            W_mean_str = \"NaN\" \n        else:\n            W_mean_str = f\"{W_mean:.6f}\"\n            \n        results.append(f\"[{tau_str},{W_mean_str}]\")\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(results)}]\")\n\nsolve()\n```", "id": "3119935"}, {"introduction": "A simulation's results are only as reliable as the model itself, making verification a critical step in the development process. This practice focuses on ensuring your simulation's logical integrity by implementing runtime checks for fundamental system invariants, such as the conservation of entities [@problem_id:3119919]. Through a guided fault-injection exercise, you will gain hands-on experience in building robust, self-validating models that can detect and report internal errors.", "problem": "You will implement a discrete event simulation of a single-server queue with exponential interarrival and service times. The goal is to verify invariant properties at runtime and to inject controlled logic faults to test detection coverage. The simulation must be deterministic through a fixed random seed. The fundamental base consists of the definitions of discrete event simulation, the notion of a Poisson process for arrivals, and the principle of conservation of entities.\n\nThe system is defined as follows:\n- Events are arrivals and service completions (departures). After each processed event at time $t$, the following invariants must be asserted:\n  1. Nonnegativity of queue length: $Q(t) \\ge 0$, where $Q(t)$ is the number of entities waiting in the queue (excluding any entity currently in service).\n  2. Conservation of entities: $S(t) + D(t) = A(t)$, where $S(t)$ is the current number of entities in the system (waiting plus being served), $D(t)$ is the cumulative number of departures, and $A(t)$ is the cumulative number of arrivals.\n- Arrivals follow an exponential interarrival distribution with rate $\\lambda$ in $\\text{s}^{-1}$ (per second). Services follow an exponential distribution with rate $\\mu$ in $\\text{s}^{-1}$. Simulation time is bounded by $T_{\\text{end}}$ in seconds.\n\nImplement the discrete event simulation according to the following rules:\n- Use a priority event list ordered by time to process events strictly in chronological order.\n- At an arrival:\n  - Increment the cumulative arrivals $A(t)$ unless a fault specifies otherwise.\n  - If the server is idle, start service immediately and schedule a departure after a service time draw; otherwise, increment the queue length.\n  - Update $S(t)$ accordingly.\n- At a departure:\n  - Increment the cumulative departures $D(t)$.\n  - If the queue is nonempty, decrement the queue length and immediately start service on the next entity (schedule its departure); otherwise, mark the server idle.\n  - Update $S(t)$ accordingly.\n- After every event, enforce runtime assertions for both invariants. If any assertion fails, the simulation must record that a violation was detected and stop processing further events for that test case.\n\nFault injection mechanisms:\n- Fault $f_1$ (\"negative queue fault\"): on the first departure event, maliciously set $Q(t)$ to $-1$ right before checking invariants. This tests detection of the nonnegativity invariant.\n- Fault $f_2$ (\"drop arrival fault\"): on the $k$-th arrival (with $k$ a positive integer), process the arrival into the system but do not increment $A(t)$. This tests detection of the conservation invariant.\n\nUnits:\n- Time $t$ and $T_{\\text{end}}$ must be in seconds.\n- Rates $\\lambda$ and $\\mu$ must be in $\\text{s}^{-1}$.\n\nRandomness:\n- Use a fixed seed $s = 42$ for all random draws to ensure determinism.\n\nYour program must implement the simulation and invariant checks, and it must support toggling the two faults per test case. For each test case, return a boolean indicating whether any invariant violation was detected (`True` if a violation was detected, else `False`).\n\nTest suite (all times in seconds, all rates in $\\text{s}^{-1}$, and $k$ is a unitless positive integer index):\n- Case 1 (happy path): $\\lambda = 1.5$, $\\mu = 2.0$, $T_{\\text{end}} = 10.0$, $f_1 = \\text{False}$, $f_2 = \\text{False}$, $k = 3$.\n- Case 2 (boundary, no arrivals): $\\lambda = 0.0$, $\\mu = 1.0$, $T_{\\text{end}} = 5.0$, $f_1 = \\text{False}$, $f_2 = \\text{False}$, $k = 3$.\n- Case 3 (fast service edge): $\\lambda = 10.0$, $\\mu = 100.0$, $T_{\\text{end}} = 1.0$, $f_1 = \\text{False}$, $f_2 = \\text{False}$, $k = 3$.\n- Case 4 (negative queue fault): $\\lambda = 0.5$, $\\mu = 0.5$, $T_{\\text{end}} = 10.0$, $f_1 = \\text{True}$, $f_2 = \\text{False}$, $k = 3$.\n- Case 5 (drop arrival fault): $\\lambda = 2.0$, $\\mu = 3.0$, $T_{\\text{end}} = 10.0$, $f_1 = \\text{False}$, $f_2 = \\text{True}$, $k = 3$.\n\nFinal output specification:\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, with one boolean per test case, in order of the cases above (e.g., `[True,False,...]`). No other output is permitted.", "solution": "The problem statement has been evaluated and is determined to be **valid**. It is scientifically grounded in the established principles of queueing theory and discrete event simulation, and it is well-posed, providing a complete and consistent set of definitions, parameters, and constraints for a deterministic implementation.\n\nThe task is to implement a discrete event simulation (DES) of a single-server queue, known in queueing theory as an M/M/1 queue, due to its **M**arkovian (exponential) interarrival and service time distributions. The implementation will be used to verify system invariants at runtime and test the detection of injected faults.\n\n**1. Principles of Discrete Event Simulation**\n\nA discrete event simulation models the evolution of a system as a sequence of discrete events occurring at specific points in time. The core components of our simulation model are:\n- **System State**: A set of variables that captures the essential information about the system at any given time $t$.\n- **Simulation Clock**: A variable representing the current time $t$ in the simulation.\n- **Event List**: A data structure, typically a priority queue, that stores future events ordered by their scheduled time of occurrence.\n\nThe simulation proceeds by repeatedly extracting the next most imminent event from the event list, advancing the simulation clock to the event's time, and executing an event-handling routine that updates the system state.\n\n**2. System State Representation**\n\nFor the M/M/1 queue, the state of the system at time $t$ is defined by the following variables:\n- $Q(t)$: The number of entities waiting in the queue. This is a non-negative integer.\n- $B(t)$: A binary variable representing the server status, where $B(t)=1$ if the server is busy and $B(t)=0$ if it is idle.\n- $A(t)$: The cumulative count of entities that have arrived in the system up to time $t$.\n- $D(t)$: The cumulative count of entities that have departed from the system up to time $t$.\n\nFrom these, we can derive $S(t)$, the total number of entities currently in the system (either in service or waiting in the queue):\n$$S(t) = Q(t) + B(t)$$\n\n**3. Event-Driven Logic and Event Routines**\n\nThe simulation is driven by an event-scheduling algorithm. An event list, implemented as a min-priority queue, stores pending events as tuples of `(event_time, event_type)`. The main loop continuously processes the event with the smallest time stamp until the event list is empty or the simulation end time $T_{\\text{end}}$ is surpassed.\n\nTwo types of events drive the system's dynamics: Arrival and Departure.\n\n**Arrival Event Routine**:\nAn arrival event at time $t$ triggers the following actions:\n1.  **Fault Injection Check**: If fault $f_2$ is enabled and this is the $k$-th arrival, the increment to $A(t)$ is skipped. Otherwise, $A(t)$ is incremented: $A(t) \\leftarrow A(t^-) + 1$.\n2.  **State Update**:\n    - If the server is idle ($B(t^-)=0$), the arriving entity immediately enters service. We set $B(t) \\leftarrow 1$ and schedule a new `Departure` event. The time of this future departure is $t + \\tau_s$, where $\\tau_s$ is a random service time drawn from an exponential distribution with rate $\\mu$.\n    - If the server is busy ($B(t^-)=1$), the entity must wait. The queue length is incremented: $Q(t) \\leftarrow Q(t^-) + 1$.\n3.  **Schedule Next Arrival**: A new `Arrival` event is scheduled at time $t + \\tau_a$, where $\\tau_a$ is a random interarrival time drawn from an exponential distribution with rate $\\lambda$. This is done only if $\\lambda > 0$.\n\n**Departure Event Routine**:\nA departure event at time $t$ signifies the completion of a service:\n1.  **State Update**: The cumulative departure count is incremented: $D(t) \\leftarrow D(t^-) + 1$.\n2.  **Server and Queue Update**:\n    - If the queue is not empty ($Q(t^-) > 0$), the next entity from the queue immediately enters service. We decrement the queue length, $Q(t) \\leftarrow Q(t^-) - 1$, and schedule a new `Departure` event at time $t + \\tau_s$, with $\\tau_s$ drawn from the service time distribution. The server remains busy ($B(t)=1$).\n    - If the queue is empty ($Q(t^-)=0$), the server becomes idle: $B(t) \\leftarrow 0$.\n\n**4. Random Variate Generation**\n\nThe interarrival and service times are random variables following exponential distributions with rates $\\lambda$ and $\\mu$, respectively. A random variate $x$ from an exponential distribution with rate parameter $\\theta$ can be generated using the inverse transform sampling method. This gives the formula:\n$$ x = -\\frac{1}{\\theta} \\ln(U) $$\nwhere $U$ is a random number drawn from a uniform distribution on the interval $(0, 1)$. To ensure the deterministic behavior required by the problem, the pseudo-random number generator is seeded with a fixed value, $s=42$, at the beginning of each simulation run.\n\n**5. Invariant Assertion and Fault Injection**\n\nAfter each event is processed, two fundamental system invariants are asserted to ensure the logical correctness of the simulation state. The fault injection mechanisms are designed to deterministically violate these invariants to test the monitoring logic.\n\n1.  **Queue Non-negativity**: $Q(t) \\ge 0$. It is physically impossible to have a negative number of items in a queue. Fault $f_1$ tests the detection of this invariant's violation. On the first departure event, it maliciously sets the value of $Q(t)$ to $-1$ immediately before the invariants are checked.\n\n2.  **Entity Conservation**: $A(t) = S(t) + D(t)$. This expresses the law of conservation: an entity that has arrived must either still be in the system ($S(t)$) or have departed ($D(t)$). Fault $f_2$ targets this invariant. On the $k$-th arrival, it causes the simulation to \"drop\" the arrival from the cumulative count $A(t)$, while still allowing the entity to enter the system. This creates a discrepancy where $S(t) + D(t)$ will be greater than $A(t)$, violating the equality.\n\nIf either check fails, a \"violation detected\" flag is set to `True`, and the simulation for that specific test case is terminated. Otherwise, the simulation continues. The final result for each case is the terminal state of this flag.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nimport heapq\n\ndef run_simulation(lam: float, mu: float, T_end: float, f1: bool, f2: bool, k: int) -> bool:\n    \"\"\"\n    Runs a discrete event simulation of a single-server queue (M/M/1).\n\n    Args:\n        lam: The arrival rate (lambda) in s^-1.\n        mu: The service rate (mu) in s^-1.\n        T_end: The simulation end time in seconds.\n        f1: Boolean flag to enable the negative queue fault.\n        f2: Boolean flag to enable the drop arrival fault.\n        k: The index of the arrival to drop for the f2 fault.\n\n    Returns:\n        A boolean indicating if any invariant violation was detected.\n    \"\"\"\n    # Set the random seed for reproducibility in this specific run.\n    np.random.seed(42)\n\n    # State variables\n    current_time = 0.0\n    queue_length = 0\n    # server_busy is equivalent to B(t), where 1 is busy and 0 is idle.\n    server_busy = False\n    cumulative_arrivals = 0\n    cumulative_departures = 0\n    \n    # Internal counters for fault logic\n    arrival_handler_calls = 0\n    departure_handler_calls = 0\n\n    violation_detected = False\n\n    # Event list: min-heap of (time, type_id, event_id)\n    # type_id: 0 for Arrival, 1 for Departure\n    # event_id: unique counter to break ties and ensure heap stability\n    event_list = []\n    event_id_counter = 0\n\n    # Schedule the first arrival if arrival rate is positive\n    if lam > 0:\n        interarrival_time = np.random.exponential(scale=1.0/lam)\n        heapq.heappush(event_list, (interarrival_time, 0, event_id_counter))\n        event_id_counter += 1\n\n    # Main simulation loop\n    while event_list:\n        event_time, event_type_id, _ = heapq.heappop(event_list)\n        \n        # Stop if simulation time exceeds T_end\n        if event_time > T_end:\n            break\n\n        current_time = event_time\n\n        # --- Event Handlers ---\n        if event_type_id == 0:  # Arrival Event\n            arrival_handler_calls += 1\n            \n            # Process arrival into system; A(t) increment is conditional on fault f2\n            if not server_busy:\n                server_busy = True\n                service_time = np.random.exponential(scale=1.0/mu)\n                departure_time = current_time + service_time\n                heapq.heappush(event_list, (departure_time, 1, event_id_counter))\n                event_id_counter += 1\n            else:\n                queue_length += 1\n            \n            # Fault f2: on k-th arrival, do not increment cumulative_arrivals\n            if not(f2 and arrival_handler_calls == k):\n                cumulative_arrivals += 1\n            \n            # Schedule the next arrival\n            if lam > 0:\n                interarrival_time = np.random.exponential(scale=1.0/lam)\n                next_arrival_time = current_time + interarrival_time\n                heapq.heappush(event_list, (next_arrival_time, 0, event_id_counter))\n                event_id_counter += 1\n\n        elif event_type_id == 1:  # Departure Event\n            departure_handler_calls += 1\n            cumulative_departures += 1\n\n            if queue_length > 0:\n                queue_length -= 1\n                # Server remains busy, start service for next in queue\n                service_time = np.random.exponential(scale=1.0/mu)\n                departure_time = current_time + service_time\n                heapq.heappush(event_list, (departure_time, 1, event_id_counter))\n                event_id_counter += 1\n            else:\n                server_busy = False\n\n        # --- Invariant Assertion ---\n        # The monitor checks the state, which may be maliciously altered.\n        q_for_check = queue_length\n\n        # Fault f1: On first departure, set Q(t) to -1 before check.\n        if f1 and event_type_id == 1 and departure_handler_calls == 1:\n            q_for_check = -1\n\n        # Invariant 1: Non-negativity of queue length, Q(t) >= 0.\n        if q_for_check  0:\n            violation_detected = True\n\n        # Invariant 2: Conservation of entities, S(t) + D(t) = A(t).\n        # S(t) is calculated based on the state visible to the monitor,\n        # which includes any faulted values.\n        # S(t) = Q(t) + B(t), where B(t) is 1 if server is busy, 0 otherwise.\n        s_for_check = q_for_check + (1 if server_busy else 0)\n        if s_for_check + cumulative_departures != cumulative_arrivals:\n            violation_detected = True\n\n        if violation_detected:\n            break\n\n    return violation_detected\n\ndef solve():\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # (lambda, mu, T_end, f1, f2, k)\n        (1.5, 2.0, 10.0, False, False, 3),  # Case 1: Happy path\n        (0.0, 1.0, 5.0, False, False, 3),   # Case 2: No arrivals\n        (10.0, 100.0, 1.0, False, False, 3),# Case 3: Fast service\n        (0.5, 0.5, 10.0, True, False, 3),   # Case 4: Negative queue fault\n        (2.0, 3.0, 10.0, False, True, 3)    # Case 5: Drop arrival fault\n    ]\n\n    results = []\n    for case in test_cases:\n        lam, mu, T_end, f1, f2, k = case\n        result = run_simulation(lam, mu, T_end, f1, f2, k)\n        results.append(result)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "3119919"}, {"introduction": "Building on the fundamentals, we now turn to more complex and dynamic scheduling rules found in systems like modern operating systems or emergency services. This advanced practice introduces the concept of preemptive-resume priority, where a high-priority task can interrupt an ongoing low-priority one [@problem_id:3119930]. You will tackle the intricate logic of preemption, learning how to manage a dynamic event calendar where scheduled events may be invalidated, a core challenge in simulating sophisticated systems.", "problem": "You must implement a Discrete Event Simulation (DES) of a single-server system with a preemptive-resume static-priority discipline. The simulation must maintain a correct event calendar with explicit preemption, including cascaded preemptions. Your task is to write a complete, runnable program that, for a fixed test suite of job sets, simulates the system and verifies a set of invariants. The program must output a single line containing a list of boolean values, one per test case, indicating whether all invariants hold for that test case.\n\nSystem description and fundamental base:\n- A Discrete Event Simulation (DES) advances the simulation clock only at times when discrete events occur. The core state is driven by an event calendar (a priority queue), and state transitions happen instantaneously at event times. The fundamental base is the event-scheduling paradigm and the definition of a preemptive-resume priority queue.\n- The system has a single server. Time is continuous and represented by a real-valued simulation clock $t \\in \\mathbb{R}_{\\ge 0}$.\n- Each job $j$ is defined by a quadruple $(\\text{id}_j, a_j, d_j, p_j)$, where $\\text{id}_j$ is a unique integer identifier, $a_j$ is the arrival time, $d_j$ is the required service duration, and $p_j$ is the static priority. Lower numeric priority means higher scheduling precedence: if $p_i  p_k$ then job $i$ has higher priority than job $k$.\n- Preemptive-resume discipline: when a job arrives at time $t$, if the server is idle it starts immediately; if the server is busy with a job $r$ and the arriving job $j$ has higher priority, i.e., $p_j  p_r$, then $r$ is preempted. The remaining processing time of $r$ is reduced by the amount of service it has received, and $r$ is placed back into the ready queue; the new job $j$ starts immediately at time $t$. Service is resumable without loss: if job $r$ has remaining time $x$ upon resumption, it needs exactly $x$ more units of service to complete.\n- Event calendar: there are two event types — arrivals and completions. The calendar is a priority queue ordered lexicographically by $(\\text{time}, \\text{kind})$ where arrivals are processed before completions when they are simultaneous. Among simultaneous arrivals, smaller $p_j$ are processed first; ties are broken by increasing arrival listing order. To support safe preemption, completion events must be cancelable by tokenization: each scheduled completion carries a token that must match the job’s current token when the completion fires; otherwise, the completion is stale and must be ignored.\n- Tie-handling at identical times $t$: process all arrivals at time $t$ before considering any completions at time $t$. This ensures that a newly arrived higher-priority job can preempt a job that would otherwise have completed at the same time $t$. If a job’s remaining time reaches $0$ exactly at a preemption instant, treat it as completed immediately at that time $t$.\n\nRequired invariants to verify per test case:\n- I$1$: Monotonic time: the sequence of popped event times from the calendar is non-decreasing. Formally, if $t_0, t_1, \\dots, t_m$ are the times of popped events, then $t_{k+1} \\ge t_k$ for all $k$.\n- I$2$: Uniqueness of running job: at any instant $t$, there is at most one running job on the single server.\n- I$3$: Per-job accounting: for every job $j$, the total service received equals its duration, i.e., $\\text{worked}_j = d_j$, and the remaining time at completion is $0$.\n- I$4$: System-wide accounting: the total integrated busy time of the server equals $\\sum_j d_j$. The integrated busy time is the measure of the set $\\{ t \\mid \\text{server is busy at time } t \\}$; you must compute it by integrating over state changes, not by summing per-job durations directly.\n- I$5$: Safe cancellation: no stale completion event changes the state. Implement this by assigning each job $j$ a token $\\tau_j \\in \\mathbb{N}$ that is incremented every time a new completion for $j$ is scheduled; a popped completion with token $\\hat{\\tau}$ must be ignored unless $\\hat{\\tau} = \\tau_j$ and the job is currently running.\n\nEvent ordering rules to implement:\n- Calendar ordering: arrivals before completions when times are equal.\n- Among arrivals at the same time $t$, sort by increasing $p_j$; ties broken by the input order for that test case.\n- Starting a job with zero remaining time $0$ results in an immediate completion at the same time $t$ without posting a completion event.\n\nTest suite:\nEach test case is a list of $(\\text{id}, a, d, p)$ quadruples. All times are in arbitrary consistent units; no physical units are required in the output since the final outputs are booleans.\n- Test case A (happy path, no preemptions):\n  - $[(0, 0, 2, 2), (1, 3, 1, 3), (2, 4, 1.5, 3)]$.\n- Test case B (single preemption):\n  - $[(0, 0, 5, 3), (1, 1, 2, 1)]$.\n- Test case C (cascading preemptions):\n  - $[(0, 0, 10, 4), (1, 1, 4, 3), (2, 2, 1, 2), (3, 2.5, 0.5, 1), (4, 6, 2, 4)]$.\n- Test case D (simultaneous arrivals and a zero-duration job at a completion time):\n  - $[(0, 0, 2, 2), (1, 0, 1, 1), (2, 1, 0, 0), (3, 1, 1, 3)]$.\n\nWhat to implement:\n- A complete DES engine as described, with an event calendar, a ready queue ordered by static priority, explicit preemption with resumable service, and tokenized completion cancellation.\n- The program must run all four test cases, verify invariants I$1$–I$5$ for each, and produce a single output line that is a Python list literal containing exactly four boolean values in order $[A, B, C, D]$ indicating whether all invariants hold for the respective test case.\n\nFinal output format:\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, for example, `[True,False,True,True]`. No other output is permitted.", "solution": "The user has provided a well-defined problem in the domain of discrete event simulation (DES). The task is to implement a simulation for a single-server queueing system with a static-priority, preemptive-resume scheduling discipline. The implementation must be validated against a comprehensive set of invariants for several test cases.\n\n### Problem Validation Verdict\nThe problem statement is **valid**. It is scientifically grounded in the established theory of queueing systems and discrete event simulation. It is well-posed, with clear and unambiguous definitions for system components, state transitions, and event-ordering rules. The requirements are self-contained and consistent, providing all necessary information to construct a correct simulation model. The task is a standard, non-trivial exercise in computational science, requiring careful algorithmic design to handle preemption, simultaneous events, and state management.\n\n### Solution Design\nThe solution is a discrete event simulation engine implemented in Python. The design is centered around a `Simulator` class that encapsulates the simulation state and logic. The core of the simulation is an event-driven loop that processes events from a time-ordered event calendar.\n\n#### Data Structures\n1.  **Job State**: Each job $j$ is represented by a data structure storing its defining parameters $(\\text{id}_j, a_j, d_j, p_j)$ as well as its dynamic state: remaining service duration, total service received, and a cancellation token $\\tau_j$ for handling preemptions.\n\n2.  **Event Calendar**: A min-priority queue, implemented using Python's `heapq` module, stores future events. Events are tuples ordered lexicographically, ensuring correct processing according to the specified rules. The tuple format for an event is $(\\text{time}, \\text{type}, \\dots)$.\n    -   An **Arrival** event is represented by a tuple $(\\text{time}, 0, \\text{priority}, \\text{input\\_order}, \\text{job\\_id})$. The numeric type $0$ ensures arrivals are processed before completions at the same time. The job's priority and original input order are included to resolve tie-breaks among simultaneous arrivals.\n    -   A **Completion** event is represented by $(\\text{time}, 1, \\text{job\\_id}, \\text{token})$. The type $1$ gives it lower precedence than an arrival. The token is used to validate the event upon execution.\n\n3.  **Ready Queue**: A min-priority queue, also implemented with `heapq`, stores jobs that have arrived but are not being served. Jobs are ordered by priority, with ties broken by their original input order. The tuple format is $(\\text{priority}, \\text{input\\_order}, \\text{job\\_id})$.\n\n#### Simulation Algorithm\nThe simulation proceeds by advancing a simulation clock, $t$, to the time of the next event. The core algorithm follows a three-phase process for each distinct event time.\n\n1.  **State Update Phase**: The clock $t$ is advanced from its previous value $t_{prev}$ to the new event time $t_{new}$. The time elapsed, $\\Delta t = t_{new} - t_{prev}$, is calculated. If a job was running on the server during this interval, its remaining duration is decremented by $\\Delta t$, and its total received service is incremented. The server's total busy time is also updated.\n\n2.  **Event Processing Phase**: All events scheduled for the current time $t_{new}$ are extracted from the event calendar. They are processed sequentially (the calendar's ordering rules have already sorted them correctly).\n    -   **Arrival**: The arriving job is added to the ready queue.\n    -   **Completion**: The event's token is checked against the job's current token, and it is verified that the job is indeed the one currently running. If the event is stale (tokens mismatch or another job is running), it is discarded. Otherwise, the job is marked as completed, and the server is marked as idle. The problem specifies this check as invariant I5.\n\n3.  **Scheduling Phase**: After processing all events at time $t_{new}$, the simulator makes a scheduling decision.\n    -   If a job is currently running, its priority is compared against the highest-priority job in the ready queue. If a ready job has a strictly higher priority (i.e., a lower priority number), the running job is preempted. Preemption involves updating the job's cancellation token (invalidating its old completion event) and moving it from the server to the ready queue.\n    -   If the server is idle (either because a job just completed or was preempted) and the ready queue is not empty, the highest-priority job is removed from the ready queue and begins service.\n    -   When a job starts service, a new completion event is scheduled and added to the event calendar. The event time is $t_{new} + d_{rem}$, where $d_{rem}$ is the job's remaining duration, and the event is tagged with the job's current token. A special case for jobs with zero remaining duration is handled by completing them immediately without scheduling an event.\n\n#### Invariant Verification\nAt the conclusion of each simulation run, the following invariants are checked:\n-   **I1 (Monotonic Time)**: A record of all popped event times is maintained. The list is checked to ensure it is non-decreasing.\n-   **I2 (Uniqueness of Running Job)**: This is guaranteed by the design of the simulator, which uses a single variable to track the ID of the running job. This invariant is considered `True` by construction.\n-   **I3 (Per-Job Accounting)**: For each job, it is verified that the total service received equals its original duration and that its remaining duration is zero, within a small floating-point tolerance $\\epsilon = 10^{-9}$.\n-   **I4 (System-Wide Accounting)**: The total integrated busy time of the server, accumulated over the simulation, is compared against the sum of all jobs' original durations. They must be equal within tolerance $\\epsilon$.\n-   **I5 (Safe Cancellation)**: This invariant is upheld by the core logic of the event-processing phase, which strictly ignores stale completion events based on the token-matching rule. This is also considered `True` by correct construction of the simulator.\n\nThe final output for each test case is a boolean indicating whether all five invariants hold.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport heapq\n\n# Per the execution environment, numpy and scipy would be available,\n# but are not necessary for this problem. The standard library's\n# heapq is sufficient and appropriate.\n\ndef solve():\n    \"\"\"\n    Main function to run the simulation for all test cases and print results.\n    \"\"\"\n\n    TOLERANCE = 1e-9  # Tolerance for floating-point comparisons\n\n    class Job:\n        \"\"\"Represents a job in the simulation.\"\"\"\n        def __init__(self, id, arrival, duration, priority, original_index):\n            self.id = id\n            self.arrival = float(arrival)\n            self.duration = float(duration)\n            self.priority = int(priority)\n            self.original_index = int(original_index)\n\n            # Dynamic state\n            self.remaining_duration = float(duration)\n            self.service_received = 0.0\n            self.token = 0\n            self.completion_time = None\n\n    class Simulator:\n        \"\"\"\n        Implements the Discrete Event Simulation for a single-server,\n        preemptive-resume, static-priority system.\n        \"\"\"\n        def __init__(self):\n            # Simulation state\n            self.time = 0.0\n            self.jobs = {}\n            self.event_calendar = []  # (time, type, prio, idx, job_id) or (time, type, job_id, token)\n            self.ready_queue = []  # (priority, original_index, job_id)\n            self.running_job_id = None\n\n            # Invariant tracking\n            self.total_server_busy_time = 0.0\n            self.event_times_log = []\n\n        def simulate(self, job_specs):\n            \"\"\"\n            Runs the full simulation for a given set of jobs.\n            \n            Args:\n                job_specs: A list of (id, arrival, duration, priority) tuples.\n            \n            Returns:\n                A boolean indicating if all invariants held true.\n            \"\"\"\n            # 1. Initialization\n            for i, spec in enumerate(job_specs):\n                job_id, arrival, duration, priority = spec\n                job = Job(job_id, arrival, duration, priority, i)\n                self.jobs[job_id] = job\n                \n                # Event tuple: (time, type, priority, original_index, job_id)\n                # type 0 for arrival, 1 for completion.\n                # This ordering handles all tie-breaking rules.\n                event = (job.arrival, 0, job.priority, job.original_index, job.id)\n                heapq.heappush(self.event_calendar, event)\n\n            # 2. Main Simulation Loop\n            while self.event_calendar:\n                # --- State Update Phase ---\n                next_event_time = self.event_calendar[0][0]\n                delta_t = next_event_time - self.time\n                if self.running_job_id is not None:\n                    job = self.jobs[self.running_job_id]\n                    job.service_received += delta_t\n                    job.remaining_duration -= delta_t\n                    self.total_server_busy_time += delta_t\n                self.time = next_event_time\n\n                # --- Event Processing Phase ---\n                newly_arrived_jobs = []\n                while self.event_calendar and self.event_calendar[0][0] == self.time:\n                    event = heapq.heappop(self.event_calendar)\n                    self.event_times_log.append(event[0])\n                    \n                    event_type = event[1]\n                    if event_type == 0:  # Arrival\n                        _, _, _, _, job_id = event\n                        newly_arrived_jobs.append(self.jobs[job_id])\n                    else:  # Completion\n                        _, _, job_id, token = event\n                        job = self.jobs[job_id]\n                        # Invariant I5 check:\n                        if token == job.token and self.running_job_id == job_id:\n                            job.completion_time = self.time\n                            job.remaining_duration = 0.0\n                            self.running_job_id = None\n                        # Stale events are ignored, upholding invariant I5.\n\n                for job in newly_arrived_jobs:\n                    heapq.heappush(self.ready_queue, (job.priority, job.original_index, job.id))\n\n                # --- Scheduling Phase ---\n                # A running job might have just finished or new higher-prio jobs arrived.\n                # Check for preemption if a job is running.\n                if self.running_job_id is not None and self.ready_queue:\n                    current_job = self.jobs[self.running_job_id]\n                    best_ready_job_spec = self.ready_queue[0]\n                    if best_ready_job_spec[0]  current_job.priority:\n                        # Preempt the current job\n                        current_job.token += 1\n                        heapq.heappush(self.ready_queue, (current_job.priority, current_job.original_index, current_job.id))\n                        self.running_job_id = None\n\n                # If server is idle, start a new job. Loop to handle zero-duration jobs.\n                while self.running_job_id is None and self.ready_queue:\n                    _, _, job_id_to_start = heapq.heappop(self.ready_queue)\n                    job = self.jobs[job_id_to_start]\n                    \n                    self.running_job_id = job.id\n                    if job.remaining_duration > TOLERANCE:\n                        completion_time = self.time + job.remaining_duration\n                        event = (completion_time, 1, job.id, job.token)\n                        heapq.heappush(self.event_calendar, event)\n                    else:\n                        job.completion_time = self.time\n                        job.remaining_duration = 0.0\n                        self.running_job_id = None # continues loop\n\n            return self.verify_invariants()\n\n        def verify_invariants(self):\n            # I1: Monotonic time\n            i1_ok = all(self.event_times_log[i] = self.event_times_log[i+1] for i in range(len(self.event_times_log) - 1))\n\n            # I2: Uniqueness of running job (guaranteed by design)\n            i2_ok = True\n\n            # I3: Per-job accounting\n            i3_ok = True\n            for job in self.jobs.values():\n                if abs(job.service_received - job.duration) > TOLERANCE or abs(job.remaining_duration) > TOLERANCE:\n                    i3_ok = False\n                    break\n            \n            # I4: System-wide accounting\n            total_job_durations = sum(j.duration for j in self.jobs.values())\n            i4_ok = abs(self.total_server_busy_time - total_job_durations)  TOLERANCE\n            \n            # I5: Safe cancellation (guaranteed by design)\n            i5_ok = True\n            \n            return all([i1_ok, i2_ok, i3_ok, i4_ok, i5_ok])\n\n    test_cases = {\n        'A': [(0, 0, 2, 2), (1, 3, 1, 3), (2, 4, 1.5, 3)],\n        'B': [(0, 0, 5, 3), (1, 1, 2, 1)],\n        'C': [(0, 0, 10, 4), (1, 1, 4, 3), (2, 2, 1, 2), (3, 2.5, 0.5, 1), (4, 6, 2, 4)],\n        'D': [(0, 0, 2, 2), (1, 0, 1, 1), (2, 1, 0, 0), (3, 1, 1, 3)],\n    }\n    \n    results = []\n    # Process test cases in specified order 'A', 'B', 'C', 'D'\n    for key in sorted(test_cases.keys()):\n        sim = Simulator()\n        result = sim.simulate(test_cases[key])\n        results.append(result)\n\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "3119930"}]}