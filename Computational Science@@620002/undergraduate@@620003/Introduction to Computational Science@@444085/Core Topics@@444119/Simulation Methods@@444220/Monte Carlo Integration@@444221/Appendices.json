{"hands_on_practices": [{"introduction": "One of the primary strengths of Monte Carlo integration is its ability to handle integrals over domains with complex geometries. While traditional grid-based methods struggle with intricate boundaries, the Monte Carlo approach elegantly sidesteps this issue by sampling from a simple bounding volume and using an indicator function to determine if a point is inside the region of interest. This exercise [@problem_id:1376816] provides a concrete application, asking you to estimate the total mass of a substance within a non-standard, three-dimensional shape, thereby solidifying your understanding of the fundamental Monte Carlo mechanism.", "problem": "A materials scientist is studying a new alloy created in a cubical mold of side length 1 meter. The coordinate system is aligned with the mold, such that it occupies the region defined by $0 \\le x \\le 1$, $0 \\le y \\le 1$, and $0 \\le z \\le 1$. The concentration of a special hardening agent, $C$, is found to be non-zero only in a specific sub-region of the mold defined by the inequalities $0 \\le z \\le y \\le x \\le 1$. Within this sub-region, the concentration at a point $(x,y,z)$ is described by the function $C(x,y,z) = k x y z$, where $k$ is a constant. Outside this region, the concentration is zero. The total mass of the agent in the mold is given by the integral of the concentration function over the entire volume of the 1-meter-cubed mold.\n\nTo estimate this total mass, an automated measurement system probes the concentration at a set of $N=5$ sample points, which are assumed to be representative of a uniform random sampling within the unit cube. The coordinates of these five points are:\n$P_1 = (0.8, 0.7, 0.2)$\n$P_2 = (0.9, 0.5, 0.6)$\n$P_3 = (0.6, 0.8, 0.3)$\n$P_4 = (0.5, 0.4, 0.3)$\n$P_5 = (0.7, 0.9, 0.8)$\n\nGiven the concentration constant $k = 4.8 \\text{ kg/m}^6$, calculate the numerical estimate for the total mass of the hardening agent in the mold based on this set of five sample points. Express your answer in kilograms (kg) and round to three significant figures.", "solution": "The total mass is the volume integral of the concentration over the unit cube:\n$$\nM=\\iiint_{[0,1]^{3}} C(x,y,z)\\,dV.\n$$\nWith uniform random sampling over a domain of volume $V=1$, the Monte Carlo estimator with $N$ samples $\\{P_{i}\\}_{i=1}^{N}$ is\n$$\n\\widehat{M}=\\frac{V}{N}\\sum_{i=1}^{N} C(P_{i})=\\frac{1}{N}\\sum_{i=1}^{N} C(P_{i}).\n$$\nHere $C(x,y,z)=k\\,x y z$ if $0 \\le z \\le y \\le x \\le 1$ and $C=0$ otherwise. Evaluate the indicator $0 \\le z \\le y \\le x \\le 1$ for each sample:\n- $P_{1}=(0.8,0.7,0.2)$: $0.2 \\le 0.7 \\le 0.8 \\le 1$ is true, so contributes $k\\cdot 0.8\\cdot 0.7\\cdot 0.2=0.112\\,k$.\n- $P_{2}=(0.9,0.5,0.6)$: $0.6 \\le 0.5$ is false, contributes $0$.\n- $P_{3}=(0.6,0.8,0.3)$: $0.8 \\le 0.6$ is false, contributes $0$.\n- $P_{4}=(0.5,0.4,0.3)$: $0.3 \\le 0.4 \\le 0.5 \\le 1$ is true, contributes $k\\cdot 0.5\\cdot 0.4\\cdot 0.3=0.06\\,k$.\n- $P_{5}=(0.7,0.9,0.8)$: $0.9 \\le 0.7$ is false, contributes $0$.\nTherefore\n$$\n\\sum_{i=1}^{5} C(P_{i})=(0.112+0.06)\\,k=0.172\\,k,\n$$\nand\n$$\n\\widehat{M}=\\frac{1}{5}\\cdot 0.172\\,k=0.0344\\,k.\n$$\nSubstituting $k=4.8$ gives\n$$\n\\widehat{M}=0.0344\\times 4.8=0.16512,\n$$\nwhich, rounded to three significant figures, is $0.165$ kilograms.", "answer": "$$\\boxed{0.165}$$", "id": "1376816"}, {"introduction": "While powerful, the convergence of the crude Monte Carlo estimator can be slow, with its error decreasing as $1/\\sqrt{N}$. To obtain precise estimates efficiently, we must employ variance reduction techniques. This practice [@problem_id:1376819] introduces one of the most effective methods: control variates. You will learn how to leverage a simpler, analytically tractable function that is correlated with your integrand to significantly reduce the variance of your estimate, and you will calculate the theoretical improvement factor to quantify its effectiveness.", "problem": "A computational scientist aims to estimate the value of the integral $I = \\int_0^1 \\exp(x^2) dx$ using a Monte Carlo method. The standard approach involves generating $N$ independent random numbers $X_1, \\dots, X_N$ from a uniform distribution on $[0, 1]$ and computing the sample mean $\\hat{I} = \\frac{1}{N} \\sum_{i=1}^N \\exp(X_i^2)$. The variance of this single-sample estimator is $\\text{Var}(\\exp(X^2))$, where $X \\sim U(0,1)$.\n\nTo improve the precision of the estimate for a given sample size, a control variate technique is employed. A function $g(x)$ is chosen that is highly correlated with $f(x) = \\exp(x^2)$ and whose integral over $[0, 1]$ is analytically known. The chosen control variate is $g(x) = 1 + x^2 + \\frac{1}{2}x^4$, inspired by the Taylor expansion of $f(x)$.\n\nThe new estimator is formed using a random variable $Y_c = f(X) - c(g(X) - \\mu_g)$, where $\\mu_g = \\int_0^1 g(x) dx$ and $c$ is a constant. The variance of this new estimator, $\\text{Var}(Y_c)$, is minimized by choosing an optimal constant $c = c^*$.\n\nYour task is to calculate the theoretical variance reduction factor achieved by using this optimal control variate. This factor is defined as the ratio of the variance of the standard Monte Carlo estimator to the variance of the optimized control variate estimator, i.e., $\\frac{\\text{Var}(f(X))}{\\text{Var}(Y_{c^*})}$.\n\nFor your calculations, use the following numerical values:\n- The mathematical constant $e \\approx 2.71828$.\n- $\\int_0^1 \\exp(x^2) dx \\approx 1.46265$.\n- $\\int_0^1 \\exp(2x^2) dx \\approx 3.01552$.\n\nExpress your final answer as a single numerical value, rounded to three significant figures.", "solution": "We seek the variance reduction factor using an optimal control variate for estimating $I=\\int_{0}^{1} f(x)\\,dx$ with $f(x)=\\exp(x^{2})$ and $g(x)=1+x^{2}+\\frac{1}{2}x^{4}$. For a control variate estimator $Y_{c}=f(X)-c\\left(g(X)-\\mu_{g}\\right)$ with $X\\sim U(0,1)$ and $\\mu_{g}=\\int_{0}^{1}g(x)\\,dx$, the variance is minimized at\n$$\nc^{*}=\\frac{\\operatorname{Cov}(f,g)}{\\operatorname{Var}(g)},\n$$\nand the minimized variance is\n$$\n\\operatorname{Var}(Y_{c^{*}})=\\operatorname{Var}(f)-\\frac{\\operatorname{Cov}(f,g)^{2}}{\\operatorname{Var}(g)}=\\operatorname{Var}(f)\\left(1-\\rho^{2}\\right),\n$$\nwhere $\\rho$ is the correlation between $f(X)$ and $g(X)$. Hence, the variance reduction factor is\n$$\n\\frac{\\operatorname{Var}(f(X))}{\\operatorname{Var}(Y_{c^{*}})}=\\frac{1}{1-\\rho^{2}}.\n$$\n\nWe now compute the necessary moments. First, $\\mu_{g}$ is\n$$\n\\mu_{g}=\\int_{0}^{1}\\left(1+x^{2}+\\frac{1}{2}x^{4}\\right)\\,dx=1+\\frac{1}{3}+\\frac{1}{10}=\\frac{43}{30}.\n$$\nNext, \n$$\n\\operatorname{E}[g(X)^{2}]=\\int_{0}^{1}\\left(1+2x^{2}+2x^{4}+x^{6}+\\frac{1}{4}x^{8}\\right)\\,dx=1+\\frac{2}{3}+\\frac{2}{5}+\\frac{1}{7}+\\frac{1}{36}=\\frac{2819}{1260},\n$$\nso\n$$\n\\operatorname{Var}(g)=\\operatorname{E}[g^{2}]-\\mu_{g}^{2}=\\frac{2819}{1260}-\\left(\\frac{43}{30}\\right)^{2}=\\frac{32}{175}.\n$$\n\nFor $f$, using the provided values,\n$$\n\\operatorname{E}[f]=\\int_{0}^{1}\\exp(x^{2})\\,dx\\approx 1.46265,\\qquad \\operatorname{E}[f^{2}]=\\int_{0}^{1}\\exp(2x^{2})\\,dx\\approx 3.01552,\n$$\nhence\n$$\n\\operatorname{Var}(f)=\\operatorname{E}[f^{2}]-\\operatorname{E}[f]^{2}\\approx 3.01552-(1.46265)^{2}\\approx 0.8761749775.\n$$\n\nTo compute $\\operatorname{E}[f\\,g]$, define $I_{n}=\\int_{0}^{1}x^{2n}\\exp(x^{2})\\,dx$. Integration by parts with $u=x^{2n-1}$ and $dv=x\\exp(x^{2})\\,dx$ yields the recurrence\n$$\nI_{n}=\\frac{1}{2}\\exp(1)-\\frac{2n-1}{2}I_{n-1},\\quad I_{0}=\\int_{0}^{1}\\exp(x^{2})\\,dx.\n$$\nUsing $\\exp(1)\\approx 2.71828$ and $I_{0}\\approx 1.46265$, we obtain\n$$\nI_{1}=\\frac{1}{2}\\exp(1)-\\frac{1}{2}I_{0}\\approx 0.627815,\\qquad\nI_{2}=\\frac{1}{2}\\exp(1)-\\frac{3}{2}I_{1}\\approx 0.4174175.\n$$\nTherefore,\n$$\n\\operatorname{E}[f\\,g]=I_{0}+I_{1}+\\frac{1}{2}I_{2}\\approx 1.46265+0.627815+0.20870875\\approx 2.29917375.\n$$\nThen\n$$\n\\operatorname{Cov}(f,g)=\\operatorname{E}[f\\,g]-\\operatorname{E}[f]\\operatorname{E}[g]\\approx 2.29917375-1.46265\\cdot\\frac{43}{30}\\approx 0.20270875,\n$$\nand\n$$\n\\rho^{2}=\\frac{\\operatorname{Cov}(f,g)^{2}}{\\operatorname{Var}(f)\\operatorname{Var}(g)}\\approx \\frac{(0.20270875)^{2}}{0.8761749775\\cdot\\frac{32}{175}}\\approx 0.256473333.\n$$\nHence the variance reduction factor is\n$$\n\\frac{1}{1-\\rho^{2}}\\approx \\frac{1}{1-0.256473333}\\approx 1.34494.\n$$\nRounded to three significant figures, this is $1.34$.", "answer": "$$\\boxed{1.34}$$", "id": "1376819"}, {"introduction": "Standard Monte Carlo methods are often impractical for estimating the probability of extremely rare events, as an immense number of samples would be needed just to observe the event a few times. Importance sampling is a sophisticated technique designed to overcome this challenge by concentrating sampling effort in the 'important' regions where the rare event occurs. In this advanced problem [@problem_id:1376872], you will design an importance sampling scheme to estimate a low-probability failure in a high-dimensional system, demonstrating how to tackle problems that are nearly intractable with basic methods.", "problem": "In many fields, such as in the modeling of communication systems or risk analysis, it is necessary to estimate the probability of rare events. Consider a system whose state is described by a vector $Z = (Z_1, Z_2, \\dots, Z_{10})$ of 10 independent and identically distributed random variates, each following a standard normal distribution, $Z_i \\sim \\mathcal{N}(0,1)$. A failure event is defined to occur if the squared L2-norm of this state vector, $\\|Z\\|^2 = \\sum_{i=1}^{10} Z_i^2$, exceeds a critical threshold $c=60$. The probability of this event, $P = P(\\|Z\\|^2 > 60)$, is extremely small and difficult to estimate using standard Monte Carlo methods.\n\nTo obtain a more efficient estimate, we will employ importance sampling. We will draw samples $X = (X_1, X_2, \\dots, X_{10})$ from a proposal distribution $q(x)$ instead of the original distribution $p(z)$. The chosen proposal distribution is a multivariate normal distribution whose components are independent and identically distributed, $X_i \\sim \\mathcal{N}(0, \\sigma^2)$, with a variance $\\sigma^2$ to be determined.\n\nYour task is to calculate the importance sampling estimate of the probability $P$. First, determine the appropriate value for the variance $\\sigma^2$ of the proposal distribution. A common and effective heuristic for this choice is to set the expectation of the quantity of interest (in this case, $\\|X\\|^2$) under the proposal distribution equal to the threshold value $c$.\n\nAfter determining $\\sigma^2$, use the results of a pre-computed simulation. In a numerical experiment, a total of $N = 5.0 \\times 10^5$ samples were drawn from the proposal distribution $q(x)$ with the value of $\\sigma^2$ you determined. For this collection of samples, the sum of the importance weights, but only for those samples that satisfy the rare event condition $\\|X\\|^2 > 60$, was calculated and found to be 0.617.\n\nBased on this information, calculate the numerical estimate for the probability $P$. Express your final answer in scientific notation, rounded to three significant figures.", "solution": "The problem asks for an importance-sampling-based estimate of the probability $P = P(\\sum_{i=1}^{10} Z_i^2 > 60)$, where $Z_i \\sim \\mathcal{N}(0,1)$ are independent random variates.\n\nThis probability can be written as an expectation:\n$$P = E_p\\left[\\mathbb{I}\\left(\\sum_{i=1}^{10} Z_i^2 > 60\\right)\\right]$$\nwhere $\\mathbb{I}(\\cdot)$ is the indicator function and $E_p[\\cdot]$ denotes the expectation with respect to the original probability distribution $p(z) = \\prod_{i=1}^{10} \\frac{1}{\\sqrt{2\\pi}} \\exp(-z_i^2/2)$.\n\nIn importance sampling, we re-write this expectation with respect to a proposal distribution $q(x)$:\n$$P = E_q\\left[\\mathbb{I}\\left(\\sum_{i=1}^{10} X_i^2 > 60\\right) \\frac{p(X)}{q(X)}\\right]$$\nwhere $X \\sim q(x)$. The term $w(X) = p(X)/q(X)$ is the importance weight. A Monte Carlo estimate of $P$ using $N$ samples $\\{X^{(j)}\\}_{j=1}^N$ drawn from $q(x)$ is given by:\n$$\\hat{P}_N = \\frac{1}{N} \\sum_{j=1}^N \\mathbb{I}\\left(\\|X^{(j)}\\|^2 > 60\\right) w(X^{(j)})$$\n\nThe first step is to determine the variance $\\sigma^2$ of the proposal distribution $q(x) = \\prod_{i=1}^{10} \\frac{1}{\\sqrt{2\\pi\\sigma^2}} \\exp(-x_i^2/(2\\sigma^2))$. The problem states that the heuristic is to set $E_q[\\|X\\|^2] = 60$.\n\nFor a single component $X_i \\sim \\mathcal{N}(0, \\sigma^2)$, its expectation is $E_q[X_i] = 0$ and its variance is $\\text{Var}_q(X_i) = \\sigma^2$. The expectation of its square is $E_q[X_i^2] = \\text{Var}_q(X_i) + (E_q[X_i])^2 = \\sigma^2 + 0^2 = \\sigma^2$.\n\nBy the linearity of expectation, the expectation of the sum of squares is:\n$$E_q[\\|X\\|^2] = E_q\\left[\\sum_{i=1}^{10} X_i^2\\right] = \\sum_{i=1}^{10} E_q[X_i^2] = 10 \\sigma^2$$\nApplying the heuristic, we set this equal to the threshold $c=60$:\n$$10 \\sigma^2 = 60 \\implies \\sigma^2 = 6$$\n\nThe second step is to find the expression for the importance weight function $w(x) = p(x)/q(x)$.\n$$p(x) = \\prod_{i=1}^{10} \\frac{1}{\\sqrt{2\\pi}} \\exp\\left(-\\frac{x_i^2}{2}\\right) = (2\\pi)^{-5} \\exp\\left(-\\frac{1}{2}\\sum_{i=1}^{10} x_i^2\\right) = (2\\pi)^{-5} \\exp\\left(-\\frac{\\|x\\|^2}{2}\\right)$$\n$$q(x) = \\prod_{i=1}^{10} \\frac{1}{\\sqrt{2\\pi\\sigma^2}} \\exp\\left(-\\frac{x_i^2}{2\\sigma^2}\\right) = (2\\pi\\sigma^2)^{-5} \\exp\\left(-\\frac{1}{2\\sigma^2}\\sum_{i=1}^{10} x_i^2\\right) = (2\\pi\\sigma^2)^{-5} \\exp\\left(-\\frac{\\|x\\|^2}{2\\sigma^2}\\right)$$\n\nThe ratio is:\n$$w(x) = \\frac{p(x)}{q(x)} = \\frac{(2\\pi)^{-5}}{(2\\pi\\sigma^2)^{-5}} \\frac{\\exp(-\\|x\\|^2/2)}{\\exp(-\\|x\\|^2/(2\\sigma^2))} = (\\sigma^2)^5 \\exp\\left(-\\frac{\\|x\\|^2}{2} + \\frac{\\|x\\|^2}{2\\sigma^2}\\right)$$\n$$w(x) = (\\sigma^2)^5 \\exp\\left(-\\frac{\\|x\\|^2}{2} \\left(1 - \\frac{1}{\\sigma^2}\\right)\\right)$$\nSubstituting $\\sigma^2 = 6$:\n$$w(x) = 6^5 \\exp\\left(-\\frac{\\|x\\|^2}{2} \\left(1 - \\frac{1}{6}\\right)\\right) = 7776 \\exp\\left(-\\frac{5}{12}\\|x\\|^2\\right)$$\n\nThe third step is to use the provided simulation data to compute the estimate. The estimator is:\n$$\\hat{P}_N = \\frac{1}{N} \\sum_{j=1}^N \\mathbb{I}(\\|X^{(j)}\\|^2 > 60) w(X^{(j)})$$\nThe sum is over all $N$ samples, but the indicator function $\\mathbb{I}(\\cdot)$ is zero for any sample that does not meet the condition $\\|X^{(j)}\\|^2 > 60$. Therefore, the sum is equivalent to summing the weights of only those samples that fall into the rare event region.\nThe problem states that this sum is given:\n$$\\sum_{j \\text{ s.t. } \\|X^{(j)}\\|^2 > 60} w(X^{(j)}) = 0.617$$\nThis is the value of the numerator in the estimator, summed over all samples:\n$$\\sum_{j=1}^N \\mathbb{I}(\\|X^{(j)}\\|^2 > 60) w(X^{(j)}) = 0.617$$\n\nThe total number of samples is $N = 5.0 \\times 10^5$. Plugging these values into the estimator formula:\n$$\\hat{P}_N = \\frac{0.617}{5.0 \\times 10^5}$$\n\nFinally, we calculate the numerical value:\n$$\\hat{P}_N = \\frac{0.617}{500000} = 0.000001234 = 1.234 \\times 10^{-6}$$\nRounding to three significant figures, we get $1.23 \\times 10^{-6}$.", "answer": "$$\\boxed{1.23 \\times 10^{-6}}$$", "id": "1376872"}]}