{"hands_on_practices": [{"introduction": "This first practice tackles a classic performance optimization problem: how to balance work in a system where workers depend on both their own processing power and a shared resource. We'll model a parallel data compression task where workers with different CPU speeds must read data from a storage system with a limited total I/O bandwidth. Your goal is to derive, from first principles, the optimal way to partition both the data and the I/O bandwidth to minimize the total completion time, a metric known as the makespan. This exercise provides a foundational, analytical look at achieving perfect load balance by ensuring all workers finish at the exact same time. [@problem_id:3155775]", "problem": "You are designing a batch compressor that splits a total data size $S$ (in megabytes) across $W$ parallel workers. Worker $j$ has a Central Processing Unit (CPU) compression rate $c_j$ (in megabytes per second). All workers read their data from a single shared storage system with total Input/Output (I/O) bandwidth $B$ (in megabytes per second) that can be arbitrarily split among workers as instantaneous bandwidth shares $u_j$ (in megabytes per second), subject to the constraint that the sum of the shares does not exceed the total bandwidth.\n\nStart from the following fundamental base:\n- For any serial stages of work, total time is additive. If a worker must read and then compute, the time is the sum of the read time and the compute time.\n- Time equals work divided by rate. If a worker processes a data amount $x$ at rate $r$, the time spent is $x/r$.\n\nModel each worker $j$ as processing a chunk of size $x_j$ (in megabytes). The worker reads at bandwidth share $u_j$ (in megabytes per second) and computes at CPU rate $c_j$ (in megabytes per second). There is no overlap between I/O and CPU; the stages are serial. Therefore, the completion time for worker $j$ is\n$$\nt_j = \\frac{x_j}{u_j} + \\frac{x_j}{c_j}.\n$$\nThe shared I/O bandwidth must satisfy\n$$\n\\sum_{j=1}^{W} u_j \\le B,\n$$\nand the total data constraint is\n$$\n\\sum_{j=1}^{W} x_j = S,\n$$\nwith $x_j \\ge 0$ and $u_j \\ge 0$ for all $j$.\n\nYour tasks are:\n- Derive, from the stated base and constraints only, the optimal assignments $\\{x_j\\}_{j=1}^W$ and $\\{u_j\\}_{j=1}^W$ that minimize the makespan, defined as the common completion time $t$ under the equalization constraint $t_j = t$ for all $j$ with $x_j > 0$.\n- Express the common completion time $t$ (in seconds) as a function of $S$, $B$, and $\\{c_j\\}$.\n- Provide explicit formulas for the optimal chunk sizes $x_j$ (in megabytes) and bandwidth shares $u_j$ (in megabytes per second) in terms of $S$, $B$, and $\\{c_j\\}$.\n\nImplement a program that computes, for each provided test case, a single list containing:\n- First, the common completion time $t$ in seconds.\n- Next, the chunk sizes $x_1, x_2, \\ldots, x_W$ in megabytes.\n- Finally, the bandwidth shares $u_1, u_2, \\ldots, u_W$ in megabytes per second.\n\nAll numeric outputs must be expressed in the units specified above and rounded to exactly $6$ decimal places. The program must aggregate the results for all test cases into a single line: a comma-separated list of per-test-case lists, each enclosed in square brackets, and the entire aggregate enclosed in square brackets. For example, the final output should look like\n$[$ $[\\,\\text{case1\\_values}\\,]$ $,$ $[\\,\\text{case2\\_values}\\,]$ $,$ $\\ldots$ $]$.\n\nTest suite:\n- Case $1$: $S = 1000$, $B = 400$, $\\{c_j\\} = [50, 100, 150]$.\n- Case $2$: $S = 800$, $B = 100000$, $\\{c_j\\} = [80, 40, 80]$.\n- Case $3$: $S = 600$, $B = 60$, $\\{c_j\\} = [500, 200, 100]$.\n- Case $4$: $S = 123$, $B = 500$, $\\{c_j\\} = [200]$.\n- Case $5$: $S = 100$, $B = 100$, $\\{c_j\\} = [1, 9]$.\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, where each test case is represented by a bracketed list in the order $[t, x_1, \\ldots, x_W, u_1, \\ldots, u_W]$, with all numbers rounded to exactly $6$ decimal places and no unit symbols included in the printed output.", "solution": "The problem is subjected to validation against the established criteria.\n\n### Step 1: Extract Givens\n- Total data size: $S$ (megabytes)\n- Number of parallel workers: $W$\n- CPU compression rate for worker $j$: $c_j$ (megabytes per second)\n- Total shared I/O bandwidth: $B$ (megabytes per second)\n- Bandwidth share for worker $j$: $u_j$ (megabytes per second)\n- Data chunk size for worker $j$: $x_j$ (megabytes)\n- Completion time for worker $j$: $t_j = \\frac{x_j}{u_j} + \\frac{x_j}{c_j}$\n- Bandwidth constraint: $\\sum_{j=1}^{W} u_j \\le B$\n- Total data constraint: $\\sum_{j=1}^{W} x_j = S$\n- Non-negativity constraints: $x_j \\ge 0$, $u_j \\ge 0$ for all $j=1, \\ldots, W$.\n- Optimization objective: Minimize the makespan, $t$.\n- Equalization constraint: $t_j = t$ for all workers $j$ with $x_j > 0$.\n\n### Step 2: Validate Using Extracted Givens\nThe problem is assessed as **valid**.\n- **Scientifically Grounded**: The model is based on fundamental principles of performance modeling in computational science, specifically relating work, rate, and time, and considering constraints on shared resources.\n- **Well-Posed**: The problem is a well-defined constrained optimization problem to minimize the makespan under an equalization constraint, which typically admits a unique and meaningful solution.\n- **Objective**: The problem is stated using precise, unambiguous mathematical and physical terms.\n- **Completeness and Consistency**: The problem provides all necessary data and constraints for a unique solution to be derived. The constraints are consistent with one another. To minimize time, it is implicit that the full bandwidth capacity will be utilized, thus $\\sum u_j = B$.\n- **Realism**: The physical quantities and their relationships are realistic simplifications used in performance analysis.\n\n### Step 3: Verdict and Action\nThe problem is valid. The derivation of the solution follows.\n\n### Derivation of Optimal Assignments and Completion Time\n\nThe objective is to minimize the common completion time, or makespan, $t$. The problem is formulated as finding the values of $\\{x_j\\}_{j=1}^W$ and $\\{u_j\\}_{j=1}^W$ that achieve this minimum $t$, subject to the given constraints.\n\nFor any worker $j$ assigned a non-zero chunk of data ($x_j > 0$), its completion time is given by:\n$$t_j = \\frac{x_j}{u_j} + \\frac{x_j}{c_j}$$\nThe equalization constraint requires that $t_j = t$ for all such workers.\n$$t = x_j \\left(\\frac{1}{u_j} + \\frac{1}{c_j}\\right)$$\nThis equation implies that for a given makespan $t$, the amount of data $x_j$ a worker can process depends on its assigned I/O bandwidth $u_j$ and its intrinsic CPU rate $c_j$.\n\nTo minimize $t$ for a fixed total amount of work $S$, the system must operate at its maximum possible aggregate throughput. The aggregate throughput is $\\frac{S}{t}$. Maximizing this throughput is equivalent to minimizing $t$.\n\nLet us express the total work $S$ in terms of $t$ and the individual assignments. First, we rearrange the time equation to solve for $x_j$:\n$$x_j = \\frac{t}{\\frac{1}{u_j} + \\frac{1}{c_j}} = t \\frac{u_j c_j}{u_j + c_j}$$\nSumming over all workers, we use the total data constraint $\\sum x_j = S$:\n$$S = \\sum_{j=1}^{W} x_j = \\sum_{j=1}^{W} t \\frac{u_j c_j}{u_j + c_j} = t \\sum_{j=1}^{W} \\frac{u_j c_j}{u_j + c_j}$$\nFrom this, the aggregate throughput is:\n$$\\frac{S}{t} = \\sum_{j=1}^{W} \\frac{u_j c_j}{u_j + c_j}$$\nOur optimization problem is to maximize this aggregate throughput by choosing the bandwidth shares $\\{u_j\\}$ subject to the constraints $\\sum_{j=1}^{W} u_j \\le B$ and $u_j \\ge 0$. To maximize throughput, the system should not be artificially bottlenecked by underutilizing the I/O resource. Therefore, the optimal solution must lie on the boundary of the constraint, where $\\sum_{j=1}^{W} u_j = B$.\n\nWe formulate this as a constrained optimization problem using the method of Lagrange multipliers. The Lagrangian function $\\mathcal{L}$ is:\n$$\\mathcal{L}(\\{u_j\\}, \\lambda) = \\sum_{j=1}^{W} \\frac{u_j c_j}{u_j + c_j} - \\lambda \\left(\\sum_{j=1}^{W} u_j - B\\right)$$\nTo find the optimal $\\{u_j\\}$, we set the partial derivative of $\\mathcal{L}$ with respect to each $u_k$ to zero:\n$$\\frac{\\partial \\mathcal{L}}{\\partial u_k} = \\frac{\\partial}{\\partial u_k}\\left(\\frac{u_k c_k}{u_k + c_k}\\right) - \\lambda = 0$$\nUsing the quotient rule for differentiation, we find:\n$$\\frac{\\partial}{\\partial u_k}\\left(\\frac{u_k c_k}{u_k + c_k}\\right) = \\frac{c_k(u_k + c_k) - u_k c_k(1)}{(u_k + c_k)^2} = \\frac{c_k^2}{(u_k + c_k)^2}$$\nThus, for each worker $k$, we have:\n$$\\frac{c_k^2}{(u_k + c_k)^2} = \\lambda \\implies \\frac{c_k}{u_k + c_k} = \\sqrt{\\lambda}$$\nWe solve for $u_k$:\n$$u_k + c_k = \\frac{c_k}{\\sqrt{\\lambda}} \\implies u_k = c_k \\left(\\frac{1}{\\sqrt{\\lambda}} - 1\\right)$$\nThis shows that $u_k$ is proportional to $c_k$. We determine the constant of proportionality (related to $\\lambda$) by applying the bandwidth constraint $\\sum u_k = B$:\n$$B = \\sum_{k=1}^{W} u_k = \\sum_{k=1}^{W} c_k \\left(\\frac{1}{\\sqrt{\\lambda}} - 1\\right) = \\left(\\frac{1}{\\sqrt{\\lambda}} - 1\\right) \\sum_{k=1}^{W} c_k$$\nLet $C_{\\text{total}} = \\sum_{k=1}^{W} c_k$. Then:\n$$B = \\left(\\frac{1}{\\sqrt{\\lambda}} - 1\\right) C_{\\text{total}} \\implies \\frac{1}{\\sqrt{\\lambda}} - 1 = \\frac{B}{C_{\\text{total}}}$$\nSubstituting this back into the expression for $u_k$:\n$$u_k = c_k \\left(\\frac{B}{C_{\\text{total}}}\\right) = B \\frac{c_k}{\\sum_{j=1}^W c_j}$$\nThis is the explicit formula for the optimal bandwidth shares $u_k$. It dictates that the total bandwidth $B$ should be allocated to workers in proportion to their CPU rates $c_k$.\n\nWith the optimal $u_j$ found, we can determine the minimal makespan $t$. First, we compute the term $\\frac{u_j c_j}{u_j + c_j}$:\n$$u_j + c_j = B \\frac{c_j}{C_{\\text{total}}} + c_j = c_j \\left(\\frac{B}{C_{\\text{total}}} + 1\\right) = c_j \\frac{B + C_{\\text{total}}}{C_{\\text{total}}}$$\n$$\\frac{u_j c_j}{u_j + c_j} = \\frac{\\left(B \\frac{c_j}{C_{\\text{total}}}\\right)c_j}{c_j \\frac{B + C_{\\text{total}}}{C_{\\text{total}}}} = \\frac{B c_j}{B + C_{\\text{total}}}$$\nThe aggregate throughput is the sum of these terms:\n$$\\frac{S}{t} = \\sum_{j=1}^{W} \\frac{B c_j}{B + C_{\\text{total}}} = \\frac{B}{B + C_{\\text{total}}} \\sum_{j=1}^{W} c_j = \\frac{B \\, C_{\\text{total}}}{B + C_{\\text{total}}}$$\nSolving for $t$, we obtain the formula for the minimal makespan:\n$$t = S \\frac{B + C_{\\text{total}}}{B \\, C_{\\text{total}}} = S \\left(\\frac{1}{B} + \\frac{1}{C_{\\text{total}}}\\right)$$\nThis elegant result shows the total time is determined by the total work $S$ divided by an effective system rate, which is the harmonic sum of the total I/O bandwidth $B$ and the total CPU rate $C_{\\text{total}}$.\n\nFinally, we find the optimal data chunk sizes $x_j$. Using the expression for $x_j$ derived earlier:\n$$x_j = t \\frac{u_j c_j}{u_j + c_j} = t \\left(\\frac{B c_j}{B + C_{\\text{total}}}\\right)$$\nSubstituting the formula for $t$:\n$$x_j = S \\left(\\frac{B + C_{\\text{total}}}{B \\, C_{\\text{total}}}\\right) \\left(\\frac{B c_j}{B + C_{\\text{total}}}\\right) = S \\frac{c_j}{C_{\\text{total}}} = S \\frac{c_j}{\\sum_{k=1}^W c_k}$$\nThis demonstrates that the total data $S$ should also be partitioned among workers in proportion to their CPU rates $c_j$.\n\n### Summary of Formulas\n1.  **Total CPU rate**: $C_{\\text{total}} = \\sum_{j=1}^{W} c_j$\n2.  **Optimal common completion time**: $t = S \\left(\\frac{1}{B} + \\frac{1}{C_{\\text{total}}}\\right)$\n3.  **Optimal chunk sizes**: $x_j = S \\frac{c_j}{C_{\\text{total}}}$\n4.  **Optimal bandwidth shares**: $u_j = B \\frac{c_j}{C_{\\text{total}}}$\n\nThese formulas will be implemented to solve the given test cases.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves for the optimal completion time, chunk sizes, and bandwidth shares\n    for a parallel processing problem.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        (1000, 400, [50, 100, 150]),     # Case 1\n        (800, 100000, [80, 40, 80]),    # Case 2\n        (600, 60, [500, 200, 100]),     # Case 3\n        (123, 500, [200]),              # Case 4\n        (100, 100, [1, 9]),             # Case 5\n    ]\n\n    all_results_str = []\n    \n    for S, B, c_j_list in test_cases:\n        # Convert inputs to numpy array for vectorized operations\n        c_j = np.array(c_j_list, dtype=float)\n        \n        # Calculate the total CPU rate\n        C_total = np.sum(c_j)\n\n        # Handle potential division by zero, though not expected from problem constraints.\n        if B == 0 or C_total == 0:\n            # This scenario corresponds to an infinite completion time.\n            # As the problem implies positive inputs, we proceed with calculation.\n            # A robust implementation might raise an error here.\n            continue\n\n        # Derived formula for the common completion time t\n        t = S * (1.0 / B + 1.0 / C_total)\n\n        # Derived formula for optimal chunk sizes x_j\n        x_j = S * (c_j / C_total)\n\n        # Derived formula for optimal bandwidth shares u_j\n        u_j = B * (c_j / C_total)\n\n        # Assemble the results for the current case in the specified order\n        case_result = [t] + x_j.tolist() + u_j.tolist()\n        \n        # Format each number to 6 decimal places and create the bracketed string\n        case_result_str = f\"[{','.join([f'{val:.6f}' for val in case_result])}]\"\n        all_results_str.append(case_result_str)\n\n    # Final print statement in the exact required format: a list of lists.\n    print(f\"[{','.join(all_results_str)}]\")\n\nsolve()\n```", "id": "3155775"}, {"introduction": "Moving from a deterministic model to a stochastic one, this practice explores one of the most fundamental choices in parallel system design: static versus dynamic load balancing. We will simulate two scenarios: a distributed-memory system where tasks are assigned to processors upfront, and a shared-memory system where workers pull tasks from a central queue as they become available. By generating tasks with random durations, you will empirically discover the crucial role that workload variability plays and quantify the trade-off between the overhead of communication in static schemes and the overhead of coordination in dynamic ones. [@problem_id:3155817]", "problem": "You must write a complete, runnable program that simulates and compares two load balancing strategies for parallel task execution while controlling the number of worker entities, the number of independent tasks, and the variance of task durations. The comparison is between a distributed memory system using static partitioning and a shared memory system using dynamic scheduling. The program must be self-contained, require no user input, and produce the specified output format in a single line.\n\nFundamental base and definitions to be used:\n- A distributed memory system assigns tasks to processors that do not share a centralized state; in static partitioning, each processor receives a predetermined subset of tasks. A shared memory system provides a global state accessible by all threads; in dynamic scheduling, a centralized queue provides one task at a time to the next available worker.\n- The total work is the sum of all task durations, written as $W = \\sum_{i=1}^{n} t_i$, where $n$ is the number of tasks and $t_i$ is the duration of task $i$. The makespan is the parallel completion time, written as $T = \\max_{j \\in \\{1,\\dots,p\\}} L_j$, where $p$ is the number of processors or threads and $L_j$ is the total load processed by worker $j$ including any overhead. Load balancing aims to minimize the variance of $L_j$ so that $T$ is near $W/p$.\n- Each task duration $t_i$ must be strictly nonnegative and measured in seconds. Any overhead for scheduling or communication must also be measured in seconds. Answer anything that involves physical time in seconds.\n\nSimulation specifications:\n- Tasks are independent and have durations $t_i$ drawn from a normal distribution with mean $\\mu$ seconds and standard deviation $\\sigma$ seconds, truncated at $0$ to enforce nonnegativity. Use a Random Number Generator (RNG) with a fixed seed per test case for reproducibility.\n- Distributed memory static partitioning: partition $n$ tasks into $p$ blocks using contiguous assignment. The first $r = n \\bmod p$ processors receive $b+1$ tasks, and the remaining $p-r$ processors receive $b$ tasks, where $b = \\left\\lfloor \\frac{n}{p} \\right\\rfloor$. The load on processor $j$ is $L^{\\text{dist}}_j = \\sum t_i + o_{\\text{dist}} \\cdot m_j$, where $m_j$ is the number of tasks assigned to processor $j$ and $o_{\\text{dist}}$ is the per-task overhead in seconds for distributed memory (e.g., communication or dispatch cost).\n- Shared memory dynamic scheduling: maintain a centralized queue of $n$ tasks. Each of $p$ workers repeatedly pulls the next available task when it becomes idle. The completion time of a worker increases by $t_i + o_{\\text{sh}}$ for each task it processes, where $o_{\\text{sh}}$ is the per-task overhead in seconds for shared memory (e.g., contention or scheduler cost). The makespan is the maximum completion time among all workers.\n\nYour program must implement both strategies and compute their makespans:\n- $T_{\\text{dist}} = \\max_j L^{\\text{dist}}_j$ for distributed static partitioning.\n- $T_{\\text{sh}}$ for shared dynamic scheduling from the event-driven assignment described above.\n\nRequired output:\n- For each test case, compute the ratio $R = \\frac{T_{\\text{dist}}}{T_{\\text{sh}}}$. This ratio is dimensionless (unitless). Larger $R$ indicates that shared memory dynamic scheduling is faster relative to distributed static partitioning for that case.\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (e.g., $[r_1,r_2,r_3]$), where each $r_k$ is the floating-point ratio for the $k$-th test case.\n\nTest suite:\nUse the following parameter sets. All time-related quantities must be handled in seconds. The RNG seed must be applied exactly as specified to make the results deterministic.\n- Case $1$ (happy path, low variance): $p=4$, $n=100$, $\\mu=1.0$ seconds, $\\sigma=0.1$ seconds, $o_{\\text{sh}}=0.0005$ seconds, $o_{\\text{dist}}=0.005$ seconds, seed $=42$.\n- Case $2$ (high variance): $p=8$, $n=1000$, $\\mu=0.5$ seconds, $\\sigma=0.6$ seconds, $o_{\\text{sh}}=0.0002$ seconds, $o_{\\text{dist}}=0.01$ seconds, seed $=123$.\n- Case $3$ (boundary: $p \\gg n$): $p=32$, $n=40$, $\\mu=1.0$ seconds, $\\sigma=0.5$ seconds, $o_{\\text{sh}}=0.0002$ seconds, $o_{\\text{dist}}=0.005$ seconds, seed $=98765$.\n- Case $4$ (moderate variance, different overheads): $p=16$, $n=1000$, $\\mu=0.2$ seconds, $\\sigma=0.2$ seconds, $o_{\\text{sh}}=0.0001$ seconds, $o_{\\text{dist}}=0.002$ seconds, seed $=2023$.\n- Case $5$ (edge: zero variance): $p=10$, $n=100$, $\\mu=1.0$ seconds, $\\sigma=0.0$ seconds, $o_{\\text{sh}}=0.0003$ seconds, $o_{\\text{dist}}=0.0003$ seconds, seed $=7$.\n\nProgram constraints:\n- Implement the simulation using any modern programming language logic, but the final submission must be Python code as specified in the final answer section.\n- Do not read input. Hard-code the test cases as listed.\n- Use the exact output format described: a single line with a list of floating-point ratios for the five cases, in order, enclosed in square brackets with comma separation.", "solution": "The problem requires a comparative analysis of two fundamental load balancing strategies in parallel computing: static partitioning for distributed memory systems and dynamic scheduling for shared memory systems. The objective is to simulate both strategies under various conditions and quantify their relative performance using the ratio of their makespans. A makespan is the total time elapsed from the start of a computation to the moment the last task is completed.\n\nThe foundation of this simulation is the generation of a workload, which consists of a set of $n$ independent tasks. The duration, $t_i$, of each task $i \\in \\{1, \\dots, n\\}$ is a random variable. As specified, task durations are drawn from a normal distribution with a given mean $\\mu$ and standard deviation $\\sigma$. Since time cannot be negative, any sampled value less than $0$ is truncated to $0$. This is mathematically expressed as $t_i = \\max(0, X_i)$, where each $X_i$ is an independent sample from the distribution $N(\\mu, \\sigma^2)$. To ensure the simulation is reproducible, the random number generator is initialized with a fixed seed for each test case.\n\nThe first strategy is static partitioning, characteristic of a distributed memory environment where inter-processor communication is costly, favoring a pre-computation allocation of work. The $n$ tasks are divided among $p$ processors using a contiguous block assignment. The number of tasks per processor is determined to be as balanced as possible: let $b = \\lfloor n/p \\rfloor$ be the base number of tasks and $r = n \\bmod p$ be the remainder. The first $r$ processors are assigned $m_j = b+1$ tasks each, and the subsequent $p-r$ processors are assigned $m_j = b$ tasks each. The total load on a processor $j$, denoted $L^{\\text{dist}}_j$, is the sum of the durations of its assigned tasks plus a total overhead cost. The overhead is modeled as a constant cost $o_{\\text{dist}}$ for each task assigned to the processor. Therefore, the load is calculated as $L^{\\text{dist}}_j = \\left(\\sum_{i \\in \\text{Tasks}_j} t_i\\right) + m_j \\cdot o_{\\text{dist}}$. Since all processors start simultaneously in this model, the overall makespan, $T_{\\text{dist}}$, is determined by the processor that takes the longest to finish its work: $T_{\\text{dist}} = \\max_{j \\in \\{1, \\dots, p\\}} L^{\\text{dist}}_j$.\n\nThe second strategy is dynamic scheduling via a central queue, typical of a shared memory environment where threads can efficiently access a common pool of work. This process is modeled as an event-driven simulation. We have $p$ workers, all initially idle at time $t=0$. The $n$ tasks are placed in a conceptual queue. Whenever a worker becomes free, it takes the next available task from the front of the queue. To implement this, we can maintain the finish time of each of the $p$ workers. A min-priority queue is an efficient data structure for this purpose, as it allows for quick retrieval of the worker that will become available earliest.\nThe simulation proceeds as follows:\n$1$. Initialize a min-priority queue with $p$ entries, each with value $0$, representing the initial availability time of each worker.\n$2$. For each of the $n$ tasks with duration $t_i$:\n    a. Extract the minimum time $t_{\\text{free}}$ from the priority queue. This represents the earliest time any worker becomes free.\n    b. Assign the task $t_i$ to this worker. The worker will now be occupied until a new finish time, calculated as $t_{\\text{new}} = t_{\\text{free}} + t_i + o_{\\text{sh}}$, where $o_{\\text{sh}}$ is the per-task overhead for accessing the shared queue.\n    c. Insert this new finish time $t_{\\text{new}}$ back into the priority queue.\n$3$. After all $n$ tasks have been assigned through this process, the values in the priority queue represent the final completion times of all tasks handled by each worker. The makespan for the dynamic scheduling strategy, $T_{\\text{sh}}$, is the maximum value in the priority queue, as this corresponds to the time the last task in the entire set is completed: $T_{\\text{sh}} = \\max(\\text{final worker finish times})$.\n\nFinally, to compare the effectiveness of the two strategies, we compute the dimensionless ratio $R = \\frac{T_{\\text{dist}}}{T_{\\text{sh}}}$. A ratio $R > 1$ signifies that dynamic scheduling was faster (i.e., had a smaller makespan) than static partitioning, indicating that its ability to adapt to variations in task durations outweighed its overhead. Conversely, a ratio $R < 1$ would suggest static partitioning was more efficient, which might occur if task durations are uniform and the distributed overhead $o_{\\text{dist}}$ is smaller than the shared overhead $o_{\\text{sh}}$. A ratio $R \\approx 1$ implies comparable performance. This ratio serves as the final output for each test case.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nimport heapq\n\ndef solve():\n    \"\"\"\n    Simulates and compares distributed static partitioning and shared dynamic scheduling\n    for parallel task execution across a suite of test cases.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    # Each tuple is (p, n, mu, sigma, o_sh, o_dist, seed)\n    test_cases = [\n        (4, 100, 1.0, 0.1, 0.0005, 0.005, 42),\n        (8, 1000, 0.5, 0.6, 0.0002, 0.01, 123),\n        (32, 40, 1.0, 0.5, 0.0002, 0.005, 98765),\n        (16, 1000, 0.2, 0.2, 0.0001, 0.002, 2023),\n        (10, 100, 1.0, 0.0, 0.0003, 0.0003, 7)\n    ]\n\n    results = []\n    for p, n, mu, sigma, o_sh, o_dist, seed in test_cases:\n        # Step 1: Generate task durations using a seeded RNG\n        # for reproducibility.\n        rng = np.random.default_rng(seed)\n        tasks = rng.normal(loc=mu, scale=sigma, size=n)\n        # Enforce non-negativity by truncating at 0.\n        tasks = np.maximum(0, tasks)\n\n        # Step 2: Simulate distributed memory static partitioning.\n        T_dist = 0.0\n        if p > 0 and n > 0:\n            b = n // p  # Base number of tasks per processor\n            r = n % p   # Remainder, for processors getting an extra task\n            \n            processor_loads_dist = np.zeros(p)\n            task_idx = 0\n            for j in range(p):\n                num_tasks_for_proc = b + 1 if j < r else b\n                if num_tasks_for_proc > 0:\n                    end_idx = task_idx + num_tasks_for_proc\n                    assigned_tasks = tasks[task_idx:end_idx]\n                    work_duration = np.sum(assigned_tasks)\n                    overhead = num_tasks_for_proc * o_dist\n                    processor_loads_dist[j] = work_duration + overhead\n                    task_idx = end_idx\n            \n            T_dist = np.max(processor_loads_dist)\n\n        # Step 3: Simulate shared memory dynamic scheduling.\n        T_sh = 0.0\n        if p > 0 and n > 0:\n            # A min-heap tracks the time each worker becomes free.\n            worker_finish_times = [0.0] * p\n            heapq.heapify(worker_finish_times)\n            \n            for task_duration in tasks:\n                # Get the worker that finishes earliest.\n                earliest_finish_time = heapq.heappop(worker_finish_times)\n                \n                # Assign the current task to this worker and update its finish time.\n                new_finish_time = earliest_finish_time + task_duration + o_sh\n                heapq.heappush(worker_finish_times, new_finish_time)\n            \n            # The makespan is the time the last worker finishes.\n            T_sh = max(worker_finish_times)\n\n        # Step 4: Compute the ratio.\n        ratio = 0.0\n        if T_sh > 0:\n            ratio = T_dist / T_sh\n        elif T_dist > 0:\n            # This case (T_sh=0, T_dist>0) is unlikely but handle for robustness.\n            ratio = float('inf')\n        else:\n            # If both are 0 (e.g., n=0), their performance is identical.\n            ratio = 1.0\n\n        results.append(ratio)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "3155817"}, {"introduction": "Our final practice introduces the complexity of multi-objective optimization, a common challenge in real-world scheduling. Finishing a set of jobs quickly (minimizing makespan, $T$) is often just one goal; ensuring individual jobs finish by their deadlines (minimizing maximum lateness, $L_{\\max}$) can be equally important. This exercise asks you to implement and compare two different scheduling policies for a set of tasks with both processing times and deadlines. By contrasting a heuristic that prioritizes long tasks to balance load against one that prioritizes urgent tasks to meet deadlines, you will gain hands-on experience with the inherent trade-offs between system throughput and task-level quality of service. [@problem_id:3155741]", "problem": "You are given a set of independent tasks to be run on a pool of identical cores under non-preemptive execution. Each task $i$ has a strictly positive processing time $p_i$ and a strict deadline $d_i$. All tasks are available at time $0$ and there are no precedence constraints. There are $m$ identical cores (machines), each capable of processing at most one task at a time, and each task must run to completion once it starts on a core.\n\nFundamental definitions are as follows. Let $C_i$ denote the completion time of task $i$ under a particular schedule. The lateness of task $i$ is defined by $L_i = C_i - d_i$. The maximum lateness is $L_{\\max} = \\max_i L_i$. The makespan is $T$, defined as the maximum completion time on any core, equivalently $T = \\max_j \\left(\\sum_{i \\in S_j} p_i\\right)$ where $S_j$ is the sequence of tasks executed on core $j$ and tasks on each core are executed according to the order they are scheduled. The goal of this exercise is to examine the trade-off between minimizing $L_{\\max}$ and balancing load across cores (which tends to minimize $T$), using two contrasting scheduling policies derived from first principles.\n\nYou must implement two scheduling policies:\n\n- Policy A (Earliest Due Date list scheduling): Earliest Due Date (EDD) is a single-machine ordering rule that minimizes maximum lateness. To extend this idea to parallel cores, consider the following non-preemptive, deterministic list scheduling: sort tasks globally by increasing $d_i$. Then, iteratively assign each task to the core with the smallest current total assigned processing time (ties broken by the lowest core index). After assignment, for each core, execute its assigned tasks in increasing $d_i$ order. Under this policy, compute $L_{\\max}$ and $T$.\n\n- Policy B (Longest Processing Time load balancing with per-core EDD): For load balancing to reduce $T$, a classical approach is to assign tasks by decreasing $p_i$ to the least-loaded core (ties broken by the lowest core index). After assignment, for each core, execute its assigned tasks in increasing $d_i$ order. Under this policy, compute $L_{\\max}$ and $T$.\n\nAll cores are identical, all tasks are independent, and processing times and deadlines are integers measured in abstract time units. The schedule is non-preemptive, meaning once a task starts, it runs until completion. All tasks have release time $0$.\n\nYour program must implement both policies and, for each test case below, output the pair of metrics for each policy as a list $[\\,L_{\\max}^{A}, T^{A}, L_{\\max}^{B}, T^{B}\\,]$, where superscripts $A$ and $B$ denote Policy A and Policy B, respectively. For each test case, $L_{\\max}$ and $T$ must be reported as integers.\n\nTest suite (five cases designed for coverage):\n- Case $1$: $m=2$, $p=[\\,3,2,4,1,6,5\\,]$, $d=[\\,7,5,8,3,10,9\\,]$.\n- Case $2$: $m=1$, $p=[\\,2,2,2,2\\,]$, $d=[\\,1,3,5,7\\,]$.\n- Case $3$: $m=5$, $p=[\\,5,1,2,3\\,]$, $d=[\\,2,3,4,10\\,]$.\n- Case $4$: $m=3$, $p=[\\,4,4,4,4,4\\,]$, $d=[\\,1,1,1,10,10\\,]$.\n- Case $5$: $m=3$, $p=[\\,1,2,3,4,5,6\\,]$, $d=[\\,10,10,10,10,10,10\\,]$.\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, where the entry for each test case is the list $[\\,L_{\\max}^{A},T^{A},L_{\\max}^{B},T^{B}\\,]$. For example, the output format must be $[\\,[\\,x_1,y_1,u_1,v_1\\,],[\\,x_2,y_2,u_2,v_2\\,],\\dots\\,]$ with no spaces.\n\nThe final output must be entirely numerical and expressed in integer time units. Angle units and percentages do not apply in this problem.", "solution": "The problem presented requires the implementation and evaluation of two distinct scheduling policies for a set of independent tasks on multiple identical cores. This is a classic problem in scheduling theory, a branch of operations research and computer science, with direct applications in parallel and distributed computing. The core of the problem is to analyze the trade-off between two key performance metrics: a deadline-oriented metric, the maximum lateness ($L_{\\max}$), and a throughput-oriented metric, the makespan ($T$).\n\nThe problem is structured as a $P||(\\text{mixed-objectives})$ scheduling problem in a non-preemptive environment with all tasks available at time $t=0$. Given $n$ tasks, each with processing time $p_i > 0$ and deadline $d_i$, and $m$ identical cores, we must determine a schedule that maps tasks to cores and specifies their execution order.\n\nThe general methodology for both policies is a two-stage greedy heuristic:\n1.  **Assignment Stage**: Tasks are first sorted according to a global priority rule. Then,tasks are iteratively assigned to a core. This specific heuristic is a form of \"list scheduling\", where the \"list\" is the sorted sequence of tasks. For each task in the list, it is assigned to the core that is currently \"least loaded,\" i.e., the core with the minimum cumulative processing time of tasks already assigned to it. This greedy choice aims to balance the load across cores. Ties in core load are broken by selecting the core with the lowest index.\n2.  **Execution Stage**: After all tasks have been assigned, a local execution schedule is determined for each core. Since all tasks are available at time $t=0$ and there are no precedence constraints, the tasks on a given core can be executed back-to-back without idle time. The problem specifies that the execution order on each core must follow the Earliest Due Date (EDD) rule, where tasks are sequenced in increasing order of their deadlines, $d_i$. This rule is known to be optimal for minimizing $L_{\\max}$ on a single machine.\n\nFrom a resulting schedule, the two metrics are calculated as follows:\n-   The **makespan**, $T$, is the time at which the last task finishes across all cores. Given that there is no idle time on any core until the tasks assigned to it are exhausted, this is equivalent to the total processing time on the busiest core. Thus, $T = \\max_{j=1..m} \\sum_{i \\in S_j} p_i$, where $S_j$ is the set of tasks assigned to core $j$.\n-   The **maximum lateness**, $L_{\\max}$, is defined as $L_{\\max} = \\max_i (C_i - d_i)$, where $C_i$ is the completion time of task $i$. The completion time $C_i$ for a task is the sum of its own processing time and the processing times of all tasks that precede it in the execution sequence on its assigned core.\n\nThe two policies differ only in the global sorting rule used in the Assignment Stage:\n\n**Policy A (EDD-based list scheduling):**\nThis policy prioritizes tasks with more urgent deadlines at the global level.\n-   **Assignment Sorting Rule**: Tasks are sorted in increasing order of their deadlines ($d_i$). This extends the single-machine EDD logic to the multi-machine assignment phase.\n-   **Execution Rule**: As per the problem, tasks on each core are executed in increasing order of $d_i$.\n\n**Policy B (LPT-based load balancing with per-core EDD):**\nThis policy prioritizes tasks that are computationally expensive, a heuristic known as Longest Processing Time (LPT) first, which is a well-known approximation algorithm for minimizing makespan ($P||C_{\\max}$).\n-   **Assignment Sorting Rule**: Tasks are sorted in decreasing order of their processing times ($p_i$).\n-   **Execution Rule**: As per the problem, tasks on each core are executed in increasing order of $d_i$.\n\nBy implementing and comparing these two policies, we can observe the fundamental trade-off: Policy A is designed with deadlines in mind from the start, potentially at the cost of a balanced load. Policy B is designed for load balancing, which minimizes makespan, but the final lateness depends on how the per-core EDD sequencing interacts with the task assignments.\n\nLet's illustrate the procedure with **Test Case 1**: $m=2$, $p=[\\,3,2,4,1,6,5\\,]$, $d=[\\,7,5,8,3,10,9\\,]$.\nWe have $6$ tasks, indexed $0$ to $5$: $T_0(p=3,d=7)$, $T_1(p=2,d=5)$, $T_2(p=4,d=8)$, $T_3(p=1,d=3)$, $T_4(p=6,d=10)$, $T_5(p=5,d=9)$.\n\n**Policy A Analysis (EDD-based)**\n1.  **Assignment**: Sort tasks by increasing $d_i$: $T_3(d=3)$, $T_1(d=5)$, $T_0(d=7)$, $T_2(d=8)$, $T_5(d=9)$, $T_4(d=10)$.\n    -   `Core loads`: $[\\,0, 0\\,]$.\n    -   Assign $T_3(p=1)$: to Core $0$. Loads: $[\\,1, 0\\,]$.\n    -   Assign $T_1(p=2)$: to Core $1$. Loads: $[\\,1, 2\\,]$.\n    -   Assign $T_0(p=3)$: to Core $0$. Loads: $[\\,4, 2\\,]$.\n    -   Assign $T_2(p=4)$: to Core $1$. Loads: $[\\,4, 6\\,]$.\n    -   Assign $T_5(p=5)$: to Core $0$. Loads: $[\\,9, 6\\,]$.\n    -   Assign $T_4(p=6)$: to Core $1$. Loads: $[\\,9, 12\\,]$.\n    -   Final assignments: Core $0$: $\\{T_3, T_0, T_5\\}$. Core $1$: $\\{T_1, T_2, T_4\\}$.\n2.  **Execution and Metrics**:\n    -   $T^A = \\max(9, 12) = 12$.\n    -   Core $0$ tasks $\\{T_3(1,3), T_0(3,7), T_5(5,9)\\}$. EDD execution order: $T_3 \\rightarrow T_0 \\rightarrow T_5$.\n        -   $C_3 = 1$. $L_3 = 1-3 = -2$.\n        -   $C_0 = 1+3 = 4$. $L_0 = 4-7 = -3$.\n        -   $C_5 = 4+5 = 9$. $L_5 = 9-9 = 0$.\n    -   Core $1$ tasks $\\{T_1(2,5), T_2(4,8), T_4(6,10)\\}$. EDD execution order: $T_1 \\rightarrow T_2 \\rightarrow T_4$.\n        -   $C_1 = 2$. $L_1 = 2-5 = -3$.\n        -   $C_2 = 2+4 = 6$. $L_2 = 6-8 = -2$.\n        -   $C_4 = 6+6 = 12$. $L_4 = 12-10 = 2$.\n    -   $L_{\\max}^A = \\max(-2, -3, 0, -3, -2, 2) = 2$.\n    -   Result for Policy A: $L_{\\max}^A = 2, T^A = 12$.\n\n**Policy B Analysis (LPT-based)**\n1.  **Assignment**: Sort tasks by decreasing $p_i$: $T_4(p=6)$, $T_5(p=5)$, $T_2(p=4)$, $T_0(p=3)$, $T_1(p=2)$, $T_3(p=1)$.\n    -   `Core loads`: $[\\,0, 0\\,]$.\n    -   Assign $T_4(p=6)$: to Core $0$. Loads: $[\\,6, 0\\,]$.\n    -   Assign $T_5(p=5)$: to Core $1$. Loads: $[\\,6, 5\\,]$.\n    -   Assign $T_2(p=4)$: to Core $1$. Loads: $[\\,6, 9\\,]$.\n    -   Assign $T_0(p=3)$: to Core $0$. Loads: $[\\,9, 9\\,]$.\n    -   Assign $T_1(p=2)$: to Core $0$ (tie-break). Loads: $[\\,11, 9\\,]$.\n    -   Assign $T_3(p=1)$: to Core $1$. Loads: $[\\,11, 10\\,]$.\n    -   Final assignments: Core $0$: $\\{T_4, T_0, T_1\\}$. Core $1$: $\\{T_5, T_2, T_3\\}$.\n2.  **Execution and Metrics**:\n    -   $T^B = \\max(11, 10) = 11$.\n    -   Core $0$ tasks $\\{T_4(6,10), T_0(3,7), T_1(2,5)\\}$. EDD execution order: $T_1 \\rightarrow T_0 \\rightarrow T_4$.\n        -   $C_1 = 2$. $L_1 = 2-5 = -3$.\n        -   $C_0 = 2+3 = 5$. $L_0 = 5-7 = -2$.\n        -   $C_4 = 5+6 = 11$. $L_4 = 11-10 = 1$.\n    -   Core $1$ tasks $\\{T_5(5,9), T_2(4,8), T_3(1,3)\\}$. EDD execution order: $T_3 \\rightarrow T_2 \\rightarrow T_5$.\n        -   $C_3 = 1$. $L_3 = 1-3 = -2$.\n        -   $C_2 = 1+4 = 5$. $L_2 = 5-8 = -3$.\n        -   $C_5 = 5+5 = 10$. $L_5 = 10-9 = 1$.\n    -   $L_{\\max}^B = \\max(-3, -2, 1, -2, -3, 1) = 1$.\n    -   Result for Policy B: $L_{\\max}^B = 1, T^B = 11$.\n\nThe final result for Test Case 1 is the list $[\\,2, 12, 1, 11\\,]$. This demonstrates that for this instance, Policy B (LPT-based) achieves both a better makespan and a lower maximum lateness. The implementation will systematically apply this logic to all test cases.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef run_schedule_policy(m, p, d, policy_type):\n    \"\"\"\n    Implements a scheduling policy and calculates L_max and T.\n\n    Args:\n        m (int): Number of cores.\n        p (list): List of processing times.\n        d (list): List of deadlines.\n        policy_type (str): 'A' for EDD-based, 'B' for LPT-based.\n\n    Returns:\n        tuple: (L_max, T) as integers.\n    \"\"\"\n    num_tasks = len(p)\n    if num_tasks == 0:\n        return 0, 0\n\n    # 1. Create task representations (dictionaries are used for clarity)\n    tasks = [{'p': p[i], 'd': d[i], 'id': i} for i in range(num_tasks)]\n\n    # 2. Global sort based on the policy\n    if policy_type == 'A':\n        # Policy A: Sort by increasing d_i.\n        # Python's sort is stable, which is a good default for tie-breaking.\n        tasks.sort(key=lambda t: t['d'])\n    elif policy_type == 'B':\n        # Policy B: Sort by decreasing p_i.\n        tasks.sort(key=lambda t: t['p'], reverse=True)\n\n    # 3. Assign tasks to cores using list scheduling heuristic\n    core_loads = np.zeros(m, dtype=int)\n    core_assignments = [[] for _ in range(m)]\n    for task in tasks:\n        # Assign task to the core with the minimum current load.\n        # np.argmin breaks ties by choosing the lowest index, as required.\n        target_core_idx = np.argmin(core_loads)\n        core_assignments[target_core_idx].append(task)\n        core_loads[target_core_idx] += task['p']\n\n    # 4. Calculate metrics (T and L_max)\n    # The makespan (T) is the maximum total load on any core.\n    T = int(np.max(core_loads)) if m > 0 else 0\n\n    max_lateness = -float('inf')\n    \n    # Iterate through each core to determine execution order and completion times\n    for core_task_list in core_assignments:\n        if not core_task_list:\n            continue\n\n        # For execution, sort tasks assigned to this core by increasing d_i.\n        # A secondary sort key (original id) is used for deterministic tie-breaking.\n        core_task_list.sort(key=lambda t: (t['d'], t['id']))\n        \n        current_core_time = 0\n        for task in core_task_list:\n            completion_time = current_core_time + task['p']\n            lateness = completion_time - task['d']\n            if lateness > max_lateness:\n                max_lateness = lateness\n            current_core_time = completion_time\n\n    L_max = int(max_lateness)\n    return L_max, T\n\ndef solve():\n    \"\"\"\n    Runs the scheduling simulation for all test cases and prints the results.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        (2, [3, 2, 4, 1, 6, 5], [7, 5, 8, 3, 10, 9]),\n        (1, [2, 2, 2, 2], [1, 3, 5, 7]),\n        (5, [5, 1, 2, 3], [2, 3, 4, 10]),\n        (3, [4, 4, 4, 4, 4], [1, 1, 1, 10, 10]),\n        (3, [1, 2, 3, 4, 5, 6], [10, 10, 10, 10, 10, 10]),\n    ]\n\n    all_results = []\n    for m, p, d in test_cases:\n        L_max_A, T_A = run_schedule_policy(m, p, d, 'A')\n        L_max_B, T_B = run_schedule_policy(m, p, d, 'B')\n        \n        # Format the result for this case as a string with no spaces\n        case_result_str = f\"[{L_max_A},{T_A},{L_max_B},{T_B}]\"\n        all_results.append(case_result_str)\n\n    # Final print statement in the exact required format: [[...],[...]] with no spaces.\n    print(f\"[{','.join(all_results)}]\")\n\n# Execute the main function.\nsolve()\n```", "id": "3155741"}]}