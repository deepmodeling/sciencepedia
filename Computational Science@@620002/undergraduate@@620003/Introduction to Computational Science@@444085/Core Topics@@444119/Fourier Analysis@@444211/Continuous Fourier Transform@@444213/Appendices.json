{"hands_on_practices": [{"introduction": "The theoretical definition of the Continuous Fourier Transform involves an integral over an infinite domain, a process that must be adapted for computers. This first practice guides you through the fundamental step of approximating this integral using a discrete sum, revealing its direct connection to the widely used Discrete Fourier Transform (DFT). You will also confront a critical artifact of this process—spectral leakage—and implement a standard technique known as windowing to mitigate it, a core skill for practical signal analysis. [@problem_id:3112450]", "problem": "You are to implement a complete computational pipeline, grounded in first principles, to approximate the continuous-time Fourier transform of a piecewise-defined function with jump discontinuities, diagnose spectral leakage, and mitigate it with boundary smoothing. Use the fundamental definition of the Continuous-Time Fourier Transform (CTFT) and construct the algorithmic steps from this base. Whenever angles are used, they must be in radians. No physical units are involved.\n\nStart from the core definition of the Continuous-Time Fourier Transform (CTFT): given a real-valued function $f(x)$ with finite support on $[0,1]$, its CTFT is the map $\\omega \\mapsto F(\\omega)$ where $F(\\omega)$ is defined via an integral against the complex exponential. You must approximate $F(\\omega)$ by a Riemann sum constructed on a uniform grid over the domain of $f$, and you must diagnose spectral leakage via a quantitative tail-energy metric. Then, propose and implement a boundary smoothing approach that enforces continuity at the domain edges and empirically reduces spectral leakage.\n\nYour program must perform the following tasks using purely mathematical and algorithmic logic:\n\n- Construct a uniform grid on $[0,1]$ of $N$ points, with $N = 4096$. Denote the grid by $x_n = n \\Delta x$ for $n \\in \\{0,1,\\ldots,N-1\\}$, where $\\Delta x = 1/N$.\n- For each test case function $f$ defined on $[0,1]$ by piecewise-constant segments with jump discontinuities, sample $f$ on the grid.\n- Approximate the CTFT at discrete angular frequencies $\\omega_k = \\frac{2\\pi k}{T}$ for $k \\in \\{-\\lfloor N/2 \\rfloor, \\ldots, \\lfloor N/2 \\rfloor - 1\\}$ with $T = 1$, by a Riemann sum that is equivalent to a Discrete Fourier Transform (DFT) scaled by $\\Delta x$. Define Discrete Fourier Transform (DFT) on the uniformly sampled sequence and use it to compute approximations $\\hat{F}(\\omega_k)$ both without smoothing and with boundary smoothing.\n- Define spectral leakage for an approximation $\\hat{F}$ by the tail-energy fraction outside a specified angular frequency threshold. Let the tail threshold be $\\omega_{\\text{tail}} = 200\\pi$. The leakage metric is the ratio of energy beyond $|\\omega| > \\omega_{\\text{tail}}$ to the total energy across all sampled frequencies. Energies are computed from the squared magnitudes $|\\hat{F}(\\omega_k)|^2$; any uniform frequency-weight factor cancels in the fraction.\n- Implement a boundary smoothing that forces continuity at $x=0$ and $x=1$ by multiplying the sampled $f$ by a smooth taper function that is zero at the endpoints and strictly positive in the interior. Use a Hann taper window $w(n)$ on the discrete grid, defined so that $w(0) = 0$ and $w(N-1) = 0$, and $w(n)$ is continuous in $n$ when viewed as a function of $x_n$. Compute the CTFT approximation for both the unsmoothed case (rectangular window equal to $1$ on the entire grid) and the smoothed case (Hann taper), then compute their respective leakage fractions.\n- Report the improvement due to boundary smoothing for each test case as the ratio of the unsmoothed leakage fraction to the smoothed leakage fraction. A ratio greater than $1$ indicates that smoothing reduced leakage.\n\nTest suite specification:\n\nLet $T = 1$ and $N = 4096$. Define three piecewise-constant test functions on $[0,1]$ using the following segment lists, where each segment is $[a,b)$ except the last which is $[a,b]$, and on each segment the function equals the given constant value.\n\n- Case $1$ (boundary discontinuity present): $f(x) = 2$ on $[0,0.4)$, $f(x) = -1$ on $[0.4,0.7)$, and $f(x) = 0$ on $[0.7,1]$.\n- Case $2$ (boundary continuity at endpoints): $f(x) = 0$ on $[0,0.3)$, $f(x) = 3$ on $[0.3,0.6)$, and $f(x) = 0$ on $[0.6,1]$.\n- Case $3$ (narrow interior jump, endpoints are zero): $f(x) = 0$ on $[0,0.49)$, $f(x) = 5$ on $[0.49,0.51)$, and $f(x) = 0$ on $[0.51,1]$.\n\nFor each case, compute:\n\n- The leakage fraction for the unsmoothed rectangular window approximation, denoted $\\lambda_{\\text{rect}}$.\n- The leakage fraction for the Hann-tapered approximation, denoted $\\lambda_{\\text{hann}}$.\n- The leakage reduction ratio $r = \\lambda_{\\text{rect}} / \\lambda_{\\text{hann}}$.\n\nFinal output format requirement:\n\nYour program should produce a single line of output containing the leakage reduction ratios for the three test cases as a comma-separated list enclosed in square brackets, with each float rounded to $6$ decimal places, for example $[r_1,r_2,r_3]$. Angles must be in radians and the angular frequency threshold is $\\omega_{\\text{tail}} = 200\\pi$.", "solution": "We begin from the fundamental definition of the Continuous-Time Fourier Transform (CTFT). For a real-valued function $f(x)$ supported on $[0,1]$, the CTFT is the function $F(\\omega)$ defined by the integral\n$$\nF(\\omega) = \\int_{-\\infty}^{\\infty} f(x) e^{-i\\omega x} \\, dx,\n$$\nwhich reduces to\n$$\nF(\\omega) = \\int_{0}^{1} f(x) e^{-i\\omega x} \\, dx\n$$\nwhen $f(x)$ is zero outside $[0,1]$. This is the fundamental base: the CTFT is defined by integration against the complex exponential kernel $e^{-i\\omega x}$, a well-tested and widely accepted definition.\n\nTo implement a computational pipeline that is principled and aligned with this definition, we follow a Riemann-sum approximation. Let the domain be sampled on a uniform grid $x_n = n \\Delta x$, $n \\in \\{0,1,\\ldots,N-1\\}$, where $\\Delta x = 1/N$. For a discrete set of angular frequencies $\\omega_k = \\frac{2\\pi k}{T}$ with $T = 1$ and $k \\in \\{-\\lfloor N/2 \\rfloor, \\ldots, \\lfloor N/2 \\rfloor - 1\\}$, a Riemann-sum approximation of the CTFT is given by\n$$\n\\hat{F}(\\omega_k) \\approx \\Delta x \\sum_{n=0}^{N-1} f(x_n) e^{-i \\omega_k x_n}.\n$$\nThis sum is exactly a Discrete Fourier Transform (DFT) of the sampled sequence $f(x_n)$ at the frequencies $\\omega_k$ when scaled by $\\Delta x$, because the exponential $e^{-i \\omega_k x_n}$ becomes $e^{-i 2\\pi k n / N}$ for $T=1$ and $x_n = n/N$. Therefore, we can compute $\\hat{F}(\\omega_k)$ via a DFT (fast implementation via the Fast Fourier Transform) multiplied by $\\Delta x$.\n\nSpectral leakage is diagnosed by measuring how energy in the spectral estimate $\\hat{F}(\\omega)$ spreads outside a chosen frequency band. While perfect band-limiting is rare for piecewise-constant functions with jumps (which are known to have high-frequency content decaying like $1/\\omega$), a consistent quantitative metric can be defined via tail energy. For any approximation $\\hat{F}$, define the leakage fraction\n$$\n\\lambda = \\frac{\\sum_{k : |\\omega_k| > \\omega_{\\text{tail}}} |\\hat{F}(\\omega_k)|^2}{\\sum_{k} |\\hat{F}(\\omega_k)|^2},\n$$\nwhere $\\omega_{\\text{tail}}$ is a fixed angular frequency threshold and all sums are taken over the discrete frequency grid. Both numerator and denominator share any uniform bin width factor, so the fraction is invariant under such scaling. This metric quantifies the proportion of energy in high-frequency tails.\n\nBoundary discontinuities are a known source of spectral leakage in DFT-based approximations: the implicit periodic extension of the sampled function can induce a jump at $x=0$ and $x=1$ when the endpoint values differ, exciting high-frequency components. A principled mitigation is boundary smoothing by tapering, which enforces continuity (and, for sufficiently smooth tapers, differentiability) at the boundaries. A Hann taper is defined on the discrete grid by\n$$\nw(n) = \\tfrac{1}{2} \\left( 1 - \\cos\\left(\\frac{2\\pi n}{N-1}\\right) \\right),\n$$\nwhich satisfies $w(0) = 0$ and $w(N-1) = 0$, and smoothly attains $1$ near the center. Applying this taper to $f$ yields $f_{\\text{hann}}(x_n) = f(x_n) w(n)$, whose implicit periodic extension is continuous at the endpoints and thus reduces leakage. In frequency, multiplication by the taper corresponds to a convolution $F * W$ of the original CTFT with the taper’s CTFT, smoothing sharp spectral features and redistributing energy away from the endpoints of the frequency grid in a controlled manner.\n\nAlgorithmic steps:\n\n1. Construct the grid: set $N = 4096$ and $\\Delta x = 1/N$, with $x_n = n \\Delta x$.\n2. For each piecewise-defined test case, sample $f(x_n)$ by selecting the constant value for each segment according to whether $x_n \\in [a,b)$, with the last segment defined as $[a,b]$ to include $x=1$.\n3. Define two window functions: the rectangular window $w_{\\text{rect}}(n) = 1$ and the Hann window $w_{\\text{hann}}(n)$ given as above.\n4. Form two sequences for each case: $f_{\\text{rect}}(x_n) = f(x_n) w_{\\text{rect}}(n)$ and $f_{\\text{hann}}(x_n) = f(x_n) w_{\\text{hann}}(n)$.\n5. Compute their DFTs $\\mathcal{F}_{\\text{rect}}[k]$ and $\\mathcal{F}_{\\text{hann}}[k]$ and scale by $\\Delta x$ to obtain CTFT approximations $\\hat{F}_{\\text{rect}}(\\omega_k)$ and $\\hat{F}_{\\text{hann}}(\\omega_k)$; the discrete angular frequencies are $\\omega_k = \\frac{2\\pi k}{T}$ with $T=1$ and $k$ determined by the DFT frequency layout.\n6. Compute leakage fractions $\\lambda_{\\text{rect}}$ and $\\lambda_{\\text{hann}}$ by summing $|\\hat{F}(\\omega_k)|^2$ beyond $\\omega_{\\text{tail}} = 200\\pi$ and dividing by the total energy sum across all $k$.\n7. Compute the leakage reduction ratio $r = \\lambda_{\\text{rect}} / \\lambda_{\\text{hann}}$ for each case; $r > 1$ indicates that boundary smoothing reduced spectral leakage.\n\nTest suite cases are:\n- Case $1$: $f(x) = 2$ on $[0,0.4)$, $f(x) = -1$ on $[0.4,0.7)$, $f(x) = 0$ on $[0.7,1]$; this has a boundary discontinuity at $x=0$ to $x=1$.\n- Case $2$: $f(x) = 0$ on $[0,0.3)$, $f(x) = 3$ on $[0.3,0.6)$, $f(x) = 0$ on $[0.6,1]$; this is continuous at the endpoints.\n- Case $3$: $f(x) = 0$ on $[0,0.49)$, $f(x) = 5$ on $[0.49,0.51)$, $f(x) = 0$ on $[0.51,1]$; this has narrow interior jumps but zero endpoints.\n\nInterpretation:\n- In Case $1$, endpoint discontinuities are expected to contribute strongly to leakage; Hann taper should significantly reduce $\\lambda$ yielding $r \\gg 1$.\n- In Case $2$, endpoints are continuous; leakage arises mainly from interior jumps; Hann taper reduces leakage less, so $r$ may be closer to $1$ than Case $1$.\n- In Case $3$, the narrow pulse produces broad frequency content mainly due to interior jumps; boundary smoothing primarily addresses endpoints, so $r$ may show modest improvement.\n\nFinally, the program must print the leakage reduction ratios $[r_1,r_2,r_3]$ on a single line, with each ratio rounded to $6$ decimal places, and angles treated in radians throughout, with $\\omega_{\\text{tail}} = 200\\pi$.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef hann_window(N: int) -> np.ndarray:\n    \"\"\"Generate a Hann window of length N that is zero at endpoints.\"\"\"\n    n = np.arange(N, dtype=float)\n    return 0.5 * (1.0 - np.cos(2.0 * np.pi * n / (N - 1)))\n\ndef sample_piecewise_function(N: int, segments: list) -> np.ndarray:\n    \"\"\"\n    Sample a piecewise-constant function on [0,1] with N samples.\n    segments: list of tuples (a, b, value), with [a,b) except last is [a,b].\n    Assumes segments cover [0,1] without gaps and with non-overlapping intervals.\n    \"\"\"\n    x = np.linspace(0.0, 1.0, N, endpoint=False)  # x_n = n/N, n=0..N-1\n    f = np.zeros_like(x)\n    for i, (a, b, val) in enumerate(segments):\n        if i  len(segments) - 1:\n            mask = (x >= a)  (x  b)\n        else:\n            # last segment includes the endpoint 1, but our grid excludes 1 (endpoint=False),\n            # so this mask is equivalent to [a,b) here.\n            mask = (x >= a)  (x  b)\n        f[mask] = val\n    return f\n\ndef ctft_approx_via_fft(samples: np.ndarray, T: float) - tuple:\n    \"\"\"\n    Approximate CTFT using FFT of samples scaled by Delta x.\n    Returns (omega, F_hat), where omega are angular frequencies in radians per unit x.\n    \"\"\"\n    N = samples.size\n    dx = T / N\n    # FFT and frequencies:\n    F = np.fft.fft(samples) * dx\n    # Frequencies in cycles per unit x, convert to angular frequency by 2*pi:\n    freqs = np.fft.fftfreq(N, d=dx)  # cycles per unit\n    omega = 2.0 * np.pi * freqs      # radians per unit\n    return omega, F\n\ndef leakage_fraction(omega: np.ndarray, F_hat: np.ndarray, omega_tail: float) - float:\n    \"\"\"\n    Compute leakage fraction: energy beyond |omega| > omega_tail divided by total energy.\n    \"\"\"\n    power = np.abs(F_hat)**2\n    mask_tail = np.abs(omega) > omega_tail\n    tail_energy = power[mask_tail].sum()\n    total_energy = power.sum()\n    # Handle potential numerical edge case:\n    if total_energy == 0.0:\n        return 0.0\n    return float(tail_energy / total_energy)\n\ndef solve():\n    # Parameters\n    T = 1.0\n    N = 4096\n    omega_tail = 200.0 * np.pi  # radians per unit x\n\n    # Define test cases: list of segments (a, b, value)\n    test_cases = [\n        # Case 1: boundary discontinuity present\n        [(0.0, 0.4, 2.0), (0.4, 0.7, -1.0), (0.7, 1.0, 0.0)],\n        # Case 2: boundary continuity at endpoints (zeros at ends)\n        [(0.0, 0.3, 0.0), (0.3, 0.6, 3.0), (0.6, 1.0, 0.0)],\n        # Case 3: narrow interior jump, endpoints are zero\n        [(0.0, 0.49, 0.0), (0.49, 0.51, 5.0), (0.51, 1.0, 0.0)],\n    ]\n\n    # Windows\n    rect = np.ones(N, dtype=float)\n    hann = hann_window(N)\n\n    results = []\n    for segments in test_cases:\n        # Sample f\n        f = sample_piecewise_function(N, segments)\n\n        # Unsmooth: rectangular window\n        f_rect = f * rect\n        omega_rect, F_rect = ctft_approx_via_fft(f_rect, T)\n        lambda_rect = leakage_fraction(omega_rect, F_rect, omega_tail)\n\n        # Smooth: Hann window\n        f_hann = f * hann\n        omega_hann, F_hann = ctft_approx_via_fft(f_hann, T)\n        lambda_hann = leakage_fraction(omega_hann, F_hann, omega_tail)\n\n        # Leakage reduction ratio\n        if lambda_hann == 0.0:\n            ratio = float('inf') if lambda_rect > 0.0 else 1.0\n        else:\n            ratio = lambda_rect / lambda_hann\n        results.append(ratio)\n\n    # Round to 6 decimal places and format output\n    formatted = [f\"{r:.6f}\" if np.isfinite(r) else \"inf\" for r in results]\n    print(f\"[{','.join(formatted)}]\")\n\nsolve()\n```", "id": "3112450"}, {"introduction": "While numerical methods often assume perfectly uniform grids, real-world measurements and computational models can involve imperfections in sampling locations, known as jitter. This exercise challenges you to investigate how these small spatial perturbations propagate and affect the accuracy of the computed Fourier transform, particularly at high frequencies. By combining theoretical analysis with a numerical experiment, you will gain a deeper understanding of error sources and the robustness of computational transform algorithms. [@problem_id:3112380]", "problem": "You are asked to investigate, by principled derivation and computation, how small random perturbations (jitter) in the spatial sampling locations propagate into the frequency-domain when numerically approximating the continuous Fourier transform. Work entirely in a purely mathematical setting with no physical units. Angles are measured in radians.\n\nStart from the fundamental definition of the continuous Fourier transform of a function $f:\\mathbb{R}\\to\\mathbb{C}$,\n$$\nF(\\omega)=\\int_{-\\infty}^{\\infty} f(x)\\,e^{-i\\,\\omega\\,x}\\,dx,\n$$\nand the fact that numerical evaluation on a finite interval using a Riemann-type quadrature requires choosing a finite domain and a grid of sample locations in $x$.\n\nYou will compare two numerical approximations of $F(\\omega)$ built on the same finite interval $[-L,L]$:\n\n- A baseline approximation built from a uniform grid $x_n=-L+n\\,\\Delta x$ for $n\\in\\{0,1,\\dots,N-1\\}$ with $\\Delta x=\\dfrac{2L}{N-1}$ and weights from the trapezoidal rule.\n\n- A jittered approximation built from perturbed sample locations $\\tilde{x}_n=x_n+\\varepsilon_n$ where each $\\varepsilon_n$ is an independent Gaussian random variable with mean $0$ and standard deviation $s\\,\\Delta x$, with the same trapezoidal rule adapted to the nonuniform grid by using the corresponding nonuniform spacings.\n\nYou must:\n\n- Derive, from the definition of $F(\\omega)$ and first-order Taylor expansions, how a small perturbation $\\delta x$ in the sampling locations changes the integrand and thus the computed transform. Express the leading-order dependence of the error on $\\omega$ and on derivatives of $f$.\n\n- Implement a program that quantifies the effect for a specific test function $f(x)=\\exp\\!\\left(-\\dfrac{x^2}{2\\,\\sigma^2}\\right)$ on a finite interval. Use the same quadrature rule for both the baseline and the jittered cases so that your metric isolates the effect of jitter.\n\n- For a given set of frequencies $\\{\\omega_m\\}_{m=1}^M$ uniformly spaced in the interval $[-\\omega_{\\max},\\omega_{\\max}]$, compute the baseline approximation $F_{\\mathrm{uni}}(\\omega_m)$ and the jittered approximation $F_{\\mathrm{jit}}(\\omega_m)$. Then compute a single scalar error metric for each parameter set:\n$$\nE=\\frac{\\left(\\frac{1}{M}\\sum_{m=1}^M \\left|F_{\\mathrm{jit}}(\\omega_m)-F_{\\mathrm{uni}}(\\omega_m)\\right|^2\\right)^{1/2}}{\\left(\\frac{1}{M}\\sum_{m=1}^M \\left|F_{\\mathrm{uni}}(\\omega_m)\\right|^2\\right)^{1/2}}.\n$$\nThis $E$ is the relative root-mean-square discrepancy over the chosen frequency grid and directly quantifies how sampling perturbations in $x$ propagate to the $\\omega$-domain.\n\nComputational requirements and conventions:\n\n- Use the trapezoidal rule on the chosen grid for numerical approximation of the integral. On the uniform grid, the weights are $\\Delta x$ at interior points and $\\dfrac{\\Delta x}{2}$ at the endpoints. On the nonuniform grid, first sort the perturbed sample locations in ascending order to restore an ordered grid, and then assign trapezoidal weights using the local nonuniform spacings. Specifically, with sorted nodes $\\{\\tilde{x}_k\\}_{k=0}^{N-1}$ and spacings $\\Delta \\tilde{x}_k=\\tilde{x}_{k+1}-\\tilde{x}_k$, use weights $w_0=\\dfrac{1}{2}\\Delta \\tilde{x}_0$, $w_{N-1}=\\dfrac{1}{2}\\Delta \\tilde{x}_{N-2}$, and for interior indices $k\\in\\{1,\\dots,N-2\\}$, $w_k=\\dfrac{1}{2}\\left(\\Delta \\tilde{x}_{k-1}+\\Delta \\tilde{x}_k\\right)$.\n\n- On both grids, approximate the integral by summing $w_k\\,f(x_k)\\,e^{-i\\,\\omega\\,x_k}$ over grid points $k$.\n\n- Random jitter should be modeled as independent Gaussian variables with mean $0$ and standard deviation $s\\,\\Delta x$. Reproducibility must be ensured by using a fixed pseudorandom number generator seed for each test case.\n\nTest suite:\n\nYour program must run the following four parameter sets and output the corresponding four error values $E$ as a single list.\n\nEach parameter set is a tuple $(\\sigma,L,N,s,\\omega_{\\max},M,\\text{seed})$:\n\n- Test $1$: $(\\sigma,L,N,s,\\omega_{\\max},M,\\text{seed}) = (0.6, 3.0, 2048, 0.0, 30.0, 301, 13)$.\n\n- Test $2$: $(\\sigma,L,N,s,\\omega_{\\max},M,\\text{seed}) = (0.6, 3.0, 2048, 0.02, 30.0, 301, 13)$.\n\n- Test $3$: $(\\sigma,L,N,s,\\omega_{\\max},M,\\text{seed}) = (0.6, 3.0, 2048, 0.1, 30.0, 301, 13)$.\n\n- Test $4$: $(\\sigma,L,N,s,\\omega_{\\max},M,\\text{seed}) = (0.6, 3.0, 2048, 0.3, 30.0, 301, 13)$.\n\nFinal output format:\n\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, with each number rounded to exactly six decimal places using standard rounding, in the order of Tests $1$ through $4$. For example, an output with four results should look like \"[0.000001,0.012345,0.067890,0.123456]\".", "solution": "The problem is valid. It is a well-posed, scientifically grounded exercise in computational science, requiring both theoretical derivation and numerical implementation based on explicitly stated mathematical definitions and algorithms. All necessary parameters are provided for a unique and verifiable solution.\n\n### Part 1: Theoretical Derivation\n\nThe problem requires a derivation of how small random perturbations (jitter) in spatial sampling locations propagate into the frequency domain when computing the Fourier transform. We begin with the quantity being numerically integrated, which is the product of the function $f(x)$ and the complex exponential kernel. Let this composite function be $g(x, \\omega) = f(x) e^{-i\\omega x}$. The Fourier transform is $F(\\omega) = \\int_{-\\infty}^{\\infty} g(x, \\omega) dx$.\n\nA numerical quadrature approximates this integral as a weighted sum over a discrete set of sampling points $\\{x_n\\}$:\n$$\nF_{\\text{approx}}(\\omega) = \\sum_n w_n g(x_n, \\omega)\n$$\nwhere $w_n$ are the quadrature weights.\n\nNow, consider a single sampling point $x_n$ that is perturbed by a small amount $\\varepsilon_n$, such that the new location is $\\tilde{x}_n = x_n + \\varepsilon_n$. The value of the integrand at this new point can be approximated by a first-order Taylor series expansion of $g(x, \\omega)$ around $x_n$:\n$$\ng(\\tilde{x}_n, \\omega) = g(x_n + \\varepsilon_n, \\omega) \\approx g(x_n, \\omega) + \\left. \\frac{\\partial g(x, \\omega)}{\\partial x} \\right|_{x=x_n} \\varepsilon_n\n$$\nThe error in the integrand's value at this point, $\\Delta g_n = g(\\tilde{x}_n, \\omega) - g(x_n, \\omega)$, is therefore approximately:\n$$\n\\Delta g_n \\approx \\left. \\frac{\\partial g(x, \\omega)}{\\partial x} \\right|_{x=x_n} \\varepsilon_n\n$$\nWe compute the derivative of $g(x, \\omega)$ with respect to $x$:\n$$\n\\frac{\\partial g(x, \\omega)}{\\partial x} = \\frac{\\partial}{\\partial x} \\left( f(x) e^{-i\\omega x} \\right) = \\frac{df(x)}{dx} e^{-i\\omega x} + f(x) \\left( -i\\omega e^{-i\\omega x} \\right) = \\left( f'(x) - i\\omega f(x) \\right) e^{-i\\omega x}\n$$\nwhere $f'(x)$ is the derivative of $f(x)$.\n\nSubstituting this back, the error in the integrand at point $x_n$ is approximately:\n$$\n\\Delta g_n \\approx \\left( f'(x_n) - i\\omega f(x_n) \\right) e^{-i\\omega x_n} \\varepsilon_n\n$$\nThis expression reveals the leading-order dependence of the local error on the properties of the function and the transform parameters:\n1.  **Dependence on function and its derivative**: The error is proportional to a linear combination of the function value $f(x_n)$ and its first derivative $f'(x_n)$. Regions where the function or its slope are large in magnitude will contribute more significantly to the total error.\n2.  **Dependence on frequency $\\omega$**: The error consists of two components. The term proportional to $f'(x_n)$ arises from the change in the function's amplitude, $f(x_n+\\varepsilon_n) - f(x_n)$. This term's magnitude is independent of $\\omega$. The term proportional to $-i\\omega f(x_n)$ arises from the change in the Fourier kernel's phase, $e^{-i\\omega(x_n+\\varepsilon_n)} - e^{-i\\omega x_n}$. The magnitude of this term grows linearly with $\\omega$.\n\nThe total error in the computed Fourier transform, $\\Delta F(\\omega) = F_{\\mathrm{jit}}(\\omega) - F_{\\mathrm{uni}}(\\omega)$, is a complex sum of these local errors, also accounting for perturbations in the quadrature weights. However, the analysis of a single point's contribution is sufficient to establish the primary dependencies. The term proportional to $\\omega$ indicates that the error due to sampling jitter is expected to be more pronounced at higher frequencies. This is because a small spatial shift $\\varepsilon_n$ causes a phase shift of $-\\omega \\varepsilon_n$ in the Fourier kernel, and this phase shift becomes larger as $|\\omega|$ increases.\n\nThe expected squared magnitude of the error will have a term proportional to $\\omega^2$:\n$$\n|\\Delta g_n|^2 \\approx \\left| f'(x_n) - i\\omega f(x_n) \\right|^2 |\\varepsilon_n|^2 = \\left( (f'(x_n))^2 + \\omega^2 (f(x_n))^2 \\right) |\\varepsilon_n|^2\n$$\nThis confirms that the error power spectrum is expected to grow quadratically with frequency, highlighting the sensitivity of high-frequency components to sampling jitter.\n\n### Part 2: Numerical Implementation\n\nThe provided Python code implements the described numerical experiment.\nFirst, a function `solve` is defined to manage the test cases. It iterates through each parameter set, setting up the required spatial and frequency grids.\n\nFor each case, two Fourier transforms are computed:\n1.  **`F_uni` (Baseline)**: This is calculated on a perfectly uniform grid `x_uni` using the trapezoidal rule with uniform weights.\n2.  **`F_jit` (Jittered)**: A random jitter array `eps` is generated from a Gaussian distribution with mean $0$ and standard deviation $s \\cdot \\Delta x$. This jitter is added to the uniform grid to create `x_jit`. A special case for $s=0$ ensures no jitter is added and the computation is short-circuited for efficiency, as the result must be identical to the uniform case. For $s0$, the perturbed grid points `x_jit` are first sorted to restore a monotonically increasing sequence, as required by the trapezoidal rule definition for non-uniform grids. The function `f(x)` is evaluated at these new sorted locations. The trapezoidal weights are then calculated based on the non-uniform spacings between the sorted points, according to the precise formula given in the problem statement.\n\nBoth `F_uni` and `F_jit` are computed by taking the matrix product of the complex exponential kernel (evaluated at all combinations of frequency and spatial points) and the corresponding vector of weighted function values. This vectorized approach is efficient.\n\nFinally, the relative root-mean-square error metric $E$ is calculated as specified. It normalizes the root-mean-square difference between the two transforms by the root-mean-square magnitude of the baseline uniform transform. The results for all test cases are collected, formatted to six decimal places, and printed in the required list format. Test case 1, with $s=0$, correctly yields an error of $0$, serving as a successful sanity check. The increasing values of $E$ for subsequent tests demonstrate the degradation of the Fourier transform approximation with increasing jitter magnitude, as predicted by the theory.", "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Computes the effect of sampling jitter on the numerical Fourier transform\n    for a series of test cases and prints the results.\n    \"\"\"\n\n    def f_gaussian(x, sigma):\n        \"\"\"\n        Computes the Gaussian function f(x) = exp(-x^2 / (2*sigma^2)).\n        \"\"\"\n        return np.exp(-x**2 / (2 * sigma**2))\n\n    def compute_ft(x_nodes, f_vals, weights, omega_grid):\n        \"\"\"\n        Computes the Fourier transform using a generic quadrature sum.\n        \"\"\"\n        # Base of the integrand for the sum: w_k * f(x_k)\n        integrand_base = f_vals * weights\n        \n        # Matrix of complex exponentials: exp(-i * omega_m * x_k)\n        # Shape: (M, N)\n        exp_matrix = np.exp(-1j * np.outer(omega_grid, x_nodes))\n        \n        # The sum is a matrix-vector product.\n        # Result shape: (M,)\n        ft_vals = exp_matrix @ integrand_base\n        return ft_vals\n\n    # Test cases as defined in the problem statement.\n    test_cases = [\n        # (sigma, L, N, s, omega_max, M, seed)\n        (0.6, 3.0, 2048, 0.0, 30.0, 301, 13),\n        (0.6, 3.0, 2048, 0.02, 30.0, 301, 13),\n        (0.6, 3.0, 2048, 0.1, 30.0, 301, 13),\n        (0.6, 3.0, 2048, 0.3, 30.0, 301, 13),\n    ]\n\n    results = []\n    for case in test_cases:\n        sigma, L, N, s, omega_max, M, seed = case\n\n        # Define the spatial and frequency grids.\n        x_uni = np.linspace(-L, L, N)\n        dx = (2 * L) / (N - 1)\n        omega_grid = np.linspace(-omega_max, omega_max, M)\n        \n        # Define the specific function for this test.\n        f = lambda x: f_gaussian(x, sigma)\n\n        # --- Baseline (Uniform Grid) Calculation ---\n        f_uni_vals = f(x_uni)\n        \n        # Trapezoidal weights for the uniform grid.\n        weights_uni = np.full(N, dx)\n        weights_uni[0] = dx / 2.0\n        weights_uni[-1] = dx / 2.0\n        \n        F_uni = compute_ft(x_uni, f_uni_vals, weights_uni, omega_grid)\n\n        # --- Jittered Grid Calculation ---\n        if s == 0.0:\n            # If there is no jitter, the result is identical to the uniform case.\n            F_jit = F_uni\n        else:\n            # Generate jitter.\n            rng = np.random.default_rng(seed)\n            jitter_std = s * dx\n            eps = rng.normal(loc=0.0, scale=jitter_std, size=N)\n            x_jit_unsorted = x_uni + eps\n            \n            # Sort the jittered grid points to apply the trapezoidal rule.\n            x_jit_sorted = np.sort(x_jit_unsorted)\n            \n            # Evaluate the function on the sorted jittered grid.\n            f_jit_vals = f(x_jit_sorted)\n\n            # Trapezoidal weights for the non-uniform (sorted jittered) grid.\n            dx_jit = np.diff(x_jit_sorted)\n            weights_jit = np.zeros(N)\n            weights_jit[0] = dx_jit[0] / 2.0\n            weights_jit[-1] = dx_jit[-2] / 2.0\n            weights_jit[1:-1] = (dx_jit[:-1] + dx_jit[1:]) / 2.0\n            \n            F_jit = compute_ft(x_jit_sorted, f_jit_vals, weights_jit, omega_grid)\n\n        # --- Compute the Error Metric E ---\n        # Numerator: RMS of the difference |F_jit - F_uni|.\n        num_rms = np.sqrt(np.mean(np.abs(F_jit - F_uni)**2))\n        \n        # Denominator: RMS of the baseline signal |F_uni|.\n        den_rms = np.sqrt(np.mean(np.abs(F_uni)**2))\n        \n        # The metric E is the ratio. Handle division by zero.\n        if den_rms == 0.0:\n            E = np.inf if num_rms > 0 else 0.0\n        else:\n            E = num_rms / den_rms\n            \n        results.append(E)\n\n    # Format results for the final output.\n    formatted_results = [f\"{res:.6f}\" for res in results]\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```", "id": "3112380"}, {"introduction": "Completing the signal processing cycle requires an accurate inverse transform to return from the frequency domain to the time domain. This practice explores how the choice of sampling points in the frequency domain—the $\\omega$ grid—profoundly impacts reconstruction accuracy. You will implement and compare standard uniform-grid methods with more advanced schemes using nonuniform sampling and higher-order quadrature, demonstrating how intelligent grid design can yield superior results. [@problem_id:3112393]", "problem": "Consider the Continuous Fourier Transform (CFT) and its inverse, defined for a square-integrable function $f(t)$ by\n$$\nF(\\omega) = \\int_{-\\infty}^{\\infty} f(t)\\,e^{-i\\omega t}\\,dt,\\quad\nf(t) = \\frac{1}{2\\pi}\\int_{-\\infty}^{\\infty} F(\\omega)\\,e^{i\\omega t}\\,d\\omega,\n$$\nwhere $i$ denotes the imaginary unit and all angular frequencies $\\omega$ and arguments of trigonometric/exponential functions are in radians. In computational practice, the inverse transform integral is approximated by a finite interval and a discrete sum. The accuracy depends strongly on the sampling of $F(\\omega)$ in the frequency domain and on the chosen quadrature scheme.\n\nYour task is to implement a program that reconstructs a known time-domain signal from its analytically known frequency-domain representation, using both uniform and nonuniform sampling schemes for $\\omega$. You must design and compare two inverse transform schemes tailored to nonuniform $\\omega$ grids, and benchmark them against a uniform-grid trapezoidal-rule baseline.\n\nUse the test signal\n$$\nf(t) = \\exp\\!\\left(-\\frac{t^2}{2\\sigma^2}\\right),\\quad F(\\omega) = \\int_{-\\infty}^{\\infty} \\exp\\!\\left(-\\frac{t^2}{2\\sigma^2}\\right) e^{-i\\omega t}\\,dt = \\sqrt{2\\pi}\\,\\sigma\\,\\exp\\!\\left(-\\frac{\\sigma^2\\omega^2}{2}\\right),\n$$\nwhich exactly satisfies the above CFT pair for the stated normalization. Fix the parameter $\\sigma = 0.75$. To approximate the inverse integral, truncate to the interval $\\omega\\in[-\\Omega,\\Omega]$ and discretize $\\omega$ using either a uniform or a specified nonuniform sampling rule.\n\nImplement the following inverse schemes.\n- Uniform-grid baseline: Use a uniform grid with $N$ points on $[-\\Omega,\\Omega]$, apply the composite trapezoidal rule to approximate\n$$\n\\hat{f}(t) \\approx \\frac{1}{2\\pi}\\sum_{k=0}^{N-1} F(\\omega_k)\\,e^{i\\omega_k t}\\,w_k,\n$$\nwith uniform spacing and trapezoidal weights $w_k$.\n- Nonuniform scheme A (composite trapezoidal on nonuniform nodes): Given a sorted, nonuniform $\\{\\omega_k\\}_{k=0}^{N-1}$ on $[-\\Omega,\\Omega]$, approximate the integral using the composite trapezoidal rule derived from linear interpolation of $F(\\omega)e^{i\\omega t}$ between adjacent nodes. Use nonuniform trapezoidal weights determined by neighboring node spacings.\n- Nonuniform scheme B (cubic-spline interpolation plus Gauss–Legendre (GL) quadrature): Build a natural cubic spline $S(\\omega)$ approximating $F(\\omega)$ on the given nonuniform nodes. On each interval $[\\omega_k,\\omega_{k+1}]$, approximate\n$$\n\\int_{\\omega_k}^{\\omega_{k+1}} S(\\omega)\\,e^{i\\omega t}\\,d\\omega\n$$\nby mapping to the standard GL nodes and weights on $[-1,1]$ (use $4$-point Gauss–Legendre), evaluating $S(\\omega)$ at the mapped nodes, and summing contributions over all intervals. Combine interval integrals and scale by $\\frac{1}{2\\pi}$ to obtain $\\hat{f}(t)$.\n\nFor all schemes, evaluate the reconstruction on a uniform time grid $t\\in[-6,6]$ with $M=201$ points. Compute the maximum absolute error\n$$\nE = \\max_{t\\in[-6,6]} \\left|\\hat{f}(t) - f(t)\\right|.\n$$\n\nDesign the following test suite of parameter sets to explore the effect of nonuniform $\\omega$ sampling on inverse-transform accuracy. In every case, compute and report three errors: the uniform-grid baseline error (using a uniform grid with the same $N$ and $\\Omega$), the nonuniform composite trapezoid error, and the nonuniform spline–GL error.\n- Case $1$ (happy path, uniform sampling): $N=513$, $\\Omega=14.0$, uniform $\\omega$ grid on $[-\\Omega,\\Omega]$.\n- Case $2$ (nonuniform clustered near $\\omega=0$): $N=513$, $\\Omega=14.0$, nonuniform nodes defined by $\\omega(u)=\\Omega\\,\\tanh(a u)/\\tanh(a)$ with $a=2.0$ and $u$ uniformly spaced in $[-1,1]$; sort nodes ascending.\n- Case $3$ (nonuniform skewed toward positive $\\omega$): $N=513$, $\\Omega=14.0$, nonuniform nodes defined by $\\omega(x)=\\Omega\\,(2x^p-1)$ with $p=3.0$ and $x$ uniformly spaced in $[0,1]$; sort nodes ascending.\n- Case $4$ (boundary, sparse nonuniform sampling): $N=65$, $\\Omega=14.0$, nonuniform clustered near $\\omega=0$ with the same $\\tanh$ mapping as Case $2$ ($a=2.0$); sort nodes ascending.\n\nAngle unit specification: all angular frequencies $\\omega$ and the exponent $i\\omega t$ are in radians.\n\nYour program must produce a single line of output containing the results as a comma-separated list enclosed in square brackets. Aggregate the $3$ errors from each case in order, producing $12$ numbers total in the order\n$$\n[\\text{Case 1 uniform},\\ \\text{Case 1 nonuniform A},\\ \\text{Case 1 nonuniform B},\\ \\text{Case 2 uniform},\\ \\text{Case 2 nonuniform A},\\ \\text{Case 2 nonuniform B},\\ \\text{Case 3 uniform},\\ \\text{Case 3 nonuniform A},\\ \\text{Case 3 nonuniform B},\\ \\text{Case 4 uniform},\\ \\text{Case 4 nonuniform A},\\ \\text{Case 4 nonuniform B}],\n$$\nwith each number rounded to six decimal places. No other text should be printed.\n\nAll computations must be performed in pure mathematics without physical units. Ensure scientific realism by choosing truncation $\\Omega$ sufficiently large that $F(\\omega)$ is numerically negligible outside $[-\\Omega,\\Omega]$ for the stated $\\sigma$. The program must be self-contained, require no input, and be runnable in any modern programming language; however, the final answer must be a complete, runnable program as specified in the answer section.", "solution": "The problem statement is scientifically sound, well-posed, objective, and contains all necessary information for a unique solution. The definitions of the Continuous Fourier Transform (CFT), the test signal, and the numerical schemes are standard and consistent with the principles of computational science and numerical analysis. The parameters provided are realistic and suitable for the proposed numerical experiment. Therefore, the problem is valid, and a solution will be provided.\n\nThe objective is to reconstruct a time-domain signal, a Gaussian function, from its analytical Fourier transform using three different numerical schemes for the inverse transform integral. The accuracy of these schemes is evaluated by comparing the reconstructed signal $\\hat{f}(t)$ to the exact signal $f(t)$ across a specified time interval. The test signal and its transform are given by:\n$$f(t) = \\exp\\left(-\\frac{t^2}{2\\sigma^2}\\right)$$\n$$F(\\omega) = \\sqrt{2\\pi}\\,\\sigma\\,\\exp\\left(-\\frac{\\sigma^2\\omega^2}{2}\\right)$$\nwith the parameter $\\sigma = 0.75$. The inverse transform integral is approximated over a finite frequency domain $\\omega \\in [-\\Omega, \\Omega]$:\n$$\\hat{f}(t) = \\frac{1}{2\\pi}\\int_{-\\Omega}^{\\Omega} F(\\omega)\\,e^{i\\omega t}\\,d\\omega$$\nThis integral is calculated for a set of discrete time points $t_j$ on the interval $[-6, 6]$ using $M=201$ uniformly spaced points.\n\nThe core of the problem lies in the design and comparison of three numerical quadrature methods to approximate the integral.\n\n1.  **Uniform-Grid Baseline (Composite Trapezoidal Rule)**\n    This method serves as a standard reference. The frequency interval $[-\\Omega, \\Omega]$ is discretized into a uniform grid of $N$ points, $\\{\\omega_k\\}_{k=0}^{N-1}$, with constant spacing $\\Delta\\omega = \\frac{2\\Omega}{N-1}$. The integral is approximated using the composite trapezoidal rule. The approximation for $\\hat{f}(t)$ is given by a weighted sum:\n    $$\\hat{f}(t) \\approx \\frac{1}{2\\pi}\\sum_{k=0}^{N-1} F(\\omega_k)\\,e^{i\\omega_k t}\\,w_k$$\n    Here, the weights $w_k$ for the trapezoidal rule are:\n    $$w_k = \\begin{cases} \\Delta\\omega/2  \\text{if } k=0 \\text{ or } k=N-1 \\\\ \\Delta\\omega  \\text{if } 1 \\le k \\le N-2 \\end{cases}$$\n    This scheme is straightforward but can be inefficient if the integrand varies rapidly in some regions and slowly in others.\n\n2.  **Nonuniform Scheme A (Composite Trapezoidal on Nonuniform Nodes)**\n    This scheme generalizes the trapezoidal rule to a sorted, nonuniform grid $\\{\\omega_k\\}_{k=0}^{N-1}$. The integral is decomposed into a sum of integrals over the subintervals $[\\omega_k, \\omega_{k+1}]$. Each sub-integral is approximated using the area of a trapezoid:\n    $$\\int_{\\omega_k}^{\\omega_{k+1}} g(\\omega) \\, d\\omega \\approx \\frac{g(\\omega_k) + g(\\omega_{k+1})}{2} (\\omega_{k+1} - \\omega_k)$$\n    where $g(\\omega) = F(\\omega)e^{i\\omega t}$. Summing over all subintervals from $k=0$ to $N-2$ gives the full integral approximation. This can be expressed in the same weighted sum form as the uniform case, but with node-dependent weights:\n    $$\\hat{f}(t) = \\frac{1}{2\\pi}\\sum_{k=0}^{N-1} F(\\omega_k)\\,e^{i\\omega_k t}\\,w_k$$\n    The weights for the nonuniform grid are:\n    $$w_k = \\begin{cases} \\frac{1}{2}(\\omega_1 - \\omega_0)  \\text{if } k=0 \\\\ \\frac{1}{2}(\\omega_{k+1} - \\omega_{k-1})  \\text{if } 1 \\le k \\le N-2 \\\\ \\frac{1}{2}(\\omega_{N-1} - \\omega_{N-2})  \\text{if } k=N-1 \\end{cases}$$\n    This method adapts to the local density of nodes, providing a more flexible quadrature.\n\n3.  **Nonuniform Scheme B (Cubic Spline Interpolation + Gauss–Legendre Quadrature)**\n    This is a more sophisticated, higher-order scheme. First, the known values of the real-valued function $F(\\omega)$ at the nonuniform nodes $\\{\\omega_k\\}$ are used to construct a natural cubic spline, $S(\\omega)$. A natural spline is one where the second derivatives at the endpoints are set to zero, which is a reasonable choice in the absence of other boundary information. This spline provides a smooth, piecewise-cubic approximation of $F(\\omega)$ across the entire interval $[-\\Omega, \\Omega]$.\n    The integral is then computed as:\n    $$\\hat{f}(t) = \\frac{1}{2\\pi}\\sum_{k=0}^{N-2} \\int_{\\omega_k}^{\\omega_{k+1}} S(\\omega)\\,e^{i\\omega t}\\,d\\omega$$\n    Each sub-integral over $[\\omega_k, \\omega_{k+1}]$ is evaluated using $4$-point Gauss–Legendre (GL) quadrature, a high-precision method. We transform the interval $[\\omega_k, \\omega_{k+1}]$ to the standard GL interval $[-1, 1]$ via the linear mapping:\n    $$\\omega(u) = \\frac{\\omega_{k+1} - \\omega_k}{2}u + \\frac{\\omega_{k+1} + \\omega_k}{2}$$\n    The integral over the subinterval becomes:\n    $$\\int_{\\omega_k}^{\\omega_{k+1}} S(\\omega)e^{i\\omega t}d\\omega = \\frac{\\omega_{k+1} - \\omega_k}{2} \\int_{-1}^{1} S(\\omega(u))e^{i\\omega(u)t}du$$\n    This is then approximated using the $4$-point GL formula:\n    $$\\approx \\frac{\\omega_{k+1} - \\omega_k}{2} \\sum_{j=1}^{4} c_j S(\\omega(u_j))e^{i\\omega(u_j)t}$$\n    where $\\{u_j\\}$ and $\\{c_j\\}$ are the standard $4$-point GL nodes and weights on $[-1, 1]$. The total integral is the sum of these contributions over all $N-1$ subintervals. This method is expected to yield high accuracy, particularly if the nonuniform grid is well-chosen for the function $F(\\omega)$.\n\nThe four test cases specified in the problem statement are designed to systematically evaluate these schemes.\n- **Case 1** tests the behavior of all three methods on a simple uniform grid. For Schemes A and B, this serves as a consistency check.\n- **Case 2** uses a `tanh` mapping to cluster frequency nodes near $\\omega=0$. Since the Gaussian $F(\\omega)$ has most of its energy concentrated around the origin, this grid is expected to be highly efficient, leading to low errors for the nonuniform schemes.\n- **Case 3** uses a power-law mapping that skews the grid towards positive $\\omega$. For an even function like our $F(\\omega)$, this asymmetric sampling is suboptimal and is expected to increase the approximation error.\n- **Case 4** repeats the efficient `tanh` mapping but with a much smaller number of points ($N=65$ vs. $N=513$), testing the robustness and convergence properties of the schemes under sparse sampling conditions.\n\nFor each case, we compute the maximum absolute error $E = \\max_{t} |\\hat{f}(t) - f(t)|$ for the uniform baseline, Scheme A, and Scheme B. The implementation will be vectorized for computational efficiency.", "answer": "```python\nimport numpy as np\nfrom scipy.interpolate import CubicSpline\nfrom scipy.special import roots_legendre\n\ndef solve():\n    \"\"\"\n    Main function to run the test suite for inverse Fourier transform schemes.\n    \"\"\"\n    # Define problem constants and evaluation grid\n    SIGMA = 0.75\n    T_MIN, T_MAX, M = -6.0, 6.0, 201\n    T_GRID = np.linspace(T_MIN, T_MAX, M)\n\n    # 4-point Gauss-Legendre nodes and weights on [-1, 1]\n    GL_NODES, GL_WEIGHTS = roots_legendre(4)\n\n    # Analytical functions for the signal and its transform\n    def f_true(t, sigma):\n        return np.exp(-t**2 / (2 * sigma**2))\n\n    def F_freq(omega, sigma):\n        return np.sqrt(2 * np.pi) * sigma * np.exp(-(sigma**2 * omega**2) / 2)\n\n    # Grid generation functions\n    def generate_uniform_grid(N, Omega):\n        return np.linspace(-Omega, Omega, N)\n\n    def generate_tanh_grid(N, Omega, a):\n        u = np.linspace(-1.0, 1.0, N)\n        omega = Omega * np.tanh(a * u) / np.tanh(a)\n        # Ensure endpoints are exactly -Omega and Omega\n        omega[0], omega[-1] = -Omega, Omega\n        return np.sort(omega)\n\n    def generate_power_law_grid(N, Omega, p):\n        x = np.linspace(0.0, 1.0, N)\n        omega = Omega * (2 * x**p - 1)\n        # Ensure endpoints are exactly -Omega and Omega\n        omega[0], omega[-1] = -Omega, Omega\n        return np.sort(omega)\n\n    # Inverse transform implementations\n    def inverse_transform_uniform_trapz(omega_grid, t_grid, sigma):\n        N = len(omega_grid)\n        Omega = omega_grid[-1]\n        delta_omega = 2 * Omega / (N - 1)\n        \n        weights = np.full(N, delta_omega)\n        weights[0] = weights[-1] = 0.5 * delta_omega\n        \n        F_vals = F_freq(omega_grid, sigma)\n        integrand_base = F_vals * weights\n        \n        exp_matrix = np.exp(1j * np.outer(t_grid, omega_grid))\n        f_hat = (1 / (2 * np.pi)) * (exp_matrix @ integrand_base)\n        return f_hat\n\n    def inverse_transform_nonuniform_trapz(omega_grid, t_grid, sigma):\n        N = len(omega_grid)\n        \n        weights = np.zeros(N)\n        weights[0] = 0.5 * (omega_grid[1] - omega_grid[0])\n        weights[1:-1] = 0.5 * (omega_grid[2:] - omega_grid[:-2])\n        weights[-1] = 0.5 * (omega_grid[-1] - omega_grid[-2])\n        \n        F_vals = F_freq(omega_grid, sigma)\n        integrand_base = F_vals * weights\n        \n        exp_matrix = np.exp(1j * np.outer(t_grid, omega_grid))\n        f_hat = (1 / (2 * np.pi)) * (exp_matrix @ integrand_base)\n        return f_hat\n\n    def inverse_transform_spline_gl(omega_grid, t_grid, sigma, gl_nodes, gl_weights):\n        N = len(omega_grid)\n        \n        # Build natural cubic spline for F(omega)\n        F_vals = F_freq(omega_grid, sigma)\n        spline = CubicSpline(omega_grid, F_vals, bc_type='natural')\n        \n        # Vectorized calculation\n        num_intervals = N - 1\n        num_gl_points = len(gl_nodes)\n        \n        # Interval properties\n        w_k = omega_grid[:-1]\n        w_kp1 = omega_grid[1:]\n        h = w_kp1 - w_k\n        jac = h / 2.0\n        \n        # Map GL nodes to each interval\n        # Shape: (num_intervals, num_gl_points)\n        omega_gl_mapped = jac[:, np.newaxis] * gl_nodes[np.newaxis, :] + (w_kp1 + w_k)[:, np.newaxis] / 2.0\n        \n        # Evaluate spline at all mapped GL nodes\n        S_at_gl = spline(omega_gl_mapped)\n        \n        # Precompute effective weights for the final sum\n        # Shape: (num_intervals, num_gl_points)\n        W_eff_matrix = jac[:, np.newaxis] * gl_weights[np.newaxis, :] * S_at_gl\n        \n        # Flatten the mapped omega and effective weights\n        omega_eff = omega_gl_mapped.flatten() # Shape: (num_intervals * num_gl_points,)\n        W_eff = W_eff_matrix.flatten()       # Shape: (num_intervals * num_gl_points,)\n        \n        # Perform the final matrix-vector product\n        exp_matrix = np.exp(1j * np.outer(t_grid, omega_eff)) # Shape: (M, num_intervals * num_gl_points)\n        f_hat = (1 / (2 * np.pi)) * (exp_matrix @ W_eff)\n        return f_hat\n\n    # Test suite definition\n    test_cases = [\n        {'N': 513, 'Omega': 14.0, 'grid_type': 'uniform', 'params': {}},\n        {'N': 513, 'Omega': 14.0, 'grid_type': 'tanh', 'params': {'a': 2.0}},\n        {'N': 513, 'Omega': 14.0, 'grid_type': 'power', 'params': {'p': 3.0}},\n        {'N': 65, 'Omega': 14.0, 'grid_type': 'tanh', 'params': {'a': 2.0}},\n    ]\n\n    results = []\n    \n    # Calculate true signal on the evaluation grid\n    f_vals_true = f_true(T_GRID, SIGMA)\n\n    for case in test_cases:\n        N, Omega = case['N'], case['Omega']\n        \n        # 1. Generate grids\n        if case['grid_type'] == 'uniform':\n            nonuniform_grid = generate_uniform_grid(N, Omega)\n        elif case['grid_type'] == 'tanh':\n            nonuniform_grid = generate_tanh_grid(N, Omega, **case['params'])\n        elif case['grid_type'] == 'power':\n            nonuniform_grid = generate_power_law_grid(N, Omega, **case['params'])\n        \n        uniform_grid = generate_uniform_grid(N, Omega)\n\n        # 2. Compute baseline error (uniform grid, uniform rule)\n        f_hat_uni = inverse_transform_uniform_trapz(uniform_grid, T_GRID, SIGMA)\n        err_uniform = np.max(np.abs(f_hat_uni - f_vals_true))\n        \n        # 3. Compute error for Scheme A (nonuniform grid, nonuniform trapz)\n        f_hat_nuni_A = inverse_transform_nonuniform_trapz(nonuniform_grid, T_GRID, SIGMA)\n        err_nonuniform_A = np.max(np.abs(f_hat_nuni_A - f_vals_true))\n        \n        # 4. Compute error for Scheme B (nonuniform grid, spline+GL)\n        f_hat_nuni_B = inverse_transform_spline_gl(nonuniform_grid, T_GRID, SIGMA, GL_NODES, GL_WEIGHTS)\n        err_nonuniform_B = np.max(np.abs(f_hat_nuni_B - f_vals_true))\n        \n        results.extend([err_uniform, err_nonuniform_A, err_nonuniform_B])\n        \n    # Print results in the required format\n    print(f\"[{','.join(f'{x:.6f}' for x in results)}]\")\n\nsolve()\n```", "id": "3112393"}]}