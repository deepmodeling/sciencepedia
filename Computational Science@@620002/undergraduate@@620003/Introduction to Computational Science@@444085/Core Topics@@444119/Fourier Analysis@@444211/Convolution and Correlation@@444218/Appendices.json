{"hands_on_practices": [{"introduction": "At first glance, discrete convolution and cross-correlation appear very similar, but a subtle difference in their definitions leads to distinct behaviors. This exercise challenges you to explore this distinction by implementing both operations from first principles [@problem_id:3114298]. By constructing signals where the two operations yield different results, you will gain a deep, practical understanding of the role of time-reversal and how boundary conditions—circular versus linear—fundamentally alter the symmetry required for convolution and correlation to be equivalent.", "problem": "You are to write a complete, runnable program that constructs and compares discrete convolution and discrete cross-correlation for carefully chosen real-valued signals under two boundary models: circular boundary conditions and zero-padding. Work from the core definitions of discrete convolution and discrete cross-correlation.\n\nUse the following foundational definitions as the basis for your reasoning and implementation. For two real-valued discrete-time signals $x[n]$ and $h[n]$ with finite lengths $N_x$ and $N_h$:\n- Linear convolution (with zero-padding) is defined by\n$$\ny_{\\text{lin}}[k] = \\sum_{n=-\\infty}^{\\infty} x[n]\\;h[k-n],\n$$\nwith the convention that values outside the supported indices are treated as zero. Practically, for finite $x[n]$ supported on $0 \\le n \\le N_x-1$ and $h[n]$ supported on $0 \\le n \\le N_h-1$, this sum reduces to indices where both $x[n]$ and $h[k-n]$ are defined within their supports. The output length is $N_x + N_h - 1$.\n- Linear cross-correlation (with zero-padding) is defined by\n$$\nr_{xh,\\text{lin}}[k] = \\sum_{n=-\\infty}^{\\infty} x[n]\\;h[n+k],\n$$\nagain with values outside supported indices treated as zero.\n- For circular boundary conditions with period $N$ (Circular Boundary Conditions (CBC)), define the circular convolution as\n$$\ny_{\\text{circ}}[k] = \\sum_{n=0}^{N-1} x[n]\\;h[(k-n)\\bmod N],\n$$\nand the circular cross-correlation as\n$$\nr_{xh,\\text{circ}}[k] = \\sum_{n=0}^{N-1} x[n]\\;h[(n+k)\\bmod N],\n$$\nfor $0 \\le k \\le N-1$.\n\nYour task is to craft signals $x[n]$ and $h[n]$ so that the circular convolution $x \\circledast h$ and the circular cross-correlation $r_{xh,\\text{circ}}[k]$ are numerically equal, but the linear (zero-padded) convolution and linear cross-correlation diverge. You must explain, in principle, why this can happen, explicitly identifying the role of flipping (time reversal) and boundary models.\n\nImplement the following three test cases to demonstrate coverage:\n- Test Case $1$ (designed to satisfy the circular equality but not the linear equality): Let $N = 5$, $x[n]$ be $[\\,3,\\,1,\\,4,\\,1,\\,5\\,]$, and $h[n]$ be $[\\,2,\\,5,\\,7,\\,7,\\,5\\,]$. Here, $h[n]$ is circularly even with respect to index $0$ because $h[1] = h[4]$ and $h[2] = h[3]$, ensuring equality under circular boundary conditions, but $h[n]$ is not palindromic under center flip, so zero-padded convolution and correlation diverge.\n- Test Case $2$ (designed to satisfy the linear equality but not the circular equality): Let $N = 5$, $x[n]$ be $[\\,2,\\,1,\\,0,\\,4,\\,3\\,]$, and $h[n]$ be $[\\,1,\\,2,\\,3,\\,2,\\,1\\,]$. Here, $h[n]$ is palindromic under center flip, ensuring linear convolution equals linear correlation, but $h[n]$ is not circularly even with respect to index $0$, so circular convolution and circular correlation diverge.\n- Test Case $3$ (edge case where both equalities hold): Let $N = 6$, $x[n]$ be $[\\,0,\\,1,\\,0,\\,2,\\,0,\\,3\\,]$, and $h[n]$ be constant $[\\,4,\\,4,\\,4,\\,4,\\,4,\\,4\\,]$, so both circular and linear equalities hold.\n\nAlgorithmic requirements:\n- Compute $y_{\\text{circ}}[k]$ and $r_{xh,\\text{circ}}[k]$ directly from their definitions using modular indexing for each $k$.\n- Compute $y_{\\text{lin}}[k]$ using standard linear convolution with zero-padding.\n- Compute $r_{xh,\\text{lin}}[k]$ using the definition given above. For implementation, it is acceptable to use the equivalence that linear cross-correlation equals linear convolution with the center-flipped version of $h[n]$, that is, define $\\mathrm{flip}(h)[m] = h[N_h - 1 - m]$, and compute $r_{xh,\\text{lin}}[k] = \\mathrm{conv}(x,\\mathrm{flip}(h))[k]$. This alignment produces the same output indexing as linear convolution for direct comparison.\n- Use a numerical tolerance for equality checks. Two sequences are considered equal if the maximum absolute elementwise difference is less than $10^{-12}$.\n\nRequired outputs:\n- For each test case, produce two boolean values: the first indicates whether $y_{\\text{circ}}[k]$ equals $r_{xh,\\text{circ}}[k]$ elementwise, and the second indicates whether $y_{\\text{lin}}[k]$ equals $r_{xh,\\text{lin}}[k]$ elementwise (under the convolution-aligned indexing produced via center-flip).\n- Your program should produce a single line of output containing the results as a comma-separated list of lists with no spaces, in the exact format\n$$\n[\\,[b_{1,1},b_{1,2}],\\,[b_{2,1},b_{2,2}],\\,[b_{3,1},b_{3,2}]\\,],\n$$\nwhere each $b_{i,j}$ is either $\\mathrm{True}$ or $\\mathrm{False}$.\n\nThere are no physical units involved in this problem. Angles and percentages do not appear.\n\nImplement the solution in Python, version $3.12$, using only the allowed libraries specified in the runtime environment.", "solution": "The solution to this problem rests on a precise understanding of the relationship between convolution and cross-correlation, and how this relationship is affected by different boundary conditions—specifically, zero-padding for linear operations and modular arithmetic for circular operations.\n\nThe fundamental definitions for discrete convolution and cross-correlation of two real-valued signals $x[n]$ and $h[n]$ are:\n- Convolution: $(x * h)[k] = \\sum_{n} x[n] h[k-n]$\n- Cross-correlation: $(x \\star h)[k] = \\sum_{n} x[n] h[n+k]$\n\nThe key insight is that cross-correlation can be expressed as a convolution with a time-reversed (flipped) version of the kernel $h[n]$. Let's define a time-reversal operator, $\\mathrm{rev}(\\cdot)$. The convolution $(x * \\mathrm{rev}(h))[k]$ is given by $\\sum_{n} x[n] (\\mathrm{rev}(h))[k-n]$. It can be shown that this expression is equivalent to the definition of cross-correlation, $(x \\star h)[k]$, provided the reversal operator and summation bounds are defined appropriately for the boundary model in use.\n\nConsequently, convolution and cross-correlation yield the same result, i.e., $(x * h)[k] = (x \\star h)[k]$, if and only if the convolution kernel $h[n]$ is symmetric under the specific time-reversal operation associated with the boundary model. This condition is $h[n] = \\mathrm{rev}(h)[n]$. The crux of the problem lies in the fact that the time-reversal operator is defined differently for linear and circular contexts.\n\n**1. Linear (Zero-Padded) Operations**\n\nFor finite-length signals like $x[n]$ of length $N_x$ and $h[n]$ of length $N_h$, linear operations assume the signals are zero outside their defined support. The corresponding time-reversal operator flips the kernel $h[n]$ about its center index. This is defined as:\n$$\n\\mathrm{rev}_{\\text{lin}}(h)[m] = h[N_h - 1 - m] \\quad \\text{for } 0 \\le m \\le N_h-1\n$$\nLinear convolution and linear cross-correlation are equal if and only if $h[m] = \\mathrm{rev}_{\\text{lin}}(h)[m]$, which means $h[m] = h[N_h - 1 - m]$. A sequence with this property is called **palindromic**. For example, $[\\,1,\\,2,\\,3,\\,2,\\,1\\,]$ is palindromic.\n\nThe problem specifies computing linear cross-correlation as the convolution of $x$ with the flipped version of $h$. This directly leverages the identity $(x \\star h)_{\\text{lin}} = (x * \\mathrm{rev}_{\\text{lin}}(h))_{\\text{lin}}$. Thus, the comparison for equality becomes a direct comparison between $(x * h)_{\\text{lin}}$ and $(x * \\mathrm{rev}_{\\text{lin}}(h))_{\\text{lin}}$.\n\n**2. Circular (Periodic) Operations**\n\nFor circular operations on signals of period $N$, the indices are treated modulo $N$. The circular time-reversal operator flips the kernel $h[n]$ around the index $n=0$ on a circle:\n$$\n\\mathrm{rev}_{\\text{circ}}(h)[n] = h[(-n) \\pmod N] \\quad \\text{for } 0 \\le n \\le N-1\n$$\nCircular convolution, $y_{\\text{circ}}[k] = \\sum_{n=0}^{N-1} x[n]\\;h[(k-n)\\bmod N]$, equals circular cross-correlation, $r_{xh,\\text{circ}}[k] = \\sum_{n=0}^{N-1} x[n]\\;h[(n+k)\\bmod N]$, if and only if $h[n] = \\mathrm{rev}_{\\text{circ}}(h)[n]$. This means $h[n] = h[(-n) \\pmod N]$. A sequence with this property is **circularly even**. For example, for $N=5$, this requires $h[1] = h[4]$ and $h[2] = h[3]$. The sequence $[\\,2,\\,5,\\,7,\\,7,\\,5\\,]$ is circularly even for $N=5$.\n\n**Discrepancy by Design**\n\nThe problem's test cases are designed to exploit the fact that palindromic symmetry and circular even symmetry are distinct properties. A signal can possess one without the other, which allows us to construct scenarios where one pair of operations (e.g., circular) results in equality while the other (e.g., linear) does not.\n\n- **Test Case 1**: $h = [\\,2,\\,5,\\,7,\\,7,\\,5\\,]$ and $N=5$.\n  - Circularly Even?: $h[1]=5$ and $h[(-1)\\bmod 5] = h[4]=5$. They are equal. $h[2]=7$ and $h[(-2)\\bmod 5] = h[3]=7$. They are equal. So, $h$ is circularly even. We expect $y_{\\text{circ}} = r_{xh,\\text{circ}}$.\n  - Palindromic?: $h[0]=2$ and $h[5-1-0] = h[4]=5$. They are not equal. So, $h$ is not palindromic. We expect $y_{\\text{lin}} \\ne r_{xh,\\text{lin}}$.\n  - Prediction: $[\\mathrm{True}, \\mathrm{False}]$\n\n- **Test Case 2**: $h = [\\,1,\\,2,\\,3,\\,2,\\,1\\,]$ and $N=5$.\n  - Palindromic?: $h[0]=1, h[4]=1$. $h[1]=2, h[3]=2$. It is palindromic. We expect $y_{\\text{lin}} = r_{xh,\\text{lin}}$.\n  - Circularly Even?: $h[1]=2$ and $h[(-1)\\bmod 5] = h[4]=1$. They are not equal. It is not circularly even. We expect $y_{\\text{circ}} \\ne r_{xh,\\text{circ}}$.\n  - Prediction: $[\\mathrm{False}, \\mathrm{True}]$\n\n- **Test Case 3**: $h = [\\,4,\\,4,\\,4,\\,4,\\,4,\\,4\\,]$ and $N=6$.\n  - A constant signal is trivially both palindromic ($h[m]=4$ and $h[6-1-m]=4$) and circularly even ($h[n]=4$ and $h[(-n)\\bmod 6]=4$). We expect both equalities to hold.\n  - Prediction: $[\\mathrm{True}, \\mathrm{True}]$\n\nThe implementation will follow these principles. Circular operations are computed directly from their summation definitions using loops and modular arithmetic. Linear operations utilize `numpy.convolve` for efficiency, with linear cross-correlation computed as the convolution with a center-flipped kernel, as specified in the problem statement. Equality is checked by ensuring the maximum absolute element-wise difference between the resulting sequences is below a tolerance of $10^{-12}$.", "answer": "```python\nimport numpy as np\n\ndef circular_convolution(x: np.ndarray, h: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Computes the circular convolution of two 1D signals x and h.\n    Assumes len(x) == len(h).\n    \"\"\"\n    N = len(x)\n    y = np.zeros(N)\n    for k in range(N):\n        for n in range(N):\n            y[k] += x[n] * h[(k - n) % N]\n    return y\n\ndef circular_cross_correlation(x: np.ndarray, h: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Computes the circular cross-correlation of two 1D signals x and h.\n    Assumes len(x) == len(h).\n    \"\"\"\n    N = len(x)\n    r = np.zeros(N)\n    for k in range(N):\n        for n in range(N):\n            r[k] += x[n] * h[(n + k) % N]\n    return r\n\ndef solve():\n    \"\"\"\n    Solves the problem by running three predefined test cases and\n    comparing convolution and cross-correlation under different boundary models.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # (N, x_list, h_list)\n        (5, [3, 1, 4, 1, 5], [2, 5, 7, 7, 5]),\n        (5, [2, 1, 0, 4, 3], [1, 2, 3, 2, 1]),\n        (6, [0, 1, 0, 2, 0, 3], [4, 4, 4, 4, 4, 4]),\n    ]\n\n    results = []\n    tolerance = 1e-12\n\n    for N, x_list, h_list in test_cases:\n        x = np.array(x_list, dtype=float)\n        h = np.array(h_list, dtype=float)\n\n        # 1. Circular operations\n        y_circ = circular_convolution(x, h)\n        r_circ = circular_cross_correlation(x, h)\n        \n        # Check for circular equality\n        circ_diff = np.max(np.abs(y_circ - r_circ))\n        is_circ_equal = circ_diff < tolerance\n\n        # 2. Linear operations\n        # Linear convolution\n        y_lin = np.convolve(x, h, mode='full')\n        \n        # Linear cross-correlation via convolution with flipped kernel\n        # h_flipped[m] = h[N_h - 1 - m] is equivalent to h[::-1]\n        h_flipped = h[::-1]\n        r_lin = np.convolve(x, h_flipped, mode='full')\n\n        # Check for linear equality\n        lin_diff = np.max(np.abs(y_lin - r_lin))\n        is_lin_equal = lin_diff < tolerance\n\n        results.append([is_circ_equal, is_lin_equal])\n\n    # Format the output string as per the requirement: [[b1,b2],[b3,b4],...] with no spaces.\n    # str(True) -> 'True', str(False) -> 'False'\n    result_str = \",\".join([f\"[{b1},{b2}]\" for b1, b2 in results])\n    print(f\"[{result_str}]\")\n\nsolve()\n```", "id": "3114298"}, {"introduction": "Moving from fundamental definitions to practical applications, this exercise demonstrates how convolution serves as a powerful filtering tool in digital signal processing. You will tackle the critical problem of aliasing, an artifact that arises when a signal is downsampled without proper preparation [@problem_id:3114347]. This practice requires you to analyze signals in the frequency domain, apply the Nyquist criterion for decimation by a factor $M$ ($|\\omega| \\le \\pi/M$), and design your own anti-aliasing filter to prevent spectral overlap, solidifying the link between time-domain operations and their frequency-domain consequences.", "problem": "A discrete-time system is defined by linear convolution of an input sequence and a finite impulse response followed by downsampling by an integer stride. Consider the following general setting. Let the input be a real, finite-length sequence $x[n]$ composed of a sum of cosines with specified angular frequencies in radians per sample and fixed phases. Let the intermediate output be $u[n] = (x * h_{\\text{task}})[n]$, where $*$ denotes linear convolution and $h_{\\text{task}}[n]$ is a fixed, short impulse response. The strided output is $y[m] = u[mM]$, where $M$ is an integer downsampling factor. Angles are to be interpreted in radians per sample. No physical units are involved beyond dimensionless discrete-time indexing.\n\nYour task is to analyze the aliasing that occurs due to downsampling and to demonstrate how anti-aliasing prefiltering can prevent it. Begin from the core definitions of discrete-time convolution, the discrete-time Fourier transform, and the sampling relation between time-domain decimation and frequency-domain spectral replication. Do not use any shortcut formulas not derivable from these bases.\n\nYou must implement a program that, for each test case, performs the following computations and returns a quantitative decision:\n\n1. Construct $x[n]$ as a sum of cosines with given angular frequencies $\\{\\omega_k\\}$ (in radians per sample), amplitudes $\\{A_k\\}$, and phases $\\{\\phi_k\\}$. Use $A_k = 1$ for all components and $\\phi_k = 0$ for all components, and let the sequence length be $N = 4096$ samples. Use indices $n = 0, 1, \\dots, N-1$.\n2. Perform linear convolution with a fixed impulse response $h_{\\text{task}}[n]$ to obtain $u[n] = (x * h_{\\text{task}})[n]$, and define the strided output as $y[m] = u[mM]$, where $M$ is the given integer downsampling factor.\n3. Determine whether aliasing will occur in $y[m]$ based on the spectral support of the post-convolution signal prior to downsampling. From first principles, aliasing is absent if the spectral content of $u[n]$ is confined to the baseband region $|\\omega| \\le \\pi/M$. Using this condition, evaluate a boolean decision \"alias before anti-aliasing prefilter\" by checking whether any sinusoidal component of $x[n]$ that survives the convolution with $h_{\\text{task}}[n]$ has $|\\omega_k| > \\pi/M$ with non-negligible magnitude after the convolution. Use a numerical magnitude threshold of $10^{-3}$ to decide \"non-negligible.\" Use a strict inequality $|\\omega_k| > \\pi/M$ (equality is treated as no aliasing).\n4. Design an anti-aliasing prefilter $h_{\\text{aa}}[n]$ as a low-pass finite impulse response with an ideal low-pass prototype windowed by a Hamming window, with length $L = 63$ and cutoff $\\omega_c = 0.9 \\cdot (\\pi/M)$. Cascade $h_{\\text{aa}}[n]$ with $h_{\\text{task}}[n]$ to produce a combined impulse response $h_{\\text{comb}}[n] = (h_{\\text{aa}} * h_{\\text{task}})[n]$. Repeat the aliasing decision of step $3$ using $h_{\\text{comb}}[n]$ instead of $h_{\\text{task}}[n]$ to obtain the boolean decision \"alias after anti-aliasing prefilter.\"\n5. Your program must not read any input and must produce a single line of output aggregating the boolean results for all test cases. The required output format is a single line containing a flat list of booleans in the order specified below, as a comma-separated list enclosed in square brackets (for example, \"[True,False,True,False,True,False]\"). The order is, for each test case in sequence: the first boolean is the \"alias before anti-aliasing prefilter\" decision and the second boolean is the \"alias after anti-aliasing prefilter\" decision.\n\nDefinitions to employ:\n- Discrete-time convolution: $u[n] = \\sum_{k=-\\infty}^{\\infty} x[k] h_{\\text{task}}[n-k]$.\n- Downsampling by $M$: $y[m] = u[mM]$ for integer $M \\ge 2$.\n- Discrete-time Fourier transform: $X(e^{j\\omega}) = \\sum_{n=-\\infty}^{\\infty} x[n] e^{-j \\omega n}$.\n\nUse the following fixed $h_{\\text{task}}[n]$ for all test cases: a $3$-tap symmetric smoothing filter $h_{\\text{task}}[0] = 0.25$, $h_{\\text{task}}[1] = 0.5$, $h_{\\text{task}}[2] = 0.25$.\n\nTest suite:\n- Case $1$: $M = 2$; frequencies $\\{\\omega_k\\} = \\{0.2\\pi, 0.8\\pi\\}$.\n- Case $2$: $M = 3$; frequencies $\\{\\omega_k\\} = \\{\\pi/3\\}$.\n- Case $3$: $M = 4$; frequencies $\\{\\omega_k\\} = \\{0, 0.9\\pi, -0.9\\pi\\}$.\n\nAngle unit specification: all angles are in radians per sample. No physical units are involved.\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, in the order [Case $1$ before, Case $1$ after, Case $2$ before, Case $2$ after, Case $3$ before, Case $3$ after].", "solution": "The problem requires an analysis of aliasing caused by downsampling a discrete-time signal that has been processed by a linear time-invariant (LTI) filter. We must determine if aliasing occurs, then design an anti-aliasing filter, and re-evaluate for aliasing. The decision is based on a precise quantitative criterion.\n\nFirst, we establish the theoretical foundation. The input signal $x[n]$ is a sum of cosines of the form $A_k \\cos(\\omega_k n + \\phi_k)$. Per the problem statement, we use $A_k=1$ and $\\phi_k=0$ for all components $k$. A real-valued sinusoid can be expressed using Euler's formula as a sum of complex exponentials:\n$$\n\\cos(\\omega_k n) = \\frac{1}{2} (e^{j\\omega_k n} + e^{-j\\omega_k n})\n$$\nComplex exponentials are eigenfunctions of LTI systems. When an LTI system with impulse response $h[n]$ and corresponding discrete-time Fourier transform (DTFT) $H(e^{j\\omega})$ is given an input $e^{j\\omega_k n}$, the output is $H(e^{j\\omega_k}) e^{j\\omega_k n}$. The function $H(e^{j\\omega})$ is the system's frequency response, defined as:\n$$\nH(e^{j\\omega}) = \\sum_{n=-\\infty}^{\\infty} h[n] e^{-j\\omega n}\n$$\nBy linearity, the output $u[n]$ from the convolution $u[n] = (x * h)[n]$ with $x[n] = \\sum_k \\cos(\\omega_k n)$ is:\n$$\nu[n] = \\sum_k \\frac{1}{2} \\left[ H(e^{j\\omega_k}) e^{j\\omega_k n} + H(e^{-j\\omega_k}) e^{-j\\omega_k n} \\right]\n$$\nFor a real-valued impulse response $h[n]$, the frequency response exhibits conjugate symmetry, i.e., $H(e^{-j\\omega}) = H^*(e^{j\\omega})$, where $*$ denotes the complex conjugate. Let $H(e^{j\\omega_k}) = |H(e^{j\\omega_k})| e^{j \\angle H(e^{j\\omega_k})}$. The expression for $u[n]$ simplifies to:\n$$\nu[n] = \\sum_k |H(e^{j\\omega_k})| \\cos(\\omega_k n + \\angle H(e^{j\\omega_k}))\n$$\nThis shows that the convolution scales the amplitude of each sinusoidal component by the magnitude of the filter's frequency response at that component's frequency.\n\nThe next stage is downsampling by an integer factor $M$, producing $y[m] = u[mM]$. In the frequency domain, downsampling causes the spectrum of $u[n]$, $U(e^{j\\omega})$, to be replicated and scaled. The spectrum of $y[m]$ is periodic with period $2\\pi$, and one period is formed by summing $M$ shifted and scaled copies of the spectrum of $u[n]$. Aliasing is the overlapping of these replicated spectra. To prevent aliasing, the spectral content of the signal $u[n]$ must be confined to the baseband region $|\\omega| \\le \\pi/M$ before downsampling. This is the Nyquist criterion for decimation.\n\nThe problem defines a quantitative rule for aliasing: aliasing is considered to occur if any input frequency component $\\omega_k$ satisfies two conditions simultaneously:\n$1$. It lies outside the Nyquist band for the downsampled signal: $|\\omega_k| > \\pi/M$.\n$2$. Its amplitude after convolution is non-negligible, defined as $|H(e^{j\\omega_k})| > 10^{-3}$. Note that the input amplitude is $A_k=1$.\n\nWe will perform this analysis in two steps for each test case.\n\n**Step 1: Analysis with the Task Filter $h_{\\text{task}}[n]$**\n\nThe given task filter is $h_{\\text{task}}[n]$ with coefficients $\\{0.25, 0.5, 0.25\\}$ for $n=\\{0, 1, 2\\}$, and $0$ otherwise. Its frequency response is:\n$$\nH_{\\text{task}}(e^{j\\omega}) = 0.25 + 0.5 e^{-j\\omega} + 0.25 e^{-j2\\omega}\n$$\nWe can factor this to analyze its magnitude:\n$$\nH_{\\text{task}}(e^{j\\omega}) = e^{-j\\omega} (0.25 e^{j\\omega} + 0.5 + 0.25 e^{-j\\omega}) = e^{-j\\omega} (0.5 + 0.5 \\cos(\\omega))\n$$\nThe magnitude is $|H_{\\text{task}}(e^{j\\omega})| = |0.5 + 0.5 \\cos(\\omega)|$. For each test case, we identify frequencies $\\omega_k$ where $|\\omega_k| > \\pi/M$ and check if $|H_{\\text{task}}(e^{j\\omega_k})| > 10^{-3}$.\n\n**Step 2: Design and Analysis with the Combined Filter $h_{\\text{comb}}[n]$**\n\nTo mitigate aliasing, we introduce a low-pass anti-aliasing prefilter, $h_{\\text{aa}}[n]$. It is specified as a finite impulse response (FIR) filter of length $L=63$, designed by windowing an ideal low-pass response with a Hamming window. The cutoff frequency is $\\omega_c = 0.9 \\cdot (\\pi/M)$, creating a guard band. The ideal impulse response for cutoff $\\omega_c$ is $h_{\\text{ideal}}[n] = \\frac{\\sin(\\omega_c (n-n_d))}{\\pi(n-n_d)}$ with delay $n_d = (L-1)/2 = 31$. The Hamming window is $w[n] = 0.54 - 0.46 \\cos\\left(\\frac{2\\pi n}{L-1}\\right)$ for $n \\in [0, L-1]$. The anti-aliasing filter is $h_{\\text{aa}}[n] = h_{\\text{ideal}}[n] \\cdot w[n]$.\n\nThis filter is cascaded with the task filter, resulting in a combined impulse response $h_{\\text{comb}}[n] = (h_{\\text{aa}} * h_{\\text{task}})[n]$. The frequency response of the combined filter is the product of the individual responses: $H_{\\text{comb}}(e^{j\\omega}) = H_{\\text{aa}}(e^{j\\omega}) H_{\\text{task}}(e^{j\\omega})$. We then repeat the aliasing check using the magnitude response $|H_{\\text{comb}}(e^{j\\omega})|$ of this new combined filter.\n\n**Evaluation of Test Cases**\n\n**Case 1:** $M=2$, frequencies $\\{\\omega_k\\} = \\{0.2\\pi, 0.8\\pi\\}$.\nThe Nyquist limit is $\\pi/M = \\pi/2 = 0.5\\pi$.\nThe frequency $\\omega_1 = 0.2\\pi$ is within the limit ($|0.2\\pi| \\le 0.5\\pi$), so it does not cause aliasing.\nThe frequency $\\omega_2 = 0.8\\pi$ is outside the limit ($|0.8\\pi| > 0.5\\pi$). We check its magnitude after convolution with $h_{\\text{task}}[n]$.\n$|H_{\\text{task}}(e^{j0.8\\pi})| = |0.5 + 0.5 \\cos(0.8\\pi)| \\approx |0.5 + 0.5(-0.8090)| = |0.5 - 0.4045| = 0.0955$.\nSince $0.0955 > 10^{-3}$, aliasing occurs. The \"before\" decision is **True**.\nNext, we design $h_{\\text{aa}}[n]$ with cutoff $\\omega_c = 0.9 \\cdot (\\pi/2) = 0.45\\pi$. This filter is designed to strongly attenuate frequencies above $0.45\\pi$, including $0.8\\pi$. The combined response $|H_{\\text{comb}}(e^{j0.8\\pi})|$ will be a product of $|H_{\\text{task}}(e^{j0.8\\pi})|$ and $|H_{\\text{aa}}(e^{j0.8\\pi})|$. Since $H_{\\text{aa}}$ is a strong low-pass filter, $|H_{\\text{aa}}(e^{j0.8\\pi})|$ will be very small, ensuring $|H_{\\text{comb}}(e^{j0.8\\pi})| \\le 10^{-3}$. The \"after\" decision is **False**.\n\n**Case 2:** $M=3$, frequency $\\{\\omega_k\\} = \\{\\pi/3\\}$.\nThe Nyquist limit is $\\pi/M = \\pi/3$.\nThe problem requires a strict inequality, $|\\omega_k| > \\pi/M$, to flag a frequency as potentially aliasing. Here, the only frequency is $\\omega_1 = \\pi/3$, which does not satisfy $|\\pi/3| > \\pi/3$. Therefore, according to the specified rule, no component is considered to cause aliasing.\nThe \"before\" decision is **False**.\nSince no frequency meets the aliasing condition to begin with, the same logic applies after introducing the anti-aliasing filter. The \"after\" decision is also **False**.\n\n**Case 3:** $M=4$, frequencies $\\{\\omega_k\\} = \\{0, 0.9\\pi, -0.9\\pi\\}$.\nThe Nyquist limit is $\\pi/M = \\pi/4 = 0.25\\pi$.\nThe DC component $\\omega_1 = 0$ is within the limit.\nThe components $\\omega_2 = 0.9\\pi$ and $\\omega_3 = -0.9\\pi$ are outside the limit, as $| \\pm 0.9\\pi | = 0.9\\pi > 0.25\\pi$. We check the magnitude response at $0.9\\pi$ (due to symmetry, the magnitude at $-0.9\\pi$ is identical).\n$|H_{\\text{task}}(e^{j0.9\\pi})| = |0.5 + 0.5 \\cos(0.9\\pi)| \\approx |0.5 + 0.5(-0.9511)| = |0.5 - 0.4755| = 0.0245$.\nSince $0.0245 > 10^{-3}$, aliasing occurs. The \"before\" decision is **True**.\nNext, we design $h_{\\text{aa}}[n]$ with cutoff $\\omega_c = 0.9 \\cdot (\\pi/4) = 0.225\\pi$. This is a sharp low-pass filter. The frequency $0.9\\pi$ is far into its stopband. The combined filter will heavily attenuate this component, making $|H_{\\text{comb}}(e^{j0.9\\pi})| \\le 10^{-3}$. The \"after\" decision is **False**.\n\nThe final results are therefore: [True, False, False, False, True, False].", "answer": "```python\nimport numpy as np\nfrom scipy.signal import firwin\n\ndef solve():\n    \"\"\"\n    Main function to solve the aliasing analysis problem for all test cases.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    # Each case is a tuple: (downsampling_factor_M, list_of_frequencies_omegas)\n    test_cases = [\n        (2, [0.2 * np.pi, 0.8 * np.pi]),\n        (3, [np.pi / 3]),\n        (4, [0.0, 0.9 * np.pi, -0.9 * np.pi]),\n    ]\n\n    # Global parameters defined in the problem\n    h_task = np.array([0.25, 0.5, 0.25])\n    L_aa = 63  # Length of the anti-aliasing filter\n    magnitude_threshold = 1e-3\n\n    results = []\n\n    def get_freq_response_magnitude(h, omega):\n        \"\"\"\n        Calculates the magnitude of the frequency response of an FIR filter h\n        at a specific angular frequency omega.\n        H(e^jω) = sum(h[n] * e^(-jωn))\n        \"\"\"\n        n = np.arange(len(h))\n        # Direct computation of DTFT at a single frequency\n        complex_response = np.sum(h * np.exp(-1j * n * omega))\n        return np.abs(complex_response)\n\n    # Process each test case\n    for M, omegas in test_cases:\n        nyquist_limit = np.pi / M\n\n        # --- \"Before\" Anti-Aliasing Filter Analysis ---\n        alias_before = False\n        for omega_k in omegas:\n            # Check if the frequency is outside the Nyquist band for downsampling\n            if abs(omega_k) > nyquist_limit:\n                # If so, check if its magnitude after convolution is non-negligible\n                mag = get_freq_response_magnitude(h_task, omega_k)\n                if mag > magnitude_threshold:\n                    alias_before = True\n                    break  # Found one aliasing component, no need to check others\n        results.append(alias_before)\n\n        # --- \"After\" Anti-Aliasing Filter Analysis ---\n        \n        # 1. Design the anti-aliasing filter h_aa\n        # Cutoff frequency, with a 10% safety margin (0.9 factor)\n        omega_c = 0.9 * nyquist_limit\n        # `firwin` requires cutoff to be normalized by pi\n        h_aa = firwin(numtaps=L_aa, cutoff=omega_c / np.pi, window='hamming')\n\n        # 2. Compute the combined impulse response\n        h_comb = np.convolve(h_aa, h_task)\n        \n        # 3. Repeat the aliasing check with the combined filter\n        alias_after = False\n        for omega_k in omegas:\n            if abs(omega_k) > nyquist_limit:\n                mag = get_freq_response_magnitude(h_comb, omega_k)\n                if mag > magnitude_threshold:\n                    alias_after = True\n                    break\n        results.append(alias_after)\n\n    # Format the final output as a comma-separated list of booleans in brackets\n    # Using str(r) directly gives \"True\" or \"False\" with correct capitalization\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "3114347"}, {"introduction": "This final practice integrates your skills to solve a sophisticated and common challenge in computational science: recovering a signal that has been distorted by a known process and corrupted by noise. You will derive and implement the Wiener deconvolution filter, an optimal solution that minimizes the Mean Squared Error (MSE) between the original signal $x$ and your estimate $\\hat{x}$ [@problem_id:3114304]. This capstone exercise will guide you through a complete deblurring workflow, connecting statistical signal properties like the Power Spectral Density (PSD) with frequency-domain filtering to achieve optimal signal restoration.", "problem": "You are given a discrete-time, real-valued, finite-length signal model in which an unknown input $x$ is observed through a linear time-invariant system with impulse response $h$ and contaminated by additive noise $n$, producing $y$ according to $y = x * h + n$, where $*$ denotes discrete convolution. Your task is to derive, from first principles, the frequency-domain filter that minimizes the expected Mean Squared Error (MSE) between the estimate $\\hat{x}$ and the true input $x$, when $x$ and $n$ are wide-sense stationary and mutually independent, and when you are given the Power Spectral Density (PSD) of $x$ and the PSD of $n$. You must then implement the resulting Wiener deconvolution procedure to recover $\\hat{x}$ from $y$, using the Fast Fourier Transform (FFT) to operate in the frequency domain.\n\nBegin your derivation strictly from foundational definitions and principles appropriate to the topic. The permitted bases include: the definition of discrete convolution, the definition of wide-sense stationarity and its link to the autocorrelation and Power Spectral Density via the Fourier transform, the definition of the Mean Squared Error, and independence properties. Do not use or cite any pre-derived Wiener filter formula or intermediate shortcut expressions. Your derivation should establish the structure of the optimal frequency-domain estimator for $x$ based on $y$, the system frequency response $H(\\omega)$, and the spectra $S_{xx}(\\omega)$ and $S_{nn}(\\omega)$.\n\nImplementation requirements:\n- Use circular convolution of length $N$ to ensure that the discrete Fourier transform precisely diagonalizes convolution. For a sequence $x$ and an impulse response $h$ both represented at length $N$, form $y$ as $y = \\mathcal{F}^{-1}\\{\\mathcal{F}\\{x\\} \\cdot \\mathcal{F}\\{h\\}\\} + n$, where $\\mathcal{F}$ denotes the Discrete Fourier Transform and $\\mathcal{F}^{-1}$ its inverse.\n- Construct the frequency-domain deconvolution filter using your derived expression, applied pointwise over the discrete frequency grid $\\omega_k = 2\\pi k / N$ for $k = 0, 1, \\dots, N-1$.\n- Use the known parametric form of $S_{xx}(\\omega)$ when $x$ is an AutoRegressive of order 1 (AR(1)), namely $x[n] = \\phi x[n-1] + w[n]$ with $w[n]$ white Gaussian of variance $\\sigma_w^2$, so that $$S_{xx}(\\omega) = \\frac{\\sigma_w^2}{\\left|1 - \\phi e^{-j\\omega}\\right|^2}.$$ Use $S_{nn}(\\omega) = \\sigma_n^2$ for white Gaussian noise $n$ with variance $\\sigma_n^2$.\n- Generate all random sequences with fixed seeds as specified for reproducibility.\n\nTest suite and parameters:\nImplement your program to run the following three test cases without any user input. In each case, all sequences are of length $N$ and circular convolution is used.\n\n$1.$ Case A (moderate blur and moderate noise):\n- $N = 256$.\n- Input $x$ is AR($1$) with parameter $\\phi = 0.9$ and driving noise variance $\\sigma_w^2 = 1.0$.\n- Impulse response $h$ is a circularly symmetric discrete Gaussian kernel on the circle of length $N$ with standard deviation $s = 3.0$ samples, defined by $h[k] = \\exp\\left(-\\frac{1}{2}\\left(\\frac{d(k)}{s}\\right)^2\\right)$ for $k=0,\\dots,N-1$, where $d(k) = \\min(k, N-k)$, and normalized so that $\\sum_{k=0}^{N-1} h[k] = 1$.\n- Additive noise $n$ is white Gaussian with variance $\\sigma_n^2 = 0.2$.\n- Random seeds: use seed $x\\_seed = 0$ when generating the AR($1$) input and seed $n\\_seed = 10$ when generating the additive noise.\n\n$2.$ Case B (identity system and very low noise):\n- $N = 128$.\n- Input $x$ is AR($1$) with parameter $\\phi = 0.6$ and driving noise variance $\\sigma_w^2 = 1.0$.\n- Impulse response $h$ is the discrete delta, i.e., $h[0] = 1$ and $h[k] = 0$ for $k \\neq 0$.\n- Additive noise $n$ is white Gaussian with variance $\\sigma_n^2 = 0.01$.\n- Random seeds: use seed $x\\_seed = 1$ for the AR($1$) input and seed $n\\_seed = 11$ for the additive noise.\n\n$3.$ Case C (near-notched system and high noise):\n- $N = 512$.\n- Input $x$ is AR($1$) with parameter $\\phi = 0.95$ and driving noise variance $\\sigma_w^2 = 1.0$.\n- Impulse response $h$ is two-tap with $h[0] = 1$ and $h[1] = -0.95$, and $h[k] = 0$ for $k \\ge 2$.\n- Additive noise $n$ is white Gaussian with variance $\\sigma_n^2 = 0.5$.\n- Random seeds: use seed $x\\_seed = 2$ for the AR($1$) input and seed $n\\_seed = 12$ for the additive noise.\n\nFor each case, generate $x$ by simulating the AutoRegressive of order 1 recursion $x[n] = \\phi x[n-1] + w[n]$ for $n = 0,\\dots,N-1$ with $x[0] = w[0]$ and $w[n]$ independent and identically distributed Gaussian samples with variance $\\sigma_w^2$. Generate $n$ as independent Gaussian samples with variance $\\sigma_n^2$. Construct $y$ via circular convolution at length $N$ and add $n$. Compute $\\hat{x}$ via your derived Wiener deconvolution filter using the known $S_{xx}(\\omega)$ and $S_{nn}(\\omega)$ at the discrete frequency grid.\n\nQuantifiable answers:\nFor each test case, compute the realized Mean Squared Error (MSE) between the estimate and the true input, $$\\text{MSE} = \\frac{1}{N}\\sum_{n=0}^{N-1}\\left(\\hat{x}[n] - x[n]\\right)^2,$$ and report these three MSE values.\n\nFinal output format:\nYour program should produce a single line of output containing the three MSE values in the order Case A, Case B, C, as a comma-separated list enclosed in square brackets, with each value rounded to six decimal places (e.g., $[\\text{mse\\_A},\\text{mse\\_B},\\text{mse\\_C}]$).", "solution": "The problem is to derive and implement the optimal linear filter for estimating a signal $x$ from a measurement $y$, which is the result of convolving $x$ with a system response $h$ and adding noise $n$. The model is given by $y = x * h + n$, where $*$ denotes discrete convolution. The optimality criterion is the minimization of the Mean Squared Error (MSE) between the true signal $x$ and its estimate $\\hat{x}$.\n\nOur derivation proceeds from first principles, assuming that the signal $x$ and noise $n$ are real-valued, wide-sense stationary (WSS) random processes, and that they are mutually independent with zero mean. We are given their Power Spectral Densities (PSDs), denoted $S_{xx}(\\omega)$ and $S_{nn}(\\omega)$, respectively.\n\nLet the estimate $\\hat{x}$ be formed by applying a linear time-invariant (LTI) filter with impulse response $g$ to the observed signal $y$.\n$$\n\\hat{x}[k] = (g * y)[k] = \\sum_{m} g[k-m] y[m]\n$$\nThe estimation error is defined as $e[k] = x[k] - \\hat{x}[k]$. Our objective is to find the filter $g$ that minimizes the MSE, which for a WSS process is the expected value of the squared error, independent of the time index $k$.\n$$\n\\text{MSE} = J = E\\left[ e[k]^2 \\right]\n$$\nWe begin by expressing the error $e[k]$ in terms of the input signals and system responses.\n$$\ne[k] = x[k] - (g * y)[k] = x[k] - (g * (x * h + n))[k]\n$$\nUsing the linearity and associativity of convolution, we get:\n$$\ne[k] = x[k] - (g * h * x)[k] - (g * n)[k]\n$$\nThe MSE is the variance of the error signal, $J = E[e[k]^2]$. For WSS processes, the average power of a signal is given by its autocovariance at lag zero, $R_{ee}[0]$. By the Wiener-Khinchin theorem, this is related to the integral of its PSD, $S_{ee}(\\omega)$.\n$$\nJ = R_{ee}[0] = \\frac{1}{2\\pi} \\int_{-\\pi}^{\\pi} S_{ee}(\\omega) \\,d\\omega\n$$\nTo minimize $J$, we can equivalently minimize the error PSD, $S_{ee}(\\omega)$, for each frequency $\\omega$. This is possible because the integrand is non-negative. We transition to the frequency domain using the Fourier Transform, which diagonalizes convolution for LTI systems. Let $\\mathcal{F}$ denote the Fourier Transform operator. Let $X(\\omega)$, $H(\\omega)$, $N(\\omega)$, $G(\\omega)$, and $E(\\omega)$ be the Fourier transforms of $x[k]$, $h[k]$, $n[k]$, $g[k]$, and $e[k]$, respectively.\n\nThe frequency-domain representation of the error is:\n$$\nE(\\omega) = X(\\omega) - G(\\omega) \\left( X(\\omega)H(\\omega) + N(\\omega) \\right)\n$$\nRearranging the terms, we get:\n$$\nE(\\omega) = X(\\omega) \\left( 1 - G(\\omega)H(\\omega) \\right) - G(\\omega)N(\\omega)\n$$\nThe PSD of the error, $S_{ee}(\\omega)$, is the expected value of the squared magnitude of its Fourier transform, $E(\\omega)$. For a discrete-time process of length $N$, this is formally defined as $S_{ee}(\\omega_k) = E[|E(\\omega_k)|^2]$.\n$$\nS_{ee}(\\omega) = E\\left[ \\left| X(\\omega) \\left( 1 - G(\\omega)H(\\omega) \\right) - G(\\omega)N(\\omega) \\right|^2 \\right]\n$$\nExpanding the magnitude squared term $|A-B|^2 = (A-B)(A-B)^* = |A|^2 - AB^* - A^*B + |B|^2$:\n$$\nS_{ee}(\\omega) = E\\left[ |X(\\omega)|^2 |1 - G(\\omega)H(\\omega)|^2 - X(\\omega)(1-G(\\omega)H(\\omega))G(\\omega)^*N(\\omega)^* - X(\\omega)^*(1-G(\\omega)H(\\omega))^*G(\\omega)N(\\omega) + |G(\\omega)|^2|N(\\omega)|^2 \\right]\n$$\nWe apply the expectation operator to each term. Since $x$ and $n$ are mutually independent and have zero mean, the cross-terms involving products of $X(\\omega)$ and $N(\\omega)$ have an expectation of zero. For instance, $E[X(\\omega)N(\\omega)^*] = E[X(\\omega)]E[N(\\omega)^*] = 0 \\cdot 0 = 0$.\nThis simplifies the expression significantly:\n$$\nS_{ee}(\\omega) = E\\left[ |X(\\omega)|^2 \\right] |1 - G(\\omega)H(\\omega)|^2 + |G(\\omega)|^2 E\\left[ |N(\\omega)|^2 \\right]\n$$\nBy definition, $S_{xx}(\\omega) = E[|X(\\omega)|^2]$ and $S_{nn}(\\omega) = E[|N(\\omega)|^2]$. Thus, the error PSD is:\n$$\nS_{ee}(\\omega) = S_{xx}(\\omega) |1 - G(\\omega)H(\\omega)|^2 + S_{nn}(\\omega) |G(\\omega)|^2\n$$\nOur goal is to find the complex-valued filter response $G(\\omega)$ that minimizes this expression for each $\\omega$. Let's expand the terms, temporarily omitting the dependence on $\\omega$ for clarity:\n$$\nS_{ee} = S_{xx} (1 - GH)(1 - G^*H^*) + S_{nn} GG^*\n$$\n$$\nS_{ee} = S_{xx} (1 - G^*H^* - GH + |G|^2|H|^2) + S_{nn} |G|^2\n$$\n$$\nS_{ee} = S_{xx} - S_{xx}G^*H^* - S_{xx}GH + |G|^2 \\left( S_{xx}|H|^2 + S_{nn} \\right)\n$$\nTo find the minimum with respect to the complex variable $G$, we can use Wirtinger calculus and set the derivative with respect to $G^*$ to zero, treating $G$ and $G^*$ as independent variables.\n$$\n\\frac{\\partial S_{ee}}{\\partial G^*} = -S_{xx}H^* + G \\left( S_{xx}|H|^2 + S_{nn} \\right)\n$$\nSetting this derivative to zero gives the optimal filter $G$:\n$$\n-S_{xx}H^* + G_{opt} \\left( S_{xx}|H|^2 + S_{nn} \\right) = 0\n$$\nSolving for $G_{opt}$:\n$$\nG_{opt}(\\omega) = \\frac{S_{xx}(\\omega)H(\\omega)^*}{S_{xx}(\\omega)|H(\\omega)|^2 + S_{nn}(\\omega)}\n$$\nThis is the celebrated Wiener deconvolution filter. The numerator term $S_{xx}(\\omega)H(\\omega)^*$ attempts to invert the system, weighted by the signal's power. The denominator is the PSD of the observed signal $y$, since $S_{yy}(\\omega) = E[|X(\\omega)H(\\omega)+N(\\omega)|^2] = S_{xx}(\\omega)|H(\\omega)|^2 + S_{nn}(\\omega)$, using the independence of $x$ and $n$. The filter can be rewritten as:\n$$\nG_{opt}(\\omega) = \\frac{1}{H(\\omega)} \\frac{S_{xx}(\\omega)|H(\\omega)|^2}{S_{xx}(\\omega)|H(\\omega)|^2 + S_{nn}(\\omega)} = \\frac{1}{H(\\omega)} \\frac{\\text{SNR}(\\omega) \\cdot |H(\\omega)|^2}{\\text{SNR}(\\omega) \\cdot |H(\\omega)|^2 + 1}\n$$\nwhere $\\text{SNR}(\\omega) = S_{xx}(\\omega)/S_{nn}(\\omega)$. This form shows that the filter approximates the inverse filter $1/H(\\omega)$ at frequencies where the signal-to-noise ratio is high, and attenuates the output at frequencies where the SNR is low, thus preventing noise amplification.\n\nFor the implementation, we use the discrete versions of these formulas. The continuous frequency $\\omega$ is replaced by discrete frequencies $\\omega_k = 2\\pi k/N$ for $k \\in \\{0, 1, \\dots, N-1\\}$. The Fourier transforms become Discrete Fourier Transforms (DFTs), which are computed using the Fast Fourier Transform (FFT) algorithm.\nThe frequency response of the system, $H(\\omega_k)$, is given by the FFT of the impulse response $h[n]$. The PSDs $S_{xx}(\\omega_k)$ and $S_{nn}(\\omega_k)$ are evaluated at these discrete frequencies.\n- For the AR($1$) process $x[n]=\\phi x[n-1]+w[n]$, the PSD is $S_{xx}(\\omega) = \\frac{\\sigma_w^2}{|1 - \\phi e^{-j\\omega}|^2}$.\n- For white noise $n[n]$, the PSD is constant: $S_{nn}(\\omega) = \\sigma_n^2$.\n\nThe implementation steps are as follows:\n1.  Generate the true signal $x[n]$ and additive noise $n[n]$ according to the given parameters and random seeds.\n2.  Define the impulse response $h[n]$ for the given case.\n3.  Compute the observed signal $y[n]$ using circular convolution via FFT: $y = \\mathcal{F}^{-1}\\{\\mathcal{F}\\{x\\} \\cdot \\mathcal{F}\\{h\\}\\} + n$.\n4.  Compute the frequency response $H[k] = \\mathcal{F}\\{h[n]\\}$.\n5.  Evaluate the PSDs $S_{xx}[k]$ and $S_{nn}[k]$ at discrete frequencies $\\omega_k$.\n6.  Construct the Wiener filter in the frequency domain: $G[k] = \\frac{S_{xx}[k]H[k]^*}{S_{xx}[k]|H[k]|^2 + S_{nn}[k]}$.\n7.  Apply the filter to the observed signal in the frequency domain: $\\hat{X}[k] = G[k] \\cdot \\mathcal{F}\\{y[n]\\}$.\n8.  Transform the estimate back to the time domain: $\\hat{x}[n] = \\mathcal{F}^{-1}\\{\\hat{X}[k]\\}$.\n9.  Compute the realized MSE: $\\frac{1}{N}\\sum_{n=0}^{N-1} (\\hat{x}[n] - x[n])^2$.\nThis procedure is repeated for all three test cases specified.", "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Derives and implements the Wiener deconvolution filter for three test cases.\n    \"\"\"\n\n    def generate_ar1(N, phi, sigma_w_sq, seed):\n        \"\"\"Generates a single realization of an AR(1) process.\"\"\"\n        rng = np.random.default_rng(seed)\n        sigma_w = np.sqrt(sigma_w_sq)\n        w = rng.normal(scale=sigma_w, size=N)\n        x = np.zeros(N)\n        # Per problem spec: x[0] = w[0].\n        # Note: This makes the process not strictly stationary at the start.\n        x[0] = w[0]\n        for n in range(1, N):\n            x[n] = phi * x[n-1] + w[n]\n        return x\n\n    def run_case(N, phi, sigma_w_sq, h_def, sigma_n_sq, x_seed, n_seed):\n        \"\"\"\n        Runs a single deconvolution test case.\n\n        Args:\n            N (int): Signal length.\n            phi (float): AR(1) parameter for the input signal x.\n            sigma_w_sq (float): Driving noise variance for x.\n            h_def (tuple): Definition of the impulse response h.\n            sigma_n_sq (float): Variance of the additive white noise n.\n            x_seed (int): Random seed for generating x.\n            n_seed (int): Random seed for generating n.\n\n        Returns:\n            float: The mean squared error between the estimated signal and the true signal.\n        \"\"\"\n        # 1. Generate signals\n        x_true = generate_ar1(N, phi, sigma_w_sq, x_seed)\n        \n        rng_n = np.random.default_rng(n_seed)\n        noise = rng_n.normal(scale=np.sqrt(sigma_n_sq), size=N)\n\n        # 2. Define impulse response h\n        h = np.zeros(N)\n        htype, params = h_def\n        if htype == 'gaussian':\n            s = params['s']\n            k = np.arange(N)\n            d = np.minimum(k, N - k)\n            h = np.exp(-0.5 * (d / s)**2)\n            h /= np.sum(h) # Normalize\n        elif htype == 'delta':\n            h[0] = 1.0\n        elif htype == 'two-tap':\n            h[0] = 1.0\n            h[1] = -0.95\n\n        # 3. Create observed signal y = x * h + n using circular convolution\n        X_true_fft = np.fft.fft(x_true)\n        H_fft = np.fft.fft(h)\n        y_conv = np.real(np.fft.ifft(X_true_fft * H_fft))\n        y_obs = y_conv + noise\n\n        # 4. Construct the Wiener filter G\n        # Discrete frequencies\n        omega_k = (2 * np.pi / N) * np.arange(N)\n        \n        # PSD of AR(1) signal x\n        S_xx = sigma_w_sq / np.abs(1 - phi * np.exp(-1j * omega_k))**2\n        \n        # PSD of white noise n\n        S_nn = np.full(N, sigma_n_sq)\n        \n        # Wiener filter G in the frequency domain\n        G_numerator = S_xx * np.conj(H_fft)\n        G_denominator = S_xx * np.abs(H_fft)**2 + S_nn\n        G_fft = G_numerator / G_denominator\n\n        # 5. Apply the filter to estimate x\n        Y_obs_fft = np.fft.fft(y_obs)\n        X_hat_fft = G_fft * Y_obs_fft\n        x_hat = np.real(np.fft.ifft(X_hat_fft))\n\n        # 6. Calculate realized MSE\n        mse = np.mean((x_hat - x_true)**2)\n        \n        return mse\n\n    # --- Test Cases ---\n    test_cases = [\n        # Case A: Moderate blur, moderate noise\n        {\n            \"N\": 256, \"phi\": 0.9, \"sigma_w_sq\": 1.0,\n            \"h_def\": ('gaussian', {'s': 3.0}),\n            \"sigma_n_sq\": 0.2, \"x_seed\": 0, \"n_seed\": 10\n        },\n        # Case B: Identity system, very low noise\n        {\n            \"N\": 128, \"phi\": 0.6, \"sigma_w_sq\": 1.0,\n            \"h_def\": ('delta', {}),\n            \"sigma_n_sq\": 0.01, \"x_seed\": 1, \"n_seed\": 11\n        },\n        # Case C: Near-notched system, high noise\n        {\n            \"N\": 512, \"phi\": 0.95, \"sigma_w_sq\": 1.0,\n            \"h_def\": ('two-tap', {}),\n            \"sigma_n_sq\": 0.5, \"x_seed\": 2, \"n_seed\": 12\n        }\n    ]\n\n    results = []\n    for case in test_cases:\n        mse = run_case(**case)\n        results.append(mse)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(f'{m:.6f}' for m in results)}]\")\n\nsolve()\n```", "id": "3114304"}]}