{"hands_on_practices": [{"introduction": "The primary motivation for using the Fast Fourier Transform (FFT) algorithm is its incredible efficiency compared to a direct implementation of the Discrete Fourier Transform (DFT). This practice moves beyond the abstract comparison of $O(N^2)$ versus $O(N \\log_2 N)$ complexity to make this advantage tangible. By calculating the precise number of arithmetic operations under a clear set of assumptions ([@problem_id:3282537]), you will quantify the staggering computational savings the FFT provides even for a moderately sized signal, solidifying your understanding of why it is a cornerstone of modern digital signal processing.", "problem": "A software engineer must decide whether to implement the Discrete Fourier Transform (DFT) directly or via the radix-2 Cooley–Tukey Fast Fourier Transform (FFT) for a dataset of size $N=1024$. The engineer measures cost solely by the number of floating-point multiplications, defined as follows:\n- A complex multiplication is implemented naïvely as $4$ real multiplications.\n- Precomputation time for twiddle factors is ignored.\n- No algebraic simplifications of special twiddle values (such as $1$, $-1$, $j$, $-j$) are applied; each appearance of a twiddle factor is treated as a general complex multiplication and counted accordingly.\n\nUsing only the definition of the DFT and the radix-2 decimation principle underlying the Cooley–Tukey FFT, determine the exact difference in the total number of real floating-point multiplications between the direct DFT computation of all $N$ outputs and the radix-2 Cooley–Tukey FFT computation of all $N$ outputs, for $N=1024$. Provide your final answer as an integer; no rounding is required.", "solution": "The problem will be validated by first extracting the given information and then assessing its scientific and logical integrity.\n\n### Step 1: Extract Givens\n- The dataset size is $N=1024$.\n- The cost metric is the total number of real floating-point multiplications.\n- A single complex multiplication is defined to cost $4$ real multiplications.\n- The time to precompute twiddle factors is ignored.\n- No algebraic simplifications for special twiddle factor values (e.g., $1$, $-1$, $j$, $-j$) are considered. Every twiddle factor multiplication is counted as a general complex multiplication.\n- The goal is to find the difference in the total number of real multiplications between a direct Discrete Fourier Transform (DFT) computation and a radix-2 Cooley–Tukey Fast Fourier Transform (FFT) computation.\n\n### Step 2: Validate Using Extracted Givens\n- **Scientifically Grounded:** The problem is a standard exercise in computational complexity analysis, comparing the performance of the DFT and FFT algorithms. This is a fundamental topic in numerical methods and signal processing. The assumptions provided, such as the naïve cost of complex multiplication and the disregard for special-case optimizations, are simplifying but are clearly stated and scientifically consistent for a theoretical analysis.\n- **Well-Posed:** The problem is well-posed. The input size $N=1024$ is a power of $2$ ($N=2^{10}$), which is a requirement for the standard radix-2 Cooley–Tukey algorithm. The cost function is explicitly defined. A unique, integer-valued solution is expected and can be determined from the provided information.\n- **Objective:** The problem statement is objective and uses precise, unambiguous language.\n- **Completeness and Consistency:** The problem is self-contained and provides all necessary data and definitions. There are no contradictions.\n\n### Step 3: Verdict and Action\nThe problem is valid. A complete solution will now be derived.\n\n### Solution Derivation\n\nThe objective is to compute the difference in the number of real floating-point multiplications between the direct DFT and the radix-2 FFT for a signal of length $N=1024$.\n\n**1. Cost of the Direct DFT**\n\nThe Discrete Fourier Transform (DFT) of a sequence $x_n$ of length $N$ is defined by the set of $N$ complex numbers $X_k$:\n$$\nX_k = \\sum_{n=0}^{N-1} x_n e^{-j \\frac{2\\pi kn}{N}} \\quad \\text{for } k = 0, 1, \\dots, N-1\n$$\nLet's analyze the computational cost for a single output coefficient, $X_k$. The calculation involves a sum of $N$ terms. Each term in the sum is of the form $x_n \\cdot e^{-j \\frac{2\\pi kn}{N}}$. This is a product of two complex numbers (the input sample $x_n$, which is complex in the general case, and the twiddle factor $e^{-j \\frac{2\\pi kn}{N}}$). According to the problem statement, we must count each such operation as a general complex multiplication.\n\nTherefore, for each of the $N$ output coefficients $X_k$, we must perform $N$ complex multiplications. The total number of complex multiplications for the direct DFT is thus:\n$$\n\\text{Cost}_{\\text{complex, DFT}} = N \\times N = N^2\n$$\nThe problem specifies that one complex multiplication costs $4$ real multiplications. Thus, the total number of real multiplications for the direct DFT is:\n$$\n\\text{Cost}_{\\text{real, DFT}} = 4 \\times N^2\n$$\n\n**2. Cost of the Radix-2 Cooley–Tukey FFT**\n\nThe radix-2 Cooley–Tukey algorithm is a recursive method for computing the DFT. It works by decomposing a DFT of size $N$ into two DFTs of size $N/2$. Let $C_{\\text{complex}}(N)$ be the number of complex multiplications required for an FFT of size $N$. The recurrence relation is:\n$$\nC_{\\text{complex}}(N) = 2 \\cdot C_{\\text{complex}}(N/2) + (\\text{multiplications in the combination step})\n$$\nThe combination step, or \"butterfly\" stage, computes the final outputs from the outputs of the two sub-problems. For $k = 0, 1, \\dots, N/2 - 1$, the computations are:\n$$\nX_k = E_k + e^{-j \\frac{2\\pi k}{N}} O_k\n$$\n$$\nX_{k+N/2} = E_k - e^{-j \\frac{2\\pi k}{N}} O_k\n$$\nwhere $E_k$ and $O_k$ are the DFTs of the even- and odd-indexed parts of the input signal, respectively.\n\nThe multiplication occurs in the term $e^{-j \\frac{2\\pi k}{N}} O_k$. This multiplication must be performed for each value of $k$ from $0$ to $N/2 - 1$. This amounts to $N/2$ complex multiplications. The problem explicitly states that no simplifications are to be made for special values, so even for $k=0$ (where the twiddle factor is $1$), we must count it as a full complex multiplication.\n\nThus, the recurrence relation becomes:\n$$\nC_{\\text{complex}}(N) = 2 C_{\\text{complex}}(N/2) + \\frac{N}{2}\n$$\nThe base case for the recursion is a DFT of size $N=1$, which is simply the identity ($X_0 = x_0$) and requires $0$ multiplications. So, $C_{\\text{complex}}(1) = 0$.\n\nSince $N$ is a power of $2$, let $N = 2^m$. There are $m = \\log_2(N)$ stages of recursion. At each stage, a total of $N/2$ complex multiplications are performed across all butterfly operations. Therefore, the total number of complex multiplications for the FFT is:\n$$\nC_{\\text{complex, FFT}}(N) = (\\log_2 N) \\times \\frac{N}{2} = \\frac{N}{2} \\log_2(N)\n$$\nThe total number of real multiplications is $4$ times this amount:\n$$\n\\text{Cost}_{\\text{real, FFT}} = 4 \\times \\left(\\frac{N}{2} \\log_2(N)\\right) = 2N \\log_2(N)\n$$\n\n**3. Calculation of the Difference**\n\nWe are asked for the difference in the number of real multiplications between the direct DFT and the FFT. Let this difference be $\\Delta M$.\n$$\n\\Delta M = \\text{Cost}_{\\text{real, DFT}} - \\text{Cost}_{\\text{real, FFT}}\n$$\n$$\n\\Delta M = 4N^2 - 2N \\log_2(N)\n$$\nSubstitute the given value $N = 1024$. We first note that $1024 = 2^{10}$, so $\\log_2(1024) = 10$.\n$$\n\\Delta M = 4(1024)^2 - 2(1024)(10)\n$$\n$$\n\\Delta M = 4(1048576) - 20(1024)\n$$\n$$\n\\Delta M = 4194304 - 20480\n$$\n$$\n\\Delta M = 4173824\n$$\nAlternatively, we can factor the expression before computing:\n$$\n\\Delta M = 2N(2N - \\log_2(N))\n$$\n$$\n\\Delta M = 2(1024)(2(1024) - 10)\n$$\n$$\n\\Delta M = 2048(2048 - 10)\n$$\n$$\n\\Delta M = 2048 \\times 2038\n$$\n$$\n\\Delta M = (2040+8)(2040-2) = 2040^2 - 4080 + 16320 - 16 = 4161600 + 12240 - 16 = 4173840 - 16 = 4173824\n$$\nThe difference in the total number of real floating-point multiplications is $4,173,824$.", "answer": "$$\n\\boxed{4173824}\n$$", "id": "3282537"}, {"introduction": "Beyond its speed, the FFT's power lies in its applications, chief among them being the ability to perform fast convolution for tasks like digital filtering. However, the convolution theorem for the DFT inherently describes a process of *circular* convolution, which differs from the *linear* convolution typically required. This hands-on coding exercise ([@problem_id:3282547]) guides you through an investigation of this crucial distinction, allowing you to observe the \"wrap-around\" artifacts of circular convolution and master the technique of zero-padding to correctly and efficiently compute linear convolution.", "problem": "You are asked to investigate how the periodicity assumption inherent in the Fast Fourier Transform (FFT) algorithm impacts convolution and how zero-padding can mitigate wrap-around artifacts. Work entirely in discrete time. Your program must implement the following, starting from core definitions.\n\nLet a finite-length, nonperiodic discrete-time signal be defined by $x[n] = n + 1$ for $n \\in \\{0,1,\\dots,N-1\\}$ and $x[n] = 0$ otherwise, with $N = 10$. Let a finite-length, nonperiodic averaging kernel be defined by $h[n] = \\frac{1}{M}$ for $n \\in \\{0,1,\\dots,M-1\\}$ and $h[n] = 0$ otherwise, with $M = 4$. Define the linear convolution $y_{\\mathrm{lin}}[n]$ by\n$$\ny_{\\mathrm{lin}}[n] = \\sum_{k=-\\infty}^{\\infty} x[k]\\,h[n-k],\n$$\nwhere $x[n]$ and $h[n]$ are taken to be zero outside their specified supports. This sum is finite and $y_{\\mathrm{lin}}[n]$ has length $N+M-1 = 13$.\n\nDefine the length-$L$ Discrete Fourier Transform (DFT) of a sequence $a[n]$ supported on $\\{0,1,\\dots,L-1\\}$ by\n$$\nA_L[m] = \\sum_{n=0}^{L-1} a[n]\\,e^{-2\\pi j \\frac{mn}{L}},\\quad m=0,1,\\dots,L-1,\n$$\nand its inverse by\n$$\na[n] = \\frac{1}{L}\\sum_{m=0}^{L-1} A_L[m]\\,e^{2\\pi j \\frac{mn}{L}}.\n$$\nFor a given length $L$, form zero-padded versions $x_L[n]$ and $h_L[n]$ by\n$$\nx_L[n] = \\begin{cases}\nx[n],& 0\\le n\\le N-1\\\\\n0,& \\text{otherwise}\n\\end{cases},\\quad\nh_L[n] = \\begin{cases}\nh[n],& 0\\le n\\le M-1\\\\\n0,& \\text{otherwise}\n\\end{cases},\n$$\nfor $n\\in\\{0,1,\\dots,L-1\\}$. Compute the length-$L$ circular convolution\n$$\ny_{\\mathrm{circ},L}[n] = \\sum_{k=0}^{L-1} x_L[k]\\,h_L[(n-k)\\bmod L],\\quad n=0,1,\\dots,L-1,\n$$\nvia pointwise multiplication in the DFT domain using the Fast Fourier Transform (FFT). It is a well-tested fact that the product of DFTs corresponds to circular convolution in the time domain.\n\nTo quantify wrap-around artifacts, define for each $L$ the error\n$$\nE(L) = \\max_{0\\le n \\le L-1} \\left| y_{\\mathrm{circ},L}[n] - y_{\\mathrm{lin},L}[n] \\right|,\n$$\nwhere $y_{\\mathrm{lin},L}[n]$ is the linear convolution $y_{\\mathrm{lin}}[n]$ either truncated to its first $L$ samples if $L \\le N+M-1$, or zero-padded with $L-(N+M-1)$ trailing zeros if $L \\ge N+M-1$. This common comparison length ensures a pointwise error over $L$ samples. The presence of wrap-around artifacts is indicated by $E(L)$ being significantly larger than numerical roundoff.\n\nYour tasks are:\n- Implement the above definitions and compute $E(L)$ for a test suite of padding lengths $L \\in \\{10,12,13,16,64\\}$.\n- Interpret the results to assess three padding strategies $L$: no padding $L=N$, minimal padding $L=N+M-1$, and a power-of-two padding $L=\\min\\{2^p: 2^p\\ge N+M-1\\}$, with an additional oversized padding $L=64$ to probe numerical stability.\n\nYour program should produce a single line of output containing the results as a comma-separated list of floating-point errors in the order of the test suite, enclosed in square brackets, for example, $[e_{10},e_{12},e_{13},e_{16},e_{64}]$ where each $e_L$ is the computed $E(L)$ for that $L$. No other output is permitted.\n\nEnsure that your implementation is self-contained, uses no user input, and adheres to the definitions above. Angles in complex exponentials are in radians by definition. There are no physical units involved. The target audience is advanced undergraduate students in numerical methods and scientific computing.", "solution": "The problem requires an investigation into the use of the Fast Fourier Transform (FFT) to compute the linear convolution of two discrete-time signals. The central principle being examined is the convolution theorem for the Discrete Fourier Transform (DFT), which states that the DFT of a circular convolution of two sequences is the pointwise product of their individual DFTs. Linear convolution can be correctly computed via this method only if the signals are zero-padded to a sufficient length to prevent time-domain aliasing, also known as wrap-around error. This exercise aims to demonstrate and quantify this effect.\n\nThe procedure is structured as follows:\n\nFirst, we define the input signals. The primary signal is a finite-length ramp sequence $x[n] = n + 1$ for $n \\in \\{0, 1, \\dots, N-1\\}$, with $N=10$, and $x[n]=0$ otherwise. The second signal is a finite-length averaging kernel $h[n] = \\frac{1}{M}$ for $n \\in \\{0, 1, \\dots, M-1\\}$, with $M=4$, and $h[n]=0$ otherwise.\n\nSecond, we compute the true linear convolution, denoted $y_{\\mathrm{lin}}[n]$, which serves as our ground truth. It is defined by the convolution sum:\n$$\ny_{\\mathrm{lin}}[n] = \\sum_{k=-\\infty}^{\\infty} x[k]\\,h[n-k]\n$$\nFor a signal of length $N$ and a kernel of length $M$, the resulting sequence $y_{\\mathrm{lin}}[n]$ has a length of $N+M-1$. In this specific case, the length is $10+4-1=13$. This computation is performed directly in the time domain.\n\nThird, for each specified transform length $L$ from the set $\\{10, 12, 13, 16, 64\\}$, we compute the length-$L$ circular convolution, $y_{\\mathrm{circ},L}[n]$. This is accomplished by leveraging the convolution theorem. The steps are:\n1.  Create length-$L$ versions of the input signals, $x_L[n]$ and $h_L[n]$, by zero-padding the original signals $x[n]$ and $h[n]$ to length $L$.\n2.  Compute the length-$L$ DFTs of the padded signals, $X_L[m] = \\text{DFT}\\{x_L[n]\\}$ and $H_L[m] = \\text{DFT}\\{h_L[n]\\}$, using the FFT algorithm for efficiency. The DFT is defined as $A_L[m] = \\sum_{n=0}^{L-1} a[n]\\,e^{-2\\pi j \\frac{mn}{L}}$.\n3.  Perform pointwise multiplication in the frequency domain: $Y_{\\mathrm{circ},L}[m] = X_L[m] \\cdot H_L[m]$.\n4.  Compute the inverse DFT of the product, $y_{\\mathrm{circ},L}[n] = \\text{IDFT}\\{Y_{\\mathrm{circ},L}[m]\\}$, to obtain the circular convolution result in the time domain. The inverse DFT is defined as $a[n] = \\frac{1}{L}\\sum_{m=0}^{L-1} A_L[m]\\,e^{2\\pi j \\frac{mn}{L}}$.\n\nFourth, we quantify the discrepancy between the circular and linear convolutions. A comparison signal, $y_{\\mathrm{lin},L}[n]$, is created from the ground-truth $y_{\\mathrm{lin}}[n]$ by either truncating it or padding it with zeros to match the length $L$. The error for a given length $L$ is then defined as the maximum absolute difference between the two results over all sample points:\n$$\nE(L) = \\max_{0\\le n \\le L-1} \\left| y_{\\mathrm{circ},L}[n] - y_{\\mathrm{lin},L}[n] \\right|\n$$\nA non-negligible value of $E(L)$ indicates the presence of wrap-around artifacts.\n\nThe theoretical basis for this analysis is that the circular convolution computed with length $L$ is equivalent to the linear convolution if and only if $L \\ge N+M-1$.\n- If $L < N+M-1$, the tail of the linear convolution result (which extends to index $N+M-2$) \"wraps around\" and adds to the initial samples of the circular convolution result, causing aliasing. Thus, for $L=10$ and $L=12$, we expect $E(L)$ to be significantly greater than zero.\n- If $L \\ge N+M-1$, there is sufficient padding to contain the entire linear convolution result without wrap-around. In this case, $y_{\\mathrm{circ},L}[n]$ will be identical to $y_{\\mathrm{lin},L}[n]$. Therefore, for $L=13$, $L=16$, and $L=64$, we expect the error $E(L)$ to be on the order of machine floating-point precision.\n\nThe test cases are chosen to illustrate key padding strategies: $L=10$ (insufficient padding), $L=13$ (minimal sufficient padding), and $L=16$ (power-of-two padding, often chosen for FFT efficiency). The $L=64$ case further confirms stability with oversized padding. The implementation calculates $E(L)$ for each of these cases.", "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Computes convolution error E(L) to demonstrate the effect of zero-padding.\n    \"\"\"\n    # Define signal and kernel parameters as per the problem statement.\n    N = 10\n    M = 4\n\n    # Define the discrete-time signal x[n] = n + 1.\n    x = np.arange(1, N + 1, dtype=float)\n\n    # Define the averaging kernel h[n] = 1/M.\n    h = np.ones(M, dtype=float) / M\n\n    # Compute the ground-truth linear convolution y_lin[n].\n    # The length of the result is N + M - 1 = 13.\n    L_lin = N + M - 1\n    y_lin = np.convolve(x, h)\n\n    # Define the test suite of padding lengths L.\n    test_Ls = [10, 12, 13, 16, 64]\n    \n    results = []\n\n    # Iterate through each padding length L to compute the error E(L).\n    for L in test_Ls:\n        # Step 1: Create the comparison linear convolution y_lin_L[n] of length L.\n        # This is done by truncating or padding y_lin to length L.\n        y_lin_L = np.zeros(L)\n        len_to_copy = min(L, L_lin)\n        y_lin_L[:len_to_copy] = y_lin[:len_to_copy]\n\n        # Step 2: Create zero-padded versions of x and h to length L.\n        x_L = np.zeros(L)\n        x_L[:N] = x\n        \n        h_L = np.zeros(L)\n        h_L[:M] = h\n\n        # Step 3: Compute circular convolution via FFT.\n        # This uses the convolution theorem: IDFT{DFT{x} * DFT{h}}.\n        X_L = np.fft.fft(x_L)\n        H_L = np.fft.fft(h_L)\n        Y_circ_L = X_L * H_L\n        y_circ_L = np.fft.ifft(Y_circ_L)\n\n        # Step 4: Calculate the error E(L) as the maximum absolute difference.\n        # np.abs handles the case where y_circ_L has a tiny imaginary part\n        # due to numerical precision.\n        error = np.max(np.abs(y_circ_L - y_lin_L))\n        results.append(error)\n\n    # Print the results in the specified single-line format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "3282547"}, {"introduction": "The FFT is an indispensable tool for spectral analysis, but interpreting its output correctly is a skill in itself. This practice addresses a common point of confusion: the difference between true frequency resolution and the apparent detail provided by the DFT's discrete frequency samples. Through a carefully designed coding experiment ([@problem_id:3127394]), you will see how zero-padding a signal before the FFT can interpolate the spectrum, revealing a smoother plot, but does not improve the fundamental ability to resolve two closely spaced sinusoids, which remains limited by the original signal duration.", "problem": "You are to write a complete, runnable program that uses the Fast Fourier Transform (FFT) algorithm to empirically demonstrate the effect of zero-padding on the interpolation of the Discrete Fourier Transform (DFT), showing that zero-padding of a finite sequence $x_n$ increases apparent frequency resolution (i.e., denser frequency sampling) but does not increase true resolving power (i.e., the ability to separate two closely spaced sinusoids). Begin from the fundamental definition of the Discrete Fourier Transform (DFT) for a finite sequence $x_n$, $n \\in \\{0,1,\\dots,N-1\\}$,\n$$\nX_k = \\sum_{n=0}^{N-1} x_n \\, e^{-j 2\\pi k n / N},\n$$\nand implement its computation using the Fast Fourier Transform (FFT) algorithm. Use a rectangular window of length $N$ implicitly induced by truncation of $x_n$ to $n \\in \\{0,\\dots,N-1\\}$. For zero-padding, define an extended length $M > N$ and consider the DFT\n$$\nX^{(M)}_k = \\sum_{n=0}^{N-1} x_n \\, e^{-j 2\\pi k n / M},\n$$\nwhich samples the same underlying spectrum at a finer grid of $k$ values.\n\nYour program must construct discrete-time signals of the form $x_n = \\sin(2\\pi f_0 n)$ or $x_n = \\sin(2\\pi f_1 n) + \\sin(2\\pi f_2 n)$ with angles in radians, where $f_0, f_1, f_2$ are discrete-time frequencies in cycles per sample and satisfy $0 < f < 1/2$. The sampling rate is $f_s = 1$ sample per unit time, so the unit for frequency is cycles per sample. For single-tone cases, estimate the frequency by selecting the index $k$ of the largest magnitude DFT sample on the positive-frequency half-spectrum and mapping it to $\\hat f = k/M$ (for padded length $M$) or $\\hat f = k/N$ (for unpadded length $N$). Report the absolute estimation error $|\\hat f - f_0|$ in cycles per sample, as a float. For two-tone cases, determine whether two peaks are resolved by counting significant local maxima on the positive-frequency magnitude spectrum: a peak at bin $k$ is significant if it is strictly greater than its immediate neighbors and its magnitude is at least one-half of the largest magnitude on that spectrum. Report resolution as a boolean for the unpadded and zero-padded cases. Angles must be in radians, and all reported frequencies and errors must be in cycles per sample.\n\nImplement the following test suite with the specified parameters:\n\n- Case $1$ (single tone not on a DFT bin):\n  - $N = 128$, $M = 2048$, $f_0 = 0.163$, phase $0$ radians.\n  - Outputs: two floats, the absolute error for the unpadded case and the absolute error for the zero-padded case.\n\n- Case $2$ (two equal-amplitude tones closer than the sequence-length-induced resolution):\n  - $N = 128$, $M = 4096$, $f_1 = 0.200$, $f_2 = 0.200 + \\frac{0.6}{128}$, both amplitudes equal to $1$.\n  - Outputs: two booleans, whether two peaks are resolved in the unpadded case and whether two peaks are resolved in the zero-padded case.\n\n- Case $3$ (two equal-amplitude tones farther apart than the sequence-length-induced resolution):\n  - $N = 128$, $M = 4096$, $f_1 = 0.200$, $f_2 = 0.200 + \\frac{1.2}{128}$, both amplitudes equal to $1$.\n  - Outputs: two booleans, whether two peaks are resolved in the unpadded case and whether two peaks are resolved in the zero-padded case.\n\n- Case $4$ (single tone exactly on a DFT bin):\n  - $N = 128$, $M = 2048$, $f_0 = \\frac{17}{128}$, phase $0$ radians.\n  - Outputs: two floats, the absolute error for the unpadded case and the absolute error for the zero-padded case.\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets. The list must be the concatenation of the outputs of the above cases in order:\n$$\n[\\text{err1\\_unpadded},\\text{err1\\_padded},\\text{res2\\_unpadded},\\text{res2\\_padded},\\text{res3\\_unpadded},\\text{res3\\_padded},\\text{err4\\_unpadded},\\text{err4\\_padded}].\n$$\nAll floats are in cycles per sample, and booleans are expressed in the programming language’s conventional boolean literals.", "solution": "The problem is valid as it is scientifically grounded in the principles of digital signal processing, is well-posed with all necessary parameters and definitions provided, and is objective in its formulation. It presents a standard, non-trivial computational exercise to demonstrate the concepts of frequency resolution and spectral interpolation via zero-padding in the context of the Fast Fourier Transform (FFT).\n\n### Principle-Based Solution\n\nThe core of this problem lies in understanding the properties of the Discrete Fourier Transform (DFT) and how they are affected by the finite length of a signal and the technique of zero-padding.\n\n**1. The Discrete Fourier Transform (DFT)**\n\nFor a finite-length discrete-time signal $x_n$ of length $N$, defined for $n \\in \\{0, 1, ..., N-1\\}$, its DFT, $X_k$, is given by:\n$$\nX_k = \\sum_{n=0}^{N-1} x_n \\, e^{-j 2\\pi k n / N}\n$$\nwhere $k \\in \\{0, 1, ..., N-1\\}$ and $j$ is the imaginary unit. The DFT provides a frequency-domain representation of the signal, sampling its spectrum at $N$ discrete frequency points, $f_k = k/N$, for a sampling rate of $f_s=1$ cycle per sample. The computation is efficiently performed using the Fast Fourier Transform (FFT) algorithm, which has a computational complexity of $O(N \\log N)$ as opposed to the $O(N^2)$ complexity of a direct DFT calculation.\n\n**2. Windowing and Spectral Leakage**\n\nObserving a signal for a finite duration $N$ is equivalent to multiplying an infinitely long signal by a rectangular window of length $N$. In the frequency domain, this multiplication corresponds to a convolution of the signal's true spectrum with the Fourier transform of the rectangular window. The transform of a rectangular window is a sinc function ($\\text{sinc}(f) = \\sin(\\pi f) / (\\pi f)$). This convolution causes the energy from a single sinusoidal frequency to \"leak\" into adjacent frequency bins, a phenomenon known as spectral leakage.\n\nIf a signal's frequency $f_0$ coincides exactly with a DFT bin frequency (i.e., $f_0 = k_0/N$ for some integer $k_0$), all its energy is captured in that single bin (and its negative-frequency counterpart), and there is no leakage. However, if $f_0$ falls between two DFT bins, the peak of the resulting sinc function in the spectrum will also be between bins, and its energy will be spread across all frequency bins. The $N$-point DFT samples this sinc-shaped spectrum at coarse intervals of $1/N$, meaning the measured peak magnitude can be significantly lower than the true peak, and its apparent location will be at the nearest bin, introducing an estimation error.\n\n**3. Zero-Padding and Spectral Interpolation**\n\nZero-padding is the process of appending zeros to the end of a signal sequence before performing the DFT. If we append $M-N$ zeros to our $N$-point sequence $x_n$ to create a new sequence $x'_n$ of length $M > N$, its DFT is:\n$$\nX^{(M)}_k = \\sum_{n=0}^{M-1} x'_n \\, e^{-j 2\\pi k n / M} = \\sum_{n=0}^{N-1} x_n \\, e^{-j 2\\pi k n / M}\n$$\nThis operation does not add new information to the signal. Instead, it computes the DFT at a finer grid of frequencies, $f_k = k/M$. The underlying continuous spectrum (the DTFT, Discrete-Time Fourier Transform) is unchanged, but we are sampling it at $M$ points instead of $N$. This process is a form of spectral interpolation. It provides a \"better-looking\" spectrum by revealing more detail of the underlying sinc-shaped spectral lobes caused by windowing.\n\n**4. Frequency Resolution**\n\nFrequency resolution is the ability to distinguish between two closely spaced frequency components. It is fundamentally determined by the width of the main lobe of the window's transform. For a rectangular window of length $N$, the main lobe width is approximately $2/N$. The Rayleigh criterion suggests that two equal-amplitude sinusoids are resolvable if their frequency separation is at least $\\Delta f \\approx 1/N$.\n\nZero-padding increases the number of DFT bins and thus provides a higher \"apparent\" resolution by sampling the spectrum more densely. However, it does not narrow the main lobes of the spectral components. If two frequencies are so close that their main lobes merge into a single peak, zero-padding will only interpolate that single, merged peak. It does not improve the \"true\" resolving power, which remains limited by the original signal duration $N$.\n\n### Analysis of Test Cases\n\n**Case 1: Single Tone Not on a DFT Bin**\n- $f_0 = 0.163$. For $N=128$, the nearest bin is $k = \\text{round}(0.163 \\times 128) = \\text{round}(20.864) = 21$. The estimated frequency without padding would be $21/128 = 0.1640625$.\n- Zero-padding to $M=2048$ allows for a much finer sampling of the sinc spectrum peak, which is centered at the true frequency $f_0 = 0.163$. The nearest bin will be $k = \\text{round}(0.163 \\times 2048) = \\text{round}(333.824) = 334$. The new estimate is $334/2048 \\approx 0.1630859$. The error will be significantly smaller with zero-padding.\n\n**Case 2: Two Tones Closer Than Resolution Limit**\n- The frequency separation is $\\Delta f = 0.6/128$, which is less than the Rayleigh criterion of $\\approx 1/128$.\n- The main lobes of the two spectral components will be substantially overlapped, creating a single, broader peak in the spectrum.\n- Neither the unpadded $N=128$ DFT nor the zero-padded $M=4096$ DFT will be able to resolve these into two distinct peaks. We expect the resolution test to return `False` for both.\n\n**Case 3: Two Tones Farther Than Resolution Limit**\n- The frequency separation is $\\Delta f = 1.2/128$, which is greater than the Rayleigh criterion. The two main lobes should be sufficiently separated to be distinguishable.\n- In the unpadded $N=128$ case, the coarse sampling of the DFT might still fail to reveal two distinct local maxima if the sample points fall unfavorably.\n- In the zero-padded $M=4096$ case, the fine sampling of the spectrum will almost certainly reveal the two distinct peaks. We expect `False` (or possibly `True`) for the unpadded case and `True` for the padded case, clearly demonstrating the utility of padding for peak visualization.\n\n**Case 4: Single Tone Exactly on a DFT Bin**\n- $f_0 = 17/128$. This frequency is exactly a bin center for the $N=128$ point DFT (at $k=17$).\n- It is also an exact bin center for the $M=2048$ point DFT, since $f_0 = 17/128 = (17 \\times 16) / (128 \\times 16) = 272/2048$ (at $k=272$).\n- In both cases, there is no spectral leakage. The peak will be found at the exact correct bin, resulting in an estimation error of $0.0$ for both the unpadded and padded transforms.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to run the test suite and demonstrate the effects of zero-padding.\n    \"\"\"\n\n    def estimate_single_tone_error(N, M, f0):\n        \"\"\"\n        Calculates frequency estimation error for a single-tone signal.\n        \"\"\"\n        # Generate N-point signal\n        n = np.arange(N)\n        x_n = np.sin(2 * np.pi * f0 * n)\n\n        # --- Unpadded case ---\n        # Compute N-point FFT\n        X_k_unpadded = np.fft.fft(x_n)\n        # Get magnitudes for positive frequencies (k=1 to N/2)\n        # We search from k=1 because f>0\n        mags_unpadded = np.abs(X_k_unpadded[1:N//2 + 1])\n        # Find index of max magnitude (add 1 to map back to original k index)\n        k_max_unpadded = np.argmax(mags_unpadded) + 1\n        f_hat_unpadded = k_max_unpadded / N\n        err_unpadded = abs(f_hat_unpadded - f0)\n\n        # --- Padded case ---\n        # Create zero-padded signal\n        x_n_padded = np.zeros(M)\n        x_n_padded[:N] = x_n\n        # Compute M-point FFT\n        X_k_padded = np.fft.fft(x_n_padded)\n        # Get magnitudes for positive frequencies (k=1 to M/2)\n        mags_padded = np.abs(X_k_padded[1:M//2 + 1])\n        # Find index of max magnitude\n        k_max_padded = np.argmax(mags_padded) + 1\n        f_hat_padded = k_max_padded / M\n        err_padded = abs(f_hat_padded - f0)\n        \n        return err_unpadded, err_padded\n\n    def check_two_tone_resolution(N, M, f1, f2):\n        \"\"\"\n        Determines if two tones are resolved for unpadded and padded FFTs.\n        \"\"\"\n        # Generate N-point signal\n        n = np.arange(N)\n        x_n = np.sin(2 * np.pi * f1 * n) + np.sin(2 * np.pi * f2 * n)\n\n        def count_significant_peaks(spectrum, L):\n            \"\"\"\n            Counts peaks based on the problem's definition.\n            A peak at bin k is significant if it is strictly greater than its\n            immediate neighbors and its magnitude is at least one-half of the\n            largest magnitude on the positive-frequency spectrum.\n            \"\"\"\n            # We only analyze the positive frequency half of the spectrum\n            mags = np.abs(spectrum[1:L//2 + 1])\n            max_mag = np.max(mags)\n            \n            # If max_mag is zero or very small, no peaks\n            if max_mag < 1e-9:\n                return 0\n            \n            peak_count = 0\n            # Iterate from k=2 to L/2-1 to have neighbors k-1 and k+1\n            # The search range is wide enough for the problem's frequencies\n            for k_idx in range(1, len(mags) - 1):\n                # k_idx is index in mags array, k is actual DFT bin index\n                if mags[k_idx] > mags[k_idx - 1] and \\\n                   mags[k_idx] > mags[k_idx + 1] and \\\n                   mags[k_idx] >= 0.5 * max_mag:\n                    peak_count += 1\n            return peak_count\n\n        # --- Unpadded case ---\n        X_k_unpadded = np.fft.fft(x_n, N)\n        peaks_unpadded = count_significant_peaks(X_k_unpadded, N)\n        res_unpadded = (peaks_unpadded >= 2)\n\n        # --- Padded case ---\n        X_k_padded = np.fft.fft(x_n, M)\n        peaks_padded = count_significant_peaks(X_k_padded, M)\n        res_padded = (peaks_padded >= 2)\n\n        return res_unpadded, res_padded\n\n    # Define test cases from the problem statement\n    test_cases = [\n        {'type': 'single', 'N': 128, 'M': 2048, 'f0': 0.163},\n        {'type': 'two', 'N': 128, 'M': 4096, 'f1': 0.200, 'f2': 0.200 + 0.6 / 128},\n        {'type': 'two', 'N': 128, 'M': 4096, 'f1': 0.200, 'f2': 0.200 + 1.2 / 128},\n        {'type': 'single', 'N': 128, 'M': 2048, 'f0': 17.0 / 128},\n    ]\n\n    results = []\n    for case in test_cases:\n        if case['type'] == 'single':\n            err_unpadded, err_padded = estimate_single_tone_error(case['N'], case['M'], case['f0'])\n            results.extend([err_unpadded, err_padded])\n        elif case['type'] == 'two':\n            res_unpadded, res_padded = check_two_tone_resolution(case['N'], case['M'], case['f1'], case['f2'])\n            results.extend([res_unpadded, res_padded])\n            \n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n\n```", "id": "3127394"}]}