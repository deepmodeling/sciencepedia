{"hands_on_practices": [{"introduction": "Before constructing a full solver, it is essential to master the local algebraic relationship that the finite difference method creates at each grid point. This exercise reverses the typical problem-solving direction. Instead of using a source term to find a solution, you will leverage a known discrete solution to deduce the underlying source term, reinforcing your understanding of how the finite difference stencil operates on a general one-dimensional problem [@problem_id:1127150].", "problem": "A one-dimensional boundary value problem is described by the Sturm-Liouville equation:\n$$\n\\frac{d}{dx}\\left(p(x)\\frac{dy}{dx}\\right) + q(x)y = f(x)\n$$\non the domain $x \\in [0, L]$. The functions $p(x)$ and $q(x)$ are given by $p(x) = 1 + \\alpha x^2$ and $q(x) = -\\beta$, where $\\alpha$ and $\\beta$ are positive constants.\n\nThe problem is discretized on a uniform grid with spacing $h$. Let $x_i = i h$ for $i=0, 1, 2, \\dots$ be the grid points, and let $y_i$ be the numerical approximation of the solution $y(x_i)$. The differential operator is approximated using a second-order accurate finite difference scheme at each interior node $x_i$:\n$$\n\\frac{1}{h^2}\\left[p_{i+1/2}(y_{i+1} - y_i) - p_{i-1/2}(y_i - y_{i-1})\\right] + q_i y_i = f_i\n$$\nwhere $p_{i \\pm 1/2} = p(x_i \\pm h/2)$, $q_i = q(x_i)$, and $f_i = f(x_i)$.\n\nSuppose that for the node at $x_k = k h$, the numerical solution has the values $y_{k-1} = A$, $y_k = B$, and $y_{k+1} = C$.\n\nDerive an expression for the value of the source term $f_k = f(x_k)$ in terms of $\\alpha, \\beta, h, k, A, B$, and $C$.", "solution": "We start from the finite-difference approximation at the interior node $x_k$:\n$$\n\\frac{1}{h^2}\\Bigl[p_{k+1/2}(y_{k+1}-y_k)\\;-\\;p_{k-1/2}(y_k-y_{k-1})\\Bigr]+q_k\\,y_k = f_k.\n$$\nSolve for $f_k$:\n$$\nf_k = \\frac{1}{h^2}\\Bigl[p_{k+1/2}(y_{k+1}-y_k) - p_{k-1/2}(y_k-y_{k-1})\\Bigr] + q_k\\,y_k.\n$$\nSubstitute $y_{k-1}=A$, $y_k=B$, $y_{k+1}=C$, $q_k=-\\beta$, and\n$$\np_{k\\pm1/2} = 1 + \\alpha\\bigl(x_k\\pm\\tfrac h2\\bigr)^2\n=1+\\alpha h^2\\bigl(k\\pm\\tfrac12\\bigr)^2.\n$$\nHence\n$$\nf_k\n=\\frac{(1+\\alpha h^2(k+\\tfrac12)^2)(C-B)\\;-\\;(1+\\alpha h^2(k-\\tfrac12)^2)(B-A)}{h^2}\n-\\beta\\,B.\n$$", "answer": "$$\\boxed{\\frac{(1+\\alpha h^2(k+\\tfrac12)^2)(C-B)-(1+\\alpha h^2(k-\\tfrac12)^2)(B-A)}{h^2}-\\beta B}$$", "id": "1127150"}, {"introduction": "A numerical scheme's overall performance is often limited by its least accurate component. This hands-on coding practice illustrates a crucial principle in numerical analysis: the global order of accuracy is dictated by the local truncation error at the boundaries [@problem_id:3127744]. You will implement a finite difference solver and perform an empirical convergence study to see firsthand how a first-order boundary approximation degrades the global accuracy, even when a second-order scheme is used for all interior points.", "problem": "Consider the linear second-order ordinary differential equation boundary value problem (BVP): find a sufficiently smooth function $u(x)$ such that $-u''(x) + u(x) = f(x)$ for $x \\in [0,1]$, subject to mixed boundary conditions consisting of a Robin condition at the left endpoint and a Dirichlet condition at the right endpoint. The Robin boundary condition at $x=0$ is $u'(0) + \\beta\\,u(0) = g$, and the Dirichlet boundary condition at $x=1$ is $u(1) = u_{R}$. Use the exact solution $u(x) = \\sin(\\pi x)$ to define the data consistently: set $f(x) = (\\pi^2 + 1)\\sin(\\pi x)$, choose a fixed parameter $\\beta = 1$, then set $g = u'(0) + \\beta\\,u(0) = \\pi$ and $u_{R} = u(1) = \\sin(\\pi) = 0$. Adopt the finite difference method (FDM) with second-order central differences in the interior derived from Taylor series expansion and the definition of the second derivative. For the Robin boundary at $x=0$, implement two closures: a first-order one-sided derivative approximation and a second-order one-sided derivative approximation derived via Taylor series expansion. Also consider a case with Dirichlet boundary conditions at both ends. For each case, form the discrete linear system and solve for the grid function using a direct method. Quantify the global order of accuracy by computing the empirical convergence rate from refinements of the grid spacing $h = 1/N$ over a sequence of values for $N$. Use the infinity norm of the error, defined on the grid including both endpoints, between the numerical solution and the exact function $u(x)$. The goal is to demonstrate how a first-order truncation at one boundary deteriorates the global accuracy even when the interior scheme is second-order.\n\nFundamental base to use: the definition of the second derivative, Taylor series expansion about a point to derive finite difference approximations, and the definition of truncation error as the difference between the continuous operator applied to $u(x)$ and the discrete operator applied to its grid representation. The empirical convergence rate should be computed as the slope of the error versus grid spacing on a logarithmic scale.\n\nImplement a single program that constructs and solves the discrete system for the following four test cases:\n- Case $1$ (happy path, mixed boundary with first-order left closure): Robin at $x=0$ with the first-order one-sided derivative approximation, Dirichlet at $x=1$, refinement levels $N \\in \\{16,32,64,128\\}$.\n- Case $2$ (mixed boundary with second-order left closure): Robin at $x=0$ with the second-order one-sided derivative approximation, Dirichlet at $x=1$, refinement levels $N \\in \\{16,32,64,128\\}$.\n- Case $3$ (Dirichlet at both ends): Dirichlet at $x=0$ and Dirichlet at $x=1$, refinement levels $N \\in \\{16,32,64,128\\}$.\n- Case $4$ (edge case, mixed boundary with first-order left closure on coarse grids): Robin at $x=0$ with the first-order one-sided derivative approximation, Dirichlet at $x=1$, refinement levels $N \\in \\{4,8,16,32\\}$.\n\nFor each case, compute the empirical global order of accuracy as a single real number by averaging the pairwise rates obtained from consecutive refinements in the sequence. Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, in the order of the cases listed above, with each number rounded to three decimal places (e.g., $[p_1,p_2,p_3,p_4]$). No physical units are involved in this problem; report pure numbers. Angles, if any, should be in radians, but this problem does not involve angles directly. The final answers for the test cases must be real numbers computed by your program.", "solution": "The problem is subjected to validation before a solution is attempted.\n\n### Step 1: Extract Givens\n- **Differential Equation:** $-u''(x) + u(x) = f(x)$ for $x \\in [0,1]$.\n- **Exact Solution:** $u(x) = \\sin(\\pi x)$.\n- **Forcing Function (derived from exact solution):** $f(x) = (\\pi^2 + 1)\\sin(\\pi x)$.\n- **Boundary Conditions (Mixed):**\n    - Robin at $x=0$: $u'(0) + \\beta\\,u(0) = g$, with $\\beta=1$ and $g=\\pi$.\n    - Dirichlet at $x=1$: $u(1) = u_{R}$, with $u_R=0$.\n- **Numerical Method:** Finite Difference Method (FDM) on a uniform grid with $N$ intervals, $h=1/N$.\n    - Interior nodes: Second-order central differences.\n    - Robin boundary at $x=0$: First-order and second-order one-sided approximations for $u'(0)$.\n- **Error Analysis:** Global order of accuracy from empirical convergence rates using the infinity norm of the error, $\\| \\mathbf{U} - \\mathbf{u} \\|_{\\infty}$, over sequences of grid refinements.\n- **Test Cases:**\n    1.  Mixed BC (1st-order Robin closure), $N \\in \\{16,32,64,128\\}$.\n    2.  Mixed BC (2nd-order Robin closure), $N \\in \\{16,32,64,128\\}$.\n    3.  Dirichlet BC at both ends, $N \\in \\{16,32,64,128\\}$.\n    4.  Mixed BC (1st-order Robin closure), $N \\in \\{4,8,16,32\\}$.\n- **Output:** Average empirical rate for each case, rounded to three decimal places, in a list `[p1, p2, p3, p4]`.\n\n### Step 2: Validate Using Extracted Givens\n1.  **Scientific or Factual Unsoundness:** The problem is mathematically sound. The BVP, the use of a given exact solution to ensure consistency, the FDM, and the method of manufactured solutions are all standard and correct concepts in numerical analysis. The derivation of problem data ($f(x)$, $g$, $u_R$) from $u(x)=\\sin(\\pi x)$ is correct:\n    - $u'(x) = \\pi \\cos(\\pi x)$, $u''(x) = -\\pi^2 \\sin(\\pi x)$.\n    - $-u''(x) + u(x) = -(-\\pi^2 \\sin(\\pi x)) + \\sin(\\pi x) = (\\pi^2+1)\\sin(\\pi x) = f(x)$.\n    - $u'(0) + \\beta u(0) = \\pi \\cos(0) + (1)\\sin(0) = \\pi = g$.\n    - $u(1) = \\sin(\\pi) = 0 = u_R$.\n2.  **Well-Posed:** The problem is well-posed. The Helmholtz-type equation with the specified Dirichlet and Robin boundary conditions guarantees the existence of a unique, stable solution.\n3.  **Objective:** The problem is stated in precise, objective mathematical language, free from ambiguity or subjective claims.\n4.  **Completeness:** The problem is self-contained. All necessary equations, parameters, and procedures for the numerical experiment are specified. It correctly implies that standard finite difference formulas must be derived or known.\n5.  **Core Concept Demonstration:** The problem is well-designed to demonstrate a fundamental principle of numerical methods for differential equations: the global order of accuracy is limited by the lowest order of local truncation error in the entire discrete system, which often occurs at the boundaries.\n\n### Step 3: Verdict and Action\nThe problem is **valid** as it constitutes a well-posed, scientifically sound, and standard exercise in computational science. A detailed solution follows.\n\n### Solution\n\nThe task is to solve a linear second-order boundary value problem using the finite difference method and analyze the empirical order of accuracy for different boundary condition implementations.\n\n**1. Discretization of the Domain and Equation**\nThe domain $[0,1]$ is discretized into $N$ uniform intervals of width $h = 1/N$. The grid points are $x_i = ih$ for $i=0, 1, \\dots, N$. Let $U_i$ be the numerical approximation to the exact solution $u(x_i)$.\n\nThe governing ODE is $-u''(x) + u(x) = f(x)$. At an interior grid point $x_i$ (for $i=1, \\dots, N-1$), we approximate the second derivative $u''(x_i)$ using a second-order central difference formula, derived from Taylor series expansions:\n$$ u''(x_i) = \\frac{u(x_{i-1}) - 2u(x_i) + u(x_{i+1})}{h^2} + O(h^2) $$\nSubstituting this into the ODE and replacing $u(x_i)$ with $U_i$ yields the discrete equation for interior nodes:\n$$ -\\frac{U_{i-1} - 2U_i + U_{i+1}}{h^2} + U_i = f(x_i) $$\nRearranging this gives a linear algebraic equation involving three neighboring grid values:\n$$ -U_{i-1} + (2 + h^2)U_i - U_{i+1} = h^2 f(x_i), \\quad \\text{for } i=1, \\dots, N-1 $$\nThese $N-1$ equations form the core of our linear system. The first and last equations of the system are determined by the boundary conditions.\n\n**2. Discretization of Boundary Conditions**\n\n**Cases 1, 2, and 4: Mixed Boundary Conditions**\nThe boundary condition at $x=1$ is a Dirichlet condition, $u(1)=0$, which is implemented exactly as $U_N = 0$. This fixes one of the grid point values.\nThe boundary condition at $x=0$ is a Robin condition, $u'(0) + \\beta u(0) = g$, with $\\beta=1$ and $g=\\pi$. We must approximate the derivative $u'(0)$. The unknowns in the system are $U_0, U_1, \\dots, U_{N-1}$, leading to an $N \\times N$ linear system.\n\n*   **Case 1 & 4 (First-Order Closure):** We use a first-order forward difference to approximate $u'(0)$. The Taylor expansion $u(h) = u(0) + h u'(0) + O(h^2)$ gives:\n    $$ u'(0) = \\frac{u(h) - u(0)}{h} + O(h) $$\n    The discrete Robin condition becomes:\n    $$ \\frac{U_1 - U_0}{h} + \\beta U_0 = g $$\n    With $\\beta=1$, this simplifies to $(h-1)U_0 + U_1 = hg$. This is the first equation (row $0$) of the linear system. The local truncation error of this approximation is $O(h)$, which is expected to dominate the global error, leading to a first-order accurate method.\n\n*   **Case 2 (Second-Order Closure):** To maintain the second-order accuracy of the interior scheme, we use a second-order one-sided approximation for $u'(0)$. This can be derived by combining Taylor expansions for $u(h)$ and $u(2h)$ about $x=0$ to eliminate the $u''(0)$ term and solve for $u'(0)$:\n    $$ u'(0) = \\frac{-3u(0) + 4u(h) - u(2h)}{2h} + O(h^2) $$\n    The discrete Robin condition is:\n    $$ \\frac{-3U_0 + 4U_1 - U_2}{2h} + \\beta U_0 = g $$\n    With $\\beta=1$, this simplifies to $(2h-3)U_0 + 4U_1 - U_2 = 2hg$. This is the first equation of the system. Since all discretizations (interior and boundary) have a local truncation error of at least $O(h^2)$, the global error is expected to be $O(h^2)$.\n\n**Case 3: Dirichlet-Dirichlet Boundary Conditions**\nHere, we have Dirichlet conditions at both ends: $u(0)=0$ and $u(1)=0$. These are implemented exactly as $U_0 = 0$ and $U_N = 0$. The unknowns are the interior points $U_1, \\dots, U_{N-1}$. The system is $(N-1) \\times (N-1)$. For the first interior node $i=1$, the equation is $-U_0 + (2+h^2)U_1 - U_2 = h^2f(x_1)$. Since $U_0=0$, it becomes $(2+h^2)U_1 - U_2 = h^2f(x_1)$. Similarly, for the last interior node $i=N-1$, knowing $U_N=0$ gives $-U_{N-2} + (2+h^2)U_{N-1} = h^2f(x_{N-1})$. The resulting matrix is a symmetric, positive-definite, tridiagonal matrix. The scheme is consistently second-order, so global $O(h^2)$ accuracy is expected.\n\n**3. System Assembly and Solution**\nFor each case, we assemble the matrix $A$ and the right-hand side vector $\\mathbf{b}$ of the system $A\\mathbf{U} = \\mathbf{b}$.\n-   **For Cases 1, 2, 4:** $A$ is an $N \\times N$ matrix, $\\mathbf{U}=[U_0, \\dots, U_{N-1}]^T$. The final solution vector is formed by appending $U_N=0$.\n-   **For Case 3:** $A$ is an $(N-1) \\times (N-1)$ matrix, $\\mathbf{U}=[U_1, \\dots, U_{N-1}]^T$. The final solution vector is formed by prepending $U_0=0$ and appending $U_N=0$.\n\nThe system is solved using a direct linear solver.\n\n**4. Empirical Convergence Rate**\nThe global error is measured in the infinity norm: $E_N = \\max_{0 \\le i \\le N} |U_i - u(x_i)|$. If the method has an order of accuracy $p$, then $E_N \\approx C h^p$ for some constant $C$ and small $h$.\nGiven errors $E_{N_1}$ and $E_{N_2}$ for grids with $N_1$ and $N_2$ intervals, where $N_2 = 2N_1$, the rate $p$ can be estimated as:\n$$ p \\approx \\log_2\\left(\\frac{E_{N_1}}{E_{N_2}}\\right) $$\nThe problem asks for the average of these pairwise rates computed from consecutive refinements in the given sequences of $N$.\n\nThe analysis will demonstrate that the first-order approximation at the boundary in Cases 1 and 4 degrades the global convergence rate to $p \\approx 1$, despite the second-order scheme in the interior. Cases 2 and 3, using exclusively second-order approximations, will exhibit $p \\approx 2$.", "answer": "```python\nimport numpy as np\nimport math\n\ndef solve_bvp(N, case_type):\n    \"\"\"\n    Constructs and solves the finite difference system for the BVP.\n\n    Args:\n        N (int): The number of intervals in the grid.\n        case_type (str): The type of case to solve. One of \n                         'mixed_1st', 'mixed_2nd', 'dirichlet'.\n\n    Returns:\n        float: The infinity norm of the error between the numerical\n               and exact solutions.\n    \"\"\"\n    h = 1.0 / N\n    x_full = np.linspace(0, 1, N + 1)\n\n    # Problem data from the exact solution u(x) = sin(pi*x)\n    pi = np.pi\n    beta = 1.0\n    g = pi\n    u_R = 0.0\n\n    def f(x):\n        return (pi**2 + 1) * np.sin(pi * x)\n\n    exact_solution = np.sin(pi * x_full)\n\n    if case_type == 'dirichlet':\n        num_unknowns = N - 1\n        if num_unknowns <= 0:\n            return np.max(np.abs(np.array([0.0, 0.0]) - np.sin(pi * np.array([0.0, 1.0]))))\n\n        A = np.zeros((num_unknowns, num_unknowns))\n        b = np.zeros(num_unknowns)\n        \n        # Grid for interior points\n        x_interior = x_full[1:-1]\n        \n        # Fill matrix A\n        # Diagonal\n        np.fill_diagonal(A, 2 + h**2)\n        # Off-diagonals\n        np.fill_diagonal(A[1:], -1)\n        np.fill_diagonal(A[:, 1:], -1)\n\n        # Fill vector b\n        b = h**2 * f(x_interior)\n        \n        # Dirichlet conditions are handled by adjusting the RHS,\n        # but here u(0)=0 and u(1)=0, so no adjustments needed.\n        # U_0 = 0, U_N = 0.\n\n        # Solve system\n        U_interior = np.linalg.solve(A, b)\n        U_full = np.concatenate(([0.0], U_interior, [u_R]))\n\n    elif case_type in ('mixed_1st', 'mixed_2nd'):\n        num_unknowns = N\n        A = np.zeros((num_unknowns, num_unknowns))\n        b = np.zeros(num_unknowns)\n        \n        # Interior equations (rows 1 to N-1)\n        for i in range(1, num_unknowns):\n            x_i = x_full[i]\n            if i > 0:\n                A[i, i-1] = -1\n            A[i, i] = 2 + h**2\n            if i < num_unknowns - 1:\n                A[i, i+1] = -1\n            b[i] = h**2 * f(x_i)\n        \n        # Handle U_N = u_R = 0 in the last equation (row N-1)\n        # The term -U_N is 0, so no change to b[N-1] needed.\n\n        # Boundary equation at x=0 (row 0)\n        if case_type == 'mixed_1st':\n            A[0, 0] = h * beta - 1\n            A[0, 1] = 1\n            b[0] = h * g\n        elif case_type == 'mixed_2nd':\n            A[0, 0] = 2 * h * beta - 3\n            A[0, 1] = 4\n            A[0, 2] = -1\n            b[0] = 2 * h * g\n        \n        # Solve system\n        U_unknowns = np.linalg.solve(A, b)\n        U_full = np.concatenate((U_unknowns, [u_R]))\n    \n    else:\n        raise ValueError(\"Invalid case type\")\n        \n    error = np.max(np.abs(U_full - exact_solution))\n    return error\n\ndef compute_avg_rate(case_type, N_list):\n    \"\"\"\n    Computes the average empirical convergence rate for a given case.\n\n    Args:\n        case_type (str): The type of case.\n        N_list (list of int): A sequence of refinement levels N.\n\n    Returns:\n        float: The average convergence rate.\n    \"\"\"\n    errors = [solve_bvp(N, case_type) for N in N_list]\n    rates = []\n    for i in range(len(N_list) - 1):\n        # Assuming N_list[i+1] is a refinement of N_list[i], typically N*2\n        ratio_h = N_list[i] / N_list[i+1]\n        rate = math.log(errors[i] / errors[i+1]) / math.log(1/ratio_h)\n        rates.append(rate)\n    return np.mean(rates)\n\ndef solve():\n    \"\"\"\n    Main function to run all test cases and print the results.\n    \"\"\"\n    # Define test cases\n    case1_N = [16, 32, 64, 128]\n    case2_N = [16, 32, 64, 128]\n    case3_N = [16, 32, 64, 128]\n    case4_N = [4, 8, 16, 32]\n    \n    # Compute rates\n    p1 = compute_avg_rate('mixed_1st', case1_N)\n    p2 = compute_avg_rate('mixed_2nd', case2_N)\n    p3 = compute_avg_rate('dirichlet', case3_N)\n    p4 = compute_avg_rate('mixed_1st', case4_N)\n    \n    results = [p1, p2, p3, p4]\n    \n    # Format and print output\n    formatted_results = [f\"{r:.3f}\" for r in results]\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```", "id": "3127744"}, {"introduction": "While linear problems provide an excellent foundation, many phenomena in science and engineering are inherently nonlinear. This advanced exercise extends your skills to this important class of problems [@problem_id:3127756]. You will discretize a nonlinear boundary value problem, which results in a system of nonlinear algebraic equations, and then implement the powerful Newton's method coupled with a parameter continuation strategy to find and track its solution as a parameter $\\lambda$ varies.", "problem": "Consider the nonlinear Boundary Value Problem (BVP) on the interval $[0,1]$ with homogeneous Dirichlet boundary conditions: find a function $u:[0,1]\\to\\mathbb{R}$ such that $$-u''(x)+\\lambda\\,u(x)^3=f(x),\\quad x\\in(0,1),\\qquad u(0)=0,\\quad u(1)=0,$$ where $f(x)$ is a given source function and $\\lambda\\in\\mathbb{R}$ is a continuation parameter. The goal is to approximate the solution $u(x)$ by a Finite Difference Method (FDM) and to track solution branches as $\\lambda$ varies using discrete Newton continuation.\n\nStart from fundamental base: \n- Approximate the second derivative by the standard central difference that follows from the definition of the derivative, $$u''(x_i)\\approx\\frac{u(x_{i-1})-2u(x_i)+u(x_{i+1})}{h^2},$$ where $x_i$ are grid points and $h$ is the uniform grid spacing.\n- Formulate the discrete nonlinear system by enforcing the differential equation at interior grid points.\n- Use Newton's method, originating from the root-finding principle for nonlinear equations $F(y)=0$, which linearizes the system at each iterate via the Jacobian matrix and solves for the Newton update.\n\nDiscretization details to implement:\n- Use a uniform grid with $N$ interior points, grid spacing $h=\\frac{1}{N+1}$, and interior nodes $x_i=i\\,h$ for $i=1,2,\\dots,N$.\n- Let $u_i\\approx u(x_i)$ and define the discrete residual vector $F(u;\\lambda)\\in\\mathbb{R}^N$ component-wise by $$F_i(u;\\lambda)=\\frac{2u_i-u_{i-1}-u_{i+1}}{h^2}+\\lambda\\,u_i^3-f(x_i),\\quad i=1,\\dots,N,$$ with the convention $u_0=0$ and $u_{N+1}=0$ from the boundary conditions.\n- For the Newton method, use the Jacobian $$J(u;\\lambda)=L+\\operatorname{diag}\\big(3\\lambda\\,u_1^2,\\dots,3\\lambda\\,u_N^2\\big),$$ where $L\\in\\mathbb{R}^{N\\times N}$ is the tridiagonal matrix representing the discrete operator $-\\frac{d^2}{dx^2}$ on the interior nodes, i.e., $L$ has diagonal entries $\\frac{2}{h^2}$ and off-diagonal entries $-\\frac{1}{h^2}$.\n\nContinuation strategy to implement:\n- At $\\lambda=0$, solve the linear system $L\\,u=f$ exactly to obtain an initial solution.\n- For subsequent $\\lambda$ values in a prescribed sequence, use the previously converged solution as the initial guess for Newton's method and iterate to convergence with a suitable stopping criterion.\n\nSource function specification:\n- Use the forcing function $f(x)=\\sin(\\pi x)$, which is smooth and compatible with the boundary conditions.\n\nConvergence and numerical details to implement:\n- Use a tolerance of $10^{-10}$ on the Euclidean norm of the residual for Newton's method convergence.\n- Limit the number of Newton iterations to $50$.\n- Employ a simple backtracking line search on the Newton step length to enhance robustness: if a full Newton step does not reduce the residual norm sufficiently, reduce the step length geometrically until a sufficient decrease is observed or a minimum step length threshold is reached.\n\nTest suite to ensure coverage:\n- Case $1$ (happy path): $N=50$, $\\lambda$ sequence $[0.0,\\,0.5,\\,1.0]$.\n- Case $2$ (coarse grid, stronger nonlinearity): $N=10$, $\\lambda$ sequence $[0.0,\\,2.0]$.\n- Case $3$ (fine grid, moderate nonlinearity): $N=150$, $\\lambda$ sequence $[0.0,\\,1.5]$.\n- Case $4$ (negative parameter branch): $N=50$, $\\lambda$ sequence $[0.0,\\,-1.0]$.\n\nRequired final outputs:\n- For each case, perform discrete Newton continuation along the specified $\\lambda$ sequence. At each $\\lambda$ value, after Newton converges, compute the discrete $\\ell_\\infty$ norm of the solution, i.e., $\\max_i |u_i|$.\n- Aggregate the results from all cases in the order listed above and within each case in the order of the $\\lambda$ sequence.\n- Round each reported $\\ell_\\infty$ norm to $6$ decimal places.\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (e.g., $[r_1,r_2,\\dots]$), where each $r_k$ is a float rounded to $6$ decimal places. No additional text should be printed.", "solution": "The problem requires the numerical solution of a nonlinear boundary value problem (BVP) using the Finite Difference Method (FDM). The resulting system of nonlinear algebraic equations is to be solved using Newton's method. To handle the parameter-dependent nature of the problem, a simple continuation method is employed, where solutions for a sequence of parameter values $\\lambda$ are traced starting from a known solution at $\\lambda=0$.\n\nThe BVP is given by:\n$$\n-u''(x) + \\lambda u(x)^3 = f(x), \\quad x \\in (0, 1)\n$$\nwith homogeneous Dirichlet boundary conditions $u(0)=0$ and $u(1)=0$. The source function is specified as $f(x) = \\sin(\\pi x)$.\n\n**1. Finite Difference Discretization**\n\nWe first discretize the domain $[0,1]$. We introduce a uniform grid with $N$ interior points, defined by the nodes $x_i = i h$ for $i=0, 1, \\dots, N+1$, where $h = \\frac{1}{N+1}$ is the grid spacing. The boundary points are $x_0=0$ and $x_{N+1}=1$. We seek an approximate solution $u_i \\approx u(x_i)$ at the interior grid points $x_i$ for $i=1, \\dots, N$. The vector of unknowns is $u = [u_1, u_2, \\dots, u_N]^T \\in \\mathbb{R}^N$.\n\nThe second derivative $u''(x)$ is approximated at each interior node $x_i$ using the second-order central difference formula:\n$$\nu''(x_i) \\approx \\frac{u(x_{i-1}) - 2u(x_i) + u(x_{i+1})}{h^2} \\approx \\frac{u_{i-1} - 2u_i + u_{i+1}}{h^2}\n$$\nSubstituting this into the differential equation and evaluating it at each interior node $x_i$ yields a system of $N$ algebraic equations:\n$$\n-\\frac{u_{i-1} - 2u_i + u_{i+1}}{h^2} + \\lambda u_i^3 = f(x_i), \\quad i=1, \\dots, N\n$$\nThe boundary conditions $u(0)=0$ and $u(1)=0$ are incorporated by setting $u_0=0$ and $u_{N+1}=0$. The system of equations can be rewritten as:\n$$\n\\frac{2u_i - u_{i-1} - u_{i+1}}{h^2} + \\lambda u_i^3 = f_i, \\quad i=1, \\dots, N\n$$\nwhere $f_i = f(x_i) = \\sin(\\pi x_i)$. This system must be solved for the unknown vector $u$.\n\nWe define a residual function $F: \\mathbb{R}^N \\to \\mathbb{R}^N$, where we seek the root $u$ such that $F(u; \\lambda) = 0$. The $i$-th component of the residual is:\n$$\nF_i(u; \\lambda) = \\frac{2u_i - u_{i-1} - u_{i+1}}{h^2} + \\lambda u_i^3 - f_i\n$$\nThe system can be expressed in a compact matrix-vector form:\n$$\nF(u; \\lambda) = L u + \\lambda u^{\\circ 3} - f = 0\n$$\nHere, $u^{\\circ 3}$ denotes the element-wise cube of the vector $u$, i.e., $(u^{\\circ 3})_i = u_i^3$. The vector $f \\in \\mathbb{R}^N$ has components $f_i = f(x_i)$. The matrix $L \\in \\mathbb{R}^{N \\times N}$ is the discrete representation of the negative second derivative operator $-\\frac{d^2}{dx^2}$ with homogeneous Dirichlet boundary conditions. It is a symmetric, tridiagonal matrix with entries:\n$$\nL_{ij} = \\begin{cases}\n2/h^2 & \\text{if } i=j \\\\\n-1/h^2 & \\text{if } |i-j|=1 \\\\\n0 & \\text{otherwise}\n\\end{cases}\n$$\n\n**2. Newton's Method**\n\nTo solve the nonlinear system $F(u;\\lambda)=0$, we employ Newton's method. Starting with an initial guess $u^{(0)}$, we generate a sequence of iterates $u^{(k)}$ that we hope converge to the solution. The update from $u^{(k)}$ to $u^{(k+1)}$ is given by:\n$$\nu^{(k+1)} = u^{(k)} + \\Delta u^{(k)}\n$$\nwhere the Newton step $\\Delta u^{(k)}$ is the solution to the linear system:\n$$\nJ(u^{(k)}; \\lambda) \\Delta u^{(k)} = -F(u^{(k)}; \\lambda)\n$$\n$J(u^{(k)}; \\lambda)$ is the Jacobian matrix of $F$ with respect to $u$, evaluated at $u^{(k)}$. The entries of the Jacobian are $J_{ij}(u; \\lambda) = \\frac{\\partial F_i}{\\partial u_j}$.\n$$\n\\frac{\\partial F_i}{\\partial u_j} = \\frac{\\partial}{\\partial u_j} \\left( \\frac{2u_i - u_{i-1} - u_{i+1}}{h^2} + \\lambda u_i^3 - f_i \\right) =\n\\begin{cases}\n2/h^2 + 3\\lambda u_i^2 & \\text{if } i=j \\\\\n-1/h^2 & \\text{if } |i-j|=1 \\\\\n0 & \\text{otherwise}\n\\end{cases}\n$$\nThus, the Jacobian matrix is the sum of the constant matrix $L$ and a diagonal matrix dependent on $u$:\n$$\nJ(u; \\lambda) = L + \\operatorname{diag}(3\\lambda u_1^2, 3\\lambda u_2^2, \\dots, 3\\lambda u_N^2)\n$$\nThe Newton iteration terminates when the Euclidean norm of the residual vector falls below a specified tolerance, $\\|F(u^{(k)}; \\lambda)\\|_2  10^{-10}$, or when a maximum number of iterations ($50$) is reached.\n\n**3. Continuation Method and Line Search**\n\nWe use a simple parameter continuation method to find solutions for a sequence of $\\lambda$ values.\n- **Initial Step ($\\lambda=0$):** For $\\lambda_0 = 0$, the BVP becomes linear: $-u''(x)=f(x)$. The discrete system is $L u = f$. This system has a unique solution which can be found by a direct linear solve.\n- **Continuation Step:** For each subsequent parameter value $\\lambda_k$ in the sequence, we use the previously computed solution $u(\\lambda_{k-1})$ as the initial guess $u^{(0)}$ for the Newton's method to find $u(\\lambda_k)$.\n\nTo improve the robustness of Newton's method, especially when the initial guess is far from the solution, we incorporate a backtracking line search. A full Newton step $\\Delta u^{(k)}$ may not decrease the residual norm. The update is therefore modified to $u^{(k+1)} = u^{(k)} + \\alpha \\Delta u^{(k)}$, where $\\alpha \\in (0, 1]$ is a step-size parameter. We start with $\\alpha=1$ and, if the condition $\\|F(u^{(k)} + \\alpha \\Delta u^{(k)})\\|_2 \\ge \\|F(u^{(k)})\\|_2$ holds, we reduce $\\alpha$ by a fixed factor (e.g., $\\alpha \\leftarrow \\alpha/2$) and re-check. This process is repeated until a sufficient decrease in the residual norm is achieved or a minimum step size is reached.\n\n**4. Algorithm Summary**\n\nFor each test case specified by $(N, \\{\\lambda_k\\})$:\n1.  Set grid spacing $h = 1/(N+1)$. Create the grid points $x_i = i h$ for $i=1,\\dots,N$.\n2.  Construct the source vector $f$ with components $f_i = \\sin(\\pi x_i)$.\n3.  Construct the constant tridiagonal matrix $L$.\n4.  Handle $\\lambda_0=0$: Solve the linear system $Lu = f$ to obtain the initial solution $u_{sol}$. Compute and store its discrete $\\ell_\\infty$-norm, $\\max_i |(u_{sol})_i|$.\n5.  Iterate through the remaining $\\lambda_k$ values:\n    a. Use $u_{sol}$ from the previous step as the initial guess $u_{current}$ for Newton's method.\n    b. Start the Newton loop (for $j=0, 1, \\dots, 49$):\n        i.   Compute the residual vector $F_{current} = L u_{current} + \\lambda_k u_{current}^{\\circ 3} - f$.\n        ii.  If $\\|F_{current}\\|_2  10^{-10}$, the method has converged. Break the loop.\n        iii. Compute the Jacobian matrix $J_{current} = L + \\operatorname{diag}(3\\lambda_k u_{current}^{\\circ 2})$.\n        iv.  Solve the linear system $J_{current} \\Delta u = -F_{current}$ for the Newton step $\\Delta u$.\n        v.   Perform backtracking line search to find a suitable step length $\\alpha$.\n        vi.  Update the solution: $u_{current} \\leftarrow u_{current} + \\alpha \\Delta u$.\n    c. The converged solution is the final $u_{current}$. Set $u_{sol} = u_{current}$.\n    d. Compute and store the $\\ell_\\infty$-norm of $u_{sol}$.\n6.  Collect all calculated norms, round them to $6$ decimal places, and format them for the final output.", "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the nonlinear BVP using FDM and Newton continuation for a suite of test cases.\n    \"\"\"\n    test_cases = [\n        (50, [0.0, 0.5, 1.0]),\n        (10, [0.0, 2.0]),\n        (150, [0.0, 1.5]),\n        (50, [0.0, -1.0])\n    ]\n\n    all_results = []\n    \n    for N, lambdas in test_cases:\n        # 1. Grid and problem setup\n        h = 1.0 / (N + 1)\n        x = np.linspace(h, 1.0 - h, N)\n        f = np.sin(np.pi * x)\n\n        # 2. Assemble the discrete Laplacian matrix L\n        diag_val = 2.0 / h**2\n        off_diag_val = -1.0 / h**2\n        L = np.diag(np.full(N, diag_val)) + \\\n            np.diag(np.full(N - 1, off_diag_val), k=1) + \\\n            np.diag(np.full(N - 1, off_diag_val), k=-1)\n\n        # 3. Continuation loop\n        u_sol = None\n        for lambd in lambdas:\n            if lambd == 0.0:\n                # 4. For lambda=0, solve the linear system\n                u_sol = np.linalg.solve(L, f)\n            else:\n                # 5. For lambda != 0, use Newton's method\n                u_current = u_sol.copy()  # Use previous solution as initial guess\n                \n                max_iter = 50\n                tol = 1e-10\n\n                for _ in range(max_iter):\n                    # a. Compute residual F(u)\n                    residual = L @ u_current + lambd * u_current**3 - f\n                    res_norm = np.linalg.norm(residual)\n\n                    if res_norm  tol:\n                        break\n\n                    # b. Compute Jacobian J(u)\n                    jacobian_diag = 3.0 * lambd * u_current**2\n                    jacobian = L + np.diag(jacobian_diag)\n\n                    # c. Solve for Newton step\n                    try:\n                        newton_step = np.linalg.solve(jacobian, -residual)\n                    except np.linalg.LinAlgError:\n                        # Jacobian is singular, convergence fails\n                        # For the purposes of this problem, we can expect this not to happen.\n                        # Marking the result as NaN if it does.\n                        u_current.fill(np.nan)\n                        break\n\n                    # d. Backtracking line search\n                    alpha = 1.0\n                    for _ in range(10): # max 10 backtracking steps\n                        u_next = u_current + alpha * newton_step\n                        next_residual = L @ u_next + lambd * u_next**3 - f\n                        if np.linalg.norm(next_residual)  res_norm:\n                            break\n                        alpha *= 0.5\n                    \n                    u_current = u_current + alpha * newton_step\n                \n                u_sol = u_current\n\n            # 6. Compute and store the l_infinity norm of the solution\n            l_inf_norm = np.max(np.abs(u_sol))\n            all_results.append(round(l_inf_norm, 6))\n\n    # Final print statement in the exact required format\n    print(f\"[{','.join(map(str, all_results))}]\")\n\nsolve()\n```", "id": "3127756"}]}