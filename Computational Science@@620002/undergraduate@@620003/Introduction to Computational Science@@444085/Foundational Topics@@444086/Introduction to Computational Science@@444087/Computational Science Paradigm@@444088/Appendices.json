{"hands_on_practices": [{"introduction": "A cornerstone of the computational science paradigm is verification: ensuring your code correctly implements the intended mathematical model. This practice introduces property-based testing, a powerful automated technique for this purpose. You will implement a numerical model for the heat equation and test it against core physical invariants—conservation, symmetry, and monotonicity—to detect intentional bugs and understand the model's stability conditions [@problem_id:3109343].", "problem": "Design and implement a self-contained program that demonstrates the computational science paradigm of validating scientific code via property-based tests. The program must instantiate a simple, physically motivated numerical model and use randomly generated inputs to test whether core invariants are respected. The model, invariants, and testing strategy are specified below.\n\nModel. Consider the one-dimensional heat equation (also known as the diffusion equation) on a periodic discrete grid with $N$ points, whose continuum form is $u_t = D u_{xx}$, where $u$ denotes a scalar field and $D$ is a diffusion coefficient. Use a standard explicit forward-Euler finite-difference time-advance with a symmetric three-point stencil, periodic boundary conditions, and non-dimensionalized parameters. Define the discrete state as a vector $u \\in \\mathbb{R}^N$ and perform one time step\n$$\nu_i^{\\text{new}} \\;=\\; u_i^{\\text{old}} \\;+\\; \\alpha \\,\\big(u_{i-1}^{\\text{old}} \\;-\\; 2\\,u_i^{\\text{old}} \\;+\\; u_{i+1}^{\\text{old}}\\big)\n$$\nfor all indices $i \\in \\{0,1,\\dots,N-1\\}$ with periodic indexing, that is $u_{-1} \\equiv u_{N-1}$ and $u_{N} \\equiv u_0$. The scalar $\\alpha \\ge 0$ encodes the non-dimensionalized time step and diffusion constant. This model is a canonical instance used across computational science for studying conservation, symmetry, and monotonicity properties.\n\nFundamental base and invariants. The following invariants arise from core physical and mathematical principles and must be used to formulate property-based tests:\n- Conservation of total quantity (mass). For periodic boundaries and the symmetric stencil above, the discrete total $S = \\sum_{i=0}^{N-1} u_i$ should be conserved under the update step, reflecting the physical conservation of mass in the absence of sources and sinks.\n- Symmetry equivariance under spatial reflection. Define the discrete reflection operator $\\mathcal{R}$ by $(\\mathcal{R}u)_i = u_{N-1-i}$. The stencil is symmetric, so performing the step on the reflected state and then reflecting the result should commute:\n$$\n\\text{step}(\\mathcal{R}u) \\;=\\; \\mathcal{R}(\\text{step}(u)).\n$$\n- Monotonicity of the range. For $0 \\le \\alpha \\le \\tfrac{1}{2}$, the update is a nonnegative convex combination of $u_{i-1}$, $u_i$, and $u_{i+1}$; consequently, the discrete range $R(u) = \\max_i u_i - \\min_i u_i$ should be non-increasing under the step (i.e., $R(u^{\\text{new}}) \\le R(u^{\\text{old}})$). This captures the smoothing character of diffusion.\n\nTesting strategy. Implement property-based tests by generating random states $u$ and automatically checking the invariants above. For numerical verification, adopt a tolerance $\\varepsilon = 10^{-10}$ and define violations as follows:\n- Conservation violation if $\\big|\\sum_i u_i^{\\text{new}} - \\sum_i u_i^{\\text{old}}\\big| > \\varepsilon$.\n- Symmetry equivariance violation if $\\max_i \\big|(\\text{step}(\\mathcal{R}u))_i - (\\mathcal{R}(\\text{step}(u)))_i\\big| > \\varepsilon$.\n- Monotonicity violation if $R(u^{\\text{new}}) - R(u^{\\text{old}}) > \\varepsilon$.\n\nDefect injection. To emulate code defects, you must implement two variants of the step:\n- A correct periodic implementation using circular shifts (i.e., periodic neighbors).\n- A buggy implementation that mistakenly uses zero boundary conditions at the ends, that is, neighbors outside $\\{0,\\dots,N-1\\}$ are taken as $0$ instead of wrapping around. This defect should break conservation and symmetry and may also affect monotonicity.\n\nRandom input generation. For each test case, draw $T$ independent random states $u$ with components sampled from a uniform distribution on $[0,1]$. Additionally, if a test case specifies “include zero,” insert one extra trial consisting of the all-zero state $u = 0$ to probe trivial invariant satisfaction. Use the provided seeds for reproducibility.\n\nTest suite. Your program must evaluate the following test cases, each given as a tuple $(N,\\alpha,T,\\text{seed},\\text{mode},\\text{include\\_zero})$:\n- Case $1$: $(64, 0.2, 200, 101, \\text{``correct''}, \\text{True})$.\n- Case $2$: $(64, 0.49, 200, 102, \\text{``correct''}, \\text{True})$.\n- Case $3$: $(64, 0.6, 200, 103, \\text{``correct''}, \\text{False})$.\n- Case $4$: $(64, 0.2, 200, 104, \\text{``buggy''}, \\text{True})$.\n- Case $5$: $(1, 0.2, 50, 105, \\text{``correct''}, \\text{True})$.\n- Case $6$: $(32, 0.2, 200, 106, \\text{``buggy''}, \\text{False})$.\n\nRequired outputs. For each test case, aggregate the number of violations observed over all its trials for the three invariants, in the fixed order: conservation, symmetry equivariance, monotonicity. Express each test case’s result as a list of three integers $[c,s,m]$, where $c$ is the conservation violation count, $s$ is the symmetry equivariance violation count, and $m$ is the monotonicity violation count. Your program must produce a single line of output containing the results for all cases as a comma-separated list enclosed in square brackets, i.e., a Python-style list of lists. The line should therefore represent a list of $6$ elements, each of which is a list of three integers in the order described.\n\nAngle units are not applicable. No physical unit conversion is required.\n\nScientific realism. The model, invariants, and tests arise from widely used numerical analysis and physical principles. The chosen parameters are within plausible ranges. The randomized trials emulate property-based testing common in computational science.\n\nYour solution must derive, implement, and test these properties without relying on shortcut formulas not justified by the fundamental base above. The final answer must be a complete, runnable program that produces the specified single-line output.", "solution": "The problem requires the design and implementation of a property-based testing framework to validate a numerical model of the one-dimensional heat equation. This involves implementing the numerical scheme, formally defining its fundamental invariants, and then systematically testing for violations of these invariants using randomly generated data.\n\n### 1. Numerical Model and Implementations\n\nThe physical system is governed by the heat equation, $u_t = D u_{xx}$, on a periodic domain. We discretize this system on a grid of $N$ points, with the state represented by a vector $u \\in \\mathbb{R}^N$. The time evolution is modeled using an explicit forward-Euler method with a centered three-point stencil for the spatial second derivative. The update rule for each grid point $u_i$ is given by:\n$$\nu_i^{\\text{new}} = u_i^{\\text{old}} + \\alpha \\left(u_{i-1}^{\\text{old}} - 2u_i^{\\text{old}} + u_{i+1}^{\\text{old}}\\right)\n$$\nwhere $\\alpha \\ge 0$ is a non-dimensional parameter combining the time step and diffusion coefficient. Indices are handled periodically, meaning $u_{-1} \\equiv u_{N-1}$ and $u_N \\equiv u_0$.\n\nThis update can be expressed in a vectorized form suitable for numerical computation. The term in the parenthesis is the discrete Laplacian, $\\Delta_d u$.\n\n**Correct Implementation (Periodic Boundaries):**\nFor periodic boundaries, the neighbors of $u_i$ are $u_{(i-1) \\pmod N}$ and $u_{(i+1) \\pmod N}$. This operation can be efficiently implemented using circular shifts on the state vector $u$. Let $u^{\\text{old}}$ be the vector of state values at the previous time step. The new state vector $u^{\\text{new}}$ is:\n$$\nu^{\\text{new}} = u^{\\text{old}} + \\alpha \\left( \\text{shift}(u^{\\text{old}}, 1) - 2u^{\\text{old}} + \\text{shift}(u^{\\text{old}}, -1) \\right)\n$$\nwhere $\\text{shift}(u, k)_i = u_{(i-k) \\pmod N}$. This corresponds to `np.roll` in NumPy.\n\n**Buggy Implementation (Zero Boundaries):**\nA common defect is the incorrect handling of boundary conditions. The buggy implementation assumes zero-flux boundaries by setting ghost-cell values to zero. For $i=0$, the neighbor $u_{-1}$ is taken as $0$. For $i=N-1$, the neighbor $u_N$ is taken as $0$. The update rules at the boundaries become:\n$$\nu_0^{\\text{new}} = u_0^{\\text{old}} + \\alpha \\left(0 - 2u_0^{\\text{old}} + u_1^{\\text{old}}\\right)\n$$\n$$\nu_{N-1}^{\\text{new}} = u_{N-1}^{\\text{old}} + \\alpha \\left(u_{N-2}^{\\text{old}} - 2u_{N-1}^{\\text{old}} + 0\\right)\n$$\nInterior points $i \\in \\{1, \\dots, N-2\\}$ are updated using the standard stencil.\n\n### 2. Invariants and Property-Based Tests\n\nWe validate the implementations against three fundamental properties derived from the underlying physics and mathematics.\n\n**A. Conservation of Total Quantity**\nThis property reflects the conservation of mass or energy in a closed system. The total quantity is the sum $S = \\sum_{i=0}^{N-1} u_i$.\nFor the **correct** periodic implementation, let's sum the update rule over all $i$:\n$$\n\\sum_{i=0}^{N-1} u_i^{\\text{new}} = \\sum_{i=0}^{N-1} u_i^{\\text{old}} + \\alpha \\sum_{i=0}^{N-1} \\left(u_{i-1}^{\\text{old}} - 2u_i^{\\text{old}} + u_{i+1}^{\\text{old}}\\right)\n$$\nThe last term is a discrete telescoping sum under periodic boundaries:\n$$\n\\sum_{i=0}^{N-1} (u_{i-1} - 2u_i + u_{i+1}) = \\sum u_{i-1} - 2\\sum u_i + \\sum u_{i+1} = S^{\\text{old}} - 2S^{\\text{old}} + S^{\\text{old}} = 0\n$$\nThus, $\\sum u_i^{\\text{new}} = \\sum u_i^{\\text{old}}$. The total sum is an invariant.\nFor the **buggy** implementation, the sum of the discrete Laplacian is $\\sum_{i=0}^{N-1} L_i = -u_0 - u_{N-1}$ (as derived via term-by-term summation), which is non-zero in general. Thus, conservation is violated.\nThe test checks if $|\\sum u_i^{\\text{new}} - \\sum u_i^{\\text{old}}| > \\varepsilon$, where $\\varepsilon=10^{-10}$.\n\n**B. Symmetry Equivariance under Spatial Reflection**\nThe reflection operator is defined by $(\\mathcal{R}u)_i = u_{N-1-i}$. The symmetry of the stencil implies that the time-step operation, $\\text{step}(\\cdot)$, should commute with $\\mathcal{R}$: $\\text{step}(\\mathcal{R}u) = \\mathcal{R}(\\text{step}(u))$.\nFor the **correct** implementation, the update at index $i$ on the reflected state $(\\mathcal{R}u)$ depends on $u_{N-1-(i-1)}, u_{N-1-i}, u_{N-1-(i+1)}$. The update on the original state $u$ at index $N-1-i$ depends on $u_{N-1-i-1}, u_{N-1-i}, u_{N-1-i+1}$. Because the coefficients for the $i\\pm1$ neighbors are identical, these two operations yield the same result.\nThe **buggy** implementation breaks this symmetry. The zero boundary condition is applied at index $0$ and $N-1$. When we compute $\\text{step}(\\mathcal{R}u)$, the zero BC is applied to $(\\mathcal{R}u)_0 = u_{N-1}$ and $(\\mathcal{R}u)_{N-1} = u_0$. When we compute $\\mathcal{R}(\\text{step}(u))$, we reflect the result of applying the zero BC to $u_0$ and $u_{N-1}$. These operations are not equivalent.\nThe test checks if $\\max_i |(\\text{step}(\\mathcal{R}u))_i - (\\mathcal{R}(\\text{step}(u)))_i| > \\varepsilon$.\n\n**C. Monotonicity of the Range**\nFor $0 \\le \\alpha \\le \\frac{1}{2}$, the update rule is a convex combination of non-negative coefficients:\n$$\nu_i^{\\text{new}} = \\alpha u_{i-1}^{\\text{old}} + (1-2\\alpha)u_i^{\\text{old}} + \\alpha u_{i+1}^{\\text{old}}\n$$\nwhere $\\alpha \\ge 0$ and $(1-2\\alpha) \\ge 0$. The sum of coefficients is $1$. This property is known as the discrete maximum principle. It implies that the new value $u_i^{\\text{new}}$ cannot be outside the range of its contributing old values. Globally, this means $\\min(u^{\\text{old}}) \\le \\min(u^{\\text{new}})$ and $\\max(u^{\\text{new}}) \\le \\max(u^{\\text{old}})$. Consequently, the range $R(u) = \\max_i u_i - \\min_i u_i$ must be non-increasing: $R(u^{\\text{new}}) \\le R(u^{\\text{old}})$.\nThis property holds for both the **correct** and **buggy** implementations, as long as $0 \\le \\alpha \\le \\frac{1}{2}$, because the update rules at the boundaries in the buggy case also form convex combinations.\nThe property is not expected to hold for $\\alpha > \\frac{1}{2}$, which corresponds to a physically and numerically unstable regime.\nThe test checks if $R(u^{\\text{new}}) - R(u^{\\text{old}}) > \\varepsilon$.\n\n### 3. Testing Procedure\n\nThe program iterates through a suite of predefined test cases. For each case, it initializes a random number generator with a given seed for reproducibility. It generates $T$ random state vectors $u$, with components drawn from a uniform distribution on $[0,1]$. If specified, an additional trial with the zero vector $u=0$ is included. For each trial state, the program applies the designated(`correct` or `buggy`) time-step function and checks for violations of the three invariants. The total number of violations for each invariant is counted and reported. This automated procedure exemplifies property-based testing, where abstract properties of a system are verified over a large set of random inputs, providing strong evidence of correctness or revealing subtle bugs.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef step_correct(u: np.ndarray, alpha: float) -> np.ndarray:\n    \"\"\"\n    Performs one time step of the 1D heat equation with periodic boundary conditions.\n    \"\"\"\n    if u.size == 0:\n        return np.array([])\n    # The discrete Laplacian with periodic boundaries is implemented via circular shifts.\n    laplacian = np.roll(u, 1) - 2 * u + np.roll(u, -1)\n    return u + alpha * laplacian\n\ndef step_buggy(u: np.ndarray, alpha: float) -> np.ndarray:\n    \"\"\"\n    Performs one time step of the 1D heat equation with buggy zero boundary conditions.\n    \"\"\"\n    n = u.size\n    if n == 0:\n        return np.array([])\n    \n    u_new = np.copy(u)\n    \n    # Interior points update\n    if n > 2:\n        laplacian_interior = u[:-2] - 2 * u[1:-1] + u[2:]\n        u_new[1:-1] += alpha * laplacian_interior\n\n    # Boundary points update with zero-value neighbors\n    if n >= 2:\n        # Left boundary i=0, neighbor u_{-1} is 0\n        laplacian_0 = 0 - 2 * u[0] + u[1]\n        u_new[0] += alpha * laplacian_0\n        # Right boundary i=n-1, neighbor u_{n} is 0\n        laplacian_n_minus_1 = u[n-2] - 2 * u[n-1] + 0\n        u_new[n-1] += alpha * laplacian_n_minus_1\n    elif n == 1:\n        # Special case for N=1, both neighbors are 0\n        laplacian_0 = 0 - 2 * u[0] + 0\n        u_new[0] += alpha * laplacian_0\n\n    return u_new\n\ndef solve():\n    \"\"\"\n    Main function to run the property-based tests for the given cases.\n    \"\"\"\n    test_cases = [\n        (64, 0.2, 200, 101, \"correct\", True),\n        (64, 0.49, 200, 102, \"correct\", True),\n        (64, 0.6, 200, 103, \"correct\", False),\n        (64, 0.2, 200, 104, \"buggy\", True),\n        (1, 0.2, 50, 105, \"correct\", True),\n        (32, 0.2, 200, 106, \"buggy\", False),\n    ]\n\n    all_results = []\n    epsilon = 1e-10\n\n    for n, alpha, t, seed, mode, include_zero in test_cases:\n        \n        # 1. Select the stepping function based on the test case mode\n        step_func = step_correct if mode == \"correct\" else step_buggy\n\n        # 2. Generate random states for testing\n        rng = np.random.default_rng(seed)\n        states = [rng.uniform(0, 1, size=n) for _ in range(t)]\n        if include_zero:\n            states.append(np.zeros(n))\n        \n        # 3. Initialize violation counters\n        conservation_violations = 0\n        symmetry_violations = 0\n        monotonicity_violations = 0\n\n        # 4. Iterate through test states and check invariants\n        for u_old in states:\n            if u_old.size == 0:\n                continue\n            \n            # --- Perform one time step ---\n            u_new = step_func(u_old, alpha)\n\n            # --- Test 1: Conservation of total quantity ---\n            sum_old = np.sum(u_old)\n            sum_new = np.sum(u_new)\n            if np.abs(sum_new - sum_old) > epsilon:\n                conservation_violations += 1\n\n            # --- Test 2: Symmetry equivariance ---\n            # LHS: step(reflect(u))\n            u_reflected = u_old[::-1]\n            lhs = step_func(u_reflected, alpha)\n            # RHS: reflect(step(u))\n            rhs = u_new[::-1]\n            \n            if np.max(np.abs(lhs - rhs)) > epsilon:\n                symmetry_violations += 1\n\n            # --- Test 3: Monotonicity of the range ---\n            # This property is only guaranteed for 0 <= alpha <= 0.5\n            # The test is run for all alpha to see when it fails.\n            if u_old.size > 0:\n                range_old = np.max(u_old) - np.min(u_old)\n                range_new = np.max(u_new) - np.min(u_new)\n                if range_new - range_old > epsilon:\n                    monotonicity_violations += 1\n            \n        all_results.append([conservation_violations, symmetry_violations, monotonicity_violations])\n\n    # Final print statement in the exact required format.\n    print(f\"{all_results}\")\n\nsolve()\n```", "id": "3109343"}, {"introduction": "Beyond verifying that the code implements the equations correctly, we must validate that our numerical choices do not introduce unphysical artifacts. This exercise demonstrates how discretization decisions can inadvertently break fundamental symmetries of the continuous model [@problem_id:3109385]. By simulating a symmetric physical system on both symmetric and asymmetric grids, you will quantify the resulting errors and learn how to design discretizations that preserve essential physical properties.", "problem": "A central theme of the computational science paradigm is the disciplined progression from modeling, through discretization and algorithmic solution, to validation and interpretation. Consider a two-dimensional steady-state diffusion model on the square domain $[0,1] \\times [0,1]$ with homogeneous Dirichlet boundary conditions $u=0$ on the boundary. The governing equation is the Poisson equation $ \\nabla^2 u = -f $, where $f$ is a source term. In the continuous model, if the source $f$ is a point source centered at $(x,y)=(0.5,0.5)$ with total strength $S$, then the solution $u(x,y)$ is radially symmetric about $(0.5,0.5)$.\n\nIn this problem, you will create a test case where symmetry breaking occurs due to discretization bias introduced by a specific grid-based representation, then redesign the mesh (grid) to restore symmetry and quantify effects on outputs. The tasks must be done in purely mathematical and algorithmic terms and produce quantitatively testable outputs.\n\nModeling and discretization:\n- Use the Poisson equation $ \\nabla^2 u = -f $ on $[0,1] \\times [0,1]$ with $u=0$ on the boundary, and $f$ representing a discrete approximation to a point source with total strength $S=1$ centered at $(0.5,0.5)$.\n- Discretize the domain with a Cartesian grid of $N_x$ points in the $x$-direction and $N_y$ points in the $y$-direction, allowing $N_x \\neq N_y$. Grid spacings are $h_x = 1/(N_x-1)$ and $h_y = 1/(N_y-1)$.\n- Discretize the Laplacian $ \\nabla^2 u $ using second-order, central finite differences derived from Taylor expansions about interior nodes; assemble a sparse linear system for the interior unknowns with homogeneous Dirichlet boundary values incorporated.\n- Represent the point source discretely by assigning the entire source strength $S$ to the single nearest grid node determined by rounding down (floor) in each coordinate. Specifically, let $I_c = \\lfloor 0.5\\,(N_x-1) \\rfloor$ and $J_c = \\lfloor 0.5\\,(N_y-1) \\rfloor$ be the indices of the chosen source node in the full grid indexing $0,\\dots,N_x-1$ and $0,\\dots,N_y-1$. Map this node into the interior system and set its right-hand side entry to $S$. This floor rule induces discretization bias whenever $(0.5,0.5)$ is not exactly a grid node.\n\nSymmetry quantification:\n- Define the mirror operator $M$ that flips the discrete field about the center by $M(u)[i,j] = u[N_x-1-i, N_y-1-j]$ for all grid indices $(i,j)$. Compute the relative asymmetry metric\n$$\nE_{\\mathrm{sym}} = \\frac{\\lVert u - M(u) \\rVert_2}{\\lVert u \\rVert_2},\n$$\nwhere $\\lVert \\cdot \\rVert_2$ denotes the Euclidean norm of the flattened grid field.\n- Let $(i_{\\max}, j_{\\max})$ be the indices of the maximum value of the computed discrete field $u$. Compute the offset of this maximum from the physical center as\n$$\nd_{\\max} = \\sqrt{\\big(i_{\\max}\\,h_x - 0.5\\big)^2 + \\big(j_{\\max}\\,h_y - 0.5\\big)^2 }.\n$$\n\nTest suite and outputs:\n- Use three test cases:\n  1. A symmetry-breaking case due to discretization bias on an even grid: $N_x=80$, $N_y=80$, source strength $S=1$, floor-based nearest-node source deposition.\n  2. A redesigned symmetric grid that aligns the center to a grid node: $N_x=81$, $N_y=81$, source strength $S=1$, floor-based nearest-node source deposition (which exactly selects the center node when both $N_x$ and $N_y$ are odd).\n  3. An anisotropic but center-aligned grid: $N_x=81$, $N_y=21$, source strength $S=1$, floor-based nearest-node source deposition.\n\nFor each test case, solve the discrete linear system to obtain the interior field, extend it to a full $N_x \\times N_y$ grid with zeros on the boundary, compute $E_{\\mathrm{sym}}$ and $d_{\\max}$, and report both values.\n\nFinal output format:\n- Your program should produce a single line of output containing the results for the three test cases as a comma-separated list enclosed in square brackets, where each test case result is a two-element list $[E_{\\mathrm{sym}}, d_{\\max}]$ with both values rounded to six decimal places. For example, the output format must be exactly\n$[[E_1,d_1],[E_2,d_2],[E_3,d_3]]$\nwith no whitespace.", "solution": "The problem requires the numerical solution of the two-dimensional Poisson equation, $\\nabla^2 u = -f$, on a unit square domain, $\\Omega = [0,1] \\times [0,1]$, with homogeneous Dirichlet boundary conditions, $u=0$ on $\\partial\\Omega$. The core of the problem is to investigate the effect of grid discretization on the symmetry of the numerical solution when the source term, $f$, is a discrete approximation of a point source of strength $S=1$ located at the domain's center, $(0.5, 0.5)$.\n\nThe solution proceeds by first discretizing the governing partial differential equation using a finite difference method, resulting in a system of linear algebraic equations. This system is then solved for three distinct grid configurations to quantify the impact of discretization choices on symmetry.\n\nThe domain is discretized using a Cartesian grid with $N_x$ points in the $x$-direction and $N_y$ points in the $y$-direction. The grid spacings are $h_x = 1/(N_x-1)$ and $h_y = 1/(N_y-1)$. The value of the solution at a grid point $(x_i, y_j) = (i h_x, j h_y)$ is denoted by $u_{i,j}$, for $i \\in \\{0, \\dots, N_x-1\\}$ and $j \\in \\{0, \\dots, N_y-1\\}$.\n\nThe Laplacian operator, $\\nabla^2 u$, at an interior grid point $(i,j)$ (where $1 \\le i \\le N_x-2$ and $1 \\le j \\le N_y-2$) is approximated using a second-order central finite difference scheme:\n$$\n\\nabla^2 u \\bigg|_{(x_i, y_j)} \\approx \\frac{u_{i-1,j} - 2u_{i,j} + u_{i+1,j}}{h_x^2} + \\frac{u_{i,j-1} - 2u_{i,j} + u_{i,j+1}}{h_y^2} = -f_{i,j}\n$$\nThe unknown values are the $N_{int} = (N_x-2)(N_y-2)$ values of $u_{i,j}$ at the interior points. By ordering these unknowns into a single vector $\\mathbf{u}$ of length $N_{int}$, the set of all discretized equations forms a sparse linear system $A\\mathbf{u} = \\mathbf{b}$. The matrix $A$ represents the discretized negative Laplacian operator (multiplied by $-1$), and the vector $\\mathbf{b}$ represents the discretized source term $-f$. The problem specifies that the source $f$ is a discrete point source of total strength $S=1$, with its entire contribution placed at a single grid node. The indices of this source node, $(I_c, J_c)$, are determined by a floor rule: $I_c = \\lfloor 0.5(N_x-1) \\rfloor$ and $J_c = \\lfloor 0.5(N_y-1) \\rfloor$. The problem further specifies that the corresponding entry in the right-hand side vector $\\mathbf{b}$ is set to $S$. This means $\\mathbf{b}$ is a vector of zeros except for a single entry with value $S=1$ at the location corresponding to the grid node $(I_c, J_c)$.\n\nThe matrix $A$ is a sparse, symmetric, and positive-definite matrix. Its structure is block-tridiagonal. For an interior grid of size $(N_x-2) \\times (N_y-2)$, and a row-major mapping from $2$D indices $(i', j')$ (where $i' \\in \\{0, \\dots, N_x-3\\}, j' \\in \\{0, \\dots, N_y-3\\}$) to a $1$D index $k = i' + j'(N_x-2)$, the matrix entries are defined as follows:\n- Diagonal entries: $A_{k,k} = \\frac{2}{h_x^2} + \\frac{2}{h_y^2}$\n- Off-diagonal entries for $x$-neighbors: $A_{k, k \\pm 1} = -\\frac{1}{h_x^2}$\n- Off-diagonal entries for $y$-neighbors: $A_{k, k \\pm (N_x-2)} = -\\frac{1}{h_y^2}$\n(The equation in the problem is $\\nabla^2 u = -f$. The matrix system $A\\mathbf{u}=\\mathbf{b}$ is formed from $-(\\frac{u_{i+1,j} - 2u_{i,j} + u_{i-1,j}}{h_x^2} + \\frac{u_{i,j+1} - 2u_{i,j} + u_{i,j-1}}{h_y^2}) = f_{i,j}$. So the matrix $A$ is for the negative Laplacian, and $\\mathbf{b}$ is for $f$. The problem says the RHS entry is $S$, so $f$ at the source node is $S$. However, the equation is $\\nabla^2u=-f$. Then the RHS of the linear system should correspond to $-f$, which would be $-S$. Let's re-read carefully: \"assemble a sparse linear system for the interior unknowns [...] and set its right-hand side entry to $S$\". This is an explicit instruction for constructing $\\mathbf{b}$, regardless of sign conventions. I will follow the explicit instruction.) So the RHS vector has one entry of $S$.\n\nFor each of the three test cases specified, the following algorithmic procedure is executed:\n$1$. Define grid parameters $N_x$ and $N_y$, and calculate $h_x$ and $h_y$.\n$2$. Construct the sparse matrix $A$ of size $N_{int} \\times N_{int}$ representing the finite difference operator.\n$3$. Construct the right-hand-side vector $\\mathbf{b}$ of size $N_{int}$. This involves finding the source node indices $(I_c, J_c)$, mapping them to the $1$D interior index $k_c$, and setting $\\mathbf{b}_{k_c} = S=1$.\n$4$. Solve the sparse linear system $A\\mathbf{u} = \\mathbf{b}$ to find the vector of interior unknowns $\\mathbf{u}$.\n$5$. Reconstruct the full solution grid $u$ of size $N_y \\times N_x$ by embedding the interior solution into a field of zeros.\n$6$. Compute the two quantitative metrics:\n    - The relative asymmetry, $E_{\\mathrm{sym}} = \\frac{\\lVert u - M(u) \\rVert_2}{\\lVert u \\rVert_2}$, where $M(u)$ is the field reflected about the center: $M(u)_{i,j} = u_{N_x-1-i, N_y-1-j}$.\n    - The offset of the maximum value from the center, $d_{\\max} = \\sqrt{(i_{\\max}h_x - 0.5)^2 + (j_{\\max}h_y - 0.5)^2}$, where $(i_{\\max}, j_{\\max})$ are the indices of the maximum value of $u$.\n\n- **Case 1 ($N_x=80, N_y=80$):** Here $N_x-1 = 79$ is odd, so the physical center $x=0.5$ falls between two grid lines. The floor rule places the source at index $I_c = \\lfloor 0.5 \\times 79 \\rfloor = 39$, which corresponds to $x_{39} = 39/79 \\approx 0.4937$. The discrete source is therefore off-center. This breaks the problem's reflectional symmetry, and we expect a non-zero asymmetry metric, $E_{\\mathrm{sym}} > 0$. The maximum of the solution will also be shifted from the center, so $d_{\\max} > 0$.\n- **Case 2 ($N_x=81, N_y=81$):** Here $N_x-1 = 80$ is even. The source index is $I_c = \\lfloor 0.5 \\times 80 \\rfloor = 40$. The physical location is $x_{40} = 40/80 = 0.5$. The source is placed exactly at the center of a symmetric grid. The discrete problem retains the full symmetry of the continuous model, so we expect both metrics to be zero (or close to machine precision), $E_{\\mathrm{sym}} \\approx 0$ and $d_{\\max} \\approx 0$.\n- **Case 3 ($N_x=81, N_y=21$):** This grid is anisotropic ($h_x \\neq h_y$), but it is symmetric with respect to reflections about the center lines $x=0.5$ and $y=0.5$. Similar to Case $2$, the source indices are $I_c=40$ and $J_c=10$, placing the source at the exact center $(0.5, 0.5)$. Despite the anisotropy of the grid and the resulting elliptical shape of the solution contours, the problem setup remains perfectly symmetric. Therefore, we again expect $E_{\\mathrm{sym}} \\approx 0$ and $d_{\\max} \\approx 0$.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy import sparse\nfrom scipy.sparse.linalg import spsolve\n\ndef solve_poisson(Nx, Ny, S=1.0):\n    \"\"\"\n    Solves the 2D Poisson equation on a unit square with a discrete point source.\n\n    Args:\n        Nx (int): Number of grid points in the x-direction.\n        Ny (int): Number of grid points in the y-direction.\n        S (float): Strength of the point source.\n\n    Returns:\n        tuple[float, float]: A tuple containing the asymmetry metric (Esym) and\n                             the offset of the maximum value (dmax).\n    \"\"\"\n\n    # 1. Grid Parameters\n    hx = 1.0 / (Nx - 1)\n    hy = 1.0 / (Ny - 1)\n\n    Nix = Nx - 2\n    Niy = Ny - 2\n    N_interior = Nix * Niy\n\n    if N_interior <= 0:\n        # Trivial case with no interior nodes\n        return 0.0, 0.5 if Nx==1 and Ny==1 else np.sqrt( (0.5-0.5)**2 + (0.5-0.5)**2 ) # special case for 1x1 grid\n\n    # 2. Construct the sparse matrix A (for -Laplacian)\n    # This matrix represents the 5-point stencil finite difference operator.\n    # It is constructed using its main and off-diagonals.\n    \n    main_diag = np.full(N_interior, 2.0/hx**2 + 2.0/hy**2)\n    \n    x_off_diag = np.full(N_interior - 1, -1.0/hx**2)\n    # Zero out connections that wrap around rows\n    x_off_diag[Nix-1::Nix] = 0.0\n\n    y_off_diag = np.full(N_interior - Nix, -1.0/hy**2)\n\n    diagonals = [y_off_diag, x_off_diag, main_diag, x_off_diag, y_off_diag]\n    offsets = [-Nix, -1, 0, 1, Nix]\n    \n    A = sparse.diags(diagonals, offsets, shape=(N_interior, N_interior), format='csr')\n\n    # 3. Construct the RHS vector b\n    b = np.zeros(N_interior)\n    \n    # Source indices based on the floor rule (global grid)\n    Ic = int(np.floor(0.5 * (Nx - 1)))\n    Jc = int(np.floor(0.5 * (Ny - 1)))\n    \n    # Convert to interior grid indices (i', j')\n    ic_int = Ic - 1\n    jc_int = Jc - 1\n\n    # Check if the source is on an interior node\n    if 0 <= ic_int < Nix and 0 <= jc_int < Niy:\n        # Convert to 1D flattened index (row-major)\n        k_c = jc_int * Nix + ic_int\n        b[k_c] = S\n\n    # 4. Solve the linear system\n    u_interior_flat = spsolve(A, b)\n\n    # 5. Reconstruct the full solution grid\n    u_full = np.zeros((Ny, Nx))\n    u_interior = u_interior_flat.reshape((Niy, Nix))\n    u_full[1:-1, 1:-1] = u_interior\n\n    # 6. Compute metrics\n    # Esym: Relative asymmetry metric\n    u_mirrored = np.flip(u_full)\n    norm_u = np.linalg.norm(u_full)\n    if norm_u == 0:\n        Esym = 0.0\n    else:\n        norm_diff = np.linalg.norm(u_full - u_mirrored)\n        Esym = norm_diff / norm_u\n\n    # dmax: Offset of the maximum value from the center\n    # np.unravel_index gives (row, col) which corresponds to (j, i)\n    j_max, i_max = np.unravel_index(np.argmax(u_full), u_full.shape)\n    \n    x_max = i_max * hx\n    y_max = j_max * hy\n    \n    dmax = np.sqrt((x_max - 0.5)**2 + (y_max - 0.5)**2)\n    \n    return Esym, dmax\n\ndef solve():\n    \"\"\"\n    Main function to run the test cases and print the results.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        (80, 80),  # Symmetry-breaking case\n        (81, 81),  # Redesigned symmetric grid\n        (81, 21),  # Anisotropic but center-aligned grid\n    ]\n\n    results = []\n    source_strength = 1.0\n\n    for case in test_cases:\n        Nx, Ny = case\n        Esym, dmax = solve_poisson(Nx, Ny, source_strength)\n        results.append([Esym, dmax])\n\n    # Final print statement in the exact required format.\n    case_strs = [f\"[{res[0]:.6f},{res[1]:.6f}]\" for res in results]\n    print(f\"[{','.join(case_strs)}]\")\n\nsolve()\n\n```", "id": "3109385"}, {"introduction": "Reproducibility is a critical pillar of the scientific method, yet it poses unique challenges in computational science where results can depend on the specific hardware and software environment. This practice provides a concrete framework for assessing computational reproducibility [@problem_id:3109390]. You will simulate a simple physical system under two slightly different \"computational environments\" and use a formal statistical test, the Kolmogorov-Smirnov test, to objectively decide whether the results are statistically equivalent.", "problem": "You are asked to design a small, self-contained reproducibility case study in the spirit of the computational science paradigm. The study will mimic running the same molecular dynamics simulation under different compiler and flag configurations, and will decide whether the results are reproducible by formally testing equality of ensemble distributions.\n\nThe simulation model is a one-dimensional harmonic oscillator integrated with a velocity Verlet update. The state at step index $t$ is position $x_t$ and velocity $v_t$. The physical parameters are mass $m$ and stiffness $k$. The simulation time step is $\\Delta t$. To emulate compiler and flag differences, intermediate arithmetic is rounded to a specified decimal precision $p$ at each update, and a tiny deterministic bias term $b$ can be applied to the update to represent effects such as fused-multiply-add reordering. All quantities are dimensionless; no physical units apply in this problem.\n\nStarting from initial conditions, your program must generate an ensemble of trajectories for a set of $N$ independent initial conditions, and then form an ensemble of final energies. The energy of a state $(x, v)$ is defined as $E = \\frac{1}{2} m v^2 + \\frac{1}{2} k x^2$. You will produce two ensembles per test case, representing two compiler and flag configurations $A$ and $B$.\n\nThe integration scheme you must implement for one time step is:\n- Compute the next position using\n$$\nx_{t+\\Delta t} = x_t + v_t \\Delta t - \\frac{1}{2}\\frac{k}{m} x_t (\\Delta t)^2 + b\\, x_t v_t,\n$$\nthen round $x_{t+\\Delta t}$ to $p$ decimal places.\n- Compute the next velocity using\n$$\nv_{t+\\Delta t} = v_t - \\frac{1}{2}\\frac{k}{m} (x_t + x_{t+\\Delta t}) \\Delta t + b\\, x_{t+\\Delta t} v_t,\n$$\nthen round $v_{t+\\Delta t}$ to $p$ decimal places.\n\nThe ensemble must be constructed by sampling $N$ deterministic initial positions $x_0$ uniformly over a symmetric interval, and setting $v_0 = 0$ for all ensemble members. Specifically, use $x_0$ values evenly spaced over $[-X, X]$ with $X = 0.5$. For a given configuration $(m, k, \\Delta t, p, b)$ and number of steps $T$, you should:\n- Initialize the ensemble as described,\n- Advance each member for $T$ steps with the above updates,\n- Compute and collect the final energy $E$ for each member, forming an energy ensemble.\n\nTo decide reproducibility, define the null hypothesis $H_0$ that the two energy ensembles from configurations $A$ and $B$ are samples from the same underlying distribution:\n$$\nH_0: F_A(E) = F_B(E) \\text{ for all } E,\n$$\nwhere $F_A$ and $F_B$ are cumulative distribution functions. Use the two-sample Kolmogorov–Smirnov (KS) test (Kolmogorov–Smirnov (KS)) at significance level $\\alpha$ to accept or reject reproducibility. Specifically, compute the KS $p$-value for the two energy samples; declare the results reproducible if the $p$-value is greater than or equal to $\\alpha$, and not reproducible otherwise.\n\nImplement the program to run the following test suite, each test case defined by the tuple of parameters for configurations $A$ and $B$, and $\\alpha$:\n\n- Test case $1$ (happy path, identical configurations):\n  - Configuration $A$: $m = 1.0$, $k = 2.0$, $\\Delta t = 0.005$, $p = 12$, $b = 0.0$, $T = 100$, $N = 1000$.\n  - Configuration $B$: $m = 1.0$, $k = 2.0$, $\\Delta t = 0.005$, $p = 12$, $b = 0.0$, $T = 100$, $N = 1000$.\n  - $\\alpha = 0.05$.\n- Test case $2$ (boundary condition, very small ensemble size):\n  - Configuration $A$: $m = 1.0$, $k = 2.0$, $\\Delta t = 0.005$, $p = 12$, $b = 0.0$, $T = 50$, $N = 8$.\n  - Configuration $B$: $m = 1.0$, $k = 2.0$, $\\Delta t = 0.005$, $p = 12$, $b = 0.0$, $T = 50$, $N = 8$.\n  - $\\alpha = 0.05$.\n- Test case $3$ (clear difference in mass parameter):\n  - Configuration $A$: $m = 1.0$, $k = 2.0$, $\\Delta t = 0.005$, $p = 12$, $b = 0.0$, $T = 100$, $N = 500$.\n  - Configuration $B$: $m = 1.5$, $k = 2.0$, $\\Delta t = 0.005$, $p = 12$, $b = 0.0$, $T = 100$, $N = 500$.\n  - $\\alpha = 0.05$.\n- Test case $4$ (multiple differences: step size, rounding precision, and bias):\n  - Configuration $A$: $m = 1.0$, $k = 2.0$, $\\Delta t = 0.005$, $p = 12$, $b = 0.0$, $T = 150$, $N = 1000$.\n  - Configuration $B$: $m = 2.0$, $k = 2.0$, $\\Delta t = 0.02$, $p = 6$, $b = 10^{-3}$, $T = 150$, $N = 1000$.\n  - $\\alpha = 0.05$.\n\nYour program must:\n- Implement the described integrator and ensemble construction,\n- For each test case, generate the energy ensembles for $A$ and $B$,\n- Apply the two-sample KS test at the specified $\\alpha$,\n- Produce a single line of output containing the results as a comma-separated list of booleans enclosed in square brackets (e.g., $[\\\\text{True},\\\\text{False},\\\\text{True}]$), ordered as test cases $1$ through $4$.\n\nAll calculations are dimensionless; do not include or convert any physical units. Angles are not used in this problem. Percentages, if any arise, must be in decimal form; however, this problem does not require percentages explicitly.", "solution": "The problem requires the design and implementation of a computational experiment to study numerical reproducibility. This is accomplished by simulating a one-dimensional harmonic oscillator under different configurations, modeling variations in compilers or hardware, and then using a statistical test to determine if the results are equivalent. The core of the solution involves numerical integration, ensemble generation, and hypothesis testing.\n\nFirst, we define the physical model and its numerical integration. The system is a simple harmonic oscillator with mass $m$ and spring constant $k$. A state is defined by its position $x$ and velocity $v$. The total energy of a state $(x, v)$ provides a conserved quantity in the ideal physical system and is given by the expression $E = \\frac{1}{2} m v^2 + \\frac{1}{2} k x^2$. For the numerical simulation, we discretize time with a step size $\\Delta t$. The state $(x_t, v_t)$ at time step index $t$ is advanced to the next state $(x_{t+\\Delta t}, v_{t+\\Delta t})$ using a specified update scheme. The problem statement provides a variant of the standard velocity Verlet algorithm. The position is updated first:\n$$\nx_{t+\\Delta t} = x_t + v_t \\Delta t - \\frac{1}{2}\\frac{k}{m} x_t (\\Delta t)^2 + b\\, x_t v_t\n$$\nThis updated position $x_{t+\\Delta t}$ is then used to compute the new velocity:\n$$\nv_{t+\\Delta t} = v_t - \\frac{1}{2}\\frac{k}{m} (x_t + x_{t+\\Delta t}) \\Delta t + b\\, x_{t+\\Delta t} v_t\n$$\nIn these equations, the term proportional to the bias parameter $b$ is a small, deterministic perturbation intended to model subtle arithmetic differences between computational environments, such as those arising from fused-multiply-add instruction reordering. To further model the effects of finite-precision arithmetic, the results of both the position and velocity updates, $x_{t+\\Delta t}$ and $v_{t+\\Delta t}$, are rounded to a specified number of decimal places, $p$.\n\nThe second principle is the use of an ensemble to capture the statistical properties of the system's evolution. A single trajectory is sensitive to initial conditions and perturbations (the \"butterfly effect\"). To obtain a robust, statistical description of the dynamics, we simulate an ensemble of $N$ independent systems, each starting from a slightly different initial condition. For this problem, the initial ensemble is constructed from $N$ deterministic starting positions $x_0$ that are evenly spaced over the interval $[-0.5, 0.5]$. For all members of the ensemble, the initial velocity $v_0$ is set to $0$. Each of these $N$ systems is then integrated forward in time for $T$ steps using the numerical scheme described above. At the end of the simulation, at time $T \\Delta t$, we compute the final energy $E$ for each of the $N$ members. This process yields two sets of final energies, one for a \"reference\" configuration $A$ and another for a \"test\" configuration $B$.\n\nThe final step is to formally test for reproducibility. The core question is whether the two ensembles of final energies, from configurations $A$ and $B$, could have been drawn from the same underlying probability distribution. We formalize this as a null hypothesis, $H_0$, stating that the cumulative distribution functions (CDFs) of energy for both configurations are identical: $H_0: F_A(E) = F_B(E)$. To test this hypothesis, we employ the two-sample Kolmogorov-Smirnov (KS) test. This is a non-parametric test that quantifies the maximum distance between the empirical CDFs of the two samples. The KS test produces a $p$-value, which represents the probability of observing a difference as large as or larger than the one measured, assuming $H_0$ is true. A small $p$-value suggests that the observed difference is unlikely to be due to random chance alone, leading us to reject $H_0$. The problem defines reproducibility based on a significance level $\\alpha$: if the computed $p$-value is greater than or equal to $\\alpha$, we fail to reject the null hypothesis and declare the results reproducible. If the $p$-value is less than $\\alpha$, we reject $H_0$ and declare the results not reproducible.\n\nThe algorithmic design directly follows these principles. A function is implemented to perform the ensemble simulation for a given set of parameters $(m, k, \\Delta t, p, b, T, N)$. This function initializes the positions and velocities for the $N$ ensemble members as `numpy` arrays, then iterates for $T$ time steps, applying the vectorized update equations to the entire ensemble at once for computational efficiency. After the integration, it calculates and returns an array of the final energies. The main part of the program iterates through the specified test cases. For each case, it calls the simulation function for configurations $A$ and $B$, obtains the two energy ensembles, and passes them to the `scipy.stats.ks_2samp` function. The resulting $p$-value is compared against the given $\\alpha$, and a boolean result ($True$ for reproducible, $False$ for not) is stored. Finally, all boolean results are collected and printed in the specified format.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy import stats\n\ndef solve():\n    \"\"\"\n    Solves the computational reproducibility case study by running simulations\n    for given test cases and performing a Kolmogorov-Smirnov test.\n    \"\"\"\n\n    def run_simulation(m: float, k: float, dt: float, p: int, b: float, T: int, N: int) -> np.ndarray:\n        \"\"\"\n        Runs a single ensemble simulation for a given configuration.\n\n        Args:\n            m: Mass parameter.\n            k: Stiffness parameter.\n            dt: Time step.\n            p: Decimal precision for rounding.\n            b: Bias term.\n            T: Number of time steps.\n            N: Number of ensemble members.\n\n        Returns:\n            An array of final energies for each ensemble member.\n        \"\"\"\n        # Initialize ensemble states (position x, velocity v)\n        # For N=1, linspace produces array([0.]), the center of the interval, which is correct.\n        x = np.linspace(-0.5, 0.5, N)\n        v = np.zeros(N)\n\n        # Time integration loop\n        for _ in range(T):\n            # Position update step\n            x_new_unrounded = x + v * dt - 0.5 * (k / m) * x * (dt**2) + b * x * v\n            x_new = np.round(x_new_unrounded, p)\n\n            # Velocity update step, using the just-computed position x_new\n            v_new_unrounded = v - 0.5 * (k / m) * (x + x_new) * dt + b * x_new * v\n            v_new = np.round(v_new_unrounded, p)\n\n            # Update state vectors for the next iteration\n            x, v = x_new, v_new\n\n        # Calculate final energy for each ensemble member\n        energy = 0.5 * m * v**2 + 0.5 * k * x**2\n        return energy\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # Test case 1 (happy path, identical configurations)\n        (\n            {'m': 1.0, 'k': 2.0, 'dt': 0.005, 'p': 12, 'b': 0.0, 'T': 100, 'N': 1000}, # Config A\n            {'m': 1.0, 'k': 2.0, 'dt': 0.005, 'p': 12, 'b': 0.0, 'T': 100, 'N': 1000}, # Config B\n            0.05  # alpha\n        ),\n        # Test case 2 (boundary condition, very small ensemble size)\n        (\n            {'m': 1.0, 'k': 2.0, 'dt': 0.005, 'p': 12, 'b': 0.0, 'T': 50, 'N': 8},\n            {'m': 1.0, 'k': 2.0, 'dt': 0.005, 'p': 12, 'b': 0.0, 'T': 50, 'N': 8},\n            0.05\n        ),\n        # Test case 3 (clear difference in mass parameter)\n        (\n            {'m': 1.0, 'k': 2.0, 'dt': 0.005, 'p': 12, 'b': 0.0, 'T': 100, 'N': 500},\n            {'m': 1.5, 'k': 2.0, 'dt': 0.005, 'p': 12, 'b': 0.0, 'T': 100, 'N': 500},\n            0.05\n        ),\n        # Test case 4 (multiple differences: step size, rounding precision, and bias)\n        (\n            {'m': 1.0, 'k': 2.0, 'dt': 0.005, 'p': 12, 'b': 0.0, 'T': 150, 'N': 1000},\n            {'m': 2.0, 'k': 2.0, 'dt': 0.02, 'p': 6, 'b': 1e-3, 'T': 150, 'N': 1000},\n            0.05\n        )\n    ]\n\n    results = []\n    for config_A, config_B, alpha in test_cases:\n        # Generate energy ensembles for both configurations\n        energy_A = run_simulation(**config_A)\n        energy_B = run_simulation(**config_B)\n        \n        # Perform the two-sample Kolmogorov-Smirnov test\n        ks_result = stats.ks_2samp(energy_A, energy_B)\n        p_value = ks_result.pvalue\n        \n        # Determine reproducibility based on the p-value and significance level alpha\n        is_reproducible = p_value >= alpha\n        results.append(is_reproducible)\n\n    # Final print statement in the exact required format.\n    # Python's str(bool) gives 'True' or 'False' as required.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "3109390"}]}