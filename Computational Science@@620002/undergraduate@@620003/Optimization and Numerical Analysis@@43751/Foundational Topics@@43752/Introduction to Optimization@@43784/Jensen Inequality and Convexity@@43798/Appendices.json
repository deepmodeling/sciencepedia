{"hands_on_practices": [{"introduction": "A foundational skill in optimization is the ability to determine whether a given function is convex. For twice-differentiable functions, the second derivative test provides a direct and powerful method for this verification. This first practice session will sharpen your analytical skills by having you apply this test to a family of functions, determining the precise conditions under which convexity is guaranteed [@problem_id:2182829].", "problem": "In optimization theory, a core concept is the convexity of a function. For a twice-differentiable function of a single variable, $f(x)$, a sufficient condition for it to be convex on a given interval is that its second derivative, $f''(x)$, is non-negative for all points within that interval.\n\nConsider the family of functions defined by:\n$$f(x) = \\exp(ax) + c x^2$$\nwhere $a$ is a non-zero real constant and $c$ is a variable real parameter. We wish to determine the conditions for which this function is convex over the closed symmetric interval $I = [-\\beta, \\beta]$, where $\\beta$ is a positive constant.\n\nIt can be established that for given values of $a$ and $\\beta$, the function $f(x)$ is convex on the interval $I$ if and only if the parameter $c$ satisfies the inequality $c \\ge c_{min}$.\n\nYour task is to find the expression for this minimum value, $c_{min}$, in terms of the parameters $a$ and $\\beta$.", "solution": "For a twice-differentiable real function on an interval, convexity is equivalent to the nonnegativity of the second derivative throughout the interval. For the given function\n$$\nf(x)=\\exp(ax)+c x^{2},\n$$\nthe first derivative is\n$$\nf'(x)=a\\exp(ax)+2cx,\n$$\nand the second derivative is\n$$\nf''(x)=a^{2}\\exp(ax)+2c.\n$$\nConvexity on the closed interval $I=[-\\beta,\\beta]$ is therefore equivalent to\n$$\nf''(x)=a^{2}\\exp(ax)+2c\\ge 0 \\quad \\text{for all } x\\in[-\\beta,\\beta].\n$$\nSince $a^{2}>0$ and $\\exp(ax)>0$, the minimum of $f''(x)$ over $I$ occurs where $\\exp(ax)$ attains its minimum over $I$. Because $\\exp(ax)$ is monotone increasing in $x$ when $a>0$ and monotone decreasing when $a<0$, we have\n$$\n\\min_{x\\in[-\\beta,\\beta]}\\exp(ax)=\\exp(-|a|\\beta).\n$$\nTherefore,\n$$\n\\min_{x\\in[-\\beta,\\beta]} f''(x)=a^{2}\\exp(-|a|\\beta)+2c.\n$$\nThe condition for convexity is that this minimum be nonnegative:\n$$\na^{2}\\exp(-|a|\\beta)+2c\\ge 0 \\quad \\Longleftrightarrow \\quad c\\ge -\\frac{a^{2}}{2}\\exp(-|a|\\beta).\n$$\nThis bound is tight: at $x$ where $\\exp(ax)$ attains its minimum, equality yields $f''(x)=0$, and any smaller $c$ would make $f''$ negative there. Hence,\n$$\nc_{\\min}=-\\frac{a^{2}}{2}\\exp(-|a|\\beta).\n$$", "answer": "$$\\boxed{-\\frac{a^{2}}{2}\\exp(-|a|\\beta)}$$", "id": "2182829"}, {"introduction": "In practice, complex models are often constructed by combining simpler functions. It is therefore crucial to understand how fundamental properties like convexity behave under operations such as addition, multiplication, and composition. This exercise challenges you to investigate these \"rules of convex calculus,\" helping you develop intuition for building and analyzing convex optimization problems by testing which operations reliably preserve convexity [@problem_id:2182853].", "problem": "In the study of optimization and signal processing, the properties of convex functions are of fundamental importance. A twice-differentiable function $f(x)$ defined on the set of all real numbers, $\\mathbb{R}$, is said to be convex if its second derivative, $f''(x)$, is non-negative for all $x \\in \\mathbb{R}$. For instance, $f(x)=x^2$ is convex because its second derivative is $f''(x)=2$, which is always non-negative.\n\nConsider the set of all such twice-differentiable convex functions defined on $\\mathbb{R}$. Evaluate the following statements about operations on these functions. Which one of the statements is always true?\n\nA. If $f(x)$ and $g(x)$ are convex functions, then their sum, $h(x) = f(x) + g(x)$, is always a convex function.\n\nB. If $f(x)$ and $g(x)$ are convex functions, then their product, $p(x) = f(x)g(x)$, is always a convex function.\n\nC. If $f(x)$ and $g(x)$ are convex functions, then their composition, $c(x) = f(g(x))$, is always a convex function.\n\nD. If $f(x)$ and $g(x)$ are convex functions, then the function representing their pointwise maximum, $m(x) = \\max(f(x), g(x))$, is not necessarily a convex function.", "solution": "We recall that a twice-differentiable function $f:\\mathbb{R}\\to\\mathbb{R}$ is convex if and only if $f''(x)\\geq 0$ for all $x\\in\\mathbb{R}$.\n\nAnalyze A: Let $f$ and $g$ be convex and twice differentiable on $\\mathbb{R}$, so $f''(x)\\geq 0$ and $g''(x)\\geq 0$ for all $x$. Consider $h(x)=f(x)+g(x)$. Then\n$$\nh''(x)=f''(x)+g''(x)\\geq 0\\quad\\text{for all }x,\n$$\nso $h$ is convex. Thus A is always true.\n\nAnalyze B: Consider $f(x)=x^{2}$ and $g(x)=x^{2}-x$. Both are twice differentiable with\n$$\nf''(x)=2\\geq 0,\\qquad g''(x)=2\\geq 0,\n$$\nso both are convex. Let $p(x)=f(x)g(x)=x^{4}-x^{3}$. Then\n$$\np'(x)=4x^{3}-3x^{2},\\qquad p''(x)=12x^{2}-6x=6\\left(2x^{2}-x\\right).\n$$\nOn the interval $0<x<\\frac{1}{2}$, we have $2x^{2}-x<0$, hence $p''(x)<0$ there. Therefore $p$ is not convex, and B is not always true.\n\nAnalyze C: Take $f(u)=\\exp(-u)$ and $g(x)=x^{2}$. Both are convex and twice differentiable on $\\mathbb{R}$, because\n$$\nf''(u)=\\exp(-u)\\geq 0,\\qquad g''(x)=2\\geq 0.\n$$\nConsider the composition $c(x)=f(g(x))=\\exp(-x^{2})$. Then\n$$\nc'(x)=-2x\\exp(-x^{2}),\\qquad c''(x)=\\exp(-x^{2})\\left(4x^{2}-2\\right).\n$$\nFor $|x|<\\frac{1}{\\sqrt{2}}$, we have $4x^{2}-2<0$, so $c''(x)<0$ on that interval. Hence $c$ is not convex, and C is not always true.\n\nAnalyze D: Let $m(x)=\\max\\{f(x),g(x)\\}$. For any $x,y\\in\\mathbb{R}$ and $t\\in[0,1]$, convexity of $f$ and $g$ gives\n$$\nf(tx+(1-t)y)\\leq t f(x)+(1-t) f(y),\\qquad g(tx+(1-t)y)\\leq t g(x)+(1-t) g(y).\n$$\nTaking pointwise maxima on both inequalities yields\n$$\nm(tx+(1-t)y)=\\max\\{f(tx+(1-t)y),g(tx+(1-t)y)\\}\n\\leq \\max\\{t f(x)+(1-t) f(y),\\, t g(x)+(1-t) g(y)\\}.\n$$\nMoreover,\n$$\n\\max\\{t f(x)+(1-t) f(y),\\, t g(x)+(1-t) g(y)\\}\\leq t \\max\\{f(x),g(x)\\}+(1-t)\\max\\{f(y),g(y)\\},\n$$\nsince each of $t f(x)+(1-t) f(y)$ and $t g(x)+(1-t) g(y)$ is bounded above by the right-hand side. Hence\n$$\nm(tx+(1-t)y)\\leq t m(x)+(1-t) m(y),\n$$\nwhich proves $m$ is convex. Therefore D, which claims $m$ is not necessarily convex, is false.\n\nOnly statement A is always true.", "answer": "$$\\boxed{A}$$", "id": "2182853"}, {"introduction": "Perhaps the most significant consequence of convexity is Jensen's inequality, which establishes a fundamental relationship between the function of an average and the average of the function. This principle has far-reaching implications in fields from probability theory to finance. In this final practice, you will explore a tangible application of Jensen's inequality by calculating the \"convexity gap\" in a scenario involving expected values, offering a concrete demonstration of why convexity is such a powerful concept [@problem_id:2182882].", "problem": "A robotic agent operates on a 2D Cartesian plane. Its position is a random vector $V$. The agent has two possible states: it can be at position $v_1 = (12, 5)$ with probability $p = \\frac{1}{2}$, or at position $v_2 = (3, 4)$ with probability $1-p = \\frac{1}{2}$. The origin $(0,0)$ is a central charging hub.\n\nA key operational metric is the \"risk-adjusted cost,\" defined as the difference between the expected travel cost and the cost of traveling to the expected position. The travel cost to any position $v$ is directly proportional to its Euclidean distance from the hub, given by the Euclidean norm $C(v) = \\|v\\|_2$.\n\nCalculate the risk-adjusted cost, which is the value of $\\mathbb{E}[C(V)] - C(\\mathbb{E}[V])$, where $\\mathbb{E}[\\cdot]$ denotes the expected value. Choose the correct option from the following.\n\nA. $9 - \\frac{3\\sqrt{34}}{2}$\n\nB. $\\frac{3\\sqrt{34}}{2} - 9$\n\nC. $0$\n\nD. $4.5$", "solution": "The problem asks for the value of $\\mathbb{E}[C(V)] - C(\\mathbb{E}[V])$. This quantity is often called the \"convexity gap\" and is a direct consequence of Jensen's inequality for convex functions. The function $C(v) = \\|v\\|_2$ (the Euclidean norm) is a convex function. For a convex function $C$ and a random variable $V$, Jensen's inequality states that $C(\\mathbb{E}[V]) \\leq \\mathbb{E}[C(V)]$, which means the result should be non-negative.\n\nThe random vector $V$ can take two values:\n$v_1 = (12, 5)$ with probability $P(V=v_1) = \\frac{1}{2}$\n$v_2 = (3, 4)$ with probability $P(V=v_2) = \\frac{1}{2}$\n\nWe need to compute two terms: the expected cost $\\mathbb{E}[C(V)]$ and the cost of the expected position $C(\\mathbb{E}[V])$.\n\nStep 1: Calculate the expected cost $\\mathbb{E}[C(V)]$.\nThe expected cost is the weighted average of the costs for each possible position.\n$$ \\mathbb{E}[C(V)] = P(V=v_1)C(v_1) + P(V=v_2)C(v_2) $$\nThe cost function is the Euclidean norm, $C(v) = \\|v\\|_2 = \\sqrt{v_x^2 + v_y^2}$.\nFirst, we find the cost for each position:\n$$ C(v_1) = \\|v_1\\|_2 = \\sqrt{12^2 + 5^2} = \\sqrt{144 + 25} = \\sqrt{169} = 13 $$\n$$ C(v_2) = \\|v_2\\|_2 = \\sqrt{3^2 + 4^2} = \\sqrt{9 + 16} = \\sqrt{25} = 5 $$\nNow, we can calculate the expected cost:\n$$ \\mathbb{E}[C(V)] = \\frac{1}{2} C(v_1) + \\frac{1}{2} C(v_2) = \\frac{1}{2}(13) + \\frac{1}{2}(5) = \\frac{13+5}{2} = \\frac{18}{2} = 9 $$\n\nStep 2: Calculate the cost of the expected position $C(\\mathbb{E}[V])$.\nFirst, we need to find the expected position vector $\\mathbb{E}[V]$.\n$$ \\mathbb{E}[V] = P(V=v_1) v_1 + P(V=v_2) v_2 $$\n$$ \\mathbb{E}[V] = \\frac{1}{2}(12, 5) + \\frac{1}{2}(3, 4) = (\\frac{12}{2}, \\frac{5}{2}) + (\\frac{3}{2}, \\frac{4}{2}) = (\\frac{12+3}{2}, \\frac{5+4}{2}) = (\\frac{15}{2}, \\frac{9}{2}) $$\nNow, we calculate the cost associated with this expected position:\n$$ C(\\mathbb{E}[V]) = \\|\\mathbb{E}[V]\\|_2 = \\left\\| \\left(\\frac{15}{2}, \\frac{9}{2}\\right) \\right\\|_2 $$\n$$ C(\\mathbb{E}[V]) = \\sqrt{\\left(\\frac{15}{2}\\right)^2 + \\left(\\frac{9}{2}\\right)^2} = \\sqrt{\\frac{225}{4} + \\frac{81}{4}} = \\sqrt{\\frac{225 + 81}{4}} = \\sqrt{\\frac{306}{4}} = \\frac{\\sqrt{306}}{2} $$\nWe can simplify the square root term: $\\sqrt{306} = \\sqrt{9 \\times 34} = 3\\sqrt{34}$.\nSo, the cost of the expected position is:\n$$ C(\\mathbb{E}[V]) = \\frac{3\\sqrt{34}}{2} $$\n\nStep 3: Calculate the final difference.\nThe risk-adjusted cost is $\\mathbb{E}[C(V)] - C(\\mathbb{E}[V])$.\n$$ \\mathbb{E}[C(V)] - C(\\mathbb{E}[V]) = 9 - \\frac{3\\sqrt{34}}{2} $$\n\nThis matches option A. We can check that the value is positive, as expected from Jensen's inequality. $\\sqrt{34}$ is between $\\sqrt{25}=5$ and $\\sqrt{36}=6$. Let's approximate it as 5.8. Then $\\frac{3\\sqrt{34}}{2} \\approx \\frac{3 \\times 5.8}{2} = 3 \\times 2.9 = 8.7$. So the difference is approximately $9 - 8.7 = 0.3 > 0$. Option B would be negative. Option C would be true if the function were linear. Option D is incorrect.", "answer": "$$\\boxed{A}$$", "id": "2182882"}]}