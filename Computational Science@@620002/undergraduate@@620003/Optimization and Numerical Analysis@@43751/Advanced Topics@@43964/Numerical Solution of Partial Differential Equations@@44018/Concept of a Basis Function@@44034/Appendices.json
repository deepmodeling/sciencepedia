{"hands_on_practices": [{"introduction": "The fundamental purpose of a basis is to provide a set of building blocks from which other elements in a vector space can be constructed. This exercise provides a tangible starting point by exploring this concept, known as spanning, within a space of familiar trigonometric functions. By finding the specific coefficients to represent one function using others, you will gain a practical understanding of what it means for a function to belong to the space spanned by a basis [@problem_id:2161516].", "id": "2161516", "problem": "In many areas of science and engineering, including signal processing and quantum mechanics, it is common to represent a function as a linear combination of a set of pre-defined basis functions. This allows for efficient storage and manipulation of complex functions.\n\nConsider a function space $S$ defined as the set of all functions $f(x)$ that can be expressed as a linear combination of the basis functions $b_1(x) = 1$ and $b_2(x) = \\cos^2(x)$. Any function $f(x)$ in this space can be written as:\n$$f(x) = c_1 b_1(x) + c_2 b_2(x) = c_1 \\cdot 1 + c_2 \\cos^2(x)$$\nwhere $c_1$ and $c_2$ are real-valued constant coefficients.\n\nYou are given a target function $g(x) = \\sin^2(x)$. Determine the specific coefficients $(c_1, c_2)$ required to express $g(x)$ as a member of the function space $S$. Your answer should be the ordered pair of coefficients $(c_1, c_2)$.\n\n", "solution": "We seek real constants $c_{1}$ and $c_{2}$ such that, for all $x$,\n$$\nc_{1}+c_{2}\\cos^{2}(x)=\\sin^{2}(x).\n$$\nUse the Pythagorean identity $\\sin^{2}(x)+\\cos^{2}(x)=1$, which implies\n$$\n\\sin^{2}(x)=1-\\cos^{2}(x).\n$$\nTherefore, we need\n$$\nc_{1}+c_{2}\\cos^{2}(x)=1-\\cos^{2}(x).\n$$\nSince the functions $1$ and $\\cos^{2}(x)$ are linearly independent, equality of these functions for all $x$ requires equality of the corresponding coefficients:\n$$\nc_{1}=1,\\qquad c_{2}=-1.\n$$\nA direct substitution verifies that $1-1\\cdot\\cos^{2}(x)=\\sin^{2}(x)$, so $g(x)$ lies in $S$ with these coefficients.", "answer": "$$\\boxed{\\begin{pmatrix}1 & -1\\end{pmatrix}}$$"}, {"introduction": "For a set of functions to serve as a valid basis, they must be linearly independent, meaning no function in the set can be constructed from the others. This practice challenges you to rigorously test for linear independence, moving beyond intuition to apply the formal definition. It highlights a common pitfall regarding dependence on sub-intervals versus the entire domain, sharpening your analytical skills for verifying basis sets [@problem_id:2161552].", "id": "2161552", "problem": "In the field of signal processing, complex signals are often approximated by a linear combination of simpler, well-understood functions. These functions must form a linearly independent set to serve as a valid basis.\n\nAn engineer is analyzing a signal over a symmetric time interval $[-T, T]$, where $T$ is a positive constant. They consider using the set of two functions $S = \\{f_1(t), f_2(t)\\}$, where $f_1(t) = t$ and $f_2(t) = |t|$.\n\nThe engineer argues that this set is not suitable because the functions are linearly dependent. Their reasoning is that for the sub-interval $[0, T]$, the functions are identical ($|t| = t$), and for the sub-interval $[-T, 0]$, one is just the negative of the other ($|t| = -t$). They conclude that since the functions are dependent on these sub-intervals, they must be dependent over the entire interval $[-T, T]$.\n\nYour task is to rigorously evaluate this claim. Which one of the following statements provides the correct assessment of the linear independence of the set of functions $S = \\{t, |t|\\}$ on the interval $[-T, T]$?\n\nA. The set $S$ is linearly dependent on $[-T, T]$ because for any $t \\neq 0$ in the interval, $f_2(t)$ can be written as a constant multiple of $f_1(t)$, specifically $|t| = (\\text{sgn}(t)) \\cdot t$.\nB. The set $S$ is linearly dependent on $[-T, T]$ because its linear dependence on the sub-intervals $[0, T]$ and $[-T, 0]$ implies dependence on their union, $[-T, T]$.\nC. The set $S$ is linearly independent on $[-T, T]$ because the equation $c_1 t + c_2 |t| = 0$ holding for all $t \\in [-T, T]$ necessarily requires that the coefficients $c_1$ and $c_2$ must both be zero.\nD. The set $S$ is linearly independent on $[-T, T]$ because $|t|$ is not a smooth function, and non-smooth functions are always linearly independent of smooth functions like $t$.\nE. The linear independence of the set $S$ cannot be determined over the interval $[-T, T]$ because the function $|t|$ is not differentiable at the point $t=0$.\n\n", "solution": "Definition used: A set of functions $\\{f_{1},f_{2}\\}$ on a domain $D$ is linearly independent if the only constants $c_{1},c_{2}$ satisfying $c_{1}f_{1}(t)+c_{2}f_{2}(t)=0$ for all $t\\in D$ are $c_{1}=0$ and $c_{2}=0$. Otherwise, they are linearly dependent.\n\nApply the definition to $f_{1}(t)=t$ and $f_{2}(t)=|t|$ on $D=[-T,T]$. Assume there exist constants $c_{1},c_{2}$ such that\n$$\nc_{1}t+c_{2}|t|=0\\quad\\text{for all }t\\in[-T,T].\n$$\nEvaluate this identity on each sub-interval using the piecewise definition of $|t|$.\n\nFor $t\\in[0,T]$, we have $|t|=t$, so the identity becomes\n$$\n(c_{1}+c_{2})\\,t=0\\quad\\text{for all }t\\in[0,T].\n$$\nThe function $t$ is not the zero function on $[0,T]$, hence the only way $(c_{1}+c_{2})\\,t$ is the zero function on $[0,T]$ is\n$$\nc_{1}+c_{2}=0.\n$$\n\nFor $t\\in[-T,0]$, we have $|t|=-t$, so the identity becomes\n$$\n(c_{1}-c_{2})\\,t=0\\quad\\text{for all }t\\in[-T,0].\n$$\nAgain, $t$ is not the zero function on $[-T,0]$, so the only way $(c_{1}-c_{2})\\,t$ is the zero function on $[-T,0]$ is\n$$\nc_{1}-c_{2}=0.\n$$\n\nSolving the system\n$$\nc_{1}+c_{2}=0,\\qquad c_{1}-c_{2}=0\n$$\ngives $c_{1}=0$ and $c_{2}=0$. Therefore, the only linear combination that vanishes identically on $[-T,T]$ is the trivial one, so $\\{t,|t|\\}$ is linearly independent on $[-T,T]$.\n\nThis directly validates statement C. Statements A and B are incorrect because linear dependence requires a single pair of constants working on the entire domain; having different constant multiples on different sub-intervals (or a sign that depends on $t$) does not establish global dependence. Statements D and E are incorrect because differentiability or smoothness is irrelevant to linear independence; only the existence of a nontrivial constant linear combination that vanishes identically matters.", "answer": "$$\\boxed{C}$$"}, {"introduction": "While any linearly independent set can form a basis, orthogonal bases offer significant advantages in stability and computational efficiency. This exercise introduces the Gram-Schmidt process, a powerful and systematic algorithm for transforming a non-orthogonal basis into an orthogonal one. Mastering this constructive method is a key step towards developing sophisticated function approximations and numerical solutions [@problem_id:2161554].", "id": "2161554", "problem": "In numerical analysis and approximation theory, it is often useful to construct a set of orthogonal basis functions from a simpler, non-orthogonal set. Consider the space of real-valued functions that are continuous on the interval $[0, 1]$. The inner product of two functions $f(x)$ and $g(x)$ in this space is defined as:\n$$ \\langle f, g \\rangle = \\int_{0}^{1} f(x)g(x) \\, dx $$\nTwo functions are considered orthogonal if their inner product is zero.\n\nStarting with the initial, non-orthogonal basis set of functions $\\{v_1(x), v_2(x)\\}$, where $v_1(x) = 1$ and $v_2(x) = x$, construct a new set of orthogonal basis functions $\\{u_1(x), u_2(x)\\}$ by applying the following procedure:\n1.  Set the first orthogonal function to be the same as the first initial function: $u_1(x) = v_1(x)$.\n2.  Construct the second orthogonal function by subtracting the projection of $v_2(x)$ onto $u_1(x)$:\n    $$ u_2(x) = v_2(x) - \\frac{\\langle v_2, u_1 \\rangle}{\\langle u_1, u_1 \\rangle} u_1(x) $$\n\nFind the resulting orthogonal functions $u_1(x)$ and $u_2(x)$. Present your answer as a pair of functions.\n\n", "solution": "We work in the space of continuous real-valued functions on $[0,1]$ with inner product $\\langle f,g\\rangle=\\int_{0}^{1}f(x)g(x)\\,dx$. The initial set is $v_{1}(x)=1$ and $v_{2}(x)=x$.\n\nStep 1: Set $u_{1}(x)=v_{1}(x)=1$ by the given procedure.\n\nStep 2: Compute the projection coefficient of $v_{2}$ onto $u_{1}$:\n$$\n\\langle v_{2},u_{1}\\rangle=\\int_{0}^{1}x\\cdot 1\\,dx=\\int_{0}^{1}x\\,dx=\\frac{1}{2},\n\\qquad\n\\langle u_{1},u_{1}\\rangle=\\int_{0}^{1}1\\cdot 1\\,dx=\\int_{0}^{1}1\\,dx=1.\n$$\nThus,\n$$\nu_{2}(x)=v_{2}(x)-\\frac{\\langle v_{2},u_{1}\\rangle}{\\langle u_{1},u_{1}\\rangle}u_{1}(x)\n=x-\\frac{\\frac{1}{2}}{1}\\cdot 1=x-\\frac{1}{2}.\n$$\n\nVerification of orthogonality:\n$$\n\\langle u_{1},u_{2}\\rangle=\\int_{0}^{1}1\\cdot\\left(x-\\frac{1}{2}\\right)\\,dx=\\int_{0}^{1}x\\,dx-\\frac{1}{2}\\int_{0}^{1}1\\,dx=\\frac{1}{2}-\\frac{1}{2}=0,\n$$\nso $u_{1}$ and $u_{2}$ are orthogonal. Therefore, the orthogonal pair is $u_{1}(x)=1$ and $u_{2}(x)=x-\\frac{1}{2}$.", "answer": "$$\\boxed{\\begin{pmatrix}1 & x-\\frac{1}{2}\\end{pmatrix}}$$"}]}