{"hands_on_practices": [{"introduction": "The power of randomized algorithms often begins with a surprisingly simple step: creating a smaller, more manageable 'sketch' of a massive dataset. In Randomized Singular Value Decomposition (rSVD), this is achieved by multiplying the original large matrix $A$ with a slender random matrix $\\Omega$. This first exercise, [@problem_id:2196192], invites you to perform this fundamental sketching operation, $Y = A\\Omega$, by hand. Completing this calculation provides a concrete understanding of how a few random projections can capture essential information from the vast column space of the original matrix.", "problem": "In many modern data analysis applications, we encounter very large matrices for which standard computational techniques, like the full Singular Value Decomposition (SVD), are too slow. Randomized numerical linear algebra offers a powerful alternative by using random sampling to create a smaller, more manageable 'sketch' of the original matrix.\n\nConsider a matrix $A$ which represents some dataset. The first step in many randomized algorithms is to probe the action of $A$ by multiplying it with a random test matrix, $\\Omega$. This product forms a new matrix $Y = A\\Omega$, often called the sketched matrix, whose columns are random linear combinations of the columns of $A$. The matrix $Y$ serves as a low-dimensional proxy for the range (or column space) of the original matrix $A$.\n\nYou are given the following matrices:\n$$\nA = \\begin{pmatrix} 1 & 0 & -1 \\\\ 2 & 1 & 0 \\\\ 0 & -2 & 3 \\\\ 1 & 1 & 1 \\end{pmatrix}\n$$\nand a random test matrix\n$$\n\\Omega = \\begin{pmatrix} 2 & -1 \\\\ 1 & 0 \\\\ 3 & 2 \\end{pmatrix}\n$$\nCalculate the sketched matrix $Y = A\\Omega$.", "solution": "We form the sketched matrix by matrix multiplication $Y=A\\Omega$. For a product of a $4\\times 3$ matrix with a $3\\times 2$ matrix, the result is $4\\times 2$, with entries given by\n$$\nY_{ij}=\\sum_{k=1}^{3}A_{ik}\\Omega_{kj}.\n$$\nEquivalently, column-wise,\n$$\nY=[A\\omega_{1},A\\omega_{2}],\n$$\nwhere $\\omega_{1}$ and $\\omega_{2}$ are the columns of $\\Omega$.\n\nLet $\\omega_{1}=\\begin{pmatrix}2 \\\\ 1 \\\\ 3\\end{pmatrix}$ and $\\omega_{2}=\\begin{pmatrix}-1 \\\\ 0 \\\\ 2\\end{pmatrix}$. Then\n$$\nA\\omega_{1}\n=\n\\begin{pmatrix}\n1 & 0 & -1 \\\\\n2 & 1 & 0 \\\\\n0 & -2 & 3 \\\\\n1 & 1 & 1\n\\end{pmatrix}\n\\begin{pmatrix}\n2 \\\\ 1 \\\\ 3\n\\end{pmatrix}\n=\n\\begin{pmatrix}\n1\\cdot 2+0\\cdot 1+(-1)\\cdot 3 \\\\\n2\\cdot 2+1\\cdot 1+0\\cdot 3 \\\\\n0\\cdot 2+(-2)\\cdot 1+3\\cdot 3 \\\\\n1\\cdot 2+1\\cdot 1+1\\cdot 3\n\\end{pmatrix}\n=\n\\begin{pmatrix}\n-1 \\\\ 5 \\\\ 7 \\\\ 6\n\\end{pmatrix}.\n$$\nSimilarly,\n$$\nA\\omega_{2}\n=\n\\begin{pmatrix}\n1 & 0 & -1 \\\\\n2 & 1 & 0 \\\\\n0 & -2 & 3 \\\\\n1 & 1 & 1\n\\end{pmatrix}\n\\begin{pmatrix}\n-1 \\\\ 0 \\\\ 2\n\\end{pmatrix}\n=\n\\begin{pmatrix}\n1\\cdot(-1)+0\\cdot 0+(-1)\\cdot 2 \\\\\n2\\cdot(-1)+1\\cdot 0+0\\cdot 2 \\\\\n0\\cdot(-1)+(-2)\\cdot 0+3\\cdot 2 \\\\\n1\\cdot(-1)+1\\cdot 0+1\\cdot 2\n\\end{pmatrix}\n=\n\\begin{pmatrix}\n-3 \\\\ -2 \\\\ 6 \\\\ 1\n\\end{pmatrix}.\n$$\nTherefore,\n$$\nY=A\\Omega=\n\\begin{pmatrix}\n-1 & -3 \\\\\n5 & -2 \\\\\n7 & 6 \\\\\n6 & 1\n\\end{pmatrix}.\n$$", "answer": "$$\\boxed{\\begin{pmatrix}-1 & -3 \\\\ 5 & -2 \\\\ 7 & 6 \\\\ 6 & 1\\end{pmatrix}}$$", "id": "2196192"}, {"introduction": "After performing the initial sketch, a natural next question is: what happens next, and how does the data shrink at each stage? This practice [@problem_id:2196156] shifts our focus from numerical calculation to the architectural blueprint of the rSVD algorithm. By tracing the dimensions of each matrix—from the random test matrix $\\Omega$ to the final components of the SVD—you will develop a clear mental map of the algorithm's data flow and see precisely how dimensionality reduction is achieved at every step.", "problem": "The Randomized Singular Value Decomposition (rSVD) is a powerful algorithm for computing a low-rank approximation of a large matrix. Consider a matrix $A \\in \\mathbb{R}^{m \\times n}$ with $m=1000$ and $n=500$. We wish to find a rank-$k$ approximation of $A$ using rSVD with a target rank of $k=10$ and an oversampling parameter of $p=5$.\n\nThe main steps of this variant of the rSVD algorithm are as follows:\n1. Generate a random Gaussian matrix $\\Omega$.\n2. Form a sketched matrix $Y = A\\Omega$.\n3. Compute an orthonormal basis $Q$ for the column space of $Y$ (e.g., using a QR decomposition).\n4. Form the smaller projected matrix $B = Q^T A$.\n5. Compute the economy-size Singular Value Decomposition (SVD) of the matrix $B$, which is given by $B = \\tilde{U}\\Sigma V^T$.\n\nBased on the parameters provided, determine the dimensions of the following matrices in the order they are listed: $\\Omega$, $Y$, $B$, $\\tilde{U}$, and $V$. The dimensions should be represented as a pair (rows, columns).\n\nSelect the option that correctly lists the sequence of dimensions for $(\\Omega, Y, B, \\tilde{U}, V)$.\n\nA. $(500, 15), (1000, 15), (15, 500), (15, 15), (500, 15)$\n\nB. $(500, 10), (1000, 10), (10, 500), (10, 10), (500, 10)$\n\nC. $(500, 15), (1000, 15), (15, 500), (15, 15), (500, 500)$\n\nD. $(500, 15), (1000, 15), (500, 15), (500, 15), (15, 15)$\n\nE. $(1000, 15), (500, 15), (15, 1000), (15, 15), (1000, 15)$", "solution": "Let $A \\in \\mathbb{R}^{m \\times n}$ with $m=1000$ and $n=500$. The target rank is $k=10$ and the oversampling parameter is $p=5$. Define the sketch size $l$ by $l=k+p$, so $l=15$.\n\nStep 1 (random test matrix): To form a column sketch $Y=A\\Omega$, the Gaussian matrix must have size $\\Omega \\in \\mathbb{R}^{n \\times l}$ so that the product is defined. Therefore, $\\Omega$ has dimensions $(500, 15)$.\n\nStep 2 (sketched matrix): Compute\n$$\nY = A \\Omega,\n$$\nwhere $A \\in \\mathbb{R}^{1000 \\times 500}$ and $\\Omega \\in \\mathbb{R}^{500 \\times 15}$. Hence, $Y \\in \\mathbb{R}^{1000 \\times 15}$, i.e., $(1000, 15)$.\n\nStep 3 (orthonormal basis): An orthonormal basis $Q$ for the columns of $Y$ has the same number of rows as $A$ and $l$ columns, so $Q \\in \\mathbb{R}^{1000 \\times 15}$.\n\nStep 4 (projected matrix): Form\n$$\nB = Q^{T} A.\n$$\nHere, $Q^{T} \\in \\mathbb{R}^{15 \\times 1000}$ and $A \\in \\mathbb{R}^{1000 \\times 500}$, so $B \\in \\mathbb{R}^{15 \\times 500}$, i.e., $(15, 500)$.\n\nStep 5 (economy-size SVD of $B$): For $B \\in \\mathbb{R}^{l \\times n}$ with $l \\leq n$, the economy SVD\n$$\nB = \\tilde{U} \\Sigma V^{T}\n$$\nhas $\\tilde{U} \\in \\mathbb{R}^{l \\times l}$ and $V \\in \\mathbb{R}^{n \\times l}$. Therefore, $\\tilde{U}$ has dimensions $(15, 15)$ and $V$ has dimensions $(500, 15)$.\n\nCollecting these, the sequence $(\\Omega, Y, B, \\tilde{U}, V)$ is $(500, 15), (1000, 15), (15, 500), (15, 15), (500, 15)$, which matches option A.", "answer": "$$\\boxed{A}$$", "id": "2196156"}, {"introduction": "Why do we bother with randomized methods when classical algorithms for SVD exist? The answer lies in computational efficiency. This hands-on practice, [@problem_id:2196151], takes you under the hood to analyze the performance of rSVD by estimating its computational cost in floating-point operations (flops). By deriving the cost for the critical 'range-finding' stage, you will gain a quantitative appreciation for the immense speed advantages that make rSVD an indispensable tool for modern large-scale data analysis.", "problem": "In modern numerical linear algebra, randomized algorithms are frequently employed to compute approximate low-rank decompositions of very large matrices. A key step in many of these methods, such as the randomized Singular Value Decomposition (SVD), is the \"range-finding\" stage. This stage aims to construct a matrix $Q$ whose columns form an orthonormal basis that approximates the range (column space) of a given data matrix $A$.\n\nConsider a dense data matrix $A \\in \\mathbb{R}^{m \\times n}$, where we assume $m \\ge n$. The standard range-finding procedure involves two main computational steps:\n1.  A random test matrix $\\Omega \\in \\mathbb{R}^{n \\times k}$ is generated, where $k$ is an integer representing the target rank of the approximation, satisfying $k \\ll n$. A sample matrix $Y \\in \\mathbb{R}^{m \\times k}$ is then formed by computing the product $Y = A\\Omega$.\n2.  The columns of the sample matrix $Y$ are then orthonormalized to produce the matrix $Q \\in \\mathbb{R}^{m \\times k}$. This is achieved by computing a QR decomposition of $Y$.\n\nFor your calculations, use the following standard estimates for the number of floating-point operations (flops):\n- The product of a matrix $C \\in \\mathbb{R}^{p \\times q}$ and a matrix $D \\in \\mathbb{R}^{q \\times r}$ requires approximately $2pqr$ flops.\n- The QR decomposition of a matrix $M \\in \\mathbb{R}^{p \\times q}$ (with $p \\ge q$) using Householder reflections requires approximately $2pq^2 - \\frac{2}{3}q^3$ flops.\n\nDetermine the total approximate number of flops required for this range-finding procedure. Express your answer as a single closed-form analytic expression in terms of $m$, $n$, and $k$.", "solution": "We need the total flop count for two operations: forming the sample matrix $Y = A\\Omega$ and orthonormalizing $Y$ via a QR decomposition.\n\nFirst, compute $Y = A\\Omega$ with $A \\in \\mathbb{R}^{m \\times n}$ and $\\Omega \\in \\mathbb{R}^{n \\times k}$. Using the given estimate that multiplying a $p \\times q$ matrix by a $q \\times r$ matrix costs approximately $2pqr$ flops, we substitute $p = m$, $q = n$, and $r = k$ to obtain the cost\n$$\n\\text{flops for } Y = A\\Omega: \\quad 2mnk.\n$$\n\nSecond, compute the QR decomposition of $Y \\in \\mathbb{R}^{m \\times k}$ with $m \\ge k$. Using the given estimate for Householder QR, which for a $p \\times q$ matrix with $p \\ge q$ costs approximately $2pq^{2} - \\frac{2}{3}q^{3}$ flops, we substitute $p = m$ and $q = k$ to obtain\n$$\n\\text{flops for QR of } Y: \\quad 2mk^{2} - \\frac{2}{3}k^{3}.\n$$\n\nAdding these two contributions gives the total approximate flop count for the range-finding procedure:\n$$\n2mnk + 2mk^{2} - \\frac{2}{3}k^{3}.\n$$", "answer": "$$\\boxed{2mnk+2mk^{2}-\\frac{2}{3}k^{3}}$$", "id": "2196151"}]}