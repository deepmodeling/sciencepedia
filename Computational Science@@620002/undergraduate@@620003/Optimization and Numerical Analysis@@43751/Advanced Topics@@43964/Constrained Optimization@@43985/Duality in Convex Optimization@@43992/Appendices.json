{"hands_on_practices": [{"introduction": "The first step in leveraging the power of duality is mastering the mechanics of constructing the dual problem. This exercise provides foundational practice by asking you to derive the Lagrange dual function for a simple, single-variable quadratic problem with interval constraints [@problem_id:2167425]. By systematically forming the Lagrangian and finding its infimum, you will build the essential skills needed to tackle more complex optimization scenarios.", "problem": "Consider the optimization problem of minimizing the function $f(x) = c x^2$ with respect to the real variable $x$. The function is parameterized by a positive constant $c$. The optimization is subject to the constraint that $x$ must lie in the closed interval $[a, b]$, where $a$ and $b$ are real constants satisfying $a < b$.\n\nYour task is to formulate the Lagrange dual of this problem. Specifically, find the dual function $g(\\lambda, \\mu)$, where $\\lambda$ is the Lagrange multiplier associated with the constraint $a \\le x$ and $\\mu$ is the Lagrange multiplier associated with the constraint $x \\le b$. Express your answer for $g(\\lambda, \\mu)$ as a function of the parameters $a, b, c$ and the dual variables $\\lambda, \\mu$.", "solution": "We rewrite the constraints in standard inequality form as $g_{1}(x) = a - x \\le 0$ and $g_{2}(x) = x - b \\le 0$. Associate Lagrange multipliers $\\lambda \\ge 0$ with $g_{1}$ and $\\mu \\ge 0$ with $g_{2}$. The Lagrangian is\n$$\nL(x,\\lambda,\\mu) = c x^{2} + \\lambda(a - x) + \\mu(x - b) = c x^{2} + (\\mu - \\lambda)x + \\lambda a - \\mu b.\n$$\nThe dual function is $g(\\lambda,\\mu) = \\inf_{x \\in \\mathbb{R}} L(x,\\lambda,\\mu)$. Since $c > 0$, $L$ is strictly convex in $x$. The minimizer satisfies the first-order condition\n$$\n\\frac{\\partial L}{\\partial x} = 2 c x + (\\mu - \\lambda) = 0 \\quad \\Rightarrow \\quad x^{\\ast} = \\frac{\\lambda - \\mu}{2 c}.\n$$\nSubstituting $x^{\\ast}$ into $L$ yields\n$$\ng(\\lambda,\\mu) = c \\left(\\frac{\\lambda - \\mu}{2 c}\\right)^{2} + (\\mu - \\lambda)\\left(\\frac{\\lambda - \\mu}{2 c}\\right) + \\lambda a - \\mu b = - \\frac{(\\mu - \\lambda)^{2}}{4 c} + \\lambda a - \\mu b,\n$$\nvalid for $\\lambda \\ge 0$ and $\\mu \\ge 0$.", "answer": "$$\\boxed{-\\frac{(\\mu - \\lambda)^{2}}{4 c} + \\lambda a - \\mu b}$$", "id": "2167425"}, {"introduction": "Once we can formulate a dual problem, the next step is to use its properties to find a solution. This practice focuses on applying the Karush-Kuhn-Tucker (KKT) conditions to pinpoint the primal-dual optimal solution, also known as the saddle point of the Lagrangian [@problem_id:2167418]. Working through this example provides a concrete understanding of how conditions like stationarity and complementary slackness forge a direct link between the primal and dual variables at optimality.", "problem": "In a simplified machine learning scenario, the cost associated with a model parameter, $x$, is described by the quadratic function $f(x) = \\frac{1}{2}x^2$. To prevent underfitting and ensure the model has a minimum level of complexity, a domain expert imposes a constraint that the parameter $x$ must be at least 2. This leads to a constrained optimization problem.\n\nThe Lagrangian function for this problem is defined as $L(x, \\lambda) = f(x) + \\lambda g(x)$, where $g(x) \\le 0$ represents the inequality constraint and $\\lambda \\ge 0$ is the Lagrange multiplier.\n\nYour task is to find the saddle point $(x^*, \\lambda^*)$ of the Lagrangian. This point corresponds to the optimal parameter value $x^*$ that minimizes the cost function subject to the constraint, and the associated optimal Lagrange multiplier $\\lambda^*$.\n\nReport the saddle point as an ordered pair $(x^*, \\lambda^*)$.", "solution": "We are given the convex quadratic objective $f(x) = \\frac{1}{2}x^{2}$ and the inequality constraint $x \\geq 2$. To express this in the standard form $g(x) \\leq 0$, define $g(x) = 2 - x$, so the constraint is $g(x) \\leq 0$. The Lagrangian is\n$$\nL(x, \\lambda) = \\frac{1}{2}x^{2} + \\lambda(2 - x),\n$$\nwith dual feasibility $\\lambda \\geq 0$.\n\nFor a convex problem with affine constraint, the Karush–Kuhn–Tucker conditions are necessary and sufficient for optimality and for characterizing a saddle point. The KKT conditions are:\n- Primal feasibility: $g(x^{*}) \\leq 0$, i.e., $x^{*} \\geq 2$.\n- Dual feasibility: $\\lambda^{*} \\geq 0$.\n- Stationarity: $\\frac{\\partial L}{\\partial x}(x^{*}, \\lambda^{*}) = 0$.\n- Complementary slackness: $\\lambda^{*} g(x^{*}) = 0$.\n\nCompute the stationarity condition:\n$$\n\\frac{\\partial L}{\\partial x} = x - \\lambda \\quad \\Rightarrow \\quad x^{*} - \\lambda^{*} = 0 \\quad \\Rightarrow \\quad x^{*} = \\lambda^{*}.\n$$\nApply complementary slackness:\n$$\n\\lambda^{*}(2 - x^{*}) = 0.\n$$\nConsider the cases:\n- If $\\lambda^{*} = 0$, then from stationarity $x^{*} = 0$, which violates primal feasibility $x^{*} \\geq 2$; reject this case.\n- Therefore $2 - x^{*} = 0 \\Rightarrow x^{*} = 2$. Then by stationarity $\\lambda^{*} = x^{*} = 2$, which satisfies $\\lambda^{*} \\geq 0$ and $x^{*} \\geq 2$.\n\nThus, the unique KKT point is $(x^{*}, \\lambda^{*}) = (2, 2)$. Because the problem is convex with an affine constraint, this KKT point is the saddle point of the Lagrangian. Equivalently, verifying the saddle property: $L(x, 2)$ is minimized at $x = 2$, and $L(2, \\lambda) = 2$ for all $\\lambda \\geq 0$, with the dual maximizer at $\\lambda^{*} = 2$.", "answer": "$$\\boxed{\\begin{pmatrix} 2 & 2 \\end{pmatrix}}$$", "id": "2167418"}, {"introduction": "Duality theory offers profound insights not just when a solution exists, but also when one doesn't. This problem explores the relationship between a primal problem that is infeasible—meaning no solution satisfies the constraints—and the behavior of its corresponding dual problem [@problem_id:2167417]. Investigating this special case reveals a fundamental principle concerning dual unboundedness and provides a more complete picture of the primal-dual connection.", "problem": "Consider the following convex optimization problem:\n$$\n\\begin{array}{ll}\n\\text{minimize} & f_0(x) = c \\\\\n\\text{subject to} & x \\ge a \\\\\n& x \\le b\n\\end{array}\n$$\nwhere $x \\in \\mathbb{R}$ is the optimization variable. The parameters $a, b, c$ are fixed real constants satisfying the condition $a > b$.\n\nWhat is the optimal value, $d^*$, of the corresponding Lagrange dual problem?\n\nA. $c$\n\nB. $b-a$\n\nC. $0$\n\nD. $-\\infty$\n\nE. $+\\infty$", "solution": "We first rewrite the constraints in the standard form for inequalities used in the Lagrangian. The constraint $x \\ge a$ is equivalent to $g_{1}(x) = a - x \\le 0$, and $x \\le b$ is equivalent to $g_{2}(x) = x - b \\le 0$. With Lagrange multipliers $\\lambda \\ge 0$ for $g_{1}$ and $\\mu \\ge 0$ for $g_{2}$, the Lagrangian is\n$$\nL(x,\\lambda,\\mu) = c + \\lambda(a - x) + \\mu(x - b) = c + \\lambda a - \\mu b + (\\mu - \\lambda)x.\n$$\nThe dual function is the infimum of $L$ over $x \\in \\mathbb{R}$:\n$$\ng(\\lambda,\\mu) = \\inf_{x \\in \\mathbb{R}} \\left[c + \\lambda a - \\mu b + (\\mu - \\lambda)x\\right].\n$$\nIf $\\mu \\ne \\lambda$, then the term $(\\mu - \\lambda)x$ is linear with nonzero slope in the unbounded variable $x$, so\n$$\ng(\\lambda,\\mu) = -\\infty \\quad \\text{for } \\mu \\ne \\lambda.\n$$\nIf $\\mu = \\lambda$, the $x$-term vanishes and\n$$\ng(\\lambda,\\lambda) = c + \\lambda(a - b).\n$$\nHence the dual problem is\n$$\n\\text{maximize } g(\\lambda,\\mu) \\quad \\text{subject to } \\lambda \\ge 0,\\ \\mu \\ge 0,\n$$\nwhich reduces to\n$$\n\\text{maximize } c + \\lambda(a - b) \\quad \\text{subject to } \\lambda \\ge 0,\n$$\nsince any $(\\lambda,\\mu)$ with $\\mu \\ne \\lambda$ yields $g(\\lambda,\\mu) = -\\infty$. Given the assumption $a > b$, we have $a - b > 0$, so the dual objective $c + \\lambda(a - b)$ increases without bound as $\\lambda \\to +\\infty$. Therefore, the dual optimal value is\n$$\nd^{*} = +\\infty,\n$$\nwhich corresponds to option E.", "answer": "$$\\boxed{E}$$", "id": "2167417"}]}