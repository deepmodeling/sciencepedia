{"hands_on_practices": [{"introduction": "Sequential Quadratic Programming (SQP) works by iteratively solving a series of simpler Quadratic Programming (QP) subproblems. The first step in this process is to construct a local model of the original nonlinear problem at the current iterate. This practice [@problem_id:2201991] provides foundational drill in calculating the necessary first-order information—the gradient of the objective function, $\\nabla f(\\mathbf{x})$, and the Jacobian of the constraints, $J_h(\\mathbf{x})$—which form the core components of the QP subproblem.", "problem": "Consider the nonlinear optimization problem:\nMinimize $f(x_1, x_2) = \\exp(x_1 + x_2)$\nSubject to the equality constraint $h(x_1, x_2) = x_1^2 + x_2^2 - 1 = 0$.\n\nAn effective method for solving such problems is the Sequential Quadratic Programming (SQP) algorithm. The first iteration of this algorithm begins at an initial point $\\mathbf{x}_0$ and involves solving a Quadratic Programming (QP) subproblem. To construct this subproblem, we need the gradient of the objective function, $\\nabla f(\\mathbf{x})$, and the Jacobian of the constraint function, $J_h(\\mathbf{x})$.\n\nGiven the initial point $\\mathbf{x}_0 = (1, 1)$, determine the gradient of the objective function, $\\nabla f(\\mathbf{x}_0)$, and the Jacobian of the constraint, $J_h(\\mathbf{x}_0)$.\n\nPresent your result as a single $2 \\times 2$ matrix, where the first row consists of the components of the transposed gradient of the objective function, $\\nabla f(\\mathbf{x}_0)^T$, and the second row consists of the components of the Jacobian of the constraint function, $J_h(\\mathbf{x}_0)$.", "solution": "We are given the objective function $f(x_{1},x_{2})=\\exp(x_{1}+x_{2})$ and the equality constraint $h(x_{1},x_{2})=x_{1}^{2}+x_{2}^{2}-1=0$, with initial point $\\mathbf{x}_{0}=(1,1)$. We need $\\nabla f(\\mathbf{x}_{0})$ and $J_{h}(\\mathbf{x}_{0})$.\n\nFirst, compute the gradient of the objective function. Using the chain rule on $f(x_{1},x_{2})=\\exp(x_{1}+x_{2})$,\n$$\n\\frac{\\partial f}{\\partial x_{1}}=\\exp(x_{1}+x_{2}), \\quad \\frac{\\partial f}{\\partial x_{2}}=\\exp(x_{1}+x_{2}).\n$$\nThus,\n$$\n\\nabla f(x_{1},x_{2})=\\begin{pmatrix}\\exp(x_{1}+x_{2}) \\\\ \\exp(x_{1}+x_{2})\\end{pmatrix}.\n$$\nEvaluating at $\\mathbf{x}_{0}=(1,1)$ gives\n$$\n\\nabla f(\\mathbf{x}_{0})=\\begin{pmatrix}\\exp(2) \\\\ \\exp(2)\\end{pmatrix}, \\quad \\nabla f(\\mathbf{x}_{0})^{T}=\\begin{pmatrix}\\exp(2)  \\exp(2)\\end{pmatrix}.\n$$\n\nNext, compute the Jacobian of the constraint. For $h(x_{1},x_{2})=x_{1}^{2}+x_{2}^{2}-1$, the partial derivatives are\n$$\n\\frac{\\partial h}{\\partial x_{1}}=2x_{1}, \\quad \\frac{\\partial h}{\\partial x_{2}}=2x_{2}.\n$$\nSince $h:\\mathbb{R}^{2}\\to\\mathbb{R}$, its Jacobian is the $1\\times 2$ row vector\n$$\nJ_{h}(x_{1},x_{2})=\\begin{pmatrix}2x_{1}  2x_{2}\\end{pmatrix}.\n$$\nEvaluating at $\\mathbf{x}_{0}=(1,1)$ gives\n$$\nJ_{h}(\\mathbf{x}_{0})=\\begin{pmatrix}2  2\\end{pmatrix}.\n$$\n\nTherefore, the requested $2\\times 2$ matrix, with the first row equal to $\\nabla f(\\mathbf{x}_{0})^{T}$ and the second row equal to $J_{h}(\\mathbf{x}_{0})$, is\n$$\n\\begin{pmatrix}\n\\exp(2)  \\exp(2) \\\\\n2  2\n\\end{pmatrix}.\n$$", "answer": "$$\\boxed{\\begin{pmatrix}\\exp(2)  \\exp(2) \\\\ 2  2\\end{pmatrix}}$$", "id": "2201991"}, {"introduction": "Once the QP subproblem is formulated, the next step is to solve it to find the search direction, $p$, for the current iteration. This vector points towards a potential better solution by aiming to improve the objective function while respecting the linearized constraints. This exercise [@problem_id:2202023] walks you through this core computational step, demonstrating how to solve a simple QP subproblem to obtain the search direction that drives the SQP algorithm forward.", "problem": "Consider the nonlinear optimization problem of minimizing a function $f(x_1, x_2)$ subject to an equality constraint $c(x_1, x_2) = 0$. The Sequential Quadratic Programming (SQP) method is an iterative algorithm for solving such problems. In each iteration, a search direction is found by solving a Quadratic Programming (QP) subproblem, which is constructed from a quadratic model of the Lagrangian function and a linear model of the constraints.\n\nLet the objective function be $f(x_1, x_2) = x_1 + x_2^2$ and the equality constraint be given by the equation $(x_1-1)^2 + x_2^2 = 1$.\n\nWe wish to perform the first iteration of an SQP algorithm starting from the initial point $x_0 = (1, 1)$. The QP subproblem to find the search direction $p = (p_1, p_2)$ is defined as:\n\nMinimize: $q(p) = \\frac{1}{2} p^T B_0 p + \\nabla f(x_0)^T p$\nSubject to: $\\nabla c(x_0)^T p + c(x_0) = 0$\n\nFor this problem, use the identity matrix, $B_0 = I$, as the approximation to the Hessian of the Lagrangian. The constraint function is defined as $c(x_1, x_2) = (x_1-1)^2 + x_2^2 - 1$.\n\nDetermine the search direction $p = (p_1, p_2)$ obtained by solving this first QP subproblem. Express your answer for $p$ as a row matrix.", "solution": "We are given $f(x_{1},x_{2})=x_{1}+x_{2}^{2}$ and $c(x_{1},x_{2})=(x_{1}-1)^{2}+x_{2}^{2}-1$, with $x_{0}=(1,1)$, and $B_{0}=I$. The QP subproblem is\n$$\n\\min_{p}\\; q(p)=\\frac{1}{2}p^{T}Ip+\\nabla f(x_{0})^{T}p\n\\quad\\text{s.t.}\\quad \\nabla c(x_{0})^{T}p+c(x_{0})=0.\n$$\nCompute gradients at $x_{0}$:\n$$\n\\nabla f(x)=\\begin{pmatrix}1\\\\2x_{2}\\end{pmatrix}\\;\\Rightarrow\\;\\nabla f(x_{0})=\\begin{pmatrix}1\\\\2\\end{pmatrix},\\qquad\n\\nabla c(x)=\\begin{pmatrix}2(x_{1}-1)\\\\2x_{2}\\end{pmatrix}\\;\\Rightarrow\\;\\nabla c(x_{0})=\\begin{pmatrix}0\\\\2\\end{pmatrix}.\n$$\nAlso $c(x_{0})=(1-1)^{2}+1^{2}-1=0$. Hence the QP is\n$$\n\\min_{p}\\;\\frac{1}{2}(p_{1}^{2}+p_{2}^{2})+p_{1}+2p_{2}\n\\quad\\text{s.t.}\\quad 0\\cdot p_{1}+2p_{2}+0=0\\;\\Rightarrow\\;p_{2}=0.\n$$\nWith $p_{2}=0$, the objective reduces to\n$$\n\\min_{p_{1}}\\;\\frac{1}{2}p_{1}^{2}+p_{1},\n$$\nwhose first-order condition $p_{1}+1=0$ yields $p_{1}=-1$.\n\nEquivalently, solving the KKT system for the QP,\n$$\nIp+\\nabla f(x_{0})+\\lambda\\,\\nabla c(x_{0})=0,\\qquad \\nabla c(x_{0})^{T}p=0,\n$$\ngives the component equations\n$$\np_{1}+1+0\\cdot\\lambda=0,\\quad p_{2}+2+2\\lambda=0,\\quad 0\\cdot p_{1}+2p_{2}=0,\n$$\nfrom which $p_{2}=0$, $p_{1}=-1$, and $\\lambda=-1$.\n\nTherefore, the SQP search direction is $p=(-1,0)$, expressed as a row matrix.", "answer": "$$\\boxed{\\begin{pmatrix}-1  0\\end{pmatrix}}$$", "id": "2202023"}, {"introduction": "While SQP is a powerful technique, its reliance on local linear models is not foolproof. A common issue arises when the linearized constraints become mutually inconsistent, which makes the QP subproblem infeasible and means no search direction can be found. This hands-on problem [@problem_id:2202038] illustrates such a scenario, providing critical insight into this potential failure mode and highlighting why practical SQP implementations must include strategies to handle such cases.", "problem": "Consider the following Non-Linear Programming (NLP) problem in two variables, $x_1$ and $x_2$:\n\nMinimize $f(x_1, x_2) = (x_1-5)^2 + x_2^2$\n\nSubject to the constraints:\n$c_1(x_1, x_2) = -x_1^2 + x_2 - 1 \\ge 0$\n$c_2(x_1, x_2) = 0.2x_1^4 + x_2^2 - x_2 - 1 \\ge 0$\n\nAn optimization algorithm based on Sequential Quadratic Programming (SQP) is used to solve this problem. The algorithm starts from the initial point $x_0 = (0, 0)$. In the first iteration of the SQP method, a Quadratic Programming (QP) subproblem is formulated to find a search direction (step) $p = (p_1, p_2)$. This QP subproblem is constructed using a quadratic approximation of the objective function and a linearization of the constraints at the current point $x_0$.\n\nWhich of the following statements correctly describes the first QP subproblem for the search direction $p$?\n\nA. The QP subproblem is unbounded.\n\nB. The QP subproblem has a unique non-zero solution for $p$.\n\nC. The only feasible solution to the QP subproblem is $p=0$.\n\nD. The QP subproblem is infeasible.\n\nE. The current point $x_0$ must be a local minimizer of the original NLP.", "solution": "We use the standard SQP first QP subproblem at the current iterate $x_{0}=(0,0)$. The QP minimizes a quadratic model of the Lagrangian with linearized constraints:\n$$\n\\min_{p\\in\\mathbb{R}^{2}} \\;\\; \\nabla f(x_{0})^{\\top}p + \\frac{1}{2} p^{\\top} B_{0} p\n\\quad\\text{subject to}\\quad\nc_{i}(x_{0}) + \\nabla c_{i}(x_{0})^{\\top} p \\ge 0,\\; i=1,2,\n$$\nwhere, with initial multipliers taken as zero, $B_{0}$ is typically chosen as $\\nabla^{2} f(x_{0})$.\n\nCompute the ingredients at $x_{0}$:\n- Objective: $f(x_{1},x_{2})=(x_{1}-5)^{2}+x_{2}^{2}$, so\n$$\n\\nabla f(x) = \\begin{pmatrix} 2(x_{1}-5) \\\\ 2 x_{2} \\end{pmatrix}, \\quad \\nabla f(x_{0})=\\begin{pmatrix} -10 \\\\ 0 \\end{pmatrix}, \\quad \\nabla^{2} f(x)=\\begin{pmatrix} 2  0 \\\\ 0  2 \\end{pmatrix}, \\; B_{0}=\\begin{pmatrix} 2  0 \\\\ 0  2 \\end{pmatrix}.\n$$\n- Constraints and their linearizations:\nFor $c_{1}(x)=-x_{1}^{2}+x_{2}-1$,\n$$\nc_{1}(x_{0})=-1,\\quad \\nabla c_{1}(x)=\\begin{pmatrix} -2 x_{1} \\\\ 1 \\end{pmatrix},\\quad \\nabla c_{1}(x_{0})=\\begin{pmatrix} 0 \\\\ 1 \\end{pmatrix},\n$$\nhence\n$$\nc_{1}(x_{0})+\\nabla c_{1}(x_{0})^{\\top}p = -1 + p_{2} \\ge 0 \\;\\;\\Longleftrightarrow\\;\\; p_{2} \\ge 1.\n$$\nFor $c_{2}(x)=0.2\\,x_{1}^{4}+x_{2}^{2}-x_{2}-1$,\n$$\nc_{2}(x_{0})=-1,\\quad \\nabla c_{2}(x)=\\begin{pmatrix} 0.8\\,x_{1}^{3} \\\\ 2 x_{2}-1 \\end{pmatrix},\\quad \\nabla c_{2}(x_{0})=\\begin{pmatrix} 0 \\\\ -1 \\end{pmatrix},\n$$\nhence\n$$\nc_{2}(x_{0})+\\nabla c_{2}(x_{0})^{\\top}p = -1 - p_{2} \\ge 0 \\;\\;\\Longleftrightarrow\\;\\; p_{2} \\le -1.\n$$\nThe linearized constraints require simultaneously $p_{2} \\ge 1$ and $p_{2} \\le -1$, which is impossible. Therefore, the feasible set of the QP subproblem is empty, so the QP subproblem is infeasible.\n\nConsequently, among the listed statements, the correct one is that the QP subproblem is infeasible.", "answer": "$$\\boxed{D}$$", "id": "2202038"}]}