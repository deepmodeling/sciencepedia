{"hands_on_practices": [{"introduction": "Finding the operational limits of a material often involves identifying maximum stress states on a given yield surface. This exercise provides practice with exactly that by asking you to find the point on an ellipsoid that is furthest from the origin [@problem_id:2173341]. This is a classic application of the method of Lagrange multipliers to maximize a function subject to a single, non-linear equality constraint, providing a foundational understanding of the geometric interpretation of first-order conditions.", "problem": "In the study of plasticity for anisotropic materials, a yield surface is a criterion that defines the elastic limit of a material under a complex loading condition. For a specific orthotropic material, the state of principal stresses, denoted by the vector $(\\sigma_1, \\sigma_2, \\sigma_3)$, is constrained to lie on an ellipsoidal yield surface. The equation for this surface is given by:\n$$ \\frac{\\sigma_1^2}{S_1^2} + \\frac{\\sigma_2^2}{S_2^2} + \\frac{\\sigma_3^2}{S_3^2} = 1 $$\nHere, $S_1, S_2,$ and $S_3$ represent the material's yield strengths along its three principal axes. These are positive constants, and for this particular material, they are ordered such that $S_1 > S_2 > S_3 > 0$.\n\nWe are interested in finding the stress state on this yield surface that has the largest overall magnitude. The magnitude of the stress vector is defined as $M = \\sqrt{\\sigma_1^2 + \\sigma_2^2 + \\sigma_3^2}$.\n\nDetermine the maximum possible value of the magnitude $M$ for a stress state lying on this yield surface.", "solution": "The problem is to find the maximum value of the magnitude of the stress vector, $M = \\sqrt{\\sigma_1^2 + \\sigma_2^2 + \\sigma_3^2}$, for a point $(\\sigma_1, \\sigma_2, \\sigma_3)$ that lies on the surface of an ellipsoid defined by the constraint equation $\\frac{\\sigma_1^2}{S_1^2} + \\frac{\\sigma_2^2}{S_2^2} + \\frac{\\sigma_3^2}{S_3^2} = 1$.\n\nThis is a constrained optimization problem. To simplify the calculations, instead of maximizing $M$, we can maximize its square, $M^2$, since $M$ is always non-negative. Let the function to be maximized be $f(\\sigma_1, \\sigma_2, \\sigma_3) = \\sigma_1^2 + \\sigma_2^2 + \\sigma_3^2$. The constraint function is $g(\\sigma_1, \\sigma_2, \\sigma_3) = \\frac{\\sigma_1^2}{S_1^2} + \\frac{\\sigma_2^2}{S_2^2} + \\frac{\\sigma_3^2}{S_3^2} - 1 = 0$.\n\nWe use the method of Lagrange multipliers. The Lagrangian function, $\\mathcal{L}$, is defined as:\n$$ \\mathcal{L}(\\sigma_1, \\sigma_2, \\sigma_3, \\lambda) = f(\\sigma_1, \\sigma_2, \\sigma_3) - \\lambda g(\\sigma_1, \\sigma_2, \\sigma_3) $$\n$$ \\mathcal{L}(\\sigma_1, \\sigma_2, \\sigma_3, \\lambda) = (\\sigma_1^2 + \\sigma_2^2 + \\sigma_3^2) - \\lambda \\left( \\frac{\\sigma_1^2}{S_1^2} + \\frac{\\sigma_2^2}{S_2^2} + \\frac{\\sigma_3^2}{S_3^2} - 1 \\right) $$\nTo find the extrema, we compute the partial derivatives of $\\mathcal{L}$ with respect to $\\sigma_1, \\sigma_2, \\sigma_3$, and $\\lambda$ and set them to zero.\n$$ \\frac{\\partial \\mathcal{L}}{\\partial \\sigma_1} = 2\\sigma_1 - \\frac{2\\lambda \\sigma_1}{S_1^2} = 2\\sigma_1 \\left( 1 - \\frac{\\lambda}{S_1^2} \\right) = 0 $$\n$$ \\frac{\\partial \\mathcal{L}}{\\partial \\sigma_2} = 2\\sigma_2 - \\frac{2\\lambda \\sigma_2}{S_2^2} = 2\\sigma_2 \\left( 1 - \\frac{\\lambda}{S_2^2} \\right) = 0 $$\n$$ \\frac{\\partial \\mathcal{L}}{\\partial \\sigma_3} = 2\\sigma_3 - \\frac{2\\lambda \\sigma_3}{S_3^2} = 2\\sigma_3 \\left( 1 - \\frac{\\lambda}{S_3^2} \\right) = 0 $$\n$$ \\frac{\\partial \\mathcal{L}}{\\partial \\lambda} = -\\left( \\frac{\\sigma_1^2}{S_1^2} + \\frac{\\sigma_2^2}{S_2^2} + \\frac{\\sigma_3^2}{S_3^2} - 1 \\right) = 0 $$\nThe last equation is simply the original constraint. From the first three equations, we analyze the conditions for a non-trivial solution (the origin $(\\sigma_1, \\sigma_2, \\sigma_3) = (0,0,0)$ is not on the ellipsoid, as it does not satisfy the constraint).\n\nCase 1: $\\sigma_1 \\neq 0$, $\\sigma_2 = 0$, $\\sigma_3 = 0$.\nThe first equation gives $1 - \\frac{\\lambda}{S_1^2} = 0$, which implies $\\lambda = S_1^2$. The second and third equations are satisfied since $\\sigma_2=0$ and $\\sigma_3=0$.\nSubstituting $\\sigma_2 = 0$ and $\\sigma_3 = 0$ into the constraint equation:\n$$ \\frac{\\sigma_1^2}{S_1^2} + 0 + 0 = 1 \\implies \\sigma_1^2 = S_1^2 \\implies \\sigma_1 = \\pm S_1 $$\nThe candidate points are $(\\pm S_1, 0, 0)$. The value of our objective function at these points is $f = (\\pm S_1)^2 + 0^2 + 0^2 = S_1^2$.\n\nCase 2: $\\sigma_2 \\neq 0$, $\\sigma_1 = 0$, $\\sigma_3 = 0$.\nThe second equation gives $1 - \\frac{\\lambda}{S_2^2} = 0$, which implies $\\lambda = S_2^2$.\nSubstituting $\\sigma_1 = 0$ and $\\sigma_3 = 0$ into the constraint equation:\n$$ 0 + \\frac{\\sigma_2^2}{S_2^2} + 0 = 1 \\implies \\sigma_2^2 = S_2^2 \\implies \\sigma_2 = \\pm S_2 $$\nThe candidate points are $(0, \\pm S_2, 0)$. The value of the objective function is $f = 0^2 + (\\pm S_2)^2 + 0^2 = S_2^2$.\n\nCase 3: $\\sigma_3 \\neq 0$, $\\sigma_1 = 0$, $\\sigma_2 = 0$.\nThe third equation gives $1 - \\frac{\\lambda}{S_3^2} = 0$, which implies $\\lambda = S_3^2$.\nSubstituting $\\sigma_1 = 0$ and $\\sigma_2 = 0$ into the constraint equation:\n$$ 0 + 0 + \\frac{\\sigma_3^2}{S_3^2} = 1 \\implies \\sigma_3^2 = S_3^2 \\implies \\sigma_3 = \\pm S_3 $$\nThe candidate points are $(0, 0, \\pm S_3)$. The value of the objective function is $f = 0^2 + 0^2 + (\\pm S_3)^2 = S_3^2$.\n\nOther cases where more than one component of $(\\sigma_1, \\sigma_2, \\sigma_3)$ is non-zero are not possible. For example, if $\\sigma_1 \\neq 0$ and $\\sigma_2 \\neq 0$, then from the first two partial derivative equations, we must have $\\lambda = S_1^2$ and $\\lambda = S_2^2$. This would mean $S_1^2 = S_2^2$, which contradicts the given condition that $S_1 > S_2 > S_3 > 0$.\n\nNow we compare the values of the objective function $f = M^2$ from the three cases: $S_1^2, S_2^2, S_3^2$.\nWe are given that $S_1 > S_2 > S_3 > 0$. Squaring these positive values preserves the inequality: $S_1^2 > S_2^2 > S_3^2$.\nThe maximum value of $f = M^2$ is therefore $S_1^2$.\nThe maximum value of the magnitude $M$ is the square root of this value.\n$$ M_{\\text{max}} = \\sqrt{S_1^2} = S_1 $$\n(We take the positive root since $M$ is a magnitude and $S_1$ is given as positive).", "answer": "$$\\boxed{S_1}$$", "id": "2173341"}, {"introduction": "Real-world optimization problems often involve satisfying several conditions simultaneously, a scenario perfectly captured in this next practice. Here, you will find the highest and lowest points on a curve formed by the intersection of a cone and a plane [@problem_id:2173347]. Solving this requires extending the Lagrange multiplier method to handle multiple constraints, a crucial skill for tackling more complex systems where a solution must lie at the intersection of several surfaces.", "problem": "Consider a curve formed by the intersection of two surfaces in three-dimensional Euclidean space. The first surface is a double cone described by the equation $z^{2} = x^{2} + y^{2}$. The second surface is a plane defined by the equation $x + 2y + z = 4$.\n\nDetermine the maximum and minimum values of the $z$-coordinate for all points $(x,y,z)$ that lie on this intersection curve.\n\nProvide your answer as a pair of exact analytical values, ordered from the minimum value to the maximum value.", "solution": "We seek extrema of $f(x,y,z)=z$ on the curve defined by the constraints $g_{1}(x,y,z)=z^{2}-x^{2}-y^{2}=0$ and $g_{2}(x,y,z)=x+2y+z-4=0$. By the method of Lagrange multipliers, there exist $\\lambda$ and $\\mu$ such that\n$$\n\\nabla f=\\lambda\\,\\nabla g_{1}+\\mu\\,\\nabla g_{2}.\n$$\nCompute gradients: $\\nabla f=(0,0,1)$, $\\nabla g_{1}=(-2x,-2y,2z)$, and $\\nabla g_{2}=(1,2,1)$. Hence,\n$$\n(0,0,1)=\\lambda(-2x,-2y,2z)+\\mu(1,2,1).\n$$\nEquating components gives $0=-2\\lambda x+\\mu$, $0=-2\\lambda y+2\\mu$, and $1=2\\lambda z+\\mu$.\nFrom the first two equations, $\\mu=2\\lambda x$ and $\\mu=\\lambda y$, so either $\\lambda=0$ or $y=2x$. If $\\lambda=0$, then $\\mu=0$ from the first equation, which contradicts the third equation $1=2\\lambda z+\\mu=0$. Therefore $\\lambda\\neq 0$ and $y=2x$.\n\nImpose the constraints with $y=2x$. The plane equation $x+2y+z=4$ becomes $x+4x+z=4$, which simplifies to $z=4-5x$.\nThe cone equation $z^{2}=x^{2}+y^{2}$ becomes $z^{2}=x^{2}+(2x)^{2}=5x^{2}$.\nSubstituting the expression for $z$ from the plane into the cone equation gives $(4-5x)^{2}=5x^{2}$, which expands to $16-40x+25x^{2}=5x^{2}$ and simplifies to $20x^{2}-40x+16=0$.\nDividing by $4$ gives $5x^{2}-10x+4=0$, whose solutions are\n$$\nx=\\frac{10\\pm\\sqrt{100-80}}{10}=\\frac{10\\pm2\\sqrt{5}}{10}=1\\pm\\frac{\\sqrt{5}}{5}.\n$$\nThen\n$$\nz=4-5x=4-5\\left(1\\pm\\frac{\\sqrt{5}}{5}\\right)=-1\\mp\\sqrt{5}.\n$$\nThus the two critical $z$-values are $-1-\\sqrt{5}$ and $-1+\\sqrt{5}$. Since the intersection curve is bounded (an ellipse), these are respectively the minimum and maximum $z$-values on the curve.\n\nOrdered from minimum to maximum, the values are $-1-\\sqrt{5}$ and $-1+\\sqrt{5}$.", "answer": "$$\\boxed{\\begin{pmatrix}-1-\\sqrt{5} & -1+\\sqrt{5}\\end{pmatrix}}$$", "id": "2173347"}, {"introduction": "The principles of constrained optimization extend far beyond three-dimensional space, proving essential in fields like signal processing and machine learning. This exercise challenges you to apply these concepts in a more abstract setting: finding the coefficients for a trigonometric model that are closest to a theoretical target, while being constrained by an experimental data point [@problem_id:2173359]. This problem illustrates how to minimize a least-squares objective in a high-dimensional parameter space, a powerful technique fundamental to modern data fitting and model calibration.", "problem": "An engineer is modelling a periodic physical process using a trigonometric polynomial of the form $P(t) = c_1 \\cos(t) + c_2 \\sin(t) + c_3 \\cos(2t) + c_4 \\sin(2t)$. The coefficients are collected in a vector $\\mathbf{x} = (c_1, c_2, c_3, c_4)^T$. Based on prior theoretical work, an ideal set of coefficients is believed to be $\\mathbf{x}_{\\text{target}} = (2, 0, 1, 0)^T$. However, a new experimental measurement requires the model to satisfy the condition $P(\\pi/3) = 1$. The engineer decides to find the coefficient vector $\\mathbf{x}^*$ that is closest to the ideal vector $\\mathbf{x}_{\\text{target}}$ in a least-squares sense, while still satisfying the experimental constraint. This means minimizing the squared Euclidean norm $\\|\\mathbf{x} - \\mathbf{x}_{\\text{target}}\\|^2$. Determine the components of the optimal coefficient vector $\\mathbf{x}^* = (c_1^*, c_2^*, c_3^*, c_4^*)^T$. Present your answer as a row matrix containing the four coefficients in their exact fractional form.", "solution": "We minimize the squared Euclidean distance subject to a linear constraint. Let $\\mathbf{x}=(c_{1},c_{2},c_{3},c_{4})^{T}$, $\\mathbf{x}_{\\text{target}}=\\mathbf{x}_{0}=(2,0,1,0)^{T}$, and the constraint be $P(\\pi/3)=1$. This constraint can be written as $a^{T}\\mathbf{x}=b$ with\n$$\na=\\begin{pmatrix}\\cos(\\pi/3)\\\\ \\sin(\\pi/3)\\\\ \\cos(2\\pi/3)\\\\ \\sin(2\\pi/3)\\end{pmatrix}\n=\\begin{pmatrix}\\frac{1}{2}\\\\ \\frac{\\sqrt{3}}{2}\\\\ -\\frac{1}{2}\\\\ \\frac{\\sqrt{3}}{2}\\end{pmatrix},\\quad b=1.\n$$\nWe solve the constrained least-squares problem by orthogonal projection (equivalently, Lagrange multipliers). The standard result is\n$$\n\\mathbf{x}^{*}=\\mathbf{x}_{0}+\\frac{b-a^{T}\\mathbf{x}_{0}}{\\|a\\|^{2}}\\,a.\n$$\nCompute the needed quantities:\n$$\n\\|a\\|^{2}=\\left(\\frac{1}{2}\\right)^{2}+\\left(\\frac{\\sqrt{3}}{2}\\right)^{2}+\\left(-\\frac{1}{2}\\right)^{2}+\\left(\\frac{\\sqrt{3}}{2}\\right)^{2}=\\frac{1}{4}+\\frac{3}{4}+\\frac{1}{4}+\\frac{3}{4}=2,\n$$\n$$\na^{T}\\mathbf{x}_{0}=2\\cdot\\frac{1}{2}+0\\cdot\\frac{\\sqrt{3}}{2}+1\\cdot\\left(-\\frac{1}{2}\\right)+0\\cdot\\frac{\\sqrt{3}}{2}=\\frac{1}{2}.\n$$\nHence\n$$\n\\frac{b-a^{T}\\mathbf{x}_{0}}{\\|a\\|^{2}}=\\frac{1-\\frac{1}{2}}{2}=\\frac{1}{4},\n$$\nand therefore\n$$\n\\mathbf{x}^{*}=\\mathbf{x}_{0}+\\frac{1}{4}a=\\begin{pmatrix}2\\\\ 0\\\\ 1\\\\ 0\\end{pmatrix}+\\frac{1}{4}\\begin{pmatrix}\\frac{1}{2}\\\\ \\frac{\\sqrt{3}}{2}\\\\ -\\frac{1}{2}\\\\ \\frac{\\sqrt{3}}{2}\\end{pmatrix}=\\begin{pmatrix}\\frac{17}{8}\\\\ \\frac{\\sqrt{3}}{8}\\\\ \\frac{7}{8}\\\\ \\frac{\\sqrt{3}}{8}\\end{pmatrix}.\n$$\nA direct check shows $P(\\pi/3)=1$ with these coefficients, and they are the closest (in Euclidean norm) to $\\mathbf{x}_{\\text{target}}$ by construction.", "answer": "$$\\boxed{\\begin{pmatrix}\\frac{17}{8} & \\frac{\\sqrt{3}}{8} & \\frac{7}{8} & \\frac{\\sqrt{3}}{8}\\end{pmatrix}}$$", "id": "2173359"}]}