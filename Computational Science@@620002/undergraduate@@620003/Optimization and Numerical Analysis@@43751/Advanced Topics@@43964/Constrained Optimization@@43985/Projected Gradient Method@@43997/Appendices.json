{"hands_on_practices": [{"introduction": "We begin with the most intuitive case: a one-dimensional optimization problem. This exercise [@problem_id:2194842] grounds the projected gradient method in a simple setting where the feasible set is an interval, making the projection step easy to visualize as \"clipping\" to the interval's boundaries. By comparing two different starting points, you will see firsthand how the algorithm behaves when the gradient step lands both inside and outside the feasible region, providing a foundational understanding of the core mechanism.", "problem": "A simple robotic actuator's control parameter, denoted by $x$, is being optimized to minimize a cost function. The cost function is given by $f(x) = (x - 5)^2$. Due to physical limitations, the control parameter $x$ must lie within the closed interval $[-1, 1]$.\n\nAn engineer decides to use the projected gradient descent method to find the optimal parameter value. The update rule for this method is given by $x_{k+1} = P_{\\mathcal{C}}(x_k - \\alpha \\nabla f(x_k))$, where $\\mathcal{C}$ is the feasible set, $\\alpha$ is the step size, and $P_{\\mathcal{C}}(y)$ is the Euclidean projection of a point $y$ onto the set $\\mathcal{C}$. For a one-dimensional interval $\\mathcal{C} = [a, b]$, the projection is defined as $P_{[a, b]}(y) = \\max(a, \\min(y, b))$.\n\nThe engineer uses a fixed step size of $\\alpha = 0.1$. Two separate optimization runs are initiated.\n- Run A starts from the initial point $x_0^{(A)} = -1$.\n- Run B starts from the initial point $x_0^{(B)} = 1$.\n\nCalculate the value of the parameter after the first iteration, $x_1$, for both runs. Present your answer as a pair of decimal numbers, $(x_1^{(A)}, x_1^{(B)})$.", "solution": "We are given the cost function $f(x) = (x - 5)^{2}$ with feasible set $\\mathcal{C} = [-1, 1]$. The projected gradient descent update is\n$$\nx_{k+1} = P_{[-1,1]}\\left(x_{k} - \\alpha \\nabla f(x_{k})\\right),\n$$\nwith $\\alpha = 0.1$ and $P_{[-1,1]}(y) = \\max(-1, \\min(y, 1))$.\n\nFirst compute the gradient. Since $f(x) = (x - 5)^{2}$, we have\n$$\n\\nabla f(x) = \\frac{d}{dx}(x - 5)^{2} = 2(x - 5).\n$$\nThe unprojected update becomes\n$$\ny_{k} = x_{k} - \\alpha \\nabla f(x_{k}) = x_{k} - 0.1 \\cdot 2(x_{k} - 5) = x_{k} - 0.2 x_{k} + 1 = 0.8 x_{k} + 1.\n$$\n\nRun A starts at $x_{0}^{(A)} = -1$. Thus,\n$$\ny_{0}^{(A)} = 0.8(-1) + 1 = -0.8 + 1 = 0.2,\n$$\nand since $0.2 \\in [-1, 1]$, the projection gives $x_{1}^{(A)} = P_{[-1,1]}(0.2) = 0.2$.\n\nRun B starts at $x_{0}^{(B)} = 1$. Thus,\n$$\ny_{0}^{(B)} = 0.8(1) + 1 = 1.8,\n$$\nand since $1.8 > 1$, the projection gives $x_{1}^{(B)} = P_{[-1,1]}(1.8) = 1$.\n\nTherefore, the pair after the first iteration is $(0.2, 1)$.", "answer": "$$\\boxed{\\begin{pmatrix}0.2 & 1\\end{pmatrix}}$$", "id": "2194842"}, {"introduction": "Moving into two dimensions, this practice introduces a common non-linear constraint: a circular feasible set. The relatable scenario of a tethered drone [@problem_id:2194905] helps illustrate the process of taking a gradient step and then projecting back to the allowed area. You will learn how to perform the projection onto a disk, which simply involves scaling a vector that has gone \"out of bounds\" back to the circle's boundary, a fundamental geometric operation in many engineering applications.", "problem": "A small autonomous drone operates in a two-dimensional plane. Its control system is designed to navigate it towards a target located at the coordinates $(5, 5)$. The drone's performance is measured by a cost function, $f(x_1, x_2) = (x_1 - 5)^2 + (x_2 - 5)^2$, which represents the squared Euclidean distance from its current position $(x_1, x_2)$ to the target. The drone is physically tethered to a central pylon at the origin $(0, 0)$ by a flexible cable of length 1, meaning its position must always satisfy the condition $x_1^2 + x_2^2 \\le 1$.\n\nThe drone updates its position once every second according to a two-stage navigation algorithm.\n1.  **Desired Move Calculation:** First, it calculates the direction of the steepest decrease of the cost function at its current position. It then determines a desired next position by moving from its current position in this direction by a distance proportional to the steepness, governed by a step-size parameter $\\alpha = 0.1$.\n2.  **Safety Correction:** If this desired position is outside the reach of its tether, a safety protocol is triggered, which instantly pulls the drone to the closest point on the boundary of its circular operational area (i.e., the circle with radius 1 centered at the origin). If the desired position is within the tether's reach, no correction is needed.\n\nIf the drone starts at the origin, $x^{(0)} = (0, 0)$, determine its exact coordinates $(x_1, x_2)$ after the first full update cycle.", "solution": "The problem asks for the position of the drone after one iteration of a specific update algorithm. Let's translate the described process into a mathematical formulation.\n\nThe drone's position at step $k$ is denoted by $x^{(k)} = (x_1^{(k)}, x_2^{(k)})$. The objective is to minimize the cost function $f(x_1, x_2) = (x_1 - 5)^2 + (x_2 - 5)^2$, subject to the constraint that the drone remains within the unit disk, $C = \\{(x_1, x_2) \\in \\mathbb{R}^2 \\mid x_1^2 + x_2^2 \\le 1\\}$. The initial position is $x^{(0)} = (0, 0)$ and the step-size is $\\alpha = 0.1$.\n\nThe algorithm described is the projected gradient method. The update rule is $x^{(k+1)} = P_C(x^{(k)} - \\alpha \\nabla f(x^{(k)}))$, where $P_C$ is the projection operator onto the feasible set $C$.\n\n**Step 1: Compute the gradient of the cost function.**\nThe direction of steepest descent is the negative of the gradient of the cost function, $-\\nabla f(x_1, x_2)$. First, we find the gradient $\\nabla f(x_1, x_2)$.\n$$\n\\nabla f(x_1, x_2) = \\left( \\frac{\\partial f}{\\partial x_1}, \\frac{\\partial f}{\\partial x_2} \\right)\n$$\nThe partial derivatives are:\n$$\n\\frac{\\partial f}{\\partial x_1} = \\frac{\\partial}{\\partial x_1} \\left( (x_1 - 5)^2 + (x_2 - 5)^2 \\right) = 2(x_1 - 5)\n$$\n$$\n\\frac{\\partial f}{\\partial x_2} = \\frac{\\partial}{\\partial x_2} \\left( (x_1 - 5)^2 + (x_2 - 5)^2 \\right) = 2(x_2 - 5)\n$$\nSo, the gradient is $\\nabla f(x_1, x_2) = (2(x_1 - 5), 2(x_2 - 5))$.\n\n**Step 2: Perform the \"Desired Move Calculation\" (gradient descent step).**\nThis step calculates an intermediate point, let's call it $y^{(1)}$, before the safety correction.\n$$\ny^{(1)} = x^{(0)} - \\alpha \\nabla f(x^{(0)})\n$$\nFirst, evaluate the gradient at the starting position $x^{(0)} = (0, 0)$:\n$$\n\\nabla f(0, 0) = (2(0 - 5), 2(0 - 5)) = (-10, -10)\n$$\nNow, calculate $y^{(1)}$ with $\\alpha = 0.1$:\n$$\ny^{(1)} = (0, 0) - 0.1 \\times (-10, -10) = (0,0) - (-1, -1) = (1, 1)\n$$\nThis point $y^{(1)} = (1, 1)$ is the drone's desired next position before the safety check.\n\n**Step 3: Perform the \"Safety Correction\" (projection step).**\nWe must check if $y^{(1)}$ is within the feasible set $C$, which is defined by $x_1^2 + x_2^2 \\le 1$.\nFor $y^{(1)} = (1, 1)$, we have $1^2 + 1^2 = 2$. Since $2 > 1$, the point $y^{(1)}$ is outside the allowed circular area. The safety protocol is triggered.\n\nThe protocol moves the drone to the closest point on the boundary of the unit circle. This is equivalent to projecting the point $y^{(1)}$ onto the set $C$. For a point $y$ outside the unit disk, its projection onto the disk is found by normalizing the vector, i.e., dividing the vector by its Euclidean norm.\n$$\nx^{(1)} = P_C(y^{(1)}) = \\frac{y^{(1)}}{\\|y^{(1)}\\|_2}\n$$\nFirst, we find the norm of $y^{(1)} = (1, 1)$:\n$$\n\\|y^{(1)}\\|_2 = \\sqrt{1^2 + 1^2} = \\sqrt{2}\n$$\nNow, we compute the new position $x^{(1)}$:\n$$\nx^{(1)} = \\frac{(1, 1)}{\\sqrt{2}} = \\left( \\frac{1}{\\sqrt{2}}, \\frac{1}{\\sqrt{2}} \\right)\n$$\nTo rationalize the denominator, we multiply the numerator and denominator by $\\sqrt{2}$:\n$$\nx^{(1)} = \\left( \\frac{1 \\cdot \\sqrt{2}}{\\sqrt{2} \\cdot \\sqrt{2}}, \\frac{1 \\cdot \\sqrt{2}}{\\sqrt{2} \\cdot \\sqrt{2}} \\right) = \\left( \\frac{\\sqrt{2}}{2}, \\frac{\\sqrt{2}}{2} \\right)\n$$\nThus, the exact coordinates of the drone after the first update cycle are $\\left(\\frac{\\sqrt{2}}{2}, \\frac{\\sqrt{2}}{2}\\right)$.", "answer": "$$\\boxed{\\begin{pmatrix} \\frac{\\sqrt{2}}{2} & \\frac{\\sqrt{2}}{2} \\end{pmatrix}}$$", "id": "2194905"}, {"introduction": "This final practice explores another fundamental type of constraint ubiquitous in optimization: a linear inequality, which defines a half-space. This exercise [@problem_id:2194883] provides the explicit formula for projecting a point onto a half-space. Applying this formula will solidify your understanding of how the algorithm mathematically enforces this type of boundary, consolidating the two-step dance of gradient descent and projection.", "problem": "Consider the constrained optimization problem of minimizing the function $f(x_1, x_2) = (x_1-1)^2 + x_2^2$ subject to the constraint that the solution vector $x = (x_1, x_2)$ must lie within the feasible set $C$. The feasible set is defined as $C = \\{x \\in \\mathbb{R}^2 \\mid x_1 + x_2 \\ge 4\\}$.\n\nWe will use the projected gradient method to find an approximate solution. The iterative update rule for this method is given by:\n$$x^{(k+1)} = \\Pi_C \\left(x^{(k)} - \\alpha \\nabla f(x^{(k)})\\right)$$\nwhere $x^{(k)}$ is the iterate at step $k$, $\\alpha$ is the step size, $\\nabla f$ is the gradient of the function $f$, and $\\Pi_C(y)$ is the Euclidean projection of a point $y$ onto the set $C$.\n\nFor a half-space defined by $C = \\{x \\mid a^T x \\ge b\\}$, the projection of a point $y$ onto $C$ is given by:\n$$ \\Pi_C(y) = \\begin{cases} y & \\text{if } a^T y \\ge b \\\\ y + \\frac{b - a^T y}{\\|a\\|^2} a & \\text{if } a^T y < b \\end{cases} $$\n\nGiven a starting point $x^{(0)} = (1, 1)$ and a fixed step size $\\alpha = 0.5$, compute the first iterate $x^{(1)}$.\n\nExpress your answer as a row vector $(x_1, x_2)$ using fractions if necessary.", "solution": "We are given $f(x_{1},x_{2})=(x_{1}-1)^{2}+x_{2}^{2}$, so its gradient is\n$$\n\\nabla f(x)=\\begin{pmatrix}2(x_{1}-1)\\\\ 2x_{2}\\end{pmatrix}.\n$$\nWith $x^{(0)}=(1,1)$ and $\\alpha=\\frac{1}{2}$, compute the unprojected gradient step\n$$\ny=x^{(0)}-\\alpha\\,\\nabla f(x^{(0)}).\n$$\nFirst evaluate the gradient at $x^{(0)}$:\n$$\n\\nabla f(1,1)=\\begin{pmatrix}2(1-1)\\\\ 2\\cdot 1\\end{pmatrix}=\\begin{pmatrix}0\\\\ 2\\end{pmatrix}.\n$$\nThen\n$$\ny=\\begin{pmatrix}1\\\\ 1\\end{pmatrix}-\\frac{1}{2}\\begin{pmatrix}0\\\\ 2\\end{pmatrix}=\\begin{pmatrix}1\\\\ 0\\end{pmatrix}.\n$$\nThe feasible set is the half-space $C=\\{x\\in\\mathbb{R}^{2}\\mid a^{T}x\\ge b\\}$ with $a=\\begin{pmatrix}1\\\\ 1\\end{pmatrix}$ and $b=4$. Since $a^{T}y=1<4$, we use the projection formula\n$$\n\\Pi_{C}(y)=y+\\frac{b-a^{T}y}{\\|a\\|^{2}}\\,a.\n$$\nCompute the needed quantities:\n$$\nb-a^{T}y=4-1=3,\\qquad \\|a\\|^{2}=1^{2}+1^{2}=2.\n$$\nHence\n$$\nx^{(1)}=\\Pi_{C}(y)=\\begin{pmatrix}1\\\\ 0\\end{pmatrix}+\\frac{3}{2}\\begin{pmatrix}1\\\\ 1\\end{pmatrix}=\\begin{pmatrix}1+\\frac{3}{2}\\\\ 0+\\frac{3}{2}\\end{pmatrix}=\\begin{pmatrix}\\frac{5}{2}\\\\ \\frac{3}{2}\\end{pmatrix}.\n$$\nAs a row vector, this is $\\left(\\frac{5}{2},\\frac{3}{2}\\right)$.", "answer": "$$\\boxed{\\begin{pmatrix}\\frac{5}{2} & \\frac{3}{2}\\end{pmatrix}}$$", "id": "2194883"}]}