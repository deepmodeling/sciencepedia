{"hands_on_practices": [{"introduction": "This first exercise is designed to give you direct, hands-on experience with the core mechanics of Newton's method for a system of equations. By performing a single iteration, you will practice all the essential steps: evaluating the function vector $\\mathbf{F}(\\mathbf{x})$, computing the Jacobian matrix $J_F(\\mathbf{x})$, solving the linear system for the update step, and finally calculating the new approximation $\\mathbf{x}_1$. This fundamental practice solidifies the computational procedure that lies at the heart of the method [@problem_id:2190496].", "problem": "An autonomous robot is programmed to navigate to a target location $(x, y)$ on a 2D plane. The target is defined as the intersection of two signal-defined paths. The equations for these paths are given by the following system of non-linear equations:\n$$\n\\begin{cases}\n    x^2 - y + \\cos(y) - 3 = 0 \\\\\n    x + y + \\sin(x) - 2 = 0\n\\end{cases}\n$$\nThe robot's current position is $\\mathbf{x}_0 = (x_0, y_0) = (1.5, 0.5)$. The coordinate system is measured in meters. To find the target, the robot's navigation algorithm will use Newton's method for systems of non-linear equations.\n\nPerform exactly one iteration of Newton's method to find the robot's next estimated position, $\\mathbf{x}_1 = (x_1, y_1)$. Assume that all arguments of trigonometric functions are given in radians.\n\nProvide the components of the updated position vector $\\mathbf{x}_1$. Express your answer for each component in meters, rounded to three significant figures.", "solution": "We frame the system as $\\mathbf{F}(x,y) = \\begin{pmatrix} f_{1}(x,y) \\\\ f_{2}(x,y) \\end{pmatrix}$ with\n$$\nf_{1}(x,y) = x^{2} - y + \\cos(y) - 3,\\quad f_{2}(x,y) = x + y + \\sin(x) - 2.\n$$\nNewton’s method for systems updates $\\mathbf{x}_{1} = \\mathbf{x}_{0} - J(\\mathbf{x}_{0})^{-1}\\mathbf{F}(\\mathbf{x}_{0})$, equivalently solve $J(\\mathbf{x}_{0})\\,\\mathbf{s} = -\\mathbf{F}(\\mathbf{x}_{0})$ for $\\mathbf{s}$ and set $\\mathbf{x}_{1} = \\mathbf{x}_{0} + \\mathbf{s}$.\n\nThe Jacobian is\n$$\nJ(x,y) = \\begin{pmatrix}\n\\frac{\\partial f_{1}}{\\partial x}  \\frac{\\partial f_{1}}{\\partial y} \\\\\n\\frac{\\partial f_{2}}{\\partial x}  \\frac{\\partial f_{2}}{\\partial y}\n\\end{pmatrix}\n=\n\\begin{pmatrix}\n2x  -1 - \\sin(y) \\\\\n1 + \\cos(x)  1\n\\end{pmatrix}.\n$$\nAt $\\mathbf{x}_{0} = (x_{0},y_{0}) = (1.5, 0.5)$ (radians for trigonometric arguments),\n$$\n\\sin(0.5) \\approx 0.4794255386,\\quad \\cos(0.5) \\approx 0.8775825620,\\quad \\sin(1.5) \\approx 0.9974949866,\\quad \\cos(1.5) \\approx 0.0707372017.\n$$\nEvaluate the function:\n$$\n\\mathbf{F}(\\mathbf{x}_{0}) = \\begin{pmatrix}\n1.5^{2} - 0.5 + \\cos(0.5) - 3 \\\\\n1.5 + 0.5 + \\sin(1.5) - 2\n\\end{pmatrix}\n=\n\\begin{pmatrix}\n-0.372417438 \\\\\n0.9974949866\n\\end{pmatrix}.\n$$\nEvaluate the Jacobian:\n$$\nJ(\\mathbf{x}_{0}) = \\begin{pmatrix}\n3  -1 - \\sin(0.5) \\\\\n1 + \\cos(1.5)  1\n\\end{pmatrix}\n=\n\\begin{pmatrix}\n3  -1.4794255386 \\\\\n1.0707372017  1\n\\end{pmatrix}.\n$$\nSet up and solve $J(\\mathbf{x}_{0})\\,\\mathbf{s} = -\\mathbf{F}(\\mathbf{x}_{0})$:\n$$\n\\begin{pmatrix}\n3  -1.4794255386 \\\\\n1.0707372017  1\n\\end{pmatrix}\n\\begin{pmatrix}\ns_{1} \\\\ s_{2}\n\\end{pmatrix}\n=\n\\begin{pmatrix}\n0.372417438 \\\\\n-0.9974949866\n\\end{pmatrix}.\n$$\nFrom the second equation, $s_{2} = -0.9974949866 - 1.0707372017\\,s_{1}$. Substitute into the first:\n$$\n(3 + 1.4794255386 \\cdot 1.0707372017)\\,s_{1} + 1.4794255386 \\cdot 0.9974949866 = 0.372417438,\n$$\nso\n$$\ns_{1} = \\frac{0.372417438 - 1.4794255386 \\cdot 0.9974949866}{3 + 1.4794255386 \\cdot 1.0707372017} \\approx \\frac{-1.103302119}{4.5840759613} \\approx -0.240682.\n$$\nThen\n$$\ns_{2} = -0.9974949866 - 1.0707372017\\,(-0.240682) \\approx -0.739788.\n$$\nUpdate the estimate:\n$$\nx_{1} = x_{0} + s_{1} \\approx 1.5 - 0.240682 = 1.259318,\\quad\ny_{1} = y_{0} + s_{2} \\approx 0.5 - 0.739788 = -0.239788.\n$$\nRounded to three significant figures (meters): $x_{1} \\approx 1.26$, $y_{1} \\approx -0.240$.", "answer": "$$\\boxed{\\begin{pmatrix} 1.26  -0.240 \\end{pmatrix}}$$", "id": "2190496"}, {"introduction": "What happens when we apply a sophisticated method for non-linear systems to a simple linear one? This problem explores that very question and reveals a fascinating property of Newton's method. By algebraically deriving the result of one iteration for a general linear system $\\mathbf{A}\\mathbf{x} = \\mathbf{b}$, you will see how the method connects directly to fundamental concepts in linear algebra, providing a deeper insight into why it is so effective [@problem_id:2190469].", "problem": "Consider a system of $n$ linear equations with $n$ unknowns, represented in matrix form as $\\mathbf{A}\\mathbf{x} = \\mathbf{b}$, where $\\mathbf{A}$ is an invertible $n \\times n$ matrix, and $\\mathbf{x}, \\mathbf{b}$ are column vectors in $\\mathbb{R}^n$. Solving this system is equivalent to finding the root of the vector-valued function $\\mathbf{F}(\\mathbf{x}) = \\mathbf{A}\\mathbf{x} - \\mathbf{b}$.\n\nOne can attempt to find this root using Newton's method for systems. The iterative formula for Newton's method is given by:\n$$\n\\mathbf{x}_{k+1} = \\mathbf{x}_k - [J_F(\\mathbf{x}_k)]^{-1} \\mathbf{F}(\\mathbf{x}_k)\n$$\nwhere $\\mathbf{x}_k$ is the approximation at iteration $k$, and $J_F(\\mathbf{x}_k)$ is the Jacobian matrix of the function $\\mathbf{F}$ evaluated at $\\mathbf{x}_k$.\n\nStarting with an arbitrary initial guess $\\mathbf{x}_0$, perform one full iteration of Newton's method to find the next approximation, $\\mathbf{x}_1$. Your task is to derive a simplified expression for $\\mathbf{x}_1$. The final expression may contain $\\mathbf{A}$, $\\mathbf{b}$, and $\\mathbf{x}_0$, or it may simplify further.", "solution": "We consider the system $\\mathbf{A}\\mathbf{x} = \\mathbf{b}$ and define the vector-valued function $\\mathbf{F}(\\mathbf{x}) = \\mathbf{A}\\mathbf{x} - \\mathbf{b}$. Newton's method for systems updates via\n$$\n\\mathbf{x}_{k+1} = \\mathbf{x}_{k} - \\left[J_{F}(\\mathbf{x}_{k})\\right]^{-1}\\mathbf{F}(\\mathbf{x}_{k}),\n$$\nwhere $J_{F}(\\mathbf{x})$ is the Jacobian matrix of $\\mathbf{F}$.\n\nSince $\\mathbf{F}(\\mathbf{x}) = \\mathbf{A}\\mathbf{x} - \\mathbf{b}$ is linear, its Jacobian is constant and equal to the matrix $\\mathbf{A}$ for all $\\mathbf{x}$:\n$$\nJ_{F}(\\mathbf{x}) = \\mathbf{A}.\n$$\nGiven that $\\mathbf{A}$ is invertible, we have $\\left[J_{F}(\\mathbf{x}_{0})\\right]^{-1} = \\mathbf{A}^{-1}$. Substituting into the Newton update with $\\mathbf{x}_{k} = \\mathbf{x}_{0}$,\n$$\n\\mathbf{x}_{1} = \\mathbf{x}_{0} - \\mathbf{A}^{-1}\\left(\\mathbf{A}\\mathbf{x}_{0} - \\mathbf{b}\\right).\n$$\nDistribute $\\mathbf{A}^{-1}$ and simplify:\n$$\n\\mathbf{x}_{1} = \\mathbf{x}_{0} - \\left(\\mathbf{x}_{0} - \\mathbf{A}^{-1}\\mathbf{b}\\right) = \\mathbf{A}^{-1}\\mathbf{b}.\n$$\nThus, after one iteration from any initial guess $\\mathbf{x}_{0}$, Newton's method yields the exact solution $\\mathbf{A}^{-1}\\mathbf{b}$.", "answer": "$$\\boxed{\\mathbf{A}^{-1}\\mathbf{b}}$$", "id": "2190469"}, {"introduction": "Newton's method is powerful but not guaranteed to work in all situations. This exercise presents a scenario where the method fails, prompting an investigation into the cause. Understanding why and when the method can break down is as important as knowing how to apply it. You will analyze the Jacobian matrix to diagnose the problem, linking the abstract mathematical condition of singularity to a clear geometric interpretation [@problem_id:2190480].", "problem": "Consider the system of two nonlinear equations:\n1. $x^2 + y^2 - 1 = 0$\n2. $y - x^3 = 0$\n\nAn attempt is made to find a numerical solution to this system using Newton's method for systems of equations. The initial guess for the solution is taken to be the point $(x_0, y_0) = (0, 2)$.\n\nWhich of the following statements best describes the outcome of the first iteration of Newton's method starting from this initial guess?\n\nA. The method successfully computes the next iteration $(x_1, y_1)$ as $(0, 1)$, which is one of the true roots of the system.\n\nB. The next iteration $(x_1, y_1)$ is computed to be the origin $(0, 0)$.\n\nC. The method fails because the Jacobian matrix evaluated at the initial guess is singular. Geometrically, this corresponds to the tangent lines to the respective level curves at the initial guess being parallel.\n\nD. The method produces a next iteration $(x_1, y_1)$ that is farther from the true roots than the initial guess, indicating divergence.\n\nE. The method fails because the initial guess lies on one of the solution curves.", "solution": "Let $f:\\mathbb{R}^{2}\\to\\mathbb{R}^{2}$ be given by\n$$\nf(x,y)=\\begin{pmatrix}\nf_{1}(x,y)\\\\\nf_{2}(x,y)\n\\end{pmatrix}\n=\\begin{pmatrix}\nx^{2}+y^{2}-1\\\\\ny-x^{3}\n\\end{pmatrix}.\n$$\nNewton’s method for systems computes $(x_{1},y_{1})=(x_{0},y_{0})+\\Delta$ by solving the linear system\n$$\nJ_{f}(x_{0},y_{0})\\,\\Delta=-f(x_{0},y_{0}),\n$$\nwhere $J_{f}$ is the Jacobian matrix of $f$:\n$$\nJ_{f}(x,y)=\\begin{pmatrix}\n\\frac{\\partial f_{1}}{\\partial x}  \\frac{\\partial f_{1}}{\\partial y}\\\\\n\\frac{\\partial f_{2}}{\\partial x}  \\frac{\\partial f_{2}}{\\partial y}\n\\end{pmatrix}\n=\\begin{pmatrix}\n2x  2y\\\\\n-3x^{2}  1\n\\end{pmatrix}.\n$$\nAt the initial guess $(x_{0},y_{0})=(0,2)$ we have\n$$\nJ_{f}(0,2)=\\begin{pmatrix}\n0  4\\\\\n0  1\n\\end{pmatrix},\n\\qquad\nf(0,2)=\\begin{pmatrix}\n0^{2}+2^{2}-1\\\\\n2-0^{3}\n\\end{pmatrix}\n=\\begin{pmatrix}\n3\\\\\n2\n\\end{pmatrix}.\n$$\nThe Newton step requires solving\n$$\n\\begin{pmatrix}\n0  4\\\\\n0  1\n\\end{pmatrix}\n\\begin{pmatrix}\n\\Delta x\\\\\n\\Delta y\n\\end{pmatrix}\n=\n-\\begin{pmatrix}\n3\\\\\n2\n\\end{pmatrix}\n=\\begin{pmatrix}\n-3\\\\\n-2\n\\end{pmatrix}.\n$$\nThis yields the equations $4\\Delta y=-3$ and $\\Delta y=-2$, which are inconsistent. Equivalently, the Jacobian is singular since\n$$\n\\det J_{f}(0,2)=0\\cdot 1-4\\cdot 0=0,\n$$\nso the linear system has no solution and Newton’s method fails to produce $(x_{1},y_{1})$.\n\nGeometrically, the rows of $J_{f}(0,2)$ are proportional, which means the gradients of the two equations at $(0,2)$ are linearly dependent:\n$$\n\\nabla f_{1}(0,2)=(2\\cdot 0,2\\cdot 2)=(0,4),\\qquad \\nabla f_{2}(0,2)=(-3\\cdot 0^{2},1)=(0,1).\n$$\nParallel gradients imply the tangent lines to the level curves $f_{1}=0$ and $f_{2}=0$ at $(0,2)$ are parallel, matching the geometric description of a singular Jacobian.\n\nTherefore, the correct statement is that the method fails at the first iteration due to a singular Jacobian, with the geometric interpretation of parallel tangents.\n\nTo rule out other options: $(0,1)$ is not a solution since it does not satisfy $y=x^{3}$, $(0,0)$ cannot be reached because the Newton step is undefined here, divergence cannot be assessed without a defined step, and the initial guess does not lie on either solution curve since $f(0,2)\\neq 0$.", "answer": "$$\\boxed{C}$$", "id": "2190480"}]}