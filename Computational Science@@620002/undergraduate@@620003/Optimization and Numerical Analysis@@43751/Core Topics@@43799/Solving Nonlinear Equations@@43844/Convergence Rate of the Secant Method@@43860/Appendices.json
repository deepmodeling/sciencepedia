{"hands_on_practices": [{"introduction": "This first exercise is a direct application of the secant method, designed to build your computational fluency. By finding the root of the specific quadratic equation $f(x) = x^2 - x - 1$, you will not only practice the iterative process but also discover a fascinating link to the Fibonacci numbers, seeing how abstract theory can generate elegant patterns [@problem_id:2163470]. This problem reinforces the mechanics of the iteration and demonstrates how the method progresses step-by-step.", "problem": "An analyst is studying the convergence behavior of the secant method for finding the roots of the quadratic function $f(x) = x^2 - x - 1$. The iterative formula for the secant method generates a sequence of approximations $\\{x_k\\}$ according to the relation:\n$$x_{k+1} = x_k - f(x_k) \\frac{x_k - x_{k-1}}{f(x_k) - f(x_{k-1})}$$\nThe process is initiated with the two starting guesses $x_0 = 1$ and $x_1 = 2$.\n\nCalculate the third iterate, $x_3$, generated by this process.\n\nA. $\\frac{3}{2}$\n\nB. $\\frac{5}{3}$\n\nC. $\\frac{8}{5}$\n\nD. $\\frac{13}{8}$\n\nE. $\\frac{21}{13}$", "solution": "The problem asks for the third iterate, $x_3$, of the secant method applied to the function $f(x) = x^2 - x - 1$, with initial guesses $x_0 = 1$ and $x_1 = 2$.\n\nThe secant method formula is given by:\n$$x_{k+1} = x_k - f(x_k) \\frac{x_k - x_{k-1}}{f(x_k) - f(x_{k-1})}$$\n\nWe need to calculate the iterates step by step.\n\n**Step 1: Calculate $x_2$ (the second iterate, for $k=1$).**\nFirst, we evaluate the function at the initial points $x_0$ and $x_1$:\n$f(x_0) = f(1) = 1^2 - 1 - 1 = -1$.\n$f(x_1) = f(2) = 2^2 - 2 - 1 = 1$.\n\nNow, we use the secant formula for $k=1$:\n$$x_2 = x_1 - f(x_1) \\frac{x_1 - x_0}{f(x_1) - f(x_0)}$$\nSubstituting the known values:\n$$x_2 = 2 - (1) \\frac{2 - 1}{1 - (-1)} = 2 - \\frac{1}{2} = \\frac{3}{2}$$\n\n**Step 2: Calculate $x_3$ (the third iterate, for $k=2$).**\nWe now need to find $x_3$ using $x_1$ and $x_2$. We already have $x_1=2$ and $f(x_1)=1$. We need to calculate $f(x_2)$:\n$$f(x_2) = f\\left(\\frac{3}{2}\\right) = \\left(\\frac{3}{2}\\right)^2 - \\frac{3}{2} - 1 = \\frac{9}{4} - \\frac{6}{4} - \\frac{4}{4} = -\\frac{1}{4}$$\n\nNow, we use the secant formula for $k=2$:\n$$x_3 = x_2 - f(x_2) \\frac{x_2 - x_1}{f(x_2) - f(x_1)}$$\nSubstituting the values for $x_1, x_2, f(x_1),$ and $f(x_2)$:\n$$x_3 = \\frac{3}{2} - \\left(-\\frac{1}{4}\\right) \\frac{\\frac{3}{2} - 2}{-\\frac{1}{4} - 1}$$\n$$x_3 = \\frac{3}{2} + \\frac{1}{4} \\frac{-\\frac{1}{2}}{-\\frac{5}{4}}$$\n$$x_3 = \\frac{3}{2} + \\frac{1}{4} \\left(\\left(-\\frac{1}{2}\\right) \\cdot \\left(-\\frac{4}{5}\\right)\\right)$$\n$$x_3 = \\frac{3}{2} + \\frac{1}{4} \\left(\\frac{4}{10}\\right) = \\frac{3}{2} + \\frac{1}{10}$$\n$$x_3 = \\frac{15}{10} + \\frac{1}{10} = \\frac{16}{10} = \\frac{8}{5}$$\n\nThe value of the third iterate is $x_3 = \\frac{8}{5}$.\n\n**Alternative Method: Deriving a Simplified Recurrence**\nFor the specific function $f(x) = x^2 - x - 1$, the secant method recurrence can be simplified.\nThe denominator of the fraction in the secant formula is:\n$f(x_k) - f(x_{k-1}) = (x_k^2 - x_k - 1) - (x_{k-1}^2 - x_{k-1} - 1) = x_k^2 - x_{k-1}^2 - (x_k - x_{k-1})$\n$f(x_k) - f(x_{k-1}) = (x_k - x_{k-1})(x_k + x_{k-1}) - (x_k - x_{k-1}) = (x_k - x_{k-1})(x_k + x_{k-1} - 1)$\n\nSubstitute this back into the secant formula:\n$x_{k+1} = x_k - \\frac{x_k^2 - x_k - 1}{(x_k - x_{k-1})(x_k + x_{k-1} - 1)} (x_k - x_{k-1})$\n$x_{k+1} = x_k - \\frac{x_k^2 - x_k - 1}{x_k + x_{k-1} - 1}$\nCombining into a single fraction:\n$x_{k+1} = \\frac{x_k(x_k + x_{k-1} - 1) - (x_k^2 - x_k - 1)}{x_k + x_{k-1} - 1}$\n$x_{k+1} = \\frac{x_k^2 + x_k x_{k-1} - x_k - x_k^2 + x_k + 1}{x_k + x_{k-1} - 1}$\n$$x_{k+1} = \\frac{x_k x_{k-1} + 1}{x_k + x_{k-1} - 1}$$\nThis simplified recurrence holds for $k \\ge 1$.\n\nUsing this recurrence:\nFor $k=1$:\n$x_2 = \\frac{x_1 x_0 + 1}{x_1 + x_0 - 1} = \\frac{(2)(1) + 1}{2 + 1 - 1} = \\frac{3}{2}$.\nFor $k=2$:\n$x_3 = \\frac{x_2 x_1 + 1}{x_2 + x_1 - 1} = \\frac{(\\frac{3}{2})(2) + 1}{\\frac{3}{2} + 2 - 1} = \\frac{3 + 1}{\\frac{3}{2} + 1} = \\frac{4}{\\frac{5}{2}} = \\frac{8}{5}$.\n\nBoth methods yield $x_3 = \\frac{8}{5}$. Comparing this with the given options:\nA. $\\frac{3}{2} = 1.5$\nB. $\\frac{5}{3} \\approx 1.667$\nC. $\\frac{8}{5} = 1.6$\nD. $\\frac{13}{8} = 1.625$\nE. $\\frac{21}{13} \\approx 1.615$\n\nThe calculated value matches option C.", "answer": "$$\\boxed{C}$$", "id": "2163470"}, {"introduction": "After computing a sequence of approximations, how do we empirically verify its convergence rate? This practice moves from calculation to analysis, demonstrating how to use a log-log plot of the errors to determine the order of convergence [@problem_id:2163458]. This powerful graphical technique is fundamental for validating the performance of numerical methods using the data they generate.", "problem": "A numerical analyst is investigating the performance of the secant method for finding the root of a complex, non-linear function $f(x) = 0$. Let $x_k$ be the estimate of the root at the $k$-th iteration and $r$ be the true root. The error at this iteration is defined as $e_k = x_k - r$.\n\nFor a root-finding algorithm with an order of convergence $\\alpha$, it is known that for large $k$, the absolute errors are related by $|e_{k+1}| \\approx C |e_k|^\\alpha$, where $C$ is a constant that depends on the function $f(x)$ but not on the iteration number $k$.\n\nTo empirically determine the order of convergence, the analyst plots $\\ln|e_{k+1}|$ on the vertical axis against $\\ln|e_k|$ on the horizontal axis. For sufficiently converged iterations, the data points form a straight line. From this line, the analyst picks two representative data points, P1 and P2, corresponding to two different pairs of consecutive iterations. The coordinates of these points are:\nP1: $(-9.50, -15.45)$\nP2: $(-15.45, -25.07)$\n\nBased on these two data points, calculate the empirical order of convergence, $\\alpha$. Round your final answer to three significant figures.", "solution": "We are given the asymptotic error relation for an order-$\\alpha$ method:\n$$|e_{k+1}| \\approx C |e_k|^{\\alpha}.$$\nTaking the natural logarithm of both sides gives\n$$\\ln|e_{k+1}| \\approx \\ln C + \\alpha \\ln|e_k|.$$\nThis is a linear relation of the form $y = b + \\alpha x$ with $y = \\ln|e_{k+1}|$ and $x = \\ln|e_k|$, so the slope of the straight line on the plot of $\\ln|e_{k+1}|$ versus $\\ln|e_k|$ equals the order of convergence $\\alpha$.\n\nUsing the two given points P1: $(-9.50,-15.45)$ and P2: $(-15.45,-25.07)$, the slope is\n$$\\alpha = \\frac{y_{2} - y_{1}}{x_{2} - x_{1}} = \\frac{-25.07 - (-15.45)}{-15.45 - (-9.50)} = \\frac{-9.62}{-5.95} = \\frac{9.62}{5.95}.$$\nComputing the quotient,\n$$\\alpha \\approx 1.616806\\ldots,$$\nwhich, rounded to three significant figures, is\n$$\\alpha \\approx 1.62.$$", "answer": "$$\\boxed{1.62}$$", "id": "2163458"}, {"introduction": "The secant method's impressive speed is not accidental; it stems from its algorithmic design. This exercise highlights this by contrasting the secant method with the closely related method of false position (regula falsi) [@problem_id:2163430]. By observing how each method behaves on a convex function, you will gain a deeper insight into the trade-off between guaranteed bracketing and the resulting speed of convergence.", "problem": "Two iterative numerical methods, Method S and Method R, are used to find the root of a function $f(x)$. Both methods start with two initial points, $x_0$ and $x_1$.\n\n**Method S:** This method generates a sequence of approximations $\\{x_k\\}$ for $k \\ge 2$ using the following update rule, which is based on the x-intercept of the secant line through the previous two points $(x_{k-1}, f(x_{k-1}))$ and $(x_k, f(x_k))$:\n$$x_{k+1} = x_k - f(x_k) \\frac{x_k - x_{k-1}}{f(x_k) - f(x_{k-1})}$$\n\n**Method R:** This method starts with an initial interval $[a_0, b_0]$ such that $f(a_0) f(b_0) < 0$. At each step $k$, a new approximation $c_k$ is computed using the endpoints of the current interval, $[a_k, b_k]$, with the same formula as Method S:\n$$c_k = b_k - f(b_k) \\frac{b_k - a_k}{f(b_k) - f(a_k)}$$\nThe next interval, $[a_{k+1}, b_{k+1}]$, is then chosen to be either $[a_k, c_k]$ or $[c_k, b_k]$ to ensure that the condition $f(a_{k+1})f(b_{k+1}) < 0$ is maintained, thus always bracketing the root.\n\nBoth methods are applied to find the single real root of the function $f(x) = \\exp(x) - 10$. For Method R, the initial interval is $[a_0, b_0] = [0, 3]$. For Method S, the initial points are $x_0 = 0$ and $x_1 = 3$. Assume that for Method S, the iterates converge to the root.\n\nWhich of the following statements most accurately describes the expected convergence behavior of the two methods in this specific scenario?\n\nA. Both Method S and Method R will converge to the root with a superlinear order of convergence (approximately 1.618).\n\nB. Method S will exhibit superlinear convergence, while Method R will exhibit a much slower, linear order of convergence.\n\nC. Both Method S and Method R will exhibit linear convergence because the function is convex.\n\nD. Method R will converge significantly faster than Method S because it is guaranteed to maintain a bracket around the root.\n\nE. Method S will fail to converge because the initial points are not sufficiently close to the root, whereas Method R will converge successfully.\n\nF. Method R will converge quadratically, while Method S will converge linearly.", "solution": "We consider $f(x)=\\exp(x)-10$, which has a single real root $x^*$ satisfying $f(x^*)=0$. Since $\\exp(x)$ is strictly increasing and strictly convex on $\\mathbb{R}$, we have\n$$f'(x)=\\exp(x)>0,\\qquad f''(x)=\\exp(x)>0,$$\nand the root is $x^*=\\ln(10)$.\n\nMethod S (secant method) with initial points $x_0=0$ and $x_1=3$ generates\n$$x_{k+1}=x_k-f(x_k)\\frac{x_k-x_{k-1}}{f(x_k)-f(x_{k-1})},\\quad k\\ge 1.$$\nUnder the standard assumptions that $f\\in C^2$ near $x^*$ and $f'(x^*)\\neq 0$, and assuming the iterates converge to $x^*$ (as stipulated), the secant method is known to converge with superlinear order $p$ satisfying $p^2-p-1=0$, hence\n$$p=\\frac{1+\\sqrt{5}}{2}.$$\nTherefore, Method S exhibits superlinear convergence.\n\nMethod R (regula falsi/false position) starts with $[a_0,b_0]=[0,3]$ with $f(a_0)f(b_0)<0$. At step $k$ it computes\n$$c_k=b_k-f(b_k)\\frac{b_k-a_k}{f(b_k)-f(a_k)},$$\nand selects $[a_{k+1},b_{k+1}]$ to preserve a sign change. For a strictly convex, strictly increasing $f$ with $f(a_k)<0<f(b_k)$, the chord through $(a_k,f(a_k))$ and $(b_k,f(b_k))$ lies above the graph of $f$ on $[a_k,b_k]$. If $\\ell_k(x)$ denotes this chord, then $f(x)\\le \\ell_k(x)$ for $x\\in[a_k,b_k]$. At the x-intercept $c_k$ of the chord, $\\ell_k(c_k)=0$, hence $f(c_k)\\le 0$, and strict convexity yields $f(c_k)<0$. Because $f$ is strictly increasing and $f(x^*)=0$, this implies $c_k<x^*$. Therefore the next interval is $[a_{k+1},b_{k+1}]=[c_k,b_k]$, so $b_{k+1}=b_k$. By induction, $b_k=b_0=3$ for all $k$, and $a_k \\nearrow x^*$.\n\nTo determine the rate, define the error $e_k=x^*-a_k>0$. Using $b_k\\equiv b_0$ and the update,\n$$c_k=b_0-f(b_0)\\frac{b_0-a_k}{f(b_0)-f(a_k)},$$\nand a first-order Taylor expansion at $x^*$,\n$$f(a_k)=f'(x^*)(a_k-x^*)+o(|a_k-x^*|) = -f'(x^*)e_k+o(e_k),$$\nwe obtain, after algebraic manipulation,\n$$e_{k+1}=x^*-c_k=\\left(1-\\frac{f'(x^*)(b_0-x^*)}{f(b_0)}\\right)e_k+o(e_k).$$\nConvexity implies $f(b_0)>f'(x^*)(b_0-x^*)$, so the coefficient\n$$\\rho=1-\\frac{f'(x^*)(b_0-x^*)}{f(b_0)}$$\nsatisfies $0<\\rho<1$. Hence Method R converges linearly:\n$$e_{k+1}\\sim \\rho e_k\\quad\\text{as }k\\to\\infty.$$\nFor this $f$, $x^*=\\ln(10)$, $b_0=3$, $f'(x^*)=\\exp(x^*)=10$, and $f(b_0)=\\exp(3)-10$, so $\\rho\\in(0,1)$ explicitly, confirming linear (and comparatively slow) convergence of Method R.\n\nTherefore, in this scenario, Method S is superlinear (order $\\frac{1+\\sqrt{5}}{2}$) and Method R is linear. Among the options, this is described by choice B.", "answer": "$$\\boxed{B}$$", "id": "2163430"}]}