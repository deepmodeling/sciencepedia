{"hands_on_practices": [{"introduction": "To truly understand convergence, we must begin with its mathematical definition. This first practice provides a direct and clear-cut scenario to apply the formula for the order of convergence $p$ and the rate of convergence $\\lambda$. By analyzing a simple linear recurrence relation for the error sequence $\\\\{e_k\\\\}$, you will solidify your grasp of the core concepts before moving on to more complex applications [@problem_id:2165607].", "id": "2165607", "problem": "An iterative numerical method is designed to find a particular value, which is known to be zero. The sequence of absolute errors at each step, denoted by $\\{e_k\\}$ for $k=0, 1, 2, \\dots$, is found to follow the recurrence relation:\n$$e_{k+1} = \\frac{1}{4} e_k$$\nwhere $e_0$ is some initial positive error. The sequence $\\{e_k\\}$ is known to converge to $e^*=0$.\n\nRecall that a sequence $\\{x_k\\}$ that converges to a limit $x^*$ is said to have an order of convergence $p$ and a rate of convergence (or asymptotic error constant) $\\lambda$ if the following limit exists and is a non-zero finite constant:\n$$ \\lim_{k \\to \\infty} \\frac{|x_{k+1} - x^*|}{|x_k - x^*|^p} = \\lambda $$\n\nBased on this definition, determine the order of convergence $p$ and the rate of convergence $\\lambda$ for the error sequence $\\{e_k\\}$.\n\nSelect the correct pair $(p, \\lambda)$ from the options below.\n\nA. Order $p=1$, Rate $\\lambda=1$\nB. Order $p=1$, Rate $\\lambda=4$\nC. Order $p=2$, Rate $\\lambda=\\frac{1}{4}$\nD. Order $p=1$, Rate $\\lambda=\\frac{1}{4}$\nE. Order $p=4$, Rate $\\lambda=1$\n\n", "solution": "We are given the error recurrence for absolute errors $e_{k} \\ge 0$:\n$$\ne_{k+1}=\\frac{1}{4}e_{k},\n$$\nwith limiting error $e^{*}=0$. Iterating the linear recurrence gives the explicit form\n$$\ne_{k}=\\left(\\frac{1}{4}\\right)^{k} e_{0},\n$$\nso $e_{k}\\to 0$ as $k\\to \\infty$.\n\nBy the definition of order $p$ and rate $\\lambda$, we consider\n$$\n\\lim_{k\\to\\infty}\\frac{|e_{k+1}-e^{*}|}{|e_{k}-e^{*}|^{p}}\n=\\lim_{k\\to\\infty}\\frac{e_{k+1}}{e_{k}^{p}}.\n$$\nUsing the recurrence $e_{k+1}=\\frac{1}{4}e_{k}$, we obtain\n$$\n\\frac{e_{k+1}}{e_{k}^{p}}=\\frac{1}{4}\\,e_{k}^{1-p}.\n$$\nSince $e_{k}\\to 0$, we analyze the limit by cases:\n- If $p=1$, then $e_{k}^{1-p}=e_{k}^{0}=1$, hence the limit is $\\lambda=\\frac{1}{4}$.\n- If $p>1$, then $1-p<0$ and $e_{k}^{1-p}\\to \\infty$, so the limit is infinite and not admissible.\n- If $0<p<1$, then $1-p>0$ and $e_{k}^{1-p}\\to 0$, so the limit is zero and not admissible.\n\nTherefore, the only admissible order is $p=1$ with rate $\\lambda=\\frac{1}{4}$, which corresponds to option D.", "answer": "$$\\boxed{D}$$"}, {"introduction": "In practice, we often evaluate an algorithm's performance without knowing its underlying mathematical structure. This exercise simulates such a scenario, where you act as a numerical analyst examining the output from a new, hypothetical root-finding method. Your task is to analyze the provided sequence of errors and determine the algorithm's order of convergence, a key skill for validating and comparing iterative methods based on empirical data [@problem_id:2165614].", "id": "2165614", "problem": "In the field of numerical analysis, a new iterative method called the \"Hyper-Attractor Root-finding Method\" is being tested. The method is designed to find a root $x^*$ of a given function $f(x)$. The performance of the algorithm is evaluated by observing the sequence of absolute errors, $\\{e_k\\}$, where $e_k = |x_k - x^*|$ and $x_k$ is the estimate of the root at the $k$-th iteration.\n\nFor a specific test function, the following sequence of errors was recorded for the first few iterations:\n\n- $e_0 = 0.6000$\n- $e_1 = 0.1800$\n- $e_2 = 0.0162$\n- $e_3 = 0.00013122$\n\nBased on a numerical analysis of this data, which of the following statements provides the most accurate classification of the algorithm's order of convergence?\n\nA. The algorithm exhibits linear convergence.\nB. The algorithm exhibits quadratic convergence.\nC. The algorithm exhibits cubic convergence.\nD. The algorithm is divergent.\nE. The order of convergence is super-linear but not a whole integer.\n\n", "solution": "We analyze the order of convergence using the standard error model: the method has order $p$ with asymptotic error constant $C>0$ if\n$$\ne_{k+1}=C e_{k}^{p}+o(e_{k}^{p}) \\quad \\text{as } k\\to\\infty.\n$$\nA practical estimator for $p$ from consecutive errors is\n$$\np \\approx \\frac{\\ln(e_{k+1})-\\ln(e_{k})}{\\ln(e_{k})-\\ln(e_{k-1})}=\\frac{\\ln\\!\\left(\\frac{e_{k+1}}{e_{k}}\\right)}{\\ln\\!\\left(\\frac{e_{k}}{e_{k-1}}\\right)}.\n$$\nUsing $e_{0}=0.6000$, $e_{1}=0.1800$, $e_{2}=0.0162$, $e_{3}=0.00013122$:\n- For $k=1$,\n$$\n\\frac{e_{2}}{e_{1}}=\\frac{0.0162}{0.1800}=0.09,\\quad \\frac{e_{1}}{e_{0}}=\\frac{0.1800}{0.6000}=0.3,\n$$\nso\n$$\np \\approx \\frac{\\ln(0.09)}{\\ln(0.3)}=\\frac{\\ln 9-2\\ln 10}{\\ln 3-\\ln 10}=\\frac{2\\ln 3-2\\ln 10}{\\ln 3-\\ln 10}=2.\n$$\n- For $k=2$,\n$$\n\\frac{e_{3}}{e_{2}}=\\frac{0.00013122}{0.0162}=0.0081=(0.09)^{2},\n$$\nhence\n$$\np \\approx \\frac{\\ln(0.0081)}{\\ln(0.09)}=\\frac{2\\ln(0.09)}{\\ln(0.09)}=2.\n$$\nThis consistently indicates quadratic convergence. As an additional check of the error model with $p=2$, the asymptotic error constant is\n$$\nC \\approx \\frac{e_{k+1}}{e_{k}^{2}},\n$$\ngiving\n$$\n\\frac{e_{1}}{e_{0}^{2}}=\\frac{0.1800}{(0.6000)^{2}}=\\frac{1}{2},\\quad \\frac{e_{2}}{e_{1}^{2}}=\\frac{0.0162}{(0.1800)^{2}}=\\frac{1}{2},\\quad \\frac{e_{3}}{e_{2}^{2}}=\\frac{0.00013122}{(0.0162)^{2}}=\\frac{1}{2},\n$$\nwhich is perfectly consistent with $e_{k+1}=\\frac{1}{2}e_{k}^{2}$. Therefore, the algorithm exhibits quadratic convergence.", "answer": "$$\\boxed{B}$$"}, {"introduction": "Beyond analyzing results, a crucial skill is predicting an algorithm's behavior before implementation. This practice explores this by examining three different fixed-point iteration schemes, all designed to solve the same equation. By analyzing the properties of each iteration function $g(x)$ near the fixed-point $x^*$, you can determine which scheme will converge and how quickly, demonstrating a powerful analytical tool in algorithm design and selection [@problem_id:2165631].", "id": "2165631", "problem": "An engineer is tasked with finding the unique positive real root, denoted as $x^*$, of the transcendental equation $x^2 = \\exp(-x)$. To solve this numerically, three different fixed-point iteration schemes are proposed, starting from an initial guess $x_0$ sufficiently close to $x^*$. Each scheme is of the form $x_{k+1} = g_i(x_k)$ for $i \\in \\{A, B, C\\}$.\n\nThe three schemes are:\n- **Scheme A:** $x_{k+1} = \\exp(-x_k/2)$\n- **Scheme B:** $x_{k+1} = -2\\ln(x_k)$\n- **Scheme C:** $x_{k+1} = x_k - \\frac{x_k^2 - \\exp(-x_k)}{2x_k + \\exp(-x_k)}$\n\nYour task is to analyze the local convergence behavior of each of these schemes at the fixed point $x^*$. Based on your analysis, determine which of the following statements correctly describes the properties of the three schemes.\n\nA) Scheme A converges linearly, Scheme B diverges, Scheme C converges quadratically.\nB) Scheme A converges quadratically, Scheme B diverges, Scheme C converges linearly.\nC) Scheme A converges linearly, Scheme B converges linearly, Scheme C diverges.\nD) All three schemes converge linearly.\nE) Scheme A diverges, Scheme B converges linearly, Scheme C converges quadratically.\n\n", "solution": "We are solving for the unique positive real root $x^{*}$ of $f(x)=x^{2}-\\exp(-x)=0$. All three fixed-point schemes aim at the same fixed point, since rearranging $x^{2}=\\exp(-x)$ yields $x=\\exp(-x/2)$ and equivalently $x=-2\\ln x$ for $x>0$, and Scheme C is Newton’s method for $f$.\n\nFirst, note that for $x\\geq 0$, $\\exp(-x)\\leq 1$, so at the positive root $x^{*}$ we have\n$$\nx^{*2}=\\exp(-x^{*})\\leq 1 \\quad \\Longrightarrow \\quad 0<x^{*}<1,\n$$\nsince $x^{*}=1$ would imply $1=\\exp(-1)$, which is false.\n\nGeneral fixed-point iteration $x_{k+1}=g(x_{k})$ converges locally to $x^{*}$ if $g(x^{*})=x^{*}$ and $|g'(x^{*})|<1$. The convergence is linear if $0<|g'(x^{*})|<1$, superlinear if $g'(x^{*})=0$, and quadratic for Newton’s method at a simple root.\n\nScheme A: $g_{A}(x)=\\exp(-x/2)$. Then\n$$\ng_{A}'(x)=-\\tfrac{1}{2}\\exp(-x/2),\n$$\nso at $x^{*}$,\n$$\ng_{A}'(x^{*})=-\\tfrac{1}{2}\\exp(-x^{*}/2)=-\\tfrac{1}{2}x^{*}.\n$$\nHence\n$$\n|g_{A}'(x^{*})|=\\tfrac{x^{*}}{2}<\\tfrac{1}{2}<1,\n$$\nso Scheme A converges locally and linearly (since $g_{A}'(x^{*})\\neq 0$).\n\nScheme B: $g_{B}(x)=-2\\ln x$ (defined for $x>0$). Then\n$$\ng_{B}'(x)=-\\frac{2}{x},\n$$\nso at $x^{*}$,\n$$\n|g_{B}'(x^{*})|=\\frac{2}{x^{*}}>2>1,\n$$\nbecause $0<x^{*}<1$. Therefore Scheme B diverges locally.\n\nScheme C: This is Newton’s method for $f(x)=x^{2}-\\exp(-x)$:\n$$\nx_{k+1}=x_{k}-\\frac{f(x_{k})}{f'(x_{k})}, \\quad f'(x)=2x+\\exp(-x).\n$$\nAt $x^{*}$,\n$$\nf'(x^{*})=2x^{*}+\\exp(-x^{*})=2x^{*}+x^{*2}=x^{*}(2+x^{*})\\neq 0,\n$$\nso the root is simple. Therefore Newton’s method converges quadratically. The classical error relation confirms this:\n$$\ne_{k+1}=\\frac{f''(x^{*})}{2f'(x^{*})}e_{k}^{2}+o(e_{k}^{2}),\n$$\nwith $f''(x)=2-\\exp(-x)$ and $f''(x^{*})=2-x^{*2}$, and $f'(x^{*})=x^{*}(2+x^{*})\\neq 0$.\n\nCollecting the results:\n- Scheme A: linear convergence.\n- Scheme B: divergence.\n- Scheme C: quadratic convergence.\n\nThis matches statement A.", "answer": "$$\\boxed{A}$$"}]}