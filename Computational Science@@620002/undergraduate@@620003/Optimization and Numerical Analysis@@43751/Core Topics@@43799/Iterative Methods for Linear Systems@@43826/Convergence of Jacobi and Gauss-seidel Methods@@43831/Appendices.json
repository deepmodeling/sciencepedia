{"hands_on_practices": [{"introduction": "While the spectral radius provides the definitive test for convergence, calculating eigenvalues can be intensive. A more practical and immediate way to guarantee convergence for both the Jacobi and Gauss-Seidel methods is to check if the system's matrix is strictly diagonally dominant (SDD). This exercise [@problem_id:2163189] offers hands-on practice in applying the SDD definition and creatively using row permutations to transform a seemingly non-convergent system into one where convergence is assured.", "problem": "An $n \\times n$ matrix $A$ is defined as being Strictly Diagonally Dominant (SDD) if, for every row, the absolute value of the diagonal entry is strictly greater than the sum of the absolute values of all other non-diagonal entries in that row. Mathematically, for each $i \\in \\{1, 2, ..., n\\}$, the condition $|a_{ii}| > \\sum_{j \\neq i} |a_{ij}|$ must hold.\n\nConsider the following 3x3 matrix $M$:\n$$\nM = \\begin{pmatrix} 1 & -2 & 9 \\\\ 7 & -3 & 2 \\\\ 1 & 8 & -4 \\end{pmatrix}\n$$\nBy performing only row swaps, is it possible to rearrange the matrix $M$ into a new matrix $P$ that is strictly diagonally dominant?\n\nSelect the correct statement from the options below.\n\nA. The original matrix $M$ is already strictly diagonally dominant.\n\nB. It is impossible to make the matrix strictly diagonally dominant through any permutation of its rows.\n\nC. The matrix $P = \\begin{pmatrix} 7 & -3 & 2 \\\\ 1 & 8 & -4 \\\\ 1 & -2 & 9 \\end{pmatrix}$ is a possible strictly diagonally dominant rearrangement.\n\nD. The matrix $P = \\begin{pmatrix} 1 & 8 & -4 \\\\ 1 & -2 & 9 \\\\ 7 & -3 & 2 \\end{pmatrix}$ is a possible strictly diagonally dominant rearrangement.\n\nE. The matrix $P = \\begin{pmatrix} 1 & -2 & 9 \\\\ 7 & -3 & 2 \\\\ 1 & 8 & -4 \\end{pmatrix}$ is strictly diagonally dominant, but this is the same as the original matrix.", "solution": "We use the definition: a matrix is strictly diagonally dominant (SDD) if for every row $i$, the diagonal entry satisfies $|a_{ii}| > \\sum_{j \\neq i} |a_{ij}|$.\n\nFirst, test the given matrix $M$ row by row to check option A and E:\n$$\nM=\\begin{pmatrix}\n1 & -2 & 9 \\\\\n7 & -3 & 2 \\\\\n1 & 8 & -4\n\\end{pmatrix}.\n$$\n- Row $1$: diagonal $a_{11}=1$, off-diagonal absolute sum $|{-2}|+|9|=2+9=11$. Check $|1|>11$, which is false.\n- Row $2$: diagonal $a_{22}=-3$, off-diagonal sum $|7|+|2|=7+2=9$. Check $|{-3}|=3>9$, which is false.\n- Row $3$: diagonal $a_{33}=-4$, off-diagonal sum $|1|+|8|=1+8=9$. Check $|{-4}|=4>9$, which is false.\n\nThus $M$ is not SDD, so options A and E are false.\n\nNext, determine whether a row permutation can make an SDD matrix. A row swap places a chosen row in position $i$, making its column-$i$ entry the diagonal. For a given row $r=(r_{1},r_{2},r_{3})$, it can occupy position $i$ only if $|r_{i}| > |r_{j}| + |r_{k}|$ for the other two columns $j,k$.\n\nCompute, for each row, which column can serve as a dominating diagonal:\n- Row $1$ is $(1,-2,9)$ with absolute values $(1,2,9)$:\n  - Column $1$: check $|1|>2+9$, i.e., $1>11$, false.\n  - Column $2$: check $|{-2}|=2>1+9=10$, false.\n  - Column $3$: check $|9|=9>1+2=3$, true. So row $1$ can be placed at position $3$.\n\n- Row $2$ is $(7,-3,2)$ with absolute values $(7,3,2)$:\n  - Column $1$: check $|7|=7>3+2=5$, true. So row $2$ can be placed at position $1$.\n  - Column $2$: check $|{-3}|=3>7+2=9$, false.\n  - Column $3$: check $|2|=2>7+3=10$, false.\n\n- Row $3$ is $(1,8,-4)$ with absolute values $(1,8,4)$:\n  - Column $1$: check $|1|=1>8+4=12$, false.\n  - Column $2$: check $|8|=8>1+4=5$, true. So row $3$ can be placed at position $2$.\n  - Column $3$: check $|{-4}|=4>1+8=9$, false.\n\nWe can therefore assign:\n- Position $1$ (column $1$): row $2$.\n- Position $2$ (column $2$): row $3$.\n- Position $3$ (column $3$): row $1$.\n\nThis yields the permuted matrix\n$$\nP=\\begin{pmatrix}\n7 & -3 & 2 \\\\\n1 & 8 & -4 \\\\\n1 & -2 & 9\n\\end{pmatrix},\n$$\nwhich matches option C. Verify SDD explicitly:\n- Row $1$: diagonal $7$, off-diagonal sum $|{-3}|+|2|=3+2=5$, and $7>5$ holds.\n- Row $2$: diagonal $8$, off-diagonal sum $|1|+|{-4}|=1+4=5$, and $8>5$ holds.\n- Row $3$: diagonal $9$, off-diagonal sum $|1|+|{-2}|=1+2=3$, and $9>3$ holds.\n\nThus $P$ is SDD, so it is possible to obtain an SDD rearrangement by row swaps. Therefore, option B is false, option D is false (its first row would have $|1|>8+4$ which fails), and the correct statement is option C.", "answer": "$$\\boxed{C}$$", "id": "2163189"}, {"introduction": "Although strict diagonal dominance is a useful shortcut, the fundamental condition for the convergence of any stationary iterative method is rooted in the properties of its iteration matrix. Convergence is guaranteed if and only if the spectral radius, $\\rho(T)$, of the iteration matrix $T$ is strictly less than 1. This practice problem [@problem_id:2163209] demystifies this core principle by guiding you through the explicit calculation of the Jacobi iteration matrix for a general 2x2 system and deriving its precise convergence condition.", "problem": "Consider a general non-singular linear system of two equations with two unknowns, represented by the matrix equation $Ax = b$, where the matrix $A$ is given by:\n$$\nA = \\begin{pmatrix} a_{11} & a_{12} \\\\ a_{21} & a_{22} \\end{pmatrix}\n$$\nIt is assumed that the diagonal elements, $a_{11}$ and $a_{22}$, are non-zero, allowing for the application of iterative methods like the Jacobi method.\n\nThe Jacobi method is an iterative algorithm for determining a numerical solution of a system of linear equations. A necessary and sufficient condition for a stationary iterative method to converge for any initial guess is that the absolute value of a specific expression, derived from the elements of matrix $A$, must be strictly less than 1.\n\nFor the Jacobi method to be guaranteed to converge for this 2x2 system, the absolute value of which of the following expressions must be strictly less than 1?\n\nA. $\\frac{a_{12}a_{21}}{a_{11}a_{22}}$\n\nB. $\\frac{a_{11}a_{22}}{a_{12}a_{21}}$\n\nC. $\\frac{a_{12}}{a_{11}} + \\frac{a_{21}}{a_{22}}$\n\nD. $\\frac{a_{11}+a_{22}}{a_{12}+a_{21}}$\n\nE. $a_{11} a_{22} - a_{12} a_{21}$", "solution": "We write the linear system as $Ax=b$ with\n$$\nA=\\begin{pmatrix} a_{11} & a_{12} \\\\ a_{21} & a_{22} \\end{pmatrix},\n$$\nand assume $a_{11}\\neq 0$ and $a_{22}\\neq 0$ so that the diagonal matrix $D=\\operatorname{diag}(a_{11},a_{22})$ is invertible. Using the standard splitting $A=D+L+U$, where $L$ is the strictly lower part of $A$ and $U$ is the strictly upper part of $A$:\n$$\nD=\\begin{pmatrix} a_{11} & 0 \\\\ 0 & a_{22} \\end{pmatrix},\\quad\nL=\\begin{pmatrix} 0 & 0 \\\\ a_{21} & 0 \\end{pmatrix},\\quad\nU=\\begin{pmatrix} 0 & a_{12} \\\\ 0 & 0 \\end{pmatrix},\n$$\nthe Jacobi iteration is\n$$\nx^{(k+1)}=-D^{-1}(L+U)x^{(k)} + D^{-1}b.\n$$\nThus the iteration matrix is\n$$\nT_{J}=-D^{-1}(L+U).\n$$\nFor the given $2\\times 2$ system,\n$$\nT_{J}\n=-\\begin{pmatrix} \\frac{1}{a_{11}} & 0 \\\\ 0 & \\frac{1}{a_{22}} \\end{pmatrix}\n\\begin{pmatrix} 0 & a_{12} \\\\ a_{21} & 0 \\end{pmatrix}\n=\n\\begin{pmatrix} 0 & -\\frac{a_{12}}{a_{11}} \\\\ -\\frac{a_{21}}{a_{22}} & 0 \\end{pmatrix}.\n$$\nA necessary and sufficient condition for convergence of a stationary iterative method for every initial guess is that the spectral radius of its iteration matrix is strictly less than $1$, i.e.,\n$$\n\\rho(T_{J})<1.\n$$\nTo compute $\\rho(T_{J})$, find the eigenvalues $\\lambda$ from the characteristic equation\n$$\n\\det(\\lambda I - T_{J})=\\det\\begin{pmatrix} \\lambda & \\frac{a_{12}}{a_{11}} \\\\ \\frac{a_{21}}{a_{22}} & \\lambda \\end{pmatrix}\n=\\lambda^{2}-\\frac{a_{12}a_{21}}{a_{11}a_{22}}=0.\n$$\nHence the eigenvalues are\n$$\n\\lambda=\\pm\\sqrt{\\frac{a_{12}a_{21}}{a_{11}a_{22}}}.\n$$\nTherefore, the spectral radius is\n$$\n\\rho(T_{J})=\\max\\{|\\lambda|\\}=\\sqrt{\\left|\\frac{a_{12}a_{21}}{a_{11}a_{22}}\\right|}.\n$$\nThe convergence condition $\\rho(T_{J})<1$ is thus equivalent to\n$$\n\\left|\\frac{a_{12}a_{21}}{a_{11}a_{22}}\\right|<1.\n$$\nAmong the given options, this is the absolute value of the expression in option A.", "answer": "$$\\boxed{A}$$", "id": "2163209"}, {"introduction": "With a firm grasp on convergence criteria, we can now explore the comparative behavior of the Jacobi and Gauss-Seidel methods. For 2x2 systems, a tidy relationship exists: the convergence of the Jacobi method implies the convergence of the Gauss-Seidel method. This final challenge [@problem_id:2163207] pushes you to investigate whether this rule holds in higher dimensions, testing your ability to analyze and compute the spectral radii for both methods to find a counterexample. This illustrates a critical lesson in numerical analysis: properties that hold in low dimensions do not always generalize.", "problem": "In the numerical analysis of linear systems of the form $A\\mathbf{x} = \\mathbf{b}$, the matrix $A$ is commonly decomposed into its diagonal part $D$, its strictly lower triangular part $L$, and its strictly upper triangular part $U$, such that $A = D + L + U$.\n\nTwo fundamental iterative schemes, which we will call Method J (Jacobi) and Method GS (Gauss-Seidel), are defined by the following update rules for the solution vector $\\mathbf{x}$ at iteration $k$:\n\n- **Method J:** $D\\mathbf{x}^{(k+1)} = -(L+U)\\mathbf{x}^{(k)} + \\mathbf{b}$\n- **Method GS:** $(D+L)\\mathbf{x}^{(k+1)} = -U\\mathbf{x}^{(k)} + \\mathbf{b}$\n\nFor these methods to converge to the unique solution for any initial guess $\\mathbf{x}^{(0)}$, the spectral radius of their respective iteration matrices ($T_J$ and $T_{GS}$) must be strictly less than 1. The iteration matrices are given by $T_J = -D^{-1}(L+U)$ and $T_{GS} = -(D+L)^{-1}U$.\n\nA well-known result states that for any $2 \\times 2$ system where the matrix $A$ has a non-zero diagonal, the convergence of Method J implies the convergence of Method GS. This property, however, does not hold for higher dimensions. Your task is to identify a counterexample in three dimensions.\n\nFor which of the following $3 \\times 3$ matrices $A$ does Method J converge, while Method GS diverges?\n\nA. $A = \\begin{pmatrix} 4 & 1 & -1 \\\\ -1 & 3 & 1 \\\\ 2 & 1 & 5 \\end{pmatrix}$\n\nB. $A = \\begin{pmatrix} 1 & 2 & -2 \\\\ 1 & 1 & 1 \\\\ 2 & 2 & 1 \\end{pmatrix}$\n\nC. $A = \\begin{pmatrix} 1 & 0 & 1 \\\\ -1 & 1 & 0 \\\\ 1 & 1 & 1 \\end{pmatrix}$\n\nD. $A = \\begin{pmatrix} 1 & 1 & 1 \\\\ 2 & 1 & 2 \\\\ 1 & 3 & 1 \\end{pmatrix}$", "solution": "To solve this problem, we must analyze each matrix option to determine the convergence properties of Method J (Jacobi) and Method GS (Gauss-Seidel). A method converges if the spectral radius, $\\rho(T)$, of its iteration matrix $T$ is less than 1.\n\nWe use the decomposition $A = D + L + U$, where $D$ is the diagonal, $L$ is the strictly lower triangular part, and $U$ is the strictly upper triangular part of $A$. The iteration matrices are $T_J = -D^{-1}(L+U)$ and $T_{GS} = -(D+L)^{-1}U$. We are looking for a case where $\\rho(T_J) < 1$ and $\\rho(T_{GS}) > 1$.\n\n**Option A: $A = \\begin{pmatrix} 4 & 1 & -1 \\\\ -1 & 3 & 1 \\\\ 2 & 1 & 5 \\end{pmatrix}$**\nThis matrix is strictly diagonally dominant because for each row, the absolute value of the diagonal element is greater than the sum of the absolute values of the off-diagonal elements.\n- Row 1: $|4| > |1| + |-1| = 2$\n- Row 2: $|3| > |-1| + |1| = 2$\n- Row 3: $|5| > |2| + |1| = 3$\nA well-known theorem states that if a matrix is strictly diagonally dominant, both Jacobi and Gauss-Seidel methods are guaranteed to converge. Thus, $\\rho(T_J) < 1$ and $\\rho(T_{GS}) < 1$. This is not the required counterexample.\n\n**Option B: $A = \\begin{pmatrix} 1 & 2 & -2 \\\\ 1 & 1 & 1 \\\\ 2 & 2 & 1 \\end{pmatrix}$**\nWe decompose $A = D+L+U$:\n$D = \\begin{pmatrix} 1 & 0 & 0 \\\\ 0 & 1 & 0 \\\\ 0 & 0 & 1 \\end{pmatrix} = I$, $L = \\begin{pmatrix} 0 & 0 & 0 \\\\ 1 & 0 & 0 \\\\ 2 & 2 & 0 \\end{pmatrix}$, $U = \\begin{pmatrix} 0 & 2 & -2 \\\\ 0 & 0 & 1 \\\\ 0 & 0 & 0 \\end{pmatrix}$\n\n*Method J analysis:*\n$T_J = -D^{-1}(L+U) = -(L+U) = -\\begin{pmatrix} 0 & 2 & -2 \\\\ 1 & 0 & 1 \\\\ 2 & 2 & 0 \\end{pmatrix} = \\begin{pmatrix} 0 & -2 & 2 \\\\ -1 & 0 & -1 \\\\ -2 & -2 & 0 \\end{pmatrix}$.\nThe characteristic equation is $\\det(T_J - \\lambda I) = 0$:\n$$ \\det \\begin{pmatrix} -\\lambda & -2 & 2 \\\\ -1 & -\\lambda & -1 \\\\ -2 & -2 & -\\lambda \\end{pmatrix} = -\\lambda(\\lambda^2 - 2) - (-2)(\\lambda - 2) + 2(2 - 2\\lambda) = -\\lambda^3 + 2\\lambda + 2\\lambda - 4 + 4 - 4\\lambda = -\\lambda^3 $$\nSo $-\\lambda^3 = 0$, which gives eigenvalues $\\lambda_{1,2,3} = 0$. The spectral radius is $\\rho(T_J) = 0$. Since $0 < 1$, Method J converges.\n\n*Method GS analysis:*\n$T_{GS} = -(D+L)^{-1}U$. First, $D+L = \\begin{pmatrix} 1 & 0 & 0 \\\\ 1 & 1 & 0 \\\\ 2 & 2 & 1 \\end{pmatrix}$.\nIts inverse is $(D+L)^{-1} = \\begin{pmatrix} 1 & 0 & 0 \\\\ -1 & 1 & 0 \\\\ 0 & -2 & 1 \\end{pmatrix}$.\nNow we compute $T_{GS}$:\n$$ T_{GS} = -\\begin{pmatrix} 1 & 0 & 0 \\\\ -1 & 1 & 0 \\\\ 0 & -2 & 1 \\end{pmatrix} \\begin{pmatrix} 0 & 2 & -2 \\\\ 0 & 0 & 1 \\\\ 0 & 0 & 0 \\end{pmatrix} = -\\begin{pmatrix} 0 & 2 & -2 \\\\ 0 & -2 & 3 \\\\ 0 & 0 & -2 \\end{pmatrix} = \\begin{pmatrix} 0 & -2 & 2 \\\\ 0 & 2 & -3 \\\\ 0 & 0 & 2 \\end{pmatrix} $$\nThis is an upper triangular matrix, so its eigenvalues are its diagonal entries: $\\lambda_1 = 0, \\lambda_2 = 2, \\lambda_3 = 2$.\nThe spectral radius is $\\rho(T_{GS}) = \\max\\{|0|, |2|, |2|\\} = 2$.\nSince $2 > 1$, Method GS diverges. This is the counterexample we are looking for.\n\n**Option C: $A = \\begin{pmatrix} 1 & 0 & 1 \\\\ -1 & 1 & 0 \\\\ 1 & 1 & 1 \\end{pmatrix}$**\n$D=I$, $L = \\begin{pmatrix} 0 & 0 & 0 \\\\ -1 & 0 & 0 \\\\ 1 & 1 & 0 \\end{pmatrix}$, $U = \\begin{pmatrix} 0 & 0 & 1 \\\\ 0 & 0 & 0 \\\\ 0 & 0 & 0 \\end{pmatrix}$.\n$T_J = -(L+U) = - \\begin{pmatrix} 0 & 0 & 1 \\\\ -1 & 0 & 0 \\\\ 1 & 1 & 0 \\end{pmatrix} = \\begin{pmatrix} 0 & 0 & -1 \\\\ 1 & 0 & 0 \\\\ -1 & -1 & 0 \\end{pmatrix}$.\n$\\det(T_J - \\lambda I) = \\det\\begin{pmatrix} -\\lambda & 0 & -1 \\\\ 1 & -\\lambda & 0 \\\\ -1 & -1 & -\\lambda \\end{pmatrix} = -\\lambda(\\lambda^2) - (-1)(-1) = -\\lambda^3 - 1$.\nThe characteristic equation $\\lambda^3 = -1$ has roots with absolute value 1. Thus, $\\rho(T_J) = 1$. Since convergence requires strict inequality $\\rho(T_J) < 1$, Method J is not guaranteed to converge.\n\n**Option D: $A = \\begin{pmatrix} 1 & 1 & 1 \\\\ 2 & 1 & 2 \\\\ 1 & 3 & 1 \\end{pmatrix}$**\n$D=I$, $L = \\begin{pmatrix} 0 & 0 & 0 \\\\ 2 & 0 & 0 \\\\ 1 & 3 & 0 \\end{pmatrix}$, $U = \\begin{pmatrix} 0 & 1 & 1 \\\\ 0 & 0 & 2 \\\\ 0 & 0 & 0 \\end{pmatrix}$.\n$T_J = -(L+U) = -\\begin{pmatrix} 0 & 1 & 1 \\\\ 2 & 0 & 2 \\\\ 1 & 3 & 0 \\end{pmatrix}$.\nThe characteristic polynomial of $-(T_J)$ is $p(\\mu) = \\mu^3 - 9\\mu - 8 = 0$. The roots are $\\mu_1 = -1$, $\\mu_{2,3} = \\frac{1 \\pm \\sqrt{33}}{2}$. The eigenvalues of $T_J$ are $\\lambda_i = -\\mu_i$, so $\\lambda_1 = 1$, $\\lambda_{2,3} = \\frac{-1 \\mp \\sqrt{33}}{2}$.\nThe absolute values are $|1|$, $|\\frac{-1 - \\sqrt{33}}{2}| = \\frac{1 + \\sqrt{33}}{2} \\approx 3.37$, and $|\\frac{-1 + \\sqrt{33}}{2}| \\approx 2.37$.\nThe spectral radius is $\\rho(T_J) = \\frac{1+\\sqrt{33}}{2} > 1$. Method J diverges.\n\nConclusion: Only matrix B satisfies the condition that Method J converges and Method GS diverges.", "answer": "$$\\boxed{B}$$", "id": "2163207"}]}