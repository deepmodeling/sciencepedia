{"hands_on_practices": [{"introduction": "We begin our practice by tackling a common and often counter-intuitive issue in numerical analysis. For ill-conditioned systems, a small residual does not necessarily imply an accurate solution. This exercise provides a concrete demonstration of this principle and showcases the power of iterative refinement to correct a solution that is far from the true answer, despite having a misleadingly small initial residual. [@problem_id:2182580]", "problem": "Consider the linear system of equations $Ax = b$, where the matrix $A$ and the vector $b$ are defined as:\n$$A = \\begin{pmatrix} 1  1 \\\\ 1  1.001 \\end{pmatrix}, \\quad b = \\begin{pmatrix} 3 \\\\ 3.002 \\end{pmatrix}$$\nAn approximate solution to this system, denoted by $x_0$, is given as $x_0 = \\begin{pmatrix} 2.998 \\\\ 0 \\end{pmatrix}$.\nUsing the provided matrix $A$ and the initial approximation $x_0$, perform a single step of iterative refinement to compute a more accurate solution, $x_1$. In this single step, you are required to solve the associated correction equation exactly.\n\nProvide the components of the refined solution vector $x_1$. Express your final answer as a row matrix containing the two components of $x_1$. Round each component to four significant figures if necessary.", "solution": "We perform one step of iterative refinement. Given $x_{0} = \\begin{pmatrix} 2.998 \\\\ 0 \\end{pmatrix}$, compute the residual\n$$r = b - A x_{0}.$$\nFirst compute\n$$A x_{0} = \\begin{pmatrix} 1  1 \\\\ 1  1.001 \\end{pmatrix} \\begin{pmatrix} 2.998 \\\\ 0 \\end{pmatrix} = \\begin{pmatrix} 2.998 \\\\ 2.998 \\end{pmatrix}.$$\nHence\n$$r = \\begin{pmatrix} 3 \\\\ 3.002 \\end{pmatrix} - \\begin{pmatrix} 2.998 \\\\ 2.998 \\end{pmatrix} = \\begin{pmatrix} 0.002 \\\\ 0.004 \\end{pmatrix}.$$\nThe correction $d$ is obtained by solving the exact correction equation\n$$A d = r, \\quad \\text{that is} \\quad \\begin{pmatrix} 1  1 \\\\ 1  1.001 \\end{pmatrix} \\begin{pmatrix} d_{1} \\\\ d_{2} \\end{pmatrix} = \\begin{pmatrix} 0.002 \\\\ 0.004 \\end{pmatrix}.$$\nThis gives the system\n$$d_{1} + d_{2} = 0.002, \\quad d_{1} + 1.001 d_{2} = 0.004.$$\nSubtract the first equation from the second:\n$$(d_{1} + 1.001 d_{2}) - (d_{1} + d_{2}) = 0.004 - 0.002 \\;\\Rightarrow\\; 0.001 d_{2} = 0.002 \\;\\Rightarrow\\; d_{2} = 2.$$\nThen\n$$d_{1} = 0.002 - d_{2} = 0.002 - 2 = -1.998.$$\nUpdate the approximation:\n$$x_{1} = x_{0} + d = \\begin{pmatrix} 2.998 \\\\ 0 \\end{pmatrix} + \\begin{pmatrix} -1.998 \\\\ 2 \\end{pmatrix} = \\begin{pmatrix} 1 \\\\ 2 \\end{pmatrix}.$$\nTherefore, the refined solution is exactly $\\begin{pmatrix} 1 \\\\ 2 \\end{pmatrix}$, which already meets any rounding requirement.", "answer": "$$\\boxed{\\begin{pmatrix} 1  2 \\end{pmatrix}}$$", "id": "2182580"}, {"introduction": "Having seen iterative refinement improve a solution, a natural next question is: how quickly does it converge? This practice shifts our focus from the mechanics of a single step to analyzing the algorithm's performance over multiple iterations. Using a set of hypothetical measurements, you will quantify the linear convergence rate, a fundamental skill in evaluating the efficiency of any iterative method. [@problem_id:2182584]", "problem": "An engineer is using an iterative refinement algorithm to improve the accuracy of a solution to a large system of linear equations, $Ax = b$, which arises from the finite element analysis of a mechanical structure. The algorithm generates a sequence of approximate solutions $x_k$ for $k=0, 1, 2, \\dots$. After each iteration, the Euclidean norm of the residual, $\\|r_k\\|_2 = \\|b - Ax_k\\|_2$, is computed to monitor the convergence. The following table shows the recorded residual norms for the first five iterations (from $k=0$ to $k=4$).\n\n| Iteration ($k$) | Residual Norm ($\\|r_k\\|_2$) |\n|:---------------:|:---------------------------:|\n| 0               | 1.521                       |\n| 1               | 0.310                       |\n| 2               | 0.061                       |\n| 3               | 0.0125                      |\n| 4               | 0.00248                     |\n\nAssuming the algorithm exhibits linear convergence, where the residual norms satisfy the relationship $\\|r_{k+1}\\|_2 \\approx C \\|r_k\\|_2$ for a constant factor $C$, estimate the value of $C$. Base your estimate on the average of the ratios $\\frac{\\|r_{k+1}\\|_2}{\\|r_k\\|_2}$ for $k=0, 1, 2, 3$.\n\nRound your final answer to three significant figures.", "solution": "Assuming linear convergence, the contraction factor is estimated by the average of successive residual ratios:\n$$\nC \\approx \\frac{1}{4}\\sum_{k=0}^{3}\\frac{\\|r_{k+1}\\|_{2}}{\\|r_{k}\\|_{2}}.\n$$\nUsing the given data:\n$$\n\\frac{\\|r_{1}\\|_{2}}{\\|r_{0}\\|_{2}}=\\frac{0.310}{1.521}=\\frac{310}{1521}\\approx 0.203813,\n$$\n$$\n\\frac{\\|r_{2}\\|_{2}}{\\|r_{1}\\|_{2}}=\\frac{0.061}{0.310}=\\frac{61}{310}\\approx 0.196774,\n$$\n$$\n\\frac{\\|r_{3}\\|_{2}}{\\|r_{2}\\|_{2}}=\\frac{0.0125}{0.061}=\\frac{25}{122}\\approx 0.204918,\n$$\n$$\n\\frac{\\|r_{4}\\|_{2}}{\\|r_{3}\\|_{2}}=\\frac{0.00248}{0.0125}=\\frac{124}{625}=0.1984.\n$$\nTherefore,\n$$\nC \\approx \\frac{1}{4}\\left(0.203813+0.196774+0.204918+0.1984\\right)=\\frac{0.803905}{4}\\approx 0.200976.\n$$\nRounded to three significant figures, this gives $C \\approx 0.201$.", "answer": "$$\\boxed{0.201}$$", "id": "2182584"}, {"introduction": "Iterative methods, including refinement, are powerful but not universally guaranteed to succeed. Their convergence depends critically on the properties of the system and the quality of the approximations used. This final practice explores a scenario where the refinement process fails, prompting an investigation into the mathematical conditions for convergence and revealing why a poorly chosen approximate inverse can lead to divergence. [@problem_id:2182564]", "problem": "A numerical analyst is attempting to solve the linear system of equations $Ax=b$, where the matrix $A$ and vector $b$ are given by:\n$$ A = \\begin{pmatrix} 1  1 \\\\ 1  1.01 \\end{pmatrix}, \\quad b = \\begin{pmatrix} 2 \\\\ 2.01 \\end{pmatrix} $$\nThe analyst does not compute the exact inverse of $A$. Instead, they use an available approximate inverse matrix $B$:\n$$ B = \\begin{pmatrix} -101  100 \\\\ -90  90 \\end{pmatrix} $$\nTo improve an initial guess for the solution, $x_0$, the analyst applies the following iterative scheme for $k \\ge 0$:\n$$ x_{k+1} = x_k + B(b - Ax_k) $$\nThe true solution to the system is $x = \\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix}$. When the scheme is initiated with a guess such as $x_0 = \\begin{pmatrix} 1.1 \\\\ 0.9 \\end{pmatrix}$, the analyst observes that the sequence of vectors $x_k$ does not converge to the true solution $x$.\n\nWhich of the following statements correctly explains the reason for this divergence?\n\nA. The matrix $A$ is singular, so a unique solution to the system does not exist.\n\nB. The matrix $B$ is not a sufficiently accurate approximation of the true inverse $A^{-1}$. The divergence is caused by the fact that the spectral radius of the iteration matrix $I - BA$ is greater than or equal to 1.\n\nC. The divergence is due to a poor choice of the initial guess $x_0$. A different initial guess that is closer to the true solution $x$ would ensure convergence.\n\nD. The matrix $A$ is ill-conditioned. For an ill-conditioned matrix, any iterative method of this form will always diverge regardless of the approximate inverse used.\n\nE. The iterative scheme fails because the approximate inverse matrix $B$ is singular.", "solution": "We analyze the stationary iteration\n$$\nx_{k+1} = x_{k} + B\\left(b - A x_{k}\\right),\n$$\nwith $A=\\begin{pmatrix}1  1 \\\\ 1  \\frac{101}{100}\\end{pmatrix}$, $B=\\begin{pmatrix}-101  100 \\\\ -90  90\\end{pmatrix}$, and exact solution $x$ satisfying $A x=b$.\n\nDefine the error $e_{k}=x_{k}-x$. Using $A x=b$, we derive the error propagation:\n$$\n\\begin{aligned}\ne_{k+1} = x_{k+1}-x \\\\\n= x_{k} + B(b - A x_{k}) - x \\\\\n= x_{k} - x + B(Ax - A x_{k}) \\\\\n= e_{k} - B A e_{k} \\\\\n= (I - B A)e_{k}.\n\\end{aligned}\n$$\nThus,\n$$\ne_{k} = (I - B A)^{k} e_{0},\n$$\nand the iteration converges for all initial guesses if and only if the spectral radius satisfies $\\rho(I - B A)  1$.\n\nCompute $B A$:\n$$\nB A\n=\n\\begin{pmatrix}\n-101  100 \\\\\n-90  90\n\\end{pmatrix}\n\\begin{pmatrix}\n1  1 \\\\\n1  \\frac{101}{100}\n\\end{pmatrix}\n=\n\\begin{pmatrix}\n-101\\cdot 1 + 100\\cdot 1  -101\\cdot 1 + 100\\cdot \\frac{101}{100} \\\\\n-90\\cdot 1 + 90\\cdot 1  -90\\cdot 1 + 90\\cdot \\frac{101}{100}\n\\end{pmatrix}\n=\n\\begin{pmatrix}\n-1  0 \\\\\n0  \\frac{9}{10}\n\\end{pmatrix}.\n$$\nTherefore,\n$$\nI - B A = \\begin{pmatrix}1  0 \\\\ 0  1\\end{pmatrix} - \\begin{pmatrix}-1  0 \\\\ 0  \\frac{9}{10}\\end{pmatrix} = \\begin{pmatrix}2  0 \\\\ 0  \\frac{1}{10}\\end{pmatrix}.\n$$\nThe eigenvalues of $I - B A$ are $2$ and $\\frac{1}{10}$, so\n$$\n\\rho(I - B A) = \\max\\left\\{2, \\frac{1}{10}\\right\\} = 2 \\geq 1.\n$$\nHence the iteration diverges for generic initial guesses, regardless of proximity to $x$, due to the eigenvalue $2$.\n\nWe now assess the options:\n\n- A is false because $A$ is nonsingular: $\\det(A) = 1\\cdot \\frac{101}{100} - 1\\cdot 1 = \\frac{1}{100} \\neq 0$.\n- B is true: $B$ is a poor approximate inverse, and $\\rho(I - B A) \\geq 1$ causes divergence.\n- C is false: convergence is governed by $\\rho(I - B A)$; changing $x_{0}$ does not ensure convergence unless $e_{0}$ lies entirely in the eigenspace corresponding to the eigenvalue $\\frac{1}{10}$.\n- D is false: ill-conditioning does not imply inevitable divergence; for example, $B=A^{-1}$ yields $I-BA=0$ and one-step convergence.\n- E is false: $B$ is nonsingular since $\\det(B) = (-101)\\cdot 90 - 100\\cdot (-90) = -90 \\neq 0$.\n\nTherefore, the correct explanation is that the spectral radius of $I - B A$ is greater than or equal to $1$, causing divergence.", "answer": "$$\\boxed{B}$$", "id": "2182564"}]}