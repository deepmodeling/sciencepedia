{"hands_on_practices": [{"introduction": "We begin our hands-on exploration with Hotelling's deflation, a foundational technique tailored for symmetric matrices. This method provides an intuitive entry point into the mechanics of how a matrix can be modified to \"remove\" a known eigenvalue. By working through this problem, you will practice the complete sequence of identifying a dominant eigenvector, normalizing it, and applying the deflation formula $A_1 = A - \\lambda_1 v_1 v_1^T$ to construct a new matrix where the dominant eigenvalue is now zero [@problem_id:2165888].", "problem": "In numerical linear algebra, deflation is a class of methods used to compute subdominant eigenvalues of a matrix. After a dominant eigenpair (eigenvalue and corresponding eigenvector) has been determined, the matrix is \"deflated\" into a new matrix. This new matrix possesses the same eigenvalues as the original, except the determined eigenvalue is replaced by zero.\n\nConsider the 3x3 symmetric matrix $A$ defined by its elements:\n$A_{11}=3$, $A_{22}=2$, $A_{33}=1$\n$A_{12}=A_{21}=2$\n$A_{23}=A_{32}=2$\n$A_{13}=A_{31}=0$\n\nThe dominant eigenvalue of this matrix is given as $\\lambda_1 = 5$.\n\nYour task is to compute the deflated matrix $A_1$ using Hotelling's deflation method. Express your answer as the resulting 3x3 matrix $A_1$, with elements written as fractions if necessary.", "solution": "We first write the given symmetric matrix as\n$$\nA=\\begin{pmatrix}\n3 & 2 & 0\\\\\n2 & 2 & 2\\\\\n0 & 2 & 1\n\\end{pmatrix}.\n$$\nHotelling’s deflation for a symmetric matrix uses the formula\n$$\nA_{1}=A-\\lambda_{1} u u^{T},\n$$\nwhere $\\lambda_{1}$ is the known dominant eigenvalue and $u$ is the corresponding unit eigenvector.\n\nTo find $u$, solve $(A-\\lambda_{1}I)x=0$ with $\\lambda_{1}=5$. This gives\n$$\nA-5I=\\begin{pmatrix}\n-2 & 2 & 0\\\\\n2 & -3 & 2\\\\\n0 & 2 & -4\n\\end{pmatrix},\n$$\nand the system\n$$\n-2x_{1}+2x_{2}=0,\\quad 2x_{1}-3x_{2}+2x_{3}=0,\\quad 2x_{2}-4x_{3}=0.\n$$\nFrom the first and third equations, $x_{2}=x_{1}$ and $x_{3}=\\frac{1}{2}x_{1}$. Hence an eigenvector is\n$$\nv=\\begin{pmatrix}1\\\\1\\\\\\frac{1}{2}\\end{pmatrix}.\n$$\nNormalize $v$:\n$$\nv^{T}v=1+1+\\frac{1}{4}=\\frac{9}{4},\\quad \\|v\\|=\\frac{3}{2},\\quad\nu=\\frac{v}{\\|v\\|}=\\frac{2}{3}\\begin{pmatrix}1\\\\1\\\\\\frac{1}{2}\\end{pmatrix}=\\begin{pmatrix}\\frac{2}{3}\\\\ \\frac{2}{3}\\\\ \\frac{1}{3}\\end{pmatrix}.\n$$\nCompute $u u^{T}$:\n$$\nu u^{T}=\\begin{pmatrix}\n\\frac{4}{9} & \\frac{4}{9} & \\frac{2}{9}\\\\\n\\frac{4}{9} & \\frac{4}{9} & \\frac{2}{9}\\\\\n\\frac{2}{9} & \\frac{2}{9} & \\frac{1}{9}\n\\end{pmatrix},\n\\quad\n5\\,u u^{T}=\\begin{pmatrix}\n\\frac{20}{9} & \\frac{20}{9} & \\frac{10}{9}\\\\\n\\frac{20}{9} & \\frac{20}{9} & \\frac{10}{9}\\\\\n\\frac{10}{9} & \\frac{10}{9} & \\frac{5}{9}\n\\end{pmatrix}.\n$$\nTherefore,\n$$\nA_{1}=A-5\\,u u^{T}=\n\\begin{pmatrix}\n3 & 2 & 0\\\\\n2 & 2 & 2\\\\\n0 & 2 & 1\n\\end{pmatrix}\n-\n\\begin{pmatrix}\n\\frac{20}{9} & \\frac{20}{9} & \\frac{10}{9}\\\\\n\\frac{20}{9} & \\frac{20}{9} & \\frac{10}{9}\\\\\n\\frac{10}{9} & \\frac{10}{9} & \\frac{5}{9}\n\\end{pmatrix}\n=\n\\begin{pmatrix}\n\\frac{7}{9} & -\\frac{2}{9} & -\\frac{10}{9}\\\\\n-\\frac{2}{9} & -\\frac{2}{9} & \\frac{8}{9}\\\\\n-\\frac{10}{9} & \\frac{8}{9} & \\frac{4}{9}\n\\end{pmatrix}.\n$$\nThis $A_{1}$ has the same eigenvalues as $A$ except that $\\lambda_{1}$ is replaced by $0$, as required by Hotelling’s deflation.", "answer": "$$\\boxed{\\begin{pmatrix}\\frac{7}{9} & -\\frac{2}{9} & -\\frac{10}{9}\\\\ -\\frac{2}{9} & -\\frac{2}{9} & \\frac{8}{9}\\\\ -\\frac{10}{9} & \\frac{8}{9} & \\frac{4}{9}\\end{pmatrix}}$$", "id": "2165888"}, {"introduction": "Building on the basics, we now turn to a more versatile tool: Wielandt's deflation. Unlike Hotelling's method, Wielandt's deflation is not restricted to symmetric matrices and demonstrates how the choice of an auxiliary vector provides additional flexibility in constructing the deflated matrix. This exercise will give you practical experience with the formula $B = A - \\lambda_1 \\frac{v_1 u^T}{u^T v_1}$, highlighting the method's broader applicability in more general eigenvalue problems [@problem_id:2165926].", "problem": "In numerical linear algebra, deflation is a technique used to find eigenvalues of a matrix sequentially. Once an eigenpair $(\\lambda_1, v_1)$ of a matrix $A$ is found, a new matrix $B$ is constructed that has $v_1$ as an eigenvector with eigenvalue zero. This process, when constructed correctly, preserves the other eigenvalues of $A$, allowing them to be found from the new matrix $B$.\n\nConsider the real, non-symmetric 2x2 matrix $A$ given by:\n$$A = \\begin{pmatrix} 4 & 1 \\\\ 2 & 3 \\end{pmatrix}$$\nOne of the eigenpairs of this matrix is $(\\lambda_1, v_1)$, where the eigenvalue is $\\lambda_1 = 5$ and its corresponding right eigenvector is $v_1 = \\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix}$.\n\nWe will use Wielandt's deflation method to construct the deflated matrix $B$. The formula for this method using an auxiliary vector $u$ is given by:\n$$B = A - \\lambda_1 \\frac{v_1 u^T}{u^T v_1}$$\nLet the auxiliary vector be $u = \\begin{pmatrix} 2 \\\\ 1 \\end{pmatrix}$.\n\nYour task is to compute the deflated matrix $B$.", "solution": "We use Wielandt’s deflation formula with the given eigenpair and auxiliary vector:\n$$B = A - \\lambda_{1} \\frac{v_{1} u^{T}}{u^{T} v_{1}}.$$\nCompute the denominator $u^{T} v_{1}$:\n$$u^{T} v_{1} = \\begin{pmatrix}2 & 1\\end{pmatrix} \\begin{pmatrix}1 \\\\ 1\\end{pmatrix} = 2 \\cdot 1 + 1 \\cdot 1 = 3.$$\nCompute the outer product $v_{1} u^{T}$:\n$$v_{1} u^{T} = \\begin{pmatrix}1 \\\\ 1\\end{pmatrix} \\begin{pmatrix}2 & 1\\end{pmatrix} = \\begin{pmatrix}2 & 1 \\\\ 2 & 1\\end{pmatrix}.$$\nTherefore,\n$$\\lambda_{1} \\frac{v_{1} u^{T}}{u^{T} v_{1}} = \\frac{5}{3} \\begin{pmatrix}2 & 1 \\\\ 2 & 1\\end{pmatrix} = \\begin{pmatrix}\\frac{10}{3} & \\frac{5}{3} \\\\ \\frac{10}{3} & \\frac{5}{3}\\end{pmatrix}.$$\nSubtract from $A$ to obtain $B$:\n$$B = \\begin{pmatrix}4 & 1 \\\\ 2 & 3\\end{pmatrix} - \\begin{pmatrix}\\frac{10}{3} & \\frac{5}{3} \\\\ \\frac{10}{3} & \\frac{5}{3}\\end{pmatrix} = \\begin{pmatrix}4 - \\frac{10}{3} & 1 - \\frac{5}{3} \\\\ 2 - \\frac{10}{3} & 3 - \\frac{5}{3}\\end{pmatrix} = \\begin{pmatrix}\\frac{2}{3} & -\\frac{2}{3} \\\\ -\\frac{4}{3} & \\frac{4}{3}\\end{pmatrix}.$$\nAs a check, $B v_{1} = \\begin{pmatrix}\\frac{2}{3} & -\\frac{2}{3} \\\\ -\\frac{4}{3} & \\frac{4}{3}\\end{pmatrix} \\begin{pmatrix}1 \\\\ 1\\end{pmatrix} = \\begin{pmatrix}0 \\\\ 0\\end{pmatrix}$, confirming that the eigenvalue is deflated to zero.", "answer": "$$\\boxed{\\begin{pmatrix}\\frac{2}{3} & -\\frac{2}{3} \\\\ -\\frac{4}{3} & \\frac{4}{3}\\end{pmatrix}}$$", "id": "2165926"}, {"introduction": "Our final practice addresses a common challenge in numerical computation: dealing with clustered or nearly identical eigenvalues, where single-vector deflation methods can suffer from numerical instability. This advanced exercise introduces block deflation, a powerful generalization that removes the influence of an entire invariant subspace at once. This practice is crucial for understanding how to robustly and efficiently find sub-dominant eigenvalues in complex systems modeled by large matrices [@problem_id:2165887].", "problem": "In the analysis of complex systems, such as in computational chemistry or structural mechanics, it is often necessary to determine not just the dominant characteristics (associated with the largest eigenvalues of a system matrix) but also the sub-dominant ones. Eigenvalue deflation is a class of methods used to remove the influence of known eigenpairs to allow numerical algorithms to find the remaining ones.\n\nConsider a real, symmetric system matrix $A \\in \\mathbb{R}^{3 \\times 3}$. Subspace iteration has been used to find an approximate basis for the two-dimensional invariant subspace corresponding to the two largest eigenvalues. This basis is given by the columns of the matrix $Q \\in \\mathbb{R}^{3 \\times 2}$, which has orthonormal columns.\n\nThe matrices $A$ and $Q$ are given by:\n$$\nA = \\begin{pmatrix} 10 & 1 & 0.1 \\\\ 1 & 10 & 1 \\\\ 0.1 & 1 & 3 \\end{pmatrix}, \\quad Q = \\begin{pmatrix} \\frac{1}{\\sqrt{2}} & \\frac{1}{\\sqrt{2}} \\\\ \\frac{1}{\\sqrt{2}} & -\\frac{1}{\\sqrt{2}} \\\\ 0 & 0 \\end{pmatrix}\n$$\n\nA block deflation procedure is applied to `A` to produce a deflated matrix `B`. This specific deflation method, a generalization of Hotelling's deflation, is designed to project out the contribution from the subspace spanned by the columns of `Q`. The deflated matrix `B` is constructed as:\n$$\nB = A - Q S Q^T\n$$\nwhere $S = Q^T A Q$ is the $2 \\times 2$ Rayleigh quotient matrix.\n\nYour task is to calculate the squared Frobenius norm of the deflated matrix, $\\|B\\|_F^2$. The Frobenius norm of a matrix $M$ is defined as $\\|M\\|_F = \\sqrt{\\sum_{i,j} |m_{ij}|^2}$. Report your answer as a single real number, rounded to four significant figures.", "solution": "We are given a symmetric matrix\n$$\nA=\\begin{pmatrix}10 & 1 & \\tfrac{1}{10}\\\\\n1 & 10 & 1\\\\\n\\tfrac{1}{10} & 1 & 3\\end{pmatrix}\n$$\nand an orthonormal basis matrix\n$$\nQ=\\begin{pmatrix}\\tfrac{1}{\\sqrt{2}} & \\tfrac{1}{\\sqrt{2}}\\\\\n\\tfrac{1}{\\sqrt{2}} & -\\tfrac{1}{\\sqrt{2}}\\\\\n0 & 0\\end{pmatrix}, \\quad Q^{T}Q=I_{2}.\n$$\nDefine $S=Q^{T}AQ$ and $B=A-QSQ^{T}$. We need $\\|B\\|_{F}^{2}$.\n\nFirst compute $S$ entrywise using $q_{1}=\\begin{pmatrix}\\tfrac{1}{\\sqrt{2}},\\tfrac{1}{\\sqrt{2}},0\\end{pmatrix}^{T}$ and $q_{2}=\\begin{pmatrix}\\tfrac{1}{\\sqrt{2}},-\\tfrac{1}{\\sqrt{2}},0\\end{pmatrix}^{T}$:\n- Using $Aq_{1}=\\begin{pmatrix}10a+b\\\\ a+10b\\\\ \\tfrac{1}{10}a+b\\end{pmatrix}$ with $a=b=\\tfrac{1}{\\sqrt{2}}$, we get\n$$\ns_{11}=q_{1}^{T}Aq_{1}=10(a^{2}+b^{2})+2ab=10\\cdot 1+2\\cdot \\tfrac{1}{2}=11.\n$$\n- Using $Aq_{2}=\\begin{pmatrix}9a\\\\ -9a\\\\ -\\tfrac{9}{10}a\\end{pmatrix}$ with $a=\\tfrac{1}{\\sqrt{2}}$, we get\n$$\ns_{22}=q_{2}^{T}Aq_{2}=9a^{2}+9a^{2}=18\\cdot \\tfrac{1}{2}=9.\n$$\n- For the off-diagonal term,\n$$\ns_{12}=q_{1}^{T}Aq_{2}=a\\cdot 9a+a\\cdot(-9a)+0\\cdot\\left(-\\tfrac{9}{10}a\\right)=0,\n$$\nand $s_{21}=s_{12}$ by symmetry. Hence\n$$\nS=\\begin{pmatrix}11 & 0\\\\ 0 & 9\\end{pmatrix}.\n$$\n\nNext, use Frobenius norm and trace identities. Since $A$ and $QSQ^{T}$ are symmetric, $B$ is symmetric and\n$$\n\\|B\\|_{F}^{2}=\\|A-QSQ^{T}\\|_{F}^{2}=\\|A\\|_{F}^{2}+\\|QSQ^{T}\\|_{F}^{2}-2\\,\\mathrm{trace}(A\\,QSQ^{T}).\n$$\nWe have\n$$\n\\|QSQ^{T}\\|_{F}^{2}=\\mathrm{trace}(QSQ^{T}QSQ^{T})=\\mathrm{trace}(QSSQ^{T})=\\mathrm{trace}(Q^{T}Q\\,SS)=\\mathrm{trace}(S^{2})=\\|S\\|_{F}^{2},\n$$\nand\n$$\n\\mathrm{trace}(A\\,QSQ^{T})=\\mathrm{trace}(Q^{T}AQ\\,S)=\\mathrm{trace}(S^{2}).\n$$\nTherefore,\n$$\n\\|B\\|_{F}^{2}=\\|A\\|_{F}^{2}+\\|S\\|_{F}^{2}-2\\,\\mathrm{trace}(S^{2})=\\|A\\|_{F}^{2}-\\|S\\|_{F}^{2}.\n$$\n\nCompute the two terms:\n$$\n\\|A\\|_{F}^{2}=10^{2}+1^{2}+\\left(\\tfrac{1}{10}\\right)^{2}+1^{2}+10^{2}+1^{2}+\\left(\\tfrac{1}{10}\\right)^{2}+1^{2}+3^{2}=213+\\tfrac{1}{50}=213.02,\n$$\n$$\n\\|S\\|_{F}^{2}=11^{2}+9^{2}=121+81=202.\n$$\nHence\n$$\n\\|B\\|_{F}^{2}=213.02-202=11.02.\n$$\nRounded to four significant figures, the value is $11.02$ (already at four significant figures).", "answer": "$$\\boxed{11.02}$$", "id": "2165887"}]}