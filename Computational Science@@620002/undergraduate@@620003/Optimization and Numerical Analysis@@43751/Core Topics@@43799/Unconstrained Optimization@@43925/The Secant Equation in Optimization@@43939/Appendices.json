{"hands_on_practices": [{"introduction": "Quasi-Newton methods build an approximation of the Hessian by observing how the gradient changes after a step. This exercise [@problem_id:2220248] will give you hands-on practice with the two fundamental vectors that capture this information: the step vector $s_k$ and the gradient difference vector $y_k$. By calculating these for a simple quadratic function, you will build a concrete understanding of the core components that form the secant equation.", "problem": "In the development of quasi-Newton methods for unconstrained optimization, the approximation of the Hessian matrix is updated at each step. This update relies on information gathered from the most recent step. Two key vectors are computed: the step vector, $s_k = x_{k+1} - x_k$, which represents the change in the variable vector, and the gradient difference vector, $y_k = \\nabla f(x_{k+1}) - \\nabla f(x_k)$, which captures the change in the gradient of the objective function $f$.\n\nConsider the quadratic objective function $f(x_1, x_2) = x_1^2 + 2x_2^2$. An optimization algorithm takes a step from the point described by the column vector $x_k = \\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix}$ to the point $x_{k+1} = \\begin{pmatrix} 2 \\\\ 0 \\end{pmatrix}$.\n\nCalculate the scalar value of the inner product $y_k^T s_k$.", "solution": "We use the standard quasi-Newton definitions: the step vector is $s_{k} = x_{k+1} - x_{k}$ and the gradient difference vector is $y_{k} = \\nabla f(x_{k+1}) - \\nabla f(x_{k})$. For $f(x_{1},x_{2}) = x_{1}^{2} + 2 x_{2}^{2}$, its gradient is\n$$\n\\nabla f(x_{1},x_{2}) = \\begin{pmatrix} \\frac{\\partial f}{\\partial x_{1}} \\\\ \\frac{\\partial f}{\\partial x_{2}} \\end{pmatrix} = \\begin{pmatrix} 2 x_{1} \\\\ 4 x_{2} \\end{pmatrix}.\n$$\nWith $x_{k} = \\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix}$ and $x_{k+1} = \\begin{pmatrix} 2 \\\\ 0 \\end{pmatrix}$, compute\n$$\ns_{k} = x_{k+1} - x_{k} = \\begin{pmatrix} 2 \\\\ 0 \\end{pmatrix} - \\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix} = \\begin{pmatrix} 1 \\\\ -1 \\end{pmatrix}.\n$$\nEvaluate the gradients:\n$$\n\\nabla f(x_{k}) = \\begin{pmatrix} 2 \\cdot 1 \\\\ 4 \\cdot 1 \\end{pmatrix} = \\begin{pmatrix} 2 \\\\ 4 \\end{pmatrix}, \\quad\n\\nabla f(x_{k+1}) = \\begin{pmatrix} 2 \\cdot 2 \\\\ 4 \\cdot 0 \\end{pmatrix} = \\begin{pmatrix} 4 \\\\ 0 \\end{pmatrix}.\n$$\nThus\n$$\ny_{k} = \\nabla f(x_{k+1}) - \\nabla f(x_{k}) = \\begin{pmatrix} 4 \\\\ 0 \\end{pmatrix} - \\begin{pmatrix} 2 \\\\ 4 \\end{pmatrix} = \\begin{pmatrix} 2 \\\\ -4 \\end{pmatrix}.\n$$\nThe desired inner product is\n$$\ny_{k}^{T} s_{k} = \\begin{pmatrix} 2 & -4 \\end{pmatrix} \\begin{pmatrix} 1 \\\\ -1 \\end{pmatrix} = 2 \\cdot 1 + (-4) \\cdot (-1) = 2 + 4 = 6.\n$$", "answer": "$$\\boxed{6}$$", "id": "2220248"}, {"introduction": "The secant equation, $B_{k+1} s_k = y_k$, forms the bedrock of quasi-Newton updates, ensuring the new Hessian approximation $B_{k+1}$ correctly maps the most recent step $s_k$ to the observed gradient change $y_k$. This exercise [@problem_id:2220287] challenges you to work backwards, using this fundamental constraint to solve for an unknown parameter within the objective function itself. It demonstrates how the secant equation connects the objective function, the step, and the Hessian approximation into a single, coherent relationship.", "problem": "In a quasi-Newton method for numerical optimization, an approximation of the Hessian matrix, denoted by $B_{k+1}$, is updated at each iteration. A fundamental property this matrix must satisfy is the secant equation, which relates the change in position to the change in the gradient of the objective function.\n\nLet the objective function be $f(x_1, x_2) = \\alpha x_1^2 + x_1 x_2 + x_2^2$, where the variable vector is $x = \\begin{pmatrix} x_1 \\\\ x_2 \\end{pmatrix}$, and $\\alpha$ is a constant parameter. An optimization algorithm proceeds from iteration $k$ to $k+1$, with the points given by $x_k = \\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix}$ and $x_{k+1} = \\begin{pmatrix} 2 \\\\ 3 \\end{pmatrix}$.\n\nThe secant equation is defined as $B_{k+1} s_k = y_k$, where the step vector is $s_k = x_{k+1} - x_k$ and the gradient difference vector is $y_k = \\nabla f(x_{k+1}) - \\nabla f(x_k)$.\n\nIf the Hessian approximation used in the update is the constant matrix $B_{k+1} = \\begin{pmatrix} 4 & 1 \\\\ 1 & 2 \\end{pmatrix}$, what value must the parameter $\\alpha$ have for the secant equation to be satisfied?", "solution": "The goal is to find the value of the parameter $\\alpha$ that satisfies the secant equation $B_{k+1} s_k = y_k$. We will compute each term in this equation step by step.\n\nFirst, we compute the step vector $s_k = x_{k+1} - x_k$. The problem provides the vectors for two consecutive iterations:\n$x_k = \\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix}$ and $x_{k+1} = \\begin{pmatrix} 2 \\\\ 3 \\end{pmatrix}$.\nSubtracting these vectors, we get:\n$$s_k = x_{k+1} - x_k = \\begin{pmatrix} 2 \\\\ 3 \\end{pmatrix} - \\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix} = \\begin{pmatrix} 2-1 \\\\ 3-1 \\end{pmatrix} = \\begin{pmatrix} 1 \\\\ 2 \\end{pmatrix}$$\n\nNext, we compute the gradient difference vector $y_k = \\nabla f(x_{k+1}) - \\nabla f(x_k)$. To do this, we first need to find the gradient of the objective function $f(x_1, x_2) = \\alpha x_1^2 + x_1 x_2 + x_2^2$.\nThe partial derivatives of $f$ are:\n$\\frac{\\partial f}{\\partial x_1} = 2\\alpha x_1 + x_2$\n$\\frac{\\partial f}{\\partial x_2} = x_1 + 2x_2$\nSo, the gradient vector $\\nabla f(x)$ is:\n$$\\nabla f(x) = \\begin{pmatrix} 2\\alpha x_1 + x_2 \\\\ x_1 + 2x_2 \\end{pmatrix}$$\n\nNow we evaluate the gradient at the points $x_k$ and $x_{k+1}$.\nAt $x_k = (1, 1)^T$:\n$$\\nabla f(x_k) = \\nabla f(1, 1) = \\begin{pmatrix} 2\\alpha(1) + 1 \\\\ 1 + 2(1) \\end{pmatrix} = \\begin{pmatrix} 2\\alpha + 1 \\\\ 3 \\end{pmatrix}$$\nAt $x_{k+1} = (2, 3)^T$:\n$$\\nabla f(x_{k+1}) = \\nabla f(2, 3) = \\begin{pmatrix} 2\\alpha(2) + 3 \\\\ 2 + 2(3) \\end{pmatrix} = \\begin{pmatrix} 4\\alpha + 3 \\\\ 8 \\end{pmatrix}$$\n\nNow we can compute the gradient difference vector $y_k$:\n$$y_k = \\nabla f(x_{k+1}) - \\nabla f(x_k) = \\begin{pmatrix} 4\\alpha + 3 \\\\ 8 \\end{pmatrix} - \\begin{pmatrix} 2\\alpha + 1 \\\\ 3 \\end{pmatrix} = \\begin{pmatrix} (4\\alpha + 3) - (2\\alpha + 1) \\\\ 8 - 3 \\end{pmatrix} = \\begin{pmatrix} 2\\alpha + 2 \\\\ 5 \\end{pmatrix}$$\n\nThe secant equation is $B_{k+1} s_k = y_k$. We have the matrix $B_{k+1} = \\begin{pmatrix} 4 & 1 \\\\ 1 & 2 \\end{pmatrix}$ and we have calculated $s_k$ and $y_k$. Let's compute the left-hand side of the equation:\n$$B_{k+1} s_k = \\begin{pmatrix} 4 & 1 \\\\ 1 & 2 \\end{pmatrix} \\begin{pmatrix} 1 \\\\ 2 \\end{pmatrix} = \\begin{pmatrix} 4(1) + 1(2) \\\\ 1(1) + 2(2) \\end{pmatrix} = \\begin{pmatrix} 4 + 2 \\\\ 1 + 4 \\end{pmatrix} = \\begin{pmatrix} 6 \\\\ 5 \\end{pmatrix}$$\n\nFinally, we equate the left-hand side and the right-hand side of the secant equation:\n$B_{k+1} s_k = y_k$\n$$\\begin{pmatrix} 6 \\\\ 5 \\end{pmatrix} = \\begin{pmatrix} 2\\alpha + 2 \\\\ 5 \\end{pmatrix}$$\nFor these two vectors to be equal, their corresponding components must be equal. This gives us a system of two linear equations:\n1) $6 = 2\\alpha + 2$\n2) $5 = 5$\n\nThe second equation is an identity, $5=5$, which confirms that our setup is consistent. We solve the first equation for $\\alpha$:\n$6 = 2\\alpha + 2$\n$6 - 2 = 2\\alpha$\n$4 = 2\\alpha$\n$\\alpha = \\frac{4}{2} = 2$\n\nThus, the parameter $\\alpha$ must be 2 for the secant equation to be satisfied.", "answer": "$$\\boxed{2}$$", "id": "2220287"}, {"introduction": "The ultimate goal of the secant equation is to guide the construction of the Hessian approximation $B_{k+1}$. While the equation $B_{k+1} s_k = y_k$ provides a set of constraints, it does not uniquely define the matrix on its own. In this problem [@problem_id:2220301], you will see how imposing additional structural requirements, such as symmetry, allows us to determine a unique Hessian approximation, providing direct insight into the core task of quasi-Newton methods.", "problem": "In quasi-Newton methods, which are used for finding local minima or maxima of functions, the Hessian matrix is approximated by a matrix $B_k$ that is updated at each iteration $k$. A fundamental requirement for this approximation is that it must satisfy the secant equation, $B_{k+1} s_k = y_k$. Here, $s_k = x_{k+1} - x_k$ represents the step taken in the variable space, and $y_k = \\nabla f(x_{k+1}) - \\nabla f(x_k)$ is the corresponding change in the gradient of the function $f$.\n\nConsider a single step of such an optimization algorithm in two dimensions. The step vector is given by $s_k = \\begin{pmatrix} 1 \\\\ 3 \\end{pmatrix}$ and the change in the gradient is $y_k = \\begin{pmatrix} 2 \\\\ -1 \\end{pmatrix}$. For this particular problem, we seek a Hessian approximation matrix, which we will simply call $B$, that has a special symmetric structure of the form $B = \\begin{pmatrix} a & b \\\\ b & a \\end{pmatrix}$, where $a$ and $b$ are real constants.\n\nDetermine the unique values of $a$ and $b$ for which the matrix $B$ satisfies the secant equation for the given $s_k$ and $y_k$. Present your answer as the ordered pair $(a, b)$.", "solution": "We must find real numbers $a$ and $b$ so that the symmetric matrix $B=\\begin{pmatrix} a & b \\\\ b & a \\end{pmatrix}$ satisfies the secant equation $B s_{k} = y_{k}$ with $s_{k}=\\begin{pmatrix} 1 \\\\ 3 \\end{pmatrix}$ and $y_{k}=\\begin{pmatrix} 2 \\\\ -1 \\end{pmatrix}$.\n\nCompute the matrix-vector product:\n$$\nB s_{k} = \\begin{pmatrix} a & b \\\\ b & a \\end{pmatrix}\\begin{pmatrix} 1 \\\\ 3 \\end{pmatrix}\n= \\begin{pmatrix} a + 3b \\\\ b + 3a \\end{pmatrix}.\n$$\nImposing the secant equation $B s_{k} = y_{k}$ gives\n$$\n\\begin{pmatrix} a + 3b \\\\ b + 3a \\end{pmatrix} = \\begin{pmatrix} 2 \\\\ -1 \\end{pmatrix},\n$$\nwhich yields the linear system\n$$\na + 3b = 2, \\quad 3a + b = -1.\n$$\nSolve by substitution. From $a + 3b = 2$, obtain $a = 2 - 3b$. Substitute into $3a + b = -1$:\n$$\n3(2 - 3b) + b = -1 \\implies 6 - 9b + b = -1 \\implies 6 - 8b = -1 \\implies -8b = -7 \\implies b = \\frac{7}{8}.\n$$\nThen\n$$\na = 2 - 3\\cdot \\frac{7}{8} = \\frac{16}{8} - \\frac{21}{8} = -\\frac{5}{8}.\n$$\nThe coefficient matrix $\\begin{pmatrix} 1 & 3 \\\\ 3 & 1 \\end{pmatrix}$ has determinant $1\\cdot 1 - 3\\cdot 3 = -8 \\neq 0$, so the solution is unique. Therefore, the required parameters are $a=-\\frac{5}{8}$ and $b=\\frac{7}{8}$.", "answer": "$$\\boxed{(-\\frac{5}{8}, \\frac{7}{8})}$$", "id": "2220301"}]}