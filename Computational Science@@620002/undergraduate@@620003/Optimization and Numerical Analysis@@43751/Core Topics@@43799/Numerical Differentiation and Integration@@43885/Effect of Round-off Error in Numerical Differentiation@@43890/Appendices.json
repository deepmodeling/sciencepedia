{"hands_on_practices": [{"introduction": "Before we build abstract models, let's get a feel for how round-off errors manifest in practice. This first exercise places you in the role of a computer with limited precision, tasked with performing a seemingly simple derivative calculation. By manually tracing the arithmetic as described in the problem [@problem_id:2167890], you will directly observe how finite-precision representation leads to catastrophic cancellation, a major source of error in numerical differentiation, and produces a result far from the analytical truth.", "problem": "In the field of computational science, understanding the limitations of floating-point arithmetic is crucial for interpreting numerical results. Consider a scenario where a scientist is modeling a physical process governed by the piecewise linear function $f(x)$ defined as:\n\n$$\nf(x) = \\begin{cases} 109.995 - 2x & \\text{if } x < 50 \\\\ 9.995 + 3(x-50) & \\text{if } x \\ge 50 \\end{cases}\n$$\n\nA hypothetical computer is tasked with numerically estimating the derivative of this function. This computer performs all its calculations using a floating-point standard that maintains a precision of 5 significant figures. After every arithmetic operation, the result is rounded to its 5-significant-figure representation. The rounding rule employed is \"round half up\" (e.g., 2.555 rounded to 3 significant figures is 2.56, and 2.554 is 2.55).\n\nThe computer uses the forward finite difference formula to approximate the derivative:\n$$\nf'(x) \\approx \\frac{f(x+h) - f(x)}{h}\n$$\n\nYour task is to determine the value this computer calculates for the derivative of $f(x)$ at the point $x = 1.0$, using a step size of $h = 10^{-4}$.\n\nExpress your answer as an integer.", "solution": "We must simulate the computer’s arithmetic with 5 significant figures and round-half-up after every operation. The function for inputs near $x=1$ uses the branch $f(x)=109.995-2x$.\n\nDefine $R(\\cdot)$ as rounding to 5 significant figures with round-half-up.\n\nFirst compute $x+h$:\n$$\nx=1.0,\\quad h=10^{-4},\\quad x+h=R(1.0+10^{-4})=R(1.0001)=1.0001.\n$$\n\nEvaluate $f(x)$ at $x=1.0$:\n- Multiply: $R(2\\cdot 1.0)=R(2.0)=2.0000$.\n- Subtract: $R(109.995-2.0000)=R(107.995)=108.00$ (since the sixth significant digit is $5$, round up).\n\nThus $f(1.0)=108.00$ in the machine.\n\nEvaluate $f(x+h)$ at $x+h=1.0001$:\n- Multiply: $R(2\\cdot 1.0001)=R(2.0002)=2.0002$.\n- Subtract: $R(109.995-2.0002)=R(107.9948)=107.99$ (since the sixth significant digit is $4$, round down).\n\nThus $f(1.0001)=107.99$ in the machine.\n\nForm the forward difference numerator and divide by $h$:\n$$\nR\\big(f(1.0001)-f(1.0)\\big)=R(107.99-108.00)=R(-0.01)=-0.01,\n$$\n$$\nR\\left(\\frac{-0.01}{10^{-4}}\\right)=R(-100)=-100.\n$$\n\nTherefore, the computer’s calculated derivative at $x=1.0$ with $h=10^{-4}$ is $-100$.", "answer": "$$\\boxed{-100}$$", "id": "2167890"}, {"introduction": "Having seen how round-off error can corrupt a calculation, our next step is to create a mathematical framework to manage it. The total error in numerical differentiation is a fundamental trade-off: a smaller step size $h$ reduces the approximation (truncation) error but amplifies the round-off error. This practice [@problem_id:2167887] challenges you to find the 'sweet spot'—the optimal step size $h_{\\text{opt}}$ that minimizes the total error—by modeling the competing error sources and using calculus to find the minimum.", "problem": "In the field of numerical analysis, a fundamental challenge is to balance truncation error (from mathematical approximation) and round-off error (from finite-precision hardware). Consider the task of computing the derivative of the function $f(x) = \\sin(x)$ at an arbitrary point $x=a$ using the central difference formula.\n\nThe total error, $E_{total}(h)$, as a function of the step size $h$, is modeled as the sum of the magnitudes of these two error types.\nThe magnitude of the truncation error for the central difference method is given by the expression:\n$$|E_{trunc}(h)| = \\frac{h^2}{6} |f'''(a)|$$\nThe magnitude of the round-off error, which results from the limitations of floating-point arithmetic, is modeled as:\n$$|E_{round}(h)| = \\frac{\\epsilon}{h}$$\nHere, $\\epsilon$ is a small, positive constant that represents the upper bound on the absolute error of a single function evaluation.\n\nThe total error is thus approximated by the sum $E_{total}(h) = |E_{trunc}(h)| + |E_{round}(h)|$. Your task is to find the optimal step size, $h_{opt}$, that minimizes this total error.\n\nProvide your answer as a closed-form analytic expression in terms of the parameters $a$ and $\\epsilon$. You may assume that $\\cos(a) \\neq 0$.", "solution": "We are given the function $f(x) = \\sin(x)$ and the central difference total error model\n$$E_{total}(h) = |E_{trunc}(h)| + |E_{round}(h)| = \\frac{h^{2}}{6}\\,|f'''(a)| + \\frac{\\epsilon}{h}.$$\nFor $f(x) = \\sin(x)$, the third derivative is $f'''(x) = -\\cos(x)$, hence $|f'''(a)| = |\\cos(a)|$. Therefore,\n$$E_{total}(h) = \\frac{h^{2}}{6}\\,|\\cos(a)| + \\frac{\\epsilon}{h}, \\quad h>0.$$\nTo find the minimizing step size, differentiate with respect to $h$ and set the derivative to zero:\n$$\\frac{dE_{total}}{dh} = \\frac{2h}{6}\\,|\\cos(a)| - \\frac{\\epsilon}{h^{2}} = \\frac{h}{3}\\,|\\cos(a)| - \\frac{\\epsilon}{h^{2}}.$$\nSetting $\\frac{dE_{total}}{dh}=0$ gives\n$$\\frac{h}{3}\\,|\\cos(a)| = \\frac{\\epsilon}{h^{2}} \\quad \\Longrightarrow \\quad \\frac{|\\cos(a)|}{3}\\,h^{3} = \\epsilon \\quad \\Longrightarrow \\quad h^{3} = \\frac{3\\epsilon}{|\\cos(a)|}.$$\nThus,\n$$h_{opt} = \\left(\\frac{3\\epsilon}{|\\cos(a)|}\\right)^{\\frac{1}{3}}.$$\nTo verify this is a minimum, compute the second derivative:\n$$\\frac{d^{2}E_{total}}{dh^{2}} = \\frac{1}{3}\\,|\\cos(a)| + \\frac{2\\epsilon}{h^{3}},$$\nwhich is strictly positive for $h>0$, confirming that the critical point is a minimizer. Therefore, the optimal step size is\n$$h_{opt} = \\left(\\frac{3\\epsilon}{|\\cos(a)|}\\right)^{\\frac{1}{3}}.$$", "answer": "$$\\boxed{\\left(\\frac{3\\epsilon}{|\\cos(a)|}\\right)^{\\frac{1}{3}}}$$", "id": "2167887"}, {"introduction": "Our analytical model reveals that the optimal step size depends critically on the machine epsilon, $\\epsilon$, which quantifies the arithmetic precision of a computer. This final practice [@problem_id:2167868] makes this connection tangible by comparing an engineering decision between two hardware platforms with vastly different precisions. By deriving the optimal step sizes for both a resource-constrained 16-bit processor and a standard 64-bit workstation, you will discover just how profoundly hardware choice impacts the implementation and accuracy of numerical algorithms.", "problem": "An engineer is developing a real-time control system for a satellite's orientation mechanism. The system needs to compute the derivative of the function $f(x) = \\cos(x)$ at the point $x = \\pi/4$ to determine a rate of change. Due to processing limitations, the derivative is approximated using the first-order forward difference formula:\n$$\nf'(x) \\approx \\frac{f(x+h) - f(x)}{h}\n$$\nThe total absolute error of this numerical differentiation is the sum of the absolute truncation error and the absolute round-off error. The truncation error is well-approximated by $\\frac{h}{2}|f''(x)|$. The round-off error arises from the finite precision of floating-point arithmetic and is approximated by $\\frac{2\\epsilon |f(x)|}{h}$, where $\\epsilon$ is the machine epsilon of the computer. The optimal step size, $h_{opt}$, is the value of $h > 0$ that minimizes this total error.\n\nThe engineer must choose between two hardware platforms for this calculation:\n1.  A resource-constrained embedded processor with a custom 16-bit floating-point unit, for which the machine epsilon is $\\epsilon_{16} = 2^{-11}$.\n2.  A standard ground-based workstation using 64-bit double-precision arithmetic, for which the machine epsilon is $\\epsilon_{64} = 2^{-53}$.\n\nLet $h_{opt, 16}$ be the optimal step size for the 16-bit system and $h_{opt, 64}$ be the optimal step size for the 64-bit system. Calculate the ratio $\\frac{h_{opt, 16}}{h_{opt, 64}}$.\n\nRound your final answer to three significant figures.", "solution": "The total absolute error for the forward-difference derivative approximation is modeled as\n$$\nE(h)=\\frac{h}{2}\\,|f''(x)|+\\frac{2\\epsilon\\,|f(x)|}{h},\n$$\nwhere the first term is the truncation error and the second term is the round-off error. To find the optimal step size, differentiate with respect to $h$ and set to zero:\n$$\n\\frac{dE}{dh}=\\frac{1}{2}|f''(x)|-\\frac{2\\epsilon\\,|f(x)|}{h^{2}}=0.\n$$\nSolving for $h$ gives\n$$\nh_{\\text{opt}}=\\sqrt{\\frac{2\\epsilon\\,|f(x)|}{\\tfrac{1}{2}|f''(x)|}}=2\\sqrt{\\frac{\\epsilon\\,|f(x)|}{|f''(x)|}}.\n$$\nFor $f(x)=\\cos(x)$, we have $f''(x)=-\\cos(x)$. At $x=\\pi/4$, $|f(x)|=|\\cos(\\pi/4)|=\\frac{\\sqrt{2}}{2}$ and $|f''(x)|=|-\\cos(\\pi/4)|=\\frac{\\sqrt{2}}{2}$, so\n$$\n\\frac{|f(x)|}{|f''(x)|}=1,\n$$\nand hence\n$$\nh_{\\text{opt}}=2\\sqrt{\\epsilon}.\n$$\nTherefore, the ratio of optimal step sizes between the two systems is\n$$\n\\frac{h_{\\text{opt},16}}{h_{\\text{opt},64}}=\\frac{2\\sqrt{\\epsilon_{16}}}{2\\sqrt{\\epsilon_{64}}}=\\sqrt{\\frac{\\epsilon_{16}}{\\epsilon_{64}}}=\\sqrt{\\frac{2^{-11}}{2^{-53}}}=\\sqrt{2^{42}}=2^{21}=2097152.\n$$\nRounding to three significant figures yields\n$$\n2.10\\times 10^{6}.\n$$", "answer": "$$\\boxed{2.10 \\times 10^{6}}$$", "id": "2167868"}]}