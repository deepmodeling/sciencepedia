{"hands_on_practices": [{"introduction": "Why does an adaptive solver take small steps for one problem and large steps for another? This practice explores the fundamental relationship between an ODE's solution and the step sizes chosen by the solver. By comparing a function with exponential growth against one with high-frequency oscillations [@problem_id:2153282], you will build an intuition for how the solution's derivatives, which measure its 'activity,' directly influence the step-size selection needed to maintain a constant error tolerance.", "problem": "An adaptive-step-size Ordinary Differential Equation (ODE) solver is employed to numerically approximate the solutions to two different Initial Value Problems (IVPs) over a time interval $t \\in [0, T]$, where $T$ is a large positive value. The solver's core mechanism is to adjust its step size, denoted by $h(t)$, at each point in time to ensure that the estimated local truncation error at each step remains approximately constant and below a predefined tolerance.\n\nConsider the following two IVPs:\n\n- **Problem A:** $y'(t) = y(t)$, with the initial condition $y(0) = 1$. Let the step size chosen by the solver for this problem be $h_A(t)$.\n- **Problem B:** $z'(t) = \\cos(\\omega t)$, with the initial condition $z(0) = 0$. Here, $\\omega$ is a large, fixed, positive constant (i.e., $\\omega \\gg 1$). Let the step size chosen by the solver for this problem be $h_B(t)$.\n\nAssuming the solver is based on a method of order $p$ (where $p \\ge 1$), which of the following statements best describes the general trend of the step sizes $h_A(t)$ and $h_B(t)$ as time $t$ increases across the interval $[0, T]$?\n\nA. $h_A(t)$ will be roughly constant, while $h_B(t)$ will steadily decrease.\n\nB. $h_A(t)$ will steadily decrease, while $h_B(t)$ will be roughly constant.\n\nC. Both $h_A(t)$ and $h_B(t)$ will steadily decrease.\n\nD. Both $h_A(t)$ and $h_B(t)$ will be roughly constant.\n\nE. $h_A(t)$ will steadily increase, while $h_B(t)$ will be roughly constant.", "solution": "An adaptive method of order $p$ selects step size $h(t)$ to keep the local truncation error (LTE) approximately at a target tolerance, say $\\varepsilon$. For a one-step method of order $p$, the LTE has the asymptotic form\n$$\n\\text{LTE}(t) \\approx C(t)\\,h(t)^{p+1},\n$$\nwhere $C(t)$ depends on derivatives of the exact solution (or equivalently derivatives of $f$ in $y'=f(t,y)$) up to order $p+1$. Enforcing $\\text{LTE}(t)\\approx\\varepsilon$ yields the scaling law\n$$\nh(t) \\approx \\left(\\frac{\\varepsilon}{C(t)}\\right)^{\\frac{1}{p+1}}.\n$$\n\nFor Problem A, $y'(t)=y(t)$ with $y(0)=1$, the exact solution is $y(t)=\\exp(t)$. All higher derivatives satisfy $y^{(k)}(t)=\\exp(t)$ for every integer $k\\ge 0$. Thus the coefficient $C_{A}(t)$ is proportional to $|y^{(p+1)}(t)|=|\\exp(t)|=\\exp(t)$, so\n$$\nh_{A}(t)\\approx \\left(\\frac{\\varepsilon}{C_{A}(t)}\\right)^{\\frac{1}{p+1}} \\propto \\exp\\!\\left(-\\frac{t}{p+1}\\right).\n$$\nHence $h_{A}(t)$ decreases monotonically as $t$ increases.\n\nFor Problem B, $z'(t)=\\cos(\\omega t)$ with $z(0)=0$, the exact solution is $z(t)=\\omega^{-1}\\sin(\\omega t)$. Its derivatives satisfy\n$$\nz^{(k)}(t)=\\omega^{k-1}\\times(\\text{a sine or cosine factor}),\n$$\nso $|z^{(p+1)}(t)|$ is bounded by a constant multiple of $\\omega^{p}$, independent of $t$, and is merely periodic in $t$. Therefore $C_{B}(t)$ is bounded and periodic with no secular growth in $t$, implying\n$$\nh_{B}(t)\\approx \\left(\\frac{\\varepsilon}{C_{B}(t)}\\right)^{\\frac{1}{p+1}} \\sim \\text{constant in }t.\n$$\nThe magnitude of $h_B$ is set by $\\omega$ as $h_{B}\\propto \\omega^{-\\frac{p}{p+1}}$, but the step size does not decrease over time.\n\nConsequently, $h_{A}(t)$ steadily decreases with $t$, while $h_{B}(t)$ remains roughly constant as $t$ increases. This corresponds to option B.", "answer": "$$\\boxed{B}$$", "id": "2153282"}, {"introduction": "Now, let's zoom in from the overall trend to the mechanics of a single, critical step. This exercise [@problem_id:2153280] offers a concrete look at the inner workings of a step-size controller when tackling a stiff ODE with an explicit method. By performing the calculation at the very edge of the method's absolute stability region, you will uncover why the controller must dramatically reduce the step size, providing a quantitative basis for understanding the challenges of stiffness.", "problem": "An engineer is using a numerical routine to simulate a process governed by a first-order stiff Ordinary Differential Equation (ODE). The routine employs an adaptive step size strategy. The integration is performed using Heun's method (also known as the improved Euler method or a second-order Runge-Kutta method), which advances the solution from time $t_n$ to $t_{n+1} = t_n + h$ using the following steps:\n1.  $k_1 = f(t_n, y_n)$\n2.  $k_2 = f(t_n + h, y_n + h k_1)$\n3.  $y_{n+1} = y_n + \\frac{h}{2}(k_1 + k_2)$\n\nTo control the step size, the local error at each step is estimated by comparing the result of Heun's method, $y_{n+1}$, with the result from the simpler forward Euler method, $\\hat{y}_{n+1} = y_n + h k_1$. The local error estimate is defined as $\\text{err}_{n+1} = |y_{n+1} - \\hat{y}_{n+1}|$.\n\nThe step size is then adjusted using the standard proportional-integral controller formula, simplified for this analysis to its proportional part:\n$$h_{n+1} = h_n \\left( \\frac{\\text{TOL}}{\\text{err}_{n+1}} \\right)^{1/2}$$\nwhere $h_n$ is the current step size, $h_{n+1}$ is the proposed next step size, and $\\text{TOL}$ is the desired error tolerance. The exponent is determined by the order of the lower-order method used for error estimation (in this case, the forward Euler method, which has order $q=1$, so the exponent is $1/(q+1)=1/2$).\n\nThe system being modeled is the stiff problem $y' = -\\lambda y$, with $\\lambda = 5 \\times 10^5~\\text{s}^{-1}$. The simulation starts at $t_0=0$ with an initial value $y(0) = y_0 = 0.1$. The error tolerance is set to $\\text{TOL} = 2.0 \\times 10^{-8}$.\n\nSuppose that, due to the sharp initial transient, the step size controller has chosen an initial step size $h_0$ that places the dimensionless product $h_0 \\lambda$ precisely at the extreme negative real boundary of the absolute stability region of Heun's method.\n\nCalculate the ratio of the proposed next step size, $h_1$, to the current step size, $h_0$. Round your final answer to four significant figures.", "solution": "For the linear test equation $y'=-\\lambda y$ with $\\lambda>0$, applying Heun's method gives:\n$$\nk_{1}=-\\lambda y_{n}\n$$\n$$\nk_{2}=-\\lambda\\left(y_{n}+h k_{1}\\right)=-\\lambda y_{n}+h\\lambda^{2}y_{n}\n$$\nThus, the higher-order (Heun) approximation is:\n$$\ny_{n+1}=y_{n}+\\frac{h}{2}\\left(k_{1}+k_{2}\\right)=y_{n}-h\\lambda y_{n}+\\frac{h^{2}}{2}\\lambda^{2}y_{n}\n$$\nThe lower-order (forward Euler) approximation is:\n$$\n\\hat{y}_{n+1}=y_{n}+h k_{1}=y_{n}-h\\lambda y_{n}\n$$\nTherefore the local error estimate is:\n$$\n\\text{err}_{n+1}=\\left|y_{n+1}-\\hat{y}_{n+1}\\right|=\\left|\\frac{h^{2}}{2}\\lambda^{2}y_{n}\\right|=\\frac{h^{2}}{2}\\lambda^{2}\\left|y_{n}\\right|\n$$\nFor Heun's method, the stability function is $R(z)=1+z+\\frac{z^{2}}{2}$. Along the negative real axis, the absolute stability interval is $z\\in[-2,0]$, with the extreme negative boundary at $z=-2$. For $y'=-\\lambda y$, we have $z=-h\\lambda$, so the problem statement implies that for the first step, $h_0$, we have:\n$$\nh_{0}\\lambda=2\n$$\nAt this first step, we use $y_{0}=0.1$ to calculate the error estimate:\n$$\n\\text{err}_{1}=\\frac{h_{0}^{2}}{2}\\lambda^{2}\\left|y_{0}\\right|=\\frac{1}{2}\\left(h_{0}\\lambda\\right)^{2}\\left|y_{0}\\right|=\\frac{1}{2}(2)^{2}(0.1)=0.2\n$$\nThe exponent for the step update is given as $p=1/(q+1) = 1/(1+1) = 1/2$. The step update formula is:\n$$\n\\frac{h_{1}}{h_{0}}=\\left(\\frac{\\text{TOL}}{\\text{err}_{1}}\\right)^{1/2}=\\left(\\frac{2.0\\times 10^{-8}}{0.2}\\right)^{1/2}=\\left(10^{-7}\\right)^{1/2}=10^{-3.5} \\approx 3.16227766 \\times 10^{-4}\n$$\nRounded to four significant figures, this ratio is $3.162\\times 10^{-4}$.", "answer": "$$\\boxed{3.162 \\times 10^{-4}}$$", "id": "2153280"}, {"introduction": "Having analyzed a single step, we now zoom back out to interpret the behavior of a solver over an entire integration interval. This practice [@problem_id:2372234] develops a crucial diagnostic skill for any computational scientist: analyzing a solver's step-size history to understand its performance and diagnose underlying issues. By contrasting the step-size evolution for a stiff versus a non-stiff problem, you will learn to recognize the characteristic signature of a stability-limited integration versus an accuracy-limited one.", "problem": "Two ordinary differential equation (ODE) initial value problems are integrated over $t\\in[0,10]$ with the same explicit embedded Rungeâ€“Kutta method of order $p=5$, using standard local error control with relative tolerance $\\mathrm{rtol}=10^{-6}$, absolute tolerance $\\mathrm{atol}=10^{-12}$, a safety factor $S\\in(0,1)$, and initial step $h(0)=10^{-3}$. The problems are:\n- System $S$: $y^{\\prime}(t)=-\\lambda\\,y(t)$ with $\\lambda=10^{4}$ and $y(0)=1$.\n- System $N$: $y^{\\prime}(t)=-y(t)$ with $y(0)=1$.\n\nTwo runs are performed, one on each system, producing the following observed step-size histories $h(t)$:\n- Run $\\mathrm{R1}$: After initial adaptation, $h(t)$ settles near a nearly constant plateau $h(t)\\approx 5\\times 10^{-4}$ for most of $t\\in[0,10]$. Repeating the run with $\\mathrm{rtol}$ multiplied by $10$ or divided by $10$ leaves this plateau essentially unchanged.\n- Run $\\mathrm{R2}$: $h(t)$ increases by orders of magnitude during the early part of the interval and eventually reaches $h(t)\\approx 5\\times 10^{-1}$ with mild fluctuations. When $\\mathrm{rtol}$ is tightened by a factor of $10$, the asymptotic $h(t)$ decreases systematically; when $\\mathrm{rtol}$ is relaxed by a factor of $10$, the asymptotic $h(t)$ increases systematically.\n\nUsing only the information in the step-size history $h(t)$ as a diagnostic, which of the following statements are valid for comparing solver performance on the stiff versus non-stiff system? Select all that apply.\n\nA. Run $\\mathrm{R1}$ corresponds to the stiff system $S$; the observed $h(t)$ plateau and its insensitivity to changes in $\\mathrm{rtol}$ indicate that the step size is limited primarily by linear stability, i.e., by a constraint of the form $\\lvert h\\,\\lambda\\rvert\\lesssim \\gamma$ for some method-dependent constant $\\gamma$, rather than by accuracy.\n\nB. Run $\\mathrm{R2}$ corresponds to the stiff system $S$; the growing $h(t)$ shows that the explicit method can take very large steps across the fast transient because stiffness permits skipping over rapidly decaying modes.\n\nC. For the non-stiff system $N$, under an adaptive embedded method of order $p$ with local error control, the asymptotic accepted step size scales as $h\\propto \\mathrm{rtol}^{1/(p+1)}$ when the solution varies on an $\\mathcal{O}(1)$ scale, which explains the sensitivity of $\\mathrm{R2}$ to changes in $\\mathrm{rtol}$.\n\nD. If both runs were repeated with an implicit $A$-stable (absolutely stable for the entire left half-plane) method of comparable order and the same tolerances, the stiff case would still exhibit a small-$h$ plateau for the same stability reason, so the presence of a plateau in $h(t)$ would not help diagnose stiffness.\n\nE. The presence of frequent step rejections alone conclusively proves stiffness, so the run with more rejections must be the stiff one regardless of other $h(t)$ features.", "solution": "To diagnose the solver's behavior, we must first identify the characteristics of each system.\n- System $S$, $y^{\\prime}(t)=-10^{4}\\,y(t)$, is **stiff**. Its time scale $\\tau = 1/\\lambda = 10^{-4}$ is extremely short compared to the integration interval. For an explicit method, the step size $h$ is severely constrained by the stability requirement $|h\\lambda| \\leq \\gamma$, where $\\gamma$ is a constant specific to the RK method (typically $\\gamma \\approx 5$ for an order 5 method). This implies $h \\lesssim 5/10^4 = 5 \\times 10^{-4}$. This small, constant step size limit is independent of the accuracy tolerance $\\mathrm{rtol}$. This behaviorâ€”a low, constant step-size plateau insensitive to toleranceâ€”perfectly matches Run $\\mathrm{R1}$.\n- System $N$, $y^{\\prime}(t)=-y(t)$, is **non-stiff**. Its time scale $\\tau = 1$ is of the same order as the integration interval. The stability limit is mild ($h \\lesssim 5$), so the step size is governed by the accuracy requirement. The adaptive algorithm adjusts $h$ to keep the local error below the tolerance, leading to a theoretical scaling of $h \\propto \\mathrm{rtol}^{1/(p+1)}$. Since the solution $y(t)=e^{-t}$ decays, accuracy becomes easier to achieve, and the solver can increase $h$ over time. This behaviorâ€”a growing step size that is sensitive to $\\mathrm{rtol}$â€”perfectly matches Run $\\mathrm{R2}$.\n\nBased on this analysis:\n- **A is correct.** Run $\\mathrm{R1}$ corresponds to the stiff system S, and its behavior is characteristic of a stability-limited integration.\n- **B is incorrect.** Run $\\mathrm{R2}$ corresponds to the non-stiff system N. Furthermore, explicit methods are hobbled by stiffness; they cannot take large steps on stiff problems.\n- **C is correct.** The sensitivity of Run R2's step size to the tolerance $\\mathrm{rtol}$ is explained by the fundamental scaling law for accuracy-limited adaptive methods.\n- **D is incorrect.** An A-stable implicit method has no stability restriction for this problem. When applied to the stiff system S, its step size would be limited only by accuracy and would grow very large after the initial transient, eliminating the plateau.\n- **E is incorrect.** Frequent step rejections can have multiple causes. The constant step-size plateau that is insensitive to $\\mathrm{rtol}$ is the key diagnostic signature of stiffness for an explicit solver.", "answer": "$$\\boxed{AC}$$", "id": "2372234"}]}