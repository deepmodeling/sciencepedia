{"hands_on_practices": [{"introduction": "The most direct way to understand perturbation analysis is to see it in action. This first exercise explores what happens to the solution of a linear system $A\\mathbf{x} = \\mathbf{b}$ when the matrix $A$ is slightly altered. By solving a nearly diagonal system, you will derive an exact formula for a component of the solution, revealing how it is composed of the original, unperturbed solution plus a distinct correction term proportional to the small change [@problem_id:2193581]. This practice provides a concrete, foundational insight into how errors or uncertainties in a system's model propagate to its output.", "problem": "Consider a system of three linear equations with three unknowns, written in matrix form as $A \\mathbf{x} = \\mathbf{b}$. Here, $\\mathbf{x} = (x_1, x_2, x_3)^T$ is the vector of unknowns and $\\mathbf{b} = (b_1, b_2, b_3)^T$ is a constant vector.\n\nThe matrix $A$ is a perturbation of a diagonal matrix. The diagonal entries of $A$ are $A_{11} = d_1$, $A_{22} = d_2$, and $A_{33} = d_3$, where $d_1, d_2, d_3$ are non-zero constants. A single off-diagonal element is non-zero: the element in the first row and second column is $A_{12} = \\epsilon$, where $\\epsilon$ is a small constant. All other off-diagonal elements of $A$ are zero.\n\nFind an exact expression for the component $x_1$ of the solution vector $\\mathbf{x}$. Express your answer in terms of the symbolic parameters $d_1, d_2, b_1, b_2$, and $\\epsilon$.", "solution": "The problem asks for the first component, $x_1$, of the solution vector $\\mathbf{x}$ for the linear system $A\\mathbf{x} = \\mathbf{b}$.\n\nFirst, let's explicitly write down the matrix $A$ based on the problem description. The matrix $A$ is a 3x3 matrix. Its diagonal entries are $A_{11}=d_1$, $A_{22}=d_2$, and $A_{33}=d_3$. The only non-zero off-diagonal entry is $A_{12}=\\epsilon$. All other off-diagonal entries are zero. Thus, the matrix $A$ is:\n$$\nA = \\begin{pmatrix} d_1  \\epsilon  0 \\\\ 0  d_2  0 \\\\ 0  0  d_3 \\end{pmatrix}\n$$\nThe system of linear equations $A\\mathbf{x} = \\mathbf{b}$ can be written out component-wise as:\n1.  $A_{11}x_1 + A_{12}x_2 + A_{13}x_3 = b_1 \\implies d_1 x_1 + \\epsilon x_2 + 0 \\cdot x_3 = b_1$\n2.  $A_{21}x_1 + A_{22}x_2 + A_{23}x_3 = b_2 \\implies 0 \\cdot x_1 + d_2 x_2 + 0 \\cdot x_3 = b_2$\n3.  $A_{31}x_1 + A_{32}x_2 + A_{33}x_3 = b_3 \\implies 0 \\cdot x_1 + 0 \\cdot x_2 + d_3 x_3 = b_3$\n\nThis simplifies to the following system of equations:\n$$\nd_1 x_1 + \\epsilon x_2 = b_1\n$$\n$$\nd_2 x_2 = b_2\n$$\n$$\nd_3 x_3 = b_3\n$$\nWe are asked to find an expression for $x_1$. To do this, we can solve this system. The matrix $A$ is upper triangular, which simplifies the process. We can solve for the variables starting from the last one, although in this case the equations for $x_2$ and $x_3$ are independent.\n\nFrom the second equation, since $d_2$ is non-zero, we can solve for $x_2$:\n$$\nx_2 = \\frac{b_2}{d_2}\n$$\nNow we can substitute this expression for $x_2$ into the first equation:\n$$\nd_1 x_1 + \\epsilon \\left( \\frac{b_2}{d_2} \\right) = b_1\n$$\nOur goal is to isolate $x_1$. We rearrange the equation to solve for the term containing $x_1$:\n$$\nd_1 x_1 = b_1 - \\frac{\\epsilon b_2}{d_2}\n$$\nFinally, since $d_1$ is non-zero, we can divide by $d_1$ to find the expression for $x_1$:\n$$\nx_1 = \\frac{1}{d_1} \\left( b_1 - \\frac{\\epsilon b_2}{d_2} \\right)\n$$\nDistributing the $1/d_1$ term gives the final answer:\n$$\nx_1 = \\frac{b_1}{d_1} - \\frac{\\epsilon b_2}{d_1 d_2}\n$$\nThis is the exact expression for the first component of the solution vector for the perturbed system. Notice that the solution consists of the original, unperturbed solution component ($b_1/d_1$) and a correction term that is proportional to the perturbation $\\epsilon$. The parameters $d_3$ and $b_3$ do not affect the value of $x_1$.", "answer": "$$\\boxed{\\frac{b_1}{d_1} - \\frac{\\epsilon b_2}{d_1 d_2}}$$", "id": "2193581"}, {"introduction": "Perturbations can affect more than just the solution vector; they can fundamentally alter a system's intrinsic properties as described by its eigenvalues. While small real perturbations to a symmetric matrix only cause small real shifts in its eigenvalues, the situation can be dramatically different for non-symmetric matrices. This exercise provides a striking example where an infinitesimally small change transforms a matrix's repeated real eigenvalue into a pair of complex conjugate eigenvalues [@problem_id:2193574]. This illustrates the delicate nature of eigenvalues in non-symmetric systems, a critical consideration in stability analysis across many scientific and engineering disciplines.", "problem": "Consider a $2 \\times 2$ matrix given by $M = \\begin{pmatrix} \\alpha  \\beta \\\\ 0  \\alpha \\end{pmatrix}$, where $\\alpha$ and $\\beta$ are positive real constants. This matrix is non-symmetric and has a repeated real eigenvalue. We introduce a small perturbation to the matrix, resulting in a new matrix $M_{\\delta} = \\begin{pmatrix} \\alpha  \\beta \\\\ -\\delta  \\alpha \\end{pmatrix}$, where $\\delta$ is a small positive real number.\n\nWhich of the following statements correctly describes the eigenvalues of the perturbed matrix $M_{\\delta}$?\n\nA. The eigenvalues remain real and equal to $\\alpha$.\n\nB. The eigenvalues are real and distinct, given by $\\alpha \\pm \\sqrt{\\beta\\delta}$.\n\nC. The eigenvalues form a complex conjugate pair.\n\nD. The eigenvalues are real, with one at $\\alpha$ and the other at $\\alpha - \\delta$.\n\nE. The eigenvalues are $\\alpha$ and $\\beta - \\delta$.", "solution": "We seek the eigenvalues of the perturbed matrix $M_{\\delta} = \\begin{pmatrix} \\alpha  \\beta \\\\ -\\delta  \\alpha \\end{pmatrix}$, with $\\alpha0$, $\\beta0$, and $\\delta0$. By definition, eigenvalues $\\lambda$ satisfy the characteristic equation\n$$\n\\det\\!\\left(M_{\\delta} - \\lambda I\\right) = 0.\n$$\nCompute the determinant explicitly:\n$$\nM_{\\delta} - \\lambda I = \\begin{pmatrix} \\alpha - \\lambda  \\beta \\\\ -\\delta  \\alpha - \\lambda \\end{pmatrix},\n$$\nso\n$$\n\\det\\!\\left(M_{\\delta} - \\lambda I\\right) = (\\alpha - \\lambda)(\\alpha - \\lambda) - (\\beta)(-\\delta) = (\\alpha - \\lambda)^{2} + \\beta\\delta.\n$$\nTherefore, the characteristic equation is\n$$\n(\\alpha - \\lambda)^{2} + \\beta\\delta = 0.\n$$\nRewriting, we obtain\n$$\n(\\lambda - \\alpha)^{2} = -\\,\\beta\\delta.\n$$\nSolving for $\\lambda$ gives\n$$\n\\lambda = \\alpha \\pm i\\sqrt{\\beta\\delta}.\n$$\nSince $\\beta0$ and $\\delta0$, we have $\\sqrt{\\beta\\delta}0$, and thus the two eigenvalues are nonreal and form a complex conjugate pair with real part $\\alpha$. This matches statement C. As a consistency check, the trace is $2\\alpha$ and the determinant is $\\alpha^{2} + \\beta\\delta$, which equal the sum and product of $\\alpha \\pm i\\sqrt{\\beta\\delta}$, respectively, confirming the result.", "answer": "$$\\boxed{C}$$", "id": "2193574"}, {"introduction": "After witnessing the potential effects of perturbations, we need a way to quantify a system's sensitivity. This is the role of the condition number, $\\kappa(A)$, a crucial concept often confused with the determinant. This practice directly confronts the common misconception that a matrix with $\\det(A) = 1$ must be well-behaved, or \"well-conditioned\" [@problem_id:2193556]. By calculating the condition number for a specific family of matrices, you will demonstrate how a system's sensitivity to perturbations can become arbitrarily large, even while its determinant remains constant. This reinforces the condition number as the true and indispensable measure of a linear system's stability.", "problem": "In numerical linear algebra, the condition number of a matrix is a crucial concept that quantifies the sensitivity of the solution of a linear system $Ax=b$ to perturbations in the input data $A$ or $b$. A matrix with a high condition number is called \"ill-conditioned,\" while one with a low condition number is \"well-conditioned.\" One might intuitively think that a matrix with a determinant close to zero is ill-conditioned, but this is not always true. Conversely, a matrix can be extremely ill-conditioned even if its determinant is exactly 1.\n\nTo explore this, consider the family of $2 \\times 2$ matrices $A_N$ defined for any real number $N  1$ as:\n$$\nA_N = \\begin{pmatrix} N  N-1 \\\\ N+1  N \\end{pmatrix}\n$$\nThe condition number of a matrix $A$ with respect to a given matrix norm can be calculated as $\\kappa(A) = \\|A\\| \\|A^{-1}\\|$. For this problem, we will use the matrix infinity-norm, denoted by $\\|A\\|_{\\infty}$, which is defined as the maximum of the absolute row sums of the matrix. That is, for an $m \\times n$ matrix $A$, $\\|A\\|_{\\infty} = \\max_{1 \\le i \\le m} \\sum_{j=1}^{n} |a_{ij}|$.\n\nDespite the fact that the determinant of $A_N$ is equal to 1 for all $N1$, the matrix becomes increasingly ill-conditioned as $N$ grows. Your task is to find a symbolic expression for the condition number $\\kappa_{\\infty}(A_N)$ in terms of $N$.", "solution": "We are asked to compute the condition number with respect to the infinity norm, defined by $\\kappa_{\\infty}(A) = \\|A\\|_{\\infty}\\,\\|A^{-1}\\|_{\\infty}$, where $\\|A\\|_{\\infty}$ is the maximum absolute row sum.\n\nGiven\n$$\nA_{N}=\\begin{pmatrix} N  N-1 \\\\ N+1  N \\end{pmatrix}, \\quad N1,\n$$\nfirst compute $\\|A_{N}\\|_{\\infty}$. Since $N1$, all entries are positive. The absolute row sums are\n$$\n\\text{row 1 sum} = |N| + |N-1| = N + (N-1) = 2N - 1,\n$$\n$$\n\\text{row 2 sum} = |N+1| + |N| = (N+1) + N = 2N + 1.\n$$\nHence\n$$\n\\|A_{N}\\|_{\\infty} = \\max\\{2N-1,\\,2N+1\\} = 2N + 1.\n$$\n\nNext compute $A_{N}^{-1}$. For a $2\\times 2$ matrix $A=\\begin{pmatrix} a  b \\\\ c  d \\end{pmatrix}$, the inverse is\n$$\nA^{-1}=\\frac{1}{ad-bc}\\begin{pmatrix} d  -b \\\\ -c  a \\end{pmatrix}.\n$$\nHere $a=N$, $b=N-1$, $c=N+1$, $d=N$, so\n$$\n\\det(A_{N})=ad-bc=N^{2}-(N-1)(N+1)=N^{2}-(N^{2}-1)=1,\n$$\nand thus\n$$\nA_{N}^{-1}=\\begin{pmatrix} N  -(N-1) \\\\ -(N+1)  N \\end{pmatrix}=\\begin{pmatrix} N  1-N \\\\ -(N+1)  N \\end{pmatrix}.\n$$\nCompute $\\|A_{N}^{-1}\\|_{\\infty}$ via absolute row sums:\n$$\n\\text{row 1 sum} = |N| + |1-N| = N + (N-1) = 2N - 1 \\quad \\text{since } N1,\n$$\n$$\n\\text{row 2 sum} = |-(N+1)| + |N| = (N+1) + N = 2N + 1.\n$$\nTherefore,\n$$\n\\|A_{N}^{-1}\\|_{\\infty} = \\max\\{2N-1,\\,2N+1\\} = 2N + 1.\n$$\n\nFinally, the condition number is\n$$\n\\kappa_{\\infty}(A_{N})=\\|A_{N}\\|_{\\infty}\\,\\|A_{N}^{-1}\\|_{\\infty}=(2N+1)(2N+1)=(2N+1)^{2}.\n$$\nThis grows quadratically with $N$, even though $\\det(A_{N})=1$ for all $N1$.", "answer": "$$\\boxed{(2N+1)^{2}}$$", "id": "2193556"}]}