{"hands_on_practices": [{"introduction": "The Cholesky factorization is a powerful tool in numerical linear algebra for decomposing a symmetric positive-definite matrix, $A$, into the product of a lower triangular matrix $L$ and its transpose $L^T$. This first exercise provides a direct opportunity to apply the factorization algorithm step-by-step to a small $2 \\times 2$ matrix drawn from a quantitative finance scenario. Mastering this core computation [@problem_id:2158812] is the foundational skill needed to unlock its applications in statistics, optimization, and simulation.", "problem": "In quantitative finance, the covariance matrix of asset returns is a fundamental tool for portfolio optimization and risk management. Consider a simplified portfolio consisting of two stocks. The daily returns of these stocks are modeled as random variables with a joint covariance matrix $A$. For this specific pair of stocks, the covariance matrix is given by:\n$$\nA = \\begin{pmatrix} 2 & 1 \\\\ 1 & 3 \\end{pmatrix}\n$$\nTo simulate correlated return scenarios using methods like Monte Carlo simulation, it is often necessary to find a matrix $L$ such that $A = LL^T$. This is known as the Cholesky factorization of $A$, where $L$ is a unique lower triangular matrix with strictly positive diagonal entries.\n\nYour task is to compute the Cholesky factor $L$ for the given covariance matrix $A$.", "solution": "We seek a lower triangular matrix $L$ with strictly positive diagonal entries such that $A=LL^{T}$, where\n$$\nA=\\begin{pmatrix}2 & 1 \\\\ 1 & 3\\end{pmatrix},\\quad L=\\begin{pmatrix} \\ell_{11} & 0 \\\\ \\ell_{21} & \\ell_{22} \\end{pmatrix}.\n$$\nCompute $LL^{T}$:\n$$\nLL^{T}=\\begin{pmatrix} \\ell_{11}^{2} & \\ell_{11}\\ell_{21} \\\\ \\ell_{21}\\ell_{11} & \\ell_{21}^{2}+\\ell_{22}^{2} \\end{pmatrix}.\n$$\nEquate entries with $A$:\n1) From the $(1,1)$ entry, $\\ell_{11}^{2}=2$, and with $\\ell_{11}>0$ we get $\\ell_{11}=\\sqrt{2}$.\n\n2) From the $(1,2)$ entry, $\\ell_{11}\\ell_{21}=1$, hence $\\ell_{21}=\\frac{1}{\\ell_{11}}=\\frac{1}{\\sqrt{2}}$.\n\n3) From the $(2,2)$ entry, $\\ell_{21}^{2}+\\ell_{22}^{2}=3$, so\n$$\n\\ell_{22}^{2}=3-\\left(\\frac{1}{\\sqrt{2}}\\right)^{2}=3-\\frac{1}{2}=\\frac{5}{2},\n$$\nand with $\\ell_{22}>0$ we obtain $\\ell_{22}=\\sqrt{\\frac{5}{2}}$.\n\nThus the Cholesky factor is\n$$\nL=\\begin{pmatrix} \\sqrt{2} & 0 \\\\ \\frac{1}{\\sqrt{2}} & \\sqrt{\\frac{5}{2}} \\end{pmatrix},\n$$\nwhich satisfies $LL^{T}=A$ and has strictly positive diagonal entries, ensuring uniqueness.", "answer": "$$\\boxed{\\begin{pmatrix}\\sqrt{2} & 0 \\\\ \\frac{1}{\\sqrt{2}} & \\sqrt{\\frac{5}{2}}\\end{pmatrix}}$$", "id": "2158812"}, {"introduction": "A key theoretical aspect of the Cholesky factorization is that it exists if and only if the matrix is symmetric and positive-definite. This practice problem [@problem_id:2158795] moves from theory to practice by asking you to perform the factorization on a matrix that does not meet these criteria. By working through the algorithm, you will identify the exact step where it fails, providing a clear and memorable demonstration of why positive-definiteness is not just an abstract requirement but a practical necessity.", "problem": "In numerical linear algebra, the Cholesky factorization is a decomposition of a Hermitian, positive-definite matrix into the product of a lower triangular matrix and its conjugate transpose. For a real symmetric matrix $A$, this decomposition takes the form $A = LL^T$, where $L$ is a real lower triangular matrix with positive diagonal entries. A matrix is positive-definite if and only if it has a unique Cholesky factorization.\n\nConsider the following symmetric matrix $A$:\n$$\nA = \\begin{pmatrix} 4 & 6 & 2 \\\\ 6 & 10 & 5 \\\\ 2 & 5 & 3 \\end{pmatrix}\n$$\nAttempt to compute the Cholesky factorization of $A$ in the form $A=LL^T$, where $L$ is a lower triangular matrix:\n$$\nL = \\begin{pmatrix} l_{11} & 0 & 0 \\\\ l_{21} & l_{22} & 0 \\\\ l_{31} & l_{32} & l_{33} \\end{pmatrix}\n$$\nIdentify the primary reason why the factorization procedure fails for this specific matrix.\n\nA. The algorithm fails at the first step because the element $a_{11}$ is not positive.\n\nB. The algorithm fails when computing the element $l_{22}$ because the expression under the square root, $a_{22} - l_{21}^2$, is negative.\n\nC. The algorithm fails when computing the element $l_{33}$ because the expression under the square root, $a_{33} - l_{31}^2 - l_{32}^2$, is negative.\n\nD. The algorithm fails because the matrix $A$ is not symmetric.\n\nE. The algorithm does not fail; a valid Cholesky factorization exists for this matrix.", "solution": "For a real symmetric matrix $A$, the Cholesky algorithm constructs a lower triangular $L$ with entries given recursively by\n$$\nl_{kk}=\\sqrt{a_{kk}-\\sum_{j=1}^{k-1} l_{kj}^{2}}, \\quad l_{ik}=\\frac{a_{ik}-\\sum_{j=1}^{k-1} l_{ij}l_{kj}}{l_{kk}} \\quad \\text{for } i>k.\n$$\nThis requires all square-root arguments to be positive.\n\nApply this to\n$$\nA=\\begin{pmatrix}4 & 6 & 2\\\\6 & 10 & 5\\\\2 & 5 & 3\\end{pmatrix}.\n$$\nStep $k=1$:\n$$\nl_{11}=\\sqrt{a_{11}}=\\sqrt{4}=2,\\quad l_{21}=\\frac{a_{21}}{l_{11}}=\\frac{6}{2}=3,\\quad l_{31}=\\frac{a_{31}}{l_{11}}=\\frac{2}{2}=1.\n$$\nStep $k=2$:\n$$\nl_{22}=\\sqrt{a_{22}-l_{21}^{2}}=\\sqrt{10-9}=\\sqrt{1}=1,\\quad l_{32}=\\frac{a_{32}-l_{31}l_{21}}{l_{22}}=\\frac{5-1\\cdot 3}{1}=2.\n$$\nStep $k=3$:\n$$\nl_{33}=\\sqrt{a_{33}-l_{31}^{2}-l_{32}^{2}}=\\sqrt{3-1-4}=\\sqrt{-2},\n$$\nwhich is not real because the expression under the square root is negative. Therefore, the Cholesky procedure fails precisely at the computation of $l_{33}$.\n\nThis failure reflects that $A$ is not positive definite; indeed, $\\det(A)=4(30-25)-6(18-10)+2(30-20)=20-48+20=-8<0$. Hence, the correct choice is that the algorithm fails at the $l_{33}$ step due to a negative radicand.", "answer": "$$\\boxed{C}$$", "id": "2158795"}, {"introduction": "Beyond the mechanics of the algorithm lies its primary purpose: simplifying complex problems. A principal application of Cholesky factorization is the efficient and numerically stable solution of linear systems $Ax=b$ where the matrix $A$ is symmetric and positive-definite. This exercise [@problem_id:2158813] demonstrates this process, showing how decomposing $A$ into $LL^T$ allows one to solve the system by tackling two much simpler triangular systems through forward and backward substitution.", "problem": "In many numerical optimization and data analysis problems, one must solve a linear system of equations of the form $Ax=b$, where the matrix $A$ is symmetric and positive-definite. A highly efficient and stable method for this task is to first compute the Cholesky factorization of $A$, which is a decomposition of the form $A = LL^T$, where $L$ is a lower triangular matrix with positive diagonal entries.\n\nSuppose that for a particular problem, the Cholesky factor $L$ and the vector $b$ are given by:\n$$L = \\begin{pmatrix} 2 & 0 & 0 \\\\ 1 & \\sqrt{5} & 0 \\\\ 3 & \\sqrt{5} & 2 \\end{pmatrix}, \\quad b = \\begin{pmatrix} 10 \\\\ 12 \\\\ 22 \\end{pmatrix}$$\nDetermine the components $(x_1, x_2, x_3)$ of the solution vector $x = \\begin{pmatrix} x_1 \\\\ x_2 \\\\ x_3 \\end{pmatrix}$ that satisfies the equation $Ax=b$.", "solution": "We are given a symmetric positive-definite system $Ax=b$ with a Cholesky factorization $A=LL^{T}$. The standard solution procedure is:\n1) Solve the lower-triangular system $L y = b$ by forward substitution.\n2) Solve the upper-triangular system $L^{T} x = y$ by back substitution.\n\nLet $y = \\begin{pmatrix} y_{1} \\\\ y_{2} \\\\ y_{3} \\end{pmatrix}$. From $L y = b$ with\n$$\nL = \\begin{pmatrix}\n2 & 0 & 0 \\\\\n1 & \\sqrt{5} & 0 \\\\\n3 & \\sqrt{5} & 2\n\\end{pmatrix},\n\\quad\nb = \\begin{pmatrix}\n10 \\\\ 12 \\\\ 22\n\\end{pmatrix},\n$$\nwe obtain the equations\n$$\n2 y_{1} = 10, \\quad y_{1} + \\sqrt{5}\\, y_{2} = 12, \\quad 3 y_{1} + \\sqrt{5}\\, y_{2} + 2 y_{3} = 22.\n$$\nSolving sequentially:\n$$\ny_{1} = 5,\n$$\n$$\n\\sqrt{5}\\, y_{2} = 12 - y_{1} = 7 \\;\\Rightarrow\\; y_{2} = \\frac{7}{\\sqrt{5}},\n$$\n$$\n\\sqrt{5}\\, y_{2} + 2 y_{3} = 22 - 3 y_{1} = 7 \\;\\Rightarrow\\; 7 + 2 y_{3} = 7 \\;\\Rightarrow\\; y_{3} = 0.\n$$\nThus $y = \\begin{pmatrix} 5 \\\\ \\frac{7}{\\sqrt{5}} \\\\ 0 \\end{pmatrix}$.\n\nNext solve $L^{T} x = y$, where\n$$\nL^{T} = \\begin{pmatrix}\n2 & 1 & 3 \\\\\n0 & \\sqrt{5} & \\sqrt{5} \\\\\n0 & 0 & 2\n\\end{pmatrix}, \\quad x = \\begin{pmatrix} x_{1} \\\\ x_{2} \\\\ x_{3} \\end{pmatrix}.\n$$\nBack substitution gives\n$$\n2 x_{3} = y_{3} = 0 \\;\\Rightarrow\\; x_{3} = 0,\n$$\n$$\n\\sqrt{5}\\, x_{2} + \\sqrt{5}\\, x_{3} = y_{2} = \\frac{7}{\\sqrt{5}} \\;\\Rightarrow\\; \\sqrt{5}\\, x_{2} = \\frac{7}{\\sqrt{5}} \\;\\Rightarrow\\; x_{2} = \\frac{7}{5},\n$$\n$$\n2 x_{1} + x_{2} + 3 x_{3} = y_{1} = 5 \\;\\Rightarrow\\; 2 x_{1} + \\frac{7}{5} = 5 \\;\\Rightarrow\\; 2 x_{1} = \\frac{18}{5} \\;\\Rightarrow\\; x_{1} = \\frac{9}{5}.\n$$\nTherefore, the solution vector is $x = \\begin{pmatrix} \\frac{9}{5} \\\\ \\frac{7}{5} \\\\ 0 \\end{pmatrix}$, and the requested components are $\\left(x_{1}, x_{2}, x_{3}\\right) = \\left(\\frac{9}{5}, \\frac{7}{5}, 0\\right)$.", "answer": "$$\\boxed{\\begin{pmatrix} \\frac{9}{5} \\\\ \\frac{7}{5} \\\\ 0 \\end{pmatrix}}$$", "id": "2158813"}]}