{"hands_on_practices": [{"introduction": "One of the most common sources of modeling error is the simplification of governing equations to make them more tractable. This exercise explores the classic small-angle approximation for a simple pendulum, where the nonlinear term $ \\sin(\\theta) $ is replaced by $ \\theta $ to yield a linear model. By deriving the period for both the exact nonlinear system and the simplified linear one, you will directly quantify how this modeling error depends on the initial amplitude of the swing. This practice provides a concrete and intuitive introduction to the trade-offs between model fidelity and analytical simplicity [@problem_id:3252538].", "problem": "You will implement and analyze the modeling error introduced by the small-angle approximation for the planar simple pendulum. The exact nonlinear equation of motion for the angular displacement is the second-order Ordinary Differential Equation (ODE) $ \\ddot{\\theta}(t) + \\frac{g}{L} \\sin(\\theta(t)) = 0 $, where $ \\theta(t) $ is the angle from the vertical, $ g $ is the gravitational acceleration, and $ L $ is the pendulum length. Under the small-angle approximation, the model replaces $ \\sin(\\theta) $ with $ \\theta $, producing a linear ODE. For an initial amplitude $ \\theta_0 $ with initial angular velocity $ \\dot{\\theta}(0) = 0 $, define the period $ T $ as the time taken to complete one full oscillation.\n\nYour tasks:\n1. Starting from conservation of mechanical energy and the exact nonlinear ODE, derive a correct integral expression for the exact period $ T_{\\text{exact}}(\\theta_0; L, g) $ in terms of $ \\theta_0 $, $ L $, and $ g $, without assuming $ \\sin(\\theta) \\approx \\theta $. Your derivation should begin from the total energy $ E = \\frac{1}{2} m L^2 \\dot{\\theta}^2 + m g L (1 - \\cos \\theta) $ and the initial conditions $ \\theta(0) = \\theta_0 $, $ \\dot{\\theta}(0) = 0 $, where $ m $ is the mass.\n2. For the small-angle model, use the linearized ODE to obtain the model period $ T_{\\text{lin}}(L, g) $.\n3. Define the modeling error as the relative difference $ \\varepsilon(\\theta_0) = \\frac{T_{\\text{lin}} - T_{\\text{exact}}}{T_{\\text{exact}}} $ expressed as a decimal (not a percentage).\n4. Implement a program that:\n   - Computes $ T_{\\text{exact}} $ from your energy-based integral by numerically evaluating it with high accuracy for any $ \\theta_0 \\in [0, \\pi) $.\n   - Computes $ T_{\\text{lin}} $ from the linearized model.\n   - Returns $ \\varepsilon(\\theta_0) $ for each test value below, rounded to $ 12 $ decimal places.\n5. Use $ g = $ $ 9.80665 $ $ \\text{m/s}^2 $ and $ L = $ $ 1.0 $ $ \\text{m} $. Angles $ \\theta_0 $ are in radians. Periods must be in $ \\text{s} $ (seconds).\n\nTest suite:\n- $ \\theta_0 = $ $ 0.0 $\n- $ \\theta_0 = $ $ 10^{-6} $\n- $ \\theta_0 = $ $ 0.5 $\n- $ \\theta_0 = $ $ 1.0 $\n- $ \\theta_0 = $ $ 2.0 $\n- $ \\theta_0 = $ $ 3.0 $\n\nFinal output format:\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, with each entry equal to $ \\varepsilon(\\theta_0) $ for the corresponding test case, each rounded to $ 12 $ decimal places. For example: $ [x_1,x_2,x_3,x_4,x_5,x_6] $ where each $ x_i $ is a decimal number with exactly $ 12 $ digits after the decimal point.", "solution": "The user-provided problem is assessed as valid. It is scientifically grounded in classical mechanics, well-posed with all necessary information provided, and objective in its formulation. The task is to analyze the modeling error of the small-angle approximation for a simple pendulum by deriving and comparing the periods from the exact nonlinear model and the approximated linear model.\n\nThe solution proceeds in three stages:\n1.  Derivation of the analytical expressions for the exact period $T_{\\text{exact}}$ and the linearized period $T_{\\text{lin}}$.\n2.  Formulation of the relative modeling error $\\varepsilon(\\theta_0)$.\n3.  Numerical implementation to compute $\\varepsilon(\\theta_0)$ for specified initial amplitudes.\n\n### 1. Derivation of the Exact Period $T_{\\text{exact}}$\n\nThe motion of the pendulum is governed by the conservation of mechanical energy. The total energy $E$ is given by the sum of kinetic and potential energy:\n$$\nE = \\frac{1}{2} m L^2 \\dot{\\theta}^2 + m g L (1 - \\cos \\theta)\n$$\nwhere $m$ is the mass, $L$ is the length, $g$ is the acceleration due to gravity, $\\theta$ is the angular displacement, and $\\dot{\\theta}$ is the angular velocity.\n\nThe initial conditions are $\\theta(0) = \\theta_0$ (initial amplitude) and $\\dot{\\theta}(0) = 0$. The total energy $E$ is conserved and can be evaluated at $t=0$:\n$$\nE = \\frac{1}{2} m L^2 (0)^2 + m g L (1 - \\cos \\theta_0) = m g L (1 - \\cos \\theta_0)\n$$\nEquating the general energy expression to this constant value, we have:\n$$\n\\frac{1}{2} m L^2 \\dot{\\theta}^2 + m g L (1 - \\cos \\theta) = m g L (1 - \\cos \\theta_0)\n$$\nSolving for $\\dot{\\theta}^2$:\n$$\n\\frac{1}{2} L^2 \\dot{\\theta}^2 = g L ((1 - \\cos \\theta_0) - (1 - \\cos \\theta)) = g L (\\cos \\theta - \\cos \\theta_0)\n$$\n$$\n\\dot{\\theta}^2 = \\left(\\frac{d\\theta}{dt}\\right)^2 = \\frac{2g}{L} (\\cos \\theta - \\cos \\theta_0)\n$$\nTaking the square root, we get the angular velocity:\n$$\n\\frac{d\\theta}{dt} = \\pm \\sqrt{\\frac{2g}{L} (\\cos \\theta - \\cos \\theta_0)}\n$$\nThe period $T_{\\text{exact}}$ is four times the time it takes for the pendulum to swing from its maximum displacement $\\theta_0$ to the vertical position $\\theta=0$. During this first quarter period, $\\theta$ is decreasing, so we take the negative root for $\\frac{d\\theta}{dt}$:\n$$\ndt = -\\frac{d\\theta}{\\sqrt{\\frac{2g}{L} (\\cos \\theta - \\cos \\theta_0)}}\n$$\nIntegrating from $t=0$ to $t=T_{\\text{exact}}/4$ as $\\theta$ goes from $\\theta_0$ to $0$:\n$$\n\\frac{T_{\\text{exact}}}{4} = \\int_{\\theta_0}^{0} -\\sqrt{\\frac{L}{2g}} \\frac{d\\theta}{\\sqrt{\\cos \\theta - \\cos \\theta_0}} = \\sqrt{\\frac{L}{2g}} \\int_{0}^{\\theta_0} \\frac{d\\theta}{\\sqrt{\\cos \\theta - \\cos \\theta_0}}\n$$\nThis integral is improper at $\\theta = \\theta_0$. To obtain a form suitable for numerical evaluation, we perform a series of substitutions. First, using the half-angle identity $\\cos x = 1 - 2\\sin^2(x/2)$:\n$$\n\\cos \\theta - \\cos \\theta_0 = (1 - 2\\sin^2(\\theta/2)) - (1 - 2\\sin^2(\\theta_0/2)) = 2(\\sin^2(\\theta_0/2) - \\sin^2(\\theta/2))\n$$\nSubstituting this into the integral for the period:\n$$\nT_{\\text{exact}} = 4 \\sqrt{\\frac{L}{2g}} \\int_{0}^{\\theta_0} \\frac{d\\theta}{\\sqrt{2(\\sin^2(\\theta_0/2) - \\sin^2(\\theta/2))}} = 2\\sqrt{\\frac{L}{g}} \\int_{0}^{\\theta_0} \\frac{d\\theta}{\\sqrt{\\sin^2(\\theta_0/2) - \\sin^2(\\theta/2)}}\n$$\nNow, we introduce a new variable $\\phi$ defined by the relation $\\sin(\\theta/2) = \\sin(\\phi) \\sin(\\theta_0/2)$. Let $k = \\sin(\\theta_0/2)$. The relation is $\\sin(\\theta/2) = k \\sin(\\phi)$.\nDifferentiating gives $\\frac{1}{2}\\cos(\\theta/2) d\\theta = k\\cos(\\phi)d\\phi$.\nThe differential $d\\theta$ is thus $d\\theta = \\frac{2k\\cos(\\phi)}{\\cos(\\theta/2)}d\\phi = \\frac{2k\\cos(\\phi)}{\\sqrt{1 - k^2\\sin^2(\\phi)}}d\\phi$.\nThe limits of integration change: when $\\theta=0$, $\\sin(\\phi)=0 \\implies \\phi=0$; when $\\theta=\\theta_0$, $\\sin(\\theta_0/2) = k\\sin(\\phi) \\implies k = k\\sin(\\phi) \\implies \\sin(\\phi)=1 \\implies \\phi=\\pi/2$.\nSubstituting these into the expression for $T_{\\text{exact}}$:\n$$\nT_{\\text{exact}} = 2\\sqrt{\\frac{L}{g}} \\int_0^{\\pi/2} \\frac{1}{\\sqrt{k^2 - k^2\\sin^2(\\phi)}} \\cdot \\frac{2k\\cos(\\phi)}{\\sqrt{1 - k^2\\sin^2(\\phi)}}d\\phi\n$$\n$$\nT_{\\text{exact}} = 2\\sqrt{\\frac{L}{g}} \\int_0^{\\pi/2} \\frac{1}{k\\cos(\\phi)} \\cdot \\frac{2k\\cos(\\phi)}{\\sqrt{1 - k^2\\sin^2(\\phi)}}d\\phi = 4\\sqrt{\\frac{L}{g}} \\int_0^{\\pi/2} \\frac{d\\phi}{\\sqrt{1 - k^2\\sin^2(\\phi)}}\n$$\nwhere $k = \\sin(\\theta_0/2)$. The integral is the complete elliptic integral of the first kind, $K(k)$.\n\n### 2. Derivation of the Linearized Period $T_{\\text{lin}}$\n\nThe small-angle approximation replaces $\\sin(\\theta)$ with $\\theta$ in the original equation of motion, $ \\ddot{\\theta} + \\frac{g}{L} \\sin(\\theta) = 0 $, yielding the linear ODE:\n$$\n\\ddot{\\theta}(t) + \\frac{g}{L} \\theta(t) = 0\n$$\nThis is the equation for a simple harmonic oscillator, $\\ddot{x} + \\omega^2 x = 0$, with angular frequency $\\omega = \\sqrt{g/L}$. The period $T$ is related to $\\omega$ by $T = 2\\pi/\\omega$. Therefore, the period for the linearized model is:\n$$\nT_{\\text{lin}} = 2\\pi \\sqrt{\\frac{L}{g}}\n$$\nThis period is independent of the initial amplitude $\\theta_0$.\n\n### 3. Modeling Error and Numerical Implementation\n\nThe modeling error is defined as the relative difference:\n$$\n\\varepsilon(\\theta_0) = \\frac{T_{\\text{lin}} - T_{\\text{exact}}}{T_{\\text{exact}}} = \\frac{2\\pi \\sqrt{L/g}}{4\\sqrt{L/g} K(\\sin(\\theta_0/2))} - 1 = \\frac{\\pi}{2K(\\sin(\\theta_0/2))} - 1\n$$\nFor the special case $\\theta_0 = 0$, $k=\\sin(0)=0$, and $K(0) = \\int_0^{\\pi/2} 1 d\\phi = \\pi/2$. Thus, $T_{\\text{exact}}(0) = 4\\sqrt{L/g}(\\pi/2) = T_{\\text{lin}}$, which means $\\varepsilon(0) = 0$.\n\nThe integral $K(k)$ does not have a closed-form solution in terms of elementary functions and must be computed numerically. We use Simpson's rule, a highly accurate method for numerical quadrature. For a function $f(x)$ over an interval $[a, b]$ divided into $N$ even subintervals of width $h=(b-a)/N$, the integral is approximated by:\n$$\n\\int_a^b f(x) dx \\approx \\frac{h}{3} \\left[ f(x_0) + 4\\sum_{i=1,3,...}^{N-1} f(x_i) + 2\\sum_{i=2,4,...}^{N-2} f(x_i) + f(x_N) \\right]\n$$\nA large number of intervals, $N$, is used to ensure the precision required for the final answer. The constants are given as $g = 9.80665 \\, \\text{m/s}^2$ and $L = 1.0 \\, \\text{m}$. The program will implement these formulas to calculate $\\varepsilon(\\theta_0)$ for each test value.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Calculates the modeling error for the small-angle approximation of a simple pendulum.\n    \"\"\"\n    # Define constants from the problem statement.\n    G = 9.80665  # Gravitational acceleration in m/s^2\n    L = 1.0      # Pendulum length in m\n\n    def simpson_rule(f, a, b, n):\n        \"\"\"\n        Numerically integrate a function f from a to b using Simpson's rule with n intervals.\n        \n        Args:\n            f: The function to integrate.\n            a: The lower limit of integration.\n            b: The upper limit of integration.\n            n: The number of intervals (must be even).\n        \n        Returns:\n            The approximate value of the integral.\n        \"\"\"\n        if n % 2 != 0:\n            raise ValueError(\"Number of intervals (n) must be even.\")\n        \n        h = (b - a) / n\n        x = np.linspace(a, b, n + 1)\n        y = f(x)\n        \n        # Simpson's rule formula: h/3 * (y_0 + 4y_1 + 2y_2 + ... + 4y_{n-1} + y_n)\n        integral = (h / 3.0) * (y[0] + y[-1] + 4.0 * np.sum(y[1:-1:2]) + 2.0 * np.sum(y[2:-2:2]))\n        return integral\n\n    def calculate_modeling_error(theta0, g, l):\n        \"\"\"\n        Computes the relative modeling error (T_lin - T_exact) / T_exact.\n        \n        Args:\n            theta0: The initial amplitude in radians.\n            g: Gravitational acceleration.\n            l: Pendulum length.\n\n        Returns:\n            The relative modeling error.\n        \"\"\"\n        # Calculate the period from the linearized model\n        T_lin = 2.0 * np.pi * np.sqrt(l / g)\n\n        # Handle the trivial case where the pendulum does not oscillate\n        if theta0 == 0.0:\n            return 0.0\n\n        # Number of intervals for Simpson's rule. A large number is chosen to ensure\n        # high accuracy (12 decimal places), especially for theta0 close to pi.\n        n_intervals = 2 * 10**7\n\n        # Calculate the exact period using the elliptic integral form\n        k = np.sin(theta0 / 2.0)\n        \n        # Define the integrand for the complete elliptic integral of the first kind, K(k)\n        def integrand(phi):\n            return 1.0 / np.sqrt(1.0 - k**2 * np.sin(phi)**2)\n\n        # Evaluate the integral K(k) from 0 to pi/2\n        integral_val = simpson_rule(integrand, 0.0, np.pi / 2.0, n_intervals)\n        \n        T_exact = 4.0 * np.sqrt(l / g) * integral_val\n        \n        # Calculate the relative modeling error\n        error = (T_lin - T_exact) / T_exact\n        \n        return error\n\n    # Define the test cases from the problem statement.\n    test_cases = [0.0, 1e-6, 0.5, 1.0, 2.0, 3.0]\n\n    results = []\n    for theta_0 in test_cases:\n        error_value = calculate_modeling_error(theta_0, G, L)\n        # Format the result to 12 decimal places as required.\n        # The f-string formatting handles rounding automatically.\n        results.append(f\"{error_value:.12f}\")\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(results)}]\")\n\nsolve()\n```", "id": "3252538"}, {"introduction": "Complex systems in science and engineering are often described by models with thousands or even millions of variables, making simulation computationally prohibitive. This exercise introduces you to model order reduction, a powerful technique to create simpler, faster \"surrogate\" models by projecting the dynamics onto a low-dimensional subspace. You will use Proper Orthogonal Decomposition (POD) to systematically construct a reduced-order model and quantify the modeling error by measuring the prediction accuracy against the original full-order system. This practice demonstrates how the error is directly linked to the \"energy\" discarded during the model reduction process, offering a quantitative approach to managing model complexity [@problem_id:3252598].", "problem": "Consider the linear time-invariant ordinary differential equation $u_t = A u + g$ with constant matrix $A \\in \\mathbb{R}^{n \\times n}$ and constant vector $g \\in \\mathbb{R}^n$. The state is $u(t) \\in \\mathbb{R}^n$ for time $t \\geq 0$. The analytic solution is defined by the fundamental solution operator and the principle of superposition, namely $u(t) = e^{A t} u(0) + \\int_{0}^{t} e^{A (t - s)} g \\, ds$. Let the Proper Orthogonal Decomposition (POD) be constructed from a snapshot matrix $X \\in \\mathbb{R}^{n \\times m}$ whose columns are the states $u(t_k)$ at a chosen set of times $t_k$, and let the POD basis of rank $r$ be obtained by orthogonal projection onto the subspace spanned by the first $r$ left singular vectors of $X$. The projection error of the snapshot matrix is tied to the singular values of $X$ through the Euclidean norm of the residual. The reduced-order model is obtained by Galerkin projection of the dynamics onto the POD subspace, which induces a model reduction error in predicting the state at a given time.\n\nYour task is to rigorously quantify and compute both the neglected snapshot energy and the prediction error at a final time using the following concrete, fully specified instance:\n\n- Dimension $n = 4$.\n- Matrix $A = \\operatorname{diag}(-1.0,\\,-0.6,\\,-2.5,\\,-0.2)$, meaning $A$ is the diagonal matrix with diagonal entries $-1.0$, $-0.6$, $-2.5$, and $-0.2$.\n- Constant vector $g = [\\,0.2,\\;1.0,\\;-0.5,\\;0.1\\,]^\\top$.\n- Initial condition $u(0) = [\\,1.0,\\;0.0,\\;0.5,\\;-1.0\\,]^\\top$.\n- Snapshot times $t_k \\in \\{\\,0.0,\\;0.5,\\;1.0,\\;1.5,\\;2.0\\,\\}$, with final time $T = 2.0$.\n- The snapshot matrix $X$ is formed with columns $u(t_k)$ for the listed times.\n- The POD basis is constructed from the singular value decomposition of $X$, using the first $r$ left singular vectors for the rank-$r$ basis.\n\nStarting from these definitions and without relying on unproven shortcut formulas, proceed as follows for each specified rank $r$:\n\n1. Compute the Singular Value Decomposition of $X$ to obtain the singular values and the corresponding POD basis of rank $r$.\n2. Compute the neglected snapshot energy associated with truncating at rank $r$. Use the Singular Value Decomposition definition of energy in the snapshot matrix to express this quantity precisely in terms of the singular values and then evaluate it numerically for this instance.\n3. Construct the Galerkin reduced-order model by projecting the dynamics $u_t = A u + g$ onto the rank-$r$ POD subspace. Predict the state at time $T$ by solving the reduced-order model with the projected initial condition.\n4. Compute the absolute prediction error at time $T$ as the Euclidean norm of the difference between the full-order solution $u(T)$ and the lifted reduced-order solution $u_r(T)$ in $\\mathbb{R}^n$.\n5. Compute the relative prediction error at time $T$ as the absolute error divided by the Euclidean norm of $u(T)$, expressed as a decimal.\n\nNo physical units are required in this problem; all quantities are dimensionless. All angles, if any were present, would be in radians, but angles do not appear here. The snapshot energy fraction should be reported as a decimal, not as a percentage.\n\nTest suite and ranks to evaluate:\n- Case $1$: $r = 0$.\n- Case $2$: $r = 1$.\n- Case $3$: $r = 2$.\n- Case $4$: $r = 4$.\n\nFor each case, produce a list of four values $[\\,E_{\\text{tail}},\\;f_{\\text{capture}},\\;e_{\\text{abs}},\\;e_{\\text{rel}}\\,]$, where $E_{\\text{tail}}$ is the neglected snapshot energy, $f_{\\text{capture}}$ is the captured energy fraction of the snapshot matrix expressed as a decimal, $e_{\\text{abs}}$ is the absolute prediction error at time $T$, and $e_{\\text{rel}}$ is the relative prediction error at time $T$.\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets with one sublist per case in the order of the test suite. For example, the output format must be exactly $[\\,[\\cdot,\\cdot,\\cdot,\\cdot],\\,[\\cdot,\\cdot,\\cdot,\\cdot],\\,[\\cdot,\\cdot,\\cdot,\\cdot],\\,[\\cdot,\\cdot,\\cdot,\\cdot]\\,]$, with decimals where appropriate and no additional text.", "solution": "The task is to perform model order reduction on a given linear time-invariant (LTI) ordinary differential equation (ODE) using Proper Orthogonal Decomposition (POD) and Galerkin projection. We must compute metrics that quantify the quality of the reduced-order model (ROM) for different ranks $r$. The process involves solving the full-order model (FOM), constructing the POD basis, deriving and solving the ROM, and finally calculating the specified error and energy metrics.\n\n### 1. Full-Order Model (FOM) Solution\nThe governing dynamics are described by the LTI system:\n$$u_t = A u + g$$\nwhere $u(t) \\in \\mathbb{R}^n$, $A \\in \\mathbb{R}^{n \\times n}$, and $g \\in \\mathbb{R}^n$. The specific parameters are:\n-   Dimension: $n = 4$.\n-   Matrix: $A = \\operatorname{diag}(\\lambda_1, \\lambda_2, \\lambda_3, \\lambda_4) = \\operatorname{diag}(-1.0, -0.6, -2.5, -0.2)$.\n-   Constant vector: $g = [0.2, 1.0, -0.5, 0.1]^\\top$.\n-   Initial condition: $u(0) = [1.0, 0.0, 0.5, -1.0]^\\top$.\n\nSince the matrix $A$ is diagonal, the system of $n$ coupled ODEs decouples into $n$ independent scalar ODEs for each component $u_i(t)$ of the state vector $u(t)$:\n$$(u_i)_t = \\lambda_i u_i(t) + g_i, \\quad \\text{with initial condition } u_i(0)$$\nThis is a standard first-order linear ODE whose analytical solution is given by the variation of parameters formula:\n$$u_i(t) = e^{\\lambda_i t} u_i(0) + \\int_{0}^{t} e^{\\lambda_i(t - s)} g_i \\, ds$$\nSince $\\lambda_i$ and $g_i$ are constants, the integral can be computed directly:\n$$\\int_{0}^{t} e^{\\lambda_i(t - s)} g_i \\, ds = g_i e^{\\lambda_i t} \\left[-\\frac{e^{-\\lambda_i s}}{\\lambda_i}\\right]_0^t = \\frac{g_i}{\\lambda_i} (e^{\\lambda_i t} - 1)$$\nThus, the analytical solution for each component is:\n$$u_i(t) = e^{\\lambda_i t} u_i(0) + \\frac{g_i}{\\lambda_i}(e^{\\lambda_i t} - 1) = \\left(u_i(0) + \\frac{g_i}{\\lambda_i}\\right)e^{\\lambda_i t} - \\frac{g_i}{\\lambda_i}$$\nThis formula provides the exact \"ground truth\" solution for the FOM at any time $t \\geq 0$.\n\n### 2. Snapshot Matrix and Proper Orthogonal Decomposition (POD)\nPOD is a data-driven technique for finding an optimal low-dimensional basis for a given dataset. The dataset, or \"snapshots,\" consists of solutions to the FOM at selected time instances.\n-   Snapshot times: $t_k \\in \\{0.0, 0.5, 1.0, 1.5, 2.0\\}$.\n-   Number of snapshots: $m = 5$.\n-   Snapshot matrix: $X = [u(t_0), u(t_1), \\dots, u(t_{m-1})] \\in \\mathbb{R}^{n \\times m}$.\n\nThe POD basis is found by computing the Singular Value Decomposition (SVD) of the snapshot matrix $X$:\n$$X = U \\Sigma V^\\top$$\n-   $U \\in \\mathbb{R}^{n \\times n}$ is an orthogonal matrix whose columns $v_i$ are the left-singular vectors, also known as the POD modes or basis vectors.\n-   $\\Sigma \\in \\mathbb{R}^{n \\times m}$ is a rectangular diagonal matrix containing the singular values $\\sigma_1 \\ge \\sigma_2 \\ge \\dots \\ge \\sigma_{\\min(n,m)} \\ge 0$.\n-   $V \\in \\mathbb{R}^{m \\times m}$ is an orthogonal matrix whose columns are the right-singular vectors.\n\nThe POD basis of rank $r$ is the matrix $U_r = [v_1, \\dots, v_r] \\in \\mathbb{R}^{n \\times r}$, which consists of the first $r$ POD modes. By the Eckart-Young-Mirsky theorem, this basis is optimal in the sense that it minimizes the projection error of the snapshots onto any rank-$r$ subspace.\n\n### 3. Snapshot Energy Analysis\nThe singular values quantify the contribution of each POD mode to the representation of the snapshot data. The \"energy\" of the snapshots is defined as the square of the Frobenius norm of $X$, which is equal to the sum of the squared singular values:\n$$E_{\\text{total}} = \\|X\\|_F^2 = \\sum_{i=1}^{\\min(n,m)} \\sigma_i^2$$\nWhen we truncate the basis to rank $r$, we retain the energy associated with the first $r$ modes and discard the rest.\n-   The captured energy is $E_{\\text{capture}} = \\sum_{i=1}^{r} \\sigma_i^2$.\n-   The **neglected snapshot energy**, or tail energy, is $E_{\\text{tail}} = \\sum_{i=r+1}^{\\min(n,m)} \\sigma_i^2$.\n-   The **captured energy fraction** is $f_{\\text{capture}} = \\frac{E_{\\text{capture}}}{E_{\\text{total}}}$.\n\n### 4. Galerkin Projection and Reduced-Order Model (ROM)\nThe core idea of model reduction is to seek an approximate solution that lies within the low-dimensional subspace spanned by the POD basis:\n$$u(t) \\approx u_r(t) = U_r \\tilde{u}(t)$$\nwhere $\\tilde{u}(t) \\in \\mathbb{R}^r$ is the vector of reduced coordinates. Substituting this ansatz into the FOM yields a residual:\n$$R(t) = U_r \\tilde{u}_t - (A U_r \\tilde{u} + g)$$\nGalerkin projection enforces this residual to be orthogonal to the basis vectors, i.e., $U_r^\\top R(t) = 0$.\n$$U_r^\\top (U_r \\tilde{u}_t - A U_r \\tilde{u} - g) = 0$$\nUsing the orthonormality of the POD basis ($U_r^\\top U_r = I_r$, the $r \\times r$ identity matrix), we obtain the ROM:\n$$\\tilde{u}_t = A_r \\tilde{u} + g_r$$\nwhere the reduced system matrix and vector are:\n-   $A_r = U_r^\\top A U_r \\in \\mathbb{R}^{r \\times r}$\n-   $g_r = U_r^\\top g \\in \\mathbb{R}^r$\n\nThe initial condition for the ROM is the projection of the FOM initial condition onto the POD subspace:\n$$\\tilde{u}(0) = U_r^\\top u(0)$$\n\n### 5. ROM Solution and Error Calculation\nThe ROM is itself an LTI system. Its formal solution is given by:\n$$\\tilde{u}(t) = e^{A_r t} \\tilde{u}(0) + \\int_{0}^{t} e^{A_r(t-s)} g_r \\, ds$$\nThe integral term can be computed as $A_r^{-1}(e^{A_r t} - I_r) g_r$, provided that $A_r$ is invertible. Since $A$ is symmetric and negative-definite, and $U_r$ has orthonormal columns, $A_r = U_r^\\top A U_r$ is also symmetric and negative-definite, and thus invertible. The matrix exponential $e^{A_r t}$ is computed by diagonalizing $A_r$. Since $A_r$ is symmetric, it is always diagonalizable: $A_r = P D P^{-1}$. Then $e^{A_r t} = P e^{D t} P^{-1}$.\n\nAfter solving for the reduced state $\\tilde{u}(T)$ at the final time $T=2.0$, we \"lift\" it back to the original $n$-dimensional space to get the ROM's prediction:\n$$u_r(T) = U_r \\tilde{u}(T)$$\nThe error of this prediction is quantified by:\n-   **Absolute prediction error**: $e_{\\text{abs}} = \\|u(T) - u_r(T)\\|_2$, where $u(T)$ is the true FOM solution.\n-   **Relative prediction error**: $e_{\\text{rel}} = \\frac{e_{\\text{abs}}}{\\|u(T)\\|_2}$.\n\n### 6. Analysis of Special Cases\n-   **Case $r=0$**: The basis is empty. The reduced space is $\\{0\\}$, so the projection of any vector is the zero vector (of dimension 0). The lifted solution is permanently the zero vector in $\\mathbb{R}^n$, i.e., $u_0(t) = 0$. The neglected energy is the total energy, and the captured fraction is $0$. The absolute prediction error is simply the norm of the true solution $\\|u(T)\\|_2$.\n-   **Case $r=n=4$**: The POD basis $U_4$ is a full orthonormal basis for $\\mathbb{R}^4$. The projection is an isometry. The ROM is mathematically equivalent to the FOM expressed in a different coordinate system. Consequently, $u_4(t) = u(t)$ for all $t$, and the prediction error must be zero (up to floating-point precision). This serves as a vital sanity check for the implementation. The neglected energy is zero, and the captured fraction is $1$.", "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the POD model reduction problem.\n    \"\"\"\n    # Problem definition\n    n = 4\n    A_diag = np.array([-1.0, -0.6, -2.5, -0.2])\n    A = np.diag(A_diag)\n    g = np.array([0.2, 1.0, -0.5, 0.1])\n    u0 = np.array([1.0, 0.0, 0.5, -1.0])\n    snapshot_times = np.array([0.0, 0.5, 1.0, 1.5, 2.0])\n    T_final = 2.0\n    ranks = [0, 1, 2, 4]\n\n    def fom_solution(t):\n        \"\"\"\n        Computes the analytical solution of the full-order model u_t = Au + g.\n        \"\"\"\n        # Element-wise solution: u_i(t) = (u0_i + g_i/lambda_i) * exp(lambda_i*t) - g_i/lambda_i\n        # Handle lambda_i = 0 case, though not present here.\n        u_t = np.zeros(n)\n        for i in range(n):\n            if np.abs(A_diag[i])  1e-15: # Unlikely given the problem, but for robustness\n                 u_t[i] = u0[i] + g[i] * t\n            else:\n                 u_t[i] = (u0[i] + g[i] / A_diag[i]) * np.exp(A_diag[i] * t) - g[i] / A_diag[i]\n        return u_t\n\n    # 1. Generate snapshot matrix X\n    snapshots = [fom_solution(t) for t in snapshot_times]\n    X = np.stack(snapshots, axis=1)\n\n    # 2. Compute SVD of X to get POD basis and singular values\n    U, s, Vh = np.linalg.svd(X, full_matrices=False)\n    # The number of singular values is min(n, m) = min(4, 5) = 4. U is 4x4.\n\n    # 3. Compute total snapshot energy\n    sigma_sq = s**2\n    total_energy = np.sum(sigma_sq)\n    \n    # Get the true final state for error calculations\n    u_T_true = fom_solution(T_final)\n    norm_u_T_true = np.linalg.norm(u_T_true)\n\n    results = []\n\n    for r in ranks:\n        # Step 1: Compute snapshot energy metrics\n        if r == 0:\n            captured_energy = 0.0\n        else:\n            captured_energy = np.sum(sigma_sq[:r])\n        \n        neglected_energy = total_energy - captured_energy\n        capture_fraction = captured_energy / total_energy if total_energy > 0 else 1.0\n\n        # Step 2: Construct and solve the ROM to find u_r(T)\n        if r == 0:\n            # For r=0, the reduced space is trivial. The prediction is the zero vector.\n            u_r_T = np.zeros(n)\n        else:\n            Ur = U[:, :r]\n            \n            # Construct ROM\n            Ar = Ur.T @ A @ Ur\n            gr = Ur.T @ g\n            u0_tilde = Ur.T @ u0\n            \n            # Solve ROM: u_tilde(t) = exp(Ar*t)u0_tilde + Ar_inv*(exp(Ar*t)-I)*gr\n            # Since Ar is symmetric, it is diagonalizable.\n            eigvals, P = np.linalg.eigh(Ar)\n            P_inv = P.T # For an orthogonal matrix from eigh\n            \n            # Compute matrix exponential exp(Ar*T)\n            exp_Dr_T = np.diag(np.exp(eigvals * T_final))\n            exp_Ar_T = P @ exp_Dr_T @ P_inv\n            \n            # Compute the integral term\n            # Ar_inv can be computed via diagonalization as well\n            Ar_inv = P @ np.diag(1.0 / eigvals) @ P_inv\n            integral_term = Ar_inv @ (exp_Ar_T - np.identity(r)) @ gr\n\n            # Solve for u_tilde at T\n            u_tilde_T = exp_Ar_T @ u0_tilde + integral_term\n\n            # Lift solution back to full space\n            u_r_T = Ur @ u_tilde_T\n            \n        # Step 3: Compute prediction errors\n        abs_error = np.linalg.norm(u_T_true - u_r_T)\n        rel_error = abs_error / norm_u_T_true if norm_u_T_true > 0 else 0.0\n\n        results.append([neglected_energy, capture_fraction, abs_error, rel_error])\n\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "3252598"}, {"introduction": "In chaotic systems, small uncertainties can lead to vastly different outcomes, a phenomenon famously known as the \"butterfly effect.\" This practice challenges you to explore how a modeling error—represented by a small inaccuracy in a system parameter—compares to an error in the initial conditions for the Lorenz system. By simulating the trajectories and comparing their divergence, you will investigate whether the system is more sensitive to an imperfect model or imperfect measurements. This exercise provides critical insight into the interplay between different error sources and their profound impact on predictability in nonlinear dynamics [@problem_id:3252605].", "problem": "Consider the Lorenz system, modeled as an autonomous Ordinary Differential Equation (ODE) in three dimensions. Let the state be $x(t) = (x(t), y(t), z(t)) \\in \\mathbb{R}^3$ and let the parameter vector be $p = (\\sigma, \\rho, \\beta) \\in \\mathbb{R}^3$. The vector field is given by\n$$\n\\frac{d}{dt}\n\\begin{bmatrix}\nx \\\\\ny \\\\\nz\n\\end{bmatrix}\n=\nf(x,y,z;p) =\n\\begin{bmatrix}\n\\sigma (y - x) \\\\\nx(\\rho - z) - y \\\\\nxy - \\beta z\n\\end{bmatrix}.\n$$\nAssume a baseline parameter set $p_0 = (\\sigma_0, \\rho_0, \\beta_0)$ with $\\sigma_0 = 10$, $\\rho_0 = 28$, and $\\beta_0 = \\frac{8}{3}$, and a baseline initial condition $x_0 = (1, 1, 1)$. We wish to compare the separation between the baseline trajectory and two perturbed trajectories: one with a small modeling error (a perturbed parameter) and one with a small initial condition error. Specifically, for a given terminal time $T  0$ and time step $h  0$, let $x_{\\text{base}}(T)$ denote the baseline numerical solution of the ODE with parameters $p_0$ and initial state $x_0$. Define two additional trajectories:\n- The initial condition error trajectory $x_{\\text{IC}}(t)$ solves the same ODE with the same parameters $p_0$, but with initial condition $x_0 + \\delta x_0$, where $\\delta x_0 = (\\epsilon, 0, 0)$ and $\\epsilon  0$ is small.\n- The modeling error trajectory $x_{\\text{model}}(t)$ solves the ODE with the same initial condition $x_0$, but with parameter vector $p_0 + \\delta p$, where $\\delta p = (0, \\delta \\rho, 0)$ and $\\delta \\rho$ is small.\n\nFor each trajectory, define the Euclidean separation at time $T$ as\n$$\ns_{\\text{IC}}(T) = \\left\\| x_{\\text{IC}}(T) - x_{\\text{base}}(T) \\right\\|_2,\\quad\ns_{\\text{model}}(T) = \\left\\| x_{\\text{model}}(T) - x_{\\text{base}}(T) \\right\\|_2.\n$$\nYour task is to implement a fixed-step numerical solver using the classical fourth-order Runge–Kutta method (RK4) to approximate $x_{\\text{base}}(T)$, $x_{\\text{IC}}(T)$, and $x_{\\text{model}}(T)$ for each test case. Then compute, for each test case, the ratio\n$$\nR = \\frac{s_{\\text{model}}(T)}{s_{\\text{IC}}(T)},\n$$\nwith the convention that if $s_{\\text{IC}}(T) = 0$, return $+\\infty$.\n\nUse the following test suite, which varies the terminal time $T$, step size $h$, and perturbation magnitudes to probe typical behavior, edge conditions, and sensitivity:\n- Test $1$ (happy path, chaotic regime, small symmetric perturbations): $T = 20$, $h = 0.01$, $\\epsilon = 10^{-6}$, $\\delta \\rho = 10^{-6}$.\n- Test $2$ (boundary case, zero initial condition error): $T = 20$, $h = 0.01$, $\\epsilon = 0$, $\\delta \\rho = 10^{-6}$.\n- Test $3$ (boundary case, zero modeling error): $T = 20$, $h = 0.01$, $\\epsilon = 10^{-6}$, $\\delta \\rho = 0$.\n- Test $4$ (longer horizon, finer step, extremely small initial error): $T = 40$, $h = 0.005$, $\\epsilon = 10^{-12}$, $\\delta \\rho = 10^{-6}$.\n\nAll quantities are dimensionless; no physical units are involved. The angle unit is not applicable.\n\nYour program must:\n- Implement the RK4 method with fixed step size $h$ to compute the numerical solution for the Lorenz ODE.\n- For each test case, compute $R$ as specified above.\n- Produce a single line of output containing the results as a comma-separated list enclosed in square brackets, in the same order as the test suite, for example: $[r_1,r_2,r_3,r_4]$, where each $r_i$ is a floating-point number (allowing $+\\infty$ where applicable).", "solution": "The user wants to solve a problem based on a set of provided data.\n\n### Step 1: Extract Givens\n- **ODE System (Lorenz System)**: \n$$\n\\frac{d}{dt}\n\\begin{bmatrix}\nx \\\\\ny \\\\\nz\n\\end{bmatrix}\n=\nf(x,y,z;p) =\n\\begin{bmatrix}\n\\sigma (y - x) \\\\\nx(\\rho - z) - y \\\\\nxy - \\beta z\n\\end{bmatrix}\n$$\n- **State Vector**: $x(t) = (x(t), y(t), z(t)) \\in \\mathbb{R}^3$.\n- **Parameter Vector**: $p = (\\sigma, \\rho, \\beta) \\in \\mathbb{R}^3$.\n- **Baseline Parameters**: $p_0 = (\\sigma_0, \\rho_0, \\beta_0)$ with $\\sigma_0 = 10$, $\\rho_0 = 28$, and $\\beta_0 = \\frac{8}{3}$.\n- **Baseline Initial Condition**: $x_0 = (1, 1, 1)$.\n- **Initial Condition Perturbation**: $\\delta x_0 = (\\epsilon, 0, 0)$ with $\\epsilon  0$. The perturbed initial condition is $x_0 + \\delta x_0$.\n- **Modeling Error Perturbation**: $\\delta p = (0, \\delta \\rho, 0)$. The perturbed parameter vector is $p_0 + \\delta p$.\n- **Trajectories to Compute**:\n    - $x_{\\text{base}}(t)$: Solution with parameters $p_0$ and initial state $x_0$.\n    - $x_{\\text{IC}}(t)$: Solution with parameters $p_0$ and initial state $x_0 + \\delta x_0$.\n    - $x_{\\text{model}}(t)$: Solution with parameters $p_0 + \\delta p$ and initial state $x_0$.\n- **Separation Measures**: At a terminal time $T$,\n$$\ns_{\\text{IC}}(T) = \\left\\| x_{\\text{IC}}(T) - x_{\\text{base}}(T) \\right\\|_2\n$$\n$$\ns_{\\text{model}}(T) = \\left\\| x_{\\text{model}}(T) - x_{\\text{base}}(T) \\right\\|_2\n$$\n- **Target Quantity**: The ratio $R = \\frac{s_{\\text{model}}(T)}{s_{\\text{IC}}(T)}$. If $s_{\\text{IC}}(T) = 0$, $R$ is returned as $+\\infty$.\n- **Numerical Method**: Classical fourth-order Runge–Kutta method (RK4) with a fixed step size $h$.\n- **Test Suite**:\n    1.  Test 1: $T = 20$, $h = 0.01$, $\\epsilon = 10^{-6}$, $\\delta \\rho = 10^{-6}$.\n    2.  Test 2: $T = 20$, $h = 0.01$, $\\epsilon = 0$, $\\delta \\rho = 10^{-6}$.\n    3.  Test 3: $T = 20$, $h = 0.01$, $\\epsilon = 10^{-6}$, $\\delta \\rho = 0$.\n    4.  Test 4: $T = 40$, $h = 0.005$, $\\epsilon = 10^{-12}$, $\\delta \\rho = 10^{-6}$.\n\n### Step 2: Validate Using Extracted Givens\n1.  **Scientifically Grounded**: The problem is based on the Lorenz system, a cornerstone model in chaos theory and dynamical systems. The RK4 method is a standard, widely used numerical integrator for ODEs. The investigation of sensitivity to initial conditions and model parameters is a fundamental topic in the study of chaotic systems. The problem is scientifically sound.\n2.  **Well-Posed**: The problem is well-defined. It specifies the governing equations, the numerical method, all necessary parameters, initial conditions, and the exact quantity to be computed for a series of distinct test cases. The logic for handling edge cases (e.g., zero denominator) is also provided. A unique numerical solution can be determined for each case.\n3.  **Objective**: The problem is stated using precise mathematical language and objective criteria. There are no subjective or opinion-based components.\n4.  **Incomplete or Contradictory Setup**: The problem is self-contained and provides all necessary information. There are no contradictions in the given data or constraints.\n5.  **Unrealistic or Infeasible**: The parameter values for the Lorenz system are the classical ones known to produce chaotic behavior. The time horizons, step sizes, and perturbation magnitudes are computationally feasible and standard for such numerical experiments.\n6.  **Ill-Posed or Poorly Structured**: The problem is clearly structured, leading to a unique and meaningful numerical result for each test case.\n7.  **Pseudo-Profound, Trivial, or Tautological**: The problem addresses a non-trivial concept—the relative impact of different error sources in a chaotic system—and requires a standard but careful numerical implementation.\n8.  **Outside Scientific Verifiability**: The results are numerically verifiable by re-implementing the specified algorithm.\n\n### Step 3: Verdict and Action\nThe problem is valid. A reasoned solution will be provided.\n\nThe problem requires a comparison of the effects of a small perturbation in the initial condition versus a small perturbation in a model parameter for the Lorenz chaotic system. This is accomplished by numerically integrating the system's governing Ordinary Differential Equations (ODEs) and analyzing the resulting trajectory separations. The specified numerical integration scheme is the classical fourth-order Runge-Kutta (RK4) method.\n\nThe Lorenz system is defined by the following set of autonomous ODEs for a state vector $x(t) = [x(t), y(t), z(t)]^T \\in \\mathbb{R}^3$:\n$$\n\\frac{d}{dt}x(t)\n=\nf(x(t); p) =\n\\begin{bmatrix}\n\\sigma (y - x) \\\\\nx(\\rho - z) - y \\\\\nxy - \\beta z\n\\end{bmatrix}\n$$\nwhere $p = (\\sigma, \\rho, \\beta)$ is the parameter vector.\n\nThe numerical solution is obtained using the RK4 method with a fixed time step $h$. For a general autonomous ODE $\\frac{dx}{dt} = f(x)$, the state $x_{n+1}$ at time $t_{n+1} = t_n + h$ is approximated from the state $x_n$ at time $t_n$ by the formula:\n$$\nx_{n+1} = x_n + \\frac{h}{6}(k_1 + 2k_2 + 2k_3 + k_4)\n$$\nThe intermediate slope vectors $k_i \\in \\mathbb{R}^3$ are computed as follows:\n$$\n\\begin{aligned}\nk_1 = f(x_n; p) \\\\\nk_2 = f(x_n + \\frac{h}{2}k_1; p) \\\\\nk_3 = f(x_n + \\frac{h}{2}k_2; p) \\\\\nk_4 = f(x_n + hk_3; p)\n\\end{aligned}\n$$\nwhere $p$ is the parameter vector for the specific simulation. To obtain the solution at a terminal time $T$, this update rule is applied iteratively $N = \\text{round}(T/h)$ times, starting from a given initial condition at $t=0$.\n\nFor each test case, three trajectories are simulated:\n1.  **Baseline Trajectory ($x_{\\text{base}}$)**: Solved with the baseline initial condition $x_0 = (1, 1, 1)$ and baseline parameters $p_0 = (10, 28, 8/3)$.\n2.  **Initial Condition Perturbed Trajectory ($x_{\\text{IC}}$)**: Solved with the perturbed initial condition $x(0) = x_0 + \\delta x_0 = (1+\\epsilon, 1, 1)$ and baseline parameters $p_0$.\n3.  **Model Perturbed Trajectory ($x_{\\text{model}}$)**: Solved with the baseline initial condition $x_0$ and perturbed parameters $p = p_0 + \\delta p = (10, 28+\\delta\\rho, 8/3)$.\n\nAfter running the simulations up to the time $T$, the final states $x_{\\text{base}}(T)$, $x_{\\text{IC}}(T)$, and $x_{\\text{model}}(T)$ are obtained. From these, the Euclidean separation distances are computed:\n$$\ns_{\\text{IC}}(T) = \\left\\| x_{\\text{IC}}(T) - x_{\\text{base}}(T) \\right\\|_2\n$$\n$$\ns_{\\text{model}}(T) = \\left\\| x_{\\text{model}}(T) - x_{\\text{base}}(T) \\right\\|_2\n$$\nThe final quantity of interest is the ratio $R$:\n$$\nR = \\frac{s_{\\text{model}}(T)}{s_{\\text{IC}}(T)}\n$$\nAs specified, if $s_{\\text{IC}}(T) = 0$ (which happens when $\\epsilon=0$), the value of $R$ is taken to be positive infinity. If $s_{\\text{model}}(T) = 0$ (when $\\delta\\rho=0$) and $s_{\\text{IC}}(T) \\neq 0$, the ratio $R$ evaluates to $0$.\n\nThis procedure is systematically applied to the four test cases provided. The resulting values of $R$ are collected and presented in a list as the final output. The test cases are designed to probe the system's sensitivity under different conditions, including standard chaotic evolution and boundary cases where one of the perturbations is null.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Computes the ratio of trajectory separation due to modeling error\n    versus initial condition error for the Lorenz system.\n    \"\"\"\n\n    def lorenz_f(state, sigma, rho, beta):\n        \"\"\"\n        Computes the Lorenz system vector field (the right-hand side of the ODE).\n\n        Args:\n            state (np.ndarray): The current state [x, y, z].\n            sigma (float): The sigma parameter.\n            rho (float): The rho parameter.\n            beta (float): The beta parameter.\n\n        Returns:\n            np.ndarray: The derivative [dx/dt, dy/dt, dz/dt].\n        \"\"\"\n        x, y, z = state\n        dx_dt = sigma * (y - x)\n        dy_dt = x * (rho - z) - y\n        dz_dt = x * y - beta * z\n        return np.array([dx_dt, dy_dt, dz_dt])\n\n    def rk4_solver(x0, T, h, sigma, rho, beta):\n        \"\"\"\n        Solves the Lorenz ODE using the classical 4th-order Runge-Kutta method.\n\n        Args:\n            x0 (np.ndarray): The initial state vector [x0, y0, z0].\n            T (float): The terminal time.\n            h (float): The fixed step size.\n            sigma (float): The sigma parameter.\n            rho (float): The rho parameter.\n            beta (float): The beta parameter.\n\n        Returns:\n            np.ndarray: The state vector at time T.\n        \"\"\"\n        num_steps = int(round(T / h))\n        x = np.copy(x0).astype(float)  # Use a copy to avoid modifying the input\n\n        for _ in range(num_steps):\n            k1 = lorenz_f(x, sigma, rho, beta)\n            k2 = lorenz_f(x + h * 0.5 * k1, sigma, rho, beta)\n            k3 = lorenz_f(x + h * 0.5 * k2, sigma, rho, beta)\n            k4 = lorenz_f(x + h * k3, sigma, rho, beta)\n            x += (h / 6.0) * (k1 + 2.0 * k2 + 2.0 * k3 + k4)\n        \n        return x\n\n    # Baseline parameters and initial condition from the problem statement.\n    sigma0 = 10.0\n    rho0 = 28.0\n    beta0 = 8.0 / 3.0\n    x0_base = np.array([1.0, 1.0, 1.0])\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # (T, h, epsilon, delta_rho)\n        (20.0, 0.01, 1e-6, 1e-6),      # Test 1\n        (20.0, 0.01, 0.0, 1e-6),       # Test 2\n        (20.0, 0.01, 1e-6, 0.0),       # Test 3\n        (40.0, 0.005, 1e-12, 1e-6),    # Test 4\n    ]\n\n    results = []\n    for T, h, epsilon, delta_rho in test_cases:\n        # 1. Compute baseline trajectory final state\n        x_base_T = rk4_solver(x0_base, T, h, sigma0, rho0, beta0)\n\n        # 2. Compute initial condition error trajectory final state\n        x0_ic = x0_base + np.array([epsilon, 0.0, 0.0])\n        x_ic_T = rk4_solver(x0_ic, T, h, sigma0, rho0, beta0)\n\n        # 3. Compute modeling error trajectory final state\n        rho_model = rho0 + delta_rho\n        x_model_T = rk4_solver(x0_base, T, h, sigma0, rho_model, beta0)\n        \n        # Calculate Euclidean separation distances\n        s_ic = np.linalg.norm(x_ic_T - x_base_T)\n        s_model = np.linalg.norm(x_model_T - x_base_T)\n\n        # Calculate the ratio R\n        if s_ic == 0.0:\n            # As per problem specification, if s_IC(T) = 0, R is +infinity.\n            # This occurs in Test 2 where epsilon = 0.\n            R = float('inf')\n        else:\n            R = s_model / s_ic\n        \n        results.append(R)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "3252605"}]}