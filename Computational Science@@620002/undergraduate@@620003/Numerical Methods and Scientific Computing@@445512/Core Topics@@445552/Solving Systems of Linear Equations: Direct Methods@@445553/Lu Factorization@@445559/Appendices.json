{"hands_on_practices": [{"introduction": "This first exercise provides a concrete walkthrough of the Doolittle LU factorization algorithm. By decomposing a matrix $A$ into a lower unit triangular matrix $L$ and an upper triangular matrix $U$, you'll practice the step-by-step process that forms the foundation of this powerful technique [@problem_id:2161051]. This practice also reinforces the concept that solving systems with triangular matrices, such as finding the inverse of $U$, is computationally efficient.", "problem": "In numerical linear algebra, the LU decomposition is a fundamental technique for solving systems of linear equations, inverting matrices, and computing determinants. For a square matrix $A$, a Doolittle LU decomposition is a factorization of the form $A = LU$, where $L$ is a lower unit triangular matrix (i.e., a lower triangular matrix with ones on its main diagonal) and $U$ is an upper triangular matrix.\n\nConsider the matrix $A$ given by:\n$$\nA = \\begin{pmatrix} 2 & 1 & -1 \\\\ 4 & 5 & -1 \\\\ -2 & 8 & 8 \\end{pmatrix}\n$$\nYour task is to first determine the Doolittle LU decomposition of $A$. After finding the matrices $L$ and $U$, you must then find the inverse of the upper triangular matrix, $U^{-1}$.\n\nPresent your final answer for $U^{-1}$ as a 3x3 matrix.", "solution": "We seek a Doolittle LU decomposition of $A$, so we write $A=LU$ with\n$$\nL=\\begin{pmatrix}1&0&0\\\\ \\ell_{21}&1&0\\\\ \\ell_{31}&\\ell_{32}&1\\end{pmatrix},\\quad\nU=\\begin{pmatrix}u_{11}&u_{12}&u_{13}\\\\ 0&u_{22}&u_{23}\\\\ 0&0&u_{33}\\end{pmatrix}.\n$$\nUsing the Doolittle procedure:\n- From the first row of $U$, set $u_{11}=a_{11}=2$, $u_{12}=a_{12}=1$, $u_{13}=a_{13}=-1$.\n- Compute multipliers $\\ell_{21}=\\frac{a_{21}}{u_{11}}=\\frac{4}{2}=2$ and $\\ell_{31}=\\frac{a_{31}}{u_{11}}=\\frac{-2}{2}=-1$.\n- Compute $u_{22}=a_{22}-\\ell_{21}u_{12}=5-2\\cdot 1=3$ and $u_{23}=a_{23}-\\ell_{21}u_{13}=-1-2\\cdot(-1)=1$.\n- Compute $\\ell_{32}=\\frac{a_{32}-\\ell_{31}u_{12}}{u_{22}}=\\frac{8-(-1)\\cdot 1}{3}=\\frac{9}{3}=3$.\n- Compute $u_{33}=a_{33}-\\ell_{31}u_{13}-\\ell_{32}u_{23}=8-(-1)\\cdot(-1)-3\\cdot 1=4$.\n\nThus\n$$\nL=\\begin{pmatrix}1&0&0\\\\ 2&1&0\\\\ -1&3&1\\end{pmatrix},\\quad\nU=\\begin{pmatrix}2&1&-1\\\\ 0&3&1\\\\ 0&0&4\\end{pmatrix}.\n$$\nTo find $U^{-1}$, we solve $UX=I$ column by column. Let the columns of $X$ be $\\mathbf{x}^{(1)}, \\mathbf{x}^{(2)}, \\mathbf{x}^{(3)}$, solving $U \\mathbf{x}^{(j)}=e_{j}$.\n\nFor $j=1$:\n$4x_{31}^{(1)}=0\\Rightarrow x_{31}^{(1)}=0$.\n$3x_{21}^{(1)}+x_{31}^{(1)}=0\\Rightarrow x_{21}^{(1)}=0$.\n$2x_{11}^{(1)}+x_{21}^{(1)}-x_{31}^{(1)}=1\\Rightarrow x_{11}^{(1)}=\\frac{1}{2}$.\nHence $\\mathbf{x}^{(1)}=(\\frac{1}{2},0,0)^{\\mathsf{T}}$.\n\nFor $j=2$:\n$4x_{32}^{(2)}=0\\Rightarrow x_{32}^{(2)}=0$.\n$3x_{22}^{(2)}+x_{32}^{(2)}=1\\Rightarrow x_{22}^{(2)}=\\frac{1}{3}$.\n$2x_{12}^{(2)}+x_{22}^{(2)}-x_{32}^{(2)}=0\\Rightarrow x_{12}^{(2)}=-\\frac{1}{6}$.\nHence $\\mathbf{x}^{(2)}=(-\\frac{1}{6},\\frac{1}{3},0)^{\\mathsf{T}}$.\n\nFor $j=3$:\n$4x_{33}^{(3)}=1\\Rightarrow x_{33}^{(3)}=\\frac{1}{4}$.\n$3x_{23}^{(3)}+x_{33}^{(3)}=0\\Rightarrow x_{23}^{(3)}=-\\frac{1}{12}$.\n$2x_{13}^{(3)}+x_{23}^{(3)}-x_{33}^{(3)}=0\\Rightarrow x_{13}^{(3)}=\\frac{1}{6}$.\nHence $\\mathbf{x}^{(3)}=(\\frac{1}{6},-\\frac{1}{12},\\frac{1}{4})^{\\mathsf{T}}$.\n\nCollecting the columns gives\n$$\nU^{-1}=\\begin{pmatrix}\n\\frac{1}{2} & -\\frac{1}{6} & \\frac{1}{6}\\\\\n0 & \\frac{1}{3} & -\\frac{1}{12}\\\\\n0 & 0 & \\frac{1}{4}\n\\end{pmatrix}.\n$$", "answer": "$$\\boxed{\\begin{pmatrix}\\frac{1}{2}&-\\frac{1}{6}&\\frac{1}{6}\\\\0&\\frac{1}{3}&-\\frac{1}{12}\\\\0&0&\\frac{1}{4}\\end{pmatrix}}$$", "id": "2161051"}, {"introduction": "Not all matrices can be directly factored using basic LU algorithms, and this diagnostic exercise explores why. By attempting to apply Crout's algorithm to a matrix that violates the conditions for a standard LU decomposition, you will pinpoint the exact computational step where the method fails [@problem_id:3249633]. This analysis provides a clear, first-principles justification for the necessity of pivoting strategies in robust numerical software.", "problem": "A square matrix $A \\in \\mathbb{R}^{n \\times n}$ admits a Lower-Upper (LU) factorization without row exchanges if and only if each leading principal minor of $A$ is nonzero. In Crout's algorithm, one seeks $A = LU$ where $L$ is lower triangular and $U$ is upper triangular with unit diagonal entries, performing an elimination process without pivoting. Consider the matrix\n$$\nA \\;=\\; \\begin{pmatrix}\n0 & 2 & 3 \\\\\n1 & 4 & 5 \\\\\n2 & 8 & 11\n\\end{pmatrix}.\n$$\nAttempt to apply Crout's algorithm to $A$ without any pivoting. Based solely on first principles of elimination and the structural definition of Crout's algorithm (unit diagonal in $U$, lower-triangular $L$), determine what happens and identify the specific calculation at which the algorithm first fails.\n\nChoose the best description.\n\nA. The failure occurs at step $k=1$ when computing $l_{11}$, because Crout's algorithm requires dividing by $a_{11}$ to obtain $l_{11}$, leading to a division-by-zero at $a_{11}=0$.\n\nB. The failure occurs at step $k=1$ when forming the first row of $U$ beyond the diagonal; specifically, computing $u_{1j}$ for $j>1$ requires division by the pivot $l_{11}=a_{11}=0$, causing a division-by-zero.\n\nC. No failure occurs: the algorithm can proceed with $l_{11}=0$, producing an $L$ with a zero diagonal entry and a compatible non-unit $U$, still yielding a valid factorization $A=L U$.\n\nD. The failure occurs later at step $k=2$ when computing $l_{22}$, because Crout's algorithm divides by $u_{11}$, which is zero in this case, causing a division-by-zero at that point.", "solution": "The problem asks to identify the failure point of Crout's LU factorization algorithm when applied to the given matrix $A$. In Crout's factorization, we decompose $A = LU$, where $L$ is a lower triangular matrix and $U$ is an upper triangular matrix with ones on its diagonal ($u_{ii} = 1$).\n\nThe relationship is defined by $A_{ij} = \\sum_{k=1}^{\\min(i,j)} L_{ik} U_{kj}$. Let's follow the algorithm step-by-step.\n\n1.  **Compute the first column of $L$**: For $i = 1, 2, 3$, the formula is $A_{i1} = L_{i1}U_{11}$. Since $U_{11}=1$, we get $L_{i1} = A_{i1}$.\n    -   $l_{11} = a_{11} = 0$.\n    -   $l_{21} = a_{21} = 1$.\n    -   $l_{31} = a_{31} = 2$.\n    This step completes without any error.\n\n2.  **Compute the first row of $U$**: For $j = 2, 3$, the formula is $A_{1j} = L_{11}U_{1j}$. To find the unknown $U_{1j}$, we must rearrange to $U_{1j} = A_{1j} / L_{11}$.\n    -   Let's compute $u_{12}$. The formula requires $u_{12} = a_{12} / l_{11}$.\n    -   Using the values from the matrix and the previous step, this becomes $u_{12} = 2 / 0$.\n    -   This is a **division-by-zero** error. The algorithm cannot proceed.\n\nThe failure occurs at step $k=1$, during the computation of the first row of $U$ (specifically, the first off-diagonal element $u_{12}$). The cause is the division by the pivot element $l_{11}$, which is zero.\n\nAnalyzing the options:\n-   **A** is incorrect. The computation of $l_{11}$ is a direct assignment ($l_{11} = a_{11}$), not a division.\n-   **B** is correct. It accurately describes that the failure happens when computing the first row of $U$ ($u_{1j}$ for $j>1$) due to division by the pivot $l_{11}=a_{11}=0$.\n-   **C** is incorrect. A failure does occur, and the algorithm cannot proceed. The equation $a_{12} = l_{11}u_{12}$ becomes $2 = 0 \\cdot u_{12}$, which is a contradiction with no solution.\n-   **D** is incorrect. The failure is at step $k=1$, not $k=2$. Also, in Crout's algorithm, $u_{11}=1$, so division by it is not an issue; the problem is division by $l_{11}$.", "answer": "$$\\boxed{B}$$", "id": "3249633"}, {"introduction": "This advanced exercise bridges the gap between theoretical algorithms and computational practice by exploring the effects of ill-conditioning. You will implement both Doolittle and Crout factorizations to analyze the famously ill-conditioned Hilbert matrix, focusing on element growth and residual errors [@problem_id:3249691]. This hands-on programming task provides direct insight into the challenges of numerical stability and the behavior of floating-point arithmetic in a challenging scenario.", "problem": "Develop a complete, runnable program that analyzes the element magnitude growth in the triangular factors produced by two classic algorithms for Lower-Upper (LU) factorization without pivoting when applied to the Hilbert matrix. Your program must implement both the Doolittle and the Crout variants of LU factorization directly from first principles and report quantitative measures of growth and residuals for a small test suite of Hilbert matrices.\n\nThe fundamental base you must use is:\n- The definition that for a nonsingular square matrix $A \\in \\mathbb{R}^{n \\times n}$, an LU factorization is a decomposition $A = LU$ where $L$ is lower triangular and $U$ is upper triangular.\n- In the Doolittle variant, $L$ is lower triangular with unit diagonal, meaning $L_{ii} = 1$ for all $i$, while $U$ is upper triangular with general diagonal.\n- In the Crout variant, $U$ is upper triangular with unit diagonal, meaning $U_{ii} = 1$ for all $i$, while $L$ is lower triangular with general diagonal.\n- The Hilbert matrix $H_n \\in \\mathbb{R}^{n \\times n}$ is given componentwise by $[H_n]_{ij} = \\frac{1}{i + j - 1}$ for $1 \\leq i,j \\leq n$. The matrix $H_n$ is symmetric positive definite and nonsingular for all positive integers $n$.\n\nStarting from these definitions, derive in your solution how to obtain the entries of $L$ and $U$ step by step, ensuring correctness without pivoting. The derivation should proceed by equating entries in $A = L U$ and solving for unknowns in an order compatible with triangular structure, without assuming any pre-existing shortcut formulas.\n\nYour program must:\n- Construct $H_n$ for each $n$ in the set $\\{1,2,5,10\\}$ using double-precision floating-point arithmetic.\n- Compute two factorizations for each $n$:\n  - The Doolittle factorization $H_n = L^{(D)} U^{(D)}$ with $L^{(D)}$ unit diagonal.\n  - The Crout factorization $H_n = L^{(C)} U^{(C)}$ with $U^{(C)}$ unit diagonal.\n- For each factorization, compute:\n  - The maximum absolute entry magnitude in the lower-triangular factor, $g_L = \\max_{i,j} |L_{ij}|$.\n  - The maximum absolute entry magnitude in the upper-triangular factor, $g_U = \\max_{i,j} |U_{ij}|$.\n  - The infinity-norm residual of the factorization, $r_{\\infty} = \\|H_n - L U\\|_{\\infty}$, where $\\|X\\|_{\\infty} = \\max_{1 \\le i \\le n} \\sum_{j=1}^n |X_{ij}|$.\n- Note that for the Hilbert matrix, $\\max_{i,j} |[H_n]_{ij}| = 1$, so the raw magnitudes $g_L$ and $g_U$ already serve as normalized growth measures relative to the largest entry of $H_n$.\n\nScientific realism and numerical soundness requirements:\n- Work strictly without pivoting.\n- Use only standard double-precision floating-point arithmetic.\n- No physical units are involved.\n- Angle units are not applicable.\n\nTest suite and output specification:\n- Use the test suite $n \\in \\{1,2,5,10\\}$.\n- For each $n$, produce a result list of the form $[n, g_L^{(D)}, g_U^{(D)}, g_L^{(C)}, g_U^{(C)}, r_{\\infty}^{(D)}, r_{\\infty}^{(C)}]$, where the superscripts $(D)$ and $(C)$ denote Doolittle and Crout, respectively.\n- Your program should produce a single line of output containing the results for all $n$ as a comma-separated list of these lists, enclosed in square brackets. For example, a syntactically valid shape is $[[\\cdot,\\cdot,\\cdot,\\cdot,\\cdot,\\cdot,\\cdot],[\\cdot,\\cdot,\\cdot,\\cdot,\\cdot,\\cdot,\\cdot],\\ldots]$ with numeric entries in place of the dots.\n\nThe final line must be exactly one line with no extra commentary.", "solution": "**1. Problem Statement Analysis and Validation**\n\nThe problem requires the implementation and analysis of two variants of LU factorization, Doolittle's and Crout's methods, applied to the Hilbert matrix $H_n$ for sizes $n \\in \\{1, 2, 5, 10\\}$. The analysis focuses on the growth of element magnitudes in the triangular factors $L$ and $U$, and the residual error of the factorization. The algorithms are to be implemented without pivoting, which is permissible and numerically stable because the Hilbert matrix is symmetric positive definite (SPD).\n\nThe problem is scientifically grounded, well-posed, and complete. All definitions—Hilbert matrix $[H_n]_{ij} = (i+j-1)^{-1}$, Doolittle factorization ($L_{ii}=1$), Crout factorization ($U_{ii}=1$), and the infinity norm $\\|X\\|_{\\infty} = \\max_i \\sum_j |X_{ij}|_—are standard in numerical linear algebra. The provided property that $H_n$ is SPD is correct and crucial, as it guarantees that LU factorization without pivoting exists, is unique, and is numerically stable. The task is a standard exercise in numerical analysis, allowing for a clear, verifiable, and non-trivial computational result. The problem is thus deemed valid.\n\n**2. Derivation of LU Factorization Algorithms from First Principles**\n\nThe objective is to find a lower triangular matrix $L$ and an upper triangular matrix $U$ such that $A = LU$ for a given square matrix $A \\in \\mathbb{R}^{n \\times n}$. The element-wise definition of this matrix product is:\n$$A_{ij} = \\sum_{k=1}^{n} L_{ik} U_{kj}$$\nDue to the triangular nature of $L$ ($L_{ik}=0$ for $k>i$) and $U$ ($U_{kj}=0$ for $k>j$), the summation simplifies to:\n$$A_{ij} = \\sum_{k=1}^{\\min(i,j)} L_{ik} U_{kj}$$\nTo ensure a unique factorization, $n^2$ unknown entries in $L$ and $U$ must be determined from the $n^2$ equations provided by the entries of $A$. There are $n^2+n$ potential unknowns in $L$ and $U$. Thus, $n$ additional constraints must be imposed, typically by setting the diagonal elements of either $L$ or $U$ to $1$.\n\n**2.1. Doolittle's Algorithm ($L_{ii}=1$)**\n\nIn the Doolittle variant, $L$ is a unit lower triangular matrix, i.e., $L_{ii} = 1$ for all $i=1, \\dots, n$. The unknowns are the sub-diagonal entries of $L$ and all entries of $U$. We can derive a sequential algorithm by isolating the unknown quantities. A common approach is to compute the rows of $U$ and columns of $L$ alternately.\n\nFor each $p$ from $1$ to $n$:\n1.  **Compute the $p$-th row of $U$**: For $j = p, \\dots, n$, we have:\n    $$A_{pj} = \\sum_{k=1}^{p} L_{pk} U_{kj} = \\sum_{k=1}^{p-1} L_{pk} U_{kj} + L_{pp} U_{pj}$$\n    Since $L_{pp} = 1$, we can solve for $U_{pj}$:\n    $$U_{pj} = A_{pj} - \\sum_{k=1}^{p-1} L_{pk} U_{kj}$$\n    At step $p$, the required entries $L_{pk}$ (for $k<p$) and $U_{kj}$ (for $k<p$) have already been computed in previous steps.\n\n2.  **Compute the $p$-th column of $L$**: For $i = p+1, \\dots, n$, we have:\n    $$A_{ip} = \\sum_{k=1}^{p} L_{ik} U_{kp} = \\sum_{k=1}^{p-1} L_{ik} U_{kp} + L_{ip} U_{pp}$$\n    Solving for $L_{ip}$ yields:\n    $$L_{ip} = \\frac{1}{U_{pp}} \\left( A_{ip} - \\sum_{k=1}^{p-1} L_{ik} U_{kp} \\right)$$\n    This computation is possible provided $U_{pp} \\neq 0$. For an SPD matrix, all its leading principal submatrices are nonsingular, which guarantees that all pivots $U_{pp}$ will be positive.\n\n**2.2. Crout's Algorithm ($U_{ii}=1$)**\n\nIn the Crout variant, $U$ is a unit upper triangular matrix, i.e., $U_{ii} = 1$ for all $i=1, \\dots, n$. The unknowns are all entries of $L$ and the super-diagonal entries of $U$. The derivation mirrors the Doolittle case, but the order of computation is adjusted.\n\nFor each $p$ from $1$ to $n$:\n1.  **Compute the $p$-th column of $L$**: For $i = p, \\dots, n$, we have:\n    $$A_{ip} = \\sum_{k=1}^{p} L_{ik} U_{kp} = \\sum_{k=1}^{p-1} L_{ik} U_{kp} + L_{ip} U_{pp}$$\n    Since $U_{pp} = 1$, we can solve for $L_{ip}$:\n    $$L_{ip} = A_{ip} - \\sum_{k=1}^{p-1} L_{ik} U_{kp}$$\n\n2.  **Compute the $p$-th row of $U$**: For $j = p+1, \\dots, n$, we have:\n    $$A_{pj} = \\sum_{k=1}^{p} L_{pk} U_{kj} = \\sum_{k=1}^{p-1} L_{pk} U_{kj} + L_{pp} U_{pj}$$\n    Solving for $U_{pj}$ yields:\n    $$U_{pj} = \\frac{1}{L_{pp}} \\left( A_{pj} - \\sum_{k=1}^{p-1} L_{pk} U_{kj} \\right)$$\n    This requires $L_{pp} \\neq 0$. $L_{pp}$ is the pivot in this case, and it is guaranteed to be non-zero for an SPD matrix.\n\n**3. Application to the Hilbert Matrix**\n\nThe Hilbert matrix $H_n$ is defined by $[H_n]_{ij} = \\frac{1}{i+j-1}$ for $1 \\le i, j \\le n$. This matrix is symmetric and positive definite. This property is critical because it ensures that LU factorization without pivoting is numerically stable. For general matrices, this is not true, and pivoting is required to control element growth and avoid division by zero or small numbers. For SPD matrices, the growth factor is bounded, and significant growth in the magnitudes of elements of $L$ and $U$ relative to the elements of $A$ is not expected. Since $\\max_{i,j} |[H_n]_{ij}| = [H_n]_{11} = 1$, the computed maximal magnitudes $g_L = \\max_{i,j} |L_{ij}|$ and $g_U = \\max_{i,j} |U_{ij}|$ directly serve as measures of element growth.\n\nFor symmetric matrices, the Doolittle and Crout factorizations are closely related. If $A = A^T$, then the Doolittle factorization $A = L^{(D)}U^{(D)}$ implies $A=A^T=(U^{(D)})^T (L^{(D)})^T$. This is another LU-type factorization. By uniqueness, we can establish a relationship. A more direct approach uses the $LDU$ factorization $A = L' D (L')^T$, where $L'$ is unit lower triangular and $D$ is diagonal.\nComparing with Doolittle, $A=L^{(D)} U^{(D)}$, we find $L^{(D)} = L'$ and $U^{(D)} = D(L')^T$.\nComparing with Crout, $A=L^{(C)} U^{(C)}$, we find $L^{(C)} = L'D$ and $U^{(C)} = (L')^T$.\nThis leads to the following relations for a symmetric matrix:\n- $U^{(C)} = (L^{(D)})^T$\n- $L^{(C)} = L^{(D)} \\cdot \\text{diag}(U^{(D)})$\nThis implies that for the Hilbert matrix, we must have $g_U^{(C)} = g_L^{(D)}$. This serves as a valuable consistency check for the implementation.\n\n**4. Computational Implementation and Metrics**\n\nThe program will implement the derived algorithms. For each $n$ in $\\{1, 2, 5, 10\\}$:\n1.  Construct the $n \\times n$ Hilbert matrix $H_n$ using double-precision floating-point numbers. Note that for 0-based array indexing, the entry is $[H_n]_{ij} = \\frac{1}{(i+1)+(j+1)-1} = \\frac{1}{i+j+1}$.\n2.  Compute $H_n = L^{(D)}U^{(D)}$ using the Doolittle algorithm.\n3.  Compute $H_n = L^{(C)}U^{(C)}$ using the Crout algorithm.\n4.  For each factorization, calculate the required metrics:\n    -   $g_L = \\max_{i,j} |L_{ij}|$ and $g_U = \\max_{i,j} |U_{ij}|$.\n    -   The residual norm $r_{\\infty} = \\|H_n - LU\\|_{\\infty}$. This measures the backward error of the factorization. Due to the ill-conditioning of the Hilbert matrix, especially for $n=10$, this residual is a key indicator of the quality of the floating-point computation, even though the underlying algorithm is stable.\n\nThe results will be collated into the specified list-of-lists format for output.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Analyzes LU factorization (Doolittle and Crout) for Hilbert matrices.\n    \"\"\"\n\n    def create_hilbert(n):\n        \"\"\"Constructs an n x n Hilbert matrix.\"\"\"\n        H = np.zeros((n, n), dtype=np.float64)\n        for i in range(n):\n            for j in range(n):\n                H[i, j] = 1.0 / (i + j + 1)\n        return H\n\n    def doolittle_lu(A):\n        \"\"\"\n        Computes the Doolittle LU factorization of matrix A (L is unit lower triangular).\n        Derived from first principles.\n        \"\"\"\n        n = A.shape[0]\n        L = np.eye(n, dtype=np.float64)\n        U = np.zeros((n, n), dtype=np.float64)\n\n        for p in range(n):\n            # Row p of U\n            for j in range(p, n):\n                # Summation part: sum(L[p, k] * U[k, j] for k in 0..p-1)\n                sum_val = np.dot(L[p, :p], U[:p, j])\n                U[p, j] = A[p, j] - sum_val\n\n            # Column p of L\n            if np.abs(U[p, p]) < 1e-16: # Avoid division by zero\n                # This should not happen for a positive definite matrix like Hilbert\n                # but is good practice for a general LU implementation.\n                raise np.linalg.LinAlgError(\"Zero pivot encountered in Doolittle LU\")\n\n            for i in range(p + 1, n):\n                # Summation part: sum(L[i, k] * U[k, p] for k in 0..p-1)\n                sum_val = np.dot(L[i, :p], U[:p, p])\n                L[i, p] = (A[i, p] - sum_val) / U[p, p]\n        \n        return L, U\n\n    def crout_lu(A):\n        \"\"\"\n        Computes the Crout LU factorization of matrix A (U is unit upper triangular).\n        Derived from first principles.\n        \"\"\"\n        n = A.shape[0]\n        L = np.zeros((n, n), dtype=np.float64)\n        U = np.eye(n, dtype=np.float64)\n\n        for p in range(n):\n            # Column p of L\n            for i in range(p, n):\n                # Summation part: sum(L[i, k] * U[k, p] for k in 0..p-1)\n                sum_val = np.dot(L[i, :p], U[:p, p])\n                L[i, p] = A[i, p] - sum_val\n            \n            # Row p of U\n            if np.abs(L[p, p]) < 1e-16: # Avoid division by zero\n                raise np.linalg.LinAlgError(\"Zero pivot encountered in Crout LU\")\n            \n            for j in range(p + 1, n):\n                # Summation part: sum(L[p, k] * U[k, j] for k in 0..p-1)\n                sum_val = np.dot(L[p, :p], U[:p, j])\n                U[p, j] = (A[p, j] - sum_val) / L[p, p]\n        \n        return L, U\n\n    test_cases_n = [1, 2, 5, 10]\n    results = []\n\n    for n in test_cases_n:\n        Hn = create_hilbert(n)\n\n        # Doolittle factorization\n        L_d, U_d = doolittle_lu(Hn)\n        g_L_d = np.max(np.abs(L_d))\n        g_U_d = np.max(np.abs(U_d))\n        residual_d = Hn - L_d @ U_d\n        r_inf_d = np.linalg.norm(residual_d, ord=np.inf)\n\n        # Crout factorization\n        L_c, U_c = crout_lu(Hn)\n        g_L_c = np.max(np.abs(L_c))\n        g_U_c = np.max(np.abs(U_c))\n        residual_c = Hn - L_c @ U_c\n        r_inf_c = np.linalg.norm(residual_c, ord=np.inf)\n        \n        # Assemble result list for this n\n        current_result = [n, g_L_d, g_U_d, g_L_c, g_U_c, r_inf_d, r_inf_c]\n        results.append(current_result)\n\n    # Format the final output string as a list of lists.\n    # The default str() representation of a list is used for the inner lists.\n    output_str = \"[\" + \",\".join([str(res) for res in results]) + \"]\"\n    \n    # Final print statement must be exactly this single line\n    print(output_str)\n\nsolve()\n```", "id": "3249691"}]}