{"hands_on_practices": [{"introduction": "Before analyzing the theoretical limits of pivoting, it is crucial to master the mechanics of the algorithm itself. This exercise provides direct, hands-on practice in applying Gaussian Elimination with Partial Pivoting (GEPP) to a well-structured matrix. By meticulously tracking the row swaps, multipliers, and evolving matrix entries, you will reinforce your understanding of the core procedure and the formal definition of the growth factor [@problem_id:3262489].", "problem": "Consider the square matrix $\\mathbf{A} \\in \\mathbb{R}^{5 \\times 5}$ with entries defined by $a_{ij} = \\max(i,j)$ for $1 \\leq i,j \\leq 5$. Starting from the core definition of Gaussian Elimination with Partial Pivoting (GEPP), which at each step selects as pivot the entry with largest absolute value in the current column among rows not yet eliminated, compute the permutation matrix $\\mathbf{P}$, the unit lower-triangular matrix $\\mathbf{L}$, and the upper-triangular matrix $\\mathbf{U}$ such that $\\mathbf{P}\\mathbf{A} = \\mathbf{L}\\mathbf{U}$. Then, from the formal definition of growth factor in GEPP as the ratio\n$$\\rho \\;=\\; \\frac{\\max_{i,j,k}\\left|a_{ij}^{(k)}\\right|}{\\max_{i,j}\\left|a_{ij}\\right|},$$\nwhere $a_{ij}^{(k)}$ denotes the $(i,j)$-entry after the $k$-th elimination step, determine the exact value of the growth factor for this factorization.\n\nProvide your final answer as the single exact value of the growth factor $\\rho$. Do not include units. Report only the value of $\\rho$ as your final answer.", "solution": "The problem requires the computation of the $PA = LU$ factorization for a specific $5 \\times 5$ matrix $\\mathbf{A}$ using Gaussian Elimination with Partial Pivoting (GEPP), and then determining the growth factor $\\rho$.\n\nFirst, we construct the matrix $\\mathbf{A}$ with entries $a_{ij} = \\max(i, j)$.\n$$\n\\mathbf{A} = \\begin{pmatrix}\n1  2  3  4  5 \\\\\n2  2  3  4  5 \\\\\n3  3  3  4  5 \\\\\n4  4  4  4  5 \\\\\n5  5  5  5  5\n\\end{pmatrix}\n$$\nThis matrix, $\\mathbf{A}$, can be denoted as $\\mathbf{A}^{(0)}$. The denominator of the growth factor is the maximum absolute value of the entries in $\\mathbf{A}$:\n$$\n\\max_{i,j} |a_{ij}| = \\max_{i,j} |a_{ij}^{(0)}| = 5\n$$\n\nWe now perform GEPP step by step, tracking the intermediate matrices $\\mathbf{A}^{(k)}$ and the permutation matrix $\\mathbf{P}$. The matrix $\\mathbf{L}$ will store the multipliers. Let $\\mathbf{P}$ start as the identity matrix $\\mathbf{I}$.\n\n**Step 1: $k=1$ (Elimination of column 1)**\nThe first column of $\\mathbf{A}^{(0)}$ is $\\begin{pmatrix} 1  2  3  4  5 \\end{pmatrix}^T$. The element with the largest absolute value is $a_{51}^{(0)} = 5$. Therefore, we must swap row $1$ and row $5$.\nThe permutation matrix for this step is $\\mathbf{P}_1$. The total permutation matrix is updated: $\\mathbf{P} \\leftarrow \\mathbf{P}_1 \\mathbf{P}$.\nThe state of the matrix after the swap is $\\mathbf{P}_1 \\mathbf{A}^{(0)}$:\n$$\n\\mathbf{P}_1 \\mathbf{A}^{(0)} = \\begin{pmatrix}\n5  5  5  5  5 \\\\\n2  2  3  4  5 \\\\\n3  3  3  4  5 \\\\\n4  4  4  4  5 \\\\\n1  2  3  4  5\n\\end{pmatrix}\n$$\nThe pivot is $5$. The multipliers $l_{i1}$ for $i > 1$ are:\n$l_{21} = 2/5$, $l_{31} = 3/5$, $l_{41} = 4/5$, $l_{51} = 1/5$.\nWe perform the row operations $R_i \\leftarrow R_i - l_{i1} R_1$ for $i=2,3,4,5$:\n$R_2 \\leftarrow R_2 - \\frac{2}{5}R_1 = \\begin{pmatrix} 22345 \\end{pmatrix} - \\begin{pmatrix} 22222 \\end{pmatrix} = \\begin{pmatrix} 00123 \\end{pmatrix}$\n$R_3 \\leftarrow R_3 - \\frac{3}{5}R_1 = \\begin{pmatrix} 33345 \\end{pmatrix} - \\begin{pmatrix} 33333 \\end{pmatrix} = \\begin{pmatrix} 00012 \\end{pmatrix}$\n$R_4 \\leftarrow R_4 - \\frac{4}{5}R_1 = \\begin{pmatrix} 44445 \\end{pmatrix} - \\begin{pmatrix} 44444 \\end{pmatrix} = \\begin{pmatrix} 00001 \\end{pmatrix}$\n$R_5 \\leftarrow R_5 - \\frac{1}{5}R_1 = \\begin{pmatrix} 12345 \\end{pmatrix} - \\begin{pmatrix} 11111 \\end{pmatrix} = \\begin{pmatrix} 01234 \\end{pmatrix}$\n\nThe matrix after the first elimination step is $\\mathbf{A}^{(1)}$:\n$$\n\\mathbf{A}^{(1)} = \\begin{pmatrix}\n5  5  5  5  5 \\\\\n0  0  1  2  3 \\\\\n0  0  0  1  2 \\\\\n0  0  0  0  1 \\\\\n0  1  2  3  4\n\\end{pmatrix}\n$$\nThe maximum absolute value in $\\mathbf{A}^{(1)}$ is $\\max_{i,j} |a_{ij}^{(1)}| = 5$.\n\n**Step 2: $k=2$ (Elimination of column 2)**\nWe examine column $2$ from row $2$ downwards in $\\mathbf{A}^{(1)}$: $\\begin{pmatrix} 0  0  0  1 \\end{pmatrix}^T$. The largest absolute value is $a_{52}^{(1)} = 1$. We swap row $2$ and row $5$.\nThe matrix state after the swap is:\n$$\n\\begin{pmatrix}\n5  5  5  5  5 \\\\\n0  1  2  3  4 \\\\\n0  0  0  1  2 \\\\\n0  0  0  0  1 \\\\\n0  0  1  2  3\n\\end{pmatrix}\n$$\nThe pivot is $a_{22} = 1$. The multipliers $l_{i2}$ for $i > 2$ are:\n$l_{32} = a_{32}/a_{22} = 0/1 = 0$\n$l_{42} = a_{42}/a_{22} = 0/1 = 0$\n$l_{52} = a_{52}/a_{22} = 0/1 = 0$\nSince all multipliers are $0$, no row operations are performed. The matrix after the second step, $\\mathbf{A}^{(2)}$, is the same as the matrix after the swap.\n$$\n\\mathbf{A}^{(2)} = \\begin{pmatrix}\n5  5  5  5  5 \\\\\n0  1  2  3  4 \\\\\n0  0  0  1  2 \\\\\n0  0  0  0  1 \\\\\n0  0  1  2  3\n\\end{pmatrix}\n$$\nThe maximum absolute value in $\\mathbf{A}^{(2)}$ is $\\max_{i,j} |a_{ij}^{(2)}| = 5$.\n\n**Step 3: $k=3$ (Elimination of column 3)**\nWe examine column $3$ from row $3$ downwards in $\\mathbf{A}^{(2)}$: $\\begin{pmatrix} 0  0  1 \\end{pmatrix}^T$. The largest absolute value is $a_{53}^{(2)} = 1$. We swap row $3$ and row $5$.\nThe matrix state after the swap is:\n$$\n\\begin{pmatrix}\n5  5  5  5  5 \\\\\n0  1  2  3  4 \\\\\n0  0  1  2  3 \\\\\n0  0  0  0  1 \\\\\n0  0  0  1  2\n\\end{pmatrix}\n$$\nThe pivot is $a_{33}=1$. The multipliers $l_{i3}$ for $i > 3$ are $l_{43} = 0/1=0$ and $l_{53} = 0/1=0$. No row operations are performed.\n$$\n\\mathbf{A}^{(3)} = \\begin{pmatrix}\n5  5  5  5  5 \\\\\n0  1  2  3  4 \\\\\n0  0  1  2  3 \\\\\n0  0  0  0  1 \\\\\n0  0  0  1  2\n\\end{pmatrix}\n$$\nThe maximum absolute value in $\\mathbf{A}^{(3)}$ is $\\max_{i,j} |a_{ij}^{(3)}| = 5$.\n\n**Step 4: $k=4$ (Elimination of column 4)**\nWe examine column $4$ from row $4$ downwards in $\\mathbf{A}^{(3)}$: $\\begin{pmatrix} 0  1 \\end{pmatrix}^T$. The largest absolute value is $a_{54}^{(3)}=1$. We swap row $4$ and row $5$.\nThe matrix state after the swap is:\n$$\n\\begin{pmatrix}\n5  5  5  5  5 \\\\\n0  1  2  3  4 \\\\\n0  0  1  2  3 \\\\\n0  0  0  1  2 \\\\\n0  0  0  0  1\n\\end{pmatrix}\n$$\nThe pivot is $a_{44}=1$. The multiplier $l_{54}=0/1=0$. No row operation is performed. The final upper-triangular matrix $\\mathbf{U}$ is this matrix.\n$$\n\\mathbf{U} = \\mathbf{A}^{(4)} = \\begin{pmatrix}\n5  5  5  5  5 \\\\\n0  1  2  3  4 \\\\\n0  0  1  2  3 \\\\\n0  0  0  1  2 \\\\\n0  0  0  0  1\n\\end{pmatrix}\n$$\nThe maximum absolute value in $\\mathbf{A}^{(4)}$ is $\\max_{i,j} |a_{ij}^{(4)}| = 5$.\n\nThe overall permutation $\\mathbf{P}$ is the product of the individual permutations: $\\mathbf{P} = \\mathbf{P}_4 \\mathbf{P}_3 \\mathbf{P}_2 \\mathbf{P}_1$. This corresponds to mapping the original rows $(1,2,3,4,5)$ to the final row order $(5,1,2,3,4)$.\n$$\n\\mathbf{P} = \\begin{pmatrix}\n0  0  0  0  1 \\\\\n1  0  0  0  0 \\\\\n0  1  0  0  0 \\\\\n0  0  1  0  0 \\\\\n0  0  0  1  0\n\\end{pmatrix}\n$$\nThe matrix $\\mathbf{L}$ contains the multipliers $l_{ij}$ arranged according to the final permutation.\n$$\n\\mathbf{L} = \\begin{pmatrix}\n1  0  0  0  0 \\\\\n1/5  1  0  0  0 \\\\\n2/5  0  1  0  0 \\\\\n3/5  0  0  1  0 \\\\\n4/5  0  0  0  1\n\\end{pmatrix}\n$$\n\nNow we compute the growth factor $\\rho$. The definition is:\n$$\n\\rho = \\frac{\\max_{i,j,k}\\left|a_{ij}^{(k)}\\right|}{\\max_{i,j}\\left|a_{ij}\\right|}\n$$\nThe numerator is the maximum absolute value found across all entries of all intermediate matrices $\\mathbf{A}^{(k)}$ (for $k=0,1,2,3,4$).\n$\\max |a_{ij}^{(0)}| = 5$\n$\\max |a_{ij}^{(1)}| = 5$\n$\\max |a_{ij}^{(2)}| = 5$\n$\\max |a_{ij}^{(3)}| = 5$\n$\\max |a_{ij}^{(4)}| = 5$\nThus, the overall maximum is $\\max_{i,j,k} |a_{ij}^{(k)}| = 5$.\n\nThe denominator is $\\max_{i,j} |a_{ij}| = 5$.\nTherefore, the growth factor is:\n$$\n\\rho = \\frac{5}{5} = 1\n$$", "answer": "$$\n\\boxed{1}\n$$", "id": "3262489"}, {"introduction": "A common misconception is that matrices with large diagonal entries relative to off-diagonal ones are inherently stable and may not require pivoting. This problem serves as a critical cautionary tale, demonstrating that the need for pivoting is determined by the entries that emerge *during* the elimination process, not just the initial structure of the matrix. By working through this example, you will see how a seemingly well-behaved matrix can generate intermediate values that compel a row swap to preserve numerical stability [@problem_id:3262474].", "problem": "Consider the matrix $A \\in \\mathbb{R}^{3 \\times 3}$ given by\n$$\nA \\;=\\; \\begin{pmatrix}\n1  \\frac{9}{10}  0 \\\\\n\\frac{9}{10}  1  0 \\\\\n\\frac{1}{5}  \\frac{4}{5}  1\n\\end{pmatrix}.\n$$\nAll diagonal entries are $1$ and all off-diagonal entries have magnitude strictly less than $1$. Apply Gaussian Elimination with Partial Pivoting (GEPP). Starting from the fundamental definition of partial pivoting (at each step, among the active rows, select as pivot the entry of largest magnitude in the current column and swap the current row with that pivot row if necessary), reason from first principles to:\n- Determine whether GEPP performs a row swap at the second elimination step, and justify why.\n- Complete the elimination to obtain the upper-triangular factor $U$.\n- Using the core definition of element growth factor for GEPP as the ratio of the largest-magnitude entry produced in the upper-triangular factor $U$ to the largest-magnitude entry of the original matrix $A$, compute this growth factor as an exact value.\n\nProvide your final answer as a single real number. No rounding is required.", "solution": "The problem is validated as scientifically grounded, well-posed, and objective. It is a standard problem in numerical linear algebra. We will proceed with the solution by applying Gaussian Elimination with Partial Pivoting (GEPP) from first principles.\n\nThe initial matrix is given by:\n$$ A = A^{(1)} = \\begin{pmatrix} 1  \\frac{9}{10}  0 \\\\ \\frac{9}{10}  1  0 \\\\ \\frac{1}{5}  \\frac{4}{5}  1 \\end{pmatrix} $$\n\n**Step 1: Elimination for column $k=1$**\n\nAccording to the GEPP algorithm, we first identify the pivot element in the first column. We examine the entries on or below the diagonal in this column: $a_{11}^{(1)}$, $a_{21}^{(1)}$, and $a_{31}^{(1)}$.\nThe values are $1$, $\\frac{9}{10}$, and $\\frac{1}{5}$. We compare their absolute values:\n$$ |a_{11}^{(1)}| = 1 $$\n$$ |a_{21}^{(1)}| = \\frac{9}{10} = 0.9 $$\n$$ |a_{31}^{(1)}| = \\frac{1}{5} = 0.2 $$\nThe entry with the largest magnitude is $a_{11}^{(1)} = 1$, which is already in the pivot position (row $1$, column $1$). Therefore, no row swap is necessary at this step.\n\nWe proceed with elimination. The multipliers are calculated as:\n$$ m_{21} = \\frac{a_{21}^{(1)}}{a_{11}^{(1)}} = \\frac{9/10}{1} = \\frac{9}{10} $$\n$$ m_{31} = \\frac{a_{31}^{(1)}}{a_{11}^{(1)}} = \\frac{1/5}{1} = \\frac{1}{5} $$\n\nWe update the matrix by performing the row operations $R_2 \\leftarrow R_2 - m_{21} R_1$ and $R_3 \\leftarrow R_3 - m_{31} R_1$.\nThe new entries of the matrix, denoted as $A^{(2)}$, are:\nFor row $2$:\n$a_{22}^{(2)} = a_{22}^{(1)} - m_{21} a_{12}^{(1)} = 1 - \\left(\\frac{9}{10}\\right)\\left(\\frac{9}{10}\\right) = 1 - \\frac{81}{100} = \\frac{19}{100}$\n$a_{23}^{(2)} = a_{23}^{(1)} - m_{21} a_{13}^{(1)} = 0 - \\left(\\frac{9}{10}\\right)(0) = 0$\nFor row $3$:\n$a_{32}^{(2)} = a_{32}^{(1)} - m_{31} a_{12}^{(1)} = \\frac{4}{5} - \\left(\\frac{1}{5}\\right)\\left(\\frac{9}{10}\\right) = \\frac{4}{5} - \\frac{9}{50} = \\frac{40}{50} - \\frac{9}{50} = \\frac{31}{50}$\n$a_{33}^{(2)} = a_{33}^{(1)} - m_{31} a_{13}^{(1)} = 1 - \\left(\\frac{1}{5}\\right)(0) = 1$\n\nAfter the first step of elimination, the matrix is:\n$$ A^{(2)} = \\begin{pmatrix} 1  \\frac{9}{10}  0 \\\\ 0  \\frac{19}{100}  0 \\\\ 0  \\frac{31}{50}  1 \\end{pmatrix} $$\n\n**Step 2: Elimination for column $k=2$ and determination of row swap**\n\nNow we consider the second column. The pivot selection is performed on the sub-column consisting of entries on or below the diagonal, which are $a_{22}^{(2)}$ and $a_{32}^{(2)}$. We compare their absolute values:\n$$ |a_{22}^{(2)}| = \\left|\\frac{19}{100}\\right| = \\frac{19}{100} = 0.19 $$\n$$ |a_{32}^{(2)}| = \\left|\\frac{31}{50}\\right| = \\frac{31}{50} = \\frac{62}{100} = 0.62 $$\nSince $|a_{32}^{(2)}| > |a_{22}^{(2)}|$, GEPP requires a row swap. The pivot must be the entry with the largest magnitude, which is $a_{32}^{(2)}$.\n\n**Justification for the second-step row swap:**\nYes, a row swap is performed at the second elimination step. This is because the partial pivoting strategy mandates selecting the element of largest magnitude in the current column (from the diagonal downwards) as the pivot. At step $k=2$, the candidates for the pivot in column $2$ were $a_{22}^{(2)} = \\frac{19}{100}$ and $a_{32}^{(2)} = \\frac{31}{50}$. As $|\\frac{31}{50}| > |\\frac{19}{100}|$, the element in row $3$ must be brought into the pivot position (row $2$, column $2$) by swapping row $2$ and row $3$.\n\nWe perform the swap $R_2 \\leftrightarrow R_3$. The matrix becomes:\n$$ A'^{(2)} = \\begin{pmatrix} 1  \\frac{9}{10}  0 \\\\ 0  \\frac{31}{50}  1 \\\\ 0  \\frac{19}{100}  0 \\end{pmatrix} $$\nThe new pivot is $a_{22}'^{(2)} = \\frac{31}{50}$. The multiplier to eliminate the element below the pivot is:\n$$ m_{32} = \\frac{a_{32}'^{(2)}}{a_{22}'^{(2)}} = \\frac{19/100}{31/50} = \\frac{19}{100} \\cdot \\frac{50}{31} = \\frac{19}{2 \\cdot 31} = \\frac{19}{62} $$\nWe perform the row operation $R_3 \\leftarrow R_3 - m_{32} R_2$:\n$a_{33}^{(3)} = a_{33}'^{(2)} - m_{32} a_{23}'^{(2)} = 0 - \\left(\\frac{19}{62}\\right)(1) = -\\frac{19}{62}$\n\nThe elimination process is now complete. The resulting upper-triangular matrix, $U$, is:\n$$ U = A^{(3)} = \\begin{pmatrix} 1  \\frac{9}{10}  0 \\\\ 0  \\frac{31}{50}  1 \\\\ 0  0  -\\frac{19}{62} \\end{pmatrix} $$\n\n**Step 3: Computation of the growth factor**\n\nThe problem defines the growth factor, $\\rho$, as the ratio of the largest-magnitude entry in $U$ to the largest-magnitude entry in the original matrix $A$.\n$$ \\rho = \\frac{\\max_{i,j} |u_{ij}|}{\\max_{i,j} |a_{ij}|} $$\n\nFirst, we find the largest-magnitude entry in $A$:\n$$ \\max_{i,j} |a_{ij}| = \\max\\left\\{|1|, \\left|\\frac{9}{10}\\right|, |0|, \\left|\\frac{9}{10}\\right|, |1|, |0|, \\left|\\frac{1}{5}\\right|, \\left|\\frac{4}{5}\\right|, |1|\\right\\} = \\max\\left\\{1, \\frac{9}{10}, 0, \\frac{1}{5}, \\frac{4}{5}\\right\\} = 1 $$\n\nNext, we find the largest-magnitude entry in $U$:\n$$ \\max_{i,j} |u_{ij}| = \\max\\left\\{|1|, \\left|\\frac{9}{10}\\right|, |0|, \\left|\\frac{31}{50}\\right|, |1|, \\left|-\\frac{19}{62}\\right|\\right\\} = \\max\\left\\{1, 0.9, 0, 0.62, 1, \\frac{19}{62}\\right\\} $$\nSince $\\frac{19}{62} \\approx 0.306$, the maximum value in this set is $1$.\n$$ \\max_{i,j} |u_{ij}| = 1 $$\n\nFinally, we compute the growth factor:\n$$ \\rho = \\frac{1}{1} = 1 $$\n\nThe growth factor is exactly $1$.", "answer": "$$\\boxed{1}$$", "id": "3262474"}, {"introduction": "While partial pivoting is an essential strategy for controlling error, it is not a panacea. A critical question in numerical analysis is how large the growth factor $\\rho$ can become even when this strategy is employed. This advanced exercise challenges you to analyze a classic family of matrices for which partial pivoting, despite being correctly applied, still permits a growth factor that increases linearly with the matrix dimension $n$. By deriving this result analytically, you will gain a deeper appreciation for the theoretical limitations of partial pivoting and the motivation behind more robust, albeit more expensive, strategies like complete pivoting [@problem_id:3262594].", "problem": "Let $n \\geq 3$ be an integer. In Gaussian elimination with partial pivoting (where at each step the pivot is chosen as the largest-by-magnitude entry in the current column among the remaining rows, with ties broken in favor of the smallest row index), the growth factor is defined as the ratio of the largest magnitude entry ever produced in the upper triangular factor to the largest magnitude entry in the original matrix. Equivalently, if $P A = L U$ is the factorization produced by Gaussian elimination with partial pivoting (so $P$ is a permutation matrix, $L$ is unit lower triangular, and $U$ is upper triangular), the growth factor is $\\gamma(A) = \\max_{i,j} |u_{ij}| \\big/ \\max_{i,j} |a_{ij}|$.\n\nConstruct an explicit $n \\times n$ matrix $A_n$ whose growth factor $\\gamma(A_n)$ under partial pivoting is large as $n$ increases, but such that $\\det(A_n) = 1$ holds exactly. Your construction must rely only on core definitions and well-tested facts such as the multiplicativity of the determinant over block diagonal matrices and the invariance of the determinant under adding a multiple of one row to another.\n\nConsider the $(n-1) \\times (n-1)$ matrix $W_{n-1}$ defined by\n- $w_{ii} = 1$ for $1 \\leq i \\leq n-1$,\n- $w_{i+1,i} = -1$ for $1 \\leq i \\leq n-2$,\n- $w_{i,\\,n-1} = 1$ for $1 \\leq i \\leq n-1$,\n- and $w_{ij} = 0$ otherwise,\nand define\n$$\nA_n \\;=\\; \\operatorname{diag}\\!\\Big(W_{n-1},\\, \\frac{1}{\\,n-1\\,}\\Big),\n$$\nthe block diagonal matrix whose top-left block is $W_{n-1}$ and bottom-right block is the $1 \\times 1$ matrix $\\big[\\tfrac{1}{n-1}\\big]$.\n\nStarting from the given definitions and facts, derive the determinant of $A_n$, analyze the Gaussian elimination with partial pivoting on $A_n$, and determine the exact closed-form expression for the growth factor $\\gamma(A_n)$ as a function of $n$. Provide your final answer as a single analytical expression. No rounding is required.", "solution": "The problem requires the analysis of a specific $n \\times n$ matrix $A_n$ for $n \\geq 3$. We must first validate the problem statement. The problem is well-defined within the standard framework of numerical linear algebra. It provides an explicit construction for the matrix $A_n$, defines all terms such as partial pivoting and growth factor, and poses a clear objective: to derive the determinant and the growth factor for this matrix. The problem is scientifically sound, self-contained, and objective. It is a valid problem.\n\nWe proceed with the solution, which consists of two main parts: calculating the determinant of $A_n$ and analyzing the process of Gaussian elimination with partial pivoting to find the growth factor.\n\nThe matrix $A_n$ is defined as a block diagonal matrix:\n$$\nA_n = \\operatorname{diag}\\!\\Big(W_{n-1},\\, \\frac{1}{\\,n-1\\,}\\Big)\n$$\nwhere $W_{n-1}$ is an $(n-1) \\times (n-1)$ matrix with entries defined as:\n$w_{ii} = 1$ for $1 \\leq i \\leq n-1$\n$w_{i+1,i} = -1$ for $1 \\leq i \\leq n-2$\n$w_{i,n-1} = 1$ for $1 \\leq i \\leq n-1$\n$w_{ij} = 0$ otherwise.\n\nFor example, for $n=4$, the matrix $W_3$ is:\n$$\nW_3 = \\begin{pmatrix} 1  0  1 \\\\ -1  1  1 \\\\ 0  -1  1 \\end{pmatrix}\n$$\nAnd $A_4$ is:\n$$\nA_4 = \\begin{pmatrix} 1  0  1  0 \\\\ -1  1  1  0 \\\\ 0  -1  1  0 \\\\ 0  0  0  \\frac{1}{3} \\end{pmatrix}\n$$\n\n**1. Determinant of $A_n$**\n\nSince $A_n$ is a block diagonal matrix, its determinant is the product of the determinants of its diagonal blocks.\n$$\n\\det(A_n) = \\det(W_{n-1}) \\cdot \\det\\left(\\left[\\frac{1}{n-1}\\right]\\right) = \\frac{1}{n-1} \\det(W_{n-1})\n$$\nTo calculate $\\det(W_{n-1})$, we can use cofactor expansion along the first column of $W_{n-1}$. The only non-zero entries in the first column are $w_{11}=1$ and $w_{21}=-1$.\n$$\n\\det(W_{n-1}) = 1 \\cdot \\det(M_{11}) - (-1) \\cdot \\det(M_{21}) = \\det(M_{11}) + \\det(M_{21})\n$$\nwhere $M_{ij}$ is the minor corresponding to the entry $w_{ij}$.\n\nThe minor $M_{11}$ is obtained by removing the first row and first column of $W_{n-1}$. The resulting $(n-2) \\times (n-2)$ matrix has the same structure as $W_{n-1}$, but with dimension $n-2$. Thus, $M_{11} = W_{n-2}$. Let $d_k = \\det(W_k)$. Then $\\det(M_{11}) = d_{n-2}$.\n\nThe minor $M_{21}$ is obtained by removing the second row and first column of $W_{n-1}$.\n$$\nM_{21} = \\begin{pmatrix}\n0  0  \\dots  0  1 \\\\\n-1  1  \\dots  0  1 \\\\\n0  -1  \\ddots  \\vdots  1 \\\\\n\\vdots   \\ddots  1  \\vdots \\\\\n0  \\dots  0  -1  1\n\\end{pmatrix}_{(n-2) \\times (n-2)}\n$$\nWe can compute the determinant of $M_{21}$ by cofactor expansion along its first row. The only non-zero entry is $1$ in the last column (column $n-2$).\n$$\n\\det(M_{21}) = (-1)^{1+(n-2)} \\cdot 1 \\cdot \\det(M'_{1,n-2})\n$$\nwhere $M'_{1,n-2}$ is the submatrix obtained by removing the first row and last column of $M_{21}$. This submatrix is a lower triangular matrix of size $(n-3) \\times (n-3)$ with all diagonal entries equal to $-1$.\n$$\nM'_{1,n-2} = \\begin{pmatrix}\n-1  1  0  \\dots \\\\\n0  -1  1  \\dots \\\\\n\\vdots  \\ddots  \\ddots  \\ddots \\\\\n0  \\dots  0  -1\n\\end{pmatrix}\n$$\nThe determinant of a triangular matrix is the product of its diagonal entries, so $\\det(M'_{1,n-2}) = (-1)^{n-3}$.\nTherefore, $\\det(M_{21}) = (-1)^{n-1} \\cdot (-1)^{n-3} = (-1)^{2n-4} = 1$.\n\nWe have established the recurrence relation $d_{n-1} = d_{n-2} + 1$.\nFor the base case, we consider $W_1 = [1]$, so $d_1 = 1$. The recurrence gives $d_2 = d_1+1 = 2$. Let's check this directly: $W_2 = \\begin{pmatrix} 1  1 \\\\ -1  1 \\end{pmatrix}$, so $d_2 = 1 \\cdot 1 - 1 \\cdot (-1) = 2$. The recurrence holds.\nUnfolding the recurrence, we get $d_k = d_{k-1}+1 = d_{k-2}+2 = \\dots = d_1 + (k-1) = 1 + k - 1 = k$.\nThus, $\\det(W_{n-1}) = n-1$.\n\nFinally, the determinant of $A_n$ is:\n$$\n\\det(A_n) = \\frac{1}{n-1} \\det(W_{n-1}) = \\frac{n-1}{n-1} = 1\n$$\n\n**2. Growth Factor of $A_n$**\n\nThe growth factor is $\\gamma(A_n) = \\max_{i,j} |u_{ij}| / \\max_{i,j} |a_{ij}|$.\nFirst, we find the maximum magnitude entry in $A_n$. The entries of $A_n$ are from the set $\\{0, 1, -1, 1/(n-1)\\}$. Since $n \\geq 3$, we have $0  1/(n-1) \\leq 1/2$. The maximum absolute value is $\\max_{i,j} |a_{ij}| = 1$.\n\nNext, we perform Gaussian elimination with partial pivoting on $A_n$. Due to the block diagonal structure, the elimination process on the first $n-1$ rows and columns only involves the $W_{n-1}$ block. Let $A^{(k)}$ denote the matrix after step $k-1$ of elimination. We start with $A^{(1)} = W_{n-1}$.\n\nStep $k$ ($1 \\le k \\le n-2$): At the beginning of step $k$, the matrix is $A^{(k)}$. The pivot column is column $k$. For $j \\geq k$, the entries below the diagonal in column $j$ are the same as in the original matrix $W_{n-1}$. Specifically, for the current pivot column $k$, the entries from row $k$ downwards are $(a_{kk}^{(k)}, a_{k+1,k}^{(k)}, \\dots)^T$. The only non-zero entry below the pivot is $a_{k+1,k}^{(k)} = -1$. The pivot element itself is $a_{kk}^{(k)} = 1$. The maximum magnitude in the pivot column (from row $k$ down) is $1$. Thus, $a_{kk}^{(k)}$ is chosen as the pivot for every step $k$. No row interchanges occur, so the permutation matrix $P$ is the identity matrix $I$. The multiplier is $m_{k+1,k} = a_{k+1,k}^{(k)}/a_{kk}^{(k)} = -1/1 = -1$. The row operation is $R_{k+1} \\leftarrow R_{k+1} - m_{k+1,k}R_k = R_{k+1} + R_k$.\n\nThe entries of the upper triangular matrix $U$ (which for $A_n$ is $\\operatorname{diag}(U_W, 1/(n-1))$ where $U_W$ is the result of elimination on $W_{n-1}$) are generated by these row operations. The largest entries appear in the last column of the $W_{n-1}$ block. Let $u_{i,j}$ denote the entries of $U_W$.\nInitially, all entries in the last column of $W_{n-1}$ are $1$.\nAfter step 1 ($R_2 \\leftarrow R_2+R_1$): the entry $u_{2,n-1}$ becomes $w_{2,n-1} + w_{1,n-1} = 1+1=2$.\nAfter step 2 ($R_3 \\leftarrow R_3+R_2$): the entry $u_{3,n-1}$ becomes $w_{3,n-1} + u_{2,n-1} = 1+2=3$.\nIn general, at step $k$, the operation $R_{k+1} \\leftarrow R_{k+1}+R_k$ is performed on the current matrix. Let $a_{i,j}^{(k+1)}$ be the entries of the matrix after this operation. The entry in the last column of row $k+1$ becomes:\n$$\na_{k+1,n-1}^{(k+1)} = a_{k+1,n-1}^{(k)} + a_{k,n-1}^{(k)}\n$$\nBefore this operation, $a_{k+1,n-1}^{(k)}$ is still the original value $1$, and $a_{k,n-1}^{(k)}$ is the value computed in the previous step. For $i \\leq k$, the entry $a_{i, n-1}^{(k)}$ is final, $u_{i,n-1} = a_{i,n-1}^{(i)}$. The recurrence for the final values in the last column is $u_{i,n-1} = 1 + u_{i-1, n-1}$ for $i \\ge 2$, with $u_{1,n-1}=1$. This gives $u_{i,n-1}=i$ for $i=1, \\dots, n-2$.\n\nThe final matrix $U_W$ is formed after $n-2$ steps. At step $n-2$, the operation is $R_{n-1} \\leftarrow R_{n-1}+R_{n-2}$. All entries in row $n-2$ are final at this point. The update for the last entry of row $n-1$ (which is $u_{n-1,n-1}$) is:\n$$\nu_{n-1,n-1} = a_{n-1,n-1}^{(n-2)} + a_{n-2,n-1}^{(n-2)}\n$$\nHere, $a_{n-1,n-1}^{(n-2)}$ is the original entry $w_{n-1,n-1}=1$, and $a_{n-2,n-1}^{(n-2)}$ is the final value $u_{n-2,n-1}=n-2$.\nThus, $u_{n-1,n-1} = 1 + (n-2) = n-1$.\n\nThe upper triangular matrix $U$ resulting from the elimination on $A_n$ is:\n$$\nU = \\begin{pmatrix}\n1  0  \\dots  0  1  0 \\\\\n0  1  \\dots  0  2  0 \\\\\n\\vdots   \\ddots   \\vdots  \\vdots \\\\\n0  0  \\dots  1  n-2  0 \\\\\n0  0  \\dots  0  n-1  0 \\\\\n0  0  \\dots  0  0  \\frac{1}{n-1}\n\\end{pmatrix}\n$$\nThe entries of $U$ are $\\{0, 1, 2, \\dots, n-1\\}$ and $\\{1/(n-1)\\}$. Since $n \\geq 3$, $n-1 \\geq 2$. The maximum magnitude among all entries of $U$ is $\\max_{i,j} |u_{ij}| = n-1$.\n\nThe growth factor is therefore:\n$$\n\\gamma(A_n) = \\frac{\\max_{i,j} |u_{ij}|}{\\max_{i,j} |a_{ij}|} = \\frac{n-1}{1} = n-1\n$$\nThis demonstrates that for the given matrix family $A_n$, the growth factor increases linearly with the size of the matrix, even under partial pivoting. Furthermore, the determinant of these matrices is exactly $1$.", "answer": "$$\\boxed{n-1}$$", "id": "3262594"}]}