{"hands_on_practices": [{"introduction": "Newton's method is not just a tool for finding roots of pre-defined functions; it's a powerful framework for designing efficient algorithms. This exercise challenges you to think like a numerical analyst by formulating the common problem of computing a reciprocal, $1/a$, as a root-finding task. By starting from the geometric interpretation of the method and choosing a clever function whose root is $1/a$, you will derive an iteration that surprisingly avoids division entirely, relying only on multiplication and subtraction [@problem_id:3234392]. This classic example showcases the elegance and practical utility of Newton's method in scientific computing.", "problem": "Consider a fixed real scalar $a \\neq 0$ and the task of computing its reciprocal $1/a$ using only multiplication and subtraction. Using the geometric interpretation of Newton’s method as the intersection of the tangent line of a function $f$ at the current iterate with the $x$-axis, formulate the computation of $1/a$ as a root-finding problem for a suitably chosen scalar function $f$ whose evaluation and Newton update can be algebraically reduced to an iteration that uses only multiplication and subtraction.\n\nStarting from the geometric definition of the Newton step (tangent-line $x$-intercept), proceed from first principles to:\n\n- Select a function $f$ with a simple root at $x^{\\star} = 1/a$.\n- Derive the explicit Newton iteration map $N_{a}(x)$ and simplify it algebraically to a form that uses only multiplication and subtraction.\n- Define the error $e_{k} = x_{k} - x^{\\star}$ and derive the exact quadratic error recurrence $e_{k+1} = C\\, e_{k}^{2}$ in a neighborhood of $x^{\\star}$, identifying the constant $C$ in terms of $a$.\n- Assume $a > 0$ and an initial guess $x_{0}$ satisfying $0 < a x_{0} < 2$ to ensure that all iterates remain well-defined and that the Newton step is geometrically meaningful.\n\nGive your final answer as the exact closed-form expression for the constant $C$ (no units). No numerical rounding is required.", "solution": "The problem requires the formulation of an iterative method to compute the reciprocal $1/a$ of a non-zero scalar $a$ using only multiplication and subtraction, based on the geometric interpretation of Newton's method. This involves selecting an appropriate function $f(x)$ whose root is the desired value, deriving the Newton iteration, and analyzing its error propagation to determine the quadratic convergence constant $C$.\n\n**Step 1: Problem Validation**\n\nThe problem is first validated against the required criteria.\n\n*   **Extraction of Givens**:\n    *   A fixed real scalar $a \\neq 0$.\n    *   Task: Compute $1/a$ using only multiplication and subtraction.\n    *   Method: Geometric interpretation of Newton's method.\n    *   The problem is to be formulated as a root-finding problem for a function $f(x)$.\n    *   The root of $f(x)$ must be $x^{\\star} = 1/a$.\n    *   The iteration map $N_a(x)$ must be simplified to a form using only multiplication and subtraction.\n    *   The error is defined as $e_k = x_k - x^{\\star}$.\n    *   The task is to derive the error recurrence $e_{k+1} = C \\, e_k^2$ and find the constant $C$.\n    *   An assumption for convergence is given: $a > 0$ and an initial guess $x_0$ satisfying $0 < a x_0 < 2$.\n\n*   **Validation Verdict**:\n    *   **Scientifically Grounded**: The problem is a standard application of Newton's method for root-finding, a fundamental topic in numerical analysis. The concepts of iteration, convergence, and error analysis are mathematically sound.\n    *   **Well-Posed**: The problem is clearly stated, provides all necessary information and conditions (including a convergence criterion), and leads to a unique, well-defined solution for the constant $C$.\n    *   **Objective**: The problem is stated in precise, objective mathematical language.\n\nThe problem is valid as it is mathematically sound, well-posed, and objective. We may proceed with the solution.\n\n**Step 2: Selection of an Appropriate Function $f(x)$**\n\nThe goal is to find $x^{\\star} = 1/a$. We need a function $f(x)$ such that $f(x^{\\star}) = f(1/a) = 0$. A simple choice that leads to the desired algebraic form for the iteration is:\n$$\nf(x) = a - \\frac{1}{x}\n$$\nClearly, $f(1/a) = a - 1/(1/a) = a - a = 0$. The root is a simple root because the derivative at the root is non-zero.\n\n**Step 3: Geometric Derivation and Simplification of the Newton Iteration**\n\nNewton's method finds the root of a function by iteratively finding the $x$-intercept of the tangent line to the function's graph at the current estimate. The equation of the tangent line to the curve $y = f(x)$ at the point $(x_k, f(x_k))$ is given by:\n$$\ny - f(x_k) = f'(x_k) (x - x_k)\n$$\nThe next iterate, $x_{k+1}$, is the $x$-intercept of this line, which is found by setting $y=0$:\n$$\n0 - f(x_k) = f'(x_k) (x_{k+1} - x_k)\n$$\nSolving for $x_{k+1}$ gives the general formula for Newton's method:\n$$\nx_{k+1} = x_k - \\frac{f(x_k)}{f'(x_k)}\n$$\nFor our chosen function $f(x) = a - x^{-1}$, the derivative is:\n$$\nf'(x) = \\frac{d}{dx} (a - x^{-1}) = -(-1)x^{-2} = \\frac{1}{x^2}\n$$\nSubstituting $f(x_k)$ and $f'(x_k)$ into the Newton iteration formula:\n$$\nx_{k+1} = x_k - \\frac{a - \\frac{1}{x_k}}{\\frac{1}{x_k^2}}\n$$\nTo simplify this expression and eliminate division, we multiply the numerator and denominator of the fraction by $x_k^2$:\n$$\nx_{k+1} = x_k - x_k^2 \\left(a - \\frac{1}{x_k}\\right)\n$$\nDistributing the $x_k^2$ term:\n$$\nx_{k+1} = x_k - (a x_k^2 - x_k^2 \\cdot \\frac{1}{x_k})\n$$\n$$\nx_{k+1} = x_k - (a x_k^2 - x_k)\n$$\n$$\nx_{k+1} = x_k - a x_k^2 + x_k\n$$\nThis simplifies to the iteration map $N_a(x_k)$:\n$$\nx_{k+1} = 2 x_k - a x_k^2\n$$\nThis expression can also be written as $x_{k+1} = x_k(2 - a x_k)$, which confirms that it uses only multiplication and subtraction, as required.\n\n**Step 4: Derivation of the Error Recurrence Relation**\n\nThe root is $x^{\\star} = 1/a$. The error at iteration $k$ is defined as $e_k = x_k - x^{\\star} = x_k - 1/a$. This implies $x_k = e_k + 1/a$. The error at the next iteration is $e_{k+1} = x_{k+1} - x^{\\star} = x_{k+1} - 1/a$.\n\nWe substitute the iteration map for $x_{k+1}$:\n$$\ne_{k+1} = \\left(2 x_k - a x_k^2\\right) - \\frac{1}{a}\n$$\nNow, we express the right-hand side in terms of the error $e_k$ by substituting $x_k = e_k + 1/a$:\n$$\ne_{k+1} = 2\\left(e_k + \\frac{1}{a}\\right) - a\\left(e_k + \\frac{1}{a}\\right)^2 - \\frac{1}{a}\n$$\nExpand the terms:\n$$\ne_{k+1} = 2e_k + \\frac{2}{a} - a\\left(e_k^2 + \\frac{2e_k}{a} + \\frac{1}{a^2}\\right) - \\frac{1}{a}\n$$\nDistribute the $-a$ term:\n$$\ne_{k+1} = 2e_k + \\frac{2}{a} - a e_k^2 - a\\left(\\frac{2e_k}{a}\\right) - a\\left(\\frac{1}{a^2}\\right) - \\frac{1}{a}\n$$\n$$\ne_{k+1} = 2e_k + \\frac{2}{a} - a e_k^2 - 2e_k - \\frac{1}{a} - \\frac{1}{a}\n$$\nCombine like terms. The terms involving $e_k$ cancel out ($2e_k - 2e_k = 0$). The constant terms also cancel out ($2/a - 1/a - 1/a = 0$).\n$$\ne_{k+1} = (2e_k - 2e_k) + \\left(\\frac{2}{a} - \\frac{1}{a} - \\frac{1}{a}\\right) - a e_k^2\n$$\n$$\ne_{k+1} = -a e_k^2\n$$\nThis is the exact error recurrence relation. Comparing this to the specified form $e_{k+1} = C \\, e_k^2$, we can identify the constant $C$.\n\n**Step 5: Identification of the Constant $C$**\n\nBy direct comparison of the derived error relation $e_{k+1} = -a e_k^2$ with the general form $e_{k+1} = C e_k^2$, the constant $C$ is found to be:\n$$\nC = -a\n$$\nThe convergence condition $0 < a x_0 < 2$ translates to $-1 < a e_0 < 1$, which ensures that $|a e_k| < 1$ for all $k \\geq 0$, leading to quadratic convergence of $x_k$ to $1/a$.", "answer": "$$\\boxed{-a}$$", "id": "3234392"}, {"introduction": "A deep understanding of any algorithm requires knowing not only when it works, but also when and why it fails. This exercise explores a fundamental failure mode of Newton's method by applying it to a function, $f(x)=1/x$, that has no real root. By tracing the geometric construction of the tangent line and its x-intercept, you will discover that the iterates do not converge but instead diverge in a predictable, exponential fashion [@problem_id:3234385]. This practice provides a stark and memorable illustration of how the method's core assumption—the existence of a root—is essential for convergence.", "problem": "Consider the scalar nonlinear equation $f(x)=0$ with $f(x)=\\frac{1}{x}$ on the domain $\\{x \\in \\mathbb{R} : x \\neq 0\\}$. Although $f(x)=\\frac{1}{x}$ has no real solution, suppose we nonetheless apply the geometric construction underlying Newton’s method: at an iterate $x_{n}$, form the tangent line to $f$ at $x_{n}$ and take its $x$-intercept as the next iterate $x_{n+1}$. Use only the definition of the derivative as the slope of the tangent line and the equation of a line to derive the iteration produced by this construction for general $x_{n} \\neq 0$. Then, by induction or direct reasoning, express $x_{n}$ in closed form as a function of $n$ and the initial guess $x_{0} \\neq 0$. In your reasoning, interpret the geometry of the tangent construction for this $f$ and explain why quadratic convergence cannot occur in this setting.\n\nProvide your final answer as a single closed-form analytic expression for $x_{n}$ in terms of $n$ and $x_{0}$. No numerical rounding is required, and no units are involved.", "solution": "The problem asks for a three-part analysis of Newton's method applied to the function $f(x) = \\frac{1}{x}$, which has no real root for the equation $f(x)=0$. First, we must derive the iteration formula from the geometric definition. Second, we must find a closed-form expression for the $n$-th iterate $x_n$. Third, we must interpret the geometry and explain the lack of quadratic convergence.\n\n**Part 1: Derivation of the Iteration Formula**\n\nThe geometric construction of Newton's method defines the next iterate, $x_{n+1}$, as the $x$-intercept of the tangent line to the function's graph at the current iterate, $x_n$.\n\nThe function is given by $f(x) = \\frac{1}{x}$.\nThe point on the curve at the iterate $x_n$ is $(x_n, f(x_n))$, which is $(x_n, \\frac{1}{x_n})$.\n\nTo find the equation of the tangent line, we need its slope, which is given by the derivative of $f(x)$ evaluated at $x_n$. The derivative of $f(x)$ is:\n$$ f'(x) = \\frac{d}{dx}\\left(x^{-1}\\right) = -1 \\cdot x^{-2} = -\\frac{1}{x^2} $$\nThe slope, $m$, of the tangent line at $x_n$ is therefore:\n$$ m = f'(x_n) = -\\frac{1}{x_n^2} $$\nUsing the point-slope form of a line, $y - y_1 = m(x - x_1)$, the equation of the tangent line at $(x_n, \\frac{1}{x_n})$ is:\n$$ y - \\frac{1}{x_n} = -\\frac{1}{x_n^2} (x - x_n) $$\nThe next iterate, $x_{n+1}$, is the $x$-intercept of this line. We find the $x$-intercept by setting $y=0$ and solving for $x$, which we will call $x_{n+1}$:\n$$ 0 - \\frac{1}{x_n} = -\\frac{1}{x_n^2} (x_{n+1} - x_n) $$\nWe can simplify this equation to solve for $x_{n+1}$. First, multiply both sides by $-x_n^2$:\n$$ \\left(-\\frac{1}{x_n}\\right) \\cdot (-x_n^2) = \\left(-\\frac{1}{x_n^2} (x_{n+1} - x_n)\\right) \\cdot (-x_n^2) $$\n$$ x_n = x_{n+1} - x_n $$\nSolving for $x_{n+1}$, we get:\n$$ x_{n+1} = x_n + x_n = 2x_n $$\nThis is the iteration formula produced by the geometric construction for the function $f(x)=\\frac{1}{x}$.\n\n**Part 2: Closed-Form Expression for $x_n$**\n\nThe iteration is a simple linear recurrence relation: $x_{n+1} = 2x_n$. This describes a geometric progression. We can find the closed-form expression by observing the pattern for the first few iterates, starting from an initial guess $x_0 \\neq 0$:\nFor $n=1$: $x_1 = 2x_0 = 2^1 x_0$\nFor $n=2$: $x_2 = 2x_1 = 2(2x_0) = 2^2 x_0$\nFor $n=3$: $x_3 = 2x_2 = 2(2^2 x_0) = 2^3 x_0$\n\nBy inspection, the pattern suggests that the general form is $x_n = 2^n x_0$. We can formally prove this by induction.\nBase case ($n=0$): $x_0 = 2^0 x_0 = 1 \\cdot x_0 = x_0$. The formula holds.\nInductive hypothesis: Assume for some integer $k \\geq 0$ that $x_k = 2^k x_0$.\nInductive step: We must show that $x_{k+1} = 2^{k+1} x_0$. Using the recurrence relation and the hypothesis:\n$$ x_{k+1} = 2x_k = 2(2^k x_0) = 2^{k+1} x_0 $$\nThe formula holds for $k+1$. Therefore, by the principle of mathematical induction, the closed-form expression for the $n$-th iterate is:\n$$ x_n = 2^n x_0 $$\n\n**Part 3: Geometric Interpretation and Lack of Quadratic Convergence**\n\nThe sequence of iterates is $x_n = \\{x_0, 2x_0, 4x_0, 8x_0, \\dots\\}$. For any initial guess $x_0 \\neq 0$, the absolute value of the iterates, $|x_n| = |x_0| 2^n$, grows exponentially and diverges to infinity. The method does not converge to any finite value.\n\nThe geometric interpretation for this specific function $f(x)=\\frac{1}{x}$ is revealing. For any point $(x_n, \\frac{1}{x_n})$ on the hyperbola, the tangent line at that point intersects the $x$-axis at exactly twice the $x$-coordinate, i.e., at $(2x_n, 0)$. This systematic doubling pushes each successive iterate further away from the origin, causing the sequence to diverge rapidly.\n\nQuadratic convergence is a property of Newton's method under specific conditions. The standard convergence theorem for Newton's method states that if a function $f$ is twice continuously differentiable, has a simple root $\\alpha$ (i.e., $f(\\alpha)=0$ and $f'(\\alpha) \\neq 0$), and the initial guess $x_0$ is sufficiently close to $\\alpha$, then the sequence of iterates converges to $\\alpha$ quadratically. This means the error $e_n = x_n - \\alpha$ satisfies $\\lim_{n \\to \\infty} \\frac{|e_{n+1}|}{|e_n|^2} = C$ for some constant $C \\neq 0$.\n\nIn this problem, quadratic convergence cannot occur for the most fundamental reason: **there is no root to converge to**. The equation $f(x) = \\frac{1}{x} = 0$ has no solution in the set of real numbers, $\\mathbb{R}$. The entire theoretical framework for convergence, which relies on Taylor series expansion around a root $\\alpha$, is inapplicable. The method is built on the assumption that a root exists, and the tangent line is a linear approximation of the function that points toward that root. When no root exists, the tangent-line construction can lead to divergent or chaotic behavior. For $f(x)=\\frac{1}{x}$, the behavior is a particularly simple and predictable divergence. Instead of the error shrinking quadratically, the magnitude of the iterate itself grows exponentially, which is the antithesis of convergence.", "answer": "$$ \\boxed{x_0 2^n} $$", "id": "3234385"}, {"introduction": "Theoretical analysis tells us that Newton's method can converge at different rates—quadratically for simple roots, linearly for multiple roots, and sometimes even faster. This practice transitions you from a user of the method to an experimentalist who can verify these theoretical claims. You will first derive a powerful formula for empirically estimating the order of convergence, $p$, from a sequence of iterates, and then implement a computational experiment to measure $p$ for functions with different root structures [@problem_id:3234430]. This hands-on approach bridges the gap between abstract convergence theory and the concrete behavior observed in numerical simulations.", "problem": "Implement an experiment that connects the geometric construction of Newton’s method with its asymptotic error behavior to empirically estimate the order of convergence. Start from the following foundational base and derive all needed formulas from first principles:\n\n- Newton’s method is the root-finding iteration produced by intersecting the tangent line of a differentiable function $f$ at a current iterate $x_n$ with the horizontal axis, yielding the next iterate $x_{n+1}$.\n- The error at step $n$ is $e_n = x_n - \\alpha$, where $\\alpha$ is an actual root of $f$.\n- The definition of order of convergence states that there exist constants $C \\gt 0$ and $p \\ge 1$ such that $\\displaystyle \\lim_{n \\to \\infty} \\frac{|e_{n+1}|}{|e_n|^p} = C$.\n\nYour tasks are:\n1) From the geometric tangent-line interpretation of Newton’s method and first-order linearization, derive the Newton update $x_{n+1}$ in terms of $x_n$, $f(x_n)$, and $f'(x_n)$, without assuming any pre-given formula.\n2) From the definition of order of convergence, eliminate the unknown asymptotic constant by combining the relation at successive indices. Using three consecutive nonzero errors $e_{n-1}$, $e_n$, and $e_{n+1}$ and natural logarithms, derive a practical estimator that produces a per-iteration estimate of the order $p$ for sufficiently large $n$.\n3) Implement a program that:\n   - Generates Newton iterates $\\{x_n\\}$ for each specified test case, using the exact root $\\alpha$ to compute the errors $e_n = x_n - \\alpha$.\n   - Produces per-iteration estimates of the order $p$ based on your derivation in item $2)$, for all $n$ where three consecutive errors are available and the computation is well-defined.\n   - Returns a single empirical estimate for each test case by taking the median of the last $k$ valid per-iteration estimates (use $k = 5$, or all available if fewer than $5$ exist).\n   - Uses absolute errors to ensure the estimator is sign-agnostic.\n   - Terminates Newton’s iteration when $|e_n| \\lt \\text{tol}$ or when a maximum number of iterations is reached.\n\nTest suite:\n- Case A (simple root, expected quadratic behavior): $f(x) = x^2 - 2$, $f'(x) = 2x$, $\\alpha = \\sqrt{2}$, $x_0 = 1.5$, $\\text{tol} = 10^{-14}$, $\\text{max\\_iter} = 50$.\n- Case B (double root, expected linear behavior): $f(x) = (x-1)^2$, $f'(x) = 2(x-1)$, $\\alpha = 1$, $x_0 = 1.5$, $\\text{tol} = 10^{-14}$, $\\text{max\\_iter} = 50$.\n- Case C (simple root with vanishing second derivative at the root, expected cubic behavior): $f(x) = x + x^3$, $f'(x) = 1 + 3x^2$, $\\alpha = 0$, $x_0 = 0.2$, $\\text{tol} = 10^{-14}$, $\\text{max\\_iter} = 50$.\n\nAngle units are not applicable. There are no physical quantities, so no physical units are required.\n\nFinal output format:\n- Your program should produce a single line of output containing the three empirical order estimates for Cases A, B, and C, in that order, rounded to $6$ decimal places, as a comma-separated list enclosed in square brackets. For example, the printed line should look like $[p_A,p_B,p_C]$, where each $p$ is a decimal rounded to $6$ places.", "solution": "The task is to conduct a computational experiment to empirically estimate the order of convergence for Newton's method. This requires two preliminary derivations based on first principles: one for the Newton iteration formula itself and one for an estimator of the convergence order, $p$. We will then implement a program to apply these formulas to three specific test cases.\n\n### 1. Derivation of the Newton Iteration Formula\n\nThe first task is to derive the update rule for Newton's method from its geometric interpretation. The method approximates a function $f(x)$ near a root by its tangent line at the current iterate, $x_n$. The next iterate, $x_{n+1}$, is defined as the x-intercept of this tangent line.\n\nLet $f(x)$ be a differentiable function. The equation of the tangent line to the curve $y = f(x)$ at the point $(x_n, f(x_n))$ is given by the point-slope form:\n$$\ny - y_1 = m(x - x_1)\n$$\nHere, the point $(x_1, y_1)$ is $(x_n, f(x_n))$, and the slope $m$ is the derivative of the function evaluated at $x_n$, i.e., $m = f'(x_n)$. Substituting these into the line equation gives:\n$$\ny - f(x_n) = f'(x_n) (x - x_n)\n$$\nThe next iterate, $x_{n+1}$, is the x-coordinate of the point where this line intersects the horizontal axis. At the point of intersection, the y-coordinate is $0$. Therefore, we set $y=0$ and $x=x_{n+1}$:\n$$\n0 - f(x_n) = f'(x_n) (x_{n+1} - x_n)\n$$\nTo find $x_{n+1}$, we solve for it, assuming $f'(x_n) \\neq 0$:\n$$\n-f(x_n) = f'(x_n) x_{n+1} - f'(x_n) x_n\n$$\n$$\nf'(x_n) x_{n+1} = f'(x_n) x_n - f(x_n)\n$$\nDividing by $f'(x_n)$ yields the Newton iteration formula:\n$$\nx_{n+1} = x_n - \\frac{f(x_n)}{f'(x_n)}\n$$\nThis formula provides the means to generate a sequence of iterates $\\{x_n\\}$ that, under suitable conditions, converge to a root $\\alpha$ of the function $f(x)$.\n\n### 2. Derivation of the Convergence Order Estimator\n\nThe second task is to derive a practical formula to estimate the order of convergence, $p$. The order of convergence describes how quickly the error of an iterative method decreases. The error at step $n$ is defined as $e_n = x_n - \\alpha$, where $\\alpha$ is the true root.\n\nThe formal definition for an iterative method having convergence order $p$ is that for some constant $C > 0$:\n$$\n\\lim_{n \\to \\infty} \\frac{|e_{n+1}|}{|e_n|^p} = C\n$$\nFor a sequence of iterates sufficiently close to the root (i.e., for large $n$), we can use this relationship as an approximation:\n$$\n\\frac{|e_{n+1}|}{|e_n|^p} \\approx C \\quad (1)\n$$\nThis approximation should also hold for the preceding pair of iterates:\n$$\n\\frac{|e_n|}{|e_{n-1}|^p} \\approx C \\quad (2)\n$$\nSince both expressions approximate the same asymptotic constant $C$, we can equate them to eliminate $C$:\n$$\n\\frac{|e_{n+1}|}{|e_n|^p} \\approx \\frac{|e_n|}{|e_{n-1}|^p}\n$$\nThe problem specifies using three consecutive nonzero errors $e_{n-1}$, $e_n$, and $e_{n+1}$. To solve for $p$, we rearrange the expression:\n$$\n|e_{n+1}| |e_{n-1}|^p \\approx |e_n|^{p+1}\n$$\nTaking the natural logarithm of both sides facilitates the isolation of $p$:\n$$\n\\ln(|e_{n+1}| |e_{n-1}|^p) \\approx \\ln(|e_n|^{p+1})\n$$\nUsing the properties of logarithms, $\\ln(ab) = \\ln(a) + \\ln(b)$ and $\\ln(a^b) = b\\ln(a)$, we get:\n$$\n\\ln|e_{n+1}| + p \\ln|e_{n-1}| \\approx (p+1) \\ln|e_n|\n$$\n$$\n\\ln|e_{n+1}| + p \\ln|e_{n-1}| \\approx p \\ln|e_n| + \\ln|e_n|\n$$\nNow, we group the terms containing $p$:\n$$\np \\ln|e_{n-1}| - p \\ln|e_n| \\approx \\ln|e_n| - \\ln|e_{n+1}|\n$$\n$$\np (\\ln|e_{n-1}| - \\ln|e_n|) \\approx \\ln|e_n| - \\ln|e_{n+1}|\n$$\nUsing the property $\\ln(a) - \\ln(b) = \\ln(a/b)$:\n$$\np \\ln\\left(\\frac{|e_{n-1}|}{|e_n|}\\right) \\approx \\ln\\left(\\frac{|e_n|}{|e_{n+1}|}\\right)\n$$\nFinally, solving for $p$ gives the per-iteration estimator:\n$$\np \\approx \\frac{\\ln\\left(|e_n|/|e_{n+1}|\\right)}{\\ln\\left(|e_{n-1}|/|e_n|\\right)}\n$$\nThis formula, which we will denote $p_n$, provides an estimate for the order of convergence at iteration $n$, given three consecutive errors $e_{n-1}$, $e_n$, and $e_{n+1}$. This estimator is well-defined as long as the errors are nonzero and $|e_{n-1}| \\neq |e_n|$.\n\n### 3. Implementation and Empirical Estimation\n\nThe computational part of the task involves implementing Newton's method and the derived order estimator. For each test case, the program will:\n1.  Initialize with the given starting value $x_0$.\n2.  Iteratively generate $x_1, x_2, \\ldots$ using the Newton update formula.\n3.  In each iteration $n$, compute the absolute error $|e_n| = |x_n - \\alpha|$. The iteration will terminate if $|e_n|$ drops below a tolerance $\\text{tol} = 10^{-14}$ or if a maximum of $\\text{max\\_iter} = 50$ iterations is reached.\n4.  Store the sequence of absolute errors.\n5.  After the iteration terminates, use the stored errors to compute a sequence of per-iteration order estimates $\\{p_n\\}$ using the derived estimator formula. An estimate $p_n$ is computed for each $n$ for which $e_{n-1}, e_n, e_{n+1}$ are available and the computation is well-defined.\n6.  A single empirical estimate of the order for the test case is then calculated by taking the median of the final $k=5$ valid per-iteration estimates. If fewer than $5$ estimates are available, the median of all available estimates is used. This approach provides a robust measure, as the estimator is most accurate for large $n$ when the iterates are close to the root.\n\nThe derived formulas and this computational strategy are sufficient to complete the required analysis for the provided test cases, which are chosen to exhibit quadratic ($p=2$), linear ($p=1$), and cubic ($p=3$) convergence, respectively.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Implements an experiment to empirically estimate the order of convergence\n    of Newton's method for three test cases.\n    \"\"\"\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        {\n            \"name\": \"Case A\",\n            \"f\": lambda x: x**2 - 2.0,\n            \"fp\": lambda x: 2.0 * x,\n            \"alpha\": np.sqrt(2.0),\n            \"x0\": 1.5,\n            \"tol\": 1e-14,\n            \"max_iter\": 50,\n        },\n        {\n            \"name\": \"Case B\",\n            \"f\": lambda x: (x - 1.0)**2,\n            \"fp\": lambda x: 2.0 * (x - 1.0),\n            \"alpha\": 1.0,\n            \"x0\": 1.5,\n            \"tol\": 1e-14,\n            \"max_iter\": 50,\n        },\n        {\n            \"name\": \"Case C\",\n            \"f\": lambda x: x + x**3,\n            \"fp\": lambda x: 1.0 + 3.0 * x**2,\n            \"alpha\": 0.0,\n            \"x0\": 0.2,\n            \"tol\": 1e-14,\n            \"max_iter\": 50,\n        },\n    ]\n\n    results = []\n    for case in test_cases:\n        x_n = case[\"x0\"]\n        alpha = case[\"alpha\"]\n        tol = case[\"tol\"]\n        max_iter = case[\"max_iter\"]\n        f = case[\"f\"]\n        fp = case[\"fp\"]\n        \n        abs_errors = []\n        for _ in range(max_iter):\n            # Compute and store the absolute error\n            error = x_n - alpha\n            abs_err = np.abs(error)\n            abs_errors.append(abs_err)\n\n            # Check for termination\n            if abs_err < tol:\n                break\n\n            # Calculate the next iterate using Newton's method\n            f_xn = f(x_n)\n            fp_xn = fp(x_n)\n            \n            # Avoid division by zero, though not expected for these cases\n            # with the given initial guesses.\n            if fp_xn == 0:\n                break\n            \n            x_n = x_n - f_xn / fp_xn\n        \n        # We need at least 3 errors to compute one estimate of p\n        if len(abs_errors) < 3:\n            # If not enough errors are generated, we cannot estimate p.\n            # This can happen if x0 is already the root or very close.\n            # For this problem, this branch is not expected to be taken.\n            results.append(np.nan)\n            continue\n\n        p_estimates = []\n        # Iterate to compute per-iteration estimates of p\n        # We need e_{n-1}, e_n, e_{n+1}, which corresponds to\n        # abs_errors[i-1], abs_errors[i], abs_errors[i+1]\n        for i in range(1, len(abs_errors) - 1):\n            e_prev = abs_errors[i-1]\n            e_curr = abs_errors[i]\n            e_next = abs_errors[i+1]\n\n            # Ensure errors are non-zero to avoid issues with log\n            if e_prev == 0 or e_curr == 0 or e_next == 0:\n                continue\n\n            # Denominator of the estimator's main fraction cannot be zero\n            log_arg_denom = e_prev / e_curr\n            if log_arg_denom == 1.0:\n                continue\n\n            # Numerator of the estimator\n            log_arg_num = e_curr / e_next\n            \n            # Compute p using the derived formula\n            p = np.log(log_arg_num) / np.log(log_arg_denom)\n            p_estimates.append(p)\n        \n        # Calculate the final empirical estimate for the case\n        if not p_estimates:\n            # No valid p estimates could be computed.\n            results.append(np.nan)\n            continue\n            \n        k = 5\n        num_estimates = len(p_estimates)\n        \n        # Take the median of the last k estimates, or all if less than k\n        if num_estimates < k:\n            estimates_to_use = p_estimates\n        else:\n            estimates_to_use = p_estimates[-k:]\n        \n        p_final = np.median(estimates_to_use)\n        results.append(p_final)\n    \n    # Format the results to 6 decimal places for final output\n    formatted_results = [f\"{res:.6f}\" for res in results]\n    \n    # Final print statement in the exact required format.\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```", "id": "3234430"}]}