{"hands_on_practices": [{"introduction": "A powerful way to understand a new numerical algorithm is to compare it with one you already know. This problem contrasts the secant method with the more familiar Newton's method, highlighting a key difference in their operational requirements. By constructing an example where Newton's method fails due to a zero derivative, you will see firsthand how the secant method's use of a finite difference approximation provides a degree of robustness in certain scenarios [@problem_id:3271725]. This exercise strengthens your foundational understanding of how the method is constructed and why it can be a valuable alternative.", "problem": "You are asked to construct and analyze a scalar nonlinear example that separates the robustness of the secant method from Newton’s method. Work in the setting of a smooth function $f:\\mathbb{R}\\to\\mathbb{R}$ with a real root.\n\nTasks:\n- Starting from the first-order Taylor expansion definition of linearization at a point, derive the iteration that defines Newton’s method and explain why the iteration is not well-defined whenever the derivative at the current iterate is zero.\n- Design a specific function $f(x)$ with a simple root $r$ such that there exists a point $x_{0}$ with $f^{\\prime}(x_{0})=0$ and $f(x_{0})\\neq 0$, so that Newton’s method fails if started at $x_{0}$. Then, justify that the secant method can still be formed from two initial points $x_{0}$ and $x_{1}$ by approximating the derivative through a finite difference and applying the same linearization logic at $x_{1}$.\n- For your explicit choice, take $f(x)=x^{3}+1$, choose $x_{0}=0$ and $x_{1}=-2$. Using only the construction principles above, compute the next secant iterate $x_{2}$ exactly.\n- Provide a brief, first-principles convergence analysis for your example that explains why the secant method is expected to converge to the unique simple root $r$ of $f(x)=0$ when initialized by $x_{0}$ and $x_{1}$ as specified. Your explanation should be based on monotonicity/concavity properties of $f$ and the geometric meaning of secant updates, and should state the local order of convergence near a simple root under smoothness assumptions.\n\nReport only the exact value of $x_{2}$ as your final answer. No rounding is required.", "solution": "The problem asks for a comprehensive analysis of the secant method, contrasting it with Newton's method using a specific nonlinear scalar example. The tasks involve derivations, a specific calculation, and a convergence analysis.\n\nFirst, we derive Newton's method from a first-order Taylor expansion. For a smooth function $f:\\mathbb{R}\\to\\mathbb{R}$, its linearization around a point $x_k$ is given by the first-order Taylor polynomial:\n$$L_k(x) = f(x_k) + f'(x_k)(x - x_k)$$\nNewton's method determines the next iterate, $x_{k+1}$, by finding the root of this linear approximation, i.e., by solving $L_k(x_{k+1}) = 0$.\n$$0 = f(x_k) + f'(x_k)(x_{k+1} - x_k)$$\nAssuming $f'(x_k) \\neq 0$, we can solve for $x_{k+1}$:\n$$-f(x_k) = f'(x_k)(x_{k+1} - x_k)$$\n$$x_{k+1} = x_k - \\frac{f(x_k)}{f'(x_k)}$$\nThis is the iteration formula for Newton's method. The iteration is not well-defined if at some iterate $x_k$, the derivative $f'(x_k)$ is zero. In this case, the denominator of the update term becomes zero, leading to a division by zero error, and the method fails to produce a next iterate. Geometrically, if $f'(x_k) = 0$ and $f(x_k) \\neq 0$, the tangent line to the graph of $f$ at $(x_k, f(x_k))$ is horizontal and never intersects the x-axis to provide the next approximation of the root.\n\nNext, we design a specific function as requested. Let us use the provided function $f(x) = x^3 + 1$. This function is smooth (infinitely differentiable). Its unique real root is found by solving $f(x) = 0$, which gives $x^3 = -1$, so the root is $r = -1$. To check if it is a simple root, we compute the derivative: $f'(x) = 3x^2$. At the root, $f'(-1) = 3(-1)^2 = 3 \\neq 0$, so $r=-1$ is indeed a simple root.\nWe need to find a point $x_0$ where $f'(x_0) = 0$ but $f(x_0) \\neq 0$. We set $f'(x_0) = 3x_0^2 = 0$, which yields $x_0 = 0$. At this point, the function value is $f(x_0) = f(0) = 0^3 + 1 = 1 \\neq 0$. Thus, if Newton's method is initialized at $x_0 = 0$, it fails immediately because $f'(0) = 0$.\n\nThe secant method circumvents this issue by not requiring the analytical derivative. It is based on the same linearization logic but approximates the derivative $f'(x_k)$ using a finite difference (the slope of the secant line) between the current iterate $x_k$ and the previous iterate $x_{k-1}$:\n$$f'(x_k) \\approx \\frac{f(x_k) - f(x_{k-1})}{x_k - x_{k-1}}$$\nSubstituting this approximation into the Newton's method formula gives the secant method iteration:\n$$x_{k+1} = x_k - \\frac{f(x_k)}{\\frac{f(x_k) - f(x_{k-1})}{x_k - x_{k-1}}} = x_k - f(x_k) \\frac{x_k - x_{k-1}}{f(x_k) - f(x_{k-1})}$$\nThis formula is well-defined as long as $f(x_k) \\neq f(x_{k-1})$. For the given problem, even though $f'(x_0) = 0$, the secant method can proceed starting with initial points $x_0=0$ and $x_1=-2$, since $f(x_0)=1$ and $f(x_1)=(-2)^3+1=-7$, which are not equal.\n\nWe now compute the next secant iterate $x_2$ for $f(x) = x^3 + 1$ with initial points $x_0 = 0$ and $x_1 = -2$. The formula for $x_2$ is obtained by setting $k=1$ in the general formula:\n$$x_2 = x_1 - f(x_1) \\frac{x_1 - x_0}{f(x_1) - f(x_0)}$$\nFirst, we evaluate the function at the initial points:\n$$f(x_0) = f(0) = 0^3 + 1 = 1$$\n$$f(x_1) = f(-2) = (-2)^3 + 1 = -8 + 1 = -7$$\nNow we substitute these values into the formula for $x_2$:\n$$x_2 = -2 - (-7) \\frac{-2 - 0}{-7 - 1}$$\n$$x_2 = -2 + 7 \\frac{-2}{-8}$$\n$$x_2 = -2 + 7 \\left(\\frac{1}{4}\\right)$$\n$$x_2 = -2 + \\frac{7}{4} = -\\frac{8}{4} + \\frac{7}{4} = -\\frac{1}{4}$$\nThe exact value of the next iterate is $x_2 = -1/4$.\n\nFinally, we provide a first-principles convergence analysis for this example. The function is $f(x) = x^3+1$, with root $r=-1$. The first and second derivatives are $f'(x) = 3x^2$ and $f''(x) = 6x$.\nThe function $f(x)$ is strictly increasing for all $x \\in \\mathbb{R}$ because $f'(x) \\ge 0$ and $f'(x)=0$ only at the isolated point $x=0$.\nThe concavity of the function changes at $x=0$. For $x  0$, $f''(x)  0$, so the function is concave down. For $x > 0$, $f''(x) > 0$, so the function is concave up. The root $r=-1$ lies in the region where the function is concave down.\n\nOur initial iterates are $x_0 = 0$ and $x_1 = -2$. The root $r=-1$ is bracketed by these points. The values are $f(0)=1>0$ and $f(-2)=-70$.\nThe first computed iterate is $x_2 = -1/4$. At this point, $f(-1/4) = (-1/4)^3+1 = 63/64 > 0$.\nThe next iteration will use the points $x_1 = -2$ and $x_2 = -1/4$. The root $r=-1$ is again bracketed by these two most recent iterates.\nThe subsequent iterate $x_3$ is generated by the secant line through $(-2, -7)$ and $(-1/4, 63/64)$. Because the root is bracketed, $x_3$ must lie between $x_1$ and $x_2$. The calculation gives $x_3 = -34/73 \\approx -0.466$.\nNow, the two most recent iterates are $x_2 = -1/4$ and $x_3 \\approx -0.466$. Both of these points are to the right of the root $r = -1$.\nThis demonstrates that the secant method, unlike the method of false position (regula falsi), does not necessarily maintain a bracket on the root.\nLet's analyze the behavior when two successive iterates, say $x_k$ and $x_{k-1}$ with $r  x_k  x_{k-1}$, are on the same side of the root. In our example, this occurs for $x_2$ and $x_3$ (after relabeling for the next step), which are in the interval $(-1, 0)$. In this interval, $f(x)$ is increasing and concave down.\nGeometrically, for a concave down function, any secant line segment connecting two points on its graph will lie below the graph of the function between those two points. The new iterate, $x_{k+1}$, is the x-intercept of this secant line. Because the secant line is below the curve, and the curve itself is below the tangent at the leftmost point $(x_k, f(x_k))$, the secant line is \"flatter\" than the tangent line at $x_k$. For a function that is increasing and concave down, this leads to an \"overshoot\", where the next iterate $x_{k+1}$ will be to the left of the root.\nThis creates an oscillatory pattern where the iterates tend to alternate sides of the root. Despite the oscillation, the magnitude of the error $|x_k - r|$ can be shown to decrease at each step, provided the initial points are sufficiently close to the root, which is the case here. The sequence of iterates converges to the root $r=-1$.\nIn general, for a $C^2$ function with a simple root, the secant method has a local order of convergence of $\\phi = \\frac{1+\\sqrt{5}}{2} \\approx 1.618$, which is superlinear but less than the quadratic order of Newton's method.", "answer": "$$\\boxed{-\\frac{1}{4}}$$", "id": "3271725"}, {"introduction": "The elegant theorems that guarantee the fast convergence of methods like the secant method rely on certain assumptions, such as the function being smooth and having a simple root. This exercise challenges you to investigate what happens when these assumptions are broken by applying the method to a function that is not differentiable at its root [@problem_id:3271709]. Analyzing this \"pathological\" case from first principles will reveal a rich variety of behaviors—including oscillation, stagnation, and even finite termination—that are hidden in standard textbook examples, thereby deepening your appreciation for the conditions that underpin convergence theory.", "problem": "Consider the secant method for solving $f(x)=0$, defined by the iteration $x_{k+1}=x_k - f(x_k)\\dfrac{x_k - x_{k-1}}{f(x_k)-f(x_{k-1})}$ for $k\\geq 1$, starting from two initial guesses $x_0\\neq x_1$. Let $f(x)=\\operatorname{sign}(x)\\sqrt{|x|}$, which has a root at $x=0$. The standard local superlinear convergence of the secant method is known to rely on $f$ being sufficiently smooth near the root and the root being simple, meaning $f$ is differentiable at the root with $f'(x^\\ast)\\neq 0$. In this problem, analyze the convergence behavior of the secant method applied to $f(x)=\\operatorname{sign}(x)\\sqrt{|x|}$ at $x=0$ from first principles.\n\nBegin with the given secant iteration and the definition of $f(x)$. Derive explicit update formulas in terms of $x_{k}$ and $x_{k-1}$ for the two cases where the iterates have the same sign and where they have opposite signs. Use these formulas to reason about whether magnitudes $|x_k|$ necessarily contract, whether oscillations in sign occur, and whether the method can terminate in finitely many steps under special configurations. Based on this analysis, select the most accurate statement below about the convergence of the secant method for this $f$ near $x=0$.\n\nA. For any starting points $x_0$ and $x_1$ sufficiently close to $0$, the secant method converges to $0$ with superlinear order approximately $\\varphi\\approx 1.618$.\n\nB. For any starting points $x_0$ and $x_1$ sufficiently close to $0$, the secant method converges to $0$ with linear order and a uniform rate $q$ satisfying $0q1$.\n\nC. The secant method does not satisfy the standard assumptions at $x=0$; convergence is not guaranteed. In fact, if $x_k$ and $x_{k-1}$ have the same sign, then $x_{k+1}=-\\operatorname{sign}(x_k)\\sqrt{|x_k x_{k-1}|}$, so magnitudes need not contract; if $|x_k|=|x_{k-1}|$ and the signs are opposite, then $x_{k+1}=0$ (finite termination). Outside such special symmetries, the method often exhibits nonmonotonic, oscillatory behavior and may stagnate.\n\nD. The secant method always diverges, i.e., $|x_k|\\to\\infty$ for all choices of $x_0$ and $x_1$.", "solution": "The user wants me to analyze the convergence of the secant method for the function $f(x) = \\operatorname{sign}(x)\\sqrt{|x|}$.\n\n### Problem Validation\n\n**Step 1: Extract Givens**\n-   **Method:** Secant method, defined by the iteration $x_{k+1}=x_k - f(x_k)\\dfrac{x_k - x_{k-1}}{f(x_k)-f(x_{k-1})}$ for $k\\geq 1$.\n-   **Initial Conditions:** Two distinct initial guesses, $x_0 \\neq x_1$.\n-   **Function:** $f(x)=\\operatorname{sign}(x)\\sqrt{|x|}$.\n-   **Root:** The problem focuses on the root at $x=0$.\n-   **Context:** The problem states that the standard conditions for superlinear convergence of the secant method (sufficient smoothness of $f$, simple root with $f'(x^\\ast)\\neq 0$) are not met.\n-   **Task:** Derive explicit update formulas for cases where iterates have the same sign and opposite signs, analyze the convergence behavior (magnitude contraction, sign oscillation, finite termination), and select the most accurate descriptive statement.\n\n**Step 2: Validate Using Extracted Givens**\n-   **Scientific Grounding:** The problem is a standard exercise in numerical analysis, concerning the behavior of a well-known root-finding algorithm (the secant method) when applied to a function that violates the typical assumptions of convergence theorems. The function $f(x)=\\operatorname{sign}(x)\\sqrt{|x|}$ is a valid mathematical function. The concepts of convergence order and iterative methods are central to numerical mathematics.\n-   **Well-Posedness:** The task is to analyze the behavior of a defined iterative process. This is a well-posed mathematical problem.\n-   **Objectivity:** The problem is stated using precise mathematical definitions and objective language.\n-   **Checking for Flaws:**\n    1.  **Scientific/Factual Unsoundness:** The premise that standard assumptions are not met is correct. The function $f(x)$ can be written as $f(x) = \\sqrt{x}$ for $x0$ and $f(x) = -\\sqrt{-x}$ for $x0$. The derivative for $x \\neq 0$ is $f'(x) = \\frac{1}{2\\sqrt{|x|}}$. As $x \\to 0$, $f'(x) \\to \\infty$. Thus, the function is not differentiable at the root $x=0$, violating a key condition for standard convergence theorems. The problem statement is factually sound.\n    2.  **No other flaws are present.** The problem is a valid, non-trivial, and standard-form problem in its field.\n\n**Step 3: Verdict and Action**\nThe problem statement is valid. I will proceed with the derivation and analysis.\n\n### Derivation and Analysis\n\nThe secant method iteration is given by:\n$$ x_{k+1} = x_k - f(x_k) \\frac{x_k - x_{k-1}}{f(x_k) - f(x_{k-1})} $$\nThe function is $f(x) = \\operatorname{sign}(x)\\sqrt{|x|}$. We analyze the iteration by considering two cases for the signs of the consecutive iterates $x_k$ and $x_{k-1}$.\n\n**Case 1: Iterates have the same sign ($\\operatorname{sign}(x_k) = \\operatorname{sign}(x_{k-1})$)**\n\nLet's assume $x_k  0$ and $x_{k-1}  0$. Then $f(x_k) = \\sqrt{x_k}$ and $f(x_{k-1}) = \\sqrt{x_{k-1}}$.\nThe iteration formula becomes:\n$$ x_{k+1} = x_k - \\sqrt{x_k} \\frac{x_k - x_{k-1}}{\\sqrt{x_k} - \\sqrt{x_{k-1}}} $$\nRecognizing that $x_k - x_{k-1} = (\\sqrt{x_k} - \\sqrt{x_{k-1}})(\\sqrt{x_k} + \\sqrt{x_{k-1}})$, we simplify the fraction (since $x_k \\neq x_{k-1}$, the denominator is non-zero):\n$$ x_{k+1} = x_k - \\sqrt{x_k} (\\sqrt{x_k} + \\sqrt{x_{k-1}}) = x_k - (x_k + \\sqrt{x_k x_{k-1}}) = -\\sqrt{x_k x_{k-1}} $$\nSince $x_k  0$ and $x_{k-1}  0$, the next iterate $x_{k+1}$ is negative.\n\nNow assume $x_k  0$ and $x_{k-1}  0$. Then $f(x_k) = -\\sqrt{-x_k}$ and $f(x_{k-1}) = -\\sqrt{-x_{k-1}}$.\nThe iteration formula becomes:\n$$ x_{k+1} = x_k - (-\\sqrt{-x_k}) \\frac{x_k - x_{k-1}}{(-\\sqrt{-x_k}) - (-\\sqrt{-x_{k-1}})} = x_k + \\sqrt{-x_k} \\frac{x_k - x_{k-1}}{\\sqrt{-x_{k-1}} - \\sqrt{-x_k}} $$\nUsing $-x_k = |-x_k| = |x_k|$, we can write $x_k - x_{k-1} = (-x_{k-1}) - (-x_k) = |x_{k-1}| - |x_k| = (\\sqrt{|x_{k-1}|} - \\sqrt{|x_k|})(\\sqrt{|x_{k-1}|} + \\sqrt{|x_k|})$.\nThe fraction simplifies to $\\sqrt{|x_{k-1}|} + \\sqrt{|x_k|}$.\n$$ x_{k+1} = x_k + \\sqrt{|x_k|} (\\sqrt{|x_{k-1}|} + \\sqrt{|x_k|}) = x_k + \\sqrt{|x_k||x_{k-1}|} + |x_k| $$\nSince $x_k  0$, $|x_k| = -x_k$.\n$$ x_{k+1} = x_k + \\sqrt{x_k x_{k-1}} - x_k = \\sqrt{x_k x_{k-1}} $$\nSince $x_k  0$ and $x_{k-1}  0$, $x_k x_{k-1}  0$, so $x_{k+1}$ is real and positive.\n\nIn both sub-cases, the sign of the next iterate is opposite to the sign of the previous two. We can combine these results into a single formula:\nIf $\\operatorname{sign}(x_k) = \\operatorname{sign}(x_{k-1})$, then $x_{k+1} = -\\operatorname{sign}(x_k)\\sqrt{|x_k x_{k-1}|}$.\nThe magnitude of the new iterate is $|x_{k+1}| = \\sqrt{|x_k||x_{k-1}|}$. This is the geometric mean of the previous two magnitudes. A sequence of magnitudes defined this way does not necessarily contract to zero. For example, if $|x_0|=4$ and $|x_1|=1$, then $|x_2|=2$, $|x_3|=\\sqrt{2}$, $|x_4|=\\sqrt{2\\sqrt{2}}$, etc. This sequence converges to a non-zero limit, indicating stagnation. Thus, magnitudes do not necessarily contract.\n\n**Case 2: Iterates have opposite signs ($\\operatorname{sign}(x_k) \\neq \\operatorname{sign}(x_{k-1})$)**\n\nLet's assume $x_k  0$ and $x_{k-1}  0$. Then $f(x_k) = \\sqrt{x_k}$ and $f(x_{k-1}) = -\\sqrt{-x_{k-1}}$.\n$$ x_{k+1} = x_k - \\sqrt{x_k} \\frac{x_k - x_{k-1}}{\\sqrt{x_k} - (-\\sqrt{-x_{k-1}})} = x_k - \\frac{\\sqrt{x_k} (x_k - x_{k-1})}{\\sqrt{x_k} + \\sqrt{-x_{k-1}}} $$\n$$ x_{k+1} = \\frac{x_k(\\sqrt{x_k} + \\sqrt{-x_{k-1}}) - \\sqrt{x_k}(x_k - x_{k-1})}{\\sqrt{x_k} + \\sqrt{-x_{k-1}}} = \\frac{x_k\\sqrt{x_k} + x_k\\sqrt{-x_{k-1}} - x_k\\sqrt{x_k} + x_{k-1}\\sqrt{x_k}}{\\sqrt{x_k} + \\sqrt{-x_{k-1}}}$$\n$$ x_{k+1} = \\frac{x_k\\sqrt{-x_{k-1}} + x_{k-1}\\sqrt{x_k}}{\\sqrt{x_k} + \\sqrt{-x_{k-1}}} = \\frac{|x_k|\\sqrt{|x_{k-1}|} - |x_{k-1}|\\sqrt{|x_k|}}{\\sqrt{|x_k|} + \\sqrt{|x_{k-1}|}} $$\nWe can factor out $\\sqrt{|x_k||x_{k-1}|}$:\n$$ x_{k+1} = \\frac{\\sqrt{|x_k||x_{k-1}|}(\\sqrt{|x_k|} - \\sqrt{|x_{k-1}|})}{\\sqrt{|x_k|} + \\sqrt{|x_{k-1}|}} $$\nA special sub-case is when the magnitudes are equal, i.e., $|x_k|=|x_{k-1}|$. In this situation, the term $(\\sqrt{|x_k|} - \\sqrt{|x_{k-1}|})$ becomes zero. Thus, if $x_k = -x_{k-1}$, then $x_{k+1} = 0$. The method terminates at the root in a single step. This is a case of finite termination.\n\nOutside this special symmetry, the behavior is more complex. The sign of $x_{k+1}$ is determined by the sign of $(\\sqrt{|x_k|} - \\sqrt{|x_{k-1}|})$, which is the sign of $|x_k| - |x_{k-1}|$. The general behavior is a mix of these two update rules, leading to oscillations in sign and non-monotonic changes in magnitude.\n\n### Option-by-Option Analysis\n\n**A. For any starting points $x_0$ and $x_1$ sufficiently close to $0$, the secant method converges to $0$ with superlinear order approximately $\\varphi\\approx 1.618$.**\nThis statement describes the standard convergence of the secant method under ideal conditions ($f \\in C^2$, $f'(x^\\ast) \\neq 0$). As established, the function $f(x)=\\operatorname{sign}(x)\\sqrt{|x|}$ is not differentiable at the root $x=0$. The standard theorem does not apply. Our derivation shows complex, oscillatory behavior, not smooth superlinear convergence. For instance, the update $|x_{k+1}| = \\sqrt{|x_k||x_{k-1}|}$ corresponds to linear convergence with rate $1$ (stagnation), not superlinear convergence.\n**Verdict: Incorrect.**\n\n**B. For any starting points $x_0$ and $x_1$ sufficiently close to $0$, the secant method converges to $0$ with linear order and a uniform rate $q$ satisfying $0q1$.**\nThe phrase \"for any starting points\" is a very strong claim that our analysis contradicts. We have seen that the sequence of magnitudes can stagnate (converge to a non-zero constant), which corresponds to a convergence rate of $1$, not a rate $q1$. The behavior is a complex mixture of two different update rules, and the effective convergence rate is not uniform. Convergence to $0$ is not guaranteed for all starting points.\n**Verdict: Incorrect.**\n\n**C. The secant method does not satisfy the standard assumptions at $x=0$; convergence is not guaranteed. In fact, if $x_k$ and $x_{k-1}$ have the same sign, then $x_{k+1}=-\\operatorname{sign}(x_k)\\sqrt{|x_k x_{k-1}|}$, so magnitudes need not contract; if $|x_k|=|x_{k-1}|$ and the signs are opposite, then $x_{k+1}=0$ (finite termination). Outside such special symmetries, the method often exhibits nonmonotonic, oscillatory behavior and may stagnate.**\nThis statement aligns perfectly with our detailed analysis.\n-   \"`does not satisfy the standard assumptions`\": Correct, $f'(0)$ is undefined.\n-   \"`convergence is not guaranteed`\": Correct, stagnation is a possible outcome.\n-   \"`if $x_k$ and $x_{k-1}$ have the same sign, then $x_{k+1}=-\\operatorname{sign}(x_k)\\sqrt{|x_k x_{k-1}|}$`\": This formula was explicitly derived and verified.\n-   \"`so magnitudes need not contract`\": Correct. The geometric mean $|x_{k+1}| = \\sqrt{|x_k||x_{k-1}|}$ can be larger than one of the previous magnitudes (e.g., if $|x_{k-1}| \\ll |x_k|$).\n-   \"`if $|x_k|=|x_{k-1}|$ and the signs are opposite, then $x_{k+1}=0$`\": This case of finite termination was explicitly derived.\n-   \"`often exhibits nonmonotonic, oscillatory behavior and may stagnate`\": Our analysis confirms this complex behavior. Signs oscillate, and magnitudes can either stall or jump around before potentially contracting.\n**Verdict: Correct.**\n\n**D. The secant method always diverges, i.e., $|x_k|\\to\\infty$ for all choices of $x_0$ and $x_1$.**\nThis is demonstrably false. We found a clear case of finite convergence (when $x_1 = -x_0$, $x_2=0$). Furthermore, our magnitude analysis, which shows $|x_{k+1}|$ is either the geometric mean of previous magnitudes or smaller, does not suggest divergence to infinity. At worst, the sequence of magnitudes stagnates.\n**Verdict: Incorrect.**", "answer": "$$\\boxed{C}$$", "id": "3271709"}, {"introduction": "After exploring the theoretical foundations and failure modes, it's time to put the secant method to work in a practical setting. This hands-on coding problem asks you to implement the algorithm to solve a physically motivated equation modeling thermal equilibrium [@problem_id:3271741]. By implementing the method and running it on a variety of test cases, you will not only translate theory into a working program but also empirically verify its convergence properties. This practice is crucial for observing the theoretical superlinear convergence rate of approximately $\\phi \\approx 1.618$ and witnessing its degradation to linear convergence when encountering a multiple root, connecting abstract analysis to concrete computational results.", "problem": "An object exchanges thermal energy with its environment in a way that can be modeled by the nonlinear scalar equation $f(T) = T^4 - c_1 T - c_2 = 0$, where $T$ is the absolute temperature and $c_1$, $c_2$ are given constants. The physically meaningful equilibrium temperature corresponds to the non-trivial solution $T  0$ of $f(T) = 0$, expressed in kelvin. The goal is to numerically approximate this positive root using the secant method and to empirically analyze the convergence behavior.\n\nStarting from foundational numerical analysis principles:\n- The task is to locate a simple root of a differentiable function $f(T)$ where $f'(T)$ is not identically zero near the root.\n- A root-finding iteration may be constructed by approximating the derivative via a finite difference and advancing $T$ along the direction suggested by this approximation.\n\nYour program must:\n1. Implement the secant method to approximate the positive root $T^\\ast$ of $f(T) = T^4 - c_1 T - c_2$ given two initial guesses $T_0$ and $T_1$, an absolute stopping tolerance $\\varepsilon$, and a maximum iteration cap $N_{\\max}$. Convergence should be declared if either the successive iterate difference satisfies $|T_{k} - T_{k-1}| \\le \\varepsilon$ or the residual satisfies $|f(T_k)| \\le \\varepsilon$. If the iteration encounters a division by zero in the secant update or fails to converge within $N_{\\max}$ iterations, treat the root as undefined and return a not-a-number value for the root.\n2. Record all iterates and, provided that at least four iterates are available, estimate the empirical order of convergence $p$ using the last iterates as follows. Let $r$ be the final iterate, and define errors $e_{n-1} = |T_{n-1} - r|$, $e_{n-2} = |T_{n-2} - r|$, and $e_{n-3} = |T_{n-3} - r|$. If these errors are strictly positive, estimate\n$$\np \\approx \\frac{\\ln\\left(e_{n-1} / e_{n-2}\\right)}{\\ln\\left(e_{n-2} / e_{n-3}\\right)}.\n$$\nIf the estimate cannot be formed due to insufficient iterates or nonpositive errors, return a not-a-number value for $p$.\n3. For each test case, output a pair consisting of the approximated root $T^\\ast$ (in kelvin) and the empirical order of convergence $p$ as floating-point numbers.\n\nUse the following test suite to exercise correctness and convergence characteristics:\n- Case A (well-conditioned, moderate coefficients): $c_1 = 5$, $c_2 = 1$, $T_0 = 1$, $T_1 = 2$, $\\varepsilon = 10^{-12}$, $N_{\\max} = 100$.\n- Case B (larger constant term, positive root around a few kelvin): $c_1 = 1$, $c_2 = 100$, $T_0 = 2.5$, $T_1 = 3.5$, $\\varepsilon = 10^{-10}$, $N_{\\max} = 100$.\n- Case C (small coefficients, small positive root): $c_1 = 0.1$, $c_2 = 0.001$, $T_0 = 0.2$, $T_1 = 0.6$, $\\varepsilon = 10^{-12}$, $N_{\\max} = 100$.\n- Case D (near a multiple root at $T = 1$ with slow convergence): $c_1 = 4$, $c_2 = -3$, $T_0 = 0.8$, $T_1 = 1.2$, $\\varepsilon = 10^{-12}$, $N_{\\max} = 200$.\n- Case E (boundary case with a trivial root at $T = 0$, but seek the non-trivial root): $c_1 = 10$, $c_2 = 0$, $T_0 = 0.5$, $T_1 = 4.0$, $\\varepsilon = 10^{-12}$, $N_{\\max} = 100$.\n\nFinal output format:\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, with each test case reported as a pair in the form $[T^\\ast,p]$ and no spaces. For example, the output must look like\n$[[x_1,y_1],[x_2,y_2],[x_3,y_3]]$\nwhere $x_i$ and $y_i$ are floating-point numbers. Report all temperatures in kelvin as floats. If a value is not available (e.g., non-convergence), print it as a not-a-number token.", "solution": "The problem requires the numerical approximation of a positive root $T^*  0$ for the nonlinear equation $f(T) = T^4 - c_1 T - c_2 = 0$. This equation models the thermal equilibrium temperature of an object. The solution is to be found using the secant method, and an empirical analysis of its convergence rate must be performed.\n\nFirst, we validate the problem statement.\nThe problem is scientifically grounded, as the $T^4$ term is reminiscent of the Stefan-Boltzmann law for black-body radiation, making the model physically plausible for thermal exchange phenomena. The problem is well-posed; it provides a specific algorithm (the secant method), well-defined initial conditions for several test cases, and clear stopping and failure criteria. The request to estimate the order of convergence is a standard exercise in numerical analysis. An analysis of the function $f(T) = T^4 - c_1 T - c_2$ and its derivative $f'(T) = 4T^3 - c_1$ confirms that for the parameters given in the test cases, a positive root exists and is unique for simple root cases. Case D is explicitly designed to test behavior near a multiple root, which is a valid and instructive scenario. All terms are defined, and no contradictions are present. The problem is therefore deemed valid.\n\nThe core of the task is the implementation of the secant method. This is an iterative root-finding algorithm that uses a sequence of roots of secant lines to better approximate a root of a function $f$. Given two initial guesses for the temperature, $T_0$ and $T_1$, the method generates a sequence of iterates $\\{T_k\\}_{k=0}^\\infty$ via the recurrence relation:\n$$\nT_{k} = T_{k-1} - f(T_{k-1}) \\frac{T_{k-1} - T_{k-2}}{f(T_{k-1}) - f(T_{k-2})}, \\quad \\text{for } k \\ge 2.\n$$\nThis formula can be geometrically interpreted as finding the x-intercept of the line passing through the points $(T_{k-2}, f(T_{k-2}))$ and $(T_{k-1}, f(T_{k-1}))$. The method approximates Newton's method by replacing the derivative $f'(T_{k-1})$ with the finite-difference approximation $\\frac{f(T_{k-1}) - f(T_{k-2})}{T_{k-1} - T_{k-2}}$.\n\nThe iteration proceeds until a convergence criterion is met or a failure condition occurs. The specified stopping criteria are:\n1.  The absolute difference between successive iterates is within a given tolerance $\\varepsilon$: $|T_k - T_{k-1}| \\le \\varepsilon$.\n2.  The absolute value of the function at the current iterate is within the tolerance: $|f(T_k)| \\le \\varepsilon$.\n\nFailure is declared under two conditions:\n1.  The number of iterations exceeds a specified maximum, $N_{\\max}$.\n2.  The denominator in the secant formula, $f(T_{k-1}) - f(T_{k-2})$, becomes zero (or numerically indistinguishable from zero), which would lead to a division by zero.\nIn either failure scenario, the root is considered undefined and is represented by a not-a-number value.\n\nThe second part of the problem is to empirically estimate the order of convergence, $p$. The error in the $k$-th iterate, $e_k = |T_k - T^*|$, for a method with convergence order $p$ generally satisfies the relationship $e_{k+1} \\approx \\lambda e_k^p$ for some constant $\\lambda$. From this, one can derive an estimate for $p$ using three consecutive errors. As specified, we use the final computed iterate, $r$, as an approximation for the true root $T^*$. The errors are defined as $e_{n-1} = |T_{n-1} - r|$, $e_{n-2} = |T_{n-2} - r|$, and $e_{n-3} = |T_{n-3} - r|$, where $T_{n-1}$, $T_{n-2}$, and $T_{n-3}$ are the three iterates preceding the final result $r$. The order $p$ is then estimated by the formula:\n$$\np \\approx \\frac{\\ln\\left(e_{n-1} / e_{n-2}\\right)}{\\ln\\left(e_{n-2} / e_{n-3}\\right)}\n$$\nThis calculation is only performed if at least four iterates are available (i.e., $T_0, T_1, T_2, T_3, \\dots$) and the errors $e_{n-1}, e_{n-2}, e_{n-3}$ are all strictly positive. Otherwise, $p$ is also considered undefined.\n\nFor a simple root (where $f(T^*) = 0$ but $f'(T^*) \\ne 0$), the secant method is known to have a superlinear convergence order of $p = \\phi = \\frac{1+\\sqrt{5}}{2} \\approx 1.618$. For a multiple root of multiplicity $m  1$ (where $f(T^*) = f'(T^*) = \\dots = f^{(m-1)}(T^*) = 0$), the convergence degrades to linear, with $p=1$. These theoretical values serve as a benchmark for our empirical estimates. For test case D, where $c_1=4$ and $c_2=-3$, the function $f(T) = T^4 - 4T + 3$ has a double root at $T=1$ since $f(1) = 1 - 4 + 3 = 0$ and $f'(1) = 4(1)^3 - 4 = 0$, while $f''(1) = 12(1)^2=12 \\ne 0$. We therefore expect to observe $p \\approx 1$ for this case. For all other cases, the roots are simple, and we expect $p \\approx 1.618$.\n\nThe implementation will consist of a function that performs the secant iteration for a given set of parameters $(c_1, c_2, T_0, T_1, \\varepsilon, N_{\\max})$, records the iterates, and upon convergence, calculates the root $T^*$ and the empirical order $p$. This function will be applied to each of the five specified test cases to generate the final output.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to solve the problem for all test cases and print the result.\n    \"\"\"\n\n    def secant_solver(c1, c2, T0, T1, tol, n_max):\n        \"\"\"\n        Implements the secant method and computes the empirical order of convergence.\n\n        Args:\n            c1 (float): Coefficient c1 in the equation f(T) = T^4 - c1*T - c2.\n            c2 (float): Coefficient c2 in the equation.\n            T0 (float): First initial guess for the root.\n            T1 (float): Second initial guess for the root.\n            tol (float): Absolute tolerance for convergence.\n            n_max (int): Maximum number of iterations.\n\n        Returns:\n            tuple: A pair (root, p) containing the approximated root and the\n                   empirical order of convergence. Returns (np.nan, np.nan) on failure.\n        \"\"\"\n\n        def f(T):\n            \"\"\"The nonlinear function for which to find the root.\"\"\"\n            return T**4 - c1 * T - c2\n\n        iterates = [T0, T1]\n        tk_minus_1 = T1\n        tk_minus_2 = T0\n        root = np.nan\n        p = np.nan\n\n        # The loop starts from k=2, but Python's range is 0-indexed.\n        # This will run n_max times for the update step.\n        for _ in range(n_max):\n            f_prev = f(tk_minus_1)\n            f_prev2 = f(tk_minus_2)\n            \n            denominator = f_prev - f_prev2\n            \n            # Check for division by zero, as specified in failure conditions.\n            if abs(denominator)  1e-15:\n                return np.nan, np.nan\n            \n            # Secant method update formula\n            tk = tk_minus_1 - f_prev * (tk_minus_1 - tk_minus_2) / denominator\n            iterates.append(tk)\n\n            # Check stopping criteria\n            if abs(tk - tk_minus_1) = tol or abs(f(tk)) = tol:\n                root = tk\n                break\n            \n            # Update values for the next iteration\n            tk_minus_2 = tk_minus_1\n            tk_minus_1 = tk\n        else:\n            # This block executes if the for loop completes without a 'break',\n            # meaning convergence was not achieved within n_max iterations.\n            return np.nan, np.nan\n\n        # If converged, try to calculate the empirical order of convergence p.\n        # This requires at least 4 iterates to have been generated (T0, T1, T2, T3).\n        if len(iterates) >= 4:\n            r = root  # Use the final iterate as the approximation for the true root.\n            \n            # The last four iterates in the list are T_{n-3}, T_{n-2}, T_{n-1}, T_n (which is r).\n            e_n_minus_1 = abs(iterates[-2] - r)\n            e_n_minus_2 = abs(iterates[-3] - r)\n            e_n_minus_3 = abs(iterates[-4] - r)\n            \n            # The formula for p is valid only if errors are strictly positive.\n            if e_n_minus_1 > 0 and e_n_minus_2 > 0 and e_n_minus_3 > 0:\n                # np.log handles arguments properly. Check denominator to avoid division by zero.\n                log_ratio_den = np.log(e_n_minus_2 / e_n_minus_3)\n                if abs(log_ratio_den) > 1e-15:\n                    log_ratio_num = np.log(e_n_minus_1 / e_n_minus_2)\n                    p = log_ratio_num / log_ratio_den\n\n        return root, p\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # Case A\n        {'c1': 5, 'c2': 1, 'T0': 1, 'T1': 2, 'tol': 1e-12, 'n_max': 100},\n        # Case B\n        {'c1': 1, 'c2': 100, 'T0': 2.5, 'T1': 3.5, 'tol': 1e-10, 'n_max': 100},\n        # Case C\n        {'c1': 0.1, 'c2': 0.001, 'T0': 0.2, 'T1': 0.6, 'tol': 1e-12, 'n_max': 100},\n        # Case D\n        {'c1': 4, 'c2': -3, 'T0': 0.8, 'T1': 1.2, 'tol': 1e-12, 'n_max': 200},\n        # Case E\n        {'c1': 10, 'c2': 0, 'T0': 0.5, 'T1': 4.0, 'tol': 1e-12, 'n_max': 100},\n    ]\n\n    results = []\n    for case in test_cases:\n        T_star, p = secant_solver(case['c1'], case['c2'], case['T0'], case['T1'], case['tol'], case['n_max'])\n        results.append([T_star, p])\n\n    # Format the final output string exactly as required, without spaces.\n    # str(np.nan) produces 'nan' as required.\n    output_parts = [f\"[{str(r)},{str(p)}]\" for r, p in results]\n    final_output = f\"[{','.join(output_parts)}]\"\n    \n    print(final_output)\n\nsolve()\n```", "id": "3271741"}]}