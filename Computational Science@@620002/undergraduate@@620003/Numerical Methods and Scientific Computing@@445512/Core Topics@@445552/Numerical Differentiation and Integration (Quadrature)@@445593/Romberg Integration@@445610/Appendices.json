{"hands_on_practices": [{"introduction": "Let's begin with a foundational exercise to master the core mechanics of Romberg integration. This practice guides you through the first complete extrapolation step, which is the heart of the method's power. By starting with basic trapezoidal rule approximations and then applying the Richardson extrapolation formula, you will see firsthand how a more accurate estimate, $R_{2,2}$, is generated for a familiar integral.", "problem": "Consider the numerical evaluation of the definite integral $I = \\int_0^{\\pi} \\sin(x) dx$, where the argument of the sine function is in radians. We will use Romberg integration to approximate its value. The Romberg tableau is constructed using the recursive formula:\n$$R_{k, j} = \\frac{4^{j-1} R_{k, j-1} - R_{k-1, j-1}}{4^{j-1} - 1}$$\nfor $k \\ge 2$ and $j \\ge 2$. The first column, $R_{k,1}$ for $k \\ge 1$, is computed using the composite trapezoidal rule with $n = 2^{k-1}$ subintervals. The composite trapezoidal rule for an integral $\\int_a^b f(x) dx$ with $n$ subintervals of width $h=(b-a)/n$ is given by:\n$$T_n = \\frac{h}{2} \\left[f(a) + 2\\sum_{i=1}^{n-1} f(a+ih) + f(b)\\right]$$\nand we set $R_{k,1} = T_{2^{k-1}}$.\n\nYour task is to compute the approximation $R_{2,2}$ for the given integral. Report your answer as a numerical value rounded to four significant figures.", "solution": "The problem asks for the Romberg integration approximation $R_{2,2}$ for the integral $I = \\int_0^{\\pi} \\sin(x) dx$. To find $R_{2,2}$, we first need to compute the trapezoidal approximations $R_{1,1}$ and $R_{2,1}$.\n\n**Step 1: Calculate $R_{1,1}$**\n$R_{1,1}$ corresponds to the composite trapezoidal rule with $n = 2^{1-1} = 1$ subinterval.\nThe interval is $[a, b] = [0, \\pi]$.\nThe step size is $h = \\frac{b-a}{n} = \\frac{\\pi-0}{1} = \\pi$.\nThe formula for the trapezoidal rule with one subinterval is:\n$$R_{1,1} = T_1 = \\frac{h}{2}[f(a) + f(b)]$$\nSubstituting the values for $f(x) = \\sin(x)$, $a=0$, $b=\\pi$, and $h=\\pi$:\n$$R_{1,1} = \\frac{\\pi}{2}[\\sin(0) + \\sin(\\pi)]$$\nSince $\\sin(0) = 0$ and $\\sin(\\pi) = 0$, we have:\n$$R_{1,1} = \\frac{\\pi}{2}[0 + 0] = 0$$\n\n**Step 2: Calculate $R_{2,1}$**\n$R_{2,1}$ corresponds to the composite trapezoidal rule with $n = 2^{2-1} = 2$ subintervals.\nThe step size is $h = \\frac{b-a}{n} = \\frac{\\pi-0}{2} = \\frac{\\pi}{2}$.\nThe evaluation points are $x_0 = 0$, $x_1 = 0+h = \\frac{\\pi}{2}$, and $x_2 = 0+2h = \\pi$.\nThe formula for the composite trapezoidal rule with two subintervals is:\n$$R_{2,1} = T_2 = \\frac{h}{2}[f(x_0) + 2f(x_1) + f(x_2)]$$\nSubstituting the values:\n$$R_{2,1} = \\frac{\\pi/2}{2}\\left[\\sin(0) + 2\\sin\\left(\\frac{\\pi}{2}\\right) + \\sin(\\pi)\\right]$$\nSince $\\sin(0) = 0$, $\\sin(\\frac{\\pi}{2}) = 1$, and $\\sin(\\pi) = 0$, we get:\n$$R_{2,1} = \\frac{\\pi}{4}[0 + 2(1) + 0] = \\frac{\\pi}{4}(2) = \\frac{\\pi}{2}$$\n\n**Step 3: Calculate $R_{2,2}$**\nNow we use the Romberg extrapolation formula provided in the problem statement to find $R_{2,2}$. For $k=2$ and $j=2$, the formula is:\n$$R_{2,2} = \\frac{4^{2-1} R_{2, 2-1} - R_{2-1, 2-1}}{4^{2-1} - 1} = \\frac{4R_{2,1} - R_{1,1}}{3}$$\nSubstituting the previously calculated values of $R_{1,1}=0$ and $R_{2,1}=\\frac{\\pi}{2}$:\n$$R_{2,2} = \\frac{4\\left(\\frac{\\pi}{2}\\right) - 0}{3} = \\frac{2\\pi}{3}$$\n\n**Step 4: Numerical value and rounding**\nFinally, we compute the numerical value and round it to four significant figures as requested.\n$$R_{2,2} = \\frac{2\\pi}{3} \\approx \\frac{2 \\times 3.14159265...}{3} \\approx 2.0943951...$$\nRounding to four significant figures, we look at the fifth figure. Since it is 3 (which is less than 5), we round down.\n$$R_{2,2} \\approx 2.094$$", "answer": "$$\\boxed{2.094}$$", "id": "2198712"}, {"introduction": "Now that you are comfortable with the basic extrapolation, let's apply the method to a more realistic scenario from engineering. This problem requires you to construct a larger portion of the Romberg table to evaluate an integral modeling energy consumption. This exercise will solidify your understanding of the recursive process and give you practice with the full workflow needed to reach a higher-order approximation like $R_{3, 3}$, demonstrating the method's practical utility.", "problem": "An engineer is modeling the energy consumption of a novel robotic actuator. The instantaneous power drawn by the actuator, $P(t)$, over a short time interval is described by the function $P(t) = P_0 f(t)$, where $f(t) = (1 + \\sin^2(\\pi t)) \\exp(-0.5 t)$ for time $t$ in seconds. To accurately determine the total energy consumed over the interval from $t=0$ to $t=1$ s, the engineer needs to compute the dimensionless integral $I = \\int_0^1 f(t) dt$.\n\nThe engineer decides to use Romberg integration to approximate this integral. The Romberg table, denoted by $R_{i, j}$, is constructed as follows:\n1.  The first column, $R_{i, 1}$ for $i \\ge 1$, contains the approximations from the composite trapezoidal rule. Specifically, $R_{i, 1}$ is the result of the composite trapezoidal rule using $n = 2^{i-1}$ subintervals.\n2.  Subsequent columns, for $j \\ge 2$, are generated using the Richardson extrapolation formula:\n    $$R_{i, j} = R_{i, j-1} + \\frac{R_{i, j-1} - R_{i-1, j-1}}{4^{j-1} - 1}$$\n    for $i \\ge j \\ge 2$.\n\nYour task is to calculate the value of the Romberg table entry $R_{3, 3}$. Round your final answer to five significant figures.", "solution": "We need $R_{3,3}$ for $I=\\int_{0}^{1} f(t)\\,\\mathrm{d}t$ with $f(t)=(1+\\sin^{2}(\\pi t))\\exp(-0.5\\,t)$ by Romberg integration.\n\nFirst, compute the composite trapezoidal approximations $R_{i,1}$ for $i=1,2,3$.\n- For $i=1$ ($n=2^{1-1}=1$), $h=1$, nodes $t_{0}=0$, $t_{1}=1$:\n$$\nf(0)=(1+\\sin^{2}(0))\\exp(0)=1,\\quad f(1)=(1+\\sin^{2}(\\pi))\\exp(-0.5)=\\exp(-0.5).\n$$\nHence\n$$\nR_{1,1}=\\frac{h}{2}\\left[f(0)+f(1)\\right]=\\frac{1}{2}\\left(1+\\exp(-0.5)\\right).\n$$\n- For $i=2$ ($n=2^{2-1}=2$), $h=\\frac{1}{2}$, nodes $t=0,\\frac{1}{2},1$:\n$$\nf\\!\\left(\\tfrac{1}{2}\\right)=(1+\\sin^{2}(\\tfrac{\\pi}{2}))\\exp(-0.25)=2\\,\\exp(-0.25).\n$$\nThus\n$$\nR_{2,1}=\\frac{h}{2}\\left[f(0)+2f\\!\\left(\\tfrac{1}{2}\\right)+f(1)\\right]\n=\\frac{1}{4}\\left(1+4\\exp(-0.25)+\\exp(-0.5)\\right).\n$$\n- For $i=3$ ($n=2^{3-1}=4$), $h=\\frac{1}{4}$, nodes $t=0,\\frac{1}{4},\\frac{1}{2},\\frac{3}{4},1$:\n$$\nf\\!\\left(\\tfrac{1}{4}\\right)=\\left(1+\\sin^{2}\\!\\left(\\tfrac{\\pi}{4}\\right)\\right)\\exp(-0.125)=\\frac{3}{2}\\exp(-0.125),\n$$\n$$\nf\\!\\left(\\tfrac{3}{4}\\right)=\\left(1+\\sin^{2}\\!\\left(\\tfrac{3\\pi}{4}\\right)\\right)\\exp(-0.375)=\\frac{3}{2}\\exp(-0.375),\n$$\nand $f(0)$, $f(\\tfrac{1}{2})$, $f(1)$ as above. Then\n$$\nR_{3,1}=\\frac{h}{2}\\left[f(0)+2\\left(f\\!\\left(\\tfrac{1}{4}\\right)+f\\!\\left(\\tfrac{1}{2}\\right)+f\\!\\left(\\tfrac{3}{4}\\right)\\right)+f(1)\\right]\n=\\frac{1}{8}\\left(1+3\\exp(-0.125)+4\\exp(-0.25)+3\\exp(-0.375)+\\exp(-0.5)\\right).\n$$\n\nNext, apply Richardson extrapolation for $j=2, 3$:\n$$\nR_{i,j}=R_{i,j-1}+\\frac{R_{i,j-1}-R_{i-1,j-1}}{4^{j-1}-1},\\quad i\\geq j\\geq 2.\n$$\nThus,\n$$\nR_{2,2}=R_{2,1}+\\frac{R_{2,1}-R_{1,1}}{3},\\qquad\nR_{3,2}=R_{3,1}+\\frac{R_{3,1}-R_{2,1}}{3},\n$$\n$$\nR_{3,3}=R_{3,2}+\\frac{R_{3,2}-R_{2,2}}{15}.\n$$\n\nNow evaluate numerically (using $\\exp(-0.125)\\approx 0.8824969$, $\\exp(-0.25)\\approx 0.7788008$, $\\exp(-0.375)\\approx 0.6872893$, $\\exp(-0.5)\\approx 0.6065307$):\n$$\nR_{1,1}\\approx 0.8032653,\\quad\nR_{2,1}\\approx 1.1804334,\\quad\nR_{3,1}\\approx 1.1788865,\n$$\n$$\nR_{2,2}\\approx 1.3061561,\\quad\nR_{3,2}\\approx 1.1783709,\n$$\n$$\nR_{3,3}\\approx 1.1698519.\n$$\nRounding to five significant figures gives $1.1699$.", "answer": "$$\\boxed{1.1699}$$", "id": "2198775"}, {"introduction": "An expert in numerical methods understands not only how to apply a technique, but also recognizes its limitations and knows how to adapt. This final practice presents a crucial challenge where standard Romberg integration fails to achieve its expected high-order accuracy due to properties of the function being integrated. You will diagnose the issue, which is rooted in the function's lack of smoothness, and identify a clever change of variables to restore the method's power—a vital skill in practical scientific computing.", "problem": "Consider the integral $I=\\int_{0}^{1}\\sqrt{x}\\,\\sin(x)\\,dx$ and the application of Romberg integration to approximate $I$. Romberg integration is obtained by applying Richardson extrapolation to the composite trapezoidal rule on successively halved step sizes, and it relies on the assumption that the error of the composite trapezoidal rule admits a regular asymptotic structure in the step size $h$ under sufficient smoothness of the integrand on $[0,1]$. Using only this definition and the behavior of derivatives implied by the integrand’s form near the endpoints, reason from first principles about whether these smoothness conditions are satisfied and how the structure of the error in $h$ is affected. Then, identify a change of variables that restores the differentiability properties required for high-order Romberg convergence on $[0,1]$.\n\nWhich option correctly explains the observed failure of Romberg to attain its nominal sequence of even orders and proposes an effective change of variables that restores high-order convergence?\n\n- A. Romberg fails because the integrand is not periodic on $[0,1]$, which invalidates the endpoint cancellation needed for the extrapolation. Use $x=\\sin^{2}(t)$ to enforce periodicity-like endpoint behavior and then apply Romberg in $t$ on $[0,\\pi/2]$.\n- B. Romberg fails because the integrand’s higher derivatives are unbounded at $x=0$, so the error of the trapezoidal rule contains non-integer powers of $h$ that the standard extrapolation cannot cancel in a hierarchy of even powers. Use the algebraic desingularizing substitution $x=t^{2}$ to obtain $\\int_{0}^{1}2t^{2}\\sin(t^{2})\\,dt$ and then apply Romberg in $t\\in[0,1]$.\n- C. Romberg fails because $\\sin(x)$ produces oscillations that require asymptotic oscillatory quadrature. Use the method of stationary phase after the substitution $x=\\ln(t)$ to convert the interval and then apply Romberg to the transformed integral.\n- D. Romberg fails because of a cusp at $x=1$ that spoils the boundary terms in the error expansion. Use $x=1-t^{2}$ to smooth the behavior at the right endpoint and then apply Romberg in $t\\in[0,1]$.", "solution": "The problem asks for an analysis of the failure of Romberg integration for the integral $I=\\int_{0}^{1}\\sqrt{x}\\,\\sin(x)\\,dx$ and for a suitable change of variables to restore its high-order convergence properties.\n\nThe core principle of Romberg integration is the application of Richardson extrapolation to the composite trapezoidal rule. The success of this extrapolation hinges on the error of the trapezoidal rule, $E_T(h)$, having a specific asymptotic expansion in even powers of the step size $h$. This expansion is given by the Euler-Maclaurin formula. For an integral $I = \\int_a^b f(x) \\, dx$ approximated by the composite trapezoidal rule $T(h)$ with step size $h=(b-a)/n$, the error is:\n$$ E_T(h) = T(h) - I = \\sum_{k=1}^{m-1} \\frac{B_{2k}}{(2k)!} h^{2k} [f^{(2k-1)}(b) - f^{(2k-1)}(a)] + R_{2m}(h) $$\nHere, $B_{2k}$ are the Bernoulli numbers, and $R_{2m}(h)$ is a remainder term of order $O(h^{2m})$. For this expansion to exist up to the $h^{2m-2}$ term, the integrand $f(x)$ must be at least of class $C^{2m-1}[a, b]$, i.e., its first $2m-1$ derivatives must exist and be continuous on the closed interval $[a, b]$. Romberg integration uses this structure by creating linear combinations of trapezoidal sums for different $h$ to systematically eliminate the error terms $c_1 h^2, c_2 h^4, c_3 h^6, \\dots$ and thereby achieve higher orders of accuracy.\n\nLet us analyze the given integrand, $f(x) = \\sqrt{x}\\sin(x)$, on the interval $[0, 1]$. The potential point of failure for differentiability is at the endpoint $x=0$.\n\nThe first derivative is:\n$$ f'(x) = \\frac{d}{dx}(x^{1/2}\\sin(x)) = \\frac{1}{2}x^{-1/2}\\sin(x) + x^{1/2}\\cos(x) $$\nTo check continuity at $x=0$, we evaluate the limit as $x \\to 0^+$. Using the approximation $\\sin(x) \\approx x$ for small $x$, the first term behaves as $\\frac{1}{2}x^{-1/2}(x) = \\frac{1}{2}x^{1/2}$, which approaches $0$. The second term $x^{1/2}\\cos(x)$ also approaches $0$. Thus, $f'(x)$ is continuous at $x=0$ with $f'(0)=0$.\n\nThe second derivative is:\n$$ f''(x) = \\frac{d}{dx} \\left( \\frac{1}{2}x^{-1/2}\\sin(x) + x^{1/2}\\cos(x) \\right) $$\n$$ f''(x) = \\left( -\\frac{1}{4}x^{-3/2}\\sin(x) + \\frac{1}{2}x^{-1/2}\\cos(x) \\right) + \\left( \\frac{1}{2}x^{-1/2}\\cos(x) - x^{1/2}\\sin(x) \\right) $$\n$$ f''(x) = -\\frac{1}{4}x^{-3/2}\\sin(x) + x^{-1/2}\\cos(x) - x^{1/2}\\sin(x) $$\nLet's examine the behavior of $f''(x)$ as $x \\to 0^+$.\n- The term $-\\frac{1}{4}x^{-3/2}\\sin(x) \\approx -\\frac{1}{4}x^{-3/2}(x) = -\\frac{1}{4}x^{-1/2}$, which is unbounded.\n- The term $x^{-1/2}\\cos(x) \\approx x^{-1/2}$, which is also unbounded.\n- The term $-x^{1/2}\\sin(x) \\approx -x^{3/2}$, which approaches $0$.\n\nSince $f''(x)$ is unbounded as $x \\to 0^+$, the function $f(x)$ is not in $C^2[0, 1]$. All higher derivatives will also be unbounded at $x=0$. This violates the smoothness condition required for the standard Euler-Maclaurin expansion.\n\nWhen the integrand is not sufficiently smooth, the error expansion contains non-integer powers of $h$. For an integrand of the form $f(x) = x^\\alpha g(x)$ with $g(x)$ smooth and $\\alpha > -1$, a generalized Euler-Maclaurin formula shows that the error for the trapezoidal rule contains terms of the form $h^{\\alpha+1+k}$ in addition to the usual even powers of $h$. In our case, $f(x) = x^{1/2} \\sin(x) = x^{1/2}(x - x^3/6 + \\dots) = x^{3/2} - x^{7/2}/6 + \\dots$. The dominant non-analytic behavior comes from the $x^{3/2}$ term (corresponding to $\\alpha=3/2 > -1$). A more careful analysis (Lyness-Ninham series) shows that the leading anomalous term in the error is of order $h^{1/2+1} = h^{3/2}$. The overall error expansion has the form:\n$E_T(h) = c_1 h^{3/2} + c_2 h^2 + c_3 h^{5/2} + c_4 h^4 + \\dots$.\nStandard Romberg extrapolation, which assumes an expansion in $h^2, h^4, \\dots$, fails because it cannot correctly cancel the leading $h^{3/2}$ term.\n\nTo restore high-order convergence, we must use a change of variables to make the integrand smooth. The singularity arises from the $\\sqrt{x}=x^{1/2}$ term. An algebraic substitution $x = t^2$ is the standard approach to remove such a singularity.\nLet $x = t^2$. Then $dx = 2t \\, dt$. The integration limits change: as $x$ goes from $0$ to $1$, $t$ also goes from $0$ to $1$.\nThe integral becomes:\n$$ I = \\int_{0}^{1} \\sqrt{t^2} \\sin(t^2) (2t \\, dt) = \\int_{0}^{1} t \\sin(t^2) (2t \\, dt) = \\int_{0}^{1} 2t^2 \\sin(t^2) \\, dt $$\nThe new integrand is $g(t) = 2t^2 \\sin(t^2)$. We check its smoothness on $[0,1]$.\nUsing the Taylor series for $\\sin(u) = u - u^3/3! + u^5/5! - \\dots$, we have:\n$$ g(t) = 2t^2 \\left( t^2 - \\frac{(t^2)^3}{6} + \\frac{(t^2)^5}{120} - \\dots \\right) = 2t^4 - \\frac{1}{3}t^8 + \\frac{1}{60}t^{12} - \\dots $$\nThis is a power series in $t$ that converges for all $t$. The function $g(t)$ is analytic, and therefore infinitely differentiable ($C^\\infty$) on $[0,1]$. All its derivatives are bounded. Applying Romberg integration to this transformed integral will now exhibit the expected high-order convergence, as the conditions for the Euler-Maclaurin formula are satisfied.\n\nNow, we evaluate each option:\n\n- **A.** \"Romberg fails because the integrand is not periodic on $[0,1]$, which invalidates the endpoint cancellation needed for the extrapolation. Use $x=\\sin^{2}(t)$ to enforce periodicity-like endpoint behavior and then apply Romberg in $t$ on $[0,\\pi/2]$.\"\nThe statement that failure is due to lack of periodicity is incorrect. Periodicity is a condition for super-algebraic convergence of the trapezoidal rule, but its absence is not the reason for the failure of standard Romberg. The failure is due to lack of smoothness (unbounded derivatives). The substitution $x=\\sin^2(t)$ does create a smooth integrand, but the reason provided for the failure is wrong. Therefore, this option does not *correctly explain* the failure. **Incorrect**.\n\n- **B.** \"Romberg fails because the integrand’s higher derivatives are unbounded at $x=0$, so the error of the trapezoidal rule contains non-integer powers of $h$ that the standard extrapolation cannot cancel in a hierarchy of even powers. Use the algebraic desingularizing substitution $x=t^{2}$ to obtain $\\int_{0}^{1}2t^{2}\\sin(t^{2})\\,dt$ and then apply Romberg in $t\\in[0,1]$.\"\nThis option correctly identifies the reason for failure: unbounded higher derivatives at $x=0$. It correctly explains the consequence: the error expansion contains non-integer powers of $h$, which foils the standard Richardson extrapolation. It also proposes the correct and effective change of variables $x=t^2$, and correctly derives the transformed integral. This option is fully consistent with our analysis. **Correct**.\n\n- **C.** \"Romberg fails because $\\sin(x)$ produces oscillations that require asymptotic oscillatory quadrature. Use the method of stationary phase after the substitution $x=\\ln(t)$ to convert the interval and then apply Romberg to the transformed integral.\"\nThe oscillations from $\\sin(x)$ on $[0,1]$ are not \"high frequency\" and are not the cause of the method's failure. Standard quadrature rules handle such mild oscillations well if the integrand is smooth. The method of stationary phase is irrelevant here. The proposed substitution $x=\\ln(t)$ maps the singularity at $x=0$ to $t=1$, but does not remove it, so it is ineffective. The explanation is incorrect, and the proposed solution is inappropriate. **Incorrect**.\n\n- **D.** \"Romberg fails because of a cusp at $x=1$ that spoils the boundary terms in the error expansion. Use $x=1-t^{2}$ to smooth the behavior at the right endpoint and then apply Romberg in $t\\in[0,1]$.\"\nThis statement is factually wrong. The integrand $f(x) = \\sqrt{x}\\sin(x)$ is analytic at $x=1$. The problem is at $x=0$. The proposed substitution $x=1-t^2$ is designed to handle a singularity at $x=1$, not $x=0$. It would merely transfer the problem from one endpoint of the integration interval to the other. The explanation is incorrect, and the proposed solution is misdirected. **Incorrect**.", "answer": "$$\\boxed{B}$$", "id": "3268261"}]}