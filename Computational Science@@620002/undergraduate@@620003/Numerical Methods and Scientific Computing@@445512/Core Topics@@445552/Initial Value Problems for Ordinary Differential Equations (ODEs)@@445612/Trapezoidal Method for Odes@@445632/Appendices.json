{"hands_on_practices": [{"introduction": "Implicit methods like the trapezoidal rule transform a differential equation into a sequence of algebraic equations that must be solved at each time step. This practice provides a purely analytical dive into this process for the nonlinear ODE $y' = y^2$, where the resulting algebraic equation is a quadratic. By solving this equation explicitly, you will uncover how the structure of the ODE imposes its own constraints on the maximum possible step size, a crucial insight into the challenges of nonlinear implicit solvers [@problem_id:3284169].", "problem": "Consider the ordinary differential equation (ODE) $y'(t) = y(t)^{2}$ with initial value $y(0) = y_{0}  0$. Let $\\{t_{n}\\}_{n \\ge 0}$ be a uniform grid with $t_{n+1} = t_{n} + h$ for a fixed step size $h  0$, and let $\\{y_{n}\\}_{n \\ge 0}$ be the discrete approximation defined by a one-step method. Starting from the fundamental integral relation for autonomous ODEs,\n$$\ny(t_{n+1}) = y(t_{n}) + \\int_{t_{n}}^{t_{n+1}} y(t)^{2} \\, dt,\n$$\napply the trapezoidal numerical quadrature to approximate the integral and thereby derive the implicit algebraic relation linking $y_{n+1}$ and $y_{n}$. Show that the resulting relation is a quadratic equation in $y_{n+1}$, and solve this quadratic explicitly for $y_{n+1}$, selecting the branch that recovers $y_{n+1} \\to y_{n}$ as $h \\to 0$. Then, enforce the condition that $y_{n+1}$ be real-valued and determine the largest positive step size $h_{\\max}(y_{n})$ admitted by this trapezoidal step when $y_{n}  0$. Briefly justify, using the exact solution of the ODE obtained from separation of variables, what happens to $h_{\\max}(y_{n})$ as the solution approaches its blow-up time. Provide your final answer as a two-entry row matrix, where the first entry is the explicit formula for $y_{n+1}$ in terms of $y_{n}$ and $h$, and the second entry is $h_{\\max}(y_{n})$. No rounding is required, and no units are needed.", "solution": "The problem requires the derivation and analysis of a numerical method for the ordinary differential equation (ODE) $y'(t) = f(y(t))$ where $f(y) = y^2$. The derivation starts from the integral form of the ODE.\n\nThe exact solution over a single time step from $t_n$ to $t_{n+1}$ is given by the integral relation:\n$$\ny(t_{n+1}) = y(t_{n}) + \\int_{t_{n}}^{t_{n+1}} y'(t) \\, dt = y(t_{n}) + \\int_{t_{n}}^{t_{n+1}} y(t)^{2} \\, dt\n$$\nWe are asked to approximate the integral using the trapezoidal rule. The trapezoidal rule for an integral $\\int_{a}^{b} g(t) \\, dt$ is given by $\\frac{b-a}{2} (g(a) + g(b))$.\nIn our case, $g(t) = y(t)^2$, $a=t_n$, $b=t_{n+1}$, and the step size is $h = t_{n+1} - t_n$. Applying the rule gives:\n$$\n\\int_{t_{n}}^{t_{n+1}} y(t)^{2} \\, dt \\approx \\frac{h}{2} (y(t_n)^2 + y(t_{n+1})^2)\n$$\nReplacing the exact values $y(t_n)$ and $y(t_{n+1})$ with their numerical approximations, denoted by $y_n$ and $y_{n+1}$ respectively, we obtain the implicit one-step method known as the trapezoidal method for this ODE:\n$$\ny_{n+1} = y_n + \\frac{h}{2} (y_n^2 + y_{n+1}^2)\n$$\nThis is the implicit algebraic relation linking $y_{n+1}$ and $y_n$.\n\nTo show that this is a quadratic equation in $y_{n+1}$, we rearrange the terms:\n$$\n\\frac{h}{2} y_{n+1}^2 - y_{n+1} + \\left(y_n + \\frac{h}{2} y_n^2\\right) = 0\n$$\nThis is an equation of the form $Ay_{n+1}^2 + By_{n+1} + C = 0$, with coefficients $A = \\frac{h}{2}$, $B = -1$, and $C = y_n + \\frac{h}{2} y_n^2$. Thus, it is a quadratic equation for the unknown $y_{n+1}$.\n\nWe solve this quadratic equation for $y_{n+1}$ using the quadratic formula, $y_{n+1} = \\frac{-B \\pm \\sqrt{B^2 - 4AC}}{2A}$:\n$$\ny_{n+1} = \\frac{-(-1) \\pm \\sqrt{(-1)^2 - 4\\left(\\frac{h}{2}\\right)\\left(y_n + \\frac{h}{2} y_n^2\\right)}}{2\\left(\\frac{h}{2}\\right)}\n$$\n$$\ny_{n+1} = \\frac{1 \\pm \\sqrt{1 - 2h(y_n + \\frac{h}{2} y_n^2)}}{h}\n$$\n$$\ny_{n+1} = \\frac{1 \\pm \\sqrt{1 - 2hy_n - h^2 y_n^2}}{h}\n$$\nThe problem requires selecting the branch that satisfies the consistency condition $y_{n+1} \\to y_n$ as $h \\to 0$. We analyze the two branches in this limit.\nFor the '+' branch:\n$$\n\\lim_{h \\to 0} \\frac{1 + \\sqrt{1 - 2hy_n - h^2 y_n^2}}{h}\n$$\nAs $h \\to 0$, the numerator approaches $1 + \\sqrt{1} = 2$, while the denominator approaches $0$. The limit tends to infinity, which is inconsistent.\nFor the '-' branch, we have a $0/0$ indeterminate form. We can use L'Hôpital's rule or a Taylor expansion. Using a Taylor expansion for $\\sqrt{1-x} \\approx 1 - \\frac{x}{2}$ for small $x$:\n$$\n\\sqrt{1 - 2hy_n - h^2 y_n^2} \\approx 1 - \\frac{1}{2}(2hy_n + h^2 y_n^2) = 1 - hy_n - \\frac{1}{2}h^2 y_n^2\n$$\nSubstituting this into the expression for the '-' branch:\n$$\ny_{n+1} \\approx \\frac{1 - (1 - hy_n - \\frac{1}{2}h^2 y_n^2)}{h} = \\frac{hy_n + \\frac{1}{2}h^2 y_n^2}{h} = y_n + \\frac{1}{2}hy_n^2\n$$\nIn the limit as $h \\to 0$, this expression becomes $y_n$. Thus, the correct branch is the one with the minus sign. The explicit formula for the step is:\n$$\ny_{n+1} = \\frac{1 - \\sqrt{1 - 2hy_n - h^2 y_n^2}}{h}\n$$\nNext, we determine the largest positive step size $h_{\\max}(y_{n})$ for which $y_{n+1}$ is real-valued. This requires the discriminant of the quadratic equation to be non-negative:\n$$\n1 - 2hy_n - h^2 y_n^2 \\ge 0\n$$\nSince $y_n  0$ and we seek $h  0$, we can rearrange this into a standard quadratic inequality for $h$:\n$$\ny_n^2 h^2 + 2y_n h - 1 \\le 0\n$$\nThe corresponding quadratic equation $y_n^2 h^2 + 2y_n h - 1 = 0$ has roots given by:\n$$\nh = \\frac{-2y_n \\pm \\sqrt{(2y_n)^2 - 4(y_n^2)(-1)}}{2y_n^2} = \\frac{-2y_n \\pm \\sqrt{8y_n^2}}{2y_n^2} = \\frac{-2y_n \\pm 2\\sqrt{2}y_n}{2y_n^2} = \\frac{-1 \\pm \\sqrt{2}}{y_n}\n$$\nSince the coefficient $y_n^2$ of the $h^2$ term is positive, the parabola opens upwards. The inequality $y_n^2 h^2 + 2y_n h - 1 \\le 0$ holds for $h$ values between the two roots. The roots are $h_1 = \\frac{-1-\\sqrt{2}}{y_n}$ and $h_2 = \\frac{\\sqrt{2}-1}{y_n}$. Since $h$ must be positive, the valid range is $0  h \\le \\frac{\\sqrt{2}-1}{y_n}$. The largest positive step size is therefore:\n$$\nh_{\\max}(y_n) = \\frac{\\sqrt{2}-1}{y_n}\n$$\nFinally, we briefly justify the behavior of $h_{\\max}(y_n)$ near the solution's blow-up time. The exact solution to $y' = y^2$ with $y(0)=y_00$ is found by separation of variables: $\\frac{dy}{y^2} = dt \\implies -1/y = t - 1/y_0 \\implies y(t) = \\frac{y_0}{1-ty_0}$. This solution exhibits finite-time blow-up, meaning $y(t) \\to \\infty$ as $t$ approaches the singularity at $t_{blow-up} = 1/y_0$. As the numerical solution approaches this singularity, the value of $y_n$ becomes arbitrarily large. Consequently, $h_{\\max}(y_n) = (\\sqrt{2}-1)/y_n$ tends to $0$. This means the numerical method requires an infinitesimally small step size to proceed as it approaches the singularity, which is a manifestation of the extreme stiffness of the problem near the blow-up time.\n\nThe problem asks for a two-entry row matrix containing the explicit formula for $y_{n+1}$ and the expression for $h_{\\max}(y_n)$.", "answer": "$$\n\\boxed{\\begin{pmatrix} \\frac{1 - \\sqrt{1 - 2hy_n - h^2 y_n^2}}{h}  \\frac{\\sqrt{2} - 1}{y_n} \\end{pmatrix}}\n$$", "id": "3284169"}, {"introduction": "Now that you have seen how an implicit step creates an algebraic equation, the next practical challenge is how to solve it efficiently. This hands-on coding exercise directs you to implement two fundamental iterative solvers—a simple fixed-point iteration and the more robust Newton's method—for a stiff linear problem. This comparison will starkly illustrate the limitations of simpler approaches and highlight why Newton's method is a cornerstone for building practical, high-performance implicit integrators [@problem_id:3284122].", "problem": "Implement a program that constructs and analyzes an implicit one-step method for a scalar initial value problem derived from the fundamental integral form. Consider the initial value problem defined by the ordinary differential equation $y'(t) = -100\\,y(t) + 100\\,t + 101$ with initial condition $y(0) = 1$. Starting from the identity $y(t_{n+1}) = y(t_n) + \\int_{t_n}^{t_{n+1}} f(t, y(t))\\,dt$ and the fact that numerical quadrature can approximate the integral of a smooth function on a short interval, derive the implicit discrete equation resulting from applying the classical trapezoidal quadrature rule to the integral. Do not write down any pre-existing step formulas; instead, use the definition of the trapezoidal rule for numerical integration as the only input and express the resulting nonlinear equation that defines $y_{n+1}$ in terms of known quantities at $t_n$ and unknown quantities at $t_{n+1}$.\n\nTo compute $y_{n+1}$ from the implicit equation at each step, implement both of the following inner solvers for the nonlinear scalar equation that must be satisfied by $y_{n+1}$:\n- A fixed-point (Picard) iteration based on repeatedly substituting the right-hand side expression that emerges from the trapezoidal construction, initialized with $y^{(0)} = y_n$.\n- Newton’s method using the derivative with respect to $y$ of the left-hand side of the implicit equation, with the same initial guess $y^{(0)} = y_n$.\n\nUse an absolute stopping tolerance of $10^{-12}$ for both inner solvers, applied to the natural residual of the equation for Newton’s method and to the difference between successive iterates for the fixed-point iteration. Use a per-step maximum of $100$ inner iterations. If the fixed-point iteration fails to converge at any step within this cap, consider the entire fixed-point solve for that step size to have failed and report a sentinel value as specified below. For both methods, count the total number of inner iterations accumulated over all steps.\n\nTo quantify accuracy, derive the exact solution of the given initial value problem using the integrating factor method and use it to compute the absolute error $|y_N - y_{\\text{exact}}(T)|$ at final time $T$. The integration interval is $[0, T]$ with $T = 1$, and the step size is $h$, so that $t_n = n h$ and $N = T/h$ is an integer.\n\nTest suite:\n- Integrate to $T = 1$ with step sizes $h \\in \\{0.001, 0.01, 0.02, 0.05\\}$, in this order. That is, $h = 0.001$, $h = 0.01$, $h = 0.02$, and $h = 0.05$.\n- For each $h$, compute:\n  1) the final value produced by the trapezoidal method when the implicit solve is carried out by Newton’s method, $y_N^{\\text{(Newton)}}$,\n  2) the absolute error at $T$, namely $|y_N^{\\text{(Newton)}} - y_{\\text{exact}}(1)|$,\n  3) the total number of inner Newton iterations summed over all steps,\n  4) the total number of inner fixed-point iterations summed over all steps if all steps converged; otherwise output the integer $-1$ to indicate failure.\n\nYour program should produce a single line of output containing the results in a flat, comma-separated list enclosed in square brackets and ordered by the step sizes listed above, with four numbers per step size in the order specified. Concretely, the output format must be\n$[y_N^{\\text{(Newton)}}(h_1), |y_N^{\\text{(Newton)}}(h_1) - y_{\\text{exact}}(1)|, \\text{iters}^{\\text{(Newton)}}(h_1), \\text{iters}^{\\text{(Fixed)}}(h_1), \\dots, y_N^{\\text{(Newton)}}(h_4), |y_N^{\\text{(Newton)}}(h_4) - y_{\\text{exact}}(1)|, \\text{iters}^{\\text{(Newton)}}(h_4), \\text{iters}^{\\text{(Fixed)}}(h_4)]$, where $h_1 = 0.001$, $h_2 = 0.01$, $h_3 = 0.02$, and $h_4 = 0.05$. If the fixed-point iteration fails for any step for a given $h$, print $-1$ for $\\text{iters}^{\\text{(Fixed)}}(h)$ for that $h$. All numbers must be printed as plain decimal numerals on a single line in the exact list format shown, with no units and no extra whitespace.", "solution": "The user-provided problem is a well-defined task in the field of numerical analysis for ordinary differential equations (ODEs). It requires the derivation, implementation, and analysis of the implicit trapezoidal method.\n\n### Step 1: Problem Validation\n\nThe problem is validated against the required criteria.\n\n*   **Extraction of Givens**:\n    *   **ODE**: The scalar initial value problem (IVP) is $y'(t) = -100\\,y(t) + 100\\,t + 101$.\n    *   **Initial Condition**: $y(0) = 1$.\n    *   **Integral Form of ODE**: $y(t_{n+1}) = y(t_n) + \\int_{t_n}^{t_{n+1}} f(t, y(t))\\,dt$.\n    *   **Method Derivation**: The numerical method must be derived by applying the trapezoidal quadrature rule to the integral form.\n    *   **Inner Solvers**: The implicit equation at each step is to be solved using two methods: a fixed-point (Picard) iteration and Newton's method.\n    *   **Initial Guess for Inner Solvers**: $y^{(0)} = y_n$ for both methods.\n    *   **Inner Solver Tolerance**: Absolute tolerance of $10^{-12}$. For Newton's method, this applies to the residual. For fixed-point, it applies to the difference between successive iterates.\n    *   **Inner Solver Iteration Limit**: Maximum of $100$ iterations per time step.\n    *   **Fixed-Point Failure**: If convergence is not achieved within the iteration limit at any step, the total iteration count for that step size $h$ is reported as $-1$.\n    *   **Analysis**: Compute the absolute error $|y_N - y_{\\text{exact}}(T)|$ at the final time $T=1$.\n    *   **Discretization**: Time interval is $[0, 1]$. Step size $h$ leads to $t_n = n h$ and total steps $N = T/h$.\n    *   **Test Suite**: Step sizes $h \\in \\{0.001, 0.01, 0.02, 0.05\\}$.\n    *   **Required Outputs per `h`**: $y_N^{\\text{(Newton)}}$, $|y_N^{\\text{(Newton)}} - y_{\\text{exact}}(1)|$, total Newton iterations, total fixed-point iterations (or $-1$).\n\n*   **Validation Verdict**:\n    *   **Scientifically Grounded**: Yes. The problem is a standard an exercise in numerical analysis, involving established methods (trapezoidal rule, Newton's method, fixed-point iteration) applied to a linear ODE.\n    *   **Well-Posed**: Yes. The linear IVP is well-posed, guaranteeing a unique solution. The numerical task is clearly specified.\n    *   **Objective**: Yes. The problem is defined with precise mathematical and computational requirements.\n    *   The problem is complete, consistent, and computationally feasible. It is a substantive and non-trivial task that requires both derivation and implementation.\n\n*   **Conclusion**: The problem is valid.\n\n### Step 2: Solution Derivations and Method Analysis\n\nThe solution requires several analytical derivations before implementation. The ODE is of the form $y'(t) = f(t, y(t))$, where $f(t, y) = -100y + 100t + 101$.\n\n#### Derivation of the Exact Solution\nThe ODE $y' + 100y = 100t + 101$ is a first-order linear ODE. We solve it using an integrating factor $I(t) = e^{\\int 100 dt} = e^{100t}$. Multiplying the ODE by $I(t)$ gives:\n$$ e^{100t}y' + 100e^{100t}y = (100t + 101)e^{100t} $$\nThe left side is the derivative of a product:\n$$ \\frac{d}{dt}(y(t)e^{100t}) = (100t + 101)e^{100t} $$\nIntegrating both sides with respect to $t$:\n$$ y(t)e^{100t} = \\int (100t + 101)e^{100t} dt $$\nThe integral on the right is solved using integration by parts, $\\int u dv = uv - \\int v du$, with $u = 100t+101$ and $dv = e^{100t}dt$. This yields $du = 100dt$ and $v = \\frac{1}{100}e^{100t}$.\n$$ \\int (100t + 101)e^{100t} dt = (100t+101)\\frac{e^{100t}}{100} - \\int \\frac{e^{100t}}{100} (100) dt = (t + 1.01)e^{100t} - \\int e^{100t}dt $$\n$$ = (t + 1.01)e^{100t} - \\frac{1}{100}e^{100t} + C = (t+1)e^{100t} + C $$\nThus, the general solution is:\n$$ y(t) = t + 1 + Ce^{-100t} $$\nApplying the initial condition $y(0) = 1$:\n$$ 1 = 0 + 1 + Ce^0 \\implies C = 0 $$\nThe exact solution is $y_{\\text{exact}}(t) = t + 1$. The value at the final time $T=1$ is $y_{\\text{exact}}(1) = 1+1=2$.\n\n#### Derivation of the Trapezoidal Method\nStarting from the integral form of the ODE over a single step $[t_n, t_{n+1}]$:\n$$ y(t_{n+1}) = y(t_n) + \\int_{t_n}^{t_{n+1}} f(t, y(t)) dt $$\nWe approximate the integral using the trapezoidal rule, $\\int_a^b g(x)dx \\approx \\frac{b-a}{2}(g(a)+g(b))$. Let $h=t_{n+1}-t_n$, $y_n \\approx y(t_n)$, and $y_{n+1} \\approx y(t_{n+1})$.\n$$ \\int_{t_n}^{t_{n+1}} f(t, y(t)) dt \\approx \\frac{h}{2}(f(t_n, y(t_n)) + f(t_{n+1}, y(t_{n+1}))) $$\nSubstituting this into the integral equation gives the implicit trapezoidal method:\n$$ y_{n+1} = y_n + \\frac{h}{2}(f(t_n, y_n) + f(t_{n+1}, y_{n+1})) $$\nThis is an implicit equation because the unknown $y_{n+1}$ appears on both sides.\n\n#### Setup for Inner Solvers\nTo find $y_{n+1}$ at each step, we must solve this equation. Let $w$ be the unknown value for $y_{n+1}$.\n\n**1. Fixed-Point Iteration:**\nThe equation is rearranged to form a fixed-point mapping $w = G(w)$:\n$$ w = y_n + \\frac{h}{2}(f(t_n, y_n) + f(t_{n+1}, w)) $$\nThe iteration is $w^{(k+1)} = G(w^{(k)})$, starting with $w^{(0)} = y_n$. The process is repeated until $|w^{(k+1)} - w^{(k)}|  10^{-12}$.\nConvergence is governed by the contraction mapping principle, which requires $|G'(w)|  1$. The derivative is:\n$$ G'(w) = \\frac{d}{dw} \\left( y_n + \\frac{h}{2}(f(t_n, y_n) + f(t_{n+1}, w)) \\right) = \\frac{h}{2} \\frac{\\partial f}{\\partial y}(t_{n+1}, w) $$\nFor the given problem, $\\frac{\\partial f}{\\partial y} = -100$. Thus, $G'(w) = -50h$. The iteration converges if $|-50h|  1$, or $h  0.02$.\n*   For $h=0.001$: $|-50(0.001)|=0.05  1$. Converges.\n*   For $h=0.01$: $|-50(0.01)|=0.5  1$. Converges.\n*   For $h=0.02$: $|-50(0.02)|=1$. This is a boundary case where convergence is not guaranteed and will be extremely slow, or may fail. The iteration will not meet the tolerance within $100$ steps.\n*   For $h=0.05$: $|-50(0.05)|=2.5  1$. Diverges.\nTherefore, the fixed-point method is expected to fail for $h=0.02$ and $h=0.05$.\n\n**2. Newton's Method:**\nWe solve for the root of the residual function $F(w) = 0$, where:\n$$ F(w) = w - y_n - \\frac{h}{2}(f(t_n, y_n) + f(t_{n+1}, w)) = 0 $$\nThe Newton-Raphson iteration is $w^{(k+1)} = w^{(k)} - \\frac{F(w^{(k)})}{F'(w^{(k)})}$, starting with $w^{(0)} = y_n$. The process repeats until the residual is small: $|F(w^{(k)})|  10^{-12}$.\nThe derivative $F'(w)$ is:\n$$ F'(w) = \\frac{d}{dw} \\left( w - y_n - \\frac{h}{2}(f(t_n, y_n) + f(t_{n+1}, w)) \\right) = 1 - \\frac{h}{2} \\frac{\\partial f}{\\partial y}(t_{n+1}, w) $$\nFor our problem, $F'(w) = 1 - \\frac{h}{2}(-100) = 1 + 50h$.\nSince $f(t,y)$ is linear in $y$, the residual $F(w)$ is a linear function of $w$. Consequently, Newton's method will find the exact root of this linear equation in a single iteration (barring floating-point inaccuracies). Thus, for each time step, the number of Newton iterations is expected to be $1$.\n\n### Step 3: Computational Algorithm\nThe overall algorithm is as follows:\n1.  Initialize a list to store the final results.\n2.  Define the function $f(t,y) = -100y + 100t + 101$ and its partial derivative $\\frac{\\partial f}{\\partial y} = -100$.\n3.  Define the exact solution $y_{\\text{exact}}(t) = t+1$. The final value is $y_{\\text{exact}}(1)=2$.\n4.  Loop through each step size $h \\in \\{0.001, 0.01, 0.02, 0.05\\}$.\n5.  For each $h$, run two separate simulations from $t=0$ to $t=1$: one using Newton's method as the inner solver, and one using the fixed-point method.\n6.  In each simulation, initialize $t=0$, $y=1$, and the total iteration counter.\n7.  Iterate $N=T/h$ times. In each step, call the respective inner solver (Newton or fixed-point) to find $y_{n+1}$ from $y_n$. Accumulate the number of iterations returned by the solver.\n8.  For the fixed-point simulation, if any step fails to converge in $100$ iterations, set a failure flag. The final iteration count will be $-1$.\n9.  After the loops, calculate the final error for the Newton method result.\n10. Store the four required values for the current $h$: $y_N^{\\text{(Newton)}}$, error, Newton iterations, and fixed-point iterations.\n11. After processing all $h$ values, flatten the list of results and format it for printing.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Implements and analyzes the trapezoidal method for a given ODE\n    using both Newton and Fixed-Point inner solvers.\n    \"\"\"\n\n    # --- Problem Definition ---\n    # ODE: y'(t) = -100*y(t) + 100*t + 101\n    # Initial Condition: y(0) = 1\n    # Time interval: [0, 1]\n    \n    y0 = 1.0\n    t_end = 1.0\n    tol = 1e-12\n    max_inner_iters = 100\n    \n    test_h_values = [0.001, 0.01, 0.02, 0.05]\n\n    def f(t, y):\n        \"\"\"RHS of the ODE y' = f(t, y).\"\"\"\n        return -100.0 * y + 100.0 * t + 101.0\n\n    def dfdy(t, y):\n        \"\"\"Partial derivative of f with respect to y.\"\"\"\n        # For this problem, df/dy is constant.\n        return -100.0\n\n    def y_exact(t):\n        \"\"\"Exact solution to the IVP.\"\"\"\n        return t + 1.0\n\n    # --- Solver Implementations ---\n\n    def run_simulation(h, inner_solver_type):\n        \"\"\"\n        Integrates the ODE from t=0 to t=T with step size h,\n        using the specified inner solver.\n\n        Args:\n            h (float): The step size.\n            inner_solver_type (str): 'newton' or 'fixed_point'.\n\n        Returns:\n            A tuple (final_y, total_iters). `total_iters` is -1 on failure.\n        \"\"\"\n        y = y0\n        t = 0.0\n        n_steps = int(round(t_end / h))\n        total_iters = 0\n        \n        for n in range(n_steps):\n            tn = n * h\n            tn1 = (n + 1) * h\n        \n            if inner_solver_type == 'newton':\n                y_next, iters_step = solve_newton_step(y, tn, h)\n            elif inner_solver_type == 'fixed_point':\n                y_next, iters_step = solve_fp_step(y, tn, h)\n            \n            if iters_step == -1:\n                return None, -1 # Failure to converge\n            \n            y = y_next\n            total_iters += iters_step\n            \n        return y, total_iters\n\n    def solve_newton_step(yn, tn, h):\n        \"\"\"Solves for y_{n+1} using Newton's method.\"\"\"\n        tn1 = tn + h\n        fn = f(tn, yn)\n        \n        # F'(w) is constant for this linear ODE\n        F_prime = 1.0 - (h / 2.0) * dfdy(tn1, 0)\n        \n        w = yn  # Initial guess w^(0)\n        \n        # Check initial guess residual\n        fw = f(tn1, w)\n        F_w = w - yn - (h / 2.0) * (fn + fw)\n        if np.abs(F_w)  tol:\n            return w, 0\n\n        for iters in range(1, max_inner_iters + 1):\n            w = w - F_w / F_prime\n            \n            # Check residual of the new iterate\n            fw = f(tn1, w)\n            F_w = w - yn - (h / 2.0) * (fn + fw)\n            \n            if np.abs(F_w)  tol:\n                return w, iters\n                \n        return None, -1  # Did not converge\n\n    def solve_fp_step(yn, tn, h):\n        \"\"\"Solves for y_{n+1} using fixed-point iteration.\"\"\"\n        tn1 = tn + h\n        fn = f(tn, yn)\n        \n        w_k = yn # Initial guess w^(0)\n        \n        for iters in range(1, max_inner_iters + 1):\n            fw_k = f(tn1, w_k)\n            w_k_plus_1 = yn + (h / 2.0) * (fn + fw_k)\n            \n            if np.abs(w_k_plus_1 - w_k)  tol:\n                return w_k_plus_1, iters\n            \n            w_k = w_k_plus_1\n        \n        return None, -1 # Did not converge\n\n    # --- Main Execution Logic ---\n    results = []\n    y_final_exact = y_exact(t_end)\n\n    for h in test_h_values:\n        # 1. Newton's method results\n        yN_newton, iters_newton = run_simulation(h, 'newton')\n        error_newton = np.abs(yN_newton - y_final_exact)\n        \n        # 2. Fixed-point method results\n        # We don't need the final y value, just the iteration count.\n        _, iters_fp = run_simulation(h, 'fixed_point')\n\n        # 3. Collect results for this h\n        results.extend([yN_newton, error_newton, iters_newton, iters_fp])\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "3284122"}, {"introduction": "A robust numerical integrator should not only be accurate but also preserve the fundamental physical properties of the system it models, such as the positivity of a population or concentration. This practice investigates this crucial qualitative feature for the trapezoidal method. You will first analytically derive the condition on the step size $h$ for preserving positivity on a test problem, and then confirm your theoretical findings with a targeted implementation, providing a clear link between the method's mathematical formula and its ability to generate physically plausible solutions [@problem_id:3284056].", "problem": "Consider the scalar initial value problem for an ordinary differential equation (ODE)\n$$\n\\frac{dy}{dt} = f(t,y), \\quad y(t_0) = y_0,\n$$\nwith the requirement that the true solution satisfies $y(t) gt; 0$ for all $t \\ge t_0$. Many models, such as population dynamics, impose $y(t) gt; 0$ as a physical constraint. A numerical method is said to preserve positivity if, starting from $y_0 gt; 0$, it produces numerical approximations $y_n$ that remain strictly positive for all steps $n$.\n\nYour task is to investigate whether the trapezoidal method preserves positivity. Start from the fundamental integral form of the initial value problem over a single time step:\n$$\ny(t_{n+1}) = y(t_n) + \\int_{t_n}^{t_{n+1}} f(t, y(t))\\, dt,\n$$\nand recall that the trapezoidal quadrature approximates an integral over an interval by the average of the integrand at the endpoints times the interval length. Using only this base, derive the trapezoidal time-stepping relation. Then, specialize to the linear test equation\n$$\n\\frac{dy}{dt} = \\mu y, \\quad \\mu \\in \\mathbb{R},\n$$\nand determine from first principles the condition on the time step size $h$ (in relation to $\\mu$) under which the trapezoidal method does or does not preserve positivity, assuming $y_0  0$.\n\nWrite a program that:\n- Implements the trapezoidal method update for the linear test equation in a way that can generate the discrete sequence $\\{y_n\\}_{n=0}^N$ starting from $y_0 gt; 0$ with uniform step size $h$.\n- For each test case below, returns a boolean indicating whether $y_n gt; 0$ for all $n = 1,2,\\ldots,N$ (strict positivity at every step).\n\nUse the following test suite of parameter sets $(\\mu, y_0, h, N)$:\n- Case $1$: $(\\mu, y_0, h, N) = (-1, 1.0, 0.1, 10)$.\n- Case $2$: $(\\mu, y_0, h, N) = (-1, 1.0, 3.0, 5)$.\n- Case $3$: $(\\mu, y_0, h, N) = (1, 0.1, 0.5, 6)$.\n- Case $4$: $(\\mu, y_0, h, N) = (1, 1.0, 3.0, 1)$.\n- Case $5$: $(\\mu, y_0, h, N) = (-10, 0.5, 0.19, 3)$.\n\nNo physical units are involved. Angles are not involved. Percentages are not involved.\n\nFinal output format:\n- Your program should produce a single line of output containing the results as a comma-separated list of booleans enclosed in square brackets, with no spaces. For example, the format must be exactly like\n$$\n[{\\rm True},{\\rm False},{\\rm True},{\\rm False},{\\rm True}].\n$$", "solution": "The problem requires an investigation into the positivity-preserving properties of the trapezoidal method for ordinary differential equations (ODEs). This validation will proceed in three steps: first, deriving the trapezoidal method from the provided integral form; second, specializing this method for the linear test equation; and third, deriving the condition on the time step $h$ that ensures positivity is maintained.\n\n**Step 1: Derivation of the Trapezoidal Method**\n\nThe fundamental theorem of calculus applied to the ODE $\\frac{dy}{dt} = f(t,y)$ over the time interval $[t_n, t_{n+1}]$ gives the exact relation:\n$$\ny(t_{n+1}) = y(t_n) + \\int_{t_n}^{t_{n+1}} f(t, y(t))\\, dt\n$$\nThe problem specifies approximating the integral using the trapezoidal quadrature rule. This rule approximates the area under a curve by the area of a trapezoid formed by the function's values at the interval endpoints. For an integrand $g(t)$ over $[a, b]$, the approximation is $\\int_a^b g(t) dt \\approx \\frac{b-a}{2}(g(a) + g(b))$.\n\nApplying this to our integral, we set the interval as $[t_n, t_{n+1}]$ with length $h = t_{n+1} - t_n$, and the integrand is $f(t, y(t))$. The approximation is:\n$$\n\\int_{t_n}^{t_{n+1}} f(t, y(t))\\, dt \\approx \\frac{h}{2} \\left[ f(t_n, y(t_n)) + f(t_{n+1}, y(t_{n+1})) \\right]\n$$\nWe define the numerical approximations as $y_n \\approx y(t_n)$ and $y_{n+1} \\approx y(t_{n+1})$. Substituting this approximation back into the exact integral relation yields the trapezoidal time-stepping formula:\n$$\ny_{n+1} = y_n + \\frac{h}{2} \\left[ f(t_n, y_n) + f(t_{n+1}, y_{n+1}) \\right]\n$$\nThis is an implicit method because the unknown value $y_{n+1}$ appears on both sides of the equation, as an argument to the function $f$ on the right-hand side.\n\n**Step 2: Specialization for the Linear Test Equation**\n\nThe linear test equation is given by $\\frac{dy}{dt} = \\mu y$, where $\\mu \\in \\mathbb{R}$. For this ODE, the function $f(t, y)$ is simply $f(t, y) = \\mu y$. Substituting this specific form of $f$ into the trapezoidal formula, we get:\n$$\ny_{n+1} = y_n + \\frac{h}{2} \\left[ (\\mu y_n) + (\\mu y_{n+1}) \\right]\n$$\nTo obtain an explicit update rule, we must algebraically solve for $y_{n+1}$:\n$$\ny_{n+1} - \\frac{h\\mu}{2} y_{n+1} = y_n + \\frac{h\\mu}{2} y_n\n$$\nFactoring out $y_{n+1}$ on the left-hand side and $y_n$ on the right-hand side gives:\n$$\ny_{n+1} \\left(1 - \\frac{h\\mu}{2}\\right) = y_n \\left(1 + \\frac{h\\mu}{2}\\right)\n$$\nAssuming that $1 - \\frac{h\\mu}{2} \\neq 0$, we can isolate $y_{n+1}$:\n$$\ny_{n+1} = y_n \\left( \\frac{1 + \\frac{h\\mu}{2}}{1 - \\frac{h\\mu}{2}} \\right)\n$$\nThis is the discrete recurrence relation for the trapezoidal method applied to the linear test equation. The term in the parenthesis is the amplification factor that determines how the solution evolves from one step to the next.\n\n**Step 3: Derivation of the Positivity-Preserving Condition**\n\nA method preserves positivity if, starting with an initial condition $y_0  0$, all subsequent approximations $y_n$ remain strictly positive. From the recurrence relation derived above, if we assume $y_n  0$, then the sign of $y_{n+1}$ is determined entirely by the sign of the amplification factor:\n$$\nR(h\\mu) = \\frac{1 + \\frac{h\\mu}{2}}{1 - \\frac{h\\mu}{2}}\n$$\nFor $y_{n+1}$ to be strictly positive, we require $R(h\\mu)  0$. Let the product $z = h\\mu$. The condition is:\n$$\n\\frac{1 + z/2}{1 - z/2}  0\n$$\nA quotient is positive if and only if the numerator and denominator have the same sign. This is equivalent to their product being positive, provided the denominator is non-zero.\n$$\n\\left(1 + \\frac{z}{2}\\right) \\left(1 - \\frac{z}{2}\\right)  0 \\quad \\text{and} \\quad 1 - \\frac{z}{2} \\neq 0\n$$\nThe product simplifies to a difference of squares:\n$$\n1 - \\left(\\frac{z}{2}\\right)^2  0\n$$\n$$\n1  \\frac{z^2}{4}\n$$\n$$\n4  z^2\n$$\nTaking the square root of both sides gives:\n$$\n|z|  2\n$$\nSubstituting back $z = h\\mu$, we arrive at the condition for strict positivity preservation:\n$$\n|h\\mu|  2\n$$\nIf $|h\\mu| = 2$, then $z^2 = 4$, which means $1-z^2/4=0$. This implies that either the numerator or the denominator (but not both) of $R(z)$ is zero. If $z=2$, the denominator is zero, leading to a division by zero. If $z=-2$, the numerator is zero, leading to $y_{n+1}=0$, which violates strict positivity. If $|h\\mu|  2$, the amplification factor is negative, causing the solution to change sign at each step, violating positivity.\n\nTherefore, the trapezoidal method preserves positivity for the linear test equation if and only if the product of the step size $h$ and the parameter $\\mu$ satisfies $|h\\mu|  2$.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Investigates the positivity preservation of the trapezoidal method for the\n    linear test ODE dy/dt = mu*y.\n    \"\"\"\n    # Define the test cases as tuples of (mu, y0, h, N).\n    test_cases = [\n        (-1.0, 1.0, 0.1, 10),\n        (-1.0, 1.0, 3.0, 5),\n        (1.0, 0.1, 0.5, 6),\n        (1.0, 1.0, 3.0, 1),\n        (-10.0, 0.5, 0.19, 3),\n    ]\n\n    results = []\n\n    for case in test_cases:\n        mu, y0, h, N = case\n        \n        # Initialize the solution variable and the positivity flag.\n        y = np.float64(y0)\n        preserves_positivity = True\n\n        # The amplification factor for the trapezoidal method on the test equation is\n        # R = (1 + h*mu/2) / (1 - h*mu/2).\n        # We check the condition |h*mu|  2, which is equivalent to R  0.\n        # This pre-check is sufficient, but the simulation is performed as requested.\n        \n        # Calculate the numerator and denominator of the amplification factor.\n        # Use np.float64 for precision consistent with typical scientific computing.\n        numerator = np.float64(1.0) + h * mu / np.float64(2.0)\n        denominator = np.float64(1.0) - h * mu / np.float64(2.0)\n\n        # A zero denominator means h*mu = 2, violating positivity.\n        if denominator == 0.0:\n            preserves_positivity = False\n        else:\n            amp_factor = numerator / denominator\n            \n            # If the amplification factor is not positive, positivity is violated.\n            if amp_factor = 0:\n                preserves_positivity = False\n            else:\n                # If the amplification factor is positive, y will never become non-positive\n                # starting from y0  0, as it's just repeated multiplication by a\n                # positive number. The simulation loop is technically redundant if we\n                # trust the analysis, but we run it to confirm step-by-step.\n                for _ in range(N):\n                    y = y * amp_factor\n                    # Check for strict positivity at each step.\n                    if y = 0.0:\n                        preserves_positivity = False\n                        break\n        \n        results.append(preserves_positivity)\n\n    # Format the final output as a comma-separated list of booleans in brackets.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "3284056"}]}