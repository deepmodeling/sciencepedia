{"hands_on_practices": [{"introduction": "The efficiency of an importance sampling estimator is quantified by its variance. A lower variance means a more accurate estimate for a given number of samples. This first exercise provides fundamental practice in deriving the variance of a simple importance sampling estimator. By working through the calculation, you will see directly how the choice of proposal distribution, specifically its variance $\\sigma_q^2$, influences the performance of the Monte Carlo estimation.", "problem": "Importance Sampling is a variance reduction technique used in Monte Carlo methods to estimate properties of a particular distribution, while sampling from a different distribution. Consider the problem of estimating the expectation $I = E_p[h(x)]$, where $p(x)$ is the target probability density function (PDF) and $h(x)$ is a function of interest. Instead of drawing samples from $p(x)$, we draw $N$ samples $\\{x_i\\}_{i=1}^N$ from a proposal distribution $q(x)$. The expectation is then estimated using the importance sampling estimator:\n$$\n\\hat{I}_N = \\frac{1}{N} \\sum_{i=1}^N w(x_i) h(x_i)\n$$\nwhere $w(x) = \\frac{p(x)}{q(x)}$ are the importance weights. The estimator is unbiased, i.e., $E_q[\\hat{I}_N] = I$. The variance of the estimator for a single sample ($N=1$) is given by $\\text{Var}_q(w(X)h(X))$, where $X \\sim q(x)$.\n\n**Problem:**\nLet the target distribution $p(x)$ be the standard normal distribution, $\\mathcal{N}(x|0, 1)$, whose PDF is $p(x) = \\frac{1}{\\sqrt{2\\pi}} e^{-x^2/2}$. We wish to estimate the fourth moment of this distribution, corresponding to the function $h(x) = x^4$.\n\nThe proposal distribution $q(x)$ is chosen to be a zero-mean normal distribution with a different variance $\\sigma_q^2$, i.e., $q(x) = \\mathcal{N}(x|0, \\sigma_q^2)$, with PDF $q(x) = \\frac{1}{\\sqrt{2\\pi}\\sigma_q} e^{-x^2/(2\\sigma_q^2)}$.\n\nDerive a closed-form expression for the variance of the single-sample importance sampling estimator, $\\text{Var}_q(w(X)h(X))$, as a function of $\\sigma_q$. You may assume that the variance is finite, which holds for $\\sigma_q^2 > 1/2$.", "solution": "1. The variance is  \n$$\n\\mathrm{Var}_q\\bigl(w(X)h(X)\\bigr)\n=E_q\\bigl[(w(X)h(X))^2\\bigr]-\\bigl(E_q[w(X)h(X)]\\bigr)^2.\n$$\nSince $h(x)=x^4$, $w(x)=\\frac{p(x)}{q(x)}$, and $I=E_p[x^4]=3$, we need \n$$\nE_q\\bigl[(w(X)x^4)^2\\bigr]\n=\\int q(x)\\Bigl(\\frac{p(x)}{q(x)}\\Bigr)^2 x^8\\,dx\n=\\int \\frac{p(x)^2}{q(x)}\\,x^8\\,dx.\n$$\n\n2. Substitute the Gaussian densities:\n$$\np(x)=\\frac{1}{\\sqrt{2\\pi}}e^{-x^2/2},\\quad\nq(x)=\\frac{1}{\\sqrt{2\\pi}\\,\\sigma_q}e^{-x^2/(2\\sigma_q^2)}.\n$$\nThen\n$$\n\\frac{p(x)^2}{q(x)}\n=\\frac{\\frac1{2\\pi}e^{-x^2}}{\\frac1{\\sqrt{2\\pi}\\,\\sigma_q}e^{-x^2/(2\\sigma_q^2)}}\n=\\frac{\\sigma_q}{\\sqrt{2\\pi}}\\,e^{-x^2\\bigl(1-\\tfrac1{2\\sigma_q^2}\\bigr)}.\n$$\n\n3. Let \n$$\na=1-\\frac1{2\\sigma_q^2}=\\frac{2\\sigma_q^2-1}{2\\sigma_q^2},\\quad\n\\int_{-\\infty}^{\\infty}x^8e^{-a x^2}dx\n=\\frac{7!!}{2^4}\\,a^{-4-\\frac12}\\sqrt\\pi\n=\\frac{105\\sqrt\\pi}{16\\,a^{9/2}}.\n$$\nThus\n$$\nE_q\\bigl[(w(X)x^4)^2\\bigr]\n=\\frac{\\sigma_q}{\\sqrt{2\\pi}}\\cdot\\frac{105\\sqrt\\pi}{16\\,a^{9/2}}\n=\\frac{105\\,\\sigma_q}{16\\sqrt2\\,a^{9/2}}\n=\\frac{105\\,\\sigma_q^{10}}{(2\\sigma_q^2-1)^{9/2}}.\n$$\n\n4. Hence\n$$\n\\mathrm{Var}_q(w(X)x^4)\n=\\frac{105\\,\\sigma_q^{10}}{(2\\sigma_q^2-1)^{9/2}}-3^2\n=\\frac{105\\,\\sigma_q^{10}}{(2\\sigma_q^2-1)^{9/2}}-9.\n$$", "answer": "$$\\boxed{\\frac{105\\,\\sigma_q^{10}}{(2\\sigma_q^2-1)^{9/2}}-9}$$", "id": "767801"}, {"introduction": "While powerful, importance sampling can fail dramatically if the proposal distribution is poorly chosen. A common pitfall is using a proposal with \"lighter tails\" than the target function, which can lead to an estimator with infinite variance. This exercise guides you through a classic example of this failure, asking you to diagnose the problem by analyzing the behavior of the importance weights. Understanding this failure mode is critical for developing the intuition needed to build reliable estimators.", "problem": "Consider the task of estimating the integral $$I=\\int_{-1}^{1}\\frac{1}{\\sqrt{1-x^{2}}}\\,dx$$ using Importance Sampling (IS), where the proposal density is uniform on the interval $$[-1,1]$$, that is $$q(x)=\\frac{1}{2}$$ for $$x\\in[-1,1]$$ and $$q(x)=0$$ otherwise. The IS weight associated with a sample $$X\\sim q$$ is defined by $$W=\\frac{f(X)}{q(X)}$$ where $$f(x)=\\frac{1}{\\sqrt{1-x^{2}}}$$. \n\nStarting from the foundational definitions of importance sampling and properties of integrable singularities, perform the following analyses to assess the reliability of the estimator:\n- Derive the IS weight $$W$$ explicitly as a function of $$X$$ and analyze its behavior near the endpoints $$x=\\pm 1$$.\n- Using the definition of the second moment under the proposal distribution, determine whether $$\\int_{-1}^{1}\\frac{f(x)^{2}}{q(x)}\\,dx$$ is finite or infinite, and justify your conclusion by a principled argument that does not rely on heuristic shortcuts.\n- To quantify the tail heaviness of $$W$$ under $$X\\sim q$$, determine the exact leading-order asymptotic decay of the tail probability $$\\mathbb{P}(W>t)$$ as $$t\\to\\infty$$. In particular, derive the exact constant $$c$$ in the asymptotic $$\\mathbb{P}(W>t)\\sim c\\,t^{-2}$$ as $$t\\to\\infty$$.\n\nProvide a complete derivation from first principles. Your final reported answer must be the single constant $$c$$ (no intermediate quantities), written in exact form. No rounding is required and no units are involved.", "solution": "The problem asks for a three-part analysis of an Importance Sampling scheme for the integral $I=\\int_{-1}^{1}\\frac{1}{\\sqrt{1-x^{2}}}\\,dx$. The target integrand is $f(x)=\\frac{1}{\\sqrt{1-x^{2}}}$, and the proposal probability density function (PDF) is a uniform distribution on the interval $[-1,1]$, given by $q(x)=\\frac{1}{2}$ for $x\\in[-1,1]$ and $q(x)=0$ otherwise.\n\nFirst, we derive the IS weight $W(x)$ and analyze its behavior. The weight function is defined as the ratio of the target integrand to the proposal density.\n$$W(x) = \\frac{f(x)}{q(x)} = \\frac{\\frac{1}{\\sqrt{1-x^{2}}}}{\\frac{1}{2}} = \\frac{2}{\\sqrt{1-x^{2}}}$$\nThis expression is valid for $x \\in (-1, 1)$. We analyze the behavior of $W(x)$ as $x$ approaches the endpoints of the interval, $x=\\pm 1$.\nAs $x \\to 1^{-}$ or $x \\to -1^{+}$, the term $1-x^2$ approaches $0$ from the positive side. Consequently, $\\sqrt{1-x^2} \\to 0^{+}$, and the weight $W(x)$ diverges to infinity:\n$$\\lim_{x\\to \\pm 1} W(x) = \\lim_{x\\to \\pm 1} \\frac{2}{\\sqrt{1-x^{2}}} = \\infty$$\nThis indicates that samples drawn near the boundaries of the integration domain will have extremely large weights, which is a sign of a potentially high-variance or infinite-variance estimator.\n\nSecond, we determine if the second moment of the weight under the proposal distribution is finite. The variance of the IS estimator is finite if and only if the second moment of the weights, $\\mathbb{E}_q[W^2]$, is finite. This moment is given by the integral:\n$$\\mathbb{E}_q[W^2] = \\int_{-1}^{1} W(x)^2 q(x) \\, dx = \\int_{-1}^{1} \\left(\\frac{f(x)}{q(x)}\\right)^2 q(x) \\, dx = \\int_{-1}^{1} \\frac{f(x)^2}{q(x)} \\, dx$$\nSubstituting the expressions for $f(x)$ and $q(x)$:\n$$\\frac{f(x)^2}{q(x)} = \\frac{\\left(\\frac{1}{\\sqrt{1-x^{2}}}\\right)^2}{\\frac{1}{2}} = \\frac{\\frac{1}{1-x^2}}{\\frac{1}{2}} = \\frac{2}{1-x^2}$$\nThus, we must evaluate the integral:\n$$\\mathbb{E}_q[W^2] = \\int_{-1}^{1} \\frac{2}{1-x^2} \\, dx$$\nThis is an improper integral due to the non-integrable singularities at $x=-1$ and $x=1$. To demonstrate its divergence, we can use the p-integral test. Near $x=1$, we can write $x=1-\\epsilon$ for a small $\\epsilon > 0$. The denominator becomes $1-x^2 = (1-x)(1+x) = \\epsilon(2-\\epsilon) \\approx 2\\epsilon$. The integrand behaves like $\\frac{2}{2\\epsilon} = \\frac{1}{\\epsilon}$. The integral near $x=1$ behaves like $\\int \\frac{1}{\\epsilon} \\, d\\epsilon$, which is a logarithmically divergent form.\nMore formally, we can compute the indefinite integral:\n$$\\int \\frac{2}{1-x^2} \\, dx = 2 \\cdot \\frac{1}{2} \\ln\\left|\\frac{1+x}{1-x}\\right| + C = \\ln\\left|\\frac{1+x}{1-x}\\right| + C$$\nEvaluating the definite integral from $-1$ to $1$:\n$$\\int_{-1}^{1} \\frac{2}{1-x^2} \\, dx = \\lim_{a \\to 1^{-}} \\lim_{b \\to -1^{+}} \\left[ \\ln\\left(\\frac{1+x}{1-x}\\right) \\right]_b^a$$\nAs $a \\to 1^{-}$, $\\ln\\left(\\frac{1+a}{1-a}\\right) \\to \\ln\\left(\\frac{2}{0^{+}}\\right) \\to \\infty$.\nAs $b \\to -1^{+}$, $\\ln\\left(\\frac{1+b}{1-b}\\right) \\to \\ln\\left(\\frac{0^{+}}{2}\\right) \\to -\\infty$.\nThe integral diverges. Therefore, the second moment $\\mathbb{E}_q[W^2]$ is infinite, which implies that the variance of the IS estimator is infinite.\n\nThird, we find the constant $c$ in the asymptotic decay of the tail probability $\\mathbb{P}(W>t) \\sim c\\,t^{-2}$. The probability is with respect to a random variable $X$ drawn from the proposal distribution $q$, i.e., $X \\sim \\text{Uniform}[-1, 1]$.\nWe need to find the probability of the event $W(X) > t$:\n$$\\mathbb{P}(W > t) = \\mathbb{P}\\left(\\frac{2}{\\sqrt{1-X^2}} > t\\right)$$\nFor $t>0$, we can rearrange the inequality:\n$$\\frac{2}{t} > \\sqrt{1-X^2}$$\nSince both sides are positive, we can square them:\n$$\\frac{4}{t^2} > 1-X^2$$\n$$X^2 > 1 - \\frac{4}{t^2}$$\nFor large $t$, specifically $t>2$, the right-hand side is positive. This inequality is equivalent to $|X| > \\sqrt{1 - \\frac{4}{t^2}}$.\nLet $a_t = \\sqrt{1 - \\frac{4}{t^2}}$. The event is $|X| > a_t$. Since $X \\in [-1, 1]$, this corresponds to $X \\in (-1, -a_t) \\cup (a_t, 1)$.\nThe probability is calculated by integrating the PDF $q(x)=\\frac{1}{2}$ over this set:\n$$\\mathbb{P}(W > t) = \\int_{-1}^{-a_t} \\frac{1}{2} \\, dx + \\int_{a_t}^{1} \\frac{1}{2} \\, dx$$\n$$\\mathbb{P}(W > t) = \\frac{1}{2} \\left( -a_t - (-1) \\right) + \\frac{1}{2} \\left( 1 - a_t \\right) = \\frac{1}{2}(1-a_t) + \\frac{1}{2}(1-a_t) = 1 - a_t$$\nSubstituting the expression for $a_t$:\n$$\\mathbb{P}(W > t) = 1 - \\sqrt{1 - \\frac{4}{t^2}}$$\nTo find the leading-order asymptotic behavior as $t \\to \\infty$, we use the Taylor expansion of $\\sqrt{1-u}$ for small $u$. Let $u = \\frac{4}{t^2}$. As $t \\to \\infty$, $u \\to 0$. The expansion is:\n$$\\sqrt{1-u} = 1 - \\frac{1}{2}u + O(u^2)$$\nSubstituting this into our expression for the probability:\n$$\\mathbb{P}(W > t) = 1 - \\left(1 - \\frac{1}{2}\\left(\\frac{4}{t^2}\\right) + O\\left(\\left(\\frac{4}{t^2}\\right)^2\\right)\\right)$$\n$$\\mathbb{P}(W > t) = 1 - 1 + \\frac{2}{t^2} - O\\left(\\frac{1}{t^4}\\right) = \\frac{2}{t^2} + O\\left(\\frac{1}{t^4}\\right)$$\nThe asymptotic relationship is defined as $\\lim_{t\\to\\infty} \\frac{\\mathbb{P}(W > t)}{c\\,t^{-2}} = 1$. Using our result:\n$$\\lim_{t\\to\\infty} \\frac{\\frac{2}{t^2} + O(\\frac{1}{t^4})}{c\\,t^{-2}} = \\lim_{t\\to\\infty} \\frac{2 + O(\\frac{1}{t^2})}{c} = \\frac{2}{c}$$\nFor this limit to equal $1$, we must have $c=2$.", "answer": "$$\\boxed{2}$$", "id": "3241984"}, {"introduction": "After seeing how a poor proposal can lead to an infinite-variance estimator, it is natural to ask: what is the condition for success? This practice moves from diagnosis to prescription by formalizing the \"heavy tails\" principle. By comparing a target and proposal from the Pareto family of distributions, you will derive a precise mathematical condition on their shape parameters that guarantees a finite variance for the importance weights. This solidifies the qualitative rule that the proposal distribution must decay slower than, or at least as slow as, the target integrand.", "problem": "In the context of Monte Carlo methods, Importance Sampling is a technique used to estimate properties of a target probability distribution $p(x)$ while only having access to samples generated from a different proposal distribution $q(x)$. The method relies on weighting the samples from $q(x)$ by the importance weights $w(x) = p(x)/q(x)$.\n\nA crucial diagnostic for the reliability of an importance sampling estimator is the variance of the importance weights, $\\text{Var}_q[w(x)]$. An infinite variance suggests that the estimator is unreliable and may be dominated by a few samples with extremely large weights. The condition for finite variance is that the second moment of the weights, $E_q[w(x)^2]$, must be finite.\n\nConsider a scenario where both the target and proposal distributions are Pareto distributions, defined for $x \\ge x_m$. The probability density function (PDF) for a Pareto distribution is given by:\n$$f(x; \\alpha, x_m) = \\frac{\\alpha x_m^\\alpha}{x^{\\alpha+1}}$$\nwhere $\\alpha > 0$ is the shape parameter and $x_m > 0$ is the scale parameter (the minimum possible value of $x$).\n\nLet the target distribution be $p(x) = f(x; \\alpha_p, x_m)$ and the proposal distribution be $q(x) = f(x; \\alpha_q, x_m)$. Note that they share the same scale parameter $x_m$. The shape parameter of the proposal, $\\alpha_q$, is related to the shape parameter of the target, $\\alpha_p$, through the relation $\\alpha_q = C \\alpha_p$, where $C$ is a positive constant.\n\nDerive the supremum value of $C$, denoted as $C_{max}$, for which the variance of the importance weights, $\\text{Var}_q[w(x)]$, is guaranteed to be finite for any valid choice of $\\alpha_p > 0$ and $x_m > 0$.", "solution": "We have \n$$p(x)=\\frac{\\alpha_p\\,x_m^{\\alpha_p}}{x^{\\alpha_p+1}},\\quad q(x)=\\frac{\\alpha_q\\,x_m^{\\alpha_q}}{x^{\\alpha_q+1}},\\quad\\alpha_q=C\\,\\alpha_p.$$\nThe importance weight is\n$$w(x)=\\frac{p(x)}{q(x)}\n=\\frac{\\alpha_p}{\\alpha_q}\\,x_m^{\\alpha_p-\\alpha_q}\\,x^{\\alpha_q-\\alpha_p}.$$\nIts second moment under $q$ is\n$$E_q[w^2]\n=\\int_{x_m}^\\infty w(x)^2\\,q(x)\\,dx\n=\\Bigl(\\frac{\\alpha_p}{\\alpha_q}\\Bigr)^2\\alpha_q\\,x_m^{2(\\alpha_p-\\alpha_q)+\\alpha_q}\n\\int_{x_m}^\\infty x^{2(\\alpha_q-\\alpha_p)-(\\alpha_q+1)}\\,dx.$$\nThe exponent in the integrand is\n$$2(\\alpha_q-\\alpha_p)-(\\alpha_q+1)=\\alpha_q-2\\alpha_p-1.$$\nThe integral converges iff\n$$\\alpha_q-2\\alpha_p-1<-1\\quad\\Longrightarrow\\quad\\alpha_q<2\\alpha_p.$$\nSubstituting $\\alpha_q=C\\,\\alpha_p$ gives\n$$C\\,\\alpha_p<2\\,\\alpha_p\\quad\\Longrightarrow\\quad C<2.$$\nHence the supremum is $C_{\\max}=2.$", "answer": "$$\\boxed{2}$$", "id": "767848"}]}