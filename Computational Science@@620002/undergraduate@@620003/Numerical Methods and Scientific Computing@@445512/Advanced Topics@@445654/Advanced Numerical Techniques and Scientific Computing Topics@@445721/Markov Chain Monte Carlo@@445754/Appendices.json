{"hands_on_practices": [{"introduction": "The Metropolis-Hastings algorithm is driven by a simple yet ingenious probabilistic rule for accepting or rejecting proposed moves. This rule ensures that the Markov chain explores the state space in a way that converges to the target distribution. This first exercise focuses squarely on this core mechanism, asking you to calculate the acceptance probability for a single proposed step, providing a concrete understanding of how the algorithm navigates the probability landscape. [@problem_id:1371728]", "problem": "A data scientist is implementing a Markov Chain Monte Carlo (MCMC) simulation to draw samples from a posterior probability distribution for a parameter $x$. The target distribution, $\\pi(x)$, is proportional to the exponential of the negative absolute value of the parameter, such that $\\pi(x) \\propto \\exp(-|x|)$.\n\nThe scientist uses the Metropolis algorithm with a symmetric proposal distribution $q(x'|x)$, where the probability of proposing a new state $x'$ given the current state $x$ is equal to the probability of proposing $x$ given $x'$ (i.e., $q(x'|x) = q(x|x')$).\n\nSuppose that at a certain step in the simulation, the current state of the chain is $x = 1.5$. The algorithm then proposes a move to a new candidate state $x' = 2.0$.\n\nCalculate the acceptance probability for this specific move. Your answer should be a dimensionless real number. Round your final answer to four significant figures.", "solution": "The Metropolis acceptance probability for a move from $x$ to $x'$ with a symmetric proposal $q(x'|x)=q(x|x')$ is\n$$\n\\alpha(x \\to x')=\\min\\left(1,\\frac{\\pi(x')q(x|x')}{\\pi(x)q(x'|x)}\\right)=\\min\\left(1,\\frac{\\pi(x')}{\\pi(x)}\\right).\n$$\nGiven the target distribution $\\pi(x)\\propto \\exp(-|x|)$, the ratio simplifies to\n$$\n\\frac{\\pi(x')}{\\pi(x)}=\\frac{\\exp(-|x'|)}{\\exp(-|x|)}=\\exp\\!\\left(-\\left(|x'|-|x|\\right)\\right).\n$$\nWith $x=1.5$ and $x'=2.0$, we have $|x|=1.5$ and $|x'|=2.0$, so\n$$\n\\frac{\\pi(x')}{\\pi(x)}=\\exp\\!\\left(-\\left(2.0-1.5\\right)\\right)=\\exp(-0.5).\n$$\nTherefore,\n$$\n\\alpha(x \\to x')=\\min\\left(1,\\exp(-0.5)\\right)=\\exp(-0.5).\n$$\nNumerically, $\\exp(-0.5)\\approx 0.6065$ when rounded to four significant figures.", "answer": "$$\\boxed{0.6065}$$", "id": "1371728"}, {"introduction": "Moving from a single step to a full implementation, this practice challenges you to build a Metropolis-Hastings sampler from the ground up for a foundational data science task: Bayesian linear regression. You will first derive the posterior probability distribution for the model's parameters and then write code to generate samples from it. This exercise bridges theory and practice, demonstrating how MCMC can be used to quantify uncertainty and perform robust parameter estimation in a familiar statistical context. [@problem_id:3250349]", "problem": "You are given the linear observational model specified by the independent and identically distributed errors assumption: for each index $i$ in a dataset, the scalar response $y_i$ is generated by\n$$\ny_i \\;=\\; m\\,x_i \\;+\\; b \\;+\\; \\epsilon_i,\n$$\nwhere the error term $\\epsilon_i$ is distributed as a zero-mean Gaussian random variable with variance $\\sigma^2$, that is $\\epsilon_i \\sim \\mathcal{N}(0,\\sigma^2)$ and the errors are independent across $i$. The parameters $m$ and $b$ are unknown. Assume independent Gaussian priors $m \\sim \\mathcal{N}(0,\\tau_m^2)$ and $b \\sim \\mathcal{N}(0,\\tau_b^2)$ with known prior standard deviations $\\tau_m$ and $\\tau_b$. The variance $\\sigma^2$ is known.\n\nStarting from Bayes' theorem and the definition of the Gaussian likelihood and Gaussian prior densities, derive an implementable expression for the unnormalized logarithm of the posterior density of $(m,b)$ given observed data $(x_i,y_i)$ and known hyperparameters $(\\sigma,\\tau_m,\\tau_b)$. Then, implement a Metropolis–Hastings Markov chain Monte Carlo (MCMC) algorithm with a symmetric Gaussian random-walk proposal for the two parameters:\n- Propose $m^\\star = m + \\eta_m$ with $\\eta_m \\sim \\mathcal{N}(0,s_m^2)$.\n- Propose $b^\\star = b + \\eta_b$ with $\\eta_b \\sim \\mathcal{N}(0,s_b^2)$.\n- Accept or reject $(m^\\star,b^\\star)$ according to the Metropolis–Hastings rule based on the ratio of unnormalized posterior densities.\n\nUse these foundations to approximate the posterior distribution of $(m,b)$ for the following test suite. In each case, the observed responses $y_i$ must be generated synthetically inside your program using the provided data-generation seeds and the stated ground-truth parameters and noise level. Then, using a separate seed for the Markov chain, run the MCMC sampler and report the posterior means of $m$ and $b$ after discarding the burn-in samples. No thinning is required.\n\nAssume the starting state $(m_0,b_0)$ is $(0,0)$ for all cases. Use the same prior standard deviations $\\tau_m=\\tau_b$ as specified below for all cases.\n\nTest suite:\n- Case $1$ (happy path):\n  - Design points: $x$ are $n=20$ equally spaced values from $-2.0$ to $2.0$ inclusive.\n  - Ground truth: $m_{\\text{true}}=2.0$, $b_{\\text{true}}=-1.0$.\n  - Noise standard deviation: $\\sigma=0.5$.\n  - Prior standard deviations: $\\tau_m=\\tau_b=10.0$.\n  - Proposal standard deviations: $s_m=0.02$, $s_b=0.05$.\n  - Data-generation seed: $11$.\n  - MCMC seed: $101$.\n  - Total iterations: $20000$.\n  - Burn-in: $5000$.\n- Case $2$ (boundary-size dataset with two points and low noise):\n  - Design points: $x=[-1.0,\\,1.0]$ with $n=2$.\n  - Ground truth: $m_{\\text{true}}=-0.5$, $b_{\\text{true}}=2.0$.\n  - Noise standard deviation: $\\sigma=0.1$.\n  - Prior standard deviations: $\\tau_m=\\tau_b=10.0$.\n  - Proposal standard deviations: $s_m=0.005$, $s_b=0.01$.\n  - Data-generation seed: $22$.\n  - MCMC seed: $202$.\n  - Total iterations: $30000$.\n  - Burn-in: $10000$.\n- Case $3$ (noisy observations):\n  - Design points: $x$ are $n=30$ equally spaced values from $0.0$ to $5.0$ inclusive.\n  - Ground truth: $m_{\\text{true}}=0.3$, $b_{\\text{true}}=4.0$.\n  - Noise standard deviation: $\\sigma=5.0$.\n  - Prior standard deviations: $\\tau_m=\\tau_b=10.0$.\n  - Proposal standard deviations: $s_m=0.05$, $s_b=0.20$.\n  - Data-generation seed: $33$.\n  - MCMC seed: $303$.\n  - Total iterations: $25000$.\n  - Burn-in: $8000$.\n\nImplementation and output requirements:\n- Implement the Metropolis–Hastings sampler exactly as described, using the unnormalized logarithm of the posterior density you derived.\n- For each case, compute the posterior mean of $m$ and the posterior mean of $b$ using only the samples after burn-in.\n- Your program must generate the synthetic $y$ values using the stated ground-truth parameters and noise levels with the given data-generation seeds, and must use the provided MCMC seeds for sampling.\n- Round each posterior mean to exactly $4$ decimal places.\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets in the order $[m^{(1)}_{\\text{mean}},b^{(1)}_{\\text{mean}},m^{(2)}_{\\text{mean}},b^{(2)}_{\\text{mean}},m^{(3)}_{\\text{mean}},b^{(3)}_{\\text{mean}}]$, where the superscript indicates the case number. For example, the output format must look like a single line with square brackets and comma-separated decimal numbers.\n\nNotes:\n- All angles, if any were present, would be in radians; no angles are used here.\n- There are no physical units required for the outputs.\n- Ensure that all computations are deterministic by using the specified seeds for pseudorandom number generation.", "solution": "The problem requires the implementation of a Metropolis-Hastings Markov chain Monte Carlo (MCMC) algorithm to sample from the posterior distribution of the parameters $(m,b)$ of a simple linear regression model. The solution requires two main components: the derivation of the target probability density function and the implementation of the MCMC sampler.\n\n### Derivation of the Unnormalized Log-Posterior Density\n\nThe problem is set within a Bayesian framework. According to Bayes' theorem, the posterior probability of the parameters $(m,b)$ given the observed data $D = \\{(x_i, y_i)\\}_{i=1}^n$ and known hyperparameters $H = (\\sigma, \\tau_m, \\tau_b)$ is given by:\n$$\np(m, b \\mid D, H) = \\frac{p(D \\mid m, b, \\sigma) p(m \\mid \\tau_m) p(b \\mid \\tau_b)}{p(D \\mid H)}\n$$\nwhere $p(D \\mid m, b, \\sigma)$ is the likelihood of the data, $p(m \\mid \\tau_m)$ and $p(b \\mid \\tau_b)$ are the prior probabilities of the parameters, and $p(D \\mid H)$ is the marginal likelihood or evidence, which acts as a normalization constant. For MCMC methods like Metropolis-Hastings, the normalization constant is not required. We can work with the unnormalized posterior, which is proportional to the numerator:\n$$\np(m, b \\mid D, H) \\propto p(D \\mid m, b, \\sigma) p(m \\mid \\tau_m) p(b \\mid \\tau_b)\n$$\n\n**1. The Likelihood Function**\nThe linear observational model is $y_i = m x_i + b + \\epsilon_i$, with the error term $\\epsilon_i$ drawn from a zero-mean normal distribution with variance $\\sigma^2$, i.e., $\\epsilon_i \\sim \\mathcal{N}(0, \\sigma^2)$. This implies that each response variable $y_i$ is also normally distributed:\n$$\ny_i \\mid m, b, x_i, \\sigma \\sim \\mathcal{N}(m x_i + b, \\sigma^2)\n$$\nThe probability density function (PDF) for a single observation $(x_i, y_i)$ is:\n$$\np(y_i \\mid m, b, x_i, \\sigma) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}} \\exp\\left(-\\frac{(y_i - (m x_i + b))^2}{2\\sigma^2}\\right)\n$$\nAssuming the errors $\\epsilon_i$ are independent and identically distributed (i.i.d.), the likelihood of the entire dataset $D$ is the product of the individual probabilities:\n$$\np(D \\mid m, b, \\sigma) = \\prod_{i=1}^n p(y_i \\mid m, b, x_i, \\sigma)\n$$\n\n**2. The Prior Distributions**\nThe problem specifies independent Gaussian priors for the parameters $m$ and $b$:\n$$\nm \\sim \\mathcal{N}(0, \\tau_m^2) \\implies p(m \\mid \\tau_m) = \\frac{1}{\\sqrt{2\\pi\\tau_m^2}} \\exp\\left(-\\frac{m^2}{2\\tau_m^2}\\right)\n$$\n$$\nb \\sim \\mathcal{N}(0, \\tau_b^2) \\implies p(b \\mid \\tau_b) = \\frac{1}{\\sqrt{2\\pi\\tau_b^2}} \\exp\\left(-\\frac{b^2}{2\\tau_b^2}\\right)\n$$\nThe joint prior is the product of the individual priors due to their independence: $p(m, b \\mid \\tau_m, \\tau_b) = p(m \\mid \\tau_m) p(b \\mid \\tau_b)$.\n\n**3. The Unnormalized Log-Posterior**\nFor numerical stability and computational convenience, it is standard practice to work with the logarithm of the posterior density. The logarithm of the unnormalized posterior, which we denote as $\\mathcal{L}_{un}(m,b)$, is:\n$$\n\\mathcal{L}_{un}(m,b) = \\log\\left[ p(D \\mid m, b, \\sigma) p(m \\mid \\tau_m) p(b \\mid \\tau_b) \\right] = \\log p(D \\mid m, b, \\sigma) + \\log p(m \\mid \\tau_m) + \\log p(b \\mid \\tau_b)\n$$\nLet's expand each term, dropping any additive constants that do not depend on $m$ or $b$:\nThe log-likelihood term is:\n$$\n\\log p(D \\mid m, b, \\sigma) = \\sum_{i=1}^n \\log p(y_i \\mid m, b, x_i, \\sigma) = \\sum_{i=1}^n \\left( \\log\\left(\\frac{1}{\\sqrt{2\\pi\\sigma^2}}\\right) - \\frac{(y_i - (m x_i + b))^2}{2\\sigma^2} \\right)\n$$\nIgnoring the constant term $\\sum_{i=1}^n \\log(1/\\sqrt{2\\pi\\sigma^2})$, we get:\n$$\n\\log p(D \\mid m, b, \\sigma) \\propto -\\frac{1}{2\\sigma^2} \\sum_{i=1}^n (y_i - m x_i - b)^2\n$$\nThe log-prior terms are:\n$$\n\\log p(m \\mid \\tau_m) \\propto -\\frac{m^2}{2\\tau_m^2} \\quad \\text{and} \\quad \\log p(b \\mid \\tau_b) \\propto -\\frac{b^2}{2\\tau_b^2}\n$$\nCombining these terms gives the final expression for the unnormalized log-posterior density:\n$$\n\\mathcal{L}_{un}(m,b) = -\\frac{1}{2\\sigma^2} \\sum_{i=1}^n (y_i - m x_i - b)^2 - \\frac{m^2}{2\\tau_m^2} - \\frac{b^2}{2\\tau_b^2}\n$$\nThis expression is the function we need to evaluate within the MCMC algorithm. The first term is proportional to the negative sum of squared residuals, and the second and third terms are regularization terms (L2 regularization) originating from the Gaussian priors.\n\n### Metropolis-Hastings Algorithm\n\nThe Metropolis-Hastings algorithm is used to generate a sequence of samples that constitutes a Markov chain, whose stationary distribution is the desired posterior distribution $p(m, b \\mid D, H)$. The algorithm proceeds as follows:\n\n1.  **Initialization**: Start the chain at an initial state $(m_0, b_0)$. The problem specifies $(m_0, b_0) = (0,0)$.\n\n2.  **Iteration**: For each step $t=1, 2, \\dots, N_{\\text{total}}$:\n    a.  **Proposal**: Given the current state $(m_t, b_t)$, propose a new state $(m^\\star, b^\\star)$ from a proposal distribution $Q((m^\\star, b^\\star) \\mid (m_t, b_t))$. The problem specifies a symmetric Gaussian random-walk proposal:\n        $$\n        m^\\star = m_t + \\eta_m, \\quad \\text{with} \\quad \\eta_m \\sim \\mathcal{N}(0, s_m^2)\n        $$\n        $$\n        b^\\star = b_t + \\eta_b, \\quad \\text{with} \\quad \\eta_b \\sim \\mathcal{N}(0, s_b^2)\n        $$\n    b.  **Acceptance Probability**: Calculate the acceptance probability $\\alpha$, which is the probability of moving to the proposed state $(m^\\star, b^\\star)$:\n        $$\n        \\alpha = \\min\\left(1, \\frac{p(m^\\star, b^\\star \\mid D, H)}{p(m_t, b_t \\mid D, H)} \\cdot \\frac{Q((m_t, b_t) \\mid (m^\\star, b^\\star))}{Q((m^\\star, b^\\star) \\mid (m_t, b_t))}\\right)\n        $$\n        Since the proposal distribution is symmetric (i.e., the probability of proposing a move from state A to B is the same as from B to A), the ratio of proposal densities (the Hastings ratio) is $1$. The acceptance probability simplifies to the Metropolis rule:\n        $$\n        \\alpha = \\min\\left(1, \\frac{p(m^\\star, b^\\star \\mid D, H)}{p(m_t, b_t \\mid D, H)}\\right)\n        $$\n        To avoid numerical underflow, this is computed using log-probabilities:\n        $$\n        \\log(\\text{ratio}) = \\mathcal{L}_{un}(m^\\star, b^\\star) - \\mathcal{L}_{un}(m_t, b_t)\n        $$\n        $$\n        \\alpha = \\min(1, \\exp(\\log(\\text{ratio})))\n        $$\n    c.  **Accept or Reject**: Generate a random number $u$ from a uniform distribution $U(0,1)$. If $u < \\alpha$, the proposal is accepted, and the next state is $(m_{t+1}, b_{t+1}) = (m^\\star, b^\\star)$. Otherwise, the proposal is rejected, and the chain remains at its current state, $(m_{t+1}, b_{t+1}) = (m_t, b_t)$.\n\n3.  **Analysis**: After running the chain for $N_{\\text{total}}$ iterations, the initial portion of the chain (the burn-in period, $N_{\\text{burn-in}}$) is discarded to allow the chain to converge to its stationary distribution. The posterior means of $m$ and $b$ are then estimated by computing the arithmetic mean of the post-burn-in samples:\n    $$\n    \\hat{m}_{\\text{mean}} = \\frac{1}{N_{\\text{total}} - N_{\\text{burn-in}}} \\sum_{t=N_{\\text{burn-in}}+1}^{N_{\\text{total}}} m_t\n    $$\n    $$\n    \\hat{b}_{\\text{mean}} = \\frac{1}{N_{\\text{total}} - N_{\\text{burn-in}}} \\sum_{t=N_{\\text{burn-in}}+1}^{N_{\\text{total}}} b_t\n    $$\nThis procedure will be applied to each of the three test cases specified in the problem statement.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Implements a Metropolis-Hastings MCMC sampler for Bayesian linear regression\n    and applies it to three test cases.\n    \"\"\"\n\n    test_cases = [\n        # Case 1 (happy path)\n        {\n            \"n\": 20, \"x_range\": [-2.0, 2.0],\n            \"m_true\": 2.0, \"b_true\": -1.0, \"sigma\": 0.5,\n            \"tau_m\": 10.0, \"tau_b\": 10.0,\n            \"s_m\": 0.02, \"s_b\": 0.05,\n            \"data_seed\": 11, \"mcmc_seed\": 101,\n            \"total_iterations\": 20000, \"burn_in\": 5000\n        },\n        # Case 2 (boundary-size dataset with two points and low noise)\n        {\n            \"n\": 2, \"x_manual\": np.array([-1.0, 1.0]),\n            \"m_true\": -0.5, \"b_true\": 2.0, \"sigma\": 0.1,\n            \"tau_m\": 10.0, \"tau_b\": 10.0,\n            \"s_m\": 0.005, \"s_b\": 0.01,\n            \"data_seed\": 22, \"mcmc_seed\": 202,\n            \"total_iterations\": 30000, \"burn_in\": 10000\n        },\n        # Case 3 (noisy observations)\n        {\n            \"n\": 30, \"x_range\": [0.0, 5.0],\n            \"m_true\": 0.3, \"b_true\": 4.0, \"sigma\": 5.0,\n            \"tau_m\": 10.0, \"tau_b\": 10.0,\n            \"s_m\": 0.05, \"s_b\": 0.20,\n            \"data_seed\": 33, \"mcmc_seed\": 303,\n            \"total_iterations\": 25000, \"burn_in\": 8000\n        }\n    ]\n\n    results = []\n    \n    for case in test_cases:\n        # Generate synthetic data\n        rng_data = np.random.default_rng(case[\"data_seed\"])\n        \n        if \"x_manual\" in case:\n            x = case[\"x_manual\"]\n        else:\n            x = np.linspace(case[\"x_range\"][0], case[\"x_range\"][1], case[\"n\"])\n            \n        noise = rng_data.normal(0, case[\"sigma\"], size=case[\"n\"])\n        y = case[\"m_true\"] * x + case[\"b_true\"] + noise\n\n        # Define the unnormalized log posterior function\n        def log_unnormalized_posterior(m, b, x, y, sigma, tau_m, tau_b):\n            residuals = y - (m * x + b)\n            sum_sq_residuals = np.sum(residuals**2)\n            log_likelihood = -0.5 * sum_sq_residuals / (sigma**2)\n            log_prior = -0.5 * (m**2 / tau_m**2 + b**2 / tau_b**2)\n            return log_likelihood + log_prior\n\n        # Initialize MCMC\n        rng_mcmc = np.random.default_rng(case[\"mcmc_seed\"])\n        m_curr, b_curr = 0.0, 0.0\n        \n        m_samples = np.zeros(case[\"total_iterations\"])\n        b_samples = np.zeros(case[\"total_iterations\"])\n        \n        log_post_curr = log_unnormalized_posterior(\n            m_curr, b_curr, x, y, case[\"sigma\"], case[\"tau_m\"], case[\"tau_b\"])\n\n        # Run MCMC sampler\n        for i in range(case[\"total_iterations\"]):\n            # Propose new parameters\n            m_prop = m_curr + rng_mcmc.normal(0, case[\"s_m\"])\n            b_prop = b_curr + rng_mcmc.normal(0, case[\"s_b\"])\n            \n            # Calculate log posterior of proposed parameters\n            log_post_prop = log_unnormalized_posterior(\n                m_prop, b_prop, x, y, case[\"sigma\"], case[\"tau_m\"], case[\"tau_b\"])\n            \n            # Calculate acceptance ratio\n            log_ratio = log_post_prop - log_post_curr\n            alpha = np.min([1.0, np.exp(log_ratio)])\n            \n            # Accept or reject\n            if rng_mcmc.uniform(0, 1)  alpha:\n                m_curr = m_prop\n                b_curr = b_prop\n                log_post_curr = log_post_prop\n            \n            m_samples[i] = m_curr\n            b_samples[i] = b_curr\n            \n        # Post-processing: discard burn-in and compute posterior means\n        post_burn_in_m = m_samples[case[\"burn_in\"]:]\n        post_burn_in_b = b_samples[case[\"burn_in\"]:]\n        \n        m_mean = np.mean(post_burn_in_m)\n        b_mean = np.mean(post_burn_in_b)\n        \n        results.extend([m_mean, b_mean])\n\n    # Format and print the final output\n    formatted_results = \",\".join([f\"{r:.4f}\" for r in results])\n    print(f\"[{formatted_results}]\")\n\nsolve()\n```", "id": "3250349"}, {"introduction": "To demonstrate the flexibility of the MCMC framework, our final practice introduces a different yet related technique: Gibbs sampling. We will apply this method to a fascinating problem from computational imaging—denoising a corrupted binary image—by framing it within the context of a physical spin system. This exercise requires deriving the local conditional probabilities that form the basis of the Gibbs sampler, showcasing how complex, high-dimensional problems can be tackled by breaking them down into a series of simple, manageable steps. [@problem_id:3250350]", "problem": "Implement a complete program that performs Markov chain Monte Carlo (MCMC) denoising of corrupted binary images by Gibbs sampling under a pairwise Markov random field prior. Work from first principles to derive the conditional distribution needed for Gibbs updates, and then implement the sampler to approximate the posterior mean of each pixel.\n\nBegin from the following modeling assumptions, which are the only allowed starting points:\n- The latent clean image is a grid of binary spins $x_{i,j} \\in \\{-1,+1\\}$ arranged on a rectangular lattice with four-neighbor structure (up, down, left, right). The prior is an Ising-type Gibbs distribution\n$$\np(x) \\propto \\exp\\left(\\beta \\sum_{\\langle (i,j),(k,\\ell)\\rangle} x_{i,j}\\,x_{k,\\ell}\\right),\n$$\nwhere the sum is over all unordered adjacent pairs $\\langle (i,j),(k,\\ell)\\rangle$ within the grid (no wrap-around), and $\\beta \\ge 0$ is a fixed coupling parameter.\n- The observation model is independent across pixels conditioned on $x$, and each pixel is flipped with probability $\\varepsilon \\in (0,1)$: for each site $(i,j)$, the observed value $y_{i,j} \\in \\{-1,+1\\}$ satisfies\n$$\n\\mathbb{P}(y_{i,j} = x_{i,j} \\mid x_{i,j}) = 1-\\varepsilon,\\quad \\mathbb{P}(y_{i,j} = -x_{i,j} \\mid x_{i,j}) = \\varepsilon.\n$$\n\nYour tasks:\n1. Using Bayes’ rule and only the definitions above, derive the full conditional distribution for a single pixel $x_{i,j}$ given its four-neighborhood in $x$ and the observation $y$. Express the conditional probability that $x_{i,j}$ equals $+1$ in closed form in terms of $\\beta$, $\\varepsilon$, the sum of its present neighbors in $x$, and the local observation $y_{i,j}$. Clearly state any algebraic transformations you use and any sufficient statistics that arise.\n2. Design a Gibbs sampler that iteratively updates each $x_{i,j}$ by drawing from the conditional distribution you derived in task $1$. Use a systematic raster scan over sites in a sweep. Use a pseudorandom number generator with a fixed seed $s$ to ensure reproducibility of the sweep updates. After a burn-in of $B$ full sweeps, collect $T$ additional full sweeps, accumulating the running sum of the spin at each site to approximate the posterior mean. Produce a denoised estimate $\\hat{x}$ by taking the sign of the accumulated sum at each site; that is, $\\hat{x}_{i,j} = +1$ if the accumulated sum is positive and $\\hat{x}_{i,j} = -1$ otherwise. Ties may be broken arbitrarily; use a consistent rule.\n3. For each test case below, compute the fraction of correctly denoised pixels, defined as\n$$\n\\text{accuracy} = \\frac{1}{N\\cdot M} \\sum_{i=1}^{N} \\sum_{j=1}^{M} \\mathbf{1}\\{\\hat{x}_{i,j} = x^{\\star}_{i,j}\\},\n$$\nwhere $x^{\\star}$ is the provided clean image and $(N,M)$ is the grid size. Report the accuracy as a real number in $[0,1]$, rounded to three decimals.\n\nImplementation details and constraints:\n- The grid neighborhood is four-connected without wrap-around; only valid in-bounds neighbors contribute.\n- The Gibbs sampler must use a single fixed pseudorandom seed $s$ for all updates within a test case.\n- Angles do not appear; there are no physical units. Output accuracies as decimal numbers (no percentage sign).\n- The program must be self-contained and require no input.\n\nTest suite:\nProvide results for the following four test cases. Each case specifies the clean image $x^{\\star}$, the observed image $y$, the coupling $\\beta$, the flip-probability parameter $\\varepsilon$, the burn-in $B$, the number of sampling sweeps $T$, and the sampler seed $s$. All grids and values are in $\\{-1,+1\\}$.\n\n- Test case $1$ (happy path, moderate noise and smoothing):\n  - Grid size: $8 \\times 8$.\n  - Clean image $x^{\\star}$: $-1$ everywhere except the central $4 \\times 4$ block indexed by rows $2$ to $5$ and columns $2$ to $5$ (zero-based indexing) set to $+1$.\n  - Observed image $y$: equal to $x^{\\star}$ except flipped at the following coordinates (zero-based): $(0,0)$, $(1,7)$, $(2,3)$, $(3,2)$, $(4,4)$, $(5,5)$, $(6,1)$, $(7,6)$.\n  - Parameters: $\\beta = 0.8$, $\\varepsilon = 0.1$, $B = 300$, $T = 601$, seed $s = 12345$.\n\n- Test case $2$ (boundary case, single pixel):\n  - Grid size: $1 \\times 1$.\n  - Clean image $x^{\\star} = [+1]$.\n  - Observed image $y = [-1]$.\n  - Parameters: $\\beta = 0.6$, $\\varepsilon = 0.3$, $B = 50$, $T = 501$, seed $s = 7$.\n\n- Test case $3$ (larger grid, low smoothing, higher noise):\n  - Grid size: $10 \\times 10$.\n  - Clean image $x^{\\star}$: $+1$ at all sites.\n  - Observed image $y$: equal to $x^{\\star}$ except flipped at all positions $(i,j)$ such that $(i + j) \\bmod 5 = 0$ (zero-based $i,j$).\n  - Parameters: $\\beta = 0.4$, $\\varepsilon = 0.3$, $B = 300$, $T = 601$, seed $s = 2024$.\n\n- Test case $4$ (edge case, no prior coupling):\n  - Grid size: $6 \\times 6$.\n  - Clean image $x^{\\star}$: left half columns $0,1,2$ set to $-1$, right half columns $3,4,5$ set to $+1$.\n  - Observed image $y$: equal to $x^{\\star}$ except flipped at all positions $(i,j)$ such that $(i \\cdot 6 + j) \\bmod 5 = 1$ (zero-based $i,j$).\n  - Parameters: $\\beta = 0.0$, $\\varepsilon = 0.2$, $B = 200$, $T = 401$, seed $s = 999$.\n\nFinal output format:\nYour program should produce a single line of output containing the four accuracies, in the order of the test cases above, as a comma-separated list enclosed in square brackets, for example, $[a_1,a_2,a_3,a_4]$, where each $a_k$ is rounded to three decimals as specified. No other output should be printed.", "solution": "The problem statement has been validated and is deemed sound, well-posed, and complete. All necessary components, including the probabilistic model, parameters, and evaluation criteria, are specified unambiguously. The problem is grounded in established principles of statistical physics and Bayesian inference as applied to computational image analysis.\n\nThe task is to denoise a binary image using a Markov chain Monte Carlo (MCMC) method, specifically Gibbs sampling. This requires deriving the conditional distribution for a single-pixel update, implementing the sampler, and evaluating its performance on several test cases.\n\n**1. Derivation of the Gibbs Sampler Conditional Distribution**\n\nLet the latent clean image be represented by a grid of spins $x = \\{x_{i,j}\\}$, where each $x_{i,j} \\in \\{-1, +1\\}$. Let the observed noisy image be $y = \\{y_{i,j}\\}$, where $y_{i,j} \\in \\{-1, +1\\}$.\n\nThe model is defined by a prior distribution $p(x)$ and a likelihood function $p(y \\mid x)$. The goal of Gibbs sampling is to draw samples from the posterior distribution $p(x \\mid y)$. By Bayes' rule, the posterior is given by:\n$$\np(x \\mid y) \\propto p(y \\mid x) p(x)\n$$\nwhere the proportionality constant is the evidence $p(y)$, which does not depend on $x$ and can be ignored for MCMC sampling.\n\nThe prior on the clean image $x$ is an Ising model on a grid, given by the Gibbs distribution:\n$$\np(x) \\propto \\exp\\left(\\beta \\sum_{\\langle (i,j),(k,\\ell)\\rangle} x_{i,j}\\,x_{k,\\ell}\\right)\n$$\nHere, $\\beta \\ge 0$ is the coupling parameter that encourages neighboring pixels to have the same spin, and the sum is over all pairs of adjacent pixels (four-neighbor structure without wrap-around).\n\nThe observation model (likelihood) states that each observed pixel $y_{i,j}$ is generated from the corresponding true pixel $x_{i,j}$ independently, with a probability $\\varepsilon$ of being flipped:\n$$\n\\mathbb{P}(y_{i,j} \\mid x_{i,j}) =\n\\begin{cases}\n1-\\varepsilon  \\text{if } y_{i,j} = x_{i,j} \\\\\n\\varepsilon  \\text{if } y_{i,j} = -x_{i,j}\n\\end{cases}\n$$\nThis can be written in a more compact exponential form. Note that $x_{i,j}y_{i,j}=+1$ when they are equal and $-1$ when they differ. We can express the probability as:\n$$\n\\mathbb{P}(y_{i,j} \\mid x_{i,j}) = (1-\\varepsilon)^{\\frac{1+x_{i,j}y_{i,j}}{2}} \\varepsilon^{\\frac{1-x_{i,j}y_{i,j}}{2}}\n$$\nTaking the logarithm:\n$$\n\\log \\mathbb{P}(y_{i,j} \\mid x_{i,j}) = \\frac{1+x_{i,j}y_{i,j}}{2}\\log(1-\\varepsilon) + \\frac{1-x_{i,j}y_{i,j}}{2}\\log(\\varepsilon) = \\frac{1}{2}x_{i,j}y_{i,j}\\log\\left(\\frac{1-\\varepsilon}{\\varepsilon}\\right) + C\n$$\nwhere $C$ is a constant that does not depend on $x_{i,j}$. Thus, we can write:\n$$\n\\mathbb{P}(y_{i,j} \\mid x_{i,j}) \\propto \\exp(\\eta \\, x_{i,j} y_{i,j})\n$$\nwhere we define the parameter $\\eta = \\frac{1}{2}\\log\\left(\\frac{1-\\varepsilon}{\\varepsilon}\\right)$.\nSince observations are independent given $x$, the full likelihood is:\n$$\np(y \\mid x) = \\prod_{(i,j)} \\mathbb{P}(y_{i,j} \\mid x_{i,j}) \\propto \\exp\\left(\\eta \\sum_{(i,j)} x_{i,j}y_{i,j}\\right)\n$$\n\nCombining the prior and likelihood, the joint distribution $p(x, y)$ is proportional to the posterior $p(x \\mid y)$:\n$$\np(x \\mid y) \\propto \\exp\\left(\\beta \\sum_{\\langle (i,j),(k,\\ell)\\rangle} x_{i,j}\\,x_{k,\\ell} + \\eta \\sum_{(i,j)} x_{i,j}y_{i,j}\\right)\n$$\n\nGibbs sampling requires the full conditional distribution for a single spin $x_{i,j}$ given all other spins $x_{\\setminus (i,j)}$ and the observations $y$. Due to the local nature of the Markov random field, this conditional distribution only depends on the Markov blanket of $x_{i,j}$, which consists of its immediate neighbors in $x$ (denoted $\\mathcal{N}_{i,j}$) and the corresponding observation $y_{i,j}$.\n$$\np(x_{i,j} \\mid x_{\\setminus (i,j)}, y) = p(x_{i,j} \\mid x_{\\mathcal{N}_{i,j}}, y_{i,j})\n$$\nTo derive this, we isolate all terms in the log-posterior that involve $x_{i,j}$:\n$$\n\\log p(x \\mid y) \\ni \\beta \\sum_{(k,\\ell) \\in \\mathcal{N}_{i,j}} x_{i,j}\\,x_{k,\\ell} + \\eta \\, x_{i,j}y_{i,j} + \\text{const}\n$$\nThis can be rewritten as:\n$$\nx_{i,j} \\left( \\beta \\sum_{(k,\\ell) \\in \\mathcal{N}_{i,j}} x_{k,\\ell} + \\eta \\, y_{i,j} \\right)\n$$\nLet $S_{i,j} = \\sum_{(k,\\ell) \\in \\mathcal{N}_{i,j}} x_{k,\\ell}$ be the sum of the spins of the neighbors of site $(i,j)$. This is a sufficient statistic for the prior's influence. The conditional distribution is then:\n$$\np(x_{i,j} \\mid x_{\\setminus (i,j)}, y) \\propto \\exp\\left( x_{i,j} \\left( \\beta S_{i,j} + \\eta y_{i,j} \\right) \\right)\n$$\nLet $A_{i,j} = \\beta S_{i,j} + \\eta y_{i,j}$. Since $x_{i,j}$ can only take values $+1$ or $-1$:\n$$\n\\mathbb{P}(x_{i,j}=+1 \\mid \\dots) = \\frac{\\exp(+1 \\cdot A_{i,j})}{\\exp(+1 \\cdot A_{i,j}) + \\exp(-1 \\cdot A_{i,j})} = \\frac{\\exp(A_{i,j})}{\\exp(A_{i,j}) + \\exp(-A_{i,j})}\n$$\nThis can be expressed using the logistic sigmoid function for numerical stability:\n$$\n\\mathbb{P}(x_{i,j}=+1 \\mid \\dots) = \\frac{1}{1 + \\exp(-2A_{i,j})}\n$$\nSubstituting the expressions for $A_{i,j}$ and $\\eta$, the final closed-form probability is:\n$$\n\\mathbb{P}(x_{i,j}=+1 \\mid x_{\\setminus (i,j)}, y) = \\frac{1}{1 + \\exp\\left(-2\\left[\\beta S_{i,j} + \\frac{y_{i,j}}{2}\\log\\left(\\frac{1-\\varepsilon}{\\varepsilon}\\right)\\right]\\right)}\n$$\nwhere $S_{i,j}$ is the sum of the spins of the four direct neighbors of pixel $(i,j)$.\n\n**2. Gibbs Sampler Algorithm Design**\n\nThe Gibbs sampler proceeds as follows to generate samples from the posterior $p(x \\mid y)$:\n\n1.  **Initialization**: Initialize the latent state $x^{(0)}$ to a starting configuration. A common and effective choice is to set it to the observed noisy image, $x^{(0)} = y$. This places the chain in a high-probability region of the state space.\n2.  **Iteration**: For each sweep $t=1, 2, \\dots, B+T$:\n    a.  **Systematic Scan**: Iterate through each pixel site $(i,j)$ in a fixed order, such as a raster scan (row by row, column by column).\n    b.  **Update**: For each site $(i,j)$, update its spin $x_{i,j}$ by drawing a new value from its full conditional distribution derived above.\n        i.  Calculate the sum of neighboring spins, $S_{i,j} = \\sum_{(k,\\ell) \\in \\mathcal{N}_{i,j}} x_{k,\\ell}^{(t')}$, where $x^{(t')}$ denotes the current state of the grid. Note that updates are done \"in-place\", so for a raster scan, neighbors already visited in the current sweep will have their new values.\n        ii. Compute $A_{i,j} = \\beta S_{i,j} + \\eta y_{i,j}$.\n        iii. Compute the conditional probability $p_{+} = \\mathbb{P}(x_{i,j}=+1 \\mid \\dots) = 1/(1 + \\exp(-2A_{i,j}))$.\n        iv. Draw a uniform random number $u \\sim U(0,1)$ from a generator with a fixed seed $s$.\n        v. Set the new spin: $x_{i,j} = +1$ if $u  p_{+}$, and $x_{i,j} = -1$ otherwise.\n3.  **Burn-in and Sampling**:\n    a.  Discard the first $B$ sweeps as \"burn-in\". This allows the Markov chain to converge to its stationary distribution, which is the desired posterior $p(x \\mid y)$.\n    b.  After burn-in, collect the states from the next $T$ sweeps, $\\{x^{(B+1)}, x^{(B+2)}, \\dots, x^{(B+T)}\\}$.\n4.  **Posterior Mean Estimation**: Approximate the posterior mean of each spin, $\\mathbb{E}[x_{i,j} \\mid y]$, by the sample mean:\n    $$\n    \\bar{x}_{i,j} = \\frac{1}{T} \\sum_{t=1}^{T} x_{i,j}^{(B+t)}\n    $$\n    In implementation, this is achieved by maintaining a running sum of the spins at each site over the $T$ sampling sweeps.\n5.  **Denoised Image Construction**: The final denoised estimate $\\hat{x}$ is obtained by taking the sign of the accumulated sum (or sample mean) at each pixel.\n    $$\n    \\hat{x}_{i,j} = \\text{sign}(\\bar{x}_{i,j})\n    $$\n    As specified, if the sum is positive, $\\hat{x}_{i,j}=+1$; otherwise (if zero or negative), $\\hat{x}_{i,j}=-1$.\n\n**3. Accuracy Calculation**\n\nFor each test case, the final denoised image $\\hat{x}$ is compared to the provided ground truth clean image $x^{\\star}$. The accuracy is the fraction of correctly estimated pixels:\n$$\n\\text{accuracy} = \\frac{1}{NM} \\sum_{i=0}^{N-1} \\sum_{j=0}^{M-1} \\mathbf{1}\\{\\hat{x}_{i,j} = x^{\\star}_{i,j}\\}\n$$\nwhere $N \\times M$ is the grid size and $\\mathbf{1}\\{\\cdot\\}$ is the indicator function. The result is rounded to three decimal places.\n\nThis completes the theoretical framework and algorithmic design for solving the problem. The implementation will follow this logic for each specified test case.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef create_test_cases():\n    \"\"\"Generates the four test cases as defined in the problem.\"\"\"\n    test_cases = []\n\n    # Test case 1\n    N1, M1 = 8, 8\n    x_star1 = np.full((N1, M1), -1, dtype=np.int8)\n    x_star1[2:6, 2:6] = 1\n    y1 = x_star1.copy()\n    flips1 = [(0, 0), (1, 7), (2, 3), (3, 2), (4, 4), (5, 5), (6, 1), (7, 6)]\n    for i, j in flips1:\n        y1[i, j] *= -1\n    case1 = {\n        \"x_star\": x_star1,\n        \"y\": y1,\n        \"beta\": 0.8,\n        \"epsilon\": 0.1,\n        \"B\": 300,\n        \"T\": 601,\n        \"seed\": 12345\n    }\n    test_cases.append(case1)\n\n    # Test case 2\n    x_star2 = np.array([[1]], dtype=np.int8)\n    y2 = np.array([[-1]], dtype=np.int8)\n    case2 = {\n        \"x_star\": x_star2,\n        \"y\": y2,\n        \"beta\": 0.6,\n        \"epsilon\": 0.3,\n        \"B\": 50,\n        \"T\": 501,\n        \"seed\": 7\n    }\n    test_cases.append(case2)\n\n    # Test case 3\n    N3, M3 = 10, 10\n    x_star3 = np.full((N3, M3), 1, dtype=np.int8)\n    y3 = x_star3.copy()\n    for i in range(N3):\n        for j in range(M3):\n            if (i + j) % 5 == 0:\n                y3[i, j] *= -1\n    case3 = {\n        \"x_star\": x_star3,\n        \"y\": y3,\n        \"beta\": 0.4,\n        \"epsilon\": 0.3,\n        \"B\": 300,\n        \"T\": 601,\n        \"seed\": 2024\n    }\n    test_cases.append(case3)\n\n    # Test case 4\n    N4, M4 = 6, 6\n    x_star4 = np.full((N4, M4), -1, dtype=np.int8)\n    x_star4[:, 3:] = 1\n    y4 = x_star4.copy()\n    for i in range(N4):\n        for j in range(M4):\n            if (i * M4 + j) % 5 == 1:\n                y4[i, j] *= -1\n    case4 = {\n        \"x_star\": x_star4,\n        \"y\": y4,\n        \"beta\": 0.0,\n        \"epsilon\": 0.2,\n        \"B\": 200,\n        \"T\": 401,\n        \"seed\": 999\n    }\n    test_cases.append(case4)\n\n    return test_cases\n\ndef gibbs_denoise(y, beta, epsilon, B, T, seed):\n    \"\"\"\n    Performs MCMC denoising using Gibbs sampling.\n    \"\"\"\n    N, M = y.shape\n    rng = np.random.default_rng(seed)\n\n    # Initialize latent state x with the observed image y\n    x = y.copy()\n\n    # Pre-calculate eta to avoid repeated computation\n    # Epsilon must be in (0,1) to avoid division by zero or log of zero.\n    # The problem statement guarantees epsilon in (0,1).\n    eta = 0.5 * np.log((1.0 - epsilon) / epsilon)\n\n    # Burn-in phase\n    for _ in range(B):\n        # Raster scan over all pixels\n        for i in range(N):\n            for j in range(M):\n                # Calculate sum of neighbors\n                S_ij = 0\n                if i > 0: S_ij += x[i - 1, j]\n                if i  N - 1: S_ij += x[i + 1, j]\n                if j > 0: S_ij += x[i, j - 1]\n                if j  M - 1: S_ij += x[i, j + 1]\n\n                # Calculate the argument of the exponential\n                A_ij = beta * S_ij + eta * y[i, j]\n\n                # Calculate conditional probability of x_ij being +1\n                p_plus = 1.0 / (1.0 + np.exp(-2.0 * A_ij))\n\n                # Sample new value for x_ij\n                if rng.random()  p_plus:\n                    x[i, j] = 1\n                else:\n                    x[i, j] = -1\n\n    # Sampling phase\n    x_sum = np.zeros_like(x, dtype=np.float64)\n    for _ in range(T):\n        # Raster scan over all pixels\n        for i in range(N):\n            for j in range(M):\n                # Calculate sum of neighbors\n                S_ij = 0\n                if i > 0: S_ij += x[i - 1, j]\n                if i  N - 1: S_ij += x[i + 1, j]\n                if j > 0: S_ij += x[i, j - 1]\n                if j  M - 1: S_ij += x[i, j + 1]\n                \n                # Calculate the argument of the exponential\n                A_ij = beta * S_ij + eta * y[i, j]\n\n                # Calculate conditional probability of x_ij being +1\n                p_plus = 1.0 / (1.0 + np.exp(-2.0 * A_ij))\n\n                # Sample new value for x_ij\n                if rng.random()  p_plus:\n                    x[i, j] = 1\n                else:\n                    x[i, j] = -1\n        \n        # Accumulate the sample after a full sweep\n        x_sum += x\n\n    # Construct the final estimate by taking the sign of the sum\n    x_hat = np.ones_like(x, dtype=np.int8)\n    x_hat[x_sum = 0] = -1\n\n    return x_hat\n\ndef solve():\n    \"\"\"\n    Main function to run the MCMC denoising for all test cases.\n    \"\"\"\n    test_cases = create_test_cases()\n    results = []\n\n    for case in test_cases:\n        x_star = case[\"x_star\"]\n        y = case[\"y\"]\n        beta = case[\"beta\"]\n        epsilon = case[\"epsilon\"]\n        B = case[\"B\"]\n        T = case[\"T\"]\n        seed = case[\"seed\"]\n\n        # Get the denoised image estimate\n        x_hat = gibbs_denoise(y, beta, epsilon, B, T, seed)\n\n        # Calculate accuracy\n        accuracy = np.mean(x_hat == x_star)\n        \n        # Round to three decimal places\n        rounded_accuracy = round(accuracy, 3)\n        results.append(f\"{rounded_accuracy:.3f}\")\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(results)}]\")\n\nsolve()\n```", "id": "3250350"}]}