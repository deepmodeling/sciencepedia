{"hands_on_practices": [{"introduction": "To truly understand an iterative method, one must look under the hood and analyze its convergence properties. This exercise guides you through a complete, from-scratch analysis of a simple two-level Algebraic Multigrid (AMG) cycle for a model problem. By analytically constructing all the core components—the smoother $S$, the coarse-grid correction operator $C$, and the final error propagation matrix $E = SC$—you will demystify how errors are transformed in a single AMG iteration. The final goal, computing the spectral radius $\\rho(E)$, provides a concrete measure of the method's effectiveness and solidifies the theoretical foundation of multigrid convergence [@problem_id:3204444].", "problem": "Consider the one-dimensional Poisson problem $-u''(x) = f(x)$ on the interval $(0,1)$ with homogeneous Dirichlet boundary conditions $u(0) = u(1) = 0$. Discretize the problem using a uniform grid with $N=4$ interior points and the standard second-order centered finite difference stencil. Let the resulting symmetric positive definite (SPD) stiffness matrix be written as $A = \\frac{1}{h^{2}}T$, where $h$ is the grid spacing and\n$$\nT = \\begin{pmatrix}\n2 & -1 & 0 & 0 \\\\\n-1 & 2 & -1 & 0 \\\\\n0 & -1 & 2 & -1 \\\\\n0 & 0 & -1 & 2\n\\end{pmatrix}.\n$$\nAll subsequent constructions may be performed with $T$ (since diagonal scaling by $\\frac{1}{h^2}$ cancels in the iteration matrix), and you may treat $A$ and $T$ interchangeably for the purposes of spectral analysis.\n\nConstruct a two-level Algebraic Multigrid (AMG) method with the following components:\n- Choose coarse nodes at fine-grid indices $2$ and $4$. Define the interpolation operator $P \\in \\mathbb{R}^{4 \\times 2}$ by injection onto coarse nodes and linear interpolation onto fine nodes as\n$$\nP = \\begin{pmatrix}\n1 & 0 \\\\\n1 & 0 \\\\\n\\frac{1}{2} & \\frac{1}{2} \\\\\n0 & 1\n\\end{pmatrix}.\n$$\n- Use restriction $R = P^{\\top}$ and the Galerkin coarse operator $A_{c} = R A P$.\n- Use a single post-smoothing step with weighted Jacobi, with weight $\\omega = \\frac{2}{3}$. The weighted Jacobi smoother is $S = I - \\omega D^{-1}A$, where $D = \\mathrm{diag}(A)$.\n- Use exact coarse-grid correction with the operator $C = I - P A_{c}^{-1} R A$.\n\nThe error-propagation matrix for one two-level cycle with coarse-grid correction followed by one post-smoothing step is $E = S C$.\n\nStarting from the above definitions and constructions, derive the spectral radius $\\rho(E)$, defined by $\\rho(E) = \\max\\{|\\lambda| : \\lambda \\in \\sigma(E)\\}$, in closed analytical form. Express your final answer as a single closed-form expression. No rounding is required, and no physical units apply.", "solution": "The two-level error propagation matrix for one cycle is given by $E = S C$, where $S$ is the smoother operator and $C$ is the coarse-grid correction operator. We need to find the spectral radius $\\rho(E)$. As noted in the problem statement, the scaling factor $\\frac{1}{h^2}$ in the matrix $A = \\frac{1}{h^2}T$ cancels out in the definitions of both $S$ and $C$. Therefore, we can perform the entire analysis using the matrix $T$, which we will denote as $A$ for simplicity for the remainder of this derivation.\n$$\nA = T = \\begin{pmatrix}\n2 & -1 & 0 & 0 \\\\\n-1 & 2 & -1 & 0 \\\\\n0 & -1 & 2 & -1 \\\\\n0 & 0 & -1 & 2\n\\end{pmatrix}\n$$\nFirst, we construct the weighted Jacobi smoother $S = I - \\omega D^{-1}A$ with weight $\\omega = \\frac{2}{3}$. The diagonal of $A$ is $D = \\mathrm{diag}(2,2,2,2) = 2I$.\n$$\nS = I - \\frac{2}{3}(2I)^{-1}A = I - \\frac{1}{3}A\n$$\n$$\nS = \\frac{1}{3}\\begin{pmatrix} 1 & 1 & 0 & 0 \\\\ 1 & 1 & 1 & 0 \\\\ 0 & 1 & 1 & 1 \\\\ 0 & 0 & 1 & 1 \\end{pmatrix}\n$$\nNext, we construct the coarse-grid correction operator $C = I - P A_c^{-1} R A$. The components are:\n$$\nP = \\begin{pmatrix}\n1 & 0 \\\\\n1 & 0 \\\\\n\\frac{1}{2} & \\frac{1}{2} \\\\\n0 & 1\n\\end{pmatrix}, \\quad R = P^{\\top} = \\begin{pmatrix}\n1 & 1 & \\frac{1}{2} & 0 \\\\\n0 & 0 & \\frac{1}{2} & 1\n\\end{pmatrix}\n$$\nThe coarse-grid operator is $A_c = R A P$:\n$$\nA_c = \\begin{pmatrix} 1 & 1 & \\frac{1}{2} & 0 \\\\ 0 & 0 & \\frac{1}{2} & 1 \\end{pmatrix} \\begin{pmatrix} 2 & -1 & 0 & 0 \\\\ -1 & 2 & -1 & 0 \\\\ 0 & -1 & 2 & -1 \\\\ 0 & 0 & -1 & 2 \\end{pmatrix} \\begin{pmatrix} 1 & 0 \\\\ 1 & 0 \\\\ \\frac{1}{2} & \\frac{1}{2} \\\\ 0 & 1 \\end{pmatrix} = \\begin{pmatrix} \\frac{3}{2} & -\\frac{1}{2} \\\\ -\\frac{1}{2} & \\frac{3}{2} \\end{pmatrix}\n$$\nThe inverse is $A_c^{-1} = \\frac{1}{(\\frac{9}{4}-\\frac{1}{4})} \\begin{pmatrix} \\frac{3}{2} & \\frac{1}{2} \\\\ \\frac{1}{2} & \\frac{3}{2} \\end{pmatrix} = \\frac{1}{4} \\begin{pmatrix} 3 & 1 \\\\ 1 & 3 \\end{pmatrix}$.\n\nThe spectral radius $\\rho(E) = \\rho(SC)$ is equal to $\\rho(CS)$. We compute the matrix $CS$. The coarse-grid correction operator is $C = I - P A_c^{-1} R A$. We calculate the matrix $\\Pi A = P A_c^{-1} R A$:\n$$\n\\Pi A = \\frac{1}{4}\\begin{pmatrix} 3 & 1 & 0 & 0 \\\\ 3 & 1 & 0 & 0 \\\\ 2 & 0 & 0 & 2 \\\\ 1 & -1 & 0 & 4 \\end{pmatrix}\n$$\nThen, $C = I - \\Pi A$:\n$$\nC = \\frac{1}{4}\\begin{pmatrix} 1 & -1 & 0 & 0 \\\\ -3 & 3 & 0 & 0 \\\\ -2 & 0 & 4 & -2 \\\\ -1 & 1 & 0 & 0 \\end{pmatrix}\n$$\nNow we compute the matrix $N = CS$:\n$$\nN = CS = \\frac{1}{12} \\begin{pmatrix} 1 & -1 & 0 & 0 \\\\ -3 & 3 & 0 & 0 \\\\ -2 & 0 & 4 & -2 \\\\ -1 & 1 & 0 & 0 \\end{pmatrix} \\begin{pmatrix} 1 & 1 & 0 & 0 \\\\ 1 & 1 & 1 & 0 \\\\ 0 & 1 & 1 & 1 \\\\ 0 & 0 & 1 & 1 \\end{pmatrix} = \\frac{1}{12} \\begin{pmatrix} 0 & 0 & -1 & 0 \\\\ 0 & 0 & 3 & 0 \\\\ -2 & 2 & 2 & 2 \\\\ 0 & 0 & 1 & 0 \\end{pmatrix}\n$$\nThe eigenvalues $\\lambda$ of $E = SC$ are the same as the eigenvalues of $N = CS$. Let $\\mu = 12\\lambda$ be the eigenvalues of the matrix $12N$. We find the characteristic polynomial $\\det(12N - \\mu I) = 0$:\n$$\n\\det\\begin{pmatrix} -\\mu & 0 & -1 & 0 \\\\ 0 & -\\mu & 3 & 0 \\\\ -2 & 2 & 2-\\mu & 2 \\\\ 0 & 0 & 1 & -\\mu \\end{pmatrix} = \\mu^2(\\mu^2 - 2\\mu - 10) = 0\n$$\nThe eigenvalues $\\mu$ of $12N$ are the roots of this polynomial: $\\mu = 0$ (with multiplicity 2), and the roots of $\\mu^2 - 2\\mu - 10 = 0$. Using the quadratic formula, these roots are:\n$$\n\\mu = \\frac{2 \\pm \\sqrt{4 - 4(-10)}}{2} = \\frac{2 \\pm \\sqrt{44}}{2} = 1 \\pm \\sqrt{11}\n$$\nThe eigenvalues of $E$ are $\\lambda = \\frac{\\mu}{12}$, which are $\\{0, 0, \\frac{1+\\sqrt{11}}{12}, \\frac{1-\\sqrt{11}}{12}\\}$. The spectral radius is the maximum of the absolute values of these eigenvalues:\n$$\n\\rho(E) = \\max\\left\\{0, \\frac{1+\\sqrt{11}}{12}, \\frac{\\sqrt{11}-1}{12}\\right\\} = \\frac{1+\\sqrt{11}}{12}\n$$", "answer": "$$\n\\boxed{\\frac{1+\\sqrt{11}}{12}}\n$$", "id": "3204444"}, {"introduction": "Moving from theory to practice, we must recognize that key operators like the prolongation matrix $P$ are not simply given to us; they must be constructed based on the system matrix $A$. This hands-on coding challenge explores a common technique, aggregation-based coarsening, and reveals its potential pitfalls [@problem_id:3204466]. You will discover firsthand how a naively implemented aggregation scheme can violate fundamental mathematical requirements—specifically, by producing a column-rank-deficient prolongation operator $P$—which in turn causes a fatal breakdown by creating a singular coarse-grid operator $A_c$. By implementing safeguards to enforce a valid aggregation, you will learn how to build robust AMG setup routines that bridge the gap between abstract theory and practical, working code.", "problem": "In Algebraic Multigrid (AMG), a coarse-grid operator is constructed by the Galerkin product $A_{c} = R A P$. In the symmetric positive definite case, a common choice is the symmetric Galerkin formulation with $R = P^{\\top}$, so that $A_{c} = P^{\\top} A P$. For a fine-level matrix $A \\in \\mathbb{R}^{n \\times n}$ that is symmetric positive definite, if the columns of the prolongation $P \\in \\mathbb{R}^{n \\times n_{c}}$ are linearly independent, then $A_{c}$ is also symmetric positive definite. However, if classical coarsening is implemented naively and violates basic constraints of aggregation (such as disjointness and non-emptiness of aggregates), then $P$ can become column-rank deficient, which forces $A_{c}$ to be singular because there exists a nonzero $y \\in \\mathbb{R}^{n_{c}}$ such that $P y = 0$ and thus $y^{\\top} A_{c} y = (P y)^{\\top} A (P y) = 0$.\n\nYour task is to construct a concrete counterexample in code where a naive classical aggregation scheme produces a singular coarse-grid operator $A_{c}$ even though the fine-level operator $A$ is symmetric positive definite. Then, you must diagnose the cause in terms of violated aggregation constraints and fix it by introducing safeguards that enforce a valid aggregation partition, yielding a full-column-rank $P$ and a nonsingular $A_{c}$.\n\nUse the following fundamental base and definitions:\n\n- Let $A$ be the one-dimensional discrete Poisson operator with homogeneous Dirichlet boundary conditions on a uniform grid, that is, the tridiagonal matrix with $2$ on the diagonal and $-1$ on the first sub- and super-diagonals. This matrix is symmetric positive definite for all $n \\ge 1$.\n- In aggregation-based coarsening, a tentative prolongation $P$ is commonly constructed as piecewise constant on aggregates: if node $i$ belongs to aggregate $j$, set $P_{ij} = 1$, and $P_{ik} = 0$ for $k \\ne j$. Valid aggregation requires that aggregates form a partition of $\\{0,1,\\dots,n-1\\}$ into disjoint, nonempty sets.\n\nYour program must implement the following steps:\n\n1. Construct fine-level matrices $A \\in \\mathbb{R}^{n \\times n}$ as the $1$-dimensional Dirichlet Poisson operator for given $n$.\n2. For each test case, construct a naive, potentially invalid tentative prolongation $P_{\\text{naive}}$ from user-specified aggregate lists that may violate the partition constraints (e.g., duplicate aggregates and empty aggregates). Define $A_{c,\\text{naive}} = P_{\\text{naive}}^{\\top} A P_{\\text{naive}}$.\n3. Implement safeguards that enforce a valid aggregation partition:\n   - Remove empty aggregates.\n   - Deduplicate identical aggregates, keeping the first occurrence.\n   - Enforce that each fine node belongs to at most one aggregate by tie-breaking in favor of the earliest aggregate.\n   - Ensure coverage by assigning any unassigned node to a singleton aggregate.\n   Construct the safeguarded prolongation $P_{\\text{safe}}$ from the repaired aggregates and compute $A_{c,\\text{safe}} = P_{\\text{safe}}^{\\top} A P_{\\text{safe}}$.\n4. Decide singularity using a numerical rank test. Compute the singular values of $A_{c}$ and declare it singular if the smallest singular value is less than a tolerance $\\tau = 10^{-12}$.\n5. For each test case, return a pair of booleans $[\\text{is\\_singular}(A_{c,\\text{naive}}), \\text{is\\_singular}(A_{c,\\text{safe}})]$.\n\nTest suite and coverage:\n\nProvide the following three test cases covering distinct failure modes and a healthy case. Each test case is a tuple $(n, \\text{aggregates})$, where $n$ is the fine-level size and $\\text{aggregates}$ is a list of lists specifying naive aggregates:\n\n- Case $1$ (duplicate aggregates causing identical columns in $P$): $n = 4$, $\\text{aggregates} = [[1], [1]]$.\n- Case $2$ (empty and overlapping aggregates causing a zero column and ties): $n = 5$, $\\text{aggregates} = [[0,1], [], [1]]$.\n- Case $3$ (valid partition as a control case): $n = 6$, $\\text{aggregates} = [[0,1,2], [3,4], [5]]$.\n\nAnswer specification:\n\n- For each of the above cases, output the pair of booleans as described in step $5$.\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, concatenating the pairs from all test cases in order. For example, an output might look like $[{\\tt True},{\\tt False},{\\tt True},{\\tt False},{\\tt False},{\\tt False}]$.\n\nNo physical units are involved. Angles and percentages are not involved.\n\nYour program must be a complete, runnable Python program that computes these results exactly as specified, with no user input.", "solution": "The problem requires the construction of a concrete numerical counterexample within the framework of Algebraic Multigrid (AMG) methods. Specifically, it aims to demonstrate that a naively constructed aggregation scheme can lead to a singular coarse-grid operator, even when the fine-grid operator is symmetric positive definite (SPD). Subsequently, a set of safeguards must be implemented to repair the aggregation, thereby ensuring the resulting coarse-grid operator is non-singular.\n\nFirst, we establish the theoretical foundation. In aggregation-based AMG, a hierarchy of problems is built, where each coarser level represents the original problem with fewer degrees of freedom. The coarse-grid operator, $A_c$, is derived from the fine-grid operator, $A \\in \\mathbb{R}^{n \\times n}$, and a prolongation operator, $P \\in \\mathbb{R}^{n \\times n_c}$, which maps coarse-grid vectors to fine-grid vectors. The standard method for constructing $A_c$ is the Galerkin projection: $A_c = R A P$, where $R \\in \\mathbb{R}^{n_c \\times n}$ is the restriction operator. For SPD systems, it is customary to choose $R = P^{\\top}$, yielding the symmetric Galerkin operator $A_c = P^{\\top} A P$.\n\nA crucial property of this construction is that if $A$ is SPD and the prolongation operator $P$ has full column rank (i.e., its $n_c$ columns are linearly independent), then the coarse-grid operator $A_c \\in \\mathbb{R}^{n_c \\times n_c}$ is also SPD, and therefore non-singular. This can be shown by examining the quadratic form for any non-zero vector $y \\in \\mathbb{R}^{n_c}$:\n$$\ny^{\\top} A_c y = y^{\\top} (P^{\\top} A P) y = (Py)^{\\top} A (Py)\n$$\nSince $P$ has full column rank, $y \\ne 0$ implies $Py \\ne 0$. Because $A$ is SPD, for any non-zero vector $v = Py$, we have $v^{\\top} A v > 0$. Therefore, $y^{\\top} A_c y > 0$ for all $y \\ne 0$, which is the definition of a symmetric positive definite matrix.\n\nConversely, if $P$ is column-rank deficient, there exists a non-zero vector $y_0 \\in \\mathbb{R}^{n_c}$ such that $P y_0 = 0$. This vector $y_0$ belongs to the null space of $P$. For this vector, we find:\n$$\nA_c y_0 = (P^{\\top} A P) y_0 = P^{\\top} A (P y_0) = P^{\\top} A 0 = 0\n$$\nSince there exists a non-zero vector $y_0$ for which $A_c y_0 = 0$, the matrix $A_c$ is by definition singular.\n\nThe problem at hand involves an aggregation-based scheme where $P$ is a piecewise-constant interpolant. The columns of $P$ correspond to aggregates, which are sets of fine-grid nodes. For an aggregation $\\{G_0, G_1, \\dots, G_{n_c-1}\\}$, the entries of $P$ are defined as $P_{ij} = 1$ if fine node $i$ is in aggregate $G_j$, and $P_{ij} = 0$ otherwise. A valid aggregation must form a partition of the set of all fine-grid nodes $\\{0, 1, \\dots, n-1\\}$ into disjoint, non-empty subsets. Violations of these constraints lead to a rank-deficient $P$:\n1.  An empty aggregate $G_j = \\emptyset$ results in the $j$-th column of $P$ being a zero vector.\n2.  Duplicate aggregates, e.g., $G_j = G_k$ for $j \\ne k$, result in identical columns in $P$.\n3.  Overlapping aggregates can lead to linear dependencies between the columns of $P$.\n\nOur implementation will follow the specified steps. The fine-grid operator $A$ is the $n \\times n$ matrix representing the 1D discrete Poisson equation with homogeneous Dirichlet boundary conditions, which has $2$ on its main diagonal and $-1$ on its first sub- and super-diagonals. This matrix is known to be SPD for any $n \\ge 1$.\n\nThe algorithmic procedure is as follows:\n1.  For each test case $(n, \\text{aggregates})$, we construct the fine-level matrix $A \\in \\mathbb{R}^{n \\times n}$.\n2.  We construct a naive prolongation operator, $P_{\\text{naive}}$, directly from the provided `aggregates` list. The number of columns in $P_{\\text{naive}}$ equals the number of lists in `aggregates`. We then compute $A_{c, \\text{naive}} = P_{\\text{naive}}^{\\top} A P_{\\text{naive}}$.\n3.  We apply a series of safeguards to the `aggregates` list to produce a valid partition:\n    a.  Empty aggregates (e.g., `[]`) are removed.\n    b.  Duplicate aggregates are removed, keeping only the first occurrence. Aggregates are considered identical if they contain the same set of nodes, regardless of order.\n    c.  Overlaps are resolved by honoring a \"first-come, first-served\" rule. We iterate through the sanitized aggregates; any node within an aggregate that has already been claimed by a previous aggregate is removed from the current one.\n    d.  Finally, we ensure full coverage of all nodes from $0$ to $n-1$. Any node not yet assigned to an aggregate is placed into a new singleton aggregate.\n4.  From this repaired partition, a safeguarded prolongation operator, $P_{\\text{safe}}$, is constructed. The coarse operator is then $A_{c, \\text{safe}} = P_{\\text{safe}}^{\\top} A P_{\\text{safe}}$.\n5.  The singularity of both $A_{c, \\text{naive}}$ and $A_{c, \\text{safe}}$ is determined by computing their singular values. A matrix is deemed singular if its smallest singular value is less than a tolerance $\\tau = 10^{-12}$. For each test case, we return a boolean pair indicating the singularity of the naive and safeguarded coarse operators.\n\nAnalysis of the test cases:\n*   **Case 1**: $n = 4$, $\\text{aggregates} = [[1], [1]]$. The naive aggregation contains duplicate aggregates. This makes the two columns of $P_{\\text{naive}}$ identical, rendering it rank-deficient. Thus, $A_{c,\\text{naive}}$ will be singular. The safeguards will remove the duplicate, leaving `[[1]]`, and then add singleton aggregates for the uncovered nodes `0`, `2`, and `3`. The resulting aggregates `[[1], [0], [2], [3]]` form a valid partition, leading to a full-rank $P_{\\text{safe}}$ and a non-singular $A_{c,\\text{safe}}$. Expected result: $[\\text{True}, \\text{False}]$.\n*   **Case 2**: $n = 5$, $\\text{aggregates} = [[0,1], [], [1]]$. The naive aggregation includes an empty aggregate, which creates a zero column in $P_{\\text{naive}}$, guaranteeing rank deficiency and a singular $A_{c,\\text{naive}}$. The safeguards will first remove the empty aggregate. Then, in processing `[[0,1], [1]]`, it will assign nodes `0` and `1` to the first aggregate. The second aggregate `[1]` will become empty as node `1` is already assigned, and thus it will be discarded. Finally, uncovered nodes `2`, `3`, and `4` will form singletons. The repaired partition will be valid, yielding a non-singular $A_{c,\\text{safe}}$. Expected result: $[\\text{True}, \\text{False}]$.\n*   **Case 3**: $n = 6$, $\\text{aggregates} = [[0,1,2], [3,4], [5]]$. This is already a valid partition. The naive construction $P_{\\text{naive}}$ will have full column rank. The safeguard procedure will not alter the aggregates. Therefore, both $P_{\\text{naive}}$ and $P_{\\text{safe}}$ will be identical and full-rank, leading to non-singular $A_{c,\\text{naive}}$ and $A_{c,\\text{safe}}$. Expected result: $[\\text{False}, \\text{False}]$.\n\nThe implementation will confirm these theoretical predictions.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Implements the full logic to test naive vs. safeguarded AMG aggregation.\n    \"\"\"\n    \n    # Test suite as specified in the problem statement.\n    test_cases = [\n        # Case 1 (duplicate aggregates)\n        (4, [[1], [1]]),\n        # Case 2 (empty and overlapping aggregates)\n        (5, [[0, 1], [], [1]]),\n        # Case 3 (valid partition)\n        (6, [[0, 1, 2], [3, 4], [5]]),\n    ]\n\n    results = []\n    \n    # Tolerance for singularity test\n    TOL = 1e-12\n\n    def construct_A(n):\n        \"\"\"Constructs the 1D Poisson matrix A of size n x n.\"\"\"\n        if n == 0:\n            return np.array([[]])\n        A = np.eye(n) * 2\n        if n > 1:\n            A -= np.eye(n, k=1)\n            A -= np.eye(n, k=-1)\n        return A\n\n    def construct_P(n, aggregates):\n        \"\"\"Constructs the prolongation matrix P from a list of aggregates.\"\"\"\n        nc = len(aggregates)\n        if n == 0 and nc == 0:\n            return np.array([[]])\n        P = np.zeros((n, nc))\n        for j, agg in enumerate(aggregates):\n            for i in agg:\n                if 0 = i  n: # Ensure node index is valid\n                    P[i, j] = 1\n        return P\n\n    def is_singular(matrix, tol):\n        \"\"\"\n        Checks if a matrix is singular based on its smallest singular value.\n        An empty matrix (0x0, 0xM, Nx0) is considered non-singular (full rank).\n        \"\"\"\n        if matrix.size == 0:\n            return False\n            \n        singular_values = np.linalg.svd(matrix, compute_uv=False)\n        \n        # If there are no singular values (e.g., for a 1x0 matrix), it's not singular.\n        if singular_values.size == 0:\n            return False\n\n        return singular_values[-1]  tol\n\n    for n, naive_aggregates in test_cases:\n        # 1. Construct the fine-level operator A\n        A = construct_A(n)\n\n        # 2. Process the naive case\n        P_naive = construct_P(n, naive_aggregates)\n        if P_naive.shape[1] > 0:\n            Ac_naive = P_naive.T @ A @ P_naive\n        else:\n            Ac_naive = np.array([[]]) # Result is a 0x0 matrix\n        \n        is_naive_singular = is_singular(Ac_naive, TOL)\n        results.append(is_naive_singular)\n\n        # 3. Implement safeguards to create a valid partition\n        \n        # Rule a: Remove empty aggregates\n        aggregates_step1 = [agg for agg in naive_aggregates if agg]\n\n        # Rule b: Deduplicate identical aggregates, keeping the first occurrence.\n        # Aggregates are identical if they contain the same nodes, regardless of order.\n        aggregates_step2 = []\n        seen_agg_tuples = set()\n        for agg in aggregates_step1:\n            # Sort to treat [0,1] and [1,0] as identical\n            agg_tuple = tuple(sorted(agg))\n            if agg_tuple not in seen_agg_tuples:\n                seen_agg_tuples.add(agg_tuple)\n                aggregates_step2.append(agg)\n\n        # Rule c: Enforce disjointness, tie-breaking to the earliest aggregate\n        assigned_nodes = np.zeros(n, dtype=bool)\n        aggregates_step3 = []\n        for agg in aggregates_step2:\n            new_agg = []\n            for node in agg:\n                if 0 = node  n and not assigned_nodes[node]:\n                    new_agg.append(node)\n                    assigned_nodes[node] = True\n            if new_agg: # Only add if it's not empty after resolving conflicts\n                aggregates_step3.append(new_agg)\n\n        # Rule d: Ensure coverage by creating singleton aggregates for unassigned nodes\n        safe_aggregates = aggregates_step3\n        for i in range(n):\n            if not assigned_nodes[i]:\n                safe_aggregates.append([i])\n        \n        # 4. Process the safeguarded case\n        P_safe = construct_P(n, safe_aggregates)\n        if P_safe.shape[1] > 0:\n            Ac_safe = P_safe.T @ A @ P_safe\n        else:\n            Ac_safe = np.array([[]])\n\n        is_safe_singular = is_singular(Ac_safe, TOL)\n        results.append(is_safe_singular)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "3204466"}, {"introduction": "What happens when a carefully implemented AMG solver fails to converge efficiently? This final practice problem equips you with the tools to answer this critical, real-world question by building a numerical diagnostic tool. Stagnation in AMG often signals a breakdown in the crucial partnership between smoothing, which damps high-energy errors, and coarse-grid correction, which handles low-energy errors. This exercise will teach you to implement and interpret a suite of professional-grade diagnostic indicators, such as the Rayleigh quotient of the residual and measures of near-nullspace dominance, to pinpoint exactly which part of this partnership is failing and why [@problem_id:3204416].", "problem": "You are asked to design and implement a diagnostic tool for Algebraic Multigrid (AMG) convergence issues. The tool receives a system matrix and a stagnated residual vector and must infer plausible root causes by measuring mathematically defined indicators and comparing them to clearly specified thresholds.\n\nStarting from core definitions in linear algebra and multigrid error propagation, recall that, for a linear system $A x = b$ with iterate $x_k$, the residual is $r_k = b - A x_k$. Convergence stagnation in Algebraic Multigrid (AMG) is often linked to how the smoother and coarse-grid correction interact with the error and residual components. The fundamental guiding facts are:\n- Smoothers, such as Jacobi or Gauss–Seidel, are effective at reducing high-energy (high-frequency) error components when measured in the $A$-energy norm, which for a symmetric positive definite (SPD) matrix is defined by $\\langle e, e \\rangle_A = e^\\top A e$.\n- Coarse-grid correction must capture low-energy (low-frequency) components; if it does not, low-energy residuals persist.\n- The Rayleigh quotient $\\lambda(v) = \\dfrac{v^\\top A v}{v^\\top v}$ measures the energy of vector $v$ relative to the operator $A$.\n- Ill-conditioning, singularity, nonsymmetry, and non-$M$-matrix structure are classical obstacles for AMG robustness.\n\nYour program must implement the following diagnostic indicators for a given pair $(A, r)$:\n1) Low-energy residual component: Define the symmetric part $A_s = \\dfrac{1}{2}(A + A^\\top)$. For nonzero $r$, compute the Rayleigh quotient $\\lambda_r = \\dfrac{r^\\top A_s r}{r^\\top r}$, and compare to the average diagonal magnitude $d_{\\mathrm{avg}} = \\dfrac{1}{n} \\sum_{i=1}^n |a_{ii}|$, where $n$ is the size of $A$. Flag this indicator if $\\lambda_r \\le \\tau_E \\, d_{\\mathrm{avg}}$ with $\\tau_E = 0.1$.\n2) Constant-mode dominance: Let $u$ be the vector of all ones of length $n$. Compute the fraction $c_{\\mathrm{frac}} = \\dfrac{|u^\\top r|}{\\sqrt{n} \\, \\|r\\|_2}$. Flag this indicator if $c_{\\mathrm{frac}} \\ge 0.7$.\n3) Nonsymmetric or non-$M$-matrix structure: Compute the Frobenius-norm-based nonsymmetry measure $s = \\dfrac{\\|A - A^\\top\\|_F}{\\|A\\|_F}$, and the fraction $p$ of positive off-diagonal entries $a_{ij}$ with $i \\ne j$. Flag this indicator if $s \\ge 0.1$ or $p \\ge 0.5$.\n4) Ill-conditioning: Estimate the $2$-norm condition number $\\kappa_2(A)$ using singular values. Flag this indicator if $\\kappa_2(A) \\ge 10^8$.\n5) Near-singularity: Let $\\sigma_{\\min}(A)$ be the smallest singular value. Flag this indicator if $\\sigma_{\\min}(A) \\le 10^{-14}$.\n6) Smoother breakdown due to extreme diagonal scaling: Let $d_{\\min} = \\min_i |a_{ii}|$ and $d_{\\max} = \\max_i |a_{ii}|$. Flag this indicator if $\\dfrac{d_{\\min}}{d_{\\max}}  10^{-8}$.\n7) Weak connectivity or nearly diagonal operator: Define the ratio $\\rho_{\\mathrm{od}} = \\dfrac{\\sum_{i \\ne j} |a_{ij}|}{\\sum_{i} |a_{ii}|}$, provided the denominator is nonzero. Flag this indicator if $\\rho_{\\mathrm{od}} \\le 0.1$.\n\nAssociate each indicator with the integer code shown below:\n- Code $1$: Low-energy residual (coarse-grid representation likely insufficient).\n- Code $2$: Residual dominated by the constant mode (missing near-nullspace vector).\n- Code $3$: Nonsymmetric or non-$M$-matrix structure (classical AMG assumptions violated).\n- Code $4$: Ill-conditioned or poorly scaled operator.\n- Code $5$: Singular or nearly singular operator.\n- Code $6$: Smoother breakdown risk due to extreme diagonal scaling (e.g., damped Jacobi with tiny diagonal entries).\n- Code $7$: Weak connectivity or nearly diagonal structure (interpolation/coarsening may be ineffective).\n\nTest suite. Your program must run on the following five test cases, each specified in purely mathematical terms:\n\n- Case A: One-dimensional Dirichlet Laplacian of size $n = 8$. The matrix $A$ is tridiagonal with $a_{ii} = 2$ and $a_{i,i+1} = a_{i+1,i} = -1$ for $i = 1, \\dots, n-1$. The residual $r$ is the lowest-frequency Dirichlet mode given by $r_i = \\sin\\!\\left(\\dfrac{\\pi i}{n+1}\\right)$ for $i = 1, \\dots, n$.\n- Case B: Strictly upper bidiagonal perturbation of the identity with size $n = 6$. The matrix $A$ has $a_{ii} = 2$ for all $i$, and $a_{i,i+1} = 1$ for $i = 1, \\dots, n-1$, with all other entries zero. The residual is $r = [1, -1, 2, -2, 1, -1]^\\top$.\n- Case C: Diagonal, SPD, strongly ill-conditioned matrix of size $n = 5$. The matrix is $A = \\mathrm{diag}(10^{-6}, 10^{-3}, 1, 10^{3}, 10^{6})$. The residual is $r = [1, 2, 3, 4, 5]^\\top$.\n- Case D: Diagonal matrix with one extremely small diagonal entry, size $n = 5$. The matrix is $A = \\mathrm{diag}(1, 1, 10^{-12}, 1, 1)$. The residual is $r = [1, 0, 1, 0, 1]^\\top$.\n- Case E: One-dimensional Neumann Laplacian of size $n = 4$, which is symmetric positive semidefinite. The matrix $A$ has $a_{11} = 1$, $a_{nn} = 1$, $a_{ii} = 2$ for $i = 2, \\dots, n-1$, and $a_{i,i+1} = a_{i+1,i} = -1$ for $i = 1, \\dots, n-1$. The residual is $r = [1, 1, 1, 1]^\\top$.\n\nOutput specification. For each test case, collect all triggered codes into a list of integers in increasing order without duplicates. Aggregate the results for all cases in the order A, B, C, D, E into a single list of lists. Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets in the following format:\n- If the per-case results are $\\mathcal{R}_A, \\mathcal{R}_B, \\mathcal{R}_C, \\mathcal{R}_D, \\mathcal{R}_E$, print the single line string \"[RA,RB,RC,RD,RE]\" where each R? is itself a bracketed list of integers, with no spaces. For example, a possible valid output is \"[[1],[3],[4,7],[4,6,7],[1,2,4,5]]\".\nThe required answers are integer lists; there are no physical units or angles involved. All fractional thresholds specified above must be implemented as decimals as given (for example, $0.1$ and $0.7$ are decimals, not percentages).", "solution": "We design the diagnostic from first principles of linear algebra and the core multigrid paradigm, which combine error smoothing and coarse-grid correction. The key mathematical entities are the residual $r = b - A x$, the Rayleigh quotient $\\lambda(v) = \\dfrac{v^\\top A v}{v^\\top v}$, singular values of $A$, and matrix norms. We use the following principles:\n\n- Energy and smoothness: In multigrid, a smoother such as weighted Jacobi damps error components with large $A$-energy, while leaving low-energy components relatively untouched. The $A$-energy of a vector $v$ is $v^\\top A v$ for symmetric positive definite $A$. For general $A$, the symmetric part $A_s = \\dfrac{1}{2}(A + A^\\top)$ makes $\\lambda(v) = \\dfrac{v^\\top A_s v}{v^\\top v}$ real-valued and interpretable as an energy density. Therefore, a small Rayleigh quotient relative to a representative scale of $A$ indicates a component that smoothers cannot remove, implying that the coarse space must represent it.\n\n- Near-nullspace and constants: For elliptic operators with Neumann boundary conditions or approximately divergence-free constraints, the constant vector often lies in or near the nullspace. If the residual has a large projection onto the constant vector, coarse-grid interpolation must include this mode, otherwise AMG stagnates.\n\n- Matrix structure and classical AMG assumptions: Classical AMG coarsening and interpolation assume an $M$-matrix-like structure (diagonally dominant with nonpositive off-diagonals) and symmetry or mild nonsymmetry. Large nonsymmetry or many positive off-diagonal entries signal that these assumptions fail, degrading both strength-of-connection measures and interpolation quality.\n\n- Conditioning and singularity: The $2$-norm condition number $\\kappa_2(A)$ quantifies sensitivity; a large $\\kappa_2(A)$ indicates severe scaling disparities that hinder convergence. A tiny smallest singular value $\\sigma_{\\min}(A)$ indicates a nearly singular operator; in the singular case, exact nullspace components cannot be reduced by iterative methods unless compatible corrections are applied.\n\n- Smoother viability: Diagonal-based smoothers such as damped Jacobi require diagonals that are well-scaled. If $\\min_i |a_{ii}|$ is many orders of magnitude smaller than $\\max_i |a_{ii}|$, the iteration matrix amplifies certain components, leading to instability.\n\n- Connectivity: Effective coarse-grid correction presumes that off-diagonal couplings convey information across the graph of $A$. If $A$ is nearly diagonal, strength-of-connection is weak, and interpolation cannot propagate corrections well.\n\nTranslating these principles into computable indicators yields:\n\n1) Low-energy residual: We compute $A_s = \\dfrac{1}{2}(A + A^\\top)$, then $\\lambda_r = \\dfrac{r^\\top A_s r}{r^\\top r}$ for $r \\ne 0$. As a scale for $A$, we use $d_{\\mathrm{avg}} = \\dfrac{1}{n}\\sum_{i=1}^n |a_{ii}|$, which has the unit of $A$’s diagonal. If $\\lambda_r \\le \\tau_E \\, d_{\\mathrm{avg}}$ with $\\tau_E = 0.1$, we flag code $1$. This criterion identifies residuals with low $A$-energy density, which smoothers do not reduce.\n\n2) Constant-mode dominance: For $u = \\mathbf{1}$, the orthogonal projection coefficient is $\\alpha = \\dfrac{u^\\top r}{u^\\top u} = \\dfrac{u^\\top r}{n}$. The norm of the constant component is $\\|\\alpha u\\|_2 = \\dfrac{|u^\\top r|}{\\sqrt{n}}$, while $\\|r\\|_2$ is the total residual norm. The fraction $c_{\\mathrm{frac}} = \\dfrac{|u^\\top r|}{\\sqrt{n}\\|r\\|_2}$ quantifies dominance. If $c_{\\mathrm{frac}} \\ge 0.7$, we flag code $2$, indicating that coarse correction must include the constant mode.\n\n3) Nonsymmetry and non-$M$-matrix structure: We compute $s = \\dfrac{\\|A - A^\\top\\|_F}{\\|A\\|_F}$, which is scale-invariant and detects nonsymmetry. We also compute the fraction $p$ of positive off-diagonals. If $s \\ge 0.1$ or $p \\ge 0.5$, we flag code $3$. Either condition suggests that classical AMG assumptions are violated, challenging standard coarsening and interpolation.\n\n4) Ill-conditioning: Using singular values $\\{\\sigma_i\\}$, we estimate $\\kappa_2(A) = \\dfrac{\\sigma_{\\max}}{\\sigma_{\\min}}$. If $\\kappa_2(A) \\ge 10^8$, we flag code $4$, reflecting that vastly different scales degrade smoother and coarse-grid effectiveness.\n\n5) Near-singularity: If $\\sigma_{\\min}(A) \\le 10^{-14}$, we flag code $5$. For singular operators (such as Neumann Laplacians), $\\sigma_{\\min} = 0$, so this indicator captures an inherent obstacle: nullspace components cannot be eliminated by relaxation.\n\n6) Smoother breakdown via extreme diagonal scaling: For diagonal-based smoothers, tiny diagonal entries are problematic. We compute $d_{\\min} = \\min_i |a_{ii}|$ and $d_{\\max} = \\max_i |a_{ii}|$ and flag code $6$ if $\\dfrac{d_{\\min}}{d_{\\max}}  10^{-8}$.\n\n7) Weak connectivity: We compute $\\rho_{\\mathrm{od}} = \\dfrac{\\sum_{i \\ne j} |a_{ij}|}{\\sum_i |a_{ii}|}$ when the denominator is nonzero. If $\\rho_{\\mathrm{od}} \\le 0.1$, we flag code $7$, indicating that $A$ is nearly diagonal.\n\nThese thresholds are chosen to be simple, scale-aware, and to separate the provided test cases meaningfully.\n\nNow we justify the expected outcomes for the test suite:\n\n- Case A (Dirichlet Laplacian, $n = 8$, $r_i = \\sin\\big(\\dfrac{\\pi i}{n+1}\\big)$): This $r$ is the lowest-frequency eigenmode with a small eigenvalue of the symmetric operator, hence a small Rayleigh quotient relative to the diagonal scale. The low-energy indicator should trigger (code $1$). Constant-mode dominance (code $2$) does not trigger because $r$ has near-zero mean. The matrix is symmetric, well-connected, and reasonably conditioned, so no other indicators trigger. Expected codes: $[1]$.\n\n- Case B (upper bidiagonal perturbation): The matrix is strongly nonsymmetric; the Frobenius-norm nonsymmetry $s$ is large. Positive off-diagonals are present, but not a majority; nonsymmetry suffices to trigger code $3$. The matrix is not excessively ill-conditioned, and connectivity is nontrivial, so other indicators remain off. Expected codes: $[3]$.\n\n- Case C (diagonal SPD, highly ill-conditioned): The singular values are precisely the diagonal entries, spanning $10^{-6}$ to $10^{6}$, giving $\\kappa_2(A) = 10^{12} \\ge 10^8$, so code $4$ triggers. Since $A$ is diagonal, $\\rho_{\\mathrm{od}} = 0 \\le 0.1$, so code $7$ triggers. The smallest singular value $10^{-6}  10^{-14}$ does not trigger near-singularity. Expected codes: $[4, 7]$.\n\n- Case D (diagonal with one extremely small diagonal entry): The ratio $\\dfrac{d_{\\min}}{d_{\\max}} = 10^{-12}  10^{-8}$ triggers code $6$. The matrix is diagonal, so code $7$ triggers. The condition number is $10^{12} \\ge 10^8$, so code $4$ triggers. It is not nearly singular by the $\\sigma_{\\min}$ threshold used. Expected codes: $[4, 6, 7]$.\n\n- Case E (Neumann Laplacian, symmetric positive semidefinite): The matrix has a zero singular value, so codes $4$ and $5$ trigger (ill-conditioning via infinite condition number and near-singularity). The constant vector lies in the nullspace; with $r$ equal to the constant vector, the constant-mode dominance triggers code $2$. The Rayleigh quotient for the constant vector is zero, which is below the threshold, so code $1$ triggers. Expected codes: $[1, 2, 4, 5]$.\n\nThe program assembles these results into the required single-line output string in the order A, B, C, D, E, each as a bracketed list of integers with no spaces.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef diagnose_amg_failure(A: np.ndarray, r: np.ndarray):\n    n = A.shape[0]\n    codes = set()\n\n    # Thresholds\n    tau_energy = 0.1          # for low-energy Rayleigh quotient relative to avg diagonal\n    tau_cfrac = 0.7           # constant-mode dominance\n    tau_nonsym = 0.1          # nonsymmetry threshold (Frobenius)\n    tau_pos_off = 0.5         # fraction of positive off-diagonals\n    tau_cond = 1e8            # ill-conditioning threshold\n    tau_sigmin = 1e-14        # near-singularity threshold\n    tau_diag_extreme = 1e-8   # extreme diagonal scaling\n    tau_od_ratio = 0.1        # weak connectivity / nearly diagonal\n\n    # Helper quantities\n    # Symmetric part for energy computation\n    As = 0.5 * (A + A.T)\n\n    # Average diagonal magnitude\n    diag = np.diag(A).astype(float)\n    abs_diag = np.abs(diag)\n    d_avg = float(np.mean(abs_diag)) if abs_diag.size > 0 else 0.0\n\n    # 1) Low-energy residual\n    rnorm2 = float(r @ r)\n    if rnorm2 > 0 and d_avg > 0:\n        lam = float(r @ (As @ r)) / rnorm2\n        if lam = tau_energy * d_avg:\n            codes.add(1)\n\n    # 2) Constant-mode dominance\n    if rnorm2 > 0:\n        u = np.ones_like(r)\n        cfrac = abs(float(u @ r)) / (np.sqrt(n) * np.sqrt(rnorm2))\n        if cfrac >= tau_cfrac:\n            codes.add(2)\n\n    # 3) Nonsymmetry or non-M-matrix structure\n    normA_F = float(np.linalg.norm(A, ord='fro'))\n    nonsym = 0.0\n    if normA_F > 0:\n        nonsym = float(np.linalg.norm(A - A.T, ord='fro')) / normA_F\n    # Fraction of positive off-diagonal entries\n    off_pos = 0\n    off_total = 0\n    for i in range(n):\n        for j in range(n):\n            if i == j:\n                continue\n            off_total += 1\n            if A[i, j] > 0:\n                off_pos += 1\n    p_pos_off = (off_pos / off_total) if off_total > 0 else 0.0\n    if nonsym >= tau_nonsym or p_pos_off >= tau_pos_off:\n        codes.add(3)\n\n    # 4) Ill-conditioning and 5) Near-singularity via singular values\n    try:\n        svals = np.linalg.svd(A, compute_uv=False)\n        svals = np.array(svals, dtype=float)\n        sigma_min = float(np.min(svals)) if svals.size > 0 else 0.0\n        sigma_max = float(np.max(svals)) if svals.size > 0 else 0.0\n        if sigma_min = tau_sigmin:\n            codes.add(5)\n        # condition number\n        if sigma_min == 0.0:\n            kappa = np.inf\n        else:\n            kappa = sigma_max / sigma_min if sigma_min > 0 else np.inf\n        if not np.isfinite(kappa) or kappa >= tau_cond:\n            codes.add(4)\n    except np.linalg.LinAlgError:\n        # If SVD fails, we conservatively flag ill-conditioning\n        codes.add(4)\n\n    # 6) Smoother breakdown due to extreme diagonal scaling\n    if abs_diag.size > 0:\n        dmin = float(np.min(abs_diag))\n        dmax = float(np.max(abs_diag))\n        if dmax > 0 and (dmin / dmax)  tau_diag_extreme:\n            codes.add(6)\n\n    # 7) Weak connectivity / nearly diagonal operator\n    sum_abs_diag = float(np.sum(np.abs(np.diag(A))))\n    sum_abs_off = float(np.sum(np.abs(A)) - sum_abs_diag)\n    if sum_abs_diag > 0:\n        od_ratio = sum_abs_off / sum_abs_diag\n        if od_ratio = tau_od_ratio:\n            codes.add(7)\n    else:\n        # If diagonal sum is zero but there are off-diagonals, we do not flag 7.\n        # If both are zero (zero matrix), it's singular; already covered by (5).\n        pass\n\n    return sorted(codes)\n\ndef build_test_cases():\n    cases = []\n\n    # Case A: 1D Dirichlet Laplacian, n=8\n    n1 = 8\n    A1 = np.zeros((n1, n1), dtype=float)\n    for i in range(n1):\n        A1[i, i] = 2.0\n        if i + 1  n1:\n            A1[i, i+1] = -1.0\n            A1[i+1, i] = -1.0\n    r1 = np.sin(np.pi * (np.arange(1, n1 + 1)) / (n1 + 1)).astype(float)\n    cases.append((A1, r1))\n\n    # Case B: Upper bidiagonal perturbation, n=6\n    n2 = 6\n    A2 = np.zeros((n2, n2), dtype=float)\n    for i in range(n2):\n        A2[i, i] = 2.0\n        if i + 1  n2:\n            A2[i, i+1] = 1.0\n    r2 = np.array([1, -1, 2, -2, 1, -1], dtype=float)\n    cases.append((A2, r2))\n\n    # Case C: Diagonal SPD ill-conditioned, n=5\n    A3 = np.diag(np.array([1e-6, 1e-3, 1.0, 1e3, 1e6], dtype=float))\n    r3 = np.array([1, 2, 3, 4, 5], dtype=float)\n    cases.append((A3, r3))\n\n    # Case D: Diagonal with one tiny diagonal entry, n=5\n    A4 = np.diag(np.array([1.0, 1.0, 1e-12, 1.0, 1.0], dtype=float))\n    r4 = np.array([1, 0, 1, 0, 1], dtype=float)\n    cases.append((A4, r4))\n\n    # Case E: 1D Neumann Laplacian, n=4\n    n5 = 4\n    A5 = np.zeros((n5, n5), dtype=float)\n    for i in range(n5):\n        if i == 0 or i == n5 - 1:\n            A5[i, i] = 1.0\n        else:\n            A5[i, i] = 2.0\n        if i + 1  n5:\n            A5[i, i+1] = -1.0\n            A5[i+1, i] = -1.0\n    r5 = np.ones(n5, dtype=float)\n    cases.append((A5, r5))\n\n    return cases\n\ndef solve():\n    test_cases = build_test_cases()\n    all_results = []\n    for A, r in test_cases:\n        codes = diagnose_amg_failure(A, r)\n        all_results.append(codes)\n\n    # Format output as a single line string with no spaces, e.g., \"[[1],[3],...]\"\n    def fmt_list(lst):\n        return \"[\" + \",\".join(str(int(x)) for x in lst) + \"]\"\n    out = \"[\" + \",\".join(fmt_list(lst) for lst in all_results) + \"]\"\n    print(out)\n\nif __name__ == \"__main__\":\n    solve()\n```", "id": "3204416"}]}