{"hands_on_practices": [{"introduction": "The two-dimensional Poisson equation serves as a fundamental model for many physical phenomena. This first practice [@problem_id:3228788] walks you through the cornerstone of the finite difference method: deriving the classic five-point stencil from Taylor series expansions. You will then implement a matrix-free iterative solver and perform a convergence study to numerically verify the method's second-order accuracy, a crucial step in validating any scientific computing code.", "problem": "Consider the two-dimensional Poisson equation on the unit square domain $\\Omega = (0,1) \\times (0,1)$ with Dirichlet boundary condition,\n$$\n-\\Delta u(x,y) = f(x,y) \\quad \\text{in } \\Omega, \n\\qquad\nu(x,y) = g(x,y) \\quad \\text{on } \\partial\\Omega.\n$$\nStart from the definition of the Laplace operator in two dimensions and the classical central difference approximation for second derivatives derived from Taylor expansions. Using only these fundamentals, derive the standard five-point finite difference method on a uniform grid of mesh spacing $h = 1/N$ with interior nodes $(x_i,y_j) = (ih,jh)$ for $i,j \\in \\{1,\\dots,N-1\\}$:\n$$\n\\frac{4u_{i,j} - u_{i-1,j} - u_{i+1,j} - u_{i,j-1} - u_{i,j+1}}{h^2} = f_{i,j},\n$$\nwhere boundary values $u_{i,j}$ on $\\partial\\Omega$ are prescribed by $g(x,y)$. Explain why, under the assumption $u \\in C^4(\\overline{\\Omega})$, the local truncation error is $\\mathcal{O}(h^2)$ and how the discrete maximum principle leads to a global error bound $\\lVert u - u_h \\rVert_\\infty = \\mathcal{O}(h^2)$.\n\nNext, implement a solver for the discrete linear system that arises from this scheme using the Conjugate Gradient iteration applied to the symmetric positive definite matrix associated with the five-point stencil. The solver must be matrix-free: apply the discrete operator to grid functions directly via the stencil, and account for Dirichlet boundary data by adding known boundary contributions to the right-hand side. Use a stopping criterion based on the reduction of the residual norm to a user-specified tolerance relative to the right-hand side norm.\n\nYou will validate error estimates and observed convergence rates for two exact solutions. In each case, set $g(x,y) = u(x,y)$ on $\\partial \\Omega$ and set $f(x,y) = -\\Delta u(x,y)$ in $\\Omega$. For each mesh size, compute the discrete solution $u_h$, embed it into the full grid including boundary nodes, and compute the maximum-norm error\n$$\nE(h) = \\max_{0 \\le i,j \\le N} \\left| u(x_i,y_j) - u_h(x_i,y_j) \\right|.\n$$\nGiven a list of mesh spacings $\\{h_k\\}$ with corresponding errors $\\{E(h_k)\\}$, estimate the Experimental Order of Convergence (EOC) as the least-squares slope $p$ in the relation $\\log E(h) \\approx \\log C + p \\log h$.\n\nUse the following two exact solutions:\n- Smooth solution: $u_s(x,y) = \\sin(\\pi x)\\sin(\\pi y)$, for which $f_s(x,y) = 2\\pi^2 \\sin(\\pi x)\\sin(\\pi y)$ and $g_s = u_s$.\n- Singular solution: $u_{sg}(x,y) = r^\\alpha$ with $\\alpha = 3/2$ and $r = \\sqrt{x^2 + y^2}$, for which for $r>0$ one has $\\Delta u_{sg}(x,y) = \\alpha^2 r^{\\alpha - 2}$, hence $f_{sg}(x,y) = -\\alpha^2 r^{\\alpha - 2}$ and $g_{sg} = u_{sg}$. Define $f_{sg}(0,0)$ by continuity if needed; note that $(0,0)$ is a boundary point and therefore not an interior node.\n\nDesign a program that performs the following test suite and reports the EOC for each case:\n- Case A (happy path, smooth and well-resolved): use $N \\in \\{8,16,32,64\\}$ with $u_s$.\n- Case B (reduced regularity, singular near a boundary corner): use $N \\in \\{8,16,32,64\\}$ with $u_{sg}$ and $\\alpha = 3/2$.\n- Case C (boundary coarse resolution edge case): use $N \\in \\{4,8,16\\}$ with $u_s$.\n\nYour program must implement the five-point method, the matrix-free Conjugate Gradient solver, the error computation in the maximum norm, and the least-squares EOC estimation. For each case, perform a linear regression of $\\log E(h)$ against $\\log h$ and report the estimated slope $p$.\n\nNo physical units are involved. All angles, where present, are in radians. The final output must be a single line containing a comma-separated list of the three EOC estimates for the cases A, B, and C, rounded to three decimal places and enclosed in square brackets, in the order [A,B,C]. For example, if the three estimated orders are $p_A$, $p_B$, and $p_C$, your program should output a single line of the form\n$[p_A,p_B,p_C]$.", "solution": "The problem is valid as it represents a well-posed, standard exercise in the numerical analysis of partial differential equations, grounded in established mathematical principles. It is self-contained, objective, and its requirements are algorithmically formalizable.\n\nThe task involves deriving the five-point finite difference scheme for the Poisson equation, analyzing its error, and implementing a matrix-free Conjugate Gradient solver to compute the experimental order of convergence (EOC) for two different test cases.\n\n### Part 1: Derivation of the Five-Point Stencil\n\nWe start with the two-dimensional Poisson equation on the unit square $\\Omega = (0,1) \\times (0,1)$:\n$$\n-\\Delta u(x,y) = f(x,y)\n$$\nwhere $\\Delta u = \\frac{\\partial^2 u}{\\partial x^2} + \\frac{\\partial^2 u}{\\partial y^2}$ is the Laplace operator. The domain is discretized using a uniform grid with mesh spacing $h=1/N$ in both directions. The grid points are $(x_i, y_j) = (ih, jh)$ for integers $i,j \\in \\{0, 1, \\dots, N\\}$. We seek an approximation $u_{i,j} \\approx u(x_i, y_j)$.\n\nThe core of the finite difference method is to approximate derivatives using Taylor series expansions. Consider the expansion of a sufficiently smooth function $u(x,y)$ around a point $(x_i, y_j)$:\n$$\nu(x_i \\pm h, y_j) = u(x_i, y_j) \\pm h \\frac{\\partial u}{\\partial x}(x_i, y_j) + \\frac{h^2}{2} \\frac{\\partial^2 u}{\\partial x^2}(x_i, y_j) \\pm \\frac{h^3}{6} \\frac{\\partial^3 u}{\\partial x^3}(x_i, y_j) + \\frac{h^4}{24} \\frac{\\partial^4 u}{\\partial x^4}(x_i, y_j) + \\mathcal{O}(h^5)\n$$\nSumming the expansions for $u(x_i+h, y_j)$ and $u(x_i-h, y_j)$:\n$$\nu(x_{i+1}, y_j) + u(x_{i-1}, y_j) = 2u(x_i, y_j) + h^2 \\frac{\\partial^2 u}{\\partial x^2}(x_i, y_j) + \\frac{h^4}{12} \\frac{\\partial^4 u}{\\partial x^4}(x_i, y_j) + \\mathcal{O}(h^6)\n$$\nRearranging to solve for the second partial derivative with respect to $x$ gives the second-order central difference approximation:\n$$\n\\frac{\\partial^2 u}{\\partial x^2}(x_i, y_j) = \\frac{u_{i+1,j} - 2u_{i,j} + u_{i-1,j}}{h^2} - \\frac{h^2}{12} \\frac{\\partial^4 u}{\\partial x^4}(x_i, y_j) + \\mathcal{O}(h^4)\n$$\nBy an identical argument for the $y$ direction:\n$$\n\\frac{\\partial^2 u}{\\partial y^2}(x_i, y_j) = \\frac{u_{i,j+1} - 2u_{i,j} + u_{i,j-1}}{h^2} - \\frac{h^2}{12} \\frac{\\partial^4 u}{\\partial y^4}(x_i, y_j) + \\mathcal{O}(h^4)\n$$\nSumming these two expressions provides an approximation for the Laplacian:\n$$\n\\Delta u(x_i, y_j) = \\frac{u_{i+1,j} + u_{i-1,j} + u_{i,j+1} + u_{i,j-1} - 4u_{i,j}}{h^2} - \\frac{h^2}{12} \\left( \\frac{\\partial^4 u}{\\partial x^4} + \\frac{\\partial^4 u}{\\partial y^4} \\right)(x_i, y_j) + \\mathcal{O}(h^4)\n$$\nWe define the discrete Laplacian operator, denoted $\\Delta_h$, as:\n$$\n\\Delta_h u_{i,j} = \\frac{u_{i+1,j} + u_{i-1,j} + u_{i,j+1} + u_{i,j-1} - 4u_{i,j}}{h^2}\n$$\nSubstituting this into the Poisson equation, $-\\Delta u(x_i, y_j) = f(x_i, y_j)$, and ignoring the higher-order terms leads to the five-point finite difference scheme for interior nodes $(i,j)$ where $i,j \\in \\{1, \\dots, N-1\\}$:\n$$\n-\\Delta_h u_{i,j} = \\frac{4u_{i,j} - u_{i-1,j} - u_{i+1,j} - u_{i,j-1} - u_{i,j+1}}{h^2} = f_{i,j}\n$$\nwhere $f_{i,j} = f(x_i, y_j)$. This is the desired formula.\n\n### Part 2: Local Truncation Error and Global Error\n\nThe local truncation error (LTE), $\\tau_{i,j}$, is the residual obtained when the exact solution $u(x,y)$ is inserted into the discrete equation. Let $L_h = -\\Delta_h$. The discrete system is $L_h u_h = f$, where $u_h$ is the numerical solution vector. Applying the operator to the exact solution $u$:\n$$\n\\tau_{i,j} = L_h u(x_i, y_j) - f(x_i, y_j) = L_h u(x_i, y_j) - (-\\Delta u(x_i, y_j))\n$$\nFrom the Taylor expansion analysis above, we have:\n$$\n\\Delta_h u(x_i, y_j) = \\Delta u(x_i, y_j) + \\frac{h^2}{12} \\left( \\frac{\\partial^4 u}{\\partial x^4} + \\frac{\\partial^4 u}{\\partial y^4} \\right)(x_i, y_j) + \\mathcal{O}(h^4)\n$$\nTherefore, the LTE is:\n$$\n\\tau_{i,j} = - \\left( \\Delta u(x_i, y_j) + \\frac{h^2}{12} \\left( \\frac{\\partial^4 u}{\\partial x^4} + \\frac{\\partial^4 u}{\\partial y^4} \\right) + \\mathcal{O}(h^4) \\right) + \\Delta u(x_i, y_j)\n$$\n$$\n\\tau_{i,j} = - \\frac{h^2}{12} \\left( \\frac{\\partial^4 u}{\\partial x^4}(x_i,y_j) + \\frac{\\partial^4 u}{\\partial y^4}(x_i,y_j) \\right) + \\mathcal{O}(h^4)\n$$\nIf the exact solution $u$ is in $C^4(\\overline{\\Omega})$, meaning its fourth-order partial derivatives are continuous and thus bounded on the closed domain $\\Omega$, then there exists a constant $M$ such that $|\\frac{\\partial^4 u}{\\partial x^4}| \\le M$ and $|\\frac{\\partial^4 u}{\\partial y^4}| \\le M$. Consequently, the maximum norm of the LTE is bounded by:\n$$\n\\lVert \\tau \\rVert_\\infty = \\max_{i,j} |\\tau_{i,j}| \\le \\frac{h^2}{12} (M+M) + \\mathcal{O}(h^4) = \\mathcal{O}(h^2)\n$$\nThe scheme is consistent with order $2$.\n\nThe global error is defined as $e_{i,j} = u(x_i, y_j) - u_{h, i,j}$, where $u_h$ is the solution of the discrete system. Applying the discrete operator $L_h$ to the error:\n$$\nL_h e_{i,j} = L_h (u_{i,j} - u_{h, i,j}) = L_h u_{i,j} - L_h u_{h, i,j}\n$$\nBy definition, $L_h u_{h, i,j} = f_{i,j}$ and $L_h u_{i,j} = f_{i,j} + \\tau_{i,j}$. Subtracting these, we obtain the error equation:\n$$\nL_h e_{i,j} = \\tau_{i,j}\n$$\nfor all interior nodes. On the boundary $\\partial\\Omega$, the error is zero, $e_{i,j} = 0$, since both the exact solution and the numerical solution take the prescribed boundary values $g(x,y)$.\n\nThe connection between the LTE and the global error is made through the stability of the discrete operator $L_h$. The operator $L_h$ satisfies a discrete maximum principle (DMP). For an operator like $L_h$, the DMP states that if $L_h v_{i,j} \\ge 0$ at all interior nodes, then the maximum value of $v$ over the entire grid must occur on the boundary. A key consequence of the DMP is the stability of its inverse in the maximum norm. That is, there exists a constant $C > 0$, independent of $h$, such that for any grid function $z$, the solution $v$ to $L_h v = z$ with zero boundary conditions satisfies:\n$$\n\\lVert v \\rVert_\\infty \\le C \\lVert z \\rVert_\\infty\n$$\nThis is expressed as $\\lVert L_h^{-1} \\rVert_\\infty \\le C$. Applying this stability estimate to the error equation $e = L_h^{-1} \\tau$:\n$$\n\\lVert e \\rVert_\\infty = \\lVert L_h^{-1} \\tau \\rVert_\\infty \\le \\lVert L_h^{-1} \\rVert_\\infty \\lVert \\tau \\rVert_\\infty \\le C \\lVert \\tau \\rVert_\\infty\n$$\nSince we have shown that $\\lVert \\tau \\rVert_\\infty = \\mathcal{O}(h^2)$, the global error in the maximum norm is also second-order accurate:\n$$\n\\lVert u - u_h \\rVert_\\infty = \\lVert e \\rVert_\\infty = \\mathcal{O}(h^2)\n$$\nThis establishes that, for a sufficiently smooth solution ($u \\in C^4(\\overline{\\Omega})$), the five-point scheme converges globally at a rate of $2$.\n\n### Part 3: Algorithmic Design\n\nThe implementation will consist of a matrix-free Conjugate Gradient (CG) solver. The linear system $A u_h = b$ must be constructed, where $A$ corresponds to the discrete operator $L_h$ on the $(N-1)^2$ interior nodes.\n\n**System Construction:** The vector $u_h$ contains the unknown values at interior nodes. The matrix $A$ represents the five-point stencil. The right-hand side vector $b$ combines the source term $f(x,y)$ and the contributions from the known Dirichlet boundary values $g(x,y)$. For an interior node $(x_i,y_j)$:\n$$\nb_{i,j} = f(x_i, y_j) + \\frac{1}{h^2} \\left[ \\delta_{i,1}g(x_0,y_j) + \\delta_{i,N-1}g(x_N,y_j) + \\delta_{j,1}g(x_i,y_0) + \\delta_{j,N-1}g(x_i,y_N) \\right]\n$$\nwhere $\\delta_{k,l}$ is the Kronecker delta. This formulation moves all known boundary terms to the right side of the equation.\n\n**Matrix-Free CG:** The CG algorithm iteratively solves a symmetric positive-definite system. The matrix for the five-point stencil has this property. The key operation in CG is the matrix-vector product $A\\vec{p}$. In a matrix-free approach, we do not assemble the $(N-1)^2 \\times (N-1)^2$ matrix $A$. Instead, we implement a function that computes the action of the operator $L_h$ on a grid function $\\vec{p}$ (representing the search direction). This is done by applying the five-point stencil at each interior node.\n\n**EOC Estimation:** The EOC $p$ is estimated from errors $E(h_k)$ at a sequence of mesh sizes $h_k$ via the model $\\log E(h) \\approx \\log C + p \\log h$. This is a linear regression problem for the pairs $(\\log h_k, \\log E_k)$. The slope $p$ is calculated using the standard least-squares formula.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to run the test suite and compute EOC for all cases.\n    \"\"\"\n\n    # --- Test Case Definitions ---\n\n    # Case 1: Smooth solution u_s(x,y) = sin(pi*x)sin(pi*y)\n    u_s = lambda x, y: np.sin(np.pi * x) * np.sin(np.pi * y)\n    f_s = lambda x, y: 2 * np.pi**2 * np.sin(np.pi * x) * np.sin(np.pi * y)\n    \n    # Case 2: Singular solution u_sg(x,y) = r^(3/2)\n    def u_sg(x, y):\n        r = np.sqrt(x**2 + y**2)\n        # Handle r=0 case to avoid 0**negative power in f_sg\n        return np.power(r, 1.5)\n\n    def f_sg(x, y):\n        # f is evaluated only at interior points, so r > 0.\n        r = np.sqrt(x**2 + y**2)\n        alpha = 1.5\n        return -alpha**2 * np.power(r, alpha - 2)\n\n    # --- Test Suite ---\n    test_cases = [\n        # Case A: Smooth solution, standard refinement\n        {'name': 'A', 'Ns': [8, 16, 32, 64], 'u_func': u_s, 'f_func': f_s},\n        # Case B: Singular solution\n        {'name': 'B', 'Ns': [8, 16, 32, 64], 'u_func': u_sg, 'f_func': f_sg},\n        # Case C: Smooth solution, coarse grids\n        {'name': 'C', 'Ns': [4, 8, 16], 'u_func': u_s, 'f_func': f_s},\n    ]\n\n    eoc_results = []\n\n    for case in test_cases:\n        h_values = []\n        error_values = []\n\n        for N in case['Ns']:\n            h = 1.0 / N\n            u_func = case['u_func']\n            f_func = case['f_func']\n            g_func = u_func # Boundary condition is the exact solution\n\n            # 1. Set up grid and coordinates\n            # Grid for interior points (1..N-1)\n            int_coords = np.linspace(h, 1.0 - h, N - 1)\n            X_int, Y_int = np.meshgrid(int_coords, int_coords, indexing='ij')\n\n            # Full grid for error calculation (0..N)\n            full_coords = np.linspace(0, 1.0, N + 1)\n            X_full, Y_full = np.meshgrid(full_coords, full_coords, indexing='ij')\n\n            # 2. Construct the right-hand side (RHS) vector 'b'\n            b = f_func(X_int, Y_int)\n            h2_inv = 1.0 / (h**2)\n            \n            # Add boundary contributions\n            # j = 1, ..., N-1\n            b[0, :] += h2_inv * g_func(0, int_coords)  # Left boundary i=0\n            b[-1, :] += h2_inv * g_func(1, int_coords) # Right boundary i=N\n            # i = 1, ..., N-1\n            b[:, 0] += h2_inv * g_func(int_coords, 0)  # Bottom boundary j=0\n            b[:, -1] += h2_inv * g_func(int_coords, 1) # Top boundary j=N\n\n            # 3. Solve the linear system using matrix-free Conjugate Gradient\n            u_h_interior = cg_solver(b, h, tol=1e-12)\n\n            # 4. Construct full solution grid and compute error\n            u_h_full = np.zeros((N + 1, N + 1))\n            # Set boundary values\n            u_h_full[0, :] = g_func(0, full_coords)\n            u_h_full[N, :] = g_func(1, full_coords)\n            u_h_full[:, 0] = g_func(full_coords, 0)\n            u_h_full[:, N] = g_func(full_coords, 1)\n            # Fill interior\n            u_h_full[1:N, 1:N] = u_h_interior\n\n            u_exact_full = u_func(X_full, Y_full)\n            \n            error = np.max(np.abs(u_exact_full - u_h_full))\n            \n            h_values.append(h)\n            error_values.append(error)\n\n        # 5. Compute EOC using least-squares fit\n        log_h = np.log(np.array(h_values))\n        log_e = np.log(np.array(error_values))\n        \n        # Fit a line (degree 1 polynomial) to (log_h, log_e)\n        # The slope is the first coefficient returned by polyfit.\n        p_eoc = np.polyfit(log_h, log_e, 1)[0]\n        eoc_results.append(p_eoc)\n    \n    # Final print statement\n    print(f\"[{','.join(f'{p:.3f}' for p in eoc_results)}]\")\n\ndef apply_A_matvec(v, h):\n    \"\"\"\n    Computes the matrix-free matrix-vector product for the 5-point stencil.\n    Assumes zero boundary conditions for the input vector v.\n    \n    Args:\n        v (np.ndarray): A 2D numpy array of size (N-1)x(N-1) representing the vector.\n        h (float): The mesh spacing.\n    \n    Returns:\n        np.ndarray: The result of Av, a 2D array of size (N-1)x(N-1).\n    \"\"\"\n    if v.shape[0] == 0:\n        return np.array([])\n    N_minus_1 = v.shape[0]\n    Av = np.zeros_like(v)\n    h2_inv = 1.0 / (h**2)\n    \n    # Pad with zeros for boundary conditions\n    v_padded = np.pad(v, pad_width=1, mode='constant', constant_values=0)\n    \n    for i in range(N_minus_1):\n        for j in range(N_minus_1):\n            # Convert to padded indices\n            ip, jp = i + 1, j + 1\n            center = v_padded[ip, jp]\n            left = v_padded[ip - 1, jp]\n            right = v_padded[ip + 1, jp]\n            down = v_padded[ip, jp - 1]\n            up = v_padded[ip, jp + 1]\n            \n            Av[i, j] = h2_inv * (4 * center - left - right - down - up)\n            \n    return Av\n\ndef cg_solver(b, h, tol=1e-10, max_iter=1000):\n    \"\"\"\n    Solves Ax=b using matrix-free Conjugate Gradient method.\n    \n    Args:\n        b (np.ndarray): The right-hand side vector as a 2D (N-1)x(N-1) array.\n        h (float): The mesh spacing.\n        tol (float): The relative tolerance for the residual norm.\n        max_iter (int): Maximum number of iterations.\n    \n    Returns:\n        np.ndarray: The solution vector x as a 2D (N-1)x(N-1) array.\n    \"\"\"\n    if b.size == 0:\n        return np.array([])\n    x = np.zeros_like(b)\n    r = b - apply_A_matvec(x, h)\n    p = r.copy()\n    rs_old = np.sum(r**2)\n    \n    b_norm = np.sqrt(np.sum(b**2))\n    if b_norm == 0:\n        return x\n\n    for k in range(max_iter):\n        Ap = apply_A_matvec(p, h)\n        pAp = np.sum(p * Ap)\n\n        if pAp == 0:\n            break\n            \n        alpha = rs_old / pAp\n        x += alpha * p\n        r -= alpha * Ap\n        \n        rs_new = np.sum(r**2)\n        \n        if np.sqrt(rs_new)  tol * b_norm:\n            break\n            \n        p = r + (rs_new / rs_old) * p\n        rs_old = rs_new\n        \n    return x\n\nif __name__ == \"__main__\":\n    solve()\n```", "id": "3228788"}, {"introduction": "Real-world physical systems are rarely homogeneous. This practice [@problem_id:3228831] extends our analysis to elliptic equations with variable coefficients, which model phenomena like heat flow through composite materials. You will move beyond simple derivative replacement to a more physical control-volume approach, learning how to correctly handle discontinuous coefficients at interfaces using the harmonic mean to ensure flux conservation.", "problem": "Implement a complete, runnable program that constructs and solves linear systems arising from a finite difference discretization of the elliptic partial differential equation\n$$\n\\nabla \\cdot \\left(\\kappa(x,y)\\,\\nabla u(x,y)\\right) \\;=\\; f(x,y)\n$$\non the unit square domain $[0,1]\\times[0,1]$ with homogeneous Dirichlet boundary conditions $u(x,y)=0$ on $\\partial\\Omega$. The unknown is the scalar field $u(x,y)$, the diffusion coefficient $\\kappa(x,y)$ is strictly positive and piecewise constant in a checkerboard pattern, and $f(x,y)$ is a given source term. Angles in any trigonometric expressions must be interpreted in radians.\n\nYour implementation must start from fundamental principles and core definitions:\n- The divergence theorem and conservation of flux over a control volume.\n- The definition of the gradient and divergence operators as limits of difference quotients.\n- The requirement of continuity of normal flux across interfaces, which leads to harmonic averaging of coefficients at interfaces for consistent discretization.\n\nFrom these bases, derive a consistent, second-order accurate, five-point finite difference scheme on a uniform Cartesian grid using a flux balance over each interior control volume. The discrete interface conductivity between two neighboring grid points must be the harmonic mean of the $\\kappa$ values at those two points to correctly capture discontinuities and enforce continuity of normal flux.\n\nDiscretization and implementation requirements:\n- Use $M$ interior points in each coordinate direction, so the grid spacing is $h=\\frac{1}{M+1}$ and interior nodes have indices $i=1,\\dots,M$ and $j=1,\\dots,M$ with coordinates $(x_i,y_j)=(ih,jh)$.\n- Impose homogeneous Dirichlet boundary conditions $u=0$ on all boundary nodes corresponding to $i=0$, $i=M+1$, $j=0$, or $j=M+1$.\n- Define the checkerboard diffusion coefficient at all grid nodes (including boundaries) by\n$$\n\\kappa_{i,j} =\n\\begin{cases}\nk_{\\text{low}},  \\text{if } (i+j+p) \\text{ is even} \\\\\nk_{\\text{high}},  \\text{if } (i+j+p) \\text{ is odd}\n\\end{cases}\n$$\nwhere $p\\in\\{0,1\\}$ is a phase that shifts the checkerboard pattern.\n- For each pair of neighboring nodes, use the face conductivity equal to the harmonic mean of the two nodal values. For two positive values $a$ and $b$, the harmonic mean is $\n\\displaystyle H(a,b) = \\frac{2ab}{a+b}.\n$\n- Assemble the linear system corresponding to the discrete balance of fluxes at each interior node in the form\n$\nA\\,\\mathbf{u} = \\mathbf{b},\n$\nwhere $\\mathbf{u}$ stacks the unknowns $u_{i,j}$ at interior nodes in lexicographic order and $\\mathbf{b}$ stacks the source samples $f(x_i,y_j)$. The matrix must encode flux differences with interface conductivities given by the harmonic means. The homogeneous Dirichlet boundary makes all contributions of boundary unknowns vanish because $u=0$ on $\\partial\\Omega$.\n- Solve the resulting linear system using a direct solver.\n- For each test case, report the discrete $L^2$ norm of the interior solution defined by\n$$\n\\|u\\|_{L_h^2} \\;=\\; \\left(h^2 \\sum_{i=1}^{M}\\sum_{j=1}^{M} u_{i,j}^2\\right)^{1/2}.\n$$\n\nTest suite and output:\n- Use the following four test cases. In each case, angles in $f(x,y)$ are in radians.\n    1. $M=16$, $k_{\\text{low}}=1$, $k_{\\text{high}}=5$, $p=0$, and $f(x,y)=\\sin\\!\\left(2\\pi x\\right)\\sin\\!\\left(2\\pi y\\right)$.\n    2. $M=5$, $k_{\\text{low}}=1$, $k_{\\text{high}}=10$, $p=1$, and $f(x,y)=0$ for all $(x,y)$.\n    3. $M=20$, $k_{\\text{low}}=1$, $k_{\\text{high}}=100$, $p=0$, and $f(x,y)=1$ for all $(x,y)$.\n    4. $M=1$, $k_{\\text{low}}=2$, $k_{\\text{high}}=8$, $p=0$, and $f(x,y)=\\cos\\!\\left(\\pi x\\right)\\cos\\!\\left(\\pi y\\right)$.\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, in the order of the test cases above. The entry for each test case must be the single float $\\|u\\|_{L_h^2}$ computed for that case. For example, an admissible output format is\n[r_1,r_2,r_3,r_4],\nwhere each $r_i$ is a floating-point number.\n\nNo user input is allowed; all data must be hard-coded as specified above, and the program must run to completion using only the provided test suite.", "solution": "The problem is valid. It presents a well-posed, scientifically grounded task within the field of numerical methods for partial differential equations. All necessary data, definitions, and boundary conditions are provided, and there are no internal contradictions or logical flaws.\n\nWe are tasked with solving the elliptic partial differential equation (PDE) with a variable diffusion coefficient $\\kappa(x,y)$:\n$$ \\nabla \\cdot \\left(\\kappa(x,y)\\,\\nabla u(x,y)\\right) = f(x,y) $$\non the unit square domain $\\Omega = [0,1]\\times[0,1]$, subject to homogeneous Dirichlet boundary conditions $u(x,y)=0$ for $(x,y) \\in \\partial\\Omega$.\n\nThe solution will be developed by deriving a finite difference scheme based on the principle of flux conservation over control volumes. We discretize the domain using a uniform Cartesian grid with $M$ interior points in each direction. The grid spacing is $h = \\frac{1}{M+1}$. The grid nodes are located at $(x_i, y_j) = (ih, jh)$ for $i, j \\in \\{0, 1, \\dots, M+1\\}$. The interior nodes correspond to indices $i, j \\in \\{1, \\dots, M\\}$.\n\nThe derivation begins by integrating the PDE over a square control volume $\\Omega_{i,j}$ of side length $h$ centered at each interior node $(x_i, y_j)$. The control volume is defined by $[x_i - h/2, x_i + h/2] \\times [y_j - h/2, y_j + h/2]$.\n$$ \\iint_{\\Omega_{i,j}} \\nabla \\cdot (\\kappa \\nabla u) \\,dA = \\iint_{\\Omega_{i,j}} f(x,y) \\,dA $$\nApplying the divergence theorem to the left-hand side converts the area integral into a line integral over the boundary of the control volume, $\\partial\\Omega_{i,j}$:\n$$ \\oint_{\\partial\\Omega_{i,j}} (\\kappa \\nabla u) \\cdot \\mathbf{n} \\,ds = \\iint_{\\Omega_{i,j}} f(x,y) \\,dA $$\nwhere $\\mathbf{n}$ is the outward unit normal vector to the boundary $\\partial\\Omega_{i,j}$.\n\nThe right-hand side is approximated by assuming $f$ is constant over the small control volume:\n$$ \\iint_{\\Omega_{i,j}} f(x,y) \\,dA \\approx f(x_i, y_j) \\cdot \\text{Area}(\\Omega_{i,j}) = f_{i,j} h^2 $$\n\nThe left-hand side represents the total flux out of the control volume. It is the sum of fluxes across the four faces of the square: east, west, north, and south. Let's denote the flux vector as $\\mathbf{F} = -\\kappa\\nabla u$. The net flux into the control volume is zero in the absence of a source. With a source, the net outward flux balances the integrated source. The outward flux across the east face (at $x=x_i+h/2$) is:\n$$ \\text{Flux}_{\\text{east}} = \\int_{y_j-h/2}^{y_j+h/2} (\\kappa \\frac{\\partial u}{\\partial x})\\Big|_{x=x_{i+1/2}} \\, dy $$\nWe approximate this by evaluating the integrand at the center of the face, $(x_{i+1/2}, y_j)$, and multiplying by the face length $h$:\n$$ \\text{Flux}_{\\text{east}} \\approx h \\cdot \\left(\\kappa \\frac{\\partial u}{\\partial x}\\right)\\Big|_{x_{i+1/2}, y_j} $$\nThe derivative $\\frac{\\partial u}{\\partial x}$ at the face is approximated by a second-order accurate central difference between the adjacent nodes:\n$$ \\frac{\\partial u}{\\partial x}\\Big|_{x_{i+1/2}, y_j} \\approx \\frac{u_{i+1,j} - u_{i,j}}{h} $$\nThe diffusion coefficient $\\kappa$ is discontinuous at interfaces. To maintain consistency and ensure continuity of the normal flux, $\\kappa \\frac{\\partial u}{\\partial n}$, across the interface, the effective conductivity at the interface, $\\kappa_{i+1/2, j}$, must be the harmonic mean of the nodal values $\\kappa_{i,j}$ and $\\kappa_{i+1,j}$:\n$$ \\kappa_{i+1/2, j} = H(\\kappa_{i,j}, \\kappa_{i+1,j}) = \\frac{2\\kappa_{i,j}\\kappa_{i+1,j}}{\\kappa_{i,j}+\\kappa_{i+1,j}} $$\nCombining these approximations, the outward flux through the east face is:\n$$ \\text{Flux}_{\\text{east}} \\approx h \\cdot \\kappa_{i+1/2, j} \\cdot \\frac{u_{i+1,j} - u_{i,j}}{h} = \\kappa_{i+1/2, j} (u_{i+1,j} - u_{i,j}) $$\nSimilarly, the outward flux through the west face (at $x=x_{i-1/2}$, where $\\mathbf{n}=(-1,0)$) is:\n$$ \\text{Flux}_{\\text{west}} = \\int_{y_j-h/2}^{y_j+h/2} (\\kappa \\nabla u \\cdot (-\\mathbf{e}_x))\\Big|_{x=x_{i-1/2}} \\, dy \\approx -h \\cdot \\kappa_{i-1/2, j} \\frac{u_{i,j} - u_{i-1,j}}{h} = -\\kappa_{i-1/2, j} (u_{i,j} - u_{i-1,j}) $$\nThe fluxes across the north and south faces are analogous:\n$$ \\text{Flux}_{\\text{north}} \\approx \\kappa_{i, j+1/2} (u_{i,j+1} - u_{i,j}) $$\n$$ \\text{Flux}_{\\text{south}} \\approx -\\kappa_{i, j-1/2} (u_{i,j} - u_{i,j-1}) $$\nSumming the four outward fluxes and equating to the source term gives the discrete balance equation for node $(i,j)$:\n$$ \\kappa_{i+1/2,j}(u_{i+1,j} - u_{i,j}) - \\kappa_{i-1/2,j}(u_{i,j} - u_{i-1,j}) + \\kappa_{i,j+1/2}(u_{i,j+1} - u_{i,j}) - \\kappa_{i,j-1/2}(u_{i,j} - u_{i,j-1}) = h^2 f_{i,j} $$\nRearranging the terms to group the unknown values $u$ yields the five-point stencil equation:\n$$ \\kappa_{i-1/2,j} u_{i-1,j} + \\kappa_{i+1/2,j} u_{i+1,j} + \\kappa_{i,j-1/2} u_{i,j-1} + \\kappa_{i,j+1/2} u_{i,j+1} - (\\kappa_{i-1/2,j} + \\kappa_{i+1/2,j} + \\kappa_{i,j-1/2} + \\kappa_{i,j+1/2}) u_{i,j} = h^2 f_{i,j} $$\nThis equation holds for each interior node, where $i,j \\in \\{1, \\dots, M\\}$. For nodes adjacent to the boundary, one or more neighboring $u$ values are prescribed by the Dirichlet boundary conditions. Since $u=0$ on $\\partial\\Omega$, any term involving a boundary node (e.g., $u_{0,j}$, $u_{M+1,j}$, $u_{i,0}$, $u_{i,M+1}$) is zero and drops from the equation.\n\nThis set of $M \\times M$ linear equations forms a linear system $A\\mathbf{u} = \\mathbf{b}$. The unknown vector $\\mathbf{u}$ contains the $M^2$ values of $u_{i,j}$ at the interior nodes, stacked in lexicographic order. The mapping from a 2D grid index $(i,j)$ (with $1 \\le i, j \\le M$) to a 1D vector index $k$ (with $0 \\le k \\le M^2-1$) is $k = (j-1)M + (i-1)$. The matrix $A$ is an $M^2 \\times M^2$ sparse matrix containing the coefficients from the stencil, and the vector $\\mathbf{b}$ contains the source terms $b_k = h^2 f_{i,j}$.\n\nThe constructed linear system is solved using a direct solver. The solution vector $\\mathbf{u}$ provides the discrete values of the field $u$ at the interior grid points. Finally, we compute the discrete $L^2$ norm of the solution as specified:\n$$ \\|u\\|_{L_h^2} = \\left(h^2 \\sum_{i=1}^{M}\\sum_{j=1}^{M} u_{i,j}^2\\right)^{1/2} = h \\left(\\sum_{k=0}^{M^2-1} \\mathbf{u}_k^2\\right)^{1/2} = h \\|\\mathbf{u}\\|_2 $$\nwhere $\\|\\mathbf{u}\\|_2$ is the standard Euclidean norm of the solution vector.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Constructs and solves linear systems for a 2D elliptic PDE with a\n    piecewise constant coefficient using a finite difference method.\n    \"\"\"\n\n    def solve_pde_case(M, k_low, k_high, p, f_func):\n        \"\"\"\n        Solves a single instance of the PDE problem.\n\n        Args:\n            M (int): Number of interior grid points in each direction.\n            k_low (float): Lower value for the checkerboard coefficient kappa.\n            k_high (float): Higher value for the checkerboard coefficient kappa.\n            p (int): Phase offset for the checkerboard pattern (0 or 1).\n            f_func (callable): The source function f(x, y).\n\n        Returns:\n            float: The discrete L2 norm of the solution.\n        \"\"\"\n        if M == 0:\n            return 0.0\n\n        h = 1.0 / (M + 1)\n        N_unknowns = M * M\n\n        #\n        # 1. Define the diffusion coefficient kappa on the full (M+2)x(M+2) grid\n        #\n        kappa = np.zeros((M + 2, M + 2))\n        for i in range(M + 2):\n            for j in range(M + 2):\n                if (i + j + p) % 2 == 0:\n                    kappa[i, j] = k_low\n                else:\n                    kappa[i, j] = k_high\n        \n        # Helper for harmonic mean\n        def h_mean(a, b):\n            # The problem statement guarantees kappa > 0, so no division by zero.\n            return 2.0 * a * b / (a + b)\n\n        #\n        # 2. Assemble the linear system A*u = b\n        #\n        A = np.zeros((N_unknowns, N_unknowns))\n        b = np.zeros(N_unknowns)\n\n        for j_int in range(1, M + 1):  # 1-based index for interior y-nodes\n            for i_int in range(1, M + 1):  # 1-based index for interior x-nodes\n                \n                # Map 2D grid index (i_int, j_int) to 1D vector index k\n                k = (j_int - 1) * M + (i_int - 1)\n\n                # Set source term in the right-hand side vector b\n                x, y = i_int * h, j_int * h\n                b[k] = h * h * f_func(x, y)\n\n                # Calculate interface conductivities using harmonic mean\n                kappa_center = kappa[i_int, j_int]\n                \n                kappa_W = h_mean(kappa_center, kappa[i_int - 1, j_int]) # West\n                kappa_E = h_mean(kappa_center, kappa[i_int + 1, j_int]) # East\n                kappa_S = h_mean(kappa_center, kappa[i_int, j_int - 1]) # South\n                kappa_N = h_mean(kappa_center, kappa[i_int, j_int + 1]) # North\n\n                # Set matrix A coefficients for the current row k\n                # Diagonal entry\n                A[k, k] = -(kappa_W + kappa_E + kappa_S + kappa_N)\n                \n                # Off-diagonal entries for neighbors\n                # Homogeneous Dirichlet BCs are handled implicitly by only\n                # setting entries for interior neighbors.\n                if i_int > 1:  # West neighbor\n                    A[k, k - 1] = kappa_W\n                if i_int  M:  # East neighbor\n                    A[k, k + 1] = kappa_E\n                if j_int > 1:  # South neighbor\n                    A[k, k - M] = kappa_S\n                if j_int  M:  # North neighbor\n                    A[k, k + M] = kappa_N\n                    \n        #\n        # 3. Solve the linear system for the unknown vector u\n        #\n        u_vec = np.linalg.solve(A, b)\n\n        #\n        # 4. Compute the discrete L2 norm of the solution\n        #\n        # norm = sqrt(h^2 * sum(u_k^2)) = h * sqrt(sum(u_k^2)) = h * linalg.norm(u_vec)\n        norm_L2h = h * np.linalg.norm(u_vec)\n\n        return norm_L2h\n\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # Case 1\n        {'M': 16, 'k_low': 1, 'k_high': 5, 'p': 0, \n         'f': lambda x, y: np.sin(2 * np.pi * x) * np.sin(2 * np.pi * y)},\n        # Case 2\n        {'M': 5, 'k_low': 1, 'k_high': 10, 'p': 1, \n         'f': lambda x, y: 0.0},\n        # Case 3\n        {'M': 20, 'k_low': 1, 'k_high': 100, 'p': 0, \n         'f': lambda x, y: 1.0},\n        # Case 4\n        {'M': 1, 'k_low': 2, 'k_high': 8, 'p': 0, \n         'f': lambda x, y: np.cos(np.pi * x) * np.cos(np.pi * y)},\n    ]\n\n    results = []\n    for case in test_cases:\n        result = solve_pde_case(\n            case['M'], case['k_low'], case['k_high'], case['p'], case['f']\n        )\n        results.append(result)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "3228831"}, {"introduction": "As the grid becomes finer to achieve higher accuracy, standard iterative solvers can become prohibitively slow. This final practice [@problem_id:3228782] introduces the fundamental concepts behind multigrid methods, one of the most efficient classes of modern solvers. By implementing a simplified two-level V-cycle for the 1D Poisson equation, you will gain hands-on experience with the core components of smoothing and coarse-grid correction that give multigrid its remarkable power.", "problem": "Implement a complete and runnable program that constructs and applies a two-level multigrid V-cycle for the one-dimensional Poisson equation. Consider the boundary value problem for the one-dimensional Poisson equation on the unit interval with homogeneous Dirichlet boundary conditions:\nGiven a right-hand side function $f(x)$ on the interval $[0,1]$, solve\n$-u''(x)=f(x)$ for $x \\in (0,1)$, with $u(0)=0$ and $u(1)=0$.\nStart from the foundational finite difference construction: for an integer $N \\ge 1$, introduce a uniform grid with $N$ interior points at $x_i = i h$, where $h = 1/(N+1)$ and $i=1,2,\\dots,N$. The second derivative $u''(x_i)$ is approximated by the standard centered finite difference, which follows from Taylor expansions about $x_i$. This produces a linear system $A_f \\, u_f = b_f$, where $u_f \\in \\mathbb{R}^N$ approximates $u(x)$ at the interior points, $b_f \\in \\mathbb{R}^N$ has entries $f(x_i)$, and $A_f \\in \\mathbb{R}^{N \\times N}$ is the discrete Laplacian matrix with Dirichlet boundary conditions.\n\nYou must implement a two-level multigrid V-cycle whose steps are justified by the error equation $A_f e_f = r_f$, where $e_f$ is the error and $r_f=b_f-A_f u_f$ is the residual. The algorithm must follow these requirements:\n- Pre-smoothing: apply $\\nu_1$ iterations of damped Jacobi to $A_f u_f = b_f$. One damped Jacobi iteration updates $u_f$ by $u_f \\leftarrow u_f + \\omega D_f^{-1}(b_f - A_f u_f)$, where $D_f$ is the diagonal of $A_f$ and $0  \\omega  1$ is a damping parameter. Use $\\omega = 2/3$.\n- Coarse-grid correction:\n  1. Restrict the fine-grid residual $r_f$ to the coarse grid using full-weighting restriction $R \\in \\mathbb{R}^{N_c \\times N}$, where $N_c = (N-1)/2$ assuming $N$ is odd. The restricted residual is $r_c = R r_f$. The full-weighting restriction maps each coarse residual entry to a weighted average of one fine-grid point and its two neighbors, ensuring that linear functions are preserved upon transfer to the coarse grid.\n  2. Define the coarse-grid operator by the Galerkin construction $A_c = R A_f P$, where $P \\in \\mathbb{R}^{N \\times N_c}$ is the linear interpolation (prolongation) operator. The prolongation $P$ should inject coarse-grid values into corresponding even-indexed fine points and linearly interpolate values at the odd-indexed fine points between neighboring coarse points. At boundaries, where a neighboring coarse point would be outside the domain, the boundary contribution is effectively zero due to the homogeneous Dirichlet boundary conditions.\n  3. Solve $A_c e_c = r_c$ exactly on the coarse grid by a direct linear solver, which is justified since $A_c$ is small and symmetric positive definite for this model problem.\n  4. Prolong the coarse error $e_c$ to the fine grid as $e_f = P e_c$ and correct $u_f \\leftarrow u_f + e_f$.\n- Post-smoothing: apply $\\nu_2$ additional iterations of damped Jacobi with the same $\\omega$.\n\nThe program must employ the following general principles derived from the foundational finite difference and linear algebra constructs:\n- The finite difference matrix $A_f$ arises from Taylor’s theorem applied to $u(x)$ at each $x_i$, yielding the standard second-order centered approximation for $-u''(x)$ and enforcing homogeneous Dirichlet boundary conditions by excluding boundary nodes from the unknown vector.\n- The residual equation $A_f e_f = r_f$ justifies the coarse-grid correction, where $R$ and $P$ are chosen so that smooth (low-frequency) components of the error on the fine grid are well-represented and efficiently corrected on the coarse grid.\n- The Galerkin operator $A_c = R A_f P$ ensures variational consistency between grid levels.\n\nImplementation details to enforce:\n- Use a zero initial guess $u_f^{(0)} = 0$.\n- Use the damped Jacobi method with damping parameter $\\omega = 2/3$ for both pre- and post-smoothing.\n- Use full-weighting restriction and linear interpolation prolongation, as described above, and construct $A_c$ using the Galerkin formula $A_c = R A_f P$.\n- Iterate V-cycles until the relative residual norm satisfies $\\|r_f^{(k)}\\|_2 / \\|r_f^{(0)}\\|_2 \\le \\tau$ for a given tolerance $\\tau$, or until a maximum of $200$ V-cycles is reached, whichever occurs first.\n- For verification, choose right-hand sides for which the exact solution is known. Specifically, let $u_{\\text{exact}}(x) = \\sin(k \\pi x)$, with $k \\in \\mathbb{N}$, so that $f(x) = k^2 \\pi^2 \\sin(k \\pi x)$. Evaluate the sine in radians.\n\nTest suite and required outputs:\nImplement the solver and run it on the following three test cases. In each case, form $b_f$ by sampling $f(x)$ at interior grid points $x_i = i h$, with $h = 1/(N+1)$, and set the initial guess to the zero vector.\n- Test case A (happy path): $N = 63$, $k = 1$, $\\nu_1 = 2$, $\\nu_2 = 2$, $\\tau = 10^{-8}$.\n- Test case B (reduced smoothing): $N = 31$, $k = 2$, $\\nu_1 = 1$, $\\nu_2 = 1$, $\\tau = 10^{-8}$.\n- Test case C (larger problem): $N = 127$, $k = 1$, $\\nu_1 = 3$, $\\nu_2 = 3$, $\\tau = 10^{-8}$.\n\nFor each test case, after convergence, report two quantities:\n- The number of V-cycles taken, as an integer.\n- The infinity norm of the error $\\|u_f - u_{\\text{exact}}\\|_{\\infty}$ on the fine grid, as a floating-point number.\n\nFinal output format:\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets. The list must contain the results for the three test cases in the order A, B, C, with two entries per test case: first the integer V-cycle count, then the floating-point infinity norm error. For example, the output must be of the form $[n_A,e_A,n_B,e_B,n_C,e_C]$ where $n_A$, $n_B$, $n_C$ are integers and $e_A$, $e_B$, $e_C$ are floating-point numbers.", "solution": "The provided problem is a well-posed and standard exercise in the field of numerical analysis for partial differential equations. It is scientifically grounded, formally specified, and internally consistent. All necessary parameters and definitions for implementing a two-level multigrid V-cycle for the one-dimensional Poisson equation are provided. Therefore, the problem is valid, and a solution can be constructed.\n\nThe problem requires solving the one-dimensional Poisson equation with homogeneous Dirichlet boundary conditions:\n$$\n-u''(x) = f(x), \\quad x \\in (0, 1) \\\\\nu(0) = 0, \\quad u(1) = 0\n$$\nWe begin by discretizing the problem domain. A uniform grid is defined with $N$ interior points $x_i = i h$ for $i=1, 2, \\dots, N$, where the grid spacing is $h = 1/(N+1)$. The second derivative $u''(x_i)$ at each interior grid point is approximated using a second-order accurate centered finite difference formula derived from Taylor series expansions:\n$$\nu''(x_i) \\approx \\frac{u(x_i - h) - 2u(x_i) + u(x_i + h)}{h^2} = \\frac{u_{i-1} - 2u_i + u_{i+1}}{h^2}\n$$\nwhere $u_i \\approx u(x_i)$. Substituting this into the Poisson equation gives a system of linear equations for the unknown values $u_i$:\n$$\n-\\frac{u_{i-1} - 2u_i + u_{i+1}}{h^2} = f(x_i) \\quad \\text{for } i=1, \\dots, N\n$$\nThe boundary conditions $u(0)=0$ and $u(1)=0$ imply $u_0=0$ and $u_{N+1}=0$. The system can be written in matrix form as $A_f u_f = b_f$, where $u_f = [u_1, u_2, \\dots, u_N]^T$ is the vector of unknown solution values on the fine grid, $b_f = [f(x_1), f(x_2), \\dots, f(x_N)]^T$ is the vector of the right-hand side function evaluated at the grid points, and $A_f$ is the $N \\times N$ discrete Laplacian matrix:\n$$\nA_f = \\frac{1}{h^2}\n\\begin{pmatrix}\n2  -1    \\\\\n-1  2  -1   \\\\\n  \\ddots  \\ddots  \\ddots  \\\\\n   -1  2  -1 \\\\\n    -1  2\n\\end{pmatrix}\n$$\nThe core of the multigrid method is to solve this system iteratively by leveraging a hierarchy of grids. The V-cycle algorithm is based on the principle that relaxation methods (smoothers) are efficient at reducing high-frequency (oscillatory) components of the error, while coarse grids are efficient at reducing low-frequency (smooth) components of the error. Given a current approximation $\\tilde{u}_f$ to the solution $u_f$, the error is $e_f = u_f - \\tilde{u}_f$ and the residual is $r_f = b_f - A_f \\tilde{u}_f$. These quantities are related by the residual equation: $A_f e_f = r_f$. The multigrid cycle approximates the error $e_f$ and uses it to correct the solution.\n\nThe two-level V-cycle consists of three main stages:\n\n1.  **Pre-smoothing**: We apply $\\nu_1$ iterations of a smoother to the current approximation. The problem specifies the damped Jacobi method. For an iteration $m$, the update is:\n    $$\n    u_f^{(m+1)} = u_f^{(m)} + \\omega D_f^{-1} (b_f - A_f u_f^{(m)})\n    $$\n    where $D_f$ is the diagonal part of $A_f$. For our matrix, $D_f = \\frac{2}{h^2} I$, where $I$ is the identity matrix. The damping parameter is given as $\\omega = 2/3$. Smoothing reduces the high-frequency components of the error $e_f$.\n\n2.  **Coarse-Grid Correction**: The remaining error is now predominantly smooth and can be effectively represented on a coarser grid.\n    *   **Restriction**: The fine-grid residual $r_f = b_f - A_f u_f$ is transferred to a coarse grid. The coarse grid has $N_c = (N-1)/2$ interior points, assuming $N$ is odd. The transfer is done by a restriction operator $R \\in \\mathbb{R}^{N_c \\times N}$, yielding the coarse-grid residual $r_c = R r_f$. The specified full-weighting restriction operator uses a stencil $[1/4, 1/2, 1/4]$, meaning the coarse-grid residual at a point is a weighted average of the fine-grid residual at the corresponding point and its two immediate neighbors.\n    *   **Coarse-Grid Problem**: We solve the residual equation on the coarse grid, $A_c e_c = r_c$, for the coarse-grid error $e_c$. The coarse-grid operator $A_c$ is formed by the Galerkin construction $A_c = R A_f P$, where $P \\in \\mathbb{R}^{N \\times N_c}$ is the prolongation (interpolation) operator. This construction ensures that the coarse operator inherits properties from the fine operator in a variationally consistent way. Since $A_c$ is a small matrix, this system is solved directly (e.g., using LU decomposition).\n    *   **Prolongation**: The computed coarse-grid error $e_c$ is interpolated back to the fine grid to form a fine-grid error correction, $e_f = P e_c$. The specified linear interpolation operator $P$ maps coarse-grid points to the even-indexed fine-grid points and linearly interpolates for the odd-indexed fine-grid points. Typically, for Galerkin methods, the restriction and prolongation operators are related by $R = c P^T$ for some constant $c$; for the standard 1D case, $c=1/2$.\n    *   **Correction**: The fine-grid solution is corrected using the interpolated error: $u_f \\leftarrow u_f + e_f$.\n\n3.  **Post-smoothing**: We apply $\\nu_2$ additional iterations of the damped Jacobi smoother to the corrected solution to eliminate any high-frequency errors introduced by the prolongation step.\n\nThis entire sequence constitutes one V-cycle. The process is repeated until the relative $L_2$-norm of the residual falls below a specified tolerance $\\tau$:\n$$\n\\frac{\\|r_f^{(k)}\\|_2}{\\|r_f^{(0)}\\|_2} \\le \\tau\n$$\nwhere $r_f^{(k)}$ is the residual after the $k$-th V-cycle and $r_f^{(0)}$ is the initial residual.\n\nTo verify the implementation, we use a manufactured solution $u_{\\text{exact}}(x) = \\sin(k \\pi x)$, which satisfies the homogeneous Dirichlet boundary conditions. The corresponding right-hand side is $f(x) = -u_{\\text{exact}}''(x) = (k \\pi)^2 \\sin(k \\pi x)$. The final accuracy of the computed solution $u_f$ is measured by the infinity norm of the error, $\\|u_f - u_{\\text{exact}}\\|_{\\infty} = \\max_i |(u_f)_i - u_{\\text{exact}}(x_i)|$.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef damped_jacobi(u, b, A, omega, nu):\n    \"\"\"\n    Applies nu iterations of the damped Jacobi smoother.\n    \n    Args:\n        u (np.ndarray): The current solution vector.\n        b (np.ndarray): The right-hand side vector.\n        A (np.ndarray): The system matrix.\n        omega (float): The damping parameter.\n        nu (int): The number of smoothing iterations.\n        \n    Returns:\n        np.ndarray: The solution vector after smoothing.\n    \"\"\"\n    # D_inv is a diagonal matrix. For the 1D Poisson matrix, A[0,0] = 2/h^2.\n    # D_inv * vector is equivalent to (h^2/2) * vector.\n    diag_inv = 1.0 / A[0, 0]\n    for _ in range(nu):\n        residual = b - A @ u\n        u = u + omega * diag_inv * residual\n    return u\n\ndef v_cycle(u_f, b_f, A_f, P, R, A_c, nu1, nu2, omega):\n    \"\"\"\n    Performs one two-level V-cycle.\n    \n    Args:\n        u_f (np.ndarray): Fine-grid solution vector.\n        b_f (np.ndarray): Fine-grid right-hand side vector.\n        A_f (np.ndarray): Fine-grid operator.\n        P (np.ndarray): Prolongation operator.\n        R (np.ndarray): Restriction operator.\n        A_c (np.ndarray): Coarse-grid operator.\n        nu1 (int): Number of pre-smoothing steps.\n        nu2 (int): Number of post-smoothing steps.\n        omega (float): Damping parameter for Jacobi.\n        \n    Returns:\n        np.ndarray: Updated fine-grid solution vector.\n    \"\"\"\n    # 1. Pre-smoothing\n    u_f = damped_jacobi(u_f, b_f, A_f, omega, nu1)\n    \n    # 2. Coarse-grid correction\n    # a. Compute residual\n    r_f = b_f - A_f @ u_f\n    \n    # b. Restrict residual to coarse grid\n    r_c = R @ r_f\n    \n    # c. Solve coarse-grid problem exactly\n    e_c = np.linalg.solve(A_c, r_c)\n    \n    # d. Prolongate error to fine grid and correct solution\n    e_f = P @ e_c\n    u_f = u_f + e_f\n    \n    # 3. Post-smoothing\n    u_f = damped_jacobi(u_f, b_f, A_f, omega, nu2)\n    \n    return u_f\n\ndef solve():\n    \"\"\"\n    Main function to run the multigrid solver for the specified test cases.\n    \"\"\"\n    test_cases = [\n        # (N, k, nu1, nu2, tolerance)\n        (63, 1, 2, 2, 1e-8),  # Test case A\n        (31, 2, 1, 1, 1e-8),  # Test case B\n        (127, 1, 3, 3, 1e-8), # Test case C\n    ]\n\n    results = []\n    omega = 2/3\n    max_cycles = 200\n\n    for N, k, nu1, nu2, tol in test_cases:\n        # 1. Setup grids and operators\n        h = 1.0 / (N + 1)\n        x_fine = np.linspace(h, 1.0 - h, N)\n        Nc = (N - 1) // 2\n\n        # Fine-grid operator A_f (discrete Laplacian)\n        diag_main = np.full(N, 2.0)\n        diag_sub = np.full(N - 1, -1.0)\n        A_f = (1.0 / h**2) * (np.diag(diag_main) + np.diag(diag_sub, k=1) + np.diag(diag_sub, k=-1))\n\n        # Prolongation operator P (linear interpolation)\n        P = np.zeros((N, Nc))\n        for j in range(Nc):\n            # Injection from coarse point j to fine point 2j+1\n            P[2 * j + 1, j] = 1.0\n            # Interpolation for neighbors\n            P[2 * j, j] += 0.5\n            if 2 * j + 2  N:\n                P[2 * j + 2, j] += 0.5\n\n        # Restriction operator R (full weighting)\n        # For standard 1D linear interpolation, R relates to P as R = 0.5 * P.T\n        R = 0.5 * P.T\n\n        # Coarse-grid operator Ac (Galerkin operator)\n        A_c = R @ A_f @ P\n\n        # 2. Setup problem: RHS and exact solution\n        f = lambda x_pts, k_val: (k_val * np.pi)**2 * np.sin(k_val * np.pi * x_pts)\n        b_f = f(x_fine, k)\n        u_exact = np.sin(k * np.pi * x_fine)\n\n        # 3. Iteratively solve using V-cycles\n        u_f = np.zeros(N)  # Initial guess is the zero vector\n        \n        r_0 = b_f - A_f @ u_f\n        r0_norm = np.linalg.norm(r_0, 2)\n        \n        if r0_norm == 0:\n            cycle_count = 0\n        else:\n            for cycle_count in range(1, max_cycles + 1):\n                u_f = v_cycle(u_f, b_f, A_f, P, R, A_c, nu1, nu2, omega)\n                \n                r_k = b_f - A_f @ u_f\n                relative_residual = np.linalg.norm(r_k, 2) / r0_norm\n                \n                if relative_residual  tol:\n                    break\n        \n        # 4. Calculate final error against exact solution\n        error_inf_norm = np.linalg.norm(u_f - u_exact, np.inf)\n        \n        results.extend([cycle_count, error_inf_norm])\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(f'{val:.8e}' if isinstance(val, float) else str(val) for val in results)}]\")\n\nsolve()\n```", "id": "3228782"}]}