{"hands_on_practices": [{"introduction": "Before writing a single line of code, a computational scientist must master the language of finite differences. This first exercise takes you to the drawing board to derive a numerical scheme for the advection-diffusion equation, a model central to fields from fluid dynamics to finance. By applying the Crank-Nicolson method, you will practice combining temporal and spatial discretizations to construct a stable and accurate implicit scheme, a cornerstone technique in numerically solving partial differential equations. [@problem_id:2139864]", "problem": "Consider the one-dimensional advection-diffusion equation, which models phenomena such as the transport of a pollutant in a channel. The equation is given by:\n$$ \\frac{\\partial u}{\\partial t} + c \\frac{\\partial u}{\\partial x} = D \\frac{\\partial^2 u}{\\partial x^2} $$\nHere, $u(x,t)$ is the concentration of the substance at position $x$ and time $t$, $c$ is the constant advection velocity, and $D$ is the constant diffusion coefficient.\n\nWe wish to construct a finite difference scheme to solve this equation numerically on a uniform grid with spatial step size $\\Delta x$ and time step size $\\Delta t$. We denote the numerical approximation of $u(j\\Delta x, n\\Delta t)$ by $u_j^n$.\n\nThe scheme is to be developed by applying the Crank-Nicolson method, which involves centering the finite differences at the half-time step $t_{n+1/2} = (n + 1/2)\\Delta t$. The specific discretization rules are as follows:\n1.  The time derivative, $\\frac{\\partial u}{\\partial t}$, is approximated by a central difference at time $t_{n+1/2}$.\n2.  The diffusion term, $D \\frac{\\partial^2 u}{\\partial x^2}$, is approximated by averaging the standard central difference approximations of the second spatial derivative at time levels $n$ and $n+1$.\n3.  The advection term, $c \\frac{\\partial u}{\\partial x}$, is approximated by a central difference in space. This spatial difference is then evaluated at the half-time step $t_{n+1/2}$ by averaging its values at time levels $n$ and $n+1$.\n\nFollowing these rules, derive the finite difference equation and rearrange it into the standard implicit tridiagonal form:\n$$ A u_{j-1}^{n+1} + B u_j^{n+1} + C u_{j+1}^{n+1} = E u_{j-1}^{n} + F u_j^{n} + G u_{j+1}^{n} $$\nDetermine the expressions for the coefficients $A, B, C, E, F,$ and $G$ in terms of the dimensionless Courant number $\\nu = \\frac{c \\Delta t}{\\Delta x}$ and the diffusion number $\\mu = \\frac{D \\Delta t}{(\\Delta x)^2}$.\n\nPresent your final answer as a single row matrix containing the six coefficients in the order $\\begin{pmatrix} A & B & C & E & F & G \\end{pmatrix}$.", "solution": "We start from the advection-diffusion equation\n$$\n\\frac{\\partial u}{\\partial t} + c \\frac{\\partial u}{\\partial x} = D \\frac{\\partial^{2} u}{\\partial x^{2}}.\n$$\nOn a uniform grid with $u_{j}^{n} \\approx u(j\\Delta x,n\\Delta t)$, the Crank-Nicolson discretization at the half-time $t_{n+1/2}$ uses:\n- the central time difference for the time derivative,\n- the average of central spatial differences at times $n$ and $n+1$ for both the first and second spatial derivatives.\n\nThus,\n$$\n\\frac{u_{j}^{n+1} - u_{j}^{n}}{\\Delta t}\n+ c \\cdot \\frac{1}{2} \\left[ \\frac{u_{j+1}^{n} - u_{j-1}^{n}}{2\\Delta x} + \\frac{u_{j+1}^{n+1} - u_{j-1}^{n+1}}{2\\Delta x} \\right]\n= D \\cdot \\frac{1}{2} \\left[ \\frac{u_{j+1}^{n} - 2u_{j}^{n} + u_{j-1}^{n}}{(\\Delta x)^{2}} + \\frac{u_{j+1}^{n+1} - 2u_{j}^{n+1} + u_{j-1}^{n+1}}{(\\Delta x)^{2}} \\right].\n$$\nMultiply by $\\Delta t$ and introduce the Courant and diffusion numbers $\\nu = \\frac{c \\Delta t}{\\Delta x}$ and $\\mu = \\frac{D \\Delta t}{(\\Delta x)^{2}}$ to obtain\n$$\nu_{j}^{n+1} - u_{j}^{n}\n+ \\frac{\\nu}{4} \\left[ \\left(u_{j+1}^{n} - u_{j-1}^{n}\\right) + \\left(u_{j+1}^{n+1} - u_{j-1}^{n+1}\\right) \\right]\n= \\frac{\\mu}{2} \\left[ \\left(u_{j+1}^{n} - 2u_{j}^{n} + u_{j-1}^{n}\\right) + \\left(u_{j+1}^{n+1} - 2u_{j}^{n+1} + u_{j-1}^{n+1}\\right) \\right].\n$$\nGather the terms at time level $n+1$ on the left and those at time level $n$ on the right:\n$$\nu_{j}^{n+1}\n+ \\frac{\\nu}{4}\\left(u_{j+1}^{n+1} - u_{j-1}^{n+1}\\right)\n- \\frac{\\mu}{2}\\left(u_{j+1}^{n+1} - 2u_{j}^{n+1} + u_{j-1}^{n+1}\\right)\n= u_{j}^{n}\n- \\frac{\\nu}{4}\\left(u_{j+1}^{n} - u_{j-1}^{n}\\right)\n+ \\frac{\\mu}{2}\\left(u_{j+1}^{n} - 2u_{j}^{n} + u_{j-1}^{n}\\right).\n$$\nExpand and collect coefficients of $u_{j-1}^{n+1}$, $u_{j}^{n+1}$, $u_{j+1}^{n+1}$ on the left, and of $u_{j-1}^{n}$, $u_{j}^{n}$, $u_{j+1}^{n}$ on the right. This yields the tridiagonal form\n$$\nA u_{j-1}^{n+1} + B u_{j}^{n+1} + C u_{j+1}^{n+1} = E u_{j-1}^{n} + F u_{j}^{n} + G u_{j+1}^{n},\n$$\nwith\n$$\nA = -\\frac{\\mu}{2} - \\frac{\\nu}{4}, \\quad\nB = 1 + \\mu, \\quad\nC = -\\frac{\\mu}{2} + \\frac{\\nu}{4}, \\quad\nE = \\frac{\\mu}{2} + \\frac{\\nu}{4}, \\quad\nF = 1 - \\mu, \\quad\nG = \\frac{\\mu}{2} - \\frac{\\nu}{4}.\n$$\nThese reduce correctly to the standard Crank-Nicolson diffusion scheme when $c=0$ and to the centered trapezoidal advection scheme when $D=0$.", "answer": "$$\\boxed{\\begin{pmatrix}-\\frac{\\mu}{2}-\\frac{\\nu}{4} & 1+\\mu & -\\frac{\\mu}{2}+\\frac{\\nu}{4} & \\frac{\\mu}{2}+\\frac{\\nu}{4} & 1-\\mu & \\frac{\\mu}{2}-\\frac{\\nu}{4}\\end{pmatrix}}$$", "id": "2139864"}, {"introduction": "A standard numerical scheme on a uniform grid can fail spectacularly when faced with solutions that have sharp features, such as boundary layers. This practice moves from pure derivation to practical problem-solving, tackling a classic singularly perturbed problem where the solution changes dramatically over a very small region. You will discover firsthand how a carefully designed non-uniform mesh, which concentrates grid points where they are most needed, can capture the boundary layer accurately and efficiently, demonstrating a key principle of smart discretization. [@problem_id:3223740]", "problem": "You will investigate non-uniform grid design for a singularly perturbed boundary value problem by deriving a stable finite difference scheme on a non-uniform mesh, implementing it, and empirically selecting a grid clustering parameter that minimizes a precise error metric. Consider the ordinary differential equation (ODE)\n$$\n\\varepsilon\\,u''(x) + u'(x) = 0,\\quad x\\in(0,1),\n$$\nwith boundary conditions\n$$\nu(0)=0,\\qquad u(1)=1,\n$$\nwhere $\\varepsilon>0$ is a given parameter. This problem exhibits a boundary layer near $x=0$ when $\\varepsilon$ is small.\n\nYou must do the following.\n\n1) Derive a consistent and stable finite difference discretization of the ODE on a strictly increasing non-uniform mesh $\\{x_j\\}_{j=0}^{N}$ with $x_0=0$, $x_N=1$, using:\n- a conservative three-point approximation for the second derivative on non-uniform meshes that is obtained from the difference of diffusive fluxes over adjacent subintervals, and\n- an upwind (backward) difference for the first derivative that respects the direction of the convective term.\n\nThe derivation must start from the definitions of the derivative as the limit of difference quotients and the integral balance over control volumes, and it must not assume any special mesh regularity beyond strict monotonicity. Let $h_{j-1/2}=x_j-x_{j-1}$ and $h_{j+1/2}=x_{j+1}-x_j$ for $j\\in\\{1,\\dots,N-1\\}$. Impose the boundary conditions strongly at $x_0$ and $x_N$.\n\n2) Let the non-uniform mesh be generated by a one-parameter exponential mapping $\\varphi_\\alpha:[0,1]\\to[0,1]$ defined for $\\alpha>0$ by\n$$\n\\varphi_\\alpha(t)=\\frac{e^{\\alpha t}-1}{e^{\\alpha}-1},\n$$\nand by $\\varphi_0(t)=t$ for $\\alpha=0$. Define grid nodes by $x_j=\\varphi_\\alpha\\!\\left(\\frac{j}{N}\\right)$ for $j\\in\\{0,1,\\dots,N\\}$. The parameter $\\alpha$ controls clustering near $x=0$; larger $\\alpha$ yields stronger clustering.\n\n3) For a given pair $(\\varepsilon,N)$, define the candidate set of clustering parameters\n$$\n\\mathcal{A}=\\{0,2,4,6,8,10\\}.\n$$\nFor each $\\alpha\\in\\mathcal{A}$, construct the mesh $\\{x_j\\}$, assemble and solve the discrete system, and compute the maximum nodal error in the infinity norm relative to the exact solution $u_{\\text{exact}}(x)$ of the ODE. The exact solution is uniquely determined by the ODE and boundary conditions.\n\nLet the discrete solution be $\\{u_j\\}_{j=0}^{N}$ and define the error\n$$\nE(\\alpha;\\varepsilon,N)=\\max_{0\\le j\\le N}\\,\\left|u_j - u_{\\text{exact}}(x_j)\\right|.\n$$\nDefine the empirically optimal clustering parameter for $(\\varepsilon,N)$ as\n$$\n\\alpha^\\star(\\varepsilon,N)=\\arg\\min_{\\alpha\\in\\mathcal{A}} E(\\alpha;\\varepsilon,N),\n$$\nwith ties broken by choosing the smallest $\\alpha$.\n\n4) Implement a program that performs the above procedure for each test case in the following test suite:\n- Test $1$: $(\\varepsilon,N)=\\left(10^{-1},\\,64\\right)$.\n- Test $2$: $(\\varepsilon,N)=\\left(5\\cdot 10^{-2},\\,64\\right)$.\n- Test $3$: $(\\varepsilon,N)=\\left(10^{-2},\\,32\\right)$.\n- Test $4$: $(\\varepsilon,N)=\\left(10^{-3},\\,64\\right)$.\n\n5) Your program must produce a single line of output containing the results as a comma-separated list enclosed in square brackets. The list must be\n$$\n[\\alpha^\\star(\\varepsilon_1,N_1),\\alpha^\\star(\\varepsilon_2,N_2),\\alpha^\\star(\\varepsilon_3,N_3),\\alpha^\\star(\\varepsilon_4,N_4)],\n$$\nin the order of Tests $1$ through $4$, with each entry as an integer from $\\mathcal{A}$. For example, the format should look like [$x$,$y$,$z$,$w$].\n\nNotes and constraints:\n- No physical units are involved.\n- Angles are not involved.\n- The only permitted libraries are the standard library and a numerical array library, and the program must be self-contained with no user input.\n- The mesh must be strictly increasing for all $\\alpha\\in\\mathcal{A}$ and $N\\in\\{32,64\\}$.\n- The discrete linear system should be solved exactly (up to floating-point arithmetic) for each mesh, and the error must be computed at all mesh nodes including endpoints.", "solution": "The user requests the solution of a singularly perturbed boundary value problem (BVP) using a finite difference method on a non-uniform grid. The core tasks are to derive the numerical scheme, implement it, and use it to find an empirically optimal grid clustering parameter for several test cases.\n\n### Part 1: Derivation of the Finite Difference Scheme\n\nThe given BVP is:\n$$\n\\varepsilon\\,u''(x) + u'(x) = 0, \\quad x \\in (0,1)\n$$\nwith boundary conditions $u(0)=0$ and $u(1)=1$.\n\nWe are to discretize this equation on a strictly increasing non-uniform mesh $\\{x_j\\}_{j=0}^{N}$ where $x_0=0$ and $x_N=1$. The step sizes are defined as $h_{j-1/2} = x_j - x_{j-1}$ and $h_{j+1/2} = x_{j+1} - x_j$. The discretization is for the interior nodes $j=1, \\dots, N-1$.\n\n**Discretization of the Second Derivative ($u''$)**\n\nThe problem requires a conservative three-point approximation for the second derivative, derived from the difference of diffusive fluxes. This is standardly achieved using a finite volume approach over a control volume centered at $x_j$, e.g., $[(x_{j-1}+x_j)/2, (x_j+x_{j+1})/2]$. The length of this control volume is $\\frac{1}{2}(h_{j-1/2} + h_{j+1/2})$. The term $\\varepsilon u''$ corresponds to the divergence of the diffusive flux $\\varepsilon u'$. Integrating $\\varepsilon u''$ over the control volume gives $\\varepsilon[u']_{(x_{j-1}+x_j)/2}^{(x_j+x_{j+1})/2}$. Approximating the derivatives at the control volume faces with central differences gives:\n$$\nu'\\left(\\frac{x_j+x_{j+1}}{2}\\right) \\approx \\frac{u_{j+1}-u_j}{x_{j+1}-x_j} = \\frac{u_{j+1}-u_j}{h_{j+1/2}}\n$$\n$$\nu'\\left(\\frac{x_{j-1}+x_j}{2}\\right) \\approx \\frac{u_j-u_{j-1}}{x_j-x_{j-1}} = \\frac{u_j-u_{j-1}}{h_{j-1/2}}\n$$\nDividing by the control volume length, the approximation for $u''(x_j)$ at node $x_j$ is:\n$$\nu''(x_j) \\approx \\frac{ \\frac{u_{j+1}-u_j}{h_{j+1/2}} - \\frac{u_j-u_{j-1}}{h_{j-1/2}} }{ \\frac{1}{2}(h_{j-1/2} + h_{j+1/2}) } = \\frac{2}{h_{j-1/2} + h_{j+1/2}} \\left( \\frac{u_{j+1}-u_j}{h_{j+1/2}} - \\frac{u_j-u_{j-1}}{h_{j-1/2}} \\right)\n$$\n\n**Discretization of the First Derivative ($u'$)**\n\nThe problem specifies an upwind (backward) difference for the first derivative. Since the coefficient of $u'(x)$ is positive ($+1$), the \"wind\" or direction of transport is from left to right. An upwind scheme at $x_j$ thus uses information from the upstream nodes, i.e., $x_j$ and $x_{j-1}$. The backward difference approximation is:\n$$\nu'(x_j) \\approx \\frac{u_j - u_{j-1}}{x_j - x_{j-1}} = \\frac{u_j - u_{j-1}}{h_{j-1/2}}\n$$\n\n**Assembling the Discrete Equation**\n\nCombining the approximations for the two derivatives, the discrete equation at an interior node $x_j$ is:\n$$\n\\varepsilon \\frac{2}{h_{j-1/2} + h_{j+1/2}} \\left( \\frac{u_{j+1}-u_j}{h_{j+1/2}} - \\frac{u_j-u_{j-1}}{h_{j-1/2}} \\right) + \\frac{u_j - u_{j-1}}{h_{j-1/2}} = 0\n$$\nTo form a linear system, we group terms by the unknowns $u_{j-1}$, $u_j$, and $u_{j+1}$:\n$a_j u_{j-1} + b_j u_j + c_j u_{j+1} = 0$, where:\n- Coefficient of $u_{j-1}$:\n  $a_j = \\varepsilon \\frac{2}{(h_{j-1/2} + h_{j+1/2})h_{j-1/2}} - \\frac{1}{h_{j-1/2}}$\n- Coefficient of $u_{j+1}$:\n  $c_j = \\varepsilon \\frac{2}{(h_{j-1/2} + h_{j+1/2})h_{j+1/2}}$\n- Coefficient of $u_j$:\n  $b_j = -\\varepsilon \\frac{2}{h_{j-1/2} + h_{j+1/2}}\\left(\\frac{1}{h_{j+1/2}} + \\frac{1}{h_{j-1/2}}\\right) + \\frac{1}{h_{j-1/2}}$\n\nThese equations hold for $j=1, \\dots, N-1$. With the strong enforcement of boundary conditions $u_0 = u(0) = 0$ and $u_N = u(1) = 1$, we can construct a linear system for the interior unknowns $\\mathbf{u} = [u_1, u_2, \\dots, u_{N-1}]^T$.\n- For $j=1$: $a_1 u_0 + b_1 u_1 + c_1 u_2 = 0 \\implies b_1 u_1 + c_1 u_2 = -a_1 u_0 = 0$.\n- For $j=N-1$: $a_{N-1} u_{N-2} + b_{N-1} u_{N-1} + c_{N-1} u_N = 0 \\implies a_{N-1} u_{N-2} + b_{N-1} u_{N-1} = -c_{N-1} u_N = -c_{N-1}$.\n\nThis results in an $(N-1) \\times (N-1)$ tridiagonal system of linear equations $A\\mathbf{u}=\\mathbf{f}$, which can be solved for the interior nodal values.\n\n### Part 2: Exact and Numerical Solution Procedure\n\n**Exact Solution**\n\nThe ODE is a second-order linear homogeneous equation with constant coefficients. The characteristic equation is $\\varepsilon r^2 + r = 0$, with roots $r_1=0$ and $r_2=-1/\\varepsilon$. The general solution is $u(x) = C_1 + C_2 e^{-x/\\varepsilon}$. Applying the boundary conditions $u(0)=0$ and $u(1)=1$ yields the unique solution:\n$$\nu_{\\text{exact}}(x) = \\frac{1 - e^{-x/\\varepsilon}}{1 - e^{-1/\\varepsilon}}\n$$\n\n**Numerical Procedure**\n\nFor each test case $(\\varepsilon, N)$, we perform the following optimization:\n1.  Initialize $\\alpha^\\star = -1$ and $E_{min} = \\infty$.\n2.  Iterate through each $\\alpha$ in the candidate set $\\mathcal{A}=\\{0, 2, 4, 6, 8, 10\\}$.\n3.  For each $\\alpha$:\n    a. Generate the non-uniform mesh $\\{x_j\\}_{j=0}^N$ using the mapping $x_j=\\varphi_\\alpha\\!\\left(j/N\\right)$, where $\\varphi_\\alpha(t)=\\frac{e^{\\alpha t}-1}{e^{\\alpha}-1}$ for $\\alpha>0$ and $\\varphi_0(t)=t$.\n    b. Assemble the tridiagonal matrix $A$ and the right-hand side vector $\\mathbf{f}$ for the unknowns $\\{u_j\\}_{j=1}^{N-1}$ using the derived coefficients $a_j, b_j, c_j$.\n    c. Solve the linear system $A\\mathbf{u}=\\mathbf{f}$ to find the numerical solution at the interior nodes.\n    d. Construct the full numerical solution vector $\\{u_j\\}_{j=0}^N$ by including the boundary values $u_0=0$ and $u_N=1$.\n    e. Compute the exact solution $u_{\\text{exact}}(x_j)$ at each mesh node.\n    f. Calculate the maximum nodal error $E(\\alpha) = \\max_{0\\le j\\le N} |u_j - u_{\\text{exact}}(x_j)|$.\n    g. If $E(\\alpha) < E_{min}$, update $E_{min} = E(\\alpha)$ and $\\alpha^\\star = \\alpha$.\n4.  The final $\\alpha^\\star$ is the empirically optimal parameter for the given $(\\varepsilon, N)$.\n\nThis procedure is repeated for all test cases specified in the problem. The final output is a list of the optimal $\\alpha^\\star$ values.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Derives, implements, and tests a finite difference scheme for a singularly\n    perturbed boundary value problem to find an optimal grid clustering parameter.\n    \"\"\"\n\n    def generate_mesh(N, alpha):\n        \"\"\"Generates a non-uniform mesh using an exponential mapping.\"\"\"\n        t = np.linspace(0, 1, N + 1)\n        if alpha == 0:\n            x = t\n        else:\n            x = (np.exp(alpha * t) - 1) / (np.exp(alpha) - 1)\n        return x\n\n    def solve_bvp(eps, N, x):\n        \"\"\"\n        Assembles and solves the tridiagonal linear system for the BVP.\n        \"\"\"\n        # We need to solve for N-1 interior unknowns u_1, ..., u_{N-1}.\n        # The system size is (N-1)x(N-1).\n        \n        # Calculate step sizes h (N elements).\n        # h[k] corresponds to x_{k+1}-x_k, which is h_{k+1/2}.\n        h = np.diff(x)\n        \n        # Diagonals of the matrix A\n        main_diag = np.zeros(N - 1)\n        lower_diag = np.zeros(N - 2)\n        upper_diag = np.zeros(N - 2)\n        \n        # Right-hand side vector f\n        f = np.zeros(N - 1)\n\n        # Loop over interior nodes j = 1, ..., N-1\n        # This corresponds to rows i = 0, ..., N-2 of the matrix.\n        for j in range(1, N):\n            i = j - 1 # Matrix row index\n            \n            h_prev = h[j - 1]  # h_{j-1/2}\n            h_next = h[j]      # h_{j+1/2}\n            h_sum = h_prev + h_next\n\n            # Coefficients a_j, b_j, c_j\n            a_j = eps * 2 / (h_sum * h_prev) - 1 / h_prev\n            c_j = eps * 2 / (h_sum * h_next)\n            b_j = -eps * 2 / h_sum * (1 / h_next + 1 / h_prev) + 1 / h_prev\n\n            main_diag[i] = b_j\n            if j > 1:\n                lower_diag[i - 1] = a_j\n            if j < N - 1:\n                upper_diag[i] = c_j\n        \n        # Build the tridiagonal matrix\n        A = np.diag(main_diag) + np.diag(lower_diag, k=-1) + np.diag(upper_diag, k=1)\n        \n        # Set the right-hand side vector f\n        # Boundary condition u_N = 1 affects the last equation (j = N-1)\n        # Calculate c_{N-1}\n        h_prev_N_minus_1 = h[N - 2]\n        h_next_N_minus_1 = h[N - 1]\n        h_sum_N_minus_1 = h_prev_N_minus_1 + h_next_N_minus_1\n        c_N_minus_1 = eps * 2 / (h_sum_N_minus_1 * h_next_N_minus_1)\n        \n        f[-1] = -c_N_minus_1 * 1.0  # u_N = 1\n\n        # Solve the linear system A*u_internal = f\n        u_internal = np.linalg.solve(A, f)\n        \n        # Construct full solution including boundaries\n        u_numerical = np.zeros(N + 1)\n        u_numerical[0] = 0.0\n        u_numerical[1:N] = u_internal\n        u_numerical[N] = 1.0\n        \n        return u_numerical\n\n    def get_exact_solution(x, eps):\n        \"\"\"Computes the exact solution of the ODE.\"\"\"\n        # The denominator can underflow to 1.0 for small eps, which is correct.\n        # np.exp(-1/eps) -> 0 for eps -> 0.\n        denominator = 1.0 - np.exp(-1.0 / eps)\n        if denominator == 0:\n             # This case is not expected for eps > 0 but is a safeguard.\n             return np.ones_like(x)\n        numerator = 1.0 - np.exp(-x / eps)\n        return numerator / denominator\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        (1e-1, 64),\n        (5e-2, 64),\n        (1e-2, 32),\n        (1e-3, 64),\n    ]\n\n    alpha_candidates = [0, 2, 4, 6, 8, 10]\n    \n    optimal_alphas = []\n\n    for eps, N in test_cases:\n        min_error = float('inf')\n        optimal_alpha = -1\n\n        for alpha in alpha_candidates:\n            # 1. Generate mesh\n            x_nodes = generate_mesh(N, alpha)\n            \n            # 2. Solve BVP numerically\n            u_numerical = solve_bvp(eps, N, x_nodes)\n            \n            # 3. Get exact solution\n            u_exact = get_exact_solution(x_nodes, eps)\n            \n            # 4. Compute error\n            error = np.max(np.abs(u_numerical - u_exact))\n            \n            # 5. Update optimal alpha\n            if error < min_error:\n                min_error = error\n                optimal_alpha = alpha\n        \n        optimal_alphas.append(optimal_alpha)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, optimal_alphas))}]\")\n\nsolve()\n\n```", "id": "3223740"}, {"introduction": "Our final practice represents a leap towards modern, automated scientific computing. While the previous exercise required us to design a static, non-uniform grid based on prior knowledge of the solution's structure, this task empowers the simulation to adapt on its own. You will implement a simple but powerful Adaptive Mesh Refinement (AMR) strategy, where the grid is dynamically refined in regions of high estimated error, allowing the computation to focus its resources precisely where they are needed most. [@problem_id:3223710]", "problem": "Implement an Adaptive Mesh Refinement (AMR) strategy for approximating a smooth scalar function on a one-dimensional domain using piecewise linear elements. The refinement criterion must be based on an a-posteriori error estimate of the form $\\lvert u_{xx} \\rvert h^2$, where $u$ is the target function, $u_{xx}$ is its second derivative, and $h$ is the local cell size.\n\nYou must proceed from the following fundamental base. For a smooth function $u$ on an interval $[x_i,x_{i+1}]$ with length $h = x_{i+1}-x_i$, the degree-$1$ Lagrange interpolant error admits a local bound derived from Taylor's theorem with Lagrange remainder: for some $\\xi \\in (x_i,x_{i+1})$,\n$$\nu\\!\\left(\\tfrac{x_i+x_{i+1}}{2}\\right) - \\tfrac{u(x_i)+u(x_{i+1})}{2} \\;=\\; \\tfrac{u_{xx}(\\xi)}{8}\\,h^2.\n$$\nTherefore, the midpoint deviation from the linear interpolant provides an a-posteriori estimator for $\\lvert u_{xx} \\rvert h^2$ via\n$$\n\\eta_i \\;=\\; 8\\,\\left\\lvert u\\!\\left(\\tfrac{x_i+x_{i+1}}{2}\\right) - \\tfrac{u(x_i)+u(x_{i+1})}{2} \\right\\rvert \\;\\approx\\; \\lvert u_{xx}(\\xi)\\rvert h^2.\n$$\n\nTask requirements:\n- Domain: $[0,1]$.\n- Function to approximate: $u(x) = \\exp\\!\\big(-50\\,(x-0.3)^2\\big) + 0.1\\sin(4\\pi x)$. All angles in trigonometric functions are in radians.\n- Initial mesh: a uniform partition of $[0,1]$ into $4$ equal cells.\n- Refinement strategy: For each cell $[x_i,x_{i+1}]$ with length $h$, compute the midpoint $m=\\tfrac{x_i+x_{i+1}}{2}$ and the estimator\n$$\n\\eta_i \\;=\\; 8\\,\\left\\lvert u(m) - \\tfrac{u(x_i)+u(x_{i+1})}{2} \\right\\rvert.\n$$\nIf $\\eta_i$ exceeds a given tolerance $\\tau$ and $h$ exceeds a minimal size $h_{\\min}$, refine the cell by bisecting it. Repeat until no cell is flagged for refinement or all cells that would be flagged are at the minimal size $h_{\\min}$.\n- Minimal cell size: $h_{\\min} = 2^{-14}$.\n- Stopping criterion: no flagged cells remain or a hard cap on the total number of cells is reached (use a sufficiently large cap to avoid non-termination while remaining computationally reasonable).\n\nYour program must implement the above AMR process and, for each prescribed tolerance, return the final number of cells after refinement terminates.\n\nTest suite:\n- Use the following tolerances $\\tau \\in \\{10^{-1},\\,10^{-2},\\,10^{-3},\\,10\\}$.\n- This suite includes a moderately coarse tolerance, a finer tolerance, a much finer tolerance, and a very large tolerance that should result in little to no refinement on the initial mesh if the estimator is everywhere below the tolerance.\n\nRequired final output format:\n- Your program should produce a single line of output containing the final cell counts for the tolerances in the listed order as a comma-separated list enclosed in square brackets. For example, a valid output looks like $[n_1,n_2,n_3,n_4]$ where each $n_k$ is an integer.", "solution": "The user requests the implementation of a one-dimensional Adaptive Mesh Refinement (AMR) algorithm. The problem is valid as it is scientifically grounded in numerical analysis principles, well-posed with a clear objective and termination criteria, and all necessary parameters are provided.\n\nThe core of the problem is to approximate a scalar function $u(x)$ on the domain $[0, 1]$ with piecewise linear functions. The mesh, which is the set of points where the function is evaluated, is not uniform. Instead, it is selectively refined in regions where the approximation error is estimated to be high.\n\n**Problem Specification**\n- **Domain**: The interval $[0, 1]$.\n- **Function**: $u(x) = \\exp\\big(-50\\,(x-0.3)^2\\big) + 0.1\\sin(4\\pi x)$.\n- **Initial Mesh**: A uniform partition of $[0, 1]$ into $4$ cells. This corresponds to an initial set of $5$ nodes: $\\{0, 0.25, 0.5, 0.75, 1\\}$.\n- **Error Estimator**: For a cell $[x_i, x_{i+1}]$ of size $h = x_{i+1} - x_i$, the error is estimated by $\\eta_i = 8\\,\\left\\lvert u(m) - \\tfrac{u(x_i)+u(x_{i+1})}{2} \\right\\rvert$, where $m = \\tfrac{x_i+x_{i+1}}{2}$ is the midpoint. This estimator is an approximation of $\\lvert u_{xx}(\\xi) \\rvert h^2$, which bounds the error of linear interpolation.\n- **Refinement Criterion**: A cell $[x_i, x_{i+1}]$ is flagged for refinement if two conditions are met:\n    1.  The error estimate exceeds a tolerance: $\\eta_i > \\tau$.\n    2.  The cell size is larger than a minimum threshold: $h > h_{\\min}$.\n- **Refinement Action**: Any flagged cell is bisected. This means its midpoint is added to the set of mesh nodes.\n- **Constants**: The minimum cell size is $h_{\\min} = 2^{-14}$.\n- **Termination**: The iterative refinement process stops when, in a full pass over the mesh, no cells are flagged for refinement.\n- **Task**: The final number of cells in the mesh must be determined for each tolerance $\\tau$ in the set $\\{10^{-1}, 10^{-2}, 10^{-3}, 10\\}$.\n\n**Algorithmic Design**\nFor each specified tolerance $\\tau$, an independent AMR process is executed. The algorithm can be structured as follows:\n\n1.  **Initialization**: Begin with a data structure representing the mesh nodes. A sorted NumPy array is suitable. For this problem, the initial array of nodes is `[0.0, 0.25, 0.5, 0.75, 1.0]`.\n\n2.  **Iterative Refinement Loop**: A `while` loop forms the heart of the algorithm. This loop continues as long as at least one cell is refined in a pass.\n    a. **Flagging Phase**: In each iteration, we traverse the current mesh, examining each cell $[x_i, x_{i+1}]$. For each cell, we perform the following checks:\n        i. Calculate the cell width $h = x_{i+1} - x_i$.\n        ii. If $h \\le h_{\\min}$, the cell is too small to be refined further, so we proceed to the next cell.\n        iii. If $h > h_{\\min}$, we compute the a-posteriori error estimator $\\eta_i$.\n        iv. If $\\eta_i > \\tau$, we mark this cell for refinement. A practical way is to store the midpoint $m = (x_i + x_{i+1})/2$ in a temporary list of points to be added.\n    b. **Termination Check**: After iterating through all cells, if the list of points to add is empty, it means no cell was flagged for refinement. The mesh is now final for the given tolerance $\\tau$. The loop terminates.\n    c. **Mesh Update**: If the list of new points is not empty, the mesh must be updated. We combine the current array of nodes with the new midpoints. To maintain a sorted and unique set of nodes, we can concatenate the two sets of points and then apply a unique-and-sort operation. This new, larger array of nodes defines the mesh for the next iteration of the loop.\n\n3.  **Finalization**: Once the loop terminates, the number of cells in the final mesh is simply the number of nodes minus one. This integer value is the result for the specific tolerance $\\tau$.\n\nThis process is repeated for each $\\tau \\in \\{10^{-1}, 10^{-2}, 10^{-3}, 10\\}$. The resulting list of cell counts constitutes the final answer. The function $u(x)$ is composed of an exponential (Gaussian-like) part and a sinusoidal part. The Gaussian term has high curvature around $x=0.3$, which will cause the error estimator $\\eta_i$ to be large in that region, leading to significant local refinement. The sinusoidal term will induce refinement across the entire domain. As the tolerance $\\tau$ becomes smaller, the algorithm will require a finer mesh to keep the local error estimate below the threshold, resulting in a larger number of cells. Conversely, a very large tolerance (like $\\tau=10$) is expected to result in little or no refinement from the initial mesh.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Implements an Adaptive Mesh Refinement (AMR) strategy and computes the\n    final number of cells for a suite of tolerances.\n    \"\"\"\n\n    # Define the scalar function to be approximated, as per the problem statement.\n    # u(x) = exp(-50*(x-0.3)^2) + 0.1*sin(4*pi*x)\n    def u(x: np.ndarray or float) -> np.ndarray or float:\n        \"\"\"\n        Calculates the value of the target function u at point(s) x.\n        All angles are in radians.\n        \"\"\"\n        return np.exp(-50.0 * (x - 0.3)**2) + 0.1 * np.sin(4.0 * np.pi * x)\n\n    def run_amr(tolerance: float, h_min: float, initial_nodes: np.ndarray) -> int:\n        \"\"\"\n        Executes the AMR algorithm for a given tolerance.\n\n        Args:\n            tolerance: The refinement threshold tau.\n            h_min: The minimum allowed cell size.\n            initial_nodes: A sorted NumPy array of the initial mesh node coordinates.\n\n        Returns:\n            The final number of cells in the mesh after refinement terminates.\n        \"\"\"\n        nodes = np.array(initial_nodes, dtype=np.float64)\n\n        # A practical cap on the number of cells to prevent accidental infinite loops.\n        # The h_min condition guarantees termination, so this is just a safeguard.\n        # Max cells would be 1/h_min = 2^14 = 16384. We set a slightly larger cap.\n        max_nodes = 20000\n\n        while True:\n            if len(nodes) > max_nodes:\n                break\n\n            # List to store the midpoints of cells that need to be refined.\n            midpoints_to_add = []\n\n            # Iterate through each cell in the current mesh.\n            for i in range(len(nodes) - 1):\n                x_i = nodes[i]\n                x_i_plus_1 = nodes[i+1]\n\n                h = x_i_plus_1 - x_i\n\n                # Condition 1: Cell must be larger than the minimum size.\n                if h <= h_min:\n                    continue\n\n                # Calculate the a-posteriori error estimator eta_i.\n                m = (x_i + x_i_plus_1) / 2.0\n                u_m = u(m)\n                u_interp_at_m = (u(x_i) + u(x_i_plus_1)) / 2.0\n                eta_i = 8.0 * np.abs(u_m - u_interp_at_m)\n\n                # Condition 2: Error estimator must exceed the tolerance.\n                if eta_i > tolerance:\n                    midpoints_to_add.append(m)\n\n            # If no cells were flagged for refinement in this pass, the process is complete.\n            if not midpoints_to_add:\n                break\n\n            # Add the new midpoints to the mesh nodes and create a new sorted, unique array.\n            nodes = np.unique(np.concatenate((nodes, midpoints_to_add)))\n\n        # The number of cells is one less than the number of nodes.\n        return len(nodes) - 1\n\n    # Define the test cases from the problem statement.\n    test_tolerances = [10**-1, 10**-2, 10**-3, 10.0]\n    \n    # Define fixed parameters.\n    h_min = 2**-14\n    # Initial mesh: a uniform partition of [0,1] into 4 cells (5 nodes).\n    initial_nodes = np.linspace(0.0, 1.0, 5, dtype=np.float64)\n\n    results = []\n    for tau in test_tolerances:\n        final_cell_count = run_amr(tolerance=tau, h_min=h_min, initial_nodes=initial_nodes)\n        results.append(final_cell_count)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "3223710"}]}