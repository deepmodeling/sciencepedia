{"hands_on_practices": [{"introduction": "The first step in implementing any finite difference method is translating the discrete equations for each grid point into a global matrix system. This practice makes the abstract Crank-Nicolson scheme concrete by having you construct the core matrices, $A$ and $B$, for a simple yet representative system. Mastering this process is fundamental to solving partial differential equations numerically. [@problem_id:2139888]", "problem": "Consider the one-dimensional heat equation, $u_t = \\alpha u_{xx}$, for a function $u(x, t)$ defined on the spatial domain $x \\in [0, L]$ and for time $t \\geq 0$. The equation is subject to homogeneous Dirichlet boundary conditions, $u(0, t) = u(L, t) = 0$.\n\nWe wish to solve this equation numerically using the Crank-Nicolson method. The spatial domain is discretized into a uniform grid with spacing $\\Delta x$, such that there are exactly three interior grid points. Let $\\Delta t$ be the time step. The method results in a matrix system of the form $A\\mathbf{u}^{n+1} = B\\mathbf{u}^{n}$, where $\\mathbf{u}^{k}$ is the column vector of the numerical solution at the three interior grid points at time step $k$.\n\nLet the parameter $\\lambda$ be defined as $\\lambda = \\frac{\\alpha \\Delta t}{(\\Delta x)^2}$.\n\nWhich of the following options correctly identifies the $3 \\times 3$ matrices $A$ and $B$?\n\nA. $A = \\begin{pmatrix} 1+\\lambda & -\\frac{\\lambda}{2} & 0 \\\\ -\\frac{\\lambda}{2} & 1+\\lambda & -\\frac{\\lambda}{2} \\\\ 0 & -\\frac{\\lambda}{2} & 1+\\lambda \\end{pmatrix}$, $B = \\begin{pmatrix} 1-\\lambda & \\frac{\\lambda}{2} & 0 \\\\ \\frac{\\lambda}{2} & 1-\\lambda & \\frac{\\lambda}{2} \\\\ 0 & \\frac{\\lambda}{2} & 1-\\lambda \\end{pmatrix}$\n\nB. $A = \\begin{pmatrix} 1-\\lambda & \\frac{\\lambda}{2} & 0 \\\\ \\frac{\\lambda}{2} & 1-\\lambda & \\frac{\\lambda}{2} \\\\ 0 & \\frac{\\lambda}{2} & 1-\\lambda \\end{pmatrix}$, $B = \\begin{pmatrix} 1+\\lambda & -\\frac{\\lambda}{2} & 0 \\\\ -\\frac{\\lambda}{2} & 1+\\lambda & -\\frac{\\lambda}{2} \\\\ 0 & -\\frac{\\lambda}{2} & 1+\\lambda \\end{pmatrix}$\n\nC. $A = \\begin{pmatrix} 1 & 0 & 0 \\\\ 0 & 1 & 0 \\\\ 0 & 0 & 1 \\end{pmatrix}$, $B = \\begin{pmatrix} 1-2\\lambda & \\lambda & 0 \\\\ \\lambda & 1-2\\lambda & \\lambda \\\\ 0 & \\lambda & 1-2\\lambda \\end{pmatrix}$\n\nD. $A = \\begin{pmatrix} 1+2\\lambda & -\\lambda & 0 \\\\ -\\lambda & 1+2\\lambda & -\\lambda \\\\ 0 & -\\lambda & 1+2\\lambda \\end{pmatrix}$, $B = \\begin{pmatrix} 1 & 0 & 0 \\\\ 0 & 1 & 0 \\\\ 0 & 0 & 1 \\end{pmatrix}$", "solution": "We discretize the spatial interval with uniform spacing $\\Delta x$ and denote interior indices $i=1,2,3$. The homogeneous Dirichlet boundary conditions impose $u_{0}^{n}=0$ and $u_{4}^{n}=0$ for all $n$.\n\nLet $u_{i}^{n}$ approximate $u(x_{i}, t^{n})$. The Crank–Nicolson discretization of $u_{t}=\\alpha u_{xx}$ at interior point $i$ is\n$$\n\\frac{u_{i}^{n+1}-u_{i}^{n}}{\\Delta t}\n=\\frac{\\alpha}{2}\\left(\\frac{u_{i+1}^{n}-2u_{i}^{n}+u_{i-1}^{n}}{(\\Delta x)^{2}}+\\frac{u_{i+1}^{n+1}-2u_{i}^{n+1}+u_{i-1}^{n+1}}{(\\Delta x)^{2}}\\right).\n$$\nWith $\\lambda=\\frac{\\alpha\\Delta t}{(\\Delta x)^{2}}$, multiply both sides by $\\Delta t$ to obtain\n$$\nu_{i}^{n+1}-u_{i}^{n}\n=\\frac{\\lambda}{2}\\left[(u_{i+1}^{n}-2u_{i}^{n}+u_{i-1}^{n})+(u_{i+1}^{n+1}-2u_{i}^{n+1}+u_{i-1}^{n+1})\\right].\n$$\nRearranging to collect the unknown time level $n+1$ on the left and time level $n$ on the right gives\n$$\n\\left(1+\\lambda\\right)u_{i}^{n+1}-\\frac{\\lambda}{2}u_{i+1}^{n+1}-\\frac{\\lambda}{2}u_{i-1}^{n+1}\n=\\left(1-\\lambda\\right)u_{i}^{n}+\\frac{\\lambda}{2}u_{i+1}^{n}+\\frac{\\lambda}{2}u_{i-1}^{n}.\n$$\nBecause the boundary values are zero, no additional boundary terms appear. Writing this system for $i=1,2,3$ in matrix form $A\\mathbf{u}^{n+1}=B\\mathbf{u}^{n}$ with $\\mathbf{u}^{k}=(u_{1}^{k},u_{2}^{k},u_{3}^{k})^{T}$, the matrices are\n$$\nA=\\begin{pmatrix}\n1+\\lambda & -\\frac{\\lambda}{2} & 0 \\\\\n-\\frac{\\lambda}{2} & 1+\\lambda & -\\frac{\\lambda}{2} \\\\\n0 & -\\frac{\\lambda}{2} & 1+\\lambda\n\\end{pmatrix},\\quad\nB=\\begin{pmatrix}\n1-\\lambda & \\frac{\\lambda}{2} & 0 \\\\\n\\frac{\\lambda}{2} & 1-\\lambda & \\frac{\\lambda}{2} \\\\\n0 & \\frac{\\lambda}{2} & 1-\\lambda\n\\end{pmatrix}.\n$$\nThese match option A.", "answer": "$$\\boxed{A}$$", "id": "2139888"}, {"introduction": "A key advantage of the Crank-Nicolson method is its second-order accuracy in time, which offers significant improvements over first-order methods. This exercise guides you through a computational verification of this theoretical property, a standard practice in the validation of numerical schemes. By cleverly using a Fourier mode as the initial condition, spatial discretization errors are eliminated, allowing for a precise measurement of the temporal convergence rate. [@problem_id:3220441]", "problem": "You are asked to verify, by computation, the temporal second-order accuracy of the Crank–Nicolson method (Crank–Nicolson (CN) is the trapezoidal rule in time) for linear constant-coefficient partial differential equations (PDEs) while ensuring that spatial discretization error is negligible. Work on the one-dimensional periodic domain $[0,2\\pi]$ and use a Fourier spectral representation for spatial operators so that each Fourier mode evolves independently and spatial differentiation is exact for the chosen initial data.\n\nStarting point and fundamental base: On a periodic domain, a sufficiently smooth function can be expanded in a Fourier series, and constant-coefficient spatial differential operators are diagonal in the Fourier basis. For any linear time-invariant system $u_t = \\mathcal{L} u$, where $\\mathcal{L}$ is a linear spatial operator with constant coefficients, each Fourier mode amplitude $a_k(t)$ satisfies the ordinary differential equation (ODE) $a_k'(t) = \\lambda_k a_k(t)$, where $\\lambda_k$ is the eigenvalue of $\\mathcal{L}$ for wavenumber $k$. The exact solution for a single mode is $a_k(t) = e^{\\lambda_k t} a_k(0)$. The Crank–Nicolson time discretization for an ODE with continuously differentiable right-hand side has local truncation error of order $\\mathcal{O}(\\Delta t^3)$, leading to a global error of order $\\mathcal{O}(\\Delta t^2)$ in time under standard smoothness assumptions.\n\nYour tasks:\n\n1) Spatial model and diagonalization. Consider the following three PDEs on $[0,2\\pi]$ with periodic boundary conditions and initial condition $u(x,0) = e^{\\mathrm{i} k x}$ for a specified integer mode $k$:\n   - Diffusion equation: $u_t = \\nu u_{xx}$ with diffusivity $\\nu > 0$.\n   - Free Schrödinger equation: $\\mathrm{i} \\psi_t = -\\alpha \\psi_{xx}$ with dispersion coefficient $\\alpha > 0$.\n   - Advection–diffusion equation: $u_t + c u_x = \\nu u_{xx}$ with advection speed $c \\in \\mathbb{R}$ and diffusivity $\\nu > 0$.\n\n   Using Fourier series on $[0,2\\pi]$, derive the associated modal ODE for the amplitude $a_k(t)$ of the Fourier mode $e^{\\mathrm{i} k x}$ in each PDE and identify the modal growth/decay rate $\\lambda_k$ in $a_k'(t) = \\lambda_k a_k(t)$.\n\n2) Time discretization. Apply the Crank–Nicolson discretization in time to the modal ODE $a_k'(t) = \\lambda_k a_k(t)$. Express the one-step update in terms of the previous step $a_k^n$ and time-step size $\\Delta t$ and obtain a closed-form formula for the one-step amplification factor in terms of $\\lambda_k$ and $\\Delta t$. Use this to advance $M$ steps to approximate $a_k(T)$ at time $T$.\n\n3) Error measurement and observed order. For each PDE, perform a temporal refinement study using time-step sizes $\\Delta t = T/M$ for the refinement levels $M \\in \\{10,20,40,80,160\\}$. For each $\\Delta t$, compute the numerical amplitude at time $T$ and compare it to the exact amplitude $e^{\\lambda_k T}$, measuring the absolute error $E(\\Delta t) = \\lvert a_k^{\\text{num}}(T) - e^{\\lambda_k T} \\rvert$. Estimate the observed order $p$ by fitting a straight line to $(\\log(\\Delta t), \\log(E(\\Delta t)))$ via least squares and taking the slope, which should be close to $2$ if the method is second order in time. Because the initial condition is a single Fourier mode exactly represented on the grid and the spatial operator is diagonal in Fourier space, the spatial discretization error for this test is negligible.\n\nTest suite specifications:\n\n- Domain: $[0,2\\pi]$ with periodic boundary conditions.\n- Initial condition for all cases: $u(x,0) = e^{\\mathrm{i} k x}$ with the specified integer $k$ below.\n- Refinement levels: $M \\in \\{10,20,40,80,160\\}$ so that $\\Delta t = T/M$.\n- Cases to test:\n  1) Diffusion: $\\nu = 0.5$, $k = 3$, $T = 1.0$.\n  2) Free Schrödinger: $\\alpha = 0.7$, $k = 4$, $T = 2.0$.\n  3) Advection–diffusion: $c = 2.0$, $\\nu = 0.1$, $k = 5$, $T = 1.5$.\n\nAnswer specification and output format:\n\n- For each case, return the observed order $p$ as a floating-point number computed from the least-squares slope of $\\log(E(\\Delta t))$ versus $\\log(\\Delta t)$.\n- Your program should produce a single line of output containing the three observed orders, in the order listed above, rounded to three decimal places, formatted as a comma-separated Python-style list, for example: \"[2.000,2.001,1.999]\".\n- No physical units are involved in this task. Angles (if any) are in radians by construction due to the domain choice $[0,2\\pi]$.\n\nYour final deliverable must be a complete, runnable program that carries out these computations exactly for the test suite above and prints the results in the required one-line format. No user input or external files are allowed. Use only the specified libraries.", "solution": "The problem statement has been validated and is deemed sound, well-posed, and complete. We now proceed with the solution. The core of this problem is to computationally verify the second-order temporal accuracy of the Crank-Nicolson method for several linear partial differential equations (PDEs). The problem is structured such that spatial discretization errors are eliminated by design, allowing for a pure assessment of the temporal error. This is achieved by using an initial condition that is a single Fourier mode, which is an eigenfunction of the constant-coefficient linear spatial operators involved.\n\n**1. Modal Analysis and Eigenvalue Derivation**\n\nWe consider a solution of the form $u(x,t) = a_k(t) e^{\\mathrm{i} k x}$ on the periodic domain $[0, 2\\pi]$ for an integer wavenumber $k$. The initial condition $u(x,0) = e^{\\mathrm{i} k x}$ implies that the initial amplitude of the $k$-th mode is $a_k(0) = 1$, and all other modal amplitudes are zero. Since the governing PDEs are linear, the modes evolve independently. We can analyze the evolution of the single non-zero mode $a_k(t)$ by substituting the solution form into each PDE.\n\nThe spatial derivatives are:\n$$\n\\frac{\\partial u}{\\partial x} = \\frac{\\partial}{\\partial x} \\left( a_k(t) e^{\\mathrm{i} k x} \\right) = \\mathrm{i} k a_k(t) e^{\\mathrm{i} k x}\n$$\n$$\n\\frac{\\partial^2 u}{\\partial x^2} = \\frac{\\partial^2}{\\partial x^2} \\left( a_k(t) e^{\\mathrm{i} k x} \\right) = (\\mathrm{i} k)^2 a_k(t) e^{\\mathrm{i} k x} = -k^2 a_k(t) e^{\\mathrm{i} k x}\n$$\nThe time derivative is $\\frac{\\partial u}{\\partial t} = a_k'(t) e^{\\mathrm{i} k x}$.\n\nFor each PDE of the form $u_t = \\mathcal{L}u$, substituting the modal form yields $a_k'(t) e^{\\mathrm{i} k x} = \\mathcal{L}(a_k(t) e^{\\mathrm{i} k x}) = a_k(t) \\mathcal{L}(e^{\\mathrm{i} k x})$. Since $e^{\\mathrm{i} k x}$ is an eigenfunction of the spatial operator $\\mathcal{L}$, we have $\\mathcal{L}(e^{\\mathrm{i} k x}) = \\lambda_k e^{\\mathrm{i} k x}$, where $\\lambda_k$ is the eigenvalue. This simplifies the PDE to a linear ordinary differential equation (ODE) for the amplitude $a_k(t)$:\n$$\na_k'(t) = \\lambda_k a_k(t)\n$$\nThe exact solution to this ODE with initial condition $a_k(0)=1$ is $a_k(t) = e^{\\lambda_k t}$.\n\nWe now determine $\\lambda_k$ for each specified PDE.\n\n- **Diffusion equation**: $u_t = \\nu u_{xx}$\n  $a_k'(t) e^{\\mathrm{i} k x} = \\nu (-k^2 a_k(t) e^{\\mathrm{i} k x})$. Dividing by $e^{\\mathrm{i} k x}$ gives $a_k'(t) = (-\\nu k^2) a_k(t)$.\n  Thus, the eigenvalue is $\\lambda_k = -\\nu k^2$.\n\n- **Free Schrödinger equation**: $\\mathrm{i} \\psi_t = -\\alpha \\psi_{xx}$. Let the solution be $\\psi(x,t) = a_k(t) e^{\\mathrm{i} k x}$.\n  The equation is equivalent to $\\psi_t = \\frac{-\\alpha}{\\mathrm{i}} \\psi_{xx} = \\mathrm{i} \\alpha \\psi_{xx}$.\n  $a_k'(t) e^{\\mathrm{i} k x} = \\mathrm{i} \\alpha (-k^2 a_k(t) e^{\\mathrm{i} k x})$. This gives $a_k'(t) = (-\\mathrm{i} \\alpha k^2) a_k(t)$.\n  Thus, the eigenvalue is $\\lambda_k = -\\mathrm{i} \\alpha k^2$.\n  (Note: The problem statement says $\\mathrm{i} \\psi_t = -\\alpha \\psi_{xx}$. Substituting gives $\\mathrm{i} a_k' = -\\alpha (-k^2) a_k = \\alpha k^2 a_k$, so $a_k' = \\frac{\\alpha k^2}{\\mathrm{i}} a_k = -\\mathrm{i} \\alpha k^2 a_k$. The result is the same).\n\n- **Advection–diffusion equation**: $u_t + c u_x = \\nu u_{xx}$, or $u_t = -c u_x + \\nu u_{xx}$.\n  $a_k'(t) e^{\\mathrm{i} k x} = -c (\\mathrm{i} k a_k(t) e^{\\mathrm{i} k x}) + \\nu (-k^2 a_k(t) e^{\\mathrm{i} k x})$.\n  This gives $a_k'(t) = (-\\mathrm{i} c k - \\nu k^2) a_k(t)$.\n  Thus, the eigenvalue is $\\lambda_k = -\\nu k^2 - \\mathrm{i} c k$.\n\n**2. Crank-Nicolson Time Discretization**\n\nThe Crank-Nicolson method is an implicit method for integrating ODEs, equivalent to the trapezoidal rule. For the ODE $a' = \\lambda a$, the discretization over a time step $\\Delta t$ from $t_n$ to $t_{n+1}$ is:\n$$\n\\frac{a^{n+1} - a^n}{\\Delta t} = \\frac{1}{2} \\left( \\lambda a^{n+1} + \\lambda a^n \\right)\n$$\nwhere $a^n \\approx a(t_n)$. We solve for $a^{n+1}$:\n$$\na^{n+1} \\left( 1 - \\frac{\\lambda \\Delta t}{2} \\right) = a^n \\left( 1 + \\frac{\\lambda \\Delta t}{2} \\right)\n$$\nThis gives the explicit update formula for a single step:\n$$\na^{n+1} = \\left( \\frac{1 + \\lambda \\Delta t / 2}{1 - \\lambda \\Delta t / 2} \\right) a^n\n$$\nThe term $G(\\lambda, \\Delta t) = \\frac{1 + \\lambda \\Delta t / 2}{1 - \\lambda \\Delta t / 2}$ is the one-step amplification factor. To advance from time $t=0$ to $T = M \\Delta t$ in $M$ steps, we apply this factor $M$ times. With $a^0 = a_k(0) = 1$, the numerical solution at time $T$ is:\n$$\na_k^{\\text{num}}(T) = a^M = (G(\\lambda_k, \\Delta t))^M a^0 = \\left( \\frac{1 + \\lambda_k \\Delta t / 2}{1 - \\lambda_k \\Delta t / 2} \\right)^M\n$$\n\n**3. Error Analysis and Observed Order of Accuracy**\n\nThe method's global error is expected to be second-order in time, meaning the error $E(\\Delta t)$ at a fixed time $T$ behaves as $E(\\Delta t) \\approx C (\\Delta t)^p$ for some constant $C$ and order $p \\approx 2$. The absolute error is defined as:\n$$\nE(\\Delta t) = \\lvert a_k^{\\text{num}}(T) - a_k(T) \\rvert = \\left| \\left( \\frac{1 + \\lambda_k \\Delta t / 2}{1 - \\lambda_k \\Delta t / 2} \\right)^M - e^{\\lambda_k T} \\right|\n$$\nTo determine the observed order $p$, we take the logarithm of the error relation:\n$$\n\\log(E(\\Delta t)) \\approx \\log(C) + p \\log(\\Delta t)\n$$\nThis shows a linear relationship between $\\log(E)$ and $\\log(\\Delta t)$, with the slope being the order of accuracy $p$. We will compute the error for a sequence of time steps $\\Delta t_i = T/M_i$ where $M_i \\in \\{10, 20, 40, 80, 160\\}$. Then, we perform a linear least-squares fit to the data points $(\\log(\\Delta t_i), \\log(E_i))$ to find the slope $p$.\n\nThe computational procedure is as follows for each test case:\n1.  Calculate the eigenvalue $\\lambda_k$ using the given parameters.\n2.  Define the set of refinement levels $M_i$.\n3.  For each $M_i$, calculate the time step $\\Delta t_i = T/M_i$.\n4.  Compute the numerical solution $a_k^{\\text{num}}(T) = \\left( \\frac{1 + \\lambda_k \\Delta t_i / 2}{1 - \\lambda_k \\Delta t_i / 2} \\right)^{M_i}$.\n5.  Compute the exact solution $a_k(T) = e^{\\lambda_k T}$.\n6.  Calculate the absolute error $E_i = |a_k^{\\text{num}}(T) - a_k(T)|$.\n7.  Form two vectors: $x = [\\log(\\Delta t_i)]$ and $y = [\\log(E_i)]$.\n8.  Calculate the slope $p$ of the best-fit line for $(x, y)$, which is the observed order. This will be accomplished using `numpy.polyfit`.\nThe calculations will be performed for the three specified cases.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef calculate_observed_order(lambda_k, T, M_levels):\n    \"\"\"\n    Computes the observed order of accuracy for the Crank-Nicolson method.\n\n    Args:\n        lambda_k (complex): The eigenvalue of the spatial operator for mode k.\n        T (float): The final time for the simulation.\n        M_levels (np.ndarray): An array of integers representing the number of time steps.\n\n    Returns:\n        float: The observed order of accuracy, p.\n    \"\"\"\n    delta_ts = T / M_levels\n    errors = np.zeros_like(delta_ts, dtype=float)\n\n    # Calculate the exact solution at time T\n    exact_solution = np.exp(lambda_k * T)\n\n    for i, M in enumerate(M_levels):\n        dt = delta_ts[i]\n        \n        # Calculate the one-step amplification factor\n        z = lambda_k * dt / 2.0\n        amplification_factor = (1.0 + z) / (1.0 - z)\n        \n        # Compute the numerical solution at time T\n        # Initial condition a_k(0) = 1 is implicit\n        numerical_solution = amplification_factor**M\n        \n        # Compute the absolute error\n        errors[i] = np.abs(numerical_solution - exact_solution)\n\n    # Perform a least-squares fit on the log-log data to find the slope\n    log_delta_ts = np.log(delta_ts)\n    log_errors = np.log(errors)\n    \n    # np.polyfit returns [slope, intercept] for degree 1\n    p, _ = np.polyfit(log_delta_ts, log_errors, 1)\n    \n    return p\n\ndef solve():\n    \"\"\"\n    Main function to run the test suite and print the results.\n    \"\"\"\n    # Refinement levels for the temporal grid\n    M_levels = np.array([10, 20, 40, 80, 160])\n    \n    # --- Test Case 1: Diffusion Equation ---\n    # u_t = nu * u_xx\n    # Parameters: nu = 0.5, k = 3, T = 1.0\n    nu1 = 0.5\n    k1 = 3\n    T1 = 1.0\n    # Eigenvalue: lambda_k = -nu * k^2\n    lambda_k1 = -nu1 * k1**2\n    p1 = calculate_observed_order(lambda_k1, T1, M_levels)\n\n    # --- Test Case 2: Free Schrödinger Equation ---\n    # i * psi_t = -alpha * psi_xx  =>  psi_t = -i * alpha * psi_xx\n    # Parameters: alpha = 0.7, k = 4, T = 2.0\n    alpha2 = 0.7\n    k2 = 4\n    T2 = 2.0\n    # Eigenvalue: lambda_k = -i * alpha * k^2\n    lambda_k2 = -1j * alpha2 * k2**2\n    p2 = calculate_observed_order(lambda_k2, T2, M_levels)\n\n    # --- Test Case 3: Advection-Diffusion Equation ---\n    # u_t + c * u_x = nu * u_xx  => u_t = -c * u_x + nu * u_xx\n    # Parameters: c = 2.0, nu = 0.1, k = 5, T = 1.5\n    c3 = 2.0\n    nu3 = 0.1\n    k3 = 5\n    T3 = 1.5\n    # Eigenvalue: lambda_k = -nu * k^2 - i * c * k\n    lambda_k3 = -nu3 * k3**2 - 1j * c3 * k3\n    p3 = calculate_observed_order(lambda_k3, T3, M_levels)\n\n    results = [p1, p2, p3]\n\n    # Format the output as a list of strings with 3 decimal places\n    formatted_results = [f'{p:.3f}' for p in results]\n    \n    # Final print statement in the exact required format.\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```", "id": "3220441"}, {"introduction": "Unconditional stability, a hallmark of the Crank-Nicolson method, guarantees that the numerical solution will not grow without bound, but it does not guarantee physical realism. This advanced practice challenges you to investigate one of the method's most famous limitations: the generation of spurious, non-physical oscillations when dealing with non-smooth data, such as discontinuities. You will design a numerical experiment to deliberately provoke and quantify these artifacts, gaining a deeper, more critical understanding of the method's practical behavior. [@problem_id:3220540]", "problem": "Consider the one-dimensional heat equation on a finite interval with homogeneous Dirichlet boundary conditions. Let $u(x,t)$ satisfy $u_t = \\nu u_{xx}$ on $x \\in (0,1)$, $t \\ge 0$, with $u(0,t) = 0$, $u(1,t) = 0$, and a discontinuous initial condition $u(x,0) = u_0(x)$ that takes only the values $0$ or $1$. The goal is to use the Crank–Nicolson method to deliberately generate and analyze unphysical oscillations caused by a discontinuity under large time steps.\n\nStarting from the partial differential equation and standard definitions of the first derivative in time and second derivative in space, do the following:\n\n1) Discretize the spatial domain into $M$ interior points with uniform spacing $\\Delta x = 1/(M+1)$, and approximate the second derivative by the central finite difference operator on the interior grid. Use the trapezoidal (Crank–Nicolson) rule in time with time step $\\Delta t > 0$ to obtain a linear system that advances $u^n$ to $u^{n+1}$ at each time step. Define the nondimensional parameter $\\mu = \\nu \\Delta t / \\Delta x^2$.\n\n2) Design, on the discrete grid, a discontinuous initial condition $u^0$ that is a binary vector ($0$-$1$ valued) with a single jump discontinuity such that it maximizes the amplitude of unphysical oscillations produced by the Crank–Nicolson method after a single time step. The design space is restricted to the family of discrete Heaviside steps of the form\n- $u_i^0 = 1$ for $i \\le m$ and $u_i^0 = 0$ for $i > m$, where $i \\in \\{1,2,\\dots,M\\}$ indexes interior points and $m \\in \\{1,2,\\dots,M-1\\}$.\nYour task is to choose $m$ (and thus the step location) in a way that maximizes oscillatory artifacts for a given $M$. The choice must be justified from first principles in your solution, but your program must implement a single, fixed design that embodies your justification.\n\n3) Implement the Crank–Nicolson time step using the tridiagonal system arising from your discretization, with the homogeneous Dirichlet boundary conditions enforced at $x=0$ and $x=1$. Advance the solution by exactly one time step from your designed $u^0$ to obtain $u^1$ for each test case defined below.\n\n4) Quantify unphysical oscillations using the following two scalars computed from $u^1$:\n- The undershoot magnitude $U = \\max(0,\\,-\\min_i u_i^1)$.\n- The overshoot magnitude $O = \\max(0,\\,\\max_i u_i^1 - 1)$.\nThese values must be nonnegative real numbers.\n\nUse the following fixed parameters for all tests:\n- $\\nu = 1$.\n- $M = 400$ interior points.\n- The grid is the $M$ interior points of a uniform partition of $[0,1]$.\n- Use exactly one time step and compute $u^1$ from $u^0$ for each parameter set.\n\nTest suite (varying the nondimensional time step $\\mu$):\n- Case A (subthreshold, expected small or no oscillations): $\\mu = 0.2$.\n- Case B (just above the threshold, expected visible oscillations): $\\mu = 0.6$.\n- Case C (highly stiff, expected strong oscillations): $\\mu = 5.0$.\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets. For each case, output the undershoot and overshoot in that order, so the final output must be the flattened list\n$[U_A, O_A, U_B, O_B, U_C, O_C]$.\n\nAll numerical values are nondimensional; no physical unit conversion is required. Angles are not involved. Percentages are not involved; any fractional quantities must be represented as decimal numbers. The result list elements must be printed as real numbers (floating-point).", "solution": "The problem requires the analysis of unphysical oscillations generated by the Crank-Nicolson method when applied to the one-dimensional heat equation with a discontinuous initial condition. The solution involves deriving the numerical scheme, designing an initial condition to maximize oscillatory artifacts, implementing the scheme for one time step, and quantifying the resulting undershoot and overshoot.\n\n### Step 1: Discretization and Crank-Nicolson Scheme\n\nThe governing partial differential equation (PDE) is the heat equation:\n$$\n\\frac{\\partial u}{\\partial t} = \\nu \\frac{\\partial^2 u}{\\partial x^2}\n$$\non the domain $x \\in (0, 1)$ and $t \\ge 0$, with a diffusion coefficient $\\nu$. The boundary conditions are homogeneous Dirichlet conditions:\n$$\nu(0, t) = 0, \\quad u(1, t) = 0 \\quad \\text{for } t \\ge 0.\n$$\nThe spatial domain $(0, 1)$ is discretized into $M$ interior points $x_i = i \\Delta x$ for $i = 1, 2, \\dots, M$, where the grid spacing is $\\Delta x = 1/(M+1)$. The boundary points are $x_0 = 0$ and $x_{M+1} = 1$. Let $u_i(t)$ be the approximation of $u(x_i, t)$.\n\nThe second spatial derivative at an interior point $x_i$ is approximated using the second-order central difference formula:\n$$\n\\frac{\\partial^2 u}{\\partial x^2}\\bigg|_{x=x_i} \\approx \\frac{u_{i+1}(t) - 2u_i(t) + u_{i-1}(t)}{\\Delta x^2}\n$$\nApplying this to the PDE yields a system of ordinary differential equations (ODEs), one for each interior point:\n$$\n\\frac{du_i}{dt} = \\frac{\\nu}{\\Delta x^2} (u_{i-1} - 2u_i + u_{i+1})\n$$\n\nThe Crank-Nicolson method applies the trapezoidal rule for time integration. Let $u_i^n$ be the approximation of $u(x_i, t_n)$ at time $t_n = n \\Delta t$. The time derivative is approximated as $(u_i^{n+1} - u_i^n) / \\Delta t$. The spatial derivative term is averaged between times $t_n$ and $t_{n+1}$:\n$$\n\\frac{u_i^{n+1} - u_i^n}{\\Delta t} = \\frac{\\nu}{2} \\left[ \\left(\\frac{u_{i+1}^{n+1} - 2u_i^{n+1} + u_{i-1}^{n+1}}{\\Delta x^2}\\right) + \\left(\\frac{u_{i+1}^{n} - 2u_i^{n} + u_{i-1}^{n}}{\\Delta x^2}\\right) \\right]\n$$\nIntroducing the non-dimensional parameter $\\mu = \\nu \\Delta t / \\Delta x^2$, we can rearrange the equation to separate terms at time step $n+1$ (unknowns) and $n$ (knowns):\n$$\nu_i^{n+1} - \\frac{\\mu}{2}(u_{i-1}^{n+1} - 2u_i^{n+1} + u_{i+1}^{n+1}) = u_i^n + \\frac{\\mu}{2}(u_{i-1}^n - 2u_i^n + u_{i+1}^n)\n$$\nCollecting terms for each grid point $i = 1, \\dots, M$:\n$$\n-\\frac{\\mu}{2}u_{i-1}^{n+1} + (1+\\mu)u_i^{n+1} - \\frac{\\mu}{2}u_{i+1}^{n+1} = \\frac{\\mu}{2}u_{i-1}^n + (1-\\mu)u_i^n + \\frac{\\mu}{2}u_{i+1}^n\n$$\nThe boundary conditions $u_0^n = u_0^{n+1} = 0$ and $u_{M+1}^n = u_{M+1}^{n+1} = 0$ are incorporated at $i=1$ and $i=M$.\nThis can be written as a linear system of equations $A \\mathbf{u}^{n+1} = B \\mathbf{u}^n$, where $\\mathbf{u}^n = [u_1^n, u_2^n, \\dots, u_M^n]^T$ is the vector of solutions at time $t_n$. The matrices $A$ and $B$ are $M \\times M$ tridiagonal matrices:\n$$\nA = \\begin{pmatrix}\n1+\\mu & -\\frac{\\mu}{2} & & & \\\\\n-\\frac{\\mu}{2} & 1+\\mu & -\\frac{\\mu}{2} & & \\\\\n& \\ddots & \\ddots & \\ddots & \\\\\n& & -\\frac{\\mu}{2} & 1+\\mu & -\\frac{\\mu}{2} \\\\\n& & & -\\frac{\\mu}{2} & 1+\\mu\n\\end{pmatrix}\n$$\n$$\nB = \\begin{pmatrix}\n1-\\mu & \\frac{\\mu}{2} & & & \\\\\n\\frac{\\mu}{2} & 1-\\mu & \\frac{\\mu}{2} & & \\\\\n& \\ddots & \\ddots & \\ddots & \\\\\n& & \\frac{\\mu}{2} & 1-\\mu & \\frac{\\mu}{2} \\\\\n& & & \\frac{\\mu}{2} & 1-\\mu\n\\end{pmatrix}\n$$\nTo advance the solution from $\\mathbf{u}^0$ to $\\mathbf{u}^1$, we first compute the right-hand-side vector $\\mathbf{d} = B \\mathbf{u}^0$ and then solve the linear system $A \\mathbf{u}^1 = \\mathbf{d}$.\n\n### Step 2: Design of the Initial Condition\n\nThe problem asks to design a discrete Heaviside initial condition, $\\mathbf{u}^0$, to maximize the unphysical oscillations produced after one time step. The form is specified as $u_i^0 = 1$ for $i \\le m$ and $u_i^0 = 0$ for $i > m$, where $m \\in \\{1, \\dots, M-1\\}$.\n\nThe Crank-Nicolson method is $L_2$-stable for all $\\mu > 0$, but it is not free from spurious oscillations, particularly for non-smooth initial data and large $\\mu$. The amplification factor for the $k$-th eigenmode of the discrete Laplacian, $\\phi_k(i) = \\sin(k \\pi x_i)$, is given by:\n$$\ng_k = \\frac{1 - 2\\mu \\sin^2(k\\pi\\Delta x/2)}{1 + 2\\mu \\sin^2(k\\pi\\Delta x/2)}\n$$\nFor large $\\mu$, the amplification factor $g_k$ for high-frequency modes (large $k$) approaches $-1$. This means that high-frequency components in the initial condition are not damped but are inverted and persist, causing oscillations. The highest frequency mode ($k=M$) corresponds to a checkerboard-like pattern.\n\nA step discontinuity is rich in high-frequency components. To maximize the resulting oscillations in $\\mathbf{u}^1 = A^{-1}B\\mathbf{u}^0$, we should place this discontinuity where its interaction with the scheme's dynamics is most pronounced and least affected by boundary damping. The homogeneous Dirichlet boundary conditions enforce $u=0$ at the ends of the domain, which has a local damping effect on oscillatory behavior. To observe the numerical artifact in its most uninhibited form, the discontinuity should be placed as far as possible from both boundaries.\n\nThe center of the spatial domain, $x=0.5$, is the point furthest from both $x=0$ and $x=1$. On our discrete grid of $M$ interior points, this corresponds to the midpoint of the indices $\\{1, \\dots, M\\}$. For $M=400$, the midpoint is between indices $i=200$ and $i=201$. Therefore, setting the jump at this location maximizes its \"distance\" from boundary influences.\n\nThe chosen design is to set the discontinuity between points $i=200$ and $i=201$. This corresponds to choosing $m=M/2=200$.\nThus, the initial condition vector $\\mathbf{u}^0$ is defined as:\n$$\nu_i^0 = \\begin{cases} 1 & \\text{if } 1 \\le i \\le 200 \\\\ 0 & \\text{if } 201 \\le i \\le 400 \\end{cases}\n$$\nThis placement ensures that the high-frequency content introduced by the step is maximally excited symmetrically within the domain's interior, leading to the strongest oscillatory response from the scheme.\n\n### Step 3: Implementation of a Single Time Step\n\nGiven $\\mathbf{u}^0$ and $\\mu$, we compute $\\mathbf{u}^1$ by solving $A\\mathbf{u}^1 = \\mathbf{d}$, where $\\mathbf{d} = B \\mathbf{u}^0$.\n\n1.  **Construct $\\mathbf{d}$**: The components $d_i$ are computed using the formula for the action of $B$ on $\\mathbf{u}^0$.\n    $$ d_i = \\frac{\\mu}{2}u_{i-1}^0 + (1-\\mu)u_i^0 + \\frac{\\mu}{2}u_{i+1}^0 $$\n    with boundary conditions $u_0^0=0$ and $u_{M+1}^0=0$. Due to the step form of $\\mathbf{u}^0$, most elements of $\\mathbf{d}$ will be constant, with non-trivial values appearing only around the jump at $i=m=200$. Specifically:\n    - For $i < 200$: $d_i = \\frac{\\mu}{2}(1) + (1-\\mu)(1) + \\frac{\\mu}{2}(1) = 1$.\n    - For $i = 200$: $d_{200} = \\frac{\\mu}{2}(1) + (1-\\mu)(1) + \\frac{\\mu}{2}(0) = 1-\\frac{\\mu}{2}$.\n    - For $i = 201$: $d_{201} = \\frac{\\mu}{2}(1) + (1-\\mu)(0) + \\frac{\\mu}{2}(0) = \\frac{\\mu}{2}$.\n    - For $i > 201$: $d_i = \\frac{\\mu}{2}(0) + (1-\\mu)(0) + \\frac{\\mu}{2}(0) = 0$.\n    (Special care is taken for $i=1$ with $u_0^0=0$, but since $u_1^0=1$, $d_1$ remains $1$.)\n\n2.  **Solve $A\\mathbf{u}^1 = \\mathbf{d}$**: The matrix $A$ is a symmetric positive-definite tridiagonal matrix. The most efficient method for solving such a system is the Thomas algorithm (a special case of Gaussian elimination for tridiagonal systems). This algorithm has a linear time complexity $\\mathcal{O}(M)$ and is numerically stable for this class of matrix. The algorithm consists of a forward elimination pass to modify the matrix coefficients and the right-hand side, followed by a backward substitution pass to find the solution vector $\\mathbf{u}^1$.\n\n### Step 4: Quantifying Oscillations\n\nAfter computing the solution vector $\\mathbf{u}^1$ for each value of $\\mu$ in the test suite, we quantify the unphysical oscillations using the specified metrics. The initial state is bounded by $0 \\le u_i^0 \\le 1$. By the maximum principle, the exact solution to the heat equation should also remain within these bounds. Any value in $\\mathbf{u}^1$ outside the interval $[0, 1]$ is a numerical artifact.\n\n-   **Undershoot ($U$)**: The maximum magnitude of any value falling below the physical minimum of $0$.\n    $$ U = \\max(0, -\\min_i u_i^1) $$\n-   **Overshoot ($O$)**: The maximum magnitude of any value exceeding the physical maximum of $1$.\n    $$ O = \\max(0, \\max_i u_i^1 - 1) $$\n\nThese two scalars will be computed for each of the three test cases (A, B, C) corresponding to $\\mu = 0.2, 0.6, 5.0$. The expected result is that as $\\mu$ increases, the values of $U$ and $O$ will increase, reflecting more severe oscillations. For $\\mu < 0.5$, oscillations are typically minimal or non-existent. For $\\mu > 0.5$, they become apparent. For large $\\mu$, they are significant.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef thomas_solver(a, b, c, d):\n    \"\"\"\n    Solves a tridiagonal system of equations Ax = d using the Thomas algorithm.\n    a: sub-diagonal vector (length n-1)\n    b: main diagonal vector (length n)\n    c: super-diagonal vector (length n-1)\n    d: right-hand side vector (length n)\n    \"\"\"\n    n = len(d)\n    if n == 0:\n        return np.array([])\n    if n == 1:\n        return np.array([d[0] / b[0]])\n\n    # Create copies to avoid modifying input arrays\n    c_prime = np.zeros(n)\n    d_prime = np.zeros(n)\n    x = np.zeros(n)\n\n    # Forward elimination\n    c_prime[0] = c[0] / b[0]\n    d_prime[0] = d[0] / b[0]\n    for i in range(1, n - 1):\n        denominator = b[i] - a[i - 1] * c_prime[i - 1]\n        c_prime[i] = c[i] / denominator\n        d_prime[i] = (d[i] - a[i - 1] * d_prime[i - 1]) / denominator\n    \n    # Last element of d_prime\n    denominator = b[n - 1] - a[n - 2] * c_prime[n - 2]\n    d_prime[n-1] = (d[n - 1] - a[n - 2] * d_prime[n - 2]) / denominator\n\n    # Backward substitution\n    x[n - 1] = d_prime[n - 1]\n    for i in range(n - 2, -1, -1):\n        x[i] = d_prime[i] - c_prime[i] * x[i + 1]\n\n    return x\n\ndef run_crank_nicolson_step(M, mu):\n    \"\"\"\n    Performs one step of the Crank-Nicolson method for the 1D heat equation.\n    \n    Args:\n        M (int): Number of interior grid points.\n        mu (float): Nondimensional parameter nu * dt / dx^2.\n        \n    Returns:\n        tuple: (undershoot, overshoot)\n    \"\"\"\n    # 1. Design the initial condition u0\n    # The jump is placed at the center of the grid to maximize oscillations.\n    m = M // 2\n    u0 = np.zeros(M)\n    # Python's slicing u0[:m] modifies indices 0 to m-1, which corresponds\n    # to grid points i=1 to m. For m=200, this is points 1 to 200.\n    u0[:m] = 1.0\n\n    # 2. Construct the right-hand side vector d = B * u0\n    d = np.zeros(M)\n    \n    # General interior points using vectorization\n    if M > 2:\n        d[1:-1] = (mu / 2) * u0[:-2] + (1 - mu) * u0[1:-1] + (mu / 2) * u0[2:]\n\n    # Boundary points (incorporating u_(-1) = 0 and u_(M) = 0)\n    # Using 0-based indexing for arrays u0[0]...u0[M-1]\n    # For i=1 (index 0): d[0] = (mu/2)*u_0 + (1-mu)*u_1 + (mu/2)*u_2\n    # with u_0=0 => d[0] = (1-mu)*u_1 + (mu/2)*u_2\n    if M > 0:\n        d[0] = (1 - mu) * u0[0] + (mu / 2) * (u0[1] if M > 1 else 0)\n    \n    # For i=M (index M-1): d[M-1] = (mu/2)*u_{M-1} + (1-mu)*u_M + (mu/2)*u_{M+1}\n    # with u_{M+1}=0 => d[M-1] = (mu/2)*u_{M-1} + (1-mu)*u_M\n    if M > 1:\n        d[M - 1] = (mu / 2) * u0[M - 2] + (1 - mu) * u0[M - 1]\n\n    # 3. Define the tridiagonal matrix A and solve A * u1 = d\n    # A = tridiag(-mu/2, 1+mu, -mu/2)\n    sub_diag_a = np.full(M - 1, -mu / 2)\n    main_diag_b = np.full(M, 1 + mu)\n    super_diag_c = np.full(M - 1, -mu / 2)\n\n    u1 = thomas_solver(sub_diag_a, main_diag_b, super_diag_c, d)\n\n    # 4. Quantify oscillations\n    undershoot = max(0.0, -np.min(u1)) if u1.size > 0 else 0.0\n    overshoot = max(0.0, np.max(u1) - 1.0) if u1.size > 0 else 0.0\n    \n    return undershoot, overshoot\n\ndef solve():\n    \"\"\"\n    Main function to run the test suite and print results.\n    \"\"\"\n    # Fixed parameters from the problem statement\n    M = 400\n    \n    # Test cases for the nondimensional time step mu\n    test_cases = [\n        0.2,  # Case A: subthreshold\n        0.6,  # Case B: just above threshold\n        5.0,  # Case C: highly stiff\n    ]\n\n    results = []\n    for mu in test_cases:\n        U, O = run_crank_nicolson_step(M=M, mu=mu)\n        results.append(U)\n        results.append(O)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(f'{x:.8f}' for x in results)}]\")\n\nsolve()\n\n```", "id": "3220540"}]}