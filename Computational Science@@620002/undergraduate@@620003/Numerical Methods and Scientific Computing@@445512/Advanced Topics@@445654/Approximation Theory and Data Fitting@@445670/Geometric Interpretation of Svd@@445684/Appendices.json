{"hands_on_practices": [{"introduction": "To build our intuition, we'll start with a very simple and familiar linear transformation: one that swaps the $x$ and $y$ coordinates. Geometrically, this is a reflection across the line $y=x$. By calculating the Singular Value Decomposition (SVD) for this transformation, we can see the fundamental 'rotation-stretch-rotation' structure in one of its clearest forms and directly connect the SVD components to the action on the unit circle [@problem_id:3234632].", "problem": "Consider the linear transformation in two dimensions that swaps the coordinates, represented by the matrix\n$$\nA=\\begin{pmatrix}0 & 1 \\\\ 1 & 0\\end{pmatrix}.\n$$\nUsing only foundational definitions of orthogonality, eigenvalues, and the geometric meaning of the Singular Value Decomposition (SVD), analyze the action of this transformation on the unit circle and determine an admissible SVD.\n\nSpecifically:\n- Determine the eigenvalues of $A^{\\mathsf T}A$ and use them to identify the singular values of $A$.\n- Construct one valid choice of orthogonal matrices $U$ and $V$ and a diagonal matrix $\\Sigma$ with nonnegative diagonal entries such that $A=U\\Sigma V^{\\mathsf T}$.\n- Explain, in geometric terms, how $A$ maps the unit circle $\\{x\\in\\mathbb{R}^{2}:\\|x\\|_{2}=1\\}$, making precise the directions and lengths of the principal axes of the image.\n\nFinally, let $S$ denote the sum of the squares of the singular values of $A$. Report the exact value of $S$ as your final answer. No rounding is required. The final answer must be a single real number with no units.", "solution": "The problem statement is evaluated as valid. It is a well-posed and self-contained problem in linear algebra, grounded in the standard theory of singular value decomposition. All provided information is consistent and sufficient to derive a unique solution for the requested value.\n\nThe analysis of the linear transformation represented by the matrix $A=\\begin{pmatrix}0 & 1 \\\\ 1 & 0\\end{pmatrix}$ proceeds as follows.\n\nFirst, we determine the singular values of $A$. The singular values, denoted $\\sigma_i$, are defined as the square roots of the eigenvalues of the matrix $A^{\\mathsf T}A$. The matrix $A$ is symmetric, so its transpose $A^{\\mathsf T}$ is equal to $A$.\n$$\nA^{\\mathsf T}A = A^2 = \\begin{pmatrix}0 & 1 \\\\ 1 & 0\\end{pmatrix} \\begin{pmatrix}0 & 1 \\\\ 1 & 0\\end{pmatrix} = \\begin{pmatrix}0\\cdot0+1\\cdot1 & 0\\cdot1+1\\cdot0 \\\\ 1\\cdot0+0\\cdot1 & 1\\cdot1+0\\cdot0\\end{pmatrix} = \\begin{pmatrix}1 & 0 \\\\ 0 & 1\\end{pmatrix} = I\n$$\nThe matrix $A^{\\mathsf T}A$ is the $2 \\times 2$ identity matrix, $I$. The eigenvalues of the identity matrix are found by solving the characteristic equation $\\det(I - \\lambda I) = 0$.\n$$\n\\det\\begin{pmatrix}1-\\lambda & 0 \\\\ 0 & 1-\\lambda\\end{pmatrix} = (1-\\lambda)^2 = 0\n$$\nThis equation yields a repeated eigenvalue $\\lambda_1 = \\lambda_2 = 1$. The singular values are the square roots of these eigenvalues. By convention, they are ordered non-increasingly.\n$$\n\\sigma_1 = \\sqrt{\\lambda_1} = \\sqrt{1} = 1\n$$\n$$\n\\sigma_2 = \\sqrt{\\lambda_2} = \\sqrt{1} = 1\n$$\nThe singular values of $A$ are $\\sigma_1 = 1$ and $\\sigma_2 = 1$.\n\nNext, we construct an admissible Singular Value Decomposition (SVD) of $A$, which is a factorization of the form $A = U\\Sigma V^{\\mathsf T}$, where $U$ and $V$ are orthogonal matrices and $\\Sigma$ is a diagonal matrix containing the singular values.\n\nThe matrix $\\Sigma$ is constructed by placing the singular values on its main diagonal:\n$$\n\\Sigma = \\begin{pmatrix}\\sigma_1 & 0 \\\\ 0 & \\sigma_2\\end{pmatrix} = \\begin{pmatrix}1 & 0 \\\\ 0 & 1\\end{pmatrix} = I\n$$\nThe matrix $V$ contains as its columns, $\\{v_i\\}$, an orthonormal set of eigenvectors of $A^{\\mathsf T}A$. Since $A^{\\mathsf T}A = I$, any vector in $\\mathbb{R}^2$ is an eigenvector corresponding to the eigenvalue $\\lambda=1$. Thus, any orthonormal basis for $\\mathbb{R}^2$ can form the columns of $V$. We make the simplest choice, the standard basis:\n$$\nv_1 = \\begin{pmatrix}1 \\\\ 0\\end{pmatrix}, \\quad v_2 = \\begin{pmatrix}0 \\\\ 1\\end{pmatrix}\n$$\nThis gives the matrix $V$:\n$$\nV = \\begin{pmatrix}1 & 0 \\\\ 0 & 1\\end{pmatrix} = I\n$$\nThe matrix $U$ has columns, $\\{u_i\\}$, which are determined by the relation $u_i = \\frac{1}{\\sigma_i}Av_i$.\nFor $i=1$:\n$$\nu_1 = \\frac{1}{\\sigma_1}Av_1 = \\frac{1}{1}\\begin{pmatrix}0 & 1 \\\\ 1 & 0\\end{pmatrix}\\begin{pmatrix}1 \\\\ 0\\end{pmatrix} = \\begin{pmatrix}0 \\\\ 1\\end{pmatrix}\n$$\nFor $i=2$:\n$$\nu_2 = \\frac{1}{\\sigma_2}Av_2 = \\frac{1}{1}\\begin{pmatrix}0 & 1 \\\\ 1 & 0\\end{pmatrix}\\begin{pmatrix}0 \\\\ 1\\end{pmatrix} = \\begin{pmatrix}1 \\\\ 0\\end{pmatrix}\n$$\nThe matrix $U$ is therefore:\n$$\nU = \\begin{pmatrix}u_1 & u_2\\end{pmatrix} = \\begin{pmatrix}0 & 1 \\\\ 1 & 0\\end{pmatrix} = A\n$$\nBoth $V=I$ and $U=A$ are orthogonal matrices, as required ($V^{\\mathsf T}V = I^{\\mathsf T}I = I$ and $U^{\\mathsf T}U = A^{\\mathsf T}A = I$).\nThus, a valid SVD for $A$ is $A = U\\Sigma V^{\\mathsf T} = A I I^{\\mathsf T} = A$.\n\nNow we provide the geometric interpretation. The SVD decomposes the transformation $A$ into three fundamental geometric actions: a rotation/reflection ($V^{\\mathsf T}$), a scaling ($\\Sigma$), and another rotation/reflection ($U$). The action of $A$ on the unit circle, $\\{x \\in \\mathbb{R}^2 : \\|x\\|_2=1\\}$, can be visualized through these steps.\n1.  **Action of $V^{\\mathsf T}$**: Since we chose $V=I$, $V^{\\mathsf T}=I$. This is the identity transformation. It leaves every vector on the unit circle unchanged. The columns of $V$, $v_1$ and $v_2$, are the principal input directions, which in this case are the standard basis vectors $e_1 = (1,0)^{\\mathsf T}$ and $e_2 = (0,1)^{\\mathsf T}$.\n2.  **Action of $\\Sigma$**: Since $\\Sigma=I$, this is a scaling operation where the scaling factors along the principal axes are both $1$. This transformation also maps the unit circle to itself, without any stretching or compression. The image after this step is a circle of radius $1$.\n3.  **Action of $U$**: The matrix $U=A$ acts on the result. The transformation $x' = Ax$ where $x=(x_1, x_2)^{\\mathsf T}$ gives $x' = (x_2, x_1)^{\\mathsf T}$. This corresponds to a reflection across the line $y=x$. This reflection maps the unit circle to itself.\n\nIn summary, the transformation $A$ is a reflection across the line $y=x$. For any point on the unit circle, its image under $A$ is also on the unit circle. The image of the entire unit circle is the unit circle itself.\nThe SVD provides the principal axes of the image ellipse. The directions of these axes are given by the left singular vectors (the columns of $U$), and their lengths are the corresponding singular values.\n- The first principal axis has direction $u_1 = (0, 1)^{\\mathsf T}$ and length $\\sigma_1=1$. This is a vector of unit length along the $y$-axis.\n- The second principal axis has direction $u_2 = (1, 0)^{\\mathsf T}$ and length $\\sigma_2=1$. This is a vector of unit length along the $x$-axis.\nThese axes confirm that the image is a unit circle centered at the origin.\n\nFinally, we are asked to find $S$, the sum of the squares of the singular values of $A$.\n$$\nS = \\sigma_1^2 + \\sigma_2^2\n$$\nUsing the calculated singular values $\\sigma_1=1$ and $\\sigma_2=1$:\n$$\nS = 1^2 + 1^2 = 1 + 1 = 2\n$$\nThis value is also equal to the squared Frobenius norm of $A$, $\\|A\\|_F^2 = \\sum_{i,j} |a_{ij}|^2 = 0^2+1^2+1^2+0^2=2$, and to the trace of $A^{\\mathsf T}A$, $\\text{tr}(I)=2$, as expected from the theory.", "answer": "$$\\boxed{2}$$", "id": "3234632"}, {"introduction": "Not all transformations preserve the dimensionality of a space. This next practice explores what happens when a transformation is rank-deficient, such as a projection that flattens a 2D plane onto a 1D line. By analyzing the SVD of a projection matrix, we can see how a singular value of zero leads to the collapse of a dimension, transforming the unit circle into a degenerate ellipseâ€”a line segment [@problem_id:3234717].", "problem": "Consider the linear map $P:\\mathbb{R}^{2}\\to\\mathbb{R}^{2}$ that orthogonally projects every vector onto the line $y=2x$. Starting from the definitions of the Euclidean inner product, orthogonal projection onto a one-dimensional subspace, and the Singular Value Decomposition (SVD) as a factorization $A=U\\Sigma V^{\\top}$ with $U$ and $V$ orthogonal and $\\Sigma$ diagonal with nonnegative entries, do the following:\n\n- Construct the matrix representation of $P$ by expressing it in terms of a unit direction vector for the line $y=2x$.\n- Determine the SVD of $P$ by identifying its singular values and the corresponding left and right singular vectors from first principles.\n- Using the geometric interpretation of SVD, describe how $P$ transforms the unit circle in $\\mathbb{R}^{2}$, including the semi-axis lengths and directions of the resulting image, and comment on whether the image is a degenerate ellipse.\n\nExpress your final answer as the ordered pair of singular values $(\\sigma_{1},\\sigma_{2})$ in a single row using the `pmatrix` environment. No rounding is required.", "solution": "The problem asks for the construction of a projection matrix $P$, its Singular Value Decomposition (SVD), and a geometric interpretation of its action on the unit circle.\n\nFirst, we construct the matrix representation of the linear map $P$ that orthogonally projects vectors in $\\mathbb{R}^{2}$ onto the line $y=2x$.\nA direction vector for the line $y=2x$ is $\\mathbf{d} = \\begin{pmatrix} 1 \\\\ 2 \\end{pmatrix}$. To create an orthogonal projection matrix, we first need a unit vector in this direction. The norm of $\\mathbf{d}$ is $\\|\\mathbf{d}\\| = \\sqrt{1^{2} + 2^{2}} = \\sqrt{5}$.\nThe unit direction vector is thus $\\mathbf{u} = \\frac{\\mathbf{d}}{\\|\\mathbf{d}\\|} = \\frac{1}{\\sqrt{5}}\\begin{pmatrix} 1 \\\\ 2 \\end{pmatrix}$.\nThe matrix $P$ for orthogonal projection onto the one-dimensional subspace spanned by a unit vector $\\mathbf{u}$ is given by the outer product $P = \\mathbf{u}\\mathbf{u}^{\\top}$.\nSubstituting our vector $\\mathbf{u}$:\n$$P = \\left(\\frac{1}{\\sqrt{5}}\\begin{pmatrix} 1 \\\\ 2 \\end{pmatrix}\\right) \\left(\\frac{1}{\\sqrt{5}}\\begin{pmatrix} 1 & 2 \\end{pmatrix}\\right) = \\frac{1}{5}\\begin{pmatrix} 1 \\\\ 2 \\end{pmatrix}\\begin{pmatrix} 1 & 2 \\end{pmatrix} = \\frac{1}{5}\\begin{pmatrix} 1 \\cdot 1 & 1 \\cdot 2 \\\\ 2 \\cdot 1 & 2 \\cdot 2 \\end{pmatrix} = \\frac{1}{5}\\begin{pmatrix} 1 & 2 \\\\ 2 & 4 \\end{pmatrix}$$\nThis is the matrix representation of the projection $P$.\n\nNext, we determine the SVD of $P$. The SVD is a factorization $P = U\\Sigma V^{\\top}$. The singular values $\\sigma_{i}$, which form the diagonal of $\\Sigma$, are the square roots of the eigenvalues of the matrix $P^{\\top}P$.\nThe matrix $P$ is symmetric, i.e., $P^{\\top} = P$. Therefore, $P^{\\top}P = P^{2}$.\nFor a projection matrix, it is an idempotent operator, meaning $P^{2} = P$. We can verify this:\n$$P^{2} = \\left(\\frac{1}{5}\\begin{pmatrix} 1 & 2 \\\\ 2 & 4 \\end{pmatrix}\\right)\\left(\\frac{1}{5}\\begin{pmatrix} 1 & 2 \\\\ 2 & 4 \\end{pmatrix}\\right) = \\frac{1}{25}\\begin{pmatrix} 1(1)+2(2) & 1(2)+2(4) \\\\ 2(1)+4(2) & 2(2)+4(4) \\end{pmatrix} = \\frac{1}{25}\\begin{pmatrix} 5 & 10 \\\\ 10 & 20 \\end{pmatrix} = \\frac{1}{5}\\begin{pmatrix} 1 & 2 \\\\ 2 & 4 \\end{pmatrix} = P$$\nThus, we need to find the eigenvalues of $P$ itself. The eigenvalues of a projection matrix are always $1$ and $0$.\n- Any vector lying on the line of projection is an eigenvector with eigenvalue $\\lambda=1$, since $P\\mathbf{x} = \\mathbf{x}$. The eigenspace for $\\lambda_1=1$ is the line $y=2x$.\n- Any vector orthogonal to the line of projection is mapped to the zero vector, so it is an eigenvector with eigenvalue $\\lambda=0$. The eigenspace for $\\lambda_2=0$ is the line orthogonal to $y=2x$, which is $y=-x/2$.\n\nThe eigenvalues of $P$ are $\\lambda_{1}=1$ and $\\lambda_{2}=0$. The singular values are the square roots of these eigenvalues, ordered non-increasingly:\n$\\sigma_{1} = \\sqrt{\\lambda_{1}} = \\sqrt{1} = 1$\n$\\sigma_{2} = \\sqrt{\\lambda_{2}} = \\sqrt{0} = 0$\nSo, the matrix $\\Sigma$ is $\\Sigma = \\begin{pmatrix} 1 & 0 \\\\ 0 & 0 \\end{pmatrix}$.\n\nThe columns of $V$ (the right singular vectors, $\\mathbf{v}_i$) are the orthonormal eigenvectors of $P^{\\top}P = P$.\n- For $\\lambda_{1}=1$, the eigenvector is any vector along the line $y=2x$. We choose the unit vector $\\mathbf{v}_{1} = \\mathbf{u} = \\frac{1}{\\sqrt{5}}\\begin{pmatrix} 1 \\\\ 2 \\end{pmatrix}$.\n- For $\\lambda_{2}=0$, the eigenvector must be orthogonal to $\\mathbf{v}_1$. A vector orthogonal to $\\begin{pmatrix} 1 \\\\ 2 \\end{pmatrix}$ is $\\begin{pmatrix} -2 \\\\ 1 \\end{pmatrix}$. Normalizing this vector gives $\\mathbf{v}_{2} = \\frac{1}{\\sqrt{(-2)^{2}+1^{2}}}\\begin{pmatrix} -2 \\\\ 1 \\end{pmatrix} = \\frac{1}{\\sqrt{5}}\\begin{pmatrix} -2 \\\\ 1 \\end{pmatrix}$.\nThe matrix $V$ is formed by these vectors as columns: $V = \\begin{pmatrix} \\mathbf{v}_{1} & \\mathbf{v}_{2} \\end{pmatrix} = \\frac{1}{\\sqrt{5}}\\begin{pmatrix} 1 & -2 \\\\ 2 & 1 \\end{pmatrix}$.\n\nThe columns of $U$ (the left singular vectors, $\\mathbf{u}_i$) are determined by the relation $P\\mathbf{v}_i = \\sigma_i \\mathbf{u}_i$.\n- For $\\sigma_{1}=1$: $\\mathbf{u}_{1} = \\frac{1}{\\sigma_{1}}P\\mathbf{v}_{1} = \\frac{1}{1}P\\mathbf{v}_{1}$. Since $\\mathbf{v}_1$ is an eigenvector of $P$ with eigenvalue $1$, $P\\mathbf{v}_1 = \\mathbf{v}_1$. So, $\\mathbf{u}_{1} = \\mathbf{v}_{1} = \\frac{1}{\\sqrt{5}}\\begin{pmatrix} 1 \\\\ 2 \\end{pmatrix}$.\n- For $\\sigma_{2}=0$: the relation is $P\\mathbf{v}_2 = 0\\cdot\\mathbf{u}_2 = \\mathbf{0}$, which is true since $\\mathbf{v}_2$ is in the null space of $P$. $\\mathbf{u}_2$ must be a unit vector orthogonal to $\\mathbf{u}_1$. We can choose $\\mathbf{u}_2 = \\mathbf{v}_2 = \\frac{1}{\\sqrt{5}}\\begin{pmatrix} -2 \\\\ 1 \\end{pmatrix}$.\nThe matrix $U$ is formed by these vectors as columns: $U = \\begin{pmatrix} \\mathbf{u}_{1} & \\mathbf{u}_{2} \\end{pmatrix} = \\frac{1}{\\sqrt{5}}\\begin{pmatrix} 1 & -2 \\\\ 2 & 1 \\end{pmatrix}$.\nNote that since $P$ is symmetric positive semi-definite, it is possible to choose $U=V$.\n\nThe SVD of $P$ is $P = U\\Sigma V^{\\top} = \\left(\\frac{1}{\\sqrt{5}}\\begin{pmatrix} 1 & -2 \\\\ 2 & 1 \\end{pmatrix}\\right) \\begin{pmatrix} 1 & 0 \\\\ 0 & 0 \\end{pmatrix} \\left(\\frac{1}{\\sqrt{5}}\\begin{pmatrix} 1 & 2 \\\\ -2 & 1 \\end{pmatrix}\\right)$.\n\nFinally, we provide the geometric interpretation of how $P$ transforms the unit circle in $\\mathbb{R}^{2}$. The SVD provides a clear picture of this transformation. The action of any matrix $A=U\\Sigma V^{\\top}$ on the unit circle can be seen as a sequence of three operations:\n1. A rotation/reflection by $V^{\\top}$, which aligns the standard basis with the right singular vectors $\\mathbf{v}_i$.\n2. A scaling along these new axes, where the scaling factor along axis $\\mathbf{v}_i$ is the singular value $\\sigma_i$.\n3. A rotation/reflection by $U$, which aligns the scaled axes with the left singular vectors $\\mathbf{u}_i$.\n\nFor the matrix $P$, the unit circle is transformed into an ellipse, whose semi-axes are given by the vectors $\\sigma_{i}\\mathbf{u}_{i}$.\n- The first semi-axis has length $\\sigma_{1}=1$ and direction $\\mathbf{u}_{1} = \\frac{1}{\\sqrt{5}}\\begin{pmatrix} 1 \\\\ 2 \\end{pmatrix}$. This vector lies along the line $y=2x$.\n- The second semi-axis has length $\\sigma_{2}=0$ and direction $\\mathbf{u}_{2} = \\frac{1}{\\sqrt{5}}\\begin{pmatrix} -2 \\\\ 1 \\end{pmatrix}$. This vector is orthogonal to the line $y=2x$.\n\nSince one of the semi-axis lengths is $0$, the resulting image is a **degenerate ellipse**. The transformation collapses the entire unit circle onto a one-dimensional object: a line segment. This line segment lies on the line $y=2x$ and is defined by the set of points $\\{c\\mathbf{u}_1 : c \\in [-1, 1]\\}$. The endpoints of the segment are $-\\mathbf{u}_1$ and $\\mathbf{u}_1$, so it stretches from $(-\\frac{1}{\\sqrt{5}}, -\\frac{2}{\\sqrt{5}})$ to $(\\frac{1}{\\sqrt{5}}, \\frac{2}{\\sqrt{5}})$. This outcome is expected, as an orthogonal projection onto a line must map all points in the plane onto that line.\n\nThe ordered pair of singular values is $(\\sigma_{1}, \\sigma_{2})=(1, 0)$.", "answer": "$$\\boxed{\\begin{pmatrix} 1 & 0 \\end{pmatrix}}$$", "id": "3234717"}, {"introduction": "Having analyzed existing transformations, we now reverse the process to truly solidify our understanding. In this exercise, we will act as designers, constructing a specific matrix from its desired geometric properties. The challenge is to build a transformation that maps the unit circle to a precisely defined, tilted ellipse, using the geometric roles of the matrices $U$, $\\Sigma$, and $V$ as our toolkit [@problem_id:3234724].", "problem": "Consider the geometric action of a real $2 \\times 2$ matrix $A$ on the unit circle $\\{x \\in \\mathbb{R}^{2} : \\|x\\|_{2} = 1\\}$. Using only the foundational definitions of the singular value decomposition (SVD) and its geometric interpretation as composition of orthogonal transformations and axis-aligned scalings, construct an explicit real $2 \\times 2$ matrix $A$ whose image of the unit circle is the ellipse centered at the origin with major semi-axis of length $\\sigma_{1} = 3$ and minor semi-axis of length $\\sigma_{2} = 1$, whose principal axes are tilted by $45$ degrees (equivalently $\\pi/4$ radians) counterclockwise relative to the $x$-axis. Among all possible matrices with this property, choose the one whose right singular vectors coincide with the standard basis of $\\mathbb{R}^{2}$. Provide the explicit matrix $A$. No rounding is required.", "solution": "The problem asks for the construction of a specific real $2 \\times 2$ matrix $A$ based on its geometric action on the unit circle and a constraint on its singular value decomposition (SVD).\n\nFirst, we validate the problem statement.\nThe givens are:\n1.  A is a real $2 \\times 2$ matrix.\n2.  The image of the unit circle $\\{x \\in \\mathbb{R}^{2} : \\|x\\|_{2} = 1\\}$ under the transformation $A$ is an ellipse.\n3.  The ellipse is centered at the origin.\n4.  The major semi-axis of the ellipse has length $\\sigma_1 = 3$.\n5.  The minor semi-axis of the ellipse has length $\\sigma_2 = 1$.\n6.  The principal axes of the ellipse are tilted by an angle of $\\pi/4$ radians ($45$ degrees) counterclockwise relative to the standard Cartesian axes.\n7.  The right singular vectors of $A$ are the standard basis vectors of $\\mathbb{R}^2$.\n\nThe problem is scientifically grounded in the theory of linear algebra, specifically the singular value decomposition. It is objective and well-posed, provided the description of the ellipse's orientation is interpreted in the standard geometric sense. This interpretation removes ambiguity and leads to a unique solution. The problem is therefore deemed valid.\n\nWe proceed with the solution by constructing the matrix $A$ from its SVD, which has the form $A = U\\Sigma V^T$. The geometric action of $A$ on a vector $x$ can be understood as a sequence of three operations: a rotation/reflection by $V^T$, an axis-aligned scaling by $\\Sigma$, and another rotation/reflection by $U$. The image of the unit circle under $A$ is an ellipse whose principal axes are aligned with the columns of $U$ (the left singular vectors) and whose semi-axis lengths are the singular values on the diagonal of $\\Sigma$.\n\n1.  **Determine the matrix of singular values, $\\Sigma$.**\n    The lengths of the semi-axes of the ellipse are given by the singular values of $A$. The problem specifies a major semi-axis of length $\\sigma_1 = 3$ and a minor semi-axis of length $\\sigma_2 = 1$. By convention, the singular values are ordered in descending magnitude. Thus, the diagonal matrix $\\Sigma$ is:\n    $$\n    \\Sigma = \\begin{pmatrix} \\sigma_1 & 0 \\\\ 0 & \\sigma_2 \\end{pmatrix} = \\begin{pmatrix} 3 & 0 \\\\ 0 & 1 \\end{pmatrix}\n    $$\n\n2.  **Determine the matrix of right singular vectors, $V$.**\n    The columns of the orthogonal matrix $V$ are the right singular vectors of $A$. The problem explicitly states that these are the standard basis vectors of $\\mathbb{R}^2$. Let $\\mathbf{v}_1 = \\mathbf{e}_1 = \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix}$ and $\\mathbf{v}_2 = \\mathbf{e}_2 = \\begin{pmatrix} 0 \\\\ 1 \\end{pmatrix}$.\n    Therefore, the matrix $V$ is the $2 \\times 2$ identity matrix:\n    $$\n    V = \\begin{pmatrix} 1 & 0 \\\\ 0 & 1 \\end{pmatrix} = I\n    $$\n    Consequently, its transpose $V^T$ is also the identity matrix, $V^T = I$.\n\n3.  **Determine the matrix of left singular vectors, $U$.**\n    The columns of the orthogonal matrix $U$ are the left singular vectors of $A$, denoted $\\mathbf{u}_1$ and $\\mathbf{u}_2$. These vectors define the directions of the principal axes of the resulting ellipse. The vector $\\mathbf{u}_1$ corresponds to the major axis (length $\\sigma_1 = 3$), and $\\mathbf{u}_2$ corresponds to the minor axis (length $\\sigma_2 = 1$).\n    The problem states that the principal axes are tilted by $\\pi/4$ radians counterclockwise relative to the standard axes. This implies that the orthonormal basis $(\\mathbf{u}_1, \\mathbf{u}_2)$ is obtained by rotating the standard basis $(\\mathbf{e}_1, \\mathbf{e}_2)$ by an angle of $\\pi/4$. The matrix representing this rotation is the standard $2 \\times 2$ rotation matrix $R_{\\theta}$ with $\\theta = \\pi/4$. This matrix is our matrix $U$.\n    The columns of $U$ are:\n    $$\n    \\mathbf{u}_1 = R_{\\pi/4} \\mathbf{e}_1 = \\begin{pmatrix} \\cos(\\pi/4) \\\\ \\sin(\\pi/4) \\end{pmatrix} = \\begin{pmatrix} \\frac{1}{\\sqrt{2}} \\\\ \\frac{1}{\\sqrt{2}} \\end{pmatrix}\n    $$\n    $$\n    \\mathbf{u}_2 = R_{\\pi/4} \\mathbf{e}_2 = \\begin{pmatrix} -\\sin(\\pi/4) \\\\ \\cos(\\pi/4) \\end{pmatrix} = \\begin{pmatrix} -\\frac{1}{\\sqrt{2}} \\\\ \\frac{1}{\\sqrt{2}} \\end{pmatrix}\n    $$\n    Thus, the matrix $U$ is:\n    $$\n    U = \\begin{pmatrix} \\frac{1}{\\sqrt{2}} & -\\frac{1}{\\sqrt{2}} \\\\ \\frac{1}{\\sqrt{2}} & \\frac{1}{\\sqrt{2}} \\end{pmatrix} = \\frac{1}{\\sqrt{2}} \\begin{pmatrix} 1 & -1 \\\\ 1 & 1 \\end{pmatrix}\n    $$\n\n4.  **Construct the matrix $A$.**\n    Now we assemble the matrix $A$ using the determined components $U$, $\\Sigma$, and $V^T$.\n    $$\n    A = U \\Sigma V^T = \\left( \\frac{1}{\\sqrt{2}} \\begin{pmatrix} 1 & -1 \\\\ 1 & 1 \\end{pmatrix} \\right) \\begin{pmatrix} 3 & 0 \\\\ 0 & 1 \\end{pmatrix} \\begin{pmatrix} 1 & 0 \\\\ 0 & 1 \\end{pmatrix}^T\n    $$\n    Since $V^T = I$, the expression simplifies to $A = U\\Sigma$.\n    $$\n    A = \\frac{1}{\\sqrt{2}} \\begin{pmatrix} 1 & -1 \\\\ 1 & 1 \\end{pmatrix} \\begin{pmatrix} 3 & 0 \\\\ 0 & 1 \\end{pmatrix}\n    $$\n    Performing the matrix multiplication:\n    $$\n    A = \\frac{1}{\\sqrt{2}} \\begin{pmatrix} (1)(3) + (-1)(0) & (1)(0) + (-1)(1) \\\\ (1)(3) + (1)(0) & (1)(0) + (1)(1) \\end{pmatrix}\n    $$\n    $$\n    A = \\frac{1}{\\sqrt{2}} \\begin{pmatrix} 3 & -1 \\\\ 3 & 1 \\end{pmatrix}\n    $$\n    Writing the matrix with explicit components:\n    $$\n    A = \\begin{pmatrix} \\frac{3}{\\sqrt{2}} & -\\frac{1}{\\sqrt{2}} \\\\ \\frac{3}{\\sqrt{2}} & \\frac{1}{\\sqrt{2}} \\end{pmatrix}\n    $$\n    This is the explicit real $2 \\times 2$ matrix that satisfies all the conditions given in the problem statement.", "answer": "$$\n\\boxed{\\begin{pmatrix} \\frac{3}{\\sqrt{2}} & -\\frac{1}{\\sqrt{2}} \\\\ \\frac{3}{\\sqrt{2}} & \\frac{1}{\\sqrt{2}} \\end{pmatrix}}\n$$", "id": "3234724"}]}