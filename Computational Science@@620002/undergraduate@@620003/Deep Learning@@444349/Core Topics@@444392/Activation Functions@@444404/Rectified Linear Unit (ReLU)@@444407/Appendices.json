{"hands_on_practices": [{"introduction": "This first practice connects two seemingly different concepts: the geometric partitioning of k-means clustering and the functional form of a neural network. You will analytically construct a one-hidden-layer ReLU network that perfectly replicates the decision boundaries of k-means. This exercise [@problem_id:3167799] is fundamental because it demonstrates from first principles how the simple \"on/off\" switching behavior of ReLU units allows a network to build complex, piecewise linear functions that divide the input space into distinct regions, revealing the core of their representational power.", "problem": "You are asked to implement and analyze a small feedforward network with Rectified Linear Unit (ReLU), where Rectified Linear Unit (ReLU) is defined as $\\mathrm{ReLU}(z) = \\max(0, z)$. The goal is to show, from first principles, how a one-hidden-layer ReLU network can partition $\\mathbb{R}^2$ into regions whose linear separators correspond to nearest-center assignments used in $k$-means clustering. Starting only from the definitions of squared Euclidean distance and the Rectified Linear Unit (ReLU), you must derive how affine transformations followed by gating via $\\mathrm{ReLU}$ can reproduce the piecewise linear decision boundaries of the nearest-center rule for $k$-means clustering. Your program must then implement this network using weights and biases directly constructed from the provided cluster centers, without any training, and verify its behavior on a set of test cases.\n\nFundamental base to use:\n- Squared Euclidean distance in $\\mathbb{R}^2$ between a point $x \\in \\mathbb{R}^2$ and a center $c \\in \\mathbb{R}^2$ is $\\|x - c\\|_2^2$.\n- The nearest-center assignment used in $k$-means clustering maps $x$ to the index $i$ of the center $c_i$ that minimizes $\\|x - c_i\\|_2^2$.\n- Rectified Linear Unit (ReLU) is defined as $\\mathrm{ReLU}(z) = \\max(0, z)$ and acts as a gating nonlinearity that outputs $z$ when $z \\ge 0$ and $0$ otherwise.\n\nYou must implement a one-hidden-layer ReLU network whose hidden units compute affine functions of the input $x$, and whose output layer linearly aggregates the hidden outputs to produce one score per cluster. The network must produce the same cluster index as the nearest-center rule for all provided test points, with ties deterministically broken by the smallest index (for example, if two centers are equidistant, choose the smaller index). Your derivation and implementation must not use any pre-built machine learning library or training; all parameters must be constructed analytically from the centers.\n\nAngle units do not apply in this problem. There are no physical quantities; therefore, no physical units are required. When you report proportions or accuracies, express them as decimal numbers (for example, $0.75$), not using a percentage sign.\n\nTest suite specification:\nFor each test case, the parameter set is a pair consisting of a list of cluster centers and a list of points in $\\mathbb{R}^2$. All coordinates below are given exactly and must be used verbatim.\n\n- Test case $1$ (two clusters; boundary along a perpendicular bisector; includes a tie on the boundary):\n  - Centers: $\\left[(0, 0), (2, 0)\\right]$.\n  - Points: $\\left[(-1, 0), (0, 0), (0.9, 0), (1.0, 0), (1.1, 0), (3, 0), (2, 1)\\right]$.\n\n- Test case $2$ (three clusters forming a triangle; general positions):\n  - Centers: $\\left[(0, 0), (2, 0), (1, 2)\\right]$.\n  - Points: $\\left[(0.1, 0.2), (2.1, -0.1), (1.0, 1.8), (0.9, 0.9), (1.1, 1.1)\\right]$.\n\n- Test case $3$ (boundary-only points with ties between two clusters; explicit tie-handling required):\n  - Centers: $\\left[(0, 0), (2, 0)\\right]$.\n  - Points: $\\left[(1, 0), (1, 2), (1, -2)\\right]$.\n\n- Test case $4$ (degenerate case with coincident centers; triple tie may occur; explicit tie-handling required):\n  - Centers: $\\left[(0, 0), (0, 0), (2, 0)\\right]$.\n  - Points: $\\left[(-1, 0), (0, 0), (1, 0), (2, 0)\\right]$.\n\n- Test case $5$ (single-cluster case; trivial partition):\n  - Centers: $\\left[(3, 3)\\right]$.\n  - Points: $\\left[(-10, -10), (0, 0), (3, 3), (5, 5)\\right]$.\n\nProgram requirements:\n- For each test case, compute the cluster assignment for every point using:\n  - The nearest-center rule that minimizes $\\|x - c_i\\|_2^2$, with ties deterministically broken by choosing the smallest index.\n  - The ReLU network whose parameters are derived analytically from the centers, and whose output scores per cluster implement gating by region so that the decision boundaries are linear separators corresponding to the perpendicular bisectors between centers. Use the same deterministic tie rule as above when multiple clusters achieve the maximal score.\n- For each test case, output a single decimal number equal to the fraction of points for which both methods produce the same index.\n\nFinal output format:\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, in the order of the test cases $1$ through $5$. For example, the format must be exactly like $\\left[\\text{result}_1,\\text{result}_2,\\text{result}_3,\\text{result}_4,\\text{result}_5\\right]$, where each $\\text{result}_i$ is a decimal number such as $1.0$ or $0.0$.", "solution": "The goal is to construct a one-hidden-layer ReLU network that replicates the nearest-center assignment rule of k-means clustering. This rule assigns a point $x \\in \\mathbb{R}^2$ to the cluster with index $j$ if its center $c_j$ is the closest among all centers $\\{c_0, c_1, \\dots, c_{K-1}\\}$. Mathematically, the assigned index is:\n$$\n\\hat{k}(x) = \\underset{k \\in \\{0, \\dots, K-1\\}}{\\mathrm{argmin}} \\|x - c_k\\|_2^2\n$$\nThis is an `argmin` operation. It is equivalent to an `argmax` operation if we negate the objective function. Let us define a score $S_k(x)$ for each cluster $k$ such that maximizing this score is equivalent to minimizing the squared distance.\n$$\n\\hat{k}(x) = \\underset{k}{\\mathrm{argmax}} \\left( -\\|x - c_k\\|_2^2 \\right)\n$$\nWe expand the squared Euclidean distance term:\n$$\n-\\|x - c_k\\|_2^2 = -( (x - c_k)^T (x - c_k) ) = -(x^T x - 2x^T c_k + c_k^T c_k) = 2x^T c_k - \\|c_k\\|_2^2 - \\|x\\|_2^2\n$$\nThe maximization problem is now:\n$$\n\\hat{k}(x) = \\underset{k}{\\mathrm{argmax}} \\left( 2x^T c_k - \\|c_k\\|_2^2 - \\|x\\|_2^2 \\right)\n$$\nThe term $-\\|x\\|_2^2$ is constant across all clusters $k$ for a given point $x$. Therefore, it does not affect the outcome of the `argmax` operation and can be dropped. We can define an equivalent target score function $S_k^*(x)$ that the network must compute or be proportional to:\n$$\nS_k^*(x) = 2x^T c_k - \\|c_k\\|_2^2\n$$\nFor an input $x = [x_1, x_2]^T$ and a center $c_k = [c_{k1}, c_{k2}]^T$, this expands to:\n$$\nS_k^*(x) = 2(c_{k1}x_1 + c_{k2}x_2) - (c_{k1}^2 + c_{k2}^2)\n$$\nThis is an affine function of the input $x$. A network with zero hidden layers (i.e., a linear layer) could compute these scores directly. However, the problem explicitly requires a one-hidden-layer ReLU network. To satisfy this, we must express the linear dependency on $x$ using ReLU units. Any real number $z$ can be expressed as the difference of its positive and negative parts, which can be implemented with the ReLU function:\n$$\nz = \\max(0, z) - \\max(0, -z) = \\mathrm{ReLU}(z) - \\mathrm{ReLU}(-z)\n$$\nApplying this decomposition to the input components $x_1$ and $x_2$:\n$$\nx_1 = \\mathrm{ReLU}(x_1) - \\mathrm{ReLU}(-x_1)\n$$\n$$\nx_2 = \\mathrm{ReLU}(x_2) - \\mathrm{ReLU}(-x_2)\n$$\nSubstituting these into the expression for $S_k^*(x)$:\n$$\nS_k^*(x) = 2c_{k1}(\\mathrm{ReLU}(x_1) - \\mathrm{ReLU}(-x_1)) + 2c_{k2}(\\mathrm{ReLU}(x_2) - \\mathrm{ReLU}(-x_2)) - \\|c_k\\|_2^2\n$$\nThis expression demonstrates how the target scores can be constructed as a linear combination of ReLU-activated functions of the input. We can now design the network architecture.\n\n**Network Architecture**\n\n1.  **Input Layer**: The input is the vector $x = [x_1, x_2]^T$.\n\n2.  **Hidden Layer**: The hidden layer must compute the terms needed for the output layer. Based on the derived expression for $S_k^*(x)$, we need the following hidden unit activations: $\\mathrm{ReLU}(x_1)$, $\\mathrm{ReLU}(-x_1)$, $\\mathrm{ReLU}(x_2)$, and $\\mathrm{ReLU}(-x_2)$. Additionally, the constant bias term $-\\|c_k\\|_2^2$ can be implemented by having a hidden unit with a constant activation of $1$. This is achieved by a neuron with zero weights and a bias of $1$: $\\mathrm{ReLU}(0 \\cdot x_1 + 0 \\cdot x_2 + 1) = 1$.\n    Thus, the hidden layer has $5$ units, with activations $h = [h_1, h_2, h_3, h_4, h_5]^T$ defined as:\n    - $h_1 = \\mathrm{ReLU}(1 \\cdot x_1 + 0 \\cdot x_2 + 0) = \\mathrm{ReLU}(x_1)$\n    - $h_2 = \\mathrm{ReLU}(-1 \\cdot x_1 + 0 \\cdot x_2 + 0) = \\mathrm{ReLU}(-x_1)$\n    - $h_3 = \\mathrm{ReLU}(0 \\cdot x_1 + 1 \\cdot x_2 + 0) = \\mathrm{ReLU}(x_2)$\n    - $h_4 = \\mathrm{ReLU}(0 \\cdot x_1 - 1 \\cdot x_2 + 0) = \\mathrm{ReLU}(-x_2)$\n    - $h_5 = \\mathrm{ReLU}(0 \\cdot x_1 + 0 \\cdot x_2 + 1) = 1$\n    The hidden layer's weights $W_h$ and biases $b_h$ are therefore:\n    $$\n    W_h = \\begin{pmatrix} 1 & 0 \\\\ -1 & 0 \\\\ 0 & 1 \\\\ 0 & -1 \\\\ 0 & 0 \\end{pmatrix}, \\quad b_h = \\begin{pmatrix} 0 \\\\ 0 \\\\ 0 \\\\ 0 \\\\ 1 \\end{pmatrix}\n    $$\n\n3.  **Output Layer**: The output layer computes $K$ scores, $S_k(x)$, one for each cluster. It is a linear layer that combines the hidden activations: $S(x) = W_o h$. By rearranging the expression for $S_k^*(x)$, we can identify the weights in the output matrix $W_o$.\n    $$\n    S_k^*(x) = (2c_{k1})\\mathrm{ReLU}(x_1) + (-2c_{k1})\\mathrm{ReLU}(-x_1) + (2c_{k2})\\mathrm{ReLU}(x_2) + (-2c_{k2})\\mathrm{ReLU}(-x_2) + (-\\|c_k\\|_2^2) \\cdot 1\n    $$\n    This corresponds to the dot product of a weight vector and the hidden activation vector $h$. The $k$-th row of the output weight matrix $W_o$ is therefore:\n    $$\n    (W_o)_k = [2c_{k1}, -2c_{k1}, 2c_{k2}, -2c_{k2}, -\\|c_k\\|_2^2]\n    $$\n\nThis construction provides the exact weights and biases for a one-hidden-layer ReLU network that computes scores $S_k(x) = S_k^*(x)$. The final cluster assignment is $\\mathrm{argmax}_k S_k(x)$, which is equivalent to the nearest-center rule. For implementation, the tie-breaking condition (choosing the smallest index) is naturally handled by standard `numpy.argmin` and `numpy.argmax` functions.\n\nThis completes the derivation. The implementation will follow this analytical construction.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Implements and verifies a one-hidden-layer ReLU network for k-means nearest-center assignment.\n    \"\"\"\n    test_cases = [\n        # Test case 1\n        (\n            [(0, 0), (2, 0)],\n            [(-1, 0), (0, 0), (0.9, 0), (1.0, 0), (1.1, 0), (3, 0), (2, 1)],\n        ),\n        # Test case 2\n        (\n            [(0, 0), (2, 0), (1, 2)],\n            [(0.1, 0.2), (2.1, -0.1), (1.0, 1.8), (0.9, 0.9), (1.1, 1.1)],\n        ),\n        # Test case 3\n        (\n            [(0, 0), (2, 0)],\n            [(1, 0), (1, 2), (1, -2)],\n        ),\n        # Test case 4\n        (\n            [(0, 0), (0, 0), (2, 0)],\n            [(-1, 0), (0, 0), (1, 0), (2, 0)],\n        ),\n        # Test case 5\n        (\n            [(3, 3)],\n            [(-10, -10), (0, 0), (3, 3), (5, 5)],\n        )\n    ]\n\n    results = []\n\n    for centers_list, points_list in test_cases:\n        centers = np.array(centers_list, dtype=np.float64)\n        points = np.array(points_list, dtype=np.float64)\n        \n        num_points = points.shape[0]\n        if num_points == 0:\n            results.append(1.0)\n            continue\n            \n        num_matches = 0\n\n        # Construct the output weight matrix W_o for the ReLU network\n        # W_o has shape (K, 5) where K is the number of clusters.\n        # The k-th row is [2*c_k1, -2*c_k1, 2*c_k2, -2*c_k2, -||c_k||^2]\n        num_clusters = centers.shape[0]\n        W_o = np.zeros((num_clusters, 5), dtype=np.float64)\n        for k in range(num_clusters):\n            c_k1, c_k2 = centers[k, 0], centers[k, 1]\n            W_o[k, 0] = 2 * c_k1\n            W_o[k, 1] = -2 * c_k1\n            W_o[k, 2] = 2 * c_k2\n            W_o[k, 3] = -2 * c_k2\n            W_o[k, 4] = -(c_k1**2 + c_k2**2)\n            \n        for point in points:\n            x1, x2 = point[0], point[1]\n\n            # 1. Nearest-center rule (k-means)\n            # Calculate squared Euclidean distances: ||x - c_k||^2\n            dist_sq = np.sum((point - centers)**2, axis=1)\n            # Find index of minimum distance. np.argmin breaks ties by choosing the smallest index.\n            kmeans_idx = np.argmin(dist_sq)\n\n            # 2. ReLU network assignment\n            # Hidden layer activations h = [ReLU(x1), ReLU(-x1), ReLU(x2), ReLU(-x2), 1]\n            h = np.array([\n                max(0, x1),\n                max(0, -x1),\n                max(0, x2),\n                max(0, -x2),\n                1.0\n            ])\n            \n            # Output layer scores S = W_o @ h\n            scores = W_o @ h\n            # Find index of maximum score. np.argmax breaks ties by choosing the smallest index.\n            relu_net_idx = np.argmax(scores)\n\n            if kmeans_idx == relu_net_idx:\n                num_matches += 1\n        \n        accuracy = float(num_matches) / float(num_points)\n        results.append(accuracy)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "3167799"}, {"introduction": "While the Rectified Linear Unit is mostly linear, its \"kink\" at zero presents a theoretical challenge for gradient-based optimization, as the derivative is undefined. This practice [@problem_id:3167839] takes you under the hood of automatic differentiation to explore how different choices for this \"subgradient\" at zero can affect the training process. By simulating gradient descent with various policies, you will gain a deeper, practical understanding of non-smooth optimization and appreciate how a seemingly minor implementation detail can have tangible consequences on model convergence.", "problem": "You are asked to study how different subgradient choices at the non-differentiable point of the Rectified Linear Unit (ReLU) activation affect training dynamics under gradient descent. The Rectified Linear Unit (ReLU) is the function $\\phi(z)$ defined pointwise as the maximum of $0$ and $z$. Consider a scalar linear model with a single hidden activation, where the pre-activation is $z = w x + b$, the activation is $\\hat{y} = \\phi(z)$, and the loss over a dataset is the average of squared errors. Use the Chain Rule from elementary calculus for composition of differentiable functions and the definition of full-batch gradient descent to derive the gradient expressions needed for parameter updates. For the subgradient at $z = 0$, use one of the following policies:\n- Policy A: always use the subgradient value $0$ at $z = 0$.\n- Policy B: always use the subgradient value $1$ at $z = 0$.\n- Policy C: at each occurrence of $z = 0$, independently choose $0$ or $1$ with equal probability $1/2$.\n\nImplement a program that simulates full-batch gradient descent on the above model. For each test case, run three training processes, one per policy (A, B, C), each for a fixed number of steps with a fixed learning rate and fixed initial parameters. Compute the final average squared error loss after training for each policy. The random choice in Policy C must be reproducible by using the provided random seed for that test case.\n\nBase your derivation and implementation on the following foundational elements only:\n- The definition of the Rectified Linear Unit (ReLU) $\\phi(z)$.\n- The Chain Rule for derivatives of compositions.\n- The definition of full-batch gradient descent for minimizing an average of squared errors.\n\nDo not assume or use any unproven shortcuts or specialized formulas beyond these definitions. Implement the gradient descent updates exactly as implied by these bases.\n\nTest suite and parameters:\n- Test case $1$ (boundary with persistent $z = 0$ unless $b$ moves): dataset $\\{(x, y)\\} = \\{(0.0, 1.0)\\}$, initial $w = 0.0$, initial $b = 0.0$, learning rate $\\alpha = 0.1$, steps $T = 50$, random seed $s = 42$.\n- Test case $2$ (mixed inputs starting at $z = 0$ for all samples): dataset $\\{(x, y)\\} = \\{(-1.0, 0.0), (1.0, 1.0)\\}$, initial $w = 0.0$, initial $b = 0.0$, learning rate $\\alpha = 0.1$, steps $T = 200$, random seed $s = 123$.\n- Test case $3$ (general case where $z = 0$ is unlikely so policies should agree): dataset $\\{(x, y)\\} = \\{(1.0, 2.0), (2.0, 4.0), (3.0, 6.0), (-1.0, 0.0)\\}$, initial $w = 0.1$, initial $b = 0.11$, learning rate $\\alpha = 0.01$, steps $T = 1000$, random seed $s = 2024$.\n- Test case $4$ (trivial exact-fit with all-zero target): dataset $\\{(x, y)\\} = \\{(0.0, 0.0)\\}$, initial $w = 0.0$, initial $b = 0.0$, learning rate $\\alpha = 0.1$, steps $T = 50$, random seed $s = 7$.\n\nFor each test case, report the final losses in the order [Policy A, Policy B, Policy C], with each value rounded to six decimal places. Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, where each element is itself a bracketed comma-separated triple for a test case. For example, the overall format must be:\n\"[[L_A1,L_B1,L_C1],[L_A2,L_B2,L_C2],[L_A3,L_B3,L_C3],[L_A4,L_B4,L_C4]]\"\nwhere $L\\_\\mathrm{A1}$ denotes the final loss for Policy A on test case $1$, and so on. No extra text should be printed.", "solution": "The core of the problem is to derive and implement the update rules for full-batch gradient descent for a simple scalar model. The model's prediction $\\hat{y}$ for an input $x$ is given by $\\hat{y} = \\phi(wx+b)$, where $\\phi$ is the ReLU function. The loss function $L$ over a dataset of $N$ samples $\\{(x_i, y_i)\\}_{i=1}^N$ is the mean squared error:\n$$\nL(w, b) = \\frac{1}{N} \\sum_{i=1}^N (\\hat{y}_i - y_i)^2 = \\frac{1}{N} \\sum_{i=1}^N (\\phi(wx_i+b) - y_i)^2\n$$\n\nThe parameters $w$ and $b$ are updated via gradient descent:\n$$\nw_{t+1} = w_t - \\alpha \\frac{\\partial L}{\\partial w}\n$$\n$$\nb_{t+1} = b_t - \\alpha \\frac{\\partial L}{\\partial b}\n$$\nwhere $\\alpha$ is the learning rate.\n\nTo find the partial derivatives $\\frac{\\partial L}{\\partial w}$ and $\\frac{\\partial L}{\\partial b}$, we apply the Chain Rule. Let $L_i = (\\hat{y}_i - y_i)^2$ be the loss for a single sample and $z_i = wx_i+b$ be the pre-activation. The total loss gradient is the average of the individual sample gradients:\n$$\n\\frac{\\partial L}{\\partial w} = \\frac{1}{N} \\sum_{i=1}^N \\frac{\\partial L_i}{\\partial w}\n\\quad \\text{and} \\quad\n\\frac{\\partial L}{\\partial b} = \\frac{1}{N} \\sum_{i=1}^N \\frac{\\partial L_i}{\\partial b}\n$$\n\nFor each sample $i$, the Chain Rule gives:\n$$\n\\frac{\\partial L_i}{\\partial w} = \\frac{\\partial L_i}{\\partial \\hat{y}_i} \\cdot \\frac{\\partial \\hat{y}_i}{\\partial z_i} \\cdot \\frac{\\partial z_i}{\\partial w}\n$$\n$$\n\\frac{\\partial L_i}{\\partial b} = \\frac{\\partial L_i}{\\partial \\hat{y}_i} \\cdot \\frac{\\partial \\hat{y}_i}{\\partial z_i} \\cdot \\frac{\\partial z_i}{\\partial b}\n$$\n\nLet's compute each component:\n1.  The derivative of the squared error with respect to the prediction is:\n    $$\n    \\frac{\\partial L_i}{\\partial \\hat{y}_i} = 2(\\hat{y}_i - y_i) = 2(\\phi(z_i) - y_i)\n    $$\n2.  The derivatives of the linear pre-activation $z_i = wx_i+b$ are:\n    $$\n    \\frac{\\partial z_i}{\\partial w} = x_i\n    $$\n    $$\n    \\frac{\\partial z_i}{\\partial b} = 1\n    $$\n3.  The derivative of the ReLU activation $\\hat{y}_i = \\phi(z_i) = \\max(0, z_i)$ is:\n    $$\n    \\phi'(z_i) = \\frac{d\\phi}{dz_i} = \\begin{cases} 1 & \\text{if } z_i > 0 \\\\ 0 & \\text{if } z_i < 0 \\end{cases}\n    $$\n    At $z_i = 0$, the function is not differentiable. The subdifferential is the interval $[0, 1]$. The problem statement provides three distinct policies for selecting a subgradient $g \\in [0, 1]$ at this point:\n    -   Policy A: $g = 0$\n    -   Policy B: $g = 1$\n    -   Policy C: $g$ is chosen from $\\{0, 1\\}$ with probability $1/2$.\n    We will denote the chosen subgradient as $\\phi'(z_i)$ for notational convenience, even at $z_i=0$.\n\nCombining these components, the gradient for a single sample $i$ is:\n$$\n\\frac{\\partial L_i}{\\partial w} = 2(\\phi(z_i) - y_i) \\cdot \\phi'(z_i) \\cdot x_i\n$$\n$$\n\\frac{\\partial L_i}{\\partial b} = 2(\\phi(z_i) - y_i) \\cdot \\phi'(z_i) \\cdot 1\n$$\n\nThe full-batch gradients are the average over all $N$ samples:\n$$\n\\frac{\\partial L}{\\partial w} = \\frac{1}{N} \\sum_{i=1}^N 2(\\phi(wx_i+b) - y_i) \\phi'(wx_i+b) x_i\n$$\n$$\n\\frac{\\partial L}{\\partial b} = \\frac{1}{N} \\sum_{i=1}^N 2(\\phi(wx_i+b) - y_i) \\phi'(wx_i+b)\n$$\n\nThe simulation proceeds by initializing $w$ and $b$, and for a fixed number of steps, repeatedly calculating these gradients (according to the specified policy for $\\phi'(0)$) and updating the parameters. For Policy C, a new random choice for $\\phi'(0)$ is made for each sample where $z_i=0$ occurs at each step, using a reproducible random number generator seeded for each test case. After the final step, the total loss $L(w,b)$ is computed.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to run the simulation for all test cases and print the results.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        {'dataset': [(0.0, 1.0)], 'w': 0.0, 'b': 0.0, 'alpha': 0.1, 'steps': 50, 'seed': 42},\n        {'dataset': [(-1.0, 0.0), (1.0, 1.0)], 'w': 0.0, 'b': 0.0, 'alpha': 0.1, 'steps': 200, 'seed': 123},\n        {'dataset': [(1.0, 2.0), (2.0, 4.0), (3.0, 6.0), (-1.0, 0.0)], 'w': 0.1, 'b': 0.11, 'alpha': 0.01, 'steps': 1000, 'seed': 2024},\n        {'dataset': [(0.0, 0.0)], 'w': 0.0, 'b': 0.0, 'alpha': 0.1, 'steps': 50, 'seed': 7},\n    ]\n\n    all_results = []\n    \n    for case in test_cases:\n        case_results = []\n        for policy in ['A', 'B', 'C']:\n            loss = run_training(\n                policy=policy,\n                dataset=case['dataset'],\n                w_init=case['w'],\n                b_init=case['b'],\n                alpha=case['alpha'],\n                steps=case['steps'],\n                seed=case['seed']\n            )\n            case_results.append(loss)\n        all_results.append(case_results)\n\n    # Format the final output string exactly as required.\n    formatted_cases = []\n    for res in all_results:\n        formatted_cases.append(f\"[{res[0]:.6f},{res[1]:.6f},{res[2]:.6f}]\")\n    \n    final_output = f\"[{','.join(formatted_cases)}]\"\n    print(final_output)\n\ndef run_training(policy, dataset, w_init, b_init, alpha, steps, seed):\n    \"\"\"\n    Simulates full-batch gradient descent for a given policy and parameters.\n    \n    Args:\n        policy (str): The subgradient policy ('A', 'B', or 'C').\n        dataset (list): The list of (x, y) data points.\n        w_init (float): Initial weight.\n        b_init (float): Initial bias.\n        alpha (float): Learning rate.\n        steps (int): Number of training steps.\n        seed (int): Random seed for Policy C.\n        \n    Returns:\n        float: The final average squared error loss.\n    \"\"\"\n    x_data = np.array([p[0] for p in dataset], dtype=np.float64)\n    y_data = np.array([p[1] for p in dataset], dtype=np.float64)\n    n_samples = len(x_data)\n    \n    w = float(w_init)\n    b = float(b_init)\n    \n    # Use a RandomState object for reproducible randomness in Policy C.\n    rng = np.random.RandomState(seed) if policy == 'C' else None\n\n    for _ in range(steps):\n        # Forward pass\n        z = w * x_data + b\n        y_hat = np.maximum(0, z)\n        \n        # Calculate the derivative of ReLU, phi_prime(z), based on the policy.\n        # Initialize with the cases for z < 0 and z > 0.\n        phi_prime = np.zeros_like(z, dtype=np.float64)\n        phi_prime[z > 0] = 1.0\n        \n        # Handle the non-differentiable point z = 0.\n        zero_indices = np.where(z == 0)[0]\n        if len(zero_indices) > 0:\n            if policy == 'A':\n                # For Policy A, phi_prime(0) is 0, which is the default.\n                pass\n            elif policy == 'B':\n                # For Policy B, phi_prime(0) is 1.\n                phi_prime[zero_indices] = 1.0\n            elif policy == 'C':\n                # For Policy C, choose 0 or 1 with equal probability.\n                for idx in zero_indices:\n                    phi_prime[idx] = rng.choice([0, 1])\n\n        # Calculate gradients using the Chain Rule.\n        # The common term in the derivative is 2 * (y_hat - y) * phi_prime.\n        delta = 2 * (y_hat - y_data) * phi_prime\n        \n        # Full-batch gradients are the average over the dataset.\n        grad_w = np.mean(delta * x_data)\n        grad_b = np.mean(delta)\n        \n        # Update parameters with gradient descent.\n        w -= alpha * grad_w\n        b -= alpha * grad_b\n        \n    # After training, calculate the final loss.\n    final_z = w * x_data + b\n    final_y_hat = np.maximum(0, final_z)\n    final_loss = np.mean((final_y_hat - y_data)**2)\n    \n    return final_loss\n\nsolve()\n```", "id": "3167839"}, {"introduction": "A powerful way to conceptualize a ReLU network is not just as a function, but as a system that maps any input to a binary \"gate pattern\" representing which neurons are active. This practice [@problem_id:3167828] asks you to build a classifier that operates directly on these gate patterns, using Hamming distance as its metric. You will then measure the classifier's robustness by observing how many \"gate flips\" are needed to change its prediction, providing a tangible and intuitive way to explore the stability and internal representations of neural networks.", "problem": "You are to implement a complete, runnable program that constructs a toy classifier for which each class corresponds to a distinct Rectified Linear Unit (ReLU) gate pattern and measures robustness to perturbations that flip gate states. The program must be self-contained, use no input, and print a single line of output with the results for a fixed test suite. The derivation must start from core definitions in deep learning. Begin from the following fundamental base: a linear layer transforms an input vector $x \\in \\mathbb{R}^d$ by $z = W x + b$, where $W \\in \\mathbb{R}^{m \\times d}$ and $b \\in \\mathbb{R}^m$, and the Rectified Linear Unit (ReLU) activation is $r(z)_i = \\max(0, z_i)$. The gate state induced by ReLU at hidden unit $i$ is the binary indicator $g_i = \\mathbb{1}[z_i > 0]$, which partitions the input space into regions indexed by $g \\in \\{0,1\\}^m$. The Hamming distance between two binary vectors $a, b \\in \\{0,1\\}^m$ is $d_H(a,b) = \\sum_{i=1}^m \\mathbb{1}[a_i \\ne b_i]$. The classifier to be implemented assigns a class to a gate vector $g$ by nearest-neighbor in Hamming distance to a set of reference class patterns $\\{p^{(c)}\\}_{c=0}^{C-1}$, using $\\hat{c}(g) = \\arg\\min_{c \\in \\{0,\\dots,C-1\\}} d_H(g, p^{(c)})$, with ties broken in favor of the smallest class index $c$. A perturbation that flips gate states is defined by selecting a subset $S \\subseteq \\{0,1,\\dots,m-1\\}$ of indices and toggling those positions, yielding a perturbed gate $\\tilde{g}^{(S)}$ with\n$$(\\tilde{g}^{(S)})_i = \\begin{cases}\n1 - g_i & \\text{if } i \\in S,\\\\\ng_i & \\text{if } i \\notin S.\n\\end{cases}$$\nFor a fixed nonnegative integer $R \\in \\mathbb{N}$, consider all subsets $S$ with cardinality at most $R$, that is, all $S$ such that $|S| \\le R$. Define the robustness fraction for a given input as\n$$\\rho = \\frac{1}{N} \\sum_{S:\\, |S| \\le R} \\mathbb{1}\\big[\\hat{c}(\\tilde{g}^{(S)}) = \\hat{c}(g)\\big], \\quad \\text{where } N = \\sum_{s=0}^{R} \\binom{m}{s}.$$\nIn words, $\\rho$ is the fraction of all perturbations that flip up to $R$ gate states which leave the predicted class unchanged.\n\nYour task is to write a program that, for each test case, computes $\\rho$ as defined above, rounding the final value to $6$ decimal places.\n\nUse the following test suite. Each test case specifies the hidden dimension $m$, the number of classes $C$, the class reference patterns $\\{p^{(c)}\\}$, the linear layer parameters $(W,b)$, the input $x$, and the perturbation radius $R$. All indices are $0$-based. The ReLU gate convention must be $g_i = \\mathbb{1}[z_i > 0]$, so exactly zero pre-activations are treated as off.\n\nTest case $1$ (happy path, clear separation):\n- $m = 4$, $C = 3$.\n- Class patterns: $p^{(0)} = (1,0,1,0)$, $p^{(1)} = (0,1,1,0)$, $p^{(2)} = (0,0,0,1)$.\n- $W = I_4$ (the $4 \\times 4$ identity), $b = (0,0,0,0)$, $x = (1,-1,2,-3)$.\n- $R = 1$.\n\nTest case $2$ (boundary case $z_i = 0$ and tie-breaking):\n- $m = 3$, $C = 2$.\n- Class patterns: $p^{(0)} = (0,0,1)$, $p^{(1)} = (0,1,0)$.\n- $W = I_3$, $b = (0,0,0)$, $x = (0,0,0)$.\n- $R = 1$.\n\nTest case $3$ (equidistant to two classes and larger radius):\n- $m = 4$, $C = 2$.\n- Class patterns: $p^{(0)} = (1,1,0,0)$, $p^{(1)} = (0,0,1,1)$.\n- $W = I_4$, $b = (0,0,0,0)$, $x = (1,-1,1,-1)$.\n- $R = 2$.\n\nTest case $4$ (class equal to all-on pattern, mixed alternatives):\n- $m = 5$, $C = 3$.\n- Class patterns: $p^{(0)} = (1,0,1,0,1)$, $p^{(1)} = (0,1,0,1,0)$, $p^{(2)} = (1,1,1,1,1)$.\n- $W = I_5$, $b = (0,0,0,0,0)$, $x = (2,3,4,5,6)$.\n- $R = 2$.\n\nProgram requirements:\n- Implement the computation of $z = W x + b$, the gate vector $g$ via $g_i = \\mathbb{1}[z_i > 0]$, the Hamming-distance based class prediction $\\hat{c}(g)$ with the specified tie-breaking rule, and the robustness fraction $\\rho$ over all subsets $S$ with $|S| \\le R$.\n- For each test case, output the robustness fraction $\\rho$ rounded to $6$ decimal places.\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, in the order of the test cases $1$ through $4$, for example, a line of the form \"[r1,r2,r3,r4]\". No additional text should be printed.", "solution": "The task is to compute a robustness metric, $\\rho$, for a toy classifier. This metric quantifies the stability of the classifier's output when its internal gate states are subjected to a specified set of perturbations. The solution procedure involves several distinct computational steps, which are detailed below.\n\nFirst, we establish the fundamental quantities as defined in the problem.\n- A linear layer's pre-activation for an input $x \\in \\mathbb{R}^d$ is $z = W x + b$, where $W \\in \\mathbb{R}^{m \\times d}$ and $b \\in \\mathbb{R}^m$.\n- The ReLU gate state vector $g \\in \\{0, 1\\}^m$ is derived from $z$, with each component $g_i = \\mathbb{1}[z_i > 0]$. Note that a pre-activation of exactly $0$ results in a gate state of $0$.\n- A gate vector $g$ is classified by finding the nearest reference pattern from a set $\\{p^{(c)}\\}_{c=0}^{C-1}$ using the Hamming distance, $d_H(a,b) = \\sum_{i=1}^m \\mathbb{1}[a_i \\ne b_i]$. The predicted class is $\\hat{c}(g) = \\arg\\min_{c \\in \\{0,\\dots,C-1\\}} d_H(g, p^{(c)})$. Ties are broken by choosing the smallest class index $c$.\n- A perturbation is defined by flipping a subset of gate states. For a set of indices $S \\subseteq \\{0,1,\\dots,m-1\\}$, the perturbed gate $\\tilde{g}^{(S)}$ is created by toggling the bits of $g$ at the indices in $S$.\n- The robustness fraction $\\rho$ is the proportion of perturbations of size up to a radius $R$ that do not change the predicted class. It is given by $\\rho = \\frac{1}{N} \\sum_{S:\\, |S| \\le R} \\mathbb{1}\\big[\\hat{c}(\\tilde{g}^{(S)}) = \\hat{c}(g)\\big]$, where $N = \\sum_{s=0}^{R} \\binom{m}{s}$ is the total number of such perturbations.\n\nThe algorithm to compute $\\rho$ for a given test case proceeds as follows:\n\n1.  **Compute the Initial Gate Vector**:\n    Given the weight matrix $W$, bias vector $b$, and input vector $x$, we first calculate the pre-activation vector $z = Wx + b$. Then, we determine the initial gate vector $g$ by applying the ReLU gate condition element-wise: $g_i = \\mathbb{1}[z_i > 0]$ for $i = 0, \\dots, m-1$.\n\n2.  **Determine the Original Predicted Class**:\n    With the initial gate vector $g$, we compute its Hamming distance to each of the $C$ class reference patterns, $\\{p^{(c)}\\}$. Let $d_c = d_H(g, p^{(c)})$. We then find the minimum distance, $d_{min} = \\min_{c} d_c$. The set of candidate classes is $\\{c \\mid d_c = d_{min}\\}$. According to the specified tie-breaking rule, the original predicted class is the smallest index in this set, $\\hat{c}_{orig} = \\min\\{c \\mid d_c = d_{min}\\}$.\n\n3.  **Generate and Evaluate All Perturbations**:\n    We must consider all perturbations corresponding to flipping up to $R$ gate states. This involves iterating through all possible numbers of flips, $s$, from $s=0$ to $s=R$.\n    - For each $s$, we generate all distinct subsets $S$ of indices $\\{0, 1, \\dots, m-1\\}$ where the size of the subset is $|S|=s$. The number of such subsets is $\\binom{m}{s}$.\n    - For each subset $S$, we construct the perturbed gate vector $\\tilde{g}^{(S)}$ by flipping the bits of $g$ at the indices specified by $S$.\n    - For each $\\tilde{g}^{(S)}$, we compute its predicted class, $\\hat{c}(\\tilde{g}^{(S)})$, using the same Hamming distance and tie-breaking logic as in Step 2.\n\n4.  **Calculate the Robustness Fraction**:\n    We maintain two counters: `robust_count` and `total_count`.\n    - We initialize `robust_count = 0` and `total_count = 0`.\n    - As we iterate through each perturbation $\\tilde{g}^{(S)}$ in Step 3, we increment `total_count`.\n    - If the predicted class for the perturbed vector matches the original class, i.e., $\\hat{c}(\\tilde{g}^{(S)}) = \\hat{c}_{orig}$, we also increment `robust_count`.\n    - The total number of perturbations, $N$, can also be calculated directly as the sum of binomial coefficients: $N = \\sum_{s=0}^{R} \\binom{m}{s}$.\n    - The final robustness fraction is the ratio $\\rho = \\frac{\\text{robust\\_count}}{\\text{total\\_count}}$. This value is then rounded to $6$ decimal places as required.\n\nThis structured procedure guarantees that all conditions of the problem are met, providing a deterministic and correct result for each test case.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.special import comb\nfrom itertools import combinations\n\ndef solve():\n    \"\"\"\n    Main function to run the test suite for the ReLU gate robustness problem.\n    \"\"\"\n    test_cases = [\n        {\n            \"m\": 4, \"C\": 3,\n            \"patterns\": np.array([[1, 0, 1, 0], [0, 1, 1, 0], [0, 0, 0, 1]]),\n            \"W\": np.identity(4),\n            \"b\": np.zeros(4),\n            \"x\": np.array([1, -1, 2, -3]),\n            \"R\": 1,\n        },\n        {\n            \"m\": 3, \"C\": 2,\n            \"patterns\": np.array([[0, 0, 1], [0, 1, 0]]),\n            \"W\": np.identity(3),\n            \"b\": np.zeros(3),\n            \"x\": np.array([0, 0, 0]),\n            \"R\": 1,\n        },\n        {\n            \"m\": 4, \"C\": 2,\n            \"patterns\": np.array([[1, 1, 0, 0], [0, 0, 1, 1]]),\n            \"W\": np.identity(4),\n            \"b\": np.zeros(4),\n            \"x\": np.array([1, -1, 1, -1]),\n            \"R\": 2,\n        },\n        {\n            \"m\": 5, \"C\": 3,\n            \"patterns\": np.array([[1, 0, 1, 0, 1], [0, 1, 0, 1, 0], [1, 1, 1, 1, 1]]),\n            \"W\": np.identity(5),\n            \"b\": np.zeros(5),\n            \"x\": np.array([2, 3, 4, 5, 6]),\n            \"R\": 2,\n        },\n    ]\n\n    results = []\n    for case in test_cases:\n        rho = compute_robustness_fraction(\n            m=case[\"m\"],\n            class_patterns=case[\"patterns\"],\n            W=case[\"W\"],\n            b=case[\"b\"],\n            x=case[\"x\"],\n            R=case[\"R\"]\n        )\n        results.append(rho)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(f'{r:.6f}' for r in results)}]\")\n\ndef get_gate_vector(W, b, x):\n    \"\"\"Computes the ReLU gate state vector g from the linear layer output.\"\"\"\n    z = np.dot(W, x) + b\n    g = (z > 0).astype(int)\n    return g\n\ndef classify_gate(g, class_patterns):\n    \"\"\"\n    Classifies a gate vector using nearest-neighbor in Hamming distance.\n    Ties are broken by choosing the smallest class index.\n    \"\"\"\n    distances = np.sum(g != class_patterns, axis=1)\n    min_dist = np.min(distances)\n    # np.where returns a tuple of arrays; we want the first element of the first array\n    winning_indices = np.where(distances == min_dist)[0]\n    return winning_indices[0]\n\ndef compute_robustness_fraction(m, class_patterns, W, b, x, R):\n    \"\"\"\n    Computes the robustness fraction rho for a given configuration.\n    \"\"\"\n    # Step 1: Compute the initial gate vector\n    initial_g = get_gate_vector(W, b, x)\n    \n    # Step 2: Determine the original predicted class\n    original_class = classify_gate(initial_g, class_patterns)\n    \n    robust_count = 0\n    total_count = 0\n    \n    # Step 3 & 4: Generate, evaluate perturbations, and count robust cases\n    for s in range(R + 1):\n        num_subsets = comb(m, s, exact=True)\n        total_count += num_subsets\n        \n        # Iterate over all subsets of indices of size s\n        for indices_to_flip in combinations(range(m), s):\n            perturbed_g = initial_g.copy()\n            \n            # Flip the bits at the specified indices\n            for index in indices_to_flip:\n                perturbed_g[index] = 1 - perturbed_g[index]\n            \n            perturbed_class = classify_gate(perturbed_g, class_patterns)\n            \n            if perturbed_class == original_class:\n                robust_count += 1\n                \n    # Step 5: Calculate the final fraction\n    if total_count == 0:\n        return 1.0  # By definition, if there are no perturbations, it's 100% robust.\n    \n    rho = robust_count / total_count\n    return rho\n\nif __name__ == \"__main__\":\n    solve()\n```", "id": "3167828"}]}