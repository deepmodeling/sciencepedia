{"hands_on_practices": [{"introduction": "Effective computer vision often requires understanding an image at multiple scales. This exercise delves into the Feature Pyramid Network (FPN), a common and powerful module for combining high-level semantic information with low-level spatial details. You will practice the essential architectural skill of tracking tensor shapes and calculating parameter costs through the FPN's lateral and top-down pathways, ensuring that features from different levels of a CNN backbone can be correctly merged [@problem_id:3103702].", "problem": "A Convolutional Neural Network (CNN) backbone processes an input image of size $640 \\times 640$ and produces three feature maps at successive stages, denoted $C_3$, $C_4$, and $C_5$. These maps have spatial strides $8$, $16$, and $32$ relative to the input, with shapes given by:\n- $C_3$: $80 \\times 80 \\times 128$,\n- $C_4$: $40 \\times 40 \\times 256$,\n- $C_5$: $20 \\times 20 \\times 512$.\n\nA Feature Pyramid Network (FPN) is constructed via lateral and top-down pathways:\n- Each $C_i$ is first passed through a lateral $1 \\times 1$ convolution with stride $1$ and zero padding, mapping to $F$ channels, with $F = 192$. Assume biases are included in every convolution.\n- Define $M_5 = \\text{Conv}_{1 \\times 1}(C_5)$, $M_4 = \\text{Conv}_{1 \\times 1}(C_4) + \\text{Upsample}_{\\times 2}(M_5)$, and $M_3 = \\text{Conv}_{1 \\times 1}(C_3) + \\text{Upsample}_{\\times 2}(M_4)$, where $\\text{Upsample}_{\\times 2}$ denotes nearest-neighbor upsampling by a factor of $2$ in height and width.\n- Each $M_i$ is then passed through a $3 \\times 3$ convolution with stride $1$ and padding $1$, producing $P_i = \\text{Conv}_{3 \\times 3}(M_i)$ with $F$ output channels.\n\nUse the following foundational facts:\n- For a convolution with kernel size $K_h \\times K_w$, input channels $C_{\\text{in}}$, and output channels $C_{\\text{out}}$, the number of trainable parameters (including biases) is $K_h \\cdot K_w \\cdot C_{\\text{in}} \\cdot C_{\\text{out}} + C_{\\text{out}}$.\n- Nearest-neighbor upsampling by a factor of $2$ maps a tensor of shape $H \\times W \\times C$ to $2H \\times 2W \\times C$.\n- Element-wise addition of tensors requires identical shapes in height, width, and channels.\n- With stride $1$ and appropriate zero padding, a $1 \\times 1$ convolution preserves spatial dimensions; a $3 \\times 3$ convolution with padding $1$ preserves spatial dimensions.\n\nTasks:\n1. Derive the shapes of $M_5$, $M_4$, and $M_3$, ensuring tensor addition in the lateral pathway is shape-aligned.\n2. Derive the shapes of $P_5$, $P_4$, and $P_3$.\n3. Compute the total number of trainable parameters used by all six convolutions in this FPN pathway (the three $1 \\times 1$ lateral convolutions and the three $3 \\times 3$ convolutions applied to $M_5$, $M_4$, and $M_3$). Express your final answer as a single exact integer. No rounding is required.", "solution": "The problem requires the calculation of feature map shapes and the total number of trainable parameters in a specified Feature Pyramid Network (FPN) architecture. The solution will be derived by sequentially addressing the three tasks given in the problem statement. All shapes are presented in the format Height $\\times$ Width $\\times$ Channels.\n\n### Task 1: Derive Shapes of $M_5$, $M_4$, and $M_3$\n\nThe FPN is constructed from a set of backbone feature maps, $C_3$, $C_4$, and $C_5$, with the following shapes:\n- $S(C_3) = 80 \\times 80 \\times 128$\n- $S(C_4) = 40 \\times 40 \\times 256$\n- $S(C_5) = 20 \\times 20 \\times 512$\n\nThe FPN pathway maps each $C_i$ to a common channel dimension $F=192$.\n\n**Shape of $M_5$**:\n$M_5$ is defined as $M_5 = \\text{Conv}_{1 \\times 1}(C_5)$.\nThe input is $C_5$ with shape $20 \\times 20 \\times 512$. The convolution is a $1 \\times 1$ layer with stride $1$ and zero padding, which preserves the spatial dimensions. The number of output channels is $F=192$.\nTherefore, the shape of $M_5$ is $20 \\times 20 \\times 192$.\n\n**Shape of $M_4$**:\n$M_4$ is defined as $M_4 = \\text{Conv}_{1 \\times 1}(C_4) + \\text{Upsample}_{\\times 2}(M_5)$.\nTo find the shape of $M_4$, we must first determine the shapes of the two tensors being added.\n1.  The first term is $\\text{Conv}_{1 \\times 1}(C_4)$. The input is $C_4$ with shape $40 \\times 40 \\times 256$. The $1 \\times 1$ convolution preserves spatial dimensions and maps the channels to $F=192$. The shape of this term is $40 \\times 40 \\times 192$.\n2.  The second term is $\\text{Upsample}_{\\times 2}(M_5)$. The input is $M_5$ with shape $20 \\times 20 \\times 192$. Nearest-neighbor upsampling by a factor of $2$ doubles the height and width. The shape of this term is $(2 \\times 20) \\times (2 \\times 20) \\times 192$, which is $40 \\times 40 \\times 192$.\n\nSince both terms have the identical shape $40 \\times 40 \\times 192$, the element-wise addition is valid. The shape of the resulting tensor $M_4$ is $40 \\times 40 \\times 192$.\n\n**Shape of $M_3$**:\n$M_3$ is defined as $M_3 = \\text{Conv}_{1 \\times 1}(C_3) + \\text{Upsample}_{\\times 2}(M_4)$.\nFollowing the same logic:\n1.  The first term is $\\text{Conv}_{1 \\times 1}(C_3)$. The input is $C_3$ with shape $80 \\times 80 \\times 128$. The $1 \\times 1$ convolution maps this to a shape of $80 \\times 80 \\times 192$.\n2.  The second term is $\\text{Upsample}_{\\times 2}(M_4)$. The input is $M_4$ with shape $40 \\times 40 \\times 192$. Upsampling by a factor of $2$ yields a shape of $(2 \\times 40) \\times (2 \\times 40) \\times 192$, which is $80 \\times 80 \\times 192$.\n\nBoth terms have the identical shape $80 \\times 80 \\times 192$. The addition is valid, and the shape of the resulting tensor $M_3$ is $80 \\times 80 \\times 192$.\n\n### Task 2: Derive Shapes of $P_5$, $P_4$, and $P_3$\n\nThe pyramid feature maps $P_i$ are produced by applying a $3 \\times 3$ convolution to each $M_i$, i.e., $P_i = \\text{Conv}_{3 \\times 3}(M_i)$. This convolution has a stride of $1$ and padding of $1$, which preserves spatial dimensions. The number of output channels is $F=192$.\n\n**Shape of $P_5$**:\nThe input is $M_5$ with shape $20 \\times 20 \\times 192$. The $3 \\times 3$ convolution preserves spatial dimensions and the number of channels. Thus, the shape of $P_5$ is $20 \\times 20 \\times 192$.\n\n**Shape of $P_4$**:\nThe input is $M_4$ with shape $40 \\times 40 \\times 192$. The $3 \\times 3$ convolution preserves spatial dimensions and the number of channels. Thus, the shape of $P_4$ is $40 \\times 40 \\times 192$.\n\n**Shape of $P_3$**:\nThe input is $M_3$ with shape $80 \\times 80 \\times 192$. The $3 \\times 3$ convolution preserves spatial dimensions and the number of channels. Thus, the shape of $P_3$ is $80 \\times 80 \\times 192$.\n\n### Task 3: Compute the Total Number of Trainable Parameters\n\nThe number of trainable parameters for a convolutional layer (including biases) is given by the formula $K_h \\cdot K_w \\cdot C_{\\text{in}} \\cdot C_{\\text{out}} + C_{\\text{out}}$, where $K_h$ and $K_w$ are the kernel dimensions, $C_{\\text{in}}$ is the number of input channels, and $C_{\\text{out}}$ is the number of output channels.\n\nWe calculate the parameters for the six convolutions in the FPN pathway.\n\n**Parameters for the three lateral $1 \\times 1$ convolutions:**\nThe kernel size is $1 \\times 1$ and $C_{\\text{out}} = F = 192$.\n1.  Convolution on $C_5$: $C_{\\text{in}} = 512$.\n    Parameters = $1 \\cdot 1 \\cdot 512 \\cdot 192 + 192 = 98304 + 192 = 98496$.\n2.  Convolution on $C_4$: $C_{\\text{in}} = 256$.\n    Parameters = $1 \\cdot 1 \\cdot 256 \\cdot 192 + 192 = 49152 + 192 = 49344$.\n3.  Convolution on $C_3$: $C_{\\text{in}} = 128$.\n    Parameters = $1 \\cdot 1 \\cdot 128 \\cdot 192 + 192 = 24576 + 192 = 24768$.\n\nTotal parameters for lateral convolutions = $98496 + 49344 + 24768 = 172608$.\n\n**Parameters for the three $3 \\times 3$ convolutions:**\nThese convolutions are applied to $M_5$, $M_4$, and $M_3$ to produce $P_5$, $P_4$, and $P_3$.\nThe kernel size is $3 \\times 3$. For all three, the input and output channel dimensions are $C_{\\text{in}} = F = 192$ and $C_{\\text{out}} = F = 192$.\nTherefore, all three convolutions have the same number of parameters.\nParameters per convolution = $3 \\cdot 3 \\cdot 192 \\cdot 192 + 192 = 9 \\cdot (192^2) + 192 = 9 \\cdot 36864 + 192 = 331776 + 192 = 331968$.\n\nTotal parameters for the three $3 \\times 3$ convolutions = $3 \\times 331968 = 995904$.\n\n**Total Trainable Parameters in the FPN Pathway:**\nThe total is the sum of parameters from both sets of convolutions.\nTotal Parameters = (Parameters of lateral convolutions) + (Parameters of $3 \\times 3$ convolutions)\nTotal Parameters = $172608 + 995904 = 1168512$.", "answer": "$$\\boxed{1168512}$$", "id": "3103702"}, {"introduction": "The U-Net architecture is a cornerstone of modern image segmentation, celebrated for its symmetric encoder-decoder structure linked by skip connections that preserve fine-grained detail. However, the success of these connections hinges on perfect spatial alignment between the encoder's feature maps and the decoder's upsampled outputs. This practice [@problem_id:3103747] provides a crucial test of your understanding of how strided and transposed convolutions affect spatial dimensions, challenging you to verify the architectural integrity of a U-Net and identify potential misalignments that can degrade performance.", "problem": "You are to design and analyze a complete Convolutional Neural Network (CNN) architecture of the U-Net family for two-dimensional image segmentation. The U-Net consists of an encoder-decoder with skip connections. Your task is to formalize the encoder-decoder structure using first principles about two-dimensional convolution and transposed convolution, compute the concatenation channel dimensions at each skip connection stage, and verify whether spatial dimensions align across the skip connections given specified strides and paddings. The required derivations and computations must be made purely from mathematical definitions and shape formulas; no external deep learning libraries are to be used.\n\nStart from the following fundamental base and standard formulas for two-dimensional convolution operations:\n\n- Two-Dimensional (2D) convolution output size formula: for input spatial height $H_{\\text{in}}$ and width $W_{\\text{in}}$, kernel size $k$, stride $s$, and zero-padding $p$, the output spatial height $H_{\\text{out}}$ and width $W_{\\text{out}}$ satisfy\n$$\nH_{\\text{out}} = \\left\\lfloor \\frac{H_{\\text{in}} + 2p - k}{s} \\right\\rfloor + 1, \\quad\nW_{\\text{out}} = \\left\\lfloor \\frac{W_{\\text{in}} + 2p - k}{s} \\right\\rfloor + 1.\n$$\n- Two-Dimensional (2D) transposed convolution output size formula: for input spatial height $H_{\\text{in}}$ and width $W_{\\text{in}}$, kernel size $k$, stride $s$, and zero-padding $p$, the output spatial height $H_{\\text{out}}$ and width $W_{\\text{out}}$ satisfy\n$$\nH_{\\text{out}} = (H_{\\text{in}} - 1) \\cdot s - 2p + k, \\quad\nW_{\\text{out}} = (W_{\\text{in}} - 1) \\cdot s - 2p + k.\n$$\n\nArchitecture specification to be used for all computations:\n\n- Let the input tensor have spatial height $H_0$, width $W_0$, and channels $C_{\\text{in}}$.\n- The encoder has depth $D$ stages. At encoder stage $i$ (where $i \\in \\{0,1,\\dots,D-1\\}$), a two-convolution block with odd kernel size $k = 3$, stride $s = 1$, and padding $p = \\left\\lfloor \\frac{k}{2} \\right\\rfloor = 1$ preserves spatial dimensions and sets the feature channels to $C_i = C_0 \\cdot 2^i$, where $C_0$ is the base number of channels. This is followed by a downsampling convolution with kernel size $k = 2$, stride $s = 2$, and padding $p = 0$. Using the above formula, this downsampling produces\n$$\nH_{i+1} = \\left\\lfloor \\frac{H_i - 2}{2} \\right\\rfloor + 1 = \\left\\lfloor \\frac{H_i}{2} \\right\\rfloor, \\quad\nW_{i+1} = \\left\\lfloor \\frac{W_i - 2}{2} \\right\\rfloor + 1 = \\left\\lfloor \\frac{W_i}{2} \\right\\rfloor,\n$$\nwhere $(H_i, W_i)$ denotes the spatial size before downsampling at stage $i$.\n- At the bottom (after $D$ downsamplings), a two-convolution block with $k = 3$, $s = 1$, $p = 1$ preserves the bottom spatial size $(H_D, W_D)$ and sets the channels to $C_D = C_0 \\cdot 2^D$.\n- The decoder performs, for $i$ descending from $D-1$ to $0$, an upsampling transposed convolution with kernel size $k = 2$, stride $s = 2$, and padding $p = 0$, which yields\n$$\n\\tilde{H}_i = 2 \\cdot H_{i+1}, \\quad \\tilde{W}_i = 2 \\cdot W_{i+1}.\n$$\nThis upsampled feature (with channels reduced to $C_i$) is concatenated with the encoder feature at stage $i$ (which has spatial size $(H_i, W_i)$ and channels $C_i$). Therefore, the concatenation at skip connection stage $i$ has channel dimension $C^{\\text{concat}}_i = C_i + C_i = 2 C_i$. Spatial concatenation requires $(\\tilde{H}_i, \\tilde{W}_i) = (H_i, W_i)$; misalignment occurs if either $\\tilde{H}_i \\neq H_i$ or $\\tilde{W}_i \\neq W_i$.\n\nYou must implement a program that, for each provided test case, computes:\n- The list of concatenation channel dimensions $[C^{\\text{concat}}_0, C^{\\text{concat}}_1, \\dots, C^{\\text{concat}}_{D-1}]$.\n- A boolean indicating whether all skip connections are spatially aligned, defined as $[\\forall i \\in \\{0,\\dots,D-1\\}: \\tilde{H}_i = H_i \\wedge \\tilde{W}_i = W_i]$.\n\nScientific realism constraints:\n- All convolutions are as specified above; no cropping or padding adjustments beyond what is stated.\n- Misalignment must be detected strictly from the formulas, not patched by ad hoc rules.\n\nTest suite:\nUse exactly the following parameter sets as inputs, in order. Each case is a tuple $(H_0, W_0, C_{\\text{in}}, C_0, D)$:\n1. $(256, 256, 3, 32, 4)$\n2. $(16, 16, 1, 8, 4)$\n3. $(101, 77, 3, 16, 3)$\n4. $(64, 64, 1, 4, 0)$\n5. $(64, 65, 2, 12, 2)$\n\nRequired final output format:\n- Your program should produce a single line of output containing a list of results (one per test case) as a comma-separated list enclosed in square brackets.\n- Each per-test-case result must itself be a two-element list: the first element is the list of concatenation channel dimensions $[C^{\\text{concat}}_0, \\dots, C^{\\text{concat}}_{D-1}]$, and the second element is the alignment boolean.\n- For example, the outer list structure must be of the form $[[\\dots,\\dots], [\\dots,\\dots], \\dots]$; values must be represented using standard Python literals.", "solution": "The problem requires the design and analysis of a U-Net-like architecture for two-dimensional image segmentation. This involves computing the channel dimensions at each skip connection and verifying the spatial alignment between the encoder and decoder paths. The analysis must be based on the provided first principles of two-dimensional convolution and transposed convolution operations.\n\nFirst, the problem statement is subjected to a rigorous validation procedure.\n\n### Step 1: Extract Givens\n- **2D Convolution Output Size Formula**: For an input of size $H_{\\text{in}} \\times W_{\\text{in}}$, kernel size $k$, stride $s$, and padding $p$, the output size $H_{\\text{out}} \\times W_{\\text{out}}$ is given by:\n$$\nH_{\\text{out}} = \\left\\lfloor \\frac{H_{\\text{in}} + 2p - k}{s} \\right\\rfloor + 1, \\quad\nW_{\\text{out}} = \\left\\lfloor \\frac{W_{\\text{in}} + 2p - k}{s} \\right\\rfloor + 1\n$$\n- **2D Transposed Convolution Output Size Formula**: For an input of size $H_{\\text{in}} \\times W_{\\text{in}}$, kernel size $k$, stride $s$, and padding $p$, the output size $H_{\\text{out}} \\times W_{\\text{out}}$ is given by:\n$$\nH_{\\text{out}} = (H_{\\text{in}} - 1) \\cdot s - 2p + k, \\quad\nW_{\\text{out}} = (W_{\\text{in}} - 1) \\cdot s - 2p + k\n$$\n- **Input Tensor**: Dimensions are $(H_0, W_0, C_{\\text{in}})$.\n- **Encoder Architecture**:\n    - Depth $D$ stages, indexed by $i \\in \\{0, 1, \\dots, D-1\\}$.\n    - At stage $i$, a two-convolution block ($k=3, s=1, p=1$) sets channels to $C_i = C_0 \\cdot 2^i$.\n    - This is followed by a downsampling convolution ($k=2, s=2, p=0$) which halves spatial dimensions: $H_{i+1} = \\lfloor H_i / 2 \\rfloor$, $W_{i+1} = \\lfloor W_i / 2 \\rfloor$.\n- **Bottleneck**: At depth $D$, a two-convolution block ($k=3, s=1, p=1$) sets channels to $C_D = C_0 \\cdot 2^D$.\n- **Decoder Architecture**:\n    - For $i$ from $D-1$ down to $0$.\n    - An upsampling transposed convolution ($k=2, s=2, p=0$) is applied to the feature map from stage $i+1$, resulting in spatial dimensions $(\\tilde{H}_i, \\tilde{W}_i)$ where $\\tilde{H}_i = 2 \\cdot H_{i+1}$ and $\\tilde{W}_i = 2 \\cdot W_{i+1}$.\n    - The upsampled feature map is concatenated with the encoder feature map from stage $i$. The concatenated channel count is $C^{\\text{concat}}_i = C_i + C_i = 2C_i$.\n- **Alignment Condition**: Spatial alignment at stage $i$ requires $(\\tilde{H}_i, \\tilde{W}_i) = (H_i, W_i)$.\n- **Task**: For a given set of parameters $(H_0, W_0, C_{\\text{in}}, C_0, D)$, calculate the list of concatenated channel dimensions $[C^{\\text{concat}}_0, \\dots, C^{\\text{concat}}_{D-1}]$ and a boolean indicating if all skip connections are spatially aligned.\n\n### Step 2: Validate Using Extracted Givens\nThe problem is scientifically grounded in the principles of deep learning and convolutional neural networks. The provided formulas are standard definitions. The U-Net structure is well-established. The problem is well-posed, with all necessary parameters and relationships defined, allowing for a unique solution. The language is objective and formal. The derivations for downsampling ($H_{i+1} = \\lfloor H_i / 2 \\rfloor$) and upsampling ($\\tilde{H}_i = 2H_{i+1}$) are correct based on the base formulas. The problem is self-contained, consistent, and mathematically tractable.\n\n### Step 3: Verdict and Action\nThe problem is **valid**. A step-by-step solution can be formulated.\n\n### Principle-Based Design and Solution\nThe solution is derived by analyzing the three main components of the task: the encoder path spatial dimensions, the concatenated channel dimensions, and the skip connection alignment.\n\n**1. Encoder Path Spatial Dimension Calculation**\nThe encoder sequentially reduces the spatial dimensions of the feature maps. Starting with the input dimensions $(H_0, W_0)$, the dimensions at each subsequent stage $i+1$ are determined by the dimensions at stage $i$ via the downsampling operation.\nThe spatial dimensions $(H_i, W_i)$ at the output of the two-convolution block at encoder stage $i$ (and thus input to the downsampling) are tracked. The process is iterative for $i = 0, \\dots, D-1$:\n$$\nH_{i+1} = \\left\\lfloor \\frac{H_i}{2} \\right\\rfloor, \\quad W_{i+1} = \\left\\lfloor \\frac{W_i}{2} \\right\\rfloor\n$$\nWe can compute a sequence of spatial dimensions $[(H_0, W_0), (H_1, W_1), \\dots, (H_D, W_D)]$ by applying this rule $D$ times.\n\n**2. Concatenation Channel Dimension Calculation**\nIn the decoder path, at each stage $i$ (from $D-1$ down to $0$), the upsampled feature map is concatenated with the feature map from the corresponding encoder stage $i$. The problem states that the channel count for the encoder feature map at stage $i$ is $C_i = C_0 \\cdot 2^i$. The upsampled feature map from stage $i+1$ is also specified to have its channels reduced to $C_i$.\nThe concatenation operation combines these two feature maps along the channel axis. Therefore, the number of channels in the resulting feature map is:\n$$\nC^{\\text{concat}}_i = C_i + C_i = 2 C_i\n$$\nSubstituting the expression for $C_i$:\n$$\nC^{\\text{concat}}_i = 2 \\cdot (C_0 \\cdot 2^i) = C_0 \\cdot 2^{i+1}\n$$\nThis formula allows for the direct calculation of the channel dimensions for all skip connections, for $i \\in \\{0, 1, \\dots, D-1\\}$.\n\n**3. Skip Connection Alignment Verification**\nFor the concatenation at stage $i$ to be possible without cropping or padding, the spatial dimensions of the two feature maps must match. The feature map from the encoder has dimensions $(H_i, W_i)$. The upsampled feature map from the decoder has dimensions $(\\tilde{H}_i, \\tilde{W}_i)$.\nThe alignment condition is:\n$$\nH_i = \\tilde{H}_i \\quad \\text{and} \\quad W_i = \\tilde{W}_i\n$$\nFrom the decoder upsampling formula, we have $\\tilde{H}_i = 2 \\cdot H_{i+1}$. From the encoder downsampling formula, we have $H_{i+1} = \\lfloor H_i / 2 \\rfloor$. Substituting these into the alignment condition gives:\n$$\nH_i = 2 \\cdot \\left\\lfloor \\frac{H_i}{2} \\right\\rfloor\n$$\nThis equality holds if and only if $H_i$ is an even integer. If $H_i$ is even, $H_i = 2k$ for some integer $k$. Then $2 \\cdot \\lfloor (2k)/2 \\rfloor = 2 \\cdot \\lfloor k \\rfloor = 2k = H_i$. The condition is met.\nIf $H_i$ is odd, $H_i = 2k+1$ for some integer $k$. Then $2 \\cdot \\lfloor (2k+1)/2 \\rfloor = 2 \\cdot \\lfloor k + 1/2 \\rfloor = 2k$. Since $2k \\neq 2k+1$, the condition is not met.\nTherefore, the alignment condition for a single skip connection at stage $i$ simplifies to checking if both $H_i$ and $W_i$ are even numbers. For the entire architecture to be aligned, this must hold true for all skip connections, i.e., for all $i \\in \\{0, 1, \\dots, D-1\\}$.\n\n**Algorithm Synthesis**\nFor a given test case $(H_0, W_0, C_{\\text{in}}, C_0, D)$:\n1. Handle the base case where $D=0$. No skip connections exist. The list of channel dimensions is empty, and the alignment is vacuously true.\n2. For $D > 0$:\n    a. Initialize an array of heights `H_dims` with $H_0$ and widths `W_dims` with $W_0$.\n    b. Iteratively compute $H_i$ and $W_i$ for $i=1, \\dots, D$, and store them.\n    c. Calculate the list of concatenation channels $[C^{\\text{concat}}_0, \\dots, C^{\\text{concat}}_{D-1}]$ using the formula $C^{\\text{concat}}_i = C_0 \\cdot 2^{i+1}$.\n    d. Initialize an alignment flag to true. Iterate from $i=0$ to $D-1$. In each iteration, check if $H_i$ and $W_i$ (from the stored arrays) are both even. If a dimension is found to be odd at any stage, the flag is set to false and the check can be terminated.\n3. Combine the computed list of channels and the final alignment flag into the specified output format.\nThis procedure provides a complete and deterministic solution for each test case.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n# from scipy import ...\n\ndef solve():\n    \"\"\"\n    Analyzes a U-Net architecture for given parameters to compute skip connection\n    channel dimensions and spatial alignment.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        (256, 256, 3, 32, 4),\n        (16, 16, 1, 8, 4),\n        (101, 77, 3, 16, 3),\n        (64, 64, 1, 4, 0),\n        (64, 65, 2, 12, 2),\n    ]\n\n    all_results_str = []\n    for case in test_cases:\n        H0, W0, Cin, C0, D = case\n\n        # Handle the special case where depth D=0 (no skip connections)\n        if D == 0:\n            concat_channels = []\n            is_aligned = True\n            \n            # Format output string for this case\n            channels_str = ''\n            aligned_str = str(is_aligned)\n            result_str = f\"[[{channels_str}],{aligned_str}]\"\n            all_results_str.append(result_str)\n            continue\n\n        # Step 1: Calculate spatial dimensions down the encoder path\n        H_dims = [H0]\n        W_dims = [W0]\n        current_H, current_W = H0, W0\n        for _ in range(D):\n            # Applying formula H_{i+1} = floor(H_i / 2)\n            current_H = int(np.floor(current_H / 2))\n            current_W = int(np.floor(current_W / 2))\n            H_dims.append(current_H)\n            W_dims.append(current_W)\n        \n        # H_dims is [H_0, H_1, ..., H_D]\n        # W_dims is [W_0, W_1, ..., W_D]\n\n        # Step 2: Calculate concatenation channel dimensions\n        # C_concat_i = 2 * C_i = 2 * (C0 * 2^i) = C0 * 2^(i+1)\n        # This is for i from 0 to D-1\n        concat_channels = [C0 * (2**(i + 1)) for i in range(D)]\n\n        # Step 3: Verify spatial alignment for all skip connections\n        is_aligned = True\n        # The loop must check dimensions H_i, W_i for i = 0 to D-1\n        for i in range(D):\n            # Alignment requires H_i = 2 * floor(H_i/2), which is true iff H_i is even.\n            if H_dims[i] % 2 != 0 or W_dims[i] % 2 != 0:\n                is_aligned = False\n                break\n        \n        # Format the result for the current case into a string with no spaces\n        channels_str = ','.join(map(str, concat_channels))\n        aligned_str = str(is_aligned)\n        result_str = f\"[[{channels_str}],{aligned_str}]\"\n        all_results_str.append(result_str)\n\n    # Final print statement in the exact required format.\n    # Produces a single line, comma-separated list of results enclosed in brackets, with no spaces.\n    print(f\"[{','.join(all_results_str)}]\")\n\nsolve()\n```", "id": "3103747"}, {"introduction": "While it is easy to design a massive, powerful neural network on paper, real-world applications demand efficiency and adherence to resource constraints. This capstone exercise simulates the practical challenge of designing a CNN under a strict parameter budget, forcing a trade-off between performance-related metrics like receptive field and spatial resolution. By searching for an optimal configuration [@problem_id:3103767], you will develop an intuition for the complex interplay between layer choices and overall network cost, a vital skill for deploying models in practice.", "problem": "You are tasked with designing an algorithmic selector for a Convolutional Neural Network (CNN) architecture under a strict parameter budget, using foundational definitions of discrete convolution. The selector must choose, for each convolutional layer, the kernel size $k$, stride $s$, padding $p$, and number of output channels $C_{\\text{out}}$, subject to a total parameter constraint, and must maximize a mathematically specified surrogate for accuracy that depends on the receptive field and the spatial resolution across layers. Your program must not use any external data or machine learning libraries; it must compute all quantities algorithmically from the provided definitions and constraints.\n\nFundamental definitions to use:\n- A convolutional layer with kernel size $k$, input channels $C_{\\text{in}}$, and output channels $C_{\\text{out}}$ has parameter count\n$$\nP_{\\text{layer}} = k^2 \\, C_{\\text{in}} \\, C_{\\text{out}} + C_{\\text{out}},\n$$\nwhere the last term accounts for one bias per output channel.\n- Given an input spatial dimension $H \\times W$, the output spatial dimension $(H', W')$ of a two-dimensional convolution with stride $s$ and padding $p$ (applied identically along both dimensions) is\n$$\nH' = \\left\\lfloor \\frac{H + 2p - k}{s} \\right\\rfloor + 1, \\quad W' = \\left\\lfloor \\frac{W + 2p - k}{s} \\right\\rfloor + 1.\n$$\n- The receptive field size along one spatial dimension after a stack of layers obeys the recursion\n$$\nR_0 = 1, \\quad J_0 = 1,\n$$\n$$\nR_\\ell = R_{\\ell-1} + (k_\\ell - 1)\\,J_{\\ell-1}, \\quad J_\\ell = J_{\\ell-1} \\, s_\\ell,\n$$\nfor layer index $\\ell = 1,2,\\dots$, where $R_\\ell$ is the receptive field and $J_\\ell$ is the effective stride (\"jump\") relative to the input.\n\nSurrogate accuracy objective:\n- Define the surrogate accuracy score $S$ for an architecture with $L$ layers as\n$$\nS = \\sum_{\\ell=1}^{L} \\left[ \\ln\\!\\big(1 + C_{\\ell}\\big) \\cdot \\left( w_c \\cdot \\min\\!\\left(1, \\frac{R_\\ell}{R_{\\text{target}}}\\right) + w_r \\cdot \\frac{H_\\ell W_\\ell}{H_0 W_0} \\right) \\right],\n$$\nwhere $C_{\\ell}$ is the number of output channels at layer $\\ell$, $(H_\\ell, W_\\ell)$ are the spatial dimensions after layer $\\ell$, $(H_0, W_0)$ are the input spatial dimensions, $R_\\ell$ is the receptive field after layer $\\ell$, $R_{\\text{target}}$ is a target receptive field, and $w_c = 0.5$, $w_r = 0.5$ weight the coverage and resolution contributions equally. The natural logarithm is used for the channel utility term.\n\nConstraints and search space:\n- Padding must be \"same-style\" in the sense $p_\\ell = \\left\\lfloor \\frac{k_\\ell}{2} \\right\\rfloor$ for every layer $\\ell$. This ensures intuitive control over spatial dimensions when $s_\\ell = 1$.\n- All layers must have valid positive spatial dimensions, that is $H_\\ell \\ge 1$ and $W_\\ell \\ge 1$.\n- Let the total parameter budget be $B$. Architectures are feasible if the sum of parameters over all layers\n$$\nP_{\\text{total}} = \\sum_{\\ell=1}^{L} \\left( k_\\ell^2 \\, C_{\\ell-1} \\, C_{\\ell} + C_\\ell \\right)\n$$\nsatisfies $P_{\\text{total}} \\le B$, where $C_0$ is the input channel count.\n- The search space for each layer is discrete: $k_\\ell \\in \\{1,3,5\\}$, $s_\\ell \\in \\{1,2\\}$, and $C_\\ell$ drawn from a specified set per test case. Padding is fixed by $k_\\ell$ as above.\n\nObjective:\n- Among all architectures that satisfy the constraints, choose one that maximizes $S$. In case of ties in $S$ to within numerical tolerance, prefer architectures with smaller $P_{\\text{total}}$. If a tie persists, prefer lexicographically smaller layer specifications when flattened to the sequence $(k_1,s_1,p_1,C_1,k_2,s_2,p_2,C_2,\\dots)$.\n\nYour program must implement the exact computational pipeline defined above and solve the following test suite. For each test case, the program must search over all allowed numbers of layers $L$ and all allowed per-layer choices, subject to the budget and validity constraints, and report the best architecture.\n\nTest suite:\n- Test case $1$ (\"happy path\"):\n    - Input spatial dimensions: $(H_0, W_0) = (32, 32)$.\n    - Input channels: $C_0 = 3$.\n    - Budget: $B = 2000$.\n    - Target receptive field: $R_{\\text{target}} = 16$.\n    - Allowed number of layers: $L \\in \\{3\\}$.\n    - Allowed output channels per layer: $C_\\ell \\in \\{8,16,32\\}$ for all $\\ell$.\n- Test case $2$ (boundary small budget):\n    - Input spatial dimensions: $(H_0, W_0) = (32, 32)$.\n    - Input channels: $C_0 = 3$.\n    - Budget: $B = 110$.\n    - Target receptive field: $R_{\\text{target}} = 8$.\n    - Allowed number of layers: $L \\in \\{2\\}$.\n    - Allowed output channels per layer: $C_\\ell \\in \\{8,16\\}$ for all $\\ell$.\n- Test case $3$ (larger budget):\n    - Input spatial dimensions: $(H_0, W_0) = (64, 64)$.\n    - Input channels: $C_0 = 3$.\n    - Budget: $B = 5000$.\n    - Target receptive field: $R_{\\text{target}} = 32$.\n    - Allowed number of layers: $L \\in \\{3\\}$.\n    - Allowed output channels per layer: $C_\\ell \\in \\{16,32,64\\}$ for all $\\ell$.\n- Test case $4$ (edge small input):\n    - Input spatial dimensions: $(H_0, W_0) = (8, 8)$.\n    - Input channels: $C_0 = 3$.\n    - Budget: $B = 800$.\n    - Target receptive field: $R_{\\text{target}} = 8$.\n    - Allowed number of layers: $L \\in \\{2\\}$.\n    - Allowed output channels per layer: $C_\\ell \\in \\{8,16,32\\}$ for all $\\ell$.\n\nOutput specification:\n- For each test case, output a list of the form\n$$\n[\\; S^\\star,\\; P_{\\text{total}}^\\star,\\; [[k_1,s_1,p_1,C_1],\\,[k_2,s_2,p_2,C_2],\\,\\dots]\\;],\n$$\nwhere $S^\\star$ is the maximized surrogate score rounded to $4$ decimal places, $P_{\\text{total}}^\\star$ is the total parameter count of the chosen architecture as an integer, and the innermost list enumerates the chosen layer hyperparameters in order. If multiple values of $L$ are allowed for a test case, the selected architecture may have any $L$ in that set.\n- Your program should produce a single line of output containing the results for all four test cases as a comma-separated list enclosed in square brackets with no spaces, for example\n$$\n[\\text{result}_1,\\text{result}_2,\\text{result}_3,\\text{result}_4].\n$$\nFor this problem, each $\\text{result}_i$ must itself be formatted with no spaces, including the nested lists, exactly as\n$$\n[\\text{score},\\text{params},[[k_1,s_1,p_1,C_1],\\dots]].\n$$", "solution": "The problem requires the design of an algorithmic selector for a Convolutional Neural Network (CNN) architecture. The selector must operate under a strict parameter budget and aim to maximize a given surrogate accuracy score, $S$. The selection process involves choosing the kernel size $k$, stride $s$, and number of output channels $C_{\\text{out}}$ for each layer in the network. The problem is a constrained optimization task over a discrete and finite search space.\n\nThe solution proceeds first by a rigorous validation of the problem statement, followed by the design and implementation of an exhaustive search algorithm to find the optimal architecture.\n\n### Problem Validation\n\n**Step 1: Extract Givens**\n\n- **Parameter Count per Layer**: $P_{\\text{layer}} = k^2 \\, C_{\\text{in}} \\, C_{\\text{out}} + C_{\\text{out}}$\n- **Output Spatial Dimension**: $H' = \\left\\lfloor \\frac{H + 2p - k}{s} \\right\\rfloor + 1$, $W' = \\left\\lfloor \\frac{W + 2p - k}{s} \\right\\rfloor + 1$\n- **Receptive Field Recursion**:\n  - $R_0 = 1, J_0 = 1$\n  - $R_\\ell = R_{\\ell-1} + (k_\\ell - 1)\\,J_{\\ell-1}$\n  - $J_\\ell = J_{\\ell-1} \\, s_\\ell$\n- **Surrogate Accuracy Score**: $S = \\sum_{\\ell=1}^{L} \\left[ \\ln\\!\\big(1 + C_{\\ell}\\big) \\cdot \\left( w_c \\cdot \\min\\!\\left(1, \\frac{R_\\ell}{R_{\\text{target}}}\\right) + w_r \\cdot \\frac{H_\\ell W_\\ell}{H_0 W_0} \\right) \\right]$, with $w_c = 0.5, w_r = 0.5$.\n- **Constraints**:\n  1.  Padding: $p_\\ell = \\left\\lfloor \\frac{k_\\ell}{2} \\right\\rfloor$ for every layer $\\ell$.\n  2.  Valid Spatial Dimensions: $H_\\ell \\ge 1, W_\\ell \\ge 1$ for all $\\ell$.\n  3.  Parameter Budget: $P_{\\text{total}} = \\sum_{\\ell=1}^{L} P_{\\text{layer}}(\\ell) \\le B$, where $P_{\\text{layer}}(\\ell) = k_\\ell^2 \\, C_{\\ell-1} \\, C_{\\ell} + C_\\ell$.\n- **Search Space**:\n  - Kernel size: $k_\\ell \\in \\{1,3,5\\}$\n  - Stride: $s_\\ell \\in \\{1,2\\}$\n  - Output channels: $C_\\ell$ from a specified set for each test case.\n- **Objective**: Maximize $S$.\n- **Tie-Breaking Rules**:\n  1.  Prefer smaller total parameters $P_{\\text{total}}$.\n  2.  If still tied, prefer lexicographically smaller flattened layer specification sequence $(k_1,s_1,p_1,C_1, k_2, \\dots)$.\n- **Test Cases**: Four specific test cases are provided with values for $(H_0, W_0)$, $C_0$, $B$, $R_{\\text{target}}$, allowed $L$, and allowed $C_\\ell$.\n\n**Step 2: Validate Using Extracted Givens**\n\nThe problem statement is analyzed against the validation criteria.\n\n- **Scientifically Grounded**: The definitions for parameter count, output dimension calculation, and receptive field propagation are standard and fundamental in the field of deep learning. The surrogate accuracy score $S$ is a synthetic objective function, but it is mathematically well-defined and constructed from plausible heuristics: rewarding networks for effective receptive field coverage, preservation of spatial information (resolution), and increased feature complexity (channel count). The problem is free of pseudoscience and adheres to established mathematical and computational principles.\n- **Well-Posed**: The task is to find the maximum of a function $S$ over a discrete search space. For each test case, the number of layers $L$, and the sets of possible values for $k_\\ell$, $s_\\ell$, and $C_\\ell$ are all finite. This results in a finite, albeit potentially large, number of possible architectures. The problem is a well-defined constrained optimization problem. The explicit tie-breaking rules ensure that a unique solution exists.\n- **Objective**: The problem is specified entirely in formal mathematical language. The objective function, constraints, and search space are all defined with precision, leaving no room for subjectivity or ambiguity.\n\n**Step 3: Verdict and Action**\n\nThe problem is determined to be **valid**. It is scientifically sound, well-posed, objective, and self-contained. The provided data and constraints are consistent and sufficient to determine a unique solution for each test case. Therefore, a computational solution will be developed.\n\n### Algorithmic Design and Implementation\n\nThe core of the solution is an exhaustive search (brute-force) algorithm that explores all possible network architectures allowed by the discrete search space for each test case. Given the finite and manageably small size of the search spaces, this approach is guaranteed to find the true optimal architecture as defined by the problem.\n\nThe algorithm proceeds as follows for each test case:\n\n1.  **Initialization**: The parameters for the test case—$(H_0, W_0)$, $C_0$, $B$, $R_{\\text{target}}$, allowed number of layers $L \\in \\mathcal{L}$, and allowed channel counts $C_\\ell \\in \\mathcal{C}$—are extracted. A data structure is initialized to store the best architecture found so far, tracking its score $S^\\star$, parameter count $P^\\star$, and layer specifications. This is initialized with a score of $-1$ to ensure any valid architecture will be selected.\n\n2.  **Architecture Generation**: The algorithm iterates through each permitted number of layers $L \\in \\mathcal{L}$. For a fixed $L$, the set of all possible single-layer configurations $(k, s, C)$ is formed. The set of all possible architectures with $L$ layers is then the $L$-th Cartesian power of this single-layer set. This systematic generation ensures every single combination is considered.\n\n3.  **Architecture Evaluation**: Each generated architecture, which is a sequence of $L$ layer configurations, is evaluated sequentially.\n    - Starting with the input state ($H_0, W_0, C_0, R_0=1, J_0=1$), the algorithm processes one layer at a time.\n    - For each layer $\\ell$:\n        a. The required layer parameters $(k_\\ell, s_\\ell, C_\\ell)$ are taken from the architecture specification. Padding $p_\\ell$ is calculated as $p_\\ell = \\lfloor k_\\ell / 2 \\rfloor$.\n        b. The parameter cost of the layer, $P_\\ell$, is calculated and added to the total, $P_{\\text{total}}$. If $P_{\\text{total}} > B$, the architecture violates the budget constraint and is immediately discarded.\n        c. The output spatial dimensions $(H_\\ell, W_\\ell)$ are calculated. If either $H_\\ell < 1$ or $W_\\ell < 1$, the architecture is invalid and discarded.\n        d. The new receptive field $R_\\ell$ and effective stride $J_\\ell$ are computed using the provided recurrence relations.\n        e. The layer's contribution to the surrogate score $S$ is calculated and added to the total score, $S_{\\text{total}}$.\n        f. The state variables $(H, W, C_{\\text{in}}, R, J)$ are updated for the next layer.\n\n4.  **Selection and Tie-Breaking**: If an architecture is processed successfully through all its layers without violating any constraints, its final score $S_{\\text{total}}$ and parameter count $P_{\\text{total}}$ are compared against the best-so-far architecture.\n    - If $S_{\\text{total}}$ is greater than the current best score $S^\\star$ (within a small numerical tolerance), the new architecture becomes the best.\n    - If $S_{\\text{total}}$ is effectively equal to $S^\\star$, the tie-breaking rules are applied in order:\n        1.  If $P_{\\text{total}}$ is less than the current best $P^\\star$, the new architecture is chosen.\n        2.  If $P_{\\text{total}}$ is also equal, the layer specifications are flattened into a single sequence of numbers, and the new architecture is chosen if its sequence is lexicographically smaller than the current best.\n\n5.  **Output Formatting**: After iterating through all possible architectures for a given test case, the details of the final optimal architecture ($S^\\star$, $P_{\\text{total}}^\\star$, and layer specifications) are formatted into the precise string format required by the problem statement, rounding the score to four decimal places and removing all whitespace from the list representations. This process is repeated for all test cases, and the final results are concatenated into a single output line.\n\nThis brute-force search combined with rigorous evaluation and rule-based selection guarantees finding the unique optimal architecture for each case as defined by the problem's objective and constraints.", "answer": "```python\nimport numpy as np\nimport itertools\n\ndef solve():\n    \"\"\"\n    Solves the CNN architecture selection problem for a suite of test cases.\n    \"\"\"\n    test_cases = [\n        # Test case 1 (\"happy path\")\n        {\n            'H0': 32, 'W0': 32, 'C0': 3, 'B': 2000, 'R_target': 16,\n            'allowed_L': {3}, 'allowed_C': {8, 16, 32}\n        },\n        # Test case 2 (boundary small budget)\n        {\n            'H0': 32, 'W0': 32, 'C0': 3, 'B': 110, 'R_target': 8,\n            'allowed_L': {2}, 'allowed_C': {8, 16}\n        },\n        # Test case 3 (larger budget)\n        {\n            'H0': 64, 'W0': 64, 'C0': 3, 'B': 5000, 'R_target': 32,\n            'allowed_L': {3}, 'allowed_C': {16, 32, 64}\n        },\n        # Test case 4 (edge small input)\n        {\n            'H0': 8, 'W0': 8, 'C0': 3, 'B': 800, 'R_target': 8,\n            'allowed_L': {2}, 'allowed_C': {8, 16, 32}\n        },\n    ]\n\n    all_results = []\n\n    for case in test_cases:\n        H0, W0, C0, B, R_target = case['H0'], case['W0'], case['C0'], case['B'], case['R_target']\n        allowed_L, allowed_C_set = case['allowed_L'], case['allowed_C']\n        \n        w_c, w_r = 0.5, 0.5\n        k_choices = (1, 3, 5)\n        s_choices = (1, 2)\n        \n        best_result = {'score': -1.0, 'params': float('inf'), 'spec': []}\n        TOL = 1e-9\n\n        for L in allowed_L:\n            single_layer_options = list(itertools.product(k_choices, s_choices, sorted(list(allowed_C_set))))\n            \n            all_architectures = itertools.product(single_layer_options, repeat=L)\n\n            for arch_spec in all_architectures:\n                is_valid = True\n                total_params = 0\n                total_score = 0.0\n                \n                H_current, W_current = H0, W0\n                C_in = C0\n                R_current, J_current = 1, 1\n                \n                layer_specs_list = []\n\n                for layer_params in arch_spec:\n                    k, s, C_out = layer_params\n                    p = k // 2\n\n                    # 1. Parameter constraint\n                    layer_p_count = k**2 * C_in * C_out + C_out\n                    total_params += layer_p_count\n                    if total_params > B:\n                        is_valid = False\n                        break\n\n                    # 2. Spatial dimension constraint\n                    H_next = (H_current + 2*p - k) // s + 1\n                    W_next = (W_current + 2*p - k) // s + 1\n                    if H_next < 1 or W_next < 1:\n                        is_valid = False\n                        break\n\n                    # 3. Receptive field update\n                    R_next = R_current + (k - 1) * J_current\n                    J_next = J_current * s\n                    \n                    # 4. Score calculation\n                    coverage_term = w_c * min(1.0, R_next / R_target)\n                    resolution_term = w_r * (H_next * W_next) / (H0 * W0)\n                    channel_term = np.log(1 + C_out)\n                    total_score += channel_term * (coverage_term + resolution_term)\n\n                    # Update state for next layer\n                    H_current, W_current = H_next, W_next\n                    C_in = C_out\n                    R_current, J_current = R_next, J_next\n                    layer_specs_list.append([k, s, p, C_out])\n\n                if is_valid:\n                    # Retrieve current best flattened spec for lexicographical comparison\n                    best_spec_list = best_result['spec']\n                    flat_best_spec = [item for sublist in best_spec_list for item in sublist] if best_spec_list else []\n                    \n                    # Candidate flattened spec\n                    flat_current_spec = [item for sublist in layer_specs_list for item in sublist]\n\n                    # Tie-breaking logic\n                    if total_score > best_result['score'] + TOL:\n                        best_result = {'score': total_score, 'params': total_params, 'spec': layer_specs_list}\n                    elif abs(total_score - best_result['score']) < TOL:\n                        if total_params < best_result['params']:\n                            best_result = {'score': total_score, 'params': total_params, 'spec': layer_specs_list}\n                        elif total_params == best_result['params']:\n                            if not flat_best_spec or flat_current_spec < flat_best_spec:\n                                best_result = {'score': total_score, 'params': total_params, 'spec': layer_specs_list}\n        \n        # Format the result for this test case\n        score_str = f\"{best_result['score']:.4f}\"\n        params_str = str(best_result['params'])\n        spec_str =str(best_result['spec']).replace(\" \", \"\")\n        \n        result_str = f\"[{score_str},{params_str},{spec_str}]\"\n        all_results.append(result_str)\n\n    # Final print statement\n    print(f\"[{','.join(all_results)}]\")\n\nsolve()\n```", "id": "3103767"}]}