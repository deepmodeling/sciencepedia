{"hands_on_practices": [{"introduction": "Before we can apply the iterative updates of gradient descent, we must first master the \"mini-batch\" component. This initial practice focuses on the crucial first step of any deep learning workflow: partitioning a large dataset into smaller, computationally manageable chunks. By calculating the number of mini-batches and the size of the final, potentially smaller batch, you will solidify your understanding of how data is processed within a single training epoch.", "problem": "In the field of machine learning, training a neural network often involves an iterative optimization process called mini-batch gradient descent. In this process, the entire training dataset is partitioned into smaller, equally-sized subsets called mini-batches. The model's parameters are updated after processing each mini-batch. One complete pass through all the mini-batches, covering the entire training dataset, is known as an epoch.\n\nA data science team is training a convolutional neural network to classify astronomical images. Their training dataset consists of a total of $N = 50,000$ distinct images. They have chosen to use a mini-batch size of $b = 128$ images. When the total number of training examples $N$ is not perfectly divisible by the batch size $b$, it is standard practice for the final mini-batch of the epoch to simply contain all the remaining samples.\n\nCalculate the total number of mini-batches that will be processed in one epoch, and determine the size of the very last mini-batch for that epoch. Provide your answer as two integers: the total number of mini-batches and the size of the final mini-batch, in that order.", "solution": "Let $N$ denote the total number of training examples and $b$ the mini-batch size. Write $N$ in Euclidean division form as\n$$\nN = qb + r,\\quad 0 \\leq r < b,\n$$\nwhere $q = \\left\\lfloor \\frac{N}{b} \\right\\rfloor$ and $r = N - qb$.\nThe total number of mini-batches in one epoch is\n$$\nm = \\begin{cases}\nq, & r=0,\\\\\nq+1, & r>0,\n\\end{cases}\n$$\nsince a nonzero remainder requires one additional (smaller) mini-batch. The size of the final mini-batch is\n$$\nL = \\begin{cases}\nb, & r=0,\\\\\nr, & r>0.\n\\end{cases}\n$$\nWith $N=50000$ and $b=128$, compute $q$ by bounding:\n$$\n128 \\times 390 = 49920,\\quad 128 \\times 391 = 50048 > 50000 \\;\\Rightarrow\\; q = 390.\n$$\nThen\n$$\nr = N - qb = 50000 - 128 \\times 390 = 50000 - 49920 = 80.\n$$\nSince $r>0$, the total number of mini-batches is\n$$\nm = q + 1 = 391,\n$$\nand the size of the final mini-batch is\n$$\nL = r = 80.\n$$\nThus, the total number of mini-batches is $391$ and the size of the final mini-batch is $80$.", "answer": "$$\\boxed{\\begin{pmatrix}391 & 80\\end{pmatrix}}$$", "id": "2186998"}, {"introduction": "With the data properly batched, we now turn to the heart of the optimization process: the \"gradient descent\" update rule. This exercise simplifies the scenario to a single parameter to provide a clear, unobstructed view of the core mechanism at work. By executing a single update step, you will see precisely how the learning rate, $\\eta$, scales the gradient, $\\nabla J(\\theta)$, to move the parameter towards a lower-cost value, forming the basis of all gradient-based learning.", "problem": "A computational science student is training a simple predictive model. The model's behavior is controlled by a single dimensionless parameter, $\\theta$. The goal is to find the value of $\\theta$ that minimizes the model's prediction error, which is measured by a cost function $J(\\theta)$.\n\nThe student employs a numerical optimization technique known as gradient descent. The process starts with an initial guess for the parameter and iteratively refines it. Each update step is designed to move the parameter value in the direction opposite to the cost function's gradient. The magnitude of each step is determined by a parameter called the learning rate.\n\nThe student initializes the parameter at $\\theta_0 = 2$. For the first iteration, they use a subset of their data to compute the gradient of the cost function with respect to the parameter at this initial point. The computation yields a gradient value of $\\nabla J(\\theta_0) = 4$. The learning rate for the optimization process is set to $\\eta = 0.01$.\n\nCalculate the updated value of the parameter, $\\theta_1$, after this first iteration. Report your answer to three significant figures.", "solution": "We use the standard gradient descent update rule for a single parameter:\n$$\n\\theta_{k+1} = \\theta_{k} - \\eta \\frac{dJ}{d\\theta}\\bigg|_{\\theta=\\theta_{k}}.\n$$\nFor the first iteration with $k=0$, the given values are $\\theta_{0} = 2$, learning rate $\\eta = 0.01$, and gradient $\\nabla J(\\theta_{0}) = 4$. Substituting these into the update rule gives:\n$$\n\\theta_{1} = \\theta_{0} - \\eta \\nabla J(\\theta_{0}) = 2 - 0.01 \\times 4.\n$$\nCompute the product:\n$$\n0.01 \\times 4 = 0.04,\n$$\nso\n$$\n\\theta_{1} = 2 - 0.04 = 1.96.\n$$\nRounded to three significant figures, the value is $1.96$.", "answer": "$$\\boxed{1.96}$$", "id": "2187026"}, {"introduction": "While standard gradient descent is effective, its path to the minimum can be slow and erratic. This final practice introduces momentum, a powerful and widely-used technique to accelerate convergence and smooth the optimization trajectory. This problem presents a special case where the current mini-batch gradient is zero, providing a profound insight into how momentum works. You will see how the accumulated \"velocity\" from past steps allows the optimizer to continue making progress, demonstrating why momentum is a key ingredient in modern optimizers.", "problem": "An engineer is training a simple linear regression model of the form $h_{\\theta}(x) = \\theta_0 + \\theta_1 x$ using mini-batch gradient descent with a momentum term. The optimization algorithm updates the parameters $\\theta = (\\theta_0, \\theta_1)$ at each step $t$ according to the following rules:\n\n1.  $v_t = \\gamma v_{t-1} + \\eta \\nabla_{\\theta} J_B(\\theta_{t-1})$\n2.  $\\theta_t = \\theta_{t-1} - v_t$\n\nwhere $\\theta_{t-1}$ are the parameter values from the previous step, $v_t$ is the current velocity vector, $v_{t-1}$ is the previous velocity vector, $\\gamma$ is the momentum coefficient, $\\eta$ is the learning rate, and $\\nabla_{\\theta} J_B(\\theta_{t-1})$ is the gradient of the loss function computed on the current mini-batch $B$ using the parameters $\\theta_{t-1}$.\n\nThe loss function is the Mean Squared Error (MSE), defined for a mini-batch $B$ with $m_B$ samples as:\n$J_B(\\theta) = \\frac{1}{2m_B} \\sum_{(x^{(i)}, y^{(i)}) \\in B} (h_{\\theta}(x^{(i)}) - y^{(i)})^2$\n\nAt the beginning of the current iteration (step $t$), the state of the model is as follows:\n- Parameters: $\\theta_{t-1} = (\\theta_0, \\theta_1) = (1.0, 2.0)$\n- Previous velocity vector: $v_{t-1} = (v_{0, t-1}, v_{1, t-1}) = (0.1, -0.2)$\n\nThe hyperparameters are set to:\n- Learning rate: $\\eta = 0.01$\n- Momentum coefficient: $\\gamma = 0.9$\n\nFor the current update step, the algorithm uses the following mini-batch $B$, which contains two data points:\n$B = \\{(1, 3), (3, 7)\\}$\n\nCalculate the updated value of the parameter $\\theta_1$ at the end of this iteration, denoted as $\\theta_{1,t}$.", "solution": "The goal is to find the updated parameter $\\theta_{1,t}$ after a single step of mini-batch gradient descent with momentum.\n\nThe update rule for the parameters $\\theta$ is given by a two-step process:\n1. Update the velocity vector: $v_t = \\gamma v_{t-1} + \\eta \\nabla_{\\theta} J_B(\\theta_{t-1})$\n2. Update the parameters: $\\theta_t = \\theta_{t-1} - v_t$\n\nWe are interested in the parameter $\\theta_1$. Let's write the update rules specifically for this parameter:\n$v_{1,t} = \\gamma v_{1,t-1} + \\eta \\frac{\\partial J_B(\\theta_{t-1})}{\\partial \\theta_1}$\n$\\theta_{1,t} = \\theta_{1,t-1} - v_{1,t}$\n\nThe first step is to compute the partial derivative of the loss function $J_B$ with respect to $\\theta_1$, evaluated at $\\theta_{t-1} = (1.0, 2.0)$.\n\nThe loss function is $J_B(\\theta) = \\frac{1}{2m_B} \\sum_{(x^{(i)}, y^{(i)}) \\in B} ((\\theta_0 + \\theta_1 x^{(i)}) - y^{(i)})^2$.\nThe partial derivative with respect to $\\theta_1$ is:\n$\\frac{\\partial J_B}{\\partial \\theta_1} = \\frac{1}{m_B} \\sum_{(x^{(i)}, y^{(i)}) \\in B} ((\\theta_0 + \\theta_1 x^{(i)}) - y^{(i)}) x^{(i)}$\n\nThe mini-batch is $B = \\{(1, 3), (3, 7)\\}$, so the mini-batch size is $m_B=2$. The current parameters are $\\theta_0 = 1.0$ and $\\theta_1 = 2.0$.\n\nLet's calculate the error term, $(\\theta_0 + \\theta_1 x^{(i)}) - y^{(i)}$, for each point in the mini-batch.\nFor the first point $(x^{(1)}, y^{(1)}) = (1, 3)$:\nPrediction: $h_{\\theta}(x^{(1)}) = \\theta_0 + \\theta_1 x^{(1)} = 1.0 + 2.0 \\cdot 1 = 3.0$\nError: $h_{\\theta}(x^{(1)}) - y^{(1)} = 3.0 - 3 = 0.0$\n\nFor the second point $(x^{(2)}, y^{(2)}) = (3, 7)$:\nPrediction: $h_{\\theta}(x^{(2)}) = \\theta_0 + \\theta_1 x^{(2)} = 1.0 + 2.0 \\cdot 3 = 1.0 + 6.0 = 7.0$\nError: $h_{\\theta}(x^{(2)}) - y^{(2)} = 7.0 - 7 = 0.0$\n\nNow, substitute these errors into the expression for the partial derivative:\n$\\frac{\\partial J_B}{\\partial \\theta_1} = \\frac{1}{2} \\left[ (0.0) \\cdot x^{(1)} + (0.0) \\cdot x^{(2)} \\right]$\n$\\frac{\\partial J_B}{\\partial \\theta_1} = \\frac{1}{2} \\left[ (0.0) \\cdot 1 + (0.0) \\cdot 3 \\right] = 0.0$\nThe gradient component for $\\theta_1$ is exactly zero.\n\nNext, we calculate the new velocity component for $\\theta_1$, which is $v_{1,t}$, using the given hyperparameters and previous velocity.\nThe given values are $\\gamma = 0.9$, $\\eta = 0.01$, and the previous velocity component for $\\theta_1$ is $v_{1,t-1} = -0.2$.\n$v_{1,t} = \\gamma v_{1,t-1} + \\eta \\frac{\\partial J_B}{\\partial \\theta_1}$\n$v_{1,t} = (0.9)(-0.2) + (0.01)(0.0)$\n$v_{1,t} = -0.18 + 0 = -0.18$\n\nFinally, we update the parameter $\\theta_1$. The current value is $\\theta_{1,t-1} = 2.0$.\n$\\theta_{1,t} = \\theta_{1,t-1} - v_{1,t}$\n$\\theta_{1,t} = 2.0 - (-0.18)$\n$\\theta_{1,t} = 2.0 + 0.18 = 2.18$\n\nSo, even though the gradient for the current mini-batch was zero, the parameter $\\theta_1$ still changed due to the momentum term carrying over velocity from the previous update step.", "answer": "$$\\boxed{2.18}$$", "id": "2187015"}]}