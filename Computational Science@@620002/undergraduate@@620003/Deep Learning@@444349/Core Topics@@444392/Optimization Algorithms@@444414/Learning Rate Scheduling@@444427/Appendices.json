{"hands_on_practices": [{"introduction": "In many deep learning frameworks, the implementation of weight decay is coupled with the learning rate, which can obscure the true effect of each hyperparameter. This practice challenges you to derive the update rule from the more fundamental perspective of proximal gradient methods. By defining and controlling the \"effective step size,\" you will design a learning rate schedule that offers more direct and interpretable control over the optimization trajectory, particularly in the context of learning rate warm-up and decay [@problem_id:3142924].", "problem": "You are asked to design and implement a learning rate scheduling function for Stochastic Gradient Descent (SGD) with weight decay regularization. Begin from a principle-based model of discrete-time optimization: treat weight decay as an implicit proximal step for a squared norm penalty. The base objective is $J(\\mathbf{w}) = L(\\mathbf{w}) + \\frac{\\lambda}{2}\\lVert \\mathbf{w} \\rVert_2^2$, where $L(\\mathbf{w})$ is the data-fitting term, $\\mathbf{w} \\in \\mathbb{R}^d$ are the parameters, and $\\lambda \\ge 0$ is the weight decay coefficient. Consider the implicit-proximal update at iteration $t$ with learning rate $\\eta_t$:\n$$\n\\mathbf{w}_{t+1} \\in \\arg\\min_{\\mathbf{w}} \\left\\{ \\frac{1}{2}\\left\\lVert \\mathbf{w} - \\left(\\mathbf{w}_t - \\eta_t \\nabla L(\\mathbf{w}_t)\\right)\\right\\rVert_2^2 + \\frac{\\eta_t \\lambda}{2} \\lVert \\mathbf{w} \\rVert_2^2 \\right\\}.\n$$\nDefine the effective step in weight space as the scalar that multiplies the negative gradient direction in the resulting update rule at iteration $t$. Your design goal is to keep this effective step equal to a target constant $s_{\\mathrm{target}}$ during an early warm-up window of iterations $t \\in \\{0,1,\\dots,T_{\\mathrm{warm}}-1\\}$, then smoothly reduce it to a smaller value $s_{\\min}$ by the end of training at $t = T_{\\mathrm{total}}-1$ using a monotone exponential decay that exactly attains $s_{\\min}$ at the final iteration. Your schedule must respect positivity and stability constraints: the learning rate must satisfy $0  \\eta_t \\le \\eta_{\\max}$, where $\\eta_{\\max} = \\frac{2}{L_g}$ and $L_g  0$ is a provided Lipschitz constant bound for the gradient of $L(\\mathbf{w})$. If the unconstrained value required to keep the effective step equal to $s_{\\mathrm{target}}$ (or its exponentially decaying continuation) violates $0  \\eta_t \\le \\eta_{\\max}$, replace it by $\\eta_{\\max}$.\n\nTasks:\n1. Starting only from the implicit-proximal update definition and the notion of the effective step as the coefficient of $-\\nabla L(\\mathbf{w}_t)$ in the resulting update rule, derive the expression for the effective step at iteration $t$ and invert it to obtain $\\eta_t$ as a function of the desired effective step at iteration $t$ and $\\lambda$.\n2. Specify a piecewise effective-step schedule $s(t)$ that equals $s_{\\mathrm{target}}$ for $t \\in \\{0,1,\\dots,T_{\\mathrm{warm}}-1\\}$ and decays exponentially to $s_{\\min}$ at $t = T_{\\mathrm{total}}-1$. Determine the exponential decay constant so that the endpoint condition is met exactly.\n3. Combine the above to produce a learning rate schedule $\\eta_t$ under the constraint $0  \\eta_t \\le \\eta_{\\max}$ for all $t$.\n4. Implement a self-contained program that computes and returns the learning rate values at specified evaluation iterations for each of the following four test cases. If $T_{\\mathrm{total}} - T_{\\mathrm{warm}} - 1 \\le 0$, treat the decay interval length as $1$ for the purpose of defining the exponential schedule.\n\nTest suite (each case specifies $(T_{\\mathrm{total}}, T_{\\mathrm{warm}}, s_{\\mathrm{target}}, s_{\\min}, \\lambda, L_g, \\text{eval times})$):\n- Case A: $(100, 40, 0.01, 0.002, 0.1, 50, [0, 20, 40, 60, 99])$.\n- Case B: $(60, 20, 0.02, 0.005, 0, 100, [0, 19, 20, 59])$.\n- Case C: $(80, 30, 0.01, 0.003, 80, 50, [0, 29, 30, 79])$.\n- Case D: $(50, 0, 0.05, 0.01, 0.5, 200, [0, 25, 49])$.\n\nFinal output specification:\n- Your program should produce a single line of output containing the results as a comma-separated list of lists enclosed in square brackets (for example, $[[\\text{list for Case A}],[\\text{list for Case B}],[\\text{list for Case C}],[\\text{list for Case D}]]$)).\n- Each inner list must contain the learning rate values $\\eta_t$ at the specified evaluation times for that case, in the same order as provided.\n- All returned values must be real numbers (floats). No physical units are used; angles are not used; do not use percentages anywhere.", "solution": "The user-provided problem statement is valid. It is scientifically grounded in optimization theory, specifically proximal gradient methods, and is directly relevant to learning rate scheduling in deep learning. The problem is well-posed, with all necessary parameters, definitions, and constraints provided to derive a unique solution. The language is objective and precise.\n\n### Step 1: Derivation of the Update Rule and Effective Step\n\nThe problem begins with the implicit-proximal update rule for the weight vector $\\mathbf{w}$ at iteration $t$:\n$$\n\\mathbf{w}_{t+1} \\in \\arg\\min_{\\mathbf{w}} \\left\\{ F(\\mathbf{w}) = \\frac{1}{2}\\left\\lVert \\mathbf{w} - \\left(\\mathbf{w}_t - \\eta_t \\nabla L(\\mathbf{w}_t)\\right)\\right\\rVert_2^2 + \\frac{\\eta_t \\lambda}{2} \\lVert \\mathbf{w} \\rVert_2^2 \\right\\}\n$$\nwhere $L(\\mathbf{w})$ is the data-fitting loss, $\\eta_t$ is the learning rate, and $\\lambda$ is the weight decay coefficient. The objective function $F(\\mathbf{w})$ is a strictly convex quadratic function of $\\mathbf{w}$, so its minimum can be found by setting its gradient with respect to $\\mathbf{w}$ to zero.\n\nLet $\\mathbf{c}_t = \\mathbf{w}_t - \\eta_t \\nabla L(\\mathbf{w}_t)$. The objective is:\n$$\nF(\\mathbf{w}) = \\frac{1}{2} (\\mathbf{w} - \\mathbf{c}_t)^T (\\mathbf{w} - \\mathbf{c}_t) + \\frac{\\eta_t \\lambda}{2} \\mathbf{w}^T \\mathbf{w}\n$$\nThe gradient $\\nabla_{\\mathbf{w}} F(\\mathbf{w})$ is:\n$$\n\\nabla_{\\mathbf{w}} F(\\mathbf{w}) = (\\mathbf{w} - \\mathbf{c}_t) + \\eta_t \\lambda \\mathbf{w}\n$$\nSetting the gradient to zero at $\\mathbf{w} = \\mathbf{w}_{t+1}$:\n$$\n(\\mathbf{w}_{t+1} - \\mathbf{c}_t) + \\eta_t \\lambda \\mathbf{w}_{t+1} = \\mathbf{0}\n$$\n$$\n\\mathbf{w}_{t+1}(1 + \\eta_t \\lambda) = \\mathbf{c}_t\n$$\n$$\n\\mathbf{w}_{t+1} = \\frac{1}{1 + \\eta_t \\lambda} \\mathbf{c}_t\n$$\nSubstituting back the definition of $\\mathbf{c}_t$:\n$$\n\\mathbf{w}_{t+1} = \\frac{1}{1 + \\eta_t \\lambda} \\left(\\mathbf{w}_t - \\eta_t \\nabla L(\\mathbf{w}_t)\\right)\n$$\n$$\n\\mathbf{w}_{t+1} = \\frac{1}{1 + \\eta_t \\lambda} \\mathbf{w}_t - \\frac{\\eta_t}{1 + \\eta_t \\lambda} \\nabla L(\\mathbf{w}_t)\n$$\nThis equation represents the standard Stochastic Gradient Descent (SGD) update with weight decay, where the weight decay term $\\frac{1}{1 + \\eta_t \\lambda}$ and the learning rate are coupled.\n\nThe problem defines the \"effective step\" $s_t$ as the scalar multiplying the negative gradient direction $-\\nabla L(\\mathbf{w}_t)$. From the derived update rule, we can identify $s_t$:\n$$\ns_t = \\frac{\\eta_t}{1 + \\eta_t \\lambda}\n$$\nTo control the schedule, we need to express the learning rate $\\eta_t$ as a function of the desired effective step $s_t$. We invert the aforementioned relationship:\n$$\ns_t (1 + \\eta_t \\lambda) = \\eta_t\n$$\n$$\ns_t + s_t \\eta_t \\lambda = \\eta_t\n$$\n$$\ns_t = \\eta_t (1 - s_t \\lambda)\n$$\n$$\n\\eta_t = \\frac{s_t}{1 - s_t \\lambda}\n$$\nFor $\\eta_t$ to be positive and well-defined, we must have $s_t  0$ and $1 - s_t \\lambda  0$, which implies $s_t \\lambda  1$.\n\n### Step 2: Design of the Effective Step Schedule $s(t)$\n\nThe effective step schedule $s(t)$ is piecewise.\n1.  **Warm-up Phase:** For iterations $t \\in \\{0, 1, \\dots, T_{\\mathrm{warn}}-1\\}$, the effective step is constant.\n    $$\n    s(t) = s_{\\mathrm{target}} \\quad \\text{for } t  T_{\\mathrm{warm}}\n    $$\n2.  **Decay Phase:** For iterations $t \\in \\{T_{\\mathrm{warm}}, T_{\\mathrm{warm}}+1, \\dots, T_{\\mathrm{total}}-1\\}$, the effective step undergoes a \"monotone exponential decay\". This is modeled as a geometric progression connecting $s(T_{\\mathrm{warm}}) = s_{\\mathrm{target}}$ to $s(T_{\\mathrm{total}}-1) = s_{\\min}$.\n\nLet the decay phase be defined on the interval $[T_{\\mathrm{warm}}, T_{\\mathrm{total}}-1]$. We require a function $s(t)$ such that $s(T_{\\mathrm{warm}}) = s_{\\mathrm{target}}$ and $s(T_{\\mathrm{total}}-1) = s_{\\min}$. An exponential function (geometric progression) that satisfies these boundary conditions is:\n$$\ns(t) = s_{\\mathrm{target}} \\cdot \\left(\\frac{s_{\\min}}{s_{\\mathrm{target}}}\\right)^{\\frac{t - T_{\\mathrm{warm}}}{(T_{\\mathrm{total}}-1) - T_{\\mathrm{warm}}}}\n$$\nThis is valid when the denominator $D = (T_{\\mathrm{total}}-1) - T_{\\mathrm{warm}} = T_{\\mathrm{total}} - T_{\\mathrm{warm}} - 1$ is positive.\n\nWe must handle edge cases:\n-   If $T_{\\mathrm{total}} - T_{\\mathrm{warm}} - 1  0$: The above formula applies.\n-   If $T_{\\mathrm{total}} - T_{\\mathrm{warm}} - 1 = 0$, i.e., $T_{\\mathrm{total}} = T_{\\mathrm{warm}} + 1$: The decay phase consists of a single point, $t=T_{\\mathrm{warm}}$. Since $t=T_{\\mathrm{warm}}$ is also the final iteration $T_{\\mathrm{total}}-1$, the value must be $s_{\\min}$. This creates a discontinuity at $t=T_{\\mathrm{warm}}$. So, $s(T_{\\mathrm{warm}}) = s_{\\min}$.\n-   If $T_{\\mathrm{total}} - T_{\\mathrm{warm}} - 1  0$, i.e., $T_{\\mathrm{total}} \\le T_{\\mathrm{warm}}$: The decay phase is empty. All iterations $t \\in \\{0, \\dots, T_{\\mathrm{total}}-1\\}$ fall into the warm-up phase, as $t  T_{\\mathrm{total}} \\le T_{\\mathrm{warm}}$. Thus, $s(t) = s_{\\mathrm{target}}$ for all relevant $t$.\n\n### Step 3: The Complete Learning Rate Schedule $\\eta_t$\n\nThe final learning rate schedule $\\eta_t$ is constructed by combining the above elements and applying the upper-bound constraint. For any given iteration $t \\in \\{0, 1, \\dots, T_{\\mathrm{total}}-1\\}$:\n1.  Determine the effective step $s(t)$ using the piecewise schedule defined in Step 2.\n2.  Calculate the unconstrained learning rate, $\\eta_t^{\\text{unconstrained}} = \\frac{s(t)}{1 - s(t) \\lambda}$.\n3.  Determine the maximum allowed learning rate, $\\eta_{\\max} = \\frac{2}{L_g}$.\n4.  The final learning rate is the unconstrained value clipped at $\\eta_{\\max}$:\n    $$\n    \\eta_t = \\min(\\eta_t^{\\text{unconstrained}}, \\eta_{\\max})\n    $$\n\n### Step 4: Implementation\n\nThe following self-contained program implements the derived learning rate schedule and computes the required values for the provided test cases. The logic is encapsulated in a function that computes $\\eta_t$ for a given $t$ and set of parameters, which is then called for each specified evaluation time in the test suite. The final output is formatted as a list of lists.", "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to solve the problem for the given test cases.\n    It computes the learning rate at specified iterations for each case\n    and prints the results in the required format.\n    \"\"\"\n    test_cases = [\n        # (T_total, T_warm, s_target, s_min, lambda, L_g, eval_times)\n        (100, 40, 0.01, 0.002, 0.1, 50, [0, 20, 40, 60, 99]),\n        (60, 20, 0.02, 0.005, 0, 100, [0, 19, 20, 59]),\n        (80, 30, 0.01, 0.003, 80, 50, [0, 29, 30, 79]),\n        (50, 0, 0.05, 0.01, 0.5, 200, [0, 25, 49]),\n    ]\n\n    all_results = []\n    \n    for case in test_cases:\n        T_total, T_warm, s_target, s_min, lambd, L_g, eval_times = case\n        \n        eta_max = 2.0 / L_g\n        \n        # Pre-calculate constants for the decay phase\n        decay_duration_denominator = float(T_total - 1 - T_warm)\n        if decay_duration_denominator  0:\n            ratio = s_min / s_target\n\n        case_results = []\n        for t in eval_times:\n            # 1. Determine the effective step s(t)\n            s_t = 0.0\n            if t  T_warm:\n                s_t = s_target\n            else: # t = T_warm\n                if decay_duration_denominator = 0:\n                    # This case corresponds to T_total = T_warm + 1.\n                    # As per the derived logic, if the decay phase has one point,\n                    # its value must be s_min. This occurs at t = T_total - 1.\n                    # For t  T_warm but t  T_total - 1 in this scenario (which is impossible),\n                    # we would continue s_target, but since the only valid t is T_total - 1,\n                    # the value is simply s_min.\n                    s_t = s_min\n                else:\n                    # Standard exponential decay\n                    exponent = (t - T_warm) / decay_duration_denominator\n                    s_t = s_target * (ratio ** exponent)\n\n            # 2. Calculate the unconstrained learning rate\n            # Denominator is 1 - s_t * lambda. This should be  0.\n            # It is guaranteed by problem constraints and schedule design (s(t) = s_target).\n            eta_unconstrained = s_t / (1.0 - s_t * lambd)\n\n            # 3. Apply the upper-bound constraint\n            eta_t = min(eta_unconstrained, eta_max)\n            case_results.append(eta_t)\n            \n        all_results.append(case_results)\n\n    # Final print statement in the exact required format.\n    # We manually format the lists to avoid spaces.\n    inner_lists_str = []\n    for res_list in all_results:\n        # Use a high-precision format for floating point numbers\n        inner_lists_str.append(f\"[{','.join(f'{val:.17g}' for val in res_list)}]\")\n    \n    print(f\"[{','.join(inner_lists_str)}]\")\n\nsolve()\n```", "id": "3142924"}, {"introduction": "Modern neural networks frequently employ non-smooth activation functions like ReLU, resulting in piecewise-smooth loss landscapes with sharp \"kinks.\" This exercise provides a hands-on opportunity to investigate how different learning rate schedules perform when navigating these non-differentiable regions. You will implement Stochastic Gradient Descent on a synthetic, non-smooth objective function and analyze how the learning rate $\\eta_t$ influences the behavior of stochastic subgradients near these critical points [@problem_id:3142877].", "problem": "You are asked to design and analyze Stochastic Gradient Descent (SGD) dynamics under different learning-rate schedules on a synthetic empirical risk that is piecewise-smooth with nonsmooth kinks. Your implementation must be a complete, runnable program. The goal is to quantify how different learning-rate sequences $\\{\\eta_t\\}_{t=0}^{T-1}$ behave when the iterates enter a nonsmooth region and to estimate a data-driven measure of subgradient noise amplification per unit learning rate.\n\nFundamental base and setup:\n- Empirical risk with piecewise-smooth absolute-value terms: for a scalar parameter $w \\in \\mathbb{R}$, define\n$$\nL(w) = \\frac{1}{n} \\sum_{i=1}^{n} \\left| a_i w - b_i \\right| + \\frac{\\lambda}{2} w^2,\n$$\nwhere $n$ is the number of data points, $(a_i,b_i)$ are fixed scalars, and $\\lambda  0$ is an $\\ell_2$ regularization weight. The absolute-value terms induce nonsmooth kinks whenever $a_i w - b_i = 0$.\n- Stochastic Gradient Descent (SGD) update rule with subgradients: initialize $w_0 \\in \\mathbb{R}$, and for each step $t \\in \\{0,1,\\dots,T-1\\}$, sample an index $I_t$ uniformly from $\\{1,\\dots,n\\}$ and update\n$$\nw_{t+1} = w_t - \\eta_t \\, g_t,\n$$\nwhere the stochastic subgradient is\n$$\ng_t = a_{I_t} \\cdot \\operatorname{sign}(a_{I_t} w_t - b_{I_t}) + \\lambda w_t,\n$$\nwith the convention $\\operatorname{sign}(0)=0$. The learning rate at step $t$ is $\\eta_t  0$.\n- Nonsmooth-region detection: define the residual vector $r(w) \\in \\mathbb{R}^n$ with components $r_i(w) = a_i w - b_i$. For a tolerance $\\varepsilon  0$, we say the iterate $w_t$ is in a nonsmooth region if $\\min_{1 \\le i \\le n} |r_i(w_t)| \\le \\varepsilon$.\n\nSynthetic dataset and fixed constants:\n- Use $n = 8$ data points with\n$$\na = [0.5,\\, 1.0,\\, 1.5,\\, 0.8,\\, 1.2,\\, 0.3,\\, 2.0,\\, 0.7], \\quad\nb = [0.6,\\, 1.2,\\, 1.8,\\, 0.9,\\, 1.5,\\, 0.2,\\, 2.3,\\, 0.85].\n$$\n- Use $\\lambda = 0.01$.\n- Use total steps $T = 4000$.\n- Use nonsmooth tolerance $\\varepsilon = 0.01$.\n- Initialize $w_0 = 0$.\n- Use a fixed pseudo-random number generator seed equal to $20231105$ for index sampling. At each step, sample a single index uniformly from $\\{1,\\dots,n\\}$.\n\nSchedules to test (test suite):\nFor each schedule, run the SGD process described above from $t=0$ to $t=T-1$, applying the schedule’s $\\eta_t$ at each step.\n\n- Schedule A (constant small): $\\eta_t = 0.05$ for all $t$.\n- Schedule B (step decay): \n  - $\\eta_t = 0.08$ for $0 \\le t  1200$,\n  - $\\eta_t = 0.02$ for $1200 \\le t  2500$,\n  - $\\eta_t = 0.005$ for $2500 \\le t  4000$.\n- Schedule C (cosine annealing without restarts): with $\\eta_{\\max} = 0.08$, $\\eta_{\\min} = 0.002$, and $T = 4000$, define\n$$\n\\eta_t = \\eta_{\\min} + \\frac{1}{2}\\left(\\eta_{\\max}-\\eta_{\\min}\\right)\\left(1 + \\cos\\left(\\pi \\frac{t}{T-1}\\right)\\right),\n$$\nfor $t \\in \\{0,\\dots,T-1\\}$.\n- Schedule D (inverse-time decay): with $\\eta_0 = 0.12$ and $\\gamma = 0.0015$,\n$$\n\\eta_t = \\frac{\\eta_0}{1 + \\gamma t}.\n$$\n- Schedule E (constant large): $\\eta_t = 0.2$ for all $t$.\n\nNoise amplification metric:\n- Let $\\Delta w_t = w_{t+1} - w_t$. Within the set of steps $K = \\{ t \\in \\{0,\\dots,T-1\\} : \\min_i |a_i w_t - b_i| \\le \\varepsilon \\}$, estimate a learning-rate-normalized amplification slope by least squares with zero intercept:\n$$\n\\hat{s} = \\underset{s \\in \\mathbb{R}}{\\arg\\min} \\sum_{t \\in K} \\left( |\\Delta w_t| - s \\, \\eta_t \\right)^2.\n$$\nShow that the minimizer is\n$$\n\\hat{s} = \\frac{\\sum_{t \\in K} \\eta_t \\, |\\Delta w_t|}{\\sum_{t \\in K} \\eta_t^2},\n$$\nand compute this value for each schedule. If $K$ is empty, define $\\hat{s} = 0$.\n\nRequired outputs per schedule:\n- After running $T$ steps, compute:\n  1. The final empirical risk $L(w_T)$.\n  2. The amplification slope $\\hat{s}$ as defined above.\n  3. The integer count $|K|$ of steps that were within the nonsmooth region.\n\nFinal output format:\n- Your program must produce a single line of output containing the concatenation of the results for Schedules A through E, each schedule contributing the triple $[L(w_T), \\hat{s}, |K|]$, flattened into one list in order A, B, C, D, E.\n- Represent floats rounded to six decimal places and integers without decimal points.\n- The final output must be a single line, a comma-separated list enclosed in square brackets. For example, an output with two schedules would look like $[0.123456,0.654321,42,0.234567,0.345678,7]$.\n\nAngle units and physical units:\n- No physical units or angles are involved in this problem.\n\nYour implementation must be a complete, runnable program as specified in the final answer section. No external input is required. All randomness must follow the specified seed. The output must reflect exactly the definitions provided here, including the rounding rule for floating-point values.", "solution": "The user has provided a well-defined computational problem in the domain of numerical optimization for machine learning. The task is to simulate Stochastic Gradient Descent (SGD) on a piecewise-smooth loss function and analyze the behavior of the iterates under five different learning rate schedules. The analysis focuses on quantifying the effect of the learning rate when iterates are near nonsmooth \"kinks\" in the objective function.\n\nThe problem is valid as it is scientifically grounded in the theory of nonsmooth optimization, is well-posed with all necessary parameters and conditions specified, and is objective and formalizable. We will proceed with a full solution.\n\nThe solution involves three main parts:\n1.  A mathematical derivation of the noise amplification metric, $\\hat{s}$.\n2.  A description of the algorithmic procedure to simulate the SGD process for each learning rate schedule.\n3.  The computation of the required output metrics: final loss $L(w_T)$, amplification slope $\\hat{s}$, and the count of steps in the nonsmooth region, $|K|$.\n\n### Derivation of the Amplification Slope $\\hat{s}$\n\nThe problem defines an amplification slope $\\hat{s}$ as the solution to a least-squares problem with zero intercept. The goal is to find the value of $s \\in \\mathbb{R}$ that minimizes the sum of squared errors between the magnitude of the weight update, $|\\Delta w_t|$, and a linear model of the learning rate, $s \\eta_t$, for all steps $t$ in the nonsmooth region set $K$. The objective function to minimize is:\n$$\nJ(s) = \\sum_{t \\in K} \\left( |\\Delta w_t| - s \\eta_t \\right)^2\n$$\nTo find the minimizer $\\hat{s}$, we compute the derivative of $J(s)$ with respect to $s$ and set it to zero.\n$$\n\\frac{dJ}{ds} = \\frac{d}{ds} \\sum_{t \\in K} \\left( |\\Delta w_t|^2 - 2s\\eta_t|\\Delta w_t| + s^2\\eta_t^2 \\right)\n$$\nSince the summation and differentiation operators are linear, we can swap their order. The terms $|\\Delta w_t|$ and $\\eta_t$ are constant with respect to $s$.\n$$\n\\frac{dJ}{ds} = \\sum_{t \\in K} \\frac{d}{ds} \\left( |\\Delta w_t|^2 - 2s\\eta_t|\\Delta w_t| + s^2\\eta_t^2 \\right) = \\sum_{t \\in K} \\left( -2\\eta_t|\\Delta w_t| + 2s\\eta_t^2 \\right)\n$$\nSetting the derivative to zero yields the optimal value $\\hat{s}$:\n$$\n\\sum_{t \\in K} \\left( -2\\eta_t|\\Delta w_t| + 2\\hat{s}\\eta_t^2 \\right) = 0\n$$\n$$\n2\\hat{s} \\sum_{t \\in K} \\eta_t^2 = 2 \\sum_{t \\in K} \\eta_t|\\Delta w_t|\n$$\nAssuming the set $K$ is not empty (otherwise, the sums are zero and $\\hat{s}$ is defined as $0$), we know $\\sum_{t \\in K} \\eta_t^2  0$ since $\\eta_t  0$. We can therefore solve for $\\hat{s}$:\n$$\n\\hat{s} = \\frac{\\sum_{t \\in K} \\eta_t |\\Delta w_t|}{\\sum_{t \\in K} \\eta_t^2}\n$$\nThis confirms the formula given in the problem statement. The second derivative, $\\frac{d^2J}{ds^2} = \\sum_{t \\in K} 2\\eta_t^2$, is positive, confirming that $\\hat{s}$ is indeed a minimizer.\n\n### Algorithmic Procedure\n\nFor each of the five learning rate schedules (A, B, C, D, E), we perform the following simulation:\n\n1.  **Initialization**:\n    *   Set the model parameter $w = w_0 = 0$.\n    *   Initialize a pseudo-random number generator with the fixed seed $20231105$. This is crucial for ensuring that the sequence of randomly sampled indices $\\{I_t\\}_{t=0}^{T-1}$ is identical for each of the five schedule simulations, allowing for a fair comparison.\n    *   Initialize an empty list, `k_data`, to store pairs of $(\\eta_t, |\\Delta w_t|)$ for steps $t$ that fall into the nonsmooth region.\n\n2.  **SGD Iteration**: The simulation runs for $T=4000$ steps, from $t=0$ to $t=3999$. In each step $t$:\n    *   **Learning Rate**: Calculate the learning rate $\\eta_t$ based on the formula for the current schedule.\n    *   **Nonsmooth Region Check**: Compute the residual vector $r(w_t)$ with components $r_i(w_t) = a_i w_t - b_i$. The iterate $w_t$ is in the nonsmooth region if $\\min_{1 \\le i \\le n} |r_i(w_t)| \\le \\varepsilon = 0.01$.\n    *   **Stochastic Subgradient**: Sample an index $I_t$ uniformly from $\\{1, \\dots, 8\\}$. The stochastic subgradient $g_t$ is then computed as:\n        $$\n        g_t = a_{I_t} \\cdot \\operatorname{sign}(a_{I_t} w_t - b_{I_t}) + \\lambda w_t\n        $$\n        where $\\lambda=0.01$ and we use the convention $\\operatorname{sign}(0)=0$.\n    *   **Parameter Update**: The weight is updated according to the SGD rule: $w_{t+1} = w_t - \\eta_t g_t$. We define the change as $\\Delta w_t = w_{t+1} - w_t = -\\eta_t g_t$.\n    *   **Data Collection**: If the nonsmooth region condition was met for $w_t$, the pair $(\\eta_t, |\\Delta w_t|)$ is appended to the `k_data` list.\n\n3.  **Post-Simulation Analysis**: After all $T$ steps are completed, we have the final weight $w_T$. We then compute the required metrics:\n    *   **Final Empirical Risk $L(w_T)$**: Calculated using the formula:\n        $$\n        L(w_T) = \\frac{1}{n} \\sum_{i=1}^{n} |a_i w_T - b_i| + \\frac{\\lambda}{2} w_T^2\n        $$\n    *   **Amplification Slope $\\hat{s}$**: Using the collected `k_data` list. If the list is empty (i.e., the set $K$ is empty), $\\hat{s}=0$. Otherwise, $\\hat{s}$ is computed using the derived formula.\n    *   **Nonsmooth Region Count $|K|$**: This is simply the number of entries in the `k_data` list.\n\nThis entire process is repeated for each of the five schedules. The resulting triples $[L(w_T), \\hat{s}, |K|]$ are collected and formatted into a single flat list for the final output. The floating-point values are rounded to six decimal places, and integers are presented as is.", "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to run the SGD simulations and produce the final output.\n    \"\"\"\n    \n    # --- Synthetic dataset and fixed constants ---\n    A = np.array([0.5, 1.0, 1.5, 0.8, 1.2, 0.3, 2.0, 0.7])\n    B = np.array([0.6, 1.2, 1.8, 0.9, 1.5, 0.2, 2.3, 0.85])\n    LAMBDA = 0.01\n    T = 4000\n    EPSILON = 0.01\n    W0 = 0.0\n    SEED = 20231105\n    N = len(A)\n\n    def get_lr(schedule_name, t, T_total):\n        \"\"\"Calculates the learning rate for a given step and schedule.\"\"\"\n        if schedule_name == 'A':\n            return 0.05\n        elif schedule_name == 'B':\n            if t  1200:\n                return 0.08\n            elif t  2500:\n                return 0.02\n            else:\n                return 0.005\n        elif schedule_name == 'C':\n            eta_max = 0.08\n            eta_min = 0.002\n            return eta_min + 0.5 * (eta_max - eta_min) * (1 + np.cos(np.pi * t / (T_total - 1)))\n        elif schedule_name == 'D':\n            eta0 = 0.12\n            gamma = 0.0015\n            return eta0 / (1 + gamma * t)\n        elif schedule_name == 'E':\n            return 0.2\n        else:\n            raise ValueError(f\"Unknown schedule: {schedule_name}\")\n\n    def run_sgd_simulation(schedule_name):\n        \"\"\"Runs one full SGD simulation for a given learning rate schedule.\"\"\"\n        \n        # Initialize RNG with fixed seed for reproducibility across schedules\n        rng = np.random.default_rng(SEED)\n\n        w = W0\n        k_data = []  # Stores (eta_t, delta_w_t) for t in K\n\n        for t in range(T):\n            # 1. Get learning rate\n            eta_t = get_lr(schedule_name, t, T)\n\n            # 2. Check for nonsmooth region\n            residuals = A * w - B\n            min_abs_residual = np.min(np.abs(residuals))\n            is_in_k = min_abs_residual = EPSILON\n\n            # 3. Sample index and compute stochastic subgradient\n            i_t = rng.integers(0, N)\n            residual_t = A[i_t] * w - B[i_t]\n            # np.sign(0.0) returns 0.0, matching the sign(0)=0 convention.\n            sign_term = np.sign(residual_t)\n            g_t = A[i_t] * sign_term + LAMBDA * w\n            \n            # 4. Compute weight update\n            delta_w_t = -eta_t * g_t\n            w_next = w + delta_w_t\n\n            # 5. Store data for hat_s if in nonsmooth region\n            if is_in_k:\n                k_data.append((eta_t, delta_w_t))\n\n            # 6. Update w for the next iteration\n            w = w_next\n        \n        w_T = w\n        \n        # --- Post-simulation analysis ---\n        \n        # 1. Final empirical risk L(w_T)\n        final_loss = np.mean(np.abs(A * w_T - B)) + (LAMBDA / 2.0) * w_T**2\n        \n        # 2. Amplification slope hat_s\n        if not k_data:\n            hat_s = 0.0\n        else:\n            k_etas = np.array([item[0] for item in k_data])\n            k_delta_ws_abs = np.abs(np.array([item[1] for item in k_data]))\n            \n            numerator = np.sum(k_etas * k_delta_ws_abs)\n            denominator = np.sum(k_etas**2)\n            \n            hat_s = numerator / denominator if denominator  0 else 0.0\n\n        # 3. Count |K|\n        k_count = len(k_data)\n        \n        return final_loss, hat_s, k_count\n\n    schedules_to_test = ['A', 'B', 'C', 'D', 'E']\n    all_results = []\n    \n    for schedule in schedules_to_test:\n        l_wT, s_hat, k_size = run_sgd_simulation(schedule)\n        all_results.append(f\"{l_wT:.6f}\")\n        all_results.append(f\"{s_hat:.6f}\")\n        all_results.append(str(k_size))\n        \n    # --- Final Output Formatting ---\n    print(f\"[{','.join(all_results)}]\")\n\n# Execute the main function\nsolve()\n```", "id": "3142877"}, {"introduction": "While predefined schedules are common, many state-of-the-art training pipelines employ adaptive strategies that react to the model's performance on a validation set. This practice guides you in building such a reactive scheduler from scratch, mimicking the popular \"reduce learning rate on plateau\" heuristic. By implementing a system based on moving averages and early-stopping detectors on a synthetic validation loss curve, you will gain insight into the design and potential pitfalls, like false positives, of data-driven scheduling policies [@problem_id:3142901].", "problem": "You are tasked with designing and testing a learning rate (LR) scheduling policy that is triggered by early stopping (ES) style detectors and validated by validation moving average (MA) crossovers, while quantifying the rate of false positives. The objective is to implement the detector logic from first principles and apply it to synthetic but scientifically plausible validation loss sequences. The schedule should reduce the learning rate during cooldown phases whenever the evidence suggests training stagnation or deterioration. Your program must output a compact summary for a small test suite of cases.\n\nBase principles to use and build on:\n- Gradient-based learning uses updates of the form $x_{t+1} = x_t - \\eta_t g_t$, where $x_t$ is the parameter vector at epoch $t$, $g_t$ is the gradient estimate, and $\\eta_t \\gt 0$ is the learning rate (LR) at epoch $t$. The schedule controls $\\eta_t$.\n- Early stopping (ES) monitors a validation criterion to detect the absence of improvement over a patience window. A detector is a logical predicate driven by observable validation statistics.\n- Moving averages (MAs) serve as noise-reduction statistics. The Simple Moving Average (SMA) of a validation sequence $(y_t)$ over window size $w$ at time $t$ is the mean of the last $w$ available values (use a shorter window if fewer than $w$ values exist), that is\n$$\n\\operatorname{SMA}_w(t) = \\frac{1}{m}\\sum_{i=t-m+1}^{t} y_i,\\quad m=\\min(w, t+1).\n$$\n\nSchedule definitions to implement:\n- Let the initial learning rate be $\\eta_0 \\gt 0$. Each time the scheduler triggers, multiply the current LR by a decay factor $\\gamma$ with $0 \\lt \\gamma \\lt 1$, and enter a cooldown phase lasting $c$ epochs. During cooldown, no new triggers are allowed. The LR persists at its most recently decayed value after cooldowns.\n- Maintain two Simple Moving Averages: a short-term SMA with window $w_s$ and a long-term SMA with window $w_\\ell$, with $w_s \\lt w_\\ell$. Denote them by $S_t = \\operatorname{SMA}_{w_s}(t)$ and $L_t = \\operatorname{SMA}_{w_\\ell}(t)$.\n- Maintain the best smoothed value observed so far, $B_t = \\min_{0 \\le i \\le t} S_i$. An improvement at time $t$ occurs if $S_t \\lt B_{t-1} - \\varepsilon$, where $\\varepsilon \\ge 0$ is a tolerance. When an improvement occurs, update $B_t = S_t$ and record the epoch $t$ as the most recent improve time.\n- Define the Early Stopping (ES) condition at time $t$ to hold if no improvements have occurred in the last $p$ epochs, i.e., $t - \\text{last\\_improve} \\ge p$.\n- Define the crossover confirmation condition at time $t$ to hold if $(S_i - L_i) \\ge \\delta$ has been true for at least the most recent $k$ consecutive epochs (including $t$), for some $\\delta \\ge 0$ and integer $k \\ge 1$.\n- Trigger rule: when not in cooldown, if both the ES condition and the crossover confirmation condition hold at time $t$, then trigger a cooldown starting at epoch $t$, set $\\eta \\leftarrow \\gamma \\eta$, and block further triggers until the cooldown elapses.\n\nFalse positive definition:\n- A trigger at epoch $t_0$ is a false positive if within the next $q$ epochs $(t_0+1,\\dots,\\min(T-1, t_0+q))$ there exists a new best raw validation loss strictly below the best raw validation loss observed up to $t_0$ by at least $\\varepsilon$. Formally, let $y_t$ be the raw validation loss, $b_{\\text{raw}}(t_0) = \\min_{0 \\le i \\le t_0} y_i$. The trigger is a false positive if\n$$\n\\min_{t_0+1 \\le j \\le \\min(T-1, t_0+q)} y_j \\le b_{\\text{raw}}(t_0) - \\varepsilon.\n$$\n\nValidation loss generator:\n- For a sequence length $T$, define for epochs $t \\in \\{0,1,\\dots,T-1\\}$ the raw validation loss\n$$\ny_t = a + b \\exp\\!\\left(-\\frac{t}{\\tau}\\right) + u \\cdot \\frac{\\max(0,\\, t - t_u)}{T} + \\epsilon_t,\n$$\nwhere $\\epsilon_t \\sim \\mathcal{N}(0, \\sigma^2)$. Use a Pseudo-Random Number Generator (PRNG) with a specified integer seed for reproducibility. The term with $u$ introduces a gentle upward drift after $t_u$ to simulate overfitting.\n\nTask:\n- Implement the schedule and detector as specified, driven by the synthetic validation loss. Use epoch indexing starting at $t=0$. Use Simple Moving Averages computed over available samples near the beginning as described above. When a trigger occurs at epoch $t$, include that epoch as the first epoch of the cooldown of length $c$.\n- For each test case below, compute:\n    1. The total number of cooldown triggers (an integer).\n    2. The number of false positives (an integer).\n    3. The final learning rate (a float), starting from $\\eta_0$ and multiplying by $\\gamma$ for each trigger.\n\nTest suite:\n- Use initial learning rate $\\eta_0 = 0.1$ for all cases.\n\n- Case A (happy path with mild overfitting tail):\n    - Sequence parameters: $T = 60$, $a = 0.2$, $b = 0.9$, $\\tau = 16$, $\\sigma = 0.008$, $u = 0.12$, $t_u = 45$, seed $= 0$.\n    - Schedule parameters: $\\gamma = 0.5$, $c = 5$, $p = 5$, $w_s = 3$, $w_\\ell = 9$, $k = 2$, $\\delta = 0.002$, $\\varepsilon = 0.0005$, $q = 4$.\n\n- Case B (continued improvement, no drift):\n    - Sequence parameters: $T = 40$, $a = 0.1$, $b = 0.8$, $\\tau = 30$, $\\sigma = 0.005$, $u = 0.0$, $t_u = 100$, seed $= 1$.\n    - Schedule parameters: $\\gamma = 0.5$, $c = 6$, $p = 7$, $w_s = 2$, $w_\\ell = 8$, $k = 3$, $\\delta = 0.001$, $\\varepsilon = 0.0005$, $q = 5$.\n\n- Case C (noisy flat region to probe false positives):\n    - Sequence parameters: $T = 50$, $a = 0.5$, $b = 0.0$, $\\tau = 1$, $\\sigma = 0.02$, $u = 0.0$, $t_u = 0$, seed $= 2$.\n    - Schedule parameters: $\\gamma = 0.5$, $c = 4$, $p = 3$, $w_s = 1$, $w_\\ell = 6$, $k = 1$, $\\delta = 0.0$, $\\varepsilon = 0.0025$, $q = 5$.\n\nFinal output format:\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets. Aggregate the results for all cases into a single list of lists, one inner list per case in the order A, B, C. Each inner list must be of the form $[\\text{num\\_cooldowns},\\text{num\\_false\\_positives},\\text{final\\_lr}]$. The final string must contain no spaces. For example, a valid output form is\n\"[[1,0,0.05],[0,0,0.1],[3,2,0.0125]]\".", "solution": "The user requires the design and implementation of a learning rate (LR) scheduling policy based on early stopping (ES) principles and moving average (MA) crossovers. The task involves simulating the scheduler's behavior on synthetic validation loss data and quantifying its performance, specifically the number of LR reductions and the rate of false positives.\n\nThe solution is developed by first principles as a discrete-time simulation over a series of epochs $t \\in \\{0, 1, \\dots, T-1\\}$.\n\n**1. Synthetic Validation Loss Generation**\n\nFor each test case, a sequence of raw validation losses, denoted by $y_t$, is generated for a total of $T$ epochs. The function used to generate this data is:\n$$\ny_t = a + b \\exp\\left(-\\frac{t}{\\tau}\\right) + u \\cdot \\frac{\\max(0, t - t_u)}{T} + \\epsilon_t\n$$\nThis model is scientifically plausible for representing validation loss curves during model training:\n- The constant term $a$ represents the irreducible error or the asymptotic loss value.\n- The term $b \\exp(-t/\\tau)$ models the initial phase of learning, where the loss decreases exponentially with a time constant $\\tau$.\n- The term $u \\cdot \\frac{\\max(0, t - t_u)}{T}$ simulates the onset of overfitting after epoch $t_u$, introducing a linear upward drift in the loss, scaled by a factor $u$.\n- The term $\\epsilon_t$ is a random noise component, sampled from a normal distribution $\\mathcal{N}(0, \\sigma^2)$, which represents the stochasticity inherent in mini-batch gradient descent and validation.\n\nReproducibility is ensured by using a specific integer seed for the pseudo-random number generator (PRNG) for each case. The entire sequence of $\\{y_t\\}_{t=0}^{T-1}$ is generated upfront before the main scheduler simulation begins.\n\n**2. Scheduler Design and State Evolution**\n\nThe scheduler's logic is executed at each epoch $t$. Its behavior is determined by a set of internal state variables and predefined rules.\n\n- **State Variables**:\n    - $\\eta_t$: The learning rate at epoch $t$, initialized to $\\eta_0$.\n    - Cooldown period: A state indicating whether the scheduler is temporarily inactive. We track `cooldown_until`, the first epoch after the cooldown period where the scheduler becomes active again.\n    - $B_t$: The best (lowest) smoothed validation loss observed so far. It is initialized to $B_{-1} = \\infty$.\n    - `last_improve_epoch`: The epoch $t$ at which the last significant improvement in smoothed loss occurred.\n    - Crossover streak counter: Tracks the number of consecutive epochs the crossover condition has been met.\n\n- **Moving Averages (SMAs)**: At each epoch $t$, two Simple Moving Averages of the raw loss $y_t$ are computed to smooth out noise:\n    - Short-term SMA: $S_t = \\operatorname{SMA}_{w_s}(t) = \\frac{1}{\\min(w_s, t+1)}\\sum_{i=t-\\min(w_s, t+1)+1}^{t} y_i$\n    - Long-term SMA: $L_t = \\operatorname{SMA}_{w_\\ell}(t) = \\frac{1}{\\min(w_\\ell, t+1)}\\sum_{i=t-\\min(w_\\ell, t+1)+1}^{t} y_i$\n    where $w_s  w_\\ell$ are the respective window sizes. The short-term SMA $S_t$ is more responsive to recent changes, while the long-term SMA $L_t$ reflects the broader trend.\n\n- **Simulation Loop (Epoch $t = 0, \\dots, T-1$)**:\n    1. **Compute SMAs**: Calculate $S_t$ and $L_t$ from the historical raw loss data $\\{y_i\\}_{i=0}^{t}$.\n    2.  **Check for Improvement**: An improvement is registered if the current short-term SMA $S_t$ is significantly better than the best value seen so far, $B_{t-1}$. The condition is $S_t  B_{t-1} - \\varepsilon$, where $\\varepsilon \\ge 0$ is a minimum improvement threshold. If this condition is met, the state is updated: $B_t = S_t$ and `last_improve_epoch` is set to $t$. Otherwise, $B_t = B_{t-1}$. At $t=0$, an improvement is assumed, so $B_0=S_0$ and `last_improve_epoch` is set to $0$.\n    3.  **Check for Trigger**: A trigger for LR reduction can only occur if the scheduler is not in a cooldown period (i.e., $t \\ge \\text{cooldown\\_until}$). The trigger requires two conditions to be met simultaneously:\n        -   **Early Stopping (ES) Condition**: No significant improvement has been observed for a specified number of epochs. This is true if $t - \\text{last\\_improve\\_epoch} \\ge p$, where $p$ is the patience parameter.\n        -   **Crossover Confirmation Condition**: The short-term SMA has been consistently above the long-term SMA, indicating a potential reversal of the learning trend (i.e., loss starting to increase). This is true if the condition $(S_i - L_i) \\ge \\delta$ has held for the last $k$ consecutive epochs (from $t-k+1$ to $t$), where $\\delta \\ge 0$ is a tolerance and $k \\ge 1$ is the confirmation length.\n    4.  **Trigger Action**: If both conditions are met, a trigger event occurs at epoch $t$. The learning rate is reduced by a multiplicative factor $\\gamma$ (i.e., $\\eta \\leftarrow \\gamma \\cdot \\eta$), and a new cooldown period of $c$ epochs is initiated. This prevents further triggers until epoch $t+c$. The epoch of the trigger is recorded for later analysis.\n\n**3. False Positive Analysis**\n\nAfter the simulation over all $T$ epochs is complete, a post-hoc analysis is performed to identify false positives among the recorded triggers. A trigger at epoch $t_0$ is defined as a false positive if, despite the scheduler's decision to reduce the LR, the model would have achieved a new best raw validation loss within a short lookahead window of $q$ epochs.\n\nFormally, for each trigger epoch $t_0$, we compute:\n- The best raw loss up to the trigger: $b_{\\text{raw}}(t_0) = \\min_{0 \\le i \\le t_0} y_i$.\n- The minimum raw loss in the subsequent $q$ epochs: $\\min_{t_0+1 \\le j \\le \\min(T-1, t_0+q)} y_j$.\n\nThe trigger at $t_0$ is counted as a false positive if:\n$$\n\\min_{t_0+1 \\le j \\le \\min(T-1, t_0+q)} y_j \\le b_{\\text{raw}}(t_0) - \\varepsilon\n$$\nThis condition means that a new raw loss, strictly better by at least the tolerance $\\varepsilon$, was found shortly after the LR was reduced, suggesting the reduction may have been premature.\n\nThe final implementation encapsulates this entire logic into a function that is executed for each provided test case, and the results — total triggers, false positives, and final LR — are aggregated.", "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to define test cases and run the simulation.\n    \"\"\"\n\n    def run_case(T, a, b, tau, sigma, u, t_u, seed,\n                 eta_0, gamma, c, p, w_s, w_ell, k, delta, epsilon, q):\n        \"\"\"\n        Runs a single simulation case for the LR scheduler.\n\n        Returns:\n            A list containing [num_triggers, num_false_positives, final_lr].\n        \"\"\"\n        # 1. Generate the full raw validation loss sequence\n        rng = np.random.default_rng(seed)\n        epochs = np.arange(T)\n        noise = rng.normal(0, sigma, T)\n        drift = u * np.maximum(0, epochs - t_u) / T\n        y_raw = a + b * np.exp(-epochs / tau) + drift + noise\n\n        # 2. Initialize scheduler state variables\n        lr = eta_0\n        cooldown_until = 0\n        trigger_epochs = []\n        \n        best_smooth_loss = np.inf\n        last_improve_epoch = 0\n        consecutive_crossover_count = 0\n        \n        # 3. Main simulation loop over epochs\n        for t in range(T):\n            # Compute Short-term and Long-term Simple Moving Averages (SMAs)\n            m_s = min(w_s, t + 1)\n            S_t = np.mean(y_raw[t - m_s + 1 : t + 1])\n\n            m_ell = min(w_ell, t + 1)\n            L_t = np.mean(y_raw[t - m_ell + 1 : t + 1])\n\n            # Check for improvement in smoothed loss\n            if t == 0:\n                best_smooth_loss = S_t\n                last_improve_epoch = 0\n            else:\n                if S_t  best_smooth_loss - epsilon:\n                    best_smooth_loss = S_t\n                    last_improve_epoch = t\n\n            # Check for trigger conditions if not in cooldown\n            if t = cooldown_until:\n                # Early Stopping condition: patience exceeded\n                es_holds = (t - last_improve_epoch) = p\n\n                # Crossover confirmation condition\n                if (S_t - L_t) = delta:\n                    consecutive_crossover_count += 1\n                else:\n                    consecutive_crossover_count = 0\n                \n                crossover_holds = consecutive_crossover_count = k\n\n                # If both conditions hold, trigger LR reduction\n                if es_holds and crossover_holds:\n                    lr *= gamma\n                    cooldown_until = t + c\n                    trigger_epochs.append(t)\n        \n        num_triggers = len(trigger_epochs)\n\n        # 4. Post-hoc analysis for false positives\n        num_false_positives = 0\n        for t0 in trigger_epochs:\n            best_raw_loss_at_trigger = np.min(y_raw[:t0 + 1])\n            \n            j_start = t0 + 1\n            j_end_inclusive = min(T - 1, t0 + q)\n            \n            # Check if lookahead window is valid\n            if j_start  j_end_inclusive:\n                continue\n                \n            future_losses = y_raw[j_start : j_end_inclusive + 1]\n            min_future_loss = np.min(future_losses)\n\n            if min_future_loss = best_raw_loss_at_trigger - epsilon:\n                num_false_positives += 1\n\n        return [num_triggers, num_false_positives, lr]\n\n    # Define the test suite as specified in the problem\n    test_cases = [\n        # Case A: Happy path with mild overfitting tail\n        dict(\n            T=60, a=0.2, b=0.9, tau=16, sigma=0.008, u=0.12, t_u=45, seed=0,\n            eta_0=0.1, gamma=0.5, c=5, p=5, w_s=3, w_ell=9, k=2, delta=0.002,\n            epsilon=0.0005, q=4\n        ),\n        # Case B: Continued improvement, no drift\n        dict(\n            T=40, a=0.1, b=0.8, tau=30, sigma=0.005, u=0.0, t_u=100, seed=1,\n            eta_0=0.1, gamma=0.5, c=6, p=7, w_s=2, w_ell=8, k=3, delta=0.001,\n            epsilon=0.0005, q=5\n        ),\n        # Case C: Noisy flat region to probe false positives\n        dict(\n            T=50, a=0.5, b=0.0, tau=1, sigma=0.02, u=0.0, t_u=0, seed=2,\n            eta_0=0.1, gamma=0.5, c=4, p=3, w_s=1, w_ell=6, k=1, delta=0.0,\n            epsilon=0.0025, q=5\n        ),\n    ]\n\n    # Run all test cases and collect results\n    results = [run_case(**case) for case in test_cases]\n\n    # Format the final output string as required\n    print(str(results).replace(' ', ''))\n\nsolve()\n```", "id": "3142901"}]}