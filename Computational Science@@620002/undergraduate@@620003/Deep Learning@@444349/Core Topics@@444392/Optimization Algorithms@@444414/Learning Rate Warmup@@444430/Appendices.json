{"hands_on_practices": [{"introduction": "To truly grasp why learning rate warmup is so effective, we must look under the hood at the optimizer's dynamics. This practice delves into the interaction between a linear warmup schedule and an optimizer with momentum, using a simplified one-dimensional model. By deriving the velocity term at the end of the warmup phase, you will mathematically demonstrate how gradually increasing the learning rate helps to tame the initial momentum and prevent the parameter updates from overshooting the optimal value, a common source of instability in early training [@problem_id:3143226].", "problem": "Consider one-dimensional training of a parameter $w_t$ on a strictly convex quadratic loss $L(w) = \\tfrac{\\lambda}{2} (w - w^{\\star})^{2}$ with curvature $\\lambda  0$. Let the error be $e_t = w_t - w^{\\star}$ and let the gradient be $g_t = \\nabla L(w_t) = \\lambda e_t$. The optimizer uses classical momentum with velocity update and parameter update\n$$\nv_{t+1} = \\beta v_t + \\eta(t)\\, g_t, \\qquad w_{t+1} = w_t - v_{t+1},\n$$\nwith momentum coefficient $0 \\le \\beta  1$, initial velocity $v_0 = 0$, and initial error $e_0 \\ne 0$. A linear learning-rate warmup is used for the first $T_w \\in \\mathbb{N}$ steps:\n$$\n\\eta(t) = \\eta_{\\max}\\,\\frac{t}{T_w} \\quad \\text{for } 0 \\le t \\le T_w,\n$$\nafter which the learning rate remains at $\\eta_{\\max}$. During the warmup phase, assume the empirically observed small-step regime in which the error changes negligibly over the first $T_w+1$ iterates, so that $e_t \\approx e_0$ for $0 \\le t \\le T_w$. This approximation is widely used to analyze the earliest-epoch dynamics under warmup when the learning rate is still small.\n\nStarting only from these definitions and this approximation:\n\n1) Derive an exact closed-form expression (under the stated approximation) for the end-of-warmup velocity $v_{T_w+1}$ in terms of $\\beta$, $\\lambda$, $e_0$, $\\eta_{\\max}$, and $T_w$.\n\n2) Let $v^{\\mathrm{const}}_{T_w+1}$ denote the end-of-warmup velocity one would obtain if the learning rate were held constant at $\\eta(t) \\equiv \\eta_{\\max}$ for all $0 \\le t \\le T_w$. Using the same approximation, derive a simplified closed-form expression for the ratio\n$$\nR(\\beta,T_w) \\equiv \\frac{v^{\\mathrm{warm}}_{T_w+1}}{v^{\\mathrm{const}}_{T_w+1}},\n$$\nexpressed solely as a function of $\\beta$ and $T_w$ (all other parameters must cancel).\n\nInterpretational note: the magnitude of $v_{T_w+1}$ relative to $|e_0|$ controls the risk of initial overshoot at the end of warmup, so the ratio $R(\\beta,T_w)$ quantifies how linear warmup damps the initial momentum build-up compared to a constant learning rate.\n\nYour final answer must be the simplified closed-form expression for $R(\\beta,T_w)$ as a single analytic expression. No numerical evaluation is required or permitted, and no rounding is needed. Assume $\\beta \\ne 1$ and $T_w \\ge 1$ are integers, but your expression may treat $T_w$ symbolically.", "solution": "The user has provided a valid, well-posed problem from the field of deep learning optimization theory. The task is to derive a simplified, closed-form expression for the ratio of end-of-warmup velocities, $R(\\beta, T_w)$, under two different learning rate schedules.\n\nThe problem is defined by the following components:\n- Loss function: $L(w) = \\frac{\\lambda}{2} (w - w^{\\star})^{2}$ with $\\lambda  0$.\n- Error and gradient: $e_t = w_t - w^{\\star}$ and $g_t = \\nabla L(w_t) = \\lambda e_t$.\n- Optimizer update rules: $v_{t+1} = \\beta v_t + \\eta(t) g_t$ and $w_{t+1} = w_t - v_{t+1}$.\n- Initial conditions: $v_0 = 0$ and $e_0 \\neq 0$.\n- Momentum parameter: $0 \\le \\beta  1$.\n- Central approximation: For the duration of the warmup phase, $0 \\le t \\le T_w$, the error is assumed to be constant, $e_t \\approx e_0$. This implies the gradient is also constant, $g_t \\approx g_0 = \\lambda e_0$.\n\nThe solution proceeds in three steps:\n1.  Derive the velocity $v^{\\mathrm{warm}}_{T_w+1}$ at the end of a linear warmup phase.\n2.  Derive the velocity $v^{\\mathrm{const}}_{T_w+1}$ that would result from a constant learning rate.\n3.  Compute and simplify the ratio $R(\\beta, T_w) = v^{\\mathrm{warm}}_{T_w+1} / v^{\\mathrm{const}}_{T_w+1}$.\n\n**Step 1: Derivation of the velocity with linear warmup ($v^{\\mathrm{warm}}_{T_w+1}$)**\n\nThe linear warmup schedule is given by $\\eta(t) = \\eta_{\\max} \\frac{t}{T_w}$ for $0 \\le t \\le T_w$.\nUnder the constant gradient approximation $g_t \\approx g_0$, the velocity update rule is a linear recurrence relation:\n$$\nv_{t+1} = \\beta v_t + \\eta(t) g_0 = \\beta v_t + \\left(\\frac{\\eta_{\\max} g_0}{T_w}\\right) t\n$$\nStarting with $v_0 = 0$, we can unroll this recurrence to find $v_{k+1}$:\n$$\nv_{k+1} = \\beta^{k+1} v_0 + \\sum_{j=0}^{k} \\beta^{k-j} \\eta(j) g_0 = g_0 \\sum_{j=0}^{k} \\beta^{k-j} \\eta(j)\n$$\nWe need the velocity at step $T_w+1$, which means we evaluate this expression for $k=T_w$, using the schedule for $j \\in \\{0, 1, \\dots, T_w\\}$:\n$$\nv^{\\mathrm{warm}}_{T_w+1} = g_0 \\sum_{j=0}^{T_w} \\beta^{T_w-j} \\left(\\eta_{\\max} \\frac{j}{T_w}\\right) = \\frac{g_0 \\eta_{\\max}}{T_w} \\sum_{j=0}^{T_w} j \\beta^{T_w-j}\n$$\nThe $j=0$ term is zero, so the sum is over $j=1, \\dots, T_w$. Let's analyze the sum $S = \\sum_{j=1}^{T_w} j \\beta^{T_w-j}$. We can re-index by letting $k = T_w - j$. As $j$ goes from $1$ to $T_w$, $k$ goes from $T_w-1$ to $0$.\n$$\nS = \\sum_{k=0}^{T_w-1} (T_w - k) \\beta^k = T_w \\sum_{k=0}^{T_w-1} \\beta^k - \\sum_{k=0}^{T_w-1} k \\beta^k\n$$\nThe first term is a standard geometric series: $\\sum_{k=0}^{T_w-1} \\beta^k = \\frac{1 - \\beta^{T_w}}{1 - \\beta}$.\nThe second term is an arithmetic-geometric series. We can evaluate it using calculus. For $|x|1$, we know $\\sum_{k=0}^{n} x^k = \\frac{1-x^{n+1}}{1-x}$. Differentiating with respect to $x$ gives $\\sum_{k=1}^{n} kx^{k-1} = \\frac{d}{dx}\\left(\\frac{1-x^{n+1}}{1-x}\\right)$. Thus, $\\sum_{k=0}^{n} kx^k = x \\frac{d}{dx}\\left(\\frac{1-x^{n+1}}{1-x}\\right)$.\nFor our sum, $n = T_w-1$ and $x=\\beta$:\n$$\n\\sum_{k=0}^{T_w-1} k \\beta^k = \\beta \\frac{d}{d\\beta} \\left(\\frac{1-\\beta^{T_w}}{1-\\beta}\\right) = \\beta \\frac{-T_w\\beta^{T_w-1}(1-\\beta) - (1-\\beta^{T_w})(-1)}{(1-\\beta)^2} = \\frac{\\beta(1 - T_w\\beta^{T_w-1} + (T_w-1)\\beta^{T_w})}{(1-\\beta)^2}\n$$\nCombining the terms for $S$:\n$$\nS = T_w \\frac{1-\\beta^{T_w}}{1-\\beta} - \\frac{\\beta - T_w\\beta^{T_w} + (T_w-1)\\beta^{T_w+1}}{(1-\\beta)^2}\n$$\nPutting everything over a common denominator $(1-\\beta)^2$:\n$$\nS = \\frac{T_w(1-\\beta^{T_w})(1-\\beta) - (\\beta - T_w\\beta^{T_w} + (T_w-1)\\beta^{T_w+1})}{(1-\\beta)^2}\n$$\nThe numerator simplifies to:\n$$\n(T_w - T_w\\beta - T_w\\beta^{T_w} + T_w\\beta^{T_w+1}) - (\\beta - T_w\\beta^{T_w} + T_w\\beta^{T_w+1} - \\beta^{T_w+1})\n= T_w - T_w\\beta - \\beta + \\beta^{T_w+1} = T_w - (T_w+1)\\beta + \\beta^{T_w+1}\n$$\nSo, $S = \\frac{T_w - (T_w+1)\\beta + \\beta^{T_w+1}}{(1-\\beta)^2}$.\nSubstituting this back into the expression for $v^{\\mathrm{warm}}_{T_w+1}$:\n$$\nv^{\\mathrm{warm}}_{T_w+1} = \\frac{g_0 \\eta_{\\max}}{T_w} \\left( \\frac{T_w - (T_w+1)\\beta + \\beta^{T_w+1}}{(1-\\beta)^2} \\right)\n$$\n\n**Step 2: Derivation of the velocity with constant learning rate ($v^{\\mathrm{const}}_{T_w+1}$)**\n\nIf the learning rate were held constant at $\\eta(t) = \\eta_{\\max}$ for $0 \\le t \\le T_w$, the velocity update would be:\n$$\nv_{t+1} = \\beta v_t + \\eta_{\\max} g_0\n$$\nUnrolling this recurrence from $v_0 = 0$:\n$$\nv_{k+1} = \\eta_{\\max} g_0 \\sum_{j=0}^{k} \\beta^j\n$$\nWe need the velocity at step $T_w+1$, so we set $k=T_w$:\n$$\nv^{\\mathrm{const}}_{T_w+1} = \\eta_{\\max} g_0 \\sum_{j=0}^{T_w} \\beta^j\n$$\nThe sum is a geometric series: $\\sum_{j=0}^{T_w} \\beta^j = \\frac{1 - \\beta^{T_w+1}}{1-\\beta}$.\nTherefore,\n$$\nv^{\\mathrm{const}}_{T_w+1} = \\eta_{\\max} g_0 \\left( \\frac{1 - \\beta^{T_w+1}}{1-\\beta} \\right)\n$$\n\n**Step 3: Calculation of the ratio $R(\\beta, T_w)$**\n\nThe ratio is defined as $R(\\beta, T_w) = \\frac{v^{\\mathrm{warm}}_{T_w+1}}{v^{\\mathrm{const}}_{T_w+1}}$. Substituting the expressions from Steps 1 and 2:\n$$\nR(\\beta, T_w) = \\frac{\\frac{g_0 \\eta_{\\max}}{T_w} \\frac{T_w - (T_w+1)\\beta + \\beta^{T_w+1}}{(1-\\beta)^2}}{\\eta_{\\max} g_0 \\frac{1 - \\beta^{T_w+1}}{1-\\beta}}\n$$\nThe terms $g_0$ and $\\eta_{\\max}$ cancel, as required. We are left with an expression depending only on $\\beta$ and $T_w$:\n$$\nR(\\beta, T_w) = \\frac{1}{T_w} \\cdot \\frac{T_w - (T_w+1)\\beta + \\beta^{T_w+1}}{(1-\\beta)^2} \\cdot \\frac{1-\\beta}{1 - \\beta^{T_w+1}}\n$$\nSimplifying by canceling one factor of $(1-\\beta)$:\n$$\nR(\\beta, T_w) = \\frac{T_w - (T_w+1)\\beta + \\beta^{T_w+1}}{T_w(1-\\beta)(1 - \\beta^{T_w+1})}\n$$\nThis is the final simplified, closed-form expression for the ratio.", "answer": "$$\n\\boxed{\\frac{T_w - (T_w+1)\\beta + \\beta^{T_w+1}}{T_w(1-\\beta)(1 - \\beta^{T_w+1})}}\n$$", "id": "3143226"}, {"introduction": "Theoretical understanding is powerful, but a practitioner must also learn to diagnose model behavior from empirical evidence like training loss curves. This hands-on coding exercise simulates the training process on a simple problem to make the effects of warmup tangible. You will implement clear, quantitative diagnostics to classify training runs as suffering from 'under-warmup' (initial loss spikes) or 'over-warmup' (delayed progress), developing crucial skills for debugging and tuning your own models [@problem_id:3115472].", "problem": "You will implement and use a simple, deterministic training-dynamics simulator to diagnose learning rate warmup using learning curves. The setting is one-dimensional gradient descent on a strictly convex quadratic, with a linearly increasing warmup learning rate followed by a constant learning rate. Your program must simulate the training loss over epochs, apply principled diagnostics on the early segment of the learning curve, and classify each case as under-warmup, over-warmup, or acceptable warmup.\n\nFundamental base:\n- Consider the loss function $L(x) = \\frac{1}{2} a x^{2}$ with curvature $a \\gt 0$. The gradient is $\\nabla L(x) = a x$. Gradient descent with learning rate $\\eta_{t}$ updates the parameter as $x_{t+1} = x_{t} - \\eta_{t} \\nabla L(x_{t})$.\n- A linear warmup learning rate schedule with warmup length $w$ and maximum learning rate $\\eta_{\\max}$ is given by\n  - $\\eta_{t} = \\eta_{\\max} \\cdot \\min\\!\\left(\\frac{t}{w}, 1\\right)$ for integer epochs $t \\in \\{1, 2, \\dots, T\\}$.\n- The observed training loss is modeled deterministically as $y_{t} = L(x_{t}) + \\sigma \\sin\\!\\left( \\frac{2 \\pi t}{P} \\right)$, with $\\sigma \\ge 0$ and period parameter $P \\ge 1$. For $t = 0$, define $y_{0} = L(x_{0})$.\n\nDiagnostics to implement from first principles:\n- Early-epoch stability: define an early window of length $K = \\min(5, T)$. Detect initial divergence by checking if there exists some $t \\in \\{1, \\dots, K\\}$ such that $y_{t} \\gt (1 + \\tau) \\, y_{t-1}$, with threshold $\\tau = 0.1$.\n- Delayed progress: quantify the fraction of total loss reduction achieved by epoch $K$ as\n  $$f_{\\text{early}} = \\frac{y_{0} - y_{K}}{\\max(y_{0} - y_{T}, \\varepsilon)},$$\n  with $\\varepsilon = 10^{-12}$. Declare delayed progress if $f_{\\text{early}} \\lt \\rho$ with $\\rho = 0.2$.\n- Classification rule, applied in this order:\n  - If initial divergence is detected in the early window, classify as under-warmup and output $-1$.\n  - Else if delayed progress is detected, classify as over-warmup and output $1$.\n  - Else classify as acceptable warmup and output $0$.\n\nSimulation details:\n- Initialize with $x_{0}$ and compute $y_{0} = L(x_{0})$.\n- For each epoch $t = 1, 2, \\dots, T$:\n  - Compute $\\eta_{t} = \\eta_{\\max} \\cdot \\min\\!\\left(\\frac{t}{w}, 1\\right)$.\n  - Update $x_{t} = x_{t-1} - \\eta_{t} a x_{t-1}$.\n  - Compute $y_{t} = \\frac{1}{2} a x_{t}^{2} + \\sigma \\sin\\!\\left( \\frac{2 \\pi t}{P} \\right)$.\n\nTest suite:\nProvide outputs for the following parameter sets. Each case is a tuple $(a, \\eta_{\\max}, w, T, x_{0}, \\sigma, P)$:\n- Case A (expected to probe initial divergence with extremely short warmup): $(10.0, 0.25, 1, 40, 1.0, 0.0, 7)$.\n- Case B (expected acceptable warmup with safe maximum learning rate and short warmup): $(10.0, 0.15, 3, 40, 1.0, 0.0, 7)$.\n- Case C (expected delayed progress with very long warmup): $(10.0, 0.18, 300, 500, 1.0, 0.0, 7)$.\n- Case D (boundary stability at the edge of the classical step-size stability limit after warmup): $(10.0, 0.20, 5, 40, 1.0, 0.0, 7)$.\n- Case E (expected initial divergence at the end of warmup with too-high maximum learning rate): $(12.0, 0.25, 5, 50, 1.0, 0.0, 7)$.\n\nFinal output format:\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, in the order of the test suite above. Each entry must be an integer in $\\{-1, 0, 1\\}$ representing the class for that case, so the output must look like $[r_{A}, r_{B}, r_{C}, r_{D}, r_{E}]$.\n\nNotes:\n- There are no physical units in this problem.\n- Angles in the sine term are in radians by construction of the argument $\\frac{2 \\pi t}{P}$.\n- Percentages must be expressed as decimals, and all thresholds $\\tau$, $\\rho$, and $\\varepsilon$ are provided numerically.", "solution": "The problem statement has been validated and is determined to be sound. It is scientifically grounded in the principles of numerical optimization, specifically gradient descent on a convex quadratic function. The problem is well-posed, with all parameters, equations, and diagnostic criteria explicitly and unambiguously defined. The setup is self-contained and internally consistent, allowing for a unique and meaningful solution.\n\nThe task is to simulate the training dynamics of a one-dimensional parameter $x$ under gradient descent and classify the behavior of the learning rate warmup schedule. The process involves several interconnected components: the mathematical model of optimization, the learning rate schedule, the simulation of training loss, and a set of diagnostic rules.\n\nFirst, we establish the core optimization model. The loss function is a simple convex quadratic, $L(x) = \\frac{1}{2} a x^2$, where $a  0$ is the curvature. The gradient of this loss function with respect to the parameter $x$ is $\\nabla L(x) = a x$. The gradient descent update rule modifies the parameter $x$ at each epoch $t$ according to the equation $x_{t} = x_{t-1} - \\eta_{t} \\nabla L(x_{t-1})$, where $\\eta_t$ is the learning rate at epoch $t$. Substituting the gradient, the specific update rule is:\n$$x_{t} = x_{t-1} - \\eta_{t} a x_{t-1} = x_{t-1}(1 - \\eta_{t} a)$$\nThis update is performed for epochs $t = 1, 2, \\dots, T$.\n\nThe learning rate $\\eta_t$ follows a linear warmup schedule. For a total warmup duration of $w$ epochs and a target maximum learning rate of $\\eta_{\\max}$, the learning rate at epoch $t$ is given by:\n$$\\eta_{t} = \\eta_{\\max} \\cdot \\min\\left(\\frac{t}{w}, 1\\right)$$\nThis means $\\eta_t$ increases linearly from $\\eta_1 = \\eta_{\\max}/w$ to $\\eta_w = \\eta_{\\max}$ for $t \\le w$. For all subsequent epochs $t  w$, the learning rate remains constant at $\\eta_t = \\eta_{\\max}$.\n\nThe simulation must track the training loss over the epochs. The problem defines an observed loss, $y_t$, which consists of the true loss $L(x_t)$ plus a deterministic sinusoidal noise term. The initial loss is $y_0 = L(x_0)$. For subsequent epochs $t \\in \\{1, 2, \\dots, T\\}$, the observed loss is:\n$$y_t = L(x_t) + \\sigma \\sin\\left(\\frac{2 \\pi t}{P}\\right) = \\frac{1}{2} a x_t^2 + \\sigma \\sin\\left(\\frac{2 \\pi t}{P}\\right)$$\nThe simulation proceeds as follows:\n1. Initialize the parameter $x_0$ and compute the initial loss $y_0 = \\frac{1}{2} a x_0^2$. Store all loss values $y_t$ in an array.\n2. For each epoch $t$ from $1$ to $T$:\n   a. Calculate the learning rate $\\eta_t$ using the warmup schedule.\n   b. Update the parameter to get $x_t$ using the gradient descent rule.\n   c. Compute the observed loss $y_t$ and store it.\n\nAfter the simulation is complete, we apply a sequence of diagnostic tests to the generated learning curve $\\{y_t\\}_{t=0}^T$.\n\nThe first diagnostic is for **early-epoch stability**. This test checks for initial divergence, a common symptom of an overly aggressive learning rate (i.e., under-warmup). We define an early window of $K = \\min(5, T)$ epochs. Initial divergence is detected if the loss increases by more than a relative threshold $\\tau = 0.1$ at any point within this window. That is, if there exists any $t \\in \\{1, \\dots, K\\}$ such that:\n$$y_t  (1 + \\tau) y_{t-1}$$\nIf this condition is met, the warmup is classified as `under-warmup` ($-1$).\n\nIf no initial divergence is found, the second diagnostic is for **delayed progress**. This test checks for an overly conservative learning rate (i.e., over-warmup), which causes the model to learn too slowly at the beginning. We quantify the fraction of the total loss reduction that occurs within the early window of $K$ epochs:\n$$f_{\\text{early}} = \\frac{y_0 - y_K}{\\max(y_0 - y_T, \\varepsilon)}$$\nHere, $\\varepsilon = 10^{-12}$ is a small constant to prevent division by zero if the loss does not decrease from epoch $0$ to $T$. If this fraction is below a threshold $\\rho = 0.2$, we declare delayed progress. The warmup is then classified as `over-warmup` ($1$).\n\nThe final classification follows a strict order.\n1. If initial divergence is detected, the result is $-1$.\n2. Otherwise, if delayed progress is detected, the result is $1$.\n3. Otherwise, the warmup is considered `acceptable`, and the result is $0$.\n\nThis procedure is applied to each test case provided. The implementation will systematically execute the simulation and apply the defined diagnostics to produce the final classification for each set of parameters.", "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Simulates training dynamics to diagnose learning rate warmup for several test cases.\n    \"\"\"\n\n    test_cases = [\n        # Case A: (a, eta_max, w, T, x0, sigma, P)\n        (10.0, 0.25, 1, 40, 1.0, 0.0, 7),\n        # Case B:\n        (10.0, 0.15, 3, 40, 1.0, 0.0, 7),\n        # Case C:\n        (10.0, 0.18, 300, 500, 1.0, 0.0, 7),\n        # Case D:\n        (10.0, 0.20, 5, 40, 1.0, 0.0, 7),\n        # Case E:\n        (12.0, 0.25, 5, 50, 1.0, 0.0, 7),\n    ]\n\n    results = []\n\n    # Diagnostic thresholds and constants\n    tau = 0.1\n    rho = 0.2\n    epsilon = 1e-12\n\n    for case in test_cases:\n        a, eta_max, w, T, x0, sigma, P = case\n\n        # --- Simulation ---\n        # Initialize arrays for parameter and loss history\n        x_history = np.zeros(T + 1)\n        y_history = np.zeros(T + 1)\n\n        # Initial conditions\n        x_history[0] = x0\n        y_history[0] = 0.5 * a * x_history[0]**2\n\n        # Run the simulation loop for T epochs\n        for t in range(1, T + 1):\n            # Calculate learning rate with linear warmup\n            eta_t = eta_max * min(t / w, 1.0)\n            \n            # Update parameter using gradient descent\n            x_prev = x_history[t-1]\n            x_curr = x_prev * (1 - eta_t * a)\n            x_history[t] = x_curr\n            \n            # Calculate observed loss\n            true_loss = 0.5 * a * x_curr**2\n            noise = sigma * np.sin(2 * np.pi * t / P) if sigma > 0 else 0.0\n            y_history[t] = true_loss + noise\n\n        # --- Diagnostics ---\n        K = min(5, T)\n        y0 = y_history[0]\n        yK = y_history[K]\n        yT = y_history[T]\n\n        # 1. Check for early-epoch stability (under-warmup)\n        initial_divergence = False\n        for t in range(1, K + 1):\n            if y_history[t] > (1 + tau) * y_history[t-1]:\n                initial_divergence = True\n                break\n\n        # 2. Check for delayed progress (over-warmup)\n        # This is only checked if no divergence was found.\n        delayed_progress = False\n        if not initial_divergence:\n            denominator = max(y0 - yT, epsilon)\n            f_early = (y0 - yK) / denominator\n            if f_early  rho:\n                delayed_progress = True\n        \n        # 3. Apply classification rule\n        if initial_divergence:\n            results.append(-1)  # Under-warmup\n        elif delayed_progress:\n            results.append(1)   # Over-warmup\n        else:\n            results.append(0)   # Acceptable warmup\n\n    # Print results in the required format\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "3115472"}, {"introduction": "Once we've established the need for warmup, the next question is one of design: what is the best way to ramp up the learning rate? This exercise explores the trade-offs between different warmup schedule shapes, such as linear and cosine. By comparing their performance under a fixed 'warmup budget'—where the sum of learning rates over the warmup period is constant—you will investigate how the profile of the learning rate increase impacts the final optimization outcome, highlighting a more subtle aspect of training dynamic control [@problem_id:3143278].", "problem": "Consider deterministic gradient descent applied to the one-dimensional quadratic objective $f(x) = \\frac{1}{2}\\lambda x^2$ with curvature parameter $\\lambda  0$. The update rule is $x_{k+1} = x_k - \\eta_k \\nabla f(x_k)$ for $k = 0, 1, \\dots, T_w - 1$, where $\\eta_k \\ge 0$ is the learning rate at step $k$ and $T_w$ is the warmup length (the number of gradient descent steps during warmup). The gradient is $\\nabla f(x) = \\lambda x$. A warmup schedule is a sequence $\\{\\eta_k\\}_{k=1}^{T_w}$ that is monotonic non-decreasing and satisfies $\\eta_{T_w} = \\eta_0$, where $\\eta_0$ is the base learning rate at the end of warmup.\n\nFundamental base:\n- Gradient descent update $x_{k+1} = x_k - \\eta_k \\nabla f(x_k)$ applied to the quadratic $f(x) = \\frac{1}{2}\\lambda x^2$ implies $x_{k+1} = (1 - \\lambda \\eta_k) x_k$.\n- The cumulative warmup \"budget\" constraint is that the discrete sum $\\sum_{k=1}^{T_w} \\eta_k$ equals a fixed constant $A  0$. This discrete sum is the Riemann sum approximation to the continuous integral $\\int_0^{T_w} \\eta(t)\\,dt$, and will be enforced exactly in the discrete setting as $\\sum_{k=1}^{T_w} \\eta_k = A$.\n\nWarmup schedule families to be analyzed:\n- Linear warmup: increases proportionally to step index, from $0$ to $\\eta_0$ by step $T_w$.\n- Cosine warmup: increases according to $1 - \\cos(\\cdot)$ from $0$ to $\\eta_0$ by step $T_w$. Angles must be interpreted in radians.\n- Exponential warmup: increases according to $1 - e^{-\\alpha k}$ for a given $\\alpha  0$, normalized so that the schedule reaches $\\eta_0$ at step $T_w$.\n\nFor each schedule family, the base $\\eta_0$ must be chosen (as a function of $T_w$ and the schedule shape parameters) so that the discrete sum $\\sum_{k=1}^{T_w} \\eta_k$ equals the fixed value $A$. Then, the gradient descent is run for $T_w$ steps starting from $x_0$, and the resulting objective value $f(x_{T_w})$ is recorded. The analysis thus compares the outcomes (final objective values) for different $(T_w, \\eta_0)$ pairs that maintain the same warmup budget $A$.\n\nYour task is to implement a program that computes $f(x_{T_w})$ for the following test suite. All angle quantities are in radians. All outputs are real numbers (floats).\n\nTest suite (each case lists the schedule family, the warmup length $T_w$, the budget $A$, the curvature $\\lambda$, the initial value $x_0$, and any additional schedule parameter):\n\n1. Linear warmup with $T_w = 10$, $A = 3.0$, $\\lambda = 0.1$, $x_0 = 1.0$.\n2. Cosine warmup with $T_w = 1$, $A = 0.5$, $\\lambda = 0.5$, $x_0 = 1.0$.\n3. Exponential warmup with $T_w = 100$, $A = 20.0$, $\\lambda = 0.05$, $x_0 = 1.0$, exponent rate $\\alpha = 0.07$.\n\nDefinitions of the schedules to be used in the computation:\n- Linear: $\\eta_k = \\eta_0 \\frac{k}{T_w}$ for $k = 1, \\dots, T_w$.\n- Cosine: $\\eta_k = \\frac{\\eta_0}{2}\\left(1 - \\cos\\left(\\frac{\\pi k}{T_w}\\right)\\right)$ for $k = 1, \\dots, T_w$, with angles in radians.\n- Exponential (normalized to reach $\\eta_0$ at $T_w$): $\\eta_k = \\eta_0 \\frac{1 - e^{-\\alpha k}}{1 - e^{-\\alpha T_w}}$ for $k = 1, \\dots, T_w$.\n\nConstraint to enforce in all cases: $\\sum_{k=1}^{T_w} \\eta_k = A$.\n\nComputation target for each case:\n- Compute $x_{T_w} = x_0 \\prod_{k=1}^{T_w} \\left(1 - \\lambda \\eta_k\\right)$.\n- Compute $f(x_{T_w}) = \\frac{1}{2}\\lambda x_{T_w}^2$.\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (e.g., $[result1,result2,result3]$). The entries must be the values of $f(x_{T_w})$ for the test suite in the order listed above, each expressed as a float.", "solution": "The problem is assessed to be valid. It is scientifically grounded in the principles of numerical optimization, is well-posed with a unique solution for each test case, and is expressed using objective and precise mathematical language. While a minor ambiguity exists in the indexing of the gradient descent steps (general rule using $k=0, \\dots, T_w-1$ versus specific schedule definitions using $k=1, \\dots, T_w$), this is unambiguously resolved by the explicit formulation of the computational target, $x_{T_w} = x_0 \\prod_{k=1}^{T_w} \\left(1 - \\lambda \\eta_k\\right)$, and the consistent use of the $k=1, \\dots, T_w$ indexing for all schedule definitions and constraints. The solution will strictly adhere to this explicit formulation.\n\nThe task is to compute the final objective function value, $f(x_{T_w})$, after applying $T_w$ steps of gradient descent with a learning rate warmup schedule. The objective function is $f(x) = \\frac{1}{2}\\lambda x^2$. The gradient is $\\nabla f(x) = \\lambda x$.\n\nThe state update rule after one step of gradient descent is $x_{k+1} = x_k - \\eta_k \\nabla f(x_k) = x_k - \\eta_k (\\lambda x_k) = (1 - \\lambda \\eta_k) x_k$. Following the problem's explicit definition, we use a sequence of learning rates $\\{\\eta_k\\}_{k=1}^{T_w}$. Applying this update rule for $T_w$ steps starting from an initial value $x_0$ yields the final state $x_{T_w}$:\n$$\nx_{T_w} = x_0 \\prod_{k=1}^{T_w} (1 - \\lambda \\eta_k)\n$$\nThe value of the objective function at this final state is:\n$$\nf(x_{T_w}) = \\frac{1}{2} \\lambda x_{T_w}^2 = \\frac{1}{2} \\lambda \\left( x_0 \\prod_{k=1}^{T_w} (1 - \\lambda \\eta_k) \\right)^2\n$$\n\nA crucial step is to determine the complete learning rate schedule $\\{\\eta_k\\}_{k=1}^{T_w}$ for each case. The schedules are defined in terms of a base learning rate $\\eta_0$, which is the final rate at step $T_w$. The value of $\\eta_0$ is determined by the \"warmup budget\" constraint:\n$$\n\\sum_{k=1}^{T_w} \\eta_k = A\n$$\nwhere $A$ is a given constant. For each schedule family, $\\eta_k$ is a function of $\\eta_0$. Let's write $\\eta_k = \\eta_0 \\cdot g_k$, where $g_k$ is the shape of the schedule. The constraint becomes:\n$$\n\\sum_{k=1}^{T_w} \\eta_0 g_k = \\eta_0 \\sum_{k=1}^{T_w} g_k = A\n$$\nLet $S = \\sum_{k=1}^{T_w} g_k$. Then $\\eta_0 = A/S$. We now derive the expression for the sum factor $S$ for each schedule family.\n\nLinear Warmup:\nThe schedule is defined as $\\eta_k = \\eta_0 \\frac{k}{T_w}$ for $k=1, \\dots, T_w$. The shape function is $g_k = k/T_w$.\nThe sum factor $S_{lin}$ is:\n$$\nS_{lin} = \\sum_{k=1}^{T_w} \\frac{k}{T_w} = \\frac{1}{T_w} \\sum_{k=1}^{T_w} k = \\frac{1}{T_w} \\frac{T_w(T_w+1)}{2} = \\frac{T_w+1}{2}\n$$\n\nCosine Warmup:\nThe schedule is $\\eta_k = \\frac{\\eta_0}{2}\\left(1 - \\cos\\left(\\frac{\\pi k}{T_w}\\right)\\right)$ for $k=1, \\dots, T_w$. The shape function is $g_k = \\frac{1}{2}\\left(1 - \\cos\\left(\\frac{\\pi k}{T_w}\\right)\\right)$.\nThe sum factor $S_{cos}$ is:\n$$\nS_{cos} = \\sum_{k=1}^{T_w} \\frac{1}{2}\\left(1 - \\cos\\left(\\frac{\\pi k}{T_w}\\right)\\right) = \\frac{1}{2} \\left( \\sum_{k=1}^{T_w} 1 - \\sum_{k=1}^{T_w} \\cos\\left(\\frac{\\pi k}{T_w}\\right) \\right) = \\frac{1}{2} \\left( T_w - \\sum_{k=1}^{T_w} \\cos\\left(\\frac{\\pi k}{T_w}\\right) \\right)\n$$\nUsing the identity $\\sum_{k=1}^{N} \\cos(k\\theta) = -1$ for $\\theta=\\pi/N$ and $N \\ge 1$ being an integer, we have $\\sum_{k=1}^{T_w} \\cos\\left(\\frac{\\pi k}{T_w}\\right) = -1$.\nThus, the sum factor is:\n$$\nS_{cos} = \\frac{1}{2} (T_w - (-1)) = \\frac{T_w+1}{2}\n$$\nInterestingly, this is identical to the sum factor for the linear schedule.\n\nExponential Warmup:\nThe schedule is $\\eta_k = \\eta_0 \\frac{1 - e^{-\\alpha k}}{1 - e^{-\\alpha T_w}}$ for $k=1, \\dots, T_w$. The shape function is $g_k = \\frac{1 - e^{-\\alpha k}}{1 - e^{-\\alpha T_w}}$.\nThe sum factor $S_{exp}$ is:\n$$\nS_{exp} = \\sum_{k=1}^{T_w} \\frac{1 - e^{-\\alpha k}}{1 - e^{-\\alpha T_w}} = \\frac{1}{1 - e^{-\\alpha T_w}} \\sum_{k=1}^{T_w} (1 - e^{-\\alpha k}) = \\frac{1}{1 - e^{-\\alpha T_w}} \\left( T_w - \\sum_{k=1}^{T_w} (e^{-\\alpha})^k \\right)\n$$\nThe second sum is a geometric series. Let $r=e^{-\\alpha}$. The sum is $\\sum_{k=1}^{T_w} r^k = r \\frac{1-r^{T_w}}{1-r}$. Substituting back:\n$$\nS_{exp} = \\frac{1}{1 - e^{-\\alpha T_w}} \\left( T_w - e^{-\\alpha} \\frac{1 - e^{-\\alpha T_w}}{1 - e^{-\\alpha}} \\right)\n$$\n\nThe overall algorithm for each test case is as follows:\n1.  Identify the schedule type and its parameters ($T_w, A, \\lambda, x_0, \\alpha$).\n2.  Calculate the corresponding sum factor $S$.\n3.  Calculate the base learning rate $\\eta_0 = A/S$.\n4.  Generate the full learning rate schedule $\\{\\eta_k\\}_{k=1}^{T_w}$ using the formula for the given family.\n5.  Compute the final state $x_{T_w} = x_0 \\prod_{k=1}^{T_w} (1 - \\lambda \\eta_k)$.\n6.  Compute the final objective value $f(x_{T_w}) = \\frac{1}{2} \\lambda x_{T_w}^2$.\n\nThis procedure is implemented for each test case specified in the problem statement.\n\nFor example, for Test Case 2 (Cosine warmup, $T_w=1, A=0.5, \\lambda=0.5, x_0=1.0$):\n1.  $S_{cos} = \\frac{1+1}{2} = 1$.\n2.  $\\eta_0 = A/S_{cos} = 0.5/1 = 0.5$.\n3.  The schedule has only one step, $k=1$. $\\eta_1 = \\frac{\\eta_0}{2}(1-\\cos(\\pi \\cdot 1/1)) = \\frac{0.5}{2}(1 - (-1)) = 0.5$.\n4.  $x_1 = x_0(1-\\lambda \\eta_1) = 1.0(1 - 0.5 \\cdot 0.5) = 0.75$.\n5.  $f(x_1) = \\frac{1}{2}\\lambda x_1^2 = \\frac{1}{2}(0.5)(0.75)^2 = 0.25 \\cdot 0.5625 = 0.140625$.\n\nThe other cases require numerical computation, which is performed by the provided program.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef calculate_linear(Tw, A, lmbda, x0):\n    \"\"\"\n    Computes f(x_Tw) for a linear warmup schedule.\n    \"\"\"\n    # Sum factor S_lin = (Tw + 1) / 2\n    S_lin = (Tw + 1.0) / 2.0\n    \n    # Base learning rate eta0\n    eta0 = A / S_lin\n    \n    # Learning rate schedule eta_k = eta0 * k / Tw\n    ks = np.arange(1, Tw + 1)\n    etas = eta0 * ks / Tw\n    \n    # Compute the product term for x_Tw\n    product_term = np.prod(1.0 - lmbda * etas)\n    \n    # Compute x_Tw\n    x_Tw = x0 * product_term\n    \n    # Compute f(x_Tw)\n    f_x_Tw = 0.5 * lmbda * x_Tw**2\n    \n    return f_x_Tw\n\ndef calculate_cosine(Tw, A, lmbda, x0):\n    \"\"\"\n    Computes f(x_Tw) for a cosine warmup schedule.\n    \"\"\"\n    # Sum factor S_cos = (Tw + 1) / 2\n    S_cos = (Tw + 1.0) / 2.0\n        \n    # Base learning rate eta0\n    eta0 = A / S_cos\n    \n    # Learning rate schedule eta_k = (eta0 / 2) * (1 - cos(pi*k/Tw))\n    ks = np.arange(1, Tw + 1)\n    etas = (eta0 / 2.0) * (1.0 - np.cos(np.pi * ks / Tw))\n    \n    # Compute the product term for x_Tw\n    product_term = np.prod(1.0 - lmbda * etas)\n    \n    # Compute x_Tw\n    x_Tw = x0 * product_term\n    \n    # Compute f(x_Tw)\n    f_x_Tw = 0.5 * lmbda * x_Tw**2\n    \n    return f_x_Tw\n\ndef calculate_exponential(Tw, A, lmbda, x0, alpha):\n    \"\"\"\n    Computes f(x_Tw) for an exponential warmup schedule.\n    \"\"\"\n    # Sum factor S_exp\n    exp_a = np.exp(-alpha)\n    exp_aTw = np.exp(-alpha * Tw)\n    \n    # Sum of geometric series part\n    # sum_{k=1}^{Tw} (e^{-alpha})^k\n    # This must handle the case where the ratio is 1 (alpha=0), but alpha > 0 is a premise.\n    sum_geom_series = exp_a * (1.0 - exp_aTw) / (1.0 - exp_a)\n    \n    # S_exp = (1 / (1-exp(-a*Tw))) * (Tw - sum_geom_series)\n    sum_term_in_S = Tw - sum_geom_series\n    S_exp = sum_term_in_S / (1.0 - exp_aTw)\n    \n    # Base learning rate eta0\n    eta0 = A / S_exp\n    \n    # Learning rate schedule eta_k = eta0 * (1 - exp(-alpha*k)) / (1 - exp(-alpha*Tw))\n    ks = np.arange(1, Tw + 1)\n    numerator = 1.0 - np.exp(-alpha * ks)\n    denominator = 1.0 - exp_aTw\n    etas = eta0 * numerator / denominator\n    \n    # Compute the product term for x_Tw\n    product_term = np.prod(1.0 - lmbda * etas)\n    \n    # Compute x_Tw\n    x_Tw = x0 * product_term\n    \n    # Compute f(x_Tw)\n    f_x_Tw = 0.5 * lmbda * x_Tw**2\n    \n    return f_x_Tw\n\ndef solve():\n    \"\"\"\n    Main function to solve the problem for the given test suite.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        {'type': 'linear', 'Tw': 10, 'A': 3.0, 'lambda': 0.1, 'x0': 1.0},\n        {'type': 'cosine', 'Tw': 1, 'A': 0.5, 'lambda': 0.5, 'x0': 1.0},\n        {'type': 'exponential', 'Tw': 100, 'A': 20.0, 'lambda': 0.05, 'x0': 1.0, 'alpha': 0.07}\n    ]\n\n    results = []\n    for case in test_cases:\n        if case['type'] == 'linear':\n            result = calculate_linear(case['Tw'], case['A'], case['lambda'], case['x0'])\n        elif case['type'] == 'cosine':\n            result = calculate_cosine(case['Tw'], case['A'], case['lambda'], case['x0'])\n        elif case['type'] == 'exponential':\n            result = calculate_exponential(case['Tw'], case['A'], case['lambda'], case['x0'], case['alpha'])\n        else:\n            raise ValueError(f\"Unknown schedule type: {case['type']}\")\n        results.append(result)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "3143278"}]}