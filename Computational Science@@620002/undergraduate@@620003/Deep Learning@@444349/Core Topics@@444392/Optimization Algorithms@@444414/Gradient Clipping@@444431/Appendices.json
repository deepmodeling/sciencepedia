{"hands_on_practices": [{"introduction": "Before diving into gradient clipping, it's valuable to understand the broader challenge of ensuring stability in numerical optimization. When an algorithm attempts to minimize a function, taking steps that are too large or based on a poor local approximation can lead to instability or divergence. This practice explores the Trust-Region (TR) method, a powerful framework that manages step sizes by building and trusting a local model only within a specific radius. By working through this exercise [@problem_id:3153333], you will derive the core step-acceptance logic of TR methods and analyze a case where the reliability metric can be misleading, providing deep insight into the subtleties of controlling optimization.", "problem": "In model-based Derivative-Free Optimization (DFO), a common approach is the Trust-Region (TR) framework that builds a local surrogate model to approximate an unknown objective function. Let $f:\\mathbb{R}^{n}\\to\\mathbb{R}$ be smooth but unavailable in closed form, and let $m_{k}:\\mathbb{R}^{n}\\to\\mathbb{R}$ be a local surrogate at an iterate $x_{k}\\in\\mathbb{R}^{n}$. The trial step $s_{k}$ is computed by (approximately) minimizing $m_{k}$ on the trust region $\\{s:\\|s\\|\\leq \\Delta_{k}\\}$, where $\\Delta_{k}>0$ is the trust-region radius. Define the actual reduction and the predicted reduction as the differences $f(x_{k})-f(x_{k}+s_{k})$ and $m_{k}(0)-m_{k}(s_{k})$, respectively. Starting only from these definitions and the guiding principle that the trust-region mechanism should accept a step when the actual improvement meaningfully agrees with the predicted improvement and should adjust $\\Delta_{k}$ to maintain model reliability, do the following:\n\n1) Derive a step-acceptance rule based on the ratio\n$$\n\\rho_{k}\\;=\\;\\frac{f(x_{k})-f(x_{k}+s_{k})}{m_{k}(0)-m_{k}(s_{k})},\n$$\nincluding a principled pair of thresholds $0<\\eta_{1}<\\eta_{2}<1$ and multiplicative update factors $\\gamma_{\\mathrm{dec}}\\in(0,1)$ and $\\gamma_{\\mathrm{inc}}>1$ for shrinking and expanding the trust-region radius. Your derivation must argue from the core definitions of actual and predicted reductions and from the intent that the model should be trusted only to the extent that its predictions align with observed reductions.\n\n2) Construct a concrete one-dimensional pathological example where the ratio $\\rho_{k}$ can be misleading because of model bias. Use the following data to instantiate the example and to compute a numeric value:\n- Objective function $f(x)=(x-1)^{2}$.\n- Current iterate $x_{k}=0$ and trust-region radius $\\Delta_{k}=0.5$.\n- Quadratic model $m_{k}(s)=a+bs+\\tfrac{1}{2}cs^{2}$ with coefficients $b=-0.2$ and $c=0.1$ (take $a$ arbitrary, since it cancels in the predicted reduction).\n- Trial step $s_{k}$ is the exact minimizer of $m_{k}(s)$ over the interval $\\{-\\Delta_{k}\\le s\\le \\Delta_{k}\\}$.\n\nCompute the value of $\\rho_{k}$ for this example, and explain in words why it is misleading about model quality. Give your final answer as the value of $\\rho_{k}$, rounded to four significant figures. No units are required.", "solution": "The problem is valid. It is scientifically grounded in the theory of numerical optimization, specifically model-based derivative-free trust-region methods. The problem is well-posed, objective, and contains all necessary information to derive the conceptual framework and compute the required numerical value.\n\nThe problem consists of two parts. The first part requires the derivation of the standard trust-region step acceptance and radius update mechanism from first principles. The second part requires the computation of a specific performance ratio, $\\rho_k$, for a pathological case and an explanation of why the ratio is misleading.\n\n**Part 1: Derivation of Trust-Region Update Rules**\n\nThe core of a trust-region method lies in managing the agreement between a local surrogate model, $m_k(s)$, and the true objective function, $f(x)$. The quantity that measures this agreement for a trial step $s_k$ is the ratio $\\rho_k$:\n$$\n\\rho_{k} = \\frac{\\text{ared}}{\\text{pred}} = \\frac{f(x_{k})-f(x_{k}+s_{k})}{m_{k}(0)-m_{k}(s_{k})}\n$$\nHere, `ared` is the \"actual reduction\" in the objective function and `pred` is the \"predicted reduction\" according to the model. We are minimizing $f$, so `pred` is assumed to be positive, as $s_k$ is chosen to decrease the model value $m_k$.\n\nThe guiding principle is that the step $s_k$ is accepted if the actual reduction is a meaningful fraction of the predicted reduction, and the trust-region radius $\\Delta_k$ is adjusted based on how accurately the model predicted the outcome.\n\nWe can analyze the value of $\\rho_k$ to create a set of rules:\n\nCase 1: Excellent model-function agreement.\nIf $\\rho_k$ is close to $1$, then `ared` $\\approx$ `pred`, indicating the model is a highly accurate predictor of the function's behavior within the trust region. If $\\rho_k > 1$, the actual reduction is even better than predicted, which is also a sign of a successful step. We can group these \"very good\" outcomes together. To formalize this, we use a threshold $\\eta_2 \\in (0, 1)$. If $\\rho_k > \\eta_2$, the model's performance is deemed excellent. Consequently, the step $s_k$ should be accepted ($x_{k+1} = x_k + s_k$) and our confidence in the model should increase. This justifies expanding the trust region for the next iteration to allow for more ambitious steps: $\\Delta_{k+1} = \\gamma_{\\text{inc}} \\Delta_k$, where $\\gamma_{\\text{inc}} > 1$.\n\nCase 2: Poor model-function agreement.\nIf $\\rho_k$ is small and positive, or negative, the model is a poor predictor. If $\\rho_k \\le 0$, the step failed to decrease the objective function at all (`ared` $\\le 0$), despite the model predicting a decrease. To handle this, we introduce a threshold $\\eta_1$, with $0 < \\eta_1 < \\eta_2$. If $\\rho_k \\le \\eta_1$, the agreement is poor. The actual reduction is either negative or an insignificant fraction of what was promised. In this case, the step $s_k$ must be rejected ($x_{k+1} = x_k$), as it is not productive. The poor prediction indicates that the trust region is too large for the model to be reliable. Thus, the radius must be shrunk: $\\Delta_{k+1} = \\gamma_{\\text{dec}} \\Delta_k$, where $\\gamma_{\\text{dec}} \\in (0, 1)$.\n\nCase 3: Acceptable model-function agreement.\nThis intermediate case occurs when $\\eta_1 < \\rho_k \\le \\eta_2$. Here, the actual reduction is a sufficient fraction of the predicted reduction for the step to be considered successful. Thus, the step is accepted: $x_{k+1} = x_k + s_k$. However, the model is not accurate enough to warrant increasing our confidence by expanding the trust region. Conversely, it is not so inaccurate as to force a reduction of the trust region. The most logical action is to maintain the current level of trust by keeping the radius the same: $\\Delta_{k+1} = \\Delta_k$.\n\nIn summary, the derived rules are:\n1.  If $\\rho_k \\le \\eta_1$: The step is rejected. Set $x_{k+1} = x_k$ and shrink the radius: $\\Delta_{k+1} = \\gamma_{\\text{dec}} \\Delta_k$.\n2.  If $\\eta_1 < \\rho_k \\le \\eta_2$: The step is accepted. Set $x_{k+1} = x_k + s_k$ and keep the radius: $\\Delta_{k+1} = \\Delta_k$.\n3.  If $\\rho_k > \\eta_2$: The step is accepted. Set $x_{k+1} = x_k + s_k$ and expand the radius: $\\Delta_{k+1} = \\gamma_{\\text{inc}} \\Delta_k$.\n\nThese rules follow logically from the principle of adapting the trust-region size to reflect the observed reliability of the surrogate model.\n\n**Part 2: Pathological Example Calculation and Analysis**\n\nWe are given the following data:\n- Objective function: $f(x) = (x-1)^2$\n- Current iterate: $x_k = 0$\n- Trust-region radius: $\\Delta_k = 0.5$\n- Quadratic model: $m_k(s) = a + bs + \\frac{1}{2}cs^2$ with $b = -0.2$ and $c = 0.1$.\n$m_k(s) = a - 0.2s + 0.05s^2$.\n\nFirst, we find the trial step $s_k$ by minimizing $m_k(s)$ on the trust region, which is the interval $[-\\Delta_k, \\Delta_k] = [-0.5, 0.5]$.\nThe unconstrained minimizer of the quadratic $m_k(s)$ is found by setting its derivative to zero:\n$$\nm_k'(s) = -0.2 + 0.1s = 0 \\implies s = \\frac{0.2}{0.1} = 2\n$$\nThe second derivative is $m_k''(s) = 0.1 > 0$, confirming this is a minimum.\nThe unconstrained minimizer $s=2$ lies outside the trust region $[-0.5, 0.5]$. Since $m_k(s)$ is a convex parabola, its minimum over the interval must occur at the boundary point closest to the unconstrained minimizer. The closest point in $[-0.5, 0.5]$ to $2$ is $0.5$.\nThus, the trial step is $s_k = 0.5$.\n\nNext, we calculate the predicted reduction, `pred`:\n$$\n\\text{pred} = m_k(0) - m_k(s_k) = m_k(0) - m_k(0.5)\n$$\n$m_k(0) = a - 0.2(0) + 0.05(0)^2 = a$.\n$m_k(0.5) = a - 0.2(0.5) + 0.05(0.5)^2 = a - 0.1 + 0.05(0.25) = a - 0.1 + 0.0125 = a - 0.0875$.\n$$\n\\text{pred} = a - (a - 0.0875) = 0.0875\n$$\n\nNow, we calculate the actual reduction, `ared`:\n$$\n\\text{ared} = f(x_k) - f(x_k + s_k) = f(0) - f(0 + 0.5) = f(0) - f(0.5)\n$$\n$f(0) = (0-1)^2 = 1$.\n$f(0.5) = (0.5-1)^2 = (-0.5)^2 = 0.25$.\n$$\n\\text{ared} = 1 - 0.25 = 0.75\n$$\n\nFinally, we compute the ratio $\\rho_k$:\n$$\n\\rho_k = \\frac{\\text{ared}}{\\text{pred}} = \\frac{0.75}{0.0875} = \\frac{7500}{875} = \\frac{60}{7} \\approx 8.571428...\n$$\nRounding to four significant figures, we get $\\rho_k \\approx 8.571$.\n\n**Explanation of Why $\\rho_k$ is Misleading:**\nThe calculated value $\\rho_k \\approx 8.571$ is very large and positive. Based on the rules derived in Part 1, this would be classified as a \"very good\" step (since $\\rho_k \\gg \\eta_2$ for any reasonable $\\eta_2 < 1$), suggesting that the model $m_k$ is an excellent approximation of the true function $f$. This would lead the algorithm to expand the trust region $\\Delta_k$.\n\nHowever, this conclusion is deeply flawed. The high value of $\\rho_k$ is not indicative of a good model but is an artifact of a bad model. Let's compare the properties of the model with the true function at the current point $x_k=0$. The behavior of $f$ around $x_k=0$ is described by $g(s) = f(x_k+s) = f(s) = (s-1)^2 = s^2 - 2s + 1$.\n- The gradient of the true function at $s=0$ is $g'(0) = -2$.\n- The curvature (second derivative) of the true function at $s=0$ is $g''(0) = 2$.\n\nThe model's properties are given by its coefficients:\n- The model's gradient at $s=0$ is $m_k'(0) = b = -0.2$.\n- The model's curvature is $m_k''(s) = c = 0.1$.\n\nThe model exhibits severe bias: it underestimates the magnitude of the true gradient by a factor of $10$ ($-0.2$ vs $-2$) and underestimates the true curvature by a factor of $20$ ($0.1$ vs $2$). This is a very poor local model.\n\nThe large value of $\\rho_k$ arises because the denominator, `pred` $= 0.0875$, is extremely small. This small predicted reduction is a direct consequence of the model's incorrectly small gradient and curvature. The model is \"flat\" and \"timid\", predicting only a minor improvement. The numerator, `ared` $= 0.75$, is large because the true function is much steeper. The ratio of a large number to a very small number is a large number.\n\nTherefore, the ratio $\\rho_k \\approx 8.571$ is misleading. It signals excellent model quality, while in reality, it is a symptom of a very poor model that severely underestimates the function's local geometry. An algorithm that blindly trusts this high $\\rho_k$ value would expand the trust region, extending its reliance on a demonstrably bad model over a wider area, which could degrade or stall the optimization process. This example highlights a critical weakness of the $\\rho_k$ ratio in the presence of significant model bias.", "answer": "$$\\boxed{8.571}$$", "id": "3153333"}, {"introduction": "In deep learning, the \"exploding gradients\" problem is a notorious cause of training instability. Gradient clipping is a widely used and effective technique to counteract this by rescaling gradients that exceed a certain magnitude. This hands-on practice [@problem_id:3131435] moves beyond a simple fixed threshold and challenges you to implement *adaptive* clipping strategies, where the threshold dynamically adjusts based on the recent history of gradient norms. You will investigate how using robust statistics, like the median and Median Absolute Deviation (MAD), creates a more stable training dynamic compared to simpler mean-based approaches, especially in the face of outlier gradients.", "problem": "Consider a discrete-time gradient-based optimization process whose parameter update at step $t$ is given by $w_{t+1} = w_t - \\eta \\cdot \\hat{g}_t$, where $\\eta > 0$ is the learning rate and $\\hat{g}_t$ is a clipped version of the raw gradient $g_t$. Gradient clipping scales $g_t$ when its Euclidean norm exceeds a threshold, which prevents excessively large steps that destabilize training. Formally, let $r_t = \\lVert g_t \\rVert_2$ denote the Euclidean norm of $g_t$. Define the clipped gradient $\\hat{g}_t$ by projecting $g_t$ onto the closed Euclidean ball of radius $\\tau_t$ centered at the origin, equivalently scaling $g_t$ by the factor $\\min\\{1, \\tau_t / r_t\\}$. The clipped step norm is then $u_t = \\eta \\cdot \\min\\{r_t, \\tau_t\\}$.\n\nYou will implement adaptive clipping thresholds $\\tau_t$ computed from a trailing window of past gradient norms to capture recent dynamics. To design and compare thresholds in a scientifically grounded way, start from the following core definitions of descriptive statistics applied to a finite window $W_t$ of past gradient norms. For a window $W_t = \\{r_{t-k} \\mid 1 \\le k \\le \\min\\{W, t-1\\}\\}$, define:\n- The sample mean $\\mu_t$ as $\\mu_t = \\frac{1}{|W_t|} \\sum_{x \\in W_t} x$.\n- The sample median $m_t$ as the middle order statistic of $W_t$ (or the average of the two middle values when $|W_t|$ is even).\n- The Median Absolute Deviation (MAD) as $\\mathrm{MAD}_t = \\operatorname{median}\\big(\\{|x - m_t| : x \\in W_t\\}\\big)$.\n\nUse these statistics to specify three adaptive clipping rules for $\\tau_t$:\n1. A mean-based threshold that scales with the sample mean $\\mu_t$.\n2. A median-based threshold that scales with the sample median $m_t$.\n3. A robust threshold that combines the sample median $m_t$ and the Median Absolute Deviation $\\mathrm{MAD}_t$ using a fixed scale factor $\\kappa = 1.4826$ motivated by normally distributed fluctuations.\n\nIn every case, the scaling constant $c > 0$ multiplies the relevant statistic. When the window $W_t$ is empty (i.e., at $t = 1$), set $\\tau_1 = c \\cdot r_1$ for all schemes. For $t > 1$, construct $W_t$ from the previous $\\min\\{W, t-1\\}$ gradient norms.\n\nYour program must compute the empirical variance of the clipped step norms $u_t$ over a fixed horizon of $T$ steps for each clipping rule, defined as\n$$\n\\operatorname{Var}(u) = \\frac{1}{T} \\sum_{t=1}^{T} \\left(u_t - \\bar{u}\\right)^2, \\quad \\text{where} \\quad \\bar{u} = \\frac{1}{T} \\sum_{t=1}^{T} u_t.\n$$\nUse this to quantify stability: lower variance indicates more stable updates.\n\nThen, report for each test case two floats that compare stability of robust statistics versus the mean-based threshold:\n- The ratio $R_{\\text{median}} = \\frac{\\operatorname{Var}(u)_{\\text{median}}}{\\operatorname{Var}(u)_{\\text{mean}}}$.\n- The ratio $R_{\\text{mad}} = \\frac{\\operatorname{Var}(u)_{\\text{mad}}}{\\operatorname{Var}(u)_{\\text{mean}}}$.\n\nA value less than $1$ indicates improved stability relative to the mean-based threshold. Compute these ratios with the following deterministic test suite of gradient norm sequences, each formed by a smooth baseline plus injected outliers. For all cases, define the baseline by\n$$\nr_t^{\\text{base}} = b + a \\cdot \\sin\\left(\\frac{2\\pi t}{P}\\right),\n$$\nand then override $r_t$ with specified outliers at the listed indices. All quantities are dimensionless, no physical units apply.\n\nUse the parameters below for four test cases:\n\n- Case $1$ (happy path, no outliers): $T = 60$, $W = 10$, $c = 1.0$, $\\eta = 0.05$, $b = 1.0$, $a = 0.2$, $P = 12$. No outliers: $r_t = r_t^{\\text{base}}$ for all $t$.\n- Case $2$ (single large outlier): Same baseline and hyperparameters as Case $1$; set $r_{30} = 15.0$.\n- Case $3$ (multiple large outliers): Same baseline and hyperparameters as Case $1$; set $r_{15} = 25.0$, $r_{35} = 25.0$, $r_{50} = 25.0$.\n- Case $4$ (boundary window size): $T = 60$, $W = 1$, $c = 1.0$, $\\eta = 0.05$, $b = 1.0$, $a = 0.2$, $P = 12$; set $r_{30} = 50.0$.\n\nImplementation details:\n- For each case, construct the full sequence $\\{r_t\\}_{t=1}^{T}$ deterministically from the baseline and outlier definitions.\n- For each $t$, construct $W_t = \\{r_{t-k}\\}$ with $1 \\le k \\le \\min\\{W, t-1\\}$.\n- For the three clipping rules, compute the thresholds using the respective statistics from $W_t$ and the scaling constants described above.\n- Compute clipped step norms $u_t = \\eta \\cdot \\min\\{r_t, \\tau_t\\}$.\n- Compute $\\operatorname{Var}(u)$ using the population variance formula given above for each clipping rule.\n- Output for each case the pair $\\left(R_{\\text{median}}, R_{\\text{mad}}\\right)$ as two floats, in order over the four cases, flattened into a single list.\n\nFinal output format:\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (e.g., $[r_1,r_2,r_3,r_4,r_5,r_6,r_7,r_8]$), where $r_{2k-1}$ and $r_{2k}$ are, respectively, $R_{\\text{median}}$ and $R_{\\text{mad}}$ for case $k$.", "solution": "The problem statement is assessed to be valid. It is scientifically grounded in the principles of numerical optimization and robust statistics, is well-posed with a clear and complete set of definitions and constraints, and is expressed objectively. A unique solution is derivable through direct application of the provided formulas.\n\nThe central task is to compare the stability of three adaptive gradient clipping strategies. Stability is quantified by the empirical variance of the clipped step norms, $u_t$, over a fixed time horizon $T$. A lower variance implies more stable, less erratic parameter updates during optimization. The three strategies define the clipping threshold $\\tau_t$ based on statistics computed over a trailing window of past gradient norms, $W_t$.\n\nFirst, we establish the sequence of raw gradient norms, $\\{r_t\\}_{t=1}^T$, which serves as the input signal for our analysis. For each test case, this sequence is generated deterministically using a baseline sinusoidal function with injected outliers. The baseline is given by:\n$$\nr_t^{\\text{base}} = b + a \\cdot \\sin\\left(\\frac{2\\pi t}{P}\\right)\n$$\nwhere $a$ is the amplitude, $b$ is the vertical shift, and $P$ is the period. Specific values $r_t$ are then overwritten at designated time steps $t$ to simulate outlier gradients, which are common in training large neural networks and can destabilize the learning process.\n\nThe core of the problem lies in defining the adaptive clipping threshold, $\\tau_t$. The clipped gradient, $\\hat{g}_t$, is obtained by scaling the raw gradient $g_t$ by a factor $\\min\\{1, \\tau_t / r_t\\}$, where $r_t = \\lVert g_t \\rVert_2$. This ensures the norm of the clipped gradient does not exceed $\\tau_t$. Consequently, the norm of the update step, which we denote as the clipped step norm $u_t$, is:\n$$\nu_t = \\eta \\cdot \\lVert \\hat{g}_t \\rVert_2 = \\eta \\cdot \\lVert g_t \\cdot \\min\\{1, \\tau_t / r_t\\} \\rVert_2 = \\eta \\cdot r_t \\cdot \\min\\{1, \\tau_t / r_t\\} = \\eta \\cdot \\min\\{r_t, \\tau_t\\}\n$$\nwhere $\\eta$ is the learning rate.\n\nThe three rules for setting $\\tau_t$ are based on statistics computed from the window of past gradient norms, $W_t = \\{r_{t-k} \\mid 1 \\le k \\le \\min\\{W, t-1\\}\\}$. For the first step, $t=1$, the window $W_1$ is empty. As specified, the threshold for all three rules is initialized as $\\tau_1 = c \\cdot r_1$. For subsequent steps ($t>1$), we define:\n\n1.  **Mean-Based Threshold**: This rule uses the sample mean of the norms in the window, $\\mu_t = \\frac{1}{|W_t|} \\sum_{x \\in W_t} x$. The threshold is directly proportional to this mean:\n    $$\n    \\tau_{t, \\text{mean}} = c \\cdot \\mu_t\n    $$\n    This method is simple but sensitive to outliers in the window, as a single large value can significantly inflate the mean.\n\n2.  **Median-Based Threshold**: This rule uses the sample median, $m_t = \\operatorname{median}(W_t)$, which is a robust measure of central tendency. The threshold is:\n    $$\n    \\tau_{t, \\text{median}} = c \\cdot m_t\n    $$\n    Since the median is resistant to outliers, this threshold is expected to be more stable than the mean-based one when the gradient norms exhibit sudden spikes.\n\n3.  **Robust MAD-Based Threshold**: This rule enhances robustness by incorporating a measure of statistical dispersion, the Median Absolute Deviation (MAD), defined as $\\mathrm{MAD}_t = \\operatorname{median}(\\{|x - m_t| : x \\in W_t\\})$. The constant $\\kappa = 1.4826$ is used to scale the MAD, making $\\kappa \\cdot \\mathrm{MAD}_t$ a consistent estimator for the standard deviation of a normal distribution. The problem states that the threshold \"combines the sample median $m_t$ and the Median Absolute Deviation $\\mathrm{MAD}_t$\" and that the scaling constant $c$ \"multiplies the relevant statistic\" in all cases. The most consistent interpretation of these statements is to define the statistic as a robust analogue of \"mean plus standard deviation\", leading to the formula:\n    $$\n    \\tau_{t, \\text{mad}} = c \\cdot (m_t + \\kappa \\cdot \\mathrm{MAD}_t)\n    $$\n    This approach sets the threshold based on both a robust measure of location ($m_t$) and a robust measure of spread ($\\mathrm{MAD}_t$), aiming for a highly stable behavior even with outliers.\n\nFor each of the four test cases, we perform the following procedure. First, we generate the entire sequence $\\{r_t\\}_{t=1}^T$. Then, for each time step $t=1, \\dots, T$, we compute the three thresholds $\\tau_{t, \\text{mean}}$, $\\tau_{t, \\text{median}}$, and $\\tau_{t, \\text{mad}}$ according to the rules above. Subsequently, we calculate the corresponding clipped step norms $\\{u_{t, \\text{mean}}\\}_{t=1}^T$, $\\{u_{t, \\text{median}}\\}_{t=1}^T$, and $\\{u_{t, \\text{mad}}\\}_{t=1}^T$.\n\nFinally, we quantify the stability of each sequence of step norms by computing its empirical population variance:\n$$\n\\operatorname{Var}(u) = \\frac{1}{T} \\sum_{t=1}^{T} \\left(u_t - \\bar{u}\\right)^2, \\quad \\text{where} \\quad \\bar{u} = \\frac{1}{T} \\sum_{t=1}^{T} u_t\n$$\nTo compare the performance, we compute the ratios of the variances of the robust methods to the variance of the baseline mean-based method:\n-   $R_{\\text{median}} = \\frac{\\operatorname{Var}(u)_{\\text{median}}}{\\operatorname{Var}(u)_{\\text{mean}}}$\n-   $R_{\\text{mad}} = \\frac{\\operatorname{Var}(u)_{\\text{mad}}}{\\operatorname{Var}(u)_{\\text{mean}}}$\n\nA ratio less than $1$ indicates that the corresponding robust method provides more stable step updates than the mean-based method for the given sequence of gradient norms. For Case 4, where the window size $W=1$, the statistics for $t>1$ are based on a single value, $r_{t-1}$. In this scenario, $\\mu_t = m_t = r_{t-1}$ and $\\mathrm{MAD}_t = 0$. Consequently, all three threshold rules simplify to $\\tau_t = c \\cdot r_{t-1}$, making the three methods identical. Therefore, the resulting variances will be equal, and both ratios will be exactly $1.0$. This serves as a critical internal consistency check for the implementation.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to run the test suite and print the results.\n    \"\"\"\n    \n    test_cases = [\n        # Case 1: No outliers\n        {'T': 60, 'W': 10, 'c': 1.0, 'eta': 0.05, 'b': 1.0, 'a': 0.2, 'P': 12, 'outliers': {}},\n        # Case 2: Single large outlier\n        {'T': 60, 'W': 10, 'c': 1.0, 'eta': 0.05, 'b': 1.0, 'a': 0.2, 'P': 12, 'outliers': {30: 15.0}},\n        # Case 3: Multiple large outliers\n        {'T': 60, 'W': 10, 'c': 1.0, 'eta': 0.05, 'b': 1.0, 'a': 0.2, 'P': 12, 'outliers': {15: 25.0, 35: 25.0, 50: 25.0}},\n        # Case 4: Boundary window size W=1\n        {'T': 60, 'W': 1, 'c': 1.0, 'eta': 0.05, 'b': 1.0, 'a': 0.2, 'P': 12, 'outliers': {30: 50.0}},\n    ]\n\n    KAPPA = 1.4826\n    \n    results = []\n    for case_params in test_cases:\n        ratios = compute_variance_ratios(case_params, KAPPA)\n        results.extend(ratios)\n\n    print(f\"[{','.join(f'{r:.8f}' for r in results)}]\")\n\ndef compute_variance_ratios(params, kappa):\n    \"\"\"\n    Computes the variance ratios for a single test case.\n    \n    Args:\n        params (dict): A dictionary of parameters for the test case.\n        kappa (float): The scaling constant for MAD.\n        \n    Returns:\n        tuple: A tuple containing (R_median, R_mad).\n    \"\"\"\n    T = params['T']\n    W = params['W']\n    c = params['c']\n    eta = params['eta']\n    b = params['b']\n    a = params['a']\n    P = params['P']\n    outliers = params['outliers']\n\n    # 1. Generate the sequence of raw gradient norms {r_t}\n    t_steps = np.arange(1, T + 1)\n    r_sequence = b + a * np.sin(2 * np.pi * t_steps / P)\n    for t, val in outliers.items():\n        # Problem uses 1-based indexing for time steps\n        if 1 <= t <= T:\n            r_sequence[t - 1] = val\n\n    u_mean = np.zeros(T)\n    u_median = np.zeros(T)\n    u_mad = np.zeros(T)\n\n    # 2. Iterate through time steps to compute thresholds and clipped norms\n    for t_idx in range(T):\n        t = t_idx + 1\n        r_t = r_sequence[t_idx]\n\n        if t == 1:\n            # Special case for t=1\n            tau_t_mean = c * r_t\n            tau_t_median = c * r_t\n            tau_t_mad = c * r_t\n        else:\n            # For t > 1, use trailing window\n            win_size = min(W, t - 1)\n            window = r_sequence[t_idx - win_size : t_idx]\n            \n            # Compute statistics\n            mu_t = np.mean(window)\n            m_t = np.median(window)\n            mad_t = np.median(np.abs(window - m_t))\n\n            # Compute thresholds for the three rules\n            tau_t_mean = c * mu_t\n            tau_t_median = c * m_t\n            tau_t_mad = c * (m_t + kappa * mad_t)\n        \n        # 3. Compute clipped step norms\n        u_mean[t_idx] = eta * min(r_t, tau_t_mean)\n        u_median[t_idx] = eta * min(r_t, tau_t_median)\n        u_mad[t_idx] = eta * min(r_t, tau_t_mad)\n\n    # 4. Compute population variances\n    # np.var computes population variance by default (ddof=0)\n    var_mean = np.var(u_mean)\n    var_median = np.var(u_median)\n    var_mad = np.var(u_mad)\n    \n    # Handle case where denominator is zero to avoid NaN\n    if var_mean == 0:\n        # This implies all step norms were identical, so others should be too.\n        # Ratios are 1 if variances are equal, or NaN if they differ.\n        # Safe to assume 1.0 in this context.\n        r_median = 1.0 if var_median == 0 else np.nan\n        r_mad = 1.0 if var_mad == 0 else np.nan\n    else:\n        r_median = var_median / var_mean\n        r_mad = var_mad / var_mean\n\n    return r_median, r_mad\n\nsolve()\n```", "id": "3131435"}, {"introduction": "The principle of adding a penalty to control a system's behavior is a powerful and recurrent theme in machine learning. While gradient clipping penalizes large gradient norms to ensure dynamic stability, a similar idea is used in statistical learning to control model complexity and prevent overfitting. This exercise [@problem_id:3143737] explores this parallel by examining Mallows' $C_p$ and the Generalized Information Criterion (GIC) for model selection in linear regression. You will experimentally see how a penalty on the number of parameters helps balance model fit with model simplicity, reinforcing the general concept of regularization that is central to both classical statistics and modern deep learning.", "problem": "Consider the standard linear regression setup with response $y \\in \\mathbb{R}^n$ and design matrix $X \\in \\mathbb{R}^{n \\times d}$, where the data are generated according to $y = X \\beta + \\varepsilon$, $\\varepsilon \\sim \\mathcal{N}(0, \\sigma^2 I_n)$. Ordinary Least Squares (OLS) provides coefficient estimates for any nested model that includes the intercept and the first $p-1$ features (so each candidate model has $p$ parameters, counting the intercept). Residual Sum of Squares (RSS) is used to quantify in-sample error. Generalized Information Criterion (GIC) is an information criterion defined with a penalty proportional to the number of parameters, and Mallows' $C_p$ is a classical criterion derived to yield an unbiased estimate of out-of-sample prediction error.\n\nYour task is to connect Mallows' $C_p$ to Generalized Information Criterion (GIC) with penalty $c\\,p$ by controlled experiments. Specifically, you will vary the penalty multiplier $c$ in GIC to mimic under- and over-penalization, and you will vary the scale of the external noise variance estimator used inside Mallows' $C_p$ to observe analogous behavior. You must demonstrate the mapping between changing $c$ in GIC and changing the scale factor in $\\hat{\\sigma}^2$ for Mallows' $C_p$.\n\nYou must follow the fundamental base:\n- Assume the linear model $y = X \\beta + \\varepsilon$ and the properties of Ordinary Least Squares (OLS), including unbiasedness in correctly specified models and the relationship between model complexity and degrees of freedom.\n- Use Residual Sum of Squares (RSS) to quantify fit quality and the unbiased estimator of the noise variance from the full model.\n\nProgram specification:\n1. Synthesize data deterministically as follows:\n   - Use a fixed random seed, $42$.\n   - Let $n = 150$ observations and $d = 10$ features.\n   - Draw $X_{\\text{feat}} \\in \\mathbb{R}^{n \\times d}$ with entries independently from $\\mathcal{N}(0,1)$.\n   - Form the augmented design $X = [\\mathbf{1}_n, X_{\\text{feat}}]$, where $\\mathbf{1}_n$ is the $n$-vector of ones (intercept column). Thus $X \\in \\mathbb{R}^{n \\times (d+1)}$.\n   - Set the true coefficient vector $\\beta \\in \\mathbb{R}^{d+1}$ to have $\\beta_0 = 0$ (intercept), $\\beta_1 = 3.0$, $\\beta_2 = -2.0$, $\\beta_3 = 1.0$, $\\beta_4 = 0.5$, and all remaining entries equal to $0$.\n   - Let the true noise standard deviation be $\\sigma_{\\text{true}} = 1.0$, i.e., $\\varepsilon \\sim \\mathcal{N}(0, 1.0^2 I_n)$, and generate $y = X \\beta + \\varepsilon$.\n2. For each nested model size $p \\in \\{1, 2, \\dots, d+1\\}$, where $p$ counts the intercept and the first $p-1$ features, compute the OLS fit and the corresponding residual sum of squares $\\text{RSS}(p)$.\n3. Estimate the noise variance from the full model ($p = d+1$) using the unbiased estimator $\\hat{\\sigma}^2 = \\text{RSS}(d+1) / (n - (d+1))$.\n4. Define Generalized Information Criterion (GIC) with penalty parameter $c$ as a criterion that, for model size $p$, adds a term proportional to $c\\,p$ to the in-sample fit term. You must implement model selection under GIC by minimizing a criterion of the form that uses $\\text{RSS}(p)$ and $\\hat{\\sigma}^2$ and includes the penalty $c\\,p$.\n5. Implement model selection under Mallows' $C_p$ using the canonical definition derived from first principles (provide the derivation in the solution). Use a scaled external noise variance estimate $\\hat{\\sigma}^2_k = k \\cdot \\hat{\\sigma}^2$, where $k$ is a positive scale factor.\n6. For each test case below, compute:\n   - The selected model size under GIC, denoted $p_{\\text{GIC}}(c)$.\n   - The selected model size under Mallows' $C_p$ with scaled variance $\\hat{\\sigma}^2_k$, denoted $p_{C_p}(k)$.\n   - Report the integer difference $p_{\\text{GIC}}(c) - p_{C_p}(k)$.\n\nTest suite:\nUse the following set of $(c, k)$ pairs, designed to test matched and mismatched mappings, happy path, and boundary conditions:\n- Case $1$: $(c, k) = (2.0, 1.0)$.\n- Case $2$: $(c, k) = (3.0, 1.5)$.\n- Case $3$: $(c, k) = (1.0, 1.0)$.\n- Case $4$: $(c, k) = (4.0, 1.0)$.\n- Case $5$: $(c, k) = (2.0, 0.5)$.\n- Case $6$: $(c, k) = (0.0, 1.0)$.\n- Case $7$: $(c, k) = (8.0, 1.0)$.\n- Case $8$: $(c, k) = (2.0, 1.25)$.\n\nFinal output format:\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (e.g., \"[r_1,r_2,\\dots,r_8]\"), where $r_i$ is the integer $p_{\\text{GIC}}(c_i) - p_{C_p}(k_i)$ for the $i$-th test case in the order given above. No other text should be printed.", "solution": "The problem requires an investigation into the relationship between two model selection criteria in the context of linear regression: the Generalized Information Criterion (GIC) and Mallows' $C_p$. We will establish their theoretical connection and then verify it computationally using a deterministically generated dataset.\n\nThe setting is a standard linear model $y = X \\beta + \\varepsilon$, where $y \\in \\mathbb{R}^n$ is the response vector, $X \\in \\mathbb{R}^{n \\times (d+1)}$ is the design matrix (including an intercept), $\\beta \\in \\mathbb{R}^{d+1}$ is the vector of true coefficients, and $\\varepsilon \\sim \\mathcal{N}(0, \\sigma^2 I_n)$ is a vector of i.i.d. Gaussian noise.\n\nWe consider a set of nested candidate models, where the $p$-th model uses the first $p$ columns of the design matrix $X$. For each candidate model, we can compute the Ordinary Least Squares (OLS) fit and its corresponding Residual Sum of Squares, denoted $\\text{RSS}(p)$. A good model selection criterion balances the in-sample fit (low $\\text{RSS}(p)$) with model complexity (low $p$).\n\nFirst, let us formalize the Mallows' $C_p$ criterion. Mallows' $C_p$ is designed to be an unbiased estimate of the true mean squared prediction error, scaled by the noise variance $\\sigma^2$. For a model with $p$ parameters, the statistic is defined as:\n$$ C_p = \\frac{\\text{RSS}(p)}{\\hat{\\sigma}^2} + 2p - n $$\nHere, $\\hat{\\sigma}^2$ is an unbiased estimate of the true error variance $\\sigma^2$. A common choice, and the one specified in the problem, is the estimator from the full model (which is assumed to be unbiased):\n$$ \\hat{\\sigma}^2 = \\frac{\\text{RSS}(d+1)}{n - (d+1)} $$\nSince $n$ is a constant for all models, selecting a model by minimizing $C_p$ is equivalent to minimizing the quantity $\\frac{\\text{RSS}(p)}{\\hat{\\sigma}^2} + 2p$.\n\nThe problem introduces a variant of Mallows' $C_p$ that uses a scaled variance estimate $\\hat{\\sigma}^2_k = k \\cdot \\hat{\\sigma}^2$ for some positive scale factor $k$. The criterion to minimize becomes:\n$$ \\min_{p} \\left( \\frac{\\text{RSS}(p)}{k \\hat{\\sigma}^2} + 2p \\right) $$\nSince $k$ and $\\hat{\\sigma}^2$ are positive constants with respect to the minimization over $p$, we can multiply the objective function by $k \\hat{\\sigma}^2$ without changing the location of the minimum. This yields an equivalent minimization problem:\n$$ \\min_{p} \\left( \\text{RSS}(p) + (2k) \\cdot p \\cdot \\hat{\\sigma}^2 \\right) $$\nThis form expresses the criterion as a sum of the in-sample error ($\\text{RSS}(p)$) and a penalty term that is linear in the number of parameters $p$.\n\nNext, we formalize the Generalized Information Criterion (GIC). GIC represents a family of criteria that take the form of a goodness-of-fit term plus a penalty on model complexity. The problem specifies a penalty proportional to $c \\cdot p$. To make a direct comparison with the Mallows' $C_p$ formulation derived above, we define the GIC score to be minimized as:\n$$ \\text{GIC\\_Score}(p) = \\text{RSS}(p) + c \\cdot p \\cdot \\hat{\\sigma}^2 $$\nThis is a valid instance of a GIC, where the penalty for each additional parameter is $c \\cdot \\hat{\\sigma}^2$. The model selected by this criterion, $p_{\\text{GIC}}(c)$, is the one that minimizes this score.\n\nBy comparing the objective functions for the scaled Mallows' $C_p$ and our GIC formulation, we can establish a direct mapping.\n$$ \\text{Scaled } C_p \\text{ objective: } \\quad \\text{RSS}(p) + (2k) \\cdot p \\cdot \\hat{\\sigma}^2 $$\n$$ \\text{GIC objective: } \\quad \\text{RSS}(p) + c \\cdot p \\cdot \\hat{\\sigma}^2 $$\nThe two criteria are mathematically identical if and only if the penalty multipliers are equal, which means:\n$$ c = 2k $$\nTherefore, we predict that the model selected by GIC with penalty multiplier $c$ will be the same as the model selected by Mallows' $C_p$ with variance scaling factor $k$, provided that $c = 2k$. In this case, $p_{\\text{GIC}}(c) - p_{C_p}(k) = 0$.\n- If $c > 2k$, the GIC imposes a stronger penalty on complexity than the corresponding scaled $C_p$, which will favor models with fewer parameters. We expect $p_{\\text{GIC}}(c) \\le p_{C_p}(k)$.\n- If $c < 2k$, the GIC imposes a weaker penalty, favoring more complex models. We expect $p_{\\text{GIC}}(c) \\ge p_{C_p}(k)$.\n\nThe computational procedure is as follows:\n1.  Set the random seed to $42$ for reproducibility. Generate the data according to the problem specification: $n=150$ observations, $d=10$ features, a specified true coefficient vector $\\beta$, and Gaussian noise with $\\sigma_{\\text{true}}=1.0$.\n2.  For each nested model size $p$ from $1$ to $d+1=11$, fit the corresponding OLS model using the first $p$ columns of the design matrix $X$.\n3.  Store the resulting $\\text{RSS}(p)$ for each $p$.\n4.  Calculate the unbiased noise variance estimate $\\hat{\\sigma}^2$ using the $\\text{RSS}$ from the full model ($p=11$).\n5.  For each $(c, k)$ pair in the test suite:\n    a. Compute the GIC score for all $p \\in \\{1, \\dots, 11\\}$: $\\text{GIC\\_Score}(p) = \\text{RSS}(p) + c \\cdot p \\cdot \\hat{\\sigma}^2$.\n    b. Find the optimal model size $p_{\\text{GIC}}(c) = \\arg\\min_{p} \\text{GIC\\_Score}(p)$.\n    c. Compute the equivalent Mallows' $C_p$ score for all $p \\in \\{1, \\dots, 11\\}$: $\\text{C}_p\\text{\\_Score}(p) = \\text{RSS}(p) + 2k \\cdot p \\cdot \\hat{\\sigma}^2$.\n    d. Find the optimal model size $p_{C_p}(k) = \\arg\\min_{p} \\text{C}_p\\text{\\_Score}(p)$.\n    e. Calculate and store the integer difference $p_{\\text{GIC}}(c) - p_{C_p}(k)$.\n6.  The final output is a list of these differences.\n\nThis procedure will numerically demonstrate the equivalence when $c=2k$ and the under/over-penalization effects when the condition does not hold.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the model selection problem by comparing GIC and Mallows' Cp.\n    \"\"\"\n    # 1. Synthesize data deterministically as specified.\n    seed = 42\n    n = 150\n    d = 10\n    \n    rng = np.random.default_rng(seed)\n\n    # Draw features from N(0,1)\n    X_feat = rng.normal(loc=0.0, scale=1.0, size=(n, d))\n    \n    # Form the augmented design matrix X with an intercept column.\n    X = np.hstack((np.ones((n, 1)), X_feat))\n\n    # Set the true coefficient vector beta.\n    beta_true = np.zeros(d + 1)\n    beta_true[0] = 0.0  # Intercept\n    beta_true[1] = 3.0\n    beta_true[2] = -2.0\n    beta_true[3] = 1.0\n    beta_true[4] = 0.5\n    # beta_true[5:] are implicitly 0.0\n\n    # Generate the response variable y.\n    sigma_true = 1.0\n    epsilon = rng.normal(loc=0.0, scale=sigma_true, size=n)\n    y = X @ beta_true + epsilon\n\n    # 2. For each nested model size p, compute RSS(p).\n    p_values = np.arange(1, d + 2)  # Model sizes from 1 to d+1 (11)\n    rss_values = []\n    \n    for p in p_values:\n        X_p = X[:, :p]\n        # Use np.linalg.lstsq to perform OLS.\n        # It returns a tuple, where the second element is the sum of squared residuals (RSS).\n        # The returned residuals is a 1-element array, so we extract the value with [0].\n        # If the model fits perfectly, residuals is an empty array.\n        res = np.linalg.lstsq(X_p, y, rcond=None)[1]\n        \n        if res.size > 0:\n            rss_values.append(res[0])\n        else:\n            # This case occurs for a perfect fit, RSS = 0.\n            rss_values.append(0.0)\n            \n    rss_values = np.array(rss_values)\n\n    # 3. Estimate the noise variance from the full model.\n    rss_full = rss_values[-1]\n    degrees_of_freedom_full = n - (d + 1)\n    sigma_hat_sq = rss_full / degrees_of_freedom_full\n\n    # Test suite of (c, k) pairs.\n    test_cases = [\n        (2.0, 1.0),\n        (3.0, 1.5),\n        (1.0, 1.0),\n        (4.0, 1.0),\n        (2.0, 0.5),\n        (0.0, 1.0),\n        (8.0, 1.0),\n        (2.0, 1.25),\n    ]\n\n    results = []\n    for c, k in test_cases:\n        # 4. Compute selected model size under GIC.\n        # The criterion to minimize is RSS(p) + c * p * sigma_hat^2.\n        gic_scores = rss_values + c * p_values * sigma_hat_sq\n        # Find the model size p that minimizes the score.\n        # np.argmin returns the 0-based index of the minimum.\n        p_gic = p_values[np.argmin(gic_scores)]\n\n        # 5. Compute selected model size under scaled Mallows' Cp.\n        # The criterion is RSS(p)/(k*sigma_hat^2) + 2p, which is equivalent to\n        # minimizing RSS(p) + 2k * p * sigma_hat^2.\n        cp_scores = rss_values + 2 * k * p_values * sigma_hat_sq\n        p_cp = p_values[np.argmin(cp_scores)]\n\n        # 6. Compute and store the difference.\n        difference = p_gic - p_cp\n        results.append(int(difference))\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "3143737"}]}