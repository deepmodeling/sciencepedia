{"hands_on_practices": [{"introduction": "To truly grasp the Nesterov Accelerated Gradient (NAG) algorithm, we must start with its core innovation: the \"look-ahead\" step. Unlike other momentum methods, NAG calculates the gradient not at the current position, but at a projected future point based on its accumulated momentum. This exercise [@problem_id:2187811] provides a concrete, step-by-step calculation of this look-ahead point for a simple quadratic function, making the central mechanism of NAG tangible and building a solid foundation for more complex applications.", "problem": "An engineer is applying the Nesterov Accelerated Gradient (NAG) algorithm to minimize a one-dimensional objective function. The function is given by $f(x) = 2x^2$. The algorithm iteratively updates a position parameter $x$ and a velocity term $v$ according to the following set of rules, starting from an initial position $x_0$ and an initial velocity $v_0=0$:\n$$ v_{t} = \\gamma v_{t-1} + \\eta \\nabla f(x_{t-1} - \\gamma v_{t-1}) $$\n$$ x_{t} = x_{t-1} - v_{t} $$\nIn these equations, a subscript denotes the iteration number, so $t=1, 2, 3, \\ldots$. The constant $\\gamma$ is the momentum parameter, $\\eta$ is the learning rate, and $\\nabla f$ is the gradient of the function $f(x)$. The evaluation of the gradient occurs at the \"look-ahead\" point, given by the term $x_{t-1} - \\gamma v_{t-1}$.\n\nFor an initial position of $x_0 = 10$, a momentum parameter of $\\gamma = 0.9$, and a learning rate of $\\eta = 0.1$, calculate the numerical value of the look-ahead point that is used during the second iteration of the algorithm (i.e., for $t=2$).", "solution": "We are given the Nesterov Accelerated Gradient updates:\n$$v_{t}=\\gamma v_{t-1}+\\eta \\nabla f\\!\\left(x_{t-1}-\\gamma v_{t-1}\\right), \\quad x_{t}=x_{t-1}-v_{t}.$$\nThe objective is $f(x)=2x^{2}$, so its gradient is\n$$\\nabla f(x)=\\frac{d}{dx}(2x^{2})=4x.$$\n\nGiven $x_{0}=10$, $v_{0}=0$, $\\gamma=0.9$, and $\\eta=0.1$, first compute the look-ahead point for $t=1$:\n$$x_{0}-\\gamma v_{0}=10-0.9\\cdot 0=10.$$\nThen update the velocity at $t=1$:\n$$v_{1}=\\gamma v_{0}+\\eta \\nabla f(10)=0.9\\cdot 0+0.1\\cdot 4\\cdot 10=4.$$\nUpdate the position:\n$$x_{1}=x_{0}-v_{1}=10-4=6.$$\n\nFor the second iteration ($t=2$), the look-ahead point is\n$$x_{1}-\\gamma v_{1}=6-0.9\\cdot 4=6-3.6=2.4.$$\nTherefore, the numerical value of the look-ahead point used during the second iteration is $2.4$.", "answer": "$$\\boxed{2.4}$$", "id": "2187811"}, {"introduction": "With a grasp of the look-ahead concept, the next logical step is to compare NAG's performance against its predecessor, the classical momentum method (also known as the \"heavy-ball\" method). This practice [@problem_id:3279039] challenges you to implement both algorithms from first principles and observe their behavior on a convex quadratic objective. By coding them yourself, you will gain a robust, practical understanding of their structural differences and see firsthand how NAG's \"smarter\" update rule can lead to faster and more stable convergence.", "problem": "You are asked to implement and compare two first-order optimization algorithms within the framework of steepest descent for convex quadratic functions: classical momentum (also called the heavy-ball method) and Nesterov Accelerated Gradient (NAG). The concept to probe is the \"look-ahead\" behavior of Nesterov Accelerated Gradient. Your goal is to design and implement both algorithms from the fundamental definitions of steepest descent and gradient evaluation in smooth convex optimization, quantify the \"look-ahead\" effect numerically, and aggregate the results over a small test suite.\n\nStart from the following fundamental base:\n- Let $f:\\mathbb{R}^{2}\\rightarrow\\mathbb{R}$ be differentiable with gradient $\\nabla f$. The steepest descent direction at $x$ is the direction $- \\nabla f(x)$.\n- A fixed step size $ \\alpha > 0 $ is a positive scalar that scales the step taken along a chosen descent direction.\n- Classical momentum augments steepest descent with an auxiliary \"velocity\" variable that accumulates past updates to accelerate motion along persistent directions, while Nesterov Accelerated Gradient evaluates the gradient at a point that is displaced along the current momentum direction before forming the update. In Nesterov Accelerated Gradient, the gradient is evaluated at a \"look-ahead\" point that depends on the current position and momentum; this is the key behavioral difference to quantify.\n\nWork with the purely quadratic objective\n$$\nf(x) = \\tfrac{1}{2} x^{\\top} A x,\n$$\nwhere $A \\in \\mathbb{R}^{2\\times 2}$ is symmetric positive definite, so that\n$$\n\\nabla f(x) = A x,\n$$\nand the unique minimizer is $x^{\\star} = 0$.\n\nImplement both methods for this objective. Use a fixed step size $\\alpha$ and a fixed momentum coefficient $\\beta \\in [0,1)$, initialize the velocity to zero, and iterate for a prescribed number of steps $T$. For classical momentum, the gradient must be evaluated at the current iterate. For Nesterov Accelerated Gradient, the gradient must be evaluated at a \"look-ahead\" point that is an explicit displacement from the current iterate along the current velocity. You must also compute a numerical surrogate that \"visualizes\" the look-ahead behavior without plotting: at each iteration $k$, compute the norm of the displacement between the look-ahead point and the current iterate, and report the average of these norms over the iterations. This surrogate measures how far Nesterov Accelerated Gradient \"looks ahead\" on average.\n\nYour program must implement both algorithms and, for each test case below, compute and return the specified quantity. Use Euclidean norm for all vector norms.\n\nTest suite:\n- Test case $1$ (ill-conditioned, happy path): Let\n  $$\n  A = \\begin{bmatrix} 10 & 0 \\\\ 0 & 1 \\end{bmatrix}, \\quad x_0 = \\begin{bmatrix} 3 \\\\ -1 \\end{bmatrix}, \\quad \\alpha = 0.1, \\quad \\beta = 0.9, \\quad T = 50.\n  $$\n  Run both methods for $T$ steps from $x_0$ with zero initial velocity. Output a boolean indicating whether the final objective value of Nesterov Accelerated Gradient is strictly smaller than that of classical momentum, that is, whether $f(x_T^{\\mathrm{NAG}}) < f(x_T^{\\mathrm{HB}})$.\n\n- Test case $2$ (boundary condition $\\beta = 0$): Let\n  $$\n  A = \\begin{bmatrix} 4 & 1 \\\\ 1 & 3 \\end{bmatrix}, \\quad x_0 = \\begin{bmatrix} 2 \\\\ 2 \\end{bmatrix}, \\quad \\alpha = 0.2, \\quad \\beta = 0, \\quad T = 30.\n  $$\n  Run both methods. Output a boolean indicating whether the final iterates coincide to within a numerical tolerance, that is, whether $\\lVert x_T^{\\mathrm{NAG}} - x_T^{\\mathrm{HB}} \\rVert_2 < 10^{-12}$.\n\n- Test case $3$ (stationary start): Let\n  $$\n  A = \\begin{bmatrix} 4 & 1 \\\\ 1 & 3 \\end{bmatrix}, \\quad x_0 = \\begin{bmatrix} 0 \\\\ 0 \\end{bmatrix}, \\quad \\alpha = 0.2, \\quad \\beta = 0.9, \\quad T = 10.\n  $$\n  Run both methods. Output a boolean indicating whether the final Nesterov Accelerated Gradient iterate remains at the minimizer to within a numerical tolerance, that is, whether $\\lVert x_T^{\\mathrm{NAG}} \\rVert_2 < 10^{-12}$.\n\n- Test case $4$ (quantified look-ahead magnitude): Let\n  $$\n  A = \\begin{bmatrix} 4 & 1 \\\\ 1 & 3 \\end{bmatrix}, \\quad x_0 = \\begin{bmatrix} 1 \\\\ -3 \\end{bmatrix}, \\quad \\alpha = 0.2, \\quad \\beta = 0.9, \\quad T = 20.\n  $$\n  For Nesterov Accelerated Gradient only, compute the average norm of the look-ahead displacement over the $T$ iterations:\n  $$\n  \\frac{1}{T} \\sum_{k=0}^{T-1} \\left\\lVert y_k - x_k \\right\\rVert_2,\n  $$\n  where $y_k$ is the look-ahead point at iteration $k$ and $x_k$ is the current iterate at iteration $k$. Output this average as a floating-point number.\n\nFinal output specification:\n- Your program must produce a single line containing the results for the test cases as a comma-separated list enclosed in square brackets. The entries, in order, must be:\n  $1)$ the boolean for test case $1$, $2)$ the boolean for test case $2$, $3)$ the boolean for test case $3$, $4)$ the floating-point value for test case $4$.\n- For example, the required format is\n  $$\n  [\\text{result}_1,\\text{result}_2,\\text{result}_3,\\text{result}_4].\n  $$\nNo plotting or file input/output is required or permitted; all computations must be numerical and self-contained. Angles are not involved. No physical units are involved. All results must be computed in floating-point arithmetic with double precision.", "solution": "The problem requires the implementation and comparison of two first-order optimization algorithms, Classical Momentum (Heavy-Ball) and Nesterov Accelerated Gradient (NAG), for minimizing a convex quadratic function. The objective is to quantify the \"look-ahead\" characteristic of NAG.\n\nThe objective function to be minimized is a convex quadratic form $f:\\mathbb{R}^{2}\\rightarrow\\mathbb{R}$ given by:\n$$\nf(x) = \\frac{1}{2} x^{\\top} A x\n$$\nwhere $x \\in \\mathbb{R}^2$ is the variable vector and $A \\in \\mathbb{R}^{2\\times 2}$ is a symmetric positive definite matrix. The gradient of this function is linear:\n$$\n\\nabla f(x) = A x\n$$\nGiven that $A$ is positive definite, the function $f(x)$ is strictly convex and has a unique minimizer at $x^{\\star} = 0$.\n\nBoth algorithms are iterative methods that start from an initial point $x_0$ and generate a sequence of iterates $\\{x_k\\}$ that converge to the minimizer $x^{\\star}$. They use a fixed step size $\\alpha > 0$ and a momentum coefficient $\\beta \\in [0,1)$. The initial velocity, a variable that accumulates past updates, is set to zero, i.e., $v_0 = 0$.\n\nThe core logic of both algorithms revolves around the following update structure for iteration $k=0, 1, 2, \\dots, T-1$:\n$1$. A gradient direction is computed.\n$2$. The velocity variable $v_k$ is updated to $v_{k+1}$.\n$3$. The position variable $x_k$ is updated to $x_{k+1}$.\n\nThe distinction between the two algorithms lies in step $1$, specifically at which point the gradient is evaluated.\n\n**Classical Momentum (Heavy-Ball Method)**\n\nIn the Heavy-Ball method, the gradient is evaluated at the current position $x_k$. The update rules for iteration $k$ are:\n$1$. Compute the gradient: $g_k = \\nabla f(x_k) = A x_k$.\n$2$. Update the velocity: $v_{k+1} = \\beta v_k - \\alpha g_k$.\n$3$. Update the position: $x_{k+1} = x_k + v_{k+1}$.\nThe process starts with $x_0$ and $v_0 = 0$.\n\n**Nesterov Accelerated Gradient (NAG)**\n\nNAG introduces a \"look-ahead\" step. Before computing the gradient, it makes a preliminary step in the direction of the current velocity. The gradient is then evaluated at this projected point, providing a correction to the momentum update.\nThe update rules for iteration $k$ are:\n$1$. Define the look-ahead point: $y_k = x_k + \\beta v_k$.\n$2$. Compute the gradient at the look-ahead point: $g_k = \\nabla f(y_k) = A y_k$.\n$3$. Update the velocity: $v_{k+1} = \\beta v_k - \\alpha g_k$.\n$4$. Update the position: $x_{k+1} = x_k + v_{k+1}$.\nThe process also starts with $x_0$ and $v_0 = 0$.\n\n**Analysis of Special Cases**\n\n- **Case $\\beta=0$**: If the momentum coefficient $\\beta$ is zero, the velocity update in both algorithms loses its dependence on the previous velocity $v_k$.\nFor HB: $v_{k+1} = -\\alpha \\nabla f(x_k)$, so $x_{k+1} = x_k - \\alpha \\nabla f(x_k)$.\nFor NAG: The look-ahead point becomes $y_k = x_k + 0 \\cdot v_k = x_k$. The velocity update is $v_{k+1} = -\\alpha \\nabla f(x_k)$, and thus $x_{k+1} = x_k - \\alpha \\nabla f(x_k)$.\nBoth algorithms reduce to the standard gradient descent method. Their trajectories $\\{x_k\\}$ will be identical. Test Case $2$ verifies this property.\n\n- **Case $x_0=x^{\\star}=0$**: If the starting point is the minimizer, the gradient is zero: $\\nabla f(0) = A \\cdot 0 = 0$.\nFor both HB and NAG, with $x_0=0$ and $v_0=0$, the first iteration yields:\n$g_0 = 0$, which leads to $v_1 = 0$ and subsequently $x_1 = 0$.\nBy induction, the iterates will remain at the minimizer for all $k > 0$, i.e., $x_k=0$ and $v_k=0$. Test Case $3$ verifies this stationary behavior.\n\n**Quantifying the Look-Ahead Effect**\n\nThe \"look-ahead\" behavior of NAG is characterized by the displacement vector $y_k - x_k = \\beta v_k$. To quantify this effect numerically, we compute the average Euclidean norm of this displacement over $T$ iterations. This surrogate measure is defined as:\n$$\n\\text{Average Look-ahead} = \\frac{1}{T} \\sum_{k=0}^{T-1} \\left\\lVert y_k - x_k \\right\\rVert_2 = \\frac{1}{T} \\sum_{k=0}^{T-1} \\left\\lVert \\beta v_k \\right\\rVert_2\n$$\nTest Case $4$ requires the computation of this value.\n\nThe solution proceeds by implementing these two algorithms and running them on the $4$ specified test cases, computing the required result for each. All vector norms are Euclidean norms ($\\ell_2$-norm), and floating-point arithmetic is performed with double precision.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Implements and compares Classical Momentum (Heavy-Ball) and Nesterov\n    Accelerated Gradient (NAG) on a set of test cases.\n    \"\"\"\n\n    def heavy_ball(A, x0, alpha, beta, T):\n        \"\"\"\n        Implements the Heavy-Ball (Classical Momentum) algorithm.\n\n        Args:\n            A (np.ndarray): The matrix of the quadratic objective.\n            x0 (np.ndarray): The starting point.\n            alpha (float): The step size.\n            beta (float): The momentum coefficient.\n            T (int): The number of iterations.\n\n        Returns:\n            np.ndarray: The final iterate x_T.\n        \"\"\"\n        x = np.copy(x0).astype(np.float64)\n        v = np.zeros_like(x0, dtype=np.float64)\n\n        for _ in range(T):\n            g = A @ x\n            v = beta * v - alpha * g\n            x = x + v\n        return x\n\n    def nesterov_ag(A, x0, alpha, beta, T, compute_lookahead=False):\n        \"\"\"\n        Implements the Nesterov Accelerated Gradient (NAG) algorithm.\n\n        Args:\n            A (np.ndarray): The matrix of the quadratic objective.\n            x0 (np.ndarray): The starting point.\n            alpha (float): The step size.\n            beta (float): The momentum coefficient.\n            T (int): The number of iterations.\n            compute_lookahead (bool): If True, also computes and returns the\n                                      average look-ahead displacement norm.\n        Returns:\n            np.ndarray or tuple: The final iterate x_T. If compute_lookahead is\n                                 True, returns (x_T, avg_lookahead_norm).\n        \"\"\"\n        x = np.copy(x0).astype(np.float64)\n        v = np.zeros_like(x0, dtype=np.float64)\n        \n        if compute_lookahead:\n            lookahead_norms = []\n\n        for _ in range(T):\n            if compute_lookahead:\n                # Displacement at step k is beta * v_k\n                lookahead_norms.append(np.linalg.norm(beta * v))\n            \n            # Look-ahead point and gradient calculation\n            y = x + beta * v\n            g = A @ y\n\n            # Update velocity and position\n            v = beta * v - alpha * g\n            x = x + v\n\n        if compute_lookahead:\n            avg_lookahead_norm = np.mean(lookahead_norms) if lookahead_norms else 0.0\n            return x, avg_lookahead_norm\n        else:\n            return x\n\n    def objective_function(x, A):\n        \"\"\"Computes f(x) = 0.5 * x.T @ A @ x.\"\"\"\n        return 0.5 * x.T @ A @ x\n\n    results = []\n\n    # Test Case 1: Ill-conditioned, comparison of objective values\n    A1 = np.array([[10, 0], [0, 1]], dtype=np.float64)\n    x0_1 = np.array([3, -1], dtype=np.float64)\n    alpha1, beta1, T1 = 0.1, 0.9, 50\n    \n    xT_hb_1 = heavy_ball(A1, x0_1, alpha1, beta1, T1)\n    xT_nag_1 = nesterov_ag(A1, x0_1, alpha1, beta1, T1)\n    \n    f_hb_1 = objective_function(xT_hb_1, A1)\n    f_nag_1 = objective_function(xT_nag_1, A1)\n    \n    results.append(f_nag_1  f_hb_1)\n\n    # Test Case 2: Boundary condition beta = 0\n    A2 = np.array([[4, 1], [1, 3]], dtype=np.float64)\n    x0_2 = np.array([2, 2], dtype=np.float64)\n    alpha2, beta2, T2 = 0.2, 0.0, 30\n\n    xT_hb_2 = heavy_ball(A2, x0_2, alpha2, beta2, T2)\n    xT_nag_2 = nesterov_ag(A2, x0_2, alpha2, beta2, T2)\n\n    diff_norm_2 = np.linalg.norm(xT_nag_2 - xT_hb_2)\n    results.append(diff_norm_2  1e-12)\n\n    # Test Case 3: Stationary start\n    A3 = np.array([[4, 1], [1, 3]], dtype=np.float64)\n    x0_3 = np.array([0, 0], dtype=np.float64)\n    alpha3, beta3, T3 = 0.2, 0.9, 10\n\n    xT_nag_3 = nesterov_ag(A3, x0_3, alpha3, beta3, T3)\n    norm_nag_3 = np.linalg.norm(xT_nag_3)\n    results.append(norm_nag_3  1e-12)\n\n    # Test Case 4: Quantified look-ahead magnitude\n    A4 = np.array([[4, 1], [1, 3]], dtype=np.float64)\n    x0_4 = np.array([1, -3], dtype=np.float64)\n    alpha4, beta4, T4 = 0.2, 0.9, 20\n\n    _, avg_lookahead_4 = nesterov_ag(A4, x0_4, alpha4, beta4, T4, compute_lookahead=True)\n    results.append(avg_lookahead_4)\n\n    # Format and print the final output\n    # The map(str, ...) part handles converting booleans to 'True'/'False'\n    # and floats to their string representation.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "3279039"}, {"introduction": "Now that we understand what makes NAG unique, let's explore one of its most celebrated practical benefits: its ability to navigate challenging, non-convex loss landscapes. Standard gradient descent can get trapped in oscillations when descending steep valleys, but NAG's look-ahead feature acts as a corrective brake, allowing it to \"see\" a steepening slope ahead and slow down. In this hands-on coding challenge [@problem_id:3157033], you will build a synthetic loss function with oscillatory curvature and quantitatively measure how effectively NAG dampens these oscillations compared to a baseline gradient descent approach.", "problem": "You are tasked with designing and analyzing a one-dimensional synthetic loss function with oscillatory curvature, then implementing two optimization methods to study their behavior. The synthetic loss is defined for a scalar variable $x \\in \\mathbb{R}$ by the function\n$$\nf(x) = \\sum_{i=1}^{n} a_i \\sin(b_i x),\n$$\nwhere $a_i \\in \\mathbb{R}$ and $b_i \\in \\mathbb{R}$ are given coefficients, and the sine function is evaluated using angles in radians. The goal is to assess the ability of Nesterov Accelerated Gradient (NAG) to stabilize oscillatory behavior compared to Stochastic Gradient Descent (SGD).\n\nYour program must implement from first principles the following components using only mathematically grounded definitions:\n- A differentiable objective $f(x)$ and its gradient $\\nabla f(x)$ derived using the rule for differentiating the sine function with respect to $x$.\n- An iterative optimization procedure that updates the variable $x$ over a fixed number of iterations $T$, starting from an initial condition $x_0$.\n- Two optimizers to compare:\n  1. A baseline gradient descent method that uses the current gradient at $x_t$ and a positive learning rate $\\eta$ to produce the next $x$.\n  2. A momentum-based method that uses a velocity vector and evaluates the gradient at a lookahead position to produce the next $x$. This method must be consistent with the definition of Nesterov Accelerated Gradient and must reduce to the baseline method when the momentum parameter $\\mu$ is set to $0$.\n\nDefine the oscillation score for an optimization trajectory as the number of sign changes in consecutive step increments, where each increment is $s_t = x_{t+1} - x_t$ for iteration index $t$. A sign change occurs when two successive nonzero increments have opposite signs. Zeros must be ignored when deciding sign changes. Formally, let $\\operatorname{sign}(z)$ be the sign function that returns $-1$, $0$, or $+1$ for a real input $z$. Define the oscillation count $C$ for a sequence $\\{s_t\\}_{t=0}^{T-1}$ by\n$$\nC = \\sum_{t=1}^{T-1} \\mathbf{1}\\Big(\\operatorname{sign}(s_{t-1}) \\cdot \\operatorname{sign}(s_t) = -1 \\ \\wedge \\ \\operatorname{sign}(s_{t-1}) \\neq 0 \\ \\wedge \\ \\operatorname{sign}(s_t) \\neq 0\\Big),\n$$\nwhere $\\mathbf{1}(\\cdot)$ denotes the indicator function that returns $1$ if its argument is true and $0$ otherwise. Use this metric to quantify oscillations. To compare methods, compute the integer difference $\\Delta = C_{\\mathrm{SGD}} - C_{\\mathrm{NAG}}$, where $C_{\\mathrm{SGD}}$ is the oscillation count for the baseline method and $C_{\\mathrm{NAG}}$ is the oscillation count for the momentum-based lookahead method. A positive $\\Delta$ indicates that Nesterov Accelerated Gradient stabilizes oscillations relative to Stochastic Gradient Descent for the given settings, a zero $\\Delta$ indicates equal oscillatory behavior, and a negative $\\Delta$ indicates worse stabilization.\n\nAngles must be in radians. There are no physical units involved beyond this angle specification. All numerical outputs must be integers.\n\nImplement a single program that, for each test case below, computes the integer $\\Delta$ and produces the results as a single line of output containing the differences as a comma-separated list enclosed in square brackets (for example, $[1,0,2]$). Use the following test suite, each case specified by $(a, b, \\eta, \\mu, T, x_0)$:\n- Case $1$ (general oscillatory curvature, moderate frequencies, expected stabilization): $a = [\\,1.0, \\ 0.5\\,]$, $b = [\\,3.0, \\ 7.0\\,]$, $\\eta = 0.05$, $\\mu = 0.9$, $T = 200$, $x_0 = 1.0$.\n- Case $2$ (high-frequency curvature, larger momentum, longer horizon): $a = [\\,1.0\\,]$, $b = [\\,40.0\\,]$, $\\eta = 0.02$, $\\mu = 0.95$, $T = 400$, $x_0 = 0.1$.\n- Case $3$ (momentum turned off, equivalence check): $a = [\\,1.0, \\ 0.5\\,]$, $b = [\\,3.0, \\ 7.0\\,]$, $\\eta = 0.05$, $\\mu = 0.0$, $T = 200$, $x_0 = 1.0$.\n- Case $4$ (very small step size, near-monotone movement): $a = [\\,1.0, \\ 0.3\\,]$, $b = [\\,5.0, \\ 6.0\\,]$, $\\eta = 0.001$, $\\mu = 0.9$, $T = 200$, $x_0 = 2.0$.\n- Case $5$ (zero initial gradient for single-frequency term): $a = [\\,1.0\\,]$, $b = [\\,10.0\\,]$, $\\eta = 0.05$, $\\mu = 0.9$, $T = 200$, $x_0 = \\pi/20$.\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets in the order of the cases provided, that is, $[\\Delta_1,\\Delta_2,\\Delta_3,\\Delta_4,\\Delta_5]$.", "solution": "The problem statement has been critically validated and is deemed to be scientifically grounded, well-posed, objective, and internally consistent. It provides a formal specification for a synthetic loss function, two distinct optimization algorithms, and a precise metric for quantifying oscillatory behavior. The terminology \"Stochastic Gradient Descent (SGD)\" is used to refer to what is technically standard Gradient Descent (GD), as the loss function is deterministic. This is a common convention in the deep learning literature and is unambiguous within the context of the problem's explicit definition of the \"baseline method.\" All parameters and conditions are sufficiently specified to permit a unique and verifiable solution.\n\n### Principle-Based Solution\n\nThe task is to compare the oscillatory behavior of two optimization algorithms on a one-dimensional, non-convex loss function. The solution involves three stages: defining the mathematical model, specifying the optimization algorithms, and implementing the comparison metric.\n\n#### 1. Objective Function and Gradient\n\nThe synthetic loss function is given by:\n$$\nf(x) = \\sum_{i=1}^{n} a_i \\sin(b_i x)\n$$\nwhere $x \\in \\mathbb{R}$, and the coefficients $a_i, b_i$ are provided as lists of real numbers. The sine function is evaluated in radians.\n\nTo perform gradient-based optimization, we must compute the first derivative of $f(x)$ with respect to $x$. Using the linearity of the derivative and the chain rule, $\\frac{d}{dx}\\sin(u) = \\cos(u) \\frac{du}{dx}$, we find the gradient $\\nabla f(x) = \\frac{df}{dx}$:\n$$\n\\nabla f(x) = \\frac{d}{dx} \\left( \\sum_{i=1}^{n} a_i \\sin(b_i x) \\right) = \\sum_{i=1}^{n} a_i \\frac{d}{dx} (\\sin(b_i x))\n$$\n$$\n\\nabla f(x) = \\sum_{i=1}^{n} a_i \\cos(b_i x) \\cdot (b_i) = \\sum_{i=1}^{n} a_i b_i \\cos(b_i x)\n$$\nThis expression for the gradient will be used in the update rules for both optimizers.\n\n#### 2. Optimization Algorithms\n\nWe will implement two iterative optimization algorithms, both of which generate a sequence of positions $\\{x_t\\}_{t=0}^T$ starting from an initial position $x_0$.\n\n**a) Baseline Method (Gradient Descent)**\n\nThe problem describes a baseline method, termed \"SGD,\" which is standard Gradient Descent (GD) for a deterministic function. At each iteration $t$, the position $x_t$ is updated by taking a step in the direction opposite to the gradient $\\nabla f(x_t)$. The update rule is:\n$$\nx_{t+1} = x_t - \\eta \\nabla f(x_t)\n$$\nwhere $\\eta  0$ is the learning rate.\n\n**b) Nesterov Accelerated Gradient (NAG)**\n\nNAG is a momentum-based method that improves upon standard momentum by calculating the gradient at a \"lookahead\" position. This allows the optimizer to anticipate changes in the gradient and correct its course, which is particularly effective in reducing oscillations. A standard implementation of NAG involves a velocity vector $v_t$ and proceeds as follows, starting with an initial velocity $v_0 = 0$:\n\n1.  **Compute Lookahead Position:** First, an intermediate \"lookahead\" position $\\tilde{x}_t$ is estimated by applying the current momentum:\n    $$\n    \\tilde{x}_t = x_t + \\mu v_t\n    $$\n    where $\\mu \\in [0, 1)$ is the momentum parameter.\n\n2.  **Update Velocity:** The velocity is updated using the gradient evaluated at the lookahead position $\\tilde{x}_t$:\n    $$\n    v_{t+1} = \\mu v_t - \\eta \\nabla f(\\tilde{x}_t)\n    $$\n\n3.  **Update Position:** The final position is updated using the new velocity:\n    $$\n    x_{t+1} = x_t + v_{t+1}\n    $$\n\nIt is a requirement that this method reduces to the baseline for $\\mu=0$. Let's verify: if $\\mu = 0$, the lookahead position is $\\tilde{x}_t = x_t$. The velocity update becomes $v_{t+1} = -\\eta \\nabla f(x_t)$. The position update becomes $x_{t+1} = x_t - \\eta \\nabla f(x_t)$, which is identical to the Gradient Descent update rule. This confirms the consistency of the chosen formulation.\n\n#### 3. Oscillation Score and Comparison\n\nThe degree of oscillation in an optimization trajectory $\\{x_t\\}_{t=0}^{T}$ is quantified by an oscillation count $C$. This metric is based on the sequence of step increments, $s_t = x_{t+1} - x_t$, for $t \\in \\{0, 1, \\dots, T-1\\}$.\n\nA sign change is registered when two consecutive non-zero steps have opposite signs. The total oscillation count $C$ is defined as:\n$$\nC = \\sum_{t=1}^{T-1} \\mathbf{1}\\Big(\\operatorname{sign}(s_{t-1}) \\cdot \\operatorname{sign}(s_t) = -1 \\Big)\n$$\nThe problem statement includes the explicit condition that both $s_{t-1}$ and $s_t$ must be non-zero. The mathematical expression $\\operatorname{sign}(s_{t-1}) \\cdot \\operatorname{sign}(s_t) = -1$ inherently enforces this, as the sign function returns $0$ for a zero input, and the product would be $0$, not $-1$.\n\nFor each test case, we will generate two trajectories, one for the baseline method (GD) and one for NAG. We then compute their respective oscillation counts, $C_{\\mathrm{GD}}$ and $C_{\\mathrm{NAG}}$. The final comparison metric is the integer difference:\n$$\n\\Delta = C_{\\mathrm{GD}} - C_{\\mathrm{NAG}}\n$$\nA positive $\\Delta$ indicates that NAG exhibits fewer oscillations than GD for the given parameters.\n\n#### 4. Computational Procedure\nFor each test case specified by the parameters $(a, b, \\eta, \\mu, T, x_0)$:\n1.  Define the gradient function $\\nabla f(x)$ using the given $a$ and $b$ coefficients.\n2.  **Run Baseline (GD):**\n    - Initialize the trajectory with $x^{\\text{GD}}_0 = x_0$.\n    - Iterate for $t = 0, \\dots, T-1$ to compute $x^{\\text{GD}}_{t+1} = x^{\\text{GD}}_{t} - \\eta \\nabla f(x^{\\text{GD}}_{t})$.\n    - Store the full trajectory $\\{x^{\\text{GD}}_t\\}_{t=0}^T$.\n3.  **Run NAG:**\n    - Initialize the trajectory with $x^{\\text{NAG}}_0 = x_0$ and velocity $v_0 = 0$.\n    - Iterate for $t = 0, \\dots, T-1$ using the NAG update rules to compute $x^{\\text{NAG}}_{t+1}$.\n    - Store the full trajectory $\\{x^{\\text{NAG}}_t\\}_{t=0}^T$.\n4.  **Calculate Oscillation Counts:**\n    - For the GD trajectory, compute the step increments $s^{\\text{GD}}_t$ and the oscillation count $C_{\\mathrm{GD}}$.\n    - For the NAG trajectory, compute the step increments $s^{\\text{NAG}}_t$ and the oscillation count $C_{\\mathrm{NAG}}$.\n5.  **Compute Difference:** Calculate $\\Delta = C_{\\mathrm{GD}} - C_{\\mathrm{NAG}}$ and record the integer result.\nThis procedure is repeated for all five test cases to generate the final output.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the optimization comparison problem for the given test cases.\n    \"\"\"\n\n    # Define the test cases from the problem statement.\n    # Each case is a tuple: (a, b, eta, mu, T, x0)\n    test_cases = [\n        # Case 1\n        (np.array([1.0, 0.5]), np.array([3.0, 7.0]), 0.05, 0.9, 200, 1.0),\n        # Case 2\n        (np.array([1.0]), np.array([40.0]), 0.02, 0.95, 400, 0.1),\n        # Case 3\n        (np.array([1.0, 0.5]), np.array([3.0, 7.0]), 0.05, 0.0, 200, 1.0),\n        # Case 4\n        (np.array([1.0, 0.3]), np.array([5.0, 6.0]), 0.001, 0.9, 200, 2.0),\n        # Case 5\n        (np.array([1.0]), np.array([10.0]), 0.05, 0.9, 200, np.pi / 20.0),\n    ]\n\n    results = []\n\n    def get_gradient_func(a, b):\n        \"\"\"Returns the gradient function for a given set of coefficients.\"\"\"\n        def grad_f(x):\n            return np.sum(a * b * np.cos(b * x))\n        return grad_f\n\n    def run_sgd(grad_f, eta, T, x0):\n        \"\"\"Runs the baseline Gradient Descent optimizer.\"\"\"\n        x_traj = [x0]\n        x_current = x0\n        for _ in range(T):\n            gradient = grad_f(x_current)\n            x_next = x_current - eta * gradient\n            x_traj.append(x_next)\n            x_current = x_next\n        return np.array(x_traj)\n\n    def run_nag(grad_f, eta, mu, T, x0):\n        \"\"\"Runs the Nesterov Accelerated Gradient optimizer.\"\"\"\n        x_traj = [x0]\n        x_current = x0\n        v = 0.0\n        for _ in range(T):\n            x_lookahead = x_current + mu * v\n            gradient = grad_f(x_lookahead)\n            v_next = mu * v - eta * gradient\n            x_next = x_current + v_next\n            \n            x_traj.append(x_next)\n            x_current = x_next\n            v = v_next\n        return np.array(x_traj)\n\n    def calculate_oscillation_count(trajectory):\n        \"\"\"Calculates the oscillation score for a given trajectory.\"\"\"\n        if len(trajectory)  3:\n            return 0\n        \n        # Calculate step increments s_t = x_{t+1} - x_t\n        steps = np.diff(trajectory)\n        \n        # The sum is from t=1 to T-1, involving pairs (s_{t-1}, s_t)\n        # There are T steps (s_0 to s_{T-1}) for T iterations.\n        # The loop iterates T-1 times.\n        count = 0\n        for t in range(1, len(steps)):\n            # The condition sign(s_1)*sign(s_2) == -1 inherently handles\n            # cases where one of them is zero, as the product would be 0.\n            if np.sign(steps[t-1]) * np.sign(steps[t]) == -1:\n                count += 1\n        return count\n\n    for case in test_cases:\n        a, b, eta, mu, T, x0 = case\n        \n        grad_f = get_gradient_func(a, b)\n        \n        # Run baseline method (SGD/GD)\n        traj_sgd = run_sgd(grad_f, eta, T, x0)\n        c_sgd = calculate_oscillation_count(traj_sgd)\n        \n        # Run momentum-based method (NAG)\n        traj_nag = run_nag(grad_f, eta, mu, T, x0)\n        c_nag = calculate_oscillation_count(traj_nag)\n        \n        # Calculate the difference and append to results\n        delta = c_sgd - c_nag\n        results.append(int(delta))\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "3157033"}]}