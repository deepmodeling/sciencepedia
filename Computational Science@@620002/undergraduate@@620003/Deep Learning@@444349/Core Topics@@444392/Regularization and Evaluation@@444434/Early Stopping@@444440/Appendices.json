{"hands_on_practices": [{"introduction": "The fundamental goal of training is not to achieve the lowest possible loss on the training data, but to find a model that generalizes well to new, unseen data. This exercise places you at the heart of this trade-off by asking you to implement and compare two popular strategies: early stopping and checkpoint averaging. By simulating a simple training process and measuring the expected generalization gap, $L_{test} - L_{train}$, you will gain a concrete understanding of how these methods work to mitigate overfitting and select a more generalizable model [@problem_id:3119093].", "problem": "You are asked to implement and analyze two model selection strategies within a controlled deep learning simulation that uses a one-dimensional linear regression surrogate to mimic training dynamics and generalization behavior. The comparison metric is the expected generalization gap across random seeds, defined as the expectation of the difference between test loss and training loss at the selected model parameters. Your program must be a complete, runnable program.\n\nFundamental base and setup:\n- Consider a data-generating process where inputs $x$ are sampled independently from a standard normal distribution $x \\sim \\mathcal{N}(0,1)$, and outputs $y$ are generated by $y = \\theta^\\ast x + \\epsilon$, where the noise $\\epsilon \\sim \\mathcal{N}(0, \\sigma_\\epsilon^2)$ is independent of $x$. The parameter $\\theta^\\ast$ is the true data-generating coefficient.\n- The training procedure is Empirical Risk Minimization (ERM) using batch Gradient Descent (GD) to minimize the Mean Squared Error (MSE) loss. For a parameter $\\theta$ and dataset $\\{(x_i, y_i)\\}_{i=1}^n$, the empirical loss is $L(\\theta) = \\frac{1}{n}\\sum_{i=1}^n (y_i - \\theta x_i)^2$. The gradient with respect to $\\theta$ is $\\nabla_\\theta L(\\theta) = \\frac{2}{n}\\sum_{i=1}^n x_i(\\theta x_i - y_i)$.\n- The GD update rule at epoch $t$ is $\\theta_{t+1} = \\theta_t - \\eta \\nabla_\\theta L(\\theta_t)$, where $\\eta$ is the learning rate and the initialization is $\\theta_0 = 0$.\n- Define the generalization gap at parameter $\\theta$ as $G(\\theta) = L_{test}(\\theta) - L_{train}(\\theta)$, where $L_{train}$ and $L_{test}$ are the empirical MSE computed on the training and test sets, respectively.\n- The expectation across seeds is the average over independent draws of datasets and noise controlled by a list of random seeds. For a selection rule that yields a parameter $\\theta_{sel}^{(s)}$ per seed $s$, the expected generalization gap is $\\mathbb{E}_s\\big[G(\\theta_{sel}^{(s)})\\big]$, approximated by the arithmetic mean over the given seeds.\n\nModel selection strategies to compare:\n1. Early Stopping (ES): Use a separate validation set to monitor the validation loss $L_{val}(\\theta_t)$ per epoch. Maintain the best validation loss seen so far and its epoch. If the validation loss does not strictly improve for $p$ consecutive epochs (the patience), stop selection and choose the parameter at the best epoch encountered before stopping. Formally, scan epochs $t=0,1,\\dots$; whenever $L_{val}(\\theta_t) < \\min_{u \\le t-1} L_{val}(\\theta_u)$, record $t$ as the new best epoch and reset a counter of non-improving epochs. Otherwise, increment the counter; if it exceeds $p$, terminate and select the last recorded best epoch. Compute the generalization gap $G(\\theta_{ES})$ for the selected parameter $\\theta_{ES}$.\n2. Checkpoint Averaging (CA): Train for a fixed total of $E$ epochs. Let the last $k$ parameters be $\\theta_{E-k+1}, \\dots, \\theta_E$. Define the averaged parameter as $\\bar{\\theta} = \\frac{1}{k}\\sum_{u=E-k+1}^E \\theta_u$. Compute the generalization gap $G(\\bar{\\theta})$.\n\nSimulation protocol per seed $s$:\n- Generate independent training, validation, and test datasets according to the given $n_{train}$, $n_{val}$, and $n_{test}$ using the seed $s$.\n- Perform batch GD for $E$ epochs using the training set, store $\\theta_t$ for each epoch $t$.\n- Compute $L_{train}(\\theta_t)$, $L_{val}(\\theta_t)$, and $L_{test}(\\theta_t)$ for each epoch $t$.\n- Apply ES to select $\\theta_{ES}$ and compute $G(\\theta_{ES})$.\n- Apply CA to compute $\\bar{\\theta}$ and $G(\\bar{\\theta})$.\n- Repeat across all seeds in the case and compute the mean of $G(\\theta_{ES})$ and the mean of $G(\\bar{\\theta})$.\n\nTest suite:\nImplement the above simulation for the following parameter sets. In all cases, the loss is dimensionless, and the final outputs must be floats. Round final outputs to $6$ decimal places.\n\n- Case $1$ (happy path):\n  - True parameter $\\theta^\\ast = 1.5$\n  - Training size $n_{train} = 50$\n  - Validation size $n_{val} = 100$\n  - Test size $n_{test} = 10000$\n  - Learning rate $\\eta = 0.05$\n  - Total epochs $E = 120$\n  - Patience $p = 5$\n  - Averaging window $k = 10$\n  - Noise standard deviation $\\sigma_\\epsilon = 0.5$\n  - Seeds: integers from $0$ to $19$ inclusive\n- Case $2$ (boundary: minimal patience, no averaging):\n  - True parameter $\\theta^\\ast = 1.5$\n  - Training size $n_{train} = 50$\n  - Validation size $n_{val} = 100$\n  - Test size $n_{test} = 10000$\n  - Learning rate $\\eta = 0.05$\n  - Total epochs $E = 120$\n  - Patience $p = 0$\n  - Averaging window $k = 1$\n  - Noise standard deviation $\\sigma_\\epsilon = 0.5$\n  - Seeds: integers from $20$ to $39$ inclusive\n- Case $3$ (boundary: average all checkpoints, low noise, larger data):\n  - True parameter $\\theta^\\ast = 1.5$\n  - Training size $n_{train} = 400$\n  - Validation size $n_{val} = 400$\n  - Test size $n_{test} = 10000$\n  - Learning rate $\\eta = 0.02$\n  - Total epochs $E = 200$\n  - Patience $p = 10$\n  - Averaging window $k = 200$\n  - Noise standard deviation $\\sigma_\\epsilon = 0.1$\n  - Seeds: integers from $40$ to $59$ inclusive\n- Case $4$ (edge: high noise, small data, different true parameter):\n  - True parameter $\\theta^\\ast = -0.8$\n  - Training size $n_{train} = 20$\n  - Validation size $n_{val} = 40$\n  - Test size $n_{test} = 10000$\n  - Learning rate $\\eta = 0.03$\n  - Total epochs $E = 150$\n  - Patience $p = 3$\n  - Averaging window $k = 20$\n  - Noise standard deviation $\\sigma_\\epsilon = 1.2$\n  - Seeds: integers from $60$ to $79$ inclusive\n\nRequired final output format:\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, where each element corresponds to one case and is itself a two-element list containing the expected generalization gap for Early Stopping and Checkpoint Averaging, respectively, both rounded to $6$ decimal places. For example, the shape must be like $\\big[ [g_{ES}^{(1)}, g_{CA}^{(1)}], [g_{ES}^{(2)}, g_{CA}^{(2)}], [g_{ES}^{(3)}, g_{CA}^{(3)}], [g_{ES}^{(4)}, g_{CA}^{(4)}] \\big]$.", "solution": "The problem statement is valid. It presents a well-posed, scientifically grounded, and objective simulation task relevant to the field of machine learning. The task involves comparing two common model selection strategies, Early Stopping (ES) and Checkpoint Averaging (CA), within a controlled one-dimensional linear regression setting. All parameters, procedures, and definitions are provided with sufficient clarity and without contradiction, enabling a unique and meaningful numerical solution.\n\nThe solution proceeds by first laying out the theoretical framework and then detailing the algorithmic implementation.\n\n### Theoretical Framework\n\n1.  **Data Generation and Model:** The problem is set in the context of a simple linear model. The data-generating process is defined by $y = \\theta^\\ast x + \\epsilon$, where inputs $x$ are drawn from a standard normal distribution, $x \\sim \\mathcal{N}(0,1)$, and the noise term $\\epsilon$ is also normally distributed, $\\epsilon \\sim \\mathcal{N}(0, \\sigma_\\epsilon^2)$. The goal is to estimate the true parameter $\\theta^\\ast$ using a model $\\hat{y} = \\theta x$.\n\n2.  **Optimization:** The parameter $\\theta$ is optimized by minimizing the Mean Squared Error (MSE) on a training set $\\{(x_i, y_i)\\}_{i=1}^{n_{train}}$. The empirical loss function is $L_{train}(\\theta) = \\frac{1}{n_{train}}\\sum_{i=1}^{n_{train}} (y_i - \\theta x_i)^2$. The optimization method is batch Gradient Descent (GD), which iteratively updates the parameter according to the rule:\n    $$\n    \\theta_{t+1} = \\theta_t - \\eta \\nabla_\\theta L_{train}(\\theta_t)\n    $$\n    where $\\theta_0 = 0$ is the initialization, $\\eta$ is the learning rate, and $t$ is the epoch index. The gradient of the loss is:\n    $$\n    \\nabla_\\theta L_{train}(\\theta) = \\frac{2}{n_{train}}\\sum_{i=1}^{n_{train}} x_i(\\theta x_i - y_i)\n    $$\n    For a given training set, this process generates a deterministic trajectory of parameters $\\{\\theta_0, \\theta_1, \\dots, \\theta_E\\}$. The randomness in the simulation arises from the sampling of the datasets for each specified random seed.\n\n3.  **Generalization Gap:** The central metric for evaluation is the generalization gap, defined as the difference between the model's performance on unseen test data and its performance on the training data:\n    $$\n    G(\\theta) = L_{test}(\\theta) - L_{train}(\\theta)\n    $$\n    A large positive gap is a hallmark of overfitting, where the model has learned idiosyncrasies of the training set that do not generalize to the broader data distribution. The final comparison metric is the expected generalization gap, $\\mathbb{E}_s[G(\\theta_{sel})]$, approximated by averaging the gap over multiple independent simulations (seeds).\n\n4.  **Model Selection Strategies:**\n    *   **Early Stopping (ES):** This technique acts as a form of regularization by preventing the model from training for too long and overfitting. It works by monitoring the loss on a separate validation set, $L_{val}(\\theta_t)$. Training is virtually halted when the validation loss fails to show strict improvement for a specified number of epochs, known as patience ($p$). The parameter selected is not the one at which training stopped, but the one from the epoch that yielded the best (minimum) validation loss observed during the process. This strategy directly aims to select a model with good generalization performance, as proxied by the validation set.\n    *   **Checkpoint Averaging (CA):** This method involves training for a fixed number of epochs ($E$) and then averaging the parameters from the last $k$ epochs. The averaged parameter is $\\bar{\\theta} = \\frac{1}{k}\\sum_{u=E-k+1}^E \\theta_u$. The intuition behind this approach, related to Polyak-Ruppert averaging, is that the average of parameters over a portion of the optimization trajectory can lead to a more stable solution residing in a wider, flatter region of the loss landscape, which is often correlated with better generalization.\n\n### Algorithmic Implementation\n\nThe solution is implemented by a program that executes the simulation for each of the four specified cases.\n\n1.  **Main Loop:** The program iterates through each parameter case. For each case, it runs a series of simulations, one for each seed in the specified range.\n\n2.  **Per-Seed Simulation:** For a given seed $s$:\n    a.  **Data Generation:** A new random number generator is seeded with $s$. Independent training, validation, and test datasets of sizes $n_{train}$, $n_{val}$, and $n_{test}$ are generated according to the process $x \\sim \\mathcal{N}(0,1)$ and $y = \\theta^\\ast x + \\epsilon$, with $\\epsilon \\sim \\mathcal{N}(0, \\sigma_\\epsilon^2)$.\n    b.  **Gradient Descent:** The GD algorithm is run for $E$ epochs, starting from $\\theta_0=0$. All intermediate parameters, $\\theta_0, \\theta_1, \\dots, \\theta_E$, are stored. The gradient calculation is vectorized for efficiency.\n    c.  **Loss Evaluation:** For each stored parameter $\\theta_t$, the MSE is computed on the training, validation, and test sets, yielding trajectories $L_{train}(\\theta_t)$, $L_{val}(\\theta_t)$, and $L_{test}(\\theta_t)$.\n    d.  **Early Stopping Selection:** The stored validation losses $L_{val}(\\theta_t)$ are scanned from $t=0$ to $E$. The epoch $t_{best}$ corresponding to the minimum validation loss seen so far is tracked. A patience counter is incremented for each epoch that does not yield a new strictly lower validation loss; it is reset upon improvement. If the counter exceeds the patience parameter $p$, the scan is terminated. The selected parameter is $\\theta_{ES} = \\theta_{t_{best}}$. The generalization gap $G(\\theta_{ES})$ is then calculated.\n    e.  **Checkpoint Averaging Selection:** The parameter $\\bar{\\theta}$ is computed by averaging the last $k$ parameters of the training trajectory, $\\{\\theta_{E-k+1}, \\dots, \\theta_E\\}$. The generalization gap $G(\\bar{\\theta})$ is then calculated.\n\n3.  **Averaging and Output:** After completing the simulations for all seeds in a case, the collected generalization gaps for ES and CA are separately averaged. These two mean values form the result for the case. The final program output collates the results from all four cases into the specified list-of-lists format, with each numerical value rounded to six decimal places.", "answer": "```python\nimport numpy as np\n\ndef mse(theta, x, y):\n    \"\"\"\n    Calculates the Mean Squared Error for a 1D linear model.\n    \"\"\"\n    if y.size == 0:\n        return 0.0\n    return np.mean((y - theta * x)**2)\n\ndef run_simulation_for_case(params):\n    \"\"\"\n    Runs the full simulation for one set of parameters.\n    \"\"\"\n    theta_star, n_train, n_val, n_test, eta, E, p, k, sigma_eps, seeds = params\n\n    es_gaps = []\n    ca_gaps = []\n\n    for seed in seeds:\n        rng = np.random.default_rng(seed)\n        \n        # 1. Data Generation\n        x_train = rng.standard_normal(n_train)\n        eps_train = rng.standard_normal(n_train) * sigma_eps\n        y_train = theta_star * x_train + eps_train\n        \n        x_val = rng.standard_normal(n_val)\n        eps_val = rng.standard_normal(n_val) * sigma_eps\n        y_val = theta_star * x_val + eps_val\n\n        x_test = rng.standard_normal(n_test)\n        eps_test = rng.standard_normal(n_test) * sigma_eps\n        y_test = theta_star * x_test + eps_test\n\n        # 2. Training (Batch Gradient Descent)\n        thetas = np.zeros(E + 1)\n        theta_t = 0.0\n        \n        mean_x_sq_train = np.mean(x_train**2)\n        mean_xy_train = np.mean(x_train * y_train)\n\n        for t in range(E):\n            grad = 2 * (theta_t * mean_x_sq_train - mean_xy_train)\n            theta_t = theta_t - eta * grad\n            thetas[t + 1] = theta_t\n\n        # 3. Loss Calculation\n        train_losses = np.array([mse(th, x_train, y_train) for th in thetas])\n        val_losses = np.array([mse(th, x_val, y_val) for th in thetas])\n        test_losses = np.array([mse(th, x_test, y_test) for th in thetas])\n\n        # 4. Early Stopping (ES)\n        best_val_loss = float('inf')\n        best_epoch = 0\n        patience_counter = 0\n\n        for t in range(E + 1):\n             current_val_loss = val_losses[t]\n             if current_val_loss < best_val_loss:\n                 best_val_loss = current_val_loss\n                 best_epoch = t\n                 patience_counter = 0\n             else:\n                 patience_counter += 1\n            \n             if patience_counter > p:\n                 break\n        \n        theta_es = thetas[best_epoch]\n        es_gap = test_losses[best_epoch] - train_losses[best_epoch]\n        es_gaps.append(es_gap)\n\n        # 5. Checkpoint Averaging (CA)\n        theta_ca_list = thetas[E - k + 1 : E + 1]\n        theta_ca = np.mean(theta_ca_list)\n        ca_gap = mse(theta_ca, x_test, y_test) - mse(theta_ca, x_train, y_train)\n        ca_gaps.append(ca_gap)\n\n    return [round(np.mean(es_gaps), 6), round(np.mean(ca_gaps), 6)]\n\ndef solve():\n    \"\"\"\n    Defines the test cases and formats the final output.\n    \"\"\"\n    case1 = (1.5, 50, 100, 10000, 0.05, 120, 5, 10, 0.5, range(0, 20))\n    case2 = (1.5, 50, 100, 10000, 0.05, 120, 0, 1, 0.5, range(20, 40))\n    case3 = (1.5, 400, 400, 10000, 0.02, 200, 10, 200, 0.1, range(40, 60))\n    case4 = (-0.8, 20, 40, 10000, 0.03, 150, 3, 20, 1.2, range(60, 80))\n    \n    test_cases = [case1, case2, case3, case4]\n\n    results = []\n    for case in test_cases:\n        result = run_simulation_for_case(case)\n        results.append(result)\n        \n    final_output_str = str(results).replace(\" \", \"\")\n    print(final_output_str)\n\nsolve()\n```", "id": "3119093"}, {"introduction": "A standard early stopping rule tracks the validation loss and stops when it ceases to improve. However, what constitutes a \"real\" improvement? Validation loss is a noisy estimate, and random fluctuations can easily mislead a naive algorithm, causing it to stop prematurely or too late. This practice challenges you to implement a more principled, \"significance-aware\" stopping rule that incorporates statistical uncertainty, making a decision only when an observed improvement is large enough that it is unlikely to be due to chance [@problem_id:3119052].", "problem": "You are given a training scenario where the model is trained with heavy input augmentations, but early stopping must be based on an unaugmented validation subset of size $m$. Because the validation subset is small, the empirical validation risk estimate exhibits sampling noise. Your task is to design and implement a principled, variance-aware early stopping rule that uses only the unaugmented validation measurements to decide when to stop and which epoch to select, while completely ignoring the augmented training losses for stopping decisions.\n\nStart from the following fundamental base:\n- Empirical Risk Minimization: the unaugmented validation loss at epoch $t$ is an empirical mean over $m$ independent and identically distributed per-example losses, which is an unbiased estimator of the true risk.\n- For a sample mean of $m$ independent and identically distributed variables with variance $\\sigma^2$, the variance of the sample mean is $\\sigma^2 / m$.\n- By the Central Limit Theorem, the empirical mean at each epoch is approximately normally distributed around the true risk with standard error $\\sqrt{\\sigma^2 / m}$.\n\nFrom these principles, derive a stopping rule that guards against falsely declaring progress when the apparent improvement is comparable to noise. Then implement the following significance-aware patience rule in your program:\n- Define a decision threshold $\\tau = c \\cdot \\sqrt{\\sigma^2 / m}$, where $c$ is a user-chosen positive constant.\n- Maintain two tracked quantities: the raw best validation mean seen so far (the minimum so far) and the last epoch at which a statistically significant improvement was recorded.\n- At each epoch $t$, update the raw best if the current unaugmented validation mean is lower than the previous raw best. Separately, record a statistically significant improvement if the current unaugmented validation mean is at least $\\tau$ lower than the best value at the time of the last significant improvement.\n- Stop at the first epoch $t$ such that $t - t_{\\text{last-significant}} \\ge P$, where $P$ is a nonnegative integer patience parameter. When this stopping condition is met, the selected epoch is the epoch index of the raw-best validation mean observed up to and including epoch $t$. If the condition never triggers, select the epoch with the raw-best validation mean across all epochs.\n- Epoch indexing must be $1$-based in your output.\n\nYour program must implement this rule exactly and produce answers for the following test suite. In each test case, you are provided:\n- A sequence of unaugmented validation means per epoch $y_1, y_2, \\dots, y_T$ (to be used for early stopping).\n- A sequence of augmented training means per epoch $a_1, a_2, \\dots, a_T$ (for context only; do not use these for stopping).\n- The subset size $m$, per-example variance $\\sigma^2$, decision parameter $c$, and patience $P$.\n\nTest suite:\n- Case A:\n  - Unaugmented validation sequence $[1.00, 0.90, 0.82, 0.79, 0.78, 0.775, 0.774, 0.776, 0.780, 0.785, 0.790, 0.800]$.\n  - Augmented training sequence $[1.50, 1.30, 1.15, 1.05, 0.98, 0.94, 0.91, 0.89, 0.87, 0.86, 0.85, 0.84]$.\n  - Parameters: $m = 25$, $\\sigma^2 = 0.0001$, $c = 1.96$, $P = 2$.\n- Case B:\n  - Unaugmented validation sequence $[1.00, 0.99, 0.98, 0.97, 0.96, 0.95, 0.94, 0.93, 0.92, 0.91]$.\n  - Augmented training sequence $[1.40, 1.30, 1.20, 1.10, 1.05, 1.00, 0.96, 0.93, 0.91, 0.90]$.\n  - Parameters: $m = 20$, $\\sigma^2 = 1 \\times 10^{-6}$, $c = 1.96$, $P = 3$.\n- Case C:\n  - Unaugmented validation sequence $[0.90, 0.85, 0.83, 0.835, 0.84, 0.845, 0.86, 0.87, 0.875, 0.88]$.\n  - Augmented training sequence $[1.20, 1.10, 1.02, 0.98, 0.95, 0.93, 0.92, 0.91, 0.905, 0.90]$.\n  - Parameters: $m = 5$, $\\sigma^2 = 0.01$, $c = 1.96$, $P = 2$.\n- Case D:\n  - Unaugmented validation sequence $[1.20, 1.00, 0.95, 0.951, 0.96, 0.97]$.\n  - Augmented training sequence $[1.60, 1.45, 1.35, 1.28, 1.22, 1.18]$.\n  - Parameters: $m = 10$, $\\sigma^2 = 0.0001$, $c = 1.96$, $P = 1$.\n\nImportant implementation and output requirements:\n- Your program must implement the significance-aware patience rule exactly as described above, using only the unaugmented validation sequence $[y_t]$ and the parameters $m$, $\\sigma^2$, $c$, and $P$.\n- The epoch index must be $1$-based.\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, in the order Case A, Case B, Case C, Case D. Each element must be the selected epoch index (an integer). For example, an output of the form $[\\text{A},\\text{B},\\text{C},\\text{D}]$ where each symbol is replaced by the computed integer.", "solution": "The user has presented a problem concerning the design of a principled early stopping rule for training machine learning models, specifically in a context where the validation loss measurements are subject to significant sampling noise. The core task is to develop a \"significance-aware patience rule\" that avoids premature stopping due to random fluctuations and correctly identifies the best model checkpoint based on statistically meaningful improvements.\n\nThe problem formulation is grounded in established principles of statistical learning theory and is self-contained, well-posed, and scientifically sound. It provides a clear algorithmic specification and a set of test cases for verification. Therefore, the problem is deemed valid and a step-by-step solution can be constructed.\n\nThe foundation of the proposed rule rests on the statistical properties of the empirical validation risk. Let the true, but unknown, risk (expected loss) of the model at epoch $t$ be $R_t$. The quantity we measure is the empirical risk, or validation mean, $y_t$, calculated over a small validation set of size $m$. This empirical risk is an unbiased estimator of the true risk, $E[y_t] = R_t$. According to the Central Limit Theorem, for a sufficiently large $m$, the distribution of $y_t$ can be approximated by a normal distribution centered at the true risk $R_t$:\n$$\ny_t \\approx \\mathcal{N}(R_t, \\frac{\\sigma^2}{m})\n$$\nwhere $\\sigma^2$ is the variance of the per-example loss, assumed to be known and constant. The standard deviation of this sampling distribution, known as the standard error of the mean, is $SE = \\sqrt{\\sigma^2 / m}$.\n\nAn observed decrease in validation loss from one epoch to another, $y_t < y_{t'}$, does not guarantee a decrease in the true risk, $R_t < R_{t'}$. The observed change might be entirely due to random sampling noise. To guard against this, we declare an improvement \"statistically significant\" only if the observed decrease is large relative to the expected noise level. We formalize this by defining a decision threshold, $\\tau$, as a multiple of the standard error:\n$$\n\\tau = c \\cdot SE = c \\cdot \\sqrt{\\frac{\\sigma^2}{m}}\n$$\nHere, $c$ is a positive constant that controls the stringency of the test. A typical choice, $c = 1.96$, is motivated by the properties of the normal distribution, where approximately $95\\%$ of values lie within $1.96$ standard deviations of the mean. An observed decrease greater than $\\tau$ is thus unlikely to have occurred by chance if the true risk had not actually decreased.\n\nThe problem specifies a complete \"significance-aware patience\" algorithm built upon this principle. It tracks several quantities over the epochs $t=1, 2, \\dots, T$:\n\n1.  $y^*$: The minimum (\"raw best\") validation mean observed so far.\n2.  $e^*$: The $1$-based epoch index at which $y^*$ was achieved.\n3.  $t_{sig}$: The $1$-based epoch index of the last recorded statistically significant improvement.\n4.  $y_{sig}$: The validation mean value $y_t$ observed at epoch $t_{sig}$.\n\nThe algorithm proceeds as follows:\n\n**Initialization (at epoch $t=1$):**\n- Let $y_1$ be the validation mean from the first epoch.\n- Set $y^* \\leftarrow y_1$.\n- Set $e^* \\leftarrow 1$.\n- Set $t_{sig} \\leftarrow 1$.\n- Set $y_{sig} \\leftarrow y_1$.\n\n**Iteration (for epochs $t = 2, 3, \\dots, T$):**\nFor each new epoch $t$ with validation mean $y_t$:\n1.  **Update Raw Best:** If $y_t < y^*$, update $y^* \\leftarrow y_t$ and $e^* \\leftarrow t$.\n2.  **Check for Significant Improvement:** Compare the current validation mean $y_t$ with the value from the last significant improvement, $y_{sig}$. If the condition $y_t \\le y_{sig} - \\tau$ is met, the improvement is deemed significant. We then update the reference point for future comparisons: $t_{sig} \\leftarrow t$ and $y_{sig} \\leftarrow y_t$.\n3.  **Check Stopping Condition:** After the above updates, check if the number of epochs since the last significant improvement has exceeded the patience limit $P$. The condition is met if $t - t_{sig} \\ge P$.\n    - If the condition is met, the training process stops. The selected epoch is the best-performing one recorded up to this point, which is the current value of $e^*$.\n    - If the condition is not met, the process continues to the next epoch.\n\n**Final Selection (if stopping condition is never met):**\n- If the training sequence of length $T$ completes without the stopping condition ever being triggered, the selected epoch is the one with the overall best raw validation mean, which is the final value of $e^*$.\n\nThis algorithm will now be applied to the provided test cases.\n\n**Case A:**\nParameters: $m = 25$, $\\sigma^2 = 0.0001$, $c = 1.96$, $P = 2$.\nValidation sequence: $y = [1.00, 0.90, 0.82, 0.79, 0.78, 0.775, 0.774, 0.776, \\dots]$.\nThreshold: $\\tau = 1.96 \\cdot \\sqrt{0.0001 / 25} = 1.96 \\cdot 0.002 = 0.00392$.\n- $t=1$: $y^*=1.00$, $e^*=1$, $t_{sig}=1$, $y_{sig}=1.00$.\n- $t=2, \\dots, 6$: Each epoch shows a decrease large enough to be significant (e.g., $y_6=0.775 \\le y_5- \\tau = 0.78 - 0.00392$). So, $t_{sig}$ is updated at each step, becoming $6$. At $t=6$, $e^*=6$.\n- $t=7$: $y_7=0.774$. This is a new raw best, so $e^* \\leftarrow 7$. However, $y_7=0.774$ is not less than or equal to $y_{sig}-\\tau = 0.775 - 0.00392 = 0.77108$. No significant improvement. $t_{sig}$ remains $6$. Patience counter: $t-t_{sig} = 7-6=1 < 2$.\n- $t=8$: $y_8=0.776$. Not a new raw best. Not a significant improvement. Patience counter: $t-t_{sig} = 8-6=2 \\ge 2$. The stopping condition is met. The selected epoch is the value of $e^*$ at this point, which is $7$.\n\n**Case B:**\nParameters: $m = 20$, $\\sigma^2 = 1 \\times 10^{-6}$, $c = 1.96$, $P = 3$.\nValidation sequence: $y = [1.00, 0.99, 0.98, \\dots, 0.91]$.\nThreshold: $\\tau = 1.96 \\cdot \\sqrt{10^{-6} / 20} \\approx 0.000438$.\nThe validation loss decreases by $0.01$ at every step. Since $0.01 > \\tau$, every single epoch constitutes a significant improvement. Therefore, $t_{sig}$ is updated to $t$ at every epoch. The condition $t - t_{sig} \\ge P$ (i.e., $t-t \\ge 3$) is never met. The process runs to completion. The selected epoch is the one with the minimum loss over the entire sequence, which is $y_{10}=0.91$. The selected epoch is $10$.\n\n**Case C:**\nParameters: $m = 5$, $\\sigma^2 = 0.01$, $c = 1.96$, $P = 2$.\nValidation sequence: $y = [0.90, 0.85, 0.83, 0.835, \\dots]$.\nThreshold: $\\tau = 1.96 \\cdot \\sqrt{0.01 / 5} \\approx 0.08765$.\n- $t=1$: $y^*=0.90$, $e^*=1$, $t_{sig}=1$, $y_{sig}=0.90$.\n- $t=2$: $y_2=0.85$. This is a new raw best ($e^* \\leftarrow 2$). However, $y_2=0.85$ is not less than or equal to $y_{sig}-\\tau = 0.90 - 0.08765 = 0.81235$. No significant improvement. $t_{sig}$ remains $1$. Patience counter: $t-t_{sig} = 2-1=1<2$.\n- $t=3$: $y_3=0.83$. This is a new raw best ($e^* \\leftarrow 3$). It is also not a significant improvement relative to $y_1$. $t_{sig}$ remains $1$. Patience counter: $t-t_{sig} = 3-1=2 \\ge 2$. The stopping condition is met. The selected epoch is the current value of $e^*$, which is $3$.\n\n**Case D:**\nParameters: $m = 10$, $\\sigma^2 = 0.0001$, $c = 1.96$, $P = 1$.\nValidation sequence: $y = [1.20, 1.00, 0.95, 0.951, \\dots]$.\nThreshold: $\\tau = 1.96 \\cdot \\sqrt{0.0001 / 10} \\approx 0.0062$.\n- $t=1$: $y^*=1.20$, $e^*=1$, $t_{sig}=1$, $y_{sig}=1.20$.\n- $t=2$: $y_2=1.00$. New raw best ($e^* \\leftarrow 2$). $y_2=1.00 \\le 1.20 - 0.0062$, so this is a significant improvement. Update $t_{sig} \\leftarrow 2$, $y_{sig} \\leftarrow 1.00$. Patience counter: $t-t_{sig}=0 < 1$.\n- $t=3$: $y_3=0.95$. New raw best ($e^* \\leftarrow 3$). $y_3=0.95 \\le 1.00 - 0.0062$, so this is a significant improvement. Update $t_{sig} \\leftarrow 3$, $y_{sig} \\leftarrow 0.95$. Patience counter: $t-t_{sig}=0 < 1$.\n- $t=4$: $y_4=0.951$. Not a new raw best. Not a significant improvement. Patience counter: $t-t_{sig} = 4-3=1 \\ge 1$. The stopping condition is met. The selected epoch is the current value of $e^*$, which is $3$.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef significance_aware_patience_stopping(\n    val_means: list[float], m: int, sigma_sq: float, c: float, p: int\n) -> int:\n    \"\"\"\n    Implements the significance-aware patience early stopping rule.\n\n    Args:\n        val_means: A sequence of unaugmented validation means per epoch.\n        m: The size of the validation subset.\n        sigma_sq: The per-example variance of the loss.\n        c: The user-chosen positive decision parameter.\n        p: The non-negative integer patience parameter.\n\n    Returns:\n        The 1-based index of the selected epoch.\n    \"\"\"\n    if not val_means:\n        # According to the problem setup, sequences are non-empty.\n        # This is a defensive check.\n        return 0\n\n    num_epochs = len(val_means)\n    \n    # Calculate the decision threshold tau\n    tau = c * np.sqrt(sigma_sq / m)\n\n    # Initialize tracked quantities\n    # All epoch indices are 1-based as per the problem description.\n    raw_best_val_mean = val_means[0]\n    epoch_of_raw_best = 1\n    t_last_significant = 1\n    val_at_last_significant = val_means[0]\n\n    for t_idx, current_val_mean in enumerate(val_means):\n        # Epochs are 1-based\n        current_epoch = t_idx + 1\n\n        # The loop starts at epoch 1 (t_idx=0). Initialization is effectively\n        # handled before the first iteration's logic would change anything.\n        if current_epoch == 1:\n            continue\n\n        # 1. Update Raw Best\n        if current_val_mean < raw_best_val_mean:\n            raw_best_val_mean = current_val_mean\n            epoch_of_raw_best = current_epoch\n\n        # 2. Check for Significant Improvement\n        if current_val_mean <= val_at_last_significant - tau:\n            val_at_last_significant = current_val_mean\n            t_last_significant = current_epoch\n\n        # 3. Check Stopping Condition\n        if current_epoch - t_last_significant >= p:\n            # Stop condition is met. The selected epoch is the best raw\n            # epoch found up to and including this point.\n            return epoch_of_raw_best\n\n    # If the loop completes without stopping, select the overall best raw epoch.\n    return epoch_of_raw_best\n\n\ndef solve():\n    \"\"\"\n    Defines and runs the test suite for the early stopping problem.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        {\n            \"val_means\": [1.00, 0.90, 0.82, 0.79, 0.78, 0.775, 0.774, 0.776, 0.780, 0.785, 0.790, 0.800],\n            \"m\": 25,\n            \"sigma_sq\": 0.0001,\n            \"c\": 1.96,\n            \"p\": 2,\n        },\n        {\n            \"val_means\": [1.00, 0.99, 0.98, 0.97, 0.96, 0.95, 0.94, 0.93, 0.92, 0.91],\n            \"m\": 20,\n            \"sigma_sq\": 1e-6,\n            \"c\": 1.96,\n            \"p\": 3,\n        },\n        {\n            \"val_means\": [0.90, 0.85, 0.83, 0.835, 0.84, 0.845, 0.86, 0.87, 0.875, 0.88],\n            \"m\": 5,\n            \"sigma_sq\": 0.01,\n            \"c\": 1.96,\n            \"p\": 2,\n        },\n        {\n            \"val_means\": [1.20, 1.00, 0.95, 0.951, 0.96, 0.97],\n            \"m\": 10,\n            \"sigma_sq\": 0.0001,\n            \"c\": 1.96,\n            \"p\": 1,\n        },\n    ]\n\n    results = []\n    for case in test_cases:\n        selected_epoch = significance_aware_patience_stopping(\n            val_means=case[\"val_means\"],\n            m=case[\"m\"],\n            sigma_sq=case[\"sigma_sq\"],\n            c=case[\"c\"],\n            p=case[\"p\"]\n        )\n        results.append(selected_epoch)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "3119052"}, {"introduction": "Advanced methods for early stopping often look beyond the simple validation loss curve for more direct signals of overfitting. In the presence of label noise, deep learning models exhibit a distinct learning pattern: they first fit the clean, generalizable patterns before eventually memorizing the noisy, incorrect labels. This exercise introduces a sophisticated technique to detect the very onset of this memorization phase by analyzing the dynamics of the per-example loss distribution on the *training set* [@problem_id:3119110]. Implementing this will give you insight into state-of-the-art approaches that monitor the learning process itself to stop training at the optimal moment.", "problem": "You are given a stylized setting to study early stopping in deep learning under label noise. The base is empirical risk minimization (ERM), where a model with parameters $\\theta$ is trained to minimize the empirical risk $\\frac{1}{n}\\sum_{i=1}^{n}\\ell(y_i, f_\\theta(x_i))$ with a nonnegative per-example loss $\\ell_i(t)$ at training epoch $t$. Under symmetric label noise at rate $\\rho \\in [0,1]$, a fraction $\\rho$ of labels are corrupted uniformly at random, while the remaining fraction $1-\\rho$ are clean. It is widely observed that over training epochs, losses of clean examples decrease early, while noisy examples maintain high losses initially and only later begin to decrease when the model starts to memorize the noise. This induces a characteristic evolution in the histogram of per-example losses: the high-loss tail remains stable at first and then begins to shrink when memorization starts. Early stopping aims to select an epoch before the model fits the noisy tail.\n\nYou must implement a program that, given a synthetic but scientifically plausible generator of per-example losses $\\ell_i(t)$ and a histogram-based detection rule, outputs the detected early stopping epoch for several test cases. The detection rule must be specified using quantiles of the loss distribution as a stable proxy for the right-tail histogram mass.\n\nSynthetic loss generator. For each test case, you are given:\n- the number of training examples $n$,\n- a symmetric label noise rate $\\rho$,\n- a total number of training epochs $T$,\n- a random seed $s$,\n- clean decay rate $\\alpha > 0$,\n- noisy decay rate after memorization $\\beta > 0$,\n- a memorization onset epoch $t_m \\in \\{0,1,\\dots,T-1\\}$,\n- a Gaussian noise standard deviation $\\sigma > 0$,\n- and detection hyperparameters defined below.\n\nFor reproducibility, you must draw all randomness from a pseudorandom number generator initialized with the given seed $s$. Generate per-example identities as noisy with probability $\\rho$ and clean with probability $1-\\rho$, independently across examples. For each example $j \\in \\{1,\\dots,n\\}$, draw a difficulty $d_j \\sim \\mathrm{Uniform}(0,1)$ once and reuse it across epochs. Define the following base values:\n- clean base $b^{\\mathrm{clean}}_j = 1.6 + 0.4 d_j$,\n- clean floor $f^{\\mathrm{clean}}_j = 0.05 + 0.05 d_j$,\n- noisy base $b^{\\mathrm{noisy}}_j = 2.2 + 0.4 d_j$,\n- noisy floor $f^{\\mathrm{noisy}}_j = 0.02 + 0.01 d_j$.\n\nFor each epoch $t \\in \\{0,1,\\dots,T-1\\}$ and example $j$, define the noise term $\\varepsilon_{j,t} \\sim \\mathcal{N}(0,\\sigma^2)$ independently across $j$ and $t$, and then define the per-example loss $\\ell_j(t)$ as follows:\n- If $j$ is clean:\n$$\n\\ell_j(t) = f^{\\mathrm{clean}}_j + \\bigl(b^{\\mathrm{clean}}_j - f^{\\mathrm{clean}}_j\\bigr)\\exp(-\\alpha t) + \\varepsilon_{j,t}.\n$$\n- If $j$ is noisy:\n$$\n\\ell_j(t) =\n\\begin{cases}\nb^{\\mathrm{noisy}}_j + \\varepsilon_{j,t}, & \\text{if } t < t_m,\\\\\nf^{\\mathrm{noisy}}_j + \\bigl(b^{\\mathrm{noisy}}_j - f^{\\mathrm{noisy}}_j\\bigr)\\exp\\bigl(-\\beta (t - t_m)\\bigr), & \\text{if } t \\ge t_m.\n\\end{cases}\n$$\nFinally, clip losses below at zero so that $\\ell_j(t) \\leftarrow \\max\\{\\ell_j(t), 0\\}$.\n\nDetection rule from loss histogram dynamics. Let $q_p(t)$ denote the empirical $p$-quantile of $\\{\\ell_1(t),\\dots,\\ell_n(t)\\}$ at epoch $t$, for a fixed $p \\in (0,1)$ emphasizing the right tail (e.g., $p=0.9$). Define a moving average smoother of window length $w \\in \\mathbb{N}$ by\n$$\n\\widehat{q}_p(t) = \\frac{1}{w}\\sum_{k=0}^{w-1} q_p(t-k), \\quad \\text{defined for } t \\ge w-1.\n$$\nDefine the discrete slope\n$$\ns(t) = \\widehat{q}_p(t) - \\widehat{q}_p(t-1), \\quad \\text{defined for } t \\ge w.\n$$\nGiven a negative slope threshold $\\gamma > 0$ and a required number of consecutive epochs $s_{\\mathrm{consec}} \\in \\mathbb{N}$, and a warm-up $t_{\\mathrm{warm}} \\in \\mathbb{N}$, detect the earliest epoch $t^\\star$ such that $t^\\star \\ge \\max\\{w, t_{\\mathrm{warm}}\\}$ and\n$$\ns(t) \\le -\\gamma \\quad \\text{for all } t \\in \\{t^\\star, t^\\star + 1, \\dots, t^\\star + s_{\\mathrm{consec}} - 1\\}.\n$$\nIf such an epoch exists, output $t^\\star$; otherwise output $T$.\n\nYour program must implement the above generator and detection rule exactly as defined, using the provided test suite. There are no physical units in this problem. Angles are not involved. All proportions must be represented as decimals (e.g., write $0.3$ for thirty percent). The final output for all test cases must be a single line containing a comma-separated list of the detected epochs enclosed in square brackets.\n\nTest suite. Implement your program to run on the following parameter sets, in this order:\n\n- Case A (happy path, moderate noise, clear memorization onset):\n    - $n = 4000$, $\\rho = 0.3$, $T = 60$, $s = 42$, $\\alpha = 0.12$, $\\beta = 0.25$, $t_m = 25$, $\\sigma = 0.03$, $p = 0.9$, $w = 3$, $\\gamma = 0.04$, $s_{\\mathrm{consec}} = 2$, $t_{\\mathrm{warm}} = 5$.\n\n- Case B (boundary: no label noise, should not trigger detection with a sufficiently strict threshold):\n    - $n = 4000$, $\\rho = 0.0$, $T = 60$, $s = 123$, $\\alpha = 0.12$, $\\beta = 0.25$, $t_m = 25$, $\\sigma = 0.03$, $p = 0.9$, $w = 3$, $\\gamma = 0.2$, $s_{\\mathrm{consec}} = 2$, $t_{\\mathrm{warm}} = 5$.\n\n- Case C (high noise, later memorization onset):\n    - $n = 4000$, $\\rho = 0.6$, $T = 70$, $s = 7$, $\\alpha = 0.12$, $\\beta = 0.20$, $t_m = 40$, $\\sigma = 0.03$, $p = 0.9$, $w = 3$, $\\gamma = 0.03$, $s_{\\mathrm{consec}} = 2$, $t_{\\mathrm{warm}} = 5$.\n\n- Case D (edge: small dataset and very slow memorization, may not trigger detection):\n    - $n = 300$, $\\rho = 0.4$, $T = 50$, $s = 999$, $\\alpha = 0.08$, $\\beta = 0.05$, $t_m = 30$, $\\sigma = 0.04$, $p = 0.9$, $w = 4$, $\\gamma = 0.03$, $s_{\\mathrm{consec}} = 3$, $t_{\\mathrm{warm}} = 5$.\n\nRequired final output format. Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (e.g., \"[result_A,result_B,result_C,result_D]\"), where each result is an integer epoch index as defined above for the corresponding case.", "solution": "The user has provided a problem that requires the implementation of a simulation and detection algorithm for early stopping in a deep learning context. The problem is scientifically grounded, well-posed, and all necessary parameters and definitions are provided. Therefore, the problem is deemed valid and a full solution will be developed.\n\nThe solution is divided into two main conceptual parts: the generation of synthetic per-example training losses over a series of epochs, and the application of a specific detection rule to these losses to determine an optimal early stopping epoch.\n\n### Part 1: Synthetic Per-Example Loss Generation\n\nThe first step is to generate the matrix of per-example losses, denoted as $\\ell_j(t)$ for example $j$ at epoch $t$. The dimensions of this process are defined by the number of examples $n$ and the total number of epochs $T$.\n\n1.  **Initialization and Randomness**: For reproducibility, all stochastic elements are derived from a pseudorandom number generator initialized with a given seed $s$.\n\n2.  **Example Identity and Difficulty**: Each of the $n$ examples is categorized as either \"clean\" or \"noisy\". An example is designated as noisy with a probability $\\rho$, and as clean with probability $1-\\rho$. This assignment is performed independently for each example. Concurrently, each example $j$ is assigned a static \"difficulty\" parameter $d_j$, drawn from a uniform distribution $\\mathrm{Uniform}(0, 1)$. This difficulty parameter modulates the loss characteristics for that specific example throughout the training process.\n\n3.  **Loss Characteristics**: Based on an example's identity (clean or noisy) and its difficulty $d_j$, four key values are defined:\n    -   Clean base loss: $b^{\\mathrm{clean}}_j = 1.6 + 0.4 d_j$\n    -   Clean floor loss: $f^{\\mathrm{clean}}_j = 0.05 + 0.05 d_j$\n    -   Noisy base loss: $b^{\\mathrm{noisy}}_j = 2.2 + 0.4 d_j$\n    -   Noisy floor loss: $f^{\\mathrm{noisy}}_j = 0.02 + 0.01 d_j$\n    The \"base\" values represent the initial high loss, while the \"floor\" values represent the minimal achievable loss after extensive training.\n\n4.  **Loss Evolution Dynamics**: The per-example loss $\\ell_j(t)$ for each example $j \\in \\{1, \\dots, n\\}$ and epoch $t \\in \\{0, \\dots, T-1\\}$ is modeled as follows.\n    -   For a **clean** example, the loss decays exponentially from its base value towards its floor value, governed by the decay rate $\\alpha$:\n        $$\n        \\ell_j(t) = f^{\\mathrm{clean}}_j + \\bigl(b^{\\mathrm{clean}}_j - f^{\\mathrm{clean}}_j\\bigr)\\exp(-\\alpha t) + \\varepsilon_{j,t}\n        $$\n    -   For a **noisy** example, the behavior is bifurcated based on the memorization onset epoch, $t_m$. Before this epoch, the model fails to fit the incorrect label, and the loss remains high. After this epoch, the model begins to \"memorize\" the noisy label, causing the loss to decrease. This is governed by the decay rate $\\beta$:\n        $$\n        \\ell_j(t) =\n        \\begin{cases}\n        b^{\\mathrm{noisy}}_j + \\varepsilon_{j,t}, & \\text{if } t < t_m, \\\\\n        f^{\\mathrm{noisy}}_j + \\bigl(b^{\\mathrm{noisy}}_j - f^{\\mathrm{noisy}}_j\\bigr)\\exp\\bigl(-\\beta (t - t_m)\\bigr), & \\text{if } t \\ge t_m.\n        \\end{cases}\n        $$\n    In both cases, $\\varepsilon_{j,t}$ is a stochastic noise term drawn from a zero-mean Gaussian distribution $\\mathcal{N}(0, \\sigma^2)$, added independently for each example and epoch to simulate the stochastic nature of training. Finally, since loss values must be non-negative, the calculated loss is clipped at zero: $\\ell_j(t) \\leftarrow \\max\\{\\ell_j(t), 0\\}$.\n\n### Part 2: Histogram-Based Early Stopping Detection\n\nThe second part of the process is to analyze the generated loss matrix to identify the optimal stopping epoch $t^\\star$. The phenomenon to be detected is the onset of memorization, which manifests as a sudden drop in the losses of the noisy examples. This drop causes the right tail of the loss distribution histogram to shrink.\n\n1.  **Quantile as a Proxy**: The right tail of the loss distribution is tracked using the empirical $p$-quantile, $q_p(t)$, of the set of losses $\\{\\ell_1(t), \\dots, \\ell_n(t)\\}$ at each epoch $t$. A value of $p$ close to $1$ (e.g., $p=0.9$) ensures that this metric is sensitive to the high-loss examples, which are predominantly the noisy ones before memorization begins.\n\n2.  **Smoothing**: To mitigate the effects of the stochastic noise $\\varepsilon_{j,t}$ and obtain a more stable signal, the raw quantile series $q_p(t)$ is smoothed using a moving average of window size $w$. The smoothed quantile, $\\widehat{q}_p(t)$, is defined for epochs $t \\ge w-1$:\n    $$\n    \\widehat{q}_p(t) = \\frac{1}{w}\\sum_{k=0}^{w-1} q_p(t-k)\n    $$\n\n3.  **Slope Calculation**: The onset of memorization is marked by a sharp decrease in the smoothed quantile. This is detected by calculating the discrete slope (or first-order difference) of the smoothed quantile series. The slope $s(t)$ is defined for epochs $t \\ge w$:\n    $$\n    s(t) = \\widehat{q}_p(t) - \\widehat{q}_p(t-1)\n    $$\n\n4.  **Detection Rule**: The early stopping epoch $t^\\star$ is identified based on a persistence condition. It is the earliest epoch $t^\\star$ that satisfies two criteria:\n    -   It must occur after a \"warm-up\" period, i.e., $t^\\star \\ge \\max\\{w, t_{\\mathrm{warm}}\\}$. The warm-up period $t_{\\mathrm{warm}}$ prevents premature stopping due to initial training transients. The condition $t^\\star \\ge w$ is necessary because the slope $s(t)$ is first defined at $t=w$.\n    -   The slope must be significantly negative for a sustained period. Specifically, the slope $s(t)$ must be less than or equal to a negative threshold $-\\gamma$ (where $\\gamma > 0$) for $s_{\\mathrm{consec}}$ consecutive epochs starting from $t^\\star$. That is, $s(t) \\le -\\gamma$ must hold for all $t \\in \\{t^\\star, t^\\star + 1, \\dots, t^\\star + s_{\\mathrm{consec}} - 1\\}$.\n\nIf an epoch $t^\\star$ satisfying these conditions is found, it is returned as the result. If the search completes without finding such an epoch, the algorithm returns the total number of epochs $T$, indicating that early stopping was not triggered.\n\nThis entire procedure is implemented and applied to each of the test cases specified in the problem statement.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef run_simulation(n, rho, T, s_seed, alpha, beta, t_m, sigma, p, w, gamma, s_consec, t_warm):\n    \"\"\"\n    Runs the simulation and detection algorithm for a single test case.\n    \"\"\"\n    # 1. Initialize random number generator for reproducibility.\n    rng = np.random.default_rng(s_seed)\n\n    # 2. Generate per-example identities and difficulties.\n    is_noisy = rng.choice([True, False], size=n, p=[rho, 1 - rho])\n    d = rng.uniform(0, 1, size=n)\n\n    # 3. Define base and floor values for losses.\n    b_clean = 1.6 + 0.4 * d\n    f_clean = 0.05 + 0.05 * d\n    b_noisy = 2.2 + 0.4 * d\n    f_noisy = 0.02 + 0.01 * d\n\n    # 4. Generate the T x n matrix of per-example losses over all epochs.\n    losses = np.zeros((T, n))\n    # Pre-generate all Gaussian noise for efficiency.\n    gaussian_noise = rng.normal(0, sigma, size=(T, n))\n\n    for t in range(T):\n        # Calculate base losses for clean examples at epoch t\n        loss_clean_t = f_clean + (b_clean - f_clean) * np.exp(-alpha * t)\n\n        # Calculate base losses for noisy examples at epoch t\n        if t < t_m:\n            loss_noisy_t = b_noisy\n        else:\n            loss_noisy_t = f_noisy + (b_noisy - f_noisy) * np.exp(-beta * (t - t_m))\n\n        # Combine based on whether an example is noisy or clean\n        epoch_losses = np.where(is_noisy, loss_noisy_t, loss_clean_t)\n        \n        # Add stochastic noise\n        epoch_losses += gaussian_noise[t, :]\n        \n        # Clip losses at zero\n        losses[t, :] = np.maximum(epoch_losses, 0)\n\n    # 5. Calculate the p-quantile of the loss distribution for each epoch.\n    if losses.shape[1] == 0:  # Handle edge case of n=0\n        q_p = np.zeros(T)\n    else:\n        q_p = np.quantile(losses, p, axis=1)\n\n    # 6. Compute the smoothed quantiles using a moving average.\n    q_p_hat = np.zeros_like(q_p)\n    # The moving average is defined for t >= w-1.\n    for t in range(w - 1, T):\n        q_p_hat[t] = np.mean(q_p[t - w + 1 : t + 1])\n\n    # 7. Compute the discrete slope of the smoothed quantiles.\n    slopes = np.zeros_like(q_p)\n    # The slope is defined for t >= w.\n    for t in range(w, T):\n        slopes[t] = q_p_hat[t] - q_p_hat[t - 1]\n\n    # 8. Search for the early stopping epoch t_star.\n    t_star = T\n    t_search_start = max(w, t_warm)\n\n    # The latest possible start of a valid sequence is T - s_consec.\n    # The loop should go up to and including this value.\n    for t_candidate in range(t_search_start, T - s_consec + 1):\n        # Check if the slope is below the threshold for s_consec consecutive epochs.\n        sub_slopes = slopes[t_candidate : t_candidate + s_consec]\n        if np.all(sub_slopes <= -gamma):\n            t_star = t_candidate\n            break  # Found the earliest such epoch\n    \n    return t_star\n\n\ndef solve():\n    \"\"\"\n    Defines the test suite and runs the simulation for each case.\n    \"\"\"\n    test_cases = [\n        # Case A (happy path, moderate noise, clear memorization onset)\n        {\"n\": 4000, \"rho\": 0.3, \"T\": 60, \"s_seed\": 42, \"alpha\": 0.12, \"beta\": 0.25, \n         \"t_m\": 25, \"sigma\": 0.03, \"p\": 0.9, \"w\": 3, \"gamma\": 0.04, \n         \"s_consec\": 2, \"t_warm\": 5},\n\n        # Case B (boundary: no label noise)\n        {\"n\": 4000, \"rho\": 0.0, \"T\": 60, \"s_seed\": 123, \"alpha\": 0.12, \"beta\": 0.25, \n         \"t_m\": 25, \"sigma\": 0.03, \"p\": 0.9, \"w\": 3, \"gamma\": 0.2, \n         \"s_consec\": 2, \"t_warm\": 5},\n\n        # Case C (high noise, later memorization onset)\n        {\"n\": 4000, \"rho\": 0.6, \"T\": 70, \"s_seed\": 7, \"alpha\": 0.12, \"beta\": 0.20, \n         \"t_m\": 40, \"sigma\": 0.03, \"p\": 0.9, \"w\": 3, \"gamma\": 0.03, \n         \"s_consec\": 2, \"t_warm\": 5},\n\n        # Case D (edge: small dataset and very slow memorization)\n        {\"n\": 300, \"rho\": 0.4, \"T\": 50, \"s_seed\": 999, \"alpha\": 0.08, \"beta\": 0.05, \n         \"t_m\": 30, \"sigma\": 0.04, \"p\": 0.9, \"w\": 4, \"gamma\": 0.03, \n         \"s_consec\": 3, \"t_warm\": 5},\n    ]\n\n    results = []\n    for params in test_cases:\n        result = run_simulation(**params)\n        results.append(result)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n\n```", "id": "3119110"}]}