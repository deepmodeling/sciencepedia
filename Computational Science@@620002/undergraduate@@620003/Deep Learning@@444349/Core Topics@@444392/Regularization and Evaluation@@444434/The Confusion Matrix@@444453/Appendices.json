{"hands_on_practices": [{"introduction": "The first step toward mastering model evaluation is achieving fluency with the fundamental metrics derived from a confusion matrix. This exercise provides a concrete scenario with a $2 \\times 2$ confusion matrix and challenges you to calculate sensitivity, specificity, predictive values, and overall accuracy. By working through these calculations, you will solidify your understanding of how these essential performance indicators are computed from raw classification counts. [@problem_id:2524028]", "problem": "A clinical microbiology laboratory evaluates a new real-time Polymerase Chain Reaction (PCR) assay for rapid detection of a bloodstream pathogen, using aerobic blood culture as the reference standard. Over a defined evaluation period, the assay and the reference standard are applied in parallel to the same set of patient specimens. The resulting $2\\times 2$ confusion matrix yields the following counts: true positives (TP) $= 94$, false positives (FP) $= 6$, false negatives (FN) $= 10$, and true negatives (TN) $= 890$. Using the foundational definitions of diagnostic performance in microbial diagnostics, where sensitivity is the probability of a positive test among infected individuals, specificity is the probability of a negative test among uninfected individuals, Positive Predictive Value (PPV) is the probability of infection given a positive test, Negative Predictive Value (NPV) is the probability of no infection given a negative test, and overall accuracy is the probability the test result matches the reference standard, compute the point estimates of sensitivity, specificity, PPV, NPV, and accuracy.\n\nThen, for each of these five proportions, construct the Wilson score interval at $95\\%$ confidence rooted in the binomial model for counts, without continuity correction. Round all reported values (point estimates and each confidence bound) to four significant figures. Express the final values as unitless decimals (do not use percentage notation). Your final answer must list, in this exact order, the $15$ numbers: sensitivity, its lower and upper confidence bounds, specificity, its lower and upper confidence bounds, PPV, its lower and upper confidence bounds, NPV, its lower and upper confidence bounds, accuracy, its lower and upper confidence bounds.", "solution": "The problem statement has been subjected to rigorous validation prior to any attempt at a solution.\n\nThe givens are the counts from a $2 \\times 2$ confusion matrix for a diagnostic test evaluation:\n- True Positives ($TP$) $= 94$\n- False Positives ($FP$) $= 6$\n- False Negatives ($FN$) $= 10$\n- True Negatives ($TN$) $= 890$\n\nThe task is to compute point estimates and $95\\%$ Wilson score confidence intervals for five standard performance metrics: sensitivity, specificity, positive predictive value (PPV), negative predictive value (NPV), and accuracy.\n\nThis problem is scientifically grounded, well-posed, and objective. It presents a complete and consistent dataset typical of a clinical microbiology study. The definitions provided are standard, and the statistical methods stipulated are appropriate and unambiguous. No scientific, logical, or structural flaws are present. Therefore, the problem is ruled valid, and we proceed with a formal derivation of the solution.\n\nFirst, we establish the necessary totals from the given counts. The population is stratified by the reference standard (true condition) and the new test's results.\n- Total with the condition (Infected): $P = TP + FN = 94 + 10 = 104$.\n- Total without the condition (Uninfected): $N = TN + FP = 890 + 6 = 896$.\n- Total positive test results: $T_{P} = TP + FP = 94 + 6 = 100$.\n- Total negative test results: $T_{N} = TN + FN = 890 + 10 = 900$.\n- Total population: $S = TP + FP + FN + TN = 94 + 6 + 10 + 890 = 1000$.\n\nFor each metric, we will calculate the point estimate, $\\hat{p}$, and its $95\\%$ Wilson score confidence interval $(L, U)$. The Wilson interval for a proportion $\\hat{p} = k/n$ (where $k$ is the number of successes in $n$ trials) is given by:\n$$ (L, U) = \\frac{1}{1 + \\frac{z^2}{n}} \\left( \\hat{p} + \\frac{z^2}{2n} \\pm z \\sqrt{\\frac{\\hat{p}(1-\\hat{p})}{n} + \\frac{z^2}{4n^2}} \\right) $$\nFor a $95\\%$ confidence level, $\\alpha = 0.05$, and the standard normal variate is $z = z_{1-\\alpha/2} = z_{0.975} \\approx 1.959964$. All final values must be rounded to four significant figures.\n\n1. Sensitivity (Sens)\nSensitivity is the proportion of correctly identified positives among all individuals with the condition.\n- Point Estimate: $Sens = \\frac{TP}{TP+FN} = \\frac{94}{104} \\approx 0.903846 \\ldots$\nRounded to four significant figures, $Sens = 0.9038$.\n- Wilson Interval: Here, $k = 94$ and $n = 104$.\nThe resulting interval is $[0.831988\\ldots, 0.946928\\ldots]$.\nLower bound, $L_{Sens} = 0.8320$.\nUpper bound, $U_{Sens} = 0.9469$.\n\n2. Specificity (Spec)\nSpecificity is the proportion of correctly identified negatives among all individuals without the condition.\n- Point Estimate: $Spec = \\frac{TN}{TN+FP} = \\frac{890}{896} \\approx 0.993303 \\ldots$\nRounded to four significant figures, $Spec = 0.9933$.\n- Wilson Interval: Here, $k = 890$ and $n = 896$.\nThe resulting interval is $[0.985472\\ldots, 0.996928\\ldots]$.\nLower bound, $L_{Spec} = 0.9855$.\nUpper bound, $U_{Spec} = 0.9969$.\n\n3. Positive Predictive Value (PPV)\nPPV is the proportion of true positives among all individuals with a positive test result.\n- Point Estimate: $PPV = \\frac{TP}{TP+FP} = \\frac{94}{100} = 0.94$.\nAs a decimal with four significant figures, $PPV = 0.9400$.\n- Wilson Interval: Here, $k = 94$ and $n = 100$.\nThe resulting interval is $[0.875231\\ldots, 0.972210\\ldots]$.\nLower bound, $L_{PPV} = 0.8752$.\nUpper bound, $U_{PPV} = 0.9722$.\n\n4. Negative Predictive Value (NPV)\nNPV is the proportion of true negatives among all individuals with a negative test result.\n- Point Estimate: $NPV = \\frac{TN}{TN+FN} = \\frac{890}{900} \\approx 0.988888 \\ldots$\nRounded to four significant figures, $NPV = 0.9889$.\n- Wilson Interval: Here, $k = 890$ and $n = 900$.\nThe resulting interval is $[0.979671\\ldots, 0.993949\\ldots]$.\nLower bound, $L_{NPV} = 0.9797$.\nUpper bound, $U_{NPV} = 0.9939$.\n\n5. Accuracy (Acc)\nAccuracy is the proportion of correct results (both true positives and true negatives) among the total population.\n- Point Estimate: $Acc = \\frac{TP+TN}{TP+FP+FN+TN} = \\frac{94+890}{1000} = \\frac{984}{1000} = 0.984$.\nAs a decimal with four significant figures, $Acc = 0.9840$.\n- Wilson Interval: Here, $k = 984$ and $n = 1000$.\nThe resulting interval is $[0.974168\\ldots, 0.990126\\ldots]$.\nLower bound, $L_{Acc} = 0.9742$.\nUpper bound, $U_{Acc} = 0.9901$.\n\nThe final set of $15$ requested values, rounded to four significant figures, is now compiled.", "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n0.9038 & 0.8320 & 0.9469 & 0.9933 & 0.9855 & 0.9969 & 0.9400 & 0.8752 & 0.9722 & 0.9889 & 0.9797 & 0.9939 & 0.9840 & 0.9742 & 0.9901\n\\end{pmatrix}\n}\n$$", "id": "2524028"}, {"introduction": "While overall accuracy is an intuitive metric, it can often be misleading, especially when dealing with imbalanced datasets or when different types of errors have different costs. This problem presents a thought experiment designed to reveal the limitations of accuracy and the importance of the $F_1$-score. You will analyze how two systems can have identical accuracy but vastly different performance profiles by exploring the underlying trade-off between precision ($P$) and recall ($R$). [@problem_id:3094202]", "problem": "A binary classifier is evaluated on a dataset summarized by a confusion matrix with entries $(TP, FP, TN, FN)$, where $TP$ denotes the number of true positives, $FP$ denotes the number of false positives, $TN$ denotes the number of true negatives, and $FN$ denotes the number of false negatives. Accuracy ($( \\text{Acc} )$) is defined by $ \\text{Acc} = \\dfrac{TP + TN}{TP + FP + TN + FN} $. Precision ($( P )$) and recall ($( R )$) are defined by $ P = \\dfrac{TP}{TP + FP} $ and $ R = \\dfrac{TP}{TP + FN} $, respectively. The $\\text{F}_{1}$-score ($( F_1 )$) is the standard single-number summary of $P$ and $R$.\n\nSelect the single option that presents two confusion matrices $(TP, FP, TN, FN)$ for two systems, say System $X$ and System $Y$, that have the same $ \\text{Acc} $ but drastically different $ F_1 $ (interpret “drastically different” as a difference of at least $0.30$ in $F_1$), and that also provides the correct structural explanation of why $F_1$ differs, stated in terms of $P$ and $R$ and grounded in how $FP$ and $FN$ differ. Only one option satisfies both the numerical and explanatory requirements.\n\nA. System $X$: $(TP, FP, TN, FN) = (20, 5, 895, 80)$; System $Y$: $(TP, FP, TN, FN) = (80, 65, 835, 20)$. Explanation: Both systems have the same $TP + TN$, so $ \\text{Acc} $ matches. $F_1$ differs because $FP$ and $FN$ are traded off: System $X$ has small $FP$ (high $P$) but large $FN$ (low $R$); System $Y$ has larger $FP$ (lower $P$) but smaller $FN$ (higher $R$), yielding a substantially different harmonic balance of $P$ and $R$.\n\nB. System $X$: $(TP, FP, TN, FN) = (50, 50, 850, 50)$; System $Y$: $(TP, FP, TN, FN) = (45, 45, 855, 55)$. Explanation: Because both have the same $ \\text{Acc} $, their $F_1$ scores are necessarily equal; $F_1$ is determined solely by $ \\text{Acc} $.\n\nC. System $X$: $(TP, FP, TN, FN) = (10, 10, 980, 0)$; System $Y$: $(TP, FP, TN, FN) = (10, 0, 970, 20)$. Explanation: Their $ \\text{Acc} $ values are equal and $F_1$ differs because the number of true negatives $TN$ drives $F_1$ directly.\n\nD. System $X$: $(TP, FP, TN, FN) = (90, 10, 890, 10)$; System $Y$: $(TP, FP, TN, FN) = (80, 0, 900, 20)$. Explanation: Any $F_1$ difference here is caused primarily by changing $TN$, since $TN$ appears in the denominators of $P$ and $R$ and directly alters both.", "solution": "The user has requested a critical validation of the problem statement, followed by a full derivation and evaluation of the options provided.\n\n### Problem Validation\n\n**Step 1: Extract Givens**\n\nThe problem provides the following definitions and conditions for a binary classifier evaluated on a dataset:\n- Confusion matrix entries: $(TP, FP, TN, FN)$, representing true positives, false positives, true negatives, and false negatives.\n- Accuracy definition: $ \\text{Acc} = \\dfrac{TP + TN}{TP + FP + TN + FN} $.\n- Precision definition: $ P = \\dfrac{TP}{TP + FP} $.\n- Recall definition: $ R = \\dfrac{TP}{TP + FN} $.\n- The $\\text{F}_{1}$-score, $( F_1 )$, is defined as \"the standard single-number summary of $P$ and $R$\".\n- The task is to select the single option that presents two confusion matrices for System $X$ and System $Y$ that satisfy two numerical criteria and one explanatory criterion:\n    1.  The accuracies are the same: $\\text{Acc}_X = \\text{Acc}_Y$.\n    2.  The $F_1$ scores are \"drastically different\", interpreted as a difference of at least $0.30$: $|F_{1,X} - F_{1,Y}| \\geq 0.30$.\n    3.  The option provides the correct structural explanation for the difference in $F_1$ in terms of $P$, $R$, $FP$, and $FN$.\n\n**Step 2: Validate Using Extracted Givens**\n\n- **Scientifically Grounded:** The problem is based on fundamental and standard metrics used in statistical learning and model evaluation. The definitions for accuracy, precision, and recall are correct. The reference to the $F_1$-score as the \"standard single-number summary\" correctly points to the harmonic mean of precision and recall, a well-established concept.\n- **Well-Posed:** The problem is a multiple-choice question requiring the application of given formulas and evaluation of logical explanations. The term \"drastically different\" is given a precise quantitative meaning ($|F_{1,X} - F_{1,Y}| \\geq 0.30$), removing ambiguity. The problem is structured to have a single correct answer satisfying both numerical and explanatory criteria.\n- **Objective:** The problem statement is written in precise, objective language, using mathematical definitions. There is no subjectivity.\n- **Completeness and Consistency:** All necessary definitions and data (within the options) are provided to solve the problem. The reference to the standard $F_1$ score is unambiguous in this context. The problem is internally consistent.\n\n**Step 3: Verdict and Action**\n\nThe problem statement is valid. It is scientifically sound, well-posed, and objective. I will proceed with the solution.\n\n### Solution Derivation\n\nThe $F_1$-score is the harmonic mean of precision ($P$) and recall ($R$). Its standard formula is:\n$$ F_1 = 2 \\cdot \\frac{P \\cdot R}{P + R} $$\nSubstituting the definitions of $P$ and $R$ gives a formula directly in terms of the confusion matrix components:\n$$ F_1 = 2 \\cdot \\frac{\\frac{TP}{TP + FP} \\cdot \\frac{TP}{TP + FN}}{\\frac{TP}{TP + FP} + \\frac{TP}{TP + FN}} = \\frac{2 \\cdot TP}{2 \\cdot TP + FP + FN} $$\nThis latter form is computationally convenient. The total number of samples is $N = TP + FP + TN + FN$. Accuracy can be written as $\\text{Acc} = \\frac{TP + TN}{N}$.\n\nWe will now evaluate each option by calculating the required metrics and assessing the validity of the provided explanation.\n\n**Analysis of Option A**\n\nSystem $X$: $(TP, FP, TN, FN) = (20, 5, 895, 80)$\n- Total samples: $N_X = 20 + 5 + 895 + 80 = 1000$.\n- Accuracy: $\\text{Acc}_X = \\frac{20 + 895}{1000} = \\frac{915}{1000} = 0.915$.\n- Precision: $P_X = \\frac{20}{20 + 5} = \\frac{20}{25} = 0.8$.\n- Recall: $R_X = \\frac{20}{20 + 80} = \\frac{20}{100} = 0.2$.\n- $F_1$-score: $F_{1,X} = \\frac{2 \\cdot TP_X}{2 \\cdot TP_X + FP_X + FN_X} = \\frac{2 \\cdot 20}{2 \\cdot 20 + 5 + 80} = \\frac{40}{40 + 85} = \\frac{40}{125} = 0.32$.\n\nSystem $Y$: $(TP, FP, TN, FN) = (80, 65, 835, 20)$\n- Total samples: $N_Y = 80 + 65 + 835 + 20 = 1000$.\n- Accuracy: $\\text{Acc}_Y = \\frac{80 + 835}{1000} = \\frac{915}{1000} = 0.915$.\n- Precision: $P_Y = \\frac{80}{80 + 65} = \\frac{80}{145} = \\frac{16}{29} \\approx 0.5517$.\n- Recall: $R_Y = \\frac{80}{80 + 20} = \\frac{80}{100} = 0.8$.\n- $F_1$-score: $F_{1,Y} = \\frac{2 \\cdot TP_Y}{2 \\cdot TP_Y + FP_Y + FN_Y} = \\frac{2 \\cdot 80}{2 \\cdot 80 + 65 + 20} = \\frac{160}{160 + 85} = \\frac{160}{245} = \\frac{32}{49} \\approx 0.6531$.\n\n**Evaluation of Option A:**\n1.  **Equal Accuracy:** $\\text{Acc}_X = 0.915$ and $\\text{Acc}_Y = 0.915$. This condition is satisfied.\n2.  **F1 Difference:** $|F_{1,X} - F_{1,Y}| = |0.32 - 0.6531| = 0.3331$. Since $0.3331 \\geq 0.30$, this condition is satisfied.\n3.  **Explanation:** The explanation states that $\\text{Acc}$ matches because $TP + TN$ is the same ($915$) for both, while the total $N$ is also the same ($1000$). This is correct. It further explains that $F_1$ differs because of a trade-off between $FP$ and $FN$. System $X$ has low $FP$ ($5$) and high $FN$ ($80$), resulting in high $P$ ($0.8$) and low $R$ ($0.2$). System $Y$ has high $FP$ ($65$) and low $FN$ ($20$), resulting in lower $P$ ($\\approx 0.55$) and high $R$ ($0.8$). This trade-off between $P$ and $R$ causes the difference in the $F_1$-score, which as a harmonic mean is sensitive to such imbalances. The explanation is structurally and factually correct.\n\nVerdict for Option A: **Correct**.\n\n**Analysis of Option B**\n\nSystem $X$: $(TP, FP, TN, FN) = (50, 50, 850, 50)$\nSystem $Y$: $(TP, FP, TN, FN) = (45, 45, 855, 55)$\n- $\\text{Acc}_X = \\frac{50 + 850}{1000} = 0.9$.\n- $\\text{Acc}_Y = \\frac{45 + 855}{1000} = 0.9$.\nThe accuracies are equal.\n- $F_{1,X} = \\frac{2 \\cdot 50}{2 \\cdot 50 + 50 + 50} = \\frac{100}{200} = 0.5$.\n- $F_{1,Y} = \\frac{2 \\cdot 45}{2 \\cdot 45 + 45 + 55} = \\frac{90}{90 + 100} = \\frac{90}{190} = \\frac{9}{19} \\approx 0.4737$.\n- $|F_{1,X} - F_{1,Y}| = |0.5 - 0.4737| \\approx 0.0263$. This is not $\\geq 0.30$.\n- **Explanation:** The explanation claims \"Because both have the same $ \\text{Acc} $, their $F_1$ scores are necessarily equal; $F_1$ is determined solely by $ \\text{Acc} $.\" This statement is fundamentally false. Accuracy and $F_1$-score are different metrics that are not deterministically linked. Our analysis of Option A has already provided a counterexample.\n\nVerdict for Option B: **Incorrect**.\n\n**Analysis of Option C**\n\nSystem $X$: $(TP, FP, TN, FN) = (10, 10, 980, 0)$\nSystem $Y$: $(TP, FP, TN, FN) = (10, 0, 970, 20)$\n- $\\text{Acc}_X = \\frac{10 + 980}{1000} = 0.99$.\n- $\\text{Acc}_Y = \\frac{10 + 970}{1000} = 0.98$.\n- The accuracies are not equal ($\\text{Acc}_X \\neq \\text{Acc}_Y$). The first condition of the problem is not met.\n- **Explanation:** The explanation contains two false statements. First, it incorrectly claims the accuracies are equal. Second, it claims \"$TN$ drives $F_1$ directly.\" The formula for $F_1$ is $F_1 = \\frac{2 \\cdot TP}{2 \\cdot TP + FP + FN}$, which does not include the $TN$ term. Therefore, $TN$ has no direct effect on the $F_1$-score.\n\nVerdict for Option C: **Incorrect**.\n\n**Analysis of Option D**\n\nSystem $X$: $(TP, FP, TN, FN) = (90, 10, 890, 10)$\nSystem $Y$: $(TP, FP, TN, FN) = (80, 0, 900, 20)$\n- $\\text{Acc}_X = \\frac{90 + 890}{1000} = 0.98$.\n- $\\text{Acc}_Y = \\frac{80 + 900}{1000} = 0.98$.\nThe accuracies are equal.\n- $F_{1,X} = \\frac{2 \\cdot 90}{2 \\cdot 90 + 10 + 10} = \\frac{180}{200} = 0.9$.\n- $F_{1,Y} = \\frac{2 \\cdot 80}{2 \\cdot 80 + 0 + 20} = \\frac{160}{180} = \\frac{8}{9} \\approx 0.8889$.\n- $|F_{1,X} - F_{1,Y}| = |0.9 - 0.8889| \\approx 0.0111$. This is not $\\geq 0.30$.\n- **Explanation:** The explanation claims the $F_1$ difference is \"caused primarily by changing $TN$, since $TN$ appears in the denominators of $P$ and $R$\". This is factually incorrect. The formulas for $P$ and $R$ are $P = \\frac{TP}{TP + FP}$ and $R = \\frac{TP}{TP + FN}$. The $TN$ term does not appear in either formula, nor in the formula for $F_1$.\n\nVerdict for Option D: **Incorrect**.\n\nBased on the detailed analysis, only Option A satisfies all the stated numerical and explanatory requirements.", "answer": "$$\\boxed{A}$$", "id": "3094202"}, {"introduction": "Real-world datasets are rarely balanced, and a classifier that simply predicts the majority class can achieve high overall accuracy while being practically useless. This practice explores the critical distinction between overall accuracy and balanced accuracy in the context of class imbalance. You will compare two classifiers to understand how optimizing for balanced accuracy can sometimes lead to a lower overall accuracy, and reason about the scenarios where this trade-off is not only acceptable but desirable. [@problem_id:3181064]", "problem": "Consider a binary classification task with a highly imbalanced dataset of size $N = 1000$, containing $100$ positive instances and $900$ negative instances. Two classifiers, denoted $\\mathcal{A}$ and $\\mathcal{B}$, are evaluated on this dataset and produce the following confusion matrices (entries are counts of instances): for $\\mathcal{A}$, $\\mathrm{TP} = 20$, $\\mathrm{FN} = 80$, $\\mathrm{TN} = 891$, and $\\mathrm{FP} = 9$; for $\\mathcal{B}$, $\\mathrm{TP} = 80$, $\\mathrm{FN} = 20$, $\\mathrm{TN} = 810$, and $\\mathrm{FP} = 90$. Using only the core definitions of confusion matrix quantities and the standard rates derived from them, reason from first principles to determine which metric each classifier optimizes, and whether choosing a classifier that optimizes a per-class-averaged measure can reduce prevalence-weighted overall accuracy. Then, based on that reasoning, select all correct statements from the options below. Do not assume any unstated formulas; base your answer on the definitions of counts and rates implied by the confusion matrix.\n\nA. Classifier $\\mathcal{A}$ has higher overall accuracy but lower balanced accuracy than classifier $\\mathcal{B}$; this pattern can occur in imbalanced data because per-class averaging treats minority and majority classes equally.\n\nB. Classifier $\\mathcal{B}$ has higher overall accuracy and higher balanced accuracy than classifier $\\mathcal{A}$; the phenomenon that optimizing a per-class-averaged measure can reduce overall accuracy cannot occur.\n\nC. Optimizing for balanced accuracy is desirable when class priors are highly imbalanced and errors in the minority and majority classes are considered comparably important, or when recall for the minority class is a primary objective, because per-class averaging counteracts prevalence dominance.\n\nD. Optimizing for balanced accuracy is undesirable when the objective is to minimize the total number of mistakes under equal per-instance misclassification costs, since overall accuracy already weights classes by prevalence.\n\nE. If two classifiers have the same balanced accuracy, then they must also have the same overall accuracy, regardless of class imbalance.", "solution": "The problem statement is first subjected to a rigorous validation process.\n\n### Step 1: Extract Givens\n- Total dataset size: $N = 1000$\n- Number of positive instances: $P = 100$\n- Number of negative instances: $N_{neg} = 900$ (to avoid confusion with total size $N$, let's denote this by $N_{neg}$)\n- Classifier $\\mathcal{A}$ confusion matrix counts: $\\mathrm{TP}_{\\mathcal{A}} = 20$, $\\mathrm{FN}_{\\mathcal{A}} = 80$, $\\mathrm{TN}_{\\mathcal{A}} = 891$, $\\mathrm{FP}_{\\mathcal{A}} = 9$\n- Classifier $\\mathcal{B}$ confusion matrix counts: $\\mathrm{TP}_{\\mathcal{B}} = 80$, $\\mathrm{FN}_{\\mathcal{B}} = 20$, $\\mathrm{TN}_{\\mathcal{B}} = 810$, $\\mathrm{FP}_{\\mathcal{B}} = 90$\n\n### Step 2: Validate Using Extracted Givens\nThe problem is situated within the standard framework of binary classification evaluation in statistical learning. We must verify the internal consistency of the provided data.\n\n1.  **Consistency of Positive Class Counts:** The total number of positive instances, $P$, must equal the sum of true positives and false negatives ($\\mathrm{TP} + \\mathrm{FN}$).\n    - For classifier $\\mathcal{A}$: $\\mathrm{TP}_{\\mathcal{A}} + \\mathrm{FN}_{\\mathcal{A}} = 20 + 80 = 100$. This matches the given $P = 100$.\n    - For classifier $\\mathcal{B}$: $\\mathrm{TP}_{\\mathcal{B}} + \\mathrm{FN}_{\\mathcal{B}} = 80 + 20 = 100$. This also matches the given $P = 100$.\n\n2.  **Consistency of Negative Class Counts:** The total number of negative instances, $N_{neg}$, must equal the sum of true negatives and false positives ($\\mathrm{TN} + \\mathrm{FP}$).\n    - For classifier $\\mathcal{A}$: $\\mathrm{TN}_{\\mathcal{A}} + \\mathrm{FP}_{\\mathcal{A}} = 891 + 9 = 900$. This matches the given $N_{neg} = 900$.\n    - For classifier $\\mathcal{B}$: $\\mathrm{TN}_{\\mathcal{B}} + \\mathrm{FP}_{\\mathcal{B}} = 810 + 90 = 900$. This also matches the given $N_{neg} = 900$.\n\n3.  **Consistency of Total Dataset Size:** The total dataset size, $N$, must equal the sum of all confusion matrix entries.\n    - For classifier $\\mathcal{A}$: $\\mathrm{TP}_{\\mathcal{A}} + \\mathrm{FN}_{\\mathcal{A}} + \\mathrm{TN}_{\\mathcal{A}} + \\mathrm{FP}_{\\mathcal{A}} = 20 + 80 + 891 + 9 = 1000$. This matches the given $N=1000$.\n    - For classifier $\\mathcal{B}$: $\\mathrm{TP}_{\\mathcal{B}} + \\mathrm{FN}_{\\mathcal{B}} + \\mathrm{TN}_{\\mathcal{B}} + \\mathrm{FP}_{\\mathcal{B}} = 80 + 20 + 810 + 90 = 1000$. This also matches the given $N=1000$.\n\nThe problem is scientifically grounded in established statistical theory, is well-posed with all necessary information provided, and is internally consistent. The scenario of an imbalanced dataset is realistic and common in practice. The language is objective and precise.\n\n### Step 3: Verdict and Action\nThe problem statement is **valid**. We proceed to the solution.\n\n### Derivation and Option Analysis\n\nWe will derive the relevant metrics from first principles for both classifiers. The core metrics are the True Positive Rate (TPR), True Negative Rate (TNR), Overall Accuracy (ACC), and Balanced Accuracy (BA). Let $P$ be the number of positive instances and $N_{neg}$ be the number of negative instances.\n\n- **True Positive Rate (TPR)** or **Recall**: $\\mathrm{TPR} = \\frac{\\mathrm{TP}}{P} = \\frac{\\mathrm{TP}}{\\mathrm{TP} + \\mathrm{FN}}$\n- **True Negative Rate (TNR)** or **Specificity**: $\\mathrm{TNR} = \\frac{\\mathrm{TN}}{N_{neg}} = \\frac{\\mathrm{TN}}{\\mathrm{TN} + \\mathrm{FP}}$\n- **Overall Accuracy (ACC)**: $\\mathrm{ACC} = \\frac{\\mathrm{TP} + \\mathrm{TN}}{P + N_{neg}}$\n- **Balanced Accuracy (BA)**: $\\mathrm{BA} = \\frac{\\mathrm{TPR} + \\mathrm{TNR}}{2}$\n\nThe given dataset has $P=100$ and $N_{neg}=900$.\n\n**Calculations for Classifier $\\mathcal{A}$:**\n- $\\mathrm{TPR}_{\\mathcal{A}} = \\frac{\\mathrm{TP}_{\\mathcal{A}}}{P} = \\frac{20}{100} = 0.2$\n- $\\mathrm{TNR}_{\\mathcal{A}} = \\frac{\\mathrm{TN}_{\\mathcal{A}}}{N_{neg}} = \\frac{891}{900} = 0.99$\n- $\\mathrm{ACC}_{\\mathcal{A}} = \\frac{\\mathrm{TP}_{\\mathcal{A}} + \\mathrm{TN}_{\\mathcal{A}}}{P + N_{neg}} = \\frac{20 + 891}{1000} = \\frac{911}{1000} = 0.911$\n- $\\mathrm{BA}_{\\mathcal{A}} = \\frac{\\mathrm{TPR}_{\\mathcal{A}} + \\mathrm{TNR}_{\\mathcal{A}}}{2} = \\frac{0.2 + 0.99}{2} = \\frac{1.19}{2} = 0.595$\n\n**Calculations for Classifier $\\mathcal{B}$:**\n- $\\mathrm{TPR}_{\\mathcal{B}} = \\frac{\\mathrm{TP}_{\\mathcal{B}}}{P} = \\frac{80}{100} = 0.8$\n- $\\mathrm{TNR}_{\\mathcal{B}} = \\frac{\\mathrm{TN}_{\\mathcal{B}}}{N_{neg}} = \\frac{810}{900} = 0.90$\n- $\\mathrm{ACC}_{\\mathcal{B}} = \\frac{\\mathrm{TP}_{\\mathcal{B}} + \\mathrm{TN}_{\\mathcal{B}}}{P + N_{neg}} = \\frac{80 + 810}{1000} = \\frac{890}{1000} = 0.890$\n- $\\mathrm{BA}_{\\mathcal{B}} = \\frac{\\mathrm{TPR}_{\\mathcal{B}} + \\mathrm{TNR}_{\\mathcal{B}}}{2} = \\frac{0.8 + 0.9}{2} = \\frac{1.7}{2} = 0.85$\n\n**Comparison:**\n- Overall Accuracy: $\\mathrm{ACC}_{\\mathcal{A}} (0.911) > \\mathrm{ACC}_{\\mathcal{B}} (0.890)$\n- Balanced Accuracy: $\\mathrm{BA}_{\\mathcal{A}} (0.595) < \\mathrm{BA}_{\\mathcal{B}} (0.85)$\n\nClassifier $\\mathcal{A}$ favors performance on the majority (negative) class, achieving a very high $\\mathrm{TNR}_{\\mathcal{A}}$ of $0.99$ at the cost of a very low $\\mathrm{TPR}_{\\mathcal{A}}$ of $0.2$. This strategy maximizes overall accuracy due to the high prevalence ($90\\%$) of the negative class. Classifier $\\mathcal{B}$ has more balanced performance across classes, achieving high $\\mathrm{TPR}_{\\mathcal{B}}$ ($0.8$) and $\\mathrm{TNR}_{\\mathcal{B}}$ ($0.9$), resulting in a much higher balanced accuracy but a slightly lower overall accuracy.\n\nNow, we evaluate each option.\n\n**A. Classifier $\\mathcal{A}$ has higher overall accuracy but lower balanced accuracy than classifier $\\mathcal{B}$; this pattern can occur in imbalanced data because per-class averaging treats minority and majority classes equally.**\n- The first clause, \"Classifier $\\mathcal{A}$ has higher overall accuracy but lower balanced accuracy than classifier $\\mathcal{B}$,\" is confirmed by our calculations ($0.911 > 0.890$ for ACC, and $0.595 < 0.85$ for BA).\n- The reasoning provided is that \"per-class averaging treats minority and majority classes equally.\" Balanced accuracy is the arithmetic mean of per-class accuracies (TPR and TNR), giving each class a weight of $1/2$. Overall accuracy can be expressed as a weighted average: $\\mathrm{ACC} = \\pi_P \\cdot \\mathrm{TPR} + \\pi_{N_{neg}} \\cdot \\mathrm{TNR}$, where $\\pi_P = P/(P+N_{neg}) = 0.1$ and $\\pi_{N_{neg}} = N_{neg}/(P+N_{neg}) = 0.9$ are the class prevalences. The high prevalence of the negative class, $\\pi_{N_{neg}}=0.9$, means overall accuracy is dominated by TNR. Balanced accuracy's equal weighting counteracts this. The statement is entirely correct.\n- Verdict: **Correct**.\n\n**B. Classifier $\\mathcal{B}$ has higher overall accuracy and higher balanced accuracy than classifier $\\mathcal{A}$; the phenomenon that optimizing a per-class-averaged measure can reduce overall accuracy cannot occur.**\n- The first clause, \"Classifier $\\mathcal{B}$ has higher overall accuracy,\" is false, as $\\mathrm{ACC}_{\\mathcal{B}} = 0.890 < \\mathrm{ACC}_{\\mathcal{A}} = 0.911$.\n- The second clause, \"the phenomenon that optimizing a per-class-averaged measure can reduce overall accuracy cannot occur,\" is also false. This exact problem provides a counterexample: classifier $\\mathcal{B}$ has a significantly higher balanced accuracy but a lower overall accuracy than classifier $\\mathcal{A}$. Choosing $\\mathcal{B}$ over $\\mathcal{A}$ (optimizing for BA) reduces ACC.\n- Verdict: **Incorrect**.\n\n**C. Optimizing for balanced accuracy is desirable when class priors are highly imbalanced and errors in the minority and majority classes are considered comparably important, or when recall for the minority class is a primary objective, because per-class averaging counteracts prevalence dominance.**\n- This is a conceptual statement about the utility of balanced accuracy. When class priors are imbalanced, a model can achieve high overall accuracy by simply predicting the majority class. If errors in both classes are \"comparably important,\" a metric that weights class performance by prevalence (like overall accuracy) is inappropriate. Balanced accuracy gives equal weight to each class's performance, fulfilling this need. Furthermore, to achieve a high balanced accuracy, a classifier cannot afford to have a very low TPR (minority class recall), making it a suitable objective when minority recall is important. The reason for this behavior is correctly identified as \"per-class averaging counteracts prevalence dominance.\" The statement is a clear and accurate description of the motivation for using balanced accuracy.\n- Verdict: **Correct**.\n\n**D. Optimizing for balanced accuracy is undesirable when the objective is to minimize the total number of mistakes under equal per-instance misclassification costs, since overall accuracy already weights classes by prevalence.**\n- The objective \"to minimize the total number of mistakes\" is mathematically equivalent to minimizing the sum $\\mathrm{FN} + \\mathrm{FP}$. Overall accuracy is defined as $\\mathrm{ACC} = 1 - \\frac{\\mathrm{FN} + \\mathrm{FP}}{N_{total}}$. Therefore, maximizing overall accuracy is equivalent to minimizing the total number of mistakes.\n- Our example shows that classifier $\\mathcal{A}$ has higher ACC ($0.911$) and fewer total mistakes ($\\mathrm{FN}_{\\mathcal{A}} + \\mathrm{FP}_{\\mathcal{A}} = 80+9=89$). Classifier $\\mathcal{B}$ has higher BA ($0.85$) but more total mistakes ($\\mathrm{FN}_{\\mathcal{B}} + \\mathrm{FP}_{\\mathcal{B}} = 20+90=110$). If the goal is to minimize total mistakes, one should prefer $\\mathcal{A}$, which is the classifier with higher ACC, not higher BA. Thus, optimizing for BA would be the wrong strategy. The reasoning provided is also correct: overall accuracy achieves this objective because it weights instances equally, which means classes are weighted by prevalence.\n- Verdict: **Correct**.\n\n**E. If two classifiers have the same balanced accuracy, then they must also have the same overall accuracy, regardless of class imbalance.**\n- This statement can be proven false with a counterexample. Let $\\mathrm{BA}_{\\mathcal{C}} = \\mathrm{BA}_{\\mathcal{D}}$. This implies $\\frac{1}{2}(\\mathrm{TPR}_{\\mathcal{C}} + \\mathrm{TNR}_{\\mathcal{C}}) = \\frac{1}{2}(\\mathrm{TPR}_{\\mathcal{D}} + \\mathrm{TNR}_{\\mathcal{D}})$.\n- Overall accuracy is $\\mathrm{ACC} = \\pi_P \\mathrm{TPR} + \\pi_{N_{neg}} \\mathrm{TNR}$.\n- Assume our imbalanced dataset with $\\pi_P = 0.1$ and $\\pi_{N_{neg}} = 0.9$.\n- Let classifier $\\mathcal{C}$ have $\\mathrm{TPR}_{\\mathcal{C}} = 0.9$ and $\\mathrm{TNR}_{\\mathcal{C}} = 0.7$. Then $\\mathrm{BA}_{\\mathcal{C}} = (0.9+0.7)/2 = 0.8$. Its accuracy is $\\mathrm{ACC}_{\\mathcal{C}} = (0.1)(0.9) + (0.9)(0.7) = 0.09 + 0.63 = 0.72$.\n- Let classifier $\\mathcal{D}$ have $\\mathrm{TPR}_{\\mathcal{D}} = 0.7$ and $\\mathrm{TNR}_{\\mathcal{D}} = 0.9$. Then $\\mathrm{BA}_{\\mathcal{D}} = (0.7+0.9)/2 = 0.8$. Its accuracy is $\\mathrm{ACC}_{\\mathcal{D}} = (0.1)(0.7) + (0.9)(0.9) = 0.07 + 0.81 = 0.88$.\n- Here, $\\mathrm{BA}_{\\mathcal{C}} = \\mathrm{BA}_{\\mathcal{D}}$, but $\\mathrm{ACC}_{\\mathcal{C}} \\neq \\mathrm{ACC}_{\\mathcal{D}}$. The statement is false. It would only be true in the special case of a balanced dataset where $\\pi_P = \\pi_{N_{neg}} = 0.5$, in which case $\\mathrm{ACC} = 0.5(\\mathrm{TPR}+\\mathrm{TNR}) = \\mathrm{BA}$. The phrase \"regardless of class imbalance\" makes the statement definitively false.\n- Verdict: **Incorrect**.", "answer": "$$\\boxed{ACD}$$", "id": "3181064"}]}