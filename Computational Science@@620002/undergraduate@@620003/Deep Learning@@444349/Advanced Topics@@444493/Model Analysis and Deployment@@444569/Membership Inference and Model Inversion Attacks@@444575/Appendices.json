{"hands_on_practices": [{"introduction": "To begin our exploration of membership inference attacks, we first ground ourselves in the foundational principles of statistical decision theory. This exercise asks you to derive a Bayes-optimal decision rule for a membership inference attack in an idealized setting. By assuming a simple, well-defined statistical model for how a classifier behaves on member and non-member data, we can determine the theoretically best possible attack strategy. This practice is invaluable for building intuition, as it demonstrates precisely how overfitting—modeled here as a systematic bias in the model's output logit—creates a vulnerability that a principled attacker can exploit.", "problem": "Consider binary classification with label $y \\in \\{-1,+1\\}$ and feature vector $x \\in \\mathbb{R}^2$. The data are generated by a Gaussian discriminant model with shared covariance: $x \\mid y \\sim \\mathcal{N}(\\mu_y,\\Sigma)$ and class prior $\\mathbb{P}(y=+1)=\\mathbb{P}(y=-1)=\\tfrac{1}{2}$. The released classifier computes the Bayes posterior $p_{\\theta}(y \\mid x)$ under the true parameters $(\\mu_{+},\\mu_{-},\\Sigma)$, which for shared covariance corresponds to a logistic function with logit $s(x) = w^{\\top}x + b$, where $w = \\Sigma^{-1}(\\mu_{+}-\\mu_{-})$ and $b = -\\tfrac{1}{2}\\left(\\mu_{+}^{\\top}\\Sigma^{-1}\\mu_{+} - \\mu_{-}^{\\top}\\Sigma^{-1}\\mu_{-}\\right)$.\n\nAssume a simple overfitting effect on members of the training set: for a data point with true label $y$, the model’s reported posterior for the true class is $q(y \\mid x) = \\sigma\\!\\left(s(x) + b_M\\right)$, where $\\sigma(z) = \\tfrac{1}{1+\\exp(-z)}$ is the logistic function and $b_M = \\beta$ if the point is a member of the training set and $b_M=0$ if it is a non-member. The attacker knows $(\\mu_{+},\\mu_{-},\\Sigma)$, the bias parameter $\\beta > 0$, and the true label $y$ for the queried point, and observes the scalar $q(y \\mid x)$. The attacker’s goal is to decide membership $M \\in \\{\\text{member},\\text{non-member}\\}$ under equal priors $\\mathbb{P}(M=\\text{member})=\\mathbb{P}(M=\\text{non-member})=\\tfrac{1}{2}$.\n\nStarting from first principles of Bayes decision theory and the Gaussian discriminant model, derive the optimal (Bayes) membership inference decision for a fixed label $y$ in the form of a single threshold on the observed logit $r = \\ln\\!\\left(\\tfrac{q(y \\mid x)}{1-q(y \\mid x)}\\right)$. Then convert this threshold to the posterior probability domain, $t_p^{\\ast} = \\sigma(t^{\\ast})$.\n\nFinally, evaluate your expression for the specific parameters\n- $\\mu_{+} = \\begin{pmatrix}1 \\\\ 0\\end{pmatrix}$, $\\mu_{-} = \\begin{pmatrix}-1 \\\\ 0\\end{pmatrix}$,\n- $\\Sigma = I_2$ (the $2 \\times 2$ identity),\n- $\\beta = 0.8$,\n- and the known true label $y=+1$,\nand report the numerical value of $t_p^{\\ast}$. Round your answer to four significant figures.\n\nFor empirical validation, consider the following six observations, all with true label $y=+1$, and their membership status $M$:\n- $x^{(1)} = \\begin{pmatrix}1.1 \\\\ -0.2\\end{pmatrix}$ with $M=\\text{member}$,\n- $x^{(2)} = \\begin{pmatrix}0.8 \\\\ 0.3\\end{pmatrix}$ with $M=\\text{member}$,\n- $x^{(3)} = \\begin{pmatrix}1.2 \\\\ -0.1\\end{pmatrix}$ with $M=\\text{member}$,\n- $x^{(4)} = \\begin{pmatrix}0.6 \\\\ -0.4\\end{pmatrix}$ with $M=\\text{non-member}$,\n- $x^{(5)} = \\begin{pmatrix}1.1 \\\\ 0.2\\end{pmatrix}$ with $M=\\text{non-member}$,\n- $x^{(6)} = \\begin{pmatrix}0.7 \\\\ 0.0\\end{pmatrix}$ with $M=\\text{non-member}$.\n\nUsing the derived optimal threshold rule and the known parameters, compute the empirical attack decisions and the resulting empirical accuracy as a check of consistency. Your final reported answer must be the single number $t_p^{\\ast}$ only, rounded to four significant figures, and without units.", "solution": "The attacker's task is to decide between two hypotheses: $H_1: M=\\text{member}$ and $H_0: M=\\text{non-member}$. The attacker observes the logit $r = \\ln\\!\\left(\\tfrac{q(y \\mid x)}{1-q(y \\mid x)}\\right)$ for a data point $(x,y)$ where the true label $y$ is known. From the problem definition, the observed logit is $r = s(x) + b_M$.\nUnder the two hypotheses:\n-   $H_1: M=\\text{member} \\implies b_M = \\beta \\implies r = s(x) + \\beta$\n-   $H_0: M=\\text{non-member} \\implies b_M = 0 \\implies r = s(x)$\n\nAccording to Bayes decision theory with equal priors, the optimal decision rule is to choose the hypothesis with the higher likelihood, which means deciding 'member' if $p(r \\mid H_1) > p(r \\mid H_0)$. To find the likelihoods, we must determine the distribution of the random variable $r$, which depends on the distribution of the true logit $s(x)$. The randomness in $s(x)$ arises from the data point $x$ being drawn from its class-conditional distribution $x \\mid y \\sim \\mathcal{N}(\\mu_y, \\Sigma)$.\n\nThe logit $s(x) = w^\\top x + b$ is an affine transformation of a Gaussian random vector $x$, and is therefore a Gaussian random variable. Its class-conditional mean is $\\mathbb{E}[s(x) \\mid y] = y \\frac{\\Delta^2}{2}$ and its variance is $\\text{Var}[s(x) \\mid y] = \\Delta^2$, where $\\Delta^2 = (\\mu_{+} - \\mu_{-})^\\top \\Sigma^{-1} (\\mu_{+} - \\mu_{-})$ is the squared Mahalanobis distance between the class means.\nSo, for a known label $y$, the distribution of the true logit is $s(x) \\mid y \\sim \\mathcal{N}(y \\frac{\\Delta^2}{2}, \\Delta^2)$.\n\nThe distributions for the observed logit $r$ under both hypotheses are:\n-   $H_0$: $r = s(x) \\sim \\mathcal{N}\\left(y \\frac{\\Delta^2}{2}, \\Delta^2\\right)$\n-   $H_1$: $r = s(x) + \\beta \\sim \\mathcal{N}\\left(y \\frac{\\Delta^2}{2} + \\beta, \\Delta^2\\right)$\n\nThe optimal decision threshold for a likelihood ratio test between two Gaussians with the same variance is the midpoint of their means:\n$$ t^* = \\frac{(y\\frac{\\Delta^2}{2}) + (y\\frac{\\Delta^2}{2} + \\beta)}{2} = y\\frac{\\Delta^2}{2} + \\frac{\\beta}{2} $$\nThe attacker decides 'member' if the observed logit $r$ satisfies $r > t^*$. The problem asks for the threshold in the probability domain:\n$$ t_p^* = \\sigma(t^*) = \\sigma\\left(y\\frac{\\Delta^2}{2} + \\frac{\\beta}{2}\\right) $$\n\n**Numerical Evaluation**\nGiven the parameters: $\\mu_{+} = \\begin{pmatrix}1 \\\\ 0\\end{pmatrix}$, $\\mu_{-} = \\begin{pmatrix}-1 \\\\ 0\\end{pmatrix}$, $\\Sigma = I_2$, $\\beta = 0.8$, and true label $y=+1$.\nFirst, we calculate $\\Delta^2$:\n$$ \\mu_{+} - \\mu_{-} = \\begin{pmatrix}2 \\\\ 0\\end{pmatrix} $$\n$$ \\Delta^2 = (\\mu_{+} - \\mu_{-})^\\top \\Sigma^{-1} (\\mu_{+} - \\mu_{-}) = \\begin{pmatrix}2 & 0\\end{pmatrix} I_2 \\begin{pmatrix}2 \\\\ 0\\end{pmatrix} = 4 $$\nNext, we compute the logit threshold $t^*$ for $y=+1$:\n$$ t^* = (+1) \\cdot \\frac{4}{2} + \\frac{0.8}{2} = 2 + 0.4 = 2.4 $$\nFinally, we convert this threshold to the probability domain:\n$$ t_p^* = \\sigma(2.4) = \\frac{1}{1 + \\exp(-2.4)} \\approx \\frac{1}{1 + 0.09071795} \\approx 0.916830005 $$\nRounding to four significant figures, we get $t_p^* \\approx 0.9168$.", "answer": "$$\\boxed{0.9168}$$", "id": "3149406"}, {"introduction": "While theoretical models provide a solid foundation, real-world attackers rarely possess complete knowledge of the target model's data-generating process. Instead, they often rely on well-established heuristics that correlate with membership status. This practice shifts our focus to a more practical scenario where you will construct a composite privacy risk score, $r(x)$, by combining several of these heuristic signals: the model's predictive margin $m(x)$, its confidence entropy $H(p)$, and the norm of its training gradient $g(x)$. You will then validate the effectiveness of this score by computing the Receiver Operating Characteristic Area Under the Curve (ROC AUC), a standard and essential metric for evaluating the performance of such binary classifiers. This exercise bridges the gap between abstract theory and the empirical realities of designing and testing membership inference attacks.", "problem": "You are given a multi-class classifier with parameters implicitly defining a conditional class probability distribution for each input instance. For an input vector $x$ with raw logits $z(x) \\in \\mathbb{R}^C$, the predictive distribution is given by the softmax function, which maps logits to probabilities via $p_\\theta(k \\mid x) = \\exp(z_k(x)) \\big/ \\sum_{j=1}^C \\exp(z_j(x))$. Consider three per-instance signals derived from $p_\\theta(\\cdot \\mid x)$ and from a per-instance gradient norm provided as input: the top-two margin, the confidence entropy, and the normalized gradient norm. Your task is to define a composite privacy risk score $r(x)$ that combines these signals and to validate its effectiveness as a predictor of membership inference vulnerability by computing the Receiver Operating Characteristic Area Under the Curve (ROC AUC) for a threshold-based membership inference attack that uses $r(x)$ as the membership score.\n\nFundamental base for the derivation:\n- The softmax definition $p_\\theta(k \\mid x) = \\exp(z_k(x)) \\big/ \\sum_{j=1}^C \\exp(z_j(x))$.\n- Shannon entropy in natural units (nats): $H(p) = -\\sum_{k=1}^C p_k \\log p_k$.\n- Normalized entropy $H_{\\mathrm{norm}}(p) = H(p) / \\log C$, which lies in $[0,1]$.\n- The top-two probability margin $m(x) = p_{(1)}(x) - p_{(2)}(x)$, where $p_{(1)}(x) \\ge p_{(2)}(x)$ are the largest and second-largest entries of $p_\\theta(\\cdot \\mid x)$; thus $m(x) \\in [0,1]$.\n- A per-instance gradient norm $g(x) \\ge 0$ w.r.t. model parameters is given as input. Normalize it within each test case by the min-max transformation $g_{\\mathrm{norm}}(x) = 0$ if $g_{\\max} = g_{\\min}$, else $g_{\\mathrm{norm}}(x) = \\big(g(x) - g_{\\min}\\big) \\big/ \\big(g_{\\max} - g_{\\min}\\big)$.\n\nDefine the privacy risk score as a nonnegative weighted combination:\n$$\nr(x) = \\alpha \\cdot \\big(1 - m(x)\\big) + \\beta \\cdot H_{\\mathrm{norm}}\\!\\big(p_\\theta(\\cdot \\mid x)\\big) + \\gamma \\cdot g_{\\mathrm{norm}}(x),\n$$\nwhere $\\alpha, \\beta, \\gamma \\ge 0$ are fixed weights provided in the test cases. Intuitively, this score is higher for points where the model is uncertain (small margin, high entropy) and for which the training gradient is large. We will test the ability of this score to act as a membership signal by computing the ROC AUC, under the hypothesis that a higher score indicates a higher likelihood of membership.\n\nValidation protocol:\n- Given labels $y_{\\mathrm{mem}}(x) \\in \\{0,1\\}$ that indicate non-member ($0$) or member ($1$) status, validate $r(x)$ as a predictor by computing the ROC AUC for using $r(x)$ as a membership score, where higher $r(x)$ implies a higher likelihood of being a member. Use the equivalence between ROC AUC and the Mann–Whitney $U$ statistic: if $n_1$ is the number of members and $n_0$ is the number of non-members, and if $\\mathrm{rank}(r_i)$ are the average ranks (starting at $1$ for the smallest score) of the scores across all instances with appropriate tie averaging, then\n$$\n\\mathrm{AUC} = \\frac{U}{n_0 n_1}, \\quad \\text{where} \\quad U = \\sum_{i:\\, y_{\\mathrm{mem},i} = 1} \\mathrm{rank}(r_i) - \\frac{n_1 (n_1 + 1)}{2}.\n$$\nThis yields $\\mathrm{AUC} \\in [0,1]$, with $\\mathrm{AUC} = 0.5$ indicating chance-level discrimination.\n\nImplementation requirements:\n- For each test case below, compute probabilities via softmax from logits, then compute $m(x)$, $H_{\\mathrm{norm}}(p)$, $g_{\\mathrm{norm}}(x)$, and $r(x)$ using the provided $\\alpha$, $\\beta$, and $\\gamma$.\n- Compute the ROC AUC using the rank-based formula with average ranks for ties, treating higher $r(x)$ as higher membership likelihood.\n- Your program should produce a single line of output containing the AUC results for all test cases as a comma-separated list enclosed in square brackets, with each AUC rounded to six decimal places, for example $[0.945000,0.731234,0.500000]$.\n\nTest suite:\n- Test Case 1 (clear separation, three classes):\n  - Number of classes $C = 3$.\n  - Weights: $\\alpha = 0.5$, $\\beta = 0.3$, $\\gamma = 0.2$.\n  - Six samples with logits, gradient norms, and membership labels:\n    1. Logits $[3.0, 0.2, -1.0]$, gradient norm $0.10$, $y_{\\mathrm{mem}} = 0$.\n    2. Logits $[2.5, -0.5, 0.0]$, gradient norm $0.15$, $y_{\\mathrm{mem}} = 0$.\n    3. Logits $[-1.0, 0.0, 3.0]$, gradient norm $0.05$, $y_{\\mathrm{mem}} = 0$.\n    4. Logits $[0.5, 0.4, 0.3]$, gradient norm $0.90$, $y_{\\mathrm{mem}} = 1$.\n    5. Logits $[0.0, 0.1, 0.2]$, gradient norm $0.70$, $y_{\\mathrm{mem}} = 1$.\n    6. Logits $[0.2, 0.1, 0.2]$, gradient norm $1.20$, $y_{\\mathrm{mem}} = 1$.\n- Test Case 2 (overlap, three classes):\n  - Number of classes $C = 3$.\n  - Weights: $\\alpha = 0.5$, $\\beta = 0.3$, $\\gamma = 0.2$.\n  - Six samples with logits, gradient norms, and membership labels:\n    1. Logits $[1.5, 1.4, 1.3]$, gradient norm $0.60$, $y_{\\mathrm{mem}} = 0$.\n    2. Logits $[2.0, 0.0, 0.0]$, gradient norm $0.40$, $y_{\\mathrm{mem}} = 0$.\n    3. Logits $[0.5, -0.2, 1.0]$, gradient norm $0.55$, $y_{\\mathrm{mem}} = 0$.\n    4. Logits $[0.8, 0.7, 0.1]$, gradient norm $0.50$, $y_{\\mathrm{mem}} = 1$.\n    5. Logits $[1.8, 0.9, 0.7]$, gradient norm $0.45$, $y_{\\mathrm{mem}} = 1$.\n    6. Logits $[0.2, 0.2, 0.2]$, gradient norm $0.65$, $y_{\\mathrm{mem}} = 1$.\n- Test Case 3 (boundary condition with ties):\n  - Number of classes $C = 3$.\n  - Weights: $\\alpha = 0.5$, $\\beta = 0.3$, $\\gamma = 0.2$.\n  - Four samples with identical logits and gradient norms causing tied risk scores:\n    1. Logits $[0.0, 0.0, 0.0]$, gradient norm $0.30$, $y_{\\mathrm{mem}} = 1$.\n    2. Logits $[0.0, 0.0, 0.0]$, gradient norm $0.30$, $y_{\\mathrm{mem}} = 0$.\n    3. Logits $[0.0, 0.0, 0.0]$, gradient norm $0.30$, $y_{\\mathrm{mem}} = 1$.\n    4. Logits $[0.0, 0.0, 0.0]$, gradient norm $0.30$, $y_{\\mathrm{mem}} = 0$.\n\nYour program must implement the definitions stated above and output a single line containing the three ROC AUC values in the exact format $[a_1,a_2,a_3]$, where each $a_i$ is a float rounded to six decimal places.", "solution": "The user-provided problem statement has been critically validated and is deemed to be **valid**. It is scientifically grounded in the domain of machine learning privacy, well-posed, objective, and self-contained. All definitions, constants, and data are provided, enabling a unique and verifiable solution.\n\nThe problem requires the implementation and validation of a privacy risk score, $r(x)$, designed to quantify the vulnerability of a data instance $x$ to membership inference attacks. The solution involves a multi-step process for each test case provided. We will systematically derive the quantities required to compute the Receiver Operating Characteristic Area Under the Curve (ROC AUC), which serves as the validation metric for the risk score.\n\n**Step 1: Computation of Probability Distributions**\n\nFor each data instance, we are given a vector of raw logits, $z(x) \\in \\mathbb{R}^C$, from a $C$-class classifier. The corresponding predictive probability distribution, $p_\\theta(\\cdot \\mid x)$, is obtained via the softmax function:\n$$\np_\\theta(k \\mid x) = \\frac{\\exp(z_k(x))}{\\sum_{j=1}^C \\exp(z_j(x))}.\n$$\nTo ensure numerical stability against potential overflow or underflow with large logit values, we use the identity $p_\\theta(k \\mid x) = \\frac{\\exp(z_k(x) - z_{\\max})}{\\sum_{j=1}^C \\exp(z_j(x) - z_{\\max})}$, where $z_{\\max} = \\max_j z_j(x)$.\n\n**Step 2: Calculation of Per-Instance Signal Components**\n\nThe privacy risk score $r(x)$ is a composite of three signals. For each instance $x$, we compute:\n\n1.  **Top-Two Probability Margin, $m(x)$**: This signal measures the model's confidence in its top prediction. A small margin indicates ambiguity. Let $p_{(1)}(x)$ and $p_{(2)}(x)$ be the largest and second-largest probabilities in the distribution $p_\\theta(\\cdot \\mid x)$. The margin is:\n    $$\n    m(x) = p_{(1)}(x) - p_{(2)}(x).\n    $$\n    The term used in the risk score is $1 - m(x)$, which is larger for less confident predictions.\n\n2.  **Normalized Confidence Entropy, $H_{\\mathrm{norm}}(p)$**: This signal measures the uncertainty of the predictive distribution. Higher entropy implies greater uncertainty. The Shannon entropy is calculated in natural units (nats):\n    $$\n    H(p) = -\\sum_{k=1}^C p_k \\log p_k,\n    $$\n    where $p_k = p_\\theta(k \\mid x)$ and we define $0 \\log 0 = 0$. This entropy is then normalized to the range $[0, 1]$ by dividing by the maximum possible entropy for a $C$-class distribution, which is $\\log C$:\n    $$\n    H_{\\mathrm{norm}}(p) = \\frac{H(p)}{\\log C}.\n    $$\n\n3.  **Normalized Gradient Norm, $g_{\\mathrm{norm}}(x)$**: For each instance, an initial gradient norm $g(x)$ is provided. This value is normalized across all instances within a single test case using min-max scaling. Let $\\{g_i\\}_{i=1}^N$ be the set of gradient norms for a test case with $N$ samples. Let $g_{\\min} = \\min_i g_i$ and $g_{\\max} = \\max_i g_i$. The normalized norm for instance $i$ is:\n    $$\n    g_{\\mathrm{norm}}(x_i) = \\begin{cases}\n    0 & \\text{if } g_{\\max} = g_{\\min} \\\\\n    \\frac{g(x_i) - g_{\\min}}{g_{\\max} - g_{\\min}} & \\text{otherwise}\n    \\end{cases}.\n    $$\n    This places the gradient norms on a common scale of $[0, 1]$ for each test case.\n\n**Step 3: Computation of the Composite Privacy Risk Score, $r(x)$**\n\nThe three signals are combined into a single risk score $r(x)$ using a weighted sum, with non-negative weights $\\alpha, \\beta, \\gamma$ provided for each test case:\n$$\nr(x) = \\alpha \\cdot \\big(1 - m(x)\\big) + \\beta \\cdot H_{\\mathrm{norm}}\\!\\big(p_\\theta(\\cdot \\mid x)\\big) + \\gamma \\cdot g_{\\mathrm{norm}}(x).\n$$\nA higher score $r(x)$ is hypothesized to indicate a greater likelihood that $x$ was part of the training set (a \"member\"), corresponding to higher membership inference vulnerability.\n\n**Step 4: Validation using ROC AUC**\n\nThe effectiveness of $r(x)$ as a membership score is evaluated by calculating the ROC AUC. This metric quantifies the ability of the score to distinguish between members ($y_{\\mathrm{mem}}=1$) and non-members ($y_{\\mathrm{mem}}=0$). We use the rank-based formula for AUC, which is equivalent to the Mann-Whitney $U$ statistic normalized by the product of the number of samples in each class.\n\nLet $\\{r_i\\}_{i=1}^N$ be the set of risk scores for all $N$ instances in a test case.\n1.  **Ranking**: We first compute the rank of each score $r_i$ in the combined list of all scores. Ranks start at $1$. In case of ties, all tied scores receive the average of the ranks they would occupy. For example, if two scores are tied for the 2nd and 3rd positions, both receive rank $(2+3)/2 = 2.5$.\n2.  **U Statistic**: Let $n_1$ be the count of members and $n_0$ be the count of non-members. The Mann-Whitney $U$ statistic is calculated by summing the ranks of the scores corresponding to the member instances and subtracting a correction term:\n    $$\n    U = \\sum_{i:\\, y_{\\mathrm{mem},i} = 1} \\mathrm{rank}(r_i) - \\frac{n_1 (n_1 + 1)}{2}.\n    $$\n3.  **AUC Calculation**: The AUC is then given by:\n    $$\n    \\mathrm{AUC} = \\frac{U}{n_0 n_1}.\n    $$\nThis value ranges from $0$ to $1$, where $1.0$ indicates perfect separation (all members have higher scores than all non-members), $0.5$ indicates performance no better than random chance, and $0.0$ indicates perfect inverse separation.\n\nThis complete procedure is applied to each of the three test cases to yield the final list of AUC values.", "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Computes the ROC AUC for a membership inference attack based on a composite privacy risk score.\n    \"\"\"\n    test_cases = [\n        {\n            \"C\": 3,\n            \"weights\": (0.5, 0.3, 0.2),  # alpha, beta, gamma\n            \"samples\": [\n                {\"logits\": [3.0, 0.2, -1.0], \"grad_norm\": 0.10, \"y_mem\": 0},\n                {\"logits\": [2.5, -0.5, 0.0], \"grad_norm\": 0.15, \"y_mem\": 0},\n                {\"logits\": [-1.0, 0.0, 3.0], \"grad_norm\": 0.05, \"y_mem\": 0},\n                {\"logits\": [0.5, 0.4, 0.3], \"grad_norm\": 0.90, \"y_mem\": 1},\n                {\"logits\": [0.0, 0.1, 0.2], \"grad_norm\": 0.70, \"y_mem\": 1},\n                {\"logits\": [0.2, 0.1, 0.2], \"grad_norm\": 1.20, \"y_mem\": 1},\n            ]\n        },\n        {\n            \"C\": 3,\n            \"weights\": (0.5, 0.3, 0.2),\n            \"samples\": [\n                {\"logits\": [1.5, 1.4, 1.3], \"grad_norm\": 0.60, \"y_mem\": 0},\n                {\"logits\": [2.0, 0.0, 0.0], \"grad_norm\": 0.40, \"y_mem\": 0},\n                {\"logits\": [0.5, -0.2, 1.0], \"grad_norm\": 0.55, \"y_mem\": 0},\n                {\"logits\": [0.8, 0.7, 0.1], \"grad_norm\": 0.50, \"y_mem\": 1},\n                {\"logits\": [1.8, 0.9, 0.7], \"grad_norm\": 0.45, \"y_mem\": 1},\n                {\"logits\": [0.2, 0.2, 0.2], \"grad_norm\": 0.65, \"y_mem\": 1},\n            ]\n        },\n        {\n            \"C\": 3,\n            \"weights\": (0.5, 0.3, 0.2),\n            \"samples\": [\n                {\"logits\": [0.0, 0.0, 0.0], \"grad_norm\": 0.30, \"y_mem\": 1},\n                {\"logits\": [0.0, 0.0, 0.0], \"grad_norm\": 0.30, \"y_mem\": 0},\n                {\"logits\": [0.0, 0.0, 0.0], \"grad_norm\": 0.30, \"y_mem\": 1},\n                {\"logits\": [0.0, 0.0, 0.0], \"grad_norm\": 0.30, \"y_mem\": 0},\n            ]\n        }\n    ]\n\n    def rankdata(data):\n        \"\"\"\n        Assigns ranks to data, dealing with ties by averaging. Ranks are 1-based.\n        Equivalent to scipy.stats.rankdata(method='average').\n        \"\"\"\n        n = len(data)\n        indexed_data = sorted([(data[i], i) for i in range(n)])\n        \n        ranks = [0.0] * n\n        i = 0\n        while i < n:\n            j = i\n            while j < n - 1 and indexed_data[j][0] == indexed_data[j+1][0]:\n                j += 1\n            \n            # Indices of tied items in the sorted list are from i to j.\n            # Ranks are 1-based, so they would occupy ranks from i+1 to j+1.\n            sum_ranks = sum(range(i + 1, j + 2))\n            avg_rank = sum_ranks / (j - i + 1)\n            \n            for k in range(i, j + 1):\n                original_index = indexed_data[k][1]\n                ranks[original_index] = avg_rank\n            \n            i = j + 1\n            \n        return ranks\n\n    all_results = []\n    for case in test_cases:\n        C = case[\"C\"]\n        alpha, beta, gamma = case[\"weights\"]\n        samples = case[\"samples\"]\n        \n        # Lists to store intermediate computed values for each sample\n        margins = []\n        norm_entropies = []\n        raw_grad_norms = []\n        labels = []\n\n        log_C = np.log(C)\n\n        for sample in samples:\n            logits = np.array(sample[\"logits\"])\n            \n            # 1. Compute probabilities using stable softmax\n            z_stable = logits - np.max(logits)\n            p = np.exp(z_stable) / np.sum(np.exp(z_stable))\n            \n            # 2. Compute margin\n            p_sorted = np.sort(p)[::-1]\n            margin = p_sorted[0] - p_sorted[1] if len(p_sorted) > 1 else p_sorted[0]\n            margins.append(margin)\n            \n            # 3. Compute normalized entropy\n            # Take log only of non-zero probabilities to avoid -inf from log(0)\n            non_zero_p = p[p > 0]\n            entropy = -np.sum(non_zero_p * np.log(non_zero_p))\n            norm_entropy = entropy / log_C\n            norm_entropies.append(norm_entropy)\n            \n            raw_grad_norms.append(sample[\"grad_norm\"])\n            labels.append(sample[\"y_mem\"])\n\n        # 4. Normalize gradient norms for the entire test case\n        g = np.array(raw_grad_norms)\n        g_min, g_max = np.min(g), np.max(g)\n        if g_max == g_min:\n            g_norm = np.zeros_like(g, dtype=float)\n        else:\n            g_norm = (g - g_min) / (g_max - g_min)\n\n        # 5. Compute the final risk score for each sample\n        risk_scores = [\n            alpha * (1 - m) + beta * h_norm + gamma * gn\n            for m, h_norm, gn in zip(margins, norm_entropies, g_norm)\n        ]\n        \n        # 6. Compute ROC AUC using the Mann-Whitney U statistic\n        n0 = labels.count(0)\n        n1 = labels.count(1)\n        \n        if n0 == 0 or n1 == 0:\n            # Although test cases prevent this, handle the edge case.\n            # AUC is typically defined as 0.5 if one class is missing.\n            auc = 0.5  \n        else:\n            ranks = rankdata(risk_scores)\n            sum_ranks_members = sum(ranks[i] for i, label in enumerate(labels) if label == 1)\n            \n            U = sum_ranks_members - (n1 * (n1 + 1) / 2.0)\n            auc = U / (float(n0) * float(n1))\n            \n        all_results.append(auc)\n\n    print(f\"[{','.join(f'{r:.6f}' for r in all_results)}]\")\n\nsolve()\n```", "id": "3149361"}, {"introduction": "Modern deep learning models are trained with sophisticated pipelines that often include techniques like data augmentation. This advanced exercise explores how these specific training procedures can inadvertently leave unique, detectable \"footprints\" in a model's behavior. Your task is to design a tailored attack that looks for the signature of a known augmentation artifact within the model's final output probabilities. By deriving a specialized statistic that leverages the properties of the softmax function and the zero-sum nature of the artifact, you will see how an attacker with knowledge of the training process can construct a powerful and targeted inference strategy. This problem highlights a key principle in machine learning security: vulnerabilities can arise not just from general overfitting, but from the specific details of the training algorithm itself.", "problem": "You are given a simulated classification model with parameters $\\theta$ that outputs a categorical distribution $p_{\\theta}(y \\mid x)$ via a softmax of logits. The model was trained using label-preserving data augmentations, and these augmentations introduce a systematic, augmentation-specific artifact in the logits for training set members. Your task is to derive and implement a principled membership inference rule that detects the footprint of a known augmentation artifact in $p_{\\theta}(y \\mid x)$ and decides whether a single observed prediction originates from a training member or a non-member.\n\nFundamental base:\n- A classification prediction for an input $x$ is generated from logits $z(x) \\in \\mathbb{R}^{C}$ according to the softmax, $p_{\\theta}(y=i \\mid x) = \\exp(z_i) / \\sum_{j=1}^{C} \\exp(z_j)$, for classes $i \\in \\{1, \\dots, C\\}$.\n- The training augmentation introduces a known, zero-sum signature vector $s \\in \\mathbb{R}^{C}$ (i.e., $\\sum_{i=1}^{C} s_i = 0$) into the logits of training members. Specifically, for a training member, the logits are modeled as $z = \\epsilon + \\alpha s$ and for a non-member $z = \\epsilon$, where $\\epsilon \\sim \\mathcal{N}(0, \\sigma^2 I_C)$ is additive Gaussian noise, $\\alpha \\in \\mathbb{R}$ is the augmentation strength, and $\\sigma > 0$ is the noise standard deviation. The attacker knows the augmentation signature $s$, the augmentation strength $\\alpha$, and the noise level $\\sigma$.\n- The attacker observes only the probability vector $p \\in \\Delta^{C-1}$ produced by the model, not the logits $z$ directly. The attacker is also given a prior membership probability $\\pi = \\Pr(M=1)$, where $M \\in \\{0,1\\}$ indicates whether the input was a training member. The attacker seeks a decision rule to infer $M$ from $p$, under the model above.\n\nPrincipled derivation requirement:\n- Use the fact that $p_{\\theta}(y \\mid x)$ arises from a softmax of logits and that the augmentation artifact $s$ is zero-sum to construct a scalar statistic on $p$ that isolates the additive artifact in the logits. Starting from the zero-sum constraint and the identity $\\log p_i = z_i - \\log \\sum_{j=1}^{C} \\exp(z_j)$, derive a statistic that depends on $z$ only through an inner product with $s$, and hence has a tractable Gaussian distribution under member versus non-member hypotheses.\n- Starting from the Gaussian model assumptions and the definition of likelihoods, apply the Neyman–Pearson lemma to obtain the optimal likelihood ratio test for deciding membership $M$ from the derived statistic and the prior $\\pi$. Provide a closed-form decision rule expressed only in terms of the observed $p$, the known parameters $(\\alpha, \\sigma, s)$, and $\\pi$.\n\nProgram requirements:\n- Implement the derived decision rule in a complete, runnable program. For each test case, you must first simulate the observed probability vector $p$ using the provided parameters and a deterministic $\\epsilon$ vector exactly as specified. Then, apply your membership inference rule to the simulated $p$ and output a boolean decision for each test case, where $True$ denotes \"member\" and $False$ denotes \"non-member\".\n- Your program must aggregate the results for all test cases into a single line of output containing the decisions as a comma-separated list enclosed in square brackets (e.g., \"[True,False,True]\").\n\nTest suite:\nFor each test case below, you are given the following parameters:\n- Number of classes $C$ (integer).\n- Noise standard deviation $\\sigma$ (float).\n- Augmentation strength $\\alpha$ (float).\n- Augmentation signature $s \\in \\mathbb{R}^{C}$ with zero sum.\n- Prior membership probability $\\pi$ (decimal in $[0,1]$).\n- Deterministic noise vector $\\epsilon \\in \\mathbb{R}^{C}$.\n- Ground-truth membership $M \\in \\{0,1\\}$ used only to simulate $p$.\n\nYou must simulate logits $z = \\epsilon + \\alpha s$ if $M=1$, and $z = \\epsilon$ if $M=0$. Then compute $p$ via the softmax of $z$, and apply your derived decision rule to output the membership decision.\n\nProvide your program’s results for the following four test cases:\n\n- Test case 1 (happy path):\n    - $C = 5$\n    - $\\sigma = 0.5$\n    - $\\alpha = 0.8$\n    - $s = [1.0, -1.0, 0.5, -0.3, -0.2]$\n    - $\\pi = 0.5$\n    - $\\epsilon = [0.2, -0.1, 0.05, -0.02, -0.13]$\n    - $M = 1$\n\n- Test case 2 (boundary condition with no artifact):\n    - $C = 4$\n    - $\\sigma = 0.6$\n    - $\\alpha = 0.0$\n    - $s = [0.6, -0.1, -0.2, -0.3]$\n    - $\\pi = 0.4$\n    - $\\epsilon = [0.1, -0.05, 0.02, -0.07]$\n    - $M = 1$\n\n- Test case 3 (high-noise regime):\n    - $C = 3$\n    - $\\sigma = 2.0$\n    - $\\alpha = 0.3$\n    - $s = [1.0, -0.5, -0.5]$\n    - $\\pi = 0.5$\n    - $\\epsilon = [-0.2, 0.1, 0.05]$\n    - $M = 1$\n\n- Test case 4 (prior shift favoring membership):\n    - $C = 6$\n    - $\\sigma = 0.4$\n    - $\\alpha = 0.5$\n    - $s = [0.9, -0.4, -0.3, 0.1, -0.1, -0.2]$\n    - $\\pi = 0.8$\n    - $\\epsilon = [-0.05, 0.02, -0.01, 0.03, -0.02, 0.03]$\n    - $M = 0$\n\nFinal output format:\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (e.g., \"[True,False,True,False]\"). No other text should be printed.", "solution": "We begin from the core definitions in probabilistic deep learning. A classifier produces logits $z(x) \\in \\mathbb{R}^{C}$ and a probability vector $p_{\\theta}(y \\mid x)$ via the softmax:\n$$\np_i = \\frac{\\exp(z_i)}{\\sum_{j=1}^{C} \\exp(z_j)}, \\quad i \\in \\{1,\\dots,C\\}.\n$$\nTaking logarithms,\n$$\n\\log p_i = z_i - \\log\\left(\\sum_{j=1}^{C} \\exp(z_j)\\right).\n$$\n\n**Augmentation artifact model:**\nWe assume an augmentation signature $s \\in \\mathbb{R}^{C}$ satisfying the zero-sum constraint $\\sum_{i=1}^{C} s_i = 0$. For a training member ($M=1$), the logits are $z = \\epsilon + \\alpha s$; for a non-member ($M=0$), logits are $z = \\epsilon$. The noise vector $\\epsilon$ is drawn from $\\mathcal{N}(0, \\sigma^2 I_C)$, where $\\sigma > 0$ and $I_C$ is the $C \\times C$ identity matrix. The signature strength is $\\alpha \\in \\mathbb{R}$. The attacker knows $(\\alpha, \\sigma, s)$.\n\n**Statistic isolating the augmentation footprint:**\nUsing the zero-sum constraint on $s$, consider the statistic\n$$\nT(p) = \\sum_{i=1}^{C} s_i \\log p_i.\n$$\nSubstituting $\\log p_i$,\n$$\nT(p) = \\sum_{i=1}^{C} s_i \\left( z_i - \\log\\left(\\sum_{j=1}^{C} \\exp(z_j)\\right) \\right) = \\underbrace{\\sum_{i=1}^{C} s_i z_i}_{s^\\top z} - \\left(\\sum_{i=1}^{C} s_i\\right) \\log\\left(\\sum_{j=1}^{C} \\exp(z_j)\\right).\n$$\nSince $\\sum_{i=1}^{C} s_i = 0$, the second term vanishes, yielding\n$$\nT(p) = s^\\top z.\n$$\nThus, although the attacker sees only $p$, the statistic $T(p)$ equals the inner product of $s$ with the logits $z$. This is invariant to additive shifts of logits and exactly isolates the augmentation footprint.\n\n**Distribution of the statistic under member and non-member hypotheses:**\nUnder $M=0$, $z = \\epsilon$ with $\\epsilon \\sim \\mathcal{N}(0, \\sigma^2 I_C)$, so $T \\mid M=0 = s^\\top \\epsilon \\sim \\mathcal{N}\\left(0, \\sigma^2 \\|s\\|_2^2\\right)$ because $s^\\top \\epsilon$ is a linear form of a multivariate normal, with variance $\\sigma^2 s^\\top s = \\sigma^2 \\|s\\|_2^2$.\n\nUnder $M=1$, $z = \\epsilon + \\alpha s$, so\n$$\nT \\mid M=1 = s^\\top (\\epsilon + \\alpha s) = s^\\top \\epsilon + \\alpha \\, s^\\top s \\sim \\mathcal{N}\\left(\\alpha \\|s\\|_2^2, \\sigma^2 \\|s\\|_2^2\\right).\n$$\nTherefore, $T$ has Gaussian distributions with shared variance under both hypotheses:\n- Mean under $M=0$: $\\mu_0 = 0$.\n- Mean under $M=1$: $\\mu_1 = \\alpha \\|s\\|_2^2$.\n- Variance under both: $v = \\sigma^2 \\|s\\|_2^2$.\n\n**Optimal decision via the Neyman–Pearson lemma:**\nFor two simple hypotheses with known densities $f_0$ and $f_1$, the most powerful test is a threshold on the likelihood ratio $\\Lambda(T) = f_1(T)/f_0(T)$. Incorporating prior probability $\\pi = \\Pr(M=1)$ and equal misclassification costs, the Bayes-optimal decision rule is:\n$$\n\\text{Decide } M=1 \\text{ if } \\log \\Lambda(T) > \\log\\left(\\frac{1-\\pi}{\\pi}\\right), \\quad \\text{otherwise decide } M=0.\n$$\nWith $T \\mid M=m \\sim \\mathcal{N}(\\mu_m, v)$, the log-likelihood ratio simplifies to:\n$$\n\\log \\Lambda(T) = \\log \\frac{\\phi(T; \\mu_1, v)}{\\phi(T; \\mu_0, v)} = -\\frac{(T-\\mu_1)^2}{2v} + \\frac{(T-\\mu_0)^2}{2v},\n$$\nwhere $\\phi(\\cdot; \\mu, v)$ denotes the Gaussian density. This form is numerically stable even when $\\alpha=0$.\n\n**Decision rule:**\nGiven $p$, compute $\\log p$ via a numerically stable log-softmax of the implied logits, then $T = \\sum_{i} s_i \\log p_i$. Compute $\\mu_0, \\mu_1, v$ as above and form the log-likelihood ratio $\\log \\Lambda(T)$. Define the threshold\n$$\n\\eta = \\log\\left(\\frac{1-\\pi}{\\pi}\\right).\n$$\nDecide $M=1$ if $\\log \\Lambda(T) > \\eta$, else $M=0$.\n\nThe program implements this procedure by first simulating the probability vector $p$ for each test case according to its ground-truth membership $M$, and then applying the derived decision rule to infer membership from $p$.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef softmax(z):\n    # Numerically stable softmax\n    z = np.asarray(z, dtype=np.float64)\n    m = np.max(z)\n    exp_z = np.exp(z - m)\n    return exp_z / np.sum(exp_z)\n\ndef log_softmax(z):\n    # Numerically stable log-softmax\n    z = np.asarray(z, dtype=np.float64)\n    m = np.max(z)\n    log_sum_exp = m + np.log(np.sum(np.exp(z - m)))\n    return z - log_sum_exp\n\ndef membership_decision_from_p(p, s, alpha, sigma, pi):\n    # Compute T = sum_i s_i * log p_i.\n    # We are given p, so we compute log(p) directly.\n    log_p = np.log(np.asarray(p, dtype=np.float64))\n    s = np.asarray(s, dtype=np.float64)\n    \n    # Statistic T\n    T = float(np.dot(s, log_p))\n    \n    # Parameters for Gaussian models under H0 (non-member) and H1 (member)\n    norm_sq = float(np.dot(s, s))\n    mu0 = 0.0\n    mu1 = alpha * norm_sq\n    v = (sigma ** 2) * norm_sq\n    \n    # Log-likelihood ratio (numerically stable quadratic form)\n    if v = 1e-12: # Guard against division by zero if s=0 or sigma=0\n        llr = 0.0\n    else:\n        llr = -((T - mu1) ** 2) / (2.0 * v) + ((T - mu0) ** 2) / (2.0 * v)\n        \n    # Threshold from prior\n    # Guard against pi=0 or pi=1\n    if pi == 1.0:\n        eta = -np.inf\n    elif pi == 0.0:\n        eta = np.inf\n    else:\n        eta = np.log((1.0 - pi) / pi)\n        \n    # Decision: True means \"member\"\n    return llr > eta\n\ndef simulate_p(s, alpha, epsilon, M):\n    # Simulate logits z and probability vector p\n    s = np.asarray(s, dtype=np.float64)\n    epsilon = np.asarray(epsilon, dtype=np.float64)\n    z = epsilon + (alpha * s if M == 1 else 0.0)\n    # Compute softmax probabilities\n    p = softmax(z)\n    return p\n\ndef solve():\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # Each case: (C, sigma, alpha, s, pi, epsilon, M)\n        (5, 0.5, 0.8, [1.0, -1.0, 0.5, -0.3, -0.2], 0.5, [0.2, -0.1, 0.05, -0.02, -0.13], 1),\n        (4, 0.6, 0.0, [0.6, -0.1, -0.2, -0.3], 0.4, [0.1, -0.05, 0.02, -0.07], 1),\n        (3, 2.0, 0.3, [1.0, -0.5, -0.5], 0.5, [-0.2, 0.1, 0.05], 1),\n        (6, 0.4, 0.5, [0.9, -0.4, -0.3, 0.1, -0.1, -0.2], 0.8, [-0.05, 0.02, -0.01, 0.03, -0.02, 0.03], 0),\n    ]\n\n    results = []\n    for case in test_cases:\n        C, sigma, alpha, s, pi, epsilon, M = case\n        # Simulate observed probability vector p\n        p = simulate_p(s, alpha, epsilon, M)\n        # Apply membership inference rule to p\n        decision = membership_decision_from_p(p, s, alpha, sigma, pi)\n        results.append(decision)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\".replace(\"True\", \"True\").replace(\"False\", \"False\"))\n\nif __name__ == \"__main__\":\n    solve()\n```", "id": "3149401"}]}