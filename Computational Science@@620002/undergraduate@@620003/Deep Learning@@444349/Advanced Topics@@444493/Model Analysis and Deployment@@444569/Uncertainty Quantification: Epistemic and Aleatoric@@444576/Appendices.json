{"hands_on_practices": [{"introduction": "To build a solid understanding of uncertainty, it is invaluable to start with a model where epistemic and aleatoric components can be computed exactly. This practice uses a classical Bayesian technique, evidential regression with a Normal-Inverse-Gamma conjugate prior, which provides an analytical solution for the posterior distribution. By working through scenarios with varying data quantity and noise levels, you will develop a foundational intuition for how data evidence, $\\nu$, directly tames epistemic uncertainty, $V_{\\text{epi}}$, while the inherent data variability governs aleatoric uncertainty, $V_{\\text{alea}}$. [@problem_id:3197127]", "problem": "You are asked to implement Bayesian evidential regression for a univariate target using the Normal–Inverse-Gamma (NIG) prior and posterior, and to explicitly compute uncertainty decompositions. The goal is to quantify and compare epistemic uncertainty and aleatoric uncertainty in sparse versus dense data regimes. The implementation must be self-contained and produce numeric outputs for a fixed test suite.\n\nStart from the following fundamental base in probability theory and Bayesian statistics:\n- Let the data-generating process be $y_i \\sim \\mathcal{N}(\\mu, \\sigma^2)$, where $\\mathcal{N}$ denotes the Normal distribution.\n- Use the conjugate prior $(\\mu, \\sigma^2) \\sim \\text{Normal–Inverse-Gamma (NIG)}(\\mu_0, \\kappa_0, \\alpha_0, \\beta_0)$, where the conditional prior $p(\\mu \\mid \\sigma^2) = \\mathcal{N}(\\mu_0, \\sigma^2 / \\kappa_0)$ and the marginal prior $p(\\sigma^2) = \\text{Inverse-Gamma}(\\alpha_0, \\beta_0)$.\n- For observed data $D = \\{y_1, \\dots, y_n\\}$ with sample mean $\\bar{y}$ and total sum of squared deviations $S = \\sum_{i=1}^n (y_i - \\bar{y})^2$, the posterior is $(\\mu, \\sigma^2) \\mid D \\sim \\text{NIG}(\\mu_n, \\kappa_n, \\alpha_n, \\beta_n)$ with updated parameters\n$$\n\\kappa_n = \\kappa_0 + n, \\quad\n\\mu_n = \\frac{\\kappa_0 \\mu_0 + n \\bar{y}}{\\kappa_0 + n}, \\quad\n\\alpha_n = \\alpha_0 + \\frac{n}{2}, \\quad\n\\beta_n = \\beta_0 + \\frac{1}{2} S + \\frac{1}{2} \\cdot \\frac{\\kappa_0 n}{\\kappa_0 + n} (\\bar{y} - \\mu_0)^2.\n$$\n- The posterior predictive distribution is Student's $t$ with location $\\mu_n$, and its variance equals\n$$\nV_{\\text{pred}} = \\frac{\\beta_n}{\\alpha_n - 1} \\left( 1 + \\frac{1}{\\kappa_n} \\right),\n$$\nprovided $\\alpha_n > 1$. The decomposition follows from the law of total variance:\n$$\nV_{\\text{alea}} = \\mathbb{E}[\\sigma^2 \\mid D] = \\frac{\\beta_n}{\\alpha_n - 1}, \\quad\nV_{\\text{epi}} = \\operatorname{Var}[\\mu \\mid D] = \\frac{\\mathbb{E}[\\sigma^2 \\mid D]}{\\kappa_n} = \\frac{\\beta_n}{(\\alpha_n - 1)\\kappa_n},\n$$\nand therefore $V_{\\text{pred}} = V_{\\text{alea}} + V_{\\text{epi}}$.\n- In evidential regression, the \"evidence level\" for the mean is quantified by the precision-like parameter $\\nu$, which corresponds here to $\\nu = \\kappa_n$; larger $\\nu$ indicates more data support in the region and thus lower epistemic uncertainty.\n\nImplement the following tasks in a single Python program:\n1. Generate data for each test case using $\\mathcal{N}(\\mu_{\\text{true}}, \\sigma_{\\text{true}}^2)$, with the sample size $n = N$. Use a fixed random seed $42$ for reproducibility. No external input is allowed.\n2. For each test case, compute the posterior parameters $(\\mu_n, \\kappa_n, \\alpha_n, \\beta_n)$ using the update equations above.\n3. Compute the evidence level $\\nu = \\kappa_n$, the aleatoric variance $V_{\\text{alea}}$, the epistemic variance $V_{\\text{epi}}$, and the predictive variance $V_{\\text{pred}}$.\n4. Round all reported numbers to six decimal places.\n\nUse the following fixed prior hyperparameters for all test cases: $\\mu_0 = 0$, $\\kappa_0 = 1$, $\\alpha_0 = 2$, $\\beta_0 = 1$.\n\nTest suite and coverage:\n- Case A (dense, low noise): $N = 200$, $\\mu_{\\text{true}} = 0$, $\\sigma_{\\text{true}} = 0.2$.\n- Case B (sparse, low noise): $N = 5$, $\\mu_{\\text{true}} = 0$, $\\sigma_{\\text{true}} = 0.2$.\n- Case C (dense, high noise): $N = 200$, $\\mu_{\\text{true}} = 0$, $\\sigma_{\\text{true}} = 1.0$.\n- Case D (extremely sparse, medium noise): $N = 1$, $\\mu_{\\text{true}} = 0$, $\\sigma_{\\text{true}} = 0.5$.\n- Case E (sparse, low noise, prior-mean conflict): $N = 5$, $\\mu_{\\text{true}} = 3.0$, $\\sigma_{\\text{true}} = 0.2$.\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, where each element is itself a bracketed list corresponding to one case. For each case, output the four-tuple [$\\nu$, $V_{\\text{alea}}$, $V_{\\text{epi}}$, $V_{\\text{pred}}$], all rounded to six decimal places. The final output format must be:\n\"[[v_a,a_a,e_a,p_a],[v_b,a_b,e_b,p_b],[v_c,a_c,e_c,p_c],[v_d,a_d,e_d,p_d],[v_e,a_e,e_e,p_e]]\"\nwith no spaces in the entire line.", "solution": "The problem is assessed to be valid. It is scientifically grounded in Bayesian statistical theory, well-posed with a unique and computable solution, objective, and self-contained. All necessary mathematical formulations, parameters, and test conditions are provided without ambiguity or contradiction. We may therefore proceed with a complete solution.\n\nThe objective is to implement a Bayesian evidential regression model for a univariate output. This model uses a Normal-Inverse-Gamma (NIG) conjugate prior to derive a posterior distribution over the mean $\\mu$ and variance $\\sigma^2$ of a Gaussian data-generating process. From this posterior, we will decompose the predictive uncertainty into its aleatoric and epistemic components and analyze how these components change with data sparsity and noise level.\n\nFirst, we formalize the probabilistic model. We assume the data $D = \\{y_1, \\dots, y_n\\}$ are independent and identically distributed samples from a Normal distribution with an unknown mean $\\mu$ and an unknown variance $\\sigma^2$:\n$$\ny_i \\sim \\mathcal{N}(\\mu, \\sigma^2)\n$$\n\nThe conjugate prior for $(\\mu, \\sigma^2)$ is the Normal-Inverse-Gamma distribution, denoted as $\\text{NIG}(\\mu_0, \\kappa_0, \\alpha_0, \\beta_0)$. This prior is defined by a conditional Normal distribution for the mean, $p(\\mu \\mid \\sigma^2) = \\mathcal{N}(\\mu_0, \\sigma^2 / \\kappa_0)$, and a marginal Inverse-Gamma distribution for the variance, $p(\\sigma^2) = \\text{Inverse-Gamma}(\\alpha_0, \\beta_0)$. The hyperparameters $(\\mu_0, \\kappa_0, \\alpha_0, \\beta_0)$ encode our prior beliefs. For this problem, we use the fixed prior hyperparameters: $\\mu_0 = 0$, $\\kappa_0 = 1$, $\\alpha_0 = 2$, and $\\beta_0 = 1$.\n\nGiven a set of $n$ observations $D$, we update our prior beliefs to form the posterior distribution $p(\\mu, \\sigma^2 \\mid D)$. Due to the conjugacy of the NIG prior, the posterior is also an NIG distribution, $p(\\mu, \\sigma^2 \\mid D) \\sim \\text{NIG}(\\mu_n, \\kappa_n, \\alpha_n, \\beta_n)$. The updated parameters are calculated using the sample statistics: the sample mean $\\bar{y} = \\frac{1}{n} \\sum_{i=1}^n y_i$ and the sum of squared deviations $S = \\sum_{i=1}^n (y_i - \\bar{y})^2$. The posterior update equations are:\n$$\n\\kappa_n = \\kappa_0 + n \\\\\n\\mu_n = \\frac{\\kappa_0 \\mu_0 + n \\bar{y}}{\\kappa_0 + n} \\\\\n\\alpha_n = \\alpha_0 + \\frac{n}{2} \\\\\n\\beta_n = \\beta_0 + \\frac{1}{2} S + \\frac{1}{2} \\cdot \\frac{\\kappa_0 n}{\\kappa_0 + n} (\\bar{y} - \\mu_0)^2\n$$\nThe parameter $\\kappa_n$ can be interpreted as the \"evidence level\" $\\nu$ in evidential regression frameworks, quantifying the amount of data supporting the posterior estimate of the mean. A larger $\\kappa_n$ signifies greater confidence in the mean's location.\n\nThe core of the analysis lies in the decomposition of the total predictive variance, $V_{\\text{pred}}$. The posterior predictive distribution for a new observation is a Student's t-distribution. Its variance, $V_{\\text{pred}}$, is given by the law of total variance:\n$$\nV_{\\text{pred}} = \\operatorname{Var}(y^* \\mid D) = \\mathbb{E}[\\operatorname{Var}(y^* \\mid \\mu, \\sigma^2)] + \\operatorname{Var}(\\mathbb{E}[y^* \\mid \\mu, \\sigma^2])\n$$\nThe first term represents the inherent, irreducible randomness in the data, which is the aleatoric uncertainty. The second term represents the uncertainty in our model parameters, which can be reduced with more data, and is thus the epistemic uncertainty. For our model, this decomposition yields:\n1.  **Aleatoric Variance ($V_{\\text{alea}}$)**: The posterior expectation of the data variance, $\\sigma^2$. This is the mean of the posterior marginal Inverse-Gamma distribution for $\\sigma^2$.\n    $$\n    V_{\\text{alea}} = \\mathbb{E}[\\sigma^2 \\mid D] = \\frac{\\beta_n}{\\alpha_n - 1} \\quad (\\text{for } \\alpha_n > 1)\n    $$\n2.  **Epistemic Variance ($V_{\\text{epi}}$)**: The posterior variance of the data mean, $\\mu$.\n    $$\n    V_{\\text{epi}} = \\operatorname{Var}[\\mu \\mid D] = \\frac{\\mathbb{E}[\\sigma^2 \\mid D]}{\\kappa_n} = \\frac{\\beta_n}{(\\alpha_n - 1)\\kappa_n}\n    $$\nThe total predictive variance is the sum of these two components: $V_{\\text{pred}} = V_{\\text{alea}} + V_{\\text{epi}}$.\n\nThe implementation will proceed as follows for each test case:\n1.  Initialize a single `numpy` random number generator with a fixed seed of $42$ for reproducibility across all data generation steps.\n2.  Generate a dataset of size $N$ by drawing from $\\mathcal{N}(\\mu_{\\text{true}}, \\sigma_{\\text{true}}^2)$.\n3.  Compute the sample statistics $\\bar{y}$ and $S$. For the case $N = 1$, $S$ is correctly treated as $0$.\n4.  Apply the update equations to compute the posterior hyperparameters $\\mu_n, \\kappa_n, \\alpha_n, \\beta_n$.\n5.  Use the posterior hyperparameters to calculate the evidence level $\\nu = \\kappa_n$ and the variance components $V_{\\text{alea}}$, $V_{\\text{epi}}$, and $V_{\\text{pred}}$.\n6.  Round all four resulting numerical values to six decimal places and format them as required.\n\nThis procedure will be repeated for all five test cases, which are designed to demonstrate key behaviors:\n-   **Case A vs. B**: Shows the effect of data quantity ($N=200$ vs. $N=5$) on epistemic uncertainty. $V_{\\text{epi}}$ will be significantly smaller in Case A.\n-   **Case A vs. C**: Shows the effect of data noise ($\\sigma_{\\text{true}}=0.2$ vs. $\\sigma_{\\text{true}}=1.0$). $V_{\\text{alea}}$ will be significantly larger in Case C, reflecting the higher intrinsic variance.\n-   **Case D**: An extreme sparse case ($N=1$) where the posterior is a slight update from the prior.\n-   **Case E**: A sparse case ($N=5$) with prior-data conflict ($\\mu_{\\text{true}}=3.0$ vs. $\\mu_0=0$). The conflict term in the $\\beta_n$ update is expected to increase the estimated aleatoric and epistemic variances.", "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Implements Bayesian evidential regression with a Normal-Inverse-Gamma prior\n    to compute and decompose predictive uncertainty for several test cases.\n    \"\"\"\n    # Fixed prior hyperparameters\n    mu_0 = 0.0\n    kappa_0 = 1.0\n    alpha_0 = 2.0\n    beta_0 = 1.0\n    \n    # Test suite: (N, mu_true, sigma_true)\n    test_cases = [\n        (200, 0.0, 0.2),  # Case A: dense, low noise\n        (5, 0.0, 0.2),    # Case B: sparse, low noise\n        (200, 0.0, 1.0),  # Case C: dense, high noise\n        (1, 0.0, 0.5),    # Case D: extremely sparse, medium noise\n        (5, 3.0, 0.2),    # Case E: sparse, low noise, prior-mean conflict\n    ]\n    \n    # Initialize a single random number generator for reproducibility\n    rng = np.random.default_rng(42)\n    \n    all_results = []\n\n    for n, mu_true, sigma_true in test_cases:\n        # Step 1: Generate data\n        y_data = rng.normal(loc=mu_true, scale=sigma_true, size=n)\n        \n        # Calculate sample statistics\n        if n > 0:\n            y_bar = np.mean(y_data)\n        else:\n            # This case is not in the test suite but is handled for completeness\n            y_bar = 0.0\n            \n        if n > 1:\n            # Sum of squared deviations from the mean\n            s_stat = np.sum((y_data - y_bar)**2)\n        else:\n            # For n=0 or n=1, the sum of squared deviations is 0\n            s_stat = 0.0\n            \n        # Step 2: Compute posterior parameters\n        kappa_n = kappa_0 + n\n        mu_n = (kappa_0 * mu_0 + n * y_bar) / kappa_n\n        alpha_n = alpha_0 + n / 2.0\n        \n        beta_update_term = (kappa_0 * n / kappa_n) * (y_bar - mu_0)**2\n        beta_n = beta_0 + 0.5 * s_stat + 0.5 * beta_update_term\n        \n        # Step 3: Compute evidence level and uncertainty variances\n        # The condition alpha_n > 1 is always met since alpha_0=2 and n>=1\n        nu = kappa_n\n        v_alea = beta_n / (alpha_n - 1.0)\n        v_epi = v_alea / kappa_n\n        v_pred = v_alea + v_epi\n        \n        # Append the results for the current case\n        # nu is treated as a float for consistent formatting\n        all_results.append([float(nu), v_alea, v_epi, v_pred])\n\n    # Step 4: Format the final output string\n    case_strings = []\n    for case_result in all_results:\n        # Format each number to 6 decimal places and join into a string\n        formatted_numbers = [f\"{num:.6f}\" for num in case_result]\n        case_strings.append(f\"[{','.join(formatted_numbers)}]\")\n        \n    final_output = f\"[{','.join(case_strings)}]\"\n    \n    # Print the final result in the exact required format\n    print(final_output)\n\nsolve()\n```", "id": "3197127"}, {"introduction": "While exact Bayesian models provide clarity, most deep learning applications require scalable approximations due to computational intractability. This exercise introduces Monte Carlo (MC) Dropout, a widely used method to estimate a model's epistemic uncertainty without the full cost of Bayesian inference. You will implement and compare the uncertainty estimated by MC Dropout against the true Bayesian posterior variance in a controlled regression setting, gaining critical insight into how this powerful heuristic relates to formal Bayesian principles and how tuning its parameters affects the quality of the uncertainty estimate. [@problem_id:3197106]", "problem": "You are asked to design and implement a program that compares epistemic uncertainty estimated by Monte Carlo (MC) Dropout across different dropout rates with the analytically correct Bayesian posterior epistemic uncertainty in a one-dimensional linear regression problem. Your program must follow the scientific base of the law of total variance and conjugate Bayesian linear regression with a Gaussian prior and Gaussian likelihood. Do not use any heuristic formulas beyond what follows from these bases.\n\nAssume a one-dimensional linear model with additive Gaussian noise: for each training pair $(x_n, y_n)$, $y_n = w x_n + \\epsilon_n$, where $\\epsilon_n \\sim \\mathcal{N}(0,\\sigma^2)$ independently, and a prior $w \\sim \\mathcal{N}(0, s_0^2)$. The law of total variance states that for a new input $x_\\star$, the predictive variance decomposes as $\\mathrm{Var}(y_\\star \\mid x_\\star, \\mathcal{D}) = \\mathbb{E}_{w \\mid \\mathcal{D}}[\\mathrm{Var}(y_\\star \\mid x_\\star, w)] + \\mathrm{Var}_{w \\mid \\mathcal{D}}(\\mathbb{E}[y_\\star \\mid x_\\star, w])$. Use this to define the aleatoric and epistemic components separately. You must derive, from these base definitions, expressions needed to compute the posterior epistemic variance and the MC Dropout-induced variance at test time for a single-weight model with inverted dropout scaling.\n\nUse the following fixed dataset $\\mathcal{D}$ of size $N = 5$:\n- Inputs $x$ and outputs $y$ (each in the same index order): $x = [-2, -1, 0, 1, 2]$ and $y = [-3.12, -1.64, 0.0, 1.65, 3.14]$. Every number here is a real scalar.\n- Known noise variance $\\sigma^2 = 0.01$ and prior variance $s_0^2 = 1.0$.\n\nDefine $x_\\star = 3.0$. Estimate a single weight parameter by maximum likelihood using ordinary least squares on the given data (no intercept term). Then:\n- Compute the analytically correct Bayesian posterior epistemic variance at $x_\\star$ based on the Gaussian prior and Gaussian likelihood model.\n- Model MC Dropout at test time with a single dropout mask applied to the single weight and inverted dropout scaling. That is, use a Bernoulli mask with keep probability $(1-p)$, scaled by $\\frac{1}{1-p}$ when kept, applied to the single learned weight before predicting at $x_\\star$. From definitions of expectation and variance for a scaled Bernoulli random variable, derive and compute the dropout-induced predictive variance (do not add aleatoric noise here; interpret this dropout-induced predictive variance as the MC Dropout estimate of epistemic variance in this single-weight setting).\n\nFor each dropout rate $p$ in the test suite below, compute the signed fractional error of the MC Dropout epistemic variance with respect to the Bayesian posterior epistemic variance at $x_\\star$:\n$$\\text{fractional\\_error}(p) = \\frac{\\widehat{v}_{\\text{drop}}(p) - v_{\\text{epistemic,true}}}{v_{\\text{epistemic,true}}}.$$\n\nUse the following test suite of dropout rates:\n- $p = 0.0$ (no dropout; boundary case),\n- $p = 0.1$ (light dropout; typical case),\n- $p = 0.5$ (moderate dropout),\n- $p = 0.9$ (heavy dropout; near-degenerate mask rate).\n\nYour program must:\n- Compute the ordinary least squares estimate $\\hat{w}$ from the provided $(x,y)$,\n- Compute the Bayesian posterior epistemic variance at $x_\\star$,\n- For each $p$ in the suite, compute the MC Dropout epistemic variance at $x_\\star$ under inverted dropout scaling applied to the single weight and then the signed fractional error defined above,\n- Produce a single line of output containing the results as a comma-separated list enclosed in square brackets, in the same order of $p$ given above, with each value rounded to exactly six decimal places.\n\nThere are no physical units or angles in this problem. All outputs must be real-valued scalars. Your output must be exactly one list on one line, for example, $[a_1,a_2,a_3,a_4]$, where each $a_k$ is the rounded signed fractional error for the corresponding $p$.", "solution": "The problem statement has been critically validated and is determined to be scientifically grounded, well-posed, and internally consistent. It presents a comparison between the epistemic uncertainty derived from a formal Bayesian linear regression model and an estimate obtained via Monte Carlo (MC) Dropout applied to a frequentist point-estimated model. This is a standard and insightful exercise in uncertainty quantification. The necessary data, constants, and definitions are provided to permit a unique and verifiable solution.\n\nThe solution proceeds in four stages:\n1.  Estimation of the model weight $\\hat{w}$ via Ordinary Least Squares (OLS).\n2.  Calculation of the true Bayesian posterior epistemic variance, $v_{\\text{epistemic,true}}$, at the test point $x_\\star$.\n3.  Derivation and calculation of the MC Dropout-induced variance, $\\widehat{v}_{\\text{drop}}(p)$, for different dropout rates $p$.\n4.  Computation of the signed fractional error for each specified dropout rate.\n\n**1. Ordinary Least Squares (OLS) Weight Estimate**\n\nThe model is a single-parameter linear equation $y = wx$. The OLS method minimizes the sum of squared residuals, $L(w) = \\sum_{n=1}^{N} (y_n - w x_n)^2$. The weight estimate $\\hat{w}$ that minimizes $L(w)$ is found by setting the derivative with respect to $w$ to zero:\n$$ \\frac{dL}{dw} = \\sum_{n=1}^{N} -2x_n(y_n - w x_n) = 0 $$\n$$ \\sum_{n=1}^{N} x_n y_n = \\hat{w} \\sum_{n=1}^{N} x_n^2 $$\n$$ \\hat{w} = \\frac{\\sum_{n=1}^{N} x_n y_n}{\\sum_{n=1}^{N} x_n^2} $$\nUsing the provided dataset $\\mathcal{D}$, where the inputs are $\\mathbf{x} = [-2, -1, 0, 1, 2]^T$ and outputs are $\\mathbf{y} = [-3.12, -1.64, 0.0, 1.65, 3.14]^T$:\n$$ \\sum_{n=1}^{N} x_n y_n = (-2)(-3.12) + (-1)(-1.64) + (0)(0.0) + (1)(1.65) + (2)(3.14) = 6.24 + 1.64 + 0 + 1.65 + 6.28 = 15.81 $$\n$$ \\sum_{n=1}^{N} x_n^2 = (-2)^2 + (-1)^2 + 0^2 + 1^2 + 2^2 = 4 + 1 + 0 + 1 + 4 = 10 $$\nThe OLS estimate for the weight is:\n$$ \\hat{w} = \\frac{15.81}{10} = 1.581 $$\n\n**2. True Bayesian Posterior Epistemic Variance**\n\nThe problem defines the epistemic uncertainty based on the law of total variance for a new prediction $y_\\star$ at input $x_\\star$:\n$$ \\mathrm{Var}(y_\\star \\mid x_\\star, \\mathcal{D}) = \\underbrace{\\mathbb{E}_{w \\mid \\mathcal{D}}[\\mathrm{Var}(y_\\star \\mid x_\\star, w)]}_{\\text{Aleatoric Variance}} + \\underbrace{\\mathrm{Var}_{w \\mid \\mathcal{D}}(\\mathbb{E}[y_\\star \\mid x_\\star, w])}_{\\text{Epistemic Variance}} $$\nFor the model $y_\\star = w x_\\star + \\epsilon_\\star$ with noise $\\epsilon_\\star \\sim \\mathcal{N}(0, \\sigma^2)$, the components are:\n- $\\mathbb{E}[y_\\star \\mid x_\\star, w] = w x_\\star$\n- $\\mathrm{Var}(y_\\star \\mid x_\\star, w) = \\sigma^2$\nThe epistemic variance is therefore:\n$$ v_{\\text{epistemic,true}} = \\mathrm{Var}_{w \\mid \\mathcal{D}}(w x_\\star) = x_\\star^2 \\mathrm{Var}_{w \\mid \\mathcal{D}}(w) $$\nTo find the posterior variance of the weight, $\\mathrm{Var}_{w \\mid \\mathcal{D}}(w)$, we use Bayesian inference. The model specifies a Gaussian prior $w \\sim \\mathcal{N}(0, s_0^2)$ and a Gaussian likelihood $p(\\mathcal{D} \\mid w) = \\prod_n \\mathcal{N}(y_n \\mid w x_n, \\sigma^2)$. The posterior $p(w \\mid \\mathcal{D})$ is also Gaussian, $w \\mid \\mathcal{D} \\sim \\mathcal{N}(\\mu_N, s_N^2)$. The posterior precision $s_N^{-2}$ is the sum of the prior precision and the data-dependent likelihood precision:\n$$ \\frac{1}{s_N^2} = \\frac{1}{s_0^2} + \\frac{1}{\\sigma^2} \\sum_{n=1}^{N} x_n^2 $$\nUsing the given values $s_0^2 = 1.0$, $\\sigma^2 = 0.01$, and $\\sum_{n=1}^{N} x_n^2 = 10$:\n$$ \\frac{1}{s_N^2} = \\frac{1}{1.0} + \\frac{10}{0.01} = 1 + 1000 = 1001 $$\nThe posterior variance of the weight is $\\mathrm{Var}_{w \\mid \\mathcal{D}}(w) = s_N^2 = \\frac{1}{1001}$.\nAt the test point $x_\\star = 3.0$, the true epistemic variance is:\n$$ v_{\\text{epistemic,true}} = x_\\star^2 s_N^2 = (3.0)^2 \\left(\\frac{1}{1001}\\right) = \\frac{9}{1001} $$\n\n**3. MC Dropout Epistemic Variance Estimate**\n\nThe problem asks to model MC Dropout at test time by applying a stochastic mask to the OLS weight estimate $\\hat{w}$. With a dropout rate of $p$, the keep probability is $1-p$. A Bernoulli mask $z \\sim \\text{Bernoulli}(1-p)$ is applied. With inverted dropout, the stochastic weight $w_{\\text{drop}}$ is:\n$$ w_{\\text{drop}} = \\hat{w} \\frac{z}{1-p} $$\nThe prediction at $x_\\star$ is $y_\\star^{\\text{drop}} = w_{\\text{drop}} x_\\star$. The MC Dropout variance is the variance of this prediction over the distribution of the mask $z$:\n$$ \\widehat{v}_{\\text{drop}}(p) = \\mathrm{Var}_z(y_\\star^{\\text{drop}}) = \\mathrm{Var}_z\\left(\\hat{w} \\frac{z}{1-p} x_\\star\\right) $$\nSince $\\hat{w}$, $x_\\star$, and $p$ are constant with respect to $z$:\n$$ \\widehat{v}_{\\text{drop}}(p) = (\\hat{w} x_\\star)^2 \\mathrm{Var}_z\\left(\\frac{z}{1-p}\\right) = \\frac{(\\hat{w} x_\\star)^2}{(1-p)^2} \\mathrm{Var}_z(z) $$\nThe variance of a Bernoulli random variable $z \\sim \\text{Bernoulli}(\\theta)$ is $\\theta(1-\\theta)$. Here, $\\theta=1-p$, so $\\mathrm{Var}_z(z) = (1-p)(1 - (1-p)) = p(1-p)$.\nSubstituting this into the expression for $\\widehat{v}_{\\text{drop}}(p)$:\n$$ \\widehat{v}_{\\text{drop}}(p) = \\frac{(\\hat{w} x_\\star)^2}{(1-p)^2} [p(1-p)] = (\\hat{w} x_\\star)^2 \\frac{p}{1-p} $$\nUsing $\\hat{w} = 1.581$ and $x_\\star = 3.0$:\n$$ \\widehat{v}_{\\text{drop}}(p) = (1.581 \\times 3.0)^2 \\frac{p}{1-p} = (4.743)^2 \\frac{p}{1-p} = 22.496049 \\frac{p}{1-p} $$\n\n**4. Signed Fractional Error Calculation**\n\nThe signed fractional error is defined as:\n$$ \\text{fractional\\_error}(p) = \\frac{\\widehat{v}_{\\text{drop}}(p) - v_{\\text{epistemic,true}}}{v_{\\text{epistemic,true}}} = \\frac{\\widehat{v}_{\\text{drop}}(p)}{v_{\\text{epistemic,true}}} - 1 $$\nWe substitute the expressions for $\\widehat{v}_{\\text{drop}}(p)$ and $v_{\\text{epistemic,true}}$:\n$$ \\text{fractional\\_error}(p) = \\frac{22.496049 \\frac{p}{1-p}}{9/1001} - 1 = \\left(\\frac{22.496049 \\times 1001}{9}\\right) \\frac{p}{1-p} - 1 \\approx 2502.060561 \\frac{p}{1-p} - 1 $$\nWe compute this for each $p$ in the test suite $\\{0.0, 0.1, 0.5, 0.9\\}$:\n- For $p=0.0$: $\\text{fractional\\_error}(0.0) = 2502.060561 \\times 0 - 1 = -1.0$.\n- For $p=0.1$: $\\text{fractional\\_error}(0.1) = 2502.060561 \\times \\frac{0.1}{0.9} - 1 \\approx 278.006729 - 1 = 277.006729$.\n- For $p=0.5$: $\\text{fractional\\_error}(0.5) = 2502.060561 \\times \\frac{0.5}{0.5} - 1 = 2502.060561 - 1 = 2501.060561$.\n- For $p=0.9$: $\\text{fractional\\_error}(0.9) = 2502.060561 \\times \\frac{0.9}{0.1} - 1 = 22518.545049 - 1 = 22517.545049$.\n\nRounding these values to six decimal places yields the final results.", "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Computes the signed fractional error of MC Dropout epistemic variance\n    with respect to the true Bayesian posterior epistemic variance for\n    a 1D linear regression problem.\n    \"\"\"\n    # Define the dataset and constants from the problem statement.\n    x_data = np.array([-2.0, -1.0, 0.0, 1.0, 2.0])\n    y_data = np.array([-3.12, -1.64, 0.0, 1.65, 3.14])\n    \n    sigma2 = 0.01  # Known noise variance\n    s02 = 1.0      # Prior variance\n    x_star = 3.0   # Test point\n    \n    # Test suite of dropout rates\n    p_values = [0.0, 0.1, 0.5, 0.9]\n\n    # Step 1: Compute the Ordinary Least Squares (OLS) estimate for the weight.\n    # The model is y = w*x, so the OLS estimate is w_hat = sum(x*y) / sum(x^2).\n    sum_xy = np.sum(x_data * y_data)\n    sum_x2 = np.sum(x_data**2)\n    w_hat = sum_xy / sum_x2\n\n    # Step 2: Compute the analytically correct Bayesian posterior epistemic variance.\n    # Posterior precision s_N^-2 = s_0^-2 + sum(x^2)/sigma^2\n    # Posterior variance s_N^2 = 1 / (1/s02 + sum_x2/sigma2)\n    posterior_variance_w = 1.0 / (1.0/s02 + sum_x2/sigma2)\n    # Epistemic variance at x_star is v_epistemic = x_star^2 * Var(w|D)\n    v_epistemic_true = x_star**2 * posterior_variance_w\n\n    results = []\n    for p in p_values:\n        # Step 3: Compute the MC Dropout epistemic variance estimate.\n        # This is the variance of the prediction over the dropout mask distribution.\n        # With inverted dropout, v_drop = (w_hat * x_star)^2 * p / (1-p).\n        if p == 1.0:\n            # Although not in the test suite, this is the theoretical limit.\n            v_drop = np.inf\n        else:\n            v_drop = (w_hat * x_star)**2 * p / (1.0 - p)\n\n        # Step 4: Compute the signed fractional error.\n        # fractional_error = (v_drop - v_epistemic_true) / v_epistemic_true\n        fractional_error = (v_drop / v_epistemic_true) - 1.0\n        results.append(fractional_error)\n\n    # Format the final results as a string with each value rounded to 6 decimal places.\n    formatted_results = [f\"{r:.6f}\" for r in results]\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```", "id": "3197106"}, {"introduction": "Moving from regression to classification, uncertainty quantification becomes essential for identifying when a model's prediction is unreliable, particularly for inputs that are out-of-distribution (OOD). This practice explores how to decompose a classifier's total uncertainty into its aleatoric and epistemic parts and introduces two powerful calibration methods: temperature scaling and Dirichlet calibration. By comparing these techniques, you will learn how to measure and refine a model's confidence, a key skill for building safer and more robust classification systems that know when they don't know. [@problem_id:3197050]", "problem": "You are given a small synthetic classification scenario to study uncertainty quantification in deep learning, focusing on separating aleatoric uncertainty from epistemic uncertainty. Consider a three-class classifier that, for each input, produces multiple stochastic forward passes due to Monte Carlo (MC) sampling such as Monte Carlo dropout. Each forward pass yields a vector of unnormalized class scores (logits). For each input, you are to compute two uncertainty measures using two different calibration methods: temperature scaling and Dirichlet calibration.\n\nFundamental base and definitions:\n- The softmax function maps logits to a categorical distribution. For a logits vector $\\ell \\in \\mathbb{R}^K$, the softmax is $p(k) = \\exp(\\ell_k)/\\sum_{j=1}^{K}\\exp(\\ell_j)$ for $k \\in \\{1,\\dots,K\\}$.\n- Under temperature scaling with temperature $T>0$, logits are scaled as $\\ell/T$ before applying softmax.\n- For a categorical distribution $p$, the entropy is $H(p) = -\\sum_{k=1}^{K} p(k)\\log p(k)$, using natural logarithms.\n- Given $S$ stochastic forward passes producing categorical distributions $\\{p^{(s)}\\}_{s=1}^{S}$ for the same input, define the predictive distribution as $\\bar{p} = \\frac{1}{S}\\sum_{s=1}^{S} p^{(s)}$ and the expected data entropy as $\\mathbb{E}[H] = \\frac{1}{S}\\sum_{s=1}^{S} H\\left(p^{(s)}\\right)$. The predictive entropy is $H(\\bar{p})$. The mutual information is $I = H(\\bar{p}) - \\mathbb{E}[H]$.\n- In Dirichlet calibration, the predictive categorical mean $\\bar{p}$ is used to define a Dirichlet distribution over class probabilities with concentration vector $\\alpha = s\\,\\bar{p}$, where $s>0$ is the total concentration hyperparameter. The predictive entropy equals $H(\\bar{p})$. The expected data entropy under this Dirichlet model is $\\mathbb{E}_{\\pi \\sim \\text{Dir}(\\alpha)}\\left[-\\sum_{k=1}^{K} \\pi_k \\log \\pi_k\\right]$, and the epistemic mutual information is $I_{\\text{Dir}} = H(\\bar{p}) - \\mathbb{E}_{\\pi}\\left[-\\sum_{k=1}^{K} \\pi_k \\log \\pi_k\\right]$.\n\nYour tasks:\n1) Implement temperature scaling and Dirichlet calibration. For temperature scaling, apply temperature $T$ to each logits vector and compute softmax probabilities. For Dirichlet calibration, use the mean categorical probabilities $\\bar{p}$ (computed from the uncalibrated logits under $T=1$ unless otherwise specified) and a given total concentration $s$ to define $\\alpha = s\\,\\bar{p}$.\n2) For each input, compute the predictive entropy $H(\\bar{p})$, the expected data entropy, and the mutual information for both calibration methods. For temperature scaling, approximate the mutual information by sample averaging across MC passes. For Dirichlet calibration, use the analytical expectation with the Dirichlet distribution as explained above.\n3) Evaluate separation between in-distribution (ID) and out-of-distribution (OOD) inputs by computing, for each calibration method, the difference of means between OOD and ID for mutual information and for predictive entropy. Specifically, define, for each method, $\\Delta I = \\text{mean}_{\\text{OOD}}(I) - \\text{mean}_{\\text{ID}}(I)$ and $\\Delta H = \\text{mean}_{\\text{OOD}}(H(\\bar{p})) - \\text{mean}_{\\text{ID}}(H(\\bar{p}))$.\n4) Compare how temperature scaling versus Dirichlet calibration affects these separations under various parameter settings.\n\nUse only the natural logarithm. Angles do not appear. No physical units are involved. All numeric outputs must be decimal floats.\n\nData:\n- Number of classes $K=3$ and number of MC samples per input $S=4$.\n- Four inputs are provided; the first two are ID and the last two are OOD. Each input provides $S$ logits vectors in $\\mathbb{R}^3$ as follows (each inner list is one logits vector):\n\nID input 1:\n[\n[5.0, 0.1, -0.2],\n[4.8, 0.0, -0.1],\n[5.2, -0.2, -0.1],\n[5.1, 0.2, -0.3]\n]\n\nID input 2:\n[\n[0.1, 5.0, -0.2],\n[-0.1, 5.2, -0.3],\n[0.0, 4.9, 0.1],\n[0.2, 5.1, -0.4]\n]\n\nOOD input 1:\n[\n[0.3, -0.2, 0.1],\n[-0.1, 0.4, -0.3],\n[0.2, 0.1, -0.3],\n[-0.4, 0.2, 0.2]\n]\n\nOOD input 2:\n[\n[0.0, 0.0, 0.0],\n[0.2, -0.2, 0.1],\n[-0.3, 0.3, 0.0],\n[0.1, 0.0, -0.1]\n]\n\nTest suite:\nCompute the required quantities for the following three parameter settings. In each setting, use the temperature $T$ for temperature scaling and the total concentration $s$ for Dirichlet calibration. For Dirichlet calibration, always form $\\bar{p}$ from the unscaled logits ($T=1$) and then set $\\alpha = s\\,\\bar{p}$.\n\n- Case A: $T=1.0$, $s=3.0$.\n- Case B: $T=2.5$, $s=0.8$.\n- Case C: $T=0.5$, $s=10.0$.\n\nFor each case, compute:\n- $\\Delta I_{\\text{temp}}$, $\\Delta H_{\\text{temp}}$ using temperature scaling with the specified $T$.\n- $\\Delta I_{\\text{Dir}}$, $\\Delta H_{\\text{Dir}}$ using Dirichlet calibration with the specified $s$.\n\nFinal output format:\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets. The list must include, in order, for cases A, B, and C respectively:\n[$\\Delta I_{\\text{temp}}^{\\text{A}}$,$\\Delta H_{\\text{temp}}^{\\text{A}}$,$\\Delta I_{\\text{Dir}}^{\\text{A}}$,$\\Delta H_{\\text{Dir}}^{\\text{A}}$,$\\Delta I_{\\text{temp}}^{\\text{B}}$,$\\Delta H_{\\text{temp}}^{\\text{B}}$,$\\Delta I_{\\text{Dir}}^{\\text{B}}$,$\\Delta H_{\\text{Dir}}^{\\text{B}}$,$\\Delta I_{\\text{temp}}^{\\text{C}}$,$\\Delta H_{\\text{temp}}^{\\text{C}}$,$\\Delta I_{\\text{Dir}}^{\\text{C}}$,$\\Delta H_{\\text{Dir}}^{\\text{C}}$]\n\nAll numbers must be decimal floats. No other text should be printed. This specification constitutes a complete, deterministically testable program requirement.", "solution": "The problem requires the computation and comparison of uncertainty metrics for a three-class classifier under two different calibration schemes: temperature scaling and Dirichlet calibration. The goal is to evaluate how well each method separates in-distribution (ID) from out-of-distribution (OOD) data, based on predictive entropy and mutual information. The solution proceeds by first implementing the necessary functions for each method and then applying them to the provided data for the three specified test cases.\n\nFirst, we define several core mathematical functions as specified in the problem statement. The softmax function, which converts a vector of logits $\\ell \\in \\mathbb{R}^K$ into a probability distribution $p \\in \\mathbb{R}^K$, is given by:\n$$p_k(\\ell) = \\frac{\\exp(\\ell_k)}{\\sum_{j=1}^{K} \\exp(\\ell_j)}$$\nFor numerical stability, this is implemented by shifting the logits by their maximum value before exponentiation. The entropy of a categorical distribution $p$ is calculated using the natural logarithm:\n$$H(p) = -\\sum_{k=1}^{K} p_k \\log(p_k)$$\nwhere the convention $0 \\log 0 = 0$ is used.\n\nThe problem provides $S=4$ sets of logits (from Monte Carlo samples) for each of the four inputs (two ID, two OOD). For each input, we can compute a set of $S$ probability distributions $\\{p^{(s)}\\}_{s=1}^{S}$. From these, we derive the predictive distribution, which is the average of the individual sample distributions:\n$$\\bar{p} = \\frac{1}{S}\\sum_{s=1}^{S} p^{(s)}$$\n\nThe total uncertainty is measured by the predictive entropy, $H(\\bar{p})$. This is decomposed into aleatoric (data) uncertainty and epistemic (model) uncertainty. The aleatoric uncertainty is the expected entropy over the samples, $\\mathbb{E}[H] = \\frac{1}{S}\\sum_{s=1}^{S} H(p^{(s)})$. The epistemic uncertainty is quantified by the mutual information, $I = H(\\bar{p}) - \\mathbb{E}[H]$.\n\nThe two calibration methods modify how these quantities are calculated.\n\n**1. Temperature Scaling**\n\nTemperature scaling adjusts the confidence of the model by scaling the logits $\\ell$ with a temperature parameter $T > 0$ before applying the softmax function: $\\ell' = \\ell/T$. A temperature $T > 1$ \"softens\" the probabilities, making the distribution more uniform and indicating lower confidence. A temperature $T  1$ \"sharpens\" the distribution, indicating higher confidence.\n\nFor each input and a given temperature $T$, the procedure is as follows:\n1. For each of the $S=4$ logit vectors $\\ell^{(s)}$, compute the scaled logits $\\ell'^{(s)} = \\ell^{(s)}/T$.\n2. Compute the corresponding probability distributions $p^{(s)}$ using the softmax function on $\\ell'^{(s)}$.\n3. Calculate the predictive distribution $\\bar{p}_{\\text{temp}} = \\frac{1}{S} \\sum_{s=1}^{S} p^{(s)}$.\n4. Compute the predictive entropy $H(\\bar{p}_{\\text{temp}})$.\n5. For each $p^{(s)}$, calculate its entropy $H(p^{(s)})$.\n6. Compute the expected data entropy $\\mathbb{E}[H]_{\\text{temp}} = \\frac{1}{S} \\sum_{s=1}^{S} H(p^{(s)})$.\n7. The mutual information is $I_{\\text{temp}} = H(\\bar{p}_{\\text{temp}}) - \\mathbb{E}[H]_{\\text{temp}}$.\n\n**2. Dirichlet Calibration**\n\nDirichlet calibration models the distribution over the class probabilities directly. Given a mean prediction $\\bar{p}$, a Dirichlet distribution $\\text{Dir}(\\alpha)$ is constructed, where the concentration parameters are $\\alpha = s \\cdot \\bar{p}$. The hyperparameter $s > 0$ represents the total concentration, or model confidence. A large $s$ implies the distribution of probabilities is tightly concentrated around $\\bar{p}$, representing high model confidence.\n\nAs per the problem specification, the mean prediction $\\bar{p}$ for this method is always derived from unscaled logits (i.e., using $T=1$). The procedure for a given concentration $s$ is:\n1. For each of the $S=4$ logit vectors $\\ell^{(s)}$, compute the probability distribution $p^{(s)}$ using softmax on the unscaled logits.\n2. Calculate the mean prediction $\\bar{p} = \\frac{1}{S} \\sum_{s=1}^{S} p^{(s)}$. This $\\bar{p}$ is fixed for a given input, regardless of $s$.\n3. The predictive entropy is $H(\\bar{p})$. This value is also fixed for a given input.\n4. The concentration parameters for the Dirichlet prior are $\\alpha_k = s \\cdot \\bar{p}_k$ for $k=1, \\dots, K$. The sum of concentrations is $\\alpha_0 = \\sum_{k=1}^K \\alpha_k = s \\sum_{k=1}^K \\bar{p}_k = s$.\n5. The expected data entropy is computed analytically as the expectation of the entropy of a random probability vector $\\pi$ drawn from $\\text{Dir}(\\alpha)$: $\\mathbb{E}_{\\pi \\sim \\text{Dir}(\\alpha)}[H(\\pi)]$. This has a closed-form solution involving the digamma function, $\\psi(x) = \\frac{d}{dx}\\log\\Gamma(x)$:\n$$\\mathbb{E}_{\\pi}[H] = \\psi(\\alpha_0+1) - \\sum_{k=1}^{K} \\frac{\\alpha_k}{\\alpha_0} \\psi(\\alpha_k+1)$$\nSubstituting $\\alpha_k = s \\cdot \\bar{p}_k$ and $\\alpha_0 = s$, the expression simplifies to:\n$$\\mathbb{E}_{\\pi}[H]_{\\text{Dir}} = \\psi(s+1) - \\sum_{k=1}^{K} \\bar{p}_k \\psi(s\\bar{p}_k + 1)$$\n6. The epistemic mutual information under this model is $I_{\\text{Dir}} = H(\\bar{p}) - \\mathbb{E}_{\\pi}[H]_{\\text{Dir}}$.\n\n**3. Final Calculation and Aggregation**\n\nFor each of the three test cases (A, B, C), defined by a pair of parameters $(T, s)$, we perform the following:\n1. For each of the two ID and two OOD inputs, calculate the predictive entropy and mutual information using both temperature scaling (with parameter $T$) and Dirichlet calibration (with parameter $s$). This yields four values per input: $H(\\bar{p})_{\\text{temp}}$, $I_{\\text{temp}}$, $H(\\bar{p})_{\\text{Dir}}$, and $I_{\\text{Dir}}$.\n2. For each method, calculate the average values for the ID set and the OOD set. For example, $\\text{mean}_{\\text{ID}}(I_{\\text{temp}}) = \\frac{1}{2}(I_{\\text{temp, ID1}} + I_{\\text{temp, ID2}})$.\n3. Compute the separation metrics, which are the differences between the OOD and ID means:\n$$\\Delta I_{\\text{temp}} = \\text{mean}_{\\text{OOD}}(I_{\\text{temp}}) - \\text{mean}_{\\text{ID}}(I_{\\text{temp}})$$\n$$\\Delta H_{\\text{temp}} = \\text{mean}_{\\text{OOD}}(H(\\bar{p})_{\\text{temp}}) - \\text{mean}_{\\text{ID}}(H(\\bar{p})_{\\text{temp}})$$\nAnd similarly for $\\Delta I_{\\text{Dir}}$ and $\\Delta H_{\\text{Dir}}$.\n4. The twelve resulting values (four for each of the three cases) are collected and formatted as the final output. Note that since $H(\\bar{p})_{\\text{Dir}}$ for a given input does not depend on $s$, the value of $\\Delta H_{\\text{Dir}}$ will be the same for all three test cases.\n\nThe implementation will follow this logic systematically to compute the required values.", "answer": "```python\nimport numpy as np\nfrom scipy.special import digamma\n\ndef solve():\n    \"\"\"\n    Solves the uncertainty quantification problem as specified.\n    \"\"\"\n\n    # Data as specified in the problem statement\n    id_logits_sets = [\n        np.array([\n            [5.0, 0.1, -0.2],\n            [4.8, 0.0, -0.1],\n            [5.2, -0.2, -0.1],\n            [5.1, 0.2, -0.3]\n        ]),\n        np.array([\n            [0.1, 5.0, -0.2],\n            [-0.1, 5.2, -0.3],\n            [0.0, 4.9, 0.1],\n            [0.2, 5.1, -0.4]\n        ])\n    ]\n\n    ood_logits_sets = [\n        np.array([\n            [0.3, -0.2, 0.1],\n            [-0.1, 0.4, -0.3],\n            [0.2, 0.1, -0.3],\n            [-0.4, 0.2, 0.2]\n        ]),\n        np.array([\n            [0.0, 0.0, 0.0],\n            [0.2, -0.2, 0.1],\n            [-0.3, 0.3, 0.0],\n            [0.1, 0.0, -0.1]\n        ])\n    ]\n\n    # Test cases: (Temperature T, Concentration s)\n    test_cases = [\n        (1.0, 3.0),   # Case A\n        (2.5, 0.8),   # Case B\n        (0.5, 10.0)   # Case C\n    ]\n\n    def stable_softmax(x, axis=-1):\n        \"\"\"Numerically stable softmax function.\"\"\"\n        e_x = np.exp(x - np.max(x, axis=axis, keepdims=True))\n        return e_x / np.sum(e_x, axis=axis, keepdims=True)\n\n    def entropy(p, axis=-1):\n        \"\"\"Calculates entropy of a probability distribution.\"\"\"\n        # Use a small epsilon to avoid log(0)\n        p_safe = p[p > 1e-9]\n        return -np.sum(p_safe * np.log(p_safe), axis=axis)\n\n    def get_temp_uncertainty(logits_set, T):\n        \"\"\"Calculates uncertainties using temperature scaling.\"\"\"\n        scaled_logits = logits_set / T\n        probs = stable_softmax(scaled_logits)\n        \n        p_bar = np.mean(probs, axis=0)\n        H_p_bar = entropy(p_bar)\n        \n        entropies = np.array([entropy(p) for p in probs])\n        E_H = np.mean(entropies)\n        \n        I = H_p_bar - E_H\n        return H_p_bar, I\n\n    def get_dirichlet_uncertainty(logits_set, s):\n        \"\"\"Calculates uncertainties using Dirichlet calibration.\"\"\"\n        # Per problem, use unscaled logits (T=1) for p_bar\n        unscaled_probs = stable_softmax(logits_set)\n        p_bar = np.mean(unscaled_probs, axis=0)\n\n        # Predictive entropy\n        H_p_bar = entropy(p_bar)\n\n        # Expected data entropy\n        alpha = s * p_bar\n        alpha_0 = s\n        \n        # Use the analytical expression for expected entropy\n        E_H_dir = digamma(alpha_0 + 1) - np.sum(p_bar * digamma(alpha + 1))\n        \n        # Epistemic mutual information\n        I_dir = H_p_bar - E_H_dir\n        \n        return H_p_bar, I_dir\n\n    final_results = []\n    for T, s in test_cases:\n        # Temperature Scaling Calculations\n        id_H_temp = []\n        id_I_temp = []\n        for logits in id_logits_sets:\n            H, I = get_temp_uncertainty(logits, T)\n            id_H_temp.append(H)\n            id_I_temp.append(I)\n\n        ood_H_temp = []\n        ood_I_temp = []\n        for logits in ood_logits_sets:\n            H, I = get_temp_uncertainty(logits, T)\n            ood_H_temp.append(H)\n            ood_I_temp.append(I)\n        \n        delta_I_temp = np.mean(ood_I_temp) - np.mean(id_I_temp)\n        delta_H_temp = np.mean(ood_H_temp) - np.mean(id_H_temp)\n        \n        # Dirichlet Calibration Calculations\n        id_H_dir = []\n        id_I_dir = []\n        for logits in id_logits_sets:\n            H, I = get_dirichlet_uncertainty(logits, s)\n            id_H_dir.append(H)\n            id_I_dir.append(I)\n        \n        ood_H_dir = []\n        ood_I_dir = []\n        for logits in ood_logits_sets:\n            H, I = get_dirichlet_uncertainty(logits, s)\n            ood_H_dir.append(H)\n            ood_I_dir.append(I)\n\n        delta_I_dir = np.mean(ood_I_dir) - np.mean(id_I_dir)\n        delta_H_dir = np.mean(ood_H_dir) - np.mean(id_H_dir)\n\n        final_results.extend([delta_I_temp, delta_H_temp, delta_I_dir, delta_H_dir])\n\n    # Format the final output as a comma-separated list of floats in brackets\n    print(f\"[{','.join(f'{x:.7f}' for x in final_results)}]\")\n\nsolve()\n```", "id": "3197050"}]}