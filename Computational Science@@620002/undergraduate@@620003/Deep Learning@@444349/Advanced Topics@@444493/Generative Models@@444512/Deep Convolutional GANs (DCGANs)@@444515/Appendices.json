{"hands_on_practices": [{"introduction": "A key advantage of Deep Convolutional Generative Adversarial Networks (DCGANs) is their fully convolutional nature, which provides flexibility in handling different image resolutions. This exercise allows you to mathematically analyze the architectural properties of a DCGAN, exploring how its internal feature map sizes and receptive fields adapt to varying input dimensions. By performing these calculations, you will gain a concrete understanding of the design principles that enable advanced training strategies like curriculum learning, where a model is progressively trained on higher-resolution data. [@problem_id:3112718]", "problem": "You are asked to formalize and analyze a curriculum training protocol for a Deep Convolutional Generative Adversarial Network (DCGAN), where training begins on low-resolution images of size $16\\times 16$ and progressively increases to $64\\times 64$, without changing the network architecture. Your task is to derive, implement, and compute shape and receptive-field properties that justify whether the discriminator and generator can handle this scaling purely by virtue of convolutional arithmetic, assuming a fully convolutional DCGAN design.\n\nUse the following context and constraints, which you must interpret in purely mathematical and algorithmic terms, without assuming access to any deep learning framework:\n\n- The model follows the Deep Convolutional Generative Adversarial Network (DCGAN) pattern, interpreted as fully convolutional networks (no linear layers), with the discriminator using a stack of strided convolutions and a final global spatial average to produce a scalar, and the generator using a stack of transposed convolutions to upsample from a small latent grid to an image. The curriculum proceeds through target resolutions $H \\in \\{16, 32, 64\\}$ (all square images), and the architecture must remain fixed across stages.\n- In each discriminator block, there is a convolution with kernel size $k$, stride $s$, and padding $p$ on both spatial dimensions. The output height (and width) after one such convolution is to be computed using the discrete convolution output size rule. For a stack of $n_d$ such blocks, apply the rule iteratively.\n- The receptive field of a single output activation at a given layer with respect to the input is defined recursively using only kernel sizes and strides. You must compute the receptive field after the last discriminator block. Padding does not change the receptive field size.\n- The generator is assumed to produce a fixed “native” resolution $H_{\\text{native}}$ determined by a base latent grid of size $H_0$ and $n_g$ transposed convolution blocks, each with stride $2$ that double the spatial size. For curriculum stages with a target resolution $H_{\\text{target}} \\in \\{16, 32, 64\\}$, we consider the generator compatible “without architectural changes” if the ratio $H_{\\text{native}}/H_{\\text{target}}$ is an integer power of $2$ (so that a fixed, external downsampler by a power-of-two factor can be used during training without modifying the network).\n- You must use only the standard discrete convolution output size rule and the standard receptive-field recursion for stride-$1$ dilations (no dilation greater than $1$ is used). No other shortcuts are permitted.\n\nFor each test case defined below, and for each target resolution $H \\in \\{16, 32, 64\\}$, your program must compute and report:\n\n1) The discriminator’s final feature-map spatial size $H_{\\text{feat}} \\times H_{\\text{feat}}$ after $n_d$ blocks.\n2) The discriminator’s last-layer receptive field $R$ (height equals width by symmetry) and the ratio $R/H$ as a float.\n3) A boolean indicating whether a single last-layer activation’s receptive field covers the entire input, that is, whether $R \\ge H$.\n4) A boolean indicating generator compatibility with the curriculum resolution without architectural changes, that is, whether $H_{\\text{native}}/H$ is an integer that is a power of $2$.\n5) The number of spatial positions contributing to the discriminator’s global decision before the final averaging, $N_{\\text{pos}} = H_{\\text{feat}}^2$.\n\nYour program must aggregate the results for all target resolutions of a given test case into a list:\n[ [H_feat(16),H_feat(32),H_feat(64)],\n  [R_over_H(16),R_over_H(32),R_over_H(64)],\n  [D_global_coverage(16),D_global_coverage(32),D_global_coverage(64)],\n  [G_compatible(16),G_compatible(32),G_compatible(64)],\n  [N_pos(16),N_pos(32),N_pos(64)] ]\n\nFinally, aggregate the three test cases into a single top-level list:\n[case1_results,case2_results,case3_results]\n\nAll numeric computations must be done exactly according to the rules given, with any floating-point outputs left in standard decimal form. If you choose to round, round the ratios $R/H$ to $6$ decimal places. There are no physical units involved.\n\nTest Suite:\n\n- Case $1$: $n_g = 4$, $n_d = 4$, $k = 4$, $s = 2$, $p = 1$, $H_0 = 4$, $H \\in \\{16,32,64\\}$.\n- Case $2$: $n_g = 4$, $n_d = 3$, $k = 4$, $s = 2$, $p = 1$, $H_0 = 4$, $H \\in \\{16,32,64\\}$.\n- Case $3$: $n_g = 4$, $n_d = 4$, $k = 3$, $s = 2$, $p = 1$, $H_0 = 4$, $H \\in \\{16,32,64\\}$.\n\nFinal Output Format:\n\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, exactly as: [case1_results,case2_results,case3_results].", "solution": "The problem requires a formal analysis of a Deep Convolutional Generative Adversarial Network (DCGAN) architecture's compatibility with a curriculum learning protocol. The protocol involves training on images of progressively increasing resolution, specifically $H \\in \\{16, 32, 64\\}$, while keeping the network architectures for the generator and discriminator fixed. The analysis is to be conducted purely through the mathematical properties of the convolutional and transposed convolutional layers, without empirical training. We must compute several key metrics for both the discriminator and the generator for three specific architectural configurations (test cases).\n\n### Principle-Based Design and Derivations\n\nThe analysis relies on fundamental principles of convolutional arithmetic and receptive field calculation.\n\n**1. Discriminator Model and Feature Map Sizing**\n\nThe discriminator is a fully convolutional network composed of a stack of $n_d$ identical convolutional blocks. Each block applies a convolution with kernel size $k$, stride $s$, and padding $p$. The problem specifies the formula for computing the output spatial dimension $H_{out}$ from an input dimension $H_{in}$:\n$$H_{out} = \\left\\lfloor \\frac{H_{in} - k + 2p}{s} \\right\\rfloor + 1$$\nFor a discriminator with $n_d$ blocks, this formula is applied iteratively. Starting with an input image of size $H \\times H$, we denote the feature map size after the $i$-th block as $H_i \\times H_i$. The sequence of sizes is given by:\n$$H_i = \\left\\lfloor \\frac{H_{i-1} - k + 2p}{s} \\right\\rfloor + 1 \\quad \\text{for } i = 1, \\dots, n_d$$\nwhere $H_0 = H$ is the input image size. The final feature map size, which we denote as $H_{\\text{feat}}$, is $H_{n_d}$. The number of spatial positions that contribute to the final global average pooling is then $N_{\\text{pos}} = H_{\\text{feat}}^2$.\n\n**2. Discriminator Receptive Field**\n\nThe receptive field ($R$) of a neuron in the final layer is the size of the region in the input image that influences its activation. The problem defines its calculation recursively. For a stack of convolutions, the receptive field $R_i$ after layer $i$ is calculated based on the receptive field $R_{i-1}$ after the previous layer, the kernel size $k_i$ of the current layer, and the cumulative stride product up to the previous layer, $J_{i-1}$.\nThe recursive relations are:\n$$R_i = R_{i-1} + (k_i - 1) \\cdot J_{i-1}$$\n$$J_i = J_{i-1} \\cdot s_i$$\nwith base cases $R_0 = 1$ (a pixel in the input layer has a receptive field of size $1$) and $J_0 = 1$. Since all discriminator blocks are identical, we have $k_i = k$ and $s_i = s$ for all $i$. The calculation is performed for $i = 1, \\dots, n_d$ to find the final receptive field $R = R_{n_d}$. A key metric is whether the receptive field covers the entire input image, i.e., whether $R \\ge H$.\n\n**3. Generator Model and Compatibility**\n\nThe generator is a fully convolutional network that upsamples a latent grid of size $H_0 \\times H_0$ to a full-sized image using $n_g$ transposed convolution blocks. Each block is specified to have a stride of $s_g=2$ and to double the spatial dimensions. The \"native\" resolution of the generator, $H_{\\text{native}}$, is the final output size after all $n_g$ blocks. It can be calculated as:\n$$H_{\\text{native}} = H_0 \\cdot (s_g)^{n_g} = H_0 \\cdot 2^{n_g}$$\nFor the generator to be considered compatible \"without architectural changes\" with a target curriculum resolution $H$, the problem states that the ratio $H_{\\text{native}} / H$ must be an integer that is also a power of $2$. This means:\n$$\\frac{H_{\\text{native}}}{H} = 2^m \\quad \\text{for some integer } m \\ge 0$$\nThis condition ensures that a simple, fixed downsampler (e.g., average pooling with a power-of-two stride) can bridge the gap between the generator's fixed output resolution and the smaller target resolutions required in the early stages of the curriculum.\n\n### Analysis Procedure\n\nFor each test case, defined by a set of parameters $\\{n_g, n_d, k, s, p, H_0\\}$, we perform the following calculations.\n\nFirst, we compute the properties that are constant for the given architecture, regardless of the input resolution $H$:\n- The generator's native resolution, $H_{\\text{native}}$.\n- The discriminator's final receptive field, $R$.\n\nNext, for each target resolution $H \\in \\{16, 32, 64\\}$, we compute the five required metrics:\n1.  **$H_{\\text{feat}}$**: Iteratively apply the convolution output size formula $n_d$ times, starting with $H_0 = H$.\n2.  **$R/H$**: Calculate the ratio of the receptive field to the input size. This will be rounded to $6$ decimal places.\n3.  **$D_{\\text{global\\_coverage}}$**: Evaluate the boolean condition $R \\ge H$.\n4.  **$G_{\\text{compatible}}$**: Evaluate the boolean condition that $H_{\\text{native}} / H$ is an integer and a power of $2$.\n5.  **$N_{\\text{pos}}$**: Compute the number of positions in the final feature map, $H_{\\text{feat}}^2$.\n\nThe results for each test case are aggregated into a list of lists, which are then collected into a single top-level list for the final output. The following Python implementation executes this procedure.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n# from scipy import ...\n\ndef solve():\n    \"\"\"\n    Computes shape and receptive-field properties for a DCGAN under a curriculum\n    training protocol.\n    \"\"\"\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # (n_g, n_d, k, s, p, H_0)\n        # Case 1\n        (4, 4, 4, 2, 1, 4),\n        # Case 2\n        (4, 3, 4, 2, 1, 4),\n        # Case 3\n        (4, 4, 3, 2, 1, 4),\n    ]\n\n    target_resolutions = [16, 32, 64]\n\n    def calculate_h_feat(h_in, n_d, k, s, p):\n        \"\"\"Calculates the discriminator's final feature map size.\"\"\"\n        h_current = h_in\n        for _ in range(n_d):\n            h_current = np.floor((h_current - k + 2 * p) / s) + 1\n        return int(h_current)\n\n    def calculate_receptive_field(n_d, k, s):\n        \"\"\"Calculates the discriminator's final receptive field size.\"\"\"\n        r = 1  # R_0\n        j = 1  # J_0\n        for _ in range(n_d):\n            r = r + (k - 1) * j\n            j = j * s\n        return r\n\n    def calculate_h_native(h_0, n_g):\n        \"\"\"Calculates the generator's native output resolution.\"\"\"\n        # Each block has stride 2 and doubles the size.\n        return h_0 * (2 ** n_g)\n\n    def is_power_of_two(n):\n        \"\"\"Checks if a positive integer is a power of two.\"\"\"\n        if n <= 0:\n            return False\n        return (n & (n - 1)) == 0\n\n    all_cases_results = []\n    for case in test_cases:\n        n_g, n_d, k, s, p, h_0 = case\n\n        h_feat_list = []\n        r_over_h_list = []\n        d_global_coverage_list = []\n        g_compatible_list = []\n        n_pos_list = []\n        \n        # Calculate case-constant values\n        r = calculate_receptive_field(n_d, k, s)\n        h_native = calculate_h_native(h_0, n_g)\n\n        for h_target in target_resolutions:\n            # 1. Discriminator's final feature-map spatial size\n            h_feat = calculate_h_feat(h_target, n_d, k, s, p)\n            h_feat_list.append(h_feat)\n\n            # 2. Discriminator's last-layer receptive field ratio\n            r_over_h = round(r / h_target, 6)\n            r_over_h_list.append(r_over_h)\n\n            # 3. Boolean indicating if receptive field covers the entire input\n            d_global_coverage = r >= h_target\n            d_global_coverage_list.append(d_global_coverage)\n\n            # 4. Boolean indicating generator compatibility\n            ratio = h_native / h_target\n            g_compatible = ratio.is_integer() and is_power_of_two(int(ratio))\n            g_compatible_list.append(g_compatible)\n\n            # 5. Number of spatial positions contributing to the discriminator's decision\n            n_pos = h_feat ** 2\n            n_pos_list.append(n_pos)\n\n        case_results = [\n            h_feat_list,\n            r_over_h_list,\n            d_global_coverage_list,\n            g_compatible_list,\n            n_pos_list,\n        ]\n        all_cases_results.append(case_results)\n\n    # Final print statement in the exact required format.\n    # Convert the nested list to a string and remove spaces for compact output.\n    final_output_string = str(all_cases_results).replace(\" \", \"\")\n    print(final_output_string)\n\nsolve()\n```", "id": "3112718"}, {"introduction": "The latent space of a GAN can be thought of as a high-dimensional space of concepts, where each point corresponds to a potential image. This practice invites you to explore the geometry of this mapping by taking a simple, straight-line walk between two points in the latent space and observing the resulting journey in the image space. By implementing simplified generator models, you will discover how architectural choices, especially the use of nonlinearities, transform this simple path into a complex, \"entangled\" manifold, providing fundamental insights into how generators create rich and varied outputs. [@problem_id:3112803]", "problem": "Consider Deep Convolutional Generative Adversarial Networks (DCGANs), where the generator maps a latent vector to an image through convolutional computations and pointwise nonlinearities. Let the latent space be a real vector space of dimension $d$, and denote latent vectors by $\\mathbf{z} \\in \\mathbb{R}^d$. A generator is a function $G: \\mathbb{R}^d \\to \\mathbb{R}^{S \\times S}$ that produces an image of spatial resolution $S \\times S$ from a latent vector. The goal is to assess whether the generator exhibits linear disentanglement along a linear interpolation in latent space, or whether the generator induces an entangled manifold, by measuring output-path smoothness via the $L_2$ differences between consecutive generated images along the path.\n\nFundamental base and definitions:\n- Generative Adversarial Networks (GANs) define a generator $G$ that transforms a latent vector $\\mathbf{z}$ into a data sample; Deep Convolutional Generative Adversarial Networks (DCGANs) specialize $G$ through convolutional layers.\n- A linear interpolation path in latent space is $ \\mathbf{z}(t) = (1-t)\\,\\mathbf{z}_1 + t\\,\\mathbf{z}_2$ for $t \\in [0,1]$.\n- The $L_2$ norm of a vector $\\mathbf{x} \\in \\mathbb{R}^n$ is $ \\|\\mathbf{x}\\|_2 = \\sqrt{\\sum_{i=1}^{n} x_i^2}$.\n- The path smoothness along a discretized interpolation $t_i$ is assessed by the sequence of $L_2$ differences $d_i = \\|G(\\mathbf{z}(t_{i+1})) - G(\\mathbf{z}(t_i))\\|_2$.\n- Angles in trigonometric functions are to be interpreted in radians.\n\nYou will implement three generator prototypes, each constructed from principled convolutional operations and upsampling, with fixed, deterministic kernels and basis maps. All constructions must use only linear convolution and pointwise nonlinearities; convolution must be two-dimensional and applied channel-wise or after channel mixing as specified. The following constants are used throughout:\n- Latent dimension $d = 8$.\n- Base feature grid size $s = 4$ and upsampled output spatial size $S = 8$.\n- Two intermediate channels, indexed by $c \\in \\{0,1\\}$.\n\nDefine the basis functions for constructing channel feature maps from a latent vector $\\mathbf{z} = (z_1,\\dots,z_d)$ as follows. For each channel $c \\in \\{0,1\\}$ and each spatial index $(i,j)$ with $i \\in \\{0,\\dots,s-1\\}$ and $j \\in \\{0,\\dots,s-1\\}$:\n- For channel $c=0$, define\n$$\na_k^{(0)}(i,j) = \\sin\\!\\left(\\frac{\\pi\\,(k+1)\\,(i+1)}{s}\\right) + \\cos\\!\\left(\\frac{\\pi\\,(k+1)\\,(j+1)}{s}\\right).\n$$\n- For channel $c=1$, define\n$$\na_k^{(1)}(i,j) = \\cos\\!\\left(\\frac{\\pi\\,(k+1)\\,(i+1)}{s}\\right) - \\sin\\!\\left(\\frac{\\pi\\,(k+1)\\,(j+1)}{s}\\right).\n$$\nConstruct the base feature maps $F_c \\in \\mathbb{R}^{s \\times s}$ by\n$$\nF_c(i,j) = \\frac{1}{d}\\sum_{k=1}^{d} z_k \\, a_k^{(c)}(i,j).\n$$\nUpsample each $F_c$ to $U_c \\in \\mathbb{R}^{S \\times S}$ by nearest-neighbor replication, that is, each element of $F_c$ is duplicated into a $2 \\times 2$ block.\n\nDefine two fixed convolution kernels of size $3 \\times 3$ with indices $p,q \\in \\{0,1,2\\}$:\n$$\nK_0(p,q) = \\frac{1}{1 + p + q}, \\quad K_1(p,q) = \\frac{(-1)^{p+q}}{1 + p + q}.\n$$\nConvolution is performed as two-dimensional convolution with stride $1$, padding handled symmetrically, and output shape equal to input shape (standard \"same\" convolution). The following three generator prototypes must be implemented:\n1. Linear generator $G_{\\mathrm{lin}}$: compute\n$$\nH_0 = \\mathrm{conv2d}(U_0, K_0), \\quad H_1 = \\mathrm{conv2d}(U_1, K_1), \\quad G_{\\mathrm{lin}}(\\mathbf{z}) = H_0 + H_1.\n$$\n2. Nonlinear gating generator $G_{\\mathrm{gate}}$: compute\n$$\nH_0 = \\mathrm{conv2d}(U_0, K_0), \\quad H_1 = \\mathrm{conv2d}(U_1, K_1),\n$$\nthen apply pointwise nonlinearities and multiplicative interaction,\n$$\nG_{\\mathrm{gate}}(\\mathbf{z}) = \\tanh(H_0) \\odot \\max(H_1, 0) + \\frac{1}{2}\\,\\mathrm{conv2d}(\\tanh(H_0), K_0),\n$$\nwhere $\\odot$ denotes elementwise multiplication.\n3. Saturating tanh generator $G_{\\tanh}$: compute\n$$\nG_{\\tanh}(\\mathbf{z}) = \\tanh\\!\\big(\\mathrm{conv2d}(U_0 + U_1, K_0)\\big).\n$$\n\nFor a given generator $G$, latent endpoints $\\mathbf{z}_1$ and $\\mathbf{z}_2$, a number of discrete steps $n \\in \\mathbb{N}$, and a threshold $\\varepsilon > 0$, define a uniform discretization $t_i = \\frac{i}{n}$ for $i \\in \\{0,1,\\dots,n\\}$ and compute differences\n$$\nd_i = \\left\\| \\mathrm{vec}\\!\\big(G(\\mathbf{z}(t_{i+1}))\\big) - \\mathrm{vec}\\!\\big(G(\\mathbf{z}(t_i))\\big) \\right\\|_2,\\quad i \\in \\{0,1,\\dots,n-1\\},\n$$\nwhere $\\mathrm{vec}(\\cdot)$ denotes vectorization of the $S \\times S$ image into $\\mathbb{R}^{S^2}$. Let the mean and standard deviation of $\\{d_i\\}_{i=0}^{n-1}$ be $m$ and $s$, respectively, and define the coefficient of variation\n$$\n\\mathrm{CV} = \\begin{cases}\n\\frac{s}{m}, & \\text{if } m > 0,\\\n$$6pt]\n0, & \\text{if } m = 0.\n\\end{cases}\n$$\nClassify the generator behavior as \"linear disentanglement\" if $\\mathrm{CV} \\le \\varepsilon$, and \"entangled manifolds\" otherwise. Return a boolean for each test case, where $\\mathrm{True}$ denotes \"linear disentanglement\" and $\\mathrm{False}$ denotes \"entangled manifolds\".\n\nYour program must implement the above definitions and compute the classification for each of the following test cases (all angles in the trigonometric functions are in radians):\n\n- Test case $1$ (happy path, linear generator):\n  - Generator: $G_{\\mathrm{lin}}$.\n  - $\\mathbf{z}_1 = [0.1, -0.2, 0.3, -0.4, 0.5, -0.6, 0.7, -0.8]$.\n  - $\\mathbf{z}_2 = [-0.5, 0.4, -0.3, 0.2, -0.1, 0.0, 0.1, 0.2]$.\n  - Steps: $n = 20$.\n  - Threshold: $\\varepsilon = 10^{-6}$.\n\n- Test case $2$ (nonlinear gating, expected entanglement):\n  - Generator: $G_{\\mathrm{gate}}$.\n  - $\\mathbf{z}_1 = [-1.5, 0.0, 0.5, -0.2, 1.0, -1.2, 0.3, 0.7]$.\n  - $\\mathbf{z}_2 = [2.0, -0.5, 0.8, -1.0, 1.5, 0.0, -0.3, 0.1]$.\n  - Steps: $n = 20$.\n  - Threshold: $\\varepsilon = 0.02$.\n\n- Test case $3$ (boundary condition, identical endpoints):\n  - Generator: $G_{\\tanh}$.\n  - $\\mathbf{z}_1 = [0.3, -0.1, 0.05, 0.0, -0.2, 0.4, -0.3, 0.2]$.\n  - $\\mathbf{z}_2 = [0.3, -0.1, 0.05, 0.0, -0.2, 0.4, -0.3, 0.2]$.\n  - Steps: $n = 10$.\n  - Threshold: $\\varepsilon = 10^{-6}$.\n\n- Test case $4$ (saturation edge case):\n  - Generator: $G_{\\tanh}$.\n  - $\\mathbf{z}_1 = [3.0, -2.5, 2.2, -1.8, 1.6, -1.4, 1.2, -1.0]$.\n  - $\\mathbf{z}_2 = [-3.0, 2.4, -2.1, 1.9, -1.7, 1.5, -1.3, 1.1]$.\n  - Steps: $n = 20$.\n  - Threshold: $\\varepsilon = 0.02$.\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (e.g., $[result_1,result_2,result_3,result_4]$), where each $result_i$ is a boolean as defined above.", "solution": "The user's problem statement has been analyzed and validated. It is scientifically grounded, well-posed, objective, and internally consistent. All definitions and parameters are provided, enabling a direct and unambiguous implementation. The problem is a stylized but conceptually sound exploration of feature entanglement in a simplified Deep Convolutional Generative Adversarial Network (DCGAN) generator, which is a relevant topic in deep learning.\n\nThe solution will be constructed by implementing the specified components in a step-by-step manner, corresponding to the mathematical definitions provided.\n\n### 1. Preliminaries and Constants\nThe problem defines several constants: latent dimension $d=8$, base grid size $s=4$, and output grid size $S=8$. The analysis involves two channels, indexed by $c \\in \\{0,1\\}$. All angles in trigonometric functions are specified to be in radians.\n\n### 2. Convolution Kernels\nTwo fixed $3 \\times 3$ convolution kernels, $K_0$ and $K_1$, are defined. For indices $p,q \\in \\{0,1,2\\}$:\n$$\nK_0(p,q) = \\frac{1}{1 + p + q}\n$$\n$$\nK_1(p,q) = \\frac{(-1)^{p+q}}{1 + p + q}\n$$\nThese kernels will be pre-computed as $3 \\times 3$ matrices. The convolution operation is a standard 2D convolution with stride $1$ and symmetric padding such that the output dimensions match the input dimensions ('same' convolution). For a $3 \\times 3$ kernel, this requires a padding of width $1$ on all sides of the input feature map.\n\n### 3. Basis Map Construction\nThe initial feature maps are constructed from a latent vector $\\mathbf{z} \\in \\mathbb{R}^d$ using a set of basis functions. For each channel $c \\in \\{0,1\\}$, a set of $d=8$ basis maps $\\{ a_k^{(c)} \\}_{k=1}^d$ are defined. For spatial indices $i \\in \\{0, \\dots, s-1\\}$ and $j \\in \\{0, \\dots, s-1\\}$, and basis index $k \\in \\{1, \\dots, d\\}$:\n- Channel $c=0$: $a_k^{(0)}(i,j) = \\sin\\!\\left(\\frac{\\pi\\,(k+1)\\,(i+1)}{s}\\right) + \\cos\\!\\left(\\frac{\\pi\\,(k+1)\\,(j+1)}{s}\\right)$\n- Channel $c=1$: $a_k^{(1)}(i,j) = \\cos\\!\\left(\\frac{\\pi\\,(k+1)\\,(i+1)}{s}\\right) - \\sin\\!\\left(\\frac{\\pi\\,(k+1)\\,(j+1)}{s}\\right)$\n\nThese basis maps of size $s \\times s$ are fixed and can be pre-computed.\n\n### 4. Base Feature Map Generation\nGiven a latent vector $\\mathbf{z} = (z_1, \\dots, z_d)$, the base feature maps $F_c \\in \\mathbb{R}^{s \\times s}$ are computed as a linear combination of the basis maps:\n$$\nF_c(i,j) = \\frac{1}{d}\\sum_{k=1}^{d} z_k \\, a_k^{(c)}(i,j)\n$$\nThis operation is linear with respect to the input latent vector $\\mathbf{z}$.\n\n### 5. Upsampling\nThe base feature maps $F_c$ of size $s \\times s = 4 \\times 4$ are upsampled to $U_c$ of size $S \\times S = 8 \\times 8$. The specified method is nearest-neighbor replication, where each value in $F_c$ is duplicated to form a $2 \\times 2$ block in $U_c$. This operation is also linear.\n\n### 6. Generator Architectures\nThree distinct generator functions, $G_{\\mathrm{lin}}$, $G_{\\mathrm{gate}}$, and $G_{\\tanh}$, are implemented. Each maps a latent vector $\\mathbf{z}$ to an $S \\times S$ output image.\n\n1.  **Linear Generator $G_{\\mathrm{lin}}$**: This generator is a purely linear transformation.\n    $$\n    H_0 = \\mathrm{conv2d}(U_0, K_0), \\quad H_1 = \\mathrm{conv2d}(U_1, K_1)\n    $$\n    $$\n    G_{\\mathrm{lin}}(\\mathbf{z}) = H_0 + H_1\n    $$\n    Since all constituent operations (basis map combination, upsampling, convolution, addition) are linear, the entire mapping from $\\mathbf{z}$ to $G_{\\mathrm{lin}}(\\mathbf{z})$ is linear.\n\n2.  **Nonlinear Gating Generator $G_{\\mathrm{gate}}$**: This generator introduces nonlinearities and channel interaction.\n    $$\n    H_0 = \\mathrm{conv2d}(U_0, K_0), \\quad H_1 = \\mathrm{conv2d}(U_1, K_1)\n    $$\n    $$\n    G_{\\mathrm{gate}}(\\mathbf{z}) = \\tanh(H_0) \\odot \\max(H_1, 0) + \\frac{1}{2}\\,\\mathrm{conv2d}(\\tanh(H_0), K_0)\n    $$\n    The pointwise hyperbolic tangent ($\\tanh$), ReLU-like gating ($\\max(H_1, 0)$), and elementwise multiplication ($\\odot$) make this a highly nonlinear function of $\\mathbf{z}$.\n\n3.  **Saturating Tanh Generator $G_{\\tanh}$**: This generator applies a final saturating nonlinearity.\n    $$\n    G_{\\tanh}(\\mathbf{z}) = \\tanh\\!\\big(\\mathrm{conv2d}(U_0 + U_1, K_0)\\big)\n    $$\n    Here, the channels are mixed by addition before convolution. The final $\\tanh$ function will cause saturation for large input values, a common feature in GANs.\n\n### 7. Path Smoothness Analysis\nThe core of the problem is to analyze the smoothness of the output path generated by a linear interpolation in the latent space.\n- The latent path is $\\mathbf{z}(t) = (1-t)\\,\\mathbf{z}_1 + t\\,\\mathbf{z}_2$ for $t \\in [0,1]$.\n- This path is discretized using $t_i = \\frac{i}{n}$ for $i \\in \\{0, 1, \\dots, n\\}$.\n- For each segment of the path, the $L_2$ distance between consecutive generated images is computed:\n$$\nd_i = \\left\\| \\mathrm{vec}\\!\\big(G(\\mathbf{z}(t_{i+1}))\\big) - \\mathrm{vec}\\!\\big(G(\\mathbf{z}(t_i))\\big) \\right\\|_2, \\quad \\text{for } i \\in \\{0, 1, \\dots, n-1\\}\n$$\nThis gives a sequence of $n$ distance values $\\{d_i\\}_{i=0}^{n-1}$.\n\n### 8. Classification\nThe behavior of the generator is classified based on the uniformity of these step sizes.\n- The mean $m$ and standard deviation $s$ of the sequence $\\{d_i\\}$ are calculated.\n- The coefficient of variation, $\\mathrm{CV} = s/m$ (or $0$ if $m=0$), is computed. A low $\\mathrm{CV}$ indicates that the step sizes $d_i$ are nearly constant, suggesting a linear or near-linear mapping along the path. A high $\\mathrm{CV}$ indicates varying step sizes, characteristic of a curved, entangled manifold.\n- The generator's behavior is classified as \"linear disentanglement\" (returning $\\mathrm{True}$) if $\\mathrm{CV} \\le \\varepsilon$, and \"entangled manifolds\" (returning $\\mathrm{False}$) otherwise.\n\n### 9. Test Case Execution\nThe implemented functions are applied to the four test cases provided.\n- For $G_{\\mathrm{lin}}$, we expect all $d_i$ values to be virtually identical because the generator is a linear transformation. This will result in $s \\approx 0$ and $\\mathrm{CV} \\approx 0$, leading to a `True` classification.\n- For the case where $\\mathbf{z}_1 = \\mathbf{z}_2$, the path is static. Thus, all $d_i=0$, leading to $m=0$, $s=0$, and $\\mathrm{CV}=0$, which results in a `True` classification.\n- For the nonlinear generators $G_{\\mathrm{gate}}$ and $G_{\\tanh}$ applied to distinct endpoints, the nonlinearities are expected to warp the latent path into a curve in the output space. The rate of travel along this curve will not be constant, leading to a significant standard deviation $s$ in the step sizes $d_i$, a non-negligible $\\mathrm{CV}$, and thus a `False` classification.\nThe final program calculates the boolean classification for each test case and prints them in the specified format.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.signal import convolve2d\n\ndef solve():\n    \"\"\"\n    Solves the problem by implementing the DCGAN generator prototypes and\n    analyzing their path smoothness.\n    \"\"\"\n\n    # Define constants from the problem statement\n    D_LATENT = 8\n    S_BASE = 4\n    S_OUTPUT = 8\n\n    # Pre-compute convolution kernels\n    p, q = np.mgrid[0:3, 0:3]\n    K0 = 1 / (1 + p + q)\n    K1 = ((-1)**(p + q)) / (1 + p + q)\n\n    # Pre-compute basis maps\n    k = np.arange(1, D_LATENT + 1)\n    i = np.arange(S_BASE)\n    j = np.arange(S_BASE)\n    \n    arg_i = np.pi * (k[:, None, None] + 1) * (i[None, :, None] + 1) / S_BASE\n    arg_j = np.pi * (k[:, None, None] + 1) * (j[None, None, :] + 1) / S_BASE\n    \n    BASIS_MAPS_0 = np.sin(arg_i) + np.cos(arg_j)\n    BASIS_MAPS_1 = np.cos(arg_i) - np.sin(arg_j)\n\n    def generate_base_maps(z: np.ndarray) -> tuple[np.ndarray, np.ndarray]:\n        \"\"\"\n        Generates the base feature maps F_0 and F_1 from a latent vector z.\n        \"\"\"\n        z_reshaped = z[:, np.newaxis, np.newaxis]\n        \n        weighted_maps_0 = z_reshaped * BASIS_MAPS_0\n        F0 = (1 / D_LATENT) * np.sum(weighted_maps_0, axis=0)\n        \n        weighted_maps_1 = z_reshaped * BASIS_MAPS_1\n        F1 = (1 / D_LATENT) * np.sum(weighted_maps_1, axis=0)\n        \n        return F0, F1\n\n    def upsample(F: np.ndarray) -> np.ndarray:\n        \"\"\"\n        Upsamples a feature map using nearest-neighbor replication.\n        \"\"\"\n        return np.kron(F, np.ones((2, 2)))\n\n    # Define Generator Prototypes\n    def g_lin(z: np.ndarray) -> np.ndarray:\n        F0, F1 = generate_base_maps(z)\n        U0, U1 = upsample(F0), upsample(F1)\n        H0 = convolve2d(U0, K0, mode='same', boundary='fill', fillvalue=0)\n        H1 = convolve2d(U1, K1, mode='same', boundary='fill', fillvalue=0)\n        return H0 + H1\n\n    def g_gate(z: np.ndarray) -> np.ndarray:\n        F0, F1 = generate_base_maps(z)\n        U0, U1 = upsample(F0), upsample(F1)\n        H0 = convolve2d(U0, K0, mode='same', boundary='fill', fillvalue=0)\n        H1 = convolve2d(U1, K1, mode='same', boundary='fill', fillvalue=0)\n        tanh_H0 = np.tanh(H0)\n        relu_H1 = np.maximum(H1, 0)\n        term1 = tanh_H0 * relu_H1\n        term2 = 0.5 * convolve2d(tanh_H0, K0, mode='same', boundary='fill', fillvalue=0)\n        return term1 + term2\n\n    def g_tanh(z: np.ndarray) -> np.ndarray:\n        F0, F1 = generate_base_maps(z)\n        U0, U1 = upsample(F0), upsample(F1)\n        U_sum = U0 + U1\n        H = convolve2d(U_sum, K0, mode='same', boundary='fill', fillvalue=0)\n        return np.tanh(H)\n\n    generator_map = {\n        \"G_lin\": g_lin,\n        \"G_gate\": g_gate,\n        \"G_tanh\": g_tanh,\n    }\n\n    def analyze_path(gen_name, z1, z2, n, epsilon):\n        \"\"\"\n        Performs the path analysis and returns the classification.\n        \"\"\"\n        gen_func = generator_map[gen_name]\n        z1_np = np.array(z1)\n        z2_np = np.array(z2)\n        \n        d_values = []\n        for i in range(n):\n            t_curr = i / n\n            t_next = (i + 1) / n\n            \n            z_curr = (1 - t_curr) * z1_np + t_curr * z2_np\n            z_next = (1 - t_next) * z1_np + t_next * z2_np\n            \n            img_curr = gen_func(z_curr)\n            img_next = gen_func(z_next)\n            \n            diff = np.linalg.norm(img_curr.flatten() - img_next.flatten())\n            d_values.append(diff)\n            \n        d_values_np = np.array(d_values)\n        \n        mean_d = np.mean(d_values_np)\n        std_d = np.std(d_values_np)\n        \n        if mean_d > 0:\n            cv = std_d / mean_d\n        else:\n            cv = 0.0\n            \n        return cv <= epsilon\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        (\"G_lin\", [0.1, -0.2, 0.3, -0.4, 0.5, -0.6, 0.7, -0.8], [-0.5, 0.4, -0.3, 0.2, -0.1, 0.0, 0.1, 0.2], 20, 1e-6),\n        (\"G_gate\", [-1.5, 0.0, 0.5, -0.2, 1.0, -1.2, 0.3, 0.7], [2.0, -0.5, 0.8, -1.0, 1.5, 0.0, -0.3, 0.1], 20, 0.02),\n        (\"G_tanh\", [0.3, -0.1, 0.05, 0.0, -0.2, 0.4, -0.3, 0.2], [0.3, -0.1, 0.05, 0.0, -0.2, 0.4, -0.3, 0.2], 10, 1e-6),\n        (\"G_tanh\", [3.0, -2.5, 2.2, -1.8, 1.6, -1.4, 1.2, -1.0], [-3.0, 2.4, -2.1, 1.9, -1.7, 1.5, -1.3, 1.1], 20, 0.02)\n    ]\n\n    results = []\n    for case in test_cases:\n        gen_name, z1, z2, n, epsilon = case\n        result = analyze_path(gen_name, z1, z2, n, epsilon)\n        results.append(result)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "3112803"}, {"introduction": "A central challenge in training GANs is managing the trade-off between the quality of individual images (fidelity) and the variety of the entire generated set (diversity). This exercise provides a hands-on analysis of the \"latent truncation trick,\" a widely used technique to control this balance. Working within a simplified linear model of a generator, you will derive and compute core statistical metrics that quantify how adjusting the variance $\\sigma^2$ of the latent sampling distribution directly impacts the fidelity and diversity of the generated outputs. [@problem_id:3112763]", "problem": "You are studying the latent truncation trick in the context of a Deep Convolutional Generative Adversarial Network (DCGAN). The core question is how sampling the latent vector with reduced variance affects both the diversity and the fidelity of generated outputs. To make the analysis mathematically precise and computationally testable, you will work with a linearized generator near the latent origin that approximates the first upsampling and convolutional blocks.\n\nAssume the latent vector $z \\in \\mathbb{R}^m$ is sampled from a multivariate normal distribution with zero mean and isotropic covariance, specifically $z \\sim \\mathcal{N}(0, \\sigma^2 I_m)$, where $\\sigma > 0$ parametrizes the truncation level. Consider a linear generator approximation $G(z) = A z + \\mu$, where $A \\in \\mathbb{R}^{d \\times m}$ has full row rank, $\\mu \\in \\mathbb{R}^d$, and $d \\le m$. The generated random vector is $X = G(z) \\in \\mathbb{R}^d$, which induces a generated distribution $p_g(x)$ that is Gaussian under this approximation.\n\nYour tasks are:\n\n$1.$ Starting only from core definitions and well-tested formulas, derive the following as functions of $\\sigma$:\n- The differential entropy of the generated distribution, $h(p_g)$.\n- A diversity measure defined as $D(\\sigma) = \\mathbb{E}\\left[\\lVert X - \\mu \\rVert_2^2\\right]$.\n- A fidelity score defined as the expected log-likelihood of generated samples under a fixed data model $p_{\\text{data}}(x) = \\mathcal{N}(\\mu_{\\text{data}}, \\Sigma_{\\text{data}})$, namely $F(\\sigma) = \\mathbb{E}_{X \\sim p_g}\\left[\\log p_{\\text{data}}(X)\\right]$.\n\nAssume $\\Sigma_{\\text{data}} \\in \\mathbb{R}^{d \\times d}$ is symmetric positive definite. Express your derivations in terms of $A$, $\\mu$, $\\mu_{\\text{data}}$, $\\Sigma_{\\text{data}}$, and $\\sigma$ only. All steps must begin from the fundamental definitions of a multivariate normal distribution, covariance propagation through linear maps, and the definition of differential entropy for continuous distributions.\n\n$2.$ Implement a program that, for each test case in the suite below, computes the triple $[h(p_g), D(\\sigma), F(\\sigma)]$ using your derived formulas. Use natural logarithms. The results must be printed as floating-point numbers. Aggregate the triples for all cases into a single list.\n\nTest suite. For each case, $d = 3$ and $m = 4$; all matrices and vectors are given explicitly:\n- Case $1$:\n  - $A = \\begin{bmatrix} 1 & 0 & 0 & 0 \\\\ 0 & 1 & 0 & 0 \\\\ 0 & 0 & 1 & 1 \\end{bmatrix}$,\n  - $\\mu = \\begin{bmatrix} 0 \\\\ 0 \\\\ 0 \\end{bmatrix}$,\n  - $\\mu_{\\text{data}} = \\begin{bmatrix} 0 \\\\ 0 \\\\ 0 \\end{bmatrix}$,\n  - $\\Sigma_{\\text{data}} = \\operatorname{diag}(1, 1, 1)$,\n  - $\\sigma = 1.0$.\n- Case $2$:\n  - Same $A$, $\\mu$, $\\mu_{\\text{data}}$, $\\Sigma_{\\text{data}}$ as Case $1$,\n  - $\\sigma = 0.2$.\n- Case $3$:\n  - $A = \\begin{bmatrix} 1 & 2 & 0 & 0 \\\\ 0 & 1 & 1 & 0 \\\\ 0 & 0 & 1 & 2 \\end{bmatrix}$,\n  - $\\mu = \\begin{bmatrix} 0.5 \\\\ -0.5 \\\\ 0.0 \\end{bmatrix}$,\n  - $\\mu_{\\text{data}} = \\begin{bmatrix} 0.2 \\\\ -0.1 \\\\ 0.1 \\end{bmatrix}$,\n  - $\\Sigma_{\\text{data}} = \\operatorname{diag}(0.8, 1.2, 1.5)$,\n  - $\\sigma = 0.5$.\n- Case $4$:\n  - $A = \\begin{bmatrix} 2 & 0 & 0 & 0 \\\\ 0 & 1 & 0 & 1 \\\\ 0 & 0 & 1 & 0 \\end{bmatrix}$,\n  - $\\mu = \\begin{bmatrix} 0.0 \\\\ 0.1 \\\\ -0.2 \\end{bmatrix}$,\n  - $\\mu_{\\text{data}} = \\begin{bmatrix} 0.1 \\\\ 0.0 \\\\ -0.1 \\end{bmatrix}$,\n  - $\\Sigma_{\\text{data}} = \\begin{bmatrix} 1.5 & 0.1 & 0.0 \\\\ 0.1 & 0.7 & 0.0 \\\\ 0.0 & 0.0 & 0.9 \\end{bmatrix}$,\n  - $\\sigma = 0.01$.\n\nFinal output format. Your program should produce a single line of output containing the results as a comma-separated list of lists in the order of the cases, where each inner list is $[h, D, F]$ with each value formatted as a floating-point number. For example, a valid output would be of the form $[[h_1,D_1,F_1],[h_2,D_2,F_2],[h_3,D_3,F_3],[h_4,D_4,F_4]]$.", "solution": "The problem requires the derivation of three quantities related to a linearized generative model and their subsequent computation for a set of test cases. The model is defined by a latent variable $z \\in \\mathbb{R}^m$ drawn from $z \\sim \\mathcal{N}(0, \\sigma^2 I_m)$ and a linear generator $G(z) = A z + \\mu$, producing an output $X = G(z) \\in \\mathbb{R}^d$.\n\nFirst, we characterize the distribution of the generated random vector $X$. Since $X$ is an affine transformation of a Gaussian random vector $z$, $X$ itself is a Gaussian random vector. Its mean $\\mu_g$ and covariance $\\Sigma_g$ are determined as follows:\nThe mean is $\\mu_g = \\mathbb{E}[X] = \\mathbb{E}[A z + \\mu] = A \\mathbb{E}[z] + \\mu$. Since $\\mathbb{E}[z] = 0$, we have $\\mu_g = \\mu$.\nThe covariance is $\\Sigma_g = \\text{Cov}(X) = \\text{Cov}(A z + \\mu) = A \\text{Cov}(z) A^T$. Given $\\text{Cov}(z) = \\sigma^2 I_m$, the covariance of $X$ is $\\Sigma_g = A (\\sigma^2 I_m) A^T = \\sigma^2 A A^T$.\nTherefore, the generated distribution $p_g$ is a multivariate normal distribution with parameters $(\\mu, \\sigma^2 A A^T)$, i.e., $X \\sim \\mathcal{N}(\\mu, \\sigma^2 A A^T)$. The problem states that $A$ has full row rank and $d \\le m$, which ensures that the $d \\times d$ matrix $A A^T$ is positive definite, and thus $\\Sigma_g$ is a valid non-singular covariance matrix.\n\nWith the distribution $p_g$ established, we can derive the three required quantities. All logarithms are natural logarithms.\n\n$1.$ Differential Entropy $h(p_g)$:\nThe differential entropy of a $d$-dimensional multivariate normal distribution $\\mathcal{N}(\\boldsymbol{\\mu}, \\boldsymbol{\\Sigma})$ is given by the standard formula $h = \\frac{1}{2} \\log \\det(2\\pi e \\boldsymbol{\\Sigma})$.\nSubstituting the parameters of $p_g$, we have $\\boldsymbol{\\Sigma} = \\Sigma_g = \\sigma^2 A A^T$.\n$$\nh(p_g) = \\frac{1}{2} \\log \\det(2\\pi e (\\sigma^2 A A^T))\n$$\nUsing properties of the determinant and logarithm:\n$$\nh(p_g) = \\frac{1}{2} \\log((2\\pi e)^d \\det(\\sigma^2 A A^T)) = \\frac{1}{2} [ \\log((2\\pi e)^d) + \\log(\\sigma^{2d} \\det(A A^T)) ]\n$$\n$$\nh(p_g) = \\frac{1}{2} [ d \\log(2\\pi e) + 2d \\log(\\sigma) + \\log(\\det(A A^T)) ]\n$$\n$$\nh(p_g) = \\frac{d}{2} (\\log(2\\pi) + \\log(e)) + d \\log(\\sigma) + \\frac{1}{2} \\log(\\det(A A^T))\n$$\nSince $\\log(e) = 1$, the final expression for the differential entropy is:\n$$\nh(p_g) = d \\log(\\sigma) + \\frac{1}{2} \\log(\\det(A A^T)) + \\frac{d}{2} (1 + \\log(2\\pi))\n$$\n\n$2.$ Diversity Measure $D(\\sigma)$:\nThe diversity measure is defined as $D(\\sigma) = \\mathbb{E}\\left[\\lVert X - \\mu \\rVert_2^2\\right]$.\nThis is the expected squared Euclidean distance of a sample $X$ from its mean $\\mu_g = \\mu$. This quantity is also known as the trace of the covariance matrix of $X$.\nLet $Y = X - \\mu$. Then $\\mathbb{E}[Y]=0$ and $\\text{Cov}(Y) = \\Sigma_g$.\n$$\nD(\\sigma) = \\mathbb{E}\\left[ \\lVert Y \\rVert_2^2 \\right] = \\mathbb{E}[Y^T Y]\n$$\nUsing the cyclic property of the trace, $Y^T Y = \\text{Tr}(Y^T Y) = \\text{Tr}(Y Y^T)$.\n$$\nD(\\sigma) = \\mathbb{E}[\\text{Tr}(Y Y^T)] = \\text{Tr}(\\mathbb{E}[Y Y^T])\n$$\nSince $\\mathbb{E}[Y] = 0$, the definition of covariance gives $\\text{Cov}(Y) = \\mathbb{E}[(Y-\\mathbb{E}[Y])(Y-\\mathbb{E}[Y])^T] = \\mathbb{E}[Y Y^T]$. Thus:\n$$\nD(\\sigma) = \\text{Tr}(\\text{Cov}(Y)) = \\text{Tr}(\\Sigma_g) = \\text{Tr}(\\sigma^2 A A^T)\n$$\nBy linearity of the trace operator, the final expression for the diversity is:\n$$\nD(\\sigma) = \\sigma^2 \\text{Tr}(A A^T)\n$$\n\n$3.$ Fidelity Score $F(\\sigma)$:\nThe fidelity score is defined as the expected log-likelihood of a generated sample $X \\sim p_g$ under a given data distribution $p_{\\text{data}}(x) = \\mathcal{N}(\\mu_{\\text{data}}, \\Sigma_{\\text{data}})$.\n$$\nF(\\sigma) = \\mathbb{E}_{X \\sim p_g}[\\log p_{\\text{data}}(X)]\n$$\nThe log-probability density function for $p_{\\text{data}}$ is:\n$$\n\\log p_{\\text{data}}(x) = -\\frac{1}{2} (x - \\mu_{\\text{data}})^T \\Sigma_{\\text{data}}^{-1} (x - \\mu_{\\text{data}}) - \\frac{1}{2} \\log \\det(2\\pi \\Sigma_{\\text{data}})\n$$\nTaking the expectation with respect to $X \\sim p_g$:\n$$\nF(\\sigma) = \\mathbb{E}_{X \\sim p_g}\\left[ -\\frac{1}{2} (X - \\mu_{\\text{data}})^T \\Sigma_{\\text{data}}^{-1} (X - \\mu_{\\text{data}}) \\right] - \\frac{1}{2} \\log((2\\pi)^d \\det(\\Sigma_{\\text{data}}))\n$$\nThe second term is a constant with respect to the expectation. Let's focus on the expected value of the quadratic form. Using the trace trick, $\\mathbb{E}[(X - \\mu_{\\text{data}})^T \\Sigma_{\\text{data}}^{-1} (X - \\mu_{\\text{data}})] = \\mathbb{E}[\\text{Tr}(\\Sigma_{\\text{data}}^{-1} (X - \\mu_{\\text{data}})(X - \\mu_{\\text{data}})^T)]$.\nBy linearity of trace and expectation, this becomes $\\text{Tr}(\\Sigma_{\\text{data}}^{-1} \\mathbb{E}[(X - \\mu_{\\text{data}})(X - \\mu_{\\text{data}})^T])$.\nThe matrix $\\mathbb{E}[(X - \\mu_{\\text{data}})(X - \\mu_{\\text{data}})^T]$ is the second moment matrix of $X$ about $\\mu_{\\text{data}}$. It can be expressed in terms of the covariance $\\Sigma_g$ and mean $\\mu_g=\\mu$ of $X$ as:\n$$\n\\mathbb{E}[(X - \\mu_{\\text{data}})(X - \\mu_{\\text{data}})^T] = \\Sigma_g + (\\mu - \\mu_{\\text{data}})(\\mu - \\mu_{\\text{data}})^T\n$$\nSubstituting this back, the expectation of the quadratic form is:\n$$\n\\text{Tr}(\\Sigma_{\\text{data}}^{-1} (\\Sigma_g + (\\mu - \\mu_{\\text{data}})(\\mu - \\mu_{\\text{data}})^T)) = \\text{Tr}(\\Sigma_{\\text{data}}^{-1} \\Sigma_g) + \\text{Tr}(\\Sigma_{\\text{data}}^{-1} (\\mu - \\mu_{\\text{data}})(\\mu - \\mu_{\\text{data}})^T)\n$$\nThe second trace term simplifies to the scalar quadratic form $(\\mu - \\mu_{\\text{data}})^T \\Sigma_{\\text{data}}^{-1} (\\mu - \\mu_{\\text{data}})$.\nSubstituting $\\Sigma_g = \\sigma^2 A A^T$, the expectation becomes:\n$$\n\\sigma^2 \\text{Tr}(\\Sigma_{\\text{data}}^{-1} A A^T) + (\\mu - \\mu_{\\text{data}})^T \\Sigma_{\\text{data}}^{-1} (\\mu - \\mu_{\\text{data}})\n$$\nPutting everything together, the fidelity score is:\n$$\nF(\\sigma) = -\\frac{1}{2} \\left[ \\sigma^2 \\text{Tr}(\\Sigma_{\\text{data}}^{-1} A A^T) + (\\mu - \\mu_{\\text{data}})^T \\Sigma_{\\text{data}}^{-1} (\\mu - \\mu_{\\text{data}}) \\right] - \\frac{d}{2}\\log(2\\pi) - \\frac{1}{2}\\log(\\det(\\Sigma_{\\text{data}}))\n$$\nThese three derived formulas are implemented to compute the required values for each test case.", "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Computes and prints the [entropy, diversity, fidelity] triples for the\n    test cases provided in the problem description.\n    \"\"\"\n    \n    # Define the test cases from the problem statement.\n    test_cases = [\n        ( # Case 1\n            np.array([[1, 0, 0, 0], [0, 1, 0, 0], [0, 0, 1, 1]]),\n            np.array([0, 0, 0]),\n            np.array([0, 0, 0]),\n            np.identity(3),\n            1.0\n        ),\n        ( # Case 2\n            np.array([[1, 0, 0, 0], [0, 1, 0, 0], [0, 0, 1, 1]]),\n            np.array([0, 0, 0]),\n            np.array([0, 0, 0]),\n            np.identity(3),\n            0.2\n        ),\n        ( # Case 3\n            np.array([[1, 2, 0, 0], [0, 1, 1, 0], [0, 0, 1, 2]]),\n            np.array([0.5, -0.5, 0.0]),\n            np.array([0.2, -0.1, 0.1]),\n            np.diag([0.8, 1.2, 1.5]),\n            0.5\n        ),\n        ( # Case 4\n            np.array([[2, 0, 0, 0], [0, 1, 0, 1], [0, 0, 1, 0]]),\n            np.array([0.0, 0.1, -0.2]),\n            np.array([0.1, 0.0, -0.1]),\n            np.array([[1.5, 0.1, 0.0], [0.1, 0.7, 0.0], [0.0, 0.0, 0.9]]),\n            0.01\n        )\n    ]\n\n    def calculate_metrics(A, mu, mu_data, Sigma_data, sigma):\n        \"\"\"\n        Calculates the entropy h, diversity D, and fidelity F using the derived formulas.\n        \"\"\"\n        # Ensure inputs are floating point numbers for precision.\n        A = A.astype(float)\n        mu = mu.astype(float)\n        mu_data = mu_data.astype(float)\n        Sigma_data = Sigma_data.astype(float)\n        sigma = float(sigma)\n        \n        d = float(A.shape[0])\n\n        # Intermediate computation: A @ A.T\n        A_AT = A @ A.T\n        \n        # --- 1. Differential Entropy h(p_g) ---\n        # h = d*log(sigma) + 0.5*log(det(A_AT)) + 0.5*d*(1 + log(2*pi))\n        # Use slogdet for numerical stability, which returns (sign, log(abs(det))).\n        # Since A_AT is positive definite, sign is 1.\n        _sign, log_det_A_AT = np.linalg.slogdet(A_AT)\n        h = d * np.log(sigma) + 0.5 * log_det_A_AT + 0.5 * d * (1.0 + np.log(2 * np.pi))\n\n        # --- 2. Diversity D(sigma) ---\n        # D = sigma^2 * tr(A_AT)\n        D = sigma**2 * np.trace(A_AT)\n\n        # --- 3. Fidelity F(sigma) ---\n        # F = -0.5*[sigma^2*Tr(inv(Sigma_d)*A_AT) + (mu-mu_d)^T*inv(Sigma_d)*(mu-mu_d)]\n        #     - 0.5*d*log(2*pi) - 0.5*log(det(Sigma_d))\n        inv_Sigma_data = np.linalg.inv(Sigma_data)\n        _sign, log_det_Sigma_data = np.linalg.slogdet(Sigma_data)\n\n        tr_term = sigma**2 * np.trace(inv_Sigma_data @ A_AT)\n        \n        delta_mu = mu - mu_data\n        mahalanobis_term = delta_mu.T @ inv_Sigma_data @ delta_mu\n\n        const_term = 0.5 * d * np.log(2 * np.pi) + 0.5 * log_det_Sigma_data\n\n        F = -0.5 * (tr_term + mahalanobis_term) - const_term\n        \n        return [h, D, F]\n\n    results = []\n    for case in test_cases:\n        A, mu, mu_data, Sigma_data, sigma = case\n        metrics = calculate_metrics(A, mu, mu_data, Sigma_data, sigma)\n        results.append(metrics)\n    \n    # Format the output string as a list of lists, with floating point numbers\n    # and no spaces.\n    output_str = \"[\" + \",\".join([f\"[{h},{D},{F}]\" for h, D, F in results]) + \"]\"\n    print(output_str)\n\nsolve()\n```", "id": "3112763"}]}