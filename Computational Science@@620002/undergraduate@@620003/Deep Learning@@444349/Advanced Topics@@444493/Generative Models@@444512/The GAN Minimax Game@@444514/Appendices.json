{"hands_on_practices": [{"introduction": "To build a solid foundation, our first practice is a theoretical exercise that reveals the ideal outcome of the GAN minimax game. By considering a simplified world where both the data and generator produce 1D Gaussian distributions, we can analytically derive the perfect generator. This practice will guide you through finding the optimal discriminator and demonstrating that the generator's ultimate goal becomes minimizing the Jensen-Shannon Divergence between its distribution and the real data distribution [@problem_id:3185804].", "problem": "Consider the standard Generative Adversarial Network (GAN) minimax game with value function\n$$\nV(D,G) \\;=\\; \\mathbb{E}_{x\\sim p_{\\text{data}}}\\big[\\ln D(x)\\big] \\;+\\; \\mathbb{E}_{z\\sim p_{z}}\\big[\\ln\\big(1 - D(G(z))\\big)\\big],\n$$\nwhere $p_{\\text{data}}=\\mathcal{N}(\\mu,\\sigma^{2})$ is a one-dimensional Gaussian data distribution with unknown parameters $\\mu\\in\\mathbb{R}$ and $\\sigma>0$, the latent distribution is $p_{z}=\\mathcal{N}(0,1)$, the generator is an affine map $G(z)=a z + b$ with parameters $a\\in\\mathbb{R}$ and $b\\in\\mathbb{R}$, and the discriminator $D:\\mathbb{R}\\to(0,1)$ is an arbitrary measurable function. Assume the parameterization enforces the identifiability constraint $a\\ge 0$.\n\nStarting from the definition of the minimax game above and using only first principles of probability, optimization, and information measures, do the following:\n- For a fixed generator $G$ (equivalently, a fixed model distribution), derive the optimal discriminator $D^{\\star}$ by maximizing the value function with respect to $D$.\n- Substitute this optimal discriminator back into the value function to obtain the generator’s induced objective. Using fundamental properties of well-known information measures, argue where this induced objective is minimized.\n- From this, determine the equilibrium generator parameters $(a^{\\star}, b^{\\star})$ as functions of $\\mu$ and $\\sigma$.\n\nProvide your final answer as the row matrix $\\big(a^{\\star}\\;\\; b^{\\star}\\big)$. No numerical rounding is required.", "solution": "The problem is to find the equilibrium parameters $(a^{\\star}, b^{\\star})$ of a generative model in a standard Generative Adversarial Network (GAN) setup. The process involves three main steps: finding the optimal discriminator for a fixed generator, deriving the generator's objective function, and minimizing this objective to find the optimal generator parameters.\n\nFirst, let's identify the distributions involved. The data distribution is given as $p_{\\text{data}} = \\mathcal{N}(\\mu, \\sigma^2)$. The generator is an affine transformation $G(z) = az + b$ applied to a latent variable $z$ drawn from a standard normal distribution, $p_z = \\mathcal{N}(0,1)$. The distribution of the generated data, $p_g$, is therefore also a normal distribution. The mean of the generated data is $\\mathbb{E}[G(z)] = \\mathbb{E}[az+b] = a\\mathbb{E}[z]+b = a \\cdot 0 + b = b$. The variance is $\\text{Var}(G(z)) = \\text{Var}(az+b) = a^2\\text{Var}(z) = a^2 \\cdot 1^2 = a^2$. Thus, the generated data distribution is $p_g = \\mathcal{N}(b, a^2)$. The identifiability constraint is $a \\ge 0$.\n\nThe minimax game is defined by the value function $V(D, G)$:\n$$V(D,G) \\;=\\; \\mathbb{E}_{x\\sim p_{\\text{data}}}\\big[\\ln D(x)\\big] \\;+\\; \\mathbb{E}_{z\\sim p_{z}}\\big[\\ln\\big(1 - D(G(z))\\big)\\big]$$\nBy a change of variables, the second expectation can be taken over the distribution of generated data, $p_g$. This allows us to write the value function as an integral over the data space $\\mathbb{R}$:\n$$V(D,G) \\;=\\; \\int_{x \\in \\mathbb{R}} p_{\\text{data}}(x) \\ln D(x) \\,dx \\;+\\; \\int_{x \\in \\mathbb{R}} p_g(x) \\ln(1 - D(x)) \\,dx$$\n$$V(D,G) \\;=\\; \\int_{x \\in \\mathbb{R}} \\big[ p_{\\text{data}}(x) \\ln D(x) + p_g(x) \\ln(1 - D(x)) \\big] \\,dx$$\nFor a fixed generator $G$ (and thus a fixed $p_g$), we find the optimal discriminator $D^{\\star}(x)$ by maximizing $V(D,G)$ with respect to the function $D(x)$. Since the integral is maximized when the integrand is maximized for each value of $x$, we consider the function $f(y) = c_1 \\ln y + c_2 \\ln(1 - y)$ for a fixed $x$, where $y = D(x)$, $c_1 = p_{\\text{data}}(x)$, and $c_2 = p_g(x)$. The domain for $y$ is $(0,1)$. To find the maximum, we compute the derivative with respect to $y$ and set it to zero:\n$$\\frac{df}{dy} = \\frac{c_1}{y} - \\frac{c_2}{1-y} = 0$$\n$$\\frac{p_{\\text{data}}(x)}{D(x)} - \\frac{p_g(x)}{1 - D(x)} = 0$$\n$$p_{\\text{data}}(x)(1 - D(x)) = p_g(x)D(x)$$\n$$p_{\\text{data}}(x) = D(x) \\big(p_{\\text{data}}(x) + p_g(x)\\big)$$\nSolving for $D(x)$ gives the optimal discriminator $D^{\\star}$:\n$$D^{\\star}(x) = \\frac{p_{\\text{data}}(x)}{p_{\\text{data}}(x) + p_g(x)}$$\n\nNext, we substitute this optimal discriminator $D^{\\star}(x)$ back into the value function $V(D,G)$ to find the objective function for the generator, $C(G) = \\max_D V(D,G) = V(D^{\\star}, G)$.\n$$C(G) = \\mathbb{E}_{x\\sim p_{\\text{data}}}\\left[\\ln\\left(\\frac{p_{\\text{data}}(x)}{p_{\\text{data}}(x) + p_g(x)}\\right)\\right] + \\mathbb{E}_{x\\sim p_g}\\left[\\ln\\left(1 - \\frac{p_{\\text{data}}(x)}{p_{\\text{data}}(x) + p_g(x)}\\right)\\right]$$\nThe term inside the second logarithm simplifies to:\n$$1 - \\frac{p_{\\text{data}}(x)}{p_{\\text{data}}(x) + p_g(x)} = \\frac{p_{\\text{data}}(x) + p_g(x) - p_{\\text{data}}(x)}{p_{\\text{data}}(x) + p_g(x)} = \\frac{p_g(x)}{p_{\\text{data}}(x) + p_g(x)}$$\nSo the generator's objective becomes:\n$$C(G) = \\mathbb{E}_{x\\sim p_{\\text{data}}}\\left[\\ln\\left(\\frac{p_{\\text{data}}(x)}{p_{\\text{data}}(x) + p_g(x)}\\right)\\right] + \\mathbb{E}_{x\\sim p_g}\\left[\\ln\\left(\\frac{p_g(x)}{p_{\\text{data}}(x) + p_g(x)}\\right)\\right]$$\nWe can relate this expression to well-known information measures. By adding and subtracting $\\ln 2$ inside each logarithm, we can express $C(G)$ in terms of the Kullback-Leibler (KL) divergence. The KL divergence between two distributions $P$ and $Q$ is $D_{KL}(P \\| Q) = \\mathbb{E}_{x \\sim P}[\\ln(P(x)/Q(x))]$.\nLet's rewrite the terms in $C(G)$:\n$$ \\ln\\left(\\frac{p_{\\text{data}}(x)}{p_{\\text{data}}(x) + p_g(x)}\\right) = \\ln\\left(\\frac{p_{\\text{data}}(x)}{\\frac{p_{\\text{data}}(x) + p_g(x)}{2}}\\right) - \\ln(2) $$\n$$ \\ln\\left(\\frac{p_g(x)}{p_{\\text{data}}(x) + p_g(x)}\\right) = \\ln\\left(\\frac{p_g(x)}{\\frac{p_{\\text{data}}(x) + p_g(x)}{2}}\\right) - \\ln(2) $$\nSubstituting these back into the expression for $C(G)$:\n$$C(G) = \\mathbb{E}_{x\\sim p_{\\text{data}}}\\left[\\ln\\left(\\frac{p_{\\text{data}}(x)}{\\frac{p_{\\text{data}}(x) + p_g(x)}{2}}\\right)\\right] - \\ln(2) \\;+\\; \\mathbb{E}_{x\\sim p_g}\\left[\\ln\\left(\\frac{p_g(x)}{\\frac{p_{\\text{data}}(x) + p_g(x)}{2}}\\right)\\right] - \\ln(2)$$\nRecognizing the KL divergence terms, we have:\n$$C(G) = D_{KL}\\left(p_{\\text{data}} \\left\\| \\frac{p_{\\text{data}} + p_g}{2}\\right.\\right) + D_{KL}\\left(p_g \\left\\| \\frac{p_{\\text{data}} + p_g}{2}\\right.\\right) - 2\\ln(2)$$\nThe sum of these two KL divergences is twice the Jensen-Shannon Divergence (JSD) between $p_{\\text{data}}$ and $p_g$, where $JSD(P \\| Q) = \\frac{1}{2} D_{KL}(P \\| M) + \\frac{1}{2} D_{KL}(Q \\| M)$ with $M = \\frac{P+Q}{2}$.\nTherefore, the generator's objective is:\n$$C(G) = 2 \\cdot JSD(p_{\\text{data}} \\| p_g) - 2\\ln(2)$$\nThe generator's goal is to minimize $C(G)$. Since $2$ and $-2\\ln(2)$ are constants, this is equivalent to minimizing the Jensen-Shannon Divergence, $JSD(p_{\\text{data}} \\| p_g)$. A fundamental property of the JSD is that it is always non-negative, and $JSD(P \\| Q) = 0$ if and only if $P=Q$. Thus, the minimum of $C(G)$ is achieved when the generated distribution $p_g$ is identical to the data distribution $p_{\\text{data}}$.\n\nFinally, we determine the optimal generator parameters $(a^{\\star}, b^{\\star})$ by setting $p_g = p_{\\text{data}}$.\nWe have the data distribution $p_{\\text{data}} = \\mathcal{N}(\\mu, \\sigma^2)$ and the generated distribution $p_g = \\mathcal{N}(b, a^2)$. For these two normal distributions to be identical, their parameters (mean and variance) must be equal.\nEquating the means:\n$$b = \\mu$$\nEquating the variances:\n$$a^2 = \\sigma^2$$\nThis implies $a = \\pm \\sigma$. The problem specifies an identifiability constraint $a \\ge 0$. Since the standard deviation $\\sigma$ is given to be positive ($\\sigma > 0$), the only solution that satisfies the constraint is $a = \\sigma$.\nTherefore, the equilibrium generator parameters are $a^{\\star} = \\sigma$ and $b^{\\star} = \\mu$.\nThe final answer is the row matrix $(a^{\\star}, b^{\\star})$.", "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n\\sigma & \\mu\n\\end{pmatrix}\n}\n$$", "id": "3185804"}, {"introduction": "While the previous exercise showed the ideal equilibrium, reaching it is notoriously difficult. This practice uncovers a fundamental reason for this instability by modeling the complex GAN objective with a simple bilinear function, $V(x,y) = xy$. You will implement and compare standard gradient descent-ascent with the more sophisticated extragradient method, empirically demonstrating why the former can lead to divergent, oscillating behavior while the latter can successfully find the saddle point, a crucial insight into GAN training dynamics [@problem_id:3185794].", "problem": "Consider the Generative Adversarial Network (GAN) minimax game, which seeks a saddle point of a value function $V(\\mathbf{x},\\mathbf{y})$ by solving $\\min_{\\mathbf{x}} \\max_{\\mathbf{y}} V(\\mathbf{x},\\mathbf{y})$. To study the local dynamics that commonly arise in GAN training, analyze the simplified two-dimensional bilinear saddle $V(x,y) = x y$. This bilinear form is a canonical local model for the interaction between parameters near equilibrium in adversarial learning.\n\nStarting from the core definitions:\n- For a minimax problem $\\min_x \\max_y V(x,y)$, the gradient descent-ascent (GDA) update computes a simultaneous step that decreases $V$ with respect to $x$ and increases $V$ with respect to $y$.\n- The extragradient method performs a two-phase step: a prediction step that uses the gradient at the current iterate to form an intermediate point, followed by a correction step that uses the gradient evaluated at the intermediate point to update the iterate.\n\nYour task is to implement, for the specific bilinear value function $V(x,y) = x y$, the following:\n- A one-step GDA update driven by the gradients of $V$, where $x$ takes a descent step and $y$ takes an ascent step.\n- A one-step extragradient update that first executes a prediction step using the gradients at the current point and then a correction step using the gradients at the predicted point.\n\nEmpirically demonstrate contraction and expansion regimes by measuring how the Euclidean norm changes under these one-step maps. For a nonzero point $(x,y)$ and step size $\\eta > 0$, define the norm ratio for a one-step map $\\Phi$ as\n$$\nr(x,y;\\eta) = \\frac{\\|\\Phi(x,y;\\eta)\\|_2}{\\|(x,y)\\|_2}.\n$$\nA region is classified as contracting if $r(x,y;\\eta)  1$, neutral if $r(x,y;\\eta) = 1$, and expanding if $r(x,y;\\eta) > 1$.\n\nImplement a program that:\n- Uses the exact bilinear gradients of $V(x,y) = x y$ to form the defined updates.\n- Evaluates the mean norm ratio over a fixed test set of initial points:\n  - The test set points are the list $[(1,0), (0,1), (1,1), (-1,1), (0.5,-0.7)]$.\n  - For each point $(x,y)$ in the test set and a given method and step size $\\eta$, compute $r(x,y;\\eta)$ and average these values to produce a single float result for the case.\n\nTest Suite:\n- Case $1$ (happy path, extragradient contraction): method is extragradient, step size $\\eta = 0.5$.\n- Case $2$ (boundary, extragradient neutrality): method is extragradient, step size $\\eta = 1.0$.\n- Case $3$ (expansion, extragradient): method is extragradient, step size $\\eta = 1.2$.\n- Case $4$ (comparison to GAN naive updates, gradient descent-ascent): method is gradient descent-ascent, step size $\\eta = 0.5$.\n- Case $5$ (small step comparison, gradient descent-ascent): method is gradient descent-ascent, step size $\\eta = 0.1$.\n\nFinal Output Format:\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, in the order of the test cases listed above. Each entry must be the mean norm ratio as a float (no units), for the corresponding case. For example, the output format is $[r_1,r_2,r_3,r_4,r_5]$ where each $r_i$ is the mean of $r(x,y;\\eta)$ over the specified test set for the given method and step size.", "solution": "The problem posed is to analyze the local dynamics of two common optimization algorithms, Gradient Descent-Ascent (GDA) and the Extragradient (EG) method, for the canonical bilinear saddle-point problem given by the value function $V(x,y) = xy$. The analysis will be conducted by examining the change in the Euclidean norm of the iterate vector $(x,y)$ after a single update step.\n\nThe problem is scientifically and mathematically sound. It investigates a well-defined question in the optimization literature relevant to the training of Generative Adversarial Networks (GANs), using standard algorithms and a simplified, yet canonical, model. All parameters and conditions are specified, making the problem well-posed and permitting a unique, verifiable solution.\n\nThe core of the minimax problem is to find a saddle point $(\\mathbf{x}^*, \\mathbf{y}^*)$ for a value function $V(\\mathbf{x}, \\mathbf{y})$ by solving $\\min_{\\mathbf{x}} \\max_{\\mathbf{y}} V(\\mathbf{x}, \\mathbf{y})$. This can be framed as finding a zero of the gradient field $F(\\mathbf{z}) = (\\nabla_{\\mathbf{x}}V, -\\nabla_{\\mathbf{y}}V)^T$, where $\\mathbf{z} = (\\mathbf{x}, \\mathbf{y})^T$. For the specific two-dimensional bilinear problem, we have $V(x,y) = xy$.\n\nFirst, we compute the partial gradients of $V(x,y)$:\n$$\n\\nabla_x V(x,y) = \\frac{\\partial}{\\partial x}(xy) = y\n$$\n$$\n\\nabla_y V(x,y) = \\frac{\\partial}{\\partial y}(xy) = x\n$$\nLet the state of the system be represented by the vector $\\mathbf{z} = (x, y)^T$. The GDA update performs a gradient descent step on $x$ and a gradient ascent step on $y$, while the EG method uses a two-step prediction-correction mechanism. We now derive the one-step update map $\\Phi(\\mathbf{z};\\eta)$ for each method.\n\n**1. Gradient Descent-Ascent (GDA) Method**\n\nThe GDA update for an iterate $\\mathbf{z}_k = (x_k, y_k)^T$ with a step size $\\eta > 0$ is defined as:\n$$\nx_{k+1} = x_k - \\eta \\nabla_x V(x_k, y_k)\n$$\n$$\ny_{k+1} = y_k + \\eta \\nabla_y V(x_k, y_k)\n$$\nSubstituting the gradients for $V(x,y) = xy$:\n$$\nx_{k+1} = x_k - \\eta y_k\n$$\n$$\ny_{k+1} = y_k + \\eta x_k\n$$\nThis constitutes the one-step GDA map, $\\Phi_{GDA}(x_k, y_k; \\eta) = (x_{k+1}, y_{k+1})$. To analyze its effect on the norm, we compute the squared Euclidean norm of the new iterate $\\mathbf{z}_{k+1}$:\n$$\n\\|\\mathbf{z}_{k+1}\\|_2^2 = x_{k+1}^2 + y_{k+1}^2 = (x_k - \\eta y_k)^2 + (y_k + \\eta x_k)^2\n$$\n$$\n\\|\\mathbf{z}_{k+1}\\|_2^2 = (x_k^2 - 2\\eta x_k y_k + \\eta^2 y_k^2) + (y_k^2 + 2\\eta x_k y_k + \\eta^2 x_k^2)\n$$\n$$\n\\|\\mathbf{z}_{k+1}\\|_2^2 = x_k^2 + y_k^2 + \\eta^2 x_k^2 + \\eta^2 y_k^2 = (1 + \\eta^2)(x_k^2 + y_k^2) = (1 + \\eta^2)\\|\\mathbf{z}_k\\|_2^2\n$$\nThe norm ratio $r_{GDA}$ is therefore:\n$$\nr_{GDA}(x,y;\\eta) = \\frac{\\|\\mathbf{z}_{k+1}\\|_2}{\\|\\mathbf{z}_k\\|_2} = \\sqrt{1 + \\eta^2}\n$$\nThis ratio is independent of the point $(x,y)$ and is strictly greater than $1$ for any $\\eta > 0$. This demonstrates that GDA consistently expands the norm of the iterate, causing divergence on this simple bilinear game.\n\n**2. Extragradient (EG) Method**\n\nThe EG method performs a two-phase update. Let the current iterate be $\\mathbf{z}_k = (x_k, y_k)^T$.\n\n**Phase 1: Prediction.** An intermediate point $\\mathbf{z}_{k+1/2} = (x_{k+1/2}, y_{k+1/2})^T$ is computed using a GDA step:\n$$\nx_{k+1/2} = x_k - \\eta \\nabla_x V(x_k, y_k) = x_k - \\eta y_k\n$$\n$$\ny_{k+1/2} = y_k + \\eta \\nabla_y V(x_k, y_k) = y_k + \\eta x_k\n$$\n\n**Phase 2: Correction.** The final update is computed from the original point $\\mathbf{z}_k$ using the gradients evaluated at the intermediate point $\\mathbf{z}_{k+1/2}$:\n$$\nx_{k+1} = x_k - \\eta \\nabla_x V(x_{k+1/2}, y_{k+1/2})\n$$\n$$\ny_{k+1} = y_k + \\eta \\nabla_y V(x_{k+1/2}, y_{k+1/2})\n$$\nThe gradients at the intermediate point are $\\nabla_x V(x_{k+1/2}, y_{k+1/2}) = y_{k+1/2}$ and $\\nabla_y V(x_{k+1/2}, y_{k+1/2}) = x_{k+1/2}$. Substituting these gives:\n$$\nx_{k+1} = x_k - \\eta (y_k + \\eta x_k) = (1 - \\eta^2)x_k - \\eta y_k\n$$\n$$\ny_{k+1} = y_k + \\eta (x_k - \\eta y_k) = \\eta x_k + (1 - \\eta^2)y_k\n$$\nThis defines the one-step EG map, $\\Phi_{EG}(x_k, y_k; \\eta) = (x_{k+1}, y_{k+1})$. We now compute the squared norm of the new iterate $\\mathbf{z}_{k+1}$:\n$$\n\\|\\mathbf{z}_{k+1}\\|_2^2 = ((1 - \\eta^2)x_k - \\eta y_k)^2 + (\\eta x_k + (1 - \\eta^2)y_k)^2\n$$\n$$\n\\|\\mathbf{z}_{k+1}\\|_2^2 = ((1-\\eta^2)^2 x_k^2 - 2\\eta(1-\\eta^2)x_ky_k + \\eta^2 y_k^2) + (\\eta^2 x_k^2 + 2\\eta(1-\\eta^2)x_ky_k + (1-\\eta^2)^2 y_k^2)\n$$\n$$\n\\|\\mathbf{z}_{k+1}\\|_2^2 = ((1-\\eta^2)^2 + \\eta^2)x_k^2 + (\\eta^2 + (1-\\eta^2)^2)y_k^2 = ((1 - 2\\eta^2 + \\eta^4) + \\eta^2)(x_k^2 + y_k^2)\n$$\n$$\n\\|\\mathbf{z}_{k+1}\\|_2^2 = (1 - \\eta^2 + \\eta^4)(x_k^2 + y_k^2) = (1 - \\eta^2 + \\eta^4)\\|\\mathbf{z}_k\\|_2^2\n$$\nThe norm ratio $r_{EG}$ is:\n$$\nr_{EG}(x,y;\\eta) = \\frac{\\|\\mathbf{z}_{k+1}\\|_2}{\\|\\mathbf{z}_k\\|_2} = \\sqrt{1 - \\eta^2 + \\eta^4}\n$$\nLike GDA, this ratio is independent of the point $(x,y)$. However, its value depends critically on the step size $\\eta$:\n- If $0  \\eta  1$, then $\\eta^4  \\eta^2$, so $1-\\eta^2+\\eta^4  1$. The method is **contracting**.\n- If $\\eta = 1$, then $1 - 1 + 1 = 1$. The method is **neutral**.\n- If $\\eta > 1$, then $\\eta^4 > \\eta^2$, so $1-\\eta^2+\\eta^4 > 1$. The method is **expanding**.\n\nThis analysis confirms the regimes described in the problem statement. The implementation will compute these theoretical ratios for each case. Since the ratio is constant for all non-zero points, the mean ratio over the test set is simply the ratio itself. The code will nevertheless perform the explicit averaging loop as requested.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Analyzes the one-step dynamics of GDA and Extragradient methods on the\n    bilinear saddle problem V(x,y) = xy. It computes the mean norm ratio\n    for several test cases.\n    \"\"\"\n\n    # The test set of initial points.\n    test_points = [\n        (1.0, 0.0),\n        (0.0, 1.0),\n        (1.0, 1.0),\n        (-1.0, 1.0),\n        (0.5, -0.7)\n    ]\n\n    # The test suite of methods and step sizes.\n    test_cases = [\n        {'method': 'extragradient', 'eta': 0.5},\n        {'method': 'extragradient', 'eta': 1.0},\n        {'method': 'extragradient', 'eta': 1.2},\n        {'method': 'gda', 'eta': 0.5},\n        {'method': 'gda', 'eta': 0.1},\n    ]\n\n    final_results = []\n\n    for case in test_cases:\n        method = case['method']\n        eta = case['eta']\n        \n        ratios_for_case = []\n        for x, y in test_points:\n            # Calculate the Euclidean norm of the initial point.\n            norm_initial = np.sqrt(x**2 + y**2)\n\n            # A non-zero point is assumed as per the problem statement.\n            # If norm is zero, the ratio is undefined, but this is handled by the test set.\n            if norm_initial == 0:\n                continue\n\n            x_next, y_next = 0.0, 0.0\n\n            if method == 'gda':\n                # Apply the one-step Gradient Descent-Ascent update.\n                # x_k+1 = x_k - eta * grad_x(V) = x_k - eta * y_k\n                # y_k+1 = y_k + eta * grad_y(V) = y_k + eta * x_k\n                x_next = x - eta * y\n                y_next = y + eta * x\n            \n            elif method == 'extragradient':\n                # Apply the one-step Extragradient update.\n                # This uses the pre-derived simplified update equations.\n                # x_k+1 = (1 - eta^2) * x_k - eta * y_k\n                # y_k+1 = eta * x_k + (1 - eta^2) * y_k\n                eta_sq = eta**2\n                x_next = (1 - eta_sq) * x - eta * y\n                y_next = eta * x + (1 - eta_sq) * y\n\n            # Calculate the Euclidean norm of the updated point.\n            norm_next = np.sqrt(x_next**2 + y_next**2)\n            \n            # Compute the norm ratio for this point.\n            ratio = norm_next / norm_initial\n            ratios_for_case.append(ratio)\n        \n        # Calculate the mean norm ratio for the current case.\n        # As derived, this ratio is constant for all non-zero points,\n        # so the mean is just the ratio itself.\n        mean_ratio = np.mean(ratios_for_case)\n        final_results.append(mean_ratio)\n\n    # Print the final results in the specified format.\n    print(f\"[{','.join(map(str, final_results))}]\")\n\nsolve()\n```", "id": "3185794"}, {"introduction": "Moving from optimization theory to a common practical failure, this exercise tackles the problem of mode collapse, where the generator fails to capture the full diversity of the data. You will build and train a simple GAN from scratch to investigate a fascinating hypothesis: that the structure of the latent space can influence the generator's ability to cover all data modes. Through this hands-on simulation, you will gain an intuitive understanding of how design choices in the generator's architecture can directly impact the quality and diversity of the generated samples [@problem_id:3185781].", "problem": "You are asked to design and implement a complete, runnable program that simulates the minimax training dynamics of a Generative Adversarial Network (GAN), and then uses this simulation to study how a multimodal latent prior distribution interacts with the game to encourage or discourage mode coverage in the generator distribution.\n\nDefinitions and setup that you must use:\n- A Generative Adversarial Network (GAN) consists of a generator and a discriminator. The generator is a function $g_{\\theta}$ with parameters $\\theta$ that maps latent variables $z$ to data space $x$, and the discriminator is a classifier $D_{\\phi}$ with parameters $\\phi$ that outputs the probability that an input $x$ is real data rather than generated.\n- The minimax value function is\n$$\nV(D_{\\phi}, G_{\\theta}) \\;=\\; \\mathbb{E}_{x \\sim p_{\\text{data}}}[\\log D_{\\phi}(x)] \\;+\\; \\mathbb{E}_{z \\sim p_{z}}[\\log(1 - D_{\\phi}(g_{\\theta}(z)))].\n$$\n- In this task, you must use a one-dimensional data domain and parametric families:\n  - Generator: $g_{\\theta}(z) \\;=\\; a z + b$, where $\\theta = (a,b)$ and $a,b \\in \\mathbb{R}$.\n  - Discriminator: $D_{\\phi}(x) \\;=\\; \\sigma(w x + c)$, where $\\phi = (w,c)$, $w,c \\in \\mathbb{R}$, and $\\sigma(u) = \\frac{1}{1 + e^{-u}}$ is the logistic sigmoid function.\n\nData distribution and latent priors to be used:\n- The target data distribution $p_{\\text{data}}$ is a balanced mixture of two Gaussians on the real line:\n$$\np_{\\text{data}} \\;=\\; \\tfrac{1}{2}\\,\\mathcal{N}(-\\mu,\\sigma_{\\text{data}}^{2}) \\;+\\; \\tfrac{1}{2}\\,\\mathcal{N}(\\mu,\\sigma_{\\text{data}}^{2}),\n$$\nwith $\\mu = 2.0$ and $\\sigma_{\\text{data}} = 0.2$.\n- The latent prior $p_{z}$ will be a mixture of two Gaussians\n$$\np_{z} \\;=\\; \\alpha\\,\\mathcal{N}(m_{1},\\sigma_{z}^{2}) \\;+\\; (1-\\alpha)\\,\\mathcal{N}(m_{2},\\sigma_{z}^{2}),\n$$\nwith parameters $(m_{1},m_{2},\\alpha,\\sigma_{z})$ specified by each test case below.\n\nTraining protocol you must implement:\n- Use the minimax objective $V(D_{\\phi}, G_{\\theta})$ as stated above.\n- Use Monte Carlo to approximate expectations at each step by independent and identically distributed samples from $p_{\\text{data}}$ and $p_{z}$.\n- Derive the parameter update rules from first principles by taking gradients of $V(D_{\\phi}, G_{\\theta})$ with respect to $(w,c)$ for the discriminator and with respect to $(a,b)$ for the generator. Use gradient ascent on $(w,c)$ and gradient descent on $(a,b)$.\n- Use the following hyperparameters exactly:\n  - Number of training iterations $T = 2000$.\n  - At each iteration, perform $1$ discriminator update followed by $1$ generator update.\n  - Batch size $B = 512$ for both real and latent samples per update.\n  - Learning rate for discriminator $\\eta_{D} = 0.01$.\n  - Learning rate for generator $\\eta_{G} = 0.05$.\n  - Initialization: $a_{0} = 0.1$, $b_{0} = 0.0$, $w_{0} = 0.0$, $c_{0} = 0.0$.\n  - Random seed set to a fixed value to ensure reproducibility.\n\nExperimental metric for mode coverage:\n- After training, compute the generator’s images of the latent component means: $m'_{1} = a\\,m_{1} + b$ and $m'_{2} = a\\,m_{2} + b$.\n- Define the set of data means $\\{-\\mu, \\mu\\}$ and the set of generated means $\\{m'_{1}, m'_{2}\\}$.\n- A data mode at mean $\\mu_{d} \\in \\{-\\mu, \\mu\\}$ is considered “covered” if $\\min\\{|m'_{1} - \\mu_{d}|, |m'_{2} - \\mu_{d}|\\} \\le \\tau$, where the coverage tolerance is $\\tau = 0.6$.\n- The coverage score is the integer count in $\\{0,1,2\\}$ equal to the number of data modes that are covered by the generator in this sense.\n\nTest suite you must implement and run:\n- Use the following five cases for $(m_{1},m_{2},\\alpha,\\sigma_{z})$:\n  - Case $1$: $(m_{1},m_{2},\\alpha,\\sigma_{z}) = (-1.0,\\,1.0,\\,0.5,\\,0.3)$.\n  - Case $2$: $(m_{1},m_{2},\\alpha,\\sigma_{z}) = (0.0,\\,0.0,\\,0.5,\\,0.3)$.\n  - Case $3$: $(m_{1},m_{2},\\alpha,\\sigma_{z}) = (-1.0,\\,1.0,\\,0.95,\\,0.3)$.\n  - Case $4$: $(m_{1},m_{2},\\alpha,\\sigma_{z}) = (-0.2,\\,0.2,\\,0.5,\\,0.3)$.\n  - Case $5$: $(m_{1},m_{2},\\alpha,\\sigma_{z}) = (-3.0,\\,3.0,\\,0.5,\\,0.3)$.\n\nWhat to output:\n- Your program must run all five cases in the test suite, train the GAN for each case as specified, compute the final coverage score for each case, and aggregate the five integer results into a single list printed on one line.\n- The final output format must be exactly one line containing the list of results as a comma-separated list enclosed in square brackets, for example: $[r_{1},r_{2},r_{3},r_{4},r_{5}]$ with each $r_{i}$ an integer in $\\{0,1,2\\}$ and no extra text.\n\nNotes:\n- All quantities are dimensionless; there are no physical units involved.\n- Angles are not used; no angle units are required.\n- Percentages, when present (e.g., $\\alpha$), are parameters in $[0,1]$ and must be treated as decimals, not as percentages.", "solution": "The problem requires the design and implementation of a simulation for the training dynamics of a simple Generative Adversarial Network (GAN). The goal is to investigate how the structure of a multimodal latent prior distribution, $p_z$, influences the generator's ability to capture the modes of a bimodal data distribution, $p_{\\text{data}}$. We will first derive the necessary mathematical framework and then specify the algorithmic implementation based on these principles.\n\nThe GAN framework consists of a generator $G_{\\theta}$ with parameters $\\theta=(a,b)$ and a discriminator $D_{\\phi}$ with parameters $\\phi=(w,c)$. The generator is a linear function $g_{\\theta}(z) = az + b$. The discriminator is a logistic classifier $D_{\\phi}(x) = \\sigma(wx + c)$, where $\\sigma(u)=(1+e^{-u})^{-1}$ is the logistic sigmoid function. The training is governed by the minimax game on the value function $V(D,G)$:\n$$\nV(D_{\\phi}, G_{\\theta}) = \\mathbb{E}_{x \\sim p_{\\text{data}}}[\\log D_{\\phi}(x)] + \\mathbb{E}_{z \\sim p_{z}}[\\log(1 - D_{\\phi}(g_{\\theta}(z)))]\n$$\nThe discriminator aims to maximize this value, while the generator aims to minimize it.\n\n### Gradient Derivation for Parameter Updates\n\nTo implement the training, we use gradient-based optimization. The discriminator parameters $\\phi=(w,c)$ are updated using gradient ascent, and the generator parameters $\\theta=(a,b)$ are updated using gradient descent. We must therefore derive the gradients of $V$ with respect to these parameters.\n\n**1. Discriminator Gradient ($\\nabla_{\\phi} V$)**\n\nThe update rule for the discriminator is $\\phi \\leftarrow \\phi + \\eta_D \\nabla_{\\phi} V$. We compute the partial derivatives of $V$ with respect to $w$ and $c$. Using the chain rule and the property $\\frac{d}{du}\\log\\sigma(u) = 1-\\sigma(u)$:\n$$\n\\frac{\\partial}{\\partial w} \\log D_{\\phi}(x) = \\frac{\\partial}{\\partial w} \\log \\sigma(wx+c) = (1 - \\sigma(wx+c)) \\cdot x = (1 - D_{\\phi}(x))x\n$$\n$$\n\\frac{\\partial}{\\partial c} \\log D_{\\phi}(x) = \\frac{\\partial}{\\partial c} \\log \\sigma(wx+c) = (1 - \\sigma(wx+c)) \\cdot 1 = 1 - D_{\\phi}(x)\n$$\nSimilarly, using the property $\\frac{d}{du}\\log(1-\\sigma(u)) = -\\sigma(u)$:\n$$\n\\frac{\\partial}{\\partial w} \\log(1 - D_{\\phi}(g_{\\theta}(z))) = -\\sigma(wg_{\\theta}(z)+c) \\cdot g_{\\theta}(z) = -D_{\\phi}(g_{\\theta}(z))g_{\\theta}(z)\n$$\n$$\n\\frac{\\partial}{\\partial c} \\log(1 - D_{\\phi}(g_{\\theta}(z))) = -\\sigma(wg_{\\theta}(z)+c) \\cdot 1 = -D_{\\phi}(g_{\\theta}(z))\n$$\nTaking the expectation over the respective distributions, we obtain the gradients:\n$$\n\\frac{\\partial V}{\\partial w} = \\mathbb{E}_{x \\sim p_{\\text{data}}}[(1 - D_{\\phi}(x))x] + \\mathbb{E}_{z \\sim p_{z}}[-D_{\\phi}(g_{\\theta}(z))g_{\\theta}(z)]\n$$\n$$\n\\frac{\\partial V}{\\partial c} = \\mathbb{E}_{x \\sim p_{\\text{data}}}[1 - D_{\\phi}(x)] + \\mathbb{E}_{z \\sim p_{z}}[-D_{\\phi}(g_{\\theta}(z))]\n$$\n\n**2. Generator Gradient ($\\nabla_{\\theta} V$)**\n\nThe update rule for the generator is $\\theta \\leftarrow \\theta - \\eta_G \\nabla_{\\theta} V$. The first term in $V$ is independent of $\\theta$. We compute the partial derivatives of the second term with respect to $a$ and $b$:\n$$\n\\nabla_{\\theta} V = \\mathbb{E}_{z \\sim p_{z}}[\\nabla_{\\theta} \\log(1 - D_{\\phi}(g_{\\theta}(z)))]\n$$\nUsing the chain rule, $\\nabla_{\\theta}[\\cdot] = \\frac{\\partial[\\cdot]}{\\partial g_{\\theta}} \\nabla_{\\theta}g_{\\theta}(z)$. The gradient with respect to the generator's output $g$ is:\n$$\n\\frac{\\partial}{\\partial g} \\log(1 - D_{\\phi}(g)) = \\frac{\\partial}{\\partial g} \\log(1 - \\sigma(wg+c)) = -\\sigma(wg+c) \\cdot w = -w D_{\\phi}(g)\n$$\nThe gradients of the generator function $g_{\\theta}(z) = az+b$ are $\\frac{\\partial g_{\\theta}}{\\partial a} = z$ and $\\frac{\\partial g_{\\theta}}{\\partial b} = 1$. Combining these gives:\n$$\n\\frac{\\partial V}{\\partial a} = \\mathbb{E}_{z \\sim p_{z}} \\left[ (-w D_{\\phi}(g_{\\theta}(z))) \\cdot z \\right] = -\\mathbb{E}_{z \\sim p_{z}} [w D_{\\phi}(g_{\\theta}(z)) z]\n$$\n$$\n\\frac{\\partial V}{\\partial b} = \\mathbb{E}_{z \\sim p_{z}} \\left[ (-w D_{\\phi}(g_{\\theta}(z))) \\cdot 1 \\right] = -\\mathbb{E}_{z \\sim p_{z}} [w D_{\\phi}(g_{\\theta}(z))]\n$$\n\n### Algorithmic Implementation\n\nThe training process is simulated for $T=2000$ iterations. At each iteration, we perform one discriminator update followed by one generator update. The expectations are approximated using Monte Carlo estimation with a batch size of $B=512$.\n\n**1. Sampling**\n-   **Data Distribution $p_{\\text{data}}$**: To draw a sample from $p_{\\text{data}} = \\frac{1}{2}\\,\\mathcal{N}(-\\mu,\\sigma_{\\text{data}}^{2}) + \\frac{1}{2}\\,\\mathcal{N}(\\mu,\\sigma_{\\text{data}}^{2})$, we first select one of the two Gaussian components with equal probability ($0.5$) and then draw a sample from the selected component. For a batch of size $B$, approximately $B/2$ samples will be drawn from each component.\n-   **Latent Distribution $p_z$**: To draw a sample from $p_{z} = \\alpha\\,\\mathcal{N}(m_{1},\\sigma_{z}^{2}) + (1-\\alpha)\\,\\mathcal{N}(m_{2},\\sigma_{z}^{2})$, we select the first component with probability $\\alpha$ and the second with probability $1-\\alpha$, then sample from the chosen Gaussian.\n\n**2. Training Loop**\nAll parameters are initialized as specified: $a_0=0.1, b_0=0.0, w_0=0.0, c_0=0.0$. For each iteration $t=0, \\dots, T-1$:\n\n-   **Discriminator Update**:\n    1.  Draw a batch of $B$ real samples $\\{x_i\\}_{i=1}^B \\sim p_{\\text{data}}$.\n    2.  Draw a batch of $B$ latent samples $\\{z_i\\}_{i=1}^B \\sim p_{z}$.\n    3.  Generate a batch of fake samples $\\{x_{g,i}\\}_{i=1}^B$ where $x_{g,i} = g_{\\theta_t}(z_i) = a_t z_i + b_t$.\n    4.  Compute gradients $\\nabla_{w} V_t$ and $\\nabla_{c} V_t$ using the current parameters $\\phi_t, \\theta_t$ and the batches:\n        $$\n        \\nabla_{w} V_t \\approx \\frac{1}{B}\\sum_{i=1}^B \\left[ (1 - D_{\\phi_t}(x_i))x_i - D_{\\phi_t}(x_{g,i})x_{g,i} \\right] \\\\\n        \\nabla_{c} V_t \\approx \\frac{1}{B}\\sum_{i=1}^B \\left[ (1 - D_{\\phi_t}(x_i)) - D_{\\phi_t}(x_{g,i}) \\right]\n        $$\n    5.  Update discriminator parameters: $w_{t+1} = w_t + \\eta_D \\nabla_{w} V_t$, $c_{t+1} = c_t + \\eta_D \\nabla_{c} V_t$.\n\n-   **Generator Update**:\n    1.  Draw a new batch of $B$ latent samples $\\{z'_i\\}_{i=1}^B \\sim p_{z}$.\n    2.  Generate a new batch of fake samples $\\{x'_{g,i}\\}_{i=1}^B$ with the old generator parameters: $x'_{g,i} = g_{\\theta_t}(z'_i) = a_t z'_i + b_t$.\n    3.  Compute gradients $\\nabla_{a} V_t$ and $\\nabla_{b} V_t$ using the old generator parameters $\\theta_t$ but the *newly updated* discriminator parameters $\\phi_{t+1}$:\n        $$\n        \\nabla_{a} V_t \\approx -\\frac{1}{B}\\sum_{i=1}^B w_{t+1} D_{\\phi_{t+1}}(x'_{g,i}) z'_i \\\\\n        \\nabla_{b} V_t \\approx -\\frac{1}{B}\\sum_{i=1}^B w_{t+1} D_{\\phi_{t+1}}(x'_{g,i})\n        $$\n    4.  Update generator parameters: $a_{t+1} = a_t - \\eta_G \\nabla_{a} V_t$, $b_{t+1} = b_t - \\eta_G \\nabla_{b} V_t$.\n\n### Evaluation of Mode Coverage\n\nAfter $T$ training iterations, the final generator parameters $(a_T, b_T)$ are used to evaluate mode coverage. The latent prior has component means $m_1$ and $m_2$. The generator maps these to $m'_1 = a_T m_1 + b_T$ and $m'_2 = a_T m_2 + b_T$. The target data distribution has means at $-\\mu$ and $\\mu$ (where $\\mu=2.0$).\n\nA data mode at mean $\\mu_d \\in \\{-\\mu, \\mu\\}$ is considered \"covered\" if at least one of the generated means is close to it, i.e., $\\min\\{|m'_{1} - \\mu_{d}|, |m'_{2} - \\mu_{d}|\\} \\le \\tau$, where the tolerance is $\\tau = 0.6$. The final score for a given test case is the total number of covered data modes, which can be $0$, $1$, or $2$. This procedure is repeated for each of the five test cases defined in the problem statement.", "answer": "```python\nimport numpy as np\nfrom scipy.special import expit as sigmoid\n\ndef solve():\n    \"\"\"\n    Main function to run the GAN simulation for all test cases and print results.\n    \"\"\"\n\n    # --- Fixed Parameters and Hyperparameters ---\n    fixed_params = {\n        \"mu\": 2.0,\n        \"sigma_data\": 0.2,\n    }\n    hyperparams = {\n        \"T\": 2000,\n        \"B\": 512,\n        \"eta_D\": 0.01,\n        \"eta_G\": 0.05,\n        \"a0\": 0.1,\n        \"b0\": 0.0,\n        \"w0\": 0.0,\n        \"c0\": 0.0,\n        \"seed\": 1234, # Fixed seed for reproducibility\n        \"tau\": 0.6,\n    }\n\n    # --- Test Suite ---\n    test_cases = [\n        # (m1, m2, alpha, sigma_z)\n        (-1.0, 1.0, 0.5, 0.3),   # Case 1\n        (0.0, 0.0, 0.5, 0.3),    # Case 2\n        (-1.0, 1.0, 0.95, 0.3),  # Case 3\n        (-0.2, 0.2, 0.5, 0.3),   # Case 4\n        (-3.0, 3.0, 0.5, 0.3),   # Case 5\n    ]\n    \n    results = []\n    for case_params_tuple in test_cases:\n        case_params = {\n            \"m1\": case_params_tuple[0],\n            \"m2\": case_params_tuple[1],\n            \"alpha\": case_params_tuple[2],\n            \"sigma_z\": case_params_tuple[3],\n        }\n        score = _run_simulation_for_case(case_params, fixed_params, hyperparams)\n        results.append(score)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\n\ndef _sample_p_data(rng, B, mu, sigma_data):\n    \"\"\"Samples a batch from the real data distribution p_data.\"\"\"\n    # Choose which Gaussian component to sample from for each point\n    # 0 for N(-mu, sigma_data^2), 1 for N(mu, sigma_data^2)\n    choices = rng.binomial(1, 0.5, size=B)\n    \n    # Sample from N(-mu, sigma_data^2)\n    n_neg = B - np.sum(choices)\n    samples_neg = rng.normal(loc=-mu, scale=sigma_data, size=n_neg)\n    \n    # Sample from N(mu, sigma_data^2)\n    n_pos = np.sum(choices)\n    samples_pos = rng.normal(loc=mu, scale=sigma_data, size=n_pos)\n    \n    return np.concatenate((samples_neg, samples_pos))\n\ndef _sample_p_z(rng, B, m1, m2, alpha, sigma_z):\n    \"\"\"Samples a batch from the latent distribution p_z.\"\"\"\n    # Choose which Gaussian component to sample from for each point\n    # 0 for N(m1, sigma_z^2), 1 for N(m2, sigma_z^2)\n    choices = rng.binomial(1, 1 - alpha, size=B)\n\n    # Sample from N(m1, sigma_z^2)\n    n_1 = B - np.sum(choices)\n    samples_1 = rng.normal(loc=m1, scale=sigma_z, size=n_1)\n\n    # Sample from N(m2, sigma_z^2)\n    n_2 = np.sum(choices)\n    samples_2 = rng.normal(loc=m2, scale=sigma_z, size=n_2)\n\n    return np.concatenate((samples_1, samples_2))\n    \n\ndef _run_simulation_for_case(case_params, fixed_params, hyperparams):\n    \"\"\"\n    Trains a GAN for a single case and computes the coverage score.\n    \"\"\"\n    # Unpack parameters for convenience\n    mu, sigma_data = fixed_params[\"mu\"], fixed_params[\"sigma_data\"]\n    m1, m2, alpha, sigma_z = case_params[\"m1\"], case_params[\"m2\"], case_params[\"alpha\"], case_params[\"sigma_z\"]\n    T, B, eta_D, eta_G, tau = hyperparams[\"T\"], hyperparams[\"B\"], hyperparams[\"eta_D\"], hyperparams[\"eta_G\"], hyperparams[\"tau\"]\n    \n    # Initialize random number generator\n    rng = np.random.default_rng(hyperparams[\"seed\"])\n\n    # Initialize parameters\n    a, b = hyperparams[\"a0\"], hyperparams[\"b0\"]\n    w, c = hyperparams[\"w0\"], hyperparams[\"c0\"]\n\n    # Training loop\n    for _ in range(T):\n        # --- Discriminator Update ---\n        x_real = _sample_p_data(rng, B, mu, sigma_data)\n        z_d = _sample_p_z(rng, B, m1, m2, alpha, sigma_z)\n        x_fake = a * z_d + b\n\n        D_real = sigmoid(w * x_real + c)\n        D_fake = sigmoid(w * x_fake + c)\n\n        grad_w_V = np.mean((1 - D_real) * x_real) - np.mean(D_fake * x_fake)\n        grad_c_V = np.mean(1 - D_real) - np.mean(D_fake)\n\n        w += eta_D * grad_w_V\n        c += eta_D * grad_c_V\n\n        # --- Generator Update ---\n        z_g = _sample_p_z(rng, B, m1, m2, alpha, sigma_z)\n        x_fake_g = a * z_g + b\n\n        # D output for fake samples using updated D parameters\n        D_fake_g = sigmoid(w * x_fake_g + c)\n        \n        # Gradients of V w.r.t a and b\n        grad_a_V = -np.mean(w * D_fake_g * z_g)\n        grad_b_V = -np.mean(w * D_fake_g)\n\n        # Gradient descent update\n        a -= eta_G * grad_a_V\n        b -= eta_G * grad_b_V\n\n    # --- Evaluation ---\n    m_prime_1 = a * m1 + b\n    m_prime_2 = a * m2 + b\n    \n    data_means = [-mu, mu]\n    gen_means = [m_prime_1, m_prime_2]\n    coverage_score = 0\n    \n    for data_mean in data_means:\n        min_dist = min(abs(gm - data_mean) for gm in gen_means)\n        if min_dist = tau:\n            coverage_score += 1\n            \n    return coverage_score\n\nif __name__ == \"__main__\":\n    solve()\n\n```", "id": "3185781"}]}