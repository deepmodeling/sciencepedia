{"hands_on_practices": [{"introduction": "The fundamental purpose of Bayes' rule is to update our beliefs in light of new evidence. This first exercise provides a clear and direct application of this principle. We will explore a hypothetical digital memory device that sometimes fails to read a stored bit, resulting in an 'erasure.' By applying Bayes' rule, you will calculate the probability that the original bit was a '0' given that we observed an erasure, learning to distinguish and combine prior beliefs with new, albeit uncertain, information [@problem_id:1603705].", "problem": "A digital memory device stores data as a sequence of binary bits. Let the source bit, denoted by the random variable $X$, be either $0$ or $1$. From extensive analysis of the data patterns, it is known that the prior probability of a bit being $0$ is $P(X=0) = \\alpha$.\n\nWhen a bit is read from the device, one of three outcomes can occur for the received symbol, denoted by $Y$: the bit is read correctly as $0$, correctly as $1$, or the read operation fails, resulting in an 'erasure' symbol, which we denote as '?'. The device is designed such that it never flips a bit; a stored $0$ is never read as a $1$, and a stored $1$ is never read as a $0$.\n\nThe reliability of the read operation, however, depends on the stored value. The probability of an erasure occurring when the stored bit is $0$ is $P(Y='?'|X=0) = p_0$. The probability of an erasure occurring when the stored bit is $1$ is $P(Y='?'|X=1) = p_1$.\n\nSuppose a single bit is read from the device and the outcome is an erasure, '?'. Determine the posterior probability that the bit originally stored in the device was a $0$. Provide your answer as a single closed-form analytic expression in terms of $\\alpha$, $p_0$, and $p_1$.", "solution": "We are asked to find the posterior probability that the transmitted bit was a $0$ given that the received symbol was an erasure. This can be written as $P(X=0 | Y='?')$.\n\nTo solve this, we apply Bayes' rule, which states:\n$$ P(A|B) = \\frac{P(B|A)P(A)}{P(B)} $$\n\nIn the context of our problem, let event $A$ be $X=0$ (the stored bit is 0) and event $B$ be $Y='?'$ (an erasure is observed). Substituting these into Bayes' rule, we get:\n$$ P(X=0 | Y='?') = \\frac{P(Y='?' | X=0) \\cdot P(X=0)}{P(Y='?')} $$\n\nThe problem provides the following values:\n- $P(X=0) = \\alpha$\n- $P(Y='?' | X=0) = p_0$\n\nThe only term we need to calculate is the total probability of observing an erasure, $P(Y='?')$. We can find this using the law of total probability, summing over all possible inputs for $X$:\n$$ P(Y='?') = P(Y='?' | X=0) \\cdot P(X=0) + P(Y='?' | X=1) \\cdot P(X=1) $$\n\nWe are given $P(X=0) = \\alpha$, which implies that the probability of the stored bit being $1$ is $P(X=1) = 1 - P(X=0) = 1 - \\alpha$. We are also given the conditional probability $P(Y='?' | X=1) = p_1$.\n\nNow, we can substitute all the known probabilities into the expression for $P(Y='?')$:\n$$ P(Y='?') = (p_0) \\cdot (\\alpha) + (p_1) \\cdot (1 - \\alpha) $$\n$$ P(Y='?') = \\alpha p_0 + p_1(1-\\alpha) $$\n\nWith the expression for $P(Y='?')$, we can now complete the calculation for our target posterior probability using Bayes' rule:\n$$ P(X=0 | Y='?') = \\frac{P(Y='?' | X=0) \\cdot P(X=0)}{P(Y='?')} $$\n$$ P(X=0 | Y='?') = \\frac{p_0 \\cdot \\alpha}{\\alpha p_0 + p_1(1-\\alpha)} $$\n\nThis is the final expression for the posterior probability that the stored bit was a $0$ given that an erasure was observed.", "answer": "$$\\boxed{\\frac{\\alpha p_{0}}{\\alpha p_{0} + p_{1}(1-\\alpha)}}$$", "id": "1603705"}, {"introduction": "Moving beyond simple formula application, this practice explores the profound and often counterintuitive implications of Bayesian reasoning. We will analyze a scenario of a medical diagnostic test deployed in two different populations: one with low disease prevalence and one with high prevalence. This exercise demonstrates why metrics like Positive Predictive Value ($PPV$) are not intrinsic properties of a test or a machine learning model, but are critically dependent on the prior probability, or \"base rate,\" of the condition in the population [@problem_id:2523977]. Understanding this concept is essential for avoiding the common \"base-rate fallacy\" and correctly interpreting the performance of any classifier in a real-world setting.", "problem": "A hospital laboratory is evaluating a new polymerase chain reaction (PCR) assay to screen for carbapenem-resistant Enterobacterales (CRE). The assay has empirically validated sensitivity and specificity, which are assumed constant across settings. The infection control team plans to deploy the same assay in two distinct settings: a low-prevalence community screening program and a high-prevalence outbreak ward. Your goal is to decide, using only core definitions and Bayes’ theorem, which statements must be true and thereby explain why positive predictive value and negative predictive value are not intrinsic properties of the test.\n\nFoundational base to use:\n- Sensitivity is $P(T^{+}\\mid D)$.\n- Specificity is $P(T^{-}\\mid \\bar D)$.\n- Prevalence is $P(D)$, denote it by $\\pi$.\n- Positive predictive value (PPV) is $P(D\\mid T^{+})$.\n- Negative predictive value (NPV) is $P(\\bar D\\mid T^{-})$.\n- Bayes’ theorem relates $P(D\\mid T^{+})$ to $P(T^{+}\\mid D)$, $P(D)$, and $P(T^{+})$.\n\nAssume the following empirically established test characteristics are the same in both settings: sensitivity $Se = 0.90$ and specificity $Sp = 0.995$. The community program screens an asymptomatic population with prevalence $\\pi = 0.0005$ (that is, $0.05\\%$). The outbreak ward screens a high-risk population with prevalence $\\pi = 0.20$ (that is, $20\\%$).\n\nWhich of the following statements are correct?\n\nA. Because sensitivity and specificity are intrinsic to the assay and do not change across settings, the positive predictive value equals sensitivity whenever specificity is high, and therefore PPV is independent of prevalence.\n\nB. Using Bayes’ theorem with pretest probability equal to prevalence $\\pi$, the positive predictive value satisfies $PPV = \\dfrac{Se\\cdot \\pi}{Se\\cdot \\pi + (1-Sp)\\cdot (1-\\pi)}$ and the negative predictive value satisfies $NPV = \\dfrac{Sp\\cdot (1-\\pi)}{Sp\\cdot (1-\\pi) + (1-Se)\\cdot \\pi}$, making both PPV and NPV explicit functions of $\\pi$.\n\nC. With $Se=0.90$ and $Sp=0.995$, in the community program with $\\pi=0.0005$, $PPV \\approx 0.083$ (about $8.3\\%$), whereas in the outbreak ward with $\\pi=0.20$, $PPV \\approx 0.978$ (about $97.8\\%$); this difference arises solely from the different prevalence.\n\nD. As prevalence decreases toward $0$, the negative predictive value approaches sensitivity, because negative results are dominated by true negatives determined by $Se$.\n\nE. Holding $Se$ and $Sp$ fixed, as $\\pi \\to 0$ one has $PPV \\to 0$ and $NPV \\to 1$, and as $\\pi \\to 1$ one has $PPV \\to 1$ and $NPV \\to 0$; thus PPV and NPV are not intrinsic properties of the test.\n\nF. Because the (positive and negative) likelihood ratios (likelihood ratio, LR) are intrinsic to the test, both PPV and NPV are intrinsic and independent of prevalence.\n\nG. The base-rate fallacy in screening arises from conflating $P(T^{+}\\mid D)$ with $P(D\\mid T^{+})$; at very low $\\pi$, even high $Sp$ and $Se$ can yield a low PPV because false positives from the large pool of non-diseased individuals dominate true positives.", "solution": "The problem statement is scientifically sound and well-posed. It provides clear definitions and all necessary data to evaluate the claims. It describes a realistic scenario in clinical microbiology and hinges on the correct application of probability theory, specifically Bayes' theorem, to diagnostic testing. Therefore, we proceed with the derivation and analysis.\n\nLet $D$ be the event that a subject has the disease (is a CRE carrier) and $\\bar D$ be the event that the subject does not have the disease. Let $T^{+}$ be the event of a positive test result and $T^{-}$ be the event of a negative test result.\n\nThe provided definitions are:\n- Sensitivity: $Se = P(T^{+} \\mid D)$\n- Specificity: $Sp = P(T^{-} \\mid \\bar D)$\n- Prevalence: $\\pi = P(D)$\n- Positive Predictive Value (PPV): $P(D \\mid T^{+})$\n- Negative Predictive Value (NPV): $P(\\bar D \\mid T^{-})$\n\nThe problem asks to determine which statements are correct based on these definitions, Bayes' theorem, and the provided numerical values: $Se = 0.90$, $Sp = 0.995$, and two prevalence values, $\\pi_1 = 0.0005$ and $\\pi_2 = 0.20$.\n\nOur first task is to derive the explicit expressions for PPV and NPV as functions of $Se$, $Sp$, and $\\pi$.\n\n**Derivation of Positive Predictive Value (PPV)**\nBy definition, $PPV = P(D \\mid T^{+})$. Using Bayes' theorem:\n$$PPV = \\frac{P(T^{+} \\mid D) P(D)}{P(T^{+})}$$\nThe total probability of a positive test, $P(T^{+})$, is given by the law of total probability:\n$$P(T^{+}) = P(T^{+} \\mid D) P(D) + P(T^{+} \\mid \\bar D) P(\\bar D)$$\nWe substitute the given definitions and relations: $P(T^{+} \\mid D) = Se$, $P(D) = \\pi$, $P(\\bar D) = 1 - \\pi$, and $P(T^{+} \\mid \\bar D) = 1 - P(T^{-} \\mid \\bar D) = 1 - Sp$.\n$$P(T^{+}) = Se \\cdot \\pi + (1 - Sp)(1 - \\pi)$$\nSubstituting this into the Bayes' theorem expression for PPV, we obtain:\n$$PPV = \\frac{Se \\cdot \\pi}{Se \\cdot \\pi + (1 - Sp)(1 - \\pi)}$$\n\n**Derivation of Negative Predictive Value (NPV)**\nBy definition, $NPV = P(\\bar D \\mid T^{-})$. Using Bayes' theorem:\n$$NPV = \\frac{P(T^{-} \\mid \\bar D) P(\\bar D)}{P(T^{-})}$$\nThe total probability of a negative test, $P(T^{-})$, is:\n$$P(T^{-}) = P(T^{-} \\mid \\bar D) P(\\bar D) + P(T^{-} \\mid D) P(D)$$\nWe substitute the given definitions and relations: $P(T^{-} \\mid \\bar D) = Sp$, $P(\\bar D) = 1 - \\pi$, $P(D) = \\pi$, and $P(T^{-} \\mid D) = 1 - P(T^{+} \\mid D) = 1 - Se$.\n$$P(T^{-}) = Sp \\cdot (1 - \\pi) + (1 - Se) \\cdot \\pi$$\nSubstituting this into the Bayes' theorem expression for NPV, we obtain:\n$$NPV = \\frac{Sp \\cdot (1 - \\pi)}{Sp \\cdot (1 - \\pi) + (1 - Se) \\cdot \\pi}$$\n\nThese derivations confirm that both PPV and NPV are explicit functions of prevalence, $\\pi$. Now we evaluate each statement.\n\n**A. Because sensitivity and specificity are intrinsic to the assay and do not change across settings, the positive predictive value equals sensitivity whenever specificity is high, and therefore PPV is independent of prevalence.**\nThis statement is fundamentally flawed. PPV, $P(D \\mid T^{+})$, and sensitivity, $P(T^{+} \\mid D)$, are probabilities of different events. Conflating them is a logical error known as the base-rate fallacy. The derived formula for PPV clearly shows its dependence on prevalence $\\pi$. The claim that $PPV$ equals $Se$ is false. For example, if we assume a perfect test where $Se=1$ and $Sp=1$, the formula gives $PPV = \\frac{1 \\cdot \\pi}{1 \\cdot \\pi + 0 \\cdot (1-\\pi)} = 1$, which is not necessarily equal to $Se$. The entire statement is incorrect.\n**Verdict: Incorrect.**\n\n**B. Using Bayes’ theorem with pretest probability equal to prevalence $\\pi$, the positive predictive value satisfies $PPV = \\dfrac{Se\\cdot \\pi}{Se\\cdot \\pi + (1-Sp)\\cdot (1-\\pi)}$ and the negative predictive value satisfies $NPV = \\dfrac{Sp\\cdot (1-\\pi)}{Sp\\cdot (1-\\pi) + (1-Se)\\cdot \\pi}$, making both PPV and NPV explicit functions of $\\pi$.**\nThe formulas presented in this statement are identical to those we derived from first principles using Bayes' theorem. The conclusion that both PPV and NPV are explicit functions of $\\pi$ is a direct consequence of these formulas. This statement is a correct representation of the mathematical relationships.\n**Verdict: Correct.**\n\n**C. With $Se=0.90$ and $Sp=0.995$, in the community program with $\\pi=0.0005$, $PPV \\approx 0.083$ (about $8.3\\%$), whereas in the outbreak ward with $\\pi=0.20$, $PPV \\approx 0.978$ (about $97.8\\%$); this difference arises solely from the different prevalence.**\nWe must perform the calculations using the derived PPV formula and the provided data.\nFor the community program with $\\pi_1 = 0.0005$:\n$$PPV_1 = \\frac{0.90 \\cdot 0.0005}{0.90 \\cdot 0.0005 + (1 - 0.995)(1 - 0.0005)} = \\frac{0.00045}{0.00045 + (0.005)(0.9995)} = \\frac{0.00045}{0.00045 + 0.0049975} = \\frac{0.00045}{0.0054475} \\approx 0.082606...$$\nThis value is approximately $0.083$, or $8.3\\%$. The calculation is correct.\nFor the outbreak ward with $\\pi_2 = 0.20$:\n$$PPV_2 = \\frac{0.90 \\cdot 0.20}{0.90 \\cdot 0.20 + (1 - 0.995)(1 - 0.20)} = \\frac{0.18}{0.18 + (0.005)(0.80)} = \\frac{0.18}{0.18 + 0.004} = \\frac{0.18}{0.184} \\approx 0.97826...$$\nThis value is approximately $0.978$, or $97.8\\%$. The calculation is also correct.\nSince $Se$ and $Sp$ were held constant, the dramatic difference in PPV is indeed caused solely by the change in prevalence $\\pi$. The statement is correct.\n**Verdict: Correct.**\n\n**D. As prevalence decreases toward $0$, the negative predictive value approaches sensitivity, because negative results are dominated by true negatives determined by $Se$.**\nWe analyze the limit of NPV as $\\pi \\to 0$:\n$$\\lim_{\\pi \\to 0} NPV = \\lim_{\\pi \\to 0} \\frac{Sp \\cdot (1 - \\pi)}{Sp \\cdot (1 - \\pi) + (1 - Se) \\cdot \\pi} = \\frac{Sp \\cdot (1 - 0)}{Sp \\cdot (1 - 0) + (1 - Se) \\cdot 0} = \\frac{Sp}{Sp} = 1$$\nThe NPV approaches $1$ (or $100\\%$), not sensitivity ($Se$). Additionally, the reasoning is incorrect: true negatives are related to specificity ($Sp$, via $P(T^{-} \\mid \\bar D)$), not sensitivity ($Se$, via $P(T^{+} \\mid D)$). The statement is incorrect on both its claim and its justification.\n**Verdict: Incorrect.**\n\n**E. Holding $Se$ and $Sp$ fixed, as $\\pi \\to 0$ one has $PPV \\to 0$ and $NPV \\to 1$, and as $\\pi \\to 1$ one has $PPV \\to 1$ and $NPV \\to 0$; thus PPV and NPV are not intrinsic properties of the test.**\nWe evaluate the stated limits.\nAs $\\pi \\to 0$:\n$$ \\lim_{\\pi \\to 0} PPV = \\lim_{\\pi \\to 0} \\frac{Se \\cdot \\pi}{Se \\cdot \\pi + (1 - Sp)(1 - \\pi)} = \\frac{Se \\cdot 0}{Se \\cdot 0 + (1 - Sp) \\cdot 1} = 0 $$\n$$ \\lim_{\\pi \\to 0} NPV = \\lim_{\\pi \\to 0} \\frac{Sp \\cdot (1 - \\pi)}{Sp \\cdot (1 - \\pi) + (1 - Se) \\cdot \\pi} = \\frac{Sp \\cdot 1}{Sp \\cdot 1 + (1 - Se) \\cdot 0} = 1 $$\nAs $\\pi \\to 1$:\n$$ \\lim_{\\pi \\to 1} PPV = \\lim_{\\pi \\to 1} \\frac{Se \\cdot \\pi}{Se \\cdot \\pi + (1 - Sp)(1 - \\pi)} = \\frac{Se \\cdot 1}{Se \\cdot 1 + (1 - Sp) \\cdot 0} = 1 $$\n$$ \\lim_{\\pi \\to 1} NPV = \\lim_{\\pi \\to 1} \\frac{Sp \\cdot (1 - \\pi)}{Sp \\cdot (1 - \\pi) + (1 - Se) \\cdot \\pi} = \\frac{Sp \\cdot 0}{Sp \\cdot 0 + (1 - Se) \\cdot 1} = 0 $$\nAll four limits are correctly stated (assuming an imperfect test where $Se < 1$ and $Sp < 1$). Since PPV and NPV vary dramatically with prevalence $\\pi$, they are not intrinsic properties of the test itself but rather are properties of the test applied to a specific population. The conclusion follows directly from the analysis.\n**Verdict: Correct.**\n\n**F. Because the (positive and negative) likelihood ratios (likelihood ratio, LR) are intrinsic to the test, both PPV and NPV are intrinsic and independent of prevalence.**\nThe likelihood ratios are defined as $LR^{+} = \\frac{Se}{1-Sp}$ and $LR^{-} = \\frac{1-Se}{Sp}$. Since $Se$ and $Sp$ are intrinsic, so are $LR^{+}$ and $LR^{-}$. However, the relationship between predictive values and LRs involves the pre-test odds of disease, $\\frac{\\pi}{1-\\pi}$. Specifically, the post-test odds are the pre-test odds multiplied by the likelihood ratio. For PPV:\n$$\\frac{PPV}{1-PPV} = \\frac{\\pi}{1-\\pi} \\cdot LR^{+}$$\nThis equation demonstrates that PPV is a function of both the intrinsic $LR^{+}$ and the extrinsic prevalence $\\pi$. The argument that intrinsic LRs imply intrinsic predictive values is a non sequitur and is demonstrably false.\n**Verdict: Incorrect.**\n\n**G. The base-rate fallacy in screening arises from conflating $P(T^{+}\\mid D)$ with $P(D\\mid T^{+})$; at very low $\\pi$, even high $Sp$ and $Se$ can yield a low PPV because false positives from the large pool of non-diseased individuals dominate true positives.**\nThis statement provides a correct definition of the base-rate fallacy in this context: confusing sensitivity with PPV. It then provides a clear and correct mechanistic explanation for the phenomenon. The number of true positives is proportional to $\\pi \\cdot Se$, while the number of false positives is proportional to $(1-\\pi)(1-Sp)$. When $\\pi$ is very low, the population of non-diseased individuals $(1-\\pi)$ is very large. Consequently, even a small false positive rate $(1-Sp)$ can generate a number of false positives that is large relative to, or even exceeds, the number of true positives. Our calculation in C for the low-prevalence setting numerically confirms this: out of $5447.5$ expected positive tests per million people screened, $4997.5$ are false positives and only $450$ are true positives. The statement is entirely correct.\n**Verdict: Correct.**", "answer": "$$\\boxed{BCEG}$$", "id": "2523977"}, {"introduction": "This final practice applies Bayesian reasoning to solve a critical and modern problem in deep learning: learning from data with noisy labels. Real-world datasets are rarely perfect, and a model trained on them will learn to predict these noisy labels. This exercise casts Bayes' rule in the language of linear algebra, using a confusion matrix $C$ to model the noise process. You will derive and implement a method to \"invert\" this process, correcting the classifier's output to better reflect the true, clean label distribution, a technique vital for building robust and reliable machine learning systems [@problem_id:3102043].", "problem": "You are given a $K$-class classification scenario with class-conditional label noise. Let the clean label be the discrete random variable $Y \\in \\{1,\\dots,K\\}$, the observed noisy label be $\\hat{Y} \\in \\{1,\\dots,K\\}$, and the input be $X \\in \\mathcal{X}$. The class-conditional noise model is summarized by a column-stochastic confusion matrix $C \\in \\mathbb{R}^{K \\times K}$ with entries $C_{ij} = p(\\hat{Y} = i \\mid Y = j)$, so that each column sums to $1$. A probabilistic classifier produces, for each input $x$, a vector of predicted probabilities over noisy labels $\\hat{p}(x) \\in \\mathbb{R}^K$, where the $i$-th component is $\\hat{p}_i(x) = p(\\hat{Y} = i \\mid X = x)$, and a prior over clean labels $\\pi \\in \\mathbb{R}^K$ with $\\pi_j = \\pi(Y=j)$ is available.\n\nStarting only from the definition of conditional probability and the law of total probability, derive a principled and computable expression for a corrected posterior over clean labels $p(Y \\mid X=x)$ that uses $C$, $\\hat{p}(x)$, and $\\pi$ as inputs. Your derivation must explicitly explain the role of the confusion matrix as a linear operator linking the distributions, justify the need for normalization, and address numerical stability via matrix invertibility and conditioning. You must design an algorithm that:\n- Accepts any $C$, $\\hat{p}(x)$, and $\\pi$ of compatible dimensions, with $C$ column-stochastic, $\\hat{p}(x)$ nonnegative, and $\\pi$ nonnegative.\n- Tests invertibility of $C$ via rank and quantifies numerical stability via the $2$-norm condition number $\\kappa_2(C)$. Use the stability threshold $\\tau = 10^6$: a matrix is considered numerically unstable if $\\kappa_2(C) > \\tau$.\n- Uses the exact inverse of $C$ only if $C$ is invertible and $\\kappa_2(C) \\le \\tau$; otherwise, uses the Moore–Penrose pseudoinverse.\n- Incorporates the prior $\\pi$ multiplicatively into the unnormalized clean posterior and then renormalizes to obtain a valid probability vector.\n- Enforces nonnegativity of the final posterior by zeroing out small negative entries (if any) introduced by numerical errors before normalization.\n- Renormalizes $\\hat{p}(x)$ and $\\pi$ to sum to $1$ if they do not already.\n\nImplement your derivation as a complete program that outputs results for the following test suite. For each test case $t \\in \\{1,2,3,4,5\\}$, return a list with five items: \n$[\\text{is\\_invertible}, \\text{is\\_stable}, \\text{cond\\_rounded}, \\text{method\\_code}, \\text{posterior\\_rounded}]$, where:\n- $\\text{is\\_invertible}$ is a boolean indicating whether $C$ is invertible.\n- $\\text{is\\_stable}$ is a boolean indicating whether $\\kappa_2(C) \\le \\tau$.\n- $\\text{cond\\_rounded}$ is the condition number rounded to $3$ decimal places.\n- $\\text{method\\_code}$ is the integer $1$ if the exact inverse was used, or $0$ if the pseudoinverse was used.\n- $\\text{posterior\\_rounded}$ is the list of the corrected clean-label posterior entries rounded to $6$ decimal places.\n\nThe final program output must be a single line containing the list of the $5$ per-test-case lists, comma-separated and enclosed in square brackets.\n\nUse the following test suite (each case is self-consistent and column-stochastic):\n\nTest case $1$ ($K=3$):\n$$\nC^{(1)} = \\begin{bmatrix}\n0.8 & 0.1 & 0.1 \\\\\n0.1 & 0.8 & 0.1 \\\\\n0.1 & 0.1 & 0.8\n\\end{bmatrix},\\quad\n\\pi^{(1)} = \\begin{bmatrix} 0.5 \\\\ 0.3 \\\\ 0.2 \\end{bmatrix},\\quad\n\\hat{p}^{(1)} = \\begin{bmatrix} 0.7 \\\\ 0.2 \\\\ 0.1 \\end{bmatrix}.\n$$\n\nTest case $2$ ($K=3$, nearly singular but invertible):\n$$\nC^{(2)} = \\begin{bmatrix}\n0.49 & 0.50 & 0.01 \\\\\n0.48 & 0.49 & 0.01 \\\\\n0.03 & 0.01 & 0.98\n\\end{bmatrix},\\quad\n\\pi^{(2)} = \\begin{bmatrix} \\tfrac{1}{3} \\\\ \\tfrac{1}{3} \\\\ \\tfrac{1}{3} \\end{bmatrix},\\quad\n\\hat{p}^{(2)} = \\begin{bmatrix} 0.50 \\\\ 0.49 \\\\ 0.01 \\end{bmatrix}.\n$$\n\nTest case $3$ ($K=3$, singular):\n$$\nC^{(3)} = \\begin{bmatrix}\n0.7 & 0.7 & 0.1 \\\\\n0.2 & 0.2 & 0.2 \\\\\n0.1 & 0.1 & 0.7\n\\end{bmatrix},\\quad\n\\pi^{(3)} = \\begin{bmatrix} 0.2 \\\\ 0.5 \\\\ 0.3 \\end{bmatrix},\\quad\n\\hat{p}^{(3)} = \\begin{bmatrix} 0.4 \\\\ 0.35 \\\\ 0.25 \\end{bmatrix}.\n$$\n\nTest case $4$ ($K=3$, extreme prior, $\\hat{p}$ does not sum to $1$ and must be renormalized):\n$$\nC^{(4)} = \\begin{bmatrix}\n0.9 & 0.05 & 0.05 \\\\\n0.05 & 0.9 & 0.05 \\\\\n0.05 & 0.05 & 0.9\n\\end{bmatrix},\\quad\n\\pi^{(4)} = \\begin{bmatrix} 0.99 \\\\ 0.005 \\\\ 0.005 \\end{bmatrix},\\quad\n\\hat{p}^{(4)} = \\begin{bmatrix} 0.34 \\\\ 0.33 \\\\ 0.35 \\end{bmatrix}.\n$$\n\nTest case $5$ ($K=2$):\n$$\nC^{(5)} = \\begin{bmatrix}\n0.95 & 0.10 \\\\\n0.05 & 0.90\n\\end{bmatrix},\\quad\n\\pi^{(5)} = \\begin{bmatrix} 0.4 \\\\ 0.6 \\end{bmatrix},\\quad\n\\hat{p}^{(5)} = \\begin{bmatrix} 0.6 \\\\ 0.4 \\end{bmatrix}.\n$$\n\nAdditional implementation details:\n- Use the stability threshold $\\tau = 10^6$.\n- If the unnormalized corrected vector becomes the zero vector after nonnegativity enforcement, set it to $\\pi$ before normalization.\n- The program must produce a single line of output containing the results as a comma-separated list enclosed in square brackets (for example, $[\\dots]$). All floating point values must be rounded as specified above.", "solution": "The problem statement is assessed to be valid. It is scientifically grounded in the principles of probability theory and machine learning, well-posed with a clear objective and sufficient data, and formulated with objective, formal language. It represents a standard, non-trivial problem in learning with noisy labels. We can therefore proceed with a full derivation and solution.\n\nThe goal is to derive a computable expression for the posterior probability of the true label $Y$ given an input $X=x$, denoted $p(Y \\mid X=x)$, using a model of class-conditional label noise. The provided components are:\n1.  A column-stochastic confusion matrix $C \\in \\mathbb{R}^{K \\times K}$, where $C_{ij} = p(\\hat{Y} = i \\mid Y = j)$ represents the probability of observing a noisy label $\\hat{Y}=i$ when the true label is $Y=j$.\n2.  A vector of predicted noisy-label posteriors from a classifier, $\\hat{p}(x) \\in \\mathbb{R}^K$, with components $\\hat{p}_i(x) = p(\\hat{Y} = i \\mid X=x)$.\n3.  A prior over the true labels, $\\pi \\in \\mathbb{R}^K$, with components $\\pi_j = \\pi(Y=j)$.\n\nOur derivation begins with the law of total probability to establish a relationship between the desired true posterior $p(Y=j \\mid X=x)$ and the observed noisy posterior $p(\\hat{Y}=i \\mid X=x)$. We can express the probability of observing a noisy label $i$ by marginalizing over all possible true labels $j \\in \\{1, \\dots, K\\}$:\n$$\np(\\hat{Y}=i \\mid X=x) = \\sum_{j=1}^{K} p(\\hat{Y}=i, Y=j \\mid X=x)\n$$\nUsing the definition of conditional probability, $p(A, B \\mid C) = p(A \\mid B, C) p(B \\mid C)$, we can rewrite the term inside the summation:\n$$\np(\\hat{Y}=i \\mid X=x) = \\sum_{j=1}^{K} p(\\hat{Y}=i \\mid Y=j, X=x) p(Y=j \\mid X=x)\n$$\nThe problem is defined under the standard assumption of class-conditional noise, which posits that the label noise process is independent of the input feature $X$, given the true label $Y$. This is formally expressed as $\\hat{Y} \\perp X \\mid Y$, which implies:\n$$\np(\\hat{Y}=i \\mid Y=j, X=x) = p(\\hat{Y}=i \\mid Y=j)\n$$\nThis term is precisely the entry $C_{ij}$ of the confusion matrix. Substituting this into our equation yields:\n$$\np(\\hat{Y}=i \\mid X=x) = \\sum_{j=1}^{K} C_{ij} \\, p(Y=j \\mid X=x)\n$$\nThis fundamental equation holds for each noisy label $i \\in \\{1, \\dots, K\\}$. By defining a column vector for the noisy posteriors, $\\hat{p}(x)$, with entries $\\hat{p}_i(x)$, and a column vector for the true posteriors, $p(x)$, with entries $p_j(x) = p(Y=j \\mid X=x)$, we can express this system of linear equations in matrix form:\n$$\n\\hat{p}(x) = C p(x)\n$$\nThis relationship demonstrates that the confusion matrix $C$ acts as a linear operator that transforms the vector of true posterior probabilities into the vector of observable noisy posterior probabilities.\n\nTo estimate the true posterior $p(x)$, we must invert this linear transformation. This suggests a solution of the form $p(x) = C^{\\dagger} \\hat{p}(x)$, where $C^{\\dagger}$ is a suitable inverse of $C$. The choice of the inverse is critical for numerical stability.\n- If $C$ is invertible (i.e., its rank equals its dimension $K$) and well-conditioned, we can use the exact matrix inverse, $C^{-1}$.\n- A matrix is ill-conditioned if its condition number is large, meaning small errors in the input $\\hat{p}(x)$ can be greatly amplified in the output. The problem specifies using the $2$-norm condition number $\\kappa_2(C) = \\|C\\|_2 \\|C^{-1}\\|_2$. If $\\kappa_2(C)$ exceeds a stability threshold $\\tau = 10^6$, the matrix is considered numerically unstable for inversion.\n- If $C$ is singular (not invertible) or numerically unstable, the Moore-Penrose pseudoinverse, $C^{+}$, provides a robust alternative. It finds the minimum-norm least-squares solution to the linear system, which is a principled approach when a unique, stable solution is not available.\n\nLet $p_{inv}(x) = C^{\\dagger} \\hat{p}(x)$ be the estimate of the true posterior obtained from inverting the noise model, where $C^{\\dagger}$ is either $C^{-1}$ or $C^{+}$ based on the stability analysis. This estimate is derived from instance-specific information $x$ via the classifier output $\\hat{p}(x)$.\n\nThe problem further requires incorporating the global class prior $\\pi$. Following the directive to incorporate $\\pi$ \"multiplicatively into the unnormalized clean posterior,\" we interpret this as a Bayesian update. The prior belief about class distribution, $\\pi$, is updated by the instance-specific evidence, which we take to be $p_{inv}(x)$. The unnormalized posterior is thus formed by the element-wise (Hadamard) product of these two vectors:\n$$\np_{unnorm}(x) = p_{inv}(x) \\odot \\pi\n$$\nThis step combines the general knowledge about class frequencies ($\\pi$) with the specific evidence for the given input instance ($x$).\n\nThe resulting vector $p_{unnorm}(x)$ is not guaranteed to be a valid probability distribution. Its components may be negative due to numerical errors or model misspecification, and its sum is not necessarily $1$. To produce a valid posterior, we must perform two final steps:\n1.  **Enforce Nonnegativity**: Negative values are unphysical for probabilities. We set any negative components of $p_{unnorm}(x)$ to $0$. Let this clipped vector be $p'_{unnorm}(x)$. In the edge case where this results in a zero vector, we reset it to the prior $\\pi$ as a fallback.\n2.  **Normalization**: To ensure the probabilities sum to $1$, we normalize the vector by dividing by its sum. This is a necessary step, as the preceding operations (inversion, multiplication) do not preserve the sum-to-one property.\n$$\np_{final}(x)_j = \\frac{p'_{unnorm, j}(x)}{\\sum_{k=1}^{K} p'_{unnorm, k}(x)}\n$$\n\nThis completes the derivation of a principled and computable expression for the corrected posterior. The full algorithm is as follows:\n\n**Algorithm: Label Noise Correction**\n1.  **Input**: Confusion matrix $C$, noisy posterior $\\hat{p}(x)$, and prior $\\pi$.\n2.  **Preprocessing**: Renormalize $\\hat{p}(x)$ and $\\pi$ to sum to $1$ if they do not.\n3.  **Stability Analysis**:\n    a. Compute the rank of $C$ to check for invertibility.\n    b. Compute the $2$-norm condition number $\\kappa_2(C)$.\n    c. If $\\text{rank}(C)=K$ and $\\kappa_2(C) \\le 10^6$, select the exact inverse $C^{-1}$.\n    d. Otherwise, select the Moore-Penrose pseudoinverse $C^{+}$.\n4.  **Correction**: Compute the initial clean posterior estimate: $p_{inv}(x) \\leftarrow C^{\\dagger} \\hat{p}(x)$.\n5.  **Prior Incorporation**: Compute the unnormalized posterior: $p_{unnorm}(x) \\leftarrow p_{inv}(x) \\odot \\pi$.\n6.  **Post-processing**:\n    a. Enforce nonnegativity: $p'_{unnorm}(x) \\leftarrow \\max(p_{unnorm}(x), 0)$.\n    b. If $\\sum_k p'_{unnorm,k}(x)$ is close to $0$, set $p'_{unnorm}(x) \\leftarrow \\pi$.\n    c. Normalize: $p_{final}(x) \\leftarrow p'_{unnorm}(x) / \\sum_k p'_{unnorm,k}(x)$.\n7.  **Output**: The corrected posterior probability vector $p_{final}(x)$.\n\nThis algorithm is robust to singular or ill-conditioned noise models and correctly combines instance-specific evidence with prior knowledge to produce a valid, corrected probability distribution.", "answer": "```python\nimport numpy as np\nimport json\n\ndef solve():\n    \"\"\"\n    Main function to run the test suite for label noise correction.\n    \"\"\"\n    \n    # Stability threshold for condition number\n    TAU = 1e6\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # Test case 1 (K=3, well-conditioned)\n        (\n            np.array([[0.8, 0.1, 0.1], [0.1, 0.8, 0.1], [0.1, 0.1, 0.8]]),\n            np.array([0.5, 0.3, 0.2]),\n            np.array([0.7, 0.2, 0.1])\n        ),\n        # Test case 2 (K=3, nearly singular but invertible)\n        (\n            np.array([[0.49, 0.50, 0.01], [0.48, 0.49, 0.01], [0.03, 0.01, 0.98]]),\n            np.array([1/3, 1/3, 1/3]),\n            np.array([0.50, 0.49, 0.01])\n        ),\n        # Test case 3 (K=3, singular)\n        (\n            np.array([[0.7, 0.7, 0.1], [0.2, 0.2, 0.2], [0.1, 0.1, 0.7]]),\n            np.array([0.2, 0.5, 0.3]),\n            np.array([0.4, 0.35, 0.25])\n        ),\n        # Test case 4 (K=3, extreme prior, inputs need renormalization)\n        (\n            np.array([[0.9, 0.05, 0.05], [0.05, 0.9, 0.05], [0.05, 0.05, 0.9]]),\n            np.array([0.99, 0.005, 0.005]),\n            np.array([0.34, 0.33, 0.35])\n        ),\n        # Test case 5 (K=2)\n        (\n            np.array([[0.95, 0.10], [0.05, 0.90]]),\n            np.array([0.4, 0.6]),\n            np.array([0.6, 0.4])\n        ),\n    ]\n\n    results = []\n    for C, pi, p_hat in test_cases:\n        # Get dimension K\n        K = C.shape[0]\n\n        # --- Step 1: Normalize inputs ---\n        p_hat_sum = np.sum(p_hat)\n        if not np.isclose(p_hat_sum, 1.0):\n            p_hat = p_hat / p_hat_sum\n        \n        pi_sum = np.sum(pi)\n        if not np.isclose(pi_sum, 1.0):\n            pi = pi / pi_sum\n\n        # --- Step 2: Analyze confusion matrix C ---\n        matrix_rank = np.linalg.matrix_rank(C)\n        is_invertible = (matrix_rank == K)\n\n        cond_num = np.linalg.cond(C)\n        is_stable = (cond_num <= TAU)\n\n        # --- Step 3: Choose inverse method ---\n        if is_invertible and is_stable:\n            method_code = 1\n            C_inv = np.linalg.inv(C)\n        else:\n            method_code = 0\n            C_inv = np.linalg.pinv(C)\n\n        # --- Step 4: Apply inverse and incorporate prior ---\n        p_inv = C_inv @ p_hat\n        p_unnorm = p_inv * pi # Element-wise multiplication\n\n        # --- Step 5: Enforce nonnegativity and handle zero vector ---\n        p_unnorm_clipped = np.maximum(p_unnorm, 0)\n        \n        # If clipping results in a zero vector, fallback to the prior\n        if np.isclose(np.sum(p_unnorm_clipped), 0.0):\n            p_unnorm_clipped = pi\n\n        # --- Step 6: Final normalization ---\n        p_unnorm_sum = np.sum(p_unnorm_clipped)\n        if np.isclose(p_unnorm_sum, 0.0):\n            # This case happens if the fallback to pi was needed and pi was a zero vector\n            # A safe default is a uniform distribution.\n            corrected_posterior = np.full(K, 1.0 / K)\n        else:\n            corrected_posterior = p_unnorm_clipped / p_unnorm_sum\n\n        # --- Step 7: Format output ---\n        cond_rounded = round(cond_num, 3)\n        posterior_rounded = [round(p, 6) for p in corrected_posterior]\n        \n        results.append([\n            is_invertible,\n            is_stable,\n            cond_rounded,\n            method_code,\n            posterior_rounded\n        ])\n\n    # Convert boolean to lowercase 'true'/'false' and remove spaces for compact output\n    # using a custom string representation build.\n    def format_result_list(lst):\n        items = []\n        for item in lst:\n            if isinstance(item, bool):\n                items.append(str(item).lower())\n            elif isinstance(item, list):\n                items.append(f\"[{','.join(map(str, item))}]\")\n            else:\n                items.append(str(item))\n        return f\"[{','.join(items)}]\"\n\n    output_str = f\"[{','.join([format_result_list(res) for res in results])}]\"\n    \n    # Final print statement in the exact required format.\n    print(output_str)\n\nsolve()\n```", "id": "3102043"}]}