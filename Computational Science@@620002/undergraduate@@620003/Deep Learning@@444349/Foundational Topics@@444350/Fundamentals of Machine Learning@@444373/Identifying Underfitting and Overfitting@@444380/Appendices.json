{"hands_on_practices": [{"introduction": "Understanding the balance between underfitting and overfitting is central to machine learning. This first practice provides a foundational, hands-on experience with this tradeoff using polynomial regression, a simple and intuitive modeling framework. You will move beyond qualitative visual inspection by implementing quantitative metrics to classify a model's behavior, including the standard Mean Squared Error and a more advanced technique involving the frequency analysis of residuals to detect the high-frequency oscillations characteristic of overfitting [@problem_id:3135788]. This exercise builds a concrete, numerical intuition for the bias-variance tradeoff in a controlled environment.", "problem": "You are given a supervised learning setting for one-dimensional regression modeled in terms of Empirical Risk Minimization (ERM). Let the input be $x \\in [-1,1]$ and the ground-truth target function be a polynomial of known degree $d^\\star$, contaminated by zero-mean Gaussian noise with variance $\\sigma^2$. Specifically, let the data be generated as $y = f^\\star(x) + \\varepsilon$, where $f^\\star(x) = \\sum_{k=0}^{d^\\star} a_k x^k$, $d^\\star = 4$, the coefficients are $a_0 = 0.3$, $a_1 = -0.8$, $a_2 = 0.5$, $a_3 = 0.0$, $a_4 = 0.7$, and the noise is $\\varepsilon \\sim \\mathcal{N}(0,\\sigma^2)$ with $\\sigma = 0.1$ (so $\\sigma^2 = 0.01$). The dataset size is $N = 200$ points with inputs $x$ drawn uniformly from $[-1,1]$. Use $N_{\\text{train}} = 120$ samples for training and $N_{\\text{valid}} = 80$ samples for validation. Use a fixed random seed, $42$, to ensure reproducibility.\n\nYour task is to implement polynomial regression with ridge regularization (also known as $\\ell_2$ regularization). For a chosen model degree $d$ and a regularization strength $\\lambda \\ge 0$, construct the design matrix $\\Phi \\in \\mathbb{R}^{m \\times (d+1)}$ with entries $\\Phi_{i,k} = x_i^k$. Given training data $(\\Phi_{\\text{train}}, y_{\\text{train}})$, compute the ridge estimator coefficients $w \\in \\mathbb{R}^{d+1}$ using the closed-form solution\n$$\nw = \\left(\\Phi_{\\text{train}}^\\top \\Phi_{\\text{train}} + \\lambda I\\right)^{-1} \\Phi_{\\text{train}}^\\top y_{\\text{train}},\n$$\nwhere $I$ is the $(d+1) \\times (d+1)$ identity matrix. Use this estimator to obtain predictions on training and validation sets, and compute the residuals $r_{\\text{train}} = y_{\\text{train}} - \\hat{y}_{\\text{train}}$ and $r_{\\text{valid}} = y_{\\text{valid}} - \\hat{y}_{\\text{valid}}$.\n\nFrom first principles, identify underfitting and overfitting using the following definitions and measurements:\n\n- Mean Squared Error (MSE) is defined as $ \\text{MSE} = \\frac{1}{m} \\sum_{i=1}^m (y_i - \\hat{y}_i)^2 $. Let $\\text{MSE}_{\\text{train}}$ and $\\text{MSE}_{\\text{valid}}$ denote the training and validation mean squared errors, respectively.\n- Oscillation in residuals is quantified in the frequency domain. Compute the Discrete Fourier Transform (DFT) of the validation residual sequence sorted by its corresponding inputs $x$ in ascending order. Use the real-valued DFT $R = \\text{rfft}(r_{\\text{valid-sorted}})$ and define the high-frequency energy ratio as\n$$\n\\rho_{\\text{HF}} = \\frac{\\sum_{k \\in \\mathcal{H}} |R_k|^2}{\\sum_{k \\in \\mathcal{P}} |R_k|^2},\n$$\nwhere $\\mathcal{P}$ indexes all positive-frequency bins excluding the zero-frequency bin and $\\mathcal{H}$ indexes the top quartile of positive-frequency bins (the highest-frequency $25\\%$ of $\\mathcal{P}$). If the denominator is zero, define $\\rho_{\\text{HF}} = 0$.\n\nUse the following classification rules with fixed thresholds to decide whether a model is underfitting, well-fit, or overfitting. Denote the known noise variance by $\\sigma^2 = 0.01$, and let the thresholds be $t_u = 1.3$, $t_o = 0.9$, $t_o' = 1.2$, $h_u = 0.35$, and $h_o = 0.45$.\n\n- Underfitting (code $0$): declare underfitting if either $d < d^\\star$ or if $\\text{MSE}_{\\text{train}} \\ge t_u \\sigma^2$ and $\\text{MSE}_{\\text{valid}} \\ge t_u \\sigma^2$ and $\\rho_{\\text{HF}} \\le h_u$.\n- Overfitting (code $2$): declare overfitting if $d > d^\\star$ and $\\text{MSE}_{\\text{train}} \\le t_o \\sigma^2$ and $\\text{MSE}_{\\text{valid}} \\ge t_o' \\sigma^2$ and $\\rho_{\\text{HF}} \\ge h_o$.\n- Well-fit (code $1$): if neither of the above conditions hold, declare well-fit.\n\nImplement the above and evaluate the following test suite that varies $d$ and $\\lambda$:\n\n- Case $1$: $d = 2$, $\\lambda = 0.001$.\n- Case $2$: $d = 4$, $\\lambda = 0.05$.\n- Case $3$: $d = 12$, $\\lambda = 0.0$.\n- Case $4$: $d = 12$, $\\lambda = 10.0$.\n- Case $5$: $d = 4$, $\\lambda = 0.0$.\n\nYour program must generate the dataset as specified, fit the model for each case, compute the metrics, and output the classification codes for the cases in the given order. Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (e.g., $[0,1,2,0,1]$). No physical units, angle units, or percentages are required for this problem. The final output values are integers specified as above. The program must be complete and runnable as is, with no external inputs or files. Use a deterministic seed as specified so results are reproducible for anyone running the program.", "solution": "The problem statement has been meticulously validated and is determined to be valid. It is scientifically sound, self-contained, and well-posed, providing a clear and formalizable task in the domain of computational statistics and machine learning.\n\nThe task is to classify polynomial regression models as underfitting, well-fit, or overfitting based on a set of precise, quantitative criteria. The solution involves data generation, model fitting, metric computation, and classification for several test cases. The entire process is deterministic due to a specified random seed.\n\n### Step 1: Data Generation and Preparation\n\nThe foundation of this regression problem is a synthetic dataset. The ground-truth relationship between the input $x$ and the output $y$ is defined by a known polynomial function $f^\\star(x)$ of degree $d^\\star=4$:\n$$\nf^\\star(x) = a_0 + a_1 x + a_2 x^2 + a_3 x^3 + a_4 x^4\n$$\nwith coefficients $a_0 = 0.3$, $a_1 = -0.8$, $a_2 = 0.5$, $a_3 = 0.0$, and $a_4 = 0.7$.\n\nThe observed data are corrupted by additive white Gaussian noise, $\\varepsilon \\sim \\mathcal{N}(0, \\sigma^2)$, where the noise variance is $\\sigma^2 = 0.01$. Thus, each data point $(x_i, y_i)$ is generated according to the model:\n$$\ny_i = f^\\star(x_i) + \\varepsilon_i\n$$\nA total of $N=200$ data points are created. The input values $x_i$ are drawn from a uniform distribution over the interval $[-1, 1]$. To ensure reproducibility, the random number generator is initialized with a fixed seed of $42$.\n\nThe generated dataset of $N=200$ points is then deterministically shuffled and split into a training set of size $N_{\\text{train}} = 120$ and a validation set of size $N_{\\text{valid}} = 80$. This partitioning allows us to train the model and independently evaluate its generalization performance.\n\n### Step 2: Polynomial Regression with Ridge Regularization\n\nFor each test case, we fit a polynomial model of a specified degree $d$ to the training data. The model hypothesis is of the form:\n$$\n\\hat{y}(x) = \\sum_{k=0}^d w_k x^k = \\mathbf{w}^\\top \\phi(x)\n$$\nwhere $\\mathbf{w} \\in \\mathbb{R}^{d+1}$ is the vector of model coefficients to be learned and $\\phi(x) = [1, x, x^2, \\dots, x^d]^\\top$ is the feature vector.\n\nFor a set of $m$ training samples, we construct the design matrix $\\Phi_{\\text{train}} \\in \\mathbb{R}^{m \\times (d+1)}$, where each entry is $(\\Phi_{\\text{train}})_{i,k} = x_i^k$ for $i \\in \\{1, \\dots, m\\}$ and $k \\in \\{0, \\dots, d\\}$.\n\nThe coefficients $\\mathbf{w}$ are estimated using ridge regression, which minimizes the regularized sum of squared errors:\n$$\n\\mathcal{L}(\\mathbf{w}) = \\|\\mathbf{y}_{\\text{train}} - \\Phi_{\\text{train}}\\mathbf{w}\\|_2^2 + \\lambda \\|\\mathbf{w}\\|_2^2\n$$\nHere, $\\lambda \\ge 0$ is the regularization parameter that controls the penalty on the magnitude of the coefficients. The closed-form solution for the optimal weight vector $\\mathbf{w}$ is given by the normal equations:\n$$\n\\mathbf{w} = \\left(\\Phi_{\\text{train}}^\\top \\Phi_{\\text{train}} + \\lambda I\\right)^{-1} \\Phi_{\\text{train}}^\\top \\mathbf{y}_{\\text{train}}\n$$\nwhere $I$ is the $(d+1) \\times (d+1)$ identity matrix. For numerical stability, this linear system is solved using `numpy.linalg.solve` rather than by computing the matrix inverse explicitly.\n\n### Step 3: Model Evaluation Metrics\n\nOnce the model is trained (i.e., $\\mathbf{w}$ is computed), its performance is evaluated using two key metrics.\n\n**Mean Squared Error (MSE):** The MSE measures the average squared difference between the predicted values $\\hat{y}_i$ and the actual values $y_i$. It is computed for both the training and validation sets:\n$$\n\\text{MSE}_{\\text{train}} = \\frac{1}{N_{\\text{train}}} \\sum_{i=1}^{N_{\\text{train}}} (y_{\\text{train},i} - \\hat{y}_{\\text{train},i})^2\n$$\n$$\n\\text{MSE}_{\\text{valid}} = \\frac{1}{N_{\\text{valid}}} \\sum_{i=1}^{N_{\\text{valid}}} (y_{\\text{valid},i} - \\hat{y}_{\\text{valid},i})^2\n$$\n\n**High-Frequency Energy Ratio ($\\rho_{\\text{HF}}$):** This metric quantifies the oscillatory nature of the model's errors on the validation set, which is a common symptom of overfitting. The procedure is as follows:\n1.  Compute the validation residuals: $\\mathbf{r}_{\\text{valid}} = \\mathbf{y}_{\\text{valid}} - \\hat{\\mathbf{y}}_{\\text{valid}}$.\n2.  Sort these residuals based on the ascending order of their corresponding input values $x_{\\text{valid}}$. Let this sorted sequence be $\\mathbf{r}_{\\text{valid-sorted}}$.\n3.  Compute the real-valued Discrete Fourier Transform (DFT) of the sorted residuals: $R = \\text{rfft}(\\mathbf{r}_{\\text{valid-sorted}})$. For $N_{\\text{valid}} = 80$, the output $R$ is a complex-valued array of length $41$.\n4.  The set of positive-frequency bins, $\\mathcal{P}$, consists of all bins except the zero-frequency (DC) component. For the RFFT output $R$, these correspond to indices $k \\in \\{1, 2, \\dots, 40\\}$.\n5.  The set of high-frequency bins, $\\mathcal{H}$, is defined as the top quartile (highest $25\\%$) of the frequencies in $\\mathcal{P}$. This corresponds to the last $40 \\times 0.25 = 10$ bins, which have indices $k \\in \\{31, 32, \\dots, 40\\}$.\n6.  The high-frequency energy ratio is then the ratio of the energy in $\\mathcal{H}$ to the total energy in $\\mathcal{P}$:\n    $$\n    \\rho_{\\text{HF}} = \\frac{\\sum_{k \\in \\mathcal{H}} |R_k|^2}{\\sum_{k \\in \\mathcal{P}} |R_k|^2}\n    $$\n    If the denominator is zero, $\\rho_{\\text{HF}}$ is defined as $0$.\n\n### Step 4: Classification Logic\n\nThe computed metrics are used to classify each model as underfitting, well-fit, or overfitting according to a fixed set of rules. The ground truth noise variance is $\\sigma^2 = 0.01$, and the thresholds are $t_u = 1.3$, $t_o = 0.9$, $t_o' = 1.2$, $h_u = 0.35$, and $h_o = 0.45$.\n\n- **Underfitting (Code $0$):** A model is declared to be underfitting if its degree $d$ is less than the true degree $d^\\star$, *or* if it exhibits high error on both training and validation sets coupled with low residual oscillation. Formally:\n  $$\n  (d < d^\\star) \\lor (\\text{MSE}_{\\text{train}} \\ge t_u \\sigma^2 \\land \\text{MSE}_{\\text{valid}} \\ge t_u \\sigma^2 \\land \\rho_{\\text{HF}} \\le h_u)\n  $$\n\n- **Overfitting (Code $2$):** A model is declared to be overfitting if its degree $d$ is greater than $d^\\star$ *and* it shows a low training error, a significantly higher validation error, and high-frequency oscillations in its residuals. Formally:\n  $$\n  (d > d^\\star) \\land (\\text{MSE}_{\\text{train}} \\le t_o \\sigma^2 \\land \\text{MSE}_{\\text{valid}} \\ge t_o' \\sigma^2 \\land \\rho_{\\text{HF}} \\ge h_o)\n  $$\n\n- **Well-fit (Code $1$):** If a model meets neither the underfitting nor the overfitting criteria, it is classified as well-fit.\n\nThese rules provide a concrete, algorithmic definition of the bias-variance trade-off concepts. The program implements this logic for each specified test case, generating a final list of classification codes.", "answer": "```python\nimport numpy as np\nimport scipy.fft\n\ndef solve():\n    \"\"\"\n    Main function to execute the polynomial regression analysis and classification.\n    \"\"\"\n    #\n    # Step 0: Define constants and problem parameters\n    #\n    RANDOM_SEED = 42\n    D_STAR = 4\n    A_COEFFS = np.array([0.3, -0.8, 0.5, 0.0, 0.7])\n    SIGMA = 0.1\n    SIGMA_SQUARED = SIGMA**2\n    N_TOTAL = 200\n    N_TRAIN = 120\n    N_VALID = 80\n\n    # Classification thresholds\n    T_U = 1.3\n    T_O = 0.9\n    T_O_PRIME = 1.2\n    H_U = 0.35\n    H_O = 0.45\n\n    # Test cases to evaluate\n    test_cases = [\n        {'d': 2, 'lambda': 0.001},  # Case 1\n        {'d': 4, 'lambda': 0.05},   # Case 2\n        {'d': 12, 'lambda': 0.0},    # Case 3\n        {'d': 12, 'lambda': 10.0},   # Case 4\n        {'d': 4, 'lambda': 0.0},    # Case 5\n    ]\n    \n    #\n    # Step 1: Generate dataset\n    #\n    rng = np.random.default_rng(RANDOM_SEED)\n\n    # Generate x values\n    x = rng.uniform(-1, 1, size=N_TOTAL)\n\n    # Generate true function values y_star\n    def f_star(x_in):\n        return A_COEFFS[0] + A_COEFFS[1] * x_in + A_COEFFS[2] * x_in**2 + \\\n               A_COEFFS[3] * x_in**3 + A_COEFFS[4] * x_in**4\n\n    y_star = f_star(x)\n\n    # Add Gaussian noise\n    noise = rng.normal(0, SIGMA, size=N_TOTAL)\n    y = y_star + noise\n\n    # Split into training and validation sets\n    indices = np.arange(N_TOTAL)\n    rng.shuffle(indices)\n    \n    train_indices = indices[:N_TRAIN]\n    valid_indices = indices[N_TRAIN:]\n\n    x_train, y_train = x[train_indices], y[train_indices]\n    x_valid, y_valid = x[valid_indices], y[valid_indices]\n\n    #\n    # Helper functions\n    #\n    def construct_design_matrix(x_data, degree):\n        \"\"\"Constructs the polynomial design matrix Phi.\"\"\"\n        return np.vander(x_data, degree + 1, increasing=True)\n\n    results = []\n\n    #\n    # Step 2-4: Process each test case\n    #\n    for case in test_cases:\n        d = case['d']\n        lambda_reg = case['lambda']\n\n        # Construct design matrices\n        phi_train = construct_design_matrix(x_train, d)\n        phi_valid = construct_design_matrix(x_valid, d)\n\n        # Fit the model using ridge regression (numerically stable)\n        d_plus_1 = d + 1\n        A = phi_train.T @ phi_train + lambda_reg * np.eye(d_plus_1)\n        b = phi_train.T @ y_train\n        w = np.linalg.solve(A, b)\n\n        # Make predictions\n        y_hat_train = phi_train @ w\n        y_hat_valid = phi_valid @ w\n\n        # Calculate metrics\n        # a) MSE\n        mse_train = np.mean((y_train - y_hat_train)**2)\n        mse_valid = np.mean((y_valid - y_hat_valid)**2)\n        \n        # b) High-frequency energy ratio rho_HF\n        residuals_valid = y_valid - y_hat_valid\n        \n        # Sort residuals according to x_valid\n        sort_indices = np.argsort(x_valid)\n        residuals_valid_sorted = residuals_valid[sort_indices]\n        \n        # Compute RFFT\n        R = scipy.fft.rfft(residuals_valid_sorted)\n        \n        # Calculate energies\n        # P: positive frequencies (indices 1 to end)\n        # H: top quartile of P (last 10 for N_valid=80)\n        # N_valid = 80 -> rfft length = 41. P_indices = 1..40. H_indices = 31..40.\n        num_positive_freqs = len(R) - 1\n        top_quartile_size = int(np.ceil(0.25 * num_positive_freqs))\n        \n        energy_P = np.sum(np.abs(R[1:])**2)\n        energy_H = np.sum(np.abs(R[-top_quartile_size:])**2)\n        \n        rho_hf = energy_H / energy_P if energy_P > 0 else 0.0\n        \n        # Apply classification rules\n        code = 1 # Default to well-fit\n\n        # Underfitting rule\n        is_underfit_by_degree = (d < D_STAR)\n        is_underfit_by_metrics = (mse_train >= T_U * SIGMA_SQUARED and \\\n                                  mse_valid >= T_U * SIGMA_SQUARED and \\\n                                  rho_hf <= H_U)\n        if is_underfit_by_degree or is_underfit_by_metrics:\n            code = 0\n\n        # Overfitting rule\n        is_overfit_by_metrics = (d > D_STAR and \\\n                                 mse_train <= T_O * SIGMA_SQUARED and \\\n                                 mse_valid >= T_O_PRIME * SIGMA_SQUARED and \\\n                                 rho_hf >= H_O)\n        if is_overfit_by_metrics:\n            code = 2\n            \n        results.append(code)\n\n    # Final print statement in the exact required format\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n\n```", "id": "3135788"}, {"introduction": "In real-world model development, a practitioner's most common diagnostic tools are the training and validation loss curves. This practice hones your ability to interpret these curves, focusing on a critical and often subtle distinction: is poor performance due to the model's inability to learn the training data (underfitting from optimization failure), or is it due to the model memorizing the training data too well (overfitting)? You will develop an algorithm to automatically diagnose these scenarios based on the trajectory of the training loss $L_{\\text{train}}$, formalizing the qualitative reasoning used by expert practitioners [@problem_id:3135765].", "problem": "You are given time series of empirical training loss and validation loss for a convolutional neural network (CNN) trained on the CIFAR-10 dataset after removing batch normalization. You must decide, for each case, whether the observed poor generalization arises from underfitting due to optimization failure or from overfitting. Your decision must be based solely on analyzing the trajectory of the training loss, denoted by $L_{\\text{train}}(t)$, and the validation loss, denoted by $L_{\\text{val}}(t)$, over epochs $t \\in \\{1,2,\\dots,T\\}$. No other metrics are available.\n\nUse the following fundamental base:\n- Empirical risk minimization: the empirical risk (training loss) $L_{\\text{train}}$ estimates the expected risk on the training sample, while the validation loss $L_{\\text{val}}$ estimates generalization to unseen data.\n- Overfitting is characterized by small $L_{\\text{train}}$ coupled with a significantly larger $L_{\\text{val}}$, indicating a large generalization gap.\n- Underfitting due to optimization failure is characterized by persistently high $L_{\\text{train}}$ and weak progress in optimization, signaling that the optimizer did not effectively minimize the empirical risk.\n\nYour program must implement a principled decision procedure grounded in these definitions to output, for each case:\n- $0$ if the pattern is consistent with overfitting.\n- $1$ if the pattern is consistent with underfitting due to optimization failure.\n\nTest suite (each case provides $L_{\\text{train}}$ and $L_{\\text{val}}$ as ordered lists over epochs):\n- Case $1$:\n  - $L_{\\text{train}}$: $[1.6, 1.2, 0.8, 0.4, 0.2, 0.1, 0.08, 0.06, 0.05]$\n  - $L_{\\text{val}}$: $[1.7, 1.3, 0.9, 0.7, 0.65, 0.6, 0.58, 0.6, 0.62]$\n- Case $2$:\n  - $L_{\\text{train}}$: $[2.0, 1.95, 1.9, 1.88, 1.87, 1.865, 1.86, 1.859, 1.858]$\n  - $L_{\\text{val}}$: $[2.0, 1.98, 1.96, 1.95, 1.94, 1.94, 1.93, 1.93, 1.93]$\n- Case $3$:\n  - $L_{\\text{train}}$: $[1.2, 1.0, 0.8, 0.6, 0.5, 0.48, 0.47, 0.46, 0.45]$\n  - $L_{\\text{val}}$: $[1.2, 1.1, 0.95, 0.9, 0.92, 0.95, 1.0, 1.05, 1.1]$\n- Case $4$:\n  - $L_{\\text{train}}$: $[1.5, 1.3, 1.2, 1.25, 1.22, 1.21, 1.2, 1.19, 1.18]$\n  - $L_{\\text{val}}$: $[1.6, 1.5, 1.45, 1.5, 1.48, 1.47, 1.47, 1.46, 1.46]$\n- Case $5$:\n  - $L_{\\text{train}}$: $[1.8, 1.5, 1.1, 0.9, 0.7, 0.5, 0.3, 0.2, 0.15]$\n  - $L_{\\text{val}}$: $[1.9, 1.6, 1.3, 1.1, 1.1, 1.15, 1.2, 1.25, 1.3]$\n\nConstraints and requirements:\n- You must base your decision rule on the above fundamental definitions by reasoning from first principles about $L_{\\text{train}}$ and $L_{\\text{val}}$ trajectories, without using any external data or heuristics not derivable from these definitions.\n- The final output must be a single line containing a list of integers corresponding to the cases in order.\n- The only allowed outputs are $0$ and $1$ as defined above. There are no physical units involved.\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (for example, $[0,1,0]$).", "solution": "The problem is scientifically grounded, well-posed, objective, and contains sufficient information to formulate a principled solution. The concepts of training loss, validation loss, overfitting, and underfitting are fundamental in machine learning. The provided data are realistic for the described scenario. The task is to formalize the given qualitative definitions into a quantitative, deterministic algorithm.\n\nThe core objective is to distinguish between two failure modes of generalization: overfitting and underfitting due to optimization failure. This distinction rests upon analyzing the optimizer's success in minimizing the empirical risk, which is represented by the training loss, $L_{\\text{train}}(t)$.\n\nThe provided definitions guide the formulation of a decision procedure:\n1.  **Underfitting due to optimization failure** is defined by a \"persistently high $L_{\\text{train}}$\" and \"weak progress in optimization\". This implies that the model has failed to learn the patterns even in the training data.\n2.  **Overfitting** is defined by a \"small $L_{\\text{train}}$\" and a \"significantly larger $L_{\\text{val}}$\". This implies the model has learned the training data so well (achieving a low empirical risk) that it has also learned the noise and specific artifacts of the training set, leading to poor performance on unseen data (a large generalization gap, $G(t) = L_{\\text{val}}(t) - L_{\\text{train}}(t)$).\n\nBased on these first principles, a sequential decision logic can be established. The primary question is whether the optimization process was successful. If the training loss was not effectively minimized, the diagnosis must be underfitting. If it was successfully minimized, then the observed poor generalization is attributable to overfitting.\n\n**Formalization of the Decision Rule**\n\nLet the sequence of training loss values be $\\mathcal{L}_{\\text{train}} = \\{L_{\\text{train}}(t)\\}_{t=1}^{T}$ over $T$ epochs.\n\n**1. Assessment of Underfitting (Optimization Failure)**\nWe translate the qualitative definition into two quantitative conditions that must be met concurrently.\n-   **\"Persistently high $L_{\\text{train}}$\"**: This is evaluated by inspecting the final training loss, $L_{\\text{train}}(T)$. For a $10$-class classification problem like CIFAR-10, the categorical cross-entropy loss for random guessing is $-\\ln(1/10) \\approx 2.3$. A well-trained model should achieve a training loss significantly below $1.0$. We therefore establish a threshold $\\theta_{\\text{loss}} = 1.0$. A final training loss above this threshold is considered \"high\".\n    $$ \\text{Condition 1: } L_{\\text{train}}(T) > \\theta_{\\text{loss}} = 1.0 $$\n-   **\"Weak progress in optimization\"**: This is measured by the total reduction in training loss from the beginning to the end of training, $\\Delta L_{\\text{train}} = L_{\\text{train}}(1) - L_{\\text{train}}(T)$. A small reduction indicates that the optimizer has stalled or is ineffective. We establish a threshold $\\theta_{\\text{progress}} = 0.5$. A total loss reduction less than this is considered \"weak progress\".\n    $$ \\text{Condition 2: } \\Delta L_{\\text{train}} < \\theta_{\\text{progress}} = 0.5 $$\n\nA case is classified as **underfitting (label $1$)** if and only if both conditions are satisfied. This corresponds to a scenario where the model ends in a state of high training error and has made little progress in reducing it.\n\n**2. Assessment of Overfitting**\nIn this problem's binary classification scheme, any case not identified as underfitting is, by exclusion, classified as **overfitting (label $0$)**. This logic is sound, as a failure to meet the underfitting criteria implies that the training loss was successfully minimized (either $L_{\\text{train}}(T)$ is low, or progress was significant, or both), which is the precondition for overfitting. These cases are characterized by a low final training loss but a large and often growing generalization gap, $G(T) = L_{\\text{val}}(T) - L_{\\text{train}}(T)$, which is the hallmark of overfitting. Often, the validation loss $L_{\\text{val}}(t)$ will reach a minimum and then begin to increase, which is a definitive sign.\n\n**Application to Test Cases**\n\nWe apply this formal procedure to each case.\n\n- **Case 1**:\n  - $L_{\\text{train}} = [1.6, 1.2, 0.8, 0.4, 0.2, 0.1, 0.08, 0.06, 0.05]$\n  - $L_{\\text{train}}(1) = 1.6$, $L_{\\text{train}}(T) = 0.05$.\n  - Condition 1: $L_{\\text{train}}(T) = 0.05 \\ngtr 1.0$. The condition for underfitting is not met.\n  - **Classification: $0$ (Overfitting)**.\n  - Justification: The training loss is minimized to a very low value ($0.05$). The validation loss $L_{\\text{val}}$ bottoms out at $0.58$ and then increases, and a large generalization gap ($0.62 - 0.05 = 0.57$) develops. This is classic overfitting.\n\n- **Case 2**:\n  - $L_{\\text{train}} = [2.0, 1.95, 1.9, 1.88, 1.87, 1.865, 1.86, 1.859, 1.858]$\n  - $L_{\\text{train}}(1) = 2.0$, $L_{\\text{train}}(T) = 1.858$.\n  - Condition 1: $L_{\\text{train}}(T) = 1.858 > 1.0$. (True)\n  - $\\Delta L_{\\text{train}} = 2.0 - 1.858 = 0.142$.\n  - Condition 2: $\\Delta L_{\\text{train}} = 0.142 < 0.5$. (True)\n  - Both conditions for underfitting are met.\n  - **Classification: $1$ (Underfitting)**.\n  - Justification: The training loss remains very high, close to the value for random guessing, and shows almost no improvement over the epochs. This is a clear case of optimization failure.\n\n- **Case 3**:\n  - $L_{\\text{train}} = [1.2, 1.0, 0.8, 0.6, 0.5, 0.48, 0.47, 0.46, 0.45]$\n  - $L_{\\text{train}}(1) = 1.2$, $L_{\\text{train}}(T) = 0.45$.\n  - Condition 1: $L_{\\text{train}}(T) = 0.45 \\ngtr 1.0$. The condition for underfitting is not met.\n  - **Classification: $0$ (Overfitting)**.\n  - Justification: The training loss is minimized to a low value ($0.45$). The validation loss $L_{\\text{val}}$ begins to increase after the fourth epoch, and the final generalization gap is large ($1.1 - 0.45 = 0.65$). This is overfitting.\n\n- **Case 4**:\n  - $L_{\\text{train}} = [1.5, 1.3, 1.2, 1.25, 1.22, 1.21, 1.2, 1.19, 1.18]$\n  - $L_{\\text{train}}(1) = 1.5$, $L_{\\text{train}}(T) = 1.18$.\n  - Condition 1: $L_{\\text{train}}(T) = 1.18 > 1.0$. (True)\n  - $\\Delta L_{\\text{train}} = 1.5 - 1.18 = 0.32$.\n  - Condition 2: $\\Delta L_{\\text{train}} = 0.32 < 0.5$. (True)\n  - Both conditions for underfitting are met.\n  - **Classification: $1$ (Underfitting)**.\n  - Justification: The training loss remains high and the optimization makes very little progress. The loss even increases at one point, indicating instability.\n\n- **Case 5**:\n  - $L_{\\text{train}} = [1.8, 1.5, 1.1, 0.9, 0.7, 0.5, 0.3, 0.2, 0.15]$\n  - $L_{\\text{train}}(1) = 1.8$, $L_{\\text{train}}(T) = 0.15$.\n  - Condition 1: $L_{\\text{train}}(T) = 0.15 \\ngtr 1.0$. The condition for underfitting is not met.\n  - **Classification: $0$ (Overfitting)**.\n  - Justification: The training loss is minimized successfully to a low value ($0.15$). However, the validation loss $L_{\\text{val}}$ diverges and starts increasing, leading to a very large final generalization gap ($1.3 - 0.15 = 1.15$). This is a clear case of overfitting.\n\nThe final sequence of classifications is $[0, 1, 0, 1, 0]$.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n# from scipy import ...\n\ndef solve():\n    \"\"\"\n    Solves the problem of classifying learning behavior as overfitting or underfitting.\n    \n    The function iterates through a predefined set of test cases, each containing\n    time series for training loss and validation loss. It applies a principled \n    decision rule to classify each case and prints the results in the required format.\n    \"\"\"\n    \n    # Test suite with training and validation loss trajectories.\n    test_cases = [\n        # Case 1: Overfitting\n        ([1.6, 1.2, 0.8, 0.4, 0.2, 0.1, 0.08, 0.06, 0.05],\n         [1.7, 1.3, 0.9, 0.7, 0.65, 0.6, 0.58, 0.6, 0.62]),\n        # Case 2: Underfitting\n        ([2.0, 1.95, 1.9, 1.88, 1.87, 1.865, 1.86, 1.859, 1.858],\n         [2.0, 1.98, 1.96, 1.95, 1.94, 1.94, 1.93, 1.93, 1.93]),\n        # Case 3: Overfitting\n        ([1.2, 1.0, 0.8, 0.6, 0.5, 0.48, 0.47, 0.46, 0.45],\n         [1.2, 1.1, 0.95, 0.9, 0.92, 0.95, 1.0, 1.05, 1.1]),\n        # Case 4: Underfitting\n        ([1.5, 1.3, 1.2, 1.25, 1.22, 1.21, 1.2, 1.19, 1.18],\n         [1.6, 1.5, 1.45, 1.5, 1.48, 1.47, 1.47, 1.46, 1.46]),\n        # Case 5: Overfitting\n        ([1.8, 1.5, 1.1, 0.9, 0.7, 0.5, 0.3, 0.2, 0.15],\n         [1.9, 1.6, 1.3, 1.1, 1.1, 1.15, 1.2, 1.25, 1.3])\n    ]\n\n    results = []\n    for l_train, l_val in test_cases:\n        # The validation loss (l_val) is provided but not strictly needed for the\n        # primary classification logic, which focuses on the success of empirical\n        # risk minimization (analyzing l_train).\n        result = classify_behavior(l_train)\n        results.append(result)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\ndef classify_behavior(l_train):\n    \"\"\"\n    Applies a principled decision rule to classify a learning trajectory.\n\n    Args:\n        l_train (list): A time series of training loss values.\n\n    Returns:\n        int: 0 for overfitting, 1 for underfitting due to optimization failure.\n    \"\"\"\n    # Convert list to a numpy array for efficient indexing.\n    l_train_np = np.array(l_train)\n\n    # Thresholds derived from first principles for a 10-class problem:\n    # A final training loss > 1.0 is considered high, indicating failure to fit the training set.\n    theta_loss = 1.0\n    # A total loss reduction < 0.5 is considered weak progress, indicating optimization failure.\n    theta_progress = 0.5\n\n    # Extract key metrics from the training loss trajectory:\n    # Final training loss, L_train(T)\n    final_train_loss = l_train_np[-1]\n    # Initial training loss, L_train(1)\n    initial_train_loss = l_train_np[0]\n    # Total progress in optimization, L_train(1) - L_train(T)\n    progress = initial_train_loss - final_train_loss\n\n    # Apply the decision rule for underfitting due to optimization failure.\n    # This is defined as having a persistently high training loss AND making weak progress.\n    if final_train_loss > theta_loss and progress < theta_progress:\n        # Pattern is consistent with underfitting due to optimization failure.\n        return 1\n    else:\n        # If the underfitting criteria are not met, it implies the optimizer succeeded\n        # in reducing the training loss. Therefore, poor generalization is due to overfitting.\n        return 0\n\nsolve()\n```", "id": "3135765"}, {"introduction": "This final practice explores a modern and subtle form of generalization failure in deep learning known as shortcut learning. Here, a model can achieve high accuracy by exploiting spurious correlations or \"shortcuts\" in the training data that are not truly representative of the underlying task. You will design and execute a complete computational experiment, from generating synthetic data with both robust and shortcut features to implementing a nuanced evaluation protocol that can diagnose if your neural network is truly learning or just taking an easy, non-generalizable path [@problem_id:3135726]. This exercise provides crucial insight into the failure modes of complex models and the experimental techniques used to uncover them.", "problem": "You must write a complete, runnable program that constructs a synthetic binary classification dataset with a mixture of robust features and shortcut features, trains a one-hidden-layer neural network using empirical risk minimization, evaluates validation accuracy under two controlled conditions (shortcut features visible and shortcut features suppressed), and diagnoses overfitting or underfitting from first principles. The program must implement the following scenario and produce a single line of output containing a list of integers for the specified test suite.\n\nFundamental base. Consider empirical risk minimization over a hypothesis class $\\mathcal{F}$, where a classifier $f \\in \\mathcal{F}$ maps inputs $x \\in \\mathbb{R}^d$ to predicted probabilities $\\hat{y} \\in [0,1]$ for a binary label $y \\in \\{0,1\\}$. Let the empirical risk on a dataset $S = \\{(x_i, y_i)\\}_{i=1}^n$ be\n$$\nR_S(f) = \\frac{1}{n} \\sum_{i=1}^n \\ell(f(x_i), y_i),\n$$\nwith the binary cross-entropy loss $\\ell(\\hat{y}, y) = -\\left[y \\log(\\hat{y}) + (1-y)\\log(1-\\hat{y})\\right]$. The expected risk under a distribution $\\mathcal{D}$ is $R_{\\mathcal{D}}(f) = \\mathbb{E}_{(x,y)\\sim\\mathcal{D}}[\\ell(f(x),y)]$. The generalization gap is $\\Gamma(f) = R_{\\mathcal{D}}(f) - R_S(f)$. Overfitting is characterized by small training error but large validation error, and underfitting is characterized by large errors across both training and validation due to insufficient model capacity or poor optimization.\n\nData generation with robust and shortcut features. For each sample, let the input be $x = [r; s] \\in \\mathbb{R}^{p+q}$, where $r \\in \\mathbb{R}^p$ are robust features and $s \\in \\mathbb{R}^q$ are shortcut features. Labels are $y \\in \\{0,1\\}$, and denote $y' = 2y - 1 \\in \\{-1, +1\\}$. Robust features follow\n$$\nr \\sim \\mathcal{N}\\left(m \\, y' \\, \\mathbf{1}_p, \\, \\sigma_r^2 I_p\\right),\n$$\nwhile shortcut features follow\n$$\ns \\sim \\mathcal{N}\\left(\\alpha \\, y' \\, \\mathbf{1}_q, \\, \\sigma_s^2 I_q\\right).\n$$\nAn augmentation called shortcut suppression replaces $s$ by noise independent of $y$:\n$$\nA(x) = [r; \\tilde{s}], \\quad \\tilde{s} \\sim \\mathcal{N}\\left(0, \\sigma_s^2 I_q\\right).\n$$\nThis augmentation preserves the robust signal while suppressing shortcuts. When shortcuts are visible, validation is performed on $x$; when suppressed, validation is performed on $A(x)$.\n\nModel and training. Use a one-hidden-layer neural network $f_\\theta$ with parameters $\\theta = (W_1, b_1, W_2, b_2)$,\n$$\nh = \\phi(W_1 x + b_1), \\quad \\hat{y} = \\sigma(W_2^\\top h + b_2),\n$$\nwhere $\\phi$ is a rectified linear unit (ReLU) and $\\sigma$ is the logistic sigmoid. Train using stochastic gradient descent to minimize $R_S(f_\\theta)$ on a training set generated as above; optionally apply shortcut suppression to the training inputs to discourage shortcut learning.\n\nDiagnosis rules. Let validation accuracy when shortcuts are visible be $a_{\\mathrm{vis}}$ and when suppressed be $a_{\\mathrm{sup}}$. Use thresholds $\\tau_h = 0.9$ (high accuracy), $\\tau_\\ell = 0.7$ (low accuracy), and drop threshold $\\Delta = 0.25$. Diagnose:\n- Overfitting to shortcuts if $a_{\\mathrm{vis}} \\ge \\tau_h$, $a_{\\mathrm{sup}} \\le \\tau_\\ell$, and $a_{\\mathrm{vis}} - a_{\\mathrm{sup}} \\ge \\Delta$.\n- Underfitting if $a_{\\mathrm{vis}} < \\tau_\\ell$ and $a_{\\mathrm{sup}} < \\tau_\\ell$.\n- Otherwise, neither underfitting nor overfitting.\n\nEncode the diagnosis as an integer: overfitting $\\to 1$, underfitting $\\to -1$, otherwise $\\to 0$.\n\nProgram requirements. Your program must:\n- Generate independent training and validation datasets for each test case using a fixed random seed per case to ensure reproducibility.\n- Implement training of the specified neural network using binary cross-entropy and stochastic gradient descent.\n- Evaluate $a_{\\mathrm{vis}}$ and $a_{\\mathrm{sup}}$ and apply the diagnosis rules above.\n- Produce a single line of output with the diagnosis results for all test cases as a comma-separated list enclosed in square brackets, e.g., $[1,0,-1,0]$.\n\nTest suite. Use the following test cases, each specified as a tuple $(p, q, m, \\alpha, \\sigma_r, \\sigma_s, H, E, \\eta, \\text{train\\_suppress}, \\text{seed})$ where $p$ and $q$ are feature dimensions, $m$ and $\\alpha$ are signal strengths, $\\sigma_r$ and $\\sigma_s$ are noise scales, $H$ is hidden layer width, $E$ is number of training epochs, $\\eta$ is learning rate, $\\text{train\\_suppress} \\in \\{0,1\\}$ indicates whether shortcut suppression is applied during training, and $\\text{seed}$ is the random seed. The dataset sizes must be fixed: training set size $n_{\\mathrm{train}} = 3000$ and validation set size $n_{\\mathrm{val}} = 3000$.\n\n- Case $1$ (expected overfitting): $(5, 3, 0.2, 4.0, 1.0, 1.0, 32, 50, 0.05, 0, 1337)$.\n- Case $2$ (expected robust generalization): $(5, 3, 0.6, 4.0, 1.0, 1.0, 32, 50, 0.05, 1, 2027)$.\n- Case $3$ (expected underfitting): $(5, 3, 0.6, 4.0, 1.0, 1.0, 2, 5, 0.01, 1, 3037)$.\n- Case $4$ (expected robust generalization even without suppression due to strong robust signal): $(5, 3, 1.5, 1.0, 1.0, 1.0, 32, 50, 0.05, 0, 4047)$.\n\nFinal output format. Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (e.g., $[r_1,r_2,r_3,r_4]$), where each $r_i \\in \\{-1,0,1\\}$ is the diagnosis for case $i$ according to the rules above. No other text should be printed.", "solution": "The problem requires the implementation of a computational experiment to diagnose overfitting and underfitting in a neural network trained on a synthetic dataset with two types of features: robust and shortcut. The solution involves four main stages: data generation, model implementation, training, and diagnosis.\n\n### 1. Data Generation\n\nFor each test case, a training set of size $n_{\\mathrm{train}} = 3000$ and a validation set of size $n_{\\mathrm{val}} = 3000$ are generated. Each data point $(x, y)$ consists of an input vector $x \\in \\mathbb{R}^{p+q}$ and a binary label $y \\in \\{0,1\\}$. The input vector $x$ is a concatenation of robust features $r \\in \\mathbb{R}^p$ and shortcut features $s \\in \\mathbb{R}^q$, i.e., $x = [r; s]$.\n\nThe labels $y$ are drawn from a Bernoulli distribution with parameter $0.5$. For mathematical convenience, the label is transformed to $y' = 2y - 1$, so $y' \\in \\{-1, +1\\}$. The features are then generated from multivariate normal distributions whose means depend on $y'$:\n-   Robust features: $r \\sim \\mathcal{N}\\left(m \\, y' \\, \\mathbf{1}_p, \\, \\sigma_r^2 I_p\\right)$\n-   Shortcut features: $s \\sim \\mathcal{N}\\left(\\alpha \\, y' \\, \\mathbf{1}_q, \\, \\sigma_s^2 I_q\\right)$\n\nHere, $m$ and $\\alpha$ control the signal strength of robust and shortcut features, respectively. $\\sigma_r^2$ and $\\sigma_s^2$ are their variances. This process is implemented using vectorized `numpy` operations for efficiency. A specific random seed is set for each test case to ensure reproducibility of the data and subsequent results.\n\n### 2. Model Architecture\n\nThe classifier is a one-hidden-layer neural network, $f_\\theta$. The input dimension is $d = p+q$. The architecture is defined as:\n$$\nh = \\phi(W_1 x + b_1)\n$$\n$$\n\\hat{y} = \\sigma(W_2^\\top h + b_2)\n$$\nwhere:\n-   $x \\in \\mathbb{R}^d$ is the input vector.\n-   $W_1 \\in \\mathbb{R}^{H \\times d}$ and $b_1 \\in \\mathbb{R}^{H}$ are the weight matrix and bias vector of the hidden layer, with $H$ being the number of hidden units.\n-   $\\phi(\\cdot)$ is the Rectified Linear Unit (ReLU) activation function, $\\phi(z) = \\max(0, z)$.\n-   $h \\in \\mathbb{R}^{H}$ is the hidden layer activation.\n-   $W_2 \\in \\mathbb{R}^{H}$ and $b_2 \\in \\mathbb{R}$ are the weight vector and scalar bias of the output layer.\n-   $\\sigma(\\cdot)$ is the logistic sigmoid function, $\\sigma(z) = (1 + e^{-z})^{-1}$, which maps the logit to a probability $\\hat{y} \\in [0,1]$.\n-   The parameters of the model are $\\theta = (W_1, b_1, W_2, b_2)$. Weights are initialized with small random values, and biases are initialized to zero.\n\n### 3. Training Procedure\n\nThe model is trained to minimize the empirical risk, which is the average binary cross-entropy loss over the training set $S = \\{(x_i, y_i)\\}_{i=1}^{n_{\\mathrm{train}}}$:\n$$\nR_S(f_\\theta) = \\frac{1}{n_{\\mathrm{train}}} \\sum_{i=1}^{n_{\\mathrm{train}}} \\ell(\\sigma(W_2^\\top \\phi(W_1 x_i + b_1) + b_2), y_i)\n$$\nOptimization is performed using mini-batch stochastic gradient descent (SGD). For each epoch, the training data is shuffled and split into mini-batches. For each mini-batch:\n1.  **Augmentation (Conditional)**: If the `train_suppress` flag is set to $1$, shortcut suppression is applied to the input batch. This involves replacing the shortcut features $s$ with noise drawn from $\\mathcal{N}(0, \\sigma_s^2 I_q)$, effectively forcing the model to rely on robust features.\n2.  **Forward Pass**: The mini-batch is passed through the network to compute the predicted probabilities $\\hat{y}$.\n3.  **Loss Calculation**: The binary cross-entropy loss is computed. A small epsilon term ($10^{-9}$) is added within the logarithm to ensure numerical stability.\n4.  **Backward Pass (Backpropagation)**: The gradients of the loss with respect to all parameters ($\\nabla_{W_1} R_S$, $\\nabla_{b_1} R_S$, $\\nabla_{W_2} R_S$, $\\nabla_{b_2} R_S$) are calculated using the chain rule. The derivative of the ReLU function is $1$ for positive inputs and $0$ otherwise.\n5.  **Parameter Update**: The model parameters are updated by taking a step in the negative gradient direction, scaled by the learning rate $\\eta$:\n    $$\n    \\theta \\leftarrow \\theta - \\eta \\nabla_\\theta R_S(f_\\theta)\n    $$\nThis process is repeated for a specified number of epochs $E$.\n\n### 4. Evaluation and Diagnosis\n\nAfter training, the model's performance is gauged on the validation set under two conditions:\n1.  **Visible Shortcuts ($a_{\\mathrm{vis}}$)**: The model's accuracy is calculated on the original validation set. The predicted label is $1$ if $\\hat{y} \\ge 0.5$ and $0$ otherwise.\n2.  **Suppressed Shortcuts ($a_{\\mathrm{sup}}$)**: A modified validation set is created by applying the shortcut suppression augmentation $A(x) = [r; \\tilde{s}]$ to every sample, where $\\tilde{s} \\sim \\mathcal{N}(0, \\sigma_s^2 I_q)$. The model's accuracy is then calculated on this suppressed dataset.\n\nThe final diagnosis is made based on a set of predefined rules using the thresholds $\\tau_h = 0.9$, $\\tau_\\ell = 0.7$, and $\\Delta = 0.25$:\n-   If $a_{\\mathrm{vis}} \\ge \\tau_h$ AND $a_{\\mathrm{sup}} \\le \\tau_\\ell$ AND $a_{\\mathrm{vis}} - a_{\\mathrm{sup}} \\ge \\Delta$, the model is diagnosed with **overfitting to shortcuts** (encoded as $1$). This indicates high reliance on shortcuts that are not robust.\n-   If $a_{\\mathrm{vis}} < \\tau_\\ell$ AND $a_{\\mathrm{sup}} < \\tau_\\ell$, the model is diagnosed with **underfitting** (encoded as $-1$). This suggests the model failed to learn meaningful patterns from either feature type.\n-   Otherwise, the model's behavior is classified as **neither** of the above, typically indicating robust generalization (encoded as $0$).\n\nThe program iterates through each test case, performs these steps, and collates the integer-encoded diagnoses into a final list.", "answer": "```python\nimport numpy as np\nfrom scipy.special import expit\n\nclass NeuralNetwork:\n    \"\"\"A one-hidden-layer neural network for binary classification.\"\"\"\n    def __init__(self, input_dim, hidden_dim):\n        \"\"\"\n        Initializes the parameters of the neural network.\n        \n        Args:\n            input_dim (int): Dimension of the input features (p+q).\n            hidden_dim (int): Number of units in the hidden layer (H).\n        \"\"\"\n        # Problem statement: W2 is a column vector, so W2.T is a row vector\n        self.W1 = np.random.randn(hidden_dim, input_dim) * 0.01\n        self.b1 = np.zeros((hidden_dim, 1))\n        self.W2 = np.random.randn(hidden_dim, 1) * 0.01\n        self.b2 = np.zeros((1, 1))\n        self.cache = {}\n\n    @staticmethod\n    def relu(z):\n        return np.maximum(0, z)\n\n    def forward(self, X):\n        \"\"\"\n        Performs the forward pass.\n        \n        Args:\n            X (np.ndarray): Input data of shape (input_dim, num_samples).\n        \n        Returns:\n            np.ndarray: Predicted probabilities of shape (1, num_samples).\n        \"\"\"\n        Z1 = self.W1 @ X + self.b1\n        A1 = self.relu(Z1)\n        Z2 = self.W2.T @ A1 + self.b2\n        A2 = expit(Z2) # Numerically stable sigmoid\n\n        self.cache = {'X': X, 'Z1': Z1, 'A1': A1, 'Z2': Z2, 'A2': A2}\n        return A2\n\n    def backward(self, Y):\n        \"\"\"\n        Performs the backward pass and computes gradients.\n        \n        Args:\n            Y (np.ndarray): True labels of shape (1, num_samples).\n        \"\"\"\n        num_samples = Y.shape[1]\n        X, A1, A2, Z1 = self.cache['X'], self.cache['A1'], self.cache['A2'], self.cache['Z1']\n\n        dZ2 = A2 - Y\n        self.dW2 = (1 / num_samples) * (A1 @ dZ2.T)\n        self.db2 = (1 / num_samples) * np.sum(dZ2, axis=1, keepdims=True)\n\n        dA1 = self.W2 @ dZ2\n        dZ1 = dA1 * (Z1 > 0)\n        self.dW1 = (1 / num_samples) * (dZ1 @ X.T)\n        self.db1 = (1 / num_samples) * np.sum(dZ1, axis=1, keepdims=True)\n\n    def update_params(self, learning_rate):\n        \"\"\"Updates parameters using computed gradients.\"\"\"\n        self.W1 -= learning_rate * self.dW1\n        self.b1 -= learning_rate * self.db1\n        self.W2 -= learning_rate * self.dW2\n        self.b2 -= learning_rate * self.db2\n\ndef generate_data(n_samples, p, q, m, alpha, sigma_r, sigma_s):\n    \"\"\"Generates synthetic data with robust and shortcut features.\"\"\"\n    y = np.random.randint(0, 2, size=(n_samples, 1))\n    y_prime = 2 * y - 1\n\n    # Generate robust features\n    mean_r_mat = y_prime @ np.ones((1, p)) * m\n    r = np.random.randn(n_samples, p) * sigma_r + mean_r_mat\n\n    # Generate shortcut features\n    mean_s_mat = y_prime @ np.ones((1, q)) * alpha\n    s = np.random.randn(n_samples, q) * sigma_s + mean_s_mat\n    \n    X = np.hstack((r, s))\n    return X, y\n\ndef apply_shortcut_suppression(X, q, sigma_s):\n    \"\"\"Applies shortcut suppression augmentation to data.\"\"\"\n    n_samples, _ = X.shape\n    p = X.shape[1] - q\n    r_features = X[:, :p]\n    noise = np.random.randn(n_samples, q) * sigma_s\n    return np.hstack((r_features, noise))\n\ndef solve():\n    \"\"\"Main function to run the test suite and produce the final output.\"\"\"\n    test_cases = [\n        (5, 3, 0.2, 4.0, 1.0, 1.0, 32, 50, 0.05, 0, 1337),\n        (5, 3, 0.6, 4.0, 1.0, 1.0, 32, 50, 0.05, 1, 2027),\n        (5, 3, 0.6, 4.0, 1.0, 1.0, 2, 5, 0.01, 1, 3037),\n        (5, 3, 1.5, 1.0, 1.0, 1.0, 32, 50, 0.05, 0, 4047),\n    ]\n\n    n_train = 3000\n    n_val = 3000\n    batch_size = 32\n    \n    tau_h = 0.9\n    tau_l = 0.7\n    delta = 0.25\n\n    results = []\n    \n    for case in test_cases:\n        p, q, m, alpha, sigma_r, sigma_s, H, E, eta, train_suppress, seed = case\n        \n        np.random.seed(seed)\n        \n        # 1. Generate Data\n        X_train, y_train = generate_data(n_train, p, q, m, alpha, sigma_r, sigma_s)\n        X_val, y_val = generate_data(n_val, p, q, m, alpha, sigma_r, sigma_s)\n\n        # 2. Initialize Model\n        input_dim = p + q\n        model = NeuralNetwork(input_dim, H)\n\n        # 3. Train Model\n        n_batches = int(np.ceil(n_train / batch_size))\n        for epoch in range(E):\n            permutation = np.random.permutation(n_train)\n            X_train_shuffled = X_train[permutation, :]\n            y_train_shuffled = y_train[permutation, :]\n\n            for i in range(n_batches):\n                start = i * batch_size\n                end = min(start + batch_size, n_train)\n                X_batch = X_train_shuffled[start:end, :]\n                y_batch = y_train_shuffled[start:end, :]\n                \n                # Apply shortcut suppression if required\n                if train_suppress == 1:\n                    X_batch = apply_shortcut_suppression(X_batch, q, sigma_s)\n                \n                # Transpose for model's expected shape (dim, samples)\n                X_batch_T = X_batch.T\n                y_batch_T = y_batch.T\n\n                # Forward, backward, update\n                _ = model.forward(X_batch_T)\n                model.backward(y_batch_T)\n                model.update_params(eta)\n\n        # 4. Evaluate Model\n        # a_vis: accuracy on validation set with shortcuts visible\n        y_hat_vis = model.forward(X_val.T)\n        predictions_vis = (y_hat_vis >= 0.5).astype(int)\n        a_vis = np.mean(predictions_vis == y_val.T)\n\n        # a_sup: accuracy on validation set with shortcuts suppressed\n        X_val_sup = apply_shortcut_suppression(X_val, q, sigma_s)\n        y_hat_sup = model.forward(X_val_sup.T)\n        predictions_sup = (y_hat_sup >= 0.5).astype(int)\n        a_sup = np.mean(predictions_sup == y_val.T)\n\n        # 5. Diagnose\n        diagnosis = 0 # Default: Neither\n        if a_vis >= tau_h and a_sup <= tau_l and (a_vis - a_sup) >= delta:\n            diagnosis = 1 # Overfitting to shortcuts\n        elif a_vis < tau_l and a_sup < tau_l:\n            diagnosis = -1 # Underfitting\n            \n        results.append(diagnosis)\n    \n    print(f\"[{','.join(map(str, results))}]\")\n\nif __name__ == '__main__':\n    solve()\n```", "id": "3135726"}]}