{"hands_on_practices": [{"introduction": "When we translate continuous governing equations into discrete algorithms for computation, our first responsibility is to ensure the numerical solution is meaningful and stable. This practice delves into the crucial concept of numerical stability for a reaction-diffusion equation, a model relevant in fields from chemical engineering to biology. By applying the foundational technique of von Neumann stability analysis, you will determine the precise conditions under which a numerical scheme remains reliable, preventing the simulation from yielding unphysical, exploding results [@problem_id:2398003]. Mastering this analysis builds essential intuition for the delicate balance between physical parameters, like diffusivity $D$, and numerical choices, such as the time step $\\Delta t$ and grid spacing $\\Delta x$.", "problem": "Consider the one-dimensional reaction-diffusion partial differential equation (PDE) $u_t = D\\,u_{xx} + u\\,(1 - u)$ on a periodic domain with constant diffusivity $D > 0$. Let $x_j = j\\,\\Delta x$ denote a uniform spatial grid and $t^n = n\\,\\Delta t$ a uniform temporal grid. The following fully explicit finite-difference scheme advances the nodal solution $u_j^n \\approx u(x_j,t^n)$ in time:\n$$\nu_j^{n+1} = u_j^n + \\Delta t\\left[ D\\,\\frac{u_{j+1}^n - 2 u_j^n + u_{j-1}^n}{\\Delta x^2} + u_j^n\\left(1 - u_j^n\\right) \\right].\n$$\nDetermine, from first principles, the largest time step $\\Delta t_{\\max}$ that guarantees linear stability of this scheme to infinitesimal perturbations about the homogeneous steady state $u \\equiv 1$ for all spatial wavenumbers supported by the periodic grid. Provide your answer as a single closed-form analytic expression in terms of $D$ and $\\Delta x$. Do not include units. No numerical rounding is required.", "solution": "The problem as stated is scientifically grounded, well-posed, objective, and contains sufficient information for a unique solution. It is a standard problem in the analysis of numerical methods for partial differential equations. We will therefore proceed with the solution.\n\nThe task is to determine the linear stability limit for the given fully explicit finite-difference scheme for the reaction-diffusion equation $u_t = D\\,u_{xx} + u\\,(1 - u)$. The analysis is to be performed for small perturbations around the homogeneous steady state $u(x,t) \\equiv 1$.\n\nFirst, we verify that $u \\equiv 1$ is indeed a steady-state solution. Substituting $u=1$ into the PDE yields $0 = D \\cdot 0 + 1 \\cdot (1 - 1)$, which simplifies to $0=0$. Thus, $u \\equiv 1$ is a valid steady state.\n\nNext, we linearize the finite-difference scheme around this steady state. Let the numerical solution at grid point $j$ and time step $n$ be represented as a sum of the steady state and a small perturbation $\\epsilon_j^n$:\n$$u_j^n = 1 + \\epsilon_j^n$$\nwhere it is assumed that $|\\epsilon_j^n| \\ll 1$. We substitute this into the given scheme:\n$$\nu_j^{n+1} = u_j^n + \\Delta t\\left[ D\\,\\frac{u_{j+1}^n - 2 u_j^n + u_{j-1}^n}{\\Delta x^2} + u_j^n\\left(1 - u_j^n\\right) \\right]\n$$\nSubstituting $u_j^n = 1 + \\epsilon_j^n$ into each term:\nThe left-hand side becomes:\n$$u_j^{n+1} = 1 + \\epsilon_j^{n+1}$$\nThe diffusion term on the right-hand side becomes:\n$$\nD\\,\\frac{(1+\\epsilon_{j+1}^n) - 2(1+\\epsilon_j^n) + (1+\\epsilon_{j-1}^n)}{\\Delta x^2} = D\\,\\frac{\\epsilon_{j+1}^n - 2\\epsilon_j^n + \\epsilon_{j-1}^n}{\\Delta x^2}\n$$\nThe reaction term on the right-hand side becomes:\n$$\nu_j^n(1 - u_j^n) = (1 + \\epsilon_j^n)(1 - (1 + \\epsilon_j^n)) = (1 + \\epsilon_j^n)(-\\epsilon_j^n) = -\\epsilon_j^n - (\\epsilon_j^n)^2\n$$\nAssembling the full equation with these substitutions:\n$$\n1 + \\epsilon_j^{n+1} = (1 + \\epsilon_j^n) + \\Delta t \\left[ D\\,\\frac{\\epsilon_{j+1}^n - 2\\epsilon_j^n + \\epsilon_{j-1}^n}{\\Delta x^2} - \\epsilon_j^n - (\\epsilon_j^n)^2 \\right]\n$$\nFor a linear stability analysis, we neglect terms of order $(\\epsilon_j^n)^2$ and higher. The constant terms $1$ on both sides cancel out. This leaves the linearized equation for the evolution of the perturbation $\\epsilon_j^n$:\n$$\n\\epsilon_j^{n+1} = \\epsilon_j^n + \\Delta t \\left[ D\\,\\frac{\\epsilon_{j+1}^n - 2\\epsilon_j^n + \\epsilon_{j-1}^n}{\\Delta x^2} - \\epsilon_j^n \\right]\n$$\nWe now apply von Neumann stability analysis to this linear equation. We consider a single Fourier mode of the perturbation on the periodic grid, of the form:\n$$\n\\epsilon_j^n = A(k)^n e^{i k x_j} = A(k)^n e^{i k j \\Delta x}\n$$\nwhere $k$ is the spatial wavenumber, $A(k)^n$ is the amplitude of the mode at time step $n$, and $i = \\sqrt{-1}$. The stability of the scheme depends on the amplification factor $G(k) = A(k)^{n+1} / A(k)^n$. For the scheme to be stable, the magnitude of this factor must not exceed unity for any wavenumber $k$, i.e., $|G(k)| \\le 1$.\n\nSubstituting the Fourier mode into the linearized equation yields:\n$$\nA(k)^{n+1} e^{i k j \\Delta x} = A(k)^n e^{i k j \\Delta x} + \\Delta t \\left[ D\\,\\frac{A(k)^n e^{i k (j+1) \\Delta x} - 2A(k)^n e^{i k j \\Delta x} + A(k)^n e^{i k (j-1) \\Delta x}}{\\Delta x^2} - A(k)^n e^{i k j \\Delta x} \\right]\n$$\nDividing the entire equation by $A(k)^n e^{i k j \\Delta x}$ gives the expression for the amplification factor $G(k)$:\n$$\nG(k) = 1 + \\Delta t \\left[ D\\,\\frac{e^{i k \\Delta x} - 2 + e^{-i k \\Delta x}}{\\Delta x^2} - 1 \\right]\n$$\nUsing the identity $e^{i\\theta} + e^{-i\\theta} = 2\\cos(\\theta)$, we simplify the numerator of the diffusion term:\n$$\ne^{i k \\Delta x} - 2 + e^{-i k \\Delta x} = 2\\cos(k \\Delta x) - 2\n$$\nUsing the half-angle trigonometric identity $1 - \\cos(\\theta) = 2\\sin^2(\\theta/2)$, we can write:\n$$\n2\\cos(k \\Delta x) - 2 = -2(1 - \\cos(k \\Delta x)) = -4\\sin^2\\left(\\frac{k \\Delta x}{2}\\right)\n$$\nSubstituting this back into the expression for $G(k)$:\n$$\nG(k) = 1 + \\Delta t \\left[ D\\,\\frac{-4\\sin^2\\left(\\frac{k \\Delta x}{2}\\right)}{\\Delta x^2} - 1 \\right] = 1 - \\Delta t \\left[ \\frac{4D}{\\Delta x^2}\\sin^2\\left(\\frac{k \\Delta x}{2}\\right) + 1 \\right]\n$$\nThe amplification factor $G(k)$ is a real number. The stability condition $|G(k)| \\le 1$ is thus equivalent to $-1 \\le G(k) \\le 1$.\n\nThe term in the square brackets is a sum of non-negative terms, since $D>0$, $\\Delta x^2 > 0$, and $\\sin^2(\\cdot) \\ge 0$. As $\\Delta t > 0$, the entire term being subtracted from $1$ is positive. Therefore, $G(k) \\le 1$ is always satisfied.\n\nThe stability is thus governed by the lower bound, $G(k) \\ge -1$:\n$$\n1 - \\Delta t \\left[ \\frac{4D}{\\Delta x^2}\\sin^2\\left(\\frac{k \\Delta x}{2}\\right) + 1 \\right] \\ge -1\n$$\n$$\n2 \\ge \\Delta t \\left[ \\frac{4D}{\\Delta x^2}\\sin^2\\left(\\frac{k \\Delta x}{2}\\right) + 1 \\right]\n$$\nRearranging to find the constraint on $\\Delta t$:\n$$\n\\Delta t \\le \\frac{2}{\\frac{4D}{\\Delta x^2}\\sin^2\\left(\\frac{k \\Delta x}{2}\\right) + 1}\n$$\nThis inequality must hold for all spatial wavenumbers $k$ supported by the grid. To find the most restrictive condition on $\\Delta t$, we must find the value of $k$ that minimizes the right-hand side of the inequality. This is equivalent to finding the $k$ that maximizes the denominator. The denominator is maximized when the term $\\sin^2\\left(\\frac{k \\Delta x}{2}\\right)$ reaches its maximum value.\n\nThe maximum value of $\\sin^2(\\theta)$ is $1$. This occurs for the highest frequency modes supported by the grid, where $\\frac{k \\Delta x}{2} = \\frac{\\pi}{2}$, corresponding to the Nyquist wavenumber where $k \\Delta x = \\pi$. These are the most unstable modes for this type of explicit scheme.\n\nSubstituting $\\sin^2\\left(\\frac{k \\Delta x}{2}\\right) = 1$ into the inequality gives the most restrictive condition for $\\Delta t$:\n$$\n\\Delta t \\le \\frac{2}{\\frac{4D}{\\Delta x^2}(1) + 1}\n$$\nThe largest time step $\\Delta t_{\\max}$ that guarantees stability for all wavenumbers is therefore the upper bound of this inequality.\n$$\n\\Delta t_{\\max} = \\frac{2}{\\frac{4D}{\\Delta x^2} + 1}\n$$\nTo present this in the required closed form, we simplify the expression:\n$$\n\\Delta t_{\\max} = \\frac{2}{\\frac{4D + \\Delta x^2}{\\Delta x^2}} = \\frac{2 \\Delta x^2}{4D + \\Delta x^2}\n$$\nThis is the final analytical expression for the maximum permissible time step.", "answer": "$$\\boxed{\\frac{2 \\Delta x^2}{4D + \\Delta x^2}}$$", "id": "2398003"}, {"introduction": "Beyond basic stability, a high-quality numerical model should also respect the fundamental conservation laws inherent in the physical system it describes, especially over long simulation times. This exercise highlights the critical difference between generic and structure-preserving algorithms by comparing a standard non-symplectic integrator with a symplectic one for a Hamiltonian system where energy is conserved. You will implement a numerical diagnostic to computationally verify that while many stable methods introduce artificial energy drift over time, specialized symplectic integrators maintain bounded energy error, faithfully reproducing the system's long-term behavior. This practice demonstrates why choosing an algorithm that mirrors the problem's underlying geometric structure is paramount in fields like celestial mechanics and molecular dynamics [@problem_id:2398024].", "problem": "You are to design and implement a numerical diagnostic for long-time energy behavior of an integrator intended for Hamiltonian dynamics, using only first principles. Consider the single-degree-of-freedom Hamiltonian system with generalized coordinate $q$ and conjugate momentum $p$ governed by the Hamiltonian\n$$\nH(q,p) \\;=\\; \\frac{p^2}{2 m} \\;+\\; \\frac{k}{2}\\,q^2 \\;+\\; \\frac{\\lambda}{4}\\,q^4,\n$$\nwhere $m$, $k$, and $\\lambda$ are positive parameters. The continuous dynamics are specified by Hamilton’s equations\n$$\n\\dot{q} \\;=\\; \\frac{\\partial H}{\\partial p}, \n\\qquad\n\\dot{p} \\;=\\; -\\frac{\\partial H}{\\partial q}.\n$$\nIn dimensionless units, take $m = 1$, $k = 1$, and $\\lambda = 1$. Use the initial condition $q(0) = 0.7$ and $p(0) = 0$.\n\nFrom first principles, energy is a first integral of the motion. Denote the initial energy by $H_0 = H(q(0),p(0))$. For a discrete-time numerical trajectory $\\{(q_n,p_n)\\}_{n=0}^{N}$ produced by time steps of size $h$ over total time $T = N h$, define the following quantitative energy-diagnostics:\n- The maximum relative energy deviation\n$$\n\\Delta_{\\max} \\;=\\; \\max_{0 \\le n \\le N} \\frac{\\left| H(q_n,p_n) - H_0 \\right|}{\\left| H_0 \\right|}.\n$$\n- The normalized linear drift magnitude, obtained by fitting the discrete energy values $\\{H(q_n,p_n)\\}$ as a function of times $\\{t_n\\}$, where $t_n = n h$, to an affine model $H(t) \\approx a + b t$ by least squares, and then defining\n$$\nD \\;=\\; \\frac{|b|}{|H_0|}.\n$$\n\nDeclare that an integrator “conserves energy over long time scales” for this system if both criteria\n$$\n\\Delta_{\\max} \\le \\varepsilon_{\\max}\n\\quad\\text{and}\\quad\nD \\le \\varepsilon_{\\text{drift}}\n$$\nare satisfied, with thresholds $\\varepsilon_{\\max} = 0.05$ and $\\varepsilon_{\\text{drift}} = 5\\times 10^{-5}$.\n\nImplement a program that, given a method class flag $M \\in \\{0,1\\}$, a time step $h$, and a final time $T$, does the following:\n- If $M = 1$, advance the dynamics using any consistent symplectic time integrator appropriate for separable Hamiltonians of the form $H(q,p) = T(p) + V(q)$.\n- If $M = 0$, advance the dynamics using any consistent explicit non-symplectic one-step method for the same ordinary differential equation (ODE) system.\n- In both cases, compute the numerical trajectory, evaluate $H(q_n,p_n)$ at each time level, compute $\\Delta_{\\max}$ and $D$, and return a boolean that is $\\,\\text{True}\\,$ if and only if both criteria above are satisfied, and $\\,\\text{False}\\,$ otherwise.\n\nTest Suite. Your program must run the following five parameter sets and aggregate the five booleans in the specified output format. Use the same initial condition $q(0) = 0.7$, $p(0) = 0$, and parameters $m = 1$, $k = 1$, $\\lambda = 1$ in all cases, with the final time $T = 4000$:\n- Case $1$: $(M,h,T) = (1,\\,0.02,\\,4000)$.\n- Case $2$: $(M,h,T) = (1,\\,0.05,\\,4000)$.\n- Case $3$: $(M,h,T) = (1,\\,0.10,\\,4000)$.\n- Case $4$: $(M,h,T) = (0,\\,0.02,\\,4000)$.\n- Case $5$: $(M,h,T) = (0,\\,0.05,\\,4000)$.\n\nFinal Output Format. Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (e.g., [True,False,True,False,True]). There are no physical units in this problem because all quantities are non-dimensional by construction. Angles do not appear, so no angle unit is required. All answers must be booleans. The final output must be exactly one line.", "solution": "The problem requires the design and implementation of a numerical diagnostic for evaluating the long-time energy conservation of numerical integrators for a specific Hamiltonian system. This first requires a critical validation of the problem statement.\n\nThe problem is scientifically grounded, well-posed, and objective. It concerns the numerical integration of Hamilton's equations for a single-degree-of-freedom system with Hamiltonian $H(q,p) = \\frac{p^2}{2m} + \\frac{k}{2}q^2 + \\frac{\\lambda}{4}q^4$. The governing equations, $\\dot{q} = \\partial H / \\partial p$ and $\\dot{p} = - \\partial H / \\partial q$, are fundamental principles of classical mechanics. The parameters $m=1$, $k=1$, $\\lambda=1$ and initial conditions $q(0)=0.7$, $p(0)=0$ are specified, making the problem self-contained. The diagnostics, $\\Delta_{\\max}$ and $D$, are standard quantitative measures for energy error and drift. The criteria for \"energy conservation\" are explicitly defined with numerical thresholds $\\varepsilon_{\\max}=0.05$ and $\\varepsilon_{\\text{drift}}=5 \\times 10^{-5}$. The task is to implement a program that applies these diagnostics to trajectories generated by two classes of integrators: a symplectic method ($M=1$) and a non-symplectic method ($M=0$). The problem is a valid and classic exercise in computational physics.\n\nWe proceed with the solution. The system under consideration is specified by the Hamiltonian with dimensionless parameters $m=1$, $k=1$, and $\\lambda=1$:\n$$\nH(q,p) = \\frac{p^2}{2} + \\frac{q^2}{2} + \\frac{q^4}{4}.\n$$\nThe corresponding Hamilton's equations of motion are:\n$$\n\\dot{q} = \\frac{\\partial H}{\\partial p} = p,\n$$\n$$\n\\dot{p} = -\\frac{\\partial H}{\\partial q} = -(q + q^3).\n$$\nThis system constitutes a set of two coupled first-order ordinary differential equations (ODEs). For any initial condition $(q_0, p_0)$, the exact solution trajectory $(q(t), p(t))$ conserves energy, meaning $H(q(t),p(t))$ is constant for all time $t$. The initial energy is $H_0 = H(q(0), p(0)) = H(0.7, 0) = \\frac{0^2}{2} + \\frac{0.7^2}{2} + \\frac{0.7^4}{4} = 0.305025$.\n\nNumerical integrators approximate the continuous-time solution with a discrete-time sequence $(q_n, p_n)$ at times $t_n = n h$. The key distinction for this problem lies in the geometric properties of the integrators.\n\nFor the case $M=1$, a symplectic integrator is required. These integrators are specifically designed for Hamiltonian systems and exactly preserve the symplectic $2$-form, a fundamental geometric property of Hamiltonian flow. While they do not exactly conserve the original Hamiltonian $H$, they do exactly conserve a nearby \"shadow\" Hamiltonian $H_h = H + O(h^p)$, where $p$ is the order of the method. This implies that the energy error $|H(q_n,p_n) - H_0|$ remains bounded over exponentially long times, exhibiting no secular drift. A standard choice for a separable Hamiltonian of the form $H=T(p)+V(q)$ is the second-order Störmer-Verlet (or leapfrog) method. We choose the velocity-Verlet variant, which for our system takes the form:\n$$\np_{n+1/2} = p_n + \\frac{h}{2} F(q_n)\n$$\n$$\nq_{n+1} = q_n + h \\, p_{n+1/2}\n$$\n$$\np_{n+1} = p_{n+1/2} + \\frac{h}{2} F(q_{n+1})\n$$\nwhere the force is $F(q) = -\\frac{dV}{dq} = -(q + q^3)$.\n\nFor the case $M=0$, a consistent explicit non-symplectic one-step method is required. Standard ODE solvers like the Runge-Kutta family fall into this category. While often highly accurate for general-purpose problems, they do not preserve the symplectic structure. When applied to Hamiltonian systems, they typically introduce a systematic energy drift, where the numerical energy $H(q_n, p_n)$ secularly increases or decreases over time. We select the classical fourth-order Runge-Kutta method (RK4), a widely used and highly accurate member of this class. For a system $\\dot{\\mathbf{y}} = \\mathbf{f}(\\mathbf{y})$ with $\\mathbf{y}=[q, p]^T$, the update rule is:\n$$\n\\mathbf{y}_{n+1} = \\mathbf{y}_n + \\frac{h}{6}(\\mathbf{k}_1 + 2\\mathbf{k}_2 + 2\\mathbf{k}_3 + \\mathbf{k}_4)\n$$\nwhere\n$$\n\\mathbf{k}_1 = \\mathbf{f}(\\mathbf{y}_n), \\quad \\mathbf{k}_2 = \\mathbf{f}(\\mathbf{y}_n + \\frac{h}{2}\\mathbf{k}_1), \\quad \\mathbf{k}_3 = \\mathbf{f}(\\mathbf{y}_n + \\frac{h}{2}\\mathbf{k}_2), \\quad \\mathbf{k}_4 = \\mathbf{f}(\\mathbf{y}_n + h\\mathbf{k}_3).\n$$\nHere, $\\mathbf{f}(q, p) = [p, -(q+q^3)]^T$.\n\nThe core of the program involves generating a numerical trajectory $\\{(q_n,p_n)\\}_{n=0}^N$ for a given method type $M$, step size $h$, and final time $T=Nh$. Following the generation of the trajectory, the two specified diagnostics are computed.\n\n$1$. The maximum relative energy deviation, $\\Delta_{\\max}$, is computed as:\n$$\n\\Delta_{\\max} = \\frac{\\max_{0 \\le n \\le N} |H(q_n, p_n) - H_0|}{|H_0|}.\n$$\nThis measures the largest fluctuation of energy from its initial value.\n\n$2$. The normalized linear drift magnitude, $D$, is computed. This requires fitting the time series of energy values $\\{H_n = H(q_n,p_n)\\}$ versus time $\\{t_n = nh\\}$ to a linear model $H(t) \\approx a + bt$ using the method of least squares. The slope $b$ quantifies the average rate of energy change over the entire integration. The formula for the slope $b$ in a simple linear regression over $N+1$ data points $(t_n, H_n)$ is:\n$$\nb = \\frac{(N+1) \\sum_{n=0}^N (t_n H_n) - (\\sum_{n=0}^N t_n)(\\sum_{n=0}^N H_n)}{(N+1) \\sum_{n=0}^N t_n^2 - (\\sum_{n=0}^N t_n)^2}.\n$$\nThis value is readily obtained using standard numerical library functions. The diagnostic $D$ is then defined as:\n$$\nD = \\frac{|b|}{|H_0|}.\n$$\nThis quantity is designed specifically to detect secular drift, which is characteristic of non-symplectic integrators.\n\nFinally, the implemented program evaluates for each test case whether both conditions $\\Delta_{\\max} \\le \\varepsilon_{\\max}$ and $D \\le \\varepsilon_{\\text{drift}}$ are met, returning a single boolean result. The results for the $5$ specified test cases are aggregated into a list.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to run the test suite and print the results.\n    \"\"\"\n    # System parameters and thresholds are fixed as per the problem statement.\n    # m = 1, k = 1, lambda = 1.\n    # q(0) = 0.7, p(0) = 0.\n    # eps_max = 0.05, eps_drift = 5e-5.\n\n    test_cases = [\n        (1, 0.02, 4000),  # Case 1: Symplectic, h=0.02\n        (1, 0.05, 4000),  # Case 2: Symplectic, h=0.05\n        (1, 0.10, 4000),  # Case 3: Symplectic, h=0.10\n        (0, 0.02, 4000),  # Case 4: Non-symplectic, h=0.02\n        (0, 0.05, 4000),  # Case 5: Non-symplectic, h=0.05\n    ]\n\n    results = []\n    for case in test_cases:\n        M, h, T = case\n        result = run_and_diagnose(M, h, T)\n        results.append(result)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\ndef H(q, p, m, k, lambda_):\n    \"\"\"\n    Computes the Hamiltonian H(q,p).\n    \"\"\"\n    return p**2 / (2 * m) + k/2 * q**2 + lambda_/4 * q**4\n\ndef run_and_diagnose(M, h, T):\n    \"\"\"\n    Runs a single simulation and computes the energy diagnostics.\n\n    Args:\n        M (int): Method flag (1 for symplectic, 0 for non-symplectic).\n        h (float): Time step size.\n        T (float): Total integration time.\n\n    Returns:\n        bool: True if energy conservation criteria are met, False otherwise.\n    \"\"\"\n    # Parameters and initial conditions\n    m, k, lambda_ = 1.0, 1.0, 1.0\n    q0, p0 = 0.7, 0.0\n    eps_max = 0.05\n    eps_drift = 5e-5\n\n    N = int(T / h)\n    q_traj = np.zeros(N + 1)\n    p_traj = np.zeros(N + 1)\n    q_traj[0], p_traj[0] = q0, p0\n\n    # Perform the time integration\n    if M == 1:\n        # Symplectic integrator: Velocity-Verlet (Störmer-Verlet)\n        for n in range(N):\n            q, p = q_traj[n], p_traj[n]\n            force = -(k * q + lambda_ * q**3)\n            p_half = p + 0.5 * h * force\n            q_next = q + h * (p_half / m)\n            force_next = -(k * q_next + lambda_ * q_next**3)\n            p_next = p_half + 0.5 * h * force_next\n            q_traj[n+1], p_traj[n+1] = q_next, p_next\n    elif M == 0:\n        # Non-symplectic integrator: Classical Runge-Kutta 4th order (RK4)\n        def f(y_vec):\n            q, p = y_vec\n            return np.array([p / m, -(k * q + lambda_ * q**3)])\n        \n        y = np.array([q0, p0])\n        for n in range(N):\n            k1 = f(y)\n            k2 = f(y + 0.5 * h * k1)\n            k3 = f(y + 0.5 * h * k2)\n            k4 = f(y + h * k3)\n            y = y + (h / 6.0) * (k1 + 2*k2 + 2*k3 + k4)\n            q_traj[n+1], p_traj[n+1] = y\n\n    # Compute diagnostics\n    H_traj = H(q_traj, p_traj, m, k, lambda_)\n    H0 = H_traj[0]\n\n    # This problem's initial conditions ensure H0 is not zero\n    # delta_max calculation\n    delta_max = np.max(np.abs(H_traj - H0)) / np.abs(H0)\n\n    # D (drift) calculation\n    t_vals = np.linspace(0, T, N + 1)\n    # Fit H(t) = b*t + a, np.polyfit returns [b, a]\n    b, _ = np.polyfit(t_vals, H_traj, 1)\n    D = np.abs(b) / np.abs(H0)\n\n    # Check criteria\n    return delta_max <= eps_max and D <= eps_drift\n\nsolve()\n```", "id": "2398024"}, {"introduction": "Computational modeling is not only for predicting the future from known conditions (a forward problem) but is also an indispensable tool for inferring unknown causes from observed effects. This hands-on practice introduces you to the powerful domain of inverse problems, where you will reconstruct an unknown initial temperature distribution in a metal bar using only sparse temperature measurements taken at its midpoint. You will leverage the analytical solution of the heat equation to formulate a linear inverse problem and directly confront its characteristic ill-posedness, where small measurement noise can lead to large, unphysical errors in the solution. By implementing Tikhonov regularization, you will gain practical skills in a standard method for obtaining stable and meaningful results from limited data, a technique with wide applications in medical imaging, system identification, and non-destructive evaluation [@problem_id:2398006].", "problem": "You are given a one-dimensional heat conduction inverse problem consistent with conservation of energy and Fourier’s law of heat conduction. A homogeneous metal bar of length $L$ is held at zero temperature at both ends for all time, and it evolves thermally according to the one-dimensional heat equation. The governing Partial Differential Equation (PDE) is\n$$\n\\frac{\\partial T}{\\partial t}(x,t) = \\alpha \\frac{\\partial^2 T}{\\partial x^2}(x,t), \\quad 0 < x < L,\\ t > 0,\n$$\nwith boundary conditions\n$$\nT(0,t)=0,\\quad T(L,t)=0,\\quad t>0,\n$$\nand an unknown initial temperature distribution\n$$\nT(x,0) = T_0(x), \\quad 0 < x < L.\n$$\nHere, $T$ is temperature in $\\mathrm{K}$, $x$ is position in $\\mathrm{m}$, $t$ is time in $\\mathrm{s}$, and $\\alpha$ is thermal diffusivity in $\\mathrm{m^2/s}$. Only the temperature time history at the midpoint is measured:\n$$\ny(t_i) = T(L/2, t_i), \\quad i=1,\\dots,m.\n$$\nAssume the bar is homogeneous with constant $\\alpha$ and there are no internal heat sources. You must reconstruct an approximation of the initial temperature $T_0(x)$ by assuming it lies in the span of the first $M$ odd sine eigenfunctions that satisfy the boundary conditions:\n$$\nT_0(x) \\approx \\sum_{k=0}^{M-1} b_{2k+1} \\sin\\!\\left(\\frac{(2k+1)\\pi x}{L}\\right),\n$$\nwhere the unknown coefficients $b_{2k+1}$ (in $\\mathrm{K}$) are to be identified from the midpoint measurements $y(t_i)$. Use a principled method derived from the governing equation and boundary conditions to express $y(t)$ in terms of the unknown coefficients and known parameters, and then pose and solve a linear inverse problem to estimate $b_{2k+1}$. Because this inverse problem is ill-posed, use linear least squares with Tikhonov regularization if needed:\n$$\n\\min_{\\mathbf{b}} \\ \\|A\\mathbf{b} - \\mathbf{y}\\|_2^2 + \\lambda_{\\mathrm{reg}}^2 \\|\\mathbf{b}\\|_2^2,\n$$\nwhere $A$ is the design matrix derived from the physics, $\\mathbf{b}$ is the vector of unknown coefficients $[b_1,b_3,\\dots,b_{2M-1}]^\\top$, $\\mathbf{y}$ collects the measurements, and $\\lambda_{\\mathrm{reg}} \\ge 0$ is the regularization parameter.\n\nImplement a complete and runnable program that, for the test suite below, reconstructs the vector of odd sine coefficients for each case. Express each coefficient in $\\mathrm{K}$ and round to three decimals. Angles in any trigonometric evaluation must be interpreted in radians.\n\nTest Suite (each case provides $L$ in $\\mathrm{m}$, $\\alpha$ in $\\mathrm{m^2/s}$, a time grid in $\\mathrm{s}$, measured midpoint temperatures in $\\mathrm{K}$, the number of odd modes $M$, and the regularization parameter $\\lambda_{\\mathrm{reg}}$):\n- Case A (happy path, single mode, noise-free):\n  - $L = 1.0\\ \\mathrm{m}$, $\\alpha = 1.0\\times 10^{-4}\\ \\mathrm{m^2/s}$,\n  - times $t = [0, 100, 300, 500]\\ \\mathrm{s}$,\n  - measured $y = [10.00000, 9.06018, 7.43722, 6.10497]\\ \\mathrm{K}$,\n  - $M=1$,\n  - $\\lambda_{\\mathrm{reg}} = 0.0$.\n- Case B (two identifiable modes, noise-free):\n  - $L = 1.0\\ \\mathrm{m}$, $\\alpha = 1.0\\times 10^{-4}\\ \\mathrm{m^2/s}$,\n  - times $t = [0, 50, 200, 500]\\ \\mathrm{s}$,\n  - measured $y = [6.00000, 7.57583, 8.83511, 7.25528]\\ \\mathrm{K}$,\n  - $M=2$,\n  - $\\lambda_{\\mathrm{reg}} = 0.0$.\n- Case C (three modes, noisy data, different bar properties):\n  - $L = 0.8\\ \\mathrm{m}$, $\\alpha = 7.0\\times 10^{-5}\\ \\mathrm{m^2/s}$,\n  - times $t = [0, 40, 120, 240, 400]\\ \\mathrm{s}$,\n  - measured $y = [4.01230, 3.42575, 3.55080, 3.55920, 3.19240]\\ \\mathrm{K}$,\n  - $M=3$,\n  - $\\lambda_{\\mathrm{reg}} = 1.0\\times 10^{-3}$.\n- Case D (edge case: non-observable even modes, zero signal):\n  - $L = 1.0\\ \\mathrm{m}$, $\\alpha = 1.0\\times 10^{-4}\\ \\mathrm{m^2/s}$,\n  - times $t = [0, 10, 20, 50, 100]\\ \\mathrm{s}$,\n  - measured $y = [0.0, 0.0, 0.0, 0.0, 0.0]\\ \\mathrm{K}$,\n  - $M=3$,\n  - $\\lambda_{\\mathrm{reg}} = 0.0$.\n\nFinal Output Format:\nYour program should produce a single line of output containing a list of results for all cases, where each case’s result is a list of the reconstructed odd coefficients $[b_1,b_3,\\dots,b_{2M-1}]$ in $\\mathrm{K}$, each rounded to three decimals. For example,\n$[[b_{1}^{(A)},b_{3}^{(A)},\\dots],[b_{1}^{(B)},b_{3}^{(B)},\\dots],\\dots]$,\nwith inner lists truncated to length $M$ for each case. The program must print exactly one line in this format.", "solution": "The problem presented is a valid inverse problem in heat conduction. It is scientifically grounded in the principles of Fourier's law and conservation of energy, which are encapsulated in the one-dimensional heat equation. The problem is well-posed for numerical solution, as it specifies a standard regularization technique to handle the inherent ill-posedness of the inverse problem. All necessary parameters and data are provided, and the objective is clearly defined without ambiguity.\n\nThe task is to reconstruct the initial temperature distribution, $T_0(x)$, of a homogeneous bar of length $L$. The temperature evolution is governed by the partial differential equation (PDE):\n$$\n\\frac{\\partial T}{\\partial t}(x,t) = \\alpha \\frac{\\partial^2 T}{\\partial x^2}(x,t), \\quad \\text{for } x \\in (0, L) \\text{ and } t > 0\n$$\nwith homogeneous Dirichlet boundary conditions:\n$$\nT(0,t) = 0, \\quad T(L,t) = 0, \\quad \\text{for } t > 0\n$$\nThe general solution to this boundary value problem can be found using the method of separation of variables. It is expressed as a Fourier sine series:\n$$\nT(x,t) = \\sum_{n=1}^{\\infty} c_n \\sin\\left(\\frac{n\\pi x}{L}\\right) e^{-\\alpha \\left(\\frac{n\\pi}{L}\\right)^2 t}\n$$\nThe coefficients $c_n$ are determined by the initial condition $T(x,0) = T_0(x)$, for which the series becomes:\n$$\nT_0(x) = \\sum_{n=1}^{\\infty} c_n \\sin\\left(\\frac{n\\pi x}{L}\\right)\n$$\nThe problem states that $T_0(x)$ is to be approximated by a finite sum of the first $M$ odd sine eigenfunctions:\n$$\nT_0(x) \\approx \\sum_{k=0}^{M-1} b_{2k+1} \\sin\\left(\\frac{(2k+1)\\pi x}{L}\\right)\n$$\nBy comparing this approximation with the general form of the initial condition, we identify the Fourier coefficients $c_n$ with the unknown coefficients $b_{2k+1}$. Specifically, we assume $c_{2k+1} = b_{2k+1}$ for $k \\in \\{0, 1, \\dots, M-1\\}$ and that all other coefficients, including all even-indexed coefficients $c_{2k}$, are zero. This is a reasonable assumption because any even mode, $\\sin(\\frac{2k\\pi x}{L})$, is zero at the midpoint $x=L/2$, and thus these modes are not observable from midpoint measurements.\n\nSubstituting this approximation back into the time-dependent solution for $T(x,t)$, we obtain:\n$$\nT(x,t) \\approx \\sum_{k=0}^{M-1} b_{2k+1} \\sin\\left(\\frac{(2k+1)\\pi x}{L}\\right) e^{-\\alpha \\left(\\frac{(2k+1)\\pi}{L}\\right)^2 t}\n$$\nThe available data consists of temperature measurements, $y(t_i)$, at the midpoint of the bar, $x = L/2$, at discrete times $t_i$ for $i \\in \\{1, \\dots, m\\}$. Evaluating our approximate solution at $x=L/2$ yields:\n$$\ny(t_i) = T(L/2, t_i) \\approx \\sum_{k=0}^{M-1} b_{2k+1} \\sin\\left(\\frac{(2k+1)\\pi (L/2)}{L}\\right) e^{-\\alpha \\left(\\frac{(2k+1)\\pi}{L}\\right)^2 t_i}\n$$\nThe sine term simplifies as:\n$$\n\\sin\\left(\\frac{(2k+1)\\pi}{2}\\right) = (-1)^k\n$$\nThis gives a direct relationship between the measurements $y(t_i)$ and the unknown coefficients $b_{2k+1}$:\n$$\ny(t_i) \\approx \\sum_{k=0}^{M-1} (-1)^k b_{2k+1} e^{-\\alpha \\left(\\frac{(2k+1)\\pi}{L}\\right)^2 t_i}\n$$\nThis constitutes a system of $m$ linear equations in the $M$ unknown coefficients. Let the vector of coefficients be $\\mathbf{b} = [b_1, b_3, \\dots, b_{2M-1}]^\\top$ and the vector of measurements be $\\mathbf{y} = [y(t_1), y(t_2), \\dots, y(t_m)]^\\top$. The system can be written in matrix form as $A\\mathbf{b} \\approx \\mathbf{y}$. The design matrix $A$ is an $m \\times M$ matrix, where the element $A_{ij}$ (for the $i$-th time point and the $j$-th mode, with $j=k+1$) is the multiplier of the coefficient $b_{2j-1}$:\n$$\nA_{ij} = (-1)^{j-1} e^{-\\alpha \\left(\\frac{(2j-1)\\pi}{L}\\right)^2 t_i}\n$$\nwhere $i \\in \\{1, \\dots, m\\}$ and $j \\in \\{1, \\dots, M\\}$.\n\nTo find the vector of coefficients $\\mathbf{b}$, we must solve this linear system. As stated, this inverse problem is typically ill-posed, meaning small errors in the measurement vector $\\mathbf{y}$ can lead to large changes in the solution $\\mathbf{b}$. Tikhonov regularization is employed to stabilize the solution by adding a penalty term proportional to the squared Euclidean norm of the solution vector. The problem is thus to find the $\\mathbf{b}$ that minimizes the following objective function:\n$$\n\\min_{\\mathbf{b}} \\|A\\mathbf{b} - \\mathbf{y}\\|_2^2 + \\lambda_{\\mathrm{reg}}^2 \\|\\mathbf{b}\\|_2^2\n$$\nwhere $\\lambda_{\\mathrm{reg}} \\ge 0$ is the regularization parameter. The solution to this regularized least squares problem is given by the normal equations:\n$$\n(A^\\top A + \\lambda_{\\mathrm{reg}}^2 I) \\mathbf{b} = A^\\top \\mathbf{y}\n$$\nwhere $I$ is the $M \\times M$ identity matrix. For numerical stability, it is preferable to avoid direct computation of $A^\\top A$. A more stable method is to solve an equivalent standard least squares problem on an augmented system. We define an augmented matrix $\\tilde{A}$ and an augmented measurement vector $\\tilde{\\mathbf{y}}$:\n$$\n\\tilde{A} = \\begin{pmatrix} A \\\\ \\lambda_{\\mathrm{reg}} I \\end{pmatrix}, \\quad \\tilde{\\mathbf{y}} = \\begin{pmatrix} \\mathbf{y} \\\\ \\mathbf{0} \\end{pmatrix}\n$$\nwhere $\\mathbf{0}$ is a zero vector of length $M$. The original minimization problem is equivalent to minimizing $\\|\\tilde{A}\\mathbf{b} - \\tilde{\\mathbf{y}}\\|_2^2$. This is a standard linear least squares problem that can be robustly solved using numerical libraries. This single framework correctly handles both the regularized case ($\\lambda_{\\mathrm{reg}} > 0$) and the non-regularized case ($\\lambda_{\\mathrm{reg}} = 0$).\n\nThe implementation will proceed as follows for each test case:\n1. Construct the $m \\times M$ matrix $A$ based on the given parameters $L$, $\\alpha$, and the time grid $t_i$.\n2. Construct the augmented matrix $\\tilde{A}$ and augmented vector $\\tilde{\\mathbf{y}}$ using the regularization parameter $\\lambda_{\\mathrm{reg}}$.\n3. Solve the linear least squares problem $\\tilde{A}\\mathbf{b} \\approx \\tilde{\\mathbf{y}}$ to find the coefficient vector $\\mathbf{b}$.\n4. Round the resulting coefficients to three decimal places and collect them for final output.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef reconstruct_coefficients(L, alpha, times, measurements, M, lambda_reg):\n    \"\"\"\n    Reconstructs the initial temperature distribution coefficients from midpoint measurements.\n\n    Args:\n        L (float): Length of the bar in meters.\n        alpha (float): Thermal diffusivity in m^2/s.\n        times (list or np.ndarray): Measurement times in seconds.\n        measurements (list or np.ndarray): Measured temperatures at the midpoint in Kelvin.\n        M (int): Number of odd sine modes to use for the approximation.\n        lambda_reg (float): Tikhonov regularization parameter.\n\n    Returns:\n        list: A list of the reconstructed coefficients [b_1, b_3, ...], rounded to three decimals.\n    \"\"\"\n    times = np.asarray(times)\n    measurements = np.asarray(measurements)\n    m = len(times)\n\n    # Construct the design matrix A\n    A = np.zeros((m, M))\n    for i in range(m):  # Loop over time points\n        for j in range(M):  # Loop over odd modes (k=j in the formula)\n            mode_index = 2 * j + 1\n            sine_term = (-1)**j\n            exponent = -alpha * (mode_index * np.pi / L)**2 * times[i]\n            A[i, j] = sine_term * np.exp(exponent)\n\n    # Solve the regularized least squares problem using an augmented system\n    # This is numerically more stable than forming A.T @ A\n    A_aug = np.vstack((A, np.eye(M) * lambda_reg))\n    y_aug = np.concatenate((measurements, np.zeros(M)))\n\n    # Use numpy's least squares solver\n    b, _, _, _ = np.linalg.lstsq(A_aug, y_aug, rcond=None)\n\n    # Round the results to three decimal places\n    return np.round(b, 3).tolist()\n\ndef solve():\n    \"\"\"\n    Runs the reconstruction for all test cases and prints the results in the required format.\n    \"\"\"\n    test_cases = [\n        # Case A\n        {\n            \"L\": 1.0, \"alpha\": 1.0e-4, \"times\": [0, 100, 300, 500],\n            \"y\": [10.00000, 9.06018, 7.43722, 6.10497],\n            \"M\": 1, \"lambda_reg\": 0.0\n        },\n        # Case B\n        {\n            \"L\": 1.0, \"alpha\": 1.0e-4, \"times\": [0, 50, 200, 500],\n            \"y\": [6.00000, 7.57583, 8.83511, 7.25528],\n            \"M\": 2, \"lambda_reg\": 0.0\n        },\n        # Case C\n        {\n            \"L\": 0.8, \"alpha\": 7.0e-5, \"times\": [0, 40, 120, 240, 400],\n            \"y\": [4.01230, 3.42575, 3.55080, 3.55920, 3.19240],\n            \"M\": 3, \"lambda_reg\": 1.0e-3\n        },\n        # Case D\n        {\n            \"L\": 1.0, \"alpha\": 1.0e-4, \"times\": [0, 10, 20, 50, 100],\n            \"y\": [0.0, 0.0, 0.0, 0.0, 0.0],\n            \"M\": 3, \"lambda_reg\": 0.0\n        }\n    ]\n\n    results = []\n    for case in test_cases:\n        coeffs = reconstruct_coefficients(\n            L=case[\"L\"],\n            alpha=case[\"alpha\"],\n            times=case[\"times\"],\n            measurements=case[\"y\"],\n            M=case[\"M\"],\n            lambda_reg=case[\"lambda_reg\"]\n        )\n        results.append(coeffs)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "2398006"}]}