{"hands_on_practices": [{"introduction": "In scientific and engineering practice, reporting a measurement is incomplete without quantifying its uncertainty. This first exercise [@problem_id:2952336] provides a foundational look at the relationship between uncertainty and significant figures. By converting a temperature measurement from Celsius to Kelvin, you will practice propagating uncertainty through a simple additive relationship and discover how this uncertainty dictates the proper precision of the final reported value.", "problem": "A constant-volume thermometer calibrated on the Celsius scale reports a temperature of $25.0 \\pm 0.2\\,^{\\circ}\\mathrm{C}$ for a liquid sample at equilibrium with a well-stirred thermal bath. Use the fact that the size of one kelvin is exactly equal to the size of one degree Celsius and that the Kelvin and Celsius scales differ by an exact offset to convert this measurement to the Kelvin scale with its properly propagated absolute uncertainty. Then, determine how many significant figures are warranted in the reported Kelvin value by appealing to the fundamental definitions of significant figures for measured quantities with uncertainty and to the propagation of uncertainty under addition by a constant. Interpret the quoted $\\pm 0.2$ as an absolute symmetric uncertainty already rounded appropriately and do not re-round it.\n\nReport only the central Kelvin value, rounded to the number of significant figures justified by your uncertainty analysis. Express your final answer in $\\mathrm{K}$ as a single number. Your rounding must be justified by the uncertainty and therefore by significant figures, not by a fixed decimal-place rule.", "solution": "The problem requires the conversion of a temperature measurement from the Celsius scale to the Kelvin scale, accompanied by a rigorous propagation of uncertainty and a determination of the appropriate number of significant figures for the final result.\n\nThe initial measurement is given as a temperature in degrees Celsius, $T_C$, with its associated absolute uncertainty, $\\delta T_C$.\n$$T_C = 25.0 \\,^{\\circ}\\mathrm{C}$$\n$$\\delta T_C = 0.2 \\,^{\\circ}\\mathrm{C}$$\n\nThe relationship between the Kelvin scale ($T_K$) and the Celsius scale ($T_C$) is defined by an exact additive offset. The size of one kelvin is identical to the size of one degree Celsius. The conversion formula is:\n$$T_K = T_C + 273.15$$\nIn this definition, the value $273.15$ is an exact constant, meaning it has zero uncertainty ($\\delta(273.15) = 0$).\n\nFirst, we convert the central value of the temperature:\n$$T_K = 25.0 + 273.15 = 298.15 \\, \\mathrm{K}$$\n\nNext, we must propagate the uncertainty. For a function $Z = f(X, Y, \\dots)$, the general formula for the propagation of uncertainty (assuming independent variables) is given by the squared sum of the contributions from each variable:\n$$(\\delta Z)^2 = \\left(\\frac{\\partial f}{\\partial X}\\right)^2 (\\delta X)^2 + \\left(\\frac{\\partial f}{\\partial Y}\\right)^2 (\\delta Y)^2 + \\dots$$\nIn our case, the function is $T_K = T_C + K_0$, where $K_0 = 273.15$ is a constant. The only variable with uncertainty is $T_C$. The uncertainty in $K_0$ is zero, $\\delta K_0 = 0$.\nThe propagated uncertainty in the Kelvin temperature, $\\delta T_K$, is therefore:\n$$(\\delta T_K)^2 = \\left(\\frac{\\partial T_K}{\\partial T_C}\\right)^2 (\\delta T_C)^2 + \\left(\\frac{\\partial T_K}{\\partial K_0}\\right)^2 (\\delta K_0)^2$$\nThe partial derivatives are:\n$$\\frac{\\partial T_K}{\\partial T_C} = \\frac{\\partial}{\\partial T_C}(T_C + K_0) = 1$$\n$$\\frac{\\partial T_K}{\\partial K_0} = \\frac{\\partial}{\\partial K_0}(T_C + K_0) = 1$$\nSubstituting these into the uncertainty formula:\n$$(\\delta T_K)^2 = (1)^2 (\\delta T_C)^2 + (1)^2 (0)^2 = (\\delta T_C)^2$$\nHence, the absolute uncertainty in the Kelvin temperature is identical to the absolute uncertainty in the Celsius temperature:\n$$\\delta T_K = \\delta T_C = 0.2 \\, \\mathrm{K}$$\n\nThe full result for the temperature in Kelvin, before considering the convention for significant figures, is:\n$$T_K = 298.15 \\pm 0.2 \\, \\mathrm{K}$$\n\nThe fundamental principle for reporting a measured quantity is that the last significant digit of the central value should be in the same decimal position as the most significant digit of its uncertainty. This ensures that the stated precision of the value is consistent with its calculated or measured uncertainty.\n\nIn our result, the uncertainty $\\delta T_K = 0.2 \\, \\mathrm{K}$ has its most significant (and only) digit in the tenths place. Consequently, the central value of the temperature must be rounded to the tenths place.\n\nThe calculated central value is $298.15 \\, \\mathrm{K}$. Rounding this value to the nearest tenth gives:\n$$298.15 \\rightarrow 298.2$$\nThe final reported result, incorporating the uncertainty, would be $T_K = 298.2 \\pm 0.2 \\, \\mathrm{K}$. The central value, $298.2$, has four significant figures. This number of significant figures is justified not by counting digits in the input data, but by a correct propagation of uncertainty.\n\nThe problem asks for the central Kelvin value, rounded to the number of significant figures justified by this analysis. This value is $298.2$.", "answer": "$$\\boxed{298.2}$$", "id": "2952336"}, {"introduction": "Beyond simple arithmetic, the algorithms we choose for our computations can dramatically impact the precision of our results. This problem [@problem_id:2432439] presents a seemingly straightforward geometry task—calculating the area of a small overlap between two circles—that reveals the hidden danger of catastrophic cancellation. You will compare a numerically unstable method with a stable, reformulated one, providing a powerful lesson in designing robust computational procedures.", "problem": "A planar imaging gauge is used to check the tiny overlap (“sliver”) between two nearly tangent circular bores in a fabricated part. The bores are modeled as circles of radii $R_1$ and $R_2$ whose centers are separated by a distance $d$. The measured values and one-standard-deviation standard uncertainties are:\n- $R_1 = 50.000 \\ \\mathrm{mm}$ with $u_{R_1} = 0.001 \\ \\mathrm{mm}$,\n- $R_2 = 80.000 \\ \\mathrm{mm}$ with $u_{R_2} = 0.001 \\ \\mathrm{mm}$,\n- $d = 129.950 \\ \\mathrm{mm}$ with $u_{d} = 0.001 \\ \\mathrm{mm}$.\n\nThe small overlap region (a lens-shaped sliver) is the intersection of the two disks. You are to compute its area twice:\n1) By starting from first principles of plane geometry: write the area of each circular segment as (area of sector) minus (area of isosceles triangle), express the sector angle in terms of the configuration geometry, and sum the two segment areas to obtain the exact lens area. Use radians for all trigonometric functions.\n2) By reformulating the geometry to avoid catastrophic cancellation for small overlaps: parameterize each segment by its sagitta height $h$ and, starting from a small-angle expansion, derive the leading-order stable expression for the segment area in terms of $R$ and $h$. Evaluate this stable approximation for both circles and sum.\n\nThen perform a first-order (linear) propagation of uncertainty from $R_1$, $R_2$, and $d$ into the lens area using partial derivatives of a suitably simplified, physically justified approximation valid for small overlaps.\n\nBased on your uncertainty estimate, select an appropriate number of significant figures for reporting the area. For the purpose of this problem, round the final reported area to two significant figures. Express the final area in $\\mathrm{mm}^2$.\n\nYour final numeric answer must be a single real number. Do not include units in the final boxed value. Use radians consistently.", "solution": "The task is to compute the intersection area (lens) between two circles with radii $R_1$ and $R_2$ and center separation $d$, first using exact geometry and then using a numerically stable approximation tailored to small overlaps. Finally we propagate measurement uncertainties and set appropriate significant figures.\n\nFundamental geometric base:\n- The area of a circular sector of radius $R$ and central angle $2\\theta$ (in radians) is $R^2 \\theta$.\n- The area of the associated isosceles triangle with sides $R$, $R$, and included angle $2\\theta$ is $\\tfrac{1}{2} R^2 \\sin(2\\theta)$.\n- Therefore, the area of a circular segment cut from a circle of radius $R$ by a chord that subtends $2\\theta$ is $R^2\\left(\\theta - \\sin\\theta \\cos\\theta\\right)$, since $\\sin\\theta \\cos\\theta = \\tfrac{1}{2}\\sin(2\\theta)$.\n- The central half-angles $\\theta_1$ and $\\theta_2$ corresponding to the two segments of the lens satisfy, by the Law of Cosines in the triangle formed by the two centers and either intersection point,\n$$\n\\cos\\theta_1 = \\frac{d^2 + R_1^2 - R_2^2}{2 d R_1}, \\qquad\n\\cos\\theta_2 = \\frac{d^2 + R_2^2 - R_1^2}{2 d R_2}.\n$$\n\nExact calculation (standard formula, cancellation-prone for small overlaps):\n- Given $R_1 = 50.000 \\ \\mathrm{mm}$, $R_2 = 80.000 \\ \\mathrm{mm}$, $d = 129.950 \\ \\mathrm{mm}$, compute\n$$\nd^2 = (129.950)^2 = 16887.0025 \\ \\mathrm{mm}^2.\n$$\nThen\n$$\n\\cos\\theta_1 = \\frac{16887.0025 + 50.000^2 - 80.000^2}{2\\cdot 129.950 \\cdot 50.000}\n= \\frac{16887.0025 + 2500 - 6400}{12995}\n= \\frac{12987.0025}{12995} \\approx 0.9993843,\n$$\n$$\n\\cos\\theta_2 = \\frac{16887.0025 + 80.000^2 - 50.000^2}{2\\cdot 129.950 \\cdot 80.000}\n= \\frac{16887.0025 + 6400 - 2500}{20792}\n= \\frac{20787.0025}{20792} \\approx 0.9997600.\n$$\nThus\n$$\n\\theta_1 \\approx \\arccos(0.9993843) \\approx 0.03509 \\ \\text{rad}, \\qquad\n\\theta_2 \\approx \\arccos(0.9997600) \\approx 0.02192 \\ \\text{rad}.\n$$\nThe two segment areas are\n$$\nA_1^{\\mathrm{exact}} = R_1^2\\left(\\theta_1 - \\sin\\theta_1 \\cos\\theta_1\\right), \\qquad\nA_2^{\\mathrm{exact}} = R_2^2\\left(\\theta_2 - \\sin\\theta_2 \\cos\\theta_2\\right),\n$$\nand the lens area is $A^{\\mathrm{exact}} = A_1^{\\mathrm{exact}} + A_2^{\\mathrm{exact}}$.\n\nNumerically, the intermediate sector and triangle terms are large and nearly equal for each segment:\n- For the first circle, $R_1^2 \\theta_1 \\approx 2500 \\times 0.03509 \\approx 87.7 \\ \\mathrm{mm}^2$, while $R_1^2 \\sin\\theta_1 \\cos\\theta_1 \\approx 2500 \\times \\tfrac{1}{2}\\sin(2\\theta_1) \\approx 87.6 \\ \\mathrm{mm}^2$. Their difference is only $\\approx 0.072 \\ \\mathrm{mm}^2$.\n- For the second circle, $R_2^2 \\theta_2 \\approx 6400 \\times 0.02192 \\approx 140.3 \\ \\mathrm{mm}^2$, while $R_2^2 \\sin\\theta_2 \\cos\\theta_2 \\approx 6400 \\times \\tfrac{1}{2}\\sin(2\\theta_2) \\approx 140.2 \\ \\mathrm{mm}^2$. Their difference is $\\approx 0.045 \\ \\mathrm{mm}^2$.\n\nSubtracting nearly equal large terms is numerically ill-conditioned and prone to loss of significant digits (subtractive cancellation), especially when the overlap is tiny. The combined exact value (if evaluated with sufficiently high precision) is\n$$\nA^{\\mathrm{exact}} \\approx 0.11695 \\ \\mathrm{mm}^2,\n$$\nbut this path is sensitive to roundoff if computed naively.\n\nStable geometric reformulation for small overlaps:\nIntroduce the sagitta heights $h_1$ and $h_2$ of the two segments. Let $x_1$ be the distance from the center of circle $1$ to the common chord along the line of centers. From geometry,\n$$\nx_1 = \\frac{d^2 + R_1^2 - R_2^2}{2d}, \\qquad h_1 = R_1 - x_1,\n$$\nand similarly $x_2 = d - x_1$, $h_2 = R_2 - x_2$. Substituting the given numbers,\n$$\nx_1 = \\frac{16887.0025 + 2500 - 6400}{2\\cdot 129.950} = \\frac{12987.0025}{259.9} \\approx 49.96923 \\ \\mathrm{mm},\n$$\n$$\nh_1 = 50.000 - 49.96923 \\approx 0.030771 \\ \\mathrm{mm}, \\quad\nx_2 = 129.950 - 49.96923 \\approx 79.98077 \\ \\mathrm{mm}, \\quad\nh_2 = 80.000 - 79.98077 \\approx 0.019229 \\ \\mathrm{mm}.\n$$\nFor a circle of radius $R$ and a very small segment of height $h$, start from the exact segment area $R^2\\left(\\theta - \\sin\\theta \\cos\\theta\\right)$ with $\\cos\\theta = (R-h)/R$ and expand for small $\\theta$:\n$$\n\\sin\\theta \\cos\\theta = \\tfrac{1}{2}\\sin(2\\theta) = \\theta - \\frac{2}{3}\\theta^3 + O(\\theta^5),\n$$\nso\n$$\n\\theta - \\sin\\theta \\cos\\theta = \\frac{2}{3}\\theta^3 + O(\\theta^5).\n$$\nSince $h = R(1 - \\cos\\theta) = \\tfrac{1}{2}R \\theta^2 + O(\\theta^4)$, the leading-order relation $\\theta \\approx \\sqrt{2h/R}$ yields the stable leading-order segment area\n$$\nA_{\\mathrm{seg}}(R,h) \\approx \\frac{4}{3} \\sqrt{2R} \\, h^{3/2}.\n$$\nEvaluating for each circle:\n$$\nA_1^{\\mathrm{stab}} \\approx \\frac{4}{3}\\sqrt{2\\cdot 50.000}\\,(0.030771)^{3/2}\n= \\frac{40}{3}\\,(0.030771)^{3/2} \\approx 0.07198 \\ \\mathrm{mm}^2,\n$$\n$$\nA_2^{\\mathrm{stab}} \\approx \\frac{4}{3}\\sqrt{2\\cdot 80.000}\\,(0.019229)^{3/2}\n\\approx 16.86548 \\times (0.019229)^{3/2} \\approx 0.04497 \\ \\mathrm{mm}^2.\n$$\nSumming,\n$$\nA^{\\mathrm{stab}} = A_1^{\\mathrm{stab}} + A_2^{\\mathrm{stab}} \\approx 0.11695 \\ \\mathrm{mm}^2.\n$$\nThe leading neglected term in the small-angle expansion is $O(\\theta^5)$, giving a relative error on the order of $0.1 \\%$ or less here, which is negligible compared to the measurement uncertainty estimated next.\n\nUncertainty propagation and significant digits:\nFor nearly tangent circles it is convenient to rewrite the stable approximation in a compact form in terms of the overlap depth $\\epsilon = R_1 + R_2 - d$ and the sum $S = R_1 + R_2$. Using $h_1 \\approx \\epsilon \\, R_2/S$ and $h_2 \\approx \\epsilon \\, R_1/S$ (accurate to first order in $\\epsilon/S$), the sum simplifies algebraically to\n$$\nA \\approx \\frac{4}{3} \\sqrt{\\frac{2 R_1 R_2}{S}} \\, \\epsilon^{3/2}, \\quad \\text{with} \\quad \\epsilon = R_1 + R_2 - d, \\ S = R_1 + R_2.\n$$\nFor uncertainty propagation, take $R_1$, $R_2$, and $d$ as independent. Using first-order (linear) propagation with partial derivatives of $A(R_1,R_2,d)$,\n$$\n\\frac{\\partial A}{\\partial d} = -\\frac{3}{2}\\frac{A}{\\epsilon}, \\quad\n\\frac{\\partial A}{\\partial R_1} = A\\left[\\frac{1}{2}\\left(\\frac{1}{R_1} - \\frac{1}{S}\\right) + \\frac{3}{2}\\frac{1}{\\epsilon}\\right], \\quad\n\\frac{\\partial A}{\\partial R_2} = A\\left[\\frac{1}{2}\\left(\\frac{1}{R_2} - \\frac{1}{S}\\right) + \\frac{3}{2}\\frac{1}{\\epsilon}\\right].\n$$\nWith $R_1 = 50.000 \\ \\mathrm{mm}$, $R_2 = 80.000 \\ \\mathrm{mm}$, $S = 130.000 \\ \\mathrm{mm}$, $\\epsilon = 0.050 \\ \\mathrm{mm}$, and $A \\approx 0.11695 \\ \\mathrm{mm}^2$,\n$$\n\\left|\\frac{\\partial A}{\\partial d}\\right| \\approx \\frac{3}{2}\\frac{0.11695}{0.050} \\approx 3.5085 \\ \\mathrm{mm},\n$$\n$$\n\\left|\\frac{\\partial A}{\\partial R_1}\\right| \\approx 0.11695\\left[ \\frac{1}{2}\\left(\\frac{1}{50} - \\frac{1}{130}\\right) + \\frac{3}{2}\\frac{1}{0.050} \\right] \\approx 3.509 \\ \\mathrm{mm},\n$$\n$$\n\\left|\\frac{\\partial A}{\\partial R_2}\\right| \\approx 0.11695\\left[ \\frac{1}{2}\\left(\\frac{1}{80} - \\frac{1}{130}\\right) + \\frac{3}{2}\\frac{1}{0.050} \\right] \\approx 3.509 \\ \\mathrm{mm}.\n$$\nWith $u_{R_1} = u_{R_2} = u_d = 0.001 \\ \\mathrm{mm}$, the combined standard uncertainty is\n$$\nu_A \\approx \\sqrt{\\left(\\frac{\\partial A}{\\partial R_1}u_{R_1}\\right)^2 + \\left(\\frac{\\partial A}{\\partial R_2}u_{R_2}\\right)^2 + \\left(\\frac{\\partial A}{\\partial d}u_d\\right)^2}\n\\approx \\sqrt{(0.003509)^2 + (0.003509)^2 + (0.003509)^2}\n\\approx 0.00608 \\ \\mathrm{mm}^2.\n$$\nThe relative standard uncertainty is $u_A/A \\approx 0.00608/0.11695 \\approx 0.052 \\ (\\text{about } 5.2\\%)$, which supports reporting the area to about two significant figures.\n\nTherefore, adopting the numerically stable value and rounding the final area to two significant figures in accordance with the problem instruction yields the reported area.\n\nFinal numeric value (units excluded in the box as required): $0.12$ when expressed in $\\mathrm{mm}^2$.", "answer": "$$\\boxed{0.12}$$", "id": "2432439"}, {"introduction": "Many complex engineering problems, from structural analysis to circuit simulation, are ultimately reduced to solving a system of linear equations, $A\\vec{x} = \\vec{b}$. This exercise [@problem_id:2432471] explores the critical concept of ill-conditioning using the classic example of the Hilbert matrix. By observing how tiny perturbations in the input data are massively amplified in the solution, you will gain a tangible understanding of how a model's inherent properties can limit the trustworthiness of its computational results.", "problem": "An engineer must evaluate how many correct significant digits can be trusted in the numerical solution of a linear system with an ill-conditioned coefficient matrix. Consider the Hilbert matrix of order $n$, defined by $H \\in \\mathbb{R}^{n \\times n}$ with entries $H_{i,j} = \\dfrac{1}{i + j - 1}$ for $1 \\leq i,j \\leq n$. For $n = 8$, let the true solution be $x^{\\mathrm{true}} \\in \\mathbb{R}^{8}$ with components $x^{\\mathrm{true}}_i = 1$ for all $i$, and define $b = H x^{\\mathrm{true}}$. In all computations, assume standard double-precision floating-point arithmetic as defined by the Institute of Electrical and Electronics Engineers (IEEE) $754$ binary64 format.\n\nDefine the number of correct significant digits $s$ in a computed solution $\\hat{x}$ relative to the true solution $x^{\\mathrm{true}}$ by\n$$\ns = \\max\\left(0,\\; -\\log_{10}\\left(\\frac{\\lVert \\hat{x} - x^{\\mathrm{true}} \\rVert_2}{\\lVert x^{\\mathrm{true}} \\rVert_2}\\right)\\right).\n$$\n\nYour task is to write a complete program that, for the following four test cases, computes $\\hat{x}$ by solving $H \\hat{x} = \\tilde{b}$ and then reports the value of $s$ for each case:\n\n- Test case $1$ (baseline): $\\tilde{b} = b$.\n- Test case $2$ (rounded right-hand side): $\\tilde{b}$ is obtained from $b$ by rounding each component to $k = 8$ significant decimal digits.\n- Test case $3$ (more severe rounding): $\\tilde{b}$ is obtained from $b$ by rounding each component to $k = 6$ significant decimal digits.\n- Test case $4$ (deterministic componentwise relative perturbation): $\\tilde{b}$ is defined componentwise by $\\tilde{b}_i = b_i + \\delta b_i$ with $\\delta b_i = 10^{-12} \\cdot (-1)^i \\cdot |b_i|$ for $i = 1,2,\\dots,8$.\n\nRequirements and conventions:\n- Construct $H$ by its definition $H_{i,j} = \\dfrac{1}{i + j - 1}$ for $n = 8$.\n- Use $x^{\\mathrm{true}}$ with all components equal to $1$, so that $b = H x^{\\mathrm{true}}$ is determined exactly from $H$ and $x^{\\mathrm{true}}$.\n- Implement rounding to $k$ significant digits for a real number $y \\neq 0$ as $y$ rounded to the nearest decimal with $k$ significant digits, and map $0$ to $0$.\n- Compute $s$ from the formula above using the Euclidean norm $\\lVert \\cdot \\rVert_2$.\n\nTest suite and output specification:\n- The four test cases are defined exactly as above and must be evaluated in the order $1,2,3,4$.\n- For each test case, compute $s$ as a floating-point number.\n- Your program should produce a single line of output containing a Python-style list of the four values of $s$, rounded to $3$ decimal places and ordered as $[s_1,s_2,s_3,s_4]$ corresponding to test cases $1$ through $4$.\n- No physical units are involved. Angles do not appear. Percentages are not to be used; all quantities are real numbers.\n\nYour final program must be self-contained and require no input. It must output exactly one line in the specified format.", "solution": "The problem presented is a valid and well-posed exercise in numerical linear algebra, specifically concerning the effects of ill-conditioning on the accuracy of solutions to linear systems. It is scientifically grounded, free of ambiguity, and provides all necessary information for a unique, computational solution. The problem requires an analysis of how perturbations in the right-hand side vector of a linear system $H\\hat{x} = \\tilde{b}$ affect the solution $\\hat{x}$, where $H$ is the notoriously ill-conditioned Hilbert matrix. This is a classic demonstration of numerical instability, a critical concept in computational engineering.\n\nThe core of the problem lies in the properties of the coefficient matrix. The Hilbert matrix of order $n$, with entries $H_{ij} = (i+j-1)^{-1}$, is a symmetric, positive-definite matrix. However, its condition number $\\kappa(H) = \\lVert H \\rVert \\lVert H^{-1} \\rVert$ grows extraordinarily rapidly with its order $n$. For the specified order $n=8$, the condition number with respect to the Euclidean norm, $\\kappa_2(H_8)$, is approximately $1.5 \\times 10^{10}$.\n\nA fundamental result in perturbation theory for linear systems states that for a perturbation $\\delta b$ in the right-hand side vector $b$, the resulting relative error in the solution $x$ is bounded as:\n$$\n\\frac{\\lVert \\delta x \\rVert_2}{\\lVert x^{\\mathrm{true}} \\rVert_2} \\leq \\kappa_2(H) \\frac{\\lVert \\delta b \\rVert_2}{\\lVert b \\rVert_2}\n$$\nwhere $\\delta x = \\hat{x} - x^{\\mathrm{true}}$ and $\\delta b = \\tilde{b} - b$. This inequality shows that the condition number acts as an amplification factor for the relative error in the input data. Standard double-precision (binary64) arithmetic offers approximately $15$ to $17$ decimal digits of precision. With a condition number of about $10^{10}$, we can expect a loss of at least $\\log_{10}(1.5 \\times 10^{10}) \\approx 10.2$ decimal digits of accuracy, even before considering any explicit perturbations to the right-hand side.\n\nThe solution proceeds as follows:\n\n1.  **Matrix and Vector Construction**: First, we construct the $8 \\times 8$ Hilbert matrix $H$ using its definition, $H_{ij} = (i+j-1)^{-1}$. We must use 0-based indexing for array implementation, so the entry at `(row, col)` indices `i`, `j` is $1.0 / (i + j + 1)$, for $i,j \\in \\{0, 1, \\dots, 7\\}$. The true solution is a vector of ones, $x^{\\mathrm{true}} = [1, 1, \\dots, 1]^T \\in \\mathbb{R}^8$. The corresponding \"true\" right-hand side vector $b$ is computed as the matrix-vector product $b = H x^{\\mathrm{true}}$. Due to the structure of $x^{\\mathrm{true}}$, $b$ is simply the vector of row sums of $H$, i.e., $b_i = \\sum_{j=1}^8 H_{ij}$.\n\n2.  **Test Case Evaluation**: For each of the four test cases, we define the perturbed right-hand side vector $\\tilde{b}$ and solve the linear system $H \\hat{x} = \\tilde{b}$ for the computed solution $\\hat{x}$. This is accomplished using a standard numerical solver, such as one based on LU decomposition, which is typically invoked by `numpy.linalg.solve`.\n\n    *   **Case 1 (Baseline)**: $\\tilde{b} = b$. Here, the only source of error is the finite precision of floating-point arithmetic. The representation of $H$ and the computation of $b$ introduce small round-off errors. The linear solver itself will introduce further errors. The resulting deviation of $\\hat{x}$ from $x^{\\mathrm{true}}$ is almost entirely due to the amplification of these intrinsic representation and arithmetic errors by the large condition number of $H$.\n\n    *   **Case 2 (Rounding to $k=8$ digits)**: We obtain $\\tilde{b}$ by rounding each component of the computed vector $b$ to $8$ significant decimal digits. This introduces an explicit relative perturbation $\\delta b / b$ on the order of $10^{-8}$. Amplified by $\\kappa_2(H_8) \\approx 10^{10}$, the expected relative error in the solution will be on the order of $10^{10} \\times 10^{-8} = 100$. A relative error greater than $1$ implies a complete loss of accuracy.\n\n    *   **Case 3 (Rounding to $k=6$ digits)**: The rounding is more severe. The relative perturbation in $b$ is on the order of $10^{-6}$. The expected relative error in the solution will be even larger, approximately $10^{10} \\times 10^{-6} = 10^4$. Again, a complete loss of accuracy is anticipated.\n\n    *   **Case 4 (Deterministic Perturbation)**: The perturbation is defined as a small, alternating relative change: $\\tilde{b}_i = b_i (1 + 10^{-12} \\cdot (-1)^i)$. The relative perturbation in $b$ is of magnitude $10^{-12}$. The expected relative error in the solution is on the order of $10^{10} \\times 10^{-12} = 10^{-2}$.\n\n3.  **Accuracy Calculation**: After computing $\\hat{x}$ for each case, we quantify the accuracy using the number of correct significant digits, $s$, defined as:\n    $$\n    s = \\max\\left(0,\\; -\\log_{10}\\left(\\frac{\\lVert \\hat{x} - x^{\\mathrm{true}} \\rVert_2}{\\lVert x^{\\mathrm{true}} \\rVert_2}\\right)\\right)\n    $$\n    The term inside the logarithm is the relative error in the solution. The Euclidean norm of the true solution is $\\lVert x^{\\mathrm{true}} \\rVert_2 = \\sqrt{8}$. We compute the error vector $\\hat{x} - x^{\\mathrm{true}}$, find its Euclidean norm, and then substitute into the formula for $s$.\n\nThe implementation requires a function to perform rounding to a specified number of significant digits. For a non-zero number $y$ and $k$ significant digits, this is achieved by rounding $y$ to $d = k - 1 - \\lfloor\\log_{10}|y|\\rfloor$ decimal places.\n\nThis systematic procedure allows for a quantitative evaluation of how an ill-conditioned system, a common hazard in engineering and scientific computation, degrades the quality of a numerical solution in response to various sources of error.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nimport math\n\ndef solve():\n    \"\"\"\n    Computes the number of correct significant digits in the solution of a\n    linear system with the 8x8 Hilbert matrix under various perturbations\n    to the right-hand side vector.\n    \"\"\"\n\n    def round_to_k_significant_digits(y, k):\n        \"\"\"\n        Rounds a number y to k significant digits.\n        \"\"\"\n        if y == 0:\n            return 0.0\n        # Determine the number of decimal places needed for rounding\n        # based on the magnitude of the number.\n        d = k - 1 - math.floor(math.log10(abs(y)))\n        # Python's round() uses round-half-to-even.\n        return round(y, int(d))\n\n    # Define problem parameters\n    n = 8  # Order of the Hilbert matrix\n\n    # Construct the Hilbert matrix H.\n    # H_ij = 1 / (i + j - 1) for 1-based indexing.\n    # For 0-based indices, this is H_ij = 1 / ((i+1) + (j+1) - 1) = 1 / (i+j+1).\n    H = np.zeros((n, n), dtype=np.float64)\n    for i in range(n):\n        for j in range(n):\n            H[i, j] = 1.0 / (i + j + 1)\n\n    # Define the true solution x_true (a vector of ones).\n    x_true = np.ones(n, dtype=np.float64)\n\n    # Calculate the true right-hand side vector b = H * x_true.\n    # Since x_true is all ones, b is the vector of row sums of H.\n    b = H @ x_true\n\n    # The Euclidean norm of the true solution is sqrt(n).\n    norm_x_true = np.linalg.norm(x_true, 2)\n\n    # List to store the results (s values) for each test case.\n    results = []\n    \n    # Define test cases as a list of perturbed right-hand side vectors.\n    # Test Case 1: Baseline (no explicit perturbation)\n    b_tilde_1 = b\n\n    # Test Case 2: Rounding to 8 significant digits\n    b_tilde_2 = np.array([round_to_k_significant_digits(val, 8) for val in b])\n\n    # Test Case 3: Rounding to 6 significant digits\n    b_tilde_3 = np.array([round_to_k_significant_digits(val, 6) for val in b])\n\n    # Test Case 4: Deterministic component-wise relative perturbation\n    # delta_b_i = 10^-12 * (-1)^i * |b_i| for i=1..8\n    # For 0-based index j=0..7, this is (-1)^(j+1).\n    delta_b_4 = np.array([1e-12 * ((-1)**(i + 1)) * abs(b[i]) for i in range(n)])\n    b_tilde_4 = b + delta_b_4\n    \n    test_cases_b = [b_tilde_1, b_tilde_2, b_tilde_3, b_tilde_4]\n\n    for b_tilde in test_cases_b:\n        # Solve the linear system H * x_hat = b_tilde.\n        x_hat = np.linalg.solve(H, b_tilde)\n\n        # Calculate the relative error of the solution.\n        # rel_err = ||x_hat - x_true|| / ||x_true||\n        error_norm = np.linalg.norm(x_hat - x_true, 2)\n        relative_error = error_norm / norm_x_true\n\n        # Calculate the number of correct significant digits, s.\n        # s = max(0, -log10(relative_error))\n        # A check for relative_error == 0 is theoretically needed but\n        # practically impossible in this floating-point context.\n        s = max(0.0, -math.log10(relative_error))\n        \n        # Store the result, rounded to 3 decimal places.\n        results.append(round(s, 3))\n\n    # Format the final output as specified.\n    output_str = \"[\" + \",\".join(map(str, results)) + \"]\"\n    print(output_str)\n\nsolve()\n```", "id": "2432471"}]}