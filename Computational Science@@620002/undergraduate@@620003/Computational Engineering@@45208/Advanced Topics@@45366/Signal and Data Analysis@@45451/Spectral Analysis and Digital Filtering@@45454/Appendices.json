{"hands_on_practices": [{"introduction": "Digital filters are fundamental tools for signal processing, and understanding their properties is a core skill. This exercise explores the widely used moving average filter, starting from its basic time-domain definition. You will practice deriving a computationally efficient recursive form and then determine its transfer function, $H(z)$, providing a crucial bridge between the filter's implementation and its behavior in the frequency domain.[@problem_id:2436705] This practice builds a foundational understanding of how a filter's structure dictates its analytical properties.", "problem": "A causal length-$M$ moving average filter, also known as a rectangular or boxcar smoother, is defined on a discrete-time input $x[n]$ by the output\n$$\ny[n] \\triangleq \\frac{1}{M} \\sum_{k=0}^{M-1} x[n-k],\n$$\nfor an integer $M \\geq 2$. Assume $x[n]=0$ and $y[n]=0$ for all $n&lt;0$. Starting solely from this definition, derive a one-step recursion to compute $y[n]$ using only $y[n-1]$, $x[n]$, and $x[n-M]$. Then, using the definition of the bilateral $z$-transform (ZT), determine the transfer function $H(z) \\triangleq \\frac{Y(z)}{X(z)}$ of this filter in closed form. Express your final answer as a single simplified rational function of $z^{-1}$. No numerical rounding is required, and no physical units are involved. Provide only the final symbolic expression for $H(z)$ as your answer.", "solution": "The problem statement is parsed and validated. It is found to be self-contained, scientifically sound, and well-posed. It presents a standard exercise in digital signal processing theory. We proceed with the derivation.\n\nThe problem requires a two-part derivation based on the definition of a causal length-$M$ moving average filter:\n$$\ny[n] \\triangleq \\frac{1}{M} \\sum_{k=0}^{M-1} x[n-k]\n$$\nwhere $M$ is an integer such that $M \\geq 2$.\n\nFirst, we will derive the one-step recursive formula for $y[n]$.\nThe definition of the output at time step $n$ is given as:\n$$\ny[n] = \\frac{1}{M} \\left( x[n] + x[n-1] + \\dots + x[n-M+1] \\right)\n$$\nWe write the expression for the output at the previous time step, $n-1$:\n$$\ny[n-1] = \\frac{1}{M} \\sum_{k=0}^{M-1} x[n-1-k]\n$$\nExpanding this sum gives:\n$$\ny[n-1] = \\frac{1}{M} \\left( x[n-1] + x[n-2] + \\dots + x[n-1-(M-1)] \\right)\n$$\n$$\ny[n-1] = \\frac{1}{M} \\left( x[n-1] + x[n-2] + \\dots + x[n-M] \\right)\n$$\nTo find a relationship between $y[n]$ and $y[n-1]$, we rearrange the expression for $y[n]$ by isolating the newest sample, $x[n]$:\n$$\nM \\cdot y[n] = x[n] + \\sum_{k=1}^{M-1} x[n-k]\n$$\nNow, we rearrange the expression for $y[n-1]$ to isolate the sum that appears in the equation for $y[n]$. Let us perform a change of index $j = k+1$ in the definition of $y[n-1]$:\n$$\nM \\cdot y[n-1] = \\sum_{k=0}^{M-1} x[n-1-k] = \\sum_{j=1}^{M} x[n-j]\n$$\nThis sum can be written as:\n$$\nM \\cdot y[n-1] = \\left( \\sum_{j=1}^{M-1} x[n-j] \\right) + x[n-M]\n$$\nFrom this, we can express the sum $\\sum_{j=1}^{M-1} x[n-j]$ in terms of $y[n-1]$ and $x[n-M]$:\n$$\n\\sum_{j=1}^{M-1} x[n-j] = M \\cdot y[n-1] - x[n-M]\n$$\nThe summation index is a dummy variable, so $\\sum_{k=1}^{M-1} x[n-k] = \\sum_{j=1}^{M-1} x[n-j]$. We substitute this expression back into the equation for $M \\cdot y[n]$:\n$$\nM \\cdot y[n] = x[n] + (M \\cdot y[n-1] - x[n-M])\n$$\nDividing by $M$ yields the desired one-step recursive formula:\n$$\ny[n] = y[n-1] + \\frac{1}{M} \\left( x[n] - x[n-M] \\right)\n$$\nThis form is computationally efficient as it requires only two additions and one multiplication per output sample, regardless of the filter length $M$.\n\nSecond, we determine the transfer function $H(z) = \\frac{Y(z)}{X(z)}$ using the definition of the bilateral $z$-transform. The transfer function is the $z$-transform of the filter's impulse response, $h[n]$. The impulse response is the output of the filter when the input is the discrete-time unit impulse signal, $x[n] = \\delta[n]$.\nSubstituting $x[n]=\\delta[n]$ into the filter definition gives $h[n]$:\n$$\nh[n] = \\frac{1}{M} \\sum_{k=0}^{M-1} \\delta[n-k]\n$$\nThe term $\\delta[n-k]$ is equal to $1$ only when $n-k=0$, i.e., when $k=n$. It is zero otherwise. The summation is over $k$ from $0$ to $M-1$. Therefore, for a given $n$, the sum is non-zero only if $n$ is in the range $[0, M-1]$. If $n$ is in this range, exactly one term in the sum (where $k=n$) is non-zero and equal to $1$.\nThus, the impulse response is:\n$$\nh[n] = \\begin{cases} \\frac{1}{M} & \\text{for } 0 \\le n \\le M-1 \\\\ 0 & \\text{otherwise} \\end{cases}\n$$\nNow, we apply the definition of the bilateral $z$-transform to $h[n]$ to find $H(z)$:\n$$\nH(z) = \\sum_{n=-\\infty}^{\\infty} h[n] z^{-n}\n$$\nSubstituting the expression for $h[n]$ restricts the summation range:\n$$\nH(z) = \\sum_{n=0}^{M-1} \\left(\\frac{1}{M}\\right) z^{-n} = \\frac{1}{M} \\sum_{n=0}^{M-1} z^{-n}\n$$\nThe summation is a finite geometric series of the form $\\sum_{n=0}^{N-1} r^n$, with $N=M$ terms and a common ratio $r = z^{-1}$. The sum of such a series is given by the formula $\\frac{1-r^N}{1-r}$.\nApplying this formula, we get:\n$$\n\\sum_{n=0}^{M-1} (z^{-1})^n = \\frac{1 - (z^{-1})^M}{1 - z^{-1}} = \\frac{1 - z^{-M}}{1 - z^{-1}}\n$$\nSubstituting this result back into the expression for $H(z)$, we obtain the transfer function in its final, simplified form as a rational function of $z^{-1}$:\n$$\nH(z) = \\frac{1}{M} \\frac{1 - z^{-M}}{1 - z^{-1}}\n$$\nThis expression represents the system's behavior in the $z$-domain.", "answer": "$$\n\\boxed{\\frac{1}{M} \\frac{1 - z^{-M}}{1 - z^{-1}}}\n$$", "id": "2436705"}, {"introduction": "One of the most powerful applications of spectral analysis is the ability to separate a desired signal from unwanted noise. In this hands-on coding practice, you will filter a noisy audio signal by transforming it into the frequency domain using the Fast Fourier Transform (FFT). By identifying and removing spectral components below a certain magnitude threshold and transforming the signal back to the time domain, you will directly experience the effectiveness of frequency-domain filtering.[@problem_id:2383381]", "problem": "Let a discrete-time signal be defined on a uniform sampling grid of $N$ samples with sampling frequency $F_s$ (in Hz). The grid is $t_n = \\dfrac{n}{F_s}$ for $n \\in \\{0,1,\\dots,N-1\\}$, with all angles in radians. Consider a clean musical note modeled as a single sinusoid $s_n = \\sin(2\\pi f_0 t_n)$ of unit amplitude and frequency $f_0$ (in Hz). The observed signal is the sum of the clean note and a deterministic additive noise composed of two sinusoids:\n$$\nx_n = s_n + 0.15\\,\\sin(2\\pi \\cdot 1000\\, t_n) + 0.10\\,\\sin(2\\pi \\cdot 3000\\, t_n).\n$$\nFor a sequence $\\{x_n\\}_{n=0}^{N-1}$, define the Discrete Fourier Transform (DFT) and its inverse by\n$$\nX_k = \\sum_{n=0}^{N-1} x_n\\, e^{-i 2\\pi kn/N},\\quad k=0,1,\\dots,N-1,\n$$\n$$\n\\widehat{x}_n = \\frac{1}{N} \\sum_{k=0}^{N-1} X_k\\, e^{i 2\\pi kn/N},\\quad n=0,1,\\dots,N-1.\n$$\nFor a given threshold fraction $\\tau \\in [0,1]$, define a filtered spectrum by zeroing all coefficients whose magnitude is below $\\tau$ times the maximum spectral magnitude:\n$$\nM = \\max_{0 \\le k \\le N-1} |X_k|,\\qquad\nY_k = \\begin{cases}\nX_k,& \\text{if } |X_k| \\ge \\tau M,\\\\\n0,& \\text{otherwise.}\n\\end{cases}\n$$\nThe filtered time-domain signal is then given by\n$$\ny_n = \\frac{1}{N} \\sum_{k=0}^{N-1} Y_k\\, e^{i 2\\pi kn/N}.\n$$\nFor each test case, compute the root-mean-square error (RMSE) between the filtered signal and the clean signal,\n$$\n\\mathrm{RMSE} = \\sqrt{\\frac{1}{N} \\sum_{n=0}^{N-1} \\left(y_n - s_n\\right)^2},\n$$\nwhich is dimensionless.\n\nAngle arguments in all trigonometric functions must be in radians. Frequencies are in hertz. No other physical units are required for the outputs.\n\nTest suite:\n- Case $1$: $(F_s, N, f_0, \\tau) = (8192,\\ 1024,\\ 440,\\ 0.25)$.\n- Case $2$: $(F_s, N, f_0, \\tau) = (8192,\\ 1024,\\ 512,\\ 0.90)$.\n- Case $3$: $(F_s, N, f_0, \\tau) = (8192,\\ 1024,\\ 440,\\ 0.00)$.\n- Case $4$: $(F_s, N, f_0, \\tau) = (8192,\\ 1024,\\ 2048,\\ 0.75)$.\n\nYour program must:\n- Construct $s_n$ and $x_n$ exactly as defined above for each test case using the corresponding $F_s$, $N$, and $f_0$.\n- Compute the DFT $X_k$ of $x_n$, apply the spectral threshold rule parameterized by $\\tau$, compute the inverse transform to obtain $y_n$, and then compute the $\\mathrm{RMSE}$ relative to $s_n$.\n\nFinal output format:\n- Produce a single line of output containing the four $\\mathrm{RMSE}$ values corresponding to the cases above, rounded to exactly $6$ decimal places, as a comma-separated list enclosed in square brackets, for example, $[r_1,r_2,r_3,r_4]$ where each $r_j$ has exactly $6$ digits after the decimal point.", "solution": "The problem requires transforming a noisy sinusoidal signal to the frequency domain, removing small-magnitude spectral components relative to the largest spectral magnitude, and transforming back to time domain to assess denoising performance through the root-mean-square error (RMSE) relative to the clean signal. This directly relies on the definitions of the Discrete Fourier Transform (DFT) and its inverse.\n\nStart from the fundamental definitions. For $N$ time samples $\\{x_n\\}_{n=0}^{N-1}$, the Discrete Fourier Transform (DFT) is\n$$\nX_k = \\sum_{n=0}^{N-1} x_n\\, e^{-i 2\\pi kn/N},\\quad k=0,1,\\dots,N-1,\n$$\nand its inverse is\n$$\n\\widehat{x}_n = \\frac{1}{N} \\sum_{k=0}^{N-1} X_k\\, e^{i 2\\pi kn/N},\\quad n=0,1,\\dots,N-1.\n$$\nThe DFT is a linear change of basis from the time-domain sequence to its representation as a sum of discrete complex exponentials with frequencies $2\\pi k/N$. For real sequences, spectral components occur in conjugate-symmetric pairs, but the general form above holds in all cases.\n\nSignal model. The clean signal is $s_n = \\sin(2\\pi f_0 t_n)$ with unit amplitude and frequency $f_0$, sampled at $t_n = n/F_s$. The noise is deterministic and defined as the sum of two sinusoids:\n$$\nn_n = 0.15\\,\\sin(2\\pi \\cdot 1000\\, t_n) + 0.10\\,\\sin(2\\pi \\cdot 3000\\, t_n).\n$$\nThe observed signal is $x_n = s_n + n_n$. Because $F_s = 8192$ and $N = 1024$, the frequency resolution is $\\Delta f = F_s/N = 8$. The chosen frequencies $f_0 \\in \\{440, 512, 2048\\}$ and the noise frequencies $1000$ and $3000$ are integer multiples of $\\Delta f$, which ensures that over $N$ samples each sinusoid completes an integer number of periods. This makes the corresponding DFT energy concentrate in exact bins and enforces orthogonality of distinct sinusoids over the finite sequence. In particular, in Case $3$ where $\\tau = 0$, no filtering is performed and the RMSE relative to the clean signal equals the root-mean-square of the noise:\n$$\n\\mathrm{RMSE}_{\\tau=0} = \\sqrt{\\frac{1}{N}\\sum_{n=0}^{N-1} n_n^2} = \\sqrt{\\frac{(0.15)^2}{2} + \\frac{(0.10)^2}{2}},\n$$\nsince the sinusoids are orthogonal and the mean of $\\sin^2$ over an integer number of periods is $1/2$.\n\nFiltering rule. Given the spectrum $X_k$, define $M = \\max_k |X_k|$ and threshold by retaining only those spectral coefficients with $|X_k| \\ge \\tau M$. The filtered spectrum is\n$$\nY_k = \\begin{cases}\nX_k,& |X_k| \\ge \\tau M,\\\\\n0,& \\text{otherwise.}\n\\end{cases}\n$$\nThe filtered time-domain signal is obtained by inverse transformation:\n$$\ny_n = \\frac{1}{N} \\sum_{k=0}^{N-1} Y_k\\, e^{i 2\\pi kn/N}.\n$$\nThe denoising performance is quantified by the root-mean-square error\n$$\n\\mathrm{RMSE} = \\sqrt{\\frac{1}{N} \\sum_{n=0}^{N-1} (y_n - s_n)^2}.\n$$\n\nEfficient computation. Direct evaluation of the DFT and its inverse from the definitions costs $\\mathcal{O}(N^2)$. For $N$ that is a power of two, the transform can be evaluated in $\\mathcal{O}(N \\log_2 N)$ by recursively dividing the sum into even and odd-indexed subsequences and combining them with twiddle factors $e^{-i 2\\pi k/N}$. This is the principle of the radix-$2$ divide-and-conquer approach. Let $x^{(e)}_m = x_{2m}$ and $x^{(o)}_m = x_{2m+1}$ for $m=0,\\dots,N/2-1$. Then\n$$\nX_k = E_k + W_N^k O_k,\\quad X_{k+N/2} = E_k - W_N^k O_k,\\quad k=0,\\dots,N/2-1,\n$$\nwhere $E_k$ and $O_k$ are the DFTs of the even and odd subsequences, and $W_N^k = e^{-i 2\\pi k/N}$. The inverse transform can be computed analogously or via conjugation and scaling:\n$$\n\\mathrm{iDFT}(X)_n = \\frac{1}{N} \\overline{\\mathrm{DFT}(\\overline{X})_n}.\n$$\n\nImplementation plan anchored in first principles:\n- For each test case, construct $t_n = n/F_s$, $s_n = \\sin(2\\pi f_0 t_n)$, $x_n = s_n + 0.15\\,\\sin(2\\pi \\cdot 1000\\, t_n) + 0.10\\,\\sin(2\\pi \\cdot 3000\\, t_n)$.\n- Compute $X_k$ using the radix-$2$ divide-and-conquer evaluation of the DFT for $N=1024$.\n- Compute $M = \\max_k |X_k|$ and define $Y_k$ by the threshold rule $|X_k| \\ge \\tau M$.\n- Compute $y_n$ via inverse transform and extract its real part (the imaginary part is numerical roundoff).\n- Compute $\\mathrm{RMSE}$ as defined.\n- Round each $\\mathrm{RMSE}$ to exactly $6$ decimal places and print the four results as a single list $[r_1,r_2,r_3,r_4]$.\n\nThis procedure yields a set of four floating-point values, one for each test case, quantifying how the threshold parameter $\\tau$ and the note frequency $f_0$ affect the denoising quality under the prescribed deterministic noise. The case with $\\tau = 0$ reproduces the unfiltered baseline, while larger $\\tau$ values suppress weaker spectral content and, for these signals with bin-aligned sinusoids, preserve the dominant note components more effectively.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef fft_radix2(x: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Compute the DFT of a 1-D complex array x using a radix-2 Cooley–Tukey algorithm.\n    Length of x must be a power of two.\n    \"\"\"\n    x = np.asarray(x, dtype=np.complex128)\n    N = x.shape[0]\n    if N == 1:\n        return x.copy()\n    if N % 2 != 0:\n        raise ValueError(\"Input length must be a power of two for radix-2 FFT.\")\n    # Recursively compute FFT of even and odd indexed elements\n    X_even = fft_radix2(x[::2])\n    X_odd = fft_radix2(x[1::2])\n    # Twiddle factors\n    k = np.arange(N // 2, dtype=np.float64)\n    twiddle = np.exp(-2j * np.pi * k / N)\n    top = X_even + twiddle * X_odd\n    bottom = X_even - twiddle * X_odd\n    return np.concatenate((top, bottom))\n\ndef ifft_radix2(X: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Compute the inverse DFT using the conjugate trick and the radix-2 FFT.\n    \"\"\"\n    X = np.asarray(X, dtype=np.complex128)\n    N = X.shape[0]\n    # iDFT(x) = conj(DFT(conj(x))) / N\n    return np.conjugate(fft_radix2(np.conjugate(X))) / N\n\ndef is_power_of_two(n: int) -> bool:\n    return n > 0 and (n & (n - 1)) == 0\n\ndef generate_signals(Fs: int, N: int, f0: float):\n    \"\"\"\n    Generate clean sinusoid s_n and observed x_n = s_n + deterministic noise.\n    Noise frequencies are 1000 Hz and 3000 Hz with amplitudes 0.15 and 0.10, respectively.\n    \"\"\"\n    if not is_power_of_two(N):\n        raise ValueError(\"N must be a power of two.\")\n    t = np.arange(N, dtype=np.float64) / float(Fs)\n    s = np.sin(2.0 * np.pi * f0 * t)\n    noise = 0.15 * np.sin(2.0 * np.pi * 1000.0 * t) + 0.10 * np.sin(2.0 * np.pi * 3000.0 * t)\n    x = s + noise\n    return s, x\n\ndef spectral_threshold_filter(x: np.ndarray, tau: float) -> np.ndarray:\n    \"\"\"\n    Apply frequency-domain thresholding: zero coefficients below tau * max |X_k|.\n    Returns the filtered time-domain signal y (real-valued).\n    \"\"\"\n    X = fft_radix2(x.astype(np.complex128))\n    mags = np.abs(X)\n    M = mags.max() if X.size > 0 else 0.0\n    threshold = tau * M\n    mask = mags >= threshold\n    Y = X * mask\n    y = ifft_radix2(Y)\n    # Numerical residual imaginary part may appear due to finite precision.\n    return np.real(y)\n\ndef rmse(a: np.ndarray, b: np.ndarray) -> float:\n    diff = a - b\n    return float(np.sqrt(np.mean(diff * diff)))\n\ndef solve():\n    # Define the test cases from the problem statement: (Fs, N, f0, tau)\n    test_cases = [\n        (8192, 1024, 440.0, 0.25),\n        (8192, 1024, 512.0, 0.90),\n        (8192, 1024, 440.0, 0.00),\n        (8192, 1024, 2048.0, 0.75),\n    ]\n\n    results = []\n    for Fs, N, f0, tau in test_cases:\n        s, x = generate_signals(Fs, N, f0)\n        y = spectral_threshold_filter(x, tau)\n        value = rmse(y, s)\n        results.append(f\"{value:.6f}\")\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(results)}]\")\n\nif __name__ == \"__main__\":\n    solve()\n```", "id": "2383381"}, {"introduction": "While theoretical filter design often assumes infinite precision, real-world implementations are constrained by the limitations of digital hardware. This problem challenges you to think critically about a seemingly simple cascade of a filter and its inverse, which should ideally form an identity system.[@problem_id:2436629] You will analyze the practical numerical issues that arise from coefficient quantization and finite-precision arithmetic, exploring why perfect pole-zero cancellation is elusive and how these imperfections can amplify computational noise.", "problem": "A discrete-time, linear, time-invariant filter is given by the transfer function\n$$\nH(z) \\;=\\; \\frac{1 - 0.999\\,z^{-1}}{1 - 0.99\\,z^{-1}}.\n$$\nA signal $x[n]$ is processed by cascading $H(z)$ with its exact inverse $G(z) = 1/H(z)$, so that ideally the overall input-output transfer function is the identity. In practice, both $H(z)$ and $G(z)$ are implemented in finite precision using a fixed structure with coefficient quantization. Each coefficient is represented with absolute error at most $\\varepsilon_c$, where $\\varepsilon_c = 10^{-5}$, and arithmetic rounding is used. The implementation of each stage introduces additive, zero-mean, white, uncorrelated round-off noise $v_1[n]$ and $v_2[n]$, respectively, each with constant power spectral density $S_{v_i}(\\omega) = \\sigma_{v_i}^2$ for $i \\in \\{1,2\\}$, and both uncorrelated with $x[n]$.\n\nWhich of the following statements about the practical numerical issues in this cascade are correct?\n\nA. Exact pole-zero cancellation is highly sensitive to coefficient quantization; small coefficient perturbations can prevent perfect cancellation and yield significant deviations from the identity response, especially near frequencies where $\\lvert H(e^{j\\omega}) \\rvert$ is small.\n\nB. If $H(z)$ has any zero outside the unit circle, a stable, causal inverse $G(z)$ still exists because the zero will be canceled by a corresponding pole of $G(z)$, so the overall cascade remains stable.\n\nC. The round-off noise $v_1[n]$ generated in the first stage will be filtered by $G(z)$; therefore, it can be strongly amplified in frequency bands where $\\lvert H(e^{j\\omega}) \\rvert$ is small.\n\nD. Using single-precision floating-point arithmetic for the given $H(z)$ can cause loss of significance when evaluating differences like $1 - 0.999\\,z^{-1}$ for $z$ near the unit circle, degrading the effective precision of cancellation in the cascade.\n\nE. If both $H(z)$ and $G(z)$ are implemented with identically quantized coefficients and identical arithmetic, then the cascade is guaranteed to be exactly an identity system for all inputs $x[n]$.", "solution": "The problem statement is subjected to validation.\n\n**Step 1: Extract Givens**\n-   Filter transfer function: $H(z) = \\frac{1 - 0.999\\,z^{-1}}{1 - 0.99\\,z^{-1}}$.\n-   Inverse filter transfer function: $G(z) = 1/H(z)$.\n-   System configuration: A cascade of the first filter, $H(z)$, followed by the second filter, $G(z)$.\n-   Ideal system response: Identity, with overall transfer function $H(z)G(z) = 1$.\n-   Implementation details: Finite precision, fixed structure, coefficient quantization.\n-   Coefficient quantization error: Absolute error is at most $\\varepsilon_c = 10^{-5}$ for each coefficient.\n-   Arithmetic model: Rounding is used.\n-   Noise model: Additive, zero-mean, white, uncorrelated round-off noise sources, $v_1[n]$ and $v_2[n]$, are introduced at the output of the first and second stages, respectively.\n-   Noise properties: The power spectral density of each noise source is constant, $S_{v_i}(\\omega) = \\sigma_{v_i}^2$ for $i \\in \\{1,2\\}$. The noise sources are uncorrelated with each other and with the input signal $x[n]$.\n\n**Step 2: Validate Using Extracted Givens**\n-   **Scientifically Grounded**: The problem is based on fundamental and well-established principles of digital signal processing (DSP), specifically concerning the practical implementation of digital filters. The concepts of transfer functions, poles, zeros, stability, coefficient quantization, and round-off noise are central to the field. The problem is scientifically sound.\n-   **Well-Posed**: The problem provides a clear description of a system and asks for an evaluation of several statements regarding its behavior under finite-precision arithmetic. This is a well-defined task with a clear objective.\n-   **Objective**: The problem is stated using precise, standard technical terminology from DSP, free of ambiguity or subjective language.\n-   **Completeness and Consistency**: The provided information is sufficient to analyze the qualitative effects of finite precision. There are no missing definitions or contradictory constraints. The problem is self-contained.\n-   **Realism**: The scenario described is a classic and realistic problem in computational engineering, representative of challenges faced when implementing algorithms on hardware with limited numerical precision, such as in DSP processors or FPGAs. The filter structure and coefficient values are typical.\n\n**Step 3: Verdict and Action**\nThe problem statement is valid. It is a standard, well-posed problem in the analysis of finite-precision effects in digital filters. The solution process will proceed.\n\n***\n\n**System Analysis**\n\nThe ideal transfer function of the first filter is $H(z) = \\frac{1 - 0.999\\,z^{-1}}{1 - 0.99\\,z^{-1}}$. This filter has a zero at $z_0 = 0.999$ and a pole at $p_0 = 0.99$. Since both the pole and the zero are inside the unit circle ($\\lvert p_0 \\rvert < 1$ and $\\lvert z_0 \\rvert < 1$), the filter $H(z)$ is stable, causal, and minimum-phase.\n\nThe ideal inverse filter is $G(z) = 1/H(z) = \\frac{1 - 0.99\\,z^{-1}}{1 - 0.999\\,z^{-1}}$. This filter has a zero at $z_1 = 0.99$ and a pole at $p_1 = 0.999$. Since $\\lvert p_1 \\rvert < 1$, the inverse filter $G(z)$ is also stable and causal.\n\nThe cascade of these two filters ideally results in an overall transfer function of $T(z) = H(z)G(z) = 1$, which is an identity system. This relies on perfect cancellation of the pole of $H(z)$ with the zero of $G(z)$, and the zero of $H(z)$ with the pole of $G(z)$.\n\nIn practice, with finite precision, let the implemented transfer functions be $H_q(z)$ and $G_q(z)$. The coefficients are quantized, and arithmetic operations introduce round-off noise.\n\n**Option-by-Option Analysis**\n\n**A. Exact pole-zero cancellation is highly sensitive to coefficient quantization; small coefficient perturbations can prevent perfect cancellation and yield significant deviations from the identity response, especially near frequencies where $\\lvert H(e^{j\\omega}) \\rvert$ is small.**\nThe pole $p_0=0.99$ and the zero $z_0=0.999$ of $H(z)$ are very close to the unit circle and also relatively close to each other. The locations of poles and zeros of a filter can be highly sensitive to small perturbations in the filter coefficients. This sensitivity is exacerbated when poles or zeros are clustered or located near the unit circle.\nDue to coefficient quantization, the pole of the implemented filter $H_q(z)$ will be at $p_{0q} \\neq 0.99$, and the zero of the implemented inverse $G_q(z)$ will be at $z_{1q} \\neq 0.99$. In general, $p_{0q} \\neq z_{1q}$. Similarly, the zero of $H_q(z)$ and the pole of $G_q(z)$ will not be identical. Therefore, the pole-zero cancellation will be imperfect.\nThe overall transfer function will be $T_q(z) = H_q(z)G_q(z) \\neq 1$. This results in a \"pole-zero dipole\" (a nearly-cancelling pair) near $z=0.99$ and another near $z=0.999$. Such dipoles, particularly when close to the unit circle, can cause significant magnitude and phase distortion, deviating from the flat response of an identity system.\nThe frequency response of $H(z)$ is smallest near $\\omega=0$. At $\\omega = 0$, $H(e^{j0}) = \\frac{1-0.999}{1-0.99} = \\frac{0.001}{0.01} = 0.1$. In this region, small absolute errors in the quantized coefficients (which are close to $1$) lead to large relative errors in the evaluation of terms like $1 - c$, which define the DC gain. This high sensitivity confirms that deviations will be significant. The statement is a correct and fundamental observation in filter implementation.\n**Verdict: Correct.**\n\n**B. If $H(z)$ has any zero outside the unit circle, a stable, causal inverse $G(z)$ still exists because the zero will be canceled by a corresponding pole of $G(z)$, so the overall cascade remains stable.**\nThis statement is fundamentally incorrect. If a filter $H(z)$ has a zero $z_0$ such that $\\lvert z_0 \\rvert > 1$ (a non-minimum phase system), its inverse $G(z) = 1/H(z)$ will have a pole at $p_0 = z_0$, with $\\lvert p_0 \\rvert > 1$. A linear time-invariant (LTI) system with a pole outside the unit circle cannot be both stable and causal. A causal system with such a pole is unstable. A stable system can be constructed, but it must be anti-causal. The problem implicitly assumes causal filters, which are the standard for real-time processing. Thus, a \"stable, causal inverse $G(z)$\" does not exist. While the theoretical product $H(z)G(z)=1$ is stable, an unstable intermediate stage ($G(z)$) is not physically realizable, as its internal states would grow without bound, leading to overflow.\n**Verdict: Incorrect.**\n\n**C. The round-off noise $v_1[n]$ generated in the first stage will be filtered by $G(z)$; therefore, it can be strongly amplified in frequency bands where $\\lvert H(e^{j\\omega}) \\rvert$ is small.**\nAccording to the problem description, the model for the cascade is as follows: The input $x[n]$ is filtered by $H(z)$, producing an intermediate signal to which the noise $v_1[n]$ is added. This sum is then fed into the second filter, $G(z)$, at the output of which a second noise term $v_2[n]$ is added.\nThe noise component at the final output due to $v_1[n]$ is the result of filtering $v_1[n]$ with $G_q(z)$, the quantized implementation of $G(z)$. The output noise power spectral density from this source is $S_{y,v1}(\\omega) = S_{v1}(\\omega) \\lvert G_q(e^{j\\omega}) \\rvert^2 = \\sigma_{v1}^2 \\lvert G_q(e^{j\\omega}) \\rvert^2$.\nIdeally, $\\lvert G(e^{j\\omega}) \\rvert = 1 / \\lvert H(e^{j\\omega}) \\rvert$. This relationship holds approximately for the quantized filters.\nTherefore, in frequency bands where the magnitude response of the first filter, $\\lvert H(e^{j\\omega}) \\rvert$, is small, the magnitude response of the inverse filter, $\\lvert G(e^{j\\omega}) \\rvert$, will be large.\nFor the given filter, at $\\omega=0$, $\\lvert H(e^{j0}) \\rvert = 0.1$. This is a region of small magnitude. Consequently, $\\lvert G(e^{j0}) \\rvert = 1/0.1 = 10$. The noise power gain at this frequency is $\\lvert G(e^{j0}) \\rvert^2 = 100$. This constitutes strong amplification.\n**Verdict: Correct.**\n\n**D. Using single-precision floating-point arithmetic for the given $H(z)$ can cause loss of significance when evaluating differences like $1 - 0.999\\,z^{-1}$ for $z$ near the unit circle, degrading the effective precision of cancellation in the cascade.**\nThe filter structure involves calculating terms of the form $1 - c \\cdot z^{-1}$, where $c$ is a coefficient close to $1$ (here, $0.999$ and $0.99$). For frequencies $\\omega$ near $0$, $z=e^{j\\omega}$ is a complex number close to $1+j0$. Thus, the product $c \\cdot z^{-1}$ is a value very close to $c$, which itself is very close to $1$. The operation becomes a subtraction of two nearly equal numbers. This operation is known to cause \"catastrophic cancellation\" or \"loss of significance\" in floating-point arithmetic. The result of the subtraction has far fewer significant digits than the original operands, leading to a large relative error. This numerical inaccuracy in evaluating the numerator and denominator polynomials degrades the effective precision of the pole and zero locations of the implemented filter. This, in turn, worsens the pole-zero cancellation in the cascade, compounding the errors from coefficient quantization alone. This is a well-known problem for direct-form filter implementations with poles or zeros near $z=1$.\n**Verdict: Correct.**\n\n**E. If both $H(z)$ and $G(z)$ are implemented with identically quantized coefficients and identical arithmetic, then the cascade is guaranteed to be exactly an identity system for all inputs $x[n]$.**\nLet the quantizer be $Q(\\cdot)$. The implemented transfer functions are $H_q(z) = \\frac{1 - Q(0.999)z^{-1}}{1 - Q(0.99)z^{-1}}$ and $G_q(z) = \\frac{1 - Q(0.99)z^{-1}}{1 - Q(0.999)z^{-1}}$.\nThe product of these transfer functions is $T_q(z) = H_q(z)G_q(z) = 1$. This suggests that the signal path of the system is indeed an identity. The output signal component is exactly the input signal, $x[n]$.\nHowever, the problem explicitly states that the implementation (\"identical arithmetic\") introduces additive round-off noise $v_1[n]$ and $v_2[n]$. An \"exactly an identity system\" implies that for any input $x[n]$, the output must be $y[n]=x[n]$. The total output of the practical system is $y[n] = x[n] + v_1[n] \\star g_q[n] + v_2[n]$, where $g_q[n]$ is the impulse response of $G_q(z)$. Since the noise terms $v_1[n]$ and $v_2[n]$ are generally non-zero, the noise component at the output, $v_1[n] \\star g_q[n] + v_2[n]$, is also non-zero.\nTherefore, $y[n] \\neq x[n]$. The system is not an exact identity system because of the presence of arithmetic round-off noise. The statement incorrectly ignores this crucial aspect of practical implementation.\n**Verdict: Incorrect.**", "answer": "$$\\boxed{ACD}$$", "id": "2436629"}]}