{"hands_on_practices": [{"introduction": "We begin our hands-on journey by confronting the fundamental challenge of stiff systems: numerical stability. Many intuitive explicit methods, like Forward Euler, fail catastrophically when applied to stiff problems with practical step sizes. This exercise provides a dramatic demonstration of this failure by integrating a stiff equation backward in time, a scenario where the instability of explicit methods becomes glaringly obvious, while a well-chosen Implicit Runge-Kutta (IRK) method remains robust and accurate [@problem_id:2402097].", "problem": "Consider the linear stiff ordinary differential equation (ODE) given by $y'(t) = \\lambda\\, y(t)$ with a prescribed terminal value $y(T) = 1$. The goal is to compute $y(0)$ by integrating backward in time from $t = T$ to $t = 0$ using a negative step size. The exact solution is $y(t) = \\exp(\\lambda (t - T))$, hence $y(0) = \\exp(-\\lambda T)$.\n\nDefine a family of one-step methods as follows for a single step from $t_n$ to $t_{n+1} = t_n + h$, where $h < 0$ denotes a negative time step and $z = h \\lambda$:\n- The explicit forward Euler method is $y_{n+1} = y_n + h \\lambda y_n = (1 + z)\\, y_n$.\n- The implicit Runge–Kutta (IRK) method to be used is the two-stage singly diagonally implicit Runge–Kutta (SDIRK) scheme with parameter $\\gamma = 1 - \\frac{1}{\\sqrt{2}}$. Its Butcher tableau is\n$$\n\\begin{array}{c|cc}\n\\gamma & \\gamma & 0 \\\\\n1 & 1-\\gamma & \\gamma \\\\\n\\hline\n& 1-\\gamma & \\gamma\n\\end{array}\n$$\nFor the scalar linear test equation $y' = \\lambda y$, this SDIRK method has the stability function\n$$\nR(z) = \\frac{1 + (1 - 2\\gamma)\\, z}{(1 - \\gamma z)^2},\n$$\nso that one step maps $y_{n+1} = R(z)\\, y_n$.\n\nYour program must, for each test case, perform $N$ uniform steps of size $h = -T/N$ starting from $y_N = y(T) = 1$ and stepping backward to $t = 0$, once using the explicit forward Euler update factor $(1 + z)$, and once using the SDIRK stability function $R(z)$. Let the two numerical approximations at $t = 0$ be denoted by $y_{\\text{explicit}}(0)$ and $y_{\\text{IRK}}(0)$, respectively. Let the exact value be $y_{\\text{exact}}(0) = \\exp(-\\lambda T)$. For each test case, compute the absolute errors\n$$\ne_{\\text{IRK}} = \\left| y_{\\text{IRK}}(0) - y_{\\text{exact}}(0) \\right|,\\quad\ne_{\\text{explicit}} = \\left| y_{\\text{explicit}}(0) - y_{\\text{exact}}(0) \\right|.\n$$\n\nUse the following test suite of parameters $(\\lambda, T, N)$:\n- Test 1 (stiff, moderately large backward step): $(\\lambda, T, N) = (1000, 0.1, 5)$.\n- Test 2 (boundary of explicit Euler stability for a single backward step): $(\\lambda, T, N) = (2, 1, 1)$.\n- Test 3 (very stiff, moderately large backward steps): $(\\lambda, T, N) = (5000, 0.05, 5)$.\n\nAll quantities are dimensionless; no physical units are involved.\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, in the following order:\n$[e_{\\text{IRK}}^{(1)}, e_{\\text{explicit}}^{(1)}, e_{\\text{IRK}}^{(2)}, e_{\\text{explicit}}^{(2)}, e_{\\text{IRK}}^{(3)}, e_{\\text{explicit}}^{(3)}]$, where the superscript indicates the test case index. Each entry must be a floating-point number.", "solution": "The problem statement has been critically evaluated and is deemed valid. It constitutes a well-posed problem in computational mathematics, specifically in the numerical analysis of stiff ordinary differential equations. All provided definitions, constants, and equations align with established principles. The task is to compare the performance of an explicit and an implicit Runge-Kutta method on a stiff problem, which is a canonical exercise for demonstrating the concept of numerical stability.\n\nThe core of the problem lies in solving the linear ordinary differential equation (ODE) $y'(t) = \\lambda y(t)$ with a terminal condition $y(T) = 1$. The integration is performed backward in time from $t=T$ to $t=0$. The exact solution to this initial value problem is $y(t) = C \\exp(\\lambda t)$. Using the terminal condition, we find $1 = C \\exp(\\lambda T)$, which implies $C = \\exp(-\\lambda T)$. Thus, the exact solution is $y(t) = \\exp(\\lambda(t-T))$. The exact value at the initial time $t=0$ is therefore $y_{\\text{exact}}(0) = \\exp(-\\lambda T)$.\n\nWe are required to approximate this solution using two numerical schemes over $N$ uniform steps. The time step for backward integration from $t=T$ to $t=0$ is negative, given by $h = (0 - T) / N = -T/N$.\n\nFor the scalar linear test equation $y'=\\lambda y$, a single step of a one-step method from $y_n$ to $y_{n+1}$ can be expressed as $y_{n+1} = R(z) y_n$, where $R(z)$ is the stability function of the method and $z = h\\lambda$. Consequently, after $N$ steps starting from an initial value $y_0 = y(T) = 1$, the numerical approximation at the final time $t_N = T+Nh = T+N(-T/N) = 0$ is given by $y_{\\text{num}}(0) = [R(z)]^N y_0 = [R(z)]^N$.\n\nThe stability of the numerical integration depends on the magnitude of the stability function, $|R(z)|$. For a stable computation, we require $|R(z)| \\leq 1$. If $|R(z)| > 1$, the numerical solution will diverge, exhibiting exponential growth in error. The provided test cases involve large positive values of $\\lambda$ and negative $h$, resulting in large negative values for $z = h\\lambda$. This represents a stiff problem scenario.\n\nThe two methods to be compared are:\n$1$. The explicit forward Euler method. Its stability function is $R_{\\text{explicit}}(z) = 1 + z$. The numerical approximation at $t=0$ is $y_{\\text{explicit}}(0) = (1 + h\\lambda)^N$. The stability region for this method is $|1+z| \\le 1$, which is a disk of radius $1$ centered at $z=-1$ in the complex plane. For real $z$, this corresponds to the interval $[-2, 0]$.\n\n$2$. The two-stage singly diagonally implicit Runge-Kutta (SDIRK) method. The stability function is given as $R_{\\text{IRK}}(z) = \\frac{1 + (1 - 2\\gamma)z}{(1 - \\gamma z)^2}$, with the parameter $\\gamma = 1 - \\frac{1}{\\sqrt{2}}$. The numerical approximation at $t=0$ is $y_{\\text{IRK}}(0) = [R_{\\text{IRK}}(h\\lambda)]^N$. This method is L-stable, meaning it is A-stable (its stability region contains the entire left half-plane, $\\text{Re}(z) \\le 0$) and additionally $\\lim_{z \\to -\\infty} |R(z)| = 0$. This property is highly desirable for stiff problems as it effectively damps out high-frequency (transient) components.\n\nThe computational procedure for each test case $(\\lambda, T, N)$ is as follows:\n$1$. Calculate the step size $h = -T/N$ and the parameter $z = h\\lambda$.\n$2$. Compute the numerical solutions $y_{\\text{explicit}}(0) = (1+z)^N$ and $y_{\\text{IRK}}(0) = [R_{\\text{IRK}}(z)]^N$.\n$3$. Compute the exact solution $y_{\\text{exact}}(0) = \\exp(-\\lambda T)$.\n$4$. Calculate the absolute errors $e_{\\text{explicit}} = | y_{\\text{explicit}}(0) - y_{\\text{exact}}(0) |$ and $e_{\\text{IRK}} = | y_{\\text{IRK}}(0) - y_{\\text{exact}}(0) |$.\n\nThis procedure is implemented for each of the three specified test cases, and the results are presented in the required format. The stiff cases (Test $1$ and $3$) are expected to show a dramatic failure of the explicit method due to instability ($|z| > 2$), while the L-stable SDIRK method should yield a small, controlled error. Test $2$ places the explicit method at the very boundary of its stability region, which is also expected to produce a poor result compared to the SDIRK method.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Computes and compares the error of explicit Euler and a SDIRK method\n    for a stiff ODE integrated backward in time.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        (1000.0, 0.1, 5),   # Test 1 (stiff, moderately large backward step)\n        (2.0, 1.0, 1),      # Test 2 (boundary of explicit Euler stability)\n        (5000.0, 0.05, 5),  # Test 3 (very stiff, moderately large backward steps)\n    ]\n\n    results = []\n    \n    # Define the SDIRK method parameter gamma\n    gamma = 1.0 - 1.0 / np.sqrt(2.0)\n\n    for case in test_cases:\n        lambda_val, T, N = case\n\n        # Calculate the uniform negative step size h and the parameter z\n        h = -T / N\n        z = h * lambda_val\n\n        # --- Method 1: Explicit Forward Euler ---\n        # The stability function for forward Euler is R(z) = 1 + z.\n        R_explicit = 1.0 + z\n        # The numerical solution at t=0 is obtained by applying the update N times, starting from y(T)=1.\n        y_explicit_0 = R_explicit**N\n\n        # --- Method 2: SDIRK ---\n        # The stability function for the SDIRK method is R(z) = (1 + (1-2g)z) / (1 - gz)^2.\n        R_irk_numerator = 1.0 + (1.0 - 2.0 * gamma) * z\n        R_irk_denominator = (1.0 - gamma * z)**2\n        R_irk = R_irk_numerator / R_irk_denominator\n        # The numerical solution at t=0 after N steps.\n        y_irk_0 = R_irk**N\n\n        # --- Exact Solution ---\n        # The exact solution is y(t) = exp(lambda * (t - T)), so y(0) = exp(-lambda*T).\n        y_exact_0 = np.exp(-lambda_val * T)\n\n        # --- Compute Absolute Errors ---\n        # error = | y_numerical(0) - y_exact(0) |\n        e_irk = np.abs(y_irk_0 - y_exact_0)\n        e_explicit = np.abs(y_explicit_0 - y_exact_0)\n\n        results.append(e_irk)\n        results.append(e_explicit)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n\n```", "id": "2402097"}, {"introduction": "Having seen *why* implicit methods are indispensable, we now focus on *how* to build one. This practice guides you through the implementation of a powerful and efficient Singly Diagonally Implicit Runge–Kutta (SDIRK) method, which involves solving nonlinear algebraic equations for the internal stages using Newton's method. You will apply your custom-built solver to a test suite of canonical stiff problems from physics and chemistry, gaining invaluable experience in developing and validating robust numerical software for real-world scientific challenges [@problem_id:2402149].", "problem": "You are given the initial value problem defined by the ordinary differential equation $y'(t) = f(t,y)$ with initial condition $y(t_0) = y_0$, where $y \\in \\mathbb{R}^d$. Implement a fixed-step, two-stage Singly Diagonally Implicit Runge–Kutta (SDIRK) method defined by the Butcher tableau with diagonal coefficient $\\gamma = 1 - 1/\\sqrt{2}$:\n$$\n\\begin{array}{c|cc}\n\\gamma & \\gamma & 0 \\\\\n1 & 1 - 2\\gamma & \\gamma \\\\\n\\hline\n & \\tfrac{1}{2} & \\tfrac{1}{2}\n\\end{array}\n$$\nThat is, $A = \\begin{bmatrix} \\gamma & 0 \\\\ 1 - 2\\gamma & \\gamma \\end{bmatrix}$, $b = [\\tfrac{1}{2}, \\tfrac{1}{2}]$, $c = [\\gamma, 1]^\\top$ with $\\gamma = 1 - 1/\\sqrt{2}$. For each time step of size $h > 0$, compute the internal stages and form the update $y_{n+1} = y_n + h \\sum_{i=1}^2 b_i f(t_n + c_i h, Y_i)$. The nonlinear algebraic equations for the stages $Y_i$ must be solved to an absolute tolerance of $10^{-12}$ in the infinity norm. Assume the Jacobian $\\partial f/\\partial y$ is available for each test case.\n\nYour implementation must be general for dimension $d \\ge 1$, use a fixed step size $h$ that divides $T - t_0$ exactly so that the number of steps $N = (T - t_0)/h$ is an integer, and must work for stiff problems.\n\nTest Suite. Implement the solver and apply it to the following five test cases, each defined by a function $f(t,y)$, its Jacobian $J(t,y) = \\partial f/\\partial y$, initial data, interval, and step size:\n\n- Test $1$ (scalar linear stiff decay):\n  - Dimension: $d = 1$.\n  - Right-hand side: $f(t,y) = -\\lambda y$ with $\\lambda = 1000$.\n  - Jacobian: $J(t,y) = [-\\lambda]$.\n  - Initial condition: $y_0 = 1$ at $t_0 = 0$.\n  - Final time: $T = 1$.\n  - Step size: $h = 0.1$.\n\n- Test $2$ (stiff Van der Pol oscillator):\n  - Dimension: $d = 2$ with $y = [x, v]^\\top$.\n  - Parameter: $\\mu = 100$.\n  - Right-hand side: $$f(t, [x, v]^\\top) = \\begin{bmatrix} v \\\\ \\mu (1 - x^2) v - x \\end{bmatrix}$$.\n  - Jacobian: $$J(t, [x, v]^\\top) = \\begin{bmatrix} 0 & 1 \\\\ -2\\mu x v - 1 & \\mu (1 - x^2) \\end{bmatrix}$$.\n  - Initial condition: $y_0 = [2, 0]^\\top$ at $t_0 = 0$.\n  - Final time: $T = 0.3$.\n  - Step size: $h = 0.001$.\n  - Required reported quantity: the first component $x(T)$.\n\n- Test $3$ (Robertson chemical kinetics, stiff, three species):\n  - Dimension: $d = 3$ with $y = [y_1, y_2, y_3]^\\top$.\n  - Right-hand side: \n    $$\n    \\begin{aligned}\n    f_1 &= -0.04 y_1 + 10^4 y_2 y_3, \\\\\n    f_2 &= 0.04 y_1 - 10^4 y_2 y_3 - 3 \\cdot 10^7 y_2^2, \\\\\n    f_3 &= 3 \\cdot 10^7 y_2^2.\n    \\end{aligned}\n    $$\n  - Jacobian:\n    $$\n    J = \\begin{bmatrix}\n    -0.04 & 10^4 y_3 & 10^4 y_2 \\\\\n    0.04 & -10^4 y_3 - 6 \\cdot 10^7 y_2 & -10^4 y_2 \\\\\n    0 & 6 \\cdot 10^7 y_2 & 0\n    \\end{bmatrix}.\n    $$\n  - Initial condition: $y_0 = [1, 0, 0]^\\top$ at $t_0 = 0$.\n  - Final time: $T = 10^{-4}$.\n  - Step size: $h = 10^{-6}$.\n  - Required reported quantity: the third component $y_3(T)$.\n\n- Test $4$ (zero vector field, invariance check):\n  - Dimension: $d = 1$.\n  - Right-hand side: $f(t,y) = 0$.\n  - Jacobian: $J(t,y) = [0]$.\n  - Initial condition: $y_0 = -5.5$ at $t_0 = 0$.\n  - Final time: $T = 3.7$.\n  - Step size: $h = 0.37$.\n\n- Test $5$ (linear, non-normal, moderately stiff $2 \\times 2$ system):\n  - Dimension: $d = 2$ with $y = [y_1, y_2]^\\top$.\n  - Matrix: $$A = \\begin{bmatrix} -50 & 49 \\\\ 0 & -1 \\end{bmatrix}$$.\n  - Right-hand side: $f(t,y) = A y$.\n  - Jacobian: $J(t,y) = A$.\n  - Initial condition: $y_0 = [1, 1]^\\top$ at $t_0 = 0$.\n  - Final time: $T = 1$.\n  - Step size: $h = 0.05$.\n  - Required reported quantity: the first component $y_1(T)$.\n\nFinal Output Format. Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, in the order of Tests $1$ through $5$, where each entry is a real number rounded to $10$ decimal places. For Tests $2$ and $5$, report the first component at the final time; for Test $3$, report the third component at the final time; for Tests $1$ and $4$, report the scalar state at the final time. For example, the output format must be exactly\n$[r_1,r_2,r_3,r_4,r_5]$\nwith no spaces, where each $r_i$ is rounded to $10$ decimal places as specified.", "solution": "The problem statement has been critically examined and is determined to be valid. It is scientifically grounded in the theory of numerical methods for ordinary differential equations, is well-posed with all necessary information provided, and is formulated objectively. The provided test cases are standard benchmarks for stiff integrators. We may proceed with the solution.\n\nThe task is to implement a specific two-stage Singly Diagonally Implicit Runge-Kutta (SDIRK) method for solving the initial value problem $y'(t) = f(t,y)$, $y(t_0) = y_0$. The method is defined by the Butcher tableau:\n$$\n\\begin{array}{c|cc}\n\\gamma & \\gamma & 0 \\\\\n1 & 1 - 2\\gamma & \\gamma \\\\\n\\hline\n & \\tfrac{1}{2} & \\tfrac{1}{2}\n\\end{array}\n$$\nwith the parameter $\\gamma = 1 - 1/\\sqrt{2}$. This corresponds to coefficients $c_1 = \\gamma$, $c_2 = 1$; $b_1 = 1/2$, $b_2 = 1/2$; and the matrix $A = \\begin{bmatrix} \\gamma & 0 \\\\ 1 - 2\\gamma & \\gamma \\end{bmatrix}$.\n\nA general $s$-stage Runge-Kutta method advances the solution from time $t_n$ to $t_{n+1} = t_n + h$ using the formula:\n$$ y_{n+1} = y_n + h \\sum_{i=1}^s b_i k_i $$\nwhere the stage derivatives $k_i$ are related to the stage values $Y_i$ by $k_i = f(t_n + c_i h, Y_i)$. The stages $Y_i$ are defined implicitly by the system of equations:\n$$ Y_i = y_n + h \\sum_{j=1}^s a_{ij} k_j = y_n + h \\sum_{j=1}^s a_{ij} f(t_n + c_j h, Y_j) $$\nFor the specified method, the stages are given by:\n$$ Y_1 = y_n + h \\gamma k_1 $$\n$$ Y_2 = y_n + h (1 - 2\\gamma) k_1 + h \\gamma k_2 $$\nSubstituting the definition of $k_i$ yields a system of equations for the stage derivatives $k_1, k_2 \\in \\mathbb{R}^d$:\n$$ k_1 = f(t_n + \\gamma h, y_n + h \\gamma k_1) $$\n$$ k_2 = f(t_n + h, y_n + h(1 - 2\\gamma)k_1 + h \\gamma k_2) $$\nThe lower triangular structure of the matrix $A$ allows these equations to be solved sequentially. Such methods are termed Diagonally Implicit Runge-Kutta (DIRK) methods. Because the diagonal elements $a_{11}$ and $a_{22}$ are identical ($a_{ii} = \\gamma$), this is a Singly DIRK (SDIRK) method, which offers computational advantages for stiff systems.\n\nThe core of the implementation is solving these nonlinear algebraic equations for $k_1$ and $k_2$ at each time step. For stiff problems, where the Jacobian $\\partial f / \\partial y$ has large eigenvalues, these equations cannot be solved by simple functional iteration. Instead, a robust root-finding algorithm like Newton's method is required.\n\nFor the first stage, we must find the root of the function $G_1(k_1) = 0$, where:\n$$ G_1(k_1) = k_1 - f(t_n + \\gamma h, y_n + h \\gamma k_1) $$\nThe Newton iteration for $k_1$ is given by:\n$$ k_1^{(m+1)} = k_1^{(m)} - [J_{G_1}(k_1^{(m)})]^{-1} G_1(k_1^{(m)}) $$\nwhere $m$ is the iteration index and $J_{G_1}$ is the Jacobian of $G_1$ with respect to $k_1$:\n$$ J_{G_1}(k_1) = \\frac{\\partial G_1}{\\partial k_1} = I - h \\gamma \\frac{\\partial f}{\\partial y}(t_n + \\gamma h, y_n + h \\gamma k_1) $$\nHere, $I$ is the identity matrix of dimension $d$. The iteration requires solving a linear system at each step for the correction $\\Delta k_1^{(m)}$:\n$$ (I - h \\gamma J_f) \\Delta k_1^{(m)} = -G_1(k_1^{(m)}) $$\nwhere $J_f$ is the Jacobian of $f$, evaluated at $(t_n + \\gamma h, y_n + h \\gamma k_1^{(m)})$. The iteration proceeds from an initial guess, such as $k_1^{(0)} = \\mathbf{0}$, until the infinity norm of the residual, $||G_1(k_1^{(m)})||_\\infty$, falls below the specified tolerance of $10^{-12}$.\n\nOnce $k_1$ has converged, we solve for the second stage derivative, $k_2$, by finding the root of $G_2(k_2) = 0$:\n$$ G_2(k_2) = k_2 - f(t_n + h, y_n + h(1-2\\gamma)k_1 + h \\gamma k_2) $$\nThe Newton iteration for $k_2$ is analogous. The corresponding linear system for the correction $\\Delta k_2^{(m)}$ is:\n$$ (I - h \\gamma J_f) \\Delta k_2^{(m)} = -G_2(k_2^{(m)}) $$\nwhere $J_f$ is now evaluated at $(t_n + h, y_n + h(1-2\\gamma)k_1 + h \\gamma k_2^{(m)})$. The matrix of the linear system, $I - h\\gamma J_f$, has the same structure for both stages, which is the defining characteristic of an SDIRK method. A full Newton method, where the Jacobian $J_f$ is re-evaluated at each iteration, will be used for maximal robustness.\n\nAfter both $k_1$ and $k_2$ are computed to the required tolerance, the solution is advanced:\n$$ y_{n+1} = y_n + \\frac{h}{2} (k_1 + k_2) $$\nThis entire procedure is repeated for the specified number of steps, $N = (T-t_0)/h$, to obtain the solution at the final time $T$. The implementation must be general for any dimension $d \\ge 1$. The provision of the analytical Jacobian for each test case is critical for the efficiency and accuracy of the Newton solver, particularly for stiff systems. The final presented code rigorously follows this logical and numerical-analytic framework.", "answer": "```python\nimport numpy as np\n\ndef sdirk_solver(f, jac, y0, t0, T, h):\n    \"\"\"\n    Solves an initial value problem using a 2-stage SDIRK method.\n\n    Args:\n        f (callable): The right-hand side function f(t, y).\n        jac (callable): The Jacobian of f, J(t, y).\n        y0 (np.ndarray): The initial condition vector.\n        t0 (float): The initial time.\n        T (float): The final time.\n        h (float): The fixed step size.\n\n    Returns:\n        np.ndarray: The solution vector at time T.\n    \"\"\"\n    gamma = 1.0 - 1.0 / np.sqrt(2.0)\n    b1, b2 = 0.5, 0.5\n    a11 = gamma\n    a21 = 1.0 - 2.0 * gamma\n    a22 = gamma\n    c1, c2 = gamma, 1.0\n    tol = 1e-12\n    max_newton_iter = 50\n    dim = len(y0)\n    identity = np.eye(dim)\n\n    # Use np.isclose for robust comparison with floating point numbers\n    num_steps = round((T - t0) / h)\n    if not np.isclose(t0 + num_steps * h, T):\n        raise ValueError(\"Step size h must divide the interval T-t0 exactly.\")\n        \n    t = t0\n    y = y0.copy()\n\n    for _ in range(num_steps):\n        # Stage 1\n        k1 = np.zeros(dim)\n        for _ in range(max_newton_iter):\n            y1_arg = y + h * a11 * k1\n            t1_arg = t + c1 * h\n            g1 = k1 - f(t1_arg, y1_arg)\n            \n            if np.linalg.norm(g1, ord=np.inf) < tol:\n                break\n                \n            j_f_val = jac(t1_arg, y1_arg)\n            m_matrix = identity - h * a11 * j_f_val\n            delta_k1 = np.linalg.solve(m_matrix, -g1)\n            k1 += delta_k1\n        else:\n            raise RuntimeError(\"Newton's method failed to converge for stage 1.\")\n\n        # Stage 2\n        k2 = np.zeros(dim)\n        for _ in range(max_newton_iter):\n            y2_arg = y + h * a21 * k1 + h * a22 * k2\n            t2_arg = t + c2 * h\n            g2 = k2 - f(t2_arg, y2_arg)\n\n            if np.linalg.norm(g2, ord=np.inf) < tol:\n                break\n\n            j_f_val = jac(t2_arg, y2_arg)\n            m_matrix = identity - h * a22 * j_f_val\n            delta_k2 = np.linalg.solve(m_matrix, -g2)\n            k2 += delta_k2\n        else:\n            raise RuntimeError(\"Newton's method failed to converge for stage 2.\")\n            \n        y += h * (b1 * k1 + b2 * k2)\n        t += h\n        \n    return y\n\ndef solve():\n    \"\"\"\n    Defines and runs the test suite for the SDIRK solver.\n    \"\"\"\n    test_cases = [\n        {\n            \"id\": 1,\n            \"f\": lambda t, y: -1000.0 * y,\n            \"jac\": lambda t, y: np.array([[-1000.0]]),\n            \"y0\": np.array([1.0]),\n            \"t0\": 0.0,\n            \"T\": 1.0,\n            \"h\": 0.1,\n            \"report_idx\": 0,\n        },\n        {\n            \"id\": 2,\n            \"f\": (lambda mu: lambda t, y: np.array([y[1], mu * (1 - y[0]**2) * y[1] - y[0]]))(100.0),\n            \"jac\": (lambda mu: lambda t, y: np.array([[0, 1.0], [-2*mu*y[0]*y[1] - 1.0, mu*(1-y[0]**2)]]))(100.0),\n            \"y0\": np.array([2.0, 0.0]),\n            \"t0\": 0.0,\n            \"T\": 0.3,\n            \"h\": 0.001,\n            \"report_idx\": 0,\n        },\n        {\n            \"id\": 3,\n            \"f\": lambda t, y: np.array([\n                -0.04 * y[0] + 1e4 * y[1] * y[2],\n                0.04 * y[0] - 1e4 * y[1] * y[2] - 3e7 * y[1]**2,\n                3e7 * y[1]**2\n            ]),\n            \"jac\": lambda t, y: np.array([\n                [-0.04, 1e4 * y[2], 1e4 * y[1]],\n                [0.04, -1e4 * y[2] - 6e7 * y[1], -1e4 * y[1]],\n                [0.0, 6e7 * y[1], 0.0]\n            ]),\n            \"y0\": np.array([1.0, 0.0, 0.0]),\n            \"t0\": 0.0,\n            \"T\": 1e-4,\n            \"h\": 1e-6,\n            \"report_idx\": 2,\n        },\n        {\n            \"id\": 4,\n            \"f\": lambda t, y: 0.0 * y,\n            \"jac\": lambda t, y: np.array([[0.0]]),\n            \"y0\": np.array([-5.5]),\n            \"t0\": 0.0,\n            \"T\": 3.7,\n            \"h\": 0.37,\n            \"report_idx\": 0,\n        },\n        {\n            \"id\": 5,\n            \"f\": (lambda A: lambda t, y: A @ y)(np.array([[-50.0, 49.0], [0.0, -1.0]])),\n            \"jac\": (lambda A: lambda t, y: A)(np.array([[-50.0, 49.0], [0.0, -1.0]])),\n            \"y0\": np.array([1.0, 1.0]),\n            \"t0\": 0.0,\n            \"T\": 1.0,\n            \"h\": 0.05,\n            \"report_idx\": 0,\n        }\n    ]\n\n    results = []\n    for case in test_cases:\n        y_final = sdirk_solver(case[\"f\"], case[\"jac\"], case[\"y0\"], case[\"t0\"], case[\"T\"], case[\"h\"])\n        results.append(y_final[case[\"report_idx\"]])\n\n    # Format output as specified: list of strings rounded to 10 decimal places.\n    formatted_results = [f\"{r:.10f}\" for r in results]\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```", "id": "2402149"}, {"introduction": "To deepen our understanding, we now compare two different implicit methods that, despite having distinct Butcher tableaus, share the same order of accuracy. This exercise introduces the elegant Kronecker product formulation for analyzing IRK methods on linear systems and pushes you to investigate the theoretical underpinnings of their behavior. By comparing the implicit midpoint rule and the trapezoidal rule, you will discover that for linear problems, they are theoretically identical, a non-obvious result that highlights the profound connection between a method's stability function and its numerical output [@problem_id:2402175].", "problem": "You are to implement and compare two distinct implicit Runge–Kutta methods of the same algebraic order on a stiff linear system. The comparison must be quantitative, using a mathematically defined error metric, and the final program must produce results for a specified test suite exactly in the required output format.\n\nThe fundamental base is the Initial Value Problem (IVP) for an autonomous, linear, stiff system of ordinary differential equations, defined by\n$$\n\\frac{d\\mathbf{y}}{dt} = \\mathbf{J}\\,\\mathbf{y}, \\quad \\mathbf{y}(0)=\\mathbf{y}_0,\n$$\nwhere $\\mathbf{y}(t)\\in\\mathbb{R}^n$, $\\mathbf{J}\\in\\mathbb{R}^{n\\times n}$ is constant, and the exact solution is\n$$\n\\mathbf{y}(t) = \\exp(t\\,\\mathbf{J})\\,\\mathbf{y}_0.\n$$\nFor the specific problem to be solved, let $n=2$, $\\mathbf{y}_0 = [1,\\,1]^\\top$, and\n$$\n\\mathbf{J} =\n\\begin{bmatrix}\n-1000 & 999\\\\\n0 & -999\n\\end{bmatrix}.\n$$\nFor this system, the exact solution components are\n$$\ny_2(t) = e^{-999 t}, \\qquad\ny_1(t) = 999\\,e^{-999 t} - 998\\,e^{-1000 t}.\n$$\n\nYou must implement a single-step implicit Runge–Kutta time integrator in its general form. Given step size $h>0$ and Butcher coefficients $(\\mathbf{A},\\mathbf{b},\\mathbf{c})$ with $s$ stages, the internal stage values $\\mathbf{Y}_i \\in \\mathbb{R}^n$ satisfy\n$$\n\\mathbf{Y}_i = \\mathbf{y}_n + h \\sum_{j=1}^{s} a_{ij}\\, f(\\mathbf{Y}_j), \\quad i=1,\\dots,s,\n$$\nand the step update is\n$$\n\\mathbf{y}_{n+1} = \\mathbf{y}_n + h \\sum_{i=1}^{s} b_i\\, f(\\mathbf{Y}_i),\n$$\nwhere $f(\\mathbf{y})=\\mathbf{J}\\mathbf{y}$ for this problem. In matrix form for a linear autonomous system, this can be written as a block linear system\n$$\n\\left(\\mathbf{I}_{sn} - h\\,\\mathbf{A}\\otimes \\mathbf{J}\\right)\\, \\mathbf{Y} = \\mathbf{1}_s \\otimes \\mathbf{y}_n,\n$$\nwhere $\\mathbf{Y}\\in\\mathbb{R}^{sn}$ stacks the stage vectors, $\\mathbf{I}_{sn}$ is the identity matrix of size $sn \\times sn$, $\\otimes$ denotes the Kronecker product, and $\\mathbf{1}_s$ is the $s$-vector of ones. After solving for $\\mathbf{Y}$, the update is\n$$\n\\mathbf{y}_{n+1} = \\mathbf{y}_n + h \\sum_{i=1}^{s} b_i\\, \\mathbf{J}\\mathbf{Y}_i.\n$$\n\nImplement and compare the following two implicit Runge–Kutta methods, both of algebraic order $2$:\n- The implicit midpoint method (one-stage Gauss–Legendre collocation at $c_1=\\tfrac{1}{2}$), with Butcher tableau coefficients\n$$\n\\mathbf{A} = \\begin{bmatrix} \\tfrac{1}{2} \\end{bmatrix}, \\quad\n\\mathbf{b} = \\begin{bmatrix} 1 \\end{bmatrix}, \\quad\n\\mathbf{c} = \\begin{bmatrix} \\tfrac{1}{2} \\end{bmatrix}.\n$$\n\n- The trapezoidal rule (two-stage Lobatto IIIA collocation at $c_1=0$, $c_2=1$), with Butcher tableau coefficients\n$$\n\\mathbf{A} = \\begin{bmatrix} 0 & 0 \\\\ \\tfrac{1}{2} & \\tfrac{1}{2} \\end{bmatrix}, \\quad\n\\mathbf{b} = \\begin{bmatrix} \\tfrac{1}{2} \\\\ \\tfrac{1}{2} \\end{bmatrix}, \\quad\n\\mathbf{c} = \\begin{bmatrix} 0 \\\\ 1 \\end{bmatrix}.\n$$\n\nUse the infinity norm of the global error at the final time, defined by\n$$\n\\|\\mathbf{e}\\|_{\\infty} = \\max\\left( |e_1|, |e_2| \\right), \\quad \\mathbf{e} = \\mathbf{y}_{\\text{num}}(T) - \\mathbf{y}_{\\text{exact}}(T),\n$$\nwhere $\\mathbf{y}_{\\text{num}}(T)$ is the numerical solution after $N$ steps of size $h$ with $N = T/h$, and $\\mathbf{y}_{\\text{exact}}(T)$ is the exact solution as given above.\n\nTest suite and required outputs:\n- Let the final time be $T=1$ for all tests. For each specified step size $h$, perform $N=T/h$ uniform steps using each method separately, starting from the same initial condition, and compute the infinity norm of the error for each method at $t=T$.\n- For each test case, compute the ratio\n$$\nr(h) = \\frac{\\|\\mathbf{e}\\|_{\\infty}^{\\text{midpoint}}}{\\|\\mathbf{e}\\|_{\\infty}^{\\text{trapezoidal}}}.\n$$\n\nUse the following three test cases, which cover a large-step regime, a typical moderate-step regime, and a refined-step regime:\n- Test $1$: $h = 1$.\n- Test $2$: $h = 0.1$.\n- Test $3$: $h = 0.01$.\n\nYour program should produce a single line of output containing the three ratios in the order of the test cases, formatted as a comma-separated list enclosed in square brackets (for example, $\\texttt{[r1,r2,r3]}$). No other text should be printed. All values are non-dimensional; there are no physical units to report. Angles are not involved. Percentages are not involved and must not be used.", "solution": "The posed problem is subjected to validation and is found to be scientifically sound, well-posed, and objective. It constitutes a standard exercise in the field of numerical analysis for stiff ordinary differential equations. All necessary data and definitions are provided, and no contradictions or ambiguities are present. Therefore, I will proceed with a complete solution.\n\nThe problem requires the implementation and comparison of two distinct second-order implicit Runge–Kutta (IRK) methods on a stiff linear initial value problem (IVP). The core of the solution is to construct a general-purpose time-stepping function based on the provided matrix formulation for linear autonomous systems, and then apply it using the Butcher tableau coefficients specific to each method.\n\nThe governing IVP is given by $\\frac{d\\mathbf{y}}{dt} = \\mathbf{J}\\,\\mathbf{y}$ with $\\mathbf{y}(t) \\in \\mathbb{R}^2$, $\\mathbf{y}(0) = [1, 1]^\\top$, and the constant Jacobian matrix\n$$\n\\mathbf{J} =\n\\begin{bmatrix}\n-1000 & 999\\\\\n0 & -999\n\\end{bmatrix}.\n$$\nThe exact solution at a time $t$ is $\\mathbf{y}_{\\text{exact}}(t) = \\exp(t\\mathbf{J})\\mathbf{y}_0$.\n\nA single step of a general $s$-stage IRK method from $\\mathbf{y}_n$ to $\\mathbf{y}_{n+1}$ over a time step $h$ is defined by the internal stages $\\mathbf{Y}_i$ and the update rule. For a linear system $f(\\mathbf{y}) = \\mathbf{J}\\mathbf{y}$, the equations for the stages can be consolidated into a single block linear system:\n$$\n\\left(\\mathbf{I}_{sn} - h\\,\\mathbf{A}\\otimes \\mathbf{J}\\right)\\, \\mathbf{Y} = \\mathbf{1}_s \\otimes \\mathbf{y}_n.\n$$\nHere, $s$ is the number of stages, $n=2$ is the dimension of the ODE system, $\\mathbf{A}$ is the $s \\times s$ matrix from the Butcher tableau, $\\otimes$ denotes the Kronecker product, $\\mathbf{I}_{sn}$ is the identity matrix of size $sn$, $\\mathbf{1}_s$ is the $s$-dimensional vector of ones, and $\\mathbf{Y} \\in \\mathbb{R}^{sn}$ is the flattened vector of all stage solutions, $\\mathbf{Y} = [\\mathbf{Y}_1^\\top, \\dots, \\mathbf{Y}_s^\\top]^\\top$.\n\nThe cornerstone of the algorithm is to solve this $sn \\times sn$ linear system for $\\mathbf{Y}$ at each time step. Once $\\mathbf{Y}$ is found, the solution is advanced to the next time level using the update formula:\n$$\n\\mathbf{y}_{n+1} = \\mathbf{y}_n + h \\sum_{i=1}^{s} b_i\\, f(\\mathbf{Y}_i) = \\mathbf{y}_n + h \\sum_{i=1}^{s} b_i\\, \\mathbf{J}\\mathbf{Y}_i,\n$$\nwhere the coefficients $b_i$ are the weights from the Butcher tableau. This provides a unified algorithmic framework for any IRK method.\n\nThe two methods to be compared are:\n1.  **The implicit midpoint method:** An $s=1$ stage Gauss-Legendre method with coefficients $\\mathbf{A} = [\\frac{1}{2}]$, $\\mathbf{b} = [1]$. The linear system for the stage is of size $1 \\cdot 2 = 2$.\n2.  **The trapezoidal rule:** An $s=2$ stage Lobatto IIIA method with coefficients $\\mathbf{A} = \\begin{bmatrix} 0 & 0 \\\\ \\frac{1}{2} & \\frac{1}{2} \\end{bmatrix}$, $\\mathbf{b} = [\\frac{1}{2}, \\frac{1}{2}]^\\top$. The linear system for the stages is of size $2 \\cdot 2 = 4$.\n\nFor linear problems of the form $\\dot{\\mathbf{y}} = \\mathbf{J}\\mathbf{y}$, the numerical solution after one step can be expressed as $\\mathbf{y}_{n+1} = R(h\\mathbf{J})\\mathbf{y}_n$, where $R(z)$ is the stability function of the method. For both the implicit midpoint and the trapezoidal rule, the stability function is the $(1,1)$-Padé approximant to the exponential function, $R(z) = (1 + z/2)/(1 - z/2)$. Consequently, for any linear problem, both methods theoretically produce an identical sequence of solutions $\\{\\mathbf{y}_n\\}$. However, their computational implementations, as dictated by the general framework and their distinct Butcher tableaus, involve different intermediate steps and matrix sizes. The requested comparison will therefore expose any differences arising from floating-point arithmetic in these distinct computational paths.\n\nThe implementation proceeds as follows:\nFirst, a generic function `irk_step(yn, h, J, A, b)` is created. This function constructs and solves the linear system for the stages $\\mathbf{Y}$ and then computes the update $\\mathbf{y}_{n+1}$, exactly following the mathematical specification.\n\nSecond, a simulation function `run_simulation(h, A, b)` repeatedly calls `irk_step` for $N=T/h$ steps to integrate the solution from $t=0$ to $t=T=1$.\n\nThird, for each test case defined by a step size $h \\in \\{1, 0.1, 0.01\\}$, both methods are simulated. The exact solution $\\mathbf{y}_{\\text{exact}}(T)$ is calculated using the provided analytical formula. The global error for each method, $\\mathbf{e} = \\mathbf{y}_{\\text{num}}(T) - \\mathbf{y}_{\\text{exact}}(T)$, is computed, and its infinity norm $\\|\\mathbf{e}\\|_\\infty$ is determined.\n\nFinally, the ratio of the error norms, $r(h) = \\|\\mathbf{e}\\|_{\\infty}^{\\text{midpoint}} / \\|\\mathbf{e}\\|_{\\infty}^{\\text{trapezoidal}}$, is calculated for each $h$. The collection of these ratios constitutes the final result. Given the theoretical equivalence of the methods for this problem, the ratio is expected to be extremely close to $1$.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Implements and compares implicit midpoint and trapezoidal Runge-Kutta methods\n    on a stiff linear system, as specified in the problem statement.\n    \"\"\"\n\n    # Define problem parameters\n    J = np.array([[-1000.0, 999.0], [0.0, -999.0]])\n    Y0 = np.array([1.0, 1.0])\n    T_FINAL = 1.0\n\n    def y_exact(t: float) -> np.ndarray:\n        \"\"\"\n        Computes the exact solution of the IVP at a given time t.\n\n        Args:\n            t: The time at which to evaluate the solution.\n\n        Returns:\n            The solution vector y(t).\n        \"\"\"\n        if t < 0:\n            raise ValueError(\"Time must be non-negative.\")\n        \n        # For large negative exponents, np.exp underflows to 0.0, which is correct.\n        exp_m999t = np.exp(-999.0 * t)\n        exp_m1000t = np.exp(-1000.0 * t)\n        \n        y2 = exp_m999t\n        y1 = 999.0 * exp_m999t - 998.0 * exp_m1000t\n        \n        return np.array([y1, y2])\n\n    def irk_step(yn: np.ndarray, h: float, J_matrix: np.ndarray, A: np.ndarray, b: np.ndarray) -> np.ndarray:\n        \"\"\"\n        Performs a single step of a generic implicit Runge-Kutta method for a\n        linear system dy/dt = J*y.\n\n        Args:\n            yn: Solution vector at the beginning of the step.\n            h: Step size.\n            J_matrix: The constant Jacobian matrix of the linear system.\n            A: The 'A' matrix from the Butcher tableau.\n            b: The 'b' vector from the Butcher tableau.\n\n        Returns:\n            The solution vector at the end of the step.\n        \"\"\"\n        s = A.shape[0]\n        n = J_matrix.shape[0]\n\n        # Form the linear system for the stages Y:\n        # (I_sn - h * A kron J) * Y_stacked = 1_s kron yn\n        M = np.eye(s * n) - h * np.kron(A, J_matrix)\n        rhs = np.kron(np.ones((s, 1)), yn.reshape(-1, 1))\n\n        # Solve for the stacked stage vector Y_stacked\n        Y_stacked = np.linalg.solve(M, rhs)\n\n        # Reshape Y_stacked into s stage vectors of size n\n        Y_stages = Y_stacked.reshape(s, n)\n\n        # Compute the update using the formula:\n        # y_{n+1} = y_n + h * sum(b_i * J * Y_i)\n        update_sum = np.zeros(n)\n        for i in range(s):\n            update_sum += b[i] * np.dot(J_matrix, Y_stages[i])\n\n        yn_plus_1 = yn + h * update_sum\n        return yn_plus_1\n\n    def run_simulation(h: float, A: np.ndarray, b: np.ndarray) -> np.ndarray:\n        \"\"\"\n        Runs the full simulation from t=0 to T_FINAL with a given step size h\n        and a specific IRK method.\n\n        Args:\n            h: The step size.\n            A: The Butcher 'A' matrix for the method.\n            b: The Butcher 'b' vector for the method.\n\n        Returns:\n            The numerical solution at T_FINAL.\n        \"\"\"\n        # The problem implies T/h is an integer number of steps.\n        # Use round to handle potential floating-point inaccuracies in division.\n        num_steps = int(round(T_FINAL / h))\n        \n        y = Y0.copy()\n        for _ in range(num_steps):\n            y = irk_step(y, h, J, A, b)\n        \n        return y\n\n    # Define Butcher tableaus for the two methods\n    # Method 1: Implicit Midpoint (s=1, order 2)\n    A_midpoint = np.array([[0.5]])\n    b_midpoint = np.array([1.0])\n\n    # Method 2: Trapezoidal Rule (s=2, order 2)\n    A_trap = np.array([[0.0, 0.0], [0.5, 0.5]])\n    b_trap = np.array([0.5, 0.5])\n    \n    # Define test cases from the problem statement\n    test_cases = [\n        1.0,    # Test 1\n        0.1,    # Test 2\n        0.01,   # Test 3\n    ]\n\n    results = []\n    \n    # Calculate exact solution at final time\n    y_exact_final = y_exact(T_FINAL)\n\n    for h in test_cases:\n        # Run simulation for both methods\n        y_num_midpoint = run_simulation(h, A_midpoint, b_midpoint)\n        y_num_trap = run_simulation(h, A_trap, b_trap)\n\n        # Calculate the infinity norm of the global error for each method\n        error_midpoint = np.max(np.abs(y_num_midpoint - y_exact_final))\n        error_trap = np.max(np.abs(y_num_trap - y_exact_final))\n\n        # Compute the ratio of the errors\n        if error_trap == 0.0:\n            # This case occurs if the trapezoidal method is numerically exact.\n            # If midpoint error is also zero, ratio is 1. Otherwise, it's infinite.\n            ratio = 1.0 if error_midpoint == 0.0 else np.inf\n        else:\n            ratio = error_midpoint / error_trap\n            \n        results.append(ratio)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "2402175"}]}