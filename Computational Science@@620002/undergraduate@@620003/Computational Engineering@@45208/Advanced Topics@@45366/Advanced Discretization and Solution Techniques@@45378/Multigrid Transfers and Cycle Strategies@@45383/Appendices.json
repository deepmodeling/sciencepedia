{"hands_on_practices": [{"introduction": "The heart of any multigrid method lies in its transfer operators, which move information between fine and coarse grids. This exercise [@problem_id:2416021] uses a specially designed restriction operator to explore a crucial concept: how an operator's structure dictates its effect on different frequency components of the residual. By implementing and analyzing an operator whose weights sum to zero, you will discover why this property is fundamental for the stability and consistency of the coarse-grid problem.", "problem": "You are given a one-dimensional discrete model of the Poisson equation on a periodic domain. Let the domain be the unit circle, discretized by $n$ equally spaced points with spacing $h = 1/n$, where $n$ is an even integer. Define the discrete negative Laplace operator $A \\in \\mathbb{R}^{n \\times n}$ with periodic boundary conditions by\n$$(A \\mathbf{u})_i = \\frac{2 u_i - u_{i-1} - u_{i+1}}{h^2}, \\quad i \\in \\{0,1,\\dots,n-1\\},$$\nwhere indexing is taken modulo $n$. For any discrete field $\\mathbf{u} \\in \\mathbb{R}^n$ and forcing $\\mathbf{f} \\in \\mathbb{R}^n$, define the residual $\\mathbf{r}(\\mathbf{u}) = \\mathbf{f} - A \\mathbf{u}$. Consider the restriction operator $R: \\mathbb{R}^n \\to \\mathbb{R}^{n/2}$ with a three-point stencil whose weights sum to zero, specified by\n$$(R \\mathbf{r})_I = w_{-1}\\, r_{2I-1} + w_0\\, r_{2I} + w_{+1}\\, r_{2I+1}, \\quad I \\in \\{0,1,\\dots,\\tfrac{n}{2}-1\\},$$\nwith periodic indexing and weights $(w_{-1}, w_0, w_{+1}) = (1,-2,1)$, so that $w_{-1} + w_0 + w_{+1} = 0$.\n\nYour task is to implement a program that, for the specified test suite below, constructs the residual $\\mathbf{r}(\\mathbf{u})$ for the initial guess $\\mathbf{u} = \\mathbf{0}$ and then computes the scalar quantity\n$$\\gamma = \\frac{\\lVert R \\mathbf{r}(\\mathbf{0}) \\rVert_2}{\\lVert \\mathbf{r}(\\mathbf{0}) \\rVert_2}.$$\nAngles used in trigonometric definitions must be in radians. No physical units are involved; the quantity $\\gamma$ is dimensionless.\n\nTest Suite:\n- Case $1$: $n = 64$, $\\mathbf{f}$ is the constant vector with entries $f_i = 1$ for all $i$.\n- Case $2$: $n = 64$, $\\mathbf{f}$ is defined by $f_i = \\sin(2 \\pi x_i)$ with $x_i = i h$ and $h = 1/n$.\n- Case $3$: $n = 64$, $\\mathbf{f}$ is defined by $f_i = (-1)^i$ for all $i$.\n- Case $4$: $n = 8$, $\\mathbf{f}$ is the constant vector with entries $f_i = 1$ for all $i$.\n\nFor each case, the program must output the corresponding value of $\\gamma$ as a floating-point number. Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (e.g., \"[a,b,c,d]\"), in the order of the test cases above. The answers must be floats. No user input is required, and the program must be fully self-contained and deterministic.", "solution": "The problem statement will first be subjected to a rigorous validation procedure before any attempt at a solution is made.\n\n### Step 1: Extract Givens\nThe explicit information provided in the problem statement is as follows:\n- **Domain**: A one-dimensional periodic domain (unit circle) discretized by $n$ equally spaced points, where $n$ is an even integer.\n- **Grid Spacing**: $h = 1/n$.\n- **Discrete Operator**: The discrete negative Laplace operator $A \\in \\mathbb{R}^{n \\times n}$ is defined by its action on a vector $\\mathbf{u} \\in \\mathbb{R}^n$:\n$$(A \\mathbf{u})_i = \\frac{2 u_i - u_{i-1} - u_{i+1}}{h^2}, \\quad i \\in \\{0,1,\\dots,n-1\\}$$\nwith indexing taken modulo $n$.\n- **Residual**: The residual vector for a given field $\\mathbf{u}$ and forcing $\\mathbf{f}$ is $\\mathbf{r}(\\mathbf{u}) = \\mathbf{f} - A \\mathbf{u}$.\n- **Restriction Operator**: The restriction operator $R: \\mathbb{R}^n \\to \\mathbb{R}^{n/2}$ is defined by:\n$$(R \\mathbf{r})_I = w_{-1}\\, r_{2I-1} + w_0\\, r_{2I} + w_{+1}\\, r_{2I+1}, \\quad I \\in \\{0,1,\\dots,\\tfrac{n}{2}-1\\}$$\nwith periodic indexing for the components of $\\mathbf{r}$.\n- **Restriction Weights**: The weights for the restriction operator are $(w_{-1}, w_0, w_{+1}) = (1, -2, 1)$. The sum of the weights is $w_{-1} + w_0 + w_{+1} = 1 - 2 + 1 = 0$.\n- **Initial Condition**: The initial guess for the solution is the zero vector, $\\mathbf{u} = \\mathbf{0}$.\n- **Target Quantity**: Compute the scalar ratio $\\gamma = \\frac{\\lVert R \\mathbf{r}(\\mathbf{0}) \\rVert_2}{\\lVert \\mathbf{r}(\\mathbf{0}) \\rVert_2}$.\n- **Test Suite**:\n    - Case 1: $n = 64$, $f_i = 1$ for all $i$.\n    - Case 2: $n = 64$, $f_i = \\sin(2 \\pi x_i)$ with $x_i = i h$.\n    - Case 3: $n = 64$, $f_i = (-1)^i$ for all $i$.\n    - Case 4: $n = 8$, $f_i = 1$ for all $i$.\n\n### Step 2: Validate Using Extracted Givens\nThe problem is assessed against the required criteria:\n- **Scientifically Grounded**: The problem is set in the context of numerical analysis for partial differential equations, specifically multigrid methods for the Poisson equation. The definitions of the discrete Laplacian, residual, and restriction operator are standard constructs in computational engineering. The choice of restriction weights $(1, -2, 1)$ is unusual for a production multigrid solver but mathematically well-defined. The problem is fundamentally sound.\n- **Well-Posed**: The task requires a direct computation of a well-defined quantity, $\\gamma$. For any given non-zero forcing vector $\\mathbf{f}$, the denominator $\\lVert \\mathbf{r}(\\mathbf{0}) \\rVert_2 = \\lVert \\mathbf{f} \\rVert_2$ will be non-zero, and the calculation will yield a unique, stable result.\n- **Objective**: The problem is stated using precise mathematical definitions and objective language. There are no subjective or ambiguous statements.\n- **Completeness and Consistency**: All necessary definitions ($A$, $R$, $\\mathbf{r}$, $\\gamma$), constants (weights), and data (test cases for $n$ and $\\mathbf{f}$) are provided. There are no contradictions in the setup.\n- **Other Flaws**: The problem is formalizable, relevant to the specified topic, computationally feasible, and its results are verifiable. It does not suffer from any of the listed invalidating flaws.\n\n### Step 3: Verdict and Action\nThe problem is **valid**. A solution will be developed.\n\n### Solution Derivation\nThe objective is to compute the quantity $\\gamma$ for four distinct cases. The definition of $\\gamma$ is:\n$$ \\gamma = \\frac{\\lVert R \\mathbf{r}(\\mathbf{0}) \\rVert_2}{\\lVert \\mathbf{r}(\\mathbf{0}) \\rVert_2} $$\nThe initial guess is given as $\\mathbf{u} = \\mathbf{0}$. The residual $\\mathbf{r}(\\mathbf{u})$ is defined as $\\mathbf{f} - A\\mathbf{u}$. Substituting $\\mathbf{u} = \\mathbf{0}$, we find:\n$$ \\mathbf{r}(\\mathbf{0}) = \\mathbf{f} - A\\mathbf{0} = \\mathbf{f} $$\nThus, the residual is simply the forcing vector $\\mathbf{f}$. The expression for $\\gamma$ simplifies to:\n$$ \\gamma = \\frac{\\lVert R \\mathbf{f} \\rVert_2}{\\lVert \\mathbf{f} \\rVert_2} $$\nThe computation proceeds in three steps for each test case:\n1.  Construct the forcing vector $\\mathbf{f} \\in \\mathbb{R}^n$.\n2.  Compute the restricted vector $R\\mathbf{f} \\in \\mathbb{R}^{n/2}$.\n3.  Compute the L2 norms of both vectors and their ratio.\n\nThe components of the restricted vector, which we denote as $\\mathbf{v} = R\\mathbf{f}$, are given by the formula:\n$$ v_I = (R\\mathbf{f})_I = f_{2I-1} - 2f_{2I} + f_{2I+1} $$\nfor $I \\in \\{0, 1, \\dots, \\frac{n}{2}-1\\}$. The indices on the components of $\\mathbf{f}$ must be handled periodically, i.e., an index $j$ corresponds to $j \\pmod n$.\n\nLet us analyze the behavior for the different types of forcing vectors.\n\n**Case 1 & 4: Constant Forcing Vector**\nHere, $f_i = c$ for all $i$, where $c=1$. The size is $n=64$ for Case 1 and $n=8$ for Case 4.\nThe components of the restricted vector $R\\mathbf{f}$ are:\n$$ (R\\mathbf{f})_I = f_{2I-1} - 2f_{2I} + f_{2I+1} = c - 2c + c = 0 $$\nThe restricted vector $R\\mathbf{f}$ is the zero vector. Its norm $\\lVert R\\mathbf{f} \\rVert_2$ is $0$. The denominator $\\lVert \\mathbf{f} \\rVert_2 = \\sqrt{\\sum_{i=0}^{n-1} c^2} = \\sqrt{n c^2}$ is non-zero. Therefore, for any constant forcing vector, $\\gamma = 0$. This confirms the result for Case 1 and Case 4 will be $0.0$.\n\n**Case 3: High-Frequency Forcing Vector**\nHere, $n=64$ and $f_i = (-1)^i$. This represents the highest frequency mode resolvable on the grid, $\\cos(\\pi i)$.\nThe components of the restricted vector $R\\mathbf{f}$ are calculated by considering the parity of the indices:\n$$ f_{2I} = (-1)^{2I} = 1 $$\n$$ f_{2I-1} = (-1)^{2I-1} = -1 $$\n$$ f_{2I+1} = (-1)^{2I+1} = -1 $$\nSubstituting these values:\n$$ (R\\mathbf{f})_I = (-1) - 2(1) + (-1) = -4 $$\nThe restricted vector $R\\mathbf{f}$ is a constant vector of size $m=n/2=32$, with all entries equal to $-4$.\nThe L2 norm of $\\mathbf{f}$ is $\\lVert \\mathbf{f} \\rVert_2 = \\sqrt{\\sum_{i=0}^{63} ((-1)^i)^2} = \\sqrt{64} = 8$.\nThe L2 norm of $R\\mathbf{f}$ is $\\lVert R\\mathbf{f} \\rVert_2 = \\sqrt{\\sum_{I=0}^{31} (-4)^2} = \\sqrt{32 \\times 16} = \\sqrt{512} = 16\\sqrt{2}$.\nThe ratio is $\\gamma = \\frac{16\\sqrt{2}}{8} = 2\\sqrt{2}$.\n\n**Case 2: Low-Frequency Forcing Vector**\nHere, $n=64$ and $f_i = \\sin(2 \\pi x_i) = \\sin(2 \\pi i / n)$. This is the smoothest non-constant Fourier mode on the grid.\nThe L2 norm of $\\mathbf{f}$ is given by $\\lVert \\mathbf{f} \\rVert_2 = \\sqrt{\\sum_{i=0}^{n-1} \\sin^2(2 \\pi i / n)}$. Using the standard discrete Fourier series identity $\\sum_{k=0}^{N-1} \\sin^2(2 \\pi jk/N) = N/2$ for integer $j$ where $1 \\le j < N/2$, we have $\\lVert \\mathbf{f} \\rVert_2 = \\sqrt{n/2} = \\sqrt{64/2} = \\sqrt{32}$.\nThe components of the restricted vector are:\n$$ (R\\mathbf{f})_I = \\sin\\left(\\frac{2\\pi(2I-1)}{n}\\right) - 2\\sin\\left(\\frac{2\\pi(2I)}{n}\\right) + \\sin\\left(\\frac{2\\pi(2I+1)}{n}\\right) $$\nLet $\\theta_I = \\frac{2\\pi(2I)}{n}$ and $\\Delta\\theta = \\frac{2\\pi}{n}$. The expression becomes $(\\sin(\\theta_I-\\Delta\\theta) + \\sin(\\theta_I+\\Delta\\theta)) - 2\\sin(\\theta_I)$. Using the sum-to-product identity, this is $2\\sin(\\theta_I)\\cos(\\Delta\\theta) - 2\\sin(\\theta_I) = 2\\sin(\\theta_I)(\\cos(\\Delta\\theta)-1)$.\nUsing the half-angle identity $1-\\cos(x) = 2\\sin^2(x/2)$, this simplifies to:\n$$ (R\\mathbf{f})_I = -4 \\sin^2\\left(\\frac{\\Delta\\theta}{2}\\right) \\sin(\\theta_I) = -4 \\sin^2\\left(\\frac{\\pi}{n}\\right) \\sin\\left(\\frac{4\\pi I}{n}\\right) $$\nThe norm of $R\\mathbf{f}$ is $\\lVert R\\mathbf{f} \\rVert_2 = \\left|-4 \\sin^2\\left(\\frac{\\pi}{n}\\right)\\right| \\sqrt{\\sum_{I=0}^{n/2 - 1} \\sin^2\\left(\\frac{4\\pi I}{n}\\right)}$.\nThe sum is $\\sum_{I=0}^{m-1} \\sin^2\\left(\\frac{2\\pi I}{m}\\right)$ with $m=n/2=32$. This sum is $m/2 = (n/2)/2 = n/4 = 16$.\nSo, $\\lVert R\\mathbf{f} \\rVert_2 = 4 \\sin^2(\\pi/n) \\sqrt{n/4} = 4 \\sin^2(\\pi/64) \\sqrt{16} = 16 \\sin^2(\\pi/64)$.\nThe ratio is $\\gamma = \\frac{16 \\sin^2(\\pi/64)}{\\sqrt{32}} = \\frac{16 \\sin^2(\\pi/64)}{4\\sqrt{2}} = \\frac{4}{\\sqrt{2}} \\sin^2(\\pi/64) = 2\\sqrt{2} \\sin^2(\\pi/64)$.\n\nThe implementation will construct these vectors numerically and compute the norms to find $\\gamma$ for each case.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef calculate_gamma(n, f_vector):\n    \"\"\"\n    Calculates the ratio gamma for a given grid size n and forcing vector f.\n\n    The quantity is defined as gamma = ||R*r||_2 / ||r||_2, where r = f for u=0.\n    The restriction operator R is defined by (R*r)_I = r_{2I-1} - 2*r_{2I} + r_{2I+1}.\n\n    Args:\n        n (int): The number of grid points, must be even.\n        f_vector (np.ndarray): The forcing vector of size n.\n\n    Returns:\n        float: The computed value of gamma.\n    \"\"\"\n    \n    # For u=0, the residual r is simply the forcing vector f.\n    r = f_vector\n    \n    # Calculate the denominator: the L2 norm of the residual vector.\n    norm_r = np.linalg.norm(r)\n    \n    # If the norm of the residual is zero, gamma is undefined or 0.\n    # In this context (non-zero f), we can treat it as 0.\n    if norm_r == 0:\n        return 0.0\n\n    # The coarse grid has n/2 points.\n    n_coarse = n // 2\n    restricted_r = np.zeros(n_coarse)\n\n    # Apply the restriction operator R to the residual vector r.\n    # (R*r)_I = r_{2I-1} - 2*r_{2I} + r_{2I+1}, with periodic indexing.\n    for I in range(n_coarse):\n        # Python's % operator correctly handles negative numbers for periodic indexing.\n        # e.g., -1 % 64 = 63.\n        idx_minus_1 = (2 * I - 1) % n\n        idx_0 = (2 * I) % n\n        idx_plus_1 = (2 * I + 1) % n\n\n        restricted_r[I] = r[idx_minus_1] - 2 * r[idx_0] + r[idx_plus_1]\n    \n    # Calculate the numerator: the L2 norm of the restricted residual.\n    norm_restricted_r = np.linalg.norm(restricted_r)\n    \n    # Compute the final ratio.\n    gamma = norm_restricted_r / norm_r\n    \n    return gamma\n\ndef solve():\n    \"\"\"\n    Solves the problem for the four specified test cases and prints the results.\n    \"\"\"\n    \n    # Define the test cases from the problem statement.\n    test_cases_params = [\n        {'n': 64, 'id': 1},\n        {'n': 64, 'id': 2},\n        {'n': 64, 'id': 3},\n        {'n': 8,  'id': 4},\n    ]\n\n    results = []\n    for params in test_cases_params:\n        n = params['n']\n        case_id = params['id']\n        f = None\n\n        if case_id == 1: # n=64, f_i = 1\n            f = np.ones(n)\n        elif case_id == 2: # n=64, f_i = sin(2*pi*x_i)\n            h = 1.0 / n\n            x = np.arange(n) * h\n            f = np.sin(2 * np.pi * x)\n        elif case_id == 3: # n=64, f_i = (-1)^i\n            f = np.power(-1.0, np.arange(n))\n        elif case_id == 4: # n=8, f_i = 1\n            f = np.ones(n)\n        \n        gamma = calculate_gamma(n, f)\n        results.append(gamma)\n\n    # Final print statement in the exact required format.\n    # The format specifier ensures that the numbers are printed as floats (e.g., 0.0).\n    print(f\"[{','.join(map(str, [float(r) for r in results]))}]\")\n\nsolve()\n```", "id": "2416021"}, {"introduction": "Building a complete multigrid cycle involves the careful orchestration of smoothing and coarse-grid correction. This practice [@problem_id:2415975] guides you through implementing a full two-grid method with an insightful modification: applying a smoother to the prolonged coarse-grid correction. This exploration of \"prolongation smoothing\" offers a hands-on opportunity to see how non-standard steps can mitigate errors introduced by interpolation and enhance the overall convergence of the cycle.", "problem": "Implement and evaluate a two-grid correction scheme for the one-dimensional Dirichlet boundary-value problem discretized by the finite difference method, focusing on the effect of smoothing the prolonged coarse-grid correction before it is added to the fine-grid approximation. The fine-grid problem is to solve the linear system $A_h u_h = f_h$, where $A_h \\in \\mathbb{R}^{n \\times n}$ is the standard second-order centered finite difference discretization of the negative second derivative operator $-u''$ on the unit interval with homogeneous Dirichlet boundary conditions, i.e., $A_h = \\frac{1}{h^2}\\,\\mathrm{tridiag}(-1,2,-1)$, where $h = \\frac{1}{n+1}$. For all computations, define the exact solution vector $u_h^{\\star}$ using the grid function $u^{\\star}(x) = \\sin(\\pi x)$ sampled at the interior grid points $x_i = i h$ for $i=1,\\dots,n$, and set $f_h = A_h u_h^{\\star}$ to ensure that $u_h^{\\star}$ is the exact fine-grid solution.\n\nYou must implement a two-grid V-cycle correction scheme with the following components and choices:\n- Fine-grid pre-smoothing: apply $\\nu_1$ steps of damped Jacobi iteration to $A_h u_h = f_h$ with damping parameter $\\omega \\in (0,1)$, where one Jacobi step updates $u \\leftarrow u + \\omega D_h^{-1}(f_h - A_h u)$ with $D_h = \\mathrm{diag}(A_h)$.\n- Residual restriction: use full-weighting restriction $R \\in \\mathbb{R}^{n_H \\times n}$, where $n_H = \\frac{n-1}{2}$ and $(R r)_I = \\frac{1}{4} r_{2I-1} + \\frac{1}{2} r_{2I} + \\frac{1}{4} r_{2I+1}$ for $I=1,\\dots,n_H$.\n- Coarse-grid operator: use the Galerkin definition $A_H = R A_h P$, where $P \\in \\mathbb{R}^{n \\times n_H}$ is the standard linear interpolation (injection at even indices and averaging at odd indices).\n- Coarse solve: solve $A_H e_H = R(f_h - A_h u_h)$ exactly.\n- Prolongation of correction: form $e_h = P e_H$ by linear interpolation.\n- Prolongation smoothing: before updating the fine-grid solution, smooth the prolonged correction $e_h$ by applying $p$ steps of homogeneous damped Jacobi on $A_h e = 0$ with the same damping parameter $\\omega$, i.e., repeatedly update $e \\leftarrow e + \\omega D_h^{-1}(0 - A_h e)$ for $p$ steps, starting from $e = e_h$.\n- Correction and post-smoothing: update $u_h \\leftarrow u_h + e_h$ and then apply $\\nu_2$ steps of damped Jacobi post-smoothing to $A_h u_h = f_h$ with the same $\\omega$.\n\nFor each test case, initialize the fine-grid approximation with $u_h^{(0)} = 0$, perform exactly one two-grid V-cycle as described, and compute the error-reduction factor defined as the ratio of Euclidean norms $ \\rho = \\frac{\\lVert u_h^{\\star} - u_h^{(1)} \\rVert_2}{\\lVert u_h^{\\star} - u_h^{(0)} \\rVert_2}$. Report this scalar as a floating-point number.\n\nYour program must implement all operators explicitly for one spatial dimension with homogeneous Dirichlet boundary conditions, using the definitions above. Use the Galerkin coarse operator $A_H$ exactly as specified. The Jacobi diagonal scaling must be $D_h = \\mathrm{diag}(A_h)$ and the same $D_h$ must be used in both the solution smoothing and the prolongation smoothing. The linear algebra for the coarse-grid solve and for constructing $f_h$ may be performed using direct dense linear solvers.\n\nTest suite. Your program must execute the following test cases and report the error-reduction factor for each:\n- Case $1$: $(n, \\nu_1, \\nu_2, \\omega, p) = (63, 1, 1, 2/3, 0)$.\n- Case $2$: $(n, \\nu_1, \\nu_2, \\omega, p) = (63, 1, 1, 2/3, 1)$.\n- Case $3$: $(n, \\nu_1, \\nu_2, \\omega, p) = (63, 1, 1, 2/3, 3)$.\n- Case $4$: $(n, \\nu_1, \\nu_2, \\omega, p) = (127, 2, 2, 0.8, 0)$.\n- Case $5$: $(n, \\nu_1, \\nu_2, \\omega, p) = (7, 1, 1, 0.5, 2)$.\n\nAnswer specification. For each case, compute the scalar error-reduction factor $\\rho$ as defined above. Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, ordered as Cases $1$ through $5$, with each floating-point number rounded to $8$ decimal places. For example, the required format is $[r_1,r_2,r_3,r_4,r_5]$ where each $r_i$ is a decimal with exactly $8$ digits after the decimal point.", "solution": "The problem statement is scrutinized and found to be valid. It presents a well-defined task in the field of computational engineering, based on established principles of numerical analysis and multigrid methods. The parameters, operators, and required cycle structure are specified with sufficient precision to permit a unique and verifiable solution. We shall proceed with the construction of the required two-grid algorithm.\n\nThe core of the problem is the solution of the linear system $A_h u_h = f_h$ arising from the finite difference discretization of the one-dimensional Poisson equation $-u''(x) = f(x)$ on the interval $[0, 1]$ with homogeneous Dirichlet boundary conditions.\n\n1.  **Discretization and Problem Setup**:\n    The fine grid $\\Omega_h$ consists of $n$ interior points $x_i = i h$ for $i=1, \\dots, n$, where the grid spacing is $h = \\frac{1}{n+1}$. The operator $A_h \\in \\mathbb{R}^{n \\times n}$ is the matrix representation of the negative second derivative using a second-order centered difference stencil. It is a symmetric positive-definite tridiagonal matrix given by\n    $$\n    A_h = \\frac{1}{h^2}\n    \\begin{pmatrix}\n    2 & -1 & & & \\\\\n    -1 & 2 & -1 & & \\\\\n     & \\ddots & \\ddots & \\ddots & \\\\\n     & & -1 & 2 & -1 \\\\\n     & & & -1 & 2\n    \\end{pmatrix}.\n    $$\n    The exact solution is defined by sampling the function $u^{\\star}(x) = \\sin(\\pi x)$ at the grid points, yielding the vector $u_h^{\\star} \\in \\mathbb{R}^n$. The right-hand side $f_h$ is constructed as $f_h = A_h u_h^{\\star}$ to ensure consistency. This means $f_h$ is a discrete representation of the function $\\pi^2 \\sin(\\pi x)$. The initial approximation for the iterative process is the zero vector, $u_h^{(0)} = 0$.\n\n2.  **Multigrid Components**:\n    A two-grid method requires transfer operators to move information between the fine grid $\\Omega_h$ and a coarse grid $\\Omega_H$. The coarse grid is defined by selecting every other point of the fine grid, resulting in $n_H = \\frac{n-1}{2}$ interior points.\n\n    -   **Restriction Operator ($R$)**: The full-weighting restriction operator $R \\in \\mathbb{R}^{n_H \\times n}$ averages values from the fine grid to the coarse grid. For a fine-grid vector $r_h$, the $I$-th component of the coarse-grid vector $r_H = R r_h$ is given by the stencil $[\\frac{1}{4}, \\frac{1}{2}, \\frac{1}{4}]$:\n        $$\n        (R r_h)_I = \\frac{1}{4} (r_h)_{2I-1} + \\frac{1}{2} (r_h)_{2I} + \\frac{1}{4} (r_h)_{2I+1}\n        $$\n        for $I=1, \\dots, n_H$, using $1$-based indexing for clarity. This stencil is applied centered at coarse-grid locations, which correspond to the even-indexed points of the fine grid.\n\n    -   **Prolongation Operator ($P$)**: The linear interpolation prolongation operator $P \\in \\mathbb{R}^{n \\times n_H}$ transfers a coarse-grid function to the fine grid. It is the transpose of the restriction operator, scaled by a factor of $2$, i.e., $P = 2R^T$. This operator injects coarse-grid values at corresponding fine-grid locations and interpolates linearly for the intermediate fine-grid points.\n\n    -   **Coarse-Grid Operator ($A_H$)**: A crucial component is the coarse-grid operator $A_H \\in \\mathbb{R}^{n_H \\times n_H}$. We use the Galerkin formulation, which provides a variationally optimal coarse representation of the fine-grid operator:\n        $$\n        A_H = R A_h P.\n        $$\n        This construction ensures that important properties like symmetry and positive-definiteness are preserved from $A_h$.\n\n    -   **Smoother**: The smoother is the damped Jacobi iteration. For a generic system $A u = f$, one step is given by\n        $$\n        u \\leftarrow u + \\omega D^{-1}(f - A u),\n        $$\n        where $D = \\mathrm{diag}(A)$ and $\\omega \\in (0, 1)$ is the damping parameter. For our specific operator $A_h$, the diagonal is a constant matrix, $D_h = \\frac{2}{h^2}I$, so its inverse is simply a scalar multiplication by $\\frac{h^2}{2}$.\n\n3.  **Two-Grid V-Cycle Algorithm**:\n    A single V-cycle, starting from an approximation $u_h^{(k)}$, consists of the following steps to produce an improved approximation $u_h^{(k+1)}$:\n    \n    a.  **Pre-smoothing**: Apply $\\nu_1$ steps of the damped Jacobi smoother to the fine-grid problem $A_h u_h = f_h$.\n        $$\n        \\tilde{u}_h \\leftarrow \\text{Smooth}^{\\nu_1}(A_h, f_h, u_h^{(k)}).\n        $$\n\n    b.  **Residual Computation**: Calculate the residual on the fine grid, which represents the error of the current smoothed approximation.\n        $$\n        r_h = f_h - A_h \\tilde{u}_h.\n        $$\n\n    c.  **Restriction**: Transfer the fine-grid residual to the coarse grid.\n        $$\n        r_H = R r_h.\n        $$\n\n    d.  **Coarse-Grid Solve**: On the coarse grid, solve the residual equation for the error correction $e_H$. This system is solved exactly as required by the problem statement.\n        $$\n        A_H e_H = r_H \\implies e_H = A_H^{-1} r_H.\n        $$\n\n    e.  **Prolongation**: Interpolate the coarse-grid correction back to the fine grid.\n        $$\n        e_h^{\\text{raw}} = P e_H.\n        $$\n\n    f.  **Prolongation Smoothing**: This is a specified, non-standard step. Before a final correction is made, the prolonged error correction $e_h^{\\text{raw}}$ is itself smoothed. This is achieved by applying $p$ iterations of the damped Jacobi method to the homogeneous problem $A_h e_h = 0$, starting with $e_h^{\\text{raw}}$.\n        $$\n        e_h \\leftarrow \\text{Smooth}^{p}(A_h, 0, e_h^{\\text{raw}}).\n        $$\n        The rationale is that prolongation can introduce high-frequency oscillations into the correction; smoothing dampens these non-smooth components, potentially improving the quality of the correction. If $p=0$, then $e_h = e_h^{\\text{raw}}$.\n\n    g.  **Correction**: Update the fine-grid approximation with the (smoothed) correction.\n        $$\n        \\hat{u}_h = \\tilde{u}_h + e_h.\n        $$\n\n    h.  **Post-smoothing**: Apply $\\nu_2$ steps of the damped Jacobi smoother to the corrected approximation $\\hat{u}_h$.\n        $$\n        u_h^{(k+1)} \\leftarrow \\text{Smooth}^{\\nu_2}(A_h, f_h, \\hat{u}_h).\n        $$\n        This step dampens any high-frequency errors introduced by the coarse-grid correction process.\n\n4.  **Evaluation**:\n    The effectiveness of one cycle is measured by the error-reduction factor $\\rho$. Starting with $u_h^{(0)} = 0$, we compute $u_h^{(1)}$ after one V-cycle. The factor $\\rho$ is the ratio of the Euclidean norms of the final and initial errors:\n    $$\n    \\rho = \\frac{\\lVert u_h^{\\star} - u_h^{(1)} \\rVert_2}{\\lVert u_h^{\\star} - u_h^{(0)} \\rVert_2} = \\frac{\\lVert u_h^{\\star} - u_h^{(1)} \\rVert_2}{\\lVert u_h^{\\star} \\rVert_2}.\n    $$\n    The implementation constructs all matrices explicitly and performs the sequence of operations for each test case to compute this factor.", "answer": "```python\nimport numpy as np\n\ndef create_A_h(n):\n    \"\"\"\n    Constructs the finite difference matrix A_h for the 1D Poisson problem.\n    A_h = (1/h^2) * tridiag(-1, 2, -1).\n    \"\"\"\n    h = 1.0 / (n + 1)\n    # The matrix is (1/h^2) * (2*I - L - U) where L and U are sub/super-diagonals\n    A_h = (2.0 * np.eye(n) - np.eye(n, k=1) - np.eye(n, k=-1)) / (h**2)\n    return A_h, h\n\ndef create_R(n):\n    \"\"\"\n    Constructs the full-weighting restriction operator R.\n    (R r)_I = 1/4 * r_{2I-1} + 1/2 * r_{2I} + 1/4 * r_{2I+1} (1-based index)\n    \"\"\"\n    if n % 2 == 0:\n        raise ValueError(\"n must be odd for this coarse grid definition.\")\n    n_H = (n - 1) // 2\n    R = np.zeros((n_H, n))\n    # Python 0-based indexing for r_h: j = 0, ..., n-1\n    # Python 0-based indexing for r_H: I = 0, ..., n_H-1\n    # Mapping 1-based formula to 0-based index:\n    # (r_H)_I corresponds to coarse node I.\n    # Fine grid nodes involved are 2(I+1)-1, 2(I+1), 2(I+1)+1 (1-based)\n    # which are 2I, 2I+1, 2I+2 (0-based) in r_h.\n    for i in range(n_H):\n        j_left = 2 * i\n        j_center = 2 * i + 1\n        j_right = 2 * i + 2\n        R[i, j_left] = 0.25\n        R[i, j_center] = 0.5\n        R[i, j_right] = 0.25\n    return R\n\ndef damped_jacobi(A, u, f, omega, nu, inv_D_scalar):\n    \"\"\"\n    Performs nu steps of the damped Jacobi iteration.\n    For this specific A_h, D is a scalar matrix, so inv_D is a scalar multiplication.\n    \"\"\"\n    u_new = u.copy()\n    for _ in range(nu):\n        residual = f - A @ u_new\n        u_new += omega * inv_D_scalar * residual\n    return u_new\n\ndef run_two_grid_cycle(n, nu1, nu2, omega, p):\n    \"\"\"\n    Executes one two-grid V-cycle and computes the error-reduction factor.\n    \"\"\"\n    # 1. Setup grids, operators, and exact solution\n    A_h, h = create_A_h(n)\n    \n    n_H = (n - 1) // 2\n\n    x_h = np.linspace(h, 1.0 - h, n)\n    u_h_star = np.sin(np.pi * x_h)\n    f_h = A_h @ u_h_star\n\n    R = create_R(n)\n    P = 2 * R.T\n    \n    A_H = R @ A_h @ P\n\n    u_h = np.zeros(n)\n    \n    initial_error_norm = np.linalg.norm(u_h_star - u_h)\n    \n    # D^-1 for damped Jacobi is a scalar multiplication\n    inv_D_h_scalar = h**2 / 2.0\n\n    # 2. Pre-smoothing\n    u_tilde = damped_jacobi(A_h, u_h, f_h, omega, nu1, inv_D_h_scalar)\n\n    # 3. Residual computation and restriction\n    r_h = f_h - A_h @ u_tilde\n    r_H = R @ r_h\n\n    # 4. Coarse-grid solve (exact)\n    e_H = np.linalg.solve(A_H, r_H)\n    \n    # 5. Prolongation of correction\n    e_h_raw = P @ e_H\n\n    # 6. Prolongation smoothing\n    if p > 0:\n        # Homogeneous Jacobi: f=0\n        f_homogeneous = np.zeros(n)\n        e_h = damped_jacobi(A_h, e_h_raw, f_homogeneous, omega, p, inv_D_h_scalar)\n    else:\n        e_h = e_h_raw\n        \n    # 7. Correction\n    u_hat = u_tilde + e_h\n\n    # 8. Post-smoothing\n    u_h_1 = damped_jacobi(A_h, u_hat, f_h, omega, nu2, inv_D_h_scalar)\n\n    # 9. Compute error-reduction factor\n    final_error_norm = np.linalg.norm(u_h_star - u_h_1)\n    \n    rho = final_error_norm / initial_error_norm if initial_error_norm > 0 else 0.0\n    \n    return rho\n\n\ndef solve():\n    \"\"\"\n    Main function to run all test cases and print results.\n    \"\"\"\n    test_cases = [\n        # (n, nu1, nu2, omega, p)\n        (63, 1, 1, 2/3, 0),\n        (63, 1, 1, 2/3, 1),\n        (63, 1, 1, 2/3, 3),\n        (127, 2, 2, 0.8, 0),\n        (7, 1, 1, 0.5, 2),\n    ]\n\n    results = []\n    for case in test_cases:\n        n, nu1, nu2, omega, p = case\n        rho = run_two_grid_cycle(n, nu1, nu2, omega, p)\n        results.append(rho)\n\n    # Format the output as requested, with 8 decimal places for each value.\n    formatted_results = [f\"{r:.8f}\" for r in results]\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```", "id": "2415975"}, {"introduction": "Moving beyond the two-grid model, this exercise [@problem_id:2416031] delves into the architecture of full, multi-level V-cycles and W-cycles, the workhorses of practical multigrid solvers. You will implement a flexible framework where the amount of smoothing can vary depending on the grid level, a common strategy in high-performance computing. By experimenting with different smoothing schedules and cycle types, you will gain a deeper understanding of the trade-offs between computational cost per cycle and the rate of convergence.", "problem": "You are asked to design and implement a variable-smoothing multigrid cycle, where the number of smoothing steps depends on the grid level. Work in one spatial dimension and consider the boundary value problem given by the Poisson equation with homogeneous Dirichlet boundary conditions on the unit interval, discretized by second-order centered finite differences. The resulting linear system is symmetric positive definite and reads, at each interior grid point, as the action of a tridiagonal operator. Your implementation must start from the following fundamental base:\n- The continuous model is the one-dimensional Poisson equation with homogeneous Dirichlet boundary conditions, written as $-u''(x)=g(x)$ for $x\\in(0,1)$, with $u(0)=u(1)=0$.\n- The second-order centered finite difference approximation on a uniform grid with spacing $h$ leads to a linear system $A^{(l)} u^{(l)} = f^{(l)}$ on level $l$, where $A^{(l)}$ is the tridiagonal operator with entries $2/h_l^2$ on the diagonal and $-1/h_l^2$ on the immediate off-diagonals, and $h_l = 1/(n_l+1)$ with $n_l$ interior unknowns on level $l$.\n- Weighted Jacobi smoothing is defined by the iteration $u^{(l)} \\leftarrow u^{(l)} + \\omega \\left(D^{(l)}\\right)^{-1}\\left(f^{(l)} - A^{(l)} u^{(l)}\\right)$ for a chosen relaxation parameter $\\omega$, where $D^{(l)}$ is the diagonal of $A^{(l)}$.\n- Restriction and prolongation between adjacent levels use standard full-weighting restriction and linear interpolation prolongation, respectively. If $r^{(l)}$ is a fine-grid vector with $n_l = 2 n_{l+1} + 1$, then restriction is $(r^{(l+1)})_j = \\frac{1}{4} r^{(l)}_{2j} + \\frac{1}{2} r^{(l)}_{2j+1} + \\frac{1}{4} r^{(l)}_{2j+2}$ for $j=0,\\dots,n_{l+1}-1$, and prolongation is given by injection at odd indices and linear interpolation at even indices.\n- A V-cycle is implemented with one recursive coarse-grid correction per visit, while a W-cycle performs two recursive coarse-grid corrections per visit. Denote the cycle index by $\\gamma$, with $\\gamma=1$ for a V-cycle and $\\gamma=2$ for a W-cycle.\n\nYour task is to implement a multigrid cycle where the number of smoothing steps $ \\nu(l)$ depends on the grid level $ l$. The level numbering must be $l=0$ at the finest grid and $l=L-1$ at the coarsest grid, where $L$ is the number of levels. Use the same number of pre-smoothing and post-smoothing steps at each level, equal to $\\nu(l)$.\n\nThe hierarchy is constructed from a finest grid with $N$ interior points where $N = 2^L - 1$ for some integer $L \\ge 2$. The coarsest-level problem must be solved exactly by a direct solve of the corresponding tridiagonal linear system. Take the right-hand side to be constant, i.e., $g(x)\\equiv 1$, which corresponds to $f^{(0)}_i = 1$ for all interior $i$ on the finest level, and use homogeneous Dirichlet boundary conditions. Initialize the finest-level approximation $u^{(0)}$ to the zero vector.\n\nDefine the smoothing schedule $\\nu(l)$ through one of the following families, in each case ensuring $\\nu(l)$ is an integer and at least $1$:\n- Constant: $\\nu(l) = \\mathrm{round}(c)$.\n- Linear: $\\nu(l) = \\max\\{1,\\ \\mathrm{round}(a + b\\,l)\\}$.\n- Geometric: $\\nu(l) = \\max\\{1,\\ \\mathrm{round}(a\\,b^{\\,l})\\}$.\n\nUse weighted Jacobi smoothing with relaxation parameter $\\omega = 2/3$.\n\nFor a given choice of $N$, $\\gamma$, the family for $\\nu(l)$, and its parameters, run $K$ cycles starting from the zero initial guess $u^{(0)}=0$ on the finest level. Let $\\lVert r_k \\rVert_2$ denote the Euclidean norm of the finest-level residual after $k$ completed cycles, and let $\\lVert r_0 \\rVert_2$ be the norm at the start (with $u^{(0)}=0$). Report the observed average per-cycle reduction factor\n$$\n\\rho_\\mathrm{obs} = \\left(\\frac{\\lVert r_K \\rVert_2}{\\lVert r_0 \\rVert_2}\\right)^{1/K}.\n$$\nYour program must compute $\\rho_\\mathrm{obs}$ for each test case below and print a single line with the results as a comma-separated list enclosed in square brackets, with each number rounded to six digits after the decimal point. No physical units are required.\n\nTest suite:\n- Case $1$ (happy path): $N=63$, $\\gamma=1$ (V-cycle), constant $\\nu(l)$ with $c=2$, and $K=8$.\n- Case $2$ (level-dependent coarse-heavy): $N=63$, $\\gamma=1$ (V-cycle), linear $\\nu(l)$ with $a=1$, $b=1$, and $K=8$.\n- Case $3$ (W-cycle with stronger coarse smoothing): $N=63$, $\\gamma=2$ (W-cycle), linear $\\nu(l)$ with $a=1$, $b=2$, and $K=6$.\n- Case $4$ (geometric growth in smoothing and larger finest grid): $N=127$, $\\gamma=1$ (V-cycle), geometric $\\nu(l)$ with $a=1$, $b=1.5$, and $K=6$.\n\nAlgorithmic requirements to enforce scientific realism:\n- Use the exact tridiagonal operator $A^{(l)}$ implied by the centered finite difference stencil $(-1,2,-1)/h_l^2$ on each level to form residuals and to solve on the coarsest level.\n- Use full-weighting restriction and linear interpolation prolongation between adjacent levels as specified above.\n- Use weighted Jacobi with $\\omega=2/3$ for both pre-smoothing and post-smoothing, with identical counts $\\nu(l)$ at each level.\n- Implement both V-cycle and W-cycle using $\\gamma$ as defined.\n\nFinal output format:\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, in the order of the test cases, for example, $[\\rho_1,\\rho_2,\\rho_3,\\rho_4]$, where each $\\rho_i$ is rounded to six digits after the decimal point. The program must read no input and must produce only this single output line.", "solution": "The problem requires the design and implementation of a multigrid method for the one-dimensional Poisson equation, $-u''(x) = g(x)$ on $x \\in (0, 1)$ with homogeneous Dirichlet boundary conditions $u(0) = u(1) = 0$. The key feature is a variable smoothing strategy, where the number of smoothing iterations depends on the grid level.\n\nFirst, we discretize the problem. We establish a hierarchy of grids, indexed by level $l$, where $l=0$ corresponds to the finest grid and $l=L-1$ to the coarsest. The finest grid has $N$ interior points, where $N=2^L-1$ for some integer $L \\ge 2$. A standard coarsening strategy is used, where the number of interior points $n_l$ on level $l$ is given by $n_l = 2^{L-l}-1$. Consequently, the number of points on the next coarser level is $n_{l+1} = (n_l-1)/2$. The grid spacing on level $l$ is $h_l = 1/(n_l+1)$.\n\nUsing a second-order centered finite difference approximation for the second derivative, we obtain a system of linear equations for the unknown values $u^{(l)}$ at the interior grid points: $A^{(l)} u^{(l)} = f^{(l)}$. The matrix $A^{(l)}$ is an $n_l \\times n_l$ symmetric positive definite and tridiagonal matrix with entries:\n$$\nA^{(l)}_{i,j} = \\frac{1}{h_l^2}\n\\begin{cases}\n2, & i=j \\\\\n-1, & |i-j|=1 \\\\\n0, & \\text{otherwise}\n\\end{cases}\n$$\nThe right-hand side vector $f^{(l)}$ on the finest level is derived from $g(x) \\equiv 1$, so $f^{(0)}_i = 1$ for all $i$. On coarser levels, $f^{(l)}$ will be the restricted residual from the next finer level.\n\nThe core of the multigrid method is a recursive cycle. A single cycle on level $l$ to approximate the solution of $A^{(l)} u^{(l)} = f^{(l)}$ consists of three main steps:\n\n1.  **Pre-smoothing**: The current approximation $u^{(l)}$ is improved by applying a smoothing operator. We use $\\nu(l)$ iterations of the weighted Jacobi method:\n    $$\n    u^{(l)} \\leftarrow u^{(l)} + \\omega (D^{(l)})^{-1} (f^{(l)} - A^{(l)} u^{(l)})\n    $$\n    Here, $D^{(l)}$ is the diagonal of $A^{(l)}$, so $(D^{(l)})^{-1}_{ii} = h_l^2/2$. The relaxation parameter is given as $\\omega=2/3$. The number of smoothing steps, $\\nu(l)$, is a function of the level $l$ defined by one of the provided constant, linear, or geometric schedules.\n\n2.  **Coarse-Grid Correction**: This step solves for the error on a coarser grid, where the problem is smaller and computationally cheaper.\n    a. Compute the residual on the fine grid: $r^{(l)} = f^{(l)} - A^{(l)} u^{(l)}$.\n    b. Restrict the residual to the next coarser grid, $l+1$: $r^{(l+1)} = R^{(l \\to l+1)} r^{(l)}$. The restriction operator $R^{(l \\to l+1)}$ is the full-weighting operator, which in one dimension has the stencil $[1/4, 1/2, 1/4]$. Its action on a fine-grid vector $v^{(l)}$ is:\n    $$\n    (v^{(l+1)})_j = \\frac{1}{4} v^{(l)}_{2j} + \\frac{1}{2} v^{(l)}_{2j+1} + \\frac{1}{4} v^{(l)}_{2j+2}, \\quad j = 0, \\dots, n_{l+1}-1.\n    $$\n    c. Solve the coarse-grid residual equation $A^{(l+1)} e^{(l+1)} = r^{(l+1)}$. If level $l+1$ is the coarsest grid ($l+1 = L-1$), this equation is solved directly. In our case, the coarsest grid has $n_{L-1}=1$ unknown, so this is a trivial scalar equation. If level $l+1$ is not the coarsest, the equation is solved recursively by applying $\\gamma$ multigrid cycles starting with an initial guess of $e^{(l+1)}=0$. For a V-cycle, $\\gamma=1$; for a W-cycle, $\\gamma=2$.\n    d. Prolongate the coarse-grid error correction back to the fine grid: $e^{(l)} = P^{(l+1 \\to l)} e^{(l+1)}$. The prolongation operator $P^{(l+1 \\to l)}$ is linear interpolation, which is the transpose of the full-weighting restriction operator scaled by $2$: $P^{(l+1 \\to l)} = 2 (R^{(l \\to l+1)})^T$. For a coarse-grid vector $v^{(l+1)}$, its action is defined by injection at odd fine-grid indices and averaging at even indices, respecting the zero boundary conditions:\n    $$\n    (v^{(l)})_{2j+1} = v^{(l+1)}_j \\\\\n    (v^{(l)})_{2j} = \\frac{1}{2} (v^{(l+1)}_{j-1} + v^{(l+1)}_j)\n    $$\n    where boundary values are taken as zero (e.g., $v^{(l+1)}_{-1} = 0$).\n    e. Update the fine-grid solution: $u^{(l)} \\leftarrow u^{(l)} + e^{(l)}$.\n\n3.  **Post-smoothing**: To damp any high-frequency errors introduced by the prolongation step, we again apply $\\nu(l)$ iterations of the weighted Jacobi smoother to the updated approximation $u^{(l)}$.\n\nThe overall process is initiated on the finest level ($l=0$) with an initial guess of $u^{(0)}=0$. After performing a specified number of cycles, $K$, the convergence is assessed. The performance is measured by the average per-cycle reduction factor in the Euclidean norm of the residual, $\\rho_{\\text{obs}}$. This is calculated from the initial residual norm $\\lVert r_0 \\rVert_2 = \\lVert f^{(0)} - A^{(0)} u^{(0)}_0 \\rVert_2$ and the final residual norm after $K$ cycles, $\\lVert r_K \\rVert_2 = \\lVert f^{(0)} - A^{(0)} u^{(0)}_K \\rVert_2$, using the formula:\n$$\n\\rho_{\\mathrm{obs}} = \\left(\\frac{\\lVert r_K \\rVert_2}{\\lVert r_0 \\rVert_2}\\right)^{1/K}\n$$\nThe implementation will construct the necessary operators and execute the recursive cycle for each of the specified test cases, calculating $\\rho_{\\mathrm{obs}}$ accordingly.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.sparse import diags\n\n# ===== Multigrid Component Implementations =====\n\ndef create_operator_A(n):\n    \"\"\"Creates the 1D Poisson matrix for a grid with n interior points.\"\"\"\n    h = 1.0 / (n + 1)\n    main_diag = np.full(n, 2.0 / h**2)\n    off_diag = np.full(n - 1, -1.0 / h**2)\n    return diags([off_diag, main_diag, off_diag], [-1, 0, 1], format='csr')\n\ndef apply_smoother(u, f, A, nu, omega):\n    \"\"\"Applies nu steps of the weighted Jacobi smoother.\"\"\"\n    u_new = np.copy(u)\n    # The diagonal of A is constant, so D_inv is a scalar multiplication.\n    # D_ii = 2 / h^2, so D_inv_ii = h^2 / 2\n    n = len(u)\n    h_sq = (1.0 / (n + 1))**2\n    D_inv_val = h_sq / 2.0\n    \n    for _ in range(nu):\n        residual = f - A @ u_new\n        u_new += omega * D_inv_val * residual\n    return u_new\n\ndef apply_restriction(r_fine):\n    \"\"\"Applies full-weighting restriction.\"\"\"\n    # Stencil is [1/4, 1/2, 1/4]\n    # Vectorized implementation for speed\n    n_fine = len(r_fine)\n    if n_fine == 1:\n        return np.array([])\n    r_coarse = 0.25 * r_fine[:-2:2] + 0.5 * r_fine[1:-1:2] + 0.25 * r_fine[2::2]\n    return r_coarse\n\ndef apply_prolongation(e_coarse, n_fine):\n    \"\"\"Applies linear interpolation prolongation.\"\"\"\n    n_coarse = len(e_coarse)\n    e_fine = np.zeros(n_fine)\n    \n    # Injection at odd indices\n    e_fine[1::2] = e_coarse\n    \n    # Interpolation at even indices (including boundaries)\n    padded_coarse = np.concatenate(([0], e_coarse, [0]))\n    e_fine[::2] = 0.5 * (padded_coarse[:-1] + padded_coarse[1:])\n    \n    return e_fine\n\ndef calculate_nu(level, family, params):\n    \"\"\"Calculates the number of smoothing steps for a given level.\"\"\"\n    if family == 'constant':\n        val = params['c']\n    elif family == 'linear':\n        val = params['a'] + params['b'] * level\n    elif family == 'geometric':\n        val = params['a'] * (params['b'] ** level)\n    else:\n        raise ValueError(f\"Unknown smoothing schedule family: {family}\")\n    \n    return max(1, int(np.round(val)))\n\ndef mg_cycle(level, u, f, grid_params):\n    \"\"\"Performs one recursive multigrid cycle.\"\"\"\n    ns, As, nus, gamma, omega = grid_params\n    \n    # Base case: on the coarsest level, solve exactly\n    if level == len(ns) - 1:\n        # For n=1, this is a 1x1 system A u = f -> u = f / A[0,0]\n        return f / As[level][0, 0]\n\n    # 1. Pre-smoothing\n    u = apply_smoother(u, f, As[level], nus[level], omega)\n\n    # 2. Coarse-grid correction\n    residual_fine = f - As[level] @ u\n    residual_coarse = apply_restriction(residual_fine)\n    \n    error_coarse = np.zeros_like(residual_coarse)\n    \n    # Recursive calls to solve the coarse-grid error equation\n    for _ in range(gamma):\n        error_coarse = mg_cycle(level + 1, error_coarse, residual_coarse, grid_params)\n        \n    error_fine = apply_prolongation(error_coarse, ns[level])\n    u += error_fine\n\n    # 3. Post-smoothing\n    u = apply_smoother(u, f, As[level], nus[level], omega)\n\n    return u\n\ndef solve():\n    \"\"\"Main function to run test cases and print results.\"\"\"\n    test_cases = [\n        {'N': 63, 'gamma': 1, 'nu_family': 'constant', 'nu_params': {'c': 2}, 'K': 8},\n        {'N': 63, 'gamma': 1, 'nu_family': 'linear', 'nu_params': {'a': 1, 'b': 1}, 'K': 8},\n        {'N': 63, 'gamma': 2, 'nu_family': 'linear', 'nu_params': {'a': 1, 'b': 2}, 'K': 6},\n        {'N': 127, 'gamma': 1, 'nu_family': 'geometric', 'nu_params': {'a': 1, 'b': 1.5}, 'K': 6},\n    ]\n\n    results = []\n    omega = 2.0 / 3.0\n\n    for case in test_cases:\n        N = case['N']\n        gamma = case['gamma']\n        nu_family = case['nu_family']\n        nu_params = case['nu_params']\n        K = case['K']\n\n        # 1. Setup grid hierarchy\n        L = int(np.log2(N + 1))\n        ns = [2**(L - l) - 1 for l in range(L)]\n        As = [create_operator_A(n) for n in ns]\n        nus = [calculate_nu(l, nu_family, nu_params) for l in range(L)]\n        \n        grid_params = (ns, As, nus, gamma, omega)\n\n        # 2. Initial state\n        u = np.zeros(N)\n        f = np.ones(N)\n\n        # 3. Calculate initial residual norm\n        r0_norm = np.linalg.norm(f) # Since u is zero, initial residual is f\n\n        # 4. Run K multigrid cycles\n        u_k = u\n        for _ in range(K):\n            u_k = mg_cycle(0, u_k, f, grid_params)\n\n        # 5. Calculate final residual norm and convergence factor\n        rK_norm = np.linalg.norm(f - As[0] @ u_k)\n        \n        if r0_norm == 0:\n             rho_obs = 0.0 if rK_norm == 0 else float('inf')\n        else:\n             rho_obs = (rK_norm / r0_norm)**(1.0 / K)\n        \n        results.append(f\"{rho_obs:.6f}\")\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(results)}]\")\n\nsolve()\n```", "id": "2416031"}]}