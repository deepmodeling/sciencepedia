{"hands_on_practices": [{"introduction": "Solving ill-conditioned or singular linear systems, which are highly sensitive to small perturbations, is a common challenge in computational engineering. Tikhonov regularization is a fundamental technique that stabilizes the problem by finding a solution that balances fitting the data and maintaining a small solution norm. This exercise guides you through implementing Tikhonov regularization, where you will analyze the residual of the original system, $\\lVert A\\mathbf{x}_\\alpha - \\mathbf{b}\\rVert_2$, and observe how the regularization parameter $\\alpha$ controls the trade-off between data fidelity and solution stability [@problem_id:2432713].", "problem": "You are given a family of linear systems of the form $A\\mathbf{x}=\\mathbf{b}$ with matrices $A$ that are nearly singular or rank-deficient. Consider the Tikhonov-regularized problem defined by the objective function\n$$\nJ(\\mathbf{x})=\\lVert A\\mathbf{x}-\\mathbf{b}\\rVert_2^2+\\alpha^2\\lVert \\mathbf{x}\\rVert_2^2,\n$$\nwhere $\\alpha > 0$ is the regularization parameter. The stationarity condition of this objective yields the regularized normal equations\n$$\n\\left(A^{\\mathsf{T}}A+\\alpha^2 I\\right)\\mathbf{x}=A^{\\mathsf{T}}\\mathbf{b}.\n$$\nYour task is to compute, for each specified test case, the unique Tikhonov solution $\\mathbf{x}_\\alpha$ that satisfies the above system and analyze the residual of the original, unregularized system. For each test case, you must compute the following quantities:\n- The original residual two-norm $r_{\\mathrm{norm}}=\\lVert A\\mathbf{x}_\\alpha-\\mathbf{b}\\rVert_2$.\n- The relative original residual two-norm $r_{\\mathrm{rel}}=\\dfrac{\\lVert A\\mathbf{x}_\\alpha-\\mathbf{b}\\rVert_2}{\\lVert \\mathbf{b}\\rVert_2}$.\n- The two-norm of the regularized normal equation residual $q_{\\mathrm{norm}}=\\left\\lVert\\left(A^{\\mathsf{T}}A+\\alpha^2 I\\right)\\mathbf{x}_\\alpha-A^{\\mathsf{T}}\\mathbf{b}\\right\\rVert_2$.\n\nUse the exact matrices, vectors, and parameters listed below. In each case, $I$ denotes the identity matrix of size matching the number of columns of $A$. All quantities are unitless.\n\nTest suite:\n- Case $1$ (square, nearly singular):\n  - $A_1=\\begin{bmatrix}\n  1 & 1 & 1\\\\\n  1 & 1 & 1+10^{-8}\\\\\n  1 & 1+10^{-8} & 1\n  \\end{bmatrix}$,\n  $\\mathbf{x}_{\\mathrm{true},1}=\\begin{bmatrix}1\\\\-1\\\\1\\end{bmatrix}$,\n  $\\boldsymbol{\\eta}_1=\\begin{bmatrix}10^{-10}\\\\-10^{-10}\\\\10^{-10}\\end{bmatrix}$,\n  $\\mathbf{b}_1=A_1\\mathbf{x}_{\\mathrm{true},1}+\\boldsymbol{\\eta}_1$,\n  $\\alpha_1=10^{-2}$.\n- Case $2$ (same $A_1$ and $\\mathbf{b}_1$ as Case $1$, weaker regularization):\n  - $\\alpha_2=10^{-6}$.\n- Case $3$ (square, rank-deficient):\n  - $A_3=\\begin{bmatrix}\n  1 & 2 & 3\\\\\n  2 & 4 & 6\\\\\n  3 & 6 & 9\n  \\end{bmatrix}$,\n  $\\mathbf{x}_{\\mathrm{true},3}=\\begin{bmatrix}1\\\\0\\\\0\\end{bmatrix}$,\n  $\\boldsymbol{\\eta}_3=\\begin{bmatrix}10^{-3}\\\\-10^{-3}\\\\2\\cdot 10^{-3}\\end{bmatrix}$,\n  $\\mathbf{b}_3=A_3\\mathbf{x}_{\\mathrm{true},3}+\\boldsymbol{\\eta}_3$,\n  $\\alpha_3=10^{-1}$.\n- Case $4$ (overdetermined, ill-conditioned, Hilbert-type):\n  - $A_4=\\begin{bmatrix}\n  1 & \\tfrac{1}{2} & \\tfrac{1}{3}\\\\\n  \\tfrac{1}{2} & \\tfrac{1}{3} & \\tfrac{1}{4}\\\\\n  \\tfrac{1}{3} & \\tfrac{1}{4} & \\tfrac{1}{5}\\\\\n  \\tfrac{1}{4} & \\tfrac{1}{5} & \\tfrac{1}{6}\n  \\end{bmatrix}$,\n  $\\mathbf{x}_{\\mathrm{true},4}=\\begin{bmatrix}1\\\\0\\\\-1\\end{bmatrix}$,\n  $\\boldsymbol{\\eta}_4=\\begin{bmatrix}10^{-6}\\\\-10^{-6}\\\\10^{-6}\\\\-10^{-6}\\end{bmatrix}$,\n  $\\mathbf{b}_4=A_4\\mathbf{x}_{\\mathrm{true},4}+\\boldsymbol{\\eta}_4$,\n  $\\alpha_4=10^{-3}$.\n\nFor each case $k\\in\\{1,2,3,4\\}$, compute $\\mathbf{x}_{\\alpha_k}$ from $\\left(A_k^{\\mathsf{T}}A_k+\\alpha_k^2 I\\right)\\mathbf{x}=A_k^{\\mathsf{T}}\\mathbf{b}_k$ and then compute $r_{\\mathrm{norm}}$, $r_{\\mathrm{rel}}$, and $q_{\\mathrm{norm}}$ defined above.\n\nFinal output format:\n- Your program should produce a single line of output containing a list of length $4$, where the $k$-th element is a list of length $3$ with the values $[r_{\\mathrm{norm}},r_{\\mathrm{rel}},q_{\\mathrm{norm}}]$ for case $k$, in this order. The list must be enclosed in square brackets with comma separators, and contain floating-point numbers. The values may appear in decimal or scientific notation as produced by the programming language. No additional text should be printed.", "solution": "The problem requires the solution of ill-posed linear systems using Tikhonov regularization and the analysis of the resulting residuals. The problem is scientifically sound, well-posed, and all necessary data are provided. We proceed with the solution.\n\nThe fundamental issue with a linear system $A\\mathbf{x}=\\mathbf{b}$ where the matrix $A$ is singular or ill-conditioned (i.e., has a large condition number) is that the solution $\\mathbf{x}$ is extremely sensitive to perturbations in the right-hand side vector $\\mathbf{b}$. Such problems are common in science and engineering, particularly in inverse problems where $\\mathbf{b}$ represents measured data containing noise.\n\nTikhonov regularization addresses this by finding an approximate solution $\\mathbf{x}_\\alpha$ that minimizes a modified objective function:\n$$\nJ(\\mathbf{x})=\\lVert A\\mathbf{x}-\\mathbf{b}\\rVert_2^2+\\alpha^2\\lVert \\mathbf{x}\\rVert_2^2\n$$\nHere, the first term, $\\lVert A\\mathbf{x}-\\mathbf{b}\\rVert_2^2$, is the squared norm of the residual, which measures the fidelity of the solution to the data. The second term, $\\alpha^2\\lVert \\mathbf{x}\\rVert_2^2$, is the regularization term, which penalizes solutions with a large Euclidean norm. The regularization parameter $\\alpha > 0$ controls the trade-off: a larger $\\alpha$ emphasizes solution stability (smaller norm) at the cost of data fidelity, while a smaller $\\alpha$ prioritizes fitting the data, which may lead to an unstable solution that heavily incorporates noise.\n\nTo find the vector $\\mathbf{x}_\\alpha$ that minimizes $J(\\mathbf{x})$, we must find where the gradient of $J(\\mathbf{x})$ with respect to $\\mathbf{x}$ is the zero vector. The objective function can be written in matrix form as:\n$$\nJ(\\mathbf{x}) = (A\\mathbf{x}-\\mathbf{b})^{\\mathsf{T}}(A\\mathbf{x}-\\mathbf{b}) + \\alpha^2 \\mathbf{x}^{\\mathsf{T}}\\mathbf{x} = \\mathbf{x}^{\\mathsf{T}}A^{\\mathsf{T}}A\\mathbf{x} - 2\\mathbf{b}^{\\mathsf{T}}A\\mathbf{x} + \\mathbf{b}^{\\mathsf{T}}\\mathbf{b} + \\alpha^2 \\mathbf{x}^{\\mathsf{T}}\\mathbf{x}\n$$\nThe gradient with respect to $\\mathbf{x}$ is:\n$$\n\\nabla_{\\mathbf{x}} J(\\mathbf{x}) = 2A^{\\mathsf{T}}A\\mathbf{x} - 2A^{\\mathsf{T}}\\mathbf{b} + 2\\alpha^2\\mathbf{x}\n$$\nSetting $\\nabla_{\\mathbf{x}} J(\\mathbf{x}) = \\mathbf{0}$ yields the aformentioned regularized normal equations:\n$$\n\\left(A^{\\mathsf{T}}A+\\alpha^2 I\\right)\\mathbf{x}=A^{\\mathsf{T}}\\mathbf{b}\n$$\nThe matrix $A^{\\mathsf{T}}A$ is always positive semi-definite. For any $\\alpha > 0$, the matrix $C = A^{\\mathsf{T}}A+\\alpha^2 I$ is positive definite. This is because all its eigenvalues are strictly positive, guaranteeing that it is invertible and that a unique solution $\\mathbf{x}_\\alpha$ exists.\n\nThe computational procedure for each test case is as follows:\n$1$. Construct the matrix $A_k$ and vectors $\\mathbf{x}_{\\mathrm{true},k}$ and $\\boldsymbol{\\eta}_k$ as specified for case $k \\in \\{1, 2, 3, 4\\}$.\n$2$. Calculate the right-hand side vector $\\mathbf{b}_k = A_k\\mathbf{x}_{\\mathrm{true},k} + \\boldsymbol{\\eta}_k$.\n$3$. Form the matrix of the regularized system $C_k = A_k^{\\mathsf{T}}A_k + \\alpha_k^2 I$, where $I$ is the identity matrix with dimensions matching the number of columns of $A_k$.\n$4$. Form the right-hand side of the regularized system $\\mathbf{d}_k = A_k^{\\mathsf{T}}\\mathbf{b}_k$.\n$5$. Solve the well-posed linear system $C_k \\mathbf{x}_{\\alpha_k} = \\mathbf{d}_k$ to find the Tikhonov solution $\\mathbf{x}_{\\alpha_k}$.\n$6$. Compute the required analytical quantities:\n   a. The original residual two-norm: $r_{\\mathrm{norm}} = \\lVert A_k\\mathbf{x}_{\\alpha_k}-\\mathbf{b}_k\\rVert_2$. This measures how well the regularized solution satisfies the original, unregularized system.\n   b. The relative original residual two-norm: $r_{\\mathrm{rel}} = \\frac{\\lVert A_k\\mathbf{x}_{\\alpha_k}-\\mathbf{b}_k\\rVert_2}{\\lVert \\mathbf{b}_k\\rVert_2}$. This normalizes the residual by the magnitude of the data vector.\n   c. The two-norm of the regularized normal equation residual: $q_{\\mathrm{norm}} = \\lVert C_k\\mathbf{x}_{\\alpha_k} - \\mathbf{d}_k\\rVert_2$. This quantity serves as a numerical check on the accuracy of the linear solver used to find $\\mathbf{x}_{\\alpha_k}$. For an exact computation, it would be zero. In floating-point arithmetic, its value should be near machine precision, scaled by the condition number of $C_k$.\n\nThis procedure is implemented for each of the four specified test cases. The matrices $A_1$, $A_3$, and $A_4$ are chosen to be nearly singular, exactly singular (rank-deficient), and ill-conditioned, respectively, representing typical scenarios where regularization is required. The comparison between Case $1$ ($\\alpha_1 = 10^{-2}$) and Case $2$ ($\\alpha_2 = 10^{-6}$) is particularly instructive, as it demonstrates the effect of the regularization parameter's magnitude on the solution and its residuals.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Computes Tikhonov-regularized solutions and associated residuals for a suite of\n    ill-posed linear systems.\n    \"\"\"\n\n    def process_case(A, b, alpha):\n        \"\"\"\n        Solves the Tikhonov regularized system and computes the required norms.\n\n        Args:\n            A (np.ndarray): The system matrix.\n            b (np.ndarray): The right-hand side vector.\n            alpha (float): The regularization parameter.\n\n        Returns:\n            list: A list containing [r_norm, r_rel, q_norm].\n        \"\"\"\n        num_cols = A.shape[1]\n        I = np.identity(num_cols)\n\n        # Form the regularized normal equations: (A.T @ A + alpha^2 * I) @ x = A.T @ b\n        C = A.T @ A + alpha**2 * I\n        d = A.T @ b\n\n        # Solve for the Tikhonov solution x_alpha\n        x_alpha = np.linalg.solve(C, d)\n\n        # 1. Compute the original residual two-norm: r_norm = ||A*x_alpha - b||_2\n        r_norm = np.linalg.norm(A @ x_alpha - b)\n\n        # 2. Compute the relative original residual two-norm: r_rel = ||A*x_alpha - b||_2 / ||b||_2\n        # np.linalg.norm(b) cannot be zero for the given problem settings.\n        r_rel = r_norm / np.linalg.norm(b)\n\n        # 3. Compute the two-norm of the regularized normal equation residual:\n        #    q_norm = ||(A.T*A + alpha^2*I)*x_alpha - A.T*b||_2\n        q_norm = np.linalg.norm(C @ x_alpha - d)\n\n        return [r_norm, r_rel, q_norm]\n\n    # --- Test Case 1 ---\n    eps1 = 1e-8\n    A1 = np.array([\n        [1.0, 1.0, 1.0],\n        [1.0, 1.0, 1.0 + eps1],\n        [1.0, 1.0 + eps1, 1.0]\n    ])\n    x_true1 = np.array([1.0, -1.0, 1.0])\n    eta1 = np.array([1e-10, -1e-10, 1e-10])\n    b1 = A1 @ x_true1 + eta1\n    alpha1 = 1e-2\n\n    # --- Test Case 2 ---\n    # A2 and b2 are the same as A1 and b1\n    alpha2 = 1e-6\n\n    # --- Test Case 3 ---\n    A3 = np.array([\n        [1.0, 2.0, 3.0],\n        [2.0, 4.0, 6.0],\n        [3.0, 6.0, 9.0]\n    ])\n    x_true3 = np.array([1.0, 0.0, 0.0])\n    eta3 = np.array([1e-3, -1e-3, 2e-3])\n    b3 = A3 @ x_true3 + eta3\n    alpha3 = 1e-1\n\n    # --- Test Case 4 ---\n    A4 = np.array([\n        [1.0, 1/2, 1/3],\n        [1/2, 1/3, 1/4],\n        [1/3, 1/4, 1/5],\n        [1/4, 1/5, 1/6]\n    ])\n    x_true4 = np.array([1.0, 0.0, -1.0])\n    eta4 = np.array([1e-6, -1e-6, 1e-6, -1e-6])\n    b4 = A4 @ x_true4 + eta4\n    alpha4 = 1e-3\n\n    test_cases = [\n        (A1, b1, alpha1),\n        (A1, b1, alpha2),\n        (A3, b3, alpha3),\n        (A4, b4, alpha4),\n    ]\n\n    results = []\n    for case in test_cases:\n        A, b, alpha = case\n        result_metrics = process_case(A, b, alpha)\n        results.append(result_metrics)\n\n    # Format the final output as a string representation of a list of lists.\n    # e.g., [[val1, val2, val3],[val4, val5, val6],...]\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "2432713"}, {"introduction": "In complex simulation software, such as finite element analysis (FEA) codes, subtle programming errors can be notoriously difficult to detect. This practice demonstrates how residual analysis serves as a powerful verification and debugging tool by exposing the location and nature of such bugs [@problem_id:2432735]. By intentionally introducing a defect into a finite element basis function and then evaluating the correct governing equations with the resulting flawed solution, you will see how the error manifests as a non-zero residual that is highly localized around the source of the bug.", "problem": "You are to write a complete, self-contained program that constructs and analyzes a one-dimensional finite element approximation for a prototypical elliptic boundary value problem and quantitatively reveals how a deliberately introduced defect in a single local basis function produces a non-physical pattern in the discrete residual field. Consider the following boundary value problem on the closed interval $[0,1]$:\nFind $u:[0,1] \\rightarrow \\mathbb{R}$ such that $-u''(x)=f(x)$ for $x \\in (0,1)$ and $u(0)=0$, $u(1)=0$, with $f(x)=1$.\n\nLet $N \\in \\mathbb{N}$ denote the number of uniform subintervals of $[0,1]$, with nodes $x_i = i h$, $h = 1/N$, $i=0,1,\\dots,N$. Let $\\{\\varphi_i\\}_{i=0}^N$ denote the standard piecewise-linear Lagrange basis functions associated with these nodes, and let $V_h$ be the associated trial and test space of functions that are continuous on $[0,1]$ and linear on each subinterval, with $u_h(0)=u_h(1)=0$. The standard Galerkin formulation asks for $u_h \\in V_h$ such that for all $v_h \\in V_h$,\n$$\n\\int_{0}^{1} u_h'(x)\\,v_h'(x)\\,dx = \\int_{0}^{1} f(x)\\,v_h(x)\\,dx.\n$$\n\nDefine a defective variant of this discrete problem by introducing a single-element basis-function bug as follows. Choose one element index $e^\\star \\in \\{0,1,\\dots,N-1\\}$. On that element only, namely on the subinterval $[x_{e^\\star}, x_{e^\\star+1}]$, replace the local basis function associated with the left endpoint by its negative: $\\tilde{\\varphi}_{e^\\star}|_{[x_{e^\\star}, x_{e^\\star+1}]} = -\\,\\varphi_{e^\\star}|_{[x_{e^\\star}, x_{e^\\star+1}]}$, while keeping the right local basis function unchanged: $\\tilde{\\varphi}_{e^\\star+1}|_{[x_{e^\\star}, x_{e^\\star+1}]} = \\varphi_{e^\\star+1}|_{[x_{e^\\star}, x_{e^\\star+1}]}$. Use these defective local basis functions for both the trial and test functions on that element. On all other elements, use the standard basis functions. Let $u_h^{\\mathrm{def}}$ denote the unique discrete solution obtained from this defective discrete system with homogeneous Dirichlet boundary conditions.\n\nDefine the true finite element residual vector $r \\in \\mathbb{R}^{N-1}$, indexed by the interior nodes $\\{1,2,\\dots,N-1\\}$, as the exact algebraic residual of the correct (non-defective) discrete operator applied to $u_h^{\\mathrm{def}}$,\n$$\nr_i \\;=\\; \\sum_{j=1}^{N-1} K^{\\mathrm{corr}}_{ij}\\, (u_h^{\\mathrm{def}})_j \\;-\\; F^{\\mathrm{corr}}_i,\\quad i=1,2,\\dots,N-1,\n$$\nwhere $K^{\\mathrm{corr}}$ and $F^{\\mathrm{corr}}$ are the stiffness matrix and load vector arising from the correct (non-defective) standard Galerkin formulation with $f(x)=1$ and homogeneous Dirichlet boundary conditions. The vector $u_h^{\\mathrm{def}}$ is the defective solution restricted to the interior degrees of freedom.\n\nFor a given pair $(N,e^\\star)$, compute the following two scalar diagnostics from $r$:\n1. The infinity norm of the residual,\n$$\n\\|r\\|_{\\infty} \\;=\\; \\max_{1 \\le i \\le N-1} |r_i|.\n$$\n2. The localization ratio\n$$\nL \\;=\\; \\frac{\\sum_{i \\in I_{\\mathrm{def}}} r_i^2}{\\sum_{i=1}^{N-1} r_i^2},\n$$\nwhere $I_{\\mathrm{def}}$ is the set of interior node indices lying on the defective element $[x_{e^\\star},x_{e^\\star+1}]$, that is, $I_{\\mathrm{def}} = \\{i \\in \\{1,\\dots,N-1\\} : i \\in \\{e^\\star, e^\\star+1\\}\\}$. In the special case of “no defect,” define $L=0$ by convention.\n\nTest Suite. Your program must evaluate the four parameter sets:\n- Case $1$: $N=8$, $e^\\star=4$.\n- Case $2$: $N=8$, $e^\\star=1$.\n- Case $3$: $N=32$, $e^\\star=16$.\n- Case $4$: $N=8$, no defect (use the correct basis on all elements).\n\nAnswer Specification. For each case, your program must compute and return the ordered pair $[\\|r\\|_{\\infty}, L]$ as real numbers. The final program output must be a single line containing a list of these four ordered pairs in case order, formatted as a comma-separated list enclosed in square brackets, for example,\n\"[[a,b],[c,d],[e,f],[g,h]]\",\nwhere $a,b,c,d,e,f,g,h$ are the floats for the respective cases. No physical units are involved. Angles do not appear. Percentages do not appear.", "solution": "The problem statement is submitted for validation.\n\nStep 1: Extract Givens\n- Differential Equation: $-u''(x)=f(x)$ for $x \\in (0,1)$.\n- Forcing Function: $f(x)=1$.\n- Boundary Conditions: $u(0)=0$, $u(1)=0$.\n- Discretization: $N$ uniform subintervals on $[0,1]$, nodes $x_i = i h$, $h = 1/N$, for $i=0,1,\\dots,N$.\n- Finite Element Space: $V_h$ is the space of continuous, piecewise-linear functions on $[0,1]$ that are zero at $x=0$ and $x=1$. Basis functions are the standard Lagrange basis functions $\\{\\varphi_i\\}_{i=1}^{N-1}$.\n- Standard Galerkin Formulation: Find $u_h \\in V_h$ such that $\\int_{0}^{1} u_h'(x)\\,v_h'(x)\\,dx = \\int_{0}^{1} f(x)\\,v_h(x)\\,dx$ for all $v_h \\in V_h$.\n- Defective Basis Function Definition: For a chosen element $e^\\star \\in \\{0,1,\\dots,N-1\\}$, on the subinterval $[x_{e^\\star}, x_{e^\\star+1}]$, the local basis function associated with the left endpoint $x_{e^\\star}$ is replaced by its negative: $\\tilde{\\varphi}_{e^\\star}|_{[x_{e^\\star}, x_{e^\\star+1}]} = -\\,\\varphi_{e^\\star}|_{[x_{e^\\star}, x_{e^\\star+1}]}$. The basis function for the right endpoint is unchanged. This defective basis is used for both trial and test functions on this element.\n- Defective Solution: $u_h^{\\mathrm{def}}$ is the solution of the Galerkin system constructed with the defect.\n- Residual Vector Definition: $r_i = \\sum_{j=1}^{N-1} K^{\\mathrm{corr}}_{ij}\\, (u_h^{\\mathrm{def}})_j - F^{\\mathrm{corr}}_i$ for $i=1,2,\\dots,N-1$, where $K^{\\mathrm{corr}}$ and $F^{\\mathrm{corr}}$ are the correct (non-defective) stiffness matrix and load vector, and $(u_h^{\\mathrm{def}})_j$ are the nodal values of the defective solution at the interior nodes.\n- Diagnostic 1: $\\|r\\|_{\\infty} = \\max_{1 \\le i \\le N-1} |r_i|$.\n- Diagnostic 2: $L = \\frac{\\sum_{i \\in I_{\\mathrm{def}}} r_i^2}{\\sum_{i=1}^{N-1} r_i^2}$, where $I_{\\mathrm{def}} = \\{i \\in \\{1,\\dots,N-1\\} : i \\in \\{e^\\star, e^\\star+1\\}\\}$. For the \"no defect\" case, $L=0$.\n- Test Suite:\n  - Case 1: $N=8$, $e^\\star=4$.\n  - Case 2: `N=8`, `e^\\star=1`.\n  - Case 3: `N=32`, `e^\\star=16`.\n  - Case 4: `N=8`, no defect.\n\nStep 2: Validate Using Extracted Givens\n- **Scientifically Grounded**: The problem is based on the standard and well-established Finite Element Method for a second-order elliptic boundary value problem (the Poisson equation). The concept of introducing a specific bug in a basis function to study its effect on the residual is a valid and instructive exercise in computational engineering and numerical analysis. It models a plausible programming error.\n- **Well-Posed**: The problem is well-posed. The standard Galerkin formulation for this equation results in a symmetric positive-definite stiffness matrix, guaranteeing a unique solution. The defective local stiffness matrix, upon assembly, results in a global defective stiffness matrix that is non-singular for the given cases, thus ensuring a unique defective solution $u_h^{\\mathrm{def}}$ exists. The residual and subsequent diagnostics are defined by explicit, deterministic formulas. All required information is provided.\n- **Objective**: The problem is formulated in precise mathematical language, free from ambiguity, subjectivity, or opinion.\n\nStep 3: Verdict and Action\nThe problem is valid. A rigorous solution can and must be constructed.\n\nThe task is to implement the finite element method for the given boundary value problem, both in its standard form and with a specified local defect, and then to analyze the resulting error. The analysis hinges on constructing the correct algebraic systems and evaluating the specified diagnostics.\n\nFirst, we establish the standard (correct) finite element formulation. The weak form is given as finding $u_h \\in V_h$ such that $a(u_h, v_h) = l(v_h)$ for all $v_h \\in V_h$, where the bilinear form is $a(u, v) = \\int_{0}^{1} u'(x)v'(x)dx$ and the linear functional is $l(v) = \\int_{0}^{1} f(x)v(x)dx$. The solution is expanded in the basis of interior nodes, $u_h(x) = \\sum_{j=1}^{N-1} U_j \\varphi_j(x)$, where $U_j$ are the unknown nodal values. This leads to the linear system $K^{\\mathrm{corr}} U = F^{\\mathrm{corr}}$, where the entries of the stiffness matrix and load vector are $K^{\\mathrm{corr}}_{ij} = a(\\varphi_j, \\varphi_i)$ and $F^{\\mathrm{corr}}_i = l(\\varphi_i)$.\n\nOn a generic element $[x_k, x_{k+1}]$ of length $h=1/N$, the two local basis functions, denoted $\\psi_1$ and $\\psi_2$, have derivatives $\\psi_1'(x) = -1/h$ and $\\psi_2'(x) = 1/h$. The correct element stiffness matrix $k^{\\mathrm{corr}}$ is:\n$$\nk^{\\mathrm{corr}}_{ij} = \\int_{x_k}^{x_{k+1}} \\psi_i'(x) \\psi_j'(x) dx = \\frac{1}{h} \\begin{pmatrix} 1 & -1 \\\\ -1 & 1 \\end{pmatrix}\n$$\nWith $f(x)=1$, the correct element load vector $f^{\\mathrm{corr}}$ is:\n$$\nf^{\\mathrm{corr}}_{i} = \\int_{x_k}^{x_{k+1}} 1 \\cdot \\psi_i(x) dx = \\frac{h}{2} \\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix}\n$$\n\nNext, we formulate the defective system. The defect is introduced on a single element $e^\\star$, on the interval $[x_{e^\\star}, x_{e^\\star+1}]$. The local basis function for the left node, $\\varphi_{e^\\star}$, is replaced by its negative. Let us denote the standard local basis functions on this element as $\\psi_1$ (for the left node) and $\\psi_2$ (for the right node). The standard derivatives are $\\psi_1'(x)=-1/h$ and $\\psi_2'(x)=1/h$. The defective basis functions become $\\tilde{\\psi}_1 = -\\psi_1$ and $\\tilde{\\psi}_2 = \\psi_2$. Their derivatives are $\\tilde{\\psi}_1'(x) = -(-1/h) = 1/h$ and $\\tilde{\\psi}_2'(x) = 1/h$.\nThe defective element stiffness matrix $k^{\\mathrm{def}}$ is computed using these modified derivatives:\n$$\nk^{\\mathrm{def}}_{ij} = \\int_{x_{e^\\star}}^{x_{e^\\star+1}} \\tilde{\\psi}_i'(x) \\tilde{\\psi}_j'(x) dx = \\int_{x_{e^\\star}}^{x_{e^\\star+1}} \\frac{1}{h^2} dx = \\frac{1}{h} \\begin{pmatrix} 1 & 1 \\\\ 1 & 1 \\end{pmatrix}\n$$\nThe defective element load vector $f^{\\mathrm{def}}$ is computed using the modified basis functions:\n$$\nf^{\\mathrm{def}}_{1} = \\int_{x_{e^\\star}}^{x_{e^\\star+1}} 1 \\cdot \\tilde{\\psi}_1(x) dx = \\int 1 \\cdot (-\\psi_1(x)) dx = -\\frac{h}{2}\n$$\n$$\nf^{\\mathrm{def}}_{2} = \\int_{x_{e^\\star}}^{x_{e^\\star+1}} 1 \\cdot \\tilde{\\psi}_2(x) dx = \\int 1 \\cdot \\psi_2(x) dx = \\frac{h}{2}\n$$\nSo, $f^{\\mathrm{def}} = \\frac{h}{2} \\begin{pmatrix} -1 \\\\ 1 \\end{pmatrix}$.\n\nTo find the defective solution $u_h^{\\mathrm{def}}$, we assemble the global defective system $K^{\\mathrm{def}}U^{\\mathrm{def}} = F^{\\mathrm{def}}$. This is done by summing the contributions from all elements, using $k^{\\mathrm{corr}}$ and $f^{\\mathrm{corr}}$ for all elements $e \\neq e^\\star$, and using $k^{\\mathrm{def}}$ and $f^{\\mathrm{def}}$ for element $e=e^\\star$. The resulting $(N-1) \\times (N-1)$ linear system is solved for the vector of interior nodal values $U^{\\mathrm{def}}$.\n\nThe core of the analysis is the computation of the true residual vector $r$. It is defined as what remains when the defective solution $U^{\\mathrm{def}}$ is inserted into the *correct* system of equations: $r = K^{\\mathrm{corr}} U^{\\mathrm{def}} - F^{\\mathrm{corr}}$. An important insight is that the residual $r$ will be non-zero only at the nodes belonging to the defective element, i.e., nodes $e^\\star$ and $e^\\star+1$. This is because for any row $i$ not corresponding to these nodes, the $i$-th equation of the defective system is identical to the $i$-th equation of the correct system, and thus $(K^{\\mathrm{corr}}U^{\\mathrm{def}})_i - F^{\\mathrm{corr}}_i = (K^{\\mathrm{def}}U^{\\mathrm{def}})_i - F^{\\mathrm{def}}_i = 0$.\n\nFinally, we compute the two diagnostics from the residual vector $r$.\n$1$. The infinity norm, $\\|r\\|_{\\infty}$, is the maximum absolute value of the components of $r$.\n$2$. The localization ratio, $L$. Given the insight that $r_i$ is non-zero only for $i \\in I_{\\mathrm{def}} = \\{e^\\star, e^\\star+1\\} \\cap \\{1, ..., N-1\\}$, the sum in the numerator of $L$, $\\sum_{i \\in I_{\\mathrm{def}}} r_i^2$, will be equal to the sum in the denominator, $\\sum_{i=1}^{N-1} r_i^2$. Therefore, for any defective case, $L$ must be exactly $1$. For the non-defective case, $U^{\\mathrm{def}}$ is the true solution $U^{\\mathrm{corr}}$, so $r = K^{\\mathrm{corr}}U^{\\mathrm{corr}} - F^{\\mathrm{corr}}$ is theoretically the zero vector. Due to floating-point arithmetic, its norm will be a small number close to machine precision. By the problem's convention, we set $L=0$ for this case.\n\nThe implementation will follow these steps:\n$1$. For each test case $(N, e^\\star)$, define $h=1/N$.\n$2$. Construct and assemble the global defective matrices $K^{\\mathrm{def}}$ and $F^{\\mathrm{def}}$.\n$3$. Solve the system $K^{\\mathrm{def}}U^{\\mathrm{def}} = F^{\\mathrm{def}}$ for $U^{\\mathrm{def}}$.\n$4$. Construct the global correct matrices $K^{\\mathrm{corr}}$ and $F^{\\mathrm{corr}}$.\n$5$. Compute the residual vector $r = K^{\\mathrm{corr}} U^{\\mathrm{def}} - F^{\\mathrm{corr}}$.\n$6$. Compute $\\|r\\|_{\\infty}$ and $L$ from $r$. Special handling for the no-defect case sets $L=0$.\n$7$. Store and format the results as specified.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef assemble(N, h, k_elem, f_elem, apply_bc=True):\n    \"\"\"\n    Assembles the global stiffness matrix and load vector.\n    \n    Args:\n        N (int): Number of subintervals.\n        h (float): Element size.\n        k_elem (np.ndarray): 2x2 element stiffness matrix.\n        f_elem (np.ndarray): 2x1 element load vector.\n        apply_bc (bool): If True, assemble for interior nodes only.\n    \n    Returns:\n        (np.ndarray, np.ndarray): Global stiffness matrix and load vector.\n    \"\"\"\n    if apply_bc:\n        num_dofs = N - 1\n        K = np.zeros((num_dofs, num_dofs))\n        F = np.zeros(num_dofs)\n        \n        for e in range(N):\n            # Global node indices for element e\n            g_idx = [e, e + 1]\n            \n            for i_loc in range(2):\n                for j_loc in range(2):\n                    g_i, g_j = g_idx[i_loc], g_idx[j_loc]\n                    # Check if both nodes are interior\n                    if 1 <= g_i <= N - 1 and 1 <= g_j <= N - 1:\n                        # Map global node index to matrix index\n                        m_i, m_j = g_i - 1, g_j - 1\n                        K[m_i, m_j] += k_elem[i_loc, j_loc]\n                \n                # Assemble load vector (once per row)\n                g_i = g_idx[i_loc]\n                if 1 <= g_i <= N - 1:\n                    m_i = g_i - 1\n                    F[m_i] += f_elem[i_loc]\n    else: # Not used in this problem, but for completeness\n        num_dofs = N + 1\n        K = np.zeros((num_dofs, num_dofs))\n        F = np.zeros(num_dofs)\n        for e in range(N):\n            g_idx = [e, e + 1]\n            K[np.ix_(g_idx, g_idx)] += k_elem\n            F[g_idx] += f_elem\n            \n    return K, F\n\ndef solve_case(N, e_star):\n    \"\"\"\n    Solves one case of the FEM problem with an optional defect.\n\n    Args:\n        N (int): Number of subintervals.\n        e_star (int or None): Index of the defective element. If None, no defect.\n\n    Returns:\n        list: A list containing [||r||_infinity, L].\n    \"\"\"\n    h = 1.0 / N\n    dof = N - 1\n\n    # Define correct element matrices\n    k_corr = (1.0 / h) * np.array([[1.0, -1.0], [-1.0, 1.0]])\n    f_corr = (h / 2.0) * np.array([1.0, 1.0])\n\n    # Define defective element matrices\n    k_def = (1.0 / h) * np.array([[1.0, 1.0], [1.0, 1.0]])\n    f_def = (h / 2.0) * np.array([-1.0, 1.0])\n\n    # 1. Assemble the defective system (K_def, F_def)\n    K_def_glob = np.zeros((dof, dof))\n    F_def_glob = np.zeros(dof)\n\n    for e in range(N):\n        is_defective_element = (e_star is not None and e == e_star)\n        k_e = k_def if is_defective_element else k_corr\n        f_e = f_def if is_defective_element else f_corr\n        \n        g_nodes = [e, e + 1]\n        for i_loc in range(2):\n            g_i = g_nodes[i_loc]\n            if 1 <= g_i <= N - 1:\n                m_i = g_i - 1\n                F_def_glob[m_i] += f_e[i_loc]\n                for j_loc in range(2):\n                    g_j = g_nodes[j_loc]\n                    if 1 <= g_j <= N - 1:\n                        m_j = g_j - 1\n                        K_def_glob[m_i, m_j] += k_e[i_loc, j_loc]\n\n    # 2. Solve for the defective solution U_def\n    U_def = np.linalg.solve(K_def_glob, F_def_glob)\n\n    # 3. Assemble the correct system (K_corr, F_corr)\n    # The correct global matrix is tridiagonal\n    K_corr_glob = np.zeros((dof, dof))\n    F_corr_glob = np.zeros(dof)\n    main_diag = 2.0 / h\n    off_diag = -1.0 / h\n    np.fill_diagonal(K_corr_glob, main_diag)\n    np.fill_diagonal(K_corr_glob[1:], off_diag)\n    np.fill_diagonal(K_corr_glob[:, 1:], off_diag)\n    # The correct load vector is constant h\n    F_corr_glob.fill(h)\n\n    # 4. Compute the residual r = K_corr * U_def - F_corr\n    r = K_corr_glob @ U_def - F_corr_glob\n\n    # 5. Compute diagnostics\n    # ||r||_infinity\n    r_inf_norm = np.linalg.norm(r, ord=np.inf)\n\n    # Localization ratio L\n    if e_star is None:\n        # Per problem specification for \"no defect\" case\n        L = 0.0\n    else:\n        # Identify interior node indices on the defective element\n        # Problem indices are 1-based, numpy are 0-based\n        num_indices = []\n        # Node e_star is interior if 1 <= e_star <= N-1\n        if 1 <= e_star <= N - 1:\n            num_indices.append(e_star - 1)\n        # Node e_star+1 is interior if 1 <= e_star+1 <= N-1\n        if 1 <= e_star + 1 <= N - 1:\n            num_indices.append(e_star)\n        \n        if not num_indices:\n             # This can happen if defect is on boundary element e.g. e_star=0 with N>1\n             # and we only consider node e_star+1.\n            if 1 <= e_star+1 <= N-1: \n                num_indices.append(e_star)\n            else: # should not be reached with problem constraints\n                L = 0.0\n\n        num_sum_sq = np.sum(r[num_indices]**2)\n        den_sum_sq = np.sum(r**2)\n        \n        if den_sum_sq < 1e-15: # Avoid division by zero\n            L = 0.0\n        else:\n            L = num_sum_sq / den_sum_sq\n\n    return [r_inf_norm, L]\n\ndef solve():\n    \"\"\"\n    Main function to run test cases and print results.\n    \"\"\"\n    test_cases = [\n        {'N': 8, 'e_star': 4},         # Case 1\n        {'N': 8, 'e_star': 1},         # Case 2\n        {'N': 32, 'e_star': 16},       # Case 3\n        {'N': 8, 'e_star': None},      # Case 4 (no defect)\n    ]\n\n    results = []\n    for case in test_cases:\n        result = solve_case(case['N'], case['e_star'])\n        results.append(result)\n\n    # Format the final output string exactly as specified\n    formatted_pairs = [f\"[{item[0]},{item[1]}]\" for item in results]\n    final_string = f\"[{','.join(formatted_pairs)}]\"\n    print(final_string)\n\nsolve()\n```", "id": "2432735"}, {"introduction": "In many engineering simulations, the ultimate goal is not the entire solution field but a specific scalar output, such as the lift on an airfoil or the maximum stress in a component. This capstone exercise introduces you to goal-oriented error estimation, a sophisticated technique used to assess the accuracy of these specific quantities of interest (QoIs) [@problem_id:2432787]. You will implement the dual-weighted residual (DWR) method, which uses an 'adjoint' problem to create a weighted residual, yielding a quantitative estimate for the error in your QoI without needing to know the exact solution.", "problem": "Consider a steady, linear surrogate of Computational Fluid Dynamics (CFD) airflow over an airfoil on the unit square domain $\\Omega = (0,1) \\times (0,1)$. Let the unknown field be $u : \\Omega \\to \\mathbb{R}$, governed by the linear convection-diffusion operator\n$$\n\\mathcal{L}u = -\\nu \\Delta u + \\boldsymbol{\\beta} \\cdot \\nabla u = s,\n$$\nwith Dirichlet boundary data $u|_{\\partial \\Omega} = g$. Take the source term $s \\equiv 0$. Prescribe the boundary data as follows: on the inflow boundary at $x=0$, $g(0,y) = \\sin(2\\pi y)$ for $y \\in [0,1]$, and on the other three sides of $\\partial \\Omega$ (that is, $x=1$, $y=0$, $y=1$), impose $g = 0$. The convective velocity is constant, $\\boldsymbol{\\beta} = (\\beta_x,\\beta_y)$, and the diffusion coefficient is $\\nu > 0$.\n\nLet $u \\in H^1(\\Omega)$ denote the exact solution of the boundary value problem, and let $J(u)$ denote the scalar quantity of interest defined by the spatial average of $u$ over a rectangular patch representing a surrogate of the lift-sensitive region near the body:\n$$\nJ(u) = \\frac{1}{|\\mathcal{S}|} \\iint_{\\mathcal{S}} u(x,y) \\, dx \\, dy, \\quad \\mathcal{S} = [0.6,0.8] \\times [0.45,0.55].\n$$\n\nDiscretize the problem on a uniform Cartesian grid with $N$ interior points in each coordinate direction and grid spacing $h = 1/(N+1)$. Denote interior grid points by $(x_i,y_j) = (ih,jh)$ for $i,j \\in \\{1,\\dots,N\\}$. Use the standard $5$-point second-order centered finite difference stencil for the diffusion operator and a first-order upwind finite difference for each component of the convection term. Specifically, for an interior node $(i,j)$, the discrete operator $A \\in \\mathbb{R}^{N^2 \\times N^2}$ acting on the nodal values $u_{i,j}$ is given by\n$$\n(Au)_{i,j} = \\frac{\\nu}{h^2}\\left(4 u_{i,j} - u_{i+1,j} - u_{i-1,j} - u_{i,j+1} - u_{i,j-1}\\right) + \\text{conv}_x(u)_{i,j} + \\text{conv}_y(u)_{i,j},\n$$\nwhere the upwind convection terms are\n$$\n\\text{conv}_x(u)_{i,j} =\n\\begin{cases}\n\\displaystyle \\beta_x \\frac{u_{i,j} - u_{i-1,j}}{h}, & \\text{if } \\beta_x \\ge 0, \\\\[1.0ex]\n\\displaystyle \\beta_x \\frac{u_{i+1,j} - u_{i,j}}{h}, & \\text{if } \\beta_x < 0,\n\\end{cases}\n\\quad\n\\text{and}\n\\quad\n\\text{conv}_y(u)_{i,j} =\n\\begin{cases}\n\\displaystyle \\beta_y \\frac{u_{i,j} - u_{i,j-1}}{h}, & \\text{if } \\beta_y \\ge 0, \\\\[1.0ex]\n\\displaystyle \\beta_y \\frac{u_{i,j+1} - u_{i,j}}{h}, & \\text{if } \\beta_y < 0.\n\\end{cases}\n$$\nDirichlet boundary values $g$ are enforced by incorporating their contributions to the discrete right-hand side $f \\in \\mathbb{R}^{N^2}$ wherever a stencil neighbor lies outside the interior. In particular, for the left boundary at $x=0$, $g(0,y_j) = \\sin(2\\pi y_j)$ is used; all other boundaries have $g=0$.\n\nDefine the discrete quantity of interest on a grid with $N$ interior points as\n$$\nJ_h(u_h) = \\frac{1}{m} \\sum_{(i,j)\\in \\mathcal{I}_h} u_{i,j},\n$$\nwhere $\\mathcal{I}_h = \\{(i,j): x_i \\in [0.6,0.8],\\ y_j \\in [0.45,0.55]\\}$ indexes the interior nodes within the patch and $m$ is the number of such nodes.\n\nSuppose you are given a discrete approximation $\\tilde{u}_{H}$ computed on a coarser grid with $H = 1/(N_H+1)$, with $N_H < N_h$, and suppose that you are to estimate the error in the quantity of interest $J(u) - J(\\tilde{u}_H)$ without access to the exact solution $u$. To that end, consider the fine-grid operator $A_h \\in \\mathbb{R}^{N_h^2 \\times N_h^2}$ and right-hand side $f_h \\in \\mathbb{R}^{N_h^2}$ constructed as above with parameters $(\\nu,\\beta_x,\\beta_y)$ and grid size $N_h$. Form a fine-grid surrogate of the coarse solution by prolongating $\\tilde{u}_H$ to the fine grid using bilinear interpolation consistent with the same Dirichlet boundary values $g$.\n\nYour task is to write a complete, runnable program that, for each test case below, constructs $A_h$, $f_h$, the prolongated fine-grid vector $\\tilde{u}_h$, the residual $r_h = f_h - A_h \\tilde{u}_h$, and a fine-grid vector $c_h \\in \\mathbb{R}^{N_h^2}$ representing $J_h(\\cdot)$ as a linear functional such that $J_h(u_h) = c_h^\\top u_h$. Then, using only these ingredients, compute a scalar error estimate $\\eta$ for $J(u) - J(\\tilde{u}_H)$ derived from first principles of linear residual weighting on the fine grid. Report $\\eta$ as a real number in decimal form.\n\nTest Suite:\n- Case $1$: $\\nu = 0.05$, $\\beta_x = 1.0$, $\\beta_y = 0.0$, $N_H = 16$, $N_h = 32$.\n- Case $2$: $\\nu = 0.01$, $\\beta_x = 2.0$, $\\beta_y = 1.0$, $N_H = 24$, $N_h = 48$.\n- Case $3$: $\\nu = 0.10$, $\\beta_x = 0.0$, $\\beta_y = 0.0$, $N_H = 16$, $N_h = 32$.\n- Case $4$: $\\nu = 0.05$, $\\beta_x = 1.0$, $\\beta_y = -1.0$, $N_H = 8$, $N_h = 16$.\n\nAngle units do not apply. There are no physical units in the output. For each case, express the final scalar result as a decimal rounded to six digits after the decimal point.\n\nFinal Output Format:\nYour program should produce a single line of output containing the results as a comma-separated list of the four estimated errors, in the order of the cases above, enclosed in square brackets. For example, an output with placeholder values would look like\n$$\n[\\eta_1,\\eta_2,\\eta_3,\\eta_4],\n$$\nwhere each $\\eta_k$ is a decimal rounded to six digits after the decimal point.", "solution": "The problem presented is a valid, well-posed computational engineering task. It asks for the implementation of an a posteriori error estimator for a scalar quantity of interest derived from the solution of a two-dimensional, linear, steady-state convection-diffusion equation. The methodology is grounded in the principles of finite difference discretization and dual-weighted residual (DWR) error estimation.\n\nThe core of the task is to estimate the error in a quantity of interest, $J(u)$, for an approximate solution, $\\tilde{u}_H$, which is computed on a coarse grid. The error is estimated without access to the exact solution, $u$. The problem asks for an estimate of $J(u) - J(\\tilde{u}_H)$. The standard approach, which will be followed, is to compute the DWR error representation on a finer grid.\n\nLet the fine-grid discretization of the governing partial differential equation, $\\mathcal{L}u = s$, be given by the linear system:\n$$\nA_h u_h = f_h\n$$\nwhere $u_h \\in \\mathbb{R}^{N_h^2}$ is the vector of unknown values at the $N_h^2$ interior grid nodes, $A_h \\in \\mathbb{R}^{N_h^2 \\times N_h^2}$ is the discrete operator, and $f_h \\in \\mathbb{R}^{N_h^2}$ is the right-hand side vector incorporating source terms (zero in this case) and boundary conditions. The subscript $h$ denotes quantities associated with the fine grid of spacing $h = 1/(N_h+1)$. The solution $u_h$ is a fine-grid approximation to the exact solution $u$.\n\nThe scalar quantity of interest, $J(u)$, is also discretized on the fine grid. As it is a linear functional of $u$, its discrete counterpart can be written as an inner product with a vector $c_h \\in \\mathbb{R}^{N_h^2}$:\n$$\nJ_h(u_h) = c_h^\\top u_h\n$$\n\nWe are given a solution $\\tilde{u}_H$ computed on a coarser grid with $N_H$ interior points and spacing $H = 1/(N_H+1)$. This solution is prolongated (interpolated) to the fine grid, yielding a vector $\\tilde{u}_h \\in \\mathbb{R}^{N_h^2}$. This prolongated vector serves as an approximation to the fine-grid solution $u_h$.\n\nThe error in the fine-grid solution is defined as $e_h = u_h - \\tilde{u}_h$. The corresponding error in the quantity of interest is:\n$$\nJ_h(u_h) - J_h(\\tilde{u}_h) = c_h^\\top u_h - c_h^\\top \\tilde{u}_h = c_h^\\top (u_h - \\tilde{u}_h) = c_h^\\top e_h\n$$\nThe error vector $e_h$ satisfies its own linear system. By substituting $u_h = e_h + \\tilde{u}_h$ into the fine-grid system, we get:\n$$\nA_h (e_h + \\tilde{u}_h) = f_h \\implies A_h e_h = f_h - A_h \\tilde{u}_h\n$$\nThe term $r_h = f_h - A_h \\tilde{u}_h$ is the residual of the prolongated coarse solution on the fine grid. It measures how poorly $\\tilde{u}_h$ satisfies the fine-grid equations. Thus, the error equation is $A_h e_h = r_h$.\n\nTo evaluate the error in the QoI, $c_h^\\top e_h$, without solving for $e_h$ (which is equivalent to solving the original fine-grid problem), we introduce a dual or adjoint problem. The discrete adjoint problem is defined as finding a vector $\\psi_h \\in \\mathbb{R}^{N_h^2}$ that solves:\n$$\nA_h^\\top \\psi_h = c_h\n$$\nThe vector $\\psi_h$ represents the sensitivity of the QoI to local residuals.\n\nUsing the adjoint solution, we can express the error in the QoI as follows:\n$$\nJ_h(u_h) - J_h(\\tilde{u}_h) = c_h^\\top e_h = (A_h^\\top \\psi_h)^\\top e_h = \\psi_h^\\top (A_h e_h) = \\psi_h^\\top r_h\n$$\nThis final expression, $\\psi_h^\\top r_h$, provides the desired error estimate, which we denote by $\\eta$. It is computed by taking the inner product of the solution to the adjoint problem and the residual of the primal problem. This is a standard and powerful technique in goal-oriented error estimation. The term $J(u) - J_h(u_h)$ is assumed to be subordinate to the error represented by $\\eta$.\n\nThe computational procedure for each test case is as follows:\n1.  **Coarse Grid Solution**: Construct the coarse-grid matrix $A_H$ and right-hand side $f_H$ for the given parameters $(\\nu, \\boldsymbol{\\beta})$ and grid size $N_H$. Solve the linear system $A_H \\tilde{u}_H = f_H$ to obtain the coarse-grid solution vector $\\tilde{u}_H$.\n2.  **Prolongation**: Form a complete coarse-grid nodal field by including the specified Dirichlet boundary values. Use bilinear interpolation on this field to find the values of the solution at the fine-grid interior node locations. This yields the prolongated solution vector $\\tilde{u}_h$.\n3.  **Fine Grid Residual**: Construct the fine-grid matrix $A_h$ and right-hand side vector $f_h$ for grid size $N_h$. Compute the fine-grid residual $r_h = f_h - A_h \\tilde{u}_h$.\n4.  **Adjoint Solution**: Construct the vector $c_h$ that represents the discrete quantity of interest. Solve the adjoint system $A_h^\\top \\psi_h = c_h$ for the adjoint solution $\\psi_h$.\n5.  **Error Estimate**: Compute the scalar error estimate as the dot product $\\eta = \\psi_h^\\top r_h$.\n\nThis procedure will be implemented for each of the four test cases provided.", "answer": "```python\nimport numpy as np\nfrom scipy import sparse\nfrom scipy.sparse import linalg as sla\nfrom scipy.interpolate import RegularGridInterpolator\n\ndef assemble_system(N, nu, beta_x, beta_y):\n    \"\"\"\n    Assembles the sparse matrix A and RHS vector f for the discretized\n    convection-diffusion problem on an N x N interior grid.\n    \n    Args:\n        N (int): Number of interior grid points in one dimension.\n        nu (float): Diffusion coefficient.\n        beta_x (float): Convection velocity in x.\n        beta_y (float): Convection velocity in y.\n        \n    Returns:\n        tuple: (scipy.sparse.csr_matrix, numpy.ndarray) representing A and f.\n    \"\"\"\n    h = 1.0 / (N + 1.0)\n    N2 = N * N\n    \n    # Use lists to build COO-format matrix data\n    data = []\n    row_ind = []\n    col_ind = []\n    f = np.zeros(N2)\n\n    nu_h2 = nu / (h * h)\n    beta_x_h = beta_x / h\n    beta_y_h = beta_y / h\n\n    beta_x_pos = max(0, beta_x_h)\n    beta_x_neg = min(0, beta_x_h)\n    beta_y_pos = max(0, beta_y_h)\n    beta_y_neg = min(0, beta_y_h)\n    \n    diag_coeff = 4.0 * nu_h2 + beta_x_pos - beta_x_neg + beta_y_pos - beta_y_neg\n\n    for j in range(1, N + 1):  # 1-based y-index of grid node\n        for i in range(1, N + 1):  # 1-based x-index of grid node\n            k = (j - 1) * N + (i - 1)  # 0-based row-major 1D index\n            \n            # Diagonal entry\n            data.append(diag_coeff)\n            row_ind.append(k)\n            col_ind.append(k)\n\n            # Neighbor u_{i, j-1}\n            if j > 1:\n                data.append(-nu_h2 - beta_y_pos)\n                row_ind.append(k)\n                col_ind.append(k - N)\n            else:  # Boundary at y=0, g=0\n                f[k] += (nu_h2 + beta_y_pos) * 0.0\n\n            # Neighbor u_{i, j+1}\n            if j < N:\n                data.append(-nu_h2 + beta_y_neg)\n                row_ind.append(k)\n                col_ind.append(k + N)\n            else:  # Boundary at y=1, g=0\n                f[k] += (nu_h2 - beta_y_neg) * 0.0\n\n            # Neighbor u_{i-1, j}\n            if i > 1:\n                data.append(-nu_h2 - beta_x_pos)\n                row_ind.append(k)\n                col_ind.append(k - 1)\n            else:  # Boundary at x=0, g=sin(2*pi*y)\n                y_j = j * h\n                g_val = np.sin(2.0 * np.pi * y_j)\n                f[k] += (nu_h2 + beta_x_pos) * g_val\n            \n            # Neighbor u_{i+1, j}\n            if i < N:\n                data.append(-nu_h2 + beta_x_neg)\n                row_ind.append(k)\n                col_ind.append(k + 1)\n            else:  # Boundary at x=1, g=0\n                f[k] += (nu_h2 - beta_x_neg) * 0.0\n\n    A = sparse.csr_matrix((data, (row_ind, col_ind)), shape=(N2, N2))\n    return A, f\n\ndef get_qoi_vector(N, h):\n    \"\"\"\n    Constructs the vector c that represents the QoI linear functional.\n    \"\"\"\n    N2 = N * N\n    c = np.zeros(N2)\n    \n    x_min, x_max = 0.6, 0.8\n    y_min, y_max = 0.45, 0.55\n\n    i_min = int(np.ceil(x_min / h))\n    i_max = int(np.floor(x_max / h))\n    j_min = int(np.ceil(y_min / h))\n    j_max = int(np.floor(y_max / h))\n    \n    node_indices = []\n    if i_min <= i_max and j_min <= j_max:\n        for j in range(j_min, j_max + 1):\n            for i in range(i_min, i_max + 1):\n                k = (j - 1) * N + (i - 1)\n                node_indices.append(k)\n    \n    m = len(node_indices)\n    if m > 0:\n        c[node_indices] = 1.0 / m\n    \n    return c\n\ndef prolongate(u_H_vec, N_H, N_h):\n    \"\"\"\n    Prolongates a coarse grid solution to the fine grid using bilinear interpolation.\n    \"\"\"\n    u_H_grid = u_H_vec.reshape((N_H, N_H))\n    \n    u_H_full = np.zeros((N_H + 2, N_H + 2))\n    u_H_full[1:-1, 1:-1] = u_H_grid\n    \n    y_H_pts_full = np.linspace(0, 1, N_H + 2)\n    x_H_pts_full = np.linspace(0, 1, N_H + 2)\n    \n    u_H_full[:, 0] = np.sin(2 * np.pi * y_H_pts_full)  # x=0 boundary\n    # Other boundaries are already 0.0\n\n    # The interpolator expects values indexed as (y, x), which matches u_H_full[j,i]\n    interp_func = RegularGridInterpolator((y_H_pts_full, x_H_pts_full), u_H_full)\n\n    h_h = 1.0 / (N_h + 1.0)\n    x_h_pts_interior = np.arange(1, N_h + 1) * h_h\n    y_h_pts_interior = np.arange(1, N_h + 1) * h_h\n    \n    # Create evaluation points (yy, xx) with 'ij' indexing\n    yy_fine, xx_fine = np.meshgrid(y_h_pts_interior, x_h_pts_interior, indexing='ij')\n    eval_points = np.vstack([yy_fine.ravel(), xx_fine.ravel()]).T\n\n    u_h_tilde_vec = interp_func(eval_points)\n    \n    return u_h_tilde_vec\n\ndef compute_error_estimate(nu, beta_x, beta_y, N_H, N_h):\n    \"\"\"\n    Computes the DWR error estimate for a given set of parameters.\n    \"\"\"\n    # 1. Coarse grid solve\n    A_H, f_H = assemble_system(N_H, nu, beta_x, beta_y)\n    u_H = sla.spsolve(A_H, f_H)\n\n    # 2. Prolongate coarse solution to fine grid\n    u_h_tilde = prolongate(u_H, N_H, N_h)\n    \n    # 3. Fine grid setup and residual computation\n    h_h = 1.0 / (N_h + 1.0)\n    A_h, f_h = assemble_system(N_h, nu, beta_x, beta_y)\n    r_h = f_h - A_h @ u_h_tilde\n\n    # 4. Adjoint problem setup and solve\n    c_h = get_qoi_vector(N_h, h_h)\n    psi_h = sla.spsolve(A_h.transpose(), c_h)\n    \n    # 5. Compute error estimate\n    eta = psi_h.T @ r_h\n\n    return eta\n\ndef solve():\n    \"\"\"\n    Main function to run all test cases and print results.\n    \"\"\"\n    test_cases = [\n        # (nu, beta_x, beta_y, N_H, N_h)\n        (0.05, 1.0, 0.0, 16, 32),\n        (0.01, 2.0, 1.0, 24, 48),\n        (0.10, 0.0, 0.0, 16, 32),\n        (0.05, 1.0, -1.0, 8, 16),\n    ]\n\n    results = []\n    for case in test_cases:\n        nu, beta_x, beta_y, N_H, N_h = case\n        eta = compute_error_estimate(nu, beta_x, beta_y, N_H, N_h)\n        results.append(f\"{eta:.6f}\")\n\n    print(f\"[{','.join(results)}]\")\n\nsolve()\n```", "id": "2432787"}]}