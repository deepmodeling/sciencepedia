{"hands_on_practices": [{"introduction": "The most fundamental check for any pseudo-random number generator is to test for bias. An unbiased generator should produce each possible outcome with equal likelihood. This practice introduces the powerful chi-squared goodness-of-fit test, a cornerstone of statistical analysis, which quantifies the discrepancy between observed frequencies and their expected values under a perfectly uniform model [@problem_id:2429686]. By working through this exercise, you will learn how to formally test for and identify bias in a generator producing discrete symbols.", "problem": "You are tasked with evaluating whether a Pseudo-Random Number Generator (PRNG) produces an unbiased sequence of discrete symbols from the alphabet $\\{ \\texttt{A}, \\texttt{T}, \\texttt{C}, \\texttt{G} \\}$. An unbiased generator would emit each symbol with equal probability $1/4$ at every draw, independently of previous draws. Using only first principles of hypothesis testing under a discrete uniform model, construct a decision rule that, given a finite sequence $s$ of length $n$ over $\\{ \\texttt{A}, \\texttt{T}, \\texttt{C}, \\texttt{G} \\}$, outputs a real-valued $p$-value and a boolean decision indicating whether there is sufficient evidence of marginal bias at significance level $\\alpha = 0.01$. Your decision rule must be based on the distribution of a scalar statistic computed from the observed counts, under the null hypothesis that each symbol has probability $1/4$ on each draw. The $p$-value must be the exact upper-tail probability of that statistic under the null model, and the boolean decision must be $\\texttt{True}$ if and only if the $p$-value is strictly less than $\\alpha$.\n\nFor a given sequence $s$, let $O_i$ be the observed count of symbol $i \\in \\{ \\texttt{A}, \\texttt{T}, \\texttt{C}, \\texttt{G} \\}$ in $s$, and let $E_i = n/4$ be the expected count under the null hypothesis. Define a single scalar test statistic from $\\{O_i\\}$ and $\\{E_i\\}$ whose reference distribution under the null is known in closed form and depends only on the number of categories $k = 4$. Use this reference distribution to compute the upper-tail probability for the realized statistic, which is the required $p$-value. Then compare the $p$-value to $\\alpha = 0.01$ to produce the boolean decision.\n\nTest suite. Apply your method to the following five sequences, each over $\\{ \\texttt{A}, \\texttt{T}, \\texttt{C}, \\texttt{G} \\}$:\n- Case $1$: $s_1$ is the concatenation of the string $\\texttt{\"ATCG\"}$ with itself $25$ times, so $n = 100$.\n- Case $2$: $s_2$ is the string $\\texttt{\"A\"}$ concatenated with itself $100$ times, so $n = 100$.\n- Case $3$: $s_3$ has counts $O_{\\texttt{A}} = 16$, $O_{\\texttt{T}} = 8$, $O_{\\texttt{C}} = 8$, $O_{\\texttt{G}} = 8$ in any order, so $n = 40$.\n- Case $4$: $s_4 = \\texttt{\"ATCG\"}$, so $n = 4$.\n- Case $5$: $s_5$ has counts $O_{\\texttt{A}} = 20$, $O_{\\texttt{T}} = 7$, $O_{\\texttt{C}} = 7$, $O_{\\texttt{G}} = 6$ in any order, so $n = 40$.\n\nAnswer specification. For each case $j \\in \\{1,2,3,4,5\\}$, your program must compute:\n- a boolean $\\texttt{reject}_j$ equal to $\\texttt{True}$ if and only if the $p$-value is less than $\\alpha = 0.01$, otherwise $\\texttt{False}$;\n- a float $p_j$ equal to the $p$-value.\n\nFinal output format. Your program should produce a single line of output containing a list of length $5$, where the $j$-th element is a two-element list $[\\texttt{reject}_j, p_j]$ in the same order as the cases above. For example, the output must have the form $[[\\texttt{bool}, \\texttt{float}],[\\texttt{bool}, \\texttt{float}],\\dots]$ with exactly five entries, printed on a single line. No physical units or angle units are involved in this problem.", "solution": "The problem statement has been critically examined and is deemed valid. It constitutes a well-posed and scientifically grounded problem in computational statistics, specifically a goodness-of-fit test for a discrete uniform distribution. The givens are complete, consistent, and objective, permitting a unique and verifiable solution using standard principles of hypothesis testing.\n\nThe task is to determine if a sequence of symbols from the alphabet $\\{ \\texttt{A}, \\texttt{T}, \\texttt{C}, \\texttt{G} \\}$ shows evidence of marginal bias. This is formulated as a hypothesis test. The null hypothesis, $H_0$, posits that the generator is unbiased, meaning each of the $k=4$ symbols is produced with equal probability $p_i = 1/4$. The alternative hypothesis, $H_A$, is that at least one symbol has a probability different from $1/4$.\n\nTo test this hypothesis, we use Pearson's chi-squared ($\\chi^2$) goodness-of-fit test. This test is based on a scalar statistic that measures the discrepancy between the observed symbol counts, $O_i$, and the expected counts under the null hypothesis, $E_i$. For a sequence of length $n$, the expected count for each symbol is $E_i = n \\cdot p_i = n/4$. The test statistic is defined as:\n$$ \\chi^2 = \\sum_{i=1}^{k} \\frac{(O_i - E_i)^2}{E_i} $$\nUnder the null hypothesis, this statistic approximately follows a chi-squared distribution with $k-1$ degrees of freedom. Since we have $k=4$ categories, the reference distribution is the chi-squared distribution with $df = 4 - 1 = 3$ degrees of freedom. This distribution is known in closed form and depends only on the number of categories, as required by the problem statement. The validity of this approximation is generally considered acceptable when all expected counts $E_i$ are at least $5$.\n\nThe decision rule is constructed as follows:\n1. For a given sequence, calculate the observed counts $O_i$ for each of the $4$ symbols.\n2. Calculate the chi-squared statistic, $\\chi^2_{\\text{calc}}$, using the formula above.\n3. Compute the $p$-value, which is the probability of observing a test statistic as extreme as or more extreme than $\\chi^2_{\\text{calc}}$, assuming $H_0$ is true. This corresponds to the upper-tail probability of the $\\chi^2_3$ distribution: $p = P(\\chi^2_3 \\ge \\chi^2_{\\text{calc}})$.\n4. Compare the $p$-value to the specified significance level $\\alpha = 0.01$. If $p < \\alpha$, we reject the null hypothesis and conclude there is sufficient evidence of marginal bias. The boolean decision `reject` is $\\texttt{True}$. Otherwise, we fail to reject $H_0$, and `reject` is $\\texttt{False}$.\n\nWe now apply this procedure to the five test cases.\n\nCase 1: $s_1$ is $\\texttt{\"ATCG\"}$ repeated $25$ times.\nThe sequence length is $n = 100$.\nThe observed counts are $O_{\\texttt{A}} = 25$, $O_{\\texttt{T}} = 25$, $O_{\\texttt{C}} = 25$, $O_{\\texttt{G}} = 25$.\nThe expected counts are $E_i = 100/4 = 25$ for all $i$.\nThe test statistic is:\n$$ \\chi^2_{\\text{calc}} = \\frac{(25-25)^2}{25} + \\frac{(25-25)^2}{25} + \\frac{(25-25)^2}{25} + \\frac{(25-25)^2}{25} = 0 $$\nThe $p$-value is $P(\\chi^2_3 \\ge 0) = 1$. Since $1 \\not< 0.01$, we fail to reject $H_0$. Decision: $\\texttt{False}$.\n\nCase 2: $s_2$ is $\\texttt{\"A\"}$ repeated $100$ times.\nThe sequence length is $n = 100$.\nThe observed counts are $O_{\\texttt{A}} = 100$, $O_{\\texttt{T}} = 0$, $O_{\\texttt{C}} = 0$, $O_{\\texttt{G}} = 0$.\nThe expected counts are $E_i = 100/4 = 25$.\nThe test statistic is:\n$$ \\chi^2_{\\text{calc}} = \\frac{(100-25)^2}{25} + \\frac{(0-25)^2}{25} + \\frac{(0-25)^2}{25} + \\frac{(0-25)^2}{25} = \\frac{75^2}{25} + 3 \\cdot \\frac{(-25)^2}{25} = 225 + 75 = 300 $$\nThe critical value for $\\chi^2_3$ at $\\alpha=0.01$ is approximately $11.345$. Since $300 \\gg 11.345$, the $p$-value is extremely small and certainly less than $0.01$. We reject $H_0$. Decision: $\\texttt{True}$.\n\nCase 3: $s_3$ has counts $O_{\\texttt{A}} = 16$, $O_{\\texttt{T}} = 8$, $O_{\\texttt{C}} = 8$, $O_{\\texttt{G}} = 8$.\nThe sequence length is $n = 16+8+8+8=40$.\nThe expected counts are $E_i = 40/4 = 10$.\nThe test statistic is:\n$$ \\chi^2_{\\text{calc}} = \\frac{(16-10)^2}{10} + \\frac{(8-10)^2}{10} + \\frac{(8-10)^2}{10} + \\frac{(8-10)^2}{10} = \\frac{36}{10} + \\frac{4}{10} + \\frac{4}{10} + \\frac{4}{10} = 3.6 + 1.2 = 4.8 $$\nSince $4.8 < 11.345$, the $p$-value is greater than $0.01$. We fail to reject $H_0$. Decision: $\\texttt{False}$.\n\nCase 4: $s_4 = \\texttt{\"ATCG\"}$.\nThe sequence length is $n = 4$.\nThe observed counts are $O_{\\texttt{A}} = 1$, $O_{\\texttt{T}} = 1$, $O_{\\texttt{C}} = 1$, $O_{\\texttt{G}} = 1$.\nThe expected counts are $E_i = 4/4 = 1$. Here, the condition $E_i \\ge 5$ is violated, so the chi-squared approximation is poor. Nonetheless, we follow the described procedure.\nThe test statistic is:\n$$ \\chi^2_{\\text{calc}} = \\frac{(1-1)^2}{1} + \\frac{(1-1)^2}{1} + \\frac{(1-1)^2}{1} + \\frac{(1-1)^2}{1} = 0 $$\nThe $p$-value is $P(\\chi^2_3 \\ge 0) = 1$. Since $1 \\not< 0.01$, we fail to reject $H_0$. Decision: $\\texttt{False}$.\n\nCase 5: $s_5$ has counts $O_{\\texttt{A}} = 20$, $O_{\\texttt{T}} = 7$, $O_{\\texttt{C}} = 7$, $O_{\\texttt{G}} = 6$.\nThe sequence length is $n = 20+7+7+6=40$.\nThe expected counts are $E_i = 40/4 = 10$.\nThe test statistic is:\n$$ \\chi^2_{\\text{calc}} = \\frac{(20-10)^2}{10} + \\frac{(7-10)^2}{10} + \\frac{(7-10)^2}{10} + \\frac{(6-10)^2}{10} = \\frac{100}{10} + \\frac{9}{10} + \\frac{9}{10} + \\frac{16}{10} = 10 + 0.9 + 0.9 + 1.6 = 13.4 $$\nSince $13.4 > 11.345$, the $p$-value is less than $0.01$. We reject $H_0$. Decision: $\\texttt{True}$.\n\nThe following program implements this logic to compute the precise $p$-values and decisions for each case.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.stats import chi2\n\ndef solve():\n    \"\"\"\n    Applies the chi-squared goodness-of-fit test to evaluate marginal bias\n    in sequences of discrete symbols.\n    \"\"\"\n    # Define the significance level from the problem statement.\n    alpha = 0.01\n    \n    # Define the number of categories (symbols in the alphabet).\n    k = 4\n    \n    # Degrees of freedom for the chi-squared distribution.\n    df = k - 1\n    \n    # Define the test cases from the problem statement.\n    # Each case is a tuple: (sequence_length_n, observed_counts_O)\n    test_cases = [\n        # Case 1: \"ATCG\" repeated 25 times. n = 100. Counts are 25 for each.\n        (100, [25, 25, 25, 25]),\n        \n        # Case 2: \"A\" repeated 100 times. n = 100. Counts are 100 for 'A', 0 for others.\n        (100, [100, 0, 0, 0]),\n        \n        # Case 3: n = 40. Counts are O_A=16, O_T=8, O_C=8, O_G=8.\n        (40, [16, 8, 8, 8]),\n        \n        # Case 4: s = \"ATCG\". n = 4. Counts are 1 for each.\n        (4, [1, 1, 1, 1]),\n        \n        # Case 5: n = 40. Counts are O_A=20, O_T=7, O_C=7, O_G=6.\n        (40, [20, 7, 7, 6]),\n    ]\n\n    results = []\n    for n, O in test_cases:\n        # Expected counts under the null hypothesis of a uniform distribution.\n        # E_i = n * (1/k) for all i.\n        E = n / k\n        \n        # Convert observed counts to a NumPy array for vectorized operations.\n        observed_counts = np.array(O)\n        \n        # Calculate Pearson's chi-squared test statistic.\n        # chi2_stat = sum((O_i - E_i)^2 / E_i)\n        # Using a small epsilon to avoid division by zero if E is zero,\n        # although in this problem E is always positive.\n        chi2_stat = np.sum((observed_counts - E)**2 / (E + 1e-9))\n        \n        # Calculate the p-value.\n        # This is the upper-tail probability of the chi-squared distribution\n        # with 'df' degrees of freedom. The survival function (sf) gives P(X > x).\n        p_value = chi2.sf(chi2_stat, df)\n        \n        # Make the decision: reject the null hypothesis if p-value  alpha.\n        # The result must be a native Python boolean (True/False).\n        reject = bool(p_value  alpha)\n        \n        # Store the boolean decision and the p-value.\n        results.append([reject, p_value])\n\n    # Final print statement in the exact required format.\n    # The format is a list of lists: [[reject_1, p_1], [reject_2, p_2], ...]\n    # Using str() on each sublist automatically formats it correctly.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "2429686"}, {"introduction": "A sequence of numbers can be perfectly uniform in its distribution but still be highly predictable and non-random. This practice explores the concept of sequential independence using the runs test, an intuitive yet effective tool for detecting patterns like clustering or alternation [@problem_id:2429680]. By counting the number of \"runs\" of values above or below the median and comparing this to statistical expectations, you will gain hands-on experience in identifying when a generator's output fails to be independent from one draw to the next.", "problem": "You are to write a complete, runnable program that evaluates the number of runs above and below a central threshold for several finite sequences generated by specific Pseudo-Random Number Generators (PRNGs). The purpose is to decide, for each sequence, whether its observed number of runs is atypical under the null hypothesis that the sequence arises from independent and identically distributed (i.i.d.) draws from a continuous distribution. The test should use the binary classification of each value as either strictly above or strictly below the sample median of the entire sequence; values exactly equal to the median must be discarded before runs are counted.\n\nDefinitions to be used:\n- Given a finite real-valued sequence $\\{x_k\\}_{k=1}^{N}$, let $m$ denote its sample median. Construct a binary sequence $\\{b_k\\}$ by setting $b_k = 1$ if $x_k  m$ and $b_k = 0$ if $x_k  m$. Any $x_k$ with $x_k = m$ must be removed along with its position before runs are counted.\n- A run is a maximal contiguous block of identical values in the binary sequence. Let $R$ be the total number of runs in the resulting binary sequence of length $n$ (note $n \\le N$ after discarding ties at the median).\n\nNull hypothesis and decision:\n- Under the null hypothesis that the original sequence is i.i.d. from a continuous distribution, the sign sequence relative to the median behaves as though successive $b_k$ are independent with fixed category counts. The decision rule must be two-sided at significance level $\\alpha = 10^{-8}$.\n- If, after discarding values equal to the median, all remaining values fall into a single category (i.e., $n = 0$ or all $b_k$ are identical), then the decision for that case must be reported as the boolean value `False` (interpreted as “do not reject”), since the number of runs is not informative in this degenerate situation.\n\nTest suite (all parameters are fully specified; there is no user input):\n- Case A (length $N = 1000$): Alternating-high/low sequence defined by $x_k = 0.25$ for odd $k$ and $x_k = 0.75$ for even $k$.\n- Case B (length $N = 1000$): Linear Congruential Generator (LCG) with modulus $m = 2^{31} - 1$, multiplier $a = 16807$, increment $c = 0$, seed $x_0 = 1$, and output $u_k = x_k / m$ for $k = 1,\\dots,N$.\n- Case C (length $N = 1000$): Two-state “sticky” generator with long persistence. Let $s_1 = 1$. For $k \\ge 2$, let $s_k = s_{k-1}$ with probability $p = 0.95$ and $s_k = 1 - s_{k-1}$ with probability $1 - p$. Map $s_k$ to real values by $x_k = 0.75 + \\delta_k$ if $s_k = 1$ and $x_k = 0.25 + \\delta_k$ if $s_k = 0$, where $\\delta_k$ are independent and uniformly distributed in $[-10^{-12}, 10^{-12}]$. All randomness for this case must be produced deterministically using the same LCG as in Case B to generate the needed uniform variates.\n- Case D (length $N = 100$): Median-ties scenario. The first $60$ values are exactly $x_k = 0.5$. The remaining $40$ values are taken as the next $40$ outputs $u_k$ from the LCG in Case B (scaled to $[0,1)$ as in Case B).\n- Case E (length $N = 30$): Single-category degeneracy. All values are $x_k = 0.7$.\n\nProgram requirements:\n- For each case, construct the sequence exactly as specified. For each sequence, compute the decision to reject or not reject the null hypothesis at two-sided significance level $\\alpha = 10^{-8}$ using the number of runs relative to the sample median as defined above. Report the decision as a boolean: `True` for “reject” and `False` for “do not reject.” If the post-discarded sequence has fewer than two categories, report `False` for that case.\n- Final output format: Your program should produce a single line of output containing the results as a comma-separated list of booleans enclosed in square brackets (e.g., “[True,False,True,False,False]”), in the fixed order of cases A, B, C, D, E.\n\nThe answers for each test case are booleans. There are no physical units or angles in this task; do not print anything else besides the required single line in the specified format.", "solution": "The problem requires the validation of several sequences against the null hypothesis of randomness using a runs test. The test statistic is the number of runs above and below the sample median. A decision to reject or not reject the null hypothesis must be made for each sequence at a significance level of $\\alpha = 10^{-8}$.\n\nFirst, we must formalize the statistical procedure.\n\n**Problem Validation**\n\nStep 1: Extract Givens\n- **Sequence Generation Methods**:\n  - Case A: Alternating sequence, $x_k = 0.25$ for odd $k$, $x_k = 0.75$ for even $k$, $N=1000$.\n  - Case B: Linear Congruential Generator (LCG) with modulus $m = 2^{31} - 1$, multiplier $a = 16807$, increment $c = 0$, seed $x_0 = 1$. Sequence is $u_k = x_k/m$ for $k=1, \\dots, N$, with $N=1000$.\n  - Case C: Two-state \"sticky\" generator. State $s_k \\in \\{0, 1\\}$. $s_1=1$. $s_k = s_{k-1}$ with probability $p=0.95$, $s_k=1-s_{k-1}$ with probability $1-p$. Output $x_k = 0.75 + \\delta_k$ for $s_k=1$, $x_k = 0.25 + \\delta_k$ for $s_k=0$. $\\delta_k$ are i.i.d. $U[-10^{-12}, 10^{-12}]$. Randomness sourced from the LCG of Case B. $N=1000$.\n  - Case D: Median-ties sequence. First $60$ values are $x_k = 0.5$. The next $40$ values are from the LCG of Case B. $N=100$.\n  - Case E: Single-category degeneracy. All $x_k = 0.7$ for $N=30$.\n- **Runs Test Definition**:\n  - The threshold is the sample median, $m$.\n  - Values $x_k = m$ are discarded. The remaining sequence has length $n$.\n  - A binary sequence is formed: $1$ for $x_k  m$, $0$ for $x_k  m$.\n  - $R$ is the number of runs in this binary sequence.\n- **Hypothesis and Decision Rule**:\n  - Null hypothesis ($H_0$): The original sequence is i.i.d. from a continuous distribution.\n  - Significance level $\\alpha = 10^{-8}$ for a two-sided test.\n  - Degenerate case rule: If, after discarding ties, all values are in one category (i.e., $n_0=0$ or $n_1=0$) or no values remain ($n=0$), the decision is to not reject $H_0$ (output `False`).\n  - The final output is a list of booleans (`True` for reject, `False` for do not reject) for cases A-E.\n\nStep 2: Validate Using Extracted Givens\n- **Scientifically Grounded**: The problem is based on the runs test, a standard non-parametric statistical test for randomness. The LCG specified is the well-known Park-Miller generator. All concepts are from established statistics and computational science.\n- **Well-Posed**: Each case is fully specified. The statistical test, including the handling of ties and degenerate cases, is clearly defined. The decision rule is unambiguous. A unique, meaningful solution exists for each case.\n- **Objective**: The problem statement is free of subjective language. All parameters and procedures are quantitatively defined.\n\nStep 3: Verdict and Action\nThe problem is valid. It is a well-defined computational statistics problem with clear instructions and scientifically sound principles. I will proceed with the solution.\n\n**Methodology and Step-by-Step Solution**\n\nThe core of the solution is the implementation of the runs test. For a sequence $\\{x_k\\}$ of length $N$:\n1.  Compute the sample median, $m$.\n2.  Filter the sequence, retaining only values not equal to $m$. Let the new sequence have length $n$.\n3.  Let $n_1$ be the count of values greater than $m$ and $n_0$ be the count of values less than $m$. Thus, $n = n_0 + n_1$.\n4.  As per the problem's explicit rule, if $n_0=0$ or $n_1=0$, the test is inconclusive, and we do not reject $H_0$. The result is `False`.\n5.  Otherwise, we proceed. Count the number of runs, $R$, in the sequence of values classified as above or below the median.\n6.  Under the null hypothesis $H_0$, for large $n_0$ and $n_1$, the distribution of $R$ is approximately normal with mean $\\mu_R$ and variance $\\sigma_R^2$ given by:\n    $$ \\mu_R = \\frac{2 n_0 n_1}{n} + 1 $$\n    $$ \\sigma_R^2 = \\frac{2 n_0 n_1 (2 n_0 n_1 - n)}{(n)^2 (n - 1)} $$\n7.  The standardized test statistic $Z$ is calculated as:\n    $$ Z = \\frac{R - \\mu_R}{\\sigma_R} $$\n8.  For a two-sided test at significance level $\\alpha = 10^{-8}$, we find the critical value $Z_{\\alpha/2}$ from the standard normal distribution. $P(|Z|  Z_{\\alpha/2}) = \\alpha$. The critical value corresponds to the $(1 - \\alpha/2)$ quantile. For $\\alpha = 10^{-8}$, this is the $(1 - 5 \\times 10^{-9})$ quantile, which is $Z_{crit} \\approx 5.7309$.\n9.  The decision rule is to reject $H_0$ if $|Z|  Z_{crit}$. This corresponds to an output of `True`. Otherwise, we do not reject $H_0$, yielding an output of `False`.\n\n**Analysis of Test Cases:**\n\n- **Case A (Alternating Sequence)**: The sequence $\\{0.25, 0.75, 0.25, \\dots\\}$ of length $N=1000$ has a median $m=0.5$. There are no ties. We have $n=1000$, with $n_0=500$ values below the median and $n_1=500$ values above. The binary sequence is $\\{0, 1, 0, 1, \\dots\\}$. The number of runs is $R=1000$.\n  The expected number of runs is $\\mu_R = \\frac{2(500)(500)}{1000} + 1 = 501$. The variance is $\\sigma_R^2 = \\frac{2(500)(500)(2(500)(500)-1000)}{1000^2(999)} \\approx 249.75$. The standard deviation is $\\sigma_R \\approx 15.80$.\n  The $Z$-score is $Z = (1000 - 501) / 15.80 \\approx 31.58$. Since $|31.58|  5.7309$, we reject $H_0$. Result: `True`.\n\n- **Case B (LCG)**: A sequence of $N=1000$ values from a good pseudo-random number generator should appear random. After finding the median, we will have $n=1000$, $n_0=500$, and $n_1=500$. The number of runs $R$ is expected to be close to $\\mu_R = 501$. The resulting $Z$-score will be small, so we will not reject $H_0$. Result: `False`.\n\n- **Case C (Sticky Generator)**: This generator is designed to have strong positive serial correlation. For $N=1000$, the state is expected to flip only about $(1-0.95) \\times (N-1) \\approx 50$ times. This will result in a very small number of runs, $R \\approx 50$. The expected number of runs, assuming the states are occupied roughly equally, is again $\\mu_R \\approx 501$. The observed $R$ is far from the expected value, leading to a large negative $Z$-score, e.g., $Z \\approx (50 - 501)/15.80 \\approx -28.5$. We reject $H_0$. Result: `True`.\n\n- **Case D (Median Ties)**: The sequence of $N=100$ has $60$ values of $0.5$ and $40$ values from an LCG. The median is $m=0.5$. The $60$ ties are discarded, leaving $n=40$ random values. The test is performed on these values relative to the original median of $0.5$. Since the LCG values are uniform on $[0,1)$, we expect $n_0 \\approx 20$ and $n_1 \\approx 20$. The number of runs $R$ in this shorter random sequence should be close to its expected value, e.g., $\\mu_R = \\frac{2(20)(20)}{40} + 1 = 21$. The $Z$-score will be small. We do not reject $H_0$. Result: `False`.\n\n- **Case E (Degenerate Case)**: All $N=30$ values are $0.7$. The median is $m=0.7$. All values are discarded. The remaining sequence has length $n=0$. This is a degenerate case as defined in the problem ($n_0=0, n_1=0$). We do not reject $H_0$. Result: `False`.\n\nThe implementation will precisely follow this logic for each case. The LCG required for cases B, C, and D will be re-initialized for each case to ensure deterministic, independent test conditions.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.stats import norm\n\ndef solve():\n    \"\"\"\n    Main function to run the test suite and print the results.\n    \"\"\"\n    \n    # --- Helper functions ---\n\n    def lcg_generator(n_values, seed=1):\n        \"\"\"Generates a sequence of n_values from a LCG.\"\"\"\n        m = 2**31 - 1\n        a = 16807\n        \n        # Use Python's arbitrary-precision integers for calculations\n        x = seed\n        results = np.zeros(n_values)\n        for i in range(n_values):\n            x = (a * x) % m\n            results[i] = x / m\n        return results\n\n    def runs_test(x, alpha=1e-8):\n        \"\"\"\n        Performs the runs test for randomness on a sequence x.\n        Returns True to reject H0, False to not reject.\n        \"\"\"\n        if len(x) == 0:\n            return False\n\n        median = np.median(x)\n        \n        # Filter out elements equal to the median\n        filtered_x = x[x != median]\n        \n        n = len(filtered_x)\n        if n == 0:\n            return False\n            \n        # Create binary sequence\n        binary_seq = (filtered_x > median).astype(int)\n        \n        n1 = np.sum(binary_seq)\n        n0 = n - n1\n        \n        # Degenerate case rule from problem statement\n        if n0 == 0 or n1 == 0:\n            return False\n\n        # Count runs\n        # A run starts at the beginning, and every time the value changes.\n        runs = 1 + np.sum(np.diff(binary_seq) != 0)\n        \n        # Large sample approximation for runs test\n        mu_r = (2 * n0 * n1) / n + 1\n        \n        # Denominator term to check for n=1 case (already covered by n0/n1 check)\n        denom_var = (n**2) * (n - 1)\n        if denom_var == 0:\n            # This case is avoided by the n0=0 or n1=0 check, but as a safeguard:\n            return False\n            \n        sigma_sq_r = (2 * n0 * n1 * (2 * n0 * n1 - n)) / denom_var\n        \n        if sigma_sq_r = 0:\n            # If R is deterministic, variance is 0. Cannot form Z-stat. Do not reject.\n            return False\n            \n        sigma_r = np.sqrt(sigma_sq_r)\n        \n        # Z-statistic\n        z_score = (runs - mu_r) / sigma_r\n        \n        # Two-sided critical value\n        z_crit = norm.ppf(1 - alpha / 2)\n        \n        # Decision: reject if |Z| > Z_crit\n        return abs(z_score) > z_crit\n\n    # --- Test Case Generators ---\n\n    def generate_case_a():\n        n = 1000\n        x = np.zeros(n)\n        x[::2] = 0.25  # Odd k (indices 0, 2, ...)\n        x[1::2] = 0.75 # Even k (indices 1, 3, ...)\n        return x\n\n    def generate_case_b():\n        n = 1000\n        return lcg_generator(n_values=n, seed=1)\n\n    def generate_case_c():\n        n = 1000\n        p_stay = 0.95\n        \n        # Use a fresh LCG instance for deterministic randomness\n        # We need N-1 values for transitions and N values for noise\n        rand_stream = lcg_generator(n_values=2 * n - 1, seed=1)\n        \n        transition_rands = rand_stream[:n - 1]\n        noise_rands = rand_stream[n - 1:]\n\n        states = np.zeros(n, dtype=int)\n        states[0] = 1\n        for i in range(1, n):\n            if transition_rands[i-1]  (1 - p_stay):\n                states[i] = 1 - states[i-1]\n            else:\n                states[i] = states[i-1]\n        \n        # Generate noise term delta in [-1e-12, 1e-12]\n        deltas = (2 * noise_rands - 1) * 1e-12\n        \n        x = np.zeros(n)\n        x[states == 1] = 0.75 + deltas[states == 1]\n        x[states == 0] = 0.25 + deltas[states == 0]\n        \n        return x\n\n    def generate_case_d():\n        n_ties = 60\n        n_lcg = 40\n        \n        ties = np.full(n_ties, 0.5)\n        lcg_vals = lcg_generator(n_values=n_lcg, seed=1)\n        \n        return np.concatenate((ties, lcg_vals))\n\n    def generate_case_e():\n        n = 30\n        return np.full(n, 0.7)\n\n    # --- Main Logic ---\n\n    test_cases = {\n        'A': generate_case_a,\n        'B': generate_case_b,\n        'C': generate_case_c,\n        'D': generate_case_d,\n        'E': generate_case_e,\n    }\n    \n    results = []\n    # Process cases in the required order A, B, C, D, E\n    for case_id in sorted(test_cases.keys()):\n        generator_func = test_cases[case_id]\n        sequence = generator_func()\n        decision = runs_test(sequence)\n        results.append(decision)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "2429680"}, {"introduction": "Some flaws in pseudo-random number generators are subtle and require more sophisticated statistical probes. This practice implements a collision test, which is conceptually linked to the famous \"birthday problem,\" to reveal such weaknesses [@problem_id:2429616]. You will learn to measure the rate at which a generator produces repeating values (collisions) and test whether this rate is consistent with what is expected from a truly random source, providing a powerful technique for vetting the quality of algorithms like Linear Congruential Generators.", "problem": "Implement a mathematically specified collision test inspired by the Diehard suite and connect it to the classical birthday problem. Consider a pseudo-random number generator (PRNG) defined by a linear congruential generator (LCG). Let the sequence $\\{x_n\\}_{n \\ge 0}$ be defined over the modulus $2^{32}$ by the recurrence\n$$\nx_{n+1} \\equiv a x_n + c \\pmod{2^{32}},\n$$\nwith multiplier $a = 1664525$, increment $c = 1013904223$, and initial seed $x_0 = s$. For a given positive integer $t$, define the first $t$ outputs as $u_1,u_2,\\dots,u_t$ where $u_n = x_n$ interpreted as an integer in $\\{0,1,\\dots,2^{32}-1\\}$.\n\nFix a positive integer $b$ (the number of bins). Define the bin index sequence $\\{i_n\\}_{n=1}^t$ by\n$$\ni_n \\equiv u_n \\bmod b \\in \\{0,1,\\dots,b-1\\}.\n$$\nLet $c_j$ be the number of indices $n \\in \\{1,\\dots,t\\}$ such that $i_n = j$, for each $j \\in \\{0,1,\\dots,b-1\\}$. Define the number of colliding unordered pairs\n$$\nK \\equiv \\sum_{j=0}^{b-1} \\binom{c_j}{2}.\n$$\n\nUnder the null hypothesis that the bin indices are independent and identically distributed with the uniform distribution on $\\{0,1,\\dots,b-1\\}$, and for large $b$ with $t$ not too large relative to $b$, the distribution of $K$ is well approximated by a Poisson distribution with mean\n$$\n\\lambda \\equiv \\frac{\\binom{t}{2}}{b} = \\frac{t(t-1)}{2b}.\n$$\nFor an observed $K$, define the two-sided $p$-value by\n$$\np \\equiv 2 \\min\\left( \\mathbb{P}(X \\le K),\\ \\mathbb{P}(X \\ge K)\\right),\n$$\nwhere $X \\sim \\mathrm{Poisson}(\\lambda)$ and $\\mathbb{P}(X \\ge K) = 1 - \\mathbb{P}(X \\le K-1)$, with the convention that $\\mathbb{P}(X \\le -1) = 0$.\n\nYour task is to write a complete program that, for each test case below, constructs the specified LCG sequence, maps values into $b$ bins, computes $K$, computes $\\lambda$, and then returns the two-sided $p$-value $p$ as defined above. No external input shall be read by the program.\n\nTest suite:\n- Case $1$: $b = 2^{16}$, $t = 100000$, $s = 123456789$.\n- Case $2$: $b = 10^{6}$, $t = 1000$, $s = 42$.\n- Case $3$: $b = 2^{20}$, $t = 1448$, $s = 987654321$.\n\nThe required program output format is a single line containing the $p$-values for the three cases in order, as a comma-separated list enclosed in square brackets, with each $p$-value rounded to exactly $6$ digits after the decimal point. For example: \"[$0.123456,0.500000,0.987654$]\". All outputs are unitless real numbers in decimal form.", "solution": "The problem statement is subjected to validation.\n\n### Step 1: Extract Givens\n- **Pseudo-Random Number Generator (PRNG)**: Linear Congruential Generator (LCG).\n- **Recurrence Relation**: $x_{n+1} \\equiv a x_n + c \\pmod{2^{32}}$, with integer sequence $\\{x_n\\}_{n \\ge 0}$.\n- **Multiplier**: $a = 1664525$.\n- **Increment**: $c = 1013904223$.\n- **Modulus**: $2^{32}$.\n- **Initial Seed**: $x_0 = s$.\n- **PRNG Outputs**: For a given positive integer $t$, the first $t$ outputs are $u_1, u_2, \\dots, u_t$, where $u_n = x_n$.\n- **Binning**: A positive integer $b$ defines the number of bins.\n- **Bin Index Sequence**: $\\{i_n\\}_{n=1}^t$ is defined by $i_n \\equiv u_n \\bmod b$, with values in $\\{0, 1, \\dots, b-1\\}$.\n- **Bin Counts**: Let $c_j$ be the count for bin $j$, for $j$ from $0$ to $b-1$.\n- **Number of Collisions**: $K \\equiv \\sum_{j=0}^{b-1} \\binom{c_j}{2}$.\n- **Null Hypothesis**: The bin indices $\\{i_n\\}$ are independent and identically distributed (i.i.d.) with the uniform distribution on $\\{0, 1, \\dots, b-1\\}$.\n- **Approximation**: Under the null hypothesis, for large $b$ and $t$ not too large relative to $b$, the distribution of $K$ is approximated by a Poisson distribution.\n- **Poisson Mean**: $\\lambda \\equiv \\frac{\\binom{t}{2}}{b} = \\frac{t(t-1)}{2b}$.\n- **Two-Sided $p$-value**: $p \\equiv 2 \\min\\left( \\mathbb{P}(X \\le K),\\ \\mathbb{P}(X \\ge K)\\right)$, where $X \\sim \\mathrm{Poisson}(\\lambda)$.\n- **Probability Calculation**: $\\mathbb{P}(X \\ge K) = 1 - \\mathbb{P}(X \\le K-1)$, with the convention that $\\mathbb{P}(X \\le -1) = 0$.\n- **Test Cases**:\n    - Case $1$: $b = 2^{16}$, $t = 100000$, $s = 123456789$.\n    - Case $2$: $b = 10^{6}$, $t = 1000$, $s = 42$.\n    - Case $3$: $b = 2^{20}$, $t = 1448$, $s = 987654321$.\n\n### Step 2: Validate Using Extracted Givens\n- **Scientific Grounding**: The problem describes a collision test, a standard statistical method for evaluating the quality of pseudo-random number generators. The LCG is a classical PRNG. The Poisson approximation for the number of collisions in a birthday-problem-like scenario is a well-established result in probability theory. The chosen LCG parameters $a$ and $c$ are known in the literature (e.g., used in Knuth's MMIX). The problem is scientifically sound.\n- **Well-Posedness**: All necessary parameters ($a, c, s, t, b$) and formulas for computation ($K, \\lambda, p$) are explicitly provided. The procedure is deterministic and leads to a unique, computable result for each test case.\n- **Objectivity**: The problem is stated in precise, mathematical terms, free from any subjective or ambiguous language.\n\n### Step 3: Verdict and Action\nThe problem is valid as it is scientifically grounded, well-posed, objective, and complete. I will now provide the solution.\n\nThe solution is a systematic implementation of the procedure described in the problem statement. For each test case, specified by the parameters $(s, t, b)$, we perform the following steps.\n\n**1. LCG Sequence Generation**\nFirst, we generate a sequence of $t$ pseudo-random integers. The sequence $\\{x_n\\}_{n \\ge 0}$ is defined by the recurrence relation\n$$x_{n+1} \\equiv (a \\cdot x_n + c) \\pmod{2^{32}}$$\nwith $a = 1664525$, $c = 1013904223$, and the modulus $M = 2^{32}$. The computation is performed using unsigned $32$-bit integer arithmetic, which corresponds to taking the result modulo $2^{32}$. Starting with the given seed $x_0 = s$, we generate the sequence of $t$ values $\\{u_1, u_2, \\dots, u_t\\}$, where $u_n = x_n$ for $n=1, \\dots, t$.\n\n**2. Binning and Collision Counting**\nThe generated integers $\\{u_n\\}_{n=1}^t$ are mapped to a set of $b$ bins. The bin index $i_n$ for each integer $u_n$ is computed as\n$$i_n = u_n \\pmod b$$\nThe result $i_n$ is an integer in the set $\\{0, 1, \\dots, b-1\\}$. We then count the number of times each bin is hit. Let $c_j$ be the count for bin $j$, for $j$ from $0$ to $b-1$. The total number of unordered colliding pairs, $K$, is the sum of collisions within each bin. The number of pairs in a bin with $c_j$ items is $\\binom{c_j}{2}$. Thus, the total number of collisions is\n$$K = \\sum_{j=0}^{b-1} \\binom{c_j}{2} = \\sum_{j=0}^{b-1} \\frac{c_j(c_j-1)}{2}$$\n\n**3. Statistical Evaluation**\nUnder the null hypothesis that the PRNG is ideal, the bin indices $\\{i_n\\}$ are i.i.d. and uniformly distributed. The number of collisions $K$ is then expected to follow a Poisson distribution, $X \\sim \\mathrm{Poisson}(\\lambda)$, with mean $\\lambda$ given by\n$$\\lambda = \\frac{\\binom{t}{2}}{b} = \\frac{t(t-1)}{2b}$$\nThis is the expected number of collisions when $t$ items are thrown randomly into $b$ bins.\n\nTo quantify the deviation of the observed collision count $K$ from its expectation, we calculate a two-sided $p$-value. The $p$-value measures the probability of observing a result at least as extreme as $K$. It is defined as\n$$p = 2 \\min\\left( \\mathbb{P}(X \\le K),\\ \\mathbb{P}(X \\ge K)\\right)$$\nwhere $X \\sim \\mathrm{Poisson}(\\lambda)$. The probabilities are calculated using the Poisson cumulative distribution function (CDF), denoted $F(k; \\lambda) = \\mathbb{P}(X \\le k)$.\nThe two terms are:\n- The left-tail probability: $\\mathbb{P}(X \\le K) = F(K; \\lambda)$.\n- The right-tail probability: $\\mathbb{P}(X \\ge K) = 1 - \\mathbb{P}(X \\le K-1) = 1 - F(K-1; \\lambda)$. This is also directly computable via the survival function (SF), where $\\mathrm{sf}(k; \\lambda) = \\mathbb{P}(X  k)$. Thus, $\\mathbb{P}(X \\ge K) = \\mathrm{sf}(K-1; \\lambda)$.\n\nThe implementation will utilize numerical libraries for these calculations: `numpy` for efficient array manipulation in the generation and binning steps, and `scipy.stats.poisson` to compute the CDF and SF of the Poisson distribution. The final $p$-value for each test case is then formatted as required.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.stats import poisson\n\ndef solve():\n    \"\"\"\n    Main function to solve the problem for the given test cases.\n    It calculates the p-value for a collision test on an LCG PRNG.\n    \"\"\"\n    \n    # Define the test cases from the problem statement.\n    test_cases = [\n        # (b, t, s)\n        (2**16, 100000, 123456789),\n        (10**6, 1000, 42),\n        (2**20, 1448, 987654321),\n    ]\n\n    results = []\n    \n    # LCG parameters\n    a = 1664525\n    c = 1013904223\n    # Use a mask for 32-bit unsigned integer arithmetic\n    mod_mask = 0xFFFFFFFF \n\n    for b, t, s in test_cases:\n        # Step 1: LCG Sequence Generation\n        # The sequence is x_1, x_2, ..., x_t\n        # where x_{n+1} = a*x_n + c (mod 2^32) and x_0 = s.\n        x_n = s\n        u_sequence = np.empty(t, dtype=np.uint32)\n        for i in range(t):\n            x_n = (a * x_n + c)  mod_mask\n            u_sequence[i] = x_n\n\n        # Step 2: Binning and Collision Counting\n        # Map generated values to bins\n        i_sequence = u_sequence % b\n        \n        # Count occurrences in each bin\n        # minlength ensures the counts array has size b even if some high-indexed bins are empty.\n        counts = np.bincount(i_sequence, minlength=b)\n        \n        # Calculate the observed number of collisions, K\n        # K = sum over all bins j of C(c_j, 2)\n        # Using np.int64 for K to avoid overflow with large counts\n        K = np.sum(counts.astype(np.int64) * (counts.astype(np.int64) - 1) // 2)\n\n        # Step 3: Statistical Evaluation\n        # Calculate the Poisson mean lambda\n        lambda_val = (t * (t - 1)) / (2 * b)\n        \n        # Calculate the two-sided p-value\n        # P(X = K)\n        prob_le_K = poisson.cdf(K, lambda_val)\n        \n        # P(X >= K) = 1 - P(X = K-1)\n        # Using the survival function sf(k) = 1 - cdf(k) is more numerically stable.\n        # P(X >= K) = P(X > K-1) = sf(K-1)\n        prob_ge_K = poisson.sf(K - 1, lambda_val)\n        \n        p_value = 2 * min(prob_le_K, prob_ge_K)\n        \n        results.append(p_value)\n\n    # Format the final output string as specified\n    formatted_results = [f\"{res:.6f}\" for res in results]\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```", "id": "2429616"}]}