{"hands_on_practices": [{"introduction": "The effectiveness of the Particle Swarm Optimization algorithm is highly dependent on the choice of its core parameters. This first practice provides a crucial, hands-on opportunity to explore this sensitivity by tuning the inertia weight $\\omega$, cognitive coefficient $c_1$, and social coefficient $c_2$. By implementing a grid search to find the optimal parameter set for a standard benchmark function, you will gain practical experience in the essential process of hyperparameter tuning and understand how it governs the balance between global exploration and local exploitation.[@problem_id:2423083]", "problem": "You are given the task of selecting hyperparameters for a continuous-domain optimizer known as Particle Swarm Optimization (PSO) to minimize a standard nonconvex function. Let the objective be the Ackley function in dimension $d$, defined for $\\mathbf{x} \\in \\mathbb{R}^d$ by\n$$\nf(\\mathbf{x}) \\;=\\; -20\\exp\\!\\left(-0.2\\sqrt{\\frac{1}{d}\\sum_{i=1}^d x_i^2}\\right) \\;-\\; \\exp\\!\\left(\\frac{1}{d}\\sum_{i=1}^d \\cos(2\\pi x_i)\\right) \\;+\\; 20 \\;+\\; e,\n$$\nwith domain constraint $\\mathbf{x}\\in[-5,5]^d$. The cosine function uses angles in radians. The goal of PSO is to minimize $f(\\mathbf{x})$ under a finite evaluation budget; the PSO algorithm is parameterized by three real-valued hyperparameters $(\\omega,c_1,c_2)$ that govern the stochastic dynamical system for particle positions and velocities.\n\nFor a PSO configuration with $n$ particles and $T$ iterations, define the dynamical update at iteration $t\\in\\{1,2,\\dots,T\\}$ for particle $p\\in\\{1,2,\\dots,n\\}$ and coordinate $j\\in\\{1,2,\\dots,d\\}$ as\n$$\nv_{p,j}^{(t)} \\;=\\; \\omega\\, v_{p,j}^{(t-1)} \\;+\\; c_1\\, r_{1,p,j}^{(t)}\\big(pbest_{p,j}^{(t-1)} - x_{p,j}^{(t-1)}\\big) \\;+\\; c_2\\, r_{2,p,j}^{(t)}\\big(gbest_{j}^{(t-1)} - x_{p,j}^{(t-1)}\\big),\n$$\n$$\nx_{p,j}^{(t)} \\;=\\; x_{p,j}^{(t-1)} \\;+\\; v_{p,j}^{(t)},\n$$\nwhere $r_{1,p,j}^{(t)}$ and $r_{2,p,j}^{(t)}$ are independent draws from the uniform distribution on $[0,1]$, $pbest_{p}^{(t-1)}$ is the best position of particle $p$ observed up to iteration $t-1$, and $gbest^{(t-1)}$ is the best position among all particles up to iteration $t-1$. Positions must be kept within the domain by projection, i.e., after each update map each coordinate to $\\min\\{5,\\max\\{-5,x_{p,j}^{(t)}\\}\\}$. Initialize all velocities to zero vectors and initialize all positions independently and uniformly in $[-5,5]^d$. At the end of iteration $T$, define the performance of $(\\omega,c_1,c_2)$ as the best objective value found by any particle up to and including iteration $T$, i.e., $\\min_{t\\in\\{0,\\dots,T\\}}\\min_{p\\in\\{1,\\dots,n\\}} f(x_p^{(t)})$.\n\nYou must select $(\\omega,c_1,c_2)$ from the following finite candidate set:\n- $\\omega \\in \\{0.2,\\,0.6,\\,0.9\\}$,\n- $c_1 \\in \\{0.5,\\,1.5,\\,2.5\\}$,\n- $c_2 \\in \\{0.5,\\,1.5,\\,2.5\\}$.\nAll candidate values are in real numbers as listed.\n\nFor each test case below, evaluate every candidate triple using the same pseudorandom initial state for that test case, i.e., for a fixed test case, the random number generator must be initialized to the same seed before each candidate evaluation so that all candidates are compared under identical stochastic realizations. For each test case, report the candidate triple $(\\omega,c_1,c_2)$ that yields the smallest final best objective value. If multiple candidates achieve the same minimal value within a tolerance of $\\epsilon = 10^{-12}$, break ties lexicographically by choosing the smallest $\\omega$, and if still tied, the smallest $c_1$, and then the smallest $c_2$.\n\nTest suite (each test case specifies dimension $d$, swarm size $n$, iteration budget $T$, and pseudorandom seed $s$):\n- Test case $1$: $d=2$, $n=20$, $T=200$, $s=1337$.\n- Test case $2$: $d=10$, $n=30$, $T=180$, $s=9001$.\n- Test case $3$: $d=2$, $n=50$, $T=30$, $s=42$.\n\nYour program must compute, for each test case, the selected $(\\omega,c_1,c_2)$ from the given candidate set that minimizes the performance measure as defined above. Angles in the cosine are in radians. There are no physical units to report.\n\nFinal output format: Your program should produce a single line of output containing a list of three inner lists, one per test case, each inner list being the selected $(\\omega,c_1,c_2)$ formatted as real numbers with exactly one digit after the decimal point, no spaces, and in the order of the test cases. For example, if the selected triples were $(0.6,1.5,2.5)$, $(0.2,0.5,0.5)$, $(0.9,2.5,1.5)$, the output must be\n[[0.6,1.5,2.5],[0.2,0.5,0.5],[0.9,2.5,1.5]].", "solution": "The problem statement has been rigorously validated and is found to be scientifically sound, well-posed, unambiguous, and complete. It describes a standard computational experiment in the field of optimization. A solution will be provided, following the specified methodology.\n\nThe task is to perform hyperparameter selection for the Particle Swarm Optimization (PSO) algorithm. The goal is to find the optimal combination of parameters $(\\omega, c_1, c_2)$ from a given finite set that minimizes the Ackley function, a standard non-convex benchmark problem.\n\nThe objective function to be minimized is the Ackley function in $d$ dimensions, given by:\n$$\nf(\\mathbf{x}) = -20\\exp\\left(-0.2\\sqrt{\\frac{1}{d}\\sum_{i=1}^d x_i^2}\\right) - \\exp\\left(\\frac{1}{d}\\sum_{i=1}^d \\cos(2\\pi x_i)\\right) + 20 + e,\n$$\nwhere $\\mathbf{x} = (x_1, \\dots, x_d) \\in [-5, 5]^d$ and $e$ is Euler's number, the base of the natural logarithm. The cosine function arguments are in radians.\n\nThe PSO algorithm is a population-based stochastic optimization technique. The swarm consists of $n$ particles, each representing a candidate solution in the $d$-dimensional search space. Each particle $p$ has a position vector $\\mathbf{x}_p^{(t)} \\in \\mathbb{R}^d$ and a velocity vector $\\mathbf{v}_p^{(t)} \\in \\mathbb{R}^d$ at iteration $t$. The algorithm proceeds as follows:\n\n1.  **Initialization ($t=0$)**:\n    - Particle positions $\\mathbf{x}_p^{(0)}$ are initialized by drawing coordinates independently from a uniform distribution over the domain $[-5, 5]$.\n    - Particle velocities $\\mathbf{v}_p^{(0)}$ are initialized to zero vectors.\n    - Each particle's personal best position, $\\mathbf{pbest}_p$, is set to its initial position, $\\mathbf{pbest}_p^{(0)} = \\mathbf{x}_p^{(0)}$.\n    - The global best position, $\\mathbf{gbest}$, is set to the personal best position of the particle with the lowest initial objective function value, i.e., $\\mathbf{gbest}^{(0)}$ is the $\\mathbf{pbest}_p^{(0)}$ for which $f(\\mathbf{pbest}_p^{(0)})$ is minimal over all $p \\in \\{1, \\dots, n\\}$.\n\n2.  **Iterative Update (for $t=1, \\dots, T$)**: For each particle $p$ and each dimension $j$:\n    - The velocity is updated according to the equation:\n      $$\n      v_{p,j}^{(t)} = \\omega\\, v_{p,j}^{(t-1)} + c_1\\, r_{1,p,j}^{(t)}\\left(pbest_{p,j}^{(t-1)} - x_{p,j}^{(t-1)}\\right) + c_2\\, r_{2,p,j}^{(t)}\\left(gbest_{j}^{(t-1)} - x_{p,j}^{(t-1)}\\right),\n      $$\n      where $\\omega$ is the inertia weight, $c_1$ is the cognitive coefficient, and $c_2$ is the social coefficient. The terms $r_{1,p,j}^{(t)}$ and $r_{2,p,j}^{(t)}$ are random numbers drawn independently from the uniform distribution $U[0, 1]$.\n    - The position is updated by:\n      $$\n      x_{p,j}^{(t)} = x_{p,j}^{(t-1)} + v_{p,j}^{(t)}.\n      $$\n    - After the position update, the coordinates are clamped to the domain $[-5, 5]$: $x_{p,j}^{(t)} = \\min(5, \\max(-5, x_{p,j}^{(t)}))$.\n    - The particle's personal best is updated: if $f(\\mathbf{x}_p^{(t)}) < f(\\mathbf{pbest}_p^{(t-1)})$, then $\\mathbf{pbest}_p^{(t)} = \\mathbf{x}_p^{(t)}$; otherwise, $\\mathbf{pbest}_p^{(t)} = \\mathbf{pbest}_p^{(t-1)}$.\n    - The global best is updated: $\\mathbf{gbest}^{(t)}$ is set to the $\\mathbf{pbest}_p^{(t)}$ that yields the minimum objective value across all particles.\n\nThe hyperparameter selection is conducted via a grid search over the candidate sets: $\\omega \\in \\{0.2, 0.6, 0.9\\}$, $c_1 \\in \\{0.5, 1.5, 2.5\\}$, and $c_2 \\in \\{0.5, 1.5, 2.5\\}$, resulting in $3 \\times 3 \\times 3 = 27$ total candidate triples $(\\omega, c_1, c_2)$.\n\nFor each test case, defined by a tuple $(d, n, T, s)$, the following evaluation protocol is strictly followed:\n- Each of the $27$ candidate triples is used to run the PSO algorithm for $T$ iterations.\n- Crucially, to ensure a fair comparison, the pseudo-random number generator is reset to the same seed $s$ before the evaluation of each candidate triple. This ensures that all triples operate under identical stochastic conditions (i.e., same initial swarm configuration and same sequence of random numbers for velocity updates).\n- The performance of a triple is defined as the best objective value found by any particle at any point up to iteration $T$, which is equivalent to $f(\\mathbf{gbest}^{(T)})$.\n\nThe winning triple for a test case is determined by the lowest performance value. In case of ties, where performance values are within a tolerance of $\\epsilon = 10^{-12}$, the tie is broken by selecting the triple $(\\omega, c_1, c_2)$ that is lexicographically smallest. This means the triple with the smallest $\\omega$ is chosen first; if a tie persists, the one with the smallest $c_1$ is chosen; and if still tied, the one with the smallest $c_2$ is chosen.\n\nThe implementation is carried out in Python, leveraging the NumPy library for efficient, vectorized computations. The swarm's positions and velocities are managed as $(n \\times d)$-dimensional arrays. The Ackley function is implemented in a vectorized form to compute objective values for all particles simultaneously, accelerating the evaluation step. A main procedure executes the workflow for each test case: it iterates through all hyperparameter candidates, runs the PSO simulation, records the performance, and then applies the specified selection and tie-breaking rules to identify the optimal triple. The final results are formatted according to the problem specification.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to solve the hyperparameter selection problem for PSO.\n    It iterates through given test cases, evaluates all candidate hyperparameter\n    triples for each case, selects the best one based on performance and tie-breaking\n    rules, and prints the final result in the specified format.\n    \"\"\"\n\n    def ackley_vec(x: np.ndarray, d: int) -> np.ndarray:\n        \"\"\"\n        Vectorized implementation of the Ackley function.\n        \n        Args:\n            x (np.ndarray): A 2D array of shape (n, d) representing n particle positions.\n            d (int): The dimension of the problem space.\n\n        Returns:\n            np.ndarray: A 1D array of shape (n,) with the objective value for each particle.\n        \"\"\"\n        assert x.shape[1] == d, \"Dimension mismatch\"\n\n        sum_sq = np.sum(x**2, axis=1)\n        term1 = -20.0 * np.exp(-0.2 * np.sqrt(sum_sq / d))\n\n        sum_cos = np.sum(np.cos(2 * np.pi * x), axis=1)\n        term2 = -np.exp(sum_cos / d)\n\n        return term1 + term2 + 20.0 + np.e\n\n    def run_pso(omega: float, c1: float, c2: float, d: int, n: int, T: int, seed: int) -> float:\n        \"\"\"\n        Runs a single instance of the Particle Swarm Optimization algorithm.\n\n        Args:\n            omega (float): Inertia weight.\n            c1 (float): Cognitive coefficient.\n            c2 (float): Social coefficient.\n            d (int): Dimension of the problem.\n            n (int): Number of particles.\n            T (int): Number of iterations.\n            seed (int): Seed for the random number generator.\n\n        Returns:\n            float: The best objective function value found during the optimization run.\n        \"\"\"\n        rng = np.random.default_rng(seed)\n        \n        # Initialization\n        domain_min, domain_max = -5.0, 5.0\n        pos = rng.uniform(domain_min, domain_max, size=(n, d))\n        vel = np.zeros((n, d))\n\n        pbest_pos = pos.copy()\n        pbest_val = ackley_vec(pbest_pos, d)\n\n        min_val_idx = np.argmin(pbest_val)\n        gbest_val = pbest_val[min_val_idx]\n        gbest_pos = pbest_pos[min_val_idx].copy()\n\n        # Iteration loop\n        for _ in range(T):\n            r1 = rng.random(size=(n, d))\n            r2 = rng.random(size=(n, d))\n\n            vel = omega * vel + c1 * r1 * (pbest_pos - pos) + c2 * r2 * (gbest_pos - pos)\n            pos = pos + vel\n            pos = np.clip(pos, domain_min, domain_max)\n\n            current_vals = ackley_vec(pos, d)\n            \n            improvement_mask = current_vals < pbest_val\n            pbest_pos[improvement_mask] = pos[improvement_mask]\n            pbest_val[improvement_mask] = current_vals[improvement_mask]\n            \n            current_best_idx = np.argmin(pbest_val)\n            if pbest_val[current_best_idx] < gbest_val:\n                gbest_val = pbest_val[current_best_idx]\n                gbest_pos = pbest_pos[current_best_idx].copy()\n\n        return gbest_val\n\n    # Define test cases and hyperparameter candidates from the problem statement.\n    test_cases = [\n        (2, 20, 200, 1337),\n        (10, 30, 180, 9001),\n        (2, 50, 30, 42),\n    ]\n\n    omegas = [0.2, 0.6, 0.9]\n    c1s = [0.5, 1.5, 2.5]\n    c2s = [0.5, 1.5, 2.5]\n    epsilon = 1e-12\n\n    all_best_params = []\n\n    for d, n, T, s in test_cases:\n        case_results = []\n        for omega in omegas:\n            for c1 in c1s:\n                for c2 in c2s:\n                    performance = run_pso(omega, c1, c2, d, n, T, s)\n                    case_results.append({'params': (omega, c1, c2), 'perf': performance})\n        \n        # Selection and tie-breaking logic\n        min_perf = min(r['perf'] for r in case_results)\n        \n        contenders = [r for r in case_results if r['perf'] <= min_perf + epsilon]\n        \n        contenders.sort(key=lambda r: r['params']) # Sorts by (omega, c1, c2)\n        \n        best_params = contenders[0]['params']\n        all_best_params.append(list(best_params))\n\n    # Final print statement in the exact required format.\n    result_str_list = []\n    for params in all_best_params:\n        result_str_list.append(f\"[{params[0]:.1f},{params[1]:.1f},{params[2]:.1f}]\")\n    \n    final_output = f\"[{','.join(result_str_list)}]\"\n    print(final_output)\n\nsolve()\n```", "id": "2423083"}, {"introduction": "Real-world optimization problems are rarely as clean as textbook examples; objective function values are often corrupted by measurement or simulation noise. This practice will challenge you to analyze PSO's performance in such a stochastic environment, where the algorithm must navigate using imperfect information. By comparing the algorithm's behavior on benchmark functions with and without noise, you will develop a deeper appreciation for its inherent robustness and the importance of statistical analysis in evaluating stochastic optimizers.[@problem_id:2423094]", "problem": "Consider a continuous optimization setting where the objective is defined by a true function $f_{\\text{true}}: \\mathbb{R}^d \\to \\mathbb{R}$, but only noisy evaluations are available through $f_{\\text{eval}}(\\boldsymbol{x}) = f_{\\text{true}}(\\boldsymbol{x}) + \\epsilon$, where $\\epsilon \\sim \\mathcal{N}(0,\\sigma^2)$ is an independent, zero-mean Gaussian random variable with variance $\\sigma^2$. A discrete-time, population-based stochastic process operates on $N$ agents (indexed by $i \\in \\{1,\\dots,N\\}$) with positions $\\boldsymbol{x}_i(t) \\in \\mathbb{R}^d$ and velocities $\\boldsymbol{v}_i(t) \\in \\mathbb{R}^d$ at iteration $t \\in \\{0,1,\\dots,T\\}$. For each agent, a personal incumbent $\\boldsymbol{p}_i(t) \\in \\mathbb{R}^d$ is maintained together with its best observed noisy value $b_i(t) \\in \\mathbb{R}$, and there is a distinguished incumbent $\\boldsymbol{g}(t) \\in \\mathbb{R}^d$ representing the best among personal incumbents under the same noisy values. The dynamics are given by the following rules:\n\n- Initialization at $t = 0$:\n  - For each $i \\in \\{1,\\dots,N\\}$ and each coordinate $j \\in \\{1,\\dots,d\\}$, draw $x_{i,j}(0)$ independently and uniformly from $[L_j,U_j]$, where $\\boldsymbol{L},\\boldsymbol{U} \\in \\mathbb{R}^d$ are given elementwise bounds with $L_j < U_j$ for all $j$.\n  - Set $\\boldsymbol{v}_i(0) = \\boldsymbol{0}$ for all $i$.\n  - Set $\\boldsymbol{p}_i(0) = \\boldsymbol{x}_i(0)$ and $b_i(0) = f_{\\text{eval}}(\\boldsymbol{x}_i(0))$ for all $i$.\n  - Let $\\ell \\in \\{1,\\dots,N\\}$ be an index that attains $\\min_{i} b_i(0)$ (break ties by the smallest index). Set $\\boldsymbol{g}(0) = \\boldsymbol{p}_\\ell(0)$.\n\n- Iteration for $t = 0,1,\\dots,T-1$:\n  - For each $i \\in \\{1,\\dots,N\\}$, draw independent random vectors $\\boldsymbol{r}_{1,i}(t), \\boldsymbol{r}_{2,i}(t) \\in [0,1]^d$ with components independently sampled from the uniform distribution on $[0,1]$.\n  - Update velocity using\n    $$\\boldsymbol{v}_i(t+1) = \\omega \\,\\boldsymbol{v}_i(t) + c_1 \\,\\boldsymbol{r}_{1,i}(t) \\odot \\left(\\boldsymbol{p}_i(t) - \\boldsymbol{x}_i(t)\\right) + c_2 \\,\\boldsymbol{r}_{2,i}(t) \\odot \\left(\\boldsymbol{g}(t) - \\boldsymbol{x}_i(t)\\right),$$\n    where $\\odot$ denotes elementwise multiplication, and $\\omega, c_1, c_2 \\in \\mathbb{R}$ are given coefficients.\n  - Update position using\n    $$\\boldsymbol{x}_i(t+1) = \\mathrm{clip}\\left(\\boldsymbol{x}_i(t) + \\boldsymbol{v}_i(t+1), \\boldsymbol{L}, \\boldsymbol{U}\\right),$$\n    where the clipping function applies elementwise saturation to the interval $[L_j, U_j]$ for each coordinate $j$.\n  - Obtain a new noisy evaluation $y_i(t+1) = f_{\\text{eval}}(\\boldsymbol{x}_i(t+1))$. If $y_i(t+1) < b_i(t)$ then set $\\boldsymbol{p}_i(t+1) = \\boldsymbol{x}_i(t+1)$ and $b_i(t+1) = y_i(t+1)$; otherwise set $\\boldsymbol{p}_i(t+1) = \\boldsymbol{p}_i(t)$ and $b_i(t+1) = b_i(t)$.\n  - Let $m \\in \\{1,\\dots,N\\}$ be an index that attains $\\min_{i} b_i(t+1)$ (break ties by the smallest index). Set $\\boldsymbol{g}(t+1) = \\boldsymbol{p}_m(t+1)$.\n\nAfter $T$ iterations, define the returned solution as $\\boldsymbol{x}^\\star = \\boldsymbol{g}(T)$. For a fixed parameter set, consider $R$ independent repetitions of the entire process as defined above, each repetition using independent randomness, and report the arithmetic mean of the true objective values at termination,\n$$\\frac{1}{R} \\sum_{r=1}^{R} f_{\\text{true}}(\\boldsymbol{x}^\\star_r),$$\nwhere $\\boldsymbol{x}^\\star_r$ denotes the returned solution of repetition $r$.\n\nAll random variates must be generated from a pseudorandom number generator with seeds specified as follows. Let a base seed $s$ be given. For the test case with zero-based index $k$ and the repetition with zero-based index $r$, use seed $s + 100000\\,k + r$ for all randomness within that repetition.\n\nUse the following objective functions, domains, and parameters. In all cases, use $\\omega = 0.7298$, $c_1 = 1.49618$, and $c_2 = 1.49618$. The functions $f_{\\text{true}}$ are:\n- Sphere: for any $d \\geq 1$, $f_{\\text{true}}(\\boldsymbol{x}) = \\sum_{j=1}^d x_j^2$ with global minimum $0$ at $\\boldsymbol{0}$.\n- Rosenbrock: for any $d \\geq 2$, $f_{\\text{true}}(\\boldsymbol{x}) = \\sum_{j=1}^{d-1} \\left(100\\,(x_{j+1} - x_j^2)^2 + (1 - x_j)^2\\right)$ with global minimum $0$ at $\\boldsymbol{1}$.\n- Rastrigin: for any $d \\geq 1$, $f_{\\text{true}}(\\boldsymbol{x}) = 10\\,d + \\sum_{j=1}^d \\left(x_j^2 - 10 \\cos(2 \\pi x_j)\\right)$ with global minimum $0$ at $\\boldsymbol{0}$.\n\nTest suite. For each case, report the mean defined above. Angles, where present in cosine, are in radians. There are no physical units.\n- Case $0$: function Sphere, $d = 5$, bounds $L_j = -5$, $U_j = 5$ for all $j$, noise standard deviation $\\sigma = 0.1$, population size $N = 30$, iterations $T = 200$, repetitions $R = 30$, base seed $s = 20240901$.\n- Case $1$: function Sphere, $d = 5$, bounds $L_j = -5$, $U_j = 5$, $\\sigma = 0$, $N = 30$, $T = 200$, $R = 30$, $s = 20240901$.\n- Case $2$: function Sphere, $d = 5$, bounds $L_j = -5$, $U_j = 5$, $\\sigma = 2.0$, $N = 30$, $T = 200$, $R = 30$, $s = 20240901$.\n- Case $3$: function Rastrigin, $d = 10$, bounds $L_j = -5.12$, $U_j = 5.12$, $\\sigma = 0.5$, $N = 40$, $T = 300$, $R = 20$, $s = 20240901$.\n- Case $4$: function Rosenbrock, $d = 3$, bounds $L_j = -2$, $U_j = 2$, $\\sigma = 0.2$, $N = 25$, $T = 400$, $R = 20$, $s = 20240901$.\n- Case $5$: function Sphere, $d = 5$, bounds $L_j = -5$, $U_j = 5$, $\\sigma = 0.1$, $N = 5$, $T = 50$, $R = 50$, $s = 20240901$.\n\nFinal output format. Your program should produce a single line of output containing the $6$ results as a comma-separated list enclosed in square brackets, with each number rounded to six decimal places and with no spaces; for example, $[a_0,a_1,a_2,a_3,a_4,a_5]$ where each $a_k$ is the specified mean for case $k$.", "solution": "The problem statement constitutes a request to implement and execute a simulation of the standard Particle Swarm Optimization (PSO) algorithm. This is a well-established stochastic metaheuristic used for continuous optimization problems. The problem is judged to be valid, as it is scientifically grounded, well-posed, objective, and provides a complete and consistent specification for a computational experiment. Every parameter, function, and procedural step is detailed with mathematical precision, allowing for a reproducible numerical study.\n\nThe PSO algorithm operates on a population, or swarm, of $N$ agents, referred to as particles, indexed by $i \\in \\{1, \\dots, N\\}$. Each particle explores a $d$-dimensional continuous search space, defined by elementwise lower and upper bounds $\\boldsymbol{L}$ and $\\boldsymbol{U}$ in $\\mathbb{R}^d$. The state of particle $i$ at a discrete time step $t$ is defined by its position vector $\\boldsymbol{x}_i(t) \\in \\mathbb{R}^d$ and its velocity vector $\\boldsymbol{v}_i(t) \\in \\mathbb{R}^d$. The algorithm's objective is to find the minimum of a true function $f_{\\text{true}}(\\boldsymbol{x})$, but it only has access to noisy evaluations $f_{\\text{eval}}(\\boldsymbol{x}) = f_{\\text{true}}(\\boldsymbol{x}) + \\epsilon$, where $\\epsilon$ is a random variable drawn from a Gaussian distribution $\\mathcal{N}(0, \\sigma^2)$.\n\nThe dynamics of the swarm evolve over $T$ iterations. At initialization ($t=0$), particle positions $\\boldsymbol{x}_i(0)$ are sampled uniformly within the search-space bounds, and velocities $\\boldsymbol{v}_i(0)$ are set to $\\boldsymbol{0}$. Each particle maintains a memory of its own best-found position, the personal best $\\boldsymbol{p}_i(t)$, which corresponds to the location yielding the lowest noisy objective value $b_i(t)$ it has encountered. Additionally, the swarm collectively tracks the global best position $\\boldsymbol{g}(t)$, which is the personal best position of the particle that has achieved the overall lowest noisy objective value across the entire population up to time $t$.\n\nThe core of the PSO algorithm lies in its iterative update rules. For each particle $i$ at each iteration $t$, the velocity for the next time step $t+1$ is updated according to the equation:\n$$\n\\boldsymbol{v}_i(t+1) = \\omega \\,\\boldsymbol{v}_i(t) + c_1 \\,\\boldsymbol{r}_{1,i}(t) \\odot \\left(\\boldsymbol{p}_i(t) - \\boldsymbol{x}_i(t)\\right) + c_2 \\,\\boldsymbol{r}_{2,i}(t) \\odot \\left(\\boldsymbol{g}(t) - \\boldsymbol{x}_i(t)\\right)\n$$\nThis update has three components: the first term, scaled by the inertia weight $\\omega$, provides momentum from the previous velocity. The second, 'cognitive' term, scaled by the coefficient $c_1$, pulls the particle towards its personal best position $\\boldsymbol{p}_i(t)$. The third, 'social' term, scaled by $c_2$, pulls the particle towards the global best position $\\boldsymbol{g}(t)$. The vectors $\\boldsymbol{r}_{1,i}(t)$ and $\\boldsymbol{r}_{2,i}(t)$ introduce stochasticity, with components drawn independently from the uniform distribution $\\mathcal{U}[0,1]$. The symbol $\\odot$ indicates elementwise vector multiplication. The problem specifies the coefficients as $\\omega = 0.7298$, $c_1 = 1.49618$, and $c_2 = 1.49618$.\n\nFollowing the velocity update, the particle's position is updated by adding the new velocity, and the result is constrained to remain within the search space bounds $[\\boldsymbol{L}, \\boldsymbol{U}]$ via a clipping operation:\n$$\n\\boldsymbol{x}_i(t+1) = \\mathrm{clip}\\left(\\boldsymbol{x}_i(t) + \\boldsymbol{v}_i(t+1), \\boldsymbol{L}, \\boldsymbol{U}\\right)\n$$\nAfter updating the position, a new noisy evaluation $y_i(t+1) = f_{\\text{eval}}(\\boldsymbol{x}_i(t+1))$ is performed. This value is used to update the particle's personal best: if $y_i(t+1) < b_i(t)$, then $\\boldsymbol{p}_i(t+1)$ is set to the new position $\\boldsymbol{x}_i(t+1)$ and $b_i(t+1)$ to $y_i(t+1)$. Otherwise, they remain unchanged. Subsequently, the global best position $\\boldsymbol{g}(t+1)$ is updated by identifying the particle with the minimum personal best value $b_i(t+1)$ across the entire swarm.\n\nThe implementation will be structured to precisely follow this specification. For reproducibility, a strict seeding protocol is defined: for a test case with index $k$ and repetition $r$ (both zero-indexed), the seed for the pseudo-random number generator (RNG) is set to $s + 100000\\,k + r$. This RNG must be used for all stochastic elements: initial positions, noise generation, and the random vectors $\\boldsymbol{r}_{1,i}$ and $\\boldsymbol{r}_{2,i}$. The implementation will utilize NumPy for efficient vectorized operations on the particle population.\n\nThe benchmark functions—Sphere, Rosenbrock, and Rastrigin—are standard test problems for global optimization. After $T$ iterations, the algorithm returns the global best position, $\\boldsymbol{x}^\\star = \\boldsymbol{g}(T)$. The performance metric for each test case is the arithmetic mean of the true objective function values, $\\frac{1}{R} \\sum_{r=1}^{R} f_{\\text{true}}(\\boldsymbol{x}^\\star_r)$, over $R$ independent repetitions. This Monte Carlo approach assesses the expected performance of the stochastic algorithm. The final program will calculate this metric for each of the $6$ specified test cases and format the results as required.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to run the PSO simulation for all specified test cases.\n    \"\"\"\n\n    # --- Objective Functions ---\n    def sphere(x: np.ndarray) -> np.ndarray:\n        \"\"\"Computes the Sphere function. x is a 2D array of positions.\"\"\"\n        return np.sum(x**2, axis=1)\n\n    def rosenbrock(x: np.ndarray) -> np.ndarray:\n        \"\"\"Computes the Rosenbrock function. x is a 2D array of positions.\"\"\"\n        term1 = 100 * (x[:, 1:] - x[:, :-1]**2)**2\n        term2 = (1 - x[:, :-1])**2\n        return np.sum(term1 + term2, axis=1)\n\n    def rastrigin(x: np.ndarray) -> np.ndarray:\n        \"\"\"Computes the Rastrigin function. x is a 2D array of positions.\"\"\"\n        d = x.shape[1]\n        sum_term = np.sum(x**2 - 10 * np.cos(2 * np.pi * x), axis=1)\n        return 10 * d + sum_term\n\n    # --- PSO Algorithm Implementation ---\n    def pso_run(f_true, d, L, U, sigma, N, T, omega, c1, c2, rng):\n        \"\"\"\n        Performs one full run of the Particle Swarm Optimization algorithm.\n        \n        Args:\n            f_true: The true objective function.\n            d: Dimension of the search space.\n            L, U: Lower and upper bounds for all dimensions.\n            sigma: Standard deviation of the Gaussian noise.\n            N: Population size.\n            T: Number of iterations.\n            omega, c1, c2: PSO coefficients.\n            rng: NumPy random number generator instance.\n\n        Returns:\n            The final global best position g(T).\n        \"\"\"\n        # Create vector bounds\n        L_vec = np.full(d, L)\n        U_vec = np.full(d, U)\n\n        # --- Initialization (t=0) ---\n        # Initialize positions and velocities\n        pos = rng.uniform(L, U, size=(N, d))\n        vel = np.zeros((N, d))\n        \n        # Evaluate initial positions\n        true_vals = f_true(pos)\n        noise = rng.normal(0, sigma, size=N) if sigma > 0 else 0\n        eval_vals = true_vals + noise\n\n        # Initialize personal bests\n        p_best_pos = np.copy(pos)\n        p_best_val = np.copy(eval_vals)\n\n        # Initialize global best\n        min_idx = np.argmin(p_best_val)\n        g_best_pos = np.copy(p_best_pos[min_idx])\n        \n        # --- Iteration Loop (t = 0 to T-1) ---\n        for _ in range(T):\n            # Generate random vectors for velocity update\n            r1 = rng.uniform(0, 1, size=(N, d))\n            r2 = rng.uniform(0, 1, size=(N, d))\n\n            # Update velocity\n            cognitive_comp = c1 * r1 * (p_best_pos - pos)\n            social_comp = c2 * r2 * (g_best_pos - pos)\n            vel = omega * vel + cognitive_comp + social_comp\n\n            # Update position and clip to bounds\n            pos = np.clip(pos + vel, L_vec, U_vec)\n            \n            # Evaluate new positions\n            true_vals = f_true(pos)\n            noise = rng.normal(0, sigma, size=N) if sigma > 0 else 0\n            eval_vals = true_vals + noise\n\n            # Update personal bests\n            update_mask = eval_vals < p_best_val\n            p_best_pos[update_mask] = pos[update_mask]\n            p_best_val[update_mask] = eval_vals[update_mask]\n\n            # Update global best\n            min_idx = np.argmin(p_best_val)\n            g_best_pos = np.copy(p_best_pos[min_idx])\n        \n        return g_best_pos\n\n    # --- Test Cases Configuration ---\n    test_cases = [\n        {'func_name': 'sphere', 'func': sphere, 'd': 5, 'bounds': (-5., 5.), 'sigma': 0.1, 'N': 30, 'T': 200, 'R': 30},\n        {'func_name': 'sphere', 'func': sphere, 'd': 5, 'bounds': (-5., 5.), 'sigma': 0.0, 'N': 30, 'T': 200, 'R': 30},\n        {'func_name': 'sphere', 'func': sphere, 'd': 5, 'bounds': (-5., 5.), 'sigma': 2.0, 'N': 30, 'T': 200, 'R': 30},\n        {'func_name': 'rastrigin', 'func': rastrigin, 'd': 10, 'bounds': (-5.12, 5.12), 'sigma': 0.5, 'N': 40, 'T': 300, 'R': 20},\n        {'func_name': 'rosenbrock', 'func': rosenbrock, 'd': 3, 'bounds': (-2., 2.), 'sigma': 0.2, 'N': 25, 'T': 400, 'R': 20},\n        {'func_name': 'sphere', 'func': sphere, 'd': 5, 'bounds': (-5., 5.), 'sigma': 0.1, 'N': 5, 'T': 50, 'R': 50},\n    ]\n\n    base_seed = 20240901\n    omega = 0.7298\n    c1 = 1.49618\n    c2 = 1.49618\n    \n    results = []\n    \n    # --- Main Execution Loop ---\n    for k, case in enumerate(test_cases):\n        rep_true_values = []\n        for r in range(case['R']):\n            seed = base_seed + 100000 * k + r\n            rng = np.random.default_rng(seed)\n            \n            g_final = pso_run(\n                f_true=case['func'],\n                d=case['d'],\n                L=case['bounds'][0],\n                U=case['bounds'][1],\n                sigma=case['sigma'],\n                N=case['N'],\n                T=case['T'],\n                omega=omega,\n                c1=c1,\n                c2=c2,\n                rng=rng\n            )\n            \n            # Evaluate the true objective function at the final solution\n            # Reshape g_final to (1,d) to be compatible with vectorized functions\n            true_value = case['func'](g_final.reshape(1, -1))[0]\n            rep_true_values.append(true_value)\n            \n        # Calculate the mean over all repetitions\n        mean_result = np.mean(rep_true_values)\n        results.append(mean_result)\n\n    # Final print statement in the exact required format.\n    formatted_results = [f\"{res:.6f}\" for res in results]\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```", "id": "2423094"}, {"introduction": "Beyond static and noisy landscapes, many real-world challenges involve optimization targets that change over time, a field known as dynamic optimization. This practice simulates such a scenario, tasking the particle swarm with tracking a moving optimum within the search space. By implementing this simulation and measuring the swarm's tracking error, you will investigate how PSO's parameters affect its ability to adapt and avoid converging on outdated solutions, a key requirement for applications in robotics and online control systems.[@problem_id:2423115]", "problem": "You are given a discrete-time model of a swarm of particles evolving in a continuous domain under a time-varying objective function. The objective function at discrete time index $t \\in \\{0,1,2,\\dots\\}$ is\n$$\nf_t(\\mathbf{x}) = \\tfrac{1}{2} \\left(\\mathbf{x} - \\mathbf{x}_{\\min}(t)\\right)^\\top \\mathbf{Q} \\left(\\mathbf{x} - \\mathbf{x}_{\\min}(t)\\right),\n$$\nwhere $\\mathbf{x} \\in \\mathbb{R}^2$, $\\mathbf{Q} = \\operatorname{diag}(q_1,q_2)$ is positive definite, and the time-varying minimizer is\n$$\n\\mathbf{x}_{\\min}(t) = \\begin{bmatrix} a \\sin(\\omega t) \\\\ b \\cos(\\omega t) \\end{bmatrix}.\n$$\nAngles are in radians. A swarm consists of $N$ particles indexed by $i \\in \\{1,\\dots,N\\}$. Each particle has position $\\mathbf{x}_i(t) \\in \\mathbb{R}^2$ and velocity $\\mathbf{v}_i(t) \\in \\mathbb{R}^2$. The state updates synchronously in discrete time as follows. Define each particle’s personal best position $\\mathbf{p}_i(t)$ and its associated best value $J_i(t)$ by\n$$\nJ_i(t) = \\min_{0 \\le \\tau \\le t} f_\\tau(\\mathbf{x}_i(\\tau)), \\quad \\mathbf{p}_i(t) \\in \\arg\\min_{\\substack{0 \\le \\tau \\le t}} f_\\tau(\\mathbf{x}_i(\\tau)),\n$$\nwith the convention that ties are broken by the most recent time index. Define the global best position $\\mathbf{g}(t)$ and value $G(t)$ across all particles and all times up to $t$ by\n$$\nG(t) = \\min_{1 \\le i \\le N} J_i(t), \\quad \\mathbf{g}(t) \\in \\arg\\min_{1 \\le i \\le N} J_i(t),\n$$\nwith the convention that ties are broken by choosing the lowest particle index. The velocity and position updates for each particle are\n$$\n\\mathbf{v}_i(t{+}1) = w \\,\\mathbf{v}_i(t) + c_1 \\, r_1 \\,\\big(\\mathbf{p}_i(t) - \\mathbf{x}_i(t)\\big) + c_2 \\, r_2 \\,\\big(\\mathbf{g}(t) - \\mathbf{x}_i(t)\\big),\n$$\n$$\n\\mathbf{x}_i(t{+}1) = \\mathbf{x}_i(t) + \\mathbf{v}_i(t{+}1),\n$$\nwhere $w$, $c_1$, and $c_2$ are nonnegative scalars, and $r_1$ and $r_2$ are fixed deterministic scalars equal to $r_1 = r_2 = 0.5$ and applied identically to each component. There is an elementwise velocity bound and position bound. After computing $\\mathbf{v}_i(t{+}1)$, it is clipped elementwise to the interval $[-v_{\\max}, v_{\\max}]$. After computing $\\mathbf{x}_i(t{+}1)$, it is clipped elementwise to $[-R,R]$. The bounds are large enough that clipping may not activate, but clipping must be implemented exactly as specified. Initialization at $t=0$ uses given positions and velocities; the initial personal bests are $\\mathbf{p}_i(0) = \\mathbf{x}_i(0)$ with $J_i(0) = f_0(\\mathbf{x}_i(0))$, and the initial global best $\\mathbf{g}(0)$ is chosen as described above.\n\nDefine the instantaneous tracking error\n$$\ne(t) = \\big\\|\\mathbf{g}(t) - \\mathbf{x}_{\\min}(t)\\big\\|_2,\n$$\nand the root-mean-square tracking error over a horizon of $T$ steps as\n$$\nE_{\\mathrm{RMS}} = \\sqrt{\\frac{1}{T{+}1} \\sum_{t=0}^{T} e(t)^2 }.\n$$\n\nYour task is to implement the above model exactly and, for each test case below, compute $E_{\\mathrm{RMS}}$ as a floating-point number rounded to exactly $6$ decimal places.\n\nThe dimension is $\\mathbb{R}^2$ for all cases, with $\\mathbf{Q} = \\operatorname{diag}(q_1,q_2)$, $q_1 = 2.0$, $q_2 = 1.0$, $a = 1.0$, and $b = 0.5$. The angle unit for $\\omega t$ is radians. The initial positions and velocities are identical across cases and given by\n$$\n\\mathbf{x}_1(0) = \\begin{bmatrix} -0.6 \\\\ -0.6 \\end{bmatrix},\\;\n\\mathbf{x}_2(0) = \\begin{bmatrix} 0.6 \\\\ -0.6 \\end{bmatrix},\\;\n\\mathbf{x}_3(0) = \\begin{bmatrix} -0.6 \\\\ 0.6 \\end{bmatrix},\\;\n\\mathbf{x}_4(0) = \\begin{bmatrix} 0.6 \\\\ 0.6 \\end{bmatrix},\n$$\n$$\n\\mathbf{v}_i(0) = \\begin{bmatrix} 0.0 \\\\ 0.0 \\end{bmatrix} \\text{ for } i \\in \\{1,2,3,4\\}.\n$$\n\nTest suite:\n- Case $1$ (happy path, slow drift): $N = 4$, $T = 60$, $w = 0.70$, $c_1 = 1.50$, $c_2 = 1.50$, $\\omega = 0.10$, $v_{\\max} = 2.00$, $R = 10.00$.\n- Case $2$ (faster drift): $N = 4$, $T = 60$, $w = 0.70$, $c_1 = 1.50$, $c_2 = 1.50$, $\\omega = 0.30$, $v_{\\max} = 2.00$, $R = 10.00$.\n- Case $3$ (no social component): $N = 4$, $T = 60$, $w = 0.70$, $c_1 = 1.50$, $c_2 = 0.00$, $\\omega = 0.10$, $v_{\\max} = 2.00$, $R = 10.00$.\n\nYour program should produce a single line of output containing the $E_{\\mathrm{RMS}}$ results for Cases $1$, $2$, and $3$, in that order, as a comma-separated list enclosed in square brackets and with each number rounded to exactly $6$ decimal places, for example, \"[0.123456,0.234567,0.345678]\". No spaces should appear in the output.", "solution": "The problem statement is assessed to be valid. It is a well-posed, scientifically grounded problem in the field of computational engineering, specifically concerning the simulation of a particle swarm optimization (PSO) algorithm in a dynamic environment. All parameters, initial conditions, and procedural rules, including tie-breaking, are defined with sufficient precision to permit a unique, deterministic solution. We will proceed with the formulation of the solution.\n\nThe task is to simulate a discrete-time PSO algorithm and compute its root-mean-square tracking error. The environment is characterized by a time-varying quadratic objective function $f_t(\\mathbf{x})$, whose minimum traces an elliptical path in $\\mathbb{R}^2$.\n\nThe objective function at time $t$ is given by:\n$$f_t(\\mathbf{x}) = \\frac{1}{2} (\\mathbf{x} - \\mathbf{x}_{\\min}(t))^\\top \\mathbf{Q} (\\mathbf{x} - \\mathbf{x}_{\\min}(t))$$\nwhere the minimizer $\\mathbf{x}_{\\min}(t)$ evolves as:\n$$\\mathbf{x}_{\\min}(t) = \\begin{bmatrix} a \\sin(\\omega t) \\\\ b \\cos(\\omega t) \\end{bmatrix}$$\nWith the constant parameters specified as $a=1.0$, $b=0.5$, and $\\mathbf{Q} = \\operatorname{diag}(2.0, 1.0)$, the objective function can be written in component form for $\\mathbf{x} = [x_1, x_2]^\\top$ as:\n$$f_t(x_1, x_2) = \\frac{1}{2} \\left( 2.0 \\cdot (x_1 - a \\sin(\\omega t))^2 + 1.0 \\cdot (x_2 - b \\cos(\\omega t))^2 \\right)$$\n\nThe simulation proceeds iteratively from an initial time $t=0$ to a final time $t=T$. The state of the swarm at any time $t$ is described by the positions $\\mathbf{x}_i(t)$ and velocities $\\mathbf{v}_i(t)$ for each particle $i \\in \\{1, \\dots, N\\}$, along with their personal best positions $\\mathbf{p}_i(t)$ and the global best position $\\mathbf{g}(t)$.\n\n**1. Initialization ($t=0$):**\n- The initial positions $\\mathbf{x}_i(0)$ and velocities $\\mathbf{v}_i(0)$ are given for all $N=4$ particles.\n- The minimizer at $t=0$ is $\\mathbf{x}_{\\min}(0) = [a \\sin(0), b \\cos(0)]^\\top = [0, 0.5]^\\top$.\n- For each particle $i$, the initial personal best position is its initial position, $\\mathbf{p}_i(0) = \\mathbf{x}_i(0)$.\n- The associated personal best value is $J_i(0) = f_0(\\mathbf{x}_i(0))$.\n- The initial global best value $G(0)$ is the minimum of all initial personal best values: $G(0) = \\min_{1 \\le i \\le N} J_i(0)$.\n- The initial global best position $\\mathbf{g}(0)$ is the personal best position $\\mathbf{p}_{i^*}(0)$ of the particle $i^*$ with the lowest index that achieves the value $G(0)$.\n- The instantaneous tracking error at $t=0$ is calculated as $e(0) = \\|\\mathbf{g}(0) - \\mathbf{x}_{\\min}(0)\\|_2$. Its square, $e(0)^2$, is stored.\n\n**2. Iterative Updates (for $t = 0, 1, \\dots, T-1$):**\nAt each time step $t$, the state of the swarm is used to compute the state at time $t+1$. This process involves two main phases: particle movement and best-position evaluation.\n\n**Phase A: Particle Movement**\nFor each particle $i$, the velocity and position for time $t+1$ are computed:\n- The velocity vector is updated according to the PSO dynamics:\n$$ \\mathbf{v}_i(t{+}1)_{\\text{raw}} = w \\mathbf{v}_i(t) + c_1 r_1 (\\mathbf{p}_i(t) - \\mathbf{x}_i(t)) + c_2 r_2 (\\mathbf{g}(t) - \\mathbf{x}_i(t)) $$\nwhere $r_1=r_2=0.5$ are fixed scalars.\n- Each component of the resulting velocity vector is clipped to the interval $[-v_{\\max}, v_{\\max}]$:\n$$ \\mathbf{v}_i(t{+}1) = \\text{clip}(\\mathbf{v}_i(t{+}1)_{\\text{raw}}, -v_{\\max}, v_{\\max}) $$\n- The position vector is updated using the clipped velocity:\n$$ \\mathbf{x}_i(t{+}1)_{\\text{raw}} = \\mathbf{x}_i(t) + \\mathbf{v}_i(t{+}1) $$\n- Each component of the new position vector is clipped to the interval $[-R, R]$:\n$$ \\mathbf{x}_i(t{+}1) = \\text{clip}(\\mathbf{x}_i(t{+}1)_{\\text{raw}}, -R, R) $$\n\n**Phase B: Evaluation and Best Position Updates**\nAfter all particles have moved to their new positions $\\mathbf{x}_i(t+1)$, the objective function and best positions are updated for time $t+1$:\n- The target minimizer is updated to its new location: $\\mathbf{x}_{\\min}(t+1) = [a \\sin(\\omega(t+1)), b \\cos(\\omega(t+1))]^\\top$.\n- For each particle $i$, the new objective value is computed: $f_{t+1}(\\mathbf{x}_i(t+1))$.\n- This new value is compared with the particle's historical best value, $J_i(t)$. If $f_{t+1}(\\mathbf{x}_i(t+1)) \\le J_i(t)$, the personal best is updated. The use of $\\le$ implements the tie-breaking rule of preferring the most recent time index.\n  - $J_i(t+1) = f_{t+1}(\\mathbf{x}_i(t+1))$\n  - $\\mathbf{p}_i(t+1) = \\mathbf{x}_i(t+1)$\n- Otherwise, the personal best remains unchanged: $J_i(t+1) = J_i(t)$ and $\\mathbf{p}_i(t+1) = \\mathbf{p}_i(t)$.\n- After all personal bests are updated, the new global best value $G(t+1)$ is found by taking the minimum of all $J_i(t+1)$.\n- The new global best position $\\mathbf{g}(t+1)$ is the personal best position $\\mathbf{p}_{i^*}(t+1)$ from the particle $i^*$ with the lowest index that achieves $G(t+1)$.\n- The instantaneous tracking error at $t+1$ is calculated as $e(t+1) = \\|\\mathbf{g}(t+1) - \\mathbf{x}_{\\min}(t+1)\\|_2$, and its square is stored.\n\n**3. Final Calculation:**\nAfter the loop completes (having computed states and errors up to $t=T$), the Root-Mean-Square Tracking Error is calculated over the entire horizon $t \\in \\{0, \\dots, T\\}$:\n$$ E_{\\mathrm{RMS}} = \\sqrt{\\frac{1}{T+1} \\sum_{t=0}^{T} e(t)^2} $$\nThe simulation is performed for each of the three test cases, which differ in the parameters $\\omega$ and $c_2$. The resulting $E_{\\mathrm{RMS}}$ value for each case is rounded to $6$ decimal places.\nThe implementation will use `numpy` for efficient vector and matrix operations, ensuring all calculations are performed with floating-point precision.", "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the particle swarm optimization problem for the given test cases.\n    \"\"\"\n\n    def run_pso_simulation(params):\n        \"\"\"\n        Runs a single PSO simulation for a given set of parameters.\n        \"\"\"\n        # Unpack parameters\n        N = params['N']\n        T = params['T']\n        w = params['w']\n        c1 = params['c1']\n        c2 = params['c2']\n        omega = params['omega']\n        v_max = params['v_max']\n        R_max = params['R']\n        \n        # Common parameters\n        q = np.array([2.0, 1.0])\n        Q = np.diag(q)\n        a = 1.0\n        b = 0.5\n        r1, r2 = 0.5, 0.5\n        \n        # Initial conditions\n        x = np.array([\n            [-0.6, -0.6], [0.6, -0.6], [-0.6, 0.6], [0.6, 0.6]\n        ])\n        v = np.zeros((N, 2))\n\n        # Personal best positions and values\n        p_best_pos = np.copy(x)\n        p_best_val = np.full(N, np.inf)\n\n        # Global best position and value\n        g_best_pos = np.zeros(2)\n        g_best_val = np.inf\n\n        squared_errors = []\n\n        # Simulation loop from t=0 to T\n        for t in range(T + 1):\n            \n            # 1. Update target minimizer\n            x_min_t = np.array([a * np.sin(omega * t), b * np.cos(omega * t)])\n            \n            # --- EVALUATION AND BEST UPDATE ---\n            # At t=0, we evaluate initial positions. For t>0, we evaluate new positions.\n            \n            # Evaluate current positions with current objective function\n            for i in range(N):\n                delta_x = x[i] - x_min_t\n                cost = 0.5 * delta_x.T @ Q @ delta_x\n                \n                # Update personal best\n                if cost = p_best_val[i]:\n                    p_best_val[i] = cost\n                    p_best_pos[i] = x[i]\n\n            # Update global best\n            min_p_best_idx = np.argmin(p_best_val)\n            current_g_best_val = p_best_val[min_p_best_idx]\n            if current_g_best_val  g_best_val:\n                g_best_val = current_g_best_val\n                g_best_pos = p_best_pos[min_p_best_idx]\n            # Tie-breaking: if values are equal, the one from the lowest index is chosen.\n            # np.argmin() inherently handles this. If new min_p_best_idx is different but value is same,\n            # this would be a situation for swarm-level tie breaking, but problem is about J_i(t)\n            # G(t) = min(J_i(t)), g(t) from argmin J_i(t).\n            # The logic here correctly reflects the problem:\n            # J_i(t) is defined over history. We update J_i(t+1) based on J_i(t) and f_{t+1}(x_i(t+1)).\n            # My 'p_best_val' represents J_i(t). Correct.\n            \n            # Let's find the true g_best for time t based on updated p_bests\n            g_best_idx = np.argmin(p_best_val)\n            g_best_pos = p_best_pos[g_best_idx]\n\n            # 2. Calculate and store tracking error\n            error = np.linalg.norm(g_best_pos - x_min_t)\n            squared_errors.append(error**2)\n\n            if t == T:\n                break\n                \n            # --- PARTICLE MOVEMENT (to get state for t+1) ---\n            \n            # Store g_best_pos to be used in velocity update (it's g(t))\n            g_t = g_best_pos\n            \n            for i in range(N):\n                # Update velocity\n                cognitive_term = c1 * r1 * (p_best_pos[i] - x[i])\n                social_term = c2 * r2 * (g_t - x[i])\n                v_new_raw = w * v[i] + cognitive_term + social_term\n                \n                # Clip velocity\n                v[i] = np.clip(v_new_raw, -v_max, v_max)\n                \n                # Update position\n                x_new_raw = x[i] + v[i]\n                \n                # Clip position\n                x[i] = np.clip(x_new_raw, -R_max, R_max)\n\n        # 4. Final RMS error calculation\n        e_rms = np.sqrt(np.mean(squared_errors))\n        return e_rms\n\n    test_cases = [\n        # Case 1 (happy path, slow drift)\n        {'N': 4, 'T': 60, 'w': 0.70, 'c1': 1.50, 'c2': 1.50, 'omega': 0.10, 'v_max': 2.00, 'R': 10.00},\n        # Case 2 (faster drift)\n        {'N': 4, 'T': 60, 'w': 0.70, 'c1': 1.50, 'c2': 1.50, 'omega': 0.30, 'v_max': 2.00, 'R': 10.00},\n        # Case 3 (no social component)\n        {'N': 4, 'T': 60, 'w': 0.70, 'c1': 1.50, 'c2': 0.00, 'omega': 0.10, 'v_max': 2.00, 'R': 10.00},\n    ]\n\n    results = []\n    for case in test_cases:\n        result = run_pso_simulation(case)\n        results.append(f\"{result:.6f}\")\n    \n    # Print the final result in the exact required format\n    print(f\"[{','.join(results)}]\")\n\nsolve()\n```", "id": "2423115"}]}