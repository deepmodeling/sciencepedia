{"hands_on_practices": [{"introduction": "Understanding the structure of an optimization problem is the first step toward solving it. This exercise [@problem_id:2399266] introduces the Uncapacitated Facility Location Problem (UFLP), a classic challenge in operations research and logistics. By implementing the cost function and exploring the solution space for small-scale instances, you will gain a concrete understanding of the trade-offs involved and appreciate why heuristic methods become essential as problem size increases.", "problem": "You are given a family of finite uncapacitated facility location problems. Let there be a set of customers indexed by $i \\in \\{1,\\dots,m\\}$ and a set of candidate facilities indexed by $j \\in \\{1,\\dots,n\\}$. Each customer $i$ has a nonnegative demand $d_i$. Opening facility $j$ incurs a fixed nonnegative cost $f_j$. Assigning customer $i$ to facility $j$ incurs a nonnegative unit assignment cost $a_{ij}$. The decision variable for each facility is $y_j \\in \\{0,1\\}$ indicating whether facility $j$ is open. Each customer must be assigned to some open facility. The total cost of a solution $\\mathbf{y} = (y_1,\\dots,y_n)$ is defined by\n$$\nF(\\mathbf{y}) \\;=\\; \\sum_{j=1}^{n} f_j \\, y_j \\;+\\; \\sum_{i=1}^{m} d_i \\, \\min_{\\{j \\,:\\, y_j = 1\\}} a_{ij},\n$$\nsubject to the feasibility condition $\\sum_{j=1}^{n} y_j \\ge 1$ so that at least one facility is opened. All inputs are dimensionless and nonnegative. Your task is to write a deterministic program that, for each test case below, returns the minimal possible objective value $F(\\mathbf{y})$ as a real number. If your procedure uses randomness internally, you must initialize any pseudo-random number generator with the fixed seed $42$ to ensure deterministic outputs.\n\nUse the following test suite. For each test case, the instance is given by the tuple $(m, n, \\mathbf{d}, \\mathbf{f}, \\mathbf{A})$, where $\\mathbf{d} = (d_1,\\dots,d_m)$, $\\mathbf{f} = (f_1,\\dots,f_n)$, and $\\mathbf{A} = [a_{ij}] \\in \\mathbb{R}_{\\ge 0}^{m \\times n}$.\n\n- Test case $1$ (boundary case with a single candidate facility):\n  - $m = 2$, $n = 1$.\n  - $\\mathbf{d} = (\\,1,\\,1\\,)$.\n  - $\\mathbf{f} = (\\,1\\,)$.\n  - $\\mathbf{A}$ rows:\n    - customer $1$: $(\\,1\\,)$,\n    - customer $2$: $(\\,1\\,)$.\n\n- Test case $2$ (trade-off between opening costs and assignment costs):\n  - $m = 4$, $n = 3$.\n  - $\\mathbf{d} = (\\,1,\\,1,\\,1,\\,1\\,)$.\n  - $\\mathbf{f} = (\\,2,\\,2,\\,2\\,)$.\n  - $\\mathbf{A}$ rows:\n    - customer $1$: $(\\,1,\\,4,\\,4\\,)$,\n    - customer $2$: $(\\,4,\\,1,\\,4\\,)$,\n    - customer $3$: $(\\,4,\\,4,\\,1\\,)$,\n    - customer $4$: $(\\,2,\\,2,\\,2\\,)$.\n\n- Test case $3$ (edge case with heterogeneous demands and high opening costs):\n  - $m = 5$, $n = 4$.\n  - $\\mathbf{d} = (\\,2,\\,1,\\,3,\\,2,\\,1\\,)$.\n  - $\\mathbf{f} = (\\,8,\\,8,\\,8,\\,8\\,)$.\n  - $\\mathbf{A}$ rows:\n    - customer $1$: $(\\,1,\\,5,\\,6,\\,7\\,)$,\n    - customer $2$: $(\\,5,\\,1,\\,6,\\,7\\,)$,\n    - customer $3$: $(\\,6,\\,6,\\,1,\\,7\\,)$,\n    - customer $4$: $(\\,7,\\,7,\\,7,\\,1\\,)$,\n    - customer $5$: $(\\,2,\\,2,\\,2,\\,2\\,)$.\n\nYour program should compute, for each test case, the minimal objective value $F(\\mathbf{y})$ as a floating-point number rounded to one digit after the decimal point. Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (for example, \"[x,y,z]\"). The results must be printed in the order of the test cases $1$, $2$, $3$.", "solution": "The problem presented is a classic formulation of the uncapacitated facility location problem (UFLP), a well-known topic in the field of operations research and combinatorial optimization.\n\nFirst, validation of the problem statement.\nThe givens are:\n- A set of $m$ customers, indexed by $i \\in \\{1,\\dots,m\\}$.\n- A set of $n$ candidate facilities, indexed by $j \\in \\{1,\\dots,n\\}$.\n- Nonnegative demand for each customer, $d_i \\ge 0$.\n- Nonnegative fixed cost for opening each facility, $f_j \\ge 0$.\n- Nonnegative unit assignment cost from customer $i$ to facility $j$, $a_{ij} \\ge 0$.\n- A binary decision variable $y_j \\in \\{0,1\\}$ for each facility.\n- An objective function to minimize: $F(\\mathbf{y}) = \\sum_{j=1}^{n} f_j y_j + \\sum_{i=1}^{m} d_i \\min_{\\{j : y_j = 1\\}} a_{ij}$.\n- A feasibility constraint: $\\sum_{j=1}^{n} y_j \\ge 1$.\n- Three specific test cases with all required data are provided.\n\nThe problem is scientifically and mathematically sound. It is a standard NP-hard optimization problem, but the instances provided are of a small scale. The definitions are precise, and all necessary data are supplied. The problem is well-posed: for a finite number of facilities $n$, there exist $2^n$ possible configurations for the set of open facilities. The feasibility constraint removes only the trivial case where no facilities are open, leaving $2^n - 1$ valid configurations. Since this is a finite set of possibilities, a minimum cost solution is guaranteed to exist. The problem is thus deemed valid.\n\nThe solution will be found by performing an exhaustive search over the entire space of feasible solutions. This approach, while computationally intractable for large $n$, is perfectly suitable and provides an exact, deterministic solution for the small values of $n$ in the test cases ($n=1, n=3, n=4$). The number of configurations to check are $2^1-1=1$, $2^3-1=7$, and $2^4-1=15$, respectively. These are computationally trivial quantities.\n\nThe algorithm proceeds as follows:\nLet the set of all candidate facilities be $\\mathcal{N} = \\{1, \\dots, n\\}$. A feasible solution corresponds to opening a non-empty subset of facilities $S \\subseteq \\mathcal{N}$, $S \\neq \\emptyset$.\nFor each such subset $S$, we calculate the total cost, which is the sum of the facility opening costs and the customer assignment costs.\n\nThe total opening cost for a given subset $S$ is:\n$$\nC_{open}(S) = \\sum_{j \\in S} f_j\n$$\n\nThe total assignment cost for the same subset $S$ is calculated by assigning each customer $i$ to the open facility $j \\in S$ that has the minimum assignment cost $a_{ij}$. The cost for customer $i$ is thus $d_i \\min_{j \\in S} a_{ij}$. Summing over all customers gives the total assignment cost:\n$$\nC_{assign}(S) = \\sum_{i=1}^{m} d_i \\min_{j \\in S} a_{ij}\n$$\n\nThe total cost for the configuration $S$ is the sum of these two components:\n$$\nF(S) = C_{open}(S) + C_{assign}(S)\n$$\n\nThe algorithm iterates through all $2^n - 1$ non-empty subsets $S$ of $\\mathcal{N}$, calculates $F(S)$ for each, and identifies the minimum value.\n\nFor example, let us consider test case $2$, where $m=4$, $n=3$, $\\mathbf{d}=(1,1,1,1)$, $\\mathbf{f}=(2,2,2)$, and $\\mathbf{A}$ is given. We must check $2^3 - 1 = 7$ configurations.\nIf we consider opening all three facilities, $S=\\{1,2,3\\}$, the cost is:\n- Opening cost: $C_{open}(\\{1,2,3\\}) = f_1 + f_2 + f_3 = 2+2+2 = 6$.\n- Assignment cost:\n    - Customer $1$: $d_1 \\min(a_{11}, a_{12}, a_{13}) = 1 \\times \\min(1,4,4) = 1$.\n    - Customer $2$: $d_2 \\min(a_{21}, a_{22}, a_{23}) = 1 \\times \\min(4,1,4) = 1$.\n    - Customer $3$: $d_3 \\min(a_{31}, a_{32}, a_{33}) = 1 \\times \\min(4,4,1) = 1$.\n    - Customer $4$: $d_4 \\min(a_{41}, a_{42}, a_{43}) = 1 \\times \\min(2,2,2) = 2$.\n- Total assignment cost: $C_{assign}(\\{1,2,3\\}) = 1+1+1+2 = 5$.\n- Total cost: $F(\\{1,2,3\\}) = 6+5 = 11$.\n\nBy systematically evaluating all $7$ configurations, we find that this value of $11$ is indeed the minimum for this test case. The same procedure is applied to all three test cases to find their respective minimal costs. The final implementation will follow this exact logic.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves a series of uncapacitated facility location problems.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # Test case 1\n        (\n            2, 1, # m, n are dummy values, overridden by array shapes\n            np.array([1, 1]),\n            np.array([1]),\n            np.array([[1], [1]])\n        ),\n        # Test case 2\n        (\n            4, 3,\n            np.array([1, 1, 1, 1]),\n            np.array([2, 2, 2]),\n            np.array([[1, 4, 4], \n                      [4, 1, 4], \n                      [4, 4, 1], \n                      [2, 2, 2]])\n        ),\n        # Test case 3\n        (\n            5, 4,\n            np.array([2, 1, 3, 2, 1]),\n            np.array([8, 8, 8, 8]),\n            np.array([[1, 5, 6, 7], \n                      [5, 1, 6, 7], \n                      [6, 6, 1, 7], \n                      [7, 7, 7, 1], \n                      [2, 2, 2, 2]])\n        )\n    ]\n\n    results = []\n    for _, _, d, f, A in test_cases:\n        m, n = A.shape\n        min_total_cost = float('inf')\n\n        # Iterate through all non-empty subsets of facilities.\n        # An integer 'i' from 1 to 2^n - 1 represents a unique subset,\n        # where the j-th bit of 'i' indicates if facility j is open.\n        for i in range(1, 1  n):\n            \n            # Create a boolean vector representing the open facilities\n            open_facilities_mask = np.array([bool(i  (1  j)) for j in range(n)])\n            \n            # 1. Calculate the total cost of opening facilities\n            opening_cost = np.sum(f[open_facilities_mask])\n            \n            # 2. Calculate the total cost of assigning customers\n            \n            # Select columns of the assignment cost matrix for open facilities\n            assignment_costs_to_open_facilities = A[:, open_facilities_mask]\n            \n            # For each customer, find the minimum assignment cost to an open facility\n            min_assignment_costs_per_customer = np.min(assignment_costs_to_open_facilities, axis=1)\n            \n            # The total assignment cost is the sum of (demand * min_cost) for all customers\n            assignment_cost = np.dot(d, min_assignment_costs_per_customer)\n            \n            # 3. Calculate the total cost for the current configuration\n            total_cost = opening_cost + assignment_cost\n            \n            # 4. Update the overall minimum cost\n            if total_cost  min_total_cost:\n                min_total_cost = total_cost\n                \n        results.append(min_total_cost)\n\n    # Format the results to one decimal place as required and print\n    formatted_results = [f\"{r:.1f}\" for r in results]\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n\n```", "id": "2399266"}, {"introduction": "Many real-world optimization problems are subject to strict constraints. Heuristic algorithms, like Genetic Algorithms (GAs), often explore the search space freely and may generate infeasible solutions. This exercise [@problem_id:2399283] challenges you to think critically about designing a \"repair operator\" for the Set Covering Problem, a mechanism that transforms an infeasible solution into a feasible one. Evaluating different repair strategies will build your intuition for designing effective and principled constraint-handling techniques.", "problem": "In the classical set covering problem, one is given a finite ground set $U = \\{1,2,\\dots,m\\}$ and a family of subsets $\\{S_j \\subseteq U\\}_{j=1}^n$ with positive costs $\\{c_j\\}_{j=1}^n$. A binary decision vector $x \\in \\{0,1\\}^n$ represents a selection of subsets, where $x_j = 1$ means $S_j$ is selected. Feasibility requires that every element $i \\in U$ is covered by at least one selected subset, that is, for all $i \\in U$, $\\sum_{j : i \\in S_j} x_j \\ge 1$. The objective is to minimize $\\sum_{j=1}^n c_j x_j$ subject to feasibility. Assume that $\\bigcup_{j=1}^n S_j = U$ so that at least one feasible solution exists.\n\nA Genetic Algorithm (GA) maintains a population of chromosomes $x \\in \\{0,1\\}^n$. Crossover and mutation can produce infeasible offspring that violate one or more covering constraints. A repair operator is applied to map an infeasible chromosome to a feasible one before evaluation.\n\nConsider the specific instance with $U = \\{1,2,3,4,5\\}$, subsets and costs\n- $S_1 = \\{1,2\\}$ with $c_1 = 3$,\n- $S_2 = \\{2,3,4\\}$ with $c_2 = 4$,\n- $S_3 = \\{3,5\\}$ with $c_3 = 2$,\n- $S_4 = \\{1,4,5\\}$ with $c_4 = 5$,\n- $S_5 = \\{2,5\\}$ with $c_5 = 2$,\nand an infeasible offspring chromosome $x = (x_1,x_2,x_3,x_4,x_5) = (1,0,0,0,1)$, which selects $S_1$ and $S_5$ only. The currently covered set is $S_1 \\cup S_5 = \\{1,2,5\\}$; elements $\\{3,4\\}$ are uncovered.\n\nYou are asked to select a repair operator that is soundly justified from first principles (definitions of feasibility and coverage) and balances cost awareness with guaranteed progress to feasibility.\n\nWhich one of the following repair mechanisms both\n(i) guarantees that at each addition step the number of uncovered elements strictly decreases (hence it terminates in at most $|U|$ additions) and never accepts a removal that breaks feasibility, and\n(ii) when applied to the given instance and chromosome $x$, results in the minimum total cost among the listed mechanisms?\n\nA. Greedy uncovered-coverage-per-cost with redundancy elimination:\n- While there exists an uncovered element, choose an index $j \\in \\{1,\\dots,5\\}$ with $x_j = 0$ that minimizes the ratio $c_j / |\\;S_j \\cap \\text{Uncovered}\\;|$, where $\\text{Uncovered} \\subseteq U$ is the current set of uncovered elements (ties broken by larger $|\\;S_j \\cap \\text{Uncovered}\\;|$). Set $x_j \\leftarrow 1$ and update $\\text{Uncovered}$.\n- After feasibility is achieved, attempt to remove redundancy: consider selected sets in nonincreasing order of $c_j / |S_j|$ and set $x_j \\leftarrow 0$ if and only if feasibility is preserved; stop when no removal is possible.\n\nB. Cheapest-first addition without regard to marginal uncovered coverage:\n- While infeasible, repeatedly select the cheapest not-yet-selected set (smallest $c_j$ among $j$ with $x_j = 0$), set $x_j \\leftarrow 1$, and stop once feasibility is achieved; do not remove any set.\n\nC. Overlap-maximizing addition:\n- While infeasible, repeatedly select the not-yet-selected set $S_j$ that maximizes $|\\;S_j \\cap (\\bigcup_{k : x_k = 1} S_k)\\;|$ (ties broken by smallest $c_j$), set $x_j \\leftarrow 1$, and stop once feasibility is achieved; do not remove any set.\n\nD. Penalty-only handling:\n- Do not change $x$; instead, assign a large additive penalty $\\rho \\cdot |\\text{Uncovered}|$ to the objective for fitness evaluation, with $\\rho \\gg \\max_j c_j$.\n\nChoose the single best option that satisfies both (i) and (ii) based on the fundamental definitions above, not on any unstated heuristics or external formulas. Provide only one answer choice.", "solution": "The problem statement has been validated and found to be self-contained, scientifically grounded, and well-posed. We may proceed with the solution.\n\nThe problem asks us to evaluate four repair mechanisms for a Genetic Algorithm solving a specific instance of the Set Covering Problem. The objective is to identify the mechanism that satisfies two conditions:\n(i) it guarantees convergence to a feasible solution by strictly reducing the number of uncovered elements at each addition step and preserving feasibility during any removal step.\n(ii) it produces a repaired solution with the minimum total cost among the four listed mechanisms for the given instance.\n\nThe specific instance is defined by:\n- Ground set $U = \\{1, 2, 3, 4, 5\\}$.\n- Subsets and costs:\n  - $S_1 = \\{1, 2\\}$ with $c_1 = 3$.\n  - $S_2 = \\{2, 3, 4\\}$ with $c_2 = 4$.\n  - $S_3 = \\{3, 5\\}$ with $c_3 = 2$.\n  - $S_4 = \\{1, 4, 5\\}$ with $c_4 = 5$.\n  - $S_5 = \\{2, 5\\}$ with $c_5 = 2$.\n- The initial infeasible chromosome is $x = (1, 0, 0, 0, 1)$. This corresponds to selecting sets $S_1$ and $S_5$.\n\nThe initial state is as follows:\n- Selected sets: $\\{S_1, S_5\\}$.\n- Initial cost: $c_1 + c_5 = 3 + 2 = 5$.\n- Covered set: $C_0 = S_1 \\cup S_5 = \\{1, 2\\} \\cup \\{2, 5\\} = \\{1, 2, 5\\}$.\n- Uncovered set: $\\text{Uncovered}_0 = U \\setminus C_0 = \\{3, 4\\}$.\n\nWe will now analyze each option.\n\n**A. Greedy uncovered-coverage-per-cost with redundancy elimination**\n\nFirst, we evaluate condition (i). The additive phase selects a set $S_j$ that minimizes the ratio $c_j / |S_j \\cap \\text{Uncovered}|$. Since all costs $c_j$ are positive, for the ratio to be finite and minimal, the denominator $|S_j \\cap \\text{Uncovered}|$ must be a positive integer. This means any added set $S_j$ must cover at least one currently uncovered element, thereby strictly decreasing the number of uncovered elements. The removal phase is explicitly constrained to preserve feasibility. Thus, condition (i) is satisfied.\n\nNext, we apply this mechanism to the instance.\n1.  **Additive phase:** The initial set of uncovered elements is $\\text{Uncovered}_0 = \\{3, 4\\}$. We must select a set $S_j$ from $\\{S_2, S_3, S_4\\}$ (those with $x_j=0$) to add. We compute the selection metric $c_j / |S_j \\cap \\text{Uncovered}_0|$ for each:\n    - $S_2$: $c_2 = 4$, $S_2 \\cap \\{3, 4\\} = \\{3, 4\\}$, so $|S_2 \\cap \\{3, 4\\}| = 2$. Ratio is $4/2 = 2$.\n    - $S_3$: $c_3 = 2$, $S_3 \\cap \\{3, 4\\} = \\{3\\}$, so $|S_3 \\cap \\{3, 4\\}| = 1$. Ratio is $2/1 = 2$.\n    - $S_4$: $c_4 = 5$, $S_4 \\cap \\{3, 4\\} = \\{4\\}$, so $|S_4 \\cap \\{3, 4\\}| = 1$. Ratio is $5/1 = 5$.\n    There is a tie between $S_2$ and $S_3$ with the minimum ratio of $2$. The tie-breaking rule is to choose the one with the larger value of $|S_j \\cap \\text{Uncovered}|$. For $S_2$, this value is $2$, and for $S_3$, it is $1$. We therefore select $S_2$.\n    We set $x_2 \\leftarrow 1$. The new set of selected subsets is $\\{S_1, S_2, S_5\\}$. The covered set is $S_1 \\cup S_2 \\cup S_5 = \\{1, 2\\} \\cup \\{2, 3, 4\\} \\cup \\{2, 5\\} = \\{1, 2, 3, 4, 5\\} = U$. The solution is now feasible.\n\n2.  **Redundancy elimination phase:** The current solution is $x=(1, 1, 0, 0, 1)$, selecting $\\{S_1, S_2, S_5\\}$. The total cost is $c_1 + c_2 + c_5 = 3 + 4 + 2 = 9$. We consider removing sets in nonincreasing order of $c_j/|S_j|$:\n    - $S_1$: $c_1/|S_1| = 3/2 = 1.5$.\n    - $S_2$: $c_2/|S_2| = 4/3 \\approx 1.33$.\n    - $S_5$: $c_5/|S_5| = 2/2 = 1$.\n    The order of consideration is $S_1, S_2, S_5$.\n    - Try removing $S_1$: The remaining sets $\\{S_2, S_5\\}$ cover $S_2 \\cup S_5 = \\{2, 3, 4, 5\\}$. Element $1$ becomes uncovered. Removal is rejected.\n    - Try removing $S_2$: The remaining sets $\\{S_1, S_5\\}$ cover $S_1 \\cup S_5 = \\{1, 2, 5\\}$. Elements $3$ and $4$ become uncovered. Removal is rejected.\n    - Try removing $S_5$: The remaining sets $\\{S_1, S_2\\}$ cover $S_1 \\cup S_2 = \\{1, 2, 3, 4\\}$. Element $5$ becomes uncovered. Removal is rejected.\n    No sets can be removed. The final repaired solution is $x = (1, 1, 0, 0, 1)$ with a total cost of $9$.\n\nVerdict for A: This mechanism satisfies condition (i). For the given instance, it produces a feasible solution with a total cost of $9$.\n\n**B. Cheapest-first addition without regard to marginal uncovered coverage**\n\nFirst, we evaluate condition (i). This mechanism adds the cheapest available set, irrespective of whether it covers any currently uncovered elements. It is possible for the cheapest set $S_j$ to be a subset of the already covered set ($S_j \\subseteq \\bigcup_{k:x_k=1} S_k$). In such a case, adding $S_j$ would not decrease the number of uncovered elements. Therefore, this mechanism does not guarantee a strict decrease at each step. Condition (i) is violated.\n\nNext, we apply this mechanism to the instance.\n1.  **Additive phase:** The uncovered set is $\\{3, 4\\}$. Available sets for addition are $\\{S_2, S_3, S_4\\}$ with costs $c_2 = 4, c_3 = 2, c_4 = 5$. The cheapest is $S_3$. We add $S_3$.\n    The selected sets are now $\\{S_1, S_3, S_5\\}$. The covered set is $S_1 \\cup S_3 \\cup S_5 = \\{1, 2, 3, 5\\}$. The uncovered set is $\\{4\\}$. The solution is still infeasible.\n2.  We repeat the process. Available sets for addition are $\\{S_2, S_4\\}$ with costs $c_2 = 4, c_4 = 5$. The cheapest is $S_2$. We add $S_2$.\n    The selected sets are now $\\{S_1, S_2, S_3, S_5\\}$. The covered set is $S_1 \\cup S_2 \\cup S_3 \\cup S_5 = \\{1, 2, 3, 4, 5\\} = U$. The solution is feasible.\nThe mechanism stops. There is no removal phase. The final solution is $x = (1, 1, 1, 0, 1)$.\nThe total cost is $c_1 + c_2 + c_3 + c_5 = 3 + 4 + 2 + 2 = 11$.\n\nVerdict for B: This mechanism violates condition (i). For the given instance, it produces a feasible solution with a total cost of $11$.\n\n**C. Overlap-maximizing addition**\n\nFirst, we evaluate condition (i). This mechanism adds the set that maximizes overlap with the *currently covered* elements. The objective is to reinforce existing coverage, not necessarily to cover new elements. It is possible that the set with maximum overlap, $S_j$, covers no new elements ($S_j \\cap \\text{Uncovered} = \\emptyset$). In this case, the number of uncovered elements does not decrease. Therefore, this mechanism does not guarantee a strict decrease at each step. Condition (i) is violated.\n\nNext, we apply this mechanism to the instance.\n1.  **Additive phase:** The initial covered set is $K_0 = \\{1, 2, 5\\}$, and the uncovered set is $\\{3, 4\\}$. We choose from $\\{S_2, S_3, S_4\\}$ based on maximizing $|S_j \\cap K_0|$.\n    - $S_2$: $|S_2 \\cap K_0| = |\\{2, 3, 4\\} \\cap \\{1, 2, 5\\}| = |\\{2\\}| = 1$.\n    - $S_3$: $|S_3 \\cap K_0| = |\\{3, 5\\} \\cap \\{1, 2, 5\\}| = |\\{5\\}| = 1$.\n    - $S_4$: $|S_4 \\cap K_0| = |\\{1, 4, 5\\} \\cap \\{1, 2, 5\\}| = |\\{1, 5\\}| = 2$.\n    $S_4$ has the maximum overlap. We add $S_4$. The selected sets are now $\\{S_1, S_4, S_5\\}$, and the covered set is $K_1 = S_1 \\cup S_4 \\cup S_5 = \\{1, 2, 4, 5\\}$. The uncovered set is $\\{3\\}$. The solution is still infeasible.\n2.  We repeat the process. The current covered set is $K_1 = \\{1, 2, 4, 5\\}$. Available sets for addition are $\\{S_2, S_3\\}$.\n    - $S_2$: $|S_2 \\cap K_1| = |\\{2, 3, 4\\} \\cap \\{1, 2, 4, 5\\}| = |\\{2, 4\\}| = 2$.\n    - $S_3$: $|S_3 \\cap K_1| = |\\{3, 5\\} \\cap \\{1, 2, 4, 5\\}| = |\\{5\\}| = 1$.\n    $S_2$ has the maximum overlap. We add $S_2$. The selected sets are now $\\{S_1, S_2, S_4, S_5\\}$, and the covered set is $S_1 \\cup S_2 \\cup S_4 \\cup S_5 = \\{1, 2, 3, 4, 5\\} = U$. The solution is feasible.\nThere is no removal phase. The final solution is $x = (1, 1, 0, 1, 1)$.\nThe total cost is $c_1 + c_2 + c_4 + c_5 = 3 + 4 + 5 + 2 = 14$.\n\nVerdict for C: This mechanism violates condition (i). For the given instance, it produces a feasible solution with a total cost of $14$.\n\n**D. Penalty-only handling**\n\nThis mechanism does not alter the chromosome. It simply adds a penalty to the objective function for evaluation. The problem defines a repair operator as a procedure that \"map[s] an infeasible chromosome to a feasible one\". This mechanism fails to do so. It does not contain any \"addition step\" and thus cannot satisfy the guarantee in condition (i). It makes no progress towards feasibility. As such, it is not a repair operator in the sense required by the problem and fails condition (i).\n\nFurthermore, since it does not produce a feasible solution, its cost under the set covering objective $\\sum c_j x_j$ is not comparable to the others which do produce feasible solutions. One might consider its effective cost to be infinite. In any case, it cannot result in the minimum total cost. The penalized cost would be $5 + 2\\rho$, which is very large by definition. So it also fails condition (ii).\n\nVerdict for D: This mechanism violates condition (i) as it does not map an infeasible solution to a feasible one. It also fails condition (ii).\n\n**Conclusion**\n\nWe summarize the findings:\n- **Mechanism A:** Satisfies condition (i). Produces a feasible solution with cost $9$.\n- **Mechanism B:** Violates condition (i). Produces a feasible solution with cost $11$.\n- **Mechanism C:** Violates condition (i). Produces a feasible solution with cost $14$.\n- **Mechanism D:** Violates condition (i) and does not produce a feasible solution.\n\nOnly mechanism A satisfies condition (i).\nFor condition (ii), we compare the costs of the solutions produced by the mechanisms: Cost(A) = $9$, Cost(B) = $11$, Cost(C) = $14$. The minimum cost among these is $9$, achieved by mechanism A. Because mechanism D does not produce a valid, finite-cost feasible solution, it is not a contender for the minimum cost.\nTherefore, mechanism A is the only one that satisfies both conditions (i) and (ii).", "answer": "$$\\boxed{A}$$", "id": "2399283"}, {"introduction": "Heuristic methods are not one-size-fits-all; they often require careful adaptation to suit different problem domains. This practice [@problem_id:2399268] explores the adaptation of Particle Swarm Optimization (PSO), a powerful algorithm designed for continuous spaces, to a discrete integer programming problem. Your task is to analyze various adaptation strategies, learning to distinguish between ad-hoc fixes and principled approaches that preserve the core intelligence of the original algorithm.", "problem": "You are asked to adapt Particle Swarm Optimization (PSO) to a discrete integer programming setting. Consider the constrained optimization problem with decision vector $x \\in \\mathbb{Z}^d$:\nminimize $f(x)$ subject to $0 \\le x_j \\le 5$ for all $j \\in \\{1,\\dots,d\\}$ and $\\sum_{j=1}^d x_j = 12$. In the continuous formulation, a standard PSO maintains, for each particle $i$, a position $x_i^t \\in \\mathbb{R}^d$ and a velocity $v_i^t \\in \\mathbb{R}^d$ updated by\n$$\nv_i^{t+1} = \\omega\\, v_i^{t} + c_1\\, r_{1}^{t} \\odot \\big(p_i^{t} - x_i^{t}\\big) + c_2\\, r_{2}^{t} \\odot \\big(g^{t} - x_i^{t}\\big), \\quad\nx_i^{t+1} = x_i^{t} + v_i^{t+1},\n$$\nwhere $\\omega, c_1, c_2 \\in \\mathbb{R}$ are parameters, $r_1^{t}, r_2^{t} \\in [0,1]^d$ are random vectors sampled componentwise, $\\odot$ denotes componentwise multiplication, $p_i^{t}$ is the personal best of particle $i$, and $g^{t}$ is the global best. You intend to adapt these updates so that, after every iteration, each particle’s position is an integer vector that satisfies the box constraints and the sum constraint. Which of the following strategies yields a well-posed adaptation that ensures every updated position lies in the feasible set $X = \\{x \\in \\mathbb{Z}^d: 0 \\le x_j \\le 5,\\ \\sum_{j=1}^d x_j = 12\\}$ and preserves the interpretation that the discrete update is the nearest feasible counterpart of the continuous attraction step? Select all that apply.\n\nA. After computing the continuous candidate $y_i^{t+1} = x_i^{t} + v_i^{t+1}$, round each component of $y_i^{t+1}$ to the nearest integer and clip it to $[0,5]$. If the sum constraint $\\sum_{j=1}^d x_{i,j}^{t+1} = 12$ is violated, repeatedly pick a random pair of distinct indices $(j,k)$ and adjust $x_{i,j}^{t+1}$ by $+1$ and $x_{i,k}^{t+1}$ by $-1$ (or vice versa, depending on the sign of the discrepancy) while respecting bounds, until the sum equals $12$.\n\nB. Replace real-valued positions by binary vectors in $\\{0,1\\}^d$ and interpret each velocity component via a sigmoid mapping as a flip probability. Update by independently flipping bits according to these probabilities. If $\\sum_{j=1}^d x_{i,j}^{t+1} \\ne 12$, repeatedly resample flips until the equality holds.\n\nC. Define an integer-valued “velocity” by rounding the right-hand side of the standard PSO velocity equation to the nearest integers. Update positions by $x_i^{t+1} = x_i^{t} + v_i^{t+1}$ componentwise and then reduce each component modulo $6$ to enforce $0 \\le x_{i,j}^{t+1} \\le 5$. Ignore the sum constraint during updates.\n\nD. Encode $x$ as a permutation of $\\{1,\\dots,d\\}$ and represent velocity as a sequence of swaps that move a permutation toward its personal and global best permutations. After applying a composed swap sequence to update a particle, decode back to an integer vector by “scaling” the permutation to meet $\\sum_{j=1}^d x_j = 12$ and clipping to $[0,5]$.\n\nE. After computing the continuous candidate $y_i^{t+1} = x_i^{t} + v_i^{t+1}$, map it to an integer feasible vector by solving\n$$\n\\min_{z \\in \\mathbb{Z}^d} \\ \\|z - y_i^{t+1}\\|_2 \\quad \\text{subject to} \\quad 0 \\le z_j \\le 5,\\ \\sum_{j=1}^d z_j = 12,\n$$\nimplemented efficiently by first rounding $y_i^{t+1}$ to nearest integers and then adjusting the rounded vector by distributing the sum-discrepancy over components with largest (in magnitude) fractional parts, while respecting bounds, so that the final $z$ has sum $12$ and remains as close as possible (in Euclidean norm) to $y_i^{t+1}$.", "solution": "The validity of the problem statement must first be established.\n\n### Step 1: Extract Givens\n- The problem is a constrained optimization problem for a function $f(x)$ where the decision vector is $x \\in \\mathbb{Z}^d$.\n- The feasible set $X$ is defined by two types of constraints:\n    1. Box constraints: $0 \\le x_j \\le 5$ for all $j \\in \\{1,\\dots,d\\}$.\n    2. A linear equality constraint (sum constraint): $\\sum_{j=1}^d x_j = 12$.\n- The task is to adapt the standard continuous Particle Swarm Optimization (PSO) algorithm for this discrete domain.\n- The standard continuous PSO update equations are given for a particle $i$ at time step $t$:\n$$\nv_i^{t+1} = \\omega\\, v_i^{t} + c_1\\, r_{1}^{t} \\odot \\big(p_i^{t} - x_i^{t}\\big) + c_2\\, r_{2}^{t} \\odot \\big(g^{t} - x_i^{t}\\big)\n$$\n$$\nx_i^{t+1} = x_i^{t} + v_i^{t+1}\n$$\n- The adaptation must satisfy two conditions:\n    1. The updated position must always belong to the feasible set $X = \\{x \\in \\mathbb{Z}^d: 0 \\le x_j \\le 5, \\sum_{j=1}^d x_j = 12\\}$.\n    2. The adaptation must preserve the interpretation that the discrete update is the \"nearest feasible counterpart\" of the continuous attraction step.\n\n### Step 2: Validate Using Extracted Givens\n- **Scientifically Grounded:** The problem is firmly rooted in the field of computational engineering and heuristic optimization. Adapting continuous metaheuristics like PSO for discrete or constrained problems is a standard and important research topic. The problem formulation uses established mathematical concepts and a well-known algorithm. The constraints define a valid integer programming feasible region. The problem is scientifically sound.\n- **Well-Posed:** The problem provides all necessary information. It clearly defines the search space, the update rules to be adapted, and the criteria for a successful adaptation (feasibility and \"nearest counterpart\"). The term \"nearest feasible counterpart\" is given a clear context by relating it to the continuous attraction step, which points unambiguously to a distance minimization principle. The question is structured to have a unique set of correct answers among the options.\n- **Objective:** The language is precise and technical. The evaluation criteria are objective and can be assessed using mathematical and algorithmic reasoning.\n\n### Step 3: Verdict and Action\nThe problem statement is valid. It is scientifically grounded, well-posed, and objective. I will now proceed with the solution by evaluating each option.\n\nThe core of the problem is to map a continuous candidate solution, $y_i^{t+1} = x_i^{t} + v_i^{t+1}$, to a point $z \\in X$ that is both feasible and conceptually \"close\" to $y_i^{t+1}$. The criterion of being the \"nearest feasible counterpart\" is most rigorously interpreted as finding a vector $z$ that minimizes a distance metric to $y_i^{t+1}$, subject to $z \\in X$. The standard choice for this is the Euclidean distance (or its square), leading to the projection problem: $\\min_{z \\in X} \\|z - y_i^{t+1}\\|_2^2$.\n\n### Option-by-Option Analysis\n\n**Option A:**\nThis strategy first creates an intermediate integer vector by rounding and clipping, which enforces the box constraints $0 \\le x_j \\le 5$ and the integer requirement. However, it then attempts to satisfy the sum constraint $\\sum x_j = 12$ through a series of random adjustments. Specifically, it randomly picks pairs of indices $(j,k)$ and applies updates of the form $(x_j, x_k) \\to (x_j+1, x_k-1)$ or $(x_j-1, x_k+1)$. While this repair mechanism will eventually enforce the sum constraint and maintain the box constraints, the random nature of the adjustments is its critical flaw. By choosing indices randomly, the procedure does not attempt to minimize the deviation from the original continuous candidate $y_i^{t+1}$. The final vector could be arbitrarily far from the true \"nearest\" feasible point, depending on the sequence of random choices. This violates the principle of preserving the \"nearest feasible counterpart\" interpretation. The procedure is ad-hoc, not principled.\n**Verdict: Incorrect.**\n\n**Option B:**\nThis strategy is fundamentally flawed because it redefines the problem. The original problem specifies integer variables $x_j \\in \\{0, 1, 2, 3, 4, 5\\}$. This option proposes using binary vectors, $x_j \\in \\{0, 1\\}$, which is a different search space. It replaces the integer programming problem with a binary programming problem. Furthermore, it proposes a \"rejection sampling\" approach (\"repeatedly resample flips\") to satisfy the sum constraint, which is computationally inefficient and may not be guaranteed to terminate in a reasonable time. This is not a valid adaptation of the given problem.\n**Verdict: Incorrect.**\n\n**Option C:**\nThis strategy fails on two counts. First, it explicitly states to \"ignore the sum constraint\". This means the resulting particles' positions $x_i^{t+1}$ are not guaranteed to be in the feasible set $X$, violating a primary requirement of the adaptation. Second, it uses a modulo operator, $x_{i,j}^{t+1} \\pmod 6$, to enforce the box constraints. The modulo operator creates a \"wrap-around\" effect. For instance, a value of $6$ becomes $0$, and a value of $-1$ becomes $5$. This is not equivalent to finding the nearest integer in the interval $[0,5]$. The standard operation for that would be clipping, i.e., $\\max(0, \\min(5, x_j))$. The wrap-around behavior is inconsistent with the PSO principle of attraction, where a large velocity should move a particle to the boundary of the search space, not teleport it to the opposite side.\n**Verdict: Incorrect.**\n\n**Option D:**\nThis strategy proposes encoding the integer vector $x$ as a permutation. This is a technique suitable for combinatorial optimization problems where the solution is an ordering of elements, such as the Traveling Salesperson Problem or scheduling problems. The problem at hand is an integer programming problem, not a permutation-based one. Using a permutation encoding here is unnatural and forces the problem into a framework for which it is not designed. Moreover, the description is vague, referring to a \"sequence of swaps\" for velocity and \"scaling\" the permutation back to an integer vector. This is not a direct adaptation of the given vector-based PSO update rules and entirely abandons the geometric interpretation of particles moving in a $d$-dimensional space. It fails to preserve the \"continuous attraction step\" concept.\n**Verdict: Incorrect.**\n\n**Option E:**\nThis strategy provides the most rigorous and principled approach. It formalizes the concept of the \"nearest feasible counterpart\" by defining it as the solution to a minimization problem: finding a point $z$ in the feasible set $X$ that minimizes the Euclidean distance to the continuous candidate $y_i^{t+1}$. This is precisely a projection of $y_i^{t+1}$ onto the feasible set $X$. This guarantees that the updated particle position is feasible by construction and is the closest possible feasible point to where the continuous PSO dynamics would have placed it. The option then describes a well-known and efficient greedy algorithm to solve this specific projection problem: first round to the nearest integers, then iteratively adjust the components to satisfy the sum constraint by adding or subtracting $1$ at each step from the component that incurs the minimal increase in the squared Euclidean distance. This corresponds to adjusting components based on their fractional parts or, more accurately, the difference between the rounded and original continuous values. This strategy is well-posed, guarantees feasibility, and perfectly aligns with the \"nearest counterpart\" principle.\n**Verdict: Correct.**", "answer": "$$\\boxed{E}$$", "id": "2399268"}]}