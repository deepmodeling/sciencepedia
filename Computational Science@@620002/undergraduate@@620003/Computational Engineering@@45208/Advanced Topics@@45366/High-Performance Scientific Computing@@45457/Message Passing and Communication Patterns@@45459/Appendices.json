{"hands_on_practices": [{"introduction": "In message-passing systems, one of the most critical challenges is avoiding deadlock, a state where multiple processes are stuck waiting for each other in a circular chain. This exercise guides you through simulating a classic deadlock scenario in a ring communication topology to develop first-hand intuition for how resource contention—in this case, limited buffer space—can halt an entire system. By identifying the conditions for deadlock and then determining the minimal resources needed for a fix, you will practice the fundamental skill of reasoning about the correctness of parallel programs [@problem_id:2413727].", "problem": "Consider a discrete, deterministic simulation of blocking message passing among $n$ sequential processes arranged in a unidirectional ring. Each process executes exactly two operations in a fixed order: (i) a blocking send of a single message of size $m$ bytes to its successor, and then (ii) a blocking receive of a single message of size $m$ bytes from its predecessor. The successor of process $i$ is $(i+1)\\bmod n$, and the predecessor is $(i-1)\\bmod n$. There is a single global system buffer pool of size $S$ bytes shared by all sends. A send operation succeeds if and only if at least $m$ bytes are currently available in the global pool; if it succeeds, it enqueues the message into the destination’s inbox and consumes exactly $m$ bytes from the pool. A receive operation succeeds if and only if the receiver’s inbox currently contains at least one message; upon success, it removes the message and returns $m$ bytes to the global pool. All channels are reliable and lossless. No process changes its operation order and no process performs any other actions.\n\nDefine deadlock as a state in which at least one process is not finished and no process can complete its next operation given the current global buffer usage and inbox contents. The simulation proceeds in deterministic round-robin sweeps over processes $0,1,\\dots,n-1,0,1,\\dots$ repeatedly. In each sweep, each process attempts to perform its current operation; if the operation’s condition is not satisfied, the process remains blocked on that operation for this attempt. The simulation terminates either when all processes have completed both operations or when an entire sweep results in no successful operation while at least one process is not finished (deadlock).\n\nTask: Write a complete program that simulates this system exactly as specified above. For each test case below, run the simulation twice:\n- First, with the provided tuple $(n,m,S)$, and record whether the simulation ends in deadlock (record boolean $true$ for deadlock, $false$ otherwise).\n- Second, without changing the send/receive order or the round-robin schedule, replace $S$ by the minimal global buffer size $S_{\\text{fix}}$ (in bytes) that guarantees the absence of deadlock for this workload, and record whether the simulation ends in deadlock under this fixed configuration. You must determine $S_{\\text{fix}}$ from first principles.\n\nAll byte quantities are to be interpreted literally in bytes. There are no other units in this problem. Your program must produce a single line of output containing the results as a comma-separated list of booleans enclosed in square brackets, in the order specified below. For each test case, output the pair of booleans $[b_{\\text{orig}},b_{\\text{fix}}]$ flattened into a single list in the same order as the test cases are listed.\n\nTest suite (each tuple is $(n,m,S)$, with all quantities in bytes):\n- $(2,10,10)$\n- $(2,10,20)$\n- $(3,8,8)$\n- $(4,8,15)$\n- $(5,7,35)$\n\nTherefore, the required single-line output must contain $10$ booleans corresponding to these $5$ test cases, each contributing $2$ booleans in the stated order. The output format must be exactly a single line:\n\"[b1,b2,b3,b4,b5,b6,b7,b8,b9,b10]\"\nwhere each $b_i$ is either \"True\" or \"False\".", "solution": "The problem statement is subjected to validation.\n\nStep 1: Extract Givens\n- Number of processes: $n$.\n- Processes are arranged in a unidirectional ring, indexed $i \\in \\{0, 1, \\dots, n-1\\}$.\n- Successor of process $i$ is $(i+1)\\bmod n$.\n- Predecessor of process $i$ is $(i-1)\\bmod n$.\n- Each process executes two fixed operations in order: (i) blocking send, then (ii) blocking receive.\n- Message size: $m$ bytes.\n- Global system buffer pool size: $S$ bytes.\n- Send operation condition: succeeds if available buffer is at least $m$ bytes. On success, it consumes $m$ bytes from the pool.\n- Receive operation condition: succeeds if the receiver's inbox contains at least one message. On success, it returns $m$ bytes to the pool.\n- Simulation schedule: deterministic round-robin sweeps over processes $0, 1, \\dots, n-1$.\n- Deadlock definition: a state where at least one process is not finished and an entire sweep results in no successful operations.\n- Termination conditions: (i) all processes complete both operations, or (ii) deadlock occurs.\n- Task: For each given tuple $(n,m,S)$:\n    1.  Simulate with $(n,m,S)$ and record deadlock status $b_{\\text{orig}}$.\n    2.  Determine minimal non-deadlocking buffer size $S_{\\text{fix}}$.\n    3.  Simulate with $(n,m,S_{\\text{fix}})$ and record deadlock status $b_{\\text{fix}}$.\n- Test Suite: $(2,10,10)$, $(2,10,20)$, $(3,8,8)$, $(4,8,15)$, $(5,7,35)$.\n\nStep 2: Validate Using Extracted Givens\n- **Scientifically Grounded**: The problem describes a canonical resource allocation scenario in concurrent systems, specifically modeling communication deadlock. The model is a well-established abstraction in computer science and computational engineering. It is scientifically sound.\n- **Well-Posed**: The system's initial state is implicitly defined (all processes at the `send` stage, buffer at full capacity $S$, all inboxes empty). The rules of state transition are deterministic and unambiguous. The termination conditions are explicit. A unique, meaningful outcome exists for any given set of parameters.\n- **Objective**: The problem is stated using precise, formal language (\"blocking send,\" \"deterministic round-robin,\" \"if and only if\"). All parameters are quantitative. It is free from subjective or ambiguous terminology.\n\nAll other validation criteria are met. The problem is not unsound, non-formalizable, incomplete, unrealistic, ill-posed, or unverifiable.\n\nStep 3: Verdict and Action\nThe problem is valid. A solution will be provided.\n\nThe system described is a discrete-time simulation of communicating sequential processes. The critical aspect of this problem is the potential for deadlock, a circular dependency on shared resources. Here, the resources are the global buffer space and the messages themselves. We must first analyze the conditions that lead to deadlock to determine the minimal buffer size $S_{\\text{fix}}$ that guarantees its prevention. Then, we construct a simulation program to verify the behavior for the given test cases.\n\nLet us analyze the system dynamics. The state of each process $i$ can be one of three: `SEND`, `RECEIVE`, or `DONE`. Initially, all $n$ processes are in the `SEND` state, the buffer holds $S$ bytes, and all message inboxes are empty. The simulation proceeds in sweeps, with processes $0, 1, \\dots, n-1$ attempting their operations sequentially.\n\nA deadlock occurs if and only if the system reaches a state where no process can proceed, yet not all processes are `DONE`. A process is blocked on `SEND` if the buffer has fewer than $m$ bytes. A process is blocked on `RECEIVE` if its inbox is empty.\n\nConsider the initial sweeps. In the first sweep, all processes attempt to send. Let $k_{\\max}$ be the maximum number of processes that can sequentially send before the buffer is exhausted. A process `SEND` consumes $m$ bytes, so $k_{\\max}$ successful sends consume $k_{\\max} \\cdot m$ bytes. This is possible if $S \\ge k_{\\max} \\cdot m$. The $(k_{\\max}+1)$-th process would fail if $S - k_{\\max} \\cdot m < m$. Thus, $k_{\\max} = \\lfloor S/m \\rfloor$. For the problem to be non-trivial, we assume $S \\ge m$ and $n \\ge 2$. Therefore, $k_{\\max} \\ge 1$.\n\nAfter the first round of send attempts based on the round-robin schedule $0, 1, \\dots, n-1$:\n- Processes $0, 1, \\dots, k_{\\max}-1$ successfully send and transition to the `RECEIVE` state.\n- Processes $k_{\\max}, \\dots, n-1$ fail to send and remain blocked in the `SEND` state.\n- The buffer size is reduced to $S' = S - k_{\\max} \\cdot m$. By definition of $k_{\\max}$, we have $S' < m$.\n- The inbox of process $i$ contains one message for each $i \\in \\{1, \\dots, k_{\\max}\\}$. Other inboxes are empty.\n\nNow, consider the next sweep.\n- Any process $j \\in \\{k_{\\max}, \\dots, n-1\\}$ is blocked on `SEND` because the buffer size $S'$ is less than $m$.\n- A process $i \\in \\{0, \\dots, k_{\\max}-1\\}$ is blocked on `RECEIVE` if its inbox is empty. This means its predecessor, $(i-1) \\bmod n$, has not yet successfully sent a message.\n- Let's examine the `RECEIVE` processes:\n    - Process $0$ is waiting for a message from process $n-1$. If $k_{\\max} < n$, then process $n-1$ is blocked on `SEND`. Thus, process $0$ is blocked on `RECEIVE`.\n    - Process $i \\in \\{1, \\dots, k_{\\max}-1\\}$ is waiting for a message from process $i-1$. In the first sweep, process $i-1$ successfully sent a message. Therefore, the inbox of process $i$ is not empty. Process $i$ can successfully receive.\n\nA deadlock occurs if no process can make progress. The `SEND`-blocked processes cannot progress. The `RECEIVE`-blocked processes can progress only if at least one of them can receive. As analyzed, processes $1, \\dots, k_{\\max}-1$ are capable of receiving. A deadlock will occur if and only if this set of receivable processes is empty.\nThe set $\\{1, \\dots, k_{\\max}-1\\}$ is empty if $k_{\\max}-1 < 1$, which simplifies to $k_{\\max} < 2$. Since we assumed $S \\ge m$, $k_{\\max}$ must be at least $1$. Thus, a deadlock is guaranteed if $k_{\\max} = 1$.\n\nThe condition $k_{\\max} = 1$ is equivalent to $1 \\le S/m < 2$, or $m \\le S < 2m$. In this scenario, only process $0$ sends. It then blocks waiting for a message from process $n-1$. All other processes, $1, \\dots, n-1$, are blocked on `SEND` due to insufficient buffer. No process can proceed, and the system is in deadlock.\n\nTo guarantee the absence of deadlock, we must ensure that this condition is avoided. We must have $k_{\\max} \\ge 2$. This requires $S/m \\ge 2$, or $S \\ge 2m$. If $S \\ge 2m$, then at least processes $0$ and $1$ can send. In the next sweep, process $1$ can receive, which returns $m$ bytes to the buffer. This may allow process $2$ (if it was blocked) to send, and a chain reaction of unblocking events propagates through the system, eventually leading to completion for all processes.\n\nTherefore, for any number of processes $n \\ge 2$, the minimal global buffer size that guarantees the absence of deadlock is $S_{\\text{fix}} = 2m$.\n\nThe program will implement a direct simulation of the system. For each test case $(n, m, S)$, it will first run the simulation with the provided $S$ to find $b_{\\text{orig}}$. It will then calculate $S_{\\text{fix}} = 2m$ and run the simulation again with this value to find $b_{\\text{fix}}$. The simulation function will maintain the state of each process, the contents of each inbox, and the available buffer size, executing sweeps until a terminal state (all processes `DONE` or deadlock) is reached.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n# from scipy import ...\n\ndef simulate(n, m, S):\n    \"\"\"\n    Simulates the message passing system as described.\n\n    Args:\n        n (int): Number of processes.\n        m (int): Message size in bytes.\n        S (int): Global buffer size in bytes.\n\n    Returns:\n        bool: True if deadlock occurs, False otherwise.\n    \"\"\"\n    # States: 0=SEND, 1=RECEIVE, 2=DONE\n    process_states = [0] * n\n    inboxes = [[] for _ in range(n)]\n    buffer_size = S\n    \n    # Handle the trivial case where no process can ever send.\n    if S  m:\n        return True\n\n    while True:\n        num_done = sum(1 for state in process_states if state == 2)\n        if num_done == n:\n            return False  # Success, all processes are done\n\n        progress_in_sweep = False\n        for i in range(n):\n            state = process_states[i]\n\n            if state == 0:  # SEND\n                if buffer_size >= m:\n                    buffer_size -= m\n                    successor = (i + 1) % n\n                    inboxes[successor].append(1)  # Message content is irrelevant\n                    process_states[i] = 1\n                    progress_in_sweep = True\n            \n            elif state == 1:  # RECEIVE\n                if len(inboxes[i]) > 0:\n                    inboxes[i].pop(0)\n                    buffer_size += m\n                    process_states[i] = 2\n                    progress_in_sweep = True\n        \n        if not progress_in_sweep:\n            # If no progress was made, check if we are done or deadlocked.\n            # The check for all_done is at the start of the loop.\n            # So if we are here with no progress, it must be a deadlock.\n            return True  # Deadlock\n\ndef solve():\n    \"\"\"\n    Runs the simulation for all test cases and prints the results.\n    \"\"\"\n    test_cases = [\n        # (n, m, S)\n        (2, 10, 10),\n        (2, 10, 20),\n        (3, 8, 8),\n        (4, 8, 15),\n        (5, 7, 35),\n    ]\n\n    results = []\n    for n, m, S in test_cases:\n        # Run original simulation\n        b_orig = simulate(n, m, S)\n        results.append(b_orig)\n\n        # Determine S_fix and run fixed simulation\n        # As derived, the minimal buffer size to avoid deadlock for n >= 2\n        # is 2*m, as this ensures at least two processes can send,\n        # allowing the second one to eventually receive and replenish the buffer.\n        S_fix = 2 * m\n        b_fix = simulate(n, m, S_fix)\n        results.append(b_fix)\n\n    # Format output as a single line: \"[True,False,True,...]\"\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "2413727"}, {"introduction": "The master-worker pattern is a cornerstone of task-based parallelism, widely used for distributing independent jobs across a pool of computational resources. This practice involves building a discrete-event simulation to model such a system, focusing on the dynamics of non-blocking sends and asynchronous task completion. By calculating the total makespan under varying conditions, you will explore how network performance, characterized by latency and bandwidth, interacts with computation time to determine overall efficiency [@problem_id:2413700].", "problem": "Implement a discrete-event simulation of a master/worker computation to study message passing and communication patterns. The master assigns independent tasks to a fixed pool of workers using non-blocking sends. Each task consists of a request message from the master to a worker, a computation on the worker, and a result message from the worker back to the master. The master does not block on sends; it can post multiple sends at the same simulation time instant. Workers process at most one task at a time and immediately become idle upon finishing computation; result messages do not delay a worker’s availability. Your goal is to compute the total completion time (makespan) for a set of given scenarios.\n\nFundamental base and assumptions:\n- Use the standard definitions from message passing systems such as Message Passing Interface (MPI). In particular, a non-blocking send returns control to the caller immediately without waiting for message transfer to complete. We model the network transfer time using a fixed latency and a bandwidth term.\n- Let $L$ be the one-way latency in seconds, $B$ be the bandwidth in bytes per second, and $s$ be the message size in bytes. The one-way transfer time is\n$$\nT(s) = L + \\frac{s}{B},\n$$\nwith the convention that if $B = \\infty$ then $\\frac{s}{B} = 0$.\n- For each task $i$ with worker compute time $c_i$ (in seconds), there is a request message of size $s_\\mathrm{req}$ sent from master to worker before computation, and a result message of size $s_\\mathrm{resp}$ sent from worker to master after computation. Thus, if a task is assigned to a worker at time $t$, it starts computing at time $t + T(s_\\mathrm{req})$ and finishes computing at time $t + T(s_\\mathrm{req}) + c_i$. Its result reaches the master at time $t + T(s_\\mathrm{req}) + c_i + T(s_\\mathrm{resp})$.\n- The master uses non-blocking sends. As soon as a worker is idle and there is a pending task, at that exact simulation time the master posts a send to that worker. The send does not block the master, and the assignment time is the moment the worker becomes idle. The worker’s availability is not delayed by sending its result because the worker’s send is assumed non-blocking.\n- Workers process at most one task at a time. The master begins by assigning up to $\\min(W, N)$ tasks at time $t=0$, where $W$ is the number of workers and $N$ is the number of tasks. There is no preemption.\n\nQuantities to compute:\n- For each scenario, compute the makespan $T_\\mathrm{end}$, defined as the time when the master has received the last result message. Formally,\n$$\nT_\\mathrm{end} = \\max_{i=1,\\dots,N} \\left( t_i^\\mathrm{assign} + T(s_\\mathrm{req}) + c_i + T(s_\\mathrm{resp}) \\right),\n$$\nwhere $t_i^\\mathrm{assign}$ is the time the master assigns task $i$ to some worker (determined by the event-driven schedule described above).\n\nAlgorithmic requirement:\n- Implement a discrete-event simulation based on the above definitions. A correct and efficient approach is to simulate worker availability using a priority queue keyed by each worker’s next compute-completion time, posting new assignments at the exact times workers become idle. You must not rely on any external libraries for message passing; this is a pure simulation.\n\nUnits and numerical specification:\n- All times must be expressed in seconds.\n- All message sizes must be expressed in bytes.\n- All bandwidths must be expressed in bytes per second.\n- Your program must output each makespan in seconds, rounded to six decimal places.\n\nTest suite:\nFor each test case, specify $(W, \\{c_i\\}, L, B, s_\\mathrm{req}, s_\\mathrm{resp})$ and compute $T_\\mathrm{end}$.\n\n- Test 1 (general case):\n  - $W = 3$\n  - $\\{c_i\\} = [2.0, 3.0, 7.0, 1.0, 4.0]$ (seconds)\n  - $L = 0.1$ (seconds)\n  - $B = 10^6$ (bytes/second)\n  - $s_\\mathrm{req} = 1000$ (bytes)\n  - $s_\\mathrm{resp} = 1000$ (bytes)\n- Test 2 (boundary with zero communication cost):\n  - $W = 1$\n  - $\\{c_i\\} = [1.0, 2.0, 3.0]$ (seconds)\n  - $L = 0.0$ (seconds)\n  - $B = \\infty$ (bytes/second)\n  - $s_\\mathrm{req} = 100$ (bytes)\n  - $s_\\mathrm{resp} = 100$ (bytes)\n- Test 3 (latency-dominated micro-tasks):\n  - $W = 2$\n  - $\\{c_i\\} = [0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05]$ (seconds)\n  - $L = 0.2$ (seconds)\n  - $B = 10^6$ (bytes/second)\n  - $s_\\mathrm{req} = 100$ (bytes)\n  - $s_\\mathrm{resp} = 100$ (bytes)\n- Test 4 (many workers, few tasks):\n  - $W = 10$\n  - $\\{c_i\\} = [5.0, 1.0, 2.0]$ (seconds)\n  - $L = 0.05$ (seconds)\n  - $B = 10^6$ (bytes/second)\n  - $s_\\mathrm{req} = 500$ (bytes)\n  - $s_\\mathrm{resp} = 500$ (bytes)\n- Test 5 (bandwidth-dominated messages):\n  - $W = 4$\n  - $\\{c_i\\} = [0.5, 1.5, 0.7, 2.0, 1.2, 0.3, 0.9]$ (seconds)\n  - $L = 0.02$ (seconds)\n  - $B = 2 \\times 10^3$ (bytes/second)\n  - $s_\\mathrm{req} = 4000$ (bytes)\n  - $s_\\mathrm{resp} = 8000$ (bytes)\n\nFinal output format:\n- Your program must produce a single line of output containing the five makespans corresponding to the five tests, as a comma-separated list enclosed in square brackets, for example, $[x_1, x_2, x_3, x_4, x_5]$, where each $x_k$ is the makespan in seconds rounded to six decimal places.\n- Your program must be self-contained, must not read any input, and must not access external files or networks.", "solution": "The problem presented is a valid and well-posed exercise in computational systems modeling. It is a standard formulation of a master-worker parallel computation pattern, grounded in the fundamental principles of discrete-event simulation and network performance modeling. The parameters are clearly defined, the objective function is specified unambiguously, and the scheduling policy is deterministic, which guarantees a unique solution. The problem provides a concrete set of test cases for verification. We will proceed with a solution based on these principles.\n\nThe system dynamics are governed by events, specifically the completion of a computation by a worker. This makes discrete-event simulation the natural and correct approach. We model the system state by tracking the availability of each worker and the queue of tasks yet to be scheduled. The most efficient method to manage worker availability is to use a priority queue, where the priority of each event is its timestamp.\n\nLet $W$ be the number of workers and $N$ be the number of tasks. The compute time for task $i$ is $c_i$. The network is characterized by a one-way latency $L$ and a bandwidth $B$. The size of a request message is $s_\\mathrm{req}$ and a response message is $s_\\mathrm{resp}$. The one-way transfer time for a message of size $s$ is given by the linear model $T(s) = L + s/B$. It is understood that if $B = \\infty$, the term $s/B$ is $0$.\n\nFrom this, we define the request transfer time $T_\\mathrm{req} = T(s_\\mathrm{req})$ and response transfer time $T_\\mathrm{resp} = T(s_\\mathrm{resp})$.\n\nA task assigned at time $t_\\mathrm{assign}$ will begin computation on the worker at time $t_\\mathrm{assign} + T_\\mathrm{req}$. The computation itself takes $c_i$ seconds. Thus, the worker completes the computation at time $t_\\mathrm{finish\\_compute} = t_\\mathrm{assign} + T_\\mathrm{req} + c_i$. Upon completion, the worker is immediately available to be assigned a new task. The result message is then sent, arriving at the master at time $t_\\mathrm{result\\_arrival} = t_\\mathrm{finish\\_compute} + T_\\mathrm{resp}$. The overall objective is to find the makespan, $T_\\mathrm{end}$, which is the time the last result message is received by the master:\n$$\nT_\\mathrm{end} = \\max_{i=1,\\dots,N} \\{t_\\mathrm{result\\_arrival}^{(i)}\\}\n$$\nwhere $t_\\mathrm{result\\_arrival}^{(i)}$ is the arrival time of the result for task $i$.\n\nThe core of our simulation is a priority queue, which we will call `worker_events`. This data structure will store events corresponding to workers finishing their computations. Each element in the queue will be a tuple $(t, w)$, representing that worker $w$ will finish its current computation at time $t$. The priority queue is ordered by time $t$, so we can always efficiently retrieve the next worker that becomes free.\n\nThe simulation proceeds as follows:\n\n1.  **Initialization**:\n    *   Initialize a variable `makespan` to $0$.\n    *   Initialize a queue of unassigned tasks, sequenced in the order they are given. Let `next_task_idx` be the index of the next task to assign.\n    *   At simulation time $t=0$, the master assigns the first $\\min(W, N)$ tasks. For each of these initial tasks $i \\in \\{0, 1, \\dots, \\min(W, N)-1\\}$, assigned to worker $i$:\n        *   The assignment time is $t_i^\\mathrm{assign} = 0$.\n        *   The computation finish time is $t_{i}^\\mathrm{finish\\_compute} = 0 + T_\\mathrm{req} + c_i$.\n        *   Push the event $(t_{i}^\\mathrm{finish\\_compute}, i)$ into the `worker_events` priority queue.\n        *   The result arrival time is $t_{i}^\\mathrm{result\\_arrival} = t_{i}^\\mathrm{finish\\_compute} + T_\\mathrm{resp}$.\n        *   Update `makespan` = $\\max(\\text{makespan}, t_{i}^\\mathrm{result\\_arrival})$.\n    *   Set `next_task_idx` to $\\min(W, N)$.\n\n2.  **Simulation Loop**:\n    *   This loop continues as long as there are tasks remaining to be assigned (i.e., `next_task_idx`  $N$).\n    *   Extract the event with the minimum time from `worker_events`. This gives $(t_\\mathrm{finish}, w_\\mathrm{free})$, the time when worker $w_\\mathrm{free}$ becomes idle.\n    *   The problem states that a new task is assigned to this worker at the exact moment it becomes idle. Therefore, the assignment time for the next task (let its index be $j = \\text{next\\_task\\_idx}$) is $t_j^\\mathrm{assign} = t_\\mathrm{finish}$.\n    *   Schedule this new task $j$ on worker $w_\\mathrm{free}$:\n        *   The new computation finish time for this worker is $t_{j}^\\mathrm{finish\\_compute} = t_j^\\mathrm{assign} + T_\\mathrm{req} + c_j$.\n        *   Push the new event $(t_{j}^\\mathrm{finish\\_compute}, w_\\mathrm{free})$ into the `worker_events` priority queue.\n        *   The result arrival time for task $j$ is $t_{j}^\\mathrm{result\\_arrival} = t_{j}^\\mathrm{finish\\_compute} + T_\\mathrm{resp}$.\n        *   Update `makespan` = $\\max(\\text{makespan}, t_{j}^\\mathrm{result\\_arrival})$.\n    *   Increment `next_task_idx`.\n\n3.  **Termination**:\n    *   The loop terminates when `next_task_idx` reaches $N$, meaning all tasks have been scheduled. The final value held by the `makespan` variable is the maximum of all result arrival times, which is precisely the definition of $T_\\mathrm{end}$.\n\nThis algorithm correctly models the specified system and will be implemented to solve for the given test cases. Python's `heapq` module provides a suitable implementation of a min-priority queue.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nimport heapq\n\ndef solve():\n    \"\"\"\n    Main function to run the simulation for all test cases and print results.\n    \"\"\"\n    # Test cases defined as tuples:\n    # (W, {c_i}, L, B, s_req, s_resp)\n    test_cases = [\n        # Test 1 (general case)\n        (3, [2.0, 3.0, 7.0, 1.0, 4.0], 0.1, 1e6, 1000, 1000),\n        # Test 2 (boundary with zero communication cost)\n        (1, [1.0, 2.0, 3.0], 0.0, np.inf, 100, 100),\n        # Test 3 (latency-dominated micro-tasks)\n        (2, [0.05] * 10, 0.2, 1e6, 100, 100),\n        # Test 4 (many workers, few tasks)\n        (10, [5.0, 1.0, 2.0], 0.05, 1e6, 500, 500),\n        # Test 5 (bandwidth-dominated messages)\n        (4, [0.5, 1.5, 0.7, 2.0, 1.2, 0.3, 0.9], 0.02, 2e3, 4000, 8000),\n    ]\n\n    results = []\n    for case in test_cases:\n        makespan = simulate_master_worker(*case)\n        results.append(f\"{makespan:.6f}\")\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(results)}]\")\n\ndef simulate_master_worker(W, c_tasks, L, B, s_req, s_resp):\n    \"\"\"\n    Implements a discrete-event simulation of a master/worker computation.\n\n    Args:\n        W (int): Number of workers.\n        c_tasks (list[float]): List of compute times for each task.\n        L (float): One-way network latency in seconds.\n        B (float): Network bandwidth in bytes per second.\n        s_req (float): Request message size in bytes.\n        s_resp (float): Response message size in bytes.\n\n    Returns:\n        float: The total completion time (makespan) in seconds.\n    \"\"\"\n    num_tasks = len(c_tasks)\n    if num_tasks == 0:\n        return 0.0\n\n    # Calculate one-way transfer times for request and response messages\n    if B == np.inf:\n        t_req = L\n        t_resp = L\n    else:\n        t_req = L + s_req / B\n        t_resp = L + s_resp / B\n\n    # Priority queue stores events of workers finishing computation.\n    # Each item is a tuple: (finish_compute_time, worker_id).\n    worker_events = []\n    \n    # Track the overall makespan (time last result is received by master).\n    makespan = 0.0\n    \n    # Index for the next task to be assigned from the c_tasks list.\n    next_task_idx = 0\n\n    # Initial phase: Assign tasks to all available workers at time t=0.\n    num_initial_tasks = min(W, num_tasks)\n    for i in range(num_initial_tasks):\n        c_i = c_tasks[i]\n        worker_id = i\n        \n        # Assignment time is 0 for the initial batch of tasks.\n        t_assign = 0.0\n        \n        # A worker finishes its computation at t_assign + network_delay + compute_time.\n        finish_compute_time = t_assign + t_req + c_i\n        \n        # The result for this task arrives at the master after the response message is sent.\n        result_arrival_time = finish_compute_time + t_resp\n        \n        # Update the makespan with the latest result arrival.\n        makespan = max(makespan, result_arrival_time)\n        \n        # Add a \"worker free\" event to the priority queue.\n        heapq.heappush(worker_events, (finish_compute_time, worker_id))\n        \n        next_task_idx += 1\n\n    # Main simulation loop: process events until all tasks are assigned.\n    while next_task_idx  num_tasks:\n        # Get the next worker to become free from the priority queue.\n        # This event defines the current simulation time for the new assignment.\n        finish_compute_time, worker_id = heapq.heappop(worker_events)\n        \n        # The worker becomes free at finish_compute_time. This is the assignment\n        # time for the next task scheduled on this worker.\n        t_assign = finish_compute_time\n        \n        # Get the compute time for the next task in the queue.\n        c_i = c_tasks[next_task_idx]\n        \n        # Schedule the new task on the now-free worker.\n        new_finish_compute_time = t_assign + t_req + c_i\n        new_result_arrival_time = new_finish_compute_time + t_resp\n        \n        # Update the overall makespan.\n        makespan = max(makespan, new_result_arrival_time)\n        \n        # Add the new event for this worker finishing its new task.\n        heapq.heappush(worker_events, (new_finish_compute_time, worker_id))\n        \n        next_task_idx += 1\n        \n    return makespan\n\nif __name__ == '__main__':\n    solve()\n```", "id": "2413700"}, {"introduction": "Efficient collective operations like $MPI\\_Allreduce$ are the backbone of many large-scale scientific simulations, but they are ultimately built from simple point-to-point messages. This exercise demystifies this process by having you implement a sum-based all-reduce operation using a highly efficient recursive doubling algorithm [@problem_id:2413720]. Simulating this pattern, which maps to a hypercube communication topology, will provide deep insight into how scalable data aggregation is achieved in modern parallel computing.", "problem": "You are given a computational model of the Message Passing Interface (MPI), restricted to point-to-point operations. Consider a set of $P$ logical processes with ranks $r \\in \\{0,1,\\dots,P-1\\}$, where $P$ is a power of $2$. Each process $r$ initially holds a single integer value $x_r$. The processes execute in synchronous rounds indexed by $k \\in \\{0,1,\\dots,R-1\\}$, where $R=\\log_2 P$. In each round $k$, process $r$ is allowed to perform exactly one point-to-point send and one point-to-point receive. The permitted communication partner in round $k$ for process $r$ is the process $r \\oplus 2^k$, where $\\oplus$ denotes bitwise exclusive-or. The communication in round $k$ is defined as: process $r$ must send its current integer to process $r \\oplus 2^k$, and must receive an integer from process $r \\oplus 2^k$. After the receive completes in round $k$, process $r$ must update its current integer by summing it with the received integer using integer addition.\n\nAfter $R$ rounds, the final integer at each process is required to equal the global sum $S=\\sum_{i=0}^{P-1} x_i$. The number of point-to-point messages is defined to be the total number of sends across all processes and all rounds. Under the above constraints, the total number of rounds is $R=\\log_2 P$, and in each round exactly $P$ sends occur, so the expected total number of messages is $P \\log_2 P$.\n\nYour task is to write a complete program that simulates the above model exactly as stated and, for each test case in the test suite below, returns a boolean that is true if and only if both of the following conditions hold: (i) every process holds the correct final integer $S$ after the final round, and (ii) the total number of point-to-point messages equals $P \\log_2 P$. Otherwise, return false for that test case.\n\nTest suite:\n- Case A: $P=1$, initial values $[42]$. Expected $R=\\log_2 1=0$ rounds and $P \\log_2 P = 1 \\cdot 0 = 0$ messages.\n- Case B: $P=2$, initial values $[5,-3]$. Expected $R=\\log_2 2 = 1$ round and $P \\log_2 P = 2 \\cdot 1 = 2$ messages.\n- Case C: $P=4$, initial values $[-10,20,0,5]$. Expected $R=\\log_2 4 = 2$ rounds and $P \\log_2 P = 4 \\cdot 2 = 8$ messages.\n- Case D: $P=8$, initial values $[1,2,3,4,5,6,7,8]$. Expected $R=\\log_2 8 = 3$ rounds and $P \\log_2 P = 8 \\cdot 3 = 24$ messages.\n\nFinal output format:\nYour program should produce a single line of output containing the results for the four test cases as a comma-separated list of booleans enclosed in square brackets, with no spaces, in the order A, B, C, D. For example, if all four conditions are satisfied, output the single line \"[True,True,True,True]\".", "solution": "The problem statement has been subjected to rigorous validation and is found to be valid.\n\n**Step 1: Extract Givens**\n\n- A set of $P$ logical processes with ranks $r \\in \\{0, 1, \\dots, P-1\\}$.\n- $P$ is a power of $2$.\n- Each process $r$ has an initial integer value $x_r$.\n- The simulation proceeds in synchronous rounds indexed by $k \\in \\{0, 1, \\dots, R-1\\}$, where $R=\\log_2 P$.\n- In each round $k$, process $r$ performs one send to and one receive from process $r \\oplus 2^k$, where $\\oplus$ is the bitwise exclusive-or operator.\n- The update rule for process $r$ after receiving a value in round $k$ is to sum its current integer with the received integer.\n- The final condition requires that after $R$ rounds, every process $r$ holds the global sum $S=\\sum_{i=0}^{P-1} x_i$.\n- The number of point-to-point messages is the total number of sends across all processes and all rounds. The expected total is $P \\log_2 P$.\n- The task is to return a boolean for each test case, which is true if and only if both the final value condition and the total message count condition are met.\n- Test Cases:\n  - A: $P=1$, initial values $[42]$.\n  - B: $P=2$, initial values $[5,-3]$.\n  - C: $P=4$, initial values $[-10,20,0,5]$.\n  - D: $P=8$, initial values $[1,2,3,4,5,6,7,8]$.\n\n**Step 2: Validate Using Extracted Givens**\n\n- **Scientific Grounding**: The problem describes a well-known parallel algorithm, specifically an all-reduce operation on a hypercube topology. The processes and their ranks can be viewed as vertices of a $d$-dimensional hypercube, where $d = \\log_2 P$. The communication partner rule, $r \\leftrightarrow r \\oplus 2^k$, defines communication along the $k$-th dimension of this hypercube. The specified update rule is the standard procedure for a prefix sum-based all-reduce operation. The problem is scientifically and algorithmically sound.\n- **Well-Posedness**: The initial state, communication rules, and update rules are deterministic. For any given input, the final state of the system is unique. The verification criteria are objective and quantifiable.\n- **Completeness and Consistency**: The problem is self-contained. All necessary parameters ($P$, initial values) and rules are provided. The definitions are precise. The special case $P=1$ implies $R=\\log_2 1 = 0$ rounds and $P \\log_2 P = 0$ messages, which is mathematically consistent and correctly handled by a zero-iteration loop. There are no contradictions.\n\n**Step 3: Verdict and Action**\n\nThe problem is valid. It is a well-posed, scientifically grounded problem that asks for the simulation and verification of a standard parallel algorithm. A solution will be provided.\n\n**Solution Design**\n\nThe problem requires a direct simulation of the described message-passing model. The core of the solution is to accurately model the state of $P$ processes over $R = \\log_2 P$ synchronous rounds.\n\nThe state of the system at any point can be represented by a vector (an array) of $P$ integers, which we can denote as $\\mathbf{x}$. Initially, this vector is $\\mathbf{x}[0] = [x_0, x_1, \\dots, x_{P-1}]$.\n\nThe simulation proceeds iteratively for each round $k$ from $0$ to $R-1$. A critical aspect of a synchronous model is that all communications within a round are based on the state at the beginning of that round. Therefore, updates must not be applied \"in-place\", as this would create a data race where a process might use a value that has already been updated within the same round. To prevent this, a temporary buffer or a second vector, say $\\mathbf{x}'$, is required to store the results of the current round's computations.\n\nFor each round $k \\in \\{0, 1, \\dots, R-1\\}$:\n1. Initialize a temporary vector $\\mathbf{x}'$ to hold the values for the next round.\n2. For each process $r \\in \\{0, 1, \\dots, P-1\\}$:\n   a. Identify the communication partner: $p = r \\oplus 2^k$.\n   b. The value received by process $r$ from process $p$ is the value $p$ held at the beginning of the round, i.e., $x_p[k]$.\n   c. The new value for process $r$ is computed according to the update rule: $x'_r = x_r[k] + x_p[k]$.\n3. After all processes have been updated, the state for the next round, $\\mathbf{x}[k+1]$, is set to the computed temporary vector $\\mathbf{x}'$.\n\nThis iterative process is repeated for $R = \\log_2 P$ rounds.\n\nThe total number of point-to-point messages is also tracked. In each of the $R$ rounds, every one of the $P$ processes performs exactly one send operation. Thus, each round contributes $P$ messages to the total count. Over $R$ rounds, the total number of messages is $P \\times R = P \\log_2 P$, which matches the expectation stated in the problem.\n\nAfter completion of all $R$ rounds, two conditions must be verified:\n1. **Final Value Condition**: The final value in every process, $x_r[R]$, must be equal to the global sum $S = \\sum_{i=0}^{P-1} x_i[0]$. This check is performed by calculating $S$ from the initial values and comparing it against every element of the final state vector $\\mathbf{x}[R]$.\n2. **Message Count Condition**: The accumulated total number of messages must be equal to the theoretical value $P \\log_2 P$.\n\nA test case evaluates to true if and only if both conditions are satisfied. The simulation will be implemented to run for each of the provided test cases.", "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Simulates a message passing model and verifies the outcome against specified conditions.\n    \"\"\"\n    test_cases = [\n        # Case A\n        (1, [42]),\n        # Case B\n        (2, [5, -3]),\n        # Case C\n        (4, [-10, 20, 0, 5]),\n        # Case D\n        (8, [1, 2, 3, 4, 5, 6, 7, 8]),\n    ]\n    \n    results = []\n\n    for case in test_cases:\n        P, initial_x = case\n        \n        # Use 64-bit integers to avoid overflow with large sums, although\n        # Python's native integers have arbitrary precision. Numpy is used\n        # for convenience and adherence to problem constraints.\n        values = np.array(initial_x, dtype=np.int64)\n        \n        # Calculate the number of rounds, R = log2(P).\n        # For P=1, log2(1)=0, so R=0 rounds.\n        # This is safe because P is guaranteed to be a power of 2.\n        R = 0\n        if P > 1:\n            R = int(np.log2(P))\n\n        total_messages = 0\n        \n        # Simulate R synchronous rounds.\n        for k in range(R):\n            # A temporary array is necessary to store the results of the synchronous round\n            # to prevent data races (i.e., using a value updated in the same round).\n            next_values = np.zeros_like(values)\n            \n            for r in range(P):\n                # Determine the communication partner in round k.\n                # The partner is r XOR 2^k. (1  k) is a fast way to compute 2^k.\n                partner = r ^ (1  k)\n                \n                # Each process r sends its current value to its partner and receives\n                # the partner's value. The new value is the sum of its own old value\n                # and the received value.\n                # Note: values[partner] refers to the value at the start of the round.\n                received_value = values[partner]\n                next_values[r] = values[r] + received_value\n            \n            # After all processes compute their next value, update the state for the next round.\n            values = next_values\n            \n            # In each round, P processes each perform one send.\n            total_messages += P\n\n        # --- Verification ---\n\n        # Condition 1: Verify all processes hold the correct global sum.\n        expected_sum = np.sum(np.array(initial_x, dtype=np.int64))\n        final_values_correct = np.all(values == expected_sum)\n        \n        # Condition 2: Verify the total number of messages.\n        expected_messages = P * R\n        message_count_correct = (total_messages == expected_messages)\n        \n        # The result is True if and only if both conditions are met.\n        result = final_values_correct and message_count_correct\n        results.append(result)\n\n    # Format the final output as specified: a comma-separated list of booleans.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n\n```", "id": "2413720"}]}