{"hands_on_practices": [{"introduction": "We often learn that an iterative linear process $\\mathbf{x}_{k+1} = M \\mathbf{x}_k$ is stable if the eigenvalues of the matrix $M$ are all within the unit circle. This practice challenges that simple picture by exploring the phenomenon of transient growth in non-normal systems. You will construct and simulate a system [@problem_id:2437705] that is guaranteed to be stable in the long run, yet exhibits significant initial growth, demonstrating that short-term behavior can be dramatically different from the ultimate asymptotic fate.", "problem": "You are given a family of discrete-time linear iterative processes on the two-dimensional real vector space defined by the recurrence\n$$\n\\mathbf{x}_{k+1} = M \\,\\mathbf{x}_{k},\n$$\nwhere\n$$\nM = \\begin{bmatrix}\nr & L\\\\\n0 & r\n\\end{bmatrix},\n$$\nwith parameters $r \\in (0,1)$ and $L \\ge 0$, and an initial state $\\mathbf{x}_0 \\in \\mathbb{R}^2$. For each process, define the Euclidean norm sequence\n$$\nn_k = \\|\\mathbf{x}_k\\|_2\n$$\nfor integer iterates $k \\ge 0$. Convergence is understood as $\\lim_{k \\to \\infty} \\mathbf{x}_k = \\mathbf{0}$, and in computation is detected when $n_k \\le \\text{tol}$ for a prescribed tolerance $\\text{tol} > 0$.\n\nYour task is to write a complete, runnable program that, for each specified parameter set, simulates the recurrence and reports quantitative indicators of its stability and transient behavior. For each parameter set, your program must compute the following quantities:\n\n- A boolean value $B$ indicating whether the norm is strictly increasing for the first $N_{\\mathrm{inc}}$ steps, that is, whether the property $n_k > n_{k-1}$ holds for all integers $k$ with $1 \\le k \\le N_{\\mathrm{inc}}$. If the process reaches the convergence threshold before $N_{\\mathrm{inc}}$ steps, then treat this property as false.\n- An integer $k_{\\mathrm{conv}}$, the smallest integer $k \\ge 0$ such that $n_k \\le \\text{tol}$. If such an integer does not exist within the prescribed iteration budget, report $k_{\\mathrm{conv}} = -1$.\n- An integer $k_{\\mathrm{peak}}$ at which the maximum norm\n$$\nn_{\\max} = \\max \\{ n_k : 0 \\le k \\le k_{\\mathrm{end}} \\}\n$$\nis attained, where $k_{\\mathrm{end}} = k_{\\mathrm{conv}}$ if $k_{\\mathrm{conv}} \\ne -1$, and $k_{\\mathrm{end}} = K_{\\max}$ otherwise, with $K_{\\max}$ the maximum number of iterations allowed. If there are multiple indices attaining the maximum, report the smallest such index.\n- A floating-point number $n_{\\max}$ as defined above.\n\nYour program must use the following test suite of parameter sets. In each case, the iteration must start from\n$$\n\\mathbf{x}_0 = \\begin{bmatrix} 1.0 \\\\ 1.0 \\end{bmatrix},\n$$\nand the Euclidean norm is used. The convergence tolerance is $\\text{tol} = 10^{-6}$ (dimensionless), and the angle unit is not applicable. For each test case, simulate up to a maximum of $K_{\\max}$ iterations as specified.\n\nTest Suite:\n- Case $1$: $r = 0.99$, $L = 100.0$, $N_{\\mathrm{inc}} = 100$, $K_{\\max} = 10000$.\n- Case $2$: $r = 0.99$, $L = 0.0$, $N_{\\mathrm{inc}} = 100$, $K_{\\max} = 10000$.\n- Case $3$: $r = 0.995$, $L = 100.0$, $N_{\\mathrm{inc}} = 100$, $K_{\\max} = 20000$.\n- Case $4$: $r = 0.9$, $L = 1000.0$, $N_{\\mathrm{inc}} = 100$, $K_{\\max} = 2000$.\n\nFinal output format:\nYour program should produce a single line of output containing the results for the test cases, in order, as a comma-separated list enclosed in square brackets, where each test case result is itself a list in the format\n$$\n[B, k_{\\mathrm{conv}}, k_{\\mathrm{peak}}, n_{\\max}],\n$$\nwith $B$ a boolean, $k_{\\mathrm{conv}}$ and $k_{\\mathrm{peak}}$ integers, and $n_{\\max}$ a floating-point number. For example, an output for two cases could look like\n$$\n[[\\text{True}, 1234, 100, 3.14159],[\\text{False}, -1, 57, 2.71828]].\n$$", "solution": "The problem as stated is valid. It is a well-posed, self-contained, and scientifically grounded exercise in the analysis of linear discrete-time systems, a fundamental topic in computational engineering and applied mathematics. All parameters and conditions are specified with sufficient precision to allow for a unique and verifiable solution.\n\nThe problem investigates the stability and transient behavior of the iterative process $\\mathbf{x}_{k+1} = M \\mathbf{x}_{k}$, where the matrix $M$ is given by\n$$\nM = \\begin{bmatrix}\nr & L\\\\\n0 & r\n\\end{bmatrix}.\n$$\nThis matrix has a repeated eigenvalue $\\lambda = r$. Since the problem specifies $r \\in (0,1)$, the spectral radius of the matrix is $\\rho(M) = r < 1$. This condition guarantees that the system is asymptotically stable, meaning $\\lim_{k \\to \\infty} M^k = \\mathbf{0}$ and consequently $\\lim_{k \\to \\infty} \\mathbf{x}_k = \\mathbf{0}$ for any initial state $\\mathbf{x}_0$.\n\nHowever, for $L > 0$, the matrix $M$ is not normal, as $MM^T \\neq M^T M$. A key property of non-normal systems is their capacity for transient growth, where the norm of the state vector, $n_k = \\|\\mathbf{x}_k\\|_2$, can increase for a period before the eventual asymptotic decay takes effect. This phenomenon is critical in many engineering applications where temporary large excursions can lead to system failure, even if the system is theoretically stable.\n\nTo analyze this behavior, we can derive a closed-form expression for $\\mathbf{x}_k$. The matrix $M$ can be decomposed as $M = rI + N$, where $I$ is the $2 \\times 2$ identity matrix and $N$ is a nilpotent matrix:\n$$\nN = \\begin{bmatrix}\n0 & L\\\\\n0 & 0\n\\end{bmatrix}, \\quad N^2 = \\mathbf{0}.\n$$\nUsing the binomial theorem, we find the $k$-th power of $M$:\n$$\nM^k = (rI + N)^k = \\binom{k}{0} (rI)^k N^0 + \\binom{k}{1} (rI)^{k-1} N^1 + \\dots = r^k I + k r^{k-1} N.\n$$\nExplicitly, this is:\n$$\nM^k = \\begin{bmatrix}\nr^k & k r^{k-1} L \\\\\n0 & r^k\n\\end{bmatrix}.\n$$\nFor the initial state $\\mathbf{x}_0 = [1.0, 1.0]^T$, the state vector at iterate $k$ is:\n$$\n\\mathbf{x}_k = M^k \\mathbf{x}_0 = \\begin{bmatrix}\nr^k & k r^{k-1} L \\\\\n0 & r^k\n\\end{bmatrix}\n\\begin{bmatrix}\n1.0 \\\\\n1.0\n\\end{bmatrix}\n=\n\\begin{bmatrix}\nr^k + k r^{k-1} L \\\\\nr^k\n\\end{bmatrix}.\n$$\nThe squared Euclidean norm, $n_k^2 = \\|\\mathbf{x}_k\\|_2^2$, is therefore:\n$$\nn_k^2 = (r^k + k r^{k-1} L)^2 + (r^k)^2 = r^{2k} \\left( \\left(1 + \\frac{kL}{r}\\right)^2 + 1 \\right).\n$$\nThis expression demonstrates the competition between the polynomial growth term, which is dominated by $(kL/r)^2$, and the exponential decay term $r^{2k}$. For $L>0$ and $r$ close to $1$, the polynomial term can cause $n_k$ to increase initially, creating the transient growth.\n\nWhile this analytical form provides a complete theoretical understanding, the problem requires a direct numerical simulation to find the specified quantitative indicators. The following algorithm is implemented to solve the problem for each test case.\n\n**Algorithm:**\nFor a given set of parameters $(r, L, N_{\\mathrm{inc}}, K_{\\max})$, tolerance $\\text{tol}$, and initial state $\\mathbf{x}_0$:\n\n1.  **Initialization**:\n    - Set the iteration counter $k = 0$.\n    - Initialize the state vector $\\mathbf{x} \\leftarrow \\mathbf{x}_0$.\n    - Compute the initial norm $n_0 = \\|\\mathbf{x}\\|_2$.\n    - Initialize a list of norms, `norm_history`, with $n_0$.\n    - Initialize maximum norm $n_{\\max} \\leftarrow n_0$ and peak index $k_{\\mathrm{peak}} \\leftarrow 0$.\n    - Initialize convergence index $k_{\\mathrm{conv}} \\leftarrow -1$.\n    - Initialize a boolean flag `is_strictly_increasing` to `True`. This flag tracks if $n_k > n_{k-1}$ for $1 \\le k \\le N_{\\mathrm{inc}}$.\n\n2.  **Iteration**: Loop for $k$ from $1$ to $K_{\\max}$:\n    a. Update the state: $\\mathbf{x} \\leftarrow M \\mathbf{x}$.\n    b. Compute the new norm $n_k = \\|\\mathbf{x}\\|_2$ and record it.\n    c. Check for strict increase: If $k \\le N_{\\mathrm{inc}}$ and $n_k \\le n_{k-1}$, set `is_strictly_increasing` to `False`.\n    d. Update peak values: If $n_k > n_{\\max}$, update $n_{\\max} \\leftarrow n_k$ and $k_{\\mathrm{peak}} \\leftarrow k$.\n    e. Check for convergence: If $n_k \\le \\text{tol}$, set $k_{\\mathrm{conv}} \\leftarrow k$ and terminate the loop.\n\n3.  **Finalization**: After the loop completes (either by convergence or by reaching $K_{\\max}$):\n    a. Determine the boolean value $B$. According to the problem, $B$ is false if the norm is not strictly increasing over the first $N_{\\mathrm{inc}}$ steps OR if the process converges at or before step $N_{\\mathrm{inc}}$. This is computed as $B = \\text{is\\_strictly\\_increasing} \\land (k_{\\mathrm{conv}} = -1 \\lor k_{\\mathrm{conv}} > N_{\\mathrm{inc}})$. This correctly implements the problem directive.\n    b. The values $k_{\\mathrm{conv}}$, $k_{\\mathrm{peak}}$, and $n_{\\max}$ are taken from the values recorded during the simulation.\n\nThis direct simulation robustly calculates the required quantities for each test case. The final output is an aggregation of the results from all specified test cases.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef run_simulation(r, L, N_inc, K_max, x0, tol):\n    \"\"\"\n    Simulates the linear iterative process and computes stability indicators.\n\n    Args:\n        r (float): Parameter r of the matrix M.\n        L (float): Parameter L of the matrix M.\n        N_inc (int): Number of initial steps to check for norm increase.\n        K_max (int): Maximum number of iterations.\n        x0 (np.ndarray): Initial state vector.\n        tol (float): Convergence tolerance.\n\n    Returns:\n        list: A list containing [B, k_conv, k_peak, n_max].\n    \"\"\"\n    M = np.array([[r, L], [0, r]], dtype=np.float64)\n    x = np.array(x0, dtype=np.float64)\n\n    n_k = np.linalg.norm(x)\n    \n    # Store history of norms to check for increase\n    norm_history = [n_k]\n    \n    n_max = n_k\n    k_peak = 0\n    k_conv = -1\n    \n    is_strictly_increasing = True\n\n    for k in range(1, K_max + 1):\n        x = M @ x\n        n_k = np.linalg.norm(x)\n        norm_history.append(n_k)\n\n        # Check for strict increase property up to N_inc steps\n        if k <= N_inc:\n            if n_k <= norm_history[k - 1]:\n                is_strictly_increasing = False\n        \n        # Update peak norm and its index\n        if n_k > n_max:\n            n_max = n_k\n            k_peak = k\n        \n        # Check for convergence\n        if n_k <= tol:\n            k_conv = k\n            break\n\n    # Determine the final boolean value B\n    # B is True iff the norm is strictly increasing for the first N_inc steps\n    # AND the process does not converge within N_inc steps.\n    converged_early = (k_conv != -1 and k_conv <= N_inc)\n    B = is_strictly_increasing and not converged_early\n\n    return [B, k_conv, k_peak, n_max]\n\ndef solve():\n    \"\"\"\n    Main function to run the test suite and print results.\n    \"\"\"\n    # Common parameters for all test cases\n    x0 = [1.0, 1.0]\n    tol = 1e-6\n\n    # Test suite from the problem statement\n    test_cases = [\n        # Case 1: r, L, N_inc, K_max\n        (0.99, 100.0, 100, 10000),\n        # Case 2\n        (0.99, 0.0, 100, 10000),\n        # Case 3\n        (0.995, 100.0, 100, 20000),\n        # Case 4\n        (0.9, 1000.0, 100, 2000),\n    ]\n\n    results = []\n    for case in test_cases:\n        r, L, N_inc, K_max = case\n        result = run_simulation(r, L, N_inc, K_max, x0, tol)\n        results.append(result)\n\n    # Final print statement in the exact required format.\n    # The string representation of a list in Python matches the desired format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "2437705"}, {"introduction": "The stability of an iterative process often has direct, physical implications. In this practice, you will use the Forward Euler method, a fundamental numerical algorithm, to simulate a predator-prey ecosystem described by the Lotka-Volterra equations. You will discover firsthand [@problem_id:2437681] how the choice of the iteration time step $h$ is critical; a step that is too large can cause the simulation to become unstable, yielding unphysical results like negative populations.", "problem": "Consider the classical predator-prey dynamics modeled by the Lotka–Volterra ordinary differential equations (ODE): \n$$\n\\begin{aligned}\n\\frac{dx}{dt} &= a\\,x - b\\,x\\,y,\\\\\n\\frac{dy}{dt} &= -c\\,y + d\\,x\\,y,\n\\end{aligned}\n$$\nwhere $x$ denotes the prey population, $y$ denotes the predator population, and $a,b,c,d$ are strictly positive real parameters. Define the Forward Euler iterative process with time step $h>0$ over a time horizon $T>0$ by the recurrence\n$$\n\\begin{aligned}\nx_{n+1} &= x_n + h\\left(a\\,x_n - b\\,x_n\\,y_n\\right) = x_n\\left(1 + h(a - b\\,y_n)\\right),\\\\\ny_{n+1} &= y_n + h\\left(-c\\,y_n + d\\,x_n\\,y_n\\right) = y_n\\left(1 + h(-c + d\\,x_n)\\right),\n\\end{aligned}\n$$\nfor integer indices $n=0,1,\\dots,N-1$ with $N=T/h$ assumed to be an integer, and initial conditions $x_0>0$, $y_0>0$. In this discrete-time setting, negative values for $x_n$ or $y_n$ represent physically impossible negative populations and are interpreted as numerical instability caused by an excessively large time step $h$.\n\nFor each test case below, simulate the Forward Euler recurrence from $n=0$ to $n=N$, inclusive of both endpoints, using the specified parameters and initial conditions. For each simulation, determine:\n- a boolean flag indicating whether any strictly negative population was encountered at any iterate (i.e., whether there exists an index $n$ such that $x_n<0$ or $y_n<0$),\n- the minimum value of $\\{x_n\\}_{n=0}^N$,\n- the minimum value of $\\{y_n\\}_{n=0}^N$.\n\nReport the minimum values rounded to six decimal places using standard rounding rules. No physical units are involved in this task. Angles are not involved. All outputs are unitless real numbers.\n\nUse the same parameter values $a=1$, $b=0.5$, $c=1$, $d=0.5$ for all cases. The test suite consists of four cases designed to probe a typical well-resolved scenario, a boundary condition, and unstable regimes:\n\n- Case $1$ (small step, well-resolved): $x_0=10$, $y_0=5$, $h=0.01$, $T=0.01$.\n- Case $2$ (boundary for prey update factor, first step to zero): $x_0=8$, $y_0=12$, $h=0.2$, $T=0.2$.\n- Case $3$ (large step yielding negative prey immediately): $x_0=8$, $y_0=30$, $h=0.2$, $T=0.2$.\n- Case $4$ (very large step yielding negative predator, and also negative prey): $x_0=0.5$, $y_0=10$, $h=2.0$, $T=2.0$.\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets. Each result is a list with three entries in the order [negativity_flag, min_x, min_y]. For example, a valid output format with four cases is \n$$\n[\\,[\\text{True},-1.234000,0.500000],[\\text{False},0.000000,2.000000],[\\text{False},1.000000,1.000000],[\\text{True},-0.100000,-0.200000]\\,].\n$$", "solution": "The problem statement has been subjected to rigorous validation and is found to be valid. It is a well-posed problem in computational mathematics, specifically the application of a numerical method to a system of ordinary differential equations. All parameters, initial conditions, and procedural steps are defined unambiguously. The problem is scientifically grounded, objective, and self-contained.\n\nThe task is to simulate the Lotka-Volterra predator-prey model using the Forward Euler method. The continuous model is given by the system of ordinary differential equations:\n$$\n\\begin{aligned}\n\\frac{dx}{dt} &= a\\,x - b\\,x\\,y \\\\\n\\frac{dy}{dt} &= -c\\,y + d\\,x\\,y\n\\end{aligned}\n$$\nwhere $x(t)$ is the prey population, $y(t)$ is the predator population, and $a, b, c, d$ are positive real parameters.\n\nThe Forward Euler method discretizes this system with a time step $h > 0$. The populations at time step $n+1$ are computed from the populations at time step $n$ using the following recurrence relations:\n$$\n\\begin{aligned}\nx_{n+1} &= x_n + h(a\\,x_n - b\\,x_n\\,y_n) = x_n\\left(1 + h(a - b\\,y_n)\\right) \\\\\ny_{n+1} &= y_n + h(-c\\,y_n + d\\,x_n\\,y_n) = y_n\\left(1 + h(-c + d\\,x_n)\\right)\n\\end{aligned}\n$$\nThe simulation runs from an initial state $(x_0, y_0)$ for $n=0, 1, \\dots, N-1$, where $N=T/h$ is the total number of steps to reach the time horizon $T$. The populations must remain non-negative, $x_n \\ge 0$ and $y_n \\ge 0$, for all $n$, to be physically meaningful.\n\nNumerical instability, manifesting as negative populations, occurs if the time step $h$ is too large. Given $x_n > 0$ and $y_n > 0$, the conditions to ensure $x_{n+1} \\ge 0$ and $y_{n+1} \\ge 0$ are:\n$$\n\\begin{aligned}\n1 + h(a - b\\,y_n) \\ge 0 \\\\\n1 + h(-c + d\\,x_n) \\ge 0\n\\end{aligned}\n$$\nIf $a - b\\,y_n < 0$, the first condition imposes a stability constraint on the time step: $h \\le \\frac{1}{b\\,y_n - a}$. Similarly, if $-c + d\\,x_n < 0$, the second condition imposes $h \\le \\frac{1}{c - d\\,x_n}$. If these conditions are violated, the Forward Euler scheme may produce unphysical negative results.\n\nThe algorithm for each test case is as follows:\n1. Set the constant parameters: $a=1$, $b=0.5$, $c=1$, $d=0.5$.\n2. For a given case with initial conditions $(x_0, y_0)$ and time parameters $(h, T)$, calculate the number of steps $N = T/h$. For all provided cases, $N=1$.\n3. Generate the population sequences $\\{x_n\\}_{n=0}^N$ and $\\{y_n\\}_{n=0}^N$. Since $N=1$, we compute only $(x_1, y_1)$ from $(x_0, y_0)$.\n4. Analyze the full sequence of iterates $\\{x_0, x_1\\}$ and $\\{y_0, y_1\\}$.\n5. Determine if any value is strictly negative, i.e., $x_1<0$ or $y_1<0$. This sets the boolean flag.\n6. Find the minimum values $\\min\\{x_0, x_1\\}$ and $\\min\\{y_0, y_1\\}$.\n7. Report the results, with minimum values rounded to six decimal places.\n\nLet us carry out the calculations for each case.\n\nCase 1: $x_0=10$, $y_0=5$, $h=0.01$, $T=0.01$. Here $N=1$.\n$x_1 = 10 \\left( 1 + 0.01(1 - 0.5 \\times 5) \\right) = 10 \\left( 1 + 0.01(-1.5) \\right) = 10(0.985) = 9.85$.\n$y_1 = 5 \\left( 1 + 0.01(-1 + 0.5 \\times 10) \\right) = 5 \\left( 1 + 0.01(4) \\right) = 5(1.04) = 5.2$.\nThe sequences are $x = \\{10, 9.85\\}$ and $y = \\{5, 5.2\\}$.\n- Negativity flag: No negative values. `False`.\n- Minimum $x$: $\\min\\{10, 9.85\\} = 9.85$.\n- Minimum $y$: $\\min\\{5, 5.2\\} = 5$.\nResult: $[\\text{False}, 9.850000, 5.000000]$.\n\nCase 2: $x_0=8$, $y_0=12$, $h=0.2$, $T=0.2$. Here $N=1$.\n$x_1 = 8 \\left( 1 + 0.2(1 - 0.5 \\times 12) \\right) = 8 \\left( 1 + 0.2(-5) \\right) = 8(1-1) = 0$.\n$y_1 = 12 \\left( 1 + 0.2(-1 + 0.5 \\times 8) \\right) = 12 \\left( 1 + 0.2(3) \\right) = 12(1.6) = 19.2$.\nThe sequences are $x = \\{8, 0\\}$ and $y = \\{12, 19.2\\}$.\n- Negativity flag: No strictly negative values. `False`.\n- Minimum $x$: $\\min\\{8, 0\\} = 0$.\n- Minimum $y$: $\\min\\{12, 19.2\\} = 12$.\nResult: $[\\text{False}, 0.000000, 12.000000]$.\n\nCase 3: $x_0=8$, $y_0=30$, $h=0.2$, $T=0.2$. Here $N=1$.\n$x_1 = 8 \\left( 1 + 0.2(1 - 0.5 \\times 30) \\right) = 8 \\left( 1 + 0.2(-14) \\right) = 8(1 - 2.8) = 8(-1.8) = -14.4$.\n$y_1 = 30 \\left( 1 + 0.2(-1 + 0.5 \\times 8) \\right) = 30 \\left( 1 + 0.2(3) \\right) = 30(1.6) = 48$.\nThe sequences are $x = \\{8, -14.4\\}$ and $y = \\{30, 48\\}$.\n- Negativity flag: $x_1 = -14.4 < 0$. `True`.\n- Minimum $x$: $\\min\\{8, -14.4\\} = -14.4$.\n- Minimum $y$: $\\min\\{30, 48\\} = 30$.\nResult: $[\\text{True}, -14.400000, 30.000000]$.\n\nCase 4: $x_0=0.5$, $y_0=10$, $h=2.0$, $T=2.0$. Here $N=1$.\n$x_1 = 0.5 \\left( 1 + 2.0(1 - 0.5 \\times 10) \\right) = 0.5 \\left( 1 + 2.0(-4) \\right) = 0.5(1 - 8) = 0.5(-7) = -3.5$.\n$y_1 = 10 \\left( 1 + 2.0(-1 + 0.5 \\times 0.5) \\right) = 10 \\left( 1 + 2.0(-0.75) \\right) = 10(1 - 1.5) = 10(-0.5) = -5$.\nThe sequences are $x = \\{0.5, -3.5\\}$ and $y = \\{10, -5\\}$.\n- Negativity flag: $x_1 = -3.5 < 0$ and $y_1 = -5 < 0$. `True`.\n- Minimum $x$: $\\min\\{0.5, -3.5\\} = -3.5$.\n- Minimum $y$: $\\min\\{10, -5\\} = -5$.\nResult: $[\\text{True}, -3.500000, -5.000000]$.\n\nThe implementation will now follow this precise logic.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Simulates the Lotka-Volterra equations using the Forward Euler method for\n    a given set of test cases and analyzes the stability and population minima.\n    \"\"\"\n    # Define the Lotka-Volterra parameters, constant for all cases.\n    a = 1.0\n    b = 0.5\n    c = 1.0\n    d = 0.5\n\n    # Define the test cases from the problem statement.\n    # Each case is a tuple: (x0, y0, h, T)\n    test_cases = [\n        (10.0, 5.0, 0.01, 0.01),  # Case 1\n        (8.0, 12.0, 0.2, 0.2),    # Case 2\n        (8.0, 30.0, 0.2, 0.2),    # Case 3\n        (0.5, 10.0, 2.0, 2.0),    # Case 4\n    ]\n\n    all_results = []\n    for case in test_cases:\n        x0, y0, h, T = case\n        \n        # Calculate the number of steps. The problem statement guarantees this is an integer.\n        N = int(T / h)\n        \n        # Initialize lists to store the history of populations, including initial values.\n        x_history = [x0]\n        y_history = [y0]\n        \n        # Set current population values.\n        x_n, y_n = x0, y0\n        \n        # Perform the Forward Euler iteration.\n        for _ in range(N):\n            # Calculate the next population values based on the recurrence relations.\n            x_n_plus_1 = x_n * (1 + h * (a - b * y_n))\n            y_n_plus_1 = y_n * (1 + h * (-c + d * x_n))\n            \n            # Append new values to history.\n            x_history.append(x_n_plus_1)\n            y_history.append(y_n_plus_1)\n            \n            # Update current values for the next iteration.\n            x_n, y_n = x_n_plus_1, y_n_plus_1\n            \n        # Analyze the results for the current case.\n        min_x = np.min(x_history)\n        min_y = np.min(y_history)\n        \n        # Check for strictly negative populations.\n        negativity_flag = (min_x < 0) or (min_y < 0)\n        \n        # Store the results for this case.\n        all_results.append([negativity_flag, min_x, min_y])\n\n    # Format the final output string according to the specified format.\n    # [ [flag,min_x,min_y],[flag,min_x,min_y],... ]\n    # with floats formatted to 6 decimal places and no spaces.\n    result_strings = []\n    for res in all_results:\n        flag, mx, my = res\n        # Apply standard rounding to 6 decimal places, then format.\n        mx_fmt = f\"{round(mx, 6):.6f}\"\n        my_fmt = f\"{round(my, 6):.6f}\"\n        # The boolean needs to be capitalized, which str() does by default.\n        result_strings.append(f\"[{str(flag)},{mx_fmt},{my_fmt}]\")\n    \n    # Final print statement in the exact required format.\n    print(f\"[{','.join(result_strings)}]\")\n\nsolve()\n```", "id": "2437681"}, {"introduction": "The principles of stability analysis extend far beyond traditional engineering systems, into fields like economics and game theory. This exercise applies these tools to \"fictitious play,\" an iterative process for finding a game's Nash Equilibrium. By linearizing the dynamics of a game of rock-paper-scissors around its equilibrium point [@problem_id:2437687], you will calculate the spectral radius of the system's Jacobian to determine whether the players' strategies will converge or diverge, illustrating the power of stability theory to analyze complex strategic interactions.", "problem": "Consider the two-player zero-sum game with the row player’s payoff matrix $A \\in \\mathbb{R}^{3 \\times 3}$ and the column player’s payoff matrix $B = -A$, where\n$$\nA \\;=\\; \\begin{pmatrix}\n0 & -1 & 1 \\\\\n1 & 0 & -1 \\\\\n-1 & 1 & 0\n\\end{pmatrix}.\n$$\nLet $x_k \\in \\mathbb{R}^3$ and $y_k \\in \\mathbb{R}^3$ denote the mixed strategies of the row and column players, respectively, at iteration $k$, with each $x_k$ and $y_k$ lying in the probability simplex, that is, each has nonnegative components summing to $1$. Define the Smoothed Fictitious Play (SFP) update with constant step size $\\eta \\in (0,1]$ and inverse temperature $\\beta > 0$ by\n$$\nx_{k+1} \\;=\\; (1-\\eta)\\,x_k \\;+\\; \\eta\\,\\sigma\\!\\left(\\beta A y_k\\right), \n\\qquad\ny_{k+1} \\;=\\; (1-\\eta)\\,y_k \\;+\\; \\eta\\,\\sigma\\!\\left(-\\beta A^{\\top} x_k\\right),\n$$\nwhere $\\sigma:\\mathbb{R}^3\\to\\mathbb{R}^3$ is the softmax map defined componentwise by\n$$\n\\sigma(z)_i \\;=\\; \\frac{\\exp(z_i)}{\\sum_{j=1}^{3}\\exp(z_j)} \\quad \\text{for } i \\in \\{1,2,3\\}.\n$$\nLet $(x^\\star,y^\\star)$ denote the unique symmetric mixed Nash Equilibrium (NE) of this zero-sum game. Linearize the SFP update around $(x^\\star,y^\\star)$ and consider the Jacobian matrix $J(\\beta,\\eta)$ of the full $(x,y)$-update at $(x^\\star,y^\\star)$. For the parameter values $\\beta = 2$ and $\\eta = 1$, compute the spectral radius $\\rho\\!\\left(J(2,1)\\right)$ exactly. Provide a single real number as your final answer in exact form (no rounding).", "solution": "The problem is valid as it is scientifically grounded, well-posed, objective, and contains all necessary information for a unique solution.\n\nThe zero-sum game is defined by the row player's payoff matrix\n$$\nA \\;=\\; \\begin{pmatrix}\n0 & -1 & 1 \\\\\n1 & 0 & -1 \\\\\n-1 & 1 & 0\n\\end{pmatrix}\n$$\nThis matrix corresponds to the game of rock-paper-scissors. The unique symmetric mixed Nash Equilibrium (NE) $(x^\\star, y^\\star)$ is well-known to be the uniform distribution over the three pure strategies for both players.\n$$\nx^\\star \\;=\\; y^\\star \\;=\\; \\begin{pmatrix} 1/3 \\\\ 1/3 \\\\ 1/3 \\end{pmatrix}\n$$\nTo verify, we check the expected payoffs. The row player's expected payoff against $y^\\star$ is $A y^\\star$:\n$$\nA y^\\star \\;=\\; \\begin{pmatrix}\n0 & -1 & 1 \\\\\n1 & 0 & -1 \\\\\n-1 & 1 & 0\n\\end{pmatrix}\n\\begin{pmatrix}\n1/3 \\\\\n1/3 \\\\\n1/3\n\\end{pmatrix}\n\\;=\\; \\begin{pmatrix}\n0 \\\\\n0 \\\\\n0\n\\end{pmatrix}\n$$\nSince the expected payoff is $0$ for each of the row player's pure strategies, any mixed strategy $x$ yields an expected payoff of $x^T (A y^\\star) = 0$. Thus, $x^\\star$ is a best response to $y^\\star$.\nThe game is zero-sum with $B=-A$, and the matrix $A$ is skew-symmetric, i.e., $A^T = -A$. The column player's payoff matrix is $B = -A = A^T$. The column player seeks to minimize $x^T A y$. The expected payoff against $x^\\star$ is $x^{\\star T} A$:\n$$\nx^{\\star T} A \\;=\\; \\begin{pmatrix} 1/3 & 1/3 & 1/3 \\end{pmatrix} \\begin{pmatrix}\n0 & -1 & 1 \\\\\n1 & 0 & -1 \\\\\n-1 & 1 & 0\n\\end{pmatrix} \\;=\\; \\begin{pmatrix} 0 & 0 & 0 \\end{pmatrix}\n$$\nAny mixed strategy $y$ for the column player yields an expected row player payoff of $x^{\\star T} A y = 0$. Thus, $y^\\star$ is a best response to $x^\\star$. This confirms $(x^\\star, y^\\star)$ is the NE.\n\nThe Smoothed Fictitious Play (SFP) update is given by the map $F(x,y) = (g(x,y), h(x,y))$, where\n$$\ng(x,y) \\;=\\; (1-\\eta) x \\;+\\; \\eta \\sigma(\\beta A y)\n$$\n$$\nh(x,y) \\;=\\; (1-\\eta) y \\;+\\; \\eta \\sigma(-\\beta A^T x)\n$$\nAt the NE $(x^\\star, y^\\star)$, we have $A y^\\star = \\mathbf{0}$ and $-\\beta A^T x^\\star = \\beta A x^\\star = \\mathbf{0}$. The softmax of a zero vector is the uniform distribution: $\\sigma(\\mathbf{0})_i = \\exp(0) / \\sum_j \\exp(0) = 1/3$. Thus $\\sigma(\\mathbf{0}) = x^\\star = y^\\star$.\nSubstituting these into the update rules confirms that $(x^\\star, y^\\star)$ is a fixed point of the SFP map:\n$$\ng(x^\\star, y^\\star) \\;=\\; (1-\\eta) x^\\star \\;+\\; \\eta \\sigma(\\mathbf{0}) \\;=\\; (1-\\eta) x^\\star \\;+\\; \\eta x^\\star \\;=\\; x^\\star\n$$\n$$\nh(x^\\star, y^\\star) \\;=\\; (1-\\eta) y^\\star \\;+\\; \\eta \\sigma(\\mathbf{0}) \\;=\\; (1-\\eta) y^\\star \\;+\\; \\eta y^\\star \\;=\\; y^\\star\n$$\nTo analyze the stability of this fixed point, we compute the Jacobian matrix $J$ of the map $F$ at $(x^\\star, y^\\star)$. The Jacobian is a $6 \\times 6$ block matrix:\n$$\nJ \\;=\\; \\begin{pmatrix} \\frac{\\partial g}{\\partial x} & \\frac{\\partial g}{\\partial y} \\\\ \\frac{\\partial h}{\\partial x} & \\frac{\\partial h}{\\partial y} \\end{pmatrix}\n\\Bigg|_{(x^\\star, y^\\star)}\n$$\nThe blocks are computed as:\n- $\\frac{\\partial g}{\\partial x} = (1-\\eta)I$, where $I$ is the $3 \\times 3$ identity matrix.\n- $\\frac{\\partial h}{\\partial y} = (1-\\eta)I$.\n- $\\frac{\\partial g}{\\partial y} = \\eta \\frac{\\partial}{\\partial y} [\\sigma(\\beta A y)] = \\eta D\\sigma(\\beta A y) \\cdot (\\beta A)$. Evaluated at $y^\\star$, this is $\\eta \\beta D\\sigma(\\mathbf{0}) A$.\n- $\\frac{\\partial h}{\\partial x} = \\eta \\frac{\\partial}{\\partial x} [\\sigma(-\\beta A^T x)] = \\eta D\\sigma(-\\beta A^T x) \\cdot (-\\beta A^T)$. Evaluated at $x^\\star$, this is $-\\eta \\beta D\\sigma(\\mathbf{0}) A^T$.\n\nLet $S = D\\sigma(\\mathbf{0})$ be the Jacobian of the softmax function at the origin. For $p = \\sigma(z)$, the entries of its Jacobian $D\\sigma(z)$ are $(D\\sigma(z))_{ij} = p_i(\\delta_{ij} - p_j)$. At $z=\\mathbf{0}$, $p = x^\\star = (1/3, 1/3, 1/3)^T$. So, $S = \\text{diag}(x^\\star) - x^\\star x^{\\star T}$.\n$$\nS \\;=\\; \\begin{pmatrix} 1/3 & 0 & 0 \\\\ 0 & 1/3 & 0 \\\\ 0 & 0 & 1/3 \\end{pmatrix} - \\begin{pmatrix} 1/9 & 1/9 & 1/9 \\\\ 1/9 & 1/9 & 1/9 \\\\ 1/9 & 1/9 & 1/9 \\end{pmatrix} \\;=\\; \\frac{1}{9} \\begin{pmatrix} 2 & -1 & -1 \\\\ -1 & 2 & -1 \\\\ -1 & -1 & 2 \\end{pmatrix}\n$$\nThe Jacobian matrix at $(x^\\star, y^\\star)$ is:\n$$\nJ(\\beta, \\eta) \\;=\\; \\begin{pmatrix} (1-\\eta)I & \\eta \\beta S A \\\\ -\\eta \\beta S A^T & (1-\\eta)I \\end{pmatrix}\n$$\nWe are given the parameters $\\beta=2$ and $\\eta=1$. For these values, $1-\\eta=0$ and $\\eta\\beta=2$.\n$$\nJ(2,1) \\;=\\; \\begin{pmatrix} 0 & 2 S A \\\\ -2 S A^T & 0 \\end{pmatrix}\n$$\nSince $A$ is skew-symmetric, $A^T=-A$. The Jacobian simplifies to:\n$$\nJ(2,1) \\;=\\; \\begin{pmatrix} 0 & 2 S A \\\\ 2 S A & 0 \\end{pmatrix} \\;=\\; \\begin{pmatrix} 0 & P \\\\ P & 0 \\end{pmatrix}\n$$\nwhere $P = 2SA$. The eigenvalues $\\lambda$ of a block matrix of this form satisfy $\\lambda^2 v_1 = P (P v_1)$, so $\\lambda^2$ are the eigenvalues of $P^2$. The eigenvalues of $J$ are therefore $\\pm \\mu_i$, where $\\mu_i$ are the eigenvalues of $P$. Thus, the spectral radius of $J(2,1)$ is equal to the spectral radius of $P$: $\\rho(J(2,1)) = \\rho(P)$.\n\nWe must compute $P=2SA$. The matrices $S$ and $A$ have a special relationship. The vector $\\mathbf{1}=(1,1,1)^T$ spans the kernel of both $A$ and $S$.\n- $A\\mathbf{1} = \\mathbf{0}$ and $A^T\\mathbf{1} = -A\\mathbf{1} = \\mathbf{0}$.\n- $S\\mathbf{1} = (\\text{diag}(x^\\star) - x^\\star x^{\\star T})\\mathbf{1} = x^\\star - x^\\star (x^{\\star T}\\mathbf{1})$. With $x^\\star = \\frac{1}{3}\\mathbf{1}$, $x^{\\star T}\\mathbf{1} = 1$. So $S\\mathbf{1} = x^\\star - x^\\star = \\mathbf{0}$.\nThe matrices $S$ and $A$ share the eigenspace $\\text{span}(\\mathbf{1})$ corresponding to eigenvalue $0$. The orthogonal complement, $\\mathbf{1}^\\perp$, is also an invariant subspace for both matrices.\nFor any vector $v \\in \\mathbf{1}^\\perp$, we have $x^{\\star T} v = 0$.\n- $Sv = (\\frac{1}{3}I - x^\\star x^{\\star T})v = \\frac{1}{3}v$. So the eigenspace $\\mathbf{1}^\\perp$ corresponds to eigenvalue $1/3$ for $S$.\n- If $v \\in \\mathbf{1}^\\perp$, then $(Av)^T \\mathbf{1} = v^T A^T \\mathbf{1} = \\mathbf{0}$, so $Av \\in \\mathbf{1}^\\perp$.\nSince $S$ acts as a scalar multiple of the identity on $\\mathbf{1}^\\perp$, $S$ and $A$ commute on this subspace: $S(Av) = \\frac{1}{3}(Av) = A(\\frac{1}{3}v) = A(Sv)$. Since both matrices are zero on $\\text{span}(\\mathbf{1})$, they commute on the entire space $\\mathbb{R}^3$.\nThe product $SA$ can be simplified:\n$$\nSA \\;=\\; S A \\;=\\; (\\frac{1}{3}I - x^\\star x^{\\star T})A \\;=\\; \\frac{1}{3}A - x^\\star (x^{\\star T}A)\n$$\nSince $x^\\star$ is a multiple of $\\mathbf{1}$ and $\\mathbf{1}^T A = \\mathbf{0}^T$, we have $x^{\\star T}A = \\mathbf{0}^T$.\nTherefore, $SA = \\frac{1}{3}A$.\nNow we can express $P$ simply in terms of $A$:\n$$\nP \\;=\\; 2SA \\;=\\; 2\\left(\\frac{1}{3}A\\right) \\;=\\; \\frac{2}{3}A\n$$\nThe spectral radius of $J(2,1)$ is $\\rho(P)$.\n$$\n\\rho(J(2,1)) \\;=\\; \\rho(P) \\;=\\; \\rho\\left(\\frac{2}{3}A\\right) \\;=\\; \\left|\\frac{2}{3}\\right|\\rho(A) \\;=\\; \\frac{2}{3}\\rho(A)\n$$\nThe final step is to find the spectral radius of $A$. We find the eigenvalues of $A$ by solving the characteristic equation $\\det(A-\\lambda I)=0$.\n$$\n\\det \\begin{pmatrix} -\\lambda & -1 & 1 \\\\ 1 & -\\lambda & -1 \\\\ -1 & 1 & -\\lambda \\end{pmatrix} \\;=\\; -\\lambda(\\lambda^2+1) - (-1)(-\\lambda-1) + 1(1-\\lambda) \\;=\\; -\\lambda^3-\\lambda-\\lambda-1+1-\\lambda \\;=\\; -\\lambda^3 - 3\\lambda \\;=\\; -\\lambda(\\lambda^2+3) \\;=\\; 0\n$$\nThe eigenvalues of $A$ are $\\lambda_1=0$, $\\lambda_2=i\\sqrt{3}$, and $\\lambda_3=-i\\sqrt{3}$.\nThe spectral radius of $A$ is the maximum modulus of its eigenvalues:\n$$\n\\rho(A) \\;=\\; \\max\\left\\{|0|, |i\\sqrt{3}|, |-i\\sqrt{3}|\\right\\} \\;=\\; \\sqrt{3}\n$$\nFinally, the spectral radius of the Jacobian $J(2,1)$ is:\n$$\n\\rho(J(2,1)) \\;=\\; \\frac{2}{3}\\rho(A) \\;=\\; \\frac{2}{3}\\sqrt{3} \\;=\\; \\frac{2\\sqrt{3}}{3}\n$$\nThis is the required exact value.", "answer": "$$\\boxed{\\frac{2\\sqrt{3}}{3}}$$", "id": "2437687"}]}