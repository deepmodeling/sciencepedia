{"hands_on_practices": [{"introduction": "How do you find the single best point to represent an entire region, even a non-convex one? This practice explores the concept of a \"minimax center,\" the point that minimizes the maximum distance to any other point within a given feasible set. By tackling this problem [@problem_id:2420377], you will uncover a powerful principle in optimization: the solution is often governed by the extreme points of the feasible region, reducing a complex problem over an infinite set to a manageable one involving a finite number of vertices.", "problem": "You are given a family of feasible regions in the plane described as unions of simple polygons. For each region, define its minimax center as the point in the Euclidean plane that minimizes the maximum Euclidean distance to any point in the region. Formally, for a nonempty compact feasible set $\\mathcal{S} \\subset \\mathbb{R}^2$, define the objective function\n$$\nf(\\mathbf{x}) = \\max_{\\mathbf{y} \\in \\mathcal{S}} \\lVert \\mathbf{x} - \\mathbf{y} \\rVert_2,\n$$\nand define the minimax center as any minimizer $\\mathbf{x}^\\star \\in \\mathbb{R}^2$ of $f(\\mathbf{x})$. The corresponding optimal objective value is the minimax radius $r^\\star = f(\\mathbf{x}^\\star)$. Note that $\\mathbf{x}^\\star$ is not required to belong to $\\mathcal{S}$.\n\nYour task is to write a complete program that, for each specified test case, computes the minimax center $\\mathbf{x}^\\star$ and the minimax radius $r^\\star$, and reports them numerically.\n\nThe feasible region for each test case is the union of one or more simple polygons in $\\mathbb{R}^2$ given by lists of their vertices in counterclockwise order. Each polygon is the filled-in region bounded by the straight-line edges joining successive vertices (with the last vertex connected back to the first). All coordinates are expressed in dimensionless Cartesian units.\n\nYou must respect the following requirements:\n\n- Treat the problem in purely mathematical terms: given $\\mathcal{S}$ as a union of polygons, compute $\\mathbf{x}^\\star \\in \\mathbb{R}^2$ and $r^\\star \\in \\mathbb{R}_{\\ge 0}$ minimizing $f(\\mathbf{x})$ as defined above.\n- The answer requires no physical units and no angles.\n- Your program must not hard-code the answers. It must implement a general solver for the described task.\n\nTest suite to implement and solve:\n\n- Case $\\mathbf{1}$ (non-convex union of two disjoint squares):\n  - Polygon $\\mathbf{A}$ vertices: $\\left(-4,-1\\right)$, $\\left(-2,-1\\right)$, $\\left(-2,1\\right)$, $\\left(-4,1\\right)$.\n  - Polygon $\\mathbf{B}$ vertices: $\\left(2,-1\\right)$, $\\left(4,-1\\right)$, $\\left(4,1\\right)$, $\\left(2,1\\right)$.\n\n- Case $\\mathbf{2}$ (nearly colinear thin rectangle, a boundary condition):\n  - Single polygon with vertices: $\\left(0,0\\right)$, $\\left(10,0\\right)$, $\\left(10,0.001\\right)$, $\\left(0,0.001\\right)$.\n\n- Case $\\mathbf{3}$ (concave U-shaped polygon):\n  - Single polygon with vertices: $\\left(-3,-2\\right)$, $\\left(3,-2\\right)$, $\\left(3,2\\right)$, $\\left(1,2\\right)$, $\\left(1,0\\right)$, $\\left(-1,0\\right)$, $\\left(-1,2\\right)$, $\\left(-3,2\\right)$.\n\n- Case $\\mathbf{4}$ (acute triangle where three points determine the optimum):\n  - Single polygon with vertices: $\\left(0,0\\right)$, $\\left(2,0\\right)$, $\\left(1,\\sqrt{3}\\right)$.\n\nYour program must produce a single line of output containing the results as a comma-separated list enclosed in square brackets. For each case, output a list of three floating-point numbers $\\left[x^\\star, y^\\star, r^\\star\\right]$ rounded to exactly $6$ decimal places, in the same order as the cases above. The final output must therefore be of the form\n$$\n\\left[\\left[x^\\star_1,y^\\star_1,r^\\star_1\\right],\\left[x^\\star_2,y^\\star_2,r^\\star_2\\right],\\left[x^\\star_3,y^\\star_3,r^\\star_3\\right],\\left[x^\\star_4,y^\\star_4,r^\\star_4\\right]\\right].\n$$\nFor example, the output format should look like $\\left[\\left[0.000000,0.000000,1.234567\\right],\\ldots\\right]$ with no spaces.\n\nYour implementation must be a complete, runnable program that constructs the above test cases internally and prints the required single-line output.", "solution": "The problem as stated is valid. It is a well-posed optimization problem within the domain of computational geometry, formulated with objective and precise language. All necessary data is provided. I will proceed with a solution.\n\nThe problem asks for the computation of the minimax center $\\mathbf{x}^\\star \\in \\mathbb{R}^2$ and the corresponding minimax radius $r^\\star \\in \\mathbb{R}_{\\ge 0}$ for a given compact set $\\mathcal{S} \\subset \\mathbb{R}^2$. The set $\\mathcal{S}$ is described as a union of simple polygons. The minimax center is the point that minimizes the maximum Euclidean distance to any point in $\\mathcal{S}$. This is formally stated as finding $\\mathbf{x}^\\star = \\arg\\min_{\\mathbf{x} \\in \\mathbb{R}^2} f(\\mathbf{x})$, where the objective function is $f(\\mathbf{x}) = \\max_{\\mathbf{y} \\in \\mathcal{S}} \\lVert \\mathbf{x} - \\mathbf{y} \\rVert_2$. This is equivalent to finding the center and radius of the smallest enclosing circle of the set $\\mathcal{S}$.\n\nA fundamental principle of convex analysis dictates the path to a solution. For any fixed point $\\mathbf{x}$, the function $g(\\mathbf{y}) = \\lVert \\mathbf{x} - \\mathbf{y} \\rVert_2$ is a convex function of $\\mathbf{y}$. A convex function defined on a compact set attains its maximum at an extreme point of the set's convex hull. The given set $\\mathcal{S}$ is a union of polygons, which is a compact set. Let $\\text{conv}(\\mathcal{S})$ denote the convex hull of $\\mathcal{S}$. The extreme points of $\\text{conv}(\\mathcal{S})$ are a subset of the vertices of the input polygons.\n\nLet $V$ be the set of all vertices from all polygons that constitute $\\mathcal{S}$. The convex hull of $\\mathcal{S}$ is identical to the convex hull of its vertices, $\\text{conv}(\\mathcal{S}) = \\text{conv}(V)$. Let $V_{\\text{ext}} \\subseteq V$ be the set of vertices that form the boundary of $\\text{conv}(V)$. The objective function can therefore be simplified, as the maximum distance from $\\mathbf{x}$ to any point in $\\mathcal{S}$ will be the maximum distance to one of these extreme vertices:\n$$\nf(\\mathbf{x}) = \\max_{\\mathbf{y} \\in \\mathcal{S}} \\lVert \\mathbf{x} - \\mathbf{y} \\rVert_2 = \\max_{\\mathbf{y} \\in \\text{conv}(\\mathcal{S})} \\lVert \\mathbf{x} - \\mathbf{y} \\rVert_2 = \\max_{\\mathbf{v} \\in V_{\\text{ext}}} \\lVert \\mathbf{x} - \\mathbf{v} \\rVert_2\n$$\nThis reduces the problem from dealing with an infinite set of points in $\\mathcal{S}$ to a finite set of points $V_{\\text{ext}}$. The task is now to find the smallest enclosing circle for this finite point set $V_{\\text{ext}}$.\n\nThis problem can be formulated as a convex optimization problem. Let the unknown center of the circle be $\\mathbf{x} = (x, y)$ and its radius be $r$. We want to minimize $r$, which is equivalent to minimizing $r^2$. The constraint is that all points $\\mathbf{v}_i \\in V_{\\text{ext}}$ must lie within or on the boundary of this circle. This is expressed mathematically as:\n$$\n\\lVert \\mathbf{x} - \\mathbf{v}_i \\rVert_2 \\le r \\quad \\forall \\mathbf{v}_i \\in V_{\\text{ext}}\n$$\nTo create a more convenient formulation for standard solvers, we use the squared radius $R = r^2$ and the squared distance:\n$$\n\\lVert \\mathbf{x} - \\mathbf{v}_i \\rVert_2^2 \\le R \\quad \\forall \\mathbf{v}_i \\in V_{\\text{ext}}\n$$\nLetting $\\mathbf{v}_i = (v_{ix}, v_{iy})$, the optimization problem is:\n$$\n\\min_{x, y, R} R\n$$\nsubject to:\n$$\n(x - v_{ix})^2 + (y - v_{iy})^2 - R \\le 0 \\quad \\forall \\mathbf{v}_i \\in V_{\\text{ext}}\n$$\n$$\nR \\ge 0\n$$\nThis is a Quadratically Constrained Program (QCP) with a linear objective function and convex quadratic constraints. It can be solved numerically using standard optimization algorithms.\n\nThe algorithmic procedure is as follows:\n$1$. For each test case, aggregate the vertices of all given polygons into a single set of points $V$.\n$2$. Compute the convex hull of the point set $V$ to identify the extreme vertices $V_{\\text{ext}}$. This is accomplished using the `ConvexHull` function from the `scipy.spatial` library.\n$3$. Solve the aforementioned QCP. We employ the `minimize` function from `scipy.optimize` with the Sequential Least Squares Programming (`SLSQP`) method. The optimization variables are $(x, y, R)$.\n$4$. The objective function passed to the solver is simply $R$.\n$5$. The constraints are formulated as a list of functions, one for each vertex $\\mathbf{v}_i \\in V_{\\text{ext}}$, ensuring $(x - v_{ix})^2 + (y - v_{iy})^2 - R \\le 0$. A non-negativity bound on $R$ is also imposed.\n$6$. An initial guess for the optimization is constructed. The centroid of $V_{\\text{ext}}$ is used as the initial center $(x_0, y_0)$, and the initial squared radius $R_0$ is the maximum squared distance from this centroid to any vertex in $V_{\\text{ext}}$.\n$7$. The solver iteratively refines this guess to find the optimal solution $(x^\\star, y^\\star, R^\\star)$.\n$8$. The final minimax center is $\\mathbf{x}^\\star = (x^\\star, y^\\star)$ and the minimax radius is $r^\\star = \\sqrt{R^\\star}$. This procedure is repeated for each test case described in the problem statement.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.optimize import minimize\nfrom scipy.spatial import ConvexHull\nimport math\n\ndef solve():\n    \"\"\"\n    Main function to solve the minimax center problem for the given test cases.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # Case 1: non-convex union of two disjoint squares\n        [[(-4,-1), (-2,-1), (-2,1), (-4,1)],\n         [(2,-1), (4,-1), (4,1), (2,1)]],\n        # Case 2: nearly colinear thin rectangle\n        [[ (0,0), (10,0), (10,0.001), (0,0.001)]],\n        # Case 3: concave U-shaped polygon\n        [[(-3,-2), (3,-2), (3,2), (1,2), (1,0), (-1,0), (-1,2), (-3,2)]],\n        # Case 4: acute triangle\n        [[(0,0), (2,0), (1,math.sqrt(3))]]\n    ]\n\n    def compute_minimax_center(polygons):\n        \"\"\"\n        Computes the minimax center and radius for a set of polygons.\n\n        The problem is reduced to finding the smallest enclosing circle of the\n        set of vertices of the convex hull of the union of the polygons. This\n        is solved as a convex optimization problem.\n        \"\"\"\n        # 1. Aggregate all vertices from all polygons\n        all_vertices = np.vstack([np.array(p, dtype=float) for p in polygons])\n        \n        # Handle cases with few points where ConvexHull would fail\n        unique_vertices = np.unique(all_vertices, axis=0)\n        \n        if unique_vertices.shape[0] < 2:\n            center = unique_vertices[0]\n            return center[0], center[1], 0.0\n\n        if unique_vertices.shape[0] == 2:\n            p1, p2 = unique_vertices[0], unique_vertices[1]\n            center = (p1 + p2) / 2.0\n            radius = np.linalg.norm(p1 - p2) / 2.0\n            return center[0], center[1], radius\n\n        # 2. Compute the convex hull of the vertices\n        try:\n            hull = ConvexHull(unique_vertices)\n            hull_vertices = unique_vertices[hull.vertices]\n        except: # QhullError often for colinear points\n             # For colinear points, the smallest enclosing circle's diameter\n             # is the distance between the two extreme points.\n            max_dist = 0\n            p1_max, p2_max = None, None\n            for i in range(len(unique_vertices)):\n                for j in range(i + 1, len(unique_vertices)):\n                    dist = np.linalg.norm(unique_vertices[i] - unique_vertices[j])\n                    if dist > max_dist:\n                        max_dist = dist\n                        p1_max = unique_vertices[i]\n                        p2_max = unique_vertices[j]\n            center = (p1_max + p2_max) / 2.0\n            radius = max_dist / 2.0\n            return center[0], center[1], radius\n\n        # 3. Set up the optimization problem\n        # Variables: p = [x, y, r_squared]\n\n        # Initial guess based on the centroid of the hull vertices\n        initial_center = np.mean(hull_vertices, axis=0)\n        initial_r_squared = np.max(np.sum((hull_vertices - initial_center)**2, axis=1))\n        p0 = np.array([initial_center[0], initial_center[1], initial_r_squared])\n\n        # Objective function: minimize r_squared (p[2])\n        objective = lambda p: p[2]\n\n        # Constraints: (x - v_x)^2 + (y - v_y)^2 <= r_squared for each v in hull_vertices\n        # The form for SLSQP is fun(p) >= 0.\n        constraints = []\n        for v in hull_vertices:\n            constraints.append({\n                'type': 'ineq',\n                'fun': lambda p, v_pt=v: p[2] - ((p[0] - v_pt[0])**2 + (p[1] - v_pt[1])**2)\n            })\n\n        # Bounds for variables: r_squared must be non-negative\n        bounds = [(None, None), (None, None), (0, None)]\n\n        # 4. Run the optimizer\n        result = minimize(\n            objective,\n            p0,\n            method='SLSQP',\n            bounds=bounds,\n            constraints=constraints,\n            tol=1e-12, # High tolerance for precision\n            options={'maxiter': 1000}\n        )\n        \n        if not result.success:\n            raise RuntimeError(f\"Optimization failed: {result.message}\")\n\n        # 5. Extract and return the results\n        x_star, y_star, r_squared_star = result.x\n        r_star = np.sqrt(r_squared_star)\n\n        return x_star, y_star, r_star\n\n    results = []\n    for case_polygons in test_cases:\n        x_star, y_star, r_star = compute_minimax_center(case_polygons)\n        results.append(f\"[{x_star:.6f},{y_star:.6f},{r_star:.6f}]\")\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(results)}]\")\n\nsolve()\n```", "id": "2420377"}, {"introduction": "Real-world engineering tasks, from manufacturing to software compilation, often involve a sequence of operations with strict dependencies. This exercise [@problem_id:2420404] casts this challenge in a familiar setting: assembling furniture. Your goal is to find an assembly sequence that respects all precedence constraints while minimizing an objective function—in this case, the number of times you must reorient the workpiece—introducing you to the world of combinatorial optimization and dynamic programming on graphs.", "problem": "You are given a finite set of assembly tasks indexed by integers $0,1,\\dots,N-1$. Each task $i$ requires the assembly to be in exactly one orientation $o(i)$ drawn from a finite set of orientations $\\mathcal{O}$ (for example, labels such as $U$, $D$, $L$, $R$). A precedence relation is specified as a set of directed edges $\\mathcal{P} \\subseteq \\{0,1,\\dots,N-1\\} \\times \\{0,1,\\dots,N-1\\}$, where $(i,j) \\in \\mathcal{P}$ means that task $i$ must be completed before task $j$. A sequence $\\pi$ of all tasks is feasible if and only if it is a topological ordering of the directed acyclic graph (DAG) induced by $\\mathcal{P}$, that is, for every $(i,j) \\in \\mathcal{P}$, the position of $i$ in $\\pi$ is less than the position of $j$ in $\\pi$.\n\nDefine the orientation switch count of a feasible sequence $\\pi$ as follows. The initial orientation can be chosen freely at zero cost. For consecutive tasks in $\\pi$, every time the required orientation changes, the count increases by one. Formally, if $\\pi = (\\pi_1,\\pi_2,\\dots,\\pi_N)$ and $o(\\pi_k)$ denotes the required orientation of the $k$-th task, the orientation switch count is\n$$\n\\sum_{k=2}^{N} \\mathbf{1}\\{\\,o(\\pi_k) \\neq o(\\pi_{k-1})\\,\\},\n$$\nwhere $\\mathbf{1}\\{\\cdot\\}$ is the indicator function that equals $1$ when its argument is true and $0$ otherwise. Your objective is to minimize this count over all feasible sequences.\n\nTasks:\n- Formulate the objective function, constraints, and feasibility conditions precisely in terms of the given data $(\\mathcal{O}, o(\\cdot), \\mathcal{P})$.\n- Design an algorithm that, for small problem sizes, finds the minimal orientation switch count by enumerating or implicitly searching the feasible set and evaluating the objective, grounded in first principles of constrained optimization and graph theory.\n\nYour program must compute the minimal orientation switch count for each of the following test cases. For each case, the problem data are given as a tuple $(N, \\mathcal{O}, \\text{orientations}, \\mathcal{P})$, where:\n- $N$ is the number of tasks.\n- $\\mathcal{O}$ is the set of orientation labels available in that case.\n- $\\text{orientations}$ is a list of length $N$ giving $o(i)$ for each task index $i$.\n- $\\mathcal{P}$ is the list of precedence pairs $(i,j)$.\n\nTest suite:\n- Case $1$ (chain with grouped orientations):\n  - $N = 4$\n  - $\\mathcal{O} = \\{U,D\\}$\n  - $\\text{orientations} = [U, U, D, D]$\n  - $\\mathcal{P} = \\{(0,1),(1,2),(2,3)\\}$\n- Case $2$ (partial order allowing grouping):\n  - $N = 5$\n  - $\\mathcal{O} = \\{U,D\\}$\n  - $\\text{orientations} = [U, U, U, D, D]$\n  - $\\mathcal{P} = \\{(0,3),(1,3),(0,4)\\}$\n- Case $3$ (all tasks same orientation):\n  - $N = 6$\n  - $\\mathcal{O} = \\{L\\}$\n  - $\\text{orientations} = [L, L, L, L, L, L]$\n  - $\\mathcal{P} = \\{(0,2),(1,2),(2,3),(2,4),(4,5)\\}$\n- Case $4$ (three orientations, no precedence):\n  - $N = 3$\n  - $\\mathcal{O} = \\{U,L,D\\}$\n  - $\\text{orientations} = [U, L, D]$\n  - $\\mathcal{P} = \\emptyset$\n- Case $5$ (single task):\n  - $N = 1$\n  - $\\mathcal{O} = \\{R\\}$\n  - $\\text{orientations} = [R]$\n  - $\\mathcal{P} = \\emptyset$\n\nOutput specification:\n- Your program should produce a single line of output containing the minimal orientation switch counts for Cases $1$ through $5$, in order, as a comma-separated list enclosed in square brackets. For example, an output of the form $[a_1,a_2,a_3,a_4,a_5]$ with each $a_i$ an integer. No spaces and no additional text should be printed.", "solution": "The problem presented is a valid combinatorial optimization problem grounded in computational engineering and graph theory. It is well-posed, objective, and scientifically sound. We shall proceed with a formal analysis and algorithmic solution.\n\nThe problem asks for the minimization of orientation switches in an assembly sequence, subject to precedence constraints. This can be formulated as follows.\n\nLet the set of tasks be $\\mathcal{T} = \\{0, 1, \\dots, N-1\\}$. The given data includes a function $o: \\mathcal{T} \\to \\mathcal{O}$ mapping each task to a required orientation, and a set of precedence constraints $\\mathcal{P}$, which defines a directed acyclic graph (DAG) $G = (\\mathcal{T}, \\mathcal{P})$.\n\nA decision variable is a sequence of tasks $\\pi = (\\pi_1, \\pi_2, \\dots, \\pi_N)$, which must be a permutation of $\\mathcal{T}$.\n\nThe objective function, $Z(\\pi)$, is the total number of orientation switches, defined as:\n$$\nZ(\\pi) = \\sum_{k=2}^{N} \\mathbf{1}\\{o(\\pi_k) \\neq o(\\pi_{k-1})\\}\n$$\nwhere $\\mathbf{1}\\{\\cdot\\}$ is the indicator function. The initial orientation is chosen freely, incurring no cost.\n\nThe constraints define the feasible set of sequences. A sequence $\\pi$ is feasible if and only if it is a topological ordering of the DAG $G$. This means that for every precedence constraint $(i, j) \\in \\mathcal{P}$, task $i$ must appear before task $j$ in the sequence $\\pi$. If we denote the position of a task $u$ in $\\pi$ by $\\text{pos}(u)$, this constraint is formally stated as:\n$$\n\\text{pos}(i)  \\text{pos}(j), \\quad \\forall (i, j) \\in \\mathcal{P}\n$$\n\nThe optimization problem is to find a feasible sequence $\\pi^*$ that minimizes the objective function:\n$$\n\\pi^* = \\arg\\min_{\\pi \\in \\text{FeasibleSet}} Z(\\pi)\n$$\nThe value to be computed is $Z(\\pi^*)$.\n\nFor small problem sizes, enumerating all feasible sequences (all topological sorts) and evaluating the objective function for each is a valid, though inefficient, approach. A more structured and efficient method is dynamic programming, which avoids recomputing solutions to overlapping subproblems. This problem is analogous to the Traveling Salesperson Problem (TSP) on a DAG and can be solved with a similar dynamic programming approach over subsets of vertices.\n\nLet us define a state by the set of tasks that have been completed, and the last task that was performed in that set. We can represent the set of completed tasks using a bitmask `mask`, an integer from $0$ to $2^N-1$.\n\nLet $dp[\\text{mask}][i]$ be the minimum number of orientation switches required to complete the set of tasks corresponding to the bits set in `mask`, with task $i$ being the final task in the sequence. Task $i$ must belong to the set represented by `mask`.\n\nThe size of the DP table will be $2^N \\times N$. The entries are initialized to infinity to represent unreachable states.\n\n**Initialization:**\nA sequence can only start with a task that has no predecessors (an in-degree of $0$ in the DAG $G$). For each such task $i$, we can start a sequence with it. This requires completing the set of tasks $\\{i\\}$, ending with task $i$. As this is the first task, there are no preceding switches.\nThus, for each task $i$ with an in-degree of $0$:\n$$\ndp[1 \\ll i][i] = 0\n$$\nwhere `1  i` is the bitmask with only the $i$-th bit set.\n\n**Recurrence Relation:**\nWe build up the solution for larger sets of tasks from the solutions for smaller sets. Consider a state $( \\text{mask}, i )$ that is reachable (i.e., $dp[\\text{mask}][i]  \\infty$). We can transition from this state by adding a new task $j$ that is not currently in `mask`. This transition is valid only if all predecessors of task $j$ are already in the set `mask`.\n\nLet $\\text{pred}(j)$ be the set of predecessors of task $j$. The transition to include task $j$ is valid if $\\text{pred}(j) \\subseteq \\text{tasks}(\\text{mask})$, where $\\text{tasks}(\\text{mask})$ is the set of tasks represented by `mask`.\n\nWhen transitioning from task $i$ to task $j$, a switch cost is incurred if their orientations differ. The cost is $1$ if $o(i) \\neq o(j)$, and $0$ otherwise.\nThe new state will be $(\\text{mask} \\cup \\{j\\}, j)$, reached from $(\\text{mask}, i)$. The DP update rule is:\n$$\ndp[\\text{mask} \\cup \\{j\\}][j] = \\min \\left( dp[\\text{mask} \\cup \\{j\\}][j], \\quad dp[\\text{mask}][i] + \\mathbf{1}\\{o(i) \\neq o(j)\\} \\right)\n$$\nThis update is performed for all valid transitions. We can implement this by iterating `mask` from $1$ to $2^N-1$, and for each `mask`, considering all pairs of tasks $(i, j)$ where $i \\in \\text{tasks}(\\text{mask})$ and $j \\notin \\text{tasks}(\\text{mask})$.\n\n**Final Answer:**\nAfter populating the DP table, the minimum total switch count is found by examining the states where all tasks have been completed. This corresponds to the mask $(1 \\ll N) - 1$. The final task could be any task $i$. Therefore, the minimal switch count for the entire sequence is:\n$$\n\\min_{i=0, \\dots, N-1} \\{ dp[(1 \\ll N) - 1][i] \\}\n$$\n\nFor a single task ($N=1$), the objective function sum is empty, so the cost is $0$. The algorithm correctly handles this as a base case. This DP approach has a time complexity of $O(N^2 2^N)$, which is acceptable for the small values of $N$ in the test suite.", "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to solve the problem for the given test suite.\n    \"\"\"\n    \n    test_cases = [\n        # Case 1 (chain with grouped orientations)\n        (4, {'U', 'D'}, ['U', 'U', 'D', 'D'], [(0, 1), (1, 2), (2, 3)]),\n        # Case 2 (partial order allowing grouping)\n        (5, {'U', 'D'}, ['U', 'U', 'U', 'D', 'D'], [(0, 3), (1, 3), (0, 4)]),\n        # Case 3 (all tasks same orientation)\n        (6, {'L'}, ['L', 'L', 'L', 'L', 'L', 'L'], [(0, 2), (1, 2), (2, 3), (2, 4), (4, 5)]),\n        # Case 4 (three orientations, no precedence)\n        (3, {'U', 'L', 'D'}, ['U', 'L', 'D'], []),\n        # Case 5 (single task)\n        (1, {'R'}, ['R'], [])\n    ]\n\n    results = []\n    for case in test_cases:\n        N, _, orientations, P = case\n        result = compute_min_switches(N, orientations, P)\n        results.append(result)\n\n    print(f\"[{','.join(map(str, results))}]\")\n\ndef compute_min_switches(N, orientations, P):\n    \"\"\"\n    Computes the minimum orientation switch count for a single problem instance.\n\n    Args:\n        N (int): The number of tasks.\n        orientations (list[str]): A list of orientation labels for each task.\n        P (list[tuple[int, int]]): The list of precedence pairs (i, j).\n\n    Returns:\n        int: The minimum number of orientation switches.\n    \"\"\"\n    if N = 1:\n        return 0\n\n    # Build predecessor masks for efficient checking of precedence constraints.\n    # predecessor_mask[j] is a bitmask of all tasks that must precede task j.\n    predecessor_mask = [0] * N\n    for i, j in P:\n        predecessor_mask[j] |= (1  i)\n\n    # Initialize DP table. dp[mask][i] stores the minimum switches to complete\n    # the tasks in `mask`, ending with task `i`.\n    dp = np.full((1  N, N), np.inf)\n\n    # Base cases: A sequence can start with any task that has no predecessors.\n    # The cost for the first task is 0 switches.\n    for i in range(N):\n        if predecessor_mask[i] == 0:\n            dp[1  i][i] = 0\n\n    # Iterate through all subsets of tasks (masks), from size 1 up to N-1.\n    for mask in range(1, 1  N):\n        for i in range(N):\n            # Check if task `i` is in the current set `mask` and the state is reachable.\n            if (mask  i)  1 and dp[mask][i] != np.inf:\n                # Try to transition to a new task `j` not in the current set.\n                for j in range(N):\n                    if not ((mask  j)  1):\n                        # Check if all predecessors of `j` are in the current set `mask`.\n                        if (predecessor_mask[j]  mask) == predecessor_mask[j]:\n                            next_mask = mask | (1  j)\n                            cost = 0 if orientations[i] == orientations[j] else 1\n                            new_total_cost = dp[mask][i] + cost\n                            \n                            # Update the DP table for the new state.\n                            if new_total_cost  dp[next_mask][j]:\n                                dp[next_mask][j] = new_total_cost\n                                \n    # The final result is the minimum cost after all tasks are completed.\n    final_mask = (1  N) - 1\n    min_total_switches = np.min(dp[final_mask])\n\n    return int(min_total_switches)\n\nif __name__ == '__main__':\n    solve()\n```", "id": "2420404"}, {"introduction": "The rise of additive manufacturing has created new frontiers for computational design, where the manufacturing process itself imposes unique constraints on the final product. In this capstone exercise [@problem_id:2420423], you will design a minimal-mass bridge that is not only structurally sound but also \"self-supporting\" at every stage of its layer-by-layer 3D printing process. This problem will challenge you to translate complex physical and geometric rules into a rigorous dynamic programming framework, a key skill in modern computational engineering.", "problem": "You must write a complete program that, given a discretized two-dimensional bridge design space, computes the minimal-mass self-supporting structure that connects two base anchors under a layer-by-layer manufacturability constraint. The final structure must be feasible at every intermediate printing stage.\n\nMathematical model. Consider a rectangular lattice of cubic voxels with horizontal index $i \\in \\{0,1,\\dots,W-1\\}$ and vertical layer index $j \\in \\{0,1,\\dots,H\\}$, where $W$ is the domain width and $H$ is the maximum allowable number of printed layers above the base plate (layer $j=0$). A binary design variable $x_{i,j} \\in \\{0,1\\}$ indicates whether the voxel at coordinates $(i,j)$ is printed. The objective is to minimize the total mass, modeled as the sum of all printed voxels,\n$$\n\\min \\; M(x) = \\sum_{j=0}^{H}\\sum_{i=0}^{W-1} x_{i,j}.\n$$\nManufacturing feasibility is imposed by a discrete self-support constraint derived from the layer-by-layer nature of Fused Deposition Modeling (FDM). Specifically, for a given maximum horizontal support offset per layer $s \\in \\mathbb{Z}_{\\ge 1}$, every printed voxel above the base must have at least one supporting voxel in the immediately lower layer within horizontal distance at most $s$:\n$$\n\\forall\\, j \\in \\{1,\\dots,H\\}, \\; \\forall\\, i \\in \\{0,\\dots,W-1\\}:\\quad\nx_{i,j} = 1 \\;\\Rightarrow\\; \\sum_{k=\\max(0,i-s)}^{\\min(W-1,i+s)} x_{k,j-1} \\ge 1.\n$$\nBase voxels at layer $j=0$ are considered supported by the build plate and therefore exempt from the above constraint. The bridge must connect two base anchors located at $(0,0)$ and $(W-1,0)$. Connectivity is defined via upward self-supporting steps: a self-supporting path is a sequence of occupied voxels $\\{(i_t,j_t)\\}_{t=0}^{T}$ such that $j_{t+1}=j_t+1$ and $|i_{t+1}-i_t| \\le s$ for all $t$. The design is feasible if there exist two self-supporting paths, one starting at $(0,0)$ and one starting at $(W-1,0)$, that terminate at a common voxel, and all printed voxels satisfy the self-support rule. Among all such feasible designs, the mass $M(x)$ must be minimized. All parameters are integers with $W \\in \\mathbb{Z}_{\\ge 1}$, $H \\in \\mathbb{Z}_{\\ge 0}$, and $s \\in \\mathbb{Z}_{\\ge 1}$.\n\nYour task. Starting from the above fundamental definitions, derive an algorithm that, given $(W,H,s)$, returns the minimal possible value of $M(x)$ if the problem is feasible and returns $-1$ if no feasible design exists under the constraints. Your algorithm must be correct for all inputs satisfying the stated bounds. No physical units are involved.\n\nTest suite. Your program must compute results for the following parameter sets, each provided as a triple $(W,H,s)$:\n- Case A: $(W,H,s) = (9,5,1)$\n- Case B: $(W,H,s) = (13,3,2)$\n- Case C: $(W,H,s) = (11,4,1)$\n- Case D: $(W,H,s) = (1,0,1)$\n- Case E: $(W,H,s) = (20,4,3)$\n\nFinal output format. Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, in the same order as the cases above. Each entry must be an integer: the minimal mass if feasible, or $-1$ if infeasible. For example, an output could look like $[3,5,-1,7,9]$ (this is only an example, not the correct answer for the given cases).", "solution": "The problem statement presented is a well-posed optimization problem within the domain of computational engineering. It is scientifically grounded, objective, and contains sufficient information to derive a unique solution. The definitions are precise and free of contradiction. Therefore, the problem is valid, and a rigorous solution is derivable.\n\nThe task is to find a minimal-mass structure on a $W \\times (H+1)$ grid of voxels that connects two anchor points, $(0,0)$ and $(W-1,0)$, subject to a layer-by-layer self-support constraint.\n\nThe objective is to minimize the total mass, which is the count of active voxels $x_{i,j}=1$:\n$$\nM(x) = \\sum_{j=0}^{H}\\sum_{i=0}^{W-1} x_{i,j}\n$$\n\nA feasible structure must satisfy two conditions:\n$1$. The connectivity requirement: There must exist two self-supporting paths, one originating from the left anchor $(0,0)$ and one from the right anchor $(W-1,0)$, that meet at a common voxel. A self-supporting path is a sequence of voxels $\\{(i_t, j_t)\\}_{t=0}^{T}$ where each subsequent voxel $(i_{t+1}, j_{t+1})$ satisfies $j_{t+1} = j_t+1$ and $|i_{t+1}-i_t| \\le s$.\n$2$. The global self-support rule: Every active voxel $x_{i,j}=1$ for $j \\ge 1$ must be supported by at least one active voxel in the layer below, within a horizontal distance of $s$. This is expressed as:\n$$\nx_{i,j} = 1 \\implies \\exists k \\in [\\max(0, i-s), \\min(W-1, i+s)] \\text{ such that } x_{k,j-1} = 1\n$$\n\nThe principle of optimality dictates that a minimal-mass structure will contain no superfluous voxels. Any voxel not part of the connecting paths or not providing essential support would be removed to decrease mass. Consequently, the minimal structure is formed precisely by the union of the two self-supporting paths. The problem is thus equivalent to finding two such paths whose union of voxels is minimal.\n\nThis problem structure is amenable to dynamic programming. We define a state by the layer index and the horizontal positions of the endpoints of the two growing paths. Let $dp[j][i_L][i_R]$ be the minimum possible mass of a structure composed of two self-supporting paths originating from $(0,0)$ and $(W-1,0)$, respectively, and terminating at layer $j$ with horizontal positions $i_L$ and $i_R$.\n\nThe state space is defined for $j \\in \\{0, \\dots, H\\}$, $i_L \\in \\{0, \\dots, W-1\\}$, and $i_R \\in \\{0, \\dots, W-1\\}$.\n\nThe base case is at layer $j=0$. The two paths must start at the anchors.\nIf $W=1$, the anchors are identical. A single voxel at $(0,0)$ constitutes a valid, connected structure of mass $1$. $dp[0][0][0] = 1$.\nIf $W1$, the paths start at $(0,0)$ and $(W-1,0)$. The initial structure consists of two voxels. Thus, $dp[0][0][W-1] = 2$.\nAll other states at $j=0$ are unreachable, so their cost is initialized to infinity:\n$$\ndp[0][i_L][i_R] = \\infty \\quad \\forall (i_L, i_R) \\neq \\begin{cases} (0,0)  \\text{if } W=1 \\\\ (0,W-1)  \\text{if } W1 \\end{cases}\n$$\n\nFor the recurrence relation, consider the state $dp[j][i_L][i_R]$ for $j0$. The paths arrive at $(i_L, j)$ and $(i_R, j)$ from some valid positions $(p_L, j-1)$ and $(p_R, j-1)$ in the layer below. The self-support constraint requires $|i_L-p_L| \\le s$ and $|i_R-p_R| \\le s$. The cost to transition from a state at layer $j-1$ to a state at layer $j$ is the number of new voxels added at layer $j$. This is $2$ if $i_L \\neq i_R$, and $1$ if $i_L = i_R$.\n\nTo achieve the minimum mass at $(j, i_L, i_R)$, we must have come from the lowest-cost valid predecessor state in layer $j-1$. The recurrence relation is therefore:\n$$\ndp[j][i_L][i_R] = \\left(2 - \\delta_{i_L, i_R}\\right) + \\min_{\\substack{p_L \\in [\\max(0, i_L-s), \\min(W-1, i_L+s)] \\\\ p_R \\in [\\max(0, i_R-s), \\min(W-1, i_R+s)]}} \\left\\{ dp[j-1][p_L][p_R] \\right\\}\n$$\nwhere $\\delta_{i_L, i_R}$ is the Kronecker delta, equal to $1$ if $i_L=i_R$ and $0$ otherwise.\n\nThe minimization term represents a 2D range minimum query over a rectangular region in the $dp[j-1]$ cost matrix. This can be computed efficiently. For each state $(j, i_L, i_R)$, we find the minimum value in the submatrix of $dp[j-1]$ defined by the support constraints.\n\nAfter populating the entire DP table from $j=1$ to $H$, the solution is found by identifying the minimum mass among all feasible final structures. A feasible structure is one where the paths meet, i.e., $i_L = i_R$. The meeting can occur at any voxel $(i, j)$ for $j \\in \\{0, \\dots, H\\}$ and $i \\in \\{0, \\dots, W-1\\}$. The cost of such a structure is given by $dp[j][i][i]$. The overall minimum mass is the minimum of these values over all possible meeting points.\n$$\nM_{min} = \\min_{\\substack{j \\in \\{0, \\dots, H\\} \\\\ i \\in \\{0, \\dots, W-1\\}}} \\left\\{ dp[j][i][i] \\right\\}\n$$\n\nIf this minimum value is infinity, it implies that no meeting of paths is possible within the given constraints ($W, H, s$), and the problem is infeasible. In this case, the specified output is $-1$.\n\nAlgorithm summary:\n$1$. Handle the trivial case $W=1$: the mass is $1$.\n$2$. Initialize a 3D DP table $dp[H+1][W][W]$ with $\\infty$.\n$3$. Set the base case: $dp[0][0][W-1] = 2$.\n$4$. Iterate $j$ from $1$ to $H$. For each $j$, compute the $dp[j]$ matrix based on $dp[j-1]$ using the recurrence. The minimization for each state $(i_L, i_R)$ is performed over a rectangular window of size up to $(2s+1) \\times (2s+1)$ in the $dp[j-1]$ matrix.\n$5$. After the DP table is complete, find the minimum value on the diagonals of all layer matrices: $\\min(dp[:, i, i])$ for all $i$.\n$6$. If the resulting minimum is $\\infty$, return $-1$. Otherwise, return the minimum mass as an integer. This algorithm correctly determines the minimal mass for any valid input.", "answer": "```python\nimport numpy as np\n\ndef solve_case(W, H, s):\n    \"\"\"\n    Computes the minimal mass of a self-supporting bridge structure.\n\n    This function uses dynamic programming to solve the problem. The state is\n    defined as dp[j][i_L][i_R], representing the minimum mass of a structure\n    with two paths ending at layer j, at horizontal positions i_L and i_R.\n    \"\"\"\n    if W = 0 or H  0 or s = 0:\n        # Invalid parameters based on problem constraints\n        return -1\n\n    if W == 1:\n        # If width is 1, anchors are at the same point. A single voxel is sufficient.\n        return 1\n\n    # dp[j][i_L][i_R]: min mass for paths ending at (i_L, j) and (i_R, j)\n    # Using np.inf for unreachable states.\n    dp = np.full((H + 1, W, W), np.inf, dtype=np.float64)\n\n    # Base case at j=0 (build plate)\n    # The two paths start at the anchors (0,0) and (W-1,0). Mass is 2.\n    dp[0, 0, W - 1] = 2.0\n\n    # Iterate through layers from 1 to H\n    for j in range(1, H + 1):\n        # We can optimize the search for the minimum in the previous layer's window.\n        # Instead of a complex sliding window, a direct slicing approach with NumPy\n        # is clear and fast enough for the given constraints.\n        prev_dp = dp[j - 1, :, :]\n        \n        # This part can be slow if written with Python loops.\n        # Let's vectorize or use efficient lookups.\n        # A 2D range minimum query structure would be optimal, but let's precompute.\n        \n        # Precompute horizontal sliding window minimums\n        h_min_vals = np.full((W, W), np.inf)\n        for r in range(W):\n            if np.all(np.isinf(prev_dp[r, :])):\n                continue\n            # Deque-based sliding window minimum for O(W) per row\n            q = []\n            for c in range(W):\n                # Window is [max(0, c-s), min(W-1, c+s)]\n                # Add current element\n                while q and prev_dp[r, q[-1]] = prev_dp[r, c]:\n                    q.pop()\n                q.append(c)\n                # Remove elements outside the right boundary of the *first* window C belongs to\n                # The window is centered at an index k, [k-s, k+s]\n                # We are at c. We want to find min for window centered at c-s.\n                # Window for k is [k-s, k+s]\n                # We need min for all k in range(W)\n            # The above logic is complex to map to a single pass. Let's use a simpler method.\n            # Simple (but slower O(W*s)) implementation of sliding window min for each row\n            for c in range(W):\n                c_min = max(0, c - s)\n                c_max = min(W, c + s + 1)\n                h_min_vals[r, c] = np.min(prev_dp[r, c_min:c_max])\n\n        # Precompute vertical sliding window minimums on the result of horizontal mins\n        min_prev_dp = np.full((W, W), np.inf)\n        for c in range(W):\n            if np.all(np.isinf(h_min_vals[:, c])):\n                continue\n            for r in range(W):\n                r_min = max(0, r - s)\n                r_max = min(W, r + s + 1)\n                min_prev_dp[r, c] = np.min(h_min_vals[r_min:r_max, c])\n        \n        # Compute dp for current layer j\n        for i_L in range(W):\n            for i_R in range(W):\n                min_cost = min_prev_dp[i_L, i_R]\n                if np.isinf(min_cost):\n                    continue\n                \n                cost_increment = 2.0 if i_L != i_R else 1.0\n                dp[j, i_L, i_R] = min_cost + cost_increment\n\n    # The minimal mass is the minimum of all states where the paths meet (i_L == i_R)\n    min_mass = np.inf\n    for j in range(H + 1):\n        for i in range(W):\n            min_mass = min(min_mass, dp[j, i, i])\n    \n    if np.isinf(min_mass):\n        return -1\n    else:\n        return int(min_mass)\n\ndef solve():\n    \"\"\"\n    Runs the solver for the given test suite and prints the formatted output.\n    \"\"\"\n    test_cases = [\n        (9, 5, 1),   # Case A\n        (13, 3, 2),  # Case B\n        (11, 4, 1),  # Case C\n        (1, 0, 1),   # Case D\n        (20, 4, 3),  # Case E\n    ]\n\n    results = []\n    for W, H, s in test_cases:\n        result = solve_case(W, H, s)\n        results.append(result)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "2420423"}]}