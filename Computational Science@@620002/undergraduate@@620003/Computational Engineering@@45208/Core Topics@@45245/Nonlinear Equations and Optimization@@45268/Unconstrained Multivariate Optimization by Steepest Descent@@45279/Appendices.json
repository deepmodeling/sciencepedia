{"hands_on_practices": [{"introduction": "Before applying an algorithm, it is crucial to understand its fundamental properties. This first practice explores the geometry of the steepest descent method. By implementing it for quadratic functions and observing its behavior under coordinate rotation and scaling, you will gain a deep, intuitive understanding of why the algorithm can be very slow and how preconditioning—a form of scaling—can dramatically speed it up [@problem_id:2448741]. This exercise forms the bedrock for analyzing and improving gradient-based optimization methods.", "problem": "Write a complete, runnable program that implements steepest descent (also called gradient descent in the Euclidean norm) with exact line search for unconstrained multivariate optimization of quadratic functions and uses it to numerically demonstrate the following two facts: (i) steepest descent is invariant under rotations of the coordinate system, and (ii) the performance of steepest descent is highly dependent on scaling of the variables. The only foundational facts you may assume are the definition of the gradient as the direction of steepest ascent in the Euclidean norm, the definition of steepest descent as moving along the negative gradient direction, and the definition of exact line search as choosing the step length that minimizes the objective function along the ray defined by the current point and descent direction. You must derive any other formulas you need inside your solution.\n\nImplement steepest descent for quadratic objectives of the form\n$$\nf(\\mathbf{x}) = \\tfrac{1}{2}\\,\\mathbf{x}^\\top A \\,\\mathbf{x} - \\mathbf{b}^\\top \\mathbf{x} + c,\n$$\nwhere $A$ is symmetric positive definite (SPD), $\\mathbf{b}$ is a vector, and $c$ is a scalar. For exact line search, at iteration $k$ with current point $\\mathbf{x}_k$ and gradient $\\nabla f(\\mathbf{x}_k)$, define the univariate function along the ray $\\phi(\\alpha) = f(\\mathbf{x}_k - \\alpha \\,\\nabla f(\\mathbf{x}_k))$ and choose $\\alpha_k$ to minimize $\\phi(\\alpha)$.\n\nYour program must run the following three test cases and aggregate their results into a single-line output. All angles must be in radians.\n\nTest case 1 (rotation invariance check):\n- Dimension $n=2$. Use $A_1 = \\begin{bmatrix} 3 & 1 \\\\ 1 & 2 \\end{bmatrix}$ and $\\mathbf{b}_1=\\begin{bmatrix} 0 \\\\ 0 \\end{bmatrix}$. Let the rotation angle be $\\theta = \\pi/6$ (that is, $30$ degrees), and let the rotation matrix be $R=\\begin{bmatrix} \\cos\\theta & -\\sin\\theta \\\\ \\sin\\theta & \\cos\\theta\\end{bmatrix}$. Define the rotated quadratic by $f_R(\\mathbf{y}) = f(R\\,\\mathbf{y})$, equivalently $A_R = R^\\top A_1 R$, $\\mathbf{b}_R = R^\\top \\mathbf{b}_1$.\n- Start from $\\mathbf{x}_0=\\begin{bmatrix}2\\\\-1\\end{bmatrix}$ in the original coordinates and from $\\mathbf{y}_0=R^\\top \\mathbf{x}_0$ in the rotated coordinates.\n- Run exactly $K=20$ steepest descent iterations with exact line search in both coordinate systems (do not stop early by tolerance).\n- Define the boolean result $T_1$ to be true if, for every iteration index $k\\in\\{0,1,\\dots,K\\}$, the corresponding iterates satisfy $\\|\\mathbf{y}_k - R^\\top \\mathbf{x}_k\\|_\\infty \\le 10^{-10}$, and false otherwise. Here $\\|\\cdot\\|_\\infty$ denotes the infinity norm.\n\nTest case 2 (scaling sensitivity of performance):\n- Dimension $n=2$. Use $A_2=\\operatorname{diag}(1,100)$ and $\\mathbf{b}_2=\\begin{bmatrix}0\\\\0\\end{bmatrix}$.\n- Consider the diagonal scaling matrix $S=\\operatorname{diag}(1,10)$ and the scaled coordinates $\\mathbf{y} = S \\mathbf{x}$, which induces the scaled quadratic $f_S(\\mathbf{y}) = f(S^{-1}\\mathbf{y})$. In quadratic form, this corresponds to $A_S=S^{-\\top} A_2 S^{-1}$ and $\\mathbf{b}_S=S^{-\\top}\\mathbf{b}_2$.\n- Use the same physical starting point represented in both coordinates: $\\mathbf{x}_0=\\begin{bmatrix}1\\\\1\\end{bmatrix}$ and $\\mathbf{y}_0=S\\,\\mathbf{x}_0$.\n- Run steepest descent with exact line search in each coordinate system until the Euclidean norm of the gradient is at most $10^{-8}$, with a maximum of $10^5$ iterations to prevent infinite loops. Record the number of iterations $\\text{iters}_\\text{unscaled}$ for the unscaled run on $(A_2,\\mathbf{b}_2)$ and $\\text{iters}_\\text{scaled}$ for the scaled run on $(A_S,\\mathbf{b}_S)$.\n- Define the test output as the floating-point ratio $r=\\text{iters}_\\text{unscaled}/\\text{iters}_\\text{scaled}$.\n\nTest case 3 (isotropic edge case):\n- Dimension $n=2$. Use $A_3=5 I_2$ and $\\mathbf{b}_3=\\begin{bmatrix}0\\\\0\\end{bmatrix}$, starting from $\\mathbf{x}_0=\\begin{bmatrix}3\\\\-4\\end{bmatrix}$.\n- Run steepest descent with exact line search until the Euclidean norm of the gradient is at most $10^{-12}$, with a maximum of $10^5$ iterations. Record the number of iterations $N_3$ required to meet the tolerance.\n\nProgram output format:\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, with no spaces, in the order $[T_1, r, N_3]$. Here $T_1$ is a boolean literal, $r$ is a floating-point number, and $N_3$ is an integer. For example, an output could look like $[True,123.0,1]$.", "solution": "The problem requires the implementation of the steepest descent algorithm with exact line search for unconstrained optimization of quadratic functions. This implementation will be used to numerically demonstrate the algorithm's invariance to coordinate system rotations and its sensitivity to variable scaling. The entire process, from first principles to final implementation, is detailed below.\n\nA general quadratic objective function is given by\n$$\nf(\\mathbf{x}) = \\tfrac{1}{2}\\,\\mathbf{x}^\\top A \\,\\mathbf{x} - \\mathbf{b}^\\top \\mathbf{x} + c\n$$\nwhere $A \\in \\mathbb{R}^{n \\times n}$ is a symmetric positive definite (SPD) matrix, $\\mathbf{b} \\in \\mathbb{R}^n$ is a vector, and $c \\in \\mathbb{R}$ is a scalar constant. The SPD property of $A$ ensures that $f(\\mathbf{x})$ is strictly convex and possesses a unique global minimum.\n\nThe steepest descent method is an iterative algorithm that, starting from an initial guess $\\mathbf{x}_0$, generates a sequence of points $\\{\\mathbf{x}_k\\}$ that converge to the minimizer of $f(\\mathbf{x})$. At each iteration $k$, the method proceeds in the direction of the negative gradient, which is the direction of steepest descent in the Euclidean norm. The update rule is:\n$$\n\\mathbf{x}_{k+1} = \\mathbf{x}_k - \\alpha_k \\nabla f(\\mathbf{x}_k)\n$$\nwhere $\\alpha_k > 0$ is the step length. The problem specifies an exact line search, meaning $\\alpha_k$ is chosen to minimize the objective function along the search direction.\n\nTo implement this algorithm, we must derive two key formulas: the gradient of $f(\\mathbf{x})$ and the optimal step length $\\alpha_k$.\n\nFirst, we derive the gradient of the quadratic function, $\\nabla f(\\mathbf{x})$. Using elementary matrix calculus, or by differentiating with respect to each component $x_i$, we analyze the terms of $f(\\mathbf{x})$:\n$f(\\mathbf{x}) = \\frac{1}{2} \\sum_{i,j} A_{ij} x_i x_j - \\sum_i b_i x_i + c$.\nThe partial derivative with respect to $x_k$ is:\n$$\n\\frac{\\partial f}{\\partial x_k} = \\frac{\\partial}{\\partial x_k} \\left( \\frac{1}{2} \\sum_{i,j} A_{ij} x_i x_j \\right) - \\frac{\\partial}{\\partial x_k} \\left( \\sum_i b_i x_i \\right) + \\frac{\\partial c}{\\partial x_k}\n$$\nThe derivative of the constant $c$ is $0$. The derivative of the linear term is $\\frac{\\partial}{\\partial x_k} (\\sum_i b_i x_i) = b_k$. For the quadratic term, using the product rule and the symmetry of $A$ ($A_{ij}=A_{ji}$):\n$$\n\\frac{\\partial}{\\partial x_k} \\left( \\frac{1}{2} \\sum_{i,j} A_{ij} x_i x_j \\right) = \\frac{1}{2} \\sum_{i,j} A_{ij} (\\delta_{ik}x_j + x_i\\delta_{jk}) = \\frac{1}{2} \\left( \\sum_j A_{kj} x_j + \\sum_i A_{ik} x_i \\right) = \\frac{1}{2} \\left( [A\\mathbf{x}]_k + [A^\\top\\mathbf{x}]_k \\right) = [A\\mathbf{x}]_k\n$$\nwhere $[ \\cdot ]_k$ denotes the $k$-th component. Assembling the components into a vector gives the gradient:\n$$\n\\nabla f(\\mathbf{x}) = A\\mathbf{x} - \\mathbf{b}\n$$\n\nNext, we derive the formula for the optimal step length $\\alpha_k$ for exact line search. We define a univariate function $\\phi(\\alpha) = f(\\mathbf{x}_k - \\alpha \\mathbf{g}_k)$, where $\\mathbf{g}_k = \\nabla f(\\mathbf{x}_k)$ is the gradient at the current iterate $\\mathbf{x}_k$. We seek $\\alpha > 0$ that minimizes $\\phi(\\alpha)$. We find this by setting its derivative to zero: $\\frac{d\\phi}{d\\alpha} = 0$.\nSubstituting $\\mathbf{x} = \\mathbf{x}_k - \\alpha \\mathbf{g}_k$ into the expression for $f(\\mathbf{x})$:\n$$\n\\phi(\\alpha) = \\tfrac{1}{2}(\\mathbf{x}_k - \\alpha \\mathbf{g}_k)^\\top A (\\mathbf{x}_k - \\alpha \\mathbf{g}_k) - \\mathbf{b}^\\top(\\mathbf{x}_k - \\alpha \\mathbf{g}_k) + c\n$$\nExpanding this expression and grouping terms by powers of $\\alpha$:\n$$\n\\phi(\\alpha) = \\left( \\tfrac{1}{2}\\mathbf{x}_k^\\top A \\mathbf{x}_k - \\mathbf{b}^\\top \\mathbf{x}_k + c \\right) - \\alpha(\\mathbf{g}_k^\\top A \\mathbf{x}_k - \\mathbf{g}_k^\\top \\mathbf{b}) + \\tfrac{1}{2}\\alpha^2(\\mathbf{g}_k^\\top A \\mathbf{g}_k)\n$$\nThe first term is simply $f(\\mathbf{x}_k)$. The coefficient of the linear term in $\\alpha$ simplifies using $\\mathbf{g}_k = A\\mathbf{x}_k - \\mathbf{b}$, so $\\mathbf{g}_k^\\top A \\mathbf{x}_k - \\mathbf{g}_k^\\top \\mathbf{b} = \\mathbf{g}_k^\\top (A\\mathbf{x}_k - \\mathbf{b}) = \\mathbf{g}_k^\\top \\mathbf{g}_k$.\nThus, $\\phi(\\alpha)$ is a simple quadratic in $\\alpha$:\n$$\n\\phi(\\alpha) = f(\\mathbf{x}_k) - \\alpha(\\mathbf{g}_k^\\top \\mathbf{g}_k) + \\tfrac{1}{2}\\alpha^2(\\mathbf{g}_k^\\top A \\mathbf{g}_k)\n$$\nDifferentiating with respect to $\\alpha$ and setting the result to zero gives:\n$$\n\\frac{d\\phi}{d\\alpha} = -(\\mathbf{g}_k^\\top \\mathbf{g}_k) + \\alpha(\\mathbf{g}_k^\\top A \\mathbf{g}_k) = 0\n$$\nSolving for $\\alpha$ yields the optimal step length:\n$$\n\\alpha_k = \\frac{\\mathbf{g}_k^\\top \\mathbf{g}_k}{\\mathbf{g}_k^\\top A \\mathbf{g}_k}\n$$\nThe second derivative, $\\frac{d^2\\phi}{d\\alpha^2} = \\mathbf{g}_k^\\top A \\mathbf{g}_k$, is positive since $A$ is SPD and $\\mathbf{g}_k \\neq \\mathbf{0}$ (if not at the minimum), confirming this is a minimum.\n\nThe complete steepest descent algorithm for quadratic optimization is:\n1. Initialize $\\mathbf{x}_0$. For $k=0, 1, 2, \\dots$:\n2. Compute the gradient: $\\mathbf{g}_k = A\\mathbf{x}_k - \\mathbf{b}$.\n3. Check for convergence, e.g., if $\\|\\mathbf{g}_k\\|_2 \\le \\epsilon$.\n4. Compute the step length: $\\alpha_k = (\\mathbf{g}_k^\\top \\mathbf{g}_k) / (\\mathbf{g}_k^\\top A \\mathbf{g}_k)$.\n5. Update the position: $\\mathbf{x}_{k+1} = \\mathbf{x}_k - \\alpha_k \\mathbf{g}_k$.\n\nThe problem's test cases are designed to demonstrate key properties of this algorithm.\n\nTest Case 1 (Rotation Invariance): When the coordinate system is rotated by a matrix $R$ (where $R^\\top R = I$), a point $\\mathbf{x}$ becomes $\\mathbf{y} = R^\\top \\mathbf{x}$. The objective function transforms from $f(\\mathbf{x})$ to $f_R(\\mathbf{y}) = f(R\\mathbf{y})$. This leads to new quadratic parameters $A_R=R^\\top A R$ and $\\mathbf{b}_R=R^\\top \\mathbf{b}$. The gradient transforms covariantly: $\\mathbf{g}_k^y = R^\\top \\mathbf{g}_k^x$. Both the numerator $(\\mathbf{g}_k^y)^\\top \\mathbf{g}_k^y = (\\mathbf{g}_k^x)^\\top R R^\\top \\mathbf{g}_k^x = (\\mathbf{g}_k^x)^\\top \\mathbf{g}_k^x$ and the denominator $(\\mathbf{g}_k^y)^\\top A_R \\mathbf{g}_k^y = (\\mathbf{g}_k^x)^\\top R(R^\\top A R)R^\\top \\mathbf{g}_k^x = (\\mathbf{g}_k^x)^\\top A \\mathbf{g}_k^x$ of the step length formula are invariant under rotation. Thus, $\\alpha_k^y = \\alpha_k^x$. By induction, if $\\mathbf{y}_k = R^\\top \\mathbf{x}_k$, then $\\mathbf{y}_{k+1} = \\mathbf{y}_k - \\alpha_k^y \\mathbf{g}_k^y = R^\\top \\mathbf{x}_k - \\alpha_k^x R^\\top \\mathbf{g}_k^x = R^\\top(\\mathbf{x}_k - \\alpha_k^x \\mathbf{g}_k^x) = R^\\top \\mathbf{x}_{k+1}$. The sequence of iterates in the rotated system is simply the rotated sequence of original iterates. The test confirms this identity numerically.\n\nTest Case 2 (Scaling Sensitivity): The convergence rate of steepest descent is governed by the condition number $\\kappa(A) = \\lambda_{\\max}(A)/\\lambda_{\\min}(A)$. For the unscaled problem, $A_2 = \\operatorname{diag}(1, 100)$, so $\\kappa(A_2) = 100/1 = 100$. This high condition number implies that the level sets of the quadratic are highly elongated ellipses, causing the steepest descent path to zigzag slowly towards the minimum. For the scaled problem, the change of variables $\\mathbf{y}=S\\mathbf{x}$ with $S=\\operatorname{diag}(1,10)$ leads to a new matrix $A_S = S^{-\\top} A_2 S^{-1}$. Since $S$ is diagonal, $S^{-\\top} = S^{-1} = \\operatorname{diag}(1, 1/10)$. The calculation becomes $A_S = \\operatorname{diag}(1, 1/10) \\operatorname{diag}(1, 100) \\operatorname{diag}(1, 1/10) = \\operatorname{diag}(1, 1) = I_2$. The new system is isotropic with $\\kappa(A_S) = 1/1 = 1$. For an isotropic quadratic, steepest descent converges in a single step, as the gradient points directly towards the minimum. This test case demonstrates a dramatic improvement in performance due to preconditioning (scaling).\n\nTest Case 3 (Isotropic Edge Case): This case uses $A_3 = 5I_2$, which is also perfectly conditioned with $\\kappa(A_3)=1$. As in the scaled problem of Test Case 2, the gradient at any point $\\mathbf{x}_0$ points directly to the minimum at $\\mathbf{x}^* = \\mathbf{0}$. The exact line search will choose $\\alpha_0$ to travel this entire distance, resulting in convergence in a single iteration. This will be verified numerically.\n\nThe implementation will follow these principles, encapsulating the algorithm in a reusable function and applying it to the three specified scenarios.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef steepest_descent(A, b, x0, tol=None, max_iter=None, fixed_iter=None):\n    \"\"\"\n    Implements steepest descent with exact line search for f(x) = 0.5*x.T*A*x - b.T*x.\n\n    The function can run for a fixed number of iterations or until a tolerance is met.\n\n    Args:\n        A (np.ndarray): The symmetric positive definite matrix A.\n        b (np.ndarray): The vector b.\n        x0 (np.ndarray): The initial point x0.\n        tol (float, optional): The tolerance for the Euclidean norm of the gradient.\n                               Used as a stopping criterion.\n        max_iter (int, optional): The maximum number of iterations. Used with `tol`.\n        fixed_iter (int, optional): If provided, run for exactly this many iterations\n                                    and return all iterates.\n\n    Returns:\n        If `fixed_iter` is provided:\n            list[np.ndarray]: A list containing all iterates from x0 to x_K.\n        If `tol` and `max_iter` are provided:\n            tuple[np.ndarray, int]: The final point and the number of iterations taken.\n    \"\"\"\n    x = x0.astype(np.float64)\n\n    if fixed_iter is not None:\n        iterates = [x.copy()]\n        for _ in range(fixed_iter):\n            # Compute gradient g = Ax - b\n            g = A @ x - b\n            \n            # Numerator of alpha: g.T * g\n            gg = g.T @ g\n            \n            # If gradient is effectively zero, an optimum is reached.\n            # Avoid division by zero and stay at the current point.\n            if gg < 1e-30:\n                x = x\n            else:\n                # Denominator of alpha: g.T * A * g\n                gAg = g.T @ A @ g\n                alpha = gg / gAg\n                \n                # Update x: x_{k+1} = x_k - alpha * g_k\n                x = x - alpha * g\n            \n            iterates.append(x.copy())\n        return iterates\n    else:\n        for k in range(max_iter):\n            g = A @ x - b\n            grad_norm = np.linalg.norm(g)\n            \n            if grad_norm <= tol:\n                return x, k\n            \n            gg = g.T @ g\n            \n            # This check is theoretically redundant if tol > 0, but good practice.\n            if gg < 1e-30:\n                return x, k\n                \n            gAg = g.T @ A @ g\n            alpha = gg / gAg\n            x = x - alpha * g\n        \n        # Return last state if max_iter is reached before tolerance\n        return x, max_iter\n\ndef solve():\n    \"\"\"\n    Runs the three test cases and prints the results in the required format.\n    \"\"\"\n    results = []\n    \n    # --- Test Case 1: Rotation Invariance ---\n    A1 = np.array([[3.0, 1.0], [1.0, 2.0]])\n    b1 = np.array([0.0, 0.0])\n    x0_1 = np.array([2.0, -1.0])\n    theta = np.pi / 6.0\n    c, s = np.cos(theta), np.sin(theta)\n    R = np.array([[c, -s], [s, c]])\n    \n    A_R = R.T @ A1 @ R\n    b_R = R.T @ b1\n    y0_1 = R.T @ x0_1\n    \n    K = 20\n    x_iterates = steepest_descent(A=A1, b=b1, x0=x0_1, fixed_iter=K)\n    y_iterates = steepest_descent(A=A_R, b=b_R, x0=y0_1, fixed_iter=K)\n    \n    t1_check = True\n    for k in range(K + 1):\n        # Check if ||y_k - R.T * x_k||_inf <= 1e-10\n        diff = y_iterates[k] - R.T @ x_iterates[k]\n        inf_norm = np.linalg.norm(diff, ord=np.inf)\n        if inf_norm > 1e-10:\n            t1_check = False\n            break\n    results.append(t1_check)\n    \n    # --- Test Case 2: Scaling Sensitivity ---\n    A2 = np.array([[1.0, 0.0], [0.0, 100.0]])\n    b2 = np.array([0.0, 0.0])\n    x0_2 = np.array([1.0, 1.0])\n    \n    S = np.array([[1.0, 0.0], [0.0, 10.0]])\n    S_inv = np.linalg.inv(S)\n    \n    A_S = S_inv.T @ A2 @ S_inv\n    b_S = S_inv.T @ b2\n    y0_2 = S @ x0_2\n    \n    tol_2 = 1e-8\n    max_iter_2 = 100000\n    \n    _, iters_unscaled = steepest_descent(A=A2, b=b2, x0=x0_2, tol=tol_2, max_iter=max_iter_2)\n    _, iters_scaled = steepest_descent(A=A_S, b=b_S, x0=y0_2, tol=tol_2, max_iter=max_iter_2)\n    \n    r = float(iters_unscaled) / float(iters_scaled) if iters_scaled > 0 else float('inf')\n    results.append(r)\n    \n    # --- Test Case 3: Isotropic Edge Case ---\n    A3 = np.array([[5.0, 0.0], [0.0, 5.0]]) # 5 * I_2\n    b3 = np.array([0.0, 0.0])\n    x0_3 = np.array([3.0, -4.0])\n    \n    tol_3 = 1e-12\n    max_iter_3 = 100000\n    \n    _, n3 = steepest_descent(A=A3, b=b3, x0=x0_3, tol=tol_3, max_iter=max_iter_3)\n    results.append(n3)\n    \n    # Final print statement in the exact required format.\n    print(f\"[{results[0]},{results[1]},{results[2]}]\")\n\nsolve()\n\n```", "id": "2448741"}, {"introduction": "Real-world optimization problems are rarely as simple as a single convex bowl. This practice moves beyond quadratics to the non-convex Himmelblau function, a classic benchmark with multiple local minima. By running steepest descent from different starting points, you will directly observe the concept of 'basins of attraction' and confirm that this local search method is not guaranteed to find the global optimum [@problem_id:2448739]. This experience underscores the critical importance of initialization strategies in practical applications.", "problem": "Design and implement a program that, for the bivariate Himmelblau function defined by\n$$\nf(x,y) = \\left(x^2 + y - 11\\right)^2 + \\left(x + y^2 - 7\\right)^2,\n$$\nperforms steepest descent from multiple initial points and summarizes the terminal behavior. For a point $\\mathbf{x}_k = [x_k, y_k]^\\top \\in \\mathbb{R}^2$, define the steepest descent iteration by\n$$\n\\mathbf{x}_{k+1} = \\mathbf{x}_k - \\alpha_k \\nabla f(\\mathbf{x}_k),\n$$\nwhere $\\alpha_k$ is chosen to be a minimizer of the one-dimensional function\n$$\n\\phi_k(\\alpha) = f\\left(\\mathbf{x}_k - \\alpha \\nabla f(\\mathbf{x}_k)\\right)\n$$\nover the closed interval $\\alpha \\in [0,1]$. Use the Euclidean norm for vectors. Terminate the iteration when either $\\lVert \\nabla f(\\mathbf{x}_k) \\rVert_2 \\leq \\tau$ or $k \\geq k_{\\max}$, where $\\tau = 10^{-8}$ and $k_{\\max} = 10000$. The gradient $\\nabla f(x,y)$ is taken in the standard sense of multivariate calculus.\n\nFor each initial point in the following test suite (listed in the given order),\n$$\n(3, 2),\\quad (0, 0),\\quad (-3, -3),\\quad (-4, 4),\\quad (5, 5),\\quad (3.5, -2.5),\n$$\nrun the steepest descent method as specified and record:\n- the final iterate $\\left(x^\\star, y^\\star\\right)$ at termination,\n- the function value $f\\left(x^\\star, y^\\star\\right)$,\n- the total number of iterations $k$ executed,\n- and an integer label identifying which of the four known local minimizers the final point is nearest to in Euclidean distance:\n  - $m_0 = (3.000000, 2.000000)$,\n  - $m_1 = (-2.805118, 3.131312)$,\n  - $m_2 = (-3.779310, -3.283186)$,\n  - $m_3 = (3.584428, -1.848126)$.\nLet $d_j = \\lVert \\left(x^\\star, y^\\star\\right) - m_j \\rVert_2$ for $j \\in \\{0,1,2,3\\}$. If $\\min_j d_j \\leq 10^{-3}$, output the index $j$ attaining the minimum; otherwise, output $-1$.\n\nRequired numerical reporting:\n- Round $x^\\star$, $y^\\star$, and $f\\left(x^\\star, y^\\star\\right)$ to $6$ decimal places.\n- Report $k$ and the label as integers.\n\nYour program should produce a single line of output containing the results as a comma-separated list of lists, in the same order as the test suite, where each inner list is\n$$\n[x^\\star, y^\\star, f(x^\\star, y^\\star), k, \\text{label}].\n$$\nFor example, the overall format must be\n$$\n\\big[ [\\cdot,\\cdot,\\cdot,\\cdot,\\cdot], [\\cdot,\\cdot,\\cdot,\\cdot,\\cdot], \\ldots \\big]\n$$\nprinted on a single line.", "solution": "The core of the problem is to minimize the bivariate Himmelblau function, defined as:\n$$\nf(x,y) = \\left(x^2 + y - 11\\right)^2 + \\left(x + y^2 - 7\\right)^2\n$$\nLet the vector of variables be $\\mathbf{x} = [x, y]^\\top$. The function can be written as $f(\\mathbf{x})$.\n\nThe steepest descent method is an iterative optimization algorithm that proceeds from an initial guess $\\mathbf{x}_0$ and generates a sequence of points $\\mathbf{x}_1, \\mathbf{x}_2, \\ldots$ intended to converge to a local minimum. The update rule for each iteration is given by:\n$$\n\\mathbf{x}_{k+1} = \\mathbf{x}_k + \\alpha_k \\mathbf{d}_k\n$$\nwhere $\\mathbf{d}_k$ is the search direction and $\\alpha_k > 0$ is the step size. For the method of steepest descent, the search direction is chosen to be the negative of the gradient of the objective function at the current point, as this is the direction in which the function's value decreases most rapidly. Thus,\n$$\n\\mathbf{d}_k = -\\nabla f(\\mathbf{x}_k)\n$$\nThe gradient of the Himmelblau function, $\\nabla f(\\mathbf{x}) = \\left[ \\frac{\\partial f}{\\partial x}, \\frac{\\partial f}{\\partial y} \\right]^\\top$, must be derived. The partial derivatives are:\n$$\n\\frac{\\partial f}{\\partial x} = 2(x^2 + y - 11)(2x) + 2(x + y^2 - 7)(1) = 4x(x^2 + y - 11) + 2(x + y^2 - 7)\n$$\n$$\n\\frac{\\partial f}{\\partial y} = 2(x^2 + y - 11)(1) + 2(x + y^2 - 7)(2y) = 2(x^2 + y - 11) + 4y(x + y^2 - 7)\n$$\n\nThe iterative formula is therefore:\n$$\n\\mathbf{x}_{k+1} = \\mathbf{x}_k - \\alpha_k \\nabla f(\\mathbf{x}_k)\n$$\nThe problem specifies that the step size $\\alpha_k$ must be chosen to minimize the function along the search direction. This is known as an exact line search. We define a one-dimensional function $\\phi_k(\\alpha)$:\n$$\n\\phi_k(\\alpha) = f(\\mathbf{x}_k - \\alpha \\nabla f(\\mathbf{x}_k))\n$$\nThe optimal step size $\\alpha_k$ is the value of $\\alpha$ that minimizes $\\phi_k(\\alpha)$ over the specified closed interval $[0, 1]$.\n$$\n\\alpha_k = \\arg\\min_{\\alpha \\in [0, 1]} \\phi_k(\\alpha)\n$$\nThis one-dimensional minimization is a standard subproblem that can be solved numerically using established methods, for instance, by using a library routine such as `scipy.optimize.minimize_scalar` with the `bounded` method.\n\nThe iterative process continues until one of two termination criteria is satisfied:\n1.  The magnitude of the gradient falls below a specified tolerance $\\tau = 10^{-8}$. This indicates that the iterate is near a stationary point (a minimum, maximum, or saddle point). The condition is $\\lVert \\nabla f(\\mathbf{x}_k) \\rVert_2 \\leq \\tau$.\n2.  The number of iterations $k$ reaches a maximum limit $k_{\\max} = 10000$. This prevents an infinite loop in cases of slow or non-convergence.\n\nUpon termination at iteration $k$ with final point $\\mathbf{x}^\\star = \\mathbf{x}_k$, the following data are recorded:\n- The final coordinates $(x^\\star, y^\\star)$.\n- The final function value $f(x^\\star, y^\\star)$.\n- The total number of iterations $k$.\n- A classification label.\n\nThe classification label is determined by comparing the final point $\\mathbf{x}^\\star$ to the four known local minimizers of the Himmelblau function:\n- $m_0 = (3.000000, 2.000000)$\n- $m_1 = (-2.805118, 3.131312)$\n- $m_2 = (-3.779310, -3.283186)$\n- $m_3 = (3.584428, -1.848126)$\n\nThe Euclidean distance $d_j = \\lVert \\mathbf{x}^\\star - m_j \\rVert_2$ is computed for each $j \\in \\{0, 1, 2, 3\\}$. If the minimum of these distances, $\\min_j d_j$, is less than or equal to $10^{-3}$, the label is the index $j$ corresponding to this minimum distance. This signifies successful convergence to the neighborhood of a known minimizer. If $\\min_j d_j > 10^{-3}$, the label is $-1$, indicating that the algorithm terminated at a point not sufficiently close to any of the known minimizers.\n\nThe computational procedure for each given initial point is as follows:\n1.  Initialize $\\mathbf{x}_0$ and set the iteration counter $k = 0$.\n2.  Begin the main loop:\n    a. Calculate the gradient vector $\\nabla f(\\mathbf{x}_k)$.\n    b. Calculate the gradient norm $\\lVert \\nabla f(\\mathbf{x}_k) \\rVert_2$.\n    c. If $\\lVert \\nabla f(\\mathbf{x}_k) \\rVert_2 \\leq 10^{-8}$ or $k \\geq 10000$, terminate the loop.\n    d. Define the line search function $\\phi_k(\\alpha) = f(\\mathbf{x}_k - \\alpha \\nabla f(\\mathbf{x}_k))$.\n    e. Find $\\alpha_k = \\arg\\min_{\\alpha \\in [0, 1]} \\phi_k(\\alpha)$ using a numerical solver.\n    f. Update the iterate: $\\mathbf{x}_{k+1} = \\mathbf{x}_k - \\alpha_k \\nabla f(\\mathbf{x}_k)$.\n    g. Increment the iteration counter: $k \\leftarrow k+1$.\n3.  After termination, perform the classification and reporting steps as described above, ensuring numerical values are rounded to $6$ decimal places as required.\nThis entire procedure is repeated for each of the specified initial points.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.optimize import minimize_scalar\n\ndef solve():\n    \"\"\"\n    Implements the steepest descent algorithm for the Himmelblau function\n    from multiple starting points and formats the results.\n    \"\"\"\n    # Define problem constants and parameters\n    TOLERANCE = 1e-8\n    MAX_ITERATIONS = 10000\n    DISTANCE_THRESHOLD = 1e-3\n\n    # Define the Himmelblau function\n    def f(x, y):\n        return (x**2 + y - 11)**2 + (x + y**2 - 7)**2\n\n    # Define the gradient of the Himmelblau function\n    def grad_f(x, y):\n        df_dx = 4 * x * (x**2 + y - 11) + 2 * (x + y**2 - 7)\n        df_dy = 2 * (x**2 + y - 11) + 4 * y * (x + y**2 - 7)\n        return np.array([df_dx, df_dy])\n\n    # Known local minimizers of the Himmelblau function\n    minimizers = np.array([\n        [3.0, 2.0],\n        [-2.805118, 3.131312],\n        [-3.779310, -3.283186],\n        [3.584428, -1.848126]\n    ])\n\n    # Test suite of initial points\n    test_cases = [\n        (3.0, 2.0),\n        (0.0, 0.0),\n        (-3.0, -3.0),\n        (-4.0, 4.0),\n        (5.0, 5.0),\n        (3.5, -2.5)\n    ]\n\n    all_results = []\n\n    for initial_point in test_cases:\n        x_k = np.array(initial_point, dtype=float)\n        \n        # Iteration loop for steepest descent\n        k = 0\n        while k < MAX_ITERATIONS:\n            grad = grad_f(x_k[0], x_k[1])\n            grad_norm = np.linalg.norm(grad)\n\n            # Termination condition: gradient norm is below tolerance\n            if grad_norm <= TOLERANCE:\n                break\n\n            # Descent direction\n            d_k = -grad\n\n            # Line search for optimal step size alpha\n            # Define the 1D function to minimize\n            phi = lambda alpha: f(x_k[0] + alpha * d_k[0], x_k[1] + alpha * d_k[1])\n            \n            # Use a bounded scalar minimizer to find alpha in [0, 1]\n            res = minimize_scalar(phi, bounds=(0, 1), method='bounded')\n            alpha_k = res.x\n\n            # Update the iterate\n            x_k = x_k + alpha_k * d_k\n            \n            k += 1\n\n        # At this point, the loop has terminated. 'k' is the number of iterations.\n        x_star, y_star = x_k[0], x_k[1]\n        f_star = f(x_star, y_star)\n\n        # Classification: find the closest known minimizer\n        distances = np.linalg.norm(minimizers - x_k, axis=1)\n        min_dist_idx = np.argmin(distances)\n        min_dist = distances[min_dist_idx]\n        \n        label = -1\n        if min_dist <= DISTANCE_THRESHOLD:\n            label = int(min_dist_idx)\n        \n        # Store results for this case\n        all_results.append([x_star, y_star, f_star, k, label])\n\n    # Format the final output string according to the specification\n    result_parts = []\n    for res in all_results:\n        x_s, y_s, f_s, num_iter, lab = res\n        part = f\"[{x_s:.6f},{y_s:.6f},{f_s:.6f},{num_iter},{lab}]\"\n        result_parts.append(part)\n    \n    final_output = f\"[{','.join(result_parts)}]\"\n    print(final_output)\n\nsolve()\n```", "id": "2448739"}, {"introduction": "The steepest descent algorithm we have explored so far is a 'batch' method, meaning it calculates the true gradient using the entire dataset at each step, which is often computationally infeasible for large-scale problems. This final practice introduces Stochastic Gradient Descent (SGD), the workhorse of modern machine learning, which uses a noisy but computationally cheap approximation of the gradient from a small, random 'mini-batch' of data [@problem_id:2448678]. You will implement SGD for fundamental machine learning tasks, gaining hands-on experience with the trade-offs between computational cost, gradient noise, and convergence.", "problem": "Consider unconstrained minimization of empirical risk functions in finite-dimensional Euclidean spaces. For each test case below, let the dimension be $d \\in \\mathbb{N}$ and the number of data points be $n \\in \\mathbb{N}$. Let the data be $\\{(\\mathbf{a}_i, b_i)\\}_{i=1}^n$ with $\\mathbf{a}_i \\in \\mathbb{R}^d$ and $b_i \\in \\mathbb{R}$, or $\\{(\\mathbf{a}_i, y_i)\\}_{i=1}^n$ with $\\mathbf{a}_i \\in \\mathbb{R}^d$ and labels $y_i \\in \\{-1,+1\\}$. Define the empirical risk $F(\\mathbf{w})$ as follows for each case, where $\\mathbf{w} \\in \\mathbb{R}^d$:\n- Least-squares cases: $F(\\mathbf{w}) = \\dfrac{1}{n}\\sum_{i=1}^n \\left(\\mathbf{a}_i^\\top \\mathbf{w} - b_i\\right)^2$.\n- Logistic case with $\\ell_2$ regularization parameter $\\lambda > 0$: $F(\\mathbf{w}) = \\dfrac{1}{n}\\sum_{i=1}^n \\log\\!\\left(1+\\exp\\!\\left(-y_i\\,\\mathbf{a}_i^\\top \\mathbf{w}\\right)\\right) + \\dfrac{\\lambda}{2}\\,\\|\\mathbf{w}\\|_2^2$.\n\nLet $\\{\\alpha_k\\}_{k=0}^{T-1}$ be step sizes given by $\\alpha_k = \\dfrac{\\eta}{\\sqrt{k+1}}$ for a specified $\\eta > 0$, and let the initialization be $\\mathbf{w}_0 \\in \\mathbb{R}^d$. For each iteration $k \\in \\{0,1,\\dots,T-1\\}$, construct a mini-batch $\\mathcal{S}_k$ by sampling $m$ indices independently with replacement from the set $\\{1,2,\\dots,n\\}$ using a pseudo-random generator seeded as specified for the case. Define the stochastic direction $\\mathbf{g}_k$ by\n- Least-squares cases: $\\mathbf{g}_k = \\dfrac{1}{m} \\sum_{i \\in \\mathcal{S}_k} \\nabla \\ell_i(\\mathbf{w}_k)$ with $\\ell_i(\\mathbf{w}) = \\left(\\mathbf{a}_i^\\top \\mathbf{w} - b_i\\right)^2$.\n- Logistic case: $\\mathbf{g}_k = \\left(\\dfrac{1}{m} \\sum_{i \\in \\mathcal{S}_k} \\nabla \\ell_i(\\mathbf{w}_k)\\right) + \\lambda \\mathbf{w}_k$ with $\\ell_i(\\mathbf{w}) = \\log\\!\\left(1+\\exp\\!\\left(-y_i\\,\\mathbf{a}_i^\\top \\mathbf{w}\\right)\\right)$.\n\nUpdate the iterate by $\\mathbf{w}_{k+1} = \\mathbf{w}_k - \\alpha_k \\mathbf{g}_k$. After $T$ iterations, report the final empirical risk value $F(\\mathbf{w}_T)$ for each case, rounded to $6$ decimal places.\n\nThe test suite consists of the following three cases. All vectors are written as columns and all numbers are real. Angles are not involved. No physical units are involved.\n\nCase A (least squares in $\\mathbb{R}^2$):\n- $d = 2$, $n = 4$, $m = 1$, $T = 4000$, $\\eta = 0.5$, seed $= 12345$.\n- Data $\\{(\\mathbf{a}_i,b_i)\\}_{i=1}^4$:\n  - $\\mathbf{a}_1 = \\begin{bmatrix}1 \\\\ 0\\end{bmatrix}$, $b_1 = 1$.\n  - $\\mathbf{a}_2 = \\begin{bmatrix}0 \\\\ 1\\end{bmatrix}$, $b_2 = 2$.\n  - $\\mathbf{a}_3 = \\begin{bmatrix}1 \\\\ 1\\end{bmatrix}$, $b_3 = 2.5$.\n  - $\\mathbf{a}_4 = \\begin{bmatrix}2 \\\\ 1\\end{bmatrix}$, $b_4 = 3.5$.\n- Initialization $\\mathbf{w}_0 = \\begin{bmatrix}0 \\\\ 0\\end{bmatrix}$.\n\nCase B (logistic in $\\mathbb{R}^3$ with $\\ell_2$ regularization):\n- $d = 3$, $n = 6$, $m = 2$, $T = 8000$, $\\eta = 0.7$, seed $= 2021$, $\\lambda = 0.1$.\n- Data $\\{(\\mathbf{a}_i,y_i)\\}_{i=1}^6$:\n  - $\\mathbf{a}_1 = \\begin{bmatrix}2 \\\\ 0 \\\\ 1\\end{bmatrix}$, $y_1 = +1$.\n  - $\\mathbf{a}_2 = \\begin{bmatrix}0 \\\\ 2 \\\\ 1\\end{bmatrix}$, $y_2 = +1$.\n  - $\\mathbf{a}_3 = \\begin{bmatrix}-2 \\\\ 0 \\\\ 1\\end{bmatrix}$, $y_3 = -1$.\n  - $\\mathbf{a}_4 = \\begin{bmatrix}0 \\\\ -2 \\\\ 1\\end{bmatrix}$, $y_4 = -1$.\n  - $\\mathbf{a}_5 = \\begin{bmatrix}1 \\\\ 1 \\\\ 1\\end{bmatrix}$, $y_5 = +1$.\n  - $\\mathbf{a}_6 = \\begin{bmatrix}-1 \\\\ -1 \\\\ 1\\end{bmatrix}$, $y_6 = -1$.\n- Initialization $\\mathbf{w}_0 = \\begin{bmatrix}0 \\\\ 0 \\\\ 0\\end{bmatrix}$.\n\nCase C (least squares in $\\mathbb{R}^5$, ill-conditioned scales):\n- $d = 5$, $n = 5$, $m = 4$, $T = 6000$, $\\eta = 0.2$, seed $= 9999$.\n- Data $\\{(\\mathbf{a}_i,b_i)\\}_{i=1}^5$:\n  - $\\mathbf{a}_1 = \\begin{bmatrix}10 \\\\ 0 \\\\ 0 \\\\ 0 \\\\ 0\\end{bmatrix}$, $b_1 = 5$.\n  - $\\mathbf{a}_2 = \\begin{bmatrix}0 \\\\ 1 \\\\ 0 \\\\ 0 \\\\ 0\\end{bmatrix}$, $b_2 = 1$.\n  - $\\mathbf{a}_3 = \\begin{bmatrix}0 \\\\ 0 \\\\ 0.5 \\\\ 0 \\\\ 0\\end{bmatrix}$, $b_3 = 0.5$.\n  - $\\mathbf{a}_4 = \\begin{bmatrix}0 \\\\ 0 \\\\ 0 \\\\ 0.2 \\\\ 0\\end{bmatrix}$, $b_4 = 0.2$.\n  - $\\mathbf{a}_5 = \\begin{bmatrix}0 \\\\ 0 \\\\ 0 \\\\ 0 \\\\ 0.1\\end{bmatrix}$, $b_5 = 0.1$.\n- Initialization $\\mathbf{w}_0 = \\begin{bmatrix}0 \\\\ 0 \\\\ 0 \\\\ 0 \\\\ 0\\end{bmatrix}$.\n\nYour program must compute $F(\\mathbf{w}_T)$ for each case using the procedure defined above and produce a single line of output containing the results as a comma-separated list enclosed in square brackets, in the order [Case A, Case B, Case C], with each number rounded to $6$ decimal places, for example $[0.123456,0.234567,0.345678]$.", "solution": "The problem statement is validated as complete, self-contained, and scientifically sound. It presents a well-posed computational task rooted in the fundamental principles of unconstrained optimization and computational engineering. The algorithm described is a standard implementation of Stochastic Gradient Descent (SGD) for empirical risk minimization. All parameters, data, and initial conditions are explicitly provided, ensuring a unique and verifiable solution for each case. We proceed to formulate the solution.\n\nThe optimization procedure for finding the weight vector $\\mathbf{w}$ that minimizes the empirical risk $F(\\mathbf{w})$ is given by the iterative update rule:\n$$ \\mathbf{w}_{k+1} = \\mathbf{w}_k - \\alpha_k \\mathbf{g}_k $$\nfor $k = 0, 1, \\dots, T-1$. Here, $\\mathbf{w}_k$ is the weight vector at iteration $k$, $\\alpha_k$ is the step size, and $\\mathbf{g}_k$ is the stochastic gradient. The initial vector is $\\mathbf{w}_0$.\n\nThe step size schedule is given by $\\alpha_k = \\frac{\\eta}{\\sqrt{k+1}}$. The stochastic gradient $\\mathbf{g}_k$ is an estimate of the true gradient of the empirical risk, computed on a mini-batch $\\mathcal{S}_k$ of size $m$ sampled with replacement from the full dataset. After $T$ iterations, the final empirical risk $F(\\mathbf{w}_T)$ is calculated using the entire dataset.\n\nWe must first specify the precise forms of the stochastic gradient $\\mathbf{g}_k$ and the empirical risk $F(\\mathbf{w})$ for each case.\n\n**1. Least-Squares Regression (Cases A and C)**\n\nThe empirical risk is the mean squared error:\n$$ F(\\mathbf{w}) = \\frac{1}{n} \\sum_{i=1}^n \\ell_i(\\mathbf{w}) = \\frac{1}{n} \\sum_{i=1}^n \\left(\\mathbf{a}_i^\\top \\mathbf{w} - b_i\\right)^2 $$\nThe gradient of the loss for a single data point $(\\mathbf{a}_i, b_i)$ is:\n$$ \\nabla \\ell_i(\\mathbf{w}) = \\nabla_{\\mathbf{w}} \\left(\\mathbf{a}_i^\\top \\mathbf{w} - b_i\\right)^2 = 2 \\left(\\mathbf{a}_i^\\top \\mathbf{w} - b_i\\right) \\mathbf{a}_i $$\nThe stochastic gradient $\\mathbf{g}_k$ is the average of these individual gradients over the mini-batch $\\mathcal{S}_k$:\n$$ \\mathbf{g}_k = \\frac{1}{m} \\sum_{i \\in \\mathcal{S}_k} \\nabla \\ell_i(\\mathbf{w}_k) = \\frac{2}{m} \\sum_{i \\in \\mathcal{S}_k} \\left(\\mathbf{a}_i^\\top \\mathbf{w}_k - b_i\\right) \\mathbf{a}_i $$\nAfter $T$ iterations, the final risk $F(\\mathbf{w}_T)$ is computed using the formula for $F(\\mathbf{w})$ with $\\mathbf{w} = \\mathbf{w}_T$.\n\n**2. Logistic Regression with $\\ell_2$ Regularization (Case B)**\n\nThe empirical risk comprises an average log-loss term and an $\\ell_2$ regularization term:\n$$ F(\\mathbf{w}) = \\left( \\frac{1}{n} \\sum_{i=1}^n \\log\\left(1+\\exp\\left(-y_i\\,\\mathbf{a}_i^\\top \\mathbf{w}\\right)\\right) \\right) + \\frac{\\lambda}{2}\\,\\|\\mathbf{w}\\|_2^2 $$\nThe loss component for a single data point $(\\mathbf{a}_i, y_i)$ is $\\ell_i(\\mathbf{w}) = \\log(1+\\exp(-y_i\\,\\mathbf{a}_i^\\top \\mathbf{w}))$. Its gradient is:\n$$ \\nabla \\ell_i(\\mathbf{w}) = \\frac{1}{1+\\exp(-y_i\\,\\mathbf{a}_i^\\top \\mathbf{w})} \\cdot \\exp(-y_i\\,\\mathbf{a}_i^\\top \\mathbf{w}) \\cdot (-y_i \\mathbf{a}_i) = -y_i \\mathbf{a}_i \\frac{1}{1+\\exp(y_i\\,\\mathbf{a}_i^\\top \\mathbf{w})} $$\nThe stochastic direction $\\mathbf{g}_k$ is defined as an unbiased estimator of the full gradient $\\nabla F(\\mathbf{w}_k)$:\n$$ \\mathbf{g}_k = \\left(\\frac{1}{m} \\sum_{i \\in \\mathcal{S}_k} \\nabla \\ell_i(\\mathbf{w}_k)\\right) + \\lambda \\mathbf{w}_k $$\nSubstituting the expression for $\\nabla \\ell_i(\\mathbf{w}_k)$:\n$$ \\mathbf{g}_k = \\left( \\frac{1}{m} \\sum_{i \\in \\mathcal{S}_k} -y_i \\mathbf{a}_i \\frac{1}{1+\\exp(y_i\\,\\mathbf{a}_i^\\top \\mathbf{w}_k)} \\right) + \\lambda \\mathbf{w}_k $$\nUpon completion of $T$ iterations, the final risk $F(\\mathbf{w}_T)$ is computed using its definition, substituting $\\mathbf{w} = \\mathbf{w}_T$.\n\nFor numerical stability when computing the logistic loss term $\\log(1 + e^x)$ where $x = -y_i \\mathbf{a}_i^\\top \\mathbf{w}$, large positive values of $x$ can cause overflow in $e^x$. A more robust computation is $\\log(1 + e^x) \\approx x$ for large $x$. A stable implementation can use the identity $\\log(1+e^x) = x + \\log(1+e^{-x})$. Thus, for any $x$, we can compute it as $\\max(0, x) + \\log(1+e^{-|x|})$. This avoids overflow and maintains precision.\n\n**Algorithm Implementation**\nThe solution requires implementing the SGD algorithm for each of the three cases specified. For each case:\n1. Initialize the weight vector $\\mathbf{w} = \\mathbf{w}_0$ and the pseudo-random number generator with the given seed.\n2. Loop for $k$ from $0$ to $T-1$:\n    a. Determine the step size $\\alpha_k = \\eta / \\sqrt{k+1}$.\n    b. Sample a mini-batch of $m$ indices $\\mathcal{S}_k$ with replacement from $\\{1, \\dots, n\\}$.\n    c. Compute the stochastic gradient $\\mathbf{g}_k$ using the data points corresponding to indices in $\\mathcal{S}_k$ and the current weight vector $\\mathbf{w}_k$, according to the formulas for the respective case.\n    d. Update the weights: $\\mathbf{w}_{k+1} = \\mathbf{w}_k - \\alpha_k \\mathbf{g}_k$. Let $\\mathbf{w} \\leftarrow \\mathbf{w}_{k+1}$.\n3. After the loop, the final weight vector is $\\mathbf{w}_T$. Calculate the full empirical risk $F(\\mathbf{w}_T)$ using all $n$ data points.\n4. Round the final risk value to $6$ decimal places.\n\nThe final output will be a list containing the computed risk values for Case A, Case B, and Case C, in that order.", "answer": "```python\nimport numpy as np\n\ndef run_sgd(case_params):\n    \"\"\"\n    Runs the Stochastic Gradient Descent algorithm for a given case.\n    \"\"\"\n    case_type = case_params['type']\n    d = case_params['d']\n    n = case_params['n']\n    m = case_params['m']\n    T = case_params['T']\n    eta = case_params['eta']\n    seed = case_params['seed']\n    lambda_reg = case_params.get('lambda', 0.0)\n    A = case_params['A']\n    b_or_y = case_params['b_or_y']\n    w0 = case_params['w0']\n\n    w = w0.copy()\n    rng = np.random.default_rng(seed)\n\n    for k in range(T):\n        alpha_k = eta / np.sqrt(k + 1)\n        \n        batch_indices = rng.choice(n, size=m, replace=True)\n        a_batch = A[batch_indices]\n        b_or_y_batch = b_or_y[batch_indices]\n\n        if case_type == 'least_squares':\n            # g_k = (2/m) * sum((a_i^T w - b_i) * a_i for i in S_k)\n            predictions = a_batch @ w\n            errors = predictions - b_or_y_batch\n            g_k = (2 / m) * (a_batch.T @ errors)\n        \n        elif case_type == 'logistic':\n            # g_k = (1/m) * sum(grad_loss_i) + lambda * w\n            # grad_loss_i = -y_i * a_i / (1 + exp(y_i * a_i^T * w))\n            z = b_or_y_batch * (a_batch @ w)\n            # Numerically stable gradient calculation\n            # Use a condition to avoid large exp values, though 1/(1+exp(z)) is stable\n            coeffs = -b_or_y_batch / (1 + np.exp(z))\n            grad_sum_part = (1 / m) * (a_batch.T @ coeffs)\n            g_k = grad_sum_part + lambda_reg * w\n        \n        w = w - alpha_k * g_k\n\n    # After T iterations, compute final empirical risk F(w_T)\n    w_T = w\n    if case_type == 'least_squares':\n        # F(w) = (1/n) * sum((a_i^T w - b_i)^2)\n        final_predictions = A @ w_T\n        final_errors = final_predictions - b_or_y\n        final_risk = np.mean(final_errors**2)\n        \n    elif case_type == 'logistic':\n        # F(w) = (1/n) * sum(log(1 + exp(-y_i * a_i^T * w))) + (lambda/2) * ||w||^2\n        z_final = b_or_y * (A @ w_T)\n        \n        # Numerically stable log-loss calculation: log(1+exp(-z))\n        # max(0, -z) + log(1 + exp(-|z|))\n        stable_log_loss_terms = np.maximum(0, -z_final) + np.log(1 + np.exp(-np.abs(z_final)))\n        \n        avg_log_loss = np.mean(stable_log_loss_terms)\n        reg_term = (lambda_reg / 2) * np.dot(w_T, w_T)\n        final_risk = avg_log_loss + reg_term\n\n    return round(final_risk, 6)\n\ndef solve():\n    \"\"\"\n    Defines test cases and computes the final empirical risk for each.\n    \"\"\"\n    test_cases = [\n        {\n            'type': 'least_squares',\n            'd': 2, 'n': 4, 'm': 1, 'T': 4000, 'eta': 0.5, 'seed': 12345,\n            'A': np.array([[1, 0], [0, 1], [1, 1], [2, 1]]),\n            'b_or_y': np.array([1, 2, 2.5, 3.5]),\n            'w0': np.array([0.0, 0.0])\n        },\n        {\n            'type': 'logistic',\n            'd': 3, 'n': 6, 'm': 2, 'T': 8000, 'eta': 0.7, 'seed': 2021, 'lambda': 0.1,\n            'A': np.array([[2, 0, 1], [0, 2, 1], [-2, 0, 1], [0, -2, 1], [1, 1, 1], [-1, -1, 1]]),\n            'b_or_y': np.array([1, 1, -1, -1, 1, -1]),\n            'w0': np.array([0.0, 0.0, 0.0])\n        },\n        {\n            'type': 'least_squares',\n            'd': 5, 'n': 5, 'm': 4, 'T': 6000, 'eta': 0.2, 'seed': 9999,\n            'A': np.array([[10, 0, 0, 0, 0], [0, 1, 0, 0, 0], [0, 0, 0.5, 0, 0], [0, 0, 0, 0.2, 0], [0, 0, 0, 0, 0.1]]),\n            'b_or_y': np.array([5, 1, 0.5, 0.2, 0.1]),\n            'w0': np.array([0.0, 0.0, 0.0, 0.0, 0.0])\n        }\n    ]\n\n    results = []\n    for case in test_cases:\n        result = run_sgd(case)\n        results.append(f\"{result:.6f}\")\n\n    print(f\"[{','.join(results)}]\")\n\nsolve()\n```", "id": "2448678"}]}