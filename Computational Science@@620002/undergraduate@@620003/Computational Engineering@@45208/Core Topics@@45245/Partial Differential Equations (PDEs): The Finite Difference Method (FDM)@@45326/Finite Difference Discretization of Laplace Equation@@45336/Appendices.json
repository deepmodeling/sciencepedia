{"hands_on_practices": [{"introduction": "A robust numerical solver is only as good as its implementation of boundary conditions. This first practice moves from theory to code, focusing on the crucial task of accurately representing derivative (Neumann) boundary conditions, a common scenario in physics and engineering. You will derive stencils of different orders of accuracy from fundamental Taylor series expansions and use the method of manufactured solutions—a powerful verification technique—to numerically confirm the accuracy of your implementation. This exercise [@problem_id:2392121] builds the foundational skill of creating a verifiable and accurate finite difference solver for a mixed-boundary value problem.", "problem": "Consider the two-dimensional Laplace's equation, which states that for a sufficiently smooth scalar field $u(x,y)$ on a domain $\\Omega \\subset \\mathbb{R}^2$, the governing equation is $\\nabla^2 u = \\partial^2 u/\\partial x^2 + \\partial^2 u/\\partial y^2 = 0$. You will work on the square domain $\\Omega = [0,1]\\times[0,1]$ and study a mixed boundary-value problem in which a Dirichlet condition meets a Neumann condition at a corner.\n\nStarting from the fundamental definition of the Laplace operator and standard Taylor expansions, construct a finite difference discretization of the interior equation and consistent boundary closures. The goal is to examine how the discrete solution behaves near the corner where a Dirichlet condition and a Neumann condition meet.\n\nThe problem specification is as follows.\n\n- Governing partial differential equation (PDE): $\\nabla^2 u = 0$ in $\\Omega$.\n- Exact manufactured harmonic solution: $u_e(x,y) = e^x \\cos(y)$.\n- Boundary conditions prescribed from $u_e$:\n  - Bottom edge ($y=0$): Dirichlet condition $u(x,0) = u_e(x,0) = e^x$.\n  - Top edge ($y=1$): Dirichlet condition $u(x,1) = u_e(x,1) = e^x \\cos(1)$.\n  - Right edge ($x=1$): Dirichlet condition $u(1,y) = u_e(1,y) = e \\cos(y)$.\n  - Left edge ($x=0$): Neumann condition specifying the outward normal derivative. The outward unit normal on $x=0$ points in the negative $x$-direction, so $\\frac{\\partial u}{\\partial n} = -\\frac{\\partial u}{\\partial x}$. Prescribe $\\frac{\\partial u}{\\partial n} \\big|_{x=0} = -\\cos(y)$, which matches the exact solution because $\\frac{\\partial u_e}{\\partial x} \\big|_{x=0} = \\cos(y)$.\n\nUse a uniform Cartesian grid with $n$ interior points per coordinate direction, grid spacing $h = 1/(n+1)$, and grid points $(x_i,y_j) = (ih,jh)$ for integers $i,j \\in \\{0,1,\\dots,n+1\\}$. Let the set of unknowns be the interior values $u_{i,j} \\approx u(x_i,y_j)$ for $i,j \\in \\{1,2,\\dots,n\\}$.\n\n- Interior discretization: Derive the standard $5$-point finite difference approximation to the Laplacian at interior nodes by truncating Taylor expansions to second order in $h$.\n- Dirichlet boundaries: Incorporate Dirichlet data into the right-hand side consistently with the interior stencil.\n- Neumann boundary on $x=0$: Derive two distinct boundary closures at the first interior column $i=1$ that eliminate the unknown boundary value $u_{0,j}$ in favor of interior values and known Neumann data:\n  - First-order closure based on the one-sided difference for $\\frac{\\partial u}{\\partial x}$ at $x=0$ using $(u_{1,j}-u_{0,j})/h$.\n  - Second-order closure based on the one-sided three-point formula for $\\frac{\\partial u}{\\partial x}$ at $x=0$ using $(-3u_{0,j}+4u_{1,j}-u_{2,j})/(2h)$.\n  In both cases, use the relation between the prescribed outward normal derivative and $\\frac{\\partial u}{\\partial x}$ to substitute the Neumann data at $x=0$ into the discrete equations.\n\nYour tasks:\n- Derive, from Taylor expansions, the interior $5$-point stencil and the two boundary closures at $x=0$ that are consistent with the above Neumann condition.\n- Assemble and solve the resulting linear systems for the interior unknowns for multiple grid sizes $n$.\n- Quantify the behavior of the numerical solution specifically near the corner where the Dirichlet and Neumann boundaries meet, i.e., at the interior node closest to the corner $(x,y)=(0,0)$, which is $(x,y)=(h,h)$.\n\nTest suite and answer specification:\n- Use three values of $n$: $n \\in \\{15,31,63\\}$.\n- For each $n$, solve the system twice, once with the first-order Neumann closure and once with the second-order Neumann closure.\n- For each solve, compute the absolute pointwise error at the corner-adjacent interior node $(i,j)=(1,1)$, i.e., $\\lvert u_{1,1} - u_e(h,h)\\rvert$.\n- Additionally, for $n=63$ only, compute the maximum-norm error over all interior nodes, i.e., $\\max_{1\\le i,j\\le n} \\lvert u_{i,j} - u_e(x_i,y_j)\\rvert$, for both the first-order and the second-order Neumann closures.\n\nFinal output format:\n- Your program must produce a single line containing the results as a comma-separated list enclosed in square brackets. The list must be ordered as follows:\n  - The three corner-adjacent absolute errors for the first-order Neumann closure at $n=15$, $n=31$, and $n=63$.\n  - The three corner-adjacent absolute errors for the second-order Neumann closure at $n=15$, $n=31$, and $n=63$.\n  - The two maximum-norm errors over all interior nodes for $n=63$, first for the first-order closure, then for the second-order closure.\n- All numbers must be printed as floating-point values rounded to eight significant digits in scientific notation.\n- Example of the required format (illustrative only): [$1.23456789e-03,5.67891234e-04,9.10111213e-05, \\dots$].\n\nNo physical units are involved in this problem. Angles, when present inside trigonometric functions, are in radians. The output must strictly follow the specified single-line format with exactly eight numbers.", "solution": "The problem presented is a well-posed boundary-value problem for the two-dimensional Laplace equation, utilizing the method of manufactured solutions for verification. It is scientifically grounded, self-contained, and objective. There are no inconsistencies or fallacies. Thus, we proceed with the solution.\n\nThe analysis is structured as follows: First, we derive the finite difference stencils for the interior nodes and the boundary nodes from fundamental Taylor series expansions. Second, we formalize the assembly of the global linear system of equations. Finally, we implement this formulation to compute the specified error metrics.\n\nLet the domain be $\\Omega = [0,1]\\times[0,1]$ discretized by a uniform grid with spacing $h = 1/(n+1)$. The grid points are $(x_i, y_j) = (ih, jh)$ for $i,j \\in \\{0, 1, \\dots, n+1\\}$. The numerical solution $u_{i,j}$ approximates the exact solution $u(x_i, y_j)$. The unknowns are the values at the interior nodes, $u_{i,j}$ for $i,j \\in \\{1, \\dots, n\\}$.\n\nThe governing partial differential equation (PDE) is Laplace's equation:\n$$\n\\nabla^2 u = \\frac{\\partial^2 u}{\\partial x^2} + \\frac{\\partial^2 u}{\\partial y^2} = 0\n$$\n\n**Part 1: Derivation of Finite Difference Stencils**\n\n**1.1. Interior Node Stencil**\nWe consider an interior node $(x_i, y_j)$ where $1  i,j  n$. We use Taylor series expansions for $u(x,y)$ around this point.\nFor the $x$-direction:\n$$\nu(x_i+h, y_j) = u(x_i, y_j) + h \\frac{\\partial u}{\\partial x} \\bigg|_{(x_i,y_j)} + \\frac{h^2}{2!} \\frac{\\partial^2 u}{\\partial x^2} \\bigg|_{(x_i,y_j)} + \\frac{h^3}{3!} \\frac{\\partial^3 u}{\\partial x^3} \\bigg|_{(x_i,y_j)} + O(h^4)\n$$\n$$\nu(x_i-h, y_j) = u(x_i, y_j) - h \\frac{\\partial u}{\\partial x} \\bigg|_{(x_i,y_j)} + \\frac{h^2}{2!} \\frac{\\partial^2 u}{\\partial x^2} \\bigg|_{(x_i,y_j)} - \\frac{h^3}{3!} \\frac{\\partial^3 u}{\\partial x^3} \\bigg|_{(x_i,y_j)} + O(h^4)\n$$\nSumming these two expansions eliminates the odd-order derivative terms:\n$$\nu(x_i+h, y_j) + u(x_i-h, y_j) = 2u(x_i, y_j) + h^2 \\frac{\\partial^2 u}{\\partial x^2} \\bigg|_{(x_i,y_j)} + O(h^4)\n$$\nRearranging for the second partial derivative gives the second-order accurate central difference formula:\n$$\n\\frac{\\partial^2 u}{\\partial x^2} \\bigg|_{(x_i,y_j)} = \\frac{u(x_{i+1}, y_j) - 2u(x_i, y_j) + u(x_{i-1}, y_j)}{h^2} + O(h^2)\n$$\nReplacing the function values with their discrete counterparts $u_{i,j}$, we get:\n$$\n\\frac{\\partial^2 u}{\\partial x^2} \\approx \\frac{u_{i+1,j} - 2u_{i,j} + u_{i-1,j}}{h^2}\n$$\nBy analogy, the discretization for the $y$-direction derivative is:\n$$\n\\frac{\\partial^2 u}{\\partial y^2} \\approx \\frac{u_{i,j+1} - 2u_{i,j} + u_{i,j-1}}{h^2}\n$$\nSubstituting these into the Laplace equation $\\frac{\\partial^2 u}{\\partial x^2} + \\frac{\\partial^2 u}{\\partial y^2} = 0$, we find:\n$$\n\\frac{u_{i+1,j} - 2u_{i,j} + u_{i-1,j}}{h^2} + \\frac{u_{i,j+1} - 2u_{i,j} + u_{i,j-1}}{h^2} = 0\n$$\nMultiplying by $h^2$ yields the standard $5$-point stencil for interior nodes:\n$$\nu_{i+1,j} + u_{i-1,j} + u_{i,j+1} + u_{i,j-1} - 4u_{i,j} = 0\n$$\n\n**1.2. Neumann Boundary Closure at $x=0$**\nThe Neumann condition on the left boundary ($x=0$) is given as $\\frac{\\partial u}{\\partial n} = -\\frac{\\partial u}{\\partial x} = -\\cos(y)$. This implies we must enforce $\\frac{\\partial u}{\\partial x}(0,y) = \\cos(y)$.\nWe apply the $5$-point stencil at the nodes adjacent to this boundary, i.e., for $i=1$ and $j \\in \\{1,\\dots,n\\}$. This stencil involves the values $u_{0,j}$ which are on the boundary and are not part of the primary set of unknowns. We must eliminate $u_{0,j}$ using the Neumann condition.\n\nLet $g_j = \\cos(y_j) = \\cos(jh)$.\n\n**Case 1: First-Order Closure**\nWe approximate the derivative at the boundary $(x_0, y_j)$ using a first-order accurate forward difference:\n$$\n\\frac{\\partial u}{\\partial x} \\bigg|_{(0,y_j)} = \\frac{u(h,y_j) - u(0,y_j)}{h} + O(h)\n$$\nUsing discrete notation and setting it to the prescribed value:\n$$\n\\frac{u_{1,j} - u_{0,j}}{h} = g_j \\implies u_{0,j} = u_{1,j} - h g_j\n$$\nThis expression for the \"ghost\" value $u_{0,j}$ is substituted into the standard stencil at $(1,j)$:\n$$\nu_{2,j} + u_{0,j} + u_{1,j+1} + u_{1,j-1} - 4u_{1,j} = 0\n$$\n$$\nu_{2,j} + (u_{1,j} - h g_j) + u_{1,j+1} + u_{1,j-1} - 4u_{1,j} = 0\n$$\nThis simplifies to the modified stencil for nodes at $i=1$:\n$$\nu_{2,j} + u_{1,j+1} + u_{1,j-1} - 3u_{1,j} = h g_j\n$$\n\n**Case 2: Second-Order Closure**\nTo maintain the second-order accuracy of the interior discretization, we use a second-order one-sided formula for the derivative, as specified. We derive this formula from Taylor series. Let $u_x = \\frac{\\partial u}{\\partial x}|_{(0,y_j)}$ and $u_{xx} = \\frac{\\partial^2 u}{\\partial x^2}|_{(0,y_j)}$.\n$$\nu_{1,j} = u_{0,j} + h u_x + \\frac{h^2}{2} u_{xx} + O(h^3) \\quad (1)\n$$\n$$\nu_{2,j} = u_{0,j} + 2h u_x + \\frac{(2h)^2}{2} u_{xx} + O(h^3) = u_{0,j} + 2h u_x + 2h^2 u_{xx} + O(h^3) \\quad (2)\n$$\nTo eliminate $u_{xx}$, we compute $4 \\times (1) - (2)$:\n$$\n4u_{1,j} - u_{2,j} = (4u_{0,j} - u_{0,j}) + (4h u_x - 2h u_x) + O(h^3) = 3u_{0,j} + 2h u_x + O(h^3)\n$$\nSolving for $u_x$ yields the required formula:\n$$\nu_x = \\frac{-3u_{0,j} + 4u_{1,j} - u_{2,j}}{2h} + O(h^2)\n$$\nSetting this to $g_j$ allows us to express $u_{0,j}$ in terms of interior points:\n$$ \\frac{-3u_{0,j} + 4u_{1,j} - u_{2,j}}{2h} = g_j \\implies u_{0,j} = \\frac{1}{3}(4u_{1,j} - u_{2,j} - 2h g_j) $$\nSubstituting this into the standard stencil at $(1,j)$:\n$$\nu_{2,j} + \\frac{1}{3}(4u_{1,j} - u_{2,j} - 2h g_j) + u_{1,j+1} + u_{1,j-1} - 4u_{1,j} = 0\n$$\nMultiplying by $3$ to clear the denominator:\n$$\n3u_{2,j} + (4u_{1,j} - u_{2,j} - 2h g_j) + 3u_{1,j+1} + 3u_{1,j-1} - 12u_{1,j} = 0\n$$\nThis simplifies to the second-order accurate modified stencil for nodes at $i=1$:\n$$\n2u_{2,j} + 3u_{1,j+1} + 3u_{1,j-1} - 8u_{1,j} = 2h g_j\n$$\n\n**1.3. Dirichlet Boundaries**\nThe Dirichlet boundary conditions are imposed by moving known boundary values to the right-hand side of the linear system. The boundary values are determined by the exact solution $u_e(x,y) = e^x \\cos(y)$.\n- Bottom ($j=0$): $u_{i,0} = u_e(x_i, 0) = e^{ih}$\n- Top ($j=n+1$): $u_{i,n+1} = u_e(x_i, 1) = e^{ih} \\cos(1)$\n- Right ($i=n+1$): $u_{n+1,j} = u_e(1, y_j) = e \\cos(jh)$\n\nFor an interior node $(i,j)$ adjacent to a Dirichlet boundary, the stencil equation incorporates the known value. For example, at a point $(i,1)$ near the bottom boundary, the standard stencil $u_{i+1,1} + u_{i-1,1} + u_{i,2} + u_{i,0} - 4u_{i,1} = 0$ becomes $u_{i+1,1} + u_{i-1,1} + u_{i,2} - 4u_{i,1} = -u_{i,0} = -e^{ih}$.\n\nAt the corner-adjacent node $(1,1)$, the stencil must account for both the Neumann condition on the left and the Dirichlet condition on the bottom. For the second-order closure, for example, the equation for $j=1$ is $2u_{2,1} + 3u_{1,2} + 3u_{1,0} - 8u_{1,1} = 2h g_1$. The term $u_{1,0}$ is known ($u_{1,0} = e^h$), so the equation becomes $2u_{2,1} + 3u_{1,2} - 8u_{1,1} = 2h \\cos(h) - 3e^h$.\n\n**Part 2: Linear System Assembly and Solution**\nThe discrete equations for all $n^2$ interior nodes form a large, sparse linear system of the form $\\mathbf{A} \\mathbf{u} = \\mathbf{b}$, where $\\mathbf{u}$ is a vector of the $n^2$ unknown values $u_{i,j}$ ordered, for instance, row by row. The matrix $\\mathbf{A}$ and vector $\\mathbf{b}$ are constructed by iterating through each interior node $(i,j)$ for $i,j \\in \\{1,\\dots,n\\}$ and populating the corresponding row of the system according to the derived stencils.\n\nThe implementation will construct this system using a sparse matrix format (`scipy.sparse`) for efficiency and solve it using a direct sparse solver (`scipy.sparse.linalg.spsolve`). This process is executed for each specified value of $n$ and for both first- and second-order Neumann closures. The numerical solution $\\mathbf{u}$ is then compared against the exact solution $u_e(x,y)$ at the grid points to compute the required errors.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.sparse import lil_matrix\nfrom scipy.sparse.linalg import spsolve\n\ndef solve():\n    \"\"\"\n    Main function to solve the Laplace problem for specified test cases\n    and print the results in the required format.\n    \"\"\"\n\n    def solve_laplace(n, neumann_order):\n        \"\"\"\n        Assembles and solves the linear system for Laplace's equation for a given\n        grid size 'n' and Neumann boundary closure 'neumann_order'.\n\n        Args:\n            n (int): Number of interior points in each direction.\n            neumann_order (int): Order of the Neumann boundary condition (1 or 2).\n\n        Returns:\n            tuple: A tuple containing:\n                - corner_error (float): Absolute error at the node (h, h).\n                - max_norm_error (float): Maximum absolute error over all interior nodes.\n        \"\"\"\n        h = 1.0 / (n + 1)\n        num_unknowns = n * n\n\n        A = lil_matrix((num_unknowns, num_unknowns))\n        b = np.zeros(num_unknowns)\n\n        # Exact solution and its derivatives for boundary conditions\n        def u_exact(x, y):\n            return np.exp(x) * np.cos(y)\n\n        # Neumann data g(y) = du/dx at x=0\n        def g(y):\n            return np.cos(y)\n\n        # Map 2D grid index (i, j) to 1D vector index k\n        def get_k(i, j):\n            return (j - 1) * n + (i - 1)\n\n        # Populate the matrix A and vector b\n        for j_idx in range(1, n + 1):  # 1-based indexing for grid\n            for i_idx in range(1, n + 1):  # 1-based indexing for grid\n                k = get_k(i_idx, j_idx)\n                x_i, y_j = i_idx * h, j_idx * h\n\n                # --- Left boundary (i_idx=1), Neumann condition ---\n                if i_idx == 1:\n                    if neumann_order == 1:\n                        # Stencil: u(2,j) + u(1,j+1) + u(1,j-1) - 3u(1,j) = h*g(y_j)\n                        A[k, k] = -3.0\n                        A[k, get_k(i_idx + 1, j_idx)] = 1.0  # u(2,j)\n                        b[k] = h * g(y_j)\n\n                        if j_idx > 1:\n                            A[k, get_k(i_idx, j_idx - 1)] = 1.0 # u(1,j-1)\n                        else:  # j_idx == 1 (Bottom boundary)\n                            b[k] -= u_exact(x_i, 0)\n                        \n                        if j_idx  n:\n                            A[k, get_k(i_idx, j_idx + 1)] = 1.0 # u(1,j+1)\n                        else:  # j_idx == n (Top boundary)\n                            b[k] -= u_exact(x_i, 1)\n\n                    elif neumann_order == 2:\n                        # Stencil: 2u(2,j) + 3u(1,j+1) + 3u(1,j-1) - 8u(1,j) = 2h*g(y_j)\n                        A[k, k] = -8.0\n                        A[k, get_k(i_idx + 1, j_idx)] = 2.0  # u(2,j)\n                        b[k] = 2.0 * h * g(y_j)\n\n                        if j_idx > 1:\n                            A[k, get_k(i_idx, j_idx - 1)] = 3.0 # u(1,j-1)\n                        else:  # j_idx == 1 (Bottom boundary)\n                            b[k] -= 3.0 * u_exact(x_i, 0)\n\n                        if j_idx  n:\n                            A[k, get_k(i_idx, j_idx + 1)] = 3.0 # u(1,j+1)\n                        else:  # j_idx == n (Top boundary)\n                            b[k] -= 3.0 * u_exact(x_i, 1)\n\n                # --- Standard interior or right boundary (i_idx > 1) ---\n                else:\n                    # Stencil: u(i-1,j) + u(i+1,j) + u(i,j-1) + u(i,j+1) - 4u(i,j) = 0\n                    A[k, k] = -4.0\n                    A[k, get_k(i_idx - 1, j_idx)] = 1.0  # u(i-1,j)\n                    \n                    if i_idx  n:\n                        A[k, get_k(i_idx + 1, j_idx)] = 1.0  # u(i+1,j)\n                    else:  # i_idx == n (Right boundary)\n                        b[k] -= u_exact(1.0, y_j)\n                    \n                    if j_idx > 1:\n                        A[k, get_k(i_idx, j_idx - 1)] = 1.0  # u(i,j-1)\n                    else:  # j_idx == 1 (Bottom boundary)\n                        b[k] -= u_exact(x_i, 0)\n                    \n                    if j_idx  n:\n                        A[k, get_k(i_idx, j_idx + 1)] = 1.0  # u(i,j+1)\n                    else:  # j_idx == n (Top boundary)\n                        b[k] -= u_exact(x_i, 1)\n        \n        # Convert A to CSR format for efficient solving\n        A_csr = A.tocsr()\n        u_sol_vec = spsolve(A_csr, b)\n        \n        # Reshape solution vector to 2D grid (row-major)\n        u_sol_grid = u_sol_vec.reshape((n, n), order='C')\n\n        # Create grid of exact solution for error calculation\n        x_coords = np.linspace(h, 1.0 - h, n)\n        y_coords = np.linspace(h, 1.0 - h, n)\n        x_grid, y_grid = np.meshgrid(x_coords, y_coords)\n        u_exact_grid = u_exact(x_grid, y_grid)\n\n        # Compute errors\n        # Python index [0, 0] corresponds to grid point (j=1, i=1) or (h,h)\n        corner_error = np.abs(u_sol_grid[0, 0] - u_exact_grid[0, 0])\n        max_norm_error = np.max(np.abs(u_sol_grid - u_exact_grid))\n        \n        return corner_error, max_norm_error\n\n    n_vals = [15, 31, 63]\n    results = []\n\n    # Calculate corner errors for 1st-order closure\n    corner_errors_order1 = []\n    max_error_order1_n63 = 0.0\n    for n_val in n_vals:\n        corner_err, max_err = solve_laplace(n_val, neumann_order=1)\n        corner_errors_order1.append(corner_err)\n        if n_val == 63:\n            max_error_order1_n63 = max_err\n\n    # Calculate corner errors for 2nd-order closure\n    corner_errors_order2 = []\n    max_error_order2_n63 = 0.0\n    for n_val in n_vals:\n        corner_err, max_err = solve_laplace(n_val, neumann_order=2)\n        corner_errors_order2.append(corner_err)\n        if n_val == 63:\n            max_error_order2_n63 = max_err\n\n    # Assemble final list in specified order\n    results.extend(corner_errors_order1)\n    results.extend(corner_errors_order2)\n    results.append(max_error_order1_n63)\n    results.append(max_error_order2_n63)\n\n    # Format for printing\n    formatted_results = [\"{:.8e}\".format(r) for r in results]\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```", "id": "2392121"}, {"introduction": "Once a solver is verified, the next challenge is often performance. For the large linear systems arising from fine grids, iterative methods like Gauss-Seidel are common, but their efficiency depends heavily on the update order. This exercise [@problem_id:2392150] explores how a clever reordering of grid points—the red-black or checkerboard scheme—can break data dependencies inherent in a standard lexicographic sweep. By implementing and comparing both methods, you will gain hands-on experience with a fundamental technique for unlocking parallelism in scientific computing.", "problem": "Consider the two-dimensional Laplace equation on the open unit square domain $\\Omega=(0,1)\\times(0,1)$ with Dirichlet boundary data. Let $u:\\overline{\\Omega}\\to\\mathbb{R}$ satisfy\n$$\n\\nabla^2 u(x,y) \\;=\\; 0 \\quad \\text{for } (x,y)\\in\\Omega,\n$$\nwith boundary values given by\n$$\nu(x,0)=0,\\quad u(0,y)=0,\\quad u(1,y)=0,\\quad u(x,1)=\\sin(\\pi x)\\quad \\text{for } (x,y)\\in\\partial\\Omega.\n$$\nDiscretize $\\Omega$ by a uniform Cartesian grid with $N_x$ and $N_y$ interior points along the $x$- and $y$-directions, respectively. The grid spacings are $h_x=1/(N_x+1)$ and $h_y=1/(N_y+1)$, and the grid points are $(x_j,y_i)=(j\\,h_x,i\\,h_y)$ for integers $i\\in\\{0,1,\\dots,N_y+1\\}$ and $j\\in\\{0,1,\\dots,N_x+1\\}$. Impose the boundary values exactly at the boundary grid points, and denote by $u_{i,j}$ the discrete approximation to $u(y_i,x_j)$ at the grid nodes.\n\nUse the standard five-point finite difference discretization of the Laplace operator at interior nodes. An interior node $(i,j)$ satisfies\n$$\nu_{i,j} \\;=\\; \\frac{1}{4}\\,\\Big(u_{i-1,j}+u_{i+1,j}+u_{i,j-1}+u_{i,j+1}\\Big)\n\\quad \\text{for all } i\\in\\{1,\\dots,N_y\\},\\; j\\in\\{1,\\dots,N_x\\}.\n$$\n\nDefine the discrete residual at an iterate $u$ by\n$$\nr_{i,j} \\;=\\; \\big(u_{i-1,j}+u_{i+1,j}+u_{i,j-1}+u_{i,j+1}-4\\,u_{i,j}\\big),\n$$\nfor interior indices $(i,j)$, and the residual norm by the Euclidean norm\n$$\n\\|r\\|_2 \\;=\\; \\Bigg(\\sum_{i=1}^{N_y}\\sum_{j=1}^{N_x} r_{i,j}^2\\Bigg)^{1/2}.\n$$\nStart from the zero initial guess on interior nodes, with boundary nodes fixed by the given data.\n\nA single “iteration” is defined as one complete update of all interior nodes. Consider two iteration orderings:\n- A lexicographic ordering that updates interior nodes in increasing $i$ and then increasing $j$.\n- A two-color checkerboard ordering that partitions interior nodes into two disjoint sets by the parity of $i+j$, and performs one sub-sweep on one color followed by one sub-sweep on the other color, counting the two sub-sweeps together as one iteration.\n\nFor each method, define the relative residual after $k$ iterations as $\\|r_k\\|_2/\\|r_0\\|_2$. Terminate the iteration when the relative residual first falls below a tolerance $\\tau$, where $\\tau=10^{-8}$, or when a maximum number of iterations $K_{\\max}$ is reached, where $K_{\\max}=10^5$. For each method, record:\n- the number of iterations $I$ taken to reach the stopping criterion (use $I=K_{\\max}$ if the tolerance is not reached),\n- an empirical asymptotic convergence factor $\\rho$, defined as the arithmetic mean of the ratios $\\|r_{k+1}\\|_2/\\|r_k\\|_2$ over the last $m$ consecutive iterations prior to termination, where $m=\\min\\{10,\\,I-1\\}$ (and define $\\rho=0$ if $I2$).\n\nTo analyze parallelization potential of the two-color checkerboard scheme, define the idealized per-iteration parallelization potential $\\mathcal{P}$ as the fraction of interior nodes in the larger of the two color classes, namely\n$$\n\\mathcal{P} \\;=\\; \\frac{\\max\\{n_{\\text{red}},\\,n_{\\text{black}}\\}}{N_x N_y},\n$$\nwhere $n_{\\text{red}}$ and $n_{\\text{black}}$ are the counts of interior nodes with $(i+j)$ even and odd, respectively.\n\nYour program must compute, for each test case, a list containing $I_{\\text{lex}}$, $I_{\\text{rb}}$, $\\rho_{\\text{lex}}$, $\\rho_{\\text{rb}}$, and $\\mathcal{P}$, where the subscripts “lex” and “rb” refer to lexicographic and two-color checkerboard orderings, respectively. The values $I_{\\text{lex}}$ and $I_{\\text{rb}}$ must be integers. The values $\\rho_{\\text{lex}}$, $\\rho_{\\text{rb}}$, and $\\mathcal{P}$ must be reported as decimal numbers rounded to exactly $6$ digits after the decimal point.\n\nTest suite:\n- Case A: $(N_x,N_y)=(30,30)$.\n- Case B: $(N_x,N_y)=(1,1)$.\n- Case C: $(N_x,N_y)=(63,31)$.\n\nFinal output format:\nYour program should produce a single line of output containing a list of results, one per test case, in the order Case A, Case B, Case C. Each result is a list $[I_{\\text{lex}},I_{\\text{rb}},\\rho_{\\text{lex}},\\rho_{\\text{rb}},\\mathcal{P}]$. The entire output must be a single line string of the form\n$$\n\\big[\\,[I_{\\text{lex}},I_{\\text{rb}},\\rho_{\\text{lex}},\\rho_{\\text{rb}},\\mathcal{P}],\\;[I_{\\text{lex}},I_{\\text{rb}},\\rho_{\\text{lex}},\\rho_{\\text{rb}},\\mathcal{P}],\\;[I_{\\text{lex}},I_{\\text{rb}},\\rho_{\\text{lex}},\\rho_{\\text{rb}},\\mathcal{P}]\\,\\big],\n$$\nwith the three decimal values in each inner list rounded to exactly $6$ digits after the decimal point, and no additional text. No physical units are involved in this problem, and all angles, if any appear implicitly in trigonometric functions, are in radians by definition.", "solution": "The Laplace equation $\\nabla^2 u = 0$ on $\\Omega=(0,1)\\times(0,1)$ with the specified boundary conditions admits a unique harmonic solution. For numerical approximation, we discretize $\\Omega$ by a uniform Cartesian grid with $N_x$ and $N_y$ interior points in the $x$ and $y$ directions, respectively, giving spacings $h_x=1/(N_x+1)$ and $h_y=1/(N_y+1)$. With the standard five-point stencil, the discrete Laplace operator at interior grid index $(i,j)$ enforces\n$$\nu_{i,j} \\;=\\; \\frac{1}{4}\\,\\Big(u_{i-1,j}+u_{i+1,j}+u_{i,j-1}+u_{i,j+1}\\Big),\n$$\nwhich is derived by second-order central differences for the second derivatives in $x$ and $y$, and here simplifies to an arithmetic average because the grid is uniform and isotropic. The boundary values are imposed directly: $u_{i,0}=0$, $u_{i,N_x+1}=0$, $u_{0,j}=0$, and $u_{N_y+1,j}=\\sin(\\pi x_j)$, where $x_j=j\\,h_x$. The chosen boundary data are consistent with the exact harmonic function $u(x,y)=\\sin(\\pi x)\\,\\sinh(\\pi y)/\\sinh(\\pi)$, ensuring that $\\nabla^2 u=0$ and that the discrete solution converges toward a consistent limit as $N_x,N_y\\to\\infty$.\n\nTo assess convergence per iteration, we define the discrete residual at iterate $u^{(k)}$ by\n$$\nr^{(k)}_{i,j} \\;=\\; u^{(k)}_{i-1,j}+u^{(k)}_{i+1,j}+u^{(k)}_{i,j-1}+u^{(k)}_{i,j+1}-4\\,u^{(k)}_{i,j},\n$$\nfor interior $(i,j)$, and its Euclidean norm\n$$\n\\|r^{(k)}\\|_2 \\;=\\; \\left(\\sum_{i=1}^{N_y}\\sum_{j=1}^{N_x}\\big(r^{(k)}_{i,j}\\big)^2\\right)^{1/2}.\n$$\nA standard stopping condition for iterative linear solvers is to bound the relative residual $\\|r^{(k)}\\|_2/\\|r^{(0)}\\|_2$ by a tolerance $\\tau$. We use $\\tau=10^{-8}$. The maximum iteration cap $K_{\\max}=10^5$ ensures termination for edge cases.\n\nTwo iteration orderings are considered:\n\n$1.$ Lexicographic ordering updates $u_{i,j}$ sequentially for $i=1,2,\\dots,N_y$ and, for each fixed $i$, $j=1,2,\\dots,N_x$. Each update enforces the discrete equation at $(i,j)$:\n$$\nu_{i,j}^{(k+1)} \\;\\gets\\; \\frac{1}{4}\\,\\Big(u_{i-1,j}^{(k+1)}+u_{i+1,j}^{(k)}+u_{i,j-1}^{(k+1)}+u_{i,j+1}^{(k)}\\Big),\n$$\ni.e., the newly updated values within the same sweep are immediately reused, which is the Gauss–Seidel iteration in a fixed linearization order.\n\n$2.$ Two-color checkerboard ordering partitions interior indices into two disjoint sets by parity: define the “red” set $\\mathcal{R}=\\{(i,j):\\,1\\le i\\le N_y,\\,1\\le j\\le N_x,\\,(i+j)\\text{ is even}\\}$ and the “black” set $\\mathcal{B}=\\{(i,j):\\,1\\le i\\le N_y,\\,1\\le j\\le N_x,\\,(i+j)\\text{ is odd}\\}$. Because the five-point stencil couples only to the four nearest neighbors and each neighbor of a red node is black (and vice versa), all nodes of a given color can be updated simultaneously without intra-color data dependencies. One full iteration consists of two sub-sweeps:\n$$\n\\text{Red sweep: } u_{i,j}^{(k+\\frac{1}{2})} \\;\\gets\\; \\frac{1}{4}\\,\\Big(u_{i-1,j}^{(k)}+u_{i+1,j}^{(k)}+u_{i,j-1}^{(k)}+u_{i,j+1}^{(k)}\\Big)\\quad \\text{for }(i,j)\\in\\mathcal{R},\n$$\nfollowed by\n$$\n\\text{Black sweep: } u_{i,j}^{(k+1)} \\;\\gets\\; \\frac{1}{4}\\,\\Big(u_{i-1,j}^{(k+\\frac{1}{2})}+u_{i+1,j}^{(k+\\frac{1}{2})}+u_{i,j-1}^{(k+\\frac{1}{2})}+u_{i,j+1}^{(k+\\frac{1}{2})}\\Big)\\quad \\text{for }(i,j)\\in\\mathcal{B}.\n$$\nBy construction, this ordering preserves the Gauss–Seidel property (using the newest available neighbor values), while exposing potential parallelism since all nodes in $\\mathcal{R}$ (and then all in $\\mathcal{B}$) are mutually independent during their respective sub-sweeps.\n\nFor each method, we measure two quantities:\n\n$-$ The iteration count $I$ is the minimal $k$ such that $\\|r^{(k)}\\|_2/\\|r^{(0)}\\|_2\\le \\tau$, with $\\tau=10^{-8}$, or $I=K_{\\max}$ if not achieved.\n\n$-$ The empirical asymptotic convergence factor $\\rho$ estimates the per-iteration linear contraction in the asymptotic regime. Given the residual norms $\\{\\|r^{(0)}\\|_2,\\dots,\\|r^{(I)}\\|_2\\}$, we define $m=\\min\\{10,\\,I-1\\}$ and compute\n$$\n\\rho \\;=\\; \\begin{cases}\n0,  I2,\\\\\n\\dfrac{1}{m}\\sum\\limits_{s=I-m}^{I-1}\\dfrac{\\|r^{(s+1)}\\|_2}{\\|r^{(s)}\\|_2},  I\\ge 2.\n\\end{cases}\n$$\nThis averaging over the last $m$ ratios suppresses transient effects and approximates the spectral radius of the iteration operator restricted to the dominant error mode.\n\nTo quantify parallelization potential for the two-color ordering, note that the red and black sets partition the $N_xN_y$ interior nodes. Their sizes are\n$$\nn_{\\text{red}} \\;=\\; \\left\\lceil \\frac{N_xN_y}{2}\\right\\rceil,\\qquad\nn_{\\text{black}} \\;=\\; N_xN_y - n_{\\text{red}},\n$$\nso the fraction of nodes that can be updated concurrently in the larger color class per sub-sweep is\n$$\n\\mathcal{P} \\;=\\; \\frac{\\max\\{n_{\\text{red}},\\,n_{\\text{black}}\\}}{N_xN_y} \\;=\\; \\frac{\\left\\lceil \\frac{N_xN_y}{2}\\right\\rceil}{N_xN_y}.\n$$\nThis is an idealized metric of concurrency; in practice, hardware and memory bandwidth considerations affect realized speedup.\n\nImplementation details consistent with these principles are as follows. We assemble the boundary values using $u(x,1)=\\sin(\\pi x)$ and zeros elsewhere. The lexicographic Gauss–Seidel update applies the averaging formula in nested loops over $(i,j)$, whereas the two-color update applies the same formula on $\\mathcal{R}$ and $\\mathcal{B}$ in two sub-sweeps, which can be implemented efficiently using array slicing to emulate simultaneous updates within each color. After each full iteration, we compute the residual norm $\\|r^{(k)}\\|_2$ by applying the discrete Laplacian to the current iterate and aggregating over interior nodes. We then test the relative residual against $\\tau=10^{-8}$ and record $I$ and $\\rho$ as defined above. For each test case $(N_x,N_y)$ in $\\{(30,30),(1,1),(63,31)\\}$, we return the list $[I_{\\text{lex}},I_{\\text{rb}},\\rho_{\\text{lex}},\\rho_{\\text{rb}},\\mathcal{P}]$, rounding the three decimal values to exactly $6$ digits after the decimal point and keeping the iteration counts as integers. The final program prints a single-line list of these per-case lists in the specified order and format.", "answer": "```python\nimport numpy as np\n\ndef build_boundary(Nx, Ny):\n    # Full grid size includes boundaries\n    u = np.zeros((Ny + 2, Nx + 2), dtype=np.float64)\n    # Grid spacing\n    hx = 1.0 / (Nx + 1)\n    # Top boundary: y = 1 => sin(pi x)\n    x = np.linspace(0.0, 1.0, Nx + 2)\n    u[Ny + 1, :] = np.sin(np.pi * x)\n    # Other boundaries are already zero\n    return u\n\ndef residual_norm(u):\n    # Compute discrete Laplacian residual on interior using 5-point stencil\n    r = (u[0:-2, 1:-1] + u[2:, 1:-1] + u[1:-1, 0:-2] + u[1:-1, 2:] - 4.0 * u[1:-1, 1:-1])\n    return float(np.linalg.norm(r.ravel(), 2))\n\ndef iterate_lex(u, Nx, Ny, tau, kmax):\n    # Lexicographic Gauss-Seidel iterations\n    res = []\n    r0 = residual_norm(u)\n    res.append(r0)\n    if r0 == 0.0:\n        return 0, 0.0  # already converged\n    for k in range(1, kmax + 1):\n        # sweep\n        for i in range(1, Ny + 1):\n            ui_minus = u[i - 1, :]\n            ui_plus = u[i + 1, :]\n            ui = u[i, :]\n            for j in range(1, Nx + 1):\n                ui[j] = 0.25 * (ui_minus[j] + ui_plus[j] + ui[j - 1] + ui[j + 1])\n        rk = residual_norm(u)\n        res.append(rk)\n        if rk / r0 = tau:\n            I = k\n            break\n    else:\n        I = kmax\n    # Empirical asymptotic factor\n    if len(res)  2:\n        rho = 0.0\n    else:\n        m = min(10, len(res) - 1)\n        tail = np.array(res[-(m + 1):], dtype=np.float64)\n        # Avoid division by zero; if previous residual is zero, ratio taken as 0\n        prev = tail[:-1]\n        nxt = tail[1:]\n        ratios = np.where(prev > 0.0, nxt / prev, 0.0)\n        rho = float(np.mean(ratios))\n    return I, rho\n\ndef iterate_red_black(u, Nx, Ny, tau, kmax):\n    # Red-black Gauss-Seidel with vectorized color updates\n    res = []\n    r0 = residual_norm(u)\n    res.append(r0)\n    if r0 == 0.0:\n        return 0, 0.0\n    for k in range(1, kmax + 1):\n        # Red sweep: (i+j) even.\n        # Odd interior rows (i=1,3,...) with odd columns (j=1,3,...)\n        u[1:Ny+1:2, 1:Nx+1:2] = 0.25 * (\n            u[0:Ny:2, 1:Nx+1:2] + u[2:Ny+2:2, 1:Nx+1:2] +\n            u[1:Ny+1:2, 0:Nx:2] + u[1:Ny+1:2, 2:Nx+2:2]\n        )\n        # Even interior rows (i=2,4,...) with even columns (j=2,4,...)\n        if Ny >= 2 and Nx >= 2:\n            u[2:Ny+1:2, 2:Nx+1:2] = 0.25 * (\n                u[1:Ny:2, 2:Nx+1:2] + u[3:Ny+2:2, 2:Nx+1:2] +\n                u[2:Ny+1:2, 1:Nx:2] + u[2:Ny+1:2, 3:Nx+2:2]\n            )\n        # Black sweep: (i+j) odd.\n        # Odd interior rows (i=1,3,...) with even columns (j=2,4,...)\n        if Nx >= 1:\n            u[1:Ny+1:2, 2:Nx+1:2] = 0.25 * (\n                u[0:Ny:2, 2:Nx+1:2] + u[2:Ny+2:2, 2:Nx+1:2] +\n                u[1:Ny+1:2, 1:Nx:2] + u[1:Ny+1:2, 3:Nx+2:2]\n            )\n        # Even interior rows (i=2,4,...) with odd columns (j=1,3,...)\n        u[2:Ny+1:2, 1:Nx+1:2] = 0.25 * (\n            u[1:Ny:2, 1:Nx+1:2] + u[3:Ny+2:2, 1:Nx+1:2] +\n            u[2:Ny+1:2, 0:Nx:2] + u[2:Ny+1:2, 2:Nx+2:2]\n        )\n        rk = residual_norm(u)\n        res.append(rk)\n        if rk / r0 = tau:\n            I = k\n            break\n    else:\n        I = kmax\n    if len(res)  2:\n        rho = 0.0\n    else:\n        m = min(10, len(res) - 1)\n        tail = np.array(res[-(m + 1):], dtype=np.float64)\n        prev = tail[:-1]\n        nxt = tail[1:]\n        ratios = np.where(prev > 0.0, nxt / prev, 0.0)\n        rho = float(np.mean(ratios))\n    return I, rho\n\ndef parallel_fraction(Nx, Ny):\n    n = Nx * Ny\n    if n == 0:\n        return 0.0\n    # Largest color class size under checkerboard coloring\n    red = (n + 1) // 2\n    black = n - red\n    return float(max(red, black) / n)\n\ndef run_case(Nx, Ny, tau=1e-8, kmax=100000):\n    # Build boundary-initialized grid\n    u_lex = build_boundary(Nx, Ny)\n    u_rb = u_lex.copy()\n\n    # Run lexicographic GS\n    I_lex, rho_lex = iterate_lex(u_lex, Nx, Ny, tau, kmax)\n\n    # Run red-black GS\n    I_rb, rho_rb = iterate_red_black(u_rb, Nx, Ny, tau, kmax)\n\n    # Parallelization potential\n    P = parallel_fraction(Nx, Ny)\n\n    return I_lex, I_rb, rho_lex, rho_rb, P\n\ndef format_case_result(res):\n    I_lex, I_rb, rho_lex, rho_rb, P = res\n    # Integers for iterations, floats with exactly 6 decimals for the others\n    return f\"[{I_lex},{I_rb},{rho_lex:.6f},{rho_rb:.6f},{P:.6f}]\"\n\ndef solve():\n    # Test suite: Case A, B, C\n    test_cases = [\n        (30, 30),  # Case A\n        (1, 1),    # Case B\n        (63, 31),  # Case C\n    ]\n    results = []\n    for Nx, Ny in test_cases:\n        # Initialize anew for each case and run\n        I_lex, I_rb, rho_lex, rho_rb, P = run_case(Nx, Ny, tau=1e-8, kmax=100000)\n        results.append((I_lex, I_rb, rho_lex, rho_rb, P))\n    # Print in the required single-line format\n    inner = \",\".join(format_case_result(r) for r in results)\n    print(f\"[{inner}]\")\n\nif __name__ == \"__main__\":\n    solve()\n```", "id": "2392150"}, {"introduction": "With a functional solver, you can now use it as a computational laboratory to investigate complex mathematical phenomena. This practice explores how the Laplace operator responds to non-smooth boundary data, specifically a sharp jump discontinuity. You will observe the Gibbs phenomenon, a characteristic overshoot, on the boundary and witness the powerful smoothing effect of the elliptic operator as this oscillation is damped away from the boundary. This numerical experiment [@problem_id:2392134] provides tangible insight into the maximum principle and the smoothing properties of elliptic partial differential equations.", "problem": "Consider the Laplace equation on the unit square domain $\\Omega = (0,1) \\times (0,1)$ with Dirichlet boundary conditions. Let $u(x,y)$ satisfy\n$$\n\\frac{\\partial^2 u}{\\partial x^2}(x,y) + \\frac{\\partial^2 u}{\\partial y^2}(x,y) = 0 \\quad \\text{for all } (x,y) \\in \\Omega,\n$$\nwith boundary data $u(x,y) = g(x,y)$ on $\\partial \\Omega$, where $g(x,y)$ is specified as follows. On the top edge $\\{(x,1) : x \\in [0,1]\\}$, define a jump discontinuity at $x_0 = 0.5$ of unit height. Two variants of the top-edge boundary data are to be used:\n- Exact step: $g(x,1) = 1$ for $x \\in [x_0,1]$ and $g(x,1) = 0$ for $x \\in [0,x_0)$.\n- Truncated Fourier partial sum: Let $f(x)$ be the $1$-periodic extension of the step function taking $0$ on $[0,x_0)$ and $1$ on $[x_0,1)$; for a given integer $K \\ge 1$, define\n$$\ng_K(x,1) = \\frac{1}{2} + \\frac{2}{\\pi} \\sum_{j=1}^{K} \\frac{1}{2j-1} \\sin\\!\\big(2\\pi (2j-1)(x - x_0)\\big).\n$$\nOn the remaining three edges $\\{(x,0): x \\in [0,1]\\}$, $\\{(0,y): y \\in [0,1]\\}$, and $\\{(1,y): y \\in [0,1]\\}$, set $g(x,y) = 0$. At the top two corners $\\{(0,1),(1,1)\\}$, adopt the value from the top edge (that is, use the top-edge $g$ there). No physical units apply.\n\nDiscretize the domain by a uniform grid of $(N+1)\\times(N+1)$ nodes with spacing $h = 1/N$, where $N$ is a positive integer. Let $u_{i,j}$ approximate $u(x_i, y_j)$ at grid points $(x_i, y_j) = (ih, jh)$ for integers $i,j \\in \\{0,1,\\dots,N\\}$. On the interior nodes $(i,j)$ with $i,j \\in \\{1,2,\\dots,N-1\\}$, enforce the standard five-point finite difference discretization\n$$\n4 u_{i,j} - u_{i-1,j} - u_{i+1,j} - u_{i,j-1} - u_{i,j+1} = 0,\n$$\nand impose Dirichlet boundary values $u_{i,j} = g(x_i,y_j)$ at boundary nodes.\n\nDefine the normalized positive overshoot of a discrete function $v_i$ relative to an upper reference value $U$ as\n$$\n\\mathcal{O}^+(v; U) = \\max\\big(0, \\max_i v_i - U\\big).\n$$\nFor each configuration below, you must compute two scalar quantities as specified:\n1. The boundary overshoot on the top edge for the chosen top-edge boundary data (using $U=1$), that is $\\mathcal{O}^+\\big(\\{g(x_i,1)\\}_{i=0}^N; 1\\big)$.\n2. The interior near-boundary overshoot along the grid line one step inside the domain from the top edge (that is, $y = 1 - h$), computed from the discrete solution, using $U=1$:\n$$\n\\mathcal{O}^+\\big(\\{u(x_i,1-h)\\}_{i=0}^N; 1\\big).\n$$\n\nUse the following test suite of parameter values:\n- Case A: $N = 64$, exact step on the top edge. Report only the interior near-boundary overshoot (do not report a boundary overshoot for this case).\n- Case B: $N = 64$, truncated Fourier top edge with $K = 11$. Report both the boundary overshoot and the interior near-boundary overshoot.\n- Case C: $N = 128$, truncated Fourier top edge with $K = 21$. Report both the boundary overshoot and the interior near-boundary overshoot.\n- Case D: $N = 256$, truncated Fourier top edge with $K = 51$. Report both the boundary overshoot and the interior near-boundary overshoot.\n\nYour program must produce a single line of output containing the results as a comma-separated list enclosed in square brackets, in the following order:\n$$\n[\\text{A\\_interior}, \\text{B\\_boundary}, \\text{B\\_interior}, \\text{C\\_boundary}, \\text{C\\_interior}, \\text{D\\_boundary}, \\text{D\\_interior}],\n$$\nwith each real number rounded to six decimal places. No other text should be printed.", "solution": "The problem statement is subjected to validation and is found to be valid. It is scientifically grounded, well-posed, and objective. It poses a standard, well-defined problem in the field of computational engineering, specifically the numerical solution of the Laplace equation using the finite difference method. All necessary data and conditions are provided, and no contradictions are present. The investigation of the Gibbs phenomenon in the context of a partial differential equation solution is a meaningful and verifiable numerical experiment.\n\nThe problem requires the solution of the two-dimensional Laplace equation,\n$$\n\\nabla^2 u(x,y) = \\frac{\\partial^2 u}{\\partial x^2}(x,y) + \\frac{\\partial^2 u}{\\partial y^2}(x,y) = 0,\n$$\non the unit square domain $\\Omega = (0,1) \\times (0,1)$. The solution $u(x,y)$ must satisfy specified Dirichlet boundary conditions $u(x,y) = g(x,y)$ on the boundary $\\partial \\Omega$. The boundary is held at $g(x,y)=0$ on the bottom, left, and right edges. On the top edge, $y=1$, the boundary condition is given by either an exact step function or a truncated Fourier series approximation of it, both centered at $x_0=0.5$.\n\nThe domain is discretized using a uniform grid with $(N+1) \\times (N+1)$ nodes $(x_i, y_j) = (ih, jh)$ where $h=1/N$ is the grid spacing and $i, j \\in \\{0, 1, \\dots, N\\}$. The numerical solution at these nodes is denoted by $u_{i,j}$. The Laplace equation is approximated at the interior nodes, where $i,j \\in \\{1, 2, \\dots, N-1\\}$, using the standard five-point finite difference stencil:\n$$\n\\frac{u_{i-1,j} - 2u_{i,j} + u_{i+1,j}}{h^2} + \\frac{u_{i,j-1} - 2u_{i,j} + u_{i,j+1}}{h^2} \\approx 0.\n$$\nMultiplying by $h^2$ and rearranging terms gives the algebraic equation for each interior node $(i,j)$:\n$$\n4 u_{i,j} - u_{i-1,j} - u_{i+1,j} - u_{i,j-1} - u_{i,j+1} = 0.\n$$\nThis set of equations for all $(N-1)^2$ interior nodes forms a large, sparse linear system of the form $A \\mathbf{u} = \\mathbf{b}$. The vector of unknowns $\\mathbf{u}$ contains the values of the solution at the interior nodes, ordered lexicographically: $\\mathbf{u} = [u_{1,1}, u_{2,1}, \\dots, u_{N-1,1}, u_{1,2}, \\dots, u_{N-1,N-1}]^T$.\n\nThe matrix $A$ is a square matrix of size $(N-1)^2 \\times (N-1)^2$. For the five-point stencil, it is a symmetric positive-definite, block-tridiagonal matrix. It can be constructed efficiently using Kronecker products. Let $T_{N-1}$ be the $(N-1) \\times (N-1)$ tridiagonal matrix with $1$ on the sub- and super-diagonals and $0$ elsewhere, and let $I_{N-1}$ be the identity matrix of the same size. The matrix of the system can be expressed as:\n$$\nA = 4 I_{(N-1)^2} - (I_{N-1} \\otimes T_{N-1}) - (T_{N-1} \\otimes I_{N-1}).\n$$\nThe right-hand side vector $\\mathbf{b}$ incorporates the known boundary values. When an equation for an interior node $(i,j)$ involves a neighbor on the boundary, that boundary value is moved to the right-hand side. In this problem, the boundary values are zero everywhere except on the top edge $y=1$. Therefore, the only non-zero entries in $\\mathbf{b}$ arise from the equations for the top row of interior nodes, i.e., for $j=N-1$. For these nodes, the stencil involves the term $u_{i,N}$, which is a known boundary value $g(x_i, 1)$. The corresponding equations become:\n$$\n4 u_{i,N-1} - u_{i-1,N-1} - u_{i+1,N-1} - u_{i,N-2} = g(x_i, 1).\n$$\nThus, the entries of $\\mathbf{b}$ corresponding to nodes $(i, N-1)$ for $i=1, \\dots, N-1$ are equal to $g(x_i, 1)$, while all other entries are zero.\n\nAfter solving the linear system $A \\mathbf{u} = \\mathbf{b}$ for the interior values $\\mathbf{u}$, we calculate the required overshoot quantities. The normalized positive overshoot is defined as $\\mathcal{O}^+(v; U) = \\max(0, \\max_i v_i - U)$.\nThe two quantities of interest are:\n1.  Boundary overshoot: $\\mathcal{O}^+\\big(\\{g(x_i,1)\\}_{i=0}^N; 1\\big)$. This measures the maximum amount by which the top boundary data exceeds the reference value $U=1$.\n2.  Interior near-boundary overshoot: $\\mathcal{O}^+\\big(\\{u_{i,N-1}\\}_{i=0}^N; 1\\big)$. This measures the overshoot on the grid line just inside the top boundary, at $y=1-h$. Note that the set includes boundary points $u_{0,N-1}=g(0, 1-h)=0$ and $u_{N,N-1}=g(1, 1-h)=0$.\n\nFor Case A, the top boundary is an exact step function with values $0$ and $1$. The maximum value on the boundary is exactly $1$. The discrete maximum principle for the Laplace equation guarantees that the maximum of the discrete solution $u_{i,j}$ cannot exceed the maximum of the boundary values. Therefore, for all interior nodes, $u_{i,j} \\le 1$. Consequently, the interior near-boundary overshoot must be $0$.\n\nFor Cases B, C, and D, the top boundary is defined by a truncated Fourier series. It is a known property of Fourier series approximations of functions with jump discontinuities that they exhibit overshoots near the discontinuity, a phenomenon known as the Gibbs phenomenon. The magnitude of this overshoot is approximately $9\\%$ of the jump height. We therefore expect the boundary function $g_K(x_i,1)$ to have a maximum value greater than $1$, leading to a positive boundary overshoot. The interior solution $u_{i,j}$ will be influenced by this boundary overshoot. However, the elliptic nature of the Laplace operator has a smoothing effect. By the strong maximum principle, the maximum of a non-constant solution must occur on the boundary. Thus, we expect the interior overshoot to be strictly less than the boundary overshoot, demonstrating the damping of the oscillation as we move into the domain.\n\nThe computational procedure involves:\n1.  For each test case, define the parameters $N$ and $K$ (if applicable).\n2.  Generate the grid points $x_i = i/N$ for $i=0, \\dots, N$.\n3.  Compute the top boundary values $g(x_i, 1)$ according to the case (exact step or Fourier sum).\n4.  For Fourier cases, calculate the boundary overshoot.\n5.  Construct the sparse matrix $A$ and the right-hand side vector $\\mathbf{b}$.\n6.  Solve the linear system $A \\mathbf{u} = \\mathbf{b}$ using a sparse linear algebra solver.\n7.  Extract the solution values on the line $y=1-h$, which are the last $N-1$ components of the solution vector $\\mathbf{u}$.\n8.  Assemble the full row of values $\\{u_{i,N-1}\\}_{i=0}^N$, including the zero boundary conditions at $i=0$ and $i=N$.\n9.  Calculate the interior near-boundary overshoot.\n10. Store the results and format them as required.\nThis procedure will be implemented for all specified test cases.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.sparse import diags, identity, kron\nfrom scipy.sparse.linalg import spsolve\n\ndef solve_laplace(N, g_top):\n    \"\"\"\n    Solves the 2D Laplace equation on a unit square using a 5-point\n    finite difference scheme.\n\n    Args:\n        N (int): Number of intervals in each dimension. The grid is (N+1)x(N+1).\n        g_top (np.ndarray): Array of N+1 boundary values on the top edge y=1.\n\n    Returns:\n        np.ndarray: Array of N+1 solution values u(x_i, 1-h) along the line y=1-h.\n    \"\"\"\n    N_inner = N - 1\n    if N_inner == 0:\n        return np.zeros(N + 1)\n    M = N_inner**2\n\n    # Assemble the sparse matrix A using Kronecker products.\n    # The matrix represents the operator 4*I - (Laplacian_x + Laplacian_y)\n    # in matrix form for the interior grid points.\n    T1D = diags([1, 1], [-1, 1], shape=(N_inner, N_inner), format='csr')\n    I_n = identity(N_inner, format='csr')\n\n    A = 4 * identity(M, format='csr') - kron(I_n, T1D) - kron(T1D, I_n)\n    \n    # Assemble the right-hand side vector b.\n    # Non-zero entries only come from the top boundary condition g(x,1).\n    # These affect the equations for the top row of interior nodes (j=N-1).\n    b = np.zeros(M)\n    start_idx = (N - 2) * N_inner\n    b[start_idx:] = g_top[1:N]  # Values at x_1, ..., x_{N-1}\n\n    # Solve the sparse linear system A * u = b.\n    u_interior_flat = spsolve(A, b)\n\n    # Extract the solution at the line y = 1 - h.\n    # These correspond to the last (N-1) elements of the solution vector.\n    u_near_boundary_interior = u_interior_flat[start_idx:]\n\n    # Assemble the full row, including the boundary values u(0, 1-h) and u(1, 1-h).\n    # These are 0 as per the problem statement.\n    u_full_row = np.zeros(N + 1)\n    u_full_row[1:N] = u_near_boundary_interior\n\n    return u_full_row\n\ndef calculate_overshoot(v, U=1.0):\n    \"\"\"Calculates the normalized positive overshoot.\"\"\"\n    return max(0.0, np.max(v) - U)\n\ndef solve():\n    \"\"\"\n    Main function to run the test suite and print results.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        {'case': 'A', 'N': 64, 'type': 'exact_step'},\n        {'case': 'B', 'N': 64, 'K': 11, 'type': 'fourier'},\n        {'case': 'C', 'N': 128, 'K': 21, 'type': 'fourier'},\n        {'case': 'D', 'N': 256, 'K': 51, 'type': 'fourier'},\n    ]\n\n    results = []\n    for params in test_cases:\n        N = params['N']\n        x = np.linspace(0.0, 1.0, N + 1)\n        x0 = 0.5\n\n        if params['type'] == 'exact_step':\n            g_top = np.where(x >= x0, 1.0, 0.0)\n            \n            # Case A: only interior overshoot is reported.\n            # As per the discrete maximum principle, this must be 0.\n            # We compute it for verification.\n            u_row = solve_laplace(N, g_top)\n            interior_overshoot = calculate_overshoot(u_row)\n            results.append(interior_overshoot)\n        \n        elif params['type'] == 'fourier':\n            K = params['K']\n            g_top = np.full_like(x, 0.5, dtype=float)\n            \n            # Vectorized calculation of the truncated Fourier sum\n            j_vals = np.arange(1, K + 1)\n            coeffs = (2.0 / np.pi) * (1.0 / (2 * j_vals - 1))\n            arg_x = 2.0 * np.pi * (x[:, np.newaxis] - x0)\n            arg_j = (2 * j_vals - 1)\n            sines = np.sin(arg_x * arg_j)\n            g_top += np.sum(coeffs * sines, axis=1)\n\n            # Calculate boundary overshoot\n            boundary_overshoot = calculate_overshoot(g_top)\n            results.append(boundary_overshoot)\n\n            # Solve for and calculate interior overshoot\n            u_row = solve_laplace(N, g_top)\n            interior_overshoot = calculate_overshoot(u_row)\n            results.append(interior_overshoot)\n\n    # Final print statement in the exact required format.\n    formatted_results = [f\"{r:.6f}\" for r in results]\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```", "id": "2392134"}]}