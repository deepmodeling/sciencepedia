{"hands_on_practices": [{"introduction": "To begin, let's ground our understanding of divided differences in a practical engineering scenario. This first exercise [@problem_id:2189672] guides you through the fundamental mechanics of taking discrete experimental data—in this case, the thermal conductivity of a new alloy at different temperatures—and constructing a continuous predictive model. You will practice building a divided difference table from scratch and using the coefficients to form a Newton polynomial, providing a robust tool for interpolating values between known data points.", "problem": "A materials science lab is characterizing a new metallic alloy intended for high-performance heat exchangers. The thermal conductivity, $k$, of the alloy is measured at several distinct temperatures, $T$. The experimental data are as follows:\n\n- At $T_0 = 100$ K, the conductivity is $k_0 = 400$ W/(m·K).\n- At $T_1 = 200$ K, the conductivity is $k_1 = 390$ W/(m·K).\n- At $T_2 = 400$ K, the conductivity is $k_2 = 350$ W/(m·K).\n- At $T_3 = 600$ K, the conductivity is $k_3 = 300$ W/(m·K).\n\nTo predict the alloy's behavior at intermediate temperatures, an engineer decides to model the thermal conductivity using a cubic interpolating polynomial in Newton's form, $P_3(T)$, that passes through all four data points.\n\nYour task is to determine the coefficients of this polynomial from a divided differences table and then use Horner's nested evaluation method to estimate the thermal conductivity of the alloy at a temperature of $T = 300$ K.\n\nExpress your final answer for the thermal conductivity in W/(m·K), rounded to four significant figures.", "solution": "We are given data points $(T_{0},k_{0})=(100,400)$, $(T_{1},k_{1})=(200,390)$, $(T_{2},k_{2})=(400,350)$, $(T_{3},k_{3})=(600,300)$, and we construct the cubic Newton interpolating polynomial\n$$\nP_{3}(T)=f[T_{0}]+f[T_{0},T_{1}](T-T_{0})+f[T_{0},T_{1},T_{2}](T-T_{0})(T-T_{1})+f[T_{0},T_{1},T_{2},T_{3}](T-T_{0})(T-T_{1})(T-T_{2}).\n$$\nCompute divided differences step by step. First-order:\n$$\nf[T_{0},T_{1}]=\\frac{k_{1}-k_{0}}{T_{1}-T_{0}}=\\frac{390-400}{200-100}=-\\frac{1}{10},\n$$\n$$\nf[T_{1},T_{2}]=\\frac{k_{2}-k_{1}}{T_{2}-T_{1}}=\\frac{350-390}{400-200}=-\\frac{1}{5},\n$$\n$$\nf[T_{2},T_{3}]=\\frac{k_{3}-k_{2}}{T_{3}-T_{2}}=\\frac{300-350}{600-400}=-\\frac{1}{4}.\n$$\nSecond-order:\n$$\nf[T_{0},T_{1},T_{2}]=\\frac{f[T_{1},T_{2}]-f[T_{0},T_{1}]}{T_{2}-T_{0}}=\\frac{-\\frac{1}{5}-\\left(-\\frac{1}{10}\\right)}{400-100}=-\\frac{1}{3000},\n$$\n$$\nf[T_{1},T_{2},T_{3}]=\\frac{f[T_{2},T_{3}]-f[T_{1},T_{2}]}{T_{3}-T_{1}}=\\frac{-\\frac{1}{4}-\\left(-\\frac{1}{5}\\right)}{600-200}=-\\frac{1}{8000}.\n$$\nThird-order:\n$$\nf[T_{0},T_{1},T_{2},T_{3}]=\\frac{f[T_{1},T_{2},T_{3}]-f[T_{0},T_{1},T_{2}]}{T_{3}-T_{0}}=\\frac{-\\frac{1}{8000}-\\left(-\\frac{1}{3000}\\right)}{600-100}=\\frac{1}{2400000}.\n$$\nThus the Newton-form coefficients are\n$$\na_{0}=f[T_{0}]=400,\\quad a_{1}=f[T_{0},T_{1}]=-\\frac{1}{10},\\quad a_{2}=f[T_{0},T_{1},T_{2}]=-\\frac{1}{3000},\\quad a_{3}=f[T_{0},T_{1},T_{2},T_{3}]=\\frac{1}{2400000}.\n$$\nHence\n$$\nP_{3}(T)=400-\\frac{1}{10}(T-100)-\\frac{1}{3000}(T-100)(T-200)+\\frac{1}{2400000}(T-100)(T-200)(T-400).\n$$\nUse Horner’s nested evaluation at $T=300$:\n$$\nb_{2}=a_{2}+(T-T_{2})a_{3}=-\\frac{1}{3000}+(-100)\\cdot\\frac{1}{2400000}=-\\frac{1}{3000}-\\frac{1}{24000}=-\\frac{3}{8000},\n$$\n$$\nb_{1}=a_{1}+(T-T_{1})b_{2}=-\\frac{1}{10}+100\\left(-\\frac{3}{8000}\\right)=-\\frac{1}{10}-\\frac{3}{80}=-\\frac{11}{80},\n$$\n$$\nP_{3}(300)=a_{0}+(T-T_{0})b_{1}=400+200\\left(-\\frac{11}{80}\\right)=400-\\frac{2200}{80}=372.5.\n$$\nRounding to four significant figures gives $372.5$ W/(m·K).", "answer": "$$\\boxed{372.5}$$", "id": "2189672"}, {"introduction": "Beyond simply fitting a curve to data, divided differences provide a powerful diagnostic tool for understanding the nature of the data itself. This problem [@problem_id:2386657] shifts our focus from calculation to analysis, challenging you to determine the minimal polynomial degree that can represent a given dataset. By observing how higher-order differences behave—specifically, whether they stabilize or approach zero—you can infer if the data originates from a simple underlying polynomial function, a key insight for model selection.", "problem": "A dataset of scalar pairs $(x_i, y_i)$ is recorded at five distinct nodes for use in a surrogate model within computational engineering. The nodes and values are:\n$(-2, -17)$, $(-1, 0)$, $(0, 4)$, $(1, 4)$, $(2, 9)$.\nBased only on the mathematical property of polynomials as reflected in divided differences, select the most precise statement about the minimal degree of a single-variable polynomial that can exactly generate all five data points.\n\nA. The data are consistent with a polynomial of degree at most $2$.\n\nB. The data are consistent with a polynomial of degree at most $3$ but not with any polynomial of degree at most $2$.\n\nC. The data are consistent with a polynomial of degree at most $4$ but not with any polynomial of degree at most $3$.\n\nD. No polynomial of degree at most $4$ can interpolate all the points.", "solution": "The problem statement is subjected to validation.\n\n**Step 1: Extract Givens**\nThe provided data consists of a set of five scalar pairs $(x_i, y_i)$:\n$(-2, -17)$, $(-1, 0)$, $(0, 4)$, $(1, 4)$, $(2, 9)$.\nThe objective is to determine the most precise statement about the minimal degree of a single-variable polynomial that interpolates these five data points, using the method of divided differences.\n\n**Step 2: Validate Using Extracted Givens**\nThe problem is scientifically grounded in the theory of polynomial interpolation, a fundamental topic in numerical analysis. The concept of divided differences is a standard technique for constructing and analyzing interpolating polynomials. The problem is well-posed: for a set of $n+1$ distinct points, there exists a unique interpolating polynomial of degree at most $n$. The task of finding the *minimal* degree is a well-defined sub-problem that is resolved by inspecting the divided difference table. The data are complete and consistent. No scientific or logical flaws are present.\n\n**Step 3: Verdict and Action**\nThe problem is valid. We will proceed with a rigorous solution.\n\nThe minimal degree of a polynomial that fits a given set of data points can be determined by constructing a Newton divided difference table. For a polynomial of degree $n$, its $n$-th order divided differences are constant, and its $(n+1)$-th order divided differences are zero.\n\nLet the given data points be $(x_i, y_i)$ for $i=0, 1, 2, 3, 4$.\n$x_0 = -2, y_0 = -17$\n$x_1 = -1, y_1 = 0$\n$x_2 = 0, y_2 = 4$\n$x_3 = 1, y_3 = 4$\n$x_4 = 2, y_4 = 9$\n\nThe zeroth-order divided differences are the function values themselves, $f[x_i] = y_i$.\n\nThe first-order divided differences are calculated as:\n$f[x_0, x_1] = \\frac{y_1 - y_0}{x_1 - x_0} = \\frac{0 - (-17)}{-1 - (-2)} = \\frac{17}{1} = 17$\n$f[x_1, x_2] = \\frac{y_2 - y_1}{x_2 - x_1} = \\frac{4 - 0}{0 - (-1)} = \\frac{4}{1} = 4$\n$f[x_2, x_3] = \\frac{y_3 - y_2}{x_3 - x_2} = \\frac{4 - 4}{1 - 0} = \\frac{0}{1} = 0$\n$f[x_3, x_4] = \\frac{y_4 - y_3}{x_4 - x_3} = \\frac{9 - 4}{2 - 1} = \\frac{5}{1} = 5$\n\nThe second-order divided differences are:\n$f[x_0, x_1, x_2] = \\frac{f[x_1, x_2] - f[x_0, x_1]}{x_2 - x_0} = \\frac{4 - 17}{0 - (-2)} = \\frac{-13}{2}$\n$f[x_1, x_2, x_3] = \\frac{f[x_2, x_3] - f[x_1, x_2]}{x_3 - x_1} = \\frac{0 - 4}{1 - (-1)} = \\frac{-4}{2} = -2$\n$f[x_2, x_3, x_4] = \\frac{f[x_3, x_4] - f[x_2, x_3]}{x_4 - x_2} = \\frac{5 - 0}{2 - 0} = \\frac{5}{2}$\n\nThe third-order divided differences are:\n$f[x_0, x_1, x_2, x_3] = \\frac{f[x_1, x_2, x_3] - f[x_0, x_1, x_2]}{x_3 - x_0} = \\frac{-2 - (-\\frac{13}{2})}{1 - (-2)} = \\frac{- \\frac{4}{2} + \\frac{13}{2}}{3} = \\frac{\\frac{9}{2}}{3} = \\frac{3}{2}$\n$f[x_1, x_2, x_3, x_4] = \\frac{f[x_2, x_3, x_4] - f[x_1, x_2, x_3]}{x_4 - x_1} = \\frac{\\frac{5}{2} - (-2)}{2 - (-1)} = \\frac{\\frac{5}{2} + \\frac{4}{2}}{3} = \\frac{\\frac{9}{2}}{3} = \\frac{3}{2}$\n\nThe third-order divided differences are constant and non-zero. This already suggests the minimal degree of the polynomial is $3$. To confirm, we calculate the fourth-order divided difference.\n\nThe fourth-order divided difference is:\n$f[x_0, x_1, x_2, x_3, x_4] = \\frac{f[x_1, x_2, x_3, x_4] - f[x_0, x_1, x_2, x_3]}{x_4 - x_0} = \\frac{\\frac{3}{2} - \\frac{3}{2}}{2 - (-2)} = \\frac{0}{4} = 0$\n\nSince the third-order divided differences are constant and equal to $\\frac{3}{2} \\neq 0$, and the fourth-order divided difference is $0$, the data correspond exactly to a polynomial of degree $3$. The Newton form of this polynomial is $P_3(x) = f[x_0] + f[x_0,x_1](x-x_0) + f[x_0,x_1,x_2](x-x_0)(x-x_1) + f[x_0,x_1,x_2,x_3](x-x_0)(x-x_1)(x-x_2)$. The coefficient of the highest degree term, $x^3$, is $f[x_0,x_1,x_2,x_3] = \\frac{3}{2}$, which is non-zero. Therefore, the minimal degree is exactly $3$.\n\nNow we evaluate the given options.\n\nA. The data are consistent with a polynomial of degree at most $2$.\nThis statement implies that the data could be represented by a polynomial of degree $2$, $1$, or $0$. For this to be true, all third-order divided differences must be zero. Our calculation shows the third-order divided differences are $\\frac{3}{2}$, which is not zero. Thus, the minimal degree of the polynomial must be greater than $2$.\nVerdict: **Incorrect**.\n\nB. The data are consistent with a polynomial of degree at most $3$ but not with any polynomial of degree at most $2$.\nThis statement is composed of two claims. First, \"consistent with a polynomial of degree at most $3$\". This is true if the fourth-order divided differences are zero. We found that $f[x_0, x_1, x_2, x_3, x_4] = 0$, confirming this part. Second, \"not with any polynomial of degree at most $2$\". This is true because the third-order divided differences are non-zero. As both claims are correct, the statement accurately describes that the minimal degree of the interpolating polynomial is exactly $3$.\nVerdict: **Correct**.\n\nC. The data are consistent with a polynomial of degree at most $4$ but not with any polynomial of degree at most $3$.\nThe first part, \"consistent with a polynomial of degree at most $4$\", is trivially true for any five points. A polynomial of degree $3$ is a special case of a polynomial of degree at most $4$ (with the $x^4$ coefficient being zero). However, the second part, \"not with any polynomial of degree at most $3$\", is false. As we have shown, the data are perfectly described by a polynomial of degree $3$.\nVerdict: **Incorrect**.\n\nD. No polynomial of degree at most $4$ can interpolate all the points.\nThis statement contradicts the fundamental theorem of polynomial interpolation, which guarantees that for any $n+1$ distinct points, there exists a unique polynomial of degree at most $n$ that passes through them. Here we have $5$ points, so $n=4$. A unique polynomial of degree at most $4$ must exist. We have explicitly found it to be a polynomial of degree $3$.\nVerdict: **Incorrect**.", "answer": "$$\\boxed{B}$$", "id": "2386657"}, {"introduction": "High-degree polynomial interpolation can sometimes lead to unexpected and wildly inaccurate results, a notorious issue known as the Runge phenomenon. This advanced computational practice [@problem_id:2426405] delves into this critical aspect of numerical stability by having you implement and compare interpolation strategies for the challenging Runge function. By contrasting the performance of interpolants built on equally spaced nodes versus strategically placed Chebyshev nodes, you will gain first-hand experience with how theoretical insights into node placement can overcome practical instabilities in computational engineering.", "problem": "You are to implement polynomial interpolation in Newton form for the Runge function using two node-generation strategies. Start from the fundamental definition that for $n+1$ distinct nodes $\\{x_0,\\dots,x_n\\}$ and function values $\\{f(x_0),\\dots,f(x_n)\\}$, there exists a unique polynomial $p_n(x)$ of degree at most $n$ that satisfies $p_n(x_i)=f(x_i)$ for all $i$. Use the recursive definition of divided differences and the Newton basis to derive a numerically stable evaluation algorithm. The target function is the Runge function $f(x)=\\dfrac{1}{1+25x^2}$ on $[-1,1]$. All angles must be in radians.\n\nYour tasks are:\n- Implement a function to compute the divided differences for nodes $\\{x_i\\}_{i=0}^n$ and values $\\{f(x_i)\\}_{i=0}^n$, producing the Newton-form coefficients $\\{c_0,\\dots,c_n\\}$ for $p_n(x)$.\n- Implement a function to evaluate the Newton-form interpolant at arbitrary $x$ using nested multiplication based on the Newton basis $\\{1,(x-x_0),(x-x_0)(x-x_1),\\dots\\}$ and the previously computed coefficients $\\{c_k\\}_{k=0}^n$.\n- Generate two sets of interpolation nodes on $[-1,1]$ for each degree $n$:\n  - Equally spaced nodes: $x_i=-1+\\dfrac{2i}{n}$ for $i=0,\\dots,n$.\n  - Chebyshev nodes of the first kind (extrema) on $[-1,1]$: $x_i=\\cos\\!\\left(\\dfrac{i\\pi}{n}\\right)$ for $i=0,\\dots,n$. Use radians.\n- For each interpolant, evaluate $p_n(x)$ on a dense grid of $M$ points uniformly spaced on $[-1,1]$ and compute the maximum absolute error $E_{\\max}=\\max_{x\\in\\mathcal{G}}|p_n(x)-f(x)|$, where $\\mathcal{G}$ is the evaluation grid.\n- Do all arithmetic in double precision.\n\nTest suite specification:\n- Use the Runge function $f(x)=\\dfrac{1}{1+25x^2}$ on $[-1,1]$.\n- Use an evaluation grid $\\mathcal{G}$ of $M=10001$ equally spaced points on $[-1,1]$.\n- Use the following degrees (with $n+1$ nodes each): $n\\in\\{0,1,5,10,20\\}$.\n- For each $n$ in the above set, compute two numbers: $E_{\\max}^{\\text{eq}}(n)$ for equally spaced nodes and $E_{\\max}^{\\text{ch}}(n)$ for Chebyshev nodes (with angles in radians).\n\nFinal output format:\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets. The list must contain real numbers in the following order:\n  - $\\big[E_{\\max}^{\\text{eq}}(0),E_{\\max}^{\\text{ch}}(0),E_{\\max}^{\\text{eq}}(1),E_{\\max}^{\\text{ch}}(1),E_{\\max}^{\\text{eq}}(5),E_{\\max}^{\\text{ch}}(5),E_{\\max}^{\\text{eq}}(10),E_{\\max}^{\\text{ch}}(10),E_{\\max}^{\\text{eq}}(20),E_{\\max}^{\\text{ch}}(20)\\big]$.\n- The output must be a single line and must not contain any additional text.", "solution": "The problem starts from the core definition of interpolation: given $n+1$ distinct nodes $\\{x_0,\\dots,x_n\\}$ and data values $\\{y_0,\\dots,y_n\\}$ with $y_i=f(x_i)$, there exists a unique polynomial $p_n(x)$ of degree at most $n$ such that $p_n(x_i)=y_i$ for $i=0,\\dots,n$. One constructive representation is the Newton form, which combines two fundamental pieces: divided differences and the Newton basis. The Newton basis is defined recursively as $N_0(x)=1$, $N_k(x)=(x-x_{k-1})N_{k-1}(x)$ for $k\\ge 1$, which yields $N_k(x)=\\prod_{j=0}^{k-1}(x-x_j)$. The interpolant can be expressed as $p_n(x)=\\sum_{k=0}^n c_k N_k(x)$, where the coefficients $c_k$ are the divided differences $c_k=f[x_0,\\dots,x_k]$. The divided differences are determined from the data via the recursion $f[x_i]=y_i$ and, for $k\\ge 1$, $f[x_i,\\dots,x_{i+k}]=\\dfrac{f[x_{i+1},\\dots,x_{i+k}]-f[x_i,\\dots,x_{i+k-1}]}{x_{i+k}-x_i}$. This construction directly encodes the data constraints $p_n(x_i)=y_i$ by induction on $i$, ensuring existence and uniqueness.\n\nAlgorithmic design proceeds as follows. First, compute the divided differences. We can implement the recursion in-place on an array $d$ initialized as $d_i^{(0)}=y_i$. For each order $k=1,\\dots,n$ and indices $i=0,\\dots,n-k$, update $d_i^{(k)}=\\dfrac{d_{i+1}^{(k-1)}-d_i^{(k-1)}}{x_{i+k}-x_i}$. After completing all orders, the Newton coefficients are $c_k=d_0^{(k)}$ for $k=0,\\dots,n$. This is an $O(n^2)$ operation and uses only the core recursion.\n\nSecond, evaluate the interpolant efficiently and stably by nested multiplication (a Horner-like scheme adapted to the Newton basis). Starting with $v=c_n$, accumulate $v \\leftarrow c_{k}+ (x-x_k)\\,v$ for $k=n-1,\\dots,0$. This follows from the basis identity $N_k(x)=(x-x_k)N_{k+1}(x)$ rearranged to express $p_n$ in nested form: $p_n(x)=c_0+(x-x_0)\\left(c_1+(x-x_1)\\left(\\dots+(x-x_{n-1})c_n\\right)\\right)$. This evaluation is $O(n)$ per point and numerically stable relative to a naive basis expansion.\n\nFor node placement, we compare two strategies on $[-1,1]$. Equally spaced nodes use $x_i=-1+\\dfrac{2i}{n}$ for $i=0,\\dots,n$. Chebyshev nodes of the first kind (extrema) are $x_i=\\cos\\!\\left(\\dfrac{i\\pi}{n}\\right)$ for $i=0,\\dots,n$, which cluster near the endpoints and are known to reduce the maximum interpolation error for analytic functions. All trigonometric computations use radians, as specified. The Runge function $f(x)=\\dfrac{1}{1+25x^2}$ is analytic on and around $[-1,1]$, yet it famously exhibits the Runge phenomenon when interpolated with equally spaced nodes: as $n$ increases, the maximum error $E_{\\max}$ may worsen due to oscillations near $x=\\pm 1$. Chebyshev nodes mitigate this by minimizing the Lebesgue constant growth and distributing node density where it is most needed.\n\nTo quantify the behavior, we evaluate on a dense grid $\\mathcal{G}$ of $M=10001$ equispaced points on $[-1,1]$. For each $n\\in\\{0,1,5,10,20\\}$ and each node strategy, we compute the interpolant $p_n(x)$ on $\\mathcal{G}$ and then the maximum absolute error $E_{\\max}=\\max_{x\\in\\mathcal{G}}|p_n(x)-f(x)|$. The program outputs the sequence $[E_{\\max}^{\\text{eq}}(0),E_{\\max}^{\\text{ch}}(0),E_{\\max}^{\\text{eq}}(1),E_{\\max}^{\\text{ch}}(1),E_{\\max}^{\\text{eq}}(5),E_{\\max}^{\\text{ch}}(5),E_{\\max}^{\\text{eq}}(10),E_{\\max}^{\\text{ch}}(10),E_{\\max}^{\\text{eq}}(20),E_{\\max}^{\\text{ch}}(20)]$ on a single line. We expect $E_{\\max}^{\\text{eq}}(n)$ to initially decrease and then increase with $n$ due to the Runge phenomenon, while $E_{\\max}^{\\text{ch}}(n)$ should decrease more steadily.\n\nImplementation details ensure numerical robustness:\n- Divided differences are computed in place using double-precision arrays to avoid unnecessary copies.\n- The evaluation uses vectorized nested multiplication over the grid for efficiency.\n- For the Chebyshev node generator, $n=0$ is handled explicitly, yielding the single node $x_0=\\cos(0)=1$. For $n\\ge 1$, nodes $\\cos\\!\\left(\\dfrac{i\\pi}{n}\\right)$ for $i=0,\\dots,n$ are generated and sorted to ascending order; sorting does not change the interpolating polynomial when coefficients are recomputed for the sorted order, and it yields consistent ordering across strategies.\n\nThis principled approach directly reflects the core definitions of interpolation and divided differences, employs the Newton basis to obtain an efficient algorithm, and computes the requested error metrics on a fixed grid for objective comparison across node sets and degrees.", "answer": "```python\nimport numpy as np\n\ndef runge_function(x: np.ndarray) -> np.ndarray:\n    # f(x) = 1 / (1 + 25 x^2)\n    return 1.0 / (1.0 + 25.0 * x * x)\n\ndef divided_differences(x: np.ndarray, y: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Compute Newton divided differences coefficients.\n    x: nodes (n+1,)\n    y: values at nodes (n+1,)\n    Returns coefficients c such that p(x) = c0 + c1*(x-x0) + ... in Newton form.\n    \"\"\"\n    n = x.size - 1\n    dd = y.astype(float).copy()\n    # In-place computation: dd[i] overwritten by higher-order divided differences\n    for k in range(1, n + 1):\n        # Update dd[0..n-k]\n        denom = x[k:] - x[:-k]\n        # Avoid division by zero; nodes are distinct by construction\n        dd[: n - k + 1] = (dd[1: n - k + 2] - dd[: n - k + 1]) / denom\n    # Coefficients are dd[0] at each order; we need to reconstruct them\n    # We can recompute to capture dd[0] at each stage by re-running but more efficient:\n    # Build the table once and collect c's\n    # Rebuild more explicitly:\n    dd_table = y.astype(float).copy()\n    coeffs = [dd_table[0]]\n    for k in range(1, n + 1):\n        dd_table[: n - k + 1] = (dd_table[1: n - k + 2] - dd_table[: n - k + 1]) / (x[k:] - x[:-k])\n        coeffs.append(dd_table[0])\n    return np.array(coeffs, dtype=float)\n\ndef newton_evaluate(x_eval: np.ndarray, x_nodes: np.ndarray, coeffs: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Evaluate Newton-form polynomial with given nodes and coefficients at x_eval.\n    Uses nested multiplication (Horner-like) for Newton basis.\n    \"\"\"\n    # Start from highest-order coefficient\n    p = np.full_like(x_eval, fill_value=coeffs[-1], dtype=float)\n    # Iterate backwards over nodes\n    for k in range(len(coeffs) - 2, -1, -1):\n        p = coeffs[k] + (x_eval - x_nodes[k]) * p\n    return p\n\ndef equispaced_nodes(n: int) -> np.ndarray:\n    # n+1 nodes from -1 to 1 inclusive\n    return np.linspace(-1.0, 1.0, n + 1, dtype=float)\n\ndef chebyshev_extrema_nodes(n: int) -> np.ndarray:\n    # Chebyshev nodes of the first kind (extrema): x_i = cos(i*pi/n), i=0..n\n    if n == 0:\n        nodes = np.array([1.0], dtype=float)\n    else:\n        i = np.arange(0, n + 1, dtype=float)\n        nodes = np.cos(np.pi * i / float(n))\n    # Sort ascending for consistency\n    nodes.sort()\n    return nodes\n\ndef max_abs_error_on_grid(n: int, node_strategy: str, grid: np.ndarray) -> float:\n    if node_strategy == \"equispaced\":\n        x_nodes = equispaced_nodes(n)\n    elif node_strategy == \"chebyshev\":\n        x_nodes = chebyshev_extrema_nodes(n)\n    else:\n        raise ValueError(\"Unknown node strategy\")\n\n    y_nodes = runge_function(x_nodes)\n    coeffs = divided_differences(x_nodes, y_nodes)\n    p_vals = newton_evaluate(grid, x_nodes, coeffs)\n    f_vals = runge_function(grid)\n    err = np.abs(p_vals - f_vals)\n    return float(np.max(err))\n\ndef solve():\n    # Define the test cases: degrees n\n    n_values = [0, 1, 5, 10, 20]\n    # Evaluation grid of M=10001 points on [-1,1]\n    M = 10001\n    grid = np.linspace(-1.0, 1.0, M, dtype=float)\n\n    results = []\n    for n in n_values:\n        e_eq = max_abs_error_on_grid(n, \"equispaced\", grid)\n        e_ch = max_abs_error_on_grid(n, \"chebyshev\", grid)\n        results.append(e_eq)\n        results.append(e_ch)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nif __name__ == \"__main__\":\n    solve()\n```", "id": "2426405"}]}