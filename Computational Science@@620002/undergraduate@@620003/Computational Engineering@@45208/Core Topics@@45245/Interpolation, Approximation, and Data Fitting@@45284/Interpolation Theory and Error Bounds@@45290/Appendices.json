{"hands_on_practices": [{"introduction": "This first exercise provides a deep dive into the fundamental structure of interpolation error. By constructing two different functions that share the exact same interpolating polynomial, you will discover that the interpolant only depends on the function's values at the nodes. This practice illuminates the critical role of the term $\\prod (x - x_k)$ in the error formula and serves as a perfect introduction to why Chebyshev nodes, which minimize the magnitude of this product, are so important for creating accurate approximations [@problem_id:2404709].", "problem": "Let $x_{1}, x_{2}, \\dots, x_{10}$ be the $10$ distinct nodes in $(-1,1)$ defined as the zeros of the Chebyshev polynomial of the first kind of degree $10$, where $T_{10}(x)$ is defined by $T_{10}(x) = \\cos(10 \\arccos(x))$. Consider the functions $f(x) = \\exp(x)$ and $g(x) = f(x) + \\alpha \\prod_{k=1}^{10} (x - x_{k})$, where $\\alpha$ is a real constant. \n\nUsing only fundamental properties of polynomial interpolation and the definition of $T_{10}(x)$ given above, justify that $f(x)$ and $g(x)$ have the same unique degree-$9$ interpolating polynomial at the nodes $\\{x_{k}\\}_{k=1}^{10}$. Then determine the unique positive value of $\\alpha$ such that \n$$\\max_{x \\in [-1,1]} |g(x) - f(x)| = \\frac{1}{8}.$$\n\nProvide the value of $\\alpha$ as your final answer. No rounding is required.", "solution": "The problem statement must first be validated for scientific soundness, well-posedness, and objectivity.\n\n**Step 1: Extract Givens**\n- Nodes: $x_{1}, x_{2}, \\dots, x_{10}$ are $10$ distinct nodes in the interval $(-1,1)$.\n- Definition of nodes: The nodes $\\{x_k\\}_{k=1}^{10}$ are the zeros of the Chebyshev polynomial of the first kind of degree $10$, $T_{10}(x)$.\n- Definition of Chebyshev polynomial: $T_{10}(x) = \\cos(10 \\arccos(x))$.\n- Function definitions: $f(x) = \\exp(x)$ and $g(x) = f(x) + \\alpha \\prod_{k=1}^{10} (x - x_{k})$, where $\\alpha$ is a real constant.\n- Condition: The unique positive value of $\\alpha$ must be determined such that $\\max_{x \\in [-1,1]} |g(x) - f(x)| = \\frac{1}{8}$.\n\n**Step 2: Validate Using Extracted Givens**\nThe problem is situated within the field of computational engineering, specifically in interpolation theory.\n1.  **Scientific or Factual Unsoundness**: The problem is built upon standard definitions and properties of polynomial interpolation and Chebyshev polynomials. The functions defined are standard elementary functions. There are no violations of mathematical logic or scientific principles.\n2.  **Non-Formalizable or Irrelevant**: The problem is a formal mathematical exercise directly relevant to the topic of interpolation and approximation theory.\n3.  **Incomplete or Contradictory Setup**: The problem is self-contained. All necessary information is provided.\n4.  **Unrealistic or Infeasible**: The conditions are mathematically sound and do not represent any physical or scientific impossibility.\n5.  **Ill-Posed or Poorly Structured**: The existence and uniqueness of an interpolating polynomial of a given degree through a given number of distinct points is a fundamental theorem of numerical analysis. The terms are well-defined.\n6.  **Outside Scientific Verifiability**: The claims and the result can be verified through direct mathematical derivation.\n\n**Step 3: Verdict and Action**\nThe problem is deemed valid. A solution will be provided.\n\nThe problem consists of two parts. First, we must justify that $f(x)$ and $g(x)$ share the same unique degree-$9$ interpolating polynomial at the specified nodes. Second, we must determine the positive constant $\\alpha$.\n\nLet $P_{9}(x)$ denote the unique polynomial of degree at most $9$ that interpolates a function at the $10$ distinct nodes $\\{x_k\\}_{k=1}^{10}$.\nFor the function $f(x)$, its interpolating polynomial, let us call it $P_{f}(x)$, must satisfy the conditions:\n$$P_{f}(x_k) = f(x_k) \\quad \\text{for } k = 1, 2, \\dots, 10.$$\nFor the function $g(x)$, its interpolating polynomial, let us call it $P_{g}(x)$, must satisfy the conditions:\n$$P_{g}(x_k) = g(x_k) \\quad \\text{for } k = 1, 2, \\dots, 10.$$\nThe function $g(x)$ is defined as $g(x) = f(x) + \\alpha \\prod_{j=1}^{10} (x - x_{j})$. Let us evaluate $g(x)$ at each of the interpolation nodes $x_k$:\n$$g(x_k) = f(x_k) + \\alpha \\prod_{j=1}^{10} (x_k - x_{j}).$$\nThe product term $\\prod_{j=1}^{10} (x_k - x_{j})$ contains the factor $(x_k - x_k)$ when the index $j$ equals $k$. This factor is equal to $0$. Consequently, the entire product is zero.\nThus, for each node $x_k$:\n$$g(x_k) = f(x_k) + \\alpha \\cdot 0 = f(x_k).$$\nThis shows that at the $10$ distinct interpolation nodes, the functions $f(x)$ and $g(x)$ have identical values. Therefore, their respective interpolating polynomials must satisfy:\n$$P_{g}(x_k) = g(x_k) = f(x_k) = P_{f}(x_k) \\quad \\text{for } k = 1, 2, \\dots, 10.$$\nConsider the difference polynomial $\\Delta(x) = P_{f}(x) - P_{g}(x)$. Since both $P_{f}(x)$ and $P_{g}(x)$ are polynomials of degree at most $9$, their difference $\\Delta(x)$ is also a polynomial of degree at most $9$.\nWe have shown that $\\Delta(x_k) = P_{f}(x_k) - P_{g}(x_k) = 0$ for all $10$ distinct nodes $\\{x_k\\}$. A polynomial of degree at most $9$ that has $10$ distinct roots must be the zero polynomial.\nTherefore, $\\Delta(x) = 0$ for all $x$, which implies $P_{f}(x) = P_{g}(x)$. This concludes the first part of the problem: $f(x)$ and $g(x)$ have the same unique degree-$9$ interpolating polynomial.\n\nNext, we must determine the value of $\\alpha$ from the condition:\n$$\\max_{x \\in [-1,1]} |g(x) - f(x)| = \\frac{1}{8}.$$\nLet us analyze the left-hand side of this equation. From the definition of $g(x)$, we have:\n$$g(x) - f(x) = \\left( f(x) + \\alpha \\prod_{k=1}^{10} (x - x_{k}) \\right) - f(x) = \\alpha \\prod_{k=1}^{10} (x - x_{k}).$$\nThe condition becomes:\n$$\\max_{x \\in [-1,1]} \\left| \\alpha \\prod_{k=1}^{10} (x - x_{k}) \\right| = \\frac{1}{8}.$$\nSince $\\alpha$ is a constant, we can write this as:\n$$|\\alpha| \\max_{x \\in [-1,1]} \\left| \\prod_{k=1}^{10} (x - x_{k}) \\right| = \\frac{1}{8}.$$\nThe nodes $\\{x_k\\}_{k=1}^{10}$ are the zeros of the Chebyshev polynomial $T_{10}(x)$. The polynomial $\\prod_{k=1}^{10} (x - x_{k})$ is a monic polynomial of degree $10$ with these same zeros.\nThe Chebyshev polynomial of the first kind of degree $n$, $T_n(x)$, has a leading coefficient of $2^{n-1}$ for $n \\ge 1$. For $n=10$, the leading coefficient is $2^{10-1} = 2^9$.\nThus, $T_{10}(x)$ can be written in its factored form as:\n$$T_{10}(x) = 2^9 \\prod_{k=1}^{10} (x - x_{k}).$$\nFrom this, we can express the product term:\n$$\\prod_{k=1}^{10} (x - x_{k}) = \\frac{T_{10}(x)}{2^9}.$$\nSubstituting this into our equation gives:\n$$|\\alpha| \\max_{x \\in [-1,1]} \\left| \\frac{T_{10}(x)}{2^9} \\right| = \\frac{1}{8}.$$\n$$|\\alpha| \\frac{1}{2^9} \\max_{x \\in [-1,1]} |T_{10}(x)| = \\frac{1}{8}.$$\nA fundamental property of the Chebyshev polynomial of the first kind, $T_n(x) = \\cos(n \\arccos(x))$, is that its maximum absolute value on the interval $[-1, 1]$ is $1$. This is because the function $\\cos(\\theta)$ oscillates between $-1$ and $1$.\nSo, $\\max_{x \\in [-1,1]} |T_{10}(x)| = 1$.\nThe equation simplifies to:\n$$|\\alpha| \\frac{1}{2^9} \\cdot 1 = \\frac{1}{8}.$$\n$$|\\alpha| \\frac{1}{512} = \\frac{1}{8}.$$\nSolving for $|\\alpha|$:\n$$|\\alpha| = \\frac{512}{8} = 64.$$\nThe problem asks for the unique positive value of $\\alpha$. Therefore, we select the positive solution.\n$$\\alpha = 64.$$\nThis completes the derivation.", "answer": "$$\\boxed{64}$$", "id": "2404709"}, {"introduction": "Moving from theory to application, this practice challenges you to model a real-world physical phenomenon: radioactive decay. You will contrast a generic quadratic interpolation with an exponential model derived from first principles in nuclear physics. This exercise is invaluable for developing the skill of deriving and calculating a rigorous, quantitative bound on interpolation error, a critical task for any engineer or scientist who needs to assess the accuracy and reliability of their computational models [@problem_id:2404756].", "problem": "A radioisotope sample exhibits nuclear decay that is well modeled by the fundamental first-order rate law from nuclear physics, which implies that the activity $A(t)$ satisfies $\\frac{dA}{dt}=-\\lambda A(t)$ with solution $A(t)=A(0)\\exp(-\\lambda t)$, where $\\lambda>0$ is the decay constant. An ideal detector records the activity at times $t=0,1,5$ days, yielding the following exact measurements: $A(0)=1000$ counts per second, $A(1)=1000\\cdot 2^{-2/5}$ counts per second, and $A(5)=250$ counts per second.\n\n- Using only these three measurements, construct the unique quadratic interpolant $p_{2}(t)$ that passes through the data points $(0,A(0))$, $(1,A(1))$, and $(5,A(5))$, and evaluate $p_{2}(3)$.\n- Independently, use the physical exponential decay model together with the endpoint measurements at $t=0$ and $t=5$ to determine the decay constant $\\lambda$ and predict the activity $A(3)$ at $t=3$ days.\n- Derive, from first principles and without invoking any shortcut formulas, an upper bound on the interpolation error at $t=3$ of the form $|A(3)-p_{2}(3)|\\leq B$, by combining a remainder estimate based on $A^{(3)}(t)$ with a bound on $|A^{(3)}(t)|$ obtained from the exponential decay model on the interval $[0,5]$. State the explicit bound $B$ you obtain.\n\nFinally, compute the absolute discrepancy $|p_{2}(3)-A(3)|$ and report its value. Round your answer to four significant figures and express it in counts per second. Provide only this single numerical value as your final answer. Angles are not involved in this problem.", "solution": "The supplied problem is first subjected to a validation procedure.\n\n**Step 1: Extract Givens**\n- The governing differential equation for activity $A(t)$ is $\\frac{dA}{dt}=-\\lambda A(t)$.\n- The physical model for activity is $A(t) = A(0)\\exp(-\\lambda t)$, where the decay constant $\\lambda > 0$.\n- The exact measurements at specific times are:\n  - $t_0=0$ days, $y_0 = A(0) = 1000$ counts per second.\n  - $t_1=1$ day, $y_1 = A(1) = 1000 \\cdot 2^{-2/5}$ counts per second.\n  - $t_2=5$ days, $y_2 = A(5) = 250$ counts per second.\n\n**Step 2: Validate Using Extracted Givens**\nThe problem is scientifically grounded, employing the standard first-order exponential decay model from nuclear physics. It is well-posed, as it requests a series of specific, computable quantities. The objectivity is clear from the precise mathematical language used. To ensure consistency, the given data points must satisfy the physical model for a single value of $\\lambda$. Using the endpoints $t_0=0$ and $t_2=5$:\n$A(5) = A(0) \\exp(-5\\lambda) \\implies 250 = 1000 \\exp(-5\\lambda)$.\nThis yields $\\exp(-5\\lambda) = \\frac{250}{1000} = \\frac{1}{4}$. From this, $-5\\lambda = \\ln(\\frac{1}{4}) = -\\ln(4) = -2\\ln(2)$, so $\\lambda = \\frac{2\\ln(2)}{5}$. This value is positive and thus physically valid.\nNow, we verify the data point at $t_1=1$ with this constant:\n$A(1) = A(0)\\exp(-\\lambda \\cdot 1) = 1000 \\exp(-\\frac{2\\ln(2)}{5}) = 1000 \\cdot (\\exp(\\ln(2)))^{-2/5} = 1000 \\cdot 2^{-2/5}$.\nThis is identical to the given value for $A(1)$. The problem is therefore self-contained, consistent, and scientifically sound.\n\n**Step 3: Verdict and Action**\nThe problem is valid. A complete solution is now derived.\n\n**Part 1: Construction of the Quadratic Interpolant $p_2(t)$**\nThe unique quadratic polynomial $p_2(t)$ that interpolates the data points $(0, y_0)$, $(1, y_1)$, $(5, y_2)$ is constructed using the Lagrange form:\n$p_2(t) = y_0 L_0(t) + y_1 L_1(t) + y_2 L_2(t)$, where the Lagrange basis polynomials $L_i(t)$ are:\n$L_0(t) = \\frac{(t-1)(t-5)}{(0-1)(0-5)} = \\frac{1}{5}(t-1)(t-5)$.\n$L_1(t) = \\frac{(t-0)(t-5)}{(1-0)(1-5)} = -\\frac{1}{4}t(t-5)$.\n$L_2(t) = \\frac{(t-0)(t-1)}{(5-0)(5-1)} = \\frac{1}{20}t(t-1)$.\n\nWe must evaluate $p_2(t)$ at $t=3$. First, we compute the values of the basis polynomials at $t=3$:\n$L_0(3) = \\frac{(3-1)(3-5)}{5} = \\frac{(2)(-2)}{5} = -\\frac{4}{5}$.\n$L_1(3) = -\\frac{3(3-5)}{4} = -\\frac{3(-2)}{4} = \\frac{6}{4} = \\frac{3}{2}$.\n$L_2(3) = \\frac{3(3-1)}{20} = \\frac{3(2)}{20} = \\frac{6}{20} = \\frac{3}{10}$.\n\nNow we can compute $p_2(3)$:\n$p_2(3) = y_0 L_0(3) + y_1 L_1(3) + y_2 L_2(3)$\n$p_2(3) = (1000)(-\\frac{4}{5}) + (1000 \\cdot 2^{-2/5})(\\frac{3}{2}) + (250)(\\frac{3}{10})$\n$p_2(3) = -800 + 1500 \\cdot 2^{-2/5} + 75 = 1500 \\cdot 2^{-2/5} - 725$.\n\n**Part 2: Prediction from the Physical Model**\nThe decay constant $\\lambda$ was determined during validation as $\\lambda = \\frac{2\\ln(2)}{5}$. We use this to predict the true activity $A(3)$:\n$A(3) = A(0)\\exp(-3\\lambda) = 1000\\exp(-3 \\cdot \\frac{2\\ln(2)}{5}) = 1000\\exp(-\\frac{6}{5}\\ln(2))$.\nUsing the identity $\\exp(c \\ln a) = a^c$:\n$A(3) = 1000 \\cdot 2^{-6/5}$.\n\n**Part 3: Derivation of the Interpolation Error Bound**\nThe error for polynomial interpolation is given by $A(t) - p_n(t) = \\frac{A^{(n+1)}(\\xi)}{(n+1)!} \\prod_{i=0}^{n} (t-t_i)$ for some $\\xi$ in the interval containing the nodes and $t$. For our quadratic case ($n=2$), the error at $t=3$ is:\n$A(3) - p_2(3) = \\frac{A^{(3)}(\\xi)}{3!}(3-t_0)(3-t_1)(3-t_2) = \\frac{A^{(3)}(\\xi)}{6}(3-0)(3-1)(3-5)$, for some $\\xi \\in (0,5)$.\n$A(3) - p_2(3) = \\frac{A^{(3)}(\\xi)}{6}(3)(2)(-2) = -2 A^{(3)}(\\xi)$.\n\nThe absolute error is $|A(3) - p_2(3)| = 2|A^{(3)}(\\xi)|$.\nTo establish an upper bound $B$, we must find the maximum of $|A^{(3)}(t)|$ on the interval $[0,5]$. First, we compute the third derivative of $A(t) = A_0 \\exp(-\\lambda t)$:\n$A'(t) = -\\lambda A_0 \\exp(-\\lambda t)$\n$A''(t) = \\lambda^2 A_0 \\exp(-\\lambda t)$\n$A'''(t) = -\\lambda^3 A_0 \\exp(-\\lambda t)$.\nSo, $|A'''(t)| = \\lambda^3 A_0 \\exp(-\\lambda t)$. Since $\\lambda>0$, this function is monotonically decreasing for $t \\ge 0$. Its maximum value on $[0,5]$ occurs at $t=0$:\n$\\max_{t \\in [0,5]} |A'''(t)| = |A'''(0)| = \\lambda^3 A_0 \\exp(0) = \\lambda^3 A_0$.\n\nAn upper bound $B$ for the error magnitude is therefore:\n$|A(3) - p_2(3)| \\leq 2 \\max_{\\xi \\in [0,5]} |A^{(3)}(\\xi)| = 2 \\lambda^3 A_0$.\nSubstituting $A_0 = 1000$ and $\\lambda = \\frac{2\\ln(2)}{5}$:\n$B = 2 \\left(\\frac{2\\ln(2)}{5}\\right)^3 (1000) = 2 \\cdot \\frac{8(\\ln(2))^3}{125} \\cdot 1000 = \\frac{16(\\ln(2))^3}{125} \\cdot (1000) = 16(\\ln(2))^3 \\cdot 8 = 128(\\ln(2))^3$.\n\n**Part 4: Computation of the Absolute Discrepancy**\nFinally, we compute the numerical value of $|p_2(3) - A(3)|$:\n$|p_2(3) - A(3)| = |(1500 \\cdot 2^{-2/5} - 725) - (1000 \\cdot 2^{-6/5})|$.\nUsing numerical computations:\n$2^{-2/5} = 2^{-0.4} \\approx 0.75785828$\n$2^{-6/5} = 2^{-1.2} \\approx 0.43527530$\n\n$p_2(3) \\approx 1500(0.75785828) - 725 = 1136.78742 - 725 = 411.78742$.\n$A(3) \\approx 1000(0.43527530) = 435.27530$.\n\nThe absolute discrepancy is:\n$|411.78742 - 435.27530| = |-23.48788| \\approx 23.48788$.\nRounding to four significant figures gives $23.49$.", "answer": "$$\\boxed{23.49}$$", "id": "2404756"}, {"introduction": "This final practice is a capstone computational experiment that brings together the concepts of error analysis and optimal node placement. You will design an adaptive algorithm that iteratively improves an approximation by placing new nodes at the points of maximum error. The true learning moment comes from observing the outcome: your greedy algorithm will naturally generate a node distribution that closely resembles the theoretically optimal Chebyshev-Lobatto points, providing a powerful, hands-on demonstration of how an iterative process can converge on a sophisticated theoretical result [@problem_id:2378821].", "problem": "You are asked to implement a program that constructs an adaptive polynomial interpolation on the closed interval $[-1,1]$ and quantitatively checks whether the final set of interpolation nodes resembles the Chebyshev–Lobatto distribution. All angles must be treated in radians.\n\nGiven a real-valued function $f:[-1,1]\\to\\mathbb{R}$ and a finite set of distinct nodes $\\{x_i\\}_{i=1}^n\\subset[-1,1]$, let $p_n$ denote the unique polynomial of degree at most $n-1$ that satisfies the interpolation conditions $p_n(x_i)=f(x_i)$ for all $i\\in\\{1,\\dots,n\\}$. Define the interpolation error as $e_n(x)=f(x)-p_n(x)$. Consider the following node selection rule that generates a sequence of node sets $S_k\\subset[-1,1]$ with $\\lvert S_k\\rvert=n_k$:\n\n- Initialization: $S_0=\\{-1,1\\}$.\n- Iteration: For $k=0,1,2,\\dots$, compute the polynomial interpolant $p_{n_k}$ associated with $S_k$ and the corresponding error $e_{n_k}(x)=f(x)-p_{n_k}(x)$. Over a uniform grid of $M$ points in $[-1,1]$, find a point $x^\\star\\in[-1,1]$ at which $\\lvert e_{n_k}(x)\\rvert$ attains its maximum over the grid. Define $S_{k+1}=S_k\\cup\\{x^\\star\\}$ and continue.\n- Termination: Stop the iteration at the first $K$ such that either $\\max_{x\\in\\text{grid}}\\lvert e_{n_K}(x)\\rvert\\le\\varepsilon$ or $n_K=n_{\\max}$.\n\nDenote the final node set by $S_K=\\{x^{(K)}_i\\}_{i=1}^{n}$ sorted in ascending order, where $n=n_K$. Define the $n$ Chebyshev–Lobatto nodes on $[-1,1]$ as $c_i=\\cos\\!\\left(\\frac{\\pi(i-1)}{n-1}\\right)$ for $i\\in\\{1,\\dots,n\\}$, and sort them in ascending order. Quantify the resemblance between $S_K$ and the Chebyshev–Lobatto nodes by the root mean square deviation (RMSD)\n$$\nr=\\sqrt{\\frac{1}{n}\\sum_{i=1}^{n}\\left(x^{(K)}_i-c_i\\right)^2}.\n$$\nYour program must do the following for each test case:\n\n- Construct $S_K$ by the above procedure with the specified function $f$, tolerance $\\varepsilon$, maximum node count $n_{\\max}$, and grid size $M$.\n- Compute the RMSD $r$ between the sorted $S_K$ and the sorted Chebyshev–Lobatto nodes for the same $n$.\n- Output a boolean indicating whether $r\\le \\tau$ for the specified threshold $\\tau$.\n\nUse the angle unit radians for all trigonometric evaluations. All outputs are dimensionless.\n\nTest suite:\n\n- Case $1$ (smooth rational function):\n  - $f(x)=\\dfrac{1}{1+25x^2}$.\n  - $\\varepsilon=5\\times 10^{-5}$.\n  - $n_{\\max}=35$.\n  - $M=8193$.\n  - $\\tau=0.20$.\n- Case $2$ (non-differentiable at the origin):\n  - $f(x)=\\lvert x\\rvert$.\n  - $\\varepsilon=3\\times 10^{-2}$.\n  - $n_{\\max}=41$.\n  - $M=8193$.\n  - $\\tau=0.20$.\n- Case $3$ (oscillatory analytic function; angles in radians):\n  - $f(x)=\\cos(10x)$.\n  - $\\varepsilon=10^{-8}$.\n  - $n_{\\max}=45$.\n  - $M=8193$.\n  - $\\tau=0.20$.\n- Case $4$ (early stop by node cap):\n  - $f(x)=e^{x}$.\n  - $\\varepsilon=10^{-8}$.\n  - $n_{\\max}=10$.\n  - $M=8193$.\n  - $\\tau=0.20$.\n\nFinal output format:\n\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, in the order of the cases $1$ through $4$, for example, $[b_1,b_2,b_3,b_4]$, where each $b_i$ is a boolean.", "solution": "The problem is valid. It presents a well-defined task in computational physics, specifically in the field of numerical analysis, concerning adaptive polynomial interpolation and its connection to theoretically optimal node distributions. All constants, functions, and procedures are specified with sufficient precision to permit a unique, verifiable solution. The underlying principles—polynomial interpolation, error analysis, and Chebyshev nodes—are fundamental and scientifically sound.\n\nThe solution is constructed by implementing the specified adaptive algorithm for each test case and then performing the quantitative comparison. The core steps of the procedure are as follows.\n\n1.  **Algorithm Initialization**: The process begins on the interval $[-1, 1]$. An initial set of two nodes, $S_0 = \\{-1, 1\\}$, is defined. A fine, uniform grid of $M$ points, denoted $\\{x_j^{\\text{grid}}\\}_{j=1}^M$, is created on $[-1, 1]$ to serve as the search space for the maximum interpolation error.\n\n2.  **Iterative Node Placement**: The algorithm proceeds iteratively. At each step $k$, given a set of $n_k$ distinct nodes $S_k = \\{x_i\\}_{i=1}^{n_k}$, the following actions are performed:\n    -   **Polynomial Interpolation**: A unique polynomial $p_{n_k}(x)$ of degree at most $n_k-1$ is constructed such that it interpolates the given function $f(x)$ at the nodes in $S_k$, i.e., $p_{n_k}(x_i) = f(x_i)$ for all $x_i \\in S_k$. For numerical stability and efficiency, this is best implemented using the barycentric form of the Lagrange interpolating polynomial:\n        $$\n        p_{n_k}(x) = \\frac{\\sum_{i=1}^{n_k} \\frac{w_i}{x-x_i} f(x_i)}{\\sum_{i=1}^{n_k} \\frac{w_i}{x-x_i}}\n        $$\n        where the barycentric weights $w_i$ are pre-computed as $w_i = 1 / \\prod_{j \\neq i}(x_i - x_j)$.\n    -   **Error Calculation**: The interpolation error function, $e_{n_k}(x) = f(x) - p_{n_k}(x)$, is evaluated over the pre-defined grid. The maximum absolute error on this grid is found: $E_k = \\max_{j} |e_{n_k}(x_j^{\\text{grid}})|$.\n    -   **Termination Check**: The iteration terminates if either of two conditions is met: the maximum error is below a specified tolerance ($E_k \\le \\varepsilon$), or the number of nodes has reached its maximum allowed value ($n_k = n_{\\max}$). If the process stops at step $K$, the final node set is $S_K$.\n    -   **Node Augmentation**: If neither termination condition is met, the point $x^\\star$ from the grid where the maximum absolute error occurred is identified. This point is added to the node set to form the set for the next iteration, $S_{k+1} = S_k \\cup \\{x^\\star\\}$. This greedy strategy aims to reduce the largest error in the subsequent step.\n\n3.  **Comparison with Chebyshev-Lobatto Nodes**: Upon termination, the final node set $S_K$ contains $n = n_K$ points. The theoretical basis for optimal polynomial interpolation suggests that for smooth functions, the nodes should be distributed according to the arcsine distribution, a characteristic of Chebyshev points. This problem investigates the resemblance to Chebyshev-Lobatto nodes, which are the extrema of the $(n-1)$-th degree Chebyshev polynomial of the first kind, $T_{n-1}(x)$, and are known to be near-optimal for interpolation.\n    -   The final adaptive nodes, $\\{x_{i}^{(K)}\\}_{i=1}^n$, are sorted in ascending order.\n    -   A corresponding set of $n$ Chebyshev-Lobatto nodes, $\\{c_i\\}_{i=1}^n$, is generated using the formula $c_i = \\cos\\left(\\frac{\\pi(i-1)}{n-1}\\right)$ for $i \\in \\{1, \\dots, n\\}$, which are then also sorted in ascending order. Note that the formula generates the nodes in descending order, so a sort is necessary.\n\n4.  **Quantitative Analysis**: The resemblance between the two sorted sets of nodes is measured by the Root Mean Square Deviation (RMSD), defined as:\n    $$\n    r = \\sqrt{\\frac{1}{n}\\sum_{i=1}^{n}\\left(x^{(K)}_i - c_i\\right)^2}\n    $$\n    This metric provides an average measure of how much the adaptively generated nodes deviate from the theoretically near-optimal Chebyshev-Lobatto nodes.\n\n5.  **Final Verdict**: For each test case, the computed RMSD value $r$ is compared to a specified threshold $\\tau$. The output is a boolean value: `True` if $r \\le \\tau$, and `False` otherwise. This provides a quantitative answer to the question of whether the adaptive node placement strategy yields a distribution sufficiently similar to the Chebyshev-Lobatto distribution under the given conditions. The entire procedure is encapsulated in a program that processes the four specified test cases.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.interpolate import BarycentricInterpolator\n\ndef runge_func(x):\n    \"\"\"The Runge function.\"\"\"\n    return 1.0 / (1.0 + 25.0 * x**2)\n\ndef abs_val_func(x):\n    \"\"\"The absolute value function.\"\"\"\n    return np.abs(x)\n\ndef cos_func(x):\n    \"\"\"An oscillatory function.\"\"\"\n    return np.cos(10.0 * x)\n\ndef exp_func(x):\n    \"\"\"The exponential function.\"\"\"\n    return np.exp(x)\n\ndef adaptive_interpolation(f, epsilon, n_max, M):\n    \"\"\"\n    Constructs an adaptive polynomial interpolation and returns the final node set.\n    \"\"\"\n    # Initialization\n    nodes = np.array([-1.0, 1.0])\n    x_grid = np.linspace(-1.0, 1.0, M)\n    f_grid = f(x_grid)\n\n    while True:\n        num_nodes = len(nodes)\n\n        # Create the interpolating polynomial and evaluate the error.\n        y_nodes = f(nodes)\n        \n        # BarycentricInterpolator can be numerically unstable if nodes are too close.\n        # However, for the given problem parameters, it is a suitable choice.\n        poly = BarycentricInterpolator(nodes, y_nodes)\n        p_grid = poly(x_grid)\n        \n        error_grid = np.abs(f_grid - p_grid)\n        max_error = np.max(error_grid)\n\n        # Termination conditions\n        if max_error <= epsilon or num_nodes >= n_max:\n            break\n\n        # Find the point of maximum error and add it to the node set.\n        idx_max_error = np.argmax(error_grid)\n        new_node = x_grid[idx_max_error]\n        \n        # Using union1d ensures nodes remain sorted and unique.\n        nodes = np.union1d(nodes, [new_node])\n\n    return nodes\n\ndef calculate_rmsd_and_check(final_nodes, tau):\n    \"\"\"\n    Calculates the RMSD between the final nodes and Chebyshev-Lobatto nodes\n    and checks if it's below the threshold tau.\n    \"\"\"\n    n = len(final_nodes)\n\n    # The number of nodes n must be >= 2 for Chebyshev-Lobatto formula.\n    # The algorithm starts with n=2 and only adds nodes, so n >= 2 always.\n    if n < 2:\n        return False # Or handle as an error, but this case shouldn't be reached.\n    \n    # Sort the adaptively generated nodes.\n    sorted_nodes = np.sort(final_nodes)\n    \n    # Generate Chebyshev-Lobatto nodes. The formula gives them in descending order,\n    # so we sort them to match the ascending order of sorted_nodes.\n    # The indices for the formula are 0, 1, ..., n-1.\n    cl_nodes_raw = np.cos(np.pi * np.arange(n) / (n - 1))\n    cl_nodes = np.sort(cl_nodes_raw)\n    \n    # Calculate Root Mean Square Deviation (RMSD).\n    rmsd = np.sqrt(np.mean((sorted_nodes - cl_nodes)**2))\n    \n    # Return boolean result of the comparison.\n    return rmsd <= tau\n\ndef solve():\n    \"\"\"\n    Main function to run all test cases and print the results.\n    \"\"\"\n    test_cases = [\n        # Case 1 (smooth rational function)\n        {'f': runge_func, 'epsilon': 5e-5, 'n_max': 35, 'M': 8193, 'tau': 0.20},\n        # Case 2 (non-differentiable at the origin)\n        {'f': abs_val_func, 'epsilon': 3e-2, 'n_max': 41, 'M': 8193, 'tau': 0.20},\n        # Case 3 (oscillatory analytic function)\n        {'f': cos_func, 'epsilon': 1e-8, 'n_max': 45, 'M': 8193, 'tau': 0.20},\n        # Case 4 (early stop by node cap)\n        {'f': exp_func, 'epsilon': 1e-8, 'n_max': 10, 'M': 8193, 'tau': 0.20},\n    ]\n\n    results = []\n    for case in test_cases:\n        final_nodes = adaptive_interpolation(case['f'], case['epsilon'], case['n_max'], case['M'])\n        result = calculate_rmsd_and_check(final_nodes, case['tau'])\n        results.append(result)\n\n    # Format the final output as specified. str(bool) gives 'True'/'False'.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "2378821"}]}