{"hands_on_practices": [{"introduction": "The stability of any molecular dynamics simulation is fundamentally limited by the fastest motion within the system, typically a high-frequency bond vibration. This exercise provides a first-principles look at this limit by asking you to \"reverse-engineer\" a molecule whose dynamics are too fast for a given timestep. By calculating the specific bond force constant $k$ that causes a $1.0\\,\\mathrm{fs}$ timestep to fail, you will gain a concrete, quantitative understanding of how molecular properties directly dictate the maximum allowable integration time [@problem_id:2452099].", "problem": "A linear, colinear triatomic molecule $A{-}B{-}C$ is modeled with two identical harmonic bonds $A{-}B$ and $B{-}C$, each with force constant $k$ (in $\\mathrm{N}\\,\\mathrm{m}^{-1}$). The atoms have equal masses $m_{A} = m_{B} = m_{C} = 1.008$ atomic mass units. Assume only small displacements along the molecular axis and neglect any angular terms or other interactions. The atomic mass unit is $1\\,\\mathrm{u} = 1.66053906660 \\times 10^{-27}\\,\\mathrm{kg}$. Consider integrating the equations of motion using the classical Verlet algorithm with a fixed timestep $\\Delta t = 1.0\\,\\mathrm{fs}$, where $1\\,\\mathrm{fs} = 1.0 \\times 10^{-15}\\,\\mathrm{s}$. Determine the smallest bond force constant $k$ (in $\\mathrm{N}\\,\\mathrm{m}^{-1}$) for which the numerical integration becomes linearly unstable at this timestep. Express your answer in $\\mathrm{N}\\,\\mathrm{m}^{-1}$ and round your result to three significant figures.", "solution": "The problem statement is subjected to validation.\n\nGivens extracted verbatim from the problem statement:\n- System: A linear, colinear triatomic molecule $A{-}B{-}C$.\n- Bonds: Two identical harmonic bonds $A{-}B$ and $B{-}C$.\n- Force constant: $k$ for each bond.\n- Masses: $m_{A} = m_{B} = m_{C} = 1.008$ atomic mass units.\n- Motion constraint: Small displacements along the molecular axis only.\n- Neglected terms: Angular terms or other interactions.\n- Constants: $1\\,\\mathrm{u} = 1.66053906660 \\times 10^{-27}\\,\\mathrm{kg}$.\n- Integration method: Classical Verlet algorithm with a fixed timestep $\\Delta t = 1.0\\,\\mathrm{fs}$, where $1\\,\\mathrm{fs} = 1.0 \\times 10^{-15}\\,\\mathrm{s}$.\n- Objective: Determine the smallest bond force constant $k$ for which the numerical integration becomes linearly unstable.\n- Output requirements: Express the answer in $\\mathrm{N}\\,\\mathrm{m}^{-1}$ and round to three significant figures.\n\nValidation verdict:\nThe problem is deemed valid. It is scientifically grounded in the principles of classical mechanics (harmonic oscillators, normal modes) and numerical analysis (stability of integration algorithms). It is well-posed, providing all necessary parameters and a clear, objective criterion for the solution. The problem is free of factual unsoundness, ambiguity, or contradiction.\n\nSolution:\nThe stability of the Verlet integration algorithm for a system of harmonic oscillators is determined by the highest angular frequency, $\\omega_{\\text{max}}$, present in the system's dynamics. The algorithm becomes linearly unstable when the product of this frequency and the integration timestep, $\\Delta t$, exceeds a critical value. For the classical Verlet algorithm, this stability condition is given by $\\omega_{\\text{max}} \\Delta t \\le 2$. The problem requires finding the force constant $k$ at the threshold of instability, which corresponds to the equality $\\omega_{\\text{max}} \\Delta t = 2$. The solution path is therefore to first determine the normal mode frequencies of the triatomic molecule as a function of $k$ and $m$, identify the highest frequency $\\omega_{\\text{max}}$, and then use the stability condition to solve for $k$.\n\nLet the displacements of the three atoms $A$, $B$, and $C$ from their equilibrium positions along the molecular axis be $q_A$, $q_B$, and $q_C$, respectively. The atoms are of equal mass, so $m_A = m_B = m_C = m$. The potential energy $V$ of the system, based on two identical harmonic bonds with force constant $k$, is:\n$$V(q_A, q_B, q_C) = \\frac{1}{2} k (q_B - q_A)^2 + \\frac{1}{2} k (q_C - q_B)^2$$\nThe forces on each atom are found by taking the negative gradient of the potential energy, $F_i = -\\frac{\\partial V}{\\partial q_i}$.\n$$F_A = -\\frac{\\partial V}{\\partial q_A} = k(q_B - q_A)$$\n$$F_B = -\\frac{\\partial V}{\\partial q_B} = -k(q_B - q_A) + k(q_C - q_B) = k(q_A - 2q_B + q_C)$$\n$$F_C = -\\frac{\\partial V}{\\partial q_C} = -k(q_C - q_B) = k(q_B - q_C)$$\nThe equations of motion are $m \\ddot{q}_i = F_i$:\n$$m \\ddot{q}_A = -k q_A + k q_B$$\n$$m \\ddot{q}_B = k q_A - 2k q_B + k q_C$$\n$$m \\ddot{q}_C = k q_B - k q_C$$\nWe seek normal mode solutions of the form $q_j(t) = A_j \\exp(i\\omega t)$, where $A_j$ are the amplitudes. Substituting this form into the equations of motion yields a system of linear algebraic equations for the amplitudes:\n$$(-m\\omega^2 + k)A_A - kA_B = 0$$\n$$-kA_A + (-m\\omega^2 + 2k)A_B - kA_C = 0$$\n$$-kA_B + (-m\\omega^2 + k)A_C = 0$$\nThis system has a non-trivial solution if and only if the determinant of the coefficient matrix is zero. This gives the secular equation:\n$$\n\\begin{vmatrix}\nk - m\\omega^2 & -k & 0 \\\\\n-k & 2k - m\\omega^2 & -k \\\\\n0 & -k & k - m\\omega^2\n\\end{vmatrix} = 0\n$$\nLet $\\lambda = m\\omega^2$. The determinant becomes:\n$$\n\\begin{vmatrix}\nk - \\lambda & -k & 0 \\\\\n-k & 2k - \\lambda & -k \\\\\n0 & -k & k - \\lambda\n\\end{vmatrix} = (k - \\lambda)\\left[(2k - \\lambda)(k - \\lambda) - k^2\\right] - (-k)\\left[-k(k - \\lambda)\\right] = 0\n$$\nExpanding and simplifying the expression:\n$$(k - \\lambda)(2k^2 - 3k\\lambda + \\lambda^2 - k^2) - k^2(k - \\lambda) = 0$$\n$$(k - \\lambda)(k^2 - 3k\\lambda + \\lambda^2) - k^2(k - \\lambda) = 0$$\n$$(k - \\lambda)[(k^2 - 3k\\lambda + \\lambda^2) - k^2] = 0$$\n$$(k - \\lambda)(\\lambda^2 - 3k\\lambda) = 0$$\n$$\\lambda(\\lambda - k)(\\lambda - 3k) = 0$$\nThe solutions for $\\lambda$ are $\\lambda_1 = 0$, $\\lambda_2 = k$, and $\\lambda_3 = 3k$. Substituting back $\\lambda = m\\omega^2$, we find the squared angular frequencies:\n$$\\omega_1^2 = 0$$\n$$\\omega_2^2 = \\frac{k}{m}$$\n$$\\omega_3^2 = \\frac{3k}{m}$$\nThe zero-frequency mode ($\\omega_1 = 0$) corresponds to the uniform translation of the entire molecule, which does not affect stability. The highest frequency mode is the asymmetric stretch, with angular frequency $\\omega_{\\text{max}} = \\omega_3 = \\sqrt{\\frac{3k}{m}}$. This is the mode that will first cause numerical instability as $k$ increases.\n\nThe threshold for linear instability of the Verlet algorithm is $\\omega_{\\text{max}} \\Delta t = 2$. We substitute the expression for $\\omega_{\\text{max}}$:\n$$\\left(\\sqrt{\\frac{3k}{m}}\\right) \\Delta t = 2$$\nTo find the smallest force constant $k$ that leads to instability, we solve this equation for $k$:\n$$\\frac{3k}{m} (\\Delta t)^2 = 4$$\n$$k = \\frac{4m}{3(\\Delta t)^2}$$\nNow, we substitute the given numerical values.\nThe mass is $m = 1.008\\,\\mathrm{u}$. Using the provided conversion factor, $1\\,\\mathrm{u} = 1.66053906660 \\times 10^{-27}\\,\\mathrm{kg}$:\n$$m = 1.008 \\times 1.66053906660 \\times 10^{-27}\\,\\mathrm{kg} \\approx 1.673823 \\times 10^{-27}\\,\\mathrm{kg}$$\nThe timestep is $\\Delta t = 1.0\\,\\mathrm{fs} = 1.0 \\times 10^{-15}\\,\\mathrm{s}$.\nSubstituting these values into the expression for $k$:\n$$k = \\frac{4 \\times (1.008 \\times 1.66053906660 \\times 10^{-27}\\,\\mathrm{kg})}{3 \\times (1.0 \\times 10^{-15}\\,\\mathrm{s})^2}$$\n$$k = \\frac{4 \\times 1.673823379... \\times 10^{-27}}{3 \\times 1.0 \\times 10^{-30}} \\,\\mathrm{N}\\,\\mathrm{m}^{-1}$$\n$$k = \\frac{6.6952935... \\times 10^{-27}}{3 \\times 10^{-30}} \\,\\mathrm{N}\\,\\mathrm{m}^{-1}$$\n$$k \\approx 2.2317645 \\times 10^3 \\,\\mathrm{N}\\,\\mathrm{m}^{-1}$$\nThe problem requires the answer to be rounded to three significant figures.\n$$k \\approx 2.23 \\times 10^3 \\,\\mathrm{N}\\,\\mathrm{m}^{-1}$$\nThis is the smallest force constant for which the integration becomes unstable.", "answer": "$$\n\\boxed{2.23 \\times 10^3}\n$$", "id": "2452099"}, {"introduction": "While understanding the theoretical stability limit is crucial, in real-world research we often simulate complex systems where calculating the highest vibrational frequency, $\\omega_{\\text{max}}$, is impractical. This practice moves from pure theory to professional methodology by tasking you with identifying the standard empirical protocol for determining an optimal timestep, $\\Delta t$. Evaluating the proposed methods will solidify your understanding of why monitoring total energy conservation in a microcanonical (NVE) ensemble is the undisputed gold standard for validating integrator stability and accuracy for any new system [@problem_id:2452115].", "problem": "You are asked to run an all-atom classical Molecular Dynamics (MD) simulation of an unknown neutral organic solute in liquid water at temperature $T=300\\,\\mathrm{K}$. The system will be described by a standard fixed-charge force field with bonded and nonbonded terms; nonbonded interactions are truncated at a real-space cutoff $r_{c}=1.0\\,\\mathrm{nm}$ with Ewald summation for long-range electrostatics. You plan to use the velocity Verlet integrator, with and without constraints that fix all bonds involving hydrogen atoms (implemented via an iterative holonomic constraint algorithm). Before any production runs in the canonical (constant number of particles, volume, and temperature) ensemble, you must determine an appropriate integration time step $\\Delta t$ for stable and accurate dynamics in this new, unknown molecular system.\n\nWhich of the following protocols constitutes a sound empirical (“experimental”) procedure to determine an appropriate $\\Delta t$ for this system?\n\nA. Run a single long isothermal–isobaric (constant number of particles, pressure, and temperature) trajectory starting from a random configuration and progressively increase $\\Delta t$ on the fly whenever the simulation appears stable; select the largest $\\Delta t$ that allows completion of the trajectory without a numerical crash, regardless of fluctuations in thermodynamic quantities.\n\nB. Use a literature estimate of the highest vibrational wavenumber of typical bonds (for example, C–H near $3000\\,\\mathrm{cm}^{-1}$) to compute the corresponding period and pick $\\Delta t$ as a fixed fraction of that period (for example, $\\Delta t$ equal to one tenth of the period), without running any short pilot simulations.\n\nC. Equilibrate the system with a conservative small $\\Delta t$ (for example, $\\Delta t=0.5\\,\\mathrm{fs}$) in the canonical ensemble to a steady state, then generate identical initial coordinates and velocities and perform a series of short microcanonical (constant number of particles, volume, and energy) test runs at candidate $\\Delta t$ values spanning a relevant range (with and without hydrogen-bond constraints as planned for production). For each $\\Delta t$, monitor the total energy $E(t)$ for systematic drift over time, check constraint convergence metrics (for example, maximum iterations and any failures), and confirm that basic observables (for example, temperature distribution in the canonical ensemble, radial distribution functions) remain invariant within statistical uncertainty across acceptable $\\Delta t$. Choose the largest $\\Delta t$ that exhibits negligible systematic energy drift over the test window (for example, relative drift $\\lvert \\mathrm{d}E/\\mathrm{d}t \\rvert / \\lvert \\langle E \\rangle \\rvert \\ll 10^{-5}\\,\\mathrm{ps}^{-1}$), no constraint failures, and stable thermodynamic behavior when the thermostat/barostat is reapplied.\n\nD. Couple the system to a very strong thermostat (very short relaxation time) during short tests so that the thermostat removes integration errors; then increase $\\Delta t$ until the instantaneous temperature remains close to $300\\,\\mathrm{K}$ even if constraints occasionally fail, and select that as the production $\\Delta t$.\n\nE. Compute the force on each atom from the equilibrated configuration and perform a single forward Euler step with a trial $\\Delta t$; if the one-step change in positions is smaller than a chosen tolerance (for example, the maximum displacement is less than $0.01\\,\\mathrm{\\AA}$), accept that $\\Delta t$ as optimal without further testing, assuming the error characteristics do not change over time.", "solution": "The problem asks for a sound empirical procedure to determine an appropriate integration time step, $\\Delta t$, for a classical all-atom Molecular Dynamics (MD) simulation of a new system. The validity and accuracy of an MD simulation are critically dependent on the choice of $\\Delta t$. An integration time step must be small enough to accurately sample the highest-frequency motions in the system, ensuring both numerical stability and the conservation of physical quantities. The velocity Verlet algorithm specified is a second-order, symplectic, and time-reversible integrator, which has good long-term stability properties when used correctly. The key to validating a chosen $\\Delta t$ is to test its ability to conserve the total energy of the system in the absence of external perturbations like thermostats or barostats.\n\nFirst, the problem statement must be validated.\n\n**Step 1: Extract Givens**\n- **System:** An unknown neutral organic solute in liquid water.\n- **Simulation Type:** All-atom classical Molecular Dynamics (MD).\n- **Ensemble (Production):** Canonical (NVT), constant number of particles ($N$), volume ($V$), and temperature ($T$).\n- **Temperature:** $T=300\\,\\mathrm{K}$.\n- **Force Field:** Standard fixed-charge with bonded and nonbonded terms.\n- **Nonbonded Interactions:** Real-space cutoff $r_{c}=1.0\\,\\mathrm{nm}$ with Ewald summation for long-range electrostatics.\n- **Integrator:** Velocity Verlet.\n- **Constraints:** Option to use an iterative holonomic constraint algorithm to fix all bonds involving hydrogen atoms.\n- **Objective:** Determine an appropriate integration time step $\\Delta t$ for this new system via an empirical procedure.\n\n**Step 2: Validate Using Extracted Givens**\nThe problem is scientifically grounded, describing a standard and fundamental task in computational chemistry. All specified methods (MD, force fields, velocity Verlet, Ewald summation, constraints, NVT/NVE ensembles) are standard in the field. The problem is well-posed, asking for the correct methodology among several choices. It is objectively stated using precise technical language. The presence of an \"unknown\" solute makes empirical determination of $\\Delta t$ not just a good practice, but a necessity, as a priori theoretical estimates might be insufficient. The problem is self-contained and free of contradictions or scientifically unsound premises.\n\n**Step 3: Verdict and Action**\nThe problem statement is **valid**. A solution will be derived by analyzing the principles of numerical integration in MD and then evaluating each proposed protocol.\n\nThe fundamental criterion for a good integrator with a specific time step $\\Delta t$ in MD is its ability to generate a trajectory that accurately approximates the true classical dynamics. For a Hamiltonian system, this means the integrator should, as closely as possible, conserve the total energy. The microcanonical (NVE) ensemble, where the number of particles ($N$), volume ($V$), and total energy ($E$) are constant, is the natural setting for testing the intrinsic quality of a numerical integrator. In an NVE simulation, any systematic drift in the total energy is a direct consequence of integration error. A thermostat or barostat, by design, adds or removes energy from the system, and therefore would mask the very integration errors we seek to quantify. Therefore, any robust protocol for testing $\\Delta t$ must be based on NVE simulations.\n\nNow, we evaluate each option:\n\n**A. Run a single long isothermal–isobaric (constant number of particles, pressure, and temperature) trajectory starting from a random configuration and progressively increase $\\Delta t$ on the fly whenever the simulation appears stable; select the largest $\\Delta t$ that allows completion of the trajectory without a numerical crash, regardless of fluctuations in thermodynamic quantities.**\n\nThis procedure is profoundly flawed for several reasons.\n1.  **Incorrect Ensemble:** It uses the isothermal-isobaric (NPT) ensemble for testing. A thermostat and a barostat actively manipulate the system's energy and volume, which will effectively hide the energy drift caused by an overly large $\\Delta t$. The purpose of the test is to isolate and observe integrator error, which this protocol fails to do.\n2.  **Changing $\\Delta t$ \"on the fly\":** Altering the time step during a simulation breaks the time-reversibility and symplectic properties of the velocity Verlet integrator. This invalidates the statistical mechanics of the generated trajectory, meaning that any averages computed from it are meaningless.\n3.  **Insufficient Criterion:** Relying on \"completion of the trajectory without a numerical crash\" is a very poor metric for stability. A simulation can be numerically stable but physically nonsensical long before it crashes. We require accuracy, not just avoidance of catastrophic failure. The disregard for fluctuations in thermodynamic quantities is a major error.\n\n**Verdict:** **Incorrect**. This protocol is naive and scientifically unsound.\n\n**B. Use a literature estimate of the highest vibrational wavenumber of typical bonds (for example, C–H near $3000\\,\\mathrm{cm}^{-1}$) to compute the corresponding period and pick $\\Delta t$ as a fixed fraction of that period (for example, $\\Delta t$ equal to one tenth of the period), without running any short pilot simulations.**\n\nThis describes a common heuristic for making an initial guess for $\\Delta t$, not a validation procedure.\n1.  **Not an Empirical Procedure:** The problem explicitly requests an *empirical* (\"experimental\") procedure. This option relies entirely on a theoretical estimate and forgoes any actual simulation test on the specific system.\n2.  **Insufficient for a New System:** The system contains an \"unknown\" solute. Relying on \"typical\" bond frequencies is risky; the molecule may possess unusual, higher-frequency modes. Furthermore, the true highest frequency in the system is a collective property influenced by the entire potential energy surface, not just isolated bond parameters.\n3.  **No Verification:** The most significant flaw is the complete absence of a verification step. A time step, no matter how it is chosen, must be tested to confirm that it yields stable and accurate dynamics for the specific system under study.\n\n**Verdict:** **Incorrect**. This is a reasonable starting point for a guess, but it is not a validation protocol.\n\n**C. Equilibrate the system with a conservative small $\\Delta t$ (for example, $\\Delta t=0.5\\,\\mathrm{fs}$) in the canonical ensemble to a steady state, then generate identical initial coordinates and velocities and perform a series of short microcanonical (constant number of particles, volume, and energy) test runs at candidate $\\Delta t$ values spanning a relevant range (with and without hydrogen-bond constraints as planned for production). For each $\\Delta t$, monitor the total energy $E(t)$ for systematic drift over time, check constraint convergence metrics (for example, maximum iterations and any failures), and confirm that basic observables (for example, temperature distribution in the canonical ensemble, radial distribution functions) remain invariant within statistical uncertainty across acceptable $\\Delta t$. Choose the largest $\\Delta t$ that exhibits negligible systematic energy drift over the test window (for example, relative drift $\\lvert \\mathrm{d}E/\\mathrm{d}t \\rvert / \\lvert \\langle E \\rangle \\rvert \\ll 10^{-5}\\,\\mathrm{ps}^{-1}$), no constraint failures, and stable thermodynamic behavior when the thermostat/barostat is reapplied.**\n\nThis protocol is methodical, rigorous, and aligns perfectly with the best practices of computational simulation.\n1.  **Proper Equilibration:** It begins with a properly equilibrated system, which is a necessary starting point for any meaningful dynamics.\n2.  **Correct Test Ensemble:** It correctly uses the microcanonical (NVE) ensemble for the core test, which allows for direct and unambiguous measurement of energy conservation, the primary indicator of integrator quality.\n3.  **Systematic Testing:** It proposes a systematic scan of candidate $\\Delta t$ values from identical initial conditions, providing a controlled comparison.\n4.  **Comprehensive Metrics:** It uses the correct and most sensitive metric: systematic drift in total energy, $\\mathrm{d}E/\\mathrm{d}t$. It also correctly includes monitoring of constraint algorithm performance, which is essential when constraints are used.\n5.  **Validation of Observables:** It includes a final sanity check that structural and thermodynamic observables are not pathologically dependent on the choice of $\\Delta t$ within the acceptable range.\n6.  **Optimal Selection:** It correctly balances computational efficiency (choosing the largest possible $\\Delta t$) with the strict requirements of accuracy and stability.\n\n**Verdict:** **Correct**. This is the textbook, professional procedure for determining an optimal and reliable integration time step.\n\n**D. Couple the system to a very strong thermostat (very short relaxation time) during short tests so that the thermostat removes integration errors; then increase $\\Delta t$ until the instantaneous temperature remains close to $300\\,\\mathrm{K}$ even if constraints occasionally fail, and select that as the production $\\Delta t$.**\n\nThis procedure is based on a fundamental misunderstanding of the role of a thermostat.\n1.  **Misuse of Thermostat:** A thermostat should maintain the temperature of a system undergoing physically correct dynamics. Here, it is explicitly proposed to use the thermostat to mask the \"heating\" caused by integration errors from a large $\\Delta t$. This does not fix the errors; it just hides them. The resulting trajectory will not sample the correct canonical ensemble because the underlying dynamics are wrong.\n2.  **Poor Stability Metric:** Constant temperature in a heavily thermostatted system is a measure of the thermostat's effectiveness, not the integrator's accuracy. One can obtain a stable temperature reading from a simulation that is producing a completely unphysical trajectory.\n3.  **Accepting Constraint Failures:** Tolerating constraint failures is unacceptable. A constraint failure is a definitive sign that the integrator is taking steps so large that the geometry of the system is being severely distorted, and it indicates a breakdown of the simulation algorithm.\n\n**Verdict:** **Incorrect**. This is a dangerous and flawed method that guarantees an unphysical simulation.\n\n**E. Compute the force on each atom from the equilibrated configuration and perform a single forward Euler step with a trial $\\Delta t$; if the one-step change in positions is smaller than a chosen tolerance (for example, the maximum displacement is less than $0.01\\,\\mathrm{\\AA}$), accept that $\\Delta t$ as optimal without further testing, assuming the error characteristics do not change over time.**\n\nThis method is overly simplistic and wholly inadequate.\n1.  **Wrong Integrator for Test:** It tests the forward Euler method, but the production simulation will use velocity Verlet. These integrators have different stability and accuracy properties. One must test the algorithm that will be used in production.\n2.  **Single-Step Test:** A single integration step from a single configuration provides almost no information about long-term stability. Integration error is a cumulative effect, and the magnitude of forces can vary dramatically as the system explores its phase space. A test must cover a statistically relevant period of time.\n3.  **Arbitrary Criterion:** The criterion of maximum displacement is arbitrary and not directly related to the most important conserved quantity, the total energy. It gives no information about error accumulation in the velocities or the total energy.\n\n**Verdict:** **Incorrect**. This test is trivial and provides no meaningful guarantee of stability or accuracy.\n\nIn summary, only protocol C represents a scientifically rigorous and sound method for the empirical determination of the integration time step. It correctly identifies the NVE ensemble as the proper testing ground and total energy conservation as the primary metric of success.", "answer": "$$\\boxed{C}$$", "id": "2452115"}, {"introduction": "We have established the need to choose a timestep that is small enough for stability, but is a smaller timestep always better? This final exercise explores a critical trade-off between numerical accuracy and computational efficiency, a central challenge when studying rare events like chemical reactions. You will analyze a scenario where choosing a timestep that is *too small* is actually counterproductive, as it prevents the simulation from running long enough (within a fixed computational budget) to observe the phenomenon of interest, a pitfall that could lead to flawed scientific conclusions [@problem_id:2452060].", "problem": "A one-dimensional isomerization along coordinate $x$ in a symmetric double-well potential $U(x)$ is simulated by Molecular Dynamics (MD) using a stochastic velocity-Verlet scheme with a Langevin thermostat at temperature $T$. The fastest bounded motion in either well is approximately harmonic with period $\\tau_{\\mathrm{fast}}=20\\,\\mathrm{fs}$. The integration time step is $\\Delta t$, and each step requires a single force evaluation. The total computational budget allows at most $N_{\\max}=5\\times 10^5$ steps. Independent kinetic measurements at these thermodynamic conditions indicate that barrier crossings (left well $\\to$ right well or vice versa) occur as a Poisson process with mean rate $k=3\\times 10^{-3}\\,\\mathrm{ps}^{-1}$ when integrator-induced bias is negligible. You begin in the left well. You wish to choose $\\Delta t$ so that the simulation (i) remains linearly stable for the fastest mode and (ii) has at least a $95\\%$ chance to observe at least one barrier-crossing event within the allotted budget, to avoid concluding (incorrectly) that the left well is the only stable state because the trajectory remained in it. Consider the following candidate time steps:\n- $\\Delta t_A=0.25\\,\\mathrm{fs}$,\n- $\\Delta t_B=1.0\\,\\mathrm{fs}$,\n- $\\Delta t_C=2.0\\,\\mathrm{fs}$,\n- $\\Delta t_D=10.0\\,\\mathrm{fs}$.\nWhich option below correctly identifies the best choice for $\\Delta t$ under these constraints and explains why an excessively small time step would be computationally wasteful and could lead to an incorrect scientific conclusion by trapping the system?\n\nA. Choose $\\Delta t_A$ because smaller $\\Delta t$ always improves both accuracy and sampling; resolving the fast mode extremely well guarantees correct kinetics and equilibrium sampling within the given computational budget.\n\nB. Choose $\\Delta t_C$ because it is within the linear stability limit set by the fastest oscillation and, for the fixed budget $N_{\\max}$, it maximizes the simulated physical time, yielding at least a $95\\%$ chance to observe a crossing; using a much smaller $\\Delta t$ would waste computation and increase the risk of observing no transitions, falsely suggesting the system is trapped.\n\nC. Choose $\\Delta t_D$ because the Langevin thermostat damps any instability, allowing a much larger step that greatly extends the simulated time and thus guarantees barrier crossings within the budget.\n\nD. Choose $\\Delta t_B$ because it provides a compromise between stability and accuracy; the probability to see a transition within a fixed number of steps depends only on the number of steps, not on $\\Delta t$, so it avoids trapping without wasting computation.", "solution": "The problem requires selecting an optimal integration time step, $\\Delta t$, for a Molecular Dynamics simulation of a one-dimensional isomerization process. The choice must satisfy two primary constraints: (i) numerical stability of the integrator for the fastest motion in the system, and (ii) a sufficiently high probability (at least $95\\%$) of observing a rare barrier-crossing event within a fixed computational budget of $N_{\\max}$ steps.\n\nFirst, let us analyze the problem statement and its constraints formally.\n\nThe given parameters are:\n- Period of the fastest bounded motion: $\\tau_{\\mathrm{fast}} = 20\\,\\mathrm{fs}$.\n- Maximum number of simulation steps: $N_{\\max} = 5 \\times 10^5$.\n- Mean rate of barrier crossings: $k = 3 \\times 10^{-3}\\,\\mathrm{ps}^{-1}$.\n- Required probability of observing at least one crossing: $P(\\text{at least one}) \\ge 0.95$.\n\nWe will evaluate the two constraints for the candidate time steps.\n\n**Constraint (i): Numerical Stability**\nThe simulation uses a velocity-Verlet scheme. For a harmonic oscillator with angular frequency $\\omega$, the strict stability limit for this integrator is $\\omega \\Delta t < 2$. The fastest motion in the system has a period $\\tau_{\\mathrm{fast}} = 20\\,\\mathrm{fs}$, which corresponds to an angular frequency of $\\omega_{\\mathrm{fast}} = 2\\pi / \\tau_{\\mathrm{fast}}$. This gives a theoretical stability limit of $\\Delta t < \\tau_{\\mathrm{fast}} / \\pi \\approx 20\\,\\mathrm{fs} / 3.14159 \\approx 6.37\\,\\mathrm{fs}$.\nHowever, for practical purposes and to ensure the accurate integration of dynamics, a much stricter rule of thumb is universally applied: the time step should be at most one-tenth of the period of the fastest oscillation.\n$$ \\Delta t \\le \\frac{\\tau_{\\mathrm{fast}}}{10} $$\nApplying this to the given problem:\n$$ \\Delta t \\le \\frac{20\\,\\mathrm{fs}}{10} = 2.0\\,\\mathrm{fs} $$\nThis condition ensures that the fastest vibrational mode is sampled with at least $10$ points per period, preventing resonance artifacts and ensuring energy conservation in the microcanonical ensemble (though here, a thermostat is used, the principle of resolving the dynamics remains crucial for correctness).\n\nLet us check the candidate time steps against this stability criterion:\n- $\\Delta t_A = 0.25\\,\\mathrm{fs}$: Stable ($0.25\\,\\mathrm{fs} \\le 2.0\\,\\mathrm{fs}$).\n- $\\Delta t_B = 1.0\\,\\mathrm{fs}$: Stable ($1.0\\,\\mathrm{fs} \\le 2.0\\,\\mathrm{fs}$).\n- $\\Delta t_C = 2.0\\,\\mathrm{fs}$: Marginally stable, as it lies at the upper bound of the commonly accepted practice. It is considered an aggressive but often acceptable choice to maximize simulation time.\n- $\\Delta t_D = 10.0\\,\\mathrm{fs}$: Unstable. This time step is $\\tau_{\\mathrm{fast}}/2$, which is far beyond the stability limit. Integration with such a step would lead to unphysical dynamics and catastrophic failure.\n\nTherefore, $\\Delta t_D$ must be rejected on grounds of numerical instability.\n\n**Constraint (ii): Sufficient Sampling of Rare Events**\nThe barrier crossings are modeled as a Poisson process with rate $k$. The total physical time simulated is $T_{\\mathrm{sim}} = N_{\\max} \\cdot \\Delta t$. The mean number of expected events, $\\lambda$, during this time is:\n$$ \\lambda = k \\cdot T_{\\mathrm{sim}} = k \\cdot N_{\\max} \\cdot \\Delta t $$\nThe probability of observing zero events in this time interval is given by the Poisson distribution for $n=0$:\n$$ P(n=0) = e^{-\\lambda} = e^{-k \\cdot N_{\\max} \\cdot \\Delta t} $$\nThe problem requires that the probability of observing at least one event is $0.95$ or greater.\n$$ P(n \\ge 1) = 1 - P(n=0) = 1 - e^{-k \\cdot N_{\\max} \\cdot \\Delta t} \\ge 0.95 $$\nThis implies:\n$$ e^{-k \\cdot N_{\\max} \\cdot \\Delta t} \\le 0.05 $$\nTaking the natural logarithm of both sides:\n$$ -k \\cdot N_{\\max} \\cdot \\Delta t \\le \\ln(0.05) $$\n$$ k \\cdot N_{\\max} \\cdot \\Delta t \\ge -\\ln(0.05) = \\ln(20) \\approx 2.9957 $$\nWe can now calculate the minimum required $\\Delta t$ to satisfy this sampling condition. Let's use consistent units. We convert $k$ to units of $\\mathrm{fs}^{-1}$:\n$$ k = 3 \\times 10^{-3}\\,\\mathrm{ps}^{-1} = 3 \\times 10^{-3} \\frac{1}{1000\\,\\mathrm{fs}} = 3 \\times 10^{-6}\\,\\mathrm{fs}^{-1} $$\nNow, we solve for $\\Delta t$:\n$$ (3 \\times 10^{-6}\\,\\mathrm{fs}^{-1}) \\cdot (5 \\times 10^5) \\cdot \\Delta t \\ge 2.9957 $$\n$$ (1.5\\,\\mathrm{fs}^{-1}) \\cdot \\Delta t \\ge 2.9957 $$\n$$ \\Delta t \\ge \\frac{2.9957}{1.5}\\,\\mathrm{fs} \\approx 1.997\\,\\mathrm{fs} $$\nSo, to meet the sampling requirement, the time step must be $\\Delta t \\ge 2.0\\,\\mathrm{fs}$.\n\n**Combining Constraints and Evaluating Options**\nWe have two conditions for the optimal time step:\n1. Stability: $\\Delta t \\le 2.0\\,\\mathrm{fs}$\n2. Sampling: $\\Delta t \\ge 2.0\\,\\mathrm{fs}$\n\nThe only candidate value that satisfies both conditions is $\\Delta t = 2.0\\,\\mathrm{fs}$. Let's verify this choice and analyze the consequences of other choices.\n\n- For $\\Delta t_C = 2.0\\,\\mathrm{fs}$: It satisfies both the stability limit (marginally) and the sampling requirement. The total simulation time is $T_{\\mathrm{sim}} = (5 \\times 10^5) \\cdot (2.0\\,\\mathrm{fs}) = 10^6\\,\\mathrm{fs} = 1000\\,\\mathrm{ps}$. The expected number of crossings is $\\lambda = (3 \\times 10^{-3}\\,\\mathrm{ps}^{-1}) \\cdot (1000\\,\\mathrm{ps}) = 3.0$. The probability of at least one crossing is $1 - e^{-3} \\approx 1 - 0.0498 = 0.9502$, which satisfies the $95\\%$ criterion. This is the optimal choice.\n\n- For $\\Delta t_A = 0.25\\,\\mathrm{fs}$ and $\\Delta t_B = 1.0\\,\\mathrm{fs}$: These time steps are stable but fail the sampling requirement.\n    - For $\\Delta t_A$: $T_{\\mathrm{sim}} = 125\\,\\mathrm{ps}$, $\\lambda = 0.375$, $P(n \\ge 1) = 1 - e^{-0.375} \\approx 0.313$ (or $31.3\\%$).\n    - For $\\Delta t_B$: $T_{\\mathrm{sim}} = 500\\,\\mathrm{ps}$, $\\lambda = 1.5$, $P(n \\ge 1) = 1 - e^{-1.5} \\approx 0.777$ (or $77.7\\%$).\nIn both cases, there is a high risk of observing no transitions. This would lead to the incorrect scientific conclusion that the system is trapped in the initial well, simply because the simulation was not run long enough. The computational effort is \"wasted\" on overly resolving the fast vibrations at the expense of sampling the slow isomerization process, which is the primary scientific interest.\n\nNow we evaluate each provided option:\n\n**A. Choose $\\Delta t_A$ because smaller $\\Delta t$ always improves both accuracy and sampling; resolving the fast mode extremely well guarantees correct kinetics and equilibrium sampling within the given computational budget.**\nThis statement is fundamentally flawed. For a fixed computational budget (number of steps), a smaller $\\Delta t$ leads to a shorter total simulation time, which severely hinders the sampling of slow, rare events. As calculated, with $\\Delta t_A$, the probability of observing the event is only about $31\\%$. Thus, it does not guarantee correct sampling. **Incorrect**.\n\n**B. Choose $\\Delta t_C$ because it is within the linear stability limit set by the fastest oscillation and, for the fixed budget $N_{\\max}$, it maximizes the simulated physical time, yielding at least a $95\\%$ chance to observe a crossing; using a much smaller $\\Delta t$ would waste computation and increase the risk of observing no transitions, falsely suggesting the system is trapped.**\nThis statement is entirely consistent with our derivation. $\\Delta t_C=2.0\\,\\mathrm{fs}$ meets the stability criterion ($\\Delta t \\le 2.0\\,\\mathrm{fs}$) and the sampling criterion ($\\Delta t \\ge 2.0\\,\\mathrm{fs}$). It is the largest stable time step, which for a fixed $N_{\\max}$ maximizes the physical time $T_{\\mathrm{sim}}$ and thus the probability of observing the rare event. The explanation of the trade-off is also correct: smaller time steps, while more accurate per-step, would fail to achieve the scientific goal due to insufficient sampling time. **Correct**.\n\n**C. Choose $\\Delta t_D$ because the Langevin thermostat damps any instability, allowing a much larger step that greatly extends the simulated time and thus guarantees barrier crossings within the budget.**\nThis represents dangerous and incorrect reasoning. $\\Delta t_D = 10.0\\,\\mathrm{fs}$ is grossly unstable for the fastest mode ($\\tau_{\\mathrm{fast}}=20\\,\\mathrm{fs}$). A thermostat cannot correct for dynamics generated by an unstable integrator. While it may prevent a simple explosion of the total energy, the trajectory generated will be unphysical and will not correspond to a valid sampling of the canonical ensemble. The results would be meaningless numerical artifacts. **Incorrect**.\n\n**D. Choose $\\Delta t_B$ because it provides a compromise between stability and accuracy; the probability to see a transition within a fixed number of steps depends only on the number of steps, not on $\\Delta t$, so it avoids trapping without wasting computation.**\nThis statement contains a severe conceptual error. The assertion that \"the probability to see a transition within a fixed number of steps depends only on the number of steps, not on $\\Delta t$\" is false. The probability of a physical process depends on physical time, $T_{\\mathrm{sim}}$, which is the product of the number of steps and the time step size ($T_{\\mathrm{sim}}=N \\cdot \\Delta t$). For a fixed number of steps, the probability is directly dependent on $\\Delta t$. Our calculation shows that $\\Delta t_B=1.0\\,\\mathrm{fs}$ yields only a $77.7\\%$ chance of observation, which is insufficient. **Incorrect**.\n\nThus, the only correct option is B, which identifies $\\Delta t_C=2.0\\,\\mathrm{fs}$ as the optimal choice and provides a sound justification.", "answer": "$$\\boxed{B}$$", "id": "2452060"}]}