{"hands_on_practices": [{"introduction": "Understanding the distinction between local and global optima begins with a fundamental question: how do local minima arise in the first place? This exercise provides a unique opportunity to see this happen in a controlled manner. You will analyze a function that transitions smoothly from a simple, convex shape with a single global minimum to a non-convex landscape with multiple local minima, a process known as bifurcation. By combining analytical calculus to find the exact moment of this transition and numerical simulation to track the solution's path, you will gain a deep, intuitive grasp of how problem structure dictates the number and nature of optima. [@problem_id:3145108]", "problem": "You are given a one-dimensional parametric objective that implements a smoothing schedule which begins convex and gradually introduces nonconvex features as the schedule parameter increases. Let the family of functions be defined by\n$$\nf(x;s) \\;=\\; x^2 \\;+\\; \\lambda(s)\\,\\bigl(x^2 - a^2\\bigr)^2,\n\\quad \\text{with} \\quad \\lambda(s) \\;=\\; c\\,s,\\quad s \\in [0,1],\n$$\nwhere $a \\gt 0$ and $c \\gt 0$ are fixed parameters. The schedule parameter $s$ controls the strength of the nonconvex quartic term. The task is to precisely characterize when local minima emerge and to simulate how a basic descent algorithm adapts across the schedule.\n\nUse the following foundations as the starting point (do not assume any result beyond these):\n- The definition of convexity in one dimension: a twice-differentiable function $f$ is convex on $\\mathbb{R}$ if and only if $f''(x) \\ge 0$ for all $x \\in \\mathbb{R}$.\n- A point $x^\\star$ is a local minimizer if there exists $\\epsilon \\gt 0$ such that $f(x^\\star) \\le f(x)$ for all $x$ with $\\lvert x - x^\\star \\rvert \\lt \\epsilon$, and for twice-differentiable $f$, a strict local minimizer with $f'(x^\\star) = 0$ typically satisfies $f''(x^\\star) \\gt 0$.\n- Gradient descent in one dimension with fixed step size $\\eta \\gt 0$ iterates $x_{k+1} = x_k - \\eta\\,f'(x_k)$ and, under sufficiently small $\\eta$ and smoothness, converges to a stationary point.\n\nYour program must carry out the following steps for each test case:\n1) Derive and compute the exact schedule value $s_\\text{crit}$ at which convexity is lost and multiple critical points coalesce or split, expressed in terms of $a$ and $c$.\n2) For a prescribed list of schedule values $S = [\\,s_0, s_1, s_2, s_3, s_4\\,] = [\\,0.0, 0.2, 0.5, 0.8, 1.0\\,]$, determine the number of distinct local minima of $f(\\cdot; s_j)$ for each $s_j \\in S$.\n3) Simulate a continuation strategy (warm-start gradient descent) across the schedule:\n   - Use initial point $x_0 = 0.05$ at $s_0$.\n   - For $j = 0,1,2,3,4$, run gradient descent on $f(\\cdot; s_j)$ from the current starting point to obtain a converged point $x^\\star(s_j)$ using fixed step size $\\eta = 0.02$, maximum iterations $N_{\\max} = 50000$, and terminate when either the step change $\\lvert x_{k+1} - x_k \\rvert \\lt 10^{-10}$ or the gradient magnitude $\\lvert f'(x_k; s_j) \\rvert \\lt 10^{-8}$.\n   - To avoid getting trapped at an unstable stationary point when moving from $s_j$ to $s_{j+1}$, perturb the next starting point as $x_0 \\leftarrow x^\\star(s_j) + \\delta \\cdot \\operatorname{sgn}_+(x^\\star(s_j))$, where $\\delta = 10^{-6}$ and $\\operatorname{sgn}_+(x) = 1$ if $x \\ge 0$ and $\\operatorname{sgn}_+(x) = -1$ if $x \\lt 0$.\n   - At the final schedule $s_4 = 1.0$, report the integer sign of the converged point using the thresholded sign function $\\text{sign\\_int}(x) = 1$ if $x \\gt 10^{-6}$, $\\text{sign\\_int}(x) = -1$ if $x \\lt -10^{-6}$, and $\\text{sign\\_int}(x) = 0$ otherwise.\n4) Probe the landscape at the final schedule $s_4 = 1.0$ using a cold multi-start gradient descent with starting points $X_\\text{seeds} = [-1.0, -0.5, -0.1, 0.1, 0.5, 1.0]$ and the same descent hyperparameters as above, cluster the converged points by merging any two within absolute distance less than $10^{-3}$, and report the integer number of distinct minima discovered.\n\nTest suite. Run the above for the following three parameter sets:\n- Test case $1$: $a = 1.0$, $c = 0.3$.\n- Test case $2$: $a = 1.0$, $c = 1.5$.\n- Test case $3$: $a = 0.7$, $c = 5.0$.\n\nYour program must produce a single line of output containing all results in a single flat list, with the following order for each test case, then concatenated across the three cases:\n- $s_\\text{crit}$ rounded to $6$ decimal places,\n- the $5$ integers giving the number of local minima at $s_0, s_1, s_2, s_3, s_4$,\n- the single integer warm-start sign at $s_4$,\n- the single integer number of distinct minima found by cold multi-start at $s_4$.\n\nThus there are $8$ values per test case and $24$ values total. The program should print exactly one line containing these $24$ values as a comma-separated list enclosed in square brackets, with no spaces, for example: \"[r_1,r_2,...,r_{24}]\".", "solution": "The user-provided problem is a well-posed exercise in nonlinear optimization and bifurcation theory. It is scientifically sound, self-contained, and all terms are formally defined. The task is to analyze the behavior of a one-dimensional parametric objective function $f(x;s)$ by deriving a critical parameter value, analyzing the number of local minima, and simulating a gradient-based optimization strategy. The problem is valid.\n\nThe objective function is given by:\n$$\nf(x;s) = x^2 + \\lambda(s)\\,\\bigl(x^2 - a^2\\bigr)^2\n$$\nwhere $\\lambda(s) = c\\,s$, with parameters $a  0$, $c  0$, and the schedule parameter $s \\in [0,1]$.\n\n**Part 1: Derivation of the Critical Schedule Value $s_\\text{crit}$**\n\nA twice-differentiable function is convex on $\\mathbb{R}$ if and only if its second derivative is non-negative everywhere. We first compute the first and second derivatives of $f(x;s)$ with respect to $x$.\n\nThe function can be expanded as:\n$$\nf(x;s) = x^2 + cs(x^4 - 2a^2x^2 + a^4)\n$$\nThe first derivative, $f'(x;s)$, is:\n$$\nf'(x;s) = \\frac{\\partial f}{\\partial x} = 2x + cs(4x^3 - 4a^2x) = 2x \\bigl(1 + 2cs(x^2 - a^2)\\bigr)\n$$\nThe second derivative, $f''(x;s)$, is:\n$$\nf''(x;s) = \\frac{\\partial^2 f}{\\partial x^2} = 2 + cs(12x^2 - 4a^2) = 2 + 4cs(3x^2 - a^2)\n$$\nFor $f(x;s)$ to be convex for all $x \\in \\mathbb{R}$, we must have $f''(x;s) \\ge 0$ for all $x$. Since $c  0$ and $s \\ge 0$, the term $12csx^2$ is non-negative. The expression $f''(x;s)$ is a parabolic function of $x$ opening upwards (or a constant if $cs=0$), so its global minimum occurs at $x=0$.\nWe evaluate $f''(x;s)$ at its minimum:\n$$\n\\min_x f''(x;s) = f''(0;s) = 2 + 4cs(3(0)^2 - a^2) = 2 - 4csa^2\n$$\nThe condition for convexity is that this minimum value must be non-negative:\n$$\n2 - 4csa^2 \\ge 0 \\implies 2 \\ge 4csa^2 \\implies s \\le \\frac{2}{4ca^2} = \\frac{1}{2ca^2}\n$$\nThe function loses convexity at the point where this inequality no longer holds. The critical schedule value, $s_\\text{crit}$, is the boundary of this inequality:\n$$\ns_\\text{crit} = \\frac{1}{2ca^2}\n$$\nFor $s  s_\\text{crit}$, $f''(0;s)  0$, indicating that $x=0$ has become a local maximum, and the function is no longer convex. This event corresponds to a pitchfork bifurcation where one minimum splits into two minima and a maximum.\n\n**Part 2: Determination of the Number of Local Minima**\n\nLocal minima are a subset of the critical points, which are the roots of $f'(x;s)=0$.\n$$\nf'(x;s) = 2x \\bigl(1 + 2cs(x^2 - a^2)\\bigr) = 0\n$$\nThis equation has solutions when $x=0$ or when $1 + 2cs(x^2-a^2) = 0$.\n\nCase 1: $s \\le s_\\text{crit}$\nIn this case, $s \\le \\frac{1}{2ca^2}$, which implies $2csa^2 \\le 1$.\nThe second term in the product gives $x^2 = a^2 - \\frac{1}{2cs}$. For a real solution for $x$ to exist, we need $a^2 - \\frac{1}{2cs} \\ge 0$, which implies $s \\ge \\frac{1}{2ca^2} = s_\\text{crit}$.\nThus, for $s  s_\\text{crit}$, the only real root is $x=0$.\nAt $s = s_\\text{crit}$, we have $x^2 = a^2 - a^2 = 0$, so again the only root is $x=0$.\nLet's check the stability at $x=0$: $f''(0;s) = 2 - 4csa^2 = 2(1 - 2csa^2)$.\nSince $s \\le s_\\text{crit}$, $2csa^2 \\le 1$, so $f''(0;s) \\ge 0$.\nTherefore, for $s \\le s_\\text{crit}$, $x=0$ is a local minimizer. There is exactly one local minimum.\n\nCase 2: $s  s_\\text{crit}$\nHere, $s  \\frac{1}{2ca^2}$, so $2csa^2  1$.\nThe critical points are:\n1.  $x_0 = 0$. At this point, $f''(0;s) = 2(1 - 2csa^2)  0$, so $x=0$ is a local maximum.\n2.  $x^2 = a^2 - \\frac{1}{2cs}$. Since $s  s_\\text{crit}$, $a^2 - \\frac{1}{2cs}  0$, giving two distinct real roots $x_{1,2} = \\pm \\sqrt{a^2 - \\frac{1}{2cs}}$.\nLet's check the stability at these points. We substitute $x^2 = a^2 - \\frac{1}{2cs}$ into the second derivative expression:\n$$\nf''(x_{1,2};s) = 2 + 4cs(3x^2 - a^2) = 2 + 4cs\\left(3\\left(a^2 - \\frac{1}{2cs}\\right) - a^2\\right)\n$$\n$$\n= 2 + 4cs\\left(3a^2 - \\frac{3}{2cs} - a^2\\right) = 2 + 4cs\\left(2a^2 - \\frac{3}{2cs}\\right) = 2 + 8csa^2 - 6 = 8csa^2 - 4 = 4(2csa^2 - 1)\n$$\nSince $s  s_\\text{crit}$, we have $2csa^2  1$, which implies $f''(x_{1,2};s)  0$.\nTherefore, for $s  s_\\text{crit}$, there are two distinct local minima.\n\nSummary for counting minima: For a given $s_j$, the number of local minima is $1$ if $s_j \\le s_\\text{crit}$ and $2$ if $s_j  s_\\text{crit}$.\n\n**Part 3  4: Numerical Simulation**\n\nThe remaining tasks involve numerical simulation.\nA gradient descent algorithm will be implemented with the update rule $x_{k+1} = x_k - \\eta f'(x_k; s)$. The specified hyperparameters are step size $\\eta=0.02$, maximum iterations $N_{\\max}=50000$, and termination based on step size change ($\\lvert x_{k+1} - x_k \\rvert  10^{-10}$) or gradient magnitude ($\\lvert f'(x_k; s) \\rvert  10^{-8}$).\n\nFor the continuation (warm-start) strategy:\n- Begin with $x_0 = 0.05$ at $s_0=0.0$.\n- For each subsequent schedule step $s_j$, the starting point is the converged point from the previous step $s_{j-1}$, perturbed by a small amount $\\delta=10^{-6}$ away from the origin. The function $\\operatorname{sgn}_+(x)$ provides the direction for this perturbation. This ensures that if the algorithm is at an unstable fixed point like $x=0$ post-bifurcation, it is pushed into a basin of attraction of a stable minimum.\n- The final result is the sign of the converged point at $s_4=1.0$, determined by the $\\text{sign\\_int}$ function.\n\nFor the multi-start (cold-start) strategy:\n- At the final schedule value $s_4 = 1.0$, gradient descent is run from a set of predefined starting points $X_\\text{seeds}$.\n- The converged points are collected and clustered. The number of clusters corresponds to the number of distinct local minima found by the search. Clustering is done by merging points within an absolute distance of $10^{-3}$.\n\nThese numerical procedures will be implemented for each of the three test cases $(a,c)$. The analytical formulas for $s_\\text{crit}$ and the number of minima will be used in conjunction with the numerical results to form the final output.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef gradient_descent(a, c, s, x0):\n    \"\"\"\n    Performs gradient descent on the objective function f(x;s).\n    \"\"\"\n    eta = 0.02\n    max_iter = 50000\n    tol_step = 1e-10\n    tol_grad = 1e-8\n    \n    x = float(x0)\n    \n    for _ in range(max_iter):\n        # f'(x;s) = 2x + 4cs(x^3 - a^2*x)\n        grad = 2.0 * x + 4.0 * c * s * (x**3 - (a**2) * x)\n        \n        if abs(grad)  tol_grad:\n            break\n            \n        x_new = x - eta * grad\n        \n        if abs(x_new - x)  tol_step:\n            x = x_new\n            break\n        \n        x = x_new\n        \n    return x\n\ndef solve():\n    \"\"\"\n    Main function to solve the problem for all test cases.\n    \"\"\"\n    test_cases = [\n        (1.0, 0.3),  # Test case 1: a, c\n        (1.0, 1.5),  # Test case 2: a, c\n        (0.7, 5.0)   # Test case 3: a, c\n    ]\n\n    S = [0.0, 0.2, 0.5, 0.8, 1.0]\n    all_results = []\n\n    for a, c in test_cases:\n        # 1) Compute s_crit\n        s_crit = 1.0 / (2.0 * c * a**2)\n        all_results.append(round(s_crit, 6))\n\n        # 2) Determine the number of distinct local minima\n        num_minima = [1 if sj = s_crit else 2 for sj in S]\n        all_results.extend(num_minima)\n        \n        # 3) Simulate continuation strategy (warm-start gradient descent)\n        x_start_warm = 0.05\n        x_conv_warm = gradient_descent(a, c, S[0], x_start_warm)\n        \n        delta = 1e-6\n        for j in range(1, len(S)):\n            sj = S[j]\n            # sgn_+(x) = 1 if x = 0, -1 if x  0\n            sgn_plus = 1.0 if x_conv_warm = 0.0 else -1.0\n            x_start_warm = x_conv_warm + delta * sgn_plus\n            x_conv_warm = gradient_descent(a, c, sj, x_start_warm)\n        \n        # At the final schedule s_4 = 1.0, report the integer sign\n        sign_threshold = 1e-6\n        if x_conv_warm  sign_threshold:\n            warm_start_sign = 1\n        elif x_conv_warm  -sign_threshold:\n            warm_start_sign = -1\n        else:\n            warm_start_sign = 0\n        all_results.append(warm_start_sign)\n\n        # 4) Probe landscape with cold multi-start gradient descent\n        s_final = 1.0\n        X_seeds = [-1.0, -0.5, -0.1, 0.1, 0.5, 1.0]\n        converged_points = []\n        for seed in X_seeds:\n            res = gradient_descent(a, c, s_final, seed)\n            converged_points.append(res)\n        \n        # Cluster the converged points\n        clusters = []\n        cluster_tol = 1e-3\n        if len(converged_points)  0:\n            clusters.append(converged_points[0])\n            for p in converged_points[1:]:\n                is_in_cluster = False\n                for cluster_rep in clusters:\n                    if abs(p - cluster_rep)  cluster_tol:\n                        is_in_cluster = True\n                        break\n                if not is_in_cluster:\n                    clusters.append(p)\n        num_clusters = len(clusters)\n        all_results.append(num_clusters)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, all_results))}]\")\n\nsolve()\n```", "id": "3145108"}, {"introduction": "Once a function possesses multiple minima, the challenge shifts to identifying the global optimum, especially when the search is confined to a specific domain. This practice explores this scenario within a trust-region subproblem, a cornerstone of modern optimization algorithms. You will minimize a non-convex quadratic function over a simple disk, a setting where the global minimum could lie either in the interior or on the boundary. This requires a rigorous application of the Karush-Kuhn-Tucker (KKT) conditions to analyze the boundary and second-order conditions to distinguish the true global solution from other candidate points. [@problem_id:3145064]", "problem": "Consider the quadratic form $f(x) = x^{\\top} Q x + b^{\\top} x$ where $x \\in \\mathbb{R}^{2}$, $Q \\in \\mathbb{R}^{2 \\times 2}$, and $b \\in \\mathbb{R}^{2}$ are given by\n$$\nQ = \\begin{pmatrix} 2  0 \\\\ 0  -3 \\end{pmatrix}, \\quad b = \\begin{pmatrix} 0 \\\\ -4 \\end{pmatrix}.\n$$\nThe feasible set is the trust region\n$$\n\\mathcal{B} = \\{ x \\in \\mathbb{R}^{2} \\mid \\|x\\| \\le r \\}, \\quad r = 2,\n$$\nwhere $\\|x\\|$ denotes the Euclidean norm. The matrix $Q$ is indefinite, so $f$ is nonconvex. Starting from the core definitions of local and global minimizers and the necessary optimality conditions for constrained problems (derive the Karush-Kuhn-Tucker conditions without assuming any pre-given formula), analyze the local minima of $f$ over $\\mathcal{B}$.\n\nYour analysis must:\n- Identify any unconstrained stationary point and determine whether it is a local minimizer within $\\mathcal{B}$ using second-order reasoning.\n- Derive the boundary optimality conditions implied by the trust-region constraint and solve them to find candidate local minimizers.\n- Use a rigorous argument based on well-tested facts in optimization to determine whether any local minimizer you find is also a global minimizer for the trust-region problem.\n\nCompute the exact minimal value $\\min\\{ f(x) \\mid x \\in \\mathcal{B} \\}$ and provide it as your final answer. No rounding is required. The final answer must be a single real number.", "solution": "The problem is to find the minimum of the quadratic function $f(x) = x^{\\top} Q x + b^{\\top} x$ over the feasible set $\\mathcal{B} = \\{ x \\in \\mathbb{R}^{2} \\mid \\|x\\| \\le r \\}$, which is a trust-region subproblem.\nThe given data are $x = \\begin{pmatrix} x_1 \\\\ x_2 \\end{pmatrix}$, $r=2$, and\n$$\nQ = \\begin{pmatrix} 2  0 \\\\ 0  -3 \\end{pmatrix}, \\quad b = \\begin{pmatrix} 0 \\\\ -4 \\end{pmatrix}.\n$$\nThe objective function can be written explicitly as:\n$f(x_1, x_2) = 2x_1^2 - 3x_2^2 - 4x_2$.\nThe constraint is $x_1^2 + x_2^2 \\le 4$.\nThe gradient of the objective function is:\n$$\n\\nabla f(x) = 2Qx + b = \\begin{pmatrix} 4  0 \\\\ 0  -6 \\end{pmatrix} \\begin{pmatrix} x_1 \\\\ x_2 \\end{pmatrix} + \\begin{pmatrix} 0 \\\\ -4 \\end{pmatrix} = \\begin{pmatrix} 4x_1 \\\\ -6x_2 - 4 \\end{pmatrix}.\n$$\nThe Hessian matrix of the objective function is:\n$$\n\\nabla^2 f(x) = 2Q = \\begin{pmatrix} 4  0 \\\\ 0  -6 \\end{pmatrix}.\n$$\nThe objective function $f(x)$ is continuous and the feasible set $\\mathcal{B}$ is compact (closed and bounded). By the Extreme Value Theorem, a global minimum must exist.\n\nFirst, we analyze the interior of the feasible set for unconstrained stationary points. We set the gradient of $f(x)$ to zero:\n$$\n\\nabla f(x) = \\begin{pmatrix} 4x_1 \\\\ -6x_2 - 4 \\end{pmatrix} = \\begin{pmatrix} 0 \\\\ 0 \\end{pmatrix}.\n$$\nThis yields $4x_1 = 0 \\implies x_1 = 0$ and $-6x_2 - 4 = 0 \\implies x_2 = -2/3$.\nThe unconstrained stationary point is $x_s = \\begin{pmatrix} 0 \\\\ -2/3 \\end{pmatrix}$.\nWe verify if this point is within the feasible set $\\mathcal{B}$:\n$$\n\\|x_s\\|^2 = 0^2 + (-2/3)^2 = 4/9.\n$$\nSince $4/9  r^2 = 4$, the point $x_s$ lies in the interior of $\\mathcal{B}$. To classify this stationary point, we examine the Hessian matrix $\\nabla^2 f(x) = \\text{diag}(4, -6)$. The eigenvalues of the Hessian are $\\lambda_1 = 4$ and $\\lambda_2 = -6$. Since one eigenvalue is positive and the other is negative, the Hessian is indefinite. Therefore, the stationary point $x_s$ is a saddle point, not a local minimizer. This implies that the global minimum of $f(x)$ on $\\mathcal{B}$ must lie on the boundary, $\\|x\\| = r = 2$.\n\nNext, we analyze the boundary of the feasible set. The problem becomes:\n$$\n\\min_{x_1, x_2} f(x_1, x_2) \\quad \\text{subject to} \\quad g(x_1, x_2) = x_1^2 + x_2^2 - 4 = 0.\n$$\nWe use the method of Lagrange multipliers. The Lagrangian function is:\n$$\n\\mathcal{L}(x, \\mu) = f(x) + \\mu g(x) = (2x_1^2 - 3x_2^2 - 4x_2) + \\mu(x_1^2 + x_2^2 - 4).\n$$\nFor a standard inequality constraint $g(x) \\le 0$, the Karush-Kuhn-Tucker (KKT) conditions require the multiplier $\\mu$ to be non-negative, i.e., $\\mu \\ge 0$. The KKT conditions are:\n1.  Stationarity: $\\nabla_x \\mathcal{L}(x, \\mu) = \\nabla f(x) + \\mu \\nabla g(x) = 0$.\n2.  Primal Feasibility: $x_1^2 + x_2^2 - 4 \\le 0$.\n3.  Dual Feasibility: $\\mu \\ge 0$.\n4.  Complementary Slackness: $\\mu(x_1^2 + x_2^2 - 4) = 0$.\n\nSince we are searching on the boundary, the constraint is active: $x_1^2+x_2^2=4$. The gradient of the constraint is $\\nabla g(x) = \\begin{pmatrix} 2x_1 \\\\ 2x_2 \\end{pmatrix}$. The stationarity condition gives:\n$$\n\\begin{pmatrix} 4x_1 \\\\ -6x_2 - 4 \\end{pmatrix} + \\mu \\begin{pmatrix} 2x_1 \\\\ 2x_2 \\end{pmatrix} = \\begin{pmatrix} 0 \\\\ 0 \\end{pmatrix}.\n$$\nThis leads to the system of equations:\n(a) $4x_1 + 2\\mu x_1 = 0 \\implies 2x_1(2 + \\mu) = 0$.\n(b) $-6x_2 - 4 + 2\\mu x_2 = 0 \\implies 2x_2(\\mu - 3) = 4$.\n\nFrom equation (a), since $\\mu \\ge 0$, the term $2 + \\mu$ is always positive. Thus, we must have $x_1 = 0$.\nSubstituting $x_1=0$ into the boundary constraint $x_1^2 + x_2^2 = 4$, we get $x_2^2 = 4$, which means $x_2 = 2$ or $x_2 = -2$. We examine these two cases:\n\nCase 1: $x_1=0, x_2=2$.\nSubstituting $x_2=2$ into equation (b): $2(2)(\\mu - 3) = 4 \\implies 4(\\mu - 3) = 4 \\implies \\mu - 3 = 1 \\implies \\mu = 4$.\nSince $\\mu=4 \\ge 0$, this is a valid KKT point. Let $x^{(1)} = \\begin{pmatrix} 0 \\\\ 2 \\end{pmatrix}$ with $\\mu_1 = 4$.\n\nCase 2: $x_1=0, x_2=-2$.\nSubstituting $x_2=-2$ into equation (b): $2(-2)(\\mu - 3) = 4 \\implies -4(\\mu - 3) = 4 \\implies \\mu - 3 = -1 \\implies \\mu = 2$.\nSince $\\mu=2 \\ge 0$, this is a valid KKT point. Let $x^{(2)} = \\begin{pmatrix} 0 \\\\ -2 \\end{pmatrix}$ with $\\mu_2 = 2$.\n\nWe have two candidate points on the boundary for a local minimum: $x^{(1)}=(0,2)$ and $x^{(2)}=(0,-2)$.\nTo determine if they are local minimizers, we check the second-order sufficient conditions (SOSC). For a point $x^*$ to be a strict local minimizer, we need $d^{\\top} \\nabla_{xx}^2 \\mathcal{L}(x^*, \\mu^*) d  0$ for all non-zero vectors $d$ in the critical cone. The Lagrangian Hessian is:\n$$\n\\nabla_{xx}^2 \\mathcal{L}(x, \\mu) = \\nabla^2 f(x) + \\mu \\nabla^2 g(x) = \\begin{pmatrix} 4  0 \\\\ 0  -6 \\end{pmatrix} + \\mu \\begin{pmatrix} 2  0 \\\\ 0  2 \\end{pmatrix} = \\begin{pmatrix} 4+2\\mu  0 \\\\ 0  -6+2\\mu \\end{pmatrix}.\n$$\nFor both points, since $\\mu0$, the critical cone is the tangent space to the constraint: $\\{d \\mid \\nabla g(x^*)^\\top d = 0\\}$.\nFor $x^{(1)}=(0,2)$, $\\nabla g(x^{(1)}) = (0,4)^\\top$. The tangent space is $d=(d_1, 0)^\\top$ with $d_1 \\ne 0$. The Lagrangian Hessian is $\\nabla_{xx}^2 \\mathcal{L}(x^{(1)}, 4) = \\text{diag}(12, 2)$. Thus, $d^\\top \\nabla_{xx}^2 \\mathcal{L} d = 12 d_1^2  0$. So $x^{(1)}$ is a strict local minimizer.\nFor $x^{(2)}=(0,-2)$, $\\nabla g(x^{(2)}) = (0,-4)^\\top$. The tangent space is also $d=(d_1, 0)^\\top$ with $d_1 \\ne 0$. The Lagrangian Hessian is $\\nabla_{xx}^2 \\mathcal{L}(x^{(2)}, 2) = \\text{diag}(8, -2)$. Thus, $d^\\top \\nabla_{xx}^2 \\mathcal{L} d = 8 d_1^2  0$. So $x^{(2)}$ is also a strict local minimizer.\n\nSo we have found two local minimizers: $(0,2)$ and $(0,-2)$. To find the global minimum, we can evaluate the objective function at these points:\n$$\nf(x^{(1)}) = f(0, 2) = 2(0)^2 - 3(2)^2 - 4(2) = -12 - 8 = -20.\n$$\n$$\nf(x^{(2)}) = f(0, -2) = 2(0)^2 - 3(-2)^2 - 4(-2) = -12 + 8 = -4.\n$$\nComparing these values, the minimum value is $-20$, which occurs at $x^{(1)}=(0,2)$.\n\nA more rigorous argument for global optimality comes from the specific theory of trust-region problems. A point $x^*$ is a global minimizer of this problem if and only if it satisfies the KKT conditions for some $\\mu \\ge 0$, and the Lagrangian Hessian, $\\nabla_{xx}^2 \\mathcal{L}(x^*, \\mu) = 2Q+2\\mu I$, is positive semi-definite.\nThe matrix is $\\begin{pmatrix} 4+2\\mu  0 \\\\ 0  -6+2\\mu \\end{pmatrix}$. For it to be positive semi-definite, both of its eigenvalues must be non-negative:\n$4+2\\mu \\ge 0 \\implies \\mu \\ge -2$.\n$-6+2\\mu \\ge 0 \\implies \\mu \\ge 3$.\nBoth conditions require $\\mu \\ge 3$.\n\nNow we check our candidate points against this global optimality condition:\n-   For $x^{(1)}=(0,2)$, the multiplier is $\\mu_1 = 4$. Since $4 \\ge 3$, this point satisfies the necessary and sufficient conditions for a global minimum.\n-   For $x^{(2)}=(0,-2)$, the multiplier is $\\mu_2 = 2$. Since $2  3$, this point does not satisfy the necessary condition for a global minimum. Although it is a local minimum, it cannot be the global one.\n\nThis confirms that $x^* = (0,2)$ is the unique global minimizer. The minimum value of the function $f(x)$ on the set $\\mathcal{B}$ is $f(0,2)$.\n$$\n\\min_{x \\in \\mathcal{B}} f(x) = f(0, 2) = -20.\n$$", "answer": "$$\\boxed{-20}$$", "id": "3145064"}, {"introduction": "While analytical tools like the KKT conditions are powerful, many real-world optimization problems are too complex for such a detailed analysis. For these \"black-box\" functions, we often turn to heuristic strategies. This hands-on practice introduces one of the most intuitive and widely used global optimization heuristics: the multistart method. By repeatedly launching a local optimization algorithm from different random starting points on the famous Himmelblau function, you will empirically map its basins of attraction and estimate the probability of finding a global minimum, providing a practical perspective on tackling complex, non-convex landscapes. [@problem_id:3145095]", "problem": "Consider the function $f:\\mathbb{R}^2\\to\\mathbb{R}$ defined by the Himmelblau function $f(x,y) = (x^2 + y - 11)^2 + (x + y^2 - 7)^2$. You will design and analyze a multistart local optimization scheme to empirically quantify the probability of reaching a global minimum from random initializations.\n\nFundamental base and definitions:\n- A point $(x^\\star,y^\\star)$ is a local minimizer if there exists a neighborhood $\\mathcal{N}$ of $(x^\\star,y^\\star)$ such that $f(x^\\star,y^\\star)\\le f(x,y)$ for all $(x,y)\\in\\mathcal{N}$.\n- A point $(x^\\star,y^\\star)$ is a global minimizer if $f(x^\\star,y^\\star)\\le f(x,y)$ for all $(x,y)\\in\\mathbb{R}^2$.\n- Because $f(x,y)$ is a sum of squares, it satisfies $f(x,y)\\ge 0$ for all $(x,y)\\in\\mathbb{R}^2$, and any point where both squared terms are simultaneously zero yields a global minimum with value $0$.\n\nTask:\n- Implement a multistart scheme that performs the following steps:\n  1. Draw $N$ independent starting points $(x_0,y_0)$ from a uniform distribution over a given axis-aligned rectangle $[a_x,b_x]\\times[a_y,b_y]$.\n  2. From each start $(x_0,y_0)$, run a deterministic local solver based on first-order calculus (for example, the Broyden–Fletcher–Goldfarb–Shanno (BFGS) method) using the analytic gradient of $f(x,y)$ derived from the product and chain rules of differentiation.\n  3. For a numerical tolerance $\\varepsilon_f0$, declare a “success” if the terminal point $(\\hat x,\\hat y)$ produced by the local solver satisfies $f(\\hat x,\\hat y)\\le \\varepsilon_f$. Otherwise, declare a “failure.”\n  4. Estimate the probability $p$ of reaching a global minimum under the specified random initialization by the Monte Carlo estimator $\\hat p = \\frac{1}{N}\\sum_{i=1}^{N} I_i$, where $I_i$ is the indicator of success for the $i$-th run.\n- Use the same solver hyperparameters for all runs within a test case, including a maximum iteration count.\n\nAngle units are not involved. No physical units are involved. All probabilities must be reported as decimal numbers in $[0,1]$.\n\nTest suite (all random draws must be uniform and reproducible via the given seeds):\n- Case $1$ (happy path, broad domain, ample iterations): $N=200$, $\\text{seed}=7$, $[a_x,b_x]=[-6,6]$, $[a_y,b_y]=[-6,6]$, $\\varepsilon_f=10^{-6}$, maximum iterations $=200$.\n- Case $2$ (small-sample boundary): $N=10$, $\\text{seed}=11$, $[a_x,b_x]=[-6,6]$, $[a_y,b_y]=[-6,6]$, $\\varepsilon_f=10^{-6}$, maximum iterations $=200$.\n- Case $3$ (domain concentrated near a single basin): $N=100$, $\\text{seed}=23$, $[a_x,b_x]=[2.5,3.5]$, $[a_y,b_y]=[1.5,2.5]$, $\\varepsilon_f=10^{-6}$, maximum iterations $=50$.\n- Case $4$ (stress test with very few iterations): $N=200$, $\\text{seed}=31$, $[a_x,b_x]=[-6,6]$, $[a_y,b_y]=[-6,6]$, $\\varepsilon_f=10^{-6}$, maximum iterations $=5$.\n\nRequired output:\n- Your program must implement the scheme above using the analytic gradient of $f(x,y)$, the Broyden–Fletcher–Goldfarb–Shanno method, and the specified parameters for each case.\n- For each case, output the estimated probability $\\hat p$ as a floating-point number. The final output must be a single line containing a list of the four probabilities in the order of Cases $1$ through $4$, as a comma-separated list enclosed in square brackets (for example, $[\\hat p_1,\\hat p_2,\\hat p_3,\\hat p_4]$). The values may be printed with any reasonable fixed precision.", "solution": "The problem requires the implementation and analysis of a multistart optimization scheme to estimate the probability of finding a global minimum of the Himmelblau function, $f(x,y)$. The validation of the problem statement confirms that it is scientifically grounded, well-posed, objective, and contains all necessary information for a computational solution. The problem is valid.\n\nThe function to be minimized is the Himmelblau function, defined as $f:\\mathbb{R}^2 \\to \\mathbb{R}$:\n$$f(x,y) = (x^2 + y - 11)^2 + (x + y^2 - 7)^2$$\nThis function is a sum of two squared terms. Its value is always non-negative, i.e., $f(x,y) \\ge 0$ for all $(x,y) \\in \\mathbb{R}^2$. The global minima of $f(x,y)$ are the points $(x^\\star, y^\\star)$ where $f(x^\\star, y^\\star) = 0$. This occurs if and only if both squared terms are simultaneously zero:\n\\begin{align*}\nx^2 + y - 11 = 0 \\\\\nx + y^2 - 7 = 0\n\\end{align*}\nSolving this system of non-linear equations reveals four distinct solutions, which are the four global minimizers of the function:\n\\begin{itemize}\n    \\item $(3, 2)$\n    \\item $(-2.805118..., 3.131312...)$\n    \\item $(-3.779310..., -3.283186...)$\n    \\item $(3.584428..., -1.848126...)$\n\\end{itemize}\nThe multistart scheme employs a local optimization algorithm, specifically the Broyden–Fletcher–Goldfarb–Shanno (BFGS) method. BFGS is a quasi-Newton method that requires the gradient of the objective function to iteratively search for a local minimum. The problem mandates the use of the analytic gradient, which we derive below.\n\nLet $u(x,y) = x^2 + y - 11$ and $v(x,y) = x + y^2 - 7$, so that $f = u^2 + v^2$. The gradient of $f$, denoted $\\nabla f(x,y)$, is a vector of its partial derivatives, $(\\frac{\\partial f}{\\partial x}, \\frac{\\partial f}{\\partial y})$. Using the chain and sum rules of differentiation:\n$$ \\frac{\\partial f}{\\partial x} = \\frac{\\partial}{\\partial x}(u^2 + v^2) = 2u \\frac{\\partial u}{\\partial x} + 2v \\frac{\\partial v}{\\partial x} $$\n$$ \\frac{\\partial f}{\\partial y} = \\frac{\\partial}{\\partial y}(u^2 + v^2) = 2u \\frac{\\partial u}{\\partial y} + 2v \\frac{\\partial v}{\\partial y} $$\nThe partial derivatives of $u(x,y)$ and $v(x,y)$ are:\n\\begin{align*}\n\\frac{\\partial u}{\\partial x} = 2x  \\frac{\\partial u}{\\partial y} = 1 \\\\\n\\frac{\\partial v}{\\partial x} = 1  \\frac{\\partial v}{\\partial y} = 2y\n\\end{align*}\nSubstituting these into the expressions for the partial derivatives of $f(x,y)$:\n\\begin{align*}\n\\frac{\\partial f}{\\partial x} = 2(x^2 + y - 11)(2x) + 2(x + y^2 - 7)(1) \\\\\n= 4x(x^2 + y - 11) + 2(x + y^2 - 7) \\\\\n\\frac{\\partial f}{\\partial y} = 2(x^2 + y - 11)(1) + 2(x + y^2 - 7)(2y) \\\\\n= 2(x^2 + y - 11) + 4y(x + y^2 - 7)\n\\end{align*}\nThe analytic gradient vector is therefore:\n$$ \\nabla f(x,y) = \\begin{pmatrix} 4x(x^2 + y - 11) + 2(x + y^2 - 7) \\\\ 2(x^2 + y - 11) + 4y(x + y^2 - 7) \\end{pmatrix} $$\nThis gradient function will be supplied to the BFGS solver for efficient convergence.\n\nThe core of the task is to implement a Monte Carlo simulation. The procedure for each test case is as follows:\n$1$. Set the random number generator seed for reproducibility. The parameters for the run are specified: the number of trials $N$, the sampling domain $[a_x,b_x]\\times[a_y,b_y]$, the success tolerance $\\varepsilon_f$, and the maximum solver iterations.\n$2$. Initialize a success counter, $S$, to $0$.\n$3$. For $i$ from $1$ to $N$:\n    a. Draw a random starting point $(x_0, y_0)$ from the uniform distribution over the specified rectangular domain, i.e., $x_0 \\sim U(a_x, b_x)$ and $y_0 \\sim U(a_y, b_y)$.\n    b. Run the BFGS algorithm starting from $(x_0, y_0)$, using the analytically derived gradient $\\nabla f$. The solver is terminated either upon convergence or after reaching the maximum number of iterations.\n    c. Let the terminal point found by the solver be $(\\hat{x}, \\hat{y})$. Evaluate the function value $f(\\hat{x}, \\hat{y})$.\n    d. If $f(\\hat{x}, \\hat{y}) \\le \\varepsilon_f$, the run is considered a \"success\", and the counter $S$ is incremented by $1$. The tolerance $\\varepsilon_f = 10^{-6}$ is sufficiently small to ensure that a successful run has terminated very close to one of the four global minima where $f=0$.\n$4$. After all $N$ trials are completed, the probability of success $p$ is estimated by the sample mean $\\hat{p} = S/N$.\n\nThis procedure is executed for each of the four test cases provided, yielding four probability estimates: $\\hat{p}_1, \\hat{p}_2, \\hat{p}_3, \\hat{p}_4$.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.optimize import minimize\n\ndef solve():\n    \"\"\"\n    Implements a multistart optimization scheme to estimate the probability of\n    finding a global minimum of the Himmelblau function for four test cases.\n    \"\"\"\n\n    # Define the Himmelblau function f(p) where p = [x, y]\n    def himmelblau_func(p):\n        x, y = p\n        term1 = x**2 + y - 11\n        term2 = x + y**2 - 7\n        return term1**2 + term2**2\n\n    # Define the analytic gradient of the Himmelblau function\n    def himmelblau_grad(p):\n        x, y = p\n        # Partial derivative with respect to x\n        df_dx = 4 * x * (x**2 + y - 11) + 2 * (x + y**2 - 7)\n        # Partial derivative with respect to y\n        df_dy = 2 * (x**2 + y - 11) + 4 * y * (x + y**2 - 7)\n        return np.array([df_dx, df_dy])\n\n    # Test suite parameters\n    test_cases = [\n        # Case 1: N=200, seed=7, [-6,6]x[-6,6], eps=1e-6, max_iter=200\n        {'N': 200, 'seed': 7, 'domain_x': [-6, 6], 'domain_y': [-6, 6], 'eps_f': 1e-6, 'max_iter': 200},\n        # Case 2: N=10, seed=11, [-6,6]x[-6,6], eps=1e-6, max_iter=200\n        {'N': 10, 'seed': 11, 'domain_x': [-6, 6], 'domain_y': [-6, 6], 'eps_f': 1e-6, 'max_iter': 200},\n        # Case 3: N=100, seed=23, [2.5,3.5]x[1.5,2.5], eps=1e-6, max_iter=50\n        {'N': 100, 'seed': 23, 'domain_x': [2.5, 3.5], 'domain_y': [1.5, 2.5], 'eps_f': 1e-6, 'max_iter': 50},\n        # Case 4: N=200, seed=31, [-6,6]x[-6,6], eps=1e-6, max_iter=5\n        {'N': 200, 'seed': 31, 'domain_x': [-6, 6], 'domain_y': [-6, 6], 'eps_f': 1e-6, 'max_iter': 5},\n    ]\n\n    results = []\n    \n    for case in test_cases:\n        N = case['N']\n        seed = case['seed']\n        ax, bx = case['domain_x']\n        ay, by = case['domain_y']\n        eps_f = case['eps_f']\n        max_iter = case['max_iter']\n\n        # Set up a random number generator with the specified seed for reproducibility\n        rng = np.random.default_rng(seed)\n\n        success_count = 0\n        for _ in range(N):\n            # 1. Draw a random starting point from the uniform distribution\n            x0 = rng.uniform(ax, bx)\n            y0 = rng.uniform(ay, by)\n            initial_guess = np.array([x0, y0])\n\n            # 2. Run the BFGS local solver\n            res = minimize(\n                himmelblau_func,\n                initial_guess,\n                method='BFGS',\n                jac=himmelblau_grad,\n                options={'maxiter': max_iter}\n            )\n\n            # 3. Check for success\n            if res.fun = eps_f:\n                success_count += 1\n        \n        # 4. Estimate the probability\n        p_hat = success_count / N\n        results.append(p_hat)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "3145095"}]}