{"hands_on_practices": [{"introduction": "The most intuitive optimization algorithm is to always move in the direction of steepest descent. While this guarantees progress, its performance can be surprisingly poor on certain problems whose objective functions form narrow, elongated valleys. This practice [@problem_id:3195724] guides you through creating such a scenario to expose this weakness, and then compares steepest descent to the more powerful Conjugate Gradient method, revealing fundamental insights into algorithmic efficiency.", "problem": "Consider unconstrained minimization of a strictly convex quadratic function $f:\\mathbb{R}^n\\to\\mathbb{R}$ defined by $f(x)=\\tfrac{1}{2}x^\\top Q x - b^\\top x$, where $Q\\in\\mathbb{R}^{n\\times n}$ is symmetric positive definite and $b\\in\\mathbb{R}^n$. The gradient is $\\nabla f(x)=Qx-b$, and the unique minimizer $x^\\star$ satisfies $Qx^\\star=b$. Two iterative methods are to be compared on this class of problems:\n\n- Steepest descent with exact line search, where one iteratively updates $x_{k+1}=x_k+\\alpha_k d_k$ with $d_k=-\\nabla f(x_k)$ and chooses the step length $\\alpha_k$ by minimizing $\\phi(\\alpha)=f(x_k+\\alpha d_k)$ over $\\alpha\\in\\mathbb{R}$.\n- Conjugate Gradient (CG), which solves the linear system $Qx=b$ by iteratively generating $Q$-conjugate directions.\n\nDesign and implement a numerical experiment that exposes a counterexample scenario where steepest descent with exact line search produces a zig-zag in narrow valleys, and compare its behavior against Conjugate Gradient on matrices with elongated eigenstructure. Use two-dimensional cases ($n=2$) with $Q$ constructed from a rotation and diagonal eigenvalues to model narrow, rotated valleys, namely $Q=R(\\theta)^\\top \\operatorname{diag}(\\lambda_1,\\lambda_2) R(\\theta)$, where $R(\\theta)$ is the rotation matrix by angle $\\theta$.\n\nFundamental base to use:\n- The definition of the gradient for differentiable functions, $\\nabla f(x)$, and the characterization of the minimizer of a strictly convex quadratic via $Qx^\\star=b$.\n- Exact line search defined by minimizing along the current search direction.\n- The concept of symmetric positive definiteness and eigenstructure of $Q$.\n\nImplement both methods and, for steepest descent with exact line search, measure the angle between the first two step directions $d_0$ and $d_1$ expressed in degrees. If the method converges in fewer than two iterations, report the angle as $0.0$ degrees. Use the Euclidean inner product and norm. The angle must be reported in degrees.\n\nTest suite specification (each case yields a distinct matrix with elongated eigenstructure):\n- Case 1 (happy path, rotated narrow valley): $\\lambda_1=1$, $\\lambda_2=1000$, $\\theta=30$ degrees, $b=\\begin{bmatrix}1\\\\-1\\end{bmatrix}$, $x_0=\\begin{bmatrix}2\\\\2\\end{bmatrix}$, tolerance $\\varepsilon=10^{-10}$, maximum iterations $10^4$ for steepest descent and $10^2$ for Conjugate Gradient.\n- Case 2 (boundary alignment, narrow valley aligned with axes): $\\lambda_1=1$, $\\lambda_2=1000$, $\\theta=0$ degrees, $b=\\begin{bmatrix}1\\\\0.5\\end{bmatrix}$, $x_0=\\begin{bmatrix}-3\\\\3\\end{bmatrix}$, tolerance $\\varepsilon=10^{-10}$, maximum iterations $10^4$ for steepest descent and $10^2$ for Conjugate Gradient.\n- Case 3 (edge case, extremely elongated and rotated): $\\lambda_1=1$, $\\lambda_2=10^6$, $\\theta=45$ degrees, $b=\\begin{bmatrix}0.5\\\\-0.5\\end{bmatrix}$, $x_0=\\begin{bmatrix}1\\\\-1\\end{bmatrix}$, tolerance $\\varepsilon=10^{-10}$, maximum iterations $10^4$ for steepest descent and $10^2$ for Conjugate Gradient.\n\nFor each test case, compute and report:\n1. The integer number of iterations required by steepest descent with exact line search to attain $\\lVert \\nabla f(x_k)\\rVert_2\\le\\varepsilon$, or the maximum iteration count if not attained.\n2. The integer number of iterations required by Conjugate Gradient to attain $\\lVert b-Qx_k\\rVert_2\\le\\varepsilon$, or the maximum iteration count if not attained.\n3. The angle between the first two steepest descent steps $d_0$ and $d_1$ in degrees as a float; if fewer than two steps occurred, report $0.0$ degrees.\n4. A boolean indicating whether steepest descent required strictly more iterations than Conjugate Gradient.\n\nYour program should produce a single line of output containing the results aggregated across the three test cases as a comma-separated list enclosed in square brackets. The order must be:\n$[k_{\\text{SD},1},k_{\\text{CG},1},\\alpha_{1},\\text{bool}_1,k_{\\text{SD},2},k_{\\text{CG},2},\\alpha_{2},\\text{bool}_2,k_{\\text{SD},3},k_{\\text{CG},3},\\alpha_{3},\\text{bool}_3]$,\nwhere $k_{\\text{SD},i}$ and $k_{\\text{CG},i}$ are the iteration counts for steepest descent and Conjugate Gradient on case $i$, $\\alpha_i$ is the angle in degrees for case $i$, and $\\text{bool}_i$ is the corresponding boolean. Angles must be expressed in degrees. No percentages or other units appear in the output.", "solution": "The user has provided a valid problem statement.\n\n### Problem Validation\n\n**Step 1: Extract Givens**\n- **Objective Function**: Unconstrained minimization of $f:\\mathbb{R}^n\\to\\mathbb{R}$, defined by $f(x)=\\tfrac{1}{2}x^\\top Q x - b^\\top x$.\n- **Matrix Q**: $Q\\in\\mathbb{R}^{n\\times n}$ is symmetric positive definite (SPD).\n- **Gradient**: $\\nabla f(x)=Qx-b$.\n- **Minimizer Condition**: The unique minimizer $x^\\star$ satisfies $Qx^\\star=b$.\n- **Method 1: Steepest Descent (SD) with Exact Line Search**:\n    - Update rule: $x_{k+1}=x_k+\\alpha_k d_k$.\n    - Search direction: $d_k=-\\nabla f(x_k)$.\n    - Step length $\\alpha_k$: chosen to minimize $\\phi(\\alpha)=f(x_k+\\alpha d_k)$ over $\\alpha\\in\\mathbb{R}$.\n- **Method 2: Conjugate Gradient (CG)**:\n    - An iterative method for solving the linear system $Qx=b$.\n- **Experiment Setup**:\n    - Dimension: $n=2$.\n    - Matrix construction: $Q=R(\\theta)^\\top \\operatorname{diag}(\\lambda_1,\\lambda_2) R(\\theta)$, where $R(\\theta)$ is the rotation matrix.\n- **Metrics to Report**:\n    1. Integer number of iterations for SD ($k_{SD}$) to reach $\\lVert \\nabla f(x_k)\\rVert_2\\le\\varepsilon$.\n    2. Integer number of iterations for CG ($k_{CG}$) to reach $\\lVert b-Qx_k\\rVert_2\\le\\varepsilon$.\n    3. Angle in degrees (float) between the first two SD step directions, $d_0$ and $d_1$. Report $0.0$ if fewer than two iterations occur.\n    4. A boolean indicating if $k_{SD}  k_{CG}$.\n- **Test Suite**:\n    - **Case 1**: $\\lambda_1=1$, $\\lambda_2=1000$, $\\theta=30^\\circ$, $b=\\begin{bmatrix}1\\\\-1\\end{bmatrix}$, $x_0=\\begin{bmatrix}2\\\\2\\end{bmatrix}$, $\\varepsilon=10^{-10}$, $max\\_iter_{SD}=10^4$, $max\\_iter_{CG}=10^2$.\n    - **Case 2**: $\\lambda_1=1$, $\\lambda_2=1000$, $\\theta=0^\\circ$, $b=\\begin{bmatrix}1\\\\0.5\\end{bmatrix}$, $x_0=\\begin{bmatrix}-3\\\\3\\end{bmatrix}$, $\\varepsilon=10^{-10}$, $max\\_iter_{SD}=10^4$, $max\\_iter_{CG}=10^2$.\n    - **Case 3**: $\\lambda_1=1$, $\\lambda_2=10^6$, $\\theta=45^\\circ$, $b=\\begin{bmatrix}0.5\\\\-0.5\\end{bmatrix}$, $x_0=\\begin{bmatrix}1\\\\-1\\end{bmatrix}$, $\\varepsilon=10^{-10}$, $max\\_iter_{SD}=10^4$, $max\\_iter_{CG}=10^2$.\n- **Output Format**: A single line `[k_SD,1,k_CG,1,angle_1,bool_1,k_SD,2,k_CG,2,angle_2,bool_2,k_SD,3,k_CG,3,angle_3,bool_3]`.\n\n**Step 2: Validate Using Extracted Givens**\n- **Scientific Groundedness**: The problem is fundamentally sound. It involves standard, well-established algorithms (Steepest Descent, Conjugate Gradient) from numerical optimization applied to a classic quadratic minimization problem. The mathematical framework is entirely correct.\n- **Well-Posedness**: The function $f(x)$ is strictly convex due to $Q$ being SPD, which guarantees a unique minimizer exists. The algorithms are deterministic and well-defined. A solution to the described numerical experiment is guaranteed to exist.\n- **Objectivity**: The problem is stated using precise, objective mathematical language. All parameters are specified numerically, leaving no room for subjective interpretation.\n- **Completeness**: All necessary components are provided: the objective function, algorithm definitions, matrix construction, termination criteria, initial conditions, and specific test parameters.\n- **Feasibility**: The numerical values are well within the range of standard floating-point arithmetic. The experiment is designed to be computationally feasible.\n- **Structure**: The problem is clearly structured as a comparative numerical experiment.\n\n**Step 3: Verdict and Action**\nThe problem is valid. We proceed with the solution.\n\n### Algorithmic Design and Principles\n\nThe problem requires the implementation and comparison of two fundamental optimization algorithms for minimizing a strictly convex quadratic function $f(x) = \\frac{1}{2}x^\\top Q x - b^\\top x$. The gradient of this function is $\\nabla f(x) = Qx - b$, and the global minimum $x^\\star$ is found by solving the linear system $\\nabla f(x^\\star) = 0$, which is equivalent to $Qx^\\star = b$. The stopping condition for both methods, $\\lVert Qx_k - b \\rVert_2 \\le \\varepsilon$ or $\\lVert b - Qx_k \\rVert_2 \\le \\varepsilon$, is based on the norm of the gradient at iterate $x_k$.\n\n**1. Steepest Descent with Exact Line Search**\n\nThe steepest descent method iteratively moves in the direction of the negative gradient, which is the direction of the steepest local decrease of the function.\nThe update rule is given by:\n$$x_{k+1} = x_k + \\alpha_k d_k$$\nwhere the search direction is $d_k = -\\nabla f(x_k) = b - Qx_k$.\n\nThe step length $\\alpha_k$ is chosen by an exact line search, meaning we find the $\\alpha \\ge 0$ that minimizes the one-dimensional function $\\phi(\\alpha) = f(x_k + \\alpha d_k)$.\n$$ \\phi(\\alpha) = \\frac{1}{2}(x_k + \\alpha d_k)^\\top Q (x_k + \\alpha d_k) - b^\\top(x_k + \\alpha d_k) $$\nTo find the minimum, we set the derivative with respect to $\\alpha$ to zero:\n$$ \\phi'(\\alpha) = (Q(x_k + \\alpha d_k) - b)^\\top d_k = (Qx_k - b + \\alpha Q d_k)^\\top d_k = 0 $$\n$$ (\\nabla f(x_k) + \\alpha Q d_k)^\\top d_k = 0 $$\nSubstituting $d_k = -\\nabla f(x_k)$:\n$$ (\\nabla f(x_k) - \\alpha Q \\nabla f(x_k))^\\top (-\\nabla f(x_k)) = 0 $$\nThis simplifies to $-\\nabla f(x_k)^\\top \\nabla f(x_k) + \\alpha \\nabla f(x_k)^\\top Q \\nabla f(x_k) = 0$. Solving for $\\alpha_k$ yields:\n$$ \\alpha_k = \\frac{\\nabla f(x_k)^\\top \\nabla f(x_k)}{\\nabla f(x_k)^\\top Q \\nabla f(x_k)} $$\nSince $Q$ is SPD, the denominator is positive, ensuring $\\alpha_k  0$ unless $\\nabla f(x_k) = 0$.\n\nA key property of exact line search on any differentiable function is that the gradient at the new point is orthogonal to the search direction used to reach it, i.e., $\\nabla f(x_{k+1})^\\top d_k = 0$. For steepest descent, this means $\\nabla f(x_{k+1})^\\top \\nabla f(x_k) = 0$. This orthogonality of successive gradients leads to the characteristic \"zig-zag\" behavior in narrow valleys (corresponding to ill-conditioned matrices $Q$), causing slow convergence.\n\n**2. Conjugate Gradient (CG) Method**\n\nThe CG method is a more sophisticated algorithm for solving $Qx=b$. Instead of repeatedly using the steepest descent direction, it constructs a sequence of $Q$-orthogonal (or \"conjugate\") search directions $p_0, p_1, \\dots$. This property ensures that, in exact arithmetic, the minimum of an $n$-dimensional quadratic is found in at most $n$ iterations.\n\nThe algorithm is as follows:\n1. Initialize: $x_0$, $r_0 = b - Qx_0$, $p_0 = r_0$, $k=0$.\n2. Iterate until convergence:\n   a. Compute step length: $\\alpha_k = \\frac{r_k^\\top r_k}{p_k^\\top Q p_k}$.\n   b. Update solution: $x_{k+1} = x_k + \\alpha_k p_k$.\n   c. Update residual: $r_{k+1} = r_k - \\alpha_k Q p_k$.\n   d. Compute improvement factor for the next direction: $\\beta_{k+1} = \\frac{r_{k+1}^\\top r_{k+1}}{r_k^\\top r_k}$.\n   e. Update search direction: $p_{k+1} = r_{k+1} + \\beta_{k+1} p_k$.\n   f. Increment $k$.\n\nCG avoids the zig-zagging of steepest descent by ensuring that each new direction $p_{k+1}$ corrects for disadvantageous components introduced by previous steps, leading to much faster convergence on ill-conditioned problems.\n\n**3. Experimental Measurement**\n\nThe numerical experiment is designed to highlight this performance difference.\n- **Matrix Construction**: The matrix $Q = R(\\theta)^\\top D R(\\theta)$ where $D=\\operatorname{diag}(\\lambda_1, \\lambda_2)$ defines the Hessian of the quadratic. The eigenvalues of $Q$ are $\\lambda_1, \\lambda_2$. The condition number $\\kappa(Q) = \\lambda_{max}/\\lambda_{min}$ quantifies how \"stretched\" the level sets of $f(x)$ are. A large condition number implies a narrow valley, where steepest descent struggles. The rotation matrix $R(\\theta)$ orients this valley in the plane.\n- **Angle Measurement**: We measure the angle $\\psi$ between the first two steepest descent directions, $d_0 = -\\nabla f(x_0)$ and $d_1 = -\\nabla f(x_1)$. A value close to $90^\\circ$ is a direct confirmation of the zig-zag behavior. The angle is calculated via the dot product:\n$$ \\psi = \\arccos\\left(\\frac{d_0^\\top d_1}{\\lVert d_0 \\rVert_2 \\lVert d_1 \\rVert_2}\\right) $$\nThe result is converted from radians to degrees. If the algorithm converges in fewer than two steps (i.e., at $k=0$ or $k=1$), it means $d_1$ is not computed, and the angle is reported as $0.0$.", "answer": "```python\nimport numpy as np\n\ndef steepest_descent(Q, b, x0, tol, max_iter):\n    \"\"\"\n    Solves min(0.5*x.T*Q*x - b.T*x) using steepest descent with exact line search.\n\n    Returns:\n        k (int): Number of iterations.\n        d_hist (list): History of the first two search directions.\n    \"\"\"\n    x = x0.copy()\n    d_hist = []\n\n    for k in range(max_iter + 1):\n        grad = Q @ x - b\n        grad_norm = np.linalg.norm(grad)\n\n        if grad_norm = tol:\n            return k, d_hist\n\n        if k == max_iter:\n            break\n\n        # Store the first two non-zero search directions\n        if k  2 and grad_norm  1e-15: # Avoid storing near-zero vectors\n            d_hist.append(-grad)\n\n        # Exact line search for quadratic function\n        alpha = (grad.T @ grad) / (grad.T @ Q @ grad)\n        \n        # Update step\n        x = x - alpha * grad\n        \n    return max_iter, d_hist\n\ndef conjugate_gradient(Q, b, x0, tol, max_iter):\n    \"\"\"\n    Solves Qx=b using the Conjugate Gradient method.\n\n    Returns:\n        k (int): Number of iterations.\n    \"\"\"\n    x = x0.copy()\n    r = b - Q @ x\n    \n    # Check initial guess\n    if np.linalg.norm(r) = tol:\n        return 0\n    \n    p = r.copy()\n    rs_old = r.T @ r\n\n    # CG algorithm allows at most n iterations for an n x n system\n    # We loop for max_iter, which might be less than n=2.\n    for k in range(max_iter):\n        Ap = Q @ p\n        alpha = rs_old / (p.T @ Ap)\n        \n        x = x + alpha * p\n        r = r - alpha * Ap\n\n        if np.linalg.norm(r) = tol:\n            return k + 1\n            \n        rs_new = r.T @ r\n        # Fletcher-Reeves update for beta\n        beta = rs_new / rs_old\n        p = r + beta * p\n        rs_old = rs_new\n        \n    return max_iter\n\ndef solve():\n    \"\"\"\n    Main function to run the numerical experiment and print results.\n    \"\"\"\n    test_cases = [\n        # Case 1: Rotated narrow valley\n        {'lambda1': 1.0, 'lambda2': 1000.0, 'theta_deg': 30.0, \n         'b': np.array([1.0, -1.0]), 'x0': np.array([2.0, 2.0]), \n         'tol': 1e-10, 'max_iter_sd': 10000, 'max_iter_cg': 100},\n        # Case 2: Axis-aligned narrow valley\n        {'lambda1': 1.0, 'lambda2': 1000.0, 'theta_deg': 0.0, \n         'b': np.array([1.0, 0.5]), 'x0': np.array([-3.0, 3.0]), \n         'tol': 1e-10, 'max_iter_sd': 10000, 'max_iter_cg': 100},\n        # Case 3: Extremely elongated and rotated\n        {'lambda1': 1.0, 'lambda2': 1e6, 'theta_deg': 45.0, \n         'b': np.array([0.5, -0.5]), 'x0': np.array([1.0, -1.0]), \n         'tol': 1e-10, 'max_iter_sd': 10000, 'max_iter_cg': 100},\n    ]\n\n    all_results = []\n\n    for case in test_cases:\n        # Unpack case parameters\n        l1, l2 = case['lambda1'], case['lambda2']\n        theta_rad = np.deg2rad(case['theta_deg'])\n        b, x0 = case['b'], case['x0']\n        tol = case['tol']\n        max_iter_sd, max_iter_cg = case['max_iter_sd'], case['max_iter_cg']\n\n        # Construct matrix Q\n        c, s = np.cos(theta_rad), np.sin(theta_rad)\n        R = np.array([[c, -s], [s, c]])\n        D = np.diag([l1, l2])\n        Q = R.T @ D @ R\n\n        # Run Steepest Descent\n        k_sd, d_hist = steepest_descent(Q, b, x0, tol, max_iter_sd)\n        \n        # Run Conjugate Gradient\n        k_cg = conjugate_gradient(Q, b, x0, tol, max_iter_cg)\n\n        # Calculate angle between first two SD steps\n        angle_deg = 0.0\n        if len(d_hist) = 2:\n            d0, d1 = d_hist[0], d_hist[1]\n            cos_angle = (d0.T @ d1) / (np.linalg.norm(d0) * np.linalg.norm(d1))\n            # Clip to handle potential floating point inaccuracies\n            cos_angle = np.clip(cos_angle, -1.0, 1.0)\n            angle_rad = np.arccos(cos_angle)\n            angle_deg = np.rad2deg(angle_rad)\n\n        # Compare iteration counts\n        sd_slower = k_sd  k_cg\n\n        # Aggregate results for this case\n        all_results.extend([k_sd, k_cg, angle_deg, sd_slower])\n\n    # Format the final output string\n    # Booleans are automatically converted to 'True'/'False' by str()\n    # Floats and ints are converted as expected.\n    output_str = f\"[{','.join(map(str, all_results))}]\"\n    print(output_str)\n\nsolve()\n```", "id": "3195724"}, {"introduction": "When moving from unconstrained to constrained optimization, a natural idea is to adapt our existing algorithms. The projected gradient method does exactly this, combining a standard gradient descent step with a \"projection\" back onto the feasible set. This exercise [@problem_id:3195673] provides hands-on experience implementing this elegant method for box constraints ($l \\le x \\le u$) and observing how the algorithm identifies and interacts with the active boundaries of the feasible region.", "problem": "You are asked to implement and analyze the projected gradient method for a convex quadratic objective with box constraints. Consider the unconstrained least-squares objective $f:\\mathbb{R}^n\\to\\mathbb{R}$ defined by $f(x)=\\tfrac{1}{2}\\lVert A x-b\\rVert_2^2$ where $A\\in\\mathbb{R}^{m\\times n}$ and $b\\in\\mathbb{R}^m$. Impose the box constraints $l\\le x\\le u$ componentwise for given $l,u\\in\\mathbb{R}^n$ with $l_i\\le u_i$ for all indices $i$. The feasible set is the hyper-rectangle (box) $[l,u]=\\{x\\in\\mathbb{R}^n\\mid l\\le x\\le u\\}$. Use the basic facts and definitions listed below as the sole starting point.\n\nFundamental definitions to use:\n- The gradient of $f(x)=\\tfrac{1}{2}\\lVert A x-b\\rVert_2^2$ is $\\nabla f(x)=A^\\top(Ax-b)$.\n- The Euclidean projection onto the box $[l,u]$ is the componentwise clipping operator $P_{[l,u]}(y)$ with components $[P_{[l,u]}(y)]_i=\\min\\{\\max\\{y_i,l_i\\},u_i\\}$.\n- The projected gradient vector at $x$ is $g_P(x)=x-P_{[l,u]}(x-\\nabla f(x))$.\n- For the convex quadratic above, a standard Lipschitz constant of the gradient is $L=\\lVert A\\rVert_2^2$, the square of the spectral norm of $A$.\n\nTasks:\n1. Implement the projected gradient method for minimizing $f(x)$ over $[l,u]$ starting from a feasible $x^{(0)}$, using the fixed step size $\\alpha=\\tfrac{1}{L}$ with $L=\\lVert A\\rVert_2^2$. At iteration $k$, perform the update\n   $$x^{(k+1)}=P_{[l,u]}\\bigl(x^{(k)}-\\alpha\\,\\nabla f(x^{(k)})\\bigr).$$\n   Stop when the infinity norm of the projected gradient satisfies $\\lVert g_P(x^{(k)})\\rVert_\\infty\\le \\varepsilon$, where $\\varepsilon0$ is a given tolerance, or when a maximum number of iterations is reached. Use $\\varepsilon=10^{-8}$ and a maximum of $10{,}000$ iterations. Use the active-set tolerance $\\varepsilon_{\\mathrm{act}}=10^{-8}$ when comparing $x_i$ to $l_i$ or $u_i$.\n\n2. At each iteration $k$, define the active sets\n   - lower-active set $\\,\\mathcal{A}_\\ell^{(k)}=\\{\\,i\\mid x_i^{(k)}\\le l_i+\\varepsilon_{\\mathrm{act}}\\,\\}$,\n   - upper-active set $\\,\\mathcal{A}_u^{(k)}=\\{\\,i\\mid x_i^{(k)}\\ge u_i-\\varepsilon_{\\mathrm{act}}\\,\\}$.\n   Count how many times across the iterations the union of active sets changes, i.e., count the number of $k\\ge 1$ such that $(\\mathcal{A}_\\ell^{(k)}\\cup\\mathcal{A}_u^{(k)})\\neq(\\mathcal{A}_\\ell^{(k-1)}\\cup\\mathcal{A}_u^{(k-1)})$.\n\n3. For each test case below, return the following tuple of results:\n   - the final objective value $f(x^{(k)})$ rounded to $6$ decimals,\n   - the final projected gradient infinity norm $\\lVert g_P(x^{(k)})\\rVert_\\infty$ rounded to $8$ decimals,\n   - the total number of iterations executed (as an integer),\n   - the final lower-active index list (sorted in increasing order),\n   - the final upper-active index list (sorted in increasing order),\n   - the number of active-set changes (as an integer).\n   Indices are zero-based.\n\nTesting and coverage:\nUse the following five test cases, which together cover a general interior solution, solutions with lower and upper bound activity, a fixed variable where $l_i=u_i$, and a constant objective case.\n\n- Test $1$ (interior solution expected): \n  $$A=\\begin{bmatrix}20\\\\01\\end{bmatrix},\\quad b=\\begin{bmatrix}1\\\\2\\end{bmatrix},\\quad l=\\begin{bmatrix}-10\\\\-10\\end{bmatrix},\\quad u=\\begin{bmatrix}10\\\\10\\end{bmatrix},\\quad x^{(0)}=\\begin{bmatrix}0\\\\0\\end{bmatrix}.$$\n\n- Test $2$ (both lower and upper activity expected): \n  $$A=\\begin{bmatrix}10\\\\01\\end{bmatrix},\\quad b=\\begin{bmatrix}-1\\\\3\\end{bmatrix},\\quad l=\\begin{bmatrix}0\\\\0\\end{bmatrix},\\quad u=\\begin{bmatrix}2\\\\2\\end{bmatrix},\\quad x^{(0)}=\\begin{bmatrix}1\\\\1\\end{bmatrix}.$$\n\n- Test $3$ (upper activity on at least one coordinate): \n  $$A=\\begin{bmatrix}10\\\\01\\end{bmatrix},\\quad b=\\begin{bmatrix}10\\\\1\\end{bmatrix},\\quad l=\\begin{bmatrix}-5\\\\-1\\end{bmatrix},\\quad u=\\begin{bmatrix}1\\\\2\\end{bmatrix},\\quad x^{(0)}=\\begin{bmatrix}0\\\\0\\end{bmatrix}.$$\n\n- Test $4$ (fixed variable with $l_1=u_1$): \n  $$A=\\begin{bmatrix}11\\\\01\\end{bmatrix},\\quad b=\\begin{bmatrix}1\\\\0\\end{bmatrix},\\quad l=\\begin{bmatrix}0\\\\-1\\end{bmatrix},\\quad u=\\begin{bmatrix}0\\\\1\\end{bmatrix},\\quad x^{(0)}=\\begin{bmatrix}0\\\\0\\end{bmatrix}.$$\n\n- Test $5$ (constant objective; zero matrix): \n  $$A=\\begin{bmatrix}00\\\\00\\end{bmatrix},\\quad b=\\begin{bmatrix}1\\\\-2\\end{bmatrix},\\quad l=\\begin{bmatrix}-1\\\\-1\\end{bmatrix},\\quad u=\\begin{bmatrix}1\\\\1\\end{bmatrix},\\quad x^{(0)}=\\begin{bmatrix}0.25\\\\-0.5\\end{bmatrix}.$$\n\nFinal output format:\nYour program should produce a single line of output containing the results for the five tests as a comma-separated list enclosed in square brackets, where each test’s result is a list in the order specified above. The exact format must be\n$$\\bigl[\\,[f_1,\\;p_1,\\;k_1,\\;L_1,\\;U_1,\\;c_1],\\;[f_2,\\;p_2,\\;k_2,\\;L_2,\\;U_2,\\;c_2],\\;[f_3,\\;p_3,\\;k_3,\\;L_3,\\;U_3,\\;c_3],\\;[f_4,\\;p_4,\\;k_4,\\;L_4,\\;U_4,\\;c_4],\\;[f_5,\\;p_5,\\;k_5,\\;L_5,\\;U_5,\\;c_5]\\bigr],$$\nwhere $f_i$ and $p_i$ are floats rounded as specified, $k_i$ and $c_i$ are integers, and $L_i,U_i$ are lists of integers. The program must not read any input and must use the test suite above internally.", "solution": "The user has requested the implementation and analysis of the projected gradient method for a convex quadratic objective function subject to box constraints. The problem is to be validated for correctness and solvability before a solution is provided.\n\n### Problem Validation\n\n**Step 1: Extract Givens**\n\n- **Objective Function:** $f(x) = \\frac{1}{2} \\lVert A x - b \\rVert_2^2$, for $A \\in \\mathbb{R}^{m \\times n}$ and $b \\in \\mathbb{R}^m$.\n- **Constraints:** Box constraints defined by $l \\le x \\le u$ for given $l, u \\in \\mathbb{R}^n$ where $l_i \\le u_i$. The feasible set is the hyper-rectangle $[l, u]$.\n- **Gradient:** $\\nabla f(x) = A^\\top(A x - b)$.\n- **Projection Operator:** The Euclidean projection onto $[l,u]$ is $P_{[l,u]}(y)$, defined component-wise as $[P_{[l,u]}(y)]_i = \\min\\{\\max\\{y_i, l_i\\}, u_i\\}$.\n- **Projected Gradient Vector:** $g_P(x) = x - P_{[l,u]}(x - \\nabla f(x))$.\n- **Lipschitz Constant:** The Lipschitz constant of the gradient $\\nabla f(x)$ is given as $L = \\lVert A \\rVert_2^2$, where $\\lVert \\cdot \\rVert_2$ is the spectral norm.\n- **Algorithm:** The projected gradient method with update rule $x^{(k+1)} = P_{[l,u]}(x^{(k)} - \\alpha \\nabla f(x^{(k)}))$ and a fixed step size $\\alpha = \\frac{1}{L}$.\n- **Initial Point:** A feasible point $x^{(0)}$ is provided for each test case.\n- **Stopping Criteria:**\n    1.  Infinity norm of the projected gradient: $\\lVert g_P(x^{(k)}) \\rVert_\\infty \\le \\varepsilon$, with tolerance $\\varepsilon = 10^{-8}$.\n    2.  Maximum iterations: $10,000$.\n- **Active Set Definitions:** For an iterate $x^{(k)}$ and active-set tolerance $\\varepsilon_{\\mathrm{act}} = 10^{-8}$:\n    - Lower-active set: $\\mathcal{A}_\\ell^{(k)} = \\{\\,i \\mid x_i^{(k)} \\le l_i + \\varepsilon_{\\mathrm{act}}\\,\\}$.\n    - Upper-active set: $\\mathcal{A}_u^{(k)} = \\{\\,i \\mid x_i^{(k)} \\ge u_i - \\varepsilon_{\\mathrm{act}}\\,\\}$.\n- **Active Set Change Count:** The number of iterations $k \\ge 1$ for which the union of active sets changes, i.e., $(\\mathcal{A}_\\ell^{(k)} \\cup \\mathcal{A}_u^{(k)}) \\neq (\\mathcal{A}_\\ell^{(k-1)} \\cup \\mathcal{A}_u^{(k-1)})$.\n- **Test Cases:** Five specific instances of $(A, b, l, u, x^{(0)})$ are provided.\n- **Required Outputs:** For each test case, a tuple containing a specific set of six values is required, with prescribed rounding for floating-point numbers.\n\n**Step 2: Validate Using Extracted Givens**\n\n- **Scientific Grounding:** The problem is a standard instance of quadratic programming with box constraints, a fundamental topic in mathematical optimization. The objective function $f(x)$ is convex, as its Hessian $\\nabla^2 f(x) = A^\\top A$ is positive semidefinite. The feasible set $[l,u]$ is compact and convex. The projected gradient method is a well-established first-order algorithm for this class of problems. The provided definitions for the gradient, projection, and Lipschitz constant are all standard and correct.\n- **Well-Posedness:** The existence of a minimizer is guaranteed because a continuous convex function ($f(x)$) is being minimized over a non-empty compact set ($[l,u]$). The algorithm specified, using a fixed step size $\\alpha = 1/L$, is guaranteed to converge to a stationary point of the problem. Thus, a meaningful solution exists and can be found by the proposed method.\n- **Objectivity:** The problem is stated using precise, unambiguous mathematical language and definitions.\n- **Completeness and Consistency:** All necessary parameters ($A, b, l, u, x^{(0)}$), algorithmic constants ($\\varepsilon, \\varepsilon_{\\mathrm{act}}$, max iterations), and definitions are provided for each test case. The condition $l_i \\le u_i$ is stated and holds for all test data. The initial points $x^{(0)}$ are confirmed to be feasible (i.e., $l \\le x^{(0)} \\le u$), satisfying a prerequisite for the algorithm. The problem is self-contained and internally consistent.\n\n**Step 3: Verdict and Action**\n\nThe problem is **valid**. It is a well-defined, scientifically sound, and complete problem in the field of numerical optimization. We may proceed with formulating the solution.\n\n### Solution\n\nThe problem requires the implementation of the projected gradient method to solve the constrained optimization problem:\n$$ \\min_{x \\in \\mathbb{R}^n} f(x) = \\frac{1}{2} \\lVert Ax - b \\rVert_2^2 \\quad \\text{subject to} \\quad l \\le x \\le u $$\nThe method is an iterative process that generalizes the standard gradient descent algorithm to handle constraints. Each iteration consists of two main parts: a gradient descent step and a projection step.\n\n**1. Algorithm Steps**\nThe iterative update is given by:\n$$ x^{(k+1)} = P_{[l,u]}\\left(x^{(k)} - \\alpha \\nabla f(x^{(k)})\\right) $$\nwhere $k$ is the iteration index, $x^{(k)}$ is the current iterate, $\\nabla f(x^{(k)})$ is the gradient of the objective function at $x^{(k)}$, $\\alpha$ is the step size, and $P_{[l,u]}$ is the projection operator onto the feasible set.\n\n**2. Gradient Calculation**\nThe objective function is $f(x) = \\frac{1}{2}(Ax-b)^\\top(Ax-b)$. Its gradient with respect to $x$ is correctly provided as:\n$$ \\nabla f(x) = A^\\top(Ax-b) $$\n\n**3. Step Size Selection**\nFor the projected gradient method to converge with a fixed step size, $\\alpha$ must be in the range $(0, 2/L)$, where $L$ is a Lipschitz constant for the gradient $\\nabla f(x)$. The problem specifies using the step size $\\alpha = 1/L$, which is a common and safe choice that guarantees convergence. The Lipschitz constant is given as the square of the spectral norm of $A$, $L = \\lVert A \\rVert_2^2$. The spectral norm $\\lVert A \\rVert_2$ is the largest singular value of $A$. In the special case where $A=0$, the gradient is always zero, $L=0$, and the algorithm should terminate immediately as the initial point is already optimal. To handle the division by zero, we can check if $L=0$ and proceed accordingly.\n\n**4. Projection Operation**\nThe projection $P_{[l,u]}(y)$ maps a point $y \\in \\mathbb{R}^n$ to the closest point in the box $[l,u]$ with respect to the Euclidean norm. This operation can be performed component-wise:\n$$ [P_{[l,u]}(y)]_i = \\text{clip}(y_i, l_i, u_i) = \\min\\{\\max\\{y_i, l_i\\}, u_i\\} $$\n\n**5. Stopping Criterion**\nA point $x^*$ is a stationary point (and a solution to this convex problem) if and only if it satisfies the first-order optimality condition $x^* = P_{[l,u]}(x^* - \\gamma \\nabla f(x^*))$ for any $\\gamma  0$. The problem defines a projected gradient vector $g_P(x) = x - P_{[l,u]}(x - \\nabla f(x))$, which corresponds to the residual of the optimality condition for a step size of $\\gamma=1$. The algorithm terminates when the infinity norm of this vector, $\\lVert g_P(x^{(k)}) \\rVert_\\infty$, falls below a tolerance $\\varepsilon = 10^{-8}$. This condition, $g_P(x^*) = 0$, correctly identifies a stationary point.\n\n**6. Active Set Tracking**\nAt each iteration $k$, we identify the set of indices corresponding to variables that are at or near their lower or upper bounds. The union of these sets, $\\mathcal{S}^{(k)} = \\mathcal{A}_\\ell^{(k)} \\cup \\mathcal{A}_u^{(k)}$, represents the active set at iteration $k$. The number of times this set changes from one iteration to the next is counted. The implementation will maintain the active set from the previous iteration to perform this comparison.\n\n**7. Implementation Plan**\nThe overall algorithm is as follows:\nFor each test case:\n1.  Initialize $k=0$, $x = x^{(0)}$, and `active_set_changes = 0`.\n2.  Calculate $L = \\lVert A \\rVert_2^2$. If $L0$, set $\\alpha = 1/L$; otherwise, $\\alpha$ can be set to any value, as the gradient will be zero.\n3.  Compute the initial active set union $\\mathcal{S}_{\\text{prev}}$ from $x$.\n4.  Loop for $k$ from $0$ up to `max_iterations - 1`:\n    a. Calculate the gradient $\\nabla f(x) = A^\\top(Ax-b)$.\n    b. Calculate the projected gradient vector $g_P(x) = x - P_{[l,u]}(x - \\nabla f(x))$.\n    c. If $\\lVert g_P(x) \\rVert_\\infty \\le \\varepsilon$, the algorithm has converged. Break the loop.\n    d. Perform the update: $x_{\\text{next}} = P_{[l,u]}(x - \\alpha \\nabla f(x))$.\n    e. Compute the active set union for the new point, $\\mathcal{S}_{\\text{curr}}$.\n    f. If $\\mathcal{S}_{\\text{curr}} \\neq \\mathcal{S}_{\\text{prev}}$, increment `active_set_changes`.\n    g. Update for the next iteration: $x = x_{\\text{next}}$ and $\\mathcal{S}_{\\text{prev}} = \\mathcal{S}_{\\text{curr}}$.\n    h. Increment $k$.\n5.  After the loop terminates, compute the final objective value, projected gradient norm, active sets, and total changes using the final iterate $x$.\n6.  Format the results as specified and store them.\n7.  After processing all test cases, print the aggregated results in the required format.", "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Implements and analyzes the projected gradient method for a convex quadratic\n    objective with box constraints, based on the provided problem description.\n    \"\"\"\n    \n    test_cases = [\n        # Test 1 (interior solution expected)\n        {\n            \"A\": np.array([[2.0, 0.0], [0.0, 1.0]]),\n            \"b\": np.array([1.0, 2.0]),\n            \"l\": np.array([-10.0, -10.0]),\n            \"u\": np.array([10.0, 10.0]),\n            \"x0\": np.array([0.0, 0.0]),\n        },\n        # Test 2 (both lower and upper activity expected)\n        {\n            \"A\": np.array([[1.0, 0.0], [0.0, 1.0]]),\n            \"b\": np.array([-1.0, 3.0]),\n            \"l\": np.array([0.0, 0.0]),\n            \"u\": np.array([2.0, 2.0]),\n            \"x0\": np.array([1.0, 1.0]),\n        },\n        # Test 3 (upper activity on at least one coordinate)\n        {\n            \"A\": np.array([[1.0, 0.0], [0.0, 1.0]]),\n            \"b\": np.array([10.0, 1.0]),\n            \"l\": np.array([-5.0, -1.0]),\n            \"u\": np.array([1.0, 2.0]),\n            \"x0\": np.array([0.0, 0.0]),\n        },\n        # Test 4 (fixed variable with l_1=u_1)\n        {\n            \"A\": np.array([[1.0, 1.0], [0.0, 1.0]]),\n            \"b\": np.array([1.0, 0.0]),\n            \"l\": np.array([0.0, -1.0]),\n            \"u\": np.array([0.0, 1.0]),\n            \"x0\": np.array([0.0, 0.0]),\n        },\n        # Test 5 (constant objective; zero matrix)\n        {\n            \"A\": np.array([[0.0, 0.0], [0.0, 0.0]]),\n            \"b\": np.array([1.0, -2.0]),\n            \"l\": np.array([-1.0, -1.0]),\n            \"u\": np.array([1.0, 1.0]),\n            \"x0\": np.array([0.25, -0.5]),\n        },\n    ]\n\n    eps = 1e-8\n    eps_act = 1e-8\n    max_iter = 10000\n    \n    all_results = []\n\n    def get_active_sets(x, l, u, tol):\n        lower_active_indices = np.where(x = l + tol)[0]\n        upper_active_indices = np.where(x = u - tol)[0]\n        return frozenset(lower_active_indices), frozenset(upper_active_indices)\n\n    for case in test_cases:\n        A, b, l, u, x = case[\"A\"], case[\"b\"], case[\"l\"], case[\"u\"], case[\"x0\"].copy()\n        \n        # Calculate Lipschitz constant and step size\n        L = np.linalg.norm(A, 2)**2\n        if L  0:\n            alpha = 1.0 / L\n        else:\n            # For A=0, L=0. Gradient is always 0. Any alpha works.\n            alpha = 1.0\n\n        active_set_changes = 0\n        \n        lower_prev, upper_prev = get_active_sets(x, l, u, eps_act)\n        union_prev = lower_prev.union(upper_prev)\n        \n        num_iter = 0\n        for k in range(max_iter):\n            # Gradient of f(x) = 1/2 ||Ax-b||^2 is A^T(Ax-b)\n            grad = A.T @ (A @ x - b)\n            \n            # Stopping criterion: ||g_P(x)||_inf = eps\n            # g_P(x) = x - P_{[l,u]}(x - grad)\n            # Projection uses a step of 1, as per problem definition\n            g_p = x - np.clip(x - grad, l, u)\n            norm_g_p = np.linalg.norm(g_p, np.inf)\n            \n            if norm_g_p = eps:\n                break\n\n            # Projected gradient update step\n            x_next = np.clip(x - alpha * grad, l, u)\n            \n            # Check for active set change\n            lower_curr, upper_curr = get_active_sets(x_next, l, u, eps_act)\n            union_curr = lower_curr.union(upper_curr)\n            \n            if union_curr != union_prev:\n                active_set_changes += 1\n                \n            x = x_next\n            union_prev = union_curr\n            num_iter = k + 1\n\n        # Final calculations\n        final_f = 0.5 * np.linalg.norm(A @ x - b)**2\n        \n        # Recalculate final projected gradient norm for consistency\n        final_grad = A.T @ (A @ x - b)\n        final_g_p = x - np.clip(x - final_grad, l, u)\n        final_norm_g_p = np.linalg.norm(final_g_p, np.inf)\n\n        final_lower_active, final_upper_active = get_active_sets(x, l, u, eps_act)\n\n        result_tuple = (\n            round(final_f, 6),\n            round(final_norm_g_p, 8),\n            int(num_iter),\n            sorted(list(final_lower_active)),\n            sorted(list(final_upper_active)),\n            int(active_set_changes)\n        )\n        all_results.append(result_tuple)\n\n    # Format output\n    result_strings = []\n    for res in all_results:\n        f_val, p_norm, k_iter, l_list, u_list, c_changes = res\n        # Python's default list-to-string conversion matches the required format\n        result_strings.append(\n            f\"[{f_val}, {p_norm}, {k_iter}, {l_list}, {u_list}, {c_changes}]\"\n        )\n    \n    print(f\"[{','.join(result_strings)}]\")\n\nsolve()\n```", "id": "3195673"}, {"introduction": "An alternative philosophy for handling constraints is to absorb them into the objective function using a penalty term. This practice [@problem_id:3195675] first explores this pure quadratic penalty method and its primary drawback: the need for an infinitely large penalty parameter, which leads to numerical instability. It then introduces the augmented Lagrangian method, a superior technique that combines the penalty idea with Lagrange multipliers to achieve faster and more stable convergence without extreme parameter values.", "problem": "Design and implement two methods for solving equality-constrained quadratic programs, and compare their convergence behavior: a pure quadratic penalty method and an augmented Lagrangian method with exact Lagrange multiplier updates. Work from the following fundamental base: first-order optimality (Karush–Kuhn–Tucker) conditions for equality-constrained optimization, properties of convex quadratic functions, and linear algebra facts about symmetric positive definite matrices.\n\nYou must solve problems of the form: minimize a strictly convex quadratic objective under linear equality constraints. Concretely, for each test case, consider minimizing the function $f(\\mathbf{x}) = \\tfrac{1}{2}\\,\\mathbf{x}^{\\top}\\mathbf{Q}\\,\\mathbf{x} + \\mathbf{c}^{\\top}\\mathbf{x}$ subject to $\\mathbf{A}\\,\\mathbf{x} = \\mathbf{b}$, where $\\mathbf{Q}\\in\\mathbb{R}^{n\\times n}$ is symmetric positive definite, $\\mathbf{A}\\in\\mathbb{R}^{m\\times n}$ has full row-rank, $\\mathbf{c}\\in\\mathbb{R}^{n}$, and $\\mathbf{b}\\in\\mathbb{R}^{m}$. There is no use of physical units in this problem.\n\nImplement and compare:\n- A pure quadratic penalty method that, for a sequence of penalty parameters $\\rho_k$, solves the unconstrained subproblem $\\min_{\\mathbf{x}}\\; f(\\mathbf{x}) + \\tfrac{\\rho_k}{2}\\,\\lVert \\mathbf{A}\\mathbf{x}-\\mathbf{b}\\rVert_2^2$, and stops when the primal feasibility $\\lVert \\mathbf{A}\\mathbf{x}-\\mathbf{b}\\rVert_2$ is at most a tolerance $\\varepsilon$ or when a maximum number of outer iterations is reached.\n- An augmented Lagrangian method (also known as the method of multipliers) that, for a fixed augmentation parameter $\\rho_{\\mathrm{AL}}$, alternates between minimizing the augmented Lagrangian with respect to $\\mathbf{x}$ and performing the exact Lagrange multiplier update, and stops when the primal feasibility $\\lVert \\mathbf{A}\\mathbf{x}-\\mathbf{b}\\rVert_2$ is at most $\\varepsilon$ or when a maximum number of outer iterations is reached. Use the initialization $\\boldsymbol{\\lambda}^{(0)} = \\mathbf{0}$.\n\nUse the following algorithmic specifications, which you must adhere to exactly:\n- Penalty method:\n  - Initial penalty $\\rho_0 = 10^{0}$.\n  - Geometric update $\\rho_{k+1} = 10\\,\\rho_k$.\n  - Maximum of $7$ outer iterations.\n  - Termination tolerance $\\varepsilon = 10^{-7}$ on the primal feasibility $\\lVert \\mathbf{A}\\mathbf{x}-\\mathbf{b}\\rVert_2$.\n- Augmented Lagrangian method:\n  - Fixed augmentation parameter $\\rho_{\\mathrm{AL}} = 10^{2}$.\n  - Initial multiplier $\\boldsymbol{\\lambda}^{(0)} = \\mathbf{0}$.\n  - Maximum of $50$ outer iterations.\n  - Termination tolerance $\\varepsilon = 10^{-7}$ on $\\lVert \\mathbf{A}\\mathbf{x}-\\mathbf{b}\\rVert_2$.\n\nIn both methods, at every outer iteration, solve the inner unconstrained quadratic minimization subproblem exactly by solving the corresponding linear system implied by the first-order condition for that subproblem. Count the number of outer iterations as the number of subproblem solves actually performed until termination (inclusive of the final successful iteration), capped by their respective maxima.\n\nTest suite. Run your program on the following three problem instances, each given by $(\\mathbf{Q}, \\mathbf{c}, \\mathbf{A}, \\mathbf{b})$:\n- Case $1$ (well-conditioned, single constraint):\n  - $\\mathbf{Q} = \\begin{bmatrix} 4  1 \\\\ 1  3 \\end{bmatrix}$, $\\;\\mathbf{c} = \\begin{bmatrix} -1 \\\\ -2 \\end{bmatrix}$,\n  - $\\mathbf{A} = \\begin{bmatrix} 1  1 \\end{bmatrix}$, $\\;\\mathbf{b} = \\begin{bmatrix} 1 \\end{bmatrix}$.\n- Case $2$ (ill-conditioned objective, single constraint):\n  - $\\mathbf{Q} = \\begin{bmatrix} 100  0 \\\\ 0  1 \\end{bmatrix}$, $\\;\\mathbf{c} = \\begin{bmatrix} -3 \\\\ -1 \\end{bmatrix}$,\n  - $\\mathbf{A} = \\begin{bmatrix} 1  -1 \\end{bmatrix}$, $\\;\\mathbf{b} = \\begin{bmatrix} 0 \\end{bmatrix}$.\n- Case $3$ (two independent constraints, unique feasible point):\n  - $\\mathbf{Q} = \\begin{bmatrix} 5  2 \\\\ 2  2 \\end{bmatrix}$, $\\;\\mathbf{c} = \\begin{bmatrix} 0 \\\\ -3 \\end{bmatrix}$,\n  - $\\mathbf{A} = \\begin{bmatrix} 1  2 \\\\ 1  -1 \\end{bmatrix}$, $\\;\\mathbf{b} = \\begin{bmatrix} 1 \\\\ 0 \\end{bmatrix}$.\n\nFor each case, produce a single integer indicator defined as follows:\n- Output $1$ if both methods achieve $\\lVert \\mathbf{A}\\mathbf{x}-\\mathbf{b}\\rVert_2 \\le \\varepsilon$ within their respective iteration limits, and the augmented Lagrangian method uses no more outer iterations than the penalty method and attains a final feasibility no worse than that of the penalty method.\n- Otherwise output $0$.\n\nFinal output format. Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, in the order of Cases $1$, $2$, $3$ (for example, $\\big[$result$_1$,result$_2$,result$_3\\big]$). No other text should be printed. The results must be integers.", "solution": "The user-provided problem is a valid exercise in numerical optimization. It requires the implementation and comparison of two standard algorithms for solving equality-constrained quadratic programs (EQPs): the pure quadratic penalty method and the augmented Lagrangian method. The problem is well-posed, scientifically sound, and all parameters are clearly specified.\n\nAn equality-constrained quadratic program has the form:\n$$ \\min_{\\mathbf{x} \\in \\mathbb{R}^n} \\quad f(\\mathbf{x}) = \\frac{1}{2}\\mathbf{x}^{\\top}\\mathbf{Q}\\mathbf{x} + \\mathbf{c}^{\\top}\\mathbf{x} $$\n$$ \\text{subject to} \\quad \\mathbf{A}\\mathbf{x} = \\mathbf{b} $$\nwhere $\\mathbf{Q}$ is a symmetric positive definite (SPD) matrix, ensuring the objective function $f(\\mathbf{x})$ is strictly convex. The matrix $\\mathbf{A}$ has full row-rank, which guarantees that the linear constraints are consistent and non-redundant. These conditions ensure the existence of a unique global minimum.\n\nThe solution to this problem is characterized by the Karush-Kuhn-Tucker (KKT) conditions. The Lagrangian is $L(\\mathbf{x}, \\boldsymbol{\\lambda}) = f(\\mathbf{x}) + \\boldsymbol{\\lambda}^{\\top}(\\mathbf{A}\\mathbf{x} - \\mathbf{b})$. The KKT conditions are:\n1. Stationarity: $\\nabla_{\\mathbf{x}} L(\\mathbf{x}, \\boldsymbol{\\lambda}) = \\mathbf{Q}\\mathbf{x} + \\mathbf{c} + \\mathbf{A}^{\\top}\\boldsymbol{\\lambda} = \\mathbf{0}$\n2. Primal Feasibility: $\\mathbf{A}\\mathbf{x} - \\mathbf{b} = \\mathbf{0}$\n\nThese two conditions form a system of linear equations, often called the KKT system, which can be solved directly for the optimal primal-dual pair $(\\mathbf{x}^*, \\boldsymbol{\\lambda}^*)$. However, the problem tasks us with implementing iterative methods.\n\n### Pure Quadratic Penalty Method\n\nThis method transforms the constrained problem into a sequence of unconstrained problems. The constraints are incorporated into the objective function via a penalty term. At each outer iteration $k$, we solve the unconstrained subproblem:\n$$ \\min_{\\mathbf{x}} \\quad P(\\mathbf{x}; \\rho_k) = f(\\mathbf{x}) + \\frac{\\rho_k}{2} \\lVert \\mathbf{A}\\mathbf{x} - \\mathbf{b} \\rVert_2^2 $$\nwhere $\\rho_k  0$ is the penalty parameter, which is progressively increased. The term $\\frac{\\rho_k}{2} \\lVert \\mathbf{A}\\mathbf{x} - \\mathbf{b} \\rVert_2^2$ penalizes violations of the equality constraints. As $\\rho_k \\to \\infty$, the solution $\\mathbf{x}_k$ of the subproblem is driven towards the feasible region.\n\nThe objective function $P(\\mathbf{x}; \\rho_k)$ is a quadratic function of $\\mathbf{x}$:\n$$ P(\\mathbf{x}; \\rho_k) = \\frac{1}{2}\\mathbf{x}^{\\top}\\mathbf{Q}\\mathbf{x} + \\mathbf{c}^{\\top}\\mathbf{x} + \\frac{\\rho_k}{2} (\\mathbf{A}\\mathbf{x} - \\mathbf{b})^{\\top}(\\mathbf{A}\\mathbf{x} - \\mathbf{b}) $$\n$$ P(\\mathbf{x}; \\rho_k) = \\frac{1}{2}\\mathbf{x}^{\\top}(\\mathbf{Q} + \\rho_k\\mathbf{A}^{\\top}\\mathbf{A})\\mathbf{x} + (\\mathbf{c} - \\rho_k\\mathbf{A}^{\\top}\\mathbf{b})^{\\top}\\mathbf{x} + \\frac{\\rho_k}{2}\\mathbf{b}^{\\top}\\mathbf{b} $$\nSince this is an unconstrained convex quadratic, its minimizer can be found by setting its gradient to zero:\n$$ \\nabla_{\\mathbf{x}} P(\\mathbf{x}; \\rho_k) = (\\mathbf{Q} + \\rho_k\\mathbf{A}^{\\top}\\mathbf{A})\\mathbf{x} + (\\mathbf{c} - \\rho_k\\mathbf{A}^{\\top}\\mathbf{b}) = \\mathbf{0} $$\nThis yields a linear system for the iterate $\\mathbf{x}_k$:\n$$ (\\mathbf{Q} + \\rho_k\\mathbf{A}^{\\top}\\mathbf{A})\\mathbf{x}_k = \\rho_k\\mathbf{A}^{\\top}\\mathbf{b} - \\mathbf{c} $$\nThe Hessian of the subproblem, $\\mathbf{H}_k = \\mathbf{Q} + \\rho_k\\mathbf{A}^{\\top}\\mathbf{A}$, is SPD because $\\mathbf{Q}$ is SPD and $\\rho_k\\mathbf{A}^{\\top}\\mathbf{A}$ is symmetric positive semidefinite. Thus, a unique solution $\\mathbf{x}_k$ exists for this system at each iteration. A major drawback of this method is that as $\\rho_k$ becomes very large, the condition number of $\\mathbf{H}_k$ deteriorates, leading to numerical instability.\n\nThe algorithm proceeds as follows:\n1. Initialize $k=0$ and $\\rho_0 = 10^0$.\n2. For $k=0, 1, 2, \\ldots, 6$:\n   a. Form the Hessian $\\mathbf{H}_k = \\mathbf{Q} + \\rho_k\\mathbf{A}^{\\top}\\mathbf{A}$ and the right-hand side $\\mathbf{r}_k = \\rho_k\\mathbf{A}^{\\top}\\mathbf{b} - \\mathbf{c}$.\n   b. Solve the linear system $\\mathbf{H}_k \\mathbf{x}_k = \\mathbf{r}_k$ for $\\mathbf{x}_k$.\n   c. Check primal feasibility: If $\\lVert \\mathbf{A}\\mathbf{x}_k - \\mathbf{b} \\rVert_2 \\le \\varepsilon = 10^{-7}$, terminate.\n   d. Update the penalty parameter: $\\rho_{k+1} = 10 \\rho_k$.\n\n### Augmented Lagrangian Method (Method of Multipliers)\n\nThis method combines the Lagrangian function with a quadratic penalty term, forming the augmented Lagrangian:\n$$ L_A(\\mathbf{x}, \\boldsymbol{\\lambda}; \\rho) = f(\\mathbf{x}) + \\boldsymbol{\\lambda}^{\\top}(\\mathbf{A}\\mathbf{x} - \\mathbf{b}) + \\frac{\\rho}{2} \\lVert \\mathbf{A}\\mathbf{x} - \\mathbf{b} \\rVert_2^2 $$\nUnlike the pure penalty method, the augmented Lagrangian method alternates between minimizing $L_A$ with respect to $\\mathbf{x}$ and updating the Lagrange multiplier estimate $\\boldsymbol{\\lambda}$. This approach typically converges for a finite, fixed penalty parameter $\\rho$, thus avoiding the ill-conditioning issues.\n\nAt each outer iteration $k$, given a multiplier estimate $\\boldsymbol{\\lambda}^{(k)}$, the method performs two steps:\n1. **$\\mathbf{x}$-minimization:** Solve $\\mathbf{x}^{(k+1)} = \\arg\\min_{\\mathbf{x}} L_A(\\mathbf{x}, \\boldsymbol{\\lambda}^{(k)}; \\rho_{\\mathrm{AL}})$.\nThis is an unconstrained quadratic minimization problem. The objective can be written as:\n$$ L_A(\\mathbf{x}, \\boldsymbol{\\lambda}^{(k)}; \\rho_{\\mathrm{AL}}) = \\frac{1}{2}\\mathbf{x}^{\\top}(\\mathbf{Q} + \\rho_{\\mathrm{AL}}\\mathbf{A}^{\\top}\\mathbf{A})\\mathbf{x} + (\\mathbf{c} + \\mathbf{A}^{\\top}\\boldsymbol{\\lambda}^{(k)} - \\rho_{\\mathrm{AL}}\\mathbf{A}^{\\top}\\mathbf{b})^{\\top}\\mathbf{x} + \\text{const.} $$\nSetting the gradient with respect to $\\mathbf{x}$ to zero gives the linear system for $\\mathbf{x}^{(k+1)}$:\n$$ (\\mathbf{Q} + \\rho_{\\mathrm{AL}}\\mathbf{A}^{\\top}\\mathbf{A})\\mathbf{x}^{(k+1)} = \\rho_{\\mathrm{AL}}\\mathbf{A}^{\\top}\\mathbf{b} - \\mathbf{c} - \\mathbf{A}^{\\top}\\boldsymbol{\\lambda}^{(k)} $$\nThe Hessian matrix $\\mathbf{H}_{\\mathrm{AL}} = \\mathbf{Q} + \\rho_{\\mathrm{AL}}\\mathbf{A}^{\\top}\\mathbf{A}$ is constant throughout the iterations since $\\rho_{\\mathrm{AL}} = 10^2$ is fixed.\n\n2. **$\\boldsymbol{\\lambda}$-update:** The problem specifies an exact Lagrange multiplier update. This corresponds to the standard first-order update rule for the method of multipliers:\n$$ \\boldsymbol{\\lambda}^{(k+1)} = \\boldsymbol{\\lambda}^{(k)} + \\rho_{\\mathrm{AL}}(\\mathbf{A}\\mathbf{x}^{(k+1)} - \\mathbf{b}) $$\nThis update is motivated by the stationarity condition of the $\\mathbf{x}$-minimization step.\n\nThe algorithm proceeds as follows:\n1. Initialize $k=0$, $\\boldsymbol{\\lambda}^{(0)} = \\mathbf{0}$, and use a fixed $\\rho_{\\mathrm{AL}} = 10^2$.\n2. For $k=0, 1, 2, \\ldots, 49$:\n   a. Form the right-hand side $\\mathbf{r}_k = \\rho_{\\mathrm{AL}}\\mathbf{A}^{\\top}\\mathbf{b} - \\mathbf{c} - \\mathbf{A}^{\\top}\\boldsymbol{\\lambda}^{(k)}$.\n   b. Solve the linear system $(\\mathbf{Q} + \\rho_{\\mathrm{AL}}\\mathbf{A}^{\\top}\\mathbf{A})\\mathbf{x}^{(k+1)} = \\mathbf{r}_k$ for $\\mathbf{x}^{(k+1)}$.\n   c. Check primal feasibility: If $\\lVert \\mathbf{A}\\mathbf{x}^{(k+1)} - \\mathbf{b} \\rVert_2 \\le \\varepsilon = 10^{-7}$, terminate.\n   d. Update the multiplier: $\\boldsymbol{\\lambda}^{(k+1)} = \\boldsymbol{\\lambda}^{(k)} + \\rho_{\\mathrm{AL}}(\\mathbf{A}\\mathbf{x}^{(k+1)} - \\mathbf{b})$.\n\nThe augmented Lagrangian method is generally preferred due to its superior convergence properties and numerical stability. It converges to the correct solution without requiring the penalty parameter to go to infinity.", "answer": "```python\nimport numpy as np\n\ndef penalty_method(Q, c, A, b):\n    \"\"\"\n    Solves an EQP using the pure quadratic penalty method.\n\n    Parameters are defined by the problem statement:\n    - Initial penalty rho_0 = 1.0\n    - Geometric update rho_{k+1} = 10 * rho_k\n    - Maximum of 7 outer iterations\n    - Tolerance eps = 1e-7 on primal feasibility\n    \"\"\"\n    rho = 1.0\n    rho_factor = 10.0\n    max_iter = 7\n    tol = 1e-7\n    \n    x = None\n    feas_err = float('inf')\n\n    for k in range(max_iter):\n        H = Q + rho * A.T @ A\n        rhs = rho * A.T @ b - c\n        \n        try:\n            x = np.linalg.solve(H, rhs)\n        except np.linalg.LinAlgError:\n            # In case of numerical instability, though unlikely with SPD Hessians\n            return max_iter, float('inf')\n\n        feas_err = np.linalg.norm(A @ x - b)\n\n        if feas_err = tol:\n            return k + 1, feas_err\n        \n        rho *= rho_factor\n        \n    return max_iter, feas_err\n\ndef augmented_lagrangian_method(Q, c, A, b):\n    \"\"\"\n    Solves an EQP using the augmented Lagrangian method (method of multipliers).\n\n    Parameters are defined by the problem statement:\n    - Fixed augmentation parameter rho_al = 100.0\n    - Initial multiplier lambda_0 = 0\n    - Maximum of 50 outer iterations\n    - Tolerance eps = 1e-7 on primal feasibility\n    \"\"\"\n    rho_al = 100.0\n    max_iter = 50\n    tol = 1e-7\n\n    m = A.shape[0]\n    n = Q.shape[0]\n    \n    lam = np.zeros(m)\n    x = np.zeros(n)\n    feas_err = float('inf')\n\n    H_al = Q + rho_al * A.T @ A\n    \n    try:\n        # Pre-compute the decomposition of H_al for efficiency, though solve does it internally.\n        # This is a good practice if H_al is used repeatedly.\n        pass\n    except np.linalg.LinAlgError:\n        return max_iter, float('inf')\n\n    for k in range(max_iter):\n        rhs = rho_al * A.T @ b - c - A.T @ lam\n        \n        try:\n            x = np.linalg.solve(H_al, rhs)\n        except np.linalg.LinAlgError:\n            return max_iter, float('inf')\n\n        residual = A @ x - b\n        feas_err = np.linalg.norm(residual)\n        \n        if feas_err = tol:\n            return k + 1, feas_err\n        \n        # Multiplier update\n        lam += rho_al * residual\n        \n    return max_iter, feas_err\n\ndef solve():\n    \"\"\"\n    Main function to run the test cases and generate the final output.\n    \"\"\"\n    test_cases = [\n        {\n            \"Q\": np.array([[4, 1], [1, 3]]),\n            \"c\": np.array([-1, -2]),\n            \"A\": np.array([[1, 1]]),\n            \"b\": np.array([1])\n        },\n        {\n            \"Q\": np.array([[100, 0], [0, 1]]),\n            \"c\": np.array([-3, -1]),\n            \"A\": np.array([[1, -1]]),\n            \"b\": np.array([0])\n        },\n        {\n            \"Q\": np.array([[5, 2], [2, 2]]),\n            \"c\": np.array([0, -3]),\n            \"A\": np.array([[1, 2], [1, -1]]),\n            \"b\": np.array([1, 0])\n        }\n    ]\n\n    results = []\n    tol = 1e-7\n\n    for case in test_cases:\n        Q, c, A, b = case[\"Q\"], case[\"c\"], case[\"A\"], case[\"b\"]\n        \n        # Run Penalty Method\n        iters_pen, feas_pen = penalty_method(Q, c, A, b)\n        \n        # Run Augmented Lagrangian Method\n        iters_al, feas_al = augmented_lagrangian_method(Q, c, A, b)\n\n        # Check convergence conditions\n        converged_pen = feas_pen = tol\n        converged_al = feas_al = tol\n\n        # Determine the output indicator\n        indicator = 0\n        if converged_pen and converged_al:\n            if iters_al = iters_pen and feas_al = feas_pen:\n                indicator = 1\n        \n        results.append(indicator)\n\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "3195675"}]}