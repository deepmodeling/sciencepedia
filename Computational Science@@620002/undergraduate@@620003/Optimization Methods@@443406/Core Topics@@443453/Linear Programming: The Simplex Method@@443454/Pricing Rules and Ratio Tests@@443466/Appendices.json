{"hands_on_practices": [{"introduction": "To truly master the simplex method, it is essential to understand its mechanics not just as a set of rules, but from first principles. This exercise [@problem_id:3164090] challenges you to derive the fundamental update formulas for basic variables and reduced costs directly from their algebraic definitions. By then applying these formulas to a concrete example, you will solidify your understanding of how each pivot operation systematically improves the solution while maintaining feasibility.", "problem": "Consider the primal Simplex method for a Linear Programming (LP) problem in standard equality form for maximization: maximize $c^{\\top} x$ subject to $A x = b$, $x \\ge 0$. Let a current basis be defined by a set of basic columns $B \\in \\mathbb{R}^{m \\times m}$ and nonbasic columns $N \\in \\mathbb{R}^{m \\times (n-m)}$, with associated subvectors $c_B \\in \\mathbb{R}^{m}$, $c_N \\in \\mathbb{R}^{n-m}$. The current basic feasible solution is $x_B = B^{-1} b$, $x_N = 0$, and the reduced costs are given by the fundamental definition $\\bar c^{\\top} = c^{\\top} - c_B^{\\top} B^{-1} A$. Suppose a nonbasic variable $x_j$ is chosen to enter the basis by a pricing rule that selects an index with strictly positive reduced cost (Dantzig’s rule: choose $j$ with the largest positive $\\bar c_j$), and let $u = B^{-1} a_j$, where $a_j$ is the $j$-th column of $A$. The primal ratio test determines the leaving basic variable by selecting index $r$ such that $u_r > 0$ and $\\theta^{\\star} = \\min_{i : u_i > 0} \\frac{x_{B,i}}{u_i}$ is attained at $i = r$. \n\nTasks:\n- Starting only from the core definitions $x_B = B^{-1} b$, $\\bar c^{\\top} = c^{\\top} - c_B^{\\top} B^{-1} A$, and the feasibility step equations induced by moving along the direction defined by $u = B^{-1} a_j$, derive exact algebraic update formulas for the new basic variable values and the new reduced costs after a single pivot. Your formulas should give $x_{B}^{+}$ and $\\bar c^{+}$ in terms of $x_B$, $\\bar c$, $u$, the pivot row index $r$, and the quantities from the pre-pivot tableau, without invoking any shortcut formulas not derived from these definitions.\n- Then apply your derived formulas to the specific LP:\nmaximize $3 x_1 + 5 x_2$ subject to\n$$\n\\begin{pmatrix}\n2 & 1 \\\\\n1 & 2\n\\end{pmatrix}\n\\begin{pmatrix}\nx_1 \\\\\nx_2\n\\end{pmatrix}\n+\n\\begin{pmatrix}\n1 & 0 \\\\\n0 & 1\n\\end{pmatrix}\n\\begin{pmatrix}\ns_1 \\\\\ns_2\n\\end{pmatrix}\n=\n\\begin{pmatrix}\n8 \\\\\n8\n\\end{pmatrix}, \\quad\nx_1, x_2, s_1, s_2 \\ge 0,\n$$\nwith initial basis given by the slack variables $s_1$ and $s_2$. Use Dantzig’s pricing rule (choose the nonbasic index with largest strictly positive reduced cost) and the standard primal minimum-ratio test with the deterministic tie-breaker “smallest row index” if needed. Perform exactly two pivots starting from the initial basic feasible solution. At each pivot, verify that the chosen entering variable satisfies the pricing rule and that the chosen leaving variable satisfies the ratio test, and check that feasibility is preserved.\n- Let $z$ denote the objective value after completing the second pivot. Provide $z$ as a single exact simplified fraction.\n\nExpress your final numerical answer as an exact fraction. Do not round. The final answer must be a single real number.", "solution": "The problem asks for two main tasks: first, to derive the update formulas for the basic variable values and reduced costs in the Simplex method, starting from fundamental definitions; and second, to apply these formulas to solve a specific Linear Programming (LP) problem for two pivots and find the resulting objective value.\n\n### Part 1: Derivation of Update Formulas\n\nLet the LP be in the standard form: maximize $z = c^{\\top} x$ subject to $A x = b$, $x \\ge 0$.\nThe matrix $A \\in \\mathbb{R}^{m \\times n}$ is partitioned into a basic matrix $B \\in \\mathbb{R}^{m \\times m}$ and a nonbasic matrix $N \\in \\mathbb{R}^{m \\times (n-m)}$. The vectors $x$ and $c$ are partitioned accordingly into $x_B, x_N$ and $c_B, c_N$.\nThe current basic feasible solution (BFS) is given by $x_N = 0$ and $x_B = B^{-1} b \\ge 0$.\nThe reduced costs are $\\bar c^{\\top} = c^{\\top} - c_B^{\\top} B^{-1} A$.\n\nA nonbasic variable $x_j$ is chosen to enter the basis, where its reduced cost $\\bar{c}_j > 0$. We seek to find a new solution $x^{\\text{new}}$ by increasing $x_j$ from $0$ to some value $\\theta > 0$, while keeping all other nonbasic variables at $0$. The basic variables $x_B$ will be adjusted to maintain feasibility.\n\n#### Derivation of the New Basic Variable Values ($x_B^{+}$)\n\nLet the new solution be $x^{\\text{new}}$. The nonbasic part is $x_N^{\\text{new}} = \\theta e_k$, where $e_k$ is the standard basis vector corresponding to the position of $x_j$ within the nonbasic variables. The feasibility constraint $A x = b$ must be maintained:\n$$B x_B^{\\text{new}} + N x_N^{\\text{new}} = b$$\n$$B x_B^{\\text{new}} + a_j \\theta = b$$\nwhere $a_j$ is the column of $A$ (and $N$) corresponding to $x_j$. To solve for $x_B^{\\text{new}}$, we multiply by $B^{-1}$:\n$$x_B^{\\text{new}} = B^{-1}(b - a_j \\theta) = B^{-1}b - \\theta (B^{-1}a_j)$$\nUsing the provided definitions $x_B = B^{-1} b$ and $u = B^{-1} a_j$, we get:\n$$x_B^{\\text{new}}(\\theta) = x_B - \\theta u$$\nFor the new solution to remain feasible, we must have $x_B^{\\text{new}} \\ge 0$, which means $x_{B,i} - \\theta u_i \\ge 0$ for all basic indices $i=1, \\dots, m$.\nIf $u_i \\le 0$, this inequality holds for any $\\theta \\ge 0$.\nIf $u_i > 0$, we must have $\\theta \\le \\frac{x_{B,i}}{u_i}$.\nTo maximize the increase in the objective function, we choose the largest possible $\\theta$ that maintains feasibility for all basic variables:\n$$\\theta^{\\star} = \\min_{i \\,:\\, u_i > 0} \\left\\{ \\frac{x_{B,i}}{u_i} \\right\\}$$\nThis is the primal ratio test. Let the minimum be achieved for the index $i=r$. This means the basic variable $x_{B,r}$ will be driven to $0$ and will leave the basis.\n$$x_{B,r}^{\\text{new}} = x_{B,r} - \\theta^{\\star} u_r = x_{B,r} - \\left(\\frac{x_{B,r}}{u_r}\\right) u_r = 0$$\nThe new set of basic variables, denoted by $x_B^{+}$, consists of the entering variable $x_j$ and the old basic variables except for the leaving variable $x_{B,r}$. The values of these new basic variables are:\n- The entering variable $x_j$ takes the value $x_j^{+} = \\theta^{\\star} = \\frac{x_{B,r}}{u_r}$.\n- The basic variables that remain in the basis, $x_{B,i}$ for $i \\neq r$, have their values updated to $x_{B,i}^{+} = x_{B,i} - \\theta^{\\star} u_i = x_{B,i} - \\left(\\frac{x_{B,r}}{u_r}\\right) u_i$.\n\n#### Derivation of the New Reduced Costs ($\\bar{c}^{+}$)\n\nThe reduced cost for any variable $x_k$ is $\\bar{c}_k = c_k - \\pi^{\\top} a_k$, where $\\pi^{\\top} = c_B^{\\top} B^{-1}$ is the vector of simplex multipliers. After the pivot, the basis changes from $B$ to $B^{+}$ and the basic cost vector changes from $c_B$ to $c_{B^{+}}$. The new multipliers are $(\\pi^{+})^{\\top} = c_{B^{+}}^{\\top} (B^{+})^{-1}$.\nThe new multipliers must satisfy $(\\pi^{+})^{\\top} a_k = c_k$ for all variables $x_k$ in the new basis.\nLet's express the new multipliers as a modification of the old ones: $(\\pi^{+})^{\\top} = \\pi^{\\top} + \\delta^{\\top}$.\n\nThe new basis consists of the columns $\\{a_{B_i}\\}_{i \\neq r}$ and the new column $a_j$.\n$1$. For the entering variable $x_j$, which is now basic:\n$$(\\pi^{+})^{\\top} a_j = c_j \\implies (\\pi^{\\top} + \\delta^{\\top}) a_j = c_j$$\nSince $\\pi^{\\top} a_j = c_j - \\bar{c}_j$, this gives $(c_j - \\bar{c}_j) + \\delta^{\\top} a_j = c_j$, which simplifies to $\\delta^{\\top} a_j = \\bar{c}_j$.\n\n$2$. For the variables $x_{B_i}$ that remain basic ($i \\neq r$):\n$$(\\pi^{+})^{\\top} a_{B_i} = c_{B_i} \\implies (\\pi^{\\top} + \\delta^{\\top}) a_{B_i} = c_{B_i}$$\nSince $\\pi^{\\top} a_{B_i} = c_{B_i}$ (as $x_{B_i}$ was in the old basis), this simplifies to $\\delta^{\\top} a_{B_i} = 0$ for all $i \\neq r$.\n\nWe now have a system of equations for $\\delta$. We use the relation $a_j = B u = \\sum_{i=1}^{m} u_i a_{B_i}$:\n$$\\bar{c}_j = \\delta^{\\top} a_j = \\delta^{\\top} \\left( \\sum_{i=1}^{m} u_i a_{B_i} \\right) = \\sum_{i=1}^{m} u_i (\\delta^{\\top} a_{B_i})$$\nUsing $\\delta^{\\top} a_{B_i}=0$ for $i \\neq r$, the sum reduces to a single term:\n$$\\bar{c}_j = u_r (\\delta^{\\top} a_{B_r})$$\nThis implies $\\delta^{\\top} a_{B_r} = \\frac{\\bar{c}_j}{u_r}$.\nLet $v_r^{\\top}$ be the $r$-th row of the matrix $B^{-1}$. Then $v_r^{\\top} B = e_r^{\\top}$ (the $r$-th standard basis vector), which means $v_r^{\\top} a_{B_i} = \\delta_{ir}$ (Kronecker delta).\nLet's define a vector $\\eta^{\\top} = \\frac{\\bar{c}_j}{u_r} v_r^{\\top}$. Let's check if this satisfies the conditions on $\\delta^{\\top}$.\n$\\eta^{\\top} a_{B_i} = \\frac{\\bar{c}_j}{u_r} (v_r^{\\top} a_{B_i}) = \\frac{\\bar{c}_j}{u_r} \\delta_{ir}$. This is $0$ for $i \\neq r$ and $\\frac{\\bar{c}_j}{u_r}$ for $i=r$. This matches our findings. So, we have found the change $\\delta^{\\top}$:\n$$\\delta^{\\top} = \\frac{\\bar{c}_j}{u_r} v_r^{\\top} = \\frac{\\bar{c}_j}{u_r} (\\text{r-th row of } B^{-1})$$\nNow we can compute the new reduced cost $\\bar{c}_k^{+}$ for any variable $x_k$:\n$$\\bar{c}_k^{+} = c_k - (\\pi^{+})^{\\top} a_k = c_k - (\\pi^{\\top} + \\delta^{\\top}) a_k = (c_k - \\pi^{\\top} a_k) - \\delta^{\\top} a_k = \\bar{c}_k - \\delta^{\\top} a_k$$\nSubstituting the expression for $\\delta^{\\top}$:\n$$\\bar{c}_k^{+} = \\bar{c}_k - \\left( \\frac{\\bar{c}_j}{u_r} (\\text{r-th row of } B^{-1}) \\right) a_k$$\nThe term $(\\text{r-th row of } B^{-1}) a_k$ is the $r$-th component of the vector $B^{-1}a_k$, which is the column corresponding to $x_k$ in the current simplex tableau. Let's denote this column by $\\bar{a}_k = B^{-1}a_k$. Then the pivot element is $u_r = (\\bar{a}_j)_r = \\bar{a}_{rj}$. The expression becomes:\n$$\\bar{c}_k^{+} = \\bar{c}_k - \\frac{\\bar{c}_j}{\\bar{a}_{rj}} \\bar{a}_{rk}$$\n\n### Part 2: Application to the Specific LP\n\nThe problem is: maximize $z = 3 x_1 + 5 x_2$ subject to\n$$\n\\begin{pmatrix} 2 & 1 \\\\ 1 & 2 \\end{pmatrix} \\begin{pmatrix} x_1 \\\\ x_2 \\end{pmatrix} + \\begin{pmatrix} 1 & 0 \\\\ 0 & 1 \\end{pmatrix} \\begin{pmatrix} s_1 \\\\ s_2 \\end{pmatrix} = \\begin{pmatrix} 8 \\\\ 8 \\end{pmatrix}, \\quad x_1, x_2, s_1, s_2 \\ge 0.\n$$\nHere, $x = [x_1, x_2, s_1, s_2]^{\\top}$, $c = [3, 5, 0, 0]^{\\top}$, $A = \\begin{pmatrix} 2 & 1 & 1 & 0 \\\\ 1 & 2 & 0 & 1 \\end{pmatrix}$, $b = \\begin{pmatrix} 8 \\\\ 8 \\end{pmatrix}$.\n\n**Initial State (Pivot 0)**\nThe initial basis is given by the slack variables $s_1$ and $s_2$.\n- Basic variables: $x_B = [s_1, s_2]^{\\top}$. Nonbasic variables: $x_N = [x_1, x_2]^{\\top}$.\n- $B = \\begin{pmatrix} 1 & 0 \\\\ 0 & 1 \\end{pmatrix} = I$, so $B^{-1} = I$.\n- $c_B = [0, 0]^{\\top}$.\n- Initial BFS: $x_B = B^{-1}b = I \\begin{pmatrix} 8 \\\\ 8 \\end{pmatrix} = \\begin{pmatrix} 8 \\\\ 8 \\end{pmatrix}$. So $s_1=8, s_2=8$. The full solution is $(x_1, x_2, s_1, s_2) = (0, 0, 8, 8)$. This is feasible as all variables are non-negative.\n- Initial objective value: $z = c^{\\top}x = 3(0) + 5(0) + 0(8) + 0(8) = 0$.\n- Reduced costs: $\\bar{c}^{\\top} = c^{\\top} - c_B^{\\top} B^{-1} A = c^{\\top} - 0 \\cdot A = c^{\\top} = [3, 5, 0, 0]$.\n- So, $\\bar{c}_1=3, \\bar{c}_2=5, \\bar{c}_{s1}=0, \\bar{c}_{s2}=0$.\n\n**Pivot 1**\n- **Pricing Rule**: We select the entering variable using Dantzig's rule: choose $j$ with $\\max_{k} \\{\\bar{c}_k\\} > 0$.\nHere, $\\max\\{3, 5\\} = 5$, corresponding to $x_2$. So $x_2$ enters the basis. The choice is valid as $\\bar{c}_2=5>0$.\n- **Ratio Test**: We find the leaving variable. The entering column is $a_2=[1, 2]^{\\top}$. The direction vector is $u = B^{-1}a_2 = I a_2 = [1, 2]^{\\top}$.\nThe current basic variables are $x_B = [s_1, s_2]^{\\top}$ with values $[8, 8]^{\\top}$.\nThe ratios are:\n  - For $s_1$ (index $i=1$): $u_1 = 1 > 0$, ratio is $x_{B,1}/u_1 = 8/1 = 8$.\n  - For $s_2$ (index $i=2$): $u_2 = 2 > 0$, ratio is $x_{B,2}/u_2 = 8/2 = 4$.\nThe minimum ratio is $\\theta^{\\star} = \\min\\{8, 4\\} = 4$, which corresponds to index $i=2$ (the variable $s_2$). So $s_2$ leaves the basis. The pivot row is $r=2$. The pivot element is $u_2=2$.\n- **Update**:\n  - New basic variables are $s_1, x_2$.\n  - New values:\n    - Entering $x_2$ gets value $\\theta^{\\star} = 4$.\n    - $s_1$ is updated: $s_1^{+} = s_1 - u_1 \\theta^{\\star} = 8 - 1 \\cdot 4 = 4$.\n  - New BFS: $(x_1, x_2, s_1, s_2) = (0, 4, 4, 0)$. This is feasible.\n  - New objective value: $z = 3(0) + 5(4) = 20$.\n  - New reduced costs using $\\bar{c}_k^{+} = \\bar{c}_k - (\\bar{c}_j/\\bar{a}_{rj}) \\bar{a}_{rk}$. Here $j=2$, $r=2$, $\\bar{c}_2=5$, pivot element $\\bar{a}_{22}=u_2=2$. The multiplier is $5/2$. The pivot row of the tableau ($B^{-1}A = A$) is the $2$nd row of $A$, which is $[1, 2, 0, 1]$.\n    - $\\bar{c}_1^{+} = \\bar{c}_1 - (5/2) \\bar{a}_{21} = 3 - (5/2)(1) = 1/2$.\n    - $\\bar{c}_2^{+} = \\bar{c}_2 - (5/2) \\bar{a}_{22} = 5 - (5/2)(2) = 0$.\n    - $\\bar{c}_{s1}^{+} = \\bar{c}_{s1} - (5/2) \\bar{a}_{2,s1} = 0 - (5/2)(0) = 0$.\n    - $\\bar{c}_{s2}^{+} = \\bar{c}_{s2} - (5/2) \\bar{a}_{2,s2} = 0 - (5/2)(1) = -5/2$.\n  - Post-pivot reduced costs: $\\bar{c}^{\\top} = [1/2, 0, 0, -5/2]$.\n\n**Pivot 2**\n- **State**: Basis consists of $s_1, x_2$. $B = [a_{s1}, a_2] = \\begin{pmatrix} 1 & 1 \\\\ 0 & 2 \\end{pmatrix}$. $x_B = [s_1, x_2]^{\\top} = [4, 4]^{\\top}$.\n- **Pricing Rule**: The only positive reduced cost is $\\bar{c}_1 = 1/2$. So $x_1$ enters the basis. This is valid.\n- **Ratio Test**: Entering column is $a_1=[2, 1]^{\\top}$. We need the corresponding tableau column $u = B^{-1}a_1$.\nFirst, find $B^{-1}$: $B^{-1} = \\frac{1}{2-0} \\begin{pmatrix} 2 & -1 \\\\ 0 & 1 \\end{pmatrix} = \\begin{pmatrix} 1 & -1/2 \\\\ 0 & 1/2 \\end{pmatrix}$.\nNow, $u = \\begin{pmatrix} 1 & -1/2 \\\\ 0 & 1/2 \\end{pmatrix} \\begin{pmatrix} 2 \\\\ 1 \\end{pmatrix} = \\begin{pmatrix} 2-1/2 \\\\ 1/2 \\end{pmatrix} = \\begin{pmatrix} 3/2 \\\\ 1/2 \\end{pmatrix}$.\nThe basic variables are $x_B = [s_1, x_2]^{\\top}$ with values $[4, 4]^{\\top}$.\nThe ratios are:\n  - For $s_1$ (index $i=1$): $u_1 = 3/2 > 0$, ratio is $x_{B,1}/u_1 = 4/(3/2) = 8/3$.\n  - For $x_2$ (index $i=2$): $u_2 = 1/2 > 0$, ratio is $x_{B,2}/u_2 = 4/(1/2) = 8$.\nThe minimum ratio is $\\theta^{\\star} = \\min\\{8/3, 8\\} = 8/3$, which corresponds to index $i=1$ (the variable $s_1$). So $s_1$ leaves the basis. The pivot row is $r=1$. The pivot element is $u_1=3/2$.\n- **Update**:\n  - New basic variables are $x_1, x_2$.\n  - New values:\n    - Entering $x_1$ gets value $\\theta^{\\star} = 8/3$.\n    - $x_2$ is updated: $x_2^{+} = x_2 - u_2 \\theta^{\\star} = 4 - (1/2)(8/3) = 4 - 4/3 = 8/3$.\n  - New BFS: $(x_1, x_2, s_1, s_2) = (8/3, 8/3, 0, 0)$. This is feasible.\n  - Final objective value after two pivots: $z = 3 x_1 + 5 x_2 = 3(8/3) + 5(8/3) = 8 + 40/3 = 24/3 + 40/3 = 64/3$.\n\nThe final state has basic variables $x_1=8/3, x_2=8/3$. The objective value is $z=64/3$. This corresponds to the optimal solution. The problem requires providing this value.", "answer": "$$\\boxed{\\frac{64}{3}}$$", "id": "3164090"}, {"introduction": "The standard simplex method can encounter a special condition known as degeneracy, where a pivot may not change the objective value, potentially leading to stalling or cycling. This practice [@problem_id:3164060] presents a hypothetical degenerate scenario to illustrate this challenge. You will explore how a naive ratio test can fail to make progress and how the more robust lexicographic ratio test, based on a conceptual perturbation, resolves the issue and guarantees improvement.", "problem": "Consider a linear programming (LP) minimization problem in standard form being solved by the simplex method. You are given a current basic feasible solution (BFS) with basic variables $s_{1}, s_{2}, s_{3}$ and nonbasic variables $x_{1}, x_{2}$, where the current solution satisfies $x_{1}=0$, $x_{2}=0$, $s_{1}=0$, $s_{2}=0$, and $s_{3}=1$. This BFS is degenerate because two basic variables are zero. The reduced cost of the nonbasic variable $x_{1}$ is $\\bar{c}_{1}=-1$, and $x_{1}$ has been selected as the entering variable by pricing.\n\nYou are provided the entering column of $x_{1}$ in the current tableau for the three basic rows:\n$$\nA_{\\cdot 1}=\\begin{pmatrix}\na_{11} \\\\\na_{21} \\\\\na_{31}\n\\end{pmatrix}\n=\n\\begin{pmatrix}\n1 \\\\\n2 \\\\\n\\frac{1}{2}\n\\end{pmatrix},\n\\quad\nb=\n\\begin{pmatrix}\nb_{1} \\\\\nb_{2} \\\\\nb_{3}\n\\end{pmatrix}\n=\n\\begin{pmatrix}\n0 \\\\\n0 \\\\\n1\n\\end{pmatrix}.\n$$\n\nThe naive ratio test selects the leaving variable using the rule $\\theta=\\min\\{b_{i}/a_{i1}:a_{i1}>0\\}$, with ties broken by the smallest row index. In contrast, the lexicographic ratio test applies a symbolic perturbation to the right-hand side vector $b$ so that\n$$\nb^{(\\varepsilon)}=\n\\begin{pmatrix}\n\\varepsilon \\\\\n\\varepsilon^{2} \\\\\n1\n\\end{pmatrix},\n\\quad 0<\\varepsilon \\ll 1,\n$$\nand then chooses the leaving variable by minimizing $b^{(\\varepsilon)}_{i}/a_{i1}$ in the lexicographic order.\n\nStarting from the foundational definitions of the simplex method, degeneracy, reduced costs, and ratio tests, do the following:\n- Use the naive ratio test to determine the step length $\\theta_{\\text{naive}}$ for the entering variable $x_{1}$ and compute the corresponding one-step change in the objective value $\\Delta z_{\\text{naive}}$.\n- Use the lexicographic ratio test with the perturbation $b^{(\\varepsilon)}$ to determine the step length $\\theta_{\\text{lex}}$ and compute the corresponding one-step change in the objective value $\\Delta z_{\\text{lex}}$.\n\nExpress your final answer as the ordered pair $\\left(\\Delta z_{\\text{naive}},\\ \\Delta z_{\\text{lex}}\\right)$ in exact analytic form as a function of $\\varepsilon$. No rounding is required.", "solution": "The problem asks for the one-step change in the objective function value, $\\Delta z$. As this is a minimization problem, the entering variable $x_1$ is chosen because its reduced cost is negative ($\\bar{c}_1 = -1$). The change in the objective value is given by the formula $\\Delta z = \\bar{c}_1 \\theta = -\\theta$. The problem implicitly asks for the objective *improvement*, which is defined as the positive quantity $-\\Delta z = \\theta$. We will therefore calculate the step length $\\theta$ for both the naive and the lexicographic ratio tests, as this value corresponds to the improvement.\n\nThe current basic feasible solution is given by the right-hand side vector $b$, which represents the values of the basic variables $(s_1, s_2, s_3)$. The entering column for $x_1$ is $A_{\\cdot 1}$. These are given as:\n$$\nb = \\begin{pmatrix} b_1 \\\\ b_2 \\\\ b_3 \\end{pmatrix} = \\begin{pmatrix} 0 \\\\ 0 \\\\ 1 \\end{pmatrix}, \\quad A_{\\cdot 1} = \\begin{pmatrix} a_{11} \\\\ a_{21} \\\\ a_{31} \\end{pmatrix} = \\begin{pmatrix} 1 \\\\ 2 \\\\ \\frac{1}{2} \\end{pmatrix}\n$$\nThe current solution is degenerate because two basic variables, $s_1$ and $s_2$, have a value of $0$.\n\nFirst, we analyze the naive ratio test. The step length $\\theta$ is determined by the minimum ratio rule:\n$$\n\\theta = \\min \\left\\{ \\frac{b_i}{a_{i1}} : a_{i1} > 0 \\right\\}\n$$\nwhere $i$ ranges over the indices of the basic variables. In this case, the indices are $1$, $2$, and $3$. All entries in the column $A_{\\cdot 1}$ are positive ($a_{11}=1 > 0$, $a_{21}=2 > 0$, $a_{31}=1/2 > 0$), so all three rows are considered in the ratio test.\nThe ratios are:\nFor row $1$ (corresponding to basic variable $s_1$): $\\frac{b_1}{a_{11}} = \\frac{0}{1} = 0$.\nFor row $2$ (corresponding to basic variable $s_2$): $\\frac{b_2}{a_{21}} = \\frac{0}{2} = 0$.\nFor row $3$ (corresponding to basic variable $s_3$): $\\frac{b_3}{a_{31}} = \\frac{1}{1/2} = 2$.\n\nThe minimum ratio is $\\min\\{0, 0, 2\\} = 0$. There is a tie between row $1$ and row $2$. The problem specifies that ties are broken by selecting the row with the smallest index. Therefore, row $1$ is chosen as the pivot row, and the corresponding basic variable $s_1$ is the leaving variable.\nThe step length for the naive test is the value of this minimum ratio:\n$$\n\\theta_{\\text{naive}} = 0\n$$\nThis is a degenerate pivot, where a nonbasic variable enters the basis, but the solution vector and the objective value do not change. The change in the objective value (improvement) is:\n$$\n\\Delta z_{\\text{naive}} = \\theta_{\\text{naive}} = 0\n$$\n\nNext, we analyze the lexicographic ratio test as described in the problem. This test resolves degeneracy by using a symbolically perturbed right-hand side vector $b^{(\\varepsilon)}$:\n$$\nb^{(\\varepsilon)} = \\begin{pmatrix} b_1^{(\\varepsilon)} \\\\ b_2^{(\\varepsilon)} \\\\ b_3^{(\\varepsilon)} \\end{pmatrix} = \\begin{pmatrix} \\varepsilon \\\\ \\varepsilon^2 \\\\ 1 \\end{pmatrix}\n$$\nwhere $\\varepsilon$ is a symbolic quantity satisfying $0 < \\varepsilon \\ll 1$. The problem states that the leaving variable is chosen by minimizing the ratio $b_i^{(\\varepsilon)}/a_{i1}$. This implies we are to find the step length for this perturbed problem. Let this step length be $\\theta_{\\text{lex}}$.\n$$\n\\theta_{\\text{lex}} = \\min \\left\\{ \\frac{b_i^{(\\varepsilon)}}{a_{i1}} : a_{i1} > 0 \\right\\}\n$$\nWe compute the ratios using the perturbed values:\nFor row $1$: $\\frac{b_1^{(\\varepsilon)}}{a_{11}} = \\frac{\\varepsilon}{1} = \\varepsilon$.\nFor row $2$: $\\frac{b_2^{(\\varepsilon)}}{a_{21}} = \\frac{\\varepsilon^2}{2}$.\nFor row $3$: $\\frac{b_3^{(\\varepsilon)}}{a_{31}} = \\frac{1}{1/2} = 2$.\n\nWe must find the minimum of these three values: $\\min\\{\\varepsilon, \\frac{\\varepsilon^2}{2}, 2\\}$. Since $\\varepsilon$ is a small positive number ($0 < \\varepsilon \\ll 1$), we know that $\\varepsilon^2$ is of a smaller order of magnitude than $\\varepsilon$. For instance, if $\\varepsilon < 2$, then $\\varepsilon^2 < 2\\varepsilon$, which implies $\\frac{\\varepsilon^2}{2} < \\varepsilon$. Also, for small $\\varepsilon$, we have $\\varepsilon < 2$. Thus, the ordering of the ratios is $\\frac{\\varepsilon^2}{2} < \\varepsilon < 2$.\nThe minimum ratio is $\\frac{\\varepsilon^2}{2}$, which corresponds to row $2$. The lexicographic rule thus selects row $2$ as the pivot row, and $s_2$ as the leaving variable. The step length under this procedure is the minimum ratio itself:\n$$\n\\theta_{\\text{lex}} = \\frac{\\varepsilon^2}{2}\n$$\nThe corresponding one-step change in the objective value (improvement) is calculated using this step length:\n$$\n\\Delta z_{\\text{lex}} = \\theta_{\\text{lex}} = \\frac{\\varepsilon^2}{2}\n$$\nThe perturbation has successfully broken the tie and produced a non-zero step length in the perturbed space, leading to a strict improvement in the objective function for any $\\varepsilon > 0$.\n\nThe final answer is the ordered pair $(\\Delta z_{\\text{naive}}, \\Delta z_{\\text{lex}})$.\n$$\n(\\Delta z_{\\text{naive}}, \\Delta z_{\\text{lex}}) = \\left(0, \\frac{\\varepsilon^2}{2}\\right)\n$$", "answer": "$$\n\\boxed{(0, \\frac{\\varepsilon^2}{2})}\n$$", "id": "3164060"}, {"introduction": "While any valid pricing rule will eventually lead to an optimum, the path taken can vary greatly in efficiency. This computational exercise [@problem_id:3164097] moves from theory to empirical analysis by comparing two famous pricing strategies: Dantzig's rule and the steepest-edge rule. By implementing these rules and testing them on randomly generated problems, you will gain insight into how different pivot selection criteria impact the per-pivot improvement in the objective function.", "problem": "Consider the linear programming minimization problem in standard form with a current basic feasible solution defined by a basis matrix and nonbasic variables at zero. The problem is posed as follows: minimize $z = c^\\top x$ subject to $A x = b$ and $x \\ge 0$, where $A \\in \\mathbb{R}^{m \\times n}$ is full row rank, $b \\in \\mathbb{R}^m$ is strictly positive, and $c \\in \\mathbb{R}^n$. Let the current basis be $B \\in \\mathbb{R}^{m \\times m}$ and the corresponding basic variables be $x_B = b$, with nonbasic variables $x_N = 0$. Define the reduced cost of a nonbasic column $j$ by $\\bar c_j = c_j - c_B^\\top B^{-1} A_j$, where $A_j$ is the $j$-th column of $A$ and $c_B$ are the cost coefficients of the basic variables. The primal simplex pivot along nonbasic variable $x_j$ changes basic variables by $x_B \\leftarrow x_B - \\theta \\, d_j$, where $d_j = B^{-1} A_j$ is the direction vector, and $\\theta$ is the ratio-test step length $\\theta = \\min_{i: (d_j)_i > 0} \\frac{(x_B)_i}{(d_j)_i}$.\n\nYour tasks are:\n\n1. Starting from these definitions, derive the exact expression for the objective value change $\\Delta z$ after one pivot that increases a single nonbasic variable $x_j$ by step length $\\theta$ while maintaining feasibility via the ratio test. Express $\\Delta z$ solely in terms of the reduced cost $\\bar c_j$ and the step length $\\theta$, and explain the sign convention for minimization regarding objective improvement.\n\n2. Implement a program that empirically evaluates the per-pivot objective improvement under two pricing rules for selecting the entering variable $x_j$:\n   - Dantzig pricing: choose the nonbasic index $j$ with the most negative reduced cost among those with finite ratio-test step length.\n   - Steepest-edge pricing: choose the nonbasic index $j$ that minimizes $\\bar c_j / \\lVert d_j \\rVert_2$ among those with $\\bar c_j < 0$ and finite ratio-test step length, where $\\lVert \\cdot \\rVert_2$ denotes the Euclidean norm.\n\nThe empirical evaluation must be conducted on randomly generated problems that guarantee a valid basic feasible solution. To ensure a tractable and reproducible setup, construct $A$ with an identity basis and a strictly positive nonbasis:\n- Set $B = I_m$ (the $m \\times m$ identity), so $B^{-1} = I_m$.\n- Construct $A = [B \\;|\\; N]$ by concatenating $B$ with $N \\in \\mathbb{R}^{m \\times (n-m)}$, where each entry of $N$ is strictly positive and drawn independently from a uniform distribution on a specified interval, so that $d_j = A_j$ for nonbasic $j$.\n- Draw $b$ with strictly positive entries from a specified uniform interval and set the current basic feasible solution as $x_B = b$ and $x_N = 0$.\n- Draw $c_B$ and $c_N$ from specified uniform intervals and compute reduced costs $\\bar c_j = c_N(j) - c_B^\\top d_j$ for all nonbasic $j$.\n\nWhen no eligible nonbasic index $j$ has $\\bar c_j < 0$ and a finite positive step length (that is, the problem is locally optimal at the current basis with respect to the nonbasic set), define both pricing rules’ objective improvements to be $0$.\n\nUse the following test suite, which covers a general case, a larger case, a boundary case with no negative reduced costs, and a case where the step length is very small. For each test case, use the given random seed and uniform ranges to generate independent draws as specified; all intervals are open, and uniform draws are over these intervals:\n- Test case $1$ (general “happy path”): $m = 3$, $n = 6$, seed $11$, $N \\sim U(0.2, 1.0)$, $b \\sim U(0.5, 2.0)$, $c_B \\sim U(0.5, 1.5)$, $c_N \\sim U(0.0, 1.0)$.\n- Test case $2$ (larger dimension): $m = 4$, $n = 9$, seed $27$, $N \\sim U(0.1, 1.5)$, $b \\sim U(0.2, 1.0)$, $c_B \\sim U(0.7, 1.3)$, $c_N \\sim U(0.0, 1.0)$.\n- Test case $3$ (boundary, locally optimal: enforce $\\bar c_j \\ge 0$ for all nonbasic $j$ by adding a nonnegative offset to $c_N$ after initial draws): $m = 3$, $n = 7$, seed $101$, $N \\sim U(0.2, 0.6)$, $b \\sim U(0.5, 1.5)$, $c_B \\sim U(0.1, 0.2)$, base $c_N \\sim U(0.3, 0.5)$, then compute $\\bar c_j$ and if any $\\bar c_j < 0$, add an offset $\\delta \\ge 0$ to all entries of $c_N$ so that $\\min_j \\bar c_j$ becomes $0$.\n- Test case $4$ (very small step lengths): $m = 5$, $n = 10$, seed $5$, $N \\sim U(0.8, 1.2)$, $b \\sim U(0.01, 0.05)$, $c_B \\sim U(1.0, 2.0)$, $c_N \\sim U(0.1, 0.5)$.\n\nFor each test case, compute and report two floats: the objective improvement per pivot under Dantzig pricing and under steepest-edge pricing. Objective improvement must be defined as the positive decrease in the minimization objective, namely $\\Delta z = -\\bar c_j \\, \\theta$. If there is no eligible entering index, report $0$ for both rules.\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, where each element is itself a list with two floats in the order $[\\Delta z_{\\text{Dantzig}}, \\Delta z_{\\text{Steepest}}]$ for the corresponding test case. For example, the output format is $[[r_{11}, r_{12}], [r_{21}, r_{22}], [r_{31}, r_{32}], [r_{41}, r_{42}]]$.", "solution": "The problem requires two tasks: first, to derive the expression for the objective value change, $\\Delta z$, after one simplex pivot, and second, to implement an empirical comparison of two pricing rules (Dantzig's and steepest-edge) on a set of generated linear programming problems.\n\n### Part 1: Derivation of Objective Value Change\n\nWe begin with the linear programming problem in standard form:\n$$\n\\text{minimize } z = c^\\top x \\\\\n\\text{subject to } A x = b, \\quad x \\ge 0\n$$\nwhere $A \\in \\mathbb{R}^{m \\times n}$, $b \\in \\mathbb{R}^m$, and $c \\in \\mathbb{R}^n$. The vector of variables $x$ is partitioned into basic variables $x_B$ and nonbasic variables $x_N$. The matrix $A$ is partitioned accordingly into a basis matrix $B$ and a nonbasic matrix $N$, so that $A = [B \\mid N]$. The constraints can be written as $B x_B + N x_N = b$.\n\nAt a given basic feasible solution (BFS), the nonbasic variables are set to zero, $x_N = 0$. The basic variables are then determined by the constraints: $x_B = B^{-1} b$. The objective function value at this solution is:\n$$\nz_{old} = c_B^\\top x_B + c_N^\\top x_N = c_B^\\top (B^{-1} b) + c_N^\\top 0 = c_B^\\top B^{-1} b\n$$\n\nA pivot operation involves selecting one nonbasic variable, say $x_j$ where $j$ is a nonbasic index, to increase from $0$ to a positive value $\\theta$. All other nonbasic variables remain at $0$. To maintain feasibility ($A x = b$), the basic variables must adjust. The new solution, $x^{new}$, is defined by:\n- $x_j^{new} = \\theta$ for the entering nonbasic variable.\n- $x_k^{new} = 0$ for all other nonbasic variables $k \\ne j$.\n- $x_B^{new}$ is determined by the constraint $B x_B^{new} + A_j x_j^{new} = b$.\n\nFrom the constraint, we solve for $x_B^{new}$:\n$$\nx_B^{new} = B^{-1}(b - A_j x_j^{new}) = B^{-1} b - B^{-1} A_j \\theta\n$$\nLet's define the direction vector $d_j = B^{-1} A_j$. The initial basic solution is $x_B^{old} = B^{-1} b$. Thus, the update rule for the basic variables is:\n$$\nx_B^{new} = x_B^{old} - \\theta d_j\n$$\nThe value of $\\theta$ is determined by the ratio test to ensure that feasibility ($x_B^{new} \\ge 0$) is maintained:\n$$\n\\theta = \\min_{i: (d_j)_i > 0} \\frac{(x_B^{old})_i}{(d_j)_i}\n$$\nNow, we can compute the new objective value, $z_{new}$:\n$$\nz_{new} = c_B^\\top x_B^{new} + c_N^\\top x_N^{new}\n$$\nThe only non-zero component of $x_N^{new}$ is $x_j = \\theta$, with its corresponding cost coefficient $c_j$. The term $c_N^\\top x_N^{new}$ simplifies to $c_j \\theta$.\n$$\nz_{new} = c_B^\\top (x_B^{old} - \\theta d_j) + c_j \\theta \\\\\n= c_B^\\top x_B^{old} - \\theta (c_B^\\top d_j) + c_j \\theta\n$$\nRecognizing that $z_{old} = c_B^\\top x_B^{old}$, we can write:\n$$\nz_{new} = z_{old} + \\theta (c_j - c_B^\\top d_j)\n$$\nThe change in the objective value, $\\Delta z = z_{new} - z_{old}$, is therefore:\n$$\n\\Delta z = \\theta (c_j - c_B^\\top d_j)\n$$\nThe term $(c_j - c_B^\\top d_j)$ is the reduced cost of the nonbasic variable $x_j$. Substituting $d_j = B^{-1} A_j$, we get the standard definition of the reduced cost $\\bar{c}_j$:\n$$\n\\bar{c}_j = c_j - c_B^\\top B^{-1} A_j\n$$\nThus, the change in the objective value is precisely:\n$$\n\\Delta z = \\bar{c}_j \\theta\n$$\nThis expression gives the change in $z$ solely in terms of the reduced cost $\\bar{c}_j$ and the step length $\\theta$.\n\nFor a minimization problem, the objective value \"improves\" when it decreases. This means we seek a negative change, $\\Delta z < 0$. Since the step length $\\theta$ (for a non-degenerate pivot) is strictly positive, an improvement requires that the reduced cost of the entering variable be negative, i.e., $\\bar{c}_j < 0$. The problem defines \"objective improvement\" as the magnitude of this decrease, which is a positive value:\n$$\n\\text{Improvement} = - \\Delta z = - \\bar{c}_j \\theta\n$$\n\n### Part 2: Algorithmic Implementation\n\nThe provided Python code implements the logic to evaluate the objective improvement for two different pricing rules on a series of randomly generated test cases. The implementation follows these steps:\n\n1.  **Problem Generation**: For each test case, a linear programming instance is constructed according to the specified parameters ($m$, $n$, seed, and uniform distribution ranges). The setup is simplified by choosing the basis matrix $B$ to be the identity matrix, $B = I_m$. This implies $B^{-1} = I_m$. The constraint matrix $A$ is formed as $A = [I_m \\mid N]$, where $N \\in \\mathbb{R}^{m \\times (n-m)}$ is a matrix with strictly positive entries drawn from a uniform distribution. The initial basic feasible solution is $x_B = b$ and $x_N = 0$, which is guaranteed to be feasible since $b$ is drawn with strictly positive entries.\n\n2.  **Reduced Cost Calculation**: With $B=I_m$, the direction vector $d_j$ for a nonbasic column $A_j$ (which is a column from $N$) simplifies to $d_j = B^{-1} A_j = I_m A_j = A_j$. The reduced costs for the nonbasic variables are computed as $\\bar{c}_j = c_j - c_B^\\top d_j = c_j - c_B^\\top A_j$. This is implemented efficiently using matrix-vector operations.\n\n3.  **Eligible Variable Identification**: A nonbasic variable $x_j$ is eligible to enter the basis if it can lead to an objective improvement, which requires $\\bar{c}_j < 0$. The problem also mentions a \"finite ratio-test step length.\" In our constructed problems, since all entries of $N$ (the direction vectors) and $b$ (the basic variables) are strictly positive, the ratio test $\\theta_j = \\min_{i} (b_i / (d_j)_i)$ will always yield a finite, positive value. Thus, the set of eligible entering variables consists of all nonbasic variables $j$ for which $\\bar{c}_j < 0$. If no such variables exist, the current solution is locally optimal, and the improvement for both pricing rules is $0$.\n\n4.  **Dantzig's Pricing Rule**: This rule selects the entering nonbasic variable $x_j$ with the most negative reduced cost. The index $j_D$ is found by $j_D = \\arg\\min_{j} \\{\\bar{c}_j \\mid \\bar{c}_j < 0\\}$. The corresponding step length $\\theta_{j_D}$ is calculated via the ratio test, and the objective improvement is $-\\bar{c}_{j_D} \\theta_{j_D}$.\n\n5.  **Steepest-Edge Pricing Rule**: This rule selects the entering nonbasic variable $x_j$ that minimizes the ratio of the reduced cost to the Euclidean norm of its direction vector, $\\bar{c}_j / \\lVert d_j \\rVert_2$. The index $j_S$ is found by $j_S = \\arg\\min_{j} \\{\\bar{c}_j / \\lVert d_j \\rVert_2 \\mid \\bar{c}_j < 0\\}$. The step length $\\theta_{j_S}$ is calculated for this variable, and the improvement is $-\\bar{c}_{j_S} \\theta_{j_S}$.\n\n6.  **Special Case Handling**: For Test Case 3, a non-negative offset $\\delta$ is added to the initially generated costs $c_N$ to ensure that all final reduced costs are non-negative ($\\min_j \\bar{c}_j = 0$). This is achieved by calculating the initial minimal reduced cost, $rc_{min}$, and if it's negative, setting $\\delta = -rc_{min}$. This forces the set of eligible entering variables to be empty, correctly yielding an improvement of $0$ for both pricing rules.\n\nThe code systematically applies this logic to each test case and formats the resulting pairs of objective improvements, $[\\Delta z_{\\text{Dantzig}}, \\Delta z_{\\text{Steepest}}]$, into the required final output format.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve_case(m, n, seed, N_range, b_range, cB_range, cN_range, is_case3=False):\n    \"\"\"\n    Solves a single test case for the LP pricing rule comparison.\n\n    Args:\n        m (int): Number of constraints (basic variables).\n        n (int): Number of variables.\n        seed (int): Random seed for reproducibility.\n        N_range (tuple): Uniform range for non-basic matrix N.\n        b_range (tuple): Uniform range for vector b.\n        cB_range (tuple): Uniform range for basic costs c_B.\n        cN_range (tuple): Uniform range for non-basic costs c_N.\n        is_case3 (bool): Flag for special handling of Test Case 3.\n\n    Returns:\n        list[float, float]: A list containing the objective improvements for\n                            Dantzig and steepest-edge rules.\n    \"\"\"\n    rng = np.random.default_rng(seed)\n    \n    num_nonbasic = n - m\n    \n    # Generate problem data based on the specified distributions.\n    # The basis B is implicitly the identity matrix I_m.\n    # N represents the non-basic columns of the constraint matrix A.\n    N = rng.uniform(N_range[0], N_range[1], size=(m, num_nonbasic))\n    \n    # b represents the values of the basic variables in the initial solution.\n    b = rng.uniform(b_range[0], b_range[1], size=m)\n    \n    # c_B and c_N are the cost coefficients for basic and non-basic variables.\n    c_B = rng.uniform(cB_range[0], cB_range[1], size=m)\n    c_N_base = rng.uniform(cN_range[0], cN_range[1], size=num_nonbasic)\n\n    # Calculate reduced costs for all non-basic variables.\n    # Since B = I, the direction vector d_j is simply the j-th column of N.\n    # The reduced cost is \\bar{c}_j = c_j - c_B^T d_j.\n    # In vector form: \\bar{c}_N = c_N - N^T c_B.\n    reduced_costs = c_N_base - N.T @ c_B\n    \n    if is_case3:\n        # For Test Case 3, adjust costs to ensure all reduced costs are non-negative.\n        min_rc = np.min(reduced_costs) if reduced_costs.size > 0 else 0\n        if min_rc  0:\n            # Add an offset delta = -min_rc to make the minimum reduced cost zero.\n            delta = -min_rc\n            reduced_costs += delta\n            \n    # Identify eligible non-basic variables (those with negative reduced cost).\n    # The 'finite step length' condition is always met since N > 0 and b > 0.\n    eligible_indices = np.where(reduced_costs  0)[0]\n    \n    if eligible_indices.size == 0:\n        # No eligible entering variable, so no improvement is possible.\n        return [0.0, 0.0]\n        \n    # --- Dantzig's Rule ---\n    # Select the variable with the most negative reduced cost.\n    dantzig_idx_in_eligible = np.argmin(reduced_costs[eligible_indices])\n    dantzig_j = eligible_indices[dantzig_idx_in_eligible]\n    \n    rc_dantzig = reduced_costs[dantzig_j]\n    d_dantzig = N[:, dantzig_j]\n    \n    # Perform the ratio test to find the step length theta.\n    # theta = min(x_B / d_j) where (d_j)_i > 0 for all i.\n    theta_dantzig = np.min(b / d_dantzig)\n    \n    # Objective improvement is -(\\bar{c}_j * theta).\n    improvement_dantzig = -rc_dantzig * theta_dantzig\n    \n    # --- Steepest-Edge Rule ---\n    # Select the variable that minimizes \\bar{c}_j / ||d_j||_2.\n    eligible_rcs = reduced_costs[eligible_indices]\n    eligible_d_vectors = N[:, eligible_indices]\n    \n    # Calculate L2 norms of the direction vectors for eligible variables.\n    norms = np.linalg.norm(eligible_d_vectors, axis=0)\n    \n    steepest_edge_scores = eligible_rcs / norms\n    \n    steepest_idx_in_eligible = np.argmin(steepest_edge_scores)\n    steepest_j = eligible_indices[steepest_idx_in_eligible]\n    \n    rc_steepest = reduced_costs[steepest_j]\n    d_steepest = N[:, steepest_j]\n    \n    # Perform the ratio test for the chosen variable.\n    theta_steepest = np.min(b / d_steepest)\n    \n    improvement_steepest = -rc_steepest * theta_steepest\n    \n    return [improvement_dantzig, improvement_steepest]\n\ndef solve():\n    \"\"\"\n    Main function to run all test cases and print results.\n    \"\"\"\n    test_cases = [\n        # (m, n, seed, N_range, b_range, cB_range, cN_range, is_case3)\n        (3, 6, 11, (0.2, 1.0), (0.5, 2.0), (0.5, 1.5), (0.0, 1.0), False),\n        (4, 9, 27, (0.1, 1.5), (0.2, 1.0), (0.7, 1.3), (0.0, 1.0), False),\n        (3, 7, 101, (0.2, 0.6), (0.5, 1.5), (0.1, 0.2), (0.3, 0.5), True),\n        (5, 10, 5, (0.8, 1.2), (0.01, 0.05), (1.0, 2.0), (0.1, 0.5), False),\n    ]\n\n    results = []\n    for params in test_cases:\n        result = solve_case(*params)\n        results.append(result)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "3164097"}]}