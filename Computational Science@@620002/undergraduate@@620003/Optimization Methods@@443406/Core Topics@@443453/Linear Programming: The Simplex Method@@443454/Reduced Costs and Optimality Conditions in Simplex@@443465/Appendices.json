{"hands_on_practices": [{"introduction": "Understanding the simplex method begins with a firm grasp of its core components. This first exercise [@problem_id:3171622] guides you through computing dual variables (shadow prices) and reduced costs from their fundamental definitions. By working through this specific linear programming example, you will reinforce the connection between the algebraic machinery of the simplex algorithm and the powerful economic interpretation of these values as marginal gains.", "problem": "Consider the Linear Program (LP) in standard form for a maximization problem with decision variables $x_1$, $x_2$, $x_3$ and slack variables $s_1$, $s_2$:\n$$\n\\text{maximize } z \\;=\\; 5 x_1 \\;+\\; 3 x_2 \\;+\\; 4 x_3\n$$\nsubject to\n$$\n2 x_1 \\;+\\; 1 x_2 \\;+\\; 1 x_3 \\;+\\; s_1 \\;=\\; 8,\n$$\n$$\n1 x_1 \\;+\\; 2 x_2 \\;+\\; 3 x_3 \\;+\\; s_2 \\;=\\; 12,\n$$\n$$\nx_1, x_2, x_3, s_1, s_2 \\;\\ge\\; 0.\n$$\nSuppose the current basis consists of the columns associated with $x_1$ and $x_3$. The nonbasic variables are $x_2$, $s_1$, and $s_2$, set to $0$. Using only core definitions from the simplex method (that is, the characterization of the induced dual variables and reduced costs at a given basis), do the following:\n\n1. Compute the dual price vector $y$ associated with the two constraints, induced by this basis.\n2. Interpret the components $y_1$ and $y_2$ as marginal values (shadow prices) of the right-hand-side resources $8$ and $12$, respectively.\n3. For the nonbasic decision variable $x_2$, compute its reduced cost $\\bar c_2$ and verify that it equals the marginal net gain of increasing $x_2$ by one unit while staying feasible by appropriately adjusting the basic variables.\n4. Report the numerical value of $\\bar c_2$ as your final answer. Express your final value as an exact rational number. No rounding is required. Do not include units.\n\nYour analysis must be self-contained and start from the fundamental definition of the LP in standard form and the induced dual variables and reduced costs at a given basis, without appealing to any shortcut formulas.", "solution": "The problem statement constitutes a valid linear programming problem. All data and conditions are provided, the problem is self-contained, scientifically grounded in the theory of optimization, and well-posed. We may proceed with the solution.\n\nThe given linear program (LP) is in standard form for a maximization problem:\n$$\n\\text{maximize } z \\;=\\; c^T x\n$$\nsubject to\n$$\nAx \\;=\\; b, \\quad x \\;\\ge\\; 0.\n$$\nFrom the problem statement, we identify the components. The complete vector of variables is $x = [x_1, x_2, x_3, s_1, s_2]^T$. The cost vector is $c = [5, 3, 4, 0, 0]^T$. The constraint matrix $A$ and the right-hand-side vector $b$ are:\n$$\nA = \\begin{pmatrix} 2  1  1  1  0 \\\\ 1  2  3  0  1 \\end{pmatrix}, \\quad b = \\begin{pmatrix} 8 \\\\ 12 \\end{pmatrix}.\n$$\nThe problem specifies that the current basis consists of the columns associated with variables $x_1$ and $x_3$. We partition the variables, costs, and matrix $A$ into basic and nonbasic components. The set of basic variable indices is $\\mathcal{B} = \\{1, 3\\}$, and the set of nonbasic variable indices is $\\mathcal{N} = \\{2, 4, 5\\}$, corresponding to variables $x_2, s_1, s_2$.\n\nThe basic variables are $x_B = [x_1, x_3]^T$, and the nonbasic variables are $x_N = [x_2, s_1, s_2]^T$.\nThe basis matrix $B$ is formed by the columns of $A$ corresponding to the basic variables:\n$$\nB = \\begin{pmatrix} 2  1 \\\\ 1  3 \\end{pmatrix}.\n$$\nThe nonbasic matrix $N$ is formed by the columns of $A$ for the nonbasic variables:\n$$\nN = \\begin{pmatrix} 1  1  0 \\\\ 2  0  1 \\end{pmatrix}.\n$$\nThe cost vector is partitioned similarly into $c_B = [5, 4]^T$ and $c_N = [3, 0, 0]^T$.\n\nWith the nonbasic variables set to zero ($x_N=0$), the system of constraints $Ax=b$ reduces to $Bx_B = b$. The current basic solution is $x_B = B^{-1}b$.\nThe inverse of the basis matrix $B$ is:\n$$\nB^{-1} = \\frac{1}{(2)(3) - (1)(1)} \\begin{pmatrix} 3  -1 \\\\ -1  2 \\end{pmatrix} = \\frac{1}{5} \\begin{pmatrix} 3  -1 \\\\ -1  2 \\end{pmatrix} = \\begin{pmatrix} \\frac{3}{5}  -\\frac{1}{5} \\\\ -\\frac{1}{5}  \\frac{2}{5} \\end{pmatrix}.\n$$\nThe values of the basic variables are:\n$$\nx_B = \\begin{pmatrix} x_1 \\\\ x_3 \\end{pmatrix} = \\begin{pmatrix} \\frac{3}{5}  -\\frac{1}{5} \\\\ -\\frac{1}{5}  \\frac{2}{5} \\end{pmatrix} \\begin{pmatrix} 8 \\\\ 12 \\end{pmatrix} = \\begin{pmatrix} \\frac{24}{5} - \\frac{12}{5} \\\\ -\\frac{8}{5} + \\frac{24}{5} \\end{pmatrix} = \\begin{pmatrix} \\frac{12}{5} \\\\ \\frac{16}{5} \\end{pmatrix}.\n$$\nSince $x_1 = 12/5 \\ge 0$ and $x_3 = 16/5 \\ge 0$, this is a basic feasible solution.\n\n**1. Computation of the Dual Price Vector**\n\nThe dual price vector (or vector of simplex multipliers) $y = [y_1, y_2]^T$ is defined by the condition that the reduced costs of the basic variables are zero. This leads to the equation:\n$$\ny^T B = c_B^T.\n$$\nSubstituting the matrices $B$ and $c_B^T$:\n$$\n\\begin{pmatrix} y_1  y_2 \\end{pmatrix} \\begin{pmatrix} 2  1 \\\\ 1  3 \\end{pmatrix} = \\begin{pmatrix} 5  4 \\end{pmatrix}.\n$$\nThis gives the following system of linear equations:\n$$\n2y_1 + y_2 = 5\n$$\n$$\ny_1 + 3y_2 = 4\n$$\nFrom the second equation, we express $y_1$ as $y_1 = 4 - 3y_2$. Substituting this into the first equation:\n$$\n2(4 - 3y_2) + y_2 = 5\n$$\n$$\n8 - 6y_2 + y_2 = 5\n$$\n$$\n8 - 5y_2 = 5 \\implies 5y_2 = 3 \\implies y_2 = \\frac{3}{5}.\n$$\nSubstituting the value of $y_2$ back into the expression for $y_1$:\n$$\ny_1 = 4 - 3\\left(\\frac{3}{5}\\right) = 4 - \\frac{9}{5} = \\frac{20 - 9}{5} = \\frac{11}{5}.\n$$\nThus, the dual price vector is $y = [\\frac{11}{5}, \\frac{3}{5}]^T$.\n\n**2. Interpretation of the Dual Prices**\n\nThe components of the dual vector $y$ are the shadow prices associated with the constraints. The objective function value at a basic feasible solution is $z = c_B^T x_B$. Since $x_B = B^{-1}b$, we can write $z = c_B^T B^{-1} b$. From the definition $y^T = c_B^T B^{-1}$, we have $z = y^T b = \\sum_i y_i b_i$.\nThe derivative of the objective function value with respect to the $i$-th right-hand-side resource value $b_i$ is $\\frac{\\partial z}{\\partial b_i} = y_i$, assuming the basis remains optimal.\nTherefore, $y_1 = \\frac{11}{5}$ is the marginal value of the first resource. If the right-hand-side of the first constraint were to increase from $8$ to $9$, the optimal objective value would be expected to increase by $\\frac{11}{5} = 2.2$.\nSimilarly, $y_2 = \\frac{3}{5}$ is the marginal value of the second resource. A one-unit increase in the second resource, from $12$ to $13$, would be expected to increase the optimal objective value by $\\frac{3}{5} = 0.6$.\n\n**3. Computation and Verification of the Reduced Cost $\\bar{c}_2$**\n\nThe reduced cost $\\bar{c}_j$ for a nonbasic variable $x_j$ is defined as the rate of change of the objective function per unit increase of $x_j$. It is calculated by the formula:\n$$\n\\bar{c}_j = c_j - y^T A_j\n$$\nwhere $A_j$ is the column of the original matrix $A$ corresponding to $x_j$. For the nonbasic variable $x_2$ (where $j=2$), we have $c_2 = 3$ and $A_2 = [1, 2]^T$.\nUsing the calculated dual vector $y$:\n$$\n\\bar{c}_2 = 3 - \\begin{pmatrix} \\frac{11}{5}  \\frac{3}{5} \\end{pmatrix} \\begin{pmatrix} 1 \\\\ 2 \\end{pmatrix} = 3 - \\left( \\frac{11}{5} \\cdot 1 + \\frac{3}{5} \\cdot 2 \\right) = 3 - \\left( \\frac{11}{5} + \\frac{6}{5} \\right) = 3 - \\frac{17}{5}.\n$$\n$$\n\\bar{c}_2 = \\frac{15}{5} - \\frac{17}{5} = -\\frac{2}{5}.\n$$\nNow, we verify this value by analyzing the marginal net gain. Let us increase the nonbasic variable $x_2$ by a small amount $\\epsilon  0$, while the other nonbasic variables $s_1$ and $s_2$ remain at $0$. To maintain feasibility, the basic variables $x_B$ must adjust. The constraint system $Bx_B + Nx_N = b$ becomes $Bx_B + A_2 x_2 = b$.\nThe new vector of basic variables, $x_B(\\epsilon)$, is given by:\n$$\nx_B(\\epsilon) = B^{-1}(b - A_2 \\epsilon) = B^{-1}b - B^{-1}A_2 \\epsilon = x_B(0) - (B^{-1}A_2)\\epsilon.\n$$\nThe vector $d = B^{-1}A_2$ represents how the basic variables must change. Let's compute it:\n$$\nd = \\begin{pmatrix} \\frac{3}{5}  -\\frac{1}{5} \\\\ -\\frac{1}{5}  \\frac{2}{5} \\end{pmatrix} \\begin{pmatrix} 1 \\\\ 2 \\end{pmatrix} = \\begin{pmatrix} \\frac{3}{5} - \\frac{2}{5} \\\\ -\\frac{1}{5} + \\frac{4}{5} \\end{pmatrix} = \\begin{pmatrix} \\frac{1}{5} \\\\ \\frac{3}{5} \\end{pmatrix}.\n$$\nSo, $\\Delta x_B = -d\\epsilon$, which means $\\Delta x_1 = -\\frac{1}{5}\\epsilon$ and $\\Delta x_3 = -\\frac{3}{5}\\epsilon$. For every unit increase in $x_2$, $x_1$ must decrease by $\\frac{1}{5}$ units and $x_3$ must decrease by $\\frac{3}{5}$ units to satisfy the constraints.\n\nThe change in the objective function, $\\Delta z$, is the sum of the direct gain from increasing $x_2$ and the indirect loss from adjusting $x_B$:\n$$\n\\Delta z = c_2 \\epsilon + c_B^T \\Delta x_B = c_2 \\epsilon + c_B^T (-d \\epsilon) = (c_2 - c_B^T d)\\epsilon.\n$$\nThe marginal net gain is $\\frac{\\Delta z}{\\epsilon} = c_2 - c_B^T d$. Let's compute this value:\n$$\nc_B^T d = \\begin{pmatrix} 5  4 \\end{pmatrix} \\begin{pmatrix} \\frac{1}{5} \\\\ \\frac{3}{5} \\end{pmatrix} = 5\\left(\\frac{1}{5}\\right) + 4\\left(\\frac{3}{5}\\right) = 1 + \\frac{12}{5} = \\frac{5+12}{5} = \\frac{17}{5}.\n$$\nThis value, $\\frac{17}{5}$, represents the cost incurred by adjusting the basic variables for a unit increase in $x_2$.\nThe direct gain from a unit increase in $x_2$ is $c_2 = 3 = \\frac{15}{5}$.\nThe marginal net gain is therefore:\n$$\n\\frac{\\Delta z}{\\epsilon} = c_2 - c_B^T d = 3 - \\frac{17}{5} = \\frac{15 - 17}{5} = -\\frac{2}{5}.\n$$\nThis result confirms that the reduced cost $\\bar{c}_2 = -\\frac{2}{5}$ is indeed the marginal net gain of increasing $x_2$ by one unit. A negative reduced cost in a maximization problem indicates that increasing the corresponding nonbasic variable will decrease the objective function value. The optimality condition for maximization requires all non-basic reduced costs to be less than or equal to zero. Since $\\bar{c}_2 = -2/5$, this variable meets the optimality condition.\n\n**4. Final Answer**\n\nThe numerical value of the reduced cost $\\bar{c}_2$ is $-\\frac{2}{5}$.", "answer": "$$\\boxed{-\\frac{2}{5}}$$", "id": "3171622"}, {"introduction": "A common heuristic in the simplex method is to select the entering variable with the most promising reduced cost. However, is this always the best single-step move? This practice [@problem_id:3171541] presents a scenario designed to illustrate the critical distinction between the *rate* of improvement (given by the reduced cost) and the *total* improvement achieved in one pivot, which also depends on the maximum allowable step size. This exercise will deepen your understanding of pivot selection strategies and the trade-offs involved.", "problem": "Consider the following Linear Programming (LP) problem in equality form suitable for the primal simplex method applied to a minimization problem:\nMinimize $z = -1 \\cdot x_1 + (-10) \\cdot x_2 + 0 \\cdot s_1 + 0 \\cdot s_2$ subject to\n$0.05 \\cdot x_1 + 100 \\cdot x_2 + s_1 = 10$,\n$0.009 \\cdot x_1 + 1 \\cdot x_2 + s_2 = 2$,\n$x_1, x_2, s_1, s_2 \\ge 0$.\nAt the current Basic Feasible Solution (BFS), the basis consists of the slack variables $s_1$ and $s_2$, so $x_1 = 0$, $x_2 = 0$, $s_1 = 10$, and $s_2 = 2$.\n\nUsing only the fundamental definitions that (i) the reduced cost of a nonbasic variable in the primal simplex equals its marginal change in the objective per unit increase in that variable at the current BFS, and (ii) feasibility of the primal move limits the step by the smallest ratio of current basic values to the corresponding positive entries in the entering column, determine which nonbasic variable $x_1$ or $x_2$, if chosen to enter the basis from this BFS, yields the larger single-pivot decrease in the objective value, and what that decrease is. Select the best answer.\n\nA. Enter $x_1$; the objective decreases by $200$.\nB. Enter $x_2$; the objective decreases by $1$.\nC. Enter $x_2$; the objective decreases by $10$.\nD. Both $x_1$ and $x_2$ yield the same decrease.", "solution": "We start from first principles for the primal simplex method on a minimization problem in equality form.\n\nAt the given BFS, the basis matrix $B$ is the identity (formed by $s_1$ and $s_2$), so $B^{-1} = I$, the basic cost vector is $c_B = (0, 0)$, and the associated dual vector is $y^\\top = c_B^\\top B^{-1} = (0, 0)$. For any nonbasic variable $x_j$, the reduced cost $\\bar c_j$ equals $c_j - a_j^\\top y$. Since $y = 0$, we have $\\bar c_j = c_j$ for all nonbasic variables at this BFS.\n\nTherefore:\n- For $x_1$, $c_1 = -1$, so $\\bar c_1 = -1$.\n- For $x_2$, $c_2 = -10$, so $\\bar c_2 = -10$.\n\nIn a minimization problem, a negative reduced cost indicates that increasing the corresponding nonbasic variable reduces the objective value. The instantaneous rate of decrease in $z$ from increasing $x_j$ is $\\bar c_j$ per unit of $x_j$. However, feasibility restricts how far we can move. If $x_j$ enters and increases by step $\\theta \\ge 0$, then the basic variables update as $x_B(\\theta) = B^{-1} b - \\theta \\cdot B^{-1} a_j = b - \\theta \\cdot a_j$ (because $B^{-1} = I$ here), and primal feasibility requires $x_B(\\theta) \\ge 0$. Hence the maximum feasible step is\n$\\theta^\\star = \\min\\{ b_i / a_{ij} : a_{ij}  0 \\}$.\nThe total one-pivot change in the objective is then $\\Delta z = \\bar c_j \\cdot \\theta^\\star$.\n\nCompute the entering-direction columns and step lengths:\n\n- Column for $x_1$ is $a_1 = \\begin{pmatrix} 0.05 \\\\ 0.009 \\end{pmatrix}$. With $b = \\begin{pmatrix} 10 \\\\ 2 \\end{pmatrix}$, the allowable step is\n$\\theta^\\star_1 = \\min\\left\\{ \\dfrac{10}{0.05}, \\dfrac{2}{0.009} \\right\\} = \\min\\{ 200, 222.\\overline{2} \\} = 200$.\nThe objective change is\n$\\Delta z_1 = \\bar c_1 \\cdot \\theta^\\star_1 = (-1) \\cdot 200 = -200$,\nso the objective decreases by $200$.\n\n- Column for $x_2$ is $a_2 = \\begin{pmatrix} 100 \\\\ 1 \\end{pmatrix}$. The allowable step is\n$\\theta^\\star_2 = \\min\\left\\{ \\dfrac{10}{100}, \\dfrac{2}{1} \\right\\} = \\min\\{ 0.1, 2 \\} = 0.1$.\nThe objective change is\n$\\Delta z_2 = \\bar c_2 \\cdot \\theta^\\star_2 = (-10) \\cdot 0.1 = -1$,\nso the objective decreases by $1$.\n\nComparing the total improvements, entering $x_1$ yields a much larger one-pivot decrease in the objective than entering $x_2$, despite $x_2$ having a more negative reduced cost. This illustrates the trade-off: the total one-step gain is the product of the reduced cost magnitude and the maximum feasible step length, and a mildly negative reduced cost can dominate if it allows a much larger step due to the ratio test.\n\nOption-by-option analysis:\n- A. Enter $x_1$; the objective decreases by $200$. This matches $\\Delta z_1 = -200$ and is the larger decrease. Correct.\n- B. Enter $x_2$; the objective decreases by $1$. While the computed decrease for $x_2$ is indeed $1$, this is not the larger decrease, and the statement prescribes entering $x_2$ as the maximizing choice. Incorrect.\n- C. Enter $x_2$; the objective decreases by $10$. This confuses the reduced cost magnitude with the total improvement and ignores the step limit. Incorrect.\n- D. Both $x_1$ and $x_2$ yield the same decrease. They do not: $200$ versus $1$. Incorrect.", "answer": "$$\\boxed{A}$$", "id": "3171541"}, {"introduction": "Moving from pure theory to computational practice reveals new challenges, such as the inaccuracies of floating-point arithmetic. This problem [@problem_id:3171526] simulates a realistic scenario where computed reduced costs are not exactly zero but very close, due to roundoff errors. You will learn how to apply a numerical tolerance to make robust decisions about optimality, a crucial skill for implementing any numerical optimization algorithm. This practice bridges the gap between textbook algorithms and their practical, stable implementation.", "problem": "Consider a linear programming problem in standard form, maximize $c^{\\top}x$ subject to $Ax=b$, $x \\ge 0$. Let the current basic feasible solution correspond to a basis matrix $B$, with basic cost vector $c_B$, and let the associated dual vector be $y^{\\top} = c_B^{\\top}B^{-1}$. The reduced cost of a nonbasic variable $x_j$ is defined by $\\bar c_j = c_j - y^{\\top}a_j$, where $a_j$ is the $j$-th column of $A$. For a maximization problem, if the current solution is primal feasible, the necessary and sufficient optimality condition is that all nonbasic reduced costs satisfy $\\bar c_j \\le 0$. If any $\\bar c_j  0$, introducing $x_j$ into the basis can improve the objective.\n\nIn practice, when forming the simplex tableau with floating-point arithmetic, rounding can make a theoretically zero reduced cost appear slightly positive or slightly negative. To mitigate this, one uses a tolerance $\\tau  0$ and applies the rule: treat $\\bar c_j$ as zero whenever $|\\bar c_j|  \\tau$, and select an entering variable only among those with $\\bar c_j  \\tau$.\n\nAssume the current objective (reduced cost) row for the nonbasic variables has been computed and printed with roundoff such that each reported reduced cost $\\bar c_j$ has an absolute uncertainty bounded by $|\\Delta \\bar c_j| \\le 7 \\times 10^{-4}$. The reported reduced costs for the nonbasic variables are:\n- $\\bar c_3 = 0.00007$,\n- $\\bar c_4 = 0.00970$,\n- $\\bar c_5 = -0.00006$.\n\nThese magnitudes are consistent with coefficients of order $1$ in $A$ and $c$. Small negative values on the order of $10^{-4}$ can be caused by roundoff even when the true value is zero.\n\nWhich option both proposes a tolerance $\\tau$ that is consistent with the stated uncertainty and correctly applies the $|\\bar c_j|  \\tau$ handling rule to decide whether the current basic feasible solution is optimal and, if not, which nonbasic variable(s) are eligible to enter the basis?\n\nA. Choose $\\tau = 10^{-8}$; the current solution is not optimal; $x_3$ and $x_4$ are eligible to enter.\n\nB. Choose $\\tau = 10^{-4}$; the current solution is not optimal; $x_4$ is the only eligible entering variable.\n\nC. Choose $\\tau = 10^{-3}$; the current solution is not optimal; $x_4$ is the only eligible entering variable.\n\nD. Choose $\\tau = 10^{-2}$; declare the current solution optimal; no variable is eligible to enter.", "solution": "The user has provided a problem statement regarding the application of numerical tolerances in the simplex method for linear programming.\n\n### Problem Validation\n\n**Step 1: Extract Givens**\n- **LP Problem Form**: Maximize $c^{\\top}x$ subject to $Ax=b$, $x \\ge 0$.\n- **Reduced Cost**: For a nonbasic variable $x_j$, the reduced cost is $\\bar c_j = c_j - y^{\\top}a_j$.\n- **Optimality Condition (Maximization)**: The current basic feasible solution is optimal if $\\bar c_j \\le 0$ for all nonbasic variables $j$.\n- **Numerical Tolerance Rule**: A tolerance $\\tau  0$ is used. A computed reduced cost $\\bar c_j$ is treated as zero if $|\\bar c_j|  \\tau$. An entering variable is selected only from those with a computed reduced cost $\\bar c_j  \\tau$. If no such variable exists, the current solution is declared optimal.\n- **Numerical Uncertainty**: The absolute uncertainty for each computed reduced cost is bounded by $|\\Delta \\bar c_j| \\le 7 \\times 10^{-4}$.\n- **Computed Reduced Costs**:\n    - $\\bar c_3 = 0.00007 = 7 \\times 10^{-5}$\n    - $\\bar c_4 = 0.00970 = 9.7 \\times 10^{-3}$\n    - $\\bar c_5 = -0.00006 = -6 \\times 10^{-5}$\n- **Question**: Identify the option that proposes a consistent tolerance $\\tau$ and correctly applies the tolerance rule.\n\n**Step 2: Validate Using Extracted Givens**\n- **Scientific Grounding**: The problem is well-grounded in the theory and numerical practice of linear programming, specifically the simplex algorithm. The concept of using a tolerance to handle floating-point inaccuracies is a standard and critical aspect of numerical optimization.\n- **Well-Posedness**: The problem is well-posed. It provides all the necessary numerical data (computed values and an uncertainty bound) and a clear decision rule to evaluate each option. A unique answer can be derived through logical deduction.\n- **Objectivity**: The problem is stated in precise, objective, and technical language.\n\n**Verdict and Action**: The problem statement is valid. It is scientifically sound, self-contained, and objective. I will now proceed with the solution.\n\n### Solution Derivation\n\nThe core of this problem lies in understanding the relationship between numerical uncertainty and the choice of a tolerance parameter.\n\n**Principle of Tolerance Selection**\nThe purpose of a tolerance $\\tau$ is to create a \"zero-region\" around $0$ to account for floating-point errors. A computed value $\\bar c_j$ falling inside this region (i.e., $|\\bar c_j|  \\tau$) cannot be reliably distinguished from zero. To ensure that numerical noise is not mistaken for a significant value, the tolerance $\\tau$ must be chosen to be at least as large as the maximum possible absolute uncertainty, which we will denote as $\\epsilon$.\nIn this problem, the uncertainty is given as $|\\Delta \\bar c_j| \\le \\epsilon = 7 \\times 10^{-4}$. Therefore, a consistent and robust choice of tolerance must satisfy $\\tau \\ge 7 \\times 10^{-4}$.\n\n**Analysis of True Values**\nLet's analyze the possible range of the true reduced costs, $\\bar c_j^{\\text{true}}$, given the computed values $\\bar c_j^{\\text{comp}}$ and the uncertainty $\\epsilon = 7 \\times 10^{-4}$. The true value lies in the interval $[\\bar c_j^{\\text{comp}} - \\epsilon, \\bar c_j^{\\text{comp}} + \\epsilon]$.\n- For $x_3$: $\\bar c_3^{\\text{true}} \\in [0.00007 - 0.0007, 0.00007 + 0.0007] = [-0.00063, 0.00077]$. This interval contains $0$. We cannot be certain that the true reduced cost is positive. Thus, $x_3$ is not a reliable candidate to enter the basis.\n- For $x_4$: $\\bar c_4^{\\text{true}} \\in [0.00970 - 0.0007, 0.00970 + 0.0007] = [0.00900, 0.01040]$. This interval is strictly positive. We are certain that the true reduced cost is positive. Therefore, the current solution is not optimal, and $x_4$ is an eligible variable to enter the basis.\n- For $x_5$: $\\bar c_5^{\\text{true}} \\in [-0.00006 - 0.0007, -0.00006 + 0.0007] = [-0.00076, 0.00064]$. This interval contains $0$. We cannot be certain that the true reduced cost is non-positive. However, since we are in a maximization context, we only consider variables with positive reduced costs to enter the basis.\n\nBased on this rigorous analysis, the correct conclusion is that the current solution is not optimal, and $x_4$ is the only nonbasic variable that should be considered for entering the basis. We will now evaluate each option against this benchmark.\n\n### Option-by-Option Analysis\n\nThe entering variable rule is to select $x_j$ if its computed reduced cost satisfies $\\bar c_j  \\tau$.\n\n**A. Choose $\\tau = 10^{-8}$; the current solution is not optimal; $x_3$ and $x_4$ are eligible to enter.**\n- **Tolerance Consistency**: The choice $\\tau = 10^{-8}$ is not consistent with the uncertainty bound $\\epsilon = 7 \\times 10^{-4}$, as $10^{-8} \\ll 7 \\times 10^{-4}$. Such a small tolerance would fail to filter out numerical noise and would treat values that could be zero as significant.\n- **Rule Application**:\n    - For $x_3$: $\\bar c_3 = 0.00007  10^{-8}$. The rule would make $x_3$ eligible.\n    - For $x_4$: $\\bar c_4 = 0.00970  10^{-8}$. The rule would make $x_4$ eligible.\nThis application incorrectly identifies $x_3$ as an eligible variable, as its true value could be zero or negative.\n- **Verdict**: **Incorrect**. The proposed tolerance is inconsistent with the stated uncertainty, and its application leads to an incorrect set of eligible variables.\n\n**B. Choose $\\tau = 10^{-4}$; the current solution is not optimal; $x_4$ is the only eligible entering variable.**\n- **Tolerance Consistency**: The choice $\\tau = 10^{-4} = 0.0001$ is not consistent. It is smaller than the uncertainty bound $\\epsilon = 7 \\times 10^{-4} = 0.0007$. A computed value of, for instance, $\\bar c_j = 5 \\times 10^{-4}$ could be due to roundoff from a true value of $0$, but since $5 \\times 10^{-4}  \\tau$, this rule would incorrectly select $x_j$ as an entering variable. The tolerance choice is not robust.\n- **Rule Application**:\n    - For $x_3$: $\\bar c_3 = 0.00007 \\ngtr 10^{-4}$. The rule would not make $x_3$ eligible.\n    - For $x_4$: $\\bar c_4 = 0.00970  10^{-4}$. The rule would make $x_4$ eligible.\nWhile the conclusion about the entering variable happens to be correct for these specific data points, the premise (the choice of $\\tau$) is flawed from a numerical stability standpoint. The question asks for an option that *both* proposes a consistent tolerance *and* correctly applies the rule. This option fails the first criterion.\n- **Verdict**: **Incorrect**. The proposed tolerance is not consistent with the stated uncertainty.\n\n**C. Choose $\\tau = 10^{-3}$; the current solution is not optimal; $x_4$ is the only eligible entering variable.**\n- **Tolerance Consistency**: The choice $\\tau = 10^{-3} = 0.001$ is consistent with the uncertainty bound $\\epsilon = 7 \\times 10^{-4} = 0.0007$, as $10^{-3}  7 \\times 10^{-4}$. This tolerance provides a safe margin to account for the numerical error.\n- **Rule Application**:\n    - For $x_3$: $\\bar c_3 = 0.00007 \\ngtr 10^{-3}$. The rule correctly does not make $x_3$ eligible. Its computed value falls well within the tolerance band ($|\\bar c_3|  \\tau$).\n    - For $x_4$: $\\bar c_4 = 0.00970  10^{-3}$. The rule correctly makes $x_4$ eligible. Its computed value is significantly larger than the tolerance.\n    - For $x_5$: $\\bar c_5 = -0.00006 \\ngtr 10^{-3}$. The rule correctly does not make $x_5$ eligible.\nThe application of this rule leads to the conclusion that the solution is not optimal and that $x_4$ is the sole eligible entering variable. This matches our rigorous analysis.\n- **Verdict**: **Correct**. The proposed tolerance is consistent with the uncertainty, and its application correctly identifies the optimality status and the set of eligible entering variables.\n\n**D. Choose $\\tau = 10^{-2}$; declare the current solution optimal; no variable is eligible to enter.**\n- **Tolerance Consistency**: The choice $\\tau = 10^{-2} = 0.01$ is consistent in the sense that $\\tau  \\epsilon$ ($10^{-2}  7 \\times 10^{-4}$). It is a safe choice.\n- **Rule Application**:\n    - For $x_3$: $\\bar c_3 = 0.00007 \\ngtr 10^{-2}$. Not eligible.\n    - For $x_4$: $\\bar c_4 = 0.00970 \\ngtr 10^{-2}$. Not eligible.\n    - For $x_5$: $\\bar c_5 = -0.00006 \\ngtr 10^{-2}$. Not eligible.\nThe rule application leads to the conclusion that no variable is eligible to enter, and thus the current solution is declared optimal. This is an incorrect conclusion. We know with certainty that the true $\\bar c_4$ is positive (at least $0.009$). A tolerance should not be so large that it masks a clear, significant signal for improvement. This choice of $\\tau$ is overly conservative, leading to premature termination of the simplex algorithm at a suboptimal solution. Thus, the rule is not \"correctly applied\" in the sense of achieving the goal of optimization.\n- **Verdict**: **Incorrect**. Although the tolerance is technically consistent (safe), it is inappropriately large, leading to an incorrect conclusion about optimality.", "answer": "$$\\boxed{C}$$", "id": "3171526"}]}