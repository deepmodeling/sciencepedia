{"hands_on_practices": [{"introduction": "This practice explores the fundamental question of when a feasible solution exists at all. By analyzing a set of constraints that includes a non-linear relationship, you will determine the precise threshold for a parameter $\\alpha$ that makes the feasible region non-empty [@problem_id:3129067]. This exercise is a great way to connect algebraic tools, such as the Arithmetic Mean-Geometric Mean inequality, to the geometric concept of feasibility.", "problem": "Let $x = (x_{1}, x_{2}) \\in \\mathbb{R}^{2}$. Consider the constraint set defined by $x_{1} \\ge 0$, $x_{2} \\ge 0$, and $x_{1}x_{2} \\ge 1$. A point $x$ is called feasible for a given parameter $\\alpha \\in \\mathbb{R}$ if it also satisfies the linear inequality $x_{1} + x_{2} \\le \\alpha$. Using only the foundational definition that a feasible region is the set of points that simultaneously satisfy all constraints, determine the smallest real number $\\alpha^{\\ast}$ such that there exists at least one feasible point if and only if $\\alpha \\ge \\alpha^{\\ast}$. Provide $\\alpha^{\\ast}$ in exact form as a single real number. Do not round your answer.", "solution": "The problem requires finding the smallest real number $\\alpha^{\\ast}$ such that a feasible region, defined by a set of inequalities, is non-empty if and only if a parameter $\\alpha$ satisfies $\\alpha \\ge \\alpha^{\\ast}$.\n\nThe set of all constraints for a point $x = (x_{1}, x_{2}) \\in \\mathbb{R}^{2}$ to be considered feasible is given by:\n1. $x_{1} \\ge 0$\n2. $x_{2} \\ge 0$\n3. $x_{1}x_{2} \\ge 1$\n4. $x_{1} + x_{2} \\le \\alpha$\n\nFor the set of feasible points to be non-empty, there must exist at least one point $(x_{1}, x_{2})$ that satisfies all four inequalities simultaneously. Let the set of points satisfying the first three constraints be denoted by $S$.\n$S = \\{ (x_{1}, x_{2}) \\in \\mathbb{R}^{2} \\mid x_{1} \\ge 0, x_{2} \\ge 0, x_{1}x_{2} \\ge 1 \\}$.\nThe feasible region is the intersection of the set $S$ and the half-plane defined by $x_{1} + x_{2} \\le \\alpha$. This intersection is non-empty if and only if there is at least one point in $S$ for which the sum $x_{1} + x_{2}$ is less than or equal to $\\alpha$.\n\nThis condition can be rephrased. The smallest value of $\\alpha$ for which the feasible region is non-empty must be the minimum possible value of the sum $x_1 + x_2$ for any point $(x_1, x_2)$ in the set $S$. Let this minimum value be $\\alpha^{\\ast}$.\nIf $\\alpha < \\alpha^{\\ast}$, then for any $(x_1, x_2) \\in S$, we have $x_1 + x_2 \\ge \\alpha^{\\ast} > \\alpha$, so the constraint $x_1 + x_2 \\le \\alpha$ can never be satisfied. The feasible region is empty.\nIf $\\alpha \\ge \\alpha^{\\ast}$, then the point $(x_1^{\\ast}, x_2^{\\ast}) \\in S$ that achieves the minimum sum $\\alpha^{\\ast}$ will satisfy $x_1^{\\ast} + x_2^{\\ast} = \\alpha^{\\ast} \\le \\alpha$. This point is therefore in the feasible region, making it non-empty.\n\nConsequently, the problem is equivalent to solving the following optimization problem:\nFind the minimum value of the function $f(x_{1}, x_{2}) = x_{1} + x_{2}$ subject to the constraints $x_{1} \\ge 0$, $x_{2} \\ge 0$, and $x_{1}x_{2} \\ge 1$.\n\nWe can solve this using the Arithmetic Mean-Geometric Mean (AM-GM) inequality. The AM-GM inequality states that for any non-negative real numbers $a$ and $b$, the following holds:\n$$ \\frac{a+b}{2} \\ge \\sqrt{ab} $$\nEquality holds if and only if $a=b$.\n\nFrom the constraints, we have $x_{1} \\ge 0$ and $x_{2} \\ge 0$. The constraint $x_{1}x_{2} \\ge 1$ implies that neither $x_{1}$ nor $x_{2}$ can be zero, so we must have $x_{1} > 0$ and $x_{2} > 0$. We can therefore apply the AM-GM inequality with $a = x_{1}$ and $b = x_{2}$:\n$$ \\frac{x_{1} + x_{2}}{2} \\ge \\sqrt{x_{1}x_{2}} $$\nMultiplying by $2$, we get:\n$$ x_{1} + x_{2} \\ge 2\\sqrt{x_{1}x_{2}} $$\nWe are also given the constraint $x_{1}x_{2} \\ge 1$. Since the square root function is monotonically increasing for non-negative arguments, we can take the square root of both sides of this inequality:\n$$ \\sqrt{x_{1}x_{2}} \\ge \\sqrt{1} = 1 $$\nCombining the two results, we have:\n$$ x_{1} + x_{2} \\ge 2\\sqrt{x_{1}x_{2}} \\ge 2(1) = 2 $$\nThis shows that for any point $(x_{1}, x_{2})$ satisfying the first three constraints, the sum $x_{1} + x_{2}$ must be greater than or equal to $2$. The minimum possible value for this sum is $2$.\n\nThis minimum value is achieved when the equality conditions for both inequalities are met.\n1. The equality in the AM-GM inequality ($x_{1} + x_{2} = 2\\sqrt{x_{1}x_{2}}$) holds if and only if $x_{1} = x_{2}$.\n2. The equality in the second step ($\\sqrt{x_{1}x_{2}} = 1$) holds if and only if $x_{1}x_{2} = 1$.\n\nTo find the point where the minimum is achieved, we solve the system of equations:\n$$ x_{1} = x_{2} $$\n$$ x_{1}x_{2} = 1 $$\nSubstituting the first equation into the second gives $x_{1}^{2} = 1$. Since we know $x_{1} > 0$, we must have $x_{1} = 1$. This implies $x_{2} = 1$.\n\nAt the point $(1, 1)$, the constraints are satisfied: $1 \\ge 0$, $1 \\ge 0$, and $(1)(1) = 1 \\ge 1$. The value of the sum is $x_{1} + x_{2} = 1 + 1 = 2$.\nThis confirms that the minimum value of $x_{1} + x_{2}$ subject to the constraints is indeed $2$.\n\nTherefore, the smallest real number $\\alpha^{\\ast}$ for which the feasible region is non-empty is $2$.\nFor any $\\alpha \\ge 2$, the point $(1, 1)$ is a feasible point. For any $\\alpha < 2$, no point can satisfy all constraints.\nThe value of $\\alpha^{\\ast}$ is thus $2$.", "answer": "$$\\boxed{2}$$", "id": "3129067"}, {"introduction": "In many practical applications, an initial measurement or estimate may not satisfy the required physical or logical constraints. This practice introduces the powerful concept of finding the closest feasible point by projecting an infeasible point onto the feasible set [@problem_id:3129154]. Solving this problem allows you to quantify the \"degree of infeasibility\" and find the minimal correction needed to satisfy all constraints, a foundational skill in data science and engineering.", "problem": "A dataset in two measured quantities is represented by the vector $y \\in \\mathbb{R}^{2}$ with $y = (2.2,\\,-0.4)$. Suppose the domain expert requires any acceptable (feasible) corrected dataset $x \\in \\mathbb{R}^{2}$ to satisfy the linear conservation rule $x_{1} + x_{2} = 2$ together with minimum-threshold bounds $x_{1} \\geq 1$ and $x_{2} \\geq 0.5$. The set of all feasible corrections is therefore the convex set $C = \\{x \\in \\mathbb{R}^{2} \\mid x_{1} + x_{2} = 2,\\ x_{1} \\geq 1,\\ x_{2} \\geq 0.5\\}$.\n\nUsing the shortest-distance-to-feasibility principle, quantify the datasetâ€™s inconsistency with the constraints by solving the optimization problem\n$$\n\\min_{x \\in \\mathbb{R}^{2}} \\ \\|x - y\\|_{2} \\quad \\text{subject to } x \\in C.\n$$\nDenote the optimal value by $d(y,C)$ and interpret geometrically which constraints are active at the closest feasible point.\n\nProvide the value of $d(y,C)$ as your final answer. Express your answer exactly in simplest radical form (no rounding).", "solution": "The problem asks for the projection of a point $y \\in \\mathbb{R}^{2}$ onto a closed, non-empty, convex set $C$. By the Hilbert projection theorem, a unique solution exists. The problem is to find the point $x \\in C$ that minimizes the Euclidean distance to a given point $y = (2.2, -0.4)$.\n\nThe optimization problem is:\n$$ \\min_{x \\in \\mathbb{R}^{2}} \\|x - y\\|_{2} \\quad \\text{subject to } x \\in C $$\nwhere $C = \\{x \\in \\mathbb{R}^{2} \\mid x_{1} + x_{2} = 2,\\ x_{1} \\geq 1,\\ x_{2} \\geq 0.5\\}$.\n\nMinimizing $\\|x - y\\|_{2}$ is equivalent to minimizing its square, $\\|x - y\\|_{2}^{2}$. We can solve this using the Karush-Kuhn-Tucker (KKT) conditions on the equivalent problem of minimizing $\\frac{1}{2}\\|x - y\\|_{2}^{2} = \\frac{1}{2} \\left( (x_1 - 2.2)^{2} + (x_2 + 0.4)^{2} \\right)$.\n\nThe constraints defining the feasible set $C$ are:\n\\begin{align*}\nh(x) &= x_1 + x_2 - 2 = 0 \\\\\ng_1(x) &= 1 - x_1 \\leq 0 \\\\\ng_2(x) &= 0.5 - x_2 \\leq 0\n\\end{align*}\nThe Lagrangian function is:\n$$ L(x, \\lambda, \\mu_1, \\mu_2) = \\frac{1}{2}((x_1 - 2.2)^{2} + (x_2 + 0.4)^{2}) + \\lambda(x_1 + x_2 - 2) + \\mu_1(1 - x_1) + \\mu_2(0.5 - x_2) $$\nThe KKT conditions include stationarity ($\\nabla_x L = 0$), primal feasibility ($x \\in C$), dual feasibility ($\\mu_1, \\mu_2 \\ge 0$), and complementary slackness ($\\mu_1(1-x_1)=0$, $\\mu_2(0.5-x_2)=0$). We analyze cases based on which inequality constraints are active.\n\n**Case 1: Both inequality constraints are inactive ($x_1 > 1, x_2 > 0.5$).**\nComplementary slackness implies $\\mu_1 = 0, \\mu_2 = 0$. The stationarity conditions become $x_1 - 2.2 + \\lambda = 0$ and $x_2 + 0.4 + \\lambda = 0$. Substituting $x_1 = 2.2 - \\lambda$ and $x_2 = -0.4 - \\lambda$ into $x_1 + x_2 = 2$ gives $(2.2 - \\lambda) + (-0.4 - \\lambda) = 2$, which yields $\\lambda = -0.1$. This gives the candidate point $x=(2.3, -0.3)$. However, this point violates the primal feasibility condition $x_2 \\ge 0.5$.\n\n**Case 2: The constraint $x_1 \\geq 1$ is active ($x_1=1$), and $x_2 \\geq 0.5$ is inactive ($x_2 > 0.5$).**\nFrom $x_1=1$, the equality constraint $x_1+x_2=2$ gives $x_2=1$. The candidate point is $(1, 1)$, which is primally feasible. Complementary slackness implies $\\mu_2=0$. The stationarity conditions are $(1 - 2.2) + \\lambda - \\mu_1 = 0$ and $(1 + 0.4) + \\lambda = 0$. The second equation gives $\\lambda = -1.4$. Substituting this into the first gives $-1.2 - 1.4 - \\mu_1 = 0$, which yields $\\mu_1 = -2.6$. This violates the dual feasibility condition $\\mu_1 \\ge 0$.\n\n**Case 3: The constraint $x_2 \\geq 0.5$ is active ($x_2=0.5$), and $x_1 \\geq 1$ is inactive ($x_1 > 1$).**\nFrom $x_2=0.5$, the equality constraint $x_1+x_2=2$ gives $x_1=1.5$. The candidate point is $(1.5, 0.5)$, which is primally feasible. Complementary slackness implies $\\mu_1=0$. The stationarity conditions are $(1.5 - 2.2) + \\lambda = 0$ and $(0.5 + 0.4) + \\lambda - \\mu_2 = 0$. The first equation gives $\\lambda = 0.7$. Substituting this into the second gives $0.9 + 0.7 - \\mu_2 = 0$, which yields $\\mu_2 = 1.6$. All KKT conditions are met: the point is primally feasible, and the dual variables $\\mu_1=0, \\mu_2=1.6$ are non-negative.\n\nSince the problem is convex, the point $(1.5, 0.5)$ satisfying the KKT conditions is the unique global minimum. The optimal feasible point is $x^* = (1.5, 0.5)$.\n\nThe problem asks for the optimal value $d(y,C)$, which is the distance $\\|x^* - y\\|_{2}$.\n$$ d(y,C) = \\|x^* - y\\|_{2} = \\sqrt{(1.5 - 2.2)^2 + (0.5 - (-0.4))^2} $$\n$$ d(y,C) = \\sqrt{(-0.7)^2 + (0.9)^2} $$\n$$ d(y,C) = \\sqrt{0.49 + 0.81} = \\sqrt{1.3} $$\nTo express this in simplest radical form:\n$$ \\sqrt{1.3} = \\sqrt{\\frac{13}{10}} = \\frac{\\sqrt{13}}{\\sqrt{10}} = \\frac{\\sqrt{13} \\cdot \\sqrt{10}}{10} = \\frac{\\sqrt{130}}{10} $$\nThe inconsistency of the dataset $y$ with the constraints, quantified by the shortest distance to feasibility, is $\\frac{\\sqrt{130}}{10}$.", "answer": "$$\n\\boxed{\\frac{\\sqrt{130}}{10}}\n$$", "id": "3129154"}, {"introduction": "The geometry of feasible regions can be surprisingly complex, especially when defined by modern mathematical tools like vector norms. This practice challenges you to investigate a feasible set defined by the interplay of the $\\ell_1$ and $\\ell_2$ norms, which are central to fields like machine learning and signal processing [@problem_id:3129136]. By determining the conditions for non-emptiness and characterizing the region's shape, you will gain a deeper, more abstract intuition for how different types of constraints define the landscape of possible solutions.", "problem": "Consider the set of feasible solutions in $\\mathbb{R}^{n}$ defined by the simultaneous constraints $\\|x\\|_{1} \\le \\alpha$ and $\\|x\\|_{2} \\ge \\beta$, where $\\|x\\|_{1} = \\sum_{i=1}^{n} |x_{i}|$ is the $\\ell_{1}$ norm and $\\|x\\|_{2} = \\left(\\sum_{i=1}^{n} x_{i}^{2}\\right)^{1/2}$ is the Euclidean ($\\ell_{2}$) norm. Let $n \\ge 2$, and suppose $\\alpha \\ge 0$ and $\\beta \\ge 0$ are real parameters.\n\nStarting from core definitions of norms and standard inequalities such as the Cauchyâ€“Schwarz inequality and the triangle inequality, rigorously determine the necessary and sufficient condition on $(\\alpha,\\beta)$ for the feasible region to be nonempty in $\\mathbb{R}^{n}$. Then, for the case $n=2$, characterize the geometric shape of the feasible region when it is nonempty by describing its boundary sets using equations and by classifying its boundedness, convexity, and connectedness.\n\nFinally, define\n$$\nc \\;=\\; \\sup\\left\\{\\frac{\\beta}{\\alpha} \\;:\\; \\text{the feasible set } \\{x \\in \\mathbb{R}^{n} : \\|x\\|_{1} \\le \\alpha,\\; \\|x\\|_{2} \\ge \\beta\\} \\text{ is nonempty with } \\alpha>0 \\right\\}.\n$$\nCompute the exact value of $c$. Provide $c$ as a single real number. No rounding is required.", "solution": "The feasible region is the set $S = \\{x \\in \\mathbb{R}^{n} : \\|x\\|_{1} \\le \\alpha \\text{ and } \\|x\\|_{2} \\ge \\beta\\}$. The solution is derived in three parts.\n\n**Part 1: Condition for a Nonempty Feasible Region**\nWe first establish the relationship between the $\\ell_1$ and $\\ell_2$ norms. For any vector $x \\in \\mathbb{R}^n$, it is a standard inequality that $\\|x\\|_{2} \\le \\|x\\|_{1}$.\n\n*   **Necessity**: Suppose the feasible set $S$ is nonempty. Then there exists a vector $x_0 \\in S$ such that $\\|x_0\\|_{1} \\le \\alpha$ and $\\|x_0\\|_{2} \\ge \\beta$. Combining these with the norm inequality, we get the chain:\n    $$ \\beta \\le \\|x_0\\|_{2} \\le \\|x_0\\|_{1} \\le \\alpha $$\n    This implies that $\\beta \\le \\alpha$ is a necessary condition.\n\n*   **Sufficiency**: Suppose $\\alpha \\ge \\beta$ holds (with the given $\\alpha, \\beta \\ge 0$). We need to show that $S$ is nonempty by constructing a feasible point. Let's consider the point $x_c = (\\alpha, 0, \\ldots, 0)$. Its norms are:\n    $$ \\|x_c\\|_{1} = |\\alpha| + 0 + \\dots + 0 = \\alpha $$\n    $$ \\|x_c\\|_{2} = \\sqrt{\\alpha^2 + 0^2 + \\dots + 0^2} = \\alpha $$\n    We check if $x_c$ is in $S$:\n    1.  $\\|x_c\\|_{1} \\le \\alpha \\implies \\alpha \\le \\alpha$, which is true.\n    2.  $\\|x_c\\|_{2} \\ge \\beta \\implies \\alpha \\ge \\beta$, which is true by our assumption.\n    Since both constraints are satisfied, $x_c \\in S$, and the set is nonempty.\n\nThus, the necessary and sufficient condition for the feasible region to be nonempty is $\\alpha \\ge \\beta$.\n\n**Part 2: Geometric Characterization for n=2**\nFor $n=2$, the feasible region is $S = \\{(x_1, x_2) \\in \\mathbb{R}^2 : |x_1| + |x_2| \\le \\alpha \\text{ and } x_1^2 + x_2^2 \\ge \\beta^2\\}$. This is the intersection of a solid square (the $\\ell_1$-ball) centered at the origin with vertices at $(\\pm\\alpha, 0)$ and $(0, \\pm\\alpha)$, and the exterior of a circle of radius $\\beta$ centered at the origin. The resulting shape is a square with a circular \"hole\" at its center.\n\n*   **Boundedness**: Since $S$ is a subset of the $\\ell_1$-ball, which is a bounded set, $S$ is also bounded.\n*   **Convexity**: If $\\beta > 0$, the set is not convex. For example, if $\\alpha \\ge \\beta > 0$, the points $x_a = (\\beta, 0)$ and $x_b = (-\\beta, 0)$ are in $S$. However, their midpoint, the origin $(0,0)$, is not in $S$ because its $\\ell_2$-norm is $0$, which is less than $\\beta$.\n*   **Connectedness**: The region is path-connected. The portions of the set in each of the four quadrants are connected to their neighbors along the coordinate axes. For example, the set of points on the positive y-axis within $S$ is $\\{(0, y) \\mid \\beta \\le y \\le \\alpha\\}$, which is a non-empty line segment since $\\alpha \\ge \\beta$. This segment connects the portions of $S$ in the first and second quadrants.\n\n**Part 3: Computation of c**\nThe constant $c$ is defined as\n$$\nc \\;=\\; \\sup\\left\\{\\frac{\\beta}{\\alpha} \\;:\\; \\text{the feasible set is nonempty with } \\alpha>0 \\right\\}.\n$$\nFrom Part 1, the condition for the set to be nonempty is $\\alpha \\ge \\beta$. We are also given $\\alpha>0$ and $\\beta \\ge 0$. Therefore, we are looking for the supremum of the ratio $\\frac{\\beta}{\\alpha}$ over all $(\\alpha, \\beta)$ that satisfy $0  \\alpha$ and $0 \\le \\beta \\le \\alpha$.\nDividing the inequality chain $0 \\le \\beta \\le \\alpha$ by the positive number $\\alpha$, we get:\n$$ 0 \\le \\frac{\\beta}{\\alpha} \\le 1 $$\nThe set of all possible values for the ratio $\\frac{\\beta}{\\alpha}$ is the closed interval $[0, 1]$. The supremum (least upper bound) of this interval is $1$.\nTherefore, $c=1$.", "answer": "$$\n\\boxed{1}\n$$", "id": "3129136"}]}