{"hands_on_practices": [{"introduction": "The best way to internalize an algorithm is by tracing its execution. This exercise provides a complete, step-by-step walkthrough of the revised simplex method on a small linear program. By manually computing the dual vector $y$, reduced costs $\\bar{c}_{N}$, search direction $d$, and step length $\\theta$ for each iteration, you will gain a concrete understanding of how these components work together to navigate from an initial feasible solution to an optimal one [@problem_id:3172864].", "problem": "Consider the following linear program in standard form for maximization. Let $x \\in \\mathbb{R}^{3}$ denote decision variables and let $s \\in \\mathbb{R}^{2}$ denote slack variables. The data are\n$$\n\\max\\ z \\;=\\; 3 x_{1} \\;+\\; 2 x_{2} \\;+\\; 4 x_{3}\n$$\nsubject to\n$$\n\\begin{aligned}\nx_{1} \\;+\\; 2 x_{2} \\;+\\; x_{3} \\;+\\; s_{1} \\;&=\\; 8,\\\\\n2 x_{1} \\;+\\; x_{2} \\;+\\; 3 x_{3} \\;+\\; s_{2} \\;&=\\; 12,\\\\\nx_{1}, x_{2}, x_{3}, s_{1}, s_{2} \\;&\\ge\\; 0.\n\\end{aligned}\n$$\nLet the initial basis be the slack-variable basis $B_{0} = \\{s_{1}, s_{2}\\}$, yielding the initial basic feasible solution $x_{B} = b$. Use the revised simplex method with Dantzigâ€™s rule (choose the entering nonbasic variable with the largest positive reduced cost in each iteration). At each iteration, compute:\n- the basic solution $x_{B} = B^{-1} b$,\n- the dual vector $y^{\\top} = c_{B}^{\\top} B^{-1}$,\n- the entering-column search direction for basic variables $d_{B} = -B^{-1} a_{j}$ if $x_{j}$ enters, together with $d_{j} = 1$ and $d_{i} = 0$ for all other nonbasic indices,\n- the step length $\\theta = \\min\\{ -x_{B,i}/d_{B,i} : d_{B,i} < 0\\}$,\n- the reduced costs of the nonbasic variables $\\bar c_{N} = c_{N} - A_{N}^{\\top} y$.\n\nProceed with pivots until optimality is certified by the revised simplex optimality condition for maximization (all reduced costs of nonbasic variables are nonpositive). Report the final optimal objective value $z^{\\star}$ as an exact rational number. The final answer must be a single number. No rounding is required.", "solution": "The problem statement is a standard linear programming problem to be solved using a specified algorithm, the revised simplex method. The data, constraints, and objective function are clearly defined and mathematically consistent. The problem is well-posed, scientifically grounded in the field of optimization, and contains no ambiguities or contradictions. Therefore, the problem is deemed valid and a solution will be furnished.\n\nThe linear program is given by:\n$$ \\max z = 3 x_{1} + 2 x_{2} + 4 x_{3} $$\nsubject to\n$$ x_{1} + 2 x_{2} + x_{3} + s_{1} = 8 $$\n$$ 2 x_{1} + x_{2} + 3 x_{3} + s_{2} = 12 $$\n$$ x_{1}, x_{2}, x_{3}, s_{1}, s_{2} \\ge 0 $$\n\nLet the vector of all variables be $(x_1, x_2, x_3, s_1, s_2)$. The problem can be written in matrix form $\\max c^\\top x$ subject to $Ax = b$ and $x \\ge 0$.\nThe matrices and vectors are:\n$$ A = \\begin{pmatrix} 1 & 2 & 1 & 1 & 0 \\\\ 2 & 1 & 3 & 0 & 1 \\end{pmatrix}, \\quad b = \\begin{pmatrix} 8 \\\\ 12 \\end{pmatrix}, \\quad c = \\begin{pmatrix} 3 & 2 & 4 & 0 & 0 \\end{pmatrix}^\\top $$\nThe variable indices are $\\{1, 2, 3, 4, 5\\}$ corresponding to $x_1, x_2, x_3, s_1, s_2$.\n\n**Iteration 0**\n\nThe initial basis consists of the slack variables $\\{s_1, s_2\\}$, so the set of basic indices is $\\mathcal{B} = \\{4, 5\\}$ and nonbasic indices is $\\mathcal{N} = \\{1, 2, 3\\}$.\n\nThe basis matrix $B$ and its inverse $B^{-1}$ are:\n$$ B = \\begin{pmatrix} 1 & 0 \\\\ 0 & 1 \\end{pmatrix}, \\quad B^{-1} = \\begin{pmatrix} 1 & 0 \\\\ 0 & 1 \\end{pmatrix} $$\nThe costs of the basic variables are $c_B = (c_4, c_5)^\\top = (0, 0)^\\top$.\n\n- Basic solution: $x_B = B^{-1} b = \\begin{pmatrix} 1 & 0 \\\\ 0 & 1 \\end{pmatrix} \\begin{pmatrix} 8 \\\\ 12 \\end{pmatrix} = \\begin{pmatrix} 8 \\\\ 12 \\end{pmatrix}$. Thus, $s_1 = 8$, $s_2 = 12$. The objective value is $z = c_B^\\top x_B = 0$.\n- Dual vector: $y^\\top = c_B^\\top B^{-1} = \\begin{pmatrix} 0 & 0 \\end{pmatrix} \\begin{pmatrix} 1 & 0 \\\\ 0 & 1 \\end{pmatrix} = \\begin{pmatrix} 0 & 0 \\end{pmatrix}$. Thus, $y = (0, 0)^\\top$.\n- Reduced costs of nonbasic variables $\\bar{c}_N = c_N - A_N^\\top y$:\n  - $\\bar{c}_1 = c_1 - y^\\top a_1 = 3 - \\begin{pmatrix} 0 & 0 \\end{pmatrix} \\begin{pmatrix} 1 \\\\ 2 \\end{pmatrix} = 3$.\n  - $\\bar{c}_2 = c_2 - y^\\top a_2 = 2 - \\begin{pmatrix} 0 & 0 \\end{pmatrix} \\begin{pmatrix} 2 \\\\ 1 \\end{pmatrix} = 2$.\n  - $\\bar{c}_3 = c_3 - y^\\top a_3 = 4 - \\begin{pmatrix} 0 & 0 \\end{pmatrix} \\begin{pmatrix} 1 \\\\ 3 \\end{pmatrix} = 4$.\nThe vector of reduced costs is $\\bar{c}_N = (3, 2, 4)^\\top$. Since there are positive reduced costs, the current solution is not optimal. By Dantzig's rule, we choose the variable with the largest positive reduced cost to enter the basis. This is $x_3$, with $\\bar{c}_3 = 4$.\n\n- Entering-column search direction: $d_B = -B^{-1} a_3 = -\\begin{pmatrix} 1 & 0 \\\\ 0 & 1 \\end{pmatrix} \\begin{pmatrix} 1 \\\\ 3 \\end{pmatrix} = \\begin{pmatrix} -1 \\\\ -3 \\end{pmatrix}$.\n- Step length: $\\theta = \\min\\{-x_{B,i}/d_{B,i} : d_{B,i} < 0\\} = \\min\\{-8/(-1), -12/(-3)\\} = \\min\\{8, 4\\} = 4$.\nThe minimum ratio corresponds to the second basic variable, $s_2$. Thus, $s_2$ leaves the basis.\n\n**Iteration 1**\n\nThe new basis is $\\{s_1, x_3\\}$, so $\\mathcal{B} = \\{4, 3\\}$ and $\\mathcal{N} = \\{1, 2, 5\\}$.\nThe basis matrix $B$ and its inverse $B^{-1}$ are:\n$$ B = \\begin{pmatrix} a_4 & a_3 \\end{pmatrix} = \\begin{pmatrix} 1 & 1 \\\\ 0 & 3 \\end{pmatrix}, \\quad B^{-1} = \\frac{1}{3}\\begin{pmatrix} 3 & -1 \\\\ 0 & 1 \\end{pmatrix} = \\begin{pmatrix} 1 & -1/3 \\\\ 0 & 1/3 \\end{pmatrix} $$\nThe costs of the basic variables are $c_B = (c_4, c_3)^\\top = (0, 4)^\\top$.\n\n- Basic solution: $x_B = B^{-1} b = \\begin{pmatrix} 1 & -1/3 \\\\ 0 & 1/3 \\end{pmatrix} \\begin{pmatrix} 8 \\\\ 12 \\end{pmatrix} = \\begin{pmatrix} 8-4 \\\\ 4 \\end{pmatrix} = \\begin{pmatrix} 4 \\\\ 4 \\end{pmatrix}$. Thus, $s_1 = 4$, $x_3 = 4$. The objective value is $z = c_B^\\top x_B = 0(4) + 4(4) = 16$.\n- Dual vector: $y^\\top = c_B^\\top B^{-1} = \\begin{pmatrix} 0 & 4 \\end{pmatrix} \\begin{pmatrix} 1 & -1/3 \\\\ 0 & 1/3 \\end{pmatrix} = \\begin{pmatrix} 0 & 4/3 \\end{pmatrix}$.\n- Reduced costs of nonbasic variables $\\bar{c}_N = c_N - A_N^\\top y$:\n  - $\\bar{c}_1 = c_1 - y^\\top a_1 = 3 - \\begin{pmatrix} 0 & 4/3 \\end{pmatrix} \\begin{pmatrix} 1 \\\\ 2 \\end{pmatrix} = 3 - 8/3 = 1/3$.\n  - $\\bar{c}_2 = c_2 - y^\\top a_2 = 2 - \\begin{pmatrix} 0 & 4/3 \\end{pmatrix} \\begin{pmatrix} 2 \\\\ 1 \\end{pmatrix} = 2 - 4/3 = 2/3$.\n  - $\\bar{c}_5 = c_5 - y^\\top a_5 = 0 - \\begin{pmatrix} 0 & 4/3 \\end{pmatrix} \\begin{pmatrix} 0 \\\\ 1 \\end{pmatrix} = -4/3$.\nThe largest positive reduced cost is $\\bar{c}_2 = 2/3$, so $x_2$ enters the basis.\n\n- Entering-column search direction: $d_B = -B^{-1} a_2 = -\\begin{pmatrix} 1 & -1/3 \\\\ 0 & 1/3 \\end{pmatrix} \\begin{pmatrix} 2 \\\\ 1 \\end{pmatrix} = -\\begin{pmatrix} 2-1/3 \\\\ 1/3 \\end{pmatrix} = \\begin{pmatrix} -5/3 \\\\ -1/3 \\end{pmatrix}$.\n- Step length: $\\theta = \\min\\{-x_{B,i}/d_{B,i} : d_{B,i} < 0\\} = \\min\\{-4/(-5/3), -4/(-1/3)\\} = \\min\\{12/5, 12\\} = 12/5$.\nThe minimum ratio corresponds to the first basic variable, $s_1$. Thus, $s_1$ leaves the basis.\n\n**Iteration 2**\n\nThe new basis is $\\{x_2, x_3\\}$, so $\\mathcal{B} = \\{2, 3\\}$ and $\\mathcal{N} = \\{1, 4, 5\\}$.\nThe basis matrix $B$ and its inverse $B^{-1}$ are:\n$$ B = \\begin{pmatrix} a_2 & a_3 \\end{pmatrix} = \\begin{pmatrix} 2 & 1 \\\\ 1 & 3 \\end{pmatrix}, \\quad B^{-1} = \\frac{1}{5}\\begin{pmatrix} 3 & -1 \\\\ -1 & 2 \\end{pmatrix} = \\begin{pmatrix} 3/5 & -1/5 \\\\ -1/5 & 2/5 \\end{pmatrix} $$\nThe costs of the basic variables are $c_B = (c_2, c_3)^\\top = (2, 4)^\\top$.\n\n- Basic solution: $x_B = B^{-1} b = \\begin{pmatrix} 3/5 & -1/5 \\\\ -1/5 & 2/5 \\end{pmatrix} \\begin{pmatrix} 8 \\\\ 12 \\end{pmatrix} = \\begin{pmatrix} (24-12)/5 \\\\ (-8+24)/5 \\end{pmatrix} = \\begin{pmatrix} 12/5 \\\\ 16/5 \\end{pmatrix}$. Thus, $x_2 = 12/5$, $x_3 = 16/5$. The objective value is $z = c_B^\\top x_B = 2(12/5) + 4(16/5) = (24+64)/5 = 88/5$.\n- Dual vector: $y^\\top = c_B^\\top B^{-1} = \\begin{pmatrix} 2 & 4 \\end{pmatrix} \\begin{pmatrix} 3/5 & -1/5 \\\\ -1/5 & 2/5 \\end{pmatrix} = \\begin{pmatrix} (6-4)/5 & (-2+8)/5 \\end{pmatrix} = \\begin{pmatrix} 2/5 & 6/5 \\end{pmatrix}$.\n- Reduced costs of nonbasic variables $\\bar{c}_N = c_N - A_N^\\top y$:\n  - $\\bar{c}_1 = c_1 - y^\\top a_1 = 3 - \\begin{pmatrix} 2/5 & 6/5 \\end{pmatrix} \\begin{pmatrix} 1 \\\\ 2 \\end{pmatrix} = 3 - (2/5 + 12/5) = 3 - 14/5 = 1/5$.\n  - $\\bar{c}_4 = c_4 - y^\\top a_4 = 0 - \\begin{pmatrix} 2/5 & 6/5 \\end{pmatrix} \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix} = -2/5$.\n  - $\\bar{c}_5 = c_5 - y^\\top a_5 = 0 - \\begin{pmatrix} 2/5 & 6/5 \\end{pmatrix} \\begin{pmatrix} 0 \\\\ 1 \\end{pmatrix} = -6/5$.\nThe only positive reduced cost is $\\bar{c}_1 = 1/5$, so $x_1$ enters the basis.\n\n- Entering-column search direction: $d_B = -B^{-1} a_1 = -\\begin{pmatrix} 3/5 & -1/5 \\\\ -1/5 & 2/5 \\end{pmatrix} \\begin{pmatrix} 1 \\\\ 2 \\end{pmatrix} = -\\begin{pmatrix} (3-2)/5 \\\\ (-1+4)/5 \\end{pmatrix} = \\begin{pmatrix} -1/5 \\\\ -3/5 \\end{pmatrix}$.\n- Step length: $\\theta = \\min\\{-x_{B,i}/d_{B,i} : d_{B,i} < 0\\} = \\min\\{-(12/5)/(-1/5), -(16/5)/(-3/5)\\} = \\min\\{12, 16/3\\} = 16/3$.\nThe minimum ratio corresponds to the second basic variable, $x_3$. Thus, $x_3$ leaves the basis.\n\n**Iteration 3**\n\nThe new basis is $\\{x_2, x_1\\}$, so $\\mathcal{B} = \\{2, 1\\}$ and $\\mathcal{N} = \\{3, 4, 5\\}$.\nThe basis matrix $B$ and its inverse $B^{-1}$ are:\n$$ B = \\begin{pmatrix} a_2 & a_1 \\end{pmatrix} = \\begin{pmatrix} 2 & 1 \\\\ 1 & 2 \\end{pmatrix}, \\quad B^{-1} = \\frac{1}{3}\\begin{pmatrix} 2 & -1 \\\\ -1 & 2 \\end{pmatrix} = \\begin{pmatrix} 2/3 & -1/3 \\\\ -1/3 & 2/3 \\end{pmatrix} $$\nThe costs of the basic variables are $c_B = (c_2, c_1)^\\top = (2, 3)^\\top$.\n\n- Basic solution: $x_B = B^{-1} b = \\begin{pmatrix} 2/3 & -1/3 \\\\ -1/3 & 2/3 \\end{pmatrix} \\begin{pmatrix} 8 \\\\ 12 \\end{pmatrix} = \\begin{pmatrix} (16-12)/3 \\\\ (-8+24)/3 \\end{pmatrix} = \\begin{pmatrix} 4/3 \\\\ 16/3 \\end{pmatrix}$. Thus, $x_2 = 4/3$, $x_1 = 16/3$. The objective value is $z = c_B^\\top x_B = 2(4/3) + 3(16/3) = (8+48)/3 = 56/3$.\n- Dual vector: $y^\\top = c_B^\\top B^{-1} = \\begin{pmatrix} 2 & 3 \\end{pmatrix} \\begin{pmatrix} 2/3 & -1/3 \\\\ -1/3 & 2/3 \\end{pmatrix} = \\begin{pmatrix} (4-3)/3 & (-2+6)/3 \\end{pmatrix} = \\begin{pmatrix} 1/3 & 4/3 \\end{pmatrix}$.\n- Reduced costs of nonbasic variables $\\bar{c}_N = c_N - A_N^\\top y$:\n  - $\\bar{c}_3 = c_3 - y^\\top a_3 = 4 - \\begin{pmatrix} 1/3 & 4/3 \\end{pmatrix} \\begin{pmatrix} 1 \\\\ 3 \\end{pmatrix} = 4 - (1/3 + 12/3) = 4 - 13/3 = -1/3$.\n  - $\\bar{c}_4 = c_4 - y^\\top a_4 = 0 - \\begin{pmatrix} 1/3 & 4/3 \\end{pmatrix} \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix} = -1/3$.\n  - $\\bar{c}_5 = c_5 - y^\\top a_5 = 0 - \\begin{pmatrix} 1/3 & 4/3 \\end{pmatrix} \\begin{pmatrix} 0 \\\\ 1 \\end{pmatrix} = -4/3$.\n\nAll reduced costs of the nonbasic variables are nonpositive ($\\bar{c}_3 = -1/3 \\le 0$, $\\bar{c}_4 = -1/3 \\le 0$, $\\bar{c}_5 = -4/3 \\le 0$). The optimality condition for maximization is satisfied. The current solution is optimal.\n\nThe optimal objective value is $z^\\star = 56/3$.", "answer": "$$\n\\boxed{\\frac{56}{3}}\n$$", "id": "3172864"}, {"introduction": "An effective algorithm must not only find solutions when they exist but also correctly diagnose when they do not. The revised simplex method has built-in signals for special cases like unboundedness. This problem focuses on one such signal, challenging you to interpret the search direction vector $d$ for an entering variable to see how the algorithm detects that the objective function can be improved indefinitely [@problem_id:2197696].", "problem": "An operations research analyst is solving a manufacturing optimization problem formulated as the following Linear Program (LP) using the revised simplex method:\nMaximize $Z = 3x_1 - x_2$\nSubject to:\n$x_1 - 2x_2 + x_3 = 10$\n$-2x_1 + x_2 + x_4 = 5$\n$x_1, x_2, x_3, x_4 \\ge 0$\n\nAfter an initial pivot, the set of basic variables is $\\{x_1, x_4\\}$. The inverse of the corresponding basis matrix $B$ is found to be:\n$$B^{-1} = \\begin{pmatrix} 1 & 0 \\\\ 2 & 1 \\end{pmatrix}$$\nThe analyst performs a pricing step and determines that the current basic feasible solution is not optimal and that variable $x_2$ should enter the basis. The column vector from the original constraint matrix corresponding to $x_2$ is $A_2 = \\begin{pmatrix} -2 \\\\ 1 \\end{pmatrix}$.\n\nThe next step in the revised simplex method is to compute the search direction vector $d = B^{-1}A_2$ to determine which variable should leave the basis. Based on the result of this computation, which of the following conclusions is correct?\n\nA. The current basic solution is optimal.\n\nB. The Linear Program is unbounded.\n\nC. Variable $x_1$ must leave the basis.\n\nD. Variable $x_4$ must leave the basis.\n\nE. The Linear Program is infeasible.", "solution": "In the revised simplex method, once an entering variable $x_{j}$ is chosen, the search direction for the basic variables is given by the vector $d = B^{-1}A_{j}$, where $A_{j}$ is the $j$th column of the original constraint matrix and $B^{-1}$ is the inverse of the current basis matrix.\n\nHere, the entering variable is $x_{2}$ and the given data are $B^{-1} = \\begin{pmatrix} 1 & 0 \\\\ 2 & 1 \\end{pmatrix}$ and $A_{2} = \\begin{pmatrix} -2 \\\\ 1 \\end{pmatrix}$. Compute the direction:\n$$\nd = B^{-1}A_{2} = \n\\begin{pmatrix} 1 & 0 \\\\ 2 & 1 \\end{pmatrix}\n\\begin{pmatrix} -2 \\\\ 1 \\end{pmatrix}\n=\n\\begin{pmatrix} 1\\cdot(-2) + 0\\cdot 1 \\\\ 2\\cdot(-2) + 1\\cdot 1 \\end{pmatrix}\n=\n\\begin{pmatrix} -2 \\\\ -3 \\end{pmatrix}.\n$$\n\nIf $\\theta \\ge 0$ denotes the step size by which we increase the entering variable $x_{2}$, the basic variables update as $x_{B}(\\theta) = x_{B}(0) - \\theta d$. Primal feasibility requires $x_{B}(\\theta) \\ge 0$. This imposes upper bounds on $\\theta$ only from components with $d_{i} > 0$, via the minimum ratio test: $\\theta \\le \\min\\{x_{B,i}/d_{i} : d_{i} > 0\\}$. In this case $d = \\begin{pmatrix} -2 \\\\ -3 \\end{pmatrix}$ has all components strictly negative. If all components of the updated column $d$ are less than or equal to zero ($d \\le 0$), there is no feasibility bound on how much the entering variable can be increased.\n\nSince the pricing step has already determined that $x_{2}$ should enter (i.e., its reduced cost is positive, so moving in this direction improves the objective), and there is no bound on the step length $\\theta$, the objective function can be increased indefinitely. Therefore, the Linear Program is unbounded. No variable leaves the basis, and the algorithm terminates.", "answer": "$$\\boxed{B}$$", "id": "2197696"}, {"introduction": "While textbook examples often involve direct matrix inversion, professional-grade optimization software employs more sophisticated techniques to ensure accuracy and speed. This advanced exercise introduces a numerically stable variant of the revised simplex method that avoids explicit computation of $B^{-1}$ by maintaining a QR factorization of the basis matrix. You will practice updating this factorization using Givens rotations, a powerful technique from numerical linear algebra that provides greater stability in large-scale problems [@problem_id:2197697].", "problem": "In optimizing numerical stability for the revised simplex method, one advanced technique replaces the explicit computation of the basis inverse with an update scheme for the QR factorization of the basis matrix. Consider an iteration of such an algorithm.\n\nLet the current $m \\times m$ basis matrix be $B = [b_1, \\dots, b_m]$, with a known QR factorization $B = QR$, where $Q$ is an orthogonal matrix and $R$ is an upper triangular matrix. A pivot operation involves replacing one column $b_p$ of the basis matrix with an entering column $a_q$ from the original constraint matrix $A$, resulting in a new basis matrix $B_{\\text{new}} = [b_1, \\dots, b_{p-1}, a_q, b_{p+1}, \\dots, b_m]$.\n\nThe QR factorization of $B_{\\text{new}}$ can be found efficiently. First, one computes the matrix $H = Q^T B_{\\text{new}}$. Because $Q^T B = R$, the columns of $H$ are the same as the columns of $R$, except for the $p$-th column, which becomes $Q^T a_q$. This makes $H$ an upper Hessenberg matrix (i.e., $H_{ij} = 0$ for $i > j+1$). To restore the upper triangular form, a sequence of Givens rotations is applied to annihilate the subdiagonal elements of $H$. For a given $p$, this sequence is $G = G_{m-1,m} \\cdots G_{p+1,p+2} G_{p,p+1}$, where $G_{k, k+1}$ is a Givens rotation in the $(k, k+1)$ plane. The new upper triangular matrix is then $R_{\\text{new}} = GH$.\n\nSuppose for a problem with $m=3$ constraints, the algorithm is at a state with the basis matrix\n$$B = \\begin{pmatrix} 1 & 1 & 0 \\\\ 1 & 0 & 1 \\\\ 0 & 1 & 1 \\end{pmatrix}$$\nand its corresponding QR factorization is given by\n$$Q = \\begin{pmatrix} 1/\\sqrt{2} & 1/\\sqrt{6} & -1/\\sqrt{3} \\\\ 1/\\sqrt{2} & -1/\\sqrt{6} & 1/\\sqrt{3} \\\\ 0 & 2/\\sqrt{6} & 1/\\sqrt{3} \\end{pmatrix}, \\quad R = \\begin{pmatrix} \\sqrt{2} & 1/\\sqrt{2} & 1/\\sqrt{2} \\\\ 0 & \\sqrt{3/2} & 1/\\sqrt{6} \\\\ 0 & 0 & 2/\\sqrt{3} \\end{pmatrix}$$\nIn the current pivot step, the column $b_2$ (the second column of $B$) is chosen to leave the basis, so $p=2$. It is replaced by the entering column vector $a_q = \\begin{pmatrix} 1 \\\\ 1 \\\\ 1 \\end{pmatrix}$.\n\nFollowing the procedure described, determine the new upper triangular matrix $R_{\\text{new}}$.", "solution": "The goal is to compute the new upper triangular matrix $R_{\\text{new}}$ after updating the basis matrix $B$. The process involves two main steps: forming the intermediate upper Hessenberg matrix $H$ and then applying a Givens rotation to restore its upper triangular structure.\n\n**Step 1: Form the upper Hessenberg matrix $H$.**\n\nThe current basis is $B = [b_1, b_2, b_3]$, and the new basis is $B_{\\text{new}} = [b_1, a_q, b_3]$, since the second column ($p=2$) is replaced.\nThe matrix $H$ is defined as $H = Q^T B_{\\text{new}} = Q^T [b_1, a_q, b_3] = [Q^T b_1, Q^T a_q, Q^T b_3]$.\n\nFrom the given QR factorization $B=QR$, we know that $Q^T B = R$. This means $Q^T[b_1, b_2, b_3] = [r_1, r_2, r_3]$, where $r_i$ are the columns of $R$.\nTherefore, the first and third columns of $H$ are simply the first and third columns of $R$:\n$h_1 = r_1 = \\begin{pmatrix} \\sqrt{2} \\\\ 0 \\\\ 0 \\end{pmatrix}$\n$h_3 = r_3 = \\begin{pmatrix} 1/\\sqrt{2} \\\\ 1/\\sqrt{6} \\\\ 2/\\sqrt{3} \\end{pmatrix}$\n\nThe second column of $H$, $h_2$, is given by $Q^T a_q$. We compute this product:\n$$h_2 = Q^T a_q = \\begin{pmatrix} 1/\\sqrt{2} & 1/\\sqrt{2} & 0 \\\\ 1/\\sqrt{6} & -1/\\sqrt{6} & 2/\\sqrt{6} \\\\ -1/\\sqrt{3} & 1/\\sqrt{3} & 1/\\sqrt{3} \\end{pmatrix} \\begin{pmatrix} 1 \\\\ 1 \\\\ 1 \\end{pmatrix}$$\n$$h_2 = \\begin{pmatrix} (1/\\sqrt{2}) \\cdot 1 + (1/\\sqrt{2}) \\cdot 1 + 0 \\cdot 1 \\\\ (1/\\sqrt{6}) \\cdot 1 + (-1/\\sqrt{6}) \\cdot 1 + (2/\\sqrt{6}) \\cdot 1 \\\\ (-1/\\sqrt{3}) \\cdot 1 + (1/\\sqrt{3}) \\cdot 1 + (1/\\sqrt{3}) \\cdot 1 \\end{pmatrix} = \\begin{pmatrix} 2/\\sqrt{2} \\\\ 2/\\sqrt{6} \\\\ 1/\\sqrt{3} \\end{pmatrix} = \\begin{pmatrix} \\sqrt{2} \\\\ \\sqrt{2/3} \\\\ 1/\\sqrt{3} \\end{pmatrix}$$\n\nNow we assemble the matrix $H$:\n$$H = [h_1, h_2, h_3] = \\begin{pmatrix} \\sqrt{2} & \\sqrt{2} & 1/\\sqrt{2} \\\\ 0 & \\sqrt{2/3} & 1/\\sqrt{6} \\\\ 0 & 1/\\sqrt{3} & 2/\\sqrt{3} \\end{pmatrix}$$\nThis is an upper Hessenberg matrix, with a single non-zero subdiagonal element at $H_{3,2} = 1/\\sqrt{3}$.\n\n**Step 2: Apply a Givens rotation to restore upper triangular form.**\n\nWe need to annihilate the element $H_{3,2}$. Since the leaving column index is $p=2$ and $m=3$, the general sequence of rotations $G_{m-1,m} \\cdots G_{p,p+1}$ simplifies to a single rotation, $G_{2,3}$. This rotation acts on rows 2 and 3.\n\nA Givens rotation matrix $G_{2,3}$ has the form $\\begin{pmatrix} 1 & 0 & 0 \\\\ 0 & c & s \\\\ 0 & -s & c \\end{pmatrix}$, where $c=\\cos\\theta$ and $s=\\sin\\theta$. It is designed such that when applied to $H$, the new element at position $(3,2)$ is zero.\n$$ \\begin{pmatrix} c & s \\\\ -s & c \\end{pmatrix} \\begin{pmatrix} H_{2,2} \\\\ H_{3,2} \\end{pmatrix} = \\begin{pmatrix} \\text{new } H_{2,2}' \\\\ 0 \\end{pmatrix} $$\nThe condition for the second component to be zero is $-s \\cdot H_{2,2} + c \\cdot H_{3,2} = 0$.\nWe have $H_{2,2} = \\sqrt{2/3}$ and $H_{3,2} = 1/\\sqrt{3}$.\nThe values for $c$ and $s$ can be calculated as:\n$$r = \\sqrt{H_{2,2}^2 + H_{3,2}^2} = \\sqrt{(\\sqrt{2/3})^2 + (1/\\sqrt{3})^2} = \\sqrt{2/3 + 1/3} = \\sqrt{1} = 1$$\n$$c = \\frac{H_{2,2}}{r} = \\frac{\\sqrt{2/3}}{1} = \\sqrt{2/3}$$\n$$s = \\frac{H_{3,2}}{r} = \\frac{1/\\sqrt{3}}{1} = 1/\\sqrt{3}$$\nSo, the Givens rotation matrix is:\n$$G_{2,3} = \\begin{pmatrix} 1 & 0 & 0 \\\\ 0 & \\sqrt{2/3} & 1/\\sqrt{3} \\\\ 0 & -1/\\sqrt{3} & \\sqrt{2/3} \\end{pmatrix}$$\n\nFinally, we compute $R_{\\text{new}} = G_{2,3} H$:\n$$R_{\\text{new}} = \\begin{pmatrix} 1 & 0 & 0 \\\\ 0 & \\sqrt{2/3} & 1/\\sqrt{3} \\\\ 0 & -1/\\sqrt{3} & \\sqrt{2/3} \\end{pmatrix} \\begin{pmatrix} \\sqrt{2} & \\sqrt{2} & 1/\\sqrt{2} \\\\ 0 & \\sqrt{2/3} & 1/\\sqrt{6} \\\\ 0 & 1/\\sqrt{3} & 2/\\sqrt{3} \\end{pmatrix}$$\n\nThe first row of $R_{\\text{new}}$ is the same as the first row of $H$: $(\\sqrt{2}, \\sqrt{2}, 1/\\sqrt{2})$.\n\nThe second row of $R_{\\text{new}}$ is:\n$R_{\\text{new},21} = 0$\n$R_{\\text{new},22} = (\\sqrt{2/3})(\\sqrt{2/3}) + (1/\\sqrt{3})(1/\\sqrt{3}) = 2/3 + 1/3 = 1$\n$R_{\\text{new},23} = (\\sqrt{2/3})(1/\\sqrt{6}) + (1/\\sqrt{3})(2/\\sqrt{3}) = \\sqrt{2/18} + 2/3 = \\sqrt{1/9} + 2/3 = 1/3 + 2/3 = 1$\n\nThe third row of $R_{\\text{new}}$ is:\n$R_{\\text{new},31} = 0$\n$R_{\\text{new},32} = (-1/\\sqrt{3})(\\sqrt{2/3}) + (\\sqrt{2/3})(1/\\sqrt{3}) = 0$ (as expected)\n$R_{\\text{new},33} = (-1/\\sqrt{3})(1/\\sqrt{6}) + (\\sqrt{2/3})(2/\\sqrt{3}) = -1/\\sqrt{18} + 2\\sqrt{2}/3 = -1/(3\\sqrt{2}) + 2\\sqrt{2}/3 = -\\sqrt{2}/6 + 4\\sqrt{2}/6 = 3\\sqrt{2}/6 = \\sqrt{2}/2 = 1/\\sqrt{2}$\n\nAssembling the matrix $R_{\\text{new}}$ gives:\n$$R_{\\text{new}} = \\begin{pmatrix} \\sqrt{2} & \\sqrt{2} & 1/\\sqrt{2} \\\\ 0 & 1 & 1 \\\\ 0 & 0 & 1/\\sqrt{2} \\end{pmatrix}$$\nThis is the new upper triangular matrix.", "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n\\sqrt{2} & \\sqrt{2} & \\frac{1}{\\sqrt{2}} \\\\\n0 & 1 & 1 \\\\\n0 & 0 & \\frac{1}{\\sqrt{2}}\n\\end{pmatrix}\n}\n$$", "id": "2197697"}]}