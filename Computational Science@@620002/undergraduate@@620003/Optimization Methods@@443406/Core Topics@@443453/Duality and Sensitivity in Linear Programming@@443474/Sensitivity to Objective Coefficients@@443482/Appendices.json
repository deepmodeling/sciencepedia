{"hands_on_practices": [{"introduction": "A cornerstone of sensitivity analysis is determining how much an objective coefficient can change before the current optimal solution is no longer valid. This practice focuses on a variable that is already part of the optimal solution (a basic variable) and challenges you to find its 'allowable range'. By ensuring the reduced costs of all non-basic variables remain optimal, you will see how the simplex tableau provides all the information needed to establish the stability of your solution. [@problem_id:3178640]", "problem": "Consider the parametric Linear Programming (LP) problem in standard form with decision variables $x_1$ and $x_2$ and slack variables $s_1$ and $s_2$:\n$$\n\\max z \\;=\\; c_1 x_1 + 3 x_2\n$$\nsubject to\n$$\nx_1 + 2 x_2 + s_1 \\;=\\; 8,\\quad 2 x_1 + x_2 + s_2 \\;=\\; 8,\\quad x_1, x_2, s_1, s_2 \\;\\ge\\; 0.\n$$\nSuppose the Simplex method has produced a current basis consisting of $\\{x_1, x_2\\}$ with the following final simplex tableau (basic rows shown; columns ordered as $x_1, x_2, s_1, s_2$):\n$$\n\\begin{array}{c|rrrr|r}\n & x_1 & x_2 & s_1 & s_2 & \\text{RHS} \\\\\n\\hline\nx_1 & 1 & 0 & -\\frac{1}{3} & \\frac{2}{3} & \\frac{8}{3} \\\\\nx_2 & 0 & 1 & \\frac{2}{3} & -\\frac{1}{3} & \\frac{8}{3}\n\\end{array}\n$$\nUsing only core definitions from Linear Programming and the structure of the Simplex tableau, derive the allowable interval of the objective coefficient $c_1$ such that the current basis $\\{x_1, x_2\\}$ remains optimal for the maximization problem. Report the exact lower and upper bounds as rational numbers. No rounding is required.", "solution": "The problem is subjected to validation.\n\n### Step 1: Extract Givens\n- Objective function: $\\max z \\;=\\; c_1 x_1 + 3 x_2$\n- Constraints:\n  - $x_1 + 2 x_2 + s_1 \\;=\\; 8$\n  - $2 x_1 + x_2 + s_2 \\;=\\; 8$\n  - $x_1, x_2, s_1, s_2 \\;\\ge\\; 0$\n- Parametric coefficient to analyze: $c_1$\n- Current basis: $\\{x_1, x_2\\}$\n- Final simplex tableau for this basis:\n$$\n\\begin{array}{c|rrrr|r}\n & x_1 & x_2 & s_1 & s_2 & \\text{RHS} \\\\\n\\hline\nx_1 & 1 & 0 & -\\frac{1}{3} & \\frac{2}{3} & \\frac{8}{3} \\\\\nx_2 & 0 & 1 & \\frac{2}{3} & -\\frac{1}{3} & \\frac{8}{3}\n\\end{array}\n$$\n\n### Step 2: Validate Using Extracted Givens\nThe problem is a standard exercise in sensitivity analysis for Linear Programming, specifically analyzing the range of an objective function coefficient.\n- **Scientifically Grounded**: The problem is based on the well-established mathematical theory of Linear Programming and the Simplex method. It is factually sound.\n- **Well-Posed**: It asks for a specific interval for a parameter, which is a standard outcome of sensitivity analysis. A unique solution is expected.\n- **Objective**: The problem is stated using precise, unambiguous mathematical terms.\n- **Completeness**: All necessary information (objective, constraints, variables, basis, and final tableau) is provided. The provided RHS values in the tableau are consistent with the original problem constraints and the basis inverse, which can be verified.\n- **No other flaws are detected.**\n\n### Step 3: Verdict and Action\nThe problem is **valid**. A solution will be derived.\n\n### Solution Derivation\nThe optimality of a basis in a maximization Linear Programming (LP) problem is maintained as long as the simplex criterion $z_j - c_j \\ge 0$ holds for all non-basic variables $j$. The term $z_j$ is calculated as $z_j = \\mathbf{c}_B^T \\mathbf{B}^{-1} \\mathbf{a}_j$.\n\nThe set of variables in the problem is $\\{x_1, x_2, s_1, s_2\\}$. The given basis is $\\{x_1, x_2\\}$, which are the basic variables. Therefore, the non-basic variables are $\\{s_1, s_2\\}$.\n\nWe calculate the criterion $z_j - c_j$ using the formula above, where:\n- $\\mathbf{c}_B$ is the vector of objective function coefficients for the basic variables.\n- $\\mathbf{B}^{-1}$ is the inverse of the basis matrix.\n- $\\mathbf{a}_j$ is the column vector for variable $j$ from the original constraint matrix.\n- $c_j$ is the objective function coefficient for variable $j$.\n\nFrom the problem statement, the objective function is $z = c_1 x_1 + 3 x_2 + 0 s_1 + 0 s_2$.\nThe basic variables are $x_1$ and $x_2$. The vector of their objective coefficients is:\n$$ \\mathbf{c}_B^T = \\begin{pmatrix} c_1 & 3 \\end{pmatrix} $$\nThe non-basic variables are $s_1$ and $s_2$. Their objective coefficients are $c_{s_1} = 0$ and $c_{s_2} = 0$.\n\nThe final simplex tableau gives the matrix product $\\mathbf{B}^{-1}\\mathbf{A}$, where $\\mathbf{A}$ is the full constraint matrix. The columns of the final tableau under the non-basic variables correspond to $\\mathbf{B}^{-1}\\mathbf{a}_j$ for each non-basic variable $j$.\n\nFrom the given tableau, we can extract these columns for the non-basic variables $s_1$ and $s_2$:\n- For $s_1$: The column is $\\mathbf{B}^{-1}\\mathbf{a}_{s_1} = \\begin{pmatrix} -\\frac{1}{3} \\\\ \\frac{2}{3} \\end{pmatrix}$.\n- For $s_2$: The column is $\\mathbf{B}^{-1}\\mathbf{a}_{s_2} = \\begin{pmatrix} \\frac{2}{3} \\\\ -\\frac{1}{3} \\end{pmatrix}$.\n\nNow, we can compute the value of the criterion for each non-basic variable.\n\n1.  **Optimality criterion for $s_1$**:\n    $$ z_{s_1} - c_{s_1} = \\mathbf{c}_B^T (\\mathbf{B}^{-1}\\mathbf{a}_{s_1}) - c_{s_1} $$\n    $$ z_{s_1} - c_{s_1} = \\begin{pmatrix} c_1 & 3 \\end{pmatrix} \\begin{pmatrix} -\\frac{1}{3} \\\\ \\frac{2}{3} \\end{pmatrix} - 0 $$\n    $$ z_{s_1} - c_{s_1} = c_1 \\left(-\\frac{1}{3}\\right) + 3 \\left(\\frac{2}{3}\\right) = -\\frac{1}{3}c_1 + 2 $$\n    For optimality, this must be non-negative:\n    $$ -\\frac{1}{3}c_1 + 2 \\ge 0 \\implies 2 \\ge \\frac{1}{3}c_1 \\implies 6 \\ge c_1 $$\n\n2.  **Optimality criterion for $s_2$**:\n    $$ z_{s_2} - c_{s_2} = \\mathbf{c}_B^T (\\mathbf{B}^{-1}\\mathbf{a}_{s_2}) - c_{s_2} $$\n    $$ z_{s_2} - c_{s_2} = \\begin{pmatrix} c_1 & 3 \\end{pmatrix} \\begin{pmatrix} \\frac{2}{3} \\\\ -\\frac{1}{3} \\end{pmatrix} - 0 $$\n    $$ z_{s_2} - c_{s_2} = c_1 \\left(\\frac{2}{3}\\right) + 3 \\left(-\\frac{1}{3}\\right) = \\frac{2}{3}c_1 - 1 $$\n    For optimality, this must be non-negative:\n    $$ \\frac{2}{3}c_1 - 1 \\ge 0 \\implies \\frac{2}{3}c_1 \\ge 1 \\implies 2c_1 \\ge 3 \\implies c_1 \\ge \\frac{3}{2} $$\n\nTo ensure the current basis $\\{x_1, x_2\\}$ remains optimal, both conditions must be satisfied simultaneously. Combining the two inequalities, we obtain the allowable interval for $c_1$:\n$$ \\frac{3}{2} \\le c_1 \\le 6 $$\nThe lower bound for $c_1$ is $\\frac{3}{2}$ and the upper bound is $6$.", "answer": "$$\n\\boxed{\\begin{pmatrix} \\frac{3}{2} & 6 \\end{pmatrix}}\n$$", "id": "3178640"}, {"introduction": "While the previous exercise examined the stability of the current plan, this problem explores the conditions for change. We now focus on a non-basic variable—an activity not chosen in the current optimal solution—and ask: at what point does its profitability make it attractive enough to consider? This practice requires you to calculate the precise threshold for an objective coefficient that would make its corresponding variable's reduced cost favorable, prompting it to enter the basis. [@problem_id:3178669]", "problem": "Consider the following Linear Programming (LP) problem in standard inequality form with slack variables introduced to obtain equalities. The primal is a maximization problem:\n$$\n\\text{maximize } c_1 x_1 + c_2 x_2 + c_3 x_3\n$$\nsubject to\n$$\n\\begin{aligned}\n2 x_1 + x_2 + x_3 + s_1 &= 8, \\\\\n- x_1 + 2 x_2 + 3 x_3 + s_2 &= 10, \\\\\nx_1, x_2, x_3, s_1, s_2 &\\geq 0,\n\\end{aligned}\n$$\nwhere $x_1, x_2, x_3$ are decision variables and $s_1, s_2$ are slack variables. The current optimal basis is reported to be $\\{ s_1, x_2 \\}$, with the associated basic feasible solution computed from the constraints. The objective coefficients are $c_1 = -4$, $c_2 = 7$, and $c_3$ is treated as a parameter that may vary.\n\nUsing only foundational definitions of LP duality, basic feasible solutions, and the Karush–Kuhn–Tucker (KKT) conditions, analyze the sensitivity of the optimal solution with respect to the single objective coefficient $c_3$ when the corresponding variable $x_3$ is currently nonbasic. In particular:\n- Determine the dual price vector (also called shadow prices) associated with the current basis.\n- Derive the reduced cost of $x_3$ as a function of $c_3$.\n- Compute the exact value of $c_3$ at which $x_3$ first becomes eligible to enter the basis (i.e., the threshold value where the sign condition for optimality is violated in a way that favors $x_3$ entering).\n\nProvide the final threshold as a single real number $c_3^\\star$. Express the answer exactly; do not round.", "solution": "The problem requires an analysis of the sensitivity of an optimal linear programming (LP) solution to a change in an objective function coefficient, $c_3$, for a nonbasic variable, $x_3$. The analysis must be based on foundational principles of duality and the Karush-Kuhn-Tucker (KKT) conditions.\n\nThe primal LP problem is given in standard form after introducing slack variables:\n$$\n\\text{maximize } z = c_1 x_1 + c_2 x_2 + c_3 x_3 + 0 s_1 + 0 s_2\n$$\nsubject to\n$$\n\\begin{aligned}\n2 x_1 + x_2 + x_3 + s_1 &= 8 \\\\\n-x_1 + 2 x_2 + 3 x_3 + s_2 &= 10 \\\\\nx_1, x_2, x_3, s_1, s_2 &\\geq 0\n\\end{aligned}\n$$\nThe objective coefficients are $c_1 = -4$, $c_2 = 7$, and $c_3$ is a parameter.\nIn matrix form, we want to maximize $\\mathbf{c}^T \\mathbf{x}$ subject to $\\mathbf{A}\\mathbf{x} = \\mathbf{b}$ and $\\mathbf{x} \\geq \\mathbf{0}$, where:\n$$ \\mathbf{x} = \\begin{pmatrix} x_1 \\\\ x_2 \\\\ x_3 \\\\ s_1 \\\\ s_2 \\end{pmatrix}, \\quad \\mathbf{c} = \\begin{pmatrix} -4 \\\\ 7 \\\\ c_3 \\\\ 0 \\\\ 0 \\end{pmatrix}, \\quad \\mathbf{A} = \\begin{pmatrix} 2 & 1 & 1 & 1 & 0 \\\\ -1 & 2 & 3 & 0 & 1 \\end{pmatrix}, \\quad \\mathbf{b} = \\begin{pmatrix} 8 \\\\ 10 \\end{pmatrix} $$\nThe problem states that the current optimal basis is $\\mathcal{B} = \\{s_1, x_2\\}$. The set of basic variables is $\\mathbf{x}_B = [s_1, x_2]^T$ and the set of nonbasic variables is $\\mathbf{x}_N = [x_1, x_3, s_2]^T$.\n\nThe basis matrix, $\\mathbf{B}$, consists of the columns of $\\mathbf{A}$ corresponding to the basic variables, which are column $4$ ($s_1$) and column $2$ ($x_2$).\n$$ \\mathbf{B} = \\begin{pmatrix} 1 & 1 \\\\ 0 & 2 \\end{pmatrix} $$\nThe cost vector for the basic variables is $\\mathbf{c}_B = [c_{s_1}, c_{x_2}]^T = [0, 7]^T$.\n\nFirst, we verify that this basis corresponds to a basic feasible solution (BFS). The values of the basic variables are given by $\\mathbf{x}_B = \\mathbf{B}^{-1}\\mathbf{b}$. We compute the inverse of $\\mathbf{B}$:\n$$ \\mathbf{B}^{-1} = \\frac{1}{(1)(2) - (1)(0)} \\begin{pmatrix} 2 & -1 \\\\ 0 & 1 \\end{pmatrix} = \\begin{pmatrix} 1 & -1/2 \\\\ 0 & 1/2 \\end{pmatrix} $$\nNow we compute the basic solution:\n$$ \\mathbf{x}_B = \\begin{pmatrix} s_1 \\\\ x_2 \\end{pmatrix} = \\begin{pmatrix} 1 & -1/2 \\\\ 0 & 1/2 \\end{pmatrix} \\begin{pmatrix} 8 \\\\ 10 \\end{pmatrix} = \\begin{pmatrix} 8 - 5 \\\\ 0 + 5 \\end{pmatrix} = \\begin{pmatrix} 3 \\\\ 5 \\end{pmatrix} $$\nSince $s_1 = 3 \\geq 0$ and $x_2 = 5 \\geq 0$, the solution is feasible. The full solution vector is $\\mathbf{x} = [0, 5, 0, 3, 0]^T$.\n\nThe dual price vector (or shadow prices), denoted by $\\mathbf{y}$, is associated with the constraints. For a given basis $\\mathbf{B}$, the dual prices are defined by the relation $\\mathbf{y}^T = \\mathbf{c}_B^T \\mathbf{B}^{-1}$. This definition ensures that the reduced costs of the basic variables are zero, a necessary condition for optimality.\n$$ \\mathbf{y}^T = \\begin{pmatrix} 0 & 7 \\end{pmatrix} \\begin{pmatrix} 1 & -1/2 \\\\ 0 & 1/2 \\end{pmatrix} = \\begin{pmatrix} 0 & 7/2 \\end{pmatrix} $$\nThus, the dual price vector is $\\mathbf{y} = [y_1, y_2]^T = [0, 7/2]^T$.\n\nThe KKT conditions provide the fundamental basis for optimality. For an LP, they consist of primal feasibility, dual feasibility, and complementary slackness. The reduced cost of a variable $x_j$, denoted $\\bar{c}_j$, is directly related to the KKT multipliers. For a maximization problem, the reduced cost is defined as $\\bar{c}_j = c_j - \\mathbf{y}^T \\mathbf{A}_j$, where $\\mathbf{A}_j$ is the $j$-th column of the constraint matrix $\\mathbf{A}$. A solution is optimal if and only if all reduced costs are non-positive, $\\bar{c}_j \\leq 0$ for all $j$.\n\nWe compute the reduced costs for the nonbasic variables $x_1$, $x_3$, and $s_2$. The columns from $\\mathbf{A}$ are $\\mathbf{A}_1 = [2, -1]^T$, $\\mathbf{A}_3 = [1, 3]^T$, and $\\mathbf{A}_5 = [0, 1]^T$. The corresponding costs are $c_1=-4$, $c_3$, and $c_{s_2}=0$.\n\nThe reduced cost for $x_1$:\n$$ \\bar{c}_1 = c_1 - \\mathbf{y}^T \\mathbf{A}_1 = -4 - \\begin{pmatrix} 0 & 7/2 \\end{pmatrix} \\begin{pmatrix} 2 \\\\ -1 \\end{pmatrix} = -4 - (-\\frac{7}{2}) = -\\frac{1}{2} $$\nThe reduced cost for $x_3$:\n$$ \\bar{c}_3 = c_3 - \\mathbf{y}^T \\mathbf{A}_3 = c_3 - \\begin{pmatrix} 0 & 7/2 \\end{pmatrix} \\begin{pmatrix} 1 \\\\ 3 \\end{pmatrix} = c_3 - \\frac{21}{2} $$\nThis is the reduced cost of $x_3$ as a function of $c_3$.\n\nThe reduced cost for $s_2$:\n$$ \\bar{c}_{s_2} = c_{s_2} - \\mathbf{y}^T \\mathbf{A}_5 = 0 - \\begin{pmatrix} 0 & 7/2 \\end{pmatrix} \\begin{pmatrix} 0 \\\\ 1 \\end{pmatrix} = -\\frac{7}{2} $$\nFor the given basis to be optimal, all these reduced costs must be less than or equal to zero.\n$$ \\bar{c}_1 = -1/2 \\leq 0 \\quad (\\text{satisfied}) $$\n$$ \\bar{c}_{s_2} = -7/2 \\leq 0 \\quad (\\text{satisfied}) $$\n$$ \\bar{c}_3 = c_3 - \\frac{21}{2} \\leq 0 \\implies c_3 \\leq \\frac{21}{2} $$\nThe current basis is optimal as long as $c_3 \\leq 21/2$.\n\nA nonbasic variable becomes eligible to enter the basis if increasing its value from $0$ improves the objective function. For a maximization problem, this occurs when its reduced cost is positive, i.e., $\\bar{c}_j > 0$. The threshold value, $c_3^\\star$, is the value of $c_3$ at which this condition is first met. This occurs at the boundary of the optimality region, where the reduced cost becomes zero.\n$$ \\bar{c}_3 = 0 \\implies c_3 - \\frac{21}{2} = 0 $$\n$$ c_3^\\star = \\frac{21}{2} $$\nFor any $c_3 > 21/2$, the reduced cost $\\bar{c}_3$ will be positive, signifying that the optimality condition is violated and $x_3$ is a candidate to enter the basis to increase the objective function value. Therefore, the threshold value is $21/2$.", "answer": "$$\\boxed{\\frac{21}{2}}$$", "id": "3178669"}, {"introduction": "The principles of sensitivity analysis extend far beyond the standard simplex algorithm, applying to a wide range of optimization problems. This hands-on exercise moves into the domain of network optimization, where you will analyze a shortest path problem with parametric arc costs. Your task is to determine the complete sequence of optimal paths as a parameter $\\theta$ varies, effectively mapping out the solution's evolution and identifying the critical values of $\\theta$ where the optimal path itself switches. [@problem_id:3178654]", "problem": "Consider a directed acyclic network with nodes $s$, $a$, $b$, $c$, and $t$. Each arc $e$ has a parametric cost of the form $c_{e}(\\theta) = c_{e} + \\theta d_{e}$, where $\\theta \\in \\mathbb{R}$ is a parameter, $c_{e} \\in \\mathbb{R}$ is the base cost, and $d_{e} \\in \\mathbb{R}$ is the sensitivity coefficient. The available arcs and their coefficients are:\n- From $s$ to $a$: $c_{sa} = 4$, $d_{sa} = 1$.\n- From $s$ to $b$: $c_{sb} = 2$, $d_{sb} = 3$.\n- From $s$ to $c$: $c_{sc} = 10$, $d_{sc} = -2$.\n- From $a$ to $c$: $c_{ac} = 3$, $d_{ac} = 2$.\n- From $a$ to $t$: $c_{at} = 9$, $d_{at} = -1$.\n- From $b$ to $c$: $c_{bc} = 2$, $d_{bc} = 2$.\n- From $b$ to $t$: $c_{bt} = 7$, $d_{bt} = 0$.\n- From $c$ to $t$: $c_{ct} = 1$, $d_{ct} = 4$.\n\nA path cost is the sum of its arc costs. Using the foundational definition that the shortest path minimizes the total path cost, construct the parametric shortest path problem by explicitly writing the path-cost functions for all $s$–$t$ paths as functions of $\\theta$. Then determine the sequence of optimal paths as $\\theta$ varies over $\\mathbb{R}$ by identifying the critical values of $\\theta$ at which the optimal path changes. Report, as your final answer, the ordered set of these critical parameter values as a single row matrix using exact fractions. No rounding is required.", "solution": "The problem is first validated against the specified criteria.\n\n### Step 1: Extract Givens\n- **Nodes**: $s$, $a$, $b$, $c$, $t$ in a directed acyclic network.\n- **Parametric Arc Cost**: For each arc $e$, the cost is $c_{e}(\\theta) = c_{e} + \\theta d_{e}$, where $\\theta \\in \\mathbb{R}$.\n- **Arc Cost Coefficients**:\n  - Arc $(s,a)$: $c_{sa} = 4$, $d_{sa} = 1$.\n  - Arc $(s,b)$: $c_{sb} = 2$, $d_{sb} = 3$.\n  - Arc $(s,c)$: $c_{sc} = 10$, $d_{sc} = -2$.\n  - Arc $(a,c)$: $c_{ac} = 3$, $d_{ac} = 2$.\n  - Arc $(a,t)$: $c_{at} = 9$, $d_{at} = -1$.\n  - Arc $(b,c)$: $c_{bc} = 2$, $d_{bc} = 2$.\n  - Arc $(b,t)$: $c_{bt} = 7$, $d_{bt} = 0$.\n  - Arc $(c,t)$: $c_{ct} = 1$, $d_{ct} = 4$.\n- **Task**:\n  1. Write the path-cost functions for all $s$–$t$ paths.\n  2. Determine the sequence of optimal paths as $\\theta$ varies.\n  3. Identify the critical values of $\\theta$ where the optimal path changes.\n  4. Report the ordered set of critical values as a row matrix.\n\n### Step 2: Validate Using Extracted Givens\nThe problem is subjected to a critical review:\n- **Scientifically Grounded**: The problem is a standard exercise in parametric sensitivity analysis for the shortest path problem, a fundamental topic in network optimization and operations research. The model is based on established mathematical principles.\n- **Well-Posed**: The problem is defined on a directed acyclic graph (DAG), which guarantees that all paths are simple. The cost functions are linear in a single parameter $\\theta$. The objective is to find the shortest path, which is well-defined. Because the cost functions are linear, the minimum cost function (the lower envelope) is a piecewise-linear, concave function, ensuring that a unique solution exists for all $\\theta$ except at a finite number of critical points where multiple paths may be optimal.\n- **Objective**: The problem is stated using precise mathematical language and numerical data. There are no subjective or ambiguous terms.\n- **Completeness and Consistency**: All necessary data (graph structure, cost parameters) are provided, and there are no internal contradictions.\n- **Other criteria**: The problem does not violate any other validation criteria. It is a formal, solvable problem.\n\n### Step 3: Verdict and Action\nThe problem is valid and well-posed. A complete solution will be developed.\n\nThe problem requires finding the sequence of shortest paths from node $s$ to node $t$ as the parameter $\\theta$ varies. The cost of any path is the sum of the costs of its arcs.\n\nFirst, we must enumerate all simple paths from $s$ to $t$ in the given directed acyclic graph.\nThe paths are:\n1. $P_1: s \\rightarrow a \\rightarrow c \\rightarrow t$\n2. $P_2: s \\rightarrow a \\rightarrow t$\n3. $P_3: s \\rightarrow b \\rightarrow c \\rightarrow t$\n4. $P_4: s \\rightarrow b \\rightarrow t$\n5. $P_5: s \\rightarrow c \\rightarrow t$\n\nNext, we formulate the total cost function for each path, $f_i(\\theta)$, by summing the parametric costs of the arcs in path $P_i$. The general form is $f_i(\\theta) = C_i + \\theta D_i$, where $C_i$ is the sum of the base costs $c_e$ and $D_i$ is the sum of the sensitivity coefficients $d_e$ for the arcs in path $P_i$.\n\n1.  For $P_1: s \\rightarrow a \\rightarrow c \\rightarrow t$:\n    $C_1 = c_{sa} + c_{ac} + c_{ct} = 4 + 3 + 1 = 8$\n    $D_1 = d_{sa} + d_{ac} + d_{ct} = 1 + 2 + 4 = 7$\n    $f_1(\\theta) = 8 + 7\\theta$\n\n2.  For $P_2: s \\rightarrow a \\rightarrow t$:\n    $C_2 = c_{sa} + c_{at} = 4 + 9 = 13$\n    $D_2 = d_{sa} + d_{at} = 1 + (-1) = 0$\n    $f_2(\\theta) = 13$\n\n3.  For $P_3: s \\rightarrow b \\rightarrow c \\rightarrow t$:\n    $C_3 = c_{sb} + c_{bc} + c_{ct} = 2 + 2 + 1 = 5$\n    $D_3 = d_{sb} + d_{bc} + d_{ct} = 3 + 2 + 4 = 9$\n    $f_3(\\theta) = 5 + 9\\theta$\n\n4.  For $P_4: s \\rightarrow b \\rightarrow t$:\n    $C_4 = c_{sb} + c_{bt} = 2 + 7 = 9$\n    $D_4 = d_{sb} + d_{bt} = 3 + 0 = 3$\n    $f_4(\\theta) = 9 + 3\\theta$\n\n5.  For $P_5: s \\rightarrow c \\rightarrow t$:\n    $C_5 = c_{sc} + c_{ct} = 10 + 1 = 11$\n    $D_5 = d_{sc} + d_{ct} = -2 + 4 = 2$\n    $f_5(\\theta) = 11 + 2\\theta$\n\nThe shortest path cost for a given $\\theta$ is $f^*(\\theta) = \\min \\{f_1(\\theta), f_2(\\theta), f_3(\\theta), f_4(\\theta), f_5(\\theta)\\}$. This function, $f^*(\\theta)$, represents the lower envelope of the set of linear path-cost functions. Critical values of $\\theta$ are the points where the identity of the minimizing path changes. These are the breakpoints of the piecewise-linear, concave function $f^*(\\theta)$.\n\nTo find these breakpoints, we analyze which path is optimal in different ranges of $\\theta$.\n- For $\\theta \\to -\\infty$, the path cost is dominated by the term with the largest slope, $D_i$. The minimum cost will be achieved by the path with the largest $D_i$. The slopes are $D_1=7, D_2=0, D_3=9, D_4=3, D_5=2$. The largest slope is $D_3=9$, so path $P_3$ is optimal for sufficiently small $\\theta$.\n- For $\\theta \\to +\\infty$, the path cost is dominated by the term with the smallest slope, $D_i$. The minimum cost will be achieved by the path with the smallest $D_i$. The smallest slope is $D_2=0$, so path $P_2$ is optimal for sufficiently large $\\theta$.\n\nThe sequence of optimal paths will transition from $P_3$ to other paths and eventually to $P_2$ as $\\theta$ increases. The transitions occur at the intersections of the cost functions that form the lower envelope.\n\nLet's start with path $P_3$ being optimal and find the first critical point by increasing $\\theta$. We find the intersection of $f_3(\\theta)$ with all other functions:\n- $f_3(\\theta) = f_1(\\theta) \\implies 5 + 9\\theta = 8 + 7\\theta \\implies 2\\theta = 3 \\implies \\theta = \\frac{3}{2}$\n- $f_3(\\theta) = f_2(\\theta) \\implies 5 + 9\\theta = 13 \\implies 9\\theta = 8 \\implies \\theta = \\frac{8}{9}$\n- $f_3(\\theta) = f_4(\\theta) \\implies 5 + 9\\theta = 9 + 3\\theta \\implies 6\\theta = 4 \\implies \\theta = \\frac{2}{3}$\n- $f_3(\\theta) = f_5(\\theta) \\implies 5 + 9\\theta = 11 + 2\\theta \\implies 7\\theta = 6 \\implies \\theta = \\frac{6}{7}$\n\nThe smallest of these intersection values is $\\theta = \\frac{2}{3}$. This is the first candidate for a critical point. At $\\theta = \\frac{2}{3}$, $f_3(\\theta) = f_4(\\theta) = 5 + 9(\\frac{2}{3}) = 11$. For $\\theta < \\frac{2}{3}$, $f_3(\\theta) < f_4(\\theta)$. We must verify that $P_3$ is indeed optimal for all $\\theta < \\frac{2}{3}$. This requires $f_3(\\theta) \\le f_j(\\theta)$ for $j \\in \\{1, 2, 4, 5\\}$ for all $\\theta < \\frac{2}{3}$. This holds if $\\theta$ is smaller than all intersection points found above, which is true for $\\theta < \\frac{2}{3}$. Thus, for $\\theta \\in (-\\infty, \\frac{2}{3}]$, $P_3$ is the optimal path. At $\\theta=\\frac{2}{3}$, the optimal path changes from $P_3$ to $P_4$. Hence, $\\theta_1 = \\frac{2}{3}$ is the first critical value.\n\nNow, for $\\theta > \\frac{2}{3}$, path $P_4$ is the new optimal path. We find its intersections with other paths to find the next critical point.\n- $f_4(\\theta) = f_1(\\theta) \\implies 9 + 3\\theta = 8 + 7\\theta \\implies 1 = 4\\theta \\implies \\theta = \\frac{1}{4}$. This is less than $\\frac{2}{3}$, so not relevant for the next transition.\n- $f_4(\\theta) = f_2(\\theta) \\implies 9 + 3\\theta = 13 \\implies 3\\theta = 4 \\implies \\theta = \\frac{4}{3}$.\n- $f_4(\\theta) = f_5(\\theta) \\implies 9 + 3\\theta = 11 + 2\\theta \\implies \\theta = 2$.\n\nThe next potential critical point for $\\theta > \\frac{2}{3}$ is the minimum of $\\{\\frac{4}{3}, 2\\}$, which is $\\theta = \\frac{4}{3}$. At this point, $f_4(\\theta) = f_2(\\theta) = 9 + 3(\\frac{4}{3}) = 13$. For $\\theta \\in (\\frac{2}{3}, \\frac{4}{3})$, $f_4(\\theta) < f_2(\\theta)$. We must check if $P_4$ is optimal in this interval. For $P_4$ to be optimal on $[\\frac{2}{3}, \\frac{4}{3}]$, we need $f_4(\\theta) \\le f_j(\\theta)$ for $j \\in \\{1,2,3,5\\}$.\n- $f_4(\\theta) \\le f_1(\\theta) \\implies \\theta \\ge \\frac{1}{4}$ (True for this interval).\n- $f_4(\\theta) \\le f_2(\\theta) \\implies \\theta \\le \\frac{4}{3}$ (True for this interval).\n- $f_4(\\theta) \\le f_3(\\theta) \\implies \\theta \\ge \\frac{2}{3}$ (True for this interval).\n- $f_4(\\theta) \\le f_5(\\theta) \\implies \\theta \\le 2$ (True for this interval).\nThus, for $\\theta \\in [\\frac{2}{3}, \\frac{4}{3}]$, $P_4$ is the optimal path. At $\\theta = \\frac{4}{3}$, the optimal path changes from $P_4$ to $P_2$. Hence, $\\theta_2 = \\frac{4}{3}$ is the second critical value.\n\nFor $\\theta > \\frac{4}{3}$, path $P_2$ is the new optimal path. We check its intersections with other functions for $\\theta > \\frac{4}{3}$.\n- $f_2(\\theta) = f_1(\\theta) \\implies 13 = 8 + 7\\theta \\implies 7\\theta = 5 \\implies \\theta = \\frac{5}{7}$. (Less than $\\frac{4}{3}$)\n- $f_2(\\theta) = f_3(\\theta) \\implies 13 = 5 + 9\\theta \\implies 9\\theta = 8 \\implies \\theta = \\frac{8}{9}$. (Less than $\\frac{4}{3}$)\n- $f_2(\\theta) = f_5(\\theta) \\implies 13 = 11 + 2\\theta \\implies 2\\theta = 2 \\implies \\theta = 1$. (Less than $\\frac{4}{3}$)\nSince all intersections of $f_2(\\theta)$ with other functions occur at $\\theta < \\frac{4}{3}$, there are no further changes in the optimal path for $\\theta > \\frac{4}{3}$. Path $P_2$ remains optimal for all $\\theta \\in [\\frac{4}{3}, \\infty)$.\n\nThe sequence of optimal paths is:\n- $P_3$ for $\\theta \\in (-\\infty, \\frac{2}{3}]$\n- $P_4$ for $\\theta \\in [\\frac{2}{3}, \\frac{4}{3}]$\n- $P_2$ for $\\theta \\in [\\frac{4}{3}, \\infty)$\n\nThe points at which the optimal path changes are the critical values. The ordered set of critical values is $\\{\\frac{2}{3}, \\frac{4}{3}\\}$.", "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n\\frac{2}{3} & \\frac{4}{3}\n\\end{pmatrix}\n}\n$$", "id": "3178654"}]}