{"hands_on_practices": [{"introduction": "This first practice walks you through the essential mechanics of Lagrangian duality. Starting with a common problem type—minimizing the maximum of several functions—you will use the epigraph transformation to restate it as a standard linear program. From there, you will apply the fundamental recipe of forming the Lagrangian, deriving the dual function, and finally formulating the dual problem [@problem_id:3139654]. This exercise is crucial for building the foundational skill of constructing duals from scratch and for seeing how the dual constraints can reveal a beautiful geometric interpretation of the original problem.", "problem": "Consider the family of affine functions $\\{a_{i}^{\\top} x - b_{i}\\}_{i=1}^{m}$ with $a_{i} \\in \\mathbb{R}^{n}$ and $b_{i} \\in \\mathbb{R}$, and the convex optimization problem\n$$\\min_{x \\in \\mathbb{R}^{n}} \\ \\max_{i \\in \\{1,\\dots,m\\}} \\ \\left(a_{i}^{\\top} x - b_{i}\\right).$$\nUsing the epigraph transformation, this can be written as\n$$\\min_{x \\in \\mathbb{R}^{n}, \\ t \\in \\mathbb{R}} \\ t \\quad \\text{subject to} \\quad a_{i}^{\\top} x - b_{i} \\le t \\ \\text{ for all } i \\in \\{1,\\dots,m\\}.$$\nStarting from the fundamental definition of the Lagrangian and the Lagrangian dual function for convex programs, derive the dual problem of this epigraph formulation. Interpret the dual feasibility conditions in terms of convex combinations of the vectors $\\{a_{i}\\}_{i=1}^{m}$.\n\nThen, for the concrete instance in $\\mathbb{R}^{2}$ with $m=3$ specified by\n$$a_{1}=\\begin{pmatrix}1\\\\0\\end{pmatrix}, \\quad a_{2}=\\begin{pmatrix}0\\\\1\\end{pmatrix}, \\quad a_{3}=\\begin{pmatrix}-1\\\\-1\\end{pmatrix}, \\quad b_{1}=1, \\quad b_{2}=2, \\quad b_{3}=3,$$\ncompute the optimal objective value $t^{\\star}$ of the original problem. Express the final answer as the exact value of $t^{\\star}$ (no rounding is required).", "solution": "This problem is solved in two parts. First, we derive the general dual problem for the epigraph formulation. Second, we solve the specific instance provided.\n\n**Part 1: Derivation of the Dual Problem**\n\nThe primal problem is a linear program with variables $x \\in \\mathbb{R}^n$ and $t \\in \\mathbb{R}$:\n$$\n\\begin{array}{ll}\n\\min_{x, t} & t \\\\\n\\text{subject to} & a_i^\\top x - b_i \\le t, \\quad i=1, \\dots, m\n\\end{array}\n$$\nWe rewrite the constraints as $a_i^\\top x - t - b_i \\le 0$. To form the Lagrangian, we introduce a non-negative Lagrange multiplier $\\lambda_i \\ge 0$ for each of the $m$ constraints. The Lagrangian $L(x, t, \\lambda)$ is:\n$$\nL(x, t, \\lambda) = t + \\sum_{i=1}^m \\lambda_i (a_i^\\top x - t - b_i)\n$$\nwhere $\\lambda = (\\lambda_1, \\dots, \\lambda_m) \\in \\mathbb{R}^m$. To find the dual function $g(\\lambda)$, we take the infimum of the Lagrangian over the primal variables $x$ and $t$. Rearranging terms to group $x$ and $t$:\n$$\nL(x, t, \\lambda) = \\left( \\sum_{i=1}^m \\lambda_i a_i^\\top \\right) x + \\left( 1 - \\sum_{i=1}^m \\lambda_i \\right) t - \\sum_{i=1}^m \\lambda_i b_i\n$$\nThe Lagrangian is an affine function of $x$ and $t$. For its infimum over $\\mathbb{R}^n$ and $\\mathbb{R}$ to be finite (i.e., not $-\\infty$), the coefficients of the variables must be zero. This yields two conditions on $\\lambda$:\n1.  The coefficient of $x$ must be zero: $\\sum_{i=1}^m \\lambda_i a_i^\\top = 0$, which is equivalent to $\\sum_{i=1}^m \\lambda_i a_i = 0$.\n2.  The coefficient of $t$ must be zero: $1 - \\sum_{i=1}^m \\lambda_i = 0$, which implies $\\sum_{i=1}^m \\lambda_i = 1$.\n\nIf these two conditions are met, the Lagrangian simplifies to $-\\sum_{i=1}^m \\lambda_i b_i$. Otherwise, its infimum is $-\\infty$. The dual function $g(\\lambda)$ is thus:\n$$\ng(\\lambda) = \\begin{cases}\n-\\sum_{i=1}^m \\lambda_i b_i & \\text{if } \\sum_{i=1}^m \\lambda_i a_i = 0 \\text{ and } \\sum_{i=1}^m \\lambda_i = 1 \\\\\n-\\infty & \\text{otherwise}\n\\end{cases}\n$$\nThe dual problem is to maximize $g(\\lambda)$ subject to the constraints $\\lambda_i \\ge 0$. This gives the dual problem:\n$$\n\\begin{array}{ll}\n\\max_{\\lambda \\in \\mathbb{R}^m} & -\\sum_{i=1}^m \\lambda_i b_i \\\\\n\\text{subject to} & \\sum_{i=1}^m \\lambda_i a_i = 0 \\\\\n& \\sum_{i=1}^m \\lambda_i = 1 \\\\\n& \\lambda_i \\ge 0, \\quad i=1, \\dots, m\n\\end{array}\n$$\nThe dual feasibility conditions ($\\sum \\lambda_i = 1$ and $\\lambda_i \\ge 0$) mean that $\\sum \\lambda_i a_i$ is a convex combination of the vectors $\\{a_i\\}$. The condition $\\sum \\lambda_i a_i = 0$ therefore states that the origin of $\\mathbb{R}^n$ must lie within the convex hull of the points $\\{a_1, \\dots, a_m\\}$.\n\n**Part 2: Solving the Concrete Instance**\n\nWe are given $n=2$, $m=3$, with $a_1 = (1,0)^\\top$, $a_2 = (0,1)^\\top$, $a_3 = (-1,-1)^\\top$, and $b_1=1, b_2=2, b_3=3$. We solve the dual problem to find the optimal value. The dual feasibility constraints on $\\lambda = (\\lambda_1, \\lambda_2, \\lambda_3)$ are:\n$$\n\\lambda_1 \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix} + \\lambda_2 \\begin{pmatrix} 0 \\\\ 1 \\end{pmatrix} + \\lambda_3 \\begin{pmatrix} -1 \\\\ -1 \\end{pmatrix} = \\begin{pmatrix} 0 \\\\ 0 \\end{pmatrix}\n$$\n$$\n\\lambda_1 + \\lambda_2 + \\lambda_3 = 1\n$$\n$$\n\\lambda_1, \\lambda_2, \\lambda_3 \\ge 0\n$$\nThe vector equation gives a system of two linear equations:\n1.  $\\lambda_1 - \\lambda_3 = 0 \\implies \\lambda_1 = \\lambda_3$\n2.  $\\lambda_2 - \\lambda_3 = 0 \\implies \\lambda_2 = \\lambda_3$\n\nThus, we must have $\\lambda_1 = \\lambda_2 = \\lambda_3$. Substituting this into the sum constraint:\n$$\n\\lambda_1 + \\lambda_1 + \\lambda_1 = 1 \\implies 3\\lambda_1 = 1 \\implies \\lambda_1 = 1/3\n$$\nThe unique feasible dual solution is $\\lambda^\\star = (1/3, 1/3, 1/3)$. Since this is a convex problem (in fact, a linear program), strong duality holds. The optimal primal value $t^\\star$ is equal to the optimal dual value $d^\\star$. We calculate $d^\\star$ using the dual objective function:\n$$\nd^\\star = -\\sum_{i=1}^3 \\lambda_i^\\star b_i = - \\left( \\frac{1}{3} \\cdot b_1 + \\frac{1}{3} \\cdot b_2 + \\frac{1}{3} \\cdot b_3 \\right)\n$$\n$$\nd^\\star = - \\frac{1}{3} (1 + 2 + 3) = - \\frac{6}{3} = -2\n$$\nTherefore, the optimal objective value of the original problem is $t^\\star = -2$.", "answer": "$$\\boxed{-2}$$", "id": "3139654"}, {"introduction": "After learning how to derive a dual problem, how can we use it? This practice focuses on the powerful relationship between primal and dual optimal solutions, codified in the Karush-Kuhn-Tucker (KKT) conditions, particularly complementary slackness. You will work with a simple linear program specifically designed to have multiple optimal solutions, allowing you to focus on the core logic [@problem_id:3139561]. By verifying that a proposed pair of primal and dual solutions satisfies both feasibility and complementary slackness, you will demonstrate their optimality, thereby gaining hands-on experience with one of the most fundamental and practical tools in optimization.", "problem": "Consider the following pair of Linear Programming (LP) problems in primal and dual form, respectively. The primal is\n$$\\min\\ c^{\\top}x \\quad \\text{subject to} \\quad Ax \\ge b,\\ x \\ge 0,$$\nand the dual is\n$$\\max\\ b^{\\top}y \\quad \\text{subject to} \\quad A^{\\top}y \\le c,\\ y \\ge 0,$$\nwhere\n$$A=\\begin{pmatrix}1 & 1 \\\\ 1 & 1\\end{pmatrix},\\quad b=\\begin{pmatrix}1 \\\\ 1\\end{pmatrix},\\quad c=\\begin{pmatrix}1 \\\\ 1\\end{pmatrix}.$$\nThis data intentionally introduces ties that produce multiple optimal solutions in both the primal and the dual. Using only core definitions of duality and complementary slackness (no shortcut formulas), determine the common optimal objective value shared by the primal and the dual. Express your final answer as a single real number. No rounding is required.", "solution": "The problem asks for the common optimal objective value of a primal-dual pair of Linear Programs (LPs). We will use the principle of complementary slackness, which provides a certificate of optimality.\n\nLet $x = (x_1, x_2)^\\top$ and $y = (y_1, y_2)^\\top$. Substituting the given data, the primal problem is:\n$$ \\min\\ z_P = x_1 + x_2 $$\nsubject to:\n$$ x_1 + x_2 \\ge 1, \\quad x_1 \\ge 0, \\quad x_2 \\ge 0 $$\nThe dual problem is:\n$$ \\max\\ z_D = y_1 + y_2 $$\nsubject to:\n$$ y_1 + y_2 \\le 1, \\quad y_1 \\ge 0, \\quad y_2 \\ge 0 $$\nA pair of feasible solutions, $x^*$ for the primal and $y^*$ for the dual, are optimal if and only if they satisfy the complementary slackness conditions:\n1.  $y^{*\\top}(Ax^* - b) = 0$\n2.  $x^{*\\top}(c - A^{\\top}y^*) = 0$\n\nWe can find the optimal value by proposing a feasible primal-dual pair $(x^*, y^*)$ and verifying that they satisfy these conditions. Let's propose the candidate primal solution $x^* = (1, 0)^\\top$ and dual solution $y^* = (1, 0)^\\top$.\n\nFirst, we verify the feasibility of $x^*$:\nThe non-negativity constraints $x_1^* \\ge 0$ and $x_2^* \\ge 0$ are satisfied ($1 \\ge 0$ and $0 \\ge 0$).\nThe main constraint is $x_1^* + x_2^* = 1+0 = 1 \\ge 1$. Thus, $x^*$ is a feasible solution for the primal problem.\n\nNext, we verify the feasibility of $y^*$:\nThe non-negativity constraints $y_1^* \\ge 0$ and $y_2^* \\ge 0$ are satisfied ($1 \\ge 0$ and $0 \\ge 0$).\nThe main constraint is $y_1^* + y_2^* = 1+0 = 1 \\le 1$. Thus, $y^*$ is a feasible solution for the dual problem.\n\nNow, we check the complementary slackness conditions.\n\n**Condition 1:** $y^{*\\top}(Ax^* - b) = 0$.\nThe primal slack vector $s = Ax^* - b$ is:\n$$ s = \\begin{pmatrix}1 & 1 \\\\ 1 & 1\\end{pmatrix} \\begin{pmatrix}1 \\\\ 0\\end{pmatrix} - \\begin{pmatrix}1 \\\\ 1\\end{pmatrix} = \\begin{pmatrix}1 \\\\ 1\\end{pmatrix} - \\begin{pmatrix}1 \\\\ 1\\end{pmatrix} = \\begin{pmatrix}0 \\\\ 0\\end{pmatrix} $$\nThe dot product is $y^{*\\top}s = (1, 0) (0, 0)^\\top = 0$. The first condition is satisfied.\n\n**Condition 2:** $x^{*\\top}(c - A^{\\top}y^*) = 0$.\nThe dual slack vector $t = c - A^{\\top}y^*$ is:\n$$ t = \\begin{pmatrix}1 \\\\ 1\\end{pmatrix} - \\begin{pmatrix}1 & 1 \\\\ 1 & 1\\end{pmatrix} \\begin{pmatrix}1 \\\\ 0\\end{pmatrix} = \\begin{pmatrix}1 \\\\ 1\\end{pmatrix} - \\begin{pmatrix}1 \\\\ 1\\end{pmatrix} = \\begin{pmatrix}0 \\\\ 0\\end{pmatrix} $$\nThe dot product is $x^{*\\top}t = (1, 0) (0, 0)^\\top = 0$. The second condition is also satisfied.\n\nSince $x^*$ is primal feasible, $y^*$ is dual feasible, and both complementary slackness conditions hold, the pair $(x^*, y^*)$ is optimal for their respective problems. By the strong duality theorem, their objective values must be equal. We can calculate this common optimal value from either problem.\n\nPrimal objective value:\n$$ z_P^* = c^{\\top}x^* = (1, 1) (1, 0)^\\top = 1 \\cdot 1 + 1 \\cdot 0 = 1 $$\n\nDual objective value:\n$$ z_D^* = b^{\\top}y^* = (1, 1) (1, 0)^\\top = 1 \\cdot 1 + 1 \\cdot 0 = 1 $$\n\nThe common optimal objective value is $1$.", "answer": "$$\\boxed{1}$$", "id": "3139561"}, {"introduction": "The elegant results of duality theory, such as zero duality gap and the convergence of dual algorithms, often rely on a critical assumption: convexity. But what happens when this condition is not met? This final practice moves from theory to computation, asking you to implement the dual ascent algorithm and observe its behavior firsthand on two carefully chosen problems: one convex and one nonconvex [@problem_id:3139644]. By seeing how the algorithm converges smoothly for the convex case but can oscillate and fail for the nonconvex one, you will gain a tangible and lasting appreciation for why convexity is a cornerstone of modern optimization.", "problem": "Consider two equality-constrained optimization problems in one real decision variable $x \\in \\mathbb{R}$, each paired with its Lagrangian dual. The first problem is nonconvex in the primal variable, and the second problem is convex and serves as a control. Your task is to implement dual ascent on the dual variable and empirically demonstrate that, without convexity of the primal, dual ascent can exhibit oscillations and yield strictly suboptimal dual bounds. Base your reasoning and implementation strictly on the following foundational concepts.\n\nFoundational base:\n- The Lagrangian for an equality-constrained problem with constraint $h(x) = 0$ is $L(x,\\lambda) = f(x) + \\lambda h(x)$, where $\\lambda \\in \\mathbb{R}$ is the Lagrange multiplier (dual variable).\n- The dual function is $g(\\lambda) = \\inf_{x \\in \\mathbb{R}} L(x,\\lambda)$.\n- Dual ascent attempts to maximize $g(\\lambda)$ by iterating $\\lambda_{k+1} = \\lambda_k + \\alpha \\nabla g(\\lambda_k)$, where $\\alpha > 0$ is a stepsize. For differentiable cases with an equality constraint $h(x) = 0$, and when $x^\\star(\\lambda)$ attains the infimum in $g(\\lambda)$, it holds that $\\nabla g(\\lambda) = h(x^\\star(\\lambda))$.\n- In convex optimization (convex objective and affine constraint), the dual function $g(\\lambda)$ is concave, and gradient ascent with a suitable stepsize can converge. When the primal objective is nonconvex, $g(\\lambda)$ need not be concave, its gradient can be discontinuous, and naive dual ascent can oscillate or get stuck providing poor bounds.\n\nPrimal problems:\n- Nonconvex primal: minimize $f_{\\text{nc}}(x) = (x^2 - 1)^2$ subject to $x = 0$. The feasible set is the single point $x=0$, and the optimal primal value is $p^\\star_{\\text{nc}} = 1$.\n- Convex control primal: minimize $f_{\\text{c}}(x) = x^2$ subject to $x = 0$. The optimal primal value is $p^\\star_{\\text{c}} = 0$.\n\nLagrangians and dual functions:\n- For both problems, use the equality constraint $h(x) = x$ so the Lagrangian is $L(x,\\lambda) = f(x) + \\lambda x$.\n- The dual function is $g(\\lambda) = \\inf_{x \\in \\mathbb{R}} \\{ f(x) + \\lambda x \\}$, with the infimum attained at $x^\\star(\\lambda) \\in \\arg\\min_x L(x,\\lambda)$.\n\nAlgorithmic specification:\n- Implement dual ascent iterates $\\lambda_{k+1} = \\lambda_k + \\alpha \\, x^\\star(\\lambda_k)$ for $k = 0,1,\\dots,N-1$, where $x^\\star(\\lambda_k)$ is a global minimizer of $x \\mapsto f(x) + \\lambda_k x$ and $\\alpha > 0$ is a fixed stepsize.\n- Compute the dual function value at each iterate via $g(\\lambda_k) = f(x^\\star(\\lambda_k)) + \\lambda_k x^\\star(\\lambda_k)$, so that $g(\\lambda_k)$ is a valid lower bound on the primal optimum along the dual ascent trajectory.\n- For the convex control case $f_{\\text{c}}(x) = x^2$, you may use fundamental calculus to determine $x^\\star_{\\text{c}}(\\lambda) = -\\lambda/2$, and hence $g_{\\text{c}}(\\lambda) = -\\lambda^2/4$ exactly. For the nonconvex case $f_{\\text{nc}}(x) = (x^2 - 1)^2$, determine $x^\\star_{\\text{nc}}(\\lambda)$ by solving for stationary points and selecting the global minimizer; ensure a deterministic tie-breaking rule when multiple minimizers have equal value (choose the largest $x$ in case of ties).\n- Demonstrate oscillations by counting sign changes in the dual variable sequence $\\{\\lambda_k\\}_{k=0}^{N}$, where a sign change is counted if $\\lambda_{k-1} \\neq 0$, $\\lambda_k \\neq 0$, and $\\lambda_{k-1}\\lambda_k < 0$.\n- Demonstrate suboptimal bounds by computing the best dual lower bound $\\max_{0 \\le k \\le N} g(\\lambda_k)$ and comparing to the primal optimum $p^\\star$ via the duality gap $p^\\star - \\max_k g(\\lambda_k)$.\n\nTest suite:\nRun your program on the following parameter sets $(\\text{problem\\_type}, \\alpha, \\lambda_0, N)$, where $\\text{problem\\_type} \\in \\{\\text{\"nonconvex\"}, \\text{\"convex\"}\\}$, $\\alpha$ is the stepsize, $\\lambda_0$ is the initial dual variable, and $N$ is the number of dual ascent iterations:\n1. $\\text{\"nonconvex\"}$, $\\alpha = 0.5$, $\\lambda_0 = 1.0$, $N = 30$.\n2. $\\text{\"nonconvex\"}$, $\\alpha = 2.0$, $\\lambda_0 = -1.0$, $N = 30$.\n3. $\\text{\"nonconvex\"}$, $\\alpha = 0.05$, $\\lambda_0 = 1.0$, $N = 100$.\n4. $\\text{\"convex\"}$, $\\alpha = 0.5$, $\\lambda_0 = 1.0$, $N = 30$.\n5. $\\text{\"convex\"}$, $\\alpha = 2.5$, $\\lambda_0 = 1.0$, $N = 30$.\n\nFor each test case, output the following list of four quantities:\n- The integer number of sign changes in $\\{\\lambda_k\\}_{k=0}^{N}$.\n- The best dual lower bound $\\max_{0 \\le k \\le N} g(\\lambda_k)$ as a float.\n- The duality gap $p^\\star - \\max_k g(\\lambda_k)$ as a float, where $p^\\star = 1$ for the nonconvex problem and $p^\\star = 0$ for the convex control problem.\n- The final dual variable $\\lambda_N$ as a float.\n\nFinal output format:\nYour program should produce a single line of output containing the results as a comma-separated list of bracketed lists, one per test case, enclosed in square brackets. All floats must be rounded to six decimal places. For example, the output should look like $[[\\text{int},\\text{float},\\text{float},\\text{float}],[\\dots],[\\dots],[\\dots],[\\dots]]$ with no spaces.\n\nNo physical units or angle units are involved. All answers are dimensionless real numbers.", "solution": "This problem requires implementing the dual ascent algorithm to observe its behavior on a convex and a nonconvex optimization problem. The algorithm iterates on the dual variable $\\lambda$ to maximize the dual function $g(\\lambda)$.\n\nThe dual ascent update rule is given by $\\lambda_{k+1} = \\lambda_k + \\alpha \\nabla g(\\lambda_k)$. For the equality constraint $h(x) = x = 0$, the gradient of the dual function is $\\nabla g(\\lambda) = x^\\star(\\lambda)$, where $x^\\star(\\lambda)$ is the value of $x$ that minimizes the Lagrangian $L(x, \\lambda) = f(x) + \\lambda x$. The update rule is therefore $\\lambda_{k+1} = \\lambda_k + \\alpha x^\\star(\\lambda_k)$.\n\n**Convex Case Analysis**\nThe primal problem is $\\min f_c(x) = x^2$ subject to $x = 0$. The Lagrangian is $L_c(x, \\lambda) = x^2 + \\lambda x$. This is a convex function of $x$, so we find the minimizer $x^\\star_c(\\lambda)$ by setting the derivative to zero:\n$$\n\\frac{\\partial L_c}{\\partial x} = 2x + \\lambda = 0 \\implies x^\\star_c(\\lambda) = -\\frac{\\lambda}{2}\n$$\nThe dual function is $g_c(\\lambda) = L_c(x^\\star_c(\\lambda), \\lambda) = (-\\lambda/2)^2 + \\lambda(-\\lambda/2) = -\\lambda^2/4$. The dual ascent iteration becomes $\\lambda_{k+1} = \\lambda_k(1 - \\alpha/2)$. This linear recurrence converges to $\\lambda=0$ for step sizes $0 < \\alpha < 4$. The dual function $g_c(\\lambda)$ is concave and its maximum is $g_c(0) = 0$, which equals the primal optimum $p^\\star_c=0$. Strong duality holds.\n\n**Nonconvex Case Analysis**\nThe primal problem is $\\min f_{nc}(x) = (x^2 - 1)^2$ subject to $x = 0$. The Lagrangian is $L_{nc}(x, \\lambda) = (x^2 - 1)^2 + \\lambda x$. To find the minimizer $x^\\star_{nc}(\\lambda)$, we find stationary points by solving $\\frac{\\partial L_{nc}}{\\partial x} = 0$:\n$$\n4x^3 - 4x + \\lambda = 0\n$$\nThis is a cubic equation in $x$. Since $L_{nc}(x, \\lambda) \\to \\infty$ as $|x| \\to \\infty$, a global minimum exists and must be one of the real roots of this equation. These roots can be found numerically. For a given $\\lambda$, we evaluate $L_{nc}(x, \\lambda)$ at each real root and select the root that yields the minimum value, applying the specified tie-breaking rule (choose largest $x$). The function $x^\\star_{nc}(\\lambda)$ can be discontinuous, which means the dual function $g_{nc}(\\lambda)$ is not necessarily concave, and its gradient can be discontinuous. This can cause the dual ascent algorithm to oscillate and fail to converge to the true dual optimum.\n\nThe provided Python code implements this logic. For each test case, it simulates the dual ascent process, calculates the required metrics (sign changes, best dual bound, duality gap, and final $\\lambda_N$), and formats the output as specified.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef get_x_star_nc(lambda_val):\n    \"\"\"\n    Finds the global minimizer of the nonconvex Lagrangian L_nc(x, lambda).\n    This involves finding the real roots of a cubic polynomial and selecting the\n    one that minimizes the Lagrangian, with a tie-breaking rule.\n    \"\"\"\n    # Find stationary points by solving the cubic equation: 4x^3 - 4x + lambda = 0\n    coeffs = [4, 0, -4, lambda_val]\n    roots = np.roots(coeffs)\n    real_roots = roots[np.isclose(roots.imag, 0)].real\n\n    if len(real_roots) == 0:\n        # This case is theoretically impossible for a real cubic polynomial.\n        raise ValueError(\"No real roots found for the cubic equation.\")\n\n    min_l_val = np.inf\n    candidate_minimizers = []\n\n    # Evaluate Lagrangian at each real root to find the global minimum.\n    for r in real_roots:\n        l_val = (r**2 - 1)**2 + lambda_val * r\n        if np.isclose(l_val, min_l_val):\n            candidate_minimizers.append(r)\n        elif l_val < min_l_val:\n            min_l_val = l_val\n            candidate_minimizers = [r]\n\n    # Apply tie-breaking rule: choose the largest x in case of a tie.\n    return max(candidate_minimizers)\n\ndef get_g_nc(lambda_val):\n    \"\"\"\n    Computes the dual function value g_nc(lambda).\n    \"\"\"\n    x_star = get_x_star_nc(lambda_val)\n    return (x_star**2 - 1)**2 + lambda_val * x_star\n\ndef get_x_star_c(lambda_val):\n    \"\"\"\n    Finds the global minimizer of the convex Lagrangian L_c(x, lambda).\n    \"\"\"\n    return -lambda_val / 2.0\n\ndef get_g_c(lambda_val):\n    \"\"\"\n    Computes the dual function value g_c(lambda).\n    \"\"\"\n    return -lambda_val**2 / 4.0\n\ndef solve():\n    \"\"\"\n    Main function to run the dual ascent algorithm for all test cases.\n    \"\"\"\n    test_cases = [\n        (\"nonconvex\", 0.5, 1.0, 30),\n        (\"nonconvex\", 2.0, -1.0, 30),\n        (\"nonconvex\", 0.05, 1.0, 100),\n        (\"convex\", 0.5, 1.0, 30),\n        (\"convex\", 2.5, 1.0, 30),\n    ]\n\n    all_results = []\n    \n    for prob_type, alpha, lambda_0, N in test_cases:\n        \n        if prob_type == \"nonconvex\":\n            p_star = 1.0\n            get_x_star = get_x_star_nc\n            f = lambda x: (x**2 - 1)**2\n        else:  # convex\n            p_star = 0.0\n            get_x_star = get_x_star_c\n            f = lambda x: x**2\n\n        # --- Dual Ascent Iteration ---\n        lambdas = [lambda_0]\n        g_values = []\n        \n        current_lambda = lambda_0\n        # Generate the sequence of N+1 lambda values (lambda_0 to lambda_N)\n        for k in range(N + 1):\n            x_star = get_x_star(current_lambda)\n            g_val = f(x_star) + current_lambda * x_star\n            g_values.append(g_val)\n            \n            if k  N:\n                next_lambda = current_lambda + alpha * x_star\n                lambdas.append(next_lambda)\n                current_lambda = next_lambda\n        \n        # --- Metric Calculation ---\n        # 1. Count sign changes in {lambda_k}_{k=0 to N}\n        sign_changes = 0\n        for i in range(1, N + 1):\n            if lambdas[i-1] != 0 and lambdas[i] != 0 and (lambdas[i-1] * lambdas[i]  0):\n                sign_changes += 1\n\n        # 2. Find best dual lower bound\n        best_g = max(g_values)\n\n        # 3. Compute duality gap\n        duality_gap = p_star - best_g\n        \n        # 4. Get final dual variable\n        final_lambda = lambdas[N]\n\n        # Append results with specified rounding\n        all_results.append([\n            sign_changes,\n            round(best_g, 6),\n            round(duality_gap, 6),\n            round(final_lambda, 6)\n        ])\n\n    # Final print statement in the exact required format.\n    # The str() representation of a list includes spaces, which need to be removed.\n    print(str(all_results).replace(\" \", \"\"))\n\nsolve()\n\n```", "id": "3139644"}]}