{"hands_on_practices": [{"introduction": "Mastering nonlinear optimization begins with a firm grasp of the first- and second-order optimality conditions. This first exercise provides a complete, step-by-step workout of this fundamental toolkit. By deriving and solving the Karush-Kuhn-Tucker (KKT) conditions, checking constraint qualifications, and applying the Second-Order Sufficient Conditions (SOSC), you will learn to systematically identify and classify stationary points for a constrained problem [@problem_id:3165953].", "problem": "Consider the equality-constrained nonlinear program with decision vector $x = (x_1, x_2) \\in \\mathbb{R}^2$:\n$$\\min_{x \\in \\mathbb{R}^2} \\; f(x) \\quad \\text{subject to} \\quad h(x) = 0,$$\nwhere $f(x) = x_1^2 + x_2^2 + x_1 x_2$ and $h(x) = x_1^2 - x_2$. Starting from the definitions of the Karush–Kuhn–Tucker (KKT) conditions for equality-constrained nonlinear programs, the Linear Independence Constraint Qualification (LICQ), and the Second-Order Sufficient Conditions (SOSC), perform the following:\n- Derive the first-order conditions from the Lagrangian and solve for all KKT stationary points.\n- Verify whether LICQ holds at each KKT stationary point.\n- Classify each KKT stationary point using SOSC as a local minimizer, local maximizer, or saddle point relative to the feasible manifold.\nFinally, report the exact minimum objective value attained by the nonlinear program. The final answer must be a single real number. No rounding is required.", "solution": "The problem is an equality-constrained nonlinear program (NLP) of the form:\n$$ \\min_{x \\in \\mathbb{R}^2} \\; f(x) \\quad \\text{subject to} \\quad h(x) = 0 $$\nwhere the decision vector is $x = (x_1, x_2)$, the objective function is $f(x) = x_1^2 + x_2^2 + x_1 x_2$, and the equality constraint is $h(x) = x_1^2 - x_2 = 0$.\n\nThe first step is to formulate the Lagrangian function $L(x, \\lambda)$, which is defined as $L(x, \\lambda) = f(x) + \\lambda h(x)$ for a Lagrange multiplier $\\lambda \\in \\mathbb{R}$.\n$$ L(x_1, x_2, \\lambda) = x_1^2 + x_2^2 + x_1 x_2 + \\lambda(x_1^2 - x_2) $$\n\nThe first-order Karush–Kuhn–Tucker (KKT) necessary conditions for optimality require that the gradient of the Lagrangian with respect to $x$ is zero, and that the original constraint is satisfied.\nThe gradient of the Lagrangian is $\\nabla_x L(x, \\lambda) = (\\frac{\\partial L}{\\partial x_1}, \\frac{\\partial L}{\\partial x_2})$. The KKT conditions are:\n1. $\\frac{\\partial L}{\\partial x_1} = 2x_1 + x_2 + 2\\lambda x_1 = 0$\n2. $\\frac{\\partial L}{\\partial x_2} = 2x_2 + x_1 - \\lambda = 0$\n3. $h(x_1, x_2) = x_1^2 - x_2 = 0$\n\nWe solve this system of three equations for the variables $x_1$, $x_2$, and $\\lambda$.\nFrom condition (3), we have $x_2 = x_1^2$.\nSubstitute this into condition (2) to express $\\lambda$ in terms of $x_1$:\n$$ 2(x_1^2) + x_1 - \\lambda = 0 \\implies \\lambda = x_1 + 2x_1^2 $$\nNow, substitute the expressions for $x_2$ and $\\lambda$ into condition (1):\n$$ 2x_1 + (x_1^2) + 2(x_1 + 2x_1^2)x_1 = 0 $$\n$$ 2x_1 + x_1^2 + 2x_1^2 + 4x_1^3 = 0 $$\n$$ 4x_1^3 + 3x_1^2 + 2x_1 = 0 $$\nFactor out $x_1$:\n$$ x_1(4x_1^2 + 3x_1 + 2) = 0 $$\nThis equation has solutions if $x_1=0$ or if $4x_1^2 + 3x_1 + 2 = 0$. The discriminant of the quadratic factor is $\\Delta = 3^2 - 4(4)(2) = 9 - 32 = -23$. Since $\\Delta  0$, the quadratic equation has no real roots. Therefore, the only real solution is $x_1 = 0$.\n\nWith $x_1 = 0$, we find the corresponding values for $x_2$ and $\\lambda$:\n- $x_2 = x_1^2 = 0^2 = 0$.\n- $\\lambda = x_1 + 2x_1^2 = 0 + 2(0)^2 = 0$.\n\nThus, there is a single KKT stationary point, $x^* = (0, 0)$, with the associated Lagrange multiplier $\\lambda^* = 0$.\n\nNext, we verify if the Linear Independence Constraint Qualification (LICQ) holds at $x^*$. LICQ requires that the gradients of the active constraints at the point are linearly independent. Here, we have one equality constraint $h(x) = 0$. LICQ holds if $\\nabla h(x^*) \\neq 0$.\nThe gradient of the constraint function is:\n$$ \\nabla h(x) = \\begin{pmatrix} \\frac{\\partial h}{\\partial x_1} \\\\ \\frac{\\partial h}{\\partial x_2} \\end{pmatrix} = \\begin{pmatrix} 2x_1 \\\\ -1 \\end{pmatrix} $$\nAt the KKT point $x^* = (0, 0)$:\n$$ \\nabla h(0, 0) = \\begin{pmatrix} 2(0) \\\\ -1 \\end{pmatrix} = \\begin{pmatrix} 0 \\\\ -1 \\end{pmatrix} $$\nSince $\\nabla h(0, 0) \\neq \\begin{pmatrix} 0 \\\\ 0 \\end{pmatrix}$, the LICQ is satisfied at $x^*$.\n\nNow, we use the Second-Order Sufficient Conditions (SOSC) to classify this stationary point. A KKT point $(x^*, \\lambda^*)$ that satisfies LICQ is a strict local minimizer if for every non-zero vector $d$ in the critical cone $C(x^*)$, we have $d^T \\nabla_{xx}^2 L(x^*, \\lambda^*) d  0$. For equality constraints, the critical cone is the tangent space to the feasible manifold, defined as $C(x^*) = \\{ d \\in \\mathbb{R}^2 \\mid \\nabla h(x^*)^T d = 0 \\}$.\n\nFirst, we compute the Hessian of the Lagrangian, $\\nabla_{xx}^2 L(x, \\lambda)$:\n$$ \\nabla_{xx}^2 L(x, \\lambda) = \\begin{pmatrix} \\frac{\\partial^2 L}{\\partial x_1^2}  \\frac{\\partial^2 L}{\\partial x_1 \\partial x_2} \\\\ \\frac{\\partial^2 L}{\\partial x_2 \\partial x_1}  \\frac{\\partial^2 L}{\\partial x_2^2} \\end{pmatrix} = \\begin{pmatrix} 2 + 2\\lambda  1 \\\\ 1  2 \\end{pmatrix} $$\nEvaluate the Hessian at the KKT point $(x^*, \\lambda^*) = ((0, 0), 0)$:\n$$ \\nabla_{xx}^2 L(x^*, \\lambda^*) = \\begin{pmatrix} 2 + 2(0)  1 \\\\ 1  2 \\end{pmatrix} = \\begin{pmatrix} 2  1 \\\\ 1  2 \\end{pmatrix} $$\n\nNext, we determine the critical cone (tangent space) at $x^* = (0, 0)$. A vector $d = (d_1, d_2)$ is in the critical cone if $\\nabla h(x^*)^T d = 0$.\n$$ \\nabla h(0, 0)^T d = \\begin{pmatrix} 0  -1 \\end{pmatrix} \\begin{pmatrix} d_1 \\\\ d_2 \\end{pmatrix} = 0 \\cdot d_1 - 1 \\cdot d_2 = -d_2 $$\nThe condition is $-d_2 = 0$, so $d_2 = 0$. The critical cone is the set of vectors $d$ of the form $(d_1, 0)$ for any $d_1 \\in \\mathbb{R}$.\n\nFinally, we check the sign of the quadratic form $d^T \\nabla_{xx}^2 L(x^*, \\lambda^*) d$ for any non-zero vector $d = (d_1, 0)$ with $d_1 \\neq 0$:\n$$ d^T \\nabla_{xx}^2 L(x^*, \\lambda^*) d = \\begin{pmatrix} d_1  0 \\end{pmatrix} \\begin{pmatrix} 2  1 \\\\ 1  2 \\end{pmatrix} \\begin{pmatrix} d_1 \\\\ 0 \\end{pmatrix} $$\n$$ = \\begin{pmatrix} d_1  0 \\end{pmatrix} \\begin{pmatrix} 2d_1 \\\\ d_1 \\end{pmatrix} = 2d_1^2 $$\nSince $d$ is a non-zero vector in the critical cone, $d_1 \\neq 0$, which implies $d_1^2  0$. Therefore, $2d_1^2  0$.\n\nThe quadratic form is positive definite on the critical cone. The SOSC are satisfied for a strict local minimizer. Thus, the point $x^* = (0, 0)$ is a strict local minimizer. As this is the only KKT point found, it is the global minimizer for this problem.\n\nThe minimum objective value is attained at $x^* = (0, 0)$:\n$$ f(0, 0) = 0^2 + 0^2 + (0)(0) = 0 $$\nThe minimum value of the objective function is $0$.", "answer": "$$\\boxed{0}$$", "id": "3165953"}, {"introduction": "The KKT conditions are powerful, but their full implications are revealed when we study cases where ideal assumptions break down. This exercise focuses on a scenario where strict complementarity fails—an active constraint is associated with a zero Lagrange multiplier. You will investigate how this failure impacts the uniqueness and sensitivity of the solution, providing a concrete link between a theoretical condition and the practical behavior of the optimal solution under perturbations [@problem_id:3165959].", "problem": "Consider the parametric nonlinear program (NLP): minimize the scalar function $f(x) = x^{2}$ subject to the single inequality constraint $g(x,\\mu) := -x + \\mu \\leq 0$, where $\\mu \\in \\mathbb{R}$ is a parameter. The terminology of Karush–Kuhn–Tucker (KKT) conditions is with respect to inequality constraints $g(x,\\mu) \\leq 0$ and multipliers $\\lambda \\geq 0$, and strict complementarity means $\\lambda_{i}^{\\star}  0$ for every inequality constraint that is active (i.e., equals zero) at a solution.\n\nTask:\n- At $\\mu = 0$, identify the optimal solution $x^{\\star}(0)$ and a KKT multiplier $\\lambda^{\\star}(0)$ that satisfy stationarity, primal feasibility, dual feasibility, and complementary slackness. Verify that strict complementarity fails because the active constraint has a zero multiplier.\n- Investigate implications for sensitivity and multiplier uniqueness at $\\mu = 0$: justify whether the KKT multiplier is unique and analyze the local behavior of the optimal solution mapping $\\mu \\mapsto x^{\\star}(\\mu)$ near $\\mu = 0$.\n- Compute the right-hand directional derivative of the optimal solution mapping at $\\mu = 0$ in the direction $d = 1$, defined by\n$$\nD^{+}x^{\\star}(0;1) := \\lim_{t \\downarrow 0} \\frac{x^{\\star}(0 + t \\cdot 1) - x^{\\star}(0)}{t}.\n$$\nExpress your final result as a single real number. No rounding is required.", "solution": "The problem is a parametric nonlinear program (NLP) defined as:\n$$\n\\text{minimize} \\quad f(x) = x^2\n$$\n$$\n\\text{subject to} \\quad g(x, \\mu) := -x + \\mu \\leq 0\n$$\nwhere $x \\in \\mathbb{R}$ is the decision variable and $\\mu \\in \\mathbb{R}$ is a parameter.\n\nThe Karush-Kuhn-Tucker (KKT) conditions are a set of first-order necessary conditions for a solution in nonlinear programming to be optimal. The Lagrangian for this problem is given by:\n$$\nL(x, \\lambda; \\mu) = f(x) + \\lambda g(x, \\mu) = x^2 + \\lambda(-x + \\mu)\n$$\nwhere $\\lambda$ is the KKT multiplier associated with the inequality constraint. The KKT conditions are:\n1.  **Stationarity**: $\\nabla_x L(x, \\lambda; \\mu) = 2x - \\lambda = 0$\n2.  **Primal Feasibility**: $-x + \\mu \\leq 0$\n3.  **Dual Feasibility**: $\\lambda \\geq 0$\n4.  **Complementary Slackness**: $\\lambda(-x + \\mu) = 0$\n\nFirst, we address the task for $\\mu = 0$. The problem becomes:\n$$\n\\text{minimize} \\quad f(x) = x^2\n$$\n$$\n\\text{subject to} \\quad -x \\leq 0 \\quad (\\text{or equivalently, } x \\geq 0)\n$$\nThe objective function $f(x) = x^2$ is a parabola with its minimum at $x=0$. The feasible region is the set of all non-negative real numbers, $x \\in [0, \\infty)$. Since the unconstrained minimizer $x=0$ lies within the feasible region, it is the optimal solution. Thus, the optimal solution at $\\mu=0$ is $x^{\\star}(0) = 0$.\n\nNow, we find the KKT multiplier $\\lambda^{\\star}(0)$ corresponding to $x^{\\star}(0)=0$ and $\\mu=0$. We use the KKT conditions with $\\mu=0$:\n1.  **Stationarity**: $2x - \\lambda = 0$. Substituting $x^{\\star}(0) = 0$, we get $2(0) - \\lambda = 0$, which implies $\\lambda = 0$. So, the KKT multiplier is $\\lambda^{\\star}(0) = 0$.\n2.  **Primal Feasibility**: $-x^{\\star}(0) \\leq 0 \\implies -0 \\leq 0$. This is satisfied.\n3.  **Dual Feasibility**: $\\lambda^{\\star}(0) \\geq 0 \\implies 0 \\geq 0$. This is satisfied.\n4.  **Complementary Slackness**: $\\lambda^{\\star}(0)(-x^{\\star}(0)) = 0 \\implies 0(-0) = 0$. This is satisfied.\n\nThe KKT pair is $(x^{\\star}(0), \\lambda^{\\star}(0)) = (0, 0)$.\nStrict complementarity requires that for any active constraint, the corresponding multiplier must be strictly positive. At the solution $x^{\\star}(0)=0$, the constraint $g(x,0) = -x \\leq 0$ is active, since $-x^{\\star}(0) = 0$. However, the corresponding multiplier is $\\lambda^{\\star}(0) = 0$. Since the multiplier is not strictly positive, the condition of strict complementarity fails.\n\nNext, we investigate the uniqueness of the multiplier and the local behavior of the solution mapping at $\\mu=0$. From the stationarity condition, $\\lambda = 2x$. Since the primal optimal solution $x^{\\star}(0)=0$ is unique, the multiplier is also uniquely determined as $\\lambda^{\\star}(0) = 2x^{\\star}(0) = 2(0) = 0$.\n\nTo analyze the local behavior of the optimal solution mapping $\\mu \\mapsto x^{\\star}(\\mu)$, we solve the NLP for a general parameter $\\mu$. The constraint is $x \\geq \\mu$.\n- If $\\mu \\leq 0$, the unconstrained minimizer $x=0$ is feasible since $0 \\geq \\mu$. Thus, the optimal solution is $x^{\\star}(\\mu) = 0$.\n- If $\\mu  0$, the unconstrained minimizer $x=0$ is not feasible. The objective function $f(x) = x^2$ is strictly increasing for $x0$. Therefore, for the feasible region $x \\in [\\mu, \\infty)$, the minimum value is attained at the boundary point $x=\\mu$. Thus, the optimal solution is $x^{\\star}(\\mu) = \\mu$.\n\nCombining these two cases, the optimal solution mapping is:\n$$\nx^{\\star}(\\mu) = \\begin{cases} 0  \\text{if } \\mu \\leq 0 \\\\ \\mu  \\text{if } \\mu  0 \\end{cases}\n$$\nThis function can also be written as $x^{\\star}(\\mu) = \\max\\{0, \\mu\\}$. This mapping is continuous, but it is not differentiable at $\\mu=0$. Its left-hand derivative is $0$ and its right-hand derivative is $1$. This lack of differentiability is characteristic of problems where strict complementarity fails.\n\nFinally, we compute the right-hand directional derivative of the optimal solution mapping at $\\mu=0$ in the direction $d=1$. The definition is:\n$$\nD^{+}x^{\\star}(0;1) := \\lim_{t \\downarrow 0} \\frac{x^{\\star}(0 + t \\cdot 1) - x^{\\star}(0)}{t}\n$$\nWe have already determined $x^{\\star}(0) = 0$. For the limit $t \\downarrow 0$, we consider $t  0$. The argument of the solution mapping is $0 + t \\cdot 1 = t$. Since $t0$, we are in the case where $\\mu  0$, so $x^{\\star}(t) = t$.\nSubstituting these into the limit definition:\n$$\nD^{+}x^{\\star}(0;1) = \\lim_{t \\downarrow 0} \\frac{x^{\\star}(t) - x^{\\star}(0)}{t} = \\lim_{t \\downarrow 0} \\frac{t - 0}{t}\n$$\n$$\nD^{+}x^{\\star}(0;1) = \\lim_{t \\downarrow 0} \\frac{t}{t} = \\lim_{t \\downarrow 0} 1 = 1\n$$\nThe right-hand directional derivative is $1$.", "answer": "$$\\boxed{1}$$", "id": "3165959"}, {"introduction": "While local optimality conditions are the bedrock of theory, practical optimization often involves complex, non-convex landscapes with multiple local minima. This computational practice moves beyond local analysis to explore the global behavior of a gradient-based algorithm on a problem with a disconnected feasible set. By implementing a multi-start strategy, you will map out the basins of attraction for different solutions, gaining crucial insights into the importance of initialization and the challenges of finding a global optimum [@problem_id:3166063].", "problem": "Consider a nonlinear program (NLP) in two variables with a smooth objective and a single smooth nonlinear inequality constraint. A nonlinear program is a mathematical optimization problem of the form minimize $f(x)$ subject to $g_i(x) \\le 0$ and $h_j(x) = 0$, where $f$, $g_i$, and $h_j$ are functions, and $x$ denotes decision variables. The feasible set is the set of all $x$ satisfying the constraints. Basins of attraction for a gradient-based method are the subsets of the domain such that, when the method is initialized within the subset, it converges to the same local solution.\n\nYour task is to implement and analyze a concrete case in which the feasible set is disconnected due to nonlinear constraints, and to measure how a multi-start strategy distributes iterates across basins of attraction when a gradient-based method is used.\n\nUse the following specific problem:\n- Variables: $x = (x_1, x_2) \\in \\mathbb{R}^2$.\n- Objective: minimize $f(x) = x_1^2 + (x_2 - 1)^2$.\n- Nonlinear constraint: define $A(x) = (x_1 - 2)^2 + x_2^2 - 1$ and $B(x) = (x_1 + 2)^2 + x_2^2 - 1$, and impose $g(x) = A(x) \\cdot B(x) \\le 0$.\n\nFundamental base to use:\n- The definition of a nonlinear program and its feasible set determined by constraints.\n- The concept of a gradient-based method that uses derivative information to update iterates and its dependence on initialization.\n- The definition of basins of attraction as sets of initial conditions that lead to the same local solution under a specified algorithm.\n- The algebraic properties of sign for products: if $A(x) \\le 0$ or $B(x) \\le 0$, then $A(x) \\cdot B(x) \\le 0$.\n\nNotes about the constraint:\n- The inequality $A(x) \\cdot B(x) \\le 0$ induces the feasible set as the union of the two closed disks of radius $1$ centered at $(2, 0)$ and $(-2, 0)$, which are disconnected subsets of $\\mathbb{R}^2$.\n\nAlgorithm requirements:\n- Use a gradient-based constrained optimizer meeting the standard definition of such methods (for example, a trust-region algorithm with nonlinear constraints) and provide exact first derivatives (gradients).\n- Classify the converged solution for each start by determining membership in the left disk (center $(-2, 0)$) or the right disk (center $(2, 0)$), using the signs of $A(x)$ and $B(x)$ at the returned solution and a small numerical tolerance.\n\nMulti-start strategy:\n- For each test case, run the optimizer from multiple specified initial points.\n- For each test case, aggregate the following metrics:\n  1. The integer count of successful runs that converged to the left-disk local minimizer (center at $(-2, 0)$).\n  2. The integer count of successful runs that converged to the right-disk local minimizer (center at $(2, 0)$).\n  3. The smallest objective value found among all successful runs in the test case, as a floating-point number.\n  4. The fraction of successful runs among all starts in the test case, expressed as a decimal in $[0, 1]$.\n\nTesting and output specification:\n- Use the following test suite of initial points (each test case is a list of starts):\n  - Test case $1$ (a symmetric line of starts): $[(-3, 0), (-1, 0), (0, 0), (1, 0), (3, 0)]$.\n  - Test case $2$ (mixed points including boundary points): Let $\\sqrt{5}$ denote the square root of $5$. Define the boundary points\n    $p_{\\text{right}} = \\left(2 - \\frac{2}{\\sqrt{5}}, \\frac{1}{\\sqrt{5}}\\right)$, \n    $p_{\\text{left}} = \\left(-2 + \\frac{2}{\\sqrt{5}}, \\frac{1}{\\sqrt{5}}\\right)$.\n    Use $[(0, 3), (0, -2), p_{\\text{right}}, p_{\\text{left}}]$.\n  - Test case $3$ (initial points inside the left disk): $[(-2, 0), (-2.5, 0.5), (-1.5, -0.5)]$.\n  - Test case $4$ (far starts): $[(-20, 0), (20, 0), (0, 10)]$.\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets of lists, one list per test case, following the format:\n  \"[[l1,r1,min1,frac1],[l2,r2,min2,frac2],[l3,r3,min3,frac3],[l4,r4,min4,frac4]]\"\n  where $l_k$ and $r_k$ are integers, and $min_k$ and $frac_k$ are floating-point numbers for test case $k$.\n\nNo physical units or angle units are involved in this problem; all answers are dimensionless. The program must be self-contained and require no external input.", "solution": "The user-provided problem is a task in computational optimization, specifically focusing on the properties of a nonlinear program (NLP) with a disconnected feasible set. The goal is to analyze the basins of attraction for two distinct global minimizers by employing a multi-start strategy with a gradient-based optimizer.\n\n### Step 1: Problem Validation\n\nThe problem is subjected to a rigorous validation process before a solution is attempted.\n\n- **Extracted Givens**:\n    - **Variables**: $x = (x_1, x_2) \\in \\mathbb{R}^2$.\n    - **Objective Function**: minimize $f(x) = x_1^2 + (x_2 - 1)^2$. This function represents the squared Euclidean distance from a point $x$ to the point $(0, 1)$.\n    - **Nonlinear Constraint**: $g(x) = A(x) \\cdot B(x) \\le 0$, where $A(x) = (x_1 - 2)^2 + x_2^2 - 1$ and $B(x) = (x_1 + 2)^2 + x_2^2 - 1$. The feasible set is the union of two disjoint closed disks: one centered at $(2, 0)$ with radius $1$ (defined by $A(x) \\le 0$) and the other centered at $(-2, 0)$ with radius $1$ (defined by $B(x) \\le 0$).\n    - **Algorithm**: A gradient-based constrained optimizer, such as a trust-region method, is required.\n    - **Multi-start Test Cases**:\n        - Case 1: $[(-3, 0), (-1, 0), (0, 0), (1, 0), (3, 0)]$.\n        - Case 2: Let $\\sqrt{5}$ be the square root of $5$. Starts are $[(0, 3), (0, -2), p_{\\text{right}}, p_{\\text{left}}]$, with $p_{\\text{right}} = (2 - \\frac{2}{\\sqrt{5}}, \\frac{1}{\\sqrt{5}})$ and $p_{\\text{left}} = (-2 + \\frac{2}{\\sqrt{5}}, \\frac{1}{\\sqrt{5}})$.\n        - Case 3: $[(-2, 0), (-2.5, 0.5), (-1.5, -0.5)]$.\n        - Case 4: $[(-20, 0), (20, 0), (0, 10)]$.\n    - **Required Metrics**: For each case, count convergences to the left disk, right disk, the minimum objective value found, and the fraction of successful runs.\n    - **Output Format**: A single-line string representation of a list of lists, e.g., `[[l1,r1,min1,frac1],[l2,r2,min2,frac2],...]`.\n\n- **Validation Verdict**:\n    - **Scientific Grounding**: The problem is well-grounded in the theory of mathematical optimization. All concepts, including NLPs, feasible sets, gradient-based methods, and basins of attraction, are standard in this field.\n    - **Well-Posedness**: The problem is well-posed. The objective function is continuous and the feasible set is compact (closed and bounded), which guarantees the existence of global minimizers by the Extreme Value Theorem. The task is an empirical study of algorithm behavior, which is a well-defined computational experiment.\n    - **Objectivity**: The problem is stated using precise mathematical language, free from subjectivity or ambiguity.\n    - **Flaw Checklist**: The problem does not violate any of the invalidity criteria. It is scientifically sound, formalizable, complete, feasible, and non-trivial.\n\n- **Action**: The problem is deemed **valid**. A solution will be developed.\n\n### Step 2: Solution Development\n\nThe problem requires implementing a multi-start optimization routine for a specific NLP. I will use the `scipy.optimize.minimize` function with the `trust-constr` method, which is a gradient-based trust-region algorithm suitable for nonlinear constraints.\n\n**Mathematical Formulation**\n\nFirst, we define the objective function and its gradient, and the constraint function and its gradient.\n\n1.  **Objective Function**: $f(x) = x_1^2 + (x_2 - 1)^2$.\n    The gradient is the vector of partial derivatives:\n    $$ \\nabla f(x) = \\left[ \\frac{\\partial f}{\\partial x_1}, \\frac{\\partial f}{\\partial x_2} \\right] = [2x_1, 2(x_2 - 1)] $$\n\n2.  **Constraint Function**: $g(x) = A(x) \\cdot B(x)$, where $A(x) = (x_1 - 2)^2 + x_2^2 - 1$ and $B(x) = (x_1 + 2)^2 + x_2^2 - 1$.\n    The gradient $\\nabla g(x)$ is found using the product rule: $\\nabla g(x) = B(x) \\nabla A(x) + A(x) \\nabla B(x)$.\n    The gradients of $A(x)$ and $B(x)$ are:\n    $$ \\nabla A(x) = [2(x_1 - 2), 2x_2] $$\n    $$ \\nabla B(x) = [2(x_1 + 2), 2x_2] $$\n    Combining these, the components of $\\nabla g(x)$ are:\n    $$ \\frac{\\partial g}{\\partial x_1} = B(x) \\cdot 2(x_1 - 2) + A(x) \\cdot 2(x_1 + 2) $$\n    $$ \\frac{\\partial g}{\\partial x_2} = B(x) \\cdot 2x_2 + A(x) \\cdot 2x_2 = 2x_2 (A(x) + B(x)) $$\n\n**Local and Global Minima**\nThe problem is to find points in the feasible set (the two disks) that minimize the distance to the point $(0, 1)$. The point $(0, 1)$ is equidistant from the centers of the two disks, $(2, 0)$ and $(-2, 0)$. The distance to both centers is $\\sqrt{(2-0)^2 + (0-1)^2} = \\sqrt{5}$.\n\nThis symmetry implies there are two global minimizers, one in each disk.\n-   The minimizer in the right disk, $x_r^*$, is the point on the circle $(x_1-2)^2 + x_2^2 = 1$ closest to $(0, 1)$. This point is $p_{\\text{right}} = (2 - \\frac{2}{\\sqrt{5}}, \\frac{1}{\\sqrt{5}})$.\n-   The minimizer in the left disk, $x_l^*$, is the point on the circle $(x_1+2)^2 + x_2^2 = 1$ closest to $(0, 1)$. This point is $p_{\\text{left}} = (-2 + \\frac{2}{\\sqrt{5}}, \\frac{1}{\\sqrt{5}})$.\n\nAt both minimal points, the distance to $(0, 1)$ is $\\sqrt{5} - 1$ (the distance to the center minus the radius). The objective function, being the squared distance, evaluates to $(\\sqrt{5} - 1)^2 = 5 - 2\\sqrt{5} + 1 = 6 - 2\\sqrt{5} \\approx 1.52786$. This is the global minimum value.\n\n**Implementation Strategy**\n\nThe solution will be a Python script that defines the functions and their gradients, sets up the test cases, and then iterates through them. For each test case, it will:\n1.  Initialize counters for left/right convergences, the number of successful runs, and set the minimum objective value found to infinity.\n2.  Iterate through each starting point $x_0$.\n3.  Call `scipy.optimize.minimize` with the `trust-constr` method, providing the functions, gradients, and the constraint $g(x) \\le 0$.\n4.  If the optimization is successful (`result.success` is `True`):\n    - Increment the success counter.\n    - Update the minimum objective value if `result.fun` is smaller.\n    - Classify the solution point $x_{sol} = result.x$. If $A(x_{sol}) \\le \\epsilon$ (for a small tolerance $\\epsilon$), it is in the right disk; if $B(x_{sol}) \\le \\epsilon$, it is in the left disk. Increment the corresponding counter.\n5.  After all starts in a test case are processed, calculate the success fraction.\n6.  Store the results `[left_count, right_count, min_obj, success_fraction]` for the case.\n7.  Finally, format the collected results from all test cases into the specified single-line string format.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.optimize import minimize, NonlinearConstraint\n\ndef solve():\n    \"\"\"\n    Solves the multi-start nonlinear optimization problem.\n    \"\"\"\n    \n    # Define the objective function f(x)\n    def f(x):\n        # f(x) = x_1^2 + (x_2 - 1)^2\n        return x[0]**2 + (x[1] - 1)**2\n\n    # Define the gradient of the objective function\n    def grad_f(x):\n        # grad_f(x) = [2*x_1, 2*(x_2 - 1)]\n        return np.array([2 * x[0], 2 * (x[1] - 1)])\n\n    # Define the constraint function g(x) = 0\n    def g(x):\n        # g(x) = A(x) * B(x)\n        # A(x) = (x_1 - 2)^2 + x_2^2 - 1\n        # B(x) = (x_1 + 2)^2 + x_2^2 - 1\n        x1, x2 = x\n        A_x = (x1 - 2)**2 + x2**2 - 1\n        B_x = (x1 + 2)**2 + x2**2 - 1\n        return A_x * B_x\n\n    # Define the gradient of the constraint function\n    def grad_g(x):\n        # grad_g(x) = B(x)*grad_A(x) + A(x)*grad_B(x)\n        x1, x2 = x\n        A_x = (x1 - 2)**2 + x2**2 - 1\n        B_x = (x1 + 2)**2 + x2**2 - 1\n        \n        grad_A_x1 = 2 * (x1 - 2)\n        grad_A_x2 = 2 * x2\n        \n        grad_B_x1 = 2 * (x1 + 2)\n        grad_B_x2 = 2 * x2\n        \n        grad_g_x1 = B_x * grad_A_x1 + A_x * grad_B_x1\n        grad_g_x2 = B_x * grad_A_x2 + A_x * grad_B_x2\n        \n        return np.array([grad_g_x1, grad_g_x2])\n\n    # Define the test cases\n    sqrt5 = np.sqrt(5)\n    p_right = np.array([2 - 2 / sqrt5, 1 / sqrt5])\n    p_left = np.array([-2 + 2 / sqrt5, 1 / sqrt5])\n\n    test_cases = [\n        [np.array([-3.0, 0.0]), np.array([-1.0, 0.0]), np.array([0.0, 0.0]), np.array([1.0, 0.0]), np.array([3.0, 0.0])],\n        [np.array([0.0, 3.0]), np.array([0.0, -2.0]), p_right, p_left],\n        [np.array([-2.0, 0.0]), np.array([-2.5, 0.5]), np.array([-1.5, -0.5])],\n        [np.array([-20.0, 0.0]), np.array([20.0, 0.0]), np.array([0.0, 10.0])]\n    ]\n\n    all_case_results = []\n\n    # Define the constraint object for scipy.optimize.minimize\n    nlc = NonlinearConstraint(g, -np.inf, 0, jac=grad_g)\n\n    for starts in test_cases:\n        left_count = 0\n        right_count = 0\n        successful_runs = 0\n        min_obj = float('inf')\n        total_runs = len(starts)\n\n        for x0 in starts:\n            res = minimize(f, x0, method='trust-constr', jac=grad_f, constraints=[nlc], options={'xtol': 1e-9, 'gtol': 1e-9})\n            \n            if res.success:\n                successful_runs += 1\n                \n                if res.fun  min_obj:\n                    min_obj = res.fun\n\n                # Classify the solution\n                x_sol = res.x\n                A_sol = (x_sol[0] - 2)**2 + x_sol[1]**2 - 1\n                B_sol = (x_sol[0] + 2)**2 + x_sol[1]**2 - 1\n                \n                # A small tolerance for floating point comparisons\n                tol = 1e-6 \n                \n                if B_sol = tol:  # Converged to the left disk\n                    left_count += 1\n                elif A_sol = tol:  # Converged to the right disk\n                    right_count += 1\n                # If neither, it's a successful run that didn't land in a basin.\n                # The problem assumes convergence to one of the two minimizers.\n                # For this specific problem and trust-constr, this is a safe assumption.\n\n        success_fraction = successful_runs / total_runs if total_runs  0 else 0.0\n        \n        # If no runs succeed, min_obj remains 'inf'. The problem statement implies success.\n        # We will set it to 0.0 as a neutral value if no minimum is found.\n        if np.isinf(min_obj):\n             min_obj = 0.0\n\n        all_case_results.append([left_count, right_count, min_obj, success_fraction])\n\n    # Format the final output string\n    formatted_strings = [f\"[{r[0]},{r[1]},{r[2]},{r[3]}]\" for r in all_case_results]\n    print(f\"[{','.join(formatted_strings)}]\")\n\nsolve()\n```", "id": "3166063"}]}