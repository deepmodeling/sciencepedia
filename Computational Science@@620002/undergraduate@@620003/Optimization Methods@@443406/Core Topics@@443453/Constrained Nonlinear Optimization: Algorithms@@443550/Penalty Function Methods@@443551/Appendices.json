{"hands_on_practices": [{"introduction": "To effectively solve the unconstrained subproblems generated by penalty methods, we often employ powerful iterative algorithms like Newton's method, which rely on derivative information. This first exercise [@problem_id:3162062] is a foundational practice in computing the gradient $\\nabla P_{\\mu}(x)$ and Hessian $\\nabla^{2}P_{\\mu}(x)$ of a general quadratic penalty function. By working through this derivation, you will gain a deeper understanding of the penalty function's structure and the computational costs involved in its optimization.", "problem": "Consider a twice continuously differentiable objective function $f:\\mathbb{R}^{n}\\to\\mathbb{R}$, a twice continuously differentiable equality constraint vector $h:\\mathbb{R}^{n}\\to\\mathbb{R}^{p}$, and a twice continuously differentiable inequality constraint vector $g:\\mathbb{R}^{n}\\to\\mathbb{R}^{m}$. Define the quadratic penalty function\n$$\nP_{\\mu}(x)\\;=\\;f(x)\\;+\\;\\frac{\\mu}{2}\\,\\|h(x)\\|^{2}\\;+\\;\\frac{\\mu}{2}\\,\\|\\max(0,\\,g(x))\\|^{2},\n$$\nwhere the maximum is understood elementwise, $\\mu0$, and $\\|\\cdot\\|$ denotes the Euclidean norm. Let $J_{h}(x)\\in\\mathbb{R}^{p\\times n}$ and $J_{g}(x)\\in\\mathbb{R}^{m\\times n}$ denote the Jacobian matrices that stack the gradients $\\nabla h_{j}(x)$ and $\\nabla g_{i}(x)$, respectively, and let $\\nabla^{2}h_{j}(x)$ and $\\nabla^{2}g_{i}(x)$ denote the Hessian matrices of individual constraint components. Assume we are at a point $x$ such that $g_{i}(x)\\neq 0$ for all $i$; define the active set $A(x)=\\{\\,i\\in\\{1,\\dots,m\\}\\;|\\;g_{i}(x)0\\,\\}$ and let $g_{A}(x)\\in\\mathbb{R}^{|A(x)|}$ and $J_{g_{A}}(x)\\in\\mathbb{R}^{|A(x)|\\times n}$ denote the subvector and sub-Jacobian restricted to indices in $A(x)$.\n\nStarting from core definitions of gradients, Jacobians, and the chain rule for composition of differentiable functions, derive closed-form expressions for the gradient $\\nabla P_{\\mu}(x)$ and the Hessian $\\nabla^{2}P_{\\mu}(x)$ at such a regular point $x$ in terms of $\\nabla f(x)$, $\\nabla^{2}f(x)$, $J_{h}(x)$, $J_{g_{A}}(x)$, $\\nabla^{2}h_{j}(x)$, and $\\nabla^{2}g_{i}(x)$. Then, discuss how the computational work required to assemble these expressions scales with the number of equality constraints $p$, the number of inequality constraints $m$, the size of the active set $|A(x)|$, and the decision dimension $n$, clearly identifying which terms dominate as $p$ and $|A(x)|$ grow.\n\nYour final answer must be the pair consisting of the gradient and Hessian expressions, written symbolically. No numerical approximation is required, and no units are involved.", "solution": "The problem asks for the gradient and Hessian of the quadratic penalty function $P_{\\mu}(x)$ and an analysis of the computational work required to assemble them. The problem is well-posed and scientifically grounded in the field of nonlinear optimization. The assumption that $g_i(x) \\neq 0$ for all $i \\in \\{1, \\dots, m\\}$ is critical, as it ensures that the penalty function $P_{\\mu}(x)$ is twice continuously differentiable in a neighborhood of $x$, thus guaranteeing the existence of its gradient and Hessian.\n\nThe quadratic penalty function is defined as:\n$$\nP_{\\mu}(x)\\;=\\;f(x)\\;+\\;\\frac{\\mu}{2}\\,\\|h(x)\\|^{2}\\;+\\;\\frac{\\mu}{2}\\,\\|\\max(0,\\,g(x))\\|^{2}\n$$\nwhere $\\mu  0$ is the penalty parameter. The squared Euclidean norms can be written as sums:\n$$\n\\|h(x)\\|^{2} = \\sum_{j=1}^{p} (h_{j}(x))^{2}\n$$\n$$\n\\|\\max(0,\\,g(x))\\|^{2} = \\sum_{i=1}^{m} (\\max(0,\\,g_{i}(x)))^{2}\n$$\nBy linearity of differentiation, the gradient $\\nabla P_{\\mu}(x)$ and Hessian $\\nabla^{2}P_{\\mu}(x)$ are the sums of the gradients and Hessians of the individual terms.\n\n**Derivation of the Gradient $\\nabla P_{\\mu}(x)$**\n\nThe gradient of $P_{\\mu}(x)$ is:\n$$\n\\nabla P_{\\mu}(x) = \\nabla f(x) + \\nabla \\left( \\frac{\\mu}{2} \\sum_{j=1}^{p} (h_{j}(x))^{2} \\right) + \\nabla \\left( \\frac{\\mu}{2} \\sum_{i=1}^{m} (\\max(0,\\,g_{i}(x)))^{2} \\right)\n$$\n\n1.  **Gradient of the equality constraint penalty term**:\n    Using the chain rule, the gradient of the term for the $j$-th equality constraint is:\n    $$\n    \\nabla \\left( \\frac{\\mu}{2} (h_{j}(x))^{2} \\right) = \\frac{\\mu}{2} \\cdot 2 h_{j}(x) \\cdot \\nabla h_{j}(x) = \\mu h_{j}(x) \\nabla h_{j}(x)\n    $$\n    Summing over all $p$ equality constraints:\n    $$\n    \\nabla \\left( \\frac{\\mu}{2} \\|h(x)\\|^{2} \\right) = \\sum_{j=1}^{p} \\mu h_{j}(x) \\nabla h_{j}(x)\n    $$\n    This sum can be expressed in matrix form. Given that the rows of the Jacobian $J_{h}(x)$ are the transposed gradients $(\\nabla h_{j}(x))^{T}$, this sum is equivalent to the matrix-vector product $\\mu J_{h}(x)^{T} h(x)$.\n\n2.  **Gradient of the inequality constraint penalty term**:\n    The derivative depends on the sign of $g_{i}(x)$. The function $\\phi(z) = (\\max(0,z))^2$ is continuously differentiable with $\\phi'(z)=2z$ for $z0$ and $\\phi'(z)=0$ for $z0$. Since we assume $g_{i}(x) \\neq 0$ for all $i$, the gradient is well-defined.\n    - If $g_{i}(x)  0$ (i.e., $i \\in A(x)$), the term is $\\frac{\\mu}{2} (g_{i}(x))^{2}$. Its gradient is $\\mu g_{i}(x) \\nabla g_{i}(x)$.\n    - If $g_{i}(x)  0$ (i.e., $i \\notin A(x)$), the term is $0$, and its gradient is the zero vector.\n    Summing over all $m$ inequality constraints, only the active ones contribute:\n    $$\n    \\nabla \\left( \\frac{\\mu}{2} \\|\\max(0, g(x))\\|^{2} \\right) = \\sum_{i \\in A(x)} \\mu g_{i}(x) \\nabla g_{i}(x)\n    $$\n    Similarly to the equality case, this sum can be written compactly as $\\mu J_{g_{A}}(x)^{T} g_{A}(x)$, where $g_{A}(x)$ is the vector of active constraint values and $J_{g_{A}}(x)$ is the Jacobian of these active constraints.\n\nCombining these results, the full gradient is:\n$$\n\\nabla P_{\\mu}(x) = \\nabla f(x) + \\mu J_{h}(x)^{T} h(x) + \\mu J_{g_{A}}(x)^{T} g_{A}(x)\n$$\n\n**Derivation of the Hessian $\\nabla^{2}P_{\\mu}(x)$**\n\nThe Hessian is the Jacobian of the gradient vector. We differentiate the expression for $\\nabla P_{\\mu}(x)$:\n$$\n\\nabla^{2} P_{\\mu}(x) = \\nabla^{2} f(x) + \\nabla^{2} \\left( \\frac{\\mu}{2} \\|h(x)\\|^{2} \\right) + \\nabla^{2} \\left( \\frac{\\mu}{2} \\|\\max(0, g(x))\\|^{2} \\right)\n$$\n\n1.  **Hessian of the equality constraint penalty term**:\n    We differentiate the gradient term $\\sum_{j=1}^{p} \\mu h_{j}(x) \\nabla h_{j}(x)$. Using the product rule for differentiation on the term for a single constraint $j$:\n    $$\n    \\nabla (\\mu h_{j}(x) \\nabla h_{j}(x))^{T} = \\mu [ \\nabla h_{j}(x) (\\nabla h_{j}(x))^{T} + h_{j}(x) \\nabla^{2}h_{j}(x) ]\n    $$\n    Summing over all $j=1, \\dots, p$:\n    $$\n    \\nabla^{2} \\left( \\frac{\\mu}{2} \\|h(x)\\|^{2} \\right) = \\mu \\sum_{j=1}^{p} \\left[ \\nabla h_{j}(x) (\\nabla h_{j}(x))^{T} + h_{j}(x) \\nabla^{2}h_{j}(x) \\right]\n    $$\n    The first part of the sum, $\\sum_{j=1}^{p} \\nabla h_{j}(x) (\\nabla h_{j}(x))^{T}$, is the definition of the matrix product $J_{h}(x)^{T} J_{h}(x)$. Thus, the Hessian contribution is:\n    $$\n    \\mu J_{h}(x)^{T} J_{h}(x) + \\mu \\sum_{j=1}^{p} h_{j}(x) \\nabla^{2}h_{j}(x)\n    $$\n\n2.  **Hessian of the inequality constraint penalty term**:\n    The logic is identical to the equality constraint case, but the sum is restricted to the active set $A(x)$. The assumption $g_i(x) \\neq 0$ ensures a constant active set in a neighborhood of $x$, making the second derivative well-defined.\n    $$\n    \\nabla^{2} \\left( \\frac{\\mu}{2} \\|\\max(0,g(x))\\|^{2} \\right) = \\mu \\sum_{i \\in A(x)} \\left[ \\nabla g_{i}(x) (\\nabla g_{i}(x))^{T} + g_{i}(x) \\nabla^{2}g_{i}(x) \\right]\n    $$\n    This can be written as:\n    $$\n    \\mu J_{g_{A}}(x)^{T} J_{g_{A}}(x) + \\mu \\sum_{i \\in A(x)} g_{i}(x) \\nabla^{2}g_{i}(x)\n    $$\n\nCombining all terms, the full Hessian matrix is:\n$$\n\\nabla^{2}P_{\\mu}(x) = \\nabla^{2}f(x) + \\mu J_{h}(x)^{T} J_{h}(x) + \\mu \\sum_{j=1}^{p} h_{j}(x) \\nabla^{2}h_{j}(x) + \\mu J_{g_{A}}(x)^{T} J_{g_{A}}(x) + \\mu \\sum_{i \\in A(x)} g_{i}(x) \\nabla^{2}g_{i}(x)\n$$\n\n**Computational Work Scaling**\n\nThe computational work to assemble the gradient and Hessian at a point $x$ scales with the number of variables $n$, equality constraints $p$, and inequality constraints $m$. Let $|A(x)|$ be the number of active inequality constraints at $x$.\n\n**Gradient Assembly**: Assembling $\\nabla P_{\\mu}(x)$ requires:\n- Evaluating all $m$ inequality constraints $g_i(x)$ to determine the active set $A(x)$, with a cost scaling as $O(m)$.\n- Evaluating the objective gradient $\\nabla f(x)$, the constraint vectors $h(x)$ and $g_{A}(x)$, and the Jacobians $J_{h}(x)$ and $J_{g_{A}}(x)$. The cost of evaluating the Jacobians is typically proportional to $O(pn)$ and $O(|A(x)|n)$, respectively.\n- Performing the matrix-vector products $J_{h}(x)^{T}h(x)$ (cost $O(pn)$) and $J_{g_{A}}(x)^{T}g_{A}(x)$ (cost $O(|A(x)|n)$).\nThe dominant work scales as $O(m + (p+|A(x)|)n)$. The cost is linear in $m$, $p$, and $|A(x)|$.\n\n**Hessian Assembly**: Assembling the $n \\times n$ matrix $\\nabla^{2}P_{\\mu}(x)$ requires:\n- All computations for the gradient, plus evaluation of second derivatives.\n- Forming the matrix products $J_{h}(x)^{T}J_{h}(x)$ (cost $O(pn^{2})$) and $J_{g_{A}}(x)^{T}J_{g_{A}}(x)$ (cost $O(|A(x)|n^{2})$).\n- Computing the $p$ Hessians $\\nabla^{2}h_{j}(x)$ and the $|A(x)|$ Hessians $\\nabla^{2}g_{i}(x)$ and forming their weighted sums. This requires on the order of $O(pn^{2})$ and $O(|A(x)|n^{2})$ operations, respectively.\nThe dominant work is in forming the outer-product-like terms and the sum of individual Hessians. As $p$ and $|A(x)|$ grow, the terms that dominate the computational effort are the matrix products $J_{h}(x)^{T}J_{h}(x)$ and $J_{g_{A}}(x)^{T}J_{g_{A}}(x)$, along with the computation and summation of the $p + |A(x)|$ individual constraint Hessians. The overall computational work to assemble the Hessian scales as $O((p + |A(x)|)n^{2})$. This scaling is linear in the number of equality constraints and active inequality constraints, but quadratic in the number of decision variables.", "answer": "$$\n\\boxed{\n\\begin{aligned}\n\\nabla P_{\\mu}(x) = \\nabla f(x) + \\mu J_{h}(x)^{T} h(x) + \\mu J_{g_{A}}(x)^{T} g_{A}(x) \\\\\n\\nabla^{2}P_{\\mu}(x) = \\nabla^{2}f(x) + \\mu \\left( J_{h}(x)^{T} J_{h}(x) + \\sum_{j=1}^{p} h_{j}(x) \\nabla^{2}h_{j}(x) \\right) + \\mu \\left( J_{g_{A}}(x)^{T} J_{g_{A}}(x) + \\sum_{i \\in A(x)} g_{i}(x) \\nabla^{2}g_{i}(x) \\right)\n\\end{aligned}\n}\n$$", "id": "3162062"}, {"introduction": "While penalty methods offer a versatile approach to constrained optimization, their effectiveness can depend on both the problem's structure and the specific penalty function used, especially for non-convex problems. This insightful exercise [@problem_id:3162017] demonstrates a scenario where a standard quadratic penalty method can fail by converging to a poor, infeasible local minimizer. In contrast, it shows how a non-differentiable exact $L_1$ penalty, with a properly chosen parameter, successfully identifies the true constrained optimum, highlighting a crucial difference in their capabilities.", "problem": "Consider the equality-constrained minimization problem in two variables with a nonconvex objective:\nminimize $f(x,y)$ subject to $g(x,y)=0$, where\n$f(x,y)=(x^{2}+y^{2}-1)^{2}+\\frac{1}{10}\\,x$ and $g(x,y)=x$.\nThis objective has a ring-shaped quartic well centered at the origin (sometimes called a “Mexican hat”) and a linear tilt. You will compare two penalty formulations for enforcing the linear equality.\n\nUsing only the foundational definitions of penalty function methods, first-order optimality, and basic calculus, do the following.\n\n1) Solve the constrained problem exactly by eliminating the constraint and minimizing $f$ over the feasible set. Identify the set of global constrained minimizers.\n\n2) Consider the quadratic penalty $P_{\\rho}(x,y)=f(x,y)+\\frac{\\rho}{2}\\,g(x,y)^{2}$ with $\\rho=\\frac{1}{10}$. Demonstrate that $P_{\\rho}$ admits an infeasible strict local minimizer and compute its objective value relative to the best feasible value under $P_{\\rho}$. Conclude why a quadratic penalty method can be attracted to a poor (infeasible) local minimizer on this nonconvex problem for finite $\\rho$.\n\n3) Consider the exact $L_1$ penalty $E_{\\mu}(x,y)=f(x,y)+\\mu\\,|g(x,y)|=f(x,y)+\\mu\\,|x|$. Determine the smallest value $\\mu^{\\star}0$ such that every global minimizer of $E_{\\mu}$ coincides with a global constrained minimizer of the original problem. Express your final answer as an exact value (no rounding).", "solution": "The problem asks for a three-part analysis of an equality-constrained optimization problem using penalty methods. I will first validate the problem statement and then proceed to solve each part in sequence.\n\nThe problem is valid. It is a well-posed mathematical problem in the field of optimization. All functions, constants, and objectives are clearly defined and scientifically sound. The problem is free of contradictions, ambiguities, and non-formalizable statements.\n\nPart 1: Exact solution of the constrained problem.\nThe problem is to minimize the objective function $f(x,y)=(x^{2}+y^{2}-1)^{2}+\\frac{1}{10}\\,x$ subject to the equality constraint $g(x,y)=x=0$.\n\nTo solve this problem, we substitute the constraint $x=0$ directly into the objective function. This reduces the problem to an unconstrained minimization problem in the single variable $y$. Let the constrained objective function be $f_c(y)$.\n$$f_c(y) = f(0,y) = (0^{2}+y^{2}-1)^{2}+\\frac{1}{10}\\,(0) = (y^{2}-1)^{2}$$\nWe need to find the value(s) of $y$ that minimize $f_c(y)$. The function $f_c(y)$ is a squared term, so its value is always non-negative, i.e., $(y^{2}-1)^{2} \\ge 0$. The minimum possible value is $0$. This minimum is achieved when the term inside the square is zero:\n$$y^{2}-1 = 0 \\implies y^{2} = 1 \\implies y = \\pm 1$$\nTherefore, the minimum value of the constrained objective function is $0$, and this occurs at $y=1$ and $y=-1$. Since the constraint dictates $x=0$, the points in the $xy$-plane that minimize the function are $(0, 1)$ and $(0, -1)$.\n\nThe set of global constrained minimizers is $\\{(0, 1), (0, -1)\\}$. The minimum objective value is $f(0, \\pm 1)=0$.\n\nPart 2: Analysis of the quadratic penalty method.\nWe consider the quadratic penalty function $P_{\\rho}(x,y) = f(x,y)+\\frac{\\rho}{2}\\,g(x,y)^{2}$ with the penalty parameter $\\rho=\\frac{1}{10}$.\n$$P_{\\frac{1}{10}}(x,y) = (x^{2}+y^{2}-1)^{2}+\\frac{1}{10}\\,x + \\frac{1}{2}\\left(\\frac{1}{10}\\right)x^{2} = (x^{2}+y^{2}-1)^{2}+\\frac{1}{10}\\,x + \\frac{1}{20}\\,x^{2}$$\nTo find local minimizers, we compute the gradient of $P_{\\frac{1}{10}}(x,y)$ and set it to zero.\n$$\\nabla P_{\\frac{1}{10}}(x,y) = \\begin{pmatrix} \\frac{\\partial P}{\\partial x} \\\\ \\frac{\\partial P}{\\partial y} \\end{pmatrix} = \\begin{pmatrix} 0 \\\\ 0 \\end{pmatrix}$$\nThe partial derivatives are:\n$$\\frac{\\partial P}{\\partial x} = 2(x^{2}+y^{2}-1)(2x) + \\frac{1}{10} + \\frac{1}{10}x = 4x(x^{2}+y^{2}-1) + \\frac{1}{10}(1+x) = 0$$\n$$\\frac{\\partial P}{\\partial y} = 2(x^{2}+y^{2}-1)(2y) = 4y(x^{2}+y^{2}-1) = 0$$\nFrom the second equation, $\\frac{\\partial P}{\\partial y}=0$, we have two cases: $y=0$ or $x^{2}+y^{2}-1=0$.\n\nCase A: $x^{2}+y^{2}-1=0$.\nSubstituting this into the equation for $\\frac{\\partial P}{\\partial x}=0$:\n$$4x(0) + \\frac{1}{10}(1+x) = 0 \\implies 1+x = 0 \\implies x=-1$$\nFrom $x^{2}+y^{2}-1=0$, we have $(-1)^{2}+y^{2}-1=0 \\implies 1+y^{2}-1=0 \\implies y^{2}=0 \\implies y=0$.\nThis gives a critical point at $(-1, 0)$. This point is infeasible as $x=-1 \\neq 0$.\n\nCase B: $y=0$.\nSubstituting this into the equation for $\\frac{\\partial P}{\\partial x}=0$:\n$$4x(x^{2}+0^{2}-1) + \\frac{1}{10}(1+x) = 0$$\n$$4x(x^{2}-1) + \\frac{1}{10}(1+x) = 0$$\n$$4x^{3}-4x + \\frac{1}{10}x + \\frac{1}{10} = 0$$\n$$4x^{3} - \\frac{39}{10}x + \\frac{1}{10} = 0$$\n$$40x^{3} - 39x + 1 = 0$$\nFrom Case A, we know $x=-1$ is a root. We can factor the polynomial: $(x+1)(40x^{2}-40x+1)=0$.\nThe roots are $x=-1$ and the roots of $40x^{2}-40x+1=0$, which are given by the quadratic formula:\n$$x = \\frac{40 \\pm \\sqrt{1600 - 4(40)(1)}}{80} = \\frac{40 \\pm \\sqrt{1440}}{80} = \\frac{40 \\pm 12\\sqrt{10}}{80} = \\frac{10 \\pm 3\\sqrt{10}}{20}$$\nSo the critical points with $y=0$ are $(-1, 0)$, $(\\frac{10+3\\sqrt{10}}{20}, 0)$, and $(\\frac{10-3\\sqrt{10}}{20}, 0)$.\n\nTo determine if these are minimizers, we use the second derivative test. The Hessian matrix of $P_{\\frac{1}{10}}(x,y)$ is:\n$$H(x,y) = \\begin{pmatrix} 12x^{2}+4y^{2}-\\frac{39}{10}  8xy \\\\ 8xy  4x^{2}+12y^{2}-4 \\end{pmatrix}$$\nAt any point $(x,0)$, the Hessian is diagonal:\n$$H(x,0) = \\begin{pmatrix} 12x^{2}-\\frac{39}{10}  0 \\\\ 0  4x^{2}-4 \\end{pmatrix}$$\nFor a point to be a strict local minimizer, the Hessian must be positive definite, meaning both diagonal entries must be positive.\n- At $(-1, 0)$: $x^{2}=1$. $H_{11}=12(1)-\\frac{39}{10}=8.1  0$. $H_{22}=4(1)-4=0$. The Hessian is positive semidefinite. A higher-order test confirms this is a strict local minimizer. This point is infeasible.\n- At $(\\frac{10+3\\sqrt{10}}{20}, 0)$: $x \\approx 0.974$, so $x^2  1$. Thus $H_{22} = 4x^2-4  0$. This is a saddle point.\n- At $(\\frac{10-3\\sqrt{10}}{20}, 0)$: $x \\approx 0.026$, so $x^2  1$ and $x^2  39/120$. Thus $H_{11}  0$ and $H_{22}  0$. This is a local maximizer.\n\nThe only infeasible local minimizer is $(-1, 0)$.\nThe value of the penalty function at this minimizer is:\n$$P_{\\frac{1}{10}}(-1, 0) = ((-1)^{2}+0^{2}-1)^{2}+\\frac{1}{10}(-1) + \\frac{1}{20}(-1)^{2} = 0 - \\frac{1}{10} + \\frac{1}{20} = -\\frac{1}{20}$$\nThe best feasible value of $P_{\\rho}$ occurs on the feasible set $x=0$. On this set, $P_{\\rho}(0,y)=f(0,y)$. From Part 1, the minimum value of $f(0,y)$ is $0$, achieved at the constrained minimizers $(0, \\pm 1)$.\nSo, the best feasible value under $P_{\\frac{1}{10}}$ is $0$.\nThe objective value at the infeasible minimizer relative to the best feasible value is the difference:\n$$P_{\\frac{1}{10}}(-1, 0) - \\min_{y} P_{\\frac{1}{10}}(0,y) = -\\frac{1}{20} - 0 = -\\frac{1}{20}$$\nSince the penalty function has a local minimum at an infeasible point $(-1, 0)$ with a value $(-\\frac{1}{20})$ that is strictly less than the minimum value on the feasible set ($0$), an algorithm performing unconstrained minimization on $P_{\\rho}(x,y)$ for this finite $\\rho$ can converge to this \"poor\" infeasible solution.\n\nPart 3: Analysis of the exact $L_1$ penalty method.\nWe consider the exact penalty function $E_{\\mu}(x,y) = f(x,y)+\\mu|g(x,y)| = (x^{2}+y^{2}-1)^{2}+\\frac{1}{10}\\,x + \\mu|x|$.\nWe want to find the smallest $\\mu^{\\star}0$ such that all global minimizers of $E_{\\mu}(x,y)$ are the constrained minimizers $\\{(0, 1), (0, -1)\\}$.\n\nAt the constrained minimizers $(0, \\pm 1)$, the value of $E_{\\mu}$ is $E_{\\mu}(0, \\pm 1) = f(0, \\pm 1) + \\mu|0| = 0$.\nFor these points to be global minimizers of $E_{\\mu}$, we require $E_{\\mu}(x,y) \\ge 0$ for all $(x,y)$.\n$$E_{\\mu}(x,y) = (x^{2}+y^{2}-1)^{2} + \\left(\\frac{1}{10}x + \\mu|x|\\right) \\ge 0$$\nThe first term $(x^{2}+y^{2}-1)^{2}$ is always non-negative. We need to analyze the second term, $h(x) = \\frac{1}{10}x + \\mu|x|$.\n- If $x0$, $h(x) = \\frac{1}{10}x + \\mu x = (\\mu+\\frac{1}{10})x$. Since $\\mu0$, $h(x)0$.\n- If $x0$, $h(x) = \\frac{1}{10}x - \\mu x = (\\frac{1}{10}-\\mu)x$. For $h(x)$ to be non-negative, since $x0$, we need the coefficient $(\\frac{1}{10}-\\mu)$ to be less than or equal to zero. This implies $\\frac{1}{10} \\le \\mu$.\n- If $x=0$, $h(0)=0$.\n\nSo, for $\\mu \\ge \\frac{1}{10}$, the term $h(x)$ is non-negative for all $x$. Consequently, $E_{\\mu}(x,y) \\ge 0$ for all $(x,y)$.\nSince we know $E_{\\mu}(0,\\pm 1)=0$, the global minimum value of $E_{\\mu}$ is $0$ for any $\\mu \\ge \\frac{1}{10}$.\n\nThe global minimizers are the points $(x,y)$ where $E_{\\mu}(x,y)=0$. This requires both non-negative terms to be zero:\n1) $(x^{2}+y^{2}-1)^{2}=0 \\implies x^{2}+y^{2}=1$.\n2) $\\frac{1}{10}x+\\mu|x|=0$.\n\nLet's inspect the solutions to the second equation for $\\mu \\ge \\frac{1}{10}$:\n- If $\\mu  \\frac{1}{10}$:\n  For $x0$, $(\\mu+\\frac{1}{10})x=0 \\implies x=0$, a contradiction.\n  For $x0$, $(\\frac{1}{10}-\\mu)x=0$. Since $\\mu \\neq \\frac{1}{10}$, we must have $x=0$, a contradiction.\n  The only solution is $x=0$.\n  If $x=0$, from condition 1), $0^{2}+y^{2}=1 \\implies y=\\pm 1$. The global minimizers are $(0, 1)$ and $(0,-1)$. This set matches the constrained minimizers.\n\n- If $\\mu = \\frac{1}{10}$:\n  For $x0$, $(\\frac{1}{10}+\\frac{1}{10})x=0 \\implies x=0$, a contradiction.\n  For $x0$, $(\\frac{1}{10}-\\frac{1}{10})x=0 \\cdot x = 0$. This is true for all $x0$.\n  So for $\\mu=\\frac{1}{10}$, the minimizers are points satisfying condition 1) $x^2+y^2=1$ and the condition $x \\le 0$. This corresponds to the left half of the unit circle. This set of minimizers is $\\{(x,y) | x^{2}+y^{2}=1, x \\le 0\\}$, which is strictly larger than the set of constrained minimizers $\\{(0,1), (0,-1)\\}$.\n\nThe problem requires that **every** global minimizer of $E_{\\mu}$ be a constrained minimizer. This condition holds if and only if $\\mu  \\frac{1}{10}$. The set of values of $\\mu$ for which the property holds is the open interval $(\\frac{1}{10}, \\infty)$. The question asks for the \"smallest value $\\mu^{\\star}0$\". This refers to the infimum of this set, which is the threshold value where the behavior changes.\nThis smallest value is $\\mu^{\\star} = \\frac{1}{10}$. This value is also given by the magnitude of the Lagrange multiplier $\\lambda^{\\star}$ of the original problem, where $|\\lambda^{\\star}| = |-\\frac{1}{10}| = \\frac{1}{10}$.", "answer": "$$\\boxed{\\frac{1}{10}}$$", "id": "3162017"}, {"introduction": "The true test of understanding often comes from implementation. This final practice [@problem_id:3162033] challenges you to apply the penalty method to a concrete network flow problem, moving from pure mathematical derivation to computational practice. You will construct and solve the necessary linear systems to see firsthand how the penalty minimizer $x(\\mu)$ approaches the feasible set as the penalty parameter $\\mu$ grows. This exercise provides a tangible way to analyze convergence and connects the behavior of the penalty solution to the true solution obtained via Euclidean projection.", "problem": "You are given a directed network with nodes $\\{0,1,2,3\\}$ and directed edges $\\{e_0,e_1,e_2,e_3,e_4\\}$ defined as follows: $e_0$ goes from node $0$ to node $1$, $e_1$ goes from node $0$ to node $2$, $e_2$ goes from node $1$ to node $2$, $e_3$ goes from node $1$ to node $3$, and $e_4$ goes from node $2$ to node $3$. Let the flow vector be $x \\in \\mathbb{R}^5$, where the component ordering is $(x_{e_0},x_{e_1},x_{e_2},x_{e_3},x_{e_4})$. Consider flow conservation equalities at nodes $\\{0,1,2\\}$ (node $3$ is omitted), using the convention that each node’s net outflow equals its divergence. With this convention, the matrix $A \\in \\mathbb{R}^{3 \\times 5}$ representing net outflow constraints at nodes $\\{0,1,2\\}$ is\n$$\nA=\\begin{bmatrix}\n1  1  0  0  0\\\\\n-1  0  1  1  0\\\\\n0  -1  -1  0  1\n\\end{bmatrix},\n$$\nand the divergence vector is $b \\in \\mathbb{R}^3$ with $b=[1,0,0]^T$. The underlying convex quadratic cost is\n$$\nf(x)=\\tfrac{1}{2} x^T Q x + c^T x,\n$$\nwhere $Q \\in \\mathbb{R}^{5 \\times 5}$ is diagonal with entries $\\{2,1,3,1,2\\}$ and $c \\in \\mathbb{R}^5$ equals $[0.1,0.2,0.0,-0.1,0.1]^T$. Consider the quadratic penalty objective\n$$\nF_\\mu(x)=\\tfrac{1}{2} x^T Q x + c^T x + \\tfrac{\\mu}{2}\\lVert A x - b\\rVert_2^2,\n$$\nfor a penalty parameter $\\mu0$.\n\nStarting from the following fundamental base: (i) the first-order optimality condition for unconstrained differentiable convex minimization that the gradient equals zero, (ii) the Euclidean projection onto an affine set minimizes a squared Euclidean distance subject to linear equalities, and (iii) the Karush–Kuhn–Tucker (KKT) conditions giving necessary and sufficient optimality conditions for convex quadratic programs with linear equality constraints, complete the tasks below without using any shortcut formulas.\n\nTasks:\n- Derive the stationarity condition for the minimizer $x(\\mu)$ of $F_\\mu(x)$ and express it as a linear system in $x(\\mu)$, $A$, $Q$, $b$, $c$, and $\\mu$.\n- Derive the Euclidean projection operator $P(\\cdot)$ onto the affine set $\\{y \\in \\mathbb{R}^5 \\mid A y = b\\}$ and express $P(x)$ via $A$ and $b$.\n- Derive the KKT conditions for the equality-constrained problem $\\min_x f(x)$ subject to $A x = b$, and write the corresponding linear system in the primal variable $x^\\star$ and Lagrange multipliers $\\lambda^\\star$.\n- Implement a program that constructs $A$, $Q$, $c$, and $b$ exactly as specified, then for each test penalty value $\\mu$ computes:\n  1. The penalty minimizer $x(\\mu)$ by solving the stationarity linear system you derived.\n  2. The feasibility violation $v(\\mu)=\\lVert A x(\\mu)-b\\rVert_2$.\n  3. The Euclidean projection $y(\\mu)=P\\big(x(\\mu)\\big)$.\n  4. The distance to projection $d(\\mu)=\\lVert x(\\mu)-y(\\mu)\\rVert_2$.\n  5. The equality-constrained optimizer $x^\\star$ by solving the KKT linear system you derived, and the objective gap $g(\\mu)=f\\big(y(\\mu)\\big)-f\\big(x^\\star\\big)$.\n- Use the following test suite for the penalty parameter $\\mu$: $\\{10^{-6},10^{-2},1,10,10^{4}\\}$.\n- Your program must output a single line containing a list of results, one per test $\\mu$, where each result is a list of three floats $[v(\\mu),d(\\mu),g(\\mu)]$, each rounded to $6$ decimal places. The final output format must be a single line that is a comma-separated list enclosed in square brackets, for example\n$[\\,[v(\\mu_1),d(\\mu_1),g(\\mu_1)],\\,[v(\\mu_2),d(\\mu_2),g(\\mu_2)],\\,\\dots\\,]$.\n\nScientific realism and derivation requirements:\n- All derivations must begin from the three foundational elements listed above and proceed step by step, without introducing any unstated shortcuts or quoting target formulas.\n- Angles and physical units do not apply here.\n- The final outputs for the test suite are lists of floats, and the single-line output must aggregate all cases into one bracketed list as specified.", "solution": "The problem is valid. It presents a well-posed, self-contained, and scientifically grounded problem in the field of convex optimization, specifically concerning the quadratic penalty method for a linearly constrained quadratic program. All necessary data, definitions, and matrices are provided, and the tasks involve standard derivations and computations in this domain.\n\n### Derivations\n\nThe solution requires three core derivations based on the fundamental principles specified in the problem statement.\n\n**1. Stationarity Condition for the Penalty Objective $F_\\mu(x)$**\n\nThe penalty objective function is given by\n$$F_\\mu(x)=\\tfrac{1}{2} x^T Q x + c^T x + \\tfrac{\\mu}{2}\\lVert A x - b\\rVert_2^2$$\nThe matrix $Q$ is diagonal with positive entries $\\{2,1,3,1,2\\}$, making it positive definite. Thus, the function $f(x)=\\tfrac{1}{2} x^T Q x + c^T x$ is strictly convex. The penalty term $\\tfrac{\\mu}{2}\\lVert A x - b\\rVert_2^2$ is also convex for any $\\mu  0$, as it is the composition of an affine function $x \\mapsto Ax-b$ and a convex function $z \\mapsto \\tfrac{\\mu}{2}\\lVert z \\rVert_2^2$. Therefore, $F_\\mu(x)$ is a strictly convex and differentiable function for $\\mu0$.\n\nBased on the first-order optimality condition for unconstrained convex minimization, the unique minimizer $x(\\mu)$ is found where the gradient of $F_\\mu(x)$ with respect to $x$ is the zero vector.\nThe gradient is:\n$$\\nabla F_\\mu(x) = \\nabla_x \\left( \\tfrac{1}{2} x^T Q x + c^T x \\right) + \\nabla_x \\left( \\tfrac{\\mu}{2}(A x - b)^T (A x - b) \\right)$$\nThe gradient of the first part is $\\nabla_x f(x) = Qx + c$.\nFor the penalty term, we expand it as $\\tfrac{\\mu}{2}(x^T A^T A x - 2b^T A x + b^T b)$. The gradient of this quadratic form is $\\tfrac{\\mu}{2}(2A^T A x - 2A^T b) = \\mu A^T(Ax-b)$.\nCombining these, the gradient of $F_\\mu(x)$ is:\n$$\\nabla F_\\mu(x) = Qx + c + \\mu A^T(Ax-b)$$\nSetting the gradient to zero at the optimizer $x(\\mu)$:\n$$\\nabla F_\\mu(x(\\mu)) = Qx(\\mu) + c + \\mu A^T(Ax(\\mu)-b) = 0$$\nRearranging the terms to form a linear system in $x(\\mu)$:\n$$Qx(\\mu) + \\mu A^T A x(\\mu) = \\mu A^T b - c$$\n$$(Q + \\mu A^T A) x(\\mu) = \\mu A^T b - c$$\nThis is the stationarity condition expressed as a linear system for the minimizer $x(\\mu)$. The matrix $(Q + \\mu A^T A)$ is positive definite since $Q$ is positive definite and $\\mu A^T A$ is positive semi-definite for $\\mu  0$, guaranteeing a unique solution for $x(\\mu)$.\n\n**2. Euclidean Projection Operator $P(x)$**\n\nThe Euclidean projection $y(\\mu) = P(x(\\mu))$ of a point $x(\\mu)$ onto the affine set $S = \\{y \\in \\mathbb{R}^5 \\mid Ay = b\\}$ is the point in $S$ that minimizes the squared Euclidean distance to $x(\\mu)$. The problem is:\n$$\\min_{y \\in \\mathbb{R}^5} \\tfrac{1}{2} \\lVert y - x(\\mu) \\rVert_2^2 \\quad \\text{subject to} \\quad Ay = b$$\nThis is an equality-constrained convex quadratic program. The Karush-Kuhn-Tucker (KKT) conditions provide necessary and sufficient conditions for optimality. Let $x$ be the point to be projected. The Lagrangian is:\n$$L(y, \\lambda) = \\tfrac{1}{2} (y-x)^T(y-x) + \\lambda^T(Ay-b)$$\nwhere $\\lambda \\in \\mathbb{R}^3$ is the vector of Lagrange multipliers. The KKT conditions are:\n1.  **Stationarity:** The gradient of $L$ with respect to $y$ must be zero.\n    $$\\nabla_y L(y, \\lambda) = (y-x) + A^T \\lambda = 0 \\implies y = x - A^T \\lambda$$\n2.  **Primal Feasibility:** The constraint must be satisfied.\n    $$Ay = b$$\nSubstituting the expression for $y$ from the stationarity condition into the feasibility condition:\n$$A(x - A^T \\lambda) = b$$\n$$Ax - A A^T \\lambda = b$$\n$$A A^T \\lambda = Ax - b$$\nThe matrix $A \\in \\mathbb{R}^{3 \\times 5}$ has full row rank (rank $3$), which means the $3 \\times 3$ matrix $A A^T$ is invertible. We can solve for $\\lambda$:\n$$\\lambda = (A A^T)^{-1} (Ax - b)$$\nSubstituting this $\\lambda$ back into the expression for $y$ gives the projection operator $P(x)$:\n$$P(x) = y = x - A^T (A A^T)^{-1} (Ax - b)$$\n\n**3. KKT System for the Constrained Problem**\n\nThe original constrained optimization problem is:\n$$\\min_x f(x) = \\tfrac{1}{2} x^T Q x + c^T x \\quad \\text{subject to} \\quad Ax = b$$\nThis is a convex quadratic program with linear equality constraints. The KKT conditions are necessary and sufficient for a point $x^\\star$ to be the unique global minimizer. The Lagrangian for this problem is:\n$$L(x, \\lambda) = f(x) + \\lambda^T(Ax-b) = \\tfrac{1}{2} x^T Q x + c^T x + \\lambda^T(Ax-b)$$\nThe KKT conditions for an optimal primal-dual pair $(x^\\star, \\lambda^\\star)$ are:\n1.  **Stationarity:** The gradient of $L$ with respect to $x$ is zero.\n    $$\\nabla_x L(x^\\star, \\lambda^\\star) = Qx^\\star + c + A^T \\lambda^\\star = 0$$\n2.  **Primal Feasibility:** The constraint is satisfied.\n    $$Ax^\\star = b$$\nThese two conditions can be combined into a single linear block system:\n$$\\begin{bmatrix} Q  A^T \\\\ A  0 \\end{bmatrix} \\begin{bmatrix} x^\\star \\\\ \\lambda^\\star \\end{bmatrix} = \\begin{bmatrix} -c \\\\ b \\end{bmatrix}$$\nwhere the $0$ is a $3 \\times 3$ zero matrix. Solving this system yields the constrained optimizer $x^\\star$ and the associated Lagrange multipliers $\\lambda^\\star$.\n\n### Computational Procedure\n\nThe numerical implementation proceeds as follows:\n1.  The matrices $A$, $Q$ and vectors $c$, $b$ are constructed as specified.\n2.  The KKT system for the constrained problem is formed and solved once to find the optimal solution $x^\\star$. This is independent of $\\mu$. The optimal objective value $f(x^\\star)$ is also computed.\n3.  A loop iterates through each penalty parameter $\\mu$ from the test suite $\\{10^{-6}, 10^{-2}, 1, 10, 10^{4}\\}$.\n4.  Inside the loop, for each $\\mu$:\n    a. The linear system $(Q + \\mu A^T A) x(\\mu) = \\mu A^T b - c$ is solved to find the penalty minimizer $x(\\mu)$.\n    b. The feasibility violation $v(\\mu) = \\lVert A x(\\mu) - b \\rVert_2$ is computed.\n    c. The projection $y(\\mu) = P(x(\\mu))$ is calculated using the derived formula $y(\\mu) = x(\\mu) - A^T (A A^T)^{-1} (A x(\\mu) - b)$.\n    d. The distance to projection $d(\\mu) = \\lVert x(\\mu) - y(\\mu) \\rVert_2$ is computed.\n    e. The objective value at the projected point, $f(y(\\mu))$, is calculated, and the objective gap $g(\\mu) = f(y(\\mu)) - f(x^\\star)$ is determined.\n5.  The computed values $[v(\\mu), d(\\mu), g(\\mu)]$ are rounded to $6$ decimal places and stored.\n6.  Finally, the collected results for all $\\mu$ values are formatted into the specified single-line string representation of a list of lists.", "answer": "[[0.509935,0.222718,0.024803],[0.509923,0.222713,0.024801],[0.508736,0.222209,0.024691],[0.498305,0.217658,0.023729],[0.07639,0.03337,0.000557]]", "id": "3162033"}]}