{"hands_on_practices": [{"introduction": "This first practice problem introduces a foundational technique in second-order cone programming: the epigraph transformation. You will learn how to convert a standard optimization problem—finding the minimum-norm solution to a system of linear equations—into the canonical SOCP format. This skill is crucial as it allows us to solve problems with nonlinear objectives, like minimizing Euclidean distance, using the powerful and efficient machinery of SOCP solvers [@problem_id:2200440].", "problem": "In many control and estimation problems, a key objective is to find a solution that is \"small\" in some sense, often corresponding to minimum energy or minimum error. Consider the problem of finding a vector $x \\in \\mathbb{R}^n$ that satisfies a set of linear constraints $Ax = b$, where $A \\in \\mathbb{R}^{m \\times n}$ and $b \\in \\mathbb{R}^m$ are given, and additionally has the smallest possible Euclidean norm $\\|x\\|_2$.\n\nThis optimization problem can be formulated as a Second-Order Cone Program (SOCP). A standard form for an SOCP is:\n$$\n\\begin{aligned}\n\\text{minimize} \\quad & f^T y \\\\\n\\text{subject to} \\quad & \\|G_i y + h_i\\|_2 \\le k_i^T y + l_i, \\quad i=1, \\dots, p \\\\\n& F y = g\n\\end{aligned}\n$$\nTo cast the minimum norm problem into this form, we introduce an auxiliary scalar variable $t$ and define a new optimization variable $y = \\begin{pmatrix} x \\\\ t \\end{pmatrix} \\in \\mathbb{R}^{n+1}$. The problem can then be expressed using a single cone constraint ($p=1$) and a single block of linear equalities.\n\nYour task is to identify the correct matrices and vectors that define this SOCP. The objective vector is $f$, the matrix for the linear constraint is $F$, and the corresponding right-hand side is $g=b$. For the single cone constraint, we can set $h_1 = 0$ (a zero vector of appropriate size) and $l_1 = 0$.\n\nWhich of the following choices for the objective vector $f$, the cone constraint matrix $G_1$, the cone constraint vector $k_1$, and the linear equality matrix $F$ is correct? Note that $I_n$ denotes the $n \\times n$ identity matrix, $0_{p \\times q}$ denotes the $p \\times q$ zero matrix, and $0_p$ denotes a zero vector of size $p$.\n\nA)\n$f = \\begin{pmatrix} 0_n \\\\ 1 \\end{pmatrix}$,\n$G_1 = [I_n \\ | \\ 0_{n \\times 1}]$,\n$k_1 = \\begin{pmatrix} 0_n \\\\ 1 \\end{pmatrix}$,\n$F = [A \\ | \\ 0_{m \\times 1}]$\n\nB)\n$f = \\begin{pmatrix} 0_n \\\\ 1 \\end{pmatrix}$,\n$G_1 = I_{n+1}$,\n$k_1 = \\begin{pmatrix} 0_n \\\\ 1 \\end{pmatrix}$,\n$F = [A \\ | \\ 0_{m \\times 1}]$\n\nC)\n$f = \\begin{pmatrix} 0_n \\\\ 1 \\end{pmatrix}$,\n$G_1 = [A \\ | \\ 0_{m \\times 1}]$,\n$k_1 = \\begin{pmatrix} 0_n \\\\ 1 \\end{pmatrix}$,\n$F = [I_n \\ | \\ 0_{n \\times 1}]$\n\nD)\n$f = \\begin{pmatrix} 0_n \\\\ 1 \\end{pmatrix}$,\n$G_1 = [I_n \\ | \\ 0_{n \\times 1}]$,\n$k_1 = \\begin{pmatrix} e_1 \\\\ 0 \\end{pmatrix}$ where $e_1 \\in \\mathbb{R}^n$ is the first standard basis vector,\n$F = [A \\ | \\ 0_{m \\times 1}]$", "solution": "We start from the minimum-norm problem:\n$$\n\\text{minimize } \\|x\\|_{2} \\quad \\text{subject to } Ax = b, \\quad x \\in \\mathbb{R}^{n}.\n$$\nIntroduce an auxiliary scalar $t \\in \\mathbb{R}$ and use the epigraph reformulation:\n$$\n\\text{minimize } t \\quad \\text{subject to } \\|x\\|_{2} \\le t, \\quad Ax = b.\n$$\nDefine the stacked variable $y \\in \\mathbb{R}^{n+1}$ by\n$$\ny = \\begin{pmatrix} x \\\\ t \\end{pmatrix}.\n$$\nThe SOCP standard form is\n$$\n\\text{minimize } f^{T} y \\quad \\text{subject to } \\|G_{1} y + h_{1}\\|_{2} \\le k_{1}^{T} y + l_{1}, \\quad Fy = g.\n$$\nWe choose the objective to be $f^{T} y = t$, which implies\n$$\nf = \\begin{pmatrix} 0_{n} \\\\ 1 \\end{pmatrix}.\n$$\nWe set $h_{1} = 0$ and $l_{1} = 0$ as allowed. To encode the cone constraint $\\|x\\|_{2} \\le t$, observe that $x$ is extracted from $y$ by the linear map $G_{1} = [I_{n} \\ \\ 0_{n \\times 1}]$, so that\n$$\nG_{1} y = [I_{n} \\ \\ 0_{n \\times 1}] \\begin{pmatrix} x \\\\ t \\end{pmatrix} = x.\n$$\nThe right-hand side is $k_{1}^{T} y = t$, which is obtained by choosing\n$$\nk_{1} = \\begin{pmatrix} 0_{n} \\\\ 1 \\end{pmatrix}.\n$$\nThe linear equality constraint $Ax = b$ is expressed as\n$$\nF y = [A \\ \\ 0_{m \\times 1}] \\begin{pmatrix} x \\\\ t \\end{pmatrix} = Ax + 0 \\cdot t = b,\n$$\nso\n$$\nF = [A \\ \\ 0_{m \\times 1}], \\quad g = b.\n$$\nDimensions are consistent: $f \\in \\mathbb{R}^{n+1}$, $G_{1} \\in \\mathbb{R}^{n \\times (n+1)}$, $k_{1} \\in \\mathbb{R}^{n+1}$, and $F \\in \\mathbb{R}^{m \\times (n+1)}$.\n\nComparing with the options:\n- A matches exactly the derived $f$, $G_{1}$, $k_{1}$, and $F$.\n- B would enforce $\\|[x; t]\\|_{2} \\le t$, which implies $x = 0$ and is not equivalent.\n- C uses $G_{1} = [A \\ \\ 0]$ and $F = [I_{n} \\ \\ 0]$, which does not encode $Ax = b$ correctly and has dimension issues unless $n = m$, and even then would force $x = b$.\n- D sets $k_{1}^{T} y = e_{1}^{T} x$, yielding $\\|x\\|_{2} \\le e_{1}^{T} x$, which is not the desired constraint.\n\nTherefore, the correct choice is A.", "answer": "$$\\boxed{A}$$", "id": "2200440"}, {"introduction": "Moving from abstract formulation to a tangible application, this exercise challenges you to solve a geometric problem common in fields like robotics and computer-aided design. You will determine the largest possible sphere that can be inscribed within a polyhedron, a problem known as finding the Chebyshev center. This practice demonstrates how to translate spatial constraints into a set of linear inequalities, showcasing the power of convex optimization to solve practical, real-world problems [@problem_id:2200474].", "problem": "A robotics company is designing a safety protocol for a spherical autonomous probe that operates within a confined industrial space. The engineers want to find the optimal fixed position for the center of the probe and the corresponding maximum possible radius such that the entire spherical probe remains within the designated flight zone.\n\nThe flight zone is a region in $\\mathbb{R}^3$ described by the coordinates $(x, y, z)$, and all measurements are in meters. The zone is mathematically defined by the intersection of the regions satisfying the following seven linear inequalities:\n1.  $x \\le 10.0$\n2.  $-x \\le -4.0$\n3.  $y \\le 10.0$\n4.  $-y \\le -4.0$\n5.  $z \\le 10.0$\n6.  $-z \\le -4.0$\n7.  $x + y + z \\le 26.0$\n\nYour task is to calculate this maximum radius. Express your final answer in meters, rounded to four significant figures.", "solution": "Let the center of the spherical probe be denoted by the vector $x_c = (x_c, y_c, z_c)^T$ and its radius be $r$. The probe is the set of points $\\{x \\mid \\|x - x_c\\|_2 \\le r\\}$. The flight zone is a polyhedron defined by a set of linear inequalities of the form $a_i^T x \\le b_i$. For the entire probe to be inside this polyhedron, every point in the sphere must satisfy all the inequalities.\n\nFor a single inequality $a_i^T x \\le b_i$, we require that for all points $u$ with $\\|u\\|_2 \\le r$, the point $x = x_c + u$ satisfies the inequality.\n$$a_i^T (x_c + u) \\le b_i$$\n$$a_i^T x_c + a_i^T u \\le b_i$$\nTo ensure this holds for all valid $u$, we must consider the worst-case scenario, which occurs when $a_i^T u$ is maximized. The maximum value of $a_i^T u$ over the ball $\\|u\\|_2 \\le r$ is $r \\|a_i\\|_2$, which is achieved when $u$ is aligned with $a_i$. Thus, the condition for the sphere to be contained by the half-space is:\n$$a_i^T x_c + r \\|a_i\\|_2 \\le b_i$$\nThis condition must hold for all seven inequalities defining the polyhedron. The problem is to find the maximum possible radius $r$. This can be formulated as a convex optimization problem, specifically a linear program, where we maximize $r$ subject to a set of linear constraints on $x_c, y_c, z_c,$ and $r$.\n\nThe optimization problem is:\n$$ \\text{maximize} \\quad r $$\n$$ \\text{subject to} \\quad a_i^T x_c + r \\|a_i\\|_2 \\le b_i, \\quad \\text{for } i=1, \\dots, 7 $$\n$$ r \\ge 0 $$\n\nLet's write down the specific constraints for the given problem. The vectors $a_i$ and scalars $b_i$ are:\n1. $a_1 = (1, 0, 0)^T, b_1 = 10.0, \\|a_1\\|_2 = 1 \\implies x_c + r \\le 10.0$\n2. $a_2 = (-1, 0, 0)^T, b_2 = -4.0, \\|a_2\\|_2 = 1 \\implies -x_c + r \\le -4.0 \\implies x_c \\ge 4.0 + r$\n3. $a_3 = (0, 1, 0)^T, b_3 = 10.0, \\|a_3\\|_2 = 1 \\implies y_c + r \\le 10.0$\n4. $a_4 = (0, -1, 0)^T, b_4 = -4.0, \\|a_4\\|_2 = 1 \\implies -y_c + r \\le -4.0 \\implies y_c \\ge 4.0 + r$\n5. $a_5 = (0, 0, 1)^T, b_5 = 10.0, \\|a_5\\|_2 = 1 \\implies z_c + r \\le 10.0$\n6. $a_6 = (0, 0, -1)^T, b_6 = -4.0, \\|a_6\\|_2 = 1 \\implies -z_c + r \\le -4.0 \\implies z_c \\ge 4.0 + r$\n7. $a_7 = (1, 1, 1)^T, b_7 = 26.0, \\|a_7\\|_2 = \\sqrt{1^2+1^2+1^2} = \\sqrt{3} \\implies x_c + y_c + z_c + r\\sqrt{3} \\le 26.0$\n\nThe feasible region (the polyhedron) is symmetric with respect to permutations of the coordinates $x, y, z$. The objective function (maximizing $r$) is also independent of this permutation. Therefore, we can assume that the optimal center $x_c$ lies on the line of symmetry $x_c = y_c = z_c$. Let's denote this common coordinate value by $u$.\n\nSubstituting $x_c=y_c=z_c=u$ into the constraints simplifies the problem:\n1. $u + r \\le 10.0 \\implies u \\le 10.0 - r$\n2. $u \\ge 4.0 + r$\n3. $u + r \\le 10.0$ (same as 1)\n4. $u \\ge 4.0 + r$ (same as 2)\n5. $u + r \\le 10.0$ (same as 1)\n6. $u \\ge 4.0 + r$ (same as 2)\n7. $3u + r\\sqrt{3} \\le 26.0 \\implies u \\le \\frac{26.0 - r\\sqrt{3}}{3}$\n\nFor a feasible solution $(u, r)$ to exist, the lower bound for $u$ must be less than or equal to the upper bounds for $u$. This gives us two conditions:\na) $4.0 + r \\le 10.0 - r \\implies 2r \\le 6.0 \\implies r \\le 3.0$\nb) $4.0 + r \\le \\frac{26.0 - r\\sqrt{3}}{3} \\implies 12.0 + 3r \\le 26.0 - r\\sqrt{3} \\implies r(3+\\sqrt{3}) \\le 14.0 \\implies r \\le \\frac{14.0}{3+\\sqrt{3}}$\n\nTo find the maximum possible $r$, we must satisfy both conditions. Thus, $r_{max}$ is the minimum of the two upper bounds we found for $r$:\n$$r_{max} = \\min\\left(3.0, \\frac{14.0}{3+\\sqrt{3}}\\right)$$\nLet's evaluate the second term:\n$$ \\frac{14.0}{3+\\sqrt{3}} = \\frac{14.0(3-\\sqrt{3})}{(3+\\sqrt{3})(3-\\sqrt{3})} = \\frac{14.0(3-\\sqrt{3})}{9-3} = \\frac{14.0(3-\\sqrt{3})}{6} = \\frac{7(3-\\sqrt{3})}{3} $$\nNow we compare this value with 3.0.\n$$ \\frac{7(3-\\sqrt{3})}{3} \\approx \\frac{7(3 - 1.73205)}{3} = \\frac{7(1.26795)}{3} \\approx \\frac{8.87565}{3} \\approx 2.95855 $$\nSince $2.95855 < 3.0$, the second inequality is the tighter constraint. The maximum radius is therefore determined by the skewed plane and the lower boundaries of the cube.\n$$ r_{max} = \\frac{7(3-\\sqrt{3})}{3} \\approx 2.95855 \\text{ meters} $$\nThe problem asks for the answer rounded to four significant figures.\n$$ r_{max} \\approx 2.959 \\text{ meters} $$", "answer": "$$\\boxed{2.959}$$", "id": "2200474"}, {"introduction": "This final exercise delves deeper into the theoretical underpinnings of SOCP by exploring the concept of duality. You will calculate the Euclidean distance from a point to an affine subspace, a classic projection problem, by formulating and solving not only the primal SOCP but also its Lagrange dual. This process illuminates the elegant relationship between the primal and dual problems and highlights the important property of self-duality in second-order cones [@problem_id:3175231].", "problem": "You are given a point $y \\in \\mathbb{R}^{3}$ and an affine subspace defined by linear equations $Gx = h$, where $G \\in \\mathbb{R}^{2 \\times 3}$ and $h \\in \\mathbb{R}^{2}$. Consider\n$$\ny = \\begin{pmatrix} 2 \\\\ 0 \\\\ 0 \\end{pmatrix}, \\quad\nG = \\begin{pmatrix} 1 & 1 & 0 \\\\ 0 & 1 & 1 \\end{pmatrix}, \\quad\nh = \\begin{pmatrix} 1 \\\\ 2 \\end{pmatrix}.\n$$\nYour task is to compute the Euclidean distance from $y$ to the affine subspace $\\{x \\in \\mathbb{R}^{3} : Gx = h\\}$ using second-order cone programming (SOCP). Proceed as follows, starting from first principles of convex optimization and conic duality.\n\n- Formulate the problem of minimizing the Euclidean norm $\\|x - y\\|_{2}$ subject to $Gx = h$ as a second-order cone program by introducing appropriate auxiliary variables so that all nonlinear constraints are represented as membership in a second-order cone.\n- Derive the Lagrange dual problem from your SOCP formulation. Explicitly identify the dual cone that appears, and explain how the geometry of the dual cone is used in the derivation. State how the self-duality of the standard second-order cone manifests in this context.\n- Use your dual or primal characterization to compute the exact minimal distance from $y$ to the affine subspace. Express your final answer as a single simplified exact expression. Do not provide intermediate quantities in the final answer.\n\nNo numerical rounding is required; give the exact value. The final answer must be a single real number or a single closed-form analytic expression (without units).", "solution": "The problem is to find the Euclidean distance from a point $y \\in \\mathbb{R}^{3}$ to the affine subspace defined by $\\{x \\in \\mathbb{R}^{3} : Gx = h\\}$. This is equivalent to solving the following optimization problem:\n$$\n\\min_{x \\in \\mathbb{R}^{3}} \\|x - y\\|_{2} \\quad \\text{subject to} \\quad Gx = h\n$$\nThe given data are:\n$$\ny = \\begin{pmatrix} 2 \\\\ 0 \\\\ 0 \\end{pmatrix}, \\quad G = \\begin{pmatrix} 1 & 1 & 0 \\\\ 0 & 1 & 1 \\end{pmatrix}, \\quad h = \\begin{pmatrix} 1 \\\\ 2 \\end{pmatrix}\n$$\n\n**1. Formulation as a Second-Order Cone Program (SOCP)**\n\nTo formulate this problem as an SOCP, we introduce an auxiliary scalar variable $t \\in \\mathbb{R}$. The objective is to minimize $t$ subject to the constraint that $t$ is an upper bound on the Euclidean norm $\\|x - y\\|_{2}$. This leads to the following equivalent problem:\n$$\n\\begin{array}{ll}\n\\text{minimize} & t \\\\\n\\text{subject to} & \\|x - y\\|_{2} \\le t \\\\\n& Gx = h\n\\end{array}\n$$\nwhere the optimization variables are $x \\in \\mathbb{R}^3$ and $t \\in \\mathbb{R}$. The constraint $\\|x - y\\|_{2} \\le t$ is a second-order cone constraint. The standard second-order cone (or Lorentz cone) in $\\mathbb{R}^{n+1}$ is defined as $K_{n+1} = \\{ (u, \\tau) \\in \\mathbb{R}^n \\times \\mathbb{R} \\mid \\|u\\|_2 \\le \\tau \\}$. In our case, with $u = x-y \\in \\mathbb{R}^3$ and $\\tau = t$, the constraint is equivalent to requiring that the vector $(x-y, t)$ belongs to the second-order cone $K_4$ in $\\mathbb{R}^4$.\n\nThe problem can be written in the standard form of a conic program:\n$$\n\\begin{array}{ll}\n\\text{minimize} & c^T z \\\\\n\\text{subject to} & Az = b \\\\\n& z \\in \\mathcal{K}\n\\end{array}\n$$\nTo do so, we introduce a substitution $u = x-y$, so $x = u+y$. The problem becomes:\n$$\n\\begin{array}{ll}\n\\text{minimize} & t \\\\\n\\text{subject to} & \\|u\\|_{2} \\le t \\\\\n& G(u+y) = h\n\\end{array}\n$$\nThe variables are now $u \\in \\mathbb{R}^3$ and $t \\in \\mathbb{R}$. The affine constraint is $Gu = h - Gy$. The conic constraint is $(u, t) \\in K_4$. This is the primal SOCP formulation.\n\n**2. Derivation of the Lagrange Dual Problem**\n\nLet us construct the Lagrangian for the primal problem. We associate a Lagrange multiplier vector $\\nu \\in \\mathbb{R}^2$ with the equality constraint $Gu = h - Gy$. The Lagrangian is:\n$$\nL(u, t, \\nu) = t - \\nu^T (Gu - (h - Gy))\n$$\nRearranging the terms, we get:\n$$\nL(u, t, \\nu) = t - \\nu^T G u + \\nu^T (h - Gy) = (-G^T \\nu)^T u + t + (h - Gy)^T \\nu\n$$\nThe Lagrange dual function $g(\\nu)$ is the infimum of the Lagrangian over the primal variables $(u,t)$ within their conic domain:\n$$\ng(\\nu) = \\inf_{(u, t) \\in K_4} L(u, t, \\nu) = (h - Gy)^T \\nu + \\inf_{(u,t) \\in K_4} \\left[ (-G^T \\nu)^T u + t \\right]\n$$\nThe infimum term can be written as an inner product. Let $s = (-G^T\\nu, 1)$. The infimum is $\\inf_{z \\in K_4} s^T z$ where $z=(u,t)$. The dual cone $K^*$ of a cone $K$ is defined as $K^* = \\{s \\mid s^T z \\ge 0 \\text{ for all } z \\in K\\}$. By definition of the dual cone, the infimum $\\inf_{z \\in K} s^T z$ is equal to $0$ if $s \\in K^*$, and $-\\infty$ otherwise. For the dual function $g(\\nu)$ to be bounded, we must have $s \\in K_4^*$.\n\nA fundamental property of the second-order cone is that it is self-dual, meaning $K_n^* = K_n$ for any $n$. This self-duality is a cornerstone of SOCP theory and its applications. Here, it implies that the dual feasibility condition $s \\in K_4^*$ becomes $s \\in K_4$.\nThe vector $s$ is given by $s = (-G^T \\nu, 1)$. The condition $s \\in K_4$ means that the norm of the vector part must be less than or equal to the scalar part:\n$$\n\\|-G^T \\nu\\|_{2} \\le 1 \\implies \\|G^T \\nu\\|_{2} \\le 1\n$$\nWhen this condition holds, the infimum is $0$, and the dual function becomes $g(\\nu) = (h - Gy)^T \\nu$. The dual problem is to maximize this function subject to the feasibility condition:\n$$\n\\begin{array}{ll}\n\\text{maximize} & (h - Gy)^T \\nu \\\\\n\\text{subject to} & \\|G^T \\nu\\|_{2} \\le 1\n\\end{array}\n$$\nwhere $\\nu \\in \\mathbb{R}^2$ is the dual variable.\n\n**3. Computation of the Minimal Distance**\n\nWe now solve the dual problem. First, we compute the necessary quantities:\n$$\nGy = \\begin{pmatrix} 1 & 1 & 0 \\\\ 0 & 1 & 1 \\end{pmatrix} \\begin{pmatrix} 2 \\\\ 0 \\\\ 0 \\end{pmatrix} = \\begin{pmatrix} 2 \\\\ 0 \\end{pmatrix}\n$$\n$$\nh - Gy = \\begin{pmatrix} 1 \\\\ 2 \\end{pmatrix} - \\begin{pmatrix} 2 \\\\ 0 \\end{pmatrix} = \\begin{pmatrix} -1 \\\\ 2 \\end{pmatrix}\n$$\nThe dual objective is to maximize $(h-Gy)^T \\nu = -\\nu_1 + 2\\nu_2$.\nThe constraint is $\\|G^T \\nu\\|_{2}^2 \\le 1$. Let's analyze the term $G^T\\nu$:\n$$\nG^T \\nu = \\begin{pmatrix} 1 & 0 \\\\ 1 & 1 \\\\ 0 & 1 \\end{pmatrix} \\begin{pmatrix} \\nu_1 \\\\ \\nu_2 \\end{pmatrix} = \\begin{pmatrix} \\nu_1 \\\\ \\nu_1 + \\nu_2 \\\\ \\nu_2 \\end{pmatrix}\n$$\nThe constraint becomes:\n$$\n\\|G^T \\nu\\|_{2}^2 = \\nu_1^2 + (\\nu_1 + \\nu_2)^2 + \\nu_2^2 = 2\\nu_1^2 + 2\\nu_1\\nu_2 + 2\\nu_2^2 \\le 1\n$$\nThis can be written in quadratic form as $\\nu^T (GG^T) \\nu \\le 1$, where:\n$$\nGG^T = \\begin{pmatrix} 1 & 1 & 0 \\\\ 0 & 1 & 1 \\end{pmatrix} \\begin{pmatrix} 1 & 0 \\\\ 1 & 1 \\\\ 0 & 1 \\end{pmatrix} = \\begin{pmatrix} 2 & 1 \\\\ 1 & 2 \\end{pmatrix}\n$$\nSo, the dual problem is:\n$$\n\\begin{array}{ll}\n\\text{maximize} & \\begin{pmatrix} -1 & 2 \\end{pmatrix} \\nu \\\\\n\\text{subject to} & \\nu^T \\begin{pmatrix} 2 & 1 \\\\ 1 & 2 \\end{pmatrix} \\nu \\le 1\n\\end{array}\n$$\nThis is the maximization of a linear function over an elliptical region. The maximum value will be attained on the boundary of the feasible set, where $\\nu^T (GG^T) \\nu = 1$.\nLet $v = h - Gy = (-1, 2)^T$ and $H = GG^T$. The dual is $\\max_{\\nu} v^T\\nu$ s.t. $\\nu^T H \\nu \\le 1$. The optimal value is given by $\\sqrt{v^T H^{-1} v}$. We compute the inverse of $H$:\n$$\nH^{-1} = (GG^T)^{-1} = \\left(\\begin{pmatrix} 2 & 1 \\\\ 1 & 2 \\end{pmatrix}\\right)^{-1} = \\frac{1}{2 \\cdot 2 - 1 \\cdot 1} \\begin{pmatrix} 2 & -1 \\\\ -1 & 2 \\end{pmatrix} = \\frac{1}{3} \\begin{pmatrix} 2 & -1 \\\\ -1 & 2 \\end{pmatrix}\n$$\nNow we compute the quadratic form $v^T H^{-1} v$:\n$$\nv^T H^{-1} v = \\begin{pmatrix} -1 & 2 \\end{pmatrix} \\left( \\frac{1}{3} \\begin{pmatrix} 2 & -1 \\\\ -1 & 2 \\end{pmatrix} \\right) \\begin{pmatrix} -1 \\\\ 2 \\end{pmatrix}\n$$\n$$\nv^T H^{-1} v = \\frac{1}{3} \\begin{pmatrix} -1 & 2 \\end{pmatrix} \\begin{pmatrix} 2(-1) - 1(2) \\\\ -1(-1) + 2(2) \\end{pmatrix} = \\frac{1}{3} \\begin{pmatrix} -1 & 2 \\end{pmatrix} \\begin{pmatrix} -4 \\\\ 5 \\end{pmatrix}\n$$\n$$\nv^T H^{-1} v = \\frac{1}{3} ((-1)(-4) + (2)(5)) = \\frac{1}{3} (4 + 10) = \\frac{14}{3}\n$$\nThe optimal value of the dual problem is $\\sqrt{v^T H^{-1} v} = \\sqrt{\\frac{14}{3}}$.\n\nFor this SOCP, strong duality holds (e.g., Slater's condition is satisfied as the primal problem is strictly feasible). Therefore, the optimal value of the primal problem (the minimal distance) is equal to the optimal value of the dual problem.\nThe minimal distance is $\\sqrt{\\frac{14}{3}}$.", "answer": "$$\n\\boxed{\\sqrt{\\frac{14}{3}}}\n$$", "id": "3175231"}]}