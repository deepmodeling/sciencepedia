{"hands_on_practices": [{"introduction": "The power of the Homogeneous Self-dual (HSD) embedding lies in its ability to recast a complex primal-dual optimization problem into a single, structured feasibility problem. At the core of this transformation is a specific skew-symmetric matrix that elegantly encodes all the Karush-Kuhn-Tucker (KKT) conditions. This first practice [@problem_id:3137126] is a foundational exercise to construct this matrix from scratch for a simple linear program, helping you internalize its block structure and verify its essential skew-symmetric property.", "problem": "Consider the linear program in standard primal-dual form with two decision variables and two equality constraints. The primal problem is to minimize $c^{\\top} x$ subject to $A x = b$ and $x \\ge 0$, and the dual problem is to maximize $b^{\\top} y$ subject to $A^{\\top} y + s = c$ and $s \\ge 0$. Let $A \\in \\mathbb{R}^{2 \\times 2}$, $b \\in \\mathbb{R}^{2}$, and $c \\in \\mathbb{R}^{2}$ be given by\n$$\nA = \\begin{pmatrix} 1  -1 \\\\ 2  3 \\end{pmatrix}, \\quad b = \\begin{pmatrix} 1 \\\\ 4 \\end{pmatrix}, \\quad c = \\begin{pmatrix} 2 \\\\ 5 \\end{pmatrix}.\n$$\nUsing the canonical Homogeneous Self-dual (HSD) embedding for linear programming, form the embedded skew-symmetric matrix $Q \\in \\mathbb{R}^{(n+m+1) \\times (n+m+1)}$ that acts on the stacked vector of augmented variables $(x, y, \\tau)$ and encodes the primal-dual system into a single linear relation. Then, verify directly by computation that $Q$ is skew-symmetric. Finally, let $S$ denote the sum of the squares of all entries of $Q$ (equivalently, the squared Frobenius norm of $Q$). Report the value of $S$ as your final answer. The final answer must be a single real number. Do not round.", "solution": "The user wants me to solve a problem on the Homogeneous Self-Dual (HSD) embedding for linear programming.\n\n### Problem Validation\n\n**Step 1: Extract Givens**\n\n- Primal Linear Program (LP): minimize $c^{\\top} x$ subject to $A x = b$ and $x \\ge 0$.\n- Dual Linear Program (LP): maximize $b^{\\top} y$ subject to $A^{\\top} y + s = c$ and $s \\ge 0$.\n- Matrix $A = \\begin{pmatrix} 1  -1 \\\\ 2  3 \\end{pmatrix} \\in \\mathbb{R}^{2 \\times 2}$.\n- Vector $b = \\begin{pmatrix} 1 \\\\ 4 \\end{pmatrix} \\in \\mathbb{R}^{2}$.\n- Vector $c = \\begin{pmatrix} 2 \\\\ 5 \\end{pmatrix} \\in \\mathbb{R}^{2}$.\n- The number of primal variables is $n=2$, and the number of equality constraints is $m=2$.\n- The task is to form the canonical Homogeneous Self-Dual (HSD) embedding, which results in a skew-symmetric matrix $Q \\in \\mathbb{R}^{(n+m+1) \\times (n+m+1)}$.\n- The augmented variable vector is $(x, y, \\tau)$.\n- A direct computational verification that $Q$ is skew-symmetric is required.\n- The final task is to compute $S$, the sum of the squares of all entries of $Q$.\n\n**Step 2: Validate Using Extracted Givens**\n\n- **Scientifically Grounded:** The problem is based on the Homogeneous Self-Dual embedding, a standard and fundamental technique in the theory of interior-point methods for linear programming. It is scientifically and mathematically sound.\n- **Well-Posed:** The problem is well-posed. All the necessary data ($A$, $b$, $c$) are provided with compatible dimensions. The procedure for constructing the HSD embedding is canonical, leading to a unique matrix $Q$. The subsequently requested calculation of $S$ is unambiguous.\n- **Objective:** The problem is stated using precise mathematical language and is free from any subjective or ambiguous terminology.\n- **Conclusion:** The problem does not exhibit any of the invalidity flaws. It is self-contained, consistent, and formalizable.\n\n**Step 3: Verdict and Action**\n\nThe problem is **valid**. A full solution will be provided.\n\n### Solution\n\nThe canonical Homogeneous Self-Dual (HSD) embedding for a standard primal-dual linear programming pair seeks a non-trivial solution to a homogeneous system that encapsulates the Karush-Kuhn-Tucker (KKT) optimality conditions. The primal-dual pair is given as:\n(P) minimize $c^{\\top} x$ subject to $A x = b, x \\ge 0$.\n(D) maximize $b^{\\top} y$ subject to $A^{\\top} y + s = c, s \\ge 0$.\n\nThe KKT conditions for optimality are:\n$1.$ Primal feasibility: $A x = b, x \\ge 0$.\n$2.$ Dual feasibility: $A^{\\top} y + s = c, s \\ge 0$.\n$3.$ Complementarity: $x^{\\top} s = 0$.\n\nThe HSD formulation introduces a homogenizing variable $\\tau \\ge 0$ and a gap variable $\\kappa \\ge 0$. The KKT conditions are transformed into a homogeneous system:\n$A x - b \\tau = 0$\n$A^{\\top} y + s - c \\tau = 0$\n$c^{\\top} x - b^{\\top} y - \\kappa = 0$\nwith non-negativity constraints $x \\ge 0, s \\ge 0, \\tau \\ge 0, \\kappa \\ge 0$.\n\nThis system can be expressed as a single linear relation involving a skew-symmetric matrix. We define a vector of variables $z = (x, y, \\tau)$ and a vector of slack variables $w = (s, 0_m, \\kappa)$, where $0_m$ is a zero vector of size $m$. The system is formulated as $Qz + w = 0$, which is equivalent to $w = -Qz$. The canonical skew-symmetric matrix $Q$ that achieves this is:\n$$\nQ = \\begin{pmatrix}\n0_{n \\times n}  A^{\\top}  -c \\\\\n-A  0_{m \\times m}  b \\\\\nc^{\\top}  -b^{\\top}  0\n\\end{pmatrix}\n$$\nLet's verify this. From $w = -Qz$, we have:\n$$\n\\begin{pmatrix} s \\\\ 0_m \\\\ \\kappa \\end{pmatrix} = -\\begin{pmatrix}\n0_{n \\times n}  A^{\\top}  -c \\\\\n-A  0_{m \\times m}  b \\\\\nc^{\\top}  -b^{\\top}  0\n\\end{pmatrix} \\begin{pmatrix} x \\\\ y \\\\ \\tau \\end{pmatrix} = \\begin{pmatrix}\n0_{n \\times n}  -A^{\\top}  c \\\\\nA  0_{m \\times m}  -b \\\\\n-c^{\\top}  b^{\\top}  0\n\\end{pmatrix} \\begin{pmatrix} x \\\\ y \\\\ \\tau \\end{pmatrix}\n$$\nExpanding this gives:\n$s = -A^{\\top} y + c \\tau \\implies A^{\\top} y + s - c \\tau = 0$\n$0_m = A x - b \\tau \\implies A x - b \\tau = 0$\n$\\kappa = -c^{\\top} x + b^{\\top} y \\implies c^{\\top} x - b^{\\top} y + \\kappa = 0$\n\nThis system differs from the one derived earlier. Let's reconsider the definition of $w$ or $Q$. A more standard formulation defines the relationship as $w = Qz$, leading to:\n$$\n\\begin{pmatrix} s \\\\ 0_m \\\\ \\kappa \\end{pmatrix} = \\begin{pmatrix} 0_{n \\times n}  -A^T  c \\\\ A  0_{m \\times m}  -b \\\\ -c^T  b^T  0 \\end{pmatrix} \\begin{pmatrix} x \\\\ y \\\\ \\tau \\end{pmatrix}\n$$\nThis gives:\n$s = -A^Ty + c\\tau \\implies A^Ty + s = c\\tau$\n$0_m = Ax - b\\tau \\implies Ax = b\\tau$\n$\\kappa = -c^Tx + b^Ty \\implies c^Tx - b^Ty + \\kappa = 0$\nThis system correctly represents the homogenized KKT conditions. The matrix in this formulation, let's call it $Q_{HSD}$, is:\n$$\nQ_{HSD} = \\begin{pmatrix} 0  -A^T  c \\\\ A  0  -b \\\\ -c^T  b^T  0 \\end{pmatrix}\n$$\nLet's verify the skew-symmetry of $Q_{HSD}$:\n$$\n(Q_{HSD})^T = \\begin{pmatrix} 0^T  A^T  (-c^T)^T \\\\ (-A^T)^T  0^T  (b^T)^T \\\\ c^T  (-b)^T  0^T \\end{pmatrix} = \\begin{pmatrix} 0  A^T  -c \\\\ -A  0  b \\\\ c^T  -b^T  0 \\end{pmatrix}\n$$\n$$\n-Q_{HSD} = -\\begin{pmatrix} 0  -A^T  c \\\\ A  0  -b \\\\ -c^T  b^T  0 \\end{pmatrix} = \\begin{pmatrix} 0  A^T  -c \\\\ -A  0  b \\\\ c^T  -b^T  0 \\end{pmatrix}\n$$\nThus, $(Q_{HSD})^T = -Q_{HSD}$, and this is the correct skew-symmetric matrix $Q$ required by the problem.\n\nNow, we construct $Q$ using the given data:\n$n=2$, $m=2$.\n$A = \\begin{pmatrix} 1  -1 \\\\ 2  3 \\end{pmatrix}$, $b = \\begin{pmatrix} 1 \\\\ 4 \\end{pmatrix}$, $c = \\begin{pmatrix} 2 \\\\ 5 \\end{pmatrix}$.\nThe required sub-matrices are:\n$A = \\begin{pmatrix} 1  -1 \\\\ 2  3 \\end{pmatrix}$, $-A^T = \\begin{pmatrix} -1  -2 \\\\ 1  -3 \\end{pmatrix}$, $c = \\begin{pmatrix} 2 \\\\ 5 \\end{pmatrix}$, $-b = \\begin{pmatrix} -1 \\\\ -4 \\end{pmatrix}$, $-c^T = \\begin{pmatrix} -2  -5 \\end{pmatrix}$, $b^T = \\begin{pmatrix} 1  4 \\end{pmatrix}$.\n\nSubstituting these into the block structure for $Q$, which has dimensions $(2+2+1) \\times (2+2+1) = 5 \\times 5$:\n$$\nQ = \\begin{pmatrix}\n0  0  -1  -2  2 \\\\\n0  0  1  -3  5 \\\\\n1  -1  0  0  -1 \\\\\n2  3  0  0  -4 \\\\\n-2  -5  1  4  0\n\\end{pmatrix}\n$$\nTo verify skew-symmetry by computation, we can explicitly write its transpose:\n$$\nQ^T = \\begin{pmatrix}\n0  0  1  2  -2 \\\\\n0  0  -1  3  -5 \\\\\n-1  1  0  0  1 \\\\\n-2  -3  0  0  4 \\\\\n2  5  -1  -4  0\n\\end{pmatrix}\n$$\nBy comparing each element, we see that $Q_{ij} = -Q_{ji}$ for all $i,j$. For example, $Q_{31} = 1$ and $Q_{13}=-1$, so $Q_{31} = -Q_{13}$. Also, $Q_{42}=3$ and $Q_{24}=-3$, so $Q_{42} = -Q_{24}$. The diagonal elements are all $0$. Hence, $Q$ is skew-symmetric.\n\nThe final step is to calculate $S$, the sum of the squares of all entries of $Q$, which is the squared Frobenius norm, $S = \\|Q\\|_F^2$.\n$$ S = \\sum_{i=1}^5 \\sum_{j=1}^5 Q_{ij}^2 $$\nWe can compute this from the block matrix definition of $Q$. The squared Frobenius norm of a block matrix is the sum of the squared Frobenius norms of its blocks.\n$$ S = \\|Q\\|_F^2 = \\|0_{n \\times n}\\|_F^2 + \\|-A^T\\|_F^2 + \\|c\\|_2^2 + \\|A\\|_F^2 + \\|0_{m \\times m}\\|_F^2 + \\|-b\\|_2^2 + \\|-c^T\\|_2^2 + \\|b^T\\|_2^2 + \\|0\\|_F^2 $$\nUsing the properties $\\|M\\|_F = \\|-M\\|_F = \\|M^T\\|_F$ and $\\|v\\|_2 = \\|v^T\\|_2$ for a vector $v$:\n$$ S = \\|A^T\\|_F^2 + \\|c\\|_2^2 + \\|A\\|_F^2 + \\|b\\|_2^2 + \\|c^T\\|_2^2 + \\|b^T\\|_2^2 $$\n$$ S = \\|A\\|_F^2 + \\|c\\|_2^2 + \\|A\\|_F^2 + \\|b\\|_2^2 + \\|c\\|_2^2 + \\|b\\|_2^2 $$\n$$ S = 2\\|A\\|_F^2 + 2\\|b\\|_2^2 + 2\\|c\\|_2^2 $$\nNow we calculate the individual squared norms:\n$\\|A\\|_F^2 = 1^2 + (-1)^2 + 2^2 + 3^2 = 1 + 1 + 4 + 9 = 15$.\n$\\|b\\|_2^2 = 1^2 + 4^2 = 1 + 16 = 17$.\n$\\|c\\|_2^2 = 2^2 + 5^2 = 4 + 25 = 29$.\n\nSubstituting these values into the expression for $S$:\n$$ S = 2(15) + 2(17) + 2(29) = 30 + 34 + 58 = 122 $$\nAs a check, we can sum the squares of the elements of the numerical matrix $Q$:\nRow 1: $(-1)^2 + (-2)^2 + 2^2 = 1+4+4 = 9$.\nRow 2: $1^2 + (-3)^2 + 5^2 = 1+9+25 = 35$.\nRow 3: $1^2 + (-1)^2 + (-1)^2 = 1+1+1 = 3$.\nRow 4: $2^2 + 3^2 + (-4)^2 = 4+9+16 = 29$.\nRow 5: $(-2)^2 + (-5)^2 + 1^2 + 4^2 = 4+25+1+16 = 46$.\nTotal sum: $S = 9 + 35 + 3 + 29 + 46 = 122$.\nBoth methods yield the same result.", "answer": "$$\\boxed{122}$$", "id": "3137126"}, {"introduction": "Once we have established the HSD framework, how do we actually use it to find the solution to a well-posed linear program? The \"happy path\" occurs when a solution with a positive homogenizing variable, $\\tau \\gt 0$, can be found, in which case the embedding's solution directly yields the optimal primal and dual variables of the original problem after simple scaling. This exercise [@problem_id:3137129] guides you through this canonical process of finding an HSD solution for an optimal problem and recovering the final answer, illustrating the embedding's primary function.", "problem": "Consider the Linear Programming (LP) problem in conic form with decision vector $x \\in \\mathbb{R}^{2}$, constraint matrix $A \\in \\mathbb{R}^{1 \\times 2}$, and data $b \\in \\mathbb{R}$ and $c \\in \\mathbb{R}^{2}$:\n$$\n\\text{minimize } c^{\\top} x \\quad \\text{subject to } A x = b, \\; x \\in \\mathbb{R}_{+}^{2}.\n$$\nTake $A = \\begin{pmatrix} 1  1 \\end{pmatrix}$, $b = 1$, and $c = \\begin{pmatrix} 1 \\\\ 2 \\end{pmatrix}$. The dual LP has variable $y \\in \\mathbb{R}$ and slack $s \\in \\mathbb{R}_{+}^{2}$.\n\nStarting from the fundamental Karush-Kuhn-Tucker (KKT) conditions for optimality of the primal-dual pair and the definition of the Homogeneous Self-dual Embedding (HSDE), construct the standard skew-symmetric HSDE operator that encodes the primal-dual equalities and complementarity in a single linear relation. Then, for this specific LP:\n- Identify a vector $u = (x, y, \\tau)$ with $x \\in \\mathbb{R}_{+}^{2}$ and $\\tau  0$ that corresponds to a primal-dual optimal solution with equality residual $r = 0$ and duality gap $\\kappa = 0$.\n- Compute $v = (s, r, \\kappa)$ from the HSDE operator, and verify the conic membership of the relevant components.\n- When $\\tau  0$, recover the primal-dual variables $(x, s, y)$ from $(u, v)$ via the appropriate scaling implied by the HSDE construction, and report $(x_{1}, x_{2}, s_{1}, s_{2}, y)$.\n\nExpress your final answer as the single row vector $(x_{1}, x_{2}, s_{1}, s_{2}, y)$ without units. No rounding is required.", "solution": "The problem is first validated to ensure it is scientifically grounded, well-posed, and complete.\n\n### Step 1: Extract Givens\n- Primal Linear Programming (LP) problem:\n  $$ \\text{minimize } c^{\\top} x \\quad \\text{subject to } A x = b, \\; x \\in \\mathbb{R}_{+}^{2} $$\n- Decision vector: $x \\in \\mathbb{R}^{2}$.\n- Constraint matrix and data: $A \\in \\mathbb{R}^{1 \\times 2}$, $b \\in \\mathbb{R}$, $c \\in \\mathbb{R}^{2}$.\n- Specific values: $A = \\begin{pmatrix} 1  1 \\end{pmatrix}$, $b = 1$, $c = \\begin{pmatrix} 1 \\\\ 2 \\end{pmatrix}$.\n- Dual variables: $y \\in \\mathbb{R}$ (dual variable), $s \\in \\mathbb{R}_{+}^{2}$ (dual slack).\n- The task requires using the Homogeneous Self-Dual Embedding (HSDE) framework.\n- We must identify a vector $u = (x, y, \\tau)$ with $x \\in \\mathbb{R}_{+}^{2}$ and $\\tau  0$ that corresponds to a primal-dual optimal solution where the equality residual $r=0$ and the duality gap $\\kappa=0$.\n- We must compute $v = (s, r, \\kappa)$ and verify conic memberships.\n- We must recover the primal-dual solution $(x_{1}, x_{2}, s_{1}, s_{2}, y)$.\n\n### Step 2: Validate Using Extracted Givens\nThe problem statement is a standard exercise in the field of mathematical optimization, specifically concerning interior-point methods for linear programming.\n- **Scientifically Grounded**: The problem is based on the well-established theory of linear programming, Karush-Kuhn-Tucker (KKT) conditions, and the Homogeneous Self-Dual Embedding method. These are fundamental concepts in optimization. The problem is mathematically and scientifically sound.\n- **Well-Posed**: The specific LP instance is well-posed. The feasible set, defined by $x_1 + x_2 = 1$ in the non-negative quadrant, is a compact set (a line segment). A continuous objective function on a compact set is guaranteed to attain its minimum. Thus, a unique optimal solution exists. The procedure requested is deterministic.\n- **Objective**: The problem is stated using precise, unambiguous mathematical language and notation. All data are provided.\n- **Completeness and Consistency**: The problem provides all necessary data ($A$, $b$, $c$) and definitions to formulate the primal and dual problems and apply the HSDE method. There are no contradictions.\n\n### Step 3: Verdict and Action\nThe problem is valid. A full solution will be provided.\n\n### Solution Derivation\nThe primal LP problem is:\n$$ \\text{minimize } c^{\\top} x = x_1 + 2x_2 $$\n$$ \\text{subject to } A x = x_1 + x_2 = 1, \\quad x = \\begin{pmatrix} x_1 \\\\ x_2 \\end{pmatrix} \\in \\mathbb{R}_{+}^{2} $$\n\nThe corresponding dual LP problem is:\n$$ \\text{maximize } b^{\\top} y = y $$\n$$ \\text{subject to } A^{\\top} y + s = c, \\quad s = \\begin{pmatrix} s_1 \\\\ s_2 \\end{pmatrix} \\in \\mathbb{R}_{+}^{2} $$\nWith the given data, the dual constraint is $\\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix} y + \\begin{pmatrix} s_1 \\\\ s_2 \\end{pmatrix} = \\begin{pmatrix} 1 \\\\ 2 \\end{pmatrix}$, which expands to:\n$$ y + s_1 = 1 $$\n$$ y + s_2 = 2 $$\n\nThe Karush-Kuhn-Tucker (KKT) conditions for optimality are:\n1.  Primal feasibility: $Ax = b$, $x \\in \\mathbb{R}_{+}^{2}$\n2.  Dual feasibility: $A^{\\top}y + s = c$, $s \\in \\mathbb{R}_{+}^{2}$\n3.  Complementary slackness: $x^{\\top}s = 0$\n\nThe Homogeneous Self-Dual Embedding (HSDE) formulates these conditions as a single homogeneous system. We introduce homogenizing variables $\\tau$ and $\\kappa$. The system is defined by a skew-symmetric matrix operator $M$ that maps a vector $u = (x, y, \\tau)$ to a vector $v = (s, r, \\kappa)$. The relationship is $v = M u$, where:\n$$\n\\begin{pmatrix} s \\\\ r \\\\ \\kappa \\end{pmatrix} = \\begin{pmatrix} 0  -A^{\\top}  c \\\\ A  0  -b \\\\ -c^{\\top}  b^{\\top}  0 \\end{pmatrix} \\begin{pmatrix} x \\\\ y \\\\ \\tau \\end{pmatrix}\n$$\nHere, $r = Ax-b\\tau$ is the primal feasibility residual, and $\\kappa = -c^{\\top}x + b^{\\top}y$ represents the duality gap. A solution must satisfy the conic constraints $x \\in \\mathbb{R}_{+}^{2}$, $s \\in \\mathbb{R}_{+}^{2}$, $\\tau \\ge 0$, $\\kappa \\ge 0$, and $r=0$.\n\nSubstituting the given data $A = \\begin{pmatrix} 1  1 \\end{pmatrix}$, $b=1$, $c = \\begin{pmatrix} 1 \\\\ 2 \\end{pmatrix}$:\n$$\nM = \\begin{pmatrix}\n0  0  -1  1 \\\\\n0  0  -1  2 \\\\\n1  1  0  -1 \\\\\n-1  -2  1  0\n\\end{pmatrix}\n$$\nThe variables are partitioned as $x=(x_1, x_2)$, $y=(y)$, $\\tau=(\\tau)$, $s=(s_1, s_2)$, $r=(r)$, $\\kappa=(\\kappa)$. The vector $u \\in \\mathbb{R}^4$ is $(x_1, x_2, y, \\tau)$ and $v \\in \\mathbb{R}^4$ is $(s_1, s_2, r, \\kappa)$.\n\nThe problem specifies finding a solution corresponding to primal-dual optimality, which means we are in the case where $\\tau  0$, the primal residual is $r=0$, and the dual gap is $\\kappa=0$. Setting $r=0$ and $\\kappa=0$ in the HSDE system $v=Mu$ gives:\n1.  $s = -A^{\\top}y + c\\tau \\implies A^{\\top}y + s = c\\tau$\n2.  $0 = Ax - b\\tau \\implies Ax = b\\tau$\n3.  $0 = -c^{\\top}x + b^{\\top}y \\implies c^{\\top}x = b^{\\top}y$\n\nSubstituting the problem data yields the following system of equations:\n(i) $y + s_1 = \\tau$\n(ii) $y + s_2 = 2\\tau$\n(iii) $x_1 + x_2 = \\tau$\n(iv) $x_1 + 2x_2 = y$\n\nWe also require the conic constraints $x_1, x_2, s_1, s_2 \\ge 0$ and the complementarity condition $x^{\\top}s = x_1s_1 + x_2s_2 = 0$. Since all variables are non-negative, this is equivalent to $x_1s_1=0$ and $x_2s_2=0$.\n\nThe system is homogeneous. Since we seek a solution with $\\tau  0$, we can simplify by setting $\\tau=1$ to find a particular solution. Any positive scalar multiple of this solution will also be valid. For $\\tau=1$:\n(i') $y + s_1 = 1$\n(ii') $y + s_2 = 2$\n(iii') $x_1 + x_2 = 1$\n(iv') $y = x_1 + 2x_2$\nAnd conditions: $x_1, x_2, s_1, s_2 \\ge 0$, $x_1s_1=0$, $x_2s_2=0$.\n\nFrom (iii'), $x_2 = 1 - x_1$. Substituting into (iv'):\n$y = x_1 + 2(1 - x_1) = 2 - x_1$.\n\nFrom (i') and (ii'):\n$s_1 = 1 - y = 1 - (2 - x_1) = x_1 - 1$.\n$s_2 = 2 - y = 2 - (2 - x_1) = x_1$.\n\nNow, we apply the non-negativity constraints:\n- $x_1 \\ge 0$.\n- $x_2 = 1 - x_1 \\ge 0 \\implies x_1 \\le 1$.\n- $s_1 = x_1 - 1 \\ge 0 \\implies x_1 \\ge 1$.\n- $s_2 = x_1 \\ge 0$.\n\nCombining $x_1 \\le 1$ and $x_1 \\ge 1$ forces $x_1=1$.\nWith $x_1=1$, we find the other variables:\n- $x_2 = 1 - 1 = 0$.\n- $y = 2 - 1 = 1$.\n- $s_1 = 1 - 1 = 0$.\n- $s_2 = 1$.\n\nThis solution $(x_1, x_2, y, s_1, s_2) = (1, 0, 1, 0, 1)$ satisfies all non-negativity constraints. Let's check complementarity:\n- $x_1s_1 = 1 \\cdot 0 = 0$.\n- $x_2s_2 = 0 \\cdot 1 = 0$.\nThe conditions are satisfied.\n\nThe problem asks for:\n- A vector $u=(x, y, \\tau)$ with $\\tau0$. We found the solution for $\\tau=1$. So, $x = \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix}$, $y=1$, $\\tau=1$.\nThus, $u = (x_1, x_2, y, \\tau) = (1, 0, 1, 1)$.\n\n- The vector $v=(s, r, \\kappa)$ and verification. We specified $r=0, \\kappa=0$. We found $s = \\begin{pmatrix} 0 \\\\ 1 \\end{pmatrix}$.\nThus, $v = (s_1, s_2, r, \\kappa) = (0, 1, 0, 0)$.\nVerification of conic membership:\nThe vector $u$ must belong to the cone $C = \\mathbb{R}^2_+ \\times \\mathbb{R} \\times \\mathbb{R}_+$. Our $x = \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix} \\in \\mathbb{R}^2_+$, $y=1 \\in \\mathbb{R}$, and $\\tau=1 \\in \\mathbb{R}_+$. This is satisfied.\nThe vector $v$ must belong to the dual cone $C^* = \\mathbb{R}^2_+ \\times \\{0\\} \\times \\mathbb{R}_+$. Our $s = \\begin{pmatrix} 0 \\\\ 1 \\end{pmatrix} \\in \\mathbb{R}^2_+$, $r=0$, and $\\kappa=0 \\in \\mathbb{R}_+$. This is also satisfied.\n\n- Recovery of the primal-dual variables $(x, s, y)$.\nFor a solution with $\\tau  0$, the optimal solution to the original LP is given by scaling by $\\tau$:\nPrimal optimal solution: $x_{opt} = x/\\tau = \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix} / 1 = \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix}$. So $x_1=1, x_2=0$.\nDual optimal solution: $y_{opt} = y/\\tau = 1/1 = 1$.\nDual optimal slacks: $s_{opt} = s/\\tau = \\begin{pmatrix} 0 \\\\ 1 \\end{pmatrix} / 1 = \\begin{pmatrix} 0 \\\\ 1 \\end{pmatrix}$. So $s_1=0, s_2=1$.\n\nThe required output is the row vector $(x_{1}, x_{2}, s_{1}, s_{2}, y)$.\nThis corresponds to $(1, 0, 0, 1, 1)$.", "answer": "$$\n\\boxed{\\begin{pmatrix} 1  0  0  1  1 \\end{pmatrix}}\n$$", "id": "3137129"}, {"introduction": "A significant advantage of the HSD embedding is its ability to gracefully handle not just solvable problems, but also those that are infeasible or unbounded. When a problem is infeasible, the HSD method yields a solution where the homogenizing variable $\\tau = 0$ and an infeasibility measure $\\kappa \\gt 0$, and the structure of this \"certificate\" vector reveals the precise source of the infeasibility. In this final practice [@problem_id:3137092], you will explore an instance where both the primal and dual problems are infeasible and see exactly how the HSD framework provides a certificate that distinguishes between these two conditions.", "problem": "Consider the canonical conic primal-dual pair defined as follows. The primal problem is to minimize $c^{\\top}x$ subject to $A x + s = b$ with $s \\in \\mathcal{K}$, and the dual problem is to maximize $-b^{\\top}y$ subject to $A^{\\top}y + c = 0$ with $y \\in \\mathcal{K}^{\\ast}$, where $\\mathcal{K}$ is a closed convex cone and $\\mathcal{K}^{\\ast}$ is its dual cone. For this exercise, take $n=2$ decision variables, $m=2$ equality constraints, the cone $\\mathcal{K} = \\mathbb{R}_{+}^{2}$, and data\n$$\nA = \\begin{pmatrix}\n0  0 \\\\\n0  0\n\\end{pmatrix},\\quad\nb = \\begin{pmatrix}\n-1 \\\\\n1\n\\end{pmatrix},\\quad\nc = \\begin{pmatrix}\n-2 \\\\\n0\n\\end{pmatrix}.\n$$\nTasks:\n1) Using only the definitions of feasibility for the primal and dual problems and the definition of the dual cone $\\mathcal{K}^{\\ast}$, prove that both the primal and the dual problems are infeasible for the given data.\n2) Starting from the conic primal-dual pair above and the fundamental idea of the Homogeneous Self-dual Embedding (HSDE), derive the simplified HSDE equalities for this specific instance. Your derivation must identify the relationships among the variables $x \\in \\mathbb{R}^{2}$, $s \\in \\mathbb{R}^{2}$, $y \\in \\mathbb{R}^{2}$, $\\tau \\in \\mathbb{R}_{+}$, and $\\kappa \\in \\mathbb{R}_{+}$, and must establish from first principles which of these variables must be zero for any certificate returned by the HSDE on this instance.\n3) Explain rigorously how the HSDE certificate vector structure separates a primal infeasibility certificate from a dual infeasibility certificate in this instance, by specifying the conditions on the components $(x, y)$ under which each certificate arises. Then, derive the scalar $\\kappa$ in terms of $c$, $b$, $x$, and $y$ for this instance.\n4) Now instantiate concrete certificate choices consistent with the cone memberships to exhibit each type of infeasibility: take $y = \\begin{pmatrix}1\\\\0\\end{pmatrix}$ and $x = \\begin{pmatrix}1\\\\0\\end{pmatrix}$, with all other certificate components set as required by your HSDE derivation. Compute the corresponding values $\\kappa_{\\text{primal}}$ (using $x=\\mathbf{0}$ and the chosen $y$) and $\\kappa_{\\text{dual}}$ (using $y=\\mathbf{0}$ and the chosen $x$), and then compute the scalar difference $\\kappa_{\\text{dual}} - \\kappa_{\\text{primal}}$. Provide this difference as your final answer. No rounding is required; give the exact value with no units.", "solution": "The analysis of the problem will be presented in four parts, corresponding to the four tasks enumerated in the problem statement.\n\nFirst, we address the feasibility of the primal and dual problems.\nThe primal problem is to find $x \\in \\mathbb{R}^{2}$ such that there exists an $s \\in \\mathcal{K} = \\mathbb{R}_{+}^{2}$ satisfying the constraint $A x + s = b$. Given $A = \\begin{pmatrix} 0  0 \\\\ 0  0 \\end{pmatrix}$, the term $A x$ is the zero vector $\\mathbf{0} \\in \\mathbb{R}^{2}$ for any $x$. The constraint simplifies to $\\mathbf{0} + s = b$, which means $s=b$. For the primal problem to be feasible, $s$ must belong to the cone $\\mathcal{K} = \\mathbb{R}_{+}^{2}$. This requires $b \\in \\mathbb{R}_{+}^{2}$. The given vector $b = \\begin{pmatrix} -1 \\\\ 1 \\end{pmatrix}$ has a negative first component, $b_1 = -1$, so it does not belong to $\\mathbb{R}_{+}^{2}$. Therefore, the primal problem is infeasible.\n\nThe dual problem is to find $y \\in \\mathcal{K}^{\\ast}$ such that $A^{\\top}y + c = 0$. The cone is $\\mathcal{K} = \\mathbb{R}_{+}^{2}$, which is self-dual, so its dual cone is $\\mathcal{K}^{\\ast} = \\mathbb{R}_{+}^{2}$. The condition $y \\in \\mathcal{K}^{\\ast}$ means $y \\ge \\mathbf{0}$. The matrix $A^{\\top}$ is also the zero matrix $\\begin{pmatrix} 0  0 \\\\ 0  0 \\end{pmatrix}$. The dual constraint $A^{\\top}y + c = 0$ thus simplifies to $\\mathbf{0} \\cdot y + c = \\mathbf{0}$, which implies $c = \\mathbf{0}$. However, the given vector is $c = \\begin{pmatrix} -2 \\\\ 0 \\end{pmatrix}$, which is not the zero vector. As the constraint $c = \\mathbf{0}$ cannot be satisfied, no such $y$ exists. Therefore, the dual problem is infeasible.\n\nSecond, we derive the simplified Homogeneous Self-Dual Embedding (HSDE) equalities for this instance. The fundamental idea of the HSDE is to embed the Karush-Kuhn-Tucker (KKT) conditions of the primal-dual pair into a larger, homogeneous linear system. The KKT conditions for an optimal solution are:\n$1.$ Primal feasibility: $A x + s = b, s \\in \\mathcal{K}$\n$2.$ Dual feasibility: $A^{\\top}y + c = 0, y \\in \\mathcal{K}^{\\ast}$\n$3.$ Complementary slackness: $s^{\\top}y = 0$\nThe HSDE introduces a homogenization parameter $\\tau \\ge 0$ and an infeasibility parameter $\\kappa \\ge 0$. The KKT conditions are reformulated into a system of linear equations. The\nnon-linear complementary slackness condition is typically replaced by a linear equation representing the duality gap. The duality gap for this pair is $g = c^{\\top}x - (-b^{\\top}y) = c^{\\top}x + b^{\\top}y$. For feasible points, this gap equals $s^{\\top}y$, which must be non-negative. The HSDE seeks a non-zero solution $(x,y,s,\\tau,\\kappa)$ to the following system, which is designed to detect either a solution ($\\tau0$) or a certificate of infeasibility ($\\tau=0$):\n(1) $A x + s = \\tau b$\n(2) $A^{\\top}y + \\tau c = 0$\n(3) $b^{\\top}y + c^{\\top}x = -\\kappa$\n(4) $s \\in \\mathcal{K}, y \\in \\mathcal{K}^{\\ast}, \\tau \\ge 0, \\kappa \\ge 0$\nSubstituting the given data $A=\\mathbf{0}$, $b=\\begin{pmatrix} -1 \\\\ 1 \\end{pmatrix}$, $c=\\begin{pmatrix} -2 \\\\ 0 \\end{pmatrix}$, and $\\mathcal{K}=\\mathcal{K}^{\\ast}=\\mathbb{R}_{+}^{2}$:\nFrom (2), $\\mathbf{0}^{\\top}y + \\tau c = \\mathbf{0}$, which simplifies to $\\tau c = \\mathbf{0}$. Since $c \\neq \\mathbf{0}$, this immediately implies that $\\tau = 0$.\nFrom (1), with $\\tau=0$, we have $\\mathbf{0} \\cdot x + s = 0 \\cdot b$, which simplifies to $s = \\mathbf{0}$.\nThus, for any non-zero solution to the HSDE for this specific instance, the variables $\\tau$ and $s$ must be zero. The remaining HSDE conditions for a non-zero certificate vector $(x, y, \\kappa \\ge 0)$ are:\n$A^{\\top}y=0$ (which is $0=0$, trivially true), $y \\in \\mathbb{R}_{+}^{2}$, and $b^{\\top}y + c^{\\top}x = -\\kappa$.\n\nThird, we explain how the HSDE certificate separates primal and dual infeasibility. When the HSDE procedure yields a solution with $\\tau=0$, it provides a certificate of infeasibility. The certificate vector is $(x, y, s=\\mathbf{0}, \\tau=0, \\kappa  0)$. The condition $b^{\\top}y + c^{\\top}x = -\\kappa$ implies $b^{\\top}y + c^{\\top}x  0$.\nA certificate of primal infeasibility is a vector $y_p$ satisfying $A^{\\top}y_p = \\mathbf{0}$, $y_p \\in \\mathcal{K}^{\\ast}$, and $b^{\\top}y_p  0$. The existence of such a $y_p$ contradicts the feasibility of the primal problem. In our HSDE framework, if we find a solution where $x=\\mathbf{0}$ and $y \\neq \\mathbf{0}$, the conditions become $y \\in \\mathbb{R}_{+}^{2}$ and $b^{\\top}y = -\\kappa  0$. This HSDE solution component $y$ is precisely a certificate of primal infeasibility.\nA certificate of dual infeasibility is a vector $x_d$ satisfying $Ax_d = -s_d$ for some $s_d \\in \\mathcal{K}$ and $c^{\\top}x_d  0$. The existence of such an $x_d$ contradicts the feasibility of the dual problem. Since $A=\\mathbf{0}$, the condition becomes $s_d = \\mathbf{0}$, which is in $\\mathcal{K}$. So we need an $x_d$ with $c^{\\top}x_d  0$. In our HSDE framework, if we find a solution where $y=\\mathbf{0}$ and $x \\neq \\mathbf{0}$, the conditions become $c^{\\top}x = -\\kappa  0$. This HSDE solution component $x$ is precisely a certificate of dual infeasibility.\nThe HSDE certificate vector $(x, y)$ is thus a composite certificate, where the $y$ component certifies primal infeasibility and the $x$ component certifies dual infeasibility. The scalar $\\kappa$ is derived from equation (3) of the HSDE system: $\\kappa = -b^{\\top}y - c^{\\top}x$.\n\nFourth, we instantiate concrete certificate choices and compute the required difference.\nFor a pure primal infeasibility certificate, we set $x = \\mathbf{0}$ and use the given $y = \\begin{pmatrix}1\\\\0\\end{pmatrix}$. We first verify that this choice of $y$ is valid: $y \\in \\mathbb{R}_{+}^{2}$ is true. The corresponding $\\kappa_{\\text{primal}}$ is:\n$$\n\\kappa_{\\text{primal}} = -b^{\\top}y - c^{\\top}\\mathbf{0} = -b^{\\top}y = -\\begin{pmatrix} -1  1 \\end{pmatrix} \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix} = -(-1 \\cdot 1 + 1 \\cdot 0) = -(-1) = 1\n$$\nFor a pure dual infeasibility certificate, we set $y = \\mathbf{0}$ and use the given $x = \\begin{pmatrix}1\\\\0\\end{pmatrix}$. The corresponding $\\kappa_{\\text{dual}}$ is:\n$$\n\\kappa_{\\text{dual}} = -b^{\\top}\\mathbf{0} - c^{\\top}x = -c^{\\top}x = -\\begin{pmatrix} -2  0 \\end{pmatrix} \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix} = -(-2 \\cdot 1 + 0 \\cdot 0) = -(-2) = 2\n$$\nThe problem asks for the scalar difference $\\kappa_{\\text{dual}} - \\kappa_{\\text{primal}}$.\n$$\n\\kappa_{\\text{dual}} - \\kappa_{\\text{primal}} = 2 - 1 = 1\n$$", "answer": "$$\\boxed{1}$$", "id": "3137092"}]}