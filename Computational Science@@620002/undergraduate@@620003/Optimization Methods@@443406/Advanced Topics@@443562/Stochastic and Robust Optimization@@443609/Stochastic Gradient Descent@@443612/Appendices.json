{"hands_on_practices": [{"introduction": "To truly understand Stochastic Gradient Descent (SGD), we must begin with its most fundamental operation: the update step. Unlike traditional gradient descent which computes the gradient from the entire dataset, SGD takes a more efficient, albeit noisier, approach by using just a single data point or a small mini-batch. This first exercise [@problem_id:2206637] will guide you through a single update, providing a concrete calculation of how the model parameters are adjusted based on the gradient from one component of the total loss function.", "problem": "An iterative optimization algorithm is used to find a parameter $x$ that minimizes a cost function. The total cost function is an average of several component functions: $F(x) = \\frac{1}{N}\\sum_{i=1}^{N} f_i(x)$. In this specific case, the component functions are quadratic and given by $f_i(x) = (x - c_i)^2$, where the constants are $c_i = i$ for $i = 1, 2, \\dots, 10$, and thus $N=10$.\n\nThe optimization process starts with an initial guess for the parameter, $x_0$. At each step, a new estimate, $x_{k+1}$, is calculated from the current estimate, $x_k$, by using only a single, randomly chosen component function, $f_j(x)$. The update rule is defined as:\n$$x_{k+1} = x_k - \\eta \\left( \\frac{d f_j(x)}{dx} \\bigg|_{x=x_k} \\right)$$\nwhere $\\eta$ is a constant known as the learning rate.\n\nGiven an initial parameter value of $x_0 = 10.0$ and a learning rate of $\\eta = 0.1$, compute the value of the parameter $x_1$ after one update step. For this first step, the component function used is $f_j(x)$ with the index $j=5$.", "solution": "We are given component functions of the form $f_{i}(x) = (x - c_{i})^{2}$ with $c_{i} = i$. For the first update, the chosen index is $j=5$, so $f_{5}(x) = (x - 5)^{2}$.\n\nThe update rule is\n$$\nx_{k+1} = x_{k} - \\eta \\left.\\frac{d f_{j}(x)}{dx}\\right|_{x=x_{k}}.\n$$\nUsing the power rule and chain rule, the derivative of the chosen component is\n$$\n\\frac{d f_{5}(x)}{dx} = \\frac{d}{dx}\\left[(x - 5)^{2}\\right] = 2(x - 5).\n$$\nEvaluating at the current iterate $x_{0} = 10$ gives\n$$\n\\left.\\frac{d f_{5}(x)}{dx}\\right|_{x=10} = 2(10 - 5) = 10.\n$$\nWith learning rate $\\eta = 0.1$, the update becomes\n$$\nx_{1} = x_{0} - \\eta \\cdot 10 = 10 - 0.1 \\times 10 = 10 - 1 = 9.\n$$\nThus, after one update step using $f_{5}$, the parameter value is $x_{1} = 9$.", "answer": "$$\\boxed{9}$$", "id": "2206637"}, {"introduction": "Having performed a single SGD step, a natural question arises: does this step guarantee an improvement in our overall objective function? While a step in full-batch gradient descent is designed to move \"downhill\" on the total loss surface, the stochastic nature of SGD introduces a fascinating twist. This practice problem [@problem_id:2206653] uses a simple, concrete example to demonstrate that a single SGD update can sometimes lead to an *increase* in the total loss, a key behavior that distinguishes it from its deterministic counterpart.", "problem": "In the field of machine learning, optimization algorithms are used to train model parameters by minimizing a loss function. Consider a simple model with a single scalar parameter, $w$. The goal is to minimize a total loss function, $F(w)$, which is defined as the average of the individual loss functions over a small dataset of two data points. The total loss function is given by:\n\n$$F(w) = \\frac{1}{2}\\left[f_1(w) + f_2(w)\\right]$$\n\nThe individual loss functions associated with the two data points are:\n\n$$f_1(w) = \\frac{1}{2}(w - 2)^2$$\n$$f_2(w) = \\frac{1}{2}(w - 10)^2$$\n\nThe training process begins with an initial parameter value of $w_0 = 3$. A single update step is performed using the Stochastic Gradient Descent (SGD) algorithm with a learning rate of $\\eta = 2$. For this specific update, the gradient is computed using only the loss function of the first data point, $f_1(w)$.\n\nCalculate the change in the value of the total loss function, $F(w_1) - F(w_0)$, that results from this single SGD update. Round your final answer to three significant figures.", "solution": "We are given $F(w)=\\frac{1}{2}\\left[f_{1}(w)+f_{2}(w)\\right]$ with $f_{1}(w)=\\frac{1}{2}(w-2)^{2}$ and $f_{2}(w)=\\frac{1}{2}(w-10)^{2}$. The initial parameter is $w_{0}=3$. A single SGD step with learning rate $\\eta=2$ uses only the gradient of $f_{1}$.\n\nThe SGD update rule in one dimension is\n$$\nw_{1}=w_{0}-\\eta\\,\\frac{d f_{1}}{d w}\\bigg|_{w=w_{0}}.\n$$\nCompute the derivative:\n$$\n\\frac{d f_{1}}{d w}=\\frac{d}{d w}\\left[\\frac{1}{2}(w-2)^{2}\\right]=(w-2).\n$$\nEvaluate at $w_{0}=3$:\n$$\n\\frac{d f_{1}}{d w}\\bigg|_{w=3}=3-2=1.\n$$\nThus the updated parameter is\n$$\nw_{1}=3-2\\cdot 1=1.\n$$\n\nNow compute $F(w_{0})$:\n$$\nf_{1}(3)=\\frac{1}{2}(3-2)^{2}=\\frac{1}{2},\\quad f_{2}(3)=\\frac{1}{2}(3-10)^{2}=\\frac{1}{2}\\cdot 49=\\frac{49}{2},\n$$\n$$\nF(3)=\\frac{1}{2}\\left(\\frac{1}{2}+\\frac{49}{2}\\right)=\\frac{1}{2}\\cdot\\frac{50}{2}=\\frac{1}{2}\\cdot 25=\\frac{25}{2}.\n$$\n\nCompute $F(w_{1})$:\n$$\nf_{1}(1)=\\frac{1}{2}(1-2)^{2}=\\frac{1}{2},\\quad f_{2}(1)=\\frac{1}{2}(1-10)^{2}=\\frac{1}{2}\\cdot 81=\\frac{81}{2},\n$$\n$$\nF(1)=\\frac{1}{2}\\left(\\frac{1}{2}+\\frac{81}{2}\\right)=\\frac{1}{2}\\cdot\\frac{82}{2}=\\frac{1}{2}\\cdot 41=\\frac{41}{2}.\n$$\n\nTherefore, the change in the total loss is\n$$\nF(w_{1})-F(w_{0})=\\frac{41}{2}-\\frac{25}{2}=\\frac{16}{2}=8.\n$$\nRounded to three significant figures, this is $8.00$.", "answer": "$$\\boxed{8.00}$$", "id": "2206653"}, {"introduction": "The fact that an SGD step might not decrease the total loss can seem like a drawback, but it is intrinsically linked to one of the algorithm's greatest strengths: its ability to escape local minima. The \"noise\" from using a subset of the data for gradient calculation allows the optimization path to jump over potential barriers that would trap a deterministic method like full-batch gradient descent. This exercise [@problem_id:2206623] provides a hands-on demonstration of this powerful concept, showing how you can quantify the amount of noise needed to overcome a local minimum and continue searching for a better, potentially global, solution.", "problem": "An optimization specialist is studying the behavior of different gradient-based algorithms on a one-dimensional non-convex loss surface. The idealized loss function is given by:\n$$L(w) = \\frac{1}{4}w^4 - \\frac{1}{3}w^3 - 3w^2$$\nwhere $w$ is a scalar parameter to be optimized.\n\nThe specialist considers two optimization algorithms, both starting from the initial parameter value $w_0 = -2.0$. Both algorithms use a fixed learning rate of $\\eta = 0.1$.\n\n1.  **Full-batch Gradient Descent (GD)**: The update rule is $w_{k+1} = w_k - \\eta L'(w_k)$.\n\n2.  **Stochastic Gradient Descent (SGD)**: The update is $w_{k+1} = w_k - \\eta \\hat{g}(w_k)$, where $\\hat{g}(w_k)$ is a noisy estimate of the gradient. This noisy gradient is modeled as $\\hat{g}(w_k) = L'(w_k) + \\xi_k$, where $\\xi_k$ is a random noise term drawn at each step $k$. For this analysis, the noise $\\xi_k$ is drawn from a simple discrete distribution: it takes the value $+\\sigma$ with probability $0.5$ and $-\\sigma$ with probability $0.5$, for some noise amplitude $\\sigma > 0$.\n\nA key feature of this loss landscape is a potential barrier that separates a local minimum from the global minimum. For the SGD algorithm, the inherent noise provides a chance to \"jump\" over this barrier. Determine the minimum value of the noise amplitude $\\sigma$ for which there is a non-zero probability for the SGD process, starting at $w_0 = -2.0$, to move to a parameter value $w_1 > 0$ in a single update step.\n\nExpress your answer as a single real number.", "solution": "Compute the gradient of the loss:\n$$L'(w) = \\frac{\\mathrm{d}}{\\mathrm{d}w}\\left(\\frac{1}{4}w^{4} - \\frac{1}{3}w^{3} - 3w^{2}\\right) = w^{3} - w^{2} - 6w.$$\n\nAt the initial point $w_{0} = -2$,\n$$L'(-2) = (-2)^{3} - (-2)^{2} - 6(-2) = -8 - 4 + 12 = 0.$$\n\nFor full-batch GD, $w_{1} = w_{0} - \\eta L'(w_{0}) = -2 - 0 = -2$, so there is no movement.\n\nFor SGD, the noisy gradient estimate at $w_{0}$ is $\\hat{g}(w_{0}) = L'(w_{0}) + \\xi_{0} = \\xi_{0}$, where $\\xi_{0} \\in \\{+\\sigma, -\\sigma\\}$ with equal probability. The update is\n$$w_{1} = w_{0} - \\eta \\hat{g}(w_{0}) = -2 - \\eta \\xi_{0}.$$\n\nThere are two cases:\n- If $\\xi_{0} = -\\sigma$, then $w_{1} = -2 + \\eta \\sigma$.\n- If $\\xi_{0} = +\\sigma$, then $w_{1} = -2 - \\eta \\sigma$.\n\nTo have a non-zero probability that $w_{1} > 0$ in one step, it suffices that the favorable outcome $\\xi_{0} = -\\sigma$ can make $w_{1} > 0$. This requires\n$$-2 + \\eta \\sigma > 0 \\quad \\Longleftrightarrow \\quad \\eta \\sigma > 2 \\quad \\Longleftrightarrow \\quad \\sigma > \\frac{2}{\\eta}.$$\n\nWith the given $\\eta = 0.1$,\n$$\\sigma > \\frac{2}{0.1} = 20.$$\n\nThus, any $\\sigma$ strictly greater than $20$ yields a non-zero probability (specifically, one-half) that $w_{1} > 0$ in a single step. The threshold value is $20$; at $\\sigma = 20$, the best-case update reaches $w_{1} = 0$ but not $w_{1} > 0$.", "answer": "$$\\boxed{20}$$", "id": "2206623"}]}