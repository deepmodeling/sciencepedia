{"hands_on_practices": [{"introduction": "To truly understand the Nesterov Accelerated Gradient method, we must first get comfortable with its fundamental mechanics. This first exercise [@problem_id:2187811] has you perform a direct calculation of the \"look-ahead\" point, the key feature that distinguishes NAG from other momentum-based optimizers. By working through the first few steps of the algorithm on a simple quadratic function, you will solidify your understanding of how it uses past velocity to anticipate the future gradient.", "problem": "An engineer is applying the Nesterov Accelerated Gradient (NAG) algorithm to minimize a one-dimensional objective function. The function is given by $f(x) = 2x^2$. The algorithm iteratively updates a position parameter $x$ and a velocity term $v$ according to the following set of rules, starting from an initial position $x_0$ and an initial velocity $v_0=0$:\n$$ v_{t} = \\gamma v_{t-1} + \\eta \\nabla f(x_{t-1} - \\gamma v_{t-1}) $$\n$$ x_{t} = x_{t-1} - v_{t} $$\nIn these equations, a subscript denotes the iteration number, so $t=1, 2, 3, \\ldots$. The constant $\\gamma$ is the momentum parameter, $\\eta$ is the learning rate, and $\\nabla f$ is the gradient of the function $f(x)$. The evaluation of the gradient occurs at the \"look-ahead\" point, given by the term $x_{t-1} - \\gamma v_{t-1}$.\n\nFor an initial position of $x_0 = 10$, a momentum parameter of $\\gamma = 0.9$, and a learning rate of $\\eta = 0.1$, calculate the numerical value of the look-ahead point that is used during the second iteration of the algorithm (i.e., for $t=2$).", "solution": "We are given the Nesterov Accelerated Gradient updates:\n$$v_{t}=\\gamma v_{t-1}+\\eta \\nabla f\\!\\left(x_{t-1}-\\gamma v_{t-1}\\right), \\quad x_{t}=x_{t-1}-v_{t}.$$\nThe objective is $f(x)=2x^{2}$, so its gradient is\n$$\\nabla f(x)=\\frac{d}{dx}(2x^{2})=4x.$$\n\nGiven $x_{0}=10$, $v_{0}=0$, $\\gamma=0.9$, and $\\eta=0.1$, first compute the look-ahead point for $t=1$:\n$$x_{0}-\\gamma v_{0}=10-0.9\\cdot 0=10.$$\nThen update the velocity at $t=1$:\n$$v_{1}=\\gamma v_{0}+\\eta \\nabla f(10)=0.9\\cdot 0+0.1\\cdot 4\\cdot 10=4.$$\nUpdate the position:\n$$x_{1}=x_{0}-v_{1}=10-4=6.$$\n\nFor the second iteration ($t=2$), the look-ahead point is\n$$x_{1}-\\gamma v_{1}=6-0.9\\cdot 4=6-3.6=2.4.$$\nTherefore, the numerical value of the look-ahead point used during the second iteration is $2.4$.", "answer": "$$\\boxed{2.4}$$", "id": "2187811"}, {"introduction": "Now that you've seen how to calculate the look-ahead update, let's explore *why* this feature is so powerful. This practice [@problem_id:2187789] presents a thought experiment where the optimizer has likely overshot a minimum, a common challenge in optimization. By analyzing NAG's behavior in this critical scenario, you will develop a deeper intuition for its self-correcting nature and its clear advantage over standard momentum methods.", "problem": "Consider a machine learning model whose parameters are being updated using an iterative optimization algorithm. At step $t$, the state of the optimizer is described by the parameter vector $\\theta_t$ and an accumulated momentum vector $v_t$. The optimizer's goal is to minimize a loss function $J(\\theta)$. The update is governed by a learning rate $\\eta > 0$ and a momentum coefficient $\\gamma \\in (0, 1)$.\n\nThe update rules for two common algorithms, Standard Momentum (SM) and Nesterov Accelerated Gradient (NAG), are given as follows:\n\n- **Standard Momentum (SM):**\n  1. Compute gradient: $g_t = \\nabla J(\\theta_t)$\n  2. Update momentum: $v_{t+1} = \\gamma v_t + \\eta g_t$\n  3. Update parameters: $\\theta_{t+1} = \\theta_t - v_{t+1}$\n\n- **Nesterov Accelerated Gradient (NAG):**\n  1. Compute lookahead position: $\\theta_{lookahead} = \\theta_t - \\gamma v_t$\n  2. Compute gradient at lookahead position: $g_{lookahead} = \\nabla J(\\theta_{lookahead})$\n  3. Update momentum: $v_{t+1} = \\gamma v_t + \\eta g_{lookahead}$\n  4. Update parameters: $\\theta_{t+1} = \\theta_t - v_{t+1}$\n\nNow, consider a specific situation where the optimizer has likely overshot a local minimum. The gradient at the current position $\\theta_t$ points in the exact opposite direction of the momentum vector, such that $\\nabla J(\\theta_t) = -c v_t$ for some positive constant $c$.\n\nTo analyze the behavior of NAG, assume that in the local vicinity of $\\theta_t$, the gradient of the loss function changes approximately linearly. That is, for a small displacement vector $d$, the gradient can be approximated as $\\nabla J(\\theta_t + d) \\approx \\nabla J(\\theta_t) + H d$, where the Hessian matrix $H$ is a constant, positive definite matrix. For this analysis, assume this relationship is exact and simplify the Hessian to $H = \\lambda I$, where $\\lambda$ is a positive scalar constant representing the local curvature and $I$ is the identity matrix. Thus, the approximation becomes an equality: $\\nabla J(\\theta_t + d) = \\nabla J(\\theta_t) + \\lambda d$.\n\nYour task is to determine the parameter update vector, $\\Delta \\theta = \\theta_{t+1} - \\theta_t$, for a single step of the Nesterov Accelerated Gradient (NAG) algorithm under these conditions. Express your answer as a symbolic expression in terms of $\\eta$, $\\gamma$, $c$, $\\lambda$, and the momentum vector $v_t$.", "solution": "We are given the Nesterov Accelerated Gradient (NAG) update:\n1) Compute lookahead position using the current momentum: $\\theta_{\\text{lookahead}} = \\theta_{t} - \\gamma v_{t}$.\n2) Compute the gradient at the lookahead position: $g_{\\text{lookahead}} = \\nabla J(\\theta_{\\text{lookahead}})$.\n3) Update the momentum: $v_{t+1} = \\gamma v_{t} + \\eta g_{\\text{lookahead}}$.\n4) Update the parameters: $\\theta_{t+1} = \\theta_{t} - v_{t+1}$.\n\nWe assume the local linear model for the gradient with Hessian $H = \\lambda I$, namely $\\nabla J(\\theta_{t} + d) = \\nabla J(\\theta_{t}) + \\lambda d$, and we are given that the current gradient is opposite to the momentum, $\\nabla J(\\theta_{t}) = - c v_{t}$ with $c > 0$.\n\nFirst, compute the gradient at the lookahead point. The displacement from $\\theta_{t}$ to the lookahead point is $d = \\theta_{\\text{lookahead}} - \\theta_{t} = - \\gamma v_{t}$. Using the linear gradient model,\n$$\ng_{\\text{lookahead}} = \\nabla J(\\theta_{\\text{lookahead}}) = \\nabla J(\\theta_{t}) + \\lambda d = - c v_{t} + \\lambda(- \\gamma v_{t}) = -\\left(c + \\gamma \\lambda\\right) v_{t}.\n$$\nUpdate the momentum using the NAG rule:\n$$\nv_{t+1} = \\gamma v_{t} + \\eta g_{\\text{lookahead}} = \\gamma v_{t} + \\eta \\left[-\\left(c + \\gamma \\lambda\\right) v_{t}\\right] = \\left[\\gamma - \\eta \\left(c + \\gamma \\lambda\\right)\\right] v_{t}.\n$$\nUpdate the parameters and form the parameter update vector $\\Delta \\theta = \\theta_{t+1} - \\theta_{t}$:\n$$\n\\theta_{t+1} = \\theta_{t} - v_{t+1} \\quad \\Longrightarrow \\quad \\Delta \\theta = - v_{t+1} = - \\left[\\gamma - \\eta \\left(c + \\gamma \\lambda\\right)\\right] v_{t} = \\left[\\eta \\left(c + \\gamma \\lambda\\right) - \\gamma\\right] v_{t}.\n$$\nThus, under the stated assumptions, the NAG one-step parameter update is\n$$\n\\Delta \\theta = \\left[\\eta \\left(c + \\gamma \\lambda\\right) - \\gamma\\right] v_{t}.\n$$", "answer": "$$\\boxed{\\left[\\eta\\left(c+\\gamma\\lambda\\right)-\\gamma\\right]v_{t}}$$", "id": "2187789"}, {"introduction": "An optimizer is only as good as its parameters, and choosing them poorly can lead to instability and divergence. This final, more advanced practice [@problem_id:3155602] moves from understanding the algorithm's mechanics to analyzing its stability, a crucial aspect of robust performance. You will determine the maximum stable momentum parameter for NAG on a class of functions, learning how theoretical analysis guides the practical choice of hyperparameters to guarantee convergence.", "problem": "Consider minimizing the strongly convex quadratic function $f(x) = \\tfrac{1}{2} x^{\\top} Q x$ with $Q \\in \\mathbb{R}^{n \\times n}$ symmetric positive definite, having eigenvalues in the interval $[\\mu, L]$ with $0 < \\mu \\leq L$. Suppose one uses the Nesterov Accelerated Gradient (NAG) method, also known as Nesterovâ€™s method, with constant step size $\\alpha$ and constant momentum parameter $\\beta \\geq 0$:\n- $y_{k} = x_{k} + \\beta \\left(x_{k} - x_{k-1}\\right)$,\n- $x_{k+1} = y_{k} - \\alpha \\nabla f(y_{k})$.\nAssume that the step size satisfies $0 < \\alpha < \\tfrac{1}{L}$ so that the underlying gradient step is nonexpansive in all eigendirections. It is empirically observed that a poor initial choice $\\beta_{0}$ can cause overshoot and instability in the iterates. Define stability to mean that, for every eigenvalue $\\lambda \\in [\\mu, L]$, the corresponding scalar error recurrence has both characteristic roots strictly inside the unit disk, which guarantees linear convergence in every eigendirection.\n\nDetermine, in closed form, the supremum $\\beta_{\\max}(\\alpha, \\mu, L)$ such that for all $\\beta \\in [0, \\beta_{\\max}(\\alpha, \\mu, L))$, the Nesterov Accelerated Gradient method is stable for every eigenvalue $\\lambda \\in [\\mu, L]$. Your final answer must be a single analytical expression in terms of $\\alpha$, $\\mu$, and $L$. No numerical approximation or rounding is required.", "solution": "The problem asks for the supremum of the momentum parameter $\\beta$, denoted $\\beta_{\\max}(\\alpha, \\mu, L)$, for which the Nesterov Accelerated Gradient (NAG) method is stable for all eigenvalues of the quadratic's Hessian matrix $Q$.\n\nFirst, we establish the recurrence relation for the error. The function to be minimized is $f(x) = \\frac{1}{2} x^{\\top} Q x$. The gradient is $\\nabla f(x) = Qx$. The optimal solution is $x^* = 0$, as $Q$ is positive definite. The error at iteration $k$ is therefore $e_k = x_k - x^* = x_k$.\n\nThe NAG update equations are given as:\n$y_{k} = x_{k} + \\beta (x_{k} - x_{k-1})$\n$x_{k+1} = y_{k} - \\alpha \\nabla f(y_{k})$\n\nSubstituting $\\nabla f(y_k) = Q y_k$ and the expression for $y_k$ into the second equation, we get a recurrence for $x_k$:\n$$x_{k+1} = (I - \\alpha Q) y_k = (I - \\alpha Q) \\left( x_k + \\beta(x_k - x_{k-1}) \\right)$$\n$$x_{k+1} = (1+\\beta)(I - \\alpha Q) x_k - \\beta(I - \\alpha Q) x_{k-1}$$\nThis is a second-order linear homogeneous vector recurrence relation. Since $Q$ is symmetric, it has a complete orthonormal basis of eigenvectors $v_i$ with corresponding real eigenvalues $\\lambda_i \\in [\\mu, L]$. The dynamics of the method can be decoupled by projecting the iterate $x_k$ onto each eigenvector. Let $x_k = \\sum_i \\xi_{k,i} v_i$. The recurrence for the component $\\xi_{k,i}$ along eigenvector $v_i$ is:\n$$\\xi_{k+1,i} = (1+\\beta)(1 - \\alpha \\lambda_i) \\xi_{k,i} - \\beta(1 - \\alpha \\lambda_i) \\xi_{k-1,i}$$\n\nFor simplicity, let us drop the index $i$ and analyze the stability for a generic eigenvalue $\\lambda \\in [\\mu, L]$. The scalar recurrence is:\n$$\\xi_{k+1} = (1+\\beta)(1 - \\alpha \\lambda) \\xi_k - \\beta(1 - \\alpha \\lambda) \\xi_{k-1}$$\nThe stability of this recurrence is determined by the roots of its characteristic polynomial. The characteristic equation is:\n$$r^2 - (1+\\beta)(1 - \\alpha \\lambda) r + \\beta(1 - \\alpha \\lambda) = 0$$\nLet's define the coefficients of the polynomial $P(r) = r^2 - A r + B$:\n$A = (1+\\beta)(1 - \\alpha \\lambda)$\n$B = \\beta(1 - \\alpha \\lambda)$\n\nThe method is stable for the eigenvalue $\\lambda$ if and only if both roots of this quadratic equation have a magnitude strictly less than $1$. For a second-order polynomial $r^2 - Ar + B = 0$, the necessary and sufficient conditions for its roots to be strictly inside the unit disk are the Jury stability criteria, which simplify to:\n1.  $P(1) = 1 - A + B > 0$\n2.  $P(-1) = 1 + A + B > 0$\n3.  $|B| < 1$\n\nWe must find the range of $\\beta \\geq 0$ for which these three conditions hold for a given $\\alpha \\in (0, 1/L)$ and for *all* $\\lambda \\in [\\mu, L]$.\n\nLet's analyze each condition:\n\n**Condition 1: $P(1) > 0$**\n$$1 - (1+\\beta)(1 - \\alpha \\lambda) + \\beta(1 - \\alpha \\lambda) = 1 - (1 - \\alpha \\lambda) = \\alpha \\lambda$$\nWe need $\\alpha \\lambda > 0$. Given that $\\alpha > 0$ and $\\lambda \\geq \\mu > 0$, this condition is satisfied for all $\\lambda \\in [\\mu, L]$ and for all valid parameters.\n\n**Condition 2: $P(-1) > 0$**\n$$1 + (1+\\beta)(1 - \\alpha \\lambda) + \\beta(1 - \\alpha \\lambda) = 1 + (1 + 2\\beta)(1 - \\alpha \\lambda)$$\nWe need $1 + (1 + 2\\beta)(1 - \\alpha \\lambda) > 0$ for all $\\lambda \\in [\\mu, L]$.\nLet $g(\\lambda) = 1 + (1 + 2\\beta)(1 - \\alpha \\lambda)$. To check if this holds for all $\\lambda$ in the interval, we find its minimum value. The derivative with respect to $\\lambda$ is $g'(\\lambda) = -(1 + 2\\beta)\\alpha$. Since $\\alpha > 0$ and $\\beta \\geq 0$, $g'(\\lambda) < 0$. Thus, $g(\\lambda)$ is a decreasing function of $\\lambda$. Its minimum value on $[\\mu, L]$ occurs at $\\lambda = L$.\nThe most stringent condition is therefore at $\\lambda=L$:\n$$1 + (1 + 2\\beta)(1 - \\alpha L) > 0$$\nThe problem states that $0 < \\alpha < 1/L$, which implies $\\alpha L < 1$, so $1 - \\alpha L > 0$. Since $\\beta \\geq 0$, the term $(1 + 2\\beta)(1 - \\alpha L)$ is strictly positive. Therefore, $1 + (1 + 2\\beta)(1 - \\alpha L) > 1 > 0$. This condition is also satisfied for all $\\lambda \\in [\\mu, L]$ and for all valid parameters.\n\n**Condition 3: $|B| < 1$**\n$$|\\beta(1 - \\alpha \\lambda)| < 1$$\nGiven $\\beta \\geq 0$ and the condition $\\alpha < 1/L$, we have $\\alpha\\lambda \\le \\alpha L < 1$ for all $\\lambda \\in [\\mu, L]$. This means $1 - \\alpha \\lambda > 0$. The absolute value can be removed:\n$$\\beta(1 - \\alpha \\lambda) < 1$$\nThis inequality must hold for all $\\lambda \\in [\\mu, L]$. This can be rewritten as:\n$$\\beta < \\frac{1}{1 - \\alpha \\lambda}$$\nTo satisfy this for the entire interval $\\lambda \\in [\\mu, L]$, $\\beta$ must be smaller than the minimum value of the function $h(\\lambda) = \\frac{1}{1 - \\alpha \\lambda}$ on this interval.\nLet's find the minimum of $h(\\lambda)$. The derivative is:\n$$h'(\\lambda) = \\frac{d}{d\\lambda} (1 - \\alpha \\lambda)^{-1} = -1(1 - \\alpha \\lambda)^{-2}(-\\alpha) = \\frac{\\alpha}{(1 - \\alpha \\lambda)^2}$$\nSince $\\alpha > 0$, $h'(\\lambda) > 0$. Thus, $h(\\lambda)$ is an increasing function of $\\lambda$. Its minimum value on the interval $[\\mu, L]$ occurs at the left endpoint, $\\lambda = \\mu$.\n$$\\min_{\\lambda \\in [\\mu, L]} \\frac{1}{1 - \\alpha \\lambda} = \\frac{1}{1 - \\alpha \\mu}$$\nTherefore, the condition for stability across the entire spectrum is:\n$$\\beta < \\frac{1}{1 - \\alpha \\mu}$$\nThe problem asks for the supremum of $\\beta$ values that ensure stability. This corresponds to the upper bound of the interval for $\\beta$.\n$$\\beta_{\\max}(\\alpha, \\mu, L) = \\frac{1}{1 - \\alpha \\mu}$$\nThis expression gives the maximum allowed value for the momentum parameter $\\beta$ to guarantee stability for all eigenmodes, as a function of the step size $\\alpha$ and the bounds on the eigenvalues of $Q$. The parameter $L$ constrains the possible values of $\\alpha$ but does not appear explicitly in the final expression for $\\beta_{\\max}$.", "answer": "$$\\boxed{\\frac{1}{1 - \\alpha \\mu}}$$", "id": "3155602"}]}