{"hands_on_practices": [{"introduction": "The power of Mirror Descent lies in its ability to adapt the geometry of the optimization landscape to the structure of the constraints. This first exercise focuses on the theoretical heart of the method for problems on the probability simplex. You will explore how the choice of the negative entropy function as a mirror map naturally leads to the elegant and efficient multiplicative weights update rule [@problem_id:3165049].", "problem": "You are asked to implement and compare two first-order methods for constrained convex optimization on the probability simplex: the Euclidean projected subgradient method and mirror descent with the negative entropy mirror map. The target function is the pointwise maximum of linear functionals. The comparison must be driven from first principles and evaluated on a fixed test suite.\n\nFundamental base definitions to use:\n- A function $f:\\mathbb{R}^n \\to \\mathbb{R}$ is convex if for all $x,y \\in \\mathbb{R}^n$ and $\\lambda \\in [0,1]$, $f(\\lambda x + (1-\\lambda) y) \\le \\lambda f(x) + (1-\\lambda) f(y)$. For $f(x) = \\max_{i \\in \\{1,\\dots,K\\}} c_i^\\top x$ with given $c_i \\in \\mathbb{R}^n$, convexity follows from the fact that a pointwise maximum of affine functions is convex.\n- A subgradient $g \\in \\mathbb{R}^n$ of a convex function $f$ at $x$ satisfies $f(y) \\ge f(x) + g^\\top (y - x)$ for all $y$. For $f(x) = \\max_i c_i^\\top x$, any $c_k$ where $k$ attains the maximum $c_k^\\top x$ is a valid subgradient.\n- The Euclidean projection of a point $y \\in \\mathbb{R}^n$ onto a nonempty closed convex set $C$ is the unique point $P_C(y)$ minimizing $\\|x - y\\|_2$ over $x \\in C$.\n- The probability simplex in $\\mathbb{R}^n$ is $\\Delta_n = \\{x \\in \\mathbb{R}^n \\mid x_i \\ge 0 \\text{ for all } i, \\ \\sum_{i=1}^n x_i = 1\\}$.\n- Given a strictly convex and differentiable function (the mirror map) $\\psi:\\text{int}(\\Delta_n) \\to \\mathbb{R}$, the Bregman divergence generated by $\\psi$ is $D_\\psi(x,y) = \\psi(x) - \\psi(y) - \\nabla \\psi(y)^\\top (x-y)$. For the negative entropy mirror map $\\psi(x) = \\sum_{i=1}^n x_i \\log x_i$ defined on the interior of the simplex, $D_\\psi$ reduces to the Kullback–Leibler divergence up to an additive constant.\n\nTask:\n- Consider the constrained minimization problem $\\min_{x \\in \\Delta_n} f(x)$ with $f(x) = \\max_{i \\in \\{1,\\dots,K\\}} c_i^\\top x$.\n- Implement two iterative methods starting from the uniform point $x^{(0)} = \\left(\\frac{1}{n},\\dots,\\frac{1}{n}\\right)$:\n  1. Euclidean projected subgradient method: at iteration $t$, choose a subgradient $g^{(t)}$ of $f$ at $x^{(t)}$, take a Euclidean step $y^{(t+1)} = x^{(t)} - \\alpha_t g^{(t)}$, and compute $x^{(t+1)}$ as the Euclidean projection of $y^{(t+1)}$ onto $\\Delta_n$.\n  2. Mirror descent with negative entropy: at iteration $t$, choose a subgradient $g^{(t)}$ of $f$ at $x^{(t)}$, and compute $x^{(t+1)}$ as the minimizer over $\\Delta_n$ of the first-order proximal subproblem with the Bregman divergence $D_\\psi$ corresponding to $\\psi(x) = \\sum_{i=1}^n x_i \\log x_i$, i.e., $x^{(t+1)} = \\arg\\min_{x \\in \\Delta_n} \\left\\{ \\alpha_t \\, g^{(t)}{}^\\top x + D_\\psi(x, x^{(t)}) \\right\\}$.\n- Use the diminishing step-size schedule $\\alpha_t = \\frac{\\alpha_0}{\\sqrt{t+1}}$ with $\\alpha_0 = 0.5$ for $t = 0,1,\\dots,T-1$, and run for $T = 300$ iterations. All indices $t$, $n$, $K$, $\\alpha_0$, and $T$ must be treated exactly as defined here.\n\nExperimental design and evaluation:\n- For each test case, after $T$ iterations, compute $f_{\\text{proj}} = \\max_i c_i^\\top x_{\\text{proj}}^{(T)}$ and $f_{\\text{mirror}} = \\max_i c_i^\\top x_{\\text{mirror}}^{(T)}$, where $x_{\\text{proj}}^{(T)}$ and $x_{\\text{mirror}}^{(T)}$ are the final iterates of the Euclidean projected subgradient and mirror descent methods, respectively. Then report the difference $d = f_{\\text{proj}} - f_{\\text{mirror}}$ as a float. A positive $d$ indicates that mirror descent achieved a lower final objective value relative to Euclidean projection under the same step-size schedule and iteration budget.\n\nTest suite:\n- Dimension $n = 6$ for all cases. Each test case is specified by a matrix $C \\in \\mathbb{R}^{K \\times n}$ with rows $c_i^\\top$. Use exactly the following four cases.\n  1. Case A (moderately mixed coefficients, interior behavior):\n     $$\n     C = \\begin{bmatrix}\n     0.2 & 0.3 & -0.1 & 0.0 & 0.4 & -0.2 \\\\\n     -0.1 & 0.5 & 0.2 & -0.3 & 0.1 & 0.0 \\\\\n     0.3 & -0.2 & 0.1 & 0.2 & -0.1 & 0.4 \\\\\n     0.0 & 0.1 & 0.3 & 0.5 & -0.4 & 0.2\n     \\end{bmatrix}.\n     $$\n  2. Case B (spiky gradients, anisotropic geometry):\n     $$\n     C = \\begin{bmatrix}\n     2.0 & -1.0 & 0.5 & 0.0 & -0.5 & 0.0 \\\\\n     -1.5 & 1.0 & -0.5 & 0.2 & 0.1 & 0.0 \\\\\n     1.0 & -0.5 & 1.5 & -1.0 & 0.0 & 0.0\n     \\end{bmatrix}.\n     $$\n  3. Case C (nearly colinear rows, flat landscape):\n     $$\n     C = \\begin{bmatrix}\n     0.5 & 0.5 & 0.5 & 0.5 & 0.5 & 0.5 \\\\\n     0.45 & 0.45 & 0.45 & 0.45 & 0.45 & 0.45 \\\\\n     0.52 & 0.52 & 0.52 & 0.52 & 0.52 & 0.52\n     \\end{bmatrix}.\n     $$\n  4. Case D (vertex-optimal due to zero-cost coordinates):\n     $$\n     C = \\begin{bmatrix}\n     1.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 \\\\\n     0.0 & 1.0 & 0.0 & 0.0 & 0.0 & 0.0 \\\\\n     0.0 & 0.0 & 1.0 & 0.0 & 0.0 & 0.0\n     \\end{bmatrix}.\n     $$\n\nRequired final output format:\n- Your program should produce a single line of output containing the results as a comma-separated list of the four float differences $d$ in the order of the test suite cases, enclosed in square brackets, with each float rounded to six decimal places. For example, the output must have the form $[d_1,d_2,d_3,d_4]$ where each $d_j$ is reported to six decimals.\n\nNo physical units or angle units are involved in this problem. All numerical values must be handled as unitless real numbers. The solution should proceed from the foundational definitions above; do not introduce shortcut formulas in the problem statement beyond these definitions.", "solution": "We begin from the convex optimization problem $\\min_{x \\in \\Delta_n} f(x)$ where $f(x) = \\max_{i \\in \\{1,\\dots,K\\}} c_i^\\top x$ and each $c_i \\in \\mathbb{R}^n$ is fixed. The function $f$ is convex because it is the pointwise maximum of affine functions. A subgradient at a point $x$ can be chosen from the set $\\{c_i : i \\in \\arg\\max_j c_j^\\top x\\}$, which is a direct consequence of the subgradient characterization for the maximum of convex functions.\n\nEuclidean projected subgradient method:\n- Constrained subgradient descent uses the principle that for a convex $f$ and a closed convex set $C$, an iteration of the form $y^{(t+1)} = x^{(t)} - \\alpha_t g^{(t)}$ with $g^{(t)} \\in \\partial f(x^{(t)})$ followed by projection $x^{(t+1)} = P_C(y^{(t+1)})$ ensures feasibility and nonexpansiveness with respect to the Euclidean norm. The Euclidean projection $P_{\\Delta_n}$ solves $\\min_{x \\in \\Delta_n} \\|x - y\\|_2$, and admits a unique solution. For the simplex, this solution has the structure $x_i = \\max\\{y_i - \\tau, 0\\}$ for a threshold $\\tau$ chosen so that $\\sum_i x_i = 1$, which can be found in $O(n \\log n)$ time by sorting $y$ and selecting an index that satisfies the complementary slackness conditions.\n\nMirror descent with negative entropy:\n- Mirror descent is derived from proximal minimization with a geometry induced by a strictly convex mirror map $\\psi$. Given $\\psi(x) = \\sum_{i=1}^n x_i \\log x_i$ defined on the interior of the simplex, the associated Bregman divergence is\n$$\nD_\\psi(x,y) = \\sum_{i=1}^n x_i \\log \\frac{x_i}{y_i} - \\sum_{i=1}^n (x_i - y_i),\n$$\nwhich, up to an additive constant, is the Kullback–Leibler divergence. The mirror descent update at iteration $t$ solves\n$$\nx^{(t+1)} = \\arg\\min_{x \\in \\Delta_n} \\left\\{ \\alpha_t \\, g^{(t)}{}^\\top x + D_\\psi(x, x^{(t)}) \\right\\},\n$$\nwhere $g^{(t)} \\in \\partial f(x^{(t)})$. The first-order optimality conditions for this strictly convex problem yield, for some Lagrange multiplier $\\lambda$ enforcing $\\sum_i x_i = 1$,\n$$\n\\alpha_t g^{(t)} + \\nabla \\psi(x^{(t+1)}) - \\nabla \\psi(x^{(t)}) + \\lambda \\mathbf{1} = 0.\n$$\nUsing $\\nabla \\psi(x)_i = \\log x_i + 1$, this simplifies (after eliminating $\\lambda$ by normalization) to the multiplicative weights update\n$$\nx^{(t+1)}_i \\propto x^{(t)}_i \\exp\\left(-\\alpha_t g^{(t)}_i\\right),\n$$\nwith proportionality constant chosen so that $\\sum_i x^{(t+1)}_i = 1$. This update preserves positivity and adjusts weights geometrically according to the subgradient components.\n\nWhy mirror descent geometry can outperform Euclidean projection on the simplex:\n- The simplex $\\Delta_n$ is a probability geometry where positivity and normalization are intrinsic constraints. The negative entropy mirror map induces the Kullback–Leibler divergence, which is naturally aligned with multiplicative changes in probabilities. This geometry yields updates that stay strictly inside the simplex, avoid abrupt truncation to zero, and modulate coordinates multiplicatively. In contrast, Euclidean projection can cause large coordinates to be truncated aggressively by the thresholding effect of projection, especially when step sizes momentarily overshoot. This can lead to oscillatory behavior near the boundary, frequent changes in active constraints, and loss of information due to zeros that cannot be revived without specific structural cues.\n- For functions like $f(x) = \\max_i c_i^\\top x$ with potentially spiky subgradients, mirror descent can dampen the influence of large components via exponentiation and normalization, adapting smoothly to anisotropy. Euclidean projection operates additively; when gradients are highly nonuniform, additive steps followed by clipping can introduce zig-zag trajectories that slow progress in objective value.\n\nAlgorithmic design details used in the program:\n- Initialize $x^{(0)}$ to the uniform point $x^{(0)} = \\left(\\frac{1}{n},\\dots,\\frac{1}{n}\\right)$.\n- At each iteration $t$ for both methods, select a subgradient $g^{(t)} = c_k$ where $k \\in \\arg\\max_i c_i^\\top x^{(t)}$. For determinism, select the smallest index $k$ in the argmax set.\n- Use the common diminishing step-size $\\alpha_t = \\frac{\\alpha_0}{\\sqrt{t+1}}$ with $\\alpha_0 = 0.5$ for $t = 0, 1, \\dots, T-1$, and set $T = 300$ iterations.\n- Projected subgradient method: compute $y^{(t+1)} = x^{(t)} - \\alpha_t g^{(t)}$, then project onto $\\Delta_n$ using the Euclidean projection onto the simplex, which can be implemented via sorting $y$, computing a threshold $\\tau$, and applying $x^{(t+1)}_i = \\max\\{y^{(t+1)}_i - \\tau, 0\\}$ so that $\\sum_i x^{(t+1)}_i = 1$.\n- Mirror descent: compute the multiplicative weights update $x^{(t+1)}_i \\propto x^{(t)}_i \\exp\\left(-\\alpha_t g^{(t)}_i\\right)$ and renormalize to enforce $\\sum_i x^{(t+1)}_i = 1$.\n- After $T$ iterations, compute $f_{\\text{proj}} = \\max_i c_i^\\top x_{\\text{proj}}^{(T)}$ and $f_{\\text{mirror}} = \\max_i c_i^\\top x_{\\text{mirror}}^{(T)}$, then report $d = f_{\\text{proj}} - f_{\\text{mirror}}$.\n\nTest suite rationale:\n- Case A has mixed positive and negative coefficients, promoting interior behavior with competing linear functionals; mirror descent's geometry is expected to yield smooth progress.\n- Case B has spiky gradients and anisotropy, making additive steps plus projection prone to clipping; mirror descent often handles such anisotropy better.\n- Case C has rows that are almost colinear, yielding a landscape where $f$ is practically constant across $x \\in \\Delta_n$ (indeed exactly constant when taking the maximum among constants); both methods should yield the same objective, leading to $d$ near zero.\n- Case D has three linear functionals affecting only the first three coordinates. The remaining coordinates incur zero cost, so the minimum of $f$ is achieved by concentrating all mass on coordinates with zero coefficients (a vertex among those). Euclidean projection may approach such vertices faster by aggressive truncation, while mirror descent, due to its interior geometry, can move more cautiously, potentially yielding $d  0$.\n\nThe program implements these algorithms exactly as derived and prints the four differences $d$ for the specified test suite, rounded to six decimals, in the required single-line format.", "answer": "```python\nimport numpy as np\n\ndef project_onto_simplex(v):\n    \"\"\"\n    Euclidean projection onto the probability simplex:\n    Solve min_x ||x - v||_2 subject to x = 0, sum x = 1.\n    \"\"\"\n    n = v.size\n    # Sort v in descending order\n    u = np.sort(v)[::-1]\n    cssv = np.cumsum(u)\n    # Find rho: the largest j such that u_j - (cssv_j - 1)/j  0\n    j = np.arange(1, n + 1)\n    cond = u - (cssv - 1) / j > 0\n    if not np.any(cond):\n        # In degenerate case, distribute uniformly\n        theta = (cssv[-1] - 1) / n\n    else:\n        rho = np.nonzero(cond)[0][-1]\n        theta = (cssv[rho] - 1) / (rho + 1)\n    w = v - theta\n    w = np.maximum(w, 0.0)\n    # Numerical guard to enforce sum to 1 exactly due to possible rounding\n    s = w.sum()\n    if s = 0:\n        # fallback uniform\n        w = np.ones(n) / n\n    else:\n        w /= s\n    return w\n\ndef subgradient_max_linear(C, x):\n    \"\"\"\n    Subgradient of f(x) = max_i c_i^T x at x: choose c_k with k in argmax.\n    Deterministic tie-breaking: smallest index k.\n    \"\"\"\n    values = C @ x\n    k = int(np.argmax(values))\n    return C[k]\n\ndef projected_subgradient(C, x0, T, alpha0):\n    x = x0.copy()\n    for t in range(T):\n        alpha_t = alpha0 / np.sqrt(t + 1)\n        g = subgradient_max_linear(C, x)\n        y = x - alpha_t * g\n        x = project_onto_simplex(y)\n    return x\n\ndef mirror_descent_entropy(C, x0, T, alpha0):\n    x = x0.copy()\n    for t in range(T):\n        alpha_t = alpha0 / np.sqrt(t + 1)\n        g = subgradient_max_linear(C, x)\n        # Multiplicative weights update\n        # Prevent overflow/underflow via clipping exponent argument\n        # However, typical magnitudes here are small; proceed directly.\n        update = x * np.exp(-alpha_t * g)\n        s = update.sum()\n        if s = 0 or not np.isfinite(s):\n            # Fallback to uniform if numerical issues\n            x = np.ones_like(x) / x.size\n        else:\n            x = update / s\n    return x\n\ndef f_max_linear(C, x):\n    return float(np.max(C @ x))\n\ndef run_case(C, T=300, alpha0=0.5):\n    n = C.shape[1]\n    x0 = np.ones(n) / n\n    x_proj = projected_subgradient(C, x0, T, alpha0)\n    x_mirror = mirror_descent_entropy(C, x0, T, alpha0)\n    f_proj = f_max_linear(C, x_proj)\n    f_mirror = f_max_linear(C, x_mirror)\n    return f_proj - f_mirror\n\ndef solve():\n    # Define the test cases from the problem statement.\n    test_cases = [\n        np.array([\n            [0.2, 0.3, -0.1, 0.0, 0.4, -0.2],\n            [-0.1, 0.5, 0.2, -0.3, 0.1, 0.0],\n            [0.3, -0.2, 0.1, 0.2, -0.1, 0.4],\n            [0.0, 0.1, 0.3, 0.5, -0.4, 0.2]\n        ], dtype=float),\n        np.array([\n            [2.0, -1.0, 0.5, 0.0, -0.5, 0.0],\n            [-1.5, 1.0, -0.5, 0.2, 0.1, 0.0],\n            [1.0, -0.5, 1.5, -1.0, 0.0, 0.0]\n        ], dtype=float),\n        np.array([\n            [0.5, 0.5, 0.5, 0.5, 0.5, 0.5],\n            [0.45, 0.45, 0.45, 0.45, 0.45, 0.45],\n            [0.52, 0.52, 0.52, 0.52, 0.52, 0.52]\n        ], dtype=float),\n        np.array([\n            [1.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n            [0.0, 1.0, 0.0, 0.0, 0.0, 0.0],\n            [0.0, 0.0, 1.0, 0.0, 0.0, 0.0]\n        ], dtype=float),\n    ]\n\n    T = 300\n    alpha0 = 0.5\n\n    results = []\n    for C in test_cases:\n        d = run_case(C, T=T, alpha0=alpha0)\n        results.append(d)\n\n    # Final print statement in the exact required format: 6 decimals.\n    formatted = \"[\" + \",\".join(f\"{r:.6f}\" for r in results) + \"]\"\n    print(formatted)\n\nsolve()\n```", "id": "3165049"}, {"introduction": "Theory provides the \"why,\" but implementation provides the \"how.\" In this practice, you will translate concepts into code by implementing both Mirror Descent with the entropy mirror map and the standard Projected Subgradient method. This head-to-head coding challenge will solidify your understanding of the algorithmic differences and prepare you to empirically test their performance on a constrained optimization problem [@problem_id:3165049].", "problem": "You are asked to implement and compare two first-order methods for constrained convex optimization on the probability simplex: the Euclidean projected subgradient method and mirror descent with the negative entropy mirror map. The target function is the pointwise maximum of linear functionals. The comparison must be driven from first principles and evaluated on a fixed test suite.\n\nFundamental base definitions to use:\n- A function $f:\\mathbb{R}^n \\to \\mathbb{R}$ is convex if for all $x,y \\in \\mathbb{R}^n$ and $\\lambda \\in [0,1]$, $f(\\lambda x + (1-\\lambda) y) \\le \\lambda f(x) + (1-\\lambda) f(y)$. For $f(x) = \\max_{i \\in \\{1,\\dots,K\\}} c_i^\\top x$ with given $c_i \\in \\mathbb{R}^n$, convexity follows from the fact that a pointwise maximum of affine functions is convex.\n- A subgradient $g \\in \\mathbb{R}^n$ of a convex function $f$ at $x$ satisfies $f(y) \\ge f(x) + g^\\top (y - x)$ for all $y$. For $f(x) = \\max_i c_i^\\top x$, any $c_k$ where $k$ attains the maximum $c_k^\\top x$ is a valid subgradient.\n- The Euclidean projection of a point $y \\in \\mathbb{R}^n$ onto a nonempty closed convex set $C$ is the unique point $P_C(y)$ minimizing $\\|x - y\\|_2$ over $x \\in C$.\n- The probability simplex in $\\mathbb{R}^n$ is $\\Delta_n = \\{x \\in \\mathbb{R}^n \\mid x_i \\ge 0 \\text{ for all } i, \\ \\sum_{i=1}^n x_i = 1\\}$.\n- Given a strictly convex and differentiable function (the mirror map) $\\psi:\\text{int}(\\Delta_n) \\to \\mathbb{R}$, the Bregman divergence generated by $\\psi$ is $D_\\psi(x,y) = \\psi(x) - \\psi(y) - \\nabla \\psi(y)^\\top (x-y)$. For the negative entropy mirror map $\\psi(x) = \\sum_{i=1}^n x_i \\log x_i$ defined on the interior of the simplex, $D_\\psi$ reduces to the Kullback–Leibler divergence up to an additive constant.\n\nTask:\n- Consider the constrained minimization problem $\\min_{x \\in \\Delta_n} f(x)$ with $f(x) = \\max_{i \\in \\{1,\\dots,K\\}} c_i^\\top x$.\n- Implement two iterative methods starting from the uniform point $x^{(0)} = \\left(\\frac{1}{n},\\dots,\\frac{1}{n}\\right)$:\n  1. Euclidean projected subgradient method: at iteration $t$, choose a subgradient $g^{(t)}$ of $f$ at $x^{(t)}$, take a Euclidean step $y^{(t+1)} = x^{(t)} - \\alpha_t g^{(t)}$, and compute $x^{(t+1)}$ as the Euclidean projection of $y^{(t+1)}$ onto $\\Delta_n$.\n  2. Mirror descent with negative entropy: at iteration $t$, choose a subgradient $g^{(t)}$ of $f$ at $x^{(t)}$, and compute $x^{(t+1)}$ as the minimizer over $\\Delta_n$ of the first-order proximal subproblem with the Bregman divergence $D_\\psi$ corresponding to $\\psi(x) = \\sum_{i=1}^n x_i \\log x_i$, i.e., $x^{(t+1)} = \\arg\\min_{x \\in \\Delta_n} \\left\\{ \\alpha_t \\, g^{(t)}{}^\\top x + D_\\psi(x, x^{(t)}) \\right\\}$.\n- Use the diminishing step-size schedule $\\alpha_t = \\frac{\\alpha_0}{\\sqrt{t+1}}$ with $\\alpha_0 = 0.5$ for $t = 0,1,\\dots,T-1$, and run for $T = 300$ iterations. All indices $t$, $n$, $K$, $\\alpha_0$, and $T$ must be treated exactly as defined here.\n\nExperimental design and evaluation:\n- For each test case, after $T$ iterations, compute $f_{\\text{proj}} = \\max_i c_i^\\top x_{\\text{proj}}^{(T)}$ and $f_{\\text{mirror}} = \\max_i c_i^\\top x_{\\text{mirror}}^{(T)}$, where $x_{\\text{proj}}^{(T)}$ and $x_{\\text{mirror}}^{(T)}$ are the final iterates of the Euclidean projected subgradient and mirror descent methods, respectively. Then report the difference $d = f_{\\text{proj}} - f_{\\text{mirror}}$ as a float. A positive $d$ indicates that mirror descent achieved a lower final objective value relative to Euclidean projection under the same step-size schedule and iteration budget.\n\nTest suite:\n- Dimension $n = 6$ for all cases. Each test case is specified by a matrix $C \\in \\mathbb{R}^{K \\times n}$ with rows $c_i^\\top$. Use exactly the following four cases.\n  1. Case A (moderately mixed coefficients, interior behavior):\n     $$\n     C = \\begin{bmatrix}\n     0.2  0.3  -0.1  0.0  0.4  -0.2 \\\\\n     -0.1  0.5  0.2  -0.3  0.1  0.0 \\\\\n     0.3  -0.2  0.1  0.2  -0.1  0.4 \\\\\n     0.0  0.1  0.3  0.5  -0.4  0.2\n     \\end{bmatrix}.\n     $$\n  2. Case B (spiky gradients, anisotropic geometry):\n     $$\n     C = \\begin{bmatrix}\n     2.0  -1.0  0.5  0.0  -0.5  0.0 \\\\\n     -1.5  1.0  -0.5  0.2  0.1  0.0 \\\\\n     1.0  -0.5  1.5  -1.0  0.0  0.0\n     \\end{bmatrix}.\n     $$\n  3. Case C (nearly colinear rows, flat landscape):\n     $$\n     C = \\begin{bmatrix}\n     0.5  0.5  0.5  0.5  0.5  0.5 \\\\\n     0.45  0.45  0.45  0.45  0.45  0.45 \\\\\n     0.52  0.52  0.52  0.52  0.52  0.52\n     \\end{bmatrix}.\n     $$\n  4. Case D (vertex-optimal due to zero-cost coordinates):\n     $$\n     C = \\begin{bmatrix}\n     1.0  0.0  0.0  0.0  0.0  0.0 \\\\\n     0.0  1.0  0.0  0.0  0.0  0.0 \\\\\n     0.0  0.0  1.0  0.0  0.0  0.0\n     \\end{bmatrix}.\n     $$\n\nRequired final output format:\n- Your program should produce a single line of output containing the results as a comma-separated list of the four float differences $d$ in the order of the test suite cases, enclosed in square brackets, with each float rounded to six decimal places. For example, the output must have the form $[d_1,d_2,d_3,d_4]$ where each $d_j$ is reported to six decimals.\n\nNo physical units or angle units are involved in this problem. All numerical values must be handled as unitless real numbers. The solution should proceed from the foundational definitions above; do not introduce shortcut formulas in the problem statement beyond these definitions.", "solution": "We begin from the convex optimization problem $\\min_{x \\in \\Delta_n} f(x)$ where $f(x) = \\max_{i \\in \\{1,\\dots,K\\}} c_i^\\top x$ and each $c_i \\in \\mathbb{R}^n$ is fixed. The function $f$ is convex because it is the pointwise maximum of affine functions. A subgradient at a point $x$ can be chosen from the set $\\{c_i : i \\in \\arg\\max_j c_j^\\top x\\}$, which is a direct consequence of the subgradient characterization for the maximum of convex functions.\n\nEuclidean projected subgradient method:\n- Constrained subgradient descent uses the principle that for a convex $f$ and a closed convex set $C$, an iteration of the form $y^{(t+1)} = x^{(t)} - \\alpha_t g^{(t)}$ with $g^{(t)} \\in \\partial f(x^{(t)})$ followed by projection $x^{(t+1)} = P_C(y^{(t+1)})$ ensures feasibility and nonexpansiveness with respect to the Euclidean norm. The Euclidean projection $P_{\\Delta_n}$ solves $\\min_{x \\in \\Delta_n} \\|x - y\\|_2$, and admits a unique solution. For the simplex, this solution has the structure $x_i = \\max\\{y_i - \\tau, 0\\}$ for a threshold $\\tau$ chosen so that $\\sum_i x_i = 1$, which can be found in $O(n \\log n)$ time by sorting $y$ and selecting an index that satisfies the complementary slackness conditions.\n\nMirror descent with negative entropy:\n- Mirror descent is derived from proximal minimization with a geometry induced by a strictly convex mirror map $\\psi$. Given $\\psi(x) = \\sum_{i=1}^n x_i \\log x_i$ defined on the interior of the simplex, the associated Bregman divergence is\n$$\nD_\\psi(x,y) = \\sum_{i=1}^n x_i \\log \\frac{x_i}{y_i} - \\sum_{i=1}^n (x_i - y_i),\n$$\nwhich, up to an additive constant, is the Kullback–Leibler divergence. The mirror descent update at iteration $t$ solves\n$$\nx^{(t+1)} = \\arg\\min_{x \\in \\Delta_n} \\left\\{ \\alpha_t \\, g^{(t)}{}^\\top x + D_\\psi(x, x^{(t)}) \\right\\},\n$$\nwhere $g^{(t)} \\in \\partial f(x^{(t)})$. The first-order optimality conditions for this strictly convex problem yield, for some Lagrange multiplier $\\lambda$ enforcing $\\sum_i x_i = 1$,\n$$\n\\alpha_t g^{(t)} + \\nabla \\psi(x^{(t+1)}) - \\nabla \\psi(x^{(t)}) + \\lambda \\mathbf{1} = 0.\n$$\nUsing $\\nabla \\psi(x)_i = \\log x_i + 1$, this simplifies (after eliminating $\\lambda$ by normalization) to the multiplicative weights update\n$$\nx^{(t+1)}_i \\propto x^{(t)}_i \\exp\\left(-\\alpha_t g^{(t)}_i\\right),\n$$\nwith proportionality constant chosen so that $\\sum_i x^{(t+1)}_i = 1$. This update preserves positivity and adjusts weights geometrically according to the subgradient components.\n\nWhy mirror descent geometry can outperform Euclidean projection on the simplex:\n- The simplex $\\Delta_n$ is a probability geometry where positivity and normalization are intrinsic constraints. The negative entropy mirror map induces the Kullback–Leibler divergence, which is naturally aligned with multiplicative changes in probabilities. This geometry yields updates that stay strictly inside the simplex, avoid abrupt truncation to zero, and modulate coordinates multiplicatively. In contrast, Euclidean projection can cause large coordinates to be truncated aggressively by the thresholding effect of projection, especially when step sizes momentarily overshoot. This can lead to oscillatory behavior near the boundary, frequent changes in active constraints, and loss of information due to zeros that cannot be revived without specific structural cues.\n- For functions like $f(x) = \\max_i c_i^\\top x$ with potentially spiky subgradients, mirror descent can dampen the influence of large components via exponentiation and normalization, adapting smoothly to anisotropy. Euclidean projection operates additively; when gradients are highly nonuniform, additive steps followed by clipping can introduce zig-zag trajectories that slow progress in objective value.\n\nAlgorithmic design details used in the program:\n- Initialize $x^{(0)}$ to the uniform point $x^{(0)} = \\left(\\frac{1}{n},\\dots,\\frac{1}{n}\\right)$.\n- At each iteration $t$ for both methods, select a subgradient $g^{(t)} = c_k$ where $k \\in \\arg\\max_i c_i^\\top x^{(t)}$. For determinism, select the smallest index $k$ in the argmax set.\n- Use the common diminishing step-size $\\alpha_t = \\frac{\\alpha_0}{\\sqrt{t+1}}$ with $\\alpha_0 = 0.5$ for $t = 0, 1, \\dots, T-1$, and set $T = 300$ iterations.\n- Projected subgradient method: compute $y^{(t+1)} = x^{(t)} - \\alpha_t g^{(t)}$, then project onto $\\Delta_n$ using the Euclidean projection onto the simplex, which can be implemented via sorting $y$, computing a threshold $\\tau$, and applying $x^{(t+1)}_i = \\max\\{y^{(t+1)}_i - \\tau, 0\\}$ so that $\\sum_i x^{(t+1)}_i = 1$.\n- Mirror descent: compute the multiplicative weights update $x^{(t+1)}_i \\propto x^{(t)}_i \\exp\\left(-\\alpha_t g^{(t)}_i\\right)$ and renormalize to enforce $\\sum_i x^{(t+1)}_i = 1$.\n- After $T$ iterations, compute $f_{\\text{proj}} = \\max_i c_i^\\top x_{\\text{proj}}^{(T)}$ and $f_{\\text{mirror}} = \\max_i c_i^\\top x_{\\text{mirror}}^{(T)}$, then report $d = f_{\\text{proj}} - f_{\\text{mirror}}$.\n\nTest suite rationale:\n- Case A has mixed positive and negative coefficients, promoting interior behavior with competing linear functionals; mirror descent's geometry is expected to yield smooth progress.\n- Case B has spiky gradients and anisotropy, making additive steps plus projection prone to clipping; mirror descent often handles such anisotropy better.\n- Case C has rows that are almost colinear, yielding a landscape where $f$ is practically constant across $x \\in \\Delta_n$ (indeed exactly constant when taking the maximum among constants); both methods should yield the same objective, leading to $d$ near zero.\n- Case D has three linear functionals affecting only the first three coordinates. The remaining coordinates incur zero cost, so the minimum of $f$ is achieved by concentrating all mass on coordinates with zero coefficients (a vertex among those). Euclidean projection may approach such vertices faster by aggressive truncation, while mirror descent, due to its interior geometry, can move more cautiously, potentially yielding $d  0$.\n\nThe program implements these algorithms exactly as derived and prints the four differences $d$ for the specified test suite, rounded to six decimals, in the required single-line format.", "answer": "```python\nimport numpy as np\n\ndef project_onto_simplex(v):\n    \"\"\"\n    Euclidean projection onto the probability simplex:\n    Solve min_x ||x - v||_2 subject to x = 0, sum x = 1.\n    \"\"\"\n    n = v.size\n    # Sort v in descending order\n    u = np.sort(v)[::-1]\n    cssv = np.cumsum(u)\n    # Find rho: the largest j such that u_j - (cssv_j - 1)/j  0\n    j = np.arange(1, n + 1)\n    cond = u - (cssv - 1) / j > 0\n    if not np.any(cond):\n        # In degenerate case, distribute uniformly\n        theta = (cssv[-1] - 1) / n\n    else:\n        rho = np.nonzero(cond)[0][-1]\n        theta = (cssv[rho] - 1) / (rho + 1)\n    w = v - theta\n    w = np.maximum(w, 0.0)\n    # Numerical guard to enforce sum to 1 exactly due to possible rounding\n    s = w.sum()\n    if s = 0:\n        # fallback uniform\n        w = np.ones(n) / n\n    else:\n        w /= s\n    return w\n\ndef subgradient_max_linear(C, x):\n    \"\"\"\n    Subgradient of f(x) = max_i c_i^T x at x: choose c_k with k in argmax.\n    Deterministic tie-breaking: smallest index k.\n    \"\"\"\n    values = C @ x\n    k = int(np.argmax(values))\n    return C[k]\n\ndef projected_subgradient(C, x0, T, alpha0):\n    x = x0.copy()\n    for t in range(T):\n        alpha_t = alpha0 / np.sqrt(t + 1)\n        g = subgradient_max_linear(C, x)\n        y = x - alpha_t * g\n        x = project_onto_simplex(y)\n    return x\n\ndef mirror_descent_entropy(C, x0, T, alpha0):\n    x = x0.copy()\n    for t in range(T):\n        alpha_t = alpha0 / np.sqrt(t + 1)\n        g = subgradient_max_linear(C, x)\n        # Multiplicative weights update\n        # Prevent overflow/underflow via clipping exponent argument\n        # However, typical magnitudes here are small; proceed directly.\n        update = x * np.exp(-alpha_t * g)\n        s = update.sum()\n        if s = 0 or not np.isfinite(s):\n            # Fallback to uniform if numerical issues\n            x = np.ones_like(x) / x.size\n        else:\n            x = update / s\n    return x\n\ndef f_max_linear(C, x):\n    return float(np.max(C @ x))\n\ndef run_case(C, T=300, alpha0=0.5):\n    n = C.shape[1]\n    x0 = np.ones(n) / n\n    x_proj = projected_subgradient(C, x0, T, alpha0)\n    x_mirror = mirror_descent_entropy(C, x0, T, alpha0)\n    f_proj = f_max_linear(C, x_proj)\n    f_mirror = f_max_linear(C, x_mirror)\n    return f_proj - f_mirror\n\ndef solve():\n    # Define the test cases from the problem statement.\n    test_cases = [\n        np.array([\n            [0.2, 0.3, -0.1, 0.0, 0.4, -0.2],\n            [-0.1, 0.5, 0.2, -0.3, 0.1, 0.0],\n            [0.3, -0.2, 0.1, 0.2, -0.1, 0.4],\n            [0.0, 0.1, 0.3, 0.5, -0.4, 0.2]\n        ], dtype=float),\n        np.array([\n            [2.0, -1.0, 0.5, 0.0, -0.5, 0.0],\n            [-1.5, 1.0, -0.5, 0.2, 0.1, 0.0],\n            [1.0, -0.5, 1.5, -1.0, 0.0, 0.0]\n        ], dtype=float),\n        np.array([\n            [0.5, 0.5, 0.5, 0.5, 0.5, 0.5],\n            [0.45, 0.45, 0.45, 0.45, 0.45, 0.45],\n            [0.52, 0.52, 0.52, 0.52, 0.52, 0.52]\n        ], dtype=float),\n        np.array([\n            [1.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n            [0.0, 1.0, 0.0, 0.0, 0.0, 0.0],\n            [0.0, 0.0, 1.0, 0.0, 0.0, 0.0]\n        ], dtype=float),\n    ]\n\n    T = 300\n    alpha0 = 0.5\n\n    results = []\n    for C in test_cases:\n        d = run_case(C, T=T, alpha0=alpha0)\n        results.append(d)\n\n    # Final print statement in the exact required format: 6 decimals.\n    formatted = \"[\" + \",\".join(f\"{r:.6f}\" for r in results) + \"]\"\n    print(formatted)\n\nsolve()\n```", "id": "3165049"}, {"introduction": "An algorithm's true character is revealed under stress. This final exercise moves from implementation to analysis, asking you to run your code on a suite of carefully designed hypothetical test cases. By comparing the performance of Mirror Descent and Projected Subgradient on landscapes with different features—from spiky gradients to nearly flat surfaces—you will build a strong intuition for the practical strengths and weaknesses of each geometric approach [@problem_id:3165049].", "problem": "You are asked to implement and compare two first-order methods for constrained convex optimization on the probability simplex: the Euclidean projected subgradient method and mirror descent with the negative entropy mirror map. The target function is the pointwise maximum of linear functionals. The comparison must be driven from first principles and evaluated on a fixed test suite.\n\nFundamental base definitions to use:\n- A function $f:\\mathbb{R}^n \\to \\mathbb{R}$ is convex if for all $x,y \\in \\mathbb{R}^n$ and $\\lambda \\in [0,1]$, $f(\\lambda x + (1-\\lambda) y) \\le \\lambda f(x) + (1-\\lambda) f(y)$. For $f(x) = \\max_{i \\in \\{1,\\dots,K\\}} c_i^\\top x$ with given $c_i \\in \\mathbb{R}^n$, convexity follows from the fact that a pointwise maximum of affine functions is convex.\n- A subgradient $g \\in \\mathbb{R}^n$ of a convex function $f$ at $x$ satisfies $f(y) \\ge f(x) + g^\\top (y - x)$ for all $y$. For $f(x) = \\max_i c_i^\\top x$, any $c_k$ where $k$ attains the maximum $c_k^\\top x$ is a valid subgradient.\n- The Euclidean projection of a point $y \\in \\mathbb{R}^n$ onto a nonempty closed convex set $C$ is the unique point $P_C(y)$ minimizing $\\|x - y\\|_2$ over $x \\in C$.\n- The probability simplex in $\\mathbb{R}^n$ is $\\Delta_n = \\{x \\in \\mathbb{R}^n \\mid x_i \\ge 0 \\text{ for all } i, \\ \\sum_{i=1}^n x_i = 1\\}$.\n- Given a strictly convex and differentiable function (the mirror map) $\\psi:\\text{int}(\\Delta_n) \\to \\mathbb{R}$, the Bregman divergence generated by $\\psi$ is $D_\\psi(x,y) = \\psi(x) - \\psi(y) - \\nabla \\psi(y)^\\top (x-y)$. For the negative entropy mirror map $\\psi(x) = \\sum_{i=1}^n x_i \\log x_i$ defined on the interior of the simplex, $D_\\psi$ reduces to the Kullback–Leibler divergence up to an additive constant.\n\nTask:\n- Consider the constrained minimization problem $\\min_{x \\in \\Delta_n} f(x)$ with $f(x) = \\max_{i \\in \\{1,\\dots,K\\}} c_i^\\top x$.\n- Implement two iterative methods starting from the uniform point $x^{(0)} = \\left(\\frac{1}{n},\\dots,\\frac{1}{n}\\right)$:\n  1. Euclidean projected subgradient method: at iteration $t$, choose a subgradient $g^{(t)}$ of $f$ at $x^{(t)}$, take a Euclidean step $y^{(t+1)} = x^{(t)} - \\alpha_t g^{(t)}$, and compute $x^{(t+1)}$ as the Euclidean projection of $y^{(t+1)}$ onto $\\Delta_n$.\n  2. Mirror descent with negative entropy: at iteration $t$, choose a subgradient $g^{(t)}$ of $f$ at $x^{(t)}$, and compute $x^{(t+1)}$ as the minimizer over $\\Delta_n$ of the first-order proximal subproblem with the Bregman divergence $D_\\psi$ corresponding to $\\psi(x) = \\sum_{i=1}^n x_i \\log x_i$, i.e., $x^{(t+1)} = \\arg\\min_{x \\in \\Delta_n} \\left\\{ \\alpha_t \\, g^{(t)}{}^\\top x + D_\\psi(x, x^{(t)}) \\right\\}$.\n- Use the diminishing step-size schedule $\\alpha_t = \\frac{\\alpha_0}{\\sqrt{t+1}}$ with $\\alpha_0 = 0.5$ for $t = 0,1,\\dots,T-1$, and run for $T = 300$ iterations. All indices $t$, $n$, $K$, $\\alpha_0$, and $T$ must be treated exactly as defined here.\n\nExperimental design and evaluation:\n- For each test case, after $T$ iterations, compute $f_{\\text{proj}} = \\max_i c_i^\\top x_{\\text{proj}}^{(T)}$ and $f_{\\text{mirror}} = \\max_i c_i^\\top x_{\\text{mirror}}^{(T)}$, where $x_{\\text{proj}}^{(T)}$ and $x_{\\text{mirror}}^{(T)}$ are the final iterates of the Euclidean projected subgradient and mirror descent methods, respectively. Then report the difference $d = f_{\\text{proj}} - f_{\\text{mirror}}$ as a float. A positive $d$ indicates that mirror descent achieved a lower final objective value relative to Euclidean projection under the same step-size schedule and iteration budget.\n\nTest suite:\n- Dimension $n = 6$ for all cases. Each test case is specified by a matrix $C \\in \\mathbb{R}^{K \\times n}$ with rows $c_i^\\top$. Use exactly the following four cases.\n  1. Case A (moderately mixed coefficients, interior behavior):\n     $$\n     C = \\begin{bmatrix}\n     0.2  0.3  -0.1  0.0  0.4  -0.2 \\\\\n     -0.1  0.5  0.2  -0.3  0.1  0.0 \\\\\n     0.3  -0.2  0.1  0.2  -0.1  0.4 \\\\\n     0.0  0.1  0.3  0.5  -0.4  0.2\n     \\end{bmatrix}.\n     $$\n  2. Case B (spiky gradients, anisotropic geometry):\n     $$\n     C = \\begin{bmatrix}\n     2.0  -1.0  0.5  0.0  -0.5  0.0 \\\\\n     -1.5  1.0  -0.5  0.2  0.1  0.0 \\\\\n     1.0  -0.5  1.5  -1.0  0.0  0.0\n     \\end{bmatrix}.\n     $$\n  3. Case C (nearly colinear rows, flat landscape):\n     $$\n     C = \\begin{bmatrix}\n     0.5  0.5  0.5  0.5  0.5  0.5 \\\\\n     0.45  0.45  0.45  0.45  0.45  0.45 \\\\\n     0.52  0.52  0.52  0.52  0.52  0.52\n     \\end{bmatrix}.\n     $$\n  4. Case D (vertex-optimal due to zero-cost coordinates):\n     $$\n     C = \\begin{bmatrix}\n     1.0  0.0  0.0  0.0  0.0  0.0 \\\\\n     0.0  1.0  0.0  0.0  0.0  0.0 \\\\\n     0.0  0.0  1.0  0.0  0.0  0.0\n     \\end{bmatrix}.\n     $$\n\nRequired final output format:\n- Your program should produce a single line of output containing the results as a comma-separated list of the four float differences $d$ in the order of the test suite cases, enclosed in square brackets, with each float rounded to six decimal places. For example, the output must have the form $[d_1,d_2,d_3,d_4]$ where each $d_j$ is reported to six decimals.\n\nNo physical units or angle units are involved in this problem. All numerical values must be handled as unitless real numbers. The solution should proceed from the foundational definitions above; do not introduce shortcut formulas in the problem statement beyond these definitions.", "solution": "We begin from the convex optimization problem $\\min_{x \\in \\Delta_n} f(x)$ where $f(x) = \\max_{i \\in \\{1,\\dots,K\\}} c_i^\\top x$ and each $c_i \\in \\mathbb{R}^n$ is fixed. The function $f$ is convex because it is the pointwise maximum of affine functions. A subgradient at a point $x$ can be chosen from the set $\\{c_i : i \\in \\arg\\max_j c_j^\\top x\\}$, which is a direct consequence of the subgradient characterization for the maximum of convex functions.\n\nEuclidean projected subgradient method:\n- Constrained subgradient descent uses the principle that for a convex $f$ and a closed convex set $C$, an iteration of the form $y^{(t+1)} = x^{(t)} - \\alpha_t g^{(t)}$ with $g^{(t)} \\in \\partial f(x^{(t)})$ followed by projection $x^{(t+1)} = P_C(y^{(t+1)})$ ensures feasibility and nonexpansiveness with respect to the Euclidean norm. The Euclidean projection $P_{\\Delta_n}$ solves $\\min_{x \\in \\Delta_n} \\|x - y\\|_2$, and admits a unique solution. For the simplex, this solution has the structure $x_i = \\max\\{y_i - \\tau, 0\\}$ for a threshold $\\tau$ chosen so that $\\sum_i x_i = 1$, which can be found in $O(n \\log n)$ time by sorting $y$ and selecting an index that satisfies the complementary slackness conditions.\n\nMirror descent with negative entropy:\n- Mirror descent is derived from proximal minimization with a geometry induced by a strictly convex mirror map $\\psi$. Given $\\psi(x) = \\sum_{i=1}^n x_i \\log x_i$ defined on the interior of the simplex, the associated Bregman divergence is\n$$\nD_\\psi(x,y) = \\sum_{i=1}^n x_i \\log \\frac{x_i}{y_i} - \\sum_{i=1}^n (x_i - y_i),\n$$\nwhich, up to an additive constant, is the Kullback–Leibler divergence. The mirror descent update at iteration $t$ solves\n$$\nx^{(t+1)} = \\arg\\min_{x \\in \\Delta_n} \\left\\{ \\alpha_t \\, g^{(t)}{}^\\top x + D_\\psi(x, x^{(t)}) \\right\\},\n$$\nwhere $g^{(t)} \\in \\partial f(x^{(t)})$. The first-order optimality conditions for this strictly convex problem yield, for some Lagrange multiplier $\\lambda$ enforcing $\\sum_i x_i = 1$,\n$$\n\\alpha_t g^{(t)} + \\nabla \\psi(x^{(t+1)}) - \\nabla \\psi(x^{(t)}) + \\lambda \\mathbf{1} = 0.\n$$\nUsing $\\nabla \\psi(x)_i = \\log x_i + 1$, this simplifies (after eliminating $\\lambda$ by normalization) to the multiplicative weights update\n$$\nx^{(t+1)}_i \\propto x^{(t)}_i \\exp\\left(-\\alpha_t g^{(t)}_i\\right),\n$$\nwith proportionality constant chosen so that $\\sum_i x^{(t+1)}_i = 1$. This update preserves positivity and adjusts weights geometrically according to the subgradient components.\n\nWhy mirror descent geometry can outperform Euclidean projection on the simplex:\n- The simplex $\\Delta_n$ is a probability geometry where positivity and normalization are intrinsic constraints. The negative entropy mirror map induces the Kullback–Leibler divergence, which is naturally aligned with multiplicative changes in probabilities. This geometry yields updates that stay strictly inside the simplex, avoid abrupt truncation to zero, and modulate coordinates multiplicatively. In contrast, Euclidean projection can cause large coordinates to be truncated aggressively by the thresholding effect of projection, especially when step sizes momentarily overshoot. This can lead to oscillatory behavior near the boundary, frequent changes in active constraints, and loss of information due to zeros that cannot be revived without specific structural cues.\n- For functions like $f(x) = \\max_i c_i^\\top x$ with potentially spiky subgradients, mirror descent can dampen the influence of large components via exponentiation and normalization, adapting smoothly to anisotropy. Euclidean projection operates additively; when gradients are highly nonuniform, additive steps followed by clipping can introduce zig-zag trajectories that slow progress in objective value.\n\nAlgorithmic design details used in the program:\n- Initialize $x^{(0)}$ to the uniform point $x^{(0)} = \\left(\\frac{1}{n},\\dots,\\frac{1}{n}\\right)$.\n- At each iteration $t$ for both methods, select a subgradient $g^{(t)} = c_k$ where $k \\in \\arg\\max_i c_i^\\top x^{(t)}$. For determinism, select the smallest index $k$ in the argmax set.\n- Use the common diminishing step-size $\\alpha_t = \\frac{\\alpha_0}{\\sqrt{t+1}}$ with $\\alpha_0 = 0.5$ for $t = 0, 1, \\dots, T-1$, and set $T = 300$ iterations.\n- Projected subgradient method: compute $y^{(t+1)} = x^{(t)} - \\alpha_t g^{(t)}$, then project onto $\\Delta_n$ using the Euclidean projection onto the simplex, which can be implemented via sorting $y$, computing a threshold $\\tau$, and applying $x^{(t+1)}_i = \\max\\{y^{(t+1)}_i - \\tau, 0\\}$ so that $\\sum_i x^{(t+1)}_i = 1$.\n- Mirror descent: compute the multiplicative weights update $x^{(t+1)}_i \\propto x^{(t)}_i \\exp\\left(-\\alpha_t g^{(t)}_i\\right)$ and renormalize to enforce $\\sum_i x^{(t+1)}_i = 1$.\n- After $T$ iterations, compute $f_{\\text{proj}} = \\max_i c_i^\\top x_{\\text{proj}}^{(T)}$ and $f_{\\text{mirror}} = \\max_i c_i^\\top x_{\\text{mirror}}^{(T)}$, then report $d = f_{\\text{proj}} - f_{\\text{mirror}}$.\n\nTest suite rationale:\n- Case A has mixed positive and negative coefficients, promoting interior behavior with competing linear functionals; mirror descent's geometry is expected to yield smooth progress.\n- Case B has spiky gradients and anisotropy, making additive steps plus projection prone to clipping; mirror descent often handles such anisotropy better.\n- Case C has rows that are almost colinear, yielding a landscape where $f$ is practically constant across $x \\in \\Delta_n$ (indeed exactly constant when taking the maximum among constants); both methods should yield the same objective, leading to $d$ near zero.\n- Case D has three linear functionals affecting only the first three coordinates. The remaining coordinates incur zero cost, so the minimum of $f$ is achieved by concentrating all mass on coordinates with zero coefficients (a vertex among those). Euclidean projection may approach such vertices faster by aggressive truncation, while mirror descent, due to its interior geometry, can move more cautiously, potentially yielding $d  0$.\n\nThe program implements these algorithms exactly as derived and prints the four differences $d$ for the specified test suite, rounded to six decimals, in the required single-line format.", "answer": "```python\nimport numpy as np\n\ndef project_onto_simplex(v):\n    \"\"\"\n    Euclidean projection onto the probability simplex:\n    Solve min_x ||x - v||_2 subject to x = 0, sum x = 1.\n    \"\"\"\n    n = v.size\n    # Sort v in descending order\n    u = np.sort(v)[::-1]\n    cssv = np.cumsum(u)\n    # Find rho: the largest j such that u_j - (cssv_j - 1)/j  0\n    j = np.arange(1, n + 1)\n    cond = u - (cssv - 1) / j > 0\n    if not np.any(cond):\n        # In degenerate case, distribute uniformly\n        theta = (cssv[-1] - 1) / n\n    else:\n        rho = np.nonzero(cond)[0][-1]\n        theta = (cssv[rho] - 1) / (rho + 1)\n    w = v - theta\n    w = np.maximum(w, 0.0)\n    # Numerical guard to enforce sum to 1 exactly due to possible rounding\n    s = w.sum()\n    if s = 0:\n        # fallback uniform\n        w = np.ones(n) / n\n    else:\n        w /= s\n    return w\n\ndef subgradient_max_linear(C, x):\n    \"\"\"\n    Subgradient of f(x) = max_i c_i^T x at x: choose c_k with k in argmax.\n    Deterministic tie-breaking: smallest index k.\n    \"\"\"\n    values = C @ x\n    k = int(np.argmax(values))\n    return C[k]\n\ndef projected_subgradient(C, x0, T, alpha0):\n    x = x0.copy()\n    for t in range(T):\n        alpha_t = alpha0 / np.sqrt(t + 1)\n        g = subgradient_max_linear(C, x)\n        y = x - alpha_t * g\n        x = project_onto_simplex(y)\n    return x\n\ndef mirror_descent_entropy(C, x0, T, alpha0):\n    x = x0.copy()\n    for t in range(T):\n        alpha_t = alpha0 / np.sqrt(t + 1)\n        g = subgradient_max_linear(C, x)\n        # Multiplicative weights update\n        # Prevent overflow/underflow via clipping exponent argument\n        # However, typical magnitudes here are small; proceed directly.\n        update = x * np.exp(-alpha_t * g)\n        s = update.sum()\n        if s = 0 or not np.isfinite(s):\n            # Fallback to uniform if numerical issues\n            x = np.ones_like(x) / x.size\n        else:\n            x = update / s\n    return x\n\ndef f_max_linear(C, x):\n    return float(np.max(C @ x))\n\ndef run_case(C, T=300, alpha0=0.5):\n    n = C.shape[1]\n    x0 = np.ones(n) / n\n    x_proj = projected_subgradient(C, x0, T, alpha0)\n    x_mirror = mirror_descent_entropy(C, x0, T, alpha0)\n    f_proj = f_max_linear(C, x_proj)\n    f_mirror = f_max_linear(C, x_mirror)\n    return f_proj - f_mirror\n\ndef solve():\n    # Define the test cases from the problem statement.\n    test_cases = [\n        np.array([\n            [0.2, 0.3, -0.1, 0.0, 0.4, -0.2],\n            [-0.1, 0.5, 0.2, -0.3, 0.1, 0.0],\n            [0.3, -0.2, 0.1, 0.2, -0.1, 0.4],\n            [0.0, 0.1, 0.3, 0.5, -0.4, 0.2]\n        ], dtype=float),\n        np.array([\n            [2.0, -1.0, 0.5, 0.0, -0.5, 0.0],\n            [-1.5, 1.0, -0.5, 0.2, 0.1, 0.0],\n            [1.0, -0.5, 1.5, -1.0, 0.0, 0.0]\n        ], dtype=float),\n        np.array([\n            [0.5, 0.5, 0.5, 0.5, 0.5, 0.5],\n            [0.45, 0.45, 0.45, 0.45, 0.45, 0.45],\n            [0.52, 0.52, 0.52, 0.52, 0.52, 0.52]\n        ], dtype=float),\n        np.array([\n            [1.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n            [0.0, 1.0, 0.0, 0.0, 0.0, 0.0],\n            [0.0, 0.0, 1.0, 0.0, 0.0, 0.0]\n        ], dtype=float),\n    ]\n\n    T = 300\n    alpha0 = 0.5\n\n    results = []\n    for C in test_cases:\n        d = run_case(C, T=T, alpha0=alpha0)\n        results.append(d)\n\n    # Final print statement in the exact required format: 6 decimals.\n    formatted = \"[\" + \",\".join(f\"{r:.6f}\" for r in results) + \"]\"\n    print(formatted)\n\nsolve()\n```", "id": "3165049"}]}