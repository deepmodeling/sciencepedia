{"hands_on_practices": [{"introduction": "This first practice tackles a foundational resource allocation problem, a classic scenario where dual decomposition excels. Here, you will analytically derive the solution for a system where several agents must share a single resource while respecting their own local constraints. By working through this exercise [@problem_id:3122710], you will gain hands-on experience in defining the dual problem, solving the decentralized subproblems as a function of the resource price, and determining the optimal price that brings the system to an equilibrium that is both feasible and optimal.", "problem": "Consider the separable convex optimization problem of allocating a single shared resource across three agents with local bound constraints. The primal problem is to minimize the sum of local convex costs subject to a single linear coupling constraint and individual bounds:\n$$\n\\min_{x_1,x_2,x_3} \\;\\; f_1(x_1)+f_2(x_2)+f_3(x_3) \\quad \\text{subject to} \\quad l_i \\le x_i \\le u_i \\; \\text{for } i\\in\\{1,2,3\\}, \\;\\; x_1+x_2+x_3=b,\n$$\nwhere the local costs are quadratic,\n$$\nf_i(x_i)=\\frac{1}{2}q_i x_i^2+r_i x_i,\n$$\nand the parameters are\n$$\nq_1=2, \\;\\; r_1=1, \\;\\; l_1=0, \\;\\; u_1=2, \\\\\nq_2=1, \\;\\; r_2=-2, \\;\\; l_2=1, \\;\\; u_2=3, \\\\\nq_3=3, \\;\\; r_3=0, \\;\\; l_3=-1, \\;\\; u_3=1, \\\\\nb=1.\n$$\nStarting from the definitions of the Lagrangian, the dual function, and the Karush–Kuhn–Tucker (KKT) conditions, use dual decomposition to:\n1. Derive the closed-form solution of each agent’s subproblem as a function of the dual variable for the coupling constraint.\n2. Determine the unique optimal dual price for the resource that is consistent with primal feasibility and optimality.\n\nExplain what this dual price represents economically in terms of marginal valuation of the shared resource and how the presence of bound constraints affects the local decisions through this price. Your final reported quantity must be the optimal dual price as a single real number. Round your final numerical answer to four significant figures.", "solution": "The problem presented is a convex optimization problem with a separable objective function and a single linear coupling constraint, along with individual bound constraints. This is a classic resource allocation problem.\n\n### Step 1: Problem Validation\n\n**1. Extraction of Givens:**\nThe optimization problem is:\n$$\n\\min_{x_1,x_2,x_3} \\sum_{i=1}^3 f_i(x_i) \\quad \\text{subject to} \\quad x_1+x_2+x_3=b, \\quad l_i \\le x_i \\le u_i \\text{ for } i\\in\\{1,2,3\\}\n$$\nThe local cost functions are quadratic:\n$$\nf_i(x_i) = \\frac{1}{2}q_i x_i^2 + r_i x_i\n$$\nThe parameters are given as:\n- Agent 1: $q_1=2$, $r_1=1$, $l_1=0$, $u_1=2$\n- Agent 2: $q_2=1$, $r_2=-2$, $l_2=1$, $u_2=3$\n- Agent 3: $q_3=3$, $r_3=0$, $l_3=-1$, $u_3=1$\n- Coupling constraint: $b=1$\n\n**2. Validation using Extracted Givens:**\n- **Scientifically Grounded:** The problem is a Quadratic Program (QP), a fundamental topic in convex optimization. Dual decomposition is a standard and well-established method for solving such separable problems. The problem is firmly grounded in mathematical optimization theory.\n- **Well-Posed:** The objective function is a sum of quadratic functions $f_i(x_i)$ with $q_i > 0$. Therefore, each $f_i(x_i)$ is strictly convex, making the total objective function $f(x_1,x_2,x_3) = \\sum f_i(x_i)$ strictly convex. The feasible set is defined by linear equality and inequality constraints, which form a non-empty, closed, and convex set (a polytope). A strictly convex function minimized over a non-empty, closed, convex set has a unique global minimum. The feasible set is non-empty because the sum of lower bounds $\\sum l_i = 0+1-1=0$ and the sum of upper bounds $\\sum u_i = 2+3+1=6$ bracket the required sum $b=1$. Thus, a unique solution exists.\n- **Objective:** The problem is stated using precise mathematical language and provides all necessary numerical data. It is free from subjective or ambiguous statements.\n\n**3. Verdict and Action:**\nThe problem is valid. We proceed with the solution.\n\n### Step 2: Formulation and Solution using Dual Decomposition\n\nThe core idea of dual decomposition is to relax the coupling constraint by introducing a Lagrange multiplier (dual variable), which decomposes the problem into smaller, independent subproblems.\n\n**1. The Lagrangian and Dual Function:**\nWe introduce a single dual variable $\\nu$ for the coupling constraint $x_1+x_2+x_3-b=0$. The Lagrangian of the problem is:\n$$\nL(x_1, x_2, x_3, \\nu) = \\sum_{i=1}^3 \\left( \\frac{1}{2}q_i x_i^2 + r_i x_i \\right) + \\nu \\left( \\sum_{i=1}^3 x_i - b \\right)\n$$\nThe bound constraints $l_i \\le x_i \\le u_i$ are not relaxed and will be handled within the subproblems. The Lagrangian is separable in the variables $x_i$:\n$$\nL(x_1, x_2, x_3, \\nu) = \\sum_{i=1}^3 \\left( \\frac{1}{2}q_i x_i^2 + r_i x_i + \\nu x_i \\right) - \\nu b\n$$\nThe dual function $g(\\nu)$ is defined as the minimum of the Lagrangian over the primal variables $x_i$ subject to their local bound constraints:\n$$\ng(\\nu) = \\min_{l_i \\le x_i \\le u_i, \\forall i} L(x_1, x_2, x_3, \\nu) = \\sum_{i=1}^3 \\left( \\min_{l_i \\le x_i \\le u_i} \\left\\{ \\frac{1}{2}q_i x_i^2 + (r_i+\\nu) x_i \\right\\} \\right) - \\nu b\n$$\n\n**2. Derivation of Agent Subproblem Solutions:**\nEach agent $i$ must solve an independent subproblem to find its resource allocation $x_i(\\nu)$ as a function of the dual price $\\nu$:\n$$\nx_i(\\nu) = \\arg\\min_{l_i \\le x_i \\le u_i} \\left\\{ \\frac{1}{2}q_i x_i^2 + (r_i+\\nu) x_i \\right\\}\n$$\nThis is a problem of minimizing a strictly convex quadratic function over a closed interval. The unconstrained minimizer is found by setting the derivative with respect to $x_i$ to zero:\n$$\nq_i x_i + r_i + \\nu = 0 \\implies x_i^{\\text{unconstrained}} = -\\frac{r_i+\\nu}{q_i}\n$$\nThe solution to the constrained subproblem is the projection of this unconstrained minimizer onto the feasible interval $[l_i, u_i]$. This is achieved by clipping or saturating the value at the bounds:\n$$\nx_i(\\nu) = \\max\\left(l_i, \\min\\left(u_i, -\\frac{r_i+\\nu}{q_i}\\right)\\right)\n$$\nThis can be written as a piecewise function:\n$$\nx_i(\\nu) = \\begin{cases} u_i  \\text{if } -\\frac{r_i+\\nu}{q_i} > u_i \\\\ -\\frac{r_i+\\nu}{q_i}  \\text{if } l_i \\le -\\frac{r_i+\\nu}{q_i} \\le u_i \\\\ l_i  \\text{if } -\\frac{r_i+\\nu}{q_i}  l_i \\end{cases}\n$$\nNow, we apply the given parameters to find the specific solution for each agent:\n\n- **Agent 1:** $q_1=2, r_1=1, l_1=0, u_1=2$. The unconstrained solution is $x_1^{\\text{uc}}(\\nu) = -\\frac{1+\\nu}{2}$.\n  The active region is $0 \\le -\\frac{1+\\nu}{2} \\le 2$, which simplifies to $-5 \\le \\nu \\le -1$.\n  $$x_1(\\nu) = \\begin{cases} 2  \\text{if } \\nu  -5 \\\\ -\\frac{1}{2}(1+\\nu)  \\text{if } -5 \\le \\nu \\le -1 \\\\ 0  \\text{if } \\nu  -1 \\end{cases}$$\n\n- **Agent 2:** $q_2=1, r_2=-2, l_2=1, u_2=3$. The unconstrained solution is $x_2^{\\text{uc}}(\\nu) = -\\frac{-2+\\nu}{1} = 2-\\nu$.\n  The active region is $1 \\le 2-\\nu \\le 3$, which simplifies to $-1 \\le \\nu \\le 1$.\n  $$x_2(\\nu) = \\begin{cases} 3  \\text{if } \\nu  -1 \\\\ 2-\\nu  \\text{if } -1 \\le \\nu \\le 1 \\\\ 1  \\text{if } \\nu  1 \\end{cases}$$\n\n- **Agent 3:** $q_3=3, r_3=0, l_3=-1, u_3=1$. The unconstrained solution is $x_3^{\\text{uc}}(\\nu) = -\\frac{0+\\nu}{3} = -\\frac{\\nu}{3}$.\n  The active region is $-1 \\le -\\frac{\\nu}{3} \\le 1$, which simplifies to $-3 \\le \\nu \\le 3$.\n  $$x_3(\\nu) = \\begin{cases} 1  \\text{if } \\nu  -3 \\\\ -\\frac{\\nu}{3}  \\text{if } -3 \\le \\nu \\le 3 \\\\ -1  \\text{if } \\nu  3 \\end{cases}$$\n\n**3. Determining the Optimal Dual Price:**\nThe dual problem is $\\max_{\\nu} g(\\nu)$. The optimal dual price $\\nu^*$ is found by finding the root of the derivative of the dual function. By Danskin's theorem, $\\frac{dg}{d\\nu} = \\sum_{i=1}^3 x_i(\\nu) - b$. Setting this to zero gives the condition for the optimal $\\nu^*$, which is that the choices of the agents must satisfy the resource constraint:\n$$\nS(\\nu^*) = x_1(\\nu^*) + x_2(\\nu^*) + x_3(\\nu^*) = b\n$$\nWe need to solve $S(\\nu) = 1$. The function $S(\\nu)$ is a continuous, piecewise-linear, and non-increasing function of $\\nu$. We can evaluate $S(\\nu)$ at the breakpoints of the piecewise definitions of $x_i(\\nu)$, which are $\\{-5, -3, -1, 1, 3\\}$.\n- For $\\nu=-1$: $x_1(-1)=0$, $x_2(-1)=3$, $x_3(-1) = 1/3$. $S(-1) = 0+3+1/3 = 10/3 \\approx 3.33$.\n- For $\\nu=1$: $x_1(1)=0$, $x_2(1)=1$, $x_3(1) = -1/3$. $S(1) = 0+1-1/3 = 2/3 \\approx 0.67$.\n\nSince $S(1) = 2/3  1$ and $S(-1) = 10/3  1$, the optimal value $\\nu^*$ must lie in the interval $[-1, 1]$. In this interval, the expressions for the agents' choices are:\n- $x_1(\\nu)=0$\n- $x_2(\\nu)=2-\\nu$\n- $x_3(\\nu)=-\\frac{\\nu}{3}$\n\nWe set their sum equal to $b=1$:\n$$\nS(\\nu) = 0 + (2-\\nu) + \\left(-\\frac{\\nu}{3}\\right) = 1\n$$\n$$\n2 - \\nu - \\frac{\\nu}{3} = 1\n$$\n$$\n2 - \\frac{4}{3}\\nu = 1\n$$\n$$\n1 = \\frac{4}{3}\\nu\n$$\n$$\n\\nu^* = \\frac{3}{4} = 0.75\n$$\nThis value $\\nu^*=0.75$ lies within the interval $[-1, 1]$, confirming our calculation is consistent.\n\n**4. Economic Interpretation:**\nThe optimal dual price, $\\nu^* = 0.75$, is the shadow price of the shared resource. It represents the marginal value of the resource for the system. Specifically, if the total amount of available resource $b$ were to increase by a small amount $\\Delta b$, the minimum total cost would decrease by approximately $\\nu^* \\Delta b$. A positive value like $\\nu^*=0.75$ indicates that the resource is scarce; relaxing the constraint (increasing $b$) would be beneficial and would lower the overall system cost.\n\nIn the dual decomposition framework, $\\nu^*$ acts as a coordinating market price. Each agent $i$ is presented with this price and independently minimizes its own local objective, which is its intrinsic cost $f_i(x_i)$ plus a cost for resource consumption, $\\nu^* x_i$. That is, each agent solves $\\min_{l_i \\le x_i \\le u_i} f_i(x_i) + \\nu^* x_i$.\n\nThe presence of the bound constraints $[l_i, u_i]$ is crucial. An agent's response to the price $\\nu^*$ is influenced by these limits.\n- If the unconstrained optimal choice for an agent, $-\\frac{r_i+\\nu^*}{q_i}$, falls within its bounds, the agent is said to be \"in its active region.\" At this point, the agent's marginal cost for the resource, $\\nabla f_i(x_i) = q_i x_i + r_i$, is exactly equal to the negative of the system price, $-\\nu^*$. This is the case for Agent 2 ($x_2 = 1.25$ in $[1, 3]$) and Agent 3 ($x_3 = -0.25$ in $[-1, 1]$). Indeed, $\\nabla f_2(1.25) = (1)(1.25) + (-2) = -0.75 = -\\nu^*$ and $\\nabla f_3(-0.25) = (3)(-0.25) + 0 = -0.75 = -\\nu^*$.\n- If the unconstrained choice falls outside the bounds, the agent is \"bound-constrained\" or \"saturated.\" The agent's optimal choice is to operate at the boundary closest to its unconstrained ideal point. This is the case for Agent 1. Its unconstrained ideal point for $\\nu^*=0.75$ would be $x_1 = -\\frac{1+0.75}{2} = -0.875$. Since this is below its lower bound of $l_1=0$, Agent 1 chooses $x_1=0$. In this situation, the agent's marginal cost is not equal to $-\\nu^*$; instead, the KKT conditions for the subproblem show that the incentive to change is directed \"into\" the forbidden region. For Agent 1, $\\nabla f_1(0) = 2(0)+1=1 \\ne -0.75$. The local marginal cost is higher than the system's marginal benefit, indicating that Agent 1 would ideally want to contribute a negative amount of the resource (or consume less than zero), but is prevented by its lower bound.\n\nThe final optimal allocation is $x_1^*=0$, $x_2^*=1.25$, and $x_3^*=-0.25$, which sum to $b=1$. The optimal dual price $\\nu^* = 0.75$ is the unique market price that induces these local decisions, which collectively satisfy the global resource constraint.\n\nThe problem asks for the optimal dual price rounded to four significant figures.\n$$\n\\nu^* = 0.7500\n$$", "answer": "$$\\boxed{0.7500}$$", "id": "3122710"}, {"introduction": "Building on the continuous case, this problem explores the application of dual decomposition to non-convex problems, specifically integer programming. This is a crucial extension, as many real-world decisions involve discrete choices. In this exercise [@problem_id:3122695], you will use Lagrangian relaxation to find a bound on the optimal solution and discover the concept of the integrality gap, which measures the difference between the solution of the relaxed problem and the true integer optimum. This practice highlights both the power and the nuances of dual methods when strong duality does not hold.", "problem": "Consider a separable maximization problem in which each subproblem is a small $0$-$1$ knapsack, coupled by a single shared budget. Use the definition of the Lagrangian relaxation and the Lagrangian dual function as your only starting points.\n\nThere are $2$ subsystems indexed by $i \\in \\{1,2\\}$. Each subsystem $i$ has a local knapsack capacity $W_i$ and two items, indexed by $j \\in \\{A,B\\}$. Choosing an item $(i,j)$ yields profit $c_{i,j}$, consumes local weight $w_{i,j}$ from subsystem $i$, and uses global budget amount $a_{i,j}$. Let $x_{i,j} \\in \\{0,1\\}$ indicate whether item $(i,j)$ is selected.\n\nSubsystem $1$ data:\n- Item $A_1$: profit $c_{1,A} = 10$, local weight $w_{1,A} = 3$, global budget coefficient $a_{1,A} = 4$.\n- Item $B_1$: profit $c_{1,B} = 6$, local weight $w_{1,B} = 2$, global budget coefficient $a_{1,B} = 1$.\n- Local capacity $W_1 = 3$.\n\nSubsystem $2$ data:\n- Item $A_2$: profit $c_{2,A} = 9$, local weight $w_{2,A} = 3$, global budget coefficient $a_{2,A} = 3$.\n- Item $B_2$: profit $c_{2,B} = 5$, local weight $w_{2,B} = 2$, global budget coefficient $a_{2,B} = 2$.\n- Local capacity $W_2 = 3$.\n\nShared budget: $\\sum_{i \\in \\{1,2\\}} \\sum_{j \\in \\{A,B\\}} a_{i,j} x_{i,j} \\le B$ with $B = 6$.\n\nThe primal problem is to maximize total profit subject to both the local knapsack constraints and the shared budget:\n- Maximize $\\sum_{i \\in \\{1,2\\}} \\sum_{j \\in \\{A,B\\}} c_{i,j} x_{i,j}$.\n- Subject to $\\sum_{j \\in \\{A,B\\}} w_{1,j} x_{1,j} \\le W_1$, $\\sum_{j \\in \\{A,B\\}} w_{2,j} x_{2,j} \\le W_2$, and $\\sum_{i \\in \\{1,2\\}} \\sum_{j \\in \\{A,B\\}} a_{i,j} x_{i,j} \\le B$.\n- Variables $x_{i,j} \\in \\{0,1\\}$.\n\nTasks:\n- Using only the definitions of the Lagrangian relaxation and Lagrangian dual, relax the shared budget constraint with multiplier $\\lambda \\ge 0$ and derive the Lagrangian dual function $q(\\lambda)$, which must decompose across $i \\in \\{1,2\\}$.\n- By analyzing the subproblem responses as functions of $\\lambda$, determine the optimal dual price $\\lambda^{\\star}$ that minimizes $q(\\lambda)$ over $\\lambda \\ge 0$, and compute the corresponding dual bound $q(\\lambda^{\\star})$.\n- Determine the optimal integer primal objective value by direct reasoning from first principles and compare it to $q(\\lambda^{\\star})$ to identify the integrality gap.\n- Finally, report the exact value of the optimal dual price $\\lambda^{\\star}$ as your answer.\n\nProvide the final answer as a single exact number. No rounding is required and no units are involved.", "solution": "The problem is a separable integer programming problem coupled by a single linear constraint. We are tasked with analyzing this problem using Lagrangian duality.\n\nFirst, we validate the problem statement.\nThe problem is formulated as a standard integer linear program, a well-defined mathematical construct. All data values (profits $c_{i,j}$, weights $w_{i,j}$, budget coefficients $a_{i,j}$, capacities $W_i$, and total budget $B$) are provided. The constraints are clearly specified, and the objective function is unambiguous. There are no scientific or logical contradictions, no missing information, and no subjective elements. The problem is well-posed and grounded in the established theory of mathematical optimization. Therefore, the problem is valid.\n\nThe primal problem is:\nMaximize $P(x) = 10x_{1,A} + 6x_{1,B} + 9x_{2,A} + 5x_{2,B}$\nSubject to:\n$1.$ $3x_{1,A} + 2x_{1,B} \\le 3$\n$2.$ $3x_{2,A} + 2x_{2,B} \\le 3$\n$3.$ $4x_{1,A} + x_{1,B} + 3x_{2,A} + 2x_{2,B} \\le 6$\n$4.$ $x_{1,A}, x_{1,B}, x_{2,A}, x_{2,B} \\in \\{0, 1\\}$\n\nThe problem asks to relax the shared budget constraint (the third constraint) using a Lagrangian multiplier $\\lambda \\ge 0$. The Lagrangian function $L(x, \\lambda)$ is defined as:\n$L(x, \\lambda) = \\sum_{i,j} c_{i,j} x_{i,j} + \\lambda (B - \\sum_{i,j} a_{i,j} x_{i,j})$\n$L(x, \\lambda) = \\sum_{i,j} (c_{i,j} - \\lambda a_{i,j}) x_{i,j} + \\lambda B$\n\nThe Lagrangian dual function $q(\\lambda)$ is the maximum value of the Lagrangian over the variables $x_{i,j}$, subject to the remaining local constraints:\n$q(\\lambda) = \\max_{x} \\{ L(x, \\lambda) \\mid 3x_{1,A} + 2x_{1,B} \\le 3, 3x_{2,A} + 2x_{2,B} \\le 3, x_{i,j} \\in \\{0,1\\} \\}$\n\nDue to the structure of the constraints, the maximization problem for $q(\\lambda)$ decomposes into a sum of independent subproblems, one for each subsystem $i \\in \\{1,2\\}$:\n$q(\\lambda) = L_1(\\lambda) + L_2(\\lambda) + \\lambda B$\nwhere\n$L_1(\\lambda) = \\max \\{ (10 - 4\\lambda)x_{1,A} + (6 - \\lambda)x_{1,B} \\mid 3x_{1,A} + 2x_{1,B} \\le 3, x_{1,A}, x_{1,B} \\in \\{0,1\\} \\}$\n$L_2(\\lambda) = \\max \\{ (9 - 3\\lambda)x_{2,A} + (5 - 2\\lambda)x_{2,B} \\mid 3x_{2,A} + 2x_{2,B} \\le 3, x_{2,A}, x_{2,B} \\in \\{0,1\\} \\}$\nand $B=6$.\n\nWe solve each subproblem as a function of $\\lambda$.\nFor subproblem $1$, the feasible solutions for $(x_{1,A}, x_{1,B})$ are $(0,0)$, $(1,0)$, and $(0,1)$.\nThe corresponding objective values are $0$, $10 - 4\\lambda$, and $6 - \\lambda$. We must choose the maximum of these.\n-   The solution is $(1,0)$ if $10 - 4\\lambda \\ge 6 - \\lambda$ and $10 - 4\\lambda \\ge 0$.\n    $10 - 4\\lambda \\ge 6 - \\lambda \\implies 4 \\ge 3\\lambda \\implies \\lambda \\le \\frac{4}{3}$.\n    $10 - 4\\lambda \\ge 0 \\implies \\lambda \\le 2.5$. Thus, for $\\lambda \\le \\frac{4}{3}$, the solution is $(1,0)$.\n-   The solution is $(0,1)$ if $6 - \\lambda \\ge 10 - 4\\lambda$ and $6 - \\lambda \\ge 0$.\n    $6 - \\lambda \\ge 10 - 4\\lambda \\implies 3\\lambda \\ge 4 \\implies \\lambda \\ge \\frac{4}{3}$.\n    $6 - \\lambda \\ge 0 \\implies \\lambda \\le 6$. Thus, for $\\frac{4}{3}  \\lambda \\le 6$, the solution is $(0,1)$.\n-   The solution is $(0,0)$ if both coefficients are negative, which occurs for $\\lambda  6$.\n\nSummary for subproblem $1$:\n-   For $0 \\le \\lambda \\le \\frac{4}{3}$, $x_1^*(\\lambda) = (1,0)$, and $L_1(\\lambda) = 10 - 4\\lambda$.\n-   For $\\frac{4}{3}  \\lambda \\le 6$, $x_1^*(\\lambda) = (0,1)$, and $L_1(\\lambda) = 6 - \\lambda$.\n-   For $\\lambda  6$, $x_1^*(\\lambda) = (0,0)$, and $L_1(\\lambda) = 0$.\n\nFor subproblem $2$, the feasible solutions for $(x_{2,A}, x_{2,B})$ are $(0,0)$, $(1,0)$, and $(0,1)$.\nThe corresponding objective values are $0$, $9 - 3\\lambda$, and $5 - 2\\lambda$.\n-   Compare $9 - 3\\lambda$ and $5 - 2\\lambda$: $9 - 3\\lambda = 5 - 2\\lambda \\implies 4 = \\lambda$. For $\\lambda  4$, $9-3\\lambda  5-2\\lambda$.\n-   $9 - 3\\lambda  0 \\implies \\lambda  3$.\n-   $5 - 2\\lambda  0 \\implies \\lambda  2.5$.\nIf $0 \\le \\lambda \\le 3$, $9-3\\lambda \\ge 0$. Since $\\lambda  4$, $9-3\\lambda  5-2\\lambda$. So the solution is $(1,0)$.\nIf $\\lambda  3$, $9-3\\lambda  0$. Also, for $\\lambda3$, $5-2\\lambda  0$. So the solution is $(0,0)$.\n\nSummary for subproblem $2$:\n-   For $0 \\le \\lambda \\le 3$, $x_2^*(\\lambda) = (1,0)$, and $L_2(\\lambda) = 9 - 3\\lambda$.\n-   For $\\lambda  3$, $x_2^*(\\lambda) = (0,0)$, and $L_2(\\lambda) = 0$.\n\nThe Lagrangian dual problem is to find $\\lambda^{\\star} = \\arg\\min_{\\lambda \\ge 0} q(\\lambda)$. The function $q(\\lambda)$ is convex and piecewise linear. The minimum is found where its subgradient contains $0$. The subgradient is given by $B - \\sum_{i,j} a_{i,j} x_{i,j}^*(\\lambda)$, where $x^*(\\lambda)$ is an optimal solution to the Lagrangian subproblems.\nWe check the subgradient in the intervals defined by the breakpoints $\\frac{4}{3}$ and $3$.\n\n-   For $0 \\le \\lambda  \\frac{4}{3}$:\n    $x_1^*(\\lambda)=(1,0)$ and $x_2^*(\\lambda)=(1,0)$.\n    The total budget consumption is $a_{1,A} \\cdot 1 + a_{2,A} \\cdot 1 = 4+3=7$.\n    The subgradient is $B - 7 = 6 - 7 = -1$.\n    $q(\\lambda) = (10-4\\lambda) + (9-3\\lambda) + 6\\lambda = 19 - \\lambda$. The slope is $-1$. Since the slope is negative, the minimum occurs at a larger $\\lambda$.\n\n-   For $\\frac{4}{3}  \\lambda \\le 3$:\n    $x_1^*(\\lambda)=(0,1)$ and $x_2^*(\\lambda)=(1,0)$.\n    The total budget consumption is $a_{1,B} \\cdot 1 + a_{2,A} \\cdot 1 = 1+3=4$.\n    The subgradient is $B - 4 = 6 - 4 = 2$.\n    $q(\\lambda) = (6-\\lambda) + (9-3\\lambda) + 6\\lambda = 15 + 2\\lambda$. The slope is $2$. Since the slope is positive, the minimum occurs at a smaller $\\lambda$.\n\nThe subgradient changes from negative to positive at $\\lambda=\\frac{4}{3}$. This indicates that the minimum of $q(\\lambda)$ is at $\\lambda^{\\star} = \\frac{4}{3}$.\nAt $\\lambda = \\frac{4}{3}$, subproblem $1$ has two optimal solutions, $(1,0)$ and $(0,1)$, because $10 - 4(\\frac{4}{3}) = \\frac{14}{3}$ and $6 - \\frac{4}{3} = \\frac{14}{3}$. The subgradient at this point is the interval $[-1, 2]$, which contains $0$. Therefore, the optimal dual price is indeed $\\lambda^{\\star} = \\frac{4}{3}$.\n\nThe corresponding dual bound is $q(\\lambda^{\\star}) = q(\\frac{4}{3})$. Using the first interval's expression:\n$q(\\frac{4}{3}) = 19 - \\frac{4}{3} = \\frac{57-4}{3} = \\frac{53}{3}$.\n\nTo find the integrality gap, we solve the primal problem by enumerating the feasible combinations.\nFeasible solutions for subsystem $1$ (s.t. $3x_{1,A} + 2x_{1,B} \\le 3$): $(0,0), (1,0), (0,1)$.\nFeasible solutions for subsystem $2$ (s.t. $3x_{2,A} + 2x_{2,B} \\le 3$): $(0,0), (1,0), (0,1)$.\nWe check pairs of these local solutions against the global budget constraint $4x_{1,A} + x_{1,B} + 3x_{2,A} + 2x_{2,B} \\le 6$.\n-   $x_{1}=(1,0)$, $x_{2}=(0,1)$: Budget used $a_{1,A}+a_{2,B}=4+2=6$. Feasible. Profit $c_{1,A}+c_{2,B}=10+5=15$.\n-   $x_{1}=(0,1)$, $x_{2}=(1,0)$: Budget used $a_{1,B}+a_{2,A}=1+3=4$. Feasible. Profit $c_{1,B}+c_{2,A}=6+9=15$.\n-   $x_{1}=(1,0)$, $x_{2}=(1,0)$: Budget used $a_{1,A}+a_{2,A}=4+3=7$. Infeasible.\n-   Other combinations yield lower profit. For instance, $x_1=(1,0), x_2=(0,0)$ gives profit $10$. $x_1=(0,1), x_2=(0,1)$ gives profit $11$.\nThe optimal primal objective value is $p^{\\star} = 15$.\n\nThe integrality gap is $q(\\lambda^{\\star}) - p^{\\star} = \\frac{53}{3} - 15 = \\frac{53-45}{3} = \\frac{8}{3}$.\n\nThe question asks for the exact value of the optimal dual price $\\lambda^{\\star}$.\nBased on our analysis, $\\lambda^{\\star} = \\frac{4}{3}$.", "answer": "$$\n\\boxed{\\frac{4}{3}}\n$$", "id": "3122695"}, {"introduction": "This final practice moves from analytical derivation to computational implementation, asking you to simulate a dynamic resource allocation system in a cloud computing cluster. You will implement the iterative price update scheme (subgradient ascent) to see how a central operator can guide independent tasks toward a globally efficient allocation. This exercise [@problem_id:3122767] provides practical insight into the behavior of dual decomposition as a real-time, distributed algorithm, particularly how it adapts to shifts in demand, a common feature in networked systems.", "problem": "Consider a cloud cluster that allocates central processing unit (CPU) cores among independent tasks. Each task selects a nonnegative CPU allotment based on a price per core, aiming to minimize its own convex cost. The cloud operator enforces a global capacity constraint and adjusts the price to equilibrate aggregate demand with capacity. The following convex resource allocation problem models this setting in purely mathematical terms.\n\nThe primal optimization problem is to choose allocations $x_i$ for tasks $i \\in \\{1,\\dots,N\\}$:\n$$\n\\text{minimize } \\sum_{i=1}^{N} f_i(x_i) \\quad \\text{subject to } \\sum_{i=1}^{N} x_i \\le C,\\quad 0 \\le x_i \\le X_i,\n$$\nwhere $f_i$ are convex functions, $C$ is the cluster capacity, and $X_i$ are per-task upper bounds. In this problem, each task has the quadratic cost\n$$\nf_i(x_i) = \\frac{1}{2} a_i x_i^2 - u_i x_i,\n$$\nwith parameters $a_i  0$ and $u_i \\ge 0$. The coefficient $a_i$ captures curvature (strict convexity), while $u_i$ captures the task’s marginal value for compute. Under dual decomposition, the cloud operator sets a nonnegative price $\\lambda$ for CPU, which enters the task’s local decision through the Lagrangian. Tasks choose $x_i$ to minimize their local objective given $\\lambda$, and the operator updates $\\lambda$ using a principled ascent on the dual.\n\nStarting from the foundational definitions of the Lagrangian for inequality-constrained convex programs, the dual function, and subgradient ascent on concave duals, derive the decoupled local minimizers that each task solves given a price $\\lambda$, and the price update that the operator performs to drive the aggregate allocation toward feasibility. Your derivation must begin from these base facts and must not assume any shortcut formulas.\n\nBursty demand is modeled as time variation in the parameters $u_i$ across discrete periods $t \\in \\{1,2,3\\}$. In each test case below, the set of tasks is fixed, but the vector $u$ changes across the three periods to represent a burst and subsequent relaxation. For each period, start the price update from the previous period’s final price (for period $t=1$, start from $\\lambda=0$). Use a diminishing step size of the form $\\alpha_k = \\alpha_0 / \\sqrt{k+1}$ at iteration $k$, and project the price onto the nonnegative reals after every update. Continue iterating until the absolute capacity residual $|\\sum_i x_i - C|$ is at most $\\varepsilon$, or until a maximum of $M$ iterations is reached.\n\nFor each test case, compute the following three scalars:\n- The mean number of iterations to reach tolerance across the three periods, expressed as a real number.\n- The maximum transient capacity overshoot across all iterations and periods, defined as $\\max\\{\\,\\sum_i x_i - C,\\,0\\,\\}$ encountered during the iterations, expressed as a real number.\n- The final price after the last period, expressed as a real number.\n\nYour program should produce a single line of output containing the results for all test cases as a comma-separated list enclosed in square brackets, where each test case’s result is itself a list of the three scalars $[\\,\\text{mean\\_iterations},\\text{max\\_overshoot},\\text{final\\_price}\\,]$. For example, the format should be $[[m_1,o_1,p_1],[m_2,o_2,p_2],\\dots]$.\n\nUse the following test suite. In all cases, use $\\alpha_0 = 0.8$, tolerance $\\varepsilon = 10^{-4}$, and maximum iterations $M = 2000$.\n\n- Test Case $1$ (happy path with moderate burst):\n  - Capacity $C = 30$.\n  - Number of tasks $N = 6$.\n  - Curvatures $a = [\\,1.8,1.6,1.4,1.2,1.0,0.8\\,]$.\n  - Upper bounds $X = [\\,8,8,8,8,8,8\\,]$.\n  - Demand values per period:\n    - Period $1$: $u = [\\,12,10,8,6,4,2\\,]$.\n    - Period $2$: $u = [\\,22,20,16,6,4,2\\,]$.\n    - Period $3$: $u = [\\,14,12,9,6,4,2\\,]$.\n\n- Test Case $2$ (boundary case where capacity matches baseline unconstrained demand, then a burst):\n  - Capacity $C = 25$.\n  - Number of tasks $N = 5$.\n  - Curvatures $a = [\\,2,2,2,2,2\\,]$.\n  - Upper bounds $X = [\\,10,10,10,10,10\\,]$.\n  - Demand values per period:\n    - Period $1$: $u = [\\,10,10,10,10,10\\,]$.\n    - Period $2$: $u = [\\,12,12,12,12,12\\,]$.\n    - Period $3$: $u = [\\,10,10,10,10,10\\,]$.\n\n- Test Case $3$ (heavy burst with many tasks and heterogeneous curvatures):\n  - Capacity $C = 40$.\n  - Number of tasks $N = 10$.\n  - Curvatures $a = [\\,1.0,0.5,0.7,1.5,0.9,1.1,0.6,1.4,0.8,1.2\\,]$.\n  - Upper bounds $X = [\\,6,6,6,6,6,6,6,6,6,6\\,]$.\n  - Demand values per period:\n    - Period $1$: $u = [\\,6,6,6,6,6,6,6,6,6,6\\,]$.\n    - Period $2$: $u = [\\,16,16,16,16,16,6,6,6,6,6\\,]$.\n    - Period $3$: $u = [\\,8,8,8,8,8,8,8,8,8,8\\,]$.\n\n- Test Case $4$ (ill-conditioned curvatures with large upper bounds and strong burst):\n  - Capacity $C = 60$.\n  - Number of tasks $N = 4$.\n  - Curvatures $a = [\\,0.2,0.3,5.0,3.0\\,]$.\n  - Upper bounds $X = [\\,50,40,15,15\\,]$.\n  - Demand values per period:\n    - Period $1$: $u = [\\,20,20,20,20\\,]$.\n    - Period $2$: $u = [\\,60,55,25,25\\,]$.\n    - Period $3$: $u = [\\,25,25,20,20\\,]$.\n\nYour task is to implement the dual decomposition with the above specifications and produce the required aggregated single-line output. No physical units or angle units are involved; all reported quantities are dimensionless real numbers.", "solution": "The problem presented is a convex resource allocation problem to be solved using dual decomposition. It is mathematically well-defined, scientifically sound within the field of optimization theory, and all necessary parameters for a numerical solution are provided. The problem is therefore valid.\n\nThe core task is to derive and implement a dual decomposition algorithm for the specified problem, tracking performance metrics across several time periods that model demand bursts.\n\n**Problem Formulation and Derivations**\n\nThe primal optimization problem is stated as:\n$$\n\\text{minimize } \\sum_{i=1}^{N} f_i(x_i) \\quad \\text{subject to } \\sum_{i=1}^{N} x_i \\le C, \\quad 0 \\le x_i \\le X_i \\text{ for } i \\in \\{1, \\ldots, N\\}\n$$\nwhere the cost function for each task $i$ is a convex quadratic:\n$$\nf_i(x_i) = \\frac{1}{2} a_i x_i^2 - u_i x_i\n$$\nThe parameters $a_i  0$ ensure strict convexity of each $f_i$, which in turn guarantees a unique solution to the primal problem.\n\n**Dual Decomposition**\n\nDual decomposition is a method for solving structured convex optimization problems. It is particularly effective when, in the absence of a few \"coupling\" constraints, the problem would decompose into several smaller, independent subproblems. Here, the constraint $\\sum_{i=1}^{N} x_i \\le C$ is the coupling constraint, as it links all the variables $x_i$. The box constraints $0 \\le x_i \\le X_i$ are local to each task.\n\nWe begin by forming the Lagrangian of the problem. We introduce a Lagrange multiplier (or dual variable) $\\lambda \\ge 0$ associated with the coupling constraint $\\sum_{i=1}^{N} x_i - C \\le 0$. The local box constraints are not dualized but are instead handled within each task's subproblem. The Lagrangian $L(x, \\lambda)$ is:\n$$\nL(x, \\lambda) = \\sum_{i=1}^{N} f_i(x_i) + \\lambda \\left( \\sum_{i=1}^{N} x_i - C \\right)\n$$\nBy rearranging the terms, we can see the separable structure of the Lagrangian:\n$$\nL(x, \\lambda) = \\sum_{i=1}^{N} \\left( f_i(x_i) + \\lambda x_i \\right) - \\lambda C\n$$\nThe dual function $g(\\lambda)$ is defined as the infimum of the Lagrangian over the primal variables $x = (x_1, \\ldots, x_N)$, subject to their local constraints:\n$$\ng(\\lambda) = \\inf_{0 \\le x_i \\le X_i \\forall i} L(x, \\lambda)\n$$\nDue to the separable structure, the infimum can be distributed:\n$$\ng(\\lambda) = \\left( \\sum_{i=1}^{N} \\inf_{0 \\le x_i \\le X_i} \\{ f_i(x_i) + \\lambda x_i \\} \\right) - \\lambda C\n$$\n\n**Task's Local Problem**\n\nThe minimization of the Lagrangian decomposes into $N$ independent subproblems, one for each task $i$. Given a price $\\lambda$ set by the operator, each task chooses its allocation $x_i$ to minimize its local portion of the Lagrangian:\n$$\nx_i^*(\\lambda) = \\arg\\min_{0 \\le x_i \\le X_i} \\left\\{ f_i(x_i) + \\lambda x_i \\right\\}\n$$\nSubstituting the specific cost function $f_i(x_i)$:\n$$\nx_i^*(\\lambda) = \\arg\\min_{0 \\le x_i \\le X_i} \\left\\{ \\frac{1}{2} a_i x_i^2 - u_i x_i + \\lambda x_i \\right\\} = \\arg\\min_{0 \\le x_i \\le X_i} \\left\\{ \\frac{1}{2} a_i x_i^2 - (u_i - \\lambda) x_i \\right\\}\n$$\nThis is a problem of minimizing a strictly convex quadratic function over a closed interval $[0, X_i]$. We first find the unconstrained minimizer by setting the derivative of the objective with respect to $x_i$ to zero:\n$$\n\\frac{d}{dx_i} \\left( \\frac{1}{2} a_i x_i^2 - (u_i - \\lambda) x_i \\right) = a_i x_i - (u_i - \\lambda) = 0\n$$\nThe unconstrained solution is $x_i^{\\text{unc}} = \\frac{u_i - \\lambda}{a_i}$. The constrained minimum over the interval $[0, X_i]$ is the projection of this unconstrained solution onto the interval. This projection is achieved by clipping the value:\n$$\nx_i^*(\\lambda) = \\text{proj}_{[0, X_i]} \\left( \\frac{u_i - \\lambda}{a_i} \\right) = \\max\\left(0, \\min\\left(X_i, \\frac{u_i - \\lambda}{a_i}\\right)\\right)\n$$\nThis closed-form solution is what each task computes locally given the price $\\lambda$.\n\n**Dual Problem and Price Update**\n\nThe dual problem consists of maximizing the dual function $g(\\lambda)$ over the feasible set of dual variables:\n$$\n\\text{maximize } g(\\lambda) \\quad \\text{subject to } \\lambda \\ge 0\n$$\nThe dual function $g(\\lambda)$ is always concave, regardless of the convexity of the primal problem. We can solve this concave maximization problem using subgradient ascent. A subgradient of $g$ at $\\lambda$ is given by $\\sum_{i=1}^{N} x_i^*(\\lambda) - C$. Since each $x_i^*(\\lambda)$ is unique, $g(\\lambda)$ is differentiable, and this is the gradient $\\nabla g(\\lambda)$.\n\nThe subgradient ascent update rule for the price $\\lambda$ at iteration $k$ is:\n$$\n\\lambda_{k+1} = \\lambda_k + \\alpha_k \\nabla g(\\lambda_k)\n$$\nwhere $\\alpha_k  0$ is the step size. Substituting the gradient, we get:\n$$\n\\lambda_{k+1} = \\lambda_k + \\alpha_k \\left( \\sum_{i=1}^{N} x_i^*(\\lambda_k) - C \\right)\n$$\nFinally, we must enforce the nonnegativity constraint $\\lambda \\ge 0$ by projecting the updated price onto the nonnegative reals:\n$$\n\\lambda_{k+1} = \\max\\left(0, \\lambda_k + \\alpha_k \\left( \\sum_{i=1}^{N} x_i^*(\\lambda_k) - C \\right)\\right)\n$$\nThis is the price update rule used by the cloud operator. The term $\\sum_i x_i^*(\\lambda_k) - C$ represents the resource surplus or deficit (the \"capacity residual\").\n\n**Algorithmic Implementation**\n\nThe complete algorithm for a single period proceeds as follows:\n1.  Initialize the price $\\lambda_0$ (at $t=1$, $\\lambda_0=0$; otherwise, use the final price from the previous period).\n2.  For each iteration $k = 0, 1, \\ldots, M-1$:\n    a.  Each task $i$ computes its desired allocation $x_i(\\lambda_k) = \\max\\left(0, \\min\\left(X_i, \\frac{u_i - \\lambda_k}{a_i}\\right)\\right)$.\n    b.  Calculate the total allocation $S_k = \\sum_{i=1}^{N} x_i(\\lambda_k)$.\n    c.  Check for convergence: if $|S_k - C| \\le \\varepsilon$, the process terminates for this period.\n    d.  Update the maximum transient overshoot metric: $\\max_{\\text{overshoot}} \\leftarrow \\max(\\max_{\\text{overshoot}}, S_k - C, 0)$.\n    e.  Compute the step size $\\alpha_k = \\alpha_0 / \\sqrt{k+1}$.\n    f.  Update the price: $\\lambda_{k+1} = \\max(0, \\lambda_k + \\alpha_k (S_k - C))$.\n3.  If the loop completes after $M$ iterations without converging, the process is terminated. The number of iterations is recorded, and the final price $\\lambda_M$ is carried over.\n\nThis procedure is repeated for each of the three time periods, with the final price of one period serving as the initial price for the next. The overall metrics (mean iterations, max overshoot, final price) are computed after all periods a test case are completed.", "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the convex resource allocation problem using dual decomposition\n    for a series of test cases and demand periods.\n    \"\"\"\n    \n    # Constants for the subgradient method\n    ALPHA_0 = 0.8\n    EPSILON = 1e-4\n    MAX_ITERATIONS = 2000\n\n    test_cases = [\n        {\n            \"C\": 30.0, \"N\": 6,\n            \"a\": np.array([1.8, 1.6, 1.4, 1.2, 1.0, 0.8]),\n            \"X\": np.array([8.0, 8.0, 8.0, 8.0, 8.0, 8.0]),\n            \"u_periods\": [\n                np.array([12.0, 10.0, 8.0, 6.0, 4.0, 2.0]),\n                np.array([22.0, 20.0, 16.0, 6.0, 4.0, 2.0]),\n                np.array([14.0, 12.0, 9.0, 6.0, 4.0, 2.0])\n            ]\n        },\n        {\n            \"C\": 25.0, \"N\": 5,\n            \"a\": np.array([2.0, 2.0, 2.0, 2.0, 2.0]),\n            \"X\": np.array([10.0, 10.0, 10.0, 10.0, 10.0]),\n            \"u_periods\": [\n                np.array([10.0, 10.0, 10.0, 10.0, 10.0]),\n                np.array([12.0, 12.0, 12.0, 12.0, 12.0]),\n                np.array([10.0, 10.0, 10.0, 10.0, 10.0])\n            ]\n        },\n        {\n            \"C\": 40.0, \"N\": 10,\n            \"a\": np.array([1.0, 0.5, 0.7, 1.5, 0.9, 1.1, 0.6, 1.4, 0.8, 1.2]),\n            \"X\": np.array([6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0]),\n            \"u_periods\": [\n                np.array([6.0] * 10),\n                np.array([16.0] * 5 + [6.0] * 5),\n                np.array([8.0] * 10)\n            ]\n        },\n        {\n            \"C\": 60.0, \"N\": 4,\n            \"a\": np.array([0.2, 0.3, 5.0, 3.0]),\n            \"X\": np.array([50.0, 40.0, 15.0, 15.0]),\n            \"u_periods\": [\n                np.array([20.0, 20.0, 20.0, 20.0]),\n                np.array([60.0, 55.0, 25.0, 25.0]),\n                np.array([25.0, 25.0, 20.0, 20.0])\n            ]\n        }\n    ]\n\n    all_results = []\n\n    for case in test_cases:\n        C = case[\"C\"]\n        a = case[\"a\"]\n        X = case[\"X\"]\n        u_periods = case[\"u_periods\"]\n\n        period_iterations = []\n        max_overall_overshoot = 0.0\n        final_lambda = 0.0  # Start with lambda = 0 for the first period\n\n        for u in u_periods:\n            lambda_k = final_lambda\n            iters_this_period = MAX_ITERATIONS\n\n            for k in range(MAX_ITERATIONS):\n                # Tasks solve their local problems\n                x_unconstrained = (u - lambda_k) / a\n                x = np.clip(x_unconstrained, 0, X)\n                \n                # Operator computes total allocation and residual\n                total_allocation = np.sum(x)\n                residual = total_allocation - C\n\n                # Update maximum overshoot\n                current_overshoot = max(0, residual)\n                if current_overshoot > max_overall_overshoot:\n                    max_overall_overshoot = current_overshoot\n\n                # Check for convergence\n                if abs(residual) = EPSILON:\n                    iters_this_period = k + 1\n                    break\n\n                # Operator updates price using subgradient ascent\n                alpha_k = ALPHA_0 / np.sqrt(k + 1)\n                lambda_k = max(0, lambda_k + alpha_k * residual)\n            \n            final_lambda = lambda_k\n            period_iterations.append(iters_this_period)\n        \n        mean_iterations = np.mean(period_iterations)\n        \n        case_result = [mean_iterations, max_overall_overshoot, final_lambda]\n        # Format with repr to get many decimal places for accuracy\n        case_result_str = f\"[{repr(case_result[0])}, {repr(case_result[1])}, {repr(case_result[2])}]\"\n        \n        # str() gives a user-friendly representation, which is what the output format implies\n        all_results.append(str(case_result))\n    \n    # The output format requires joining string representations of lists.\n    print(f\"[{','.join(all_results)}]\")\n\nsolve()\n```", "id": "3122767"}]}