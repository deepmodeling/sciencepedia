{"hands_on_practices": [{"introduction": "This practice provides a bridge between gradient-based methods and the core idea of alternating minimization. By analyzing a simple quadratic function, you will see that what might appear as an \"inexact\" gradient step is, in fact, an exact minimization of the block subproblem [@problem_id:3097264]. This exercise demystifies the minimization step of the algorithm and builds intuition by connecting it to the familiar concept of the coordinate-wise Lipschitz constant and gradient descent.", "problem": "Consider the twice continuously differentiable function\n$$\nf(x,y) \\;=\\; \\frac{3}{2}\\,x^{2} \\;+\\; 2\\,x\\,y \\;+\\; \\frac{5}{2}\\,y^{2} \\;-\\; 4\\,x \\;-\\; 6\\,y,\n$$\nwith decision variables $x \\in \\mathbb{R}$ and $y \\in \\mathbb{R}$. Use the definition that a partial gradient is coordinate-wise Lipschitz continuous if there exists a constant $L_{x} \\ge 0$ such that for all $x, x' \\in \\mathbb{R}$ and any fixed $y \\in \\mathbb{R}$,\n$$\n\\big\\|\\nabla_{x} f(x,y) - \\nabla_{x} f(x',y)\\big\\| \\;\\le\\; L_{x}\\,|x-x'|,\n$$\nand analogously for $L_{y}$ with $y,y'$ at fixed $x$. \n\nTasks:\n1) Derive the smallest valid coordinate-wise Lipschitz constants $L_{x}$ and $L_{y}$ for $f(x,y)$ from first principles. \n2) Using these constants, form a single-step inexact Alternating Minimization (AM) scheme, where the $x$-update is one gradient step on $f(\\cdot,y^{k})$ with step size $1/L_{x}$, followed by the $y$-update as one gradient step on $f(x^{k+1},\\cdot)$ with step size $1/L_{y}$. Starting from $(x^{0},y^{0})=(1,0)$, compute $(x^{1},y^{1})$ produced by this scheme.\n3) For this quadratic $f$, derive the exact block minimizers for $x$ given $y$ and for $y$ given $x$, and briefly compare them to the inexact AM updates you obtained in step $2$.\n\nReport your final answer as the row matrix containing $(x^{1},y^{1})$. No rounding is necessary.", "solution": "The problem is well-posed, scientifically grounded, and objective. It consists of standard tasks in continuous optimization involving a convex quadratic function. All necessary information is provided, and the problem is free of contradictions or ambiguities. Therefore, the problem is valid, and a complete solution will be provided.\n\nThe function under consideration is\n$$\nf(x,y) \\;=\\; \\frac{3}{2}\\,x^{2} \\;+\\; 2\\,x\\,y \\;+\\; \\frac{5}{2}\\,y^{2} \\;-\\; 4\\,x \\;-\\; 6\\,y.\n$$\n\n**1) Derivation of Coordinate-wise Lipschitz Constants**\n\nThe definition of a coordinate-wise Lipschitz continuous partial gradient requires that for a constant $L_x \\ge 0$, the inequality $|\\nabla_{x} f(x,y) - \\nabla_{x} f(x',y)| \\le L_{x}\\,|x-x'|$ holds for all $x, x' \\in \\mathbb{R}$ and any fixed $y \\in \\mathbb{R}$. Since $f$ is twice continuously differentiable, the smallest such constant $L_x$ is given by the supremum of the absolute value of the second partial derivative with respect to $x$.\n\nFirst, we compute the partial gradient with respect to $x$:\n$$\n\\nabla_{x} f(x,y) = \\frac{\\partial f}{\\partial x} = 3\\,x + 2\\,y - 4.\n$$\nThen, we compute the second partial derivative with respect to $x$:\n$$\n\\frac{\\partial^2 f}{\\partial x^2} = \\frac{\\partial}{\\partial x} (3\\,x + 2\\,y - 4) = 3.\n$$\nThe smallest Lipschitz constant $L_x$ is the supremum of the absolute value of this derivative over all $x$ and $y$:\n$$\nL_x = \\sup_{x, y \\in \\mathbb{R}} \\left| \\frac{\\partial^2 f}{\\partial x^2}(x,y) \\right| = |3| = 3.\n$$\nAnalogously, for the $y$-coordinate, we first compute the partial gradient with respect to $y$:\n$$\n\\nabla_{y} f(x,y) = \\frac{\\partial f}{\\partial y} = 2\\,x + 5\\,y - 6.\n$$\nThen, we compute the second partial derivative with respect to $y$:\n$$\n\\frac{\\partial^2 f}{\\partial y^2} = \\frac{\\partial}{\\partial y} (2\\,x + 5\\,y - 6) = 5.\n$$\nThe smallest Lipschitz constant $L_y$ is the supremum of the absolute value of this derivative:\n$$\nL_y = \\sup_{x, y \\in \\mathbb{R}} \\left| \\frac{\\partial^2 f}{\\partial y^2}(x,y) \\right| = |5| = 5.\n$$\nThus, the smallest valid coordinate-wise Lipschitz constants are $L_x = 3$ and $L_y = 5$.\n\n**2) Inexact Alternating Minimization (AM) Step**\n\nThe inexact AM scheme is defined by the following updates, starting from $(x^0, y^0) = (1, 0)$:\n$$\nx^{k+1} = x^{k} - \\frac{1}{L_x} \\nabla_x f(x^k, y^k)\n$$\n$$\ny^{k+1} = y^{k} - \\frac{1}{L_y} \\nabla_y f(x^{k+1}, y^k)\n$$\nWe compute the first iteration, i.e., for $k=0$, to find $(x^1, y^1)$.\n\nFirst, we perform the $x$-update. We need the partial gradient $\\nabla_x f(x^0, y^0)$:\n$$\n\\nabla_x f(x^0, y^0) = \\nabla_x f(1, 0) = 3(1) + 2(0) - 4 = -1.\n$$\nUsing $L_x = 3$, the update for $x^1$ is:\n$$\nx^{1} = x^{0} - \\frac{1}{L_x} \\nabla_x f(x^0, y^0) = 1 - \\frac{1}{3}(-1) = 1 + \\frac{1}{3} = \\frac{4}{3}.\n$$\nNext, we perform the $y$-update. This update uses the newly computed value $x^1 = 4/3$ and the previous value $y^0 = 0$. We need the partial gradient $\\nabla_y f(x^1, y^0)$:\n$$\n\\nabla_y f(x^1, y^0) = \\nabla_y f\\left(\\frac{4}{3}, 0\\right) = 2\\left(\\frac{4}{3}\\right) + 5(0) - 6 = \\frac{8}{3} - 6 = \\frac{8}{3} - \\frac{18}{3} = -\\frac{10}{3}.\n$$\nUsing $L_y = 5$, the update for $y^1$ is:\n$$\ny^{1} = y^{0} - \\frac{1}{L_y} \\nabla_y f(x^1, y^0) = 0 - \\frac{1}{5}\\left(-\\frac{10}{3}\\right) = \\frac{10}{15} = \\frac{2}{3}.\n$$\nTherefore, the result of one step of the scheme is $(x^1, y^1) = \\left(\\frac{4}{3}, \\frac{2}{3}\\right)$.\n\n**3) Exact Block Minimizers and Comparison**\n\nTo find the exact block minimizer for $x$ given a fixed $y$, denoted $x^*(y)$, we solve the first-order optimality condition $\\nabla_x f(x,y) = 0$ for $x$:\n$$\n3\\,x + 2\\,y - 4 = 0 \\implies 3\\,x = 4 - 2\\,y \\implies x^*(y) = \\frac{4 - 2\\,y}{3}.\n$$\nSimilarly, to find the exact block minimizer for $y$ given a fixed $x$, denoted $y^*(x)$, we solve $\\nabla_y f(x,y) = 0$ for $y$:\n$$\n2\\,x + 5\\,y - 6 = 0 \\implies 5\\,y = 6 - 2\\,x \\implies y^*(x) = \\frac{6 - 2\\,x}{5}.\n$$\nNow we compare these exact minimizers to the \"inexact\" AM updates from step $2$. Let's examine the-update rule algebraically:\n$$\nx^{k+1} = x^k - \\frac{1}{L_x}\\nabla_x f(x^k, y^k) = x^k - \\frac{1}{3}(3x^k + 2y^k - 4) = x^k - x^k - \\frac{2}{3}y^k + \\frac{4}{3} = \\frac{4 - 2y^k}{3}.\n$$\nThis expression is identical to $x^*(y^k)$.\n\nLet's examine the $y$-update rule:\n$$\ny^{k+1} = y^k - \\frac{1}{L_y}\\nabla_y f(x^{k+1}, y^k) = y^k - \\frac{1}{5}(2x^{k+1} + 5y^k - 6) = y^k - \\frac{2}{5}x^{k+1} - y^k + \\frac{6}{5} = \\frac{6 - 2x^{k+1}}{5}.\n$$\nThis expression is identical to $y^*(x^{k+1})$.\n\nThe comparison reveals that the prescribed \"inexact\" AM scheme is, for this particular quadratic function, equivalent to the exact Alternating Minimization method, also known as Block Coordinate Descent (BCD). This occurs because for a one-dimensional quadratic subproblem of the form $g(z) = \\frac{1}{2}Az^2 + Bz + C$ (with $A > 0$), the Lipschitz constant of the gradient $g'(z)$ is $L=A$. A single gradient descent step with step size $1/L$ finds the exact minimizer: $z_{k+1} = z_k - \\frac{1}{A}(Az_k + B) = -B/A$. In our problem, the subproblems for $x$ and $y$ are quadratic, and the selected step sizes ($1/L_x$ and $1/L_y$) are precisely the reciprocals of the second derivatives, causing each update step to be an exact minimization of its respective subproblem.", "answer": "$$\\boxed{\\begin{pmatrix} \\frac{4}{3} & \\frac{2}{3} \\end{pmatrix}}$$", "id": "3097264"}, {"introduction": "While powerful, alternating minimization is not foolproof, especially on non-convex landscapes. This exercise explores a classic failure mode where the algorithm can get trapped at a non-optimal stationary point, even on a seemingly simple bilinear problem like $f(x,y) = (xy - b)^2$ [@problem_id:3097240]. By dissecting why this happens, you will develop a deeper understanding of the algorithm's limitations and learn to critically evaluate strategies like regularization and careful initialization to ensure convergence to a useful solution.", "problem": "Consider the scalar bilinear least-squares objective $f(x,y) = (xy - b)^2$ with $x \\in \\mathbb{R}$, $y \\in \\mathbb{R}$, and a fixed scalar $b \\in \\mathbb{R}$ with $b \\neq 0$. Alternating Minimization (AM) updates one block at a time by solving the exact block subproblem: given an iterate $(x^{(k)}, y^{(k)})$, compute $x^{(k+1)} \\in \\underset{x \\in \\mathbb{R}}{\\arg\\min}\\ f(x, y^{(k)})$, then $y^{(k+1)} \\in \\underset{y \\in \\mathbb{R}}{\\arg\\min}\\ f(x^{(k+1)}, y)$. Use the core definitions of minimizers and first-order optimality for univariate convex problems, together with basic calculus facts about quadratics, to reason about the AM dynamics for this $f$. In particular, explain from first principles why AM can become trapped at trivial values $x=0$ or $y=0$ even when $b \\neq 0$, and assess strategies that can prevent or escape such traps.\n\nSelect all statements that are correct.\n\nA. AM can get stuck at $x=0$ or $y=0$ because when one block equals $0$, the corresponding block subproblem becomes flat (the objective does not depend on the other block), so the gradient with respect to that block is $0$ for all values and the iterate can remain at a nonoptimal stationary point when $b \\neq 0$.\n\nB. Adding a Tikhonov regularizer $\\lambda(x^2 + y^2)$ with $\\lambda > 0$ makes each block subproblem strictly convex and have a unique minimizer; however, if the other block equals $0$, the unique minimizer of the current block is also $0$, so this regularization alone does not prevent being trapped at $(0,0)$ from such an initialization.\n\nC. If neither block is initialized at $0$, then exact AM reaches a global minimizer in at most $2$ block updates for $b \\neq 0$; thus, avoiding zero initialization (for example, by randomizing away from $0$) prevents the zero trap.\n\nD. Using a smaller step size in the block updates prevents AM from getting stuck at $0$ by avoiding overshooting.\n\nE. Enforcing lower bounds $|x| \\ge \\varepsilon$ and $|y| \\ge \\varepsilon$ for some small $\\varepsilon > 0$ (for example, by perturbing or restarting when a block hits $0$) removes the flat subproblems and can help avoid the trivial solution while preserving the set of global minimizers $\\{(x,y): xy=b\\}$.", "solution": "The problem statement is analyzed for validity.\n\n### Step 1: Extract Givens\n-   Objective function: $f(x,y) = (xy - b)^2$.\n-   Variables: $x \\in \\mathbb{R}$, $y \\in \\mathbb{R}$.\n-   Constant: A fixed scalar $b \\in \\mathbb{R}$ with $b \\neq 0$.\n-   Algorithm: Alternating Minimization (AM) with exact block minimization.\n-   Update steps:\n    1.  $x^{(k+1)} \\in \\underset{x \\in \\mathbb{R}}{\\arg\\min}\\ f(x, y^{(k)})$.\n    2.  $y^{(k+1)} \\in \\underset{y \\in \\mathbb{R}}{\\arg\\min}\\ f(x^{(k+1)}, y)$.\n-   Task: Analyze the AM dynamics, explain the trapping phenomenon at zero, and assess strategies to prevent it.\n\n### Step 2: Validate Using Extracted Givens\n-   **Scientifically Grounded**: The problem is a standard exercise in optimization theory, analyzing the behavior of the Alternating Minimization (block coordinate descent) algorithm on a non-convex but biconvex objective function. The function and algorithm are well-defined in mathematics and engineering.\n-   **Well-Posed**: The problem is clearly stated. The objective function $f(x,y)$ is continuously differentiable. The global minima are the points on the hyperbola $xy=b$, where $f(x,y)=0$. The condition $b \\neq 0$ is critical, as it implies that the origin $(0,0)$ is not a global minimum, since $f(0,0)=b^2 > 0$. The question asks for a standard analysis of algorithmic behavior.\n-   **Objective**: The problem uses precise, standard mathematical terminology and is free of subjective or ambiguous language.\n\n### Step 3: Verdict and Action\nThe problem statement is valid. A full analysis can be performed.\n\n### Derivation and Analysis\n\nThe objective function is $f(x,y) = (xy - b)^2$. The global minimum value is $0$, achieved at any point $(x,y)$ such that $xy=b$. Since $b \\neq 0$, neither $x$ nor $y$ can be zero at a global minimum.\nThe gradient of $f$ is $\\nabla f(x,y) = \\left( \\frac{\\partial f}{\\partial x}, \\frac{\\partial f}{\\partial y} \\right) = (2y(xy-b), 2x(xy-b))$.\nA point $(x,y)$ is a stationary point if $\\nabla f(x,y) = (0,0)$.\nThis occurs if $y(xy-b)=0$ and $x(xy-b)=0$.\n-   If $xy-b=0$, the gradient is $(0,0)$. These are the global minimizers.\n-   If $x=0$, the first equation becomes $y(0-b)=0$, which implies $-by=0$. Since $b\\neq0$, we must have $y=0$.\n-   If $y=0$, the second equation becomes $x(0-b)=0$, which implies $-bx=0$. Since $b\\neq0$, we must have $x=0$.\nThus, the only stationary point that is not a global minimum is $(0,0)$. At this point, $f(0,0)=b^2>0$.\n\nThe Alternating Minimization (AM) updates are as follows:\n\n**1. Minimization over $x$:**\nGiven $y^{(k)}$, we solve for $x^{(k+1)} \\in \\underset{x}{\\arg\\min} f(x, y^{(k)}) = \\underset{x}{\\arg\\min} (x y^{(k)} - b)^2$.\n-   If $y^{(k)} \\neq 0$, this is a strictly convex quadratic function of $x$. The unique minimum is found by setting the derivative to zero: $2y^{(k)}(x y^{(k)} - b) = 0 \\implies x^{(k+1)} = \\frac{b}{y^{(k)}}$.\n-   If $y^{(k)} = 0$, the objective becomes $f(x,0) = (0 - b)^2 = b^2$. This function is constant with respect to $x$. Thus, the set of minimizers is all of $\\mathbb{R}$. Any $x \\in \\mathbb{R}$ is a valid choice for $x^{(k+1)}$.\n\n**2. Minimization over $y$:**\nGiven $x^{(k+1)}$, we solve for $y^{(k+1)} \\in \\underset{y}{\\arg\\min} f(x^{(k+1)}, y) = \\underset{y}{\\arg\\min} (x^{(k+1)} y - b)^2$.\n-   If $x^{(k+1)} \\neq 0$, this is a strictly convex quadratic function of $y$. The unique minimum is found by setting the derivative to zero: $2x^{(k+1)}(x^{(k+1)} y - b) = 0 \\implies y^{(k+1)} = \\frac{b}{x^{(k+1)}}$.\n-   If $x^{(k+1)} = 0$, the objective becomes $f(0,y) = (0 - b)^2 = b^2$. This function is constant with respect to $y$. The set of minimizers is $\\mathbb{R}$.\n\n**The Trap at $(0,0)$:**\nAM can get trapped at the non-optimal stationary point $(0,0)$. Consider an iterate $(x^{(k)}, y^{(k)})$ where $y^{(k)}=0$. The subproblem for $x$ is flat. A valid, though perhaps unfortunate, choice for the update is $x^{(k+1)}=0$. Now the iterate is at $(0,0)$ (if $x^{(k)}$ was already $0$) or has been moved to $(0,0)$ in the $x$-update (if, for example, $x^{(k)}\\neq 0$ and we choose $x^{(k+1)}=0$). With the current point being $(0,0)$, we update $y$. The subproblem for $y$ is now $f(0,y) = b^2$, which is also flat. A valid choice is $y^{(k+1)}=0$. The new iterate is $(0,0)$. Subsequent updates will continue to be flat, and if the choice is always to stay at $0$, the algorithm is trapped at $(0,0)$. Since $(0,0)$ is a stationary point, AM has converged, but to a non-optimal point.\n\n### Option-by-Option Analysis\n\n**A. AM can get stuck at $x=0$ or $y=0$ because when one block equals $0$, the corresponding block subproblem becomes flat (the objective does not depend on the other block), so the gradient with respect to that block is $0$ for all values and the iterate can remain at a nonoptimal stationary point when $b \\neq 0$.**\nThis statement accurately describes the failure mechanism. If, for instance, $y^{(k)}=0$, the subproblem for $x$ is to minimize $f(x,0)=b^2$. This objective is \"flat\" (constant) with respect to $x$. The gradient of this subproblem, $\\frac{d}{dx}f(x,0)$, is indeed $0$ for all $x$. This means any $x$ is a minimizer. This allows for a sequence of updates that leads to the iterate $(0,0)$. For example, if we are at $(x_0, 0)$ for $x_0 \\neq 0$, a valid $x$-update is $x_1=0$. Then, from $(0,0)$, a valid $y$-update is $y_1=0$. The algorithm is now at the nonoptimal stationary point $(0,0)$ and is trapped. The reasoning is sound.\nVerdict: **Correct**.\n\n**B. Adding a Tikhonov regularizer $\\lambda(x^2 + y^2)$ with $\\lambda > 0$ makes each block subproblem strictly convex and have a unique minimizer; however, if the other block equals $0$, the unique minimizer of the current block is also $0$, so this regularization alone does not prevent being trapped at $(0,0)$ from such an initialization.**\nThe regularized objective is $f_{reg}(x,y) = (xy-b)^2 + \\lambda(x^2+y^2)$.\nThe subproblem for $x$ is to minimize $g(x) = f_{reg}(x,y^{(k)}) = (xy^{(k)}-b)^2 + \\lambda x^2 + \\lambda(y^{(k)})^2$.\nThe second derivative is $\\frac{d^2g}{dx^2} = 2(y^{(k)})^2 + 2\\lambda$. Since $\\lambda>0$, this is always positive, so the subproblem is always strictly convex with a unique minimizer.\nThe minimizer is found by setting $\\frac{dg}{dx} = 2y^{(k)}(xy^{(k)}-b) + 2\\lambda x = 0$, which gives $x((y^{(k)})^2+\\lambda) = by^{(k)}$, so $x^{(k+1)} = \\frac{by^{(k)}}{(y^{(k)})^2+\\lambda}$.\nNow, consider the case where the other block is zero, i.e., $y^{(k)}=0$. The update rule gives $x^{(k+1)} = \\frac{b \\cdot 0}{0^2+\\lambda} = 0$.\nSo, if an iterate lands on an axis, say at $(x_0, 0)$, the next update for $x$ will be $x_1=0$. The iterate becomes $(0,0)$. Then, updating $y$ from $(0,0)$, the update rule for $y$ ($y_{k+1} = \\frac{bx^{(k+1)}}{(x^{(k+1)})^2+\\lambda}$) gives $y_1=0$. The algorithm is trapped at $(0,0)$. The statement is therefore entirely correct.\nVerdict: **Correct**.\n\n**C. If neither block is initialized at $0$, then exact AM reaches a global minimizer in at most $2$ block updates for $b \\neq 0$; thus, avoiding zero initialization (for example, by randomizing away from $0$) prevents the zero trap.**\nLet the initialization be $(x^{(0)}, y^{(0)})$ with $x^{(0)}\\neq 0$ and $y^{(0)}\\neq 0$.\nThe first block update is for $x$. Since $y^{(0)}\\neq 0$, the unique minimizer is $x^{(1)} = \\frac{b}{y^{(0)}}$.\nThe iterate becomes $(x^{(1)}, y^{(0)}) = (\\frac{b}{y^{(0)}}, y^{(0)})$. Let's check if this is a global minimizer. The product of its components is $\\frac{b}{y^{(0)}} \\cdot y^{(0)} = b$. Thus, $f(x^{(1)}, y^{(0)}) = (b-b)^2 = 0$. This is a global minimum.\nThis was achieved in just one block update. The statement claims it is reached in \"at most $2$ block updates,\" which is true.\nThe second part of the statement, \"thus, avoiding zero initialization... prevents the zero trap,\" is also correct. If $x^{(0)}, y^{(0)} \\neq 0$, the updates are $x^{(k+1)} = b/y^{(k)}$ and $y^{(k+1)} = b/x^{(k+1)}$. Since $b\\neq 0$, none of the subsequent iterates can have a zero component. The algorithm will never encounter the flat subproblems associated with the axes.\nVerdict: **Correct**.\n\n**D. Using a smaller step size in the block updates prevents AM from getting stuck at $0$ by avoiding overshooting.**\nThe problem statement specifies exact Alternating Minimization: $x^{(k+1)} \\in \\underset{x}{\\arg\\min} f(x, y^{(k)})$. This method does not have a user-defined \"step size\" parameter. The update moves the variable directly to the minimizer of the block subproblem. The concept of using a \"smaller step size\" is not applicable to the algorithm as defined. This statement is based on a false premise, likely confusing exact AM with a gradient-based or proximal method.\nVerdict: **Incorrect**.\n\n**E. Enforcing lower bounds $|x| \\ge \\varepsilon$ and $|y| \\ge \\varepsilon$ for some small $\\varepsilon > 0$ (for example, by perturbing or restarting when a block hits $0$) removes the flat subproblems and can help avoid the trivial solution while preserving the set of global minimizers $\\{(x,y): xy=b\\}$.**\nThis statement proposes a strategy to avoid the trap.\n1. \"Enforcing lower bounds $|x| \\ge \\varepsilon$ and $|y| \\ge \\varepsilon$ ... removes the flat subproblems\": The subproblems become flat only when one coordinate is zero. By enforcing that $|x|$ and $|y|$ are always at least $\\varepsilon > 0$, we ensure that subproblems are never flat. This part is correct.\n2. \"can help avoid the trivial solution\": The trivial trapped solution is $(0,0)$. The constraints $|x| \\ge \\varepsilon, |y| \\ge \\varepsilon$ make $(0,0)$ and the rest of the axes infeasible, thus avoiding the trap. This part is correct.\n3. \"while preserving the set of global minimizers\": This is the most subtle part. If the strategy is to change the problem's feasible set to $\\{ (x,y) : |x|\\ge\\varepsilon, |y|\\ge\\varepsilon \\}$, then the set of global minimizers is restricted to $\\{ (x,y) : xy=b, |x|\\ge\\varepsilon, |y|\\ge\\varepsilon \\}$. This is a strict subset of the original problem's minimizers, so the set is not preserved. However, the statement provides an example implementation: \"by perturbing or restarting when a block hits $0$\". This describes a procedural modification to the algorithm, not a change to the problem definition. In this procedural interpretation, the underlying optimization problem remains the same, and its set of global minimizers, $\\{(x,y): xy=b\\}$, is indeed preserved. The algorithm is simply guided away from problematic regions. Since this is a valid and common way to implement such a safeguard, this interpretation is the most reasonable. Under this reading, the statement is correct.\nVerdict: **Correct**.", "answer": "$$\\boxed{ABCE}$$", "id": "3097240"}, {"introduction": "Real-world optimization problems are often complicated by constraints, such as requiring variables to be positive or to sum to one. This hands-on coding practice demonstrates how to adapt alternating minimization to solve a constrained bilinear inverse problem, a structure found in many scientific applications [@problem_id:3097289]. You will implement the core update steps, which involve solving a standard least-squares problem, and then enforce the constraints by projecting the solution onto the feasible set, highlighting the crucial role of projection in practical algorithm design.", "problem": "You are given a bilinear inverse problem defined as follows. Let $A \\in \\mathbb{R}^{m \\times n}$ be a known matrix and $b \\in \\mathbb{R}^{m}$ be an observation vector generated according to the bilinear sensing model\n$$\nb \\;=\\; A\\,(x \\odot y),\n$$\nwhere $x \\in \\mathbb{R}^{n}$ and $y \\in \\mathbb{R}^{n}$ are unknown vectors with the positivity and normalization constraints $x \\ge 0$, $y \\ge 0$, $\\sum_{i=1}^{n} x_i = 1$, and $\\sum_{i=1}^{n} y_i = 1$. Here, $\\odot$ denotes the element-wise (Hadamard) product. The goal is to estimate $x$ and $y$ by minimizing the squared residual\n$$\nf(x,y) \\;=\\; \\tfrac{1}{2}\\,\\left\\|A\\big(\\operatorname{diag}(y)\\,x\\big) - b\\right\\|_2^2 \\;=\\; \\tfrac{1}{2}\\,\\left\\|A\\big(x \\odot y\\big) - b\\right\\|_2^2,\n$$\nsubject to the constraints $x \\ge 0$, $y \\ge 0$, $\\sum_{i=1}^{n} x_i = 1$, and $\\sum_{i=1}^{n} y_i = 1$.\n\nStarting from the fundamental definition of least squares and the Euclidean projection onto a closed convex set, implement Alternating Minimization: alternately minimize $f(x,y)$ over $x$ with $y$ fixed, and over $y$ with $x$ fixed. At each block update, linearize the bilinear term to obtain a least-squares subproblem and then enforce the constraints by Euclidean projection onto the probability simplex\n$$\n\\Delta^n \\;=\\; \\left\\{z \\in \\mathbb{R}^n \\;:\\; z_i \\ge 0 \\text{ for all } i, \\;\\sum_{i=1}^{n} z_i = 1 \\right\\}.\n$$\nTo investigate the role of projections, implement and compare two variants:\n- Variant $\\mathsf{proj}$: after each least-squares block update, project the updated vector onto $\\Delta^n$.\n- Variant $\\mathsf{unproj}$: perform the least-squares block updates without any projection.\n\nFor each variant, after a fixed number of iterations, report:\n- The final residual $r \\;=\\; \\left\\|A\\,(x \\odot y) - b\\right\\|_2$.\n- The total constraint violation $v$, defined for a pair $(x,y)$ by\n$$\nv \\;=\\; \\left(\\sum_{i=1}^{n} \\max\\{0, -x_i\\} \\right) \\;+\\; \\left|\\sum_{i=1}^{n} x_i - 1\\right| \\;+\\; \\left(\\sum_{i=1}^{n} \\max\\{0, -y_i\\} \\right) \\;+\\; \\left|\\sum_{i=1}^{n} y_i - 1\\right|.\n$$\n\nYour program must implement both variants and compute the metrics $(r, v)$ for each test case described below. No physical units are involved. Angles are not part of this problem.\n\nTest Suite:\n- Case $1$ (happy path): $m = 7$, $n = 5$. Generate $A$ with independent standard normal entries using random seed $s_A = 0$. Generate $x^\\star$ and $y^\\star$ by sampling independent exponential entries with rate $1$ and normalizing each to lie in $\\Delta^n$ using random seed $s_\\star = 1$. Set $b = A\\,(x^\\star \\odot y^\\star)$. Initialize the algorithm with $x^{(0)} = \\tfrac{1}{n}\\,\\mathbf{1}$ and $y^{(0)} = \\tfrac{1}{n}\\,\\mathbf{1}$, and perform $T = 50$ alternating updates in each variant.\n- Case $2$ (boundary components near zero): $m = 7$, $n = 5$. Generate $A$ with independent standard normal entries using random seed $s_A = 1$. Choose $\\epsilon = 10^{-6}$ and set\n$$\nx^\\star \\;=\\; \\operatorname{normalize}\\big([\\epsilon,\\, 0.7,\\, 0.299999,\\, \\epsilon,\\, \\epsilon]\\big), \\quad\ny^\\star \\;=\\; \\operatorname{normalize}\\big([0.6,\\, \\epsilon,\\, \\epsilon,\\, 0.4,\\, \\epsilon]\\big),\n$$\nwhere $\\operatorname{normalize}(z)$ denotes $z/\\sum_i z_i$ to ensure membership in $\\Delta^n$. Set $b = A\\,(x^\\star \\odot y^\\star)$, initialize $x^{(0)} = \\tfrac{1}{n}\\,\\mathbf{1}$ and $y^{(0)} = \\tfrac{1}{n}\\,\\mathbf{1}$, and perform $T = 50$ updates.\n- Case $3$ (ill-conditioned design): $m = 7$, $n = 5$. Generate $A$ with independent standard normal entries using random seed $s_A = 2$ and scale its columns by the diagonal matrix $D = \\operatorname{diag}([1,\\, 10^{-2},\\, 10^{-3},\\, 1,\\, 10^{-4}])$. Generate $x^\\star$ and $y^\\star$ by sampling independent exponential entries with rate $1$ and normalizing each to lie in $\\Delta^n$ using random seed $s_\\star = 3$. Set $b = A\\,(x^\\star \\odot y^\\star)$, initialize $x^{(0)} = \\tfrac{1}{n}\\,\\mathbf{1}$ and $y^{(0)} = \\tfrac{1}{n}\\,\\mathbf{1}$, and perform $T = 50$ updates.\n\nImplementation requirements:\n- In each $x$-update with $y$ fixed, reduce $f(x,y)$ to a least-squares problem of the form $\\min_x \\tfrac{1}{2}\\|B\\,x - b\\|_2^2$ with a suitably defined matrix $B$, then update $x$ by the least-squares solution followed by projection onto $\\Delta^n$ in variant $\\mathsf{proj}$, or without projection in variant $\\mathsf{unproj}$.\n- In each $y$-update with $x$ fixed, similarly reduce to $\\min_y \\tfrac{1}{2}\\|C\\,y - b\\|_2^2$ with a suitable matrix $C$, followed by projection in variant $\\mathsf{proj}$, or without projection in variant $\\mathsf{unproj}$.\n- Use deterministic random seeds exactly as specified above.\n\nFinal Output Format:\nYour program should produce a single line of output containing all twelve results in the order\n$$\n\\big[r^{\\mathrm{proj}}_1,\\, r^{\\mathrm{unproj}}_1,\\, v^{\\mathrm{proj}}_1,\\, v^{\\mathrm{unproj}}_1,\\, r^{\\mathrm{proj}}_2,\\, r^{\\mathrm{unproj}}_2,\\, v^{\\mathrm{proj}}_2,\\, v^{\\mathrm{unproj}}_2,\\, r^{\\mathrm{proj}}_3,\\, r^{\\mathrm{unproj}}_3,\\, v^{\\mathrm{proj}}_3,\\, v^{\\mathrm{unproj}}_3\\big],\n$$\nprinted as a comma-separated list enclosed in square brackets (for example, $[a,b,c,d,e,f,g,h,i,j,k,l]$), where each entry is a floating-point number.", "solution": "The problem at hand is to estimate two unknown vectors, $x \\in \\mathbb{R}^n$ and $y \\in \\mathbb{R}^n$, from an observation vector $b \\in \\mathbb{R}^m$ acquired through a bilinear sensing model $b = A(x \\odot y)$, where $A \\in \\mathbb{R}^{m \\times n}$ is a known matrix and $\\odot$ denotes the element-wise product. The estimation is formulated as a constrained optimization problem, seeking to minimize the squared residual while enforcing positivity and normalization constraints on $x$ and $y$.\n\nThe objective function is given by:\n$$\nf(x,y) = \\tfrac{1}{2}\\,\\left\\|A\\big(x \\odot y\\big) - b\\right\\|_2^2\n$$\nThe constraints require that both $x$ and $y$ belong to the probability simplex $\\Delta^n$:\n$$\n\\Delta^n = \\left\\{z \\in \\mathbb{R}^n \\mid z_i \\ge 0 \\text{ for all } i, \\text{ and } \\sum_{i=1}^{n} z_i = 1 \\right\\}\n$$\nDue to the bilinear term $x \\odot y$, the objective function $f(x,y)$ is non-convex, which makes finding a global minimum challenging. The problem specifies the use of an Alternating Minimization (AM) algorithm, a common iterative method for problems with multiple variable blocks. AM proceeds by fixing one block of variables and minimizing the objective function with respect to the other, and then swapping their roles.\n\nThe AM algorithm for this problem iterates through two main steps:\n1.  **$x$-minimization**: Fix $y$ to its current estimate $y^{(k)}$ and solve for $x$.\n2.  **$y$-minimization**: Fix $x$ to its newly computed estimate $x^{(k+1)}$ and solve for $y$.\n\nLet us detail each subproblem.\n\n**1. The $x$-minimization subproblem:**\nWith $y=y^{(k)}$ held constant, the objective function becomes a function of $x$ only:\n$$\n\\min_x \\tfrac{1}{2}\\,\\left\\|A\\big(x \\odot y^{(k)}\\big) - b\\right\\|_2^2\n$$\nWe can express the element-wise product as a matrix-vector product by defining a diagonal matrix $D_y = \\operatorname{diag}(y^{(k)})$. With this, $x \\odot y^{(k)} = D_y x$. The subproblem is then a standard linear least-squares problem:\n$$\n\\min_x \\tfrac{1}{2}\\,\\left\\| (A D_y) x - b \\right\\|_2^2\n$$\nLet $B_k = A \\operatorname{diag}(y^{(k)})$. The unconstrained minimizer $x_{LS}$ is the solution to the normal equations $(B_k^T B_k) x = B_k^T b$. This solution is formally given by $x_{LS} = B_k^\\dagger b$, where $B_k^\\dagger$ is the Moore-Penrose pseudoinverse of $B_k$.\n\n**2. The $y$-minimization subproblem:**\nSimilarly, after obtaining an updated estimate for $x$, which we denote $x^{(k+1)}$, we fix it and solve for $y$. The subproblem is:\n$$\n\\min_y \\tfrac{1}{2}\\,\\left\\|A\\big(x^{(k+1)} \\odot y\\big) - b\\right\\|_2^2\n$$\nUsing the identity $x^{(k+1)} \\odot y = \\operatorname{diag}(x^{(k+1)}) y$, we define $D_x = \\operatorname{diag}(x^{(k+1)})$ and obtain another linear least-squares problem:\n$$\n\\min_y \\tfrac{1}{2}\\,\\left\\| (A D_x) y - b \\right\\|_2^2\n$$\nLet $C_{k+1} = A \\operatorname{diag}(x^{(k+1)})$. The unconstrained minimizer is $y_{LS} = C_{k+1}^\\dagger b$.\n\nThe problem requires a comparison of two variants for handling the constraints.\n\n**Variant $\\mathsf{unproj}$**: In this variant, the constraints are ignored during the iterative updates. The updates are simply the unconstrained least-squares solutions:\n$$\nx^{(k+1)} = \\left(A \\operatorname{diag}(y^{(k)})\\right)^\\dagger b\n$$\n$$\ny^{(k+1)} = \\left(A \\operatorname{diag}(x^{(k+1)})\\right)^\\dagger b\n$$\nThe constraints are not enforced, so the final iterates $x$ and $y$ are not guaranteed to lie in $\\Delta^n$.\n\n**Variant $\\mathsf{proj}$**: This variant enforces the simplex constraints after each least-squares update by projecting the intermediate solution onto $\\Delta^n$. The steps are:\n1.  Compute the unconstrained update for $x$: $x_{LS} = \\left(A \\operatorname{diag}(y^{(k)})\\right)^\\dagger b$.\n2.  Project onto the simplex: $x^{(k+1)} = \\operatorname{proj}_{\\Delta^n}(x_{LS})$.\n3.  Compute the unconstrained update for $y$: $y_{LS} = \\left(A \\operatorname{diag}(x^{(k+1)})\\right)^\\dagger b$.\n4.  Project onto the simplex: $y^{(k+1)} = \\operatorname{proj}_{\\Delta^n}(y_{LS})$.\n\n**Euclidean Projection onto the Probability Simplex**\nThe projection of a vector $z \\in \\mathbb{R}^n$ onto $\\Delta^n$ is the solution to the convex optimization problem:\n$$\n\\operatorname{proj}_{\\Delta^n}(z) = \\arg\\min_{p \\in \\Delta^n} \\tfrac{1}{2} \\|p-z\\|_2^2\n$$\nThe solution to this problem can be found efficiently. The Karush-Kuhn-Tucker (KKT) conditions imply that the projected vector $p$ is of the form $p_i = \\max(0, z_i - \\mu)$ for all $i=1, \\dots, n$, where $\\mu$ is a Lagrange multiplier chosen to satisfy the constraint $\\sum_i p_i = 1$. This means we must find a $\\mu$ such that $\\sum_{i=1}^n \\max(0, z_i - \\mu) = 1$. The function $g(\\mu) = \\sum_{i=1}^n \\max(0, z_i - \\mu)$ is continuous, piecewise-linear, and monotonically decreasing. Finding the root of $g(\\mu) - 1 = 0$ yields the correct $\\mu$. An effective algorithm sorts the elements of $z$ in descending order, say $z_{(1)} \\ge z_{(2)} \\ge \\dots \\ge z_{(n)}$, and finds an index $\\rho$ such that $\\mu$ is determined by the first $\\rho$ elements. The algorithm is as follows:\n1. Sort $z$ into $u$: $u_1 \\ge u_2 \\ge \\dots \\ge u_n$.\n2. Find $\\rho = \\max\\left\\{j \\in \\{1, \\dots, n\\} \\mid u_j - \\frac{1}{j}\\left(\\sum_{i=1}^j u_i - 1\\right) > 0\\right\\}$.\n3. Compute the threshold $\\theta = \\frac{1}{\\rho}\\left(\\sum_{i=1}^\\rho u_i - 1\\right)$.\n4. The components of the projection are $p_i = \\max(0, z_i - \\theta)$.\n\nThis procedure allows us to implement Variant $\\mathsf{proj}$ correctly. The numerical implementation will use `numpy.linalg.lstsq` for a stable solution to the least-squares subproblems, followed by the projection algorithm for Variant $\\mathsf{proj}$. Finally, we compute the residual $r$ and constraint violation $v$ for each variant and test case as specified.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef project_simplex(v: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Projects a vector v onto the probability simplex.\n    \"\"\"\n    n_features = v.shape[0]\n    u = np.sort(v)[::-1]\n    cssv = np.cumsum(u)\n    rho = np.nonzero(u * np.arange(1, n_features + 1) > cssv - 1)[0][-1]\n    theta = (cssv[rho] - 1) / (rho + 1.0)\n    return np.maximum(v - theta, 0)\n\ndef calculate_metrics(A: np.ndarray, b: np.ndarray, x: np.ndarray, y: np.ndarray):\n    \"\"\"\n    Calculates the final residual and constraint violation.\n    \"\"\"\n    # Residual\n    residual_vec = A @ (x * y) - b\n    r = np.linalg.norm(residual_vec)\n\n    # Constraint violation\n    v_x = np.sum(np.maximum(0, -x)) + np.abs(np.sum(x) - 1)\n    v_y = np.sum(np.maximum(0, -y)) + np.abs(np.sum(y) - 1)\n    v = v_x + v_y\n    \n    return r, v\n\ndef run_am_variant(A: np.ndarray, b: np.ndarray, x0: np.ndarray, y0: np.ndarray, T: int, variant: str):\n    \"\"\"\n    Runs an Alternating Minimization variant ('proj' or 'unproj').\n    \"\"\"\n    x, y = x0.copy(), y0.copy()\n    n = A.shape[1]\n\n    for _ in range(T):\n        # x-update\n        # Reformulate as || (A * diag(y)) * x - b ||^2\n        if np.all(np.abs(y) < 1e-9): # handle case where y is near zero\n            B = np.zeros_like(A)\n        else:\n            B = A * y.reshape(1, n)\n        \n        x_ls = np.linalg.lstsq(B, b, rcond=None)[0]\n        \n        if variant == 'proj':\n            x = project_simplex(x_ls)\n        else: # unproj\n            x = x_ls\n\n        # y-update\n        # Reformulate as || (A * diag(x)) * y - b ||^2\n        if np.all(np.abs(x) < 1e-9):\n            C = np.zeros_like(A)\n        else:\n            C = A * x.reshape(1, n)\n            \n        y_ls = np.linalg.lstsq(C, b, rcond=None)[0]\n        \n        if variant == 'proj':\n            y = project_simplex(y_ls)\n        else: # unproj\n            y = y_ls\n\n    return calculate_metrics(A, b, x, y)\n\n\ndef solve():\n    \"\"\"\n    Main function to run test cases and generate the final output.\n    \"\"\"\n    test_cases = []\n    \n    # Case 1 Setup\n    m, n, s_A, s_star, T = 7, 5, 0, 1, 50\n    rng_A = np.random.default_rng(s_A)\n    A1 = rng_A.standard_normal((m, n))\n    rng_star = np.random.default_rng(s_star)\n    x_star_raw = rng_star.exponential(1.0, size=n)\n    x_star1 = x_star_raw / np.sum(x_star_raw)\n    y_star_raw = rng_star.exponential(1.0, size=n)\n    y_star1 = y_star_raw / np.sum(y_star_raw)\n    b1 = A1 @ (x_star1 * y_star1)\n    x0_1 = np.ones(n) / n\n    y0_1 = np.ones(n) / n\n    test_cases.append({'A': A1, 'b': b1, 'x0': x0_1, 'y0': y0_1, 'T': T})\n\n    # Case 2 Setup\n    m, n, s_A, T = 7, 5, 1, 50\n    rng_A = np.random.default_rng(s_A)\n    A2 = rng_A.standard_normal((m, n))\n    eps = 1e-6\n    x_star_raw = np.array([eps, 0.7, 0.299999, eps, eps])\n    x_star2 = x_star_raw / np.sum(x_star_raw)\n    y_star_raw = np.array([0.6, eps, eps, 0.4, eps])\n    y_star2 = y_star_raw / np.sum(y_star_raw)\n    b2 = A2 @ (x_star2 * y_star2)\n    x0_2 = np.ones(n) / n\n    y0_2 = np.ones(n) / n\n    test_cases.append({'A': A2, 'b': b2, 'x0': x0_2, 'y0': y0_2, 'T': T})\n\n    # Case 3 Setup\n    m, n, s_A, s_star, T = 7, 5, 2, 3, 50\n    rng_A = np.random.default_rng(s_A)\n    A_raw = rng_A.standard_normal((m, n))\n    D = np.diag([1.0, 1e-2, 1e-3, 1.0, 1e-4])\n    A3 = A_raw @ D\n    rng_star = np.random.default_rng(s_star)\n    x_star_raw = rng_star.exponential(1.0, size=n)\n    x_star3 = x_star_raw / np.sum(x_star_raw)\n    y_star_raw = rng_star.exponential(1.0, size=n)\n    y_star3 = y_star_raw / np.sum(y_star_raw)\n    b3 = A3 @ (x_star3 * y_star3)\n    x0_3 = np.ones(n) / n\n    y0_3 = np.ones(n) / n\n    test_cases.append({'A': A3, 'b': b3, 'x0': x0_3, 'y0': y0_3, 'T': T})\n\n    results = []\n    for case in test_cases:\n        A, b, x0, y0, T_iter = case['A'], case['b'], case['x0'], case['y0'], case['T']\n        \n        # Run proj variant\n        r_proj, v_proj = run_am_variant(A, b, x0, y0, T_iter, 'proj')\n        \n        # Run unproj variant\n        r_unproj, v_unproj = run_am_variant(A, b, x0, y0, T_iter, 'unproj')\n        \n        results.extend([r_proj, r_unproj, v_proj, v_unproj])\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(f'{x:.6f}' for x in results)}]\")\n\nsolve()\n```", "id": "3097289"}]}