{"hands_on_practices": [{"introduction": "To begin our hands-on exploration of the Pontryagin Maximum Principle (PMP), let's tackle a foundational problem. This exercise explores the time-optimal control of a simple first-order system, modeling a leaky capacitor circuit [@problem_id:1600522]. Intuitively, driving a system to a target state as quickly as possible often requires applying the maximum available effort. This problem allows us to formalize this intuition and demonstrates one of the most famous results of time-optimal control for linear systems: \"bang-bang\" control, where the optimal strategy involves pushing the control input to its physical limits.", "problem": "A simple electronic circuit consists of a capacitor and a leaky resistor. The dynamics of the voltage $x(t)$ across the capacitor are modeled by the first-order linear differential equation:\n$$ \\frac{dx}{dt} = -x(t) + u(t) $$\nHere, $x(t)$ is the voltage in volts at time $t$, and $u(t)$ is a controllable voltage source, also in volts, which represents the control input. Due to power supply limitations, the control input is constrained such that $|u(t)| \\le 1$ for all time $t \\ge 0$.\n\nThe initial voltage on the capacitor is measured to be $x(0) = 5.0$ V. Your task is to determine the control strategy $u(t)$ that drives the capacitor's voltage to zero in the shortest possible time. Calculate this minimum time, $t_f$, required to reach the final state $x(t_f) = 0$.\n\nExpress your answer for the minimum time in seconds, rounded to three significant figures.", "solution": "We are given the controlled linear system\n$$\n\\frac{dx}{dt}=-x(t)+u(t), \\quad |u(t)|\\le 1, \\quad x(0)=5.\n$$\nWe want to minimize the time to reach $x(t_{f})=0$. To achieve this in the shortest time, we must make the velocity $\\frac{dx}{dt}$ as negative as possible at all times, since we start at $x=5$ and want to reach $x=0$. The velocity is given by $-x(t) + u(t)$. Since $x(t)$ will be positive along the entire trajectory, the term $-x(t)$ is negative. To make the velocity most negative, we should choose the smallest possible value for $u(t)$, which is $u(t) \\equiv -1$.\n\nThis intuitive result is confirmed by the Pontryagin Maximum Principle. For a minimum time problem, the cost integrand is $L=1$. The Hamiltonian is $H = \\lambda(-x+u) - 1$. To maximize $H$, we must maximize the term $\\lambda u$. This gives the control law $u = \\operatorname{sgn}(\\lambda)$. The costate dynamics are $\\dot{\\lambda} = - \\partial H / \\partial x = -(-\\lambda) = \\lambda$, which means $\\lambda(t)$ is exponential and never changes sign. To drive $x$ from 5 to 0 requires a negative velocity, so $u$ must be negative, implying $\\lambda  0$ and $u \\equiv -1$.\n\nWith $u(t)\\equiv -1$, the system is\n$$\n\\frac{dx}{dt}=-x(t)-1.\n$$\nSolving this linear ODE, using the standard form $x(t)=(x_0-u_0)\\exp(-t)+u_0$ for a constant input $u_0$, gives\n$$\nx(t)=(5-(-1))\\exp(-t)-1=6\\exp(-t)-1.\n$$\nThe hitting time $t_{f}$ satisfies $x(t_{f})=0$, so\n$$\n6\\exp(-t_{f})-1=0 \\quad \\Longrightarrow \\quad \\exp(-t_{f})=\\frac{1}{6} \\quad \\Longrightarrow \\quad t_{f}=\\ln 6.\n$$\nNumerically, to three significant figures,\n$$\nt_{f}\\approx 1.79.\n$$\nThus the minimum-time control is $u(t)\\equiv -1$ until $x$ reaches zero, and the minimum time is $t_{f}=\\ln 6\\approx 1.79$ seconds.", "answer": "$$\\boxed{1.79}$$", "id": "1600522"}, {"introduction": "Building on the concept of bang-bang control, we now advance to a second-order system known as the double integrator [@problem_id:3162819]. This classic problem models the motion of a mass in one dimension and is a cornerstone of control theory. Unlike the first-order system where a single constant control might suffice, here we must devise a strategy that may involve switching the control from one extreme to the other. By applying the Pontryagin Maximum Principle, you will derive the famous \"switching curve,\" a beautiful and powerful result that provides the complete optimal control policy for bringing the mass to rest from any initial condition.", "problem": "Consider the time-optimal control problem for the double integrator with bounded control. The system dynamics are given by\n$$\\dot{x}_1 = x_2, \\quad \\dot{x}_2 = u,$$\nwith the control constraint\n$$|u| \\leq 1.$$\nGiven an arbitrary initial condition $(x_1(0), x_2(0))$ and the fixed terminal condition\n$$x_1(T) = 0, \\quad x_2(T) = 0,$$\nthe objective is to minimize the transfer time $T$. Using the Pontryagin Maximum Principle (PMP), start from the fundamental definitions of the Hamiltonian, costate dynamics, transversality conditions for free final time, and the maximization condition to derive the optimal control structure $u = \\operatorname{sgn}(\\lambda_2)$, where $\\lambda_2$ is the second costate. Show from first principles that $\\lambda_2$ is affine in time and that an optimal trajectory has at most one switch. Then, by eliminating the costate and switching time using the state dynamics and the condition that the last arc must exactly reach the terminal manifold with zero velocity, derive the switching curve in the $(x_1,x_2)$-plane as a single explicit function $x_1 = \\Phi(x_2)$ that is valid for all $x_2 \\in \\mathbb{R}$. Your final answer must be the explicit analytic expression for this switching curve. No numerical approximation is required, and no units are involved. Provide the final expression for $x_1$ as a function of $x_2$ only.", "solution": "The objective is to minimize the final time $T$, which means we minimize the cost functional $J = \\int_0^T 1 \\, dt$. The integrand is $L(x, u, t) = 1$. The state vector is $x(t) = \\begin{pmatrix} x_1(t) \\\\ x_2(t) \\end{pmatrix}$, and the state dynamics are $\\dot{x} = f(x, u) = \\begin{pmatrix} x_2 \\\\ u \\end{pmatrix}$.\n\nAccording to Pontryagin's Maximum Principle, we define the Hamiltonian $H$.\n$$H(\\lambda, x, u) = \\lambda^T f(x, u) - L(x, u, t)$$\n$$H = \\lambda_1 x_2 + \\lambda_2 u - 1$$\nwhere $\\lambda = \\begin{pmatrix} \\lambda_1 \\\\ \\lambda_2 \\end{pmatrix}$ is the costate vector.\n\nThe costate (or adjoint) equations are given by $\\dot{\\lambda} = -\\frac{\\partial H}{\\partial x}$.\n$$\\dot{\\lambda}_1 = -\\frac{\\partial H}{\\partial x_1} = 0$$\n$$\\dot{\\lambda}_2 = -\\frac{\\partial H}{\\partial x_2} = -\\lambda_1$$\nIntegrating the first equation gives $\\lambda_1(t) = c_1$, where $c_1$ is a constant. Substituting this into the second equation gives $\\dot{\\lambda}_2 = -c_1$. Integrating this yields:\n$$\\lambda_2(t) = -c_1 t + c_2$$\nwhere $c_2$ is another constant of integration. This demonstrates that the costate $\\lambda_2(t)$ is an affine function of time $t$.\n\nThe PMP requires that the optimal control $u^*(t)$ maximizes the Hamiltonian at every instant $t \\in [0, T]$ over the set of admissible controls $U = [-1, 1]$.\n$$u^*(t) = \\arg\\max_{u \\in [-1, 1]} H(\\lambda(t), x(t), u) = \\arg\\max_{u \\in [-1, 1]} (\\lambda_1 x_2 + \\lambda_2 u - 1)$$\nTo maximize $H$, we must maximize the term $\\lambda_2 u$. The optimal control law is therefore a function of the sign of $\\lambda_2(t)$:\n- If $\\lambda_2(t)  0$, we choose $u(t) = 1$.\n- If $\\lambda_2(t)  0$, we choose $u(t) = -1$.\nThis control structure can be written compactly as $u^*(t) = \\operatorname{sgn}(\\lambda_2(t))$, provided $\\lambda_2(t) \\neq 0$. Since $\\lambda_2(t)$ is an affine function of time, it can cross the axis $\\lambda_2=0$ at most once (if $c_1 \\neq 0$). Consequently, an optimal trajectory can have at most one control switch.\n\nThe switching curve is the set of states in the $(x_1, x_2)$-plane from which the origin can be reached by applying a constant control, either $u=+1$ or $u=-1$. These are the final segments of any optimal trajectory. We derive this curve by analyzing the system dynamics in reverse time from the origin.\n\nCase 1: Constant control $u = -1$.\nThe system dynamics are $\\dot{x}_2 = -1$ and $\\dot{x}_1 = x_2$.\nIntegrating from an initial state $(x_1(0), x_2(0))$:\n$x_2(t) = x_2(0) - t$\n$x_1(t) = x_1(0) + x_2(0)t - \\frac{1}{2}t^2$\nWe require the state to reach the origin $(0,0)$ at time $T$.\n$x_2(T) = x_2(0) - T = 0 \\implies T = x_2(0)$. Since $T  0$, we must have $x_2(0)  0$.\n$x_1(T) = x_1(0) + x_2(0)T - \\frac{1}{2}T^2 = 0$.\nSubstituting $T = x_2(0)$:\n$x_1(0) + x_2(0)(x_2(0)) - \\frac{1}{2}(x_2(0))^2 = 0 \\implies x_1(0) + \\frac{1}{2}x_2(0)^2 = 0$.\nDropping the $(0)$ notation for the initial state, we get the curve for any state $(x_1, x_2)$:\n$$x_1 = -\\frac{1}{2}x_2^2, \\quad \\text{for } x_2 \\ge 0$$\nThis is the part of the switching curve where the final control action is $u=-1$.\n\nCase 2: Constant control $u = +1$.\nThe system dynamics are $\\dot{x}_2 = 1$ and $\\dot{x}_1 = x_2$.\nIntegrating from $(x_1(0), x_2(0))$:\n$x_2(t) = x_2(0) + t$\n$x_1(t) = x_1(0) + x_2(0)t + \\frac{1}{2}t^2$\nWe require the state to reach $(0,0)$ at time $T$.\n$x_2(T) = x_2(0) + T = 0 \\implies T = -x_2(0)$. Since $T  0$, this requires $x_2(0)  0$.\n$x_1(T) = x_1(0) + x_2(0)T + \\frac{1}{2}T^2 = 0$.\nSubstituting $T = -x_2(0)$:\n$x_1(0) + x_2(0)(-x_2(0)) + \\frac{1}{2}(-x_2(0))^2 = 0 \\implies x_1(0) - \\frac{1}{2}x_2(0)^2 = 0$.\nThis gives the curve for any state $(x_1,x_2)$:\n$$x_1 = \\frac{1}{2}x_2^2, \\quad \\text{for } x_2 \\le 0$$\nThis is the part of the switching curve where the final control action is $u=+1$.\n\nThe complete switching curve, $\\mathcal{S}$, is the union of these two parabolic arcs and the origin. To express this as a single explicit function $x_1 = \\Phi(x_2)$, we observe:\nIf $x_2 \\ge 0$, then $|x_2| = x_2$. The expression $x_1 = -\\frac{1}{2}x_2|x_2|$ becomes $x_1 = -\\frac{1}{2}x_2(x_2) = -\\frac{1}{2}x_2^2$. This matches the first piece.\nIf $x_2 \\le 0$, then $|x_2| = -x_2$. The expression $x_1 = -\\frac{1}{2}x_2|x_2|$ becomes $x_1 = -\\frac{1}{2}x_2(-x_2) = \\frac{1}{2}x_2^2$. This matches the second piece.\nThus, the switching curve is described by the single explicit function:\n$$x_1 = -\\frac{1}{2}x_2|x_2|$$", "answer": "$$\\boxed{x_1 = -\\frac{1}{2}x_2|x_2|}$$", "id": "3162819"}, {"introduction": "Our final practice problem showcases the versatility of the Pontryagin Maximum Principle beyond simple time-optimal scenarios. Here, the goal is not just to reach a target, but to do so while minimizing a combination of control energy and elapsed time [@problem_id:1600523]. Furthermore, the destination is not a fixed point but a manifold—a circle of a given radius—and the final time is not predetermined. This problem requires a careful application of the transversality conditions of PMP to handle the free final time and terminal manifold, demonstrating how the principle elegantly handles more complex and realistic optimization goals.", "problem": "A particle in a two-dimensional Cartesian plane, with position vector $\\mathbf{x}(t) = [x_1(t), x_2(t)]^T$, is controlled by a velocity input $\\mathbf{u}(t) = [u_1(t), u_2(t)]^T$. The dynamics of the particle are governed by the simple integrator model:\n$$\n\\dot{\\mathbf{x}}(t) = \\mathbf{u}(t)\n$$\nThe particle starts at the origin at time $t=0$, i.e., $\\mathbf{x}(0) = [0, 0]^T$. The objective is to steer the particle to a target circle of radius $R$ centered at the origin. The final time, $t_f$, is not fixed and is determined by when the particle first reaches this circle. The terminal condition is therefore given by the manifold equation $x_1(t_f)^2 + x_2(t_f)^2 = R^2$.\n\nThe goal is to find a control input $\\mathbf{u}(t)$ that minimizes the objective functional $J$, which represents a combination of control energy and time duration:\n$$\nJ = \\int_{0}^{t_f} \\left( \\frac{1}{2} (u_1(t)^2 + u_2(t)^2) + 1 \\right) dt\n$$\n\nDetermine the minimum possible value of this objective functional, $J_{min}$, in terms of the radius $R$.", "solution": "We apply Pontryagin’s Maximum Principle to the problem of minimizing\n$$\nJ=\\int_{0}^{t_{f}}\\left(\\frac{1}{2}\\left(u_{1}(t)^{2}+u_{2}(t)^{2}\\right)+1\\right)dt=\\int_{0}^{t_{f}}\\left(\\frac{1}{2}\\|\\mathbf{u}(t)\\|^{2}+1\\right)dt\n$$\nsubject to the dynamics $\\dot{\\mathbf{x}}(t)=\\mathbf{u}(t)$, initial condition $\\mathbf{x}(0)=\\mathbf{0}$, free final time $t_{f}$, and terminal manifold $g(\\mathbf{x}(t_{f}))=\\|\\mathbf{x}(t_{f})\\|^{2}-R^{2}=0$.\n\nThe cost integrand is $L(\\mathbf{u}) = \\frac{1}{2}\\|\\mathbf{u}\\|^{2}+1$. Define the Hamiltonian\n$$\nH(\\mathbf{x},\\mathbf{u},\\boldsymbol{\\lambda})=\\boldsymbol{\\lambda}^{T}\\mathbf{u} - L(\\mathbf{u}) = \\boldsymbol{\\lambda}^{T}\\mathbf{u} - \\left(\\frac{1}{2}\\|\\mathbf{u}\\|^{2}+1\\right).\n$$\nTo maximize the Hamiltonian with respect to $\\mathbf{u}$, we set the gradient to zero:\n$$\n\\frac{\\partial H}{\\partial \\mathbf{u}}=\\boldsymbol{\\lambda}-\\mathbf{u}=\\mathbf{0}\\quad\\Rightarrow\\quad \\mathbf{u}^{*}(t)=\\boldsymbol{\\lambda}(t).\n$$\nThe costate dynamics are\n$$\n\\dot{\\boldsymbol{\\lambda}}(t)=-\\frac{\\partial H}{\\partial \\mathbf{x}}=\\mathbf{0}\\quad\\Rightarrow\\quad \\boldsymbol{\\lambda}(t)=\\boldsymbol{\\lambda}_{0}\\ \\text{(constant)}.\n$$\nTherefore the optimal control is constant, $\\mathbf{u}^{*}(t)=\\boldsymbol{\\lambda}_{0}$, and the state evolves as\n$$\n\\mathbf{x}(t)=\\int_{0}^{t}\\mathbf{u}^{*}(\\tau)\\,d\\tau=\\mathbf{u}^{*}\\,t.\n$$\nThe terminal manifold condition is\n$$\n\\|\\mathbf{x}(t_{f})\\|^{2}=R^{2}\\quad\\Rightarrow\\quad \\|\\mathbf{u}^{*}\\|^{2}\\,t_{f}^{2}=R^{2}\\quad\\Rightarrow\\quad t_{f}=\\frac{R}{\\|\\mathbf{u}^{*}\\|}.\n$$\nBecause the final time is free and there is no terminal cost, the transversality condition for an autonomous system requires the maximized Hamiltonian to be zero along the optimal path:\n$$\nH^{*}(t)=0.\n$$\nSubstituting $\\mathbf{u}^{*}=\\boldsymbol{\\lambda}_{0}$ into the Hamiltonian gives the maximized value:\n$$\nH^{*}=(\\boldsymbol{\\lambda}_{0})^{T}\\boldsymbol{\\lambda}_{0} - \\left(\\frac{1}{2}\\|\\boldsymbol{\\lambda}_{0}\\|^{2}+1\\right) = \\|\\boldsymbol{\\lambda}_{0}\\|^{2} - \\frac{1}{2}\\|\\boldsymbol{\\lambda}_{0}\\|^{2} - 1 = \\frac{1}{2}\\|\\boldsymbol{\\lambda}_{0}\\|^{2} - 1.\n$$\nSetting $H^{*}=0$ yields\n$$\n\\frac{1}{2}\\|\\boldsymbol{\\lambda}_{0}\\|^{2}-1=0\\quad\\Rightarrow\\quad \\|\\boldsymbol{\\lambda}_{0}\\|^{2}=2.\n$$\nSince $\\mathbf{u}^{*} = \\boldsymbol{\\lambda}_0$, we have $\\|\\mathbf{u}^{*}\\|^{2}=2$, so $\\|\\mathbf{u}^{*}\\|=\\sqrt{2}$. Hence, the optimal time is\n$$\nt_{f}=\\frac{R}{\\|\\mathbf{u}^{*}\\|} = \\frac{R}{\\sqrt{2}}.\n$$\nThe minimum cost is then\n$$\nJ_{\\min}=\\int_{0}^{t_{f}}\\left(\\frac{1}{2}\\|\\mathbf{u}^{*}\\|^{2}+1\\right)dt\n=\\int_{0}^{t_{f}}\\left(\\frac{1}{2}\\cdot 2+1\\right)dt\n=\\int_{0}^{t_{f}}2\\,dt\n=2t_{f}\n=2\\cdot\\frac{R}{\\sqrt{2}}\n=\\sqrt{2}\\,R.\n$$\nThis result can be verified by a direct variational argument. For any fixed $t_{f}$ and terminal point $\\mathbf{y}$ with $\\|\\mathbf{y}\\|=R$, the minimal control energy is achieved by a constant control $\\mathbf{u}(t)=\\mathbf{y}/t_{f}$, yielding\n$$\nJ(t_{f})=\\frac{1}{2}\\int_{0}^{t_{f}}\\|\\mathbf{u}\\|^{2}dt+\\int_{0}^{t_{f}}1\\,dt=\\frac{1}{2} t_{f}\\frac{R^{2}}{t_{f}^{2}}+t_{f}=\\frac{R^{2}}{2t_{f}}+t_{f}.\n$$\nMinimizing over $t_{f}0$ by setting $\\frac{dJ}{dt_{f}}=-\\frac{R^{2}}{2t_{f}^{2}}+1=0$ gives $t_{f}=R/\\sqrt{2}$, and thus $J_{\\min}=\\sqrt{2}\\,R$, consistent with the Pontryagin analysis.", "answer": "$$\\boxed{\\sqrt{2}\\,R}$$", "id": "1600523"}]}