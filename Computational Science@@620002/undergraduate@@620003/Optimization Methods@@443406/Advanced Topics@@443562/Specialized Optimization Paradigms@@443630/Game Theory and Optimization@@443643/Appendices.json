{"hands_on_practices": [{"introduction": "We begin our practical journey with the foundational case of an unconstrained, two-player game with quadratic payoffs. This exercise demonstrates how the concept of a Nash Equilibrium, where each player makes their best possible move given the other's strategy, can be translated into a system of linear equations. By solving this system, you will find the exact equilibrium analytically, providing a crucial baseline for understanding the more complex iterative methods that follow [@problem_id:2448674].", "problem": "You are given a family of two-player continuous-strategy games parameterized by real matrices and vectors. Player $1$ chooses a vector $x \\in \\mathbb{R}^{n_1}$ and Player $2$ chooses a vector $y \\in \\mathbb{R}^{n_2}$. The payoffs are\n$$\nu_1(x,y) = -\\tfrac{1}{2}\\,x^\\top A x \\;-\\; x^\\top B y \\;+\\; b^\\top x,\n\\qquad\nu_2(x,y) = -\\tfrac{1}{2}\\,y^\\top C y \\;-\\; y^\\top B^\\top x \\;+\\; c^\\top y,\n$$\nwhere $A \\in \\mathbb{R}^{n_1 \\times n_1}$ and $C \\in \\mathbb{R}^{n_2 \\times n_2}$ are symmetric positive definite, $B \\in \\mathbb{R}^{n_1 \\times n_2}$, $b \\in \\mathbb{R}^{n_1}$, and $c \\in \\mathbb{R}^{n_2}$. A strategy pair $(x^\\star,y^\\star)$ is a Nash equilibrium (NE) if $x^\\star$ maximizes $u_1(\\cdot,y^\\star)$ and $y^\\star$ maximizes $u_2(x^\\star,\\cdot)$ over $\\mathbb{R}^{n_1}$ and $\\mathbb{R}^{n_2}$, respectively. For an interior unconstrained equilibrium, the first-order stationarity conditions must hold:\n$$\n\\nabla_x u_1(x^\\star,y^\\star) = 0, \\qquad \\nabla_y u_2(x^\\star,y^\\star) = 0.\n$$\n\nFor each parameter set below, determine a strategy profile $(x^\\star,y^\\star)$ that satisfies the above stationarity conditions up to a numerical tolerance of $10^{-6}$ in the infinity norm of the joint residual vector. All quantities are dimensionless. Report the result as a list concatenating $x^\\star$ followed by $y^\\star$, with each entry rounded to six decimal places using standard rounding.\n\nTest suite:\n1. Case 1 with $n_1 = 1$, $n_2 = 1$:\n   - $A = [2]$, $B = [1]$, $C = [3]$, $b = [1]$, $c = [2]$.\n2. Case 2 with $n_1 = 2$, $n_2 = 1$:\n   - $A = \\begin{bmatrix} 4 & 1 \\\\ 1 & 3 \\end{bmatrix}$, $B = \\begin{bmatrix} 1 \\\\ 0.5 \\end{bmatrix}$, $C = [2]$, $b = \\begin{bmatrix} 1 \\\\ 0 \\end{bmatrix}$, $c = [1]$.\n3. Case 3 with $n_1 = 1$, $n_2 = 2$:\n   - $A = [5]$, $B = \\begin{bmatrix} 1 & -0.5 \\end{bmatrix}$, $C = \\begin{bmatrix} 3 & 1 \\\\ 1 & 2 \\end{bmatrix}$, $b = [0]$, $c = \\begin{bmatrix} 1 \\\\ -1 \\end{bmatrix}$.\n\nFinal output format:\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, where each element is itself a bracketed comma-separated list of numbers corresponding to a test case in the order listed above. For example,\n$$\n\\texttt{[[x\\_1,\\dots,x\\_{n\\_1},y\\_1,\\dots,y\\_{n\\_2}],[\\dots],[\\dots]]}\n$$\nNo additional text should be printed. All numbers must be rounded to six decimal places and printed in standard decimal notation (no scientific notation).", "solution": "The problem presented is a well-defined task from computational game theory. It requires finding the Nash equilibrium for a class of two-player games with continuous strategy spaces and quadratic payoff functions. A rigorous analysis must precede any computation.\n\nThe problem is valid. It is scientifically grounded in the principles of game theory and optimization, it is well-posed with sufficient and consistent data, and it is expressed in objective mathematical language. All conditions for validity are met.\n\nLet us proceed with the derivation of the solution.\n\nA strategy profile $(x^\\star, y^\\star)$ constitutes a Nash Equilibrium if neither player has a unilateral incentive to deviate. This means $x^\\star$ must maximize Player 1's payoff $u_1(x, y^\\star)$ with respect to $x$, and $y^\\star$ must maximize Player 2's payoff $u_2(x^\\star, y)$ with respect to $y$.\n\nThe payoff functions are given as:\n$$\nu_1(x,y) = -\\tfrac{1}{2}\\,x^\\top A x - x^\\top B y + b^\\top x,\n$$\n$$\nu_2(x,y) = -\\tfrac{1}{2}\\,y^\\top C y - y^\\top B^\\top x + c^\\top y.\n$$\nFor a fixed strategy $\\bar{y}$ of Player 2, Player 1's payoff $u_1(x, \\bar{y})$ is a function of $x$. The Hessian matrix of this function with respect to $x$ is $\\nabla_{xx}^2 u_1 = -A$. The problem states that $A$ is a symmetric positive definite matrix. Consequently, $-A$ is symmetric and negative definite. This proves that $u_1(x, \\bar{y})$ is a strictly concave function of $x$. Similarly, for a fixed strategy $\\bar{x}$ of Player 1, the Hessian of $u_2(\\bar{x}, y)$ with respect to $y$ is $\\nabla_{yy}^2 u_2 = -C$. Since $C$ is also given as symmetric positive definite, $u_2(\\bar{x}, y)$ is a strictly concave function of $y$.\n\nFor strictly concave functions defined on an unconstrained Euclidean space (here, $\\mathbb{R}^{n_1}$ and $\\mathbb{R}^{n_2}$), the first-order necessary conditions for a maximum are also sufficient. A unique global maximum is found at the point where the gradient is the zero vector.\n\nThe first-order conditions for optimality are $\\nabla_x u_1(x^\\star, y^\\star) = 0$ and $\\nabla_y u_2(x^\\star, y^\\star) = 0$. We compute the gradients:\nUsing standard rules of matrix calculus, where $A$ and $C$ are symmetric:\n$$\n\\nabla_x u_1(x,y) = \\nabla_x \\left(-\\tfrac{1}{2}x^\\top Ax - x^\\top By + b^\\top x\\right) = -Ax - By + b.\n$$\n$$\n\\nabla_y u_2(x,y) = \\nabla_y \\left(-\\tfrac{1}{2}y^\\top Cy - y^\\top B^\\top x + c^\\top y\\right) = -Cy - B^\\top x + c.\n$$\n\nSetting these gradients to zero gives the system of equations that a Nash Equilibrium $(x^\\star, y^\\star)$ must satisfy:\n$$\n-Ax^\\star - By^\\star + b = 0 \\quad \\implies \\quad Ax^\\star + By^\\star = b\n$$\n$$\n-B^\\top x^\\star - Cy^\\star + c = 0 \\quad \\implies \\quad B^\\top x^\\star + Cy^\\star = c\n$$\nThis is a system of linear equations. We can express it in a more compact block matrix form. Let $z = \\begin{bmatrix} x \\\\ y \\end{bmatrix}$ be the concatenated vector of strategies. Then the equilibrium condition is:\n$$\n\\begin{bmatrix}\nA & B \\\\\nB^\\top & C\n\\end{bmatrix}\n\\begin{bmatrix}\nx^\\star \\\\\ny^\\star\n\\end{bmatrix}\n=\n\\begin{bmatrix}\nb \\\\\nc\n\\end{bmatrix}\n$$\nLet this system be denoted by $M z^\\star = d$, where $M = \\begin{bmatrix} A & B \\\\ B^\\top & C \\end{bmatrix}$ is the coefficient matrix of size $(n_1+n_2) \\times (n_1+n_2)$, $z^\\star = \\begin{bmatrix} x^\\star \\\\ y^\\star \\end{bmatrix}$ is the unknown equilibrium strategy profile, and $d = \\begin{bmatrix} b \\\\ c \\end{bmatrix}$ is the constant vector.\n\nA unique Nash equilibrium exists if and only if the matrix $M$ is non-singular. For each test case provided, we can construct the matrix $M$ and vector $d$ and solve the linear system for $z^\\star$. The solution is formally given by $z^\\star = M^{-1} d$.\n\nWe apply this procedure to each test case.\n\n**Case 1:** $n_1=1, n_2=1$\nParameters: $A = [2]$, $B = [1]$, $C = [3]$, $b = [1]$, $c = [2]$.\nThe system is:\n$$\n\\begin{bmatrix} 2 & 1 \\\\ 1 & 3 \\end{bmatrix} \\begin{bmatrix} x^\\star \\\\ y^\\star \\end{bmatrix} = \\begin{bmatrix} 1 \\\\ 2 \\end{bmatrix}\n$$\nThe determinant of the matrix is $(2)(3) - (1)(1) = 5$, which is non-zero. The solution is:\n$$\n\\begin{bmatrix} x^\\star \\\\ y^\\star \\end{bmatrix} = \\frac{1}{5} \\begin{bmatrix} 3 & -1 \\\\ -1 & 2 \\end{bmatrix} \\begin{bmatrix} 1 \\\\ 2 \\end{bmatrix} = \\frac{1}{5} \\begin{bmatrix} 1 \\\\ 3 \\end{bmatrix} = \\begin{bmatrix} 0.2 \\\\ 0.6 \\end{bmatrix}\n$$\nThe result is $(x^\\star, y^\\star) = (0.2, 0.6)$.\n\n**Case 2:** $n_1=2, n_2=1$\nParameters: $A = \\begin{bmatrix} 4 & 1 \\\\ 1 & 3 \\end{bmatrix}$, $B = \\begin{bmatrix} 1 \\\\ 0.5 \\end{bmatrix}$, $C = [2]$, $b = \\begin{bmatrix} 1 \\\\ 0 \\end{bmatrix}$, $c = [1]$.\nThe concatenated vector is $z = \\begin{bmatrix} x_1 \\\\ x_2 \\\\ y_1 \\end{bmatrix}$. The linear system is:\n$$\n\\begin{bmatrix} 4 & 1 & 1 \\\\ 1 & 3 & 0.5 \\\\ 1 & 0.5 & 2 \\end{bmatrix} \\begin{bmatrix} x_1^\\star \\\\ x_2^\\star \\\\ y_1^\\star \\end{bmatrix} = \\begin{bmatrix} 1 \\\\ 0 \\\\ 1 \\end{bmatrix}\n$$\nSolving this $3 \\times 3$ system yields the unique solution.\n\n**Case 3:** $n_1=1, n_2=2$\nParameters: $A = [5], B = \\begin{bmatrix} 1 & -0.5 \\end{bmatrix}, C = \\begin{bmatrix} 3 & 1 \\\\ 1 & 2 \\end{bmatrix}, b = [0], c = \\begin{bmatrix} 1 \\\\ -1 \\end{bmatrix}$.\nThe concatenated vector is $z = \\begin{bmatrix} x_1 \\\\ y_1 \\\\ y_2 \\end{bmatrix}$. The linear system is:\n$$\n\\begin{bmatrix} 5 & 1 & -0.5 \\\\ 1 & 3 & 1 \\\\ -0.5 & 1 & 2 \\end{bmatrix} \\begin{bmatrix} x_1^\\star \\\\ y_1^\\star \\\\ y_2^\\star \\end{bmatrix} = \\begin{bmatrix} 0 \\\\ 1 \\\\ -1 \\end{bmatrix}\n$$\nThis $3 \\times 3$ system also has a unique solution.\n\nThe implementation will construct these systems and use a standard high-precision linear solver to find the solution vectors, which are then formatted as required. The use of a direct solver such as LU decomposition ensures that the numerical tolerance on the residual is satisfied to a high degree of precision, far exceeding the requirement of $10^{-6}$.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves for the Nash Equilibrium of a two-player continuous-strategy game\n    with quadratic payoffs for a given set of test cases.\n    \"\"\"\n    \n    # Define the test cases from the problem statement.\n    test_cases = [\n        {\n            \"A\": np.array([[2.0]]),\n            \"B\": np.array([[1.0]]),\n            \"C\": np.array([[3.0]]),\n            \"b\": np.array([1.0]),\n            \"c\": np.array([2.0]),\n        },\n        {\n            \"A\": np.array([[4.0, 1.0], [1.0, 3.0]]),\n            \"B\": np.array([[1.0], [0.5]]),\n            \"C\": np.array([[2.0]]),\n            \"b\": np.array([1.0, 0.0]),\n            \"c\": np.array([1.0]),\n        },\n        {\n            \"A\": np.array([[5.0]]),\n            \"B\": np.array([[1.0, -0.5]]),\n            \"C\": np.array([[3.0, 1.0], [1.0, 2.0]]),\n            \"b\": np.array([0.0]),\n            \"c\": np.array([1.0, -1.0]),\n        },\n    ]\n\n    results = []\n    for case in test_cases:\n        A = case[\"A\"]\n        B = case[\"B\"]\n        C = case[\"C\"]\n        b = case[\"b\"]\n        c = case[\"c\"]\n\n        n1 = A.shape[0]\n        n2 = C.shape[0]\n\n        # Construct the block matrix M = [[A, B], [B.T, C]]\n        # The total size is (n1+n2) x (n1+n2)\n        M = np.block([\n            [A, B],\n            [B.T, C]\n        ])\n\n        # Construct the concatenated vector d = [b, c]\n        d = np.concatenate((b, c))\n\n        # Solve the linear system M*z = d for z = [x, y]\n        # np.linalg.solve is a high-precision direct solver, which is\n        # appropriate for this problem and ensures the residual tolerance\n        # is met.\n        z_star = np.linalg.solve(M, d)\n\n        results.append(z_star)\n\n    # Format the output string exactly as required.\n    # Each number must be rounded to six decimal places.\n    case_strings = []\n    for res_vector in results:\n        # Using f-string formatting handles rounding and avoids scientific notation.\n        formatted_vector = [f\"{x:.6f}\" for x in res_vector]\n        case_strings.append(f\"[{','.join(formatted_vector)}]\")\n    \n    final_output = f\"[{','.join(case_strings)}]\"\n    \n    # Final print statement in the exact required format.\n    print(final_output)\n\nsolve()\n```", "id": "2448674"}, {"introduction": "While direct analytical solutions are elegant, many large-scale or decentralized games require iterative approaches. This practice challenges you to implement and compare four fundamental algorithms used to compute Nash equilibria: Best Response, Gradient Play, Proximal Best Response, and the Extragradient method [@problem_id:3154618]. By benchmarking their performance on a suite of games with varying properties, you will develop a hands-on intuition for their convergence rates, stability, and practical effectiveness.", "problem": "You are asked to design, implement, and compare four iterative methods for computing a Nash equilibrium in smooth, strictly convex quadratic two-player games, and to benchmark their convergence behavior across a suite of test cases. A Nash equilibrium is defined by the point where each player’s strategy is optimal given the other’s strategy. For differentiable cost functions, the first-order optimality conditions characterize the Nash equilibrium as a zero of a suitable operator. Your program must be a complete, runnable program that takes no input and prints a single line with the aggregated results.\n\nThe fundamental base for this task is as follows.\n\n- Two players choose vectors $x \\in \\mathbb{R}^{n}$ and $y \\in \\mathbb{R}^{m}$, respectively. Player $1$ minimizes the quadratic objective\n$$\nf_1(x,y) = \\tfrac{1}{2} x^\\top Q_1 x + x^\\top C y + b_1^\\top x + c_1,\n$$\nand Player $2$ minimizes\n$$\nf_2(x,y) = \\tfrac{1}{2} y^\\top Q_2 y + y^\\top D x + b_2^\\top y + c_2,\n$$\nwhere $Q_1 \\in \\mathbb{R}^{n \\times n}$ and $Q_2 \\in \\mathbb{R}^{m \\times m}$ are symmetric positive definite matrices, $C \\in \\mathbb{R}^{n \\times m}$ and $D \\in \\mathbb{R}^{m \\times n}$ are coupling matrices, and $b_1 \\in \\mathbb{R}^n$, $b_2 \\in \\mathbb{R}^m$ are vectors. Constants $c_1$ and $c_2$ play no role in optimality and may be arbitrary.\n\n- The operator mapping that encodes the first-order optimality conditions is\n$$\nF(z) = \\begin{bmatrix}\n\\nabla_x f_1(x,y) \\\\\n\\nabla_y f_2(x,y)\n\\end{bmatrix}\n= M z + q,\n\\quad\nz = \\begin{bmatrix} x \\\\ y \\end{bmatrix},\n\\quad\nM = \\begin{bmatrix} Q_1 & C \\\\ D & Q_2 \\end{bmatrix},\n\\quad\nq = \\begin{bmatrix} b_1 \\\\ b_2 \\end{bmatrix}.\n$$\nUnder symmetric positive definiteness of $M$ (for example, with $D=C^\\top$ and $Q_1$, $Q_2$ symmetric positive definite), $F$ is strongly monotone and Lipschitz continuous. The unique Nash equilibrium $z^\\star$ solves $F(z^\\star) = 0$.\n\nYour task is to implement the following iterative methods, starting from the fundamental base above and without relying on any shortcut formulas in the problem statement.\n\n- Best Response (BR): Sequentially minimize each player’s objective with the opponent’s current strategy held fixed, using the exact solution of the quadratic subproblem.\n\n- Gradient Play (GP): Apply a simultaneous gradient-based step to both players’ strategies using the operator $F$.\n\n- Proximal Best Response (PBR): Modify Best Response by adding a quadratic regularization term to each player’s subproblem, penalizing deviation from the current iterate to induce a contraction and stabilize the iteration.\n\n- Extragradient (EG): Apply an additional look-ahead gradient step before the main update to correct for the operator’s curvature; use the mapping $F$ in both stages.\n\nFor Gradient Play and Extragradient, you must choose a stepsize based on the Lipschitz constant of $F$. For quadratic games, $F$ is linear, and the Lipschitz constant equals the spectral norm of $M$, denoted by $L$. A safe choice is a stepsize $\\gamma$ satisfying $0 < \\gamma \\leq 1/L$. For Proximal Best Response, select a regularization parameter $\\rho > 0$; a practical, theoretically motivated choice is $\\rho = L$.\n\nImplementation details to follow:\n\n- Initialization: Use the zero vector $z_0 = \\begin{bmatrix} 0 \\\\ 0 \\end{bmatrix}$ for all methods.\n\n- Termination criterion: For each method, iterate until the Euclidean norm error $\\lVert z_k - z^\\star \\rVert_2$ is less than a tolerance $\\varepsilon = 10^{-8}$, or until a maximum of $N_{\\max} = 5000$ iterations is reached. If the method fails to reach the tolerance within $N_{\\max}$ iterations, report $-1$ for that method.\n\n- Output: For each test case, report a list of $4$ integers corresponding to the number of iterations taken by BR, GP, PBR, and EG, in that order. Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, where each element is itself a list for one test case. For example, a valid output format is\n$$\n[\\,[i_{1,\\mathrm{BR}}, i_{1,\\mathrm{GP}}, i_{1,\\mathrm{PBR}}, i_{1,\\mathrm{EG}}],\\,[i_{2,\\mathrm{BR}}, i_{2,\\mathrm{GP}}, i_{2,\\mathrm{PBR}}, i_{2,\\mathrm{EG}}],\\,\\dots\\,]\n$$\nwith each $i_{\\cdot,\\cdot}$ an integer.\n\nTest suite specification:\n\nProvide the following five convex quadratic games, all with $D = C^\\top$ to ensure a symmetric $M$.\n\n- Case $1$ (scalar variables, moderate coupling):\n$$\nn=m=1,\\quad\nQ_1 = [\\,2\\,],\\quad\nQ_2 = [\\,3\\,],\\quad\nC = [\\,0.5\\,],\\quad\nb_1 = [\\,1\\,],\\quad\nb_2 = [\\,-2\\,].\n$$\n\n- Case $2$ (scalar variables, decoupled boundary case):\n$$\nn=m=1,\\quad\nQ_1 = [\\,1.5\\,],\\quad\nQ_2 = [\\,2.5\\,],\\quad\nC = [\\,0.0\\,],\\quad\nb_1 = [\\,-1.0\\,],\\quad\nb_2 = [\\,3.0\\,].\n$$\n\n- Case $3$ (two-dimensional variables, moderate coupling):\n$$\nn=m=2,\\quad\nQ_1 = \\begin{bmatrix} 2 & 0 \\\\ 0 & 4 \\end{bmatrix},\\quad\nQ_2 = \\begin{bmatrix} 3 & 0 \\\\ 0 & 1.5 \\end{bmatrix},\\quad\nC = \\begin{bmatrix} 0.3 & -0.1 \\\\ 0.2 & 0.0 \\end{bmatrix},\\quad\nb_1 = \\begin{bmatrix} 1 \\\\ -1 \\end{bmatrix},\\quad\nb_2 = \\begin{bmatrix} 0.5 \\\\ -0.5 \\end{bmatrix}.\n$$\n\n- Case $4$ (two-dimensional variables, ill-conditioned but stable):\n$$\nn=m=2,\\quad\nQ_1 = \\begin{bmatrix} 0.01 & 0 \\\\ 0 & 100 \\end{bmatrix},\\quad\nQ_2 = \\begin{bmatrix} 0.001 & 0 \\\\ 0 & 50 \\end{bmatrix},\\quad\nC = \\begin{bmatrix} 0.05 & 0.0 \\\\ 0.0 & 0.05 \\end{bmatrix},\\quad\nb_1 = \\begin{bmatrix} 1 \\\\ 1 \\end{bmatrix},\\quad\nb_2 = \\begin{bmatrix} -1 \\\\ 2 \\end{bmatrix}.\n$$\n\n- Case $5$ (three-dimensional variables, stronger but still stable coupling):\n$$\nn=m=3,\\quad\nQ_1 = \\mathrm{diag}(1,2,3),\\quad\nQ_2 = \\mathrm{diag}(1.5,2.5,3.5),\\quad\nC = 0.3\\,I_3,\\quad\nb_1 = \\begin{bmatrix} 1 \\\\ -2 \\\\ 0.5 \\end{bmatrix},\\quad\nb_2 = \\begin{bmatrix} -1 \\\\ 1 \\\\ 2 \\end{bmatrix},\n$$\nwhere $I_3$ is the $3 \\times 3$ identity matrix.\n\nImplementation constraints:\n\n- Compute $z^\\star$ exactly by solving the linear system $M z^\\star + q = 0$.\n\n- For Gradient Play and Extragradient, compute $L$ as the spectral norm of $M$ and use $\\gamma = 1/L$.\n\n- For Proximal Best Response, use $\\rho = L$.\n\n- Ensure all iterations begin at $z_0 = 0$ and use the Euclidean norm error tolerance $\\varepsilon = 10^{-8}$.\n\nYour final program must print the results for all five cases as a single line in the specified format, with each inner list giving the iteration counts $[i_{\\mathrm{BR}}, i_{\\mathrm{GP}}, i_{\\mathrm{PBR}}, i_{\\mathrm{EG}}]$ for the corresponding case.", "solution": "We start from the fundamental definitions of Nash equilibrium and first-order optimality in differentiable, strictly convex quadratic games. Player $1$’s gradient with respect to $x$ is\n$$\n\\nabla_x f_1(x,y) = Q_1 x + C y + b_1,\n$$\nand Player $2$’s gradient with respect to $y$ is\n$$\n\\nabla_y f_2(x,y) = Q_2 y + D x + b_2.\n$$\nStacking variables $z = \\begin{bmatrix} x \\\\ y \\end{bmatrix}$ and gradients yields the operator $F(z) = M z + q$ with\n$$\nM = \\begin{bmatrix} Q_1 & C \\\\ D & Q_2 \\end{bmatrix}, \\quad q = \\begin{bmatrix} b_1 \\\\ b_2 \\end{bmatrix}.\n$$\nWhen $M$ is symmetric positive definite, which holds for the test suite by taking $D=C^\\top$ and $Q_1$, $Q_2$ symmetric positive definite and couplings sufficiently small, then $F$ is strongly monotone and Lipschitz continuous. The unique Nash equilibrium solves $F(z^\\star) = 0$. Because $F$ is linear, we obtain\n$$\nM z^\\star + q = 0 \\quad \\Rightarrow \\quad z^\\star = - M^{-1} q,\n$$\nwhich can be computed using a linear solver.\n\nWe now derive each iterative method from the core principles.\n\n- Best Response (BR). Holding the opponent’s strategy fixed reduces each player’s problem to a strictly convex quadratic in their own variable. The minimizer of a quadratic $x \\mapsto \\tfrac{1}{2} x^\\top Q_1 x + (C y_k + b_1)^\\top x$ is characterized by the first-order condition $Q_1 x_{k+1} + C y_k + b_1 = 0$, i.e.,\n$$\nx_{k+1} = -Q_1^{-1}(C y_k + b_1).\n$$\nThen, given $x_{k+1}$, Player $2$’s best response satisfies $Q_2 y_{k+1} + D x_{k+1} + b_2 = 0$, i.e.,\n$$\ny_{k+1} = -Q_2^{-1}(D x_{k+1} + b_2).\n$$\nThese two updates implement a block Gauss–Seidel method to solve $M z + q = 0$.\n\n- Gradient Play (GP). A simultaneous gradient step for both players using the operator $F$ reads\n$$\nz_{k+1} = z_k - \\gamma F(z_k) = z_k - \\gamma (M z_k + q).\n$$\nFor a linear Lipschitz operator with constant $L = \\lVert M \\rVert_2$ (the spectral norm), a sufficient condition for stability is $0 < \\gamma \\le 1/L$. We choose $\\gamma = 1/L$ to have a safe stepsize.\n\n- Proximal Best Response (PBR). The proximal modification adds a quadratic regularization penalizing the change from the current iterate. For Player $1$, the subproblem is\n$$\n\\min_x \\left\\{ \\tfrac{1}{2} x^\\top Q_1 x + (C y_k + b_1)^\\top x + \\tfrac{\\rho}{2} \\lVert x - x_k \\rVert_2^2 \\right\\}.\n$$\nIts first-order condition is\n$$\nQ_1 x_{k+1} + C y_k + b_1 + \\rho (x_{k+1} - x_k) = 0 \\quad \\Rightarrow \\quad (Q_1 + \\rho I) x_{k+1} = \\rho x_k - C y_k - b_1,\n$$\ngiving\n$$\nx_{k+1} = (Q_1 + \\rho I)^{-1}(\\rho x_k - C y_k - b_1).\n$$\nSimilarly, Player $2$’s update is\n$$\ny_{k+1} = (Q_2 + \\rho I)^{-1}(\\rho y_k - D x_{k+1} - b_2).\n$$\nChoosing $\\rho = L$ yields a strong contraction that stabilizes and often accelerates convergence compared to unregularized BR.\n\n- Extragradient (EG). Korpelevich’s extragradient method for monotone variational inequalities computes a look-ahead point and evaluates the operator there before the main update. For our unconstrained linear $F$,\n$$\nz_{k+\\tfrac{1}{2}} = z_k - \\gamma F(z_k), \\quad\nz_{k+1} = z_k - \\gamma F(z_{k+\\tfrac{1}{2}}),\n$$\nwith the same safe stepsize choice $\\gamma = 1/L$. This corrects for curvature and yields improved robustness and, in many settings, faster convergence than plain Gradient Play.\n\nAll methods start from $z_0 = 0$. We terminate when the Euclidean norm error satisfies\n$$\n\\lVert z_k - z^\\star \\rVert_2 \\le \\varepsilon, \\quad \\varepsilon = 10^{-8},\n$$\nor when the iteration count exceeds $N_{\\max} = 5000$, in which case we report the failure code $-1$.\n\nFor each test case defined by $(Q_1, Q_2, C, D, b_1, b_2)$, we:\n\n1. Form $M$ and $q$.\n2. Compute the equilibrium $z^\\star = -M^{-1} q$.\n3. Compute $L = \\lVert M \\rVert_2$, the spectral norm, via singular values, and set $\\gamma = 1/L$ and $\\rho = L$.\n4. Run BR, GP, PBR, and EG from $z_0 = 0$, counting iterations until the tolerance is reached or failure occurs.\n5. Record the four integers $[i_{\\mathrm{BR}}, i_{\\mathrm{GP}}, i_{\\mathrm{PBR}}, i_{\\mathrm{EG}}]$.\n\nDesign coverage in the test suite:\n\n- Case $2$ sets $C = 0$, creating decoupled problems. BR and PBR attain the exact solution in one pass because each player’s subproblem is independent; GP and EG still converge linearly but usually require multiple iterations. This is a boundary case testing correctness and exactness.\n\n- Case $4$ uses ill-conditioned $Q_1$ and $Q_2$ with small but nonzero coupling. GP slows markedly due to conditioning; EG and PBR improve stability. This tests sensitivity to conditioning and the benefit of regularization and look-ahead.\n\n- Cases $1$, $3$, and $5$ provide “happy path” and stronger coupling scenarios in $1$-, $2$-, and $3$-dimensional settings, respectively, testing scalability and robustness across dimensions.\n\nThe final program implements exactly these steps and prints a single line with the requested nested list of iteration counts for the five cases. This quantitatively benchmarks the convergence behavior (“rates”) through iteration counts to a fixed tolerance, using the same initialization and theoretically safe parameter choices derived from the operator’s Lipschitz constant.", "answer": "```python\n# Python 3.12; numpy 1.23.5; scipy not used.\nimport numpy as np\n\ndef spectral_norm(M: np.ndarray) -> float:\n    # Spectral norm (largest singular value)\n    return np.linalg.svd(M, compute_uv=False)[0]\n\ndef equilibrium(M: np.ndarray, q: np.ndarray) -> np.ndarray:\n    # Solve M z* + q = 0 => z* = - M^{-1} q\n    return -np.linalg.solve(M, q)\n\ndef best_response(Q1, Q2, C, D, b1, b2, z_star, tol=1e-8, max_iters=5000):\n    n = Q1.shape[0]\n    m = Q2.shape[0]\n    x = np.zeros(n)\n    y = np.zeros(m)\n    for k in range(1, max_iters + 1):\n        # Player 1 best response\n        rhs1 = -C @ y - b1\n        x = np.linalg.solve(Q1, rhs1)\n        # Player 2 best response\n        rhs2 = -D @ x - b2\n        y = np.linalg.solve(Q2, rhs2)\n        z = np.concatenate([x, y])\n        err = np.linalg.norm(z - z_star)\n        if err <= tol:\n            return k\n    return -1\n\ndef proximal_best_response(Q1, Q2, C, D, b1, b2, z_star, rho, tol=1e-8, max_iters=5000):\n    n = Q1.shape[0]\n    m = Q2.shape[0]\n    x = np.zeros(n)\n    y = np.zeros(m)\n    Q1p = Q1 + rho * np.eye(n)\n    Q2p = Q2 + rho * np.eye(m)\n    for k in range(1, max_iters + 1):\n        rhs1 = rho * x - C @ y - b1\n        x = np.linalg.solve(Q1p, rhs1)\n        rhs2 = rho * y - D @ x - b2\n        y = np.linalg.solve(Q2p, rhs2)\n        z = np.concatenate([x, y])\n        err = np.linalg.norm(z - z_star)\n        if err <= tol:\n            return k\n    return -1\n\ndef gradient_play(M, q, z_star, gamma, tol=1e-8, max_iters=5000):\n    z = np.zeros_like(z_star)\n    for k in range(1, max_iters + 1):\n        Fz = M @ z + q\n        z = z - gamma * Fz\n        err = np.linalg.norm(z - z_star)\n        if err <= tol:\n            return k\n    return -1\n\ndef extragradient(M, q, z_star, gamma, tol=1e-8, max_iters=5000):\n    z = np.zeros_like(z_star)\n    for k in range(1, max_iters + 1):\n        Fz = M @ z + q\n        z_half = z - gamma * Fz\n        Fz_half = M @ z_half + q\n        z = z - gamma * Fz_half\n        err = np.linalg.norm(z - z_star)\n        if err <= tol:\n            return k\n    return -1\n\ndef build_block_matrix(Q1, Q2, C, D):\n    return np.block([[Q1, C],\n                     [D, Q2]])\n\ndef solve_case(Q1, Q2, C, D, b1, b2):\n    M = build_block_matrix(Q1, Q2, C, D)\n    q = np.concatenate([b1, b2])\n    z_star = equilibrium(M, q)\n    L = spectral_norm(M)\n    gamma = 1.0 / L\n    rho = L\n    it_br = best_response(Q1, Q2, C, D, b1, b2, z_star, tol=1e-8, max_iters=5000)\n    it_gp = gradient_play(M, q, z_star, gamma=gamma, tol=1e-8, max_iters=5000)\n    it_pbr = proximal_best_response(Q1, Q2, C, D, b1, b2, z_star, rho=rho, tol=1e-8, max_iters=5000)\n    it_eg = extragradient(M, q, z_star, gamma=gamma, tol=1e-8, max_iters=5000)\n    return [it_br, it_gp, it_pbr, it_eg]\n\ndef solve():\n    test_cases = []\n\n    # Case 1: scalar, moderate coupling\n    Q1 = np.array([[2.0]])\n    Q2 = np.array([[3.0]])\n    C = np.array([[0.5]])\n    D = C.T\n    b1 = np.array([1.0])\n    b2 = np.array([-2.0])\n    test_cases.append((Q1, Q2, C, D, b1, b2))\n\n    # Case 2: scalar, decoupled\n    Q1 = np.array([[1.5]])\n    Q2 = np.array([[2.5]])\n    C = np.array([[0.0]])\n    D = C.T\n    b1 = np.array([-1.0])\n    b2 = np.array([3.0])\n    test_cases.append((Q1, Q2, C, D, b1, b2))\n\n    # Case 3: 2D, moderate coupling\n    Q1 = np.array([[2.0, 0.0],\n                   [0.0, 4.0]])\n    Q2 = np.array([[3.0, 0.0],\n                   [0.0, 1.5]])\n    C = np.array([[0.3, -0.1],\n                  [0.2,  0.0]])\n    D = C.T\n    b1 = np.array([1.0, -1.0])\n    b2 = np.array([0.5, -0.5])\n    test_cases.append((Q1, Q2, C, D, b1, b2))\n\n    # Case 4: 2D, ill-conditioned\n    Q1 = np.array([[0.01, 0.0],\n                   [0.0, 100.0]])\n    Q2 = np.array([[0.001, 0.0],\n                   [0.0, 50.0]])\n    C = np.array([[0.05, 0.0],\n                  [0.0, 0.05]])\n    D = C.T\n    b1 = np.array([1.0, 1.0])\n    b2 = np.array([-1.0, 2.0])\n    test_cases.append((Q1, Q2, C, D, b1, b2))\n\n    # Case 5: 3D, stronger but stable coupling\n    Q1 = np.diag([1.0, 2.0, 3.0])\n    Q2 = np.diag([1.5, 2.5, 3.5])\n    C = 0.3 * np.eye(3)\n    D = C.T\n    b1 = np.array([1.0, -2.0, 0.5])\n    b2 = np.array([-1.0, 1.0, 2.0])\n    test_cases.append((Q1, Q2, C, D, b1, b2))\n\n    results = []\n    for Q1, Q2, C, D, b1, b2 in test_cases:\n        res = solve_case(Q1, Q2, C, D, b1, b2)\n        results.append(res)\n\n    print(str(results).replace(' ', ''))\n\nif __name__ == \"__main__\":\n    solve()\n```", "id": "3154618"}, {"introduction": "Our final practice moves into the realm of constrained games, which more accurately model real-world scenarios like resource allocation. You will analyze a water allocation game where players' choices are limited by a total available supply, a typical feature of economic and engineering systems. This exercise introduces the powerful concept of a potential game and requires you to implement the projected gradient method to find the Nash equilibrium, directly handling the constraints and revealing the difference between selfish behavior and the socially optimal outcome [@problem_id:3154624].", "problem": "Consider a noncooperative water allocation game with $n$ players indexed by $i \\in \\{1,\\dots,n\\}$. Each player $i$ chooses a nonnegative allocation $a_i \\in \\mathbb{R}_{\\ge 0}$ of a shared resource. The feasible set is the convex set $X = \\{a \\in \\mathbb{R}^n \\mid a_i \\ge 0 \\text{ for all } i, \\ \\sum_{i=1}^n a_i \\le W\\}$, where $W \\in \\mathbb{R}_{>0}$ is the total available water. Player $i$’s benefit from allocation $a_i$ is modeled by the concave quadratic utility $u_i(a_i) = b_i a_i - \\frac{c_i}{2} a_i^2$, with parameters $b_i \\in \\mathbb{R}_{>0}$ and $c_i \\in \\mathbb{R}_{>0}$. The group faces a convex scarcity penalty that depends on the aggregate allocation $z = \\sum_{i=1}^n a_i$, defined by $s(z) = \\alpha \\left(\\frac{z}{W}\\right)^2$, where $\\alpha \\in \\mathbb{R}_{>0}$. Each player’s payoff is\n$$\nf_i(a) = u_i(a_i) - s\\!\\left(\\sum_{j=1}^n a_j\\right) = b_i a_i - \\frac{c_i}{2} a_i^2 - \\alpha \\left(\\frac{\\sum_{j=1}^n a_j}{W}\\right)^2,\n$$\nwhich induces an exact potential game with potential\n$$\n\\Phi(a) = \\sum_{i=1}^n u_i(a_i) - s\\!\\left(\\sum_{i=1}^n a_i\\right).\n$$\nA Nash equilibrium is any $a^\\star \\in X$ such that no unilateral deviation by any player increases their payoff.\n\nTask:\n1. Compute a Nash equilibrium $a^{\\mathrm{NE}}$ of this game by maximizing the potential $\\Phi(a)$ over the convex set $X$ using a projected gradient method. The projection is with respect to the Euclidean norm onto $X$. The projected gradient method should update $a$ via ascent along $\\nabla \\Phi(a)$ followed by projection onto $X$. Use a backtracking step-size selection to ensure monotonic ascent of $\\Phi(a)$, and terminate when the change in iterates is below a small tolerance or a fixed maximum number of iterations is reached.\n2. Compute the efficient allocation $a^{\\mathrm{eff}}$ that maximizes the total utility $\\sum_{i=1}^n u_i(a_i)$ over $X$ (i.e., without the scarcity penalty), using a method justified from first principles (e.g., solving the Karush-Kuhn-Tucker (KKT) conditions via bisection on the Lagrange multiplier for the aggregate constraint).\n3. For each test case, report the Euclidean distance between the Nash equilibrium and the efficient allocation, i.e., compute $d = \\|a^{\\mathrm{NE}} - a^{\\mathrm{eff}}\\|_2$.\n\nFundamental base for reasoning and derivation:\n- Definition of Nash equilibrium in terms of best responses.\n- Properties of concave optimization over convex sets.\n- Exact potential games where Nash equilibria coincide with maximizers of the potential over the feasible set.\n- Karush-Kuhn-Tucker (KKT) conditions for convex optimization.\n\nUse the following test suite with parameter sets $(n, W, \\alpha, b, c)$:\n- Case $1$: $n = 3$, $W = 5$, $\\alpha = 1$, $b = [4, 3, 2]$, $c = [1, 1.5, 2]$.\n- Case $2$: $n = 3$, $W = 100$, $\\alpha = 0.5$, $b = [2, 2, 2]$, $c = [1, 1, 1]$.\n- Case $3$: $n = 4$, $W = 7$, $\\alpha = 1$, $b = [3, 3, 3, 3]$, $c = [1, 1, 1, 1]$.\n- Case $4$: $n = 3$, $W = 2$, $\\alpha = 2$, $b = [1, 2, 6]$, $c = [2, 1, 1.5]$.\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (e.g., $[r_1,r_2,r_3,r_4]$), where $r_k$ is the Euclidean distance $d$ for the $k$-th test case. No physical units are used; all quantities are dimensionless real numbers. The outputs must be floating-point numbers.", "solution": "The user-provided problem is a well-posed optimization and game theory problem that is scientifically grounded and formally stated. It requires the computation of two different resource allocation vectors, a Nash Equilibrium and a socially efficient allocation, and the distance between them. The problem is valid and can be solved using the principles of convex optimization and game theory.\n\nThe solution is divided into two main parts as per the problem description:\n1.  Computation of the efficient allocation, $a^{\\mathrm{eff}}$.\n2.  Computation of the Nash equilibrium, $a^{\\mathrm{NE}}$.\nFinally, the Euclidean distance between these two vectors is calculated for each test case.\n\n### Part 1: Computation of the Efficient Allocation ($a^{\\mathrm{eff}}$)\n\nThe efficient allocation $a^{\\mathrm{eff}}$ is defined as the allocation vector $a$ that maximizes the sum of individual utilities, $\\sum_{i=1}^n u_i(a_i)$, subject to the constraints that define the feasible set $X = \\{a \\in \\mathbb{R}^n \\mid a_i \\ge 0 \\text{ for all } i, \\ \\sum_{i=1}^n a_i \\le W\\}$.\n\nThe optimization problem is:\n$$\n\\max_{a} \\quad U(a) = \\sum_{i=1}^n \\left( b_i a_i - \\frac{c_i}{2} a_i^2 \\right) \\\\\n\\text{subject to} \\quad \\sum_{i=1}^n a_i \\le W, \\quad a_i \\ge 0 \\quad \\forall i \\in \\{1, \\dots, n\\}.\n$$\nThe objective function $U(a)$ is a sum of strictly concave functions, hence it is strictly concave. The feasible set $X$ is a compact convex set. Therefore, there exists a unique solution $a^{\\mathrm{eff}}$ to this convex optimization problem. We can find this solution using the Karush-Kuhn-Tucker (KKT) conditions.\n\nThe Lagrangian is:\n$$\n\\mathcal{L}(a, \\lambda, \\mu) = \\sum_{i=1}^n \\left(b_i a_i - \\frac{c_i}{2} a_i^2\\right) - \\lambda \\left(\\sum_{i=1}^n a_i - W\\right) - \\sum_{i=1}^n \\mu_i (-a_i)\n$$\nwhere $\\lambda \\ge 0$ is the Lagrange multiplier for the aggregate resource constraint and $\\mu_i \\ge 0$ are the multipliers for the non-negativity constraints $a_i \\ge 0$.\n\nThe KKT conditions are:\n1.  **Stationarity**: $\\frac{\\partial \\mathcal{L}}{\\partial a_i} = b_i - c_i a_i - \\lambda + \\mu_i = 0$ for $i=1, \\dots, n$.\n2.  **Primal Feasibility**: $\\sum_{i=1}^n a_i \\le W$ and $a_i \\ge 0$.\n3.  **Dual Feasibility**: $\\lambda \\ge 0$ and $\\mu_i \\ge 0$.\n4.  **Complementary Slackness**: $\\lambda(\\sum_{i=1}^n a_i - W) = 0$ and $\\mu_i a_i = 0$.\n\nFrom the stationarity condition, we have $c_i a_i = b_i - \\lambda + \\mu_i$. From the complementary slackness condition $\\mu_i a_i = 0$, we have two cases for each player $i$:\n- If $a_i > 0$, then $\\mu_i = 0$. The stationarity condition gives $a_i = (b_i - \\lambda) / c_i$. For $a_i > 0$, we must have $b_i > \\lambda$.\n- If $a_i = 0$, then $\\mu_i \\ge 0$. The stationarity condition gives $\\mu_i = \\lambda - b_i$, which requires $\\lambda \\ge b_i$.\n\nCombining these cases, the allocation for player $i$ can be expressed as a function of the single multiplier $\\lambda$:\n$$\na_i(\\lambda) = \\max\\left(0, \\frac{b_i - \\lambda}{c_i}\\right)\n$$\nThe value of $\\lambda$ is determined by the aggregate resource constraint and its corresponding slackness condition $\\lambda(\\sum a_i - W) = 0$:\n- **Case 1**: The unconstrained maximizer has $\\sum_{i=1}^n (b_i/c_i) \\le W$. In this case, we can set $\\lambda=0$. The constraint $\\sum a_i \\le W$ is not active. The solution is $a_i^{\\mathrm{eff}} = b_i/c_i$, which are all positive since $b_i, c_i > 0$.\n- **Case 2**: The unconstrained maximizer violates the resource limit, i.e., $\\sum_{i=1}^n (b_i/c_i) > W$. The constraint must be active, so $\\sum a_i = W$ and $\\lambda > 0$. We must find a value of $\\lambda > 0$ that satisfies the equation $\\sum_{i=1}^n \\max\\left(0, \\frac{b_i - \\lambda}{c_i}\\right) = W$. The function $g(\\lambda) = \\sum_{i=1}^n \\max\\left(0, \\frac{b_i - \\lambda}{c_i}\\right)$ is continuous and monotonically decreasing in $\\lambda$. We can efficiently find the root $\\lambda$ that solves $g(\\lambda) = W$ using a bisection search on the interval $[0, \\max_i(b_i)]$.\n\n### Part 2: Computation of the Nash Equilibrium ($a^{\\mathrm{NE}}$)\n\nThe problem states that the game is an exact potential game with potential function $\\Phi(a)$. For such games, the set of Nash equilibria coincides with the set of local maximizers of the potential function over the feasible strategy space. Since $\\Phi(a)$ is strictly concave (as we will see) and the feasible set $X$ is convex, there is a unique global maximizer of $\\Phi(a)$ which is the unique Nash equilibrium of the game.\n\nThe potential function is:\n$$\n\\Phi(a) = \\sum_{i=1}^n u_i(a_i) - s\\left(\\sum_{i=1}^n a_i\\right) = \\sum_{i=1}^n \\left( b_i a_i - \\frac{c_i}{2} a_i^2 \\right) - \\frac{\\alpha}{W^2} \\left(\\sum_{j=1}^n a_j\\right)^2\n$$\nThe Hessian of $\\Phi(a)$ is a matrix whose entries are $H_{ij} = \\frac{\\partial^2 \\Phi}{\\partial a_i \\partial a_j}$.\n$$\nH_{ii} = -c_i - \\frac{2\\alpha}{W^2} \\qquad \\text{and} \\qquad H_{ij} = -\\frac{2\\alpha}{W^2} \\quad \\text{for } i \\ne j\n$$\nThe Hessian matrix is $H = -\\left(\\text{diag}(c) + \\frac{2\\alpha}{W^2} \\mathbf{1}\\mathbf{1}^T\\right)$, where $\\text{diag}(c)$ is a diagonal matrix with entries $c_i > 0$ and $\\mathbf{1}\\mathbf{1}^T$ is a matrix of all ones. This matrix is negative definite, confirming that $\\Phi(a)$ is strictly concave.\n\nWe find $a^{\\mathrm{NE}}$ by solving the optimization problem:\n$$\n\\max_{a \\in X} \\Phi(a)\n$$\nWe use the projected gradient ascent method as specified. The iterative update rule is:\n$$\na^{(k+1)} = P_X\\left(a^{(k)} + t_k \\nabla \\Phi(a^{(k)})\\right)\n$$\nwhere $P_X$ is the Euclidean projection onto the set $X$, and $t_k$ is the step size.\n\nThe gradient of the potential function $\\nabla \\Phi(a)$ has components:\n$$\n[\\nabla \\Phi(a)]_i = \\frac{\\partial \\Phi}{\\partial a_i} = b_i - c_i a_i - \\frac{2\\alpha}{W^2} \\sum_{j=1}^n a_j\n$$\nThe projection $P_X(y)$ for a point $y \\in \\mathbb{R}^n$ onto the set $X = \\{a \\in \\mathbb{R}^n \\mid a_i \\ge 0, \\sum a_i \\le W\\}$ is a standard problem. If $y_i \\ge 0$ for all $i$ and $\\sum y_i \\le W$, then $P_X(y)=y$. Otherwise, the projection lies on the boundary of $X$. A common algorithm first projects $y$ onto the non-negative orthant, $y' = \\max(0, y)$. If $\\sum y'_i \\le W$, then $P_X(y) = y'$. If $\\sum y'_i > W$, then the projection must lie on the simplex $\\{a \\mid a_i \\ge 0, \\sum a_i = W\\}$. This projection can be computed efficiently, for example by sorting the components of $y$.\n\nThe step size $t_k$ is chosen using a backtracking line search to ensure monotonic ascent, i.e., $\\Phi(a^{(k+1)}) > \\Phi(a^{(k)})$. We start with an initial step size $t$ and reduce it by a factor $\\beta \\in (0,1)$ until the condition is met.\n\nThe algorithm terminates when the norm of the difference between successive iterates, $\\|a^{(k+1)}-a^{(k)}\\|_2$, falls below a specified tolerance, or a maximum number of iterations is reached.\n\n### Part 3: Distance Calculation\n\nAfter computing $a^{\\mathrm{eff}}$ and $a^{\\mathrm{NE}}$, the Euclidean distance between them is calculated as:\n$$\nd = \\|a^{\\mathrm{NE}} - a^{\\mathrm{eff}}\\|_2 = \\sqrt{\\sum_{i=1}^n (a_i^{\\mathrm{NE}} - a_i^{\\mathrm{eff}})^2}\n$$", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef compute_efficient_allocation(n, W, b, c):\n    \"\"\"\n    Computes the socially efficient allocation by maximizing sum of utilities.\n    Solves the KKT conditions, using bisection if the aggregate constraint is active.\n    \"\"\"\n    b = np.array(b)\n    c = np.array(c)\n    \n    # Unconstrained maximizers\n    a_unconstrained = b / c\n    \n    if np.sum(a_unconstrained) <= W:\n        return a_unconstrained\n    else:\n        # Constraint is active, find lambda using bisection\n        \n        # The sum of allocations as a function of lambda\n        def sum_a(lam):\n            return np.sum(np.maximum(0, (b - lam) / c))\n\n        # Search space for lambda\n        low_lam, high_lam = 0.0, np.max(b)\n        \n        # Bisection search for 100 iterations for high precision\n        for _ in range(100):\n            mid_lam = (low_lam + high_lam) / 2\n            if sum_a(mid_lam) > W:\n                low_lam = mid_lam\n            else:\n                high_lam = mid_lam\n        \n        final_lambda = (low_lam + high_lam) / 2.0\n        a_eff = np.maximum(0, (b - final_lambda) / c)\n        return a_eff\n\ndef compute_nash_equilibrium(n, W, alpha, b, c):\n    \"\"\"\n    Computes the Nash equilibrium by maximizing the potential function\n    using a projected gradient ascent method.\n    \"\"\"\n    b = np.array(b)\n    c = np.array(c)\n\n    def potential(a):\n        z = np.sum(a)\n        utility_sum = np.sum(b * a - (c / 2) * a**2)\n        scarcity_penalty = alpha * (z / W)**2\n        return utility_sum - scarcity_penalty\n\n    def grad_potential(a):\n        z = np.sum(a)\n        return b - c * a - (2 * alpha / W**2) * z\n\n    def project_onto_X(y, W_proj):\n        \"\"\" Projects a vector y onto the set {x | x_i >= 0, sum(x_i) <= W_proj}. \"\"\"\n        y_plus = np.maximum(0, y)\n        if np.sum(y_plus) <= W_proj:\n            return y_plus\n        \n        # Projection onto the simplex {x | x_i >= 0, sum(x_i) = W_proj}\n        # Using the algorithm from Duchi et al. (2008)\n        u = np.sort(y)[::-1]\n        cssv = np.cumsum(u)\n        indices = np.arange(1, len(y) + 1)\n        \n        # valid_indices filters the indices `j` that satisfy the condition\n        # u_j - (1/j) * (cssv_j - W) > 0\n        valid_indices = u * indices > (cssv - W_proj)\n        \n        # In case all are False (e.g. y components are very negative)\n        if not np.any(valid_indices):\n             rho = len(y)\n        else:\n             rho = np.max(indices[valid_indices])\n\n        theta = (cssv[rho - 1] - W_proj) / rho\n        return np.maximum(0, y - theta)\n\n    # Projected gradient ascent parameters\n    max_iter = 2000\n    tolerance = 1e-10\n    step_size_init = 1.0\n    beta = 0.5  # Backtracking factor\n\n    a_k = np.zeros(n) # Initial allocation\n\n    for _ in range(max_iter):\n        phi_k = potential(a_k)\n        grad_k = grad_potential(a_k)\n        \n        t = step_size_init\n        \n        a_k_next = None\n        while t > 1e-12:\n            a_candidate = project_onto_X(a_k + t * grad_k, W)\n            if potential(a_candidate) >= phi_k:\n                a_k_next = a_candidate\n                break\n            t *= beta\n        \n        if a_k_next is None:\n            a_k_next = a_k\n        \n        if np.linalg.norm(a_k_next - a_k) < tolerance:\n            a_k = a_k_next\n            break\n            \n        a_k = a_k_next\n        \n    return a_k\n\ndef solve():\n    \"\"\"\n    Main solver function that processes all test cases.\n    \"\"\"\n    test_cases = [\n        # (n, W, alpha, b, c)\n        (3, 5.0, 1.0, [4.0, 3.0, 2.0], [1.0, 1.5, 2.0]),\n        (3, 100.0, 0.5, [2.0, 2.0, 2.0], [1.0, 1.0, 1.0]),\n        (4, 7.0, 1.0, [3.0, 3.0, 3.0, 3.0], [1.0, 1.0, 1.0, 1.0]),\n        (3, 2.0, 2.0, [1.0, 2.0, 6.0], [2.0, 1.0, 1.5]),\n    ]\n\n    results = []\n    for case in test_cases:\n        n, W, alpha, b, c = case\n        \n        # 1. Compute the efficient allocation\n        a_eff = compute_efficient_allocation(n, W, b, c)\n        \n        # 2. Compute the Nash equilibrium\n        a_ne = compute_nash_equilibrium(n, W, alpha, b, c)\n        \n        # 3. Compute the Euclidean distance\n        distance = np.linalg.norm(a_ne - a_eff)\n        results.append(distance)\n\n    # Format output as a comma-separated list of floats in brackets\n    print(f\"[{','.join(f'{r:.8f}' for r in results)}]\")\n\nsolve()\n```", "id": "3154624"}]}