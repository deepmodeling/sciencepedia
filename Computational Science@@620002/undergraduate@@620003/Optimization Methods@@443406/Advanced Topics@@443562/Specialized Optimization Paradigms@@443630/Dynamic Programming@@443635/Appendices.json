{"hands_on_practices": [{"introduction": "Many optimization problems involve allocating limited resources over time. A simple approach is to be \"greedy\" and make the choice that seems best at the current moment. This exercise demonstrates a classic scenario where such a myopic strategy fails to find the true optimal solution. By applying the principles of dynamic programming, you will use backward induction and a value function to correctly solve the resource allocation problem, gaining a clear understanding of why DP's global perspective is superior to a local one. [@problem_id:3124007]", "problem": "Consider a finite-horizon resource allocation problem over $T=2$ discrete periods and two projects, $A$ and $B$. In each period $t \\in \\{1,2\\}$, exactly $1$ indivisible unit of resource must be allocated to exactly one project. Let $x_A$ and $x_B$ denote the cumulative units allocated to projects $A$ and $B$ by the end of period $2$, so that $x_A + x_B = 2$ and $x_A, x_B \\in \\{0,1,2\\}$. The total reward at the end of period $2$ is the sum of project-specific rewards $f_A(x_A) + f_B(x_B)$, where the project reward functions $f_A$ and $f_B$ are defined on $\\{0,1,2\\}$ by\n- $f_A(0)=0$, $f_A(1)=8$, $f_A(2)=9$,\n- $f_B(0)=0$, $f_B(1)=7$, $f_B(2)=20$.\n\nA natural greedy policy that ignores future periods proceeds as follows: at each period $t$, allocate the current unit to the project with the largest current marginal increase in reward $\\Delta f_i(x_i) = f_i(x_i+1)-f_i(x_i)$, breaking ties arbitrarily.\n\nTasks:\n1. Using the principle of optimality from dynamic programming, define a value function over time $t$ and an appropriate state that captures cumulative allocations, and write the corresponding Bellman recursion that evaluates the total reward at the terminal time as $f_A(x_A)+f_B(x_B)$.\n2. Use this recursion to compute the optimal allocation and its total reward.\n3. Compute the total reward obtained by the greedy policy described above and show that it is strictly less than the optimal value, thereby providing a concrete counterexample where greedy by maximal marginal increase fails while Dynamic Programming (DP) over time $t$ yields the optimal allocation.\n\nProvide as your final answer only the optimal total reward as a single real number. No rounding is required and no units are involved.", "solution": "The problem as stated is a finite-horizon resource allocation problem. It is self-contained, mathematically consistent, and falls within the standard framework of optimization methods. It is therefore valid. We proceed with the solution, addressing the three tasks in order.\n\n### Task 1: Dynamic Programming Formulation\n\nLet the time periods be indexed by $t \\in \\{1, 2\\}$. At each period, one indivisible unit of a resource is allocated to one of two projects, $A$ or $B$. The total number of units to be allocated is $T=2$.\n\nWe define the state of the system at the beginning of period $t$ as $s_t = (n_A, n_B)$, where $n_A$ and $n_B$ are the cumulative number of units allocated to projects $A$ and $B$, respectively, during periods $1, \\dots, t-1$. This implies the state constraint $n_A + n_B = t-1$.\n\nThe decision, or action, at period $t$ is $u_t \\in \\{A, B\\}$, representing the choice to allocate the unit to project $A$ or project $B$.\n\nThe state transition is deterministic. If the state at period $t$ is $(n_A, n_B)$, the state at period $t+1$ becomes:\n- $(n_A+1, n_B)$ if the action is $u_t=A$.\n- $(n_A, n_B+1)$ if the action is $u_t=B$.\n\nThe objective is to maximize the total reward at the end of the horizon, which is given by $f_A(x_A) + f_B(x_B)$, where $(x_A, x_B)$ is the final allocation after $T=2$ periods, with $x_A+x_B=2$.\n\nLet $J_t(n_A, n_B)$ be the optimal (maximum) total reward from the end of the horizon, given that the system is in state $(n_A, n_B)$ at the beginning of period $t$. This is a value function defined over the state and time. The principle of optimality leads to the following Bellman recursion, derived by working backward in time:\n$$\nJ_t(n_A, n_B) = \\max \\begin{cases} J_{t+1}(n_A+1, n_B) & \\text{if } u_t=A \\\\ J_{t+1}(n_A, n_B+1) & \\text{if } u_t=B \\end{cases}\n$$\nThe recursion terminates at a conceptual period $t=3$, which occurs after all $2$ allocations are made. The value at this terminal stage is the total reward itself, based on the final allocation $(x_A, x_B)$:\n$$\nJ_3(x_A, x_B) = f_A(x_A) + f_B(x_B) \\quad \\text{where } x_A+x_B=2.\n$$\n\n### Task 2: Computation of Optimal Allocation and Reward\n\nWe apply the backward recursion developed in Task 1.\n\n**Terminal Stage ($t=3$):**\nWe compute the value for all possible final allocations $(x_A, x_B)$ such that $x_A, x_B \\in \\{0,1,2\\}$ and $x_A+x_B=2$.\n- For allocation $(2,0)$: $J_3(2,0) = f_A(2) + f_B(0) = 9 + 0 = 9$.\n- For allocation $(1,1)$: $J_3(1,1) = f_A(1) + f_B(1) = 8 + 7 = 15$.\n- For allocation $(0,2)$: $J_3(0,2) = f_A(0) + f_B(2) = 0 + 20 = 20$.\n\n**Period $t=2$:**\nAt the start of period $2$, one unit has been allocated ($t-1=1$). The possible states are $(1,0)$ and $(0,1)$.\n- For state $s_2 = (1,0)$: We are deciding the allocation of the second unit.\n  - Action $A$: Leads to final state $(2,0)$. Value is $J_3(2,0)=9$.\n  - Action $B$: Leads to final state $(1,1)$. Value is $J_3(1,1)=15$.\n  Therefore, $J_2(1,0) = \\max\\{9, 15\\} = 15$. The optimal action is $B$.\n- For state $s_2 = (0,1)$: We are deciding the allocation of the second unit.\n  - Action $A$: Leads to final state $(1,1)$. Value is $J_3(1,1)=15$.\n  - Action $B$: Leads to final state $(0,2)$. Value is $J_3(0,2)=20$.\n  Therefore, $J_2(0,1) = \\max\\{15, 20\\} = 20$. The optimal action is $B$.\n\n**Period $t=1$:**\nAt the start of period $1$, no units have been allocated, so the state is $s_1 = (0,0)$. We are deciding the allocation of the first unit.\n- Action $A$: Leads to state $(1,0)$ at $t=2$. The optimal value from this path is $J_2(1,0)=15$.\n- Action $B$: Leads to state $(0,1)$ at $t=2$. The optimal value from this path is $J_2(0,1)=20$.\nTherefore, the maximum achievable reward is $J_1(0,0) = \\max\\{15, 20\\} = 20$. The optimal first action is $B$.\n\nBy tracing the optimal decisions forward:\n1. At $t=1$, starting in state $(0,0)$, the optimal action is $B$. The system moves to state $(0,1)$.\n2. At $t=2$, in state $(0,1)$, the optimal action is $B$. The system moves to the final allocation $(0,2)$.\n\nThe optimal allocation is $(x_A, x_B) = (0,2)$, which yields an optimal total reward of $f_A(0) + f_B(2) = 0 + 20 = 20$.\n\n### Task 3: Analysis of the Greedy Policy\n\nThe greedy policy allocates the unit at each period to the project with the largest current marginal reward, defined as $\\Delta f_i(x_i) = f_i(x_i+1) - f_i(x_i)$, where $x_i$ is the number of units currently allocated to project $i$.\n\nFirst, we compute the marginal rewards:\n- For project $A$:\n  - $\\Delta f_A(0) = f_A(1) - f_A(0) = 8 - 0 = 8$.\n  - $\\Delta f_A(1) = f_A(2) - f_A(1) = 9 - 8 = 1$.\n- For project $B$:\n  - $\\Delta f_B(0) = f_B(1) - f_B(0) = 7 - 0 = 7$.\n  - $\\Delta f_B(1) = f_B(2) - f_B(1) = 20 - 7 = 13$.\n\nNow, we simulate the greedy policy:\n- **Period $t=1$**: The current allocation is $(0,0)$. We compare the marginal rewards for adding the first unit: $\\Delta f_A(0)=8$ and $\\Delta f_B(0)=7$. Since $8 > 7$, the greedy policy allocates the unit to project $A$. The allocation becomes $(1,0)$.\n- **Period $t=2$**: The current allocation is $(1,0)$. We compare the marginal rewards for adding the second unit: $\\Delta f_A(1)=1$ for project $A$ and $\\Delta f_B(0)=7$ for project $B$. Since $7 > 1$, the greedy policy allocates the unit to project $B$. The final allocation becomes $(1,1)$.\n\nThe final allocation from the greedy policy is $(x_A, x_B) = (1,1)$. The total reward for this allocation is:\n$$ f_A(1) + f_B(1) = 8 + 7 = 15. $$\nThe total reward obtained by the greedy policy is $15$, which is strictly less than the optimal reward of $20$ found using dynamic programming. This confirms that the myopic, greedy approach is suboptimal for this problem. The greedy choice at $t=1$ locks the system out of the state $(0,2)$, which has the highest reward, because it fails to account for the large future marginal gain from the second allocation to project $B$.", "answer": "$$\n\\boxed{20}\n$$", "id": "3124007"}, {"introduction": "Translating a real-world problem into a formal dynamic programming model is a crucial skill. This exercise, a classic stock trading problem, challenges you to do just that. To find the maximum profit, you must define a set of states that capture all the necessary information at each point in time. By identifying the correct states and the transitions between them, you can build a recurrence relation that solves the problem efficiently, providing excellent practice in the core mechanics of state-based DP. [@problem_id:3230619]", "problem": "You are given a finite sequence of daily prices for a single stock and a nonnegative fixed transaction fee that is charged once per completed buy-then-sell transaction at the moment of selling. You may complete any number of transactions subject to the constraint that you cannot hold more than one share at any time; that is, you must sell before you can buy again. Short selling is not allowed. Your task is to design and implement a program that, for each provided test case, computes the maximum possible total profit under these rules.\n\nUse only the following fundamental base to reason about and derive your algorithm: the principle of optimality and subproblem decomposition from Dynamic Programming (DP), and the standard definition of profit as accumulated sum of realized gains from completed transactions. The program must compute the exact optimal value, not an approximation, and must be efficient enough to handle long sequences in linear time with constant extra space.\n\nAssumptions and clarifications:\n- The fee is applied once per transaction upon selling, never upon buying.\n- Prices are integers and nonnegative.\n- If no profitable transaction exists, the maximum profit is zero.\n- The initial state before any day is that no stock is held and the accumulated profit is zero.\n\nTest suite to implement and evaluate in your program (process in the listed order):\n- Case $1$: prices $[1,3,2,8,4,9]$, fee $2$.\n- Case $2$: prices $[9,8,7,6,5]$, fee $1$.\n- Case $3$: prices $[1,5,3,8,4,9]$, fee $10$.\n- Case $4$: prices $[1,2,3,4,5]$, fee $0$.\n- Case $5$: prices $[5]$, fee $3$.\n- Case $6$: prices $[1,1,1,2,2,3,1,2]$, fee $1$.\n- Case $7$: prices $[]$ (empty sequence), fee $5$.\n- Case $8$: prices $[3,2,6,5,0,3]$, fee $1$.\n\nOutput requirement:\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (e.g., $[ \\text{result1}, \\text{result2}, \\text{result3}, \\dots ]$), where each result is the maximum profit for the corresponding test case, expressed as a nonnegative integer.", "solution": "The problem of maximizing profit from stock transactions with a fixed fee is a classic optimization problem that can be solved efficiently using the principles of Dynamic Programming (DP). The problem exhibits optimal substructure, meaning that an optimal solution for a sequence of prices can be constructed from optimal solutions for its prefixes. This allows us to decompose the problem into a series of smaller, overlapping subproblems.\n\nOur derivation will proceed by defining the states of our system, formulating the recurrence relations that govern transitions between states, establishing the initial conditions, and finally, showing how these elements combine to yield the solution with linear time and constant space complexity.\n\nLet the sequence of daily prices be denoted by $P = [p_0, p_1, \\dots, p_{n-1}]$ and the transaction fee be $f$. At the end of any given day $i$, our financial state is fully determined by our accumulated profit and whether we are holding a share of the stock. This leads to the definition of two state variables for each day $i$:\n\n1.  $cash_i$: The maximum profit achievable at the end of day $i$, given that we are **not** holding a stock (i.e., we have cash).\n2.  $hold_i$: The maximum profit achievable at the end of day $i$, given that we **are** holding one share of the stock. Note that this value can be negative, as it represents our net worth including the cost of the stock we hold.\n\nWe can now establish the state transition equations, or recurrence relations, that define $cash_i$ and $hold_i$ based on the states at day $i-1$.\n\nTo compute $cash_i$, we consider two possibilities at the end of day $i$:\n- We were already in a cash state at the end of day $i-1$ and chose to do nothing. In this case, our profit remains $cash_{i-1}$.\n- We were holding a stock at the end of day $i-1$ and sold it on day $i$. Selling the stock yields the price $p_i$ but incurs the fee $f$. Our new profit is the sum of our previous state's value, $hold_{i-1}$, and the net proceeds from the sale, $p_i - f$.\nThe optimal cash state at day $i$ is the maximum of these two outcomes:\n$$ cash_i = \\max(cash_{i-1}, hold_{i-1} + p_i - f) $$\n\nTo compute $hold_i$, we also consider two possibilities at the end of day $i$:\n- We were already holding a stock at the end of day $i-1$ and a chose to keep holding it. Our state value remains $hold_{i-1}$.\n- We were in a cash state at the end of day $i-1$ and chose to buy one share of stock on day $i$. This action costs $p_i$, which is subtracted from our available cash, $cash_{i-1}$.\nThe optimal hold state at day $i$ is the maximum of these two scenarios. This reflects the strategy of either holding a previously acquired stock or buying one at the current price, whichever results in a better (less negative or more positive) position:\n$$ hold_i = \\max(hold_{i-1}, cash_{i-1} - p_i) $$\n\nThe base cases for these recurrences correspond to the state before the first day (i.e., at $i=-1$).\n- Initially, we have zero profit and hold no stock. Therefore, $cash_{-1} = 0$.\n- It is impossible to start the process already holding a stock. To correctly model this in the recurrence, we initialize the hold state to a value that ensures it cannot be the maximum in the first step unless a stock is bought. A value of negative infinity, $hold_{-1} = -\\infty$, serves this purpose.\n\nThe algorithm proceeds by iterating from day $i=0$ to $i=n-1$, applying the state transition equations at each step. The final answer is the maximum profit after the last day. Since profit can only be realized when we are not holding any stock, the solution is the value of the cash state on the final day, $cash_{n-1}$. The recurrences ensure this value is non-negative, as $cash_i$ starts at $0$ and only increases if a profitable transaction occurs.\n\nThese recurrences suggest an implementation using two arrays of size $n$ to store the values of $cash_i$ and $hold_i$ for all $i$. However, notice that the computation for day $i$ depends only on the values from day $i-1$. This allows for a significant space optimization. Instead of storing the entire history, we only need to maintain two variables representing the latest values of the cash and hold states.\n\nLet these variables be $current\\_cash$ and $current\\_hold$. The iterative algorithm is as follows:\n1.  Initialize $current\\_cash = 0$ and $current\\_hold = -\\infty$.\n2.  For each price $p$ in the sequence of prices $P$:\n    a. Store the value of $current\\_cash$ from the previous step in a temporary variable, e.g., $previous\\_cash = current\\_cash$.\n    b. Update $current\\_cash = \\max(current\\_cash, current\\_hold + p - f)$.\n    c. Update $current\\_hold = \\max(current\\_hold, previous\\_cash - p)$.\n3.  After the loop completes, the final result is $current\\_cash$.\n\nThis optimized approach has a time complexity of $O(n)$, as it involves a single pass through the price sequence, and a space complexity of $O(1)$, as it uses only a few variables to store the current state. This meets the problem's efficiency requirements.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef compute_max_profit(prices, fee):\n    \"\"\"\n    Computes the maximum profit from stock transactions with a fee.\n\n    This function uses a dynamic programming approach with O(1) space complexity.\n    It maintains two state variables:\n    - cash: the maximum profit at the end of a day if not holding a stock.\n    - hold: the maximum profit at the end of a day if holding a stock.\n\n    Args:\n        prices (list[int]): A list of daily stock prices.\n        fee (int): The transaction fee applied on each sale.\n\n    Returns:\n        int: The maximum possible profit.\n    \"\"\"\n    # cash: max profit if we end the day with no stock\n    cash = 0\n    # hold: max profit if we end the day with one stock\n    # Initialized to a very small number, as it's impossible to hold a stock\n    # before the first day. This represents a state of negative infinity.\n    hold = -np.inf\n\n    # Iterate through each day's price\n    for price in prices:\n        # Cache the cash value from the previous step before it's updated.\n        # This is crucial because the new 'hold' state depends on the 'cash'\n        # state before any transaction on the current day.\n        prev_cash = cash\n\n        # Update the 'cash' state.\n        # We can either do nothing (maintaining 'cash') or sell the stock we're\n        # holding ('hold + price - fee'). We take the maximum.\n        cash = max(cash, hold + price - fee)\n\n        # Update the 'hold' state.\n        # We can either do nothing (maintaining 'hold') or buy a stock today,\n        # which transitions from the previous cash state ('prev_cash - price').\n        # We take the maximum.\n        hold = max(hold, prev_cash - price)\n\n    # The final profit must be an integer and is the profit in the 'cash' state\n    # after the last day, as we must sell all stock to realize profit.\n    return int(cash)\n\ndef solve():\n    \"\"\"\n    Defines and runs the test suite for the stock profit problem.\n    \"\"\"\n    # The test suite provided in the problem statement.\n    test_cases = [\n        # (prices, fee)\n        ([1, 3, 2, 8, 4, 9], 2),       # Case 1\n        ([9, 8, 7, 6, 5], 1),         # Case 2\n        ([1, 5, 3, 8, 4, 9], 10),      # Case 3\n        ([1, 2, 3, 4, 5], 0),         # Case 4\n        ([5], 3),                     # Case 5\n        ([1, 1, 1, 2, 2, 3, 1, 2], 1), # Case 6\n        ([], 5),                      # Case 7\n        ([3, 2, 6, 5, 0, 3], 1),      # Case 8\n    ]\n\n    results = []\n    for prices, fee in test_cases:\n        result = compute_max_profit(prices, fee)\n        results.append(result)\n\n    # Print the final results in the specified format.\n    print(f\"[{','.join(map(str, results))}]\")\n\n# Execute the solver.\nsolve()\n```", "id": "3230619"}, {"introduction": "Dynamic programming is not limited to problems with a simple linear or grid-like structure. This job sequencing exercise introduces a powerful technique used for combinatorial problems like the famous Traveling Salesperson Problem. To find the minimum cost sequence, you must think beyond simple indices and define a state that includes the subset of all jobs visited so far. This practice will expand your concept of a DP state and demonstrate how to solve complex routing and scheduling problems by systematically building optimal solutions over subsets. [@problem_id:3123982]", "problem": "A manufacturing cell must process a set of jobs with indices $[n] = \\{1,2,3,4,5\\}$. Switching from job $i$ to job $j$ incurs a setup-dependent cost $s_{ij}$, and switching from the initial machine state $0$ to job $j$ incurs $s_{0j}$. Each job must be processed exactly once in some sequence that starts from the initial state $0$. The total sequence cost is defined as the sum of setup costs along the sequence, that is, if the sequence is $0 \\to j_{1} \\to j_{2} \\to \\dots \\to j_{n}$, then the total cost is $s_{0,j_{1}} + \\sum_{k=1}^{n-1} s_{j_{k}, j_{k+1}}$. The goal is to minimize this total setup cost.\n\nThe instance is given by the following data. The initial setup costs are\n$$\n\\bigl(s_{0,1}, s_{0,2}, s_{0,3}, s_{0,4}, s_{0,5}\\bigr) = (8, 3, 9, 4, 7).\n$$\nThe job-to-job setup costs $s_{ij}$ for $i,j \\in \\{1,2,3,4,5\\}$ are specified by the matrix\n$$\n\\begin{bmatrix}\ns_{1,1} & s_{1,2} & s_{1,3} & s_{1,4} & s_{1,5} \\\\\ns_{2,1} & s_{2,2} & s_{2,3} & s_{2,4} & s_{2,5} \\\\\ns_{3,1} & s_{3,2} & s_{3,3} & s_{3,4} & s_{3,5} \\\\\ns_{4,1} & s_{4,2} & s_{4,3} & s_{4,4} & s_{4,5} \\\\\ns_{5,1} & s_{5,2} & s_{5,3} & s_{5,4} & s_{5,5}\n\\end{bmatrix}\n=\n\\begin{bmatrix}\n0 & 6 & 7 & 5 & 3 \\\\\n4 & 0 & 5 & 2 & 6 \\\\\n7 & 4 & 0 & 7 & 5 \\\\\n1 & 6 & 6 & 0 & 4 \\\\\n5 & 5 & 2 & 6 & 0\n\\end{bmatrix}.\n$$\n\nStarting from the foundational Bellman principle of optimality, derive a dynamic programming formulation that uses states of the form $(S,j)$, where $S \\subseteq [n]$ is the set of completed jobs and $j \\in S$ is the last completed job, to compute the minimal total setup cost. Then, apply your formulation to the given instance to compute the minimal achievable total setup cost over all sequences that visit each job exactly once starting from the initial state $0$.\n\nExpress your final answer as an exact integer with no rounding and no units.", "solution": "The problem is evaluated against the specified validation criteria.\n\n### Problem Validation\n**Step 1: Extract Givens**\n- Job set: $[n] = \\{1, 2, 3, 4, 5\\}$.\n- Initial machine state: $0$.\n- Setup cost from job $i$ to job $j$: $s_{ij}$.\n- Initial setup costs from state $0$ to job $j$: $s_{0j}$.\n- Data for initial setup costs: $(s_{0,1}, s_{0,2}, s_{0,3}, s_{0,4}, s_{0,5}) = (8, 3, 9, 4, 7)$.\n- Data for job-to-job setup costs $s_{ij}$ for $i,j \\in \\{1,2,3,4,5\\}$:\n$$\n\\begin{bmatrix}\n0 & 6 & 7 & 5 & 3 \\\\\n4 & 0 & 5 & 2 & 6 \\\\\n7 & 4 & 0 & 7 & 5 \\\\\n1 & 6 & 6 & 0 & 4 \\\\\n5 & 5 & 2 & 6 & 0\n\\end{bmatrix}\n$$\n- Constraint: Each job must be processed exactly once.\n- Sequence of operations: $0 \\to j_{1} \\to j_{2} \\to \\dots \\to j_{n}$.\n- Objective function: Minimize the total cost, defined as $s_{0,j_{1}} + \\sum_{k=1}^{n-1} s_{j_{k}, j_{k+1}}$.\n- Task: Derive a dynamic programming formulation with states $(S, j)$ and apply it to find the minimal total setup cost.\n\n**Step 2: Validate Using Extracted Givens**\n- **Scientific Grounding**: The problem is a classic instance of the Asymmetric Traveling Salesperson Path Problem (ATSPP), a well-established problem in combinatorial optimization and operations research. The requested solution method, dynamic programming, is a standard and powerful technique for this class of problems (specifically, the Held-Karp algorithm). The problem is mathematically and scientifically sound.\n- **Well-Posedness**: The problem is well-posed. It seeks to find the minimum of a cost function over a finite, non-empty set of permutations. A minimum is guaranteed to exist. The dynamic programming approach ensures a unique minimal cost is found.\n- **Objectivity**: The problem is stated with precise, objective language. All costs are given as explicit numerical data, and the objective function is unambiguously defined.\n- **Completeness and Consistency**: All necessary data (costs) and constraints are provided. There are no contradictions in the problem statement. The diagonal elements $s_{ii}=0$ are consistent with the problem's constraint that each job is visited exactly once, which precludes transitions from a job to itself.\n\n**Step 3: Verdict and Action**\nThe problem is valid as it is scientifically grounded, well-posed, objective, and complete. A solution will be derived and computed.\n\n### Dynamic Programming Formulation\n\nThis problem can be modeled as finding the shortest path in a state-space graph, making it amenable to dynamic programming. The formulation is based on the Bellman principle of optimality, which states that an optimal path consists of optimal subpaths.\n\nLet $S \\subseteq [n]$ be a subset of jobs that have been processed, and let $j \\in S$ be the last job processed in the sequence. We define the state as the pair $(S, j)$.\n\nLet $C(S, j)$ be the minimum cost of a path starting from the initial machine state $0$, visiting every job in the set $S$ exactly once, and ending at job $j$.\n\n**Base Cases:**\nFor a path that has visited only one job, the set of visited jobs is $S = \\{j\\}$. The path is simply $0 \\to j$. The cost is the initial setup cost $s_{0j}$.\nTherefore, for each $j \\in [n]$, the base cases are:\n$$\nC(\\{j\\}, j) = s_{0j}\n$$\n\n**Recurrence Relation:**\nFor any set $S$ with size $|S| > 1$ and any job $j \\in S$, an optimal path to $j$ that covers all jobs in $S$ must have come from some job $i \\in S \\setminus \\{j\\}$. The subpath to $i$ must have covered all jobs in $S \\setminus \\{j\\}$ and must have been optimal itself, according to the Bellman principle. The cost of such a subpath is $C(S \\setminus \\{j\\}, i)$. To get from $i$ to $j$, we incur an additional setup cost of $s_{ij}$. To find the minimum cost to reach $j$ as the last job in the set $S$, we must consider all possible penultimate jobs $i$ and choose the one that minimizes the total cost.\n\nThis gives the recurrence relation for $|S| \\geq 2$:\n$$\nC(S, j) = \\min_{i \\in S \\setminus \\{j\\}} \\{ C(S \\setminus \\{j\\}, i) + s_{ij} \\}\n$$\n\n**Final Solution:**\nThe problem requires processing all $n$ jobs. The final set of visited jobs is $S = [n] = \\{1, 2, 3, 4, 5\\}$. The sequence can end at any job $j \\in [n]$. The minimal total setup cost is the minimum of the costs of all possible complete sequences.\n$$\n\\text{Minimal Total Cost} = \\min_{j \\in [n]} \\{ C([n], j) \\}\n$$\n\n### Application to the Given Instance\nWe now apply this formulation to the provided data, with $n=5$.\n\n**Stage 1: $|S|=1$**\nThe costs are the initial setup costs $s_{0j}$.\n$C(\\{1\\}, 1) = s_{0,1} = 8$\n$C(\\{2\\}, 2) = s_{0,2} = 3$\n$C(\\{3\\}, 3) = s_{0,3} = 9$\n$C(\\{4\\}, 4) = s_{0,4} = 4$\n$C(\\{5\\}, 5) = s_{0,5} = 7$\n\n**Stage 2: $|S|=2$**\nWe compute $C(\\{i,j\\}, j) = C(\\{i\\}, i) + s_{ij}$.\n$C(\\{1,2\\}, 1) = C(\\{2\\},2)+s_{2,1} = 3+4 = 7$\n$C(\\{1,2\\}, 2) = C(\\{1\\},1)+s_{1,2} = 8+6 = 14$\n$C(\\{1,3\\}, 1) = C(\\{3\\},3)+s_{3,1} = 9+7 = 16$\n$C(\\{1,3\\}, 3) = C(\\{1\\},1)+s_{1,3} = 8+7 = 15$\n$C(\\{1,4\\}, 1) = C(\\{4\\},4)+s_{4,1} = 4+1 = 5$\n$C(\\{1,4\\}, 4) = C(\\{1\\},1)+s_{1,4} = 8+5 = 13$\n$C(\\{1,5\\}, 1) = C(\\{5\\},5)+s_{5,1} = 7+5 = 12$\n$C(\\{1,5\\}, 5) = C(\\{1\\},1)+s_{1,5} = 8+3 = 11$\n$C(\\{2,3\\}, 2) = C(\\{3\\},3)+s_{3,2} = 9+4 = 13$\n$C(\\{2,3\\}, 3) = C(\\{2\\},2)+s_{2,3} = 3+5 = 8$\n$C(\\{2,4\\}, 2) = C(\\{4\\},4)+s_{4,2} = 4+6 = 10$\n$C(\\{2,4\\}, 4) = C(\\{2\\},2)+s_{2,4} = 3+2 = 5$\n$C(\\{2,5\\}, 2) = C(\\{5\\},5)+s_{5,2} = 7+5 = 12$\n$C(\\{2,5\\}, 5) = C(\\{2\\},2)+s_{2,5} = 3+6 = 9$\n$C(\\{3,4\\}, 3) = C(\\{4\\},4)+s_{4,3} = 4+6 = 10$\n$C(\\{3,4\\}, 4) = C(\\{3\\},3)+s_{3,4} = 9+7 = 16$\n$C(\\{3,5\\}, 3) = C(\\{5\\},5)+s_{5,3} = 7+2 = 9$\n$C(\\{3,5\\}, 5) = C(\\{3\\},3)+s_{3,5} = 9+5 = 14$\n$C(\\{4,5\\}, 4) = C(\\{5\\},5)+s_{5,4} = 7+6 = 13$\n$C(\\{4,5\\}, 5) = C(\\{4\\},4)+s_{4,5} = 4+4 = 8$\n\n**Stage 3: $|S|=3$**\nUsing the recurrence $C(S,k) = \\min_{j \\in S \\setminus \\{k\\}} \\{ C(S \\setminus \\{k\\}, j) + s_{jk} \\}$.\n$C(\\{1,2,3\\},1) = \\min\\{C(\\{2,3\\},2)+s_{21}, C(\\{2,3\\},3)+s_{31}\\} = \\min\\{13+4, 8+7\\} = 15$\n$C(\\{1,2,3\\},2) = \\min\\{C(\\{1,3\\},1)+s_{12}, C(\\{1,3\\},3)+s_{32}\\} = \\min\\{16+6, 15+4\\} = 19$\n$C(\\{1,2,3\\},3) = \\min\\{C(\\{1,2\\},1)+s_{13}, C(\\{1,2\\},2)+s_{23}\\} = \\min\\{7+7, 14+5\\} = 14$\n$C(\\{1,2,4\\},1) = \\min\\{C(\\{2,4\\},2)+s_{21}, C(\\{2,4\\},4)+s_{41}\\} = \\min\\{10+4, 5+1\\} = 6$\n$C(\\{1,2,4\\},2) = \\min\\{C(\\{1,4\\},1)+s_{12}, C(\\{1,4\\},4)+s_{42}\\} = \\min\\{5+6, 13+6\\} = 11$\n$C(\\{1,2,4\\},4) = \\min\\{C(\\{1,2\\},1)+s_{14}, C(\\{1,2\\},2)+s_{24}\\} = \\min\\{7+5, 14+2\\} = 12$\n$C(\\{1,3,5\\},3) = \\min\\{C(\\{1,5\\},1)+s_{13}, C(\\{1,5\\},5)+s_{53}\\} = \\min\\{12+7, 11+2\\} = 13$\n$C(\\{2,3,4\\},3) = \\min\\{C(\\{2,4\\},2)+s_{23}, C(\\{2,4\\},4)+s_{43}\\} = \\min\\{10+5, 5+6\\} = 11$\n$C(\\{2,3,5\\},3) = \\min\\{C(\\{2,5\\},2)+s_{23}, C(\\{2,5\\},5)+s_{53}\\} = \\min\\{12+5, 9+2\\} = 11$\n$C(\\{2,4,5\\},5) = \\min\\{C(\\{2,4\\},2)+s_{25}, C(\\{2,4\\},4)+s_{45}\\} = \\min\\{10+6, 5+4\\} = 9$\n$C(\\{3,4,5\\},3) = \\min\\{C(\\{4,5\\},4)+s_{43}, C(\\{4,5\\},5)+s_{53}\\} = \\min\\{13+6, 8+2\\} = 10$\nThe other values for $|S|=3$ are computed similarly.\n\n**Stage 4: $|S|=4$**\nThe calculation proceeds. For example, for $S=\\{1,2,3,4\\}$:\n$C(\\{1,2,3,4\\},1) = \\min\\{C(\\{2,3,4\\},2)+s_{21}, C(\\{2,3,4\\},3)+s_{31}, C(\\{2,3,4\\},4)+s_{41}\\} = \\min\\{14+4, 11+7, 15+1\\} = 16$\n$C(\\{1,2,3,4\\},2) = \\min\\{C(\\{1,3,4\\},1)+s_{12}, C(\\{1,3,4\\},3)+s_{32}, C(\\{1,3,4\\},4)+s_{42}\\} = \\min\\{17+6, 12+4, 21+6\\} = 16$\n$C(\\{1,2,3,4\\},3) = \\min\\{C(\\{1,2,4\\},1)+s_{13}, C(\\{1,2,4\\},2)+s_{23}, C(\\{1,2,4\\},4)+s_{43}\\} = \\min\\{6+7, 11+5, 12+6\\} = 13$\n$C(\\{1,2,3,4\\},4) = \\min\\{C(\\{1,2,3\\},1)+s_{14}, C(\\{1,2,3\\},2)+s_{24}, C(\\{1,2,3\\},3)+s_{34}\\} = \\min\\{15+5, 19+2, 14+7\\} = 20$\nThe other values for $|S|=4$ are computed similarly, leading to the following values which are used in the final stage:\n$C(\\{1,2,3,5\\},1)=17, C(\\{1,2,3,5\\},2)=17, C(\\{1,2,3,5\\},3)=12, C(\\{1,2,3,5\\},5)=18$\n$C(\\{1,2,4,5\\},1)=14, C(\\{1,2,4,5\\},2)=13, C(\\{1,2,4,5\\},4)=16, C(\\{1,2,4,5\\},5)=9$\n$C(\\{1,3,4,5\\},1)=17, C(\\{1,3,4,5\\},3)=10, C(\\{1,3,4,5\\},4)=20, C(\\{1,3,4,5\\},5)=17$\n$C(\\{2,3,4,5\\},2)=14, C(\\{2,3,4,5\\},3)=11, C(\\{2,3,4,5\\},4)=15, C(\\{2,3,4,5\\},5)=16$\n\n**Stage 5: $|S|=5$**\nWe compute the costs for the full set $S=\\{1,2,3,4,5\\}$.\n$C(S,1) = \\min\\{C(\\{2,3,4,5\\},2)+s_{21}, C(\\{2,3,4,5\\},3)+s_{31}, C(\\{2,3,4,5\\},4)+s_{41}, C(\\{2,3,4,5\\},5)+s_{51}\\} = \\min\\{14+4, 11+7, 15+1, 16+5\\} = \\min\\{18, 18, 16, 21\\} = 16$.\n\n$C(S,2) = \\min\\{C(\\{1,3,4,5\\},1)+s_{12}, C(\\{1,3,4,5\\},3)+s_{32}, C(\\{1,3,4,5\\},4)+s_{42}, C(\\{1,3,4,5\\},5)+s_{52}\\} = \\min\\{17+6, 10+4, 20+6, 17+5\\} = \\min\\{23, 14, 26, 22\\} = 14$.\n\n$C(S,3) = \\min\\{C(\\{1,2,4,5\\},1)+s_{13}, C(\\{1,2,4,5\\},2)+s_{23}, C(\\{1,2,4,5\\},4)+s_{43}, C(\\{1,2,4,5\\},5)+s_{53}\\} = \\min\\{14+7, 13+5, 16+6, 9+2\\} = \\min\\{21, 18, 22, 11\\} = 11$.\n\n$C(S,4) = \\min\\{C(\\{1,2,3,5\\},1)+s_{14}, C(\\{1,2,3,5\\},2)+s_{24}, C(\\{1,2,3,5\\},3)+s_{34}, C(\\{1,2,3,5\\},5)+s_{54}\\} = \\min\\{17+5, 17+2, 12+7, 18+6\\} = \\min\\{22, 19, 19, 24\\} = 19$.\n\n$C(S,5) = \\min\\{C(\\{1,2,3,4\\},1)+s_{15}, C(\\{1,2,3,4\\},2)+s_{25}, C(\\{1,2,3,4\\},3)+s_{35}, C(\\{1,2,3,4\\},4)+s_{45}\\} = \\min\\{16+3, 16+6, 13+5, 20+4\\} = \\min\\{19, 22, 18, 24\\} = 18$.\n\n**Final Answer Calculation**\nThe minimum total setup cost is the minimum over all possible ending jobs:\n$$\n\\text{Minimal Total Cost} = \\min \\{ C(S,1), C(S,2), C(S,3), C(S,4), C(S,5) \\}\n$$\n$$\n\\text{Minimal Total Cost} = \\min \\{16, 14, 11, 19, 18\\} = 11\n$$\nThe optimal sequence giving this cost can be found by backtracking the calculations. The minimum cost of $11$ is $C(\\{1,2,3,4,5\\},3)$. This was achieved from state $(\\{1,2,4,5\\}, 5)$ with cost $C(\\{1,2,4,5\\},5)+s_{53} = 9+2=11$. Tracing back further reveals the optimal path is $0 \\to 2 \\to 4 \\to 1 \\to 5 \\to 3$, with a total cost of $s_{0,2} + s_{2,4} + s_{4,1} + s_{1,5} + s_{5,3} = 3 + 2 + 1 + 3 + 2 = 11$.", "answer": "$$\n\\boxed{11}\n$$", "id": "3123982"}]}