{"hands_on_practices": [{"introduction": "This first practice delves into a classic production smoothing problem, a cornerstone of inventory and supply chain management. We will apply the forward recursion principle of dynamic programming to track the cumulative deviation from a production target, represented by the state $d_{t+1} = d_t + x_t - \\bar{x}$. By building a table of reachable states and their minimum associated costs stage by stage, you will see firsthand how forward recursion systematically finds an optimal production plan that balances costs and constraints over time [@problem_id:3130922].", "problem": "A manufacturer plans production over a discrete, finite horizon of $T=4$ periods to smooth inventory swings around a target average production. Let the per-period production decision be $x_t$ and the target average be $\\bar{x}$. Define the cumulative deviation (inventory deviation) state by the forward recursion $d_{t+1} = d_t + x_t - \\bar{x}$ with initial condition $d_1 = 0$. The per-period penalty for inventory swings is the absolute deviation of the next state, namely $|d_{t+1}|$. The terminal deviation must be zero, $d_{5} = 0$, to enforce end-of-horizon balance. The objective is to minimize the total penalty $\\sum_{t=1}^{4} |d_{t+1}|$ subject to the forward state recursion and the following time-varying production feasibility sets:\n- At $t=1$: $x_1 \\in \\{8,\\,10\\}$.\n- At $t=2$: $x_2 \\in \\{8,\\,12\\}$.\n- At $t=3$: $x_3 \\in \\{10,\\,12\\}$.\n- At $t=4$: $x_4 \\in \\{8,\\,10\\}$.\nTake $\\bar{x} = 10$.\nUsing the principle of optimality from dynamic programming, construct a forward recursion that propagates the minimal cumulative penalty to each reachable state $d_{t+1}$ and enforces the terminal constraint $d_5=0$. Then compute the minimal total penalty value $\\sum_{t=1}^{4} |d_{t+1}|$ achieved by an optimal production sequence that satisfies all constraints. Report your final answer as a single real number. No rounding is required.", "solution": "The user wants me to solve a dynamic programming problem using forward recursion. The problem is to find the minimum total penalty over a $T=4$ period horizon.\n\n### Step 1: Extract Givens\n-   Time horizon: $T=4$ periods.\n-   Production decision at period $t$: $x_t$.\n-   Target average production: $\\bar{x} = 10$.\n-   State variable: $d_t$, the cumulative deviation from the target average.\n-   State transition (forward recursion): $d_{t+1} = d_t + x_t - \\bar{x}$.\n-   Initial condition: $d_1 = 0$.\n-   Per-period penalty: $|d_{t+1}|$.\n-   Objective function to minimize: $\\sum_{t=1}^{4} |d_{t+1}|$.\n-   Terminal constraint: $d_5 = 0$.\n-   Production feasibility sets:\n    -   $t=1$: $x_1 \\in \\{8, 10\\}$.\n    -   $t=2$: $x_2 \\in \\{8, 12\\}$.\n    -   $t=3$: $x_3 \\in \\{10, 12\\}$.\n    -   $t=4$: $x_4 \\in \\{8, 10\\}$.\n\n### Step 2: Validate Using Extracted Givens\nThe problem is a well-defined discrete-time finite-horizon optimal control problem. It is mathematically and logically self-contained. The state, control, dynamics, and cost are all clearly specified. The problem is scientifically grounded in the principles of dynamic programming and optimization theory. All terms are objective and precisely defined. It does not violate any scientific principles, is not ill-posed, and contains all necessary information for a solution. The constraints are not contradictory.\n\n### Step 3: Verdict and Action\nThe problem is valid. A solution will be provided.\n\nThis problem can be solved using a forward recursion approach, as suggested by the problem statement. We define the state of the system at the beginning of period $t$ by the cumulative deviation $d_t$. The decision variable is the production $x_t$. The state transition equation is given by $d_{t+1} = d_t + x_t - \\bar{x}$, with $\\bar{x}=10$. The initial state is $d_1 = 0$.\n\nLet $J_t(d_t)$ be the minimum cumulative penalty to reach state $d_t$ at the beginning of period $t$. The objective is to find $\\min \\sum_{t=1}^{4} |d_{t+1}|$ subject to the constraints. This is equivalent to finding the minimum value of $J_5(d_5=0)$. The forward recursion for the minimum cost is:\n$$J_{t+1}(d_{t+1}) = \\min_{d_t, x_t} \\{ J_t(d_t) + |d_{t+1}| \\}$$\nwhere the minimization is over all pairs of prior states $d_t$ and feasible decisions $x_t$ that result in the state $d_{t+1} = d_t + x_t - 10$.\n\nWe proceed stage by stage.\n\n**Stage 1: From $t=1$ to $t=2$**\nThe system starts in state $d_1 = 0$ with an initial cost of $J_1(0)=0$.\nThe available production decisions are $x_1 \\in \\{8, 10\\}$.\n\n-   If $x_1 = 8$: The next state is $d_2 = d_1 + x_1 - 10 = 0 + 8 - 10 = -2$.\n    The cumulative cost to reach this state is $J_2(-2) = J_1(0) + |d_2| = 0 + |-2| = 2$.\n-   If $x_1 = 10$: The next state is $d_2 = d_1 + x_1 - 10 = 0 + 10 - 10 = 0$.\n    The cumulative cost to reach this state is $J_2(0) = J_1(0) + |d_2| = 0 + |0| = 0$.\n\nAt the start of period $t=2$, the reachable states are $d_2 \\in \\{-2, 0\\}$ with minimum costs $J_2(-2)=2$ and $J_2(0)=0$.\n\n**Stage 2: From $t=2$ to $t=3$**\nThe available production decisions are $x_2 \\in \\{8, 12\\}$. We compute the next states $d_3$ and their costs from each reachable state $d_2$.\n\n-   From $d_2 = -2$ (with current cost $J_2(-2)=2$):\n    -   If $x_2 = 8$: $d_3 = -2 + 8 - 10 = -4$. New cost: $J_2(-2) + |-4| = 2 + 4 = 6$.\n    -   If $x_2 = 12$: $d_3 = -2 + 12 - 10 = 0$. New cost: $J_2(-2) + |0| = 2 + 0 = 2$.\n-   From $d_2 = 0$ (with current cost $J_2(0)=0$):\n    -   If $x_2 = 8$: $d_3 = 0 + 8 - 10 = -2$. New cost: $J_2(0) + |-2| = 0 + 2 = 2$.\n    -   If $x_2 = 12$: $d_3 = 0 + 12 - 10 = 2$. New cost: $J_2(0) + |2| = 0 + 2 = 2$.\n\nAt the start of period $t=3$, the reachable states are $d_3 \\in \\{-4, -2, 0, 2\\}$. Since no state is reached by multiple paths, we do not need to take a minimum. The minimum costs are:\n-   $J_3(-4) = 6$\n-   $J_3(-2) = 2$\n-   $J_3(0) = 2$\n-   $J_3(2) = 2$\n\n**Stage 3: From $t=3$ to $t=4$**\nThe available production decisions are $x_3 \\in \\{10, 12\\}$.\n\n-   From $d_3 = -4$ (cost $6$):\n    -   $x_3 = 10 \\implies d_4 = -4+10-10 = -4$. Cost: $6+|-4|=10$.\n    -   $x_3 = 12 \\implies d_4 = -4+12-10 = -2$. Cost: $6+|-2|=8$.\n-   From $d_3 = -2$ (cost $2$):\n    -   $x_3 = 10 \\implies d_4 = -2+10-10 = -2$. Cost: $2+|-2|=4$.\n    -   $x_3 = 12 \\implies d_4 = -2+12-10 = 0$. Cost: $2+|0|=2$.\n-   From $d_3 = 0$ (cost $2$):\n    -   $x_3 = 10 \\implies d_4 = 0+10-10 = 0$. Cost: $2+|0|=2$.\n    -   $x_3 = 12 \\implies d_4 = 0+12-10 = 2$. Cost: $2+|2|=4$.\n-   From $d_3 = 2$ (cost $2$):\n    -   $x_3 = 10 \\implies d_4 = 2+10-10 = 2$. Cost: $2+|2|=4$.\n    -   $x_3 = 12 \\implies d_4 = 2+12-10 = 4$. Cost: $2+|4|=6$.\n\nAt the start of period $t=4$, the reachable states are $d_4 \\in \\{-4, -2, 0, 2, 4\\}$. Some states are reached via multiple paths, so we apply the principle of optimality by taking the minimum cost for each state.\n-   $J_4(-4)$: Reached only from $d_3 = -4, x_3=10$. Cost $10$. So, $J_4(-4) = 10$.\n-   $J_4(-2)$: Reached from ($d_3=-4, x_3=12$) with cost $8$ and from ($d_3=-2, x_3=10$) with cost $4$. So, $J_4(-2) = \\min(8, 4) = 4$.\n-   $J_4(0)$: Reached from ($d_3=-2, x_3=12$) with cost $2$ and from ($d_3=0, x_3=10$) with cost $2$. So, $J_4(0) = \\min(2, 2) = 2$.\n-   $J_4(2)$: Reached from ($d_3=0, x_3=12$) with cost $4$ and from ($d_3=2, x_3=10$) with cost $4$. So, $J_4(2) = \\min(4, 4) = 4$.\n-   $J_4(4)$: Reached only from $d_3 = 2, x_3=12$. Cost $6$. So, $J_4(4) = 6$.\n\nSummary of minimum costs at $t=4$: $J_4(-4)=10$, $J_4(-2)=4$, $J_4(0)=2$, $J_4(2)=4$, $J_4(4)=6$.\n\n**Stage 4: From $t=4$ to $t=5$**\nThe available production decisions are $x_4 \\in \\{8, 10\\}$. We must enforce the terminal constraint $d_5=0$. The state transition is $d_5 = d_4 + x_4 - 10$. The constraint implies $0 = d_4 + x_4 - 10$, or $x_4 = 10 - d_4$.\nWe check which of the reachable states $d_4$ lead to a feasible $x_4$. The total cost will be $J_4(d_4) + |d_5| = J_4(d_4) + |0| = J_4(d_4)$.\n\n-   If $d_4 = -4$: Required $x_4 = 10 - (-4) = 14$. This is not in $\\{8, 10\\}$, so this path is infeasible.\n-   If $d_4 = -2$: Required $x_4 = 10 - (-2) = 12$. This is not in $\\{8, 10\\}$, so this path is infeasible.\n-   If $d_4 = 0$: Required $x_4 = 10 - 0 = 10$. This is in $\\{8, 10\\}$. This path is feasible. The total cost is $J_4(0) = 2$.\n-   If $d_4 = 2$: Required $x_4 = 10 - 2 = 8$. This is in $\\{8, 10\\}$. This path is feasible. The total cost is $J_4(2) = 4$.\n-   If $d_4 = 4$: Required $x_4 = 10 - 4 = 6$. This is not in $\\{8, 10\\}$, so this path is infeasible.\n\nThe possible total penalties for feasible production sequences are $2$ and $4$. The minimum of these is the optimal value.\nMinimal total penalty $= \\min(2, 4) = 2$.\nTo verify, an optimal sequence is $x=(10, 8, 12, 10)$. The states are $d_1=0 \\to d_2=0 \\to d_3=-2 \\to d_4=0 \\to d_5=0$. The total penalty is $|0| + |-2| + |0| + |0| = 2$.\nAnother optimal sequence is $x=(8, 12, 10, 10)$. The states are $d_1=0 \\to d_2=-2 \\to d_3=0 \\to d_4=0 \\to d_5=0$. The total penalty is $|-2| + |0| + |0| + |0| = 2$.\nThe minimal total penalty is $2$.", "answer": "$$\\boxed{2}$$", "id": "3130922"}, {"introduction": "Moving from simple linear models to more realistic scenarios, this exercise tackles an optimal control problem featuring actuator nonlinearities. Real-world systems often have physical limitations like deadzones and saturation, which we will model explicitly using the function $\\phi(u)$. You will implement a forward recursion as a search algorithm that propagates the system's state forward in time, exploring all feasible control actions and pruning paths that violate constraints, demonstrating how this method handles complex, nonlinear dynamics to find an optimal solution [@problem_id:3130998].", "problem": "You are given a discrete-time control system with actuator nonlinearity that includes a deadzone and saturation. The state update is given by the forward recursion\n$$\nx_{t+1} = f(x_t, \\phi(u_t)) = a x_t + b \\,\\phi(u_t),\n$$\nwhere $x_t \\in \\mathbb{R}$ is the state at time $t$, $u_t \\in \\mathbb{R}$ is the commanded actuator input, and $\\phi(u)$ models actuator deadzone and saturation via\n$$\n\\phi(u) = \\operatorname{sign}(u)\\,\\min\\left(\\max\\left(|u| - d,\\, 0\\right),\\, u_{\\max}\\right).\n$$\nThe objective is to choose a control sequence $\\{u_t\\}_{t=0}^{T-1}$ from a finite control set $U$ to minimize the quadratic cost\n$$\nJ(\\{u_t\\}) = \\sum_{t=0}^{T-1} \\left(q\\,x_t^2 + r\\,u_t^2\\right) + q_f\\,x_T^2,\n$$\nsubject to the forward-propagated nonlinear path constraints for all $t \\in \\{0,1,\\dots,T\\}$:\n$$\n|x_t| \\le x_{\\max}, \\quad g(x_t) \\le 0, \\quad \\text{where} \\quad g(x) = \\alpha x^2 + \\beta |x| - \\gamma.\n$$\nStart from the fundamental definitions of discrete-time dynamics and actuator nonlinearity as given above. Design and implement a forward recursion that:\n- Builds the trajectory forward in time by enumerating the control set $U$ at each stage.\n- Applies the actuator nonlinearity $\\phi(\\cdot)$ and propagates the state via $f(\\cdot,\\cdot)$.\n- Enforces the path constraints at each time step and prunes any partial trajectory that violates them.\n- Accumulates the cost $J$ across the horizon and returns the minimal cost over all feasible control sequences.\n\nYour program must implement this forward recursion to find the globally minimal cost over the discrete control set $U$ for each of the test cases below. If no feasible control sequence exists, the minimal cost is undefined; however, the provided test suite is designed to be feasible.\n\nUse the fixed discrete control set $U = \\{-1.0, -0.5, 0.0, 0.5, 1.0\\}$ for all cases. For each test case, the parameters $(a,b,x_0,T,q,r,q_f,d,u_{\\max},x_{\\max},\\alpha,\\beta,\\gamma)$ are given as follows:\n\n- Case $1$ (happy path, moderate dynamics):\n  - $a = 0.9$, $b = 1.0$, $x_0 = 2.5$, $T = 5$\n  - $q = 1.0$, $r = 0.1$, $q_f = 2.0$\n  - $d = 0.2$, $u_{\\max} = 0.8$\n  - $x_{\\max} = 5.0$\n  - $\\alpha = 0.05$, $\\beta = 0.0$, $\\gamma = 2.0$\n\n- Case $2$ (boundary case, unstable open-loop with strong deadzone and tight nonlinear constraint):\n  - $a = 1.1$, $b = 0.7$, $x_0 = 1.0$, $T = 6$\n  - $q = 1.0$, $r = 0.05$, $q_f = 1.5$\n  - $d = 0.4$, $u_{\\max} = 0.6$\n  - $x_{\\max} = 3.0$\n  - $\\alpha = 0.1$, $\\beta = 0.2$, $\\gamma = 1.0$\n\n- Case $3$ (edge case, short horizon with small saturation and no additional nonlinear constraint beyond $|x_t| \\le x_{\\max}$):\n  - $a = 1.0$, $b = 1.0$, $x_0 = -0.3$, $T = 1$\n  - $q = 0.0$, $r = 0.2$, $q_f = 1.0$\n  - $d = 0.1$, $u_{\\max} = 0.3$\n  - $x_{\\max} = 0.5$\n  - $\\alpha = 0.0$, $\\beta = 0.0$, $\\gamma = 0.25$\n\nImplementation requirements:\n- Use a forward recursion that enumerates controls $u_t \\in U$ depth-first, computes $\\phi(u_t)$, updates $x_{t+1}$, checks constraints on both $x_t$ and $x_{t+1}$, accumulates stage cost $q x_t^2 + r u_t^2$, and at $t = T$ adds the terminal cost $q_f x_T^2$.\n- Your program must compute the minimal feasible cost $J^\\star$ for each case.\n\nFinal output specification:\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, for example, $[j_1, j_2, j_3]$, where each $j_k$ is the minimal feasible cost for the corresponding case.\n- Express each $j_k$ as a floating-point number rounded to exactly $6$ decimal places.", "solution": "The problem is valid. It presents a well-defined discrete-time finite-horizon optimal control problem with a discrete control set. The dynamics, cost function, and constraints are mathematically precise and consistent. The task is to find the minimum cost by enumerating all feasible control sequences, which is a standard approach for such problems, often referred to as forward recursion or exhaustive search with pruning.\n\nThe core of the problem is to find a control sequence $\\{u_t\\}_{t=0}^{T-1}$ with each $u_t$ chosen from a finite set $U$, that minimizes the total cost $J$ while satisfying all constraints. The system evolves according to the forward recursion:\n$$\nx_{t+1} = a x_t + b \\,\\phi(u_t)\n$$\nwhere the state is $x_t \\in \\mathbb{R}$ and the control is $u_t \\in U$. The function $\\phi(u)$ models a physical actuator with a deadzone of size $d$ and saturation at $u_{\\max}$:\n$$\n\\phi(u) = \\operatorname{sign}(u)\\,\\min\\left(\\max\\left(|u| - d,\\, 0\\right),\\, u_{\\max}\\right)\n$$\nThe objective is to minimize the quadratic cost function:\n$$\nJ(\\{u_t\\}) = \\sum_{t=0}^{T-1} \\left(q\\,x_t^2 + r\\,u_t^2\\right) + q_f\\,x_T^2\n$$\nThe trajectory must satisfy path constraints for all time steps $t \\in \\{0, 1, \\dots, T\\}$:\n$$\n|x_t| \\le x_{\\max} \\quad \\text{and} \\quad g(x_t) \\le 0\n$$\nwhere the nonlinear constraint function $g(x)$ is given by:\n$$\ng(x) = \\alpha x^2 + \\beta |x| - \\gamma\n$$\nGiven that the time horizon $T$ is finite and the control set $U$ is discrete and finite, the total number of possible control sequences is $|U|^T$. This allows for a direct solution via systematic enumeration. The specified \"forward recursion\" approach is implemented as a depth-first search algorithm that explores the tree of possible state trajectories.\n\nThe algorithm proceeds as follows:\nWe define a recursive function, let's call it `search(t, x_t, accumulated_cost)`, which explores possible trajectories starting from state $x_t$ at time $t$ with a cost of `accumulated_cost` incurred up to time $t-1$.\n\n1.  **Constraint Enforcement and Pruning**: At the beginning of the `search(t, x_t, ...)` call, the state $x_t$ is checked against the path constraints: $|x_t| \\le x_{\\max}$ and $g(x_t) \\le 0$. If either constraint is violated, the current trajectory is infeasible. This entire branch of the search tree is \"pruned\" by immediately returning from the function, preventing further exploration of invalid paths. This step is crucial for efficiency.\n\n2.  **Base Case**: The recursion terminates when $t=T$, signifying the end of the horizon. At this point, the state $x_T$ has been reached. The constraints are checked for this final state. If valid, the total cost for this complete, feasible trajectory is calculated by adding the terminal cost to the accumulated running cost: $J = \\text{accumulated\\_cost} + q_f x_T^2$. This cost is then compared with the globally stored minimum cost, and if it is lower, the global minimum is updated.\n\n3.  **Recursive Step**: If $t < T$ and the state $x_t$ is valid, the algorithm iterates through every possible control input $u_t \\in U$. For each choice of $u_t$:\n    a. The stage cost for the current time step, $q x_t^2 + r u_t^2$, is computed and added to the cost accumulated so far.\n    b. The next state, $x_{t+1}$, is calculated using the system dynamics: $x_{t+1} = a x_t + b \\,\\phi(u_t)$.\n    c. A recursive call is made for the next time step: `search(t + 1, x_{t+1}, new_accumulated_cost)`.\n\nThe initial call to the algorithm is `search(0, x_0, 0)`, starting at the initial state $x_0$ at time $t=0$ with zero accumulated cost. A variable holding the minimum cost found is initialized to infinity. Since the problem statement guarantees that feasible solutions exist for the given test cases, this process is guaranteed to find the true global minimum cost.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to solve the optimal control problem for all test cases.\n    \"\"\"\n    test_cases = [\n        # Case 1\n        (0.9, 1.0, 2.5, 5, 1.0, 0.1, 2.0, 0.2, 0.8, 5.0, 0.05, 0.0, 2.0),\n        # Case 2\n        (1.1, 0.7, 1.0, 6, 1.0, 0.05, 1.5, 0.4, 0.6, 3.0, 0.1, 0.2, 1.0),\n        # Case 3\n        (1.0, 1.0, -0.3, 1, 0.0, 0.2, 1.0, 0.1, 0.3, 0.5, 0.0, 0.0, 0.25),\n    ]\n\n    results = []\n    for params in test_cases:\n        solver = ForwardRecursionSolver(params)\n        min_cost = solver.solve()\n        results.append(f\"{min_cost:.6f}\")\n\n    print(f\"[{','.join(results)}]\")\n\nclass ForwardRecursionSolver:\n    \"\"\"\n    Solves the discrete-time optimal control problem using forward recursion\n    (depth-first search with pruning).\n    \"\"\"\n\n    def __init__(self, params):\n        (self.a, self.b, self.x0, self.T, self.q, self.r, self.qf,\n         self.d, self.umax, self.xmax, self.alpha, self.beta, self.gamma) = params\n        self.U = [-1.0, -0.5, 0.0, 0.5, 1.0]\n        self.min_cost = float('inf')\n\n    def phi(self, u: float) -> float:\n        \"\"\"\n        Actuator nonlinearity with deadzone and saturation.\n        phi(u) = sign(u) * min(max(|u| - d, 0), u_max)\n        \"\"\"\n        if u == 0:\n            return 0.0\n        return np.sign(u) * min(max(abs(u) - self.d, 0.0), self.umax)\n\n    def g(self, x: float) -> float:\n        \"\"\"\n        Nonlinear path constraint function.\n        g(x) = alpha * x^2 + beta * |x| - gamma\n        \"\"\"\n        return self.alpha * x**2 + self.beta * abs(x) - self.gamma\n\n    def check_constraints(self, x: float) -> bool:\n        \"\"\"\n        Checks if the state x violates any path constraints.\n        Returns True if valid, False if violated.\n        \"\"\"\n        if abs(x) > self.xmax:\n            return False\n        if self.g(x) > 0:\n            return False\n        return True\n\n    def find_min_cost_recursive(self, t: int, xt: float, accumulated_cost: float):\n        \"\"\"\n        Recursive function to perform the depth-first search.\n        \"\"\"\n        # 1. Enforce path constraints and prune if violated.\n        if not self.check_constraints(xt):\n            return\n\n        # 2. Base case: Reached the end of the time horizon.\n        if t == self.T:\n            final_cost = accumulated_cost + self.qf * xt**2\n            if final_cost < self.min_cost:\n                self.min_cost = final_cost\n            return\n\n        # 3. Recursive step: Explore control inputs for the current stage.\n        cost_from_state = self.q * xt**2\n        for ut in self.U:\n            cost_from_control = self.r * ut**2\n            new_accumulated_cost = accumulated_cost + cost_from_state + cost_from_control\n\n            # Prune if accumulated cost already exceeds the best found so far.\n            if new_accumulated_cost >= self.min_cost:\n                continue\n\n            # Propagate state to the next time step.\n            phi_u = self.phi(ut)\n            x_next = self.a * xt + self.b * phi_u\n\n            # Recursive call for the next stage.\n            self.find_min_cost_recursive(t + 1, x_next, new_accumulated_cost)\n\n    def solve(self) -> float:\n        \"\"\"\n        Initializes the recursive search and returns the minimal cost.\n        \"\"\"\n        # The cost sum starts from t=0. At t=0, the accumulated cost is 0.\n        self.find_min_cost_recursive(0, self.x0, 0.0)\n        return self.min_cost\n\nif __name__ == \"__main__\":\n    solve()\n```", "id": "3130998"}, {"introduction": "Our final practice introduces the element of uncertainty, a key challenge in modern optimization. We will address a stochastic resource allocation problem where the goal is to allocate a finite budget over time to minimize the expected number of future constraint violations, $\\mathbb{E}[V_T]$. This problem requires you to build a forward dynamic programming recursion for a value function, $F_t(b)$, which represents the minimum expected cost achievable up to a given stage. This advanced application demonstrates the power of forward recursion in making optimal decisions under uncertainty [@problem_id:3130969].", "problem": "You are given a finite-horizon stochastic resource allocation problem whose goal is to minimize the expected number of constraint violations. At each discrete time step $t \\in \\{0,1,\\dots,T-1\\}$ you choose a nonnegative scalar decision $x_t \\in \\mathbb{R}_{\\ge 0}$. The system is subject to a stochastic inequality constraint represented by the function $g_t(x_t,\\xi_t) = \\xi_t - x_t$, where $\\xi_t$ is a random variable. A violation at time $t$ occurs when $g_t(x_t,\\xi_t) > 0$, equivalently when $\\xi_t > x_t$. Let the running violation count be the forward recursion\n$$\nV_{t+1} = V_t + \\mathbb{1}\\{\\xi_t > x_t\\}, \\quad V_0 = 0,\n$$\nwhere $\\mathbb{1}\\{\\cdot\\}$ denotes the indicator function. Your objective is to choose the sequence $(x_0,\\dots,x_{T-1})$ to minimize the expected total number of violations $\\mathbb{E}[V_T]$, subject to the total budget constraint $\\sum_{t=0}^{T-1} x_t \\le B$.\n\nAssume the following model and foundational facts:\n- For each $t$, the random variables $\\xi_t$ are independent and normally distributed with mean $\\mu_t$ and standard deviation $\\sigma_t$, written $\\xi_t \\sim \\mathcal{N}(\\mu_t,\\sigma_t^2)$.\n- The indicator function satisfies $\\mathbb{E}[\\mathbb{1}\\{A\\}] = \\mathbb{P}(A)$ for any event $A$.\n- Linearity of expectation holds: for random variables $Y_t$, $\\mathbb{E}\\Big[\\sum_t Y_t\\Big] = \\sum_t \\mathbb{E}[Y_t]$.\n- The survival function of a normal random variable is well-defined and numerically computable.\n\nStarting from these bases only (definitions and laws above), do the following.\n\n1) Derive a forward recursion for the conditional expectation of the violation count and conclude a non-asymptotic expression for $\\mathbb{E}[V_T]$ in terms of the decisions $x_t$ and the survival probabilities $\\mathbb{P}(\\xi_t > x_t)$.\n\n2) Reformulate the optimization of $\\mathbb{E}[V_T]$ under the budget constraint as a finite-horizon dynamic program over a discretized action space. Specifically, let the decision grid step be $\\Delta > 0$ and restrict each $x_t$ to the grid $\\{0,\\Delta,2\\Delta,\\dots\\}$, so that the cumulative budget spent after $t$ steps is an integer multiple of $\\Delta$. Define a forward dynamic programming state $b_t \\in \\{0,\\Delta,2\\Delta,\\dots,B\\}$ representing the cumulative resource used by time $t$, and define a value function $F_t(b)$ as the minimal expected violation count achievable up to time $t$ using exactly budget $b$. Provide the forward recursion that updates $F_t$ to $F_{t+1}$ and explain how this realizes the forward recursion on expected violation counts while enforcing the budget feasibility $\\sum_{t=0}^{T-1} x_t \\le B$.\n\n3) Implement the forward recursion numerically for the following test suite. In each test case, you must compute:\n- the minimal expected number of violations $\\min \\mathbb{E}[V_T]$ over all $(x_t)$ lying on the grid,\n- and one corresponding grid-feasible optimal allocation $(x_0^\\star,\\dots,x_{T-1}^\\star)$ with $\\sum_{t=0}^{T-1} x_t^\\star \\le B$.\n\nUse the normal survival function to evaluate $\\mathbb{P}(\\xi_t > x_t)$ exactly (no Monte Carlo sampling). Your program must solve each test case by forward dynamic programming and output a single line containing a list of results, one per test case, where each test case result is a list whose first entry is the minimal expected number of violations and whose subsequent entries are the optimal allocations in temporal order.\n\nTest suite:\n- Case A: $T=4$, $\\mu=(1.5,2.0,1.0,3.0)$, $\\sigma=(0.5,1.0,1.5,0.75)$, $B=3.0$, $\\Delta=0.25$.\n- Case B: $T=3$, $\\mu=(0.0,0.5,-0.5)$, $\\sigma=(1.0,1.5,0.5)$, $B=0.0$, $\\Delta=0.5$.\n- Case C: $T=5$, $\\mu=(0.5,0.5,0.5,0.5,0.5)$, $\\sigma=(0.25,0.25,0.25,0.25,0.25)$, $B=5.0$, $\\Delta=0.5$.\n\nOutput format and numerical details:\n- For each test case, output a list whose first element is the minimal expected violation count rounded to six decimal places, followed by the optimal decisions $(x_0^\\star,\\dots,x_{T-1}^\\star)$ as decimal numbers (multiples of $\\Delta$). \n- Aggregate all test case results into a single list and print exactly one line containing that list without any additional text. For example, the printed line should have the form $[\\text{caseA},\\text{caseB},\\text{caseC}]$ where each $\\text{caseX}$ is itself a list as specified.\n- There are no physical units and no angles; all quantities are unitless real numbers.", "solution": "The user wants me to solve a finite-horizon stochastic resource allocation problem.\n\n### Step 1: Extract Givens\n- **Problem Type**: Finite-horizon stochastic resource allocation.\n- **Time Horizon**: Discrete time steps $t \\in \\{0, 1, \\dots, T-1\\}$.\n- **Decision Variables**: A sequence of nonnegative scalar decisions $(x_0, x_1, \\dots, x_{T-1})$, with $x_t \\in \\mathbb{R}_{\\ge 0}$.\n- **Stochastic Constraint Function**: $g_t(x_t, \\xi_t) = \\xi_t - x_t$.\n- **Constraint Violation Event**: A violation occurs at time $t$ if $g_t(x_t, \\xi_t) > 0$, which is equivalent to $\\xi_t > x_t$.\n- **Random Variables**: For each $t$, $\\xi_t$ is an independent random variable with distribution $\\xi_t \\sim \\mathcal{N}(\\mu_t, \\sigma_t^2)$.\n- **State Variable (Violation Count)**: The running violation count $V_t$ follows the forward recursion $V_{t+1} = V_t + \\mathbb{1}\\{\\xi_t > x_t\\}$, with initial condition $V_0 = 0$. $\\mathbb{1}\\{\\cdot\\}$ is the indicator function.\n- **Objective Function**: Minimize the expected total number of violations, $\\mathbb{E}[V_T]$.\n- **Budget Constraint**: The total resource usage is limited: $\\sum_{t=0}^{T-1} x_t \\le B$.\n- **Provided Foundational Facts**:\n    1. $\\mathbb{E}[\\mathbb{1}\\{A\\}] = \\mathbb{P}(A)$ for any event $A$.\n    2. Linearity of expectation: $\\mathbb{E}\\left[\\sum_t Y_t\\right] = \\sum_t \\mathbb{E}[Y_t]$.\n    3. The survival function of a normal random variable is well-defined and computable.\n- **Task 1**: Derive a forward recursion for the conditional expectation of the violation count and a non-asymptotic expression for $\\mathbb{E}[V_T]$.\n- **Task 2**: Formulate a forward dynamic program over a discretized action space.\n    - Decision grid step: $\\Delta > 0$, $x_t \\in \\{0, \\Delta, 2\\Delta, \\dots\\}$.\n    - DP state: $b_t \\in \\{0, \\Delta, \\dots, B\\}$, cumulative resource used by time $t$.\n    - Value function: $F_t(b)$, minimal expected violation count up to time $t$ using exactly budget $b$.\n    - Provide the forward DP recursion.\n- **Task 3**: Implement the forward DP numerically for three test cases and output the minimal expected violations and a corresponding optimal allocation policy.\n- **Test Cases**:\n    - Case A: $T=4$, $\\mu=(1.5, 2.0, 1.0, 3.0)$, $\\sigma=(0.5, 1.0, 1.5, 0.75)$, $B=3.0$, $\\Delta=0.25$.\n    - Case B: $T=3$, $\\mu=(0.0, 0.5, -0.5)$, $\\sigma=(1.0, 1.5, 0.5)$, $B=0.0$, $\\Delta=0.5$.\n    - Case C: $T=5$, $\\mu=(0.5, 0.5, 0.5, 0.5, 0.5)$, $\\sigma=(0.25, 0.25, 0.25, 0.25, 0.25)$, $B=5.0$, $\\Delta=0.5$.\n\n### Step 2: Validate Using Extracted Givens\nThe problem is subjected to a critical review based on the validation criteria.\n\n- **Scientifically Grounded**: The problem is formulated within the well-established mathematical frameworks of probability theory, stochastic processes, and dynamic programming. The use of normal distributions, expectation, and optimization is standard in engineering and operations research. The problem is scientifically sound.\n- **Well-Posed**: The problem is a standard resource allocation problem with a separable objective function and a linear constraint. The objective is to find a sequence of decisions $(x_0, \\dots, x_{T-1})$ that minimizes an expected value. Given the properties of the probability distributions (continuous and well-behaved), a solution exists. The discretization for the dynamic programming approach ensures a unique minimum value can be found. The problem is well-posed.\n- **Objective**: The problem is stated using precise mathematical language and definitions. All quantities are defined, and the objectives are unambiguous. It is free of subjective or opinion-based statements.\n- **Completeness**: All necessary information is provided: the time horizon $T$, the parameters $(\\mu_t, \\sigma_t)$ for the random variables at each stage, the total budget $B$, and the discretization step $\\Delta$. The problem is self-contained.\n- **Consistency**: There are no contradictory constraints or definitions.\n- **Relevance**: The problem directly addresses the topic of forward recursion and its application in optimization methods, specifically dynamic programming.\n\nThe problem statement does not exhibit any of the invalidity flaws. It is a standard, well-defined problem from the field of stochastic optimal control.\n\n### Step 3: Verdict and Action\nThe problem is **valid**. A full solution will be provided.\n\n### Solution Derivation and Dynamic Programming Formulation\n\n**1) Expression for the Expected Total Violations $\\mathbb{E}[V_T]$**\n\nThe total number of violations at the end of the horizon, $V_T$, is found by unrolling the given forward recursion for $V_{t+1}$:\n$$\nV_{t+1} = V_t + \\mathbb{1}\\{\\xi_t > x_t\\}, \\quad V_0 = 0\n$$\nUnrolling this from $t=0$ to $T-1$, we obtain:\n$$\nV_T = V_{T-1} + \\mathbb{1}\\{\\xi_{T-1} > x_{T-1}\\}\n$$\n$$\nV_T = \\left(V_{T-2} + \\mathbb{1}\\{\\xi_{T-2} > x_{T-2}\\}\\right) + \\mathbb{1}\\{\\xi_{T-1} > x_{T-1}\\}\n$$\n$$\n\\dots\n$$\n$$\nV_T = V_0 + \\sum_{t=0}^{T-1} \\mathbb{1}\\{\\xi_t > x_t\\}\n$$\nSince $V_0=0$, the total number of violations is simply the sum of the indicator functions over the horizon:\n$$\nV_T = \\sum_{t=0}^{T-1} \\mathbb{1}\\{\\xi_t > x_t\\}\n$$\nThe objective is to minimize the expectation of this quantity, $\\mathbb{E}[V_T]$. Using the provided principle of linearity of expectation, we can write:\n$$\n\\mathbb{E}[V_T] = \\mathbb{E}\\left[\\sum_{t=0}^{T-1} \\mathbb{1}\\{\\xi_t > x_t\\}\\right] = \\sum_{t=0}^{T-1} \\mathbb{E}[\\mathbb{1}\\{\\xi_t > x_t\\}]\n$$\nNow, using the second provided principle, $\\mathbb{E}[\\mathbb{1}\\{A\\}] = \\mathbb{P}(A)$, we have:\n$$\n\\mathbb{E}[V_T] = \\sum_{t=0}^{T-1} \\mathbb{P}(\\xi_t > x_t)\n$$\nThis is the non-asymptotic expression for the expected total violations. The quantity $\\mathbb{P}(\\xi_t > x_t)$ is the survival function of the normal random variable $\\xi_t \\sim \\mathcal{N}(\\mu_t, \\sigma_t^2)$ evaluated at $x_t$.\n\nThe problem also requests a forward recursion for the conditional expectation. Let $E_t = \\mathbb{E}[V_t]$. This represents the unconditional expected number of violations up to time $t-1$. The recursion for this quantity is derived as follows:\n$E_{t+1} = \\mathbb{E}[V_{t+1}] = \\mathbb{E}[V_t + \\mathbb{1}\\{\\xi_t > x_t\\}]$. By linearity of expectation and independence of $\\xi_t$ from past random variables, this becomes:\n$E_{t+1} = \\mathbb{E}[V_t] + \\mathbb{E}[\\mathbb{1}\\{\\xi_t > x_t\\}] = E_t + \\mathbb{P}(\\xi_t > x_t)$.\nWith the initial condition $E_0 = \\mathbb{E}[V_0] = 0$, this establishes the forward recursion for the expected violation count.\n\nThe optimization problem can now be stated as:\n$$\n\\min_{x_0, \\dots, x_{T-1}} \\sum_{t=0}^{T-1} \\mathbb{P}(\\xi_t > x_t)\n$$\nsubject to:\n$$\n\\sum_{t=0}^{T-1} x_t \\le B, \\quad x_t \\ge 0 \\quad \\forall t \\in \\{0, \\dots, T-1\\}\n$$\n\n**2) Forward Dynamic Programming Formulation**\n\nWe reformulate the problem using forward dynamic programming. The problem structure, with an additively separable objective and a linear sum constraint, is ideal for this approach.\n\n- **Stages**: The stages are indexed by time, $t = 0, 1, \\dots, T-1$.\n- **Discretization**: The decisions $x_t$ and budget $B$ are discretized into integer multiples of a step size $\\Delta > 0$. We work with integer indices for budget levels to ensure numerical stability. The number of budget levels is $N_b = \\text{round}(B/\\Delta) + 1$. A budget index $k \\in \\{0, 1, \\dots, N_b-1\\}$ corresponds to a budget value of $k\\Delta$.\n- **State**: The state at stage $t$ is the cumulative budget spent up to and including that stage. Let $b_t = \\sum_{i=0}^t x_i$. The state space at stage $t$ is $\\{0, \\Delta, \\dots, B\\}$, which corresponds to integer indices $\\{0, 1, \\dots, N_b-1\\}$.\n- **Value Function**: As specified, $F_t(b)$ is the minimal expected violation count from stage $0$ up to stage $t$, using a cumulative budget of exactly $b$.\n- **Cost Function**: The cost incurred at stage $t$ with decision $x_t$ is $C_t(x_t) = \\mathbb{P}(\\xi_t > x_t)$.\n\nThe DP recursion proceeds as follows:\n\n**Initialization (Stage $t=0$):**\nAt the first stage, the decision $x_0$ determines the initial cumulative budget $b_0 = x_0$. The value function is the cost incurred at this stage.\nFor each possible cumulative budget $b \\in \\{0, \\Delta, \\dots, B\\}$:\n$$\nF_0(b) = C_0(b) = \\mathbb{P}(\\xi_0 > b)\n$$\nWe also store the decision that leads to this state, which is simply $x_0 = b$. Let's use a policy table $\\pi_t(b)$ to store the optimal decision $x_t$ for achieving state $b$ at stage $t$. So, $\\pi_0(b) = b$.\n\n**Recursion (Stages $t=1, \\dots, T-1$):**\nTo compute the value function $F_t(b)$ for a cumulative budget $b$ at stage $t$, we consider all possible decisions $x_t \\in \\{0, \\Delta, \\dots, b\\}$ that could have been made at stage $t$. If we spend $x_t$ at stage $t$, the cumulative budget at the previous stage must have been $b - x_t$. The minimal cost to reach that previous state was $F_{t-1}(b - x_t)$. Thus, the new total cost is $F_{t-1}(b - x_t) + C_t(x_t)$. We choose the decision $x_t$ that minimizes this sum.\nFor each $t \\in \\{1, \\dots, T-1\\}$ and for each cumulative budget state $b \\in \\{0, \\Delta, \\dots, B\\}$:\n$$\nF_t(b) = \\min_{x_t \\in \\{0, \\Delta, \\dots, b\\}} \\left\\{ F_{t-1}(b - x_t) + C_t(x_t) \\right\\}\n$$\nThe corresponding optimal decision for this state is stored:\n$$\n\\pi_t(b) = \\arg\\min_{x_t \\in \\{0, \\Delta, \\dots, b\\}} \\left\\{ F_{t-1}(b - x_t) + C_t(x_t) \\right\\}\n$$\n\n**Final Solution and Policy Reconstruction:**\nAfter computing the value function table up to stage $T-1$, the overall minimum expected violation count is the minimum value in the final row of the table, since the total budget used can be any value up to $B$.\n$$\n\\min \\mathbb{E}[V_T] = \\min_{b \\in \\{0, \\Delta, \\dots, B\\}} F_{T-1}(b)\n$$\nLet $B^\\star$ be the optimal final cumulative budget that achieves this minimum:\n$$\nB^\\star = \\arg\\min_{b \\in \\{0, \\Delta, \\dots, B\\}} F_{T-1}(b)\n$$\nThe optimal allocation sequence $(x_0^\\star, x_1^\\star, \\dots, x_{T-1}^\\star)$ is reconstructed by backtracking from this final optimal state:\n- Let $b_{T-1}^\\star = B^\\star$.\n- $x_{T-1}^\\star = \\pi_{T-1}(b_{T-1}^\\star)$.\n- For $t = T-2, \\dots, 1$:\n    - The cumulative budget at stage $t$ was $b_t^\\star = b_{t+1}^\\star - x_{t+1}^\\star$.\n    - The decision was $x_t^\\star = \\pi_t(b_t^\\star)$.\n- Finally, for $t=0$:\n    - The cumulative budget at stage $0$ was $b_0^\\star = b_1^\\star - x_1^\\star$.\n    - The decision was $x_0^\\star = \\pi_0(b_0^\\star) = b_0^\\star$.\n\nThis procedure yields the minimum expected number of violations and a corresponding grid-feasible optimal allocation.\n\n**3) Numerical Implementation**\n\nThe logic described above is implemented in Python. The probability $\\mathbb{P}(\\xi_t > x_t)$ for $\\xi_t \\sim \\mathcal{N}(\\mu_t, \\sigma_t^2)$ is computed using the survival function `scipy.stats.norm.sf(x_t, loc=mu_t, scale=sigma_t)`. The DP table is built using `numpy` arrays, and the backtracking procedure recovers the optimal policy. The implementation handles the specified test cases and formats the output as required.", "answer": "```python\nimport numpy as np\nfrom scipy.stats import norm\n\ndef solve():\n    \"\"\"\n    Solves a stochastic resource allocation problem using forward dynamic programming.\n    \"\"\"\n    \n    test_cases = [\n        {\n            \"T\": 4,\n            \"mu\": (1.5, 2.0, 1.0, 3.0),\n            \"sigma\": (0.5, 1.0, 1.5, 0.75),\n            \"B\": 3.0,\n            \"Delta\": 0.25,\n        },\n        {\n            \"T\": 3,\n            \"mu\": (0.0, 0.5, -0.5),\n            \"sigma\": (1.0, 1.5, 0.5),\n            \"B\": 0.0,\n            \"Delta\": 0.5,\n        },\n        {\n            \"T\": 5,\n            \"mu\": (0.5, 0.5, 0.5, 0.5, 0.5),\n            \"sigma\": (0.25, 0.25, 0.25, 0.25, 0.25),\n            \"B\": 5.0,\n            \"Delta\": 0.5,\n        },\n    ]\n\n    results = []\n\n    for case in test_cases:\n        T = case[\"T\"]\n        mu = case[\"mu\"]\n        sigma = case[\"sigma\"]\n        B = case[\"B\"]\n        Delta = case[\"Delta\"]\n\n        # Use integer indices for budget levels to avoid floating point issues\n        # Number of discrete budget levels\n        num_budget_levels = int(round(B / Delta)) + 1\n        \n        # DP table F[t][b_idx] stores the min cost up to stage t with cumulative budget b_idx*Delta\n        F = np.full((T, num_budget_levels), np.inf)\n        \n        # Policy table pi[t][b_idx] stores the optimal decision x_t\n        pi = np.full((T, num_budget_levels), np.nan)\n\n        # Precompute costs C[t][x_idx] = P(xi_t > x_idx*Delta)\n        # The decision x_t can be at most B\n        num_decision_levels = int(round(B / Delta)) + 1\n        C = np.zeros((T, num_decision_levels))\n        for t in range(T):\n            for x_idx in range(num_decision_levels):\n                x_val = x_idx * Delta\n                C[t, x_idx] = norm.sf(x_val, loc=mu[t], scale=sigma[t])\n\n        # Initialization (Stage t=0)\n        # The cumulative budget b_0 is simply the decision x_0\n        for b0_idx in range(num_budget_levels):\n            x0_idx = b0_idx\n            F[0, b0_idx] = C[0, x0_idx]\n            pi[0, b0_idx] = x0_idx * Delta\n\n        # Forward recursion (Stages t=1 to T-1)\n        for t in range(1, T):\n            for b_cum_idx in range(num_budget_levels):\n                min_cost = np.inf\n                best_xt_val = -1.0\n\n                # Iterate through possible decisions x_t at stage t\n                # The cumulative budget b_cum_idx is already given.\n                # The decision x_t can't be larger than the cumulative budget\n                max_xt_idx = b_cum_idx\n                for xt_idx in range(max_xt_idx + 1):\n                    b_prev_idx = b_cum_idx - xt_idx\n                    \n                    cost_at_t = C[t, xt_idx]\n                    total_cost = F[t - 1, b_prev_idx] + cost_at_t\n\n                    if total_cost < min_cost:\n                        min_cost = total_cost\n                        best_xt_val = xt_idx * Delta\n                \n                F[t, b_cum_idx] = min_cost\n                pi[t, b_cum_idx] = best_xt_val\n\n        # Find the final optimal solution\n        # The total budget can be <= B, so we look for min cost across all final states\n        final_costs = F[T - 1, :]\n        min_total_cost = np.min(final_costs)\n        \n        # In case of ties, numpy.argmin returns the first occurrence\n        final_b_cum_idx = np.argmin(final_costs)\n        final_b_cum_val = final_b_cum_idx * Delta\n\n        # Backtrack to find the optimal allocation\n        x_opt = np.zeros(T)\n        current_b_cum = final_b_cum_val\n        for t in range(T - 1, -1, -1):\n            current_b_cum_idx = int(round(current_b_cum / Delta))\n            x_opt[t] = pi[t, current_b_cum_idx]\n            current_b_cum -= x_opt[t]\n        \n        # Format the output for the current case\n        case_result = [f\"{min_total_cost:.6f}\"]\n        case_result.extend([f\"{val:.2f}\".rstrip('0').rstrip('.') if val != 0 else \"0.0\" for val in x_opt])\n        results.append(case_result)\n\n    # Format the final output string as a list of lists\n    # Example: [[...], [...], [...]]\n    final_output = []\n    for case_res in results:\n        # Convert numeric strings to numbers where appropriate for final list\n        # first element is string, rest are floats\n        final_case = [case_res[0]]\n        for x_val in case_res[1:]:\n             final_case.append(float(x_val))\n        final_output.append(final_case)\n\n    print(str(final_output).replace(\"'\", \"\").replace(\" \", \"\"))\n\nsolve()\n```", "id": "3130969"}]}