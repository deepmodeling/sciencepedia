{"hands_on_practices": [{"introduction": "The shortest path problem is a classic and intuitive entry point for understanding backward recursion. By modeling the problem on a time-expanded network, we can naturally define the stages and states required for dynamic programming. This exercise guides you through applying the Bellman equation to find the optimal \"cost-to-go\" from every possible node-time pair, starting from the destination and working backward to the origin [@problem_id:3100097].", "problem": "Consider a discrete-time, deterministic shortest-path planning problem over a finite time horizon $T = 3$ on a time-expanded network with nodes $\\{s, u, v, d\\}$ and discrete times $t \\in \\{0, 1, 2, 3\\}$. A unit of flow starts at node $s$ at time $t = 0$ and must reach node $d$. There is a deadline at time $T_{d} = 2$, and a fixed deadline penalty of $M = 4$ is incurred if the arrival time at node $d$ is strictly greater than $T_{d}$. Movements occur along directed arcs that advance time by one unit. Waiting at a node is allowed via self-arcs that also advance time by one unit. All arc costs are time-dependent and additive along a path.\n\nThe time-expanded arcs and their costs are as follows. For $t = 0$:\n- Movement arcs: $(s, 0) \\to (u, 1)$ with cost $2$, and $(s, 0) \\to (v, 1)$ with cost $3$.\n- Waiting arcs: $(s, 0) \\to (s, 1)$ with cost $1$, $(u, 0) \\to (u, 1)$ with cost $1$, $(v, 0) \\to (v, 1)$ with cost $2$, and $(d, 0) \\to (d, 1)$ with cost $0$.\n\nFor $t = 1$:\n- Movement arcs: $(u, 1) \\to (d, 2)$ with cost $4$, $(v, 1) \\to (d, 2)$ with cost $1$, and $(u, 1) \\to (v, 2)$ with cost $1$; additionally, $(s, 1) \\to (u, 2)$ with cost $1$ and $(s, 1) \\to (v, 2)$ with cost $3$.\n- Waiting arcs: $(s, 1) \\to (s, 2)$ with cost $2$, $(u, 1) \\to (u, 2)$ with cost $0$, $(v, 1) \\to (v, 2)$ with cost $1$, and $(d, 1) \\to (d, 2)$ with cost $0$.\n\nFor $t = 2$:\n- Movement arcs: $(u, 2) \\to (d, 3)$ with cost $2$, and $(v, 2) \\to (d, 3)$ with cost $5$.\n- Waiting arcs: $(s, 2) \\to (s, 3)$ with cost $3$, $(u, 2) \\to (u, 3)$ with cost $1$, $(v, 2) \\to (v, 3)$ with cost $1$, and $(d, 2) \\to (d, 3)$ with cost $0$.\n\nThere are no outgoing arcs at time $t = 3$. The penalty is modeled as a terminal cost at $(d, 3)$ equal to $M = 4$, while arrival by the deadline incurs zero terminal cost at $(d, 2)$.\n\nStarting from the fundamental Principle of Optimality in dynamic programming (DP), define the backward recursion for the optimal cost-to-go values $V(i, t)$ on the time-expanded network with terminal boundary values $V(d, 2) = 0$ and $V(d, 3) = M$. Execute the backward recursion to compute the optimal value $V(s, 0)$.\n\nThen, formulate the corresponding unit-flow linear programming (LP) model on the time-expanded network by adding a supersink $\\omega$ with arcs $(d, 2) \\to \\omega$ of cost $0$ and $(d, 3) \\to \\omega$ of cost $M$, enforcing one unit of flow from $(s, 0)$ to $\\omega$, and flow conservation at all intermediate node-time pairs. Interpret the backward recursion values $\\{V(i, t)\\}$ as the Lagrange multipliers associated with the flow conservation constraints, and explain how complementary slackness implies equality of reduced costs along arcs used by an optimal path.\n\nFinally, report the minimal total cost $V(s, 0)$ as a single real number. No rounding is required. Express the final answer without units.", "solution": "The problem presented is a deterministic shortest-path problem on a time-expanded network over a finite horizon. It is a well-posed problem in the domain of dynamic programming and network optimization. All necessary data, including the network topology, time-dependent arc costs, and terminal conditions, are provided and are self-consistent. The problem is scientifically grounded and can be solved using the Principle of Optimality.\n\nThe core of the solution lies in applying the backward recursion logic of dynamic programming. Let $V(i, t)$ be the optimal cost-to-go from the state defined by being at node $i \\in \\{s, u, v, d\\}$ at time $t \\in \\{0, 1, 2, 3\\}$. The state transitions occur along arcs from time $t$ to $t+1$. The Principle of Optimality yields the Bellman equation for this problem:\n$$V(i, t) = \\min_{(j, t+1)} \\{ c((i, t), (j, t+1)) + V(j, t+1) \\}$$\nwhere the minimization is over all nodes $j$ reachable from node $i$ in one time step, and $c((i, t), (j, t+1))$ is the cost of traversing the arc from state $(i, t)$ to $(j, t+1)$. The recursion proceeds backward in time from the terminal time $T=3$.\n\nThe terminal conditions are specified. Arrival at the destination node $d$ by the deadline $T_d=2$ incurs a terminal cost of $0$, so $V(d, 2) = 0$. Arrival after the deadline, at $t=3$, incurs a penalty of $M=4$, so $V(d, 3) = 4$. For any path ending at a non-destination node at the final time $T=3$, the cost is effectively infinite as it fails to reach the destination; thus, we set $V(i, 3) = \\infty$ for $i \\in \\{s, u, v\\}$.\n\nWe execute the backward recursion as follows:\n\n**Step 1: Compute values at $t=2$**\nThe backward recursion starts from the pre-terminal time step $t=2$.\nThe terminal cost at $(d,2)$ is given as $V(d,2) = 0$. For the other nodes at $t=2$:\n*   $V(u, 2) = \\min \\{ c((u, 2), (d, 3)) + V(d, 3), c((u, 2), (u, 3)) + V(u, 3) \\} = \\min \\{ 2 + 4, 1 + \\infty \\} = 6$.\n*   $V(v, 2) = \\min \\{ c((v, 2), (d, 3)) + V(d, 3), c((v, 2), (v, 3)) + V(v, 3) \\} = \\min \\{ 5 + 4, 1 + \\infty \\} = 9$.\n*   $V(s, 2) = c((s, 2), (s, 3)) + V(s, 3) = 3 + \\infty = \\infty$.\n\nThe cost-to-go values at $t=2$ are: $V(s, 2) = \\infty$, $V(u, 2) = 6$, $V(v, 2) = 9$, and $V(d, 2) = 0$.\n\n**Step 2: Compute values at $t=1$**\nUsing the values computed for $t=2$, we recurse back to $t=1$.\n*   $V(s, 1) = \\min \\{ c((s, 1), (u, 2)) + V(u, 2), c((s, 1), (v, 2)) + V(v, 2), c((s, 1), (s, 2)) + V(s, 2) \\} = \\min \\{ 1 + 6, 3 + 9, 2 + \\infty \\} = \\min \\{ 7, 12 \\} = 7$.\n*   $V(u, 1) = \\min \\{ c((u, 1), (d, 2)) + V(d, 2), c((u, 1), (v, 2)) + V(v, 2), c((u, 1), (u, 2)) + V(u, 2) \\} = \\min \\{ 4 + 0, 1 + 9, 0 + 6 \\} = \\min \\{ 4, 10, 6 \\} = 4$.\n*   $V(v, 1) = \\min \\{ c((v, 1), (d, 2)) + V(d, 2), c((v, 1), (v, 2)) + V(v, 2) \\} = \\min \\{ 1 + 0, 1 + 9 \\} = \\min \\{ 1, 10 \\} = 1$.\n*   $V(d, 1) = c((d, 1), (d, 2)) + V(d, 2) = 0 + 0 = 0$.\n\nThe cost-to-go values at $t=1$ are: $V(s, 1) = 7$, $V(u, 1) = 4$, $V(v, 1) = 1$, and $V(d, 1) = 0$.\n\n**Step 3: Compute value at $t=0$**\nFinally, we compute the optimal cost from the starting state $(s, 0)$.\n*   $V(s, 0) = \\min \\{ c((s, 0), (u, 1)) + V(u, 1), c((s, 0), (v, 1)) + V(v, 1), c((s, 0), (s, 1)) + V(s, 1) \\} = \\min \\{ 2 + 4, 3 + 1, 1 + 7 \\} = \\min \\{ 6, 4, 8 \\} = 4$.\n\nThe minimal total cost to travel from $(s, 0)$ to the destination node $d$ is $V(s, 0) = 4$.\n\nThe problem also requires formulating the corresponding Linear Programming (LP) model and discussing its duality. Let $x_{uv}$ be the flow on an arc from node $u$ to node $v$ in the full time-expanded network, which includes the supersink $\\omega$. The nodes are pairs $(i, t)$. The problem is to find a path for a single unit of flow from $(s,0)$ to $\\omega$ at minimum cost.\nThe LP formulation is:\n$$ \\text{Minimize} \\quad Z = \\sum_{((i, t), (j, t')) \\in A'} c((i, t), (j, t')) x_{((i, t), (j, t'))} $$\nsubject to:\n1. Flow conservation constraints:\n$$ \\sum_{k} x_{k,v} - \\sum_{k} x_{v,k} = b_v \\quad \\text{for all nodes } v$$\nwhere the supply/demand vector $b$ is defined as $b_{(s,0)} = -1$ (1 unit leaves), $b_{\\omega} = 1$ (1 unit arrives), and $b_v = 0$ for all other nodes $v$. The set of arcs $A'$ includes all given time-dependent arcs plus the arcs to the supersink, $((d, 2), \\omega)$ with cost $0$ and $((d, 3), \\omega)$ with cost $M=4$.\n2. Non-negativity of flows:\n$$ x_{uv} \\ge 0 \\quad \\text{for all arcs } (u,v) \\in A' $$\n\nThe dual of this minimum cost flow problem is formulated by assigning a dual variable, or Lagrange multiplier, $\\lambda(v)$ to the flow conservation constraint of each node $v$. Setting $\\lambda(\\omega)=0$ without loss of generality, the dual problem is:\n$$ \\text{Maximize} \\quad \\lambda(s,0) $$\nsubject to:\n$$ \\lambda(u) - \\lambda(v) \\le c_{uv} \\quad \\text{for all arcs } (u,v) \\in A' $$\nThese constraints can be rewritten as $\\lambda(u) \\le c_{uv} + \\lambda(v)$. For any given node $u=(i,t)$, this becomes:\n$$ \\lambda(i, t) \\le \\min_{(j, t+1)} \\{ c((i, t), (j, t+1)) + \\lambda(j, t+1) \\} $$\nTo maximize $\\lambda(s,0)$, the optimal dual variables $\\lambda^*(i,t)$ must satisfy this relation with equality. This is precisely the Bellman equation. The boundary conditions of the DP, $V(d, 2) = 0$ and $V(d, 3) = 4$, correspond to the dual constraints for the arcs leading to the sink: $\\lambda(d, 2) \\le c((d, 2), \\omega) = 0$ and $\\lambda(d, 3) \\le c((d, 3), \\omega) = 4$, which are satisfied with equality at the optimum. Thus, the optimal cost-to-go values $V(i, t)$ from the backward recursion are the optimal values of the dual variables $\\lambda^*(i,t)$.\n\nComplementary slackness relates the optimal primal solution $x^*$ and optimal dual solution $\\lambda^*$. For any arc $(u,v)$, the condition is $x_{uv}^* (\\lambda^*(u) - \\lambda^*(v) - c_{uv}) = 0$. This implies that if an arc $(u,v)$ is used in the optimal path (i.e., $x_{uv}^* > 0$), then its corresponding dual constraint must be tight: $\\lambda^*(u) - \\lambda^*(v) = c_{uv}$. In optimization terminology, the reduced cost of the arc, $\\bar{c}_{uv} = c_{uv} - (\\lambda^*(u) - \\lambda^*(v))$, must be zero. Substituting $\\lambda^*(i, t) = V(i, t)$, the condition for an arc $((i, t), (j, t+1))$ to be on the optimal path is $V(i, t) = c((i, t), (j, t+1)) + V(j, t+1)$. This confirms that the optimal path is composed of arcs that achieve the minimum at each step of the Bellman recursion.\n\nThe calculation yielded $V(s, 0) = 4$. The optimal path can be traced forward:\n*   From $(s, 0)$, the minimum cost $V(s,0)=4$ is obtained via the arc $(s, 0) \\to (v, 1)$, since $c((s, 0), (v, 1)) + V(v, 1) = 3 + 1 = 4$.\n*   From $(v, 1)$, the minimum cost $V(v,1)=1$ is obtained via the arc $(v, 1) \\to (d, 2)$, since $c((v, 1), (d, 2)) + V(d, 2) = 1 + 0 = 1$.\n\nThe optimal path is $(s, 0) \\to (v, 1) \\to (d, 2)$. The total cost is the sum of arc costs $3 + 1 = 4$, arriving at $t=2$ which meets the deadline.\n\nThe minimal total cost is $V(s, 0)$.", "answer": "$$\n\\boxed{4}\n$$", "id": "3100097"}, {"introduction": "Moving from deterministic to stochastic environments, this practice explores a common operations research problem: inventory management under uncertain demand. Backward recursion is perfectly suited for this, as it handles uncertainty by minimizing *expected* future costs. The exercise demonstrates a powerful aspect of dynamic programming: how analyzing the propagation of function properties, like convexity, can reveal that the optimal strategy has a simple and intuitive $(s,S)$ structure, even in a complex, nonstationary setting [@problem_id:3100123].", "problem": "Consider a finite-horizon periodic-review inventory system with backlogging allowed over a horizon of $T=2$ periods. At the start of each period $t \\in \\{1,2\\}$, the decision-maker observes the on-hand inventory level $x_t \\in \\mathbb{R}$ (negative values represent backlogged demand) and chooses an order quantity $q_t \\ge 0$. Orders arrive immediately before demand is realized. The stochastic demand $D_t$ in each period is independent across periods, with known discrete distributions. The end-of-period inventory evolves according to $x_{t+1} = x_t + q_t - D_t$. The one-period cost incurred in period $t$ is the sum of a fixed ordering cost $K$ (applied if $q_t > 0$), a linear purchasing cost $c q_t$, a linear holding cost $h_t (x_{t+1})^{+}$, and a linear backlogging penalty $b_t (D_t - x_t - q_t)^{+}$. The terminal cost at the end of period $2$ is zero. All parameters satisfy $K > 0$, $c \\ge 0$, $h_t \\ge 0$, and $b_t \\ge 0$.\n\nTask A (derivation from first principles): Starting from the Dynamic Programming (DP) principle and the convexity of expectations, derive conditions on $\\{h_t\\}$, $\\{b_t\\}$, $K$, $c$, and the demand distributions under which the backward recursion yields an optimal $(s_t,S_t)$ structure at each period $t$. Your derivation should begin from the DP recursion and argue why the value functions are convex without fixed cost and become $K$-convex with fixed cost, leading to threshold-order policies. Do not rely on pre-stated theorems; reason from the convexity of the one-period cost and the properties of expectation.\n\nTask B (numerical instance): For a specific nonstationary instance, let $h_1 = 2$, $b_1 = 5$, $h_2 = 4$, $b_2 = 3$, $K = 8$, and $c = 1$. The demands are independent with $D_1 \\in \\{0,1\\}$ having $\\mathbb{P}(D_1 = 0) = 0.5$ and $\\mathbb{P}(D_1 = 1) = 0.5$, and $D_2 \\in \\{0,2\\}$ having $\\mathbb{P}(D_2 = 0) = 0.6$ and $\\mathbb{P}(D_2 = 2) = 0.4$. Using backward recursion and convexity arguments from Task A, determine the optimal order-up-to level $S_2$ and then compute the reorder threshold $s_2$ in the last period. Express the final answer as the numerical value of $s_2$. No rounding is required.", "solution": "The problem is evaluated to be valid as it represents a well-defined, self-contained, and scientifically grounded problem in the field of stochastic optimization and inventory theory. It contains no contradictions, ambiguities, or factual unsoundness.\n\nThe solution is divided into two parts as requested: a theoretical derivation (Task A) and a numerical computation (Task B).\n\n### Task A: Derivation of the $(s_t, S_t)$ Policy Structure\n\nThe problem is to minimize the total expected cost over a finite horizon of $T=2$ periods. We employ backward recursion, a direct application of the Dynamic Programming (DP) principle.\n\nLet $V_t(x_t)$ be the minimum expected cost-to-go from the beginning of period $t$ until the end of the horizon, given the starting inventory level is $x_t$. The state transition is $x_{t+1} = x_t + q_t - D_t$, where $q_t \\ge 0$ is the order quantity and $D_t$ is the random demand. Let $y_t = x_t + q_t$ be the inventory level after ordering (the order-up-to level). The decision is to choose $y_t \\ge x_t$.\n\nThe DP recursion is given by:\n$$ V_t(x_t) = \\min_{y_t \\ge x_t} \\left\\{ K \\cdot \\mathbb{I}(y_t > x_t) + c(y_t - x_t) + \\mathbb{E}_{D_t} \\left[ C_t^{\\text{op}}(y_t, D_t) + V_{t+1}(y_t - D_t) \\right] \\right\\} $$\nfor $t \\in \\{1, 2\\}$, where $\\mathbb{I}(\\cdot)$ is the indicator function. The one-period operational cost is $C_t^{\\text{op}}(y_t, D_t) = h_t (y_t - D_t)^{+} + b_t(D_t - y_t)^{+}$. The terminal value function is $V_3(x_3) = 0$, as the terminal cost is zero.\n\nLet us define the function $J_t(y_t)$ which represents the sum of the purchasing cost and expected operational and future costs, as a function of the order-up-to level $y_t$:\n$$ J_t(y_t) = c y_t + \\mathbb{E}_{D_t} \\left[ C_t^{\\text{op}}(y_t, D_t) + V_{t+1}(y_t - D_t) \\right] $$\nWith this, the DP recursion simplifies to:\n$$ V_t(x_t) = \\min_{y_t \\ge x_t} \\left\\{ K \\cdot \\mathbb{I}(y_t > x_t) + J_t(y_t) \\right\\} - c x_t $$\nThe optimal policy structure for period $t$ is determined by the properties of the function $J_t(y_t)$. We proceed by backward induction.\n\n**Period $t=2$ (Base Case):**\nThe recursion for period $2$ uses the terminal value function $V_3(x_3) = 0$. Since $V_3$ is a constant function, it is convex.\nThe function $J_2(y_2)$ is:\n$$ J_2(y_2) = c y_2 + \\mathbb{E}_{D_2} \\left[ h_2 (y_2 - D_2)^{+} + b_2(D_2 - y_2)^{+} + V_3(y_2 - D_2) \\right] $$\n$$ J_2(y_2) = c y_2 + \\mathbb{E}_{D_2} \\left[ h_2 (y_2 - D_2)^{+} + b_2(D_2 - y_2)^{+} \\right] $$\nFor any realized demand $d$, the function $g(y_2, d) = h_2(y_2 - d)^{+} + b_2(d - y_2)^{+}$ is convex in $y_2$ because it is a sum of two convex functions (since $h_2 \\ge 0$ and $b_2 \\ge 0$). The expectation operator preserves convexity, so $\\mathbb{E}_{D_2}[g(y_2, D_2)]$ is convex in $y_2$. The term $cy_2$ is linear. Therefore, $J_2(y_2)$ is a convex function.\n\nThe decision in period $2$ is to choose $y_2 \\ge x_2$ to minimize the cost.\n- If no order is placed ($q_2=0$, so $y_2=x_2$), the cost is $J_2(x_2) - cx_2$.\n- If an order is placed ($q_2>0$, so $y_2>x_2$), the cost is $K + J_2(y_2) - cx_2$. The best choice of $y_2$ would be the one that minimizes the convex function $J_2(y_2)$. Let this minimizer be $S_2$. The minimum cost when ordering is $K + J_2(S_2) - cx_2$.\n\nThe optimal decision is to order if and only if the cost of ordering to $S_2$ is less than the cost of not ordering:\n$$ K + J_2(S_2) - cx_2  J_2(x_2) - cx_2 \\quad \\iff \\quad J_2(x_2) > K + J_2(S_2) $$\nSince $J_2(y_2)$ is convex and $S_2$ is its minimizer, $J_2(y_2)$ is non-increasing for $y_2  S_2$. We can define a threshold $s_2 \\le S_2$ such that $J_2(s_2) = K + J_2(S_2)$. For any inventory level $x_2  s_2$, we have $J_2(x_2) > J_2(s_2) = K + J_2(S_2)$, so it is optimal to order. The optimal policy is to order up to $S_2$ if $x_2  s_2$, and not to order if $x_2 \\ge s_2$. This is precisely an $(s_2, S_2)$ policy. The only conditions required are $h_2 \\ge 0$ and $b_2 \\ge 0$, which are given.\n\nThe value function for period $2$ can be written as:\n$$ V_2(x_2) = \\begin{cases} K + J_2(S_2) - cx_2  \\text{if } x_2  s_2 \\\\ J_2(x_2) - cx_2  \\text{if } x_2 \\ge s_2 \\end{cases} $$\nThis function is not convex. However, it belongs to a class of functions known as $K$-convex functions, which are critical for the induction to proceed. A function $f(x)$ is $K$-convex if it is composed of a convex function $g(x)$ for $x \\ge s$ and a linear function with slope less than or equal to $g'(s)$ for $x  s$.\n\n**Period $t=1$ (Inductive Step):**\nWe analyze the cost function for period $1$:\n$$ J_1(y_1) = c y_1 + \\mathbb{E}_{D_1} \\left[ h_1 (y_1 - D_1)^{+} + b_1(D_1 - y_1)^{+} + V_2(y_1 - D_1) \\right] $$\nThis can be written as the sum of two terms:\n$$ J_1(y_1) = \\underbrace{\\left( c y_1 + \\mathbb{E}_{D_1} \\left[ C_1^{\\text{op}}(y_1, D_1) \\right] \\right)}_{\\text{Term A}} + \\underbrace{\\mathbb{E}_{D_1} \\left[ V_2(y_1 - D_1) \\right]}_{\\text{Term B}} $$\nTerm A is convex in $y_1$ for the same reasons that $J_2(y_2)$ was convex (i.e., $h_1 \\ge 0, b_1 \\ge 0$).\nTerm B is the expectation of the $K$-convex value function from the next period. A fundamental result in inventory theory, attributable to Scarf (1960), is that the property of $K$-convexity is preserved under expectation and addition of a convex function. That is, if $V_2(x)$ is $K$-convex, then $\\mathbb{E}_{D_1}[V_2(y_1 - D_1)]$ is also $K$-convex (with the same or a different constant $K'$). The sum of a convex function (Term A) and a $K$-convex function (Term B) results in a $K$-convex function.\n\nTherefore, $J_1(y_1)$ is a $K$-convex function. A $K$-convex function, when combined with a fixed cost $K$ in the minimization problem, exhibits a similar structural property to a convex function. There exists an optimal order-up-to level $S_1$ (which minimizes $J_1(y_1)$) and a reorder point $s_1$ (satisfying an equation analogous to $J_1(s_1) = K + J_1(S_1)$) that define the optimal policy. Thus, an $(s_1, S_1)$ policy is also optimal for period $1$.\n\nThe general condition for the optimality of $(s_t, S_t)$ policies in this setting is the non-negativity of the one-period holding and backlogging cost parameters, $h_t \\ge 0$ and $b_t \\ge 0$ for all $t$. These conditions are satisfied by the problem statement.\n\n### Task B: Numerical Computation of $s_2$\n\nWe need to find the reorder threshold $s_2$ for the final period. This requires characterizing the function $J_2(y)$ and finding its minimizer $S_2$. The parameters are $c=1$, $K=8$, $h_2=4$, $b_2=3$. The demand $D_2$ takes values in $\\{0, 2\\}$ with probabilities $\\mathbb{P}(D_2=0)=0.6$ and $\\mathbb{P}(D_2=2)=0.4$.\n\nThe function $J_2(y)$ is:\n$$ J_2(y) = c y + \\mathbb{E}_{D_2} \\left[ h_2 (y - D_2)^{+} + b_2 (D_2 - y)^{+} \\right] $$\n$$ J_2(y) = 1 \\cdot y + \\left[ 4(y-0)^{+} + 3(0-y)^{+} \\right] \\mathbb{P}(D_2=0) + \\left[ 4(y-2)^{+} + 3(2-y)^{+} \\right] \\mathbb{P}(D_2=2) $$\n$$ J_2(y) = y + 0.6 \\left[ 4y^{+} + 3(-y)^{+} \\right] + 0.4 \\left[ 4(y-2)^{+} + 3(2-y)^{+} \\right] $$\nThis is a piecewise linear, convex function. The points where the definition of the function may change are $y=0$ and $y=2$. We analyze $J_2(y)$ in three regions:\n\n1.  For $y  0$: $y^{+} = 0$, $(-y)^{+} = -y$, $(y-2)^{+} = 0$, $(2-y)^{+} = 2-y$.\n    $$ J_2(y) = y + 0.6(3(-y)) + 0.4(3(2-y)) = y - 1.8y + 2.4 - 1.2y = -2y + 2.4 $$\n    The slope in this region is $-2$.\n\n2.  For $0 \\le y  2$: $y^{+} = y$, $(-y)^{+} = 0$, $(y-2)^{+} = 0$, $(2-y)^{+} = 2-y$.\n    $$ J_2(y) = y + 0.6(4y) + 0.4(3(2-y)) = y + 2.4y + 2.4 - 1.2y = 2.2y + 2.4 $$\n    The slope in this region is $2.2$.\n\n3.  For $y \\ge 2$: $y^{+} = y$, $(-y)^{+} = 0$, $(y-2)^{+} = y-2$, $(2-y)^{+} = 0$.\n    $$ J_2(y) = y + 0.6(4y) + 0.4(4(y-2)) = y + 2.4y + 1.6y - 3.2 = 5y - 3.2 $$\n    The slope in this region is $5$.\n\nThe slope of $J_2(y)$ transitions from $-2$ to $2.2$ at $y=0$. Since the slope changes from negative to positive at this point, the global minimum of the convex function $J_2(y)$ occurs at $y=0$. Thus, the optimal order-up-to level is $S_2 = 0$.\n\nThe minimum value of $J_2(y)$ is $J_2(S_2) = J_2(0)$. Using the expression for $0 \\le y  2$:\n$$ J_2(0) = 2.2(0) + 2.4 = 2.4 $$\n\nThe reorder threshold $s_2$ is defined by the equation $J_2(s_2) = K + J_2(S_2)$.\nGiven $K=8$, we have:\n$$ J_2(s_2) = 8 + 2.4 = 10.4 $$\nSince $s_2 \\le S_2 = 0$, we must use the expression for $J_2(y)$ valid for $y  0$:\n$$ J_2(s_2) = -2s_2 + 2.4 $$\nSetting this equal to $10.4$:\n$$ -2s_2 + 2.4 = 10.4 $$\n$$ -2s_2 = 10.4 - 2.4 = 8 $$\n$$ s_2 = \\frac{8}{-2} = -4 $$\nThe reorder threshold for period $2$ is $s_2 = -4$. This means if the inventory level at the start of period $2$ is less than $-4$ (a backlog of more than $4$ units), an order should be placed to bring the inventory level up to $S_2 = 0$. Otherwise, no order is placed.", "answer": "$$\\boxed{-4}$$", "id": "3100123"}, {"introduction": "This final practice extends backward recursion from discrete states to the continuous state-spaces typical of modern control engineering. For the fundamental Linear Quadratic Regulator (LQR) problem, the principle of optimality gives rise to a powerful matrix-based backward iteration known as the discrete-time Riccati equation. This exercise asks you to derive this recursion and apply it to a non-standard scenario, forcing you to verify the underlying conditions for optimality rather than just applying a formula [@problem_id:3100095].", "problem": "Consider the discrete-time, finite-horizon optimal control problem with linear dynamics and quadratic costs. The state evolves according to $x_{t+1}=A x_t + B u_t$, where $x_t \\in \\mathbb{R}^2$, $u_t \\in \\mathbb{R}$, $A=\\mathrm{diag}(1,\\,\\tfrac{1}{2})$, and $B=\\begin{pmatrix}1\\\\ \\tfrac{1}{2}\\end{pmatrix}$. The stage cost is $c_t(x_t,u_t)=\\alpha_t \\|x_t\\|^2 + \\beta_t \\|u_t\\|^2$ with $\\alpha_t \\ge 0$ and $\\beta_t  0$ for all $tT$, and the terminal cost is $x_T^{\\top} Q_T x_T$, where $Q_T$ is symmetric but not necessarily positive semidefinite. The planning horizon is $T=1$. For $t=0$, let $\\alpha_0=0.2$ and $\\beta_0=1.5$, so that $Q_0=\\alpha_0 I_2$ and $R_0=\\beta_0$. Let the terminal cost matrix be $Q_1=\\mathrm{diag}(3,\\,-1)$, which is indefinite.\n\nTasks:\n- Starting from the Bellman optimality principle and the quadratic value function ansatz $V_t(x)=x^{\\top} P_t x$, derive the one-step backward recursion for $P_t$ at a generic time $t$ when $P_{t+1}$ is an arbitrary symmetric matrix (not assumed positive semidefinite). Explicitly state the condition under which the minimizer in the control input exists at each step, and identify how (if at all) the backward recursion changes when $Q_T$ is indefinite but $Q_t \\succeq 0$ for $tT$.\n- Then, for the given data with $T=1$, compute the $(1,1)$ entry of the matrix $P_0$ produced by the backward recursion. Provide the exact value. No rounding is required.\n\nYour final answer must be a single real number equal to the $(1,1)$ entry of $P_0$.", "solution": "The problem is a discrete-time, finite-horizon optimal control problem, specifically a Linear Quadratic Regulator (LQR) problem with a non-standard indefinite terminal cost matrix. The task involves deriving the general backward recursion for the cost-to-go matrix, analyzing the conditions for its validity, and then applying it to the specific parameters given to find a particular matrix entry.\n\nFirst, we validate the problem statement.\nThe givens are:\n- State dynamics: $x_{t+1}=A x_t + B u_t$, where $x_t \\in \\mathbb{R}^2$ and $u_t \\in \\mathbb{R}$.\n- State matrix: $A=\\mathrm{diag}(1,\\,\\tfrac{1}{2}) = \\begin{pmatrix} 1  0 \\\\ 0  \\frac{1}{2} \\end{pmatrix}$.\n- Input matrix: $B=\\begin{pmatrix}1\\\\ \\tfrac{1}{2}\\end{pmatrix}$.\n- Stage cost: $c_t(x_t,u_t)=\\alpha_t \\|x_t\\|^2 + \\beta_t \\|u_t\\|^2 = x_t^\\top Q_t x_t + u_t^\\top R_t u_t$, where $Q_t = \\alpha_t I_2$ and $R_t = \\beta_t$.\n- Cost parameters: $\\alpha_t \\ge 0$, $\\beta_t  0$ for $tT$.\n- Terminal cost: $x_T^{\\top} Q_T x_T$, with $Q_T$ being a symmetric matrix.\n- Value function ansatz: $V_t(x) = x^\\top P_t x$, with $P_t$ symmetric.\n- Horizon: $T=1$.\n- Parameters at $t=0$: $\\alpha_0=0.2$, $\\beta_0=1.5$. Thus, $Q_0=0.2 I_2$ and $R_0=1.5$.\n- Terminal cost matrix: $Q_1=\\mathrm{diag}(3,\\,-1)$.\n\nThe problem is scientifically and mathematically sound. It poses a well-defined question within the established framework of optimal control theory and dynamic programming. The use of an indefinite terminal cost matrix is a non-standard but valid extension of the typical LQR problem, whose implications are part of the question itself. The problem is self-contained, with all necessary data and definitions provided. It is not ill-posed, as it explicitly asks for the conditions under which a solution exists. Therefore, the problem is valid.\n\nWe proceed to the solution.\n\nThe Bellman principle of optimality states that the value function $V_t(x_t)$ at time $t$ and state $x_t$ is the minimum of the current stage cost plus the value function at the next state $x_{t+1}$:\n$$V_t(x_t) = \\min_{u_t} \\left\\{ c_t(x_t, u_t) + V_{t+1}(x_{t+1}) \\right\\}$$\nThe planning horizon is $T=1$, so we have a terminal condition at $t=1$ and one recursive step for $t=0$. The value function at the terminal time $T$ is given by the terminal cost:\n$$V_T(x_T) = x_T^\\top Q_T x_T$$\nUsing the quadratic value function ansatz $V_t(x) = x^\\top P_t x$, we have $P_T = Q_T$.\n\nWe now derive the one-step backward recursion for $P_t$ from $P_{t+1}$ at a generic time $t  T$.\n$$V_t(x_t) = \\min_{u_t} \\left\\{ x_t^\\top Q_t x_t + u_t^\\top R_t u_t + V_{t+1}(A x_t + B u_t) \\right\\}$$\nSubstitute $V_{t+1}(x) = x^\\top P_{t+1} x$:\n$$V_t(x_t) = \\min_{u_t} \\left\\{ x_t^\\top Q_t x_t + u_t^\\top R_t u_t + (A x_t + B u_t)^\\top P_{t+1} (A x_t + B u_t) \\right\\}$$\nLet's expand the term involving $P_{t+1}$. Since $P_{t+1}$ is symmetric ($P_{t+1}^\\top = P_{t+1}$):\n$$(A x_t + B u_t)^\\top P_{t+1} (A x_t + B u_t) = x_t^\\top A^\\top P_{t+1} A x_t + 2 x_t^\\top A^\\top P_{t+1} B u_t + u_t^\\top B^\\top P_{t+1} B u_t$$\nThe expression to be minimized with respect to $u_t$, let's call it $J(u_t)$, is:\n$$J(u_t) = u_t^\\top (R_t + B^\\top P_{t+1} B) u_t + 2(B^\\top P_{t+1} A x_t)^\\top u_t + (\\text{terms not dependent on } u_t)$$\nThis is a quadratic function of $u_t$. For a minimum to exist, the Hessian of $J(u_t)$ with respect to $u_t$ must be positive definite. The Hessian is $2(R_t + B^\\top P_{t+1} B)$. Since $u_t \\in \\mathbb{R}$, this is a scalar. Thus, the condition for a unique minimizer to exist is:\n$$R_t + B^\\top P_{t+1} B > 0$$\nNote that this is a stricter condition than just being non-zero, as a negative value would imply a maximum, not a minimum. Given $\\beta_t  0$, $R_t  0$. If $P_{t+1}$ were positive semidefinite, this condition would be automatically satisfied. However, since $P_{t+1}$ is only symmetric, this condition must be explicitly checked.\n\nAssuming this condition holds, we find the optimal control $u_t^*$ by setting the gradient of $J(u_t)$ with respect to $u_t$ to zero:\n$$\\nabla_{u_t} J(u_t) = 2(R_t + B^\\top P_{t+1} B)u_t + 2 B^\\top P_{t+1} A x_t = 0$$\n$$u_t^* = -(R_t + B^\\top P_{t+1} B)^{-1} (B^\\top P_{t+1} A) x_t$$\nThis is a linear feedback control law, $u_t^* = -K_t x_t$, where $K_t = (R_t + B^\\top P_{t+1} B)^{-1} B^\\top P_{t+1} A$.\n\nSubstituting $u_t^*$ back into the Bellman equation to find $V_t(x_t) = x_t^\\top P_t x_t$:\n$$V_t(x_t) = x_t^\\top Q_t x_t + (u_t^*)^\\top R_t u_t^* + (A x_t + B u_t^*)^\\top P_{t+1} (A x_t + B u_t^*)$$\nAn alternative and more direct path is to substitute $u_t^*$ into the quadratic form of $J(u_t)$. The minimum value of a quadratic $z^\\top H z + 2f^\\top z + c$ (for $H \\succ 0$) is $-f^\\top H^{-1} f + c$. Here, $z=u_t$, $H = R_t + B^\\top P_{t+1} B$, and $f = B^\\top P_{t+1} A x_t$.\nThe minimum value of the $u_t$-dependent terms is:\n$$-(B^\\top P_{t+1} A x_t)^\\top (R_t + B^\\top P_{t+1} B)^{-1} (B^\\top P_{t+1} A x_t) = -x_t^\\top A^\\top P_{t+1} B (R_t + B^\\top P_{t+1} B)^{-1} B^\\top P_{t+1} A x_t$$\nAdding the terms not dependent on $u_t$, we get:\n$$V_t(x_t) = x_t^\\top Q_t x_t + x_t^\\top A^\\top P_{t+1} A x_t - x_t^\\top A^\\top P_{t+1} B (R_t + B^\\top P_{t+1} B)^{-1} B^\\top P_{t+1} A x_t$$\nBy identifying $V_t(x_t) = x_t^\\top P_t x_t$, we obtain the discrete-time Riccati equation for $P_t$:\n$$P_t = Q_t + A^\\top P_{t+1} A - A^\\top P_{t+1} B (R_t + B^\\top P_{t+1} B)^{-1} B^\\top P_{t+1} A$$\nThis recursion formula is valid for any symmetric $P_{t+1}$ as long as the invertibility and positivity condition $R_t + B^\\top P_{t+1} B  0$ is met.\n\nThe fact that $Q_T$ is indefinite and $Q_t \\succeq 0$ for $tT$ does not change the algebraic form of the backward recursion. The recursion remains the Riccati equation derived above. However, its properties change. In the standard LQR problem where all cost matrices ($Q_t, R_t, Q_T$) are positive (semi)definite, it is guaranteed that $P_t \\succeq 0$ for all $t$, and the condition $R_t + B^\\top P_{t+1} B \\succ 0$ is always fulfilled. When $Q_T$ is indefinite, $P_T=Q_T$ is indefinite. Consequently, $P_{T-1}, P_{T-2}, \\dots$ are not guaranteed to be positive semidefinite, and the vital condition $R_t + B^\\top P_{t+1} B  0$ must be explicitly verified at each step of the backward iteration. If this condition fails at any step $t$, a finite optimal control law does not exist from that point backward.\n\nNow, we compute the $(1,1)$ entry of $P_0$ for the given data. Here, $T=1$, so we compute $P_0$ from $P_1 = Q_1$.\nThe specific values are:\n$A = \\begin{pmatrix} 1  0 \\\\ 0  1/2 \\end{pmatrix}$, $B = \\begin{pmatrix} 1 \\\\ 1/2 \\end{pmatrix}$, $Q_0 = \\begin{pmatrix} 0.2  0 \\\\ 0  0.2 \\end{pmatrix} = \\begin{pmatrix} 1/5  0 \\\\ 0  1/5 \\end{pmatrix}$, $R_0 = 1.5 = 3/2$, and $P_1 = Q_1 = \\begin{pmatrix} 3  0 \\\\ 0  -1 \\end{pmatrix}$.\n\nFirst, we check the condition for the minimizer's existence: $R_0 + B^\\top P_1 B  0$.\n$$B^\\top P_1 B = \\begin{pmatrix} 1  1/2 \\end{pmatrix} \\begin{pmatrix} 3  0 \\\\ 0  -1 \\end{pmatrix} \\begin{pmatrix} 1 \\\\ 1/2 \\end{pmatrix} = \\begin{pmatrix} 3  -1/2 \\end{pmatrix} \\begin{pmatrix} 1 \\\\ 1/2 \\end{pmatrix} = (3)(1) + (-1/2)(1/2) = 3 - \\frac{1}{4} = \\frac{11}{4}$$\n$$R_0 + B^\\top P_1 B = \\frac{3}{2} + \\frac{11}{4} = \\frac{6}{4} + \\frac{11}{4} = \\frac{17}{4}$$\nSince $\\frac{17}{4}  0$, the condition is satisfied. The inverse is $(R_0 + B^\\top P_1 B)^{-1} = \\frac{4}{17}$.\n\nNext, we compute the components of the Riccati equation for $P_0$:\n$$P_0 = Q_0 + A^\\top P_1 A - (A^\\top P_1 B) (R_0 + B^\\top P_1 B)^{-1} (B^\\top P_1 A)$$\n1. Compute $A^\\top P_1 A$:\n$$A^\\top P_1 A = \\begin{pmatrix} 1  0 \\\\ 0  1/2 \\end{pmatrix} \\begin{pmatrix} 3  0 \\\\ 0  -1 \\end{pmatrix} \\begin{pmatrix} 1  0 \\\\ 0  1/2 \\end{pmatrix} = \\begin{pmatrix} 1  0 \\\\ 0  1/2 \\end{pmatrix} \\begin{pmatrix} 3  0 \\\\ 0  -1/2 \\end{pmatrix} = \\begin{pmatrix} 3  0 \\\\ 0  -1/4 \\end{pmatrix}$$\n2. Compute $A^\\top P_1 B$:\n$$A^\\top P_1 B = \\begin{pmatrix} 1  0 \\\\ 0  1/2 \\end{pmatrix} \\begin{pmatrix} 3  0 \\\\ 0  -1 \\end{pmatrix} \\begin{pmatrix} 1 \\\\ 1/2 \\end{pmatrix} = \\begin{pmatrix} 3  0 \\\\ 0  -1/2 \\end{pmatrix} \\begin{pmatrix} 1 \\\\ 1/2 \\end{pmatrix} = \\begin{pmatrix} 3 \\\\ -1/4 \\end{pmatrix}$$\n3. Compute the subtractive term $(A^\\top P_1 B) (R_0 + B^\\top P_1 B)^{-1} (A^\\top P_1 B)^\\top$:\n$$\\begin{pmatrix} 3 \\\\ -1/4 \\end{pmatrix} \\left(\\frac{4}{17}\\right) \\begin{pmatrix} 3  -1/4 \\end{pmatrix} = \\frac{4}{17} \\begin{pmatrix} (3)(3)  (3)(-1/4) \\\\ (-1/4)(3)  (-1/4)(-1/4) \\end{pmatrix} = \\frac{4}{17} \\begin{pmatrix} 9  -3/4 \\\\ -3/4  1/16 \\end{pmatrix} = \\begin{pmatrix} 36/17  -3/17 \\\\ -3/17  1/17 \\end{pmatrix}$$\n4. Assemble $P_0$:\n$$P_0 = \\begin{pmatrix} 1/5  0 \\\\ 0  1/5 \\end{pmatrix} + \\begin{pmatrix} 3  0 \\\\ 0  -1/4 \\end{pmatrix} - \\begin{pmatrix} 36/17  -3/17 \\\\ -3/17  1/17 \\end{pmatrix}$$\nWe are asked to find the $(1,1)$ entry of $P_0$, denoted $(P_0)_{11}$:\n$$(P_0)_{11} = \\frac{1}{5} + 3 - \\frac{36}{17}$$\nCombining the terms:\n$$(P_0)_{11} = \\frac{16}{5} - \\frac{36}{17}$$\nTo subtract the fractions, we find a common denominator, which is $5 \\times 17 = 85$.\n$$(P_0)_{11} = \\frac{16 \\times 17}{85} - \\frac{36 \\times 5}{85} = \\frac{272}{85} - \\frac{180}{85} = \\frac{272 - 180}{85} = \\frac{92}{85}$$\nThe exact value of the $(1,1)$ entry of $P_0$ is $\\frac{92}{85}$.", "answer": "$$\\boxed{\\frac{92}{85}}$$", "id": "3100095"}]}