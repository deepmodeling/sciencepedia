{"hands_on_practices": [{"introduction": "Particle Swarm Optimization (PSO) is a powerful derivative-free method inspired by the collective behavior of animal swarms, like flocks of birds or schools of fish. The algorithm's core lies in its velocity update rule, which guides each 'particle' through the search space by balancing its current momentum, its own best-discovered position, and the best position found by the entire swarm. This exercise will give you direct practice in applying this fundamental equation, which is the engine driving the PSO search process. [@problem_id:2166499]", "problem": "An autonomous drone is part of a swarm searching for the location of a maximum intensity radio signal in a large, open field, which is modeled as a 2D Cartesian plane. The search is guided by the Particle Swarm Optimization (PSO) algorithm. At each time step, every drone updates its velocity based on its current velocity, its own best-found position, and the best-found position by any drone in the entire swarm.\n\nThe velocity update for a single particle (drone) at time step $t+1$ is given by the equation:\n$$ \\vec{v}(t+1) = \\omega \\vec{v}(t) + c_1 r_1 (\\vec{p} - \\vec{x}(t)) + c_2 r_2 (\\vec{g} - \\vec{x}(t)) $$\nwhere:\n- $\\vec{v}(t)$ is the drone's current velocity vector.\n- $\\vec{x}(t)$ is the drone's current position vector.\n- $\\vec{p}$ is the drone's personal best position found so far.\n- $\\vec{g}$ is the global best position found by the entire swarm so far.\n- $\\omega$ is the inertia weight, controlling the influence of the previous velocity.\n- $c_1$ and $c_2$ are the cognitive and social coefficients, respectively, which weight the influence of the personal and global best positions.\n- $r_1$ and $r_2$ are random numbers uniformly distributed in $[0, 1]$.\n\nConsider a specific drone at a particular time step $t$. The state of this drone and the swarm parameters are given as follows:\n- Current position: $\\vec{x}(t) = \\begin{pmatrix} 8.0 & 14.0 \\end{pmatrix}$\n- Current velocity: $\\vec{v}(t) = \\begin{pmatrix} -1.0 & 2.0 \\end{pmatrix}$\n- Personal best position: $\\vec{p} = \\begin{pmatrix} 10.0 & 12.0 \\end{pmatrix}$\n- Global best position: $\\vec{g} = \\begin{pmatrix} 11.0 & 10.0 \\end{pmatrix}$\n- Inertia weight: $\\omega = 0.7$\n- Cognitive coefficient: $c_1 = 1.5$\n- Social coefficient: $c_2 = 1.5$\nFor this specific update step, the generated random numbers are $r_1 = 0.4$ and $r_2 = 0.9$.\n\nCalculate the drone's new velocity vector, $\\vec{v}(t+1)$. All positions are given in meters and velocities in meters per second (m/s). Express your answer as a 2-element row matrix $[v_x, v_y]$ in m/s. Round each component of the vector to three significant figures.", "solution": "We apply the PSO velocity update rule\n$$\\vec{v}(t+1)=\\omega \\vec{v}(t)+c_{1}r_{1}\\left(\\vec{p}-\\vec{x}(t)\\right)+c_{2}r_{2}\\left(\\vec{g}-\\vec{x}(t)\\right).$$\nCompute the displacement vectors:\n$$\\vec{p}-\\vec{x}(t)=\\begin{pmatrix}10.0-8.0 \\\\ 12.0-14.0\\end{pmatrix}=\\begin{pmatrix}2 \\\\ -2\\end{pmatrix},\\quad \\vec{g}-\\vec{x}(t)=\\begin{pmatrix}11.0-8.0 \\\\ 10.0-14.0\\end{pmatrix}=\\begin{pmatrix}3 \\\\ -4\\end{pmatrix}.$$\nCompute each term:\n$$\\omega \\vec{v}(t)=0.7\\begin{pmatrix}-1.0 \\\\ 2.0\\end{pmatrix}=\\begin{pmatrix}-0.7 \\\\ 1.4\\end{pmatrix},$$\n$$c_{1}r_{1}\\left(\\vec{p}-\\vec{x}(t)\\right)=1.5\\cdot 0.4\\begin{pmatrix}2 \\\\ -2\\end{pmatrix}=0.6\\begin{pmatrix}2 \\\\ -2\\end{pmatrix}=\\begin{pmatrix}1.2 \\\\ -1.2\\end{pmatrix},$$\n$$c_{2}r_{2}\\left(\\vec{g}-\\vec{x}(t)\\right)=1.5\\cdot 0.9\\begin{pmatrix}3 \\\\ -4\\end{pmatrix}=1.35\\begin{pmatrix}3 \\\\ -4\\end{pmatrix}=\\begin{pmatrix}4.05 \\\\ -5.4\\end{pmatrix}.$$\nSum the contributions to obtain\n$$\\vec{v}(t+1)=\\begin{pmatrix}-0.7 \\\\ 1.4\\end{pmatrix}+\\begin{pmatrix}1.2 \\\\ -1.2\\end{pmatrix}+\\begin{pmatrix}4.05 \\\\ -5.4\\end{pmatrix}=\\begin{pmatrix}4.55 \\\\ -5.2\\end{pmatrix}.$$\nRounding each component to three significant figures gives\n$$\\vec{v}(t+1)=\\begin{pmatrix}4.55 \\\\ -5.20\\end{pmatrix}.$$\nExpressed as a row matrix, this is $\\begin{pmatrix}4.55 & -5.20\\end{pmatrix}$ in meters per second.", "answer": "$$\\boxed{\\begin{pmatrix}4.55 & -5.20\\end{pmatrix}}$$", "id": "2166499"}, {"introduction": "Pattern Search methods are a class of direct search algorithms that systematically explore the area around a current point without using any derivative information. A crucial element of their success is the adaptive step-size mechanism, which allows the algorithm to take large steps when making progress and smaller, more refined steps when searching a promising region. This practice focuses on tracking how the step size, $\\Delta$, evolves based on a sequence of successful and unsuccessful iterations, a key behavior that governs the algorithm's balance between exploration and exploitation. [@problem_id:2166475]", "problem": "An engineer is using a Pattern Search (PS) algorithm to optimize a system's performance, which is dependent on two parameters. The goal is to find the parameter values that minimize a cost function $f(x, y)$. The PS algorithm is an iterative, derivative-free method that adjusts a step size, $\\Delta$, based on the outcome of each iteration.\n\nThe step-size update rule for this particular implementation is defined as follows:\n- At the start of iteration $k$, the algorithm possesses a step size $\\Delta_k$.\n- If the iteration is **successful**, meaning a new set of parameters with a lower cost function value is found, the step size for the next iteration, $\\Delta_{k+1}$, remains the same: $\\Delta_{k+1} = \\Delta_k$.\n- If the iteration is **unsuccessful**, meaning no better parameter set is found after exploring the vicinity of the current best point, the step size is reduced for the next iteration using a contraction factor $\\theta$: $\\Delta_{k+1} = \\theta \\Delta_k$.\n\nThe optimization process begins with an initial step size of $\\Delta_0 = 1.00$. The contraction factor is given as $\\theta = 0.400$. The algorithm runs for five full iterations, with the outcomes recorded in sequence as: Success, Fail, Success, Fail, Fail.\n\nCalculate the value of the step size, denoted as $\\Delta_5$, after the completion of the fifth iteration. Provide your answer as a numerical value, rounded to three significant figures.", "solution": "We use the given step-size update rule: at the start of iteration $k$ the step size is $\\Delta_{k}$. After iteration $k$, if the iteration is successful, $\\Delta_{k+1} = \\Delta_{k}$; if it fails, $\\Delta_{k+1} = \\theta \\Delta_{k}$.\n\nWith initial $\\Delta_{0} = 1.00$ and contraction factor $\\theta = 0.400$, and the five outcomes in order: Success, Fail, Success, Fail, Fail, we update as follows (indexing iterations as $k=0,1,2,3,4$ to match $\\Delta_{0}$ being the initial step size):\n\nIteration $k=0$ (Success): \n$$\\Delta_{1} = \\Delta_{0}.$$\n\nIteration $k=1$ (Fail): \n$$\\Delta_{2} = \\theta \\Delta_{1}.$$\n\nIteration $k=2$ (Success): \n$$\\Delta_{3} = \\Delta_{2} = \\theta \\Delta_{1}.$$\n\nIteration $k=3$ (Fail): \n$$\\Delta_{4} = \\theta \\Delta_{3} = \\theta^{2} \\Delta_{1}.$$\n\nIteration $k=4$ (Fail): \n$$\\Delta_{5} = \\theta \\Delta_{4} = \\theta^{3} \\Delta_{1}.$$\n\nSince $\\Delta_{1} = \\Delta_{0}$, we have \n$$\\Delta_{5} = \\theta^{3} \\Delta_{0}.$$\n\nSubstituting the given numerical values and rounding to three significant figures,\n$$\\Delta_{5} = (0.400)^{3} \\times 1.00 = 0.0640.$$", "answer": "$$\\boxed{0.0640}$$", "id": "2166475"}, {"introduction": "The Nelder-Mead algorithm uses a geometric object called a simplex to crawl through the parameter space in search of an optimum. While elegant and often effective, it is important to understand its potential failure modes to use it robustly. This problem explores one such critical issue, simplex degeneracy, where the vertices of the simplex become collinear and can no longer effectively explore the multi-dimensional space, stalling the algorithm's progress. [@problem_id:2166485]", "problem": "The Nelder-Mead algorithm is a widely used derivative-free optimization method for finding the minimum of a function $f(\\mathbf{x})$ in an $n$-dimensional space. In a 2D space ($n=2$), the algorithm maintains a simplex, which is a triangle defined by three vertices: $\\mathbf{x}_1, \\mathbf{x}_2, \\mathbf{x}_3$. At each iteration, the algorithm attempts to improve the simplex by replacing the vertex with the highest (worst) function value, $\\mathbf{x}_h$, with a new, better point.\n\nThe first step in this process is reflection. The algorithm calculates the centroid, $\\mathbf{x}_c$, of all vertices *except* for the worst one, $\\mathbf{x}_h$. It then computes a reflected point, $\\mathbf{x}_r$, using the formula $\\mathbf{x}_r = \\mathbf{x}_c + \\alpha(\\mathbf{x}_c - \\mathbf{x}_h)$, where $\\alpha$ is a positive reflection coefficient, typically set to $\\alpha=1$.\n\nConsider a scenario where a 2D Nelder-Mead optimization routine is initiated with the following three vertices and their corresponding function values:\n- Vertex $\\mathbf{x}_1 = (2, 3)$ with function value $f(\\mathbf{x}_1) = 8$.\n- Vertex $\\mathbf{x}_2 = (6, 9)$ with function value $f(\\mathbf{x}_2) = 20$.\n- Vertex $\\mathbf{x}_3 = (-2, -3)$ with function value $f(\\mathbf{x}_3) = 4$.\n\nThe algorithm uses a standard reflection coefficient of $\\alpha = 1$. A critical failure mode for the Nelder-Mead method is \"simplex degeneracy,\" which occurs when the vertices of the simplex become collinear (i.e., they all lie on a single straight line). Given the initial state described, what is the most direct and immediate consequence of the simplex being degenerate on the first reflection step?\n\nA. The centroid of the non-worst points, $\\mathbf{x}_c$, will be identical to the best vertex.\n\nB. The reflected point, $\\mathbf{x}_r$, cannot be computed because it involves division by zero.\n\nC. The reflected point, $\\mathbf{x}_r$, will be identical to the worst vertex, $\\mathbf{x}_h$, causing the algorithm to enter an infinite loop without changing the simplex.\n\nD. The new simplex, formed by replacing the worst vertex with the reflected point, will also have its vertices lying on the same line as the original degenerate simplex.\n\nE. The reflected point, $\\mathbf{x}_r$, will be located at the origin $(0, 0)$.", "solution": "The Nelder-Mead reflection step in two dimensions replaces the worst vertex $\\mathbf{x}_{h}$ by the reflected point\n$$\n\\mathbf{x}_{r}=\\mathbf{x}_{c}+\\alpha\\left(\\mathbf{x}_{c}-\\mathbf{x}_{h}\\right),\n$$\nwhere $\\mathbf{x}_{c}$ is the centroid of the two non-worst vertices and $\\alpha>0$ (here $\\alpha=1$). The centroid is the arithmetic mean of the two retained vertices:\n$$\n\\mathbf{x}_{c}=\\frac{\\mathbf{x}_{i}+\\mathbf{x}_{j}}{2},\n$$\nwhere $\\{\\mathbf{x}_{i},\\mathbf{x}_{j}\\}=\\{\\mathbf{x}_{1},\\mathbf{x}_{2},\\mathbf{x}_{3}\\}\\setminus\\{\\mathbf{x}_{h}\\}$.\n\nA simplex is degenerate in 2D if its three vertices are collinear. If $\\mathbf{x}_{1},\\mathbf{x}_{2},\\mathbf{x}_{3}$ are collinear, there exists a nonzero vector $\\mathbf{v}$ and scalars $p_{1},p_{2},p_{3}$ such that $\\mathbf{x}_{k}=p_{k}\\mathbf{v}$ for $k\\in\\{1,2,3\\}$. Without loss of generality, let $\\mathbf{x}_{h}=p_{h}\\mathbf{v}$ be the worst vertex and the two non-worst vertices be $\\mathbf{x}_{i}=p_{i}\\mathbf{v}$ and $\\mathbf{x}_{j}=p_{j}\\mathbf{v}$. Then the centroid is\n$$\n\\mathbf{x}_{c}=\\frac{\\mathbf{x}_{i}+\\mathbf{x}_{j}}{2}=\\frac{p_{i}+p_{j}}{2}\\,\\mathbf{v},\n$$\nwhich lies on the same line spanned by $\\mathbf{v}$. The reflected point with $\\alpha=1$ is\n$$\n\\mathbf{x}_{r}=\\mathbf{x}_{c}+(\\mathbf{x}_{c}-\\mathbf{x}_{h})=2\\mathbf{x}_{c}-\\mathbf{x}_{h}=\\left(p_{i}+p_{j}-p_{h}\\right)\\mathbf{v},\n$$\nwhich also lies on the same line spanned by $\\mathbf{v}$. Therefore, replacing $\\mathbf{x}_{h}$ with $\\mathbf{x}_{r}$ yields a new simplex whose three vertices remain collinear, so the degeneracy persists after the reflection step.\n\nApplying this to the given data confirms the general conclusion. The function values are $f(\\mathbf{x}_{2})=20$ (worst), $f(\\mathbf{x}_{1})=8$, and $f(\\mathbf{x}_{3})=4$ (best), so $\\mathbf{x}_{h}=\\mathbf{x}_{2}=(6,9)$ and the non-worst vertices are $\\mathbf{x}_{1}=(2,3)$ and $\\mathbf{x}_{3}=(-2,-3)$. The three vertices are collinear since each is a scalar multiple of $\\mathbf{v}=(2,3)$, namely $\\mathbf{x}_{1}=1\\cdot\\mathbf{v}$, $\\mathbf{x}_{2}=3\\cdot\\mathbf{v}$, and $\\mathbf{x}_{3}=-1\\cdot\\mathbf{v}$. The centroid is\n$$\n\\mathbf{x}_{c}=\\frac{\\mathbf{x}_{1}+\\mathbf{x}_{3}}{2}=\\frac{(2,3)+(-2,-3)}{2}=(0,0),\n$$\nand the reflected point is\n$$\n\\mathbf{x}_{r}=2\\mathbf{x}_{c}-\\mathbf{x}_{h}=(0,0)-(6,9)=(-6,-9)=-3\\cdot\\mathbf{v},\n$$\nwhich lies on the same line. Hence the new simplex $\\{\\mathbf{x}_{1},\\mathbf{x}_{3},\\mathbf{x}_{r}\\}$ is still collinear.\n\nThus, the most direct and immediate consequence of degeneracy at the reflection step is that the new simplex remains degenerate, i.e., all vertices lie on the same line. This corresponds to option D, while:\n- A is false in general and false here since $\\mathbf{x}_{c}=(0,0)\\neq\\mathbf{x}_{3}=(-2,-3)$.\n- B is false because the reflection uses no division.\n- C is not generally implied by degeneracy; it would require $\\mathbf{x}_{c}=\\mathbfx_{h}$, which does not hold here.\n- E is false; here $\\mathbf{x}_{c}$ is at the origin, not $\\mathbf{x}_{r}$.", "answer": "$$\\boxed{D}$$", "id": "2166485"}]}