{"hands_on_practices": [{"introduction": "The journey to mastering game theory begins with its most fundamental building block: the $2 \\times 2$ game. This exercise guides you through the derivation of a general solution for any such game, using the powerful indifference principle. By working through this problem [@problem_id:3199092], you will develop the core algebraic skills needed to find mixed-strategy Nash equilibria from first principles, a foundational technique in the analysis of strategic conflict.", "problem": "Consider a zero-sum matrix game with a row player (the maximizer) and a column player (the minimizer). The row player’s payoff matrix is\n$$\nA=\\begin{pmatrix}\na & b\\\\\nc & d\n\\end{pmatrix},\n$$\nwhere $a,b,c,d \\in \\mathbb{R}$. Let the row player mix between the first and second row with probabilities $x=(p,1-p)$ and the column player mix between the first and second column with probabilities $y=(q,1-q)$, where $p,q \\in [0,1]$. The value of the game is the equilibrium payoff $v$ to the row player. Starting only from the definitions of expected payoff, best response, and the Minimax Theorem (which asserts the equality of the maximin and minimax values in finite zero-sum games), derive explicit closed-form expressions for the equilibrium mixture $x^\\star=(p^\\star,1-p^\\star)$, the equilibrium mixture $y^\\star=(q^\\star,1-q^\\star)$, and the value $v$ in the generic case in which both players mix strictly (that is, no pure strategy dominates for either player and there is no pure-strategy saddle point). Express your answer in terms of $a,b,c,d$.\n\nThen, analyze the edge cases in which strict mixing fails. Your analysis should identify:\n- When a player has a strictly dominant pure strategy and how this determines $(x^\\star,y^\\star,v)$.\n- When a pure-strategy saddle point exists and how to read $(x^\\star,y^\\star,v)$ directly from $A$.\n- What happens in the degenerate case where $a-b-c+d=0$ and how this interacts with the previous two items, including the fully degenerate subcase $a=b=c=d$.\n\nYou must present the generic mixed-strategy formulas in closed form. Do not assume any numerical values and do not round. Your final reported answer should be the ordered triple consisting of $p^\\star$, $q^\\star$, and $v$, written purely in terms of $a,b,c,d$ for the generic strictly mixed case.", "solution": "The problem requires the derivation of the equilibrium strategies and the value of a general $2 \\times 2$ zero-sum game, followed by an analysis of special cases.\n\nLet the row player's strategy be the probability distribution $x=(p, 1-p)$ over the two rows, and the column player's strategy be the probability distribution $y=(q, 1-q)$ over the two columns, with $p, q \\in [0,1]$. The payoff matrix for the row player is given by\n$$\nA=\\begin{pmatrix}\na & b\\\\\nc & d\n\\end{pmatrix}\n$$\nThe expected payoff $E$ to the row player is a function of the players' strategies:\n$$\nE(x,y) = x A y^T = \\begin{pmatrix} p & 1-p \\end{pmatrix} \\begin{pmatrix} a & b \\\\ c & d \\end{pmatrix} \\begin{pmatrix} q \\\\ 1-q \\end{pmatrix}\n$$\nExpanding this expression gives the expected payoff $E(p,q)$:\n$$\nE(p,q) = p(aq + b(1-q)) + (1-p)(cq + d(1-q))\n$$\n$$\nE(p,q) = paq + pb - pbq + cq + d - dq - pcq - pd + pdq\n$$\n$$\nE(p,q) = pq(a-b-c+d) + p(b-d) + q(c-d) + d\n$$\n\nThe Minimax Theorem for finite zero-sum games guarantees the existence of a Nash equilibrium in mixed strategies, and that the value of the game $v$ is unique. An equilibrium is a pair of strategies $(x^\\star, y^\\star)$ such that neither player has an incentive to unilaterally deviate.\n\n**1. Generic Case: Strictly Mixed Strategy Equilibrium**\n\nWe first analyze the generic case where the equilibrium strategies $x^\\star=(p^\\star, 1-p^\\star)$ and $y^\\star=(q^\\star, 1-q^\\star)$ are strictly mixed, meaning $p^\\star \\in (0,1)$ and $q^\\star \\in (0,1)$. For a player to be willing to mix their pure strategies, they must be indifferent between them, given the opponent's equilibrium strategy. This is known as the indifference principle.\n\nRow Player's Indifference: For the row player to be willing to mix between row $1$ and row $2$, the expected payoff from each must be equal when the column player uses strategy $y^\\star=(q^\\star, 1-q^\\star)$.\n- Expected payoff for Row $1$: $a q^\\star + b(1-q^\\star)$\n- Expected payoff for Row $2$: $c q^\\star + d(1-q^\\star)$\n\nSetting these equal gives the condition for the row player's indifference:\n$$\na q^\\star + b(1-q^\\star) = c q^\\star + d(1-q^\\star)\n$$\n$$\nq^\\star(a-b) + b = q^\\star(c-d) + d\n$$\n$$\nq^\\star(a-b-c+d) = d-b\n$$\nAssuming the denominator is non-zero, we can solve for $q^\\star$:\n$$\nq^\\star = \\frac{d-b}{a-b-c+d}\n$$\nThis equilibrium payoff, which is the same for both of the row player's pure strategies, is the value of the game, $v$.\n\nColumn Player's Indifference: Similarly, for the column player to be willing to mix, the expected payoff to the row player (which the column player seeks to minimize) must be the same for both column choices, given the row player's strategy $x^\\star=(p^\\star, 1-p^\\star)$.\n- Expected payoff for Column $1$: $a p^\\star + c(1-p^\\star)$\n- Expected payoff for Column $2$: $b p^\\star + d(1-p^\\star)$\n\nSetting these equal gives the condition for the column player's indifference:\n$$\na p^\\star + c(1-p^\\star) = b p^\\star + d(1-p^\\star)\n$$\n$$\np^\\star(a-c) + c = p^\\star(b-d) + d\n$$\n$$\np^\\star(a-c-b+d) = d-c\n$$\nSolving for $p^\\star$:\n$$\np^\\star = \\frac{d-c}{a-b-c+d}\n$$\nThis common payoff is also the value of the game, $v$.\n\nValue of the Game, $v$: We can calculate $v$ by substituting the equilibrium strategy of one player into the payoff expression for the other. Using the expression for the row player's payoff against $q^\\star$:\n$$\nv = a q^\\star + b(1-q^\\star) = a \\left( \\frac{d-b}{a-b-c+d} \\right) + b \\left( 1 - \\frac{d-b}{a-b-c+d} \\right)\n$$\n$$\nv = \\frac{a(d-b)}{a-b-c+d} + \\frac{b(a-b-c+d - (d-b))}{a-b-c+d}\n$$\n$$\nv = \\frac{ad-ab}{a-b-c+d} + \\frac{b(a-c)}{a-b-c+d} = \\frac{ad-ab+ab-bc}{a-b-c+d}\n$$\n$$\nv = \\frac{ad-bc}{a-b-c+d}\n$$\nThis provides the complete solution for the generic case where a strictly mixed equilibrium exists. This case occurs when neither player has a dominant strategy and no pure-strategy saddle point exists, which corresponds to conditions on $a,b,c,d$ such that $p^\\star \\in (0,1)$ and $q^\\star \\in (0,1)$.\n\n**2. Analysis of Edge Cases**\n\nThe formulas above are valid only if $a-b-c+d \\neq 0$ and the resulting probabilities are in the interval $(0,1)$. We now analyze the cases where these conditions fail.\n\n**Dominant Pure Strategies**\nA pure strategy strictly dominates another if it yields a better payoff for every possible strategy of the opponent.\n\n- If the row player has a strictly dominant strategy, e.g., Row $1$ dominates Row $2$ ($a>c$ and $b>d$), the row player will always choose Row $1$. The equilibrium strategy is $x^\\star = (1,0)$, so $p^\\star=1$. The column player, knowing this, will choose the column that minimizes the row player's payoff. The payoff will be $\\min(a,b)$. So $y^\\star$ will be $(1,0)$ if $a<b$ or $(0,1)$ if $b<a$. The value of the game is $v = \\min(a,b)$.\n- Symmetrically, if Row $2$ dominates Row $1$ ($c>a$ and $d>b$), then $x^\\star=(0,1)$ ($p^\\star=0$) and $v = \\min(c,d)$.\n\n- If the column player has a strictly dominant strategy, e.g., Column $1$ dominates Column $2$ ($a<b$ and $c<d$, meaning payoffs are smaller for the row player), the column player will always choose Column $1$. The equilibrium strategy is $y^\\star = (1,0)$, so $q^\\star=1$. The row player, knowing this, will choose the row that maximizes their payoff. The payoff will be $\\max(a,c)$. The equilibrium strategy is $x^\\star=(1,0)$ if $a>c$ or $(0,1)$ if $c>a$. The value is $v=\\max(a,c)$.\n- Symmetrically, if Column $2$ dominates Column $1$ ($b<a$ and $d<c$), then $y^\\star=(0,1)$ ($q^\\star=0$) and $v=\\max(b,d)$.\n\n**Pure-Strategy Saddle Points**\nA pure-strategy equilibrium, or saddle point, exists if an entry $A_{ij}$ is simultaneously the minimum of its row and the maximum of its column. This occurs if $\\max_i \\min_j A_{ij} = \\min_j \\max_i A_{ij}$. In this case, the equilibrium is for both players to play the pure strategies corresponding to the saddle point's location.\n\n- $A_{11}=a$ is a saddle point if $a \\le b$ and $a \\ge c$. Then $x^\\star=(1,0)$, $y^\\star=(1,0)$, so $(p^\\star,q^\\star)=(1,1)$, and $v=a$.\n- $A_{12}=b$ is a saddle point if $b \\le a$ and $b \\ge d$. Then $x^\\star=(1,0)$, $y^\\star=(0,1)$, so $(p^\\star,q^\\star)=(1,0)$, and $v=b$.\n- $A_{21}=c$ is a saddle point if $c \\le d$ and $c \\ge a$. Then $x^\\star=(0,1)$, $y^\\star=(1,0)$, so $(p^\\star,q^\\star)=(0,1)$, and $v=c$.\n- $A_{22}=d$ is a saddle point if $d \\le c$ and $d \\ge b$. Then $x^\\star=(0,1)$, $y^\\star=(0,1)$, so $(p^\\star,q^\\star)=(0,0)$, and $v=d$.\n\nExistence of a saddle point or a dominant strategy precludes a strictly mixed strategy equilibrium.\n\n**The Degenerate Case: $a-b-c+d=0$**\nWhen the denominator of the mixed-strategy formulas is zero, the indifference principle gives further constraints. The condition $a-b-c+d=0$ can be rewritten as $a-c=b-d$. This means the row player's gain from choosing Row $1$ over Row $2$ is the same regardless of what the column player does.\n- If $a-c=b-d > 0$, then Row $1$ weakly dominates Row $2$.\n- If $a-c=b-d < 0$, then Row $2$ weakly dominates Row $1$.\n- If $a-c=b-d = 0$, then $a=c$ and $b=d$, so the two rows are identical.\n\nIn this degenerate case, at least one player will have a weakly dominant strategy (or be fully indifferent between their strategies). The equilibrium will not be strictly mixed. Often one player plays a pure strategy, and the other player best responds, possibly with a range of optimal strategies.\n- For example, if $a-c=b-d>0$, Row $1$ weakly dominates Row $2$. A rational row player will play $p^\\star=1$. The column player then chooses a column to minimize the payoff, so $v=\\min(a,b)$. The equilibrium strategy $y^\\star$ is a pure strategy corresponding to that minimum. This outcome is consistent with either dominance or a saddle point. For instance, if we have $a=4, c=2, b=3, d=1$, then $a-b-c+d = 4-3-2+1=0$. Here, $a-c = 2$ and $b-d=2$, so Row $1$ weakly dominates Row $2$. The row player chooses $p^\\star=1$. The column player faces payoffs $(4,3)$ and chooses the minimum, $3$. So $y^\\star=(0,1)$ ($q^\\star=0$), and $v=3$. In this case, $d=1 \\le b=3 \\le a=4$, which means $b$ is a saddle point if we consider the reduced game on Row 1. More generally, we can have a line of equilibria.\n- The condition $a-b-c+d = 0$ is also equivalent to $a-b=c-d$, which implies weak dominance for the column player.\n- **Interaction**: If a strictly dominant strategy exists (e.g., $a>c$ and $b>d$), then $a-c>0$ and $b-d>0$. If we also have $a-b-c+d=0$, then $a-c=b-d$. This is a case of strict dominance that also satisfies the degeneracy condition. The strict dominance logic takes precedence, yielding a unique pure strategy equilibrium as described before. A similar argument holds for saddle points. The existence of dominance or a saddle point resolves the ambiguity of the degenerate case into a pure strategy solution.\n- **Fully Degenerate Subcase $a=b=c=d$**: In this subcase, the payoff is a constant $k$. The condition $a-b-c+d=k-k-k+k=0$ holds. The value of the game is trivially $v=k$. Both players are completely indifferent about their choices. Any strategy profile $(x,y)$ constitutes a Nash equilibrium. Thus, $p^\\star$ and $q^\\star$ can be any value in $[0,1]$.", "answer": "$$\n\\boxed{\\begin{pmatrix} \\frac{d-c}{a-b-c+d} & \\frac{d-b}{a-b-c+d} & \\frac{ad-bc}{a-b-c+d} \\end{pmatrix}}\n$$", "id": "3199092"}, {"introduction": "Having mastered the mechanics of finite games, we now deepen our understanding by exploring the theoretical underpinnings of the Minimax Theorem in a continuous setting. This problem illustrates the crucial role of convexity and concavity, revealing what happens when these conditions are not met—the emergence of a 'minimax gap' where the order of play matters. By engaging with this hypothetical scenario [@problem_id:3199088], you will see how allowing for mixed strategies can be viewed as a geometric operation that closes this gap, connecting game theory directly to the principles of convex analysis.", "problem": "Consider a two-player zero-sum game in which Player X (the minimizer) chooses $x$ in the interval $X = [0, 2\\pi]$ and Player Y (the maximizer) chooses $y$ from the discrete set $Y_{\\text{pure}} = \\{-1, 1\\}$. The payoff to Player Y is $f(x,y) = \\sin(x)\\, y$. In the sense of optimization methods, the minimax value is $\\inf_{x \\in X} \\sup_{y \\in Y_{\\text{pure}}} f(x,y)$ and the maximin value is $\\sup_{y \\in Y_{\\text{pure}}} \\inf_{x \\in X} f(x,y)$, with the classical minimax inequality stating $\\inf_{x} \\sup_{y} f(x,y) \\ge \\sup_{y} \\inf_{x} f(x,y)$ under no further assumptions.\n\nDefine the inner maximum function $g(x) = \\sup_{y \\in Y_{\\text{pure}}} f(x,y)$ and let $\\operatorname{co}(g)$ denote the concave envelope of $g$ over $X$, namely the largest concave function $h: X \\to \\mathbb{R}$ such that $h(x) \\le g(x)$ for all $x \\in X$. Suppose that, motivated by the structural conditions in minimax theorems, one substitutes the non-concave inner payoff $g$ by its concave envelope $\\operatorname{co}(g)$ to form the relaxed minimax value $\\inf_{x \\in X} \\operatorname{co}(g)(x)$. Additionally, allow Player Y to use mixed strategies supported on $Y_{\\text{pure}}$, which is equivalent (in this bilinear payoff) to choosing $y$ in the convex hull $\\operatorname{conv}(Y_{\\text{pure}}) = [-1, 1]$.\n\nStarting from the core definitions above (zero-sum game, minimax/maximin values, concave envelope), do the following:\n\n1. Derive $g(x)$ explicitly from $f(x,y)$ and $Y_{\\text{pure}}$.\n2. Compute the pure-strategy minimax value $\\inf_{x \\in X} \\sup_{y \\in Y_{\\text{pure}}} f(x,y)$ and the pure-strategy maximin value $\\sup_{y \\in Y_{\\text{pure}}} \\inf_{x \\in X} f(x,y)$.\n3. Determine the concave envelope $\\operatorname{co}(g)$ on $X$ and compute $\\inf_{x \\in X} \\operatorname{co}(g)(x)$.\n4. Compute the maximin value when Player Y is allowed to mix, equivalently $\\sup_{y \\in [-1,1]} \\inf_{x \\in X} f(x,y)$, and show that this equals the relaxed minimax value in step 3.\n5. Finally, report the numerical value of the minimax gap for the pure-strategy game, defined as\n$$\nG \\equiv \\inf_{x \\in X} \\sup_{y \\in Y_{\\text{pure}}} f(x,y)\\;-\\;\\sup_{y \\in Y_{\\text{pure}}} \\inf_{x \\in X} f(x,y).\n$$\n\nThe required final answer is the single real number $G$. No rounding is needed, and no physical units are involved.", "solution": "The user-provided problem is a valid exercise in optimization methods and game theory. All terms are well-defined, and the problem is mathematically and logically self-consistent. We proceed with the solution by following the five steps outlined in the problem statement.\n\nThe payoff function is $f(x,y) = \\sin(x) y$, where Player X chooses $x \\in X = [0, 2\\pi]$ to minimize the payoff, and Player Y chooses $y \\in Y_{\\text{pure}} = \\{-1, 1\\}$ to maximize the payoff.\n\n1. Derivation of $g(x) = \\sup_{y \\in Y_{\\text{pure}}} f(x,y)$:\nThe inner maximum function $g(x)$ is defined as the maximum payoff Player Y can achieve for a fixed choice of $x$ by Player X.\n$$\ng(x) = \\sup_{y \\in \\{-1, 1\\}} \\sin(x) y\n$$\nWe evaluate the payoff for each of Player Y's possible pure strategies:\n- If $y = 1$, the payoff is $\\sin(x)$.\n- If $y = -1$, the payoff is $-\\sin(x)$.\nThe supremum is the larger of these two values:\n$$\ng(x) = \\max\\{\\sin(x), -\\sin(x)\\}\n$$\nThis is the definition of the absolute value function. Therefore,\n$$\ng(x) = |\\sin(x)|\n$$\n\n2. Computation of the pure-strategy minimax and maximin values:\n\nThe pure-strategy minimax value is $\\inf_{x \\in X} \\sup_{y \\in Y_{\\text{pure}}} f(x,y)$. Using the result from step 1, this is:\n$$\n\\inf_{x \\in [0, 2\\pi]} g(x) = \\inf_{x \\in [0, 2\\pi]} |\\sin(x)|\n$$\nThe function $|\\sin(x)|$ is always non-negative, i.e., $|\\sin(x)| \\ge 0$. It reaches its minimum value of $0$ when $\\sin(x) = 0$. Within the interval $x \\in [0, 2\\pi]$, this occurs at $x = 0$, $x = \\pi$, and $x = 2\\pi$. Thus, the minimax value is $0$.\n$$\n\\inf_{x \\in X} \\sup_{y \\in Y_{\\text{pure}}} f(x,y) = 0\n$$\nThe pure-strategy maximin value is $\\sup_{y \\in Y_{\\text{pure}}} \\inf_{x \\in X} f(x,y)$. We first compute the inner infimum for each of Player Y's pure strategies:\n- For $y=1$: The problem is to find $\\inf_{x \\in [0, 2\\pi]} \\sin(x) \\cdot 1$. The minimum value of $\\sin(x)$ on the interval $[0, 2\\pi]$ is $-1$, which occurs at $x=3\\pi/2$.\n- For $y=-1$: The problem is to find $\\inf_{x \\in [0, 2\\pi]} \\sin(x) \\cdot (-1) = \\inf_{x \\in [0, 2\\pi]} -\\sin(x)$. This is equivalent to $-\\sup_{x \\in [0, 2\\pi]} \\sin(x)$. The maximum value of $\\sin(x)$ on $[0, 2\\pi]$ is $1$, occurring at $x=\\pi/2$. So, the infimum is $-1$.\nNow, we take the supremum over Player Y's choices:\n$$\n\\sup_{y \\in \\{-1, 1\\}} \\{-1, -1\\} = -1\n$$\nTherefore, the maximin value is $-1$.\n$$\n\\sup_{y \\in Y_{\\text{pure}}} \\inf_{x \\in X} f(x,y) = -1\n$$\n\n3. Determination of $\\operatorname{co}(g)$ and computation of $\\inf_{x \\in X} \\operatorname{co}(g)(x)$:\nThe function to be analyzed is $g(x) = |\\sin(x)|$ on the interval $X = [0, 2\\pi]$. The concave envelope, $\\operatorname{co}(g)$, is the largest concave function $h(x)$ such that $h(x) \\le g(x)$ for all $x \\in X$.\nLet $h(x) = \\operatorname{co}(g)(x)$. By definition, $h(x) \\le |\\sin(x)|$ for all $x \\in [0, 2\\pi]$.\nThe function $k(x) = 0$ for all $x \\in [0, 2\\pi]$ is a concave function (as it is linear). It also satisfies $k(x) = 0 \\le |\\sin(x)| = g(x)$. Since $h(x)$ is the *largest* such concave function, it must be that $h(x) \\ge k(x) = 0$ for all $x$. Thus, we have $0 \\le h(x) \\le |\\sin(x)|$.\nThis implies that at the points where $|\\sin(x)|=0$, we must also have $h(x)=0$. These points in $[0, 2\\pi]$ are $x=0$, $x=\\pi$, and $x=2\\pi$. So, $h(0)=0$, $h(\\pi)=0$, and $h(2\\pi)=0$.\nA function $h$ that is concave on $[0, 2\\pi]$ must satisfy Jensen's inequality. Let's examine the midpoint between $x_1 = \\pi/2$ and $x_2 = 3\\pi/2$, which is $x_m = \\pi$. Concavity requires:\n$$\nh(\\pi) \\ge \\frac{1}{2}h(\\pi/2) + \\frac{1}{2}h(3\\pi/2)\n$$\nSince $h(\\pi)=0$ and $h(x) \\ge 0$ for all $x$, we have:\n$$\n0 \\ge \\frac{1}{2}(h(\\pi/2) + h(3\\pi/2))\n$$\nAs $h(\\pi/2) \\ge 0$ and $h(3\\pi/2) \\ge 0$, the only way to satisfy this inequality is if $h(\\pi/2)=0$ and $h(3\\pi/2)=0$.\nNow consider the interval $[0, \\pi]$. We have a concave function $h(x)$ such that $h(0)=0$, $h(\\pi/2)=0$, $h(\\pi)=0$, and $h(x) \\ge 0$. A non-negative concave function on an interval that is zero at the endpoints must be zero everywhere in that interval. Applying this to sub-intervals like $[0, \\pi/2]$ and $[\\pi/2, \\pi]$, we deduce that $h(x)=0$ for all $x \\in [0, \\pi]$. A similar argument for the interval $[\\pi, 2\\pi]$ shows that $h(x)=0$ on this interval as well.\nTherefore, the only function satisfying the conditions is $h(x)=0$ for all $x \\in [0, 2\\pi]$.\n$$\n\\operatorname{co}(g)(x) = 0\n$$\nThe relaxed minimax value is then:\n$$\n\\inf_{x \\in X} \\operatorname{co}(g)(x) = \\inf_{x \\in [0, 2\\pi]} 0 = 0\n$$\n\n4. Computation of the mixed-strategy maximin value:\nHere, Player Y is allowed to choose any $y$ from the convex hull of $Y_{\\text{pure}}$, which is $\\operatorname{conv}(\\{-1,1\\}) = [-1, 1]$. The value to compute is $\\sup_{y \\in [-1,1]} \\inf_{x \\in [0, 2\\pi]} f(x,y)$.\nLet $H(y) = \\inf_{x \\in [0, 2\\pi]} \\sin(x) y$.\n- If $y > 0$, Player X wants to make $\\sin(x)$ as negative as possible. Thus, $\\inf_{x} \\sin(x) y = y \\cdot (\\inf_{x} \\sin(x)) = y \\cdot (-1) = -y$.\n- If $y < 0$, Player X wants to make $\\sin(x)$ as positive as possible to minimize $y \\sin(x)$. Thus, $\\inf_{x} \\sin(x) y = y \\cdot (\\sup_{x} \\sin(x)) = y \\cdot (1) = y$.\n- If $y=0$, $H(0) = \\inf_x 0 = 0$.\nCombining these cases, we have $H(y) = -|y|$ for $y \\in [-1, 1]$.\nThe problem is now to compute $\\sup_{y \\in [-1,1]} H(y)$:\n$$\n\\sup_{y \\in [-1,1]} -|y|\n$$\nThe function $-|y|$ has a maximum value of $0$ at $y=0$.\n$$\n\\sup_{y \\in [-1,1]} \\inf_{x \\in [0, 2\\pi]} f(x,y) = 0\n$$\nAs expected by the theory of minimax relaxations, this value, $0$, is equal to the relaxed minimax value $\\inf_{x \\in X} \\operatorname{co}(g)(x)$ found in step 3.\n\n5. Computation of the minimax gap $G$:\nThe minimax gap for the pure-strategy game is defined as:\n$$\nG = \\left(\\inf_{x \\in X} \\sup_{y \\in Y_{\\text{pure}}} f(x,y)\\right) - \\left(\\sup_{y \\in Y_{\\text{pure}}} \\inf_{x \\in X} f(x,y)\\right)\n$$\nUsing the values computed in step 2:\n$$\nG = 0 - (-1) = 1\n$$\nThis non-zero gap indicates that for the pure-strategy game, the order of play matters, and an equilibrium in pure strategies does not exist. The game value, established by allowing mixed strategies, is $0$.", "answer": "$$\\boxed{1}$$", "id": "3199088"}, {"introduction": "Theory and practice are two sides of the same coin, and this computational exercise makes that connection tangible. You will investigate what happens when the mathematical guarantees of the Minimax Theorem are violated, not just in theory, but in the behavior of a widely used algorithm. By implementing a gradient-based method [@problem_id:3199108] on a function that fails the theorem's concavity requirement, you will observe firsthand why these conditions are essential for algorithmic stability and convergence, a critical lesson in modern optimization and machine learning.", "problem": "You are asked to design and implement an empirical test that illustrates the necessity of concavity in the second player’s variable for the minimax theorem to guarantee convergence to a value in two-player zero-sum games. The design must originate from fundamental definitions and facts:\n\n- A two-player zero-sum game is specified by a payoff function $f(x,y)$ with $x$ chosen by the minimizing player and $y$ chosen by the maximizing player over compact convex sets. The minimax theorem states that if $f$ is convex in $x$ and concave in $y$ and the domains are compact and convex, then the game has a value and\n$$\n\\min_{x \\in X} \\max_{y \\in Y} f(x,y) \\;=\\; \\max_{y \\in Y} \\min_{x \\in X} f(x,y).\n$$\n- When concavity in $y$ fails, the equality can fail, the game may have no single value, and standard saddle-point algorithms can fail to converge to a common value.\n\nConstruct a family $f_{\\alpha}$ and demonstrate how the violation of concavity in $y$ can be detected via numerical minimax and the behavior of a standard projected gradient method.\n\nYour tasks:\n\n1) Define the domains and function family.\n- Let $X = [-1,1]$ and $Y = [-1,1]$.\n- For a parameter $\\alpha \\in \\mathbb{R}_{\\ge 0}$, define the payoff function\n$$\nf_{\\alpha}(x,y) \\;=\\; x\\,y \\;+\\; \\alpha\\, y^4.\n$$\n- For fixed $y$, $f_{\\alpha}$ is linear in $x$ and hence convex in $x$. For $\\alpha > 0$, $f_{\\alpha}$ is not concave in $y$ on $Y$.\n\n2) Quantify minimax orderings by discretization.\n- Approximate\n$$\nV^{-+}_{\\alpha} \\;=\\; \\min_{x \\in X} \\max_{y \\in Y} f_{\\alpha}(x,y), \\qquad\nV^{+-}_{\\alpha} \\;=\\; \\max_{y \\in Y} \\min_{x \\in X} f_{\\alpha}(x,y)\n$$\nby uniform discretization of $X$ and $Y$ into $N = 1001$ evenly spaced points each, evaluating $f_{\\alpha}$ on the tensor grid, and taking discrete extrema in the prescribed order.\n\n3) Implement a standard saddle algorithm and observe behavior.\n- Use Projected Gradient Descent-Ascent (PGDA): at iteration $t \\in \\{1,\\dots,T\\}$ with stepsize $\\eta_t = \\eta_0/\\sqrt{t}$,\n$$\nx_{t+1} \\;=\\; \\Pi_X\\!\\left( x_t \\;-\\; \\eta_t \\,\\nabla_x f_{\\alpha}(x_t,y_t) \\right), \\qquad\ny_{t+1} \\;=\\; \\Pi_Y\\!\\left( y_t \\;+\\; \\eta_t \\,\\nabla_y f_{\\alpha}(x_t,y_t) \\right),\n$$\nwhere $\\Pi_X$ and $\\Pi_Y$ are projections onto $X$ and $Y$, respectively, and\n$$\n\\nabla_x f_{\\alpha}(x,y) \\;=\\; y, \\qquad \\nabla_y f_{\\alpha}(x,y) \\;=\\; x \\;+\\; 4\\alpha y^3.\n$$\n- Use $T = 20000$, $\\eta_0 = 0.2$, and initialize $(x_1,y_1) = (0.5,-0.5)$.\n- Let the running average of payoffs be\n$$\n\\bar{f} \\;=\\; \\frac{2}{T} \\sum_{t=T/2+1}^{T} f_{\\alpha}(x_t,y_t).\n$$\n\n4) Measure a primal-dual gap at the final iterate.\n- At $(x_T,y_T)$, approximate the gap\n$$\n\\mathrm{gap}_T \\;=\\; \\max_{y \\in Y} f_{\\alpha}(x_T,y) \\;-\\; \\min_{x \\in X} f_{\\alpha}(x,y_T)\n$$\nby one-dimensional discretizations of $X$ and $Y$ using $N = 1001$ equally spaced points.\n\n5) Test suite.\n- Use the parameter set $\\alpha \\in \\{0.0, 0.3, 2.0\\}$.\n- For each $\\alpha$, compute $(V^{-+}_{\\alpha}, V^{+-}_{\\alpha})$, run the PGDA algorithm to compute $\\bar{f}$, and compute $\\mathrm{gap}_T$.\n- Define a success criterion “algorithm converged to a value” as the conjunction of:\n  - $|V^{-+}_{\\alpha} - V^{+-}_{\\alpha}| \\le \\varepsilon_{\\mathrm{eq}}$,\n  - $\\mathrm{gap}_T \\le \\varepsilon_{\\mathrm{gap}}$,\n  - $|\\bar{f} - V^{-+}_{\\alpha}| \\le \\varepsilon_{\\mathrm{val}}$.\n- Use tolerances $\\varepsilon_{\\mathrm{eq}} = 10^{-2}$, $\\varepsilon_{\\mathrm{gap}} = 5 \\times 10^{-2}$, $\\varepsilon_{\\mathrm{val}} = 5 \\times 10^{-2}$.\n\n6) Required final output format.\n- Your program should produce a single line of output containing the results, aggregating all test cases in order of the test suite. For each $\\alpha$, output the quadruple\n$$\n\\left[ V^{-+}_{\\alpha},\\; V^{+-}_{\\alpha},\\; \\bar{f},\\; \\text{success} \\right],\n$$\nflattened into one list over all test cases. Thus the final output must be a single line in the exact format\n\"[r1,r2,r3,r4,r5,r6,r7,r8,r9,r10,r11,r12]\",\nwhere $r_k$ are the values in the order described, with the Boolean printed as either True or False.\n\nNo user input should be required; all parameters are fixed as above. There are no physical units, angles, or percentages in this problem, so none are required to be reported.", "solution": "The problem requires an empirical demonstration of the minimax theorem's reliance on the concavity-convexity of the payoff function. Specifically, we will construct a family of two-player zero-sum games, parameterized by a value $\\alpha$, where the conditions of the theorem are violated for $\\alpha > 0$. We will then use numerical methods to show that this violation leads to a failure in the equality of minimax values and the convergence of a standard saddle-point algorithm, Projected Gradient Descent-Ascent (PGDA).\n\nA two-player zero-sum game is defined by a payoff function $f(x, y)$, where player 1 chooses $x$ from a set $X$ to minimize the payoff, and player 2 chooses $y$ from a set $Y$ to maximize it. The domains $X$ and $Y$ are required to be compact and convex. The Von Neumann-Sion minimax theorem states that if $f(x, y)$ is convex in $x$ for every fixed $y$, and concave in $y$ for every fixed $x$, then the game has a value, meaning:\n$$\n\\min_{x \\in X} \\max_{y \\in Y} f(x,y) = \\max_{y \\in Y} \\min_{x \\in X} f(x,y)\n$$\nWe denote the left-hand side as $V^{-+}$ and the right-hand side as $V^{+-}$.\n\n**1. Problem Formulation**\n\nThe chosen domains are $X = [-1, 1]$ and $Y = [-1, 1]$, which are both compact and convex. The payoff function is given by:\n$$\nf_{\\alpha}(x,y) = xy + \\alpha y^4\n$$\nwhere $\\alpha \\ge 0$ is a parameter.\n\nWe must first verify the convexity-concavity properties. The second partial derivatives are:\n$$\n\\frac{\\partial^2 f_{\\alpha}}{\\partial x^2} = 0\n$$\n$$\n\\frac{\\partial^2 f_{\\alpha}}{\\partial y^2} = 12 \\alpha y^2\n$$\nFor any fixed $y$, $f_{\\alpha}$ is linear in $x$, so its second derivative with respect to $x$ is $0$. A function with a non-negative second derivative is convex, so $f_{\\alpha}$ is convex in $x$ for all $\\alpha$.\nFor the function to be concave in $y$, its second derivative with respect to $y$ must be non-positive. $\\frac{\\partial^2 f_{\\alpha}}{\\partial y^2} = 12 \\alpha y^2 \\ge 0$ for all $y$ when $\\alpha \\ge 0$. This is non-positive only in the trivial case where $\\alpha = 0$. For any $\\alpha > 0$, the function is strictly convex in $y$ (for $y \\neq 0$), thus violating the concavity requirement of the minimax theorem.\n\n**2. Numerical Analysis Methods**\n\nWe will employ three numerical measures to investigate the impact of violating the concavity condition.\n\n**a) Discretized Minimax Values:** We approximate $V^{-+}_{\\alpha}$ and $V^{+-}_{\\alpha}$ by discretizing the domains $X$ and $Y$ into $N=1001$ equally spaced points. We construct a payoff matrix $M_{ij} = f_{\\alpha}(x_i, y_j)$ and compute the discrete minimax values:\n$$\nV^{-+}_{\\alpha} \\approx \\min_{i} \\max_{j} M_{ij} \\qquad \\text{and} \\qquad V^{+-}_{\\alpha} \\approx \\max_{j} \\min_{i} M_{ij}\n$$\nThe weak minimax inequality always holds: $V^{+-}_{\\alpha} \\le V^{-+}_{\\alpha}$. The theorem guarantees equality under its conditions. A significant difference $|V^{-+}_{\\alpha} - V^{+-}_{\\alpha}| > \\varepsilon_{\\mathrm{eq}}$ is a strong indicator that the theorem's conditions are not met and the game lacks a single value.\n\n**b) Projected Gradient Descent-Ascent (PGDA):** This is an iterative algorithm designed to find a saddle point $(x^*, y^*)$. The updates are given by:\n$$\nx_{t+1} = \\Pi_X\\left( x_t - \\eta_t \\nabla_x f_{\\alpha}(x_t,y_t) \\right)\n$$\n$$\ny_{t+1} = \\Pi_Y\\left( y_t + \\eta_t \\nabla_y f_{\\alpha}(x_t,y_t) \\right)\n$$\nwhere $\\Pi_X$ and $\\Pi_Y$ are projections onto the sets $X=[-1,1]$ and $Y=[-1,1]$ respectively, and $\\eta_t$ is the step size at iteration $t$. The gradients for our function are:\n$$\n\\nabla_x f_{\\alpha}(x,y) = y\n$$\n$$\n\\nabla_y f_{\\alpha}(x,y) = x + 4\\alpha y^3\n$$\nIf the algorithm converges to a saddle point $(x^*, y^*)$, the sequence of payoffs $f_{\\alpha}(x_t, y_t)$ should converge to the game's value, $f_{\\alpha}(x^*, y^*)$. We monitor the running average of the payoffs over the second half of the iterations, $\\bar{f}$, as a measure of the algorithm's behavior.\n\n**c) Primal-Dual Gap:** At the final iteration $T$, we measure the primal-dual gap, which quantifies how far the state $(x_T, y_T)$ is from being a true saddle point.\n$$\n\\mathrm{gap}_T = \\max_{y \\in Y} f_{\\alpha}(x_T,y) - \\min_{x \\in X} f_{\\alpha}(x,y_T)\n$$\nFor a true saddle point $(x^*, y^*)$, this gap is zero. A large, non-zero gap indicates that the algorithm has failed to find a saddle point.\n\n**3. Expected Results**\n\n*   **Case $\\alpha = 0$:** The function is $f_0(x,y) = xy$. This is linear-linear, satisfying the convex-concave condition. We expect $V^{-+}_0 = V^{+-}_0 = 0$. The PGDA algorithm should converge to the saddle point $(0,0)$, leading to $\\bar{f} \\approx 0$ and $\\mathrm{gap}_T \\approx 0$. The test for convergence should succeed.\n\n*   **Case $\\alpha > 0$:** The concavity condition on $y$ is violated. We expect to observe a minimax gap, $V^{-+}_{\\alpha} > V^{+-}_{\\alpha}$. The term $4\\alpha y^3$ in the gradient for $y$ acts as a destabilizing force, pushing $y$ away from $0$ towards the boundaries of its domain, $y=\\pm 1$. This can prevent the PGDA algorithm from converging to a single point, potentially causing cyclic or chaotic behavior. Consequently, the final iterates $(x_T, y_T)$ will not form a saddle point, resulting in a large $\\mathrm{gap}_T$, and the running average $\\bar{f}$ may not correspond to a meaningful value. The convergence test is expected to fail.\n\nThe implementation will carry out these computations for $\\alpha \\in \\{0.0, 0.3, 2.0\\}$ and apply the specified success criteria to formally report on the convergence for each case. The results will empirically validate that the convex-concave structure is essential for the guarantees provided by the minimax theorem.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Performs an empirical test to illustrate the necessity of concavity\n    in the second player’s variable for the minimax theorem to hold.\n    \"\"\"\n    # Define the test cases and parameters from the problem statement.\n    test_cases = [\n        # (alpha)\n        (0.0),\n        (0.3),\n        (2.0),\n    ]\n\n    # --- Fixed Parameters ---\n    N = 1001\n    T = 20000\n    eta_0 = 0.2\n    x_init, y_init = 0.5, -0.5\n    \n    # Tolerances for success criterion\n    eps_eq = 1e-2\n    eps_gap = 5e-2\n    eps_val = 5e-2\n\n    # Discretization grids for X and Y\n    x_grid = np.linspace(-1, 1, N)\n    y_grid = np.linspace(-1, 1, N)\n\n    results = []\n\n    for alpha in test_cases:\n        # Define the payoff function and its gradients\n        f_alpha = lambda x, y: x * y + alpha * y**4\n        grad_x_f = lambda x, y: y\n        grad_y_f = lambda x, y: x + 4 * alpha * y**3\n\n        # Task 2: Quantify minimax orderings by discretization\n        # We use broadcasting for efficiency. X_col is (N, 1), Y_row is (1, N).\n        # The resulting payoff_matrix[i, j] corresponds to f(x_grid[i], y_grid[j]).\n        X_col = x_grid[:, np.newaxis]\n        Y_row = y_grid[np.newaxis, :]\n        payoff_matrix = X_col * Y_row + alpha * Y_row**4\n\n        # V_minus_plus = min_x max_y f(x,y)\n        # For each x (row), find the max over y (columns). Then find min of those maxes.\n        max_over_y = np.max(payoff_matrix, axis=1)\n        V_minus_plus = np.min(max_over_y)\n        \n        # V_plus_minus = max_y min_x f(x,y)\n        # For each y (column), find min over x (rows). Then find max of those mins.\n        min_over_x = np.min(payoff_matrix, axis=0)\n        V_plus_minus = np.max(min_over_x)\n\n        # Task 3: Implement Projected Gradient Descent-Ascent (PGDA)\n        x, y = x_init, y_init\n        f_values_second_half = []\n        \n        for t in range(1, T + 1):\n            eta_t = eta_0 / np.sqrt(t)\n            \n            # Gradient update step\n            x_new = x - eta_t * grad_x_f(x, y)\n            y_new = y + eta_t * grad_y_f(x, y)\n            \n            # Projection step\n            x = np.clip(x_new, -1, 1)\n            y = np.clip(y_new, -1, 1)\n            \n            # Store payoffs from the second half of iterations\n            if t > T / 2:\n                f_values_second_half.append(f_alpha(x, y))\n        \n        # Final iterates\n        x_T, y_T = x, y\n        \n        # Calculate the running average of payoffs\n        f_bar = np.mean(f_values_second_half)\n\n        # Task 4: Measure primal-dual gap at the final iterate\n        # max_{y in Y} f(x_T, y) approximated by discretization\n        max_val_y = np.max(f_alpha(x_T, y_grid))\n        \n        # min_{x in X} f(x, y_T) approximated by discretization\n        min_val_x = np.min(f_alpha(x_grid, y_T))\n        \n        gap_T = max_val_y - min_val_x\n\n        # Task 5: Test for success\n        cond1 = np.abs(V_minus_plus - V_plus_minus) = eps_eq\n        cond2 = gap_T = eps_gap\n        cond3 = np.abs(f_bar - V_minus_plus) = eps_val\n        \n        success = cond1 and cond2 and cond3\n        \n        # Append the quadruple of results\n        results.extend([V_minus_plus, V_plus_minus, f_bar, success])\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "3199108"}]}