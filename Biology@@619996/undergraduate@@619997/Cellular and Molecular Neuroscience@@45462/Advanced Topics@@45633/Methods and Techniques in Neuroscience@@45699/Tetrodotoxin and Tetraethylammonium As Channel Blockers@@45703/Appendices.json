{"hands_on_practices": [{"introduction": "The chi-squared ($\\chi^2$) distribution is a cornerstone of modern statistics, essential for tasks like hypothesis testing and analyzing the goodness-of-fit of a model to data. Before we can confidently apply such a tool, we must first understand its fundamental properties. This first exercise guides you through calculating the variance of a $\\chi^2$ random variable directly from its definition, reinforcing the foundational link between the normal and chi-squared distributions. [@problem_id:2282]", "id": "2282", "problem": "Let $X_1, X_2, \\ldots, X_6$ be six independent and identically distributed (i.i.d.) random variables. Each variable $X_i$ is drawn from a normal distribution with mean $\\mu = 0$ and variance $\\sigma^2 = 9$.\n\nWe define a new random variable $Y$ as the sum of the squares of these variables, scaled by a factor:\n$$Y = \\sum_{i=1}^{6} \\left(\\frac{X_i}{3}\\right)^2$$\n\n**Background Information:**\n1.  A random variable $Z$ has a **standard normal distribution**, denoted $Z \\sim N(0, 1)$, if it is a normal distribution with mean $\\mu=0$ and variance $\\sigma^2=1$.\n2.  If a random variable $X$ is normally distributed with mean $\\mu$ and variance $\\sigma^2$, i.e., $X \\sim N(\\mu, \\sigma^2)$, then the standardized variable $Z = \\frac{X - \\mu}{\\sigma}$ follows a standard normal distribution.\n3.  The **chi-squared distribution** with $k$ degrees of freedom, denoted $\\chi^2(k)$, is defined as the distribution of the sum of the squares of $k$ independent standard normal random variables. If $Z_1, Z_2, \\ldots, Z_k$ are i.i.d. with $Z_i \\sim N(0, 1)$, then the random variable $Q = \\sum_{i=1}^{k} Z_i^2$ follows a chi-squared distribution with $k$ degrees of freedom, i.e., $Q \\sim \\chi^2(k)$.\n4.  The variance of a random variable $Q$ that follows a chi-squared distribution with $k$ degrees of freedom is given by $\\text{Var}(Q) = 2k$.\n\nUsing this information, derive the variance of the random variable $Y$.\n\n", "solution": "Define the standardized variables \n$$Z_i=\\frac{X_i-0}{3}=\\frac{X_i}{3},$$\nso that $Z_i\\sim N(0,1)$ independently for $i=1,\\dots,6$.  Then\n$$Y=\\sum_{i=1}^{6}\\Bigl(\\frac{X_i}{3}\\Bigr)^2=\\sum_{i=1}^{6}Z_i^2.$$\nBy definition, $\\sum_{i=1}^6 Z_i^2\\sim\\chi^2(6)$, and for a chi‚Äêsquared random variable $Q\\sim\\chi^2(k)$ we have\n$$\\Var(Q)=2k.$$\nHere $k=6$, so\n$$\\Var(Y)=2\\cdot6=12.$$", "answer": "$$\\boxed{12}$$"}, {"introduction": "Building on our understanding of a single chi-squared variable, we now explore how these distributions behave when combined. This practice leverages the powerful and wonderfully simple property of the linearity of expectation to determine the expected value of the difference between two independent chi-squared variables. Mastering this type of calculation is a key step toward comparing different statistical samples or evaluating competing models in experimental science. [@problem_id:2300]", "id": "2300", "problem": "This problem requires you to derive the expectation of the difference between two independent chi-squared random variables, using fundamental definitions.\n\n**Background:**\n\n1.  A standard normal random variable, let's call it $Z$, is a continuous random variable with a mean (or expectation) of $E[Z] = 0$ and a variance of $\\text{Var}(Z) = 1$.\n2.  The variance of any random variable $Z$ is related to its expectation through the formula: $\\text{Var}(Z) = E[Z^2] - (E[Z])^2$.\n3.  A random variable $Y$ is said to follow a chi-squared distribution with $k$ degrees of freedom, denoted $Y \\sim \\chi^2(k)$, if it can be expressed as the sum of the squares of $k$ independent standard normal random variables. That is, $Y = \\sum_{i=1}^{k} Z_i^2$, where each $Z_i$ is an independent standard normal random variable.\n4.  The expectation operator is linear. For any two random variables $X_1$ and $X_2$, $E[X_1 - X_2] = E[X_1] - E[X_2]$.\n\n**Problem Statement:**\n\nConsider two **independent** random variables, $X_1$ and $X_2$. The variable $X_1$ follows a chi-squared distribution with $k_1$ degrees of freedom ($X_1 \\sim \\chi^2(k_1)$), and the variable $X_2$ follows a chi-squared distribution with $k_2$ degrees of freedom ($X_2 \\sim \\chi^2(k_2)$).\n\nUsing only the fundamental definitions provided above, derive the value of $E[X_1 - X_2]$ for the case where $k_1 = 4$ and $k_2 = 6$.\n\n", "solution": "The goal is to compute the expectation of the difference between two independent chi-squared random variables, $E[X_1 - X_2]$.\n\n**Step 1: Apply the linearity of expectation.**\nAs stated in the background, the expectation of a difference is the difference of the expectations.\n$$\nE[X_1 - X_2] = E[X_1] - E[X_2]\n$$\nTo solve the problem, we need to find the expectation of a general chi-squared random variable, $E[X]$, where $X \\sim \\chi^2(k)$.\n\n**Step 2: Express the expectation of a chi-squared variable using its definition.**\nFrom the background, a chi-squared variable $X$ with $k$ degrees of freedom is defined as the sum of squares of $k$ independent standard normal random variables, $Z_i$.\n$$\nX = \\sum_{i=1}^{k} Z_i^2\n$$\nThe expectation of $X$ is therefore:\n$$\nE[X] = E\\left[\\sum_{i=1}^{k} Z_i^2\\right]\n$$\nUsing the linearity of expectation for a sum:\n$$\nE[X] = \\sum_{i=1}^{k} E[Z_i^2]\n$$\n\n**Step 3: Calculate the expectation of a squared standard normal variable, $E[Z^2]$.**\nWe are given the formula for variance:\n$$\n\\text{Var}(Z) = E[Z^2] - (E[Z])^2\n$$\nFor a standard normal random variable $Z$, we know that $E[Z] = 0$ and $\\text{Var}(Z) = 1$. Substituting these values into the variance formula:\n$$\n1 = E[Z^2] - (0)^2\n$$\nThis simplifies to:\n$$\nE[Z^2] = 1\n$$\n\n**Step 4: Determine the expectation of a general chi-squared variable.**\nNow we substitute the result from Step 3 back into the expression for $E[X]$ from Step 2. Since each $Z_i$ is a standard normal variable, $E[Z_i^2] = 1$ for all $i$.\n$$\nE[X] = \\sum_{i=1}^{k} (1)\n$$\nThe sum consists of $k$ terms, each equal to 1. Therefore, the expectation of a chi-squared random variable with $k$ degrees of freedom is simply its degrees of freedom.\n$$\nE[X] = k\n$$\n\n**Step 5: Calculate the final result for the specific variables $X_1$ and $X_2$.**\nUsing the general result from Step 4, we can find the expectations for $X_1$ and $X_2$:\nFor $X_1 \\sim \\chi^2(k_1)$, the expectation is $E[X_1] = k_1$.\nFor $X_2 \\sim \\chi^2(k_2)$, the expectation is $E[X_2] = k_2$.\n\nNow, substitute these back into the expression from Step 1:\n$$\nE[X_1 - X_2] = k_1 - k_2\n$$\nFinally, we substitute the given numerical values for the degrees of freedom, $k_1 = 4$ and $k_2 = 6$:\n$$\nE[X_1 - X_2] = 4 - 6 = -2\n$$", "answer": "$$\\boxed{-2}$$"}, {"introduction": "The principles of mathematical transformation extend far beyond statistics into the realm of fundamental physics, demonstrating the unifying power of mathematical formalism. This advanced problem offers a glimpse into electrodynamics, exploring how the observed pattern of radiated energy from a source is altered when it moves at speeds approaching the speed of light. By systematically applying a transformation rule, we can relate observations made in different inertial frames, a core concept in Einstein's theory of special relativity that has profound implications for our understanding of the universe. [@problem_id:2266]", "id": "2266", "problem": "An oscillating, pure axial electric quadrupole source has its symmetry axis aligned with the $z$-axis. In its rest frame (S'), the time-averaged angular distribution of radiated power is given by:\n$$\n\\left(\\frac{dP'}{d\\Omega'}\\right) = \\frac{5 P_0'}{16\\pi} (3\\cos^2\\theta' - 1)^2\n$$\nwhere $P_0'$ is the total power radiated in the rest frame, and $\\theta'$ is the polar angle with respect to the $z'$-axis.\n\nThis source moves with a constant relativistic velocity $\\vec{v} = v\\hat{x}$ in the lab frame (S). The symmetry axis of the quadrupole remains along the $z$-axis (i.e., $\\hat{z}' = \\hat{z}$).\n\nFind the time-averaged angular power distribution $\\frac{dP}{d\\Omega}(\\theta, \\phi)$ observed in the lab frame. Your result should be an expansion in powers of $\\beta = v/c$, keeping terms up to and including $\\mathcal{O}(\\beta^2)$.\n\nTo simplify your final answer, express it in terms of the total rest-frame power $P_0'$, the relativistic factor $\\beta$, the laboratory direction cosine $n_x = \\sin\\theta\\cos\\phi$, and the quantity $A = 3\\cos^2\\theta - 1$.\n\nYou may use the following relation for the transformation of the angular power distribution from the rest frame S' to the lab frame S, for any radiation source:\n$$\n\\frac{dP}{d\\Omega}(\\vec{n}) = \\frac{1}{\\gamma^4(1-\\vec{\\beta}\\cdot\\vec{n})^4} \\left(\\frac{dP'}{d\\Omega'}\\right)_{\\vec{n}'(\\vec{n})}\n$$\nwhere $\\vec{n}$ is the direction of observation in the lab frame, $\\vec{n}'(\\vec{n})$ is the corresponding direction in the rest frame, and $\\gamma = (1-\\beta^2)^{-1/2}$.\n\n", "solution": "The problem asks for the lab-frame angular power distribution $\\frac{dP}{d\\Omega}$ of a moving electric quadrupole source, expanded to second order in $\\beta=v/c$.\n\n**1. Set up the transformation**\n\nThe transformation formula for the angular power distribution is given:\n$$\n\\frac{dP}{d\\Omega}(\\vec{n}) = \\frac{1}{\\gamma^4(1-\\vec{\\beta}\\cdot\\vec{n})^4} \\left(\\frac{dP'}{d\\Omega'}\\right)_{\\vec{n}'(\\vec{n})}\n$$\nThe source moves with velocity $\\vec{v}=v\\hat{x}$, so $\\vec{\\beta} = \\beta\\hat{x}$. The direction of observation in the lab frame is $\\vec{n} = (\\sin\\theta\\cos\\phi, \\sin\\theta\\sin\\phi, \\cos\\theta)$. Thus, $\\vec{\\beta}\\cdot\\vec{n} = \\beta n_x = \\beta\\sin\\theta\\cos\\phi$.\n\nThe rest-frame power distribution is given as:\n$$\n\\left(\\frac{dP'}{d\\Omega'}\\right) = K (3\\cos^2\\theta' - 1)^2\n$$\nwhere $K = \\frac{5P_0'}{16\\pi}$. To use this, we must express $\\cos\\theta'$ in terms of the lab-frame angles $(\\theta, \\phi)$.\n\n**2. Relativistic Aberration**\n\nThe relation between the direction vectors $\\vec{n}$ and $\\vec{n}'$ is given by the relativistic aberration formulas. For a velocity along the $x$-axis, the components of $\\vec{n}'$ are:\n$$\nn'_x = \\frac{n_x - \\beta}{1-\\beta n_x}, \\quad n'_y = \\frac{n_y}{\\gamma(1-\\beta n_x)}, \\quad n'_z = \\frac{n_z}{\\gamma(1-\\beta n_x)}\n$$\nThe quadrupole's symmetry axis is the $z$-axis, so $\\theta'$ is the angle with respect to the $z'$-axis. Therefore, $\\cos\\theta' = n'_z$.\n$$\n\\cos\\theta' = \\frac{n_z}{\\gamma(1-\\beta n_x)} = \\frac{\\cos\\theta}{\\gamma(1-\\beta\\sin\\theta\\cos\\phi)}\n$$\n\n**3. The Exact Expression for Power Distribution**\n\nSubstituting the expression for $\\cos\\theta'$ into the rest-frame power distribution formula, and then into the transformation equation:\n$$\n\\frac{dP}{d\\Omega} = \\frac{K}{\\gamma^4(1-\\beta n_x)^4} \\left( 3\\left[\\frac{\\cos\\theta}{\\gamma(1-\\beta n_x)}\\right]^2 - 1 \\right)^2\n$$\n$$\n= \\frac{K}{\\gamma^4(1-\\beta n_x)^4} \\frac{1}{\\gamma^4(1-\\beta n_x)^4} \\left( 3\\cos^2\\theta - \\gamma^2(1-\\beta n_x)^2 \\right)^2\n$$\n$$\n= \\frac{K}{\\gamma^8(1-\\beta n_x)^8} \\left( 3\\cos^2\\theta - \\gamma^2(1-\\beta n_x)^2 \\right)^2\n$$\n\n**4. Expansion in powers of $\\beta$**\n\nWe need to expand this expression up to order $\\beta^2$. First, let's expand the terms involving $\\gamma$ and powers of $(1-\\beta n_x)$.\n$\\gamma = (1-\\beta^2)^{-1/2} \\approx 1 + \\frac{1}{2}\\beta^2$.\n$\\gamma^2 \\approx 1+\\beta^2$.\n$\\gamma^{-8} = (1-\\beta^2)^4 \\approx 1-4\\beta^2$.\n\nThe denominator factor is:\n$$\n\\frac{1}{(1-\\beta n_x)^8} \\approx 1 + 8(\\beta n_x) + \\frac{8 \\cdot 9}{2!}(\\beta n_x)^2 + \\dots = 1 + 8\\beta n_x + 36\\beta^2 n_x^2\n$$\nSo the full pre-factor is:\n$$\n\\frac{1}{\\gamma^8(1-\\beta n_x)^8} \\approx (1-4\\beta^2)(1 + 8\\beta n_x + 36\\beta^2 n_x^2) \\approx 1 + 8\\beta n_x + (36n_x^2 - 4)\\beta^2 + \\mathcal{O}(\\beta^3)\n$$\nNext, let's expand the term in the parenthesis in the numerator. Let $A = 3\\cos^2\\theta - 1$.\n$$\nX = 3\\cos^2\\theta - \\gamma^2(1-\\beta n_x)^2 = (A+1) - \\gamma^2(1-2\\beta n_x + \\beta^2 n_x^2)\n$$\nUsing $\\gamma^2 \\approx 1+\\beta^2$:\n$$\nX \\approx (A+1) - (1+\\beta^2)(1-2\\beta n_x + \\beta^2 n_x^2)\n$$\n$$\n\\approx (A+1) - (1-2\\beta n_x + \\beta^2 n_x^2 + \\beta^2) = A + 2\\beta n_x - (n_x^2+1)\\beta^2\n$$\nNow, we square this expression, keeping terms up to $\\beta^2$:\n$$\nX^2 \\approx \\left[ A + (2\\beta n_x - (n_x^2+1)\\beta^2) \\right]^2\n$$\n$$\n\\approx A^2 + 2A(2\\beta n_x - (n_x^2+1)\\beta^2) + (2\\beta n_x)^2 + \\mathcal{O}(\\beta^3)\n$$\n$$\n\\approx A^2 + 4A n_x \\beta + \\left(4n_x^2 - 2A(n_x^2+1)\\right)\\beta^2\n$$\n$$\n= A^2 + 4A n_x \\beta + \\left( (4-2A)n_x^2 - 2A \\right)\\beta^2\n$$\n\n**5. Combine Expansions**\n\nNow multiply the expanded pre-factor and the expanded numerator term:\n$$\n\\frac{dP}{d\\Omega} \\approx K \\left[ 1 + 8\\beta n_x + (36n_x^2 - 4)\\beta^2 \\right] \\left[ A^2 + 4A n_x \\beta + \\left( (4-2A)n_x^2 - 2A \\right)\\beta^2 \\right]\n$$\nWe collect terms order by order in $\\beta$:\n- **Order $\\beta^0$**: $K A^2$\n- **Order $\\beta^1$**: $K \\left[ (8n_x)A^2 + 4A n_x \\right]\\beta = K \\left[ (8A^2 + 4A)n_x \\right]\\beta = 4K A(2A+1)n_x \\beta$\n- **Order $\\beta^2$**:\n$$\nK \\left[ (36n_x^2-4)A^2 + (8n_x)(4An_x) + ((4-2A)n_x^2 - 2A) \\right]\\beta^2\n$$\n$$\n= K \\left[ 36A^2n_x^2 - 4A^2 + 32An_x^2 + 4n_x^2 - 2An_x^2 - 2A \\right]\\beta^2\n$$\n$$\n= K \\left[ (36A^2 + 30A + 4)n_x^2 - (4A^2 + 2A) \\right]\\beta^2\n$$\n$$\n= 2K \\left[ (18A^2 + 15A + 2)n_x^2 - A(2A+1) \\right]\\beta^2\n$$\nThe quadratic term $18A^2 + 15A + 2$ can be factored as $(3A+2)(6A+1)$.\nSo the $\\beta^2$ coefficient is $2K \\left[ (3A+2)(6A+1)n_x^2 - A(2A+1) \\right]$.\n\n**6. Final Result**\n\nCombining all terms and substituting $K = \\frac{5P_0'}{16\\pi}$, we get the final expression for the angular power distribution:\n$$\n\\frac{dP}{d\\Omega}(\\theta,\\phi) \\approx K\\left[ A^2 + 4A(2A+1) n_x \\beta + 2\\left( (3A+2)(6A+1)n_x^2 - A(2A+1) \\right)\\beta^2 \\right]\n$$\n$$\n\\frac{dP}{d\\Omega}(\\theta,\\phi) = \\frac{5P_0'}{16\\pi} \\left[ A^2 + 4\\beta n_x A(2A+1) + 2\\beta^2 \\left( n_x^2(3A+2)(6A+1) - A(2A+1) \\right) \\right]\n$$\nwhere $A = 3\\cos^2\\theta - 1$ and $n_x = \\sin\\theta\\cos\\phi$.", "answer": "\n$$\n\\boxed{\\frac{5P_0'}{16\\pi} \\left[ A^2 + 4\\beta n_x A(2A+1) + 2\\beta^2 \\left( n_x^2(3A+2)(6A+1) - A(2A+1) \\right) \\right]}\n$$\n"}]}