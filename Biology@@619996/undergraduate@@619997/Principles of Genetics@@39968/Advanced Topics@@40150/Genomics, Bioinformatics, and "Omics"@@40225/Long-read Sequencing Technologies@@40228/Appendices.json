{"hands_on_practices": [{"introduction": "The primary goal of *de novo* genome sequencing is to construct the most complete and continuous representation of an organism's chromosomes. A key metric for measuring assembly quality is the N50 statistic, which reflects the contiguity of the assembled scaffolds. This exercise asks you to calculate and compare the N50 values from two hypothetical genome assemblies to understand the dramatic impact of sequencing read length on assembly quality and learn why long-read technologies are revolutionary for overcoming the challenges of repetitive genomic regions.", "problem": "A team of molecular biologists is studying the genome of a newly discovered fungal species. The genome is estimated to be approximately 20 megabases (Mb) in size. To create a reference genome, they employ two different Deoxyribonucleic Acid (DNA) sequencing and assembly pipelines, resulting in two distinct draft assemblies, which they label Assembly A and Assembly B.\n\nThe quality of a genome assembly is often measured by its contiguity, which can be quantified using the N50 statistic. The N50 is defined as the minimum contig length such that at least half of the total assembled genome sequence is contained in contigs of that length or longer. For these calculations, assume 1 megabase (Mb) = 1,000 kilobases (kb).\n\nThe contents of the two assemblies are as follows:\n- **Assembly A** consists of: 5 contigs of 100 kb, 10 contigs of 80 kb, 20 contigs of 60 kb, 150 contigs of 50 kb, 100 contigs of 40 kb, and 300 contigs of 20 kb.\n- **Assembly B** consists of: one 7 Mb contig, one 5 Mb contig, one 3 Mb contig, one 2 Mb contig, one 1 Mb contig, and four 0.5 Mb contigs.\n\nBased on an analysis of these two assemblies, which one of the following statements is the most accurate conclusion regarding the sequencing technologies used?\n\nA. Assembly A was likely generated using long-read sequencing because it has a greater number of contigs, indicating more comprehensive coverage of the genome.\n\nB. Assembly A was likely generated using long-read sequencing because its N50 value is smaller, which is characteristic of the higher error rates in long reads.\n\nC. Assembly B was likely generated using long-read sequencing because a larger N50 indicates better assembly contiguity, a primary advantage of using longer reads to span repetitive regions.\n\nD. Assembly B was likely generated using long-read sequencing because its total assembled size is exactly 20 Mb, matching the estimate perfectly.\n\nE. It is impossible to determine the sequencing technology from this data alone; information about read error rates is also required.", "solution": "The goal of this problem is to compare two genome assemblies, calculate their respective N50 values, and use this information to infer which sequencing technology (long-read vs. short-read) was likely used for each.\n\nFirst, we must calculate the total assembled size for each assembly to verify they are comparable and to find the halfway point for the N50 calculation.\n\nFor Assembly A, the total size is the sum of the lengths of all its contigs:\nTotal size A = (5 * 100 kb) + (10 * 80 kb) + (20 * 60 kb) + (150 * 50 kb) + (100 * 40 kb) + (300 * 20 kb)\nTotal size A = 500 kb + 800 kb + 1,200 kb + 7,500 kb + 4,000 kb + 6,000 kb\nTotal size A = 20,000 kb = 20 Mb.\n\nFor Assembly B, the total size is:\nTotal size B = (1 * 7 Mb) + (1 * 5 Mb) + (1 * 3 Mb) + (1 * 2 Mb) + (1 * 1 Mb) + (4 * 0.5 Mb)\nTotal size B = 7 Mb + 5 Mb + 3 Mb + 2 Mb + 1 Mb + 2 Mb\nTotal size B = 20 Mb.\n\nBoth assemblies have a total size of 20 Mb. For the N50 calculation, we need to find the contig length at which the cumulative size of contigs of that length or greater reaches 50% of the total assembly size, which is 0.5 * 20 Mb = 10 Mb.\n\nNow, let's calculate the N50 for Assembly A. We need to work in kilobases (kb). The target cumulative size is 10,000 kb. We sort the contig groups by size in descending order and sum their total lengths:\n1.  Contigs of 100 kb: 5 * 100 kb = 500 kb. Cumulative sum = 500 kb.\n2.  Contigs of 80 kb: 10 * 80 kb = 800 kb. Cumulative sum = 500 kb + 800 kb = 1,300 kb.\n3.  Contigs of 60 kb: 20 * 60 kb = 1,200 kb. Cumulative sum = 1,300 kb + 1,200 kb = 2,500 kb.\n4.  Contigs of 50 kb: 150 * 50 kb = 7,500 kb. Cumulative sum = 2,500 kb + 7,500 kb = 10,000 kb.\n\nThe cumulative sum reaches the 10,000 kb mark exactly upon the inclusion of all contigs of 50 kb. By definition, the N50 is the minimum contig length in this set, so the N50 for Assembly A is 50 kb.\n\nNext, let's calculate the N50 for Assembly B. The target cumulative size is 10 Mb. We sort the contigs by size in descending order and sum their lengths:\n1.  Contig of 7 Mb: 1 * 7 Mb = 7 Mb. Cumulative sum = 7 Mb.\n2.  Contig of 5 Mb: 1 * 5 Mb = 5 Mb. Cumulative sum = 7 Mb + 5 Mb = 12 Mb.\n\nThe cumulative sum (12 Mb) surpasses the 10 Mb target upon the inclusion of the 5 Mb contig. Therefore, the N50 for Assembly B is the length of this contig, which is 5 Mb.\n\nNow we compare the two assemblies.\n- Assembly A: N50 = 50 kb = 0.05 Mb\n- Assembly B: N50 = 5 Mb\n\nAssembly B's N50 is 100 times larger than Assembly A's N50. A higher N50 indicates a more contiguous and less fragmented assembly. Long-read sequencing technologies (e.g., PacBio, Oxford Nanopore) produce very long reads that can span repetitive or complex regions of the genome. These regions are difficult to assemble from short reads (e.g., Illumina), leading to breaks in the assembly and a large number of smaller contigs. Consequently, long-read technologies typically yield assemblies with much higher contiguity and larger N50 values. Assembly B, with its massive 5 Mb N50, is characteristic of a long-read assembly. Assembly A, with its highly fragmented nature and low 50 kb N50, is characteristic of a short-read assembly.\n\nFinally, let's evaluate the given options:\nA: Incorrect. A greater number of contigs indicates a more fragmented, lower-quality assembly, which is typical of short-read technologies, not long-read.\nB: Incorrect. A smaller N50 indicates a more fragmented assembly, which is not a feature of a successful long-read assembly project. The primary advantage of long reads is achieving a high N50.\nC: Correct. Assembly B has a drastically larger N50 (5 Mb) compared to Assembly A (50 kb). This superior contiguity is the hallmark achievement of long-read sequencing technologies, which excel at resolving repetitive genomic elements that typically fragment assemblies built from short reads.\nD: Incorrect. Both assemblies sum to the same total size (20 Mb), so this is not a distinguishing feature between them.\nE: Incorrect. While other metrics like error rates are important for a full picture of assembly quality, the difference in N50 is so dramatic and is such a direct consequence of read length that it serves as a very strong primary indicator of the underlying sequencing technology.\n\nTherefore, the most accurate conclusion is that Assembly B was likely generated using long-read sequencing.", "answer": "$$\\boxed{C}$$", "id": "1501367"}, {"introduction": "Beyond assembling a linear sequence of A's, T's, C's, and G's, a crucial task in genomics is to determine the complete structure of genetic elements, which are often circular, like plasmids and many bacterial chromosomes. Short sequencing reads can make it difficult to distinguish a large circular molecule from a long linear one. This problem explores how a single long read, capable of sequencing an entire plasmid in one pass, provides definitive evidence of circularity through a characteristic \"split-alignment\" signature.", "problem": "A researcher is studying a novel bacterium and has used computational methods to assemble its genome. The assembly includes a putative circular plasmid with a total length of 15,000 base pairs (bp). To verify the assembly and confirm that the plasmid is indeed circular, the researcher performs long-read sequencing on the bacterium's genetic material. A single, high-quality read is obtained that is approximately 15,000 bp long and appears to span the entire plasmid molecule.\n\nThe assembled 15,000 bp plasmid sequence is used as a linear reference. This reference is simply the circular sequence \"unrolled\" starting from an arbitrary nucleotide, which is designated as position 1, and ending at position 15,000. The long read, being a linear sequence of nucleotides generated from the circular plasmid, also has a starting point, but this start is random and does not necessarily correspond to position 1 of the reference.\n\nWhen this single long read is computationally aligned to the linear reference sequence, which of the following descriptions best characterizes the expected alignment pattern that would confirm the plasmid's circularity?\n\nA. The 15,000 bp read aligns contiguously, starting at position 1 of the reference and ending precisely at position 15,000.\n\nB. The read is visualized as being split into two segments. The beginning of the read aligns to a region near the end of the reference sequence, while the end of the read aligns to a region near the beginning of the reference sequence.\n\nC. The read aligns to the exact middle of the reference sequence, leaving approximately 7,500 bp of the reference unaligned at both the beginning and the end.\n\nD. The read aligns from position 1 to position 15,000 of the reference, but shows a large deletion in its central part, indicating a missing segment.\n\nE. The read aligns to the reference, but a large central portion of the read is inverted relative to the reference sequence.", "solution": "Let the circular plasmid have total length $L=15000$ base pairs. A linear reference for a circular molecule is obtained by choosing an arbitrary cut between positions $L$ and $1$ and listing the circular sequence from position $1$ to position $L$. A single long read produced from the circular plasmid starts at a random position on the circle; denote this start by an offset $s$ relative to the linear reference, where $s\\in\\{1,\\dots,L\\}$.\n\nBecause the read spans the entire circle, its sequence equals the circular sequence starting at position $s$ and proceeding for $L$ consecutive bases. In coordinates of the linear reference, that implies the read’s prefix corresponds to the interval $[s,L]$ and the read’s suffix corresponds to the interval $[1,s-1]$. When aligning to the linearized reference, this produces a split alignment across the artificial breakpoint of the linear reference: the beginning of the read aligns near the end of the reference (positions close to $L$), and the end of the read aligns near the beginning of the reference (positions close to $1$).\n\nOnly in the special case $s=1$ would the read align contiguously from position $1$ through position $L$ on the linear reference; this is not the general expectation for a random starting point. Therefore:\n- Option A would occur only if $s=1$, which is a special case rather than the characteristic pattern for a circular molecule.\n- Option B matches the expected split alignment across the reference ends caused by wrapping around the circular origin, which is the hallmark confirming circularity.\n- Option C describes an internal alignment block with flanking unaligned regions, not the wraparound signature of circularity.\n- Option D suggests a deletion rather than circular wraparound.\n- Option E suggests an inversion rather than circular wraparound.\n\nThus, the alignment pattern confirming circularity is the split alignment with the read’s beginning mapping near the end of the reference and its end mapping near the beginning, corresponding to Option B.", "answer": "$$\\boxed{B}$$", "id": "1501345"}, {"introduction": "A powerful and cost-effective strategy in genomics is hybrid assembly, which leverages the high accuracy of short reads to build reliable contigs and then uses long reads to order and orient these contigs into chromosome-scale scaffolds. A critical step in this process is \"gap-bridging,\" where a long read spans the unknown sequence between two contigs. This thought experiment guides you through a probabilistic calculation to determine the likelihood of successfully bridging a gap, a fundamental consideration when designing a long-read sequencing experiment for genome finishing.", "problem": "In a de novo genome assembly project for a novel extremophilic archaeon, an initial analysis using short-read sequencing has produced a high-quality set of contigs. To arrange these contigs into a complete chromosome, a bioinformatician employs long-read sequencing technology.\n\nConsider two specific contigs, Contig A and Contig B, that are believed to be adjacent in the genome. Based on other evidence, they are known to be separated by a single contiguous gap of length $L_g = 12,000$ base pairs (bp).\n\nTo bridge this gap, long-read sequencing is performed using a Pacific Biosciences (PacBio) instrument, which generates reads of a constant length $L_r = 15,000$ bp. The total dataset provides an average sequencing coverage of $C = 5\\text{x}$ across the genome.\n\nA \"bridging read\" is defined as a single long read that completely spans the gap between Contig A and Contig B. For this to occur, a read's starting point must be located in a position such that the read covers the entire $L_g$ region of the gap. Assume that the start positions of the long reads are randomly distributed across the genome, and the number of reads that successfully bridge the gap can be modeled as a random variable following a Poisson distribution.\n\nCalculate the probability that you obtain at least one bridging read for this specific gap from the sequencing experiment. Provide your answer as a decimal rounded to four significant figures.", "solution": "Let the genome length be $G$ and the total number of long reads be $N$. The average coverage is defined by\n$$\nC=\\frac{N L_{r}}{G}\\quad\\Rightarrow\\quad N=\\frac{C G}{L_{r}}.\n$$\nA read of length $L_{r}$ will bridge a gap of length $L_{g}$ if its start position falls within a window of length $L_{r}-L_{g}$ that ensures the read fully covers the entire gap. With start positions uniformly distributed over the genome, the probability that a given read is a bridging read is\n$$\np=\\frac{L_{r}-L_{g}}{G}.\n$$\nThe expected number of bridging reads is then\n$$\n\\lambda=N p=\\frac{C G}{L_{r}}\\cdot\\frac{L_{r}-L_{g}}{G}=C\\,\\frac{L_{r}-L_{g}}{L_{r}}.\n$$\nUnder the Poisson model, the probability of obtaining at least one bridging read is\n$$\nP(\\text{at least one})=1-\\exp(-\\lambda).\n$$\nSubstituting $C=5$, $L_{r}=15000$, and $L_{g}=12000$,\n$$\n\\lambda=5\\left(1-\\frac{12000}{15000}\\right)=5\\cdot 0.2=1,\n$$\nso\n$$\nP=1-\\exp(-1)\\approx 0.6321\\ \\text{(to four significant figures)}.\n$$", "answer": "$$\\boxed{0.6321}$$", "id": "1501370"}]}