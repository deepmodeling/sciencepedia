{"hands_on_practices": [{"introduction": "This problem addresses the cornerstone of experimental design in transcriptomics: the necessity of biological replicates. Before any data is generated, understanding why a single sample per condition is insufficient for statistical inference is crucial for designing a meaningful and robust study. This exercise will help you grasp the fundamental distinction between a drug's true effect and random biological variation, a concept that underpins all downstream statistical analysis [@problem_id:2336590].", "problem": "A junior researcher is designing an experiment to study the effect of a new drug on gene expression in a human cancer cell line. The plan is to use Ribonucleic Acid (RNA) sequencing, a technology that measures the expression level of thousands of genes simultaneously. The experimental design consists of two groups:\n\n1.  **Control Group:** One culture flask of cancer cells grown under standard conditions.\n2.  **Treatment Group:** One culture flask of cancer cells grown with the new drug added to the medium.\n\nAfter culturing, the researcher will extract the RNA from each flask, prepare sequencing libraries, and perform RNA-Seq. The goal is to identify genes whose expression levels are significantly altered by the drug.\n\nWhich of the following statements identifies the most fundamental statistical limitation of this experimental design for drawing conclusions about the drug's effect?\n\nA. The experiment cannot produce a list of differentially expressed genes because a fold-change calculation is impossible with only one measurement per group.\n\nB. The absence of technical replicates for each condition means it is impossible to assess variability introduced by the sequencing machine.\n\nC. A single culture flask provides insufficient total RNA for a standard sequencing run, likely leading to a failed experiment.\n\nD. The design cannot distinguish the true effect of the drug from the inherent, random biological variability that exists between any two individual cell cultures, making statistical tests of significance invalid.\n\nE. The data cannot be properly normalized, as methods like Transcripts Per Million (TPM) require at least three replicates per condition to be calculated.", "solution": "The core inferential goal is to test whether observed differences in gene expression between conditions are attributable to the drug rather than to random biological variability among independently cultured samples. Any valid statistical test of differential expression requires an estimate of the within-group biological variance, typically denoted $\\sigma^{2}$, obtained from biological replicates within each condition. With one culture flask per group ($n=1$ per condition), the within-condition variance cannot be estimated, so any test statistic comparing groups lacks a denominator that reflects biological noise, rendering $p$-values and claims of significance invalid for distinguishing drug effects from inherent culture-to-culture variability.\n\nEvaluate each option:\n\nA is incorrect because one can compute a fold change between two single measurements (e.g., log fold change); what is not possible is a valid significance test without variance estimates, not the fold-change itself.\n\nB is not the most fundamental limitation. While technical replicates can quantify machine-induced variability, modern RNA-seq pipelines typically prioritize biological replicates; sequencing technical variance is usually smaller and can be controlled by standardized protocols. The critical limitation here is biological, not technical.\n\nC is incorrect; a single culture flask typically yields ample RNA for library preparation and sequencing. Availability of input material is not the limiting factor.\n\nD is correct. With only one biological sample per condition, the experiment cannot separate drug effects from inherent biological variability across cultures. Without biological replicates, the within-group variance is unestimable, and statistical significance cannot be validly assessed.\n\nE is incorrect; normalization methods such as TPM are computed per sample and do not require replicates.\n\nTherefore, the most fundamental statistical limitation is the inability to estimate biological variability necessary for valid significance testing, as stated in D.", "answer": "$$\\boxed{D}$$", "id": "2336590"}, {"introduction": "After running an experiment, the first step is often to assess the overall quality and structure of the data. Principal Component Analysis (PCA) is a powerful tool for this exploratory step, helping to visualize the major sources of variation in a high-dimensional dataset like transcriptomics. This practice exercise will guide you in interpreting a typical PCA plot, learning how to connect visual patterns of sample clustering and separation to conclusions about experimental success and data reliability [@problem_id:2336609].", "problem": "A molecular biologist is investigating the transcriptional response of human fibroblast cells to a new growth factor. The experiment consists of two conditions: a 'control' group of cells grown in standard media and a 'treatment' group grown in media supplemented with the growth factor. For each condition, three independent biological replicates were prepared, resulting in a total of six samples. After 24 hours, Ribonucleic Acid (RNA) was extracted from all samples and subjected to RNA-Seq to quantify the expression levels of all genes.\n\nTo get a high-level overview of the data and assess its quality, the biologist performs Principal Component Analysis (PCA), a statistical procedure that reduces the dimensionality of the data by transforming the gene expression values into a set of new variables called principal components. These components are ordered so that the first few retain most of the variation present in the original data. When the samples are plotted based on their values for the first two principal components (PC1 and PC2), the biologist observes the following:\n1.  The three samples from the 'control' group form a very tight, compact cluster.\n2.  The three samples from the 'treatment' group also form a very tight, compact cluster.\n3.  The 'control' cluster and the 'treatment' cluster are located far apart from each other on the plot.\n\nBased on this PCA plot, what is the most appropriate conclusion about the experiment and the quality of the data?\n\nA. The data quality is likely high. The tight clustering within each group suggests low variability among replicates, and the separation between groups indicates a clear and consistent effect of the growth factor on gene expression.\n\nB. The experiment likely failed because the tight clustering indicates that the growth factor had no effect, and all samples are essentially identical. The separation between groups is likely a computational artifact.\n\nC. The data reveals a significant technical problem, often called a batch effect. The clear separation is not due to the growth factor but rather a systematic error introduced during sample preparation or sequencing that happened to correlate with the experimental groups.\n\nD. The data quality is poor. The tight clustering within groups suggests there was not enough biological variation, and the experiment may not be representative of the true biological response.\n\nE. The experiment shows high variability within the treatment group and low variability between the control and treatment groups, suggesting an inconsistent and weak response to the growth factor.", "solution": "We are asked to interpret a principal component analysis (PCA) plot of RNA-seq gene expression profiles from two conditions with three biological replicates each. PCA is a dimensionality-reduction technique that maps high-dimensional data (gene expression vectors per sample) into a low-dimensional space defined by orthogonal directions (principal components) that are ordered by explained variance. In this framework, distances between samples in the PCA plot reflect major sources of variance in the data, while cluster compactness reflects within-group variability.\n\nGiven the observations:\n1. The three control replicates form a tight, compact cluster. This implies low within-group variability among controls, consistent with good technical quality and reproducible sample processing. In PCA terms, the variance of the control replicates across the leading principal components is small, suggesting that technical noise and uncontrolled biological variation within controls are minimal.\n2. The three treatment replicates also form a tight, compact cluster. This similarly indicates low within-group variability for the treated samples, again consistent with high data quality and reproducibility.\n3. The control and treatment clusters are far apart from each other on the PCA plot. In PCA, separation between groups along the leading components implies that the dominant source of variance in the data corresponds to differences between conditions. When the groups separate clearly, it indicates a consistent, systematic shift in the multivariate gene expression profiles attributable to the experimental manipulation (here, the growth factor).\n\nEvaluating the answer choices against these principles:\n- Choice A states that tight within-group clustering suggests low variability among replicates (high quality), and separation between groups indicates a clear, consistent effect of the treatment. This directly matches the standard interpretation of PCA in well-controlled transcriptomic experiments.\n- Choice B claims failure due to no effect and calls the separation a computational artifact. This contradicts the observed clear separation; tight clustering does not indicate no effect, and PCA separation is not, by default, an artifact without external evidence.\n- Choice C asserts a batch effect. While batch effects can cause separation, there is no information indicating confounding or batch structure aligned with condition. The observed pattern is equally, and more parsimoniously, explained by the intended biological effect, especially given tight replicate clustering within each condition.\n- Choice D claims poor data quality due to insufficient biological variation; however, biological replicates are expected to be similar under the same condition, and tight clusters are typically a sign of good quality and controlled experimental variability.\n- Choice E contradicts the observations by asserting high within-treatment variability and low between-group variability; this is the opposite of what is described.\n\nTherefore, the most appropriate conclusion is that the data quality is high and the growth factor induces a clear and consistent transcriptional response, corresponding to choice A.", "answer": "$$\\boxed{A}$$", "id": "2336609"}, {"introduction": "Identifying \"significant\" changes from thousands of measurements is a central challenge in RNA-seq analysis, requiring careful statistical treatment. This introduces the problem of multiple hypothesis testing, where naively applying standard $p$-value thresholds can lead to a high number of false positives. This exercise explores the critical difference between the traditional $p$-value and the False Discovery Rate (FDR), empowering you to make more informed decisions about which genes to report as genuinely differentially expressed [@problem_id:2336625].", "problem": "A molecular biology researcher is conducting an RNA-Seq experiment to identify genes that are differentially expressed in a drug-treated cancer cell line compared to an untreated control. The analysis involves performing a statistical test for each of the 20,000 genes measured, resulting in a p-value for every gene. The researcher identifies 1,000 genes with a p-value less than 0.05.\n\nTo account for the large number of tests performed (a multiple hypothesis testing problem), the researcher also calculates a q-value for each gene. The q-value represents the False Discovery Rate (FDR) associated with a particular p-value threshold. The researcher is now considering two different strategies for reporting their list of \"significant\" genes:\n\n1.  **Strategy P:** Report all genes with a p-value  0.05.\n2.  **Strategy Q:** Report all genes with a q-value (FDR)  0.05.\n\nWhich of the following statements provides the most accurate interpretation and comparison of the expected outcomes of these two strategies?\n\nA. Strategy P implies that for each of the 1,000 significant genes, there is a 5% probability that it is truly differentially expressed. Strategy Q is more conservative and implies that the overall probability of making at least one false discovery among the significant genes is 5%.\n\nB. Strategy P and Strategy Q are conceptually similar. In a large-scale experiment like this, applying a threshold of 0.05 will yield approximately the same number of false positives regardless of whether p-value or FDR is used.\n\nC. Strategy P implies that if the experiment were repeated many times on a non-responsive cell line (where no genes are truly affected), we would expect to call about 5% of the 1,000 significant genes (i.e., 50 genes) false positives. Strategy Q implies that about 5% of the genes *called significant* by this method are expected to be false positives.\n\nD. Strategy P implies that for any gene with a p-value  0.05, there is a less than 5% chance that the null hypothesis (no differential expression) is true for that gene. Strategy Q is a method to ensure that the reported genes also have a large biological effect size (fold-change).\n\nE. Strategy P operates under a framework where, if no genes were truly differentially expressed, we would expect to find about 5% of all 20,000 genes tested (i.e., 1,000 genes) as significant just by chance. Strategy Q provides a different guarantee: of the total list of genes declared significant, we should expect approximately 5% of them to be false positives.", "solution": "Define the total number of hypotheses tested as $m=20000$. Let $m_{0}$ be the (unknown) number of true null hypotheses and $m_{1}=m-m_{0}$ be the number of true alternatives. Let $R$ be the total number of rejections (called significant), $V$ the number of false positives (Type I errors), and $S=R-V$ the number of true positives.\n\nStrategy P uses an unadjusted per-test significance threshold $\\alpha=0.05$ on $p$-values. By the definition of Type I error, for each true null hypothesis, the probability of rejection is $\\alpha$. Therefore, the expected number of false positives under Strategy P is\n$$\n\\mathbb{E}[V]=\\alpha m_{0}.\n$$\nIn the special case where the global null holds (no true effects), $m_{0}=m$, so\n$$\n\\mathbb{E}[V]=\\alpha m=0.05\\times 20000=1000,\n$$\nand all rejections are false positives. In general, Strategy P does not control the proportion of false discoveries among the rejected hypotheses; that proportion is $V/R$ when $R0$, and its expectation is not guaranteed to be small. Moreover, a $p$-value is defined as $P(\\text{data as or more extreme} \\mid H_{0})$ and is not the posterior probability $P(H_{0}\\mid \\text{data})$, so interpreting $p0.05$ as “less than $0.05$ probability that the null is true” is incorrect.\n\nStrategy Q uses $q$-values, where for each test the $q$-value is the minimum false discovery rate (FDR) at which that test would be called significant. The false discovery rate is defined as\n$$\n\\mathrm{FDR}=\\mathbb{E}\\!\\left[\\frac{V}{\\max(R,1)}\\right],\n$$\nwith the convention that $V/\\max(R,1)=0$ when $R=0$. Thresholding at $q0.05$ corresponds to controlling the FDR at level $0.05$, implying that, in expectation, the proportion of false discoveries among the set of reported significant genes is about $0.05$. FDR control does not control the family-wise error rate (FWER), defined as\n$$\n\\mathrm{FWER}=P(V\\geq 1),\n$$\nwhich is a different and typically more stringent criterion.\n\nEvaluate the options:\n- A is incorrect: a $p$-value does not give $P(H_{0}\\mid \\text{data})$, and FDR control does not ensure $\\mathrm{FWER}=0.05$.\n- B is incorrect: per-test $p0.05$ and FDR $0.05$ are not equivalent; they generally yield different numbers of discoveries and false positives.\n- C is incorrect in its first claim: under the global null, Strategy P would yield about $0.05\\times 20000=1000$ discoveries and all would be false positives, not $0.05$ of the $1000$. Its second claim correctly describes FDR but the option as a whole is false.\n- D is incorrect: $p0.05$ does not imply $P(H_{0}\\mid \\text{data})0.05$, and FDR control does not ensure large effect sizes.\n- E is correct: under the global null, Strategy P would yield about $0.05$ of all tests (about $1000$) as significant by chance, and Strategy Q’s $q0.05$ implies that, among the reported significant genes, the expected fraction that are false positives is about $0.05$.\n\nTherefore, the most accurate statement is E.", "answer": "$$\\boxed{E}$$", "id": "2336625"}]}