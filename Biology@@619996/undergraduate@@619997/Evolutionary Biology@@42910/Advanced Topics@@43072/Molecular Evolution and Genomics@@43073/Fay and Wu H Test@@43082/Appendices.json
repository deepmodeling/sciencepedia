{"hands_on_practices": [{"introduction": "To effectively use any statistical test, we must first build an intuition for its core mechanism. This first exercise provides a thought experiment to solidify your understanding of how Fay and Wu's H statistic, calculated as $H = \\theta_{\\pi} - \\theta_{H}$, captures the signature of a selective sweep. By focusing on a simplified scenario dominated by a single high-frequency derived allele, you will explore why this specific pattern leads to a strongly negative H value.", "problem": "In population genetics, neutrality tests are used to detect deviations from the standard neutral model of molecular evolution, which can be indicative of natural selection. One such test is Fay and Wu's H test. This test compares two different estimators of the population mutation parameter, $4N_e\\mu$, where $N_e$ is the effective population size and $\\mu$ is the mutation rate.\n\nThe first estimator, $\\theta_\\pi$, is the average number of pairwise nucleotide differences between sequences in a sample. It is most sensitive to polymorphisms at intermediate frequencies.\n\nThe second estimator, $\\theta_H$, is based on the frequency of derived alleles (mutations that have arisen in the population relative to an outgroup species). It gives greater weight to high-frequency derived alleles.\n\nThe statistic is calculated as $H = \\theta_\\pi - \\theta_H$.\n\nImagine you are studying a gene in a large population. You collect and sequence this gene from 100 individuals. By comparing these sequences to the homologous gene from a closely related species (an outgroup), you identify all derived mutations. You observe several low-frequency derived mutations, but one particular derived mutation stands out: it is present in 98 out of the 100 sampled individuals. Assuming this high-frequency allele is the dominant feature of the genetic data, what would be the predicted sign of Fay and Wu's H statistic for this gene region?\n\nA. Strongly positive\n\nB. Strongly negative\n\nC. Approximately zero\n\nD. The sign cannot be determined without knowing the exact number of low-frequency mutations.", "solution": "Fay and Wu's statistic is defined as $H=\\theta_{\\pi}-\\theta_{H}$, where both $\\theta_{\\pi}$ and $\\theta_{H}$ are linear functionals of the site frequency spectrum of derived alleles. For a sample of size $n$, if $\\xi_{i}$ denotes the number of derived polymorphisms observed at frequency $i$ (with $1 \\leq i \\leq n-1$), the standard forms are\n$$\n\\theta_{\\pi}=\\frac{2}{n(n-1)}\\sum_{i=1}^{n-1}i(n-i)\\,\\xi_{i},\\qquad\n\\theta_{H}=\\frac{2}{n(n-1)}\\sum_{i=1}^{n-1}i^{2}\\,\\xi_{i}.\n$$\nThese weight functions show that $\\theta_{\\pi}$ is most influenced by intermediate frequencies (since $i(n-i)$ is maximized near $i\\approx n/2$), whereas $\\theta_{H}$ gives greater weight to high-frequency derived alleles (since $i^{2}$ grows with $i$).\n\nAssume the data are dominated by a single high-frequency derived mutation at count $i$ with $i$ close to $n$. Then the contributions to the two estimators are well approximated by\n$$\n\\theta_{\\pi}\\approx \\frac{2}{n(n-1)}\\,i(n-i)\\,\\xi_{i},\\qquad\n\\theta_{H}\\approx \\frac{2}{n(n-1)}\\,i^{2}\\,\\xi_{i}.\n$$\nHence,\n$$\nH\\approx \\frac{2}{n(n-1)}\\,\\xi_{i}\\,[i(n-i)-i^{2}]=\\frac{2}{n(n-1)}\\,\\xi_{i}\\,i\\,(n-2i).\n$$\nFor a high-frequency derived allele, one has $i> \\frac{n}{2}$, so $n-2i<0$, which implies $H<0$. Moreover, as $i$ approaches $n$ (i.e., the derived allele is at very high frequency), the factor $|n-2i|$ grows in magnitude, making $H$ strongly negative. The presence of several low-frequency derived mutations does not change this sign when the high-frequency derived allele dominates, because those low-frequency variants primarily increase $\\theta_{\\pi}$ relative to $\\theta_{H}$, while the dominant high-frequency variant makes $\\theta_{H}$ exceed $\\theta_{\\pi}$ by a large margin.\n\nTherefore, the predicted sign is strongly negative.", "answer": "$$\\boxed{B}$$", "id": "1928826"}, {"introduction": "In real-world data analysis, a single statistic rarely tells the whole story, as different evolutionary processes can sometimes produce similar patterns. This practice challenges you to act as a data detective, using the combined signals from Tajima's D and Fay and Wu's H to distinguish between a selective sweep and a change in population size. Understanding how these tests complement each other is a key skill for robust evolutionary inference.", "problem": "A population geneticist is investigating the evolutionary history of a specific gene in a species of marine copepod. They collect sequence data for this gene from a large, randomly sampled population. To infer the ancestral state of mutations, they also sequence the homologous gene from a closely related sister species, which serves as an outgroup.\n\nThe researcher calculates two well-known statistics that test for deviations from the standard neutral model of molecular evolution.\n1.  **Tajima's D**: This statistic compares two different estimates of population mutation rate, one based on the average number of pairwise nucleotide differences between sequences and another based on the total number of polymorphic sites. Its value reflects the allele frequency spectrum.\n2.  **Fay and Wu's H**: This statistic also examines the allele frequency spectrum but specifically incorporates information from the outgroup to distinguish between ancestral and derived alleles. It is particularly sensitive to the presence of high-frequency derived alleles.\n\nAfter analysis, the researcher finds that the gene has a statistically significant negative value for Tajima's D (D < 0). However, the value for Fay and Wu's H is found to be very close to zero and is not statistically significant.\n\nWhich of the following evolutionary scenarios provides the most plausible explanation for this specific combination of results?\n\nA. A recent classic selective sweep, where a new advantageous mutation has rapidly risen to high frequency or fixation.\n\nB. Long-term balancing selection maintaining multiple alleles at intermediate frequencies in the population.\n\nC. A recent and rapid expansion of the entire population.\n\nD. A recent population bottleneck that severely reduced the population size.\n\nE. Strong, pervasive purifying selection that consistently removes deleterious mutations from the gene.", "solution": "The problem asks us to interpret a specific combination of population genetic test statistics: a significantly negative Tajima's D and a Fay and Wu's H value near zero. To do this, we must understand what each statistic measures and what evolutionary forces cause them to deviate from zero.\n\nFirst, let's consider Tajima's D. This statistic is designed to detect an excess or deficit of rare alleles compared to the expectations of the standard neutral model.\n- A negative Tajima's D ($D < 0$) indicates an excess of low-frequency (rare) alleles in the sample. This pattern can be caused by two primary scenarios:\n    1.  A recent selective sweep (positive selection): When a beneficial mutation rapidly increases in frequency, it \"drags\" linked neutral variants with it, reducing diversity. Subsequently, new mutations arise on this successful genetic background. These new mutations have not had much time to drift to higher frequencies, so they exist as rare alleles, leading to a negative D.\n    2.  A rapid population expansion: As a population grows, many new mutations arise. Since most of these mutations are recent, they will be at low frequencies in the expanded population, resulting in a genome-wide excess of rare alleles and thus a negative Tajima's D.\n\nSecond, let's consider Fay and Wu's H. This statistic is also sensitive to the allele frequency spectrum but has a crucial difference: it uses an outgroup to polarize mutations into ancestral and derived states. It is specifically designed to detect an excess of high-frequency *derived* alleles.\n- A value of H near zero is consistent with the neutral model.\n- A significantly negative H ($H < 0$) indicates an excess of high-frequency derived alleles. This is considered a powerful and specific signature of a classic selective sweep. In a sweep, a new, beneficial *derived* mutation rises to a high frequency, creating exactly the pattern that a negative H detects.\n\nNow, we must synthesize the two observations: D < 0 and H ≈ 0.\n\nThe negative Tajima's D suggests that we are looking at either a selective sweep or a population expansion. We can use the Fay and Wu's H value to distinguish between these two possibilities.\n\nThe observed H statistic is near zero, not significantly negative. This implies that there is *no excess* of high-frequency derived alleles at this locus. This finding directly contradicts the primary expectation for a classic selective sweep, which would generate a strongly negative H value. Therefore, a selective sweep (option A) is an unlikely explanation.\n\nThe alternative cause for a negative D is population expansion. In this scenario, the entire population grows, leading to the accumulation of new, rare mutations across the entire genome. This demographic process explains the negative Tajima's D. Importantly, because this is a population-wide phenomenon and not selection acting on a specific beneficial derived allele, it does not create an excess of high-frequency derived alleles at any particular locus. Thus, Fay and Wu's H would be expected to remain near zero, which is exactly what was observed. This makes population expansion (option C) the most consistent explanation for the data.\n\nLet's briefly consider the other options:\n- **B. Balancing selection:** This process maintains alleles at intermediate frequencies, which leads to a *positive* Tajima's D. This is the opposite of what was observed.\n- **D. A population bottleneck:** A bottleneck tends to eliminate rare alleles, causing an excess of intermediate-frequency alleles among the survivors. This, like balancing selection, tends to produce a *positive* Tajima's D.\n- **E. Purifying selection:** This is the removal of deleterious alleles. While it is a ubiquitous force (also known as background selection), it does not typically produce the specific signal of D < 0 and H ≈ 0 as clearly and parsimoniously as population expansion does. Background selection can cause a negative D, but the combination is most classically interpreted as a demographic effect.\n\nTherefore, the combination of an excess of rare alleles (negative D) without an excess of high-frequency derived alleles (H near zero) strongly points to a demographic event—namely, population expansion—rather than a locus-specific selective event like a sweep.", "answer": "$$\\boxed{C}$$", "id": "1928814"}, {"introduction": "The signatures of selection are not permanently etched into the genome; they fade over time. This final practice explores the temporal limitations of the Fay and Wu's H test, which is defined here as $H = \\theta_{\\pi} - \\theta_H$, by considering a scenario where a selective sweep occurred in the distant past. You will reason through why new mutations and genetic drift can eventually erase the classic sweep signature, leading to a non-significant result even when selection did occur.", "problem": "A population geneticist is investigating a specific gene locus in a human population. Based on archeological and anthropological evidence, it is strongly hypothesized that this locus underwent a powerful selective sweep, where a highly advantageous allele and its linked genetic background rapidly rose to fixation approximately 100,000 years ago.\n\nTo find molecular evidence for this ancient event, the researcher sequences the gene locus from a large sample of individuals. They then apply the Fay and Wu's H test. This test is designed to detect selective sweeps by looking for a characteristic distortion in the site frequency spectrum. Specifically, it compares two estimators of population mutation rate: $\\theta_{\\pi}$, the average number of pairwise differences between sequences, and $\\theta_H$, an estimator based on the frequency of derived alleles (variants that have arisen via mutation from the ancestral state). A classic selective sweep creates an excess of high-frequency derived alleles, causing $\\theta_{\\pi}$ to be much smaller than $\\theta_H$, resulting in a significantly negative H statistic ($H = \\theta_{\\pi} - \\theta_H$). For this problem, we use the definition $H=\\theta_{\\pi}-\\theta_H$, which is expected to be negative after a sweep.\n\nTo the researcher's surprise, the calculated H statistic is close to zero and not statistically significant, offering no support for the selective sweep hypothesis. Assuming the ancient selective sweep did in fact occur, which of the following provides the most direct and primary explanation for why the H test failed to detect its signature after such a long period?\n\nA. Subsequent neutral mutations occurring after the sweep have accumulated in the region. Over time, these have created a new pool of low- and intermediate-frequency variants, causing the value of $\\theta_{\\pi}$ to increase and approach $\\theta_H$.\n\nB. The selective pressure that drove the sweep was relaxed, allowing the beneficial allele to drift to a lower frequency and erasing the signal.\n\nC. Recombination events have shuffled the gene locus so extensively that it is now in perfect linkage equilibrium, meaning no haplotypes exist.\n\nD. The outgroup species used to determine the ancestral state of alleles was too closely related, leading to an underestimation of derived allele frequencies.\n\nE. The effective population size has remained perfectly constant since the sweep, which is the null hypothesis condition for the H-test, thus a non-significant result is expected.", "solution": "We are asked why Fay and Wu’s H test, defined as $H=\\theta_{\\pi}-\\theta_{H}$, failed to detect an ancient selective sweep that occurred a long time ago, even though the sweep is assumed real. The key is how the site frequency spectrum (SFS) evolves with time after a completed sweep.\n\nBy definition, $\\theta_{\\pi}$ is the average number of pairwise differences and is an estimator of the population mutation rate $\\theta=4N_{e}\\mu$ under the standard neutral model, with $E[\\theta_{\\pi}]=\\theta$. The estimator $\\theta_{H}$ upweights high-frequency derived alleles; under the standard neutral model without selection and with correct polarization, $E[\\theta_{H}]=\\theta$ as well. Thus, under neutrality, $E[H]=E[\\theta_{\\pi}-\\theta_{H}]=E[\\theta_{\\pi}]-E[\\theta_{H}]=\\theta-\\theta=0$.\n\nImmediately after a classic hard sweep to fixation, coalescent trees in the swept region are shallow and star-like, making $\\theta_{\\pi}$ small. Meanwhile, the hitchhiking process can generate an excess of high-frequency derived variants, inflating $\\theta_{H}$. Consequently, right after the sweep, $H=\\theta_{\\pi}-\\theta_{H}<0$ is expected.\n\nHowever, as time $t$ elapses after fixation, new neutral mutations continuously arise on the now-fixed haplotype background at rate $\\mu$, and genetic drift and recombination act on them. The SFS gradually reverts toward its neutral form on the characteristic timescale of order $N_{e}$ generations. As this happens, the following changes occur:\n1. New mutations at low and intermediate frequencies accumulate, which increases the average number of pairwise differences. Hence $\\theta_{\\pi}(t)$ rises toward its neutral expectation $E[\\theta_{\\pi}]\\to\\theta$.\n2. The excess of high-frequency derived polymorphisms created by the sweep dissipates; after fixation, the segregating sites in the region are predominantly recent, and therefore mostly at low or intermediate frequencies. Because $\\theta_{H}$ heavily weights high-frequency derived variants, $\\theta_{H}(t)$ declines toward the neutral expectation $E[\\theta_{H}]\\to\\theta$.\n\nTherefore, for sufficiently ancient sweeps, the SFS in the region becomes indistinguishable from neutrality, and\n$$\nE[H(t)] \\;=\\; E[\\theta_{\\pi}(t)-\\theta_{H}(t)] \\;\\approx\\; \\theta-\\theta \\;=\\; 0,\n$$\nwhich explains a nonsignificant $H$ despite a true, but ancient, sweep. This is the most direct, primary reason for loss of power of the H test over long timescales: neutral variation re-accumulates and erodes the sweep-induced distortion of the SFS, driving $\\theta_{\\pi}$ back up and making it approach $\\theta_{H}$.\n\nNow we assess the options:\n- Option A states that subsequent neutral mutations have accumulated, creating low- and intermediate-frequency variants, raising $\\theta_{\\pi}$ and making it approach $\\theta_{H}$. This exactly matches the reasoning above and directly explains why $H$ returns to near zero for ancient sweeps.\n- Option B is incorrect because once an allele has fixed, relaxing selection does not cause its frequency to drift downward absent back mutation; fixation is absorbing under neutrality.\n- Option C mischaracterizes linkage equilibrium and haplotypes; recombination does not eliminate haplotypes, and while recombination contributes to decay of sweep signals, the primary driver of $H$ returning to zero is the re-accumulation of neutral polymorphism that restores the SFS, not the attainment of “no haplotypes.”\n- Option D concerns outgroup choice and polarization error. While mispolarization can bias $H$, the age of the sweep primarily erodes signal via SFS equilibration; “too closely related outgroup” is not the central explanation for failure after long times.\n- Option E is incorrect because a sweep produces a deviation from the neutral constant-size null; constancy of $N_{e}$ does not force $H$ to be nonsignificant if the sweep were recent. The lack of signal arises from temporal decay of the sweep signature, not from the null itself.\n\nHence the most direct and primary explanation is Option A.", "answer": "$$\\boxed{A}$$", "id": "1928815"}]}