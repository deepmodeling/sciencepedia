{"hands_on_practices": [{"introduction": "Before diving into complex simulations, it's essential to grasp how stochasticity is described analytically in simple systems. This exercise explores the most fundamental model of gene expression: a \"birth-death\" process where molecules are produced at a constant rate and degrade linearly. By solving the chemical master equation for its steady state, you will derive the resulting probability distribution, providing a foundational understanding of how inherent randomness shapes molecular counts in a cell.[@problem_id:1468478]", "problem": "In a synthetic biology experiment, a genetically engineered bacterium is designed to produce a fluorescent protein. The production of a single protein molecule is a stochastic event that occurs with a constant average rate of production, denoted by $k$. Each fluorescent protein molecule, once synthesized, can be independently and stochastically degraded. The probability per unit time that any single protein molecule is degraded is a constant, $\\gamma$. Let $n$ be the number of fluorescent protein molecules in the bacterium at a given time.\n\nAfter the system has been operating for a very long time and has reached a statistical equilibrium, what is the probability distribution, $P(n)$, of finding exactly $n$ fluorescent protein molecules in a single bacterium? Express your answer for $P(n)$ as a function of the number of molecules $n$, the production rate $k$, and the per-molecule degradation rate constant $\\gamma$.", "solution": "Let $P(n, t)$ be the probability of having $n$ molecules in the cell at time $t$. The state of the system is the integer $n$. We can model the time evolution of $P(n, t)$ using a chemical master equation, which accounts for the probability fluxes into and out of state $n$.\n\nThe two processes changing the number of molecules are:\n1.  **Production (Birth):** A new molecule is produced at a constant rate $k$. This process transitions the system from state $n-1$ to state $n$. The rate of this transition is $k$.\n2.  **Degradation (Death):** An existing molecule is degraded. If there are $n$ molecules, and each degrades independently with a rate constant $\\gamma$, the total rate of degradation for the cell is $n\\gamma$. This process transitions the system from state $n$ to state $n-1$.\n\nThe master equation for the state $n$ is given by the balance of probability fluxes:\n$$ \\frac{dP(n,t)}{dt} = (\\text{flux into state } n) - (\\text{flux out of state } n) $$\n\nThe flux into state $n$ comes from two sources:\n- Production from state $n-1$: The rate is $k \\times P(n-1, t)$.\n- Degradation from state $n+1$: The rate is $\\gamma(n+1) \\times P(n+1, t)$.\n\nThe flux out of state $n$ also has two contributions:\n- Production from state $n$: This leads to state $n+1$. The rate is $k \\times P(n, t)$.\n- Degradation from state $n$: This leads to state $n-1$. The rate is $\\gamma n \\times P(n, t)$.\n\nCombining these terms, the master equation is:\n$$ \\frac{dP(n,t)}{dt} = \\left[ k P(n-1, t) + \\gamma(n+1) P(n+1, t) \\right] - \\left[ k P(n, t) + \\gamma n P(n, t) \\right] $$\nThis equation holds for $n \\ge 1$. For $n=0$, there can be no degradation, so the equation is slightly different:\n$$ \\frac{dP(0,t)}{dt} = \\gamma(1) P(1, t) - k P(0, t) $$\n\nThe problem asks for the probability distribution at statistical equilibrium, which is the steady-state distribution. In steady state, the probabilities are no longer changing with time, so $\\frac{dP(n,t)}{dt} = 0$ for all $n$. Let's denote the steady-state probability as $P(n)$.\n\nSetting the time derivatives to zero, we get:\nFor $n \\ge 1$:\n$$ 0 = k P(n-1) + \\gamma(n+1) P(n+1) - (k + \\gamma n) P(n) $$\nFor $n = 0$:\n$$ 0 = \\gamma P(1) - k P(0) \\implies k P(0) = \\gamma P(1) $$\n\nFor a one-dimensional system like this, the steady-state condition implies that the net probability flux between any two adjacent states must be zero. This is the principle of detailed balance. The flux from state $n$ to $n+1$ must equal the flux from state $n+1$ to $n$.\n$$ \\text{Flux}(n \\to n+1) = \\text{Flux}(n+1 \\to n) $$\n$$ k P(n) = \\gamma (n+1) P(n+1) $$\n\nThis single relation holds for all $n \\ge 0$ and is equivalent to the full set of steady-state master equations. We now have a recurrence relation for the probabilities:\n$$ P(n+1) = \\frac{k}{\\gamma(n+1)} P(n) $$\n\nWe can solve this by iteration:\nFor $n=0$: $P(1) = \\frac{k}{\\gamma(1)} P(0)$\nFor $n=1$: $P(2) = \\frac{k}{\\gamma(2)} P(1) = \\frac{k}{2\\gamma} \\left(\\frac{k}{\\gamma} P(0)\\right) = \\frac{1}{2} \\left(\\frac{k}{\\gamma}\\right)^2 P(0)$\nFor $n=2$: $P(3) = \\frac{k}{\\gamma(3)} P(2) = \\frac{k}{3\\gamma} \\left(\\frac{1}{2} \\left(\\frac{k}{\\gamma}\\right)^2 P(0)\\right) = \\frac{1}{3 \\cdot 2} \\left(\\frac{k}{\\gamma}\\right)^3 P(0) = \\frac{1}{3!} \\left(\\frac{k}{\\gamma}\\right)^3 P(0)$\n\nBy induction, we can see the general pattern:\n$$ P(n) = \\frac{1}{n!} \\left(\\frac{k}{\\gamma}\\right)^n P(0) $$\n\nTo find $P(0)$, we use the normalization condition that the sum of all probabilities must be 1:\n$$ \\sum_{n=0}^{\\infty} P(n) = 1 $$\n$$ \\sum_{n=0}^{\\infty} \\frac{1}{n!} \\left(\\frac{k}{\\gamma}\\right)^n P(0) = 1 $$\n$$ P(0) \\sum_{n=0}^{\\infty} \\frac{1}{n!} \\left(\\frac{k}{\\gamma}\\right)^n = 1 $$\n\nWe recognize the sum as the Taylor series expansion for the exponential function, $\\sum_{n=0}^{\\infty} \\frac{x^n}{n!} = \\exp(x)$, with $x = k/\\gamma$.\n$$ P(0) \\exp\\left(\\frac{k}{\\gamma}\\right) = 1 $$\n$$ P(0) = \\frac{1}{\\exp\\left(\\frac{k}{\\gamma}\\right)} = \\exp\\left(-\\frac{k}{\\gamma}\\right) $$\n\nFinally, we substitute this expression for $P(0)$ back into our formula for $P(n)$:\n$$ P(n) = \\frac{1}{n!} \\left(\\frac{k}{\\gamma}\\right)^n \\exp\\left(-\\frac{k}{\\gamma}\\right) $$\nThis is the Poisson distribution with mean $\\lambda = k/\\gamma$.", "answer": "$$\\boxed{\\frac{\\left(\\frac{k}{\\gamma}\\right)^{n} \\exp\\left(-\\frac{k}{\\gamma}\\right)}{n!}}$$", "id": "1468478"}, {"introduction": "While analytical solutions are enlightening, most biological networks are too complex to be solved with pen and paper, requiring computational simulation. The Gillespie algorithm provides a way to generate exact stochastic trajectories of such systems, and its core component is the reaction propensity. This practice provides a concrete first step into the world of stochastic simulation by asking you to calculate the total propensity for a set of reactions, which determines the overall rate of events in the system.[@problem_id:1468506]", "problem": "In a simplified model of a gene regulatory network within a single cell, a protein species $P$ is produced and can subsequently form a dimer $D$. The dynamics of this system are governed by four fundamental stochastic reactions. The number of molecules of protein $P$ and dimer $D$ at any time are denoted as $N_P$ and $N_D$, respectively.\n\nThe four reactions are:\n1.  **Production**: A new molecule of protein $P$ is synthesized. This is a zeroth-order process that occurs with a constant stochastic rate of $k_{prod}$.\n2.  **Degradation**: A single molecule of protein $P$ is degraded. This is a first-order process, where each molecule of $P$ has an independent chance of degrading, described by the stochastic rate constant $k_{deg}$.\n3.  **Dimerization**: Two molecules of protein $P$ combine to form one molecule of dimer $D$. This is a second-order process described by the stochastic rate constant $k_{dimer}$.\n4.  **Dissociation**: A single molecule of dimer $D$ breaks apart into two molecules of protein $P$. This is a first-order process described by the stochastic rate constant $k_{diss}$.\n\nThe total event rate, $a_{tot}$, is defined as the sum of the instantaneous rates of all possible reactions in the system. This quantity is crucial for stochastic simulation algorithms as it determines the time to the next molecular event.\n\nGiven the following rate constants and the system's state at a particular moment in time:\n-   $k_{prod} = 2.50 \\, \\text{s}^{-1}$\n-   $k_{deg} = 0.15 \\, \\text{s}^{-1}$\n-   $k_{dimer} = 0.0040 \\, \\text{s}^{-1}$\n-   $k_{diss} = 0.80 \\, \\text{s}^{-1}$\n-   Number of protein molecules, $N_P = 60$\n-   Number of dimer molecules, $N_D = 25$\n\nCalculate the numerical value of the total event rate $a_{tot}$ at this instant. Express your answer in units of $\\text{s}^{-1}$, rounded to three significant figures.", "solution": "The total event rate is the sum of the propensities of all reactions. For the four reactions, the propensities are:\n- Production (zeroth order): $a_{prod} = k_{prod}$.\n- Degradation (first order in $P$): $a_{deg} = k_{deg} N_{P}$.\n- Dimerization (second order in $P$): $a_{dimer} = k_{dimer} \\binom{N_{P}}{2} = k_{dimer} \\frac{N_{P}(N_{P}-1)}{2}$.\n- Dissociation (first order in $D$): $a_{diss} = k_{diss} N_{D}$.\n\nThus,\n$$\na_{tot} = a_{prod} + a_{deg} + a_{dimer} + a_{diss}\n= k_{prod} + k_{deg} N_{P} + k_{dimer} \\frac{N_{P}(N_{P}-1)}{2} + k_{diss} N_{D}.\n$$\n\nSubstituting the given values,\n$$\na_{prod} = 2.50, \\quad\na_{deg} = 0.15 \\times 60 = 9.00, \\quad\na_{dimer} = 0.0040 \\times \\frac{60 \\times 59}{2} = 0.0040 \\times 1770 = 7.08, \\quad\na_{diss} = 0.80 \\times 25 = 20.0.\n$$\n\nSumming,\n$$\na_{tot} = 2.50 + 9.00 + 7.08 + 20.0 = 38.58.\n$$\n\nRounded to three significant figures,\n$$\na_{tot} = 38.6.\n$$", "answer": "$$\\boxed{38.6}$$", "id": "1468506"}, {"introduction": "Theoretical models of noise are powerful, but their true test lies in connecting them to experimental data. A classic technique in systems biology, the dual-reporter assay, allows researchers to distinguish between noise sources that are specific to a gene ('intrinsic') and those that affect the entire cell ('extrinsic'). This problem puts you in the role of an experimentalist, using statistical moments from hypothetical fluorescence data to dissect and quantify these two fundamental components of cellular variability.[@problem_id:1468474]", "problem": "A researcher is investigating the stochastic nature of gene expression from a synthetic promoter, $P_{syn}$, in a population of bacterial cells. To dissect the different sources of noise, an experimental strategy involving a dual-reporter system is employed. A plasmid is constructed to carry two fluorescent reporter genes: one encoding Green Fluorescent Protein (GFP) and the other encoding Cyan Fluorescent Protein (CFP). Both genes are independently controlled by identical copies of the $P_{syn}$ promoter.\n\nAfter allowing the bacterial culture to reach a steady state, the fluorescence intensities from a large number of individual cells are measured. Let $G$ and $C$ represent the fluorescence intensity for GFP and CFP, respectively, in arbitrary fluorescence units (AFU). The statistical analysis of the population data yields the following moments:\n\n- Mean GFP intensity: $\\langle G \\rangle = 1.60 \\times 10^3$ AFU\n- Mean of the squared GFP intensity: $\\langle G^2 \\rangle = 2.768 \\times 10^6$ AFU$^2$\n- Mean of the product of GFP and CFP intensities: $\\langle G C \\rangle = 2.688 \\times 10^6$ AFU$^2$\n\nAssume that due to the identical design of the two reporter cassettes, the mean expression level of CFP is the same as that of GFP, i.e., $\\langle C \\rangle = \\langle G \\rangle$. The total noise for a given gene can be separated into two components: intrinsic noise, which arises from the stochastic biochemical events of that gene's own expression process, and extrinsic noise, which originates from fluctuations in shared cellular factors affecting both reporters simultaneously.\n\nCalculate the ratio of the extrinsic noise strength to the intrinsic noise strength, $\\frac{\\eta_{\\text{ext}}^2}{\\eta_{\\text{int}}^2}$. Report your answer as a real number rounded to three significant figures.", "solution": "The total variance in the expression of a single reporter, e.g., GFP, can be decomposed into two components: the intrinsic variance ($\\text{Var}_{\\text{int}}$), which is specific to that gene's expression process, and the extrinsic variance ($\\text{Var}_{\\text{ext}}$), which arises from shared cellular fluctuations.\n$$ \\text{Var}(G) = \\text{Var}_{\\text{int}} + \\text{Var}_{\\text{ext}} $$\nThe covariance between the two reporters, $\\text{Cov}(G, C)$, measures the fluctuations that affect both reporters in a correlated manner. By definition, this is the extrinsic variance.\n$$ \\text{Cov}(G, C) = \\text{Var}_{\\text{ext}} $$\nTherefore, we can find the intrinsic variance by subtraction:\n$$ \\text{Var}_{\\text{int}} = \\text{Var}(G) - \\text{Cov}(G, C) $$\nThe noise strengths, $\\eta^2$, are defined as the squared coefficients of variation (variance normalized by the squared mean). Let $\\mu = \\langle G \\rangle = \\langle C \\rangle$.\n$$ \\eta_{\\text{ext}}^2 = \\frac{\\text{Var}_{\\text{ext}}}{\\mu^2} = \\frac{\\text{Cov}(G, C)}{\\mu^2} $$\n$$ \\eta_{\\text{int}}^2 = \\frac{\\text{Var}_{\\text{int}}}{\\mu^2} = \\frac{\\text{Var}(G) - \\text{Cov}(G, C)}{\\mu^2} $$\nThe ratio of extrinsic to intrinsic noise strength is therefore:\n$$ \\frac{\\eta_{\\text{ext}}^2}{\\eta_{\\text{int}}^2} = \\frac{\\text{Var}_{\\text{ext}}}{\\text{Var}_{\\text{int}}} = \\frac{\\text{Cov}(G, C)}{\\text{Var}(G) - \\text{Cov}(G, C)} $$\nNow, we compute the necessary statistical moments from the given data:\n-   $\\mu = \\langle G \\rangle = 1.60 \\times 10^3$\n-   $\\text{Var}(G) = \\langle G^2 \\rangle - \\langle G \\rangle^2 = 2.768 \\times 10^6 - (1.60 \\times 10^3)^2 = 2.768 \\times 10^6 - 2.56 \\times 10^6 = 2.08 \\times 10^5$\n-   $\\text{Cov}(G, C) = \\langle GC \\rangle - \\langle G \\rangle \\langle C \\rangle = 2.688 \\times 10^6 - (1.60 \\times 10^3)^2 = 2.688 \\times 10^6 - 2.56 \\times 10^6 = 1.28 \\times 10^5$\nFinally, we calculate the ratio:\n$$ \\frac{\\eta_{\\text{ext}}^2}{\\eta_{\\text{int}}^2} = \\frac{1.28 \\times 10^5}{2.08 \\times 10^5 - 1.28 \\times 10^5} = \\frac{1.28 \\times 10^5}{0.80 \\times 10^5} = 1.6 $$\nRounded to three significant figures, the result is 1.60.", "answer": "$$\\boxed{1.60}$$", "id": "1468474"}]}