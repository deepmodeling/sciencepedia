{"hands_on_practices": [{"introduction": "Before a deep learning model can predict interactions, it must first understand what a protein is in its own language: the language of numbers. This process, known as feature engineering, involves converting a biological entity like an amino acid into a numerical vector. This foundational exercise guides you through creating such a representation based on key physicochemical properties, illustrating how we bridge the gap between qualitative biology and quantitative computation. [@problem_id:1426736]", "problem": "In the field of bioinformatics, machine learning models are frequently used to predict protein structures and functions. A crucial first step in this process is to convert qualitative biological entities, such as amino acids, into quantitative numerical representations that a computer can process. This conversion is known as feature engineering.\n\nYou are tasked with creating a numerical feature vector for a specific amino acid based on some of its fundamental physicochemical properties. You are provided with the following data for a small set of amino acids:\n\n| Amino Acid | Symbol | Hydrophobicity (Kyte-Doolittle Scale) | Molecular Weight (Da) | Net Charge at pH 7.4 |\n| :--- | :---: | :---: | :---: | :---: |\n| Alanine | A | 1.8 | 89.1 | 0 |\n| Glycine | G | -0.4 | 75.1 | 0 |\n| Leucine | L | 3.8 | 131.2 | 0 |\n| Lysine | K | -3.9 | 146.2 | +1 |\n| Glutamic Acid | E | -3.5 | 147.1 | -1 |\n\nTo ensure that each property contributes fairly to the model and to bring all values into a common range, you must apply min-max normalization to each property. The formula for min-max normalization of a value $x$ is:\n\n$$x_{\\text{norm}} = \\frac{x - x_{\\min}}{x_{\\max} - x_{\\min}}$$\n\nwhere $x_{\\min}$ and $x_{\\max}$ are the minimum and maximum values for that specific property across the entire dataset provided in the table.\n\nUsing the data from the table, calculate the 3-dimensional normalized feature vector for **Glutamic Acid (E)**. The vector should be of the form $[v_1, v_2, v_3]$, where $v_1$ is the normalized hydrophobicity, $v_2$ is the normalized molecular weight, and $v_3$ is the normalized net charge.\n\nExpress your answer as a dimensionless row vector. Round each numerical component of the vector to three significant figures.", "solution": "The goal is to compute the normalized feature vector for Glutamic Acid (E) using the provided data and the min-max normalization formula. The feature vector has three components: normalized hydrophobicity ($v_1$), normalized molecular weight ($v_2$), and normalized net charge ($v_3$).\n\n**Step 1: Identify the values for Glutamic Acid (E).**\nFrom the table, the properties of Glutamic Acid are:\n- Hydrophobicity, $x_{\\text{hydro}}$ = -3.5\n- Molecular Weight, $x_{\\text{mw}}$ = 147.1 Da\n- Net Charge, $x_{\\text{charge}}$ = -1\n\n**Step 2: Determine the minimum and maximum for each property from the entire dataset.**\n\n**For Hydrophobicity:**\n- The values are: 1.8, -0.4, 3.8, -3.9, -3.5.\n- Minimum value, $x_{\\text{hydro, min}} = -3.9$ (from Lysine).\n- Maximum value, $x_{\\text{hydro, max}} = 3.8$ (from Leucine).\n\n**For Molecular Weight:**\n- The values are: 89.1, 75.1, 131.2, 146.2, 147.1.\n- Minimum value, $x_{\\text{mw, min}} = 75.1$ (from Glycine).\n- Maximum value, $x_{\\text{mw, max}} = 147.1$ (from Glutamic Acid).\n\n**For Net Charge:**\n- The values are: 0, 0, 0, +1, -1.\n- Minimum value, $x_{\\text{charge, min}} = -1$ (from Glutamic Acid).\n- Maximum value, $x_{\\text{charge, max}} = +1$ (from Lysine).\n\n**Step 3: Apply the min-max normalization formula for each property of Glutamic Acid.**\n\n**Component 1: Normalized Hydrophobicity ($v_1$)**\nUsing the formula $x_{\\text{norm}} = (x - x_{\\min}) / (x_{\\max} - x_{\\min})$:\n$$v_1 = \\frac{x_{\\text{hydro}} - x_{\\text{hydro, min}}}{x_{\\text{hydro, max}} - x_{\\text{hydro, min}}} = \\frac{-3.5 - (-3.9)}{3.8 - (-3.9)} = \\frac{0.4}{7.7}$$\n$$v_1 \\approx 0.05194805...$$\nRounding to three significant figures, we get $v_1 = 0.0519$.\n\n**Component 2: Normalized Molecular Weight ($v_2$)**\n$$v_2 = \\frac{x_{\\text{mw}} - x_{\\text{mw, min}}}{x_{\\text{mw, max}} - x_{\\text{mw, min}}} = \\frac{147.1 - 75.1}{147.1 - 75.1} = \\frac{72.0}{72.0} = 1$$\nThe value is exactly 1. To express this to three significant figures, we write it as $v_2 = 1.00$.\n\n**Component 3: Normalized Net Charge ($v_3$)**\n$$v_3 = \\frac{x_{\\text{charge}} - x_{\\text{charge, min}}}{x_{\\text{charge, max}} - x_{\\text{charge, min}}} = \\frac{-1 - (-1)}{1 - (-1)} = \\frac{0}{2} = 0$$\nThe value is exactly 0. In a vector context, it is often represented with the same number of decimal places as other components for consistency, so we write $v_3 = 0.00$.\n\n**Step 4: Assemble the final feature vector.**\nThe normalized feature vector for Glutamic Acid (E) is $[v_1, v_2, v_3]$.\nSubstituting the calculated and rounded values:\n$$[0.0519, 1.00, 0.00]$$\nThis is presented as a row vector as requested.", "answer": "$$\\boxed{\\begin{pmatrix} 0.0519 & 1.00 & 0.00 \\end{pmatrix}}$$", "id": "1426736"}, {"introduction": "Once proteins are represented as numerical vectors, we can design a neural network to learn from them. The architecture of this network—its layers, neurons, and connections—defines its learning capacity and complexity. This practice invites you to look under the hood of a simple feed-forward network, calculating its total number of trainable parameters to develop an intuition for how a model's structure relates to its size and power. [@problem_id:1426734]", "problem": "A computational biology team is designing a simple Feed-Forward Neural Network (FNN) to predict whether two proteins, Protein A and Protein B, will interact. The model's design is as follows:\n\n1.  **Input Representation:** Each protein is characterized by a numerical feature vector of length $D$. For this model, $D=50$. The input to the neural network is formed by creating a single larger vector by concatenating the feature vector of Protein A with the feature vector of Protein B.\n\n2.  **Network Architecture:** The network has an input layer, two hidden layers, and an output layer.\n    *   The first hidden layer contains $H_1 = 128$ neurons.\n    *   The second hidden layer contains $H_2 = 64$ neurons.\n    *   The output layer consists of a single neuron, which produces a value related to the probability of an interaction.\n\n3.  **Connectivity:** The network is fully connected between consecutive layers. Every neuron in the hidden layers and the output layer has an associated trainable bias term.\n\nBased on this architecture, calculate the total number of trainable parameters (i.e., the sum of all weights and biases) in the entire network.", "solution": "The input is formed by concatenating two vectors of length $D$, so the input dimension is $I=2D$.\n\nFor a fully connected layer mapping from $n_{\\text{in}}$ inputs to $n_{\\text{out}}$ outputs with biases, the number of trainable parameters equals $n_{\\text{in}} n_{\\text{out}} + n_{\\text{out}}$ (weights plus biases).\n\nApplying this to each layer:\n- Input to first hidden layer: $n_{\\text{in}} = I = 2D$, $n_{\\text{out}} = H_{1}$. Parameters: $(2D)H_{1} + H_{1} = (2D+1)H_{1}$.\n- First to second hidden layer: $n_{\\text{in}} = H_{1}$, $n_{\\text{out}} = H_{2}$. Parameters: $H_{1}H_{2} + H_{2} = (H_{1}+1)H_{2}$.\n- Second hidden to output layer: $n_{\\text{in}} = H_{2}$, $n_{\\text{out}} = 1$. Parameters: $H_{2}\\cdot 1 + 1 = H_{2}+1$.\n\nThus the total number of trainable parameters is\n$$\nP = (2D+1)H_{1} + (H_{1}+1)H_{2} + (H_{2}+1).\n$$\nSubstitute $D=50$, $H_{1}=128$, $H_{2}=64$:\n$$\nP = (2\\cdot 50 + 1)\\cdot 128 + (128+1)\\cdot 64 + (64+1).\n$$\nCompute each term:\n$$\n(100+1)\\cdot 128 = 101\\cdot 128 = 12928,\n$$\n$$\n(128+1)\\cdot 64 = 129\\cdot 64 = 8256,\n$$\n$$\n64+1 = 65.\n$$\nSum:\n$$\nP = 12928 + 8256 + 65 = 21249.\n$$", "answer": "$$\\boxed{21249}$$", "id": "1426734"}, {"introduction": "A trained model is only as good as our ability to measure its performance accurately. In many biological problems, such as virtual screening for new drugs, positive examples are exceedingly rare, creating a severe class imbalance. This exercise demonstrates why a metric like accuracy can be dangerously misleading in such scenarios, and introduces more robust metrics like precision and recall that are crucial for judging a model's true scientific value. [@problem_id:1426729]", "problem": "In a computational drug discovery project, a researcher trains a Graph Neural Network (GNN) to perform virtual screening. The goal is to identify which molecules from a large library are \"active,\" meaning they are likely to bind to a specific target protein.\n\nThe model is tested on a dataset of 1,000,000 candidate molecules. Within this dataset, it is known from previous experimental work that exactly 100 molecules are active and the remaining 999,900 are inactive.\n\nAfter running the screening, the GNN's predictions yield the following results:\n- Of the 100 actual active molecules, the model correctly identifies 80.\n- Of the 999,900 actual inactive molecules, the model incorrectly identifies 1,920 as active.\n\nBased on this information, perform the following tasks:\n1.  Calculate the model's accuracy, which is the proportion of all predictions that were correct.\n2.  For the \"active\" class, calculate the model's precision (the proportion of predicted positives that were correct) and recall (the proportion of actual positives that were correctly identified).\n3.  Given the context of virtual screening, where finding the rare active compounds is the primary goal while minimizing wasted follow-up experiments on false positives, evaluate the model's performance. Consider the calculated metrics and the severe class imbalance of the dataset.\n\nWhich of the following statements provides the most accurate assessment of the model's performance and the best evaluation strategy for this task?\n\nA. The model's accuracy is extremely high, demonstrating its excellent overall performance and suitability for identifying active compounds.\n\nB. The model's accuracy is misleadingly high due to the large number of true negatives. The Area Under the Precision-Recall Curve (AUPRC) would be a more informative metric because it better illustrates the trade-off between finding active compounds and avoiding false alarms in an imbalanced dataset.\n\nC. The model's recall is high, but its precision is extremely low. Thus, the model is useless because a useful model must have both high precision and high recall. Accuracy remains the best single metric for a quick performance summary.\n\nD. Both accuracy and AUPRC are equally informative. The choice between them depends only on the user's preference for a specific performance score.\n\nE. The model's performance is poor, as indicated by its low precision. A better metric to use in this case would be the F1-score, as the AUPRC is too complex to interpret and is only useful when precision is high.", "solution": "Define the confusion matrix entries from the description. The number of true positives is $TP=80$ because the model correctly identified $80$ of the $100$ actual active molecules. The number of false negatives is $FN=100-80=20$. Among the $999{,}900$ actual inactive molecules, the model predicted $1{,}920$ as active, which are false positives $FP=1{,}920$. Therefore, the number of true negatives is $TN=999{,}900-1{,}920=997{,}980$. The total number of samples is $N=1{,}000{,}000$.\n\nAccuracy is defined as the proportion of correct predictions:\n$$\n\\text{Accuracy}=\\frac{TP+TN}{N}=\\frac{80+997{,}980}{1{,}000{,}000}=\\frac{998{,}060}{1{,}000{,}000}=0.99806.\n$$\n\nFor the active class, precision is the proportion of predicted positives that are correct and recall is the proportion of actual positives that are correctly identified. By definition,\n$$\n\\text{Precision}=\\frac{TP}{TP+FP}=\\frac{80}{80+1{,}920}=\\frac{80}{2{,}000}=0.04,\n$$\n$$\n\\text{Recall}=\\frac{TP}{TP+FN}=\\frac{80}{80+20}=\\frac{80}{100}=0.8.\n$$\n\nInterpreting these results in the virtual screening context with severe class imbalance: the accuracy $0.99806$ is dominated by the large number of true negatives and is therefore misleading for assessing the model’s ability to find rare actives while controlling false positives. The recall $0.8$ indicates the model retrieves many of the actual actives, but the precision $0.04$ is very low, implying many false positives and substantial wasted follow-up effort. An evaluation that captures the trade-off between identifying actives and limiting false positives across thresholds is needed; the precision-recall curve and its area (AUPRC) are specifically suited for imbalanced problems and directly reflect this trade-off better than accuracy. Hence, the most accurate assessment and appropriate evaluation strategy are stated in option B.", "answer": "$$\\boxed{B}$$", "id": "1426729"}]}