{"hands_on_practices": [{"introduction": "Before any complex statistical analysis, the first step is always data quality control and exploratory visualization. High-dimensional data from techniques like RNA-sequencing can be visualized using methods such as Principal Component Analysis (PCA) to reveal the main patterns and identify potential outliers. This exercise [@problem_id:1422075] challenges you to act as a data detective, interpreting a common anomaly in a PCA plot and deducing the most likely source of error, a crucial skill for ensuring the integrity of your dataset from the very beginning.", "problem": "A team of student researchers is conducting a study on the transcriptomic differences between healthy human bronchial epithelial cells and those infected with a common respiratory virus. They collect 20 independent cell culture samples. Ten samples are mock-infected and labeled `Control_01` through `Control_10`. The other ten are infected with the virus and labeled `Infected_01` through `Infected_10`. After 24 hours, they perform RNA sequencing (RNA-Seq) to measure the expression levels of thousands of genes in each sample.\n\nTo get a high-level view of their data, they perform a Principal Component Analysis (PCA), a dimensionality reduction technique used to visualize the overall variation between samples. When they plot the first two principal components, they observe two distinct and well-separated clusters of data points. As expected, nine of the `Control` samples form one cluster, and all ten `Infected` samples form the other. However, the data point for the sample originally labeled `Control_08` is located squarely within the center of the `Infected` sample cluster.\n\nAssuming there are no major errors in the computational analysis pipeline (e.g., the PCA algorithm was run correctly) and no undiscovered, complex biological phenomena at play, which of the following represents the most probable and parsimonious (simplest) explanation for this observation?\n\nA. A rare spontaneous mutation occurred in the `Control_08` cell line, causing its gene expression profile to coincidentally converge with that of virus-infected cells.\n\nB. During the RNA-Seq data processing, a random hardware error (e.g., a bit-flip in the computer's memory) corrupted the data file for `Control_08` in a way that made it resemble an infected sample.\n\nC. The RNA extraction procedure failed for `Control_08`, leading to no genetic material being sequenced and the analysis software assigning it a default position in the middle of the plot.\n\nD. The `Control_08` sample was mislabeled at some point during the experimental workflow (e.g., sample collection, plating, or harvesting) and is, in fact, an infected sample that was given the wrong label.\n\nE. The sequencing machine introduced a systematic bias that specifically affected only the `Control_08` sample, altering its entire gene expression profile.", "solution": "We first interpret the PCA result in terms of the underlying data. PCA maps high-dimensional gene expression profiles to a low-dimensional space by finding orthogonal directions that capture maximal variance. When samples form two well-separated clusters corresponding to control and infected groups, it indicates that the dominant axes of variation in the data reflect infection status and that within-group biological and technical variability is small relative to the infection effect.\n\nThe observation that nine control samples cluster together and all ten infected samples cluster together, while the sample labeled Control_08 lies squarely in the center of the infected cluster, implies that the global transcriptome of Control_08 is highly similar to those of infected samples and dissimilar to the other controls. Being in the center of the infected cluster specifically indicates close overall concordance across many genes, not merely a partial resemblance.\n\nWe now evaluate each proposed explanation against empirical plausibility, typical failure modes, and parsimony:\n\nA. A rare spontaneous mutation in Control_08 causing its expression to match infected cells is highly implausible. Viral infection induces coordinated, genome-wide changes involving antiviral responses, metabolic rewiring, and other pathway-level shifts across many genes. A single spontaneous mutation would not predictably reproduce this broad infected-like program across thousands of genes, nor would it place the sample at the cluster center of infected samples. This lacks parsimony.\n\nB. A random hardware error corrupting the Control_08 data to specifically resemble an infected profile is extraordinarily unlikely. Random bit-flips are effectively random noise and would not produce a coherent, biologically structured pattern that aligns closely with the infected cluster centroid. Moreover, such corruption typically produces detectable file errors or nonsensical metrics rather than a clean, class-consistent profile.\n\nC. RNA extraction failure would yield extremely low counts or missing data, which downstream QC would flag. PCA does not assign default positions; samples with little informative signal typically appear as outliers or are excluded, and they would not fall squarely at the center of a biologically coherent cluster. Thus, this is incompatible with the precise infected-like placement observed.\n\nD. Mislabeling of Control_08 is the most parsimonious and common explanation consistent with the data. Label swaps or mis-tracking during collection, plating, or harvesting are well-documented practical issues in experimental workflows. If Control_08 was actually infected but mislabeled, it should cluster with infected samples; being in the cluster center is exactly what one expects for a typical infected sample.\n\nE. A sequencing-machine-induced systematic bias affecting only Control_08 is unlikely. Platform or lane effects usually influence batches of samples rather than a single sample, and such effects do not typically transform a control profile into one that closely matches the infected centroid. A device-specific artifact so selectively aligned with the infected signal in one sample would be non-parsimonious.\n\nGiven the assumptions that the computational pipeline is correct and no undiscovered complex biology is at play, the explanation with the highest plausibility and parsimony is a sample mislabeling event in the workflow. Therefore, the most probable explanation is that Control_08 is actually an infected sample that was given the wrong label.", "answer": "$$\\boxed{D}$$", "id": "1422075"}, {"introduction": "Once satisfied with data quality, researchers often turn to hypothesis testing to identify significant differences between experimental groups. However, when many tests are performed simultaneously—for example, across multiple time points or conditions—the risk of finding a \"significant\" result by pure chance increases dramatically. This problem [@problem_id:1422062] illustrates this critical statistical pitfall, known as the multiple comparisons problem, which is a major contributor to irreproducible findings in scientific literature.", "problem": "A team of systems biologists is investigating the temporal dynamics of a signaling pathway in response to a specific drug. They conduct a time-course experiment, collecting cell samples at 6 different time points: 0 hours (pre-treatment control), 2 hours, 4 hours, 8 hours, 16 hours, and 24 hours post-treatment. At each time point, they prepare three independent biological replicates. For a particular protein of interest, 'Protein P', they measure its phosphorylation level using a quantitative assay.\n\nA student on the team is tasked with determining when the phosphorylation of Protein P changes significantly. To do this, they decide to perform an independent two-sample t-test for every possible pair of time points (e.g., 0h vs 2h, 0h vs 4h, 2h vs 4h, etc.). They set a significance level, $\\alpha$, of 0.05 for each test. If the p-value for any comparison is less than 0.05, they conclude that there is a significant difference in phosphorylation between those two time points.\n\nWhat is the single most significant statistical flaw in this analytical strategy?\n\nA. The use of an independent two-sample t-test is incorrect; a paired t-test is required because the data are collected over time from the same experiment.\n\nB. The normality assumption of the t-test is likely violated by protein phosphorylation data, rendering the p-values invalid.\n\nC. The statistical power of the analysis is too low to detect real differences, as there are only three biological replicates per time point.\n\nD. The approach fails to correct for the multiple comparisons problem, leading to a high probability of finding false-positive results (Type I errors).\n\nE. It is statistically invalid to compare any time points other than the 0-hour control group; all comparisons must be made against the baseline.", "solution": "Let the number of time points be $T=6$. The student performs all pairwise comparisons, so the total number of independent hypothesis tests is the number of unordered pairs:\n$$\nm=\\binom{T}{2}=\\binom{6}{2}=15.\n$$\nFor each test, the per-comparison Type I error rate is set to $\\alpha=0.05$. When multiple tests are conducted without adjustment, the family-wise error rate (FWER), the probability of at least one false positive among the $m$ tests, satisfies\n$$\n\\text{FWER}=P(\\text{at least one false positive})=1-(1-\\alpha)^{m},\n$$\nunder independence of tests. More generally, by the Bonferroni inequality,\n$$\n\\text{FWER}\\leq m\\alpha.\n$$\nIn either case, with $m=15$ and $\\alpha=0.05$, the FWER is substantially larger than $\\alpha$, indicating a high probability of at least one false-positive result when no correction for multiple comparisons is applied. Therefore, the single most significant statistical flaw is the failure to address the multiple comparisons problem.\n\nRegarding the other options:\n- A is not the primary issue: with three independent biological replicates per time point and no explicit pairing across time, an independent two-sample $t$-test is not inherently invalid; a paired test requires matched measurements on the same experimental units.\n- B is not necessarily the main flaw: while normality is an assumption, the $t$-test is often reasonably robust, and the dominant problem here is multiplicity, not distributional form.\n- C concerns statistical power, which may be limited with three replicates, but low power increases Type II errors, not false-positive inflation; it is not the most significant flaw relative to the uncorrected multiple testing.\n- E is incorrect: comparisons among non-baseline time points are not inherently invalid; what is required is an analysis plan that controls error rates (e.g., ANOVA, linear mixed models, or adjusted pairwise tests).\n\nThus, the most critical flaw is the absence of multiple-comparisons correction leading to inflated Type I error.", "answer": "$$\\boxed{D}$$", "id": "1422062"}, {"introduction": "Reproducibility challenges in systems biology extend beyond the lab bench and statistical design; they are also prevalent in the computational analysis itself. The same raw dataset can yield different results depending on the software pipeline used for processing, a concept known as analytical variability. This practice [@problem_id:1422097] provides a concrete example by asking you to quantify the level of agreement between two different bioinformatics tools, demonstrating how choices made during data processing can impact the final interpretation of biological results.", "problem": "A systems biology researcher is investigating the cellular response to a new drug. They perform a Ribonucleic acid sequencing (RNA-seq) experiment to compare gene expression in a treated cell culture versus an untreated control culture. The raw sequencing data is processed to identify genes that are significantly up-regulated by the drug.\n\nTo ensure the robustness of their findings, the researcher analyzes the same raw data using two different, widely-used computational pipelines: \"QuantFlow\" and \"ExpressAlign\". Each pipeline produces a ranked list of genes based on statistical significance. The researcher decides to compare the top 10 most significantly up-regulated genes identified by each pipeline.\n\nThe set of top 10 genes from the QuantFlow pipeline, let's call it set Q, is:\n{GENE01, GENE03, GENE04, GENE05, GENE07, GENE08, GENE11, GENE12, GENE15, GENE17}\n\nThe set of top 10 genes from the ExpressAlign pipeline, let's call it set E, is:\n{GENE02, GENE03, GENE05, GENE06, GENE07, GENE09, GENE11, GENE15, GENE18, GENE20}\n\nTo quantify the concordance between the two analysis methods, calculate the Jaccard index for the two sets of genes, Q and E. The Jaccard index is a measure of similarity for two sets, defined as the size of the intersection divided by the size of the union of the two sets.\n\nExpress your answer as a decimal, rounded to three significant figures.", "solution": "We are asked to compute the Jaccard index for two sets $Q$ and $E$, defined by\n$$\nQ=\\{\\text{GENE01}, \\text{GENE03}, \\text{GENE04}, \\text{GENE05}, \\text{GENE07}, \\text{GENE08}, \\text{GENE11}, \\text{GENE12}, \\text{GENE15}, \\text{GENE17}\\},\n$$\n$$\nE=\\{\\text{GENE02}, \\text{GENE03}, \\text{GENE05}, \\text{GENE06}, \\text{GENE07}, \\text{GENE09}, \\text{GENE11}, \\text{GENE15}, \\text{GENE18}, \\text{GENE20}\\}.\n$$\nThe Jaccard index $J$ is defined as\n$$\nJ=\\frac{|Q\\cap E|}{|Q\\cup E|}.\n$$\nCompute the intersection explicitly:\n$$\nQ\\cap E=\\{\\text{GENE03}, \\text{GENE05}, \\text{GENE07}, \\text{GENE11}, \\text{GENE15}\\},\n$$\nso\n$$\n|Q\\cap E|=5.\n$$\nCompute the union size using the identity $|A\\cup B|=|A|+|B|-|A\\cap B|$:\n$$\n|Q|=10,\\quad |E|=10,\\quad |Q\\cup E|=10+10-5=15.\n$$\nTherefore,\n$$\nJ=\\frac{5}{15}=\\frac{1}{3}.\n$$\nExpressing as a decimal and rounding to three significant figures gives\n$$\n\\frac{1}{3}=0.\\overline{3}\\approx 0.333 \\text{ (to three significant figures)}.\n$$", "answer": "$$\\boxed{0.333}$$", "id": "1422097"}]}