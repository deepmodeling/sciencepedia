{"hands_on_practices": [{"introduction": "A robust computational workflow begins with well-organized code, as a single, large script can quickly become unmanageable and prone to error. This exercise challenges you to refactor a hypothetical, monolithic analysis script into smaller, modular functions based on the single-responsibility principle [@problem_id:1463184]. Practicing this skill is crucial for creating code that is not only easier to read and debug but also forms the testable and reusable foundation of a truly reproducible project.", "problem": "A student in an introductory systems biology course has written a single, 300-line Python script to analyze a gene expression dataset from a microarray experiment. The script performs a complete end-to-end analysis. The sequence of operations is as follows:\n\n1.  It loads the raw gene expression data from a specified comma-separated values (CSV) file into a data structure.\n2.  It filters out genes where the expression level is below a certain threshold in all experimental samples, as these are likely experimental noise.\n3.  It performs quantile normalization on the filtered data to ensure the expression distributions for each sample are statistically comparable.\n4.  It conducts a gene-wise t-test to identify genes that are statistically significantly differentially expressed between a 'treated' group and a 'control' group.\n5.  It generates a volcano plot to visualize the fold change and statistical significance for every gene.\n6.  Finally, it saves the list of significantly differentially expressed genes to a new CSV file and saves the generated volcano plot as a PNG image file.\n\nTo improve the script's readability, make it easier to debug, and allow for parts of the analysis to be reused in other projects, the student decides to refactor this monolithic script into a set of smaller, more focused functions.\n\nWhich of the following sets of functions represents the most logical and maintainable modularization of the original script, based on the principle that each function should have a single, well-defined responsibility?\n\nA. `load_expression_data(filepath)`\n   `filter_low_expression_genes(data)`\n   `normalize_data(data)`\n   `find_differential_genes(data)`\n   `create_volcano_plot(statistics)`\n   `save_results(gene_list, plot_object)`\n\nB. `prepare_and_normalize_data(filepath)`\n   `analyze_and_visualize(data)`\n   `save_all_outputs(results)`\n\nC. `handle_file_io(input_path, output_path_prefix)`\n   `compute_statistics(raw_data)`\n   `generate_visuals(stats_results)`\n\nD. `run_full_analysis(file_path)`\n   `configure_parameters()`\n\nE. `load_data_and_filter(filepath)`\n   `normalize_and_analyze(filtered_data)`\n   `plot_and_save(analysis_results, output_path)`", "solution": "We want a modular decomposition that follows the single-responsibility principle: each function should perform one coherent task, have clear inputs and outputs, be easy to test in isolation, and be reusable in different contexts. The original script’s workflow consists of six conceptually distinct steps: load data, filter low-expression genes, normalize, perform statistical testing for differential expression, create a volcano plot, and save outputs (list and plot).\n\nAssessing each option:\n\n- Option A defines one function per conceptual step:\n  - load_expression_data(filepath): responsible only for reading the CSV into a data structure.\n  - filter_low_expression_genes(data): responsible only for filtering by expression thresholds.\n  - normalize_data(data): responsible only for normalization (quantile normalization).\n  - find_differential_genes(data): responsible only for statistical testing (e.g., gene-wise t-tests and fold-changes).\n  - create_volcano_plot(statistics): responsible only for generating the visualization object from test statistics.\n  - save_results(gene_list, plot_object): responsible only for persisting outputs (CSV and PNG).\n  This maps one-to-one to the six steps, minimizes coupling between concerns, maximizes cohesion within each function, facilitates unit testing (e.g., mock inputs for each function), and promotes reuse (e.g., reuse normalization or plotting independently).\n\n- Option B groups multiple distinct responsibilities into broad functions (e.g., prepare_and_normalize_data merges loading and normalization; analyze_and_visualize merges statistics and plotting), reducing clarity, testability, and reuse.\n\n- Option C conflates reading and writing into a single IO function and combines filtering, normalization, and testing under compute_statistics, which obscures boundaries between preprocessing and inference. This decreases modularity and flexibility.\n\n- Option D is essentially non-modular: run_full_analysis does everything, and configure_parameters is not part of the analysis pipeline itself.\n\n- Option E still bundles tasks (e.g., load_data_and_filter, normalize_and_analyze, plot_and_save), violating single responsibility and making reuse and testing harder.\n\nTherefore, Option A is the most logical and maintainable modularization because it cleanly separates each pipeline step into a single, well-defined function that directly corresponds to one stage of the original workflow, improving readability, debuggability, and reuse potential.", "answer": "$$\\boxed{A}$$", "id": "1463184"}, {"introduction": "Once your workflow is broken down into modular functions, you must verify that each component behaves as expected. This practice introduces the concept of automated unit testing, a systematic method for validating individual pieces of code in isolation [@problem_id:1463255]. By writing a simple test for a common bioinformatics helper function using the \"Arrange-Act-Assert\" pattern, you will learn how to build a safety net that ensures your code's reliability and provides executable documentation of its purpose.", "problem": "A systems biology researcher is developing a Python script to analyze transcriptomics data. A crucial part of the script is a function named `get_ensembl_id` that converts common gene symbols into their corresponding Ensembl Gene IDs. The function is designed to take two arguments: a single gene symbol (as a string) and a dictionary that maps gene symbols to Ensembl IDs.\n\nHere is the function's definition:\n```python\ndef get_ensembl_id(gene_symbol, mapping_dict):\n    \"\"\"\n    Looks up the Ensembl ID for a given gene symbol.\n    Returns the Ensembl ID if found, otherwise returns None.\n    \"\"\"\n    return mapping_dict.get(gene_symbol)\n```\n\nTo ensure this function is reliable and to establish a reproducible workflow, the researcher decides to write a unit test. For this purpose, they create a small, known mapping dictionary to use within the test:\n```python\ntest_map = {\"TP53\": \"ENSG00000141510\", \"EGFR\": \"ENSG00000146648\"}\n```\n\nWhich of the following code snippets represents a correct and conventional unit test for the `get_ensembl_id` function, specifically for the case where the gene symbol exists in the mapping dictionary?\n\nA.\n```python\ninput_symbol = \"TP53\"\nexpected_id = \"ENSG00000141510\"\nresult = get_ensembl_id(input_symbol, test_map)\nprint(f\"Test passed: {result == expected_id}\")\n```\n\nB.\n```python\n## Arrange\ninput_symbol = \"TP53\"\nexpected_id = \"ENSG00000141510\"\ntest_map = {\"TP53\": \"ENSG00000141510\", \"EGFR\": \"ENSG00000146648\"}\n\n## Act\nactual_id = get_ensembl_id(input_symbol, test_map)\n\n## Assert\nassert actual_id == expected_id\n```\n\nC.\n```python\n## Test for TP53\nif get_ensembl_id(\"TP53\", test_map) == \"ENSG00000141510\":\n    print(\"TP53 test passed.\")\nelse:\n    print(\"TP53 test failed.\")\n```\n\nD.\n```python\ntest_map = {\"TP53\": \"ENSG00000141510\", \"EGFR\": \"ENSG00000146648\"}\nall_results = []\nfor symbol in test_map:\n    all_results.append(get_ensembl_id(symbol, test_map))\nassert all_results == [\"ENSG00000141510\", \"ENSG00000146648\"]\n```\n\nE.\n```python\n## Arrange\ninput_symbol = \"BRCA1\"\ntest_map = {\"TP53\": \"ENSG00000141510\", \"EGFR\": \"ENSG00000146648\"}\n\n## Act\nactual_id = get_ensembl_id(input_symbol, test_map)\n\n## Assert\nassert actual_id is None\n```", "solution": "We begin by restating the target behavior to be tested. The function `get_ensembl_id(gene_symbol, mapping_dict)` should return the Ensembl ID corresponding to the provided gene symbol when that symbol exists as a key in `mapping_dict`, and return `None` otherwise. The current question focuses specifically on the case where the gene symbol exists in the mapping dictionary.\n\nA conventional unit test should:\n- Follow the Arrange-Act-Assert pattern to clearly separate setup, execution, and verification.\n- Use assertions to signal pass or fail to a test runner, rather than printing output.\n- Be specific to the behavior being tested without introducing unnecessary dependencies (e.g., on iteration order).\n\nNow we evaluate each option:\n\n- Option A uses a `print` statement to indicate pass or fail. This is not conventional unit testing practice because it does not use an assertion mechanism that integrates with test frameworks. Therefore A is not correct for a conventional unit test.\n\n- Option B follows the Arrange-Act-Assert pattern:\n  - Arrange: defines `input_symbol = \"TP53\"`, `expected_id = \"ENSG00000141510\"`, and a local `test_map` containing the relevant mapping.\n  - Act: calls the function to produce `actual_id`.\n  - Assert: checks `actual_id == expected_id` using an assertion.\n  This directly and conventionally tests the case where the gene symbol exists in the dictionary.\n\n- Option C uses a conditional with `print` statements rather than assertions. This is not conventional unit testing practice, for the same reason as A.\n\n- Option D constructs a list by iterating over the dictionary and asserting a specific order of results. While it uses an assertion, it inadvertently couples the test to the iteration order of the dictionary and tests more than the single existence case for a specific symbol. It is less focused and less conventional for the specific case in question.\n\n- Option E tests the missing-symbol behavior (expects `None` for a symbol not in the dictionary), which is not the requested case.\n\nTherefore, the correct and conventional unit test for the specified case is Option B.", "answer": "$$\\boxed{B}$$", "id": "1463255"}, {"introduction": "Reproducibility extends beyond just the code; it includes being able to understand the history of how and why an analysis evolved over time. This exercise focuses on a critical aspect of version control: writing an informative commit message [@problem_id:1463216]. Learning to clearly articulate the purpose behind a code change transforms a simple log entry into a powerful piece of documentation, making your project's history transparent and understandable for your future self and any collaborators.", "problem": "A researcher in a systems biology lab is developing a computational workflow to analyze proteomics data from a mass spectrometer. They are using the version control system Git to track changes to their main analysis script, `process_quantification.py`. The researcher has just modified the script to introduce a new quality control step: any protein that was identified based on fewer than two unique peptides is now filtered out and excluded from the final results. They now need to commit this change to the repository.\n\nTheir initial, uninformative commit message is `git commit -m \"updated script\"`. Which of the following alternative commit messages is the most effective and informative for this change, following established best practices for maintaining a reproducible and understandable project history?\n\nA. `git commit -m \"I added a new filtering step to process_quantification.py\"`\n\nB. `git commit -m \"Bugfix: Correct protein quantification values\"`\n\nC. `git commit -m \"Feat: Add filter for low-confidence proteins\n\n   Proteins identified by fewer than two unique peptides are now\n   removed from the analysis. This improves the reliability of the\n   downstream analysis by eliminating poorly supported protein\n   identifications.\"`\n\nD. `git commit -m \"Updated process_quantification.py on line 87 to add a filter where df['unique_peptides'] >= 2.\"`\n\nE. `git commit -m \"misc changes and updates\"`", "solution": "Goal: choose the most effective, informative commit message that maintains a reproducible and understandable project history.\n\nBest-practice criteria:\n- Use a concise, imperative subject line that describes what the change does, not what was done (e.g., “Add filter” rather than “I added” or “Updated”).\n- Optionally use a conventional commit type (e.g., Feat, Fix) to classify the change.\n- Include a body explaining what changed and why, focusing on behavior and rationale rather than low-level implementation details.\n- Avoid vague messages and avoid incorrect classification (e.g., calling a feature a bugfix).\n- Avoid volatile specifics like line numbers or transient variable names that may change and do not help future readers understand intent.\n\nEvaluate options:\n- A: Uses first person and past tense (“I added ...”), lacks rationale and detail; less aligned with imperative mood and best practices.\n- B: Labeled as a bugfix but the described change is a new filtering behavior; misclassified and misleading.\n- C: Uses “Feat” type, imperative “Add,” clearly states the behavior change (filter proteins with fewer than two unique peptides), and explains the rationale and impact (improves reliability by removing poorly supported identifications). This best supports reproducibility and understanding.\n- D: Mentions a line number and specific code expression; not durable or helpful for intent, and the subject is “Updated,” which is vague and not imperative.\n- E: Vague and uninformative.\n\nConclusion: The best option according to established best practices is C.", "answer": "$$\\boxed{C}$$", "id": "1463216"}]}