{"hands_on_practices": [{"introduction": "At the heart of proteomics is the ability to compare protein quantities between different cellular states, such as healthy versus diseased or untreated versus treated. This exercise explores a foundational technique for this task: Stable Isotope Labeling with Amino acids in Cell culture (SILAC). By interpreting the mass spectrometry signal from cells grown in 'light' and 'heavy' media, you will practice translating raw data into a core biological conclusion about protein expression [@problem_id:1515635].", "problem": "A molecular biologist is investigating the cellular response to a newly synthesized compound, \"Compound-Z,\" which is hypothesized to alter protein expression in a human cancer cell line. To test this, a quantitative proteomics experiment is performed using Stable Isotope Labeling with Amino acids in Cell culture (SILAC).\n\nTwo populations of the same cancer cell line are cultured.\n- The 'Control' population is grown in a standard medium containing normal (\"light\") versions of lysine and arginine.\n- The 'Treated' population is grown in an identical medium, except that the lysine and arginine have been replaced with stable, heavy-isotope-labeled versions (e.g., $^{13}\\text{C}_6$-lysine and $^{13}\\text{C}_6{}^{15}\\text{N}_4$-arginine).\n\nAfter several cell divisions to ensure complete labeling, the 'Treated' population is exposed to Compound-Z for 24 hours, while the 'Control' population is given a sham treatment. Subsequently, equal numbers of cells from both populations are mixed, lysed, and their proteins are digested into peptides. The resulting peptide mixture is analyzed by mass spectrometry.\n\nFor a specific protein, named \"Regulin,\" the mass spectrometer consistently detects pairs of peptides where the intensity of the heavy-isotope version is equal to the intensity of the light-isotope version. What is the most accurate biological conclusion that can be drawn from this 1:1 heavy-to-light ratio for Regulin?\n\nA. The expression level of Regulin is unchanged by treatment with Compound-Z.\n\nB. Compound-Z causes a two-fold increase in the expression of Regulin.\n\nC. The experiment failed, as no Regulin protein was present in either cell population.\n\nD. Compound-Z completely inhibits the synthesis of Regulin.\n\nE. The Regulin protein is twice as large in the treated cells compared to the control cells.", "solution": "SILAC uses isotopically light and heavy amino acids to generate peptide pairs whose mass spectrometric signal intensities are proportional to the relative abundances of the corresponding proteins in two conditions. Let the treated (heavy-labeled) population contribute an amount of Regulin proportional to $n_{H}$ and the control (light-labeled) population contribute an amount proportional to $n_{L}$. Under complete labeling, equal cell mixing, identical peptide sequences, and equivalent physicochemical behavior of light and heavy counterparts, the measured ion intensities satisfy\n$$\nI_{H} = k\\,n_{H}, \\quad I_{L} = k\\,n_{L},\n$$\nwhere $k$ is a shared proportionality constant capturing digestion efficiency, chromatographic recovery, and ionization/fragmentation response for the light/heavy peptide pair.\n\nThe observed 1:1 heavy-to-light ratio implies\n$$\n\\frac{I_{H}}{I_{L}} = 1 \\;\\Rightarrow\\; \\frac{k\\,n_{H}}{k\\,n_{L}} = 1 \\;\\Rightarrow\\; \\frac{n_{H}}{n_{L}} = 1 \\;\\Rightarrow\\; n_{H} = n_{L}.\n$$\nBecause equal numbers of cells from the treated and control populations were mixed and labeling is complete, $n_{H}$ and $n_{L}$ are proportional to the per-cell abundance of Regulin in treated and control conditions, respectively. Therefore $n_{H} = n_{L}$ indicates no change in Regulin expression due to Compound-Z.\n\nEvaluating the alternatives:\n- A is consistent with $I_{H}/I_{L} = 1$.\n- B would require $I_{H}/I_{L} = 2$.\n- C would correspond to no detectable peptide signal, not equal heavy and light signals.\n- D would yield $I_{H} \\approx 0$ (heavy absent) while light persists.\n- E is unrelated to SILAC intensity ratios; protein size does not affect the heavy-to-light ratio for a given peptide pair.\n\nThus, the most accurate conclusion is that Regulin expression is unchanged by treatment with Compound-Z.", "answer": "$$\\boxed{A}$$", "id": "1515635"}, {"introduction": "While proteomics focuses on the ensemble of proteins, metabolomics provides a snapshot of cellular activity by measuring small-molecule metabolites. A powerful application of this approach is in identifying the mechanism of action for new drugs or herbicides, as explored in this problem. By analyzing the accumulation and depletion of specific metabolites within a biochemical pathway, you can deduce the precise enzymatic step being inhibited, a critical skill for functional systems biology [@problem_id:1515636].", "problem": "A team of agricultural scientists is investigating the mechanism of a new, highly effective herbicide called \"PhytoBlock.\" They treat a sample of a common weed, *Amaranthus retroflexus*, with a non-lethal dose of PhytoBlock. After a few hours, they perform a metabolomic analysis to measure the relative concentrations of metabolites involved in the biosynthesis of the essential amino acid L-tyrosine.\n\nThe simplified L-tyrosine biosynthetic pathway in plants proceeds as follows:\n\n1.  Chorismate is converted to Prephenate by the enzyme Chorismate Mutase.\n2.  Prephenate is converted to 4-Hydroxyphenylpyruvate by the enzyme Prephenate Dehydrogenase.\n3.  4-Hydroxyphenylpyruvate is converted to L-tyrosine by the enzyme Tyrosine Aminotransferase.\n\nThe analysis of the PhytoBlock-treated plants reveals the following changes compared to untreated control plants:\n*   The concentration of Chorismate is approximately normal.\n*   The concentration of Prephenate is over 50 times higher than normal.\n*   The concentrations of 4-Hydroxyphenylpyruvate and L-tyrosine are both less than 2% of their normal levels.\n\nBased on these experimental results, which of the following is the most likely primary molecular target of the PhytoBlock herbicide?\n\nA. Chorismate Mutase\n\nB. Prephenate Dehydrogenase\n\nC. Tyrosine Aminotransferase\n\nD. A general inhibitor of protein synthesis (translation)\n\nE. A transporter protein that brings Chorismate to the enzyme complex", "solution": "The pathway is linear: Chorismate is converted to Prephenate, which is converted to 4-Hydroxyphenylpyruvate, which is converted to L-tyrosine. In a steady-state metabolic pathway, inhibition of an enzyme typically causes accumulation of its substrate (immediately upstream metabolite) and depletion of products downstream, while metabolites upstream of the block may remain near normal if their production and consumption balance is not severely disrupted.\n\nAnalyze each enzymatic step against the observations:\n1. If Chorismate Mutase were inhibited (option A), the conversion of Chorismate to Prephenate would be reduced. This predicts elevated Chorismate and decreased Prephenate. The data instead show normal Chorismate and massively elevated Prephenate, which contradicts this prediction. Therefore, A is inconsistent.\n2. If Prephenate Dehydrogenase were inhibited (option B), Prephenate would accumulate because its conversion to 4-Hydroxyphenylpyruvate is blocked, and downstream metabolites (4-Hydroxyphenylpyruvate and L-tyrosine) would be depleted due to lack of precursor. This exactly matches the observations: Prephenate is more than $50$ times normal, and 4-Hydroxyphenylpyruvate and L-tyrosine are each less than $0.02$ of normal. Chorismate being approximately normal is also consistent, as its production and consumption via Chorismate Mutase can continue without necessarily causing large accumulation when the block is downstream of Prephenate.\n3. If Tyrosine Aminotransferase were inhibited (option C), 4-Hydroxyphenylpyruvate would accumulate (its conversion to L-tyrosine is blocked), and L-tyrosine would be low. The data instead show 4-Hydroxyphenylpyruvate is very low, not high. Therefore, C is inconsistent.\n4. A general inhibitor of protein synthesis (option D) would decrease levels of many enzymes globally, causing widespread metabolic changes rather than a specific, massive accumulation at a single intermediate. The specific pattern of extreme Prephenate accumulation with severely depleted immediate downstream products is most consistent with a specific block, not a global translation inhibition. Therefore, D is unlikely.\n5. If a transporter delivering Chorismate to the enzyme complex were inhibited (option E), Prephenate would be reduced (due to limited substrate delivery) and Chorismate would tend to accumulate. The observed opposite pattern (normal Chorismate, extremely high Prephenate) rules out E.\n\nThus, the metabolite pattern uniquely supports inhibition of Prephenate Dehydrogenase.", "answer": "$$\\boxed{B}$$", "id": "1515636"}, {"introduction": "Proteomics and metabolomics experiments do not measure one molecule at a time; they measure thousands simultaneously, creating a significant statistical challenge known as the multiple comparisons problem. When performing thousands of statistical tests, the probability of obtaining false positives by chance becomes unacceptably high. This exercise introduces the critical concept of multiple testing correction, guiding you through the justification and direct application of the Benjamini-Hochberg procedure to control the False Discovery Rate (FDR), an indispensable skill for rigorously interpreting any large-scale biological dataset [@problem_id:2829953].", "problem": "A label-free quantitative proteomics experiment compares two biological conditions with independent biological replicates per condition, yielding a two-sample test for each detected protein. For a subset of proteins, the per-protein tests return the following raw $p$-values in the original protein order $P_1$ through $P_{10}$: $\\left[0.0008,\\ 0.045,\\ 0.13,\\ 0.021,\\ 0.0025,\\ 0.33,\\ 0.078,\\ 0.00012,\\ 0.009,\\ 0.56\\right]$. In high-dimensional proteomics, thousands of proteins are typically tested, test statistics across proteins often exhibit positive dependence due to shared biology and batch effects, and scientific aims prioritize controlling the expected proportion of false positives among reported discoveries rather than eliminating any possibility of a single false positive.\n\nStarting from the definitions of hypothesis testing, the null distribution of $p$-values under true null hypotheses, and the concept of the expected proportion of false discoveries among all rejections, first justify rigorously which family-wise error or false discovery error rate control principle is most appropriate for this proteomics setting and why it remains valid under positive dependence typical of protein expression data. Then, using the standard step-up multiple testing procedure that controls the expected proportion of false discoveries under independence or certain forms of positive dependence, compute the adjusted $p$-values for the given $10$ proteins and report them in the original protein order.\n\nRound your final adjusted $p$-values to four significant figures. Express the final answer as a single row vector of the $10$ adjusted $p$-values, in the order $P_1$ through $P_{10}$, with no units.", "solution": "The problem statement is scientifically sound and well-posed. It describes a standard statistical challenge in high-dimensional biology and provides all necessary information for a rigorous solution. We will proceed.\n\nThe problem requires two parts: first, a justification for the choice of a multiple testing error-control principle appropriate for the described proteomics experiment; second, the computation of adjusted $p$-values for the provided raw data using the corresponding standard procedure.\n\nWe begin with the fundamental definitions. In hypothesis testing, for each of $m$ proteins, we are testing a null hypothesis $H_{0,i}$ (e.g., no differential expression) against an alternative $H_{a,i}$. A $p$-value, $p_i$, is the probability of observing data at least as extreme as what was actually measured, under the assumption that $H_{0,i}$ is true. A key property is that for all tests $i$ where $H_{0,i}$ is true, the corresponding $p$-values $p_i$ are independent and identically distributed random variables following a Uniform distribution on the interval $[0, 1]$.\n\nWhen conducting $m$ simultaneous tests, we can make two types of errors. A Type I error, or a false positive, occurs when we reject a true null hypothesis. Let $V$ be the random variable for the number of false positives. A Type II error, or a false negative, occurs when we fail to reject a false null hypothesis. The total number of tests is $m$. Let $m_0$ be the number of true null hypotheses and $m_1 = m - m_0$ be the number of true alternative hypotheses. Let $R$ be the total number of rejected hypotheses.\n\nThe problem describes an exploratory, high-dimensional setting where the goal is to generate a list of candidate proteins for follow-up studies. It explicitly prioritizes \"controlling the expected proportion of false positives among reported discoveries\" over \"eliminating any possibility of a single false positive.\" This distinction is critical.\n\nControlling the probability of making *at least one* false positive is defined as controlling the Family-Wise Error Rate (FWER), where $\\text{FWER} = P(V \\ge 1)$. Procedures like the Bonferroni correction, which would adjust the significance threshold $\\alpha$ to $\\alpha/m$, are designed to control the FWER. However, in a high-dimensional context where $m$ is large and many true discoveries are anticipated (i.e., $m_1$ is substantial), FWER control is excessively stringent. It leads to a severe loss of statistical power, meaning a high rate of false negatives, and would likely result in missing most of the genuine biological signals present in the data.\n\nThe alternative, which directly matches the stated scientific goal, is to control the False Discovery Rate (FDR). The FDR is the expectation of the False Discovery Proportion, $Q$, where $Q$ is defined as the proportion of false positives among all discoveries: $Q = V/R$ for $R > 0$, and $Q=0$ for $R=0$. Thus, $\\text{FDR} = E[Q] = E[V/R | R>0]P(R>0)$. Controlling the FDR at a level $\\alpha$ means ensuring that, on average, no more than a fraction $\\alpha$ of the declared discoveries are false. This framework tolerates a small, controlled number of false positives in exchange for a substantial increase in power to detect true effects, which is precisely the desired trade-off in exploratory proteomics research.\n\nThe problem also notes that protein expression data typically exhibits \"positive dependence.\" The standard procedure for FDR control is the Benjamini-Hochberg (BH) step-up procedure. While originally proven to control the FDR for independent tests, Benjamini and Yekutieli (2001) later showed that this same procedure also provably controls the FDR at level $\\alpha$ under a condition known as Positive Regression Dependency (PRD). This form of dependence is considered a reasonable and often-invoked assumption for the positively correlated test statistics commonly found in biological datasets like proteomics, where cellular pathways and co-regulation lead to correlated expression changes. Therefore, the BH procedure is the appropriate and valid method to use.\n\nWe now apply the Benjamini-Hochberg procedure to compute the adjusted $p$-values. The adjusted $p$-value for a given test is the lowest FDR level, $\\alpha$, at which that test's null hypothesis would be rejected.\n\nThe raw $p$-values for $m=10$ proteins are:\n$P = [0.0008, 0.045, 0.13, 0.021, 0.0025, 0.33, 0.078, 0.00012, 0.009, 0.56]$.\n\nFirst, we order the raw $p$-values, $p_i$, from smallest to largest, which we denote $p_{(i)}$, and keep track of their original indices.\nThe sorted $p$-values $p_{(i)}$ with their rank $i$ from $1$ to $m=10$:\n$p_{(1)} = 0.00012$ (original index $8$)\n$p_{(2)} = 0.0008$ (original index $1$)\n$p_{(3)} = 0.0025$ (original index $5$)\n$p_{(4)} = 0.009$ (original index $9$)\n$p_{(5)} = 0.021$ (original index $4$)\n$p_{(6)} = 0.045$ (original index $2$)\n$p_{(7)} = 0.078$ (original index $7$)\n$p_{(8)} = 0.13$ (original index $3$)\n$p_{(9)} = 0.33$ (original index $6$)\n$p_{(10)} = 0.56$ (original index $10$)\n\nNext, for each ordered $p$-value $p_{(i)}$, we calculate an intermediate value $p_{BH,(i)} = \\frac{m \\cdot p_{(i)}}{i}$.\n$p_{BH,(1)} = \\frac{10 \\cdot 0.00012}{1} = 0.0012$\n$p_{BH,(2)} = \\frac{10 \\cdot 0.0008}{2} = 0.004$\n$p_{BH,(3)} = \\frac{10 \\cdot 0.0025}{3} \\approx 0.008333$\n$p_{BH,(4)} = \\frac{10 \\cdot 0.009}{4} = 0.0225$\n$p_{BH,(5)} = \\frac{10 \\cdot 0.021}{5} = 0.042$\n$p_{BH,(6)} = \\frac{10 \\cdot 0.045}{6} = 0.075$\n$p_{BH,(7)} = \\frac{10 \\cdot 0.078}{7} \\approx 0.111429$\n$p_{BH,(8)} = \\frac{10 \\cdot 0.13}{8} = 0.1625$\n$p_{BH,(9)} = \\frac{10 \\cdot 0.33}{9} \\approx 0.366667$\n$p_{BH,(10)} = \\frac{10 \\cdot 0.56}{10} = 0.56$\n\nThe adjusted $p$-value, $q_{(i)}$, for the $i$-th ordered raw $p$-value is defined to enforce monotonicity. This is achieved by taking the cumulative minimum of the $p_{BH}$ values, starting from the largest one. That is, $q_{(i)} = \\min_{k=i}^{m} \\left(\\frac{m \\cdot p_{(k)}}{k}\\right)$.\n$q_{(10)} = p_{BH,(10)} = 0.56$\n$q_{(9)} = \\min(p_{BH,(9)}, q_{(10)}) = \\min(0.366667, 0.56) = 0.366667$\n$q_{(8)} = \\min(p_{BH,(8)}, q_{(9)}) = \\min(0.1625, 0.366667) = 0.1625$\n$q_{(7)} = \\min(p_{BH,(7)}, q_{(8)}) = \\min(0.111429, 0.1625) = 0.111429$\n$q_{(6)} = \\min(p_{BH,(6)}, q_{(7)}) = \\min(0.075, 0.111429) = 0.075$\n$q_{(5)} = \\min(p_{BH,(5)}, q_{(6)}) = \\min(0.042, 0.075) = 0.042$\n$q_{(4)} = \\min(p_{BH,(4)}, q_{(5)}) = \\min(0.0225, 0.042) = 0.0225$\n$q_{(3)} = \\min(p_{BH,(3)}, q_{(4)}) = \\min(0.008333, 0.0225) = 0.008333$\n$q_{(2)} = \\min(p_{BH,(2)}, q_{(3)}) = \\min(0.004, 0.008333) = 0.004$\n$q_{(1)} = \\min(p_{BH,(1)}, q_{(2)}) = \\min(0.0012, 0.004) = 0.0012$\n\nFinally, we reorder these adjusted $p$-values back to their original protein order ($P_1$ through $P_{10}$) and round to four significant figures as required.\n- $P_1$ (was rank $2$): $q = 0.004000$\n- $P_2$ (was rank $6$): $q = 0.07500$\n- $P_3$ (was rank $8$): $q = 0.1625$\n- $P_4$ (was rank $5$): $q = 0.04200$\n- $P_5$ (was rank $3$): $q = 0.008333$\n- $P_6$ (was rank $9$): $q = 0.3667$\n- $P_7$ (was rank $7$): $q = 0.1114$\n- $P_8$ (was rank $1$): $q = 0.001200$\n- $P_9$ (was rank $4$): $q = 0.02250$\n- $P_{10}$ (was rank $10$): $q = 0.5600$\n\nThe final vector of adjusted $p$-values is constructed from these values.", "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n0.004000 & 0.07500 & 0.1625 & 0.04200 & 0.008333 & 0.3667 & 0.1114 & 0.001200 & 0.02250 & 0.5600\n\\end{pmatrix}\n}\n$$", "id": "2829953"}]}