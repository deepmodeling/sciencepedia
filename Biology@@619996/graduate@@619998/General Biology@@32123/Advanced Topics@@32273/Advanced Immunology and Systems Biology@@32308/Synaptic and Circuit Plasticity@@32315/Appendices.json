{"hands_on_practices": [{"introduction": "To understand synaptic plasticity, we must be able to pinpoint where the changes occur. This exercise challenges you to act as a quantitative neurophysiologist, using the canonical binomial model of transmitter release to determine if a change in synaptic strength is presynaptic in origin [@problem_id:2840032]. By deriving relationships between the model's parameters and experimentally measurable quantities like the paired-pulse ratio and coefficient of variation, you will practice the critical skill of testing a hypothesis for self-consistency across multiple lines of evidence.", "problem": "A glutamatergic synapse is modeled as having $N$ independent presynaptic release sites. On each evoked spike, each site releases one vesicle with probability $p$, and each released vesicle produces a postsynaptic current of quantal amplitude $q$. Assume negligible variability in quantal amplitude and negligible postsynaptic noise, so that the evoked excitatory postsynaptic current (EPSC) amplitude equals the sum of released quanta times $q$. Paired pulses are delivered with a short inter-pulse interval so that there is no replenishment between pulses and no facilitation; sites that released on the first pulse are unavailable on the second pulse, while sites that failed remain available.\n\nYou record the following steady-state measurements before and after a long-term potentiation (LTP) induction protocol:\n- Before LTP (baseline): mean EPSC amplitude $= 38.4$ pA, paired-pulse ratio (PPR; defined as $\\text{EPSC}_2/\\text{EPSC}_1$) $= 0.60$, coefficient of variation squared ($\\text{CV}^2$; defined as $\\text{variance}/\\text{mean}^2$) $= 0.1875$.\n- After LTP: mean EPSC amplitude $= 52.8$ pA, PPR $= 0.45$, $\\text{CV}^2 = 0.1023$.\n\nUsing only the binomial model and the assumptions stated, start from first principles to:\n- Relate the paired-pulse ratio to the release probability for a depletion-only second pulse.\n- Relate the coefficient of variation to $N$ and $p$ when quantal variability is negligible.\n- Use the above to determine whether the plasticity is presynaptic and self-consistent across all measurements.\n\nFinally, compute the fold-change in release probability $p$ produced by LTP, that is $p_{\\text{after}}/p_{\\text{before}}$. Express your final answer as a dimensionless number and round to four significant figures.", "solution": "The problem is validated as scientifically grounded, well-posed, and objective. It is based on the canonical binomial model of synaptic transmission, a cornerstone of quantitative neuroscience. All necessary data are provided, and the task is to derive parameters from first principles and test for self-consistency, which is a standard analytical procedure in this field. The problem is valid and a solution will be provided.\n\nThe model assumes that the number of vesicles released upon a presynaptic spike, denoted by the random variable $k$, follows a binomial distribution, $k \\sim B(N, p)$. Here, $N$ is the number of independent release sites (trials) and $p$ is the uniform probability of release at any given site (probability of success). The probability mass function for releasing exactly $k$ vesicles is given by:\n$$ P(k; N, p) = \\binom{N}{k} p^{k} (1-p)^{N-k} $$\nThe mean and variance of this distribution are well-known:\n$$ \\langle k \\rangle = Np $$\n$$ \\text{var}(k) = \\sigma_{k}^{2} = Np(1-p) $$\nThe problem states that quantal variability is negligible, meaning each vesicle contributes a fixed quantal current $q$ to the excitatory postsynaptic current (EPSC). Therefore, the EPSC amplitude $A$ is directly proportional to the number of released vesicles: $A = kq$. The mean and variance of the EPSC amplitude are then:\n$$ \\mu_A = \\langle A \\rangle = \\langle kq \\rangle = q \\langle k \\rangle = Npq $$\n$$ \\sigma_{A}^{2} = \\text{var}(A) = \\text{var}(kq) = q^{2} \\text{var}(k) = q^{2}Np(1-p) $$\n\nFirst, we relate the coefficient of variation squared ($\\text{CV}^2$) to the binomial parameters $N$ and $p$. By definition, $\\text{CV}^2 = \\sigma_{A}^{2}/\\mu_{A}^{2}$. Substituting the expressions above:\n$$ \\text{CV}^2 = \\frac{q^{2}Np(1-p)}{(Npq)^{2}} = \\frac{q^{2}Np(1-p)}{N^{2}p^{2}q^{2}} = \\frac{1-p}{Np} $$\nThis equation relates one of the observables ($\\text{CV}^2$) to the presynaptic parameters $N$ and $p$.\n\nSecond, we relate the paired-pulse ratio (PPR) to the release probability $p$. The model specifies simple depletion: sites that release on the first pulse are unavailable for the second. The mean amplitude of the first pulse, $\\mu_1$, is simply $\\mu_A = Npq$. For the second pulse, the number of available sites is reduced by the number of sites that released on the first pulse, $k_1$. For a given outcome $k_1$, the expected number of vesicles released on the second pulse is $p(N-k_1)$. To find the overall mean number of releases on the second pulse, $\\langle k_2 \\rangle$, we must average over all possible outcomes of the first pulse:\n$$ \\langle k_2 \\rangle = \\langle p(N-k_1) \\rangle = p(N - \\langle k_1 \\rangle) $$\nSince $\\langle k_1 \\rangle = Np$, we have:\n$$ \\langle k_2 \\rangle = p(N - Np) = Np(1-p) $$\nThe mean amplitude of the second pulse, $\\mu_2$, is therefore $\\mu_2 = q \\langle k_2 \\rangle = Npq(1-p)$. The PPR is the ratio of the mean second pulse amplitude to the mean first pulse amplitude:\n$$ \\text{PPR} = \\frac{\\mu_2}{\\mu_1} = \\frac{Npq(1-p)}{Npq} = 1-p $$\nThis provides a direct measure of $p$ from the PPR, under the assumption of a pure depletion mechanism.\n\nNow, we use the provided data to determine the model parameters and check for self-consistency.\n\n**Before LTP (baseline condition):**\nGiven PPR $= 0.60$, we determine the baseline release probability, $p_{\\text{before}}$:\n$$ p_{\\text{before}} = 1 - \\text{PPR} = 1 - 0.60 = 0.40 $$\nGiven $\\text{CV}^2 = 0.1875$, we use our derived formula to find $N$:\n$$ \\text{CV}^2_{\\text{before}} = \\frac{1-p_{\\text{before}}}{N p_{\\text{before}}} \\implies 0.1875 = \\frac{1-0.40}{N \\cdot 0.40} = \\frac{0.60}{0.40 N} = \\frac{1.5}{N} $$\n$$ N = \\frac{1.5}{0.1875} = 8 $$\nThe number of release sites is $N=8$. This is a constant property of the synapse, which we assume does not change during LTP.\nFinally, using the mean EPSC amplitude $\\mu_{1, \\text{before}} = 38.4$ pA, we find the quantal amplitude $q$:\n$$ q = \\frac{\\mu_{1, \\text{before}}}{N p_{\\text{before}}} = \\frac{38.4}{8 \\cdot 0.40} = \\frac{38.4}{3.2} = 12 \\text{ pA} $$\nThe quantal size $q$ is a postsynaptic property. The hypothesis of presynaptic plasticity implies $q$ also remains constant.\n\n**After LTP:**\nGiven PPR' $= 0.45$, we determine the release probability after LTP, $p_{\\text{after}}$:\n$$ p_{\\text{after}} = 1 - \\text{PPR}' = 1 - 0.45 = 0.55 $$\nThe change in PPR from $0.60$ to $0.45$ indicates an increase in release probability, which is a hallmark of presynaptic expression of LTP.\n\nWe must now verify that this change is self-consistent with all other measurements, assuming only $p$ has changed (i.e., the plasticity is purely presynaptic, with $N=8$ and $q=12$ pA remaining constant).\nWe predict the new mean EPSC amplitude, $\\mu_{1, \\text{after}}$:\n$$ \\mu_{1, \\text{predicted}} = N p_{\\text{after}} q = 8 \\cdot 0.55 \\cdot 12 = 52.8 \\text{ pA} $$\nThis predicted value matches the measured value $\\mu_{1, \\text{after}} = 52.8$ pA exactly.\nNext, we predict the new $\\text{CV}^2_{\\text{after}}$:\n$$ \\text{CV}^2_{\\text{predicted}} = \\frac{1-p_{\\text{after}}}{N p_{\\text{after}}} = \\frac{1-0.55}{8 \\cdot 0.55} = \\frac{0.45}{4.4} = \\frac{9}{88} \\approx 0.10227... $$\nThis predicted value is in excellent agreement with the measured value $\\text{CV}^2_{\\text{after}} = 0.1023$. The minuscule discrepancy is attributable to rounding in the provided measurement data. Thus, the full set of measurements is self-consistent under the hypothesis of a purely presynaptic change in release probability $p$.\n\nFinally, we compute the fold-change in release probability, $p_{\\text{after}}/p_{\\text{before}}$:\n$$ \\frac{p_{\\text{after}}}{p_{\\text{before}}} = \\frac{0.55}{0.40} = \\frac{55}{40} = \\frac{11}{8} = 1.375 $$\nRounding to four significant figures as requested, the result is $1.375$.", "answer": "$$\n\\boxed{1.375}\n$$", "id": "2840032"}, {"introduction": "The strength of many excitatory synapses is dynamically regulated by the number of AMPA receptors in the postsynaptic membrane. This practice delves into this core mechanism, asking you to model the process using differential equations based on mass-action kinetics [@problem_id:2839982]. By analyzing how changes in receptor insertion and removal rates lead to a new steady-state synaptic conductance, you will gain a quantitative understanding of how postsynaptic long-term potentiation (LTP) is expressed and maintained.", "problem": "A single excitatory synapse on a dendritic spine contains a pool of $\\alpha$-amino-3-hydroxy-5-methyl-4-isoxazolepropionic acid (AMPA) receptors that cycle between an intracellular pool and the postsynaptic membrane. Let $S$ denote the fixed number of available binding “slots” at the synapse, and let $N(t)$ denote the number of AMPA receptors occupying those slots at time $t$. Assume mass-action trafficking with:\n- an exocytosis (insertion) process that inserts AMPA receptors into empty slots at rate constant $k_{\\mathrm{ins}}$ (units $\\mathrm{s}^{-1}$), and\n- an endocytosis (removal) process that removes AMPA receptors from the membrane at rate constant $k_{\\mathrm{rem}}$ (units $\\mathrm{s}^{-1}$).\n\nAssume the single-receptor unitary contribution to synaptic conductance is constant and denoted $g_{\\mathrm{unit}}$ (units $\\mathrm{S}$), so that the AMPA-mediated synaptic conductance is $g_{\\mathrm{AMPA}}(t)=g_{\\mathrm{unit}}\\,N(t)$.\n\nStarting from conservation of slots and mass-action kinetics, derive the dynamical equation for $N(t)$ and hence for $g_{\\mathrm{AMPA}}(t)$ under constant $k_{\\mathrm{ins}}$ and $k_{\\mathrm{rem}}$. Then consider a long-term potentiation (LTP) induction at time $t=0$ that instantaneously changes the rate constants from pre-induction values $\\{k_{\\mathrm{ins}}^{-},k_{\\mathrm{rem}}^{-}\\}$ to post-induction values $\\{k_{\\mathrm{ins}}^{+},k_{\\mathrm{rem}}^{+}\\}$, with $N(0)$ equal to the pre-induction steady state.\n\nUsing your derived model, show how LTP emerges as a shift in the steady-state conductance and obtain a closed-form expression for $g_{\\mathrm{AMPA}}(t)$ for $t\\ge 0$ in terms of $\\{S,g_{\\mathrm{unit}},k_{\\mathrm{ins}}^{\\pm},k_{\\mathrm{rem}}^{\\pm}\\}$.\n\nFinally, evaluate the fold-change in the steady-state conductance $g_{\\mathrm{AMPA}}^{*}$ induced by LTP, defined as the ratio $g_{\\mathrm{AMPA}}^{*+}/g_{\\mathrm{AMPA}}^{*-}$, for the following biologically plausible parameters:\n- Pre-induction: $k_{\\mathrm{ins}}^{-}=0.010~\\mathrm{s}^{-1}$, $k_{\\mathrm{rem}}^{-}=0.020~\\mathrm{s}^{-1}$.\n- Post-induction: $k_{\\mathrm{ins}}^{+}$ is multiplied by $3$ relative to $k_{\\mathrm{ins}}^{-}$, and $k_{\\mathrm{rem}}^{+}$ is multiplied by $0.8$ relative to $k_{\\mathrm{rem}}^{-}$.\n\nReport the fold-change as a pure decimal (no units) and round your answer to four significant figures.", "solution": "The problem as stated is scientifically grounded, well-posed, and internally consistent. It describes a standard simplified model of AMPA receptor trafficking, a fundamental mechanism of synaptic plasticity. We shall therefore proceed with its solution.\n\nFirst, we derive the dynamical equation governing the number of postsynaptic AMPA receptors, $N(t)$. The model is based on mass-action kinetics. The total number of available \"slots\" for receptors is a fixed number, $S$. The number of occupied slots at time $t$ is $N(t)$, so the number of empty slots is $S - N(t)$.\n\nThe rate of insertion (exocytosis) is proportional to the number of empty slots, with rate constant $k_{\\mathrm{ins}}$.\nRate of insertion = $k_{\\mathrm{ins}} (S - N(t))$.\n\nThe rate of removal (endocytosis) is proportional to the number of occupied slots, with rate constant $k_{\\mathrm{rem}}$.\nRate of removal = $k_{\\mathrm{rem}} N(t)$.\n\nThe net rate of change of $N(t)$ is the difference between the insertion and removal rates:\n$$\n\\frac{dN(t)}{dt} = k_{\\mathrm{ins}}(S - N(t)) - k_{\\mathrm{rem}}N(t)\n$$\nThis equation can be rearranged into the form of a first-order linear ordinary differential equation:\n$$\n\\frac{dN(t)}{dt} = k_{\\mathrm{ins}}S - (k_{\\mathrm{ins}} + k_{\\mathrm{rem}})N(t)\n$$\nThe synaptic conductance $g_{\\mathrm{AMPA}}(t)$ is directly proportional to $N(t)$ via the unitary conductance $g_{\\mathrm{unit}}$, such that $g_{\\mathrm{AMPA}}(t) = g_{\\mathrm{unit}}N(t)$. We can express the dynamics in terms of $g_{\\mathrm{AMPA}}(t)$. Since $g_{\\mathrm{unit}}$ is constant, we have $N(t) = g_{\\mathrm{AMPA}}(t)/g_{\\mathrm{unit}}$ and $\\frac{dN(t)}{dt} = \\frac{1}{g_{\\mathrm{unit}}}\\frac{dg_{\\mathrm{AMPA}}(t)}{dt}$. Substituting these into the differential equation for $N(t)$:\n$$\n\\frac{1}{g_{\\mathrm{unit}}}\\frac{dg_{\\mathrm{AMPA}}(t)}{dt} = k_{\\mathrm{ins}}S - (k_{\\mathrm{ins}} + k_{\\mathrm{rem}})\\frac{g_{\\mathrm{AMPA}}(t)}{g_{\\mathrm{unit}}}\n$$\nMultiplying through by $g_{\\mathrm{unit}}$ gives the dynamical equation for the synaptic conductance:\n$$\n\\frac{dg_{\\mathrm{AMPA}}(t)}{dt} = k_{\\mathrm{ins}}g_{\\mathrm{unit}}S - (k_{\\mathrm{ins}} + k_{\\mathrm{rem}})g_{\\mathrm{AMPA}}(t)\n$$\nThe steady-state conductance, which we denote as $g_{\\mathrm{AMPA}}^{*}$, is found by setting the derivative to zero, $\\frac{dg_{\\mathrm{AMPA}}}{dt} = 0$:\n$$\n0 = k_{\\mathrm{ins}}g_{\\mathrm{unit}}S - (k_{\\mathrm{ins}} + k_{\\mathrm{rem}})g_{\\mathrm{AMPA}}^{*}\n$$\nSolving for $g_{\\mathrm{AMPA}}^{*}$ yields:\n$$\ng_{\\mathrm{AMPA}}^{*} = \\frac{k_{\\mathrm{ins}}g_{\\mathrm{unit}}S}{k_{\\mathrm{ins}} + k_{\\mathrm{rem}}}\n$$\nLong-term potentiation (LTP) is manifested in this model as a persistent increase in synaptic conductance. This is achieved by changing the rate constants. Before the LTP induction at $t=0$, the system is at a steady state defined by the rates $\\{k_{\\mathrm{ins}}^{-}, k_{\\mathrm{rem}}^{-}\\}$. The pre-induction steady-state conductance is:\n$$\ng_{\\mathrm{AMPA}}^{*-} = \\frac{k_{\\mathrm{ins}}^{-}g_{\\mathrm{unit}}S}{k_{\\mathrm{ins}}^{-} + k_{\\mathrm{rem}}^{-}}\n$$\nAt $t=0$, the rates are instantaneously changed to $\\{k_{\\mathrm{ins}}^{+}, k_{\\mathrm{rem}}^{+}\\}$. The system will then evolve towards a new, post-induction steady state:\n$$\ng_{\\mathrm{AMPA}}^{*+} = \\frac{k_{\\mathrm{ins}}^{+}g_{\\mathrm{unit}}S}{k_{\\mathrm{ins}}^{+} + k_{\\mathrm{rem}}^{+}}\n$$\nLTP occurs if $g_{\\mathrm{AMPA}}^{*+} > g_{\\mathrm{AMPA}}^{*-}$. According to the problem, $k_{\\mathrm{ins}}$ increases and $k_{\\mathrm{rem}}$ decreases, which ensures that the fraction of occupied slots at steady state, $\\frac{k_{\\mathrm{ins}}}{k_{\\mathrm{ins}} + k_{\\mathrm{rem}}}$, increases, thus leading to potentiation.\n\nTo find the time course of the conductance change for $t \\ge 0$, we must solve the differential equation with the post-induction rates and the appropriate initial condition. The equation is:\n$$\n\\frac{dg_{\\mathrm{AMPA}}(t)}{dt} = k_{\\mathrm{ins}}^{+}g_{\\mathrm{unit}}S - (k_{\\mathrm{ins}}^{+} + k_{\\mathrm{rem}}^{+})g_{\\mathrm{AMPA}}(t)\n$$\nThis ODE can be written as $\\frac{dg_{\\mathrm{AMPA}}(t)}{dt} + (k_{\\mathrm{ins}}^{+} + k_{\\mathrm{rem}}^{+})g_{\\mathrm{AMPA}}(t) = k_{\\mathrm{ins}}^{+}g_{\\mathrm{unit}}S$. The general solution is the sum of the homogeneous solution and a particular solution. The particular solution is the new steady state $g_{\\mathrm{AMPA}}^{*+}$. The full solution is:\n$$\ng_{\\mathrm{AMPA}}(t) = g_{\\mathrm{AMPA}}^{*+} + C \\exp(-(k_{\\mathrm{ins}}^{+} + k_{\\mathrm{rem}}^{+})t)\n$$\nThe constant $C$ is determined by the initial condition at $t=0$. The system starts from the pre-induction steady state, so $g_{\\mathrm{AMPA}}(0) = g_{\\mathrm{AMPA}}^{*-}$.\n$$\ng_{\\mathrm{AMPA}}(0) = g_{\\mathrm{AMPA}}^{*-} = g_{\\mathrm{AMPA}}^{*+} + C \\exp(0) \\implies C = g_{\\mathrm{AMPA}}^{*-} - g_{\\mathrm{AMPA}}^{*+}\n$$\nSubstituting $C$ back into the solution, we obtain the closed-form expression for the conductance for $t \\ge 0$:\n$$\ng_{\\mathrm{AMPA}}(t) = g_{\\mathrm{AMPA}}^{*+} + (g_{\\mathrm{AMPA}}^{*-} - g_{\\mathrm{AMPA}}^{*+})\\exp(-(k_{\\mathrm{ins}}^{+} + k_{\\mathrm{rem}}^{+})t)\n$$\nReplacing the steady-state terms with their full expressions in terms of the fundamental parameters gives:\n$$\ng_{\\mathrm{AMPA}}(t) = \\frac{g_{\\mathrm{unit}}Sk_{\\mathrm{ins}}^{+}}{k_{\\mathrm{ins}}^{+}+k_{\\mathrm{rem}}^{+}} + \\left(\\frac{g_{\\mathrm{unit}}Sk_{\\mathrm{ins}}^{-}}{k_{\\mathrm{ins}}^{-}+k_{\\mathrm{rem}}^{-}} - \\frac{g_{\\mathrm{unit}}Sk_{\\mathrm{ins}}^{+}}{k_{\\mathrm{ins}}^{+}+k_{\\mathrm{rem}}^{+}}\\right) \\exp(-(k_{\\mathrm{ins}}^{+} + k_{\\mathrm{rem}}^{+})t)\n$$\nFinally, we must evaluate the fold-change in the steady-state conductance, defined as the ratio $g_{\\mathrm{AMPA}}^{*+}/g_{\\mathrm{AMPA}}^{*-}$.\n$$\n\\frac{g_{\\mathrm{AMPA}}^{*+}}{g_{\\mathrm{AMPA}}^{*-}} = \\frac{\\frac{k_{\\mathrm{ins}}^{+}g_{\\mathrm{unit}}S}{k_{\\mathrm{ins}}^{+} + k_{\\mathrm{rem}}^{+}}}{\\frac{k_{\\mathrm{ins}}^{-}g_{\\mathrm{unit}}S}{k_{\\mathrm{ins}}^{-} + k_{\\mathrm{rem}}^{-}}} = \\left(\\frac{k_{\\mathrm{ins}}^{+}}{k_{\\mathrm{ins}}^{-}}\\right) \\left(\\frac{k_{\\mathrm{ins}}^{-} + k_{\\mathrm{rem}}^{-}}{k_{\\mathrm{ins}}^{+} + k_{\\mathrm{rem}}^{+}}\\right)\n$$\nWe are given the following parameter values:\n$k_{\\mathrm{ins}}^{-} = 0.010~\\mathrm{s}^{-1}$\n$k_{\\mathrm{rem}}^{-} = 0.020~\\mathrm{s}^{-1}$\n$k_{\\mathrm{ins}}^{+} = 3 \\times k_{\\mathrm{ins}}^{-} = 3 \\times 0.010~\\mathrm{s}^{-1} = 0.030~\\mathrm{s}^{-1}$\n$k_{\\mathrm{rem}}^{+} = 0.8 \\times k_{\\mathrm{rem}}^{-} = 0.8 \\times 0.020~\\mathrm{s}^{-1} = 0.016~\\mathrm{s}^{-1}$\n\nNow we substitute these values into the expression for the fold-change.\nThe ratio of insertion rates is $\\frac{k_{\\mathrm{ins}}^{+}}{k_{\\mathrm{ins}}^{-}} = 3$.\nThe sum of pre-induction rates is $k_{\\mathrm{ins}}^{-} + k_{\\mathrm{rem}}^{-} = 0.010 + 0.020 = 0.030~\\mathrm{s}^{-1}$.\nThe sum of post-induction rates is $k_{\\mathrm{ins}}^{+} + k_{\\mathrm{rem}}^{+} = 0.030 + 0.016 = 0.046~\\mathrm{s}^{-1}$.\n\nThe fold-change is therefore:\n$$\n\\frac{g_{\\mathrm{AMPA}}^{*+}}{g_{\\mathrm{AMPA}}^{*-}} = 3 \\times \\frac{0.030}{0.046} = \\frac{0.090}{0.046} = \\frac{90}{46} = \\frac{45}{23}\n$$\nConverting this fraction to a decimal:\n$$\n\\frac{45}{23} \\approx 1.9565217...\n$$\nRounding to four significant figures, we obtain $1.957$.", "answer": "$$\n\\boxed{1.957}\n$$", "id": "2839982"}, {"introduction": "Synaptic plasticity rules do not operate in isolation; they collectively shape the intricate wiring diagram of the brain. This computational exercise transitions from the single synapse to the circuit level, allowing you to implement a Hebbian learning rule to see how network structure emerges from correlated activity patterns [@problem_id:2840008]. By simulating the evolution of synaptic weights between two populations, you will directly observe how \"cells that fire together, wire together\" can sculpt a random network into one with specific, functional connectivity motifs.", "problem": "You are asked to implement a principled calculation showing how pairwise connectivity motifs emerge between two neural populations under a correlation-based plasticity rule. Consider two populations, denoted $A$ and $B$, each of size $N$. Assume that neurons are rate units driven by zero-mean external inputs whose second-order statistics are summarized by cross-covariance matrices. The task is to compute the steady-state inter-population synaptic weight matrices under a covariance Hebbian rule with homeostatic decay and a non-negativity constraint (excitatory-only projections), and then quantify motif prevalence as a function of input correlation structure.\n\nFundamental base and modeling assumptions:\n- Use the classical Hebbian principle: synaptic weight change is proportional to the correlation between pre- and post-synaptic activities. Implement covariance Hebbian learning with linear homeostatic decay, a widely used and experimentally grounded form of synaptic plasticity. For a synaptic weight $w_{ij}$ from presynaptic neuron $j$ in population $A$ to postsynaptic neuron $i$ in population $B$, the expected-rate learning dynamics are\n$$\n\\frac{d}{dt} w^{AB}_{ij} = \\eta \\left( \\mathbb{E}[b_i a_j] - \\gamma_{AB} w^{AB}_{ij} \\right),\n$$\nand for the reverse direction\n$$\n\\frac{d}{dt} w^{BA}_{ji} = \\eta \\left( \\mathbb{E}[a_j b_i] - \\gamma_{BA} w^{BA}_{ji} \\right),\n$$\nwhere $a_j$ and $b_i$ are zero-mean activities of neurons in populations $A$ and $B$, $\\eta$ is a learning-rate constant, and $\\gamma_{AB}$ and $\\gamma_{BA}$ are decay rates that stabilize weights. Assume excitatory-only synapses implemented by non-negativity projection on the weights.\n- Assume a linear instantaneous relationship between inputs and activities (no recurrent contribution to activities during learning), so that the relevant drivers for plasticity are the external cross-covariances. Define the input cross-covariance $C_{AB} \\in \\mathbb{R}^{N \\times N}$ with entries $C^{AB}_{ij} = \\mathbb{E}[a_i b_j]$, and $C_{BA} = (C_{AB})^\\top$ up to a scalar asymmetry factor.\n\nFrom the above, in matrix form and at steady state, set derivatives to zero and apply the non-negativity projection,\n$$\nW_{BA}^\\star = \\max\\!\\left(0, \\frac{1}{\\gamma_{BA}} C_{AB} \\right), \\quad\nW_{AB}^\\star = \\max\\!\\left(0, \\frac{1}{\\gamma_{AB}} C_{BA} \\right),\n$$\nwhere $\\max(0,\\cdot)$ is applied elementwise. These steady-state weights encode how motifs emerge from the correlation structure.\n\nConnectivity motifs to quantify:\n- Define a threshold $T > 0$ to classify strong connections. For each ordered pair $(i,j)$ with $i \\in \\{1,\\dots,N\\}$ in $A$ and $j \\in \\{1,\\dots,N\\}$ in $B$:\n    - A reciprocal motif occurs if $W^\\star_{BA}[i,j] > T$ and $W^\\star_{AB}[j,i] > T$.\n    - An $A \\to B$ only motif occurs if $W^\\star_{AB}[j,i] > T$ and $W^\\star_{BA}[i,j] \\le T$.\n    - A $B \\to A$ only motif occurs if $W^\\star_{BA}[i,j] > T$ and $W^\\star_{AB}[j,i] \\le T$.\nCompute motif fractions as counts divided by the total number of ordered pairs $N^2$ and report them as decimals (not percentages).\n\nInput correlation parametrization for the test suite:\n- Construct $C_{AB}$ by\n$$\nC^{AB}_{ij} = r_0 + d \\cdot \\mathbf{1}[i=j] + o \\cdot \\mathbf{1}[i \\ne j],\n$$\nwith $r_0$ the base correlation level, $d$ a diagonal boost, and $o$ an off-diagonal adjustment (which may be negative). Introduce directional asymmetry by setting\n$$\nC_{BA} = a \\cdot (C_{AB})^\\top,\n$$\nwith scalar $a$ controlling direction-dependent correlation strength.\n\nYour program must implement the computation of $W^\\star_{AB}$ and $W^\\star_{BA}$, apply the threshold $T$, compute the three motif fractions, and return the results for each test case.\n\nTest suite (each case is a tuple $(N, r_0, d, o, a, \\gamma_{AB}, \\gamma_{BA}, T)$):\n- Case $1$: $(6, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.05)$.\n- Case $2$: $(6, 0.12, 0.0, 0.0, 1.0, 1.0, 1.0, 0.10)$.\n- Case $3$: $(6, 0.02, 0.20, -0.03, 1.0, 1.0, 1.0, 0.10)$.\n- Case $4$: $(6, 0.08, 0.06, 0.00, 0.5, 1.0, 1.0, 0.10)$.\n\nRequired final output format:\n- For each test case, compute a list $[\\text{recip}, \\text{AtoB\\_only}, \\text{BtoA\\_only}]$ of the three motif fractions rounded to three decimal places. Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, where each element is the list for a test case, in order (for example, $[[0.000,0.000,0.000],[1.000,0.000,0.000],\\dots]$). No other text should be printed.", "solution": "The problem is valid. It presents a well-defined computational task based on a standard, scientifically grounded model of correlation-based synaptic plasticity in neuroscience. All necessary parameters and definitions are provided, and the problem is logically consistent and objective.\n\nThe objective is to calculate the prevalence of specific synaptic connectivity motifs between two neural populations, $A$ and $B$, which emerge from a Hebbian learning rule. The prevalence is to be quantified as a function of the statistical structure of external inputs. The solution proceeds in a sequence of logical steps.\n\nFirst, we must establish the structure of the input correlations that drive synaptic changes. The problem specifies a parametric form for the cross-covariance matrix $C_{AB} \\in \\mathbb{R}^{N \\times N}$, whose elements $C^{AB}_{ij} = \\mathbb{E}[a_i b_j]$ represent the covariance between the activity $a_i$ of neuron $i$ in population $A$ and the activity $b_j$ of neuron $j$ in population $B$. The matrix is constructed as:\n$$\nC^{AB}_{ij} = r_0 + d \\cdot \\mathbf{1}[i=j] + o \\cdot \\mathbf{1}[i \\ne j]\n$$\nHere, $N$ is the size of each population, $r_0$ is a baseline correlation, $d$ is a diagonal-specific boost (representing, for example, stronger correlation for neurons with corresponding indices), and $o$ is an off-diagonal adjustment. The term $\\mathbf{1}[\\cdot]$ is the indicator function, which is $1$ if its argument is true and $0$ otherwise. This structure can be efficiently implemented by creating a matrix of size $N \\times N$ filled with the value $r_0 + o$, and then setting the diagonal elements to $r_0 + d$.\n\nSecond, we determine the cross-covariance matrix for the reverse direction, $C_{BA}$. The problem states that this matrix is related to $C_{AB}$ by an asymmetry factor $a$:\n$$\nC_{BA} = a \\cdot (C_{AB})^\\top\n$$\nwhere $(C_{AB})^\\top$ is the transpose of $C_{AB}$. This parameter $a$ introduces a potential asymmetry in the correlations, meaning the correlation between neuron $i \\in A$ and $j \\in B$ might not be the same as the correlation between $j \\in B$ and $i \\in A$.\n\nThird, we compute the steady-state synaptic weight matrices. The learning dynamics are given by a covariance-based Hebbian rule with linear homeostatic decay:\n$$\n\\frac{d}{dt} w^{AB}_{ij} = \\eta \\left( \\mathbb{E}[b_i a_j] - \\gamma_{AB} w^{AB}_{ij} \\right)\n$$\n$$\n\\frac{d}{dt} w^{BA}_{ji} = \\eta \\left( \\mathbb{E}[a_j b_i] - \\gamma_{BA} w^{BA}_{ji} \\right)\n$$\nwhere $w^{AB}_{ij}$ is the weight from neuron $j \\in A$ to $i \\in B$, and $w^{BA}_{ji}$ is from $i \\in B$ to $j \\in A$. At steady state, the time derivatives are set to zero, $\\frac{d}{dt} = 0$. Solving for the weights and applying a non-negativity constraint (as synapses are excitatory), we obtain the steady-state weight matrices $W_{AB}^\\star$ (from population $A$ to $B$) and $W_{BA}^\\star$ (from population $B$ to $A$). In matrix form, these are:\n$$\nW_{BA}^\\star = \\max\\!\\left(0, \\frac{1}{\\gamma_{BA}} C_{AB} \\right)\n$$\n$$\nW_{AB}^\\star = \\max\\!\\left(0, \\frac{1}{\\gamma_{AB}} C_{BA} \\right)\n$$\nThe $\\max(0, \\cdot)$ operation is applied element-wise, ensuring all synaptic weights are non-negative. $\\gamma_{AB}$ and $\\gamma_{BA}$ are the decay constants for the respective synaptic projections.\n\nFourth, we identify strong connections, which are the basis for forming motifs. A connection is defined as strong if its weight exceeds a given threshold $T > 0$. We must consider both directions of connectivity between any pair of neurons $(i, j)$, where neuron $i$ is in population $A$ and neuron $j$ is in population $B$.\nThe weight of the connection from neuron $i \\in A$ to neuron $j \\in B$ is given by the element $W_{AB}^\\star[j, i]$.\nThe weight of the connection from neuron $j \\in B$ to neuron $i \\in A$ is given by the element $W_{BA}^\\star[i, j]$.\nWe can create two boolean matrices to represent strong connections. Let `strong_AtoB` be an $N \\times N$ matrix where `strong_AtoB`$[i,j]$ is true if the connection from neuron $i \\in A$ to neuron $j \\in B$ is strong. This is checked by the condition $W_{AB}^\\star[j, i] > T$. Similarly, let `strong_BtoA`$[i,j]$ be true if the connection from neuron $j \\in B$ to neuron $i \\in A$ is strong, checked by $W_{BA}^\\star[i, j] > T$.\n\nFifth, we count the number of occurrences of each of the three defined motifs across all $N^2$ possible neuron pairs. Using the boolean matrices from the previous step, we can use logical operations to find the counts:\n- **Reciprocal motif:** Both connections are strong. The count is the number of pairs $(i, j)$ where `strong_AtoB`$[i,j]$ and `strong_BtoA`$[i,j]$ are both true.\n- **$A \\to B$ only motif:** The connection from $A$ to $B$ is strong, but the reverse is not. The count is the number of pairs where `strong_AtoB`$[i,j]$ is true and `strong_BtoA`$[i,j]$ is false.\n- **$B \\to A$ only motif:** The connection from $B$ to $A$ is strong, but the reverse is not. The count is the number of pairs where `strong_BtoA`$[i,j]$ is true and `strong_AtoB`$[i,j]$ is false.\n\nFinally, the motif fractions are calculated by dividing the count for each motif type by the total number of pairs, which is $N^2$. These fractions are then rounded to three decimal places as required. This procedure is repeated for each test case provided in the problem statement.", "answer": "[[0.000,0.000,0.000],[1.000,0.000,0.000],[0.167,0.000,0.000],[0.000,0.000,0.167]]", "id": "2840008"}]}