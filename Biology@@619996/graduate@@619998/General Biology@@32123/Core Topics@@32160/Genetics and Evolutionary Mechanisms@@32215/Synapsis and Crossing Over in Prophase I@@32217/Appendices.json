{"hands_on_practices": [{"introduction": "A fundamental skill in cell biology is translating static images from a population of cells into a dynamic understanding of a biological process. This exercise simulates the analysis of immunofluorescence data to connect the molecular choreography of synapsis and recombination with the classical stages of meiotic prophase I. By categorizing nuclei based on the presence and pattern of key protein markers, you will not only identify the sequence of events but also apply a steady-state assumption to estimate the relative time cells spend in each stage, a powerful concept for studying the kinetics of cellular pathways [@problem_id:2839833].", "problem": "A researcher performs immunofluorescence microscopy on a large asynchronous population of mammalian spermatocyte nuclei to study synapsis and crossing over during meiotic prophase I. For each nucleus, three markers are recorded: Synaptonemal Complex Protein 3 (SYCP3; axial/lateral elements), Synaptonemal Complex Protein 1 (SYCP1; transverse filaments indicating synapsis), and MutL homolog 1 (MLH1; crossover-designated recombination nodules). The population is assumed to be at steady state with respect to meiotic progression, and sampling is uniform across substages.\n\nAcross a sample of $N = 500$ nuclei, the following qualitative marker patterns and counts are observed:\n- Pattern A: SYCP3-positive axial elements, SYCP1 undetectable, MLH1 foci $= 0$; count $= 75$.\n- Pattern B: SYCP3-positive axial elements, SYCP1 discontinuous/partial filaments, MLH1 foci $= 0$; count $= 140$.\n- Pattern C: SYCP3-positive axial elements, SYCP1 continuous filaments spanning nearly all homologs, MLH1 foci $= 0$; count $= 150$.\n- Pattern D: SYCP3-positive axial elements, SYCP1 continuous filaments spanning nearly all homologs, MLH1 foci $> 0$; count $= 80$.\n- Pattern E: SYCP3-positive axial elements, SYCP1 discontinuous or fragmented filaments, MLH1 foci $> 0$; count $= 55$.\n\nBased only on widely accepted marker dynamics for the synaptonemal complex and crossover designation across prophase I substages, first infer which meiotic prophase I substage (leptotene, zygotene, pachytene, diplotene) each pattern corresponds to. Then, using the standard steady-state fraction-of-cells argument to relate substage occupancy to substage duration, estimate the absolute duration of pachytene if the total duration of meiotic prophase I in this system is $T = 96$ hours. Round your final numerical answer to four significant figures and express it in hours. Provide only the single requested numerical value for the pachytene duration in your final answer.", "solution": "The problem statement is subjected to critical validation before any attempt at a solution.\n\nStep 1: Extract Givens.\n- Total number of nuclei sampled: $N = 500$.\n- Population is asynchronous and at steady state.\n- Sampling is uniform across prophase I substages.\n- Total duration of meiotic prophase I: $T = 96$ hours.\n- Markers: SYCP3 (axial elements), SYCP1 (synapsis), MLH1 (crossovers).\n- Observed patterns and counts:\n  - Pattern A: SYCP3+, SYCP1-, MLH1=0; count $N_A = 75$.\n  - Pattern B: SYCP3+, SYCP1 discontinuous, MLH1=0; count $N_B = 140$.\n  - Pattern C: SYCP3+, SYCP1 continuous, MLH1=0; count $N_C = 150$.\n  - Pattern D: SYCP3+, SYCP1 continuous, MLH1>0; count $N_D = 80$.\n  - Pattern E: SYCP3+, SYCP1 discontinuous/fragmented, MLH1>0; count $N_E = 55$.\nThe sum of counts is $75 + 140 + 150 + 80 + 55 = 500$, which matches the total sample size $N$.\n\nStep 2: Validate Using Extracted Givens.\nThe problem is scientifically grounded. The premise is based on the canonical progression of meiotic prophase I in eukaryotes, and the markers used (SYCP3, SYCP1, MLH1) are standard cytological indicators for the synaptonemal complex and crossover formation. The described patterns A through E correctly represent the expected sequence of events: axial element formation, initiation of synapsis, completion of synapsis, maturation of crossover sites, and disassembly of the synaptonemal complex. The problem is well-posed, providing all necessary information for a unique solution under the steady-state assumption. The language is objective and unambiguous. The problem is self-contained and internally consistent.\n\nStep 3: Verdict and Action.\nThe problem is valid. A solution will be derived.\n\nThe first task is to assign each observed pattern to its corresponding substage of meiotic prophase I. The progression is as follows: Leptotene $\\rightarrow$ Zygotene $\\rightarrow$ Pachytene $\\rightarrow$ Diplotene.\n- **Leptotene**: Axial elements, marked by SYCP3, begin to form along chromosomes. Synapsis has not yet begun, so SYCP1 is absent. Crossover designation has not occurred, so MLH1 is absent. This corresponds to Pattern A: SYCP3+, SYCP1-, MLH1=0.\n- **Zygotene**: Synapsis initiates, with transverse filaments (SYCP1) beginning to connect homologous chromosomes. The synaptonemal complex is therefore incomplete or discontinuous. Crossover designation has not yet completed. This corresponds to Pattern B: SYCP3+, SYCP1 discontinuous, MLH1=0.\n- **Pachytene**: Synapsis is complete, with continuous SYCP1 filaments along the full length of the bivalents. During this stage, recombination nodules mature, and a subset become designated as crossovers, which are then marked by MLH1. The absence and presence of MLH1 foci on fully synapsed chromosomes allows us to subdivide the pachytene stage for observational purposes. Pattern C (SYCP3+, SYCP1 continuous, MLH1=0) represents early pachytene, before MLH1 foci are stabilised and detectable. Pattern D (SYCP3+, SYCP1 continuous, MLH1>0) represents mid-to-late pachytene, where crossover designation is cytologically visible. Therefore, the entire pachytene stage encompasses both Pattern C and Pattern D.\n- **Diplotene**: The synaptonemal complex disassembles, leading to fragmentation and loss of the continuous SYCP1 signal. The homologous chromosomes are held together by chiasmata, the structural consequence of the crossovers marked by MLH1 foci. This corresponds to Pattern E: SYCP3+, SYCP1 discontinuous/fragmented, MLH1>0.\n\nThe problem requires the calculation of the duration of pachytene. The total number of cells observed in pachytene, $N_{pachy}$, is the sum of the counts for Patterns C and D.\n$$N_{pachy} = N_C + N_D = 150 + 80 = 230$$\n\nThe problem states that the cell population is at a steady state. This is a crucial condition. For a process with a total duration $T_{total}$ composed of sequential stages with durations $T_i$, the fraction of the population observed in stage $i$ at any given moment, $\\frac{N_i}{N_{total}}$, is directly proportional to the relative duration of that stage, $\\frac{T_i}{T_{total}}$.\nThis relationship is expressed as:\n$$\\frac{N_i}{N_{total}} = \\frac{T_i}{T_{total}}$$\nWe can solve for the duration of a specific stage, $T_i$:\n$$T_i = T_{total} \\times \\frac{N_i}{N_{total}}$$\nIn this problem, we want to find the duration of pachytene, $T_{pachy}$. We are given:\n- Total duration of prophase I, $T_{total} = T = 96$ hours.\n- Total number of cells, $N_{total} = N = 500$.\n- Number of cells in pachytene, $N_{pachy} = 230$.\n\nSubstituting these values into the formula:\n$$T_{pachy} = T \\times \\frac{N_{pachy}}{N}$$\n$$T_{pachy} = 96 \\times \\frac{230}{500}$$\nFirst, we compute the fraction:\n$$\\frac{230}{500} = \\frac{23}{50} = 0.46$$\nNow, we calculate the duration:\n$$T_{pachy} = 96 \\times 0.46$$\n$$T_{pachy} = 44.16 \\text{ hours}$$\nThe problem asks for the result to be rounded to four significant figures. The calculated value $44.16$ already has four significant figures. No further rounding is necessary. The duration of pachytene is $44.16$ hours.", "answer": "$$\\boxed{44.16}$$", "id": "2839833"}, {"introduction": "Raw experimental counts are often just the starting point for quantitative biological inquiry. This practice delves into the critical step of data correction, a necessary procedure to account for the imperfections and limitations inherent in any measurement technique [@problem_id:2839805]. By correcting observed crossover marker foci for detection efficiency and the completeness of synapsis, you will calculate the true underlying frequencies of both interference-sensitive (Class I) and interference-insensitive (Class II) crossovers, providing a more accurate picture of how these two distinct pathways contribute to overall recombination.", "problem": "A cytological analysis of meiotic prophase I is performed in a rodent testis to estimate the number of crossovers per nucleus and to partition the interference-free component. The following facts are well established and will serve as the basis for your reasoning:\n\n- Class I crossovers are interference-sensitive and are specifically marked at late pachytene by MutL homolog 1 (MLH1) and MutL homolog 3 (MLH3) co-foci. If each true class I crossover is independently detected with probability $a$, then the observed mean MLH1/MLH3 co-foci per nucleus equals the true mean class I crossovers multiplied by $a$ and by the fraction of chromosome axis that is synapsed at the stage when the marker is visible, because MLH1/MLH3 foci occur on synapsed axes.\n- Class II crossovers are interference-insensitive and are marked by MUS81 (MMS and UV sensitive protein 81) foci at diplotene. If each true class II crossover is independently detected with probability $b$, then the observed mean MUS81 foci per nucleus equals the true mean class II crossovers multiplied by $b$. Assume class I and class II crossovers are disjoint pathways.\n\nYou are given the following measurements:\n- Mean observed MLH1/MLH3 co-foci per nucleus in late pachytene: $m_{\\mathrm{obs}} = 17.1$.\n- Mean synapsis fraction at this stage, quantified by Synaptonemal Complex Protein 1 (SYCP1) and Synaptonemal Complex Protein 3 (SYCP3) overlap: $s = 0.95$.\n- Detection probability for an individual class I crossover by MLH1/MLH3 staining: $a = 0.90$.\n- Mean observed MUS81 foci per nucleus in diplotene (synapsis complete): $u_{\\mathrm{obs}} = 3.2$.\n- Detection probability for an individual class II crossover by MUS81 staining: $b = 0.65$.\n\nAssume uniform crossover density along synapsed axes at the stage of MLH1/MLH3 visibility, and that the MUS81 measurements are not limited by synapsis completeness. Using only these premises, compute:\n1) the corrected total number of crossovers per nucleus, and\n2) the fraction (as a decimal) of crossovers that are interference-free (class II).\n\nReport your two answers in a single row vector $\\begin{pmatrix}\\text{total crossovers} & \\text{class II fraction}\\end{pmatrix}$. Round both entries to four significant figures. Do not use a percent sign for the fraction.", "solution": "The posed problem is subjected to validation.\n\n**Step 1: Extracted Givens**\n- Class I crossovers are interference-sensitive, marked by MLH1/MLH3 co-foci. True class I crossovers are detected with probability $a$.\n- The observed mean MLH1/MLH3 co-foci per nucleus, $m_{\\mathrm{obs}}$, is related to the true mean class I crossovers, which we denote $N_{\\mathrm{I}}$, by the formula: $m_{\\mathrm{obs}} = N_{\\mathrm{I}} \\times a \\times s$, where $s$ is the mean synapsis fraction.\n- Class II crossovers are interference-insensitive, marked by MUS81 foci. True class II crossovers are detected with probability $b$.\n- The observed mean MUS81 foci per nucleus, $u_{\\mathrm{obs}}$, is related to the true mean class II crossovers, which we denote $N_{\\mathrm{II}}$, by the formula: $u_{\\mathrm{obs}} = N_{\\mathrm{II}} \\times b$.\n- Class I and Class II crossover pathways are disjoint.\n- Measured values:\n  - $m_{\\mathrm{obs}} = 17.1$\n  - $s = 0.95$\n  - $a = 0.90$\n  - $u_{\\mathrm{obs}} = 3.2$\n  - $b = 0.65$\n- Assumption: Uniform crossover density along synapsed axes.\n- Assumption: MUS81 measurements are not limited by synapsis completeness.\n- Required computation: (1) Corrected total number of crossovers per nucleus. (2) Fraction of crossovers that are interference-free (class II).\n\n**Step 2: Validation Using Extracted Givens**\nThe problem is scientifically grounded. The methodology described—using specific protein markers like MLH1/MLH3 and MUS81 to count different classes of crossovers and correcting for detection efficiency and synapsis completeness—is a standard and valid approach in modern cytogenetics and meiosis research. The problem is well-posed, providing all necessary data and relationships to compute the required quantities. The language is objective and precise. It is a formalizable problem directly relevant to the topic of prophase I. The provided data are dimensionally consistent and within a realistic range for a mammalian species. The problem setup admits a unique, stable solution. There are no apparent logical contradictions, ambiguities, or factual inaccuracies.\n\n**Step 3: Verdict and Action**\nThe problem is deemed valid. A solution will be derived.\n\nThe task is to determine the true total number of crossovers per nucleus and the fraction of these that are of Class II. Let $N_{\\mathrm{I}}$ and $N_{\\mathrm{II}}$ represent the true mean number of Class I and Class II crossovers per nucleus, respectively. The total number of crossovers is $N_{\\mathrm{total}} = N_{\\mathrm{I}} + N_{\\mathrm{II}}$, as the pathways are stated to be disjoint.\n\nFirst, we calculate the true number of Class I crossovers, $N_{\\mathrm{I}}$. The problem states the relationship between the observed mean foci, $m_{\\mathrm{obs}}$, and the true mean, $N_{\\mathrm{I}}$, is modulated by the detection probability, $a$, and the synapsis fraction, $s$. The given formula is:\n$$m_{\\mathrm{obs}} = N_{\\mathrm{I}} \\cdot a \\cdot s$$\nWe rearrange this equation to solve for $N_{\\mathrm{I}}$:\n$$N_{\\mathrm{I}} = \\frac{m_{\\mathrm{obs}}}{a \\cdot s}$$\nSubstituting the provided values, $m_{\\mathrm{obs}} = 17.1$, $a = 0.90$, and $s = 0.95$:\n$$N_{\\mathrm{I}} = \\frac{17.1}{0.90 \\times 0.95} = \\frac{17.1}{0.855} = 20$$\nThe true mean number of Class I crossovers per nucleus is exactly $20$.\n\nNext, we calculate the true number of Class II crossovers, $N_{\\mathrm{II}}$. The relationship between the observed mean foci, $u_{\\mathrm{obs}}$, and the true mean, $N_{\\mathrm{II}}$, is dependent only on the detection probability, $b$:\n$$u_{\\mathrm{obs}} = N_{\\mathrm{II}} \\cdot b$$\nWe solve for $N_{\\mathrm{II}}$:\n$$N_{\\mathrm{II}} = \\frac{u_{\\mathrm{obs}}}{b}$$\nSubstituting the values $u_{\\mathrm{obs}} = 3.2$ and $b = 0.65$:\n$$N_{\\mathrm{II}} = \\frac{3.2}{0.65} \\approx 4.9230769...$$\nThe true mean number of Class II crossovers per nucleus is approximately $4.9231$.\n\nThe total number of crossovers, $N_{\\mathrm{total}}$, is the sum of the true numbers of Class I and Class II crossovers:\n$$N_{\\mathrm{total}} = N_{\\mathrm{I}} + N_{\\mathrm{II}} = 20 + \\frac{3.2}{0.65} \\approx 20 + 4.9230769... = 24.9230769...$$\nRounding to four significant figures, the corrected total number of crossovers per nucleus is $24.92$.\n\nFinally, we compute the fraction of crossovers that are interference-free (Class II), which we denote as $F_{\\mathrm{II}}$. This is the ratio of the true number of Class II crossovers to the true total number of crossovers:\n$$F_{\\mathrm{II}} = \\frac{N_{\\mathrm{II}}}{N_{\\mathrm{total}}} = \\frac{N_{\\mathrm{II}}}{N_{\\mathrm{I}} + N_{\\mathrm{II}}}$$\nSubstituting the unrounded values for precision:\n$$F_{\\mathrm{II}} = \\frac{4.9230769...}{24.9230769...} \\approx 0.19752688...$$\nRounding to four significant figures, the fraction of Class II crossovers is $0.1975$.\n\nThe two required values are the total crossovers, $24.92$, and the Class II fraction, $0.1975$.", "answer": "$$\\boxed{\\begin{pmatrix} 24.92 & 0.1975 \\end{pmatrix}}$$", "id": "2839805"}, {"introduction": "Modern biology increasingly relies on building predictive models to understand complex systems. This advanced practice challenges you to step into the world of computational biology by constructing a statistical model to predict the activity of meiotic recombination hotspots based on genomic and epigenetic features [@problem_id:2839842]. You will formalize the biological role of the PRDM9 protein and its associated histone marks into a Poisson regression model, implement its estimation from first principles, and validate its predictive power, demonstrating the full workflow from biological hypothesis to computational validation.", "problem": "You are asked to construct and validate a quantitative model of meiotic double-strand break hotspot usage during synapsis and crossing over in prophase I. Use the following foundational biological facts as the conceptual basis for modeling: (i) in many mammals, the `PRDM9` (PR domain zinc finger protein 9) binds DNA motifs and deposits histone H3 lysine 4 trimethylation (H3K4me3) and histone H3 lysine 36 trimethylation (H3K36me3) at recombination hotspots, (ii) the topoisomerase-like protein `SPO11` generates meiotic double-strand breaks whose covalently attached oligonucleotides (`SPO11`-oligos) provide a quantitative proxy for hotspot usage, and (iii) across genomic loci, double-strand break counts are discrete events that can be reasonably modeled as draws from a counting process. Your task is to formalize these into a statistical model, estimate its parameters from synthetic training data, and validate predictions on synthetic test data that emulate `SPO11`-oligo maps.\n\nModeling requirement. Assume that, for each hotspot $i$, you observe a `PRDM9` motif score $M_i$, an H3K4me3 signal $K4_i$, and an H3K36me3 signal $K36_i$. Let the expected `SPO11`-oligo count at hotspot $i$ be $\\mu_i$. Model the observed `SPO11`-oligo counts $Y_i$ as independent draws from a Poisson process with mean $\\mu_i$, and link $\\mu_i$ to the features via a log link: for a parameter vector $\\beta \\in \\mathbb{R}^4$ and feature vector $x_i = [1, M_i, K4_i, K36_i]^\\top$, set $\\mu_i = \\exp(x_i^\\top \\beta)$. Estimate $\\beta$ by maximum likelihood using only the training data for each test case. You must derive and implement the estimator from the Poisson log-likelihood without using any black-box generalized linear model routines; use an iterative method grounded in first principles, such as Newton–Raphson or iteratively reweighted least squares, to find the maximizer.\n\nData generation. For each test case, you will generate training and test datasets according to the following deterministic procedure using a pseudorandom number generator initialized with the specified seed:\n- For a dataset of size $n$, draw $M_i \\sim \\mathcal{N}(\\mu_M, \\sigma_M^2)$ independently and then clip to the interval $[M_{\\min}, M_{\\max}]$.\n- Draw $\\varepsilon^{(4)}_i \\sim \\mathcal{N}(0, \\sigma_4^2)$ and $\\varepsilon^{(36)}_i \\sim \\mathcal{N}(0, \\sigma_{36}^2)$ independently.\n- Compute $K4_i = \\max\\{0, \\alpha_4 + \\rho_4 M_i + \\varepsilon^{(4)}_i\\}$ and $K36_i = \\max\\{0, \\alpha_{36} + \\rho_{36} M_i + \\varepsilon^{(36)}_i\\}$.\n- Let $\\eta_i = \\beta_0 + \\beta_M M_i + \\beta_4 K4_i + \\beta_{36} K36_i$ and $\\mu_i = \\exp(\\eta_i)$.\n- For Poisson noise, draw $Y_i \\sim \\text{Poisson}(\\mu_i)$. For negative binomial noise with overdispersion parameter $k > 0$, draw $\\Lambda_i \\sim \\text{Gamma}(\\text{shape}=k, \\text{scale}=\\mu_i/k)$ and then $Y_i \\sim \\text{Poisson}(\\Lambda_i)$, so that $\\mathbb{E}[Y_i]=\\mu_i$ and $\\operatorname{Var}(Y_i)=\\mu_i + \\mu_i^2/k$.\nAll random draws must be generated with a pseudorandom number generator initialized to the stated integer seed for each test case, and applied in the order specified above.\n\nEstimation. Given the training set $\\{(x_i, Y_i)\\}_{i=1}^{n_{\\text{train}}}$ in each test case, compute the maximum likelihood estimate $\\hat{\\beta}$ under the Poisson model with log link. Use $\\hat{\\beta}$ to predict $\\hat{\\mu}_j = \\exp(x_j^\\top \\hat{\\beta})$ on each test set observation $x_j$ in the corresponding test case.\n\nValidation metric. For each test case, compute the Pearson product–moment correlation coefficient between the predicted expected counts $\\{\\hat{\\mu}_j\\}_{j=1}^{n_{\\text{test}}}$ and the observed SPO$11$-oligo counts $\\{Y_j\\}_{j=1}^{n_{\\text{test}}}$ on the test set. Report this as a real number.\n\nTest suite. Implement the three test cases below. All scalars are given in the units implied by their definitions (dimensionless scores or counts). Use exactly these values:\n- Case A (Poisson, motif and histone informative): seed $123$, $n_{\\text{train}}=5000$, $n_{\\text{test}}=3000$, $\\mu_M=1.5$, $\\sigma_M=1.0$, $M_{\\min}=0.0$, $M_{\\max}=6.0$, $\\alpha_4=0.5$, $\\rho_4=0.7$, $\\sigma_4=0.5$, $\\alpha_{36}=0.3$, $\\rho_{36}=0.5$, $\\sigma_{36}=0.4$, $\\beta_0=-1.0$, $\\beta_M=0.3$, $\\beta_4=0.25$, $\\beta_{36}=0.15$; noise is Poisson.\n- Case B (Poisson, negligible direct motif effect): seed $456$, $n_{\\text{train}}=4000$, $n_{\\text{test}}=2000$, $\\mu_M=1.0$, $\\sigma_M=1.2$, $M_{\\min}=0.0$, $M_{\\max}=6.0$, $\\alpha_4=0.7$, $\\rho_4=0.6$, $\\sigma_4=0.6$, $\\alpha_{36}=0.2$, $\\rho_{36}=0.3$, $\\sigma_{36}=0.6$, $\\beta_0=-0.8$, $\\beta_M=0.0$, $\\beta_4=0.3$, $\\beta_{36}=0.2$; noise is Poisson.\n- Case C (negative binomial overdispersion): seed $789$, $n_{\\text{train}}=6000$, $n_{\\text{test}}=4000$, $\\mu_M=1.8$, $\\sigma_M=1.1$, $M_{\\min}=0.0$, $M_{\\max}=6.0$, $\\alpha_4=0.6$, $\\rho_4=0.8$, $\\sigma_4=0.7$, $\\alpha_{36}=0.4$, $\\rho_{36}=0.6$, $\\sigma_{36}=0.6$, $\\beta_0=-1.2$, $\\beta_M=0.35$, $\\beta_4=0.2$, $\\beta_{36}=0.12$; noise is negative binomial with $k=2.0$ as defined above.\n\nFinal output format. Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, ordered as $[\\text{Case A result}, \\text{Case B result}, \\text{Case C result}]$. Each result must be the Pearson correlation coefficient rounded to exactly $6$ decimal places. For example, a valid output line would look like $[0.812345,0.734567,0.652345]$.", "solution": "The problem statement has been evaluated and is deemed valid. It presents a well-posed, scientifically grounded task in computational biology and statistics. The problem provides a complete specification for data simulation, model formulation, parameter estimation, and validation, with no internal contradictions or ambiguities. The biological context concerning meiotic recombination hotspots serves as a realistic basis for a quantitative modeling exercise.\n\nThe core of the problem is to estimate the parameters of a Poisson regression model via maximum likelihood. The model specifies that the observed SPO11-oligo count $Y_i$ at hotspot $i$ is a random variable drawn from a Poisson distribution with mean $\\mu_i$:\n$$\nY_i \\sim \\text{Poisson}(\\mu_i)\n$$\nThe probability mass function is given by:\n$$\nP(Y_i = y_i | \\mu_i) = \\frac{e^{-\\mu_i} \\mu_i^{y_i}}{y_i!}\n$$\nThe mean count $\\mu_i$ is related to a set of features through a log-linear model. The feature vector for hotspot $i$ is $x_i = [1, M_i, K4_i, K36_i]^\\top$, where $1$ is for the intercept, $M_i$ is the PRDM9 motif score, $K4_i$ is the H3K4me3 signal, and $K36_i$ is the H3K36me3 signal. The parameter vector is $\\beta = [\\beta_0, \\beta_M, \\beta_4, \\beta_{36}]^\\top$. The linear predictor is $\\eta_i = x_i^\\top \\beta$, and the link between $\\mu_i$ and $\\eta_i$ is the natural logarithm (log link):\n$$\n\\ln(\\mu_i) = \\eta_i = x_i^\\top \\beta \\implies \\mu_i = \\exp(x_i^\\top \\beta)\n$$\nGiven a training dataset of $n$ observations $\\{(x_i, y_i)\\}_{i=1}^n$, the goal is to find the parameter vector $\\beta$ that maximizes the log-likelihood function. The likelihood function is the product of the individual probabilities:\n$$\nL(\\beta) = \\prod_{i=1}^n P(Y_i = y_i | x_i, \\beta) = \\prod_{i=1}^n \\frac{\\exp(-\\mu_i) \\mu_i^{y_i}}{y_i!}\n$$\nThe log-likelihood function $\\ell(\\beta)$ is:\n$$\n\\ell(\\beta) = \\ln L(\\beta) = \\sum_{i=1}^n \\left( y_i \\ln(\\mu_i) - \\mu_i - \\ln(y_i!) \\right)\n$$\nSubstituting $\\mu_i = \\exp(x_i^\\top \\beta)$, we get:\n$$\n\\ell(\\beta) = \\sum_{i=1}^n \\left( y_i (x_i^\\top \\beta) - \\exp(x_i^\\top \\beta) - \\ln(y_i!) \\right)\n$$\nTo find the maximum likelihood estimate $\\hat{\\beta}$, we must solve for $\\nabla_\\beta \\ell(\\beta) = 0$. The gradient of the log-likelihood, known as the score function $g(\\beta)$, is found by differentiating with respect to each component $\\beta_j$:\n$$\n\\frac{\\partial \\ell(\\beta)}{\\partial \\beta_j} = \\sum_{i=1}^n \\left( y_i x_{ij} - \\exp(x_i^\\top \\beta) x_{ij} \\right) = \\sum_{i=1}^n (y_i - \\mu_i) x_{ij}\n$$\nIn matrix notation, where $X$ is the $n \\times 4$ design matrix with rows $x_i^\\top$, $y$ is the vector of observed counts, and $\\mu$ is the vector of means, the gradient is:\n$$\ng(\\beta) = \\nabla_\\beta \\ell(\\beta) = X^\\top (y - \\mu)\n$$\nSince the score equations $X^\\top (y - \\exp(X\\beta)) = 0$ are non-linear in $\\beta$, an iterative numerical method is required. We employ the Newton-Raphson method, which requires the Hessian matrix of second derivatives, $H(\\beta)$. The entry $(j, k)$ of the Hessian is:\n$$\nH_{jk}(\\beta) = \\frac{\\partial^2 \\ell(\\beta)}{\\partial \\beta_j \\partial \\beta_k} = \\frac{\\partial}{\\partial \\beta_k} \\sum_{i=1}^n (y_i - \\exp(x_i^\\top \\beta)) x_{ij} = - \\sum_{i=1}^n \\exp(x_i^\\top \\beta) x_{ij} x_{ik} = - \\sum_{i=1}^n \\mu_i x_{ij} x_{ik}\n$$\nIn matrix form, the Hessian is:\n$$\nH(\\beta) = -X^\\top W X\n$$\nwhere $W$ is a diagonal matrix with diagonal entries $W_{ii} = \\mu_i$. The Newton-Raphson update rule for maximizing $\\ell(\\beta)$ is:\n$$\n\\beta^{(t+1)} = \\beta^{(t)} - [H(\\beta^{(t)})]^{-1} g(\\beta^{(t)})\n$$\nSubstituting our expressions for the gradient and Hessian:\n$$\n\\beta^{(t+1)} = \\beta^{(t)} - [-X^\\top W^{(t)} X]^{-1} [X^\\top (y - \\mu^{(t)})] = \\beta^{(t)} + (X^\\top W^{(t)} X)^{-1} X^\\top (y - \\mu^{(t)})\n$$\nwhere quantities with superscript $(t)$ are evaluated at $\\beta^{(t)}$. This update is implemented by first solving for the step $\\Delta\\beta^{(t)}$ in the linear system:\n$$\n(X^\\top W^{(t)} X) \\Delta\\beta^{(t)} = X^\\top (y - \\mu^{(t)})\n$$\nand then updating $\\beta^{(t+1)} = \\beta^{(t)} + \\Delta\\beta^{(t)}$. The iteration starts with an initial guess, such as $\\beta^{(0)} = 0$, and continues until the change in $\\beta$ is below a small tolerance.\n\nThe overall procedure is as follows:\n$1$. For each test case, generate training and testing datasets according to the specified deterministic procedure. This involves initializing a pseudorandom number generator with the given seed, sampling features $M_i$, generating correlated histone marks $K4_i$ and $K36_i$, and finally sampling the response variable $Y_i$ from either a Poisson or a Negative Binomial distribution, as specified.\n$2$. Using the training data $(X_{\\text{train}}, y_{\\text{train}})$, estimate the parameter vector $\\hat\\beta$ by implementing the Newton-Raphson algorithm described above.\n$3$. Using the estimated $\\hat\\beta$ and the test set features $X_{\\text{test}}$, predict the expected counts $\\hat{\\mu}_{\\text{test}} = \\exp(X_{\\text{test}} \\hat\\beta)$.\n$4$. Compute the Pearson product-moment correlation coefficient between the vector of predicted means $\\hat{\\mu}_{\\text{test}}$ and the vector of observed counts $y_{\\text{test}}$. This value, for each case, constitutes the final result. For Case C, the estimation is performed under a deliberately misspecified Poisson model, while the data is generated from a Negative Binomial process exhibiting overdispersion. This tests the robustness of the Poisson model fit.\n\nThe entire process is implemented in a Python script, adhering strictly to the specified libraries and versions.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n# No other libraries are needed.\n\ndef generate_data(params, n, rng):\n    \"\"\"Generates synthetic data for one dataset (train or test).\"\"\"\n    # Unpack parameters\n    true_beta = np.array([params['beta_0'], params['beta_M'], params['beta_4'], params['beta_36']])\n    \n    # Generate M_i\n    M = rng.normal(params['mu_M'], params['sigma_M'], size=n)\n    M = np.clip(M, params['M_min'], params['M_max'])\n\n    # Generate K4_i\n    eps_4 = rng.normal(0, params['sigma_4'], size=n)\n    K4 = np.maximum(0, params['alpha_4'] + params['rho_4'] * M + eps_4)\n\n    # Generate K36_i\n    eps_36 = rng.normal(0, params['sigma_36'], size=n)\n    K36 = np.maximum(0, params['alpha_36'] + params['rho_36'] * M + eps_36)\n    \n    # Construct design matrix X\n    X = np.c_[np.ones(n), M, K4, K36]\n\n    # Generate true mean mu_i\n    mu = np.exp(X @ true_beta)\n\n    # Generate observed counts Y_i based on noise model\n    if params['noise'] == 'poisson':\n        Y = rng.poisson(mu)\n    elif params['noise'] == 'neg_binomial':\n        k = params['k']\n        # The gamma distribution in numpy.random.gamma is specified by a shape\n        # parameter k and a scale parameter theta. scale = mean / shape.\n        # For a Gamma-Poisson mixture, we want a Gamma distribution for the Poisson\n        # rate, such that E[rate]=mu. The specified parameterization gives\n        # E[lambda] = k * (mu/k) = mu, Var[lambda] = k * (mu/k)^2 = mu^2/k.\n        # This leads to E[Y] = E[E[Y|lambda]] = E[lambda] = mu\n        # Var[Y] = E[Var[Y|lambda]] + Var[E[Y|lambda]] = E[lambda] + Var(lambda) = mu + mu^2/k.\n        lambda_i = rng.gamma(shape=k, scale=mu / k)\n        Y = rng.poisson(lambda_i)\n    \n    return X, Y\n\ndef estimate_beta_poisson(X, Y, max_iter=30, tol=1e-8):\n    \"\"\"\n    Estimates parameters for a Poisson GLM with log link using Newton-Raphson.\n    This is equivalent to Iteratively Reweighted Least Squares (IRLS).\n    \"\"\"\n    num_features = X.shape[1]\n    beta = np.zeros(num_features)\n    \n    for _ in range(max_iter):\n        # Linear predictor\n        eta = X @ beta\n        # Mean response\n        mu = np.exp(eta)\n        \n        # To avoid numerical instability (division by zero or overflow if mu is tiny),\n        # we clip mu at a small positive value.\n        mu = np.maximum(mu, 1e-9)\n\n        # Gradient g = X.T @ (Y - mu)\n        grad = X.T @ (Y - mu)\n        \n        # Hessian H = -X.T @ W @ X, where W = diag(mu).\n        # We compute -H = X.T @ W @ X for the update step.\n        neg_hessian = X.T @ (mu[:, np.newaxis] * X)\n\n        # The Newton-Raphson update step for beta is:\n        # beta_new = beta - H_inv @ g = beta + (-H)_inv @ g\n        # We solve the linear system (-H) @ delta = g for delta\n        # where delta = beta_new - beta\n        try:\n            delta_beta = np.linalg.solve(neg_hessian, grad)\n        except np.linalg.LinAlgError:\n            # In case of singularity, we can use a pseudo-inverse for robustness,\n            # though this is unlikely with the given data generation.\n            delta_beta = np.linalg.pinv(neg_hessian) @ grad\n            \n        beta_new = beta + delta_beta\n        \n        # Check for convergence\n        if np.linalg.norm(delta_beta) < tol:\n            beta = beta_new\n            break\n        \n        beta = beta_new\n        \n    return beta\n\ndef run_case(params):\n    \"\"\"Runs a full test case from data generation to validation.\"\"\"\n    rng = np.random.default_rng(params['seed'])\n    \n    # Generate training and test data\n    X_train, Y_train = generate_data(params, params['n_train'], rng)\n    X_test, Y_test = generate_data(params, params['n_test'], rng)\n\n    # Estimate beta using the training set under the Poisson model\n    beta_hat = estimate_beta_poisson(X_train, Y_train)\n\n    # Predict expected counts on the test set\n    mu_pred = np.exp(X_test @ beta_hat)\n\n    # Compute Pearson correlation between predicted means and observed counts\n    corr = np.corrcoef(mu_pred, Y_test)[0, 1]\n    \n    return corr\n\ndef solve():\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # Case A: Poisson noise, all predictors informative\n        {\n            'seed': 123, 'n_train': 5000, 'n_test': 3000,\n            'mu_M': 1.5, 'sigma_M': 1.0, 'M_min': 0.0, 'M_max': 6.0,\n            'alpha_4': 0.5, 'rho_4': 0.7, 'sigma_4': 0.5,\n            'alpha_36': 0.3, 'rho_36': 0.5, 'sigma_36': 0.4,\n            'beta_0': -1.0, 'beta_M': 0.3, 'beta_4': 0.25, 'beta_36': 0.15,\n            'noise': 'poisson'\n        },\n        # Case B: Poisson noise, negligible direct motif effect\n        {\n            'seed': 456, 'n_train': 4000, 'n_test': 2000,\n            'mu_M': 1.0, 'sigma_M': 1.2, 'M_min': 0.0, 'M_max': 6.0,\n            'alpha_4': 0.7, 'rho_4': 0.6, 'sigma_4': 0.6,\n            'alpha_36': 0.2, 'rho_36': 0.3, 'sigma_36': 0.6,\n            'beta_0': -0.8, 'beta_M': 0.0, 'beta_4': 0.3, 'beta_36': 0.2,\n            'noise': 'poisson'\n        },\n        # Case C: Negative Binomial overdispersion (model misspecification)\n        {\n            'seed': 789, 'n_train': 6000, 'n_test': 4000,\n            'mu_M': 1.8, 'sigma_M': 1.1, 'M_min': 0.0, 'M_max': 6.0,\n            'alpha_4': 0.6, 'rho_4': 0.8, 'sigma_4': 0.7,\n            'alpha_36': 0.4, 'rho_36': 0.6, 'sigma_36': 0.6,\n            'beta_0': -1.2, 'beta_M': 0.35, 'beta_4': 0.2, 'beta_36': 0.12,\n            'noise': 'neg_binomial', 'k': 2.0\n        }\n    ]\n\n    results = []\n    for params in test_cases:\n        correlation = run_case(params)\n        results.append(f\"{correlation:.6f}\")\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(results)}]\")\n\nsolve()\n```", "id": "2839842"}]}