{"hands_on_practices": [{"introduction": "A fundamental task in pangenome analysis is to categorize genes based on their frequency across a set of genomes. This exercise [@problem_id:2476544] begins with this descriptive classification, asking you to apply standard frequency thresholds to define a gene as part of the 'core', 'shell', or 'cloud' genome. It then introduces a more sophisticated layer of analysis, employing a Bayesian model to help predict how our observations might generalize, providing a powerful lens through which to understand the relationship between a finite sample and the broader bacterial population.", "problem": "A bacterial species is sampled across $50$ genomes with a binary presence–absence matrix for a single gene of interest. The gene is observed to be present in $44$ of the $50$ genomes. In the study, genes are categorized by their frequency across genomes as follows: strict core if present in $100\\%$ of genomes, soft core if present in at least $95\\%$ of genomes, shell if present in at least $15\\%$ but less than $95\\%$ of genomes, and cloud if present in less than $15\\%$ of genomes. Assume the following modeling framework: gene presence in each genome is a Bernoulli random variable with an unknown population frequency $p$, the genomes are exchangeable and independent given $p$, and the prior on $p$ is $\\operatorname{Beta}(1,1)$.\n\nUsing only the definitions above, determine the category of this gene at sample size $50$. Then suppose the sample size doubles to $100$ genomes while the empirical frequency remains the same as the current sample frequency. Determine the category under this doubled sample using the same thresholds.\n\nFinally, under the Bernoulli–Beta model, compute the posterior predictive expected number of genomes (out of $100$) in which the gene will be present, and report this number as your final answer. Round your answer to four significant figures.", "solution": "The problem will be validated before a solution is attempted.\n\n**Problem Validation**\n\n**Step 1: Extract Givens**\n- Initial sample size: $N_1 = 50$ genomes.\n- Number of genomes with the gene present: $k_1 = 44$.\n- Gene category definitions based on presence frequency $f$:\n    - Strict core: $f = 100\\%$.\n    - Soft core: $f \\ge 95\\%$.\n    - Shell: $15\\% \\le f < 95\\%$.\n    - Cloud: $f < 15\\%$.\n- Modeling framework:\n    - Gene presence in a genome is a Bernoulli random variable with parameter $p$.\n    - Genomes are independent and identically distributed trials given $p$.\n    - Prior distribution on $p$ is $\\operatorname{Beta}(1, 1)$.\n- Scenario 2:\n    - New sample size: $N_2 = 100$ genomes.\n    - Empirical frequency is unchanged from the first sample.\n- Final Task:\n    - Compute the posterior predictive expected number of genomes with the gene present in a new sample of $100$ genomes, based on the initial sample data ($N_1=50$, $k_1=44$).\n    - Round the final answer to four significant figures.\n\n**Step 2: Validate Using Extracted Givens**\nThe problem is scientifically grounded. The pangenome concept, with its categorization of genes into core, shell, and cloud, is a fundamental paradigm in modern microbial genomics. The use of a Bernoulli-Beta conjugate model to represent uncertainty in gene frequency is a standard and appropriate statistical method in bioinformatics. The problem is well-posed, providing all necessary definitions, data, and constraints required for a unique solution. The language is objective and precise. The problem does not violate any fundamental principles, is not based on false premises, and contains no contradictions or ambiguities.\n\n**Step 3: Verdict and Action**\nThe problem is deemed **valid**. A solution will be provided.\n\n**Solution**\n\nThe problem consists of three parts. The first two parts concern the classification of a gene based on its empirical frequency in a sample. The third part requires a Bayesian approach to calculate a posterior predictive expectation.\n\n**Part 1: Gene Category for Sample Size $N_1 = 50$**\n\nGiven a sample of $N_1 = 50$ genomes, the gene is observed in $k_1 = 44$ of them. The empirical frequency of the gene, denoted as $f_1$, is the ratio of the number of genomes carrying the gene to the total number of genomes sampled.\n$$f_1 = \\frac{k_1}{N_1} = \\frac{44}{50} = 0.88$$\nTo compare this with the given thresholds, we express the frequency as a percentage: $0.88 \\times 100\\% = 88\\%$. According to the definitions:\n- Strict core: requires $100\\%$ presence.\n- Soft core: requires presence in at least $95\\%$ of genomes.\n- Shell: requires presence in at least $15\\%$ but less than $95\\%$ of genomes.\n- Cloud: requires presence in less than $15\\%$ of genomes.\n\nThe observed frequency of $88\\%$ satisfies the condition $15\\% \\le 88\\% < 95\\%$. Therefore, based on the sample of $50$ genomes, the gene is classified in the **shell** category.\n\n**Part 2: Gene Category for Sample Size $N_2 = 100$**\n\nThe problem states that for a new sample size of $N_2 = 100$, the empirical frequency remains the same as in the first sample. Thus, $f_2 = f_1 = 0.88$, which corresponds to $88\\%$. The number of genomes with the gene in this hypothetical sample would be $k_2 = f_2 \\times N_2 = 0.88 \\times 100 = 88$. The gene classification is based solely on this frequency. Since the frequency is unchanged, the classification also remains unchanged. The condition $15\\% \\le 88\\% < 95\\%$ is still met. Therefore, for a sample size of $100$ with the same empirical frequency, the gene is still classified in the **shell** category.\n\n**Part 3: Posterior Predictive Expected Number**\n\nThis part of the problem requires the application of a Bayesian model. The unknown population frequency of the gene, $p$, is treated as a random variable.\nThe model is as follows:\n- The prior distribution for $p$ is specified as a Beta distribution with parameters $\\alpha_0 = 1$ and $\\beta_0 = 1$:\n  $$p \\sim \\operatorname{Beta}(\\alpha_0, \\beta_0) = \\operatorname{Beta}(1, 1)$$\n  This is a uniform distribution on the interval $[0, 1]$, representing maximal prior uncertainty about $p$.\n- The observed data consists of $k_1 = 44$ \"successes\" (gene presence) in $N_1 = 50$ independent Bernoulli trials. The likelihood of the data given $p$ is proportional to $p^{k_1}(1-p)^{N_1-k_1}$.\n\nThe Beta distribution is the conjugate prior for the Bernoulli/Binomial likelihood. Therefore, the posterior distribution of $p$ after observing the data is also a Beta distribution. The parameters of the posterior distribution, $\\alpha'$ and $\\beta'$, are updated as follows:\n$$\\alpha' = \\alpha_0 + k_1 = 1 + 44 = 45$$\n$$\\beta' = \\beta_0 + (N_1 - k_1) = 1 + (50 - 44) = 1 + 6 = 7$$\nSo, the posterior distribution for the gene frequency $p$ is:\n$$p | (k_1=44, N_1=50) \\sim \\operatorname{Beta}(45, 7)$$\n\nWe are asked to compute the posterior predictive expected number of genomes in which the gene will be present in a new sample of $M = 100$ genomes. Let $Y$ be the random variable representing this number. The expected value of $Y$, $E[Y]$, is given by the new sample size $M$ multiplied by the posterior expected value of $p$.\n\nThe expected value of a random variable following a Beta distribution $\\operatorname{Beta}(\\alpha, \\beta)$ is $E[p] = \\frac{\\alpha}{\\alpha + \\beta}$.\nFor our posterior distribution $\\operatorname{Beta}(45, 7)$, the posterior mean of $p$ is:\n$$E[p | \\text{data}] = \\frac{\\alpha'}{\\alpha' + \\beta'} = \\frac{45}{45 + 7} = \\frac{45}{52}$$\nThis value, approximately $0.8654$, represents our updated belief about the true frequency of the gene in the population.\n\nNow, we can compute the posterior predictive expected number of genomes with the gene in a new sample of size $M=100$:\n$$E[Y | \\text{data}] = M \\times E[p | \\text{data}] = 100 \\times \\frac{45}{52}$$\n$$E[Y | \\text{data}] = \\frac{4500}{52} = \\frac{1125}{13} \\approx 86.5384615...$$\nThe problem requires the answer to be rounded to four significant figures. The first four significant figures are $8, 6, 5, 3$. The fifth digit is $8$, so we round up the third decimal place.\n$$E[Y | \\text{data}] \\approx 86.54$$\n\nThis is the final answer.", "answer": "$$\n\\boxed{86.54}\n$$", "id": "2476544"}, {"introduction": "The dynamic nature of the accessory genome is governed by fundamental evolutionary processes. This thought experiment [@problem_id:2476507] challenges you to build a model from first principles, quantitatively exploring how a neutral accessory gene can be lost from a population. By combining binomial sampling to model a transmission bottleneck with a simple branching process to represent genetic drift, you will derive the probability of gene loss, gaining a deeper, mechanistic appreciation for the stochastic forces that shape pangenome content.", "problem": "A facultative accessory gene in a bacterial pangenome is neutral with respect to within-host fitness. In a donor host, the within-host allele frequency of this gene (fraction of cells carrying the gene) is $p \\in [0,1]$. Transmission to a new host occurs through a severe bottleneck of size $b \\in \\mathbb{N}$, modeled as sampling $b$ individual bacterial cells independently and without replacement effects (i.e., each draw is from a large donor population, so the number of carriers among the $b$ founders is binomially distributed with parameter $p$). After colonization, within-host ecological control imposes strong neutral drift over $t \\in \\mathbb{N}$ discrete generations. Assume the following within-host neutral drift model:\n- Each founding bacterial lineage evolves independently across generations with no horizontal gene transfer or mutation that would create or delete the accessory gene within a lineage.\n- In each generation, a lineage that is extant at the start of the generation persists to the next generation (i.e., has at least one descendant) with probability $s \\in (0,1)$ and goes extinct with probability $1-s$, independently across lineages and across generations.\n- The gene is present in the host at generation $t$ if and only if at least one of the initially gene-bearing founder lineages has at least one surviving descendant at generation $t$.\n\nUnder these assumptions, derive a closed-form analytic expression for the probability that the accessory gene is absent in the recipient host at generation $t$ as a function of $p$, $b$, $s$, and $t$. Express your final answer as a single simplified expression. No numerical rounding is required.", "solution": "The problem statement will first be subjected to rigorous validation.\n\n**Step 1: Extract Givens**\n- The allele frequency of a neutral accessory gene in a donor host is $p \\in [0,1]$.\n- A transmission bottleneck of size $b \\in \\mathbb{N}$ occurs.\n- The number of founder cells carrying the gene is binomially distributed with parameters $b$ and $p$.\n- Within-host evolution involves neutral drift for $t \\in \\mathbb{N}$ discrete generations.\n- During each generation, an extant lineage persists with probability $s \\in (0,1)$ and goes extinct with probability $1-s$.\n- Lineage persistence is independent across lineages and generations.\n- There is no horizontal gene transfer or de novo gene gain/loss within a lineage.\n- The gene is present at generation $t$ if and only if at least one of the initial gene-bearing founder lineages has a surviving descendant at generation $t$.\n- The objective is to find the probability that the accessory gene is **absent** at generation $t$.\n\n**Step 2: Validate Using Extracted Givens**\nThe problem is assessed against the required criteria.\n- **Scientific Grounding**: The model is a well-established construct in theoretical population genetics and microbial ecology. It combines a binomial sampling process (modeling the transmission bottleneck) with a discrete-time branching process (modeling lineage extinction due to neutral drift). These are standard and scientifically sound tools for modeling such phenomena.\n- **Well-Posedness**: The problem is well-posed. The parameters ($p, b, s, t$) are clearly defined, the stochastic process is fully specified, and the question asks for a single, calculable probability. A unique, stable, and meaningful solution is expected to exist.\n- **Objectivity**: The language is technical, precise, and free of subjective or ambiguous claims.\n- **Completeness and Consistency**: The problem is self-contained. It provides all necessary parameters and model rules. The statement that sampling is \"without replacement effects\" and then modeled as binomial is not a contradiction; it is a standard clarification for sampling a small number, $b$, from a population assumed to be large enough that the probability $p$ does not change between draws.\n\n**Step 3: Verdict and Action**\nThe problem is deemed **valid**. It is a standard, solvable problem in mathematical biology. I will now proceed with the derivation of the solution.\n\nThe derivation proceeds by formalizing the stochastic events described. Let $A$ be the event that the accessory gene is absent in the recipient host at generation $t$. We wish to compute $P(A)$.\n\nThe process can be divided into two main stages: the initial sampling at the bottleneck and the subsequent within-host evolution.\n\n**1. Initial Sampling of Founders**\nLet $K$ be the random variable representing the number of founder cells (out of the total $b$) that carry the accessory gene immediately after transmission. According to the problem statement, $K$ follows a binomial distribution with parameters $b$ (number of trials) and $p$ (probability of success, i.e., a founder carrying the gene).\nThe probability mass function of $K$ is given by:\n$$P(K=k) = \\binom{b}{k} p^k (1-p)^{b-k} \\quad \\text{for } k \\in \\{0, 1, 2, \\dots, b\\}$$\n\n**2. Within-Host Lineage Dynamics**\nConsider a single lineage that initially carried the gene. The probability that this lineage persists for one generation is $s$. Since persistence events are independent across generations, the probability that this single lineage survives for $t$ generations is the product of the probabilities of surviving each generation:\n$$P(\\text{single lineage survives for } t \\text{ generations}) = s \\times s \\times \\cdots \\times s \\text{ (t times)} = s^t$$\nThe complementary event is that this lineage goes extinct at or before generation $t$. The probability of this is:\n$$P(\\text{single lineage is extinct by generation } t) = 1 - s^t$$\n\n**3. Condition for Gene Absence**\nThe gene is absent at generation $t$ if and only if **all** of the lineages that initially carried the gene have gone extinct by generation $t$.\nWe can first find the probability of this event, conditioned on the initial number of gene-bearing founders, $K=k$.\nIf $k=0$, no founders carried the gene, so the gene is certain to be absent. $P(A | K=0) = 1$.\nIf $k > 0$, there are $k$ gene-bearing lineages. Since their survival is independent, the gene is absent at time $t$ if and only if all $k$ of these lineages go extinct. The probability of this is:\n$$P(A | K=k) = [P(\\text{single lineage is extinct by generation } t)]^k = (1 - s^t)^k$$\nNote that for $k=0$, this formula correctly yields $(1 - s^t)^0 = 1$. Thus, the expression $P(A | K=k) = (1 - s^t)^k$ is valid for all $k \\in \\{0, 1, \\dots, b\\}$.\n\n**4. Total Probability Calculation**\nTo find the unconditional probability $P(A)$, we use the law of total probability, summing over all possible values of $k$:\n$$P(A) = \\sum_{k=0}^{b} P(A | K=k) P(K=k)$$\nSubstituting the expressions derived above:\n$$P(A) = \\sum_{k=0}^{b} (1 - s^t)^k \\left[ \\binom{b}{k} p^k (1-p)^{b-k} \\right]$$\nWe can rearrange the terms within the summation to group a common base:\n$$P(A) = \\sum_{k=0}^{b} \\binom{b}{k} [p(1 - s^t)]^k (1-p)^{b-k}$$\nThis sum is of the form of the binomial theorem, which states that $(x+y)^n = \\sum_{k=0}^{n} \\binom{n}{k} x^k y^{n-k}$.\nBy setting $n=b$, $x = p(1 - s^t)$, and $y = 1-p$, we can simplify the entire summation to a closed form:\n$$P(A) = [p(1 - s^t) + (1-p)]^b$$\nSimplifying the expression inside the brackets:\n$$p - ps^t + 1 - p = 1 - ps^t$$\nTherefore, the final expression for the probability that the gene is absent at generation $t$ is:\n$$P(A) = (1 - ps^t)^b$$\nThis is the required closed-form analytic expression as a function of $p$, $b$, $s$, and $t$.", "answer": "$$\n\\boxed{(1 - ps^t)^b}\n$$", "id": "2476507"}, {"introduction": "While neutral processes like drift are critical, natural selection is a primary driver of accessory gene frequency change. This exercise [@problem_id:2476519] provides a practical guide to quantifying this force, demonstrating how to estimate a gene's selection coefficient $s$ from time-series prevalence data. You will apply a standard population genetics model within a Generalized Linear Model (GLM) framework, giving you hands-on experience in fitting a logistic growth model to empirical data and interpreting the results, a core skill in evolutionary data analysis.", "problem": "You are given time-series data describing the prevalence of a single accessory gene across a population of hosts at multiple time points. For each time point, you observe the number of hosts carrying the gene out of a total number of hosts sampled. Assume that the host population is large and well-mixed, and that the net selection on the gene across hosts can be approximated by a constant selection coefficient, denoted by $s$, over the sampling period. Under this assumption and a deterministic selection model, the prevalence $p(t)$ of the gene across hosts satisfies the ordinary differential equation $dp/dt = s\\,p(t)\\,(1 - p(t))$, whose solution implies a linear relationship in the log-odds scale: $\\mathrm{logit}(p(t)) = \\alpha + s\\,t$, where $\\alpha$ is an unknown intercept capturing the initial log-odds. The sampling model at each time $t_i$ is $Y_i \\sim \\mathrm{Binomial}(n_i, p(t_i))$, with independent observations across time points.\n\nYour task is to write a program that, for each provided test case, estimates the selection coefficient $s$ by Maximum Likelihood Estimation (MLE) under the Binomial Generalized Linear Model (GLM) with a logit link, where $\\mathrm{logit}(p(t)) = \\alpha + s\\,t$. Compute a two-sided Wald confidence interval for $s$ based on the observed Fisher information at the MLE. The confidence interval limits must be computed as $s \\pm z \\cdot \\mathrm{SE}(s)$ with $z$ equal to the standard normal $0.975$ quantile and $\\mathrm{SE}(s)$ obtained from the square root of the $(2,2)$ element of the inverse of the observed information matrix evaluated at the MLE. You must implement the estimation numerically using the Iteratively Reweighted Least Squares (IRLS) algorithm for the Binomial GLM. All quantities must be reported per unit time of $t$.\n\nUse the following test suite of three cases. In each case, $t$ is the vector of time points, $n$ is the vector of total hosts sampled at each time, and $y$ is the vector of observed carriers at each time. All integers and time values are exact.\n\n- Case A (growth, moderate prevalence rise):\n  - $t = [0,2,4,6,8]$\n  - $n = [200,200,200,200,200]$\n  - $y = [20,34,54,80,110]$\n\n- Case B (decline from high prevalence):\n  - $t = [0,1,2,3,4,5]$\n  - $n = [150,150,150,150,150,150]$\n  - $y = [120,113,106,98,89,80]$\n\n- Case C (near-neutral change at low prevalence):\n  - $t = [0,5,10,15,20]$\n  - $n = [500,500,500,500,500]$\n  - $y = [25,28,30,33,36]$\n\nScientific and statistical bases you must use:\n- Accessory gene prevalence across hosts changes deterministically under effective selection according to $dp/dt = s\\,p\\,(1-p)$, implying $\\mathrm{logit}(p(t)) = \\alpha + s\\,t$.\n- Sampling at each time follows the Binomial model $Y_i \\sim \\mathrm{Binomial}(n_i, p_i)$ with $p_i = \\mathrm{logit}^{-1}(\\alpha + s\\,t_i)$.\n- The Binomial GLM with logit link is estimated by IRLS, and the observed information matrix at convergence equals $X^\\top W X$, where $X$ is the design matrix with columns $[1, t]$ and $W$ is the diagonal matrix with entries $n_i\\,\\hat{p}_i\\,(1-\\hat{p}_i)$.\n\nAlgorithmic requirements:\n- Implement IRLS to estimate $(\\alpha, s)$ by solving $(X^\\top W X)\\,\\beta = X^\\top W z$ iteratively, with $\\beta = (\\alpha, s)^\\top$ and working response $z = \\eta + (y - n\\,\\hat{p})/(n\\,\\hat{p}(1-\\hat{p}))$, where $\\eta = X\\beta$ and $\\hat{p} = \\mathrm{logit}^{-1}(\\eta)$.\n- At convergence, compute the covariance matrix of $\\hat{\\beta}$ as $(X^\\top W X)^{-1}$ and report $\\hat{s}$ and its Wald interval using $z = 1.959963984540054$.\n- For numerical stability, ensure that each $\\hat{p}_i$ is bounded away from $0$ and $1$ during iterations by clipping to $[\\varepsilon, 1-\\varepsilon]$ with a small $\\varepsilon$, and also avoid division by zero by using the same clipping in the weights.\n\nOutput specification:\n- For each case, output the triple $[\\hat{s}, \\mathrm{lower}, \\mathrm{upper}]$, where $\\mathrm{lower}$ and $\\mathrm{upper}$ are the two-sided Wald $95$ percent confidence bounds for $s$.\n- Round all three numbers to $6$ decimal places in decimal form (not as fractions and not with a percent sign).\n- Your program should produce a single line of output containing the results for all cases as a comma-separated list of lists without spaces, in the form: $[[\\hat{s}_A,\\mathrm{lower}_A,\\mathrm{upper}_A],[\\hat{s}_B,\\mathrm{lower}_B,\\mathrm{upper}_B],[\\hat{s}_C,\\mathrm{lower}_C,\\mathrm{upper}_C]]$.", "solution": "The problem as stated is subjected to validation.\n\n**Step 1: Extract Givens**\n- **Model for gene prevalence dynamics:** The prevalence $p(t)$ follows the ordinary differential equation $dp/dt = s\\,p(t)\\,(1 - p(t))$.\n- **Linearized model:** The solution to the ODE implies a linear relationship on the log-odds scale: $\\mathrm{logit}(p(t)) = \\alpha + s\\,t$, where $\\alpha$ is an intercept and $s$ is the selection coefficient.\n- **Sampling model:** The number of observed gene carriers $Y_i$ at time $t_i$ from a sample of size $n_i$ follows a binomial distribution: $Y_i \\sim \\mathrm{Binomial}(n_i, p(t_i))$, with observations being independent across time points.\n- **Estimation framework:** The parameters $(\\alpha, s)$ are to be estimated via Maximum Likelihood Estimation (MLE) under a Binomial Generalized Linear Model (GLM) with a logit link function.\n- **Numerical algorithm:** The MLE must be found using the Iteratively Reweighted Least Squares (IRLS) algorithm.\n- **IRLS update equations:**\n    - The parameter vector $\\beta = (\\alpha, s)^\\top$ is updated by solving $(X^\\top W X)\\,\\beta = X^\\top W z$.\n    - The design matrix $X$ has columns $[1, t]$.\n    - The working response is $z = \\eta + (y - n\\,\\hat{p})/(n\\,\\hat{p}(1-\\hat{p}))$.\n    - The linear predictor is $\\eta = X\\beta$.\n    - The fitted probabilities are $\\hat{p} = \\mathrm{logit}^{-1}(\\eta)$.\n    - The weight matrix $W$ is a diagonal matrix with entries $n_i\\,\\hat{p}_i\\,(1-\\hat{p}_i)$.\n- **Confidence interval:** A two-sided Wald confidence interval for $s$ is to be computed as $s \\pm z \\cdot \\mathrm{SE}(s)$.\n    - The quantile $z$ is specified as $1.959963984540054$.\n    - The standard error $\\mathrm{SE}(s)$ is derived from the inverse of the observed Fisher information matrix, $I(\\hat{\\beta}) = X^\\top W X$, evaluated at the MLE. Specifically, $\\mathrm{SE}(s)$ is the square root of the $(2,2)$ element of $(I(\\hat{\\beta}))^{-1}$.\n- **Numerical stability:** Fitted probabilities $\\hat{p}_i$ must be clipped to $[\\varepsilon, 1-\\varepsilon]$ to prevent values of $0$ or $1$.\n- **Test Cases:**\n    - Case A: $t = [0,2,4,6,8]$, $n = [200,200,200,200,200]$, $y = [20,34,54,80,110]$.\n    - Case B: $t = [0,1,2,3,4,5]$, $n = [150,150,150,150,150,150]$, $y = [120,113,106,98,89,80]$.\n    - Case C: $t = [0,5,10,15,20]$, $n = [500,500,500,500,500]$, $y = [25,28,30,33,36]$.\n- **Output Specification:** For each case, report a list $[\\hat{s}, \\mathrm{lower}, \\mathrm{upper}]$ rounded to $6$ decimal places. The final output is a single line containing a list of these lists.\n\n**Step 2: Validate Using Extracted Givens**\n- **Scientifically Grounded:** The problem is firmly rooted in population genetics and modern statistical methods. The logistic model for gene frequency change under selection is a cornerstone of the field. The use of a Binomial GLM with a logit link function (logistic regression) is the standard, correct statistical approach for analyzing such binary outcome data (presence/absence of a gene) as a function of a continuous predictor (time).\n- **Well-Posed:** The problem provides a complete specification. It defines the model, the data structure, the estimation algorithm (IRLS), the method for calculating confidence intervals (Wald interval based on observed Fisher information), and all necessary constants and data for the test cases. A unique and stable solution is expected.\n- **Objective:** The problem is stated with mathematical and statistical precision, devoid of any subjective or ambiguous language.\n\nThe problem does not exhibit any of the flaws listed in the validation criteria. It is scientifically sound, well-posed, objective, complete, and non-trivial.\n\n**Step 3: Verdict and Action**\nThe problem is valid. A complete solution will be provided.\n\n**Solution Derivation**\n\nThe objective is to estimate the selection coefficient $s$ from time-series data on gene prevalence. The problem specifies a Binomial Generalized Linear Model (GLM) with a logit link function.\n\nThe model is defined by:\n1.  **Systematic Component:** The linear predictor $\\eta_i$ for the $i$-th observation at time $t_i$ is given by $\\eta_i = \\alpha + s \\cdot t_i$. In matrix notation, for the entire dataset, $\\boldsymbol{\\eta} = X\\beta$, where $\\beta = [\\alpha, s]^\\top$ is the vector of parameters and $X$ is the design matrix. The design matrix has $N$ rows (for $N$ time points) and $2$ columns. The first column is a vector of ones (for the intercept $\\alpha$) and the second column is the vector of time points $\\mathbf{t}$.\n    $$\n    X = \\begin{pmatrix} 1 & t_1 \\\\ 1 & t_2 \\\\ \\vdots & \\vdots \\\\ 1 & t_N \\end{pmatrix}, \\quad \\beta = \\begin{pmatrix} \\alpha \\\\ s \\end{pmatrix}\n    $$\n2.  **Link Function:** The linear predictor $\\eta_i$ is related to the expected prevalence $p_i$ via the logit link function: $\\eta_i = \\mathrm{logit}(p_i) = \\ln\\left(\\frac{p_i}{1-p_i}\\right)$. The inverse link function gives the probability: $p_i = \\mathrm{logit}^{-1}(\\eta_i) = \\frac{e^{\\eta_i}}{1+e^{\\eta_i}} = \\frac{1}{1+e^{-\\eta_i}}$.\n3.  **Random Component:** The observed counts $y_i$ are assumed to follow a Binomial distribution, $y_i \\sim \\mathrm{Binomial}(n_i, p_i)$, where $n_i$ is the sample size at time $t_i$.\n\nThe parameters $\\beta$ are estimated by maximizing the log-likelihood function. For a GLM, this is efficiently done using the Iteratively Reweighted Least Squares (IRLS) algorithm. IRLS is equivalent to the Newton-Raphson method for finding the root of the score function.\n\nThe IRLS algorithm proceeds as follows:\n1.  **Initialization:** Choose an initial estimate for the parameter vector, $\\beta^{(0)}$. A common choice is $\\beta^{(0)} = \\mathbf{0}$.\n2.  **Iteration:** For iteration $k=0, 1, 2, \\dots$ until convergence:\n    a.  Calculate the current linear predictor: $\\boldsymbol{\\eta}^{(k)} = X \\beta^{(k)}$.\n    b.  Calculate the current fitted probabilities (mean values): $\\mathbf{\\hat{p}}^{(k)} = (1 + \\exp(-\\boldsymbol{\\eta}^{(k)}))^{-1}$. For numerical stability, these probabilities are clipped to a small interval $[\\varepsilon, 1-\\varepsilon]$.\n    c.  Calculate the diagonal weight matrix $W^{(k)}$. The diagonal elements are $W_{ii}^{(k)} = n_i \\hat{p}_i^{(k)} (1-\\hat{p}_i^{(k)})$. This is the variance of the binomial response, $n_i p_i (1-p_i)$, evaluated at the current estimate $\\hat{p}_i^{(k)}$.\n    d.  Calculate the working response vector $\\mathbf{z}^{(k)}$. Its elements are $z_i^{(k)} = \\eta_i^{(k)} + \\frac{y_i - n_i \\hat{p}_i^{(k)}}{n_i \\hat{p}_i^{(k)} (1-\\hat{p}_i^{(k)})}$. This can be viewed as a first-order Taylor expansion of the link function around the current mean.\n    e.  Update the parameter estimate by solving the weighted least squares problem:\n        $$\n        \\beta^{(k+1)} = (X^\\top W^{(k)} X)^{-1} X^\\top W^{(k)} \\mathbf{z}^{(k)}\n        $$\n3.  **Convergence:** The iterations stop when the change in the parameter vector, e.g., $||\\beta^{(k+1)} - \\beta^{(k)}||_2$, falls below a predefined tolerance.\n\nUpon convergence, the final estimate is $\\hat{\\beta} = [\\hat{\\alpha}, \\hat{s}]^\\top$. The asymptotic covariance matrix of this estimator is estimated by the inverse of the observed Fisher information matrix, evaluated at the MLE:\n$$\n\\mathrm{Cov}(\\hat{\\beta}) = I(\\hat{\\beta})^{-1} = (X^\\top \\hat{W} X)^{-1}\n$$\nwhere $\\hat{W}$ is the final weight matrix at convergence.\n\nThe standard error of the selection coefficient estimate, $\\mathrm{SE}(\\hat{s})$, is the square root of the second diagonal element (the $(2,2)$ element) of this covariance matrix:\n$$\n\\mathrm{SE}(\\hat{s}) = \\sqrt{[\\mathrm{Cov}(\\hat{\\beta})]_{2,2}}\n$$\nFinally, a $(1-\\gamma) \\times 100\\%$ two-sided Wald confidence interval for $s$ is constructed as:\n$$\n\\hat{s} \\pm z_{1-\\gamma/2} \\cdot \\mathrm{SE}(\\hat{s})\n$$\nFor a $95\\%$ confidence interval, $\\gamma = 0.05$, and $z_{0.975} \\approx 1.96$. The problem provides the precise value $z = 1.959963984540054$.\n\nThe implementation will apply this algorithm to each of the three test cases provided.", "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to solve the problem for the given test cases.\n    It estimates the selection coefficient 's' and its 95% Wald confidence interval\n    for three different scenarios of gene prevalence data.\n    \"\"\"\n\n    test_cases = [\n        # Case A (growth, moderate prevalence rise)\n        {\n            \"t\": np.array([0, 2, 4, 6, 8], dtype=float),\n            \"n\": np.array([200, 200, 200, 200, 200], dtype=float),\n            \"y\": np.array([20, 34, 54, 80, 110], dtype=float),\n        },\n        # Case B (decline from high prevalence)\n        {\n            \"t\": np.array([0, 1, 2, 3, 4, 5], dtype=float),\n            \"n\": np.array([150, 150, 150, 150, 150, 150], dtype=float),\n            \"y\": np.array([120, 113, 106, 98, 89, 80], dtype=float),\n        },\n        # Case C (near-neutral change at low prevalence)\n        {\n            \"t\": np.array([0, 5, 10, 15, 20], dtype=float),\n            \"n\": np.array([500, 500, 500, 500, 500], dtype=float),\n            \"y\": np.array([25, 28, 30, 33, 36], dtype=float),\n        },\n    ]\n\n    results = []\n    for case_data in test_cases:\n        s_hat, lower, upper = estimate_s_with_ci(\n            case_data[\"t\"], case_data[\"n\"], case_data[\"y\"]\n        )\n        results.append([round(val, 6) for val in [s_hat, lower, upper]])\n\n    # Format the final output string as specified\n    output_str = \"[\" + \",\".join([str(res) for res in results]) + \"]\"\n    output_str = output_str.replace(\" \", \"\") # Remove spaces as per format\n    print(output_str)\n\ndef estimate_s_with_ci(t, n, y):\n    \"\"\"\n    Estimates the selection coefficient (s) and its confidence interval using IRLS\n    for a Binomial GLM with a logit link.\n\n    Args:\n        t (np.ndarray): Vector of time points.\n        n (np.ndarray): Vector of total hosts sampled at each time.\n        y (np.ndarray): Vector of observed carriers at each time.\n\n    Returns:\n        tuple: A tuple containing the estimated selection coefficient (s_hat),\n               the lower confidence bound, and the upper confidence bound.\n    \"\"\"\n    # Constants for the algorithm\n    Z_SCORE = 1.959963984540054\n    EPSILON = 1e-8  # For numerical stability\n    TOLERANCE = 1e-9 # Convergence criterion\n    MAX_ITER = 50\n\n    # 1. Construct the design matrix X\n    X = np.stack([np.ones_like(t), t], axis=1)\n\n    # 2. Initialize the parameter vector beta = [alpha, s]\n    # A simple initialization for beta is a zero vector.\n    # An improved start can be from a linear regression on transformed proportions,\n    # but a zero vector is robust enough for this problem.\n    beta = np.zeros(X.shape[1])\n\n    # 3. Implement the Iteratively Reweighted Least Squares (IRLS) algorithm\n    for i in range(MAX_ITER):\n        # Calculate linear predictor eta\n        eta = X @ beta\n\n        # Calculate fitted probabilities p_hat using the inverse logit function\n        p_hat = 1.0 / (1.0 + np.exp(-eta))\n\n        # Clip p_hat to avoid p=0 or p=1 for numerical stability\n        p_hat = np.clip(p_hat, EPSILON, 1.0 - EPSILON)\n\n        # Calculate the diagonal of the weight matrix W\n        # W_ii = n_i * p_hat_i * (1 - p_hat_i)\n        w_diag = n * p_hat * (1.0 - p_hat)\n\n        # Calculate the working response z\n        # z_i = eta_i + (y_i - n_i * p_hat_i) / (n_i * p_hat_i * (1 - p_hat_i))\n        z = eta + (y - n * p_hat) / w_diag\n        \n        # Store old beta for convergence check\n        beta_old = beta\n\n        # Update beta by solving the weighted least squares step\n        # beta_new = inv(X.T W X) * X.T W z\n        # To avoid creating the full diagonal matrix W, we can use broadcasting.\n        X_T_W = X.T * w_diag # Broadcasting w_diag onto rows of X.T\n        X_T_W_X = X_T_W @ X\n        X_T_W_z = X_T_W @ z\n        \n        # Solve the linear system for the new beta\n        beta = np.linalg.solve(X_T_W_X, X_T_W_z)\n\n        # Check for convergence\n        if np.linalg.norm(beta - beta_old)  TOLERANCE:\n            break\n            \n    # 4. Extract the MLE for s\n    s_hat = beta[1]\n\n    # 5. Calculate the Wald confidence interval\n    # Re-calculate final weights and probabilities based on the converged beta\n    eta = X @ beta\n    p_hat = np.clip(1.0 / (1.0 + np.exp(-eta)), EPSILON, 1.0 - EPSILON)\n    w_diag = n * p_hat * (1.0 - p_hat)\n    \n    # Observed Fisher Information Matrix: I = X.T * W * X\n    info_matrix = X.T @ (np.diag(w_diag) @ X)\n\n    # Covariance matrix is the inverse of the information matrix\n    try:\n        cov_matrix = np.linalg.inv(info_matrix)\n    except np.linalg.LinAlgError:\n        # Handle cases where the matrix is singular, returning NaNs\n        return (np.nan, np.nan, np.nan)\n\n    # Standard error of s is the square root of the (2,2) element of the covariance matrix\n    se_s = np.sqrt(cov_matrix[1, 1])\n\n    # Calculate confidence interval limits\n    margin_of_error = Z_SCORE * se_s\n    lower_bound = s_hat - margin_of_error\n    upper_bound = s_hat + margin_of_error\n\n    return s_hat, lower_bound, upper_bound\n\nif __name__ == \"__main__\":\n    solve()\n```", "id": "2476519"}]}