{"hands_on_practices": [{"introduction": "Metagenomics provides a powerful lens into the genetic potential and ecological interactions within microbial communities. A critical application is identifying predator-prey or host-parasite relationships, such as those between bacteria and the viruses (phages) that infect them. This exercise [@problem_id:2507091] guides you through building a computational pipeline to predict these linkages by leveraging the CRISPR-Cas adaptive immune system, where microbial hosts store fragments of viral DNA as 'spacers' to guide future defense. You will implement a biologically-informed scoring model to match spacers to viral protospacers, accounting for sequence features like the Protospacer Adjacent Motif (PAM) and mismatch penalties to quantify the confidence of each predicted interaction.", "problem": "You are given short DNA sequences representing clustered regularly interspaced short palindromic repeats (CRISPR) spacers from microbial hosts and long DNA sequences representing viral contigs. The task is to construct host-virus linkages by matching spacers to protospacer targets on the viral contigs under constraints implied by CRISPR interference and to assess a quantitative confidence for each linkage by penalizing mismatches.\n\nBase your reasoning on the following fundamental definitions and well-tested facts:\n- The Central Dogma of Molecular Biology states that DNA encodes RNA which may encode protein, and CRISPR interference is a DNA-guided process wherein a CRISPR spacer targets a complementary protospacer in foreign DNA, with the requirement of a Protospacer Adjacent Motif (PAM) flanking the protospacer. The presence and correctness of a PAM is essential for recognition and interference.\n- Sequence complementarity can be quantified by counting mismatches, and the physicochemical impact of mismatches is often modeled by additive penalties, with transitions (purine to purine or pyrimidine to pyrimidine) generally being less disruptive than transversions (purine to pyrimidine or vice versa). Let purines be $\\{ \\mathrm{A}, \\mathrm{G} \\}$ and pyrimidines be $\\{ \\mathrm{C}, \\mathrm{T} \\}$.\n- The CRISPR “seed” region proximal to the PAM is more sensitive to mismatches. This is represented by applying a multiplicative factor to mismatch penalties in the seed region.\n- A Boltzmann-type mapping from total penalty to confidence, $C = \\exp(-\\lambda P)$, is a well-tested way to convert an additive penalty $P$ into a value in $[0,1]$ that decays monotonically with increasing penalty.\n\nYour program must implement the following mathematical specification to compute linkages and confidences.\n\n1. Input data and parameters are embedded in the program as constants as follows.\n   - DNA alphabet is $\\{ \\mathrm{A}, \\mathrm{C}, \\mathrm{G}, \\mathrm{T} \\}$.\n   - PAM motif set $\\mathcal{M} = \\{ \\text{\"NGG\"}, \\text{\"CCN\"} \\}$, where the character $\\mathrm{N}$ matches any nucleotide.\n   - Transition penalty $\\alpha = 0.5$, transversion penalty $\\beta = 1.0$.\n   - Seed length $s = 5$. If a downstream PAM is used, the seed is the last $s$ bases of the protospacer; if an upstream PAM is used, the seed is the first $s$ bases of the protospacer.\n   - Seed mismatch multiplier $\\gamma = 2.0$.\n   - Confidence mapping parameter $\\lambda = \\ln 2$.\n   - Confidence categories are defined by thresholds $\\tau_{\\mathrm{high}} = 0.8$ and $\\tau_{\\mathrm{med}} = 0.5$ with the following inclusive-exclusive rules:\n     - High confidence if $C \\ge \\tau_{\\mathrm{high}}$.\n     - Medium confidence if $\\tau_{\\mathrm{med}} \\le C < \\tau_{\\mathrm{high}}$.\n     - Low confidence if $0 < C < \\tau_{\\mathrm{med}}$.\n     - No linkage if $C = 0$.\n   - For each host-virus pair, compute the maximum confidence across all spacers of the host and across all positions and strand orientations on the viral contig.\n\n2. Matching and scoring procedure.\n   - For each spacer string $s$ of length $L$, for each viral contig string $v$:\n     - Consider both the forward strand $v$ and its reverse complement $v^{\\mathrm{rc}}$.\n     - For each position $i$ such that a length-$L$ window fits:\n       - Let $w$ be the substring of length $L$ at position $i$.\n       - Evaluate both PAM orientations:\n         - Downstream PAM: the $3$-mer immediately after $w$, i.e., indices $[i+L, i+L+3)$, must match at least one motif in $\\mathcal{M}$ (with $\\mathrm{N}$ matching any base). If out of bounds, this orientation is invalid.\n         - Upstream PAM: the $3$-mer immediately before $w$, i.e., indices $[i-3, i)$, must match at least one motif in $\\mathcal{M}$. If out of bounds, this orientation is invalid.\n       - If a valid PAM is found for an orientation, compute the total penalty $P$ for $w$ versus $s$ by summing per-position mismatch penalties:\n         - For position $j \\in \\{0,1,\\dots,L-1\\}$, if $w_j = s_j$ the penalty is $0$. If $w_j \\ne s_j$ and $\\{w_j, s_j\\}$ are both purines or both pyrimidines, add $\\alpha$; otherwise add $\\beta$. If $j$ lies within the seed region for the considered PAM orientation, multiply the positional penalty by $\\gamma$.\n       - Among all valid windows and orientations on both strands, take the minimal penalty $P_{\\min}$. If no valid window/orientation exists, define $P_{\\min} = +\\infty$.\n     - Convert $P_{\\min}$ to confidence $C = \\exp(-\\lambda P_{\\min})$ if $P_{\\min} < +\\infty$, and $C=0$ otherwise.\n   - For a given host with spacer set $S$ and a viral contig $v$, define the host-virus confidence as $C_{hv} = \\max_{s \\in S} C(s,v)$.\n\n3. Test suite. Your program must apply the above to the following four cases. Each case contains one host with its spacer set and a list of viral contigs.\n   - Case $1$:\n     - Host spacers: [\"ATGACCTGACCTGACCTGAC\"] (length $20$).\n     - Viral contigs:\n       - \"TTTATGACCTGACCTGACCTGACAGGCCC\".\n     - This case includes an exact protospacer match with a valid downstream PAM \"AGG\".\n   - Case $2$:\n     - Host spacers: [\"GGTACGATGACGTTACGTAC\"] (length $20$).\n     - Viral contigs:\n       - \"AAAGGTGCGATGACGTTACGTACCGGTTT\" (one transition mismatch outside seed, downstream PAM \"CGG\").\n       - \"GGGCCAGTTACGATGACGTTACGTACAAA\" (one transversion mismatch in seed, upstream PAM \"CCA\").\n   - Case $3$:\n     - Host spacers: [\"TACGATCGATCGTTACGAAC\"] (length $20$).\n     - Viral contigs:\n       - \"GGGGTTCGTAACGATCGATCGTATGGAAA\" (contains the reverse complement of the spacer followed by downstream PAM \"TGG\").\n       - \"TTTTACGATCGATCGTTACGAACAAACCC\" (contains the spacer but with an invalid PAM context).\n   - Case $4$:\n     - Host spacers: [\"ACGTACGTACGTACGTACGT\"] (length $20$).\n     - Viral contigs:\n       - \"TTTGCATACGTACGTACGTACGTAGGGGG\" (two transition mismatches outside seed, downstream PAM \"AGG\").\n\n4. Required output. For each case, compute the number of host-virus linkages in each confidence category, counting at most one linkage per host-virus pair using $C_{hv}$. Produce one list per case in the order [high_count, medium_count, low_count]. Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, where each element is itself a bracketed triple. For example: \"[[a,b,c],[d,e,f],...]\".\n\nAll angles are dimensionless; there are no physical units in this problem. All outputs must be integers.", "solution": "The problem requires the development of a computational method to predict and quantify linkages between microbial hosts and viruses. This is achieved by simulating the CRISPR-Cas interference mechanism, where a host's CRISPR spacer sequence targets a complementary protospacer sequence on a viral contig. The validity and strength of this interaction are determined by specific molecular recognition rules, which we will formalize into a quantitative scoring model.\n\nThe algorithmic approach is structured as a systematic search for potential protospacer targets for each given host spacer within each viral contig. The search must account for all possible target sites on both strands of the viral DNA and must respect the critical requirement of a Protospacer Adjacent Motif (PAM) for target recognition.\n\nFirst, we define the fundamental operations. For a given viral contig sequence $v$, we must consider both its forward strand and its reverse complement, $v^{\\mathrm{rc}}$. The reverse complement is obtained by reversing the sequence and replacing each nucleotide with its complementary base ($\\mathrm{A} \\leftrightarrow \\mathrm{T}$, $\\mathrm{C} \\leftrightarrow \\mathrm{G}$).\n\nThe core of the algorithm is a sliding window search. For each spacer $s$ of length $L$ and for each strand of a viral contig, we iterate through all possible substrings (windows) $w$ of length $L$. For each window $w$ at starting position $i$, we check for the presence of a valid PAM. The PAM is a short, specific sequence flanking the protospacer. The problem specifies two orientations:\n1.  **Downstream PAM**: A $3$-base sequence immediately following the window $w$. This sequence must match one of the motifs in the set $\\mathcal{M} = \\{ \\text{\"NGG\"}, \\text{\"CCN\"} \\}$, where $\\mathrm{N}$ can be any of the four DNA bases.\n2.  **Upstream PAM**: A $3$-base sequence immediately preceding the window $w$, which must also match a motif from $\\mathcal{M}$.\n\nIf no valid PAM is found for a given window, that window is not a valid protospacer candidate. If a valid PAM is found, we proceed to calculate a penalty score $P$ that quantifies the dissimilarity between the spacer $s$ and the protospacer candidate $w$. The penalty is calculated as a sum of position-wise mismatch penalties.\nFor each position $j$ from $0$ to $L-1$:\n- If $s_j = w_j$, the penalty is $0$.\n- If $s_j \\neq w_j$, a penalty is incurred based on the type of substitution. A transition (purine-to-purine $\\{\\mathrm{A, G}\\}$ or pyrimidine-to-pyrimidine $\\{\\mathrm{C, T}\\}$) has a penalty of $\\alpha = 0.5$. A transversion (purine-to-pyrimidine or vice versa) has a penalty of $\\beta = 1.0$.\n\nA crucial biological feature is the \"seed\" region, a subsequence of the protospacer where mismatches are more detrimental to binding. The problem defines a seed length of $s=5$. Its location depends on the PAM orientation: for a downstream PAM, the seed is the last $s$ bases of the protospacer; for an upstream PAM, it is the first $s$ bases. Any mismatch penalty occurring within the seed region is amplified by a multiplicative factor $\\gamma = 2.0$.\n\nThe total penalty $P$ for a given spacer-protospacer pair is the sum of all such position-wise, seed-weighted penalties.\n\nFor a single spacer $s$ and a viral contig $v$, we must find the best possible match. This corresponds to the minimum penalty, $P_{\\min}$, found across all windows, on both strands of the contig, and considering both PAM orientations. If no valid protospacer (a window with a valid PAM) is found anywhere on the contig, we define $P_{\\min} = +\\infty$.\n\nThis minimum penalty is then converted into a confidence score $C$ using a Boltzmann-like exponential mapping: $C = \\exp(-\\lambda P_{\\min})$, where $\\lambda = \\ln 2$. This is equivalent to $C = 2^{-P_{\\min}}$. This function ensures that a perfect match ($P_{\\min}=0$) yields maximum confidence ($C=1$), and the confidence decays exponentially as the penalty increases. If no valid match exists ($P_{\\min}=+\\infty$), the confidence is $C=0$.\n\nA host can have multiple spacers. The overall confidence of a host-virus linkage, $C_{hv}$, is defined as the maximum confidence obtained from any of the host's spacers against the given viral contig: $C_{hv} = \\max_{s \\in S} C(s,v)$, where $S$ is the set of the host's spacers.\n\nFinally, for each host-virus pair, the computed confidence $C_{hv}$ is categorized based on predefined thresholds:\n- High confidence: $C_{hv} \\ge \\tau_{\\mathrm{high}} = 0.8$\n- Medium confidence: $\\tau_{\\mathrm{med}} = 0.5 \\le C_{hv} < \\tau_{\\mathrm{high}}$\n- Low confidence: $0 < C_{hv} < \\tau_{\\mathrm{med}}$\n- No linkage: $C_{hv} = 0$\n\nThe program will implement this full procedure for each test case, counting the number of viral contigs that fall into each of the high, medium, and low confidence categories for a given host. The final output for each case is an ordered list containing these three counts.", "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the CRISPR host-virus linkage problem by implementing the specified\n    matching, scoring, and confidence evaluation algorithm.\n    \"\"\"\n\n    # 1. Input data and parameters\n    DNA_ALPHABET = {'A', 'C', 'G', 'T'}\n    PURINES = {'A', 'G'}\n    PYRIMIDINES = {'C', 'T'}\n    PAM_MOTIFS = [\"NGG\", \"CCN\"]\n    ALPHA = 0.5  # Transition penalty\n    BETA = 1.0   # Transversion penalty\n    SEED_LENGTH = 5\n    GAMMA = 2.0  # Seed mismatch multiplier\n    LAMBDA_VAL = np.log(2)\n    TAU_HIGH = 0.8\n    TAU_MED = 0.5\n\n    # Test suite\n    test_cases = [\n        {\n            \"spacers\": [\"ATGACCTGACCTGACCTGAC\"],\n            \"contigs\": [\"TTTATGACCTGACCTGACCTGACAGGCCC\"]\n        },\n        {\n            \"spacers\": [\"GGTACGATGACGTTACGTAC\"],\n            \"contigs\": [\n                \"AAAGGTGCGATGACGTTACGTACCGGTTT\",\n                \"GGGCCAGTTACGATGACGTTACGTACAAA\",\n            ]\n        },\n        {\n            \"spacers\": [\"TACGATCGATCGTTACGAAC\"],\n            \"contigs\": [\n                \"GGGGTTCGTAACGATCGATCGTATGGAAA\",\n                \"TTTTACGATCGATCGTTACGAACAAACCC\",\n            ]\n        },\n        {\n            \"spacers\": [\"ACGTACGTACGTACGTACGT\"],\n            \"contigs\": [\"TTTGCATACGTACGTACGTACGTAGGGGG\"]\n        }\n    ]\n\n    # Helper functions\n    def get_reverse_complement(seq):\n        complement = {'A': 'T', 'T': 'A', 'C': 'G', 'G': 'C'}\n        return \"\".join(complement.get(base, base) for base in reversed(seq))\n\n    def check_pam(subseq, motifs):\n        if len(subseq) != 3:\n            return False\n        for motif in motifs:\n            match = True\n            for i in range(3):\n                if motif[i] != 'N' and motif[i] != subseq[i]:\n                    match = False\n                    break\n            if match:\n                return True\n        return False\n\n    def get_mismatch_penalty(b1, b2, alpha, beta):\n        if (b1 in PURINES and b2 in PURINES) or \\\n           (b1 in PYRIMIDINES and b2 in PYRIMIDINES):\n            return alpha  # Transition\n        else:\n            return beta   # Transversion\n\n    def calculate_penalty(spacer, window, seed_indices):\n        penalty = 0.0\n        for j, (s_base, w_base) in enumerate(zip(spacer, window)):\n            if s_base != w_base:\n                p = get_mismatch_penalty(s_base, w_base, ALPHA, BETA)\n                if j in seed_indices:\n                    p *= GAMMA\n                penalty += p\n        return penalty\n\n    all_results = []\n    \n    # Main logic loop\n    for case in test_cases:\n        host_spacers = case[\"spacers\"]\n        viral_contigs = case[\"contigs\"]\n        \n        counts = {'high': 0, 'medium': 0, 'low': 0}\n        \n        for v_contig in viral_contigs:\n            max_confidence_for_contig = 0.0\n            \n            for spacer in host_spacers:\n                spacer_len = len(spacer)\n                min_penalty_for_spacer = float('inf')\n                \n                contig_strands = [v_contig, get_reverse_complement(v_contig)]\n                \n                for strand in contig_strands:\n                    strand_len = len(strand)\n                    for i in range(strand_len - spacer_len + 1):\n                        window = strand[i : i + spacer_len]\n                        \n                        # Downstream PAM check\n                        if i + spacer_len + 3 <= strand_len:\n                            pam_subseq = strand[i + spacer_len : i + spacer_len + 3]\n                            if check_pam(pam_subseq, PAM_MOTIFS):\n                                seed_indices = set(range(spacer_len - SEED_LENGTH, spacer_len))\n                                p = calculate_penalty(spacer, window, seed_indices)\n                                min_penalty_for_spacer = min(min_penalty_for_spacer, p)\n\n                        # Upstream PAM check\n                        if i - 3 >= 0:\n                            pam_subseq = strand[i - 3 : i]\n                            if check_pam(pam_subseq, PAM_MOTIFS):\n                                seed_indices = set(range(SEED_LENGTH))\n                                p = calculate_penalty(spacer, window, seed_indices)\n                                min_penalty_for_spacer = min(min_penalty_for_spacer, p)\n\n                # Calculate confidence for the spacer\n                if np.isinf(min_penalty_for_spacer):\n                    confidence = 0.0\n                else:\n                    confidence = np.exp(-LAMBDA_VAL * min_penalty_for_spacer)\n                \n                max_confidence_for_contig = max(max_confidence_for_contig, confidence)\n            \n            # Categorize the linkage for the host-virus pair\n            if max_confidence_for_contig >= TAU_HIGH:\n                counts['high'] += 1\n            elif max_confidence_for_contig >= TAU_MED:\n                counts['medium'] += 1\n            elif max_confidence_for_contig > 0:\n                counts['low'] += 1\n                \n        case_result = [counts['high'], counts['medium'], counts['low']]\n        all_results.append(case_result)\n        \n    # Format and print the final output\n    print(f\"[{','.join(map(str, all_results))}]\")\n\nsolve()\n```", "id": "2507091"}, {"introduction": "While metagenomics reveals the 'who' and 'what could be', metatranscriptomics measures gene expression to reveal 'what is happening'. A fundamental goal is to move beyond relative abundances to absolute quantification of transcripts, which is essential for accurate modeling of microbial physiology and function. This practice [@problem_id:2507273] challenges you to use data from external spike-in controls—transcripts added in known amounts—to calibrate sequencing data. You will derive the maximum likelihood estimator for a reads-per-molecule conversion factor and propagate the measurement uncertainty to determine the confidence in your absolute count of a target transcript.", "problem": "A single metatranscriptomic ribonucleic acid sequencing (RNA-seq) library was prepared from a marine biofilm sample with External RNA Controls Consortium (ERCC) spike-in transcripts added at known absolute molecule numbers before library construction. Assume the following foundational model: each transcript class $j$ (including spike-ins and native transcripts) contributes sequencing reads according to independent Poisson counting with mean proportional to its absolute molecules in the input. Formally, for each spike-in $i$, the observed aligned read count $R_{i}$ satisfies $R_{i} \\sim \\mathrm{Poisson}(k\\, m_{i})$, where $m_{i}$ is the known number of input molecules for spike-in $i$, and $k$ is a sample-specific conversion factor (reads per molecule). For a target native transcript $t$, the observed count $R_{t}$ satisfies $R_{t} \\sim \\mathrm{Poisson}(k\\, m_{t})$, where $m_{t}$ is the unknown absolute number of molecules for that transcript in the library input. Assume no intercept (that is, zero molecules yield zero expected reads) and ignore length or guanine-cytosine (GC) biases.\n\nData from this library:\n- Spike-in $S_{1}$: $m_{1} = 2.00 \\times 10^{6}$ molecules, observed $R_{1} = 19{,}820$ reads.\n- Spike-in $S_{2}$: $m_{2} = 5.00 \\times 10^{5}$ molecules, observed $R_{2} = 4{,}930$ reads.\n- Spike-in $S_{3}$: $m_{3} = 1.00 \\times 10^{5}$ molecules, observed $R_{3} = 1{,}010$ reads.\n- Spike-in $S_{4}$: $m_{4} = 2.00 \\times 10^{4}$ molecules, observed $R_{4} = 210$ reads.\n- Target transcript $t$: observed $R_{t} = 2{,}560$ reads.\n\nTasks:\n1. Starting from the Poisson likelihood for independent spike-ins and the model $R_{i} \\sim \\mathrm{Poisson}(k\\, m_{i})$, derive the maximum likelihood estimator $\\hat{k}$ for the conversion factor $k$ and the corresponding large-sample variance $\\mathrm{Var}(\\hat{k})$ under the model assumptions.\n2. Using the delta method with $f(R,k) = R/k$ applied to the estimator $\\hat{m}_{t} = R_{t}/\\hat{k}$, derive an approximate expression for $\\mathrm{Var}(\\hat{m}_{t})$ that accounts for uncertainty from both $R_{t}$ and $\\hat{k}$, assuming $R_{t}$ is independent of the spike-in counts. Where needed, use the Poisson property $\\mathrm{Var}(R) = \\mathbb{E}[R]$ and a plug-in approximation.\n3. Compute the estimated standard uncertainty $\\sqrt{\\widehat{\\mathrm{Var}}(\\hat{m}_{t})}$ in units of copies (molecules), using the data provided. Round your final reported value to three significant figures. Express the final answer in copies.", "solution": "The problem as stated is scientifically grounded, well-posed, and objective. It presents a standard problem in quantitative transcriptomics using external spike-in controls, based on a simplified but valid Poisson model of sequencing counts. All necessary data and assumptions are provided. I will therefore proceed with a solution.\n\nThe problem is solved in three parts as requested: derivation of the maximum likelihood estimator (MLE) for the conversion factor $k$ and its variance, derivation of the variance of the estimated target molecule number $\\hat{m}_t$, and computation of the standard uncertainty of $\\hat{m}_t$.\n\n_Task 1: Derivation of the MLE $\\hat{k}$ and its variance $\\mathrm{Var}(\\hat{k})$_\n\nThe model states that the observed read counts $R_i$ for $N$ independent spike-in standards are drawn from Poisson distributions, $R_i \\sim \\mathrm{Poisson}(\\lambda_i)$, where the mean $\\lambda_i$ is given by $k m_i$. Here, $m_i$ are the known input molecule numbers and $k$ is the unknown conversion factor. The likelihood function $L(k)$ is the product of the probabilities of observing the counts $\\{R_1, \\dots, R_N\\}$:\n$$ L(k) = \\prod_{i=1}^{N} P(R_i | k, m_i) = \\prod_{i=1}^{N} \\frac{\\exp(-k m_i) (k m_i)^{R_i}}{R_i!} $$\nTo find the MLE, we maximize the log-likelihood function, $\\ell(k) = \\ln L(k)$:\n$$ \\ell(k) = \\sum_{i=1}^{N} \\ln\\left( \\frac{\\exp(-k m_i) (k m_i)^{R_i}}{R_i!} \\right) = \\sum_{i=1}^{N} \\left( -k m_i + R_i \\ln(k) + R_i \\ln(m_i) - \\ln(R_i!) \\right) $$\nWe find the MLE, $\\hat{k}$, by differentiating $\\ell(k)$ with respect to $k$ and setting the result to zero:\n$$ \\frac{d\\ell}{dk} = \\sum_{i=1}^{N} \\left( -m_i + \\frac{R_i}{k} \\right) = - \\sum_{i=1}^{N} m_i + \\frac{1}{k} \\sum_{i=1}^{N} R_i $$\nSetting $\\frac{d\\ell}{dk} = 0$ at $k = \\hat{k}$:\n$$ \\frac{1}{\\hat{k}} \\sum_{i=1}^{N} R_i = \\sum_{i=1}^{N} m_i \\implies \\hat{k} = \\frac{\\sum_{i=1}^{N} R_i}{\\sum_{i=1}^{N} m_i} $$\nThis result is intuitive: the best estimate for the average number of reads per molecule is the total number of reads from the standards divided by their total number of molecules.\n\nNext, we find the large-sample variance of $\\hat{k}$. This is given by the inverse of the Fisher information, $I(k)$. The Fisher information is $I(k) = -\\mathbb{E}\\left[\\frac{d^2\\ell}{dk^2}\\right]$. The second derivative of the log-likelihood is:\n$$ \\frac{d^2\\ell}{dk^2} = \\frac{d}{dk} \\left( - \\sum_{i=1}^{N} m_i + \\frac{1}{k} \\sum_{i=1}^{N} R_i \\right) = -\\frac{1}{k^2} \\sum_{i=1}^{N} R_i $$\nTaking the expectation, with $\\mathbb{E}[R_i] = k m_i$:\n$$ \\mathbb{E}\\left[\\frac{d^2\\ell}{dk^2}\\right] = -\\frac{1}{k^2} \\sum_{i=1}^{N} \\mathbb{E}[R_i] = -\\frac{1}{k^2} \\sum_{i=1}^{N} (k m_i) = -\\frac{1}{k} \\sum_{i=1}^{N} m_i $$\nThe Fisher information is therefore:\n$$ I(k) = - \\left( -\\frac{1}{k} \\sum_{i=1}^{N} m_i \\right) = \\frac{1}{k} \\sum_{i=1}^{N} m_i $$\nThe asymptotic variance of the MLE is $\\mathrm{Var}(\\hat{k}) \\approx [I(k)]^{-1}$:\n$$ \\mathrm{Var}(\\hat{k}) = \\frac{k}{\\sum_{i=1}^{N} m_i} $$\n\n_Task 2: Derivation of the approximate variance of $\\hat{m}_t$_\n\nThe estimator for the absolute molecule number of the target transcript, $m_t$, is given by $\\hat{m}_t = R_t / \\hat{k}$. This is a function of two random variables: the read count for the target, $R_t$, and the estimated conversion factor, $\\hat{k}$. The problem states that $R_t$ is independent of the spike-in counts, and therefore $\\hat{k}$ (which is a function of only spike-in counts) is independent of $R_t$.\nWe use the delta method to approximate the variance of the ratio of two independent random variables. For a function $f(X,Y) = X/Y$, the variance is approximated by:\n$$ \\mathrm{Var}(f(X,Y)) \\approx \\left(\\frac{\\partial f}{\\partial X}\\right)^2 \\mathrm{Var}(X) + \\left(\\frac{\\partial f}{\\partial Y}\\right)^2 \\mathrm{Var}(Y) $$\nwhere the partial derivatives are evaluated at the expected values of $X$ and $Y$. Here, $X=R_t$ and $Y=\\hat{k}$. The partial derivatives are:\n$$ \\frac{\\partial f}{\\partial R_t} = \\frac{1}{\\hat{k}} \\quad \\text{and} \\quad \\frac{\\partial f}{\\partial \\hat{k}} = -\\frac{R_t}{\\hat{k}^2} $$\nThe expectations are $\\mathbb{E}[R_t] = k m_t$ and $\\mathbb{E}[\\hat{k}] = k$. Evaluating the derivatives at these expectations gives:\n$$ \\frac{\\partial f}{\\partial R_t} \\bigg|_{\\mathbb{E}} = \\frac{1}{k} \\quad \\text{and} \\quad \\frac{\\partial f}{\\partial \\hat{k}} \\bigg|_{\\mathbb{E}} = -\\frac{k m_t}{k^2} = -\\frac{m_t}{k} $$\nThe variances of the random variables are $\\mathrm{Var}(R_t) = k m_t$ (from the Poisson property) and $\\mathrm{Var}(\\hat{k}) \\approx \\frac{k}{\\sum m_i}$ (from Task 1). Substituting these into the delta method formula:\n$$ \\mathrm{Var}(\\hat{m}_t) \\approx \\left(\\frac{1}{k}\\right)^2 \\mathrm{Var}(R_t) + \\left(-\\frac{m_t}{k}\\right)^2 \\mathrm{Var}(\\hat{k}) $$\n$$ \\mathrm{Var}(\\hat{m}_t) \\approx \\frac{1}{k^2} (k m_t) + \\frac{m_t^2}{k^2} \\left( \\frac{k}{\\sum_{i=1}^{N} m_i} \\right) $$\n$$ \\mathrm{Var}(\\hat{m}_t) \\approx \\frac{m_t}{k} + \\frac{m_t^2}{k \\sum_{i=1}^{N} m_i} $$\nThis expression represents the variance in terms of the true (but unknown) parameters. The first term, $m_t/k$, arises from the Poisson counting noise of the target transcript, while the second term arises from the propagated uncertainty in the estimation of the conversion factor $k$.\n\n_Task 3: Computation of the standard uncertainty_\n\nFor computation, we use a plug-in estimator for the variance, $\\widehat{\\mathrm{Var}}(\\hat{m}_t)$, by replacing the unknown parameters $k$ and $m_t$ with their estimates $\\hat{k}$ and $\\hat{m}_t$. A convenient form for computation is derived by factoring $\\hat{m}_t^2$:\n$$ \\widehat{\\mathrm{Var}}(\\hat{m}_t) \\approx \\frac{\\hat{m}_t}{\\hat{k}} + \\frac{\\hat{m}_t^2}{\\hat{k} \\sum m_i} = \\hat{m}_t^2 \\left( \\frac{1}{\\hat{m}_t \\hat{k}} + \\frac{1}{\\hat{k} \\sum m_i} \\right) $$\nUsing the definitions $\\hat{m}_t \\hat{k} = R_t$ and $\\hat{k} \\sum m_i = \\sum R_i$:\n$$ \\widehat{\\mathrm{Var}}(\\hat{m}_t) \\approx \\hat{m}_t^2 \\left( \\frac{1}{R_t} + \\frac{1}{\\sum_{i=1}^{N} R_i} \\right) $$\nNow, we substitute the provided data:\n$R_1 = 19,820$, $R_2 = 4,930$, $R_3 = 1,010$, $R_4 = 210$.\n$m_1 = 2.00 \\times 10^6$, $m_2 = 5.00 \\times 10^5$, $m_3 = 1.00 \\times 10^5$, $m_4 = 2.00 \\times 10^4$.\n$R_t = 2,560$.\n\nFirst, we calculate the total spike-in reads and molecules:\n$$ \\sum_{i=1}^{4} R_i = 19,820 + 4,930 + 1,010 + 210 = 25,970 $$\n$$ \\sum_{i=1}^{4} m_i = (2.00 \\times 10^6) + (5.00 \\times 10^5) + (1.00 \\times 10^5) + (2.00 \\times 10^4) = 2.62 \\times 10^6 $$\nNext, we compute the estimates for $k$ and $m_t$:\n$$ \\hat{k} = \\frac{\\sum R_i}{\\sum m_i} = \\frac{25,970}{2.62 \\times 10^6} \\approx 0.0099122 \\text{ reads/molecule} $$\n$$ \\hat{m}_t = \\frac{R_t}{\\hat{k}} = \\frac{2,560}{0.0099122} \\approx 258,266 \\text{ molecules} $$\nNow we use the computational formula for the variance:\n$$ \\widehat{\\mathrm{Var}}(\\hat{m}_t) \\approx (\\hat{m}_t)^2 \\left( \\frac{1}{R_t} + \\frac{1}{\\sum R_i} \\right) = (258,266)^2 \\left( \\frac{1}{2,560} + \\frac{1}{25,970} \\right) $$\n$$ \\widehat{\\mathrm{Var}}(\\hat{m}_t) \\approx (6.6701 \\times 10^{10}) \\left( \\frac{1}{2,560} + \\frac{1}{25,970} \\right) $$\n$$ \\widehat{\\mathrm{Var}}(\\hat{m}_t) \\approx (6.6701 \\times 10^{10}) (3.90625 \\times 10^{-4} + 3.8506 \\times 10^{-5}) $$\n$$ \\widehat{\\mathrm{Var}}(\\hat{m}_t) \\approx (6.6701 \\times 10^{10}) (4.29131 \\times 10^{-4}) \\approx 2.8623 \\times 10^7 \\text{ molecules}^2 $$\nThe estimated standard uncertainty is the square root of this variance:\n$$ \\sqrt{\\widehat{\\mathrm{Var}}(\\hat{m}_t)} \\approx \\sqrt{2.8623 \\times 10^7} \\approx 5350.05 \\text{ molecules} $$\nRounding to three significant figures, the standard uncertainty is $5.35 \\times 10^3$ copies.", "answer": "$$\\boxed{5.35 \\times 10^3}$$", "id": "2507273"}, {"introduction": "Metaproteomics directly measures the protein machinery executing cellular functions, but inferring which proteins are present from fragmentary peptide evidence is a significant bioinformatic challenge. This 'protein inference problem' arises because homologous proteins across different species often share identical peptide sequences, creating ambiguity. This hands-on practice [@problem_id:2507167] formalizes this challenge as a classic set cover problem, where the goal is to explain all observed peptides with the most parsimonious set of proteins. By implementing an exact algorithm, you will learn to construct protein groups from peptide-protein mappings and apply principles of parsimony to generate the most plausible and defensible list of proteins present in a complex sample.", "problem": "You are given a set of peptide observations from a community (metaproteome) where peptides arise from proteins across potentially multiple taxa. The Central Dogma of Molecular Biology asserts that proteins are expressed gene products, and in bottom-up mass spectrometry experiments, detected peptides are substrings of proteins. In the presence of homologous proteins from related organisms, a single peptide can map to multiple proteins. To perform parsimony-based protein inference, define protein groups and compute a minimal set of protein groups whose union explains all observed peptides.\n\nFormalization. Let there be a finite set of peptides indexed by $i \\in \\{0,1,\\dots,m-1\\}$ and proteins indexed by $j \\in \\{0,1,\\dots,n-1\\}$. You are given a binary matrix $M \\in \\{0,1\\}^{m \\times n}$, where $M_{i,j} = 1$ if and only if peptide $i$ can be produced by protein $j$. Define for each protein $j$ the peptide incidence set $S_j = \\{ i \\in \\{0,\\dots,m-1\\} \\mid M_{i,j} = 1 \\}$. Define an equivalence relation on proteins $j \\sim j'$ if and only if $S_j = S_{j'}$. Each equivalence class is a protein group. Let the universe of observed peptides be $U = \\bigcup_{j: S_j \\neq \\emptyset} S_j$. For each non-empty equivalence class (protein group) $G$, define its group peptide set $S_G$ to be $S_j$ for any $j \\in G$ (well-defined by equivalence). Assign to each protein group a deterministic identifier equal to the smallest protein index in the group, that is $g = \\min(G)$.\n\nParsimony objective. Find a minimal-cardinality set of protein groups $\\mathcal{C}$ such that $\\bigcup_{g \\in \\mathcal{C}} S_g = U$. If multiple solutions have the same minimal cardinality, break ties by choosing the lexicographically smallest sorted list of group identifiers $[g_1,\\dots,g_k]$.\n\nTask. Write a complete program that, for each provided test case matrix $M$, constructs protein groups, computes the universe $U$, and returns the minimal set cover of $U$ by the protein groups as a sorted list of chosen group identifiers, using the above tie-break rule. For any group with an empty peptide set (i.e., $S_G = \\emptyset$), ignore it. You may assume $U \\neq \\emptyset$ for all test cases below. The algorithm must be exact (not heuristic) for the provided inputs.\n\nTest suite. For each case, rows correspond to peptides indexed from $0$ to $m-1$, columns correspond to proteins indexed from $0$ to $n-1$, and entries are in $\\{0,1\\}$.\n\n- Case A (unique peptides per protein): $m = 3$, $n = 3$, with\n  $$\n  M^{(A)} =\n  \\begin{bmatrix}\n  1 & 0 & 0 \\\\\n  0 & 1 & 0 \\\\\n  0 & 0 & 1\n  \\end{bmatrix}.\n  $$\n- Case B (indistinguishable proteins sharing all peptides): $m = 2$, $n = 3$, with\n  $$\n  M^{(B)} =\n  \\begin{bmatrix}\n  1 & 1 & 0 \\\\\n  1 & 1 & 1\n  \\end{bmatrix}.\n  $$\n- Case C (shared peptides with multiple minimal covers): $m = 3$, $n = 4$, with\n  $$\n  M^{(C)} =\n  \\begin{bmatrix}\n  1 & 0 & 1 & 0 \\\\\n  0 & 1 & 1 & 0 \\\\\n  0 & 1 & 0 & 1\n  \\end{bmatrix}.\n  $$\n- Case D (one protein explains all peptides): $m = 4$, $n = 3$, with\n  $$\n  M^{(D)} =\n  \\begin{bmatrix}\n  1 & 1 & 0 \\\\\n  1 & 1 & 0 \\\\\n  1 & 0 & 1 \\\\\n  1 & 0 & 1\n  \\end{bmatrix}.\n  $$\n\nOutput specification. Your program should produce a single line of output containing the results as a comma-separated list of per-case lists of chosen group identifiers, enclosed in square brackets, with no spaces. For example, the format must be exactly like $[[a_1,\\dots,a_k],[b_1,\\dots,b_\\ell],\\dots]$ where each symbol denotes an integer. The required final output for the test suite is a single line in that format.\n\nNotes and constraints.\n\n- Construct protein groups by exact equivalence of peptide incidence sets $S_j$.\n- Define each group identifier $g$ as the smallest protein index in its group.\n- Solve the set cover problem exactly by finding the smallest cardinality $k$ and then applying the lexicographic tie-break on sorted identifiers.\n- The final answer for each test case is a list of integers (group identifiers).", "solution": "The problem statement has been analyzed and is determined to be valid. It is scientifically grounded in the principles of metaproteomics, mathematically well-posed, and free from any factual errors, contradictions, or ambiguity. The objective is to implement an exact algorithm for a parsimony-based protein inference task, which is a specific a formulation of the classic Set Cover problem.\n\nThe solution is constructed in three main stages:\n1.  Construction of Protein Groups.\n2.  Determination of the peptide universe.\n3.  Solving the exact Set Cover problem with the specified tie-breaking rule.\n\n**1. Protein Group Construction**\n\nGiven the input matrix $M \\in \\{0,1\\}^{m \\times n}$, where $m$ is the number of peptides and $n$ is the number of proteins, we first determine the peptide incidence set for each protein $j \\in \\{0, 1, \\dots, n-1\\}$. This set, $S_j$, contains the indices of all peptides produced by protein $j$:\n$$S_j = \\{ i \\in \\{0, \\dots, m-1\\} \\mid M_{i,j} = 1 \\}$$\nProteins are partitioned into equivalence classes, called protein groups, based on an equivalence relation $\\sim$. Two proteins $j$ and $j'$ are equivalent, $j \\sim j'$, if and only if they have identical peptide incidence sets, i.e., $S_j = S_{j'}$.\n\nAlgorithmically, this is achieved by creating a map where keys are an immutable representation of the peptide incidence sets (e.g., a `frozenset` or `tuple` of sorted peptide indices) and values are lists of protein indices that share this set.\n\nFor each resulting protein group $G$, which is a set of protein indices, its identifier $g$ is defined as the smallest protein index in the group:\n$$g = \\min(G)$$\nThe peptide set for the group, $S_g$, is the common peptide incidence set shared by all proteins in $G$. Any group $G$ for which $S_g = \\emptyset$ is disregarded, as specified. This process yields a set of candidate groups, each represented by its identifier $g$ and its peptide set $S_g$.\n\n**2. Determination of the Peptide Universe**\n\nThe universe of observed peptides, denoted by $U$, comprises all peptides that are explained by at least one protein. This is the union of all non-empty peptide incidence sets:\n$$U = \\bigcup_{j: S_j \\neq \\emptyset} S_j$$\nIn practice, $U$ is computed as the union of all peptide sets $S_g$ from the valid protein groups identified in the previous step. The problem assumes $U \\neq \\emptyset$.\n\n**3. Minimal Set Cover with Lexicographical Tie-Breaking**\n\nThe core of the problem is to find a minimal-cardinality set of protein groups $\\mathcal{C}$ whose peptide sets collectively cover the entire universe $U$. That is, we seek $\\mathcal{C}$ such that:\n$$ \\bigcup_{g \\in \\mathcal{C}} S_g = U \\quad \\text{and} \\quad |\\mathcal{C}| \\text{ is minimized.} $$\nThis is a formulation of the exact Set Cover problem, which is NP-hard. However, given the small dimensions of the input matrices in the test suite, an exact solution can be found by systematically searching through combinations of the candidate groups.\n\nThe search proceeds by checking for a valid cover with increasing cardinality $k$. We start with $k=1$, then $k=2$, and so on, up to the total number of candidate groups.\nFor each cardinality $k$, we generate all combinations of $k$ groups from the set of candidate groups. For each combination, we test if the union of their corresponding peptide sets $S_g$ is equal to the universe $U$.\n\nThe first value of $k$ for which at least one such covering combination exists is the minimal cardinality.\n\nOnce the minimal cardinality $k_{min}$ is determined, the tie-breaking rule must be applied. If multiple sets of groups of size $k_{min}$ cover $U$, we must select the one that is lexicographically smallest. The procedure is as follows:\n1.  Identify all covering sets of groups $\\mathcal{C}_1, \\mathcal{C}_2, \\dots, \\mathcal{C}_p$ where $|\\mathcal{C}_i| = k_{min}$.\n2.  For each cover $\\mathcal{C}_i$, create a sorted list of its group identifiers, $[g_1, g_2, \\dots, g_{k_{min}}]$.\n3.  Compare these sorted lists lexicographically. The final answer is the list that is determined to be the smallest.\n\nThis systematic, exhaustive search guarantees finding the unique, correct solution according to the problem's parsimony objective and tie-breaking rule.", "answer": "```python\nimport numpy as np\nfrom itertools import combinations\n\ndef solve_case(M: np.ndarray):\n    \"\"\"\n    Solves the protein inference problem for a single test case matrix M.\n    \"\"\"\n    m, n = M.shape\n\n    # Step 1: Form Protein Groups\n    # First, determine the peptide incidence set for each protein.\n    # We map a frozenset of peptide indices to a list of protein indices.\n    groups_by_peptides = {}\n    for j in range(n):\n        # A protein's peptide set is the set of peptide indices (rows) where M[i, j] is 1.\n        peptide_indices = frozenset(np.where(M[:, j] == 1)[0])\n        if peptide_indices not in groups_by_peptides:\n            groups_by_peptides[peptide_indices] = []\n        groups_by_peptides[peptide_indices].append(j)\n\n    # Step 2: Define Group Representatives, Sets, and the Universe\n    # candidate_groups stores tuples of (group_id, peptide_set).\n    candidate_groups = []\n    universe = set()\n    for peptide_set, protein_indices in groups_by_peptides.items():\n        # Ignore groups with an empty peptide set, as per the problem statement.\n        if not peptide_set:\n            continue\n        \n        # The group identifier is the smallest protein index in the group.\n        group_id = min(protein_indices)\n        candidate_groups.append((group_id, peptide_set))\n        \n        # Accumulate peptides into the universe.\n        universe.update(peptide_set)\n\n    # Sort candidate groups by their identifier. This ensures that the combinations\n    # are generated in a deterministic order, though it is not strictly necessary\n    # for correctness as the final solution sorting handles the tie-break.\n    candidate_groups.sort(key=lambda x: x[0])\n    \n    # Per the problem, we can assume U is not empty.\n    if not universe:\n        return []\n\n    # Step 3: Solve the Exact Set Cover Problem\n    num_groups = len(candidate_groups)\n    for k in range(1, num_groups + 1):\n        # Check all combinations of size k.\n        potential_solutions = []\n        for combo in combinations(candidate_groups, k):\n            # Check if this combination covers the universe.\n            union_of_peptides = set()\n            for _, peptide_set in combo:\n                union_of_peptides.update(peptide_set)\n            \n            if union_of_peptides == universe:\n                # This is a valid cover. Extract and sort the group identifiers.\n                group_ids = sorted([group_id for group_id, _ in combo])\n                potential_solutions.append(group_ids)\n        \n        if potential_solutions:\n            # We have found the minimal cardinality k.\n            # Apply the lexicographical tie-breaking rule.\n            potential_solutions.sort()\n            return potential_solutions[0]\n            \n    # This part should not be reached if U is non-empty and can be covered.\n    return []\n\ndef solve():\n    \"\"\"\n    Main function to run all test cases and print the final result.\n    \"\"\"\n    test_cases = [\n        # Case A: m=3, n=3\n        np.array([\n            [1, 0, 0],\n            [0, 1, 0],\n            [0, 0, 1]\n        ]),\n        # Case B: m=2, n=3\n        np.array([\n            [1, 1, 0],\n            [1, 1, 1]\n        ]),\n        # Case C: m=3, n=4\n        np.array([\n            [1, 0, 1, 0],\n            [0, 1, 1, 0],\n            [0, 1, 0, 1]\n        ]),\n        # Case D: m=4, n=3\n        np.array([\n            [1, 1, 0],\n            [1, 1, 0],\n            [1, 0, 1],\n            [1, 0, 1]\n        ]),\n    ]\n\n    all_results = []\n    for M in test_cases:\n        result = solve_case(M)\n        all_results.append(result)\n\n    # Format the final output string as specified: [[a,b,...],[c,d,...],...]\n    string_parts = []\n    for res_list in all_results:\n        part = f\"[{','.join(map(str, res_list))}]\"\n        string_parts.append(part)\n    \n    final_output = f\"[{','.join(string_parts)}]\"\n    print(final_output)\n\nsolve()\n```", "id": "2507167"}]}