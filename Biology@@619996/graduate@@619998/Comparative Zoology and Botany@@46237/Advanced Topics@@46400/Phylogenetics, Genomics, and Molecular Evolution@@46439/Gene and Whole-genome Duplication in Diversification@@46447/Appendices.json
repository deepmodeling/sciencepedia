{"hands_on_practices": [{"introduction": "A fundamental task in evolutionary genomics is placing major events like whole-genome duplications (WGDs) onto a geological timeline. This practice will guide you through the cornerstone method for dating a WGD using molecular data. By applying the principles of the molecular clock to synonymous substitution divergence ($K_s$), you will translate a measure of genetic difference into an estimate of absolute time, a critical skill for correlating genomic events with macroevolutionary patterns [@problem_id:2577160].", "problem": "In comparative zoology and botany, whole-genome duplication (WGD) leaves a characteristic signal of duplicate genes retained in conserved syntenic blocks. Consider a plant lineage in which a WGD is inferred from a cohort of anchor gene pairs (syntenic paralogs). The median synonymous divergence across these pairs is reported as $K_s = 1.2$. Assume that this reported $K_s$ is the Jukes–Cantor (JC) corrected synonymous distance between paralogous sequences. Let the synonymous substitution rate be $r = 6 \\times 10^{-9}$ substitutions per site per year per lineage, and assume a strict molecular clock operating at the synonymous sites. Under the Jukes–Cantor model of nucleotide substitution, and assuming that the duplication event instantaneously produced two daughter copies that have since accumulated substitutions independently and at the same rate, derive from first principles an expression for the time since duplication $t$ in terms of the JC-corrected synonymous distance and the per-lineage rate. Then evaluate this expression using the values above. Express your final answer in million years (Ma) and round your answer to four significant figures.", "solution": "The problem statement must first be validated for scientific soundness, consistency, and completeness.\n\n**Step 1: Extract Givens**\n-   Topic: Whole-genome duplication (WGD) in a plant lineage.\n-   Data: Median synonymous divergence across anchor gene pairs, $K_s = 1.2$.\n-   Model: The divergence $K_s$ is the Jukes–Cantor (JC) corrected synonymous distance.\n-   Constant: Synonymous substitution rate, $r = 6 \\times 10^{-9}$ substitutions per site per year per lineage.\n-   Assumption 1: A strict molecular clock operates at synonymous sites.\n-   Assumption 2: The duplication event was instantaneous.\n-   Assumption 3: Daughter copies have accumulated substitutions independently and at the same rate $r$.\n-   Task 1: Derive from first principles an expression for the time since duplication, $t$.\n-   Task 2: Evaluate this expression using the given values.\n-   Output Format: The final answer for time $t$ must be in million years (Ma) and rounded to four significant figures.\n\n**Step 2: Validate Using Extracted Givens**\nThe problem is assessed against the required criteria.\n-   **Scientifically Grounded:** The problem uses standard concepts from molecular evolution and computational biology: whole-genome duplication (WGD), synonymous substitution rate ($r$), synonymous divergence ($K_s$), the Jukes-Cantor (JC) model, and the molecular clock hypothesis. These are foundational principles in the field. The provided values for $K_s$ and $r$ are realistic for plant evolution. The problem is scientifically sound.\n-   **Well-Posed:** The problem is well-defined. It asks for the derivation of a standard formula and its application to a concrete case. The givens and assumptions are sufficient to determine a unique solution.\n-   **Objective:** The language is technical and precise. There are no subjective or ambiguous statements.\n-   **Completeness and Consistency:** The problem is self-contained. The provided information is sufficient and there are no internal contradictions. The distinction between a per-lineage rate and the total divergence rate is a critical element, which is correctly specified.\n\n**Step 3: Verdict and Action**\nThe problem is deemed **valid**. It is a standard, well-posed problem in molecular phylogenetics. I will proceed with a full derivation and solution.\n\nThe problem requires the derivation of the time ($t$) since a duplication event based on the synonymous divergence ($K_s$) between the resulting paralogous genes.\n\nLet us begin from first principles. The duplication event creates two identical gene copies from a single ancestral gene. Let this event occur at time $t=0$. We are interested in the time $t$ that has passed since this event. After duplication, the two copies evolve independently along two separate lineages.\n\nThe substitution rate is given as $r$, in units of substitutions per site per year per lineage. This is the rate at which substitutions accumulate in a single evolutionary line.\n\nThe divergence between the two paralogous sequences is the result of substitutions accumulating in *both* lineages. The total evolutionary time separating the two contemporary sequences is the sum of the lengths of the two branches back to their common ancestor, the duplication node. Each branch has a length of $t$ years. Thus, the total evolutionary path length between the two sequences is $t + t = 2t$.\n\nAccording to the strict molecular clock hypothesis, the number of substitutions is proportional to time. The rate of divergence between the two sequences, let us call it $k_{div}$, is the rate at which differences accumulate between them. Since the two lineages are evolving independently, this rate is the sum of their individual substitution rates.\n$$k_{div} = r_{lineage\\,1} + r_{lineage\\,2}$$\nGiven that both lineages evolve at the same rate $r$, we have:\n$$k_{div} = r + r = 2r$$\n\nThe total synonymous divergence, $K_s$, represents the expected number of synonymous substitutions per synonymous site that have occurred between the two sequences since they diverged. It is the product of the rate of divergence and the time elapsed.\n$$K_s = k_{div} \\times t$$\nSubstituting the expression for $k_{div}$, we obtain the fundamental relationship:\n$$K_s = (2r)t$$\n\nIt is important to note that the problem specifies $K_s$ as the Jukes-Cantor corrected distance. This means the provided value of $K_s=1.2$ already accounts for multiple substitutions occurring at the same site over time and directly represents the expected number of substitutions per site. Therefore, the linear relationship derived above is appropriate. If we were given the raw proportion of different sites, $p$, we would first need to compute $K_s$ using the Jukes-Cantor formula, $K = -\\frac{3}{4}\\ln(1-\\frac{4}{3}p)$, but this is not necessary here.\n\nFrom the derived equation, we can now solve for the time since duplication, $t$:\n$$t = \\frac{K_s}{2r}$$\nThis is the required expression for $t$ derived from first principles.\n\nNow, we evaluate this expression using the provided values:\n-   $K_s = 1.2$ (dimensionless, substitutions per site)\n-   $r = 6 \\times 10^{-9}$ (substitutions per site per year)\n\nSubstituting these values into the expression for $t$:\n$$t = \\frac{1.2}{2 \\times (6 \\times 10^{-9} \\text{ year}^{-1})}$$\n$$t = \\frac{1.2}{12 \\times 10^{-9}} \\text{ years}$$\n$$t = \\frac{1.2}{1.2 \\times 10^{-8}} \\text{ years}$$\n$$t = 1 \\times 10^8 \\text{ years}$$\n\nThe problem requires the answer to be expressed in million years (Ma), where $1 \\text{ Ma} = 10^6$ years.\n$$t = (1 \\times 10^8) \\text{ years} \\times \\frac{1 \\text{ Ma}}{10^6 \\text{ years}} = 100 \\text{ Ma}$$\n\nFinally, the answer must be rounded to four significant figures. The calculated value is exactly $100$. To express this with four significant figures, we write it as $100.0$.", "answer": "$$\n\\boxed{100.0}\n$$", "id": "2577160"}, {"introduction": "Following a WGD, not all duplicated genes are preserved; there is a biased retention process that offers clues about functional constraints. This exercise explores the influential dosage-balance hypothesis, which predicts that genes sensitive to stoichiometric changes are preferentially retained after WGD compared to small-scale duplications. You will use the Pearson chi-square test, a workhorse of statistical analysis, to determine if hypothetical gene retention data supports this foundational theory in molecular evolution [@problem_id:2577002].", "problem": "A long-standing prediction of the dosage-balance hypothesis is that dosage-sensitive gene classes, such as transcription factors and protein kinases, are preferentially retained after Whole-Genome Duplication (WGD) relative to Small-Scale Duplication (SSD), because WGD preserves stoichiometric balance among interacting partners, whereas SSD does not. Consider a comparative dataset pooled across representative vertebrate and angiosperm clades, in which retained duplicate genes have been classified by duplication mechanism (WGD versus SSD) and by gene class (transcription factor, kinase, metabolic enzyme). You are to test whether the distribution of retained duplicates across gene classes differs between WGD and SSD, consistent with dosage-balance-mediated enrichment.\n\nThe observed retained-duplicate counts are:\n- WGD-retained: transcription factors $=$ $240$, kinases $=$ $200$, metabolic enzymes $=$ $160$.\n- SSD-retained: transcription factors $=$ $30$, kinases $=$ $40$, metabolic enzymes $=$ $230$.\n\nUsing the Pearson chi-square test of independence on the resulting $2 \\times 3$ contingency structure, compute the chi-square test statistic under the null hypothesis that duplication mechanism and gene class are independent among retained duplicates. Assume all cell counts are sufficiently large for the asymptotic approximation to hold, and do not apply continuity corrections.\n\nReport only the chi-square test statistic, rounded to four significant figures. No units are required.", "solution": "The problem statement is scientifically grounded, well-posed, and contains all necessary information to conduct the specified statistical test. The premise is based on the valid dosage-balance hypothesis in evolutionary genomics, and the data provided form a complete contingency table suitable for a chi-square analysis. The problem is therefore deemed valid and a solution will be provided.\n\nThe primary task is to compute the Pearson chi-square test statistic, denoted $\\chi^2$, for a test of independence on the given contingency table. The null hypothesis, $H_0$, states that the gene class of a retained duplicate is independent of the duplication mechanism (Whole-Genome Duplication, WGD, versus Small-Scale Duplication, SSD). The alternative hypothesis, $H_A$, is that these two classifications are not independent.\n\nFirst, we organize the observed frequencies, $O_{ij}$, into a $2 \\times 3$ contingency table, where $i$ indexes the rows (duplication mechanism) and $j$ indexes the columns (gene class).\n\nThe table of observed counts is:\n$$\n\\begin{array}{c|ccc|c}\n & \\text{Transcription Factors} & \\text{Kinases} & \\text{Metabolic Enzymes} & \\text{Row Total} \\\\\n\\hline\n\\text{WGD} & O_{11} = 240 & O_{12} = 200 & O_{13} = 160 & R_1 \\\\\n\\text{SSD} & O_{21} = 30  & O_{22} = 40  & O_{23} = 230 & R_2 \\\\\n\\hline\n\\text{Column Total} & C_1 & C_2 & C_3 & N\n\\end{array}\n$$\n\nNext, we calculate the row totals ($R_i$), column totals ($C_j$), and the grand total ($N$).\nThe row totals are:\n$$R_1 = 240 + 200 + 160 = 600$$\n$$R_2 = 30 + 40 + 230 = 300$$\n\nThe column totals are:\n$$C_1 = 240 + 30 = 270$$\n$$C_2 = 200 + 40 = 240$$\n$$C_3 = 160 + 230 = 390$$\n\nThe grand total, $N$, is the sum of all observations:\n$$N = R_1 + R_2 = 600 + 300 = 900$$\nAs a check, $N = C_1 + C_2 + C_3 = 270 + 240 + 390 = 900$. The totals are consistent.\n\nUnder the null hypothesis of independence, the expected frequency, $E_{ij}$, for each cell is calculated using the formula:\n$$E_{ij} = \\frac{R_i \\times C_j}{N}$$\n\nWe compute the expected frequencies for each of the six cells:\n$$E_{11} = \\frac{R_1 \\times C_1}{N} = \\frac{600 \\times 270}{900} = 180$$\n$$E_{12} = \\frac{R_1 \\times C_2}{N} = \\frac{600 \\times 240}{900} = 160$$\n$$E_{13} = \\frac{R_1 \\times C_3}{N} = \\frac{600 \\times 390}{900} = 260$$\n$$E_{21} = \\frac{R_2 \\times C_1}{N} = \\frac{300 \\times 270}{900} = 90$$\n$$E_{22} = \\frac{R_2 \\times C_2}{N} = \\frac{300 \\times 240}{900} = 80$$\n$$E_{23} = \\frac{R_2 \\times C_3}{N} = \\frac{300 \\times 390}{900} = 130$$\n\nThe Pearson chi-square test statistic is defined as the sum of the squared differences between observed and expected frequencies, divided by the expected frequencies, over all cells:\n$$\\chi^2 = \\sum_{i=1}^{2} \\sum_{j=1}^{3} \\frac{(O_{ij} - E_{ij})^2}{E_{ij}}$$\n\nWe now calculate the contribution of each cell to the $\\chi^2$ value:\n$$\\frac{(O_{11} - E_{11})^2}{E_{11}} = \\frac{(240 - 180)^2}{180} = \\frac{60^2}{180} = \\frac{3600}{180} = 20$$\n$$\\frac{(O_{12} - E_{12})^2}{E_{12}} = \\frac{(200 - 160)^2}{160} = \\frac{40^2}{160} = \\frac{1600}{160} = 10$$\n$$\\frac{(O_{13} - E_{13})^2}{E_{13}} = \\frac{(160 - 260)^2}{260} = \\frac{(-100)^2}{260} = \\frac{10000}{260} = \\frac{1000}{26} = \\frac{500}{13}$$\n$$\\frac{(O_{21} - E_{21})^2}{E_{21}} = \\frac{(30 - 90)^2}{90} = \\frac{(-60)^2}{90} = \\frac{3600}{90} = 40$$\n$$\\frac{(O_{22} - E_{22})^2}{E_{22}} = \\frac{(40 - 80)^2}{80} = \\frac{(-40)^2}{80} = \\frac{1600}{80} = 20$$\n$$\\frac{(O_{23} - E_{23})^2}{E_{23}} = \\frac{(230 - 130)^2}{130} = \\frac{100^2}{130} = \\frac{10000}{130} = \\frac{1000}{13}$$\n\nFinally, we sum these contributions to obtain the total $\\chi^2$ statistic:\n$$\\chi^2 = 20 + 10 + \\frac{500}{13} + 40 + 20 + \\frac{1000}{13}$$\n$$\\chi^2 = 90 + \\frac{1500}{13}$$\nTo combine these terms, we find a common denominator:\n$$\\chi^2 = \\frac{90 \\times 13}{13} + \\frac{1500}{13} = \\frac{1170 + 1500}{13} = \\frac{2670}{13}$$\nConverting the exact fraction to a decimal value gives:\n$$\\chi^2 \\approx 205.384615...$$\nThe problem requires the result to be rounded to four significant figures.\n$$\\chi^2 \\approx 205.4$$\nThis large value of the $\\chi^2$ statistic suggests a significant deviation from the expected frequencies under the null hypothesis, indicating that duplication mechanism and gene class are not independent.", "answer": "$$\n\\boxed{205.4}\n$$", "id": "2577002"}, {"introduction": "A central, debated question in evolutionary biology is whether WGDs act as engines of diversification by increasing speciation rates. This advanced practice dives into the modern phylogenetic methods used to test this hypothesis, framing it as a model selection problem [@problem_id:2577034]. You will implement and compare two competing macroevolutionary models—one where diversification rates change with time, and another where they depend on a lineage's post-WGD 'state'—using the Akaike Information Criterion (AIC) to determine which provides a better explanation for the observed patterns of diversity.", "problem": "You are given a time-calibrated ultrametric phylogeny with annotated Whole-Genome Duplication (WGD) events. You will compare two macroevolutionary models that explain lineage diversification and compute the Akaike Information Criterion (AIC) difference for model selection. The two models are:\n- A time-varying birth process with a single rate shift at time $\\tau$, where the per-lineage speciation rate is $\\lambda(t) = \\lambda_{1}$ for $t \\in [0,\\tau)$ and $\\lambda_{2}$ for $t \\in [\\tau, T]$.\n- A state-dependent speciation model with two heritable states $s \\in \\{0,1\\}$, where the per-lineage speciation rate is $\\lambda_{0}$ for state $0$ and $\\lambda_{1}$ for state $1$. State $1$ arises only at the annotated WGD times and is otherwise inherited by descent without reversal.\n\nAssumptions and foundations:\n- Begin at the crown age with $2$ lineages at time $t=0$ (root), both in state $0$. The present is at time $t=T$.\n- The tree is fully sampled and extinction is negligible over the study interval, such that the reconstructed process is a pure-birth (Yule) process approximation.\n- For a counting process with instantaneous intensity $\\Lambda(t)$, the likelihood of an observed event sequence at times $\\{t_i\\}$ is the product of the intensities at the event times times the exponential of the negative integral of the intensity: $\\prod_i \\Lambda(t_i) \\exp\\left(-\\int_0^T \\Lambda(t)\\,dt\\right)$. In the time-varying model $\\Lambda(t) = \\lambda(t) \\, n(t)$, where $n(t)$ is the number of extant lineages at time $t$. In the state-dependent model with known states, $\\Lambda(t) = \\lambda_0 \\, n_0(t) + \\lambda_1 \\, n_1(t)$, where $n_0(t)$ and $n_1(t)$ are the numbers of lineages in states $0$ and $1$ at time $t$.\n- At each speciation event, exactly one existing lineage splits, increasing the count of its state by $1$ and the total number of lineages by $1$. At each WGD event time, exactly one state-$0$ lineage switches to state $1$, decreasing $n_0(t)$ by $1$ and increasing $n_1(t)$ by $1$ instantaneously. No WGD occurs when $n_0(t)=0$.\n- The log-likelihoods of both models must be computed from first principles via the event contributions and the integrated intensity over time, using the event-parent states (state-dependent model) and the epoch placement of each event (time-varying model). Parameters are estimated by maximum likelihood.\n- Use the Akaike Information Criterion (AIC), defined as $\\mathrm{AIC} = 2k - 2\\hat{\\ell}$ where $k$ is the number of free parameters and $\\hat{\\ell}$ is the maximized log-likelihood. Treat $k=2$ for both models. Report $\\Delta \\mathrm{AIC} = \\mathrm{AIC}_{\\text{time-varying}} - \\mathrm{AIC}_{\\text{state-dependent}}$ as a float for each test case. Do not report percentages.\n\nInput specification for each test case:\n- Total duration $T$ (with $t=0$ at the root and $t=T$ at the present).\n- Rate-shift time $\\tau$ with $0 \\le \\tau \\le T$.\n- A list of speciation events given as ordered pairs $(t_i, s_i)$ for $i=1,\\dots,m$, where $t_i \\in (0,T]$ is the speciation time and $s_i \\in \\{0,1\\}$ is the state of the parent lineage that split at $t_i$. No two events share the same time.\n- A list of WGD times $\\{w_j\\}$ with $w_j \\in (0,T]$, strictly increasing, and no WGD time coincides with a speciation event time.\n\nComputation requirements:\n- For the time-varying model, the instantaneous intensity is $\\Lambda(t) = \\lambda(t)\\, n(t)$ with $n(t)$ the total number of lineages. The log-likelihood equals\n$$\n\\ell_{\\text{tv}}(\\lambda_{1},\\lambda_{2})\n= \\sum_{i=1}^{m} \\left[\\log \\lambda(t_i) + \\log n(t_i^-)\\right] \n- \\int_0^T \\lambda(t)\\, n(t)\\, dt,\n$$\nwhere $n(t_i^-)$ is the number of lineages immediately before time $t_i$ and $\\lambda(t)$ is piecewise constant on $[0,\\tau)$ and $[\\tau,T]$.\n- For the state-dependent model, the instantaneous intensity is $\\Lambda(t) = \\lambda_{0} \\, n_0(t) + \\lambda_{1} \\, n_1(t)$, and the log-likelihood equals\n$$\n\\ell_{\\text{sd}}(\\lambda_{0},\\lambda_{1})\n= \\sum_{i=1}^{m} \\left[\\log \\lambda_{s_i} + \\log n_{s_i}(t_i^-)\\right]\n- \\int_0^T \\left(\\lambda_0 \\, n_0(t) + \\lambda_1 \\, n_1(t)\\right) dt.\n$$\n- Estimate parameters by maximizing the respective log-likelihoods. Handle boundary cases where an exposure integral equals $0$ by setting the corresponding maximum likelihood estimate to $0$ and treating any $0 \\cdot \\log 0$ term as $0$.\n\nTest suite:\nProvide $\\;3\\;$ independent test cases. For each case, list $T$, $\\tau$, the ordered speciation events $(t_i,s_i)$, and the WGD times $\\{w_j\\}$. All times are in the same arbitrary unit and must be interpreted on the interval $[0,T]$.\n\n- Case A:\n  - $T = 10$, $\\tau = 5$,\n  - Speciation events: $(2,0)$, $(6,1)$, $(8,0)$,\n  - WGD times: $4$.\n- Case B:\n  - $T = 6$, $\\tau = 3$,\n  - Speciation events: $(1,0)$, $(2.5,0)$, $(5.5,0)$,\n  - WGD times: $5.8$.\n- Case C:\n  - $T = 9$, $\\tau = 7$,\n  - Speciation events: $(1,0)$, $(2,0)$, $(3,0)$,\n  - WGD times: $4$.\n\nFinal output format:\n- Your program should produce a single line of output containing the $\\Delta \\mathrm{AIC}$ values for the three cases, as a comma-separated list enclosed in square brackets, with each value rounded to six decimal places (for example, $\\;[0.123456,-0.500000,2.718282]\\;$). No additional text should be printed.", "solution": "The problem requires the computation of the Akaike Information Criterion (AIC) difference, $\\Delta \\mathrm{AIC} = \\mathrm{AIC}_{\\text{time-varying}} - \\mathrm{AIC}_{\\text{state-dependent}}$, between two macroevolutionary models of lineage diversification on a given phylogeny. The number of free parameters for both models is given as $k=2$. The AIC is defined as $\\mathrm{AIC} = 2k - 2\\hat{\\ell}$, where $\\hat{\\ell}$ is the maximized log-likelihood. Consequently, the required quantity simplifies to $\\Delta \\mathrm{AIC} = (4 - 2\\hat{\\ell}_{\\text{tv}}) - (4 - 2\\hat{\\ell}_{\\text{sd}}) = 2(\\hat{\\ell}_{\\text{sd}} - \\hat{\\ell}_{\\text{tv}})$. The core of the task is thus to compute the maximized log-likelihood for each model.\n\nThe log-likelihood for a model component (e.g., a specific epoch or a specific state) driven by a constant rate $\\lambda$, with $N$ observed events and a total lineage-time exposure of $I = \\int n(t) dt$, is given by the general form $\\ell(\\lambda) = N \\log\\lambda + S_n - \\lambda I$. Here, $S_n$ represents the sum of the logarithms of the number of lineages available to speciate at each event time, $\\sum_{i=1}^N \\log n(t_i^-)$. To find the maximum likelihood estimate (MLE) of the rate, $\\hat{\\lambda}$, we differentiate with respect to $\\lambda$ and set the result to zero:\n$$\n\\frac{\\partial \\ell}{\\partial \\lambda} = \\frac{N}{\\lambda} - I = 0 \\implies \\hat{\\lambda} = \\frac{N}{I}\n$$\nThis result is valid for $N > 0$ and $I > 0$. If $N=0$, the likelihood $\\ell(\\lambda) = S_n - \\lambda I$ is maximized at $\\hat{\\lambda}=0$ (since $I \\ge 0$ and $S_n=0$ for an empty set of events), yielding a log-likelihood contribution of $\\hat{\\ell}=0$. Per the problem statement, if an exposure integral $I$ is zero, the rate is set to zero, which also implies no events occurred ($N=0$), and the log-likelihood contribution is again zero.\n\nSubstituting the MLE $\\hat{\\lambda}=N/I$ back into the log-likelihood function for the case $N > 0$ yields the maximized value for that component:\n$$\n\\hat{\\ell} = N \\log\\left(\\frac{N}{I}\\right) + S_n - \\frac{N}{I}I = N \\log N - N \\log I + S_n - N\n$$\nThe total maximized log-likelihood for each model is the sum of these values over its components.\nFor the time-varying (TV) model, the components are the two time epochs: $[0, \\tau)$ and $[\\tau, T]$. We denote their respective event counts, exposures, and sums of log-lineages as $(N_{\\text{tv},1}, I_{\\text{tv},1}, S_{n,\\text{tv},1})$ and $(N_{\\text{tv},2}, I_{\\text{tv},2}, S_{n,\\text{tv},2})$.\nFor the state-dependent (SD) model, the components correspond to the two states, $0$ and $1$. We denote their quantities as $(N_{\\text{sd},0}, I_{\\text{sd},0}, S_{n,\\text{sd},0})$ and $(N_{\\text{sd},1}, I_{\\text{sd},1}, S_{n,\\text{sd},1})$.\n\nTo compute these quantities ($N, I, S_n$ for each component), we must reconstruct the history of lineage diversification. The number of lineages in total, $n(t)$, and in each state, $n_0(t)$ and $n_1(t)$, are piecewise-constant functions that change only at event times (speciation or WGD). The algorithm proceeds as follows:\n1.  All speciation and WGD events are collected and sorted chronologically.\n2.  Starting at time $t=0$ with initial conditions $n(0)=2$, $n_0(0)=2$, and $n_1(0)=0$, we traverse time from one event to the next.\n3.  For each interval between consecutive events, from $t_{prev}$ to $t_{curr}$, the constant lineage counts ($n, n_0, n_1$) are used to update the exposure integrals, $I$. For an interval of duration $\\Delta t = t_{curr} - t_{prev}$, the contribution to an integral is $n \\cdot \\Delta t$ or $n_s \\cdot \\Delta t$. For the TV model, care is taken if the interval crosses the rate-shift time $\\tau$.\n4.  At each event time, the state of the system is updated.\n    -   A speciation event increments the relevant event count $N$ and the sum of log-lineages $S_n$ for the corresponding model component. It then increments the lineage counts: $n$ increases by $1$, and either $n_0$ or $n_1$ increases by $1$ depending on the parent lineage's state.\n    -   A WGD event does not contribute to $N$ or $S_n$ but changes the state counts: $n_0$ decreases by $1$, and $n_1$ increases by $1$. The total lineage count $n$ remains unchanged.\n5.  After the last event, the final interval to time $T$ is processed to complete the integrals.\n6.  With all $N, I, S_n$ components calculated for both models, their respective maximized log-likelihoods, $\\hat{\\ell}_{\\text{tv}}$ and $\\hat{\\ell}_{\\text{sd}}$, are computed by summing the contributions from their components.\n7.  Finally, the AIC difference is calculated as $\\Delta \\mathrm{AIC} = 2(\\hat{\\ell}_{\\text{sd}} - \\hat{\\ell}_{\\text{tv}})$.\n\nThis structured, event-based approach ensures that all contributions to the log-likelihood are accounted for precisely according to the specified models and underlying principles of stochastic processes.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to solve the problem for the given test cases.\n    It orchestrates the calculation of delta AIC for each case and prints the results.\n    \"\"\"\n    test_cases = [\n        {\n            \"T\": 10, \"tau\": 5,\n            \"speciation_events\": [(2, 0), (6, 1), (8, 0)],\n            \"wgd_times\": [4]\n        },\n        {\n            \"T\": 6, \"tau\": 3,\n            \"speciation_events\": [(1, 0), (2.5, 0), (5.5, 0)],\n            \"wgd_times\": [5.8]\n        },\n        {\n            \"T\": 9, \"tau\": 7,\n            \"speciation_events\": [(1, 0), (2, 0), (3, 0)],\n            \"wgd_times\": [4]\n        }\n    ]\n\n    results = []\n    for case in test_cases:\n        result = calculate_delta_aic(\n            case[\"T\"],\n            case[\"tau\"],\n            case[\"speciation_events\"],\n            case[\"wgd_times\"]\n        )\n        results.append(result)\n        \n    # Final print statement in the exact required format.\n    print(f\"[{','.join(f'{x:.6f}' for x in results)}]\")\n\ndef calculate_log_likelihood_component(N, I, S_n):\n    \"\"\"\n    Calculates a component of the maximized log-likelihood.\n    The formula is derived from substituting the MLE rate back into the log-likelihood function.\n    Handles the case where N=0, for which the log-likelihood contribution is 0.\n    \"\"\"\n    if N == 0:\n        # If no events occurred, the MLE rate is 0, and log-likelihood is 0.\n        return 0.0\n    \n    # Formula for maximized log-likelihood component: N*log(N) - N*log(I) + S_n - N\n    # This must be handled carefully. If N > 0 and I = 0, this is an impossible scenario\n    # as exposure is required for an event. Here we assume I > 0 if N > 0.\n    return N * np.log(N) - N * np.log(I) + S_n - N\n\ndef calculate_delta_aic(T, tau, speciation_events, wgd_times):\n    \"\"\"\n    Calculates the delta AIC between the time-varying and state-dependent models for a single test case.\n    \"\"\"\n    # Combine and sort all events by time\n    events = []\n    for t, s in speciation_events:\n        events.append({'time': t, 'type': 'spec', 'state': s})\n    for t in wgd_times:\n        events.append({'time': t, 'type': 'wgd', 'state': None})\n    \n    events.sort(key=lambda e: e['time'])\n\n    # Initialize state variables at t=0\n    current_time = 0.0\n    n = 2   # Total number of lineages\n    n0 = 2  # Number of lineages in state 0\n    n1 = 0  # Number of lineages in state 1\n\n    # Initialize accumulators for the time-varying model (TVM)\n    # Index 0: epoch [0, tau), Index 1: epoch [tau, T]\n    N_tv = np.array([0, 0])\n    I_tv = np.array([0.0, 0.0])\n    S_n_tv = np.array([0.0, 0.0])\n\n    # Initialize accumulators for the state-dependent model (SDM)\n    # Index 0: state 0, Index 1: state 1\n    N_sd = np.array([0, 0])\n    I_sd = np.array([0.0, 0.0])\n    S_n_sd = np.array([0.0, 0.0])\n\n    # Iterate through time intervals defined by events\n    for event in events:\n        event_time = event['time']\n        delta_t = event_time - current_time\n\n        if delta_t > 0:\n            # Update exposure integrals over the interval [current_time, event_time)\n            # SDM integrals\n            I_sd[0] += n0 * delta_t\n            I_sd[1] += n1 * delta_t\n            \n            # TVM integrals (handle case where interval crosses tau)\n            if current_time  tau and event_time = tau:\n                I_tv[0] += n * delta_t\n            elif current_time >= tau:\n                I_tv[1] += n * delta_t\n            elif current_time  tau and event_time > tau:\n                I_tv[0] += n * (tau - current_time)\n                I_tv[1] += n * (event_time - tau)\n        \n        # Process the event at event_time\n        if event['type'] == 'spec':\n            parent_state = event['state']\n            \n            # Record log lineage counts just before the event\n            # TVM stats\n            if event_time  tau:\n                N_tv[0] += 1\n                S_n_tv[0] += np.log(n)\n            else:\n                N_tv[1] += 1\n                S_n_tv[1] += np.log(n)\n            \n            # SDM stats\n            if parent_state == 0:\n                N_sd[0] += 1\n                S_n_sd[0] += np.log(n0) if n0 > 0 else -np.inf \n            else: # parent_state == 1\n                N_sd[1] += 1\n                S_n_sd[1] += np.log(n1) if n1 > 0 else -np.inf \n\n            # Update lineage counts after speciation\n            n += 1\n            if parent_state == 0:\n                n0 += 1\n            else:\n                n1 += 1\n        \n        elif event['type'] == 'wgd':\n            # Update lineage counts after WGD\n            if n0 > 0:\n                n0 -= 1\n                n1 += 1\n        \n        current_time = event_time\n\n    # Process the final interval from the last event to T\n    delta_t = T - current_time\n    if delta_t > 0:\n        I_sd[0] += n0 * delta_t\n        I_sd[1] += n1 * delta_t\n        \n        if current_time  tau and T = tau:\n            I_tv[0] += n * delta_t\n        elif current_time >= tau:\n            I_tv[1] += n * delta_t\n        elif current_time  tau and T > tau:\n            I_tv[0] += n * (tau - current_time)\n            I_tv[1] += n * (T - tau)\n\n    # Calculate total maximized log-likelihoods for each model\n    log_likelihood_tv = calculate_log_likelihood_component(N_tv[0], I_tv[0], S_n_tv[0]) + \\\n                        calculate_log_likelihood_component(N_tv[1], I_tv[1], S_n_tv[1])\n\n    log_likelihood_sd = calculate_log_likelihood_component(N_sd[0], I_sd[0], S_n_sd[0]) + \\\n                        calculate_log_likelihood_component(N_sd[1], I_sd[1], S_n_sd[1])\n\n    # Calculate delta AIC = AIC_tv - AIC_sd = 2 * (ll_sd - ll_tv)\n    delta_aic = 2 * (log_likelihood_sd - log_likelihood_tv)\n\n    return delta_aic\n\nif __name__ == '__main__':\n    solve()\n\n```", "id": "2577034"}]}