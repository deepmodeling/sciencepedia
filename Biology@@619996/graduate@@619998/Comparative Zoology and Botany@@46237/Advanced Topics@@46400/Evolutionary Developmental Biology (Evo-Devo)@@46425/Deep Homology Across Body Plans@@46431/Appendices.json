{"hands_on_practices": [{"introduction": "Research in comparative biology often begins with identifying a compelling pattern across disparate taxa. A classic example is the hypothesized inversion of the dorsoventral (DV) axis between protostomes and deuterostomes, where a conserved patterning gradient appears to be flipped. This practice challenges you to formalize this observation by selecting a statistical test that can rigorously evaluate the hypothesis of mirror-image correspondence from spatial expression data. You will need to account for real-world data complexities, such as spatial autocorrelation and unknown non-linear relationships in signal amplitude, moving beyond simplistic correlations to a robust, non-parametric approach. [@problem_id:2564809]", "problem": "In comparative zoology and botany, deep homology predicts that conserved gene regulatory networks can underlie divergent body plans. For dorsoventral patterning, Bone Morphogenetic Protein (BMP) signaling often forms a graded profile along the dorsoventral axis. Consider $2$ taxa, $\\mathcal{T}_1$ and $\\mathcal{T}_2$, for which spatial BMP concentration profiles have been measured along a normalized dorsoventral coordinate $x \\in [0,1]$ at a comparable developmental stage, yielding discrete samples $\\{(x_i, g_1(x_i))\\}_{i=1}^n$ and $\\{(x_i, g_2(x_i))\\}_{i=1}^n$ with $x_{i+1}-x_i=\\Delta x$ for all $i$ and $n \\ge 20$. Assume both profiles are smooth and spatially autocorrelated along $x$. A canonical inversion hypothesis predicts mirror-image correspondence, i.e., after reflecting one axis, there exists an unknown monotone increasing transformation $h$ and constants $\\alpha \\in \\mathbb{R}$ and $\\beta > 0$ such that\n$$\ng_2(x) \\approx \\alpha + \\beta \\, h\\!\\big(g_1(1-x)\\big) + \\varepsilon(x),\n$$\nwhere $\\varepsilon(x)$ is zero-mean noise with spatial autocorrelation along $x$.\n\nYour goal is to select a statistical test that, starting from first principles of hypothesis testing and accounting for spatial autocorrelation and unknown monotone transformations of signal amplitude, evaluates whether the profiles exhibit significant mirror-image correspondence consistent with inversion. The test should control the type I error at level $\\alpha = 0.05$ without assuming independent samples across $x$.\n\nWhich option most appropriately specifies such a test?\n\nA. Reflect $\\mathcal{T}_1$ by $R(x)=1-x$, rank-transform both reflected $g_1$ and $g_2$ across the shared grid to obtain ranks $\\tilde{g}_1(1-x_i)$ and $\\tilde{g}_2(x_i)$, compute the Spearman rank correlation $T_{\\mathrm{obs}}=\\rho_s\\big(\\tilde{g}_1(1-x_i),\\tilde{g}_2(x_i)\\big)$, estimate an autocorrelation length $b$ from the first zero crossing of the empirical autocorrelation function, generate a null distribution by block-permuting $\\tilde{g}_2(x_i)$ in contiguous blocks of length $b$ for $B \\ge 1000$ replicates, compute the permutation $p$-value $p=\\frac{1+\\#\\{T_b \\ge T_{\\mathrm{obs}}\\}}{1+B}$, and reject for $p<0.05$.\n\nB. Apply the two-sample Kolmogorovâ€“Smirnov test at level $\\alpha=0.05$ to compare the empirical distributions of $g_1$ and $g_2$ (without reflection). If the null of identical distributions is not rejected, conclude mirror-image correspondence consistent with inversion.\n\nC. Compute the Pearson correlation $r$ between $g_1(x_i)$ and $g_2(x_i)$ (without reflection). If $r< -0.8$ and significant at $\\alpha=0.05$ under the usual $t$-test for correlation with $n-2$ degrees of freedom, conclude inversion.\n\nD. Fit the linear model $g_2(x_i)=\\alpha+\\beta g_1(x_i)+\\epsilon_i$ (without reflection) by ordinary least squares, then test $H_0\\!:\\beta=0$ against $H_1\\!:\\beta<0$ at $\\alpha=0.05$. If $H_0$ is rejected, conclude mirror-image correspondence indicative of inversion.\n\nAssume no robust cross-taxon anatomical landmarks are available for registration beyond the shared normalized coordinate grid, and that any valid test must explicitly accommodate unknown monotone rescaling of signal amplitude and spatial autocorrelation along the dorsoventral axis. Choose the single best option.", "solution": "The problem asks for an appropriate statistical test to evaluate the canonical inversion hypothesis in developmental biology. This hypothesis posits a mirror-image correspondence between the dorsoventral patterning signal profiles of two taxa, $\\mathcal{T}_1$ and $\\mathcal{T}_2$.\n\nFirst, we must validate the problem statement.\n\n**Step 1: Extract Givens**\n- Data consist of two spatial profiles, $g_1(x)$ and $g_2(x)$, sampled on a shared, normalized grid $x \\in [0,1]$ with $n \\ge 20$ points. Sample locations are $\\{x_i\\}_{i=1}^n$.\n- The profiles are signals representing BMP concentration: $\\{(x_i, g_1(x_i))\\}$ and $\\{(x_i, g_2(x_i))\\}$.\n- The profiles are stated to be smooth and spatially autocorrelated along the coordinate $x$.\n- The inversion hypothesis is mathematically formulated as $g_2(x) \\approx \\alpha + \\beta \\, h\\!\\big(g_1(1-x)\\big) + \\varepsilon(x)$.\n- In this model:\n    - $1-x$ represents the reflection of the spatial axis.\n    - $h$ is an unknown, monotone increasing function.\n    - $\\alpha \\in \\mathbb{R}$ and $\\beta > 0$ are unknown constants for offset and scaling.\n    - $\\varepsilon(x)$ is a zero-mean noise term that is spatially autocorrelated.\n- The goal is to find a statistical test that:\n    1.  Evaluates the mirror-image correspondence.\n    2.  Accounts for the unknown monotone transformation $h$.\n    3.  Accounts for spatial autocorrelation.\n    4.  Controls the Type I error at $\\alpha = 0.05$.\n    5.  Does not assume independent samples.\n\n**Step 2: Validate Using Extracted Givens**\n- **Scientific Grounding:** The problem is based on the well-established dorsoventral axis inversion hypothesis in evolutionary developmental biology, a central concept in the field. The use of BMP signaling as the specific example is canonical. The problem is scientifically sound.\n- **Well-Posedness:** The problem is well-posed. It defines a specific hypothesis and describes the properties of the data, asking for a suitable statistical procedure that respects these properties. The constraints (autocorrelation, unknown monotone function) are clear and point toward a specific class of statistical methods.\n- **Objectivity:** The problem statement is objective and uses precise mathematical and biological terminology.\n- **Conclusion:** The problem statement is valid. It contains no scientific or logical flaws, is well-defined, and presents a non-trivial challenge in applied statistics.\n\n**Step 3: Verdict and Action**\n- **Verdict:** The problem is valid.\n- **Action:** Proceed to derive the solution and evaluate the options.\n\n**Derivation of the Appropriate Test**\n\nThe hypothesis is $g_2(x) \\approx \\alpha + \\beta \\, h\\!\\big(g_1(1-x)\\big)$. We must construct a test that addresses each component of this model.\n\n1.  **The Mirror-Image Component ($g_1(1-x)$):** The hypothesis is not about the direct relationship between $g_1(x)$ and $g_2(x)$, but about the relationship between $g_2(x)$ and a spatially reflected version of $g_1(x)$. Therefore, the first step must be to compute the reflected profile, let us call it $g_{1,R}(x) = g_1(1-x)$. The hypothesis then becomes a positive association between $g_2(x)$ and $g_{1,R}(x)$.\n\n2.  **The Unknown Monotone Transformation ($h$):** The relationship between the signal amplitudes is not necessarily linear. The function $h$ is only specified as being monotone increasing. This means that if $u > v$, then $h(u) \\ge h(v)$. The linear scaling by $\\beta>0$ and offset by $\\alpha$ preserve this monotonicity. Therefore, the hypothesis is one of a *monotonic association* between $g_2(x)$ and $g_{1,R}(x) = g_1(1-x)$. A test for linear association, such as Pearson correlation, would be incorrect because it is not invariant under general monotonic transformations. The correct approach is to use a rank-based method. Spearman's rank correlation coefficient, $\\rho_s$, is specifically designed to measure the strength of a monotonic relationship. It is calculated as the Pearson correlation of the rank-transformed data. By converting the values of $g_2(x_i)$ and $g_{1,R}(x_i)$ to their respective ranks, we effectively linearize the relationship, making it amenable to correlation analysis. The resulting test statistic would be $T = \\rho_s(\\text{rank}(g_2), \\text{rank}(g_{1,R}))$. A large positive value of $T$ would support the hypothesis.\n\n3.  **The Spatial Autocorrelation ($\\varepsilon(x)$):** The problem states that the data are spatially autocorrelated. This means the samples $(x_i, g(x_i))$ are not independent and identically distributed ($i.i.d.$). Standard statistical tests for the significance of a correlation coefficient (e.g., a $t$-test using a transformation of $r$ or $\\rho_s$) rely critically on the assumption of independence. When this assumption is violated by positive autocorrelation, the effective number of degrees of freedom is much smaller than the number of samples minus $2$, and naive application of the standard test leads to a severely inflated Type I error rate (i.e., we would find significant correlations far too often by chance).\n    To correctly assess significance, we must generate a null distribution for the test statistic ($T = \\rho_s$) that preserves the autocorrelation structure of the original time series. This is achieved using a **block permutation test**. Under the null hypothesis of no association between the two profiles, we can shuffle one profile relative to the other. To preserve the autocorrelation, we do not shuffle individual data points. Instead, we divide the series to be shuffled (e.g., the ranked $g_2$ profile) into contiguous blocks of length $b$ and then shuffle these blocks. The block length $b$ should be chosen to approximate the autocorrelation length of the data. This procedure creates a set of surrogate datasets that are consistent with the null hypothesis but have the same short-range temporal structure as the original data.\n\n**Summary of the Correct Procedure:**\n1.  Create the reflected profile from $\\mathcal{T}_1$: $\\{g_1(1-x_i)\\}_{i=1}^n$.\n2.  Compute the ranks of the data in the reflected profile of $\\mathcal{T}_1$ and the profile of $\\mathcal{T}_2$. Let these be $\\{\\tilde{g}_1(1-x_i)\\}$ and $\\{\\tilde{g}_2(x_i)\\}$.\n3.  Calculate the observed Spearman's rank correlation: $T_{\\mathrm{obs}} = \\rho_s\\big(\\{\\tilde{g}_1(1-x_i)\\}, \\{\\tilde{g}_2(x_i)\\}\\big)$.\n4.  Estimate an appropriate block length $b$ from the data, for example, from the autocorrelation function of one of the series.\n5.  Generate a null distribution by repeatedly ($B$ times, e.g., $B \\ge 1000$):\n    a. Creating a permuted rank series $\\{\\tilde{g}_2^*(x_i)\\}$ by shuffling blocks of length $b$ of the original rank series $\\{\\tilde{g}_2(x_i)\\}$.\n    b. Calculating the correlation for this replicate: $T_j = \\rho_s\\big(\\{\\tilde{g}_1(1-x_i)\\}, \\{\\tilde{g}_2^*(x_i)\\}\\big)$.\n6.  Calculate the one-tailed $p$-value as the proportion of simulated statistics that are at least as extreme as the observed one: $p = (1 + \\#\\{T_j \\ge T_{\\mathrm{obs}}\\}) / (1 + B)$.\n7.  Compare the $p$-value to the significance level $\\alpha=0.05$. If $p < 0.05$, reject the null hypothesis.\n\nNow, we evaluate the given options against this derived procedure.\n\n**Option-by-Option Analysis**\n\n**A. Reflect $\\mathcal{T}_1$ by $R(x)=1-x$, rank-transform both reflected $g_1$ and $g_2$ across the shared grid to obtain ranks $\\tilde{g}_1(1-x_i)$ and $\\tilde{g}_2(x_i)$, compute the Spearman rank correlation $T_{\\mathrm{obs}}=\\rho_s\\big(\\tilde{g}_1(1-x_i),\\tilde{g}_2(x_i)\\big)$, estimate an autocorrelation length $b$ from the first zero crossing of the empirical autocorrelation function, generate a null distribution by block-permuting $\\tilde{g}_2(x_i)$ in contiguous blocks of length $b$ for $B \\ge 1000$ replicates, compute the permutation $p$-value $p=\\frac{1+\\#\\{T_b \\ge T_{\\mathrm{obs}}\\}}{1+B}$, and reject for $p<0.05$.**\n\nThis option precisely matches the procedure derived from first principles. It correctly identifies the need to (1) reflect the axis, (2) use rank correlation (Spearman's $\\rho_s$) to handle the unknown monotone function $h$, and (3) use block permutation to generate a null distribution that correctly accounts for spatial autocorrelation. The method for estimating block length and calculating the $p$-value are standard and appropriate.\n**Verdict: Correct.**\n\n**B. Apply the two-sample Kolmogorovâ€“Smirnov test at level $\\alpha=0.05$ to compare the empirical distributions of $g_1$ and $g_2$ (without reflection). If the null of identical distributions is not rejected, conclude mirror-image correspondence consistent with inversion.**\n\nThis procedure is fundamentally flawed for several reasons. First, it fails to perform the axis reflection ($1-x$), which is a core component of the inversion hypothesis. Second, the Kolmogorov-Smirnov (K-S) test compares the overall distributions of values, but says nothing about their spatial ordering. The inversion hypothesis is about the correspondence of values at specific (reflected) spatial locations. Two series can have identical distributions but be spatially uncorrelated. Third, the transformation $h$ and constants $\\alpha, \\beta$ will, in general, change the distribution of $g_1(1-x)$, so there is no reason to expect the distributions of $g_1$ and $g_2$ to be identical even if the hypothesis is true. Fourth, the standard K-S test assumes independent samples, which is violated by the stated spatial autocorrelation. Finally, concluding equivalence from a failure to reject the null hypothesis is a logical fallacy known as \"accepting the null\".\n**Verdict: Incorrect.**\n\n**C. Compute the Pearson correlation $r$ between $g_1(x_i)$ and $g_2(x_i)$ (without reflection). If $r< -0.8$ and significant at $\\alpha=0.05$ under the usual $t$-test for correlation with $n-2$ degrees of freedom, conclude inversion.**\n\nThis option is incorrect on multiple grounds. First, it fails to reflect the axis. A correct test would look for a positive correlation after reflection, not a negative one without reflection. Second, it uses Pearson correlation, which measures *linear* association. The problem specifies a general *monotone* function $h$, making Pearson correlation inappropriate. Third, it uses the standard $t$-test for significance, which assumes independent data points. This is explicitly contradicted by the problem statement of spatial autocorrelation, rendering the test invalid and prone to false positives. The threshold of $r < -0.8$ is also arbitrary.\n**Verdict: Incorrect.**\n\n**D. Fit the linear model $g_2(x_i)=\\alpha+\\beta g_1(x_i)+\\epsilon_i$ (without reflection) by ordinary least squares, then test $H_0\\!:\\beta=0$ against $H_1\\!:\\beta<0$ at $\\alpha=0.05$. If $H_0$ is rejected, conclude mirror-image correspondence indicative of inversion.**\n\nThis is also incorrect. Like option C, it fails to reflect the axis. It assumes a linear relationship between $g_1$ and $g_2$ by omitting the function $h$, which contradicts the problem statement. Furthermore, it proposes using ordinary least squares (OLS), which assumes independent and homoscedastic errors ($\\epsilon_i$). The stated spatial autocorrelation violates the independence assumption, invalidating the standard errors and significance tests associated with OLS. While one could use generalized least squares (GLS) to account for autocorrelation, the model would still be misspecified due to the incorrect assumption of a linear relationship.\n**Verdict: Incorrect.**", "answer": "$$\\boxed{A}$$", "id": "2564809"}, {"introduction": "After identifying a large-scale pattern, a key step in evo-devo research is to experimentally test the function of the underlying molecular components. Deep homology often involves the conservation of *cis*-regulatory enhancers, which orchestrate gene expression in space and time. This exercise places you in the role of an experimentalist designing a definitive test of enhancer function using modern genome engineering, challenging you to think beyond simple reporter assays. You must design a precise, CRISPR-based cross-species enhancer swap at the endogenous locus that respects genomic context and provides quantitative, spatially-resolved data to truly assess functional conservation. [@problem_id:2564636]", "problem": "In comparative zoology and botany, deep homology refers to the conservation of gene regulatory networks across distantly related body plans, even when morphologies differ. A central test is whether a cis-regulatory enhancer from one species can functionally substitute for its ortholog at the endogenous locus in another species. Consider the following framework: the Central Dogma of molecular biology states that DNA is transcribed into RNA and translated into protein, and for spatial and temporal specificity of transcription, cis-regulatory modules (enhancers) integrate transcription factor inputs through sequence-specific binding sites to modulate promoter activity. In Hox gene clusters, conserved anteriorâ€“posterior expression domains are established by regulatory architecture that includes enhancers, insulators, and three-dimensional genome topology constrained within Topologically Associating Domains (TADs). Assume that orthology of enhancers can be established by conserved synteny and shared motif content rather than strict sequence identity. Your task is to identify, from the options below, the most rigorous Clustered Regularly Interspaced Short Palindromic Repeats (CRISPR)-based cross-species enhancer swap experiment that would directly test whether Hox regulatory architecture is functionally conserved across phyla, and to recognize the appropriate predictions and controls that follow from first principles. The design should isolate enhancer function, avoid position effects, respect local chromatin topology, and provide quantitative, spatially resolved readouts of gene function.\n\nWhich option best satisfies these criteria?\n\nA. Use CRISPR-associated protein $9$ (Cas$9$) and homology-directed repair (HDR) to perform a scarless replacement of a defined, necessary Hox enhancer at its endogenous locus in Drosophila with the orthologous mouse enhancer, preserving enhancer orientation and distance to the promoter within the same Topologically Associating Domain (TAD). Include a reciprocal swap at the orthologous mouse locus. Use single-copy edits confirmed by whole-genome sequencing, and allele-specific reporters to distinguish the edited allele from the wild type. Quantify spatial expression with single-molecule RNA Fluorescence In Situ Hybridization (RNA-FISH), assess transcription factor occupancy by Chromatin Immunoprecipitation followed by sequencing (ChIP-seq), and test phenotypic rescue in a sensitized mutant background. Include controls: species-matched enhancer replacement (positive control), size-matched non-orthologous enhancer (negative control), and a scrambled enhancer of identical base composition (negative control). Predict that if regulatory architecture is conserved, the cross-species enhancer will drive expression domain boundaries within approximately $10\\%$ of the wild-type positions along the anteriorâ€“posterior axis and rescue segment identity defects, while maintaining appropriate three-dimensional contacts as measured by chromosome conformation capture.\n\nB. Generate transgenic Drosophila embryos carrying a multicopy plasmid with the mouse Hox enhancer driving Green Fluorescent Protein (GFP) under a heterologous minimal promoter inserted at a random genomic location. If GFP is expressed in any axial domain, conclude that regulatory architecture is conserved. No reciprocal experiment or endogenous locus replacement is needed, and bulk RNA sequencing suffices to quantify conservation without spatial analysis.\n\nC. Replace the Drosophila Hox coding sequence with the mouse Hox coding sequence using CRISPR-Cas$9$, leaving all Drosophila enhancers intact. If the mouse coding sequence rescues Drosophila segment identity phenotypes, conclude that Hox regulatory architecture is conserved across species. Enhancer manipulations are unnecessary because coding-region rescue demonstrates deep homology.\n\nD. Use CRISPR-Cas$9$ to insert the mouse enhancer into the Drosophila genome at a safe-harbor site outside the Hox cluster, while deleting the endogenous Hox enhancer. Measure overall Hox mRNA levels by bulk quantitative polymerase chain reaction (qPCR) from whole embryos at a single time point. If total mRNA is within $2$-fold of wild type, interpret this as functional conservation, because the enhancer still increases transcription even if the location differs.\n\nE. Test cross-kingdom conservation by replacing a Drosophila Hox enhancer with a plant KNOX gene enhancer at the endogenous locus. If any change in Drosophila Hox expression is detected by immunostaining at $24$ hours, conclude that deep homology of Hox regulatory architecture extends across animals and plants, rendering animalâ€“animal comparisons unnecessary.\n\nSelect the best option.", "solution": "The problem statement is subjected to validation.\n\n**Step 1: Extract Givens**\n- **Concept**: Deep homology is the conservation of gene regulatory networks across distantly related body plans.\n- **Test**: A functional substitution of a cis-regulatory enhancer from one species for its ortholog at the endogenous locus in another.\n- **Biological Framework**: Central Dogma (DNA $\\rightarrow$ RNA $\\rightarrow$ protein); enhancers integrate transcription factor (TF) inputs to modulate promoter activity for spatio-temporal gene expression.\n- **Model System**: Hox gene clusters, where expression domains are set by a regulatory architecture involving enhancers, insulators, and 3D genome topology (Topologically Associating Domains, or TADs).\n- **Assumption**: Enhancer orthology is determined by conserved synteny and shared motif content, not strict sequence identity.\n- **Task**: Identify the most rigorous CRISPR-based cross-species enhancer swap experiment to test the functional conservation of Hox regulatory architecture across phyla.\n- **Experimental Design Criteria**:\n    1. Isolate enhancer function.\n    2. Avoid position effects.\n    3. Respect local chromatin topology.\n    4. Provide quantitative, spatially resolved readouts of gene function.\n    5. Include appropriate predictions and controls.\n\n**Step 2: Validate Using Extracted Givens**\nThe problem is scientifically grounded. It accurately describes established principles in molecular, evolutionary, and developmental biology, including deep homology, the function of cis-regulatory elements, the structure of Hox gene regulation, and the application of modern genomic and gene-editing techniques like CRISPR-Cas$9$. The question is well-posed, asking for the evaluation of experimental designs against a clear and rigorous set of criteria. The language is objective and precise. The problem is self-contained and does not suffer from contradictions or missing information. The proposed scenario is a realistic, albeit challenging, representation of cutting-edge research in the field.\n\n**Step 3: Verdict and Action**\nThe problem statement is valid. It presents a sophisticated and correct challenge in experimental design. I will proceed with a full analysis of the provided options.\n\n**Solution Derivation and Option Analysis**\n\nThe task demands identification of the most rigorous experimental design to test the functional conservation of a *regulatory architecture*. This implies that the experiment must preserve the native context of the regulatory element as much as possible, as architecture is defined by the relationships between components. The core of such an experiment must be a precise replacement of the element of interest (the enhancer) at its endogenous genomic locus, minimizing all other perturbations. The readouts must be sensitive enough to detect subtle, spatially-defined changes in gene expression, which is the key function of Hox gene enhancers.\n\n**Analysis of Option A**\nThis option proposes a scarless replacement of a *Drosophila* Hox enhancer with its mouse ortholog at the endogenous locus using CRISPR-associated protein $9$ (Cas$9$) and homology-directed repair (HDR).\n- **`endogenous locus` replacement**: This is the most crucial feature. It directly tests the enhancer's function within its native chromatin environment, including its interaction with the correct promoter, insulators, and 3D contacts within the Topologically Associating Domain (TAD). This methodology correctly addresses criteria to avoid position effects and respect local chromatin topology.\n- **`scarless` replacement and preservation of `orientation` and `distance`**: These details demonstrate a high level of experimental rigor, ensuring that the only variable is the enhancer sequence itself, not artifacts of the editing process or changes in genome geometry.\n- **`reciprocal swap`**: Performing the experiment in both host organisms (*Drosophila* and mouse) provides the strongest possible evidence for conserved function.\n- **Readouts**: The use of single-molecule RNA Fluorescence In Situ Hybridization (smFISH or RNA-FISH) provides the necessary quantitative and spatially resolved expression data (criterion $4$). Chromatin Immunoprecipitation followed by sequencing (ChIP-seq) directly probes the mechanismâ€”whether host transcription factors bind the foreign enhancer. Phenotypic rescue assesses function at the organismal level. This is a multi-layered, comprehensive approach.\n- **Controls**: The inclusion of a species-matched positive control, a non-orthologous negative control, and a scrambled sequence negative control is exemplary. This allows for unambiguous attribution of any observed function to the specific, conserved regulatory information in the orthologous enhancer.\n- **Predictions**: The predictions are specific, quantitative (e.g., expression domain boundaries within $10\\%$), and mechanistically grounded, reflecting a clear hypothesis.\n**Verdict:** **Correct**. This option describes the \"gold standard\" experiment that satisfies all criteria for rigor, precision, and comprehensive analysis stated in the problem.\n\n**Analysis of Option B**\nThis option proposes generating transgenic *Drosophila* with a plasmid carrying the mouse enhancer and a reporter gene, inserted randomly.\n- **`random genomic location`**: This is a fundamental flaw. It completely fails to test the enhancer in its native architectural context. The expression will be subject to \"position effects\" from the surrounding chromatin at the insertion site, making the results uninterpretable with respect to the original Hox locus.\n- **`multicopy plasmid`**: This introduces gene dosage artifacts, another serious confounder.\n- **`heterologous minimal promoter`**: This decouples the enhancer from its native cognate promoter, failing to test a potentially conserved aspect of the regulatory architecture.\n- **`bulk RNA sequencing`**: This readout is not spatially resolved and is therefore inadequate for assessing the primary function of Hox enhancers, which is to create precise spatial patterns of expression.\n- **Conclusion logic**: Concluding conservation based on \"any axial domain\" expression is an unacceptably low standard of evidence.\n**Verdict:** **Incorrect**. This design is primitive and suffers from multiple, disqualifying flaws.\n\n**Analysis of Option C**\nThis option proposes replacing the *Drosophila* Hox *coding sequence* (the protein-coding part of the gene) with the mouse ortholog.\n- **Target of manipulation**: This experiment tests the functional conservation of the Hox *protein*, not the cis-regulatory architecture (the enhancers). The question explicitly asks to test the *regulatory architecture*. Therefore, this experiment, while potentially interesting for other reasons, does not address the question posed.\n- **Logical error**: The conclusion that regulatory architecture is conserved is a non-sequitur. The experiment provides no information about enhancer function.\n**Verdict:** **Incorrect**. This option fundamentally misunderstands the distinction between cis-regulatory elements and protein-coding genes and fails to test the specified hypothesis.\n\n**Analysis of Option D**\nThis option proposes inserting the mouse enhancer at a \"safe-harbor\" site while deleting the endogenous enhancer.\n- **`safe-harbor site`**: Although an improvement over a random insertion, this still removes the enhancer from its native TAD and its correct proximity and orientation to the target promoter. It fails to test the enhancer's function as part of the endogenous architecture, thus violating criterion $3$. The three-dimensional looping and interactions that define the architecture are lost.\n- **Readout**: The use of bulk quantitative polymerase chain reaction (qPCR) is, like bulk RNA-seq, spatially blind. It cannot measure the precision of expression domains, which is the critical functional output. Measuring total mRNA levels is a crude proxy that misses the essential biological function.\n- **Interpretation**: A $2$-fold change in total mRNA is a simplistic metric that ignores all spatial information and would not constitute a rigorous demonstration of conserved patterning function.\n**Verdict:** **Incorrect**. This design fails to test the enhancer in its proper context and uses an inadequate measurement technique.\n\n**Analysis of Option E**\nThis option proposes a cross-kingdom swap, replacing a *Drosophila* Hox enhancer with a plant *KNOX* gene enhancer.\n- **Scientific premise**: This is scientifically unsound. While *KNOX* and *Hox* genes both involve homeodomains, plants (Plantae) and animals (Animalia) have been evolving independently for over a billion years. Their transcriptional regulatory networks, including the transcription factors and the DNA sequence motifs they bind, are not conserved. Such an experiment is not a test of \"deep homology\" as the term is meaningfully used for animal phyla, but rather a speculation based on a superficial analogy. There is no a priori reason to expect functional compatibility.\n- **Experimental rigor**: The criterion for success, \"any change in Drosophila Hox expression,\" is vague and uninformative. A disruption of expression is the most likely outcome, and it proves nothing about conservation.\n- **Conclusion**: The conclusion that this would render animal-animal comparisons unnecessary is illogical and contrary to all established principles of evolutionary biology.\n**Verdict:** **Incorrect**. This option is based on a flawed scientific premise and represents a poorly conceived experiment.\n\nIn summary, Option A is the only one that describes a scientifically rigorous, methodologically sound, and comprehensive experiment that directly addresses the question of conserved regulatory architecture, meeting all the specified criteria.", "answer": "$$\\boxed{A}$$", "id": "2564636"}, {"introduction": "While testing individual components is crucial, the concept of deep homology ultimately applies to entire gene regulatory networks (GRNs). To move from single-gene studies to a systems-level understanding, we need computational tools to identify conserved network motifs across vast evolutionary distances. This practice introduces a graph-based approach to this challenge, asking you to implement a deterministic algorithm to discover \"$k$-conserved modules\" from network data annotated with taxon-specific information. This hands-on computational exercise operationalizes the search for deep homology, allowing you to systematically identify candidate conserved circuits for further experimental study. [@problem_id:2564709]", "problem": "A gene regulatory network is modeled as a directed graph $G = (V,E)$ over a finite taxa set $T$. Each node $v \\in V$ is annotated with a taxa-presence set $P_V(v) \\subseteq T$ indicating the taxa in which an orthologous gene is present. Each directed edge $e = (u \\rightarrow w) \\in E$ is annotated with a taxa-presence set $P_E(e) \\subseteq T$ indicating the taxa in which that regulatory interaction is present. For any node subset $V_H \\subseteq V$, define the induced subgraph $H = (V_H, E_H)$ where $E_H = \\{ (u \\rightarrow w) \\in E \\mid u \\in V_H, w \\in V_H \\}$. Define the support of a subgraph $H$ as\n$$\n\\mathrm{supp}(H) = \\left( \\bigcap_{v \\in V_H} P_V(v) \\right) \\cap \\left( \\bigcap_{e \\in E_H} P_E(e) \\right),\n$$\nwith the convention that $\\bigcap \\emptyset = T$. A subgraph $H$ is $k$-conserved if $|\\mathrm{supp}(H)| \\ge k$. A subgraph $H$ is connected if its underlying undirected graph is connected. A $k$-conserved module is a connected induced subgraph that is $k$-conserved. A $k$-conserved module is maximal if no node $x \\in V \\setminus V_H$ can be added to form the induced subgraph on $V_H \\cup \\{x\\}$ that remains $k$-conserved.\n\nUsing the fundamental anti-monotonicity of set intersection cardinality, namely that for any family of sets $\\{A_i\\}_{i=1}^m$ and any additional set $B$, it holds that $|\\bigcap_{i=1}^m A_i \\cap B| \\le |\\bigcap_{i=1}^m A_i|$, design and implement a deterministic lexicographic-greedy algorithm to enumerate candidate deep-homologous modules as follows:\n\n- For each seed node $s \\in V$ with $|P_V(s)| \\ge k$, initialize $V_H \\leftarrow \\{s\\}$.\n- Repeatedly attempt to add one node at a time from the set of candidate neighbors $C = \\{ x \\in V \\setminus V_H \\mid \\exists v \\in V_H \\text{ with } (x \\rightarrow v) \\in E \\text{ or } (v \\rightarrow x) \\in E \\}$, scanning nodes in strictly increasing order of their integer identifiers. For a candidate $x \\in C$, let $V_H' = V_H \\cup \\{x\\}$ and $H' = (V_H', E_{H'})$ be the induced subgraph. If $|\\mathrm{supp}(H')| \\ge k$, accept the addition by setting $V_H \\leftarrow V_H'$ and restart scanning from the smallest identifier in the updated candidate set. If no candidate node can be added without violating the threshold, stop; the final induced subgraph on $V_H$ is the module derived from seed $s$.\n- After processing all seeds, deduplicate modules by their node sets to obtain the set of distinct maximal modules produced by this lexicographic-greedy procedure.\n\nImplement this exact algorithm and apply it to the following test suite. Each test case provides $T$, $V$, $E$ (with presence sets), and $k$. Node identifiers are nonnegative integers. Presence sets are specified by taxa names. The underlying undirected connectivity criterion must be used to test connectedness during the greedy additions as defined by the candidate neighbor construction. The output for each test case is the total number of distinct maximal $k$-conserved modules produced by the algorithm. Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (e.g., \"[1,2,3]\").\n\nTest Suite:\n\n- Case $1$ (happy path):\n  - $T = \\{\\mathrm{A}, \\mathrm{B}, \\mathrm{C}, \\mathrm{D}\\}$.\n  - $V = \\{0,1,2,3,4,5\\}$ with node presence:\n    - $P_V(0) = \\{\\mathrm{A},\\mathrm{B},\\mathrm{C},\\mathrm{D}\\}$,\n    - $P_V(1) = \\{\\mathrm{A},\\mathrm{B},\\mathrm{C}\\}$,\n    - $P_V(2) = \\{\\mathrm{A},\\mathrm{C},\\mathrm{D}\\}$,\n    - $P_V(3) = \\{\\mathrm{B},\\mathrm{C}\\}$,\n    - $P_V(4) = \\{\\mathrm{A},\\mathrm{D}\\}$,\n    - $P_V(5) = \\{\\mathrm{C},\\mathrm{D}\\}$.\n  - Directed edges with presence:\n    - $(0 \\rightarrow 1): \\{\\mathrm{A},\\mathrm{B},\\mathrm{C}\\}$,\n    - $(1 \\rightarrow 2): \\{\\mathrm{A},\\mathrm{C}\\}$,\n    - $(2 \\rightarrow 3): \\{\\mathrm{C}\\}$,\n    - $(0 \\rightarrow 4): \\{\\mathrm{A},\\mathrm{D}\\}$,\n    - $(4 \\rightarrow 2): \\{\\mathrm{A},\\mathrm{D}\\}$,\n    - $(5 \\rightarrow 2): \\{\\mathrm{C},\\mathrm{D}\\}$,\n    - $(3 \\rightarrow 5): \\{\\mathrm{C}\\}$,\n    - $(1 \\rightarrow 3): \\{\\mathrm{B},\\mathrm{C}\\}$,\n    - $(4 \\rightarrow 5): \\{\\mathrm{D}\\}$.\n  - Threshold $k = 2$.\n\n- Case $2$ (boundary on conservation stringency):\n  - Same $T$, $V$, and $E$ as Case $1$.\n  - Threshold $k = 3$.\n\n- Case $3$ (edge case with only a singleton module):\n  - $T = \\{\\mathrm{A}, \\mathrm{B}\\}$.\n  - $V = \\{0,1,2\\}$ with node presence:\n    - $P_V(0) = \\{\\mathrm{A},\\mathrm{B}\\}$,\n    - $P_V(1) = \\{\\mathrm{A}\\}$,\n    - $P_V(2) = \\{\\mathrm{B}\\}$.\n  - Directed edges with presence:\n    - $(0 \\rightarrow 1): \\{\\mathrm{A}\\}$,\n    - $(0 \\rightarrow 2): \\{\\mathrm{B}\\}$.\n  - Threshold $k = 2$.\n\nYour program must compute, for each test case, the number of distinct maximal $k$-conserved modules found by the specified algorithm, and print a single line containing these three integers in order as a comma-separated list enclosed in square brackets.", "solution": "The problem statement has been rigorously analyzed and is deemed valid. It is scientifically grounded in the domain of computational systems biology, specifically concerning the identification of conserved gene regulatory modules. The problem is mathematically well-posed, providing unambiguous definitions for all componentsâ€”the graph model, node and edge annotations, the support metric $\\mathrm{supp}(H)$, and the property of being a $k$-conserved module. All necessary data and constraints for the test cases are provided, forming a self-contained and solvable computational task. The specified algorithm is deterministic, ensuring a unique solution.\n\nThe task is to implement a specific lexicographic-greedy algorithm for identifying candidate deep-homologous modules in a gene regulatory network. The fundamental principle underpinning this greedy approach is the anti-monotonicity of set intersection cardinality. For a family of sets $\\{A_i\\}$, the cardinality of their intersection cannot increase when a new set $B$ is added to the intersection: $|\\bigcap A_i \\cap B| \\le |\\bigcap A_i|$. In the context of the problem, the support of a subgraph $H'$, $\\mathrm{supp}(H')$, is the intersection of presence sets of its nodes and edges. If we extend a subgraph $H$ to a larger subgraph $H''$ by adding nodes or edges, the support of $H''$ is an intersection over a larger collection of sets. Consequently, $\\mathrm{supp}(H'') \\subseteq \\mathrm{supp}(H)$, which implies $|\\mathrm{supp}(H'')| \\le |\\mathrm{supp}(H)|$. This property ensures that if a potential subgraph formed by adding a new node fails the $k$-conservation test (i.e., its support is too small), no further expansion of that subgraph can ever satisfy the criterion. This validates the greedy strategy of terminating an expansion path once the conservation threshold is violated.\n\nThe algorithm will be implemented following these structured steps:\n\n1.  **Data Representation**: The taxa set $T$ and all presence sets ($P_V(v)$ for nodes $v \\in V$ and $P_E(e)$ for edges $e \\in E$) will be represented as `set` objects in Python for efficient intersection operations. The graph $G=(V, E)$ will be stored using an adjacency structure that allows efficient lookup of all neighbors of a node (both incoming and outgoing), as required for identifying candidate nodes for module expansion.\n\n2.  **Seed Identification**: The algorithm initiates a search process from each \"seed\" node. A node $s \\in V$ is a valid seed if it forms a $k$-conserved module by itself. A single-node induced subgraph $H_s$ on $V_H=\\{s\\}$ has an empty edge set $E_H=\\emptyset$. By the convention that an empty intersection yields the universal set $T$, the support is $\\mathrm{supp}(H_s) = P_V(s) \\cap T = P_V(s)$. Thus, a node $s$ is a valid seed if and only if $|P_V(s)| \\ge k$. All such seed nodes will be identified and processed in increasing order of their integer identifiers to ensure deterministic behavior, though the problem does not mandate a specific order for processing seeds.\n\n3.  **Greedy Module Expansion**: For each seed node $s$, a module is grown iteratively.\n    - **Initialization**: The module is initialized with the node set $V_H = \\{s\\}$, and its support is `supp_H` $= P_V(s)$.\n    - **Iteration**: The algorithm enters a loop that continues as long as the module can be expanded. In each iteration, it identifies a set of candidate nodes $C$. A node $x \\in V \\setminus V_H$ is a candidate if it is adjacent to at least one node currently in the module $V_H$. This construction ensures that the resulting module remains connected.\n    - **Candidate Evaluation**: The candidates in $C$ are evaluated in strictly increasing lexicographical order of their integer identifiers. For each candidate $x$, a prospective new module $H'$ on the vertex set $V'_H = V_H \\cup \\{x\\}$ is considered. Its support is calculated efficiently by taking the current module's support, `supp_H`, and intersecting it with the presence set of the new node, $P_V(x)$, and the presence sets of all newly induced edges. These new edges are those connecting $x$ to nodes already in $V_H$.\n    - **Acceptance and Restart**: If the support of the prospective module, $|\\mathrm{supp}(H')|$, is greater than or equal to the threshold $k$, the candidate $x$ is accepted. The module is updated ($V_H \\leftarrow V'_H$, `supp_H` $\\leftarrow \\mathrm{supp}(H')$), and the candidate evaluation loop is immediately restarted with the new, larger module. This \"first-fit\" greedy choice is key to the algorithm's definition.\n    - **Termination**: If a full pass through all sorted candidates yields no node that can be added without violating the $k$-conservation criterion, the expansion loop for the current seed terminates. The resulting module $V_H$ is considered maximal as per the algorithm's definition.\n\n4.  **Deduplication and Final Count**: The set of nodes for each generated module is stored. Since different seeds may lead to the same final module, these sets are stored in a manner that allows for automatic deduplication, for instance, by adding `frozenset` representations of the node sets to a master `set`. The final result for each test case is the total count of unique modules found.\n\nThis detailed, principle-based design will be translated into a Python program that precisely adheres to the specified logic and data, thereby guaranteeing a correct solution to the problem.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to define, run, and print results for all test cases.\n    \"\"\"\n    \n    # Test Case 1\n    case1 = {\n        \"T\": {\"A\", \"B\", \"C\", \"D\"},\n        \"V\": list(range(6)),\n        \"P_V\": [\n            {\"A\", \"B\", \"C\", \"D\"},  # Node 0\n            {\"A\", \"B\", \"C\"},      # Node 1\n            {\"A\", \"C\", \"D\"},      # Node 2\n            {\"B\", \"C\"},           # Node 3\n            {\"A\", \"D\"},           # Node 4\n            {\"C\", \"D\"},           # Node 5\n        ],\n        \"E\": {\n            (0, 1): {\"A\", \"B\", \"C\"},\n            (1, 2): {\"A\", \"C\"},\n            (2, 3): {\"C\"},\n            (0, 4): {\"A\", \"D\"},\n            (4, 2): {\"A\", \"D\"},\n            (5, 2): {\"C\", \"D\"},\n            (3, 5): {\"C\"},\n            (1, 3): {\"B\", \"C\"},\n            (4, 5): {\"D\"},\n        },\n        \"k\": 2,\n    }\n\n    # Test Case 2\n    case2 = {\n        \"T\": case1[\"T\"],\n        \"V\": case1[\"V\"],\n        \"P_V\": case1[\"P_V\"],\n        \"E\": case1[\"E\"],\n        \"k\": 3,\n    }\n\n    # Test Case 3\n    case3 = {\n        \"T\": {\"A\", \"B\"},\n        \"V\": list(range(3)),\n        \"P_V\": [\n            {\"A\", \"B\"},  # Node 0\n            {\"A\"},      # Node 1\n            {\"B\"},      # Node 2\n        ],\n        \"E\": {\n            (0, 1): {\"A\"},\n            (0, 2): {\"B\"},\n        },\n        \"k\": 2,\n    }\n\n    test_cases = [case1, case2, case3]\n    results = []\n\n    for case in test_cases:\n        result = find_modules(case[\"T\"], case[\"V\"], case[\"P_V\"], case[\"E\"], case[\"k\"])\n        results.append(result)\n\n    # The correct results based on a rigorous trace of the specified algorithm are [4, 2, 1].\n    # The code below correctly calculates these results.\n    print(f\"[{','.join(map(str, results))}]\")\n\ndef find_modules(T, V_ids, P_V, E, k):\n    \"\"\"\n    Implements the specified lexicographic-greedy algorithm to find k-conserved modules.\n    \n    Args:\n        T (set): The set of all taxa.\n        V_ids (list): A list of integer node identifiers.\n        P_V (list): A list where P_V[i] is the presence set for node i.\n        E (dict): A dictionary where keys are edge tuples (u, v) and values are presence sets.\n        k (int): The conservation threshold.\n    \n    Returns:\n        int: The number of distinct maximal k-conserved modules found.\n    \"\"\"\n    \n    all_neighbors = {v: set() for v in V_ids}\n    for u, w in E:\n        all_neighbors[u].add(w)\n        all_neighbors[w].add(u)\n\n    found_modules = set()\n\n    seed_nodes = sorted([v for v in V_ids if len(P_V[v]) >= k])\n\n    for seed in seed_nodes:\n        V_H = {seed}\n        current_support = P_V[seed]\n\n        while True:\n            added_node_in_iteration = False\n            \n            candidate_neighbors = set()\n            for node in V_H:\n                candidate_neighbors.update(all_neighbors[node])\n            candidate_neighbors -= V_H\n            \n            sorted_candidates = sorted(list(candidate_neighbors))\n            \n            for candidate in sorted_candidates:\n                # Calculate the support for the potential new module\n                potential_support = current_support  P_V[candidate]\n                \n                # If potential support is already too small, no need to check edges\n                if len(potential_support)  k:\n                    continue\n\n                for node_in_module in V_H:\n                    if (node_in_module, candidate) in E:\n                        potential_support = E[(node_in_module, candidate)]\n                    if (candidate, node_in_module) in E:\n                        potential_support = E[(candidate, node_in_module)]\n                \n                if len(potential_support) >= k:\n                    V_H.add(candidate)\n                    current_support = potential_support\n                    added_node_in_iteration = True\n                    break  # Restart candidate search with the new_V_H\n            \n            if not added_node_in_iteration:\n                break  # Module is maximal for this seed, stop expansion\n\n        found_modules.add(frozenset(V_H))\n\n    return len(found_modules)\n\nsolve()\n```", "id": "2564709"}]}