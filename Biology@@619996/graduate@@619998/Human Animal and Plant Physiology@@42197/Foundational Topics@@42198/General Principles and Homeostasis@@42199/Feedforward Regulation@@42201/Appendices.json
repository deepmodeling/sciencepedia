{"hands_on_practices": [{"introduction": "Feedforward regulation is essential for maintaining homeostasis during rapid changes in metabolic state. This first practice invites you to apply the fundamental principles of thermodynamics to a classic physiological scenario: the onset of exercise [@problem_id:2568002]. By calculating the required anticipatory sweat rate, you will quantify how the nervous system predicts and counteracts a future thermal load before core temperature is significantly disturbed.", "problem": "A human runner of mass $m = 70\\,\\mathrm{kg}$ begins a steady endurance run at time $t=0$ in a temperate environment. Before any appreciable core temperature change occurs, the nervous system generates a feedforward (anticipatory) increase in sweat secretion based on the predicted metabolic heat load. Assume the following scientifically supported facts and conditions, which you must treat as the fundamental starting point for your derivation:\n\n- The First Law of Thermodynamics applied to the bodyâ€™s core compartment relates the rate of change of core thermal energy to the difference between metabolic heat production and total heat loss.\n- The whole-body heat capacity is $C = m c_b$, where the specific heat capacity is $c_b = 3.5\\,\\mathrm{kJ\\,kg^{-1}\\,K^{-1}}$.\n- Initial core temperature is $T_c(0) = 37^{\\circ}\\mathrm{C}$ and ambient temperature is $T_a = 25^{\\circ}\\mathrm{C}$.\n- Over the first instants after $t=0$, dry heat exchange (convection plus radiation) can be modeled as linear with the instantaneous core-to-ambient temperature difference, with coefficient $k_d = 6.0\\,\\mathrm{W\\,K^{-1}}$ that remains approximately constant over this short interval.\n- The latent heat of water vaporization at skin temperature is $\\lambda = 2.43 \\times 10^{6}\\,\\mathrm{J\\,kg^{-1}}$.\n- Only a fraction $\\eta = 0.70$ of secreted sweat evaporates and contributes to cooling over this short interval (the remainder drips or accumulates).\n- Metabolic heat production increases as a step at $t=0$ from $M_{\\mathrm{rest}} = 80\\,\\mathrm{W}$ to $M_{\\mathrm{ex}} = 680\\,\\mathrm{W}$ due to the onset of exercise. Assume external mechanical work is negligible compared to $M_{\\mathrm{ex}}$ so that $M_{\\mathrm{ex}}$ can be treated as net heat generation to be dissipated.\n- Respiratory heat and mass exchange are negligible compared to cutaneous pathways over this short interval.\n\nUsing these bases, and starting from energy conservation applied to the core, determine the minimal instantaneous feedforward sweat secretion rate $\\dot{m}_{s,\\mathrm{ff}}$ at $t=0^{+}$ that ensures the instantaneous core temperature slope is zero, that is, $\\frac{dT_c}{dt}(0^{+}) = 0$. Express $\\dot{m}_{s,\\mathrm{ff}}$ in $\\mathrm{g\\,min^{-1}}$. Round your final numerical result to three significant figures.", "solution": "The problem requires the determination of a specific feedforward physiological response, the sweat secretion rate, that ensures thermal stability at the onset of exercise. This is a problem of energy conservation, and its solution must be grounded in the First Law of Thermodynamics.\n\nWe begin by applying the principle of energy conservation to the human body, treated as a single thermodynamic compartment. The rate of change of the body's internal thermal energy, $\\frac{dE}{dt}$, is equal to the rate of metabolic heat production, $M$, minus the rate of total heat loss to the environment, $H_{loss}$.\nThe change in thermal energy is related to the change in core temperature, $T_c$, by the whole-body heat capacity, $C$. Thus, the energy balance equation is:\n$$C \\frac{dT_c}{dt} = M - H_{loss}$$\nThe total heat loss, $H_{loss}$, is the sum of dry heat loss (convection and radiation), $H_d$, and evaporative (latent) heat loss, $H_e$. We are told to neglect respiratory heat loss.\n$$H_{loss} = H_d + H_e$$\nSubstituting this into the energy balance equation gives:\n$$C \\frac{dT_c}{dt} = M - (H_d + H_e)$$\nThis equation governs the behavior of the core temperature. The problem specifies a critical condition at the exact moment exercise begins, which we denote as $t=0^{+}$. At this instant, a feedforward control mechanism seeks to maintain thermal homeostasis by ensuring the core temperature does not immediately begin to rise. This is expressed mathematically as:\n$$\\frac{dT_c}{dt}(0^{+}) = 0$$\nApplying this condition to our energy balance equation, we find that the term on the left-hand side becomes zero. This implies that, for stability to be maintained at $t=0^{+}$, the rate of heat production must be exactly balanced by the rate of heat loss.\n$$0 = M(0^{+}) - (H_d(0^{+}) + H_e(0^{+} ))$$\n$$M(0^{+}) = H_d(0^{+}) + H_e(0^{+})$$\nNote that the heat capacity of the body, $C$, is not required to solve for the condition where the temperature change is zero. Its inclusion in the problem statement serves to test one's understanding of the governing equation.\n\nNow, we must define each term at the instant $t=0^{+}$ using the provided information.\nThe metabolic heat production rate, $M$, increases as a step function from a resting value to an exercise value. At $t=0^{+}$, it is the exercise value:\n$$M(0^{+}) = M_{ex} = 680\\,\\mathrm{W}$$\nThe dry heat loss, $H_d$, is given as a linear function of the temperature difference between the core and the ambient environment, $H_d = k_d (T_c - T_a)$. At $t=0^{+}$, the core temperature has not yet had time to change from its initial value, $T_c(0)$.\n$$H_d(0^{+}) = k_d (T_c(0) - T_a)$$\nSubstituting the given values:\n$$T_c(0) = 37^{\\circ}\\mathrm{C}$$\n$$T_a = 25^{\\circ}\\mathrm{C}$$\nThe temperature difference, which is equivalent in Celsius and Kelvin, is $\\Delta T = 37 - 25 = 12\\,\\mathrm{K}$.\n$$H_d(0^{+}) = (6.0\\,\\mathrm{W\\,K^{-1}}) \\times (12\\,\\mathrm{K}) = 72\\,\\mathrm{W}$$\nThe evaporative heat loss, $H_e$, is due to the phase change of sweat. It is the product of the effective rate of sweat evaporation and the latent heat of vaporization, $\\lambda$. The feedforward sweat secretion rate is $\\dot{m}_{s,\\mathrm{ff}}$, but only a fraction $\\eta$ evaporates effectively.\n$$H_e(0^{+}) = \\eta \\cdot \\dot{m}_{s,\\mathrm{ff}} \\cdot \\lambda$$\nWe now substitute these expressions back into our steady-state energy balance equation:\n$$M_{ex} = k_d (T_c(0) - T_a) + \\eta \\cdot \\dot{m}_{s,\\mathrm{ff}} \\cdot \\lambda$$\nThe only unknown is the quantity we seek, $\\dot{m}_{s,\\mathrm{ff}}$. We rearrange the equation to solve for it:\n$$\\eta \\cdot \\dot{m}_{s,\\mathrm{ff}} \\cdot \\lambda = M_{ex} - k_d (T_c(0) - T_a)$$\n$$\\dot{m}_{s,\\mathrm{ff}} = \\frac{M_{ex} - k_d (T_c(0) - T_a)}{\\eta \\lambda}$$\nWe can now substitute the numerical values into this expression. All values are in base SI units (watts, joules, kelvin, kilograms).\n$$M_{ex} = 680\\,\\mathrm{J\\,s^{-1}}$$\n$$k_d (T_c(0) - T_a) = 72\\,\\mathrm{J\\,s^{-1}}$$\n$$\\eta = 0.70$$\n$$\\lambda = 2.43 \\times 10^{6}\\,\\mathrm{J\\,kg^{-1}}$$\n$$\\dot{m}_{s,\\mathrm{ff}} = \\frac{680\\,\\mathrm{J\\,s^{-1}} - 72\\,\\mathrm{J\\,s^{-1}}}{0.70 \\times (2.43 \\times 10^{6}\\,\\mathrm{J\\,kg^{-1}})} = \\frac{608\\,\\mathrm{J\\,s^{-1}}}{1.701 \\times 10^{6}\\,\\mathrm{J\\,kg^{-1}}}$$\n$$\\dot{m}_{s,\\mathrm{ff}} \\approx 3.574368 \\times 10^{-4}\\,\\mathrm{kg\\,s^{-1}}$$\nThe problem requires the answer in units of grams per minute ($\\mathrm{g\\,min^{-1}}$). We perform the necessary unit conversion:\n$$1\\,\\mathrm{kg} = 1000\\,\\mathrm{g}$$\n$$1\\,\\mathrm{min} = 60\\,\\mathrm{s}$$\n$$\\dot{m}_{s,\\mathrm{ff}} \\approx (3.574368 \\times 10^{-4}\\,\\frac{\\mathrm{kg}}{\\mathrm{s}}) \\times (\\frac{1000\\,\\mathrm{g}}{1\\,\\mathrm{kg}}) \\times (\\frac{60\\,\\mathrm{s}}{1\\,\\mathrm{min}})$$\n$$\\dot{m}_{s,\\mathrm{ff}} \\approx 21.4462\\,\\mathrm{g\\,min^{-1}}$$\nRounding the result to three significant figures, as instructed:\n$$\\dot{m}_{s,\\mathrm{ff}} \\approx 21.4\\,\\mathrm{g\\,min^{-1}}$$\nThis is the minimal sweat secretion rate required by the feedforward system to instantaneously balance the heat budget at the onset of exercise, thereby preventing an initial rise in core temperature.", "answer": "$$\\boxed{21.4}$$", "id": "2568002"}, {"introduction": "Biological systems are rarely perfect; they are shaped by evolutionary trade-offs. This exercise moves beyond the idea of perfect disturbance rejection to explore the optimal design of a feedforward controller from a bioenergetic and evolutionary perspective [@problem_id:2568003]. You will derive an optimal feedforward gain, $g^{\\ast}$, by minimizing a fitness cost that balances the penalty for physiological mismatch against the energetic cost of the response itself, a core principle in systems biology.", "problem": "In a vertebrate digestive system, anticipatory secretion of a hormone is driven by a feedforward cue. Let the anticipatory effector output be modeled as $R = g S$, where $S$ is a sensory cue available at time $t=0$ and $g$ is a dimensionless feedforward gain. The physiological load that arrives later (for example, absorbed nutrients) is denoted by $X$. Across many episodes, assume that $S$ and $X$ are jointly Gaussian with zero means, finite second moments, and known second-order statistics.\n\nDefine the expected Malthusian fitness decrement per episode as the sum of two components: a mismatch penalty proportional to the expected squared deviation between the load and the anticipatory response, and an energetic cost proportional to the expected squared magnitude of the anticipatory response. Specifically, the decrement is\n$$\n\\Delta \\mathcal{F}(g) \\equiv \\alpha \\,\\mathbb{E}\\!\\left[(X - g S)^{2}\\right] + \\beta \\,\\mathbb{E}\\!\\left[R^{2}\\right],\n$$\nwhere $\\alpha>0$ and $\\beta>0$ are fixed coefficients reflecting, respectively, the strength of selection against mismatch and the energetic penalty of producing effector output. Assume that the baseline Malthusian fitness is sufficiently large that maximizing expected fitness is equivalent to minimizing $\\Delta \\mathcal{F}(g)$.\n\nUsing only the definitions of expectation, variance, and covariance for jointly Gaussian zero-mean variables, and the small-deviation quadratic approximation near physiological optima, derive from first principles the optimal feedforward gain $g^{\\ast}$ that minimizes $\\Delta \\mathcal{F}(g)$ in terms of $\\alpha$, $\\beta$, $\\mathrm{Var}(S)$, and $\\mathrm{Cov}(X,S)$. Then, for the empirically observed values $\\mathrm{Var}(S)=16$, $\\mathrm{Var}(X)=25$, correlation coefficient $\\rho=0.5$ between $S$ and $X$, $\\alpha=1.8$, and $\\beta=0.6$, compute the numerical value of $g^{\\ast}$.\n\nExpress your final answer as a single dimensionless number, rounded to four significant figures.", "solution": "The objective function to be minimized is the expected Malthusian fitness decrement, given by\n$$ \\Delta \\mathcal{F}(g) = \\alpha \\,\\mathbb{E}\\!\\left[(X - g S)^{2}\\right] + \\beta \\,\\mathbb{E}\\!\\left[R^{2}\\right] $$\nWe are given that the anticipatory response is $R = gS$. Substituting this into the expression for $\\Delta \\mathcal{F}(g)$ yields\n$$ \\Delta \\mathcal{F}(g) = \\alpha \\,\\mathbb{E}\\!\\left[(X - g S)^{2}\\right] + \\beta \\,\\mathbb{E}\\!\\left[(gS)^{2}\\right] $$\nWe expand the squared terms inside the expectation operators:\n$$ \\Delta \\mathcal{F}(g) = \\alpha \\,\\mathbb{E}\\!\\left[X^2 - 2gXS + g^2 S^2\\right] + \\beta \\,\\mathbb{E}\\!\\left[g^2 S^2\\right] $$\nBy the linearity of the expectation operator, we can distribute it over the terms:\n$$ \\Delta \\mathcal{F}(g) = \\alpha \\left(\\mathbb{E}[X^2] - 2g\\mathbb{E}[XS] + g^2\\mathbb{E}[S^2]\\right) + \\beta g^2 \\mathbb{E}[S^2] $$\nThe problem states that $X$ and $S$ are zero-mean random variables, i.e., $\\mathbb{E}[X] = 0$ and $\\mathbb{E}[S] = 0$. For a zero-mean variable $Z$, its variance is defined as $\\mathrm{Var}(Z) = \\mathbb{E}[(Z - \\mathbb{E}[Z])^2] = \\mathbb{E}[Z^2]$. Similarly, the covariance between two zero-mean variables $X$ and $S$ is $\\mathrm{Cov}(X,S) = \\mathbb{E}[(X - \\mathbb{E}[X])(S - \\mathbb{E}[S])] = \\mathbb{E}[XS]$.\nUsing these definitions, we substitute the second moments with their corresponding variance and covariance terms:\n$$ \\Delta \\mathcal{F}(g) = \\alpha \\left(\\mathrm{Var}(X) - 2g\\mathrm{Cov}(X,S) + g^2\\mathrm{Var}(S)\\right) + \\beta g^2 \\mathrm{Var}(S) $$\nWe can rearrange this expression by grouping terms with respect to powers of the gain $g$:\n$$ \\Delta \\mathcal{F}(g) = (\\alpha \\mathrm{Var}(S) + \\beta \\mathrm{Var}(S)) g^2 - (2\\alpha \\mathrm{Cov}(X,S)) g + \\alpha \\mathrm{Var}(X) $$\n$$ \\Delta \\mathcal{F}(g) = (\\alpha + \\beta)\\mathrm{Var}(S) g^2 - 2\\alpha \\mathrm{Cov}(X,S) g + \\alpha \\mathrm{Var}(X) $$\nThis expression is a quadratic function of $g$. To find the value of $g$ that minimizes $\\Delta \\mathcal{F}(g)$, we must compute the derivative with respect to $g$ and set it to zero.\n$$ \\frac{d}{dg} \\Delta \\mathcal{F}(g) = \\frac{d}{dg} \\left( (\\alpha + \\beta)\\mathrm{Var}(S) g^2 - 2\\alpha \\mathrm{Cov}(X,S) g + \\alpha \\mathrm{Var}(X) \\right) $$\n$$ \\frac{d}{dg} \\Delta \\mathcal{F}(g) = 2(\\alpha + \\beta)\\mathrm{Var}(S) g - 2\\alpha \\mathrm{Cov}(X,S) $$\nSetting the derivative to zero to find the optimal gain $g^{\\ast}$:\n$$ 2(\\alpha + \\beta)\\mathrm{Var}(S) g^{\\ast} - 2\\alpha \\mathrm{Cov}(X,S) = 0 $$\n$$ (\\alpha + \\beta)\\mathrm{Var}(S) g^{\\ast} = \\alpha \\mathrm{Cov}(X,S) $$\nSolving for $g^{\\ast}$ yields the analytical expression for the optimal feedforward gain:\n$$ g^{\\ast} = \\frac{\\alpha \\mathrm{Cov}(X,S)}{(\\alpha + \\beta) \\mathrm{Var}(S)} $$\nThe second derivative, $\\frac{d^2}{dg^2} \\Delta \\mathcal{F}(g) = 2(\\alpha + \\beta)\\mathrm{Var}(S)$, is positive because $\\alpha > 0$, $\\beta > 0$, and $\\mathrm{Var}(S) \\geq 0$ (and must be strictly positive for the expression to be well-defined), confirming that $g^{\\ast}$ indeed corresponds to a minimum.\n\nNow, we compute the numerical value of $g^{\\ast}$ using the provided empirical data: $\\mathrm{Var}(S)=16$, $\\mathrm{Var}(X)=25$, $\\rho=0.5$, $\\alpha=1.8$, and $\\beta=0.6$.\nFirst, we must find the covariance $\\mathrm{Cov}(X,S)$ from the correlation coefficient $\\rho$. The definition of the correlation coefficient is $\\rho = \\frac{\\mathrm{Cov}(X,S)}{\\sqrt{\\mathrm{Var}(X)}\\sqrt{\\mathrm{Var}(S)}}$.\nRearranging for the covariance:\n$$ \\mathrm{Cov}(X,S) = \\rho \\sqrt{\\mathrm{Var}(X)} \\sqrt{\\mathrm{Var}(S)} $$\nSubstituting the numerical values:\n$$ \\mathrm{Cov}(X,S) = 0.5 \\times \\sqrt{25} \\times \\sqrt{16} = 0.5 \\times 5 \\times 4 = 10 $$\nNow, we substitute all numerical values into the expression for $g^{\\ast}$:\n$$ g^{\\ast} = \\frac{\\alpha \\mathrm{Cov}(X,S)}{(\\alpha + \\beta) \\mathrm{Var}(S)} = \\frac{1.8 \\times 10}{(1.8 + 0.6) \\times 16} $$\n$$ g^{\\ast} = \\frac{18}{2.4 \\times 16} $$\n$$ g^{\\ast} = \\frac{18}{38.4} = 0.46875 $$\nThe problem requires the final answer to be rounded to four significant figures.\n$$ g^{\\ast} \\approx 0.4688 $$\nThis is the optimal dimensionless feedforward gain under the given conditions.", "answer": "$$\\boxed{0.4688}$$", "id": "2568003"}, {"introduction": "To bridge the gap between abstract theory and practical application, we must account for the imperfections inherent in any real system. This final practice challenges you to model and simulate a feedforward controller subject to common non-idealities, including sensor bias ($\\rho$), parameter variability ($\\gamma$), and the physical saturation of an effector's output [@problem_id:2568005]. By implementing the controller computationally, you will gain direct insight into how these factors degrade performance and lead to residual errors in regulation.", "problem": "You are asked to formalize and compute a feedforward regulator for a homeostatic variable in a physiological system under small deviations about a setpoint. The context is that a controlled variable (for example, blood glucose concentration) is regulated by an effector (for example, insulin secretion) while facing an incoming disturbance (for example, a nutrient influx). Starting from core definitions and widely accepted approximations used in physiology and control, assume the following:\n\n1. Around a setpoint, small deviations of the controlled variable obey first-order linearization and superposition, so that the steady-state deviation of the controlled variable, denoted by $\\Delta y$, in response to small changes in the effector $\\Delta u$ and a small disturbance $d$, satisfies an additive relation with constant local sensitivities (gain coefficients). Concretely, the controlled variable deviation is determined by the effector sensitivity and the disturbance sensitivity, both taken as constants in a neighborhood of the setpoint under the standard linear approximation used in physiology when the perturbations are small.\n\n2. A feedforward controller uses an anticipatory estimate $\\hat{d}$ of the disturbance $d$ and applies an effector command proportional to this estimate, $\\Delta u = k \\,\\hat{d}$, where $k$ is a feedforward gain to be designed. The estimator may exhibit a consistent multiplicative bias, modeled as $\\hat{d} = \\rho \\, d$, where $\\rho$ is a constant.\n\n3. The actual effector sensitivity may deviate from the nominal model by a constant multiplicative factor $\\gamma$ due to physiological variability (for example, receptor sensitivity variability). Thus, the actual sensitivity to the effector is scaled by $\\gamma$ relative to its nominal value.\n\n4. The effector pathway is bounded by actuator limits, meaning the commanded change in effector is saturated according to the clipping map $\\mathrm{clip}(x, a, b) = \\min(\\max(x,a), b)$. Hence, the applied effector is $\\Delta u_{\\mathrm{applied}} = \\mathrm{clip}(k \\,\\hat{d}, -U_{\\max}, U_{\\max})$, where $U_{\\max} \\ge 0$ is a known bound.\n\nTasks:\n\na) Starting only from the above fundamental base consisting of first-order linearization and superposition, and the given structural assumptions about the estimator bias, plant sensitivity variability, and actuator saturation, derive an expression for the ideal feedforward gain $k^{\\star}$ that nulls the first-order steady-state deviation of the controlled variable when there is no estimator bias and no sensitivity deviation, that is, when $\\rho = 1$ and $\\gamma = 1$, and when the actuator is not saturated.\n\nb) Under general bias and variability $(\\rho, \\gamma)$ and with actuator saturation, derive the expression for the residual steady-state deviation $\\Delta y$ of the controlled variable in terms of the nominal sensitivities, the implemented feedforward gain $k$, the bias factor $\\rho$, the variability factor $\\gamma$, the disturbance magnitude $d$, and the bound $U_{\\max}$. Your expression must correctly account for the clipping nonlinearity via $\\Delta u_{\\mathrm{applied}}$.\n\nc) Implement a program that, for each test case below, computes the ideal gain $k^{\\star}$ from the nominal sensitivities and then uses $k = k^{\\star}$ in the presence of the specified $(\\rho, \\gamma, U_{\\max})$ to compute the residual steady-state deviation $\\Delta y$. You must report the numerical values of $\\Delta y$ in millimoles per liter (mmol/L), rounded to $3$ decimals. The effector and disturbance sensitivities should be treated as nominal constants in your computation of $k^{\\star}$.\n\nQuantities and symbols to be used in the derivation and computation:\n\n- Nominal effector sensitivity to the controlled variable: $G_{u}$.\n- Nominal disturbance sensitivity to the controlled variable: $G_{d}$.\n- Disturbance magnitude: $d$.\n- Feedforward gain: $k$.\n- Bias factor: $\\rho$.\n- Variability factor: $\\gamma$.\n- Effector bound: $U_{\\max}$.\n- Applied effector after saturation: $\\Delta u_{\\mathrm{applied}} = \\mathrm{clip}(k \\,\\rho \\, d, -U_{\\max}, U_{\\max})$.\n- Residual controlled variable deviation: $\\Delta y$ in $\\mathrm{mmol/L}$.\n\nUse the following test suite of parameter values, which span a happy path, biased estimation without saturation, saturation with plant variability, a zero-disturbance boundary case, and a negative disturbance with saturation:\n\n- Test $1$: $G_{u} = -0.9$, $G_{d} = 1.2$, $d = 2.0$, $\\rho = 1.0$, $\\gamma = 1.0$, $U_{\\max} = 10.0$.\n- Test $2$: $G_{u} = -0.9$, $G_{d} = 1.2$, $d = 2.0$, $\\rho = 0.7$, $\\gamma = 1.0$, $U_{\\max} = 10.0$.\n- Test $3$: $G_{u} = -0.8$, $G_{d} = 1.0$, $d = 5.0$, $\\rho = 1.1$, $\\gamma = 1.25$, $U_{\\max} = 3.0$.\n- Test $4$: $G_{u} = -1.0$, $G_{d} = 0.5$, $d = 0.0$, $\\rho = 0.5$, $\\gamma = 2.0$, $U_{\\max} = 1.0$.\n- Test $5$: $G_{u} = -0.6$, $G_{d} = 0.9$, $d = -1.5$, $\\rho = 1.0$, $\\gamma = 1.0$, $U_{\\max} = 1.0$.\n\nYour program should compute, for each test, the ideal gain $k^{\\star}$ from the nominal pair $(G_{u}, G_{d})$, then set $k = k^{\\star}$, form $\\Delta u_{\\mathrm{applied}} = \\mathrm{clip}(k \\,\\rho \\, d, -U_{\\max}, U_{\\max})$, and finally compute $\\Delta y$ according to your derived relation. Express each $\\Delta y$ in $\\mathrm{mmol/L}$ rounded to $3$ decimals.\n\nFinal output format: Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (for example, $[r_{1},r_{2},r_{3},r_{4},r_{5}]$), where each $r_{i}$ is the rounded $\\Delta y$ in $\\mathrm{mmol/L}$ for test $i$.", "solution": "The derivation proceeds from the fundamental principles.\nBased on the principle of superposition for a linearized system, the total steady-state deviation of the controlled variable, $\\Delta y$, is the sum of the deviation caused by the disturbance $d$ and the deviation caused by the applied effector action $\\Delta u_{\\mathrm{applied}}$. The effect of the disturbance is its magnitude multiplied by the disturbance sensitivity, $G_{d}d$. The effect of the effector is its applied magnitude multiplied by the *actual* effector sensitivity. The nominal effector sensitivity is $G_{u}$, and it is subject to a variability factor $\\gamma$, so the actual sensitivity is $\\gamma G_{u}$. Thus, the fundamental equation for the system is:\n$$\n\\Delta y = (\\gamma G_{u}) \\Delta u_{\\mathrm{applied}} + G_{d} d\n$$\n\n(a) Derivation of the ideal feedforward gain $k^{\\star}$.\nFor the ideal case, we are given no estimator bias ($\\rho = 1$), no plant sensitivity deviation ($\\gamma = 1$), and no actuator saturation.\nIn this scenario, the disturbance estimate is perfect: $\\hat{d} = \\rho d = (1)d = d$.\nThe controller command is $\\Delta u = k \\hat{d} = k d$.\nWith no saturation, the applied effector equals the commanded effector: $\\Delta u_{\\mathrm{applied}} = \\Delta u = k d$.\nSubstituting these ideal conditions ($\\gamma=1$ and $\\Delta u_{\\mathrm{applied}} = kd$) into the fundamental system equation gives:\n$$\n\\Delta y = (1 \\cdot G_{u}) (k d) + G_{d} d\n$$\n$$\n\\Delta y = (k G_{u} + G_{d}) d\n$$\nThe ideal feedforward gain, denoted $k^{\\star}$, is designed to nullify this deviation, meaning $\\Delta y = 0$. For any non-zero disturbance $d \\neq 0$, this requires:\n$$\nk^{\\star} G_{u} + G_{d} = 0\n$$\nSolving for $k^{\\star}$ yields the expression for the ideal gain:\n$$\nk^{\\star} = -\\frac{G_{d}}{G_{u}}\n$$\nThis gain ensures the control action generates an effect equal in magnitude and opposite in sign to the effect of the disturbance, thereby achieving perfect cancellation.\n\n(b) Derivation of the residual steady-state deviation $\\Delta y$ under general conditions.\nNow we consider the general case with estimator bias $\\rho$, plant variability $\\gamma$, and actuator saturation defined by $U_{\\max}$.\nThe controller command is based on the biased estimate: $\\Delta u = k \\hat{d} = k (\\rho d)$.\nThis command is then clipped by the actuator limits:\n$$\n\\Delta u_{\\mathrm{applied}} = \\mathrm{clip}(k \\rho d, -U_{\\max}, U_{\\max})\n$$\nWe substitute this expression for the applied effector action into the fundamental system equation:\n$$\n\\Delta y = \\gamma G_{u} \\cdot \\mathrm{clip}(k \\rho d, -U_{\\max}, U_{\\max}) + G_{d} d\n$$\nThis is the complete and general expression for the residual steady-state deviation $\\Delta y$ in terms of all specified parameters and the clipping nonlinearity.\n\n(c) Computation for test cases.\nFor each test case, we first compute the ideal gain $k^{\\star} = -G_d/G_u$ using the nominal sensitivities. We then set the implemented gain $k = k^{\\star}$ and use the general formula for $\\Delta y$ from part (b) with the specified parameters $(\\rho, \\gamma, d, U_{\\max})$.\n\nTest $1$: $G_{u} = -0.9$, $G_{d} = 1.2$, $d = 2.0$, $\\rho = 1.0$, $\\gamma = 1.0$, $U_{\\max} = 10.0$.\n$k = k^{\\star} = - (1.2) / (-0.9) = 4/3$.\nCommanded effector: $k \\rho d = (4/3) \\cdot 1.0 \\cdot 2.0 = 8/3 \\approx 2.667$.\nApplied effector: $\\Delta u_{\\mathrm{applied}} = \\mathrm{clip}(8/3, -10.0, 10.0) = 8/3$.\nResidual deviation: $\\Delta y = 1.0 \\cdot (-0.9) \\cdot (8/3) + 1.2 \\cdot 2.0 = -2.4 + 2.4 = 0$.\n$\\Delta y = 0.000$ mmol/L.\n\nTest $2$: $G_{u} = -0.9$, $G_{d} = 1.2$, $d = 2.0$, $\\rho = 0.7$, $\\gamma = 1.0$, $U_{\\max} = 10.0$.\n$k = k^{\\star} = - (1.2) / (-0.9) = 4/3$.\nCommanded effector: $k \\rho d = (4/3) \\cdot 0.7 \\cdot 2.0 = (4/3) \\cdot 1.4 = 5.6/3 \\approx 1.867$.\nApplied effector: $\\Delta u_{\\mathrm{applied}} = \\mathrm{clip}(5.6/3, -10.0, 10.0) = 5.6/3$.\nResidual deviation: $\\Delta y = 1.0 \\cdot (-0.9) \\cdot (5.6/3) + 1.2 \\cdot 2.0 = -0.3 \\cdot 5.6 + 2.4 = -1.68 + 2.4 = 0.72$.\n$\\Delta y = 0.720$ mmol/L.\n\nTest $3$: $G_{u} = -0.8$, $G_{d} = 1.0$, $d = 5.0$, $\\rho = 1.1$, $\\gamma = 1.25$, $U_{\\max} = 3.0$.\n$k = k^{\\star} = - (1.0) / (-0.8) = 1.25$.\nCommanded effector: $k \\rho d = 1.25 \\cdot 1.1 \\cdot 5.0 = 6.875$.\nApplied effector: $\\Delta u_{\\mathrm{applied}} = \\mathrm{clip}(6.875, -3.0, 3.0) = 3.0$.\nResidual deviation: $\\Delta y = 1.25 \\cdot (-0.8) \\cdot 3.0 + 1.0 \\cdot 5.0 = -1.0 \\cdot 3.0 + 5.0 = -3.0 + 5.0 = 2.0$.\n$\\Delta y = 2.000$ mmol/L.\n\nTest $4$: $G_{u} = -1.0$, $G_{d} = 0.5$, $d = 0.0$, $\\rho = 0.5$, $\\gamma = 2.0$, $U_{\\max} = 1.0$.\n$k = k^{\\star} = - (0.5) / (-1.0) = 0.5$.\nCommanded effector: $k \\rho d = 0.5 \\cdot 0.5 \\cdot 0.0 = 0$.\nApplied effector: $\\Delta u_{\\mathrm{applied}} = \\mathrm{clip}(0, -1.0, 1.0) = 0$.\nResidual deviation: $\\Delta y = 2.0 \\cdot (-1.0) \\cdot 0 + 0.5 \\cdot 0.0 = 0$.\n$\\Delta y = 0.000$ mmol/L.\n\nTest $5$: $G_{u} = -0.6$, $G_{d} = 0.9$, $d = -1.5$, $\\rho = 1.0$, $\\gamma = 1.0$, $U_{\\max} = 1.0$.\n$k = k^{\\star} = - (0.9) / (-0.6) = 1.5$.\nCommanded effector: $k \\rho d = 1.5 \\cdot 1.0 \\cdot (-1.5) = -2.25$.\nApplied effector: $\\Delta u_{\\mathrm{applied}} = \\mathrm{clip}(-2.25, -1.0, 1.0) = -1.0$.\nResidual deviation: $\\Delta y = 1.0 \\cdot (-0.6) \\cdot (-1.0) + 0.9 \\cdot (-1.5) = 0.6 - 1.35 = -0.75$.\n$\\Delta y = -0.750$ mmol/L.\n\nThese calculations will be implemented programmatically as required.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Computes the residual steady-state deviation for a feedforward-regulated\n    physiological variable under various conditions.\n    \"\"\"\n    \n    # Define the test cases from the problem statement.\n    # Each case is a tuple: (G_u, G_d, d, rho, gamma, U_max)\n    test_cases = [\n        (-0.9, 1.2, 2.0, 1.0, 1.0, 10.0),  # Test 1\n        (-0.9, 1.2, 2.0, 0.7, 1.0, 10.0),  # Test 2\n        (-0.8, 1.0, 5.0, 1.1, 1.25, 3.0),  # Test 3\n        (-1.0, 0.5, 0.0, 0.5, 2.0, 1.0),   # Test 4\n        (-0.6, 0.9, -1.5, 1.0, 1.0, 1.0)  # Test 5\n    ]\n\n    results = []\n    \n    for case in test_cases:\n        # Unpack parameters for the current test case\n        G_u, G_d, d, rho, gamma, U_max = case\n\n        # Task (a) and (c): Compute the ideal feedforward gain k_star\n        # and set k = k_star.\n        # This gain is based on nominal sensitivities and is intended to\n        # perfectly cancel the disturbance in the ideal case.\n        # k_star = -G_d / G_u\n        # A check for G_u being zero is good practice, but not necessary for\n        # the given test cases.\n        if G_u == 0:\n            # If G_u is zero, the effector has no influence, so control is impossible.\n            # This scenario is not in the test data but represents a singularity.\n            # For this problem, we can assume G_u is never zero.\n            pass\n        \n        k_star = -G_d / G_u\n        k = k_star\n\n        # Task (b) and (c): Derive and compute the residual deviation delta_y\n        # under general conditions, including saturation.\n\n        # 1. Calculate the commanded effector change before saturation\n        # delta_u_command = k * rho * d\n        u_command = k * rho * d\n\n        # 2. Apply the actuator saturation (clipping)\n        # delta_u_applied = clip(delta_u_command, -U_max, U_max)\n        u_applied = np.clip(u_command, -U_max, U_max)\n\n        # 3. Compute the final residual steady-state deviation\n        # delta_y = gamma * G_u * delta_u_applied + G_d * d\n        delta_y = gamma * G_u * u_applied + G_d * d\n\n        # Round the result to 3 decimal places as required\n        rounded_delta_y = round(delta_y, 3)\n        results.append(f\"{rounded_delta_y:.3f}\")\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(results)}]\")\n\nsolve()\n```", "id": "2568005"}]}