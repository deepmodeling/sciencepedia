{"hands_on_practices": [{"introduction": "A fundamental step in designing any clinical study, including a Controlled Human Infection Model (CHIM), is determining the appropriate number of participants. An adequately powered study has a high probability of detecting a true effect, such as a vaccine's efficacy, while enrolling too few participants wastes resources and exposes volunteers to risk without a high likelihood of a conclusive result. This exercise [@problem_id:2854507] guides you through a robust sample size calculation and introduces the practical concept of adaptive re-estimation, a crucial technique used when initial assumptions about parameters like the infection attack rate prove incorrect.", "problem": "A two-arm randomized Controlled Human Infection Model (CHIM) study is planned to evaluate a vaccine against influenza. After informed consent, adults are randomized $1:1$ to receive vaccine or placebo and then are inoculated with a standardized challenge dose. The primary endpoint is infection status within $7$ days by reverse-transcription polymerase chain reaction (RT-PCR), coded as infected ($1$) or not infected ($0$). Let $p_{C}$ denote the infection probability in the placebo (control) arm and $p_{V}$ the infection probability in the vaccine arm. The estimand is the log risk ratio $\\theta = \\ln\\!\\left(p_{V}/p_{C}\\right)$. The target Vaccine Efficacy (VE) is $0.60$, so that the design alternative corresponds to a risk ratio $RR = 1 - \\mathrm{VE} = 0.40$ and $\\theta_{1} = \\ln(0.40)$. The primary analysis uses a one-sided Wald test of $H_{0}:\\theta \\ge 0$ versus $H_{1}:\\theta < 0$, with one-sided type I error $\\alpha = 0.025$ and desired power $0.90$ at $\\theta_{1}$. Assume equal allocation with $n$ participants per arm at the final analysis. Assume standard large-sample theory applies: by the Central Limit Theorem and the delta method, $\\hat{\\theta}$ is approximately normal with mean $\\theta$ and variance $\\mathrm{Var}(\\hat{\\theta}) \\approx \\frac{1-p_{V}}{n\\,p_{V}} + \\frac{1-p_{C}}{n\\,p_{C}}$, and the Wald statistic $T = \\hat{\\theta}/\\sqrt{\\mathrm{Var}(\\hat{\\theta})}$ is approximately standard normal under $H_{0}$.\n\nAn unblinded Data Monitoring Committee (DMC) performs a single interim nuisance-parameter check for sample size re-estimation only (no early stopping), using only the control-arm attack rate to update $\\mathrm{Var}(\\hat{\\theta})$. Initially, the design assumed $p_{C}^{(0)} = 0.60$. At the interim, the DMC estimates $p_{C} = 0.45$. The adaptation rule is to update the final per-arm sample size $n$ so that the unconditional power remains $0.90$ at the same design alternative $\\theta_{1} = \\ln(0.40)$, using the updated nuisance values $p_{C} = 0.45$ and $p_{V} = (1-\\mathrm{VE})\\,p_{C}$, with $\\mathrm{VE} = 0.60$. Assume no continuity correction and no finite-sample adjustments.\n\nUsing only the fundamentals stated above, and treating the interim update as affecting only the variance through the revised $(p_{C}, p_{V})$, compute the minimal integer total number of participants per arm $n^{\\star}$ required to achieve power $0.90$ at one-sided $\\alpha = 0.025$ under the updated nuisance values. Report the single integer $n^{\\star}$ as the number of participants per arm. Do not include any unit in your final boxed answer. If any rounding is needed during intermediate steps, carry sufficient precision to ensure the final integer is correct without reliance on rounding rules based on significant figures.", "solution": "The problem is subjected to validation before a solution is attempted.\n\nGivens are extracted verbatim from the problem statement:\n- Study Design: A two-arm randomized Controlled Human Infection Model (CHIM) study.\n- Randomization: $1:1$ to vaccine or placebo.\n- Sample Size: $n$ participants per arm.\n- Primary Endpoint: Infection status (coded $1$ for infected, $0$ for not infected) within $7$ days.\n- Parameters: $p_{C}$ is the infection probability in the placebo (control) arm; $p_{V}$ is the infection probability in the vaccine arm.\n- Estimand: $\\theta = \\ln(p_{V}/p_{C})$.\n- Hypotheses: One-sided Wald test of $H_{0}: \\theta \\ge 0$ versus $H_{1}: \\theta < 0$.\n- Type I Error: $\\alpha = 0.025$ (one-sided).\n- Desired Power: $0.90$.\n- Design Alternative: Vaccine Efficacy (VE) of $0.60$, corresponding to a risk ratio $RR = 1 - \\mathrm{VE} = 0.40$, so $\\theta_{1} = \\ln(0.40)$.\n- Statistical Approximations: $\\hat{\\theta}$ is approximately normal with mean $\\theta$ and variance $\\mathrm{Var}(\\hat{\\theta}) \\approx \\frac{1-p_{V}}{n p_{V}} + \\frac{1-p_{C}}{n p_{C}}$. The Wald statistic $T = \\hat{\\theta}/\\sqrt{\\mathrm{Var}(\\hat{\\theta})}$ is approximately standard normal under $H_{0}$.\n- Adaptation Plan: A single interim check to re-estimate sample size based on the control-arm attack rate.\n- Initial Assumption for $p_C$: $p_{C}^{(0)} = 0.60$.\n- Interim Estimate for $p_C$: $p_{C} = 0.45$.\n- Adaptation Rule: Update the per-arm sample size $n$ to maintain power of $0.90$ at $\\theta_{1} = \\ln(0.40)$, using updated nuisance parameters $p_{C} = 0.45$ and $p_{V} = (1 - \\mathrm{VE})p_{C} = 0.40 \\times 0.45$.\n- Constraints: No continuity correction, no finite-sample adjustments.\n- Objective: Compute the minimal integer number of participants per arm, $n^{\\star}$.\n\nValidation Verdict:\nThe problem is scientifically grounded, well-posed, and objective. It describes a standard sample size re-estimation procedure in a clinical trial context using established statistical theory (Wald test, delta method). All necessary parameters for the calculation ($\\alpha$, power, effect size, nuisance parameters) are provided. The problem does not violate any principles of mathematics or scientific realism and is free of ambiguity or contradiction. It is therefore deemed a valid problem.\n\nSolution:\nThe objective is to find the required sample size per arm, $n$, to achieve a statistical power of $1-\\beta = 0.90$ for a one-sided test of the hypothesis $H_{0}: \\theta \\ge 0$ versus $H_{1}: \\theta < 0$ at a significance level of $\\alpha = 0.025$. The alternative hypothesis corresponds to an effect size of $\\theta_1 = \\ln(0.40)$.\n\nThe Wald test described in the problem rejects the null hypothesis $H_0$ if the test statistic is smaller than a critical value from the standard normal distribution. For a one-sided test at significance level $\\alpha$, the rejection region is $T < z_{\\alpha}$, where $z_{\\alpha}$ is the $\\alpha$-quantile of the standard normal distribution. Since $\\hat{\\theta}$ is asymptotically normal with mean $\\theta$ and variance $V = \\mathrm{Var}(\\hat{\\theta})$, the test statistic under the alternative hypothesis $\\theta = \\theta_1$ is such that $\\frac{\\hat{\\theta} - \\theta_1}{\\sqrt{V}}$ is approximately a standard normal variate.\n\nThe power of the test is the probability of rejecting $H_0$ when $H_1$ is true:\n$$ \\text{Power} = P(\\text{Reject } H_0 | \\theta = \\theta_1) = P(T < z_{\\alpha} | \\theta = \\theta_1) = 1 - \\beta $$\nFor sample size planning, the denominator of the test statistic $T$ is taken to be the true variance under the alternative, $V_1 = \\mathrm{Var}(\\hat{\\theta})|_{\\theta=\\theta_1}$.\n$$ P\\left(\\frac{\\hat{\\theta}}{\\sqrt{V_1}} < z_{\\alpha} \\bigg| \\theta = \\theta_1\\right) = 1-\\beta $$\nWe standardize the random variable $\\hat{\\theta}$ by subtracting its mean $\\theta_1$ and dividing by its standard deviation $\\sqrt{V_1}$:\n$$ P\\left(\\frac{\\hat{\\theta} - \\theta_1}{\\sqrt{V_1}} < z_{\\alpha} - \\frac{\\theta_1}{\\sqrt{V_1}} \\right) = 1 - \\beta $$\nThe term on the left inside the probability is a standard normal variate, which we denote as $Z$. Thus, we have $P(Z < z_{\\alpha} - \\frac{\\theta_1}{\\sqrt{V_1}}) = 1-\\beta$. This implies that the argument must be equal to the $(1-\\beta)$-quantile of the standard normal distribution, $z_{1-\\beta}$:\n$$ z_{\\alpha} - \\frac{\\theta_1}{\\sqrt{V_1}} = z_{1-\\beta} $$\nThe quantiles are related by symmetry: $z_{\\alpha} = -z_{1-\\alpha}$. Substituting this into the equation gives:\n$$ -z_{1-\\alpha} - \\frac{\\theta_1}{\\sqrt{V_1}} = z_{1-\\beta} $$\nSolving for $\\sqrt{V_1}$:\n$$ -\\frac{\\theta_1}{\\sqrt{V_1}} = z_{1-\\alpha} + z_{1-\\beta} $$\nSince $\\theta_1 < 0$, both sides of the equation are positive. We can now solve for $V_1$:\n$$ V_1 = \\left( \\frac{-\\theta_1}{z_{1-\\alpha} + z_{1-\\beta}} \\right)^2 = \\frac{\\theta_1^2}{(z_{1-\\alpha} + z_{1-\\beta})^2} $$\nThe problem states the variance formula for $\\hat{\\theta}$ is:\n$$ \\mathrm{Var}(\\hat{\\theta}) = \\frac{1}{n}\\left(\\frac{1-p_V}{p_V} + \\frac{1-p_C}{p_C}\\right) $$\nWe set this equal to $V_1$ and solve for the sample size per arm, $n$:\n$$ \\frac{1}{n}\\left(\\frac{1-p_V}{p_V} + \\frac{1-p_C}{p_C}\\right) = \\frac{\\theta_1^2}{(z_{1-\\alpha} + z_{1-\\beta})^2} $$\n$$ n = \\frac{(z_{1-\\alpha} + z_{1-\\beta})^2}{\\theta_1^2} \\left(\\frac{1-p_V}{p_V} + \\frac{1-p_C}{p_C}\\right) $$\nThis is the required formula for the sample size per arm. We now substitute the post-interim values to calculate the re-estimated sample size, $n^{\\star}$.\n\nThe specified parameters are:\n- One-sided $\\alpha = 0.025$, so $z_{1-\\alpha} = z_{0.975}$.\n- Power $1-\\beta = 0.90$, so $z_{1-\\beta} = z_{0.90}$.\n- The standard normal quantiles are $z_{0.975} \\approx 1.95996$ and $z_{0.90} \\approx 1.28155$.\n- The effect size under the alternative is $\\theta_{1} = \\ln(0.40) \\approx -0.91629$.\n- The updated nuisance parameters are $p_C = 0.45$.\n- With $\\mathrm{VE} = 0.60$, the risk ratio is $RR = 1 - 0.60 = 0.40$.\n- The updated vaccine arm probability is $p_V = RR \\times p_C = 0.40 \\times 0.45 = 0.18$.\n\nWe now compute the terms needed for the sample size formula:\n- The sum of Z-scores: $z_{1-\\alpha} + z_{1-\\beta} \\approx 1.95996 + 1.28155 = 3.24151$.\n- The squared sum of Z-scores: $(3.24151)^2 \\approx 10.5074$.\n- The squared effect size: $\\theta_1^2 = (\\ln(0.40))^2 \\approx (-0.91629)^2 \\approx 0.83959$.\n- The variance component related to proportions:\n$$ \\frac{1-p_V}{p_V} + \\frac{1-p_C}{p_C} = \\frac{1-0.18}{0.18} + \\frac{1-0.45}{0.45} = \\frac{0.82}{0.18} + \\frac{0.55}{0.45} = \\frac{41}{9} + \\frac{11}{9} = \\frac{52}{9} $$\nThe fraction $\\frac{52}{9}$ is approximately $5.777...$.\n\nSubstitute these values into the sample size formula for $n^{\\star}$:\n$$ n^{\\star} = \\frac{(1.95996 + 1.28155)^2}{(\\ln(0.40))^2} \\left( \\frac{52}{9} \\right) \\approx \\frac{10.5074}{0.83959} \\times 5.777... $$\n$$ n^{\\star} \\approx 12.51496 \\times 5.777... \\approx 72.3023 $$\nSince the number of participants must be an integer, and the calculated value is the minimum required to achieve the specified power, we must take the ceiling of this result.\n$$ n^{\\star} = \\lceil 72.3023 \\rceil = 73 $$\nThe minimal integer number of participants required per arm is $73$.", "answer": "$$\\boxed{73}$$", "id": "2854507"}, {"introduction": "The ethical conduct of CHIMs hinges on rigorous safety monitoring, where every adverse event is carefully evaluated. A key question for any safety board is determining the likelihood that an observed adverse event was actually caused by the challenge agent versus being a coincidental background event. This practice [@problem_id:2854504] delves into the statistical framework of competing risks, using time-dependent hazard functions to model and quantify the probability of causation, a core skill for making principled safety decisions during a trial.", "problem": "A Controlled Human Infection Model (CHIM) trial of an attenuated influenza virus in healthy adults conducts continuous safety monitoring for febrile adverse events. For causality assessment, the study assumes two independent mechanisms that can generate a first febrile adverse event after challenge at time $t$ (in hours): a challenge-related process with a time-varying hazard $h_{c}(t)$ and a background process with a constant hazard $h_{b}(t)$. The study defines causality using the following principles: (i) by the definition of the hazard function, given no event before time $t$, the probability of an event in the next infinitesimal interval $[t,t+\\mathrm{d}t)$ is $h(t)\\,\\mathrm{d}t$, and (ii) if two independent risk processes are active, the instantaneous probability that the next event at time $t$ arises from a given cause is proportional to its cause-specific hazard at time $t$. The background hazard is modeled as a homogeneous Poisson process with constant rate $h_{b}(t)=\\lambda_{b}$, and the challenge-related hazard is modeled as $h_{c}(t)=\\beta \\exp(-\\alpha t)$, where $\\alpha>0$ and $\\beta>0$. The Data and Safety Monitoring Board (DSMB) defines the window-of-attribution threshold as the set of times $t$ for which the posterior probability that an event observed at time $t$ is caused by the challenge agent is at least $q$, with $0<q<1$.\n\nStarting only from the above fundamental definitions and assumptions, and without invoking any unprovided shortcut formulas, derive a closed-form expression for the latest time $t^{\\ast}$ (in hours) such that any first febrile adverse event observed at or before $t^{\\ast}$ would have posterior probability of challenge-related causation at least $q$. Then, evaluate $t^{\\ast}$ for the parameter values $\\alpha=0.05~\\mathrm{h}^{-1}$, $\\beta=0.05~\\mathrm{h}^{-1}$, $\\lambda_{b}=0.0005~\\mathrm{h}^{-1}$, and $q=0.9$. Round your final numerical answer to four significant figures and express it in hours.", "solution": "The problem requires the derivation of a time threshold, $t^{\\ast}$, for causality assessment in a Controlled Human Infection Model. The problem statement itself must first be subjected to rigorous validation.\n\nStep 1: Extraction of Givens.\n- Time to first event: $t$ (hours).\n- Challenge-related hazard: $h_{c}(t) = \\beta \\exp(-\\alpha t)$, with $\\alpha > 0$ and $\\beta > 0$.\n- Background hazard: $h_{b}(t) = \\lambda_{b}$, a constant rate.\n- The two processes are independent.\n- The total hazard for an event at time $t$ is $h(t)$.\n- The infinitesimal probability of an event in $[t, t+\\mathrm{d}t)$, given survival until $t$, is $h(t)\\,\\mathrm{d}t$.\n- The instantaneous probability of causation by a specific process at time $t$ is proportional to its cause-specific hazard at that time.\n- The posterior probability threshold for challenge-related causation is $q$, where $0 < q < 1$.\n- The goal is to find the latest time $t^{\\ast}$ such that for any event observed at time $t \\le t^{\\ast}$, the posterior probability of challenge-related causation is at least $q$.\n- Parameter values for evaluation: $\\alpha = 0.05~\\mathrm{h}^{-1}$, $\\beta = 0.05~\\mathrm{h}^{-1}$, $\\lambda_{b} = 0.0005~\\mathrm{h}^{-1}$, and $q = 0.9$.\n\nStep 2: Validation.\nThe problem is scientifically grounded, employing standard principles of competing risks analysis from survival theory, a branch of statistics. The models for hazard functions are common and well-defined. The problem is well-posed, providing all necessary definitions and parameters to derive a unique solution. The language is objective and precise. No violations of scientific principles, logical contradictions, or ambiguities are present. The problem is therefore deemed valid and a solution may be pursued.\n\nStep 3: Derivation of the Solution.\nLet $T$ be the random variable for the time to the first febrile event. Let $C$ be a random variable indicating the cause of the event, with $C=c$ for a challenge-related cause and $C=b$ for a background cause.\n\nThe total hazard rate, $h(t)$, is the sum of the independent cause-specific hazard rates, as the processes are independent.\n$$ h(t) = h_{c}(t) + h_{b}(t) $$\nThe problem asks for the posterior probability that an event observed at time $t$ is caused by the challenge agent. This is the conditional probability $P(C=c | T=t)$. According to the provided principle (ii), this probability is proportional to the cause-specific hazard $h_c(t)$. Let us formalize this.\nThe probability of an event from any cause occurring in the infinitesimal interval $[t, t+\\mathrm{d}t)$, given survival up to time $t$, is $h(t)\\,\\mathrm{d}t$.\nThe probability of an event specifically caused by the challenge agent in the same interval is $h_c(t)\\,\\mathrm{d}t$.\nThe probability of an event specifically caused by the background process in the same interval is $h_b(t)\\,\\mathrm{d}t$.\n\nThe posterior probability of challenge-related causation, which we shall denote as $\\pi_{c}(t)$, given that an event occurred at time $t$, is the ratio of the rate of challenge-caused events to the rate of total events at that instant.\n$$ \\pi_{c}(t) = \\frac{P(\\text{event in } [t, t+\\mathrm{d}t) \\text{ is from cause } c)}{P(\\text{event in } [t, t+\\mathrm{d}t) \\text{ from any cause})} = \\frac{h_{c}(t)\\,\\mathrm{d}t}{h(t)\\,\\mathrm{d}t} = \\frac{h_{c}(t)}{h_{c}(t) + h_{b}(t)} $$\nSubstituting the given functional forms for the hazard rates:\n$$ \\pi_{c}(t) = \\frac{\\beta \\exp(-\\alpha t)}{\\beta \\exp(-\\alpha t) + \\lambda_{b}} $$\nThe Data and Safety Monitoring Board (DSMB) requires this probability to be at least $q$. This gives the inequality:\n$$ \\frac{\\beta \\exp(-\\alpha t)}{\\beta \\exp(-\\alpha t) + \\lambda_{b}} \\ge q $$\nWe must solve this inequality for $t$. Since all parameters $\\alpha, \\beta, \\lambda_b$ are positive, and the exponential function is positive, the denominator is always positive. We can multiply both sides by the denominator without altering the direction of the inequality.\n$$ \\beta \\exp(-\\alpha t) \\ge q (\\beta \\exp(-\\alpha t) + \\lambda_{b}) $$\n$$ \\beta \\exp(-\\alpha t) \\ge q \\beta \\exp(-\\alpha t) + q \\lambda_{b} $$\nGroup the terms containing $\\exp(-\\alpha t)$:\n$$ \\beta \\exp(-\\alpha t) - q \\beta \\exp(-\\alpha t) \\ge q \\lambda_{b} $$\n$$ (1-q) \\beta \\exp(-\\alpha t) \\ge q \\lambda_{b} $$\nGiven that $0 < q < 1$, the term $(1-q)$ is positive. The parameter $\\beta$ is also positive. We can therefore divide by $(1-q)\\beta$.\n$$ \\exp(-\\alpha t) \\ge \\frac{q \\lambda_{b}}{(1-q)\\beta} $$\nTo solve for $t$, we apply the natural logarithm, which is a monotonically increasing function, to both sides. This preserves the inequality. The argument of the logarithm is positive as all constituent parameters are positive.\n$$ \\ln(\\exp(-\\alpha t)) \\ge \\ln\\left(\\frac{q \\lambda_{b}}{(1-q)\\beta}\\right) $$\n$$ -\\alpha t \\ge \\ln\\left(\\frac{q \\lambda_{b}}{(1-q)\\beta}\\right) $$\nFinally, we divide by $-\\alpha$. Since $\\alpha > 0$, $-\\alpha$ is negative, which requires reversing the direction of the inequality.\n$$ t \\le -\\frac{1}{\\alpha} \\ln\\left(\\frac{q \\lambda_{b}}{(1-q)\\beta}\\right) $$\nUsing the property $\\ln(1/x) = -\\ln(x)$, this can be written more cleanly as:\n$$ t \\le \\frac{1}{\\alpha} \\ln\\left(\\frac{(1-q)\\beta}{q \\lambda_{b}}\\right) $$\nThis inequality defines the window of time for which the condition is met. The latest time, $t^{\\ast}$, is the maximum value of $t$ that satisfies this condition.\n$$ t^{\\ast} = \\frac{1}{\\alpha} \\ln\\left(\\frac{(1-q)\\beta}{q \\lambda_{b}}\\right) $$\nThis is the required closed-form expression for $t^{\\ast}$.\n\nNow, we evaluate $t^{\\ast}$ using the provided numerical values:\n$\\alpha = 0.05~\\mathrm{h}^{-1}$\n$\\beta = 0.05~\\mathrm{h}^{-1}$\n$\\lambda_{b} = 0.0005~\\mathrm{h}^{-1}$\n$q = 0.9$\n\nFirst, compute the argument of the logarithm:\n$$ \\frac{(1-q)\\beta}{q \\lambda_{b}} = \\frac{(1 - 0.9) \\times 0.05}{0.9 \\times 0.0005} = \\frac{0.1 \\times 0.05}{0.00045} = \\frac{0.005}{0.00045} = \\frac{50}{4.5} = \\frac{100}{9} $$\nSubstitute this into the expression for $t^{\\ast}$:\n$$ t^{\\ast} = \\frac{1}{0.05} \\ln\\left(\\frac{100}{9}\\right) $$\n$$ t^{\\ast} = 20 \\times \\ln\\left(\\frac{100}{9}\\right) $$\nCalculating the numerical value:\n$$ \\ln\\left(\\frac{100}{9}\\right) \\approx 2.4079456 $$\n$$ t^{\\ast} \\approx 20 \\times 2.4079456 \\approx 48.158912~\\mathrm{h} $$\nThe problem requires the answer to be rounded to four significant figures.\n$$ t^{\\ast} \\approx 48.16~\\mathrm{h} $$\nThis is the latest time in hours at which a first febrile event can be observed and still have a posterior probability of being challenge-related of at least $90\\%$.", "answer": "$$\\boxed{48.16}$$", "id": "2854504"}, {"introduction": "The interpretation of a trial’s outcome depends critically on a clear and accurate definition of the primary endpoint, such as \"confirmed infection.\" Because no single diagnostic test is perfect, robust studies often use a composite endpoint that combines evidence from multiple assays, for example, virological swabs and serological tests. This problem [@problem_id:2854508] provides hands-on practice in applying Bayesian principles to assess the performance of such an endpoint by calculating its positive predictive value, which quantifies our confidence in a true infection given a positive test result.", "problem": "In a human influenza challenge model, the primary endpoint for “confirmed infection” is defined as follows. A volunteer is classified as endpoint-positive if either (i) there are at least two consecutive positive Reverse Transcriptase quantitative Polymerase Chain Reaction (RT-qPCR) nasopharyngeal swabs among exactly three scheduled swabs on days $2$, $3$, and $4$ post-challenge, or (ii) there is seroconversion by day $28$ defined as a fourfold or greater rise in Hemagglutination Inhibition (HAI) antibody titer from baseline. Assume that, conditional on a volunteer’s latent true infection status, all assay outcomes are independent both across time for RT-qPCR and across assay modalities (RT-qPCR versus HAI). The per-swab RT-qPCR sensitivity given true infection is $s_{\\mathrm{PCR}} = 0.90$ and its specificity given no infection is $\\mathrm{sp}_{\\mathrm{PCR}} = 0.995$. The HAI serology sensitivity given true infection is $s_{\\mathrm{HAI}} = 0.95$ and its specificity given no infection is $\\mathrm{sp}_{\\mathrm{HAI}} = 0.99$. The probability that a randomly selected challenged volunteer truly becomes infected (the attack rate) is $p = 0.65$.\n\nUsing only foundational definitions of sensitivity, specificity, conditional independence, and the law of total probability, derive the posterior probability that a volunteer with this composite endpoint positive classification is truly infected. Express the final probability as a decimal and round your answer to six significant figures.", "solution": "Let $I$ be the event that a volunteer is truly infected and $I^c$ be the event of no true infection. Let $E$ be the event that the composite endpoint is positive. The problem requires the calculation of the posterior probability $P(I|E)$, which is the probability of a true infection given a positive composite endpoint.\n\nThe provided prior probability of infection (attack rate) is $P(I) = p = 0.65$. The probability of no infection is therefore $P(I^c) = 1 - p = 1 - 0.65 = 0.35$.\n\nThe composite endpoint $E$ is positive if either of two criteria is met. Let $C_1$ be the event corresponding to the RT-qPCR criterion (at least two consecutive positive swabs) and $C_2$ be the event corresponding to the HAI serology criterion (seroconversion). The event $E$ is the union of these two events: $E = C_1 \\cup C_2$.\n\nAccording to Bayes' theorem, the posterior probability is:\n$$ P(I | E) = \\frac{P(E \\cap I)}{P(E)} = \\frac{P(E|I)P(I)}{P(E)} $$\nThe denominator, $P(E)$, can be expanded using the law of total probability:\n$$ P(E) = P(E|I)P(I) + P(E|I^c)P(I^c) $$\nSubstituting this into the Bayes' formula, we obtain:\n$$ P(I | E) = \\frac{P(E|I)P(I)}{P(E|I)P(I) + P(E|I^c)P(I^c)} $$\nThis is the expression for the Positive Predictive Value (PPV) of the composite endpoint. To find its value, we must first compute the conditional probabilities $P(E|I)$ and $P(E|I^c)$.\n\nThe problem states that conditional on the true infection status, all assay outcomes are independent. This implies that the events $C_1$ and $C_2$ are conditionally independent given $I$, and also given $I^c$. Using the inclusion-exclusion principle for probabilities:\n$$ P(E|I) = P(C_1 \\cup C_2 | I) = P(C_1|I) + P(C_2|I) - P(C_1 \\cap C_2 | I) $$\nBy conditional independence, $P(C_1 \\cap C_2 | I) = P(C_1|I)P(C_2|I)$, so:\n$$ P(E|I) = P(C_1|I) + P(C_2|I) - P(C_1|I)P(C_2|I) $$\nA similar expression holds for the no-infection case:\n$$ P(E|I^c) = P(C_1|I^c) + P(C_2|I^c) - P(C_1|I^c)P(C_2|I^c) $$\n\nThe performance characteristics of the HAI assay are given directly:\nThe sensitivity is $P(C_2|I) = s_{\\mathrm{HAI}} = 0.95$.\nThe specificity is $\\mathrm{sp}_{\\mathrm{HAI}} = 0.99$, which implies the probability of a positive HAI test given no infection is $P(C_2|I^c) = 1 - \\mathrm{sp}_{\\mathrm{HAI}} = 1 - 0.99 = 0.01$.\n\nNext, we must calculate the probabilities for the RT-qPCR criterion, $P(C_1|I)$ and $P(C_1|I^c)$.\nCriterion $C_1$ requires at least two consecutive positive RT-qPCR swabs among three swabs. Let $S^+$ denote a positive result and $S^-$ denote a negative result for a single swab. The sequences of three swabs that satisfy $C_1$ are $\\{S^+, S^+, S^-\\}$, $\\{S^-, S^+, S^+\\}$, and $\\{S^+, S^+, S^+\\}$. These are disjoint events.\n\nWe first calculate $P(C_1|I)$. The sensitivity of a single RT-qPCR swab is $P(S^+|I) = s_{\\mathrm{PCR}} = 0.90$. Thus, $P(S^-|I) = 1 - s_{\\mathrm{PCR}} = 0.10$. Given the conditional independence of swabs:\n$$ P(\\{S^+, S^+, S^-\\}|I) = P(S^+|I)P(S^+|I)P(S^-|I) = (0.90)^2(0.10) = 0.081 $$\n$$ P(\\{S^-, S^+, S^+\\}|I) = P(S^-|I)P(S^+|I)P(S^+|I) = (0.10)(0.90)^2 = 0.081 $$\n$$ P(\\{S^+, S^+, S^+\\}|I) = P(S^+|I)P(S^+|I)P(S^+|I) = (0.90)^3 = 0.729 $$\nSumming the probabilities of these disjoint events gives $P(C_1|I)$:\n$$ P(C_1|I) = 0.081 + 0.081 + 0.729 = 0.891 $$\n\nNext, we calculate $P(C_1|I^c)$. The specificity of a single swab is $\\mathrm{sp}_{\\mathrm{PCR}} = 0.995$. The probability of a false positive is $P(S^+|I^c) = 1 - \\mathrm{sp}_{\\mathrm{PCR}} = 1 - 0.995 = 0.005$. The probability of a true negative is $P(S^-|I^c) = \\mathrm{sp}_{\\mathrm{PCR}} = 0.995$.\n$$ P(\\{S^+, S^+, S^-\\}|I^c) = (0.005)^2(0.995) = (0.000025)(0.995) = 0.000024875 $$\n$$ P(\\{S^-, S^+, S^+\\}|I^c) = (0.995)(0.005)^2 = (0.995)(0.000025) = 0.000024875 $$\n$$ P(\\{S^+, S^+, S^+\\}|I^c) = (0.005)^3 = 0.000000125 $$\nSumming these probabilities gives $P(C_1|I^c)$:\n$$ P(C_1|I^c) = 0.000024875 + 0.000024875 + 0.000000125 = 0.000049875 $$\n\nWith these intermediate results, we can compute the overall sensitivity $P(E|I)$ and the probability of a false positive $P(E|I^c)$ for the composite endpoint.\n$$ P(E|I) = P(C_1|I) + P(C_2|I) - P(C_1|I)P(C_2|I) = 0.891 + 0.95 - (0.891)(0.95) $$\n$$ P(E|I) = 1.841 - 0.84645 = 0.99455 $$\n$$ P(E|I^c) = P(C_1|I^c) + P(C_2|I^c) - P(C_1|I^c)P(C_2|I^c) $$\n$$ P(E|I^c) = 0.000049875 + 0.01 - (0.000049875)(0.01) $$\n$$ P(E|I^c) = 0.010049875 - 0.00000049875 = 0.01004937625 $$\n\nFinally, we substitute these values into the expression for $P(I|E)$:\nThe term for true positives in the population is:\n$$ P(E|I)P(I) = (0.99455)(0.65) = 0.6464575 $$\nThe term for false positives in the population is:\n$$ P(E|I^c)P(I^c) = (0.01004937625)(0.35) = 0.0035172816875 $$\nThe total probability of a positive endpoint is the sum of these two terms:\n$$ P(E) = 0.6464575 + 0.0035172816875 = 0.6499747816875 $$\nThe posterior probability is the ratio of the true positive term to the total probability:\n$$ P(I | E) = \\frac{0.6464575}{0.6499747816875} \\approx 0.99458857002 $$\nRounding the result to six significant figures yields $0.994589$.", "answer": "$$\\boxed{0.994589}$$", "id": "2854508"}]}