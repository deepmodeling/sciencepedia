{"hands_on_practices": [{"introduction": "Understanding a signaling pathway often involves dissecting the function of its individual components, and a powerful experimental strategy is the use of dominant-negative mutants, which competitively inhibit the function of the wild-type protein. This exercise [@problem_id:2277393] challenges you to apply this concept to the Jak-STAT pathway, reasoning through the molecular consequences of expressing a STAT5 protein that can dimerize but cannot bind DNA. This practice is invaluable for developing a mechanistic intuition for how protein structure dictates function and how specific mutations can be used to probe complex cellular systems.", "problem": "In a laboratory study of erythropoiesis (the production of red blood cells), researchers are using an erythroid progenitor cell line that relies on the hormone erythropoietin (Epo) for survival and differentiation. The signaling cascade initiated by Epo is critical for this process and proceeds through the following well-established pathway:\n\n1.  Epo binds to the Epo receptor on the cell surface, causing the receptor to dimerize.\n2.  This dimerization activates the associated Janus Kinase 2 (JAK2).\n3.  Active JAK2 phosphorylates specific tyrosine residues on the intracellular domain of the Epo receptor.\n4.  A protein called Signal Transducer and Activator of Transcription 5 (STAT5), which contains a Src Homology 2 (SH2) domain and a DNA-Binding Domain (DBD), is recruited to the phosphorylated receptor by binding via its SH2 domain.\n5.  The recruited STAT5 is then phosphorylated by JAK2.\n6.  Phosphorylated STAT5 proteins dissociate from the receptor and form homodimers (STAT5-STAT5) through interactions between their respective SH2 domains and phosphorylated tyrosine residues.\n7.  These functional dimers translocate to the nucleus, where they bind to specific DNA sequences via their DBDs to activate the transcription of target genes, such as the anti-apoptotic gene *Bcl-xL*, which promotes cell survival.\n\nThe researchers transfect these cells to cause high-level expression of a mutant STAT5 protein, which we will call STAT5-DN. This mutant protein has a fully functional SH2 domain but completely lacks its DNA-Binding Domain (DBD). The endogenous, wild-type STAT5 is still present in the cells. When these transfected cells are stimulated with Epo, the researchers observe a significant reduction in the transcription of the *Bcl-xL* gene compared to non-transfected cells.\n\nWhich of the following statements provides the most accurate molecular explanation for this observed dominant-negative inhibition of Epo-induced gene transcription?\n\nA. The STAT5-DN mutant protein binds permanently to the Epo receptor, preventing the binding and phosphorylation of wild-type STAT5.\n\nB. The STAT5-DN mutant protein dimerizes with itself in the cytoplasm and sequesters the JAK2 kinase, preventing it from associating with the Epo receptor.\n\nC. The STAT5-DN mutant protein cannot bind to DNA, but it is still phosphorylated and forms non-functional heterodimers with wild-type STAT5, preventing the wild-type protein from binding to target gene promoters.\n\nD. The STAT5-DN mutant protein lacks a DNA-binding domain, which also prevents its phosphorylation by JAK2, causing it to accumulate in an inactive state and block the pathway through steric hindrance.\n\nE. The STAT5-DN mutant protein enters the nucleus and binds to an inhibitory co-factor, which then actively represses the transcription of all STAT5 target genes.", "solution": "The Epo signaling pathway requires sequential steps: Epo-induced receptor dimerization activates JAK2, which phosphorylates tyrosines on the Epo receptor. STAT5 is recruited via its SH2 domain to these phosphotyrosines, then phosphorylated by JAK2. Phosphorylated STAT5 forms dimers through SH2–phosphotyrosine interactions, translocates to the nucleus, and binds DNA through its DNA-binding domain (DBD) to drive transcription of target genes such as Bcl-xL.\n\nThe mutant STAT5-DN retains an intact SH2 domain but lacks the DBD. Therefore:\n1. Recruitment: Because the SH2 domain is intact, STAT5-DN can still bind phosphorylated receptor sites, compete with endogenous STAT5 for recruitment, and be phosphorylated by JAK2. Lack of a DBD does not impair JAK2 recognition or phosphorylation, which occur on other STAT5 residues.\n2. Dimerization: Once phosphorylated, STAT5-DN can dimerize via the canonical SH2–phosphotyrosine-mediated interface. It can form both homodimers (STAT5-DN:STAT5-DN) and heterodimers with wild-type STAT5 (STAT5-DN:STAT5-WT).\n3. Nuclear function: DNA binding by STAT dimers requires proper engagement of both monomers with their respective half-sites in GAS elements; loss of the DBD in one partner disrupts stable, sequence-specific binding and transcriptional activation. Thus, heterodimers containing STAT5-DN are non-functional on DNA, and homodimers of STAT5-DN are also non-functional. As a result, STAT5-DN acts in a dominant-negative manner by sequestering wild-type STAT5 into non-productive dimers and reducing the pool of functional STAT5-WT homodimers competent for promoter binding and transcriptional activation.\n4. This mechanism directly explains the reduced Epo-induced Bcl-xL transcription observed despite the presence of endogenous STAT5.\n\nEvaluating the options:\n- A is incorrect because STAT5 binding to receptor phosphotyrosines via SH2 is transient; phosphorylation triggers dissociation and dimerization rather than permanent receptor occupancy.\n- B is incorrect because STAT5 does not sequester JAK2 in the cytoplasm; JAK2 is receptor-associated, and STAT5 dimerization is phosphorylation-dependent at the receptor.\n- C is correct: STAT5-DN is phosphorylated, forms non-functional heterodimers with wild-type STAT5, and prevents wild-type STAT5 from binding target promoters, yielding dominant-negative inhibition.\n- D is incorrect because loss of the DBD does not prevent phosphorylation by JAK2.\n- E is incorrect because STAT5-DN lacks a DBD and would not specifically bind DNA to recruit repressors to all STAT5 targets; there is no evidence for universal active repression by such a mutant.\n\nThus, the most accurate explanation is formation of non-functional heterodimers that block wild-type STAT5 DNA binding and transcriptional activation.", "answer": "$$\\boxed{C}$$", "id": "2277393"}, {"introduction": "Beyond conceptual models, a quantitative understanding of pathway dynamics is essential for fields like pharmacology and drug design. This problem [@problem_id:2950344] transitions from qualitative reasoning to quantitative analysis by focusing on the kinetics of JAK kinase inhibition. By applying the principles of competitive inhibition and Michaelis-Menten kinetics, you will calculate the concentration of an inhibitor required to achieve a specific level of pathway suppression, connecting the intrinsic potency of a drug ($K_i$) to its effective performance in a biologically relevant context with competing substrates like ATP.", "problem": "A reconstituted Janus kinase–Signal Transducer and Activator of Transcription (JAK–STAT) signaling module is studied under steady-state initial-rate conditions. A Janus kinase (JAK) phosphorylates Signal Transducer and Activator of Transcription (STAT) using adenosine triphosphate (ATP) as the cosubstrate at a fixed ATP concentration. An ATP-competitive small-molecule inhibitor is introduced. Assume classical Michaelis–Menten kinetics for the JAK catalytic step and classical competitive inhibition with inhibition constant $K_i$ defined for competition with ATP. The $K_m$ of JAK for ATP is $50\\,\\mu\\mathrm{M}$, the ATP concentration is fixed at $1\\,\\mathrm{mM}$, and the inhibitor has $K_i=5\\,\\mathrm{nM}$. Define $IC_{90}$ as the inhibitor concentration that reduces the initial phosphorylation rate to $0.1$ times the uninhibited rate at the same ATP concentration. Starting from the definitions of Michaelis–Menten kinetics and competitive inhibition, derive the analytic expression for the inhibitor concentration that achieves this fractional rate and then compute the numerical value of $IC_{90}$ for these conditions. Express the final concentration in $\\mathrm{nM}$ and round your answer to three significant figures.", "solution": "The catalytic phosphorylation of Signal Transducer and Activator of Transcription (STAT) by Janus kinase (JAK) using adenosine triphosphate (ATP) as cosubstrate is modeled by the Michaelis–Menten equation for the ATP-dependent step. Let $[S]$ denote the ATP concentration, $K_m$ the Michaelis constant for ATP, $V_{\\max}$ the maximal velocity, and $v_0$ the uninhibited initial rate at ATP concentration $[S]$. The classical Michaelis–Menten form is\n$$\nv_0 \\;=\\; \\frac{V_{\\max}\\,[S]}{K_m + [S]}.\n$$\nFor a competitive inhibitor with respect to ATP, with inhibition constant $K_i$ and inhibitor concentration $[I]$, the presence of the inhibitor increases the apparent Michaelis constant by a factor $\\alpha$, where\n$$\n\\alpha \\;=\\; 1 + \\frac{[I]}{K_i}.\n$$\nUnder competitive inhibition, the initial rate $v$ at the same ATP concentration $[S]$ becomes\n$$\nv \\;=\\; \\frac{V_{\\max}\\,[S]}{\\alpha K_m + [S]}.\n$$\nDefine the fractional activity $r$ as the ratio of inhibited to uninhibited rates at the same $[S]$:\n$$\nr \\;\\equiv\\; \\frac{v}{v_0} \\;=\\; \\frac{\\dfrac{V_{\\max}\\,[S]}{\\alpha K_m + [S]}}{\\dfrac{V_{\\max}\\,[S]}{K_m + [S]}} \\;=\\; \\frac{K_m + [S]}{\\alpha K_m + [S]}.\n$$\nWe require $r = 0.1$ to achieve a $90\\%$ reduction in rate. Solving the above relation for $\\alpha$ in terms of $r$, $K_m$, and $[S]$:\n$$\nr \\,(\\alpha K_m + [S]) \\;=\\; K_m + [S]\n\\;\\;\\Longrightarrow\\;\\;\n\\alpha \\;=\\; \\frac{K_m + [S] - r\\,[S]}{r\\,K_m}\n\\;=\\; \\frac{K_m + (1 - r)\\,[S]}{r\\,K_m}.\n$$\nThe inhibitor concentration $[I]$ follows from $\\alpha = 1 + [I]/K_i$:\n$$\n[I] \\;=\\; K_i\\,(\\alpha - 1) \\;=\\; K_i\\left(\\frac{K_m + (1 - r)\\,[S]}{r\\,K_m} - 1\\right)\n\\;=\\; K_i\\,\\frac{(1 - r)\\,[S] + (1 - r)\\,K_m}{r\\,K_m}\n\\;=\\; K_i\\,\\frac{1 - r}{r}\\,\\frac{[S] + K_m}{K_m}.\n$$\nThus, the general analytic expression for the inhibitor concentration that yields fractional activity $r$ under competitive inhibition is\n$$\n[I] \\;=\\; K_i\\,\\frac{1 - r}{r}\\,\\frac{[S] + K_m}{K_m}.\n$$\nFor the specific case of $r = 0.1$, $K_m = 50\\,\\mu\\mathrm{M}$, and $[S] = 1\\,\\mathrm{mM} = 1000\\,\\mu\\mathrm{M}$, we first compute the dimensionless ratio:\n$$\n\\frac{[S] + K_m}{K_m} \\;=\\; \\frac{1000\\,\\mu\\mathrm{M} + 50\\,\\mu\\mathrm{M}}{50\\,\\mu\\mathrm{M}} \\;=\\; \\frac{1050}{50} \\;=\\; 21.\n$$\nNext, compute the factor $\\dfrac{1 - r}{r}$ at $r = 0.1$:\n$$\n\\frac{1 - r}{r} \\;=\\; \\frac{0.9}{0.1} \\;=\\; 9.\n$$\nTherefore,\n$$\n[I] \\;=\\; K_i \\times 9 \\times 21 \\;=\\; 189\\,K_i.\n$$\nWith $K_i = 5\\,\\mathrm{nM}$, the required inhibitor concentration is\n$$\n[I] \\;=\\; 189 \\times 5\\,\\mathrm{nM} \\;=\\; 945\\,\\mathrm{nM}.\n$$\nRounded to three significant figures and expressed in $\\mathrm{nM}$ as requested, the $IC_{90}$ is $945\\,\\mathrm{nM}$.", "answer": "$$\\boxed{945}$$", "id": "2950344"}, {"introduction": "This advanced practice places you in the role of a computational systems biologist, tackling the challenge of deciphering pathway architecture from experimental data. The task [@problem_id:2681319] is to implement and use a Bayesian inference framework to distinguish between two competing models of JAK-STAT regulation: one with and one without a negative feedback loop. This exercise builds essential skills in formulating mechanistic models as ordinary differential equations (ODEs), fitting them to data, and using statistical evidence to evaluate biological hypotheses, a workflow at the forefront of modern quantitative biology.", "problem": "You are asked to implement a self-contained Bayesian parameter inference and comparison for two mechanistic hypotheses of the Janus kinase–signal transducer and activator of transcription (JAK-STAT) signaling pathway. The two hypotheses differ by the presence or absence of a transcriptional negative feedback mediated by Suppressor Of Cytokine Signaling (SOCS).\n\nStart from the following accepted bases:\n- The law of mass action for well-mixed systems implies that macroscopic reaction rates can be modeled by ordinary differential equations (ODEs) in which the rate of change of a concentration is a linear combination of current concentrations and inputs when considering first-order processes.\n- Bayes' theorem states that, for parameters $\\theta$, data $D$, and hypothesis $H$, the posterior density is $p(\\theta \\mid D, H) \\propto p(D \\mid \\theta, H) p(\\theta \\mid H)$.\n- For additive measurement noise modeled as independent identically distributed Gaussian noise of known standard deviation $\\sigma$, the likelihood is $p(D \\mid \\theta, H) \\propto \\exp\\left(-\\tfrac{1}{2} \\sum_{i=1}^{n} \\left(\\tfrac{y_i - \\hat{y}_i(\\theta)}{\\sigma}\\right)^2 \\right)$ where $y_i$ are observations and $\\hat{y}_i(\\theta)$ are model predictions at observation times.\n\nMechanistic models:\n- Hypothesis without feedback ($H_0$): Let $N(t)$ denote the nuclear signal of activated STAT dimers and assume a constant upstream drive. The dynamics are\n$$\n\\frac{dN}{dt} = k_{\\text{in}} - k_{\\text{out}} N,\n$$\nwith initial condition $N(0)=0$. Here $k_{\\text{in}}$ is the effective input rate (per minute) driven by upstream receptor–Janus kinase activity, and $k_{\\text{out}}$ is the first-order loss rate (per minute) representing export/dephosphorylation.\n- Hypothesis with feedback ($H_1$): Let $S(t)$ denote the SOCS level with induction proportional to $N(t)$ and linear decay. The dynamics are\n$$\n\\begin{aligned}\n\\frac{dN}{dt} &= k_{\\text{in}} - \\left(k_{\\text{out}} + k_f S\\right) N, \\\\\n\\frac{dS}{dt} &= \\alpha N - \\gamma S,\n\\end{aligned}\n$$\nwith initial conditions $N(0)=0$ and $S(0)=0$. The constants $k_f$ (feedback strength, per minute per SOCS unit), $\\alpha$ (SOCS induction rate, per minute), and $\\gamma$ (SOCS decay rate, per minute) are known and fixed.\n\nObservation model:\n- Observations $y_i$ at times $t_i$ are generated as $y_i = N(t_i) + \\epsilon_i$ with $\\epsilon_i \\sim \\mathcal{N}(0,\\sigma^2)$, independently across $i$.\n\nBayesian inference task:\n- Unknown parameters under both $H_0$ and $H_1$ are $\\theta = (k_{\\text{in}}, k_{\\text{out}})$ with independent uniform priors:\n$$\nk_{\\text{in}} \\sim \\text{Uniform}(0.05, 1.0), \\quad k_{\\text{out}} \\sim \\text{Uniform}(0.02, 0.4).\n$$\n- Use a rectangular grid approximation for the posterior with $25$ linearly spaced points for $k_{\\text{in}}$ over $[0.05, 1.0]$ and $25$ linearly spaced points for $k_{\\text{out}}$ over $[0.02, 0.4]$.\n- For each grid point, compute the log-likelihood using the Gaussian model and obtain a normalized posterior over the grid using Bayes' theorem and log-sum-exp normalization.\n- For each hypothesis, compute the posterior mean of $k_{\\text{in}}$ by marginalization over the grid.\n\nNumerical integration:\n- For simulating the ODEs to compute model predictions $\\hat{y}_i(\\theta)$, use the explicit Euler method with a fixed time step $\\Delta t = 0.1$ minutes from $t=0$ to the maximum observation time. Use the recorded states at the provided observation times. Set $k_f = 0.5$, $\\alpha = 0.05$, and $\\gamma = 0.1$ (all per minute).\n\nData generation for test suite:\n- Use the same ODE solver and parameters as above to generate synthetic datasets with known seeds. For each test case, generate observations $y_i$ by simulating the specified hypothesis with the given true parameters, then adding Gaussian noise with the specified $\\sigma$ using a NumPy random number generator initialized as `default_rng(seed)`.\n- Observation times for all test cases are the minutes in the range $[0, 60]$ sampled every $2$ minutes, i.e., $t_i \\in \\{0, 2, 4, \\dots, 60\\}$.\n\nTest suite (three cases):\n1. Case A (feedback-generated): Generate data with $H_1$ using $k_{\\text{in}}^{\\text{true}} = 0.5$, $k_{\\text{out}}^{\\text{true}} = 0.1$, noise $\\sigma = 0.02$, and seed $12345$.\n2. Case B (no-feedback-generated): Generate data with $H_0$ using $k_{\\text{in}}^{\\text{true}} = 0.5$, $k_{\\text{out}}^{\\text{true}} = 0.1$, noise $\\sigma = 0.02$, and seed $54321$.\n3. Case C (feedback-generated, noisy): Generate data with $H_1$ using $k_{\\text{in}}^{\\text{true}} = 0.3$, $k_{\\text{out}}^{\\text{true}} = 0.08$, noise $\\sigma = 0.10$, and seed $2021$.\n\nRequired computation and output:\n- For each test case, perform Bayesian inference under both $H_0$ and $H_1$ and compute the difference in the posterior means of $k_{\\text{in}}$:\n$$\n\\Delta \\mu = \\mathbb{E}[k_{\\text{in}} \\mid D, H_1] - \\mathbb{E}[k_{\\text{in}} \\mid D, H_0].\n$$\n- Report one scalar per test case: the value of $\\Delta \\mu$ in units of $\\text{min}^{-1}$, rounded to six decimal places.\n\nFinal output format:\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (e.g., $[r_1,r_2,r_3]$), where $r_1$, $r_2$, and $r_3$ are the $\\Delta \\mu$ values for Cases A, B, and C, respectively, each in $\\text{min}^{-1}$ rounded to six decimal places.", "solution": "The task is to perform a Bayesian model comparison between two hypotheses, $H_0$ (no feedback) and $H_1$ (negative feedback), for the Janus kinase–signal transducer and activator of transcription (JAK-STAT) signaling pathway. This is accomplished by computing the posterior mean of the parameter $k_{\\text{in}}$ under each hypothesis for three distinct synthetic datasets and analyzing the difference.\n\nThe dynamics of the system are described by ordinary differential equations (ODEs).\nFor hypothesis $H_0$, which assumes no feedback, the concentration of nuclear activated STAT, denoted $N(t)$, evolves according to the first-order linear ODE:\n$$\n\\frac{dN}{dt} = k_{\\text{in}} - k_{\\text{out}} N\n$$\nwith the initial condition $N(0) = 0$. The parameters $k_{\\text{in}}$ and $k_{\\text{out}}$ represent the effective input and loss rates, respectively.\n\nFor hypothesis $H_1$, the system includes a negative feedback loop mediated by the Suppressor Of Cytokine Signaling (SOCS), whose concentration is denoted $S(t)$. The coupled dynamics are given by a system of two ODEs:\n$$\n\\begin{aligned}\n\\frac{dN}{dt} &= k_{\\text{in}} - \\left(k_{\\text{out}} + k_f S\\right) N \\\\\n\\frac{dS}{dt} &= \\alpha N - \\gamma S\n\\end{aligned}\n$$\nwith initial conditions $N(0) = 0$ and $S(0) = 0$. The parameters governing the feedback dynamics are specified as fixed constants: the feedback strength $k_f = 0.5$, the SOCS induction rate $\\alpha = 0.05$, and the SOCS decay rate $\\gamma = 0.1$. All rates are in units of $\\text{min}^{-1}$ or consistent combinations thereof.\n\nTo obtain model predictions $\\hat{y}_i(\\theta)$ for a given parameter set $\\theta = (k_{\\text{in}}, k_{\\text{out}})$, the ODEs must be solved numerically. The specified method is the explicit Euler scheme with a fixed time step of $\\Delta t = 0.1$ minutes. For a state vector $X_j$ at time $t_j$, representing $[N_j]$ for $H_0$ or $[N_j, S_j]^T$ for $H_1$, the state at the next time step $t_{j+1} = t_j + \\Delta t$ is computed as $X_{j+1} = X_j + \\Delta t \\cdot f(X_j, \\theta)$, where $f$ is the vector field defined by the right-hand side of the respective ODE system.\n\nThe core of the analysis is Bayesian inference. Bayes' theorem provides the posterior probability density of the parameters $\\theta$ given the data $D$ and a hypothesis $H$:\n$$\np(\\theta \\mid D, H) \\propto p(D \\mid \\theta, H) \\cdot p(\\theta \\mid H)\n$$\nThe parameters to be inferred, $\\theta=(k_{\\text{in}}, k_{\\text{out}})$, are assigned independent uniform prior distributions:\n$$\nk_{\\text{in}} \\sim \\text{Uniform}(0.05, 1.0), \\quad k_{\\text{out}} \\sim \\text{Uniform}(0.02, 0.4)\n$$\nAs the prior probability density $p(\\theta \\mid H)$ is constant over this specified rectangular domain and zero elsewhere, the posterior density is simply proportional to the likelihood function within this domain: $p(\\theta \\mid D, H) \\propto p(D \\mid \\theta, H)$.\n\nThe observation model posits that measurements $y_i$ are generated from the true nuclear STAT concentration $N(t_i)$ corrupted by additive, independent, and identically distributed Gaussian noise: $y_i = N(t_i) + \\epsilon_i$, where $\\epsilon_i \\sim \\mathcal{N}(0, \\sigma^2)$. Consequently, the log-likelihood function takes the form:\n$$\n\\log p(D \\mid \\theta, H) = \\text{const} - \\frac{1}{2\\sigma^2} \\sum_{i=1}^{n} (y_i - \\hat{y}_i(\\theta))^2\n$$\nwhere $y_i$ are the observed data at times $t_i \\in \\{0, 2, 4, \\dots, 60\\}$ and $\\hat{y}_i(\\theta)$ are the corresponding model predictions for $N(t_i)$.\n\nThe posterior distribution is approximated on a discrete grid. The parameter space for $(k_{\\text{in}}, k_{\\text{out}})$ is discretized into a $25 \\times 25$ rectangular grid. Let $\\theta_{ij} = (k_{\\text{in},i}, k_{\\text{out},j})$ denote a single point on this grid. For each hypothesis $H \\in \\{H_0, H_1\\}$, the following procedure is executed:\n$1$. For each grid point $\\theta_{ij}$, the corresponding ODE model is simulated to obtain predictions.\n$2$. The log-likelihood $\\mathcal{L}_{ij} = \\log p(D \\mid \\theta_{ij}, H)$ is computed from the sum of squared residuals.\n$3$. The unnormalized posterior log-probability at each grid point is equal to $\\mathcal{L}_{ij}$ due to the uniform prior. To obtain a normalized discrete probability distribution $P_{ij}$, the log-sum-exp trick is employed for numerical stability:\n$$\nP_{ij} = \\frac{\\exp(\\mathcal{L}_{ij} - \\mathcal{L}_{\\max})}{\\sum_{i'=1}^{25} \\sum_{j'=1}^{25} \\exp(\\mathcal{L}_{i'j'} - \\mathcal{L}_{\\max})}\n$$\nwhere $\\mathcal{L}_{\\max} = \\max_{i,j} \\mathcal{L}_{ij}$.\n\nOnce the posterior probability mass function on the grid, $P_{ij}$, is computed, the posterior mean of $k_{\\text{in}}$ is calculated as its expectation over this discrete distribution:\n$$\n\\mathbb{E}[k_{\\text{in}} \\mid D, H] = \\sum_{i=1}^{25} \\sum_{j=1}^{25} k_{\\text{in},i} \\cdot P_{ij}\n$$\nThis calculation is performed independently for both hypotheses, $H_0$ and $H_1$.\n\nThe final objective is to compute, for each of the three provided test cases, the difference between these posterior means:\n$$\n\\Delta \\mu = \\mathbb{E}[k_{\\text{in}} \\mid D, H_1] - \\mathbb{E}[k_{\\text{in}} \\mid D, H_0]\n$$\nThis quantity, $\\Delta \\mu$, measures how the estimate of the input rate $k_{\\text{in}}$ is adjusted when the model is expanded to include a negative feedback mechanism. A non-zero value indicates that the two models interpret the data differently with respect to this parameter. The overall algorithm proceeds by first generating the synthetic data for each test case, then performing the described inference procedure for both models, and finally computing their difference in posterior means.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.special import logsumexp\n\ndef solve():\n    \"\"\"\n    Main function to run the Bayesian inference for the specified test cases.\n    \"\"\"\n    # Define constants from the problem statement\n    KF = 0.5\n    ALPHA = 0.05\n    GAMMA = 0.1\n    DT = 0.1\n    T_MAX = 60.0 # Use float for calculations\n    T_OBS = np.arange(0, T_MAX + DT, 2) # Use DT to avoid float precision issues with T_MAX\n    KIN_GRID = np.linspace(0.05, 1.0, 25)\n    KOUT_GRID = np.linspace(0.02, 0.4, 25)\n    N_GRID_POINTS = 25\n\n    def solve_h0(k_in, k_out):\n        \"\"\"Solves the H0 model (no feedback) using explicit Euler.\"\"\"\n        num_steps = int(T_MAX / DT)\n        n_hist = np.zeros(num_steps + 1)\n        \n        for i in range(num_steps):\n            n_i = n_hist[i]\n            n_dot = k_in - k_out * n_i\n            n_hist[i + 1] = n_i + DT * n_dot\n            \n        return n_hist\n\n    def solve_h1(k_in, k_out):\n        \"\"\"Solves the H1 model (with feedback) using explicit Euler.\"\"\"\n        num_steps = int(T_MAX / DT)\n        n_hist = np.zeros(num_steps + 1)\n        s_hist = np.zeros(num_steps + 1)\n\n        for i in range(num_steps):\n            n_i = n_hist[i]\n            s_i = s_hist[i]\n            \n            n_dot = k_in - (k_out + KF * s_i) * n_i\n            s_dot = ALPHA * n_i - GAMMA * s_i\n            \n            n_hist[i + 1] = n_i + DT * n_dot\n            s_hist[i + 1] = s_i + DT * s_dot\n            \n        return n_hist\n\n    def generate_data(model_type, true_params, sigma, seed):\n        \"\"\"Generates synthetic data for a given model and parameters.\"\"\"\n        k_in_true, k_out_true = true_params\n        if model_type == 'H0':\n            n_true_hist = solve_h0(k_in_true, k_out_true)\n        else:  # H1\n            n_true_hist = solve_h1(k_in_true, k_out_true)\n        \n        obs_indices = (T_OBS / DT).astype(int)\n        n_at_obs = n_true_hist[obs_indices]\n        \n        rng = np.random.default_rng(seed)\n        noise = rng.normal(0, sigma, size=len(T_OBS))\n        y_obs = n_at_obs + noise\n        return y_obs\n\n    def run_inference(data, sigma, model_type):\n        \"\"\"Performs grid-based Bayesian inference and returns the posterior mean of k_in.\"\"\"\n        log_likelihoods = np.zeros((N_GRID_POINTS, N_GRID_POINTS))\n        obs_indices = (T_OBS / DT).astype(int)\n\n        for i, k_in in enumerate(KIN_GRID):\n            for j, k_out in enumerate(KOUT_GRID):\n                if model_type == 'H0':\n                    n_pred_hist = solve_h0(k_in, k_out)\n                else:  # H1\n                    n_pred_hist = solve_h1(k_in, k_out)\n                \n                n_pred_at_obs = n_pred_hist[obs_indices]\n                sse = np.sum((data - n_pred_at_obs)**2)\n                log_likelihoods[i, j] = -0.5 * sse / (sigma**2)\n\n        # Normalize posterior using log-sum-exp for numerical stability\n        log_posterior = log_likelihoods - logsumexp(log_likelihoods)\n        posterior = np.exp(log_posterior)\n        \n        # Calculate posterior mean of k_in\n        # posterior has shape (n_kin, n_kout)\n        # We need to compute Sum(k_in_i * P_ij) over i and j\n        mean_kin = np.sum(posterior * KIN_GRID[:, np.newaxis])\n        \n        return mean_kin\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        {'gen_model': 'H1', 'true_params': (0.5, 0.1), 'sigma': 0.02, 'seed': 12345},\n        {'gen_model': 'H0', 'true_params': (0.5, 0.1), 'sigma': 0.02, 'seed': 54321},\n        {'gen_model': 'H1', 'true_params': (0.3, 0.08), 'sigma': 0.10, 'seed': 2021}\n    ]\n\n    results = []\n    for case in test_cases:\n        # Generate data for the case\n        data = generate_data(\n            model_type=case['gen_model'],\n            true_params=case['true_params'],\n            sigma=case['sigma'],\n            seed=case['seed']\n        )\n        \n        # Run inference under H0\n        mean_kin_h0 = run_inference(data, case['sigma'], model_type='H0')\n        \n        # Run inference under H1\n        mean_kin_h1 = run_inference(data, case['sigma'], model_type='H1')\n        \n        delta_mu = mean_kin_h1 - mean_kin_h0\n        results.append(f\"{delta_mu:.6f}\") # Use formatted string for rounding\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(results)}]\")\n\nsolve()\n```", "id": "2681319"}]}