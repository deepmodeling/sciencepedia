{"hands_on_practices": [{"introduction": "This first practice establishes the quantitative foundation of the Bateson-Dobzhansky-Muller (BDM) model. By analyzing a classic dihybrid cross where the interacting loci are unlinked, you will directly apply the Mendelian principle of independent assortment to calculate the expected frequency of incompatible genotypes in the F2 generation. This exercise provides the essential baseline for understanding the genetic basis of hybrid breakdown and serves as a crucial starting point for more complex scenarios [@problem_id:2793247].", "problem": "Two allopatric lineages have evolved derived alleles at two autosomal, unlinked loci under the Bateson–Dobzhansky–Muller (BDM) model of genetic incompatibility. Lineage $1$ is fixed for the genotype $AA\\,bb$ (derived at locus $A$, ancestral at locus $B$), and lineage $2$ is fixed for $aa\\,BB$ (ancestral at locus $A$, derived at locus $B$). Under the BDM model, any hybrid individual carrying at least one copy of allele $A$ together with at least one copy of allele $B$ exhibits an incompatibility. Assume the following fundamental conditions: Mendelian segregation with fair meiosis, random mating, infinite population size, and no selection prior to the formation of the $F_2$ generation (so that Hardy–Weinberg proportions apply within loci). Also assume independent assortment of the two loci.\n\nStarting from these assumptions, derive the Hardy–Weinberg genotype frequencies at the two-locus level for the $F_2$ generation produced by intercrossing $F_1$ hybrids derived from the initial cross $AA\\,bb \\times aa\\,BB$. Then, using your derived two-locus distribution, compute the expected pre-selection fraction of $F_2$ individuals in the incompatible class denoted $A\\_B\\_$ (that is, individuals that are not $aa$ at locus $A$ and not $bb$ at locus $B$).\n\nReport only the expected incompatible fraction as a single reduced exact fraction. Do not approximate. No units are required.", "solution": "The problem statement is first subjected to validation.\n\nGivens:\n1. Two allopatric lineages, Lineage $1$ and Lineage $2$.\n2. Two autosomal, unlinked loci, denoted $A$ and $B$.\n3. Bateson–Dobzhansky–Muller (BDM) model of genetic incompatibility is assumed.\n4. Lineage $1$ genotype is fixed for $AA\\,bb$.\n5. Lineage $2$ genotype is fixed for $aa\\,BB$.\n6. BDM incompatibility is defined for any individual carrying at least one allele $A$ and at least one allele $B$. This phenotypic class is denoted $A\\_B\\_$.\n7. Assumed conditions: Mendelian segregation with fair meiosis, random mating, infinite population size, no selection prior to the F2 generation, and independent assortment of the two loci.\n8. The task is to derive the two-locus genotype frequencies in the F2 generation and then compute the expected pre-selection fraction of incompatible individuals.\n\nValidation:\nThe problem is scientifically grounded, relying on the established Bateson–Dobzhansky–Muller model and fundamental principles of Mendelian genetics. It is well-posed, providing all necessary assumptions (parental genotypes, unlinked loci, random mating, etc.) to derive a unique, meaningful solution. The terminology is precise and objective. The problem is a standard exercise in population and evolutionary genetics, and it contains no logical contradictions, scientific inaccuracies, or ambiguities. Therefore, the problem is valid.\n\nSolution Derivation:\nThe process begins with the parental cross ($P$ generation) and proceeds to the second filial generation ($F_2$).\n\nStep 1: Parental Cross and F1 Generation\nThe parental cross is between an individual from Lineage $1$ and an individual from Lineage $2$:\n$$P: AA\\,bb \\times aa\\,BB$$\nThe individual of genotype $AA\\,bb$ produces only one type of gamete: $Ab$.\nThe individual of genotype $aa\\,BB$ produces only one type of gamete: $aB$.\nThe fusion of these gametes produces the first filial generation ($F_1$), where all individuals are heterozygous at both loci:\n$$F_1 \\text{ genotype}: Aa\\,Bb$$\n\nStep 2: F1 Intercross and F2 Generation Gametes\nThe $F_2$ generation is produced by intercrossing the $F_1$ individuals:\n$$F_1 \\text{ intercross}: Aa\\,Bb \\times Aa\\,Bb$$\nDue to Mendelian segregation and the principle of independent assortment for unlinked loci, an individual of genotype $Aa\\,Bb$ produces four types of gametes in equal proportions. The frequency of each gamete type is $\\frac{1}{4}$:\n$$\n\\text{Gamete frequencies from } F_1: P(AB) = \\frac{1}{4}, P(Ab) = \\frac{1}{4}, P(aB) = \\frac{1}{4}, P(ab) = \\frac{1}{4}\n$$\nThe allele frequencies in this gamete pool are $p_A = P(A) = \\frac{1}{2}$, $q_a = P(a) = \\frac{1}{2}$, $p_B = P(B) = \\frac{1}{2}$, and $q_b = P(b) = \\frac{1}{2}$.\n\nStep 3: Genotype Frequencies in the F2 Generation\nWith random mating (equivalent to the random fusion of these gametes), the genotype frequencies at each locus will follow the Hardy-Weinberg proportions.\nFor locus $A$, the genotype frequencies are:\n$$P(AA) = p_A^2 = \\left(\\frac{1}{2}\\right)^2 = \\frac{1}{4}$$\n$$P(Aa) = 2p_A q_a = 2\\left(\\frac{1}{2}\\right)\\left(\\frac{1}{2}\\right) = \\frac{1}{2}$$\n$$P(aa) = q_a^2 = \\left(\\frac{1}{2}\\right)^2 = \\frac{1}{4}$$\nSimilarly, for locus $B$, the genotype frequencies are:\n$$P(BB) = p_B^2 = \\left(\\frac{1}{2}\\right)^2 = \\frac{1}{4}$$\n$$P(Bb) = 2p_B q_b = 2\\left(\\frac{1}{2}\\right)\\left(\\frac{1}{2}\\right) = \\frac{1}{2}$$\n$$P(bb) = q_b^2 = \\left(\\frac{1}{2}\\right)^2 = \\frac{1}{4}$$\nBecause the loci assort independently, the frequency of any two-locus genotype is the product of the corresponding single-locus genotype frequencies. This constitutes the derivation of the two-locus genotype distribution requested by the problem.\n\nStep 4: Calculation of the Incompatible Fraction\nThe problem defines the incompatible class as individuals with the phenotype $A\\_B\\_$, meaning they possess at least one derived allele $A$ and at least one derived allele $B$. We must calculate the expected fraction of $F_2$ individuals belonging to this class. This is the probability $P(A\\_B\\_)$.\nThe probability of an individual having at least one $A$ allele, denoted $P(A\\_)$, is the sum of the probabilities of being $AA$ or $Aa$:\n$$P(A\\_) = P(AA) + P(Aa) = \\frac{1}{4} + \\frac{1}{2} = \\frac{3}{4}$$\nAlternatively, this can be calculated as $1$ minus the probability of being homozygous for the ancestral allele $a$:\n$$P(A\\_) = 1 - P(aa) = 1 - \\frac{1}{4} = \\frac{3}{4}$$\nSimilarly, the probability of an individual having at least one $B$ allele, $P(B\\_)$, is:\n$$P(B\\_) = P(BB) + P(Bb) = \\frac{1}{4} + \\frac{1}{2} = \\frac{3}{4}$$\nOr, equivalently:\n$$P(B\\_) = 1 - P(bb) = 1 - \\frac{1}{4} = \\frac{3}{4}$$\nSince the loci are unlinked, the joint probability of having both phenotypes is the product of their individual probabilities:\n$$P(A\\_B\\_) = P(A\\_) \\times P(B\\_)$$\nSubstituting the calculated values:\n$$P(A\\_B\\_) = \\frac{3}{4} \\times \\frac{3}{4} = \\frac{9}{16}$$\nThis is the expected fraction of $F_2$ individuals that exhibit the BDM incompatibility before any selection acts upon them. The result is a reduced exact fraction as required.", "answer": "$$\\boxed{\\frac{9}{16}}$$", "id": "2793247"}, {"introduction": "Building upon the foundational case of independent assortment, this exercise introduces the crucial role of genetic linkage in modulating hybrid breakdown. When interacting loci reside on the same chromosome, recombination becomes the key process that generates novel, incompatible haplotypes not present in the parental lineages. By deriving the frequency of incompatible genotypes as a function of the recombination fraction $r$, you will gain a deeper appreciation for how the physical arrangement of genes on chromosomes can either promote or suppress the manifestation of hybrid incompatibilities [@problem_id:2793337].", "problem": "Two allopatric lineages have fixed different derived alleles at two interacting loci, consistent with the Bateson–Dobzhansky–Muller (BDM) model of genetic incompatibility. Lineage $1$ is fixed for haplotype $A b$ (genotype $AA\\,bb$), and lineage $2$ is fixed for haplotype $a B$ (genotype $aa\\,BB$). The two loci $A$ and $B$ reside on the same chromosome with recombination fraction $r$ between them, where $0 \\le r \\le \\tfrac{1}{2}$. The incompatibility is recessive-by-recessive: the combination of derived alleles at both loci is deleterious only when both are homozygous derived in the same individual, that is, only genotype $AA\\,BB$ experiences a fitness reduction. Let the fitness reduction of the incompatible genotype be $s$, with $0 < s \\le 1$ (where $s = 1$ corresponds to complete inviability).\n\nFoundational principles to use:\n- Mendel’s laws of segregation and random union of gametes.\n- The definition of the recombination fraction $r$ in a double heterozygote in a specified phase: the fraction of gametes that are recombinant haplotypes equals $r$, split equally among the two recombinant haplotypes, while the nonrecombinant haplotypes collectively have frequency $1 - r$.\n\nA large number of $F_1$ individuals are produced by crossing the lineages above. These $F_1$s are then randomly mated (equivalently, selfed, since all $F_1$s are genetically identical at these loci) to generate the $F_2$ generation.\n\nTasks:\n1. Derive, from first principles, the haplotype distribution of gametes produced by the $F_1$ double heterozygotes as a function of $r$, explicitly identifying the expected frequency of the recombinant gamete $AB$ among the gametes that give rise to the $F_2$.\n2. Using random union of these gametes, compute the expected fraction of $F_2$ zygotes that are $AA\\,BB$ and therefore experience hybrid breakdown under the recessive-by-recessive incompatibility with effect size $s$.\n3. Provide your final answer as a single closed-form analytic expression in terms of $r$ and $s$ for the expected fraction of $F_2$ zygotes eliminated by hybrid breakdown. No rounding is required. Express the final answer without units.\n\nYour derivation must not assume any formulas beyond the fundamental definitions stated above, and must make clear how variation in $r$ modulates the magnitude of hybrid breakdown in the $F_2$.", "solution": "We begin by formalizing the genetic states implied by the Bateson–Dobzhansky–Muller (BDM) scenario. The parental lineages are fixed for distinct haplotypes: lineage $1$ is $AA\\,bb$ (haplotype $A b$) and lineage $2$ is $aa\\,BB$ (haplotype $a B$). A cross between these lineages produces $F_1$ individuals that are double heterozygotes at the two loci. Because the parental haplotypes are $A b$ and $a B$, the $F_1$ phase is $Ab/aB$ (repulsion phase).\n\nBy Mendel’s law of segregation and the definition of the recombination fraction $r$ in a double heterozygote of known phase, the gametes produced by an $Ab/aB$ individual occur as follows:\n- The two nonrecombinant (parental) haplotypes are $A b$ and $a B$.\n- The two recombinant haplotypes are $A B$ and $a b$.\n- The total frequency of recombinant gametes is $r$, split equally between $A B$ and $a b$, while the total frequency of nonrecombinant gametes is $1 - r$, split equally between $A b$ and $a B$.\n\nTherefore, the $F_1$ gamete haplotype distribution is:\n- $A b$ with frequency $\\tfrac{1 - r}{2}$,\n- $a B$ with frequency $\\tfrac{1 - r}{2}$,\n- $A B$ with frequency $\\tfrac{r}{2}$,\n- $a b$ with frequency $\\tfrac{r}{2}$.\n\nThis completes task $1$, and in particular identifies the expected frequency of the recombinant gamete $AB$ among gametes that form the $F_2$ as $\\tfrac{r}{2}$.\n\nNext, we compute the expected fraction of $F_2$ zygotes that are $AA\\,BB$. The $F_2$ is formed by random union of gametes drawn independently from the $F_1$ gamete pool described above. Mendel’s random union of gametes stipulates that the two gametes forming a zygote are independent draws from this distribution.\n\nTo obtain the $AA\\,BB$ genotype, both loci must be homozygous for the derived alleles $A$ and $B$. The only way to achieve $AA\\,BB$ given the $F_1$ haplotype distribution is for both gametes to be the $AB$ recombinant haplotype. Any other combination yields at least one ancestral allele at one locus and so cannot be $AA\\,BB$. Thus, the probability that a randomly formed $F_2$ zygote is $AA\\,BB$ equals the probability that both maternal and paternal gametes are $AB$:\n$$\n\\Pr(AA\\,BB) = \\Pr(AB) \\times \\Pr(AB) = \\left(\\frac{r}{2}\\right)^{2} = \\frac{r^{2}}{4}.\n$$\n\nUnder the recessive-by-recessive BDM incompatibility, only genotype $AA\\,BB$ is affected, experiencing a fitness reduction of $s$ (with $0 < s \\le 1$). The expected fraction of $F_2$ zygotes eliminated by hybrid breakdown is therefore the product of the fraction of $F_2$ zygotes that are $AA\\,BB$ and the effect size $s$:\n$$\n\\text{Expected fraction eliminated} = s \\times \\Pr(AA\\,BB) = s \\times \\frac{r^{2}}{4} = \\frac{s \\, r^{2}}{4}.\n$$\n\nThis expression shows explicitly how recombination modulates hybrid breakdown. As $r$ increases from $0$ to $\\tfrac{1}{2}$, the frequency of recombinant $AB$ gametes increases linearly from $0$ to $\\tfrac{1}{4}$, and the expected fraction of incompatible $F_2$ zygotes increases quadratically from $0$ to $\\tfrac{1}{16}$ (scaled by $s$). Formally, the sensitivity is\n$$\n\\frac{d}{dr}\\left(\\frac{s \\, r^{2}}{4}\\right) = \\frac{s \\, r}{2},\n$$\nwhich is positive for $r > 0$, confirming monotonic increase with $r$. The maximum possible breakdown under this model occurs at $r = \\tfrac{1}{2}$ with value $\\tfrac{s}{16}$, while no breakdown occurs at $r = 0$ because recombination never produces the $AB$ haplotype required for $AA\\,BB$.\n\nHence, the requested closed-form analytic expression for the expected fraction of $F_2$ zygotes eliminated by hybrid breakdown is $\\tfrac{s \\, r^{2}}{4}$, with the intermediate result that the expected frequency of the recombinant gamete $AB$ in the $F_2$-forming gamete pool is $\\tfrac{r}{2}$.", "answer": "$$\\boxed{\\frac{s\\,r^{2}}{4}}$$", "id": "2793337"}, {"introduction": "This final practice moves from deterministic theoretical predictions to the realm of statistical inference, reflecting a common challenge in modern evolutionary biology. Here, you will tackle the inverse problem: given an observed level of hybrid inviability, how can we estimate the number of underlying Bateson-Dobzhansky-Muller incompatibilities? This exercise guides you through constructing a Bayesian model to infer this key parameter from experimental data, providing hands-on experience with the powerful computational methods used to dissect the genetic architecture of speciation [@problem_id:2793240].", "problem": "Consider a model of Bateson-Dobzhansky-Muller incompatibilities (BDMIs), where hybrid fitness reduction arises from the presence of epistatic genetic incompatibilities accumulated between diverging lineages. Suppose there are an unknown number $k$ of Dobzhansky-Muller incompatibilities (DMIs), each of which independently manifests in a given hybrid individual with probability $q$, and if at least one DMI manifests, the individual is inviable. Assume the following modeling assumptions from first principles.\n\n- The number of DMIs $k$ is an integer-valued random variable with a Poisson prior, $k \\sim \\operatorname{Poisson}(\\lambda)$ with rate parameter $\\lambda > 0$.\n- For a given $k$, the probability that a hybrid individual is viable equals the probability that none of the $k$ independent DMIs manifests. Under independence, this is the product of the probabilities that each incompatibility does not manifest, so the viability probability equals $(1 - q)^k$. Therefore, the inviability probability for a single hybrid equals $p(k) = 1 - (1 - q)^k$.\n- Given $k$, let $X$ denote the number of inviable hybrids among $n$ independently tested hybrids. Then $X \\mid k \\sim \\operatorname{Binomial}(n, p(k))$ by the well-tested Bernoulli trial model.\n\nYour task is to construct a Bayesian posterior over $k$ using the above model and to compute a $100 \\times (1-\\alpha)$ credible interval for $k$ based on the observed count $x$ of inviable hybrids. The derivation must start from the above foundational facts: independence, the binomial model for counts of events in repeated trials, the Poisson prior on count parameters, and Bayes’ theorem.\n\nDefinitions and requirements:\n\n- Use Bayes’ theorem to write the unnormalized posterior $P(k \\mid x) \\propto P(x \\mid k) P(k)$, where $P(k)$ is the Poisson probability mass function and $P(x \\mid k)$ is the Binomial likelihood evaluated at $p(k) = 1 - (1 - q)^k$.\n- Because the posterior is discrete on $k \\in \\{0,1,2,\\dots\\}$, compute an equal-tailed $(1-\\alpha)$ credible interval $[k_{\\text{lo}}, k_{\\text{hi}}]$ by finding the smallest integers $k_{\\text{lo}}$ and $k_{\\text{hi}}$ such that the posterior cumulative distribution function satisfies $\\Pr(K \\le k_{\\text{lo}} \\mid x) \\ge \\alpha/2$ and $\\Pr(K \\le k_{\\text{hi}} \\mid x) \\ge 1 - \\alpha/2$.\n- For numerical stability, evaluate the posterior up to an upper truncation $k_{\\max}$ that is large enough to capture essentially all posterior mass. Choose $k_{\\max}$ deterministically as $k_{\\max} = \\lceil \\lambda + 15\\sqrt{\\lambda} + 50 \\rceil$, but not less than $1000$, so that $k_{\\max} = \\max\\{\\lceil \\lambda + 15\\sqrt{\\lambda} + 50 \\rceil, 1000\\}$. This is a conservative bound designed to keep the neglected tail probability negligible across the provided test suite. Use log-probabilities to avoid underflow, employing the identity $\\log((1 - q)^k) = k \\log(1 - q)$ and stable functions such as $\\log(1+z)$ for small $z$.\n- Do not include any physical units. All probabilities must be handled as real numbers between $0$ and $1$.\n\nImplement a program that, for a given list of test cases $(\\lambda, n, x, q, \\alpha)$, returns the equal-tailed $(1-\\alpha)$ credible interval for $k$ for each test case. The final program must be self-contained, require no input, and print the results for the provided test suite.\n\nUse the following test suite, each specified as a tuple $(\\lambda, n, x, q, \\alpha)$:\n\n- Test $1$: $(\\lambda, n, x, q, \\alpha) = (5.0, 100, 30, 0.1, 0.05)$.\n- Test $2$: $(\\lambda, n, x, q, \\alpha) = (1.5, 100, 0, 0.2, 0.05)$.\n- Test $3$: $(\\lambda, n, x, q, \\alpha) = (10.0, 50, 50, 0.05, 0.05)$.\n- Test $4$: $(\\lambda, n, x, q, \\alpha) = (2.0, 30, 3, 0.5, 0.05)$.\n- Test $5$: $(\\lambda, n, x, q, \\alpha) = (15.0, 200, 80, 0.02, 0.05)$.\n\nYour program should produce a single line of output containing the results as a comma-separated list of the credible intervals, each interval formatted as a two-integer list $[k_{\\text{lo}},k_{\\text{hi}}]$, and the entire set enclosed in square brackets. For example, the output should look like $[[a,b],[c,d],\\dots]$ with no spaces.", "solution": "The problem requires the construction of a Bayesian posterior distribution for the number of Dobzhansky-Muller incompatibilities, $k$, and the subsequent calculation of a credible interval for $k$. The solution proceeds by first validating the problem statement, which is found to be scientifically sound, well-posed, and computationally tractable. We then derive the mathematical form of the posterior and outline the numerical algorithm for its computation.\n\nThe model is structured as follows:\n- A prior distribution for the number of incompatibilities, $k$: $k \\sim \\operatorname{Poisson}(\\lambda)$.\n- A data-generating process (likelihood) for the observed number of inviable hybrids, $x$, out of $n$ total hybrids: $x \\mid k \\sim \\operatorname{Binomial}(n, p(k))$.\n- The probability of inviability for a single hybrid, $p(k)$, depends on $k$ as $p(k) = 1 - (1 - q)^k$.\n\nThe core of the task is to apply Bayes' theorem to find the posterior distribution of $k$ given the observation $x$.\n\n**1. Formulation of the Posterior Distribution**\n\nAccording to Bayes' theorem, the posterior probability mass function (PMF) for $k$ is proportional to the product of the likelihood and the prior:\n$$ P(k \\mid x, \\lambda, n, q) \\propto P(x \\mid k, n, q) \\cdot P(k \\mid \\lambda) $$\nThe components are:\n- The prior, $P(k \\mid \\lambda)$, is the Poisson PMF:\n  $$ P(k) = \\frac{e^{-\\lambda} \\lambda^k}{k!} \\quad \\text{for } k \\in \\{0, 1, 2, \\dots\\} $$\n- The likelihood, $P(x \\mid k, n, q)$, is the Binomial PMF:\n  $$ P(x \\mid k) = \\binom{n}{x} p(k)^x (1 - p(k))^{n-x} $$\n  where $p(k) = 1 - (1-q)^k$ and consequently, the viability probability is $1-p(k) = (1-q)^k$.\n\nFor numerical computation, it is standard practice to work with logarithms to prevent floating-point underflow or overflow. The unnormalized log-posterior, denoted $\\log \\tilde{P}(k \\mid x)$, is the sum of the log-prior and the log-likelihood:\n$$ \\log \\tilde{P}(k \\mid x) = \\log P(x \\mid k) + \\log P(k) $$\nExpanding these terms, we have:\n$$ \\log P(k) = -\\lambda + k \\log(\\lambda) - \\log(k!) $$\n$$ \\log P(x \\mid k) = \\log\\left(\\binom{n}{x}\\right) + x \\log(p(k)) + (n-x) \\log(1 - p(k)) $$\nSubstituting $p(k) = 1 - (1-q)^k$ and $\\log(1-p(k)) = k \\log(1-q)$:\n$$ \\log \\tilde{P}(k \\mid x) = \\left( \\log\\left(\\binom{n}{x}\\right) - \\lambda \\right) + x\\log(1 - (1-q)^k) + (n-x)k\\log(1-q) + k\\log(\\lambda) - \\log(k!) $$\nThe term $\\log(k!)$ is computed efficiently using the log-gamma function, $\\log(k!) = \\operatorname{gammaln}(k+1)$. The term $\\log(1 - e^z)$ for $z < 0$ is computed using a stable function like `numpy.log1p(-numpy.exp(z))`, where here $z = k\\log(1-q)$. Since the term $\\log\\left(\\binom{n}{x}\\right) - \\lambda$ is constant with respect to $k$, it can be ignored when finding the shape of the posterior, but must be included for the correctly scaled log-posterior.\n\n**2. Numerical Computation Algorithm**\n\nThe posterior distribution for $k$ does not have a simple closed-form solution and must be computed numerically over its support, which is the set of non-negative integers $\\{0, 1, 2, \\dots\\}$.\n\n**Step 2.1: Truncation of Posterior Support**\nThe support of $k$ is infinite. For computation, we must truncate it at a sufficiently large integer $k_{\\max}$ such that the neglected posterior probability $\\Pr(K > k_{\\max} \\mid x)$ is negligible. The problem specifies a conservative choice for $k_{\\max}$:\n$$ k_{\\max} = \\max\\left\\{\\lceil \\lambda + 15\\sqrt{\\lambda} + 50 \\rceil, 1000\\right\\} $$\nWe will evaluate the posterior for $k \\in \\{0, 1, \\dots, k_{\\max}\\}$.\n\n**Step 2.2: Evaluation of Log-Posterior**\nWe compute the vector of unnormalized log-posterior probabilities, `log_post`, for each $k$ in the range $[0, k_{\\max}]$. Special care is required for the edge case $k=0$, where $p(0)=0$:\n- If $k=0$ and $x=0$, the likelihood is $\\binom{n}{0}0^0(1-0)^n = 1$, so the log-likelihood is $0$.\n- If $k=0$ and $x > 0$, the likelihood is $0$, so the log-likelihood is $-\\infty$.\n\n**Step 2.3: Normalization**\nTo obtain the normalized posterior PMF, we must convert from log-probabilities to probabilities and ensure they sum to $1$. The standard and numerically stable \"log-sum-exp\" trick is employed:\n1. Find the maximum value of the computed unnormalized log-posteriors: $L_{\\max} = \\max_k(\\log \\tilde{P}(k \\mid x))$.\n2. Compute shifted log-posteriors: $\\log \\tilde{P}'(k \\mid x) = \\log \\tilde{P}(k \\mid x) - L_{\\max}$.\n3. Exponentiate to get unnormalized probabilities: $\\tilde{P}'(k \\mid x) = \\exp(\\log \\tilde{P}'(k \\mid x))$.\n4. The normalization constant is the sum of these probabilities: $C = \\sum_{k=0}^{k_{\\max}} \\tilde{P}'(k \\mid x)$.\n5. The final, normalized PMF is $P(k \\mid x) = \\tilde{P}'(k \\mid x) / C$.\n\n**Step 2.4: Credible Interval Calculation**\nThe $(1-\\alpha)$ equal-tailed credible interval $[k_{\\text{lo}}, k_{\\text{hi}}]$ is determined from the posterior cumulative distribution function (CDF), $F(k) = \\Pr(K \\le k \\mid x)$. The CDF is computed by taking the cumulative sum of the normalized PMF. The interval bounds are the smallest integers satisfying:\n- $\\Pr(K \\le k_{\\text{lo}} \\mid x) \\ge \\alpha/2$\n- $\\Pr(K \\le k_{\\text{hi}} \\mid x) \\ge 1 - \\alpha/2$\nThese values are found by searching for the first index in the CDF array that meets or exceeds the respective probability thresholds $\\alpha/2$ and $1 - \\alpha/2$.\n\nThis complete algorithm is implemented in the Python program below to solve for the provided test cases.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.special import gammaln\n\ndef calculate_credible_interval(lambda_val, n, x, q, alpha):\n    \"\"\"\n    Calculates the (1-alpha) credible interval for k using Bayesian inference.\n    \n    Args:\n        lambda_val (float): The rate parameter of the Poisson prior for k.\n        n (int): The total number of hybrids tested.\n        x (int): The number of inviable hybrids observed.\n        q (float): The probability that a single DMI manifests.\n        alpha (float): The significance level for the credible interval.\n        \n    Returns:\n        list: A two-element list [k_lo, k_hi] representing the credible interval.\n    \"\"\"\n    # 1. Determine the truncation point k_max for the posterior evaluation\n    k_max_calc = np.ceil(lambda_val + 15 * np.sqrt(lambda_val) + 50)\n    k_max = int(max(k_max_calc, 1000))\n\n    k_range = np.arange(k_max + 1)\n    \n    # 2. Calculate the unnormalized log-posterior for each k\n    log_post_unnorm = np.full(k_max + 1, -np.inf, dtype=np.float64)\n    \n    # Pre-compute constants\n    log_lambda = np.log(lambda_val)\n    log_q1 = np.log(1 - q)\n    log_binom_coeff = gammaln(n + 1) - gammaln(x + 1) - gammaln(n - x + 1)\n\n    # Handle the k=0 case separately\n    # Log-prior for k=0\n    log_prior_0 = -lambda_val  # Based on Poisson PMF: exp(-lambda)*lambda^0/0!\n    # Log-likelihood for k=0, where p(0)=0\n    if x == 0:\n        log_likelihood_0 = 0.0\n    else:\n        log_likelihood_0 = -np.inf\n    log_post_unnorm[0] = log_prior_0 + log_likelihood_0\n    \n    # Handle cases for k > 0 using vectorized operations\n    k_vals_gt0 = k_range[1:]\n    \n    # Log-prior for k > 0\n    log_prior_k = -lambda_val + k_vals_gt0 * log_lambda - gammaln(k_vals_gt0 + 1)\n    \n    # Log-likelihood for k > 0\n    k_log_q1 = k_vals_gt0 * log_q1\n    log_1_minus_p_k = k_log_q1\n    \n    if x == 0:\n        log_likelihood_term = n * log_1_minus_p_k\n    else:\n        # log(p_k) = log(1 - (1-q)^k) = log(1 - exp(k*log(1-q)))\n        # np.log1p(-np.exp(z)) is a stable way to compute log(1-exp(z)) for z<0\n        log_p_k = np.log1p(-np.exp(k_log_q1))\n        \n        if x == n:\n            log_likelihood_term = n * log_p_k\n        else:  # 0 < x < n\n            log_likelihood_term = x * log_p_k + (n - x) * log_1_minus_p_k\n            \n    log_likelihood_k = log_binom_coeff + log_likelihood_term\n    log_post_unnorm[1:] = log_prior_k + log_likelihood_k\n    \n    # 3. Normalize the posterior using the log-sum-exp trick for stability\n    # Check if any finite posterior values exist\n    if not np.any(np.isfinite(log_post_unnorm)):\n        # This case suggests the model is inconsistent with the data; should not happen with test cases.\n        return [0, k_max] \n\n    log_max = np.max(log_post_unnorm[np.isfinite(log_post_unnorm)])\n    log_post_shifted = log_post_unnorm - log_max\n    post_unnorm_shifted = np.exp(log_post_shifted)  # np.exp(-inf) correctly yields 0.0\n    \n    norm_const = np.sum(post_unnorm_shifted)\n    if norm_const == 0.0:\n        return [0, k_max] # Fallback if all posteriors are zero\n        \n    post_pmf = post_unnorm_shifted / norm_const\n\n    # 4. Compute the Cumulative Distribution Function (CDF)\n    post_cdf = np.cumsum(post_pmf)\n    \n    # 5. Find the credible interval bounds\n    alpha_half = alpha / 2.0\n    \n    # k_lo is the smallest k such that CDF(k) >= alpha/2\n    k_lo = np.argmax(post_cdf >= alpha_half)\n    \n    # k_hi is the smallest k such that CDF(k) >= 1 - alpha/2\n    k_hi = np.argmax(post_cdf >= 1 - alpha_half)\n    \n    return [int(k_lo), int(k_hi)]\n\ndef solve():\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # (lambda, n, x, q, alpha)\n        (5.0, 100, 30, 0.1, 0.05),\n        (1.5, 100, 0, 0.2, 0.05),\n        (10.0, 50, 50, 0.05, 0.05),\n        (2.0, 30, 3, 0.5, 0.05),\n        (15.0, 200, 80, 0.02, 0.05),\n    ]\n\n    results = []\n    for case in test_cases:\n        lambda_val, n, x, q, alpha = case\n        interval = calculate_credible_interval(lambda_val, n, x, q, alpha)\n        results.append(f\"[{interval[0]},{interval[1]}]\")\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(results)}]\")\n\nsolve()\n```", "id": "2793240"}]}