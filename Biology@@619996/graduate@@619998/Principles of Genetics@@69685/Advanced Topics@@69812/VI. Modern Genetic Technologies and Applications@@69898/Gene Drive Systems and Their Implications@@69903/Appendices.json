{"hands_on_practices": [{"introduction": "A key feature of many gene drive systems, particularly those designed for population suppression, is the fitness cost associated with the drive allele. This cost leads to a reduction in the mean fitness of the population, a concept known as \"genetic load.\" This exercise [@problem_id:2813416] provides foundational practice in quantifying this load, applying core population genetics principles such as Hardy-Weinberg equilibrium and viability selection to derive a precise expression for the demographic impact of a drive system.", "problem": "Consider a large, randomly mating population in which a homing gene drive allele $D$ segregates with a wild-type allele $W$. Assume Hardy–Weinberg equilibrium (HWE) at the zygote stage and viability selection acting between the zygote and adult stages. Let the relative viabilities (fitnesses) of the genotypes be given by $w_{WW}=1$, $w_{DW}=1-hs$, and $w_{DD}=1-s$, where $s \\in [0,1]$ is the selection coefficient against the homozygous drive genotype and $h \\in [0,1]$ is the dominance coefficient for the fitness cost in the heterozygote. Suppose the frequency of the drive allele $D$ at the zygote stage is $p \\in [0,1]$.\n\nUsing only the definitions of HWE genotype frequencies, mean fitness under viability selection, and genetic load, derive a closed-form expression for the genetic load imposed by the drive at frequency $p$. Define the genetic load as $L = 1 - \\overline{w}/w_{\\max}$, where $\\overline{w}$ is the mean fitness after viability selection and $w_{\\max}$ is the maximum genotype fitness present in the population.\n\nProvide your final answer as a single simplified analytic expression in terms of $p$, $h$, and $s$. No numerical evaluation or rounding is required.", "solution": "The problem statement must first be subjected to rigorous validation.\n\nStep 1: Extract Givens.\nThe givens are:\n- A large, randomly mating population.\n- Two alleles: a homing gene drive allele $D$ and a wild-type allele $W$.\n- Assumption of Hardy–Weinberg equilibrium (HWE) at the zygote stage.\n- Viability selection acts between the zygote and adult stages.\n- Relative viabilities (fitnesses) of genotypes: $w_{WW}=1$, $w_{DW}=1-hs$, and $w_{DD}=1-s$.\n- The selection coefficient $s$ is in the range $s \\in [0,1]$.\n- The dominance coefficient $h$ is in the range $h \\in [0,1]$.\n- The frequency of the drive allele $D$ at the zygote stage is $p \\in [0,1]$.\n- The definition of genetic load is $L = 1 - \\overline{w}/w_{\\max}$, where $\\overline{w}$ is the mean fitness after viability selection and $w_{\\max}$ is the maximum genotype fitness present in the population.\n\nStep 2: Validate Using Extracted Givens.\nThe problem is scientifically grounded, employing standard, well-established models from population genetics, namely Hardy-Weinberg equilibrium and viability selection. The fitness structure and the concept of genetic load are fundamental in this field. The problem is well-posed, providing all necessary definitions, variables, and constraints ($p, h, s \\in [0,1]$) to derive a unique analytical solution. The language is objective and precise. The problem does not violate any of the criteria for invalidity; it is not unsound, incomplete, contradictory, unrealistic, or trivial.\n\nStep 3: Verdict and Action.\nThe problem is deemed valid. A solution will be derived.\n\nThe derivation begins from first principles. The population is assumed to be in Hardy–Weinberg equilibrium at the zygote stage. Given that the frequency of allele $D$ is $p$, the frequency of the wild-type allele $W$ is $1-p$. The genotype frequencies at the zygote stage are therefore:\n- Frequency of $WW$: $f(WW) = (1-p)^2$\n- Frequency of $DW$: $f(DW) = 2p(1-p)$\n- Frequency of $DD$: $f(DD) = p^2$\n\nThe mean fitness of the population, $\\overline{w}$, is the weighted average of the fitnesses of each genotype, with the weights being the HWE frequencies of those genotypes. The formula for mean fitness is:\n$$\n\\overline{w} = f(WW)w_{WW} + f(DW)w_{DW} + f(DD)w_{DD}\n$$\nSubstituting the given frequencies and fitness values:\n$$\n\\overline{w} = (1-p)^2(1) + 2p(1-p)(1-hs) + p^2(1-s)\n$$\nTo simplify this expression, we expand the terms:\n$$\n\\overline{w} = (1 - 2p + p^2) + (2p - 2p^2)(1-hs) + (p^2 - p^2s)\n$$\n$$\n\\overline{w} = 1 - 2p + p^2 + 2p - 2p^2 - 2p(1-p)hs + p^2 - p^2s\n$$\nThis can be regrouped more efficiently by recognizing that $(1-p)^2 + 2p(1-p) + p^2 = ((1-p)+p)^2 = 1^2 = 1$. We can separate the terms containing the selection coefficient $s$:\n$$\n\\overline{w} = \\left[(1-p)^2 + 2p(1-p) + p^2\\right] - 2p(1-p)hs - p^2s\n$$\nThis simplifies to:\n$$\n\\overline{w} = 1 - 2p(1-p)hs - p^2s\n$$\nNext, we must determine the maximum fitness, $w_{\\max}$. This is defined as the maximum genotype fitness present in the population. The fitnesses are $w_{WW}=1$, $w_{DW}=1-hs$, and $w_{DD}=1-s$. Given the constraints $s \\in [0,1]$ and $h \\in [0,1]$, the products $s$ and $hs$ are non-negative. Thus, $1-hs \\le 1$ and $1-s \\le 1$. The maximum fitness is therefore the fitness of the wild-type homozygote:\n$$\nw_{\\max} = w_{WW} = 1\n$$\nNow we can compute the genetic load, $L$, using its definition:\n$$\nL = 1 - \\frac{\\overline{w}}{w_{\\max}}\n$$\nSubstituting the expressions for $\\overline{w}$ and $w_{\\max}$:\n$$\nL = 1 - \\frac{1 - 2p(1-p)hs - p^2s}{1}\n$$\n$$\nL = 1 - (1 - 2p(1-p)hs - p^2s)\n$$\n$$\nL = 1 - 1 + 2p(1-p)hs + p^2s\n$$\nThis yields the expression for the genetic load:\n$$\nL = 2p(1-p)hs + p^2s\n$$\nTo obtain a simplified closed-form expression, we can factor out the common terms $p$ and $s$:\n$$\nL = ps[2(1-p)h + p]\n$$\nThis final expression represents the genetic load imposed by the drive allele at frequency $p$ as a function of the selection coefficient $s$ and the dominance coefficient $h$.", "answer": "$$\n\\boxed{ps(2h(1-p) + p)}\n$$", "id": "2813416"}, {"introduction": "The evolution of resistance is one of the most significant challenges to the long-term efficacy of gene drive strategies. Resistance alleles can arise naturally through processes like non-homologous end joining (NHEJ) during the drive's conversion mechanism. This thought-provoking problem [@problem_id:2813497] explores the critical co-evolutionary dynamic between the drive and the emergence of resistance, asking you to determine the conditions under which resistance either blocks the drive's spread or, counterintuitively, aids its population-suppressing goal.", "problem": "Consider a homing gene drive released into a large, randomly mating population to suppress fertility by disrupting a haplosufficient target gene. In heterozygotes carrying one drive allele and one wild-type allele, denote the probability that the wild-type allele is cleaved in the germline by $c \\in (0,1]$. Conditional on cleavage, homology-directed repair (HDR) occurs with probability $h \\in [0,1)$, converting the wild-type allele to the drive allele, and non-homologous end joining (NHEJ) occurs with probability $1-h$, creating a resistance allele. Among NHEJ outcomes, a fraction $p \\in (0,1)$ are in-frame mutations that restore target-gene function and produce a functional resistance allele $r_1$, while a fraction $1-p$ are frameshift or otherwise disruptive mutations that produce a nonfunctional resistance allele $r_2$. Both $r_1$ and $r_2$ alleles are fully resistant to further cutting by the drive endonuclease.\n\nAssume discrete, non-overlapping generations with Hardy–Weinberg genotype formation prior to viability selection. Let the relative viability-fertility fitness of carriers of $r_1$ be $w_1$ and of carriers of $r_2$ be $w_2$, both measured relative to wild type set to $1$, and assume that when $r_1$ and $r_2$ are rare they occur almost exclusively in heterozygotes with nonresistant alleles so that $w_1$ and $w_2$ apply uniformly to their bearers. Ignore resistance homozygotes and linkage disequilibria while resistance is rare. Treat the supply of newly formed resistance alleles as arising only from cleavage–repair events in drive/wild-type heterozygotes, and note that any factors common to both $r_1$ and $r_2$ production do not differentially favor one type over the other.\n\nUnder these conditions, there is a sharp threshold in the relative fitness of functional resistance versus nonfunctional resistance that determines whether the resistance pool that emerges tends to preserve target-gene function (thereby blocking suppression and effectively converting the drive to a modification outcome) or tends to disrupt target-gene function (thereby facilitating suppression). Define the critical relative-fitness ratio\n$$\nF^{\\ast} \\equiv \\frac{w_1}{w_2},\n$$\nat which the expected fraction of $r_1$ among all resistance alleles does not change after one generation of production and selection. For $w_1/w_2 > F^{\\ast}$, functional resistance $r_1$ increases in representation among resistance alleles and blocks suppression; for $w_1/w_2 < F^{\\ast}$, nonfunctional resistance $r_2$ increases and facilitates suppression.\n\nDerive $F^{\\ast}$ symbolically in terms of $p$ only. Express your final answer as a single simplified symbolic expression. No numerical approximation is required.", "solution": "The problem asks for the critical relative-fitness ratio, $F^{\\ast} \\equiv \\frac{w_1}{w_2}$, that determines whether a functional resistance allele ($r_1$) or a non-functional resistance allele ($r_2$) will predominate as resistance emerges in a population subject to a gene drive. This threshold is defined as the point at which the expected fraction of $r_1$ among all resistance alleles does not change.\n\nLet us analyze the dynamics of the two types of resistance alleles, $r_1$ and $r_2$, when they are rare. The problem specifies that new resistance alleles are generated exclusively from gene drive activity in drive/wild-type ($D/W$) heterozygotes.\n\nThe production of new resistance alleles occurs through the process of cleavage followed by non-homologous end joining (NHEJ). Let us denote the rate at which wild-type alleles are targeted for conversion in the population per generation as $R_{conv}$. This rate is proportional to the number of $D/W$ heterozygotes, the cleavage probability $c$, and the probability of NHEJ, $1-h$.\nThe problem states that a fraction $p$ of NHEJ events result in a functional resistance allele $r_1$, and a fraction $1-p$ result in a non-functional resistance allele $r_2$.\n\nThus, the rate of de novo production (mutation rate) for allele $r_1$ is $\\mu_1 = R_{conv} \\cdot p$.\nThe rate of de novo production for allele $r_2$ is $\\mu_2 = R_{conv} \\cdot (1-p)$.\nThe ratio of the production rates is therefore:\n$$\n\\frac{\\mu_1}{\\mu_2} = \\frac{R_{conv} \\cdot p}{R_{conv} \\cdot (1-p)} = \\frac{p}{1-p}\n$$\nThe problem states \"any factors common to both $r_1$ and $r_2$ production do not differentially favor one type over the other,\" which justifies this focus on the relative rates determined by $p$.\n\nThese newly produced alleles, as well as any pre-existing resistance alleles, are then subject to selection. The relative viability-fertility fitness of carriers of $r_1$ is $w_1$, and for carriers of $r_2$ is $w_2$.\n\nThe question of which allele type comes to dominate the emerging resistance pool is a question of which has a higher effective rate of increase from a rare state. A common, albeit simplified, model for this scenario in gene drive literature considers the effective rate of introduction of \"fit alleles\" into the population. This rate is taken to be the product of the de novo production rate of an allele and its fitness. This quantity represents the rate at which new, selectively-weighted copies of the allele appear in the population each generation.\n\nThe effective rate of introduction for $r_1$ can be written as:\n$$\n\\text{Rate}_{eff}(r_1) \\propto \\mu_1 w_1\n$$\nAnd the effective rate of introduction for $r_2$ is:\n$$\n\\text{Rate}_{eff}(r_2) \\propto \\mu_2 w_2\n$$\nThe critical threshold $F^{\\ast}$ represents the condition where neither allele has an advantage; that is, their effective rates of introduction are equal.\n$$\n\\mu_1 w_1 = \\mu_2 w_2\n$$\nWe can rearrange this equation to solve for the ratio $\\frac{w_1}{w_2}$:\n$$\n\\frac{w_1}{w_2} = \\frac{\\mu_2}{\\mu_1}\n$$\nSubstituting the ratio of the production rates we found earlier:\n$$\n\\frac{w_1}{w_2} = \\frac{1-p}{p}\n$$\nBy definition, the critical relative-fitness ratio is $F^{\\ast} \\equiv \\frac{w_1}{w_2}$. Therefore, we have derived the expression for $F^{\\ast}$.\n$$\nF^{\\ast} = \\frac{1-p}{p}\n$$\nLet us verify this threshold against the conditions described in the problem. If $\\frac{w_1}{w_2} > F^{\\ast}$, then $\\frac{w_1}{w_2} > \\frac{1-p}{p}$, which implies $p w_1 > (1-p) w_2$, and thus $\\mu_1 w_1 > \\mu_2 w_2$. In this case, the effective rate of introduction of functional resistance allele $r_1$ is greater than that of the non-functional allele $r_2$, so $r_1$ is expected to increase its representation in the resistance pool. This is consistent with the problem statement. Conversely, if $\\frac{w_1}{w_2} < F^{\\ast}$, $r_2$ will be favored. The derived expression is therefore correct under this modeling framework.", "answer": "$$\\boxed{\\frac{1-p}{p}}$$", "id": "2813497"}, {"introduction": "Theoretical models are essential for understanding gene drive dynamics, but their predictive power relies on parameters grounded in empirical reality. This hands-on computational practice [@problem_id:2813409] bridges the gap between theory and experiment, guiding you to develop a likelihood-based framework for parameter inference. By fitting a deterministic model to simulated time-series data from a cage experiment, you will estimate crucial biological parameters like the cleavage efficiency and repair pathway choice, a core skill for the quantitative analysis of real-world gene drive systems.", "problem": "You are tasked with building a complete, runnable program that uses a principled likelihood-based approach to infer cleavage and repair parameters in a simplified gene drive model from time series of allele counts in a closed, randomly mating population (a cage experiment). The system involves three alleles at a single locus: wildtype ($W$), drive ($D$), and resistance ($R$). The drive allele is based on Clustered Regularly Interspaced Short Palindromic Repeats (CRISPR) machinery. Conversion of the wildtype allele can occur via cleavage followed by repair, leading to either drive conversion via Homology-Directed Repair (HDR) or resistance via Nonhomologous End Joining (NHEJ).\n\nFundamental base to use:\n- Mendelian segregation and random mating.\n- Hardy–Weinberg proportions at zygote formation under random mating.\n- Deterministic allele frequency recursions in large populations.\n- Multinomial sampling noise for observed allele counts.\n- Definitions: Let $c \\in [0,1]$ denote the cleavage probability of a wildtype allele in a $W D$ heterozygote. Conditional on cleavage, let $h \\in [0,1]$ denote the probability that repair yields the drive allele via Homology-Directed Repair (HDR). With probability $(1-h)$, repair yields a resistance allele via Nonhomologous End Joining (NHEJ).\n\nModel assumptions and derivation requirements:\n- Let the adult allele frequency vector at discrete generation $t$ be $\\mathbf{f}_t = (w_t, d_t, r_t)$ with $w_t + d_t + r_t = 1$.\n- Assume random mating leading to Hardy–Weinberg genotype frequencies before gametogenesis, namely $w_t^2$ for $W W$, $d_t^2$ for $D D$, $r_t^2$ for $R R$, and $2 w_t d_t$, $2 w_t r_t$, $2 d_t r_t$ for the heterozygotes $W D$, $W R$, and $D R$, respectively.\n- Assume the CRISPR nuclease is present only in genotypes carrying the drive allele $D$. Cleavage and repair affect only the wildtype allele $W$ when paired with a drive allele in $W D$ heterozygotes during gametogenesis. Specifically, in $W D$:\n  - The $D$ allele is transmitted intact to gametes.\n  - The $W$ allele is cleaved with probability $c$; if cleaved, it becomes $D$ with probability $h$ (HDR) or becomes $R$ with probability $(1-h)$ (NHEJ). If not cleaved (probability $(1-c)$), it remains $W$.\n- No conversion occurs in $W R$, $D R$, $W W$, $D D$, or $R R$ beyond standard Mendelian segregation.\n- Let $\\mathbf{g}_t = (g_{W,t}, g_{D,t}, g_{R,t})$ be the gamete allele frequencies produced at generation $t$ by summing contributions over genotype classes as implied by the above rules. The adult allele frequencies in the next generation satisfy $\\mathbf{f}_{t+1} = \\mathbf{g}_t$ (no selection, no migration).\n- Observations: At each generation $t \\in \\{0,1,2,\\dots,T\\}$, a sample of $M_t$ chromosomes (alleles) is drawn from the adult population, producing observed counts $\\mathbf{X}_t = (X_{W,t}, X_{D,t}, X_{R,t})$ with $X_{W,t} + X_{D,t} + X_{R,t} = M_t$. Assume $\\mathbf{X}_t \\sim \\text{Multinomial}(M_t, \\mathbf{f}_t)$ independently over $t$.\n\nLikelihood framework:\n- For a candidate parameter pair $(c,h)$ and a known initial allele frequency $\\mathbf{f}_0$, the model deterministically produces $\\mathbf{f}_1, \\dots, \\mathbf{f}_T$ via the recursion. The log-likelihood (up to an additive constant that does not depend on $(c,h)$) under multinomial sampling is\n$$\n\\ell(c,h) \\propto \\sum_{t=0}^{T} \\sum_{a \\in \\{W,D,R\\}} X_{a,t} \\log f_{a,t}(c,h),\n$$\nwhere $f_{a,t}(c,h)$ is the model-predicted allele frequency of allele $a$ at time $t$ under parameters $(c,h)$.\n- You must handle zeros robustly in computation; terms with $X_{a,t} = 0$ contribute $0$ even if $f_{a,t} = 0$. Numerically, clip model probabilities to a small $\\varepsilon$ (for example, $\\varepsilon = 10^{-12}$) to avoid $\\log(0)$, which preserves the correct limit for $X_{a,t} = 0$ and penalizes parameter values that predict zero probability for observed nonzero counts.\n\nProgramming task:\n- Implement the deterministic recursion for $\\mathbf{f}_{t+1}$ from $\\mathbf{f}_t$ implied by the above biological rules, starting from a known initial $\\mathbf{f}_0$.\n- Implement a grid search over $(c,h)$ in the closed unit square (excluding exact $0$ and $1$ to avoid numerical issues) with a resolution sufficient to identify the maximum likelihood estimates at graduate-level accuracy. Use at least a step size of $0.01$ over $[0.001, 0.999]$ for both $c$ and $h$. For each grid point, compute the log-likelihood (up to an additive constant) using the observed counts and the model-predicted frequencies.\n- For each dataset in the test suite, report the maximum likelihood estimates $\\hat{c}$ and $\\hat{h}$ together with the maximized log-likelihood value. Round all three reported values to three decimal places.\n\nTest suite:\nProvide a program that solves the following three datasets. In all cases, treat the initial adult allele frequency $\\mathbf{f}_0$ as known from the founding mix; equivalently, you may take it as the normalized counts at $t=0$.\n\n- Dataset A (moderate drive, mixed repair):\n  - Time points $t = 0,1,2$ with $M_t = 200$.\n  - Observed allele counts $(W,D,R)$ by generation:\n    - $t=0$: $[180, 20, 0]$\n    - $t=1$: $[165, 29, 6]$\n    - $t=2$: $[147, 40, 13]$\n\n- Dataset B (near-no cleavage, HDR-dominant repair):\n  - Time points $t = 0,1,2$ with $M_t = 200$.\n  - Observed allele counts $(W,D,R)$ by generation:\n    - $t=0$: $[100, 100, 0]$\n    - $t=1$: $[98, 102, 0]$\n    - $t=2$: $[95, 104, 1]$\n\n- Dataset C (high cleavage, NHEJ-dominant repair generating resistance):\n  - Time points $t = 0,1,2$ with $M_t = 200$.\n  - Observed allele counts $(W,D,R)$ by generation:\n    - $t=0$: $[190, 10, 0]$\n    - $t=1$: $[181, 12, 7]$\n    - $t=2$: $[171, 14, 15]$\n\nFinal output format:\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, where each dataset’s result is itself a list of three floats $[\\hat{c}, \\hat{h}, \\widehat{\\ell}]$, rounded to three decimal places. For example:\n  - Output format: $[[\\hat{c}_A,\\hat{h}_A,\\widehat{\\ell}_A],[\\hat{c}_B,\\hat{h}_B,\\widehat{\\ell}_B],[\\hat{c}_C,\\hat{h}_C,\\widehat{\\ell}_C]]$\n- There are no physical units or angles to report. All values are dimensionless. Express any proportions or probabilities as decimals (not percentages).", "solution": "The problem is subjected to validation and is deemed valid. It presents a well-posed, scientifically grounded problem in statistical population genetics. All necessary components—the biological model, the statistical framework, and the empirical data—are provided clearly and without contradiction. The task is to infer parameters of a standard gene drive model, which is a non-trivial but standard exercise in computational biology.\n\nThe solution proceeds by first deriving the deterministic model for allele frequency dynamics, then formulating the log-likelihood function for the observed count data, and finally detailing the grid search procedure for finding the maximum likelihood estimates of the parameters.\n\nThe system involves three alleles: wild-type ($W$), drive ($D$), and resistance ($R$). Let the allele frequencies at generation $t$ be $\\mathbf{f}_t = (w_t, d_t, r_t)$, where $w_t+d_t+r_t = 1$. With random mating, the zygote genotype frequencies at the start of generation $t$ are given by Hardy-Weinberg proportions: $w_t^2$ for $WW$, $d_t^2$ for $DD$, $r_t^2$ for $RR$, $2w_td_t$ for $WD$, $2w_tr_t$ for $WR$, and $2d_tr_t$ for $DR$.\n\nThe core of the model is the gene conversion process occurring during gametogenesis exclusively in $WD$ heterozygotes. In these individuals (frequency $2w_td_t$), the $D$ allele is transmitted normally. The $W$ allele, however, is cleaved with probability $c$. If cleaved, it is repaired as a $D$ allele via Homology-Directed Repair (HDR) with probability $h$, or as an $R$ allele via Nonhomologous End Joining (NHEJ) with probability $(1-h)$. If not cleaved (probability $1-c$), it remains a $W$ allele. All other genotypes undergo standard Mendelian segregation.\n\nTo derive the allele frequencies for the next generation, $\\mathbf{f}_{t+1} = (w_{t+1}, d_{t+1}, r_{t+1})$, we sum the contributions to the gamete pool from each parental genotype class, weighted by their frequencies.\n\nThe frequency of $W$ gametes, $w_{t+1}$, is composed of contributions from:\n- $WW$ genotypes (frequency $w_t^2$): contribute $w_t^2$.\n- $WR$ genotypes (frequency $2w_tr_t$): contribute $\\frac{1}{2}(2w_tr_t) = w_tr_t$.\n- $WD$ genotypes (frequency $2w_td_t$): the $W$ allele is passed on with probability $(1-c)$. This sub-pool has size $w_td_t$. Thus, the contribution is $w_td_t(1-c)$.\nSumming these gives:\n$$w_{t+1} = w_t^2 + w_tr_t + w_td_t(1-c) = w_t(w_t+r_t+d_t) - w_t d_t c = w_t(1-cd_t)$$\n\nThe frequency of $D$ gametes, $d_{t+1}$, is composed of contributions from:\n- $DD$ genotypes (frequency $d_t^2$): contribute $d_t^2$.\n- $DR$ genotypes (frequency $2d_tr_t$): contribute $\\frac{1}{2}(2d_tr_t) = d_tr_t$.\n- $WD$ genotypes (frequency $2w_td_t$): the $D$ allele is passed on (contribution $w_td_t$), and the $W$ allele is converted to $D$ with probability $ch$ (contribution $w_td_tch$).\nSumming these gives:\n$$d_{t+1} = d_t^2 + d_tr_t + w_td_t + w_td_tch = d_t(d_t+r_t+w_t) + w_td_tch = d_t(1+chw_t)$$\n\nThe frequency of $R$ gametes, $r_{t+1}$, is composed of contributions from:\n- $RR$ genotypes (frequency $r_t^2$): contribute $r_t^2$.\n- $WR$ genotypes (frequency $2w_tr_t$): contribute $\\frac{1}{2}(2w_tr_t) = w_tr_t$.\n- $DR$ genotypes (frequency $2d_tr_t$): contribute $\\frac{1}{2}(2d_tr_t) = d_tr_t$.\n- $WD$ genotypes (frequency $2w_td_t$): the $W$ allele is converted to $R$ with probability $c(1-h)$. Contribution: $w_td_tc(1-h)$.\nSumming these gives:\n$$r_{t+1} = r_t^2 + w_tr_t + d_tr_t + w_td_tc(1-h) = r_t(r_t+w_t+d_t) + w_td_tc(1-h) = r_t + c(1-h)w_td_t$$\n\nThe state of the system is thus propagated by the deterministic recursion:\n$$ \\mathbf{f}_{t+1} = \\left( w_t(1-cd_t), \\quad d_t(1+chw_t), \\quad r_t + c(1-h)w_td_t \\right) $$\n\nThe observed data consist of allele counts $\\mathbf{X}_t = (X_{W,t}, X_{D,t}, X_{R,t})$ from samples of size $M_t$ at each generation $t$. These counts are modeled as draws from a Multinomial distribution: $\\mathbf{X}_t \\sim \\text{Multinomial}(M_t, \\mathbf{f}_t(c,h))$, where $\\mathbf{f}_t(c,h)$ is the allele frequency vector at generation $t$ predicted by the recursion for a given parameter pair $(c,h)$. The initial frequency $\\mathbf{f}_0$ is taken from the observed counts at $t=0$.\n\nThe log-likelihood of the parameters $(c,h)$ given the full time-series of counts is the sum of the log-likelihoods for each generation:\n$$ \\ell(c,h) = \\sum_{t=0}^{T} \\log P(\\mathbf{X}_t | \\mathbf{f}_t(c,h)) $$\nIgnoring constant terms that do not depend on the parameters, this is proportional to:\n$$ \\ell(c,h) \\propto \\sum_{t=0}^{T} \\sum_{a \\in \\{W,D,R\\}} X_{a,t} \\log f_{a,t}(c,h) $$\nTo avoid numerical issues with $\\log(0)$ when a predicted frequency $f_{a,t}(c,h)$ is zero for a non-zero count $X_{a,t}$, predicted frequencies are clipped to a small positive value $\\varepsilon = 10^{-12}$. This correctly imposes a large penalty on parameter values that are inconsistent with the observations.\n\nTo find the maximum likelihood estimates $(\\hat{c}, \\hat{h})$, we perform a grid search over the parameter space. The problem specifies a grid for $c$ and $h$ over the interval $[0.001, 0.999]$ with a step size of $0.01$. For each pair $(c,h)$ on this grid, the following procedure is executed for each dataset:\n1.  Initialize the allele frequencies $\\mathbf{f}_0$ from the $t=0$ count data.\n2.  Compute the theoretical frequency trajectory $\\mathbf{f}_1, \\dots, \\mathbf{f}_T$ using the recursion equations.\n3.  Calculate the total log-likelihood $\\ell(c,h)$ by summing the contributions from all time points $t=0, \\dots, T$.\n4.  The pair $(\\hat{c}, \\hat{h})$ that yields the highest log-likelihood value across the grid is retained as the maximum likelihood estimate, along with its corresponding log-likelihood value $\\widehat{\\ell}$.\nThis procedure is implemented for the three provided datasets.", "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves for the maximum likelihood estimates of gene drive parameters\n    for three datasets using a grid search.\n    \"\"\"\n    \n    # Epsilon for numerical stability to avoid log(0)\n    EPSILON = 1e-12\n\n    def get_next_gen_freqs(f_t, c, h):\n        \"\"\"\n        Calculates the allele frequencies for the next generation based on the\n        deterministic model.\n\n        Args:\n            f_t (tuple): A tuple (w, d, r) of allele frequencies at generation t.\n            c (float): The cleavage probability.\n            h (float): The HDR probability, conditional on cleavage.\n\n        Returns:\n            tuple: A tuple (w_tp1, d_tp1, r_tp1) of allele frequencies at generation t+1.\n        \"\"\"\n        w_t, d_t, r_t = f_t\n        \n        # Recursion equations derived from the model\n        w_tp1 = w_t * (1.0 - c * d_t)\n        d_tp1 = d_t * (1.0 + c * h * w_t)\n        r_tp1 = r_t + c * (1.0 - h) * w_t * d_t\n        \n        # Renormalize to ensure sum is exactly 1, correcting for potential floating point error\n        total = w_tp1 + d_tp1 + r_tp1\n        if total == 0:\n            return (0.0, 0.0, 0.0)\n        return (w_tp1 / total, d_tp1 / total, r_tp1 / total)\n\n    def calculate_log_likelihood(counts_data, c, h):\n        \"\"\"\n        Calculates the log-likelihood of the observed count data for a given \n        set of parameters (c, h).\n\n        Args:\n            counts_data (list): A list of tuples, where each tuple contains the \n                                observed allele counts (X_W, X_D, X_R) for a generation.\n            c (float): The cleavage probability.\n            h (float): The HDR probability, conditional on cleavage.\n\n        Returns:\n            float: The calculated log-likelihood value.\n        \"\"\"\n        log_likelihood = 0.0\n        \n        # Initial frequencies are derived from the first time point's counts\n        M0 = sum(counts_data[0])\n        if M0 == 0:\n            return -np.inf # Cannot start from no observations\n        f_t = (counts_data[0][0] / M0, counts_data[0][1] / M0, counts_data[0][2] / M0)\n\n        for t, counts in enumerate(counts_data):\n            # For t > 0, evolve frequencies from previous generation\n            if t > 0:\n                f_t = get_next_gen_freqs(f_t, c, h)\n\n            f_W, f_D, f_R = f_t\n            X_W, X_D, X_R = counts\n            \n            # Clip predicted frequencies to avoid log(0) and re-normalize\n            f_W_clipped = max(f_W, EPSILON)\n            f_D_clipped = max(f_D, EPSILON)\n            f_R_clipped = max(f_R, EPSILON)\n            \n            norm_factor = f_W_clipped + f_D_clipped + f_R_clipped\n            f_W_final = f_W_clipped / norm_factor\n            f_D_final = f_D_clipped / norm_factor\n            f_R_final = f_R_clipped / norm_factor\n            \n            # Sum the log-likelihood contributions for this time point\n            log_likelihood += X_W * np.log(f_W_final) + X_D * np.log(f_D_final) + X_R * np.log(f_R_final)\n            \n        return log_likelihood\n\n    # Define the test cases from the problem statement.\n    test_cases = {\n        \"A\": [\n            (180, 20, 0),\n            (165, 29, 6),\n            (147, 40, 13)\n        ],\n        \"B\": [\n            (100, 100, 0),\n            (98, 102, 0),\n            (95, 104, 1)\n        ],\n        \"C\": [\n            (190, 10, 0),\n            (181, 12, 7),\n            (171, 14, 15)\n        ]\n    }\n\n    results = []\n\n    # Define grid for parameters c and h as specified\n    c_grid = np.arange(0.001, 1.0, 0.01)\n    h_grid = np.arange(0.001, 1.0, 0.01)\n\n    # An ordered list of keys to ensure consistent output order\n    case_ids = sorted(test_cases.keys())\n\n    for case_id in case_ids:\n        counts_data = test_cases[case_id]\n        \n        max_log_likelihood = -np.inf\n        best_c = None\n        best_h = None\n        \n        # Perform grid search\n        for c in c_grid:\n            for h in h_grid:\n                current_log_likelihood = calculate_log_likelihood(counts_data, c, h)\n                \n                if current_log_likelihood > max_log_likelihood:\n                    max_log_likelihood = current_log_likelihood\n                    best_c = c\n                    best_h = h\n        \n        # Store results rounded to three decimal places\n        result = [round(best_c, 3), round(best_h, 3), round(max_log_likelihood, 3)]\n        results.append(result)\n\n    # Format the final output string exactly as required\n    output_parts = []\n    for res in results:\n        # Format each list of results: [c,h,l]\n        output_parts.append(f\"[{res[0]:.3f},{res[1]:.3f},{res[2]:.3f}]\")\n    \n    # Join the formatted lists and enclose in brackets\n    final_output = f\"[{','.join(output_parts)}]\"\n    print(final_output)\n\nsolve()\n```", "id": "2813409"}]}