{"hands_on_practices": [{"introduction": "Success in paleogenomics begins long before data analysis; it starts with meticulous experimental design. A critical first step is to estimate the required sequencing effort to achieve a desired genomic coverage, a calculation that hinges on sample-specific properties like endogenous DNA content and library complexity. This practice [@problem_id:2691892] guides you through this essential calculation, translating a target effective coverage into the total number of raw sequencing reads needed from the sequencer. Mastering this conversion is fundamental for planning cost-effective studies and ensuring that the generated data will be sufficient to address the research question at hand.", "problem": "In ancient DNA (aDNA) sequencing projects, planning the sequencing depth requires connecting expected endogenous content, duplication rate, and read length to the effective unique coverage on the target genome. Consider a single-end Illumina run with read length $75 \\ \\mathrm{bp}$ for a genome of size $3 \\times 10^{9} \\ \\mathrm{bp}$. You aim for an effective post-deduplication coverage of $0.5\\times$ on the target genome. Pilot data indicate an endogenous content of $0.05$ (that is, a fraction $0.05$ of raw reads derive from the target taxon), and library complexity suggests that $0.30$ of the endogenous reads will be marked as duplicates and removed during deduplication.\n\nAssume the following standard approximations consistent with paleogenomics practice:\n- Coverage is defined as total aligned unique on-target bases divided by the haploid genome size.\n- The endogenous fraction applies uniformly to all raw reads, and all endogenous reads map correctly with full usable length $75 \\ \\mathrm{bp}$.\n- Deduplication removes a fraction $0.30$ of endogenous reads, leaving a fraction $0.70$ of endogenous reads as unique. Contaminant reads provide no on-target coverage.\n- Losses due to adapter trimming, base quality filtering, and mapping failures beyond the above assumptions are negligible for this calculation.\n\nUnder these assumptions, compute the required number of raw reads to achieve the target effective coverage. Express your final answer as the number of reads and round to three significant figures.", "solution": "The problem statement is subjected to validation.\n\nGivens are extracted verbatim:\n- Read length: $L = 75 \\ \\mathrm{bp}$\n- Genome size: $G = 3 \\times 10^{9} \\ \\mathrm{bp}$\n- Target effective post-deduplication coverage: $C_{eff} = 0.5\\times$\n- Endogenous content: $f_{endo} = 0.05$\n- Duplicate fraction of endogenous reads: $f_{dup} = 0.30$\n- Unique fraction of endogenous reads: $1 - f_{dup} = 1 - 0.30 = 0.70$\n- Definition of coverage: Total aligned unique on-target bases divided by the haploid genome size.\n- Assumptions: Endogenous fraction is uniform; all endogenous reads map with full length $L$; deduplication removes fraction $f_{dup}$; other losses are negligible.\n- Required output: Required number of raw reads, rounded to three significant figures.\n\nValidation verdict: The problem is valid. It is scientifically grounded in the principles of genomics and sequencing analysis, providing a well-posed, objective, and self-contained quantitative question with realistic parameters. It does not violate any criteria for invalidity. The assumptions provided are standard simplifications used for such preliminary calculations in paleogenomics.\n\nThe solution proceeds as follows.\n\nLet $N_{raw}$ be the total number of raw reads required.\nThe target effective coverage, $C_{eff}$, is defined as the total number of unique, on-target bases, which we will call $B_{eff}$, divided by the genome size, $G$.\n$$C_{eff} = \\frac{B_{eff}}{G}$$\nFrom this, the total number of effective bases required to achieve the target coverage is:\n$$B_{eff} = C_{eff} \\times G$$\nNow, we must relate $B_{eff}$ to the total number of raw reads, $N_{raw}$. The process involves several steps reflecting the data processing pipeline.\n\nFirst, the total number of raw reads, $N_{raw}$, is filtered by the endogenous content fraction, $f_{endo}$, to determine the number of reads originating from the target genome, $N_{endo}$.\n$$N_{endo} = N_{raw} \\times f_{endo}$$\nSecond, these endogenous reads are subject to deduplication. A fraction $f_{dup}$ of these reads are identified as duplicates and removed. The remaining fraction of unique reads is $(1 - f_{dup})$. The number of unique endogenous reads, $N_{unique}$, is therefore:\n$$N_{unique} = N_{endo} \\times (1 - f_{dup}) = N_{raw} \\times f_{endo} \\times (1 - f_{dup})$$\nAccording to the problem's assumptions, each of these unique endogenous reads contributes its full length, $L$, to the effective base count. Thus, the total number of effective bases, $B_{eff}$, can be expressed as:\n$$B_{eff} = N_{unique} \\times L = N_{raw} \\times f_{endo} \\times (1 - f_{dup}) \\times L$$\nWe now have two expressions for $B_{eff}$. By equating them, we can construct an equation to solve for the unknown quantity, $N_{raw}$.\n$$C_{eff} \\times G = N_{raw} \\times f_{endo} \\times (1 - f_{dup}) \\times L$$\nRearranging to solve for $N_{raw}$:\n$$N_{raw} = \\frac{C_{eff} \\times G}{f_{endo} \\times (1 - f_{dup}) \\times L}$$\nNow, we substitute the given values into this expression:\n- $C_{eff} = 0.5$\n- $G = 3 \\times 10^{9}$\n- $f_{endo} = 0.05$\n- $f_{dup} = 0.30$\n- $L = 75$\n\n$$N_{raw} = \\frac{0.5 \\times (3 \\times 10^{9})}{0.05 \\times (1 - 0.30) \\times 75}$$\nWe calculate the numerator and the denominator separately.\nNumerator:\n$$0.5 \\times 3 \\times 10^{9} = 1.5 \\times 10^{9}$$\nDenominator:\n$$0.05 \\times (1 - 0.30) \\times 75 = 0.05 \\times 0.70 \\times 75 = 0.035 \\times 75 = 2.625$$\nNow, we perform the division:\n$$N_{raw} = \\frac{1.5 \\times 10^{9}}{2.625}$$\n$$N_{raw} = \\frac{1500}{2625} \\times 10^{9} = \\frac{4}{7} \\times 10^{9} \\approx 0.57142857... \\times 10^{9}$$\nTo express this in standard scientific notation, we write:\n$$N_{raw} \\approx 5.7142857... \\times 10^{8}$$\nThe problem requires the answer to be rounded to three significant figures.\n$$N_{raw} \\approx 5.71 \\times 10^{8}$$\nThis is the total number of raw sequencing reads that must be generated to meet the specified effective coverage goal under the given conditions.", "answer": "$$\\boxed{5.71 \\times 10^8}$$", "id": "2691892"}, {"introduction": "One of the most significant challenges in paleogenomics is distinguishing genuine biological variation from post-mortem DNA damage artifacts. The most common form of such damage, cytosine deamination, can generate substitutions that mimic true Single Nucleotide Polymorphisms (SNPs). This exercise [@problem_id:1468882] introduces a powerful diagnostic principle: the analysis of strand bias. By formalizing this concept into a quantitative asymmetry score, you will learn how to computationally assess whether an observed variant is a true polymorphism or a likely artifact of chemical degradation.", "problem": "In the field of paleogenomics, a significant challenge is distinguishing genuine genetic variation from post-mortem DNA damage. One of the most common forms of such damage is the deamination of cytosine (C) into uracil (U). During the Polymerase Chain Reaction (PCR) amplification process, which is necessary for studying the trace amounts of ancient DNA, DNA polymerase reads this U as a thymine (T). Consequently, a C-base in the ancient organism's DNA can be erroneously reported as a T-base by a sequencing machine, mimicking a C-to-T Single Nucleotide Polymorphism (SNP).\n\nThis issue is further complicated by the double-stranded nature of DNA. If a C on the reverse strand deaminates, its original partner on the forward strand was a guanine (G). The damaged C-to-U change on the reverse strand will be read as a T, and bioinformatic pipelines will infer its complement on the forward strand as an adenine (A). Therefore, C-deamination damage can manifest as either a C-to-T or a G-to-A substitution in the final sequence data, depending on which strand the damage occurred.\n\nA key diagnostic method to identify these damage artifacts is to check for strand bias. A true heterozygous SNP should be present on DNA fragments originating from both the forward and reverse strands. In contrast, a damage-induced substitution is a chemical artifact that is more likely to accumulate on one strand over the other at a given position.\n\nConsider a scenario where you are analyzing a single nucleotide position in an ancient DNA sample. The reference genome has a guanine (G) at this position, but your sequencing reads show a mixture of both 'G' and 'A' bases. The counts are as follows:\n- $n_{f,A}$: The number of reads aligned to the forward strand that show an 'A'.\n- $n_{f,G}$: The number of reads aligned to the forward strand that show a 'G'.\n- $n_{r,A}$: The number of reads aligned to the reverse strand that show an 'A'.\n- $n_{r,G}$: The number of reads aligned to the reverse strand that show a 'G'.\n\nTo quantify the degree of strand preference for the 'A' base, we define a custom \"Asymmetry Score\", $S_{bias}$. This score is defined as the absolute difference between the observed fraction of 'A' reads on the forward strand and the expected fraction under a no-bias assumption, all normalized by this expected fraction.\n- The observed fraction, $F_{obs}$, is the proportion of all observed 'A' reads that map to the forward strand.\n- The expected fraction, $F_{exp}$, is the proportion of all reads (of any base) that map to the forward strand. This represents the baseline expectation for the distribution of 'A' reads if they were distributed without any strand preference.\n\nThe Asymmetry Score is thus given by $S_{bias} = \\frac{|F_{obs} - F_{exp}|}{F_{exp}}$.\n\nDerive a single closed-form analytic expression for $S_{bias}$ in terms of the four measured quantities: $n_{f,A}$, $n_{f,G}$, $n_{r,A}$, and $n_{r,G}$.", "solution": "The goal is to derive a closed-form expression for the Asymmetry Score, $S_{bias}$, using the provided counts. The formula for the score is $S_{bias} = \\frac{|F_{obs} - F_{exp}|}{F_{exp}}$. We need to find expressions for $F_{obs}$ and $F_{exp}$ in terms of the given variables.\n\nFirst, let's define the intermediate total counts based on the four fundamental measurements:\n- The total number of reads showing an 'A' is $N_A = n_{f,A} + n_{r,A}$.\n- The total number of reads showing a 'G' is $N_G = n_{f,G} + n_{r,G}$.\n- The total number of reads aligned to the forward strand is $N_f = n_{f,A} + n_{f,G}$.\n- The total number of reads aligned to the reverse strand is $N_r = n_{r,A} + n_{r,G}$.\n- The total number of all reads covering this position is $N_{total} = N_f + N_r = n_{f,A} + n_{f,G} + n_{r,A} + n_{r,G}$.\n\nNow, we can formulate expressions for $F_{obs}$ and $F_{exp}$ as defined in the problem statement.\n\nStep 1: Determine the expression for $F_{obs}$.\n$F_{obs}$ is the observed fraction of all 'A' reads that are found on the forward strand. This is the number of 'A' reads on the forward strand divided by the total number of 'A' reads.\n$$F_{obs} = \\frac{n_{f,A}}{N_A} = \\frac{n_{f,A}}{n_{f,A} + n_{r,A}}$$\n\nStep 2: Determine the expression for $F_{exp}$.\n$F_{exp}$ is the expected fraction of 'A' reads on the forward strand under a no-bias assumption. The problem defines this as the overall proportion of all reads that map to the forward strand. This is the total number of forward reads divided by the total number of all reads.\n$$F_{exp} = \\frac{N_f}{N_{total}} = \\frac{n_{f,A} + n_{f,G}}{n_{f,A} + n_{f,G} + n_{r,A} + n_{r,G}}$$\n\nStep 3: Substitute the expressions for $F_{obs}$ and $F_{exp}$ into the definition of $S_{bias}$.\n$$S_{bias} = \\frac{|F_{obs} - F_{exp}|}{F_{exp}} = \\frac{\\left| \\frac{n_{f,A}}{n_{f,A} + n_{r,A}} - \\frac{n_{f,A} + n_{f,G}}{n_{f,A} + n_{f,G} + n_{r,A} + n_{r,G}} \\right|}{\\frac{n_{f,A} + n_{f,G}}{n_{f,A} + n_{f,G} + n_{r,A} + n_{r,G}}}$$\n\nStep 4: Simplify the expression. Let's start with the difference inside the absolute value in the numerator.\nTo subtract the fractions, we find a common denominator, which is $(n_{f,A} + n_{r,A})(n_{f,A} + n_{f,G} + n_{r,A} + n_{r,G})$.\n$$F_{obs} - F_{exp} = \\frac{n_{f,A}(n_{f,A} + n_{f,G} + n_{r,A} + n_{r,G}) - (n_{f,A} + n_{f,G})(n_{f,A} + n_{r,A})}{(n_{f,A} + n_{r,A})(n_{f,A} + n_{f,G} + n_{r,A} + n_{r,G})}$$\nNow, expand the numerator of this expression:\n$$n_{f,A}(n_{f,A} + n_{f,G} + n_{r,A} + n_{r,G}) = n_{f,A}^2 + n_{f,A}n_{f,G} + n_{f,A}n_{r,A} + n_{f,A}n_{r,G}$$\n$$(n_{f,A} + n_{f,G})(n_{f,A} + n_{r,A}) = n_{f,A}^2 + n_{f,A}n_{r,A} + n_{f,G}n_{f,A} + n_{f,G}n_{r,A}$$\nSubtracting the second expanded term from the first:\n$$(n_{f,A}^2 + n_{f,A}n_{f,G} + n_{f,A}n_{r,A} + n_{f,A}n_{r,G}) - (n_{f,A}^2 + n_{f,A}n_{r,A} + n_{f,G}n_{f,A} + n_{f,G}n_{r,A})$$\nThe terms $n_{f,A}^2$, $n_{f,A}n_{f,G}$, and $n_{f,A}n_{r,A}$ cancel out, leaving:\n$$n_{f,A}n_{r,G} - n_{f,G}n_{r,A}$$\nSo, the difference is:\n$$F_{obs} - F_{exp} = \\frac{n_{f,A}n_{r,G} - n_{f,G}n_{r,A}}{(n_{f,A} + n_{r,A})(n_{f,A} + n_{f,G} + n_{r,A} + n_{r,G})}$$\n\nStep 5: Substitute this simplified difference back into the expression for $S_{bias}$.\n$$S_{bias} = \\frac{\\left| \\frac{n_{f,A}n_{r,G} - n_{f,G}n_{r,A}}{(n_{f,A} + n_{r,A})(n_{f,A} + n_{f,G} + n_{r,A} + n_{r,G})} \\right|}{\\frac{n_{f,A} + n_{f,G}}{n_{f,A} + n_{f,G} + n_{r,A} + n_{r,G}}}$$\nWe can cancel the term $(n_{f,A} + n_{f,G} + n_{r,A} + n_{r,G})$ which appears in the denominator of both the numerator and the main denominator.\n$$S_{bias} = \\frac{\\frac{|n_{f,A}n_{r,G} - n_{f,G}n_{r,A}|}{n_{f,A} + n_{r,A}}}{\\frac{n_{f,A} + n_{f,G}}{1}} = \\frac{|n_{f,A}n_{r,G} - n_{f,G}n_{r,A}|}{(n_{f,A} + n_{r,A})(n_{f,A} + n_{f,G})}$$\nThis is the final simplified, closed-form expression for the Asymmetry Score.", "answer": "$$\\boxed{\\frac{|n_{f,A}n_{r,G} - n_{f,G}n_{r,A}|}{(n_{f,A} + n_{r,A})(n_{f,A} + n_{f,G})}}$$", "id": "1468882"}, {"introduction": "Having learned to identify potential damage artifacts, it is crucial to understand their impact on downstream evolutionary analyses. Uncorrected errors do not simply add noise; they can introduce systematic biases that lead to erroneous biological conclusions. This thought experiment [@problem_id:1908415] challenges you to quantify the effect of cytosine deamination on nucleotide diversity ($\\pi$), a fundamental measure of genetic variation. By calculating how damage artifacts are expected to inflate this key statistic, you will gain a deeper appreciation for the necessity of rigorous data filtering and damage modeling in paleogenomics.", "problem": "A team of paleogenomicists is studying the genetic diversity of an extinct hominin population using ancient DNA (aDNA). They have recovered partial genomic sequences from three different individuals. A key concern in aDNA studies is post-mortem chemical degradation. The most common form of damage is cytosine deamination, where a cytosine (C) base is biochemically altered and, upon sequencing using Polymerase Chain Reaction (PCR), is incorrectly read as a thymine (T). Other bases (A, G, T) are assumed to be unaffected.\n\nThe team wants to quantify how this specific type of sequencing artifact would affect their estimate of genetic diversity. They use nucleotide diversity, denoted by $\\pi$, which is defined as the average number of nucleotide differences per site between any two sequences randomly chosen from the sample. For a sample of $N$ sequences each of length $L$, the formula is:\n$$ \\pi = \\frac{1}{\\binom{N}{2}} \\sum_{i<j} \\frac{d_{ij}}{L} $$\nwhere $d_{ij}$ is the number of nucleotide sites at which sequence $i$ and sequence $j$ differ, and $\\binom{N}{2}$ is the number of distinct pairs of sequences.\n\nAssume the \"true\" (undamaged) DNA sequences for a specific 10-base-pair region from the three ancient individuals ($N=3$, $L=10$) are:\n- Individual 1: `ATCGATCGAT`\n- Individual 2: `ATCGGTCGAT`\n- Individual 3: `ATGGATCGAT`\n\nSuppose that for any given cytosine base in the ancient samples, there is a constant probability $p_d = 0.1$ that it undergoes deamination and is misread as a thymine.\n\nCalculate the ratio of the *expected* nucleotide diversity of the sequenced (damaged) sample, $\\pi_{\\text{artifact}}$, to the nucleotide diversity of the true (undamaged) sample, $\\pi_{\\text{true}}$. Express your answer for the ratio $\\frac{\\pi_{\\text{artifact}}}{\\pi_{\\text{true}}}$ as a single number, rounded to three significant figures.", "solution": "We use nucleotide diversity $\\pi$ defined by\n$$\n\\pi=\\frac{1}{\\binom{N}{2}}\\sum_{i<j}\\frac{d_{ij}}{L}.\n$$\nFor $N=3$ and $L=10$, $\\binom{3}{2}=3$, and $\\sum_{i<j}d_{ij}$ equals the sum over sites of the number of differing pairs at each site.\n\nFirst compute $\\pi_{\\text{true}}$. The three true sequences are:\n- Individual 1: ATCGATCGAT\n- Individual 2: ATCGGTCGAT\n- Individual 3: ATGGATCGAT\n\nComparing site by site, differences occur only at positions $3$ and $5$. At position $3$ (C,C,G), the differing pairs are $(1,3)$ and $(2,3)$, giving $2$ differing pairs. At position $5$ (A,G,A), the differing pairs are $(1,2)$ and $(2,3)$, giving $2$ differing pairs. All other positions contribute $0$. Thus the total number of differing pairs across all sites is\n$$\nS_{\\text{true}}=2+2=4,\n$$\nso\n$$\n\\pi_{\\text{true}}=\\frac{S_{\\text{true}}}{3L}=\\frac{4}{30}.\n$$\n\nNow compute the expected number of differing pairs after damage. Only cytosines can change, independently for each cytosine, to thymine with probability $p_{d}=p$. All other bases are unchanged.\n\n- Sites with no cytosines (positions $1,2,4,6,8,9,10$): contribute $0$ expected differing pairs (unchanged).\n- Site $5$ (A,G,A): contains no cytosine; expected differing pairs remain $2$.\n- Site $3$ (C,C,G): the G is unaffected; each C independently deaminates to T with probability $p$. Pairs involving the G, namely $(1,3)$ and $(2,3)$, always differ, contributing $2$. The pair $(1,2)$ differs if and only if exactly one of the two C deaminates, which occurs with probability $2p(1-p)$. Hence the expected differing pairs at this site are\n$$\n2+2p(1-p).\n$$\n- Site $7$ (C,C,C): each of the three C independently deaminates to T with probability $p$. Let $k$ be the number of T after damage, so $k\\sim\\text{Binomial}(3,p)$. The number of differing pairs at the site equals $k(3-k)$. Therefore\n$$\n\\mathbb{E}[\\text{differing pairs at site }7]=\\mathbb{E}[k(3-k)]=3\\mathbb{E}[k]-\\mathbb{E}[k^{2}].\n$$\nWith $\\mathbb{E}[k]=3p$ and $\\mathbb{E}[k^{2}]=\\operatorname{Var}(k)+(\\mathbb{E}[k])^{2}=3p(1-p)+(3p)^{2}$, we obtain\n$$\n3(3p)-\\left(3p(1-p)+(3p)^{2}\\right)=6p-6p^{2}=6p(1-p).\n$$\n\nSumming the expected differing pairs across all sites gives\n$$\nS_{\\text{artifact}}^{\\text{exp}}=\\bigl(2+2p(1-p)\\bigr)+2+6p(1-p)=4+8p(1-p).\n$$\nTherefore,\n$$\n\\pi_{\\text{artifact}}=\\frac{S_{\\text{artifact}}^{\\text{exp}}}{30}=\\frac{4+8p(1-p)}{30}.\n$$\nThe ratio is\n$$\n\\frac{\\pi_{\\text{artifact}}}{\\pi_{\\text{true}}}=\\frac{\\frac{4+8p(1-p)}{30}}{\\frac{4}{30}}=\\frac{4+8p(1-p)}{4}=1+2p(1-p).\n$$\nSubstituting $p=0.1$ yields\n$$\n1+2(0.1)(1-0.1)=1+2(0.1)(0.9)=1+0.18=1.18.\n$$\nRounded to three significant figures, the ratio is $1.18$.", "answer": "$$\\boxed{1.18}$$", "id": "1908415"}]}