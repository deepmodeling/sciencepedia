{"hands_on_practices": [{"introduction": "A Genome-Wide Association Study (GWAS) involves simultaneously testing millions of genetic variants, creating a massive multiple testing problem. To avoid a flood of false-positive results, a stringent statistical threshold is required. This exercise provides a foundational, hands-on calculation of the Bonferroni-corrected significance threshold, making concrete the reason behind the conventional genome-wide significance level of $p < 5 \\times 10^{-8}$ and introducing a core statistical principle essential for interpreting any GWAS paper [@problem_id:1494362].", "problem": "A team of geneticists is conducting a Genome-Wide Association Study (GWAS) to identify genetic markers associated with a newly discovered complex disorder. A GWAS involves scanning the genomes of many individuals to determine if any specific genetic variants are more frequent in people with the disease compared to a control group. The genetic variants being analyzed in this study are Single Nucleotide Polymorphisms (SNPs).\n\nIn this particular study, the researchers are simultaneously testing $m = 1,000,000$ independent SNPs for a statistical association with the disorder. Conventionally, for a single statistical test, a $p$-value threshold ($\\alpha$ level) for significance is set at $\\alpha = 0.05$. However, performing such a large number of tests significantly inflates the probability of obtaining at least one \"false positive\" result (a Type I error) purely by chance.\n\nTo counteract this multiple testing problem, the research team decides to control the Family-Wise Error Rate (FWER), defined as the probability of making one or more Type I errors among all the tests performed. They aim to keep the FWER at or below 0.05. To achieve this, they will apply the Bonferroni correction to their significance threshold.\n\nGiven the number of independent SNPs being tested and the desired FWER, calculate the new, Bonferroni-corrected p-value threshold that a single SNP must meet to be considered statistically significant. Express your answer in scientific notation.", "solution": "The family-wise error rate under the Bonferroni procedure satisfies the Bonferroni inequality:\n$$\n\\text{FWER} \\leq \\sum_{i=1}^{m} \\alpha_{i}.\n$$\nIf each of the $m$ tests is conducted at the same per-test significance level $\\alpha^{*}$, then\n$$\n\\text{FWER} \\leq m \\alpha^{*}.\n$$\nTo control the FWER at the desired level $\\alpha$, choose $\\alpha^{*}$ such that\n$$\nm \\alpha^{*} \\leq \\alpha \\quad \\Rightarrow \\quad \\alpha^{*} = \\frac{\\alpha}{m}.\n$$\nWith $\\alpha = 0.05$ and $m = 1{,}000{,}000 = 10^{6}$, write $0.05 = 5 \\times 10^{-2}$ and compute\n$$\n\\alpha^{*} = \\frac{5 \\times 10^{-2}}{10^{6}} = 5 \\times 10^{-2-6} = 5 \\times 10^{-8}.\n$$\nThus, the Bonferroni-corrected p-value threshold is $5 \\times 10^{-8}$.", "answer": "$$\\boxed{5 \\times 10^{-8}}$$", "id": "1494362"}, {"introduction": "The validity of any GWAS finding hinges on the quality of the underlying genetic data. Systematic genotyping errors can mimic true genetic associations, leading to spurious conclusions. This practice problem moves from statistical theory to practical data quality control (QC) by implementing an exact test for Hardy-Weinberg Equilibrium (HWE), a cornerstone of genetic QC pipelines. By writing the code to filter out SNPs that fail this test, you will gain hands-on experience with a critical step that ensures the integrity of GWAS results before association testing even begins [@problem_id:2394652].", "problem": "You are given the task of constructing a program that implements a quality control filter for a Genome-Wide Association Study (GWAS). The filter must detect and mark single-nucleotide polymorphisms (SNPs) in control samples that show a statistically significant deviation from Hardy-Weinberg equilibrium (HWE). A SNP is biallelic with alleles denoted by $A$ and $a$. For each SNP, you are provided the genotype counts in controls: $n_{AA}$ for homozygous $AA$, $n_{Aa}$ for heterozygous $Aa$, and $n_{aa}$ for homozygous $aa$. Let $n = n_{AA} + n_{Aa} + n_{aa}$ denote the number of control individuals.\n\nUnder the null hypothesis of Hardy-Weinberg equilibrium (HWE), the population is assumed to arise from random mating given the underlying allele frequencies. Consider the exact conditional test for HWE that conditions on the total number of copies of one allele in the sample. Let there be $2n$ chromosomal positions and let $r$ denote the number of copies of the rarer allele among these $2n$ positions. Assume that every allocation of the $r$ rarer-allele copies to the $2n$ chromosomal positions is equally likely under the null hypothesis. Define the two-sided exact $p$-value for a given observed genotype configuration as the sum of the conditional probabilities of all genotype configurations that have the same total allele count and are at least as unlikely as the observed configuration under the null hypothesis.\n\nFor each SNP, use the following decision rule: remove the SNP (mark it as $1$) if the exact two-sided HWE $p$-value is strictly less than the given significance level $\\alpha$, otherwise keep it (mark it as $0$).\n\nImplement a single program that applies this rule to the following test suite of independent SNPs, each specified as a tuple $(n_{AA}, n_{Aa}, n_{aa}, \\alpha)$:\n\n- Test $1$: $(50, 20, 30, 10^{-6})$, i.e., $n_{AA} = 50$, $n_{Aa} = 20$, $n_{aa} = 30$, $\\alpha = 10^{-6}$.\n- Test $2$: $(36, 48, 16, 10^{-6})$, i.e., $n_{AA} = 36$, $n_{Aa} = 48$, $n_{aa} = 16$, $\\alpha = 10^{-6}$.\n- Test $3$: $(100, 0, 0, 10^{-6})$, i.e., $n_{AA} = 100$, $n_{Aa} = 0$, $n_{aa} = 0$, $\\alpha = 10^{-6}$.\n- Test $4$: $(18, 2, 0, 0.05)$, i.e., $n_{AA} = 18$, $n_{Aa} = 2$, $n_{aa} = 0$, $\\alpha = 0.05$.\n- Test $5$: $(0, 10, 0, 0.01)$, i.e., $n_{AA} = 0$, $n_{Aa} = 10$, $n_{aa} = 0$, $\\alpha = 0.01$.\n- Test $6$: $(405, 90, 5, 0.05)$, i.e., $n_{AA} = 405$, $n_{Aa} = 90$, $n_{aa} = 5$, $\\alpha = 0.05$.\n\nYour program should produce a single line of output containing the results as a comma-separated list of integers enclosed in square brackets, in the same order as the tests above, where each entry is $1$ if the SNP is to be removed and $0$ otherwise. For example, a valid output format is $[1,0,1]$ (this is only an example of formatting, not the correct answers).", "solution": "The user-provided problem is subjected to rigorous validation.\n\nStep 1: Extract Givens\n- **Task**: Implement a quality control filter for a Genome-Wide Association Study (GWAS) to remove single-nucleotide polymorphisms (SNPs) that deviate from Hardy-Weinberg Equilibrium (HWE).\n- **Model**: SNPs are biallelic with alleles $A$ and $a$.\n- **Input Data**: For each SNP, genotype counts are given: $n_{AA}$, $n_{Aa}$, $n_{aa}$.\n- **Total Sample Size**: $n = n_{AA} + n_{Aa} + n_{aa}$.\n- **Statistical Test**: A two-sided exact conditional test for HWE.\n- **Conditioning**: The test is conditional on the total observed counts of each allele.\n- **Null Hypothesis ($H_0$)**: The genotype counts follow HWE. Under $H_0$, any allocation of the $r$ rarer-allele copies to the $2n$ chromosomal positions is equally likely.\n- **P-value Definition**: The sum of conditional probabilities of all genotype configurations that have the same total allele count and are at least as unlikely as the observed configuration.\n- **Decision Rule**: Remove SNP (mark as $1$) if $p < \\alpha$; otherwise, keep SNP (mark as $0$).\n- **Test Cases**:\n    - Test 1: $(n_{AA}=50, n_{Aa}=20, n_{aa}=30, \\alpha=10^{-6})$\n    - Test 2: $(n_{AA}=36, n_{Aa}=48, n_{aa}=16, \\alpha=10^{-6})$\n    - Test 3: $(n_{AA}=100, n_{Aa}=0, n_{aa}=0, \\alpha=10^{-6})$\n    - Test 4: $(n_{AA}=18, n_{Aa}=2, n_{aa}=0, \\alpha=0.05)$\n    - Test 5: $(n_{AA}=0, n_{Aa}=10, n_{aa}=0, \\alpha=0.01)$\n    - Test 6: $(n_{AA}=405, n_{Aa}=90, n_{aa}=5, \\alpha=0.05)$\n- **Output Format**: A single line with a comma-separated list of results, e.g., `[1,0,1]`.\n\nStep 2: Validate Using Extracted Givens\n- **Scientifically Grounded**: The problem is valid. It describes the implementation of the HWE exact test, a standard and fundamental statistical procedure in population genetics and bioinformatics, often used for quality control in GWAS. The concepts of alleles, genotypes, and HWE are cornerstones of genetics.\n- **Well-Posed**: The problem is valid. It provides all necessary components: input data ($n_{AA}, n_{Aa}, n_{aa}, \\alpha$), the specific statistical test to use (conditional exact test), a precise definition for the $p$-value, and a clear decision rule. This structure allows for a unique, computable solution for each test case.\n- **Objective**: The problem is valid. It is formulated using objective, technical language devoid of subjectivity or ambiguity.\n\nStep 3: Verdict and Action\nThe problem is scientifically sound, well-posed, and objective. It is **valid**. A solution will be constructed.\n\n---\n\nThe problem requires the implementation of an exact test for Hardy-Weinberg Equilibrium (HWE). This test is a standard procedure for quality control in genetic studies, as significant deviations from HWE can indicate genotyping errors. The solution involves calculating a two-sided $p$-value for a given set of observed genotype counts and comparing it to a significance level $\\alpha$.\n\nLet the observed genotype counts for a biallelic SNP be $n_{AA}$, $n_{Aa}$, and $n_{aa}$. The total number of individuals in the sample is $n = n_{AA} + n_{Aa} + n_{aa}$. The counts of the two alleles, which we denote as $A$ and $a$, are:\n- Number of $A$ alleles: $N_A = 2n_{AA} + n_{Aa}$\n- Number of $a$ alleles: $N_a = 2n_{aa} + n_{Aa}$\nThe total number of alleles in the sample is $2n = N_A + N_a$.\n\nThe exact test for HWE is conditional on the observed allele counts, $N_A$ and $N_a$. Under the null hypothesis of HWE, we can conceptualize the $2n$ alleles in the sample as being randomly paired to form $n$ diploid individuals. Keeping the allele counts $N_A$ and $N_a$ fixed restricts the possible genotype configurations. Specifically, if we know the number of heterozygotes, $n_{Aa}$, the counts of homozygotes are determined:\n$$ n_{AA} = \\frac{N_A - n_{Aa}}{2} $$\n$$ n_{aa} = \\frac{N_a - n_{Aa}}{2} $$\nSince $n_{AA}$ and $n_{aa}$ must be non-negative integers, the number of heterozygotes, $n_{Aa}$, uniquely defines the genotype counts for a fixed $N_A$ and $N_a$. The probability of observing a specific count of heterozygotes, $k$, given the allele counts, follows a specific probability distribution derived from combinatorial arguments. The probability mass function (PMF) is:\n$$ P(n_{Aa} = k | n, N_A, N_a) = \\frac{n! N_A! N_a! 2^k}{(2n)! n_{AA_k}! k! n_{aa_k}!} $$\nwhere $n_{AA_k} = (N_A - k)/2$ and $n_{aa_k} = (N_a - k)/2$.\n\nThe range of possible values for $k$ (the support of the distribution) is determined by the constraints that genotype counts must be non-negative integers.\n1.  $k \\geq 0$\n2.  $n_{AA_k} \\geq 0 \\implies k \\leq N_A$\n3.  $n_{aa_k} \\geq 0 \\implies k \\leq N_a$\n4.  Furthermore, for $n_{AA_k}$ and $n_{aa_k}$ to be integers, $(N_A - k)$ and $(N_a - k)$ must be even. This implies that $k$ must have the same parity (even or odd) as $N_A$ and $N_a$. Note that $N_A$ and $N_a$ always have the same parity because their sum, $2n$, is even.\n\nThe two-sided $p$-value is defined as the sum of probabilities of all possible configurations that are as probable or less probable than the observed configuration. Let the observed heterozygote count be $n_{Aa,obs}$. The probability of this observation is $P_{obs} = P(n_{Aa} = n_{Aa,obs})$. The $p$-value is then:\n$$ p = \\sum_{k \\in \\text{support}} P(n_{Aa} = k) \\quad \\text{such that} \\quad P(n_{Aa} = k) \\leq P_{obs} $$\n\nThe calculation involves factorials of large numbers, which can lead to numerical overflow or underflow. To maintain precision, computations should be performed in log-space. The logarithm of the PMF is:\n$$ \\ln P(k) = \\ln(n!) + \\ln(N_A!) + \\ln(N_a!) + k\\ln(2) - \\ln((2n)!) - \\ln(n_{AA_k}!) - \\ln(k!) - \\ln(n_{aa_k}!) $$\nThe log-factorial, $\\ln(x!)$, can be computed using the log-gamma function, `gammaln`, as $\\ln(x!) = \\text{gammaln}(x+1)$.\n\nThe algorithm proceeds as follows for each test case:\n1.  Calculate $n, N_A, N_a$ from the input genotype counts $n_{AA,obs}, n_{Aa,obs}, n_{aa,obs}$.\n2.  Handle the trivial case where the SNP is monomorphic (i.e., $N_A=0$ or $N_a=0$). In this situation, only one genotype configuration is possible, its probability is $1$, and thus the $p$-value is $1$.\n3.  Determine the support for $n_{Aa}$: iterate from the minimum possible value (0 or 1, depending on parity) to the maximum possible value, $\\min(N_A, N_a)$, with a step of $2$.\n4.  Calculate the log-probability of the observed configuration, $\\ln(P_{obs})$.\n5.  Initialize the $p$-value to $0$. Iterate through all possible values $k$ in the support. For each $k$, calculate its log-probability, $\\ln(P_k)$.\n6.  If $\\ln(P_k) \\leq \\ln(P_{obs})$, add the probability $P_k = \\exp(\\ln(P_k))$ to the total $p$-value.\n7.  Finally, compare the calculated $p$-value with the given significance level $\\alpha$. If $p < \\alpha$, the result is $1$ (remove). Otherwise, the result is $0$ (keep).\n\nThis procedure is implemented for each of the specified test cases to produce the final output.", "answer": "```python\nimport numpy as np\nfrom scipy.special import gammaln\n\ndef solve():\n    \"\"\"\n    Main solver function to process the test suite for Hardy-Weinberg Equilibrium.\n    \"\"\"\n    test_cases = [\n        (50, 20, 30, 1e-6),\n        (36, 48, 16, 1e-6),\n        (100, 0, 0, 1e-6),\n        (18, 2, 0, 0.05),\n        (0, 10, 0, 0.01),\n        (405, 90, 5, 0.05),\n    ]\n\n    results = []\n    for n_AA, n_Aa, n_aa, alpha in test_cases:\n        p_value = calculate_hwe_exact_p_value(n_AA, n_Aa, n_aa)\n        if p_value < alpha:\n            results.append(1)\n        else:\n            results.append(0)\n\n    # Format output as a comma-separated list of integers in square brackets.\n    print(f\"[{','.join(map(str, results))}]\")\n\ndef calculate_hwe_exact_p_value(n_AA_obs, n_Aa_obs, n_aa_obs):\n    \"\"\"\n    Calculates the two-sided exact p-value for Hardy-Weinberg Equilibrium.\n\n    Args:\n        n_AA_obs (int): Observed count of homozygous genotype AA.\n        n_Aa_obs (int): Observed count of heterozygous genotype Aa.\n        n_aa_obs (int): Observed count of homozygous genotype aa.\n\n    Returns:\n        float: The calculated p-value.\n    \"\"\"\n    n = n_AA_obs + n_Aa_obs + n_aa_obs\n    if n == 0:\n        return 1.0\n\n    n_A = 2 * n_AA_obs + n_Aa_obs\n    n_a = 2 * n_aa_obs + n_Aa_obs\n    \n    # If the SNP is monomorphic, HWE is trivially satisfied.\n    if n_A == 0 or n_a == 0:\n        return 1.0\n\n    # Determine the range of possible heterozygote counts\n    n_het_min = 0 if n_A % 2 == 0 else 1\n    n_het_max = min(n_A, n_a)\n\n    # Pre-calculate the constant part of the log-probability\n    log_const_term = (gammaln(n + 1) + gammaln(n_A + 1) + gammaln(n_a + 1) -\n                      gammaln(2 * n + 1))\n    \n    log_probs = {}\n    \n    # Calculate log-probability for all possible heterozygote counts\n    for k in range(n_het_min, n_het_max + 1, 2):\n        n_AA_k = (n_A - k) / 2\n        n_aa_k = (n_a - k) / 2\n        \n        # Ensure counts are valid integers, though the loop structure should guarantee this\n        if n_AA_k < 0 or n_aa_k < 0 or n_AA_k != int(n_AA_k) or n_aa_k != int(n_aa_k):\n            continue\n            \n        log_prob = (log_const_term + k * np.log(2) -\n                    gammaln(n_AA_k + 1) - gammaln(k + 1) - gammaln(n_aa_k + 1))\n        log_probs[k] = log_prob\n\n    # Find the log-probability of the observed configuration\n    # If observed het count is impossible given allele counts, its prob is 0.\n    if n_Aa_obs not in log_probs:\n        # This case should not happen with valid inputs. \n        # If it did, p-value would cover all possible outcomes, so 1.0.\n        return 1.0 \n    \n    log_p_obs = log_probs[n_Aa_obs]\n\n    # Calculate the p-value by summing probabilities of configurations\n    # that are as likely or less likely than the observed one.\n    p_value = 0.0\n    for k, log_p_k in log_probs.items():\n        if log_p_k <= log_p_obs:\n            p_value += np.exp(log_p_k)\n            \n    # Clamp p-value to ensure it is within [0, 1] due to potential floating point inaccuracies\n    return max(0.0, min(1.0, p_value))\n\nsolve()\n```", "id": "2394652"}, {"introduction": "Beyond identifying individual genetic variants, a primary goal of modern genetics is to predict an individual's risk for complex traits. This is achieved by creating a Polygenic Risk Score (PRS), which aggregates the effects of many variants across the genome. This advanced simulation exercise guides you through the entire process, from generating a synthetic GWAS dataset to building a PRS and evaluating its predictive power. This practice provides a capstone experience, illustrating how to translate GWAS summary statistics into a clinically and scientifically valuable predictive tool [@problem_id:2394707].", "problem": "You are given the task of constructing a polygenic risk score (PRS) within a simulated genome-wide association study (GWAS) setting and evaluating its predictive accuracy as a function of a single-nucleotide polymorphism (SNP) inclusion threshold. The goal is to define, compute, and report the squared predictive correlation for several parameter configurations.\n\nDefinitions and setting:\n\n- Genome-Wide Association Study (GWAS) examines associations between genetic variants and a trait. Consider $m$ single-nucleotide polymorphisms (SNPs), each with a minor allele frequency (MAF). For each SNP $j \\in \\{1,\\ldots,m\\}$, the genotype for an individual is encoded as the count of minor alleles in $\\{0,1,2\\}$.\n- For each SNP $j$, draw its MAF $p_j$ independently from the continuous uniform distribution on $[0.05, 0.5]$. Under Hardy–Weinberg equilibrium, simulate each genotype entry as an independent draw from $\\mathrm{Binomial}(2, p_j)$.\n- Split the sample into a training cohort of size $n_{\\text{train}}$ and a testing cohort of size $n_{\\text{test}}$. Let $\\mathbf{G}_{\\text{train}} \\in \\mathbb{R}^{n_{\\text{train}} \\times m}$ and $\\mathbf{G}_{\\text{test}} \\in \\mathbb{R}^{n_{\\text{test}} \\times m}$ be the corresponding genotype matrices.\n- Standardize SNP columns using the training cohort statistics: for each SNP $j$, compute the training mean $\\mu_j$ and standard deviation $\\sigma_j$ of column $j$ in $\\mathbf{G}_{\\text{train}}$. Define standardized matrices $\\mathbf{X}_{\\text{train}}$ and $\\mathbf{X}_{\\text{test}}$ via\n  $$X_{\\text{train}}[i,j] = \\begin{cases}\n  \\dfrac{G_{\\text{train}}[i,j] - \\mu_j}{\\sigma_j} & \\text{if } \\sigma_j > 0,\\\\\n  0 & \\text{if } \\sigma_j = 0,\n  \\end{cases}\n  \\qquad\n  X_{\\text{test}}[i,j] = \\begin{cases}\n  \\dfrac{G_{\\text{test}}[i,j] - \\mu_j}{\\sigma_j} & \\text{if } \\sigma_j > 0,\\\\\n  0 & \\text{if } \\sigma_j = 0.\n  \\end{cases}$$\n  If $\\sigma_j = 0$, treat the standardized column as identically $0$ in both cohorts.\n- Choose $k$ causal SNP indices uniformly without replacement from $\\{1,\\ldots,m\\}$; define the true effect vector $\\boldsymbol{\\beta}^{\\star} \\in \\mathbb{R}^m$ such that $\\beta^{\\star}_j = 0$ for non-causal $j$ and raw causal effects are drawn independently as $\\mathcal{N}(0,1)$.\n- Let the narrow-sense heritability be $h^2 \\in [0,1]$. Scale the raw effect vector to achieve training genetic variance equal to $h^2$ as follows. Compute the genetic component in training $\\mathbf{g}_{\\text{train}} = \\mathbf{X}_{\\text{train}} \\boldsymbol{\\beta}_{\\text{raw}}$, its variance $v_g = \\mathrm{Var}(\\mathbf{g}_{\\text{train}})$, and set\n  $$\\boldsymbol{\\beta}^{\\star} = \\begin{cases}\n  \\boldsymbol{\\beta}_{\\text{raw}} \\sqrt{\\dfrac{h^2}{v_g}} & \\text{if } v_g > 0,\\\\\n  \\mathbf{0} & \\text{if } v_g = 0.\n  \\end{cases}$$\n  Define the environmental noise variance as $\\sigma_e^2 = 1 - h^2$.\n- Generate phenotypes in both cohorts by\n  $$\\mathbf{y}_{\\text{train}} = \\mathbf{X}_{\\text{train}} \\boldsymbol{\\beta}^{\\star} + \\boldsymbol{\\varepsilon}_{\\text{train}}, \\quad \\boldsymbol{\\varepsilon}_{\\text{train}} \\sim \\mathcal{N}(\\mathbf{0}, \\sigma_e^2 \\mathbf{I}),$$\n  $$\\mathbf{y}_{\\text{test}} = \\mathbf{X}_{\\text{test}} \\boldsymbol{\\beta}^{\\star} + \\boldsymbol{\\varepsilon}_{\\text{test}}, \\quad \\boldsymbol{\\varepsilon}_{\\text{test}} \\sim \\mathcal{N}(\\mathbf{0}, \\sigma_e^2 \\mathbf{I}).$$\n- Perform univariate association in the training cohort for each SNP $j$ by fitting a linear model with intercept, and let $p_j$ be the two-sided $p$-value for the null hypothesis that the slope for SNP $j$ equals $0$. Equivalently, if $r_j$ denotes the Pearson correlation between column $j$ of $\\mathbf{X}_{\\text{train}}$ and $\\mathbf{y}_{\\text{train}}$, with degrees of freedom $\\nu = n_{\\text{train}} - 2$, define the $t$-statistic\n  $$t_j = \\frac{r_j}{\\sqrt{1 - r_j^2}} \\sqrt{\\nu},$$\n  and the two-sided $p$-value\n  $$p_j = 2 \\, \\mathbb{P}\\left(T_{\\nu} \\ge |t_j|\\right),$$\n  where $T_{\\nu}$ is a Student's $t$-distributed random variable with $\\nu$ degrees of freedom. If the variance of SNP $j$ in training is zero or the variance of $\\mathbf{y}_{\\text{train}}$ is zero, set $p_j = 1$.\n- For a given threshold $p_T \\in (0,1]$, define the included SNP set $S(p_T) = \\{j \\in \\{1,\\ldots,m\\} \\mid p_j \\le p_T\\}$. Let $\\hat{\\beta}_j$ be the univariate ordinary least squares slope for SNP $j$ estimated in the training cohort (with intercept). Define the test-set PRS at threshold $p_T$ by\n  $$\\mathrm{PRS}_{\\text{test}}(p_T) = \\sum_{j \\in S(p_T)} \\hat{\\beta}_j \\, X_{\\text{test}}[:,j].$$\n  If $S(p_T)$ is empty, define $\\mathrm{PRS}_{\\text{test}}(p_T)$ to be the zero vector.\n- Define predictive accuracy as the coefficient of determination on the test cohort,\n  $$R^2(p_T) = \\left(\\mathrm{Corr}\\left(\\mathrm{PRS}_{\\text{test}}(p_T), \\mathbf{y}_{\\text{test}}\\right)\\right)^2,$$\n  where $\\mathrm{Corr}$ denotes the Pearson correlation. If either $\\mathrm{PRS}_{\\text{test}}(p_T)$ or $\\mathbf{y}_{\\text{test}}$ has zero variance in the test cohort, set $R^2(p_T) = 0$.\n\nTask:\n\n- For each parameter set in the test suite below, perform the above simulation and analysis using the provided random seed. For each specified list of thresholds, compute $R^2(p_T)$ for each $p_T$ in the given order.\n- Report each $R^2(p_T)$ rounded to $6$ decimal places.\n\nTest suite:\n\n- Case A: seed $= 42$, $n_{\\text{train}} = 1500$, $n_{\\text{test}} = 1000$, $m = 3000$, $k = 150$, $h^2 = 0.5$, thresholds $= \\left[10^{-8}, 10^{-5}, 10^{-3}, 10^{-2}, 10^{-1}, 5 \\times 10^{-1}, 1\\right]$.\n- Case B: seed $= 7$, $n_{\\text{train}} = 300$, $n_{\\text{test}} = 300$, $m = 1500$, $k = 50$, $h^2 = 0.5$, thresholds $= \\left[10^{-20}, 10^{-5}, 10^{-3}, 10^{-2}, 10^{-1}, 1\\right]$.\n- Case C: seed $= 2023$, $n_{\\text{train}} = 800$, $n_{\\text{test}} = 800$, $m = 2000$, $k = 0$, $h^2 = 0.0$, thresholds $= \\left[10^{-5}, 10^{-3}, 10^{-2}, 10^{-1}, 1\\right]$.\n- Case D: seed $= 99$, $n_{\\text{train}} = 1200$, $n_{\\text{test}} = 800$, $m = 2500$, $k = 100$, $h^2 = 0.8$, thresholds $= \\left[10^{-8}, 10^{-6}, 10^{-4}, 10^{-2}, 1\\right]$.\n\nEdge-case conventions:\n\n- If any SNP column has zero variance in the training cohort, set its standardized values to zero in both cohorts, its estimated effect $\\hat{\\beta}_j$ to $0$, and its $p_j$ to $1$.\n- If the training phenotypic variance is zero, set all $\\hat{\\beta}_j = 0$ and all $p_j = 1$.\n- If the test PRS or test phenotype has zero variance, set $R^2(p_T) = 0$ for that threshold.\n\nFinal output specification:\n\n- Your program should produce a single line of output containing the results as a comma-separated list of lists, with no spaces, in the following format:\n  - For each case, output the list $\\left[R^2(p_{T,1}), R^2(p_{T,2}), \\ldots \\right]$ for its thresholds in the given order, rounding each entry to $6$ decimal places.\n  - Aggregate the four cases in order A, B, C, D into a single list, yielding a nested list. For example: $\\left[[r_{A,1},r_{A,2}], [r_{B,1},r_{B,2}], [r_{C,1},r_{C,2}], [r_{D,1},r_{D,2}]\\right]$.", "solution": "The problem presented is a comprehensive and valid simulation study in statistical genetics, specifically concerning genome-wide association studies (GWAS) and polygenic risk scores (PRS). The task is to implement the specified simulation pipeline, which is scientifically grounded in the standard polygenic model of complex traits, and to evaluate the predictive accuracy of the resulting PRS. All parameters and procedures are well-defined, making the problem objective and algorithmically tractable. I shall proceed with a detailed explanation of the methodology, followed by its implementation.\n\nThe overall process can be decomposed into several logical stages: data simulation, association analysis, PRS construction, and evaluation.\n\nFirst, we simulate the genetic and phenotypic data for two distinct cohorts: a training cohort of size $n_{\\text{train}}$ and a testing cohort of size $n_{\\text{test}}$. We consider a genome of $m$ single-nucleotide polymorphisms (SNPs). For each SNP $j$, its minor allele frequency (MAF), denoted $p_j$, is drawn from a uniform distribution $\\mathrm{Uniform}(0.05, 0.5)$. Under the assumption of Hardy–Weinberg equilibrium, the genotype for each individual at SNP $j$, which is the count of minor alleles, is an independent random draw from a Binomial distribution, $\\mathrm{Binomial}(2, p_j)$. This process generates the raw genotype matrices $\\mathbf{G}_{\\text{train}}$ and $\\mathbf{G}_{\\text{test}}$.\n\nThe raw genotype counts are not typically used directly in analysis. Instead, they are standardized. For each SNP $j$, we compute its mean $\\mu_j$ and standard deviation $\\sigma_j$ using only the training data. These statistics are then used to standardize the genotype matrices for both cohorts:\n$$X_{\\text{train}}[i,j] = \\frac{G_{\\text{train}}[i,j] - \\mu_j}{\\sigma_j} \\quad \\text{and} \\quad X_{\\text{test}}[i,j] = \\frac{G_{\\text{test}}[i,j] - \\mu_j}{\\sigma_j}$$\nA crucial edge case is when a SNP has zero variance in the training cohort ($\\sigma_j = 0$). In this situation, the SNP is non-informative, and its standardized values are set to $0$ in both cohorts.\n\nNext, we establish the ground truth for our simulation by defining a genetic architecture for the trait. We randomly select $k$ out of the $m$ SNPs to be \"causal\". The true genetic effect vector, $\\boldsymbol{\\beta}^{\\star} \\in \\mathbb{R}^m$, has non-zero entries only for these causal SNPs. The initial raw effects for these $k$ SNPs are drawn from a standard normal distribution, $\\mathcal{N}(0,1)$. These raw effects, $\\boldsymbol{\\beta}_{\\text{raw}}$, are then scaled to satisfy a specified narrow-sense heritability, $h^2$. Heritability represents the proportion of phenotypic variance attributable to genetic variance. We calculate the genetic component in the training set as $\\mathbf{g}_{\\text{train}} = \\mathbf{X}_{\\text{train}} \\boldsymbol{\\beta}_{\\text{raw}}$ and its variance $v_g = \\mathrm{Var}(\\mathbf{g}_{\\text{train}})$. The final, scaled effect vector is:\n$$\\boldsymbol{\\beta}^{\\star} = \\boldsymbol{\\beta}_{\\text{raw}} \\sqrt{\\frac{h^2}{v_g}}$$\nThis scaling ensures that the variance of the true genetic component in the training data, $\\mathrm{Var}(\\mathbf{X}_{\\text{train}} \\boldsymbol{\\beta}^{\\star})$, is precisely $h^2$. If $v_g=0$, $\\boldsymbol{\\beta}^{\\star}$ is the zero vector. The total phenotypic variance is normalized to $1$, so the variance of the environmental noise is $\\sigma_e^2 = 1 - h^2$. The phenotypes are then generated for both cohorts using the linear model:\n$$\\mathbf{y}_{\\text{train}} = \\mathbf{X}_{\\text{train}} \\boldsymbol{\\beta}^{\\star} + \\boldsymbol{\\varepsilon}_{\\text{train}}, \\quad \\text{where} \\quad \\boldsymbol{\\varepsilon}_{\\text{train}} \\sim \\mathcal{N}(\\mathbf{0}, \\sigma_e^2 \\mathbf{I})$$\n$$\\mathbf{y}_{\\text{test}} = \\mathbf{X}_{\\text{test}} \\boldsymbol{\\beta}^{\\star} + \\boldsymbol{\\varepsilon}_{\\text{test}}, \\quad \\text{where} \\quad \\boldsymbol{\\varepsilon}_{\\text{test}} \\sim \\mathcal{N}(\\mathbf{0}, \\sigma_e^2 \\mathbf{I})$$\n\nWith the simulated training data $(\\mathbf{X}_{\\text{train}}, \\mathbf{y}_{\\text{train}})$ in hand, we perform a GWAS. For each SNP $j$, we test the null hypothesis of no association with the phenotype. This is done by fitting a univariate linear model. The strength of association is quantified by a $t$-statistic. Let $r_j$ be the Pearson correlation between the $j$-th SNP vector $\\mathbf{X}_{\\text{train}}[:,j]$ and the phenotype vector $\\mathbf{y}_{\\text{train}}$. The $t$-statistic is:\n$$t_j = \\frac{r_j}{\\sqrt{1 - r_j^2}} \\sqrt{\\nu}$$\nwhere $\\nu = n_{\\text{train}} - 2$ are the degrees of freedom. The two-sided $p$-value, $p_j$, is then computed from the Student's $t$-distribution: $p_j = 2 \\, \\mathbb{P}(T_{\\nu} \\ge |t_j|)$, where $T_{\\nu}$ is a random variable following the $t$-distribution with $\\nu$ degrees of freedom. In parallel, we estimate the univariate ordinary least squares (OLS) effect size, $\\hat{\\beta}_j$, for each SNP. For a standardized predictor, this slope can be efficiently calculated.\n\nThe next step is to construct the PRS for the test set. Based on a specified $p$-value threshold, $p_T$, we form a set of included SNPs, $S(p_T) = \\{j \\mid p_j \\le p_T\\}$. The PRS is the weighted sum of the standardized genotypes in the test cohort, where the weights are the estimated effect sizes $\\hat{\\beta}_j$ from the training GWAS:\n$$\\mathrm{PRS}_{\\text{test}}(p_T) = \\sum_{j \\in S(p_T)} \\hat{\\beta}_j \\, X_{\\text{test}}[:,j]$$\nIf no SNPs meet the threshold, $S(p_T)$ is empty and the PRS is a vector of zeros.\n\nFinally, we evaluate the predictive accuracy of the PRS. This is measured by the coefficient of determination, $R^2$, which is the squared Pearson correlation between the predicted PRS and the actual phenotypes in the test cohort:\n$$R^2(p_T) = \\left(\\mathrm{Corr}\\left(\\mathrm{PRS}_{\\text{test}}(p_T), \\mathbf{y}_{\\text{test}}\\right)\\right)^2$$\nIf either the PRS or the test phenotype has zero variance, the correlation is undefined, and $R^2(p_T)$ is set to $0$.\n\nThe algorithm will systematically execute this entire pipeline for each parameter set provided in the test suite. Vectorized computations using `numpy` will be employed for efficiency, particularly for the GWAS summary statistics and PRS calculation. The random seed for each case ensures the reproducibility of the stochastic simulation. The final output will be the calculated $R^2(p_T)$ values, rounded and formatted as specified.", "answer": "```python\nimport numpy as np\nfrom scipy.stats import t as student_t\n\ndef run_simulation(seed, n_train, n_test, m, k, h2, thresholds):\n    \"\"\"\n    Performs a single GWAS/PRS simulation run for a given set of parameters.\n    \"\"\"\n    rng = np.random.default_rng(seed)\n    \n    # 1. Simulate MAFs and Genotypes\n    mafs = rng.uniform(0.05, 0.5, size=m)\n    g_train = rng.binomial(2, mafs, size=(n_train, m))\n    g_test = rng.binomial(2, mafs, size=(n_test, m))\n    \n    # 2. Standardize Genotypes\n    mu_train = np.mean(g_train, axis=0)\n    sigma_train = np.std(g_train, axis=0)\n    \n    std_is_zero = (sigma_train == 0)\n    \n    x_train = np.zeros_like(g_train, dtype=float)\n    x_test = np.zeros_like(g_test, dtype=float)\n    \n    non_zero_std_indices = ~std_is_zero\n    \n    # Use np.divide with where clause to avoid runtime warnings\n    if np.any(non_zero_std_indices):\n        x_train[:, non_zero_std_indices] = np.divide(\n            g_train[:, non_zero_std_indices] - mu_train[non_zero_std_indices],\n            sigma_train[non_zero_std_indices]\n        )\n        x_test[:, non_zero_std_indices] = np.divide(\n            g_test[:, non_zero_std_indices] - mu_train[non_zero_std_indices],\n            sigma_train[non_zero_std_indices]\n        )\n\n    # 3. Simulate True Effects and Scale by Heritability\n    beta_raw = np.zeros(m)\n    if k > 0:\n        causal_indices = rng.choice(m, size=k, replace=False)\n        beta_raw[causal_indices] = rng.normal(0, 1, size=k)\n    \n    g_train_component = x_train @ beta_raw\n    v_g = np.var(g_train_component)\n    \n    beta_star = np.zeros(m)\n    if v_g > 0 and h2 > 0:\n        scaling_factor = np.sqrt(h2 / v_g)\n        beta_star = beta_raw * scaling_factor\n    \n    # 4. Simulate Phenotypes\n    sigma_e2 = 1.0 - h2\n    sigma_e = np.sqrt(sigma_e2) if sigma_e2 > 0 else 0.0\n    \n    y_train = x_train @ beta_star + rng.normal(0, sigma_e, size=n_train)\n    y_test = x_test @ beta_star + rng.normal(0, sigma_e, size=n_test)\n    \n    # 5. Perform GWAS in Training Cohort\n    hat_betas = np.zeros(m)\n    p_values = np.ones(m)\n    \n    y_train_var = np.var(y_train, ddof=1)\n    if y_train_var == 0:\n        # If y_train has no variance, all betas are 0 and p-values are 1.\n        # This is handled by hat_betas and p_values being pre-initialized.\n        pass\n    else:\n        y_train_c = y_train - np.mean(y_train)\n        \n        # OLS slope estimates (beta_hat)\n        sum_x_sq = np.sum(x_train**2, axis=0)\n        valid_snps_for_beta = (sum_x_sq > 0)\n        \n        if np.any(valid_snps_for_beta):\n            hat_betas[valid_snps_for_beta] = (x_train[:, valid_snps_for_beta].T @ y_train_c) / sum_x_sq[valid_snps_for_beta]\n        \n        # Pearson correlations (r)\n        # r = beta_hat * (std_x / std_y)\n        std_x_train_sample = np.std(x_train, axis=0, ddof=1)\n        std_y_train_sample = np.sqrt(y_train_var)\n        \n        correlations = np.zeros(m)\n        valid_snps_for_corr = (std_x_train_sample > 0)\n        if np.any(valid_snps_for_corr):\n            correlations[valid_snps_for_corr] = hat_betas[valid_snps_for_corr] * (std_x_train_sample[valid_snps_for_corr] / std_y_train_sample)\n\n        # Handle perfect correlation case to avoid division by zero in t-statistic\n        correlations = np.clip(correlations, -1.0 + 1e-15, 1.0 - 1e-15)\n\n        # t-statistics and p-values\n        df = n_train - 2\n        if df > 0:\n            t_stats = (correlations / np.sqrt(1 - correlations**2)) * np.sqrt(df)\n            p_values = 2 * student_t.sf(np.abs(t_stats), df)\n            \n            # SNPs with zero variance in training must have p-value of 1\n            p_values[std_is_zero] = 1.0\n\n    # 6. Calculate PRS and R^2 for each threshold\n    r2_results = []\n    y_test_var = np.var(y_test)\n    \n    for p_t in thresholds:\n        included_snps_mask = (p_values <= p_t)\n        \n        if not np.any(included_snps_mask) or y_test_var == 0:\n            r2_results.append(0.0)\n            continue\n        \n        hat_betas_selected = hat_betas[included_snps_mask]\n        x_test_selected = x_test[:, included_snps_mask]\n        \n        prs_test = x_test_selected @ hat_betas_selected\n        \n        prs_var = np.var(prs_test)\n        \n        if prs_var == 0:\n            r2_results.append(0.0)\n            continue\n            \n        corr_matrix = np.corrcoef(prs_test, y_test)\n        corr = corr_matrix[0, 1]\n        \n        r2 = corr**2\n        r2_results.append(np.round(r2, 6))\n        \n    return r2_results\n\n\ndef solve():\n    test_cases = [\n        {'seed': 42, 'n_train': 1500, 'n_test': 1000, 'm': 3000, 'k': 150, 'h2': 0.5, 'thresholds': [1e-8, 1e-5, 1e-3, 1e-2, 1e-1, 5e-1, 1]},\n        {'seed': 7, 'n_train': 300, 'n_test': 300, 'm': 1500, 'k': 50, 'h2': 0.5, 'thresholds': [1e-20, 1e-5, 1e-3, 1e-2, 1e-1, 1]},\n        {'seed': 2023, 'n_train': 800, 'n_test': 800, 'm': 2000, 'k': 0, 'h2': 0.0, 'thresholds': [1e-5, 1e-3, 1e-2, 1e-1, 1]},\n        {'seed': 99, 'n_train': 1200, 'n_test': 800, 'm': 2500, 'k': 100, 'h2': 0.8, 'thresholds': [1e-8, 1e-6, 1e-4, 1e-2, 1]}\n    ]\n\n    all_results = []\n    for case in test_cases:\n        results = run_simulation(\n            seed=case['seed'],\n            n_train=case['n_train'],\n            n_test=case['n_test'],\n            m=case['m'],\n            k=case['k'],\n            h2=case['h2'],\n            thresholds=case['thresholds']\n        )\n        all_results.append(results)\n    \n    # Format the final output string exactly as required\n    output_str = str(all_results).replace(\" \", \"\")\n    print(output_str)\n\nsolve()\n```", "id": "2394707"}]}