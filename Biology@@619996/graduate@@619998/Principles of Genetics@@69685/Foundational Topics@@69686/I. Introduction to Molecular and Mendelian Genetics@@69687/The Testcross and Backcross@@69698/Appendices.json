{"hands_on_practices": [{"introduction": "A solid grasp of genetic analysis begins with the ability to predict outcomes from first principles. This exercise challenges you to derive the expected genotypic frequencies in a classic dihybrid testcross, starting only with Mendel's foundational laws of segregation and independent assortment. Mastering this derivation ensures a deep understanding of how these principles combine to produce predictable patterns of inheritance, a cornerstone for analyzing more complex genetic scenarios [@problem_id:2860525].", "problem": "A diploid organism carries two loci, denoted by alleles $A/a$ and $B/b$. Consider a single individual with genotype $A\\!aB\\!b$ in coupling phase (haplotypes $AB$ and $ab$). This individual is testcrossed to a homozygous recessive $a\\!abb$ tester. Assume the following foundational conditions hold: (i) Mendel’s law of segregation at each locus, so that alleles at a locus separate equally into gametes, (ii) Mendel’s law of independent assortment between the two loci (no linkage and no crossover interference beyond that implied by independence), and (iii) equal viability and fertility of all gametes and zygotes, with no segregation distortion or selection.\n\nStarting only from these foundational conditions and the definition of a testcross (cross to a double homozygous recessive), first derive the expected gamete distribution produced by the $A\\!aB\\!b$ parent and then the resulting expected genotype distribution among the testcross progeny.\n\nUsing the derived progeny distribution, determine the expected proportion of testcross progeny that are heterozygous at exactly one of the two loci. Express your final answer as a single reduced fraction. Do not include any units. No rounding is required.", "solution": "The problem as stated is subjected to validation against the required criteria.\n\nFirst, the givens are extracted verbatim:\n1.  A diploid organism carries two loci, with alleles $A/a$ and $B/b$.\n2.  A single individual has genotype $A\\!aB\\!b$ in coupling phase (haplotypes $AB$ and $ab$).\n3.  This individual is testcrossed to a homozygous recessive $a\\!abb$ tester.\n4.  Condition (i): Mendel’s law of segregation at each locus holds.\n5.  Condition (ii): Mendel’s law of independent assortment between the two loci holds.\n6.  Condition (iii): Equal viability and fertility of all gametes and zygotes, with no segregation distortion or selection.\n7.  The task is to derive the gamete distribution from the $A\\!aB\\!b$ parent, then the genotype distribution of the testcross progeny, and finally determine the proportion of progeny heterozygous at exactly one locus.\n\nThe problem is now validated.\nIt is **scientifically grounded**, based on the foundational principles of Mendelian genetics. It is **well-posed**, as it provides all necessary information and conditions for a unique, stable solution. The terminology is precise and **objective**. The problem is a standard, fundamental exercise in genetics, requiring derivation from first principles, and is therefore neither trivial nor ill-posed. All conditions are internally consistent. The problem is deemed valid.\n\nThe solution proceeds as follows.\n\nThe problem requires a derivation starting from the foundational conditions provided. We begin by determining the gamete distribution produced by the heterozygous parent with genotype $A\\!aB\\!b$.\n\nAccording to Condition (i), the law of segregation, the alleles at a single locus separate into gametes such that half of the gametes receive one allele and the other half receive the other.\nFor the first locus, the genotype is $A\\!a$. The probability of a gamete receiving the $A$ allele is $P(A) = \\frac{1}{2}$, and the probability of receiving the $a$ allele is $P(a) = \\frac{1}{2}$.\nFor the second locus, the genotype is $B\\!b$. The probability of a gamete receiving the $B$ allele is $P(B) = \\frac{1}{2}$, and the probability of receiving the $b$ allele is $P(b) = \\frac{1}{2}$.\n\nAccording to Condition (ii), the law of independent assortment, the segregation of alleles for the first locus occurs independently of the segregation of alleles for the second locus. This allows us to calculate the probabilities of the four possible gamete haplotypes by multiplying the probabilities of the constituent alleles.\nThe expected proportion of gamete type $AB$ is $P(AB) = P(A) \\times P(B) = \\frac{1}{2} \\times \\frac{1}{2} = \\frac{1}{4}$.\nThe expected proportion of gamete type $Ab$ is $P(Ab) = P(A) \\times P(b) = \\frac{1}{2} \\times \\frac{1}{2} = \\frac{1}{4}$.\nThe expected proportion of gamete type $aB$ is $P(aB) = P(a) \\times P(B) = \\frac{1}{2} \\times \\frac{1}{2} = \\frac{1}{4}$.\nThe expected proportion of gamete type $ab$ is $P(ab) = P(a) \\times P(b) = \\frac{1}{2} \\times \\frac{1}{2} = \\frac{1}{4}$.\n\nThus, the gamete distribution from the $A\\!aB\\!b$ parent is $1/4$ $AB$, $1/4$ $Ab$, $1/4$ $aB$, and $1/4$ $ab$. The information that the parent is in coupling phase ($AB/ab$) is consistent with this result, as independent assortment is equivalent to a recombination frequency of $50\\%$, which produces equal frequencies of parental ($AB$, $ab$) and recombinant ($Ab$, $aB$) gametes.\n\nNext, we consider the testcross. The $A\\!aB\\!b$ individual is crossed with a homozygous recessive tester of genotype $a\\!abb$. This tester parent, being homozygous at both loci, can only produce one type of gamete: $ab$, with a frequency of $1$.\n\nThe genotypes of the progeny are determined by the fusion of gametes from the two parents. We can determine the expected genotype distribution in the progeny by considering the combination of each gamete from the $A\\!aB\\!b$ parent with the single gamete type from the $a\\!abb$ tester.\n1.  Gamete $AB$ (from parent 1) $\\times$ Gamete $ab$ (from parent 2) $\\rightarrow$ Progeny genotype $A\\!aB\\!b$. The expected frequency is $P(A\\!aB\\!b) = P(AB) \\times P(ab) = \\frac{1}{4} \\times 1 = \\frac{1}{4}$.\n2.  Gamete $Ab$ (from parent 1) $\\times$ Gamete $ab$ (from parent 2) $\\rightarrow$ Progeny genotype $A\\!abb$. The expected frequency is $P(A\\!abb) = P(Ab) \\times P(ab) = \\frac{1}{4} \\times 1 = \\frac{1}{4}$.\n3.  Gamete $aB$ (from parent 1) $\\times$ Gamete $ab$ (from parent 2) $\\rightarrow$ Progeny genotype $a\\!aB\\!b$. The expected frequency is $P(a\\!aB\\!b) = P(aB) \\times P(ab) = \\frac{1}{4} \\times 1 = \\frac{1}{4}$.\n4.  Gamete $ab$ (from parent 1) $\\times$ Gamete $ab$ (from parent 2) $\\rightarrow$ Progeny genotype $a\\!abb$. The expected frequency is $P(a\\!abb) = P(ab) \\times P(ab) = \\frac{1}{4} \\times 1 = \\frac{1}{4}$.\n\nThe resulting expected genotype distribution among the testcross progeny is therefore $\\frac{1}{4} A\\!aB\\!b$, $\\frac{1}{4} A\\!abb$, $\\frac{1}{4} a\\!aB\\!b$, and $\\frac{1}{4} a\\!abb$.\n\nThe final step is to determine the proportion of progeny that are heterozygous at exactly one of the two loci. We examine each progeny genotype:\n-   $A\\!aB\\!b$: Heterozygous at locus A ($A\\!a$) and locus B ($B\\!b$). It is heterozygous at two loci.\n-   $A\\!abb$: Heterozygous at locus A ($A\\!a$) but homozygous at locus B ($bb$). It is heterozygous at exactly one locus.\n-   $a\\!aB\\!b$: Homozygous at locus A ($aa$) but heterozygous at locus B ($B\\!b$). It is heterozygous at exactly one locus.\n-   $a\\!abb$: Homozygous at locus A ($aa$) and locus B ($bb$). It is heterozygous at zero loci.\n\nThe progeny genotypes that satisfy the condition of being heterozygous at exactly one locus are $A\\!abb$ and $a\\!aB\\!b$. The total expected proportion of such progeny is the sum of their individual proportions:\n$$ \\text{Proportion} = P(A\\!abb) + P(a\\!aB\\!b) = \\frac{1}{4} + \\frac{1}{4} = \\frac{2}{4} $$\nThis fraction reduces to its simplest form.\n$$ \\frac{2}{4} = \\frac{1}{2} $$\nTherefore, the expected proportion of testcross progeny that are heterozygous at exactly one of the two loci is $\\frac{1}{2}$.", "answer": "$$\\boxed{\\frac{1}{2}}$$", "id": "2860525"}, {"introduction": "While Mendelian principles provide a baseline, real genetic data requires statistical evaluation. This practice introduces the Logarithm of the Odds (LOD) score, a pivotal tool in gene mapping for quantifying the evidence for linkage against the null hypothesis of independent assortment. By deriving the LOD score expression from a binomial sampling model, you will gain insight into how geneticists rigorously test hypotheses and build genetic maps from testcross data [@problem_id:2860533].", "problem": "A diploid organism is analyzed in a classical testcross/backcross design: an individual doubly heterozygous at two codominant marker loci, written as $A B / a b$, is crossed to a doubly homozygous recessive tester $a b / a b$. Progeny are classified as recombinant if they carry $A b$ or $a B$, and as nonrecombinant if they carry $A B$ or $a b$. Assume meioses are independent, segregation is Mendelian with no viability biases, and there is no chromatid interference. Let $R$ denote the observed number of recombinant progeny out of a total of $N$ scored progeny in this testcross.\n\nStarting from the binomial sampling model for the count of recombinants in a testcross with recombination fraction $r$, and from the definition of the logarithm of the odds (LOD) score as the base-$10$ logarithm of a likelihood ratio, do the following:\n\n- Define precisely the LOD score that compares the null model of no linkage ($r = 0.5$) to the alternative model evaluated at the maximum likelihood recombination fraction $\\hat{r}$ consistent with the constraint $0 \\le r \\le 0.5$.\n- Derive an explicit expression for this LOD score in terms of $R$, $N$, and $\\hat{r}$, making clear why the combinatorial factor cancels in the likelihood ratio.\n- Using your derived expression, compute the LOD score for $R = 40$ recombinants out of $N = 100$ progeny. Round your numerical answer to four significant figures. Express the final answer as a pure number with no units.", "solution": "The problem as stated is scientifically sound, self-contained, and well-posed. It describes a standard procedure in statistical genetics and requests a derivation and calculation based on established principles. We shall proceed directly to the solution.\n\nThe experimental setup is a testcross designed to measure the recombination fraction, $r$, between two gene loci. The number of recombinant progeny, $R$, observed out of a total of $N$ progeny, is a random variable. Under the assumptions of Mendelian segregation, no viability biases, and independent meioses, the count $R$ follows a binomial distribution with parameters $N$ and $r$. The probability of observing exactly $R$ recombinants is given by the probability mass function:\n$$P(R | N, r) = \\binom{N}{R} r^{R} (1-r)^{N-R}$$\nWhen the data, specifically the values of $N$ and $R$, are observed, this expression, viewed as a function of the unknown parameter $r$, is known as the likelihood function, denoted $\\mathcal{L}(r; N, R)$.\n$$\\mathcal{L}(r; N, R) = \\binom{N}{R} r^{R} (1-r)^{N-R}$$\n\nThe problem requires the calculation of a logarithm of the odds (LOD) score. The LOD score is a statistical test used for linkage analysis, defined as the base-$10$ logarithm of a likelihood ratio. This ratio compares the likelihood of the data under two competing hypotheses.\n\nThe null hypothesis, $H_0$, is that of no linkage between the loci. For genes on different chromosomes or very far apart on the same chromosome, they assort independently, which corresponds to a recombination fraction of $r_0 = 0.5$.\n\nThe alternative hypothesis, $H_A$, is that of linkage, meaning $r < 0.5$. The problem specifies that this hypothesis is to be evaluated at the maximum likelihood estimate (MLE) of the recombination fraction, denoted $\\hat{r}$, which is consistent with the physical constraint that $0 \\le r \\le 0.5$.\n\nThe LOD score is therefore defined as:\n$$\\text{LOD} = \\log_{10} \\left( \\frac{\\mathcal{L}(\\hat{r}; N, R)}{\\mathcal{L}(r_0; N, R)} \\right) = \\log_{10} \\left( \\frac{\\mathcal{L}(\\hat{r})}{\\mathcal{L}(0.5)} \\right)$$\n\nLet us substitute the expression for the likelihood function into this ratio:\n$$\\frac{\\mathcal{L}(\\hat{r})}{\\mathcal{L}(0.5)} = \\frac{\\binom{N}{R} \\hat{r}^{R} (1-\\hat{r})^{N-R}}{\\binom{N}{R} (0.5)^{R} (1-0.5)^{N-R}}$$\n\nThe combinatorial factor $\\binom{N}{R}$ represents the number of ways to arrange $R$ recombinant outcomes among $N$ total progeny. This term is a constant with respect to the parameter $r$. Since we are evaluating the likelihood of the same observed data ($N, R$) under different values of the parameter $r$, this combinatorial factor appears in both the numerator and the denominator of the likelihood ratio. Consequently, it cancels out. This cancellation is a general feature of likelihood ratio tests where the same parametric family of distributions is used for both hypotheses.\n\nAfter cancellation, the likelihood ratio simplifies to:\n$$\\frac{\\mathcal{L}(\\hat{r})}{\\mathcal{L}(0.5)} = \\frac{\\hat{r}^{R} (1-\\hat{r})^{N-R}}{(0.5)^{R} (0.5)^{N-R}} = \\frac{\\hat{r}^{R} (1-\\hat{r})^{N-R}}{(0.5)^{N}}$$\n\nThe LOD score is the base-$10$ logarithm of this expression. Using the properties of logarithms, we derive the explicit expression for the LOD score in terms of $R$, $N$, and $\\hat{r}$:\n$$\\text{LOD} = \\log_{10} \\left( \\frac{\\hat{r}^{R} (1-\\hat{r})^{N-R}}{0.5^{N}} \\right)$$\n$$\\text{LOD} = \\log_{10}(\\hat{r}^{R}) + \\log_{10}((1-\\hat{r})^{N-R}) - \\log_{10}(0.5^{N})$$\n$$\\text{LOD} = R \\log_{10}(\\hat{r}) + (N-R) \\log_{10}(1-\\hat{r}) - N \\log_{10}(0.5)$$\nThis is the required general expression.\n\nNext, we must find the MLE, $\\hat{r}$. The unconstrained MLE is found by maximizing $\\mathcal{L}(r)$, or equivalently its logarithm, $\\ln(\\mathcal{L}(r))$.\n$$\\ln(\\mathcal{L}(r)) = \\ln\\binom{N}{R} + R\\ln(r) + (N-R)\\ln(1-r)$$\nDifferentiating with respect to $r$ and setting the result to zero gives the unconstrained estimate $r_{unc}$:\n$$\\frac{d}{dr}\\ln(\\mathcal{L}(r)) = \\frac{R}{r} - \\frac{N-R}{1-r} = 0 \\implies R(1-r) = (N-R)r \\implies R = Nr \\implies r_{unc} = \\frac{R}{N}$$\nThe problem imposes the constraint $0 \\le r \\le 0.5$. The likelihood function is maximized at $r = R/N$. If $R/N > 0.5$, the function is monotonically increasing on the interval $[0, 0.5]$, so its maximum on this interval is at the boundary, $r=0.5$. Thus, the constrained MLE is:\n$$\\hat{r} = \\min\\left(\\frac{R}{N}, 0.5\\right)$$\n\nWe are given the data $R=40$ recombinants out of $N=100$ total progeny. We first compute $\\hat{r}$:\n$$\\frac{R}{N} = \\frac{40}{100} = 0.4$$\nSince $0.4 \\le 0.5$, the maximum likelihood estimate is $\\hat{r} = 0.4$.\n\nWe now substitute $N=100$, $R=40$, and $\\hat{r}=0.4$ into our derived expression for the LOD score:\n$$\\text{LOD} = 40 \\log_{10}(0.4) + (100-40) \\log_{10}(1-0.4) - 100 \\log_{10}(0.5)$$\n$$\\text{LOD} = 40 \\log_{10}(0.4) + 60 \\log_{10}(0.6) - 100 \\log_{10}(0.5)$$\nUsing precise values for the logarithms:\n$\\log_{10}(0.4) \\approx -0.397940$\n$\\log_{10}(0.6) \\approx -0.221849$\n$\\log_{10}(0.5) \\approx -0.301030$\n\nSubstituting these values:\n$$\\text{LOD} \\approx 40(-0.397940) + 60(-0.221849) - 100(-0.301030)$$\n$$\\text{LOD} \\approx -15.91760 + (-13.31094) + 30.10300$$\n$$\\text{LOD} \\approx -29.22854 + 30.10300$$\n$$\\text{LOD} \\approx 0.87446$$\nRounding the result to four significant figures, as requested, we obtain $0.8745$.\nA positive LOD score provides evidence in favor of linkage over the hypothesis of no linkage. In this case, the evidence is present but not considered statistically significant by conventional thresholds (typically, a LOD score of $3.0$ is required to formally declare linkage).", "answer": "$$\\boxed{0.8745}$$", "id": "2860533"}, {"introduction": "Modern genetic datasets are often large, complex, and imperfect, containing missing information and genotyping errors. This advanced exercise introduces the Hidden Markov Model (HMM) as a powerful framework for inferring the true sequence of inherited alleles despite these challenges. By applying the forward-backward algorithm, you will practice a core technique in computational genetics used to calculate the most probable genotypes, bridging the gap between theoretical recombination models and practical data analysis [@problem_id:2860505].", "problem": "In a three-locus testcross, a single heterozygous parent at each locus transmits either the paternal-type allele or the maternal-type allele to each offspring, while the tester parent is homozygous recessive at all loci. Let the ordered markers be $A \\text{--} B \\text{--} C$ on the same chromosome in that order. Assume the following:\n\n- The meiosis in the heterozygous parent proceeds under the standard no-interference model such that the indicator of whether a recombination event occurs between adjacent loci is Bernoulli with parameter equal to the recombination fraction, and adjacent intervals are conditionally independent given the underlying crossover process. Consequently, the transmitted allele type along loci forms a first-order Markov chain.\n- At each locus $i \\in \\{A,B,C\\}$, define a hidden state $X_i \\in \\{P,M\\}$ indicating whether the transmitted allele from the heterozygous parent is paternal-type ($P$) or maternal-type ($M$). Under Mendelian segregation with no imprinting, $P(X_A=P)=P(X_A=M)=\\tfrac{1}{2}$.\n- Between adjacent loci, the recombination fractions are $r_{AB}=0.10$ and $r_{BC}=0.20$. With these, the transition probabilities are $P(X_{i+1}=X_i)=1-r_{i,i+1}$ and $P(X_{i+1}\\neq X_i)=r_{i,i+1}$.\n- At each locus, the observed marker call $Y_i \\in \\{\\text{calls }P,\\ \\text{calls }M,\\ \\text{missing}\\}$ is conditionally independent across loci given the hidden states. Given $X_i$, the emission model has a symmetric genotyping error rate $e=0.01$: $P(Y_i=\\text{calls }P \\mid X_i=P)=1-e$, $P(Y_i=\\text{calls }P \\mid X_i=M)=e$, $P(Y_i=\\text{calls }M \\mid X_i=M)=1-e$, and $P(Y_i=\\text{calls }M \\mid X_i=P)=e$. If $Y_i$ is missing, assume missingness is independent of $X_i$ and all else, so $P(Y_i=\\text{missing} \\mid X_i=x)$ is the same for both $x \\in \\{P,M\\}$ and thus contributes a multiplicative factor that cancels in posterior ratios; you may take the corresponding emission factor to be $1$ for both states.\n\nYou observe $Y_A=\\text{calls }P$, $Y_B=\\text{missing}$, and $Y_C=\\text{calls }M$ for a single offspring.\n\nTasks:\n1) Formalize this as a Hidden Markov Model (HMM), explicitly specifying the state space, initial distribution, transition model in terms of recombination fractions, and emission model in terms of the genotyping error rate and missingness.\n2) Starting only from conditional independence implied by the HMM factorization and the Markov property derived from the no-interference recombination model, derive the recursive forward and backward relations for the joint partial likelihoods $ \\alpha_i(x) := P(Y_A,\\dots,Y_i, X_i=x)$ and $ \\beta_i(x) := P(Y_{i+1},\\dots,Y_C \\mid X_i=x)$, and then derive the expression for the posterior $P(X_i=x \\mid Y_A,\\dots,Y_C)$ in terms of $ \\alpha_i$ and $ \\beta_i$.\n3) Using your derived recursions, compute the posterior probability $P(X_B=P \\mid Y_A=\\text{calls }P,\\, Y_B=\\text{missing},\\, Y_C=\\text{calls }M)$ for the given numerical values $r_{AB}=0.10$, $r_{BC}=0.20$, and $e=0.01$. Round your final numerical answer to four significant figures. Express your answer as a pure decimal (no percent sign).", "solution": "The problem statement is evaluated to be scientifically grounded, well-posed, objective, and self-contained. It describes a standard application of a Hidden Markov Model (HMM) to genetic data analysis, using established principles of Mendelian genetics, recombination, and statistical modeling. All necessary parameters are provided, and the tasks are clearly defined and solvable. Therefore, the problem is valid and a full solution can be constructed.\n\nThe problem requires a three-part solution: formalizing the HMM, deriving the forward-backward algorithm, and computing a specific posterior probability.\n\nTask 1: Formalization of the Hidden Markov Model\n\nThe system is modeled as a Hidden Markov Model with $3$ time steps corresponding to the loci $A$, $B$, and $C$.\n\n- **State Space**: At each locus $i \\in \\{A, B, C\\}$, the hidden state $X_i$ represents the parental origin of the transmitted allele. The state space is $\\mathcal{S} = \\{P, M\\}$, where $P$ denotes the paternal-type allele and $M$ denotes the maternal-type allele.\n\n- **Initial State Distribution ($\\pi$)**: The probability distribution for the state at the first locus, $X_A$, is given by Mendelian segregation principles.\n$$ \\pi_P = P(X_A=P) = \\frac{1}{2} $$\n$$ \\pi_M = P(X_A=M) = \\frac{1}{2} $$\n\n- **Transition Model ($T$)**: The state transitions from locus $i$ to locus $i+1$ are governed by the recombination fraction $r_{i,i+1}$. The transition probability $P(X_{i+1}=x' \\mid X_i=x)$ is the probability of the state transitioning from $x$ to $x'$. A recombination event corresponds to a state change ($X_{i+1} \\neq X_i$), which occurs with probability $r_{i,i+1}$. No recombination corresponds to the state remaining the same ($X_{i+1} = X_i$), which occurs with probability $1-r_{i,i+1}$.\nThe transition matrix from locus $i$ to $i+1$ is:\n$$ T_{i,i+1} = \\begin{pmatrix} P(X_{i+1}=P \\mid X_i=P) & P(X_{i+1}=M \\mid X_i=P) \\\\ P(X_{i+1}=P \\mid X_i=M) & P(X_{i+1}=M \\mid X_i=M) \\end{pmatrix} = \\begin{pmatrix} 1-r_{i,i+1} & r_{i,i+1} \\\\ r_{i,i+1} & 1-r_{i,i+1} \\end{pmatrix} $$\nFor this problem, the specific transition matrices are:\n$$ T_{A,B} = \\begin{pmatrix} 1-r_{AB} & r_{AB} \\\\ r_{AB} & 1-r_{AB} \\end{pmatrix} = \\begin{pmatrix} 1-0.10 & 0.10 \\\\ 0.10 & 1-0.10 \\end{pmatrix} = \\begin{pmatrix} 0.90 & 0.10 \\\\ 0.10 & 0.90 \\end{pmatrix} $$\n$$ T_{B,C} = \\begin{pmatrix} 1-r_{BC} & r_{BC} \\\\ r_{BC} & 1-r_{BC} \\end{pmatrix} = \\begin{pmatrix} 1-0.20 & 0.20 \\\\ 0.20 & 1-0.20 \\end{pmatrix} = \\begin{pmatrix} 0.80 & 0.20 \\\\ 0.20 & 0.80 \\end{pmatrix} $$\n\n- **Emission Model ($E$)**: The emission probability $P(Y_i=y \\mid X_i=x)$ is the probability of observing marker call $y$ given the true hidden state $x$. Let $e=0.01$ be the genotyping error rate. The observations are $Y_i \\in \\{\\text{calls }P, \\text{calls }M, \\text{missing}\\}$. The emission probabilities for a given locus $i$ are:\n  - $P(Y_i=\\text{calls }P \\mid X_i=P) = 1-e$\n  - $P(Y_i=\\text{calls }M \\mid X_i=P) = e$\n  - $P(Y_i=\\text{calls }P \\mid X_i=M) = e$\n  - $P(Y_i=\\text{calls }M \\mid X_i=M) = 1-e$\n  - $P(Y_i=\\text{missing} \\mid X_i=P) = 1$\n  - $P(Y_i=\\text{missing} \\mid X_i=M) = 1$ (as specified in the problem)\n\nTask 2: Derivation of the Forward-Backward Recursions\n\nThe forward-backward algorithm provides a method for computing posterior probabilities of hidden states. We derive the recursions for the forward variable $\\alpha_i(x)$ and the backward variable $\\beta_i(x)$. Let the sequence of observations be $Y = (Y_A, \\dots, Y_C)$.\n\n- **Forward Variable $\\alpha_i(x)$**: Defined as the joint probability of the observations up to locus $i$ and the state at locus $i$ being $x$.\n$$ \\alpha_i(x) := P(Y_A, \\dots, Y_i, X_i=x) $$\n  - **Initialization (at locus $A$)**:\n    $$ \\alpha_A(x) = P(Y_A, X_A=x) = P(Y_A \\mid X_A=x) P(X_A=x) $$\n  - **Recursion (from locus $i$ to $i+1$)**:\n    $$ \\alpha_{i+1}(x_{i+1}) = P(Y_A, \\dots, Y_{i+1}, X_{i+1}=x_{i+1}) $$\n    By marginalizing over the previous state $X_i$:\n    $$ \\alpha_{i+1}(x_{i+1}) = \\sum_{x_i \\in \\mathcal{S}} P(Y_A, \\dots, Y_{i+1}, X_i=x_i, X_{i+1}=x_{i+1}) $$\n    Using conditional independence properties of HMMs:\n    \\begin{align*} \\alpha_{i+1}(x_{i+1}) &= \\sum_{x_i \\in \\mathcal{S}} P(Y_{i+1} \\mid X_{i+1}=x_{i+1}) P(X_{i+1}=x_{i+1} \\mid X_i=x_i) P(Y_A, \\dots, Y_i, X_i=x_i) \\\\ &= P(Y_{i+1} \\mid X_{i+1}=x_{i+1}) \\sum_{x_i \\in \\mathcal{S}} \\alpha_i(x_i) P(X_{i+1}=x_{i+1} \\mid X_i=x_i) \\end{align*}\n\n- **Backward Variable $\\beta_i(x)$**: Defined as the conditional probability of the observations from locus $i+1$ to the end, given the state at locus $i$ is $x$.\n$$ \\beta_i(x) := P(Y_{i+1}, \\dots, Y_C \\mid X_i=x) $$\n  - **Initialization (at locus $C$)**: By convention, the probability of an empty future sequence is $1$.\n    $$ \\beta_C(x) = 1 \\text{ for all } x \\in \\mathcal{S} $$\n  - **Recursion (from locus $i+1$ to $i$)**:\n    $$ \\beta_i(x_i) = P(Y_{i+1}, \\dots, Y_C \\mid X_i=x_i) $$\n    By marginalizing over state $X_{i+1}$:\n    $$ \\beta_i(x_i) = \\sum_{x_{i+1} \\in \\mathcal{S}} P(Y_{i+1}, \\dots, Y_C, X_{i+1}=x_{i+1} \\mid X_i=x_i) $$\n    Using conditional independence properties:\n    \\begin{align*} \\beta_i(x_i) &= \\sum_{x_{i+1} \\in \\mathcal{S}} P(Y_{i+2}, \\dots, Y_C \\mid X_{i+1}=x_{i+1}) P(Y_{i+1} \\mid X_{i+1}=x_{i+1}) P(X_{i+1}=x_{i+1} \\mid X_i=x_i) \\\\ &= \\sum_{x_{i+1} \\in \\mathcal{S}} \\beta_{i+1}(x_{i+1}) P(Y_{i+1} \\mid X_{i+1}=x_{i+1}) P(X_{i+1}=x_{i+1} \\mid X_i=x_i) \\end{align*}\n- **Posterior Probability**: The posterior probability of being in state $x$ at locus $i$ given the full observation sequence is given by:\n$$ P(X_i=x \\mid Y_A, \\dots, Y_C) = \\frac{P(X_i=x, Y_A, \\dots, Y_C)}{P(Y_A, \\dots, Y_C)} $$\nThe numerator can be expressed as the product of the forward and backward variables:\n$$ P(X_i=x, Y_A, \\dots, Y_C) = P(Y_{i+1}, \\dots, Y_C \\mid Y_A, \\dots, Y_i, X_i=x) P(Y_A, \\dots, Y_i, X_i=x) $$\nBy conditional independence, $P(Y_{i+1}, \\dots, Y_C \\mid Y_A, \\dots, Y_i, X_i=x) = P(Y_{i+1}, \\dots, Y_C \\mid X_i=x) = \\beta_i(x)$. The second term is $\\alpha_i(x)$.\nThus, $P(X_i=x, Y_A, \\dots, Y_C) = \\alpha_i(x) \\beta_i(x)$.\nThe denominator is the marginal probability of the observations, obtained by summing over all possible states at locus $i$:\n$$ P(Y_A, \\dots, Y_C) = \\sum_{z \\in \\mathcal{S}} P(X_i=z, Y_A, \\dots, Y_C) = \\sum_{z \\in \\mathcal{S}} \\alpha_i(z) \\beta_i(z) $$\nThe final expression for the posterior is:\n$$ P(X_i=x \\mid Y_A, \\dots, Y_C) = \\frac{\\alpha_i(x) \\beta_i(x)}{\\sum_{z \\in \\mathcal{S}} \\alpha_i(z) \\beta_i(z)} $$\n\nTask 3: Computation of $P(X_B=P \\mid Y_A=\\text{calls }P, Y_B=\\text{missing}, Y_C=\\text{calls }M)$\n\nWe use the derived formulas with the given values: $r_{AB}=0.10$, $r_{BC}=0.20$, and $e=0.01$. The observation sequence is $Y = (\\text{calls }P, \\text{missing}, \\text{calls }M)$.\n\nLet $e_i(x) = P(Y_i \\mid X_i=x)$ be the emission probability for the given observation at locus $i$.\n$e_A(P) = P(Y_A=\\text{calls }P \\mid X_A=P) = 1-e = 0.99$\n$e_A(M) = P(Y_A=\\text{calls }P \\mid X_A=M) = e = 0.01$\n$e_B(P) = e_B(M) = P(Y_B=\\text{missing} \\mid X_B) = 1$\n$e_C(P) = P(Y_C=\\text{calls }M \\mid X_C=P) = e = 0.01$\n$e_C(M) = P(Y_C=\\text{calls }M \\mid X_C=M) = 1-e = 0.99$\n\nLet $T_{x,x'}^{i,i+1} = P(X_{i+1}=x' \\mid X_i=x)$.\n\n**Forward Pass:**\n1.  **Compute $\\alpha_A(x)$**:\n    $\\alpha_A(P) = e_A(P) P(X_A=P) = 0.99 \\times 0.5 = 0.495$\n    $\\alpha_A(M) = e_A(M) P(X_A=M) = 0.01 \\times 0.5 = 0.005$\n\n2.  **Compute $\\alpha_B(x)$**:\n    $\\alpha_B(P) = e_B(P) \\left[ \\alpha_A(P) T_{P,P}^{A,B} + \\alpha_A(M) T_{M,P}^{A,B} \\right]$\n    $\\alpha_B(P) = 1 \\times [ (0.495)(1-0.10) + (0.005)(0.10) ] = 0.495 \\times 0.90 + 0.005 \\times 0.10 = 0.4455 + 0.0005 = 0.446$\n    \n    $\\alpha_B(M) = e_B(M) \\left[ \\alpha_A(P) T_{P,M}^{A,B} + \\alpha_A(M) T_{M,M}^{A,B} \\right]$\n    $\\alpha_B(M) = 1 \\times [ (0.495)(0.10) + (0.005)(1-0.10) ] = 0.495 \\times 0.10 + 0.005 \\times 0.90 = 0.0495 + 0.0045 = 0.054$\n\n**Backward Pass:**\n1.  **Initialize $\\beta_C(x)$**:\n    $\\beta_C(P) = 1$\n    $\\beta_C(M) = 1$\n\n2.  **Compute $\\beta_B(x)$**:\n    $\\beta_B(P) = T_{P,P}^{B,C} e_C(P) \\beta_C(P) + T_{P,M}^{B,C} e_C(M) \\beta_C(M)$\n    $\\beta_B(P) = (1-0.20)(0.01)(1) + (0.20)(0.99)(1) = 0.80 \\times 0.01 + 0.20 \\times 0.99 = 0.008 + 0.198 = 0.206$\n\n    $\\beta_B(M) = T_{M,P}^{B,C} e_C(P) \\beta_C(P) + T_{M,M}^{B,C} e_C(M) \\beta_C(M)$\n    $\\beta_B(M) = (0.20)(0.01)(1) + (1-0.20)(0.99)(1) = 0.20 \\times 0.01 + 0.80 \\times 0.99 = 0.002 + 0.792 = 0.794$\n\n**Posterior Probability Calculation:**\nWe need to find $P(X_B=P \\mid Y) = \\frac{\\alpha_B(P)\\beta_B(P)}{\\alpha_B(P)\\beta_B(P) + \\alpha_B(M)\\beta_B(M)}$.\n\nNumerator:\n$\\alpha_B(P)\\beta_B(P) = 0.446 \\times 0.206 = 0.091876$\n\nDenominator (normalization constant):\n$\\alpha_B(P)\\beta_B(P) + \\alpha_B(M)\\beta_B(M) = (0.446)(0.206) + (0.054)(0.794)$\n$= 0.091876 + 0.042876 = 0.134752$\n\nPosterior Probability:\n$P(X_B=P \\mid Y) = \\frac{0.091876}{0.134752} \\approx 0.68181555$\n\nRounding to four significant figures, the result is $0.6818$.", "answer": "$$\\boxed{0.6818}$$", "id": "2860505"}]}