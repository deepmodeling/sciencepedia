{"hands_on_practices": [{"introduction": "Parental care represents a significant investment, and for males in many species, this investment comes with uncertainty about paternity. This exercise explores the fundamental trade-off between investing in a current brood of uncertain genetic relation and conserving resources for future mating opportunities. By applying marginal value analysis, you will derive the precise condition under which natural selection should favor an increase in male parental care, a result elegantly expressed as the inequality $pB > C$, where $p$ is paternity certainty, $B$ is the marginal benefit, and $C$ is the marginal cost. [@problem_id:2532459]", "problem": "In a large, panmictic population of a biparental vertebrate, males can provide postzygotic care to a single current brood at an energetic and time cost that reduces their future reproductive success. Let $x$ denote a continuous, one-dimensional measure of a male’s care effort allocated to the current brood during a breeding episode. Assume that selection on $x$ is weak such that local marginal effects determine the evolutionary response. The paternity of the current brood is uncertain: with probability $p$ a randomly sampled offspring in the current brood was sired by the focal male, and with probability $1 - p$ it was not.\n\nDefine the focal male’s expected lifetime number of his own surviving offspring (his direct genetic contribution) as\n$$\nW(x) = \\underbrace{p\\,S(x)}_{\\text{expected own surviving offspring from current brood}} + \\underbrace{F(x)}_{\\text{expected own surviving offspring from future reproduction}}.\n$$\nAssume $S(x)$ and $F(x)$ are differentiable at a resident baseline $x = x_{0}$ and that small increases in $x$ produce:\n- a marginal increase in the number of surviving offspring from the current brood of $B \\equiv \\left.\\frac{dS}{dx}\\right|_{x_{0}}$,\n- a marginal decrease in future surviving offspring of $C \\equiv -\\left.\\frac{dF}{dx}\\right|_{x_{0}}$.\n\nYou may assume $B > 0$ and $C > 0$ and that $p \\in (0,1)$. Using only the principle that, under weak selection, an infinitesimal increase in $x$ is favored when it increases $W(x)$ (i.e., when the selection gradient on $x$ is positive), derive the threshold paternity probability $p^{*}$ such that an infinitesimal increase in male care from $x_{0}$ is favored if and only if $p > p^{*}$. Express your final result as a closed-form symbolic expression in terms of $B$ and $C$. Do not include units. No numerical rounding is required.", "solution": "The problem statement has been subjected to validation and is found to be scientifically sound, well-posed, and free of contradictions or ambiguities. It presents a standard optimization problem in the field of behavioral ecology, grounded in the principles of evolutionary theory. It contains all necessary information for a rigorous solution. Therefore, we proceed.\n\nThe task is to determine the threshold probability of paternity, denoted as $p^{*}$, above which an infinitesimal increase in male parental care, $x$, from a baseline level $x_{0}$ is favored by selection. The principle for this decision is that the behavior is favored if it leads to an increase in the male's expected lifetime fitness, $W(x)$.\n\nThe fitness of the focal male is given by the function:\n$$\nW(x) = p\\,S(x) + F(x)\n$$\nHere, $p\\,S(x)$ represents the expected number of the male's own offspring surviving from the current brood, where $p$ is the probability of paternity and $S(x)$ is the number of surviving offspring as a function of care effort $x$. The term $F(x)$ represents the male's expected future reproductive success, which is a function of the current care effort $x$.\n\nSelection favors an infinitesimal increase in care effort $x$ from the resident value $x_{0}$ if the marginal change in fitness with respect to $x$ is positive. This marginal change is the selection gradient on the trait $x$, which is the derivative of the fitness function, $\\frac{dW}{dx}$, evaluated at $x = x_{0}$. The condition for the increase in care to be favored is:\n$$\n\\left.\\frac{dW}{dx}\\right|_{x=x_{0}} > 0\n$$\nTo evaluate this, we first compute the derivative of $W(x)$ with respect to $x$:\n$$\n\\frac{dW}{dx} = \\frac{d}{dx} \\left( p\\,S(x) + F(x) \\right)\n$$\nUsing the sum rule and the constant multiple rule for differentiation, we obtain:\n$$\n\\frac{dW}{dx} = p\\,\\frac{dS}{dx} + \\frac{dF}{dx}\n$$\nNow, we evaluate this derivative at the specific point $x = x_{0}$:\n$$\n\\left.\\frac{dW}{dx}\\right|_{x=x_{0}} = p\\,\\left.\\frac{dS}{dx}\\right|_{x=x_{0}} + \\left.\\frac{dF}{dx}\\right|_{x=x_{0}}\n$$\nThe problem statement provides definitions for the marginal benefit and marginal cost of care at $x_{0}$. The marginal benefit, $B$, is the rate of increase in current offspring survival:\n$$\nB \\equiv \\left.\\frac{dS}{dx}\\right|_{x_{0}}\n$$\nThe marginal cost, $C$, is the rate of decrease in future reproductive success. It is defined with a negative sign to ensure $C$ is a positive quantity:\n$$\nC \\equiv -\\left.\\frac{dF}{dx}\\right|_{x_{0}}\n$$\nThis implies that $\\left.\\frac{dF}{dx}\\right|_{x_{0}} = -C$.\n\nSubstituting these definitions for $B$ and $-C$ into the expression for the selection gradient gives:\n$$\n\\left.\\frac{dW}{dx}\\right|_{x=x_{0}} = p\\,B - C\n$$\nThe condition for an increase in care to be favored by selection, $\\left.\\frac{dW}{dx}\\right|_{x=x_{0}} > 0$, becomes:\n$$\np\\,B - C > 0\n$$\nThis inequality represents the core trade-off: the fitness benefit from the current brood, devalued by the probability of paternity ($pB$), must exceed the fitness cost to future reproduction ($C$). To find the condition on $p$, we solve this inequality.\n$$\np\\,B > C\n$$\nSince it is given that the marginal benefit $B > 0$, we can divide both sides of the inequality by $B$ without changing the direction of the inequality sign:\n$$\np > \\frac{C}{B}\n$$\nThis inequality states that an increase in male care is favored if and only if the probability of paternity $p$ is greater than the ratio of the marginal cost of care to the marginal benefit of care. The threshold paternity probability, $p^{*}$, is therefore the value at which the net marginal fitness gain is zero, which is the boundary of this condition.\n$$\np^{*} = \\frac{C}{B}\n$$\nThus, an infinitesimal increase in male care from $x_0$ is favored if and only if $p > p^{*}$.", "answer": "$$\\boxed{\\frac{C}{B}}$$", "id": "2532459"}, {"introduction": "Theoretical models, like the one explored previously, generate testable hypotheses that drive empirical research. This practice transitions from theory to direct application, tasking you with formally testing the prediction that a higher probability of paternity increases a male's likelihood of providing care. You will implement a logistic regression model from its mathematical foundations to analyze a dataset of paternity shares and care decisions, building essential skills in linking evolutionary theory to rigorous statistical inference. [@problem_id:2532476]", "problem": "In many species with biparental care, ecological and sexual selection theory predicts that a male’s certainty of paternity may shape his caregiving effort. You are given independent observations at the brood level: a male’s realized paternity share and whether he exhibited care. You must formalize caregiving as a Bernoulli random variable with probability linked to paternity share via a logistic link, and estimate the effect of paternity share on caregiving by maximum likelihood. Starting only from the definitions of the Bernoulli distribution, independence of observations, and the logistic link function, derive a principled estimation and testing procedure.\n\nYour task is to implement a program that, for each provided dataset, performs the following steps:\n- Model caregiving as a binary response $y_i \\in \\{0,1\\}$ dependent on a scalar predictor $x_i \\in [0,1]$ (the male’s paternity share for brood $i$).\n- Use the logistic link with a linear predictor $\\eta_i = \\beta_0 + \\beta_1 x_i$ and probability $p_i$ given by $p_i = \\sigma(\\eta_i)$, where $\\sigma(\\cdot)$ is the logistic function.\n- Assume observations are independent and identically distributed conditional on predictors, such that the joint likelihood is the product of Bernoulli probabilities.\n- Estimate the coefficient vector $\\boldsymbol{\\beta} = (\\beta_0,\\beta_1)$ by maximizing the log-likelihood using a numerically stable method grounded in first principles of maximum likelihood estimation.\n- Using the large-sample normal approximation of the maximum likelihood estimator and the observed Fisher information, construct a Wald statistic to test the one-sided hypothesis $H_0: \\beta_1 \\le 0$ versus $H_1: \\beta_1 > 0$. Compute the corresponding one-sided p-value.\n- For each dataset, return a three-element list $[\\hat{\\beta}_1, p, d]$ where $\\hat{\\beta}_1$ is the estimated slope rounded to $3$ decimal places, $p$ is the one-sided p-value rounded to $4$ decimal places, and $d$ is a boolean decision that is $True$ if and only if $\\hat{\\beta}_1 > 0$ and $p < 0.05$.\n\nScientific realism constraints: The link between paternity and care is mechanistically justified by sexual selection and parental investment theory. The inference you implement must start from the Bernoulli model and logistic link, without using any prepackaged shortcuts beyond numerical linear algebra and basic special functions.\n\nTest suite:\nProvide results for the following datasets. In each case, $x$ is the list of paternity shares and $y$ is the list of observed male care outcomes, with $1$ meaning care and $0$ meaning no care.\n\n- Dataset A (general positive association with variation across the range):\n  - $x = [\\, 0.05,\\, 0.10,\\, 0.15,\\, 0.20,\\, 0.30,\\, 0.35,\\, 0.40,\\, 0.50,\\, 0.60,\\, 0.70,\\, 0.80,\\, 0.90 \\,]$\n  - $y = [\\, 0,\\, 0,\\, 0,\\, 0,\\, 0,\\, 1,\\, 1,\\, 1,\\, 1,\\, 1,\\, 0,\\, 1 \\,]$\n\n- Dataset B (weak or no association):\n  - $x = [\\, 0.10,\\, 0.15,\\, 0.20,\\, 0.25,\\, 0.30,\\, 0.35,\\, 0.40,\\, 0.45,\\, 0.50,\\, 0.55 \\,]$\n  - $y = [\\, 0,\\, 1,\\, 0,\\, 1,\\, 0,\\, 0,\\, 1,\\, 0,\\, 1,\\, 0 \\,]$\n\n- Dataset C (negative association with exceptions to avoid separation):\n  - $x = [\\, 0.10,\\, 0.20,\\, 0.25,\\, 0.30,\\, 0.40,\\, 0.45,\\, 0.50,\\, 0.55,\\, 0.60,\\, 0.70,\\, 0.80,\\, 0.85,\\, 0.90,\\, 0.95 \\,]$\n  - $y = [\\, 1,\\, 1,\\, 1,\\, 1,\\, 1,\\, 0,\\, 0,\\, 0,\\, 0,\\, 0,\\, 1,\\, 0,\\, 0,\\, 0 \\,]$\n\nFinal output format:\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets. Each dataset’s result must itself be a three-element list in the order $[\\hat{\\beta}_1, p, d]$. For example, the printed output should look like:\n[ [b1_A,p_A,decision_A], [b1_B,p_B,decision_B], [b1_C,p_C,decision_C] ]\nThere are no physical units or angles in this task. All numeric outputs must be rounded as specified above, and the boolean decision must reflect the one-sided test at significance level $\\alpha = 0.05$.", "solution": "The problem presented is a standard, valid exercise in statistical modeling applied to evolutionary ecology. It concerns the estimation of the effect of a continuous predictor, paternal share, on a binary outcome, male parental care. This requires the application of a Generalized Linear Model (GLM), specifically logistic regression. We will proceed with a full derivation and implementation from first principles as demanded.\n\nThe problem is validated as follows:\n- **Scientific Grounding**: The premise, linking paternity certainty to parental investment, is a cornerstone of sexual selection theory. It is scientifically sound.\n- **Well-Posedness**: The problem defines a clear objective: to estimate parameters of a logistic model via maximum likelihood and to perform a hypothesis test. The specified model and estimation technique lead to a well-defined statistical procedure.\n- **Objectivity**: The problem is stated in precise, objective mathematical and statistical language.\n\nThe verdict is that the problem is **valid**. A rigorous solution follows.\n\n**1. The Statistical Model**\n\nLet $Y_i$ be the binary random variable representing the care decision for brood $i$, where $Y_i=1$ if care is provided and $Y_i=0$ otherwise. Let $x_i \\in [0, 1]$ be the observed paternity share for that brood. We model $Y_i$ as a Bernoulli-distributed random variable, conditional on $x_i$:\n$$ Y_i \\sim \\text{Bernoulli}(p_i) $$\nThe probability mass function for observation $i$ is:\n$$ f(y_i|p_i) = p_i^{y_i} (1-p_i)^{1-y_i}, \\quad y_i \\in \\{0, 1\\} $$\nThe probability $p_i$ is related to the predictor $x_i$ through a logistic link function. The linear predictor, $\\eta_i$, is defined as a linear function of the predictor:\n$$ \\eta_i = \\beta_0 + \\beta_1 x_i $$\nThe logistic link function, $\\sigma(\\cdot)$, maps the linear predictor from $(-\\infty, \\infty)$ to the probability space $(0, 1)$:\n$$ p_i = \\sigma(\\eta_i) = \\frac{1}{1 + e^{-\\eta_i}} $$\nThe parameter $\\beta_1$ quantifies the change in the log-odds of providing care for a one-unit increase in paternity share. Our goal is to estimate the vector of coefficients $\\boldsymbol{\\beta} = [\\beta_0, \\beta_1]^T$.\n\n**2. Maximum Likelihood Estimation (MLE)**\n\nAssuming the $n$ observations $(x_i, y_i)$ are independent, the total likelihood of the observed data $\\mathbf{y} = (y_1, ..., y_n)$ given the predictors $\\mathbf{x} = (x_1, ..., x_n)$ and parameters $\\boldsymbol{\\beta}$ is the product of the individual probabilities:\n$$ \\mathcal{L}(\\boldsymbol{\\beta}; \\mathbf{x}, \\mathbf{y}) = \\prod_{i=1}^n p_i^{y_i} (1-p_i)^{1-y_i} $$\nFor analytical and numerical convenience, we maximize the log-likelihood function $\\ell(\\boldsymbol{\\beta}) = \\log \\mathcal{L}(\\boldsymbol{\\beta})$:\n$$ \\ell(\\boldsymbol{\\beta}) = \\sum_{i=1}^n \\left[ y_i \\log(p_i) + (1-y_i) \\log(1-p_i) \\right] $$\nWe can re-express this in terms of the linear predictor $\\eta_i$. Using the identities $\\log(p_i/(1-p_i)) = \\eta_i$ and $\\log(1-p_i) = -\\log(1+e^{\\eta_i})$, we derive the canonical form of the log-likelihood for logistic regression:\n$$ \\ell(\\boldsymbol{\\beta}) = \\sum_{i=1}^n \\left[ y_i \\eta_i - \\log(1+e^{\\eta_i}) \\right] $$\nHere, $\\eta_i = \\mathbf{x}_i^T \\boldsymbol{\\beta}$, where $\\mathbf{x}_i = [1, x_i]^T$ is the predictor vector for observation $i$.\n\nTo find the maximum likelihood estimate $\\hat{\\boldsymbol{\\beta}}$, we must find the value of $\\boldsymbol{\\beta}$ that maximizes $\\ell(\\boldsymbol{\\beta})$. This is achieved by solving $\\nabla \\ell(\\boldsymbol{\\beta}) = \\mathbf{0}$, where $\\nabla \\ell(\\boldsymbol{\\beta})$ is the gradient of the log-likelihood function. The components of the gradient are the partial derivatives with respect to each parameter $\\beta_j$:\n$$ \\frac{\\partial \\ell}{\\partial \\beta_j} = \\sum_{i=1}^n \\frac{\\partial}{\\partial \\beta_j} \\left[ y_i \\eta_i - \\log(1+e^{\\eta_i}) \\right] = \\sum_{i=1}^n \\left( y_i \\frac{\\partial \\eta_i}{\\partial \\beta_j} - \\frac{e^{\\eta_i}}{1+e^{\\eta_i}} \\frac{\\partial \\eta_i}{\\partial \\beta_j} \\right) $$\nNoting that $p_i = e^{\\eta_i}/(1+e^{\\eta_i})$ and $\\partial \\eta_i / \\partial \\beta_j = x_{ij}$ (where $x_{i0}=1$ and $x_{i1}=x_i$), we have:\n$$ \\frac{\\partial \\ell}{\\partial \\beta_j} = \\sum_{i=1}^n (y_i - p_i) x_{ij} $$\nIn matrix notation, the gradient vector is:\n$$ \\nabla \\ell(\\boldsymbol{\\beta}) = \\mathbf{X}^T (\\mathbf{y} - \\mathbf{p}) $$\nwhere $\\mathbf{X}$ is the $n \\times 2$ design matrix whose rows are $\\mathbf{x}_i^T$, $\\mathbf{y}$ is the vector of outcomes, and $\\mathbf{p}$ is the vector of probabilities.\n\nThere is no closed-form solution for $\\hat{\\boldsymbol{\\beta}}$, so we must use a numerical optimization algorithm. We will employ a quasi-Newton method (BFGS), which requires the gradient of the function to be minimized. We will minimize the negative log-likelihood, $-\\ell(\\boldsymbol{\\beta})$, whose gradient is simply $-\\nabla \\ell(\\boldsymbol{\\beta})$.\n\n**3. Hypothesis Testing using the Wald Test**\n\nThe problem requires a one-sided test of the null hypothesis $H_0: \\beta_1 \\le 0$ against the alternative $H_1: \\beta_1 > 0$. We use a Wald test based on the asymptotic normality of the MLE. For large sample sizes, the distribution of the MLE $\\hat{\\boldsymbol{\\beta}}$ is approximately normal:\n$$ \\hat{\\boldsymbol{\\beta}} \\stackrel{\\cdot}{\\sim} \\mathcal{N}(\\boldsymbol{\\beta}, \\mathcal{I}(\\boldsymbol{\\beta})^{-1}) $$\nwhere $\\mathcal{I}(\\boldsymbol{\\beta})$ is the Fisher information matrix. We use the **observed Fisher information matrix**, $\\mathcal{J}(\\hat{\\boldsymbol{\\beta}})$, which is the negative of the Hessian matrix of the log-likelihood, evaluated at the MLE $\\hat{\\boldsymbol{\\beta}}$. The Hessian matrix $\\mathbf{H}(\\boldsymbol{\\beta})$ contains the second partial derivatives:\n$$ H_{jk} = \\frac{\\partial^2 \\ell}{\\partial \\beta_j \\partial \\beta_k} = \\frac{\\partial}{\\partial \\beta_k} \\sum_{i=1}^n (y_i - p_i) x_{ij} = \\sum_{i=1}^n -x_{ij} \\frac{\\partial p_i}{\\partial \\beta_k} $$\nUsing the chain rule, $\\frac{\\partial p_i}{\\partial \\beta_k} = \\frac{dp_i}{d\\eta_i}\\frac{\\partial \\eta_i}{\\partial \\beta_k} = p_i(1-p_i)x_{ik}$. Thus:\n$$ H_{jk} = -\\sum_{i=1}^n p_i(1-p_i) x_{ij} x_{ik} $$\nIn matrix form, $\\mathbf{H}(\\boldsymbol{\\beta}) = -\\mathbf{X}^T \\mathbf{W} \\mathbf{X}$, where $\\mathbf{W}$ is a diagonal matrix with diagonal entries $W_{ii} = p_i(1-p_i)$.\nThe observed Fisher information is $\\mathcal{J}(\\hat{\\boldsymbol{\\beta}}) = -\\mathbf{H}(\\hat{\\boldsymbol{\\beta}}) = \\mathbf{X}^T \\hat{\\mathbf{W}} \\mathbf{X}$, where $\\hat{\\mathbf{W}}$ is evaluated using $\\hat{\\mathbf{p}}$, the probabilities calculated from $\\hat{\\boldsymbol{\\beta}}$.\n\nThe estimated asymptotic covariance matrix of $\\hat{\\boldsymbol{\\beta}}$ is $\\widehat{\\text{Cov}}(\\hat{\\boldsymbol{\\beta}}) = \\mathcal{J}(\\hat{\\boldsymbol{\\beta}})^{-1}$. The standard error of $\\hat{\\beta}_1$ is the square root of the corresponding diagonal element of this matrix:\n$$ \\text{SE}(\\hat{\\beta}_1) = \\sqrt{[\\mathcal{J}(\\hat{\\boldsymbol{\\beta}})^{-1}]_{11}} $$\n(using $0$-based indexing, this is the element at position (1,1)).\n\nThe Wald statistic is:\n$$ W = \\frac{\\hat{\\beta}_1}{\\text{SE}(\\hat{\\beta}_1)} $$\nUnder $H_0$, $W$ converges in distribution to a standard normal variable, $Z \\sim \\mathcal{N}(0, 1)$. For the one-sided alternative $H_1: \\beta_1 > 0$, the p-value is the probability of observing a statistic at least as large as $W$:\n$$ p = P(Z \\ge W) = 1 - \\Phi(W) $$\nwhere $\\Phi$ is the CDF of the standard normal distribution.\n\nThe final decision, $d$, is `True` if and only if the estimate supports the alternative hypothesis ($\\hat{\\beta}_1 > 0$) and the result is statistically significant at the $\\alpha = 0.05$ level ($p < 0.05$).\n\nThis completes the theoretical derivation. We will now implement this procedure.", "answer": "```python\nimport numpy as np\nfrom scipy.optimize import minimize\nfrom scipy.stats import norm\n\ndef solve():\n    \"\"\"\n    Main function to process datasets and print results.\n    \"\"\"\n    test_cases = [\n        {\n            \"x\": [0.05, 0.10, 0.15, 0.20, 0.30, 0.35, 0.40, 0.50, 0.60, 0.70, 0.80, 0.90],\n            \"y\": [0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1],\n        },\n        {\n            \"x\": [0.10, 0.15, 0.20, 0.25, 0.30, 0.35, 0.40, 0.45, 0.50, 0.55],\n            \"y\": [0, 1, 0, 1, 0, 0, 1, 0, 1, 0],\n        },\n        {\n            \"x\": [0.10, 0.20, 0.25, 0.30, 0.40, 0.45, 0.50, 0.55, 0.60, 0.70, 0.80, 0.85, 0.90, 0.95],\n            \"y\": [1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n        },\n    ]\n\n    results = []\n    for case in test_cases:\n        x_data = case[\"x\"]\n        y_data = case[\"y\"]\n        result = estimate_and_test(x_data, y_data)\n        results.append(result)\n\n    # Format output to be a single line with no spaces within sublists.\n    # Example: [[-1.23,0.456,False],[...]]\n    formatted_results = f\"[{','.join([str(r).replace(' ', '') for r in results])}]\"\n    print(formatted_results)\n\ndef estimate_and_test(x, y):\n    \"\"\"\n    Performs logistic regression from first principles and a one-sided Wald test.\n    \n    Args:\n        x (list): List of paternity shares (predictor).\n        y (list): List of care outcomes (binary response).\n        \n    Returns:\n        list: A list containing [beta_1_hat, p_value, decision].\n    \"\"\"\n    # 1. Prepare data\n    x_vec = np.array(x, dtype=np.float64)\n    y_vec = np.array(y, dtype=np.float64)\n    X_design = np.vstack([np.ones(len(x_vec)), x_vec]).T\n    \n    # 2. Define objective function (negative log-likelihood) and its gradient\n    def neg_log_likelihood(beta, X, y):\n        # eta = beta_0 + beta_1 * x\n        eta = X @ beta\n        # Numerically stable log-likelihood using logaddexp for log(1+exp(eta))\n        # l = sum(y*eta - log(1+exp(eta)))\n        # Here we return -l\n        return -np.sum(y * eta - np.logaddexp(0, eta))\n\n    def gradient(beta, X, y):\n        # eta = beta_0 + beta_1 * x\n        eta = X @ beta\n        # p = 1 / (1 + exp(-eta))\n        p = 1 / (1 + np.exp(-eta))\n        # grad(l) = X^T * (y - p)\n        # We return -grad(l) for the minimization problem\n        return -X.T @ (y - p)\n    \n    # 3. Perform optimization to find MLE for beta\n    initial_beta = np.zeros(2)\n    opt_result = minimize(\n        neg_log_likelihood,\n        initial_beta,\n        args=(X_design, y_vec),\n        jac=gradient,\n        method='BFGS'\n    )\n    beta_hat = opt_result.x\n    beta_1_hat = beta_hat[1]\n    \n    # 4. Calculate standard error of beta_1_hat\n    # eta_hat = X @ beta_hat\n    eta_hat = X_design @ beta_hat\n    # p_hat = 1 / (1 + exp(-eta_hat))\n    p_hat = 1 / (1 + np.exp(-eta_hat))\n    # W is a diagonal matrix of weights p_hat * (1 - p_hat)\n    weights = p_hat * (1 - p_hat)\n    # Observed Fisher Information Matrix: J = X^T * W * X\n    fisher_info_matrix = X_design.T @ (weights[:, np.newaxis] * X_design)\n    \n    try:\n        # Covariance matrix is the inverse of the Fisher Information Matrix\n        cov_matrix = np.linalg.inv(fisher_info_matrix)\n        # Variance of beta_1_hat is the (1,1) element\n        var_beta_1 = cov_matrix[1, 1]\n        se_beta_1 = np.sqrt(var_beta_1)\n        \n        # 5. Perform one-sided Wald test\n        # H0: beta_1 <= 0, H1: beta_1 > 0\n        wald_statistic = beta_1_hat / se_beta_1\n        # p_value is the upper tail probability of a standard normal distribution\n        p_value = norm.sf(wald_statistic)\n\n    except np.linalg.LinAlgError:\n        # Handle cases of singularity, e.g., perfect separation,\n        # which would make inference impossible.\n        p_value = np.nan\n        se_beta_1 = np.nan\n\n    # 6. Format the output\n    beta_1_rounded = round(beta_1_hat, 3)\n    p_value_rounded = round(p_value, 4) if not np.isnan(p_value) else None\n    \n    # Decision: True if beta_1_hat > 0 and p-value < 0.05\n    decision = False\n    if p_value_rounded is not None:\n        if beta_1_hat > 0 and p_value_rounded < 0.05:\n            decision = True\n            \n    return [beta_1_rounded, p_value_rounded, decision]\n\nif __name__ == \"__main__\":\n    solve()\n```", "id": "2532476"}, {"introduction": "Sexual selection often involves intricate communication, where females choose mates based on elaborate signals. But when is a signal an honest indicator of a male's quality, $\\kappa$? This exercise delves into the logic of honest signaling using a game-theoretic framework, demonstrating how condition-dependent costs, $c(z, \\kappa)$, can ensure signal reliability. You will derive a \"separating equilibrium,\" where males of different qualities adopt distinct signaling strategies, revealing the evolutionary stability of the \"handicap principle.\" [@problem_id:2532490]", "problem": "In a sexually selected signaling system, consider a large population of males who differ in condition (quality) and a large population of females who prefer to mate with high-condition males. Males choose a signal intensity $z \\geq 0$ that is observable to females. The biological premise is that the energetic and risk costs of signaling are condition-dependent: higher-condition males pay lower marginal costs for the same signal intensity.\n\nAssume there are exactly two male condition types, indexed by parameter $\\kappa \\in \\{\\kappa_{L}, \\kappa_{H}\\}$ with $\\kappa_{H} > \\kappa_{L} > 0$. If a female mates with a male she believes to be high-condition, the male obtains a mating success benefit $V > 0$. If she does not mate with the male, the male obtains $0$. The cost of signaling is given by the function $c(z,\\kappa)$, which is increasing and convex in $z$, and decreasing in $\\kappa$. Specifically, suppose\n$$\nc(z,\\kappa) \\;=\\; \\frac{z^{2}}{2\\,\\kappa}\\,,\n$$\nwhich captures the condition-dependence: for a given $z$, the cost is smaller when $\\kappa$ is larger.\n\nFemales adopt a threshold strategy: they mate if and only if the observed signal exceeds some threshold $t$, which they set to maximize their own expected fitness, given the population and the signals chosen by males. In a separating equilibrium, low-condition males select $z_{L}^{\\ast}$ and high-condition males select $z_{H}^{\\ast}$ with $z_{H}^{\\ast} > t > z_{L}^{\\ast}$, so that females can infer male condition from $z$. The male payoff is the benefit of mating, if achieved, minus the signaling cost.\n\nUsing only standard definitions of equilibrium (each type of male best-responds to the female strategy and the other male type’s action) and the biological assumptions above, derive the smallest separating equilibrium signal pair $\\big(z_{L}^{\\ast}, z_{H}^{\\ast}\\big)$ consistent with incentive compatibility for both types, under the additional biologically realistic restriction that a low-condition male who is not mated will choose to avoid unnecessary cost.\n\nExpress your final answer as a single row matrix $\\begin{pmatrix} z_{L}^{\\ast} & z_{H}^{\\ast} \\end{pmatrix}$ in closed form in terms of $V$, $\\kappa_{L}$, and $\\kappa_{H}$. No numerical evaluation is required, and no units are needed. Do not round.", "solution": "The problem requires the derivation of the smallest separating equilibrium signal pair, denoted $\\big(z_{L}^{\\ast}, z_{H}^{\\ast}\\big)$, in a simple model of sexual selection.\n\nFirst, we must validate the problem statement.\n\nStep 1: Extract Givens\n- Male population has two condition types: high condition ($\\kappa_{H}$) and low condition ($\\kappa_{L}$), with $\\kappa_{H} > \\kappa_{L} > 0$.\n- Mating success benefit for a male believed to be high-condition: $V > 0$.\n- Mating success benefit for a male not mated with: $0$.\n- Cost of signaling with intensity $z \\geq 0$ for a male of condition $\\kappa$: $c(z,\\kappa) = \\frac{z^2}{2\\kappa}$.\n- Female strategy: Mate if and only if observed signal $z$ exceeds a threshold $t$.\n- Separating equilibrium: Low-condition males choose $z_{L}^{\\ast}$, high-condition males choose $z_{H}^{\\ast}$, with $z_{H}^{\\ast} > t > z_{L}^{\\ast}$.\n- Male payoff: Benefit minus cost.\n- Additional restriction: A low-condition male who is not mated will choose to avoid unnecessary cost.\n\nStep 2: Validate Using Extracted Givens\nThe problem is scientifically grounded, being a standard application of signaling theory (a Spence-type model) to evolutionary biology. The assumptions, such as condition-dependent costs (the single-crossing property) and female choice based on signals, are cornerstones of this field. The problem is well-posed, objective, self-contained, and consistent. It asks for the \"smallest\" separating equilibrium, which is a standard refinement (the Riley equilibrium) in such models, indicating a well-structured problem. The additional restriction on the low-condition male's behavior provides the specific criterion needed to find this unique equilibrium among a potential set of separating equilibria. The problem is not trivial and is verifiable through logical and mathematical derivation. All parameters and functions are clearly defined.\n\nStep 3: Verdict and Action\nThe problem is valid. We will proceed to the solution.\n\nThe payoff, $U(z, \\kappa)$, for a male of condition $\\kappa$ choosing signal level $z$, given the female's threshold strategy $t$, is:\n$$\nU(z, \\kappa) =\n\\begin{cases}\nV - c(z, \\kappa) & \\text{if } z > t \\\\\n-c(z, \\kappa) & \\text{if } z \\leq t\n\\end{cases}\n$$\nIn a separating equilibrium, low-condition ($\\kappa_{L}$) males choose $z_{L}^{\\ast}$ and high-condition ($\\kappa_{H}$) males choose $z_{H}^{\\ast}$ such that females can distinguish them. This requires $z_{H}^{\\ast} \\neq z_{L}^{\\ast}$. Females set a threshold $t$ between these signals, i.e., $z_{L}^{\\ast} < t < z_{H}^{\\ast}$. Consequently, high-condition males are mated, and low-condition males are not.\n\nThe payoffs for each type at the proposed equilibrium are:\n- For a $\\kappa_{H}$ male choosing $z_{H}^{\\ast}$: $U_{H}(z_{H}^{\\ast}) = V - c(z_{H}^{\\ast}, \\kappa_{H})$.\n- For a $\\kappa_{L}$ male choosing $z_{L}^{\\ast}$: $U_{L}(z_{L}^{\\ast}) = -c(z_{L}^{\\ast}, \\kappa_{L})$.\n\nFor this to be an equilibrium, two sets of conditions, known as incentive compatibility (IC) constraints, must be met. Each type must find it optimal to choose its equilibrium signal rather than mimic the other type.\n\n1.  Incentive Compatibility for the High-Condition Male (IC-H): The $\\kappa_{H}$ male must not prefer to signal $z_{L}^{\\ast}$ (and thus not mate).\n    $$ U_{H}(z_{H}^{\\ast}) \\geq U_{H}(z_{L}^{\\ast}) $$\n    $$ V - c(z_{H}^{\\ast}, \\kappa_{H}) \\geq -c(z_{L}^{\\ast}, \\kappa_{H}) $$\n\n2.  Incentive Compatibility for the Low-Condition Male (IC-L): The $\\kappa_{L}$ male must not prefer to mimic the high-condition male by signaling $z_{H}^{\\ast}$ (and thus mate).\n    $$ U_{L}(z_{L}^{\\ast}) \\geq U_{L}(z_{H}^{\\ast}) $$\n    $$ -c(z_{L}^{\\ast}, \\kappa_{L}) \\geq V - c(z_{H}^{\\ast}, \\kappa_{L}) $$\n\nThe problem specifies an additional biologically realistic restriction: \"a low-condition male who is not mated will choose to avoid unnecessary cost.\" In this separating equilibrium, the $\\kappa_{L}$ male is not mated. His payoff is $U_{L}(z_{L}^{\\ast}) = -c(z_{L}^{\\ast}, \\kappa_{L}) = -\\frac{(z_{L}^{\\ast})^2}{2\\kappa_{L}}$. To maximize this payoff (i.e., minimize his cost), he must choose the signal $z_{L}^{\\ast}$ that minimizes the cost function. Since $c(z, \\kappa_{L})$ is an increasing function of $z$ for $z \\geq 0$, the cost is minimized at $z=0$. Therefore, this restriction implies:\n$$ z_{L}^{\\ast} = 0 $$\nThis choice is a defining feature of the \"least-cost\" or \"Riley\" separating equilibrium.\n\nSubstituting $z_{L}^{\\ast} = 0$ into the IC constraints:\n1.  IC-H becomes:\n    $$ V - c(z_{H}^{\\ast}, \\kappa_{H}) \\geq -c(0, \\kappa_{H}) $$\n    $$ V - \\frac{(z_{H}^{\\ast})^2}{2\\kappa_{H}} \\geq 0 \\quad \\implies \\quad \\frac{(z_{H}^{\\ast})^2}{2\\kappa_{H}} \\leq V $$\n    This is also the individual rationality (IR) constraint for the high-condition male, ensuring his payoff is non-negative.\n\n2.  IC-L becomes:\n    $$ -c(0, \\kappa_{L}) \\geq V - c(z_{H}^{\\ast}, \\kappa_{L}) $$\n    $$ 0 \\geq V - \\frac{(z_{H}^{\\ast})^2}{2\\kappa_{L}} \\quad \\implies \\quad \\frac{(z_{H}^{\\ast})^2}{2\\kappa_{L}} \\geq V $$\n\nSo, the equilibrium signal $z_{H}^{\\ast}$ must satisfy both:\n$$ \\frac{(z_{H}^{\\ast})^2}{2\\kappa_{L}} \\geq V \\quad \\text{and} \\quad \\frac{(z_{H}^{\\ast})^2}{2\\kappa_{H}} \\leq V $$\nThe high-condition male benefits from signaling but also incurs a cost. He has an incentive to choose the lowest possible signal level $z_{H}^{\\ast}$ that successfully deters the low-condition male from mimicking. Any signal higher than this minimum is unnecessarily costly. Therefore, $z_{H}^{\\ast}$ will be the lowest value that satisfies the IC-L constraint. This occurs when the IC-L constraint is binding (holds with equality):\n$$ \\frac{(z_{H}^{\\ast})^2}{2\\kappa_{L}} = V $$\nSolving for $z_{H}^{\\ast}$:\n$$ (z_{H}^{\\ast})^2 = 2V\\kappa_{L} $$\nSince $z \\geq 0$, we take the principal root:\n$$ z_{H}^{\\ast} = \\sqrt{2V\\kappa_{L}} $$\nWe must verify that this solution for $z_{H}^{\\ast}$ also satisfies the IC-H constraint:\n$$ \\frac{(z_{H}^{\\ast})^2}{2\\kappa_{H}} \\leq V $$\nSubstituting the expression for $(z_{H}^{\\ast})^2$:\n$$ \\frac{2V\\kappa_{L}}{2\\kappa_{H}} \\leq V $$\n$$ V \\frac{\\kappa_{L}}{\\kappa_{H}} \\leq V $$\nSince $V > 0$, we can divide by $V$:\n$$ \\frac{\\kappa_{L}}{\\kappa_{H}} \\leq 1 $$\nThis inequality is true because the problem states $\\kappa_{H} > \\kappa_{L} > 0$. Thus, the solution is internally consistent.\n\nThe smallest separating equilibrium signal pair is $(z_{L}^{\\ast}, z_{H}^{\\ast})$, where $z_{L}^{\\ast}$ is the signal resulting from cost minimization for the unmated type, and $z_{H}^{\\ast}$ is the minimal signal required to prevent imitation by the low-quality type.\n\nThe final result is:\n$z_{L}^{\\ast} = 0$\n$z_{H}^{\\ast} = \\sqrt{2V\\kappa_{L}}$", "answer": "$$\n\\boxed{\\begin{pmatrix} 0 & \\sqrt{2 V \\kappa_{L}} \\end{pmatrix}}\n$$", "id": "2532490"}]}