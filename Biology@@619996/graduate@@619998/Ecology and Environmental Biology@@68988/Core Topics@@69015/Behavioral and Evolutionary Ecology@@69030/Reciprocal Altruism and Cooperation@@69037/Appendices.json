{"hands_on_practices": [{"introduction": "Understanding reciprocal altruism begins with quantifying the long-term consequences of strategic choices in repeated interactions. The normalized discounted payoff is a standard tool for this, capturing the idea that future rewards are valued slightly less than immediate ones using a discount factor $\\delta$. This practice provides essential training in calculating these payoffs for fundamental strategies like Tit-for-Tat and Always Defect, laying the groundwork for more complex evolutionary analyses [@problem_id:2527624].", "problem": "An indefinitely repeated Prisoner’s Dilemma (PD) is played between two pure strategies from the set $\\{\\text{Always Defect (ALLD)}, \\text{Always Cooperate (ALLC)}, \\text{Tit-for-Tat (TFT)}, \\text{Grim Trigger (GRIM)}\\}$. The one-shot PD payoffs are denoted by $T$ (temptation), $R$ (reward), $P$ (punishment), and $S$ (sucker), satisfying $T>R>P>S$ and $2R>T+S$. Time is infinite-horizon with common discount factor $\\delta \\in [0,1)$, and per-period payoffs are aggregated by the normalized discounted value\n$$\nV \\;=\\; (1-\\delta)\\sum_{t=1}^{\\infty} \\delta^{t-1} u_t,\n$$\nwhere $u_t$ is the stage payoff in period $t$. Strategies are defined as follows: $\\text{ALLD}$ defects in every period; $\\text{ALLC}$ cooperates in every period; $\\text{TFT}$ cooperates in period $1$ and thereafter repeats the opponent’s previous actual move; $\\text{GRIM}$ cooperates until the opponent defects once, after which it defects forever.\n\nTasks:\n- Using only the above primitives, derive closed-form expressions for the normalized discounted payoffs for every unordered pairwise matchup among $\\{\\text{ALLD}, \\text{ALLC}, \\text{TFT}, \\text{GRIM}\\}$ as functions of $\\delta$, $T$, $R$, $P$, and $S$.\n- From these expressions, identify, for each unordered pair of strategies, which member of the pair obtains the larger normalized discounted payoff as a function of $\\delta$ (state explicitly if the payoffs are equal for all $\\delta$).\n- Finally, solve for the critical discount factor $\\delta^{\\star} \\in [0,1]$ at which the normalized discounted payoff of $\\text{ALLD}$ against $\\text{TFT}$ equals the normalized discounted payoff of $\\text{TFT}$ against $\\text{ALLD}$. Provide your final answer as the exact value of $\\delta^{\\star}$ (no units). No rounding is required.", "solution": "The problem is first subjected to rigorous validation before a solution is attempted.\n\n**Step 1: Extract Givens**\nThe following information is provided verbatim in the problem statement:\n- Game type: Indefinitely repeated Prisoner’s Dilemma (PD).\n- Set of pure strategies: $\\{\\text{Always Defect (ALLD)}, \\text{Always Cooperate (ALLC)}, \\text{Tit-for-Tat (TFT)}, \\text{Grim Trigger (GRIM)}\\}$.\n- One-shot PD payoffs: $T$ (temptation), $R$ (reward), $P$ (punishment), and $S$ (sucker).\n- Payoff ordering constraints: $T>R>P>S$ and $2R>T+S$.\n- Time horizon: Infinite, with common discount factor $\\delta \\in [0,1)$.\n- Normalized discounted value: $V = (1-\\delta)\\sum_{t=1}^{\\infty} \\delta^{t-1} u_t$.\n- Strategy definitions:\n    - $\\text{ALLD}$: defects in every period.\n    - $\\text{ALLC}$: cooperates in every period.\n    - $\\text{TFT}$: cooperates in period $1$ and thereafter repeats the opponent’s previous actual move.\n    - $\\text{GRIM}$: cooperates until the opponent defects once, after which it defects forever.\n- Tasks:\n    1. Derive closed-form expressions for the normalized discounted payoffs for every unordered pairwise matchup.\n    2. Identify which strategy in each pair obtains the larger payoff.\n    3. Solve for the critical discount factor $\\delta^{\\star} \\in [0,1]$ at which the payoff of $\\text{ALLD}$ against $\\text{TFT}$ equals the payoff of $\\text{TFT}$ against $\\text{ALLD}$.\n\n**Step 2: Validate Using Extracted Givens**\nThe problem is assessed for validity against established criteria.\n- **Scientific Grounding**: The problem is a standard, canonical model from game theory and evolutionary biology used to study the emergence of cooperation. The repeated Prisoner's Dilemma, the strategies specified (especially $\\text{TFT}$ and $\\text{GRIM}$), and the payoff structure including the conditions $T>R>P>S$ and $2R>T+S$ are all fundamental and well-established in the scientific literature. The problem is scientifically sound.\n- **Well-Posedness**: The problem is mathematically unambiguous. All variables, functions, and objectives are clearly defined. The provided information is complete, consistent, and sufficient to derive a unique solution for all stated tasks.\n- **Objectivity**: The language is formal and precise, free from subjective claims or ambiguity.\n\n**Step 3: Verdict and Action**\nThe problem is valid. It is a well-posed, scientifically grounded problem that can be solved with the given information. The solution will now be derived.\n\nThe normalized discounted value of a constant payoff stream, where $u_t = u$ for all $t \\geq 1$, is $V = (1-\\delta)\\sum_{t=1}^{\\infty} \\delta^{t-1} u = (1-\\delta) u (\\frac{1}{1-\\delta}) = u$. If a payoff stream is $(u_1, u_2, u_2, \\dots)$, the value is $V = (1-\\delta)[u_1 + \\delta u_2 + \\delta^2 u_2 + \\dots] = (1-\\delta)[u_1 + \\frac{\\delta u_2}{1-\\delta}] = (1-\\delta)u_1 + \\delta u_2$. These formulae will be used for the subsequent calculations. Let $V(A, B)$ denote the payoff to strategy $A$ when playing against strategy $B$.\n\n**Part 1: Derivation of Payoffs**\nThere are $\\binom{4}{2} + 4 = 10$ possible pairings to consider.\n\n1.  **ALLC vs. ALLC**: Both players cooperate in all periods. The payoff stream for each is $(R, R, R, \\dots)$. Thus, $V(\\text{ALLC, ALLC}) = R$.\n\n2.  **ALLD vs. ALLD**: Both players defect in all periods. The payoff stream for each is $(P, P, P, \\dots)$. Thus, $V(\\text{ALLD, ALLD}) = P$.\n\n3.  **TFT vs. TFT**: Both players start by cooperating. In each subsequent period, each player observes the other's cooperation and cooperates in turn. The payoff stream is $(R, R, R, \\dots)$. Thus, $V(\\text{TFT, TFT}) = R$.\n\n4.  **GRIM vs. GRIM**: Both players start by cooperating. Since no defections ever occur, both cooperate indefinitely. The payoff stream is $(R, R, R, \\dots)$. Thus, $V(\\text{GRIM, GRIM}) = R$.\n\n5.  **ALLC vs. ALLD**: ALLC consistently cooperates, and ALLD consistently defects. The payoff stream for ALLC is $(S, S, S, \\dots)$ and for ALLD is $(T, T, T, \\dots)$.\n    $V(\\text{ALLC, ALLD}) = S$.\n    $V(\\text{ALLD, ALLC}) = T$.\n\n6.  **ALLC vs. TFT**: ALLC always cooperates. TFT starts with cooperation. TFT observes ALLC's cooperation and continues to cooperate. The result is mutual cooperation in all periods.\n    $V(\\text{ALLC, TFT}) = R$ and $V(\\text{TFT, ALLC}) = R$.\n\n7.  **ALLC vs. GRIM**: ALLC always cooperates. GRIM starts with cooperation and never observes a defection, so it continues to cooperate. The result is mutual cooperation in all periods.\n    $V(\\text{ALLC, GRIM}) = R$ and $V(\\text{GRIM, ALLC}) = R$.\n\n8.  **ALLD vs. TFT**: ALLD always defects. TFT starts by cooperating.\n    - Period $t=1$: TFT plays C, ALLD plays D. Payoffs are $S$ for TFT, $T$ for ALLD.\n    - Period $t \\geq 2$: TFT observes the defection from period $t-1$ and plays D. ALLD continues to play D. Payoffs are $P$ for both.\n    The payoff stream for TFT is $(S, P, P, \\dots)$. The stream for ALLD is $(T, P, P, \\dots)$.\n    $V(\\text{TFT, ALLD}) = (1-\\delta)S + \\delta P$.\n    $V(\\text{ALLD, TFT}) = (1-\\delta)T + \\delta P$.\n\n9.  **ALLD vs. GRIM**: ALLD always defects. GRIM starts by cooperating.\n    - Period $t=1$: GRIM plays C, ALLD plays D. Payoffs are $S$ for GRIM, $T$ for ALLD.\n    - Period $t \\geq 2$: GRIM observes the defection and switches to permanent defection. ALLD continues to play D. Payoffs are $P$ for both.\n    The payoff streams are identical to the ALLD vs. TFT matchup.\n    $V(\\text{GRIM, ALLD}) = (1-\\delta)S + \\delta P$.\n    $V(\\text{ALLD, GRIM}) = (1-\\delta)T + \\delta P$.\n\n10. **TFT vs. GRIM**: Both strategies start by cooperating. Since no player ever defects, they cooperate in all subsequent periods.\n    $V(\\text{TFT, GRIM}) = R$ and $V(\\text{GRIM, TFT}) = R$.\n\n**Part 2: Payoff Comparison for Unordered Pairs**\n\n-   **ALLC vs. ALLD**: $V(\\text{ALLD, ALLC}) = T$ and $V(\\text{ALLC, ALLD}) = S$. Since $T > S$, $\\text{ALLD}$ obtains the larger payoff.\n-   **ALLC vs. TFT**: $V(\\text{TFT, ALLC}) = R$ and $V(\\text{ALLC, TFT}) = R$. The payoffs are equal for all $\\delta$.\n-   **ALLC vs. GRIM**: $V(\\text{GRIM, ALLC}) = R$ and $V(\\text{ALLC, GRIM}) = R$. The payoffs are equal for all $\\delta$.\n-   **ALLD vs. TFT**: $V(\\text{ALLD, TFT}) = (1-\\delta)T + \\delta P$ and $V(\\text{TFT, ALLD}) = (1-\\delta)S + \\delta P$. The difference is $(1-\\delta)(T-S)$. Given $T > S$ and $\\delta \\in [0, 1)$, we have $1-\\delta > 0$, so the difference is strictly positive. Therefore, $\\text{ALLD}$ obtains the larger payoff for all $\\delta \\in [0,1)$.\n-   **ALLD vs. GRIM**: The payoffs are identical to the ALLD vs. TFT case, so $\\text{ALLD}$ obtains the larger payoff for all $\\delta \\in [0,1)$.\n-   **TFT vs. GRIM**: $V(\\text{TFT, GRIM}) = R$ and $V(\\text{GRIM, TFT}) = R$. The payoffs are equal for all $\\delta$.\n\n**Part 3: Critical Discount Factor Calculation**\n\nThe final task is to find $\\delta^{\\star} \\in [0,1]$ such that the normalized discounted payoff of $\\text{ALLD}$ against $\\text{TFT}$ equals the normalized discounted payoff of $\\text{TFT}$ against $\\text{ALLD}$. This is a direct application of the results from Part 1, requiring the solution to the equation:\n$$\nV(\\text{ALLD, TFT}) = V(\\text{TFT, ALLD})\n$$\nSubstituting the derived expressions:\n$$\n(1-\\delta^{\\star})T + \\delta^{\\star}P = (1-\\delta^{\\star})S + \\delta^{\\star}P\n$$\nThe term $\\delta^{\\star}P$ cancels from both sides:\n$$\n(1-\\delta^{\\star})T = (1-\\delta^{\\star})S\n$$\nThis equation can be rearranged to:\n$$\n(1-\\delta^{\\star})T - (1-\\delta^{\\star})S = 0\n$$\n$$\n(1-\\delta^{\\star})(T - S) = 0\n$$\nThe problem specifies the strict inequality $T > S$, which implies that the term $(T-S)$ is a non-zero positive constant. For the product of two terms to be zero, at least one of the terms must be zero. Therefore, we must have:\n$$\n1 - \\delta^{\\star} = 0\n$$\nSolving for $\\delta^{\\star}$ yields the unique solution:\n$$\n\\delta^{\\star} = 1\n$$\nThis value is in the search set $\\delta^{\\star} \\in [0,1]$ as specified by the problem.", "answer": "$$\\boxed{1}$$", "id": "2527624"}, {"introduction": "While understanding pairwise interactions is crucial, the evolutionary success of a strategy like Tit-for-Tat depends on how it performs within a population of diverse strategies. The replicator equation is a powerful tool from evolutionary game theory that formalizes this process, modeling natural selection as a function of strategy-dependent fitness. This practice will guide you through deriving the fitness functions for cooperators and defectors and analyzing the resulting population dynamics, revealing how cooperation can invade, or be invaded by, defection [@problem_id:2527577].", "problem": "An infinitely large, well-mixed population is composed of two behavioral strategies that interact in pairwise, indefinitely repeated Prisoner’s Dilemma (PD) encounters with a geometric continuation probability $\\delta \\in (0,1)$. The one-shot PD has standard payoffs satisfying $T>R>P>S$, where $T$ is the temptation payoff, $R$ is the reward for mutual cooperation, $P$ is the punishment for mutual defection, and $S$ is the sucker’s payoff. Each repeated encounter yields a sequence of stage payoffs $\\{u_t\\}_{t=1}^{\\infty}$, and an individual’s fitness contribution from a single encounter is the geometrically weighted average payoff per stage,\n$$(1-\\delta)\\sum_{t=1}^{\\infty}\\delta^{t-1}u_t.$$\nThe two strategies are:\n- Tit-for-Tat (TFT): cooperate in the first round; thereafter, cooperate if the partner cooperated in the previous round, defect otherwise.\n- Always Defect (ALLD): defect in every round.\n\nLet $x \\in [0,1]$ denote the frequency of TFT in the population. Assume random matching and that fitness is equal to the expected weighted average payoff per encounter. The frequency dynamics follow the continuous-time replicator equation for two strategies.\n\nTask:\n1. Starting only from the definitions of the repeated-interaction payoff above and the replicator equation, derive the expected fitnesses of TFT and ALLD as functions of $x$, $\\delta$, and the PD payoffs $T,R,P,S$.\n2. Derive the replicator equation for $x$ and determine all fixed points in $[0,1]$.\n3. Analyze the local stability of the boundary fixed points and any interior fixed point in terms of $\\delta$ and the payoffs $T,R,P,S$, providing explicit conditions derived from first principles.\n4. Report, as your final answer, the closed-form expression for the interior fixed point frequency $x^{\\ast}$ (if it exists) as a function of $\\delta$, $T$, $R$, $P$, and $S$. Do not simplify to numerical values.\n\nYour final answer must be a single closed-form expression. No rounding is required.", "solution": "The problem statement is first subjected to validation.\n\nStep 1: Extract Givens\n- Population: Infinitely large, well-mixed.\n- Strategies: Tit-for-Tat (TFT) and Always Defect (ALLD).\n- Frequency of TFT: $x \\in [0,1]$.\n- Interaction: Pairwise, indefinitely repeated Prisoner’s Dilemma (PD).\n- Continuation probability: $\\delta \\in (0,1)$.\n- One-shot PD payoffs: $T>R>P>S$.\n- Fitness contribution from an encounter: $W = (1-\\delta)\\sum_{t=1}^{\\infty}\\delta^{t-1}u_t$, where $u_t$ is the payoff at stage $t$.\n- Dynamics: Continuous-time replicator equation for two strategies.\n\nStep 2: Validate Using Extracted Givens\nThe problem is a standard and fundamental model in evolutionary game theory, specifically concerning the evolution of cooperation.\n- **Scientifically Grounded**: The problem is based on the well-established framework of the replicator equation and repeated games, central to theoretical biology and economics. The Prisoner's Dilemma is a canonical model for studying cooperation. All premises are factually sound within this framework.\n- **Well-Posed**: The problem is clearly defined with all necessary parameters and equations. It is structured to admit a unique and stable solution under specified conditions.\n- **Objective**: The language is precise and devoid of any subjective or non-scientific claims. The tasks are analytical and require rigorous derivation.\n- The problem is self-contained, consistent, and does not contain any of the invalidating flaws listed in the instructions.\n\nStep 3: Verdict and Action\nThe problem is valid. A complete solution will be provided.\n\nThe solution proceeds by following the four tasks specified in the problem statement.\n\nTask 1: Derivation of Expected Fitnesses\nFirst, we determine the discounted payoffs for each possible pairwise encounter between the two strategies, TFT and ALLD. The fitness contribution is the geometrically weighted average payoff, calculated as $(1-\\delta)\\sum_{t=1}^{\\infty}\\delta^{t-1}u_t$.\n\n- **TFT vs. TFT**: Both individuals cooperate in the first round. Since the partner cooperated, both cooperate in the second round, and this continues indefinitely. The payoff sequence for each player is $\\{R, R, R, \\dots\\}$. The discounted payoff is:\n$$W(\\text{TFT} | \\text{TFT}) = (1-\\delta)\\sum_{t=1}^{\\infty}\\delta^{t-1}R = (1-\\delta)R \\left(\\frac{1}{1-\\delta}\\right) = R$$\n\n- **TFT vs. ALLD**: In the first round ($t=1$), TFT cooperates and ALLD defects. TFT receives the sucker's payoff $S$, and ALLD receives the temptation payoff $T$. For all subsequent rounds ($t \\ge 2$), TFT observes the defection from round $t-1$ and defects in response. ALLD continues to defect. Thus, both individuals defect from round $2$ onwards, receiving the punishment payoff $P$ in each of these rounds.\nThe payoff sequence for TFT is $\\{S, P, P, \\dots\\}$, and its discounted payoff is:\n$$W(\\text{TFT} | \\text{ALLD}) = (1-\\delta) \\left( S \\cdot \\delta^0 + \\sum_{t=2}^{\\infty} \\delta^{t-1}P \\right) = (1-\\delta) \\left( S + P \\frac{\\delta}{1-\\delta} \\right) = (1-\\delta)S + \\delta P$$\nThe payoff sequence for ALLD is $\\{T, P, P, \\dots\\}$, and its discounted payoff is:\n$$W(\\text{ALLD} | \\text{TFT}) = (1-\\delta) \\left( T \\cdot \\delta^0 + \\sum_{t=2}^{\\infty} \\delta^{t-1}P \\right) = (1-\\delta) \\left( T + P \\frac{\\delta}{1-\\delta} \\right) = (1-\\delta)T + \\delta P$$\n\n- **ALLD vs. ALLD**: Both individuals defect in every round, starting from the first. The payoff sequence for each is $\\{P, P, P, \\dots\\}$. The discounted payoff is:\n$$W(\\text{ALLD} | \\text{ALLD}) = (1-\\delta)\\sum_{t=1}^{\\infty}\\delta^{t-1}P = (1-\\delta)P \\left(\\frac{1}{1-\\delta}\\right) = P$$\n\nNow, we can write the expected fitness for each strategy, which is the average payoff over all possible encounters. Let $x$ be the frequency of TFT. A TFT individual encounters another TFT with probability $x$ and an ALLD with probability $1-x$.\n\nThe expected fitness of TFT, $W_{\\text{TFT}}(x)$, is:\n$$W_{\\text{TFT}}(x) = x \\cdot W(\\text{TFT} | \\text{TFT}) + (1-x) \\cdot W(\\text{TFT} | \\text{ALLD})$$\n$$W_{\\text{TFT}}(x) = xR + (1-x)((1-\\delta)S + \\delta P)$$\n\nThe expected fitness of ALLD, $W_{\\text{ALLD}}(x)$, is:\n$$W_{\\text{ALLD}}(x) = x \\cdot W(\\text{ALLD} | \\text{TFT}) + (1-x) \\cdot W(\\text{ALLD} | \\text{ALLD})$$\n$$W_{\\text{ALLD}}(x) = x((1-\\delta)T + \\delta P) + (1-x)P$$\n\nTask 2: Replicator Equation and Fixed Points\nThe continuous-time replicator equation for the frequency $x$ of the TFT strategy is given by:\n$$\\dot{x} = \\frac{dx}{dt} = x (W_{\\text{TFT}}(x) - \\bar{W}(x))$$\nwhere $\\bar{W}(x) = x W_{\\text{TFT}}(x) + (1-x) W_{\\text{ALLD}}(x)$ is the average fitness of the population. The equation can be simplified to:\n$$\\dot{x} = x(1-x) (W_{\\text{TFT}}(x) - W_{\\text{ALLD}}(x))$$\nLet's compute the fitness difference, $W_{\\text{TFT}}(x) - W_{\\text{ALLD}}(x)$:\n$$W_{\\text{TFT}}(x) - W_{\\text{ALLD}}(x) = [xR + (1-x)((1-\\delta)S + \\delta P)] - [x((1-\\delta)T + \\delta P) + (1-x)P]$$\nRearranging terms by powers of $x$:\n$$= x(R - ((1-\\delta)T + \\delta P)) - (1-x)(P - ((1-\\delta)S + \\delta P))$$\n$$= x(R - (1-\\delta)T - \\delta P) + (1-x)(-(P - (1-\\delta)S - \\delta P))$$\n$$= x(R - T + \\delta T - \\delta P) + (1-x)( (1-\\delta)S - (1-\\delta)P )$$\n$$= x(R - T + \\delta(T-P)) + (1-x)(S-P)(1-\\delta)$$\nExpanding this expression into a linear function of $x$:\n$$W_{\\text{TFT}}(x) - W_{\\text{ALLD}}(x) = x[R - T + \\delta(T-P) - (S-P)(1-\\delta)] + (S-P)(1-\\delta)$$\n$$= x[R - T + \\delta T - \\delta P - S + P + \\delta S - \\delta P] + (S-P)(1-\\delta)$$\n$$= x[R - T - S + P + \\delta(T+S-2P)] + (S-P)(1-\\delta)$$\nThe fixed points of the replicator dynamics are the values of $x \\in [0,1]$ for which $\\dot{x}=0$.\nFrom $\\dot{x} = x(1-x)(W_{\\text{TFT}}(x) - W_{\\text{ALLD}}(x)) = 0$, we identify three possible fixed points:\n1. $x = 0$: A monomorphic population of ALLD.\n2. $x = 1$: A monomorphic population of TFT.\n3. An interior fixed point $x^*$, where $W_{\\text{TFT}}(x^*) - W_{\\text{ALLD}}(x^*) = 0$.\nSetting the linear expression for the fitness difference to zero gives:\n$$x^*[R - T - S + P + \\delta(T+S-2P)] + (S-P)(1-\\delta) = 0$$\nSolving for $x^*$:\n$$x^* = -\\frac{(S-P)(1-\\delta)}{R - T - S + P + \\delta(T+S-2P)}$$\n$$x^* = \\frac{(P-S)(1-\\delta)}{R - T - S + P + \\delta(T+S-2P)}$$\nThis interior fixed point $x^*$ is biologically meaningful only if $x^* \\in (0,1)$.\n\nTask 3: Local Stability Analysis\nLet $f(x) = \\dot{x} = x(1-x) (W_{\\text{TFT}}(x) - W_{\\text{ALLD}}(x))$. The local stability of a fixed point $x_{fp}$ is determined by the sign of the derivative $f'(x_{fp})$. If $f'(x_{fp}) < 0$, the fixed point is locally stable. If $f'(x_{fp}) > 0$, it is unstable.\nLet $g(x) = W_{\\text{TFT}}(x) - W_{\\text{ALLD}}(x)$. Then $f(x) = x(1-x)g(x)$.\n$f'(x) = (1-2x)g(x) + x(1-x)g'(x)$.\n\n- Stability of $x=0$:\n$f'(0) = (1-0)g(0) + 0 = g(0) = W_{\\text{TFT}}(0) - W_{\\text{ALLD}}(0)$.\nAt $x=0$, $W_{\\text{TFT}}(0)=(1-\\delta)S+\\delta P$ and $W_{\\text{ALLD}}(0)=P$.\n$f'(0) = (1-\\delta)S+\\delta P - P = (1-\\delta)(S-P)$.\nGiven $P>S$ and $\\delta \\in (0,1)$, we have $S-P<0$ and $1-\\delta>0$. Thus, $f'(0) < 0$.\nThe fixed point $x=0$ is always locally stable.\n\n- Stability of $x=1$:\n$f'(1) = (1-2)g(1) + 0 = -g(1) = -(W_{\\text{TFT}}(1) - W_{\\text{ALLD}}(1))$.\nAt $x=1$, $W_{\\text{TFT}}(1)=R$ and $W_{\\text{ALLD}}(1)=(1-\\delta)T+\\delta P$.\n$f'(1) = -[R - ((1-\\delta)T+\\delta P)] = (1-\\delta)T+\\delta P - R$.\nThe fixed point $x=1$ is locally stable if $f'(1) < 0$, which requires:\n$$(1-\\delta)T+\\delta P - R < 0 \\implies R > (1-\\delta)T+\\delta P$$\nThis is the well-known condition for TFT to be an evolutionarily stable strategy (ESS) against ALLD. If the inequality is reversed, $x=1$ is unstable.\n\n- Stability of the interior fixed point $x^*$:\nFor $x^* \\in (0,1)$, it must be that $W_{\\text{TFT}}(x^*)-W_{\\text{ALLD}}(x^*) = g(x^*) = 0$.\nThe derivative at $x^*$ is $f'(x^*) = x^*(1-x^*) g'(x)$.\nThe slope $g'(x)$ is the coefficient of $x$ in the linear expression for $g(x)$:\n$$g'(x) = R - T - S + P + \\delta(T+S-2P)$$\nSo, $f'(x^*) = x^*(1-x^*)[R - T - S + P + \\delta(T+S-2P)]$.\nThe sign of $f'(x^*)$ is determined by the sign of the term in square brackets, which is the denominator of the expression for $x^*$.\nThe interior fixed point $x^*$ exists in $(0,1)$ if and only if $g(0)$ and $g(1)$ have opposite signs.\nWe know $g(0) = (S-P)(1-\\delta) < 0$.\nTherefore, for an interior fixed point to exist, we must have $g(1) > 0$.\n$g(1) = R - ((1-\\delta)T+\\delta P) > 0$, which is the condition for $x=1$ to be stable.\nSo, an interior fixed point $x^* \\in (0,1)$ exists if and only if $R > (1-\\delta)T+\\delta P$.\nUnder this condition:\n- The numerator of $x^*$ is $(P-S)(1-\\delta) > 0$.\n- The denominator is $g'(x) = g(1)-g(0) = [R - ((1-\\delta)T+\\delta P)] - [(S-P)(1-\\delta)]$. Since $g(1)>0$ and $-g(0)>0$, the denominator $g'(x)$ is positive.\nTherefore $x^* > 0$. The condition $g(1)>0$ is also equivalent to $x^*<1$.\nSince the denominator $g'(x)$ is positive, $f'(x^*) = x^*(1-x^*)g'(x) > 0$.\nThis means that if the interior fixed point $x^*$ exists, it is always unstable. This creates a bistable system where the population evolves to all-TFT ($x=1$) if the initial frequency $x_0 > x^*$ and to all-ALLD ($x=0$) if $x_0 < x^*$.\n\nTask 4: Report the Final Answer\nThe final answer is the closed-form expression for the interior fixed point frequency $x^*$, which exists if $R > (1-\\delta)T + \\delta P$.\nThe expression, as derived in Task $2$, is:\n$$x^* = \\frac{(P-S)(1-\\delta)}{R - T - S + P + \\delta(T+S-2P)}$$\nThis is the required final expression.", "answer": "$$\n\\boxed{\\frac{(P-S)(1-\\delta)}{R - T - S + P + \\delta(T+S-2P)}}\n$$", "id": "2527577"}, {"introduction": "Theoretical models of cooperation are built on parameters representing behavioral traits like responsiveness, $\\rho$, or error rates, $\\epsilon$. To test these models against reality, we must be able to estimate these parameters from observational data. This practice introduces the powerful framework of maximum likelihood estimation, guiding you to think like an experimentalist and a statistician by deriving estimators for a model of reactive cooperation. Through this exercise, you will gain hands-on experience with the critical concepts of model fitting and parameter identifiability, which are essential for connecting theory to empirical biology [@problem_id:2527630].", "problem": "A pair of individuals in a cooperative species engage in a long run of repeated dyadic interactions indexed by discrete time steps $t \\in \\{1,2,\\dots,T\\}$. At each step $t \\geq 2$, each individual $i \\in \\{A,B\\}$ produces an observed binary act $Y_{t}^{i} \\in \\{0,1\\}$, where $Y_{t}^{i} = 1$ denotes cooperation and $Y_{t}^{i} = 0$ denotes defection. The underlying behavioral control is a symmetric, reactive policy specified as follows.\n\n- Each individual $i$ forms an intended cooperative act $I_{t}^{i} \\in \\{0,1\\}$ that depends only on the partner’s previous observed act $Y_{t-1}^{-i}$. Conditional on $Y_{t-1}^{-i} = x \\in \\{0,1\\}$, the intended cooperative probability is\n$$\n\\mathbb{P}\\!\\left(I_{t}^{i} = 1 \\,\\big|\\, Y_{t-1}^{-i} = x\\right) = p_{x}, \\quad \\text{with } p_{0} = \\delta,\\; p_{1} = \\delta + \\rho,\n$$\nwhere $\\delta \\in [0,1]$ is the baseline propensity to cooperate and $\\rho \\in \\mathbb{R}$ is the responsiveness to the partner’s previous cooperation, constrained by $0 \\leq \\delta \\leq 1$ and $0 \\leq \\delta + \\rho \\leq 1$.\n\n- Execution is imperfect: with probability $\\epsilon \\in [0,1]$, the observed act flips the intended act, $Y_{t}^{i} = 1 - I_{t}^{i}$, and with probability $1 - \\epsilon$ it is executed as intended, $Y_{t}^{i} = I_{t}^{i}$. Conditional on $Y_{t-1}^{-i}$, the two individuals act independently and identically.\n\nData are collected under three protocols, interleaved across the same dyads over the same horizon $t \\in \\{1,2,\\dots,T\\}$:\n\n- Natural steps: no intervention; only $Y_{t}^{i}$ is recorded. Let $N_{x}$ be the total number of individual acts (pooling both individuals across time) that occur at steps with $Y_{t-1}^{-i} = x$, and let $S_{x}$ be the total number of those acts that are cooperative, for $x \\in \\{0,1\\}$.\n\n- Probe steps: the experimenter exogenously sets $Y_{t-1}^{-i} = x$ via a stimulus with $x \\in \\{0,1\\}$ and directly measures the intended act $I_{t}^{i}$ without execution error (e.g., through validated pre-action signaling proxies). Let $M_{x}$ be the number of such probed instances with stimulus $x$, and $R_{x}$ the number of cooperative intentions observed among those, for $x \\in \\{0,1\\}$.\n\n- Calibration steps: the experimenter directly observes both $I_{t}^{i}$ and $Y_{t}^{i}$ under natural conditions (no probe stimulus). Let $K$ be the number of such calibration instances (pooling both individuals across time), and let $E$ be the number of mismatches where $Y_{t}^{i} \\neq I_{t}^{i}$.\n\nAssume that, conditional on the indicated conditioning variables, all acts across individuals and time are independent Bernoulli trials, and that the scheduling of probe and calibration steps is independent of the individuals’ internal states and actions. The time series is long enough that $N_{x}$, $M_{x}$, and $K$ are each large and finite.\n\nTasks:\n\n- Starting from the definitions of Bernoulli likelihood and conditional independence, write the full likelihood for the joint data under the parameter vector $(\\delta,\\epsilon,\\rho)$, and show how this likelihood factorizes by protocol.\n\n- Using first principles of maximum likelihood estimation, derive closed-form maximum likelihood estimators for $(\\delta,\\epsilon,\\rho)$ in terms of the sufficient statistics $(R_{0},M_{0},R_{1},M_{1},E,K)$.\n\n- Derive the structural identifiability conditions for $(\\delta,\\epsilon,\\rho)$ under (i) natural steps only, and (ii) the combined protocol used here (natural, probe, calibration). State the minimal sample size and parameter-space constraints needed so that the maximum likelihood estimators exist, are unique, and lie in the admissible parameter space.\n\nProvide the final estimators in closed form as a single row vector $(\\hat{\\delta},\\hat{\\epsilon},\\hat{\\rho})$ in terms of $(R_{0},M_{0},R_{1},M_{1},E,K)$. No numerical approximation is required and no rounding is required. Express no units.", "solution": "The problem presented is a well-posed question in statistical modeling and parameter estimation, relevant to the field of behavioral ecology. I will first validate its components and then proceed to a rigorous derivation of the solution.\n\nFirst, an analysis of the problem statement is required.\n\n**Givens:**\n- Individuals $i \\in \\{A,B\\}$, discrete time $t \\in \\{1,2,\\dots,T\\}$.\n- Observed act: $Y_{t}^{i} \\in \\{0,1\\}$, with $1$ for cooperation.\n- Intended act: $I_{t}^{i} \\in \\{0,1\\}$.\n- Intended cooperation probability: $\\mathbb{P}(I_{t}^{i} = 1 | Y_{t-1}^{-i} = x) = p_{x}$, where $p_{0} = \\delta$ and $p_{1} = \\delta + \\rho$.\n- Parameter constraints: $\\delta \\in [0,1]$, $\\rho \\in \\mathbb{R}$, $0 \\leq \\delta + \\rho \\leq 1$.\n- Execution error: $\\mathbb{P}(Y_{t}^{i} \\neq I_{t}^{i}) = \\epsilon$, with $\\epsilon \\in [0,1]$.\n- Independence: Individuals act independently and identically, conditional on $Y_{t-1}^{-i}$.\n- Data from Natural steps: $(S_{x}, N_{x})$ for $x \\in \\{0,1\\}$, where $S_x$ is the number of cooperative acts out of a total of $N_x$ acts following a partner's previous act $x$.\n- Data from Probe steps: $(R_{x}, M_{x})$ for $x \\in \\{0,1\\}$, where $R_x$ is the number of cooperative intentions among $M_x$ probes with stimulus $x$.\n- Data from Calibration steps: $(E, K)$, where $E$ is the number of mismatches $Y_{t}^{i} \\neq I_{t}^{i}$ in $K$ calibration instances.\n- Assumptions: independence of trials conditional on specified variables; large finite sample sizes $N_x, M_x, K$.\n\n**Validation:**\n1.  **Scientific Grounding**: The model is a form of a probabilistic reactive strategy, a standard class of models in game theory and behavioral ecology used to study cooperation (e.g., \"Generous Tit-for-Tat\" with implementation error). It is scientifically sound.\n2.  **Well-Posedness**: The problem asks for the likelihood, estimators, and identifiability conditions. This is a standard and well-posed problem in statistical inference.\n3.  **Objectivity**: The problem is stated in precise mathematical terms, free of subjective content.\n4.  All other criteria for validity (completeness, non-triviality, verifiability) are met. The problem is a rigorous exercise in mathematical statistics.\n\n**Verdict:** The problem is valid. I will proceed with the solution.\n\n**Task 1: Likelihood and Factorization**\n\nThe likelihood function $L(\\delta, \\epsilon, \\rho)$ is the probability of observing the complete dataset given the parameters. Because the three data collection protocols (natural, probe, calibration) are independent processes, the total likelihood is the product of the likelihoods from each protocol.\n$L(\\delta, \\epsilon, \\rho) = L_{\\text{probe}}(\\delta, \\rho) \\cdot L_{\\text{calib}}(\\epsilon) \\cdot L_{\\text{nat}}(\\delta, \\epsilon, \\rho)$.\n\n1.  **Probe Likelihood ($L_{\\text{probe}}$)**:\n    In probe steps, the intended act $I_t^i$ is measured directly. For a given stimulus $x \\in \\{0,1\\}$, the probability of an intended cooperative act is $p_x$. The data consist of $R_x$ cooperative intentions in $M_x$ independent Bernoulli trials. This gives a binomial likelihood for each $x$:\n    $$L_{\\text{probe}}(p_0, p_1) = \\left[\\binom{M_0}{R_0} p_0^{R_0} (1-p_0)^{M_0-R_0}\\right] \\cdot \\left[\\binom{M_1}{R_1} p_1^{R_1} (1-p_1)^{M_1-R_1}\\right]$$\n    Substituting $p_0 = \\delta$ and $p_1 = \\delta + \\rho$:\n    $$L_{\\text{probe}}(\\delta, \\rho) \\propto \\delta^{R_0} (1-\\delta)^{M_0-R_0} \\cdot (\\delta+\\rho)^{R_1} (1-\\delta-\\rho)^{M_1-R_1}$$\n    This component of the likelihood depends only on $\\delta$ and $\\rho$.\n\n2.  **Calibration Likelihood ($L_{\\text{calib}}$)**:\n    In calibration steps, mismatches between intention $I_t^i$ and execution $Y_t^i$ are observed. The probability of a mismatch is $\\epsilon$. The data consist of $E$ mismatches in $K$ independent Bernoulli trials. The likelihood is:\n    $$L_{\\text{calib}}(\\epsilon) = \\binom{K}{E} \\epsilon^E (1-\\epsilon)^{K-E}$$\n    This component of the likelihood depends only on $\\epsilon$.\n\n3.  **Natural Likelihood ($L_{\\text{nat}}$)**:\n    In natural steps, only the executed act $Y_t^i$ is observed. The intention $I_t^i$ is a latent variable. We must find the marginal probability of observing a cooperative act, $\\pi_x = \\mathbb{P}(Y_t^i = 1 | Y_{t-1}^{-i} = x)$. Using the law of total probability, marginalizing over $I_t^i$:\n    $$\\pi_x = \\mathbb{P}(Y_t^i=1|I_t^i=1) \\mathbb{P}(I_t^i=1|Y_{t-1}^{-i}=x) + \\mathbb{P}(Y_t^i=1|I_t^i=0) \\mathbb{P}(I_t^i=0|Y_{t-1}^{-i}=x)$$\n    Substituting the given probabilities:\n    $$\\pi_x = (1-\\epsilon) p_x + \\epsilon (1-p_x) = p_x(1-2\\epsilon) + \\epsilon$$\n    The data consist of $S_x$ cooperative acts in $N_x$ independent Bernoulli trials with success probability $\\pi_x$. The likelihood is:\n    $$L_{\\text{nat}}(p_0, p_1, \\epsilon) = \\left[\\binom{N_0}{S_0} \\pi_0^{S_0} (1-\\pi_0)^{N_0-S_0}\\right] \\cdot \\left[\\binom{N_1}{S_1} \\pi_1^{S_1} (1-\\pi_1)^{N_1-S_1}\\right]$$\n    where $\\pi_0 = \\delta(1-2\\epsilon)+\\epsilon$ and $\\pi_1 = (\\delta+\\rho)(1-2\\epsilon)+\\epsilon$. This component depends on all three parameters.\n\n**Factorization:**\nThe full likelihood for the joint data $(\\{R_x, M_x\\}, \\{E,K\\}, \\{S_x, N_x\\})$ is:\n$$L(\\delta, \\epsilon, \\rho) \\propto \\delta^{R_0} (1-\\delta)^{M_0-R_0} (\\delta+\\rho)^{R_1} (1-\\delta-\\rho)^{M_1-R_1} \\cdot \\epsilon^E (1-\\epsilon)^{K-E} \\cdot \\pi_0^{S_0} (1-\\pi_0)^{N_0-S_0} \\pi_1^{S_1} (1-\\pi_1)^{N_1-S_1}$$\nThe likelihood factorizes into three parts corresponding to the three protocols. However, the parameters are coupled across factors, as $\\delta, \\rho, \\epsilon$ all appear in the term $L_{\\text{nat}}$.\n\n**Task 2: Maximum Likelihood Estimators (MLEs)**\n\nTo find the MLEs, we must maximize the full likelihood, or equivalently, its logarithm $\\ell = \\ln L$.\n$$\\ell(\\delta, \\epsilon, \\rho) = \\ell_{\\text{probe}}(\\delta, \\rho) + \\ell_{\\text{calib}}(\\epsilon) + \\ell_{\\text{nat}}(\\delta, \\epsilon, \\rho)$$\nThe derivative of the full log-likelihood with respect to each parameter must be set to zero. This results in a system of coupled non-linear equations. For example, the score function for $\\epsilon$ is:\n$$\\frac{\\partial \\ell}{\\partial \\epsilon} = \\frac{\\partial \\ell_{\\text{calib}}}{\\partial \\epsilon} + \\frac{\\partial \\ell_{\\text{nat}}}{\\partial \\epsilon} = \\left(\\frac{E}{\\epsilon} - \\frac{K-E}{1-\\epsilon}\\right) + \\sum_{x=0,1} \\left(\\frac{S_x}{\\pi_x} - \\frac{N_x-S_x}{1-\\pi_x}\\right)\\frac{\\partial \\pi_x}{\\partial \\epsilon}$$\nSolving this coupled system does not generally yield a closed-form solution.\n\nHowever, the problem structure and the request for a closed-form solution in terms of only $(R_0, M_0, R_1, M_1, E, K)$ is crucial. This implies that the estimation must rely solely on the data from the probe and calibration experiments, which were designed specifically to provide direct, unconfounded measurements of the parameters. The probe data directly measures intended probabilities $p_0$ and $p_1$, while the calibration data directly measures the error rate $\\epsilon$. This approach is justified because these experiments provide direct identification, and in the large-sample limit (which is assumed), the information from these direct measures dominates the confounded information from the naturalistic data for parameter estimation.\n\nTherefore, we find the estimators by maximizing the likelihood components that depend directly on the target parameters.\n\n1.  **Estimator for $\\epsilon$**: We maximize $L_{\\text{calib}}(\\epsilon)$ or its log-likelihood, $\\ell_{\\text{calib}}(\\epsilon) = E \\ln \\epsilon + (K-E) \\ln(1-\\epsilon) + \\text{const}$.\n    $$\\frac{d\\ell_{\\text{calib}}}{d\\epsilon} = \\frac{E}{\\epsilon} - \\frac{K-E}{1-\\epsilon} = 0 \\implies E(1-\\epsilon) = (K-E)\\epsilon \\implies E = K\\epsilon$$\n    $$\\hat{\\epsilon} = \\frac{E}{K}$$\n\n2.  **Estimator for $\\delta$ and $\\rho$**: We maximize $L_{\\text{probe}}(\\delta, \\rho)$ or its log-likelihood, $\\ell_{\\text{probe}}(\\delta, \\rho)$. It is simpler to reparameterize in terms of $p_0=\\delta$ and $p_1=\\delta+\\rho$. Maximizing the binomial likelihoods for $p_0$ and $p_1$ yields:\n    $$\\hat{p}_0 = \\frac{R_0}{M_0} \\quad \\text{and} \\quad \\hat{p}_1 = \\frac{R_1}{M_1}$$\n    Transforming back to the original parameters:\n    $$\\hat{\\delta} = \\hat{p}_0 = \\frac{R_0}{M_0}$$\n    $$\\hat{\\rho} = \\hat{p}_1 - \\hat{p}_0 = \\frac{R_1}{M_1} - \\frac{R_0}{M_0}$$\n\nThese estimators are the MLEs based on the unconfounded data sources and provide the closed-form solution demanded by the problem.\n\n**Task 3: Identifiability and Constraints**\n\n1.  **Identifiability with Natural Steps Only**:\n    With only natural data, we can consistently estimate the observable probabilities $\\pi_0$ and $\\pi_1$ via $\\hat{\\pi}_x = S_x/N_x$. The parameters $(\\delta, \\rho, \\epsilon)$ are linked to these observables through two equations:\n    $$\\pi_0 = \\delta(1-2\\epsilon) + \\epsilon$$\n    $$\\pi_1 = (\\delta+\\rho)(1-2\\epsilon) + \\epsilon$$\n    This is a system of two equations with three unknowns. For any chosen $\\epsilon \\in [0, 1)$ with $\\epsilon \\neq 1/2$, one can solve for a unique pair $(\\delta, \\rho)$: $\\delta = (\\pi_0 - \\epsilon)/(1-2\\epsilon)$ and $\\rho = (\\pi_1 - \\pi_0)/(1-2\\epsilon)$. This means there is an infinite family of parameter triplets that produce the same observable dynamics. The parameters are therefore not structurally identifiable from natural data alone.\n\n2.  **Identifiability with Combined Protocol**:\n    The combined protocol resolves this ambiguity.\n    - The calibration data allows for direct, unique estimation of $\\epsilon$ via $\\hat{\\epsilon} = E/K$.\n    - The probe data allows for direct, unique estimation of $p_0=\\delta$ and $p_1=\\delta+\\rho$ via $\\hat{p}_0=R_0/M_0$ and $\\hat{p}_1=R_1/M_1$.\n    From these, $\\delta$ and $\\rho$ are uniquely determined. Since all three parameters $(\\delta, \\epsilon, \\rho)$ can be determined uniquely, the model is structurally identifiable under the full protocol.\n\n3.  **Minimal Conditions for Estimators**:\n    For the MLEs to exist, be unique, and lie in the admissible parameter space, the denominators of the estimators must be non-zero.\n    - For $\\hat{\\epsilon} = E/K$: we require the number of calibration trials $K > 0$. The condition $0 \\le E \\le K$ guarantees $0 \\le \\hat{\\epsilon} \\le 1$.\n    - For $\\hat{\\delta} = R_0/M_0$: we require the number of probes $M_0 > 0$. The condition $0 \\le R_0 \\le M_0$ guarantees $0 \\le \\hat{\\delta} \\le 1$.\n    - For $\\hat{\\delta}+\\hat{\\rho} = R_1/M_1$: we require the number of probes $M_1 > 0$. The condition $0 \\le R_1 \\le M_1$ guarantees $0 \\le \\hat{\\delta}+\\hat{\\rho} \\le 1$.\n    Uniqueness of the estimators is guaranteed by the strict concavity of the corresponding log-likelihood functions, provided these sample sizes are positive.\n    Thus, the minimal sample size constraints are $K>0$, $M_{0}>0$, and $M_{1}>0$. The problem states these are large, so these conditions are met.\n\nThe final estimators for $(\\hat{\\delta}, \\hat{\\epsilon}, \\hat{\\rho})$ are collected below.", "answer": "$$ \\boxed{ \\begin{pmatrix} \\frac{R_0}{M_0} & \\frac{E}{K} & \\frac{R_1}{M_1} - \\frac{R_0}{M_0} \\end{pmatrix} } $$", "id": "2527630"}]}