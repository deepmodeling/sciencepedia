{"hands_on_practices": [{"introduction": "This first practice grounds our theoretical understanding by applying the core definitions of an Evolutionarily Stable Strategy (ESS) to a concrete scenario. You will analyze a given $2 \\times 2$ payoff matrix to determine if a pure or mixed strategy is evolutionarily stable. This exercise reinforces the fundamental process of checking stability conditions and identifying strictly dominant strategies, which are guaranteed to be ESSs. [@problem_id:2490130]", "problem": "In a large, well-mixed asexual population where payoffs correspond to additive fitness increments, individuals are randomly paired to play a symmetric game with two heritable strategies, labeled strategy $1$ and strategy $2$. The symmetric payoff matrix is\n$$\nA=\\begin{pmatrix}\n6  2\\\\\n7  3\n\\end{pmatrix},\n$$\nwhere the entry $A_{ij}$ gives the payoff to a focal individual playing strategy $i$ against an opponent playing strategy $j$. An evolutionarily stable strategy (ESS) is defined as a strategy $s$ such that for every mutant strategy $t \\neq s$, either $E(s,s)  E(t,s)$ or, if $E(s,s)=E(t,s)$, then $E(s,t)  E(t,t)$, where $E(x,y)$ denotes the expected payoff to strategy $x$ when facing strategy $y$. Starting from this definition and the notion of symmetric Nash equilibrium in symmetric $2 \\times 2$ games, determine whether the ESS is pure or mixed for the game specified by $A$, and compute it if mixed. Report your final answer as the probability $p^{\\ast}$ assigned to strategy $1$ in the ESS. If the ESS is pure strategy $1$, then $p^{\\ast}=1$; if the ESS is pure strategy $2$, then $p^{\\ast}=0$; if the ESS is mixed, then $p^{\\ast}\\in(0,1)$. No rounding is required, and no physical units apply.", "solution": "The problem requires the determination of the Evolutionarily Stable Strategy (ESS) for a symmetric two-player game defined by the payoff matrix\n$$\nA = \\begin{pmatrix} A_{11}  A_{12} \\\\ A_{21}  A_{22} \\end{pmatrix} = \\begin{pmatrix} 6  2 \\\\ 7  3 \\end{pmatrix}.\n$$\nHere, $A_{ij}$ is the payoff to an individual playing strategy $i$ against an opponent playing strategy $j$. The population is large and well-mixed, and strategies are heritable. An ESS can be a pure strategy (always play strategy $1$ or always play strategy $2$) or a mixed strategy (play strategy $1$ with probability $p$ and strategy $2$ with probability $1-p$). We denote a strategy by the probability $p \\in [0, 1]$ assigned to playing strategy $1$. Thus, a pure strategy $1$ corresponds to $p=1$, a pure strategy $2$ corresponds to $p=0$, and a mixed strategy corresponds to $p \\in (0, 1)$.\n\nThe first step in finding an ESS is typically to find the symmetric Nash Equilibria (NE) of the game, as any ESS must be a NE. A strategy is a symmetric NE if it is a best response to itself.\n\nLet us analyze the given payoff matrix. The payoff for playing strategy $1$ against an opponent is $A_{1j}$ and for playing strategy $2$ is $A_{2j}$.\nWe compare the payoffs for playing strategy $1$ versus strategy $2$ against each of the opponent's possible pure strategies.\n\nCase 1: The opponent plays strategy $1$.\nThe payoff for playing strategy $1$ is $A_{11} = 6$.\nThe payoff for playing strategy $2$ is $A_{21} = 7$.\nSince $7 > 6$, strategy $2$ is a better response to strategy $1$ than strategy $1$ itself. This implies that pure strategy $1$ is not a Nash Equilibrium. A population of individuals playing strategy $1$ could be invaded by a mutant playing strategy $2$, as the mutant would achieve a higher payoff ($7$) than the incumbents ($6$).\n\nCase 2: The opponent plays strategy $2$.\nThe payoff for playing strategy $1$ is $A_{12} = 2$.\nThe payoff for playing strategy $2$ is $A_{22} = 3$.\nSince $3 > 2$, strategy $2$ is a better response to strategy $2$ than strategy $1$. This implies that pure strategy $2$ is a Nash Equilibrium.\n\nFrom this analysis, we observe that $A_{21} > A_{11}$ and $A_{22} > A_{12}$. This means that regardless of the opponent's strategy, playing strategy $2$ yields a strictly higher payoff than playing strategy $1$. Strategy $2$ is a strictly dominant strategy.\n\nTo confirm this more generally, let us consider an opponent playing a mixed strategy $p$, where strategy $1$ is played with probability $p$ and strategy $2$ with probability $1-p$.\nThe expected payoff for playing strategy $1$ against this opponent is:\n$$\nE(1, p) = p \\cdot A_{11} + (1-p) \\cdot A_{12} = 6p + 2(1-p) = 4p + 2\n$$\nThe expected payoff for playing strategy $2$ against this opponent is:\n$$\nE(2, p) = p \\cdot A_{21} + (1-p) \\cdot A_{22} = 7p + 3(1-p) = 4p + 3\n$$\nWe compare these expected payoffs:\n$$\nE(2, p) - E(1, p) = (4p + 3) - (4p + 2) = 1\n$$\nSince $E(2, p) - E(1, p) = 1 > 0$ for any value of $p \\in [0, 1]$, strategy $2$ always yields a strictly higher payoff than strategy $1$, irrespective of the strategy distribution in the population. Therefore, strategy $2$ is a strictly dominant strategy.\n\nWhen a strictly dominant strategy exists, the only Nash Equilibrium is for all players to play that strategy. In this case, the only NE is pure strategy $2$.\n\nNow we must verify if this NE is also an ESS. The definition of an ESS for a strategy $s$ against any mutant strategy $t \\neq s$ is:\n1. $E(s, s) > E(t, s)$ (Stability Condition)\nOR\n2. $E(s, s) = E(t, s)$ and $E(s, t) > E(t, t)$ (Neutral Stability)\n\nLet the incumbent strategy be pure strategy $2$ ($s=2$, which corresponds to $p=0$). Let the mutant strategy be any other strategy $t \\neq 2$. A mutant strategy $t$ can be represented by a probability $p_t \\in (0,1]$ of playing strategy $1$.\nThe payoff for an incumbent playing against another incumbent is $E(2, 2) = A_{22} = 3$.\nThe payoff for a mutant $t$ playing against an incumbent is the expected payoff against strategy $2$:\n$$\nE(t, 2) = p_t \\cdot E(1, 2) + (1-p_t) \\cdot E(2, 2) = p_t \\cdot A_{12} + (1-p_t) \\cdot A_{22} = p_t \\cdot 2 + (1-p_t) \\cdot 3 = 3 - p_t\n$$\nThe first ESS condition requires $E(2, 2) > E(t, 2)$. Let's check this:\n$$\n3 > 3 - p_t\n$$\nThis inequality simplifies to $0 > -p_t$, or $p_t > 0$.\nSince the mutant strategy $t$ must be different from the pure strategy $2$, it must have a non-zero probability of playing strategy $1$, so $p_t > 0$. Therefore, the condition $E(s,s) > E(t,s)$ is satisfied for any possible mutant strategy $t$.\n\nThis confirms that pure strategy $2$ is a strict Nash Equilibrium and therefore is the unique ESS. No mixed strategy ESS exists because there is no mixed strategy Nash Equilibrium, as shown by the payoff comparison $E(2,p) > E(1,p)$.\n\nThe problem asks for the probability $p^{\\ast}$ assigned to strategy $1$ in the ESS. Since the ESS is pure strategy $2$, the probability of playing strategy $1$ is $0$.", "answer": "$$\\boxed{0}$$", "id": "2490130"}, {"introduction": "Moving beyond simple two-player interactions, this problem explores a more complex ecological system with three cyclically competing strategies, modeled by the classic Rock-Paper-Scissors game. Your task is to calculate the \"invasion fitness\" for one morph within a resident population of a specific composition. This practice makes a crucial link between the static payoff matrix and the dynamic process of natural selection, as invasion fitness determines whether a strategy's frequency will increase or decrease over time. [@problem_id:2490104]", "problem": "A well-mixed population of a species exhibits three cyclically interacting behavioral morphs commonly modeled as a rock–paper–scissors game: Rock, Paper, and Scissors. Interactions are pairwise and payoffs capture ecological gains and losses in mating opportunities and resource access. Let the payoff to the row morph against the column morph be given by the matrix\n$$\nA \\;=\\;\n\\begin{pmatrix}\n0  -2  1.5 \\\\\n2  0  -3 \\\\\n-1.5  3  0\n\\end{pmatrix},\n$$\nwhere $A_{ij}$ is the payoff to morph $i$ interacting with morph $j$, with $i,j \\in \\{\\text{Rock},\\text{Paper},\\text{Scissors}\\}$ ordered as $(\\text{Rock},\\text{Paper},\\text{Scissors})$. Assume Malthusian fitnesses are affine in expected payoff: for morph $i$, \n$$\nm_i \\;=\\; m_0 \\;+\\; \\gamma \\, u_i, \\quad \\text{where } u_i \\;=\\; \\sum_{j} A_{ij}\\,p_j,\n$$\n$p_j$ is the frequency of morph $j$, $m_0$ is a baseline Malthusian fitness, and $\\gamma$ is a positive scaling constant. Consider a resident population with morph frequencies $(p_{\\text{Rock}},p_{\\text{Paper}},p_{\\text{Scissors}}) = (0.2,\\,0.5,\\,0.3)$. Define the invasion fitness of a rare Rock morph as the difference between its Malthusian fitness when rare and the resident population’s mean Malthusian fitness. Take $\\gamma = 1$.\n\nUsing these assumptions and definitions, calculate the invasion fitness of a rare Rock morph into this resident population and determine, based on its sign, whether Rock will increase when rare. Express your final numerical answer for the invasion fitness as an exact decimal (no units). No rounding is required.", "solution": "Let the three morphs—Rock, Paper, and Scissors—be indexed by $i, j \\in \\{1, 2, 3\\}$, respectively. The population state is a frequency vector $\\mathbf{p} = (p_1, p_2, p_3)^{\\top}$, where the given frequencies are $p_1 = 0.2$, $p_2 = 0.5$, and $p_3 = 0.3$. The sum of frequencies is $0.2 + 0.5 + 0.3 = 1$, as required.\n\nThe payoff matrix is given by:\n$$\nA \\;=\\;\n\\begin{pmatrix}\n0  -2  1.5 \\\\\n2  0  -3 \\\\\n-1.5  3  0\n\\end{pmatrix}\n$$\nThe Malthusian fitness $m_i$ for a morph $i$ is an affine function of its expected payoff $u_i$:\n$$\nm_i \\;=\\; m_0 \\;+\\; \\gamma \\, u_i\n$$\nwhere $m_0$ is a baseline fitness and $\\gamma$ is a scaling constant. We are given $\\gamma = 1$, so $m_i = m_0 + u_i$.\n\nThe expected payoff $u_i$ for an individual of morph $i$ in a population with frequency vector $\\mathbf{p}$ is calculated by averaging its payoffs against all possible opponents, weighted by their frequencies:\n$$\nu_i \\;=\\; \\sum_{j=1}^{3} A_{ij}\\,p_j\n$$\nThis can be expressed in vector form as $\\mathbf{u} = A\\mathbf{p}$.\n\nThe problem defines the invasion fitness of the Rock morph ($F_1$) as the difference between its Malthusian fitness ($m_1$) and the resident population’s mean Malthusian fitness ($\\bar{m}$).\n$$\nF_1 \\;=\\; m_1 \\;-\\; \\bar{m}\n$$\nThe mean Malthusian fitness $\\bar{m}$ is the average fitness of all individuals in the population, weighted by their morph's frequency:\n$$\n\\bar{m} \\;=\\; \\sum_{i=1}^{3} p_i m_i \\;=\\; \\sum_{i=1}^{3} p_i (m_0 + u_i) \\;=\\; m_0 \\sum_{i=1}^{3} p_i + \\sum_{i=1}^{3} p_i u_i\n$$\nSince $\\sum_{i=1}^{3} p_i = 1$, this simplifies to $\\bar{m} = m_0 + \\bar{u}$, where $\\bar{u} = \\sum_{i=1}^{3} p_i u_i$ is the mean expected payoff in the population.\n\nSubstituting the expressions for $m_1$ and $\\bar{m}$ into the definition of invasion fitness:\n$$\nF_1 \\;=\\; (m_0 + u_1) - (m_0 + \\bar{u}) \\;=\\; u_1 - \\bar{u}\n$$\nThus, the invasion fitness is the difference between the expected payoff of the Rock morph and the mean expected payoff of the entire population. This quantity determines the sign of the rate of change of the Rock morph's frequency, $\\dot{p_1}$, according to the replicator equation $\\dot{p_1} = p_1(m_1 - \\bar{m}) = p_1 F_1$. A positive sign for $F_1$ indicates that the frequency of the Rock morph will increase, while a negative sign indicates it will decrease.\n\nWe now proceed with the calculation. First, we compute the expected payoff $u_i$ for each of the three morphs.\n\nFor the Rock morph ($i=1$):\n$$\nu_1 = A_{11}p_1 + A_{12}p_2 + A_{13}p_3 = (0)(0.2) + (-2)(0.5) + (1.5)(0.3) = 0 - 1 + 0.45 = -0.55\n$$\n\nFor the Paper morph ($i=2$):\n$$\nu_2 = A_{21}p_1 + A_{22}p_2 + A_{23}p_3 = (2)(0.2) + (0)(0.5) + (-3)(0.3) = 0.4 + 0 - 0.9 = -0.5\n$$\n\nFor the Scissors morph ($i=3$):\n$$\nu_3 = A_{31}p_1 + A_{32}p_2 + A_{33}p_3 = (-1.5)(0.2) + (3)(0.5) + (0)(0.3) = -0.3 + 1.5 + 0 = 1.2\n$$\n\nNext, we calculate the mean expected payoff $\\bar{u}$:\n$$\n\\bar{u} = p_1 u_1 + p_2 u_2 + p_3 u_3 = (0.2)(-0.55) + (0.5)(-0.5) + (0.3)(1.2)\n$$\n$$\n\\bar{u} = -0.11 - 0.25 + 0.36 = -0.36 + 0.36 = 0\n$$\n\nFinally, we calculate the invasion fitness of the Rock morph, $F_1$:\n$$\nF_1 = u_1 - \\bar{u} = -0.55 - 0 = -0.55\n$$\n\nThe invasion fitness of the Rock morph is $-0.55$. Since this value is negative, the frequency of the Rock morph will decrease from its current value of $0.2$. Therefore, the Rock morph will not increase from the specified frequency. The problem asks for the numerical value of this invasion fitness.", "answer": "$$\\boxed{-0.55}$$", "id": "2490104"}, {"introduction": "This final exercise challenges you to explore the subtle yet critical distinction between a Nash Equilibrium (NE) and an Evolutionarily Stable Strategy (ESS). Rather than analyzing a given game, you will construct a payoff matrix that satisfies specific constraints to create a scenario where a strategy is a Nash Equilibrium but fails to be an ESS. This hands-on construction solidifies the importance of the second ESS condition, which deals with neutral mutants, and deepens the understanding of what makes a strategy truly robust against invasion. [@problem_id:2490134]", "problem": "In a well-mixed ecological population with two heritable phenotypes, define the symmetric two-player interaction by a payoff function $u(\\cdot,\\cdot)$, measured in offspring equivalents per encounter. The population-level concept of a symmetric Nash equilibrium requires that, for a resident phenotype $\\mathrm{R}$, the condition $u(\\mathrm{R},\\mathrm{R}) \\geq u(\\mathrm{M},\\mathrm{R})$ hold for all possible mutant phenotypes $\\mathrm{M}$. The concept of an Evolutionarily Stable Strategy (ESS), in the sense of Maynard Smith, requires in addition that for every $\\mathrm{M} \\neq \\mathrm{R}$, either $u(\\mathrm{R},\\mathrm{R})  u(\\mathrm{M},\\mathrm{R})$ or, if $u(\\mathrm{R},\\mathrm{R}) = u(\\mathrm{M},\\mathrm{R})$, then $u(\\mathrm{R},\\mathrm{M})  u(\\mathrm{M},\\mathrm{M})$.\n\nConstruct, from first principles, a concrete symmetric two-strategy payoff matrix for the row player,\n$$\n\\begin{pmatrix}\nu(\\mathrm{R},\\mathrm{R})  u(\\mathrm{R},\\mathrm{M}) \\\\\nu(\\mathrm{M},\\mathrm{R})  u(\\mathrm{M},\\mathrm{M})\n\\end{pmatrix},\n$$\nthat exhibits a symmetric Nash equilibrium at $\\mathrm{R}$ that is not an ESS via a neutral deviation $\\mathrm{M}$ that yields a higher second-order payoff against itself. Impose the following ecological calibration constraints:\n\n- Neutrality against the resident: $u(\\mathrm{R},\\mathrm{R}) = u(\\mathrm{M},\\mathrm{R})$.\n- A specified second-order advantage of the mutant against itself over the resident against the mutant: $u(\\mathrm{M},\\mathrm{M}) - u(\\mathrm{R},\\mathrm{M}) = 0.8$.\n- Average per-encounter payoff at a population split evenly between $\\mathrm{R}$ and $\\mathrm{M}$ equals $1.5$:\n$$\\frac{u(\\mathrm{R},\\mathrm{R}) + u(\\mathrm{R},\\mathrm{M}) + u(\\mathrm{M},\\mathrm{R}) + u(\\mathrm{M},\\mathrm{M})}{4} = 1.5.$$\n- Baseline monomorphic resident payoff: $u(\\mathrm{R},\\mathrm{R}) = 1.2$.\n\nUsing only the definitions given above and these constraints, derive the unique value of $u(\\mathrm{M},\\mathrm{M})$ that makes $\\mathrm{R}$ a symmetric Nash equilibrium but not an ESS. Express your final answer in offspring equivalents per encounter. No rounding is required.", "solution": "The problem requires the construction of a symmetric two-strategy payoff matrix where a resident phenotype $\\mathrm{R}$ constitutes a symmetric Nash equilibrium but fails to be an Evolutionarily Stable Strategy (ESS). The analysis will proceed from the definitions and constraints provided.\n\nFirst, let us formalize the given conditions. A resident phenotype $\\mathrm{R}$ is a symmetric Nash equilibrium if, for any mutant phenotype $\\mathrm{M}$, the following inequality holds:\n$$\nu(\\mathrm{R},\\mathrm{R}) \\geq u(\\mathrm{M},\\mathrm{R})\n$$\nThis condition ensures that a mutant cannot gain a fitness advantage by invading a population composed entirely of residents.\n\nFor $\\mathrm{R}$ to be an ESS, a more stringent set of conditions must be met. For any mutant $\\mathrm{M} \\neq \\mathrm{R}$, one of the following two conditions must hold:\n1. $u(\\mathrm{R},\\mathrm{R})  u(\\mathrm{M},\\mathrm{R})$\n2. $u(\\mathrm{R},\\mathrm{R}) = u(\\mathrm{M},\\mathrm{R})$ and $u(\\mathrm{R},\\mathrm{M})  u(\\mathrm{M},\\mathrm{M})$\n\nThe problem states that $\\mathrm{R}$ is a Nash equilibrium but not an ESS. The failure to be an ESS occurs in the case of a neutral deviation, which corresponds to the second ESS condition. That is, we must have $u(\\mathrm{R},\\mathrm{R}) = u(\\mathrm{M},\\mathrm{R})$, which satisfies the Nash equilibrium condition (non-strictly), but the second part of the ESS condition must fail. The failure is specified as the mutant having a \"higher second-order payoff against itself,\" which implies $u(\\mathrm{R},\\mathrm{M}) \\leq u(\\mathrm{M},\\mathrm{M})$.\n\nThe problem provides four explicit constraints that uniquely determine the payoff matrix values: $u(\\mathrm{R},\\mathrm{R})$, $u(\\mathrm{R},\\mathrm{M})$, $u(\\mathrm{M},\\mathrm{R})$, and $u(\\mathrm{M},\\mathrm{M})$. Let us list these as a system of equations.\n\n1.  Baseline monomorphic resident payoff:\n    $$u(\\mathrm{R},\\mathrm{R}) = 1.2$$\n2.  Neutrality against the resident:\n    $$u(\\mathrm{R},\\mathrm{R}) = u(\\mathrm{M},\\mathrm{R})$$\n3.  Specified second-order advantage of the mutant:\n    $$u(\\mathrm{M},\\mathrm{M}) - u(\\mathrm{R},\\mathrm{M}) = 0.8$$\n4.  Average per-encounter payoff at a $50/50$ population split:\n    $$\\frac{u(\\mathrm{R},\\mathrm{R}) + u(\\mathrm{R},\\mathrm{M}) + u(\\mathrm{M},\\mathrm{R}) + u(\\mathrm{M},\\mathrm{M})}{4} = 1.5$$\n\nWe must solve this system for the four unknown payoff values. The objective is to find the specific value of $u(\\mathrm{M},\\mathrm{M})$.\n\nFrom constraint (1), we have the value of the resident's payoff against itself:\n$$u(\\mathrm{R},\\mathrm{R}) = 1.2$$\n\nUsing constraint (2), we can determine the mutant's payoff against the resident:\n$$u(\\mathrm{M},\\mathrm{R}) = u(\\mathrm{R},\\mathrm{R}) = 1.2$$\n\nNow we substitute these known values into constraint (4):\n$$\\frac{1.2 + u(\\mathrm{R},\\mathrm{M}) + 1.2 + u(\\mathrm{M},\\mathrm{M})}{4} = 1.5$$\nMultiplying by $4$ and simplifying gives:\n$$2.4 + u(\\mathrm{R},\\mathrm{M}) + u(\\mathrm{M},\\mathrm{M}) = 6$$\nThis simplifies to a linear relationship between the two remaining unknowns:\n$$u(\\mathrm{R},\\mathrm{M}) + u(\\mathrm{M},\\mathrm{M}) = 3.6$$\n\nWe now have a system of two linear equations for the two unknowns $u(\\mathrm{R},\\mathrm{M})$ and $u(\\mathrm{M},\\mathrm{M})$. The first equation is derived from constraint (4) and the second is constraint (3):\n\\begin{align*}\nu(\\mathrm{R},\\mathrm{M}) + u(\\mathrm{M},\\mathrm{M}) = 3.6 \\\\\n-u(\\mathrm{R},\\mathrm{M}) + u(\\mathrm{M},\\mathrm{M}) = 0.8\n\\end{align*}\nTo solve for $u(\\mathrm{M},\\mathrm{M})$, we can add these two equations together. The $u(\\mathrm{R},\\mathrm{M})$ terms will cancel:\n$$(u(\\mathrm{R},\\mathrm{M}) + u(\\mathrm{M},\\mathrm{M})) + (-u(\\mathrm{R},\\mathrm{M}) + u(\\mathrm{M},\\mathrm{M})) = 3.6 + 0.8$$\n$$2 \\cdot u(\\mathrm{M},\\mathrm{M}) = 4.4$$\nSolving for $u(\\mathrm{M},\\mathrm{M})$ yields:\n$$u(\\mathrm{M},\\mathrm{M}) = \\frac{4.4}{2} = 2.2$$\n\nThis is the required value. For completeness, we can also find $u(\\mathrm{R},\\mathrm{M})$ by substituting the value of $u(\\mathrm{M},\\mathrm{M})$ back into one of the equations:\n$$u(\\mathrm{R},\\mathrm{M}) + 2.2 = 3.6$$\n$$u(\\mathrm{R},\\mathrm{M}) = 3.6 - 2.2 = 1.4$$\n\nThe resulting payoff matrix is:\n$$\n\\begin{pmatrix}\nu(\\mathrm{R},\\mathrm{R})  u(\\mathrm{R},\\mathrm{M}) \\\\\nu(\\mathrm{M},\\mathrm{R})  u(\\mathrm{M},\\mathrm{M})\n\\end{pmatrix}\n=\n\\begin{pmatrix}\n1.2  1.4 \\\\\n1.2  2.2\n\\end{pmatrix}\n$$\nLet us verify that this matrix satisfies the problem's qualitative conditions.\n-   **Nash Equilibrium**: $u(\\mathrm{R},\\mathrm{R}) \\geq u(\\mathrm{M},\\mathrm{R})$ becomes $1.2 \\geq 1.2$, which is true. $\\mathrm{R}$ is a symmetric Nash equilibrium.\n-   **Not an ESS**: We check the two ESS conditions.\n    1.  $u(\\mathrm{R},\\mathrm{R})  u(\\mathrm{M},\\mathrm{R})$ becomes $1.2  1.2$, which is false.\n    2.  This requires us to check the second condition: $u(\\mathrm{R},\\mathrm{R}) = u(\\mathrm{M},\\mathrm{R})$ and $u(\\mathrm{R},\\mathrm{M})  u(\\mathrm{M},\\mathrm{M})$. The first part, $1.2 = 1.2$, is true. The second part, $1.4  2.2$, is false.\nSince both ESS conditions fail, $\\mathrm{R}$ is not an ESS. The failure occurs exactly as described: the mutant $\\mathrm{M}$ is a neutral invader that has a higher payoff against itself than the resident has against it ($u(\\mathrm{M},\\mathrm{M})  u(\\mathrm{R},\\mathrm{M})$), allowing it to proliferate once introduced. The derived value is therefore correct.", "answer": "$$\\boxed{2.2}$$", "id": "2490134"}]}