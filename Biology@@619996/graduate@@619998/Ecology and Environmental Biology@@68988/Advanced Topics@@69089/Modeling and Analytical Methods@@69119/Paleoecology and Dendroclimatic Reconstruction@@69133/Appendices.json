{"hands_on_practices": [{"introduction": "A robust dendroclimatic reconstruction begins with a high-quality tree-ring chronology. This first practice [@problem_id:2517256] delves into a fundamental metric for assessing this quality: the Expressed Population Signal (EPS). By working through the standard signal-plus-noise model, you will derive and calculate EPS to determine if a hypothetical chronology has sufficient common signal to be considered reliable for climate analysis, providing a cornerstone skill for evaluating any proxy dataset.", "problem": "A dendroclimatic site chronology is constructed from $N=15$ detrended, standardized tree-ring width series. Assume the standard site-level signal-plus-noise model in which each series at a given time $t$ can be written as $x_{i,t}=s_{t}+e_{i,t}$, where $s_{t}$ is a common site-wide signal and $e_{i,t}$ are independent, zero-mean, homoscedastic individual noises that are uncorrelated with $s_{t}$. Over a reference interval, the mean interseries correlation among distinct trees is estimated as $\\bar{r}=0.35$. Under these assumptions, starting from the variance decomposition and the definition of interseries correlation in terms of the common-signal and individual-noise variances, derive an expression for the expressed population signal (EPS) in terms of $N$ and $\\bar{r}$. Then compute the EPS for the given $N$ and $\\bar{r}$. In your reasoning, also evaluate whether the commonly used threshold of $0.85$ is met. Report only the EPS value as your final answer. Round your answer to $4$ significant figures. Do not include units.", "solution": "The problem as stated is scientifically grounded, well-posed, objective, and contains sufficient information for a unique solution. It is a standard exercise in dendroclimatology, a sub-discipline of paleoecology, and is therefore valid.\n\nThe task is to derive an expression for the Expressed Population Signal (EPS) and compute its value given a set of parameters from a dendroclimatic study. The foundation for this derivation is the signal-plus-noise model.\n\nLet each standardized tree-ring series $x_{i,t}$ for tree $i$ at time $t$ be represented by the linear model:\n$$x_{i,t} = s_t + e_{i,t}$$\nwhere $s_t$ is the common signal shared by all trees at the site, and $e_{i,t}$ is the random noise unique to tree $i$. The series are standardized, which implies that for any series $i$, its mean is $0$ and its variance is $1$.\n$$\\text{Var}(x_{i,t}) = 1$$\n\nThe problem states several crucial assumptions about the components:\n1. The noise terms $e_{i,t}$ have a mean of zero: $\\mathbb{E}[e_{i,t}] = 0$.\n2. The noise terms are uncorrelated with the common signal $s_t$: $\\text{Cov}(s_t, e_{i,t}) = 0$ for all $i$.\n3. The noise terms are independent across different trees: for $i \\neq j$, $\\text{Cov}(e_{i,t}, e_{j,t}) = 0$.\n4. The noise is homoscedastic, meaning its variance is constant for all series: $\\text{Var}(e_{i,t}) = \\sigma_e^2$.\n\nLet the variance of the common signal be $\\text{Var}(s_t) = \\sigma_s^2$.\nUsing the property that the variance of a sum of uncorrelated variables is the sum of their variances, we can decompose the variance of a single series $x_{i,t}$:\n$$\\text{Var}(x_{i,t}) = \\text{Var}(s_t + e_{i,t}) = \\text{Var}(s_t) + \\text{Var}(e_{i,t})$$\nSince the series are standardized, $\\text{Var}(x_{i,t}) = 1$. This gives the fundamental variance decomposition:\n$$1 = \\sigma_s^2 + \\sigma_e^2$$\n\nNext, we relate these variances to the mean interseries correlation, $\\bar{r}$. The correlation, $r_{ij}$, between two distinct series $x_{i,t}$ and $x_{j,t}$ (where $i \\neq j$) is defined as:\n$$r_{ij} = \\frac{\\text{Cov}(x_{i,t}, x_{j,t})}{\\sqrt{\\text{Var}(x_{i,t})\\text{Var}(x_{j,t})}}$$\nSince $\\text{Var}(x_{i,t}) = \\text{Var}(x_{j,t}) = 1$, the correlation is simply the covariance:\n$$r_{ij} = \\text{Cov}(x_{i,t}, x_{j,t})$$\nWe now compute this covariance:\n$$\\text{Cov}(x_{i,t}, x_{j,t}) = \\text{Cov}(s_t + e_{i,t}, s_t + e_{j,t})$$\nUsing the bilinearity of the covariance operator:\n$$\\text{Cov}(x_{i,t}, x_{j,t}) = \\text{Cov}(s_t, s_t) + \\text{Cov}(s_t, e_{j,t}) + \\text{Cov}(e_{i,t}, s_t) + \\text{Cov}(e_{i,t}, e_{j,t})$$\nFrom our assumptions, for $i \\neq j$, the cross-terms are zero: $\\text{Cov}(s_t, e_{j,t}) = 0$, $\\text{Cov}(e_{i,t}, s_t) = 0$, and $\\text{Cov}(e_{i,t}, e_{j,t}) = 0$. This leaves:\n$$r_{ij} = \\text{Cov}(s_t, s_t) = \\text{Var}(s_t) = \\sigma_s^2$$\nThe mean interseries correlation, $\\bar{r}$, is the average of all such pairwise correlations. Since every $r_{ij}$ (for $i \\neq j$) is equal to $\\sigma_s^2$, their mean is also $\\sigma_s^2$.\n$$\\bar{r} = \\sigma_s^2$$\nFrom the variance decomposition $1 = \\sigma_s^2 + \\sigma_e^2$, we can express the noise variance in terms of $\\bar{r}$:\n$$\\sigma_e^2 = 1 - \\sigma_s^2 = 1 - \\bar{r}$$\n\nThe Expressed Population Signal (EPS) is a measure of how well the site chronology, which is the average of the $N$ available series, represents the true underlying signal $s_t$. The site chronology is:\n$$\\bar{x}_t = \\frac{1}{N} \\sum_{i=1}^N x_{i,t} = \\frac{1}{N} \\sum_{i=1}^N (s_t + e_{i,t}) = s_t + \\frac{1}{N} \\sum_{i=1}^N e_{i,t} = s_t + \\bar{e}_t$$\nEPS is defined as the squared correlation coefficient between the site chronology $\\bar{x}_t$ and the true signal $s_t$:\n$$\\text{EPS} = (\\text{Corr}(\\bar{x}_t, s_t))^2 = \\frac{(\\text{Cov}(\\bar{x}_t, s_t))^2}{\\text{Var}(\\bar{x}_t)\\text{Var}(s_t)}$$\nWe compute the terms in this expression. First, the covariance:\n$$\\text{Cov}(\\bar{x}_t, s_t) = \\text{Cov}(s_t + \\bar{e}_t, s_t) = \\text{Cov}(s_t, s_t) + \\text{Cov}(\\bar{e}_t, s_t) = \\text{Var}(s_t) = \\sigma_s^2$$\nsince $\\text{Cov}(\\bar{e}_t, s_t) = 0$.\nNext, the variance of the site chronology:\n$$\\text{Var}(\\bar{x}_t) = \\text{Var}(s_t + \\bar{e}_t) = \\text{Var}(s_t) + \\text{Var}(\\bar{e}_t) = \\sigma_s^2 + \\text{Var}\\left(\\frac{1}{N} \\sum_{i=1}^N e_{i,t}\\right)$$\nBecause the individual noise terms $e_{i,t}$ are independent, the variance of their sum is the sum of their variances:\n$$\\text{Var}(\\bar{e}_t) = \\frac{1}{N^2} \\sum_{i=1}^N \\text{Var}(e_{i,t}) = \\frac{1}{N^2} \\sum_{i=1}^N \\sigma_e^2 = \\frac{N \\sigma_e^2}{N^2} = \\frac{\\sigma_e^2}{N}$$\nSo, the variance of the chronology is:\n$$\\text{Var}(\\bar{x}_t) = \\sigma_s^2 + \\frac{\\sigma_e^2}{N}$$\nSubstituting these into the formula for EPS:\n$$\\text{EPS} = \\frac{(\\sigma_s^2)^2}{(\\sigma_s^2 + \\frac{\\sigma_e^2}{N})\\sigma_s^2} = \\frac{\\sigma_s^2}{\\sigma_s^2 + \\frac{\\sigma_e^2}{N}}$$\nNow, we substitute $\\sigma_s^2 = \\bar{r}$ and $\\sigma_e^2 = 1 - \\bar{r}$ to express EPS in terms of the given parameters $N$ and $\\bar{r}$:\n$$\\text{EPS} = \\frac{\\bar{r}}{\\bar{r} + \\frac{1-\\bar{r}}{N}}$$\nThis is a valid expression. It is often convenient to eliminate the fraction in the denominator by multiplying the numerator and denominator by $N$:\n$$\\text{EPS} = \\frac{N\\bar{r}}{N\\bar{r} + (1 - \\bar{r})} = \\frac{N\\bar{r}}{1 + N\\bar{r} - \\bar{r}}$$\n$$\\text{EPS} = \\frac{N\\bar{r}}{1 + (N-1)\\bar{r}}$$\nThis is the final derived expression for EPS.\n\nNow, we compute the value for the given data: $N=15$ and $\\bar{r}=0.35$.\n$$\\text{EPS} = \\frac{15 \\times 0.35}{1 + (15-1) \\times 0.35}$$\n$$\\text{EPS} = \\frac{5.25}{1 + 14 \\times 0.35}$$\n$$\\text{EPS} = \\frac{5.25}{1 + 4.9} = \\frac{5.25}{5.9}$$\n$$\\text{EPS} \\approx 0.8898305...$$\nThe problem requires the answer to be rounded to $4$ significant figures, which gives $0.8898$.\n\nThe commonly used threshold for a reliable chronology is $\\text{EPS} \\ge 0.85$. In this case, our computed value of $0.8898$ is greater than $0.85$, so the quality of this chronology would be considered adequate for climatic reconstruction purposes.", "answer": "$$\\boxed{0.8898}$$", "id": "2517256"}, {"introduction": "Once a chronology's signal strength is confirmed, we must understand its precise relationship with climate. This exercise [@problem_id:2517268] explores the temporal dynamics between different tree-ring proxies and climate variables using cross-correlation analysis. You will investigate how maximum latewood density (MXD) and ring width (RW) respond to temperature, learning to identify crucial lead-lag relationships that are essential for building mechanistically sound and statistically robust reconstruction models.", "problem": "A high-elevation conifer site provides standardized, prewhitened chronologies for maximum latewood density (MXD) and ring width (RW), alongside instrumental growing-season and peak-summer temperature anomalies, all as annual anomalies relative to a common baseline. Because standardization and prewhitening have removed most low-frequency growth trends and first-order autocorrelation, assume serial autocorrelation is negligible and that the Pearson product-moment correlation and its associated Student $t$ test are appropriate for inference.\n\nLet years be indexed by $t = 1, \\dots, 10$. Denote the MXD index by $M_t$, the ring-width index by $R_t$, the growing-season temperature anomaly by $G_t$, and the peak-summer temperature anomaly by $P_t$. The observed series are:\n- $M_t$: $\\{-1.8,\\,-1.1,\\,0.0,\\,1.1,\\,1.8,\\,1.9,\\,1.0,\\,0.1,\\,-1.1,\\,-1.9\\}$\n- $R_t$: $\\{0.0,\\,-1.9,\\,-1.1,\\,0.0,\\,0.9,\\,2.1,\\,2.0,\\,1.1,\\,-0.1,\\,-1.0\\}$\n- $G_t$: $\\{-2.1,\\,-1.0,\\,0.1,\\,1.0,\\,2.0,\\,2.1,\\,1.0,\\,-0.1,\\,-1.0,\\,-2.0\\}$\n- $P_t$: $\\{-2,\\,-1,\\,0,\\,1,\\,2,\\,2,\\,1,\\,0,\\,-1,\\,-2\\}$\n\nTasks:\n1) Using the definition of the Pearson correlation coefficient, compute the contemporaneous correlation between the MXD index and the growing-season temperature anomaly, $r_{MG}(0)$.\n\n2) To assess leadâ€“lag relationships with peak-summer temperature, define the cross-correlation for a generic index $X_t \\in \\{M_t, R_t\\}$ at lag $l$ as\n$$\nr_{XP}(l) \\equiv \\operatorname{corr}(X_{t+l},\\,P_t),\n$$\nwhere positive $l$ means the tree-ring index lags temperature by $l$ years, and negative $l$ means the tree-ring index leads temperature by $|l|$ years. Compute $r_{MP}(l)$ for $l \\in \\{-1,\\,0,\\,+1\\}$ and $r_{RP}(l)$ for $l \\in \\{-1,\\,0,\\,+1\\}$, using all available paired years for each $l$. For each index $X_t$, identify the lag $l_X^{\\ast}$ that maximizes $\\lvert r_{XP}(l)\\rvert$ over the set $\\{-1,\\,0,\\,+1\\}$.\n\n3) For the correlation at $l_M^{\\ast}$ and at $l_R^{\\ast}$, test whether each is significantly different from zero at significance level $\\alpha = 0.05$ using the standard $t$ statistic for correlation under bivariate normality:\n$$\nt = r \\sqrt{\\frac{n-2}{1-r^2}},\n$$\nwith $n-2$ degrees of freedom, where $n$ is the number of paired years used at that lag. Use the two-sided critical values $t_{0.975,\\,8} = 2.306$ and $t_{0.975,\\,7} = 2.365$ as needed.\n\nFinally, define the lead (in years) by which MXD leads RW in capturing peak-summer temperature variability as\n$$\n\\Delta l \\equiv l_{R}^{\\ast} - l_{M}^{\\ast}.\n$$\nReport $\\Delta l$ as an integer number of years. If either peak correlation is not significant at $\\alpha=0.05$, set $\\Delta l = 0$. The final answer must be a single number without units.", "solution": "The problem statement has been analyzed and is deemed valid. It is scientifically grounded in standard dendroclimatic principles, well-posed with sufficient data and clear objectives, and free of contradictions or ambiguities. We proceed with the solution.\n\nThe Pearson product-moment correlation coefficient $r$ for two series $X$ and $Y$ of length $n$ is given by\n$$r_{XY} = \\frac{\\sum_{i=1}^{n} (X_i - \\bar{X})(Y_i - \\bar{Y})}{\\sqrt{\\sum_{i=1}^{n} (X_i - \\bar{X})^2} \\sqrt{\\sum_{i=1}^{n} (Y_i - \\bar{Y})^2}}$$\nwhere $\\bar{X}$ and $\\bar{Y}$ are the sample means. If the means are zero, the formula simplifies to\n$$r_{XY} = \\frac{\\sum_{i=1}^{n} X_i Y_i}{\\sqrt{\\sum_{i=1}^{n} X_i^2} \\sqrt{\\sum_{i=1}^{n} Y_i^2}}$$\n\n**Task 1: Correlation between MXD and Growing-Season Temperature, $r_{MG}(0)$**\n\nThe given series are:\n$M_t = \\{-1.8,\\,-1.1,\\,0.0,\\,1.1,\\,1.8,\\,1.9,\\,1.0,\\,0.1,\\,-1.1,\\,-1.9\\}$\n$G_t = \\{-2.1,\\,-1.0,\\,0.1,\\,1.0,\\,2.0,\\,2.1,\\,1.0,\\,-0.1,\\,-1.0,\\,-2.0\\}$\nThe number of observations is $n=10$. First, we verify the means.\n$$\\sum_{t=1}^{10} M_t = -1.8 - 1.1 + 0.0 + 1.1 + 1.8 + 1.9 + 1.0 + 0.1 - 1.1 - 1.9 = 0$$\n$$\\sum_{t=1}^{10} G_t = -2.1 - 1.0 + 0.1 + 1.0 + 2.0 + 2.1 + 1.0 - 0.1 - 1.0 - 2.0 = 0$$\nSince $\\bar{M} = 0$ and $\\bar{G} = 0$, the simplified formula for correlation is applicable. We compute the necessary sums of squares and cross-products.\n$$\\sum_{t=1}^{10} M_t^2 = (-1.8)^2 + (-1.1)^2 + 0.0^2 + 1.1^2 + 1.8^2 + 1.9^2 + 1.0^2 + 0.1^2 + (-1.1)^2 + (-1.9)^2$$\n$$= 3.24 + 1.21 + 0.0 + 1.21 + 3.24 + 3.61 + 1.0 + 0.01 + 1.21 + 3.61 = 18.34$$\n$$\\sum_{t=1}^{10} G_t^2 = (-2.1)^2 + (-1.0)^2 + 0.1^2 + 1.0^2 + 2.0^2 + 2.1^2 + 1.0^2 + (-0.1)^2 + (-1.0)^2 + (-2.0)^2$$\n$$= 4.41 + 1.0 + 0.01 + 1.0 + 4.0 + 4.41 + 1.0 + 0.01 + 1.0 + 4.0 = 20.84$$\n$$\\sum_{t=1}^{10} M_t G_t = (-1.8)(-2.1) + (-1.1)(-1.0) + (0.0)(0.1) + \\dots + (-1.9)(-2.0)$$\n$$= 3.78 + 1.1 + 0.0 + 1.1 + 3.6 + 3.99 + 1.0 - 0.01 + 1.1 + 3.8 = 19.46$$\nThe correlation is therefore:\n$$r_{MG}(0) = \\frac{19.46}{\\sqrt{18.34 \\times 20.84}} = \\frac{19.46}{\\sqrt{382.2056}} \\approx 0.99539$$\n\n**Task 2: Lead-Lag Cross-Correlations with Peak-Summer Temperature**\n\nThe series for peak-summer temperature is $P_t = \\{-2,\\,-1,\\,0,\\,1,\\,2,\\,2,\\,1,\\,0,\\,-1,\\,-2\\}$. The sum is $\\sum P_t = 0$, so $\\bar{P}=0$. For lagged correlations, the series are truncated, and their means must be re-evaluated for each calculation.\n\n**Analysis for MXD ($M_t$) vs. $P_t$:**\n- **Lag $l=0$: $r_{MP}(0) = \\operatorname{corr}(M_t, P_t)$.** Here, $n=10$. Since $\\bar{M}=0$ and $\\bar{P}=0$:\n$$\\sum M_t P_t = (-1.8)(-2) + (-1.1)(-1) + \\dots + (-1.9)(-2) = 3.6+1.1+0+1.1+3.6+3.8+1.0+0+1.1+3.8 = 19.1$$\n$$\\sum M_t^2 = 18.34 \\quad (\\text{from Task 1})$$\n$$\\sum P_t^2 = (-2)^2 + (-1)^2 + \\dots + (-2)^2 = 4+1+0+1+4+4+1+0+1+4 = 20$$\n$$r_{MP}(0) = \\frac{19.1}{\\sqrt{18.34 \\times 20}} = \\frac{19.1}{\\sqrt{366.8}} \\approx 0.99728$$\n\n- **Lag $l=+1$: $r_{MP}(+1) = \\operatorname{corr}(M_{t+1}, P_t)$.** Paired data for $t=1,\\dots,9$, so $n=9$.\nThe series are $X = M_{t+1} = \\{-1.1, 0.0, 1.1, 1.8, 1.9, 1.0, 0.1, -1.1, -1.9\\}$ and $Y = P_t = \\{-2, -1, 0, 1, 2, 2, 1, 0, -1\\}$.\n$\\sum X = 0$, so $\\bar{X}=0$. $\\sum Y = 2$, so $\\bar{Y}=2/9$. We use the general formula.\n$\\sum X Y = 11.8$, $\\sum X^2 = 15.1$, $\\sum Y^2 = 16$.\n$$r_{MP}(+1) = \\frac{9(11.8) - (0)(2)}{\\sqrt{[9(15.1) - 0^2][9(16) - 2^2]}} = \\frac{106.2}{\\sqrt{135.9 \\times 140}} = \\frac{106.2}{\\sqrt{19026}} \\approx 0.76993$$\n\n- **Lag $l=-1$: $r_{MP}(-1) = \\operatorname{corr}(M_{t-1}, P_t)$.** Paired data for $t=2,\\dots,10$, so $n=9$.\nThe series are $X = M_{t-1} = \\{-1.8, -1.1, 0.0, 1.1, 1.8, 1.9, 1.0, 0.1, -1.1\\}$ and $Y = P_t = \\{-1, 0, 1, 2, 2, 1, 0, -1, -2\\}$.\n$\\sum X = 0$, so $\\bar{X}=0$. $\\sum Y = 2$, so $\\bar{Y}=2/9$.\n$\\sum X Y = 11.6$, $\\sum X^2 = 14.73$, $\\sum Y^2 = 16$.\n$$r_{MP}(-1) = \\frac{9(11.6) - (0)(2)}{\\sqrt{[9(14.73) - 0^2][9(16) - 2^2]}} = \\frac{104.4}{\\sqrt{132.57 \\times 140}} = \\frac{104.4}{\\sqrt{18559.8}} \\approx 0.76634$$\n\nComparing absolute values for $M_t$: $|r_{MP}(0)| \\approx 0.997$, $|r_{MP}(+1)| \\approx 0.770$, $|r_{MP}(-1)| \\approx 0.766$. The maximum is at lag $0$. Thus, $l_M^{\\ast} = 0$.\n\n**Analysis for Ring Width ($R_t$) vs. $P_t$:**\nThe series is $R_t = \\{0.0,\\,-1.9,\\,-1.1,\\,0.0,\\,0.9,\\,2.1,\\,2.0,\\,1.1,\\,-0.1,\\,-1.0\\}$.\n$\\sum R_t = 2.0$, so $\\bar{R} = 0.2$. The general correlation formula is required.\n\n- **Lag $l=0$: $r_{RP}(0) = \\operatorname{corr}(R_t, P_t)$.** Here, $n=10$. $\\bar{R}=0.2, \\bar{P}=0$.\n$\\sum R_t=2, \\sum P_t=0$.\n$\\sum R_t P_t = 0 + 1.9 + 0 + 0 + 1.8 + 4.2 + 2.0 + 0 + 0.1 + 2.0 = 12.0$.\n$\\sum R_t^2 = 0 + 3.61 + 1.21 + 0 + 0.81 + 4.41 + 4.0 + 1.21 + 0.01 + 1.0 = 16.26$.\n$\\sum P_t^2 = 20$.\n$$r_{RP}(0) = \\frac{10(12.0) - (2)(0)}{\\sqrt{[10(16.26) - 2^2][10(20) - 0^2]}} = \\frac{120}{\\sqrt{(162.6-4)(200)}} = \\frac{120}{\\sqrt{158.6 \\times 200}} \\approx 0.67377$$\n\n- **Lag $l=+1$: $r_{RP}(+1) = \\operatorname{corr}(R_{t+1}, P_t)$.** Paired data for $t=1,\\dots,9$, so $n=9$.\nThe series are $X = R_{t+1} = \\{-1.9, -1.1, 0.0, 0.9, 2.1, 2.0, 1.1, -0.1, -1.0\\}$ and $Y = P_t = \\{-2, -1, 0, 1, 2, 2, 1, 0, -1\\}$.\n$\\sum X = 2.0$, so $\\bar{X}=2/9$. $\\sum Y = 2.0$, so $\\bar{Y}=2/9$.\n$\\sum X Y = 16.1$, $\\sum X^2 = 16.26$, $\\sum Y^2 = 16$.\n$$r_{RP}(+1) = \\frac{9(16.1) - (2)(2)}{\\sqrt{[9(16.26) - 2^2][9(16) - 2^2]}} = \\frac{144.9 - 4}{\\sqrt{(146.34-4)(144-4)}} = \\frac{140.9}{\\sqrt{142.34 \\times 140}} \\approx 0.99812$$\n\n- **Lag $l=-1$: $r_{RP}(-1) = \\operatorname{corr}(R_{t-1}, P_t)$.** Paired data for $t=2,\\dots,10$, so $n=9$.\nThe series are $X = R_{t-1} = \\{0.0, -1.9, -1.1, 0.0, 0.9, 2.1, 2.0, 1.1, -0.1\\}$ and $Y = P_t = \\{-1, 0, 1, 2, 2, 1, 0, -1, -2\\}$.\n$\\sum X = 3.0$, so $\\bar{X}=1/3$. $\\sum Y = 2.0$, so $\\bar{Y}=2/9$.\n$\\sum X Y = 1.9$, $\\sum X^2 = 15.26$, $\\sum Y^2 = 16$.\n$$r_{RP}(-1) = \\frac{9(1.9) - (3)(2)}{\\sqrt{[9(15.26) - 3^2][9(16) - 2^2]}} = \\frac{17.1 - 6}{\\sqrt{(137.34-9)(144-4)}} = \\frac{11.1}{\\sqrt{128.34 \\times 140}} \\approx 0.08281$$\n\nComparing absolute values for $R_t$: $|r_{RP}(0)| \\approx 0.674$, $|r_{RP}(+1)| \\approx 0.998$, $|r_{RP}(-1)| \\approx 0.083$. The maximum is at lag $+1$. Thus, $l_R^{\\ast} = +1$.\n\n**Task 3: Significance Testing and Final Calculation**\n\nWe test the significance of the correlations at the optimal lags $l_M^{\\ast}=0$ and $l_R^{\\ast}=+1$ using the $t$-statistic $t = r \\sqrt{(n-2)/(1-r^2)}$. The significance level is $\\alpha=0.05$.\n\n- **Test for $r_{MP}(l_M^{\\ast}) = r_{MP}(0) \\approx 0.99728$**:\nHere, $n=10$, so the degrees of freedom are $df = n-2=8$. The two-sided critical value is $t_{0.975, 8} = 2.306$.\n$$t_M = 0.99728 \\sqrt{\\frac{10-2}{1 - (0.99728)^2}} \\approx 0.99728 \\sqrt{\\frac{8}{0.005433}} \\approx 0.99728 \\times 38.373 \\approx 38.27$$\nSince $|t_M| \\approx 38.27 > 2.306$, the correlation is statistically significant at $\\alpha = 0.05$.\n\n- **Test for $r_{RP}(l_R^{\\ast}) = r_{RP}(+1) \\approx 0.99812$**:\nHere, $n=9$, so the degrees of freedom are $df = n-2=7$. The two-sided critical value is $t_{0.975, 7} = 2.365$.\n$$t_R = 0.99812 \\sqrt{\\frac{9-2}{1 - (0.99812)^2}} \\approx 0.99812 \\sqrt{\\frac{7}{0.003757}} \\approx 0.99812 \\times 43.165 \\approx 43.08$$\nSince $|t_R| \\approx 43.08 > 2.365$, this correlation is also statistically significant at $\\alpha = 0.05$.\n\nBoth peak correlations are significant. We can now calculate the lead of MXD over RW.\n$$\\Delta l = l_{R}^{\\ast} - l_{M}^{\\ast} = (+1) - (0) = 1$$\nThis indicates that maximum latewood density leads ring width by $1$ year in its response to peak-summer temperature.", "answer": "$$\\boxed{1}$$", "id": "2517268"}, {"introduction": "The final and most critical step in developing a reconstruction is to rigorously verify its predictive skill against instrumental data not used in calibration. This practice [@problem_id:2517280] moves beyond simple correlation to employ more stringent verification statistics: the Reduction of Error (RE) and Coefficient of Efficiency (CE). By calculating these metrics, you will learn how to formally assess whether a reconstruction model has true predictive power or if it performs worse than a simple climatological mean, a crucial distinction for producing credible paleoclimatic findings.", "problem": "A tree-ring based reconstruction is evaluated over a verification period of $10$ years using observed instrumental summer temperature anomalies $\\{y_t\\}$ and reconstructed anomalies $\\{\\hat{y}_t\\}$. The observed series for the verification period is\n$\\{y_t\\} = \\{0.3,\\ 0.5,\\ -0.2,\\ 0.0,\\ 0.8,\\ 1.1,\\ 0.6,\\ -0.1,\\ 0.2,\\ 0.9\\}$,\nand the reconstructed series is\n$\\{\\hat{y}_t\\} = \\{0.7,\\ 0.7,\\ 0.7,\\ 0.7,\\ 0.7,\\ 0.7,\\ 0.7,\\ 0.7,\\ 0.7,\\ 0.7\\}$.\nAssume these anomalies are standardized relative to a fixed climatological baseline so that the skill metrics are dimensionless.\n\nFrom the independent calibration period (not shown), the mean of the observed anomalies is known to be $\\mu_{\\mathrm{cal}} = 0.6$. In dendroclimatology, predictive skill is assessed by comparing the sum of squared reconstruction errors to a reference sum of squares defined by a fixed baseline. The Reduction of Error (RE) compares to the calibration-period mean baseline, while the Coefficient of Efficiency (CE) compares to the verification-period mean baseline.\n\nStarting from the core definitions of mean, deviation, and sum of squared errors, and using the definitions above for Reduction of Error (RE) and Coefficient of Efficiency (CE) as skill relative to their respective baselines, compute RE and CE for the verification period using the data provided. Then, based on first principles, explain the meaning of a negative CE in this context in terms of relative predictive skill.\n\nRound your numerical answers for RE and CE to four significant figures. Report the final numerical values only. No units are required for these dimensionless metrics.", "solution": "The problem statement has been evaluated and is determined to be valid. It is scientifically grounded in the field of climatology, well-posed, and contains all necessary data and definitions for a unique solution. We shall proceed with the analysis.\n\nThe objective is to compute two standard skill metrics for a climate reconstruction: the Reduction of Error ($RE$) and the Coefficient of Efficiency ($CE$). We must also provide a first-principles explanation for the meaning of a negative $CE$ value.\n\nThe fundamental quantities are the sum of squared errors of the reconstruction model, which we denote as $SSE_{model}$, and the sum of squared errors of a reference forecast, denoted as $SSE_{ref}$. A skill score, $S$, is generally defined as:\n$$S = 1 - \\frac{SSE_{model}}{SSE_{ref}}$$\nA score of $S=1$ indicates a perfect forecast ($SSE_{model}=0$), a score of $S=0$ indicates the model has the same skill as the reference forecast, and a negative score indicates the model is worse than the reference forecast.\n\nThe given data are:\nThe number of years in the verification period, $n = 10$.\nThe observed anomalies, $\\{y_t\\}_{t=1}^{10} = \\{0.3, 0.5, -0.2, 0.0, 0.8, 1.1, 0.6, -0.1, 0.2, 0.9\\}$.\nThe reconstructed anomalies, $\\{\\hat{y}_t\\}_{t=1}^{10} = \\{0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7\\}$.\nThe mean of the observed anomalies from the calibration period, $\\mu_{\\mathrm{cal}} = 0.6$.\n\nThe sum of squared errors for the reconstruction model is given by:\n$$SSE_{model} = \\sum_{t=1}^{n} (y_t - \\hat{y}_t)^2$$\nSubstituting the given values:\n$$SSE_{model} = (0.3-0.7)^2 + (0.5-0.7)^2 + (-0.2-0.7)^2 + (0.0-0.7)^2 + (0.8-0.7)^2 + (1.1-0.7)^2 + (0.6-0.7)^2 + (-0.1-0.7)^2 + (0.2-0.7)^2 + (0.9-0.7)^2$$\n$$SSE_{model} = (-0.4)^2 + (-0.2)^2 + (-0.9)^2 + (-0.7)^2 + (0.1)^2 + (0.4)^2 + (-0.1)^2 + (-0.8)^2 + (-0.5)^2 + (0.2)^2$$\n$$SSE_{model} = 0.16 + 0.04 + 0.81 + 0.49 + 0.01 + 0.16 + 0.01 + 0.64 + 0.25 + 0.04 = 2.61$$\n\nFor the Reduction of Error ($RE$), the reference forecast is the mean of the observed data from the calibration period, $\\mu_{\\mathrm{cal}}$. The sum of squared errors for this reference is:\n$$SSE_{ref,RE} = \\sum_{t=1}^{n} (y_t - \\mu_{\\mathrm{cal}})^2$$\nSubstituting the given values, with $\\mu_{\\mathrm{cal}} = 0.6$:\n$$SSE_{ref,RE} = (0.3-0.6)^2 + (0.5-0.6)^2 + (-0.2-0.6)^2 + (0.0-0.6)^2 + (0.8-0.6)^2 + (1.1-0.6)^2 + (0.6-0.6)^2 + (-0.1-0.6)^2 + (0.2-0.6)^2 + (0.9-0.6)^2$$\n$$SSE_{ref,RE} = (-0.3)^2 + (-0.1)^2 + (-0.8)^2 + (-0.6)^2 + (0.2)^2 + (0.5)^2 + (0.0)^2 + (-0.7)^2 + (-0.4)^2 + (0.3)^2$$\n$$SSE_{ref,RE} = 0.09 + 0.01 + 0.64 + 0.36 + 0.04 + 0.25 + 0.00 + 0.49 + 0.16 + 0.09 = 2.13$$\nThe Reduction of Error is therefore:\n$$RE = 1 - \\frac{SSE_{model}}{SSE_{ref,RE}} = 1 - \\frac{2.61}{2.13} \\approx 1 - 1.225352... = -0.225352...$$\nRounded to four significant figures, $RE = -0.2254$.\n\nFor the Coefficient of Efficiency ($CE$), the reference forecast is the mean of the observed data from the verification period itself, which we denote as $\\bar{y}_{ver}$. First, we must calculate this mean:\n$$\\bar{y}_{ver} = \\frac{1}{n}\\sum_{t=1}^{n} y_t = \\frac{1}{10}(0.3 + 0.5 - 0.2 + 0.0 + 0.8 + 1.1 + 0.6 - 0.1 + 0.2 + 0.9) = \\frac{4.1}{10} = 0.41$$\nThe sum of squared errors for this reference, which is the total sum of squares of the verification data, is:\n$$SSE_{ref,CE} = \\sum_{t=1}^{n} (y_t - \\bar{y}_{ver})^2$$\nSubstituting the values:\n$$SSE_{ref,CE} = (0.3-0.41)^2 + (0.5-0.41)^2 + (-0.2-0.41)^2 + (0.0-0.41)^2 + (0.8-0.41)^2 + (1.1-0.41)^2 + (0.6-0.41)^2 + (-0.1-0.41)^2 + (0.2-0.41)^2 + (0.9-0.41)^2$$\n$$SSE_{ref,CE} = (-0.11)^2 + (0.09)^2 + (-0.61)^2 + (-0.41)^2 + (0.39)^2 + (0.69)^2 + (0.19)^2 + (-0.51)^2 + (-0.21)^2 + (0.49)^2$$\n$$SSE_{ref,CE} = 0.0121 + 0.0081 + 0.3721 + 0.1681 + 0.1521 + 0.4761 + 0.0361 + 0.2601 + 0.0441 + 0.2401 = 1.769$$\nThe Coefficient of Efficiency is therefore:\n$$CE = 1 - \\frac{SSE_{model}}{SSE_{ref,CE}} = 1 - \\frac{2.61}{1.769} \\approx 1 - 1.475409... = -0.475409...$$\nRounded to four significant figures, $CE = -0.4754$.\n\nNow, we explain the meaning of a negative $CE$.\nThe definition is $CE = 1 - \\frac{\\sum_{t=1}^{n} (y_t - \\hat{y}_t)^2}{\\sum_{t=1}^{n} (y_t - \\bar{y}_{ver})^2}$.\nA negative $CE$ implies $CE < 0$. Algebraically, this means:\n$$1 - \\frac{\\sum (y_t - \\hat{y}_t)^2}{\\sum (y_t - \\bar{y}_{ver})^2} < 0$$\n$$\\sum (y_t - \\bar{y}_{ver})^2 < \\sum (y_t - \\hat{y}_t)^2$$\nThe term on the left, $\\sum (y_t - \\bar{y}_{ver})^2$, represents the sum of squared errors that would result from using a naive \"climatology\" forecast where the prediction for every point in the verification period is simply the mean of that period, $\\bar{y}_{ver}$. This is the error of the reference model for $CE$.\nThe term on the right, $\\sum (y_t - \\hat{y}_t)^2$, is the sum of squared errors of the actual reconstruction model, $\\hat{y}_t$.\nTherefore, a negative $CE$ indicates that the reconstruction model's sum of squared errors is greater than the sum of squared errors produced by a simple model that always predicts the mean of the verification period. In terms of predictive skill, this signifies that the reconstruction is less accurate than merely assuming the average condition of the period it is attempting to predict. The model demonstrates \"negative skill\" relative to this specific baseline. It is a fundamental property of statistics that the sample mean, $\\bar{y}_{ver}$, is the constant value that minimizes the sum of squared deviations for the sample $\\{y_t\\}$. Any other constant prediction, such as the $\\hat{y}_t=0.7$ used here, will necessarily yield a larger sum of squared errors and thus a negative $CE$.", "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n-0.2254 & -0.4754\n\\end{pmatrix}\n}\n$$", "id": "2517280"}]}