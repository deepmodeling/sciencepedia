{"hands_on_practices": [{"introduction": "The cornerstone of a robust experimental design is the correct identification of the experimental unit. In ecology, where studies often have complex hierarchical structures, mistaking subsamples for true replicates is a frequent and critical error known as pseudoreplication. This exercise [@problem_id:2538657] challenges you to meticulously dissect a multi-level laboratory experiment to determine the true unit of analysis, which is fundamental for ensuring valid statistical inference.", "problem": "A laboratory microcosm experiment tests the effect of temperature on per-capita metabolic rate of a small aquatic invertebrate. There are $3$ temperature treatments: $12$, $18$, and $24$ degrees Celsius. To implement treatments, the laboratory maintains, for each temperature, $2$ independent water baths, each with its own thermostat and recirculating loop. Within each water bath, $4$ aerated tanks are placed on the same rack and plumbed exclusively to that bath. Each tank contains $8$ individuals drawn at random from a large, well-mixed stock population. Each individual’s oxygen-consumption rate is measured $3$ times on consecutive days with calibrated respirometry. Temperature is controlled only at the water-bath level; all tanks plumbed to the same bath share the same recirculating water and ambient microclimate. No other blocking factors are present. Assume no mortality, no missing data, and that all measurement errors are independent and identically distributed within their appropriate level of the design hierarchy.\n\nThe investigators plan to test whether mean metabolic rate differs among temperatures using a fixed-effect one-way analysis of variance (ANOVA). Starting from core definitions of experimental units, replication, and degrees of freedom, determine the appropriate unit of analysis that avoids pseudoreplication in this design, and compute the denominator degrees of freedom for the $F$-test of the temperature effect under a design-based analysis that respects the randomization.\n\nProvide your final answer as the denominator degrees of freedom for the temperature effect $F$-test (an integer). No rounding is required.", "solution": "The problem requires the determination of the appropriate unit of analysis and the corresponding denominator degrees of freedom for an $F$-test of a treatment effect in a hierarchical experimental design. The solution demands a strict application of the definitions of an experimental unit and replication to avoid the statistical fallacy of pseudoreplication.\n\nFirst, we must define the central concepts. An **experimental unit** is the smallest division of the experimental material to which a treatment is independently applied. True **replication** consists of applying a treatment to multiple, independent experimental units. **Pseudoreplication** occurs when one treats subsamples or repeated measurements from a single experimental unit as if they were independent replicates. The denominator degrees of freedom in an Analysis of Variance ($ANOVA$) for a treatment effect must be based on the number of true experimental units, not the number of subsamples or measurements.\n\nLet us dissect the hierarchical structure of the experiment as described.\nThe treatment factor is temperature, with $a=3$ levels: $12^\\circ\\text{C}$, $18^\\circ\\text{C}$, and $24^\\circ\\text{C}$.\n\nThe highest level of the experimental structure below the treatment is the **water bath**. The problem states that \"for each temperature, [there are] $2$ independent water baths, each with its own thermostat and recirculating loop.\" This statement is critical. The application of a specific temperature is controlled at the level of the water bath. Because each bath has its own thermostat, the assignment of a temperature to one bath is physically and statistically independent of the assignment to any other bath. Therefore, the **water bath is the experimental unit**.\nThe number of true replicates per temperature treatment is $n=2$.\nThe total number of experimental units in the entire experiment is the number of treatments multiplied by the number of replicates per treatment: $N = a \\times n = 3 \\times 2 = 6$.\n\nThe subsequent levels in the design hierarchy are subsamples within these experimental units.\n- **Tanks**: Within each water bath, there are $k=4$ tanks. These tanks \"share the same recirculating water and ambient microclimate.\" Consequently, the observations from tanks within the same water bath are not independent. They are subject to the same random error associated with that specific water bath's temperature regulation and water chemistry. These tanks are **subsamples** or **observational units**, not experimental units.\n- **Individuals**: Within each tank, there are $m=8$ individuals. These individuals are also subsamples, nested within tanks. Their metabolic rates are not independent because they share the common environment of the tank and, by extension, the water bath.\n- **Measurements**: Each individual is measured $p=3$ times. These are **repeated measures** on the same individual and are also not independent replicates of the temperature effect.\n\nA one-way $ANOVA$ tests the hypothesis that the means of the treatment groups are equal. The $F$-statistic for this test is the ratio of the mean square for the treatment to the mean square for the error:\n$$ F = \\frac{\\text{MS}_{\\text{Treatment}}}{\\text{MS}_{\\text{Error}}} $$\nThe $\\text{MS}_{\\text{Treatment}}$ quantifies the variation *among* the mean metabolic rates of the $a=3$ temperature groups. Its degrees of freedom are $df_{\\text{Treatment}} = a - 1 = 3 - 1 = 2$.\nThe $\\text{MS}_{\\text{Error}}$ must quantify the random variation *among the true experimental units* within each treatment group. This is the variation among the water baths. The degrees of freedom for this error term, which become the denominator degrees of freedom for the $F$-test, are calculated based on the total number of experimental units ($N$) and the number of treatment groups ($a$).\n\nThe denominator degrees of freedom are given by:\n$$ \\text{df}_{\\text{Error}} = N - a $$\nIn this design, the total number of experimental units (water baths) is $N=6$, and the number of treatment groups (temperatures) is $a=3$.\nTherefore, the denominator degrees of freedom for the $F$-test of the temperature effect are:\n$$ \\text{df}_{\\text{Error}} = 6 - 3 = 3 $$\nAny analysis that uses the total number of tanks ($24$), individuals ($192$), or measurements ($576$) to calculate the error degrees of freedom (e.g., $24-3=21$, $192-3=189$, or $576-3=573$) would commit the error of pseudoreplication, leading to an invalid inflation of statistical power and a high probability of a Type I error. The correct analysis respects the randomization, which occurred at the level of the water bath. The appropriate error term for the temperature effect is the variation observed among the $n=2$ water baths within each of the $a=3$ temperatures.", "answer": "$$\\boxed{3}$$", "id": "2538657"}, {"introduction": "Once the experimental units are defined, a fundamental question in study design is: how many replicates are needed? Answering this requires a power analysis, which balances the desired statistical power against available resources. This practice [@problem_id:2538634] takes a first-principles approach, guiding you through the derivation of the classic sample size formula for a two-sample test. By building the formula from the ground up, you will gain a deeper intuition for the interplay between effect size ($\\delta$), significance level ($\\alpha$), and power ($1-\\beta$) in planning statistically sound research.", "problem": "An ecologist is planning a randomized, parallel-group field experiment to compare the mean invertebrate biomass between a restored habitat and an unrestored control. Let the restored group have mean $\\mu_{T}$ and the control group have mean $\\mu_{C}$. Assume independent observations, a common and known variance $\\sigma^{2}$ across groups, and equal allocation with $n$ observations per group. The investigator will conduct a $2$-sided hypothesis test of $H_{0}:\\mu_{T}-\\mu_{C}=0$ at significance level $\\alpha$, targeting power $1-\\beta$ to detect a standardized effect size $\\delta$, defined by $\\delta=(\\mu_{T}-\\mu_{C})/\\sigma$. \n\nUsing only first principles that are appropriate for planning in ecological study design—namely, the Central Limit Theorem (CLT), the definition of Type I and Type II errors, and the large-sample normal approximation to the two-sample $t$-statistic—derive the per-group sample size $n$ (not rounded to an integer) required to achieve the specified $\\alpha$, $\\beta$, and $\\delta$ under a $2$-sided test with equal group sizes. \n\nYour derivation must:\n- Start from the distribution of the difference in sample means and the definition of the test statistic under $H_{0}$ and under the alternative.\n- Use the standard normal cumulative distribution function $\\Phi(\\cdot)$ and its quantile function $\\Phi^{-1}(\\cdot)$ to express the rejection threshold for level $\\alpha$ and the noncentral mean under the alternative that corresponds to power $1-\\beta$.\n- Solve explicitly for $n$ in closed form as a function of $\\alpha$, $\\beta$, and $\\delta$.\n\nReport your final answer as a single closed-form analytic expression in terms of $\\Phi^{-1}(\\cdot)$. Do not apply any ceiling or rounding; a numerical evaluation is not required. The sample size is unitless, so no units are needed.", "solution": "The problem statement is scientifically sound, well-posed, objective, and contains all necessary information for a rigorous derivation. It presents a standard task in statistical power analysis. Therefore, the problem is valid, and we proceed with the solution.\n\nWe are tasked to derive the per-group sample size, denoted by $n$, for a two-sample study. The objective is to compare two means, $\\mu_{T}$ for the treatment group and $\\mu_{C}$ for the control group.\n\nLet $\\bar{X}_{T}$ and $\\bar{X}_{C}$ be the sample means obtained from the treatment and control groups, respectively, each of size $n$. The observations are independent, and the population variance $\\sigma^{2}$ is common and assumed to be known. Based on the Central Limit Theorem (CLT), for a sufficiently large sample size $n$, the distributions of the sample means are approximated by the normal distribution:\n$$ \\bar{X}_{T} \\sim \\mathcal{N}\\left(\\mu_{T}, \\frac{\\sigma^{2}}{n}\\right) $$\n$$ \\bar{X}_{C} \\sim \\mathcal{N}\\left(\\mu_{C}, \\frac{\\sigma^{2}}{n}\\right) $$\nDue to the independence of the two groups, the distribution of the difference in sample means, $\\bar{X}_{T} - \\bar{X}_{C}$, is also normal. The expected value and variance of this difference are:\n$$ E[\\bar{X}_{T} - \\bar{X}_{C}] = E[\\bar{X}_{T}] - E[\\bar{X}_{C}] = \\mu_{T} - \\mu_{C} $$\n$$ \\text{Var}(\\bar{X}_{T} - \\bar{X}_{C}) = \\text{Var}(\\bar{X}_{T}) + \\text{Var}(\\bar{X}_{C}) = \\frac{\\sigma^{2}}{n} + \\frac{\\sigma^{2}}{n} = \\frac{2\\sigma^{2}}{n} $$\nThus, the sampling distribution of the difference in means is:\n$$ (\\bar{X}_{T} - \\bar{X}_{C}) \\sim \\mathcal{N}\\left(\\mu_{T} - \\mu_{C}, \\frac{2\\sigma^{2}}{n}\\right) $$\nThe test statistic for the hypothesis test is the standardized difference in sample means. We define the test statistic $Z$ as:\n$$ Z = \\frac{(\\bar{X}_{T} - \\bar{X}_{C}) - (\\mu_{T} - \\mu_{C})}{\\sqrt{\\frac{2\\sigma^{2}}{n}}} $$\nUnder the null hypothesis, $H_{0}: \\mu_{T} - \\mu_{C} = 0$, the statistic simplifies to:\n$$ Z_{0} = \\frac{\\bar{X}_{T} - \\bar{X}_{C}}{\\sigma\\sqrt{\\frac{2}{n}}} $$\nUnder $H_{0}$, $Z_{0}$ follows a standard normal distribution, $Z_{0} \\sim \\mathcal{N}(0, 1)$.\n\nFor a $2$-sided test at a significance level of $\\alpha$, we reject $H_{0}$ if the absolute value of the observed test statistic, $|Z_{0}|$, exceeds the critical value. This critical value is the upper $\\alpha/2$ quantile of the standard normal distribution. Using the standard normal cumulative distribution function $\\Phi(\\cdot)$ and its inverse (the quantile function) $\\Phi^{-1}(\\cdot)$, the critical value is $\\Phi^{-1}(1 - \\alpha/2)$.\nThe rejection rule is: Reject $H_{0}$ if $|Z_{0}| > \\Phi^{-1}(1 - \\alpha/2)$.\n\nNext, we consider the power of the test, $1 - \\beta$. This is the probability of correctly rejecting $H_{0}$ when the alternative hypothesis, $H_{A}$, is true. The problem specifies a standardized effect size $\\delta = (\\mu_{T} - \\mu_{C})/\\sigma$ that we wish to detect. We consider a specific alternative hypothesis where the true difference is $\\mu_{T} - \\mu_{C} = \\Delta$, so $\\delta = \\Delta/\\sigma$.\nThe power is the probability of the test statistic falling into the rejection region, conditional on $H_{A}$ being true. For a $2$-sided test, power is $P(|Z_{0}| > \\Phi^{-1}(1 - \\alpha/2) | \\mu_{T} - \\mu_{C} = \\Delta)$.\nIn typical power calculations for a two-sided test, we assume without loss of generality that $\\Delta > 0$. In this case, the probability of rejecting in the lower tail becomes negligible for reasonable power. The power is dominated by the probability of rejecting in the upper tail.\n$$ 1 - \\beta \\approx P\\left(Z_{0} > \\Phi^{-1}(1 - \\alpha/2) | \\mu_{T} - \\mu_{C} = \\Delta\\right) $$\n$$ 1 - \\beta \\approx P\\left(\\frac{\\bar{X}_{T} - \\bar{X}_{C}}{\\sigma\\sqrt{\\frac{2}{n}}} > \\Phi^{-1}(1 - \\alpha/2) | \\mu_{T} - \\mu_{C} = \\Delta\\right) $$\nTo evaluate this probability, we must standardize the random variable $\\bar{X}_{T} - \\bar{X}_{C}$ under the alternative hypothesis, where its mean is $\\Delta$. We subtract the mean $\\Delta$ and divide by the standard deviation $\\sigma\\sqrt{2/n}$:\n$$ 1 - \\beta \\approx P\\left( \\frac{(\\bar{X}_{T} - \\bar{X}_{C}) - \\Delta}{\\sigma\\sqrt{\\frac{2}{n}}} > \\frac{\\sigma\\sqrt{\\frac{2}{n}}\\Phi^{-1}(1 - \\alpha/2) - \\Delta}{\\sigma\\sqrt{\\frac{2}{n}}} \\right) $$\nThe term on the left inside the probability is a standard normal random variable. Let's call it $Z_{A}$.\n$$ 1 - \\beta \\approx P\\left( Z_{A} > \\Phi^{-1}(1 - \\alpha/2) - \\frac{\\Delta}{\\sigma\\sqrt{\\frac{2}{n}}} \\right) $$\nThe probability that a standard normal variable $Z_{A}$ exceeds some value $c$ is $1 - \\Phi(c)$. For this probability to be equal to $1-\\beta$, the value $c$ must be the quantile $\\Phi^{-1}(\\beta)$.\n$$ \\Phi^{-1}(\\beta) = \\Phi^{-1}(1 - \\alpha/2) - \\frac{\\Delta}{\\sigma\\sqrt{\\frac{2}{n}}} $$\nUsing the symmetry of the normal distribution, $\\Phi^{-1}(\\beta) = -\\Phi^{-1}(1 - \\beta)$. Substituting this and the definition of the standardized effect size $\\delta = \\Delta/\\sigma$:\n$$ -\\Phi^{-1}(1 - \\beta) = \\Phi^{-1}(1 - \\alpha/2) - \\frac{\\delta \\sigma}{\\sigma\\sqrt{\\frac{2}{n}}} $$\n$$ -\\Phi^{-1}(1 - \\beta) = \\Phi^{-1}(1 - \\alpha/2) - \\delta\\sqrt{\\frac{n}{2}} $$\nNow, we must solve for the sample size $n$.\n$$ \\delta\\sqrt{\\frac{n}{2}} = \\Phi^{-1}(1 - \\frac{\\alpha}{2}) + \\Phi^{-1}(1 - \\beta) $$\n$$ \\sqrt{n} = \\frac{\\sqrt{2}}{\\delta} \\left( \\Phi^{-1}(1 - \\frac{\\alpha}{2}) + \\Phi^{-1}(1 - \\beta) \\right) $$\nSquaring both sides yields the final closed-form expression for the per-group sample size $n$:\n$$ n = \\frac{2}{\\delta^{2}} \\left( \\Phi^{-1}(1 - \\frac{\\alpha}{2}) + \\Phi^{-1}(1 - \\beta) \\right)^{2} $$\nThis expression provides the required sample size per group as a function of the desired Type I error rate $\\alpha$, Type II error rate $\\beta$, and standardized effect size $\\delta$.", "answer": "$$ \\boxed{ \\frac{2}{\\delta^2} \\left( \\Phi^{-1}\\left(1 - \\frac{\\alpha}{2}\\right) + \\Phi^{-1}(1 - \\beta) \\right)^{2} } $$", "id": "2538634"}, {"introduction": "Ecological field data are often imperfect; for example, failing to detect a species during a survey does not necessarily mean it is absent. Occupancy modeling provides a powerful statistical framework to account for such imperfect detection, enabling more accurate estimates of species distribution. This problem [@problem_id:2538648] delves into the core concepts of this methodology, contrasting naive estimates of occupancy ($\\psi$) with model-based approaches that explicitly incorporate detection probability ($p$) and false positive rates ($f$) to reduce bias.", "problem": "A researcher designs a repeated-visit species detection study across $N$ spatially distinct sites. Each site is visited $K$ times using a standardized protocol that can yield either a detection or a non-detection at each visit. Assume the following idealizations hold for this study design: site occupancy status does not change during the survey window; visits are conditionally independent given a site’s true occupancy state; detection probability and false positive rate are constant across visits and sites; and detections at unoccupied sites can occur due to errors such as misidentification or sensor noise. Let $\\psi$ denote the probability a randomly selected site is truly occupied, $p$ the probability of recording a detection in a single visit given the site is truly occupied, and $f$ the probability of recording a detection in a single visit given the site is truly unoccupied. Define the naive occupancy estimator as the proportion of sites with at least $1$ recorded detection across $K$ visits. Model-based occupancy estimation uses the full detection histories across $K$ visits at each site to jointly infer $\\psi$ and observation process parameters under a correctly specified likelihood.\n\nSelect all statements that are correct under this framework.\n\nA. Detection probability $p$ is the conditional probability of recording a detection in a single survey given the species is truly present at the site; occupancy $\\psi$ is the marginal probability that a randomly selected site is truly occupied; and the false positive rate $f$ is the conditional probability of recording a detection in a single survey given the species is truly absent.\n\nB. When $f = 0$ and $0 < p < 1$, the expected value of the naive occupancy estimator equals $\\psi\\, p^{K}$, because an occupied site contributes to naive occupancy only if it is detected on all $K$ visits.\n\nC. When $f = 0$ and $0 < p < 1$, the expected value of the naive occupancy estimator equals $\\psi \\,[1 - (1-p)^{K}]$, so the naive estimator is biased low for $\\psi$ unless $p = 1$ or $K$ is sufficiently large that $(1-p)^{K}$ is negligible.\n\nD. When $f > 0$, the expected value of the naive occupancy estimator equals $\\psi \\,[1 - (1-p)^{K}] + (1-\\psi)\\,[1 - (1-f)^{K}]$, so naive occupancy can be larger or smaller than $\\psi$ depending on $p$, $f$, and $K$. A model-based estimator that accounts for both $p$ and $f$ using the full detection histories can be approximately unbiased for $\\psi$ under correct model specification.\n\nE. Model-based occupancy estimation ignores within-site detection histories beyond whether there was at least $1$ detection and is therefore equivalent to the naive estimator.\n\nF. The only way to address imperfect detection is to increase $K$ until every occupied site is detected at least once; without ground-truth presence–absence, statistical modeling cannot adjust for imperfect detection or false positives.", "solution": "The problem statement will be validated before a solution is attempted.\n\n### Step 1: Extract Givens\n- Number of sites: $N$\n- Number of visits per site: $K$\n- Observation outcome: detection or non-detection\n- Assumption 1: Site occupancy status is constant during the survey window (closure).\n- Assumption 2: Visits are conditionally independent given the true occupancy state of a site.\n- Assumption 3: Detection probability and false positive rate are constant across all visits and sites.\n- Assumption 4: Detections at unoccupied sites can occur.\n- $\\psi$: The probability a randomly selected site is truly occupied.\n- $p$: The probability of recording a detection in a single visit given the site is truly occupied.\n- $f$: The probability of recording a detection in a single visit given the site is truly unoccupied.\n- Naive occupancy estimator: The proportion of sites with at least $1$ recorded detection across $K$ visits.\n- Model-based occupancy estimation: Uses the full detection histories to jointly infer $\\psi$, $p$, and $f$ via a correctly specified likelihood.\n\n### Step 2: Validate Using Extracted Givens\nThe problem statement describes a standard ecological statistics scenario known as occupancy modeling. The parameters $\\psi$, $p$, and $f$ are defined in a manner consistent with the established literature (e.g., MacKenzie et al., 2002; Royle & Link, 2006). The assumptions of closure, independence, and constant parameters are the basis for the simplest, yet foundational, occupancy models. The distinction between naive estimation and model-based estimation is also central to this field. The problem is scientifically grounded, well-posed, and objective. It provides all necessary definitions and assumptions to evaluate the provided statements rigorously. There are no contradictions, ambiguities, or factual unsoundness.\n\n### Step 3: Verdict and Action\nThe problem statement is valid. A full analysis of each option will be conducted.\n\n### Analysis of the Options\n\nLet $Z$ be a random variable for the true occupancy state of a randomly selected site, where $Z=1$ if the site is occupied and $Z=0$ if it is unoccupied. From the problem definition, $P(Z=1) = \\psi$ and $P(Z=0) = 1-\\psi$.\nLet $Y_k$ be the random variable for the observation at visit $k$, where $Y_k=1$ for a detection and $Y_k=0$ for a non-detection. The problem defines the conditional probabilities:\n- $p = P(Y_k=1 | Z=1)$\n- $f = P(Y_k=1 | Z=0)$\n\nThe naive occupancy estimator, $\\hat{\\psi}_{\\text{naive}}$, is the proportion of sites where at least one detection was recorded over $K$ visits. The expected value of this estimator, $E[\\hat{\\psi}_{\\text{naive}}]$, is the probability that a randomly selected site has at least one detection. Let $D$ be the event of at least one detection at a site.\n$$E[\\hat{\\psi}_{\\text{naive}}] = P(D) = P(D|Z=1)P(Z=1) + P(D|Z=0)P(Z=0)$$\n\nThe probability of *no* detection in a single visit at an occupied site is $1-p$. The probability of *no* detection in any of the $K$ independent visits is $(1-p)^K$. Thus, the probability of at least one detection is $P(D|Z=1) = 1 - (1-p)^K$.\nSimilarly, the probability of at least one false positive detection at an unoccupied site is $P(D|Z=0) = 1 - (1-f)^K$.\nSubstituting these into the expression for $P(D)$ gives the general formula for the expected value of the naive estimator:\n$$E[\\hat{\\psi}_{\\text{naive}}] = \\psi[1 - (1-p)^K] + (1-\\psi)[1 - (1-f)^K]$$\n\nWe will now evaluate each statement using this framework.\n\n**A. Detection probability $p$ is the conditional probability of recording a detection in a single survey given the species is truly present at the site; occupancy $\\psi$ is the marginal probability that a randomly selected site is truly occupied; and the false positive rate $f$ is the conditional probability of recording a detection in a single survey given the species is truly absent.**\n\nThis statement provides formal probabilistic definitions for the parameters.\n- The parameter $p$ is defined in the problem as \"the probability of recording a detection in a single visit given the site is truly occupied,\" which is precisely the conditional probability $P(\\text{detection} | \\text{present})$.\n- The parameter $\\psi$ is defined as \"the probability a randomly selected site is truly occupied,\" which is the marginal probability $P(\\text{present})$.\n- The parameter $f$ is defined as \"the probability of recording a detection in a single visit given the site is truly unoccupied,\" which is the conditional probability $P(\\text{detection} | \\text{absent})$.\nThe statement is a correct and precise articulation of the definitions provided in the problem statement.\n**Verdict: Correct.**\n\n**B. When $f = 0$ and $0 < p < 1$, the expected value of the naive occupancy estimator equals $\\psi\\, p^{K}$, because an occupied site contributes to naive occupancy only if it is detected on all $K$ visits.**\n\nThe condition for a site to contribute to the naive occupancy count is that it has *at least one* detection, not that it is detected on *all* $K$ visits. The reasoning is fundamentally flawed.\nUsing our general formula for the expected value and setting $f=0$:\n$$E[\\hat{\\psi}_{\\text{naive}}] = \\psi[1 - (1-p)^K] + (1-\\psi)[1 - (1-0)^K]$$\n$$E[\\hat{\\psi}_{\\text{naive}}] = \\psi[1 - (1-p)^K] + (1-\\psi)[1 - 1^K] = \\psi[1 - (1-p)^K]$$\nThe statement claims the expected value is $\\psi p^K$. This is incorrect. The quantity $p^K$ is the probability of detecting the species on *all* $K$ visits, given it is present. The statement is incorrect both in its formula and its reasoning.\n**Verdict: Incorrect.**\n\n**C. When $f = 0$ and $0 < p < 1$, the expected value of the naive occupancy estimator equals $\\psi \\,[1 - (1-p)^{K}]$, so the naive estimator is biased low for $\\psi$ unless $p = 1$ or $K$ is sufficiently large that $(1-p)^{K}$ is negligible.**\n\nFrom the analysis of option B, the formula for the expected value is correct: $E[\\hat{\\psi}_{\\text{naive}}] = \\psi[1 - (1-p)^K]$.\nThe bias of an estimator is the difference between its expected value and the true parameter value.\n$$\\text{Bias} = E[\\hat{\\psi}_{\\text{naive}}] - \\psi = \\psi[1 - (1-p)^K] - \\psi = \\psi - \\psi(1-p)^K - \\psi = -\\psi(1-p)^K$$\nGiven that $\\psi > 0$ and $0 < p < 1$, it follows that $0 < 1-p < 1$. For any finite integer $K \\ge 1$, $(1-p)^K$ is a positive number. Therefore, the bias $-\\psi(1-p)^K$ is strictly negative. An estimator with a negative bias is said to be \"biased low.\"\nThe bias is zero only if $\\psi = 0$ (a trivial case) or if $(1-p)^K = 0$. This second condition is met if $p=1$ (perfect detection) or in the limit as $K \\to \\infty$. The statement that the bias becomes negligible for sufficiently large $K$ is also correct, as $\\lim_{K\\to\\infty} (1-p)^K = 0$. The statement is entirely correct.\n**Verdict: Correct.**\n\n**D. When $f > 0$, the expected value of the naive occupancy estimator equals $\\psi \\,[1 - (1-p)^{K}] + (1-\\psi)\\,[1 - (1-f)^{K}]$, so naive occupancy can be larger or smaller than $\\psi$ depending on $p$, $f$, and $K$. A model-based estimator that accounts for both $p$ and $f$ using the full detection histories can be approximately unbiased for $\\psi$ under correct model specification.**\n\nThe first part of the statement provides the formula for the expected value of the naive estimator. This matches the general formula derived at the beginning of this analysis.\n$$E[\\hat{\\psi}_{\\text{naive}}] = \\psi[1 - (1-p)^K] + (1-\\psi)[1 - (1-f)^K]$$\nThe bias is:\n$$\\text{Bias} = E[\\hat{\\psi}_{\\text{naive}}] - \\psi = -\\psi(1-p)^K + (1-\\psi)[1 - (1-f)^K]$$\nThis bias is composed of two terms: a negative component $-\\psi(1-p)^K$ due to imperfect detection at occupied sites, and a positive component $(1-\\psi)[1 - (1-f)^K]$ due to false positive detections at unoccupied sites. Since the total bias is the sum of a negative and a positive term, its sign depends on their relative magnitudes, which are functions of $\\psi$, $p$, $f$, and $K$. Thus, the naive estimator can overestimate ($\\text{Bias} > 0$) or underestimate ($\\text{Bias} < 0$) the true occupancy $\\psi$.\nThe second part of the statement addresses the utility of model-based estimation. The entire purpose of constructing a likelihood from the full detection histories is to separate the ecological state process (parameter $\\psi$) from the observation process (parameters $p$ and $f$). Maximum likelihood estimators, which are derived from such models, are known to be consistent and asymptotically unbiased under correct model specification. For a finite sample size $N$, they are approximately unbiased. This statement accurately describes a primary advantage of model-based occupancy estimation.\n**Verdict: Correct.**\n\n**E. Model-based occupancy estimation ignores within-site detection histories beyond whether there was at least $1$ detection and is therefore equivalent to the naive estimator.**\n\nThis statement is a direct contradiction of the definition given in the problem statement, which says model-based estimation \"uses the full detection histories.\" A full detection history is a sequence of outcomes, like $(0, 1, 0, 0, \\dots)$, not just a summary of whether any detection occurred. The naive estimator collapses this detailed information into a binary variable (detection/no detection overall). The model-based approach uses the full sequence to build a likelihood function, from which parameters like $p$ and $f$ can be estimated. For example, the two histories $(1, 0, 0, 0)$ and $(1, 1, 1, 1)$ yield the same naive result but provide substantially different information for estimating $p$. Therefore, model-based estimation is fundamentally different from and not equivalent to the naive estimator.\n**Verdict: Incorrect.**\n\n**F. The only way to address imperfect detection is to increase $K$ until every occupied site is detected at least once; without ground-truth presence–absence, statistical modeling cannot adjust for imperfect detection or false positives.**\n\nThis statement makes two strong, incorrect claims. First, it claims increasing $K$ is the *only* way to address imperfect detection. This is false. The entire premise of the problem is that statistical modeling provides an alternative way to account for imperfect detection and obtain an unbiased estimate of $\\psi$ without requiring $p=1$ or $K \\to \\infty$.\nSecond, it claims that \"without ground-truth presence–absence, statistical modeling cannot adjust for imperfect detection or false positives.\" This is precisely the fallacy that occupancy modeling was designed to overcome. By using repeated observations at sites, the model can estimate the observation process parameters ($p$ and $f$) directly from the data, even without a pre-verified set of occupied and unoccupied sites. The replication in the survey design provides the statistical power to separate the state and observation processes.\n**Verdict: Incorrect.**", "answer": "$$\\boxed{ACD}$$", "id": "2538648"}]}