{"hands_on_practices": [{"introduction": "The journey from raw sequencing data to a meaningful contact map begins with rigorous quality control. Not all mapped read pairs represent genuine long-range chromatin interactions; many are artifacts arising from the molecular biology of the Hi-C/Micro-C protocol. This first practice challenges you to build a classifier from first principles to distinguish valid contacts from common artifacts, such as dangling ends, re-ligations, and self-circles, a critical first step in any Hi-C analysis pipeline. [@problem_id:2939509]", "problem": "Design and implement a program that classifies paired-end alignments from High-throughput chromosome conformation capture (Hi-C) or Micrococcal nuclease-based chromosome conformation capture (Micro-C) into mechanistic categories based on alignment flags (strands) and genomic positions, using only fundamental facts about restriction digestion, ligation geometry, and paired-end sequencing orientation. Your classifier must use a purely logical rule set grounded in the following base facts and definitions:\n\n- In Chromosome Conformation Capture (3C)-derived assays such as Hi-C and Micro-C, DNA is cut into fragments whose ends can ligate. Restriction enzymes in Hi-C cut at known genomic coordinates (restriction cut sites). For Micro-C, micrococcal nuclease generates fragment boundaries; for this problem, boundaries are provided as if generated by restriction enzyme digestion. Positions are measured in base pairs (bp).\n- A paired-end read maps two reads to the genome, each with a strand: plus ($+$) or minus ($-$). When both reads map to the same chromosome, define the left read as the one with the smaller genomic coordinate. When ordered left-to-right by coordinate on the same chromosome, an inward-facing pair has strands $(+,-)$; an outward-facing pair has strands $(-,+)$; otherwise, the orientation is \"other.\"\n- A restriction fragment on a chromosome is the half-open interval between two consecutive cut sites. For a position $p$ with a sorted cut list $C = [c_0,c_1,\\dots,c_n]$, the fragment containing $p$ is the interval $(c_i, c_{i+1}]$ such that $c_i < p \\le c_{i+1}$. The left boundary is $c_i$ and the right boundary is $c_{i+1}$.\n- Define the distance from a mapped position $p$ to its fragment’s left boundary as $d_{\\text{left}} = p - c_i$, and to its right boundary as $d_{\\text{right}} = c_{i+1} - p$. The distance to a specific cut site $s$ is $|p - s|$.\n\nUsing these foundations, implement the following classification logic with thresholds expressed in base pairs:\n\n- Dangling end: reads map to the same fragment, they are inward-facing, and both are near the same boundary (i.e., the nearest boundary to each read is the same cut site), with each read’s distance to that boundary $\\le t_{\\text{dang}}$.\n- Re-ligation: reads map to two adjacent fragments that share a cut site $s$, they are outward-facing, and both are near the shared cut site, with each read’s distance to $s$ $\\le t_{\\text{reli}}$.\n- Self-circle: reads map to the same fragment, they are outward-facing, and one read is near the left boundary while the other is near the right boundary, with the respective distances $\\le t_{\\text{self}}$.\n- Valid: any pair not meeting the above artefactual patterns is considered a valid contact.\n\nYou must implement a program that, given a fixed set of restriction cut sites per chromosome and a fixed set of read pairs with strands and positions, computes a classification code for each pair according to the rule set above. Use the following integer encoding for the output categories:\n- Valid contact $\\to$ $1$\n- Dangling end $\\to$ $2$\n- Re-ligation $\\to$ $3$\n- Self-circle $\\to$ $4$\n\nThreshold parameters (in base pairs) to use for all test cases are:\n- $t_{\\text{dang}} = 25$\n- $t_{\\text{reli}} = 25$\n- $t_{\\text{self}} = 25$\n\nRestriction cut sites (sorted, in base pairs) per chromosome are:\n- Chromosome \"chrA\": $[0, 1000, 2000, 3000, 4000, 100000]$\n- Chromosome \"chrB\": $[0, 500, 1500, 2500, 100000]$\n\nTest suite of paired-end mappings (each as $(\\text{chrom}_1, p_1, s_1, \\text{chrom}_2, p_2, s_2)$ with $p$ in base pairs and $s \\in \\{+,-\\}$):\n- Case $1$: $\\text{chrA}, 1010, +, \\text{chrA}, 1020, -$ (same fragment, near same boundary, inward)\n- Case $2$: $\\text{chrA}, 1995, -, \\text{chrA}, 2005, +$ (adjacent fragments around shared cut, outward)\n- Case $3$: $\\text{chrA}, 1010, -, \\text{chrA}, 1990, +$ (same fragment, opposite boundaries, outward)\n- Case $4$: $\\text{chrA}, 1500, +, \\text{chrB}, 700, -$ (inter-chromosomal)\n- Case $5$: $\\text{chrA}, 1500, +, \\text{chrA}, 3500, -$ (different non-adjacent fragments)\n- Case $6$: $\\text{chrA}, 2975, -, \\text{chrA}, 3025, +$ (adjacent, exactly at threshold, outward)\n- Case $7$: $\\text{chrA}, 1990, +, \\text{chrA}, 2010, +$ (adjacent, same-strand)\n- Case $8$: $\\text{chrB}, 1500, -, \\text{chrB}, 1503, +$ (one read exactly on cut, outward)\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, in the order of the test cases defined above. For example, the output format must be exactly like $[r_1,r_2,\\dots,r_8]$ where each $r_i$ is an integer encoding the classification of case $i$ defined above. All distances and thresholds are in base pairs, and no additional text should be printed.", "solution": "The problem as stated is valid. It is scientifically grounded in the principles of chromosome conformation capture experiments, well-posed with clear and unambiguous definitions, and provides a complete set of data and constraints for a deterministic solution. There are no logical contradictions, scientific inaccuracies, or ill-defined terms. We may, therefore, proceed with the design of a classification algorithm.\n\nThe development of the classifier is a deductive process, starting from the given axiomatic definitions of molecular biological events and sequencing geometry. The objective is to construct a set of mutually exclusive logical conditions that map each paired-end read to a unique category. A read pair is defined by the tuple $(\\text{chrom}_1, p_1, s_1, \\text{chrom}_2, p_2, s_2)$, where $\\text{chrom}$ denotes the chromosome, $p$ is the $5'$-end mapping coordinate, and $s \\in \\{+, -\\}$ is the strand.\n\nThe algorithm proceeds in the following sequential steps:\n\n1.  **Initial Triage**: The first distinction is between inter-chromosomal and intra-chromosomal contacts.\n    If $\\text{chrom}_1 \\neq \\text{chrom}_2$, the reads map to different chromosomes. Such pairs represent long-range interactions and do not fit the mechanistic patterns of the specified artifacts, which are defined for reads in close proximity on the same chromosome. Therefore, all inter-chromosomal pairs are classified as **Valid** (code $1$).\n\n2.  **Standardization of Intra-chromosomal Pairs**: For a pair on the same chromosome, we must establish a canonical representation to simplify downstream logic. The reads are ordered by their genomic coordinate. Let the \"left\" read $(p_L, s_L)$ be the one with the smaller coordinate and the \"right\" read $(p_R, s_R)$ be the one with the larger coordinate.\n    $$\n    p_L = \\min(p_1, p_2), \\quad p_R = \\max(p_1, p_2)\n    $$\n    The strands $s_L$ and $s_R$ are assigned to correspond to their respective positions.\n\n3.  **Orientation Analysis**: The relative orientation of the standardized pair is fundamental. Based on the problem definition:\n    - If $(s_L, s_R) = (+, -)$, the pair is **inward-facing**.\n    - If $(s_L, s_R) = (-, +)$, the pair is **outward-facing**.\n    - If $(s_L, s_R) = (+, +)$ or $(-, -)$, the orientation is designated as **\"other\"**.\n    The specified artifact types (Dangling end, Re-ligation, Self-circle) require either an inward or outward orientation. Any pair with an \"other\" orientation cannot be one of these artifacts and is thus classified as **Valid** (code $1$).\n\n4.  **Fragment Identification**: The genomic context of each read must be determined. For a given chromosome with a sorted list of cut sites $C = [c_0, c_1, \\dots, c_n]$, the fragment containing a position $p$ is the half-open interval $(c_j, c_{j+1}]$ such that $c_j < p \\le c_{j+1}$. To find this interval for a given position $p$, we must identify the index $j$. This is efficiently accomplished using a binary search algorithm. We find the index $k$ such that $c_{k-1} < p \\le c_k$. The boundaries of the fragment containing $p$ are then $(c_{k-1}, c_k)$. Let the fragment for the left read $p_L$ be $(c_{L,i}, c_{L,i+1}]$ and for the right read $p_R$ be $(c_{R,j}, c_{R,j+1}]$.\n\n5.  **Rule-Based Classification**: With the orientation and fragment context established, we apply the specific logical rules for each artifact category.\n\n    - **Re-ligation (Code $3$)**: This artifact arises from the ligation of two ends from adjacent fragments.\n        - The reads must be in adjacent fragments. This is true if the right boundary of the left read's fragment is the same as the left boundary of the right read's fragment, i.e., $c_{L,i+1} = c_{R,j}$. Let this shared cut site be $c_{shared}$.\n        - The pair must be outward-facing, i.e., $(s_L, s_R) = (-, +)$.\n        - Both reads must be close to the shared cut site. The distance from each read's position to $c_{shared}$ must be no more than the threshold $t_{\\text{reli}}$.\n        Condition: $c_{L,i+1} = c_{R,j} = c_{shared}$ AND $(s_L, s_R) = (-, +)$ AND $|p_L - c_{shared}| \\le t_{\\text{reli}}$ AND $|p_R - c_{shared}| \\le t_{\\text{reli}}$.\n        Note that since $p_L \\in (c_{L,i}, c_{shared}]$ and $p_R \\in (c_{shared}, c_{R,j+1}]$, the absolute values can be written as $c_{shared} - p_L$ and $p_R - c_{shared}$.\n\n    - **Same-Fragment Artifacts**: If the reads map to the same fragment, i.e., $c_{L,i} = c_{R,j}$ and $c_{L,i+1} = c_{R,j+1}$, we check for either a dangling end or a self-circle. Let the common fragment be $(c_i, c_{i+1}]$.\n\n        - **Dangling End (Code $2$)**: This artifact results from incomplete digestion, where two reads originate from the same side of a single ligation junction.\n            - The pair must be inward-facing, i.e., $(s_L, s_R) = (+, -)$.\n            - Both reads must be proximal to the *same* fragment boundary. We determine the nearest boundary for each read. For $p_L$, the nearest boundary is $\\text{argmin}_{b \\in \\{c_i, c_{i+1}\\}} |p_L - b|$. For $p_R$, it is $\\text{argmin}_{b \\in \\{c_i, c_{i+1}\\}} |p_R - b|$. Let this common nearest boundary be $b^*$.\n            - The distance from each read to this common boundary $b^*$ must be no more than the threshold $t_{\\text{dang}}$.\n            Condition: $p_L, p_R \\in (c_i, c_{i+1}]$ AND $(s_L, s_R) = (+, -)$ AND $\\text{argmin}_{b \\in \\{c_i, c_{i+1}\\}} |p_L-b| = \\text{argmin}_{b \\in \\{c_i, c_{i+1}\\}} |p_R-b| = b^*$ AND $|p_L - b^*| \\le t_{\\text{dang}}$ AND $|p_R - b^*| \\le t_{\\text{dang}}$.\n\n        - **Self-circle (Code $4$)**: This artifact results from the circularization of a single restriction fragment.\n            - The pair must be outward-facing, i.e., $(s_L, s_R) = (-, +)$.\n            - The two reads must be located near the opposite ends of the fragment. Since $p_L < p_R$, this means the left read $p_L$ must be near the left boundary $c_i$, and the right read $p_R$ must be near the right boundary $c_{i+1}$.\n            - The respective distances to these boundaries must be no more than the threshold $t_{\\text{self}}$.\n            Condition: $p_L, p_R \\in (c_i, c_{i+1}]$ AND $(s_L, s_R) = (-, +)$ AND $(p_L - c_i) \\le t_{\\text{self}}$ AND $(c_{i+1} - p_R) \\le t_{\\text{self}}$.\n\n6.  **Default Classification**: If a read pair does not satisfy any of the conditions for codes $2$, $3$, or $4$, it is, by elimination, classified as a **Valid** contact (code $1$). This includes reads in non-adjacent fragments or pairs that are far from any restriction site.\n\nThis logical structure ensures that every pair is assigned a single, unambiguous classification based strictly on the provided definitions.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to define test cases and run the classification.\n    \"\"\"\n    \n    # Define thresholds as per the problem statement.\n    t_dang = 25\n    t_reli = 25\n    t_self = 25\n\n    # Define restriction cut sites per chromosome.\n    cut_sites = {\n        \"chrA\": np.array([0, 1000, 2000, 3000, 4000, 100000], dtype=np.int64),\n        \"chrB\": np.array([0, 500, 1500, 2500, 100000], dtype=np.int64),\n    }\n\n    # Define the test suite of paired-end mappings.\n    # Format: (chrom1, pos1, strand1, chrom2, pos2, strand2)\n    test_cases = [\n        # Case 1: Dangling end\n        (\"chrA\", 1010, '+', \"chrA\", 1020, '-'),\n        # Case 2: Re-ligation\n        (\"chrA\", 1995, '-', \"chrA\", 2005, '+'),\n        # Case 3: Self-circle\n        (\"chrA\", 1010, '-', \"chrA\", 1990, '+'),\n        # Case 4: Inter-chromosomal -> Valid\n        (\"chrA\", 1500, '+', \"chrB\", 700, '-'),\n        # Case 5: Distant intra-chromosomal -> Valid\n        (\"chrA\", 1500, '+', \"chrA\", 3500, '-'),\n        # Case 6: Re-ligation at threshold\n        (\"chrA\", 2975, '-', \"chrA\", 3025, '+'),\n        # Case 7: Same-strand orientation -> Valid\n        (\"chrA\", 1990, '+', \"chrA\", 2010, '+'),\n        # Case 8: Re-ligation with one read on cut site\n        (\"chrB\", 1500, '-', \"chrB\", 1503, '+'),\n    ]\n\n    results = []\n    for case in test_cases:\n        result = classify_pair(case, cut_sites, t_dang, t_reli, t_self)\n        results.append(result)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\n\ndef classify_pair(pair, cut_sites_map, t_dang, t_reli, t_self):\n    \"\"\"\n    Classifies a single paired-end read based on provided rules.\n    Classification codes: 1 (Valid), 2 (Dangling end), 3 (Re-ligation), 4 (Self-circle).\n    \"\"\"\n    chrom1, p1, s1, chrom2, p2, s2 = pair\n\n    # Rule: If inter-chromosomal, it's a valid contact.\n    if chrom1 != chrom2:\n        return 1\n\n    # Standardize reads: (p_left, s_left) and (p_right, s_right)\n    if p1 < p2:\n        p_left, s_left = p1, s1\n        p_right, s_right = p2, s2\n    else:\n        p_left, s_left = p2, s2\n        p_right, s_right = p1, s1\n\n    # Determine orientation\n    orientation = \"other\"\n    if (s_left, s_right) == ('+', '-'):\n        orientation = \"inward\"\n    elif (s_left, s_right) == ('-', '+'):\n        orientation = \"outward\"\n    \n    # Rule: If orientation is 'other', it's a valid contact.\n    if orientation == \"other\":\n        return 1\n\n    cuts = cut_sites_map[chrom1]\n\n    # Find fragments for each read using binary search.\n    # The definition is c_i < p <= c_{i+1}, which corresponds to `side='right'`.\n    # np.searchsorted finds insertion index `k` so that cuts[k-1] < p <= cuts[k].\n    idx_left = np.searchsorted(cuts, p_left, side='right')\n    idx_right = np.searchsorted(cuts, p_right, side='right')\n    \n    # Check for reads outside the defined chromosomal range with cut sites\n    if idx_left == 0 or idx_left == len(cuts) or idx_right == 0 or idx_right == len(cuts):\n        return 1 # Out of bounds, considered valid\n\n    frag_left_start, frag_left_end = cuts[idx_left - 1], cuts[idx_left]\n    frag_right_start, frag_right_end = cuts[idx_right - 1], cuts[idx_right]\n\n    # Check for same-fragment artifacts\n    if frag_left_start == frag_right_start:\n        fragment_start, fragment_end = frag_left_start, frag_left_end\n\n        # Rule: Dangling end\n        if orientation == \"inward\":\n            dist_left_to_start = p_left - fragment_start\n            dist_left_to_end = fragment_end - p_left\n            \n            nearest_boundary_left = fragment_start if dist_left_to_start < dist_left_to_end else fragment_end\n\n            dist_right_to_start = p_right - fragment_start\n            dist_right_to_end = fragment_end - p_right\n\n            nearest_boundary_right = fragment_start if dist_right_to_start < dist_right_to_end else fragment_end\n            \n            if nearest_boundary_left == nearest_boundary_right:\n                b_star = nearest_boundary_left\n                dist_left = abs(p_left - b_star)\n                dist_right = abs(p_right - b_star)\n                if dist_left <= t_dang and dist_right <= t_dang:\n                    return 2 # Dangling end\n\n        # Rule: Self-circle\n        elif orientation == \"outward\":\n            dist_left = p_left - fragment_start\n            dist_right = fragment_end - p_right\n            if dist_left <= t_self and dist_right <= t_self:\n                return 4 # Self-circle\n\n    # Rule: Re-ligation (adjacent fragments)\n    elif frag_left_end == frag_right_start and orientation == \"outward\":\n        shared_site = frag_left_end\n        dist_left = shared_site - p_left\n        dist_right = p_right - shared_site\n        if dist_left <= t_reli and dist_right <= t_reli:\n            return 3 # Re-ligation\n            \n    # Default case: valid contact\n    return 1\n\n# Execute the solution\nsolve()\n```", "id": "2939509"}, {"introduction": "Once a valid contact matrix is generated, the next step is to identify higher-order structural features. A key feature is the Topologically Associating Domain (TAD), a region of the genome with high internal interaction frequency, which is insulated from its neighbors. This exercise guides you through the implementation of the insulation score algorithm, a powerful method for locating the boundaries of these domains by quantifying the degree of interaction across potential boundary regions. [@problem_id:2939484]", "problem": "You are given the task of implementing a program that, for each of several synthetic chromosome contact matrices representing chromosome conformation capture data (Hi-C or Micro-C), computes insulation scores across multiple window sizes, identifies local boundary minima per window, and then calls boundaries that are stable across scales. The procedure must be derived from first principles of chromosome conformation capture and formalized into an unambiguous algorithm.\n\nFoundational base. Chromosome conformation capture yields a symmetric nonnegative contact count matrix $M \\in \\mathbb{R}_{\\ge 0}^{N \\times N}$ indexed by genomic bins, where $M_{ij}$ is the observed contact count between bin $i$ and bin $j$. Domain boundaries are local barriers that reduce cross-boundary interactions; therefore, a bin boundary with a low local cross-boundary interaction density is a candidate boundary.\n\nDefinitions and algorithm to implement.\n\n1. Contact matrix and boundary index domain.\n   - Let $N$ be the number of bins, with indices $i \\in \\{0,1,\\dots,N-1\\}$.\n   - Define the boundary position index as the integer $i \\in \\{0,1,\\dots,N-2\\}$ referring to the interface between bin $i$ and bin $i+1$.\n   - Let $W$ be a set of window sizes in bins, with each window size $w \\in \\mathbb{N}$ and $w \\ge 1$. For a given $w$, the set of valid boundary indices is those $i$ satisfying $i - w + 1 \\ge 0$ and $i + w \\le N-1$, equivalently $i \\in \\{w-1, w, \\dots, N-1-w\\}$.\n\n2. Cross-boundary interaction density and insulation score at scale $w$.\n   - For a valid boundary index $i$ and window $w$, define the cross-boundary region to be the index pairs $(a,b)$ with $a \\in \\{i-w+1, i-w+2, \\dots, i\\}$ and $b \\in \\{i+1, i+2, \\dots, i+w\\}$.\n   - Define the cross-boundary average contact (insulation precursor) as\n     $$ S_w(i) = \\frac{1}{w^2} \\sum_{a=i-w+1}^{i} \\sum_{b=i+1}^{i+w} M_{ab}. $$\n   - To stabilize variance and handle zeros, define a log-transformed insulation value\n     $$ L_w(i) = \\log_2\\big(S_w(i) + \\varepsilon\\big), $$\n     where $\\varepsilon = 10^{-6}$ is a fixed small constant.\n\n3. Optional smoothing across boundary indices.\n   - Given a nonnegative integer smoothing radius $s \\in \\mathbb{Z}_{\\ge 0}$, define the smoothed insulation series $\\tilde{L}_w(i)$ by centered moving-average smoothing over the valid index set for $w$:\n     $$ \\tilde{L}_w(i) = \\frac{1}{K_i} \\sum_{j = \\max(i-s, w-1)}^{\\min(i+s, N-1-w)} L_w(j), $$\n     where $K_i$ is the number of terms in the sum. If $s = 0$, then $\\tilde{L}_w(i) = L_w(i)$.\n\n4. Local minima detection at scale $w$.\n   - Given a neighborhood radius $r \\in \\mathbb{Z}_{\\ge 1}$, call $i$ a local minimum of $\\tilde{L}_w$ if\n     $$ \\tilde{L}_w(i) < \\tilde{L}_w(j) \\quad \\text{for all } j \\in \\{ \\max(w-1, i-r), \\dots, \\min(N-1-w, i+r) \\} \\setminus \\{i\\}. $$\n     Ties (i.e., equality with any neighbor in the comparison set) do not qualify as minima.\n\n5. Scale-stable boundaries across window sizes.\n   - Let $\\mathcal{M}_w$ be the set of local minima indices for window $w$.\n   - Given a stability tolerance $\\tau \\in \\mathbb{Z}_{\\ge 0}$, a boundary is called scale-stable if there exists an index $m$ and, for each window $w \\in W$, an index $i_w \\in \\mathcal{M}_w$ such that $|i_w - m| \\le \\tau$. The canonical reported coordinate for such a stable boundary is defined to be the integer median of the matched indices $\\{i_w : w \\in W\\}$ rounded to the nearest integer (with halves rounded away from zero). If multiple candidates produce the same canonical coordinate, report it only once.\n\nYour program must implement the above procedure to compute the set of scale-stable boundaries for each test case described below. No physical units or angle units are involved. All outputs must be integers.\n\nTest suite. Implement the following three test cases.\n\n- Test case A (two-domain matrix, clear single boundary):\n  - Matrix size $N = 8$.\n  - Define two domains: bins $\\{0,1,2,3\\}$ and bins $\\{4,5,6,7\\}$. For $i \\neq j$, set\n    $$ M_{ij} = \\begin{cases}\n    h, & \\text{if } \\left\\lfloor \\frac{i}{4} \\right\\rfloor = \\left\\lfloor \\frac{j}{4} \\right\\rfloor, \\\\\n    \\ell, & \\text{otherwise},\n    \\end{cases} $$\n    with $h = 50$ and $\\ell = 2$. Set $M_{ii} = h$ for all $i$, and enforce symmetry.\n  - Window sizes $W = \\{1, 2\\}$.\n  - Smoothing radius $s = 0$.\n  - Local-minimum neighborhood radius $r = 1$.\n  - Stability tolerance $\\tau = 1$.\n\n- Test case B (three-domain matrix, two boundaries stable across multiple scales):\n  - Matrix size $N = 12$.\n  - Define three domains: bins $\\{0,1,2,3\\}$, bins $\\{4,5,6,7\\}$, and bins $\\{8,9,10,11\\}$. For $i \\neq j$, set\n    $$ M_{ij} = \\begin{cases}\n    h, & \\text{if } \\left\\lfloor \\frac{i}{4} \\right\\rfloor = \\left\\lfloor \\frac{j}{4} \\right\\rfloor, \\\\\n    \\ell, & \\text{otherwise},\n    \\end{cases} $$\n    with $h = 60$ and $\\ell = 2$. Set $M_{ii} = h$ for all $i$, and enforce symmetry.\n  - Window sizes $W = \\{1, 2, 3\\}$.\n  - Smoothing radius $s = 1$.\n  - Local-minimum neighborhood radius $r = 1$.\n  - Stability tolerance $\\tau = 1$.\n\n- Test case C (uniform matrix, no boundaries):\n  - Matrix size $N = 6$.\n  - Define $M_{ij} = 1$ for all $i,j \\in \\{0,1,\\dots,5\\}$.\n  - Window sizes $W = \\{1, 2\\}$.\n  - Smoothing radius $s = 0$.\n  - Local-minimum neighborhood radius $r = 1$.\n  - Stability tolerance $\\tau = 1$.\n\nFinal output format. Your program should produce a single line of output containing the results for the test cases in the order A, B, C, as a comma-separated list of lists of integers enclosed in square brackets. For example, if the outputs are lists $\\mathcal{B}_A$, $\\mathcal{B}_B$, and $\\mathcal{B}_C$ of stable boundary indices (each list sorted in ascending order), the program must print\n\"[[$\\mathcal{B}_A$],[ $\\mathcal{B}_B$],[ $\\mathcal{B}_C$]]\" with no spaces, where each inner list is represented as comma-separated integers, e.g., \"[[3],[3,7],[]]\".", "solution": "The problem presents a well-defined, scientifically grounded procedure for identifying chromosome domain boundaries from contact matrices, a common task in genomics. The methodology is based on the concept of an insulation score, which quantifies the degree of interaction across a potential boundary. The problem is valid as it provides a complete, consistent, and formalizable algorithmic specification. We shall proceed with a systematic derivation and solution.\n\nThe overall algorithm consists of five main stages:\n1.  Construction of the contact matrix $M$.\n2.  Calculation of insulation scores $L_w(i)$ for each window size $w \\in W$.\n3.  Smoothing of the insulation score series to obtain $\\tilde{L}_w(i)$.\n4.  Detection of local minima $\\mathcal{M}_w$ in each smoothed series.\n5.  Identification of scale-stable boundaries by finding consistent minima across all window sizes.\n\nLet us formalize and implement each stage.\n\n**1. Matrix Construction**\nFor each test case, a symmetric contact matrix $M \\in \\mathbb{R}_{\\ge 0}^{N \\times N}$ is constructed according to the provided rules. For a given number of bins $N$ and domain definitions, the matrix element $M_{ij}$ is assigned a high value $h$ for intra-domain contacts and a low value $\\ell$ for inter-domain contacts. The diagonal elements $M_{ii}$ are also set to $h$.\n\n**2. Insulation Score Calculation**\nThe insulation score is designed to measure the relative lack of interaction across a given boundary. For a boundary at index $i$ (separating bin $i$ and bin $i+1$) and a given window size $w$, we consider a square region of the contact map, specifically the $w \\times w$ submatrix of interactions between the $w$ bins upstream of the boundary and the $w$ bins downstream.\n\nThe cross-boundary average contact, $S_w(i)$, is the mean of contact frequencies in this square region:\n$$ S_w(i) = \\frac{1}{w^2} \\sum_{a=i-w+1}^{i} \\sum_{b=i+1}^{i+w} M_{ab} $$\nThis calculation is performed for all valid boundary indices $i$, which are those for which the $w \\times w$ square fits within the matrix, i.e., $i \\in \\{w-1, w, \\dots, N-1-w\\}$.\n\nTo mitigate the effect of extreme values and stabilize variance, a logarithmic transformation is applied. A small constant $\\varepsilon = 10^{-6}$ is added to prevent taking the logarithm of zero. The log-transformed insulation value $L_w(i)$ is defined as:\n$$ L_w(i) = \\log_2\\big(S_w(i) + \\varepsilon\\big) $$\nA lower value of $L_w(i)$ indicates stronger insulation, meaning fewer contacts cross the boundary $i$, making it a candidate for a domain boundary.\n\n**3. Smoothing of Insulation Scores**\nTo reduce noise in the insulation signal, a centered moving-average filter can be applied. Given a smoothing radius $s \\ge 0$, the smoothed insulation value $\\tilde{L}_w(i)$ at a valid boundary index $i$ is the average of $L_w(j)$ over a neighborhood of indices $j$ around $i$.\n$$ \\tilde{L}_w(i) = \\frac{1}{K_i} \\sum_{j = \\max(i-s, w-1)}^{\\min(i+s, N-1-w)} L_w(j) $$\nHere, $K_i$ is the number of terms in the summation, which accounts for boundary effects where the smoothing window is truncated at the ends of the valid index range $\\{w-1, \\dots, N-1-w\\}$. If $s=0$, no smoothing is performed, and $\\tilde{L}_w(i) = L_w(i)$.\n\n**4. Local Minima Detection**\nDomain boundaries correspond to local minima in the insulation score profile. An index $i$ is identified as a local minimum for a given scale $w$ if its smoothed insulation score $\\tilde{L}_w(i)$ is strictly less than that of all its neighbors within a radius $r \\ge 1$.\nFormally, $i$ is a local minimum if:\n$$ \\tilde{L}_w(i) < \\tilde{L}_w(j) \\quad \\text{for all } j \\in \\{ \\max(w-1, i-r), \\dots, \\min(N-1-w, i+r) \\} \\setminus \\{i\\} $$\nThe strict inequality ensures that plateaus are not considered minima. For each window size $w \\in W$, this step yields a set of local minimum indices, $\\mathcal{M}_w$.\n\n**5. Scale-Stable Boundary Calling**\nTrue domain boundaries are expected to be robust features, identifiable across a range of analysis scales (window sizes). This final step filters for boundaries that are consistently detected as local minima across all specified window sizes in $W$.\n\nA boundary is deemed scale-stable if a consistent set of local minima, one from each $\\mathcal{M}_w$, can be found that are spatially clustered. A group of minima $\\{i_w \\mid i_w \\in \\mathcal{M}_w, w \\in W\\}$ is considered stable if there exists an integer position $m$ such that for every minimum $i_w$ in the group, the distance $|i_w - m|$ is no more than a given tolerance $\\tau$. This condition is equivalent to requiring that the entire group of minima can be contained within an interval of size $2\\tau$, i.e., $\\max(\\{i_w\\}) - \\min(\\{i_w\\}) \\le 2\\tau$.\n\nThe algorithm proceeds as follows:\n1.  Generate all possible combinations of minima by taking the Cartesian product of the sets of minima: $\\mathcal{C} = \\mathcal{M}_{w_1} \\times \\mathcal{M}_{w_2} \\times \\dots$ for all $w_k \\in W$.\n2.  For each tuple of minima $T = (i_{w_1}, i_{w_2}, \\dots) \\in \\mathcal{C}$, check if it forms a stable group by testing if $\\max(T) - \\min(T) \\le 2\\tau$.\n3.  For each stable group found, calculate its canonical coordinate. This is defined as the integer median of the indices in the group, with halves rounded away from zero. For non-negative values, this corresponds to $\\text{int}(\\text{median} + 0.5)$.\n4.  The final result is the sorted list of unique canonical coordinates obtained from all stable groups.\n\nThis comprehensive procedure allows for the robust identification of boundaries from raw contact data, progressing from local interaction patterns to globally consistent structural features. We will now implement this procedure.", "answer": "```python\nimport numpy as np\nimport itertools\nfrom math import log2\n\ndef solve():\n    \"\"\"\n    Main function to run all test cases and print the results.\n    \"\"\"\n    \n    epsilon = 1e-6\n\n    def round_half_away_from_zero(x):\n        \"\"\"Rounds a number to the nearest integer, with halves rounded away from zero.\"\"\"\n        if x >= 0:\n            return int(x + 0.5)\n        else:\n            return int(x - 0.5)\n\n    def get_median_coordinate(indices):\n        \"\"\"Calculates the integer median of a list of indices, with special rounding.\"\"\"\n        sorted_indices = sorted(indices)\n        n = len(sorted_indices)\n        if n % 2 == 1:\n            median = float(sorted_indices[n // 2])\n        else:\n            mid1 = sorted_indices[n // 2 - 1]\n            mid2 = sorted_indices[n // 2]\n            median = (mid1 + mid2) / 2.0\n        return round_half_away_from_zero(median)\n\n    def compute_stable_boundaries(N, M, W, s, r, tau):\n        \"\"\"Orchestrates the entire boundary calling pipeline for a single test case.\"\"\"\n        \n        # Store results for each window size\n        minima_sets = {}\n\n        for w in W:\n            # Step 1: Calculate insulation scores\n            valid_indices_w = range(w - 1, N - w)\n            if not valid_indices_w:\n                minima_sets[w] = []\n                continue\n\n            L_w = {}\n            for i in valid_indices_w:\n                # Extract the w x w submatrix for cross-boundary interactions\n                sub_matrix = M[i - w + 1 : i + 1, i + 1 : i + w + 1]\n                S_wi = np.mean(sub_matrix)\n                L_w[i] = log2(S_wi + epsilon)\n\n            # Step 2: Smooth insulation scores\n            tilde_L_w = {}\n            if s == 0:\n                tilde_L_w = L_w\n            else:\n                for i in valid_indices_w:\n                    j_start = max(i - s, w - 1)\n                    j_end = min(i + s, N - 1 - w)\n                    \n                    sum_val = 0\n                    count = 0\n                    for j in range(j_start, j_end + 1):\n                        if j in L_w:\n                            sum_val += L_w[j]\n                            count += 1\n                    \n                    if count > 0:\n                        tilde_L_w[i] = sum_val / count\n            \n            # Step 3: Find local minima\n            local_minima = []\n            for i in valid_indices_w:\n                is_min = True\n                \n                # Define neighborhood for local minimum check\n                j_start_min = max(w - 1, i - r)\n                j_end_min = min(N - 1 - w, i + r)\n                \n                if i not in tilde_L_w: continue\n\n                val_i = tilde_L_w[i]\n                \n                found_neighbor = False\n                for j in range(j_start_min, j_end_min + 1):\n                    if i == j:\n                        continue\n                    if j in tilde_L_w:\n                        found_neighbor = True\n                        if val_i >= tilde_L_w[j]:\n                            is_min = False\n                            break\n                \n                if is_min and found_neighbor:\n                    local_minima.append(i)\n                elif is_min and not found_neighbor: # An isolated point is not a local minimum\n                    is_min = False\n\n            minima_sets[w] = local_minima\n        \n        # Step 4: Find scale-stable boundaries\n        if not W or any(not minima_sets[w] for w in W):\n            return []\n\n        minima_lists = [minima_sets[w] for w in W]\n        \n        stable_groups = []\n        # Generate Cartesian product of minima sets\n        for combo in itertools.product(*minima_lists):\n            if max(combo) - min(combo) <= 2 * tau:\n                stable_groups.append(combo)\n        \n        # Calculate canonical coordinates and find unique ones\n        boundary_coords = set()\n        for group in stable_groups:\n            coord = get_median_coordinate(group)\n            boundary_coords.add(coord)\n            \n        return sorted(list(boundary_coords))\n\n    # --- Test Cases ---\n\n    def run_case_A():\n        N = 8\n        h = 50\n        ell = 2\n        M = np.zeros((N, N))\n        for i in range(N):\n            for j in range(N):\n                if i == j:\n                    M[i, j] = h\n                else:\n                    if (i // 4) == (j // 4):\n                        M[i, j] = h\n                    else:\n                        M[i, j] = ell\n        return compute_stable_boundaries(N=N, M=M, W={1, 2}, s=0, r=1, tau=1)\n\n    def run_case_B():\n        N = 12\n        h = 60\n        ell = 2\n        M = np.zeros((N, N))\n        for i in range(N):\n            for j in range(N):\n                if i == j:\n                    M[i, j] = h\n                else:\n                    if (i // 4) == (j // 4):\n                        M[i, j] = h\n                    else:\n                        M[i, j] = ell\n        return compute_stable_boundaries(N=N, M=M, W={1, 2, 3}, s=1, r=1, tau=1)\n\n    def run_case_C():\n        N = 6\n        M = np.ones((N, N))\n        return compute_stable_boundaries(N=N, M=M, W={1, 2}, s=0, r=1, tau=1)\n\n    results_A = run_case_A()\n    results_B = run_case_B()\n    results_C = run_case_C()\n    \n    # Format final output\n    final_output = []\n    for res in [results_A, results_B, results_C]:\n        final_output.append(f\"[{','.join(map(str, res))}]\")\n    \n    print(f\"[{','.join(final_output)}]\")\n\nsolve()\n```", "id": "2939484"}, {"introduction": "The ultimate goal of Hi-C analysis is to connect 3D genome architecture to biological function and mechanism. One of the most influential models, the loop extrusion hypothesis, makes a specific prediction: chromatin loops are often anchored by CTCF proteins whose binding motifs are oriented towards each other in a \"convergent\" rule. This final practice provides a framework for using statistical testing to validate this biological model, asking you to quantify the enrichment of convergent motifs and assess its significance against a null model. [@problem_id:2939318]", "problem": "You are given a statistical testing task motivated by Chromosome Conformation Capture (3C) family assays, including genome-wide variants Hi-C and Micro-C, which detect chromatin loops anchored by CCCTC-binding factor (CTCF) sites. The loop extrusion model predicts a \"convergent motif\" rule in which chromatin loops are preferentially anchored by CTCF motifs oriented towards each other. You will formalize and test this rule using a principled null model that preserves marginal motif orientation frequencies at the left and right loop anchors.\n\nStart from the following fundamental base: (i) the assignment of a CTCF motif orientation at each loop anchor is a categorical variable taking two values denoted \"plus\" and \"minus\"; (ii) under a null model of independence between left and right anchors with fixed marginal orientation frequencies, the number of convergent loops (defined as left-anchor \"plus\" and right-anchor \"minus\") is a random variable that follows a hypergeometric distribution when pairings are formed without replacement while preserving the marginal totals, and follows a binomial distribution when pairings are considered as independent Bernoulli trials with replacement; and (iii) the expected probability of a convergent loop under independence equals the product of the marginal probabilities at left and right anchors.\n\nFor each test case, you are provided:\n- The total number of loops with confidently assigned CTCF motif orientations at both anchors, denoted by $N$.\n- The number of left anchors with \"plus\" orientation, denoted by $L_{+}$, and with \"minus\" orientation, denoted by $L_{-}$, satisfying $L_{+} + L_{-} = N$.\n- The number of right anchors with \"plus\" orientation, denoted by $R_{+}$, and with \"minus\" orientation, denoted by $R_{-}$, satisfying $R_{+} + R_{-} = N$.\n- The observed number of convergent loops (left \"plus\" and right \"minus\"), denoted by $x$, which must satisfy $0 \\le x \\le \\min(L_{+}, R_{-})$.\n\nYour program must, for each test case, compute:\n1. The expected convergent probability under the independence null, $$p_{\\mathrm{exp}} = \\left(\\frac{L_{+}}{N}\\right)\\left(\\frac{R_{-}}{N}\\right).$$\n2. The expected convergent count, $$\\mu = N \\, p_{\\mathrm{exp}}.$$\n3. The enrichment fold, $$E = \\frac{x / N}{p_{\\mathrm{exp}}},$$ defined only when $0 < p_{\\mathrm{exp}} < 1$.\n4. The exact upper-tail hypergeometric $p$-value under fixed margins, with $X \\sim \\mathrm{Hypergeometric}(N, R_{-}, L_{+})$, reported as $\\Pr(X \\ge x)$.\n5. The exact upper-tail binomial $p$-value under independent trials with replacement, with $Y \\sim \\mathrm{Binomial}(N, p_{\\mathrm{exp}})$, reported as $\\Pr(Y \\ge x)$.\n6. The normal-approximation $z$-score, $$z = \\frac{x - \\mu}{\\sqrt{N \\, p_{\\mathrm{exp}} \\, (1 - p_{\\mathrm{exp}})}},$$ defined only when $0 < p_{\\mathrm{exp}} < 1$.\n\nAll reported real-valued outputs must be rounded to $6$ decimal places.\n\nTest suite:\n- Case $1$ (general \"happy path\"): $N = 1000$, $L_{+} = 600$, $L_{-} = 400$, $R_{+} = 300$, $R_{-} = 700$, $x = 520$.\n- Case $2$ (near-null boundary): $N = 500$, $L_{+} = 250$, $L_{-} = 250$, $R_{+} = 250$, $R_{-} = 250$, $x = 125$.\n- Case $3$ (low expected probability, strong enrichment): $N = 800$, $L_{+} = 200$, $L_{-} = 600$, $R_{+} = 700$, $R_{-} = 100$, $x = 60$.\n- Case $4$ (small-sample edge): $N = 20$, $L_{+} = 10$, $L_{-} = 10$, $R_{+} = 10$, $R_{-} = 10$, $x = 10$.\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, where each test case contributes a list of five real numbers in the order $[E, p_{\\mathrm{hyper}}, p_{\\mathrm{binom}}, \\mu, z]$. The overall output must therefore be a list of lists, for example $[[\\cdots],[\\cdots],[\\cdots],[\\cdots]]$, with every real number rounded to $6$ decimal places and no additional text. No physical units are involved, and no angular quantities are used. All results must be purely numeric as specified.", "solution": "The problem presented is a standard task in bioinformatics, specifically the statistical analysis of chromosome looping data from assays like Hi-C and Micro-C. It is scientifically sound, mathematically well-posed, and all provided data are consistent. We will proceed with the solution.\n\nThe problem requires testing whether the observed number of \"convergent\" CTCF-anchored loops is significantly greater than expected under a null model of independence. A convergent loop is defined as having a \"plus\" oriented motif at the left anchor and a \"minus\" oriented motif at the right anchor. The data can be organized into a $2 \\times 2$ contingency table, where the rows represent the orientation of the left anchor (plus, minus) and the columns represent the orientation of the right anchor (plus, minus).\n\nThe provided givens for each test case are:\n- The total number of loops, $N$.\n- The marginal count of left anchors with \"plus\" orientation, $L_{+}$.\n- The marginal count of right anchors with \"minus\" orientation, $R_{-}$.\n- The observed count of convergent loops (Left \"plus\", Right \"minus\"), $x$.\n\nFrom these, we can deduce the full table:\n- Left \"plus\" & Right \"minus\": $x$\n- Left \"plus\" & Right \"plus\": $L_{+} - x$\n- Left \"minus\" & Right \"minus\": $R_{-} - x$\n- Left \"minus\" & Right \"plus\": $(N - L_{+}) - (R_{-} - x) = N - L_{+} - R_{-} + x$\n\nThe total number of trials is $N$. We must compute five metrics: the enrichment fold $E$, the hypergeometric $p$-value $p_{\\mathrm{hyper}}$, the binomial $p$-value $p_{\\mathrm{binom}}$, the expected count $\\mu$, and the normal-approximation $z$-score. All numerical results must be rounded to $6$ decimal places.\n\nThe calculations are as follows:\n\nFirst, we determine the expected probability of a convergent loop under the null hypothesis of independence between left and right anchor orientations. The probability of a left anchor being \"plus\" is $\\frac{L_{+}}{N}$, and the probability of a right anchor being \"minus\" is $\\frac{R_{-}}{N}$.\nThe expected probability, $p_{\\mathrm{exp}}$, is their product:\n$$p_{\\mathrm{exp}} = \\left(\\frac{L_{+}}{N}\\right) \\left(\\frac{R_{-}}{N}\\right) = \\frac{L_{+} R_{-}}{N^2}$$\n\nThe expected number of convergent loops, $\\mu$, in a sample of size $N$ is then:\n$$\\mu = N \\cdot p_{\\mathrm{exp}} = N \\cdot \\frac{L_{+} R_{-}}{N^2} = \\frac{L_{+} R_{-}}{N}$$\n\nThe enrichment fold, $E$, compares the observed proportion of convergent loops, $\\frac{x}{N}$, to the expected proportion, $p_{\\mathrm{exp}}$. It quantifies the degree of over-representation.\n$$E = \\frac{x/N}{p_{\\mathrm{exp}}} = \\frac{xN}{L_{+}R_{-}}$$\nThis is defined for $0 < p_{\\mathrm{exp}} < 1$.\n\nThe upper-tail hypergeometric $p$-value, $p_{\\mathrm{hyper}}$, is derived from a model of sampling without replacement, where the row and column marginals of the contingency table are considered fixed. This is equivalent to Fisher's exact test. The number of convergent loops, $X$, is a random variable following the hypergeometric distribution. We consider drawing a sample of size $K=L_{+}$ (the number of left \"plus\" anchors) from a population of size $M=N$ (all right anchors), which contains $n=R_{-}$ items of interest (the right \"minus\" anchors). The probability of observing $k$ successes is given by the probability mass function:\n$$P(X=k) = \\frac{\\binom{R_{-}}{k} \\binom{N - R_{-}}{L_{+} - k}}{\\binom{N}{L_{+}}}$$\nThe $p$-value is the probability of observing a result at least as extreme as $x$, which is the sum of probabilities for all outcomes greater than or equal to $x$:\n$$p_{\\mathrm{hyper}} = \\Pr(X \\ge x) = \\sum_{k=x}^{\\min(L_{+}, R_{-})} P(X=k)$$\n\nThe upper-tail binomial $p$-value, $p_{\\mathrm{binom}}$, is based on a model of $N$ independent Bernoulli trials, where each trial represents a loop pairing and has a success probability of $p_{\\mathrm{exp}}$. The number of convergent loops, $Y$, follows a binomial distribution, $Y \\sim \\mathrm{Binomial}(N, p_{\\mathrm{exp}})$. The probability of observing $k$ successes is:\n$$P(Y=k) = \\binom{N}{k} p_{\\mathrm{exp}}^k (1-p_{\\mathrm{exp}})^{N-k}$$\nThe $p$-value is the probability of observing at least $x$ successes:\n$$p_{\\mathrm{binom}} = \\Pr(Y \\ge x) = \\sum_{k=x}^{N} P(Y=k)$$\n\nFinally, the normal-approximation $z$-score is derived by approximating the binomial distribution with a normal distribution. The mean of this distribution is $\\mu = N p_{\\mathrm{exp}}$ and the variance is $\\sigma^2 = N p_{\\mathrm{exp}} (1 - p_{\\mathrm{exp}})$. The $z$-score measures how many standard deviations the observation $x$ is from the expected value $\\mu$.\n$$z = \\frac{x - \\mu}{\\sigma} = \\frac{x - \\mu}{\\sqrt{N p_{\\mathrm{exp}} (1 - p_{\\mathrm{exp}})}}$$\nThis is also defined for $0 < p_{\\mathrm{exp}} < 1$.\n\nThe implementation will apply these formulas to each test case. For computation of the hypergeometric and binomial cumulative probabilities, we will use the survival function (sf) from the `scipy.stats` library, which calculates $\\Pr(X>k)$, to compute $\\Pr(X \\ge x)$ as `sf(x-1)`. This approach maintains precision for very small $p$-values.", "answer": "```python\nimport numpy as np\nfrom scipy import stats\n\ndef solve():\n    \"\"\"\n    Solves the statistical testing problem for CTCF motif orientation in chromatin loops.\n    \"\"\"\n    # Test cases are defined as tuples: (N, L_plus, R_minus, x)\n    test_cases = [\n        (1000, 600, 700, 520),\n        (500, 250, 250, 125),\n        (800, 200, 100, 60),\n        (20, 10, 10, 10),\n    ]\n\n    all_results = []\n    for N, L_plus, R_minus, x in test_cases:\n        # 1. Expected convergent probability under the independence null\n        p_exp = (L_plus / N) * (R_minus / N)\n\n        # 2. Expected convergent count\n        mu = N * p_exp\n\n        # 3. Enrichment fold, E\n        # This is defined for 0 < p_exp < 1, which is true for all test cases.\n        E = (x / N) / p_exp\n\n        # 4. Upper-tail hypergeometric p-value\n        # Parameters for scipy.stats.hypergeom(M, n, K)\n        # M = Total number of objects (N)\n        # n = Total number of objects of type I (R_minus)\n        # K = Number of objects drawn (L_plus)\n        p_hyper = stats.hypergeom.sf(x - 1, N, R_minus, L_plus)\n\n        # 5. Upper-tail binomial p-value\n        # Parameters for scipy.stats.binom(n, p)\n        # n = Number of trials (N)\n        # p = Probability of success (p_exp)\n        p_binom = stats.binom.sf(x - 1, N, p_exp)\n\n        # 6. Normal-approximation z-score\n        # This is defined for 0 < p_exp < 1, which is true for all test cases.\n        std_dev = np.sqrt(N * p_exp * (1 - p_exp))\n        z = (x - mu) / std_dev\n        \n        # Assemble results for the current case in the specified order:\n        # [E, p_hyper, p_binom, mu, z]\n        case_results = [\n            E,\n            p_hyper,\n            p_binom,\n            mu,\n            z,\n        ]\n        all_results.append(case_results)\n\n    # Format the final output string as a list of lists of real numbers\n    # with 6 decimal places.\n    list_of_strings = []\n    for res_list in all_results:\n        # Format each number to have exactly 6 decimal places.\n        str_res = [f\"{val:.6f}\" for val in res_list]\n        list_of_strings.append(f\"[{','.join(str_res)}]\")\n    \n    final_output_string = f\"[{','.join(list_of_strings)}]\"\n    print(final_output_string)\n\nsolve()\n```", "id": "2939318"}]}