{"hands_on_practices": [{"introduction": "In bulk RNA sequencing, raw read counts are not directly comparable across genes or samples due to technical biases, most notably sequencing depth and gene length. This exercise [@problem_id:2967173] guides you through the process of deriving and implementing Transcripts Per Million (TPM), a standard normalization method that corrects for these biases. By transforming raw counts into TPM, you will gain hands-on experience with a fundamental step in transcriptomic data processing and appreciate how proper normalization can drastically alter the apparent ranking of gene expression levels.", "problem": "You are given a set of gene-level read count observations and corresponding effective lengths, arising from a standard bulk RNA sequencing protocol under uniform random fragmentation and sampling. Let there be $G$ genes indexed by $i \\in \\{0,1,\\dots,G-1\\}$. For each gene $i$, you are provided two quantities: an observed read count $c_{i} \\in \\mathbb{N}_{0}$ and a positive effective length $\\ell_{i} \\in \\mathbb{R}_{>0}$ measured in nucleotides. Assume the widely used model in transcriptomics that, for a fixed sequencing depth, the expected number of reads originating from a gene is proportional to both its underlying transcript abundance and its effective length. Under this model, removing length-dependent sampling bias requires an explicit length correction, followed by conversion to a relative abundance scale that sums to a fixed constant. Transcripts Per Million (TPM) is defined as a length-corrected relative abundance scale that sums to $10^{6}$ across genes. If the length correction yields a zero total across all genes, define the TPM vector to be the all-zero vector to avoid division by zero.\n\nYour tasks are:\n1) For each test case, derive an algorithm from first principles to compute a TPM vector $t \\in \\mathbb{R}_{\\ge 0}^{G}$ from $(c_{i}, \\ell_{i})_{i=0}^{G-1}$ under the modeling assumptions above, such that $\\sum_{i=0}^{G-1} t_{i} = 10^{6}$ whenever the total length-corrected signal is nonzero, and $t_{i} = 0$ for all $i$ otherwise. Do not assume any intermediate formulas other than the modeling statements given; reason from the proportional relationships implied by the sampling model and the definition that TPM is the length-corrected relative abundance scaled to sum to $10^{6}$.\n2) For each test case, compute two rank orderings of the genes as lists of zero-based indices:\n   a) The ordering by raw counts, from largest to smallest $c_{i}$.\n   b) The ordering by TPM, from largest to smallest $t_{i}$.\n   In both orderings, if values are equal for a tie, break ties by smaller index first.\n\nYour program must implement this algorithm and apply it to the following test suite. Each test case is fully specified by two lists of equal length: counts and effective lengths. All effective lengths are positive. The units of $\\ell_{i}$ are nucleotides, and the TPM scale is unitless.\n\nTest suite (each bullet gives counts then effective lengths for that case):\n- Case A:\n  - counts: [$500$, $1000$, $500$]\n  - effective lengths: [$1000$, $2000$, $500$]\n- Case B:\n  - counts: [$0$, $0$, $0$]\n  - effective lengths: [$1000$, $1000$, $1000$]\n- Case C:\n  - counts: [$100$, $101$, $102$, $103$]\n  - effective lengths: [$100$, $10000$, $100$, $100000$]\n- Case D:\n  - counts: [$10$, $10$, $5$, $5$]\n  - effective lengths: [$1000$, $1000$, $500$, $1000$]\n\nFinal output format:\n- Your program should produce a single line of output containing one top-level list with one entry per test case, in the order A, B, C, D.\n- For each test case, output a list with three elements:\n  1) the TPM vector $[t_{0}, t_{1}, \\dots, t_{G-1}]$ as floats in gene index order;\n  2) the rank ordering by raw counts as a list of zero-based indices in descending order with tie-breaking by smaller index;\n  3) the rank ordering by TPM as a list of zero-based indices in descending order with tie-breaking by smaller index.\n- The entire output must be formatted on a single line as a comma-separated list enclosed in square brackets, with no additional text. For example, the top-level structure must look like $[\\dots]$ where each per-case element is itself a list $[\\dots]$. No physical units should be printed. Express any fractions or proportions as decimal floats in the TPM vector. Angles are not applicable.\n\nYour program must be self-contained, take no input, and print exactly the specified single-line result for the given test suite.", "solution": "The problem as stated is valid. It is scientifically grounded in the standard principles of transcriptomic data analysis, is well-posed with sufficient information for a unique solution, and is formulated in objective, precise language. We shall proceed with a derivation from first principles.\n\nThe fundamental modeling assumption is that the expected read count for a gene, $E[c_i]$, is proportional to the product of its true transcript abundance, $A_i$, and its effective length, $\\ell_i$. This can be stated mathematically for a library of $G$ genes as:\n$$ E[c_i] = K \\cdot A_i \\cdot \\ell_i $$\nwhere $i \\in \\{0, 1, \\dots, G-1\\}$ is the gene index, $c_i \\in \\mathbb{N}_0$ is the observed read count, $\\ell_i \\in \\mathbb{R}_{>0}$ is the effective length, and $K$ is a library-wide normalization constant reflecting sequencing depth.\n\nOur objective is to estimate the relative abundance of each gene's transcripts. The observed count $c_i$ serves as our empirical estimate for the expectation $E[c_i]$. By rearranging the proportionality, we deduce that the true abundance $A_i$ is proportional to the read count divided by the effective length:\n$$ A_i \\propto \\frac{c_i}{\\ell_i} $$\nThis ratio, which we shall denote $s_i = c_i / \\ell_i$, represents a length-normalized measure of expression. It corrects for the sampling bias inherent in RNA sequencing, where longer transcripts are more likely to be fragmented and sequenced, thus producing more reads even at the same level of true cellular abundance. The quantity $s_i$ is therefore our best estimate of the abundance $A_i$, up to a common scaling factor across all genes.\n\nThe set of values $\\{s_0, s_1, \\dots, s_{G-1}\\}$ represents the relative expression levels of all genes. To convert these into true fractional abundances, we must normalize them by their sum. The total length-corrected signal in the library is the sum over all genes:\n$$ S_{total} = \\sum_{j=0}^{G-1} s_j = \\sum_{j=0}^{G-1} \\frac{c_j}{\\ell_j} $$\nThe fractional abundance of gene $i$, denoted $r_i$, is then the fraction of its length-corrected signal relative to the total:\n$$ r_i = \\frac{s_i}{S_{total}} = \\frac{c_i / \\ell_i}{\\sum_{j=0}^{G-1} (c_j / \\ell_j)} $$\nBy construction, these fractional abundances sum to unity: $\\sum_{i=0}^{G-1} r_i = 1$.\n\nThe problem defines Transcripts Per Million (TPM) as this fractional abundance scaled to a total of $10^6$. Therefore, the TPM value for gene $i$, denoted $t_i$, is obtained by multiplying its fractional abundance $r_i$ by $10^6$:\n$$ t_i = r_i \\cdot 10^6 = \\left( \\frac{c_i / \\ell_i}{\\sum_{j=0}^{G-1} (c_j / \\ell_j)} \\right) \\cdot 10^6 $$\nThis is the general formula for computing TPM from read counts and effective lengths.\n\nWe must also consider the specified edge case. If the total length-corrected signal $S_{total}$ is zero, the formula for $t_i$ involves division by zero and is therefore undefined. Since all counts $c_i \\ge 0$ and all lengths $\\ell_i > 0$, the sum $S_{total}$ can only be $0$ if all individual terms $c_i / \\ell_i$ are $0$, which implies that all counts $c_i$ must be $0$. In this scenario, the problem statement requires that the TPM for all genes must be $0$. Our algorithm must explicitly implement this condition.\n\nFor the second task, we must determine the rank ordering of genes based on two different metrics: raw counts, $c_i$, and the derived TPM values, $t_i$. The ordering must be from largest to smallest value. For any ties in these values, the problem specifies that the tie must be broken by giving precedence to the gene with the smaller index. This defines a lexicographical sort. For a set of values $v_i$ with indices $i$, the sorted order of indices is determined by sorting the pairs $(v_i, i)$ with the primary key $v_i$ in descending order and the secondary key $i$ in ascending order. This can be achieved algorithmically by sorting on the tuple $(-v_i, i)$.\n\nThe final algorithm is as follows:\n1.  For each gene $i$, calculate the length-normalized signal $s_i = c_i / \\ell_i$.\n2.  Calculate the total signal $S_{total} = \\sum_{i=0}^{G-1} s_i$.\n3.  If $S_{total} = 0$, set the TPM vector $t$ to be a vector of zeros. Otherwise, calculate $t_i = (s_i / S_{total}) \\cdot 10^6$ for all $i$.\n4.  Generate the list of gene indices $\\{0, 1, \\dots, G-1\\}$.\n5.  To obtain the raw count ranking, sort this list of indices based on the key $(-c_i, i)$.\n6.  To obtain the TPM ranking, sort this list of indices based on the key $(-t_i, i)$.\n\nThis completes the derivation from first principles as required.", "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to solve the transcriptomics problem for the given test suite.\n    \"\"\"\n\n    test_cases = [\n        {\n            \"counts\": [500, 1000, 500],\n            \"effective_lengths\": [1000, 2000, 500]\n        },\n        {\n            \"counts\": [0, 0, 0],\n            \"effective_lengths\": [1000, 1000, 1000]\n        },\n        {\n            \"counts\": [100, 101, 102, 103],\n            \"effective_lengths\": [100, 10000, 100, 100000]\n        },\n        {\n            \"counts\": [10, 10, 5, 5],\n            \"effective_lengths\": [1000, 1000, 500, 1000]\n        }\n    ]\n\n    all_results = []\n    for case in test_cases:\n        counts = np.array(case[\"counts\"], dtype=float)\n        lengths = np.array(case[\"effective_lengths\"], dtype=float)\n        \n        # 1. Calculate TPM vector\n        \n        # Calculate rates (reads per nucleotide)\n        # np.divide handles division by zero, but lengths are guaranteed > 0.\n        rates = counts / lengths\n        \n        # Sum of rates\n        sum_of_rates = np.sum(rates)\n        \n        tpm_vector = []\n        if sum_of_rates == 0:\n            # Edge case: If total signal is zero, TPMs are all zero.\n            tpm_vector = np.zeros_like(counts, dtype=float)\n        else:\n            # TPM = (rate / sum_of_rates) * 1e6\n            tpm_vector = (rates / sum_of_rates) * 1e6\n\n        # 2. Compute rank orderings\n\n        num_genes = len(counts)\n        indices = list(range(num_genes))\n        \n        # Rank by raw counts (descending), tie-break by smaller index (ascending)\n        # Sorting by a tuple (-value, index) achieves this.\n        count_ranking = sorted(indices, key=lambda i: (-counts[i], i))\n        \n        # Rank by TPM (descending), tie-break by smaller index (ascending)\n        tpm_ranking = sorted(indices, key=lambda i: (-tpm_vector[i], i))\n\n        all_results.append([\n            tpm_vector.tolist(),\n            count_ranking,\n            tpm_ranking\n        ])\n    \n    # Format the final output string exactly as specified.\n    # The default str() representation for lists and floats is sufficient.\n    # .replace(\" \", \"\") is used to remove whitespace for a compact representation.\n    # The problem did not specify float precision, so default is used.\n    case_strings = []\n    for tpm_vec, count_rank, tpm_rank in all_results:\n        # Manually construct string to avoid unwanted whitespace from str(list)\n        tpm_str = f\"[{','.join(map(str, tpm_vec))}]\"\n        count_rank_str = f\"[{','.join(map(str, count_rank))}]\"\n        tpm_rank_str = f\"[{','.join(map(str, tpm_rank))}]\"\n        case_strings.append(f\"[{tpm_str},{count_rank_str},{tpm_rank_str}]\")\n        \n    print(f\"[{','.join(case_strings)}]\")\n\nsolve()\n```", "id": "2967173"}, {"introduction": "Droplet-based single-cell RNA sequencing (scRNA-seq) relies on the random encapsulation of individual cells into nanoliter-sized droplets, a process governed by Poisson statistics. A critical parameter in experimental design is the cell loading concentration, which creates a trade-off between throughput and the rate of \"multiplets\"—droplets containing more than one cell that can confound analysis. This practice [@problem_id:2967132] invites you to derive the multiplet probability from first principles, providing a quantitative understanding of how experimental choices directly impact the quality and interpretability of single-cell data.", "problem": "In a droplet-based single-cell RNA sequencing (single-cell RNA-seq) workflow, a microfluidic generator forms monodisperse droplets of volume $V_d$ from a well-mixed cell suspension at concentration $c$ (cells per unit volume). Assume the following fundamental premises:\n- Cells are uniformly and independently distributed in space within the suspension at the moment of droplet formation.\n- Each cell is assigned to exactly one of $M$ exchangeable droplets uniformly at random, and the total number of cells in the input is $N$, with $N$ and $M$ both large.\n- The expected number of cells per droplet is $\\lambda$, and in the limit of large $N$ and $M$ at fixed $\\lambda$, the number of cells per droplet follows the Poisson distribution with mean $\\lambda$.\n\nStarting from these premises (and not from any pre-stated target formula), first derive a closed-form expression for the probability that a droplet is a multiplet (contains at least two cells) written solely in terms of $\\lambda$. Then connect $\\lambda$ to the loading concentration $c$ and droplet volume $V_d$ under the assumption of a homogeneous Poisson process in space, and use this to compute the multiplet probability for $c = 1.0 \\times 10^{5}\\ \\mathrm{cells/mL}$ and $V_d = 1.0\\ \\mathrm{nL}$. Express your final numerical answer as a decimal fraction, rounded to four significant figures.\n\nFinally, based on your derived expression, state whether the multiplet probability increases or decreases with loading concentration $c$, and justify your conclusion from first principles (no numerical value required for this part).", "solution": "The problem statement is subjected to validation.\n\nStep 1: Extract Givens\n- Droplet volume is $V_d$.\n- Cell suspension concentration is $c$.\n- Cells are uniformly and independently distributed.\n- Total number of cells is $N$, total number of droplets is $M$.\n- Each cell is assigned to one of $M$ exchangeable droplets uniformly at random.\n- $N$ and $M$ are large.\n- Expected number of cells per droplet is $\\lambda$.\n- The number of cells per droplet, $K$, follows a Poisson distribution with mean $\\lambda$ in the limit of large $N$ and $M$ at fixed $\\lambda$.\n- A multiplet is a droplet containing at least two cells ($K \\ge 2$).\n- The loading concentration is $c = 1.0 \\times 10^{5}\\ \\mathrm{cells/mL}$.\n- The droplet volume is $V_d = 1.0\\ \\mathrm{nL}$.\n- The final numerical answer must be rounded to four significant figures.\n\nStep 2: Validate Using Extracted Givens\nThe problem is scientifically grounded. The assumption that cell encapsulation in droplets follows a Poisson distribution is a standard and well-validated model in the field of microfluidics and single-cell genomics. It is a direct consequence of counting rare, independent events (cell capture) in a fixed volume. The problem is well-posed, providing all necessary information for derivation and calculation. The language is objective and precise. The numerical values provided are realistic for typical droplet-based single-cell sequencing experiments. The problem does not violate any of the invalidity criteria.\n\nStep 3: Verdict and Action\nThe problem is valid. A solution will be provided.\n\nThe solution proceeds in three parts as requested.\n\nFirst, we derive the probability of a droplet being a multiplet in terms of the mean number of cells per droplet, $\\lambda$.\nLet $K$ be the random variable representing the number of cells in a single droplet. According to the problem statement, $K$ follows a Poisson distribution with mean $\\lambda$. The probability mass function (PMF) is given by:\n$$P(K=k) = \\frac{\\lambda^k \\exp(-\\lambda)}{k!}$$\nfor $k \\in \\{0, 1, 2, \\dots\\}$.\n\nA multiplet is defined as a droplet containing at least two cells, which corresponds to the event $K \\ge 2$. The probability of this event, $P_{\\text{multiplet}}$, can be calculated as the complement of the event that a droplet contains fewer than two cells (i.e., zero or one cell).\n$$P_{\\text{multiplet}} = P(K \\ge 2) = 1 - P(K < 2) = 1 - [P(K=0) + P(K=1)]$$\nWe calculate the probabilities for $K=0$ and $K=1$ using the Poisson PMF:\nThe probability of a droplet being empty ($k=0$):\n$$P(K=0) = \\frac{\\lambda^0 \\exp(-\\lambda)}{0!} = \\frac{1 \\cdot \\exp(-\\lambda)}{1} = \\exp(-\\lambda)$$\nThe probability of a droplet containing exactly one cell (a singlet, $k=1$):\n$$P(K=1) = \\frac{\\lambda^1 \\exp(-\\lambda)}{1!} = \\frac{\\lambda \\exp(-\\lambda)}{1} = \\lambda \\exp(-\\lambda)$$\nSubstituting these expressions back into the equation for the multiplet probability, we obtain the closed-form expression in terms of $\\lambda$:\n$$P_{\\text{multiplet}} = 1 - [\\exp(-\\lambda) + \\lambda \\exp(-\\lambda)] = 1 - (1+\\lambda)\\exp(-\\lambda)$$\n\nSecond, we connect $\\lambda$ to the physical parameters $c$ and $V_d$ and compute the numerical probability.\nThe problem states to assume a homogeneous Poisson process in space. For such a process, the expected number of events (cells) in a given volume is the product of the event density (concentration $c$) and the volume ($V_d$). Therefore, the mean $\\lambda$ is given by:\n$$\\lambda = c \\cdot V_d$$\nWe are given $c = 1.0 \\times 10^{5}\\ \\mathrm{cells/mL}$ and $V_d = 1.0\\ \\mathrm{nL}$. To ensure dimensional consistency, we must convert the units to be compatible. We convert nanoliters (nL) to milliliters (mL):\n$$1\\ \\mathrm{nL} = 10^{-6}\\ \\mathrm{mL}$$\nSo, $V_d = 1.0 \\times 10^{-6}\\ \\mathrm{mL}$.\nNow, we can calculate the dimensionless parameter $\\lambda$:\n$$\\lambda = (1.0 \\times 10^{5}\\ \\mathrm{cells/mL}) \\times (1.0 \\times 10^{-6}\\ \\mathrm{mL}) = 0.1$$\nThe expected number of cells per droplet is $\\lambda = 0.1$.\nWe substitute this value into our derived expression for the multiplet probability:\n$$P_{\\text{multiplet}} = 1 - (1 + 0.1) \\exp(-0.1) = 1 - 1.1 \\exp(-0.1)$$\nUsing the value $\\exp(-0.1) \\approx 0.904837418$:\n$$P_{\\text{multiplet}} \\approx 1 - 1.1 \\times 0.904837418 = 1 - 0.995321160$$\n$$P_{\\text{multiplet}} \\approx 0.004678840$$\nRounding to four significant figures as required, we get:\n$$P_{\\text{multiplet}} \\approx 0.004679$$\n\nThird, we determine if the multiplet probability increases or decreases with loading concentration $c$.\nThe multiplet probability is a function of $\\lambda$, $P_{\\text{multiplet}}(\\lambda) = 1 - (1+\\lambda)\\exp(-\\lambda)$. The mean $\\lambda$ is itself a function of concentration $c$, $\\lambda(c) = c \\cdot V_d$. Since the droplet volume $V_d$ is a positive constant, $\\lambda$ is directly and linearly proportional to $c$. To understand how $P_{\\text{multiplet}}$ changes with $c$, we can analyze its derivative with respect to $\\lambda$. By the chain rule, $\\frac{d P_{\\text{multiplet}}}{d c} = \\frac{d P_{\\text{multiplet}}}{d \\lambda} \\cdot \\frac{d\\lambda}{dc}$. Since $\\frac{d\\lambda}{dc} = V_d > 0$, the sign of $\\frac{d P_{\\text{multiplet}}}{d c}$ is the same as the sign of $\\frac{d P_{\\text{multiplet}}}{d \\lambda}$.\nLet us compute the derivative of $P_{\\text{multiplet}}(\\lambda)$ with respect to $\\lambda$:\n$$\\frac{d}{d\\lambda} P_{\\text{multiplet}}(\\lambda) = \\frac{d}{d\\lambda} [1 - (1+\\lambda)\\exp(-\\lambda)]$$\n$$= 0 - \\frac{d}{d\\lambda} [(1+\\lambda)\\exp(-\\lambda)]$$\nUsing the product rule for differentiation, $[f(\\lambda)g(\\lambda)]' = f'(\\lambda)g(\\lambda) + f(\\lambda)g'(\\lambda)$, with $f(\\lambda) = 1+\\lambda$ and $g(\\lambda) = \\exp(-\\lambda)$:\n$$\\frac{d}{d\\lambda} [(1+\\lambda)\\exp(-\\lambda)] = (\\frac{d}{d\\lambda}(1+\\lambda))\\exp(-\\lambda) + (1+\\lambda)(\\frac{d}{d\\lambda}\\exp(-\\lambda))$$\n$$= (1)\\exp(-\\lambda) + (1+\\lambda)(-\\exp(-\\lambda))$$\n$$= \\exp(-\\lambda) - \\exp(-\\lambda) - \\lambda\\exp(-\\lambda) = -\\lambda\\exp(-\\lambda)$$\nSubstituting this back into the derivative of $P_{\\text{multiplet}}$:\n$$\\frac{d}{d\\lambda} P_{\\text{multiplet}}(\\lambda) = -(-\\lambda\\exp(-\\lambda)) = \\lambda\\exp(-\\lambda)$$\nFor any physically realistic scenario, the concentration $c$ is non-negative, and the droplet volume $V_d$ is positive, so $\\lambda = c V_d \\ge 0$. The exponential term $\\exp(-\\lambda)$ is always positive. Therefore, for any $\\lambda > 0$ (which corresponds to $c > 0$), the derivative $\\frac{d}{d\\lambda} P_{\\text{multiplet}}(\\lambda)$ is strictly positive.\nA positive derivative indicates that the function $P_{\\text{multiplet}}(\\lambda)$ is a monotonically increasing function of $\\lambda$ for $\\lambda > 0$. Since $\\lambda$ is itself a monotonically increasing function of $c$, it follows that the multiplet probability increases as the loading concentration $c$ increases. This confirms the intuition that a higher density of cells in the suspension naturally leads to a higher chance of capturing multiple cells in a droplet of fixed volume.", "answer": "$$\\boxed{0.004679}$$", "id": "2967132"}, {"introduction": "Spatially resolved transcriptomics provides a powerful view of gene expression within the native tissue context, but each measurement spot often captures a mixture of signals from multiple cell types. A key computational challenge is \"deconvolution,\" or unmixing these signals to infer the underlying cellular composition. This exercise [@problem_id:2967180] provides a practical application of a linear mixture model, where you will use non-negative least squares to estimate cell type proportions, offering insight into how we can reconstruct the cellular architecture of tissues from their spatial gene expression maps.", "problem": "You are tasked with implementing and evaluating a simple spatial deconvolution model for transcriptomics using a linear mixture framework grounded in additivity of molecular counts. In spatially resolved transcriptomics, a single spot typically captures messenger ribonucleic acid (mRNA) originating from multiple cell types. Under library size normalization and stable marker expression, the expected expression of each gene in a spot can be approximated as a nonnegative linear combination of cell-type-specific signatures.\n\nFundamental base. The Central Dogma of molecular biology states that deoxyribonucleic acid (DNA) is transcribed to mRNA, which is quantified by transcriptomic assays. For a spot containing a mixture of cell types, the expected expression of a gene is the sum over contributions from each cell type, scaled by the proportion of that cell type present in the spot. This leads to a linear mixture model in which an observed expression vector is an additive combination of cell-type signatures weighted by nonnegative proportions.\n\nMathematical model. Let there be $G$ genes and $K$ cell types. Let $\\mathbf{S} \\in \\mathbb{R}_{\\ge 0}^{G \\times K}$ be a nonnegative signature matrix whose column $k$ contains reference expression levels of each gene for cell type $k$. Let $\\mathbf{y} \\in \\mathbb{R}_{\\ge 0}^{G}$ be the observed expression vector of the spot. Let $\\mathbf{p} \\in \\mathbb{R}_{\\ge 0}^{K}$ be the vector of cell type proportions. The linear mixture model posits\n$$\n\\mathbf{y} \\approx \\mathbf{S}\\,\\mathbf{p},\n$$\nwith constraints $\\mathbf{p} \\ge \\mathbf{0}$ element-wise and $\\sum_{k=1}^{K} p_k = 1$. Because the equality constraint can be addressed after estimation by renormalization, you will estimate $\\mathbf{p}$ by solving a nonnegative least squares problem and then normalizing.\n\nComputation objectives.\n1. Estimate $\\mathbf{p}$ by solving the nonnegative least squares problem\n$$\n\\min_{\\mathbf{p} \\in \\mathbb{R}^{K}} \\left\\| \\mathbf{S}\\,\\mathbf{p} - \\mathbf{y} \\right\\|_2 \\quad \\text{subject to} \\quad \\mathbf{p} \\ge \\mathbf{0}.\n$$\n2. Renormalize the estimate to obtain proportions that sum to $1$: if $\\sum_{k=1}^{K} p_k > 0$, set $\\tilde{\\mathbf{p}} = \\mathbf{p} / \\left(\\sum_{k=1}^{K} p_k\\right)$; otherwise, set $\\tilde{\\mathbf{p}} = \\mathbf{p}$.\n3. Compute the reconstructed expression $\\hat{\\mathbf{y}} = \\mathbf{S}\\,\\tilde{\\mathbf{p}}$.\n4. Compute the residual vector $\\mathbf{r} = \\mathbf{y} - \\hat{\\mathbf{y}}$.\n5. Compute the root-mean-square error (RMSE)\n$$\n\\mathrm{RMSE} = \\sqrt{\\frac{1}{G}\\sum_{g=1}^{G} r_g^2 }.\n$$\n\nTest suite. Implement your program to run on the following four test cases. Each test case consists of a specific signature matrix $\\mathbf{S}$ and spot vector $\\mathbf{y}$. All numbers are unitless and must be treated as floats.\n\n- Test case $1$ (perfect mixture, identifiable):\n  - $\\mathbf{S} = \\begin{bmatrix}\n  10 & 2 & 0 \\\\\n  2 & 8 & 1 \\\\\n  0 & 1 & 9 \\\\\n  1 & 0 & 1\n  \\end{bmatrix}$, where $G = 4$, $K = 3$.\n  - $\\mathbf{y} = \\begin{bmatrix} 5.6 \\\\ 3.6 \\\\ 2.1 \\\\ 0.7 \\end{bmatrix}$.\n\n- Test case $2$ (noisy mixture, same signatures):\n  - $\\mathbf{S}$ identical to test case $1$.\n  - $\\mathbf{y} = \\begin{bmatrix} 3.1 \\\\ 4.5 \\\\ 3.25 \\\\ 0.5 \\end{bmatrix}$.\n\n- Test case $3$ (near-collinearity, well-fitted but ambiguous attribution):\n  - $\\mathbf{S} = \\begin{bmatrix}\n  5 & 5.1 \\\\\n  5 & 4.9 \\\\\n  1 & 1.1\n  \\end{bmatrix}$, where $G = 3$, $K = 2$.\n  - $\\mathbf{y} = \\begin{bmatrix} 5.04 \\\\ 4.96 \\\\ 1.04 \\end{bmatrix}$.\n\n- Test case $4$ (unexplained gene, structured residual):\n  - $\\mathbf{S} = \\begin{bmatrix}\n  4 & 0 \\\\\n  0 & 3 \\\\\n  1 & 1 \\\\\n  0 & 0\n  \\end{bmatrix}$, where $G = 4$, $K = 2$.\n  - $\\mathbf{y} = \\begin{bmatrix} 2.8 \\\\ 0.9 \\\\ 1.0 \\\\ 0.5 \\end{bmatrix}$.\n\nOutput specification. For each test case, your program must output a list with three elements: the estimated proportions $\\tilde{\\mathbf{p}}$ as a list of floats, the $\\mathrm{RMSE}$ as a float, and the residual vector $\\mathbf{r}$ as a list of floats. Round every float in the output to $6$ decimal places. Your program should produce a single line of output containing the results for all test cases as a comma-separated list enclosed in square brackets. Specifically, the final output must have the format\n$$\n\\left[ [\\text{proportions}_1, \\text{rmse}_1, \\text{residuals}_1], [\\text{proportions}_2, \\text{rmse}_2, \\text{residuals}_2], [\\text{proportions}_3, \\text{rmse}_3, \\text{residuals}_3], [\\text{proportions}_4, \\text{rmse}_4, \\text{residuals}_4] \\right]\n$$\nwith all numeric entries rounded to $6$ decimal places and represented as decimals (not fractions and not percentages).", "solution": "The problem presented is a standard deconvolution task in computational biology, specifically for spatially resolved transcriptomics. The objective is to estimate the proportions of different cell types within a spatially defined tissue spot, given the spot's aggregated gene expression profile and a reference signature matrix of pure cell types. The problem is well-defined, scientifically grounded in the linear mixture model, and computationally tractable. It is valid.\n\nThe mathematical formulation rests upon the assumption that the observed gene expression vector $\\mathbf{y} \\in \\mathbb{R}_{\\ge 0}^{G}$ for a spot with $G$ genes is a linear combination of the expression signatures of $K$ constituent cell types. These signatures are encoded in the columns of a matrix $\\mathbf{S} \\in \\mathbb{R}_{\\ge 0}^{G \\times K}$. The model is $\\mathbf{y} \\approx \\mathbf{S}\\,\\mathbf{p}$, where $\\mathbf{p} \\in \\mathbb{R}_{\\ge 0}^{K}$ is the vector of cell type proportions.\n\nThe estimation of $\\mathbf{p}$ is formulated as an optimization problem. We seek to find a proportion vector $\\mathbf{p}$ that minimizes the squared Euclidean distance between the observed expression $\\mathbf{y}$ and the reconstructed expression $\\mathbf{S}\\,\\mathbf{p}$. This is a classical least squares problem. Critically, the proportions must be non-negative, as a negative quantity of a cell type is physically meaningless. This leads to the following Nonnegative Least Squares (NNLS) problem:\n$$\n\\min_{\\mathbf{p} \\in \\mathbb{R}^{K}} \\left\\| \\mathbf{S}\\,\\mathbf{p} - \\mathbf{y} \\right\\|_2^2 \\quad \\text{subject to} \\quad \\mathbf{p} \\ge \\mathbf{0}\n$$\nThis is a convex optimization problem with a unique solution, which can be found using well-established algorithms, such as an active-set method. The `scipy.optimize.nnls` function provides an efficient implementation for this task.\n\nUpon solving for the unnormalized proportion vector $\\mathbf{p}$, two subsequent steps are required. First, the vector must be normalized to satisfy the constraint that the proportions sum to unity, $\\sum_{k=1}^{K} p_k = 1$. The normalized proportion vector, denoted $\\tilde{\\mathbf{p}}$, is calculated as:\n$$\n\\tilde{\\mathbf{p}} = \\frac{\\mathbf{p}}{\\sum_{k=1}^{K} p_k}\n$$\nThis normalization is performed only if the sum of the elements of $\\mathbf{p}$ is greater than $0$; otherwise, the zero vector remains a zero vector.\n\nWith the normalized proportions $\\tilde{\\mathbf{p}}$, we can compute the final model outputs. The reconstructed expression vector $\\hat{\\mathbf{y}}$ is calculated as:\n$$\n\\hat{\\mathbf{y}} = \\mathbf{S}\\,\\tilde{\\mathbf{p}}\n$$\nThe quality of the fit is assessed through the residual vector $\\mathbf{r}$ and the Root-Mean-Square Error (RMSE). The residual vector is the difference between the observed and reconstructed expression:\n$$\n\\mathbf{r} = \\mathbf{y} - \\hat{\\mathbf{y}}\n$$\nThe RMSE provides a single metric summarizing the average magnitude of the residuals across all $G$ genes:\n$$\n\\mathrm{RMSE} = \\sqrt{\\frac{1}{G}\\sum_{g=1}^{G} r_g^2} = \\frac{\\left\\| \\mathbf{r} \\right\\|_2}{\\sqrt{G}}\n$$\nThis procedure will be applied to each test case. The specified input matrices $\\mathbf{S}$ and vectors $\\mathbf{y}$ will be used to compute the estimated proportions $\\tilde{\\mathbf{p}}$, the RMSE, and the residual vector $\\mathbf{r}$. All numerical results will be rounded to $6$ decimal places as required.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.optimize import nnls\n\ndef solve():\n    \"\"\"\n    Solves the spatial deconvolution problem for four test cases.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        (\n            np.array([\n                [10, 2, 0],\n                [2, 8, 1],\n                [0, 1, 9],\n                [1, 0, 1]\n            ], dtype=float),\n            np.array([5.6, 3.6, 2.1, 0.7], dtype=float)\n        ),\n        (\n            np.array([\n                [10, 2, 0],\n                [2, 8, 1],\n                [0, 1, 9],\n                [1, 0, 1]\n            ], dtype=float),\n            np.array([3.1, 4.5, 3.25, 0.5], dtype=float)\n        ),\n        (\n            np.array([\n                [5, 5.1],\n                [5, 4.9],\n                [1, 1.1]\n            ], dtype=float),\n            np.array([5.04, 4.96, 1.04], dtype=float)\n        ),\n        (\n            np.array([\n                [4, 0],\n                [0, 3],\n                [1, 1],\n                [0, 0]\n            ], dtype=float),\n            np.array([2.8, 0.9, 1.0, 0.5], dtype=float)\n        )\n    ]\n\n    results = []\n    for S, y in test_cases:\n        # 1. Estimate p by solving the nonnegative least squares problem.\n        # nnls expects 1-D array for the second argument.\n        p, _ = nnls(S, y.flatten())\n\n        # 2. Renormalize the estimate.\n        p_sum = np.sum(p)\n        if p_sum > 0:\n            p_tilde = p / p_sum\n        else:\n            p_tilde = p\n\n        # 3. Compute the reconstructed expression.\n        y_hat = S @ p_tilde\n\n        # 4. Compute the residual vector.\n        r = y - y_hat\n\n        # 5. Compute the root-mean-square error (RMSE).\n        G = S.shape[0]\n        rmse = np.sqrt(np.sum(r**2) / G)\n\n        # Format outputs with rounding to 6 decimal places.\n        p_out = [round(val, 6) for val in p_tilde]\n        rmse_out = round(rmse, 6)\n        r_out = [round(val, 6) for val in r]\n\n        results.append([p_out, rmse_out, r_out])\n\n    # Final print statement in the exact required format.\n    # Note: The template `f\"[{','.join(map(str, results))}]\"` results in\n    # a string with no spaces between list items, e.g., \"[[...],[...]]\"\n    # This is followed strictly.\n    output_str = f\"[{','.join(map(str, results))}]\"\n    # Python's str() on a list adds spaces, so this replacement is needed\n    # to match the template's literal output.\n    output_str = output_str.replace(\"', '\", \"','\") \n    print(output_str)\n\nsolve()\n```", "id": "2967180"}]}