{"hands_on_practices": [{"introduction": "Our journey into quantitative modeling begins with the deterministic framework, which describes the average behavior of a large population of molecules. This exercise grounds your understanding in the Law of Mass Action, a cornerstone of chemical kinetics. By deriving the steady-state protein concentration for a detailed, multi-step transcription initiation process, you will practice the essential skill of translating a biological reaction scheme into a system of ordinary differential equations and solving for its equilibrium state. This foundational practice is crucial for building intuition before we introduce the complexities of stochasticity. [@problem_id:2728827]", "problem": "Consider a single-copy bacterial promoter driving expression of a protein via a three-state transcription initiation cycle under deterministic mass-action kinetics. The promoter states are free promoter, closed complex, and open complex. RNA polymerase (RNAP) binding and isomerization steps are modeled explicitly; productive initiation produces one messenger ribonucleic acid (mRNA) and returns the promoter to the free state, releasing RNAP back to the solution. Assume well-mixed conditions and a constant bulk RNAP concentration because RNAP is in large excess over the promoter.\n\nThe promoter-state reaction scheme is:\n- Free promoter $F$ binds RNAP $R$ to form a closed complex $C$: $F + R \\xrightarrow{k_1} C$.\n- Closed complex dissociates: $C \\xrightarrow{k_{-1}} F + R$.\n- Closed complex isomerizes to the open complex $O$: $C \\xrightarrow{k_2} O$.\n- Open complex reverts to closed complex: $O \\xrightarrow{k_{-2}} C$.\n- Open complex undergoes productive initiation, yielding one mRNA and resetting the promoter: $O \\xrightarrow{k_3} F + R + \\text{mRNA}$.\n\nLet the total promoter concentration be $[G_{\\mathrm{tot}}]$, with $[F] + [C] + [O] = [G_{\\mathrm{tot}}]$. Let $[R]$ be the constant RNAP concentration. The mRNA and protein dynamics follow:\n- mRNA production rate equals $k_3 [O]$. mRNA degrades with first-order rate constant $\\gamma_m$.\n- Protein is translated from mRNA with first-order rate constant $k_{\\mathrm{tl}}$ and is diluted/degraded with first-order rate constant $\\gamma_p$.\n\nStarting from the law of mass action and mass conservation, derive the steady-state open-complex concentration $[O]^*$ in terms of $k_1, k_{-1}, k_2, k_{-2}, k_3, [R]$, and $[G_{\\mathrm{tot}}]$ by solving the steady-state balance of promoter states. Then, use $[O]^*$ to compute the steady-state protein concentration $[P]^*$.\n\nUse the following scientifically plausible parameter values:\n- $k_1 = 1.0 \\times 10^{-3}$ (nM$^{-1}$ s$^{-1}$)\n- $k_{-1} = 0.1$ (s$^{-1}$)\n- $k_2 = 10$ (s$^{-1}$)\n- $k_{-2} = 1$ (s$^{-1}$)\n- $k_3 = 0.5$ (s$^{-1}$)\n- $[R] = 1000$ (nM)\n- $[G_{\\mathrm{tot}}] = 1$ (nM)\n- $\\gamma_m = 2.0 \\times 10^{-3}$ (s$^{-1}$)\n- $k_{\\mathrm{tl}} = 3.0 \\times 10^{-2}$ (s$^{-1}$)\n- $\\gamma_p = 2.0 \\times 10^{-4}$ (s$^{-1}$)\n\nExpress the final steady-state protein concentration $[P]^*$ in micromolar. Round your answer to three significant figures.", "solution": "The problem statement is subjected to validation and is found to be scientifically grounded, well-posed, and objective. It describes a standard model of gene expression using deterministic mass-action kinetics, a fundamental approach in quantitative biology. All necessary parameters and constraints are provided, and no contradictions or ambiguities are present. Therefore, we proceed with a rigorous derivation of the solution.\n\nThe dynamics of the promoter states—free ($[F]$), closed complex ($[C]$), and open complex ($[O]$)—are described by a system of ordinary differential equations (ODEs) based on the law of mass action. The concentration of RNA polymerase, $[R]$, is assumed to be constant.\n\n$$\n\\frac{d[F]}{dt} = -k_1 [F][R] + k_{-1}[C] + k_3[O]\n$$\n$$\n\\frac{d[C]}{dt} = k_1 [F][R] - (k_{-1} + k_2)[C] + k_{-2}[O]\n$$\n$$\n\\frac{d[O]}{dt} = k_2[C] - (k_{-2} + k_3)[O]\n$$\n\nThe total concentration of promoter, $[G_{\\mathrm{tot}}]$, is conserved:\n$$\n[F] + [C] + [O] = [G_{\\mathrm{tot}}]\n$$\n\nTo find the steady-state concentrations, we set the time derivatives to zero. Let the steady-state concentrations be denoted with an asterisk ($*$). From the ODE for $[O]$, we have:\n$$\n0 = k_2[C]^* - (k_{-2} + k_3)[O]^*\n$$\nThis allows us to express $[C]^*$ in terms of $[O]^*$:\n$$\n[C]^* = \\frac{k_{-2} + k_3}{k_2} [O]^*\n$$\n\nNext, from the steady-state ODE for $[C]$, we have:\n$$\n0 = k_1 [F]^*[R] - (k_{-1} + k_2)[C]^* + k_{-2}[O]^*\n$$\nSubstituting the expression for $[C]^*$ allows us to solve for $[F]^*$ in terms of $[O]^*$:\n$$\nk_1 [F]^*[R] = (k_{-1} + k_2)[C]^* - k_{-2}[O]^* = (k_{-1} + k_2)\\left(\\frac{k_{-2} + k_3}{k_2}\\right)[O]^* - k_{-2}[O]^*\n$$\n$$\nk_1 [F]^*[R] = \\frac{(k_{-1} + k_2)(k_{-2} + k_3) - k_2 k_{-2}}{k_2} [O]^* = \\frac{k_{-1}k_{-2} + k_{-1}k_3 + k_2 k_3}{k_2} [O]^*\n$$\n$$\n[F]^* = \\frac{k_{-1}k_{-2} + k_{-1}k_3 + k_2 k_3}{k_1 k_2 [R]} [O]^*\n$$\n\nNow, we enforce the conservation law for the total promoter concentration:\n$$\n[F]^* + [C]^* + [O]^* = [G_{\\mathrm{tot}}]\n$$\nSubstituting the expressions for $[F]^*$ and $[C]^*$ gives an equation solely in terms of $[O]^*$:\n$$\n\\left( \\frac{k_{-1}k_{-2} + k_{-1}k_3 + k_2 k_3}{k_1 k_2 [R]} \\right)[O]^* + \\left( \\frac{k_{-2} + k_3}{k_2} \\right)[O]^* + [O]^* = [G_{\\mathrm{tot}}]\n$$\nFactoring out $[O]^*$ and solving for it yields the steady-state open-complex concentration:\n$$\n[O]^* \\left( \\frac{k_{-1}k_{-2} + k_{-1}k_3 + k_2 k_3 + k_1[R](k_{-2}+k_3) + k_1k_2[R]}{k_1 k_2 [R]} \\right) = [G_{\\mathrm{tot}}]\n$$\n$$\n[O]^* = \\frac{[G_{\\mathrm{tot}}] k_1 k_2 [R]}{k_{-1}k_{-2} + k_{-1}k_3 + k_2 k_3 + k_1[R](k_{-2}+k_3) + k_1k_2[R]}\n$$\n\nThe dynamics of mRNA ($[m]$) and protein ($[P]$) concentrations are given by:\n$$\n\\frac{d[m]}{dt} = k_3 [O] - \\gamma_m [m]\n$$\n$$\n\\frac{d[P]}{dt} = k_{\\mathrm{tl}} [m] - \\gamma_p [P]\n$$\nAt steady state, their derivatives are also zero.\nFrom the mRNA equation:\n$$\nk_3 [O]^* = \\gamma_m [m]^* \\implies [m]^* = \\frac{k_3}{\\gamma_m} [O]^*\n$$\nFrom the protein equation:\n$$\nk_{\\mathrm{tl}} [m]^* = \\gamma_p [P]^* \\implies [P]^* = \\frac{k_{\\mathrm{tl}}}{\\gamma_p} [m]^*\n$$\nSubstituting the expression for $[m]^*$, we find the steady-state protein concentration $[P]^*$ in terms of $[O]^*$:\n$$\n[P]^* = \\frac{k_{\\mathrm{tl}}}{\\gamma_p} \\left( \\frac{k_3}{\\gamma_m} [O]^* \\right) = \\frac{k_{\\mathrm{tl}} k_3}{\\gamma_p \\gamma_m} [O]^*\n$$\nBy substituting the full expression for $[O]^*$, we obtain the final analytical solution for $[P]^*$.\n\nWe now substitute the provided parameter values:\n$k_1 = 1.0 \\times 10^{-3}$ nM$^{-1}$ s$^{-1}$, $k_{-1} = 0.1$ s$^{-1}$, $k_2 = 10$ s$^{-1}$, $k_{-2} = 1$ s$^{-1}$, $k_3 = 0.5$ s$^{-1}$, $[R] = 1000$ nM, $[G_{\\mathrm{tot}}] = 1$ nM, $\\gamma_m = 2.0 \\times 10^{-3}$ s$^{-1}$, $k_{\\mathrm{tl}} = 3.0 \\times 10^{-2}$ s$^{-1}$, and $\\gamma_p = 2.0 \\times 10^{-4}$ s$^{-1}$.\n\nFirst, we compute the denominator of the expression for $[O]^*$:\nThe term $k_1[R] = (1.0 \\times 10^{-3}) \\times 1000 = 1.0$ s$^{-1}$.\nThe denominator is $D = k_{-1}k_{-2} + k_{-1}k_3 + k_2 k_3 + k_1[R](k_{-2}+k_3) + k_1[R]k_2$.\n$D = (0.1)(1) + (0.1)(0.5) + (10)(0.5) + (1.0)(1 + 0.5) + (1.0)(10)$\n$D = 0.1 + 0.05 + 5.0 + 1.5 + 10.0 = 16.65$ s$^{-2}$.\n\nNext, we compute the numerator of the expression for $[O]^*$:\n$N_O = [G_{\\mathrm{tot}}] k_1 k_2 [R] = (1) \\times (1.0 \\times 10^{-3}) \\times (10) \\times (1000) = 10$ nM s$^{-2}$.\n\nThe steady-state open complex concentration is:\n$$\n[O]^* = \\frac{N_O}{D} = \\frac{10}{16.65} \\text{ nM}\n$$\n\nFinally, we compute the steady-state protein concentration $[P]^*$:\n$$\n[P]^* = \\frac{k_{\\mathrm{tl}} k_3}{\\gamma_p \\gamma_m} [O]^* = \\frac{(3.0 \\times 10^{-2})(0.5)}{(2.0 \\times 10^{-4})(2.0 \\times 10^{-3})} \\times \\frac{10}{16.65} \\text{ nM}\n$$\n$$\n[P]^* = \\frac{1.5 \\times 10^{-2}}{4.0 \\times 10^{-7}} \\times \\frac{10}{16.65} \\text{ nM} = 37500 \\times \\frac{10}{16.65} \\text{ nM}\n$$\n$$\n[P]^* = \\frac{375000}{16.65} \\text{ nM} \\approx 22522.52 \\text{ nM}\n$$\n\nThe problem requires the final answer in micromolar ($\\mu$M). Since $1$ $\\mu$M $= 1000$ nM, we must divide our result by $1000$:\n$$\n[P]^* \\approx \\frac{22522.52}{1000} \\text{ } \\mu\\text{M} \\approx 22.52252 \\text{ } \\mu\\text{M}\n$$\nRounding to three significant figures, as required, gives the final answer.\n$$\n[P]^* \\approx 22.5 \\text{ } \\mu\\text{M}\n$$", "answer": "$$\n\\boxed{22.5}\n$$", "id": "2728827"}, {"introduction": "Moving beyond population averages, we now dive into the inherently probabilistic nature of gene expression at the single-cell level. This practice introduces the Stochastic Simulation Algorithm (SSA), often called the Gillespie algorithm, which provides an exact method for simulating the time evolution of a chemically reacting system. You will apply this powerful tool to a bistable genetic toggle switch, a canonical motif in synthetic biology, to investigate how a transient environmental pulse can induce a probabilistic switch between two distinct cellular phenotypes. This hands-on coding exercise provides a practical understanding of how intrinsic noise generates variability and facilitates complex behaviors like polyphenism. [@problem_id:2630111]", "problem": "A bistable gene regulatory network can generate discrete alternative phenotypes (polyphenisms) through mutual repression between two transcription factors. Developmental plasticity arises when a transient environmental input biases the system toward one stable state or the other. Consider a minimal model of a mutually repressing toggle switch comprising two molecular species, denoted by $X$ and $Y$ (copy numbers in molecules), with synthesis and first-order degradation reactions. The effective synthesis propensities are repressed by the antagonist via a Hill function, and an environmental pulse transiently increases the synthesis propensity of $X$. The goal is to compute, using exact stochastic simulation in the Stochastic Simulation Algorithm (SSA) of Daniel T. Gillespie, the distribution of first-passage switching times into the $X$-high state in response to a transient pulse, and to summarize it per parameter set.\n\nFundamental base:\n- Chemical Master Equation (CME): Reaction events for a well-mixed system at constant volume and temperature follow a continuous-time Markov process with state-dependent propensities, and exact sample paths are generated by the Stochastic Simulation Algorithm (SSA).\n- For a given state, the waiting time to the next reaction is exponentially distributed with rate equal to the sum of propensities, and the reaction identity is chosen proportional to its propensity.\n- Hill repression is a well-tested phenomenological rule in gene regulation: repression of a target synthesis rate by an antagonist with copy number $Z$ is modeled as $1/\\left(1+\\left(Z/K\\right)^n\\right)$ where $K$ is a dissociation parameter and $n$ is a Hill coefficient.\n\nModel specification:\n- Species: $X$, $Y$ (nonnegative integers, molecules).\n- Reactions and propensities at time $t$ and state $\\left(X,Y\\right)$:\n  - $R_1$: $X \\to X+1$ with propensity\n    $$ a_1\\left(X,Y,t\\right) \\;=\\; \\frac{k_X\\left(t\\right)}{1+\\left(\\frac{Y}{K}\\right)^n}.$$\n  - $R_2$: $X \\to X-1$ with propensity\n    $$ a_2\\left(X,Y,t\\right) \\;=\\; d_X \\, X.$$\n  - $R_3$: $Y \\to Y+1$ with propensity\n    $$ a_3\\left(X,Y,t\\right) \\;=\\; \\frac{k_Y}{1+\\left(\\frac{X}{K}\\right)^n}.$$\n  - $R_4$: $Y \\to Y-1$ with propensity\n    $$ a_4\\left(X,Y,t\\right) \\;=\\; d_Y \\, Y.$$\n- Environmental pulse:\n  $$ k_X\\left(t\\right) \\;=\\; \\begin{cases}\n  p \\, k_{X,0}  \\text{if } 0 \\le t  T_p,\\\\\n  k_{X,0}  \\text{if } t \\ge T_p,\n  \\end{cases} $$\n  with pulse factor $p \\ge 1$ and pulse duration $T_p$ (both specified per test case). The parameter $k_Y$ is time invariant.\n- Initial condition: $t=0$, $X\\left(0\\right)=X_0$, $Y\\left(0\\right)=Y_0$ with $X_0 - Y_0 \\le -h$ (i.e., initially in the $Y$-high basin with a margin $h$).\n- Switching time definition (first-passage): the switching time $\\tau$ is the first time $t$ such that $X\\left(t\\right) - Y\\left(t\\right) \\ge h$, where $h$ is a positive threshold (in molecules). If no such time occurs before a maximum simulation time $T_{\\max}$, the run is deemed non-switching.\n\nUnits:\n- Time is in minutes, reaction rate constants $k_{X,0}$, $k_Y$ are in molecules per minute, degradation constants $d_X$, $d_Y$ are in per minute, $K$ and $h$ are in molecules. The output mean switching time must be reported in minutes. The fraction of switched runs must be reported as a decimal (not a percentage).\n\nComputation protocol:\n- For each parameter set (test case), simulate $N$ independent SSA trajectories, each up to time $T_{\\max}$ or until switching occurs. Let $M$ be the number of trajectories that switch. Compute:\n  - Fraction switched $f = M/N$ (decimal).\n  - Mean switching time $\\bar{\\tau} = \\left(\\sum_{i=1}^{M} \\tau_i\\right)/M$ in minutes, computed over only the switching trajectories. If $M=0$, define $\\bar{\\tau} = -1.0$ by convention.\n- Randomness control: Use a fixed base seed $s_0$ for reproducibility and independent streams per trajectory. For test case index $i$ (starting at $0$) and replicate index $j$ (starting at $0$), seed the pseudo-random number generator for that replicate with\n  $$ s_{i,j} \\;=\\; s_0 \\;+\\; 104729\\, i \\;+\\; 10007\\, j, $$\n  where $104729$ and $10007$ are fixed integers. All uniform random variates used by SSA must be generated from this seeded stream.\n- Rounding: Report $f$ and $\\bar{\\tau}$ rounded to three decimal places.\n\nTest suite:\nUse the following four parameter sets, each with $N=64$ replicates and base seed $s_0 = 1357911$. All other parameters not explicitly varied are identical across cases. Specifically:\n- Shared parameters for all cases:\n  - $k_{X,0} = 12.0$ molecules/minute,\n  - $k_Y = 12.0$ molecules/minute,\n  - $d_X = 0.2$ per minute,\n  - $d_Y = 0.2$ per minute,\n  - $K = 40$ molecules,\n  - $n = 2$ (dimensionless Hill coefficient),\n  - $h = 20$ molecules,\n  - $X_0 = 10$ molecules,\n  - $Y_0 = 90$ molecules,\n  - $T_{\\max} = 200.0$ minutes,\n  - $N = 64$,\n  - $s_0 = 1357911$.\n- Case $0$ (happy path): $p = 3.0$, $T_p = 10.0$ minutes.\n- Case $1$ (boundary/weak pulse): $p = 1.5$, $T_p = 10.0$ minutes.\n- Case $2$ (no pulse control): $p = 1.0$, $T_p = 0.0$ minutes.\n- Case $3$ (strong/brief pulse): $p = 4.0$, $T_p = 5.0$ minutes.\n\nRequired final output format:\n- Your program should produce a single line of output containing the results as a comma-separated list of pairs $\\left[f,\\bar{\\tau}\\right]$ for the cases in order $0,1,2,3$, enclosed in square brackets, with no whitespace. For example, the syntactic shape must be\n  $$\\left[\\left[f_0,\\bar{\\tau}_0\\right],\\left[f_1,\\bar{\\tau}_1\\right],\\left[f_2,\\bar{\\tau}_2\\right],\\left[f_3,\\bar{\\tau}_3\\right]\\right],$$\n  with both $f_i$ and $\\bar{\\tau}_i$ rounded to three decimal places and $\\bar{\\tau}_i$ equal to $-1.0$ if no switching was observed in case $i$.", "solution": "We derive an exact stochastic simulation and a computable definition of first-passage switching times in a bistable toggle switch subject to a transient environmental pulse, using the foundational principles of the Chemical Master Equation (CME) and the Stochastic Simulation Algorithm (SSA).\n\nPrincipled modeling of bistability and environmental control:\n- In a well-mixed volume at constant temperature, the CME models the time evolution of the probability distribution over molecular counts. Each reaction channel is a Poisson process with an instantaneous hazard equal to its propensity. Exact sample paths can be generated with the SSA of Daniel T. Gillespie.\n- Mutual repression is captured via Hill-type repression. If species $Y$ represses $X$, then the effective synthesis rate of $X$ is $k_X\\left(t\\right)\\,/\\left(1+\\left(\\frac{Y}{K}\\right)^n\\right)$, where $K$ is a dissociation parameter and $n$ is a Hill coefficient. Bistability in the deterministic analog can occur for sufficiently strong nonlinearity, and in the stochastic setting, the system exhibits metastable states corresponding to $X$-dominant and $Y$-dominant phenotypes. This provides a quantitative basis for polyphenism: the environment can transiently modify parameters to bias state occupancy.\n- Here, the environment acts as a transient pulse that multiplies the synthesis propensity of $X$ by a factor $p$ during a window $0 \\le t  T_p$.\n\nReaction system and propensities:\n- We model four reactions: synthesis and degradation for each of $X$ and $Y$.\n- The propensities at state $\\left(X,Y\\right)$ and time $t$ are\n  $$ a_1\\left(X,Y,t\\right) \\;=\\; \\frac{k_X\\left(t\\right)}{1+\\left(\\frac{Y}{K}\\right)^n}, \\quad a_2\\left(X,Y,t\\right) \\;=\\; d_X X, $$\n  $$ a_3\\left(X,Y,t\\right) \\;=\\; \\frac{k_Y}{1+\\left(\\frac{X}{K}\\right)^n}, \\quad a_4\\left(X,Y,t\\right) \\;=\\; d_Y Y, $$\n  with $k_X\\left(t\\right) = p\\,k_{X,0}$ for $0 \\le t  T_p$ and $k_X\\left(t\\right) = k_{X,0}$ otherwise. The Hill coefficient $n$ is dimensionless, and $K$ is in molecules, consistent with $X$ and $Y$ being discrete counts.\n\nExact stochastic simulation (Gillespie SSA):\n- Given propensities $a_1,\\dots,a_4$, the total propensity is $a_0 = \\sum_{r=1}^{4} a_r$. The CME implies that the waiting time $\\Delta t$ to the next reaction is exponentially distributed with rate $a_0$, so we can sample it as \n  $$ \\Delta t \\;=\\; \\frac{1}{a_0} \\ln\\left(\\frac{1}{u_1}\\right), $$\n  where $u_1 \\sim \\text{Uniform}\\left(0,1\\right)$. The reaction index $r$ is chosen by drawing $u_2 \\sim \\text{Uniform}\\left(0,1\\right)$ and selecting the smallest $r$ such that $\\sum_{q=1}^{r} a_q \\ge u_2 a_0$. The state is updated by the stoichiometric change of reaction $r$, and time advances by $\\Delta t$. This process is repeated until a stopping condition is met.\n- The algorithm above is exact for the CME and is therefore the correct foundation for sampling switching times.\n\nSwitching time definition and detection:\n- We define the switching time as the first-passage time to the set $\\left\\{ \\left(X,Y\\right): X-Y \\ge h \\right\\}$ starting from $X_0 - Y_0 \\le -h$. Because the SSA produces a right-continuous piecewise-constant sample path that jumps at reaction times, we detect switching immediately after a reaction update at time $t$ if $X-Y \\ge h$ holds.\n- If no switching occurs by $T_{\\max}$, the trajectory is classified as non-switching.\n\nMonte Carlo estimation for each parameter set:\n- For each test case, we run $N$ independent replicates. Let $M$ be the number of replicates that switch and $\\tau_1,\\dots,\\tau_M$ the corresponding switching times. We compute the fraction switched $f = M/N$ and the conditional mean switching time $\\bar{\\tau} = \\left(\\sum_{i=1}^M \\tau_i\\right)/M$ in minutes. If $M=0$ we adopt the convention $\\bar{\\tau}=-1.0$ to avoid undefined division.\n- To ensure reproducibility and independence of replicates, we deterministically seed each replicate’s pseudo-random number generator (PRNG). Using a fixed base seed $s_0$ and coprime offsets, we choose\n  $$ s_{i,j} \\;=\\; s_0 \\;+\\; 104729\\, i \\;+\\; 10007\\, j, $$\n  where $i \\in \\left\\{0,1,2,3\\right\\}$ is the test-case index and $j \\in \\left\\{0,\\dots,N-1\\right\\}$ is the replicate index. This provides independent streams while preserving full reproducibility.\n\nAlgorithmic steps:\n- For each case $i$:\n  - For each replicate $j$:\n    1. Initialize $\\left(t,X,Y\\right) \\leftarrow \\left(0,X_0,Y_0\\right)$; if $X-Y \\ge h$, record $\\tau=0$ and continue to next replicate.\n    2. Loop:\n       - Compute $k_X\\left(t\\right)$ from the pulse rule and the propensities $a_1,\\dots,a_4$.\n       - Compute $a_0 = \\sum_{r=1}^4 a_r$.\n       - Draw $u_1,u_2$ from the uniform distribution $\\text{Uniform}\\left(0,1\\right)$ using the PRNG with seed $s_{i,j}$.\n       - Set $\\Delta t = \\left(1/a_0\\right)\\ln\\left(1/u_1\\right)$ and choose reaction $r$ by cumulative sums versus $u_2 a_0$.\n       - Update $\\left(X,Y\\right)$ and $t \\leftarrow t + \\Delta t$.\n       - If $X-Y \\ge h$, set $\\tau = t$ and stop the loop; if $t \\ge T_{\\max}$, mark non-switching and stop.\n  - Aggregate $M$, $f = M/N$, and $\\bar{\\tau}$ (with $\\bar{\\tau}=-1.0$ if $M=0$).\n  - Round $f$ and $\\bar{\\tau}$ to three decimal places.\n- Output the results as a single line: a list of four pairs $\\left[f,\\bar{\\tau}\\right]$ for cases $0,1,2,3$ with no whitespace.\n\nScientific realism and connection to developmental plasticity:\n- The toggle switch with Hill repression is an established minimal model for bistable gene circuits. Stochasticity in gene expression induces fluctuations that can lead to probabilistic switching. A transient environmental pulse that modifies $k_X\\left(t\\right)$ temporarily shifts the landscape, biasing the system toward the $X$-high phenotype. The computed distribution of first-passage times identifies how pulse intensity and duration modulate polyphenic outcomes.\n- The test suite covers a happy path (moderate pulse promotes frequent switching), a boundary case (weak pulse yields rare switching), a control (no pulse, effectively testing spontaneous switching within the imposed time horizon), and a strong/brief pulse ensuring fast and frequent switching.\n\nNumerical specification for the test suite:\n- Shared parameters: $k_{X,0}=12.0$, $k_Y=12.0$, $d_X=0.2$, $d_Y=0.2$, $K=40$, $n=2$, $h=20$, $X_0=10$, $Y_0=90$, $T_{\\max}=200.0$, $N=64$, $s_0=1357911$. Pulse parameters per case:\n  - Case $0$: $p=3.0$, $T_p=10.0$.\n  - Case $1$: $p=1.5$, $T_p=10.0$.\n  - Case $2$: $p=1.0$, $T_p=0.0$.\n  - Case $3$: $p=4.0$, $T_p=5.0$.\nAll times are in minutes, rate constants are in molecules per minute or per minute as appropriate, and molecule counts are dimensionless integers. The final output is formatted as specified.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef hill_repression(z, K, n):\n    # Returns 1 / (1 + (z/K)^n) as a float\n    return 1.0 / (1.0 + (float(z) / float(K)) ** float(n))\n\ndef gillespie_switch_time(params, rng):\n    # Unpack parameters\n    kX0 = params[\"kX0\"]\n    kY = params[\"kY\"]\n    dX = params[\"dX\"]\n    dY = params[\"dY\"]\n    K = params[\"K\"]\n    n = params[\"n\"]\n    p = params[\"pulse_factor\"]\n    Tp = params[\"pulse_duration\"]\n    h = params[\"h\"]\n    Tmax = params[\"Tmax\"]\n    X = int(params[\"X0\"])\n    Y = int(params[\"Y0\"])\n\n    t = 0.0\n\n    # Immediate check: already in X-dominant state by threshold?\n    if X - Y >= h:\n        return 0.0  # switched at time 0\n\n    # Safety cap on maximum reaction events to avoid runaway loops (should not trigger)\n    max_events = 10_000_000\n    event_count = 0\n\n    while t  Tmax and event_count  max_events:\n        # Compute time-dependent kX(t) due to pulse\n        kXt = (p * kX0) if t  Tp else kX0\n\n        # Compute propensities\n        a1 = kXt * hill_repression(Y, K, n)       # X synthesis\n        a2 = dX * X                                # X degradation\n        a3 = kY * hill_repression(X, K, n)         # Y synthesis\n        a4 = dY * Y                                # Y degradation\n\n        a0 = a1 + a2 + a3 + a4\n\n        # If a0 is zero (should not occur with given params), stop\n        if a0 = 0.0:\n            break\n\n        # Draw two uniforms\n        u1 = rng.random()\n        while u1 = 0.0:\n            u1 = rng.random()\n        u2 = rng.random()\n\n        # Time to next event\n        dt = (1.0 / a0) * np.log(1.0 / u1)\n        t_next = t + dt\n\n        # Determine which reaction fires\n        thresh = u2 * a0\n        # Cumulative sum\n        c = a1\n        if thresh  c:\n            # X synthesis\n            X += 1\n        else:\n            c += a2\n            if thresh  c:\n                # X degradation\n                if X > 0:\n                    X -= 1\n            else:\n                c += a3\n                if thresh  c:\n                    # Y synthesis\n                    Y += 1\n                else:\n                    # Y degradation\n                    if Y > 0:\n                        Y -= 1\n\n        # Advance time\n        t = t_next\n        event_count += 1\n\n        # Check switching condition after state update\n        if X - Y >= h:\n            return t\n\n    # If loop ends without switching before Tmax, return None\n    return None\n\ndef simulate_case(case_params, case_index, N, base_seed):\n    switch_times = []\n    for j in range(N):\n        # Independent, reproducible seed per replicate\n        seed = int(base_seed + 104729 * case_index + 10007 * j)\n        rng = np.random.default_rng(seed)\n        tau = gillespie_switch_time(case_params, rng)\n        if tau is not None:\n            switch_times.append(tau)\n\n    M = len(switch_times)\n    f = M / float(N)\n    if M == 0:\n        mean_tau = -1.0\n    else:\n        mean_tau = float(np.mean(switch_times))\n\n    # Round to three decimals for reporting\n    f_rounded = round(f, 3)\n    mean_tau_rounded = round(mean_tau, 3)\n    return f_rounded, mean_tau_rounded\n\ndef solve():\n    # Shared parameters\n    shared = {\n        \"kX0\": 12.0,        # molecules/min\n        \"kY\": 12.0,         # molecules/min\n        \"dX\": 0.2,          # per min\n        \"dY\": 0.2,          # per min\n        \"K\": 40,            # molecules\n        \"n\": 2,             # Hill coefficient\n        \"h\": 20,            # molecules\n        \"X0\": 10,           # molecules\n        \"Y0\": 90,           # molecules\n        \"Tmax\": 200.0       # minutes\n    }\n\n    # Test suite cases\n    test_cases = [\n        # Case 0: happy path\n        {\n            **shared,\n            \"pulse_factor\": 3.0,\n            \"pulse_duration\": 10.0\n        },\n        # Case 1: boundary/weak pulse\n        {\n            **shared,\n            \"pulse_factor\": 1.5,\n            \"pulse_duration\": 10.0\n        },\n        # Case 2: no pulse control\n        {\n            **shared,\n            \"pulse_factor\": 1.0,\n            \"pulse_duration\": 0.0\n        },\n        # Case 3: strong/brief pulse\n        {\n            **shared,\n            \"pulse_factor\": 4.0,\n            \"pulse_duration\": 5.0\n        }\n    ]\n\n    N = 64\n    base_seed = 1357911\n\n    results = []\n    for i, params in enumerate(test_cases):\n        f, mt = simulate_case(params, i, N, base_seed)\n        results.append((f, mt))\n\n    # Produce exact required format: [[f0,mt0],[f1,mt1],[f2,mt2],[f3,mt3]]\n    out = \"[\" + \",\".join(f\"[{f:.3f},{mt:.3f}]\" for (f, mt) in results) + \"]\"\n    print(out)\n\nif __name__ == \"__main__\":\n    solve()\n```", "id": "2630111"}, {"introduction": "After simulating stochastic dynamics, a critical task for any scientist is to interpret the resulting noisy data and connect it back to underlying models. This final exercise addresses the inverse problem: how do we infer the parameters of a deterministic model from experiments that are inevitably noisy and conducted over finite time? You will explore how the sharp saddle-node bifurcations, or 'fold points', of a bistable system are 'smeared out' in single-cell experiments, leading to broad distributions of switching events. This thought experiment will equip you with a principled framework for analyzing such data, a crucial skill for quantitatively validating and refining genetic circuit designs. [@problem_id:2717466]", "problem": "A synthetic bistable toggle switch is driven by an external inducer with concentration $u$. In a deterministic model, the two stable branches of steady states collide with the unstable saddle at two saddle-node (fold) points $u_c^{\\uparrow}$ and $u_c^{\\downarrow}$, at which the upper and lower branches, respectively, lose stability. In a real single-cell experiment, gene expression dynamics is noisy due to molecular fluctuations, which can be approximated near the fold by a one-dimensional stochastic differential equation (SDE) for a suitable reaction coordinate $x$ of the form $\\mathrm{d}x = f(x,u)\\,\\mathrm{d}t + \\sqrt{2D}\\,\\mathrm{d}W_t$, where $D$ is an effective noise intensity and $W_t$ is a standard Wiener process. An experimenter performs repeated single-cell up-ramps and down-ramps of $u$ at a constant rate $r$, and records, for each cell and each ramp direction, the inducer concentration at which the cell transitions between the two expression states. The resulting histograms of switching concentrations show broad distributions whose locations shift with $r$ and noise level.\n\nFrom first principles of stochastic dynamics and metastability, explain why the apparent up- and down-sweep transition points are broadened and biased relative to $u_c^{\\uparrow}$ and $u_c^{\\downarrow}$ in finite-time, noisy experiments. Then, choose the option that gives a principled and practically feasible procedure to estimate the underlying deterministic fold points $u_c^{\\uparrow}$ and $u_c^{\\downarrow}$ from such noisy, finite-time ramp data.\n\nA. Noise induces premature stochastic switching before the deterministic fold during up-ramps and delayed switching after the deterministic fold during down-ramps, so the apparent transition points become distributions influenced by both $D$ and $r$. To estimate $u_c^{\\uparrow}$ and $u_c^{\\downarrow}$, perform many single-cell ramps at several rates, compute for each direction the empirical distribution of switching concentrations, convert it to an instantaneous hazard of switching as a function of $u$ using survival analysis and the known ramp rate, and fit the resulting rate to a scaling law predicted by saddle-node theory for the noise-activated escape rate. Extrapolate the inferred critical parameter to the joint limit of vanishing noise and vanishing ramp rate to obtain $u_c^{\\uparrow}$ and $u_c^{\\downarrow}$.\n\nB. Because noise averages out over many cells, the average of the median up-sweep and median down-sweep switching concentrations at a sufficiently slow ramp rate is an unbiased estimator of the true deterministic fold points, regardless of noise strength. Therefore, measuring at a single slow rate and averaging the two medians recovers $u_c^{\\uparrow}$ and $u_c^{\\downarrow}$.\n\nC. The apparent fold points sharpen as noise increases because more frequent switching reveals the underlying deterministic threshold. Thus, deliberately increasing noise (for example, by lowering gene copy numbers) and taking the switching concentration at the peak of the histogram at the highest noise level provides the best estimate of $u_c^{\\uparrow}$ and $u_c^{\\downarrow}$.\n\nD. The mean expression versus inducer curve measured at long but finite times under a single slow ramp is sufficient to identify the folds by fitting a deterministic Hill-function model and solving for its saddle-node conditions; noise only increases variance around the mean and does not bias the inferred fold locations from such a fit.\n\nSelect the best option.", "solution": "The problem statement must first be validated for scientific soundness and logical consistency.\n\n**Step 1: Extract Givens**\n- **System**: A synthetic bistable toggle switch.\n- **Control Parameter**: External inducer concentration, $u$.\n- **Deterministic Dynamics**: Two stable steady-state branches and one unstable saddle branch. The stable branches terminate at saddle-node (fold) points, $u_c^{\\uparrow}$ and $u_c^{\\downarrow}$.\n- **Stochastic Dynamics**: Near a fold point, the dynamics of a reaction coordinate $x$ are approximated by the one-dimensional stochastic differential equation (SDE): $\\mathrm{d}x = f(x,u)\\,\\mathrm{d}t + \\sqrt{2D}\\,\\mathrm{d}W_t$. Here, $D$ is the noise intensity and $W_t$ is a standard Wiener process.\n- **Experimental Protocol**: The inducer concentration $u$ is ramped up and down at a constant rate $r$. For many single cells, the value of $u$ at which a transition occurs is recorded.\n- **Observation**: The histograms of switching concentrations are broad distributions, and their locations depend on the ramp rate $r$ and noise level $D$.\n- **Objective**: First, to explain the broadening and biasing of observed switching points relative to the deterministic fold points. Second, to select the best procedure for estimating $u_c^{\\uparrow}$ and $u_c^{\\downarrow}$ from the experimental data.\n\n**Step 2: Validate Using Extracted Givens**\nThe problem is scientifically well-grounded. It describes a canonical problem in systems biology and nonlinear dynamics: parameter inference for a bistable system in the presence of noise and a time-varying control parameter. The model used, a Langevin equation of the form $\\mathrm{d}x = -\\frac{\\partial V}{\\partial x}\\,\\mathrm{d}t + \\sqrt{2D}\\,\\mathrm{d}W_t$, is a standard and appropriate framework for analyzing noise-induced transitions near a bifurcation. The experimental protocol of ramping a control parameter is a common method for characterizing hysteresis. The observed phenomena—broadened and biased switching distributions—are consistent with established theories of stochastic escape and non-equilibrium dynamics (e.g., Kramers' escape theory applied to a time-varying potential). The problem is well-posed, objective, and contains no scientific or logical contradictions. It poses a non-trivial question about deconvolving deterministic properties from noisy, non-equilibrium data.\n\n**Step 3: Verdict and Action**\nThe problem statement is valid. I will proceed with the derivation and evaluation of the options.\n\n**Theoretical Explanation of Broadening and Bias**\n\nThe dynamics of the system can be conceptualized as the motion of a particle in a potential landscape $V(x,u)$, where the deterministic force is given by $f(x,u) = -\\frac{\\partial V}{\\partial x}$. The stable states of the toggle switch correspond to the minima (wells) of this potential. The control parameter $u$ modulates the shape of $V(x,u)$.\n\nConsider an up-ramp, where $u$ increases with time. The system starts in the low-expression state, which corresponds to a potential well. As $u$ approaches the upper fold point $u_c^{\\uparrow}$, this well becomes shallower and the potential barrier $\\Delta V(u)$ separating it from the high-expression state's well decreases. In a purely deterministic system ($D=0$), the system remains in the low state until $u$ reaches exactly $u_c^{\\uparrow}$, at which point the well disappears and the system deterministically transitions to the high state.\n\nIn a stochastic system ($D0$), the noise term $\\sqrt{2D}\\,\\mathrm{d}W_t$ represents random fluctuations. These fluctuations can provide the \"energy\" for the system to escape the potential well by crossing the barrier, even for $u  u_c^{\\uparrow}$. The rate of such an escape event, $k_{escape}$, is highly sensitive to the barrier height $\\Delta V$ and noise intensity $D$, as described by Kramers' theory: $k_{escape} \\propto \\exp(-\\Delta V(u)/D)$.\n\n$1$. **Broadening**: Since escape over the barrier is a probabilistic event, the exact value of $u$ at which a given cell transitions is a random variable. Repeated experiments on a population of single cells will therefore yield a distribution of switching concentrations rather than a single value. This accounts for the observed **broadening** of the transition.\n\n$2$. **Bias**: During a ramp where $u(t) = u_{start} + rt$, the system spends a finite amount of time at each value of $u$. A transition becomes likely when the escape rate $k_{escape}(u)$ becomes sufficiently high. Since $k_{escape}(u)  0$ for any $u$ where a barrier exists (i.e., for $u  u_c^{\\uparrow}$ on an up-ramp), the noise-induced transition will almost surely occur *before* the deterministic fold point is reached. Thus, the mean observed switching concentration $\\langle u_{switch}^{\\uparrow} \\rangle$ will be less than $u_c^{\\uparrow}$. This phenomenon is often called premature switching. The magnitude of this **bias**, $u_c^{\\uparrow} - \\langle u_{switch}^{\\uparrow} \\rangle$, depends on both $r$ and $D$. A slower ramp (smaller $r$) allows more time for escape at each $u$, leading to an earlier switch and a larger bias. A larger noise level (larger $D$) also makes escape easier, increasing the bias. An analogous argument holds for the down-ramp: the mean switching concentration $\\langle u_{switch}^{\\downarrow} \\rangle$ is biased such that $\\langle u_{switch}^{\\downarrow} \\rangle  u_c^{\\downarrow}$.\n\nIn summary, noisy, finite-time ramps inherently lead to broadened distributions of switching concentrations that are systematically biased away from the true deterministic fold points.\n\n**Evaluation of Options**\n\n**A. Noise induces premature stochastic switching before the deterministic fold during up-ramps and delayed switching after the deterministic fold during down-ramps, so the apparent transition points become distributions influenced by both $D$ and $r$. To estimate $u_c^{\\uparrow}$ and $u_c^{\\downarrow}$, perform many single-cell ramps at several rates, compute for each direction the empirical distribution of switching concentrations, convert it to an instantaneous hazard of switching as a function of $u$ using survival analysis and the known ramp rate, and fit the resulting rate to a scaling law predicted by saddle-node theory for the noise-activated escape rate. Extrapolate the inferred critical parameter to the joint limit of vanishing noise and vanishing ramp rate to obtain $u_c^{\\uparrow}$ and $u_c^{\\downarrow}$.**\n\nThis option presents a comprehensive and theoretically sound procedure.\n- The initial qualitative description is correct. \"Premature switching\" ($u  u_c^{\\uparrow}$) is accurate for up-ramps. \"Delayed switching after the deterministic fold\" for down-ramps might refer to bifurcation lag or overshoot ($u  u_c^{\\downarrow}$ for fast ramps), which is a valid rate-dependent phenomenon. Regardless of the ambiguity, the core claim that switching points are distributed and biased is correct.\n- The proposed method is correct. Measuring switching distributions at multiple ramp rates $r$ is necessary to characterize the rate dependence.\n- Converting the switching distribution $p(u)$ and survival function $S(u)$ into an instantaneous hazard rate $h(u) = p(u)/S(u)$ is the correct way to estimate the underlying transition rate.\n- Fitting this hazard rate to a scaling law is the key step. Near a saddle-node bifurcation, theory predicts the potential barrier scales as $\\Delta V \\propto |u_c - u|^{3/2}$. This leads to a specific functional form for the escape rate, $k(u)$, which can be fit to the data to extract an estimate of $u_c$.\n- Extrapolation of the fitted $u_c(r, D)$ to the limit $(r, D) \\to (0, 0)$ is the most rigorous method to eliminate all dynamic and stochastic biases and recover the true, static, deterministic fold points.\n\nVerdict: **Correct**.\n\n**B. Because noise averages out over many cells, the average of the median up-sweep and median down-sweep switching concentrations at a sufficiently slow ramp rate is an unbiased estimator of the true deterministic fold points, regardless of noise strength. Therefore, measuring at a single slow rate and averaging the two medians recovers $u_c^{\\uparrow}$ and $u_c^{\\downarrow}$.**\n\nThis option is based on several fundamental misconceptions.\n- Noise does not \"average out\" in nonlinear systems to recover deterministic behavior. The expectation of a function of a random variable is not the function of the expectation, i.e., $\\langle g(x) \\rangle \\neq g(\\langle x \\rangle)$. The average behavior of a stochastic system is itself influenced by noise.\n- A \"sufficiently slow ramp rate\" does not remove bias; it typically increases it by allowing more time for premature stochastic escape. The median switching point at a slow rate will be far from the fold point.\n- The procedure of averaging the up-sweep and down-sweep medians has no theoretical justification for estimating the fold points $u_c^{\\uparrow}$ and $u_c^{\\downarrow}$.\n\nVerdict: **Incorrect**.\n\n**C. The apparent fold points sharpen as noise increases because more frequent switching reveals the underlying deterministic threshold. Thus, deliberately increasing noise (for example, by lowering gene copy numbers) and taking the switching concentration at the peak of the histogram at the highest noise level provides the best estimate of $u_c^{\\uparrow}$ and $u_c^{\\downarrow}$.**\n\nThis option's premise and conclusion are the opposite of the correct physical picture.\n- Increasing noise $D$ *broadens* the distribution of switching times, as the process becomes more random. The switching points do not sharpen.\n- To estimate the *deterministic* threshold, one must approach the deterministic limit, which corresponds to $D \\to 0$, not $D \\to \\infty$. Increasing noise moves the system further from this limit, making estimation of deterministic parameters more difficult and less accurate.\n\nVerdict: **Incorrect**.\n\n**D. The mean expression versus inducer curve measured at long but finite times under a single slow ramp is sufficient to identify the folds by fitting a deterministic Hill-function model and solving for its saddle-node conditions; noise only increases variance around the mean and does not bias the inferred fold locations from such a fit.**\n\nThis option incorrectly conflates the average of the stochastic process with the deterministic solution.\n- The mean expression curve from a population of stochastically switching cells will show a smooth transition, not a sharp jump or a vertical tangent at the fold points. The hysteresis loop is effectively \"rounded\" by averaging.\n- Fitting a deterministic model (like one based on Hill functions) to this averaged, non-equilibrium data will yield effective parameters that are themselves dependent on the noise level $D$ and ramp rate $r$, not the true underlying deterministic parameters.\n- The statement that noise does not bias the inferred fold locations is false. The bias in switching times at the single-cell level directly translates to a biased (smoothed) average curve at the population level.\n\nVerdict: **Incorrect**.", "answer": "$$\\boxed{A}$$", "id": "2717466"}]}