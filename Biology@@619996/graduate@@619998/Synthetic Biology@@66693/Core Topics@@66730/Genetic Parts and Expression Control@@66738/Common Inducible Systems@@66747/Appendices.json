{"hands_on_practices": [{"introduction": "At the heart of any inducible system lies the physical interaction between a regulatory protein, its specific DNA binding site, and a small-molecule inducer. This first practice invites you to quantify this core relationship using a simple but powerful biophysical model. By applying principles of mass-action kinetics and equilibrium binding, you will calculate the precise concentration of an inducer required to achieve a target level of gene expression, providing a foundational understanding of how molecular affinities ($K_d$) dictate the response of a genetic switch [@problem_id:2722523].", "problem": "A commonly used repressor in tetracycline-inducible systems is the tetracycline repressor (TetR), which binds the tet operator (tetO) on deoxyribonucleic acid (DNA) and blocks transcription. The small-molecule inducer anhydrotetracycline (aTc) binds TetR and abolishes its ability to bind DNA. Consider a TetR variant that binds tetO with a dissociation constant $K_{d,\\mathrm{DNA}} = 0.1\\ \\mathrm{nM}$ (defined for the active TetR dimer binding a single tetO site), and binds anhydrotetracycline with a dissociation constant $K_{d,\\mathrm{aTc}} = 10\\ \\mathrm{nM}$ (defined for a $1{:}1$ TetR dimerâ€“anhydrotetracycline complex). Assume the following:\n- TetR is active as a dimer, and all concentrations of TetR refer to the dimer.\n- Binding of anhydrotetracycline to TetR and binding of TetR to tetO are mutually exclusive; anhydrotetracycline-bound TetR does not bind DNA.\n- The total concentration of TetR dimers is $T_{\\mathrm{tot}} = 10\\ \\mathrm{nM}$.\n- The concentration of tetO sites is sufficiently low that binding to DNA does not appreciably deplete free TetR, and the concentration of anhydrotetracycline added is sufficiently high relative to TetR that its free concentration equals its total concentration at steady state.\n- All interactions are at steady state and follow mass-action binding without cooperativity.\n\nDefine the derepression fraction as the fraction of tetO sites unbound by TetR. Determine the anhydrotetracycline concentration required to achieve $90\\%$ derepression at steady state. Express your final answer in $\\mathrm{\\mu M}$ and round your answer to three significant figures.", "solution": "The problem presented is a standard equilibrium problem from biophysical chemistry, applied to a synthetic gene circuit. It is scientifically grounded, well-posed, and contains sufficient information for a unique solution. Therefore, we proceed.\n\nThe task is to determine the concentration of the inducer, anhydrotetracycline ($[A]$), required to achieve a $90\\%$ derepression of the target operator sites ($tetO$). We are given the relevant parameters for the system. Let us formalize the interactions.\n\nLet $[R]$ denote the concentration of free, active tetracycline repressor dimers (TetR), which are capable of binding to DNA.\nLet $[O]$ be the concentration of free $tetO$ sites and $[RO]$ be the concentration of TetR-tetO complexes.\nLet $[RA]$ be the concentration of TetR-aTc complexes.\nThe total concentration of TetR dimers is $T_{\\mathrm{tot}}$.\nThe concentration of aTc is $[A]$. The problem states that the free concentration of aTc is equal to its total added concentration.\n\nThe system is described by two main equilibria:\n$1$. The binding of TetR to the $tetO$ site:\n$$R + O \\rightleftharpoons RO$$\nThe dissociation constant for this reaction is given as $K_{d,\\mathrm{DNA}}$:\n$$K_{d,\\mathrm{DNA}} = \\frac{[R][O]}{[RO]} = 0.1\\ \\mathrm{nM}$$\n\n$2$. The binding of aTc to the TetR dimer:\n$$R + A \\rightleftharpoons RA$$\nThe dissociation constant for this reaction is given as $K_{d,\\mathrm{aTc}}$:\n$$K_{d,\\mathrm{aTc}} = \\frac{[R][A]}{[RA]} = 10\\ \\mathrm{nM}$$\n\nThe problem states that binding of aTc to TetR and binding of TetR to $tetO$ are mutually exclusive. This is consistent with our formulation, where only the free repressor $[R]$ can participate in either binding event.\n\nThe derepression fraction is defined as the fraction of $tetO$ sites that are not bound by TetR. Let $O_{\\mathrm{tot}}$ be the total concentration of $tetO$ sites, so $O_{\\mathrm{tot}} = [O] + [RO]$. The derepression fraction, $f_{\\mathrm{unbound}}$, is:\n$$f_{\\mathrm{unbound}} = \\frac{[O]}{O_{\\mathrm{tot}}} = \\frac{[O]}{[O] + [RO]}$$\nWe are required to find the concentration $[A]$ for which $f_{\\mathrm{unbound}} = 0.90$.\nSetting the derepression fraction to $0.90$:\n$$0.90 = \\frac{[O]}{[O] + [RO]}$$\n$$0.90([O] + [RO]) = [O]$$\n$$0.90[O] + 0.90[RO] = [O]$$\n$$0.90[RO] = (1 - 0.90)[O] = 0.10[O]$$\nThis gives us a ratio for the concentrations of bound and unbound operator sites:\n$$\\frac{[RO]}{[O]} = \\frac{0.10}{0.90} = \\frac{1}{9}$$\nNow, we can use the equilibrium expression for DNA binding to determine the required concentration of free active repressor, $[R]$.\n$$[R] = K_{d,\\mathrm{DNA}} \\frac{[RO]}{[O]}$$\nSubstituting the ratio we just derived:\n$$[R] = K_{d,\\mathrm{DNA}} \\left(\\frac{1}{9}\\right)$$\nThis is the concentration of active repressor, $[R]$, that must be maintained in the system to achieve the target $90\\%$ derepression.\n\nNext, we must relate this required concentration of $[R]$ to the total amount of repressor, $T_{\\mathrm{tot}}$, and the inducer concentration, $[A]$. The problem states that binding to DNA does not appreciably deplete the free TetR pool. This is a simplifying assumption meaning that the concentration of the $[RO]$ complex is negligible compared to the total TetR concentration. The mass balance for the total TetR concentration, $T_{\\mathrm{tot}}$, is therefore:\n$$T_{\\mathrm{tot}} = [R] + [RA]$$\nFrom the aTc binding equilibrium, we can express $[RA]$ in terms of $[R]$ and $[A]$:\n$$[RA] = \\frac{[R][A]}{K_{d,\\mathrm{aTc}}}$$\nSubstituting this into the mass balance equation:\n$$T_{\\mathrm{tot}} = [R] + \\frac{[R][A]}{K_{d,\\mathrm{aTc}}} = [R] \\left(1 + \\frac{[A]}{K_{d,\\mathrm{aTc}}}\\right)$$\nWe can now equate the two expressions for $[R]$ or, more directly, substitute the required concentration $[R] = \\frac{K_{d,\\mathrm{DNA}}}{9}$ into the mass balance equation:\n$$T_{\\mathrm{tot}} = \\frac{K_{d,\\mathrm{DNA}}}{9} \\left(1 + \\frac{[A]}{K_{d,\\mathrm{aTc}}}\\right)$$\nOur goal is to solve for $[A]$. Rearranging the equation:\n$$\\frac{9 T_{\\mathrm{tot}}}{K_{d,\\mathrm{DNA}}} = 1 + \\frac{[A]}{K_{d,\\mathrm{aTc}}}$$\n$$\\frac{[A]}{K_{d,\\mathrm{aTc}}} = \\frac{9 T_{\\mathrm{tot}}}{K_{d,\\mathrm{DNA}}} - 1$$\n$$[A] = K_{d,\\mathrm{aTc}} \\left(\\frac{9 T_{\\mathrm{tot}}}{K_{d,\\mathrm{DNA}}} - 1\\right)$$\nNow, we substitute the given numerical values: $T_{\\mathrm{tot}} = 10\\ \\mathrm{nM}$, $K_{d,\\mathrm{DNA}} = 0.1\\ \\mathrm{nM}$, and $K_{d,\\mathrm{aTc}} = 10\\ \\mathrm{nM}$.\n$$[A] = (10\\ \\mathrm{nM}) \\left(\\frac{9 \\times (10\\ \\mathrm{nM})}{0.1\\ \\mathrm{nM}} - 1\\right)$$\n$$[A] = 10 \\left(\\frac{90}{0.1} - 1\\right)\\ \\mathrm{nM}$$\n$$[A] = 10 (900 - 1)\\ \\mathrm{nM}$$\n$$[A] = 10 (899)\\ \\mathrm{nM} = 8990\\ \\mathrm{nM}$$\nThe problem requires the final answer to be expressed in micromolar ($\\mathrm{\\mu M}$) and rounded to three significant figures. We perform the unit conversion:\n$$1\\ \\mathrm{\\mu M} = 1000\\ \\mathrm{nM}$$\n$$[A] = 8990\\ \\mathrm{nM} \\times \\frac{1\\ \\mathrm{\\mu M}}{1000\\ \\mathrm{nM}} = 8.99\\ \\mathrm{\\mu M}$$\nThe result $8.99$ already has three significant figures, so no further rounding is necessary. This is the concentration of anhydrotetracycline required to achieve $90\\%$ derepression.", "answer": "$$\n\\boxed{8.99}\n$$", "id": "2722523"}, {"introduction": "Moving from theoretical models to experimental reality, this practice addresses the crucial task of characterizing an inducible system's performance from laboratory data. You will learn to fit the versatile Hill function to a set of expression measurements, a standard procedure in quantitative biology. This hands-on coding exercise will guide you in extracting essential system parameters like the half-maximal effective concentration ($EC_{50}$), the Hill coefficient ($n$), and the fold-change, complete with statistical confidence intervals, thereby transforming raw data into meaningful biological insights [@problem_id:2722510].", "problem": "A synthetic biology group measured steady-state gene expression driven by a lactose inducible promoter (Lac system) under different concentrations of the small-molecule inducer Isopropyl $\\beta$-D-$1$-thiogalactopyranoside (IPTG). You are asked to implement a program that, for each provided dataset, derives and fits a mechanistically grounded Hill-type input-output relation from first principles and reports key pharmacodynamic-like parameters with confidence intervals. The problem must be solved by deriving the model from equilibrium binding and applying nonlinear regression with asymptotic inference.\n\nFundamental principles to use:\n- Central Dogma of Molecular Biology: DNA is transcribed to RNA and translated to protein, with steady-state protein levels proportional to effective promoter activity under fixed growth conditions.\n- Law of Mass Action at equilibrium for ligand binding: For a ligand concentration $I$ binding to a regulator with dissociation constant $K$, the fractional occupancy is a function of $I$ and $K$. For $n$ independent and identical binding events, the occupancy follows a Hill-type dependence on $I$.\n- Nonlinear least squares as maximum likelihood under homoscedastic Gaussian noise: Given observations $\\{(I_i, y_i)\\}_{i=1}^N$, parameter estimates minimize the sum of squared residuals.\n- Asymptotic normality of nonlinear least squares estimators: Near the optimum, parameter estimates are approximately normal with covariance obtained from the Jacobian of the model at the optimum. The delta method propagates uncertainty to smooth functions of parameters.\n\nYour tasks:\n- For each dataset, starting from the above principles, derive a Hill-type regulatory function for mean expression as a function of inducer concentration $I$ that contains basal activity, dynamic range, an effective concentration for half-maximal response (the $50\\%$ effective concentration (EC$50$)), and a Hill coefficient. Do not assume any particular numeric parameter values a priori.\n- Fit the derived function to the data by nonlinear regression with positivity constraints appropriate for physical quantities.\n- Compute two-sided $0.95$ confidence intervals for EC$50$ (in micromolar) and the Hill coefficient using the asymptotic covariance of the nonlinear least squares estimator and the Student-$t$ quantile with degrees of freedom $N - p$, where $p$ is the number of fitted parameters.\n- Define fold-change as the ratio of maximal mean expression to basal mean expression. Compute its estimate and a two-sided $0.95$ confidence interval using the delta method applied to the parameter covariance.\n- Express EC$50$ in micromolar and report all numerical outputs as floating-point values rounded to $4$ decimal places.\n- For angles, if any trigonometric functions are used internally, measure angles in radians. There is no requirement to report any angles in this problem.\n- There are no percentages in the output; if a fraction is needed, it must be reported as a decimal.\n\nData to fit:\n- Test case A (Lac-like strong dynamic range; IPTG in micromolar, expression in arbitrary units): concentrations $[0, 0.3, 1, 3, 10, 30, 100, 300, 1000]$; mean expressions $[100.5, 101.0, 109.1, 176.0, 548.0, 911.5, 990.0, 998.5, 999.7]$.\n- Test case B (near-linear response; IPTG in micromolar): concentrations $[0, 1, 3, 10, 30, 100, 300, 1000]$; mean expressions $[49.5, 53.4, 58.0, 75.8, 105.2, 151.0, 179.9, 193.1]$.\n- Test case C (high cooperativity; IPTG in micromolar): concentrations $[0, 0.1, 1, 3, 10, 30, 100, 300, 1000]$; mean expressions $[20.3, 20.1, 20.0, 20.2, 20.4, 33.0, 261.0, 484.2, 499.0]$.\n\nConstraints and definitions:\n- Your derived model should include $p = 4$ free parameters: basal expression $b$, dynamic range $a$ (amplitude), EC$50$ denoted $K$, and Hill coefficient $n$, subject to $b \\ge 0$, $a \\ge 0$, $K > 0$, $n > 0$.\n- Confidence intervals must be computed using the asymptotic covariance of the fitted parameters, the two-sided Student-$t$ critical value at level $\\alpha = 0.05$ with degrees of freedom $N - p$, and the delta method for fold-change defined as $(b + a)/b$.\n- All computations must be performed in terms of the provided numerical data and the derived model; no external data may be used.\n\nRequired final output format:\n- For each test case in the order A, B, C, output a list of $9$ floating-point numbers in the following order: $[EC50, EC50_{low}, EC50_{high}, n, n_{low}, n_{high}, fold, fold_{low}, fold_{high}]$, where the subscripts denote the bounds of the two-sided $0.95$ confidence interval.\n- Your program should produce a single line of output containing a list of the three case results in order, with each case result as its own list. There must be no spaces in the output. For example: \"[[caseA_9_numbers],[caseB_9_numbers],[caseC_9_numbers]]\".\n- Round all printed floating-point numbers to $4$ decimal places.\n\nTest suite summary (units: EC$50$ in micromolar, expression in arbitrary fluorescence units):\n- Case A: $I = [0, 0.3, 1, 3, 10, 30, 100, 300, 1000]$, $y = [100.5, 101.0, 109.1, 176.0, 548.0, 911.5, 990.0, 998.5, 999.7]$.\n- Case B: $I = [0, 1, 3, 10, 30, 100, 300, 1000]$, $y = [49.5, 53.4, 58.0, 75.8, 105.2, 151.0, 179.9, 193.1]$.\n- Case C: $I = [0, 0.1, 1, 3, 10, 30, 100, 300, 1000]$, $y = [20.3, 20.1, 20.0, 20.2, 20.4, 33.0, 261.0, 484.2, 499.0]$.", "solution": "The problem requires the derivation and application of a biophysical model to describe gene expression from an inducible promoter, followed by statistical analysis to determine key parameters and their confidence intervals. The problem is scientifically valid and well-posed.\n\n### Step 1: Model Derivation\nThe system described is a gene under the control of a lactose-inducible promoter. The expression of the gene is regulated by the concentration of an inducer molecule, IPTG, denoted by $I$. The relationship between the inducer concentration $I$ and the steady-state protein expression level $y$ can be derived from first principles of molecular binding and gene regulation.\n\n1.  **Basal and Maximal Expression:** In the absence of the inducer ($I=0$), there is a baseline or \"leaky\" level of expression, which we denote as the basal expression, $b$. As the inducer concentration becomes very large ($I \\to \\infty$), the promoter becomes fully active, leading to a maximal expression level. The difference between the maximal and basal expression is the dynamic range, which we denote as $a$. Therefore, the total expression is bounded between $b$ and $b+a$.\n\n2.  **Inducer-Regulator Interaction:** The inducer $I$ functions by inactivating a repressor protein, thereby allowing transcription. The fraction of promoters that are active is determined by the fraction of repressor molecules that are bound by the inducer. This binding process is often cooperative, meaning that the binding of one inducer molecule to a repressor multimer influences the binding of subsequent molecules.\n\n3.  **The Hill Function:** A standard phenomenological model for such cooperative binding processes is the Hill function. The fraction of activated promoters, $\\theta(I)$, can be modeled as a function of the inducer concentration $I$:\n    $$ \\theta(I) = \\frac{I^n}{K^n + I^n} $$\n    Here, $K$ is the effective concentration for half-maximal activation (EC$50$), defined as the inducer concentration at which the response is halfway between the minimum and maximum. The parameter $n$ is the Hill coefficient, which quantifies the steepness or cooperativity of the response. A value of $n>1$ indicates positive cooperativity, $n<1$ indicates negative cooperativity, and $n=1$ describes a non-cooperative (Michaelis-Menten) process.\n\n4.  **Full Input-Output Function:** Combining these components, the total expression level $y(I)$ is the sum of the basal expression and the inducible part, which is the dynamic range $a$ scaled by the activation fraction $\\theta(I)$. This gives the four-parameter Hill model:\n    $$ y(I; b, a, K, n) = b + a \\frac{I^n}{K^n + I^n} $$\n    The parameters ($(p=4)$) have clear physical interpretations and are subject to constraints based on these interpretations: $b \\ge 0$ (basal expression cannot be negative), $a \\ge 0$ (induction increases expression), $K > 0$ (concentration must be positive), and $n > 0$ (for a monotonic response).\n\n### Step 2: Parameter Estimation\nThe optimal set of parameters $\\hat{\\mathbf{p}} = (\\hat{b}, \\hat{a}, \\hat{K}, \\hat{n})$ is found by fitting the model function $y(I; \\mathbf{p})$ to the provided experimental data $\\{(I_i, y_i)\\}_{i=1}^N$. Under the assumption of independent and identically distributed Gaussian noise on the measurements, the maximum likelihood estimate for $\\mathbf{p}$ is equivalent to the one that minimizes the Sum of Squared Residuals (SSR):\n$$ \\hat{\\mathbf{p}} = \\arg\\min_{\\mathbf{p}} \\sum_{i=1}^N \\left(y_i - y(I_i; \\mathbf{p})\\right)^2 $$\nThis is a nonlinear least-squares (NLS) regression problem. We will employ the Levenberg-Marquardt algorithm, as implemented in `scipy.optimize.curve_fit`, to find the optimal parameter values $\\hat{\\mathbf{p}}$, subject to the positivity constraints.\n\n### Step 3: Uncertainty Quantification\nThe uncertainty in the estimated parameters is calculated using the asymptotic properties of NLS estimators.\n\n1.  **Parameter Confidence Intervals:** For a sufficiently large number of data points, the sampling distribution of the estimated parameters $\\hat{\\mathbf{p}}$ is approximately a multivariate normal distribution centered at the true parameter values, with a covariance matrix $\\mathbf{C}_{\\mathbf{p}}$. This matrix is estimated as:\n    $$ \\mathbf{C}_{\\mathbf{p}} \\approx s^2 (\\mathbf{J}^T \\mathbf{J})^{-1} $$\n    where $\\mathbf{J}$ is the Jacobian matrix of the model residuals with respect to the parameters, evaluated at $\\hat{\\mathbf{p}}$, and $s^2$ is the estimated variance of the measurement error, with $N-p$ being the degrees of freedom:\n    $$ s^2 = \\frac{SSR(\\hat{\\mathbf{p}})}{N-p} $$\n    The standard error for each parameter $\\hat{p}_j$ is the square root of the corresponding diagonal element of $\\mathbf{C}_{\\mathbf{p}}$:\n    $$ \\text{se}(\\hat{p}_j) = \\sqrt{[\\mathbf{C}_{\\mathbf{p}}]_{jj}} $$\n    The two-sided $100(1-\\alpha)\\%$ confidence interval for a parameter $p_j$ is then computed as:\n    $$ \\hat{p}_j \\pm t_{1-\\alpha/2, N-p} \\cdot \\text{se}(\\hat{p}_j) $$\n    where $t_{1-\\alpha/2, N-p}$ is the critical value from the Student's t-distribution for a significance level of $\\alpha = 0.05$ and $N-p$ degrees of freedom. We will compute these intervals for the EC$50$ ($K$) and the Hill coefficient ($n$).\n\n2.  **Fold-Change Confidence Interval:** The fold-change ($F$) is defined as the ratio of maximal to basal expression:\n    $$ F = g(b, a) = \\frac{b+a}{b} = 1 + \\frac{a}{b} $$\n    Since $F$ is a function of the fitted parameters $b$ and $a$, its uncertainty depends on their uncertainties and covariance. The delta method is used to approximate the variance of $\\hat{F} = g(\\hat{b}, \\hat{a})$:\n    $$ \\sigma^2_F \\approx \\nabla g^T \\mathbf{C}_{\\mathbf{p}} \\nabla g $$\n    The gradient of $g$ with respect to the parameter vector $\\mathbf{p}=(b, a, K, n)$ is:\n    $$ \\nabla g = \\left( \\frac{\\partial g}{\\partial b}, \\frac{\\partial g}{\\partial a}, \\frac{\\partial g}{\\partial K}, \\frac{\\partial g}{\\partial n} \\right)^T = \\left( -\\frac{a}{b^2}, \\frac{1}{b}, 0, 0 \\right)^T $$\n    The standard error of the fold-change is $\\text{se}(\\hat{F}) = \\sqrt{\\sigma^2_F}$. The confidence interval for $F$ is constructed similarly:\n    $$ \\hat{F} \\pm t_{1-\\alpha/2, N-p} \\cdot \\text{se}(\\hat{F}) $$\n\n### Step 4: Implementation Strategy\nFor each dataset, we will:\n1.  Establish initial guesses for the parameters $(b_0, a_0, K_0, n_0)$ by inspecting the data: $b_0$ from the minimum observed expression, $a_0$ from the total observed range, and $K_0$ from the inducer concentration corresponding to the midpoint of the expression range. A default $n_0=2.0$ is used.\n2.  Perform the NLS fit using `scipy.optimize.curve_fit`, providing the model, data, initial guesses, and parameter bounds $([0, 0, 10^{-9}, 10^{-9}], [\\infty, \\infty, \\infty, \\infty])$.\n3.  From the returned optimal parameters and covariance matrix, compute the point estimates and confidence intervals for $K$, $n$, and the fold-change $F$ as detailed above.\n4.  Finally, all results will be formatted and printed according to the specified structure.", "answer": "```python\nimport numpy as np\nfrom scipy.optimize import curve_fit\nfrom scipy.stats import t\n\ndef solve():\n    \"\"\"\n    Derives and fits a Hill-type model for inducible gene expression, reporting\n    key parameters (EC50, Hill coefficient, fold-change) with confidence intervals.\n    \"\"\"\n\n    def hill_model(I, b, a, K, n):\n        \"\"\"\n        Calculates gene expression based on the Hill equation.\n        y(I) = b + a * I^n / (K^n + I^n)\n        \n        Args:\n            I (np.ndarray): Inducer concentrations.\n            b (float): Basal expression level.\n            a (float): Dynamic range (amplitude).\n            K (float): EC50, concentration for half-maximal response.\n            n (float): Hill coefficient.\n        \n        Returns:\n            np.ndarray: Predicted expression levels.\n        \"\"\"\n        # np.power is used for element-wise exponentiation on the array I.\n        # It is robust to I=0 when n>0, which is enforced by bounds.\n        # errstate context manager prevents warnings from flooding the console during\n        # optimization, e.g., if transient non-physical parameters are tested.\n        with np.errstate(all='ignore'):\n            power_I = np.power(I, n)\n            power_K = np.power(K, n)\n            response_fraction = power_I / (power_K + power_I)\n        \n        # Handle potential NaNs, though unlikely with given bounds.\n        response_fraction[np.isnan(response_fraction)] = 0.0\n        \n        return b + a * response_fraction\n\n    test_cases = [\n        # Case A: Strong dynamic range\n        {'I': np.array([0, 0.3, 1, 3, 10, 30, 100, 300, 1000]),\n         'y': np.array([100.5, 101.0, 109.1, 176.0, 548.0, 911.5, 990.0, 998.5, 999.7])},\n        # Case B: Near-linear response\n        {'I': np.array([0, 1, 3, 10, 30, 100, 300, 1000]),\n         'y': np.array([49.5, 53.4, 58.0, 75.8, 105.2, 151.0, 179.9, 193.1])},\n        # Case C: High cooperativity\n        {'I': np.array([0, 0.1, 1, 3, 10, 30, 100, 300, 1000]),\n         'y': np.array([20.3, 20.1, 20.0, 20.2, 20.4, 33.0, 261.0, 484.2, 499.0])}\n    ]\n\n    all_case_results = []\n\n    for case in test_cases:\n        I_data, y_data = case['I'], case['y']\n        N = len(I_data)\n        p = 4  # Number of parameters: b, a, K, n\n\n        # Generate robust initial parameter guesses (p0)\n        b0 = np.min(y_data)\n        a0 = np.max(y_data) - b0\n        if a0 <= 1e-9: a0 = 1.0  # Avoid a0=0 for ill-defined K0 guess\n\n        K0_val = b0 + a0 / 2.0\n        idx = np.argmin(np.abs(y_data - K0_val))\n        K0 = I_data[idx]\n        if K0 < 1e-9:  # Fallback if K0 is zero\n            non_zero_I = I_data[I_data > 0]\n            K0 = np.median(non_zero_I) if len(non_zero_I) > 0 else 1.0\n        \n        n0 = 2.0  # A common starting point for cooperativity\n        p0 = [b0, a0, K0, n0]\n\n        bounds = ([0.0, 0.0, 1e-9, 1e-9], [np.inf, np.inf, np.inf, np.inf])\n\n        # Perform nonlinear least squares fitting\n        # If sigma is not provided, curve_fit estimates variance from residuals,\n        # which is the desired behavior for this problem.\n        popt, pcov = curve_fit(hill_model, I_data, y_data, p0=p0, bounds=bounds)\n        b, a, K, n = popt\n\n        # Standard errors from the diagonal of the covariance matrix\n        perr = np.sqrt(np.diag(pcov))\n\n        # Student's t-critical value for 95% CI\n        alpha = 0.05\n        dof = N - p\n        t_crit = t.ppf(1 - alpha / 2, df=dof)\n\n        # Confidence intervals for EC50 (K) and Hill coefficient (n)\n        K_se, n_se = perr[2], perr[3]\n        K_low, K_high = K - t_crit * K_se, K + t_crit * K_se\n        n_low, n_high = n - t_crit * n_se, n + t_crit * n_se\n\n        # Fold-change and its confidence interval via the delta method\n        if b < 1e-9:  # Handle case where basal expression is near zero\n            fold_change, fold_low, fold_high = np.inf, np.inf, np.inf\n        else:\n            fold_change = (b + a) / b\n            # Gradient of fold-change function g(b,a) = 1 + a/b\n            grad_g = np.array([-a / b**2, 1 / b, 0, 0])\n            # Variance of fold-change\n            var_fold_change = grad_g.T @ pcov @ grad_g\n            se_fold_change = np.sqrt(var_fold_change)\n            # CI for fold-change\n            fold_low = fold_change - t_crit * se_fold_change\n            fold_high = fold_change + t_crit * se_fold_change\n        \n        case_results = [K, K_low, K_high, n, n_low, n_high, fold_change, fold_low, fold_high]\n        \n        formatted_results = [f\"{val:.4f}\" for val in case_results]\n        all_case_results.append(f\"[{','.join(formatted_results)}]\")\n\n    print(f\"[{','.join(all_case_results)}]\")\n\nsolve()\n```", "id": "2722510"}, {"introduction": "This final practice elevates our analysis from static input-output functions to the dynamic, systems-level behavior that emerges from feedback loops within a circuit. We will investigate the arabinose system, where a positive feedback loop in inducer transport can create bistabilityâ€”a state where the system can act like a toggle switch, exhibiting memory. By implementing and analyzing a model based on ordinary differential equations (ODEs), you will explore the conditions that give rise to such complex, non-linear dynamics, a key concept for engineering sophisticated cellular decision-making circuits [@problem_id:2722504].", "problem": "Consider inducible control of the arabinose promoter $P_{BAD}$ mediated by AraC in a bacterial cell. L-arabinose is transported into the cytoplasm primarily by two systems: AraE (a low-affinity uniporter) and AraFGH (a high-affinity adenosine triphosphate (ATP)-binding cassette transporter). In many engineered systems, both transporter activities effectively increase the net inward flux of arabinose in proportion to transporter abundance. The central dogma of molecular biology (deoxyribonucleic acid to ribonucleic acid to protein) and basic enzyme and transporter kinetics imply the following modeling principles: (i) transcription-translation produces transporters with a rate that depends on promoter activity, (ii) promoter activity increases with internal arabinose via AraC-mediated activation and saturates cooperatively, (iii) internal arabinose increases via transporter-mediated uptake that saturates with external arabinose, and (iv) proteins and small molecules are removed by dilution and first-order loss. These well-tested principles motivate a reduced two-dimensional ordinary differential equation model with positive feedback between $P_{BAD}$ activity and arabinose uptake.\n\nYour task is to implement a program that (a) formalizes this model, (b) computes steady states for specified parameter sets, and (c) determines the number of asymptotically stable steady states for each case. The goal is to algorithmically assess whether the arabinose transport dynamics can produce bistability for given parameters.\n\nModel to implement. Let $A$ denote the internal arabinose concentration and $T$ denote the lumped transporter abundance. Let the external arabinose concentration be $A_{ext}$, which is treated as a constant parameter. Define the Hill activation function for $P_{BAD}$ by $H(A;n,K)=\\dfrac{A^n}{K^n + A^n}$, where $n$ is the Hill coefficient and $K$ is the activation half-saturation constant. Define the Michaelis-Menten-like uptake factor in terms of external arabinose by $U(A_{ext};V_{max},K_m)=V_{max}\\dfrac{A_{ext}}{K_m + A_{ext}}$. Using these, the model is\n$$\n\\frac{dA}{dt} \\;=\\; U(A_{ext};V_{max},K_m)\\,T \\;-\\; k_{loss}\\,A\n$$\n$$\n\\frac{dT}{dt} \\;=\\; k_{basal} \\;+\\; k_{act}\\,H(A;n,K) \\;-\\; k_{deg}\\,T\n$$\nwith parameters $k_{basal}$ (basal expression rate), $k_{act}$ (maximal inducible expression increment), $k_{deg}$ (first-order transporter removal rate), $k_{loss}$ (net first-order loss rate for internal arabinose, combining efflux and dilution), $V_{max}$ (uptake capacity per transporter), $K_m$ (external arabinose half-saturation), $n$ (Hill coefficient), $K$ (internal half-saturation for activation), and $A_{ext}$ (external arabinose level). Positive feedback arises because $A$ activates $T$ production, and $T$ increases $A$ influx.\n\nFor a steady state $(A^\\*,T^\\*)$, you must solve\n$$\n0 \\;=\\; U(A_{ext};V_{max},K_m)\\,T^\\* \\;-\\; k_{loss}\\,A^\\* \\quad 0 \\;=\\; k_{basal} \\;+\\; k_{act}\\,H(A^\\*;n,K) \\;-\\; k_{deg}\\,T^\\*.\n$$\nFor each steady state, determine linear stability by evaluating the Jacobian matrix of the vector field at $(A^\\*,T^\\*)$ and checking whether both eigenvalues have negative real parts. For a $2\\times 2$ system with Jacobian $J$, asymptotic stability is equivalent to $\\operatorname{trace}(J) < 0$ and $\\det(J) > 0$.\n\nYou must write a complete, runnable program that, for each parameter set in the test suite below, finds all biologically nonnegative steady states $(A^\\*,T^\\*)$ with $A^\\* \\ge 0$ and $T^\\* \\ge 0$, determines which are asymptotically stable, and returns the total count of stable steady states as an integer.\n\nNumerical details and constraints:\n- You may transform the steady-state problem to a single scalar equation in $A^\\*$ by eliminating $T^\\*$ from the steady-state equations if you wish, but you must still perform a correct stability check using the full $2\\times 2$ Jacobian.\n- Search the interval $A^\\* \\in [0, A_{max}]$ for roots of the steady-state condition, where $A_{max}$ should be chosen sufficiently large based on parameters. Your program must choose $A_{max}$ automatically in a way that guarantees that any root is not missed in realistic parameter regimes (for example, by using an upper bound derived from the asymptotic behavior when $A$ is large).\n- Treat any two roots whose $A^\\*$ values differ by less than a small tolerance (e.g., $10^{-6}$) as a single root.\n- If a root lands exactly at the boundary within tolerance, include it. Count only steady states with $T^\\* \\ge 0$.\n- For stability, compute the Jacobian entries analytically from the model and evaluate the trace and determinant at the steady state. A steady state counts as asymptotically stable if $\\operatorname{trace}(J) < 0$ and $\\det(J) > 0$.\n\nTest suite of parameter sets:\nFor each case, the required parameters are $(k_{basal}, k_{act}, k_{deg}, k_{loss}, V_{max}, K_m, n, K, A_{ext})$, in that order. There are five cases:\n- Case $1$ (no positive feedback, monostable expected): $(k_{basal}=\\,$$0.2$$,\\, k_{act}=\\,$$0.0$$,\\, k_{deg}=\\,$$1.0$$,\\, k_{loss}=\\,$$0.5$$,\\, V_{max}=\\,$$1.0$$,\\, K_m=\\,$$0.05$$,\\, n=\\,$$2.0$$,\\, K=\\,$$0.05$$,\\, A_{ext}=\\,$$0.1$$)$.\n- Case $2$ (weak feedback, low cooperativity): $(k_{basal}=\\,$$0.05$$,\\, k_{act}=\\,$$0.5$$,\\, k_{deg}=\\,$$1.0$$,\\, k_{loss}=\\,$$0.5$$,\\, V_{max}=\\,$$1.0$$,\\, K_m=\\,$$0.05$$,\\, n=\\,$$1.0$$,\\, K=\\,$$0.05$$,\\, A_{ext}=\\,$$0.2$$)$.\n- Case $3$ (strong feedback, high cooperativity, bistability anticipated): $(k_{basal}=\\,$$0.01$$,\\, k_{act}=\\,$$9.0$$,\\, k_{deg}=\\,$$1.0$$,\\, k_{loss}=\\,$$0.5$$,\\, V_{max}=\\,$$1.5$$,\\, K_m=\\,$$0.02$$,\\, n=\\,$$4.0$$,\\, K=\\,$$0.05$$,\\, A_{ext}=\\,$$0.2$$)$.\n- Case $4$ (very low external arabinose, monostable off expected): $(k_{basal}=\\,$$0.01$$,\\, k_{act}=\\,$$9.0$$,\\, k_{deg}=\\,$$1.0$$,\\, k_{loss}=\\,$$0.5$$,\\, V_{max}=\\,$$1.5$$,\\, K_m=\\,$$0.02$$,\\, n=\\,$$4.0$$,\\, K=\\,$$0.05$$,\\, A_{ext}=\\,$$0.000001$$)$.\n- Case $5$ (strong feedback but high loss, monostable expected): $(k_{basal}=\\,$$0.01$$,\\, k_{act}=\\,$$9.0$$,\\, k_{deg}=\\,$$1.0$$,\\, k_{loss}=\\,$$4.0$$,\\, V_{max}=\\,$$1.5$$,\\, K_m=\\,$$0.02$$,\\, n=\\,$$4.0$$,\\, K=\\,$$0.05$$,\\, A_{ext}=\\,$$0.2$$)$.\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets. The $i$-th entry must be the integer number of asymptotically stable steady states for Case $i$, for $i \\in \\{1,2,3,4,5\\}$. For example, your program must print a line of the form $[r_1,r_2,r_3,r_4,r_5]$ where each $r_i$ is an integer. No physical unit conversion is required, and you must return integers only as specified. Angles, if any, are not used in this problem.", "solution": "The problem presents a well-posed and scientifically grounded model of an inducible gene circuit, specifically the arabinose-inducible $P_{BAD}$ promoter system. The model is based on established principles of biochemical kinetics and gene regulation. All parameters are clearly defined, and the objective is a standard analysis of a dynamical system: finding steady states and determining their stability. The problem is valid.\n\nThe solution proceeds in three stages: (1) reduction of the two-dimensional steady-state problem to a single scalar equation, (2) derivation of the stability condition for a steady state, and (3) development of a numerical algorithm to find all stable steady states.\n\nThe system is described by the following ordinary differential equations for internal arabinose concentration, $A$, and transporter abundance, $T$:\n$$\n\\frac{dA}{dt} = U(A_{ext}) T - k_{loss} A\n$$\n$$\n\\frac{dT}{dt} = k_{basal} + k_{act} H(A) - k_{deg} T\n$$\nwhere $U(A_{ext}) = V_{max}\\frac{A_{ext}}{K_m + A_{ext}}$ is the uptake factor and $H(A) = \\frac{A^n}{K^n + A^n}$ is the Hill activation function. For any given set of parameters, $A_{ext}$ is constant, making $U(A_{ext})$ a constant value which we will denote simply as $U$.\n\nA steady state $(A^\\*, T^\\*)$ satisfies $\\frac{dA}{dt}=0$ and $\\frac{dT}{dt}=0$:\n$$\n(1) \\qquad 0 = U T^\\* - k_{loss} A^\\*\n$$\n$$\n(2) \\qquad 0 = k_{basal} + k_{act} H(A^\\*) - k_{deg} T^\\*\n$$\nProvided $U > 0$ (which is true for any $A_{ext} > 0$), we can solve for $T^\\*$ from equation (1):\n$$\nT^\\* = \\frac{k_{loss}}{U} A^\\*\n$$\nSince all parameters ($k_{loss}$, $U$) are positive, any biologically relevant steady state with $A^\\* \\ge 0$ will also have $T^\\* \\ge 0$. Substituting this expression for $T^\\*$ into equation (2) eliminates $T^\\*$ and yields a single scalar equation for $A^\\*$:\n$$\n0 = k_{basal} + k_{act} H(A^\\*) - k_{deg} \\left(\\frac{k_{loss}}{U} A^\\*\\right)\n$$\nFinding the steady states is equivalent to finding the non-negative roots $A^\\*$ of the function $f(A)$:\n$$\nf(A) = \\underbrace{k_{basal} + k_{act} \\frac{A^n}{K^n + A^n}}_{\\text{Production term } g(A)} - \\underbrace{\\left(\\frac{k_{deg} k_{loss}}{U}\\right) A}_{\\text{Loss term } l(A)}\n$$\nThe roots of $f(A)=0$ correspond to the intersection points of the sigmoidal production curve $g(A)$ and the linear loss line $l(A)$. Depending on the parameters, there may be one or three such intersections in the non-negative domain, corresponding to monostability or bistability.\n\nTo determine the stability of a steady state $(A^\\*, T^\\*)$, we analyze the Jacobian matrix of the system, $J$, evaluated at that state. The vector field is $\\mathbf{F}(A, T) = [F_A, F_T]^T = [U T - k_{loss} A, \\,\\, k_{basal} + k_{act} H(A) - k_{deg} T]^T$. The Jacobian matrix is:\n$$\nJ = \\begin{pmatrix} \\frac{\\partial F_A}{\\partial A} & \\frac{\\partial F_A}{\\partial T} \\\\ \\frac{\\partial F_T}{\\partial A} & \\frac{\\partial F_T}{\\partial T} \\end{pmatrix} = \\begin{pmatrix} -k_{loss} & U \\\\ k_{act} H'(A) & -k_{deg} \\end{pmatrix}\n$$\nwhere \n$$ H'(A) = \\frac{d}{dA}H(A) = \\frac{n K^n A^{n-1}}{(K^n + A^n)^2} $$\nFor a two-dimensional system, a steady state is asymptotically stable if the trace of its Jacobian is negative and the determinant is positive.\nThe trace of the Jacobian is $\\operatorname{trace}(J) = -k_{loss} - k_{deg}$. Since the physical loss and degradation rates $k_{loss}$ and $k_{deg}$ must be positive, $\\operatorname{trace}(J)$ is always negative. Therefore, the stability condition simplifies to checking if the determinant is positive:\n$$ \\det(J) = (-k_{loss})(-k_{deg}) - (U)(k_{act} H'(A^\\*)) > 0 $$\n$$ k_{loss} k_{deg} - U k_{act} H'(A^\\*) > 0 $$\nThis inequality can be related to the derivative of our scalar function $f(A)$. The derivative is $f'(A) = g'(A) - l'(A)$, where $g'(A) = k_{act} H'(A)$ and $l'(A) = \\frac{k_{deg} k_{loss}}{U}$.\nThe stability condition is thus:\n$$ k_{loss} k_{deg} > U k_{act} H'(A^\\*) \\iff \\frac{k_{loss} k_{deg}}{U} > k_{act} H'(A^\\*) \\iff l'(A^\\*) > g'(A^\\*) $$\nThis is equivalent to $f'(A^\\*) = g'(A^\\*) - l'(A^\\*)  0$. In summary, a steady state $A^\\*$ is asymptotically stable if and only if the derivative of the scalar root-finding function $f(A)$ is negative at that root. This provides a direct and efficient method for stability analysis.\n\nThe numerical implementation plan is as follows:\n1.  For each parameter set, define the scalar function $f(A)$ and its derivative $f'(A)$.\n2.  Determine a sufficiently large search interval $[0, A_{max}]$ for the roots $A^\\*$. An upper bound is derived from the fact that at steady state, $l(A^\\*) = g(A^\\*) \\le k_{basal} + k_{act}$. This gives $A^\\* \\le \\frac{U(k_{basal} + k_{act})}{k_{deg} k_{loss}}$. We use this to define $A_{max}$.\n3.  Numerically find all roots of $f(A)=0$ within $[0, A_{max}]$. This is achieved by dividing the interval into a fine grid, identifying subintervals where the function changes sign, and applying a robust root-finding algorithm like Brent's method (`brentq`) on each such subinterval.\n4.  Consolidate the list of found roots, removing duplicates within a tolerance of $10^{-6}$.\n5.  For each unique, non-negative root $A^\\*$, evaluate $f'(A^\\*)$. If $f'(A^\\*)  0$, the corresponding steady state is stable, and a counter is incremented.\n6.  The final count of stable steady states is reported for each parameter set.\nThis procedure robustly identifies all physically meaningful steady states and correctly assesses their stability.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.optimize import brentq\n\ndef solve():\n    \"\"\"\n    Main function to solve the problem for all test cases.\n    \"\"\"\n    # Define the test cases from the problem statement as a list of tuples.\n    # Parameters: (k_basal, k_act, k_deg, k_loss, V_max, K_m, n, K, A_ext)\n    test_cases = [\n        # Case 1 (no positive feedback, monostable expected)\n        (0.2, 0.0, 1.0, 0.5, 1.0, 0.05, 2.0, 0.05, 0.1),\n        # Case 2 (weak feedback, low cooperativity)\n        (0.05, 0.5, 1.0, 0.5, 1.0, 0.05, 1.0, 0.05, 0.2),\n        # Case 3 (strong feedback, high cooperativity, bistability anticipated)\n        (0.01, 9.0, 1.0, 0.5, 1.5, 0.02, 4.0, 0.05, 0.2),\n        # Case 4 (very low external arabinose, monostable off expected)\n        (0.01, 9.0, 1.0, 0.5, 1.5, 0.02, 4.0, 0.05, 0.000001),\n        # Case 5 (strong feedback but high loss, monostable expected)\n        (0.01, 9.0, 1.0, 4.0, 1.5, 0.02, 4.0, 0.05, 0.2),\n    ]\n\n    results = []\n    # Process each test case.\n    for params in test_cases:\n        count = count_stable_steady_states(params)\n        results.append(count)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\ndef count_stable_steady_states(params):\n    \"\"\"\n    Finds and counts the number of stable steady states for a given parameter set.\n    \"\"\"\n    k_basal, k_act, k_deg, k_loss, V_max, K_m, n, K, A_ext = params\n\n    # Calculate the uptake factor U. If A_ext is 0, U is 0.\n    if A_ext == 0:\n        U = 0.0\n    else:\n        U = V_max * A_ext / (K_m + A_ext)\n\n    # Special case: If U is zero, there's a simple single steady state.\n    if U == 0:\n        # A_star = 0. T_star = k_basal / k_deg.\n        # det(J) = k_loss * k_deg  0, so it's always stable.\n        return 1\n\n    # Define the scalar function f(A) whose roots are the steady states for A.\n    # f(A) = Production(A) - Loss(A) = 0\n    def f(A):\n        if A  0: return np.inf # physically irrelevant\n        hill_term = A**n / (K**n + A**n)\n        production = k_basal + k_act * hill_term\n        loss = (k_deg * k_loss / U) * A\n        return production - loss\n\n    # Define the derivative f'(A) to check stability.\n    # A steady state A* is stable if f'(A*)  0.\n    def f_prime(A):\n        if A  0: return 0\n        # Derivative of the Hill function component\n        hill_derivative = (n * K**n * A**(n - 1)) / (K**n + A**n)**2\n        # Derivative of the production term g(A)\n        g_prime = k_act * hill_derivative\n        # Derivative of the loss term l(A)\n        l_prime = k_deg * k_loss / U\n        return g_prime - l_prime\n\n    # Determine a safe upper bound for the search range [0, A_max].\n    # At steady state, Loss(A*) = Production(A*).\n    # Since Production(A*) = k_basal + k_act, we have\n    # (k_deg * k_loss / U) * A* = k_basal + k_act\n    # A* = U * (k_basal + k_act) / (k_deg * k_loss)\n    A_max = U * (k_basal + k_act) / (k_deg * k_loss)\n    # Add a buffer to ensure the interval is robust.\n    A_max *= 1.2\n    if A_max == 0: # This can happen if k_act and k_basal are 0\n        A_max = K * 10 \n\n    # Find all roots by scanning the interval [0, A_max].\n    num_points = 20001\n    grid = np.linspace(0, A_max, num=num_points)\n    found_roots = []\n\n    # Check for a root exactly at A=0.\n    if abs(f(0.0))  1e-12:\n        found_roots.append(0.0)\n\n    # Scan grid for sign changes, which indicates a root is bracketed.\n    f_values = np.array([f(a) for a in grid])\n    for i in range(num_points - 1):\n        if f_values[i] * f_values[i+1]  0:\n            try:\n                root = brentq(f, grid[i], grid[i+1])\n                found_roots.append(root)\n            except ValueError:\n                # Brentq can fail if signs are not opposite due to precision issues\n                # near a root. We can safely ignore this case as the grid is fine.\n                pass\n\n    # Deduplicate roots to handle cases where multiple scans find the same root.\n    if not found_roots:\n        unique_roots = []\n    else:\n        found_roots.sort()\n        unique_roots = [found_roots[0]]\n        for root in found_roots[1:]:\n            if abs(root - unique_roots[-1])  1e-6:\n                unique_roots.append(root)\n\n    # Count the number of stable steady states.\n    stable_count = 0\n    for A_star in unique_roots:\n        # The stability condition is f'(A*)  0.\n        if f_prime(A_star)  0:\n            stable_count += 1\n            \n    return stable_count\n\n# Execute the main function when the script is run.\nsolve()\n```", "id": "2722504"}]}