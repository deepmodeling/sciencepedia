{"hands_on_practices": [{"introduction": "Before designing a controller, it's crucial to first build a quantitative understanding of the problem. This exercise [@problem_id:2712681] guides you through a derivation based on a foundational proteome allocation model. By formalizing the competition for finite cellular resources, you will establish the fundamental linear relationship between synthetic protein expression and the reduction in cellular growth rate, providing a mathematical basis for predicting and managing metabolic burden.", "problem": "A bacterial cell is modeled using a coarse-grained proteome allocation framework in the translation-limited regime. The proteome is partitioned into three sectors: ribosomal proteins with mass fraction $ \\phi_{R} $, a fixed housekeeping sector with mass fraction $ \\phi_{H} $, and a synthetic protein sector with mass fraction $ \\phi_{p} $. Proteome conservation imposes the linear constraint $ \\phi_{R} + \\phi_{p} + \\phi_{H} = 1 $. Assume that $ \\phi_{H} $ is set by the nutrient condition and is constant over the range of burden considered, and that a constant fraction $ \\phi_{0} $ of ribosomes is inactive.\n\nUse as a fundamental base the well-tested empirical growth law for translation-limited growth that connects the cellular growth rate $ \\lambda $ to the active ribosomal proteome fraction:\n$$\n\\lambda \\;=\\; \\sigma \\bigl( \\phi_{R} - \\phi_{0} \\bigr),\n$$\nwhere $ \\sigma $ is the effective translational capacity per unit ribosomal proteome. Let $ \\lambda_{0} $ denote the baseline growth rate at zero synthetic burden $ \\phi_{p} = 0 $ in the same environment (same $ \\phi_{H} $, same $ \\sigma $, same $ \\phi_{0} $).\n\nDefine the dimensionless proteome cost coefficient $ c $ as the relative slope of the growth rate with respect to the synthetic proteome fraction at zero burden:\n$$\nc \\;\\equiv\\; \\lim_{\\Delta \\phi_{p} \\to 0} \\frac{\\lambda_{0} - \\lambda(\\phi_{p})}{\\lambda_{0}\\,\\phi_{p}}.\n$$\n\nStarting only from the proteome conservation constraint, the constancy of $ \\phi_{H} $ and $ \\phi_{0} $, and the growth law above, derive an explicit expression for $ \\lambda(\\phi_{p}) $ in closed form, expressed entirely in terms of $ \\lambda_{0} $, $ c $, and $ \\phi_{p} $. Your final answer must be a single closed-form analytic expression for $ \\lambda(\\phi_{p}) $. Do not include units in your final boxed answer.", "solution": "We are tasked with deriving an expression for the cellular growth rate, $ \\lambda $, as a function of the synthetic protein mass fraction, $ \\phi_{p} $, in terms of the baseline growth rate $ \\lambda_{0} $ and the cost coefficient $ c $. The derivation will proceed from the given first principles.\n\nThe system is described by two fundamental equations:\n$1$. The proteome conservation constraint:\n$$ \\phi_{R} + \\phi_{p} + \\phi_{H} = 1 $$\n$2$. The translation-limited growth law:\n$$ \\lambda = \\sigma (\\phi_{R} - \\phi_{0}) $$\nThe parameters $ \\phi_{H} $ (housekeeping proteome fraction), $ \\phi_{0} $ (inactive ribosomal proteome fraction), and $ \\sigma $ (effective translational capacity) are given as constants for a specific growth environment.\n\nFrom the proteome conservation equation, we first isolate the ribosomal protein fraction, $ \\phi_{R} $, as it is the variable that links the proteome composition to the growth rate:\n$$ \\phi_{R} = 1 - \\phi_{H} - \\phi_{p} $$\nSubstituting this expression for $ \\phi_{R} $ into the growth law yields the growth rate $ \\lambda $ as an explicit function of $ \\phi_{p} $:\n$$ \\lambda(\\phi_{p}) = \\sigma \\left( (1 - \\phi_{H} - \\phi_{p}) - \\phi_{0} \\right) $$\nBy rearranging the terms inside the parenthesis, we obtain a linear relationship between $ \\lambda $ and $ \\phi_{p} $:\n$$ \\lambda(\\phi_{p}) = \\sigma (1 - \\phi_{H} - \\phi_{0}) - \\sigma \\phi_{p} $$\n\nThe objective is to re-parameterize this expression using $ \\lambda_{0} $ and $ c $.\nFirst, we utilize the definition of the baseline growth rate $ \\lambda_{0} $, which corresponds to the case of zero synthetic burden, i.e., $ \\phi_{p} = 0 $. By setting $ \\phi_{p} = 0 $ in our expression for $ \\lambda(\\phi_{p}) $, we find:\n$$ \\lambda_{0} = \\lambda(0) = \\sigma (1 - \\phi_{H} - \\phi_{0}) $$\nThis term is precisely the constant intercept in our linear equation for $ \\lambda(\\phi_{p}) $. Therefore, we can simplify the expression for $ \\lambda(\\phi_{p}) $ to:\n$$ \\lambda(\\phi_{p}) = \\lambda_{0} - \\sigma \\phi_{p} $$\n\nNext, we must eliminate the parameter $ \\sigma $. For this, we use the definition of the dimensionless proteome cost coefficient $ c $:\n$$ c \\equiv \\lim_{\\phi_{p} \\to 0} \\frac{\\lambda_{0} - \\lambda(\\phi_{p})}{\\lambda_{0}\\,\\phi_{p}} $$\nThis expression defines $ c $ in terms of a limit, which can be identified with a derivative. Rewriting the expression clarifies this:\n$$ c = \\frac{1}{\\lambda_{0}} \\lim_{\\phi_{p} \\to 0} \\frac{-(\\lambda(\\phi_{p}) - \\lambda_{0})}{\\phi_{p} - 0} = -\\frac{1}{\\lambda_{0}} \\left( \\frac{d\\lambda}{d\\phi_{p}} \\right)_{\\phi_{p}=0} $$\nWe now compute the derivative of $ \\lambda(\\phi_{p}) $ with respect to $ \\phi_{p} $ using the expression we derived:\n$$ \\frac{d\\lambda}{d\\phi_{p}} = \\frac{d}{d\\phi_{p}} (\\lambda_{0} - \\sigma \\phi_{p}) = -\\sigma $$\nThe derivative is a constant, so its value at $ \\phi_{p}=0 $ is also $ -\\sigma $. Substituting this result into the formula for $ c $:\n$$ c = -\\frac{1}{\\lambda_{0}} (-\\sigma) = \\frac{\\sigma}{\\lambda_{0}} $$\nThis provides an expression for $ \\sigma $ in terms of the desired parameters:\n$$ \\sigma = c \\lambda_{0} $$\n\nFinally, we substitute this expression for $ \\sigma $ back into our equation for $ \\lambda(\\phi_{p}) $:\n$$ \\lambda(\\phi_{p}) = \\lambda_{0} - (c \\lambda_{0}) \\phi_{p} $$\nFactoring out the common term $ \\lambda_{0} $ yields the final closed-form expression for the growth rate as a function of synthetic protein fraction, expressed entirely in terms of the specified parameters:\n$$ \\lambda(\\phi_{p}) = \\lambda_{0}(1 - c \\phi_{p}) $$\nThis result demonstrates a linear decrease in growth rate as the burden from synthetic protein expression increases, with the rate of decrease determined by the product of the baseline growth rate and the cost coefficient.", "answer": "$$ \\boxed{\\lambda_{0}(1 - c \\phi_{p})} $$", "id": "2712681"}, {"introduction": "An effective adaptive control system relies on real-time measurements of the state it aims to regulate. In synthetic biology, this is often achieved with genetically encoded biosensors, whose behavior must be precisely characterized. This hands-on coding problem [@problem_id:2712619] immerses you in the essential engineering task of system identification, where you will fit a standard nonlinear model to sensor data to calibrate a burden reporter, extracting control-relevant parameters like sensitivity and the operational setpoint.", "problem": "You are designing an adaptive control strategy for cellular burden mitigation, where a burden reporter maps the effective resource limitation imposed by a heterologous module to an inducible actuator. To tune the controller safely, you must calibrate the reporter by identifying a static input-output nonlinearity from perturbation experiments and extracting interpretable parameters relevant to control: the sensitivity at the half-activation point and the half-activation input. Assume the following modeling base: gene regulation often exhibits cooperative binding behavior that is well-approximated by a Hill nonlinearity at steady state due to promoter occupancy, and a first-order low-pass dynamics due to transcription-translation-maturation; however, for calibration, you are provided plateau-averaged steady-state data computed from multiple stepwise inductions, which eliminates the need to model the dynamics explicitly.\n\nFormalize the calibration as follows. Let the heterologous induction input be $u \\ge 0$ and the steady-state reporter output be $y \\ge 0$. Assume the steady-state mapping is\n$$\nf(u; \\theta) \\;=\\; y_0 \\;+\\; y_{\\max}\\,\\frac{u^{n}}{K^{n} + u^{n}},\n$$\nwith parameter vector $\\theta = (y_0, y_{\\max}, K, n)$, baseline $y_0 \\ge 0$, dynamic range $y_{\\max} > 0$, half-activation point $K > 0$, and Hill coefficient $n > 0$. Define the local sensitivity at half-activation as the steady-state gain\n$$\nS \\;=\\; \\left.\\frac{d f(u;\\theta)}{d u}\\right|_{u = K}.\n$$\nFrom a control-design perspective for burden mitigation, $S$ quantifies the small-signal amplification at the operating point and $K$ anchors the operating input where burden regulation is most responsive.\n\nYour task is to write a complete, runnable program that, for each test case below, constructs a deterministic steady-state dataset $\\{(u_i,y_i)\\}_{i=1}^m$ from specified inputs $u_i$ and a generative rule, fits the Hill parameters $\\theta$ by nonlinear least squares under physically meaningful bounds, and returns the estimated sensitivity $S$ and half-activation point $K$ for each case.\n\nUse the following data-generation procedure per test case. Given parameters $(y_0^{\\star}, y_{\\max}^{\\star}, K^{\\star}, n^{\\star})$, a noise amplitude $a \\ge 0$, a noise frequency $\\omega \\ge 0$, and an input grid $\\mathcal{U} = [u_1,\\dots,u_m]$, define the measured steady states by\n$$\ny_i \\;=\\; y_0^{\\star} \\;+\\; y_{\\max}^{\\star}\\,\\frac{u_i^{n^{\\star}}}{(K^{\\star})^{n^{\\star}} + u_i^{n^{\\star}}} \\;+\\; a \\,\\sin(\\omega\\,u_i), \\quad i \\in \\{1,\\dots,m\\}.\n$$\nNo random numbers are permitted; the sinusoidal term is a deterministic disturbance modeling repeatable preparation bias. You must fit $\\theta$ to minimize the sum of squared residuals $\\sum_{i=1}^m \\left(y_i - f(u_i;\\theta)\\right)^2$ subject to bounds $y_0 \\ge 0$, $y_{\\max} \\ge 0$, $K > 0$, and $n \\in [\\,0.5,\\,8\\,]$. Then compute $S$ from the fitted $\\hat{\\theta}$ and report $(S, K)$ per test case.\n\nTest suite. For each test case $j \\in \\{1,2,3\\}$, construct $\\mathcal{U}^{(j)}$ and $y^{(j)}$ using the parameters below. All numbers are exact and must be used exactly as specified.\n\n- Case $1$ (happy path, moderate cooperativity, well-covered dynamic range):\n  - True parameters: $y_0^{\\star} = 0.05$, $y_{\\max}^{\\star} = 1.2$, $K^{\\star} = 1.0$, $n^{\\star} = 2.5$.\n  - Disturbance: $a = 0.01$, $\\omega = 1.7$.\n  - Input grid: $\\mathcal{U}^{(1)} = [\\,0.0,\\,0.05,\\,0.1,\\,0.2,\\,0.5,\\,1.0,\\,2.0,\\,5.0,\\,10.0\\,]$.\n\n- Case $2$ (boundary regime near Michaelis–Menten, small $K$):\n  - True parameters: $y_0^{\\star} = 0.02$, $y_{\\max}^{\\star} = 0.8$, $K^{\\star} = 0.2$, $n^{\\star} = 1.05$.\n  - Disturbance: $a = 0.005$, $\\omega = 2.3$.\n  - Input grid: $\\mathcal{U}^{(2)} = [\\,0.0,\\,0.02,\\,0.05,\\,0.1,\\,0.2,\\,0.4,\\,0.8,\\,1.6\\,]$.\n\n- Case $3$ (edge case, highly ultrasensitive):\n  - True parameters: $y_0^{\\star} = 0.1$, $y_{\\max}^{\\star} = 2.0$, $K^{\\star} = 3.0$, $n^{\\star} = 6.0$.\n  - Disturbance: $a = 0.02$, $\\omega = 0.5$.\n  - Input grid: $\\mathcal{U}^{(3)} = [\\,0.0,\\,0.5,\\,1.0,\\,2.0,\\,3.0,\\,4.0,\\,6.0,\\,9.0\\,]$.\n\nAlgorithmic and numerical requirements:\n- Implement a nonlinear least-squares fit for $\\theta = (y_0, y_{\\max}, K, n)$ with the bounds $y_0 \\in [\\,0,\\,+\\infty)$, $y_{\\max} \\in [\\,0,\\,+\\infty)$, $K \\in (\\,0,\\,+\\infty)$, $n \\in [\\,0.5,\\,8\\,]$. Use a deterministic initial guess strategy derived from the data (for example, using $\\min y_i$, $\\max y_i$, and the mid-response input to initialize $y_0$, $y_{\\max}$, and $K$; and a fixed initial $n$).\n- After fitting, compute $S$ from the fitted parameters $\\hat{y}_0, \\hat{y}_{\\max}, \\hat{K}, \\hat{n}$ using the definition $S = \\left.\\frac{d f(u;\\hat{\\theta})}{d u}\\right|_{u=\\hat{K}}$.\n- Numerical stability must be handled gracefully for $u=0$ and small $K$ by relying on the bounded parameters rather than any ad hoc regularization.\n- No randomness is permitted anywhere.\n\nFinal output format:\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets in the order $[\\,S^{(1)}, K^{(1)}, S^{(2)}, K^{(2)}, S^{(3)}, K^{(3)}\\,]$, where $S^{(j)}$ and $K^{(j)}$ are the estimated sensitivity and half-activation for case $j$. Each entry must be a floating-point number.\n\nAnswer in dimensionless values. No physical units or angles are involved. Express all numeric results as plain decimal floats in the specified list format.", "solution": "The problem posed is a well-defined exercise in system identification and parameter estimation, situated within the context of synthetic biology. It is scientifically grounded, logically consistent, and contains all necessary information to proceed with a unique, verifiable solution. Therefore, the problem is deemed valid.\n\nThe core task is to estimate parameters of a Hill-type nonlinearity from synthetic steady-state data and then compute control-relevant metrics. The process involves three main stages: data generation, parameter fitting via nonlinear least squares, and calculation of derived quantities.\n\nFirst, we formalize the model. The steady-state relationship between the input inducer concentration $u$ and the output reporter level $y$ is given by the Hill function:\n$$\ny = f(u; \\theta) = y_0 + y_{\\max}\\,\\frac{u^{n}}{K^{n} + u^{n}}\n$$\nwhere $\\theta = (y_0, y_{\\max}, K, n)$ is the vector of parameters: $y_0$ is the baseline output, $y_{\\max}$ is the dynamic range, $K$ is the half-activation concentration (the input $u$ at which the response is halfway between $y_0$ and $y_0 + y_{\\max}$), and $n$ is the Hill coefficient, which quantifies the steepness or cooperativity of the response.\n\nFor each test case, a dataset $\\{(u_i, y_i)\\}_{i=1}^m$ is generated according to the rule:\n$$\ny_i = \\left( y_0^{\\star} + y_{\\max}^{\\star}\\,\\frac{u_i^{n^{\\star}}}{(K^{\\star})^{n^{\\star}} + u_i^{n^{\\star}}} \\right) + a \\,\\sin(\\omega\\,u_i)\n$$\nwhere $(y_0^{\\star}, y_{\\max}^{\\star}, K^{\\star}, n^{\\star})$ are the true model parameters, and the term $a \\,\\sin(\\omega\\,u_i)$ represents a deterministic, structured disturbance, not random noise.\n\nThe second stage is parameter estimation. We seek the parameter vector $\\hat{\\theta} = (\\hat{y}_0, \\hat{y}_{\\max}, \\hat{K}, \\hat{n})$ that minimizes the sum of squared residuals between the measured data $y_i$ and the model predictions $f(u_i; \\theta)$:\n$$\n\\hat{\\theta} = \\arg\\min_{\\theta} \\sum_{i=1}^m \\left(y_i - f(u_i;\\theta)\\right)^2\n$$\nThis minimization is performed subject to physically meaningful constraints on the parameters: $y_0 \\ge 0$, $y_{\\max} \\ge 0$, $K > 0$, and $n \\in [0.5, 8]$. These constraints ensure the biological interpretability of the fitted model. This is a standard nonlinear least-squares regression problem, which can be solved numerically using algorithms like the Levenberg-Marquardt algorithm, as implemented in `scipy.optimize.curve_fit`. A deterministic initial guess for the optimization routine is crucial for reproducibility and is constructed from the data itself: $y_0$ is initialized from the response at $u=0$, $y_{\\max}$ from the observed range of the data, $K$ from the input that yields a half-maximal response, and $n$ is set to a fixed initial value (e.g., $2$).\n\nThe final stage is the calculation of the control-relevant parameters from the fitted model $\\hat{\\theta}$. The half-activation point is simply the fitted parameter $\\hat{K}$. The sensitivity at this point, $S$, is defined as the derivative of the steady-state function evaluated at $u=\\hat{K}$:\n$$\nS = \\left.\\frac{d f(u;\\hat{\\theta})}{d u}\\right|_{u = \\hat{K}}\n$$\nTo find an expression for $S$, we differentiate the Hill function with respect to $u$:\n$$\n\\frac{df}{du} = y_{\\max} \\frac{d}{du}\\left(\\frac{u^n}{K^n + u^n}\\right) = y_{\\max} \\frac{(n u^{n-1})(K^n + u^n) - (u^n)(n u^{n-1})}{(K^n + u^n)^2}\n$$\nSimplifying the numerator gives:\n$$\n\\frac{df}{du} = y_{\\max} \\frac{n K^n u^{n-1}}{(K^n + u^n)^2}\n$$\nNow, we evaluate this derivative at $u=K$:\n$$\nS = \\left.\\frac{df}{du}\\right|_{u=K} = \\hat{y}_{\\max} \\frac{\\hat{n} \\hat{K}^n \\hat{K}^{\\hat{n}-1}}{(\\hat{K}^{\\hat{n}} + \\hat{K}^{\\hat{n}})^2} = \\hat{y}_{\\max} \\frac{\\hat{n} \\hat{K}^{2\\hat{n}-1}}{(2\\hat{K}^{\\hat{n}})^2} = \\hat{y}_{\\max} \\frac{\\hat{n} \\hat{K}^{2\\hat{n}-1}}{4\\hat{K}^{2\\hat{n}}}\n$$\nThis simplifies to the final expression for sensitivity based on the fitted parameters:\n$$\nS = \\frac{\\hat{y}_{\\max} \\hat{n}}{4\\hat{K}}\n$$\nThis procedure is applied to each of the three test cases specified in the problem, yielding a pair of values $(S^{(j)}, K^{(j)})$ for each case $j \\in \\{1, 2, 3\\}$.", "answer": "```python\nimport numpy as np\nfrom scipy.optimize import curve_fit\n\ndef solve():\n    \"\"\"\n    Solves the problem of fitting a Hill function to synthetic data for three\n    test cases and calculates control-relevant parameters S and K.\n    \"\"\"\n\n    # Define the test cases as per the problem statement.\n    test_cases = [\n        {\n            \"case_id\": 1,\n            \"true_params\": {\"y0_star\": 0.05, \"ymax_star\": 1.2, \"K_star\": 1.0, \"n_star\": 2.5},\n            \"disturbance\": {\"a\": 0.01, \"omega\": 1.7},\n            \"u_grid\": np.array([0.0, 0.05, 0.1, 0.2, 0.5, 1.0, 2.0, 5.0, 10.0])\n        },\n        {\n            \"case_id\": 2,\n            \"true_params\": {\"y0_star\": 0.02, \"ymax_star\": 0.8, \"K_star\": 0.2, \"n_star\": 1.05},\n            \"disturbance\": {\"a\": 0.005, \"omega\": 2.3},\n            \"u_grid\": np.array([0.0, 0.02, 0.05, 0.1, 0.2, 0.4, 0.8, 1.6])\n        },\n        {\n            \"case_id\": 3,\n            \"true_params\": {\"y0_star\": 0.1, \"ymax_star\": 2.0, \"K_star\": 3.0, \"n_star\": 6.0},\n            \"disturbance\": {\"a\": 0.02, \"omega\": 0.5},\n            \"u_grid\": np.array([0.0, 0.5, 1.0, 2.0, 3.0, 4.0, 6.0, 9.0])\n        }\n    ]\n\n    # Model definition: Hill function\n    def hill_function(u, y0, ymax, K, n):\n        \"\"\"\n        Calculates the Hill function response.\n        f(u) = y0 + ymax * u^n / (K^n + u^n)\n        \"\"\"\n        # To avoid potential warnings with u=0 and n<1, although not an issue here.\n        # Added a small epsilon to the numerator and denominator for robustness.\n        u_n = np.power(u, n)\n        K_n = np.power(K, n)\n        return y0 + ymax * u_n / (K_n + u_n)\n\n    results = []\n    for case in test_cases:\n        u_data = case[\"u_grid\"]\n        \n        # --- 1. Data Generation ---\n        p_true = case[\"true_params\"]\n        dist = case[\"disturbance\"]\n        \n        y_model = hill_function(u_data, p_true[\"y0_star\"], p_true[\"ymax_star\"], p_true[\"K_star\"], p_true[\"n_star\"])\n        y_noise = dist[\"a\"] * np.sin(dist[\"omega\"] * u_data)\n        y_data = y_model + y_noise\n\n        # --- 2. Parameter Fitting ---\n        \n        # Deterministic initial guess strategy\n        # Initial y0: response at u=0. Assumes u=0 is the first data point.\n        y0_guess = y_data[0]\n        # Initial ymax: max response - min response\n        ymax_guess = np.max(y_data) - y0_guess\n        # Initial K: input at which response is half-maximal\n        y_mid = y0_guess + ymax_guess / 2.0\n        mid_idx = np.argmin(np.abs(y_data - y_mid))\n        K_guess = u_data[mid_idx]\n        if K_guess == 0.0:  # Avoid K=0 as it is out of bounds\n            K_guess = np.median(u_data[u_data > 0]) if np.any(u_data > 0) else 0.1\n        # Initial n: fixed value as suggested\n        n_guess = 2.0\n\n        p0 = [y0_guess, ymax_guess, K_guess, n_guess]\n        \n        # Parameter bounds\n        # y0 >= 0, ymax >= 0, K > 0 (approximated as K >= 1e-9), 0.5 <= n <= 8\n        bounds = ([0, 0, 1e-9, 0.5], [np.inf, np.inf, np.inf, 8.0])\n\n        # Perform nonlinear least-squares fit\n        p_opt, _ = curve_fit(hill_function, u_data, y_data, p0=p0, bounds=bounds, method='trf')\n        \n        y0_fit, ymax_fit, K_fit, n_fit = p_opt\n\n        # --- 3. Calculation of S and K ---\n        # K is the fitted parameter itself\n        K_est = K_fit\n        # S = (ymax * n) / (4 * K)\n        S_est = (ymax_fit * n_fit) / (4 * K_fit)\n        \n        results.extend([S_est, K_est])\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n\n```", "id": "2712619"}, {"introduction": "With a quantitative model of burden and a calibrated sensor, the final piece is the controller algorithm itself. This practice [@problem_id:2712643] delves into the core of feedback control theory by analyzing how a controller can be designed to robustly maintain burden at a desired level despite unknown disturbances. By deriving the steady-state performance of both proportional (P) and proportional-integral (PI) controllers, you will uncover the critical role of integral action in achieving perfect setpoint tracking and disturbance rejection, a cornerstone of robust control design.", "problem": "A burden-aware resource allocation module is used to mitigate host load in a synthetic Escherichia coli strain. Let the scalar host burden state be denoted by $b(t)$, defined as a dimensionless fractional deviation of translational capacity from a no-load baseline. Near a nominal operating point, suppose $b(t)$ is well approximated by a first-order linear dynamics with additive constant disturbance:\n$$\n\\frac{db}{dt} \\;=\\; -k_{b}\\,\\big(b(t) - b_{0}\\big) \\;+\\; S_{p}\\,u(t) \\;+\\; d,\n$$\nwhere $k_{b} \\gt 0$ is the host’s intrinsic relaxation rate back to the baseline $b_{0}$ in the absence of control, $S_{p} \\neq 0$ is the plant sensitivity of burden to the control input $u(t)$ (the actuator’s net effect on burden), and $d$ is an unknown but constant exogenous load. The measured output is $y(t) = b(t)$, and the control objective is to track a constant burden setpoint $r$ using output feedback.\n\nConsider two controllers that actuate the same $u(t)$:\n- Proportional (P) control: $u(t) = K_{p}\\,\\big(r - y(t)\\big)$ with $K_{p} \\in \\mathbb{R}$.\n- Proportional–Integral (PI) control: $u(t) = K_{p}\\,\\big(r - y(t)\\big) + K_{i}\\,\\int_{0}^{t} \\big(r - y(\\tau)\\big)\\,d\\tau$ with $K_{p} \\in \\mathbb{R}$ and $K_{i} \\ge 0$.\n\nAssume the closed-loop system is internally stable for the chosen gains and that all signals settle to a steady state under the constant setpoint $r$ and constant disturbance $d$. Starting from the given plant dynamics and these controller definitions, derive from first principles the steady-state tracking error $e_{\\mathrm{ss}} = r - y_{\\mathrm{ss}}$ under proportional control as a function of $K_{p}$ and $S_{p}$ together with $k_{b}$, $b_{0}$, $r$, and $d$. Then determine the steady-state error under proportional–integral control and explain under what condition integral action eliminates the steady-state error against constant $d$.\n\nExpress your final answer as a single row matrix $\\big[e_{\\mathrm{ss}}^{(P)} \\;\\; e_{\\mathrm{ss}}^{(PI)}\\big]$, where each entry is a closed-form analytic expression in the symbols specified above. Do not include units. If any approximation is required, state and justify it; otherwise, provide exact expressions.", "solution": "The problem requires the derivation of the steady-state tracking error for a first-order linear system under proportional (P) and proportional-integral (PI) control. The analysis will be conducted from first principles, assuming the closed-loop systems are stable and all signals converge to a steady state.\n\nFirst, the validation of the problem statement is performed.\nThe given information is:\nPlant dynamics: $\\frac{db}{dt} = -k_{b}(b(t) - b_{0}) + S_{p}u(t) + d$\nParameters: $k_{b} > 0$, $b_{0}$, $S_{p} \\neq 0$, $d$ is constant.\nOutput: $y(t) = b(t)$\nSetpoint: $r$ is constant.\nP-controller: $u(t) = K_{p}(r - y(t))$ with $K_{p} \\in \\mathbb{R}$.\nPI-controller: $u(t) = K_{p}(r - y(t)) + K_{i}\\int_{0}^{t} (r - y(\\tau))d\\tau$ with $K_{p} \\in \\mathbb{R}$, $K_{i} \\ge 0$.\nAssumptions: The closed-loop system is internally stable and settles to a steady state.\nObjective: Derive the steady-state tracking error $e_{\\mathrm{ss}} = r - y_{\\mathrm{ss}}$ for both controllers.\n\nThe problem is valid. It is a standard exercise in linear control theory, grounded in established principles. It is well-posed, objective, and contains sufficient information for a unique solution without contradictions. The model is a common and scientifically sound simplification used in systems and synthetic biology. We proceed to the solution.\n\nLet us first analyze the system under proportional (P) control.\nThe control law is $u(t) = K_{p}(r - y(t))$.\nSubstituting this into the plant dynamics, and using $y(t) = b(t)$, we obtain the closed-loop differential equation for the output $y(t)$:\n$$\n\\frac{dy}{dt} = -k_{b}(y(t) - b_{0}) + S_{p}K_{p}(r - y(t)) + d\n$$\nAt steady state, as $t \\to \\infty$, all time derivatives approach zero. Therefore, $\\frac{dy}{dt} \\to 0$, and the output converges to a constant value, $y(t) \\to y_{\\mathrm{ss}}$. The equation becomes:\n$$\n0 = -k_{b}(y_{\\mathrm{ss}} - b_{0}) + S_{p}K_{p}(r - y_{\\mathrm{ss}}) + d\n$$\nWe must now solve this algebraic equation for $y_{\\mathrm{ss}}$. Expanding the terms:\n$$\n0 = -k_{b}y_{\\mathrm{ss}} + k_{b}b_{0} + S_{p}K_{p}r - S_{p}K_{p}y_{\\mathrm{ss}} + d\n$$\nGroup the terms containing $y_{\\mathrm{ss}}$:\n$$\n(k_{b} + S_{p}K_{p})y_{\\mathrm{ss}} = k_{b}b_{0} + S_{p}K_{p}r + d\n$$\nThe assumption of stability for this first-order system implies that the effective rate constant, $k_{b} + S_{p}K_{p}$, must be positive, and thus non-zero. We can therefore solve for $y_{\\mathrm{ss}}$:\n$$\ny_{\\mathrm{ss}} = \\frac{k_{b}b_{0} + S_{p}K_{p}r + d}{k_{b} + S_{p}K_{p}}\n$$\nThe steady-state error, $e_{\\mathrm{ss}}^{(P)}$, is defined as $r - y_{\\mathrm{ss}}$. Substituting the expression for $y_{\\mathrm{ss}}$:\n$$\ne_{\\mathrm{ss}}^{(P)} = r - \\frac{k_{b}b_{0} + S_{p}K_{p}r + d}{k_{b} + S_{p}K_{p}}\n$$\nTo simplify, we place the expression over a common denominator:\n$$\ne_{\\mathrm{ss}}^{(P)} = \\frac{r(k_{b} + S_{p}K_{p}) - (k_{b}b_{0} + S_{p}K_{p}r + d)}{k_{b} + S_{p}K_{p}}\n$$\n$$\ne_{\\mathrm{ss}}^{(P)} = \\frac{rk_{b} + rS_{p}K_{p} - k_{b}b_{0} - S_{p}K_{p}r - d}{k_{b} + S_{p}K_{p}}\n$$\nCanceling the $rS_{p}K_{p}$ terms yields the final expression for the steady-state error under P control:\n$$\ne_{\\mathrm{ss}}^{(P)} = \\frac{k_{b}r - k_{b}b_{0} - d}{k_{b} + S_{p}K_{p}} = \\frac{k_{b}(r - b_{0}) - d}{k_{b} + S_{p}K_{p}}\n$$\nThis is a non-zero error, which depends on the system parameters, the setpoint $r$, and the disturbance $d$.\n\nNext, we analyze the system under proportional-integral (PI) control.\nThe control law is $u(t) = K_{p}(r - y(t)) + K_{i}\\int_{0}^{t} (r - y(\\tau))d\\tau$.\nAt steady state, all signals are constant: $y(t) \\to y_{\\mathrm{ss}}$, $u(t) \\to u_{\\mathrm{ss}}$, and $\\frac{dy}{dt} \\to 0$.\nThe plant equation at steady state is unchanged in form:\n$$\n0 = -k_{b}(y_{\\mathrm{ss}} - b_{0}) + S_{p}u_{\\mathrm{ss}} + d\n$$\nThis requires the control input $u(t)$ to approach a constant value $u_{\\mathrm{ss}} = \\frac{k_{b}(y_{\\mathrm{ss}} - b_{0}) - d}{S_{p}}$.\nNow, we examine the controller. For the control input $u(t)$ to converge to a constant value $u_{\\mathrm{ss}}$, its time derivative must approach zero, i.e., $\\frac{du}{dt} \\to 0$. We differentiate the PI control law with respect to time:\n$$\n\\frac{du}{dt} = \\frac{d}{dt} \\left[ K_{p}(r - y(t)) + K_{i}\\int_{0}^{t} (r - y(\\tau))d\\tau \\right]\n$$\nUsing a constant setpoint $r$ and the fundamental theorem of calculus:\n$$\n\\frac{du}{dt} = -K_{p}\\frac{dy}{dt} + K_{i}(r - y(t))\n$$\nNow, we apply the steady-state conditions: as $t \\to \\infty$, $\\frac{du}{dt} \\to 0$, $\\frac{dy}{dt} \\to 0$, and $y(t) \\to y_{\\mathrm{ss}}$. Substituting these into the differentiated controller equation:\n$$\n0 = -K_{p}(0) + K_{i}(r - y_{\\mathrm{ss}})\n$$\nThis simplifies to:\n$$\nK_{i}(r - y_{\\mathrm{ss}}) = 0\n$$\nOr, in terms of the steady-state error $e_{\\mathrm{ss}}^{(PI)} = r - y_{\\mathrm{ss}}$:\n$$\nK_{i}e_{\\mathrm{ss}}^{(PI)} = 0\n$$\nThis equation is central to the behavior of integral control. The question asks for the condition under which integral action eliminates the steady-state error. The integral action is represented by the term with gain $K_{i}$. This action is present if $K_{i} \\neq 0$. Given the constraint $K_{i} \\ge 0$, this means $K_{i} > 0$.\nIf $K_{i} > 0$, then for the product $K_{i}e_{\\mathrm{ss}}^{(PI)}$ to be zero, it must be that $e_{\\mathrm{ss}}^{(PI)} = 0$.\nTherefore, provided the system is stable and the integral gain $K_{i}$ is strictly positive, the PI controller will drive the steady-state tracking error to zero, perfectly rejecting the constant disturbance $d$ and tracking the setpoint $r$.\nIf $K_{i} = 0$, the controller degenerates to a P controller, and the error is given by the expression derived in the first part. The problem, however, asks for the error under PI control, which by convention implies the presence of integral action, i.e., $K_{i} > 0$. Under this condition, the error is eliminated.\nThus, the steady-state error under PI control is $e_{\\mathrm{ss}}^{(PI)} = 0$.\n\nThe final answer consists of the two derived expressions for the steady-state errors.\nFor P control: $e_{\\mathrm{ss}}^{(P)} = \\frac{k_{b}(r - b_{0}) - d}{k_{b} + S_{p} K_{p}}$.\nFor PI control (with $K_{i} > 0$): $e_{\\mathrm{ss}}^{(PI)} = 0$.", "answer": "$$\n\\boxed{\n\\begin{bmatrix}\n\\frac{k_{b}(r - b_{0}) - d}{k_{b} + S_{p} K_{p}} & 0\n\\end{bmatrix}\n}\n$$", "id": "2712643"}]}