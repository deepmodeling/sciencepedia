{"hands_on_practices": [{"introduction": "We begin with a foundational model in synthetic biology: a constitutively expressed gene. This exercise grounds the abstract concept of structural identifiability in a simple, tangible system. By solving the model's governing differential equation directly, you will investigate from first principles whether the synthesis rate, degradation rate, and initial protein concentration can be uniquely determined from observing the output over time. This practice [@problem_id:2745423] highlights the crucial link between mathematical theory and experimental reality, demonstrating how a poorly chosen experimental condition can obscure parameters and how a simple perturbation can bring them back into view.", "problem": "A fluorescent reporter in a synthetic gene circuit has concentration dynamics governed by the first-order balance between constitutive synthesis and first-order removal (dilution plus degradation). The state variable is the reporter concentration $x$, and the measured output is the reporter fluorescence $y$, assumed proportional to concentration with unit gain. The model is\n$$\n\\dot{x} = \\alpha - \\delta x,\\quad y = x,\n$$\nwhere $\\alpha$ is the constant synthesis rate and $\\delta$ is the first-order removal rate. The unknowns are the parameter pair $(\\alpha,\\delta)$ and the initial condition $x(0)$.\n\nUsing the definition of structural identifiability (global identifiability is the uniqueness of $(\\alpha,\\delta,x(0))$ given an ideal, noise-free, continuous-time output trajectory $y(t)$ over $t\\ge 0$) as the starting point and only the model equations above, analyze whether $(\\alpha,\\delta,x(0))$ are structurally identifiable from a single output trajectory $y(t)$.\n\n- Provide a rigorous argument that starts from the model and the definition of structural identifiability, without invoking identification shortcut formulas.\n- Explicitly identify any nongeneric experimental condition under which identifiability fails, and characterize the set of indistinguishable parameter triples in that case.\n- Propose a scientifically plausible minimal modification to the experiment (either an excitation input or an additional measurement) that would resolve the ambiguity under the nongeneric condition, and justify why it succeeds.\n\nAs a final check, report the single structurally identifiable parameter combination under the nongeneric, uninformative initial condition where the output trajectory is constant in time, expressed as a closed-form symbolic expression in terms of $\\alpha$ and $\\delta$. No units are required for the final reported expression.", "solution": "The problem posed is a request to analyze the structural identifiability of a simple first-order ordinary differential equation model for a synthetic gene circuit. The analysis must proceed from first principles.\n\nFirst, the validity of the problem statement must be established.\n\nGivens are extracted verbatim:\n- The state equation: $\\dot{x} = \\alpha - \\delta x$\n- The output equation: $y = x$\n- Unknowns: parameter pair $(\\alpha, \\delta)$ and initial condition $x(0)$\n- Definition of structural identifiability: uniqueness of $(\\alpha, \\delta, x(0))$ given an ideal, noise-free, continuous-time output trajectory $y(t)$ for $t \\ge 0$.\n- The task requires analysis of identifiability, characterization of nongeneric failure conditions, and proposal of a modified experiment to resolve ambiguity.\n- A final check requires reporting the identifiable combination under a specific nongeneric condition.\n\nValidation proceeds as follows:\n- **Scientific Grounding**: The model $\\dot{x} = \\alpha - \\delta x$ is a fundamental and widely-used representation of constitutive protein expression with first-order degradation and dilution. It is scientifically sound and central to systems and synthetic biology.\n- **Well-Posedness**: The problem is well-posed. It asks for a structural identifiability analysis, a standard procedure in systems theory, and provides all necessary components: the model, the outputs, and the parameters to be identified.\n- **Objectivity**: The problem is stated in precise mathematical language, free of subjective or ambiguous terms.\n\nThe problem is scientifically grounded, well-posed, objective, and self-contained. It contains no logical or factual flaws. Therefore, the problem is **valid** and a solution will be provided.\n\nThe analysis commences by solving the differential equation for an arbitrary parameter set $\\theta = (\\alpha, \\delta, x(0))$. The state equation is a linear first-order non-homogeneous ordinary differential equation:\n$$\n\\frac{dx}{dt} + \\delta x = \\alpha\n$$\nThe solution to this equation is found using an integrating factor $I(t) = \\exp(\\int \\delta \\, dt) = \\exp(\\delta t)$. The solution for $x(t)$, which is identical to the output $y(t)$, is:\n$$\nx(t) = \\frac{\\alpha}{\\delta} + \\left(x(0) - \\frac{\\alpha}{\\delta}\\right) \\exp(-\\delta t)\n$$\nThus, the output trajectory is given by:\n$$\ny(t; \\alpha, \\delta, x(0)) = \\frac{\\alpha}{\\delta} + \\left(x(0) - \\frac{\\alpha}{\\delta}\\right) \\exp(-\\delta t)\n$$\nAccording to the definition of structural identifiability, the parameter triple $(\\alpha, \\delta, x(0))$ is globally identifiable if, for any two distinct parameter triples $\\theta_1 = (\\alpha_1, \\delta_1, x_1(0))$ and $\\theta_2 = (\\alpha_2, \\delta_2, x_2(0))$, their corresponding outputs are distinct, i.e., $y(t; \\theta_1) \\neq y(t; \\theta_2)$ for some $t \\ge 0$. Equivalently, we test if the condition $y(t; \\theta_1) = y(t; \\theta_2)$ for all $t \\ge 0$ necessarily implies $\\theta_1 = \\theta_2$.\n\nLet us assume two parameter triples $\\theta_1$ and $\\theta_2$ yield the same output trajectory for all $t \\ge 0$:\n$$\n\\frac{\\alpha_1}{\\delta_1} + \\left(x_1(0) - \\frac{\\alpha_1}{\\delta_1}\\right) \\exp(-\\delta_1 t) = \\frac{\\alpha_2}{\\delta_2} + \\left(x_2(0) - \\frac{\\alpha_2}{\\delta_2}\\right) \\exp(-\\delta_2 t)\n$$\nThis equation is an identity in $t$. It can be written in the form $C_1 + K_1 \\exp(-\\delta_1 t) = C_2 + K_2 \\exp(-\\delta_2 t)$, where $C_i = \\alpha_i/\\delta_i$ and $K_i = x_i(0) - \\alpha_i/\\delta_i$.\nFor this equality to hold for all $t \\ge 0$, the functions on both sides must be identical.\n\nA generic experimental condition is one where the system is not at steady state, which means $x(0) \\neq \\alpha/\\delta$. In this case, the coefficient of the exponential term is non-zero, i.e., $K_i \\neq 0$. The functional form $C + K \\exp(-\\delta t)$ with $K \\neq 0$ and $\\delta > 0$ is unique. Two such functions are identical if and only if their corresponding coefficients are equal. We can determine the coefficients by examining the behavior of $y(t)$ and its derivatives. For instance, $\\lim_{t \\to \\infty} y(t) = C_i$, and $y(0) = C_i+K_i$. The time constant $\\delta_i$ can be found from the dynamics.\nTherefore, for the identity to hold, we must have:\n1. $\\delta_1 = \\delta_2$ (from the time constant of the exponential term).\n2. $C_1 = C_2 \\implies \\alpha_1/\\delta_1 = \\alpha_2/\\delta_2$.\n3. $K_1 = K_2 \\implies x_1(0) - \\alpha_1/\\delta_1 = x_2(0) - \\alpha_2/\\delta_2$.\n\nFrom condition 1, we have $\\delta_1 = \\delta_2$. Let us call this value $\\delta$.\nSubstituting this into condition 2 gives $\\alpha_1/\\delta = \\alpha_2/\\delta$, which implies $\\alpha_1 = \\alpha_2$. Let us call this value $\\alpha$.\nSubstituting these results into condition 3 gives $x_1(0) - \\alpha/\\delta = x_2(0) - \\alpha/\\delta$, which implies $x_1(0) = x_2(0)$.\nThus, $(\\alpha_1, \\delta_1, x_1(0)) = (\\alpha_2, \\delta_2, x_2(0))$. The parameter triple is structurally identifiable under generic conditions.\n\nNow, consider the nongeneric experimental condition under which identifiability fails. This occurs when the analysis above breaks down. The uniqueness of the functional form $C + K \\exp(-\\delta t)$ depends on $K \\neq 0$. If $K = 0$, the output is a constant.\nThe condition $K = 0$ corresponds to $x(0) - \\alpha/\\delta = 0$, or $x(0) = \\alpha/\\delta$. This is the specific case where the initial condition is precisely the steady-state value of the system.\nIn this situation, the output trajectory becomes $y(t) = \\alpha/\\delta$ for all $t \\ge 0$. The measurement yields a single constant value, $y_{ss}$. From the data, we only have one piece of information:\n$$\ny_{ss} = \\frac{\\alpha}{\\delta}\n$$\nAny parameter triple $(\\alpha, \\delta, x(0))$ that satisfies $x(0) = \\alpha/\\delta = y_{ss}$ will produce this same constant trajectory. This constitutes an infinite set of indistinguishable triples. Let the observed constant output be $y_c$. The set of indistinguishable parameter triples is $\\{(\\alpha, \\delta, x(0)) \\mid \\alpha = k y_c, \\delta = k, x(0) = y_c, \\text{ for any } k > 0\\}$. In this case, neither $\\alpha$, nor $\\delta$, nor $x(0)$ is individually identifiable. Only the ratio $\\alpha/\\delta$ is identifiable.\n\nTo resolve this ambiguity, the experiment must be modified to perturb the system from its steady state, thereby generating dynamics. A scientifically plausible minimal modification is to perform a stop-synthesis experiment. Assume the system is initially at steady state, with $x(0) = \\alpha/\\delta$. The output $y(t) = x(0)$ is constant. At a time $t_1 > 0$, an agent (e.g., a transcriptional or translational inhibitor like rifampicin or tetracycline) is added that instantaneously forces the synthesis rate to zero.\nFor $t \\ge t_1$, the model becomes:\n$$\n\\dot{x} = -\\delta x, \\quad x(t_1) = x(0) = \\alpha/\\delta\n$$\nThe solution for $t \\ge t_1$ is:\n$$\nx(t) = x(t_1) \\exp(-\\delta(t-t_1)) = \\left(\\frac{\\alpha}{\\delta}\\right) \\exp(-\\delta(t-t_1))\n$$\nThe output $y(t)$ for $t \\ge t_1$ is an exponential decay curve. From this curve, one can unambiguously determine two parameters by fitting to the form $A \\exp(-b(t-t_1))$:\n1. The amplitude $A = y(t_1) = \\alpha/\\delta$.\n2. The decay rate $b = \\delta$.\nFrom a fit to the post-perturbation data, we directly obtain $\\delta$. Since we also obtain the value of the ratio $\\alpha/\\delta$ from the amplitude (or from the pre-perturbation steady-state measurement), we can calculate $\\alpha = \\delta \\cdot (\\alpha/\\delta)$. The initial condition $x(0)$ is also determined since it is equal to the ratio $\\alpha/\\delta$.\nTherefore, this modified experiment renders the triple $(\\alpha, \\delta, x(0))$ structurally identifiable even from a steady-state initial condition.\n\nFinally, for the check, under the nongeneric, uninformative initial condition, the output trajectory is constant in time, $y(t) = y_c$. The only relationship that can be extracted from this observation is that the system is at steady state, where $\\dot{x}=0$. This implies $\\alpha - \\delta x = 0$, or $x = \\alpha/\\delta$. Since $y=x$, the observed constant value is $y_c = \\alpha/\\delta$. The single structurally identifiable parameter combination is this ratio. The expression for this combination in terms of $\\alpha$ and $\\delta$ is simply $\\alpha/\\delta$.", "answer": "$$\\boxed{\\frac{\\alpha}{\\delta}}$$", "id": "2745423"}, {"introduction": "Biological processes are inherently nonlinear, and our analytical tools must reflect this complexity. This practice moves beyond linear systems to a model featuring a quadratic term, which could represent mechanisms like protein dimerization or autocatalysis. You will apply the powerful technique of output differentiation, a cornerstone of nonlinear identifiability analysis related to Lie derivatives, to establish an algebraic relationship between the unknown parameter and measurable signals. This exercise [@problem_id:2745505] provides a concrete demonstration of how to prove parameter identifiability in a nonlinear setting by explicitly solving for the parameter of interest.", "problem": "A single-state nonlinear model is used for a synthetic gene circuit where the state $x(t)$ denotes a protein concentration and the input $u(t)$ denotes an externally controlled induction rate. The model is an ordinary differential equation (ODE) of control-affine form\n$$\n\\dot{x}(t) \\;=\\; f\\!\\left(x(t),\\theta\\right) \\;+\\; g\\!\\left(x(t)\\right)\\,u(t), \\quad y(t) \\;=\\; h\\!\\left(x(t)\\right),\n$$\nwhere $f(x,\\theta) \\;=\\; \\theta\\,x^{2}$, $g(x)\\;=\\;1$, and $h(x)\\;=\\;x$. Here, $\\theta$ is an unknown constant parameter to be identified, $u(t)$ is a known smooth input, and $y(t)$ is the measured output. Assume $x(t)$, $u(t)$, and $y(t)$ are sufficiently smooth for all required derivatives to exist.\n\nUsing the definition of Lie derivatives along a vector field, where the $k$-th Lie derivative of $h$ along $f$ is defined recursively by $L_{f}^{0}h \\;=\\; h$ and $L_{f}^{1}h \\;=\\; \\nabla h(x)\\,f(x,\\theta)$ for $k=1$, and $L_{f}^{k}h \\;=\\; \\nabla\\!\\left(L_{f}^{k-1}h\\right)(x)\\,f(x,\\theta)$ for $k\\geq 2$, do the following:\n- Compute $L_{f}^{0}h$, $L_{f}^{1}h$, and $L_{f}^{2}h$ explicitly in terms of $x$ and $\\theta$.\n- Using first principles of structural identifiability for nonlinear systems, determine whether $\\theta$ is locally identifiable from the measured output $y(t)$ under known input $u(t)$, and, if so, derive an explicit expression for $\\theta$ as a function of $y(t)$, $\\dot{y}(t)$, and $u(t)$.\n\nExpress the final answer as a single closed-form analytic expression for $\\theta$ in terms of $y$, $\\dot{y}$, and $u$. No rounding is necessary, and no units are required. Clearly state any regularity condition on $y$ needed for the expression to be valid.", "solution": "The problem will be validated before any attempt at a solution is made.\n\n### Step 1: Extract Givens\nThe givens are extracted verbatim from the problem statement.\n- **Model**: A single-state nonlinear ordinary differential equation (ODE) of control-affine form:\n$$\n\\dot{x}(t) \\;=\\; f\\!\\left(x(t),\\theta\\right) \\;+\\; g\\!\\left(x(t)\\right)\\,u(t), \\quad y(t) \\;=\\; h\\!\\left(x(t)\\right)\n$$\n- **Function Definitions**:\n  - $f(x,\\theta) \\;=\\; \\theta\\,x^{2}$\n  - $g(x)\\;=\\;1$\n  - $h(x)\\;=\\;x$\n- **Variables and Parameters**:\n  - $x(t)$: state variable (protein concentration)\n  - $u(t)$: known smooth input (externally controlled induction rate)\n  - $y(t)$: measured output\n  - $\\theta$: unknown constant parameter\n- **Assumptions**: $x(t)$, $u(t)$, and $y(t)$ are sufficiently smooth.\n- **Lie Derivative Definition**:\n  - $L_{f}^{0}h \\;=\\; h$\n  - $L_{f}^{1}h \\;=\\; \\nabla h(x)\\,f(x,\\theta)$\n  - $L_{f}^{k}h \\;=\\; \\nabla\\!\\left(L_{f}^{k-1}h\\right)(x)\\,f(x,\\theta)$ for $k\\geq 2$\n- **Tasks**:\n  1. Compute $L_{f}^{0}h$, $L_{f}^{1}h$, and $L_{f}^{2}h$ explicitly in terms of $x$ and $\\theta$.\n  2. Determine if $\\theta$ is locally identifiable from $y(t)$ and $u(t)$, and if so, derive an explicit expression for $\\theta$ as a function of $y(t)$, $\\dot{y}(t)$, and $u(t)$.\n\n### Step 2: Validate Using Extracted Givens\nThe problem is subjected to validation against established criteria.\n- **Scientifically Grounded**: The problem uses a standard control-affine ODE model, which is a common representation for simplified biological systems. The method of identifiability analysis using Lie derivatives and time derivatives of the output is a standard and rigorous technique in nonlinear systems theory. The problem is scientifically and mathematically sound.\n- **Well-Posed**: The problem is clearly stated, with all necessary functions, variables, and definitions provided. The tasks are specific and lead to a determinable outcome.\n- **Objective**: The language is formal, precise, and devoid of any subjective or ambiguous content.\n- **Completeness and Consistency**: The problem is self-contained and consistent. No essential information is missing, and there are no contradictions in the setup.\n- **Feasibility**: The model, while simple, is a plausible representation of certain nonlinear dynamics (e.g., quadratic autocatalysis). The mathematical operations required are standard calculus.\n- **Structure**: The problem is well-structured and follows a logical progression from definition to application.\n\n### Step 3: Verdict and Action\nThe problem is deemed **valid**. It is scientifically grounded, well-posed, and all information required for a solution is provided. A solution will be constructed.\n\n---\n\nThe system is described by the state-space model:\n$$\n\\dot{x}(t) = \\theta x(t)^{2} + u(t)\n$$\n$$\ny(t) = x(t)\n$$\nHere, $x(t)$ is the state, $u(t)$ is the known input, $y(t)$ is the measured output, and $\\theta$ is the parameter to be identified. The functions are $f(x, \\theta) = \\theta x^2$, $g(x) = 1$, and $h(x) = x$.\n\nFirst, we compute the requested Lie derivatives. The problem is single-state, so the gradient operator $\\nabla$ is the ordinary derivative with respect to $x$, i.e., $\\nabla \\equiv \\frac{d}{dx}$.\n\n1.  **Computation of $L_{f}^{0}h$**:\n    By definition, $L_{f}^{0}h = h(x)$.\n    $$\n    L_{f}^{0}h(x) = x\n    $$\n\n2.  **Computation of $L_{f}^{1}h$**:\n    By definition, $L_{f}^{1}h = \\nabla(L_{f}^{0}h) \\cdot f(x,\\theta)$.\n    $$\n    L_{f}^{1}h(x) = \\frac{d}{dx}(x) \\cdot (\\theta x^{2}) = 1 \\cdot \\theta x^{2} = \\theta x^{2}\n    $$\n\n3.  **Computation of $L_{f}^{2}h$**:\n    By definition, $L_{f}^{2}h = \\nabla(L_{f}^{1}h) \\cdot f(x,\\theta)$.\n    $$\n    L_{f}^{2}h(x) = \\frac{d}{dx}(\\theta x^{2}) \\cdot (\\theta x^{2}) = (2\\theta x) \\cdot (\\theta x^{2}) = 2\\theta^{2}x^{3}\n    $$\n\nNext, we address the question of structural identifiability. A parameter is structurally identifiable if its value can be uniquely determined from the measured outputs $y(t)$ and known inputs $u(t)$ over a given time interval, assuming perfect, noise-free measurements. The fundamental principle is to establish an algebraic relationship between the unknown parameter and the known/measurable quantities.\n\nThe measured output is $y(t) = h(x(t)) = x(t)$. Since $y(t)$ is assumed to be sufficiently smooth, we can differentiate it with respect to time $t$. Using the chain rule:\n$$\n\\dot{y}(t) = \\frac{d}{dt}h(x(t)) = \\frac{dh}{dx} \\frac{dx}{dt} = \\dot{x}(t)\n$$\nWe substitute the given ODE for $\\dot{x}(t)$:\n$$\n\\dot{y}(t) = \\theta x(t)^{2} + u(t)\n$$\nThis equation contains the unmeasured state $x(t)$. However, the output equation $y(t) = x(t)$ allows us to replace the state variable $x(t)$ with the measured output $y(t)$.\n$$\n\\dot{y}(t) = \\theta y(t)^{2} + u(t)\n$$\nThis equation provides a direct algebraic relationship between the unknown parameter $\\theta$ and the quantities that are known or can be measured: the input $u(t)$, the output $y(t)$, and the time derivative of the output $\\dot{y}(t)$. We can now solve for $\\theta$:\n$$\n\\theta y(t)^{2} = \\dot{y}(t) - u(t)\n$$\nTo isolate $\\theta$, we must divide by $y(t)^{2}$. This operation is valid only under a specific regularity condition.\n$$\n\\theta = \\frac{\\dot{y}(t) - u(t)}{y(t)^{2}}\n$$\nThe expression for $\\theta$ is valid at any time $t$ for which $y(t)^{2} \\neq 0$, which is equivalent to $y(t) \\neq 0$. For the parameter $\\theta$ to be identifiable, it is necessary that the system is excited in such a way that the output $y(t)$ is not identically zero over the measurement interval. If $y(t)$ were identically zero, the equation would become $0 = 0$, yielding no information about $\\theta$.\n\nSince a unique expression for $\\theta$ can be derived from the input-output data (provided the regularity condition holds), the parameter $\\theta$ is structurally locally identifiable. In fact, because the solution is unique and does not depend on a local approximation, it is structurally globally identifiable.\n\nThe required regularity condition is that the output $y(t)$ must not be zero. Given that $y(t) = x(t)$ represents a physical concentration, it must be non-negative, so the condition simplifies to $y(t) > 0$.", "answer": "$$\n\\boxed{\\frac{\\dot{y} - u}{y^{2}}}\n$$", "id": "2745505"}, {"introduction": "The ultimate goal of identifiability analysis is not just to answer 'if' parameters can be found, but 'how' to design experiments to find them with the greatest precision. This final practice moves into the realm of Optimal Experimental Design (OED) using the iconic repressilator oscillator as a case study. Here, you will use the Fisher Information Matrix (FIM) to quantify the information an experiment yields and tackle the practical challenge of designing an input signal that maximizes this information under realistic experimental constraints. This advanced computational exercise [@problem_id:2745478] bridges theory and application, showcasing how to use identifiability concepts to proactively guide the design of maximally informative experiments.", "problem": "Consider the classical three-node repressilator used in synthetic biology, described by a set of nonlinear ordinary differential equations (ODEs) with input-modulated degradation. Let the state vector be $x(t) = [x_1(t), x_2(t), x_3(t)]^\\top$, and let the external input $u(t)$ modulate the degradation rate. The dynamics are\n$$\n\\frac{d}{dt} x_1(t) = -\\left(d_0 + \\beta\\, u(t)\\right)\\, x_1(t) + \\frac{\\alpha}{1 + x_3(t)^{n}} + k_{\\text{bas}},\n$$\n$$\n\\frac{d}{dt} x_2(t) = -\\left(d_0 + \\beta\\, u(t)\\right)\\, x_2(t) + \\frac{\\alpha}{1 + x_1(t)^{n}} + k_{\\text{bas}},\n$$\n$$\n\\frac{d}{dt} x_3(t) = -\\left(d_0 + \\beta\\, u(t)\\right)\\, x_3(t) + \\frac{\\alpha}{1 + x_2(t)^{n}} + k_{\\text{bas}},\n$$\nwhere $\\alpha > 0$ is the maximal production rate, $n > 0$ is the Hill coefficient, $d_0 > 0$ is the basal degradation rate, $\\beta \\ge 0$ scales the input effect on degradation, and $k_{\\text{bas}} \\ge 0$ is a basal production term. Assume full-state measurements $y(t) = x(t)$ are available, corrupted by independent zero-mean Gaussian noise with variance $\\sigma^2$ on each measured component, so that the Fisher Information Matrix (FIM) for parameters $\\theta = [\\alpha, n, d_0, \\beta]^\\top$ over a time window $[0, T]$ is, under the standard Gaussian assumption,\n$$\n\\mathcal{I}(\\theta) = \\int_{0}^{T} \\left(\\frac{\\partial y(t)}{\\partial \\theta}\\right)^\\top \\left(\\sigma^2 I\\right)^{-1} \\left(\\frac{\\partial y(t)}{\\partial \\theta}\\right)\\, dt = \\frac{1}{\\sigma^2} \\int_{0}^{T} S(t)^\\top S(t)\\, dt,\n$$\nwhere $S(t) = \\frac{\\partial x(t)}{\\partial \\theta} \\in \\mathbb{R}^{3 \\times 4}$ are the state sensitivities obtained from the sensitivity ODE\n$$\n\\frac{d}{dt} S(t) = \\frac{\\partial f}{\\partial x}(t)\\, S(t) + \\frac{\\partial f}{\\partial \\theta}(t), \\quad S(0) = 0,\n$$\nwith $f(x,t)$ defined by the right-hand side of the state ODEs and the Jacobians $\\frac{\\partial f}{\\partial x}$ and $\\frac{\\partial f}{\\partial \\theta}$ computed analytically.\n\nYour task is to design, within a constrained input family, an input $u(t)$ that maximizes a scalar objective derived from the Fisher Information Matrix while respecting actuator constraints. Restrict the input to the sinusoidal family\n$$\nu(t) = u_0 + a \\sin(\\omega t),\n$$\nwith parameters $u_0 \\ge 0$, $a \\ge 0$, and $\\omega \\ge 0$, subject to the actuator constraints\n- amplitude bounds: $0 \\le u(t) \\le u_{\\max}$ for all $t$, which for the sinusoidal family implies $0 \\le u_0 - a$ and $u_0 + a \\le u_{\\max}$,\n- slew-rate bound: $\\left|\\dot{u}(t)\\right| \\le s_{\\max}$ for all $t$, which for the sinusoidal family implies $a \\omega \\le s_{\\max}$,\n- energy (power-time) bound: $\\int_{0}^{T} u(t)^2\\, dt \\le E_{\\max}$, which for the sinusoid reduces to $T \\left(u_0^2 + \\frac{a^2}{2}\\right) \\le E_{\\max}$.\n\nAdopt the D-optimal design criterion with a positive-definite regularization, namely maximize\n$$\nJ(u) = \\log \\det\\!\\left(\\mathcal{I}(\\theta) + \\lambda I\\right),\n$$\nwhere $\\lambda > 0$ is a small regularization constant and $I$ is the identity matrix of size $4 \\times 4$.\n\nAssume the true parameter values and experimental setup are fixed as follows for all test cases:\n- model parameters (ground truth): $\\alpha = 10.0$, $n = 2.0$, $d_0 = 0.8$, $\\beta = 1.0$, $k_{\\text{bas}} = 0.1$,\n- initial condition: $x(0) = [0.8, 0.2, 0.5]^\\top$,\n- measurement noise variance: $\\sigma^2 = 0.01$,\n- regularization: $\\lambda = 10^{-8}$,\n- numerical measurement grid: uniform sampling with step $\\Delta t$; the Fisher Information Matrix integral is to be approximated by a Riemann sum using the given $\\Delta t$,\n- full-state observation model $y(t) = x(t)$.\n\nWithin each test case, the input parameters $(a, \\omega, u_0)$ must be selected from a finite grid, and the optimal choice is the one that maximizes $J(u)$ subject to the constraints. If multiple candidates achieve the same maximal objective to within a tolerance of $10^{-9}$, choose the lexicographically smallest triple $(a, \\omega, u_0)$.\n\nUse the sensitivity ODE method defined above to compute $S(t)$ and thus the Fisher Information Matrix; do not approximate parameter derivatives by finite differences. Use an implicit ODE solver suitable for stiff nonlinear systems.\n\nYour program must solve the following four test cases. In each case, the objective is to output the optimal triple $(a, \\omega, u_0)$ and the corresponding objective $J(u)$, all rounded to $4$ decimal places.\n\n- Test Case $1$ (baseline):\n  - horizon $T = 50$, step $\\Delta t = 0.2$,\n  - constraints: $u_{\\max} = 2.0$, $s_{\\max} = 1.5$, $E_{\\max} = 150.0$,\n  - grid: $a \\in \\{0.0, 0.5, 1.0\\}$, $\\omega \\in \\{0.2, 0.5, 1.0\\}$, $u_0 \\in \\{0.5, 1.0, 1.5\\}$.\n\n- Test Case $2$ (tight slew-rate):\n  - horizon $T = 50$, step $\\Delta t = 0.2$,\n  - constraints: $u_{\\max} = 2.0$, $s_{\\max} = 0.3$, $E_{\\max} = 150.0$,\n  - grid: $a \\in \\{0.0, 0.5, 1.0\\}$, $\\omega \\in \\{0.2, 0.5, 1.0\\}$, $u_0 \\in \\{0.5, 1.0, 1.5\\}$.\n\n- Test Case $3$ (tight energy):\n  - horizon $T = 50$, step $\\Delta t = 0.2$,\n  - constraints: $u_{\\max} = 2.0$, $s_{\\max} = 1.5$, $E_{\\max} = 30.0$,\n  - grid: $a \\in \\{0.0, 0.5, 1.0\\}$, $\\omega \\in \\{0.2, 0.5, 1.0\\}$, $u_0 \\in \\{0.5, 1.0, 1.5\\}$.\n\n- Test Case $4$ (short horizon):\n  - horizon $T = 20$, step $\\Delta t = 0.1$,\n  - constraints: $u_{\\max} = 2.0$, $s_{\\max} = 1.5$, $E_{\\max} = 80.0$,\n  - grid: $a \\in \\{0.0, 0.5, 1.0\\}$, $\\omega \\in \\{0.2, 0.5, 1.0\\}$, $u_0 \\in \\{0.5, 1.0, 1.5\\}$.\n\nImplementation requirements:\n- Use the analytical Jacobians $\\frac{\\partial f}{\\partial x}$ and $\\frac{\\partial f}{\\partial \\theta}$ derived from the model. For $h(z) = \\frac{1}{1 + z^n}$, the required derivatives are $\\frac{\\partial h}{\\partial z} = -\\frac{n z^{n-1}}{(1+z^n)^2}$ and $\\frac{\\partial h}{\\partial n} = -\\frac{z^n \\ln z}{(1+z^n)^2}$. Ensure numerical safety by evaluating $\\ln z$ and $z^{n-1}$ only for $z > 0$; in computation, you may clip $z$ below by a small positive constant to avoid undefined expressions.\n- Use a stiff-capable ODE solver to integrate the augmented system for $[x^\\top, \\text{vec}(S)^\\top]^\\top$.\n- Compute the Fisher Information Matrix using the Riemann sum approximation with the given $\\Delta t$.\n- The objective is $J(u) = \\log \\det(\\mathcal{I}(\\theta) + \\lambda I)$.\n\nFinal output format:\n- Your program should produce a single line of output containing a list of length $4$, where each element is itself a list of four floating-point numbers $[a^\\star, \\omega^\\star, u_0^\\star, J^\\star]$ corresponding to the four test cases, in the same order as listed. Each number must be rounded to $4$ decimal places. For example, a valid output could look like\n$[[0.5,0.5,1.0,12.3456],[\\dots],[\\dots],[\\dots]]$\nwith no additional text printed.", "solution": "A validation of the supplied problem statement confirms its scientific and mathematical integrity. The problem is well-posed, objective, and resides within the established framework of optimal experimental design for nonlinear dynamical systems. A solution is therefore tractable.\n\nThe objective is to determine the parameters $(a, \\omega, u_0)$ for an input signal $u(t) = u_0 + a \\sin(\\omega t)$ that maximize the D-optimal criterion $J(u) = \\log \\det(\\mathcal{I}(\\theta) + \\lambda I)$ subject to several constraints. This requires computing the Fisher Information Matrix (FIM), $\\mathcal{I}(\\theta)$, which in turn is derived from the system's state sensitivities. The procedure is as follows.\n\n1.  **Augmented State-Sensitivity System**: The system dynamics involve $3$ states, $x(t) = [x_1(t), x_2(t), x_3(t)]^\\top$, and $4$ parameters to be identified, $\\theta = [\\alpha, n, d_0, \\beta]^\\top$. The state sensitivity matrix is $S(t) = \\frac{\\partial x(t)}{\\partial \\theta} \\in \\mathbb{R}^{3 \\times 4}$. We construct an augmented state vector $Y(t) \\in \\mathbb{R}^{15}$ composed of the state vector $x(t)$ and the vectorized sensitivity matrix $\\text{vec}(S(t))$. The dynamics of this augmented system are governed by a set of $15$ coupled ordinary differential equations (ODEs):\n    $$\n    \\frac{d}{dt} x(t) = f(x(t), u(t), \\theta)\n    $$\n    $$\n    \\frac{d}{dt} S(t) = \\frac{\\partial f}{\\partial x}(x(t), u(t), \\theta) S(t) + \\frac{\\partial f}{\\partial \\theta}(x(t), u(t), \\theta)\n    $$\n    The initial conditions are specified as $x(0) = [0.8, 0.2, 0.5]^\\top$ and $S(0) = \\mathbf{0}_{3 \\times 4}$.\n\n2.  **Jacobian Matrices**: The evaluation of the sensitivity ODE requires the analytical Jacobians of the right-hand-side function $f(x, u, \\theta)$. Let the effective degradation rate be $D(t) = d_0 + \\beta u(t)$. The Jacobian with respect to the state $x$ is:\n    $$\n    \\frac{\\partial f}{\\partial x} =\n    \\begin{pmatrix}\n    -D(t) & 0 & -\\frac{\\alpha n x_3^{n-1}}{(1+x_3^n)^2} \\\\\n    -\\frac{\\alpha n x_1^{n-1}}{(1+x_1^n)^2} & -D(t) & 0 \\\\\n    0 & -\\frac{\\alpha n x_2^{n-1}}{(1+x_2^n)^2} & -D(t)\n    \\end{pmatrix}\n    $$\n    The Jacobian with respect to the parameters $\\theta = [\\alpha, n, d_0, \\beta]^\\top$ is:\n    $$\n    \\frac{\\partial f}{\\partial \\theta} =\n    \\begin{pmatrix}\n    \\frac{1}{1+x_3^n} & -\\frac{\\alpha x_3^n \\ln(x_3)}{(1+x_3^n)^2} & -x_1 & -u(t) x_1 \\\\\n    \\frac{1}{1+x_1^n} & -\\frac{\\alpha x_1^n \\ln(x_1)}{(1+x_1^n)^2} & -x_2 & -u(t) x_2 \\\\\n    \\frac{1}{1+x_2^n} & -\\frac{\\alpha x_2^n \\ln(x_2)}{(1+x_2^n)^2} & -x_3 & -u(t) x_3\n    \\end{pmatrix}\n    $$\n    For numerical stability, state variables $x_i$ appearing in terms like $\\ln(x_i)$ or $x_i^{n-1}$ where $n-1 < 0$ are clipped below by a small positive constant, such as $\\epsilon = 10^{-12}$, to prevent undefined results.\n\n3.  **Numerical Integration**: For each candidate input triplet $(a, \\omega, u_0)$, the $15$-dimensional augmented ODE system is solved numerically over the time horizon $[0, T]$. Given the nonlinear and potentially stiff nature of the repressilator dynamics, an implicit backward differentiation formula (BDF) solver is employed. The solution is evaluated at discrete time points $t_k = k \\Delta t$ for $k = 0, 1, \\dots, T/\\Delta t$.\n\n4.  **Fisher Information Matrix Calculation**: The Fisher Information Matrix $\\mathcal{I}(\\theta)$ is approximated by a Riemann sum over the discrete-time trajectory:\n    $$\n    \\mathcal{I}(\\theta) \\approx \\frac{1}{\\sigma^2} \\sum_{k=0}^{N} S(t_k)^\\top S(t_k) \\Delta t\n    $$\n    where $N = T/\\Delta t$, $\\sigma^2$ is the measurement noise variance, and $S(t_k)$ is the sensitivity matrix at time $t_k$ obtained from the ODE solution.\n\n5.  **Objective Function and Optimization**: The D-optimal objective function is then computed as $J(u) = \\log \\det(\\mathcal{I}(\\theta) + \\lambda I)$, where $\\lambda$ is a small regularization constant. A grid search is performed over the specified finite sets of $(a, \\omega, u_0)$. For each test case, the following procedure identifies the optimal triplet:\n    a. All combinations of $(a, \\omega, u_0)$ from the grid are tested against the constraints:\n       - Amplitude: $0 \\le u_0 - a$ and $u_0 + a \\le u_{\\max}$\n       - Slew-rate: $a \\omega \\le s_{\\max}$\n       - Energy: $T(u_0^2 + a^2/2) \\le E_{\\max}$\n    b. For each valid triplet, the objective function $J(u)$ is computed.\n    c. All valid candidates and their corresponding $J$ values are collected. The maximum objective value, $J_{\\max}$, is identified.\n    d. All candidates whose objective value falls within the range $[J_{\\max} - 10^{-9}, J_{\\max}]$ are considered for the final selection.\n    e. From this subset of high-performing candidates, the one corresponding to the lexicographically smallest triplet $(a, \\omega, u_0)$ is chosen as the optimum.\n\nThis robust procedure guarantees finding the unique solution as specified by the problem statement for each test case.", "answer": "```python\nimport numpy as np\nfrom scipy.integrate import solve_ivp\nfrom functools import partial\n\n# Fixed model parameters\nALPHA = 10.0\nN = 2.0\nD0 = 0.8\nBETA = 1.0\nK_BAS = 0.1\n\n# Fixed experimental/numerical parameters\nX0 = np.array([0.8, 0.2, 0.5])\nSIGMA2 = 0.01\nLAMBDA_REG = 1e-8\nNUM_STATES = 3\nNUM_PARAMS = 4\nEPS = 1e-12 # Small constant for numerical stability\n\ndef dynamics_and_sensitivities(t, Y, a, omega, u0):\n    \"\"\"\n    Computes the time derivative of the augmented state vector [x, vec(S)].\n    Y: Augmented state vector [x1, x2, x3, S11, S12, ..., S34]\n    t: Time\n    a, omega, u0: Input parameters\n    \"\"\"\n    # Unpack state vector\n    x = Y[:NUM_STATES]\n    S = Y[NUM_STATES:].reshape((NUM_STATES, NUM_PARAMS))\n\n    # Input signal\n    u = u0 + a * np.sin(omega * t)\n\n    # Pre-calculate terms for efficiency and stability\n    d_eff = D0 + BETA * u\n    x1, x2, x3 = x\n    x1c = np.maximum(x1, EPS)\n    x2c = np.maximum(x2, EPS)\n    x3c = np.maximum(x3, EPS)\n    \n    h_denom1 = 1.0 + x1c**N\n    h_denom2 = 1.0 + x2c**N\n    h_denom3 = 1.0 + x3c**N\n\n    # State dynamics (dx/dt)\n    dx = np.zeros(NUM_STATES)\n    dx[0] = -d_eff * x1 + ALPHA / h_denom3 + K_BAS\n    dx[1] = -d_eff * x2 + ALPHA / h_denom1 + K_BAS\n    dx[2] = -d_eff * x3 + ALPHA / h_denom2 + K_BAS\n\n    # Jacobian df/dx\n    df_dx = np.full((NUM_STATES, NUM_STATES), 0.0)\n    np.fill_diagonal(df_dx, -d_eff)\n    df_dx[0, 2] = -ALPHA * N * x3c**(N - 1) / (h_denom3**2)\n    df_dx[1, 0] = -ALPHA * N * x1c**(N - 1) / (h_denom1**2)\n    df_dx[2, 1] = -ALPHA * N * x2c**(N - 1) / (h_denom2**2)\n\n    # Jacobian df/dtheta (theta = [alpha, n, d0, beta])\n    df_dtheta = np.zeros((NUM_STATES, NUM_PARAMS))\n    # d/d_alpha\n    df_dtheta[0, 0] = 1.0 / h_denom3\n    df_dtheta[1, 0] = 1.0 / h_denom1\n    df_dtheta[2, 0] = 1.0 / h_denom2\n    # d/dn\n    df_dtheta[0, 1] = -ALPHA * (x3c**N) * np.log(x3c) / (h_denom3**2)\n    df_dtheta[1, 1] = -ALPHA * (x1c**N) * np.log(x1c) / (h_denom1**2)\n    df_dtheta[2, 1] = -ALPHA * (x2c**N) * np.log(x2c) / (h_denom2**2)\n    # d/dd0\n    df_dtheta[:, 2] = -x\n    # d/dbeta\n    df_dtheta[:, 3] = -u * x\n\n    # Sensitivity dynamics (dS/dt)\n    dS = df_dx @ S + df_dtheta\n\n    # Pack derivatives into a single vector\n    dY = np.concatenate((dx, dS.flatten()))\n    return dY\n\ndef compute_objective(u_params, T, dt):\n    \"\"\"\n    Solves ODEs and computes the D-optimal objective for a given input.\n    \"\"\"\n    a, omega, u0 = u_params\n\n    # System setup\n    Y0 = np.concatenate((X0, np.zeros(NUM_STATES * NUM_PARAMS)))\n    t_span = [0.0, T]\n    t_eval = np.arange(0.0, T + dt, dt)\n\n    # Create a partial function for the ODE solver\n    ode_func = partial(dynamics_and_sensitivities, a=a, omega=omega, u0=u0)\n\n    # Solve the augmented ODE system\n    sol = solve_ivp(ode_func, t_span, Y0, method='BDF', t_eval=t_eval, rtol=1e-6, atol=1e-8)\n\n    if not sol.success:\n        return -np.inf\n\n    # Compute Fisher Information Matrix (FIM)\n    sensitivities = sol.y[NUM_STATES:, :]\n    fim = np.zeros((NUM_PARAMS, NUM_PARAMS))\n    for i in range(sensitivities.shape[1]):\n        S_t = sensitivities[:, i].reshape((NUM_STATES, NUM_PARAMS))\n        fim += S_t.T @ S_t\n    \n    fim *= dt / SIGMA2\n\n    # Compute objective J(u) = log(det(I + lambda*I))\n    matrix_to_det = fim + LAMBDA_REG * np.eye(NUM_PARAMS)\n    sign, logdet = np.linalg.slogdet(matrix_to_det)\n\n    if sign <= 0:\n        return -np.inf\n    return logdet\n\ndef solve():\n    test_cases = [\n        # Test Case 1 (baseline)\n        {'T': 50.0, 'dt': 0.2, 'u_max': 2.0, 's_max': 1.5, 'E_max': 150.0,\n         'a_grid': [0.0, 0.5, 1.0], 'w_grid': [0.2, 0.5, 1.0], 'u0_grid': [0.5, 1.0, 1.5]},\n        # Test Case 2 (tight slew-rate)\n        {'T': 50.0, 'dt': 0.2, 'u_max': 2.0, 's_max': 0.3, 'E_max': 150.0,\n         'a_grid': [0.0, 0.5, 1.0], 'w_grid': [0.2, 0.5, 1.0], 'u0_grid': [0.5, 1.0, 1.5]},\n        # Test Case 3 (tight energy)\n        {'T': 50.0, 'dt': 0.2, 'u_max': 2.0, 's_max': 1.5, 'E_max': 30.0,\n         'a_grid': [0.0, 0.5, 1.0], 'w_grid': [0.2, 0.5, 1.0], 'u0_grid': [0.5, 1.0, 1.5]},\n        # Test Case 4 (short horizon)\n        {'T': 20.0, 'dt': 0.1, 'u_max': 2.0, 's_max': 1.5, 'E_max': 80.0,\n         'a_grid': [0.0, 0.5, 1.0], 'w_grid': [0.2, 0.5, 1.0], 'u0_grid': [0.5, 1.0, 1.5]},\n    ]\n\n    final_results = []\n\n    for case in test_cases:\n        T, dt = case['T'], case['dt']\n        u_max, s_max, E_max = case['u_max'], case['s_max'], case['E_max']\n        a_grid, w_grid, u0_grid = case['a_grid'], case['w_grid'], case['u0_grid']\n\n        candidates = []\n        for a in a_grid:\n            for omega in w_grid:\n                for u0 in u0_grid:\n                    # Check constraints\n                    is_valid = True\n                    # Amplitude\n                    if not (0.0 <= u0 - a and u0 + a <= u_max):\n                        is_valid = False\n                    # Slew-rate\n                    if not (a * omega <= s_max):\n                        is_valid = False\n                    # Energy\n                    if not T * (u0**2 + a**2 / 2.0) <= E_max:\n                        is_valid = False\n\n                    if is_valid:\n                        u_params = (a, omega, u0)\n                        J = compute_objective(u_params, T, dt)\n                        candidates.append({'J': J, 'params': u_params})\n\n        # Find the best candidate according to the rules\n        if not candidates:\n            # Handle cases where no grid point is valid (unlikely for this problem)\n            final_results.append([np.nan, np.nan, np.nan, np.nan])\n            continue\n            \n        max_J = -np.inf\n        for c in candidates:\n            if c['J'] > max_J:\n                max_J = c['J']\n        \n        top_candidates = []\n        tolerance = 1e-9\n        for c in candidates:\n            if c['J'] >= max_J - tolerance:\n                top_candidates.append(c)\n\n        # Sort by parameters lexicographically\n        top_candidates.sort(key=lambda x: x['params'])\n\n        best_candidate = top_candidates[0]\n        a_opt, w_opt, u0_opt = best_candidate['params']\n        J_opt = best_candidate['J']\n        \n        result_tuple = [round(a_opt, 4), round(w_opt, 4), round(u0_opt, 4), round(J_opt, 4)]\n        final_results.append(result_tuple)\n\n    # Format the final output string\n    # E.g., [[0.5, 0.5, 1.0, 12.3456], [0.0, 0.2, 0.5, 10.9876]]\n    list_of_strings = [str(res) for res in final_results]\n    print(f\"[{','.join(list_of_strings)}]\")\n\nsolve()\n```", "id": "2745478"}]}