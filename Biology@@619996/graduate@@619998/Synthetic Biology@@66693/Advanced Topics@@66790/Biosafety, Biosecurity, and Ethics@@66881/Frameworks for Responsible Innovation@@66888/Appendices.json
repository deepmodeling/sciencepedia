{"hands_on_practices": [{"introduction": "Effective responsible innovation requires moving beyond qualitative safety goals to quantitative risk assessment. This practice introduces Fault Tree Analysis (FTA), a powerful, top-down method for dissecting how a complex system can fail. By modeling an engineered kill-switch, you will learn to identify minimal failure pathways and quantify their probabilities, enabling a direct, evidence-based assessment of whether residual risk meets standards like 'As Low As Reasonably Practicable' (ALARP) [@problem_id:2739680].", "problem": "A biosafety program for a synthetic biology chassis employs a multi-modal engineered kill-switch intended to prevent organism survival and proliferation after accidental escape. To evaluate whether residual risk is within the As Low As Reasonably Practicable (ALARP) region, perform a fault tree analysis that explicitly quantifies minimal cut sets and derives the top-event probability.\n\nAssume the following:\n- The top event $\\mathcal{T}$ is “organism survives and proliferates outside containment.”\n- By design and standard biosafety doctrine, $\\mathcal{T}$ occurs if and only if all three of the following subsystem events occur: release $\\mathcal{E}$, kill-switch failure $\\mathcal{K}$, and environmental permissivity $\\mathcal{P}$. Thus $\\mathcal{T} = \\mathcal{E} \\land \\mathcal{K} \\land \\mathcal{P}$.\n- Subsystem event structures (fault tree logic) are:\n  - Release: $\\mathcal{E} = E_1 \\lor E_2$ where $E_1$ is a primary containment breach and $E_2$ is a procedural lapse.\n  - Kill-switch failure: $\\mathcal{K} = M \\lor I \\lor (S \\land F)$ where $M$ is mutational inactivation, $I$ is failure to induce the kill-switch, $S$ is loss of signal availability, and $F$ is sensor fault.\n  - Environmental permissivity: $\\mathcal{P} = N \\land W$ where $N$ is sufficient nutrient availability and $W$ is a suitable abiotic window (temperature and pH).\n- Basic events are independent across the tree and are rare enough that the rare-event approximation is valid. The per-day probabilities of basic events are:\n  - $p_{E_1} = 2 \\times 10^{-6}$, $p_{E_2} = 5 \\times 10^{-6}$,\n  - $p_{M} = 1 \\times 10^{-4}$, $p_{I} = 2 \\times 10^{-4}$, $p_{S} = 1 \\times 10^{-3}$, $p_{F} = 2 \\times 10^{-3}$,\n  - $p_{N} = 1 \\times 10^{-2}$, $p_{W} = 5 \\times 10^{-2}$.\n- Consequence magnitude per occurrence of $\\mathcal{T}$ is $C = 5.0 \\times 10^{6}$ biosafety harm units (BHU). The upper boundary of the ALARP region is $R_{U} = 1.0 \\times 10^{-6}$ BHU/day, and the lower boundary is $R_{L} = 1.0 \\times 10^{-8}$ BHU/day.\n- A mitigation is proposed that uniformly reduces each basic event within the kill-switch branch $\\mathcal{K}$ by a multiplicative factor $r \\geq 1$, without affecting other branches: $p_{M}^{\\prime} = p_{M}/r$, $p_{I}^{\\prime} = p_{I}/r$, $p_{S}^{\\prime} = p_{S}/r$, $p_{F}^{\\prime} = p_{F}/r$.\n\nUsing only probability axioms, Boolean logic for fault trees, and the rare-event approximation, do the following in order: enumerate the minimal cut sets of $\\mathcal{T}$; quantify their contributions to the top-event probability; and derive an analytic expression for the daily risk $R(r)$ in terms of $r$. Then, determine the minimal $r$ such that $R(r) \\leq R_{U}$, and report the value of $r$. Round your answer to three significant figures. The final reported $r$ is dimensionless.", "solution": "The problem requires a quantitative fault tree analysis to determine a necessary mitigation factor for a synthetic biology chassis. We will proceed by first establishing the logical structure of the top event, enumerating the minimal cut sets, calculating the baseline risk, deriving the risk as a function of the mitigation factor $r$, and finally solving for the minimum required value of $r$.\n\nThe problem states that \"per-day probabilities\" for basic events are given. We interpret this in the standard context of Probabilistic Risk Assessment (PRA), where for a small time interval $\\Delta t = 1$ day, the dimensionless probability of an event $p$ is numerically equal to its frequency $\\lambda$ in units of (day)$^{-1}$. The daily risk $R$, with units of biosafety harm units (BHU) per day, is then calculated as $R = \\lambda_{\\mathcal{T}} \\times C = (P(\\mathcal{T}) / \\Delta t) \\times C$, where $P(\\mathcal{T})$ is the dimensionless probability of the top event over the interval $\\Delta t$ and $C$ is the consequence magnitude. Given $\\Delta t = 1$ day, the numerical value of the daily risk is $R = P(\\mathcal{T}) \\times C$, with the required units of BHU/day.\n\nThe top event $\\mathcal{T}$ is defined by the logical expression:\n$$ \\mathcal{T} = \\mathcal{E} \\land \\mathcal{K} \\land \\mathcal{P} $$\nSubstituting the given subsystem event structures:\n$$ \\mathcal{T} = (E_1 \\lor E_2) \\land (M \\lor I \\lor (S \\land F)) \\land (N \\land W) $$\nwhere $\\land$ represents logical AND and $\\lor$ represents logical OR. Basic events $E_1, E_2, M, I, S, F, N, W$ are assumed to be statistically independent.\n\nFirst, we enumerate the minimal cut sets (MCS) of $\\mathcal{T}$. A cut set is a set of basic events whose simultaneous occurrence causes the top event. A minimal cut set is a cut set that cannot be reduced without losing its status as a cut set. By applying the distributive law of Boolean algebra to the expression for $\\mathcal{T}$, we find the minimal cut sets:\n$$ \\mathcal{T} = \\bigvee_{i \\in \\{1,2\\}, j \\in \\{M,I,SF\\}, k \\in \\{NW\\}} (E_i \\land j \\land k) $$\nThis expands to the following $6$ minimal cut sets:\n$1$. MCS$_1 = \\{E_1, M, N, W\\}$\n$2$. MCS$_2 = \\{E_1, I, N, W\\}$\n$3$. MCS$_3 = \\{E_1, S, F, N, W\\}$\n$4$. MCS$_4 = \\{E_2, M, N, W\\}$\n$5$. MCS$_5 = \\{E_2, I, N, W\\}$\n$6$. MCS$_6 = \\{E_2, S, F, N, W\\}$\n\nNext, we quantify the baseline probabilities (for $r=1$) of these minimal cut sets using the given per-day probabilities and the rare-event approximation, where the probability of a cut set is the product of the probabilities of its basic events.\nThe basic event probabilities are:\n$p_{E_1} = 2 \\times 10^{-6}$, $p_{E_2} = 5 \\times 10^{-6}$\n$p_{M} = 1 \\times 10^{-4}$, $p_{I} = 2 \\times 10^{-4}$, $p_{S} = 1 \\times 10^{-3}$, $p_{F} = 2 \\times 10^{-3}$\n$p_{N} = 1 \\times 10^{-2}$, $p_{W} = 5 \\times 10^{-2}$\n\nThe probability contributions are:\n$P(\\text{MCS}_1) = p_{E_1} p_{M} p_{N} p_{W} = (2 \\times 10^{-6})(1 \\times 10^{-4})(1 \\times 10^{-2})(5 \\times 10^{-2}) = 1 \\times 10^{-13}$\n$P(\\text{MCS}_2) = p_{E_1} p_{I} p_{N} p_{W} = (2 \\times 10^{-6})(2 \\times 10^{-4})(1 \\times 10^{-2})(5 \\times 10^{-2}) = 2 \\times 10^{-13}$\n$P(\\text{MCS}_3) = p_{E_1} p_{S} p_{F} p_{N} p_{W} = (2 \\times 10^{-6})(1 \\times 10^{-3})(2 \\times 10^{-3})(1 \\times 10^{-2})(5 \\times 10^{-2}) = 2 \\times 10^{-15}$\n$P(\\text{MCS}_4) = p_{E_2} p_{M} p_{N} p_{W} = (5 \\times 10^{-6})(1 \\times 10^{-4})(1 \\times 10^{-2})(5 \\times 10^{-2}) = 2.5 \\times 10^{-13}$\n$P(\\text{MCS}_5) = p_{E_2} p_{I} p_{N} p_{W} = (5 \\times 10^{-6})(2 \\times 10^{-4})(1 \\times 10^{-2})(5 \\times 10^{-2}) = 5 \\times 10^{-13}$\n$P(\\text{MCS}_6) = p_{E_2} p_{S} p_{F} p_{N} p_{W} = (5 \\times 10^{-6})(1 \\times 10^{-3})(2 \\times 10^{-3})(1 \\times 10^{-2})(5 \\times 10^{-2}) = 5 \\times 10^{-15}$\n\nUnder the rare-event approximation, the total probability of the top event $P(\\mathcal{T})$ is the sum of the probabilities of the minimal cut sets:\n$P(\\mathcal{T})_{\\text{baseline}} = \\sum_{i=1}^{6} P(\\text{MCS}_i) = (1 + 2 + 0.02 + 2.5 + 5 + 0.05) \\times 10^{-13} = 10.57 \\times 10^{-13} = 1.057 \\times 10^{-12}$.\n\nNow, we derive the analytic expression for the daily risk $R(r)$ as a function of the mitigation factor $r \\geq 1$. The risk is $R(r) = P(\\mathcal{T}(r)) \\times C$. The mitigation factor $r$ reduces the probabilities of the kill-switch basic events: $p_{M}^{\\prime} = p_{M}/r$, $p_{I}^{\\prime} = p_{I}/r$, $p_{S}^{\\prime} = p_{S}/r$, and $p_{F}^{\\prime} = p_{F}/r$.\nThe probability of the top event $P(\\mathcal{T}(r))$ is:\n$$ P(\\mathcal{T}(r)) = P(\\mathcal{E}) \\times P(\\mathcal{K}(r)) \\times P(\\mathcal{P}) $$\nThe probabilities of the subsystem events are calculated using the rare-event approximation:\n$P(\\mathcal{E}) \\approx p_{E_1} + p_{E_2} = 2 \\times 10^{-6} + 5 \\times 10^{-6} = 7 \\times 10^{-6}$\n$P(\\mathcal{P}) = p_{N} p_{W} = (1 \\times 10^{-2})(5 \\times 10^{-2}) = 5 \\times 10^{-4}$\n$P(\\mathcal{K}(r)) \\approx p_{M}^{\\prime} + p_{I}^{\\prime} + p_{S}^{\\prime} p_{F}^{\\prime} = \\frac{p_{M}}{r} + \\frac{p_{I}}{r} + \\frac{p_{S} p_{F}}{r^2} = \\frac{p_{M} + p_{I}}{r} + \\frac{p_{S} p_{F}}{r^2}$\nSubstituting the values:\n$P(\\mathcal{K}(r)) = \\frac{1 \\times 10^{-4} + 2 \\times 10^{-4}}{r} + \\frac{(1 \\times 10^{-3})(2 \\times 10^{-3})}{r^2} = \\frac{3 \\times 10^{-4}}{r} + \\frac{2 \\times 10^{-6}}{r^2}$\nThe total probability $P(\\mathcal{T}(r))$ is:\n$P(\\mathcal{T}(r)) = (7 \\times 10^{-6}) \\left( \\frac{3 \\times 10^{-4}}{r} + \\frac{2 \\times 10^{-6}}{r^2} \\right) (5 \\times 10^{-4})$\n$P(\\mathcal{T}(r)) = (3.5 \\times 10^{-9}) \\left( \\frac{3 \\times 10^{-4}}{r} + \\frac{2 \\times 10^{-6}}{r^2} \\right)$\nThe daily risk $R(r)$, with consequence $C = 5.0 \\times 10^{6}$ BHU, is:\n$R(r) = P(\\mathcal{T}(r)) \\times C = (5.0 \\times 10^{6}) (3.5 \\times 10^{-9}) \\left( \\frac{3 \\times 10^{-4}}{r} + \\frac{2 \\times 10^{-6}}{r^2} \\right)$\n$R(r) = (1.75 \\times 10^{-2}) \\left( \\frac{3 \\times 10^{-4}}{r} + \\frac{2 \\times 10^{-6}}{r^2} \\right)$\n$$ R(r) = \\frac{5.25 \\times 10^{-6}}{r} + \\frac{3.5 \\times 10^{-8}}{r^2} $$\nThis expression for $R(r)$ has units of BHU/day.\n\nFinally, we must find the minimal $r$ such that the risk is no greater than the upper boundary of the ALARP region, $R_{U} = 1.0 \\times 10^{-6}$ BHU/day.\nWe solve the inequality $R(r) \\leq R_{U}$:\n$$ \\frac{5.25 \\times 10^{-6}}{r} + \\frac{3.5 \\times 10^{-8}}{r^2} \\leq 1.0 \\times 10^{-6} $$\nSince $r \\geq 1$, we can multiply by $r^2$ without changing the inequality's direction.\n$$ (5.25 \\times 10^{-6})r + (3.5 \\times 10^{-8}) \\leq (1.0 \\times 10^{-6})r^2 $$\nRearranging into standard quadratic form $ar^2+br+c \\geq 0$:\n$$ (1.0 \\times 10^{-6})r^2 - (5.25 \\times 10^{-6})r - (3.5 \\times 10^{-8}) \\geq 0 $$\nTo simplify the coefficients, we multiply by $10^8$:\n$$ 100r^2 - 525r - 3.5 \\geq 0 $$\nWe find the roots of the corresponding quadratic equation $100r^2 - 525r - 3.5 = 0$ using the quadratic formula $r = \\frac{-b \\pm \\sqrt{b^2-4ac}}{2a}$:\n$$ r = \\frac{525 \\pm \\sqrt{(-525)^2 - 4(100)(-3.5)}}{2(100)} $$\n$$ r = \\frac{525 \\pm \\sqrt{275625 + 1400}}{200} = \\frac{525 \\pm \\sqrt{277025}}{200} $$\nThe discriminant is positive, yielding two real roots. The term $\\sqrt{277025} \\approx 526.33$.\nThe two roots are $r_1 = \\frac{525 - 526.33}{200} < 0$ and $r_2 = \\frac{525 + 526.33}{200} > 0$. Since $r$ must be positive, we are concerned with $r_2$.\n$$ r_2 = \\frac{525 + \\sqrt{277025}}{200} \\approx \\frac{525 + 526.3316}{200} \\approx 5.256658 $$\nThe quadratic function is a parabola opening upwards, so the inequality $100r^2 - 525r - 3.5 \\geq 0$ is satisfied for $r \\geq r_2$. The minimal value for $r$ is therefore $r_2$.\nRounding the result to three significant figures, we get:\n$$ r_{\\text{min}} \\approx 5.26 $$\nThis value is greater than $1$, which is consistent with the problem's premise of mitigation.", "answer": "$$\n\\boxed{5.26}\n$$", "id": "2739680"}, {"introduction": "While high-level system models are essential, robust risk assessment also demands a deep dive into the reliability of critical components. This exercise challenges you to analyze a multi-layer biocontainment system from first principles of probability, moving beyond simple failure models. You will quantify the increased risk posed by common-cause failures, a critical real-world factor that violates assumptions of independence and can dramatically alter safety calculations [@problem_id:2739681].", "problem": "A synthetic biology team designs a $2$-layer biocontainment architecture for a chassis microbe intended for open-system bioprocessing research. In each operating cycle, layer $1$ fails with marginal probability $p_{1}$ and layer $2$ fails with marginal probability $p_{2}$, where $0 < p_{1} < 1$ and $0 < p_{2} < 1$. Within Responsible Research and Innovation (RRI), the team must quantify the overall probability of organism escape in a single cycle and assess the robustness of the independence assumption for the two layers.\n\nStarting only from the axioms of probability, the definition of independence, and the law of total probability, do the following:\n\n1. Define the escape event as the joint failure of both layers in a cycle and derive, from first principles, the expression for the escape probability under the assumption that layer failures are independent.\n\n2. Independence can fail in realistic field conditions because a single common-cause hazard (for example, an off-nominal temperature spike) can simultaneously disable both layers. Let $C$ be the event that such a common cause occurs in a cycle with probability $\\delta$, where $0 \\leq \\delta \\leq \\min\\{p_{1}, p_{2}\\}$, and suppose that:\n   - Given $C$, both layers fail in that cycle.\n   - Given $\\overline{C}$, the two layers fail independently, and the observed marginal failure probabilities of the layers over the full mixture of conditions remain $p_{1}$ and $p_{2}$.\n\nUsing only these assumptions and the law of total probability, derive a closed-form expression for the escape probability in a single cycle as a function of $p_{1}$, $p_{2}$, and $\\delta$. Your final answer must be a single closed-form analytic expression.\n\nIn your derivation, explicitly state the conditions under which the independence assumption fails in this model in terms of the parameters and events you introduce. Do not use any shortcut formulas that are not derived from the stated foundational principles. Do not perform any numerical substitutions. Express the final escape probability as a symbolic expression in terms of $p_{1}$, $p_{2}$, and $\\delta$ only. No units are required.", "solution": "The problem statement is subjected to validation and is found to be scientifically grounded, well-posed, and objective. It is a standard problem in reliability theory, framed within the context of synthetic biology, and is constructed from fundamental principles of probability theory. All parameters and conditions are clearly defined and consistent. We may therefore proceed with the derivation.\n\nLet $F_{1}$ be the event that layer $1$ fails and $F_{2}$ be the event that layer $2$ fails in a single operating cycle. The problem statement gives their marginal probabilities as $P(F_{1}) = p_{1}$ and $P(F_{2}) = p_{2}$, with $0 < p_{1} < 1$ and $0 < p_{2} < 1$. The escape event, which we denote as $E$, is defined as the joint failure of both layers, i.e., $E = F_{1} \\cap F_{2}$. We are tasked to find the probability of this event, $P(E) = P(F_{1} \\cap F_{2})$.\n\nFirst, we address part $1$ of the problem, which assumes the failure events $F_{1}$ and $F_{2}$ are statistically independent. The definition of independence for two events $A$ and $B$ states that $P(A \\cap B) = P(A)P(B)$. Applying this principle directly to the events $F_{1}$ and $F_{2}$ gives the probability of the escape event $E$:\n$$P(E) = P(F_{1} \\cap F_{2}) = P(F_{1})P(F_{2})$$\nSubstituting the given marginal probabilities, we obtain the expression for the escape probability under the independence assumption:\n$$P(E) = p_{1}p_{2}$$\n\nNext, we address part $2$, which introduces a more complex model involving a common-cause failure event. Let $C$ be the event of a common-cause hazard occurring, with probability $P(C) = \\delta$. The complementary event, $\\overline{C}$, is the absence of such a hazard, and its probability is $P(\\overline{C}) = 1 - P(C) = 1 - \\delta$. The set of events $\\{C, \\overline{C}\\}$ forms a partition of the sample space.\n\nWe are to derive the escape probability $P(E) = P(F_{1} \\cap F_{2})$ using the law of total probability, which states that for any event $A$ and a partition $\\{B_{i}\\}$, $P(A) = \\sum_{i} P(A|B_{i})P(B_{i})$. Applying this to event $E$ over the partition $\\{C, \\overline{C}\\}$:\n$$P(E) = P(F_{1} \\cap F_{2} | C)P(C) + P(F_{1} \\cap F_{2} | \\overline{C})P(\\overline{C})$$\n\nWe evaluate each term based on the problem's stated assumptions:\n1.  \"Given $C$, both layers fail in that cycle.\" This means the conditional probability of joint failure, given the common cause, is unity: $P(F_{1} \\cap F_{2} | C) = 1$.\n2.  \"Given $\\overline{C}$, the two layers fail independently.\" This implies that the conditional probability of joint failure, given no common cause, is the product of their individual conditional probabilities: $P(F_{1} \\cap F_{2} | \\overline{C}) = P(F_{1} | \\overline{C})P(F_{2} | \\overline{C})$.\n\nSubstituting these into the total probability equation yields:\n$$P(E) = (1) \\cdot \\delta + P(F_{1} | \\overline{C})P(F_{2} | \\overline{C})(1 - \\delta)$$\n\nTo complete this expression, we must find the conditional probabilities $P(F_{1} | \\overline{C})$ and $P(F_{2} | \\overline{C})$. The problem specifies that the overall marginal probabilities $P(F_{1}) = p_{1}$ and $P(F_{2}) = p_{2}$ are conserved. We again use the law of total probability, this time for $F_{1}$ and $F_{2}$ individually:\n$$P(F_{1}) = p_{1} = P(F_{1} | C)P(C) + P(F_{1} | \\overline{C})P(\\overline{C})$$\n$$P(F_{2}) = p_{2} = P(F_{2} | C)P(C) + P(F_{2} | \\overline{C})P(\\overline{C})$$\nFrom assumption $1$, if $C$ occurs, both layers are guaranteed to fail, which implies $P(F_1 | C) = 1$ and $P(F_2 | C) = 1$. Substituting these values:\n$$p_{1} = (1)\\cdot\\delta + P(F_{1} | \\overline{C})(1 - \\delta)$$\n$$p_{2} = (1)\\cdot\\delta + P(F_{2} | \\overline{C})(1 - \\delta)$$\nWe must now solve these equations for the conditional probabilities. The condition $0 < p_{1,2} < 1$ and $0 \\leq \\delta \\leq \\min\\{p_{1}, p_{2}\\}$ ensures that $\\delta < 1$, so $1 - \\delta > 0$, and we can divide by this term.\n$$P(F_{1} | \\overline{C}) = \\frac{p_{1} - \\delta}{1 - \\delta}$$\n$$P(F_{2} | \\overline{C}) = \\frac{p_{2} - \\delta}{1 - \\delta}$$\nThe condition $\\delta \\leq p_{1}$ and $\\delta \\leq p_{2}$ ensures the numerators are non-negative, and the condition $p_{1,2} < 1$ ensures the resulting fractions are less than or equal to $1$, confirming these are valid probabilities.\n\nNow, we substitute these expressions back into our formula for $P(E)$:\n$$P(E) = \\delta + \\left( \\frac{p_{1} - \\delta}{1 - \\delta} \\right) \\left( \\frac{p_{2} - \\delta}{1 - \\delta} \\right) (1 - \\delta)$$\nThis simplifies to:\n$$P(E) = \\delta + \\frac{(p_{1} - \\delta)(p_{2} - \\delta)}{1 - \\delta}$$\nTo obtain a single closed-form expression, we combine the terms:\n$$P(E) = \\frac{\\delta(1 - \\delta) + (p_{1} - \\delta)(p_{2} - \\delta)}{1 - \\delta}$$\n$$P(E) = \\frac{\\delta - \\delta^2 + (p_{1}p_{2} - p_{1}\\delta - p_{2}\\delta + \\delta^2)}{1 - \\delta}$$\n$$P(E) = \\frac{p_{1}p_{2} + \\delta - p_{1}\\delta - p_{2}\\delta}{1 - \\delta}$$\nAn alternative, more insightful rearrangement is derived by relating this result to the independent case:\n$$P(E) = p_{1}p_{2} - p_{1}p_{2} + \\frac{p_{1}p_{2} + \\delta(1 - p_{1} - p_{2})}{1 - \\delta}$$\n$$P(E) = p_{1}p_{2} + \\frac{p_{1}p_{2}(1-\\delta) - p_{1}p_{2} - \\delta(p_{1} + p_{2} - 1)}{1 - \\delta}$$\n$$P(E) = p_{1}p_{2} + \\frac{p_{1}p_{2} - p_{1}p_{2}\\delta - p_{1}p_{2} - p_{1}\\delta - p_{2}\\delta + \\delta}{1 - \\delta}$$\nLet us use a simpler method.\n$P(E) - p_1 p_2 = \\delta + \\frac{(p_{1} - \\delta)(p_{2} - \\delta)}{1 - \\delta} - p_1 p_2 = \\frac{\\delta(1-\\delta) + p_1 p_2 - p_1 \\delta - p_2 \\delta + \\delta^2 - p_1 p_2(1-\\delta)}{1-\\delta}$\n$= \\frac{\\delta - \\delta^2 + p_1 p_2 - p_1 \\delta - p_2 \\delta + \\delta^2 - p_1 p_2 + p_1 p_2 \\delta}{1-\\delta}$\n$= \\frac{\\delta - p_1 \\delta - p_2 \\delta + p_1 p_2 \\delta}{1-\\delta} = \\frac{\\delta(1 - p_1 - p_2 + p_1 p_2)}{1-\\delta} = \\frac{\\delta(1 - p_{1})(1 - p_{2})}{1 - \\delta}$\nTherefore, the escape probability can be expressed as:\n$$P(E) = p_{1}p_{2} + \\frac{\\delta(1 - p_{1})(1 - p_{2})}{1 - \\delta}$$\nThis expression clearly separates the baseline probability under independence, $p_{1}p_{2}$, from the additional risk term arising from the non-zero probability $\\delta$ of a common-cause failure.\n\nFinally, we identify the conditions under which the independence assumption fails. The events $F_{1}$ and $F_{2}$ are independent if and only if $P(F_{1} \\cap F_{2}) = P(F_{1})P(F_{2})$. In our model, this means:\n$$p_{1}p_{2} + \\frac{\\delta(1 - p_{1})(1 - p_{2})}{1 - \\delta} = p_{1}p_{2}$$\nThis equality holds if and only if the second term is zero:\n$$\\frac{\\delta(1 - p_{1})(1 - p_{2})}{1 - \\delta} = 0$$\nGiven the constraints $0 < p_{1} < 1$ and $0 < p_{2} < 1$, the terms $(1-p_{1})$ and $(1-p_{2})$ are strictly positive. As $\\delta \\le \\min\\{p_1, p_2\\}$, we have $\\delta < 1$, so the denominator $(1-\\delta)$ is also strictly positive. Thus, the fraction is zero if and only if its numerator is zero, which requires $\\delta = 0$.\nThe independence assumption fails if and only if $\\delta > 0$. In terms of the events defined, this means independence is violated whenever the common-cause event $C$ has a non-zero probability of occurrence. The existence of event $C$ is the sole source of statistical dependence in this model.", "answer": "$$\n\\boxed{p_{1}p_{2} + \\frac{\\delta(1 - p_{1})(1 - p_{2})}{1 - \\delta}}\n$$", "id": "2739681"}, {"introduction": "Responsible innovation is an adaptive process, often involving high-stakes decisions made with incomplete information. This practice applies Bayesian decision theory to a classic dilemma: should we proceed with a large-scale deployment or first invest time and resources in a smaller pilot study? By calculating the Expected Value of Sample Information (EVSI), you will develop a quantitative framework for justifying whether 'waiting and learning' is the most rational path forward [@problem_id:2739646].", "problem": "A municipal authority is applying the principles of Responsible Research and Innovation (RRI) to decide whether to proceed with a city-scale release of an engineered microbe designed to improve wastewater nitrogen removal. Acting under adaptive risk governance, they consider running a small pilot study before a city-scale release. Model the decision using Bayesian decision theory and the Expected Value of Sample Information (EVSI), and determine whether running the pilot is rational when accounting for both direct pilot costs and time delay.\n\nFoundational base facts and definitions:\n- Expected utility is defined as the probability-weighted sum of utilities over uncertain states.\n- Bayes’ theorem updates a prior probability to a posterior probability given new data.\n- The Expected Value of Sample Information (EVSI) is the expected increase in maximum expected utility enabled by observing sample information, before subtracting the cost of obtaining that information.\n\nSetup:\n- There are two states of the world: $S$ (sufficiently safe to deploy) and $U$ (unsafe to deploy).\n- The prior probability of $S$ based on preclinical and contained-field data is $P(S)=0.6$; thus $P(U)=0.4$.\n- If the city deploys at scale and the true state is $S$, the net social benefit is $B=10$ (in millions of dollars). If the city deploys at scale and the true state is $U$, the net social welfare is $-H$ with $H=40$ (in millions of dollars), representing expected harm and mitigation costs. If the city does not deploy, the net utility is $0$ regardless of the state.\n- Without new information, the authority will choose the action with the higher expected utility under the prior.\n- A proposed small pilot produces a binary signal: “pass” (meets containment and ecological performance thresholds) or “fail.” Its performance is characterized by sensitivity and specificity:\n  - Sensitivity $=$ $P(\\text{pass}\\mid S)=0.85$.\n  - Specificity $=$ $P(\\text{fail}\\mid U)=0.90$ (hence $P(\\text{pass}\\mid U)=0.10$).\n- The pilot costs $C_{p}=1$ (in millions of dollars), paid now.\n- The pilot requires $\\tau=0.5$ years to complete, after which the city-scale decision is made conditioned on the signal. Benefits or harms from city-scale deployment, if chosen after observing the pilot, are realized after this delay.\n- Use a continuous discount rate of $\\delta=0.05$ per year for time preference. Assume that any benefits or harms of city-scale deployment are realized as a lump-sum net utility at deployment time; therefore, discount them by $\\exp(-\\delta \\tau)$ when evaluating the with-pilot strategy relative to the status quo.\n\nTask:\n- Starting from the definitions of expected utility, Bayes’ theorem, and the definition of EVSI as an expected gain in optimal expected utility from conditioning the decision on the pilot signal, derive the decision rule with and without the pilot and compute the EVSI.\n- Account for the delay by discounting any post-pilot deployment payoffs by $\\exp(-\\delta \\tau)$, and subtract the pilot cost $C_{p}$ to obtain the net value of running the pilot.\n\nProvide as your final answer the net expected value of running the pilot (EVSI adjusted for delay and minus $C_{p}$), expressed in millions of dollars. Round your answer to four significant figures.", "solution": "The problem asks for the net expected value of conducting a pilot study before making a decision on the city-scale deployment of an engineered microbe. This is a problem in Bayesian decision theory, where we must compare the expected utility of two strategies: making a decision now versus making a decision after gathering more information.\n\nFirst, I will validate the problem statement.\nThe givens are:\nStates of the world: $S$ (sufficiently safe), $U$ (unsafe).\nPrior probabilities: $P(S) = 0.6$, $P(U) = 1 - 0.6 = 0.4$.\nPayoffs for city-scale deployment: Net benefit if state is $S$ is $B=10$. Net harm if state is $U$ is $-H$ with $H=40$. The utility of not deploying is $0$.\nPilot signal performance:\nSensitivity: $P(\\text{pass}\\mid S) = 0.85$.\nSpecificity: $P(\\text{fail}\\mid U) = 0.90$.\nFrom these, we can deduce:\n$P(\\text{fail}\\mid S) = 1 - P(\\text{pass}\\mid S) = 1 - 0.85 = 0.15$.\n$P(\\text{pass}\\mid U) = 1 - P(\\text{fail}\\mid U) = 1 - 0.90 = 0.10$.\nCosts and time parameters:\nPilot cost: $C_{p} = 1$ (millions of dollars), paid at present time.\nPilot duration: $\\tau = 0.5$ years.\nContinuous discount rate: $\\delta = 0.05$ per year.\nThe discount factor for payoffs realized after the pilot is $\\exp(-\\delta \\tau)$.\n\nThe problem is scientifically grounded, well-posed, objective, and contains all necessary information for a solution. It does not violate any listed criteria for invalidity. Therefore, I will proceed with the solution.\n\nThe decision must be made by comparing the expected utility of two strategies. All utility values are in millions of dollars.\n\nStrategy 1: Decision without a pilot study.\nThe decision is between \"Deploy\" and \"Not Deploy\", made at present time based on prior probabilities.\nThe expected utility of deploying, $EU(\\text{Deploy})$, is the sum of probability-weighted outcomes:\n$$EU(\\text{Deploy}) = P(S) \\cdot B + P(U) \\cdot (-H)$$\nSubstituting the given values:\n$$EU(\\text{Deploy}) = (0.6)(10) + (0.4)(-40) = 6 - 16 = -10$$\nThe expected utility of not deploying, $EU(\\text{Not Deploy})$, is given as $0$.\n$$EU(\\text{Not Deploy}) = 0$$\nThe optimal decision is the one with the higher expected utility. Let $V_{\\text{no pilot}}$ be the value of this optimal strategy.\n$$V_{\\text{no pilot}} = \\max(EU(\\text{Deploy}), EU(\\text{Not Deploy})) = \\max(-10, 0) = 0$$\nWithout the pilot, the rational decision is to not deploy, for an expected utility of $0$.\n\nStrategy 2: Decision after conducting the pilot study.\nThis strategy has three components: the immediate cost of the pilot, the time delay, and the information-contingent decision. The value of this strategy is evaluated at the present time.\nFirst, we must calculate the posterior probabilities of the states $S$ and $U$ conditional on the pilot signal (\"pass\" or \"fail\"), using Bayes' theorem. To do so, we first need the marginal probabilities of the signals.\n\nThe probability of a \"pass\" signal, $P(\\text{pass})$, is:\n$$P(\\text{pass}) = P(\\text{pass} \\mid S)P(S) + P(\\text{pass} \\mid U)P(U)$$\n$$P(\\text{pass}) = (0.85)(0.6) + (0.10)(0.4) = 0.51 + 0.04 = 0.55$$\nThe probability of a \"fail\" signal, $P(\\text{fail})$, is:\n$$P(\\text{fail}) = P(\\text{fail} \\mid S)P(S) + P(\\text{fail} \\mid U)P(U)$$\n$$P(\\text{fail}) = (0.15)(0.6) + (0.90)(0.4) = 0.09 + 0.36 = 0.45$$\nAs a check, $P(\\text{pass}) + P(\\text{fail}) = 0.55 + 0.45 = 1.0$, which is correct.\n\nNow, we calculate the posterior probabilities.\nIf the pilot signal is \"pass\":\n$$P(S \\mid \\text{pass}) = \\frac{P(\\text{pass} \\mid S)P(S)}{P(\\text{pass})} = \\frac{(0.85)(0.6)}{0.55} = \\frac{0.51}{0.55} = \\frac{51}{55}$$\n$$P(U \\mid \\text{pass}) = \\frac{P(\\text{pass} \\mid U)P(U)}{P(\\text{pass})} = \\frac{(0.10)(0.4)}{0.55} = \\frac{0.04}{0.55} = \\frac{4}{55}$$\nIf the pilot signal is \"fail\":\n$$P(S \\mid \\text{fail}) = \\frac{P(\\text{fail} \\mid S)P(S)}{P(\\text{fail})} = \\frac{(0.15)(0.6)}{0.45} = \\frac{0.09}{0.45} = \\frac{1}{5} = 0.2$$\n$$P(U \\mid \\text{fail}) = \\frac{P(\\text{fail} \\mid U)P(U)}{P(\\text{fail})} = \\frac{0.90 \\cdot 0.4}{0.45} = \\frac{0.36}{0.45} = \\frac{4}{5} = 0.8$$\nAfter observing the signal, a new decision is made.\nIf the signal is \"pass\", the expected utility of deploying is:\n$$EU(\\text{Deploy} \\mid \\text{pass}) = P(S \\mid \\text{pass}) \\cdot B + P(U \\mid \\text{pass}) \\cdot (-H)$$\n$$EU(\\text{Deploy} \\mid \\text{pass}) = \\left(\\frac{51}{55}\\right)(10) + \\left(\\frac{4}{55}\\right)(-40) = \\frac{510 - 160}{55} = \\frac{350}{55} = \\frac{70}{11} \\approx 6.36$$\nThe optimal action after a \"pass\" signal is to deploy, with an expected utility of $\\frac{70}{11}$, since this is greater than $0$.\nIf the signal is \"fail\", the expected utility of deploying is:\n$$EU(\\text{Deploy} \\mid \\text{fail}) = P(S \\mid \\text{fail}) \\cdot B + P(U \\mid \\text{fail}) \\cdot (-H)$$\n$$EU(\\text{Deploy} \\mid \\text{fail}) = (0.2)(10) + (0.8)(-40) = 2 - 32 = -30$$\nThe optimal action after a \"fail\" signal is to not deploy, with an expected utility of $0$, since $-30 < 0$.\n\nLet $EU_{\\text{post}}$ be the expected utility of the post-pilot decision, calculated before observing the signal. This is the probability-weighted average of the optimal utilities for each signal outcome.\n$$EU_{\\text{post}} = P(\\text{pass}) \\cdot \\max(EU(\\text{Deploy} \\mid \\text{pass}), 0) + P(\\text{fail}) \\cdot \\max(EU(\\text{Deploy} \\mid \\text{fail}), 0)$$\n$$EU_{\\text{post}} = (0.55) \\cdot \\left(\\frac{70}{11}\\right) + (0.45) \\cdot (0) = \\frac{55}{100} \\cdot \\frac{70}{11} = \\frac{5 \\cdot 70}{100} = \\frac{350}{100} = 3.5$$\nThis value of $3.5$ represents the expected benefit from the deployment decision, which is only realized after the pilot completion time $\\tau$. Therefore, its present value must be discounted by the factor $\\exp(-\\delta \\tau)$. The cost of the pilot, $C_p$, is incurred now and is not discounted.\nThe total present value of the pilot strategy, $V_{\\text{pilot}}$, is:\n$$V_{\\text{pilot}} = -C_p + EU_{\\text{post}} \\cdot \\exp(-\\delta \\tau)$$\nThe discount factor is:\n$$\\exp(-\\delta \\tau) = \\exp(-0.05 \\cdot 0.5) = \\exp(-0.025)$$\nSo, the value of the pilot strategy is:\n$$V_{\\text{pilot}} = -1 + 3.5 \\cdot \\exp(-0.025)$$\nThe problem asks for the *net* expected value of running the pilot. This is the difference between the value of the pilot strategy and the value of the no-pilot strategy.\n$$\\text{Net Value} = V_{\\text{pilot}} - V_{\\text{no pilot}}$$\n$$\\text{Net Value} = (-1 + 3.5 \\cdot \\exp(-0.025)) - 0 = 3.5 \\cdot \\exp(-0.025) - 1$$\nNow, we compute the numerical value.\nUsing the value $\\exp(-0.025) \\approx 0.97530991$:\n$$\\text{Net Value} \\approx 3.5 \\cdot (0.97530991) - 1 = 3.41358469 - 1 = 2.41358469$$\nRounding to four significant figures, the net expected value is $2.414$.\nSince this value is positive, it is rational to run the pilot study.\nThe value $V_{\\text{no pilot}} = 0$ is the Expected Value of the Prior Information (EVPIor). The value $V_{\\text{pilot}} = 2.414$ is the Expected Value of Sample Information (EVSI) including costs and discounting. The term EVSI is often used for the gross information gain, which would be $EU_{\\text{post}} - V_{\\text{no pilot}} = 3.5 - 0 = 3.5$. But the question asks for the fully adjusted net value.\nMy calculation provides this net value as requested.\nFinal check of calculation:\n$V_{\\text{pilot}} - V_{\\text{no pilot}} = (3.5 \\cdot \\exp(-0.025) - 1) - 0 = 2.41358... \\approx 2.414$. The calculation is correct.\nThe result is $2.414$ million dollars.", "answer": "$$\\boxed{2.414}$$", "id": "2739646"}]}