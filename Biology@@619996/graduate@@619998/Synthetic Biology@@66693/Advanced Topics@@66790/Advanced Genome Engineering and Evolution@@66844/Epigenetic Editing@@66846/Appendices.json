{"hands_on_practices": [{"introduction": "A core task in engineering epigenetic editors is to quantify their activity. This practice introduces a fundamental kinetic model, based on mass-action principles, to describe the writing and erasing of an epigenetic mark. By fitting this model to time-course data from a simulated induction-washout experiment, you will develop the essential skill of estimating the kinetic rate constants, $k_{\\text{write}}$ and $k_{\\text{erase}}$, that define an editor's dynamic behavior [@problem_id:2737422].", "problem": "You are given time-course measurements of histone mark enrichment at a single genomic locus, obtained by Chromatin Immunoprecipitation followed by quantitative Polymerase Chain Reaction (ChIP-qPCR). The enrichment is normalized to represent a fraction between $0$ and $1$. A synthetic epigenetic editor is induced at time $t=0$ and removed (washout) at a known time $T_{\\mathrm{wash}}$. Assume a homogeneous population with first-order mass-action kinetics for mark writing and erasing at the locus: during induction, the fraction of marked nucleosomes $M(t)$ evolves according to the ordinary differential equation (ODE) $dM/dt = k_{\\mathrm{write}}(1 - M) - k_{\\mathrm{erase}} M$, and after washout only erasing remains, with $dM/dt = -k_{\\mathrm{erase}} M$. Here $k_{\\mathrm{write}} \\ge 0$ and $k_{\\mathrm{erase}} \\ge 0$ are constants to be inferred from the data. The initial marked fraction is $M(0) = M_0$, which for this problem should be taken as the first measured value in each test set. The half-life after editor removal is defined as $t_{1/2} = \\ln(2)/k_{\\mathrm{erase}}$.\n\nTask: For each test case below, estimate $k_{\\mathrm{write}}$ and $k_{\\mathrm{erase}}$ by least squares fitting of the two-phase model (induction followed by washout) to the provided measurements, and then compute the post-wash half-life $t_{1/2}$. Express $t_{1/2}$ in hours. Round each reported number to three decimals.\n\nFoundational starting point: Use the Central Dogma of molecular biology as background context (transcription requires chromatin state) and first-order mass-action kinetics for writing and erasing marks. Do not assume any pre-derived shortcut formulas for the time course; derive what you need from the stated ODEs.\n\nPhysical units: Time $t$ and $T_{\\mathrm{wash}}$ are in hours, and $t_{1/2}$ must be reported in hours.\n\nAngle unit: Not applicable.\n\nPercentages: Not applicable.\n\nTest Suite (each case specifies $(T_{\\mathrm{wash}}, \\{t_i\\}, \\{M_i\\})$):\n- Case A:\n  - $T_{\\mathrm{wash}} = 4$\n  - Time points $t$: $[0, 1, 2, 3, 4, 8, 12]$\n  - Measured enrichment $M$: $[0, \\tfrac{3}{8}, \\tfrac{9}{16}, \\tfrac{21}{32}, \\tfrac{45}{64}, \\tfrac{45}{128}, \\tfrac{45}{256}]$\n- Case B:\n  - $T_{\\mathrm{wash}} = 3$\n  - Time points $t$: $[0, 1, 2, 3, 6, 9]$\n  - Measured enrichment $M$: $[0, \\tfrac{4}{9}, \\tfrac{16}{27}, \\tfrac{52}{81}, \\tfrac{52}{243}, \\tfrac{52}{729}]$\n- Case C:\n  - $T_{\\mathrm{wash}} = 2$\n  - Time points $t$: $[0, 1, 2, 10, 18]$\n  - Measured enrichment $M$: $[\\tfrac{1}{8}, \\tfrac{1}{2}, \\tfrac{11}{16}, \\tfrac{11}{32}, \\tfrac{11}{64}]$\n\nEstimation target: For each case, fit $k_{\\mathrm{write}}$ and $k_{\\mathrm{erase}}$ with $M(0)$ fixed to the first measured value $M_0$ of that case. Use a two-phase solution consistent with the ODEs above: one form that applies for $0 \\le t \\le T_{\\mathrm{wash}}$ (induction) and a separate form for $t \\ge T_{\\mathrm{wash}}$ (washout).\n\nRequired final output format: Your program should produce a single line of output containing a flat, comma-separated list enclosed in square brackets with the $3$ results for Case A, then the $3$ results for Case B, then the $3$ results for Case C, in the order $[k_{\\mathrm{write}}, k_{\\mathrm{erase}}, t_{1/2}]$ for each case. Round each number to three decimals. For example, an output with three cases should look like $[x_1,y_1,z_1,x_2,y_2,z_2,x_3,y_3,z_3]$, where each of $x_i, y_i, z_i$ is a float rounded to three decimals.", "solution": "The problem statement is subjected to validation and is found to be scientifically grounded, well-posed, and objective. It describes a standard parameter estimation task for a system of ordinary differential equations (ODEs) representing mass-action kinetics, a fundamental concept in chemical and biological sciences. The problem provides all necessary data and constraints for a unique solution to be determined. We may therefore proceed with the derivation and solution.\n\nThe evolution of the fraction of marked nucleosomes, $M(t)$, is described by a two-phase kinetic model.\n\nPhase 1: Induction ($0 \\le t \\le T_{\\mathrm{wash}}$)\nThe governing ODE is given as:\n$$\\frac{dM}{dt} = k_{\\mathrm{write}}(1 - M) - k_{\\mathrm{erase}} M$$\nThis is a first-order linear non-homogeneous ODE. We rearrange it into the standard form $\\frac{dy}{dx} + P(x)y = Q(x)$:\n$$\\frac{dM}{dt} + (k_{\\mathrm{write}} + k_{\\mathrm{erase}})M = k_{\\mathrm{write}}$$\nLet $k_{\\mathrm{sum}} = k_{\\mathrm{write}} + k_{\\mathrm{erase}}$. The equation becomes $\\frac{dM}{dt} + k_{\\mathrm{sum}}M = k_{\\mathrm{write}}$.\nThe solution to this ODE with the initial condition $M(0) = M_0$ is:\n$$M_1(t) = M_{\\mathrm{ss}} + (M_0 - M_{\\mathrm{ss}})e^{-k_{\\mathrm{sum}}t}$$\nwhere $M_{\\mathrm{ss}}$ is the steady-state concentration, found by setting $\\frac{dM}{dt} = 0$.\n$$k_{\\mathrm{write}}(1 - M_{\\mathrm{ss}}) - k_{\\mathrm{erase}} M_{\\mathrm{ss}} = 0 \\implies k_{\\mathrm{write}} = (k_{\\mathrm{write}} + k_{\\mathrm{erase}})M_{\\mathrm{ss}}$$\n$$M_{\\mathrm{ss}} = \\frac{k_{\\mathrm{write}}}{k_{\\mathrm{write}} + k_{\\mathrm{erase}}} = \\frac{k_{\\mathrm{write}}}{k_{\\mathrm{sum}}}$$\nThus, the solution for the induction phase is:\n$$M_1(t) = \\frac{k_{\\mathrm{write}}}{k_{\\mathrm{sum}}} + \\left(M_0 - \\frac{k_{\\mathrm{write}}}{k_{\\mathrm{sum}}}\\right)e^{-k_{\\mathrm{sum}}t} \\quad \\text{for } 0 \\le t \\le T_{\\mathrm{wash}}$$\n\nPhase 2: Washout ($t > T_{\\mathrm{wash}}$)\nAfter the editor is removed at $T_{\\mathrm{wash}}$, the writing process ceases, and the ODE simplifies to:\n$$\\frac{dM}{dt} = -k_{\\mathrm{erase}} M$$\nThis is a first-order linear homogeneous ODE representing exponential decay. Its general solution is:\n$$M(t) = C e^{-k_{\\mathrm{erase}}t}$$\nwhere $C$ is a constant of integration. We determine $C$ by enforcing continuity of the histone mark fraction at the transition time $t = T_{\\mathrm{wash}}$. The value of $M$ at the beginning of the washout phase must equal the value at the end of the induction phase. Let $M(T_{\\mathrm{wash}}) = M_1(T_{\\mathrm{wash}})$.\n$$M_1(T_{\\mathrm{wash}}) = C e^{-k_{\\mathrm{erase}}T_{\\mathrm{wash}}}$$\nSolving for $C$, we get $C = M_1(T_{\\mathrm{wash}}) e^{k_{\\mathrm{erase}}T_{\\mathrm{wash}}}$. Substituting this back into the general solution gives the specific solution for the washout phase:\n$$M_2(t) = \\left(M_1(T_{\\mathrm{wash}}) e^{k_{\\mathrm{erase}}T_{\\mathrm{wash}}}\\right) e^{-k_{\\mathrm{erase}}t} = M_1(T_{\\mathrm{wash}}) e^{-k_{\\mathrm{erase}}(t - T_{\\mathrm{wash}})} \\quad \\text{for } t > T_{\\mathrm{wash}}$$\n\nEstimation of Parameters\nThe parameters $k_{\\mathrm{write}}$ and $k_{\\mathrm{erase}}$ are unknown. To estimate them, we fit the complete two-phase model to the experimental data $\\{t_i, M_i\\}$. The model prediction $M_{\\mathrm{model}}(t_i; k_{\\mathrm{write}}, k_{\\mathrm{erase}})$ is a piecewise function:\n$$M_{\\mathrm{model}}(t) = \\begin{cases} M_1(t) & \\text{if } 0 \\le t \\le T_{\\mathrm{wash}} \\\\ M_2(t) & \\text{if } t > T_{\\mathrm{wash}} \\end{cases}$$\nWe seek the parameters that minimize the sum of squared errors (SSE) between the model predictions and the measured data:\n$$S(k_{\\mathrm{write}}, k_{\\mathrm{erase}}) = \\sum_i (M_i - M_{\\mathrm{model}}(t_i; k_{\\mathrm{write}}, k_{\\mathrm{erase}}))^2$$\nThis constitutes a nonlinear least-squares optimization problem. We solve it numerically for each test case, subject to the physical constraints $k_{\\mathrm{write}} \\ge 0$ and $k_{\\mathrm{erase}} \\ge 0$.\n\nUpon finding the optimal value for $k_{\\mathrm{erase}}$, the post-washout half-life $t_{1/2}$ is calculated using the provided definition:\n$$t_{1/2} = \\frac{\\ln(2)}{k_{\\mathrm{erase}}}$$\n\nThe implementation will utilize a numerical optimization algorithm from the SciPy library to find the values of $k_{\\mathrm{write}}$ and $k_{\\mathrm{erase}}$ that minimize the SSE for each dataset.", "answer": "```python\nimport numpy as np\nfrom scipy.optimize import minimize\n\ndef solve():\n    \"\"\"\n    Solves for epigenetic kinetic parameters from time-course data.\n    \"\"\"\n    test_cases = [\n        {\n            \"T_wash\": 4.0,\n            \"t\": np.array([0, 1, 2, 3, 4, 8, 12], dtype=float),\n            \"M\": np.array([0, 3/8, 9/16, 21/32, 45/64, 45/128, 45/256], dtype=float)\n        },\n        {\n            \"T_wash\": 3.0,\n            \"t\": np.array([0, 1, 2, 3, 6, 9], dtype=float),\n            \"M\": np.array([0, 4/9, 16/27, 52/81, 52/243, 52/729], dtype=float)\n        },\n        {\n            \"T_wash\": 2.0,\n            \"t\": np.array([0, 1, 2, 10, 18], dtype=float),\n            \"M\": np.array([1/8, 1/2, 11/16, 11/32, 11/64], dtype=float)\n        }\n    ]\n\n    all_results = []\n\n    for case in test_cases:\n        t_data = case[\"t\"]\n        M_data = case[\"M\"]\n        T_wash = case[\"T_wash\"]\n        M0 = M_data[0]\n\n        def model_predictions(params):\n            \"\"\"\n            Calculates model predictions for a full time course.\n            \"\"\"\n            k_write, k_erase = params\n            \n            # Use small epsilon to avoid division by zero or log(0)\n            epsilon = 1e-12\n            k_sum = k_write + k_erase\n            \n            # Vectorized calculation for the induction phase\n            t_ind = t_data[t_data <= T_wash]\n            if k_sum > epsilon:\n                M_ss = k_write / k_sum\n                M_pred_ind = M_ss + (M0 - M_ss) * np.exp(-k_sum * t_ind)\n                M_at_washout = M_ss + (M0 - M_ss) * np.exp(-k_sum * T_wash)\n            else: # If rates are zero, no change from M0\n                M_pred_ind = np.full_like(t_ind, M0)\n                M_at_washout = M0\n            \n            # Vectorized calculation for the washout phase\n            t_wash = t_data[t_data > T_wash]\n            if t_wash.size > 0:\n                M_pred_wash = M_at_washout * np.exp(-k_erase * (t_wash - T_wash))\n                predictions = np.concatenate((M_pred_ind, M_pred_wash))\n            else:\n                predictions = M_pred_ind\n                \n            return predictions\n\n        def objective_function(params):\n            \"\"\"\n            Objective function for least squares minimization (Sum of Squared Errors).\n            \"\"\"\n            M_pred = model_predictions(params)\n            return np.sum((M_data - M_pred)**2)\n\n        # Initial guess and bounds for the optimizer\n        initial_guess = [0.5, 0.5]\n        bounds = [(0, None), (0, None)]\n\n        # Perform optimization\n        result = minimize(\n            objective_function,\n            initial_guess,\n            method='L-BFGS-B',\n            bounds=bounds,\n            options={'ftol': 1e-12, 'gtol': 1e-12}\n        )\n        \n        k_write_fit, k_erase_fit = result.x\n\n        # Calculate half-life, protecting against k_erase being zero\n        if k_erase_fit > 1e-12:\n            t_half_life = np.log(2) / k_erase_fit\n        else:\n            t_half_life = np.inf\n\n        # Format and store results\n        all_results.extend([\n            f\"{k_write_fit:.3f}\",\n            f\"{k_erase_fit:.3f}\",\n            f\"{t_half_life:.3f}\"\n        ])\n\n    print(f\"[{','.join(all_results)}]\")\n\nsolve()\n```", "id": "2737422"}, {"introduction": "While fitting a model to data is a crucial first step, a rigorous analysis requires asking whether the model's parameters are uniquely determinable from the chosen experiment. This exercise introduces the concept of structural identifiability and the powerful technique of Fisher Information Matrix (FIM) analysis to quantitatively assess it. You will explore how experimental design choices, such as the timing of measurements, directly impact our ability to confidently estimate the kinetic rates of an epigenetic editor [@problem_id:2737391].", "problem": "You will analyze structural identifiability of two kinetic parameters for a single-site epigenetic mark under constitutive writing and erasing, using a principled Fisher Information analysis and explicit numerical evaluation. Consider the fraction of marked loci $m(t)$ governed by mass-action kinetics under constant writer and eraser activities,\n$$\\frac{dm}{dt} \\;=\\; k_{\\text{write}}\\,(1 - m) \\;-\\; k_{\\text{erase}}\\,m,$$\nwith initial condition $m(0) = m_0$. Measurements of $m(t)$ are corrupted by independent, zero-mean Gaussian noise of known standard deviation $\\sigma_m$. You will assess whether both $k_{\\text{write}}$ and $k_{\\text{erase}}$ are locally identifiable from noisy time-course measurements by computing the Fisher Information Matrix (FIM) and examining parameter correlations. You will also evaluate how adding specified additional observables resolves degeneracies.\n\nUse the following foundational facts as the base for your derivations and algorithm design:\n- The Central Dogma of Molecular Biology motivates the separation of writer and eraser activities as distinct processes; here, the mark state follows first-order kinetics as above.\n- For independent Gaussian noise with known variance, the FIM equals the sum over observations of the outer product of the sensitivity (the gradient of the model prediction with respect to parameters) divided by the variance of that observation.\n- The Cramér–Rao lower bound (CRLB) covariance is the inverse of the FIM when the FIM is nonsingular; when ill-conditioned, the Moore–Penrose pseudoinverse can be used to approximate uncertainty structure.\n- The absolute correlation between parameters can be obtained from the CRLB covariance matrix $C$ as $|\\rho| = |C_{12}| / \\sqrt{C_{11} C_{22}}$.\n\nYour program must implement the following steps for each test case:\n1. Starting from the differential equation above, express $m(t)$ and its sensitivities with respect to $k_{\\text{write}}$ and $k_{\\text{erase}}$. Construct the FIM using all specified observations for that case. Observations include:\n   - Time-course measurements: a set of times $\\{t_i\\}$ in hours at which $m(t_i)$ is measured with standard deviation $\\sigma_m$ (dimensionless, since $m$ is a fraction).\n   - Optional steady-state observable: an additional observation of the steady-state fraction $m_{\\infty}$ with standard deviation $\\sigma_{\\infty}$.\n   - Optional initial-slope observable: an additional observation of the initial slope $s_0 = \\left.\\frac{dm}{dt}\\right|_{t=0}$ with standard deviation $\\sigma_{s}$.\n   All rates must be treated in $\\text{h}^{-1}$ and times in $\\text{h}$. The outputs below are dimensionless and require no physical unit.\n2. From the FIM, compute:\n   - The absolute parameter correlation $|\\rho|$ using the CRLB covariance (use the matrix inverse if numerically stable; otherwise use the Moore–Penrose pseudoinverse).\n   - The base-$10$ logarithm of the condition number of the FIM, $\\log_{10}(\\kappa)$, where $\\kappa$ is the ratio of the largest to smallest eigenvalue (treat a nonpositive smallest eigenvalue as $\\kappa = \\infty$).\n   - A boolean identifiability decision that is $\\text{True}$ if and only if both $|\\rho| < 0.9$ and $\\log_{10}(\\kappa) < 6$, and $\\text{False}$ otherwise.\n3. Aggregate the results for all test cases and print a single line containing a list of per-case results, where each per-case result is a list of the form $[|\\rho|,\\log_{10}(\\kappa),\\text{decision}]$. The two floating-point values must be rounded to six decimal places. For example, a two-case output could look like $[[0.123456,2.345678,True],[0.987654,9.876543,False]]$.\n\nTest suite. Use the same kinetic parameters and initial condition across all cases: $k_{\\text{write}} = 0.3\\,\\text{h}^{-1}$, $k_{\\text{erase}} = 0.2\\,\\text{h}^{-1}$, and $m_0 = 0$. All time-course measurements have $\\sigma_m = 0.02$. The additional observables, when present, use the stated noise values.\n\n- Case A (well-conditioned, broad time window):\n  - Times (in hours): $[0,1,2,3,4,5,6,7,8,9,10,11,12]$.\n  - No additional observables.\n\n- Case B (degenerate, short-time window):\n  - Times (in hours): $[0,0.05,0.1,0.15,0.2,0.25,0.3,0.35,0.4,0.45,0.5]$.\n  - No additional observables.\n\n- Case C (short-time window plus steady-state observable):\n  - Times (in hours): $[0,0.05,0.1,0.15,0.2,0.25,0.3,0.35,0.4,0.45,0.5]$.\n  - Additional observable: one measurement of $m_{\\infty}$ with $\\sigma_{\\infty} = 0.02$.\n\n- Case D (short-time window plus initial-slope observable):\n  - Times (in hours): $[0,0.05,0.1,0.15,0.2,0.25,0.3,0.35,0.4,0.45,0.5]$.\n  - Additional observable: one measurement of $s_0$ with $\\sigma_{s} = 0.05$.\n\nFinal output format. Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, where each element is a three-element list $[|\\rho|,\\log_{10}(\\kappa),\\text{decision}]$ with the floating-point values rounded to six decimal places, in the order Case A, Case B, Case C, Case D.", "solution": "The problem presented is valid. It is scientifically grounded in mass-action kinetics and systems identification theory, it is mathematically well-posed, and all necessary parameters and conditions are provided for a unique numerical solution. We will proceed with the analysis.\n\nThe objective is to assess the local structural identifiability of two kinetic parameters, the writing rate $k_{\\text{write}}$ and the erasing rate $k_{\\text{erase}}$, from time-series and other measurements of an epigenetic mark's fractional state, $m(t)$. The analysis will be performed using the Fisher Information Matrix (FIM).\n\nThe state of the system is governed by the linear first-order ordinary differential equation:\n$$\n\\frac{dm}{dt} = k_{\\text{write}}(1 - m) - k_{\\text{erase}}m\n$$\nwith the initial condition $m(0) = m_0$.\n\nWe can rewrite the equation as:\n$$\n\\frac{dm}{dt} + (k_{\\text{write}} + k_{\\text{erase}})m = k_{\\text{write}}\n$$\nThis is a standard linear ODE. Let $k_s = k_{\\text{write}} + k_{\\text{erase}}$. The unique solution for $m(t)$ is found using an integrating factor, $e^{k_s t}$. The solution is of the form:\n$$\nm(t) = \\frac{k_{\\text{write}}}{k_{\\text{write}} + k_{\\text{erase}}} + \\left(m_0 - \\frac{k_{\\text{write}}}{k_{\\text{write}} + k_{\\text{erase}}}\\right) e^{-(k_{\\text{write}} + k_{\\text{erase}})t}\n$$\nThe steady-state value as $t \\to \\infty$ is $m_{\\infty} = \\frac{k_{\\text{write}}}{k_{\\text{write}} + k_{\\text{erase}}}$. We can thus express the solution more compactly:\n$$\nm(t) = m_{\\infty} + (m_0 - m_{\\infty})e^{-k_s t}\n$$\n\nTo perform an identifiability analysis, we construct the Fisher Information Matrix. For a set of independent measurements $\\{y_i\\}$ with Gaussian noise of variances $\\{\\sigma_i^2\\}$, the FIM for a parameter vector $\\theta$ is given by:\n$$\n\\text{FIM} = \\sum_i \\frac{1}{\\sigma_i^2} \\left( \\nabla_{\\theta} f_i(\\theta) \\right) \\left( \\nabla_{\\theta} f_i(\\theta) \\right)^T\n$$\nwhere $f_i(\\theta)$ is the model prediction for the $i$-th measurement, and $\\nabla_{\\theta} f_i(\\theta)$ is the gradient of the prediction with respect to the parameters, also known as the sensitivity vector. Our parameter vector is $\\theta = [k_{\\text{write}}, k_{\\text{erase}}]^T$.\n\nThe total FIM is the sum of contributions from each type of measurement:\n$$\n\\text{FIM}_{\\text{total}} = \\text{FIM}_{\\text{time-course}} + \\text{FIM}_{\\text{steady-state}} + \\text{FIM}_{\\text{initial-slope}}\n$$\n\nFirst, we require the sensitivities of the time-course observable $m(t)$ with respect to $k_{\\text{write}}$ and $k_{\\text{erase}}$. Let $S_w(t) = \\frac{\\partial m(t)}{\\partial k_{\\text{write}}}$ and $S_e(t) = \\frac{\\partial m(t)}{\\partial k_{\\text{erase}}}$. Using the chain and product rules:\n$$\nS_w(t) = \\frac{\\partial m(t)}{\\partial k_{\\text{write}}} = \\frac{\\partial m_{\\infty}}{\\partial k_{\\text{write}}}(1 - e^{-k_s t}) + (m_0 - m_{\\infty})(-t e^{-k_s t})\\frac{\\partial k_s}{\\partial k_{\\text{write}}}\n$$\n$$\nS_e(t) = \\frac{\\partial m(t)}{\\partial k_{\\text{erase}}} = \\frac{\\partial m_{\\infty}}{\\partial k_{\\text{erase}}}(1 - e^{-k_s t}) + (m_0 - m_{\\infty})(-t e^{-k_s t})\\frac{\\partial k_s}{\\partial k_{\\text{erase}}}\n$$\nThe component sensitivities are:\n$$\n\\frac{\\partial k_s}{\\partial k_{\\text{write}}} = 1, \\quad \\frac{\\partial k_s}{\\partial k_{\\text{erase}}} = 1\n$$\n$$\n\\frac{\\partial m_{\\infty}}{\\partial k_{\\text{write}}} = \\frac{1 \\cdot (k_{\\text{write}} + k_{\\text{erase}}) - k_{\\text{write}} \\cdot 1}{(k_{\\text{write}} + k_{\\text{erase}})^2} = \\frac{k_{\\text{erase}}}{k_s^2}\n$$\n$$\n\\frac{\\partial m_{\\infty}}{\\partial k_{\\text{erase}}} = \\frac{0 \\cdot (k_{\\text{write}} + k_{\\text{erase}}) - k_{\\text{write}} \\cdot 1}{(k_{\\text{write}} + k_{\\text{erase}})^2} = \\frac{-k_{\\text{write}}}{k_s^2}\n$$\nSubstituting these into the expressions for $S_w(t)$ and $S_e(t)$ yields:\n$$\nS_w(t) = \\frac{k_{\\text{erase}}}{k_s^2}(1 - e^{-k_s t}) - t(m_0 - m_{\\infty})e^{-k_s t}\n$$\n$$\nS_e(t) = \\frac{-k_{\\text{write}}}{k_s^2}(1 - e^{-k_s t}) - t(m_0 - m_{\\infty})e^{-k_s t}\n$$\nFor a set of time-point measurements $\\{t_i\\}$ with variance $\\sigma_m^2$, the FIM contribution is:\n$$\n\\text{FIM}_{\\text{time-course}} = \\frac{1}{\\sigma_m^2} \\sum_i \\begin{pmatrix} S_w(t_i)^2 & S_w(t_i)S_e(t_i) \\\\ S_w(t_i)S_e(t_i) & S_e(t_i)^2 \\end{pmatrix}\n$$\n\nFor an additional steady-state measurement of $m_{\\infty}$ with variance $\\sigma_{\\infty}^2$, the sensitivity vector is $\\nabla_{\\theta} m_{\\infty} = [\\frac{\\partial m_{\\infty}}{\\partial k_{\\text{write}}}, \\frac{\\partial m_{\\infty}}{\\partial k_{\\text{erase}}}]^T$. The FIM contribution is:\n$$\n\\text{FIM}_{\\text{steady-state}} = \\frac{1}{\\sigma_{\\infty}^2} \\begin{pmatrix} (\\frac{k_{\\text{erase}}}{k_s^2})^2 & \\frac{-k_{\\text{write}}k_{\\text{erase}}}{k_s^4} \\\\ \\frac{-k_{\\text{write}}k_{\\text{erase}}}{k_s^4} & (\\frac{-k_{\\text{write}}}{k_s^2})^2 \\end{pmatrix}\n$$\n\nFor an additional measurement of the initial slope, $s_0 = \\left.\\frac{dm}{dt}\\right|_{t=0} = k_{\\text{write}}(1-m_0) - k_{\\text{erase}}m_0$, with variance $\\sigma_s^2$, the sensitivities are:\n$$\n\\frac{\\partial s_0}{\\partial k_{\\text{write}}} = 1-m_0\n$$\n$$\n\\frac{\\partial s_0}{\\partial k_{\\text{erase}}} = -m_0\n$$\nThe FIM contribution is:\n$$\n\\text{FIM}_{\\text{initial-slope}} = \\frac{1}{\\sigma_s^2} \\begin{pmatrix} (1-m_0)^2 & -(1-m_0)m_0 \\\\ -(1-m_0)m_0 & m_0^2 \\end{pmatrix}\n$$\nIn the specific cases where $m_0=0$, this simplifies to $\\frac{\\partial s_0}{\\partial k_{\\text{write}}} = 1$ and $\\frac{\\partial s_0}{\\partial k_{\\text{erase}}} = 0$, indicating the initial slope only provides information about $k_{\\text{write}}$.\n\nFrom the total FIM, we compute the Cramér-Rao Lower Bound (CRLB) covariance matrix, $C = \\text{FIM}_{\\text{total}}^{-1}$. To ensure numerical stability, we use the Moore-Penrose pseudoinverse. The absolute correlation coefficient between the parameter estimates is:\n$$\n|\\rho| = \\frac{|C_{12}|}{\\sqrt{C_{11} C_{22}}}\n$$\nThe condition number of the FIM, $\\kappa$, is the ratio of its largest eigenvalue $\\lambda_{\\text{max}}$ to its smallest eigenvalue $\\lambda_{\\text{min}}$. A large condition number signifies an ill-conditioned problem and poor identifiability. If $\\lambda_{\\text{min}} \\le 0$, the FIM is singular, and we define $\\kappa = \\infty$. We evaluate $\\log_{10}(\\kappa)$.\n\nThe algorithm proceeds as follows for each test case:\n1. Initialize a $2 \\times 2$ FIM to zeros.\n2. For each time point $t_i$ in the specified time-course, calculate the sensitivity vector $[S_w(t_i), S_e(t_i)]^T$ and add its contribution to the FIM, scaled by $1/\\sigma_m^2$.\n3. If a steady-state measurement is provided, calculate its sensitivity vector and add the corresponding contribution to the FIM, scaled by $1/\\sigma_{\\infty}^2$.\n4. If an initial-slope measurement is provided, calculate its sensitivity vector and add the corresponding contribution to the FIM, scaled by $1/\\sigma_s^2$.\n5. Compute the eigenvalues of the resulting total FIM to find $\\kappa$ and $\\log_{10}(\\kappa)$.\n6. Compute the pseudoinverse of the FIM to obtain the CRLB covariance matrix $C$.\n7. Calculate the absolute correlation $|\\rho|$ from the elements of $C$.\n8. Make the identifiability decision: $\\text{True}$ if $|\\rho| < 0.9$ and $\\log_{10}(\\kappa) < 6$, and $\\text{False}$ otherwise.\n\nThis procedure will be implemented to evaluate the four specified cases.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to solve the identifiability problem for all test cases.\n    \"\"\"\n\n    # Common parameters for all test cases\n    k_write_true = 0.3  # h^-1\n    k_erase_true = 0.2  # h^-1\n    m0 = 0.0\n    sigma_m = 0.02\n\n    # Define the test cases\n    test_cases = {\n        'A': {\n            'times': np.linspace(0, 12, 13),\n            'sigma_m': sigma_m,\n            'ss_obs': None,\n            's0_obs': None,\n        },\n        'B': {\n            'times': np.linspace(0, 0.5, 11),\n            'sigma_m': sigma_m,\n            'ss_obs': None,\n            's0_obs': None,\n        },\n        'C': {\n            'times': np.linspace(0, 0.5, 11),\n            'sigma_m': sigma_m,\n            'ss_obs': {'sigma_inf': 0.02},\n            's0_obs': None,\n        },\n        'D': {\n            'times': np.linspace(0, 0.5, 11),\n            'sigma_m': sigma_m,\n            'ss_obs': None,\n            's0_obs': {'sigma_s': 0.05},\n        }\n    }\n\n    results = []\n    # Process cases in specified order: A, B, C, D\n    for case_name in sorted(test_cases.keys()):\n        params = test_cases[case_name]\n        case_result = analyze_identifiability(\n            k_write=k_write_true,\n            k_erase=k_erase_true,\n            m0=m0,\n            times=params['times'],\n            sigma_m=params['sigma_m'],\n            ss_obs=params['ss_obs'],\n            s0_obs=params['s0_obs']\n        )\n        results.append(case_result)\n\n    # Format the final output string as per requirements\n    output_parts = []\n    for res in results:\n        # res is [abs_rho, log10_kappa, decision]\n        abs_rho_rounded = round(res[0], 6)\n        log10_kappa_rounded = round(res[1], 6) if np.isfinite(res[1]) else res[1]\n        decision = res[2]\n        # Format inner list string manually to remove spaces\n        inner_str = f\"[{abs_rho_rounded},{log10_kappa_rounded},{decision}]\"\n        output_parts.append(inner_str)\n\n    # Note: `str(np.inf)` prints 'inf'. The example output suggests this is implicitly handled,\n    # but for strictness one might replace it. However, the problem definition is fulfilled\n    # by standard float-to-string conversion. The Boolean 'True'/'False' also matches.\n    final_output = f\"[{','.join(output_parts)}]\"\n    print(final_output)\n\ndef analyze_identifiability(k_write, k_erase, m0, times, sigma_m, ss_obs, s0_obs):\n    \"\"\"\n    Calculates identifiability metrics for a single case.\n    \"\"\"\n    # Initialize Fisher Information Matrix (FIM)\n    fim = np.zeros((2, 2))\n    \n    # Pre-calculate common terms\n    k_s = k_write + k_erase\n    k_s_sq = k_s**2\n    m_inf = k_write / k_s if k_s != 0 else 0\n    m0_minus_minf = m0 - m_inf\n\n    # 1. Contribution from time-course measurements\n    for t in times:\n        exp_term = np.exp(-k_s * t)\n        common_term1 = (1 - exp_term) / k_s_sq\n        common_term2 = -t * m0_minus_minf * exp_term\n\n        s_w = k_erase * common_term1 + common_term2\n        s_e = -k_write * common_term1 + common_term2\n        \n        grad = np.array([s_w, s_e])\n        fim += np.outer(grad, grad) / (sigma_m**2)\n\n    # 2. Contribution from steady-state measurement (if any)\n    if ss_obs:\n        sigma_inf = ss_obs['sigma_inf']\n        # Sensitivities of m_inf\n        grad_inf = np.array([k_erase / k_s_sq, -k_write / k_s_sq])\n        fim += np.outer(grad_inf, grad_inf) / (sigma_inf**2)\n\n    # 3. Contribution from initial slope measurement (if any)\n    if s0_obs:\n        sigma_s = s0_obs['sigma_s']\n        # Sensitivities of s0 = k_write*(1-m0) - k_erase*m0\n        grad_s0 = np.array([1 - m0, -m0])\n        fim += np.outer(grad_s0, grad_s0) / (sigma_s**2)\n\n    # 4. Compute metrics from FIM\n    # Eigenvalues for condition number. use eigvalsh for symmetric matrix.\n    try:\n        eigs = np.linalg.eigvalsh(fim)\n        min_eig, max_eig = np.min(eigs), np.max(eigs)\n\n        if min_eig <= 1e-12:  # Treat near-zero or negative as singular\n            kappa = np.inf\n            log10_kappa = np.inf\n        else:\n            kappa = max_eig / min_eig\n            log10_kappa = np.log10(kappa)\n    except np.linalg.LinAlgError:\n        log10_kappa = np.inf\n\n    # CRLB Covariance Matrix and Correlation\n    # Use pseudoinverse for stability, as per problem description\n    crlb_cov = np.linalg.pinv(fim)\n    \n    # Check for non-invertibility manifest as zero diagonal elements\n    if crlb_cov[0, 0] <= 0 or crlb_cov[1, 1] <= 0:\n        abs_rho = 1.0 # Maximum correlation\n    else:\n        rho = crlb_cov[0, 1] / np.sqrt(crlb_cov[0, 0] * crlb_cov[1, 1])\n        abs_rho = np.abs(rho)\n\n    # 5. Make identifiability decision\n    is_identifiable = bool(abs_rho < 0.9 and log10_kappa < 6)\n\n    return [abs_rho, log10_kappa, is_identifiable]\n\nsolve()\n```", "id": "2737391"}, {"introduction": "Modern single-cell technologies reveal that even in a genetically identical population, epigenetic editing outcomes can be highly heterogeneous. This practice moves beyond bulk population averages to address this variability, using a statistical mixture model to analyze simulated single-cell multiome data. You will apply the Law of Total Variance to decompose observed variation into components arising from incomplete editing versus intrinsic cell-to-cell noise, a critical skill for interpreting the results of single-cell perturbation screens [@problem_id:2737397].", "problem": "You are given a simplified generative model for single-cell multiome data that jointly measures Assay for Transposase-Accessible Chromatin (ATAC) and Ribonucleic Acid (RNA) abundance for a single target locus after an epigenetic editing intervention in a homogeneous cell population. Each cell is assumed to be in one of two latent states: an unedited state or an edited state. Let the observed two-dimensional readout for a cell be the vector $y \\in \\mathbb{R}^2$, where the first coordinate represents ATAC accessibility and the second coordinate represents RNA expression, both transformed to logarithmic scale so they are dimensionless. Let the hidden state be $z \\in \\{0,1\\}$, with $\\mathbb{P}(z=1)=p \\in (0,1)$ capturing the editing completeness at the population level (for example, measured by targeted genotyping of the edit). Conditioned on $z$, assume a location-shifted Gaussian model with equal within-state covariance: $y \\mid z=0 \\sim \\mathcal{N}(\\mu_0,\\Sigma_{\\text{intrinsic}})$ and $y \\mid z=1 \\sim \\mathcal{N}(\\mu_0 + d,\\Sigma_{\\text{intrinsic}})$, where $d \\in \\mathbb{R}^2$ is the mean shift induced by editing, representing the coupled effect on ATAC and RNA, and $\\Sigma_{\\text{intrinsic}} \\in \\mathbb{R}^{2 \\times 2}$ captures cell-intrinsic variability that is shared between edited and unedited cells. Assume isotropic intrinsic variability $\\Sigma_{\\text{intrinsic}} = s^2 I_2$ with $s^2 \\ge 0$, where $I_2$ is the $2 \\times 2$ identity matrix. The vector $u \\in \\mathbb{R}^2$ is a known unit vector representing the direction in which editing is expected to act in the joint ATAC–RNA space, determined a priori from perturbation design or orthogonal calibration; the effect vector $d$ is assumed to be colinear with $u$, that is, $d = \\|d\\| u$. The only data available to you for inference on a single target are the empirical covariance matrix $S \\in \\mathbb{R}^{2 \\times 2}$ estimated from many cells, the known $p$, and the known unit vector $u$. Your task is to derive, from first principles, a method to decompose the observed variability into components attributable to incomplete editing versus cell-intrinsic variability, under the model and assumptions above, and then implement it.\n\nStarting base facts and definitions you may use: the Central Dogma of Molecular Biology establishes a causal chain from Deoxyribonucleic Acid (DNA) to RNA to protein, and epigenetic editing aims to alter chromatin state and transcription. Mathematically, you may use the Law of Total Expectation and the Law of Total Variance for random variables, and standard properties of multivariate normal distributions. Do not assume any formulas beyond these foundational principles.\n\nYour program must, for each test case, compute the following quantities based only on $S$, $u$, and $p$ under the assumptions above:\n- The estimated magnitude $\\|d\\|$ of the editing-induced shift, expressed as a nonnegative real number.\n- The estimated intrinsic variance $s^2$, expressed as a nonnegative real number.\n- A heterogeneity index $H$ defined as the fraction of the total variance (trace of the total covariance in the two-dimensional space) that is attributable to incomplete editing, expressed as a real number in $[0,1]$.\n\nImportant requirements and conventions for the computation:\n- Let $v_{\\perp} \\in \\mathbb{R}^2$ denote any unit vector orthogonal to $u$. Use $v_{\\perp} = (-u_2, u_1)$ normalized to unit length, where $u = (u_1,u_2)$.\n- Use the Law of Total Variance to separate within-state variance from between-state variance along $u$ and along $v_{\\perp}$, and the isotropy assumption to identify $s^2$.\n- If numerical estimation yields a negative estimate for the between-state contribution along $u$ due to sampling noise, clamp that contribution to $0$ to maintain physical interpretability, and propagate this clamp consistently to the estimates of $\\|d\\|$ and $H$.\n- All computations are dimensionless. Express all outputs as real numbers rounded to $6$ decimal places.\n\nTest suite of parameter values to exercise your implementation:\n- Case $1$ (general, aligned to a rotated axis): $p = 0.5$, $u = \\left(\\frac{1}{\\sqrt{2}},\\frac{1}{\\sqrt{2}}\\right)$, $S = \\begin{bmatrix} 0.325 & 0.125 \\\\ 0.125 & 0.325 \\end{bmatrix}$.\n- Case $2$ (no detectable editing effect): $p = 0.6$, $u = (1.0, 0.0)$, $S = \\begin{bmatrix} 0.3 & 0.0 \\\\ 0.0 & 0.3 \\end{bmatrix}$.\n- Case $3$ (high editing completeness but small incomplete fraction): $p = 0.95$, $u = (0.6, 0.8)$, $S = \\begin{bmatrix} 0.138475 & 0.0513 \\\\ 0.0513 & 0.1684 \\end{bmatrix}$.\n- Case $4$ (edge case, apparent variance along $u$ not exceeding orthogonal): $p = 0.5$, $u = (1.0, 0.0)$, $S = \\begin{bmatrix} 0.19 & 0.0 \\\\ 0.0 & 0.2 \\end{bmatrix}$.\n- Case $5$ (strong effect along an oblique direction): $p = 0.3$, $u = (-0.8, 0.6)$, $S = \\begin{bmatrix} 0.115856 & -0.049392 \\\\ -0.049392 & 0.087044 \\end{bmatrix}$.\n\nFinal output specification:\n- For each case, output a list $\\left[\\|d\\|, s^2, H\\right]$ with each entry rounded to $6$ decimal places.\n- Aggregate the results for all cases into a single line as a comma-separated list enclosed in square brackets, with no spaces, where each element is the per-case list. For example, the overall output format must be of the form $[[a_1,b_1,c_1],[a_2,b_2,c_2],\\dots]$.", "solution": "The problem presents a valid statistical inference task grounded in a simplified biophysical model of epigenetic editing. The model assumes that a population of cells is a mixture of two states, unedited ($z=0$) and edited ($z=1$), with a known mixing proportion $p = \\mathbb{P}(z=1)$. The observed two-dimensional data for a cell, $y \\in \\mathbb{R}^2$, comprising Assay for Transposase-Accessible Chromatin (ATAC) and Ribonucleic Acid (RNA) readouts, is modeled by a Gaussian mixture. Specifically, the conditional distributions are given as $y \\mid z=0 \\sim \\mathcal{N}(\\mu_0, \\Sigma_{\\text{intrinsic}})$ and $y \\mid z=1 \\sim \\mathcal{N}(\\mu_0 + d, \\Sigma_{\\text{intrinsic}})$. The intrinsic covariance is assumed isotropic, $\\Sigma_{\\text{intrinsic}} = s^2 I_2$, and the editing effect vector $d$ is assumed to be colinear with a known unit vector $u$, i.e., $d = \\|d\\|u$. We are provided with the empirical covariance matrix $S$ of the observed data $y$, the editing probability $p$, and the effect direction vector $u$. The task is to derive from first principles a method to estimate the magnitude of the editing effect $\\|d\\|$, the intrinsic variance $s^2$, and a heterogeneity index $H$.\n\nThe derivation proceeds by applying the Law of Total Variance to relate the model parameters to the observable total covariance matrix $\\Sigma_y$, which is estimated by the empirical covariance matrix $S$. The Law of Total Variance states:\n$$\n\\Sigma_y = \\text{Var}(y) = \\mathbb{E}[\\text{Var}(y|z)] + \\text{Var}(\\mathbb{E}[y|z])\n$$\n\nThe first term, $\\mathbb{E}[\\text{Var}(y|z)]$, represents the average within-state covariance. Given that the within-state covariance $\\text{Var}(y|z) = \\Sigma_{\\text{intrinsic}} = s^2 I_2$ is identical for both states $z=0$ and $z=1$, its expectation over $z$ is simply:\n$$\n\\mathbb{E}[\\text{Var}(y|z)] = (1-p)(s^2 I_2) + p(s^2 I_2) = s^2 I_2\n$$\n\nThe second term, $\\text{Var}(\\mathbb{E}[y|z])$, represents the between-state covariance, which arises from the difference in mean vectors between the states. The conditional mean vectors are $\\mathbb{E}[y|z=0] = \\mu_0$ and $\\mathbb{E}[y|z=1] = \\mu_0 + d$. The random variable $\\mathbb{E}[y|z]$ takes these two vector values with probabilities $1-p$ and $p$, respectively. The mean of this random variable is $\\mathbb{E}_{\\!z}[\\mathbb{E}_y[y|z]] = (1-p)\\mu_0 + p(\\mu_0+d) = \\mu_0 + pd$. The variance is then calculated as:\n$$\n\\begin{aligned}\n\\text{Var}(\\mathbb{E}[y|z]) &= (1-p)(\\mu_0 - (\\mu_0+pd))(\\mu_0 - (\\mu_0+pd))^T + p((\\mu_0+d) - (\\mu_0+pd))((\\mu_0+d) - (\\mu_0+pd))^T \\\\\n&= (1-p)(-pd)(-pd)^T + p((1-p)d)((1-p)d)^T \\\\\n&= (1-p)p^2 dd^T + p(1-p)^2 dd^T \\\\\n&= p(1-p)(p + (1-p)) dd^T \\\\\n&= p(1-p) dd^T\n\\end{aligned}\n$$\n\nCombining the two components, the total theoretical covariance matrix is:\n$$\n\\Sigma_y = s^2 I_2 + p(1-p) dd^T\n$$\nSubstituting the assumption $d = \\|d\\|u$, where $u$ is a unit vector:\n$$\n\\Sigma_y = s^2 I_2 + p(1-p)\\|d\\|^2 uu^T\n$$\nWe equate this theoretical covariance with the empirical covariance matrix $S$ to form the basis of our estimation procedure. To solve for the two scalar unknowns, $s^2$ and $\\|d\\|$, we project the covariance matrix onto an orthonormal basis defined by the effect direction $u$ and its orthogonal vector $v_{\\perp}$. The variance of the data projected onto an arbitrary unit vector $v$ is given by $v^T S v$. Applying this to our model of $S \\approx \\Sigma_y$:\n$$\nv^T S v \\approx v^T(s^2 I_2 + p(1-p)\\|d\\|^2 uu^T)v = s^2(v^T v) + p(1-p)\\|d\\|^2 (v^T u)(u^T v) = s^2 + p(1-p)\\|d\\|^2 (v \\cdot u)^2\n$$\nWe choose $v = v_{\\perp}$, a unit vector orthogonal to $u$. For this choice, $v_{\\perp} \\cdot u = 0$. The projected variance is:\n$$\n\\sigma^2_{\\perp} = v_{\\perp}^T S v_{\\perp} = s^2 + 0 = s^2\n$$\nThis provides a direct estimator for the intrinsic variance: $\\hat{s}^2 = v_{\\perp}^T S v_{\\perp}$. As $S$ is a positive semi-definite matrix, $\\hat{s}^2$ is guaranteed to be non-negative.\n\nNext, we choose $v = u$. Since $u$ is a unit vector, $u \\cdot u = 1$. The projected variance along $u$ is:\n$$\n\\sigma^2_u = u^T S u = s^2 + p(1-p)\\|d\\|^2\n$$\nThe term $p(1-p)\\|d\\|^2$ represents the variance added by the mixture of states, projected along the direction of the mean shift. We can solve for this term by substituting our estimator for $s^2$:\n$$\np(1-p)\\|d\\|^2 = \\sigma^2_u - s^2 = u^T S u - v_{\\perp}^T S v_{\\perp}\n$$\nDue to sampling variability in $S$, the term $u^T S u - v_{\\perp}^T S v_{\\perp}$ may be negative. As variance cannot be negative, we clamp this estimate at zero. Let $\\hat{V}_{between, u}$ be the estimated between-state variance contribution along $u$:\n$$\n\\hat{V}_{between, u} = \\max(0, u^T S u - v_{\\perp}^T S v_{\\perp})\n$$\nFrom this, we estimate the magnitude of the effect vector $\\|d\\|$. Since $p \\in (0,1)$, $p(1-p)>0$:\n$$\n\\|\\hat{d}\\| = \\sqrt{\\frac{\\hat{V}_{between, u}}{p(1-p)}}\n$$\nFinally, we compute the heterogeneity index $H$, defined as the fraction of total variance attributable to incomplete editing. The total variance is the trace of the covariance matrix, $\\text{Tr}(S)$. The variance attributable to editing is the trace of the between-state covariance component, $\\text{Tr}(p(1-p)dd^T)$. Using the cyclic property of the trace, $\\text{Tr}(dd^T) = \\text{Tr}(d^T d) = \\|d\\|^2$, this becomes $p(1-p)\\|d\\|^2$. The estimator for $H$ is therefore the ratio of our estimated between-state variance to the total variance:\n$$\n\\hat{H} = \\frac{\\hat{V}_{between, u}}{\\text{Tr}(S)}\n$$\nThe identity $\\text{Tr}(S) = u^T S u + v_{\\perp}^T S v_{\\perp}$ confirms that the total variance is the sum of projected variances along the orthonormal basis vectors, ensuring $\\hat{H} \\in [0,1]$.\nThis completes the derivation of the estimators for $\\|d\\|$, $s^2$, and $H$. The procedure is implemented in the provided Python code.", "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the variance decomposition problem for a series of test cases.\n    \"\"\"\n    # Test suite of parameter values.\n    # Each case is a tuple: (p, u, S)\n    test_cases = [\n        (0.5, np.array([1/np.sqrt(2), 1/np.sqrt(2)]), np.array([[0.325, 0.125], [0.125, 0.325]])),\n        (0.6, np.array([1.0, 0.0]), np.array([[0.3, 0.0], [0.0, 0.3]])),\n        (0.95, np.array([0.6, 0.8]), np.array([[0.138475, 0.0513], [0.0513, 0.1684]])),\n        (0.5, np.array([1.0, 0.0]), np.array([[0.19, 0.0], [0.0, 0.2]])),\n        (0.3, np.array([-0.8, 0.6]), np.array([[0.115856, -0.049392], [-0.049392, 0.087044]]))\n    ]\n\n    results = []\n    \n    for p, u, S in test_cases:\n        # Define the unit vector orthogonal to u.\n        # For u = (u1, u2), v_perp = (-u2, u1) is orthogonal and has the same length.\n        # Since u is a unit vector, v_perp is also a unit vector.\n        v_perp = np.array([-u[1], u[0]])\n\n        # Calculate the variance of the data projected onto u and v_perp.\n        # var(v^T y) = v^T S v\n        sigma_sq_u = u.T @ S @ u\n        sigma_sq_perp = v_perp.T @ S @ v_perp\n\n        # 1. Estimate intrinsic variance s^2.\n        # s^2 is the variance in the direction orthogonal to the effect.\n        s_squared_hat = sigma_sq_perp\n\n        # 2. Estimate the magnitude of the editing-induced shift ||d||.\n        # The between-state variance contribution along u is V_between_u = sigma_sq_u - s^2.\n        # It must be non-negative, so we clamp at 0.\n        V_between_u_hat = max(0, sigma_sq_u - s_squared_hat)\n        \n        # Denominator p*(1-p) for calculating ||d||^2.\n        p_factor = p * (1 - p)\n        \n        # Calculate ||d||. Handle potential division by zero although p is in (0,1).\n        if p_factor > 0:\n            d_norm_hat = np.sqrt(V_between_u_hat / p_factor)\n        else:\n            d_norm_hat = 0.0\n\n        # 3. Estimate the heterogeneity index H.\n        # H is the fraction of total variance (Tr(S)) from between-state variance.\n        # Total variance Tr(S) can also be computed as sigma_sq_u + sigma_sq_perp.\n        total_variance = np.trace(S)\n        \n        if total_variance > 0:\n            H_hat = V_between_u_hat / total_variance\n        else:\n            H_hat = 0.0\n\n        # Collect results, rounded to 6 decimal places.\n        results.append([\n            round(d_norm_hat, 6),\n            round(s_squared_hat, 6),\n            round(H_hat, 6)\n        ])\n\n    # Format the final output string as specified.\n    # e.g., [[a1,b1,c1],[a2,b2,c2],...]\n    output_str = \"[\" + \",\".join([f\"[{r[0]},{r[1]},{r[2]}]\" for r in results]) + \"]\"\n    print(output_str)\n\nsolve()\n```", "id": "2737397"}]}