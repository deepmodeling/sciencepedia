{"hands_on_practices": [{"introduction": "Large-scale genome engineering often involves ambitious goals such as recoding, where the function of specific codons is reassigned throughout the genome. This practice is crucial for creating genetically isolated organisms or incorporating non-standard amino acids, but such modifications must be carefully planned to preserve the original proteome. This exercise challenges you to develop a computational strategy to determine the minimum number of codon substitutions needed to eliminate a target codon, while respecting the original and reassigned genetic codes [@problem_id:2752407]. Mastering this type of constrained optimization is fundamental to automating the design phase of complex genome engineering projects.", "problem": "You are designing a high-level planning algorithm to support Multiplex Automated Genome Engineering (MAGE) and Conjugative Assembly Genome Engineering (CAGE) recoding strategies. The aim is to reason about codon usage changes while preserving protein amino acid sequences. Use the following fundamental base: the Central Dogma of molecular biology (DNA to amino acids via translation), and the well-established Standard Genetic Code mapping codons (triplets over $\\{A,C,G,T\\}$) to amino acids.\n\nGiven:\n- A fixed Standard Genetic Code mapping $G_0$ from each of the $64$ codons to one of the $20$ amino acids or a stop symbol.\n- A desired reassignment scheme represented as a modified mapping $G_1$ obtained from $G_0$ by changing the amino acid assignment of a specified subset of codons, leaving all others unchanged.\n- A target codon $c^\\star$ to be eliminated from all coding sequences.\n- A set of one or more coding sequences, each represented as a string over $\\{A,C,G,T\\}$ with length divisible by $3$ and intended to be translated in frame under both $G_0$ and $G_1$.\n\nDefinitions:\n- For any coding sequence $s$ of length $3n$, write $s = x_1 x_2 \\dots x_n$ where each $x_i$ is a codon (a length-$3$ string).\n- For a codon $x$, define $a_0(x) = G_0(x)$ and $a_1(x) = G_1(x)$.\n- A position-wise replacement plan is a function $\\phi$ that maps each codon $x_i$ to a codon $\\phi(x_i)$ (possibly equal to $x_i$). Applying $\\phi$ to $s$ yields a new sequence $\\phi(s)$ by replacing each $x_i$ with $\\phi(x_i)$ independently.\n- The plan $\\phi$ is valid if, for all positions $i$ and all sequences in the input set, the following hold:\n  - Elimination constraint: $\\phi(x_i) \\neq c^\\star$.\n  - Pre-implementation preservation: $a_0(\\phi(x_i)) = a_0(x_i)$.\n  - Post-reassignment preservation: $a_1(\\phi(x_i)) = a_0(x_i)$.\n- The cost of $\\phi$ is the number of positions $i$ across all sequences where $\\phi(x_i) \\neq x_i$.\n\nTask:\n- Compute the minimal possible cost among all valid $\\phi$, or report that no valid $\\phi$ exists. In other words, compute the minimal number of codon replacements required to eliminate all instances of $c^\\star$ while ensuring that, at every position, the amino acid produced under the Standard Genetic Code and under the reassigned code both match the original amino acid under the Standard Genetic Code.\n\nYour program must:\n- Implement $G_0$ as the Standard Genetic Code (single-letter amino acid codes, with stop denoted by $*$).\n- Construct $G_1$ by applying reassignment overrides provided in each test case to $G_0$.\n- For each codon position $x_i$, decide whether a replacement is required and whether a valid synonymous replacement exists that satisfies both preservation constraints and the elimination constraint. If any position requires a replacement but no valid codon exists, the test case result is $-1$ (impossible). Otherwise, the result is the minimal number of replacements.\n\nDesign constraints:\n- Assume independence across codon positions; you are not allowed to shift reading frames or use indels. Only codon substitutions are permitted at fixed positions.\n- If a position $x_i$ is neither equal to $c^\\star$ nor altered in meaning by $G_1$ (i.e., $a_1(x_i)=a_0(x_i)$), then it can be left unchanged to minimize the cost.\n- For positions where a change is required (either to eliminate $c^\\star$ or to restore agreement between $a_1$ and $a_0$), a valid choice at that position is any codon $y$ such that $G_0(y) = a_0(x_i)$, $G_1(y) = a_0(x_i)$, and $y \\neq c^\\star$.\n\nTest suite:\nProvide results for the following test cases. Each test case is specified as a triple $(\\text{sequences}, c^\\star, \\text{reassignments})$, where:\n- $\\text{sequences}$ is a list of coding sequences, each of length divisible by $3$.\n- $c^\\star$ is a single codon string to eliminate.\n- $\\text{reassignments}$ is a dictionary of codon-to-amino-acid letter overrides to define $G_1$.\n\nThe test cases are:\n- Case $1$ (happy path, stop-codon elimination): sequences $=$ [$\\text{\"ATGAAATAG\"}$], $c^\\star=$ $\\text{\"TAG\"}$, reassignments $=$ $\\{\\text{\"TAG\"}:\\text{\"Q\"}\\}$.\n- Case $2$ (sense-codon elimination): sequences $=$ [$\\text{\"TCGTCGAGT\"}$], $c^\\star=$ $\\text{\"TCG\"}$, reassignments $=$ $\\{\\text{\"TCG\"}:\\text{\"L\"}\\}$.\n- Case $3$ (impossible: unique codon for methionine): sequences $=$ [$\\text{\"ATGATGATG\"}$], $c^\\star=$ $\\text{\"ATG\"}$, reassignments $=$ $\\{\\}$.\n- Case $4$ (additional forced replacements from reassignment): sequences $=$ [$\\text{\"TCGAGCAGC\"}$], $c^\\star=$ $\\text{\"TCG\"}$, reassignments $=$ $\\{\\text{\"TCG\"}:\\text{\"L\"}, \\text{\"AGC\"}:\\text{\"G\"}\\}$.\n- Case $5$ (impossible: target unrelated but reassignment removes all codons for tryptophan): sequences $=$ [$\\text{\"TGGGATTGG\"}$], $c^\\star=$ $\\text{\"TAG\"}$, reassignments $=$ $\\{\\text{\"TGG\"}:\\text{\"*\"}\\}$.\n\nAnswer specification:\n- For each case, output a single integer: the minimal number of replacements, or $-1$ if no valid plan exists.\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (e.g., $[\\text{result}_1,\\text{result}_2,\\dots]$). No spaces are allowed in the output string.\n\nAngles and units:\n- There are no physical units or angle measures in this problem.\n\nYour program must be self-contained and require no user input.", "solution": "The problem presented is a constrained optimization task in the domain of synthetic biology, specifically concerning genome recoding strategies. The analysis is valid and proceeds from first principles.\n\nThe central task is to calculate the minimum cost, defined as the number of codon substitutions, required to transform a given set of coding sequences. This transformation must adhere to three strict constraints for every codon position $i$ in every sequence:\n$1$. The **Elimination Constraint**: The final codon, $\\phi(x_i)$, must not be the target codon $c^\\star$.\n$2$. The **Pre-implementation Preservation Constraint**: The amino acid encoded by the new codon $\\phi(x_i)$ under the standard genetic code $G_0$ must be identical to the amino acid encoded by the original codon $x_i$ under $G_0$. Formally, $a_0(\\phi(x_i)) = a_0(x_i)$, where $a_0(x) = G_0(x)$.\n$3$. The **Post-reassignment Preservation Constraint**: The amino acid encoded by the new codon $\\phi(x_i)$ under the modified genetic code $G_1$ must also be identical to the amino acid encoded by the original codon $x_i$ under $G_0$. Formally, $a_1(\\phi(x_i)) = a_0(x_i)$, where $a_1(x) = G_1(x)$.\n\nThe problem states that codon replacements are independent. This is a critical simplifying assumption. It implies that the globally minimal cost is the sum of the minimal costs for each individual codon position. Therefore, we can design a strategy that makes a locally optimal decision for each codon, one by one. The total cost is the sum of costs incurred at each position. If any position cannot be made valid, no valid plan $\\phi$ exists, and the task is impossible.\n\nOur algorithm is structured as follows. First, for each test case, we establish the necessary context: the standard code $G_0$, the target codon $c^\\star$, and the reassigned code $G_1$, which is derived from $G_0$ and the specified reassignments. Based on this context, we can pre-compute a set of valid replacement codons for each amino acid. Let $\\text{AA}$ be an amino acid. The set $S_{\\text{AA}}$ of valid codons for $\\text{AA}$ is defined as:\n$$S_{\\text{AA}} = \\{ y \\mid G_0(y) = \\text{AA} \\land G_1(y) = \\text{AA} \\land y \\neq c^\\star \\}$$\nThis set $S_{\\text{AA}}$ contains all codons $y$ that can serve as a valid replacement for any original codon $x_i$ that encoded for $\\text{AA}$ (i.e., $G_0(x_i) = \\text{AA}$). This pre-computation is efficient as it avoids repeated searches.\n\nWith these sets $S_{\\text{AA}}$ prepared, we iterate through each codon $x_i$ of each input sequence. For each $x_i$, we perform a two-step decision process. Let the original amino acid be $\\text{AA}_i = G_0(x_i)$.\n\nFirst, we determine if a replacement is mandatory for the codon $x_i$. A replacement is not required if and only if $x_i$ itself satisfies all three constraints when chosen as its own replacement (i.e., $\\phi(x_i) = x_i$). This simplifies to checking two conditions:\n$1$. $x_i \\neq c^\\star$\n$2$. $G_1(x_i) = G_0(x_i)$ (since $G_0(x_i) = G_0(x_i)$ is tautological)\n\nIf both conditions are met, the codon $x_i$ is already valid. The optimal choice is to leave it unchanged, $\\phi(x_i) = x_i$, incurring a cost of $0$ for this position.\n\nSecond, if either of the above conditions fails ($x_i = c^\\star$ or $G_1(x_i) \\neq G_0(x_i)$), a replacement is necessary. The cost for this position will be $1$, provided a valid replacement can be found. A valid replacement must be an element of the pre-computed set $S_{\\text{AA}_i}$.\n- If the set $S_{\\text{AA}_i}$ is empty, it signifies that no codon in the entire genetic code can validly encode the required amino acid $\\text{AA}_i$ under the given constraints. In this scenario, no valid plan $\\phi$ can be constructed. The process for this test case terminates, and the result is reported as $-1$.\n- If $S_{\\text{AA}_i}$ is not empty, a valid replacement is possible. We do not need to choose a specific one; knowing that at least one exists is sufficient. The minimal cost for this position is $1$ (as a change is mandatory), and we add this to the total accumulated cost.\n\nThis procedure is repeated for all codons in all sequences. If the process completes without encountering any position for which a required replacement is impossible, the final accumulated sum represents the minimal total cost.\n\nLet us briefly illustrate with Case $4$: sequences = $[\\text{\"TCGAGCAGC\"}]$, $c^\\star = \\text{\"TCG\"}$, reassignments = $\\{\\text{\"TCG\"}:\\text{\"L\"}, \\text{\"AGC\"}:\\text{\"G\"}\\}$.\nThe codons are $x_1=\\text{\"TCG\"}$, $x_2=\\text{\"AGC\"}$, $x_3=\\text{\"AGC\"}$.\nThe standard code $G_0$ maps both $\\text{\"TCG\"}$ and $\\text{\"AGC\"}$ to Serine ($\\text{S}$). So, $\\text{AA}_1 = \\text{AA}_2 = \\text{AA}_3 = \\text{S}$.\nThe reassigned code $G_1$ maps $\\text{\"TCG\"}$ to Leucine ($\\text{L}$) and $\\text{\"AGC\"}$ to Glycine ($\\text{G}$).\nThe set of valid codons for Serine, $S_\\text{S}$, are those $y$ where $G_0(y)=\\text{S}$, $G_1(y)=\\text{S}$, and $y \\neq \\text{\"TCG\"}$. The codons for Serine are $\\text{\"TCT\"}, \\text{\"TCC\"}, \\text{\"TCA\"}, \\text{\"TCG\"}, \\text{\"AGT\"}, \\text{\"AGC\"}$. We must exclude $\\text{\"TCG\"}$ (as $c^\\star$) and $\\text{\"AGC\"}$ (as $G_1(\\text{\"AGC\"})=\\text{G}$). This leaves $S_\\text{S} = \\{\\text{\"TCT\"}, \\text{\"TCC\"}, \\text{\"TCA\"}, \\text{\"AGT\"}\\}$.\n\n- For $x_1=\\text{\"TCG\"}$: Replacement is mandatory as $x_1=c^\\star$. The set $S_\\text{S}$ is not empty, so a replacement is possible. Cost is $1$.\n- For $x_2=\\text{\"AGC\"}$: Replacement is mandatory as $G_1(\\text{\"AGC\"}) \\neq G_0(\\text{\"AGC\"})$. The set $S_\\text{S}$ is not empty. Cost is $1$.\n- For $x_3=\\text{\"AGC\"}$: Same as $x_2$. Cost is $1$.\n\nThe minimal total cost is $1 + 1 + 1 = 3$. This systematic, position-independent evaluation guarantees the correct minimal cost or correctly identifies impossibility.", "answer": "```python\nimport numpy as np\n# The problem does not necessitate the use of numpy or scipy,\n# but they are included to strictly adhere to the specified environment.\n\ndef solve():\n    \"\"\"\n    Solves the MAGE/CAGE codon replacement problem for a suite of test cases.\n    \"\"\"\n\n    # The Standard Genetic Code, mapping DNA codons to amino acids.\n    # '*' denotes a STOP codon.\n    STANDARD_GENETIC_CODE = {\n        'TTT': 'F', 'TTC': 'F', 'TTA': 'L', 'TTG': 'L',\n        'TCT': 'S', 'TCC': 'S', 'TCA': 'S', 'TCG': 'S',\n        'TAT': 'Y', 'TAC': 'Y', 'TAA': '*', 'TAG': '*',\n        'TGT': 'C', 'TGC': 'C', 'TGA': '*', 'TGG': 'W',\n        'CTT': 'L', 'CTC': 'L', 'CTA': 'L', 'CTG': 'L',\n        'CCT': 'P', 'CCC': 'P', 'CCA': 'P', 'CCG': 'P',\n        'CAT': 'H', 'CAC': 'H', 'CAA': 'Q', 'CAG': 'Q',\n        'CGT': 'R', 'CGC': 'R', 'CGA': 'R', 'CGG': 'R',\n        'ATT': 'I', 'ATC': 'I', 'ATA': 'I', 'ATG': 'M',\n        'ACT': 'T', 'ACC': 'T', 'ACA': 'T', 'ACG': 'T',\n        'AAT': 'N', 'AAC': 'N', 'AAA': 'K', 'AAG': 'K',\n        'AGT': 'S', 'AGC': 'S', 'AGA': 'R', 'AGG': 'R',\n        'GTT': 'V', 'GTC': 'V', 'GTA': 'V', 'GTG': 'V',\n        'GCT': 'A', 'GCC': 'A', 'GCA': 'A', 'GCG': 'A',\n        'GAT': 'D', 'GAC': 'D', 'GAA': 'E', 'GAG': 'E',\n        'GGT': 'G', 'GGC': 'G', 'GGA': 'G', 'GGG': 'G',\n    }\n    \n    ALL_CODONS = list(STANDARD_GENETIC_CODE.keys())\n    \n    test_cases = [\n        # Case 1: Stop-codon elimination\n        ([\"ATGAAATAG\"], \"TAG\", {\"TAG\": \"Q\"}),\n        # Case 2: Sense-codon elimination\n        ([\"TCGTCGAGT\"], \"TCG\", {\"TCG\": \"L\"}),\n        # Case 3: Impossible due to unique methionine codon\n        ([\"ATGATGATG\"], \"ATG\", {}),\n        # Case 4: Reassignment forces additional replacements\n        ([\"TCGAGCAGC\"], \"TCG\", {\"TCG\": \"L\", \"AGC\": \"G\"}),\n        # Case 5: Impossible due to losing all codons for an amino acid\n        ([\"TGGGATTGG\"], \"TAG\", {\"TGG\": \"*\"}),\n    ]\n\n    results = []\n    \n    for sequences, c_star, reassignments in test_cases:\n        \n        G0 = STANDARD_GENETIC_CODE\n        G1 = G0.copy()\n        G1.update(reassignments)\n        \n        # Pre-compute the set of valid replacement codons for each original amino acid.\n        # A codon `y` is a valid replacement for an original amino acid `aa` if:\n        # 1. G0(y) == aa (pre-preservation via synonymy)\n        # 2. G1(y) == aa (post-preservation)\n        # 3. y != c_star (elimination)\n        valid_codons_map = {}\n        all_amino_acids = set(G0.values())\n        for aa in all_amino_acids:\n            valid_set = set()\n            for codon in ALL_CODONS:\n                if G0[codon] == aa and G1[codon] == aa and codon != c_star:\n                    valid_set.add(codon)\n            valid_codons_map[aa] = valid_set\n\n        total_cost = 0\n        possible = True\n        \n        for seq in sequences:\n            if not possible:\n                break\n            \n            # Process the sequence codon by codon\n            for i in range(0, len(seq), 3):\n                codon = seq[i:i+3]\n                original_aa = G0[codon]\n                \n                # Check if codon needs replacement. This is true if it's the target\n                # for elimination OR if its meaning changes in G1.\n                needs_replacement = (codon == c_star) or (G1[codon] != original_aa)\n                \n                if needs_replacement:\n                    # A change is mandatory. Check if a valid replacement exists.\n                    if not valid_codons_map[original_aa]:\n                        # No valid replacement codon exists for this amino acid.\n                        total_cost = -1\n                        possible = False\n                        break\n                    else:\n                        # A replacement is possible and necessary.\n                        total_cost += 1\n                # If no replacement is needed, cost is 0, so do nothing.\n\n        results.append(total_cost)\n\n    # Format the final output string exactly as specified.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "2752407"}, {"introduction": "Conjugative Assembly Genome Engineering (CAGE) enables the construction of entire genomes by sequentially transferring large DNA segments. A critical strategic decision is how to partition the target genome into segments for transfer, as this involves a trade-off: larger segments mean fewer conjugation rounds, but each round has a lower probability of success. This exercise guides you through modeling this trade-off and using dynamic programming to find an optimal segmentation strategy that minimizes the total expected time for assembly [@problem_id:2752386]. This practice demonstrates how to apply formal optimization techniques to enhance the efficiency of real-world synthetic biology workflows.", "problem": "A laboratory is planning a Conjugative Assembly Genome Engineering (CAGE) program to assemble a redesigned genome by transferring a set of contiguous DNA segments into a recipient strain. In each conjugation round, the attempt to transfer a single contiguous segment of length $\\ell$ (measured in kilobases, abbreviated as kb) succeeds with probability $p(\\ell)$, independently of all other rounds and segments. The laboratory can choose a segmentation scheme that partitions a target genome length $L$ (in kb) into a multiset of allowed segment sizes $S$ (in kb), under a constraint that the number of segments is at most $K_{\\max}$. The probability of successful transfer per round declines with segment length according to an exponential rule. The goal is to compute an optimal segmentation scheme that minimizes the total expected number of conjugation rounds needed to successfully transfer all segments sequentially into a single strain.\n\nUse the following foundational facts and definitions as the starting point:\n- By the Central Dogma of molecular biology, a DNA segment is a physical substrate whose manipulation probability does not depend on symbolic interpretation, but rather on process parameters; we therefore model each conjugation attempt as a Bernoulli trial with a length-dependent success probability.\n- For a Bernoulli process with per-trial success probability $p \\in (0,1]$, the expected number of trials until the first success (a geometric random variable) is $1/p$.\n- Assuming independence across segments and strictly sequential assembly into a single strain (i.e., segments do not overlap temporally and must be completed one after another), the total expected number of rounds is the sum of expected rounds for each segment.\n\nModel of length-dependent transfer probability:\n- Let $S$ be the set of allowed segment sizes (in kb), and let $\\ell_{\\min} = \\min S$.\n- Let $p_0 \\in (0,1]$ be the baseline success probability for a segment of length $\\ell_{\\min}$ in a single round.\n- Let $\\alpha > 0$ be a decay constant with units $\\text{kb}^{-1}$.\n- For any allowed segment length $\\ell \\in S$, define\n$$\np(\\ell) = \\min\\!\\left(1,\\; p_0 \\, e^{-\\alpha(\\ell - \\ell_{\\min})}\\right).\n$$\n- The expected number of rounds for a single segment of length $\\ell$ is then\n$$\n\\mathbb{E}[\\text{rounds} \\mid \\ell] = \\frac{1}{p(\\ell)}.\n$$\n\nOptimization problem:\n- Choose a multiset $\\{\\ell_1,\\ell_2,\\dots,\\ell_k\\}$ such that each $\\ell_i \\in S$, $\\sum_{i=1}^{k} \\ell_i = L$, and $1 \\leq k \\leq K_{\\max}$.\n- Minimize the total expected rounds\n$$\n\\sum_{i=1}^{k} \\frac{1}{p(\\ell_i)}.\n$$\n- If no exact partition of $L$ exists using elements of $S$ with at most $K_{\\max}$ segments, report no feasible solution.\n- Tie-breaking: if multiple segmentations achieve the same minimal total expected rounds (to within exact arithmetic under the model), select the one with the smallest $k$; if a tie remains, select the lexicographically smallest nondecreasing list $(\\ell_1\\leq \\ell_2 \\leq \\dots \\leq \\ell_k)$.\n\nPhysical units and output requirements:\n- All lengths must be expressed in kilobases (kb).\n- Probabilities are unitless; do not use the percentage symbol; represent any real-valued results in decimal form if needed.\n- Angles are not involved in this problem.\n\nYour task is to write a complete program that, for each test case below, computes the optimal segmentation scheme under the model and constraints. If a test case has no feasible segmentation, return the empty list. Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, where each result is itself a list of integers (segment sizes in kb) in nondecreasing order. For example, a valid output with three results could look like \"[[a,b],[c,d,e],[]]\".\n\nTest suite:\n- Case $1$ (general happy path):\n  - $L = 200$ kb\n  - $S = \\{20,40,60,80\\}$ kb\n  - $K_{\\max} = 5$\n  - $p_0 = 0.92$\n  - $\\alpha = 0.03$ $\\text{kb}^{-1}$\n- Case $2$ (infeasible under tight $K_{\\max}$):\n  - $L = 180$ kb\n  - $S = \\{20,40,60,80\\}$ kb\n  - $K_{\\max} = 2$\n  - $p_0 = 0.92$\n  - $\\alpha = 0.03$ $\\text{kb}^{-1}$\n- Case $3$ (boundary with a single segment):\n  - $L = 80$ kb\n  - $S = \\{20,40,60,80\\}$ kb\n  - $K_{\\max} = 1$\n  - $p_0 = 0.92$\n  - $\\alpha = 0.03$ $\\text{kb}^{-1}$\n- Case $4$ (alternative allowed sizes and trade-offs):\n  - $L = 240$ kb\n  - $S = \\{30,60,90\\}$ kb\n  - $K_{\\max} = 4$\n  - $p_0 = 0.85$\n  - $\\alpha = 0.02$ $\\text{kb}^{-1}$\n- Case $5$ (balanced interior optimum):\n  - $L = 150$ kb\n  - $S = \\{25,50,75\\}$ kb\n  - $K_{\\max} = 3$\n  - $p_0 = 0.90$\n  - $\\alpha = 0.025$ $\\text{kb}^{-1}$\n\nFinal output format:\n- Your program should produce a single line of output containing the segmentation lists for the cases in order as a Python-style list literal, e.g., \"[[...],[...],...]\", where each inner list contains integers representing segment sizes in kb in nondecreasing order. If no feasible segmentation exists for a case, output \"[]\" for that case.", "solution": "The problem as stated is valid. It is scientifically grounded in the principles of molecular biology and probability theory, is mathematically well-posed as a constrained optimization problem, and is articulated with objective, unambiguous terminology. All necessary data are provided. No internal contradictions or violations of fundamental principles are present.\n\nThe problem is to find an optimal partition of a target genome of total length $L$ into a multiset of segments $\\{\\ell_1, \\ell_2, \\dots, \\ell_k\\}$. Each segment length $\\ell_i$ must be chosen from a given set of allowed sizes $S$. The partition must satisfy two constraints: the sum of segment lengths must equal the target length, $\\sum_{i=1}^{k} \\ell_i = L$, and the total number of segments must not exceed a maximum, $k \\leq K_{\\max}$. The objective is to minimize the total expected number of conjugation rounds, which is given by the sum of the expected rounds for each segment:\n$$\n\\text{Minimize } \\sum_{i=1}^{k} \\mathbb{E}[\\text{rounds} \\mid \\ell_i] = \\sum_{i=1}^{k} \\frac{1}{p(\\ell_i)}\n$$\nwhere the success probability $p(\\ell)$ for a segment of length $\\ell$ is defined as\n$$\np(\\ell) = \\min\\!\\left(1,\\; p_0 \\, e^{-\\alpha(\\ell - \\ell_{\\min})}\\right)\n$$\nwith $\\ell_{\\min} = \\min S$.\n\nThis problem is a variation of the classic change-making problem and can be solved optimally using dynamic programming. The core idea is to iteratively build up solutions for increasing total lengths, from $1$ up to $L$.\n\nFirst, an important optimization can be made. Any valid segmentation is a sum of integers from the set $S$. Therefore, the total length $L$ must be an integer linear combination of the elements in $S$. This implies that $L$ must be a multiple of the greatest common divisor (GCD) of all segment sizes in $S$. If $L \\pmod{\\text{gcd}(S)} \\neq 0$, no feasible solution exists. This check can prune infeasible cases immediately. If this condition holds, we can scale down the problem by dividing $L$ and all elements of $S$ by their GCD, which reduces the size of the state space for the dynamic programming algorithm.\n\nLet the scaled target length be $L'$ and the set of scaled segment sizes be $S'$. We define a DP table, `dp`, of size $L'+1$. Each entry `dp[i]` will store the optimal solution for assembling a total scaled length of $i$. An \"optimal solution\" must encapsulate all information needed for the tie-breaking rules. Thus, `dp[i]` will be a tuple: `(total_cost, num_segments, segmentation_list)`.\n\nThe base case for the recursion is for a total length of $0$, which requires zero segments and incurs zero cost.\n$$\n\\text{dp}[0] = (0.0, 0, [])\n$$\nAll other entries $\\text{dp}[i]$ for $i > 0$ are initialized to a state representing infinity, e.g., $(\\infty, \\infty, [])$.\n\nThe DP table is filled iteratively for scaled lengths $i$ from $1$ to $L'$. For each length $i$, we consider forming it by adding a segment of size $s' \\in S'$ to a previously computed optimal solution for length $i-s'$. The original segment size is $s = s' \\cdot \\text{gcd}(S)$. The candidate solution derived from `dp[i-s']` and segment $s$ is:\n-   New cost: $\\text{dp}[i-s'].\\text{cost} + \\frac{1}{p(s)}$\n-   New segment count: $\\text{dp}[i-s'].\\text{count} + 1$\n-   New segmentation list: sorted list from appending $s$ to $\\text{dp}[i-s'].\\text{list}$\n\nThis candidate solution is valid only if its segment count does not exceed $K_{\\max}$. If valid, it is compared against the current best solution stored in `dp[i]`. The comparison strictly follows the specified tie-breaking hierarchy:\n1.  The solution with the lower total cost is preferred. A small tolerance $\\epsilon$ is used for floating-point comparisons.\n2.  If costs are equal, the solution with the smaller number of segments ($k$) is preferred.\n3.  If both cost and segment count are equal, the solution with the lexicographically smaller nondecreasing asegmentation list is preferred.\n\nIf the candidate is better than the existing entry in `dp[i]`, `dp[i]` is updated with the new optimal solution tuple.\n\nAfter the DP table is fully computed up to $L'$, the entry `dp[L']` contains the optimal solution for the original problem. If the cost in `dp[L']` remains infinite, no feasible segmentation was found. Otherwise, the segmentation list stored in `dp[L']` is the final answer.", "answer": "```python\nimport numpy as np\nimport math\n\ndef solve():\n    \"\"\"\n    Solves the CAGE segmentation problem for a suite of test cases.\n    \"\"\"\n    test_cases = [\n        # Case 1: General happy path\n        {'L': 200, 'S': [20, 40, 60, 80], 'K_max': 5, 'p0': 0.92, 'alpha': 0.03},\n        # Case 2: Infeasible under tight K_max\n        {'L': 180, 'S': [20, 40, 60, 80], 'K_max': 2, 'p0': 0.92, 'alpha': 0.03},\n        # Case 3: Boundary with a single segment\n        {'L': 80, 'S': [20, 40, 60, 80], 'K_max': 1, 'p0': 0.92, 'alpha': 0.03},\n        # Case 4: Alternative allowed sizes and trade-offs\n        {'L': 240, 'S': [30, 60, 90], 'K_max': 4, 'p0': 0.85, 'alpha': 0.02},\n        # Case 5: Balanced interior optimum\n        {'L': 150, 'S': [25, 50, 75], 'K_max': 3, 'p0': 0.90, 'alpha': 0.025},\n    ]\n\n    results = []\n    for case in test_cases:\n        result = find_optimal_segmentation(**case)\n        results.append(result)\n\n    # Format the final output string to match \"[[...],[...],[]]\"\n    def format_list_of_lists(lol):\n        outer_parts = []\n        for inner_list in lol:\n            outer_parts.append(f\"[{','.join(map(str, inner_list))}]\")\n        return f\"[{','.join(outer_parts)}]\"\n\n    print(format_list_of_lists(results))\n\ndef find_optimal_segmentation(L, S, K_max, p0, alpha):\n    \"\"\"\n    Finds the optimal segmentation for a single case using dynamic programming.\n    \"\"\"\n    if not S or L == 0:\n        return []\n\n    # --- Pre-computation and Optimizations ---\n    # GCD optimization: if L is not divisible by gcd of S, no solution exists.\n    g = S[0]\n    for i in range(1, len(S)):\n        g = math.gcd(g, S[i])\n    if L % g != 0:\n        return []\n\n    L_scaled = L // g\n    S_sorted = sorted(S)\n    S_scaled = [s // g for s in S_sorted]\n\n    # Calculate transfer costs for each allowed segment size.\n    l_min = S_sorted[0]\n    \n    def get_prob(l):\n        return min(1.0, p0 * np.exp(-alpha * (l - l_min)))\n        \n    costs = {s: 1.0 / get_prob(s) for s in S_sorted}\n\n    # --- Dynamic Programming Setup ---\n    # dp[i] stores a tuple: (total_cost, num_segments, segmentation_list)\n    dp = [(float('inf'), float('inf'), []) for _ in range(L_scaled + 1)]\n    dp[0] = (0.0, 0, [])\n    \n    EPS = 1e-9 # Epsilon for floating-point comparisons\n\n    def is_better(candidate, best):\n        cand_cost, cand_k, cand_seg = candidate\n        best_cost, best_k, best_seg = best\n\n        if cand_cost  best_cost - EPS: return True\n        if cand_cost > best_cost + EPS: return False\n        \n        if cand_k  best_k: return True\n        if cand_k > best_k: return False\n        \n        if cand_seg  best_seg: return True\n        return False\n\n    # --- DP Computation ---\n    for i in range(1, L_scaled + 1):\n        for s_idx, s_scaled in enumerate(S_scaled):\n            s_original = S_sorted[s_idx]\n            if i >= s_scaled:\n                prev_cost, prev_k, prev_seg = dp[i - s_scaled]\n\n                if prev_k  K_max:\n                    new_cost = prev_cost + costs[s_original]\n                    new_k = prev_k + 1\n                    \n                    # To avoid re-sorting, create the sorted list only when needed for tie-breaking.\n                    # For simplicity and correctness given problem constraints, we form it here.\n                    new_seg = sorted(prev_seg + [s_original])\n                    candidate = (new_cost, new_k, new_seg)\n\n                    if is_better(candidate, dp[i]):\n                        dp[i] = candidate\n\n    # --- Final Result ---\n    final_cost, _, final_segmentation = dp[L_scaled]\n\n    if final_cost == float('inf'):\n        return []\n    else:\n        return final_segmentation\n\nsolve()\n```", "id": "2752386"}, {"introduction": "After executing a multiplex genome engineering experiment, a crucial step is to analyze the outcomes using high-throughput sequencing to quantify the frequency of different engineered variants. However, when edits create a library of closely related sequences, short reads can map ambiguously, confounding simple counting methods. This exercise introduces the Expectation-Maximization (EM) algorithm, a powerful statistical method for resolving such ambiguity by probabilistically assigning reads to their most likely origin [@problem_id:2752515]. Completing this practice will equip you with a fundamental tool for robust data analysis in genomics, allowing you to extract meaningful conclusions from complex sequencing datasets.", "problem": "You are modeling the assignment of short sequencing reads generated during Multiplex Automated Genome Engineering (MAGE) or Conjugative Assembly Genome Engineering (CAGE) to a set of closely related edited loci. Each read is assumed to originate from exactly one edited locus, but similarity among loci and sequencing errors cause ambiguous mapping. You are given, for each read-locus pair, a nonnegative compatibility score that is proportional to the conditional probability of observing the read given the locus. You will estimate the mixture proportions of loci and quantify uncertainty in both read assignments and locus proportions, using an expectation-maximization approach grounded in first principles.\n\nFundamental base:\n- The Central Dogma of molecular biology provides the flow of information from DNA to RNA to protein; high-throughput sequencing reads arise from DNA, and mapping uncertainty follows from stochastic sequencing errors and sequence similarity.\n- Bayesâ€™ theorem and mixture models: if a sample arises from a mixture of sources with unknown proportions, the likelihood for independent observations is the product over observations of the mixture-weighted sum of component likelihoods.\n- Expectation-Maximization (EM) is a principled approach to maximum likelihood for latent-variable models, alternating between computing the expected latent responsibilities and maximizing parameters.\n- For quantifying parametric uncertainty in a multinomial mixture proportion vector, a Dirichlet prior yields a Dirichlet posterior, from which analytic variances are available.\n\nMathematical specification:\n- Let there be $R$ reads and $L$ edited loci. Let $Q \\in \\mathbb{R}_{\\ge 0}^{R \\times L}$ with entries $Q_{r\\ell}$ proportional to $p(x_r \\mid z_r = \\ell)$, where $x_r$ denotes read $r$ and $z_r$ is the latent locus identity. Let the locus mixture proportions be $p = (p_1,\\dots,p_L)$ with $p_\\ell \\ge 0$ and $\\sum_{\\ell=1}^L p_\\ell = 1$.\n- The log-likelihood of the data under the mixture model is\n$$\n\\mathcal{L}(p) = \\sum_{r=1}^R \\log\\left(\\sum_{\\ell=1}^L p_\\ell Q_{r\\ell}\\right).\n$$\n- Introduce responsibilities (posterior assignment probabilities) $\\gamma_{r\\ell}$ satisfying $\\gamma_{r\\ell} \\ge 0$ and $\\sum_{\\ell=1}^L \\gamma_{r\\ell} = 1$. The expectation step computes\n$$\n\\gamma_{r\\ell} \\propto p_\\ell Q_{r\\ell},\n$$\nwith the convention that if $\\sum_{\\ell=1}^L p_\\ell Q_{r\\ell} = 0$ (an uninformative read), then $\\gamma_{r\\cdot} = p$.\n- The maximization step updates $p$ by normalizing the soft counts:\n$$\np_\\ell \\leftarrow \\frac{1}{R}\\sum_{r=1}^R \\gamma_{r\\ell}.\n$$\n- For uncertainty quantification of $p$, use a symmetric Dirichlet prior with concentration vector $\\alpha_0 \\in \\mathbb{R}_{0}^L$ and compute a Dirichlet posterior with parameters $a_\\ell = \\alpha_{0,\\ell} + \\sum_{r=1}^R \\gamma_{r\\ell}$ and total concentration $A = \\sum_{\\ell=1}^L a_\\ell$. The posterior variance of $p_\\ell$ is\n$$\n\\mathrm{Var}(p_\\ell) = \\frac{a_\\ell (A - a_\\ell)}{A^2 (A+1)}.\n$$\n- For uncertainty in read assignments, use the mean per-read entropy,\n$$\n\\bar{H} = \\frac{1}{R}\\sum_{r=1}^R \\left(-\\sum_{\\ell=1}^L \\gamma_{r\\ell} \\log \\gamma_{r\\ell}\\right),\n$$\nwith natural logarithm and the convention $0 \\log 0 = 0$.\n\nProgramming task:\n- Implement the Expectation-Maximization algorithm to find the maximum likelihood estimate of $p$ given $Q$, using the responsibility convention above for uninformative reads. Initialize $p$ uniformly, iterate until the absolute change in $\\mathcal{L}(p)$ is less than $10^{-12}$ or until $10000$ iterations, whichever comes first. Use the natural logarithm.\n- After convergence, compute posterior standard deviations $\\sigma_\\ell = \\sqrt{\\mathrm{Var}(p_\\ell)}$ using a symmetric Dirichlet prior with concentration vector $\\alpha_0$ provided per test case.\n- Compute the mean per-read entropy $\\bar{H}$.\n\nTest suite:\nFor each test case, you are given $Q$ and $\\alpha_0$.\n\n- Test case $1$ (happy path, three loci):\nLet $Q^{(1)} \\in \\mathbb{R}^{5 \\times 3}$ with rows\n(0.90, 0.05, 0.05),\n(0.80, 0.10, 0.10),\n(0.10, 0.80, 0.10),\n(0.05, 0.10, 0.85),\n(0.33, 0.33, 0.34).\nLet $\\alpha_0^{(1)} = (1.0, 1.0, 1.0)$.\n\n- Test case $2$ (non-identifiability/symmetry, two loci):\nLet $Q^{(2)} \\in \\mathbb{R}^{4 \\times 2}$ with rows\n(0.50, 0.50),\n(0.70, 0.70),\n(0.10, 0.10),\n(1.00, 1.00).\nLet $\\alpha_0^{(2)} = (1.0, 1.0)$.\n\n- Test case $3$ (zero-support locus, three loci):\nLet $Q^{(3)} \\in \\mathbb{R}^{4 \\times 3}$ with rows\n(0.60, 0.40, 0.00),\n(0.10, 0.90, 0.00),\n(0.50, 0.50, 0.00),\n(0.90, 0.10, 0.00).\nLet $\\alpha_0^{(3)} = (1.0, 1.0, 1.0)$.\n\n- Test case $4$ (four loci, varying ambiguity):\nLet $Q^{(4)} \\in \\mathbb{R}^{6 \\times 4}$ with rows\n(0.40, 0.30, 0.20, 0.10),\n(0.25, 0.25, 0.25, 0.25),\n(0.10, 0.20, 0.30, 0.40),\n(0.35, 0.30, 0.20, 0.15),\n(0.05, 0.05, 0.45, 0.45),\n(0.45, 0.10, 0.30, 0.15).\nLet $\\alpha_0^{(4)} = (1.0, 1.0, 1.0, 1.0)$.\n\nRequired final output format:\n- For each test case with $L$ loci, output a flat list of length $2L+1$ consisting of, in order: the $L$ estimated mixture proportions $(p_1,\\dots,p_L)$, the $L$ posterior standard deviations $(\\sigma_1,\\dots,\\sigma_L)$, and finally the scalar mean entropy $\\bar{H}$. All floats must be rounded to $6$ decimal places.\n- Aggregate the four per-case lists into a single list and print exactly one line containing this aggregate list as a comma-separated list enclosed in square brackets, for example: $[[...],[...],[...],[...]]$.", "solution": "The problem requires the estimation of mixture proportions for a set of $L$ genomic loci from a dataset of $R$ sequencing reads, and the quantification of uncertainty in these estimates. The provided data is a compatibility matrix $Q \\in \\mathbb{R}_{\\ge 0}^{R \\times L}$, where the entry $Q_{r\\ell}$ is proportional to the conditional probability of observing read $r$ given it originates from locus $\\ell$, denoted $p(x_r | z_r = \\ell)$.\n\nThe underlying statistical framework is a finite mixture model. The unknown mixture proportions are $p = (p_1, \\dots, p_L)$, which must satisfy $p_\\ell \\ge 0$ for all $\\ell \\in \\{1, \\dots, L\\}$ and $\\sum_{\\ell=1}^L p_\\ell = 1$. The log-likelihood of the observed reads, assuming independence, is given by:\n$$\n\\mathcal{L}(p) = \\sum_{r=1}^R \\log\\left(\\sum_{\\ell=1}^L p_\\ell Q_{r\\ell}\\right)\n$$\nDirect maximization of $\\mathcal{L}(p)$ is complicated. A standard and principled approach for Maximum Likelihood Estimation (MLE) in such latent variable models is the Expectation-Maximization (EM) algorithm. The algorithm iteratively alternates between an Expectation (E) step and a Maximization (M) step until convergence.\n\nFirst, the parameters $p$ are initialized. A uniform distribution is chosen, such that $p_\\ell^{(0)} = 1/L$ for all $\\ell$.\n\nThe E-step computes the expected values of the latent variables $z_r$, which indicate the originating locus for each read $r$. This is equivalent to calculating the posterior probability, or \"responsibility,\" $\\gamma_{r\\ell}$ that locus $\\ell$ is responsible for read $r$, given the current parameter estimates $p$. Applying Bayes' theorem:\n$$\n\\gamma_{r\\ell} = P(z_r = \\ell | x_r, p) = \\frac{p(x_r | z_r = \\ell) P(z_r = \\ell)}{\\sum_{k=1}^L p(x_r | z_k = k) P(z_k = k)} = \\frac{p_\\ell Q_{r\\ell}}{\\sum_{k=1}^L p_k Q_{rk}}\n$$\nA special case arises if the denominator $\\sum_{k=1}^L p_k Q_{rk}$ is zero, which signifies that read $r$ is impossible under the current model. For such uninformative reads, the responsibility vector $\\gamma_{r\\cdot}$ is defined to be the current proportion vector $p$.\n\nThe M-step updates the parameter estimates $p$ to maximize the expected complete-data log-likelihood, using the responsibilities computed in the E-step. This yields a simple and intuitive update rule where each proportion $p_\\ell$ is set to the average responsibility for that locus across all reads:\n$$\np_\\ell^{\\text{(new)}} \\leftarrow \\frac{1}{R} \\sum_{r=1}^R \\gamma_{r\\ell}\n$$\nThe E and M steps are repeated until the absolute change in the log-likelihood $\\mathcal{L}(p)$ between successive iterations falls below a tolerance of $10^{-12}$, or a maximum of $10000$ iterations is reached.\n\nUpon convergence to the MLE $\\hat{p}$, uncertainty is quantified in two ways.\n\nFirst, the uncertainty in the parameter estimates $\\hat{p}$ is assessed using a Bayesian framework. A symmetric Dirichlet prior, $p \\sim \\mathrm{Dir}(\\alpha_0, \\dots, \\alpha_0)$, is placed on the proportion vector $p$. Due to the conjugacy of the Dirichlet and Multinomial distributions, the posterior distribution is also a Dirichlet distribution, $p | \\{x_r\\} \\sim \\mathrm{Dir}(a_1, \\dots, a_L)$, with parameters:\n$$\na_\\ell = \\alpha_{0,\\ell} + \\sum_{r=1}^R \\gamma_{r\\ell}\n$$\nwhere $\\gamma_{r\\ell}$ are the final responsibilities computed with the MLE $\\hat{p}$. The total concentration is $A = \\sum_{\\ell=1}^L a_\\ell$. The posterior variance for each component $p_\\ell$ is then analytically given by:\n$$\n\\mathrm{Var}(p_\\ell) = \\frac{a_\\ell (A - a_\\ell)}{A^2 (A+1)}\n$$\nThe reported uncertainty is the standard deviation $\\sigma_\\ell = \\sqrt{\\mathrm{Var}(p_\\ell)}$.\n\nSecond, the uncertainty in the assignment of individual reads to loci is quantified using the Shannon entropy. For each read $r$, the entropy of its responsibility vector $\\gamma_{r\\cdot}$ measures the ambiguity of its origin: $H(\\gamma_{r\\cdot}) = -\\sum_{\\ell=1}^L \\gamma_{r\\ell} \\log \\gamma_{r\\ell}$, where the natural logarithm is used and the convention $0 \\log 0 = 0$ is followed. The mean per-read entropy, $\\bar{H}$, provides a single measure of the overall assignment ambiguity for the entire dataset:\n$$\n\\bar{H} = \\frac{1}{R}\\sum_{r=1}^R H(\\gamma_{r\\cdot})\n$$\nThis complete procedure is implemented to process the provided test cases, yielding the estimated proportions, their posterior standard deviations, and the mean assignment entropy.", "answer": "```python\nimport numpy as np\nfrom scipy.special import xlogy\n\ndef solve():\n    \"\"\"\n    Main function to run all test cases and print the final results.\n    \"\"\"\n    test_cases = [\n        {\n            \"Q\": [\n                [0.90, 0.05, 0.05],\n                [0.80, 0.10, 0.10],\n                [0.10, 0.80, 0.10],\n                [0.05, 0.10, 0.85],\n                [0.33, 0.33, 0.34],\n            ],\n            \"alpha_0\": [1.0, 1.0, 1.0],\n        },\n        {\n            \"Q\": [\n                [0.50, 0.50],\n                [0.70, 0.70],\n                [0.10, 0.10],\n                [1.00, 1.00],\n            ],\n            \"alpha_0\": [1.0, 1.0],\n        },\n        {\n            \"Q\": [\n                [0.60, 0.40, 0.00],\n                [0.10, 0.90, 0.00],\n                [0.50, 0.50, 0.00],\n                [0.90, 0.10, 0.00],\n            ],\n            \"alpha_0\": [1.0, 1.0, 1.0],\n        },\n        {\n            \"Q\": [\n                [0.40, 0.30, 0.20, 0.10],\n                [0.25, 0.25, 0.25, 0.25],\n                [0.10, 0.20, 0.30, 0.40],\n                [0.35, 0.30, 0.20, 0.15],\n                [0.05, 0.05, 0.45, 0.45],\n                [0.45, 0.10, 0.30, 0.15],\n            ],\n            \"alpha_0\": [1.0, 1.0, 1.0, 1.0],\n        },\n    ]\n\n    results = []\n    for case in test_cases:\n        result = _solve_case(case[\"Q\"], case[\"alpha_0\"])\n        results.append(result)\n\n    # Format the final output string as a list of lists.\n    # The string representation of each sublist is joined by a comma.\n    print(f\"[{','.join(map(str, results))}]\")\n\ndef _solve_case(Q_list, alpha_0_list):\n    \"\"\"\n    Solves a single test case for MAGE/CAGE analysis.\n    \"\"\"\n    # 1. Initialization\n    Q = np.array(Q_list, dtype=np.float64)\n    alpha_0 = np.array(alpha_0_list, dtype=np.float64)\n    R, L = Q.shape  # Number of reads and loci\n\n    p = np.full(L, 1.0 / L, dtype=np.float64)\n    \n    TOL = 1e-12\n    MAX_ITER = 10000\n\n    log_likelihood_old = -np.inf\n\n    # 2. Expectation-Maximization (EM) Loop\n    for _ in range(MAX_ITER):\n        # --- E-step: Compute responsibilities (gamma) ---\n        weighted_scores = Q @ p\n        numerator = p * Q  # Element-wise product, using broadcasting\n\n        # Denominator for Bayes' rule; has shape (R, 1) for broadcasting\n        denominator = weighted_scores.reshape(R, 1)\n        \n        gamma = np.zeros_like(Q)\n        \n        # Mask for reads with a non-zero marginal probability\n        non_zero_denom_mask = denominator.flatten() > 0\n        \n        # Standard case: update responsibilities where denominator is non-zero\n        gamma[non_zero_denom_mask, :] = numerator[non_zero_denom_mask, :] / denominator[non_zero_denom_mask]\n        \n        # Special convention: for uninformative reads (denominator is zero), gamma = p\n        zero_denom_mask = ~non_zero_denom_mask\n        if np.any(zero_denom_mask):\n            gamma[zero_denom_mask, :] = p\n        \n        # --- M-step: Update mixture proportions (p) ---\n        soft_counts = np.sum(gamma, axis=0)\n        p = soft_counts / R\n\n        # --- Convergence Check ---\n        # Recalculate weighted scores with new p\n        weighted_scores = Q @ p\n        \n        # Filter out zero scores to avoid log(0) -> -inf\n        valid_scores = weighted_scores[weighted_scores > 0]\n        \n        if len(valid_scores)  R:\n            log_likelihood_new = -np.inf\n        else:\n            log_likelihood_new = np.sum(np.log(valid_scores))\n\n        if abs(log_likelihood_new - log_likelihood_old)  TOL:\n            break\n        \n        log_likelihood_old = log_likelihood_new\n\n    # 3. Post-convergence computations using the final p\n    final_p = p\n    \n    # Re-compute final responsibilities with the MLE p\n    weighted_scores = Q @ final_p\n    numerator = final_p * Q\n    denominator = weighted_scores.reshape(R, 1)\n    final_gamma = np.zeros_like(Q)\n    non_zero_denom_mask = denominator.flatten() > 0\n    final_gamma[non_zero_denom_mask, :] = numerator[non_zero_denom_mask, :] / denominator[non_zero_denom_mask]\n    zero_denom_mask = ~non_zero_denom_mask\n    if np.any(zero_denom_mask):\n        final_gamma[zero_denom_mask, :] = final_p\n    \n    # --- Uncertainty in p (Posterior Standard Deviation) ---\n    final_soft_counts = np.sum(final_gamma, axis=0)\n    a = alpha_0 + final_soft_counts\n    A = np.sum(a)\n    \n    # Handle case where A+1 could be zero, though unlikely with alpha_0 > 0\n    if A == 0 or (A + 1) == 0:\n        var_p = np.zeros(L)\n    else:    \n        var_p = (a * (A - a)) / (A**2 * (A + 1))\n    \n    # Ensure variance is non-negative before taking sqrt\n    std_dev_p = np.sqrt(np.maximum(0, var_p))\n\n    # --- Uncertainty in assignments (Mean Per-Read Entropy) ---\n    # xlogy(x, y) computes x*log(y) and handles x=0 correctly\n    entropy_per_read = -np.sum(xlogy(final_gamma, final_gamma), axis=1)\n    H_bar = np.mean(entropy_per_read)\n\n    # 4. Format and return results\n    full_result = np.concatenate([final_p, std_dev_p, [H_bar]])\n    \n    # Round all final values to 6 decimal places\n    rounded_result = [round(x, 6) for x in full_result]\n    \n    return rounded_result\n\nsolve()\n\n```", "id": "2752515"}]}