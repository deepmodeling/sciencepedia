{"hands_on_practices": [{"introduction": "Understanding the cotangent space begins with its definition as the dual to the tangent space. This first exercise bridges the gap between the abstract definition of tangent vectors as derivations and covectors as linear functionals, and their concrete representation in a coordinate system [@problem_id:2994006]. By working through the case of $M = \\mathbb{R}^n$ from first principles, you will verify the fundamental isomorphism between covectors and row vectors, seeing how their pairing with tangent vectors manifests as simple matrix multiplication.", "problem": "Let $M = \\mathbb{R}^{n}$ with its standard smooth structure and global coordinates $x^{1}, \\dots, x^{n}$. Fix a point $p \\in \\mathbb{R}^{n}$. Using only the definition of the tangent space $T_{p}M$ as derivations at $p$ and the definition of the cotangent space $T_{p}^{*}M$ as the dual vector space of $T_{p}M$, answer the following in a logically complete derivation:\n\n- Construct the canonical basis $\\left\\{\\left.\\frac{\\partial}{\\partial x^{i}}\\right|_{p}\\right\\}_{i=1}^{n}$ of $T_{p}M$ and the dual basis $\\{dx^{i}|_{p}\\}_{i=1}^{n}$ of $T_{p}^{*}M$ from first principles, and justify the duality relation $dx^{i}|_{p}\\!\\left(\\left.\\frac{\\partial}{\\partial x^{j}}\\right|_{p}\\right) = \\delta^{i}{}_{j}$.\n\n- Using only the above definitions, identify $T_{p}M$ with column vectors in $\\mathbb{R}^{n}$ via the basis $\\left\\{\\left.\\frac{\\partial}{\\partial x^{i}}\\right|_{p}\\right\\}$, and identify $T_{p}^{*}M$ with row vectors in $\\mathbb{R}^{n}$ via the basis $\\{dx^{i}|_{p}\\}$. Verify that the natural pairing $T_{p}^{*}M \\times T_{p}M \\to \\mathbb{R}$ is given by row-by-column matrix multiplication.\n\nFinally, let $\\alpha \\in T_{p}^{*}M$ be specified by its values on the basis vectors $\\alpha\\!\\left(\\left.\\frac{\\partial}{\\partial x^{i}}\\right|_{p}\\right) = a_{i}$ for $i \\in \\{1,\\dots,n\\}$, and let $v \\in T_{p}M$ be given by $v = \\sum_{i=1}^{n} v^{i}\\left.\\frac{\\partial}{\\partial x^{i}}\\right|_{p}$. Compute the single analytic expression for $\\alpha(v)$ in terms of the symbols $a_{i}$ and $v^{i}$ (no numerical evaluation is required). Express your final answer as a single closed-form analytic expression.", "solution": "The problem as stated is valid, being well-posed, objective, and scientifically grounded in the standard framework of differential geometry. We shall proceed with the derivation from the specified first principles.\n\nLet $M = \\mathbb{R}^{n}$ be the smooth manifold with its standard smooth structure and global coordinate chart $(M, \\text{id})$, where the coordinate functions are $x^{1}, \\dots, x^{n}$. Let $p \\in M$ be a fixed point.\n\n**Part 1: Construction of the Tangent Space Basis and Dual Basis**\n\nThe tangent space $T_{p}M$ is defined as the vector space of all derivations at $p$. A derivation at $p$ is a linear map $v: C^{\\infty}(M) \\to \\mathbb{R}$ satisfying the product rule (Leibniz rule):\n$$v(fg) = f(p)v(g) + g(p)v(f) \\quad \\forall f, g \\in C^{\\infty}(M)$$\nwhere $C^{\\infty}(M)$ is the algebra of smooth real-valued functions on $M$.\n\nFor each coordinate $x^{i}$, we define an operator $\\left.\\frac{\\partial}{\\partial x^{i}}\\right|_{p}$ by its action on any smooth function $f \\in C^{\\infty}(M)$:\n$$\\left.\\frac{\\partial}{\\partial x^{i}}\\right|_{p}(f) := \\frac{\\partial f}{\\partial x^{i}}(p)$$\nThis operator is a derivation because it is linear and satisfies the Leibniz rule, inheriting these properties directly from the standard partial derivative.\n\nTo show that the set $\\left\\{\\left.\\frac{\\partial}{\\partial x^{i}}\\right|_{p}\\right\\}_{i=1}^{n}$ forms a basis for $T_{p}M$, we must prove linear independence and that it spans the space.\n- **Linear Independence**: Assume a linear combination is the zero derivation: $\\sum_{i=1}^{n} c^{i} \\left.\\frac{\\partial}{\\partial x^{i}}\\right|_{p} = 0$ for some coefficients $c^{i} \\in \\mathbb{R}$. Applying this derivation to the coordinate function $x^{j}$ for any $j \\in \\{1,\\dots,n\\}$ gives:\n$$0 = \\left(\\sum_{i=1}^{n} c^{i} \\left.\\frac{\\partial}{\\partial x^{i}}\\right|_{p}\\right)(x^{j}) = \\sum_{i=1}^{n} c^{i} \\frac{\\partial x^{j}}{\\partial x^{i}}(p) = \\sum_{i=1}^{n} c^{i} \\delta^{j}{}_{i} = c^{j}$$\nThus, $c^{j}=0$ for all $j$, proving linear independence.\n- **Spanning**: Let $v \\in T_{p}M$ be an arbitrary derivation. For any $f \\in C^{\\infty}(M)$, Taylor's theorem at $p$ gives $f(x) = f(p) + \\sum_{i=1}^{n} \\frac{\\partial f}{\\partial x^{i}}(p)(x^{i} - p^{i}) + O((x-p)^{2})$. Any derivation $v$ annihilates constants, so $v(f(p))=0$. Applying $v$ to the expansion and using the Leibniz rule shows that $v$ annihilates terms of order $2$ and higher in $(x-p)$. Thus, $v(f) = \\sum_{i=1}^{n} \\frac{\\partial f}{\\partial x^{i}}(p) v(x^{i})$. If we define the coefficients $v^{i} := v(x^{i})$, we can write $v(f) = \\sum_{i=1}^{n} v^{i} \\frac{\\partial f}{\\partial x^{i}}(p) = \\left(\\sum_{i=1}^{n} v^{i} \\left.\\frac{\\partial}{\\partial x^{i}}\\right|_{p}\\right)(f)$. Since this holds for all $f$, we have $v = \\sum_{i=1}^{n} v^{i} \\left.\\frac{\\partial}{\\partial x^{i}}\\right|_{p}$, which proves the set spans $T_{p}M$.\n\nThe cotangent space $T_{p}^{*}M$ is the dual vector space to $T_{p}M$. For any smooth function $f \\in C^{\\infty}(M)$, its differential at $p$, denoted $df|_{p}$, is an element of $T_{p}^{*}M$ defined by its action on any $v \\in T_{p}M$:\n$$df|_{p}(v) = v(f)$$\nWe construct the dual basis $\\{dx^{i}|_{p}\\}_{i=1}^{n}$ by taking the differentials of the coordinate functions $x^{i}$. To verify the duality relation, we apply $dx^{i}|_{p}$ to a basis vector $\\left.\\frac{\\partial}{\\partial x^{j}}\\right|_{p}$:\n$$dx^{i}|_{p}\\left(\\left.\\frac{\\partial}{\\partial x^{j}}\\right|_{p}\\right) = \\left.\\frac{\\partial}{\\partial x^{j}}\\right|_{p}(x^{i}) = \\frac{\\partial x^{i}}{\\partial x^{j}}(p) = \\delta^{i}{}_{j}$$\nThis equation is the defining property of a dual basis, thus confirming that $\\{dx^{i}|_{p}\\}$ is the basis of $T_{p}^{*}M$ dual to $\\left\\{\\left.\\frac{\\partial}{\\partial x^{j}}\\right|_{p}\\right\\}$.\n\n**Part 2: Representation and Pairing**\n\nA tangent vector $v \\in T_{p}M$ is written in the basis as $v = \\sum_{i=1}^{n} v^{i} \\left.\\frac{\\partial}{\\partial x^{i}}\\right|_{p}$. This establishes an isomorphism with the space of column vectors in $\\mathbb{R}^{n}$:\n$$v \\longleftrightarrow [v] = \\begin{pmatrix} v^{1} \\\\ \\vdots \\\\ v^{n} \\end{pmatrix}$$\nA cotangent vector (or covector) $\\alpha \\in T_{p}^{*}M$ is written in the dual basis as $\\alpha = \\sum_{j=1}^{n} a_{j} dx^{j}|_{p}$. The components $a_j$ are found by evaluating $\\alpha$ on the basis vectors: $a_{j} = \\alpha\\left(\\left.\\frac{\\partial}{\\partial x^{j}}\\right|_{p}\\right)$. This establishes an isomorphism with the space of row vectors in $\\mathbb{R}^{n}$:\n$$\\alpha \\longleftrightarrow [\\alpha] = \\begin{pmatrix} a_{1} & \\dots & a_{n} \\end{pmatrix}$$\nThe natural pairing $\\alpha(v)$ is a linear map from $T_{p}^{*}M \\times T_{p}M \\to \\mathbb{R}$. We compute its value using the basis expansions:\n$$\\alpha(v) = \\left(\\sum_{j=1}^{n} a_{j} dx^{j}|_{p}\\right) \\left(\\sum_{i=1}^{n} v^{i} \\left.\\frac{\\partial}{\\partial x^{i}}\\right|_{p}\\right) = \\sum_{i,j=1}^{n} a_{j}v^{i} \\left( dx^{j}|_{p}\\left(\\left.\\frac{\\partial}{\\partial x^{i}}\\right|_{p}\\right) \\right)$$\nUsing the duality relation $dx^{j}|_{p}\\left(\\left.\\frac{\\partial}{\\partial x^{i}}\\right|_{p}\\right) = \\delta^{j}{}_{i}$:\n$$\\alpha(v) = \\sum_{i,j=1}^{n} a_{j}v^{i} \\delta^{j}{}_{i} = \\sum_{i=1}^{n} a_{i}v^{i}$$\nThis scalar result is precisely the result of row-by-column matrix multiplication:\n$$[\\alpha][v] = \\begin{pmatrix} a_{1} & \\dots & a_{n} \\end{pmatrix} \\begin{pmatrix} v^{1} \\\\ \\vdots \\\\ v^{n} \\end{pmatrix} = \\sum_{i=1}^{n} a_{i}v^{i}$$\nThis verifies the correspondence.\n\n**Part 3: Final Computation**\n\nWe are given a covector $\\alpha \\in T_{p}^{*}M$ defined by its action on the basis vectors, $\\alpha\\left(\\left.\\frac{\\partial}{\\partial x^{i}}\\right|_{p}\\right) = a_{i}$, and a vector $v \\in T_{p}M$ given by its basis expansion $v = \\sum_{i=1}^{n} v^{i}\\left.\\frac{\\partial}{\\partial x^{i}}\\right|_{p}$.\nWe compute the value of $\\alpha(v)$ using the linearity of $\\alpha$:\n$$\\alpha(v) = \\alpha\\left(\\sum_{i=1}^{n} v^{i}\\left.\\frac{\\partial}{\\partial x^{i}}\\right|_{p}\\right)$$\n$$\\alpha(v) = \\sum_{i=1}^{n} v^{i} \\alpha\\left(\\left.\\frac{\\partial}{\\partial x^{i}}\\right|_{p}\\right)$$\nSubstituting the given definition for the components $a_{i}$:\n$$\\alpha(v) = \\sum_{i=1}^{n} v^{i} a_{i} = \\sum_{i=1}^{n} a_{i}v^{i}$$\nThis is the final analytical expression.", "answer": "$$\\boxed{\\sum_{i=1}^{n} a_{i}v^{i}}$$", "id": "2994006"}, {"introduction": "While the cotangent space is fundamentally a vector space, a Riemannian metric endows it with geometric structure. This structure is an inner product, $g^{-1}$, which allows us to define notions like length and orthogonality for covectors [@problem_id:2994026]. In this practice, you will use the Gram-Schmidt algorithm—a familiar tool from linear algebra—to transform a given coordinate-based coframe into an orthonormal one, providing a direct, computational experience of how the metric shapes the geometry of the cotangent space.", "problem": "Let $(M,g)$ be a Riemannian manifold and let $p \\in M$. Denote by $T_{p}M$ the tangent space at $p$ and by $T^{*}_{p}M$ the cotangent space at $p$. The Riemannian metric $g$ is a symmetric, positive-definite bilinear form on $T_{p}M$ and induces an inner product $g^{-1}$ on $T^{*}_{p}M$ via the inverse metric tensor, defined by the requirement that $g^{-1}(\\alpha,\\beta) = g(g^{-1}\\alpha,g^{-1}\\beta)$ for all $\\alpha,\\beta \\in T^{*}_{p}M$, where $g^{-1}:T^{*}_{p}M \\to T_{p}M$ is the musical isomorphism mapping covectors to vectors through the inverse metric.\n\nConsider a coordinate chart $(x^{1},x^{2})$ near $p$ and the coordinate frame $\\{\\partial/\\partial x^{1},\\partial/\\partial x^{2}\\}$ of $T_{p}M$, with dual coframe $\\{dx^{1},dx^{2}\\}$ of $T^{*}_{p}M$. Suppose the metric at $p$ has matrix\n$$\nG \\;=\\; \\begin{pmatrix} 2 & 0 \\\\ 0 & 1 \\end{pmatrix}\n$$\nwith respect to the basis $\\{\\partial/\\partial x^{1},\\partial/\\partial x^{2}\\}$, so the induced inner product $g^{-1}$ on $T^{*}_{p}M$ is represented by the matrix $G^{-1}$ with respect to $\\{dx^{1},dx^{2}\\}$. Let the initial coframe $\\{\\theta^{1},\\theta^{2}\\}$ at $p$ be given by\n$$\n\\theta^{1} \\;=\\; dx^{1} + dx^{2}, \\qquad \\theta^{2} \\;=\\; 2\\,dx^{1} + dx^{2}.\n$$\n\nStarting from the fundamental definitions of a Riemannian metric and the induced inner product on $T^{*}_{p}M$, explain why performing the Gram–Schmidt process on $\\{\\theta^{1},\\theta^{2}\\}$ with respect to $g^{-1}$ produces an orthonormal coframe at $p$. Then carry out this process explicitly to compute the transformation matrix $B$ such that\n$$\n\\begin{pmatrix} \\omega^{1} \\\\ \\omega^{2} \\end{pmatrix} \\;=\\; B \\begin{pmatrix} \\theta^{1} \\\\ \\theta^{2} \\end{pmatrix},\n$$\nwhere $\\{\\omega^{1},\\omega^{2}\\}$ is the resulting $g^{-1}$-orthonormal coframe. Express your final answer for $B$ in exact form with radicals if necessary. No rounding is required, and no physical units are involved. Provide the final matrix as your answer.", "solution": "The problem is first assessed for validity.\n\n### Step 1: Extract Givens\n-   **Manifold and Metric**: A Riemannian manifold $(M,g)$ with a point $p \\in M$.\n-   **Tangent and Cotangent Spaces**: $T_{p}M$ and $T^{*}_{p}M$.\n-   **Metric Properties**: $g$ is a symmetric, positive-definite bilinear form on $T_pM$. It induces an inner product $g^{-1}$ on $T^*_pM$ defined by $g^{-1}(\\alpha,\\beta) = g(g^{-1}\\alpha,g^{-1}\\beta)$ for $\\alpha,\\beta \\in T^{*}_{p}M$, where $g^{-1}: T^{*}_{p}M \\to T_{p}M$ is the musical isomorphism (commonly denoted $g^\\sharp$).\n-   **Coordinate System**: A chart $(x^{1},x^{2})$ near $p$, with coordinate basis $\\{\\partial/\\partial x^{1},\\partial/\\partial x^{2}\\}$ for $T_pM$ and dual coframe $\\{dx^{1},dx^{2}\\}$ for $T^*_pM$.\n-   **Metric Matrix**: At point $p$, the matrix of $g$ with respect to $\\{\\partial/\\partial x^{1},\\partial/\\partial x^{2}\\}$ is $G = \\begin{pmatrix} 2 & 0 \\\\ 0 & 1 \\end{pmatrix}$.\n-   **Induced Inner Product Matrix**: The matrix of the induced inner product $g^{-1}$ on $T^*_pM$ with respect to $\\{dx^{1},dx^{2}\\}$ is $G^{-1}$.\n-   **Initial Coframe**: A set of covectors $\\{\\theta^{1},\\theta^{2}\\}$ is given by $\\theta^{1} = dx^{1} + dx^{2}$ and $\\theta^{2} = 2\\,dx^{1} + dx^{2}$.\n-   **Task**: 1. Explain why the Gram-Schmidt process applied to $\\{\\theta^{1},\\theta^{2}\\}$ with respect to $g^{-1}$ yields an orthonormal coframe. 2. Perform the calculation to find the orthonormal coframe $\\{\\omega^{1},\\omega^{2}\\}$. 3. Determine the matrix $B$ such that $\\begin{pmatrix} \\omega^{1} \\\\ \\omega^{2} \\end{pmatrix} = B \\begin{pmatrix} \\theta^{1} \\\\ \\theta^{2} \\end{pmatrix}$.\n\n### Step 2: Validate Using Extracted Givens\n-   **Scientific Grounding**: The problem is set within the standard framework of Riemannian geometry. All concepts—tangent/cotangent spaces, metrics, musical isomorphisms, and the Gram-Schmidt process—are standard and correctly defined. The use of $g^{-1}$ to denote both the inner product on $T^*_pM$ and the musical isomorphism $g^\\sharp$ is a slight notational overload but is unambiguous in context and internally consistent.\n-   **Well-Posedness**: The problem is well-posed. A set of linearly independent vectors in an inner product space can be uniquely (up to sign choices inherent in the standard algorithm) converted into an orthonormal basis spanning the same space. The initial covectors are linearly independent, the inner product is properly defined by a positive-definite matrix, and the objective is a specific, computable matrix $B$.\n-   **Objectivity**: The problem is stated in precise, objective mathematical language.\n-   **Conclusion**: The problem is valid as it is scientifically sound, self-contained, and well-posed.\n\n### Solution\n\n**Part 1: Justification of the Gram-Schmidt Process**\n\nThe cotangent space $T^*_pM$ is a finite-dimensional real vector space. For this problem, its dimension is $2$.\nThe Riemannian metric $g$ at $p$ is a symmetric, positive-definite bilinear form on the tangent space $T_pM$. This structure induces an inner product on the cotangent space $T^*_pM$. As defined in the problem, for any two covectors $\\alpha, \\beta \\in T^*_pM$, this induced inner product, denoted $g^{-1}(\\cdot, \\cdot)$, is given by $g^{-1}(\\alpha,\\beta) = g(g^{-1}\\alpha, g^{-1}\\beta)$, where $g^{-1}: T^*_pM \\to T_pM$ is the musical isomorphism mapping covectors to vectors. Since $g$ is an inner product on $T_pM$ and the musical isomorphism is an isomorphism of vector spaces, the induced bilinear form $g^{-1}(\\cdot, \\cdot)$ is also symmetric and positive-definite, thus making it a valid inner product on $T^*_pM$.\nConsequently, $(T^*_pM, g^{-1})$ is a finite-dimensional inner product space.\n\nThe Gram-Schmidt process is a standard algorithm that takes a finite, linearly independent set of vectors in any inner product space and generates an orthonormal set of vectors spanning the same subspace.\nThe given initial coframe $\\{\\theta^1, \\theta^2\\}$ consists of two covectors, $\\theta^1 = dx^1 + dx^2$ and $\\theta^2 = 2dx^1 + dx^2$. In the basis $\\{dx^1, dx^2\\}$, these have coefficient vectors $(1, 1)$ and $(2, 1)$, respectively. The determinant of the matrix of these coefficients is $1 \\cdot 1 - 1 \\cdot 2 = -1 \\neq 0$, which confirms that $\\{\\theta^1, \\theta^2\\}$ is a linearly independent set and thus forms a basis for the $2$-dimensional space $T^*_pM$.\n\nBy its very definition, applying the Gram-Schmidt algorithm to the basis $\\{\\theta^1, \\theta^2\\}$ with respect to the inner product $g^{-1}$ will produce an orthonormal basis for $T^*_pM$, which is the desired orthonormal coframe $\\{\\omega^1, \\omega^2\\}$. Orthonormality means that $g^{-1}(\\omega^i, \\omega^j) = \\delta^{ij}$, where $\\delta^{ij}$ is the Kronecker delta.\n\n**Part 2: Explicit Gram-Schmidt Orthonormalization**\n\nThe matrix of the metric $g$ at $p$ with respect to the basis $\\{\\frac{\\partial}{\\partial x^1}, \\frac{\\partial}{\\partial x^2}\\}$ is given as\n$$G = \\begin{pmatrix} 2 & 0 \\\\ 0 & 1 \\end{pmatrix}$$\nThe components are $g_{11} = 2$, $g_{22} = 1$, and $g_{12} = g_{21} = 0$.\nThe matrix of the induced inner product $g^{-1}$ on $T^*_pM$ with respect to the dual basis $\\{dx^1, dx^2\\}$ is the inverse of $G$:\n$$G^{-1} = \\begin{pmatrix} 2 & 0 \\\\ 0 & 1 \\end{pmatrix}^{-1} = \\begin{pmatrix} \\frac{1}{2} & 0 \\\\ 0 & 1 \\end{pmatrix}$$\nThe components are $g^{11} = 1/2$, $g^{22} = 1$, and $g^{12} = g^{21} = 0$.\nFor any two covectors $\\alpha = \\alpha_1 dx^1 + \\alpha_2 dx^2$ and $\\beta = \\beta_1 dx^1 + \\beta_2 dx^2$, their inner product is\n$g^{-1}(\\alpha, \\beta) = \\sum_{i,j=1}^2 \\alpha_i \\beta_j g^{ij} = \\frac{1}{2}\\alpha_1\\beta_1 + \\alpha_2\\beta_2$.\nThe norm-squared of a covector $\\alpha$ is $\\|\\alpha\\|^2_{g^{-1}} = g^{-1}(\\alpha, \\alpha)$.\n\nLet's apply the Gram-Schmidt process to $\\{\\theta^1, \\theta^2\\}$.\n1.  **Construct $\\omega^1$**:\n    Let the first vector of the new basis be proportional to $\\theta^1$. We normalize it.\n    $\\theta^1 = 1 \\cdot dx^1 + 1 \\cdot dx^2$.\n    The norm-squared of $\\theta^1$ is:\n    $\\|\\theta^1\\|^2_{g^{-1}} = g^{-1}(\\theta^1, \\theta^1) = \\frac{1}{2}(1)^2 + (1)^2 = \\frac{1}{2} + 1 = \\frac{3}{2}$.\n    The norm is $\\|\\theta^1\\|_{g^{-1}} = \\sqrt{\\frac{3}{2}}$.\n    The first orthonormal covector is:\n    $\\omega^1 = \\frac{\\theta^1}{\\|\\theta^1\\|_{g^{-1}}} = \\frac{1}{\\sqrt{3/2}}\\theta^1 = \\sqrt{\\frac{2}{3}}\\theta^1$.\n\n2.  **Construct $\\omega^2$**:\n    First, we construct a vector $\\alpha^2$ orthogonal to $\\omega^1$ (and thus to $\\theta^1$):\n    $\\alpha^2 = \\theta^2 - \\text{proj}_{\\omega^1}\\theta^2 = \\theta^2 - g^{-1}(\\theta^2, \\omega^1)\\omega^1$.\n    We compute the inner product:\n    $g^{-1}(\\theta^2, \\omega^1) = g^{-1}(\\theta^2, \\sqrt{\\frac{2}{3}}\\theta^1) = \\sqrt{\\frac{2}{3}}g^{-1}(\\theta^2, \\theta^1)$.\n    $\\theta^2 = 2 \\cdot dx^1 + 1 \\cdot dx^2$.\n    $g^{-1}(\\theta^2, \\theta^1) = \\frac{1}{2}(2)(1) + (1)(1) = 1 + 1 = 2$.\n    So, $g^{-1}(\\theta^2, \\omega^1) = 2\\sqrt{\\frac{2}{3}}$.\n    Substituting this back into the expression for $\\alpha^2$:\n    $\\alpha^2 = \\theta^2 - \\left(2\\sqrt{\\frac{2}{3}}\\right) \\omega^1 = \\theta^2 - \\left(2\\sqrt{\\frac{2}{3}}\\right) \\left(\\sqrt{\\frac{2}{3}}\\theta^1\\right) = \\theta^2 - \\frac{4}{3}\\theta^1$.\n    Now, we normalize $\\alpha^2$ to get $\\omega^2$. Let's first express $\\alpha^2$ in the $\\{dx^1, dx^2\\}$ basis:\n    $\\alpha^2 = (2dx^1 + dx^2) - \\frac{4}{3}(dx^1 + dx^2) = (2 - \\frac{4}{3})dx^1 + (1 - \\frac{4}{3})dx^2 = \\frac{2}{3}dx^1 - \\frac{1}{3}dx^2$.\n    The norm-squared of $\\alpha^2$ is:\n    $\\|\\alpha^2\\|^2_{g^{-1}} = g^{-1}(\\alpha^2, \\alpha^2) = \\frac{1}{2}\\left(\\frac{2}{3}\\right)^2 + \\left(-\\frac{1}{3}\\right)^2 = \\frac{1}{2}\\left(\\frac{4}{9}\\right) + \\frac{1}{9} = \\frac{2}{9} + \\frac{1}{9} = \\frac{3}{9} = \\frac{1}{3}$.\n    The norm is $\\|\\alpha^2\\|_{g^{-1}} = \\sqrt{\\frac{1}{3}} = \\frac{1}{\\sqrt{3}}$.\n    The second orthonormal covector is:\n    $\\omega^2 = \\frac{\\alpha^2}{\\|\\alpha^2\\|_{g^{-1}}} = \\frac{1}{1/\\sqrt{3}}\\alpha^2 = \\sqrt{3}\\alpha^2 = \\sqrt{3}\\left(\\theta^2 - \\frac{4}{3}\\theta^1\\right)$.\n\n**Part 3: Determination of the Transformation Matrix $B$**\n\nWe have found the expressions for $\\{\\omega^1, \\omega^2\\}$ in terms of $\\{\\theta^1, \\theta^2\\}$:\n$\\omega^1 = \\sqrt{\\frac{2}{3}}\\theta^1 + 0 \\cdot \\theta^2$\n$\\omega^2 = \\sqrt{3}\\left(-\\frac{4}{3}\\theta^1 + \\theta^2\\right) = -\\frac{4\\sqrt{3}}{3}\\theta^1 + \\sqrt{3}\\theta^2$\n\nThe problem requires finding the matrix $B$ such that:\n$$\n\\begin{pmatrix} \\omega^{1} \\\\ \\omega^{2} \\end{pmatrix} \\;=\\; B \\begin{pmatrix} \\theta^{1} \\\\ \\theta^{2} \\end{pmatrix} \\;=\\; \\begin{pmatrix} b_{11} & b_{12} \\\\ b_{21} & b_{22} \\end{pmatrix} \\begin{pmatrix} \\theta^{1} \\\\ \\theta^{2} \\end{pmatrix}\n$$\nThis corresponds to the system of equations:\n$\\omega^1 = b_{11}\\theta^1 + b_{12}\\theta^2$\n$\\omega^2 = b_{21}\\theta^1 + b_{22}\\theta^2$\n\nBy comparing coefficients with our derived expressions, we identify the elements of $B$:\n$b_{11} = \\sqrt{\\frac{2}{3}}$\n$b_{12} = 0$\n$b_{21} = -\\frac{4\\sqrt{3}}{3}$\n$b_{22} = \\sqrt{3}$\n\nThus, the transformation matrix $B$ is:\n$$\nB = \\begin{pmatrix} \\sqrt{\\frac{2}{3}} & 0 \\\\ -\\frac{4\\sqrt{3}}{3} & \\sqrt{3} \\end{pmatrix}\n$$", "answer": "$$\n\\boxed{\\begin{pmatrix} \\sqrt{\\frac{2}{3}} & 0 \\\\ -\\frac{4\\sqrt{3}}{3} & \\sqrt{3} \\end{pmatrix}}\n$$", "id": "2994026"}, {"introduction": "A key skill in Riemannian geometry is the ability to work fluidly in different bases. While coordinate bases are convenient for calculus, orthonormal bases are essential for simplifying geometric expressions and understanding intrinsic properties. This exercise focuses on the practical task of changing the representation of a covector from a standard coordinate coframe to a custom orthonormal coframe [@problem_id:2994065]. By deriving and applying the change-of-basis rules for covector components, you will solidify your understanding of the relationship between tangent frames, dual coframes, and the metric that connects them.", "problem": "Let $(M,g)$ be a $3$-dimensional Riemannian manifold and let $p \\in M$ be a point with a local coordinate chart $(x^{1},x^{2},x^{3})$ around $p$. At the point $p$, the Riemannian metric has matrix representation with respect to the coordinate frame $\\{\\frac{\\partial}{\\partial x^{1}},\\frac{\\partial}{\\partial x^{2}},\\frac{\\partial}{\\partial x^{3}}\\}$ given by\n$$\n[g_{ij}(p)] \\;=\\; \\begin{pmatrix}\n4 & 0 & 0 \\\\\n0 & 9 & 0 \\\\\n0 & 0 & 16\n\\end{pmatrix}.\n$$\nLet $\\{dx^{1},dx^{2},dx^{3}\\}$ denote the coordinate coframe on the cotangent space $T^{*}_{p}M$. Define a frame $\\{E_{1},E_{2},E_{3}\\}$ of the tangent space $T_{p}M$ by\n$$\n\\begin{pmatrix}\nE_{1} \\\\\nE_{2} \\\\\nE_{3}\n\\end{pmatrix}\n\\;=\\;\nA\n\\begin{pmatrix}\n\\frac{\\partial}{\\partial x^{1}} \\\\\n\\frac{\\partial}{\\partial x^{2}} \\\\\n\\frac{\\partial}{\\partial x^{3}}\n\\end{pmatrix},\n\\qquad\nA \\;=\\; R D,\n$$\nwhere\n$$\nR \\;=\\; \\begin{pmatrix}\n\\frac{1}{\\sqrt{2}} & \\frac{1}{\\sqrt{2}} & 0 \\\\\n-\\frac{1}{\\sqrt{2}} & \\frac{1}{\\sqrt{2}} & 0 \\\\\n0 & 0 & 1\n\\end{pmatrix},\n\\qquad\nD \\;=\\; \\begin{pmatrix}\n\\frac{1}{2} & 0 & 0 \\\\\n0 & \\frac{1}{3} & 0 \\\\\n0 & 0 & \\frac{1}{4}\n\\end{pmatrix}.\n$$\nAssume the dual coframe $\\{e^{1},e^{2},e^{3}\\}$ on $T^{*}_{p}M$ is defined by the duality condition $e^{i}(E_{j})=\\delta^{i}{}_{j}$, where $\\delta^{i}{}_{j}$ is the Kronecker delta. Consider the covector $\\alpha_{p} \\in T^{*}_{p}M$ whose components in the coordinate coframe are\n$$\n\\alpha_{p} \\;=\\; 6\\,dx^{1} \\;-\\; 3\\,dx^{2} \\;+\\; 8\\,dx^{3}.\n$$\nStarting from the definitions of dual bases and the Riemannian inner product, derive the change-of-basis relation between the components of a covector in $\\{dx^{i}\\}$ and in $\\{e^{i}\\}$ using the matrix $A$, and compute the components of $\\alpha_{p}$ in the orthonormal coframe $\\{e^{i}\\}$. Provide your final answer as exact values; do not round.", "solution": "The problem provides a Riemannian manifold $(M,g)$ of dimension $3$, a point $p \\in M$, and a local coordinate chart $(x^1, x^2, x^3)$. At $p$, the coordinate basis for the tangent space $T_pM$ is $\\{\\partial_1, \\partial_2, \\partial_3\\}$, where $\\partial_i = \\frac{\\partial}{\\partial x^i}$. The metric tensor components in this basis are given by the matrix\n$$\n[g_{ij}(p)] = G = \\begin{pmatrix} 4 & 0 & 0 \\\\ 0 & 9 & 0 \\\\ 0 & 0 & 16 \\end{pmatrix}\n$$\nThe inner product of two coordinate basis vectors is $g(\\partial_i, \\partial_j) = g_{ij}$.\n\nA new frame $\\{E_1, E_2, E_3\\}$ for $T_pM$ is defined by the transformation\n$$\n\\begin{pmatrix} E_1 \\\\ E_2 \\\\ E_3 \\end{pmatrix} = A \\begin{pmatrix} \\partial_1 \\\\ \\partial_2 \\\\ \\partial_3 \\end{pmatrix}\n$$\nThis matrix equation corresponds to the component relations $E_i = \\sum_{j=1}^3 A_{ij} \\partial_j$ for $i=1, 2, 3$.\n\nThe dual coframe to $\\{E_i\\}$ is $\\{e^i\\}$, defined by the duality relation $e^i(E_j) = \\delta^i_j$. The coordinate coframe $\\{dx^i\\}$ is dual to the coordinate frame $\\{\\partial_j\\}$, so $dx^i(\\partial_j) = \\delta^i_j$.\n\nThe problem asks for two things: first, to derive the change-of-basis relation for the components of a covector between the coordinate coframe $\\{dx^i\\}$ and the new coframe $\\{e^i\\}$, and second, to compute the components of the specific covector $\\alpha_p = 6\\,dx^1 - 3\\,dx^2 + 8\\,dx^3$ in the new coframe.\n\nLet $\\alpha_p \\in T_p^*M$ be a covector. Its representation in the coordinate coframe is $\\alpha_p = \\sum_{i=1}^3 \\alpha_i dx^i$, where $(\\alpha_1, \\alpha_2, \\alpha_3) = (6, -3, 8)$. Its representation in the new coframe is $\\alpha_p = \\sum_{j=1}^3 \\tilde{\\alpha}_j e^j$. We need to find the components $\\tilde{\\alpha}_j$.\n\nThe components of a covector in a given basis are obtained by evaluating the covector on the corresponding basis vectors of the tangent space.\nThe components in the coordinate basis are $\\alpha_k = \\alpha_p(\\partial_k)$.\nThe components in the new basis are $\\tilde{\\alpha}_j = \\alpha_p(E_j)$.\n\nWe can relate these two sets of components using the transformation rule for the tangent vectors:\n$$\n\\tilde{\\alpha}_j = \\alpha_p(E_j)\n$$\nSubstituting the expression for $E_j$ in terms of $\\partial_k$:\n$$\n\\tilde{\\alpha}_j = \\alpha_p\\left(\\sum_{k=1}^3 A_{jk} \\partial_k\\right)\n$$\nSince $\\alpha_p$ is a linear functional (a covector), we can write:\n$$\n\\tilde{\\alpha}_j = \\sum_{k=1}^3 A_{jk} \\alpha_p(\\partial_k)\n$$\nRecognizing that $\\alpha_p(\\partial_k) = \\alpha_k$, we get the change-of-basis relation for the components:\n$$\n\\tilde{\\alpha}_j = \\sum_{k=1}^3 A_{jk} \\alpha_k\n$$\nIf we represent the components as column vectors $\\vec{\\alpha}_{\\text{coord}} = (\\alpha_1, \\alpha_2, \\alpha_3)^T$ and $\\vec{\\alpha}_{\\text{ONB}} = (\\tilde{\\alpha}_1, \\tilde{\\alpha}_2, \\tilde{\\alpha}_3)^T$, this relation is expressed in matrix form as:\n$$\n\\vec{\\alpha}_{\\text{ONB}} = A \\vec{\\alpha}_{\\text{coord}}\n$$\nThis is the required change-of-basis relation. The components of the covector in the new basis $\\{e^i\\}$ are obtained by left-multiplying the column vector of its components in the coordinate basis $\\{dx^i\\}$ by the matrix $A$.\n\nNext, we compute the matrix $A = RD$.\nGiven\n$$\nR = \\begin{pmatrix}\n\\frac{1}{\\sqrt{2}} & \\frac{1}{\\sqrt{2}} & 0 \\\\\n-\\frac{1}{\\sqrt{2}} & \\frac{1}{\\sqrt{2}} & 0 \\\\\n0 & 0 & 1\n\\end{pmatrix},\n\\qquad\nD = \\begin{pmatrix}\n\\frac{1}{2} & 0 & 0 \\\\\n0 & \\frac{1}{3} & 0 \\\\\n0 & 0 & \\frac{1}{4}\n\\end{pmatrix}\n$$\nThe product is:\n$$\nA = RD = \\begin{pmatrix}\n\\frac{1}{\\sqrt{2}} & \\frac{1}{\\sqrt{2}} & 0 \\\\\n-\\frac{1}{\\sqrt{2}} & \\frac{1}{\\sqrt{2}} & 0 \\\\\n0 & 0 & 1\n\\end{pmatrix}\n\\begin{pmatrix}\n\\frac{1}{2} & 0 & 0 \\\\\n0 & \\frac{1}{3} & 0 \\\\\n0 & 0 & \\frac{1}{4}\n\\end{pmatrix}\n= \\begin{pmatrix}\n\\frac{1}{2\\sqrt{2}} & \\frac{1}{3\\sqrt{2}} & 0 \\\\\n-\\frac{1}{2\\sqrt{2}} & \\frac{1}{3\\sqrt{2}} & 0 \\\\\n0 & 0 & \\frac{1}{4}\n\\end{pmatrix}\n$$\nThe components of $\\alpha_p$ in the coordinate coframe are given as $\\alpha_p = 6\\,dx^1 - 3\\,dx^2 + 8\\,dx^3$, so the component vector is:\n$$\n\\vec{\\alpha}_{\\text{coord}} = \\begin{pmatrix} 6 \\\\ -3 \\\\ 8 \\end{pmatrix}\n$$\nNow we compute the components $\\vec{\\alpha}_{\\text{ONB}}$ in the new coframe $\\{e^i\\}$:\n$$\n\\vec{\\alpha}_{\\text{ONB}} = A \\vec{\\alpha}_{\\text{coord}} = \n\\begin{pmatrix}\n\\frac{1}{2\\sqrt{2}} & \\frac{1}{3\\sqrt{2}} & 0 \\\\\n-\\frac{1}{2\\sqrt{2}} & \\frac{1}{3\\sqrt{2}} & 0 \\\\\n0 & 0 & \\frac{1}{4}\n\\end{pmatrix}\n\\begin{pmatrix} 6 \\\\ -3 \\\\ 8 \\end{pmatrix}\n$$\nPerforming the matrix-vector multiplication:\n$$\n\\tilde{\\alpha}_1 = \\left(\\frac{1}{2\\sqrt{2}}\\right)(6) + \\left(\\frac{1}{3\\sqrt{2}}\\right)(-3) + (0)(8) = \\frac{6}{2\\sqrt{2}} - \\frac{3}{3\\sqrt{2}} = \\frac{3}{\\sqrt{2}} - \\frac{1}{\\sqrt{2}} = \\frac{2}{\\sqrt{2}} = \\sqrt{2}\n$$\n$$\n\\tilde{\\alpha}_2 = \\left(-\\frac{1}{2\\sqrt{2}}\\right)(6) + \\left(\\frac{1}{3\\sqrt{2}}\\right)(-3) + (0)(8) = -\\frac{6}{2\\sqrt{2}} - \\frac{3}{3\\sqrt{2}} = -\\frac{3}{\\sqrt{2}} - \\frac{1}{\\sqrt{2}} = -\\frac{4}{\\sqrt{2}} = -2\\sqrt{2}\n$$\n$$\n\\tilde{\\alpha}_3 = (0)(6) + (0)(-3) + \\left(\\frac{1}{4}\\right)(8) = 2\n$$\nThus, the components of $\\alpha_p$ in the coframe $\\{e^1, e^2, e^3\\}$ are $(\\sqrt{2}, -2\\sqrt{2}, 2)$, and the covector can be written as $\\alpha_p = \\sqrt{2}\\,e^1 - 2\\sqrt{2}\\,e^2 + 2\\,e^3$.\nThe problem asks for the components. We present them as a row matrix.", "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n\\sqrt{2} & -2\\sqrt{2} & 2\n\\end{pmatrix}\n}\n$$", "id": "2994065"}]}