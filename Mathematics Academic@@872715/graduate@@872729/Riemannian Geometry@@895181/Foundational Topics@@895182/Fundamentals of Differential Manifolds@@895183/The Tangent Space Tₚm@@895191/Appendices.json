{"hands_on_practices": [{"introduction": "The modern definition of a tangent vector as a derivation on smooth functions can seem abstract at first. This foundational exercise bridges the gap between this abstraction and the familiar world of linear algebra. By working from first principles in the simple setting of $\\mathbb{R}^n$, you will see how the definition of tangent vectors as derivations naturally leads to their identification with column vectors, and their dual counterparts, covectors, with row vectors [@problem_id:2994006]. Mastering this connection is a crucial first step toward building a robust intuition for the tangent space.", "problem": "Let $M = \\mathbb{R}^{n}$ with its standard smooth structure and global coordinates $x^{1}, \\dots, x^{n}$. Fix a point $p \\in \\mathbb{R}^{n}$. Using only the definition of the tangent space $T_{p}M$ as derivations at $p$ and the definition of the cotangent space $T_{p}^{*}M$ as the dual vector space of $T_{p}M$, answer the following in a logically complete derivation:\n\n- Construct the canonical basis $\\left\\{\\left.\\frac{\\partial}{\\partial x^{i}}\\right|_{p}\\right\\}_{i=1}^{n}$ of $T_{p}M$ and the dual basis $\\{dx^{i}|_{p}\\}_{i=1}^{n}$ of $T_{p}^{*}M$ from first principles, and justify the duality relation $dx^{i}|_{p}\\!\\left(\\left.\\frac{\\partial}{\\partial x^{j}}\\right|_{p}\\right) = \\delta^{i}{}_{j}$.\n\n- Using only the above definitions, identify $T_{p}M$ with column vectors in $\\mathbb{R}^{n}$ via the basis $\\left\\{\\left.\\frac{\\partial}{\\partial x^{i}}\\right|_{p}\\right\\}$, and identify $T_{p}^{*}M$ with row vectors in $\\mathbb{R}^{n}$ via the basis $\\{dx^{i}|_{p}\\}$. Verify that the natural pairing $T_{p}^{*}M \\times T_{p}M \\to \\mathbb{R}$ is given by row-by-column matrix multiplication.\n\nFinally, let $\\alpha \\in T_{p}^{*}M$ be specified by its values on the basis vectors $\\alpha\\!\\left(\\left.\\frac{\\partial}{\\partial x^{i}}\\right|_{p}\\right) = a_{i}$ for $i \\in \\{1,\\dots,n\\}$, and let $v \\in T_{p}M$ be given by $v = \\sum_{i=1}^{n} v^{i}\\left.\\frac{\\partial}{\\partial x^{i}}\\right|_{p}$. Compute the single analytic expression for $\\alpha(v)$ in terms of the symbols $a_{i}$ and $v^{i}$ (no numerical evaluation is required). Express your final answer as a single closed-form analytic expression.", "solution": "Let $M = \\mathbb{R}^{n}$ be the smooth manifold with its standard smooth structure and global coordinate chart $(M, \\text{id})$, where the coordinate functions are $x^{1}, \\dots, x^{n}$. Let $p \\in M$ be a fixed point.\n\n**Part 1: Construction of the Tangent Space Basis and Dual Basis**\n\nThe tangent space $T_{p}M$ is defined as the vector space of all derivations at $p$. A derivation at $p$ is a linear map $v: C^{\\infty}(M) \\to \\mathbb{R}$ satisfying the product rule (Leibniz rule):\n$$v(fg) = f(p)v(g) + g(p)v(f) \\quad \\forall f, g \\in C^{\\infty}(M)$$\nwhere $C^{\\infty}(M)$ is the algebra of smooth real-valued functions on $M$.\n\nFor each coordinate $x^{i}$, we define an operator $\\left.\\frac{\\partial}{\\partial x^{i}}\\right|_{p}$ by its action on any smooth function $f \\in C^{\\infty}(M)$:\n$$\\left.\\frac{\\partial}{\\partial x^{i}}\\right|_{p}(f) := \\frac{\\partial f}{\\partial x^{i}}(p)$$\nThis operator is a derivation because it is linear and satisfies the Leibniz rule, inheriting these properties directly from the standard partial derivative.\n\nTo show that the set $\\left\\{\\left.\\frac{\\partial}{\\partial x^{i}}\\right|_{p}\\right\\}_{i=1}^{n}$ forms a basis for $T_{p}M$, we must prove linear independence and that it spans the space.\n- **Linear Independence**: Assume a linear combination is the zero derivation: $\\sum_{i=1}^{n} c^{i} \\left.\\frac{\\partial}{\\partial x^{i}}\\right|_{p} = 0$ for some coefficients $c^{i} \\in \\mathbb{R}$. Applying this derivation to the coordinate function $x^{j}$ for any $j \\in \\{1,\\dots,n\\}$ gives:\n$$0 = \\left(\\sum_{i=1}^{n} c^{i} \\left.\\frac{\\partial}{\\partial x^{i}}\\right|_{p}\\right)(x^{j}) = \\sum_{i=1}^{n} c^{i} \\frac{\\partial x^{j}}{\\partial x^{i}}(p) = \\sum_{i=1}^{n} c^{i} \\delta^{j}{}_{i} = c^{j}$$\nThus, $c^{j}=0$ for all $j$, proving linear independence.\n- **Spanning**: Let $v \\in T_{p}M$ be an arbitrary derivation. For any $f \\in C^{\\infty}(M)$, Taylor's theorem at $p$ gives $f(x) = f(p) + \\sum_{i=1}^{n} \\frac{\\partial f}{\\partial x^{i}}(p)(x^{i} - p^{i}) + O((x-p)^{2})$. Any derivation $v$ annihilates constants, so $v(f(p))=0$. Applying $v$ to the expansion and using the Leibniz rule shows that $v$ annihilates terms of order $2$ and higher in $(x-p)$. Thus, $v(f) = \\sum_{i=1}^{n} \\frac{\\partial f}{\\partial x^{i}}(p) v(x^{i})$. If we define the coefficients $v^{i} := v(x^{i})$, we can write $v(f) = \\sum_{i=1}^{n} v^{i} \\frac{\\partial f}{\\partial x^{i}}(p) = \\left(\\sum_{i=1}^{n} v^{i} \\left.\\frac{\\partial}{\\partial x^{i}}\\right|_{p}\\right)(f)$. Since this holds for all $f$, we have $v = \\sum_{i=1}^{n} v^{i} \\left.\\frac{\\partial}{\\partial x^{i}}\\right|_{p}$, which proves the set spans $T_{p}M$.\n\nThe cotangent space $T_{p}^{*}M$ is the dual vector space to $T_{p}M$. For any smooth function $f \\in C^{\\infty}(M)$, its differential at $p$, denoted $df|_{p}$, is an element of $T_{p}^{*}M$ defined by its action on any $v \\in T_{p}M$:\n$$df|_{p}(v) = v(f)$$\nWe construct the dual basis $\\{dx^{i}|_{p}\\}_{i=1}^{n}$ by taking the differentials of the coordinate functions $x^{i}$. To verify the duality relation, we apply $dx^{i}|_{p}$ to a basis vector $\\left.\\frac{\\partial}{\\partial x^{j}}\\right|_{p}$:\n$$dx^{i}|_{p}\\left(\\left.\\frac{\\partial}{\\partial x^{j}}\\right|_{p}\\right) = \\left.\\frac{\\partial}{\\partial x^{j}}\\right|_{p}(x^{i}) = \\frac{\\partial x^{i}}{\\partial x^{j}}(p) = \\delta^{i}{}_{j}$$\nThis equation is the defining property of a dual basis, thus confirming that $\\{dx^{i}|_{p}\\}$ is the basis of $T_{p}^{*}M$ dual to $\\left\\{\\left.\\frac{\\partial}{\\partial x^{j}}\\right|_{p}\\right\\}$.\n\n**Part 2: Representation and Pairing**\n\nA tangent vector $v \\in T_{p}M$ is written in the basis as $v = \\sum_{i=1}^{n} v^{i} \\left.\\frac{\\partial}{\\partial x^{i}}\\right|_{p}$. This establishes an isomorphism with the space of column vectors in $\\mathbb{R}^{n}$:\n$$v \\longleftrightarrow [v] = \\begin{pmatrix} v^{1} \\\\ \\vdots \\\\ v^{n} \\end{pmatrix}$$\nA cotangent vector (or covector) $\\alpha \\in T_{p}^{*}M$ is written in the dual basis as $\\alpha = \\sum_{j=1}^{n} a_{j} dx^{j}|_{p}$. The components $a_j$ are found by evaluating $\\alpha$ on the basis vectors: $a_{j} = \\alpha\\left(\\left.\\frac{\\partial}{\\partial x^{j}}\\right|_{p}\\right)$. This establishes an isomorphism with the space of row vectors in $\\mathbb{R}^{n}$:\n$$\\alpha \\longleftrightarrow [\\alpha] = \\begin{pmatrix} a_{1} & \\dots & a_{n} \\end{pmatrix}$$\nThe natural pairing $\\alpha(v)$ is a linear map from $T_{p}^{*}M \\times T_{p}M \\to \\mathbb{R}$. We compute its value using the basis expansions:\n$$\\alpha(v) = \\left(\\sum_{j=1}^{n} a_{j} dx^{j}|_{p}\\right) \\left(\\sum_{i=1}^{n} v^{i} \\left.\\frac{\\partial}{\\partial x^{i}}\\right|_{p}\\right) = \\sum_{i,j=1}^{n} a_{j}v^{i} \\left( dx^{j}|_{p}\\left(\\left.\\frac{\\partial}{\\partial x^{i}}\\right|_{p}\\right) \\right)$$\nUsing the duality relation $dx^{j}|_{p}\\left(\\left.\\frac{\\partial}{\\partial x^{i}}\\right|_{p}\\right) = \\delta^{j}{}_{i}$:\n$$\\alpha(v) = \\sum_{i,j=1}^{n} a_{j}v^{i} \\delta^{j}{}_{i} = \\sum_{i=1}^{n} a_{i}v^{i}$$\nThis scalar result is precisely the result of row-by-column matrix multiplication:\n$$[\\alpha][v] = \\begin{pmatrix} a_{1} & \\dots & a_{n} \\end{pmatrix} \\begin{pmatrix} v^{1} \\\\ \\vdots \\\\ v^{n} \\end{pmatrix} = \\sum_{i=1}^{n} a_{i}v^{i}$$\nThis verifies the correspondence.\n\n**Part 3: Final Computation**\n\nWe are given a covector $\\alpha \\in T_{p}^{*}M$ defined by its action on the basis vectors, $\\alpha\\left(\\left.\\frac{\\partial}{\\partial x^{i}}\\right|_{p}\\right) = a_{i}$, and a vector $v \\in T_{p}M$ given by its basis expansion $v = \\sum_{i=1}^{n} v^{i}\\left.\\frac{\\partial}{\\partial x^{i}}\\right|_{p}$.\nWe compute the value of $\\alpha(v)$ using the linearity of $\\alpha$:\n$$\\alpha(v) = \\alpha\\left(\\sum_{i=1}^{n} v^{i}\\left.\\frac{\\partial}{\\partial x^{i}}\\right|_{p}\\right)$$\n$$\\alpha(v) = \\sum_{i=1}^{n} v^{i} \\alpha\\left(\\left.\\frac{\\partial}{\\partial x^{i}}\\right|_{p}\\right)$$\nSubstituting the given definition for the components $a_{i}$:\n$$\\alpha(v) = \\sum_{i=1}^{n} v^{i} a_{i} = \\sum_{i=1}^{n} a_{i}v^{i}$$\nThis is the final analytical expression.", "answer": "$$\\boxed{\\sum_{i=1}^{n} a_{i}v^{i}}$$", "id": "2994006"}, {"introduction": "In practice, many manifolds are not given by an explicit parameterization but are defined implicitly as the level sets of functions in a higher-dimensional Euclidean space. This exercise provides a concrete application of multivariable calculus to determine the tangent space of such a manifold. You will compute a basis for the tangent space to a curve formed by the intersection of a sphere and a cone, reinforcing the powerful idea that the tangent space is the orthogonal complement to the space spanned by the gradients of the defining functions [@problem_id:1506518].", "problem": "Consider a manifold $M$ embedded in three-dimensional Euclidean space, $\\mathbb{R}^3$. The manifold is defined by the intersection of two surfaces: a sphere given by the equation $x^2 + y^2 + z^2 = 4$ and a cone given by the equation $z^2 = x^2 + y^2$.\nDetermine the components of a non-zero basis vector for the tangent space $T_P M$ to the manifold $M$ at the point $P = (\\sqrt{\\frac{3}{2}}, \\sqrt{\\frac{1}{2}}, \\sqrt{2})$.\nYour answer should be presented as a row matrix containing the three components of the vector.", "solution": "The manifold $M$ is defined by the set of points $(x, y, z) \\in \\mathbb{R}^3$ that satisfy the two simultaneous equations:\n1. $F_1(x, y, z) = x^2 + y^2 + z^2 - 4 = 0$\n2. $F_2(x, y, z) = x^2 + y^2 - z^2 = 0$\n\nThe tangent space $T_P M$ at a point $P$ on the manifold is the vector space of all tangent vectors to curves on $M$ passing through $P$. Since $M$ is defined by the level sets of $F_1$ and $F_2$, any tangent vector $\\mathbf{v} \\in T_P M$ must be orthogonal to the gradient vectors of both $F_1$ and $F_2$ at the point $P$. These gradient vectors, $\\nabla F_1(P)$ and $\\nabla F_2(P)$, form a basis for the normal space to the manifold at $P$.\n\nFirst, we compute the gradients of the functions $F_1$ and $F_2$:\n$$ \\nabla F_1 = \\left( \\frac{\\partial F_1}{\\partial x}, \\frac{\\partial F_1}{\\partial y}, \\frac{\\partial F_1}{\\partial z} \\right) = (2x, 2y, 2z) $$\n$$ \\nabla F_2 = \\left( \\frac{\\partial F_2}{\\partial x}, \\frac{\\partial F_2}{\\partial y}, \\frac{\\partial F_2}{\\partial z} \\right) = (2x, 2y, -2z) $$\n\nNext, we evaluate these gradients at the given point $P = (\\sqrt{\\frac{3}{2}}, \\sqrt{\\frac{1}{2}}, \\sqrt{2})$. Let's denote the resulting normal vectors as $\\mathbf{n}_1$ and $\\mathbf{n}_2$.\n$$ \\mathbf{n}_1 = \\nabla F_1(P) = \\left( 2\\sqrt{\\frac{3}{2}}, 2\\sqrt{\\frac{1}{2}}, 2\\sqrt{2} \\right) = (\\sqrt{4 \\cdot \\frac{3}{2}}, \\sqrt{4 \\cdot \\frac{1}{2}}, 2\\sqrt{2}) = (\\sqrt{6}, \\sqrt{2}, 2\\sqrt{2}) $$\n$$ \\mathbf{n}_2 = \\nabla F_2(P) = \\left( 2\\sqrt{\\frac{3}{2}}, 2\\sqrt{\\frac{1}{2}}, -2\\sqrt{2} \\right) = (\\sqrt{6}, \\sqrt{2}, -2\\sqrt{2}) $$\nThe intersection of the two surfaces forms a one-dimensional manifold (a curve). The tangent space $T_P M$ is therefore a one-dimensional line. A basis for this tangent space can be given by a single vector $\\mathbf{v}$ which is orthogonal to both $\\mathbf{n}_1$ and $\\mathbf{n}_2$. In $\\mathbb{R}^3$, such a vector can be found by computing the cross product of the two normal vectors.\n$$ \\mathbf{v}' = \\mathbf{n}_1 \\times \\mathbf{n}_2 = \\begin{vmatrix} \\mathbf{i} & \\mathbf{j} & \\mathbf{k} \\\\ \\sqrt{6} & \\sqrt{2} & 2\\sqrt{2} \\\\ \\sqrt{6} & \\sqrt{2} & -2\\sqrt{2} \\end{vmatrix} $$\nWe compute the components of the cross product:\nThe $x$-component is:\n$$ v_x' = (\\sqrt{2})(-2\\sqrt{2}) - (2\\sqrt{2})(\\sqrt{2}) = -4 - 4 = -8 $$\nThe $y$-component is:\n$$ v_y' = (2\\sqrt{2})(\\sqrt{6}) - (\\sqrt{6})(-2\\sqrt{2}) = 2\\sqrt{12} - (-2\\sqrt{12}) = 4\\sqrt{12} = 4(2\\sqrt{3}) = 8\\sqrt{3} $$\nThe $z$-component is:\n$$ v_z' = (\\sqrt{6})(\\sqrt{2}) - (\\sqrt{2})(\\sqrt{6}) = \\sqrt{12} - \\sqrt{12} = 0 $$\nSo, a tangent vector is $\\mathbf{v}' = (-8, 8\\sqrt{3}, 0)$.\n\nAny non-zero scalar multiple of $\\mathbf{v}'$ is also a valid basis vector for the one-dimensional tangent space $T_P M$. To simplify, we can divide $\\mathbf{v}'$ by the scalar $-8$. Let this simplified basis vector be $\\mathbf{v}$:\n$$ \\mathbf{v} = \\frac{1}{-8} \\mathbf{v}' = \\frac{1}{-8}(-8, 8\\sqrt{3}, 0) = (1, -\\sqrt{3}, 0) $$\nThe components of this basis vector are $(1, -\\sqrt{3}, 0)$. This is a valid basis vector for the tangent space $T_P M$.\n\nThus, a basis for the tangent space $T_P M$ is given by the vector $(1, -\\sqrt{3}, 0)$.", "answer": "$$\\boxed{\\begin{pmatrix} 1 & -\\sqrt{3} & 0 \\end{pmatrix}}$$", "id": "1506518"}, {"introduction": "A tangent space is fundamentally a vector space; it is the Riemannian metric $g$ that endows it with geometric structure, defining notions of length and angle. This practice demonstrates how the metric induces an inner product on the cotangent space, turning it into a Euclidean space in its own right. By applying the Gram-Schmidt process to a given basis of covectors, you will construct an orthonormal coframe, a fundamental technique that is the starting point for many advanced calculations in Riemannian geometry, from computing curvature to solving geodesic equations [@problem_id:2994026].", "problem": "Let $(M,g)$ be a Riemannian manifold and let $p \\in M$. Denote by $T_p M$ the tangent space at $p$ and by $T_p^* M$ the cotangent space at $p$. The Riemannian metric $g$ is a symmetric, positive-definite bilinear form on $T_p M$ and induces an inner product $g^{-1}$ on $T_p^* M$ via the inverse metric tensor, defined by the requirement that $g^{-1}(\\alpha,\\beta) = g(g^{-1}\\alpha,g^{-1}\\beta)$ for all $\\alpha,\\beta \\in T_p^* M$, where $g^{-1}:T_p^* M \\to T_p M$ is the musical isomorphism mapping covectors to vectors through the inverse metric.\n\nConsider a coordinate chart $(x^{1},x^{2})$ near $p$ and the coordinate frame $\\{\\partial/\\partial x^{1},\\partial/\\partial x^{2}\\}$ of $T_p M$, with dual coframe $\\{dx^{1},dx^{2}\\}$ of $T_p^* M$. Suppose the metric at $p$ has matrix\n$$\nG \\;=\\; \\begin{pmatrix} 2 & 0 \\\\ 0 & 1 \\end{pmatrix}\n$$\nwith respect to the basis $\\{\\partial/\\partial x^{1},\\partial/\\partial x^{2}\\}$, so the induced inner product $g^{-1}$ on $T_p^* M$ is represented by the matrix $G^{-1}$ with respect to $\\{dx^{1},dx^{2}\\}$. Let the initial coframe $\\{\\theta^{1},\\theta^{2}\\}$ at $p$ be given by\n$$\n\\theta^{1} \\;=\\; dx^{1} + dx^{2}, \\qquad \\theta^{2} \\;=\\; 2\\,dx^{1} + dx^{2}.\n$$\n\nStarting from the fundamental definitions of a Riemannian metric and the induced inner product on $T_p^* M$, explain why performing the Gramâ€“Schmidt process on $\\{\\theta^{1},\\theta^{2}\\}$ with respect to $g^{-1}$ produces an orthonormal coframe at $p$. Then carry out this process explicitly to compute the transformation matrix $B$ such that\n$$\n\\begin{pmatrix} \\omega^{1} \\\\ \\omega^{2} \\end{pmatrix} \\;=\\; B \\begin{pmatrix} \\theta^{1} \\\\ \\theta^{2} \\end{pmatrix},\n$$\nwhere $\\{\\omega^{1},\\omega^{2}\\}$ is the resulting $g^{-1}$-orthonormal coframe. Express your final answer for $B$ in exact form with radicals if necessary. No rounding is required, and no physical units are involved. Provide the final matrix as your answer.", "solution": "**Part 1: Justification of the Gram-Schmidt Process**\n\nThe cotangent space $T_p^* M$ is a finite-dimensional real vector space. For this problem, its dimension is $2$.\nThe Riemannian metric $g$ at $p$ is a symmetric, positive-definite bilinear form on the tangent space $T_p M$. This structure makes $T_p M$ an inner product space. The metric in turn induces an inner product on the cotangent space $T_p^* M$. This induced inner product, let's call it $\\tilde{g}$, is defined via the musical isomorphism $\\sharp: T_p^* M \\to T_p M$ by the relation $\\tilde{g}(\\alpha, \\beta) = g(\\alpha^\\sharp, \\beta^\\sharp)$. Since $g$ is an inner product and $\\sharp$ is a vector space isomorphism, $\\tilde{g}$ is also symmetric and positive-definite, thus making $(T_p^* M, \\tilde{g})$ a valid inner product space.\n\nThe Gram-Schmidt process is a standard algorithm that takes a finite, linearly independent set of vectors in any inner product space and generates an orthonormal set of vectors spanning the same subspace.\nThe given initial coframe $\\{\\theta^1, \\theta^2\\}$ consists of two covectors, $\\theta^1 = dx^1 + dx^2$ and $\\theta^2 = 2dx^1 + dx^2$. In the basis $\\{dx^1, dx^2\\}$, these have coefficient vectors $(1, 1)$ and $(2, 1)$, respectively. The determinant of the matrix of these coefficients is $1 \\cdot 1 - 1 \\cdot 2 = -1 \\neq 0$, which confirms that $\\{\\theta^1, \\theta^2\\}$ is a linearly independent set and thus forms a basis for the $2$-dimensional space $T_p^* M$.\n\nBy its very definition, applying the Gram-Schmidt algorithm to the basis $\\{\\theta^1, \\theta^2\\}$ with respect to the induced inner product (denoted $g^{-1}$ in the problem) will produce an orthonormal basis for $T_p^* M$, which is the desired orthonormal coframe $\\{\\omega^1, \\omega^2\\}$. Orthonormality means that $\\tilde{g}(\\omega^i, \\omega^j) = \\delta^{ij}$, where $\\delta^{ij}$ is the Kronecker delta.\n\n**Part 2: Explicit Gram-Schmidt Orthonormalization**\n\nThe matrix of the metric $g$ at $p$ with respect to the basis $\\{\\frac{\\partial}{\\partial x^1}, \\frac{\\partial}{\\partial x^2}\\}$ is given as\n$$G = \\begin{pmatrix} 2 & 0 \\\\ 0 & 1 \\end{pmatrix}$$\nThe matrix of the induced inner product on $T_p^* M$ with respect to the dual basis $\\{dx^1, dx^2\\}$ is the inverse of $G$:\n$$G^{-1} = \\begin{pmatrix} 2 & 0 \\\\ 0 & 1 \\end{pmatrix}^{-1} = \\begin{pmatrix} \\frac{1}{2} & 0 \\\\ 0 & 1 \\end{pmatrix}$$\nThe components are $g^{11} = 1/2$, $g^{22} = 1$, and $g^{12} = g^{21} = 0$.\nFor any two covectors $\\alpha = \\alpha_1 dx^1 + \\alpha_2 dx^2$ and $\\beta = \\beta_1 dx^1 + \\beta_2 dx^2$, their inner product (which we'll denote by angle brackets for simplicity) is\n$\\langle\\alpha, \\beta\\rangle = \\sum_{i,j=1}^2 \\alpha_i \\beta_j g^{ij} = \\frac{1}{2}\\alpha_1\\beta_1 + \\alpha_2\\beta_2$.\nThe norm-squared of a covector $\\alpha$ is $\\|\\alpha\\|^2 = \\langle\\alpha, \\alpha\\rangle$.\n\nLet's apply the Gram-Schmidt process to $\\{\\theta^1, \\theta^2\\}$.\n1.  **Construct $\\omega^1$**:\n    Let the first vector of the new basis be proportional to $\\theta^1$. We normalize it.\n    $\\theta^1 = 1 \\cdot dx^1 + 1 \\cdot dx^2$.\n    The norm-squared of $\\theta^1$ is:\n    $\\|\\theta^1\\|^2 = \\langle\\theta^1, \\theta^1\\rangle = \\frac{1}{2}(1)^2 + (1)^2 = \\frac{1}{2} + 1 = \\frac{3}{2}$.\n    The norm is $\\|\\theta^1\\| = \\sqrt{\\frac{3}{2}}$.\n    The first orthonormal covector is:\n    $\\omega^1 = \\frac{\\theta^1}{\\|\\theta^1\\|} = \\frac{1}{\\sqrt{3/2}}\\theta^1 = \\sqrt{\\frac{2}{3}}\\theta^1$.\n\n2.  **Construct $\\omega^2$**:\n    First, we construct a vector $\\alpha^2$ orthogonal to $\\omega^1$ (and thus to $\\theta^1$):\n    $\\alpha^2 = \\theta^2 - \\text{proj}_{\\omega^1}\\theta^2 = \\theta^2 - \\langle\\theta^2, \\omega^1\\rangle\\omega^1$.\n    We compute the inner product:\n    $\\langle\\theta^2, \\omega^1\\rangle = \\langle\\theta^2, \\sqrt{\\frac{2}{3}}\\theta^1\\rangle = \\sqrt{\\frac{2}{3}}\\langle\\theta^2, \\theta^1\\rangle$.\n    $\\theta^2 = 2 \\cdot dx^1 + 1 \\cdot dx^2$.\n    $\\langle\\theta^2, \\theta^1\\rangle = \\frac{1}{2}(2)(1) + (1)(1) = 1 + 1 = 2$.\n    So, $\\langle\\theta^2, \\omega^1\\rangle = 2\\sqrt{\\frac{2}{3}}$.\n    Substituting this back into the expression for $\\alpha^2$:\n    $\\alpha^2 = \\theta^2 - \\left(2\\sqrt{\\frac{2}{3}}\\right) \\omega^1 = \\theta^2 - \\left(2\\sqrt{\\frac{2}{3}}\\right) \\left(\\sqrt{\\frac{2}{3}}\\theta^1\\right) = \\theta^2 - \\frac{4}{3}\\theta^1$.\n    Now, we normalize $\\alpha^2$ to get $\\omega^2$. Let's first express $\\alpha^2$ in the $\\{dx^1, dx^2\\}$ basis:\n    $\\alpha^2 = (2dx^1 + dx^2) - \\frac{4}{3}(dx^1 + dx^2) = (2 - \\frac{4}{3})dx^1 + (1 - \\frac{4}{3})dx^2 = \\frac{2}{3}dx^1 - \\frac{1}{3}dx^2$.\n    The norm-squared of $\\alpha^2$ is:\n    $\\|\\alpha^2\\|^2 = \\langle\\alpha^2, \\alpha^2\\rangle = \\frac{1}{2}\\left(\\frac{2}{3}\\right)^2 + \\left(-\\frac{1}{3}\\right)^2 = \\frac{1}{2}\\left(\\frac{4}{9}\\right) + \\frac{1}{9} = \\frac{2}{9} + \\frac{1}{9} = \\frac{3}{9} = \\frac{1}{3}$.\n    The norm is $\\|\\alpha^2\\| = \\sqrt{\\frac{1}{3}} = \\frac{1}{\\sqrt{3}}$.\n    The second orthonormal covector is:\n    $\\omega^2 = \\frac{\\alpha^2}{\\|\\alpha^2\\|} = \\frac{1}{1/\\sqrt{3}}\\alpha^2 = \\sqrt{3}\\alpha^2 = \\sqrt{3}\\left(\\theta^2 - \\frac{4}{3}\\theta^1\\right)$.\n\n**Part 3: Determination of the Transformation Matrix $B$**\n\nWe have found the expressions for $\\{\\omega^1, \\omega^2\\}$ in terms of $\\{\\theta^1, \\theta^2\\}$:\n$\\omega^1 = \\sqrt{\\frac{2}{3}}\\theta^1 + 0 \\cdot \\theta^2$\n$\\omega^2 = \\sqrt{3}\\left(-\\frac{4}{3}\\theta^1 + \\theta^2\\right) = -\\frac{4\\sqrt{3}}{3}\\theta^1 + \\sqrt{3}\\theta^2$\n\nThe problem requires finding the matrix $B$ such that:\n$$\n\\begin{pmatrix} \\omega^{1} \\\\ \\omega^{2} \\end{pmatrix} \\;=\\; B \\begin{pmatrix} \\theta^{1} \\\\ \\theta^{2} \\end{pmatrix} \\;=\\; \\begin{pmatrix} b_{11} & b_{12} \\\\ b_{21} & b_{22} \\end{pmatrix} \\begin{pmatrix} \\theta^{1} \\\\ \\theta^{2} \\end{pmatrix}\n$$\nThis corresponds to the system of equations:\n$\\omega^1 = b_{11}\\theta^1 + b_{12}\\theta^2$\n$\\omega^2 = b_{21}\\theta^1 + b_{22}\\theta^2$\n\nBy comparing coefficients with our derived expressions, we identify the elements of $B$:\n$b_{11} = \\sqrt{\\frac{2}{3}}$\n$b_{12} = 0$\n$b_{21} = -\\frac{4\\sqrt{3}}{3}$\n$b_{22} = \\sqrt{3}$\n\nThus, the transformation matrix $B$ is:\n$$\nB = \\begin{pmatrix} \\sqrt{\\frac{2}{3}} & 0 \\\\ -\\frac{4\\sqrt{3}}{3} & \\sqrt{3} \\end{pmatrix}\n$$", "answer": "$$\n\\boxed{\\begin{pmatrix} \\sqrt{\\frac{2}{3}} & 0 \\\\ -\\frac{4\\sqrt{3}}{3} & \\sqrt{3} \\end{pmatrix}}\n$$", "id": "2994026"}]}