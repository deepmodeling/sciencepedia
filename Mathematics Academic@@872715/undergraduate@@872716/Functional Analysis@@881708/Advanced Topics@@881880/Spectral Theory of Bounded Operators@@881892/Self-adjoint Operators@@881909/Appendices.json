{"hands_on_practices": [{"introduction": "Understanding an abstract concept often begins with exploring its most concrete manifestation. For self-adjoint operators on a finite-dimensional complex vector space, the abstract definition translates into a very tangible property of its matrix representation: the matrix must be Hermitian, meaning it equals its own conjugate transpose. This exercise provides direct practice in manipulating matrices to enforce the self-adjoint condition, solidifying the link between the operator and its matrix form. [@problem_id:1879058]", "problem": "In the study of functional analysis, constructing operators with specific properties is a fundamental task. Consider the complex vector space $V = \\mathbb{C}^2$, equipped with the standard inner product. Let $A$ and $B$ be two linear operators on $V$. Their matrix representations with respect to the standard basis $\\{ (1,0), (0,1) \\}$ are given by:\n$$\nM_A = \\begin{pmatrix} 1 & 1+i \\\\ 1 & 2 \\end{pmatrix}\n\\quad \\text{and} \\quad\nM_B = \\begin{pmatrix} 0 & 1 \\\\ 0 & 0 \\end{pmatrix}\n$$\nA new operator, $L_{\\alpha}$, is defined as a linear combination of these operators: $L_{\\alpha} = A + \\alpha B$, where $\\alpha$ is a complex number.\n\nFind the complex number $\\alpha$ for which the operator $L_{\\alpha}$ is self-adjoint.", "solution": "On a complex inner product space with the standard inner product, a linear operator is self-adjoint if and only if its matrix in the standard basis is equal to its conjugate transpose. Denote the conjugate transpose by $^{*}$. For $L_{\\alpha} = A + \\alpha B$, its matrix is\n$$\nM_{L_{\\alpha}} = M_{A} + \\alpha M_{B}\n= \\begin{pmatrix} 1 & 1+i \\\\ 1 & 2 \\end{pmatrix} + \\alpha \\begin{pmatrix} 0 & 1 \\\\ 0 & 0 \\end{pmatrix}\n= \\begin{pmatrix} 1 & 1+i+\\alpha \\\\ 1 & 2 \\end{pmatrix}.\n$$\nSelf-adjointness requires $M_{L_{\\alpha}} = M_{L_{\\alpha}}^{*}$. Compute the conjugate transpose:\n$$\nM_{L_{\\alpha}}^{*} = \\begin{pmatrix} 1 & 1 \\\\ 1 - i + \\overline{\\alpha} & 2 \\end{pmatrix}.\n$$\nEquating entries gives the conditions\n$$\n1+i+\\alpha = 1, \\quad 1 = 1 - i + \\overline{\\alpha}.\n$$\nFrom the first equation, $\\alpha = -i$. Substituting into the second,\n$$\n1 - i + \\overline{\\alpha} = 1 - i + i = 1,\n$$\nwhich holds, so the choice is consistent. Therefore, the unique value ensuring self-adjointness is $\\alpha = -i$.", "answer": "$$\\boxed{-i}$$", "id": "1879058"}, {"introduction": "Moving from finite-dimensional vectors to infinite sequences brings us to the Hilbert space $\\ell^2(\\mathbb{C})$, a cornerstone of functional analysis. The right and left shift operators are some of the most fundamental and illustrative operators on this space, and their properties are essential to understand. This practice challenges you to compute the adjoint of a combination of these shifts, a key skill that requires applying the definition $\\langle Tx, y \\rangle = \\langle x, T^*y \\rangle$ directly in an infinite-dimensional setting. [@problem_id:1879064]", "problem": "Let $\\ell^2(\\mathbb{C})$ be the Hilbert space of all complex-valued sequences $x = (x_1, x_2, x_3, \\dots)$ such that $\\sum_{n=1}^{\\infty} |x_n|^2 < \\infty$. The inner product on this space is defined as $\\langle x, y \\rangle = \\sum_{n=1}^{\\infty} x_n \\overline{y_n}$ for any two sequences $x, y \\in \\ell^2(\\mathbb{C})$.\n\nConsider two linear operators, the right shift operator $R$ and the left shift operator $L$, which act on any sequence $x = (x_1, x_2, x_3, \\dots)$ in $\\ell^2(\\mathbb{C})$ as follows:\n$$R(x_1, x_2, x_3, \\dots) = (0, x_1, x_2, \\dots)$$\n$$L(x_1, x_2, x_3, \\dots) = (x_2, x_3, x_4, \\dots)$$\nNow, let's define a new operator $T$ as a linear combination of $R$ and $L$:\n$$T = \\alpha R + \\beta L$$\nwhere $\\alpha$ and $\\beta$ are complex constants.\n\nWhich of the following conditions on the constants $\\alpha$ and $\\beta$ is the necessary and sufficient condition for the operator $T$ to be a self-adjoint operator (i.e., $T = T^*$, where $T^*$ is the adjoint of $T$)?\n\nA. $\\alpha = \\beta$\n\nB. $\\alpha = -\\beta$\n\nC. $\\alpha = \\overline{\\beta}$\n\nD. $\\alpha + \\overline{\\beta} = 0$\n\nE. $|\\alpha| = |\\beta|$", "solution": "We work in the Hilbert space $\\ell^{2}(\\mathbb{C})$ with inner product $\\langle x, y \\rangle = \\sum_{n=1}^{\\infty} x_{n}\\overline{y_{n}}$, which is linear in the first argument and conjugate-linear in the second. The right shift $R$ and left shift $L$ are defined by\n$$\nR(x_{1},x_{2},x_{3},\\dots) = (0,x_{1},x_{2},\\dots), \\quad\nL(x_{1},x_{2},x_{3},\\dots) = (x_{2},x_{3},x_{4},\\dots).\n$$\nWe first compute the adjoints of $R$ and $L$. For any $x,y \\in \\ell^{2}(\\mathbb{C})$,\n$$\n\\langle Rx, y \\rangle = \\sum_{n=1}^{\\infty} (Rx)_{n}\\overline{y_{n}} = \\sum_{n=2}^{\\infty} x_{n-1}\\overline{y_{n}} = \\sum_{m=1}^{\\infty} x_{m}\\overline{y_{m+1}} = \\langle x, Ly \\rangle,\n$$\nwhich shows $R^{*} = L$. Similarly,\n$$\n\\langle Lx, y \\rangle = \\sum_{n=1}^{\\infty} x_{n+1}\\overline{y_{n}} = \\sum_{m=2}^{\\infty} x_{m}\\overline{y_{m-1}} = \\sum_{m=1}^{\\infty} x_{m}\\overline{(Ry)_{m}} = \\langle x, Ry \\rangle,\n$$\nso $L^{*} = R$.\n\nNow consider $T = \\alpha R + \\beta L$ with $\\alpha,\\beta \\in \\mathbb{C}$. Using linearity of the adjoint and conjugation of scalars, we have\n$$\nT^{*} = \\overline{\\alpha}\\,R^{*} + \\overline{\\beta}\\,L^{*} = \\overline{\\alpha}\\,L + \\overline{\\beta}\\,R.\n$$\nThe self-adjointness condition $T = T^{*}$ is therefore equivalent to\n$$\n\\alpha R + \\beta L = \\overline{\\alpha}\\,L + \\overline{\\beta}\\,R.\n$$\nRewriting,\n$$\n(\\alpha - \\overline{\\beta})R + (\\beta - \\overline{\\alpha})L = 0.\n$$\nTo conclude the coefficients must vanish, apply this operator to standard basis vectors. Let $e_{1} = (1,0,0,\\dots)$. Then $Re_{1} = (0,1,0,\\dots) \\neq 0$ and $Le_{1} = (0,0,0,\\dots) = 0$. Applying to $e_{1}$ gives\n$$\n(\\alpha - \\overline{\\beta})Re_{1} + (\\beta - \\overline{\\alpha})Le_{1} = (\\alpha - \\overline{\\beta})Re_{1} = 0,\n$$\nwhich implies $\\alpha = \\overline{\\beta}$. Substituting back shows also $\\beta = \\overline{\\alpha}$, which is the same condition. Hence, the necessary and sufficient condition for $T$ to be self-adjoint is\n$$\n\\alpha = \\overline{\\beta}.\n$$\nAmong the given options, this corresponds to option C.", "answer": "$$\\boxed{C}$$", "id": "1879064"}, {"introduction": "Alongside sequence spaces, spaces of functions like $L^2([0,1])$ are central to the study of analysis and its applications in physics and engineering. Integral operators are a major class of operators on these spaces, and the Volterra operator is a classic example. This exercise demonstrates how to find the adjoint of such an operator, a process that involves a powerful technique from calculus: changing the order of integration (Fubini's Theorem). [@problem_id:1879028]", "problem": "Consider the Hilbert space $L^2([0,1])$, which consists of complex-valued, square-integrable functions on the interval $[0,1]$. The inner product on this space is defined as $\\langle f, g \\rangle = \\int_0^1 f(x) \\overline{g(x)} dx$ for any functions $f, g \\in L^2([0,1])$.\n\nLet $V$ be the Volterra integral operator, which maps a function $f \\in L^2([0,1])$ to another function $(Vf)$ according to the rule:\n$$ (Vf)(x) = \\int_0^x f(t) dt $$\nAn operator $A$ is self-adjoint if it is equal to its adjoint operator $A^*$, where the adjoint is defined by the relation $\\langle Af, g \\rangle = \\langle f, A^*g \\rangle$ for all $f, g$ in the space.\n\nAnalyze the Volterra operator $V$ and determine which of the following statements is correct.\n\nA. $V$ is self-adjoint.\n\nB. $V$ is not self-adjoint, and its adjoint is given by $(V^*g)(x) = -\\int_0^x g(t) dt$.\n\nC. $V$ is not self-adjoint, and its adjoint is given by $(V^*g)(x) = \\int_x^1 g(t) dt$.\n\nD. $V$ is not self-adjoint, and its adjoint is given by $(V^*g)(x) = \\int_0^1 g(t) dt$.\n\nE. The adjoint operator $V^*$ does not exist for the Volterra operator on $L^2([0,1])$.", "solution": "To determine if the Volterra operator $V$ is self-adjoint, we must first find its adjoint operator, $V^*$. The adjoint operator is defined by the relation $\\langle Vf, g \\rangle = \\langle f, V^*g \\rangle$ for all functions $f, g \\in L^2([0,1])$.\n\nLet's start by calculating the left-hand side of the defining relation, $\\langle Vf, g \\rangle$. Using the definition of the inner product and the operator $V$:\n$$ \\langle Vf, g \\rangle = \\int_0^1 (Vf)(x) \\overline{g(x)} dx $$\nSubstituting the definition of $(Vf)(x)$:\n$$ \\langle Vf, g \\rangle = \\int_0^1 \\left( \\int_0^x f(t) dt \\right) \\overline{g(x)} dx $$\nThis is a double integral over a triangular region in the $tx$-plane. The region of integration is defined by the inequalities $0 \\le x \\le 1$ and $0 \\le t \\le x$. To proceed, we can change the order of integration. The current order is $dt$ then $dx$. We want to switch to $dx$ then $dt$.\n\nThe region can also be described by the inequalities $0 \\le t \\le 1$ and $t \\le x \\le 1$. This allows us to rewrite the integral as:\n$$ \\langle Vf, g \\rangle = \\int_0^1 \\int_t^1 \\left( f(t) \\overline{g(x)} \\right) dx dt $$\nSince $f(t)$ does not depend on $x$, we can move it outside the inner integral:\n$$ \\langle Vf, g \\rangle = \\int_0^1 f(t) \\left( \\int_t^1 \\overline{g(x)} dx \\right) dt $$\nWe want to express this in the form $\\langle f, V^*g \\rangle = \\int_0^1 f(t) \\overline{(V^*g)(t)} dt$. By comparing the two expressions, we can identify the term that corresponds to $\\overline{(V^*g)(t)}$:\n$$ \\overline{(V^*g)(t)} = \\int_t^1 \\overline{g(x)} dx $$\nTo find $(V^*g)(t)$, we take the complex conjugate of both sides.\n$$ (V^*g)(t) = \\overline{\\int_t^1 \\overline{g(x)} dx} $$\nThe conjugate of an integral is the integral of the conjugate:\n$$ (V^*g)(t) = \\int_t^1 \\overline{\\overline{g(x)}} dx = \\int_t^1 g(x) dx $$\nFor notational consistency, we can replace the integration variable $x$ with $t$ and the function variable $t$ with $x$:\n$$ (V^*g)(x) = \\int_x^1 g(t) dt $$\nNow we have found the adjoint operator $V^*$. We can compare it to the original operator $V$:\n$$ (Vf)(x) = \\int_0^x f(t) dt \\quad \\text{and} \\quad (V^*f)(x) = \\int_x^1 f(t) dt $$\nSince $(Vf)(x) \\neq (V^*f)(x)$ in general (for example, take $f(x)=1$, then $(Vf)(x)=x$ while $(V^*f)(x)=1-x$), the operator $V$ is not self-adjoint.\n\nThe correct statement is that $V$ is not self-adjoint, and its adjoint is given by $(V^*g)(x) = \\int_x^1 g(t) dt$. This corresponds to option C.", "answer": "$$\\boxed{C}$$", "id": "1879028"}]}