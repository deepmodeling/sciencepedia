{"hands_on_practices": [{"introduction": "The concept of a dense subset formalizes the idea of approximation. This first exercise makes the abstract definition of density tangible by exploring it within the sequence space $\\ell^1$. You will see how a simpler set of sequences—those with only a finite number of non-zero terms—can get arbitrarily close to any sequence in the entire space. This practice builds foundational intuition by translating the abstract idea of an $\\epsilon$-approximation into a concrete computational task. [@problem_id:1857752]", "problem": "Consider the space $\\ell^1$, which consists of all real-valued sequences $x = (x_1, x_2, x_3, \\dots)$ for which the series of absolute values converges, i.e., $\\sum_{k=1}^{\\infty} |x_k|  \\infty$. The distance between two sequences $x$ and $y$ in this space is defined by the $\\ell^1$-norm of their difference: $d(x, y) = \\|x - y\\|_1 = \\sum_{k=1}^{\\infty} |x_k - y_k|$.\n\nLet $C_{00}$ be the set of all sequences in $\\ell^1$ that have only a finite number of non-zero terms. An element of $C_{00}$ can be written as $(y_1, y_2, \\dots, y_N, 0, 0, \\dots)$ for some positive integer $N$.\n\nNow, consider the specific sequence $x \\in \\ell^1$ defined by $x_k = \\frac{1}{k(k+1)}$ for $k = 1, 2, 3, \\dots$. We want to approximate this sequence $x$ by a sequence $y \\in C_{00}$. A natural way to do this is to create a truncated sequence $y^{(N)}$ by keeping the first $N$ terms of $x$ and setting the rest to zero:\n$$y^{(N)} = (x_1, x_2, \\dots, x_N, 0, 0, \\dots)$$\nGiven $\\epsilon = 0.04$, what is the smallest positive integer $N$ such that the distance between $x$ and $y^{(N)}$ is less than $\\epsilon$?", "solution": "We have $x \\in \\ell^{1}$ with $x_{k}=\\frac{1}{k(k+1)}$ and its truncation $y^{(N)}$ defined by $y^{(N)}_{k}=x_{k}$ for $k \\leq N$ and $y^{(N)}_{k}=0$ for $k \\geq N+1$. Then\n$$\nd(x,y^{(N)})=\\sum_{k=1}^{\\infty}\\left|x_{k}-y^{(N)}_{k}\\right|=\\sum_{k=N+1}^{\\infty}|x_{k}|=\\sum_{k=N+1}^{\\infty}\\frac{1}{k(k+1)},\n$$\nsince $x_{k}0$ for all $k$ and the first $N$ terms cancel.\n\nUse the telescoping decomposition\n$$\n\\frac{1}{k(k+1)}=\\frac{1}{k}-\\frac{1}{k+1}.\n$$\nFor $M \\geq N+1$,\n$$\n\\sum_{k=N+1}^{M}\\frac{1}{k(k+1)}=\\sum_{k=N+1}^{M}\\left(\\frac{1}{k}-\\frac{1}{k+1}\\right)=\\frac{1}{N+1}-\\frac{1}{M+1}.\n$$\nTaking $M \\to \\infty$ gives\n$$\nd(x,y^{(N)})=\\sum_{k=N+1}^{\\infty}\\frac{1}{k(k+1)}=\\frac{1}{N+1}.\n$$\nWe require $d(x,y^{(N)})\\epsilon$ with $\\epsilon=0.04=\\frac{1}{25}$, i.e.,\n$$\n\\frac{1}{N+1}\\frac{1}{25}.\n$$\nSince both sides are positive, this is equivalent to $N+125$. The smallest positive integer $N$ satisfying this is $N=25$.", "answer": "$$\\boxed{25}$$", "id": "1857752"}, {"introduction": "We now shift our focus from sequences to functions. A central question in analysis is whether a simple family of functions, such as polynomials, can be used to approximate any continuous function. This problem requires you to apply the celebrated Stone-Weierstrass theorem, a cornerstone of approximation theory, to investigate this question. Rather than performing a direct calculation, you will use this powerful theorem to reason conceptually about the density of various sets of polynomials in subspaces of continuous functions. [@problem_id:1857732]", "problem": "Let $C[0,1]$ be the vector space of all continuous real-valued functions on the interval $[0,1]$, equipped with the supremum norm defined as $\\|f\\|_{\\infty} = \\sup_{x \\in [0,1]} |f(x)|$. We define the following subspaces and subsets of $C[0,1]$:\n\n*   $V_0 = \\{f \\in C[0,1] : f(0) = 0\\}$\n*   $V_1 = \\{f \\in C[0,1] : f(1) = 0\\}$\n*   $V_{01} = \\{f \\in C[0,1] : f(0) = 0 \\text{ and } f(1) = 0\\}$\n*   $I = \\{f \\in C[0,1] : \\int_0^1 f(x) dx = 0\\}$\n\nFurthermore, let $\\mathcal{P}$ denote the set of all polynomials with real coefficients, and let $\\mathcal{P}_0$ be the subset of $\\mathcal{P}$ containing polynomials with a zero constant term, i.e., for any $p(x) \\in \\mathcal{P}_0$, we have $p(0)=0$.\n\nA set of functions $\\mathcal{A}$ is said to be dense in a subspace $V$ if for every function $f \\in V$ and every $\\epsilon  0$, there exists a function $g \\in \\mathcal{A}$ such that $\\|f - g\\|_{\\infty}  \\epsilon$.\n\nWhich of the following statements about denseness is true?\n\nA. The set $\\mathcal{P}_0$ is dense in the subspace $V_1$.\n\nB. The set $\\mathcal{P}_0$ is dense in the subspace $V_{01}$.\n\nC. The set $\\mathcal{P}$ is dense in the subspace $I$.\n\nD. The set $\\{p \\in \\mathcal{P} : p(0)=p(1)\\}$ is dense in the subspace $\\{f \\in C[0,1] : f(0)=f(1)\\}$.\n\nE. The set $\\mathcal{P}_0$ is dense in the subspace $I$.", "solution": "The core principle in solving this problem is the Stone-Weierstrass theorem and the definition of a dense subset within a subspace. A set $\\mathcal{A}$ is dense in a subspace $V$ (with respect to the topology of the larger space, here $C[0,1]$) if and only if the closure of $\\mathcal{A}$, denoted $\\overline{\\mathcal{A}}$, contains $V$. That is, $V \\subseteq \\overline{\\mathcal{A}}$. We will analyze the closure of each approximating set of polynomials and then check the inclusion condition for each option.\n\nFirst, let's determine the closures of the relevant sets of polynomials.\n\n1.  **Closure of $\\mathcal{P}$**: The classic Stone-Weierstrass theorem states that if a subalgebra of $C(X, \\mathbb{R})$ (for a compact Hausdorff space $X$) separates points and contains the constant functions, it is dense in $C(X, \\mathbb{R})$. Here $X=[0,1]$. The set of all polynomials $\\mathcal{P}$ forms a subalgebra of $C[0,1]$, contains constant functions (e.g., $p(x)=1$), and separates points (e.g., $p(x)=x$ separates any two distinct points). Therefore, $\\mathcal{P}$ is dense in $C[0,1]$, which means $\\overline{\\mathcal{P}} = C[0,1]$.\n\n2.  **Closure of $\\mathcal{P}_0$**: The set $\\mathcal{P}_0 = \\{p \\in \\mathcal{P} : p(0)=0\\}$ is a subalgebra of $C[0,1]$. It separates points (e.g., $p(x)=x \\in \\mathcal{P}_0$ separates distinct points). The common set of zeros for all functions in $\\mathcal{P}_0$ is the single point $\\{0\\}$. A variation of the Stone-Weierstrass theorem states that the closure of such a subalgebra is the set of all continuous functions that vanish on this common set of zeros. Thus, $\\overline{\\mathcal{P}_0} = \\{f \\in C[0,1] : f(0)=0\\}$, which is precisely the subspace $V_0$.\n\n3.  **Closure of $\\mathcal{A}_* = \\{p \\in \\mathcal{P} : p(0)=p(1)\\}$**: Let $V_* = \\{f \\in C[0,1] : f(0)=f(1)\\}$. We want to find $\\overline{\\mathcal{A}_*}$. Let $f \\in V_*$ and $\\epsilon  0$. By the main Stone-Weierstrass theorem, there exists a polynomial $p \\in \\mathcal{P}$ such that $\\|f - p\\|_{\\infty}  \\epsilon/2$. Let $\\delta = p(1) - p(0)$. We construct a new polynomial $q(x) = p(x) - \\delta x$.\n    We check if $q \\in \\mathcal{A}_*$:\n    $q(0) = p(0) - \\delta(0) = p(0)$.\n    $q(1) = p(1) - \\delta(1) = p(1) - (p(1)-p(0)) = p(0)$.\n    Since $q(0)=q(1)$, $q$ is in $\\mathcal{A}_*$.\n    Now we check the approximation error:\n    $\\|f - q\\|_{\\infty} = \\|f - (p - \\delta x)\\|_{\\infty} = \\|(f-p) + \\delta x\\|_{\\infty} \\leq \\|f-p\\|_{\\infty} + \\|\\delta x\\|_{\\infty}$.\n    We know $\\|f-p\\|_{\\infty}  \\epsilon/2$ and $\\|\\delta x\\|_{\\infty} = |\\delta| \\sup_{x \\in [0,1]} |x| = |\\delta|$.\n    The value of $\\delta$ can be bounded:\n    $|\\delta| = |p(1) - p(0)| = |(p(1) - f(1)) - (p(0) - f(0))|$ since $f(1)=f(0)$.\n    $|\\delta| \\leq |p(1) - f(1)| + |p(0) - f(0)| \\leq \\|p-f\\|_{\\infty} + \\|p-f\\|_{\\infty}  \\epsilon/2 + \\epsilon/2 = \\epsilon$.\n    So, $\\|f - q\\|_{\\infty}  \\epsilon/2 + \\epsilon = \\frac{3}{2}\\epsilon$. Since $\\epsilon$ is arbitrary, we can make the approximation arbitrarily good. This shows that $\\mathcal{A}_*$ is dense in $V_*$, so $\\overline{\\mathcal{A}_*} = V_*$.\n\nNow we evaluate each option:\n\n**A. The set $\\mathcal{P}_0$ is dense in the subspace $V_1$.**\nThis requires $V_1 \\subseteq \\overline{\\mathcal{P}_0}$. We found $\\overline{\\mathcal{P}_0} = V_0$. The condition is $V_1 \\subseteq V_0$. This is false. For example, the function $f(x)=1-x$ is in $V_1$ because $f(1)=0$, but it is not in $V_0$ because $f(0)=1 \\neq 0$. So, **A is false**.\n\n**B. The set $\\mathcal{P}_0$ is dense in the subspace $V_{01}$.**\nThis requires $V_{01} \\subseteq \\overline{\\mathcal{P}_0} = V_0$. If a function $f$ is in $V_{01}$, then $f(0)=0$ and $f(1)=0$. By definition, any such function satisfies $f(0)=0$, so it must be in $V_0$. The inclusion $V_{01} \\subseteq V_0$ is true. Thus, **B is true**.\n\n**C. The set $\\mathcal{P}$ is dense in the subspace $I$.**\nThis requires $I \\subseteq \\overline{\\mathcal{P}}$. We found $\\overline{\\mathcal{P}} = C[0,1]$. The subspace $I$ is a set of continuous functions on $[0,1]$, so by definition, $I \\subseteq C[0,1]$. The inclusion is true. Thus, **C is true**.\n\n**D. The set $\\{p \\in \\mathcal{P} : p(0)=p(1)\\}$ is dense in the subspace $\\{f \\in C[0,1] : f(0)=f(1)\\}$.**\nThis requires $V_* \\subseteq \\overline{\\mathcal{A}_*}$, where these sets are as defined in our preliminary analysis. We showed that $\\overline{\\mathcal{A}_*} = V_*$. The inclusion $V_* \\subseteq V_*$ is trivially true. Thus, **D is true**.\n\n**E. The set $\\mathcal{P}_0$ is dense in the subspace $I$.**\nThis requires $I \\subseteq \\overline{\\mathcal{P}_0} = V_0$. This means that any continuous function with a zero integral must also be zero at the origin. This is false. Consider the function $f(x) = x - 1/2$. We have $\\int_0^1 (x-1/2)dx = [\\frac{x^2}{2} - \\frac{x}{2}]_0^1 = 0$, so $f \\in I$. However, $f(0)=-1/2 \\neq 0$, so $f \\notin V_0$. Thus, **E is false**.\n\nThe correct statements are B, C, and D.", "answer": "$$\\boxed{BCD}$$", "id": "1857732"}, {"introduction": "While the previous exercises focused on demonstrating density, it is equally important to know how to prove that a set is *not* dense. This practice introduces a powerful geometric technique for doing so within the context of a Hilbert space, $\\ell^2$. You will calculate the exact distance from a specific point to a subspace using the concept of orthogonal projection. By finding a non-zero distance, you will furnish a rigorous proof that the subspace fails to be dense, providing a crucial counterpoint to our study of approximation. [@problem_id:1857721]", "problem": "Consider the real Hilbert space $\\ell^2$, which consists of all real-valued sequences $x = (x_n)_{n=1}^\\infty$ for which the series $\\sum_{n=1}^\\infty x_n^2$ converges. The inner product for two sequences $u=(u_n)$ and $v=(v_n)$ in $\\ell^2$ is defined as $\\langle u, v \\rangle = \\sum_{n=1}^\\infty u_n v_n$, and the induced norm is given by $\\|x\\|_{\\ell^2} = \\sqrt{\\langle x, x \\rangle} = \\left(\\sum_{n=1}^\\infty x_n^2\\right)^{1/2}$.\n\nLet $M$ be the subspace of $\\ell^2$ defined as:\n$$M = \\{ x = (x_n)_{n=1}^\\infty \\in \\ell^2 \\mid x_1 - 3x_2 = 0 \\}$$\n\nNow, consider the specific sequence $y = (y_n)_{n=1}^\\infty$ in $\\ell^2$ where the $n$-th term is given by $y_n = \\left(\\frac{1}{2}\\right)^n$ for all integers $n \\ge 1$.\n\nYour task is to calculate the distance from the point $y$ to the subspace $M$. This distance is defined as $d(y, M) = \\inf_{x \\in M} \\|y-x\\|_{\\ell^2}$. Express your answer as a single closed-form analytic expression.", "solution": "We work in the real Hilbert space $\\ell^{2}$ with inner product $\\langle u,v\\rangle=\\sum_{n=1}^{\\infty}u_{n}v_{n}$. The subspace is\n$$\nM=\\{x\\in\\ell^{2}:\\ x_{1}-3x_{2}=0\\}.\n$$\nDefine $a=(1,-3,0,0,\\dots)\\in\\ell^{2}$. Then for any $x\\in\\ell^{2}$,\n$$\n\\langle x,a\\rangle=x_{1}-3x_{2},\n$$\nso $M=\\{x\\in\\ell^{2}:\\ \\langle x,a\\rangle=0\\}=\\ker\\langle\\cdot,a\\rangle$. Hence $M^{\\perp}=\\operatorname{span}\\{a\\}$.\n\nIn a Hilbert space, for a closed subspace $M$, the distance from $y$ to $M$ is the norm of the orthogonal projection of $y$ onto $M^{\\perp}$:\n$$\nd(y,M)=\\|P_{M^{\\perp}}y\\|.\n$$\nSince $M^{\\perp}=\\operatorname{span}\\{a\\}$, the orthogonal projection is\n$$\nP_{M^{\\perp}}y=\\frac{\\langle y,a\\rangle}{\\langle a,a\\rangle}a,\n$$\nand therefore\n$$\nd(y,M)=\\left\\|P_{M^{\\perp}}y\\right\\|=\\frac{|\\langle y,a\\rangle|}{\\|a\\|}.\n$$\n\nFor $y=(y_{n})$ with $y_{n}=\\left(\\frac{1}{2}\\right)^{n}$, we compute\n$$\n\\langle y,a\\rangle=y_{1}\\cdot 1+y_{2}\\cdot(-3)=\\left(\\frac{1}{2}\\right)-3\\left(\\frac{1}{4}\\right)=\\frac{1}{2}-\\frac{3}{4}=-\\frac{1}{4},\n$$\nand\n$$\n\\|a\\|=\\sqrt{\\langle a,a\\rangle}=\\sqrt{1^{2}+(-3)^{2}}=\\sqrt{10}.\n$$\nThus,\n$$\nd(y,M)=\\frac{\\left|-\\frac{1}{4}\\right|}{\\sqrt{10}}=\\frac{1}{4\\sqrt{10}}.\n$$", "answer": "$$\\boxed{\\frac{1}{4\\sqrt{10}}}$$", "id": "1857721"}]}