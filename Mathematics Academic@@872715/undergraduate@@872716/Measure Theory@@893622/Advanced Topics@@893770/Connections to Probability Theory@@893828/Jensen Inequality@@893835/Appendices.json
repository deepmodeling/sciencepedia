{"hands_on_practices": [{"introduction": "We begin with a foundational concept in statistics and physics: the relationship between the arithmetic mean and the root-mean-square (RMS) value. While they both measure central tendency, they are not identical. This exercise [@problem_id:2304611] invites you to discover the fundamental inequality that connects them by applying Jensen's inequality to the simple, convex function $f(x) = x^2$, providing a powerful insight into the nature of data dispersion.", "problem": "In statistical analysis of physical measurements, different types of averages are used to characterize a dataset. Consider a set of $N$ non-negative experimental outcomes, denoted by $\\{x_1, x_2, \\ldots, x_N\\}$, where each $x_i \\ge 0$.\n\nTwo fundamental quantities describing this dataset are:\n1.  The arithmetic mean, $\\mu$, defined as $\\mu = \\frac{1}{N} \\sum_{i=1}^{N} x_i$.\n2.  The Mean Square Value, $M_2$, defined as the square of the Root-Mean-Square (RMS) value: $M_2 = \\left(\\sqrt{\\frac{1}{N} \\sum_{i=1}^{N} x_i^2}\\right)^2 = \\frac{1}{N} \\sum_{i=1}^{N} x_i^2$.\n\nDetermine the greatest possible lower bound for the Mean Square Value, $M_2$, that can be expressed solely in terms of the arithmetic mean, $\\mu$. This bound must be valid for any choice of $N$ and any set of non-negative values $\\{x_1, x_2, \\ldots, x_N\\}$.", "solution": "We are given $x_{i} \\ge 0$ for $i=1,\\ldots,N$, the arithmetic mean $\\mu = \\frac{1}{N}\\sum_{i=1}^{N} x_{i}$, and the mean square value $M_{2} = \\frac{1}{N}\\sum_{i=1}^{N} x_{i}^{2}$. We seek the greatest possible lower bound for $M_{2}$ in terms of $\\mu$, valid for any $N$ and any such dataset.\n\nConsider the variance identity derived from the definition of variance:\n$$\n\\frac{1}{N}\\sum_{i=1}^{N} (x_{i} - \\mu)^{2} \\ge 0.\n$$\nExpanding the square and summing term-by-term gives\n$$\n\\frac{1}{N}\\sum_{i=1}^{N} \\left(x_{i}^{2} - 2\\mu x_{i} + \\mu^{2}\\right)\n= \\frac{1}{N}\\sum_{i=1}^{N} x_{i}^{2} - \\frac{2\\mu}{N}\\sum_{i=1}^{N} x_{i} + \\frac{1}{N}\\sum_{i=1}^{N} \\mu^{2}.\n$$\nUsing $\\sum_{i=1}^{N} x_{i} = N\\mu$ and $\\sum_{i=1}^{N} \\mu^{2} = N\\mu^{2}$, we obtain\n$$\n\\frac{1}{N}\\sum_{i=1}^{N} (x_{i} - \\mu)^{2}\n= \\frac{1}{N}\\sum_{i=1}^{N} x_{i}^{2} - 2\\mu^{2} + \\mu^{2}\n= \\left(\\frac{1}{N}\\sum_{i=1}^{N} x_{i}^{2}\\right) - \\mu^{2}\n= M_{2} - \\mu^{2}.\n$$\nSince the left-hand side is nonnegative, it follows that\n$$\nM_{2} - \\mu^{2} \\ge 0 \\quad \\Longrightarrow \\quad M_{2} \\ge \\mu^{2}.\n$$\nEquality holds if and only if $\\frac{1}{N}\\sum_{i=1}^{N} (x_{i} - \\mu)^{2} = 0$, which occurs exactly when $x_{1} = x_{2} = \\cdots = x_{N} = \\mu$. Therefore, the lower bound $M_{2} \\ge \\mu^{2}$ is tight and thus is the greatest possible lower bound that depends only on $\\mu$ and holds for all $N$ and all nonnegative datasets.", "answer": "$$\\boxed{\\mu^{2}}$$", "id": "2304611"}, {"introduction": "Jensen's inequality is not limited to convex functions; it works just as powerfully for concave functions, simply by reversing the inequality sign. This exercise [@problem_id:1926102] moves into the realm of probability theory, where calculating the exact expected value of a transformed random variable can be computationally intensive. You will see how to use the concavity of the natural logarithm function, $f(x) = \\ln(x)$, to swiftly establish a tight upper bound on an expectation, a technique with wide applications in information theory and Bayesian statistics.", "problem": "In Bayesian statistics, the Beta distribution serves as a conjugate prior for the parameter of a Bernoulli process. Let a random variable $X$ follow a Beta distribution with positive shape parameters $\\alpha > 0$ and $\\beta > 0$. The support of this distribution is the open interval $(0, 1)$. The expected value, or mean, of this random variable is given by the expression $E[X] = \\frac{\\alpha}{\\alpha + \\beta}$.\n\nWithout performing any integration, find a simple upper bound for the expected value of the natural logarithm of the random variable, denoted as $E[\\ln(X)]$. Express your answer as a closed-form analytic expression in terms of $\\alpha$ and $\\beta$.", "solution": "We are asked for a simple upper bound on $E[\\ln(X)]$ when $X \\sim \\operatorname{Beta}(\\alpha,\\beta)$ with $\\alpha0$ and $\\beta0$, without performing integration.\n\nFirst, recall that the natural logarithm function $\\ln(x)$ is concave on $(0,\\infty)$. Since the support of $X$ is $(0,1)$, this concavity applies on the support of $X$. By Jensen's inequality for a concave function $f$, we have $E[f(X)] \\leq f(E[X])$ whenever the expectation exists. Applying this with $f(x)=\\ln(x)$ gives\n$$\nE[\\ln(X)] \\leq \\ln\\big(E[X]\\big).\n$$\nFor a Beta random variable with parameters $\\alpha$ and $\\beta$, the mean is known (without integration) to be\n$$\nE[X] = \\frac{\\alpha}{\\alpha+\\beta}.\n$$\nSubstituting this into the Jensen bound yields the desired simple closed-form upper bound:\n$$\nE[\\ln(X)] \\leq \\ln\\!\\left(\\frac{\\alpha}{\\alpha+\\beta}\\right).\n$$\nThis completes the derivation of a simple upper bound in terms of $\\alpha$ and $\\beta$.", "answer": "$$\\boxed{\\ln\\!\\left(\\frac{\\alpha}{\\alpha+\\beta}\\right)}$$", "id": "1926102"}, {"introduction": "Beyond statistics and probability, Jensen's inequality proves to be a surprisingly elegant tool for solving optimization problems. This problem [@problem_id:2304596] presents a geometric challenge: finding the minimum value of a sum of tangents under a specific constraint. By recognizing the convexity of the tangent function over the relevant interval, you can bypass more complex calculus-based methods and find the solution with remarkable efficiency.", "problem": "Three variable acute angles, denoted by $\\alpha$, $\\beta$, and $\\gamma$, are constrained such that their sum is always equal to $\\frac{\\pi}{2}$ radians. Determine the minimum possible value of the expression $T = \\tan(\\alpha) + \\tan(\\beta) + \\tan(\\gamma)$. The angles are all strictly greater than 0 and strictly less than $\\frac{\\pi}{2}$ radians. Express your answer as a single closed-form analytic expression.", "solution": "Let the expression be $T = \\tan(\\alpha) + \\tan(\\beta) + \\tan(\\gamma)$. The angles $\\alpha, \\beta, \\gamma$ are in the interval $(0, \\frac{\\pi}{2})$.\n\nThe function $f(x) = \\tan(x)$ is convex on the interval $(0, \\frac{\\pi}{2})$. We can verify this by checking its second derivative:\n$f'(x) = \\sec^2(x)$\n$f''(x) = 2\\sec(x) \\cdot (\\sec(x)\\tan(x)) = 2\\sec^2(x)\\tan(x)$\nFor $x \\in (0, \\frac{\\pi}{2})$, both $\\sec^2(x)$ and $\\tan(x)$ are positive, so $f''(x) > 0$. This confirms that $\\tan(x)$ is strictly convex on this interval.\n\nWe can apply the discrete form of Jensen's inequality with equal weights $w_1=w_2=w_3=1/3$ to the points $\\alpha, \\beta, \\gamma$:\n$$\n\\frac{f(\\alpha) + f(\\beta) + f(\\gamma)}{3} \\ge f\\left(\\frac{\\alpha + \\beta + \\gamma}{3}\\right)\n$$\nSubstituting $f(x) = \\tan(x)$ and the expression for $T$:\n$$\n\\frac{\\tan(\\alpha) + \\tan(\\beta) + \\tan(\\gamma)}{3} \\ge \\tan\\left(\\frac{\\alpha + \\beta + \\gamma}{3}\\right)\n$$\n$$\n\\frac{T}{3} \\ge \\tan\\left(\\frac{\\alpha + \\beta + \\gamma}{3}\\right)\n$$\nWe are given the constraint $\\alpha + \\beta + \\gamma = \\frac{\\pi}{2}$. Substituting this into the inequality:\n$$\n\\frac{T}{3} \\ge \\tan\\left(\\frac{\\pi/2}{3}\\right) = \\tan\\left(\\frac{\\pi}{6}\\right)\n$$\nThe value of $\\tan(\\frac{\\pi}{6})$ is $\\frac{1}{\\sqrt{3}}$.\n$$\n\\frac{T}{3} \\ge \\frac{1}{\\sqrt{3}}\n$$\nSolving for $T$:\n$$\nT \\ge \\frac{3}{\\sqrt{3}} = \\sqrt{3}\n$$\nThis establishes a lower bound for $T$. For a strictly convex function, equality in Jensen's inequality holds if and only if the input points are equal, i.e., $\\alpha = \\beta = \\gamma$.\nGiven the constraint $\\alpha + \\beta + \\gamma = \\frac{\\pi}{2}$, this occurs when $\\alpha = \\beta = \\gamma = \\frac{\\pi}{6}$. Since these angles are acute and in $(0, \\frac{\\pi}{2})$, this is a valid configuration.\n\nTherefore, the minimum possible value of $T$ is $\\sqrt{3}$.", "answer": "$$\\boxed{\\sqrt{3}}$$", "id": "2304596"}]}