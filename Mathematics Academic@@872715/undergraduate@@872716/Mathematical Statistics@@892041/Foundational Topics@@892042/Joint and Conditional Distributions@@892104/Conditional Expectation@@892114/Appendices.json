{"hands_on_practices": [{"introduction": "We begin our practice with a foundational scenario involving discrete random variables. This exercise, focusing on the roll of two dice, is designed to build your intuition for how new information alters expected outcomes. By calculating the expected value of one die's outcome given a condition on the sum of both [@problem_id:1905679], you will directly apply the definition of conditional expectation by re-evaluating probabilities over a reduced, known sample space.", "problem": "Two fair, six-sided dice are rolled independently. Let $X_1$ represent the outcome of the first die and $X_2$ represent the outcome of the second die. Calculate the expected value of the first die's outcome, $X_1$, given that the sum of the outcomes of the two dice, $X_1+X_2$, is less than 5. Express your answer as a single fraction in simplest form.", "solution": "Let $X_{1}$ and $X_{2}$ be the outcomes of two independent fair six-sided dice, so each ordered pair $(i,j)$ with $i,j \\in \\{1,2,3,4,5,6\\}$ occurs with probability $1/36$. Define the event $A=\\{X_{1}+X_{2}<5\\}$. The definition of conditional expectation for a discrete random variable gives\n$$\n\\mathbb{E}[X_{1}\\mid A]=\\sum_{(i,j)\\in A} i\\;\\mathbb{P}((i,j)\\mid A).\n$$\nSince all pairs are equally likely and $A$ consists exactly of the pairs with $i+j<5$, we first enumerate\n$$\nA=\\{(1,1),(1,2),(2,1),(1,3),(2,2),(3,1)\\}.\n$$\nThus $|A|=6$, so\n$$\n\\mathbb{P}(A)=\\frac{6}{36}=\\frac{1}{6},\\qquad \\mathbb{P}((i,j)\\mid A)=\\frac{\\mathbb{P}((i,j))}{\\mathbb{P}(A)}=\\frac{1/36}{1/6}=\\frac{1}{6}\\quad \\text{for each }(i,j)\\in A.\n$$\nTherefore,\n$$\n\\mathbb{E}[X_{1}\\mid A]=\\sum_{(i,j)\\in A} i\\cdot \\frac{1}{6}=\\frac{1}{6}\\sum_{(i,j)\\in A} i.\n$$\nCompute the sum of the first coordinates over $A$:\n$$\n\\sum_{(i,j)\\in A} i=1+1+2+1+2+3=10.\n$$\nHence\n$$\n\\mathbb{E}[X_{1}\\mid X_{1}+X_{2}<5]=\\frac{1}{6}\\cdot 10=\\frac{5}{3}.\n$$", "answer": "$$\\boxed{\\frac{5}{3}}$$", "id": "1905679"}, {"introduction": "Moving from discrete to continuous random variables, we now explore conditional expectation in a geometric context. In this problem, a point is selected uniformly from a region defined by two curves. Your task is to find the expected value of the $Y$-coordinate given a specific value for the $X$-coordinate [@problem_id:1905673]. This practice illustrates the crucial technique of deriving a conditional probability density function, $f_{Y|X}(y|x)$, and using it to compute an expectation, which corresponds intuitively to finding the center of mass along a vertical slice of the region.", "problem": "A point $(X, Y)$ is chosen uniformly at random from the region $R$ in the first quadrant of the Cartesian plane. The region $R$ is bounded by the curves $y = \\sqrt{x}$ and $y = x^3$. Find the conditional expectation of the random variable $Y$ given that the random variable $X$ takes on the value $x$, for $0 < x < 1$. Your answer should be a closed-form analytic expression in terms of $x$.", "solution": "The region $R$ in the first quadrant bounded by $y=\\sqrt{x}$ and $y=x^{3}$ has intersection points where $\\sqrt{x}=x^{3}$, which gives $x=x^{6}$, so $x=0$ or $x=1$. For $0<x<1$, the vertical cross-section at a fixed $x$ runs from $y_{\\ell}=x^{3}$ to $y_{u}=\\sqrt{x}$, with $y_{u}>y_{\\ell}$.\n\nSince $(X,Y)$ is uniformly distributed over $R$, the joint density is\n$$\nf_{X,Y}(x,y)=\\frac{1}{|R|} \\quad \\text{for } (x,y)\\in R,\n$$\nwhere $|R|$ is the area of $R$. The marginal density of $X$ for $0<x<1$ is\n$$\nf_{X}(x)=\\int_{y=x^{3}}^{\\sqrt{x}} \\frac{1}{|R|}\\,dy=\\frac{\\sqrt{x}-x^{3}}{|R|}.\n$$\nHence, for $0<x<1$, the conditional density of $Y$ given $X=x$ is\n$$\nf_{Y\\mid X}(y\\mid x)=\\frac{f_{X,Y}(x,y)}{f_{X}(x)}=\\frac{1/|R|}{(\\sqrt{x}-x^{3})/|R|}=\\frac{1}{\\sqrt{x}-x^{3}}, \\quad x^{3}\\leq y\\leq \\sqrt{x}.\n$$\nTherefore, the conditional expectation is\n$$\n\\mathbb{E}[Y\\mid X=x]=\\int_{x^{3}}^{\\sqrt{x}} y\\,f_{Y\\mid X}(y\\mid x)\\,dy=\\int_{x^{3}}^{\\sqrt{x}} \\frac{y}{\\sqrt{x}-x^{3}}\\,dy.\n$$\nEvaluating the integral,\n$$\n\\mathbb{E}[Y\\mid X=x]=\\left.\\frac{y^{2}}{2(\\sqrt{x}-x^{3})}\\right|_{y=x^{3}}^{y=\\sqrt{x}}=\\frac{(\\sqrt{x})^{2}-(x^{3})^{2}}{2(\\sqrt{x}-x^{3})}=\\frac{x-x^{6}}{2(\\sqrt{x}-x^{3})}.\n$$\nSimplify by factoring the numerator as a difference of squares:\n$$\n\\frac{x-x^6}{2(\\sqrt{x}-x^3)} = \\frac{(x^{1/2})^2 - (x^3)^2}{2(\\sqrt{x}-x^3)} = \\frac{(x^{1/2}-x^3)(x^{1/2}+x^3)}{2(\\sqrt{x}-x^3)} = \\frac{x^{1/2}+x^3}{2}.\n$$\nThus, for $0<x<1$,\n$$\n\\mathbb{E}[Y\\mid X=x]=\\frac{x^{1/2}+x^{3}}{2}.\n$$", "answer": "$$\\boxed{\\frac{x^{1/2}+x^{3}}{2}}$$", "id": "1905673"}, {"introduction": "This final practice problem delves into a more nuanced aspect of conditional expectation involving transformations of random variables. Here, we define a new variable $Y$ as the absolute value of another continuous random variable $X$, and then condition on the value of $Y$ [@problem_id:1291523]. This exercise compellingly demonstrates that conditioning can fundamentally change the nature of a random variable; even though $X$ is continuous, its distribution, given that $|X|=y$, becomes discrete. Solving this will sharpen your understanding of how to construct a conditional expectation by correctly identifying the conditional sample space and its associated probabilities.", "problem": "A continuous random variable $X$ has a probability density function (PDF) given by\n$$ f_X(x) = \\begin{cases} \\frac{1}{2}(x+1) & \\text{if } x \\in [-1, 1] \\\\ 0 & \\text{otherwise} \\end{cases} $$\nA second random variable $Y$ is defined as the absolute value of $X$, i.e., $Y = |X|$.\n\nDetermine the conditional expectation of $X$ given that $Y=y$, where $y$ is a constant in the interval $(0, 1)$. Express your answer as a function of $y$.", "solution": "We are given a continuous random variable $X$ with density\n$$\nf_{X}(x)=\\begin{cases}\\frac{1}{2}(x+1), & x\\in[-1,1],\\\\ 0, & \\text{otherwise,}\\end{cases}\n$$\nand define $Y=|X|$. For a fixed $y\\in(0,1)$, the preimage of $y$ under $x\\mapsto |x|$ is $\\{y,-y\\}$.\n\nFor a transformation $Y=g(X)$ with finitely many preimages and differentiable $g$ at those points, the density of $Y$ is given by\n$$\nf_{Y}(y)=\\sum_{x:g(x)=y}\\frac{f_{X}(x)}{|g'(x)|}.\n$$\nHere $g(x)=|x|$, so for $y\\in(0,1)$ the relevant points are $x=y$ and $x=-y$, with $g'(y)=1$ and $g'(-y)=-1$, hence $\\lvert g'(y)\\rvert=\\lvert g'(-y)\\rvert=1$. Therefore,\n$$\nf_{Y}(y)=f_{X}(y)+f_{X}(-y).\n$$\nUsing the given $f_{X}$,\n$$\nf_{X}(y)=\\frac{1}{2}(y+1),\\qquad f_{X}(-y)=\\frac{1}{2}(1-y),\n$$\nso\n$$\nf_{Y}(y)=\\frac{1}{2}(y+1)+\\frac{1}{2}(1-y)=1.\n$$\n\nThe conditional distribution of $X$ given $Y=y$ assigns mass to $x=y$ and $x=-y$ in proportion to $\\frac{f_{X}(x)}{|g'(x)|}$, hence\n$$\n\\mathbb{P}(X=y\\mid Y=y)=\\frac{f_{X}(y)}{f_{Y}(y)},\\qquad \\mathbb{P}(X=-y\\mid Y=y)=\\frac{f_{X}(-y)}{f_{Y}(y)}.\n$$\nTherefore, the conditional expectation is\n$$\n\\mathbb{E}[X\\mid Y=y]=y\\cdot\\frac{f_{X}(y)}{f_{Y}(y)}+(-y)\\cdot\\frac{f_{X}(-y)}{f_{Y}(y)}=y\\cdot\\frac{f_{X}(y)-f_{X}(-y)}{f_{Y}(y)}.\n$$\nCompute the numerator:\n$$\nf_{X}(y)-f_{X}(-y)=\\frac{1}{2}(y+1)-\\frac{1}{2}(1-y)=\\frac{1}{2}(2y)=y,\n$$\nand use $f_{Y}(y)=1$ to get\n$$\n\\mathbb{E}[X\\mid Y=y]=y\\cdot\\frac{y}{1}=y^{2}.\n$$\nThis holds for $y\\in(0,1)$.", "answer": "$$\\boxed{y^{2}}$$", "id": "1291523"}]}