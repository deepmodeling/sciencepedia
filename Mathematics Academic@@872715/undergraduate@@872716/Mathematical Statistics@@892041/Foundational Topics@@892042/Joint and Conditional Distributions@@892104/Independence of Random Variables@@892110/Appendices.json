{"hands_on_practices": [{"introduction": "Understanding independence often begins with intuitive scenarios. This first exercise explores a common situation where two random variables are derived from the same sequence of events. By examining the number of defective microchips in overlapping segments of a production sequence, you will directly test the definition of independence, $P(X=x, Y=y) = P(X=x)P(Y=y)$, and see how a shared component can create statistical dependence [@problem_id:1922949].", "problem": "A quality control process involves testing a sequence of three identical microchips from a production line. For any given chip, it is either classified as 'Functional' (F) or 'Defective' (D). The probability of a chip being Defective is $0.5$, and the state of each chip is statistically independent of the others.\n\nLet the random variable $X$ be the total number of Defective chips among the first two chips in the sequence. Let the random variable $Y$ be the total number of Defective chips among the last two chips in the sequence.\n\nWhich of the following statements is correct?\n\nA. $X$ and $Y$ are independent.\nB. $X$ and $Y$ are not independent.\nC. There is not enough information to determine their independence.\nD. $X$ and $Y$ are perfectly correlated.", "solution": "Let $D_{i}\\in\\{0,1\\}$ be the indicator that chip $i$ is Defective, with $P(D_{i}=1)=\\frac{1}{2}$ and $P(D_{i}=0)=\\frac{1}{2}$, and $(D_{1},D_{2},D_{3})$ mutually independent. Then\n$$\nX=D_{1}+D_{2},\\qquad Y=D_{2}+D_{3}.\n$$\nWe test independence by checking whether $P(X=x,Y=y)=P(X=x)P(Y=y)$ holds for all $(x,y)$. A single counterexample suffices to prove non-independence.\n\nFirst, compute the marginal probabilities needed:\n$$\nP(X=0)=P(D_{1}=0,D_{2}=0)=P(D_{1}=0)P(D_{2}=0)=\\frac{1}{2}\\cdot\\frac{1}{2}=\\frac{1}{4},\n$$\n$$\nP(Y=2)=P(D_{2}=1,D_{3}=1)=P(D_{2}=1)P(D_{3}=1)=\\frac{1}{2}\\cdot\\frac{1}{2}=\\frac{1}{4}.\n$$\nThus,\n$$\nP(X=0)P(Y=2)=\\frac{1}{4}\\cdot\\frac{1}{4}=\\frac{1}{16}.\n$$\nNext, compute the corresponding joint probability:\n$$\nP(X=0,Y=2)=P(D_{1}=0,D_{2}=0\\ \\text{and}\\ D_{2}=1,D_{3}=1)=0,\n$$\nsince the event requires $D_{2}=0$ and $D_{2}=1$ simultaneously, which is impossible.\n\nBecause\n$$\nP(X=0,Y=2)=0\\neq \\frac{1}{16}=P(X=0)P(Y=2),\n$$\nthe random variables $X$ and $Y$ are not independent.\n\nAdditionally, $X$ and $Y$ are not perfectly correlated because, for example, when $X=1$ (which occurs with positive probability), $Y$ can take multiple values ($0,1,2$) with positive probability, so $Y$ is not a deterministic function of $X$. Therefore, the correct choice is that $X$ and $Y$ are not independent.", "answer": "$$\\boxed{B}$$", "id": "1922949"}, {"introduction": "We now shift our focus from discrete events to continuous variables, a common context in fields like engineering and physics. This practice involves the lifetimes of two different microchips, described by a joint probability density function (PDF). You will apply the fundamental test for independence of continuous random variables: determining if the joint PDF, $f(x,y)$, can be factored into the product of its marginal PDFs, $f_X(x)$ and $f_Y(y)$ [@problem_id:1922964]. This exercise provides essential practice in computing marginal distributions from a joint distribution.", "problem": "A quality control engineer is analyzing the lifetimes of two different microchips, Chip A and Chip B, which are integrated into a single device. Let the random variables $X$ and $Y$ represent the lifetimes, in thousands of hours, of Chip A and Chip B, respectively. The joint probability density function (PDF) for these two lifetimes is given by:\n$$ f(x,y) = \\begin{cases} 6 \\exp(-2x - 3y)  \\text{for } x > 0, y > 0 \\\\ 0  \\text{otherwise} \\end{cases} $$\nBased on this information, which of the following statements is true?\n\nA. The random variables $X$ and $Y$ are not independent.\nB. The marginal probability density function of $X$ is $f_X(x) = 3\\exp(-3x)$ for $x0$.\nC. The marginal probability density function of $Y$ is $f_Y(y) = 2\\exp(-2y)$ for $y0$.\nD. The random variables $X$ and $Y$ are independent.\nE. The expected lifetime of Chip A is equal to the expected lifetime of Chip B.", "solution": "The joint PDF is given by $f(x,y)=6\\exp(-2x-3y)$ for $x0$, $y0$, and $0$ otherwise. The marginal PDFs are obtained by integrating the joint PDF over the other variable:\n$$\nf_{X}(x)=\\int_{0}^{\\infty}6\\exp(-2x-3y)\\,dy=6\\exp(-2x)\\int_{0}^{\\infty}\\exp(-3y)\\,dy=6\\exp(-2x)\\cdot\\frac{1}{3}=2\\exp(-2x)\n$$\nfor $x0$, and\n$$\nf_{Y}(y)=\\int_{0}^{\\infty}6\\exp(-2x-3y)\\,dx=6\\exp(-3y)\\int_{0}^{\\infty}\\exp(-2x)\\,dx=6\\exp(-3y)\\cdot\\frac{1}{2}=3\\exp(-3y)\n$$\nfor $y0$.\n\nTo test independence, use the criterion that $X$ and $Y$ are independent if and only if $f(x,y)=f_{X}(x)f_{Y}(y)$ for all $(x,y)$ in the support. Compute\n$$\nf_{X}(x)f_{Y}(y)=\\left(2\\exp(-2x)\\right)\\left(3\\exp(-3y)\\right)=6\\exp(-2x-3y)=f(x,y),\n$$\nso $X$ and $Y$ are independent. Therefore, statement D is true and statement A is false.\n\nNext, compare the claimed marginals in B and C to the correct marginals. Statement B claims $f_{X}(x)=3\\exp(-3x)$, which is incorrect since $f_{X}(x)=2\\exp(-2x)$. Statement C claims $f_{Y}(y)=2\\exp(-2y)$, which is incorrect since $f_{Y}(y)=3\\exp(-3y)$.\n\nFinally, evaluate the expected values to assess statement E. Using the definition,\n$$\n\\mathbb{E}[X]=\\int_{0}^{\\infty}x\\,f_{X}(x)\\,dx=\\int_{0}^{\\infty}x\\cdot 2\\exp(-2x)\\,dx=\\frac{1}{2},\n$$\nand\n$$\n\\mathbb{E}[Y]=\\int_{0}^{\\infty}y\\,f_{Y}(y)\\,dy=\\int_{0}^{\\infty}y\\cdot 3\\exp(-3y)\\,dy=\\frac{1}{3}.\n$$\nSince $\\mathbb{E}[X]\\neq\\mathbb{E}[Y]$, statement E is false.\n\nThus, the only true statement is D.", "answer": "$$\\boxed{D}$$", "id": "1922964"}, {"introduction": "Is a \"uniform\" distribution synonymous with independence? This final practice challenges that common misconception by exploring a geometric probability problem. While the factorization of the PDF is a necessary condition for independence, it is not sufficient; the domain over which the variables are defined, known as the support, is equally critical. By analyzing the coordinates of a point chosen uniformly from a circular disk, you will discover why a non-rectangular support prevents independence, even when the density function itself is constant [@problem_id:1922966].", "problem": "A point $(X, Y)$ is chosen from a two-dimensional region such that the probability of the point falling in any subregion is proportional to the area of that subregion. This selection process is known as a uniform random selection. Consider the specific case where the point is selected uniformly at random from the area of a circular disk centered at the origin, defined by the inequality $x^2 + y^2 \\le 1$. The random variables $X$ and $Y$ represent the Cartesian coordinates of this point.\n\nBased on this scenario, which of the following statements about the statistical relationship between the random variables $X$ and $Y$ is correct?\n\nA. Yes, they are independent because the selection is uniform over the entire area.\nB. No, they are not independent.\nC. They would be independent only if the point were chosen from a square region instead of a disk.\nD. There is not enough information to determine their independence.\nE. Yes, they are independent because the marginal distributions for $X$ and $Y$ are identical.", "solution": "A point is chosen uniformly in the unit disk, so the joint probability density function is constant on the disk and zero outside. By the area rule, the constant must be the reciprocal of the area of the disk, hence\n$$\nf_{X,Y}(x,y)=\\frac{1}{\\pi}\\quad\\text{for }x^{2}+y^{2}\\le 1,\\quad\\text{and }f_{X,Y}(x,y)=0\\text{ otherwise}.\n$$\nThe marginal density of $X$ is obtained by integrating $f_{X,Y}$ over all $y$ that satisfy the constraint $x^{2}+y^{2}\\le 1$. For any $x$ with $|x|\\le 1$, the admissible $y$ range is from $-\\sqrt{1-x^{2}}$ to $\\sqrt{1-x^{2}}$, so\n$$\nf_{X}(x)=\\int_{-\\sqrt{1-x^{2}}}^{\\sqrt{1-x^{2}}}\\frac{1}{\\pi}\\,dy=\\frac{2}{\\pi}\\sqrt{1-x^{2}}\\quad\\text{for }|x|\\le 1,\\quad\\text{and }f_{X}(x)=0\\text{ otherwise}.\n$$\nBy symmetry, the marginal density of $Y$ is\n$$\nf_{Y}(y)=\\frac{2}{\\pi}\\sqrt{1-y^{2}}\\quad\\text{for }|y|\\le 1,\\quad\\text{and }f_{Y}(y)=0\\text{ otherwise}.\n$$\nIf $X$ and $Y$ were independent, then we would have $f_{X,Y}(x,y)=f_{X}(x)f_{Y}(y)$ for all $(x,y)$. However, for any $(x,y)$ with $|x|1$, $|y|1$, and $x^{2}+y^{2}1$, the joint density satisfies $f_{X,Y}(x,y)=0$ (since such points lie outside the disk), while the marginals satisfy $f_{X}(x)0$ and $f_{Y}(y)0$, hence $f_{X}(x)f_{Y}(y)0$. This contradicts the factorization required by independence.\n\nTherefore, $X$ and $Y$ are not independent. The correct choice is B.", "answer": "$$\\boxed{B}$$", "id": "1922966"}]}