{"hands_on_practices": [{"introduction": "Deviance serves as a key measure of how well a Generalized Linear Model fits the data, acting as a counterpart to the sum of squared residuals in ordinary least squares regression. To truly understand deviance, it's helpful to build it from the ground up. This first exercise [@problem_id:1930938] focuses on calculating the deviance contribution from a single observation, making the abstract statistical concept concrete and demonstrating how each data point informs the overall model's goodness-of-fit.", "problem": "A financial services company has developed a logistic regression model to predict whether a loan applicant will default on a loan. The outcome for the $i$-th applicant is a binary variable $y_i$, where $y_i=1$ indicates a default and $y_i=0$ indicates no default. The model provides a predicted probability of default, $\\hat{p}_i$.\n\nThe goodness-of-fit for such a model is often assessed using the deviance, which is based on the log-likelihood function. The contribution of a single observation to the total deviance is given by twice the difference between the log-likelihood of the saturated model (a model that fits the data perfectly) and the log-likelihood of the fitted model for that observation.\n\nConsider a single applicant for whom the model predicted a probability of default $\\hat{p} = 0.80$. In reality, this applicant did default on the loan, so the observed outcome is $y=1$.\n\nCalculate the numerical contribution of this single observation to the total deviance of the model. Round your final answer to four significant figures.", "solution": "For a Bernoulli observation with outcome $y \\in \\{0,1\\}$ and model-predicted probability $\\hat{p}$, the log-likelihood contribution of the fitted model is\n$$\n\\ell_{\\text{fit}}(y;\\hat{p})=y\\ln(\\hat{p})+(1-y)\\ln(1-\\hat{p}).\n$$\nThe saturated model fits the observation perfectly, assigning probability $1$ to the observed outcome, so its log-likelihood contribution is\n$$\n\\ell_{\\text{sat}}(y)=\\ln(1)=0.\n$$\nThe deviance contribution for a single observation is defined as\n$$\nD=2\\big(\\ell_{\\text{sat}}-\\ell_{\\text{fit}}\\big).\n$$\nWith $y=1$ and $\\hat{p}=0.80$, we have\n$$\n\\ell_{\\text{fit}}=\\ln(0.80),\n$$\nso\n$$\nD=2\\big(0-\\ln(0.80)\\big)=-2\\ln(0.80)=2\\ln\\!\\left(\\frac{1}{0.80}\\right)=2\\ln(1.25).\n$$\nNumerically,\n$$\n2\\ln(1.25)=2\\big(\\ln(5)-\\ln(4)\\big)\\approx 2\\times 0.2231435513\\approx 0.4462871026,\n$$\nwhich rounds to four significant figures as $0.4463$.", "answer": "$$\\boxed{0.4463}$$", "id": "1930938"}, {"introduction": "In a GLM, the link function provides the crucial bridge between the mean of the response variable and the linear predictor. However, not every function is suitable for this role. This problem [@problem_id:1930962] challenges you to evaluate a proposed link function against the fundamental requirement that it must correctly map the parameter space of the mean, such as probabilities in $(0,1)$, to the entire real line $(-\\infty, \\infty)$ where the linear predictor lives.", "problem": "In the framework of Generalized Linear Models (GLMs), the relationship between the expected value of a response variable, $\\mu = E[Y]$, and a linear predictor, $\\eta = \\mathbf{x}^T\\beta$, is established through a link function, $g$. The core equation is $g(\\mu) = \\eta$. For this model to be well-defined, the link function must map the space of possible values for the mean $\\mu$ to the space of possible values for the linear predictor $\\eta$.\n\nConsider a response variable $Y$ that follows a Bernoulli distribution, where $Y$ can take values $0$ or $1$. The mean of this variable, $\\mu = P(Y=1)$, is therefore restricted to the open interval $(0,1)$. The linear predictor $\\eta$, being a linear combination of explanatory variables, can theoretically take any value on the real line, i.e., $\\eta \\in (-\\infty, \\infty)$.\n\nAn analyst proposes using the function $g(\\mu) = \\mu^2$ as a link function for this Bernoulli GLM. Which of the following statements identifies the fundamental reason why this function is not suitable for this purpose?\n\nA. The function $g(\\mu) = \\mu^2$ is not the canonical link function for the Bernoulli distribution.\n\nB. The function $g(\\mu) = \\mu^2$ is not one-to-one over the entire real line.\n\nC. The range of the function $g(\\mu)$ for $\\mu \\in (0,1)$ does not cover the set of all real numbers.\n\nD. The inverse of the link function, $g^{-1}(\\eta)$, does not exist.\n\nE. The second derivative of the link function, $g''(\\mu)$, is not zero.", "solution": "In a generalized linear model, the link function $g$ must map the mean parameter space to the linear predictor space and be invertible so that, for any $\\eta \\in (-\\infty,\\infty)$, the inverse $g^{-1}(\\eta)$ yields a valid mean $\\mu$ in the allowable range. For a Bernoulli response, the mean satisfies $\\mu \\in (0,1)$, so a valid link must satisfy\n$$\ng:(0,1)\\to(-\\infty,\\infty)\n$$\nand be one-to-one with an inverse\n$$\ng^{-1}:(-\\infty,\\infty)\\to(0,1).\n$$\n\nConsider $g(\\mu)=\\mu^{2}$. For $\\mu \\in (0,1)$, we have $0<\\mu^{2}<1$, hence\n$$\ng\\big((0,1)\\big)=(0,1).\n$$\nTherefore, the range of $g$ over the admissible domain of $\\mu$ is $(0,1)$, which does not cover $(-\\infty,\\infty)$. Consequently, for any $\\eta \\notin (0,1)$, there is no $\\mu \\in (0,1)$ such that $g(\\mu)=\\eta$, and the inverse $g^{-1}(\\eta)=\\sqrt{\\eta}$ cannot be defined for all $\\eta \\in (-\\infty,\\infty)$. This violates the requirement that the link map be surjective onto the linear predictor space.\n\nEvaluating the options:\n- A is not fundamental; non-canonical links can still be valid.\n- B is irrelevant to the required domain; on $(0,1)$, $g$ is one-to-one.\n- C correctly identifies that $g\\big((0,1)\\big)\\neq(-\\infty,\\infty)$, which is the essential failure.\n- D is false as stated; an inverse exists but only on the restricted range $(0,1)$, not on $(-\\infty,\\infty)$.\n- E is irrelevant to link validity.\n\nThus, the fundamental reason is the range mismatch described in C.", "answer": "$$\\boxed{C}$$", "id": "1930962"}, {"introduction": "The choice between different valid link functions like the logit, probit, or complementary log-log is not merely academic; it has real consequences for model interpretation. This practice [@problem_id:1930929] provides a hands-on opportunity to quantify these differences by calculating the derivative $\\frac{d\\mu}{d\\eta}$, which measures the sensitivity of the predicted probability to changes in the linear predictor. By comparing this value for different links, you will gain a deeper intuition for their distinct characteristics and behaviors.", "problem": "In the framework of a Generalized Linear Model (GLM) for binary data, the link function, $g(\\mu)$, relates the expected value of the response variable, $\\mu = E[Y]$, to the linear predictor, $\\eta$. The linear predictor is a linear combination of explanatory variables. This relationship is given by $\\eta = g(\\mu)$, where $0 < \\mu < 1$. The quantity $\\frac{d\\mu}{d\\eta}$ represents the sensitivity of the mean response to a small change in the linear predictor.\n\nConsider the following three commonly used link functions:\n1.  **Logit**: $\\eta = \\ln\\left(\\frac{\\mu}{1-\\mu}\\right)$\n2.  **Probit**: $\\eta = \\Phi^{-1}(\\mu)$, where $\\Phi^{-1}$ is the quantile function (the inverse of the Cumulative Distribution Function) of the standard normal distribution. The probability density function of the standard normal distribution is $\\phi(z) = \\frac{1}{\\sqrt{2\\pi}}\\exp\\left(-\\frac{z^{2}}{2}\\right)$.\n3.  **Complementary log-log (cloglog)**: $\\eta = \\ln(-\\ln(1-\\mu))$\n\nCalculate the numerical value of the derivative $\\frac{d\\mu}{d\\eta}$ for each of these three models, evaluated at the point where the mean response is $\\mu = 0.5$.\n\nPresent your three results as a single collection of numbers, corresponding to the logit, probit, and cloglog models, in that specific order. Round each numerical value to four significant figures.", "solution": "We seek $d\\mu/d\\eta$ for each link at $\\mu=0.5$. In a GLM, with link $\\eta=g(\\mu)$, the inverse link is $\\mu=g^{-1}(\\eta)$ and the derivative satisfies\n$$\n\\frac{d\\mu}{d\\eta}=\\frac{1}{g'(\\mu)}.\n$$\n\nLogit link: $g(\\mu)=\\ln\\!\\left(\\frac{\\mu}{1-\\mu}\\right)$. Differentiate:\n$$\ng'(\\mu)=\\frac{d}{d\\mu}\\left[\\ln(\\mu)-\\ln(1-\\mu)\\right]=\\frac{1}{\\mu}+\\frac{1}{1-\\mu}=\\frac{1}{\\mu(1-\\mu)}.\n$$\nHence,\n$$\n\\frac{d\\mu}{d\\eta}=\\mu(1-\\mu).\n$$\nAt $\\mu=0.5$, $\\frac{d\\mu}{d\\eta}=0.5\\times 0.5=0.25$.\n\nProbit link: $g(\\mu)=\\Phi^{-1}(\\mu)$. Using the derivative of the inverse function,\n$$\ng'(\\mu)=\\frac{1}{\\Phi'\\!\\left(\\Phi^{-1}(\\mu)\\right)}=\\frac{1}{\\phi\\!\\left(\\Phi^{-1}(\\mu)\\right)}.\n$$\nThus,\n$$\n\\frac{d\\mu}{d\\eta}=\\phi\\!\\left(\\Phi^{-1}(\\mu)\\right).\n$$\nAt $\\mu=0.5$, $\\eta=\\Phi^{-1}(0.5)=0$, and $\\phi(0)=\\frac{1}{\\sqrt{2\\pi}}$. Numerically, $\\frac{1}{\\sqrt{2\\pi}}\\approx 0.3989$ to four significant figures.\n\nComplementary log-log link: $g(\\mu)=\\ln\\!\\big(-\\ln(1-\\mu)\\big)$. Differentiate using the chain rule:\n$$\ng'(\\mu)=\\frac{1}{-\\ln(1-\\mu)}\\cdot\\frac{d}{d\\mu}\\big[-\\ln(1-\\mu)\\big]=\\frac{1}{-\\ln(1-\\mu)}\\cdot\\frac{1}{1-\\mu}=\\frac{1}{(1-\\mu)\\big(-\\ln(1-\\mu)\\big)}.\n$$\nTherefore,\n$$\n\\frac{d\\mu}{d\\eta}=(1-\\mu)\\big(-\\ln(1-\\mu)\\big).\n$$\nAt $\\mu=0.5$, this is $(1-0.5)\\big(-\\ln(0.5)\\big)=0.5\\ln 2\\approx 0.3466$ to four significant figures.\n\nCollecting the results in the order logit, probit, cloglog and rounding to four significant figures gives $0.2500$, $0.3989$, $0.3466$.", "answer": "$$\\boxed{\\begin{pmatrix}0.2500 & 0.3989 & 0.3466\\end{pmatrix}}$$", "id": "1930929"}]}