{"hands_on_practices": [{"introduction": "A cornerstone of time series analysis is the concept of stationarity, which implies that the statistical properties of a process do not change over time. For a stationary autoregressive model, this allows us to determine its long-run equilibrium or unconditional mean. This first exercise provides foundational practice in calculating this crucial property for a simple AR(1) model, which is the first step toward characterizing the central tendency of a time series [@problem_id:1897485].", "problem": "An economic research group is modeling the quarterly inflation anomaly, denoted by $I_t$, for a certain country. The anomaly is defined as the deviation of the observed inflation rate from the central bank's target rate. The group's analysis suggests that this time series can be effectively described by a first-order autoregressive (AR(1)) model of the form:\n\n$I_t = \\alpha + \\beta I_{t-1} + \\epsilon_t$\n\nHere, $I_t$ represents the inflation anomaly in percentage points during quarter $t$. The model includes a constant intercept $\\alpha = 0.4$, and an autoregressive coefficient $\\beta = 0.75$, which captures the persistence of the anomaly from the previous quarter. The term $\\epsilon_t$ is a white noise process, characterized by a mean of zero and constant variance, representing unpredictable shocks to inflation.\n\nAssuming the time series process for the inflation anomaly is stationary, calculate its long-run expected value. Express your answer in percentage points.", "solution": "We are given the AR(1) process for the inflation anomaly:\n$$\nI_{t} = \\alpha + \\beta I_{t-1} + \\epsilon_{t},\n$$\nwith $\\alpha = 0.4$, $\\beta = 0.75$, and $\\epsilon_{t}$ a white noise process with $\\mathbb{E}[\\epsilon_{t}] = 0$. Under the stationarity assumption (which requires $|\\beta|  1$), the long-run expected value, or unconditional mean, is constant and equal to $\\mu = \\mathbb{E}[I_{t}]$.\n\nTaking expectations on both sides of the model:\n$$\n\\mathbb{E}[I_{t}] = \\mathbb{E}[\\alpha + \\beta I_{t-1} + \\epsilon_{t}] = \\alpha + \\beta \\mathbb{E}[I_{t-1}] + \\mathbb{E}[\\epsilon_{t}].\n$$\nUsing $\\mathbb{E}[\\epsilon_{t}] = 0$ and stationarity $\\mathbb{E}[I_{t}] = \\mathbb{E}[I_{t-1}] = \\mu$, we get:\n$$\n\\mu = \\alpha + \\beta \\mu.\n$$\nRearranging,\n$$\n\\mu - \\beta \\mu = \\alpha \\quad \\Rightarrow \\quad \\mu (1 - \\beta) = \\alpha \\quad \\Rightarrow \\quad \\mu = \\frac{\\alpha}{1 - \\beta}.\n$$\nSubstituting $\\alpha = 0.4$ and $\\beta = 0.75$,\n$$\n\\mu = \\frac{0.4}{1 - 0.75} = \\frac{0.4}{0.25} = 1.6.\n$$\nThus, the long-run expected value of the inflation anomaly is $1.6$ percentage points.", "answer": "$$\\boxed{1.6}$$", "id": "1897485"}, {"introduction": "After understanding a series' central tendency, the next step is to quantify its volatility. This practice shifts our focus to moving average (MA) models, which attribute the current value of a series to present and past random shocks. You will calculate the theoretical variance of an MA(2) process, seeing firsthand how the finite memory of MA models leads to a straightforward computation of their unconditional variance [@problem_id:1897432].", "problem": "A simplified model for the daily error in a weather forecasting system is described by a time series process $X_t$. The error on day $t$ is given by the following equation:\n$$X_t = 5 + \\epsilon_t + 0.8 \\epsilon_{t-1} - 0.5 \\epsilon_{t-2}$$\nIn this model, the term $\\{\\epsilon_t\\}$ represents a white noise process, which is a sequence of independent and identically distributed random variables. Each random variable $\\epsilon_k$ in the sequence has a mean of zero and a constant variance denoted by $\\sigma^2$.\nDetermine the theoretical variance of the forecast error process $X_t$. Express your answer as a symbolic expression in terms of $\\sigma^2$.", "solution": "We are given the process\n$$X_{t} = 5 + \\epsilon_{t} + 0.8\\,\\epsilon_{t-1} - 0.5\\,\\epsilon_{t-2},$$\nwhere $\\{\\epsilon_{t}\\}$ is white noise with $\\mathbb{E}[\\epsilon_{t}] = 0$ and $\\operatorname{Var}(\\epsilon_{t}) = \\sigma^{2}$, and the $\\epsilon_{t}$ are mutually independent.\n\nFirst, use the property that adding a constant does not change variance:\n$$\\operatorname{Var}(X_{t}) = \\operatorname{Var}\\big(\\epsilon_{t} + 0.8\\,\\epsilon_{t-1} - 0.5\\,\\epsilon_{t-2}\\big).$$\n\nNext, apply the variance of a linear combination. For independent random variables $Y_{1},Y_{2},Y_{3}$ and constants $a_{1},a_{2},a_{3}$,\n$$\\operatorname{Var}(a_{1}Y_{1} + a_{2}Y_{2} + a_{3}Y_{3}) = a_{1}^{2}\\operatorname{Var}(Y_{1}) + a_{2}^{2}\\operatorname{Var}(Y_{2}) + a_{3}^{2}\\operatorname{Var}(Y_{3}),$$\nsince independence implies all covariances are zero. Here, identify $Y_{1}=\\epsilon_{t}$, $Y_{2}=\\epsilon_{t-1}$, $Y_{3}=\\epsilon_{t-2}$, with $a_{1}=1$, $a_{2}=0.8$, $a_{3}=-0.5$, and each $\\operatorname{Var}(Y_{i})=\\sigma^{2}$. Thus,\n$$\\operatorname{Var}(X_{t}) = \\big(1^{2} + 0.8^{2} + (-0.5)^{2}\\big)\\sigma^{2}.$$\n\nCompute the sum of squares exactly:\n$$1^{2} + 0.8^{2} + (-0.5)^{2} = 1 + \\frac{16}{25} + \\frac{1}{4} = \\frac{100}{100} + \\frac{64}{100} + \\frac{25}{100} = \\frac{189}{100}.$$\n\nTherefore,\n$$\\operatorname{Var}(X_{t}) = \\frac{189}{100}\\,\\sigma^{2}.$$", "answer": "$$\\boxed{\\frac{189}{100}\\sigma^{2}}$$", "id": "1897432"}, {"introduction": "The primary application of ARMA models is to make predictions about the future. This exercise brings together autoregressive and moving average components to tackle the core task of forecasting. By calculating the one-step-ahead forecast for an ARMA(1,1) process, you will learn how the conditional expectation uses past observations ($X_T$) and past shocks ($\\epsilon_T$) to produce an optimal prediction, a fundamental skill for any time series analyst [@problem_id:1897427].", "problem": "An economist is modeling a quarterly economic sentiment index, denoted by $X_t$, using a stationary Autoregressive Moving Average (ARMA) model. The model is specified as an ARMA(1,1) process:\n$$X_t = c + \\phi_1 X_{t-1} + \\epsilon_t + \\theta_1 \\epsilon_{t-1}$$\nThe term $\\epsilon_t$ represents a white noise process with mean zero and constant variance, i.e., $E[\\epsilon_t] = 0$ and $\\text{Var}(\\epsilon_t) = \\sigma^2  0$. For this particular model, it is determined that the long-run mean of the process is zero, which implies the constant $c=0$. The fitted model parameters are $\\phi_1 = 0.55$ and $\\theta_1 = 0.32$.\n\nAt the end of the most recent quarter, time $T$, the observed value of the index is $X_T = 10.4$, and the corresponding realized shock (or residual) for that quarter is $\\epsilon_T = 2.1$.\n\nBased on this information, calculate the optimal one-step-ahead forecast for the index, denoted $\\hat{X}_T(1)$. This forecast is defined as the expected value of $X_{T+1}$ conditional on all information available up to and including time $T$. Report your final answer rounded to three significant figures.", "solution": "We are given the ARMA(1,1) model\n$$X_{t} = c + \\phi_{1} X_{t-1} + \\epsilon_{t} + \\theta_{1} \\epsilon_{t-1},$$\nwith $E[\\epsilon_{t}] = 0$ and $\\text{Var}(\\epsilon_{t}) = \\sigma^{2}$. The long-run mean is zero, so $c=0$. The optimal one-step-ahead forecast is the conditional expectation\n$$\\hat{X}_{T}(1) = E[X_{T+1} \\mid \\mathcal{I}_{T}],$$\nwhere $\\mathcal{I}_{T}$ denotes the information set up to time $T$. Using the model at $t=T+1$,\n$$X_{T+1} = c + \\phi_{1} X_{T} + \\epsilon_{T+1} + \\theta_{1} \\epsilon_{T},$$\nand taking conditional expectation given $\\mathcal{I}_{T}$, we use $E[\\epsilon_{T+1} \\mid \\mathcal{I}_{T}] = 0$ (white noise) and $\\epsilon_{T}$, $X_{T}$ are known at time $T$, hence\n$$\\hat{X}_{T}(1) = c + \\phi_{1} X_{T} + \\theta_{1} \\epsilon_{T}.$$\nSubstituting $c=0$, $\\phi_{1}=0.55$, $\\theta_{1}=0.32$, $X_{T}=10.4$, and $\\epsilon_{T}=2.1$,\n$$\\hat{X}_{T}(1) = 0.55 \\times 10.4 + 0.32 \\times 2.1 = 5.72 + 0.672 = 6.392.$$\nRounded to three significant figures, this is $6.39$.", "answer": "$$\\boxed{6.39}$$", "id": "1897427"}]}