{"hands_on_practices": [{"introduction": "The best way to understand a new statistical technique is to apply it. This first exercise provides a hands-on opportunity to calculate the jackknife bias estimate for a common, real-world estimator. By working through the step-by-step resampling process on a small dataset [@problem_id:1961125], you will build a concrete understanding of how the jackknife quantifies the bias of a non-linear estimator like the inverse sample mean.", "problem": "In reliability engineering, the lifetime of a certain electronic component is often modeled by an exponential distribution with a rate parameter $\\lambda$. The parameter $\\lambda$ represents the constant failure rate. A common estimator for this parameter, based on a sample of observed lifetimes $X_1, X_2, \\ldots, X_n$, is the inverse of the sample mean, given by $\\hat{\\lambda} = 1/\\bar{X}$, where $\\bar{X} = \\frac{1}{n}\\sum_{i=1}^{n} X_i$. While this estimator is the Maximum Likelihood Estimator, it is known to be biased.\n\nSuppose a small sample of $n=4$ component lifetimes has been collected, with the observed values in minutes being:\n$$ \\{2.3, 1.5, 3.1, 2.5\\} $$\nApply the jackknife resampling method to calculate a numerical estimate for the bias of the estimator $\\hat{\\lambda}$.\n\nExpress your answer in units of min⁻¹, rounded to four significant figures.", "solution": "The problem asks for the jackknife estimate of the bias of the estimator $\\hat{\\lambda} = 1/\\bar{X}$ for a given dataset. The dataset is $X = \\{2.3, 1.5, 3.1, 2.5\\}$, and the sample size is $n=4$. The units of the data are minutes, so the units of $\\lambda$ and its bias will be min⁻¹.\n\nFirst, we calculate the sample mean $\\bar{X}$ and the estimate $\\hat{\\lambda}$ from the full sample.\nThe sum of the observations is $\\sum_{i=1}^4 X_i = 2.3 + 1.5 + 3.1 + 2.5 = 9.4$.\nThe sample mean is $\\bar{X} = \\frac{9.4}{4} = 2.35$ min.\nThe estimate of $\\lambda$ based on the full sample is $\\hat{\\lambda} = \\frac{1}{\\bar{X}} = \\frac{1}{2.35}$ min⁻¹.\n\nNext, we apply the jackknife procedure. This involves creating $n=4$ subsamples, where each subsample is formed by removing one observation at a time from the original sample. For each subsample, we calculate the corresponding estimate of $\\lambda$. Let $X_{(i)}$ denote the subsample with the $i$-th observation removed, and let $\\hat{\\lambda}_{(i)}$ be the estimate calculated from this subsample.\n\nThe mean of a subsample with observation $X_i$ removed, $\\bar{X}_{(i)}$, can be calculated as $\\bar{X}_{(i)} = \\frac{n\\bar{X} - X_i}{n-1}$. The corresponding estimate is $\\hat{\\lambda}_{(i)} = 1/\\bar{X}_{(i)}$.\n\nLet's calculate $\\hat{\\lambda}_{(i)}$ for each $i=1, 2, 3, 4$:\nFor $i=1$, we remove $X_1 = 2.3$.\n$\\bar{X}_{(1)} = \\frac{4 \\times 2.35 - 2.3}{4-1} = \\frac{9.4 - 2.3}{3} = \\frac{7.1}{3}$ min.\n$\\hat{\\lambda}_{(1)} = \\frac{1}{\\bar{X}_{(1)}} = \\frac{3}{7.1}$ min⁻¹.\n\nFor $i=2$, we remove $X_2 = 1.5$.\n$\\bar{X}_{(2)} = \\frac{4 \\times 2.35 - 1.5}{4-1} = \\frac{9.4 - 1.5}{3} = \\frac{7.9}{3}$ min.\n$\\hat{\\lambda}_{(2)} = \\frac{1}{\\bar{X}_{(2)}} = \\frac{3}{7.9}$ min⁻¹.\n\nFor $i=3$, we remove $X_3 = 3.1$.\n$\\bar{X}_{(3)} = \\frac{4 \\times 2.35 - 3.1}{4-1} = \\frac{9.4 - 3.1}{3} = \\frac{6.3}{3} = 2.1$ min.\n$\\hat{\\lambda}_{(3)} = \\frac{1}{\\bar{X}_{(3)}} = \\frac{1}{2.1}$ min⁻¹.\n\nFor $i=4$, we remove $X_4 = 2.5$.\n$\\bar{X}_{(4)} = \\frac{4 \\times 2.35 - 2.5}{4-1} = \\frac{9.4 - 2.5}{3} = \\frac{6.9}{3} = 2.3$ min.\n$\\hat{\\lambda}_{(4)} = \\frac{1}{\\bar{X}_{(4)}} = \\frac{1}{2.3}$ min⁻¹.\n\nThe jackknife estimate of bias is given by the formula:\n$$ \\widehat{\\text{Bias}}_{jack}(\\hat{\\lambda}) = (n-1)(\\bar{\\hat{\\lambda}}_{(\\cdot)} - \\hat{\\lambda}) $$\nwhere $\\bar{\\hat{\\lambda}}_{(\\cdot)}$ is the average of the leave-one-out estimates:\n$$ \\bar{\\hat{\\lambda}}_{(\\cdot)} = \\frac{1}{n} \\sum_{i=1}^n \\hat{\\lambda}_{(i)} $$\n\nFirst, we find the numerical values of the estimates, keeping sufficient precision for intermediate calculations.\n$\\hat{\\lambda} = \\frac{1}{2.35} \\approx 0.42553191$ min⁻¹\n$\\hat{\\lambda}_{(1)} = \\frac{3}{7.1} \\approx 0.42253521$ min⁻¹\n$\\hat{\\lambda}_{(2)} = \\frac{3}{7.9} \\approx 0.37974684$ min⁻¹\n$\\hat{\\lambda}_{(3)} = \\frac{1}{2.1} \\approx 0.47619048$ min⁻¹\n$\\hat{\\lambda}_{(4)} = \\frac{1}{2.3} \\approx 0.43478261$ min⁻¹\n\nNow, we calculate the average of these leave-one-out estimates:\n$$ \\bar{\\hat{\\lambda}}_{(\\cdot)} = \\frac{1}{4} (0.42253521 + 0.37974684 + 0.47619048 + 0.43478261) $$\n$$ \\bar{\\hat{\\lambda}}_{(\\cdot)} = \\frac{1}{4} (1.71325514) \\approx 0.42831379 \\text{ min}^{-1} $$\n\nFinally, we use the jackknife bias formula:\n$$ \\widehat{\\text{Bias}}_{jack}(\\hat{\\lambda}) = (4-1) (0.42831379 - 0.42553191) $$\n$$ \\widehat{\\text{Bias}}_{jack}(\\hat{\\lambda}) = 3 \\times (0.00278188) $$\n$$ \\widehat{\\text{Bias}}_{jack}(\\hat{\\lambda}) \\approx 0.00834564 \\text{ min}^{-1} $$\n\nThe problem asks for the answer rounded to four significant figures.\n$$ \\widehat{\\text{Bias}}_{jack}(\\hat{\\lambda}) \\approx 0.008346 \\text{ min}^{-1} $$", "answer": "$$\\boxed{0.008346}$$", "id": "1961125"}, {"introduction": "Beyond bias, the jackknife is a powerful tool for estimating the variance of an estimator and assessing its stability. This practice demonstrates how to calculate the jackknife variance and, more importantly, how to use it as a diagnostic tool. By comparing the variance estimate before and after introducing an outlier [@problem_id:1961127], you will gain insight into the sensitivity of statistical estimates and the diagnostic power of resampling methods.", "problem": "A data scientist is analyzing a small dataset and is concerned about the stability of their variance estimates. They decide to use the jackknife resampling method to assess this. The jackknife estimate of the variance of an estimator $\\hat{\\theta}$, based on a sample of size $n$, is given by the formula:\n$$ \\widehat{\\text{Var}}_{\\text{jack}}(\\hat{\\theta}) = \\frac{n-1}{n} \\sum_{i=1}^{n} \\left(\\hat{\\theta}_{(i)} - \\bar{\\theta}_{(\\cdot)}\\right)^2 $$\nwhere $\\hat{\\theta}_{(i)}$ is the estimate computed from the sample with the $i$-th data point removed, and $\\bar{\\theta}_{(\\cdot)} = \\frac{1}{n} \\sum_{i=1}^{n} \\hat{\\theta}_{(i)}$ is the average of these \"leave-one-out\" estimates.\n\nThe parameter of interest is the population mean, and the estimator used is the sample mean, $\\hat{\\theta} = \\bar{x}$.\n\nInitially, the dataset is $S_1 = \\{10, 12, 13, 15\\}$. Calculate the jackknife variance estimate, $V_1$, for the sample mean of this dataset.\n\nSubsequently, one measurement is found to be anomalous, and the dataset is updated to $S_2 = \\{10, 12, 13, 40\\}$. Calculate the new jackknife variance estimate, $V_2$, for the sample mean of this modified dataset.\n\nDetermine the ratio $V_2 / V_1$, which quantifies the impact of the single outlier on the variance estimate. Round your final answer to three significant figures.", "solution": "We use the jackknife variance estimator\n$$\\widehat{\\text{Var}}_{\\text{jack}}(\\hat{\\theta})=\\frac{n-1}{n}\\sum_{i=1}^{n}\\left(\\hat{\\theta}_{(i)}-\\bar{\\theta}_{(\\cdot)}\\right)^{2},$$\nwhere $\\hat{\\theta}_{(i)}$ is the estimator computed after removing observation $i$, and $\\bar{\\theta}_{(\\cdot)}=\\frac{1}{n}\\sum_{i=1}^{n}\\hat{\\theta}_{(i)}$. Here $\\hat{\\theta}$ is the sample mean, so $\\hat{\\theta}_{(i)}$ is the mean of the $n-1$ observations excluding the $i$-th.\n\nFor $S_{1}=\\{10,12,13,15\\}$, $n=4$. The leave-one-out means are\n$$\\hat{\\theta}_{(1)}=\\frac{12+13+15}{3}=\\frac{40}{3},\\quad \\hat{\\theta}_{(2)}=\\frac{10+13+15}{3}=\\frac{38}{3},$$\n$$\\hat{\\theta}_{(3)}=\\frac{10+12+15}{3}=\\frac{37}{3},\\quad \\hat{\\theta}_{(4)}=\\frac{10+12+13}{3}=\\frac{35}{3}.$$\nTheir average is\n$$\\bar{\\theta}_{(\\cdot)}=\\frac{1}{4}\\left(\\frac{40}{3}+\\frac{38}{3}+\\frac{37}{3}+\\frac{35}{3}\\right)=\\frac{50}{4}=\\frac{25}{2},$$\nwhich equals the sample mean of $S_{1}$. The deviations and their squares are\n$$\\frac{40}{3}-\\frac{25}{2}=\\frac{5}{6}\\;\\Rightarrow\\;\\left(\\frac{5}{6}\\right)^{2}=\\frac{25}{36},\\quad \\frac{38}{3}-\\frac{25}{2}=\\frac{1}{6}\\;\\Rightarrow\\;\\frac{1}{36},$$\n$$\\frac{37}{3}-\\frac{25}{2}=-\\frac{1}{6}\\;\\Rightarrow\\;\\frac{1}{36},\\quad \\frac{35}{3}-\\frac{25}{2}=-\\frac{5}{6}\\;\\Rightarrow\\;\\frac{25}{36}.$$\nThus\n$$\\sum_{i=1}^{4}\\left(\\hat{\\theta}_{(i)}-\\bar{\\theta}_{(\\cdot)}\\right)^{2}=\\frac{25+1+1+25}{36}=\\frac{52}{36}=\\frac{13}{9},$$\nand\n$$V_{1}=\\widehat{\\text{Var}}_{\\text{jack}}(\\bar{x};S_{1})=\\frac{3}{4}\\cdot\\frac{13}{9}=\\frac{13}{12}.$$\n\nFor $S_{2}=\\{10,12,13,40\\}$, $n=4$. The leave-one-out means are\n$$\\hat{\\theta}_{(1)}=\\frac{12+13+40}{3}=\\frac{65}{3},\\quad \\hat{\\theta}_{(2)}=\\frac{10+13+40}{3}=\\frac{63}{3}=21,$$\n$$\\hat{\\theta}_{(3)}=\\frac{10+12+40}{3}=\\frac{62}{3},\\quad \\hat{\\theta}_{(4)}=\\frac{10+12+13}{3}=\\frac{35}{3}.$$\nTheir average is\n$$\\bar{\\theta}_{(\\cdot)}=\\frac{1}{4}\\left(\\frac{65}{3}+\\frac{63}{3}+\\frac{62}{3}+\\frac{35}{3}\\right)=\\frac{75}{4},$$\nwhich equals the sample mean of $S_{2}$. The deviations and their squares are\n$$\\frac{65}{3}-\\frac{75}{4}=\\frac{35}{12}\\;\\Rightarrow\\;\\frac{1225}{144},\\quad 21-\\frac{75}{4}=\\frac{9}{4}\\;\\Rightarrow\\;\\frac{81}{16}=\\frac{729}{144},$$\n$$\\frac{62}{3}-\\frac{75}{4}=\\frac{23}{12}\\;\\Rightarrow\\;\\frac{529}{144},\\quad \\frac{35}{3}-\\frac{75}{4}=-\\frac{85}{12}\\;\\Rightarrow\\;\\frac{7225}{144}.$$\nThus\n$$\\sum_{i=1}^{4}\\left(\\hat{\\theta}_{(i)}-\\bar{\\theta}_{(\\cdot)}\\right)^{2}=\\frac{1225+729+529+7225}{144}=\\frac{9708}{144}=\\frac{809}{12},$$\nand\n$$V_{2}=\\widehat{\\text{Var}}_{\\text{jack}}(\\bar{x};S_{2})=\\frac{3}{4}\\cdot\\frac{809}{12}=\\frac{809}{16}.$$\n\nThe requested ratio is\n$$\\frac{V_{2}}{V_{1}}=\\frac{\\frac{809}{16}}{\\frac{13}{12}}=\\frac{809}{16}\\cdot\\frac{12}{13}=\\frac{2427}{52}\\approx 46.6730769,$$\nwhich, to three significant figures, is $46.7$.", "answer": "$$\\boxed{46.7}$$", "id": "1961127"}, {"introduction": "A crucial part of mastering any statistical method is learning its limitations. This final exercise explores a scenario where the jackknife method does not perform well, specifically with a \"non-smooth\" estimator like the sample maximum. By applying the jackknife procedure in this context [@problem_id:1961143], you will see why the method can fail and learn the importance of considering the theoretical properties of your estimator before applying a resampling technique.", "problem": "A small random sample of size $n=5$ is drawn from a continuous uniform distribution on the interval $[0, \\theta]$, where $\\theta > 0$ is an unknown parameter. The observed sample values are $\\{6.3, 2.5, 9.1, 4.8, 1.7\\}$. An estimator for $\\theta$ is proposed as the sample maximum, which we denote as $T(X)$.\n\nUsing the jackknife method, calculate the estimated bias of this estimator. Express your answer as an exact decimal value.", "solution": "We are given an estimator $T(X)$ equal to the sample maximum for a sample of size $n=5$ from a $\\operatorname{Unif}(0,\\theta)$ distribution, with observed sample $\\{6.3, 2.5, 9.1, 4.8, 1.7\\}$. The jackknife estimate of the bias of $T$ is defined by\n$$\n\\widehat{\\operatorname{bias}}_{\\text{jack}}(T)\n=\n(n-1)\\left(\\bar{T}_{(.)}-T\\right),\n$$\nwhere $T$ is the full-sample estimate and $\\bar{T}_{(.)}=\\frac{1}{n}\\sum_{i=1}^{n}T_{(i)}$ is the average of the leave-one-out estimates $T_{(i)}$ computed by omitting the $i$-th observation.\n\nFirst compute the full-sample estimator:\n$$\nT=\\max\\{6.3,2.5,9.1,4.8,1.7\\}=9.1.\n$$\n\nNext compute the leave-one-out maxima:\n- Omitting $6.3$: $T_{(1)}=\\max\\{2.5,9.1,4.8,1.7\\}=9.1$.\n- Omitting $2.5$: $T_{(2)}=\\max\\{6.3,9.1,4.8,1.7\\}=9.1$.\n- Omitting $9.1$: $T_{(3)}=\\max\\{6.3,2.5,4.8,1.7\\}=6.3$.\n- Omitting $4.8$: $T_{(4)}=\\max\\{6.3,2.5,9.1,1.7\\}=9.1$.\n- Omitting $1.7$: $T_{(5)}=\\max\\{6.3,2.5,9.1,4.8\\}=9.1$.\n\nThus\n$$\n\\bar{T}_{(.)}\n=\n\\frac{1}{5}\\left(T_{(1)}+T_{(2)}+T_{(3)}+T_{(4)}+T_{(5)}\\right)\n=\n\\frac{1}{5}\\left(9.1+9.1+6.3+9.1+9.1\\right)\n=\n\\frac{42.7}{5}\n=\n8.54.\n$$\n\nApply the jackknife bias formula with $n=5$:\n$$\n\\widehat{\\operatorname{bias}}_{\\text{jack}}(T)\n=\n(5-1)\\left(8.54-9.1\\right)\n=\n4\\cdot(-0.56)\n=\n-2.24.\n$$\n\nTherefore, the jackknife estimated bias of the sample-maximum estimator for this dataset is $-2.24$.", "answer": "$$\\boxed{-2.24}$$", "id": "1961143"}]}