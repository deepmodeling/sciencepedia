{"hands_on_practices": [{"introduction": "This first practice serves as a fundamental check on your understanding of the ANOVA table's structure. By calculating the $F$-statistic from given sums of squares, you will directly apply the principle of variance decomposition ($SST = SSR + SSE$), which is the cornerstone of analysis of variance for regression [@problem_id:1895430]. This exercise hones your ability to interpret standard statistical output and compute the key metric for assessing a model's overall significance.", "problem": "An agricultural scientist is studying the relationship between the amount of a newly developed nutrient supplement applied to soil and the subsequent height of a particular plant species. A simple linear regression model is fitted to the collected data to predict plant height based on the quantity of the supplement.\n\nAfter fitting the model, a statistical analysis yielded the following quantities:\n- The Total Sum of Squares ($SST$), which measures the total variance in the plant heights, was calculated to be $100.0$.\n- The Sum of Squares for Regression ($SSR$), which represents the variation in plant height explained by the regression model, was found to be $40.0$.\n- The analysis was based on a sample size such that the degrees of freedom for the error (residual) term is $df_E = 10$.\n\nBased on these results from the Analysis of Variance (ANOVA), calculate the F-statistic used to test the overall significance of the simple linear regression model. Express your answer as a number rounded to three significant figures.", "solution": "In one-predictor simple linear regression with an intercept, the ANOVA partitions total variability as $SST = SSR + SSE$. Thus the error sum of squares is\n$$\nSSE = SST - SSR.\n$$\nThe regression and error mean squares are defined by\n$$\nMSR = \\frac{SSR}{df_{R}}, \\quad MSE = \\frac{SSE}{df_{E}},\n$$\nand the overall F-statistic is\n$$\nF = \\frac{MSR}{MSE} = \\frac{\\frac{SSR}{df_{R}}}{\\frac{SSE}{df_{E}}}.\n$$\nFor simple linear regression, $df_{R} = 1$. Using the given values $SST = 100.0$, $SSR = 40.0$, and $df_{E} = 10$, compute\n$$\nSSE = 100.0 - 40.0 = 60.0,\n$$\n$$\nMSR = \\frac{40.0}{1} = 40.0, \\quad MSE = \\frac{60.0}{10} = 6.0,\n$$\nso\n$$\nF = \\frac{40.0}{6.0} = 6.\\overline{6}.\n$$\nRounded to three significant figures, the F-statistic is $6.67$.", "answer": "$$\\boxed{6.67}$$", "id": "1895430"}, {"introduction": "Moving from summary statistics to raw data, this exercise challenges you to perform a complete analysis from start to finish. The core goal is to not only fit a simple linear regression model but also to empirically verify a critical theoretical link: the equivalence between the $F$-test for overall model significance and the $t$-test for the slope coefficient [@problem_id:1895391]. Completing this practice will solidify your understanding that for a simple linear model, testing $H_0: \\beta_1 = 0$ with a $t$-test is equivalent to the overall $F$-test, as you will demonstrate that $F=t^2$.", "problem": "An undergraduate student in chemical engineering is investigating the relationship between the concentration of a novel catalyst and the rate of a chemical reaction. The student performs the reaction five times, each with a different catalyst concentration, and measures the resulting reaction rate. The collected data are as follows:\n\n-   Catalyst Concentration, $x$ (in mol/L): `{1.0, 2.0, 3.0, 4.0, 5.0}`\n-   Reaction Rate, $y$ (in mol/L/s): `{2.5, 4.0, 4.8, 6.0, 7.5}`\n\nThe student proposes a simple linear regression model of the form $Y_i = \\beta_0 + \\beta_1 x_i + \\epsilon_i$, where the errors $\\epsilon_i$ are assumed to be independent and normally distributed with mean 0 and constant variance $\\sigma^2$.\n\nYour task is to perform two key statistical tests on this model.\nFirst, calculate the t-statistic for testing the null hypothesis $H_0: \\beta_1 = 0$ against the two-sided alternative $H_a: \\beta_1 \\neq 0$.\nSecond, construct an Analysis of Variance (ANOVA) table for the regression and calculate the F-statistic.\n\nProvide the values of the t-statistic and the F-statistic. Report your answers, rounded to four significant figures, as a row matrix in the format `[t-statistic, F-statistic]`.", "solution": "We adopt the simple linear regression model $Y_{i}=\\beta_{0}+\\beta_{1}x_{i}+\\epsilon_{i}$ with independent, normally distributed errors of constant variance. For simple linear regression with intercept, the least-squares slope estimator and its standard error are\n$$\n\\hat{\\beta}_{1}=\\frac{S_{xy}}{S_{xx}},\\quad S_{xx}=\\sum_{i=1}^{n}(x_{i}-\\bar{x})^{2},\\quad S_{xy}=\\sum_{i=1}^{n}(x_{i}-\\bar{x})(y_{i}-\\bar{y}),\n$$\nand\n$$\n\\operatorname{SE}(\\hat{\\beta}_{1})=\\sqrt{\\frac{\\operatorname{MSE}}{S_{xx}}},\\quad \\operatorname{MSE}=\\frac{\\operatorname{SSE}}{n-2},\\quad \\operatorname{SSE}=S_{yy}-\\frac{S_{xy}^{2}}{S_{xx}},\\quad S_{yy}=\\sum_{i=1}^{n}(y_{i}-\\bar{y})^{2}.\n$$\nThe $t$-statistic for testing $H_{0}:\\beta_{1}=0$ against $H_{a}:\\beta_{1}\\neq 0$ is\n$$\nt=\\frac{\\hat{\\beta}_{1}}{\\operatorname{SE}(\\hat{\\beta}_{1})}.\n$$\n\nUsing the data $x=\\{1,2,3,4,5\\}$ and $y=\\{2.5,4.0,4.8,6.0,7.5\\}$ with $n=5$, compute the sample means $\\bar{x}=3$ and $\\bar{y}=\\frac{2.5+4.0+4.8+6.0+7.5}{5}=4.96$. Then\n$$\nS_{xx}=\\sum(x_{i}-\\bar{x})^{2}=10,\\quad S_{xy}=\\sum(x_{i}-\\bar{x})(y_{i}-\\bar{y})=12.\n$$\nHence the slope estimate is\n$$\n\\hat{\\beta}_{1}=\\frac{S_{xy}}{S_{xx}}=\\frac{12}{10}=1.2.\n$$\nNext, compute\n$$\nS_{yy}=\\sum(y_{i}-\\bar{y})^{2}=\\left(\\sum y_{i}^{2}\\right)-n\\bar{y}^{2}=(6.25+16+23.04+36+56.25)-5(4.96)^{2}=137.54-123.008=14.532.\n$$\nTherefore,\n$$\n\\operatorname{SSE}=S_{yy}-\\frac{S_{xy}^{2}}{S_{xx}}=14.532-\\frac{144}{10}=14.532-14.4=0.132,\\quad \\operatorname{MSE}=\\frac{\\operatorname{SSE}}{n-2}=\\frac{0.132}{3}=0.044.\n$$\nThe standard error of the slope is\n$$\n\\operatorname{SE}(\\hat{\\beta}_{1})=\\sqrt{\\frac{\\operatorname{MSE}}{S_{xx}}}=\\sqrt{\\frac{0.044}{10}}=\\sqrt{0.0044}=\\sqrt{\\frac{11}{2500}}=\\frac{\\sqrt{11}}{50}.\n$$\nThus the $t$-statistic is\n$$\nt=\\frac{\\hat{\\beta}_{1}}{\\operatorname{SE}(\\hat{\\beta}_{1})}=\\frac{1.2}{\\sqrt{11}/50}=\\frac{60}{\\sqrt{11}}\\approx 18.09\\quad(\\text{with }3\\text{ degrees of freedom}).\n$$\n\nFor the ANOVA, the regression sum of squares is\n$$\n\\operatorname{SSR}=\\frac{S_{xy}^{2}}{S_{xx}}=\\frac{144}{10}=14.4,\n$$\nwith $1$ degree of freedom, and the error sum of squares is $\\operatorname{SSE}=0.132$ with $n-2=3$ degrees of freedom. The mean squares are\n$$\n\\operatorname{MSR}=\\frac{\\operatorname{SSR}}{1}=14.4,\\quad \\operatorname{MSE}=\\frac{\\operatorname{SSE}}{3}=0.044.\n$$\nThe $F$-statistic for testing the overall regression is\n$$\nF=\\frac{\\operatorname{MSR}}{\\operatorname{MSE}}=\\frac{14.4}{0.044}=\\frac{3600}{11}\\approx 327.3.\n$$\nIn simple linear regression, $F=t^{2}$ holds, and indeed $\\left(\\frac{60}{\\sqrt{11}}\\right)^{2}=\\frac{3600}{11}$.\n\nRounded to four significant figures, the requested statistics are $t\\approx 18.09$ and $F\\approx 327.3$.", "answer": "$$\\boxed{\\begin{pmatrix}18.09 & 327.3\\end{pmatrix}}$$", "id": "1895391"}, {"introduction": "This problem pushes you beyond mechanical calculations to think conceptually about the meaning of the values in an ANOVA table. By considering the ideal scenario of a perfect fit where the Sum of Squared Errors ($SSE$) is zero, you will reinforce your understanding of how model error relates to goodness-of-fit metrics like the coefficient of determination ($R^2$) and the correlation coefficient ($r$) [@problem_id:1895411]. It's a quick but powerful test of your grasp on these interconnected concepts and what they imply about the relationship between variables.", "problem": "In the context of a simple linear regression model, an Analysis of Variance (ANOVA) is often performed to partition the total variability in the response variable. The Total Sum of Squares (SST) is decomposed into the Regression Sum of Squares (SSR) and the Sum of Squared Errors (SSE), such that $SST = SSR + SSE$.\n\nConsider a specific simple linear regression analysis performed on a dataset where the calculated Sum of Squared Errors (SSE) is found to be exactly zero. This scenario implies a perfect fit of the regression line to the data points. Given this information, what must be the values of the coefficient of determination, denoted as $R^2$, and the absolute value of the sample correlation coefficient, denoted as $|r|$?\n\nSelect the correct pair of values from the options below.\n\nA. $R^2 = 1$ and $|r|=1$\n\nB. $R^2 = 0$ and $|r|=0$\n\nC. $R^2 = 1$ and $|r|=0$\n\nD. $R^2 = 0$ and $|r|=1$\n\nE. The values depend on the sample size and cannot be determined.", "solution": "In simple linear regression, the total variability in the response is decomposed as $SST = SSR + SSE$. The coefficient of determination is defined as\n$$\nR^{2} = \\frac{SSR}{SST} = 1 - \\frac{SSE}{SST}.\n$$\nGiven $SSE = 0$ and assuming $SST > 0$ so that $R^{2}$ is well-defined, it follows that\n$$\nR^{2} = 1 - \\frac{0}{SST} = 1.\n$$\nFor simple linear regression, the identity $R^{2} = r^{2}$ holds, where $r$ is the sample correlation coefficient between the predictor and response. Therefore,\n$$\n|r| = \\sqrt{R^{2}} = 1.\n$$\nHence the correct option is $R^{2} = 1$ and $|r| = 1$.", "answer": "$$\\boxed{A}$$", "id": "1895411"}]}