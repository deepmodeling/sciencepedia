{"hands_on_practices": [{"introduction": "To begin our hands-on exploration, we will tackle a classic hypothesis testing problem from the field of engineering. This exercise provides a practical application of setting up null and alternative hypotheses to assess a product's quality against a specified benchmark. You will practice calculating a test statistic based on experimental data and using it to make a decision, reinforcing the core mechanics of hypothesis testing in a tangible scenario involving the exponential distribution, which is frequently used to model component lifetimes [@problem_id:1940676].", "problem": "An aerospace engineering team is developing a new type of radioisotope thermoelectric generator for a long-duration deep-space mission. The design specification states that the mean time to failure (MTTF) of these generators must be greater than 5000 hours. To verify this, the team conducts a life-test on a random sample of $n=10$ prototype generators. The lifetimes of these generators are assumed to be independent and to follow an exponential distribution. The test is run until all 10 generators fail, and the sum of their lifetimes is recorded as 60,000 hours.\n\nThe team decides to perform a hypothesis test with the null hypothesis that the true MTTF is exactly 5000 hours, against the alternative hypothesis that it is greater than 5000 hours. The test is conducted at a significance level of $\\alpha = 0.05$. For the purpose of this problem, the critical value for the appropriate test statistic at the given significance level is 31.410. A test statistic value greater than this critical value would lead to the rejection of the null hypothesis.\n\nBased on the experimental data, which of the following conclusions is correct?\n\nA. The team should reject the null hypothesis.\n\nB. The team should fail to reject the null hypothesis.\n\nC. The results are inconclusive because the sample size is too small to draw a meaningful conclusion.\n\nD. The test cannot be performed because both the population mean and variance are unknown parameters.\n\nE. The team should accept the null hypothesis as proven true.", "solution": "The problem asks us to perform a hypothesis test for the mean of an exponential distribution. Let the random variable $X$ represent the lifetime of a generator. We are given that $X$ follows an exponential distribution. The probability density function (PDF) of an exponential distribution can be parameterized by its mean $\\mu$, or by its rate parameter $\\lambda = 1/\\mu$. The PDF in terms of $\\mu$ is $f(x; \\mu) = \\frac{1}{\\mu} \\exp(-\\frac{x}{\\mu})$ for $x \\ge 0$.\n\nFirst, we state the null and alternative hypotheses in terms of the mean time to failure (MTTF), $\\mu$.\nThe null hypothesis ($H_0$) is that the MTTF is exactly 5000 hours.\n$$H_0: \\mu = 5000$$\nThe alternative hypothesis ($H_a$) is that the MTTF is greater than 5000 hours.\n$$H_a: \\mu > 5000$$\n\nFor an exponential distribution, a powerful and commonly used test statistic is based on the sum of the observations. Let $X_1, X_2, \\dots, X_n$ be the lifetimes of the $n$ generators in the sample. A key result in mathematical statistics states that if $X_i$ are independent and identically distributed as $\\text{Exp}(\\lambda)$, where $\\lambda=1/\\mu$, then the quantity $2\\lambda \\sum_{i=1}^n X_i$ follows a chi-squared distribution with $2n$ degrees of freedom, i.e., $2\\lambda \\sum_{i=1}^n X_i \\sim \\chi^2_{2n}$.\n\nWe construct our test based on this property. Under the null hypothesis, the mean is $\\mu_0 = 5000$, which corresponds to a rate parameter of $\\lambda_0 = 1/\\mu_0 = 1/5000$. So, under $H_0$, the test statistic\n$$S = 2\\lambda_0 \\sum_{i=1}^n X_i = \\frac{2}{\\mu_0} \\sum_{i=1}^n X_i$$\nfollows a chi-squared distribution with $2n$ degrees of freedom. In our case, the sample size is $n=10$, so the degrees of freedom are $2n = 2(10) = 20$.\n\nThe alternative hypothesis is $H_a: \\mu > 5000$. A larger sample mean, $\\bar{X} = (\\sum X_i)/n$, provides evidence in favor of $H_a$. A large sample mean corresponds to a large sum $\\sum X_i$, which in turn corresponds to a large value of the test statistic $S$. Therefore, we have a right-tailed test. We will reject $H_0$ if the observed value of our statistic, $s_{obs}$, is greater than a certain critical value. The problem provides this critical value as 31.410 for a significance level of $\\alpha = 0.05$.\n\nNow, we calculate the observed value of the test statistic, $s_{obs}$, using the given data:\nSample size, $n=10$.\nSum of lifetimes, $\\sum_{i=1}^{10} x_i = 60,000$ hours.\nNull hypothesis mean, $\\mu_0 = 5000$ hours.\n\n$$s_{obs} = \\frac{2}{\\mu_0} \\sum_{i=1}^{10} x_i = \\frac{2}{5000} \\times 60,000 = \\frac{120,000}{5000} = 24$$\n\nFinally, we compare the observed statistic to the critical value.\nObserved statistic: $s_{obs} = 24$.\nCritical value (from the problem statement): $c = 31.410$.\n\nSince $s_{obs} = 24$ is not greater than the critical value of $31.410$, the test statistic does not fall into the rejection region. Therefore, we do not have sufficient evidence at the $\\alpha = 0.05$ significance level to reject the null hypothesis. The correct conclusion is to \"fail to reject the null hypothesis\".\n\nLet's evaluate the given options:\nA. The team should reject the null hypothesis. This is incorrect.\nB. The team should fail to reject the null hypothesis. This is the correct conclusion.\nC. The results are inconclusive because the sample size is too small. This is a misinterpretation. Hypothesis testing provides a definite conclusion (reject or fail to reject) based on the chosen framework.\nD. The test cannot be performed because both the population mean and variance are unknown. This is incorrect. The test is specifically designed for this situation. For an exponential distribution, the variance is $\\mu^2$, so knowing the mean determines the variance. The test makes an assumption about the mean under the null hypothesis to proceed.\nE. The team should accept the null hypothesis as proven true. This is a common logical fallacy. Failing to reject the null hypothesis simply means there is not enough evidence to discard it, not that it has been proven true.\n\nThus, the only correct statement is B.", "answer": "$$\\boxed{B}$$", "id": "1940676"}, {"introduction": "Moving from calculation to interpretation, this next practice addresses a crucial and often misunderstood aspect of statistical inference: the relationship between confidence intervals and hypothesis tests. Using a realistic scenario from modern bioinformatics, this problem demonstrates that a confidence interval provides much more information than a simple \"reject\" or \"fail to reject\" decision. Mastering this connection is key to accurately interpreting and communicating scientific findings, as it provides a range of plausible values for the effect you are studying [@problem_id:2410254].", "problem": "A computational biologist analyzes differential expression from an RNA sequencing (RNA-seq) experiment comparing two conditions. For a particular gene, the estimated log fold-change (base-$2$), denoted $\\text{logFC}$, has a reported $95\\%$ confidence interval $[-0.2,\\,1.5]$. Consider the null hypothesis $H_0: \\text{logFC} = 0$ (no change between conditions), with the usual two-sided significance level $\\alpha = 0.05$. Which conclusion is most justified?\n\nA. Reject $H_0$ at level $\\alpha = 0.05$; there is sufficient evidence the gene is upregulated.\n\nB. Fail to reject $H_0$ at level $\\alpha = 0.05$; the data are compatible with effects ranging from slight downregulation to substantial upregulation.\n\nC. Accept $H_0$ as true; the gene exhibits exactly no change between conditions.\n\nD. The two-sided $p$-value is less than $0.05$.\n\nE. A one-sided test for downregulation at level $\\alpha = 0.05$ would necessarily be significant because the interval includes negative values.", "solution": "The problem statement must first be validated for its scientific and logical integrity.\n\n### Step 1: Extract Givens\nThe problem provides the following information:\n- The parameter of interest is the base-$2$ log fold-change in gene expression, denoted $\\text{logFC}$.\n- A $95\\%$ confidence interval for the $\\text{logFC}$ is given as $[-0.2, 1.5]$.\n- The null hypothesis is $H_0: \\text{logFC} = 0$.\n- The significance level for a two-sided test is $\\alpha = 0.05$.\n\n### Step 2: Validate Using Extracted Givens\nThe problem is well-defined and scientifically sound.\n1.  **Scientific Grounding**: The concepts of log fold-change, confidence intervals, null hypothesis testing, and significance levels are fundamental, standard tools in computational biology and bioinformatics for analyzing differential gene expression data from RNA-seq experiments. The stated values are plausible.\n2.  **Well-Posed**: The question asks for a conclusion based on a standard statistical relationship between a confidence interval and a hypothesis test. Given a confidence level of $(1-\\alpha) \\times 100\\%$ and a null hypothesis value, the outcome of the corresponding two-sided test at level $\\alpha$ is uniquely determined.\n3.  **Consistency**: The confidence level of $95\\%$ corresponds precisely to the significance level $\\alpha = 1 - 0.95 = 0.05$. There are no internal contradictions.\n4.  **Clarity**: The terminology is unambiguous and standard in the field of statistics and its applications.\n\n### Step 3: Verdict and Action\nThe problem statement is valid. A rigorous solution can be derived.\n\n### Derivation\nThe fundamental principle connecting a confidence interval (CI) and a two-sided hypothesis test is the concept of duality. A $(1-\\alpha) \\times 100\\%$ confidence interval for a parameter contains all the values for that parameter which would not be rejected as a null hypothesis in a two-sided test at the $\\alpha$ significance level.\n\nIn this problem:\n- The parameter is $\\text{logFC}$.\n- The null hypothesis value is $H_0: \\text{logFC} = 0$.\n- The significance level is $\\alpha = 0.05$.\n- The corresponding confidence interval is the $95\\%$ CI, given as $[-0.2, 1.5]$.\n\nThe decision rule is as follows:\n- If the null value (in this case, $0$) is contained within the $(1-\\alpha) \\times 100\\%$ CI, we **fail to reject** the null hypothesis $H_0$ at the $\\alpha$ level of significance.\n- If the null value is not contained within the $(1-\\alpha) \\times 100\\%$ CI, we **reject** the null hypothesis $H_0$ at the $\\alpha$ level of significance.\n\nLet us apply this rule. The given $95\\%$ CI is $[-0.2, 1.5]$. The value $0$ lies within this interval, as $-0.2 \\le 0 \\le 1.5$.\nTherefore, based on the provided data and significance level, we must **fail to reject** the null hypothesis $H_0: \\text{logFC} = 0$.\n\nThis means that the data are statistically consistent with a true log fold-change of $0$ (no change). However, a confidence interval also provides a range of other plausible values for the true parameter. The interval $[-0.2, 1.5]$ indicates that the true effect could plausibly be a slight downregulation (e.g., $\\text{logFC} = -0.2$) or a substantial upregulation (e.g., $\\text{logFC} = 1.5$), or any value in between. The result is inconclusive regarding the direction of the change, as both downregulation and upregulation are included in the interval of plausible values.\n\n### Option-by-Option Analysis\n\n**A. Reject $H_0$ at level $\\alpha = 0.05$; there is sufficient evidence the gene is upregulated.**\nThis statement is incorrect. As derived above, since the null value $\\text{logFC} = 0$ is included in the $95\\%$ CI, we fail to reject $H_0$ at $\\alpha = 0.05$. Furthermore, to conclude there is sufficient evidence for upregulation, the entire confidence interval would need to consist of values strictly greater than $0$. This is not the case.\n**Verdict: Incorrect.**\n\n**B. Fail to reject $H_0$ at level $\\alpha = 0.05$; the data are compatible with effects ranging from slight downregulation to substantial upregulation.**\nThis statement is correct. The first part, \"Fail to reject $H_0$ at level $\\alpha = 0.05$,\" is the direct consequence of the null value $\\text{logFC}=0$ being in the $95\\%$ CI. The second part provides the correct interpretation of the confidence interval $[-0.2, 1.5]$. A value of $-0.2$ represents slight downregulation, while a value of $1.5$ represents a substantial upregulation. The interval correctly describes the range of effects that are compatible with the observed data.\n**Verdict: Correct.**\n\n**C. Accept $H_0$ as true; the gene exhibits exactly no change between conditions.**\nThis is a fundamental error in statistical reasoning. In frequentist hypothesis testing, we never \"accept\" the null hypothesis. A failure to reject $H_0$ simply means there is insufficient evidence to discard it, not that it is proven true. The confidence interval $[-0.2, 1.5]$ explicitly shows that values other than $0$ are also plausible. Claiming the effect is *exactly* $0$ is an unjustifiably strong conclusion.\n**Verdict: Incorrect.**\n\n**D. The two-sided $p$-value is less than $0.05$.**\nThis statement is incorrect. The condition for rejecting the null hypothesis at level $\\alpha$ is that the $p$-value must be less than $\\alpha$. Since we failed to reject $H_0$ at $\\alpha = 0.05$, it necessarily follows that the $p$-value must be greater than or equal to $0.05$. Stating the $p$-value is less than $0.05$ contradicts the conclusion derived from the confidence interval.\n**Verdict: Incorrect.**\n\n**E. A one-sided test for downregulation at level $\\alpha = 0.05$ would necessarily be significant because the interval includes negative values.**\nThis statement is incorrect. A test for downregulation ($H_1: \\text{logFC}  0$) would only be significant if there were strong evidence that the true $\\text{logFC}$ is negative. The point estimate for the $\\text{logFC}$, assuming symmetry of the sampling distribution, is the center of the CI: $(\\frac{-0.2 + 1.5}{2}) = 0.65$. Since the point estimate is positive, the data trends towards upregulation. A test for downregulation would almost certainly yield a large $p$-value and would not be significant. The mere inclusion of some negative values in the two-sided CI does not guarantee significance in a one-sided test, especially when the point estimate is in the opposite direction.\n**Verdict: Incorrect.**", "answer": "$$\\boxed{B}$$", "id": "2410254"}, {"introduction": "Our final practice takes a deeper dive into the theoretical underpinnings of hypothesis testing. Instead of using a pre-defined formula, this exercise will guide you through the process of deriving a test statistic from first principles for a more complex, non-standard hypothesis. By constructing a Generalized Log-Likelihood Ratio Test (GLRT) for a \"change-point\" problem, you will gain a profound understanding of how statisticians create powerful tools to answer specific scientific questions, revealing the logic and elegance behind the test statistics we often take for granted [@problem_id:1940664].", "problem": "A systems engineer is monitoring the daily average latency of a critical server. The latency measurements on consecutive days are recorded as a sequence of random variables $X_1, X_2, \\ldots, X_n$. It is assumed that these measurements are independent and drawn from a normal distribution with a known variance $\\sigma^2$, so that $X_i \\sim N(\\mu_i, \\sigma^2)$ for $i=1, \\ldots, n$.\n\nThe engineer wants to detect if a single, abrupt change in the server's performance occurred during the observation period. This corresponds to a change in the mean latency, $\\mu_i$. The problem is framed as a hypothesis test between a \"stable system\" null hypothesis and a \"single change-point\" alternative hypothesis:\n\n- **Null Hypothesis ($H_0$):** The system is stable, meaning the mean latency is constant over the period. The population means are all equal to some unknown constant $\\mu$.\n$$H_0: \\mu_1 = \\mu_2 = \\dots = \\mu_n = \\mu$$\n\n- **Alternative Hypothesis ($H_A$):** A single change occurred at an unknown time $\\tau \\in \\{1, \\dots, n-1\\}$. The population mean is $\\theta_1$ up to time $\\tau$ and changes to $\\theta_2$ after time $\\tau$, where $\\theta_1 \\neq \\theta_2$. The parameters $\\theta_1$, $\\theta_2$, and the change-point $\\tau$ are all unknown.\n$$H_A: \\text{There exists } \\tau \\in \\{1, \\dots, n-1\\} \\text{ such that } \\mu_1 = \\dots = \\mu_\\tau = \\theta_1 \\text{ and } \\mu_{\\tau+1} = \\dots = \\mu_n = \\theta_2, \\text{ with } \\theta_1 \\neq \\theta_2$$\n\nTo perform this test, a Generalized Log-Likelihood Ratio Test (GLRT) statistic, denoted by $T_n$, is constructed. It is defined as $T_n = 2 \\left( \\sup_{H_A} \\ln L - \\sup_{H_0} \\ln L \\right)$, where $\\ln L$ is the log-likelihood function of the observations and the supremum is taken over all unknown parameters within the respective hypothesis.\n\nDerive the analytical expression for the statistic $T_n$. Your final answer should be expressed in terms of $n$, $\\sigma^2$, and the observations $X_i$.", "solution": "The joint density under independent Gaussian measurements with known variance $\\sigma^2$ is\n$$\nL(\\mu_1, \\ldots, \\mu_n)=(2\\pi\\sigma^2)^{-n/2}\\exp\\left(-\\frac{1}{2\\sigma^2}\\sum_{i=1}^{n}(X_i-\\mu_i)^2\\right),\n$$\nso the log-likelihood is\n$$\n\\ln L(\\mu_1, \\ldots, \\mu_n)=-\\frac{n}{2}\\ln(2\\pi\\sigma^2)-\\frac{1}{2\\sigma^2}\\sum_{i=1}^{n}(X_i-\\mu_i)^2.\n$$\n\nUnder $H_0$, $\\mu_i=\\mu$ for all $i$. The maximizer satisfies\n$$\n\\frac{\\partial}{\\partial \\mu}\\ln L=\\frac{1}{\\sigma^2}\\sum_{i=1}^{n}(X_i-\\mu)=0\n\\implies\n\\hat{\\mu}=\\bar{X}_n:=\\frac{1}{n}\\sum_{i=1}^{n}X_i.\n$$\nHence, the maximized log-likelihood under the null is\n$$\n\\sup_{H_0}\\ln L=-\\frac{n}{2}\\ln(2\\pi\\sigma^2)-\\frac{1}{2\\sigma^2}\\sum_{i=1}^{n}(X_i-\\bar{X}_n)^2.\n$$\n\nUnder $H_A$ with a fixed change-point $\\tau \\in \\{1, \\ldots, n-1\\}$, we have $\\mu_1=\\cdots=\\mu_\\tau=\\theta_1$ and $\\mu_{\\tau+1}=\\cdots=\\mu_n=\\theta_2$. The maximizers solve\n$$\n\\frac{\\partial}{\\partial \\theta_1}\\ln L=\\frac{1}{\\sigma^2}\\sum_{i=1}^{\\tau}(X_i-\\theta_1)=0, \\quad\n\\frac{\\partial}{\\partial \\theta_2}\\ln L=\\frac{1}{\\sigma^2}\\sum_{i=\\tau+1}^{n}(X_i-\\theta_2)=0,\n$$\nso\n$$\n\\hat{\\theta}_1=\\bar{X}_{1:\\tau}:=\\frac{1}{\\tau}\\sum_{i=1}^{\\tau}X_i, \\qquad\n\\hat{\\theta}_2=\\bar{X}_{\\tau+1:n}:=\\frac{1}{n-\\tau}\\sum_{i=\\tau+1}^{n}X_i.\n$$\nThe corresponding maximized log-likelihood for this $\\tau$ is\n$$\n\\sup_{\\theta_1,\\theta_2}\\ln L=-\\frac{n}{2}\\ln(2\\pi\\sigma^2)-\\frac{1}{2\\sigma^2}\\left[\\sum_{i=1}^{\\tau}(X_i-\\bar{X}_{1:\\tau})^2+\\sum_{i=\\tau+1}^{n}(X_i-\\bar{X}_{\\tau+1:n})^2\\right].\n$$\nMaximizing over $\\tau$ is equivalent to minimizing the bracketed within-group sum of squares, hence\n$$\n\\sup_{H_A}\\ln L=-\\frac{n}{2}\\ln(2\\pi\\sigma^2)-\\frac{1}{2\\sigma^2}\\min_{1\\le \\tau\\le n-1}\\left[\\sum_{i=1}^{\\tau}(X_i-\\bar{X}_{1:\\tau})^2+\\sum_{i=\\tau+1}^{n}(X_i-\\bar{X}_{\\tau+1:n})^2\\right].\n$$\n\nTherefore, the GLRT statistic is\n$$\nT_n = 2\\left(\\sup_{H_A}\\ln L-\\sup_{H_0}\\ln L\\right)\n=\\frac{1}{\\sigma^2}\\left\\{\\sum_{i=1}^{n}(X_i-\\bar{X}_n)^2-\\min_{1\\le \\tau\\le n-1}\\left[\\sum_{i=1}^{\\tau}(X_i-\\bar{X}_{1:\\tau})^2+\\sum_{i=\\tau+1}^{n}(X_i-\\bar{X}_{\\tau+1:n})^2\\right]\\right\\}.\n$$\n\nUsing the ANOVA identity\n$$\n\\sum_{i=1}^{n}(X_i-\\bar{X}_n)^2-\\left[\\sum_{i=1}^{\\tau}(X_i-\\bar{X}_{1:\\tau})^2+\\sum_{i=\\tau+1}^{n}(X_i-\\bar{X}_{\\tau+1:n})^2\\right]\n=\\frac{\\tau(n-\\tau)}{n}\\left(\\bar{X}_{1:\\tau}-\\bar{X}_{\\tau+1:n}\\right)^2,\n$$\nwe obtain the explicit maximization form\n$$\nT_n=\\frac{1}{\\sigma^2}\\max_{1\\le \\tau\\le n-1}\\left\\{\\frac{\\tau(n-\\tau)}{n}\\left(\\bar{X}_{1:\\tau}-\\bar{X}_{\\tau+1:n}\\right)^2\\right\\}\n=\\frac{1}{\\sigma^2}\\max_{1\\le \\tau\\le n-1}\\left\\{\\frac{\\tau(n-\\tau)}{n}\\left(\\frac{1}{\\tau}\\sum_{i=1}^{\\tau}X_i-\\frac{1}{n-\\tau}\\sum_{i=\\tau+1}^{n}X_i\\right)^2\\right\\}.\n$$\nThis expression is in terms of $n$, $\\sigma^2$, and the observations $X_i$.", "answer": "$$\\boxed{\\frac{1}{\\sigma^{2}}\\max_{1\\le \\tau\\le n-1}\\left\\{\\frac{\\tau\\,(n-\\tau)}{n}\\left(\\frac{1}{\\tau}\\sum_{i=1}^{\\tau}X_{i}-\\frac{1}{n-\\tau}\\sum_{i=\\tau+1}^{n}X_{i}\\right)^{2}\\right\\}}$$", "id": "1940664"}]}