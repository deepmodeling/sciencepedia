{"hands_on_practices": [{"introduction": "We begin with a common scenario in quality control: modeling the occurrence of defects. This exercise [@problem_id:1917484] uses the Poisson distribution, a cornerstone for modeling count data, to estimate the average defect rate. By working through this problem, you will not only apply the core mechanics of maximum likelihood estimation to a discrete distribution but also discover the powerful invariance property, which allows us to find the MLE for the variance directly from the MLE of the rate parameter $\\lambda$.", "problem": "A textile manufacturer is implementing a new quality control protocol. The number of defects, such as snags or discoloration, found in a randomly selected one-square-meter area of fabric is modeled by a Poisson distribution with an unknown rate parameter $\\lambda$. This parameter $\\lambda$ represents the average number of defects per square meter.\n\nTo assess a new batch of fabric, a quality control engineer inspects $n=8$ independent one-square-meter patches and records the number of defects for each. The observed counts are:\n$$3, 5, 2, 4, 3, 4, 6, 3$$\n\nAssuming the observations are independent and identically distributed samples from this Poisson distribution, determine the Maximum Likelihood Estimate (MLE) for the variance of the number of defects per square meter for this batch of fabric.", "solution": "Let $X_{1},\\dots,X_{n}$ be independent and identically distributed as $\\operatorname{Poisson}(\\lambda)$, with pmf $P(X=x)=\\frac{\\lambda^{x}\\exp(-\\lambda)}{x!}$ for $x\\in\\{0,1,2,\\dots\\}$. The likelihood for observations $x_{1},\\dots,x_{n}$ is\n$$\nL(\\lambda)=\\prod_{i=1}^{n}\\frac{\\lambda^{x_{i}}\\exp(-\\lambda)}{x_{i}!}\n=\\frac{\\lambda^{\\sum_{i=1}^{n}x_{i}}\\exp(-n\\lambda)}{\\prod_{i=1}^{n}x_{i}!}.\n$$\nThe log-likelihood is\n$$\n\\ell(\\lambda)=\\ln L(\\lambda)=\\left(\\sum_{i=1}^{n}x_{i}\\right)\\ln\\lambda - n\\lambda - \\sum_{i=1}^{n}\\ln(x_{i}!).\n$$\nDifferentiate with respect to $\\lambda$ and set to zero:\n$$\n\\frac{\\partial \\ell}{\\partial \\lambda}=\\frac{\\sum_{i=1}^{n}x_{i}}{\\lambda}-n=0\n\\quad\\Longrightarrow\\quad\n\\hat{\\lambda}=\\frac{1}{n}\\sum_{i=1}^{n}x_{i}.\n$$\nThe second derivative is $\\frac{\\partial^{2}\\ell}{\\partial \\lambda^{2}}=-\\frac{\\sum_{i=1}^{n}x_{i}}{\\lambda^{2}}0$ for $\\lambda0$, confirming a maximum.\n\nFor a Poisson distribution, the variance equals the parameter: $\\operatorname{Var}(X)=\\lambda$. Therefore, the MLE for the variance is the MLE for $\\lambda$:\n$$\n\\widehat{\\operatorname{Var}}(X)=\\hat{\\lambda}=\\frac{1}{n}\\sum_{i=1}^{n}x_{i}.\n$$\nWith the given data $3,5,2,4,3,4,6,3$, we have\n$$\n\\sum_{i=1}^{8}x_{i}=3+5+2+4+3+4+6+3=30,\\quad n=8,\n$$\nso\n$$\n\\widehat{\\operatorname{Var}}(X)=\\hat{\\lambda}=\\frac{30}{8}=\\frac{15}{4}.\n$$", "answer": "$$\\boxed{\\frac{15}{4}}$$", "id": "1917484"}, {"introduction": "Next, we shift our focus from discrete counts to continuous measurements, a frequent task in engineering and the physical sciences. This practice problem [@problem_id:1917486] explores a model for material resilience, where the parameter $\\theta$ characterizes a component's durability. Here, you will solidify your understanding of the MLE process for continuous distributions by constructing the log-likelihood function from a sample and using calculus to find the parameter value that best explains the observed data.", "problem": "A research group in material science is studying the failure behavior of a new type of fiber optic cable under stress. They model the proportion of the cable's cross-sectional area that remains intact after a specific stress test as a random variable $X$, where $X$ can take any value in the interval $[0, 1]$. A value of $X=1$ means the cable is undamaged, while $X=0$ means it has completely failed.\n\nThe researchers hypothesize that the probability density function (PDF) for $X$ is given by:\n$$f(x|\\theta) = \\theta x^{\\theta-1}$$\nfor $x \\in [0, 1]$, and $f(x|\\theta) = 0$ otherwise. The parameter $\\theta  0$ is a measure of the cable's resilience; higher values of $\\theta$ indicate a greater tendency for the cable to remain largely intact.\n\nTo estimate this resilience parameter, the researchers perform the stress test on a random sample of $n$ cables, recording the intact proportions $X_1, X_2, \\ldots, X_n$.\n\nYour task is to find the Maximum Likelihood Estimator (MLE) for the resilience parameter $\\theta$. Express your answer as a formula in terms of the sample size $n$ and the observations $X_i$.", "solution": "Let $X_{1},\\ldots,X_{n}$ be independent and identically distributed with density $f(x\\mid\\theta)=\\theta x^{\\theta-1}$ for $x\\in[0,1]$ and $\\theta0$. The likelihood function for $\\theta$ given observations $x_{1},\\ldots,x_{n}$ (assumed in $[0,1]$) is\n$$\nL(\\theta)=\\prod_{i=1}^{n} f(x_{i}\\mid\\theta)=\\prod_{i=1}^{n}\\left[\\theta x_{i}^{\\theta-1}\\right]=\\theta^{n}\\prod_{i=1}^{n}x_{i}^{\\theta-1}.\n$$\nThe log-likelihood is\n$$\n\\ell(\\theta)=\\ln L(\\theta)=n\\ln\\theta+(\\theta-1)\\sum_{i=1}^{n}\\ln x_{i}.\n$$\nDifferentiate with respect to $\\theta$ and set the derivative to zero to obtain the critical point:\n$$\n\\frac{d\\ell}{d\\theta}=\\frac{n}{\\theta}+\\sum_{i=1}^{n}\\ln x_{i}=0\n\\quad\\Longrightarrow\\quad\n\\hat{\\theta}=-\\frac{n}{\\sum_{i=1}^{n}\\ln x_{i}}.\n$$\nTo verify that this critical point corresponds to a maximum, compute the second derivative:\n$$\n\\frac{d^{2}\\ell}{d\\theta^{2}}=-\\frac{n}{\\theta^{2}}0\\quad\\text{for }\\theta0,\n$$\nso the log-likelihood is strictly concave in $\\theta0$ and the critical point is the unique maximizer whenever $\\sum_{i=1}^{n}\\ln x_{i}0$ (which holds almost surely unless all $x_{i}=1$). In the edge case where all $x_{i}=1$, $\\ell(\\theta)=n\\ln\\theta$ is increasing in $\\theta$ and the MLE is $+\\infty$. Otherwise, the MLE is given by the formula above.", "answer": "$$\\boxed{-\\frac{n}{\\sum_{i=1}^{n}\\ln X_{i}}}$$", "id": "1917486"}, {"introduction": "Our final practice problem presents a unique challenge that requires a different approach. Instead of estimating a continuous parameter like a rate or a mean, we tackle the problem of estimating the number of trials $n$ in a binomial experimentâ€”a discrete parameter [@problem_id:1917493]. Since we cannot use differentiation on an integer parameter, this exercise will guide you through the powerful technique of comparing the likelihood of successive values, introducing you to the method of likelihood ratios for solving maximization problems over discrete sets.", "problem": "A data science team is analyzing the results of a large-scale A/B test. A specific variant of a feature was shown to an unknown number of users, $n$. From extensive historical data, it is well-established that the probability of any given user engaging with this type of feature is $p$, where $0  p  1$. The engagement of each user is an independent event.\n\nAfter the test concluded, the analytics dashboard reported a total of $k$ user engagements, where $k$ is a positive integer. The number of engagements $k$ is modeled as a single observation from a binomial distribution, $B(n, p)$. The probability mass function for this distribution is given by:\n$$ P(X=k) = \\binom{n}{k} p^k (1-p)^{n-k} $$\nfor integers $n$ and $k$ such that $n \\ge k  0$.\n\nGiven the observed number of engagements $k$ and the known probability $p$, your task is to determine the Maximum Likelihood Estimator (MLE) for the total number of users, $n$. Express your answer, denoted by $\\hat{n}$, as a single, closed-form analytic expression in terms of $k$ and $p$. You may use the floor function, $\\lfloor x \\rfloor$, which returns the greatest integer less than or equal to $x$.", "solution": "We are given a single observation $X=k$ from $B(n,p)$ with known $p \\in (0,1)$ and unknown integer $n \\ge k$. The likelihood as a function of $n$ is\n$$\nL(n) = \\binom{n}{k} p^{k} (1-p)^{n-k}, \\quad n \\in \\{k, k+1, k+2, \\dots\\}.\n$$\nSince $p^{k}$ is constant in $n$, maximizing $L(n)$ over integer $n \\ge k$ is equivalent to maximizing\n$$\ng(n) = \\binom{n}{k} (1-p)^{n-k}.\n$$\nConsider the ratio of successive terms to determine where $g(n)$ increases or decreases. Using $\\binom{n+1}{k} = \\binom{n}{k} \\frac{n+1}{n+1-k}$, we have\n$$\n\\frac{g(n+1)}{g(n)} = \\frac{\\binom{n+1}{k}(1-p)^{n+1-k}}{\\binom{n}{k}(1-p)^{n-k}} = \\frac{n+1}{n+1-k}(1-p).\n$$\nDefine\n$$\nR(n) \\equiv \\frac{g(n+1)}{g(n)} = \\frac{n+1}{n+1-k}(1-p), \\quad n \\ge k.\n$$\nBecause $n+1-k \\ge 1$ and $1-p0$, the sign of monotonicity is determined by whether $R(n)$ is above or below $1$. The likelihood $L(n)$ increases with $n$ when $R(n)1$ and decreases when $R(n)1$. Solve $R(n) \\ge 1$:\n$$\n\\frac{n+1}{n+1-k}(1-p) \\ge 1\n\\;\\;\\Longleftrightarrow\\;\\;\n(1-p)(n+1) \\ge n+1-k\n\\;\\;\\Longleftrightarrow\\;\\;\n-p(n+1) \\ge -k\n\\;\\;\\Longleftrightarrow\\;\\;\np(n+1) \\le k.\n$$\nEquivalently, $n \\le \\frac{k}{p}-1$. Thus, $L(n)$ is increasing for integers $n$ up to the largest integer not exceeding $\\frac{k}{p}-1$, and decreasing thereafter. To pinpoint the mode among integers, use the standard discrete mode condition: the maximizing integers $n$ satisfy\n$$\nR(n-1) \\ge 1 \\quad \\text{and} \\quad R(n) \\le 1.\n$$\nCompute each inequality explicitly. For $nk$,\n$$\nR(n-1) \\ge 1\n\\;\\;\\Longleftrightarrow\\;\\;\n\\frac{n}{n-k}(1-p) \\ge 1\n\\;\\;\\Longleftrightarrow\\;\\;\npn \\le k,\n$$\nand\n$$\nR(n) \\le 1\n\\;\\;\\Longleftrightarrow\\;\\;\n\\frac{n+1}{n+1-k}(1-p) \\le 1\n\\;\\;\\Longleftrightarrow\\;\\;\np(n+1) \\ge k.\n$$\nCombining,\n$$\npn \\le k \\le p(n+1)\n\\;\\;\\Longleftrightarrow\\;\\;\nn \\le \\frac{k}{p} \\le n+1.\n$$\nTherefore, the MLE over integers is any integer $n$ in the interval $\\left[\\frac{k}{p}-1, \\frac{k}{p}\\right]$. If $\\frac{k}{p}$ is not an integer, the unique integer in this interval is $n = \\left\\lfloor \\frac{k}{p} \\right\\rfloor$. If $\\frac{k}{p}$ is an integer $m$, then both $n=m-1$ and $n=m$ maximize the likelihood; a valid single-valued choice is\n$$\n\\hat{n} = \\left\\lfloor \\frac{k}{p} \\right\\rfloor,\n$$\nwhich also respects the constraint $\\hat{n} \\ge k$ because $\\frac{k}{p} \\ge k$ for $p \\in (0,1)$.", "answer": "$$\\boxed{\\left\\lfloor \\frac{k}{p} \\right\\rfloor}$$", "id": "1917493"}]}