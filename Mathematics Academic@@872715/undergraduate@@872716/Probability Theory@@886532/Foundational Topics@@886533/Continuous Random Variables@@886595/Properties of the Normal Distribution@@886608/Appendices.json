{"hands_on_practices": [{"introduction": "Often in real-world scenarios, we observe outcomes and want to infer the underlying process that generates them. This first practice flips the typical problem on its head: instead of using a known mean and standard deviation to find probabilities, you will use given probabilities to determine these fundamental parameters. This exercise [@problem_id:1383355] is crucial for fields like quality control and process analysis, where understanding the central tendency and variability of a system is the primary goal.", "problem": "A new automated coffee machine is designed to dispense a precise amount of espresso for a premium coffee beverage. However, due to minor fluctuations in pressure and temperature, the actual volume of espresso dispensed, denoted by the random variable $V$, follows a normal distribution. A quality control analysis has determined that 15% of the drinks dispensed contain more than 55.0 milliliters (mL) of espresso, and 15% of the drinks contain less than 45.0 mL.\n\nYou are tasked with determining the operational parameters of this machine. Find the mean $\\mu$ and the standard deviation $\\sigma$ of the volume of espresso dispensed.\n\nFor your calculations, assume that for a standard normal random variable $Z \\sim N(0, 1)$, the value $z$ such that $P(Z \\le z) = 0.85$ is approximately $1.036$.\n\nProvide your answer as the numerical values for the mean and the standard deviation, in that order, both expressed in mL. Do not round the mean. Round your value for the standard deviation to three significant figures.", "solution": "Let $V \\sim N(\\mu,\\sigma^{2})$. Standardizing gives $Z=\\frac{V-\\mu}{\\sigma} \\sim N(0,1)$.\n\nGiven $P(V55)=0.15$, we have $P(V \\leq 55)=0.85$, so\n$$\n\\frac{55-\\mu}{\\sigma}=z_{0.85}=1.036.\n$$\nGiven $P(V45)=0.15$, we have $P(V \\leq 45)=0.15$, so by symmetry of the standard normal,\n$$\n\\frac{45-\\mu}{\\sigma}=z_{0.15}=-1.036.\n$$\nThese give the system\n$$\n55-\\mu=1.036\\,\\sigma, \\quad 45-\\mu=-1.036\\,\\sigma.\n$$\nAdding the two equations yields\n$$\n(55+45)-2\\mu=0 \\;\\;\\Rightarrow\\;\\; \\mu=50.\n$$\nSubstituting back,\n$$\n\\sigma=\\frac{55-\\mu}{1.036}=\\frac{5}{1.036}=\\frac{1250}{259}\\approx 4.826254\\ldots\n$$\nRounding $\\sigma$ to three significant figures gives $\\sigma \\approx 4.83$. The mean is exact and is not rounded.", "answer": "$$\\boxed{\\begin{pmatrix}50  4.83\\end{pmatrix}}$$", "id": "1383355"}, {"introduction": "Many complex phenomena can be modeled as the aggregate effect of multiple independent factors. This exercise [@problem_id:15194] explores one of the most powerful and elegant properties of the normal distribution: its closure under addition. By working through this problem, you will see how to characterize the distribution of a sum of two independent normal variables and calculate probabilities associated with it, a skill vital in fields ranging from signal processing to financial modeling.", "problem": "Let $X$ and $Y$ be two independent random variables. The variable $X$ follows a normal distribution with mean $\\mu_X$ and variance $\\sigma_X^2$, and its probability density function (PDF) is given by:\n$$f_X(x) = \\frac{1}{\\sqrt{2\\pi\\sigma_X^2}} \\exp\\left(-\\frac{(x-\\mu_X)^2}{2\\sigma_X^2}\\right)$$\nSimilarly, the variable $Y$ follows a normal distribution with mean $\\mu_Y$ and variance $\\sigma_Y^2$.\n\nA new random variable, $Z$, is defined as the sum of $X$ and $Y$, i.e., $Z = X + Y$.\n\nThe cumulative distribution function (CDF) of a standard normal variable $W \\sim N(0,1)$ is denoted by $\\Phi(w) = P(W \\le w)$.\n\nGiven a constant $k$, derive a closed-form expression for the probability $P(Z  k)$. The expression should be in terms of $\\mu_X$, $\\mu_Y$, $\\sigma_X^2$, $\\sigma_Y^2$, the constant $k$, and the standard normal CDF, $\\Phi$.", "solution": "Since $X$ and $Y$ are independent and Gaussian, their sum $Z=X+Y$ is also Gaussian with mean and variance given by the sum of the individual means and variances.  Thus\n$$\n\\mu_Z = \\mu_X + \\mu_Y,\n\\qquad\n\\sigma_Z^2 = \\sigma_X^2 + \\sigma_Y^2.\n$$\nHence \n$$\nZ\\sim N\\bigl(\\mu_X+\\mu_Y,\\;\\sigma_X^2+\\sigma_Y^2\\bigr).\n$$\nWe seek \n$$\nP(Zk)=1-P(Z\\le k).\n$$\nStandardizing,\n$$\nP(Z\\le k)\n= \\Phi\\!\\Bigl(\\frac{k-\\mu_Z}{\\sigma_Z}\\Bigr)\n= \\Phi\\!\\Bigl(\\frac{k-(\\mu_X+\\mu_Y)}{\\sqrt{\\sigma_X^2+\\sigma_Y^2}}\\Bigr).\n$$\nTherefore\n$$\nP(Zk)\n=1-\\Phi\\!\\Bigl(\\frac{k-(\\mu_X+\\mu_Y)}{\\sqrt{\\sigma_X^2+\\sigma_Y^2}}\\Bigr).\n$$", "answer": "$$\\boxed{1 - \\Phi\\!\\Bigl(\\frac{k - (\\mu_X + \\mu_Y)}{\\sqrt{\\sigma_X^2 + \\sigma_Y^2}}\\Bigr)}$$", "id": "15194"}, {"introduction": "Beyond analyzing individual variables or simple sums, a deeper understanding of statistics requires examining the relationships between different combinations of random variables. This final practice [@problem_id:15188] challenges you to investigate the covariance between the sum and difference of two independent and identically distributed (IID) normal variables. The result is surprisingly clean and reveals a fundamental structural property that is especially significant in the study of multivariate normal distributions and statistical independence.", "problem": "Let $X$ and $Y$ be two independent and identically distributed (IID) random variables, each following a normal distribution with mean $\\mu$ and variance $\\sigma^2$, denoted as $X, Y \\sim \\mathcal{N}(\\mu, \\sigma^2)$.\n\nConsider two new random variables, $U$ and $V$, defined as the sum and difference of $X$ and $Y$, respectively:\n$$U = X + Y$$\n$$V = X - Y$$\n\nDerive the covariance between $U$ and $V$, denoted as $\\text{Cov}(U, V)$.", "solution": "We have $U=X+Y$ and $V=X-Y$, with $X,Y\\sim \\mathcal N(\\mu,\\sigma^2)$ independent.  First compute the means:\n$$E[U]=E[X]+E[Y]=\\mu+\\mu=2\\mu,\\qquad \nE[V]=E[X]-E[Y]=\\mu-\\mu=0.$$\nBy definition,\n$$\\mathrm{Cov}(U,V)\n=E\\bigl[(U-E[U])(V-E[V])\\bigr]\n=E\\bigl[(X+Y-2\\mu)(X-Y)\\bigr].$$\nExpand the product:\n$$(X+Y-2\\mu)(X-Y)\n=(X-\\mu+Y-\\mu)(X-Y)$$\n$$=(X-\\mu)(X-Y)+(Y-\\mu)(X-Y)$$\n$$=(X-\\mu)^2-(X-\\mu)(Y-\\mu)+(Y-\\mu)(X-\\mu)-(Y-\\mu)^2.$$\nTaking expectation and using independence ($\\mathrm{Cov}(X,Y)=0$) and $\\mathrm{Var}(X)=\\mathrm{Var}(Y)=\\sigma^2$ gives\n$$\\mathrm{Cov}(U,V)\n=E[(X-\\mu)^2]-E[(X-\\mu)(Y-\\mu)]+E[(Y-\\mu)(X-\\mu)]-E[(Y-\\mu)^2]$$\n$$=\\sigma^2-0+0-\\sigma^2=0.$$", "answer": "$$\\boxed{0}$$", "id": "15188"}]}