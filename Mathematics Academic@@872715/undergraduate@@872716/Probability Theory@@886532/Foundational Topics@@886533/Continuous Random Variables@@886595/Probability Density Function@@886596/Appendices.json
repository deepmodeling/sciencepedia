{"hands_on_practices": [{"introduction": "To truly understand a random variable, we must be able to quantify its key characteristics. This practice focuses on two of the most fundamental measures: the mean, which indicates the 'center' of the distribution, and the variance, which describes its 'spread' or dispersion. By working through this problem, you will gain hands-on experience applying the integral formulas for $\\mathbb{E}[T]$ and $\\operatorname{Var}(T)$, solidifying your ability to extract essential statistical information directly from a probability density function [@problem_id:1379851].", "problem": "The operational lifetime of a specialized electronic component, in years, is modeled as a continuous random variable $T$. Its probability density function (PDF) is given by\n$$\nf(t) = \\begin{cases} \\frac{3}{t^4}  \\text{if } t \\ge 1 \\\\ 0  \\text{if } t  1 \\end{cases}\n$$\nCalculate the variance of the lifetime $T$. Report your answer for the variance as an exact numerical value in units of years$^2$.", "solution": "We first verify that $f(t)$ is a valid probability density function by checking normalization:\n$$\n\\int_{-\\infty}^{\\infty} f(t) \\, dt = \\int_{1}^{\\infty} \\frac{3}{t^{4}} \\, dt = 3 \\int_{1}^{\\infty} t^{-4} \\, dt = 3 \\left[ \\frac{t^{-3}}{-3} \\right]_{1}^{\\infty} = 3 \\left( 0 - \\left( -\\frac{1}{3} \\right) \\right) = 1.\n$$\nThe variance is $\\operatorname{Var}(T) = \\mathbb{E}[T^{2}] - \\left( \\mathbb{E}[T] \\right)^{2}$. Compute the mean:\n$$\n\\mathbb{E}[T] = \\int_{1}^{\\infty} t \\cdot \\frac{3}{t^{4}} \\, dt = 3 \\int_{1}^{\\infty} t^{-3} \\, dt = 3 \\left[ \\frac{t^{-2}}{-2} \\right]_{1}^{\\infty} = 3 \\left( 0 - \\left( -\\frac{1}{2} \\right) \\right) = \\frac{3}{2}.\n$$\nCompute the second moment:\n$$\n\\mathbb{E}[T^{2}] = \\int_{1}^{\\infty} t^{2} \\cdot \\frac{3}{t^{4}} \\, dt = 3 \\int_{1}^{\\infty} t^{-2} \\, dt = 3 \\left[ \\frac{t^{-1}}{-1} \\right]_{1}^{\\infty} = 3 \\left( 0 - \\left( -1 \\right) \\right) = 3.\n$$\nTherefore, the variance is\n$$\n\\operatorname{Var}(T) = 3 - \\left( \\frac{3}{2} \\right)^{2} = \\frac{3}{4}.\n$$", "answer": "$$\\boxed{\\frac{3}{4}}$$", "id": "1379851"}, {"introduction": "The power of probability theory shines when we apply it to solve real-world problems. This exercise moves beyond calculating basic properties to finding the expected value of a function of a random variable, a technique with vast applications in fields like finance and engineering. You will model a company's warranty policy to determine the expected refund cost, learning how PDFs can be used to inform business strategy and risk assessment [@problem_id:1379821].", "problem": "A company manufactures a specific type of electronic sensor. The operational lifetime $T$ of a sensor, measured in years, is a continuous random variable. The probability density function (PDF) that models this lifetime is given by $f(t) = \\frac{t}{8}$ for $0 \\le t \\le 4$, and $f(t) = 0$ for all other values of $t$.\n\nThe company sells each sensor for a price $P$ and offers a warranty based on the following terms:\n- If the sensor fails within the first year ($0 \\le T  1$), the company provides a full refund of $P$.\n- If the sensor fails during the second year ($1 \\le T  2$), the company provides a partial refund of $\\frac{P}{2}$.\n- If the sensor fails at any point after two years ($T \\ge 2$), no refund is given.\n\nBased on this model, what is the expected refund cost per sensor for the company, expressed as a fraction of the selling price $P$?", "solution": "Let $T$ be the sensor lifetime with PDF $f(t)=\\frac{t}{8}$ for $0 \\leq t \\leq 4$ and $f(t)=0$ otherwise. First, verify that $f$ is a valid PDF:\n$$\n\\int_{0}^{4} \\frac{t}{8}\\,dt=\\left.\\frac{t^{2}}{16}\\right|_{0}^{4}=\\frac{16}{16}=1.\n$$\nDefine the refund function $g(t)$ by the warranty terms:\n$$\ng(t)=\\begin{cases}\nP,  0 \\leq t  1,\\\\\n\\frac{P}{2},  1 \\leq t  2,\\\\\n0,  t \\geq 2.\n\\end{cases}\n$$\nThe expected refund is $E[g(T)]=\\int_{0}^{\\infty} g(t) f(t)\\,dt$, which reduces to the intervals where $g(t)\\neq 0$:\n$$\nE[g(T)]=\\int_{0}^{1} P \\cdot \\frac{t}{8}\\,dt+\\int_{1}^{2} \\frac{P}{2}\\cdot \\frac{t}{8}\\,dt.\n$$\nCompute each integral:\n$$\n\\int_{0}^{1} \\frac{t}{8}\\,dt=\\left.\\frac{t^{2}}{16}\\right|_{0}^{1}=\\frac{1}{16},\\qquad \\int_{1}^{2} \\frac{t}{8}\\,dt=\\left.\\frac{t^{2}}{16}\\right|_{1}^{2}=\\frac{4-1}{16}=\\frac{3}{16}.\n$$\nThus,\n$$\nE[g(T)]=P\\cdot \\frac{1}{16}+\\frac{P}{2}\\cdot \\frac{3}{16}=P\\left(\\frac{1}{16}+\\frac{3}{32}\\right)=P\\cdot \\frac{5}{32}.\n$$\nTherefore, the expected refund cost per sensor, expressed as a fraction of the selling price $P$, is $\\frac{5}{32}$.", "answer": "$$\\boxed{\\frac{5}{32}}$$", "id": "1379821"}, {"introduction": "Many complex systems can be modeled as the sum of simpler, independent random processes. This practice introduces a powerful mathematical tool—the convolution—for determining the probability density function of such a sum. By finding the distribution of the total time for a task composed of two separate random intervals, you will learn a fundamental method for building more sophisticated probability models from basic components [@problem_id:1379824].", "problem": "In a simplified model of a computational task, the total time to completion, $T$, is the sum of two independent random time intervals: a setup time $T_s$ and an execution time $T_e$.\n\nThe setup time, $T_s$, is modeled as a random variable that is uniformly distributed over the interval $[0, \\alpha]$, where $\\alpha=1$ second is the maximum possible setup time.\n\nThe execution time, $T_e$, follows a standard exponential distribution. The probability density function (PDF) for a standard exponential random variable $Y$ is given by $f_Y(y) = \\exp(-y)$ for $y \\ge 0$ and $f_Y(y) = 0$ for $y  0$.\n\nLet $T = T_s + T_e$ be the total time for the task. Determine the probability density function, $f_T(t)$, for the total time $T$. Express your answer as a function of $t$, defined for all real numbers.", "solution": "Let $T_{s}$ and $T_{e}$ be independent. The setup time is $T_{s} \\sim \\text{Uniform}(0,\\alpha)$ with $\\alpha0$, so its PDF is\n$$\nf_{T_{s}}(s)=\\begin{cases}\n\\frac{1}{\\alpha},  0 \\le s \\le \\alpha,\\\\\n0,  \\text{otherwise}.\n\\end{cases}\n$$\nThe execution time is $T_{e}$ with standard exponential PDF\n$$\nf_{T_{e}}(u)=\\begin{cases}\n\\exp(-u),  u \\ge 0,\\\\\n0,  u0.\n\\end{cases}\n$$\nFor the sum $T=T_{s}+T_{e}$ of independent random variables, the PDF is given by the convolution\n$$\nf_{T}(t)=\\int_{-\\infty}^{\\infty} f_{T_{s}}(s)\\,f_{T_{e}}(t-s)\\,ds.\n$$\nBecause $f_{T_{s}}(s)$ is supported on $[0,\\alpha]$ and $f_{T_{e}}(t-s)$ is supported when $t-s \\ge 0$, the integrand is nonzero only when $0 \\le s \\le \\alpha$ and $s \\le t$. Therefore the limits reduce to $s \\in [0,\\min\\{\\alpha,t\\}]$ for $t \\ge 0$, and there is no contribution for $t0$. Hence, for $t0$, $f_{T}(t)=0$. For $t \\ge 0$,\n$$\nf_{T}(t)=\\int_{0}^{\\min\\{\\alpha,t\\}} \\frac{1}{\\alpha}\\,\\exp\\!\\big(-(t-s)\\big)\\,ds.\n$$\nConsider the two cases:\n\n1) For $0 \\le t \\le \\alpha$,\n$$\nf_{T}(t)=\\frac{1}{\\alpha}\\int_{0}^{t} \\exp\\!\\big(-(t-s)\\big)\\,ds\n=\\frac{1}{\\alpha}\\exp(-t)\\int_{0}^{t}\\exp(s)\\,ds\n=\\frac{1}{\\alpha}\\exp(-t)\\big(\\exp(t)-1\\big)\n=\\frac{1}{\\alpha}\\big(1-\\exp(-t)\\big).\n$$\n\n2) For $t \\ge \\alpha$,\n$$\nf_{T}(t)=\\frac{1}{\\alpha}\\int_{0}^{\\alpha} \\exp\\!\\big(-(t-s)\\big)\\,ds\n=\\frac{1}{\\alpha}\\exp(-t)\\int_{0}^{\\alpha}\\exp(s)\\,ds\n=\\frac{1}{\\alpha}\\exp(-t)\\big(\\exp(\\alpha)-1\\big)\n=\\frac{\\exp(\\alpha)-1}{\\alpha}\\,\\exp(-t).\n$$\n\nWith the given $\\alpha=1$, these simplify to\n$$\nf_{T}(t)=\\begin{cases}\n0,  t0,\\\\\n1-\\exp(-t),  0 \\le t \\le 1,\\\\\n\\big(\\exp(1)-1\\big)\\exp(-t),  t \\ge 1.\n\\end{cases}\n$$\nThis function is continuous at $t=1$ and integrates to $1$ over $(-\\infty,\\infty)$, so it is a valid PDF for $T$.", "answer": "$$\\boxed{f_{T}(t)=\\begin{cases}\n0,  t0,\\\\\n1-\\exp(-t),  0 \\le t \\le 1,\\\\\n\\big(\\exp(1)-1\\big)\\exp(-t),  t \\ge 1.\n\\end{cases}}$$", "id": "1379824"}]}