{"hands_on_practices": [{"introduction": "This first exercise tackles a core problem in computer science: hash table collisions. Calculating the exact probability for a specific number of collisions can be very complex, but this practice demonstrates how linearity of expectation provides a direct and elegant path to the average number of collisions. The key is to decompose the total count into a sum of simple indicator variables, one for each potential pair-wise collision. [@problem_id:1381865]", "problem": "A university's computer science department is tasked with archiving student projects. There are $m$ distinct student projects to be stored on a set of $n$ available servers. The system administrator employs a simple distribution scheme: each of the $m$ projects is assigned to exactly one of the $n$ servers, with the choice of server for each project being made independently and uniformly at random from the set of available servers.\n\nA \"collision\" is defined as an event where a pair of two distinct projects are assigned to the same server. Determine the expected total number of such colliding pairs. Provide your answer as a closed-form analytic expression in terms of $m$ and $n$.", "solution": "Let $X$ be the random variable representing the total number of colliding pairs of projects. Our goal is to find the expected value of $X$, denoted as $\\mathbb{E}[X]$.\n\nA direct calculation of the probability distribution of $X$ is complex. A more effective method is to use linearity of expectation. We can express $X$ as a sum of simpler random variables.\n\nFirst, let's identify all possible pairs of projects. Since there are $m$ projects, the total number of distinct pairs of projects is given by the binomial coefficient $\\binom{m}{2}$. Let the projects be indexed from $1$ to $m$. A generic pair of projects can be denoted as $(i, j)$, where $1 \\le i  j \\le m$.\n\nFor each such pair $(i, j)$, we define an indicator random variable, $X_{ij}$, as follows:\n$$\nX_{ij} =\n\\begin{cases}\n1  \\text{if project } i \\text{ and project } j \\text{ are assigned to the same server} \\\\\n0  \\text{otherwise}\n\\end{cases}\n$$\nThe total number of collisions, $X$, is the sum of these indicator variables over all unique pairs of projects:\n$$\nX = \\sum_{1 \\le i  j \\le m} X_{ij}\n$$\nBy the linearity of expectation, the expected total number of collisions is the sum of the expected values of these individual indicator variables:\n$$\n\\mathbb{E}[X] = \\mathbb{E}\\left[\\sum_{1 \\le i  j \\le m} X_{ij}\\right] = \\sum_{1 \\le i  j \\le m} \\mathbb{E}[X_{ij}]\n$$\nThe expectation of an indicator random variable is equal to the probability of the event it indicates. Therefore, for any pair $(i, j)$:\n$$\n\\mathbb{E}[X_{ij}] = \\mathbb{P}(X_{ij} = 1)\n$$\n$\\mathbb{P}(X_{ij} = 1)$ is the probability that project $i$ and project $j$ are assigned to the same server. Let's calculate this probability.\n\nProject $i$ can be assigned to any of the $n$ servers. Let's say it is assigned to server $k$. Since the assignments are independent and uniform, the probability of project $j$ being assigned to that same server $k$ is $\\frac{1}{n}$. This holds regardless of which server project $i$ was assigned to.\n\nAlternatively, we can consider the total sample space of assignments for the pair $(i, j)$. There are $n$ choices for project $i$ and $n$ choices for project $j$, so there are $n \\times n = n^2$ possible outcomes in the sample space, each equally likely. A collision occurs if both projects are assigned to server 1, or both to server 2, ..., or both to server $n$. There are $n$ such favorable outcomes. Thus, the probability of a collision for the pair $(i, j)$ is:\n$$\n\\mathbb{P}(X_{ij} = 1) = \\frac{\\text{Number of favorable outcomes}}{\\text{Total number of outcomes}} = \\frac{n}{n^2} = \\frac{1}{n}\n$$\nSo, the expectation of each indicator variable is $\\mathbb{E}[X_{ij}] = \\frac{1}{n}$.\n\nNow we can substitute this back into the sum for $\\mathbb{E}[X]$. The sum is taken over all unique pairs of projects. The number of such pairs is:\n$$\n\\binom{m}{2} = \\frac{m(m-1)}{2}\n$$\nTherefore, the expected total number of collisions is:\n$$\n\\mathbb{E}[X] = \\sum_{1 \\le i  j \\le m} \\frac{1}{n} = \\left(\\text{Number of pairs}\\right) \\times \\frac{1}{n} = \\binom{m}{2} \\cdot \\frac{1}{n}\n$$\nSubstituting the expression for the binomial coefficient, we get:\n$$\n\\mathbb{E}[X] = \\frac{m(m-1)}{2} \\cdot \\frac{1}{n} = \\frac{m(m-1)}{2n}\n$$\nThis is the final expression for the expected number of colliding pairs.", "answer": "$$\\boxed{\\frac{m(m-1)}{2n}}$$", "id": "1381865"}, {"introduction": "This next practice explores a scenario common in network analysis and statistical physics. A key insight here is that while the states of adjacent communication links are not independent (as they share a server), linearity of expectation still applies perfectly. This exercise powerfully illustrates that the random variables being summed do not need to be independent, a crucial feature that makes this tool so broadly applicable. [@problem_id:1381855]", "problem": "Consider a distributed computing network represented by a simple undirected graph $G=(V, E)$, where $V$ is the set of $n$ server nodes and $E$ is the set of $m$ communication links between them. For a system audit, each server is independently and randomly assigned one of two operational states: 'online' or 'offline'. The probability of a server being assigned the 'online' state is exactly $1/2$, and the probability of it being assigned the 'offline' state is also $1/2$.\n\nA communication link is defined as 'coherent' if the two servers it connects are in the same state (i.e., both are online or both are offline).\n\nYour task is to determine the expected number of coherent communication links across the entire network. Express your answer as a symbolic expression in terms of $n$ and/or $m$.", "solution": "Let each server node $v \\in V$ be assigned a state $S_{v} \\in \\{0,1\\}$, where $S_{v}=1$ denotes 'online' and $S_{v}=0$ denotes 'offline'. By assumption, for each $v$, $\\mathbb{P}(S_{v}=1)=\\mathbb{P}(S_{v}=0)=\\frac{1}{2}$, and the assignments are independent across nodes.\n\nFor each communication link (edge) $e=\\{u,v\\} \\in E$, define the indicator random variable\n$$\nX_{e}=\\begin{cases}\n1,  \\text{if } S_{u}=S_{v},\\\\\n0,  \\text{if } S_{u}\\neq S_{v}.\n\\end{cases}\n$$\nThe total number of coherent links is\n$$\nX=\\sum_{e \\in E} X_{e}.\n$$\nBy linearity of expectation,\n$$\n\\mathbb{E}[X]=\\sum_{e \\in E} \\mathbb{E}[X_{e}]=\\sum_{e \\in E} \\mathbb{P}(S_{u}=S_{v}).\n$$\nFor a fixed edge $e=\\{u,v\\}$, using independence of $S_{u}$ and $S_{v}$,\n$$\n\\mathbb{P}(S_{u}=S_{v})=\\mathbb{P}(S_{u}=1,S_{v}=1)+\\mathbb{P}(S_{u}=0,S_{v}=0)=\\left(\\frac{1}{2}\\right)\\left(\\frac{1}{2}\\right)+\\left(\\frac{1}{2}\\right)\\left(\\frac{1}{2}\\right)=\\frac{1}{4}+\\frac{1}{4}=\\frac{1}{2}.\n$$\nTherefore, each edge contributes expected value $\\frac{1}{2}$, and with $m=|E|$ edges,\n$$\n\\mathbb{E}[X]=m \\cdot \\frac{1}{2}=\\frac{m}{2}.\n$$\nThis result does not depend on the structure of $G$, only on the number of edges $m$, because linearity of expectation does not require independence between different $X_{e}$.", "answer": "$$\\boxed{\\frac{m}{2}}$$", "id": "1381855"}, {"introduction": "Our final practice demonstrates how linearity of expectation can be combined with other mathematical principles for elegant solutions to seemingly complex problems. The fragmentation of a network into disconnected clusters appears difficult to model at first glance. However, by using a fundamental identity from graph theory relating vertices, edges, and components, this exercise reveals a surprisingly simple and powerful solution. [@problem_id:1381828]", "problem": "A newly deployed constellation of $n$ satellites is designed for deep-space communication. The network topology connecting the satellites is a tree, ensuring that there is a unique communication path between any two satellites and that the number of active links is minimized.\n\nDuring a period of intense solar activity, each active communication link is subject to potential failure. It has been determined that each link fails independently of the others with a constant probability $p$, where $0  p  1$. When a link fails, it is permanently removed from the network. The failure of links may cause the network to fragment into several disconnected clusters. A cluster is defined as a maximal set of satellites that can still communicate with each other, either directly or indirectly.\n\nAssuming the initial network is an arbitrary tree with $n$ vertices (satellites), determine the expected number of disconnected clusters after the solar event. Express your answer as a single closed-form analytic expression in terms of $n$ and $p$.", "solution": "Let the initial satellite network be modeled as a tree $T = (V, E)$, where $V$ is the set of $n$ satellites (vertices) and $E$ is the set of $n-1$ communication links (edges). After the solar event, some edges are deleted, resulting in a new graph $G' = (V, E')$, where $E' \\subseteq E$. Since the original graph $T$ is a tree, it contains no cycles. The new graph $G'$, being a subgraph of $T$, also contains no cycles. A graph with no cycles is a forest.\n\nA fundamental property of any forest is the relationship between its number of vertices, edges, and connected components. For any forest with $V_{\\text{forest}}$ vertices, $E_{\\text{forest}}$ edges, and $C_{\\text{forest}}$ connected components, the identity $C_{\\text{forest}} = V_{\\text{forest}} - E_{\\text{forest}}$ holds.\n\nIn our problem, the resulting graph $G'$ is a forest. The number of vertices in $G'$ is fixed at $|V| = n$. The number of edges, $|E'|$, is a random variable, as is the number of clusters (connected components), which we denote by the random variable $C$. Applying the forest identity to $G'$, we get the relation:\n$$C = n - |E'|$$\nOur goal is to find the expected number of clusters, $\\mathbb{E}[C]$. Using the relation above and the property of linearity of expectation, we have:\n$$\\mathbb{E}[C] = \\mathbb{E}[n - |E'|] = \\mathbb{E}[n] - \\mathbb{E}[|E'|]$$\nSince $n$ is a constant, its expectation is $n$. The problem thus reduces to finding the expected number of edges in the resulting graph, $\\mathbb{E}[|E'|]$.\n$$\\mathbb{E}[C] = n - \\mathbb{E}[|E'|]$$\nTo find $\\mathbb{E}[|E'|]$, we can define indicator random variables. The initial tree has $|E| = n-1$ edges. Let's label them $e_1, e_2, \\ldots, e_{n-1}$. For each edge $e_i \\in E$, let $X_i$ be an indicator variable such that:\n$$X_i = \\begin{cases} 1  \\text{if edge } e_i \\text{ survives (does not fail)} \\\\ 0  \\text{if edge } e_i \\text{ fails} \\end{cases}$$\nThe problem states that each link fails with probability $p$. Therefore, the probability that a link survives is $1-p$.\nThe expectation of the indicator variable $X_i$ is given by:\n$$\\mathbb{E}[X_i] = 1 \\cdot \\mathbb{P}(X_i=1) + 0 \\cdot \\mathbb{P}(X_i=0) = \\mathbb{P}(X_i=1) = 1-p$$\nThe total number of edges in the final graph $G'$ is the sum of these indicator variables over all initial edges:\n$$|E'| = \\sum_{i=1}^{n-1} X_i$$\nWe can now find the expected value of $|E'|$ by again using the linearity of expectation:\n$$\\mathbb{E}[|E'|] = \\mathbb{E}\\left[\\sum_{i=1}^{n-1} X_i\\right] = \\sum_{i=1}^{n-1} \\mathbb{E}[X_i]$$\nSince the expectation of each $X_i$ is $1-p$, and there are $n-1$ edges in the initial tree, we have:\n$$\\mathbb{E}[|E'|] = \\sum_{i=1}^{n-1} (1-p) = (n-1)(1-p)$$\nFinally, we substitute this result back into our expression for $\\mathbb{E}[C]$:\n$$\\mathbb{E}[C] = n - \\mathbb{E}[|E'|] = n - (n-1)(1-p)$$\nExpanding and simplifying the expression gives the final answer:\n$$\\mathbb{E}[C] = n - (n - np - 1 + p) = n - n + np + 1 - p = 1 + p(n-1)$$\nThis result is notably independent of the specific structure of the initial tree, depending only on the number of satellites $n$ and the failure probability $p$.", "answer": "$$\\boxed{1 + (n-1)p}$$", "id": "1381828"}]}