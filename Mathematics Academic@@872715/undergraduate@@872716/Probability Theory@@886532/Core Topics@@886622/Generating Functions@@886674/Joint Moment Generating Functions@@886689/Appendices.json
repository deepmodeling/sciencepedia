{"hands_on_practices": [{"introduction": "A fundamental skill in working with multiple random variables is the ability to derive their joint moment generating function (MGF) from a given joint probability density function (PDF). This exercise provides practice in this core competency by asking you to calculate the joint MGF for two continuous variables whose distribution is uniform over a triangular region [@problem_id:1369211]. Mastering this type of calculation, which involves setting up and evaluating a double integral, is essential for analyzing systems where variables are constrained and dependent.", "problem": "Let $X$ and $Y$ be two continuous random variables. Their joint probability density function, $f_{X,Y}(x, y)$, is uniform over the triangular region in the $xy$-plane defined by the inequalities $0 \\leq y \\leq x \\leq 1$. Specifically, the joint PDF is given by:\n$$\nf_{X,Y}(x, y) = \\begin{cases} 2  \\text{if } 0 \\leq y \\leq x \\leq 1 \\\\ 0  \\text{otherwise} \\end{cases}\n$$\nDetermine the joint Moment Generating Function (MGF) of $X$ and $Y$, denoted as $M_{X,Y}(t_1, t_2)$. Express your answer as a single closed-form analytic expression in terms of $t_1$ and $t_2$.", "solution": "By definition, the joint MGF is\n$$\nM_{X,Y}(t_{1},t_{2})=\\mathbb{E}\\left[\\exp(t_{1}X+t_{2}Y)\\right]=\\iint_{\\mathbb{R}^{2}}\\exp(t_{1}x+t_{2}y)\\,f_{X,Y}(x,y)\\,dx\\,dy.\n$$\nSince $f_{X,Y}(x,y)=2$ on the region $0\\leq y\\leq x\\leq 1$ and zero otherwise, we integrate over this triangle:\n$$\nM_{X,Y}(t_{1},t_{2})=\\int_{0}^{1}\\int_{0}^{x}2\\,\\exp(t_{1}x+t_{2}y)\\,dy\\,dx.\n$$\nEvaluate the inner integral with respect to $y$ using the antiderivative of $\\exp(t_{2}y)$:\n$$\n\\int_{0}^{x}\\exp(t_{2}y)\\,dy=\\frac{\\exp(t_{2}x)-1}{t_{2}},\n$$\nwhere the expression is understood via its analytic extension at $t_{2}=0$. Thus,\n$$\nM_{X,Y}(t_{1},t_{2})=\\int_{0}^{1}2\\,\\exp(t_{1}x)\\,\\frac{\\exp(t_{2}x)-1}{t_{2}}\\,dx=\\frac{2}{t_{2}}\\int_{0}^{1}\\left[\\exp((t_{1}+t_{2})x)-\\exp(t_{1}x)\\right]dx.\n$$\nUse $\\int_{0}^{1}\\exp(ax)\\,dx=\\frac{\\exp(a)-1}{a}$ (with analytic continuation at $a=0$) to obtain\n$$\nM_{X,Y}(t_{1},t_{2})=\\frac{2}{t_{2}}\\left(\\frac{\\exp(t_{1}+t_{2})-1}{t_{1}+t_{2}}-\\frac{\\exp(t_{1})-1}{t_{1}}\\right).\n$$\nThis expression is analytic in $(t_{1},t_{2})$ with removable singularities at $t_{2}=0$, $t_{1}=0$, and $t_{1}+t_{2}=0$, and it satisfies $M_{X,Y}(0,0)=1$ by continuity.", "answer": "$$\\boxed{\\frac{2}{t_{2}}\\left(\\frac{\\exp(t_{1}+t_{2})-1}{t_{1}+t_{2}}-\\frac{\\exp(t_{1})-1}{t_{1}}\\right)}$$", "id": "1369211"}, {"introduction": "Complementing the continuous case, this practice explores the joint MGF for discrete random variables. You will work with a classic scenario of drawing numbered balls from an urn without replacement, which introduces dependence between the outcomes [@problem_id:1369244]. The task is to apply the definition of expectation as a weighted sum over a discrete sample space to construct the joint MGF, highlighting how combinatorial structures translate into the MGF's final form.", "problem": "Consider an urn containing three balls, uniquely numbered with the integers in the set $S = \\{1, 2, 3\\}$. An experiment consists of drawing two balls sequentially from the urn without replacement. Let the random variable $X_1$ denote the number on the first ball drawn, and let the random variable $X_2$ denote the number on the second ball drawn.\n\nDetermine the joint Moment Generating Function (MGF) of the random vector $(X_1, X_2)$, denoted by $M_{X_1, X_2}(t_1, t_2)$. Provide your answer as a single closed-form analytic expression in terms of $t_1$ and $t_2$.", "solution": "By definition, the joint moment generating function of $(X_{1}, X_{2})$ is\n$$\nM_{X_{1}, X_{2}}(t_{1}, t_{2}) = \\mathbb{E}\\!\\left[\\exp\\!\\left(t_{1} X_{1} + t_{2} X_{2}\\right)\\right].\n$$\nThe sample space of ordered draws without replacement from $S=\\{1,2,3\\}$ consists of the $3 \\times 2 = 6$ ordered pairs with distinct entries, each with probability $\\frac{1}{6}$. Therefore,\n$$\nM_{X_{1}, X_{2}}(t_{1}, t_{2}) = \\frac{1}{6} \\sum_{\\substack{i,j \\in \\{1,2,3\\} \\\\ i \\neq j}} \\exp\\!\\left(t_{1} i + t_{2} j\\right).\n$$\nEquivalently, separating the full product sum from the diagonal terms,\n$$\n\\sum_{\\substack{i,j \\in \\{1,2,3\\} \\\\ i \\neq j}} \\exp\\!\\left(t_{1} i + t_{2} j\\right)\n= \\left(\\sum_{i=1}^{3} \\exp\\!\\left(t_{1} i\\right)\\right)\\left(\\sum_{j=1}^{3} \\exp\\!\\left(t_{2} j\\right)\\right) - \\sum_{k=1}^{3} \\exp\\!\\left((t_{1}+t_{2}) k\\right),\n$$\nso\n$$\nM_{X_{1}, X_{2}}(t_{1}, t_{2})\n= \\frac{1}{6} \\left[\\left(\\exp(t_{1})+\\exp(2 t_{1})+\\exp(3 t_{1})\\right)\\left(\\exp(t_{2})+\\exp(2 t_{2})+\\exp(3 t_{2})\\right) - \\left(\\exp(t_{1}+t_{2})+\\exp\\!\\left(2(t_{1}+t_{2})\\right)+\\exp\\!\\left(3(t_{1}+t_{2})\\right)\\right)\\right].\n$$\nThis is a single closed-form analytic expression in terms of $t_{1}$ and $t_{2}$.", "answer": "$$\\boxed{\\frac{1}{6}\\left[\\left(\\exp(t_{1})+\\exp(2 t_{1})+\\exp(3 t_{1})\\right)\\left(\\exp(t_{2})+\\exp(2 t_{2})+\\exp(3 t_{2})\\right)-\\left(\\exp(t_{1}+t_{2})+\\exp\\!\\left(2(t_{1}+t_{2})\\right)+\\exp\\!\\left(3(t_{1}+t_{2})\\right)\\right)\\right]}$$", "id": "1369244"}, {"introduction": "Beyond pure calculation, a primary use of the joint MGF is to analyze the relationship between random variables, particularly their independence. This problem presents a hypothetical joint MGF from an engineering model and asks you to determine if the underlying variables are independent based on the function's structure alone [@problem_id:1369190]. It provides a direct application of the factorization theorem, demonstrating how a non-separable cross-product term in the MGF's exponent immediately signals dependence.", "problem": "An electrical engineer is studying the noise characteristics of a new amplifier circuit. The noise is modeled by two random voltage components, $X$ and $Y$. After extensive measurements, the engineer determines that the joint behavior of these two components can be accurately described by the joint Moment Generating Function (MGF), $M_{X,Y}(t_1, t_2)$, given by:\n\n$$M_{X,Y}(t_1, t_2) = \\exp\\left(5t_1 + 2t_2 + 8t_1^2 + \\frac{1}{2}t_2^2 + 4t_1t_2\\right)$$\n\nfor all real numbers $t_1$ and $t_2$.\n\nBased on this model, are the random voltage components $X$ and $Y$ independent?\n\nA. Yes, because the MGF is an exponential function.\n\nB. No, because the means of the random variables (the coefficients of $t_1$ and $t_2$) are non-zero.\n\nC. No, because the exponent of the MGF contains a cross-product term, $4t_1t_2$.\n\nD. Yes, because the joint MGF exists for all real values of $t_1$ and $t_2$.\n\nE. It is impossible to determine independence from the joint MGF alone.", "solution": "The central principle for determining the independence of two random variables, $X$ and $Y$, from their joint Moment Generating Function (MGF) is the factorization theorem. This theorem states that $X$ and $Y$ are independent if and only if their joint MGF, $M_{X,Y}(t_1, t_2)$, can be factored into the product of their individual (marginal) MGFs, $M_X(t_1)$ and $M_Y(t_2)$. That is:\n\n$$X \\text{ and } Y \\text{ are independent} \\iff M_{X,Y}(t_1, t_2) = M_X(t_1) M_Y(t_2)$$\n\nThe given joint MGF is:\n$$M_{X,Y}(t_1, t_2) = \\exp\\left(5t_1 + 2t_2 + 8t_1^2 + \\frac{1}{2}t_2^2 + 4t_1t_2\\right)$$\n\nFor the factorization condition $M_{X,Y}(t_1, t_2) = M_X(t_1) M_Y(t_2)$ to hold, we need to be able to write the joint MGF as a product of a function of only $t_1$ and a function of only $t_2$. Since the joint MGF is of the form $\\exp(P(t_1, t_2))$, this is equivalent to checking if the exponent, $P(t_1, t_2)$, can be separated into the sum of a function of only $t_1$ and a function of only $t_2$.\n\nLet's examine the exponent:\n$$P(t_1, t_2) = 5t_1 + 2t_2 + 8t_1^2 + \\frac{1}{2}t_2^2 + 4t_1t_2$$\n\nWe can try to rearrange the terms to see if separation is possible:\n$$P(t_1, t_2) = (5t_1 + 8t_1^2) + \\left(2t_2 + \\frac{1}{2}t_2^2\\right) + 4t_1t_2$$\n\nLet the hypothetical separated functions be $g(t_1) = 5t_1 + 8t_1^2$ and $h(t_2) = 2t_2 + \\frac{1}{2}t_2^2$. The exponent can be written as:\n$$P(t_1, t_2) = g(t_1) + h(t_2) + 4t_1t_2$$\n\nThe term $4t_1t_2$ is a \"cross-product\" term because it involves both $t_1$ and $t_2$. This term cannot be separated into a sum of a function of $t_1$ and a function of $t_2$. Because of the presence of this term, the exponent $P(t_1, t_2)$ cannot be written in the form $g(t_1) + h(t_2)$.\n\nConsequently, the joint MGF cannot be factored into the product of two functions, one depending only on $t_1$ and the other only on $t_2$:\n$$M_{X,Y}(t_1, t_2) = \\exp(g(t_1) + h(t_2) + 4t_1t_2) = \\exp(g(t_1)) \\exp(h(t_2)) \\exp(4t_1t_2) \\neq M_X(t_1)M_Y(t_2)$$\n\nSince the joint MGF does not factor into the product of the marginal MGFs, the random variables $X$ and $Y$ are not independent. The reason for the failure of factorization is the presence of the cross-product term $4t_1t_2$ in the exponent.\n\nLet's review the options:\nA. The form of the function (exponential) is not sufficient to determine independence. This is incorrect.\nB. The means of the variables being non-zero has no bearing on their independence. This is incorrect.\nC. The presence of the cross-product term $4t_1t_2$ prevents the MGF from being factorable, which implies that the variables are not independent. This is the correct reasoning.\nD. The existence of the MGF is a necessary prerequisite, but it does not guarantee independence. This is incorrect.\nE. It is possible to determine independence from the joint MGF, as demonstrated above. This is incorrect.\n\nTherefore, the correct conclusion and reasoning are provided in option C.", "answer": "$$\\boxed{C}$$", "id": "1369190"}]}