{"hands_on_practices": [{"introduction": "Let's begin with a foundational exercise that illustrates the core technique for finding the distribution of a transformed random variable. This problem involves a simple, one-to-one function—the square root—applied to a uniformly distributed variable. By mastering this, you will build a solid base for tackling more complex transformations, using the change of variables formula for monotonic functions. [@problem_id:5136]", "problem": "A continuous random variable $X$ is said to be uniformly distributed on the interval $[a, b]$ if its probability density function (PDF), $f_X(x)$, is given by:\n$$\nf_X(x) = \\begin{cases} \\frac{1}{b-a}  \\text{for } a \\le x \\le b \\\\ 0  \\text{otherwise} \\end{cases}\n$$\nConsider a random variable $X$ that is uniformly distributed on the interval $[0, L^2]$, where $L$ is a positive real constant. A new random variable $Y$ is defined as the positive square root of $X$, such that $Y = \\sqrt{X}$.\n\nFirst, derive the probability density function, $f_Y(y)$, for the random variable $Y$. Then, use this PDF to calculate the expected value of $Y$, denoted as $E[Y]$.", "solution": "We start with $X \\sim \\text{Unif}(0,L^2)$, so\n$$f_X(x)=\\begin{cases}\\frac{1}{L^2}0\\le x\\le L^2,\\\\0\\text{otherwise}.\\end{cases}$$\n\nLet $Y=\\sqrt{X} \\implies x=y^2$ and $dx/dy=2y$.  Hence for $0\\le y\\le L$:\n$$f_Y(y)=f_X(y^2)\\Bigl|\\frac{dx}{dy}\\Bigr|=\\frac{1}{L^2}\\cdot2y=\\frac{2y}{L^2}.$$\n\nThe expectation is\n$$E[Y]=\\int_0^L y\\,f_Y(y)\\,dy\n=\\int_0^L y\\frac{2y}{L^2}\\,dy\n=\\frac{2}{L^2}\\int_0^L y^2\\,dy\n=\\frac{2}{L^2}\\cdot\\frac{L^3}{3}\n=\\frac{2L}{3}.$$", "answer": "$$\\boxed{\\frac{2L}{3}}$$", "id": "5136"}, {"introduction": "Many real-world phenomena, such as signal power or kinetic energy, involve the square of a variable. This exercise explores such a quadratic transformation, which is a classic example of a many-to-one function where different input values can produce the same output. The key challenge lies in carefully considering the original variable's domain to correctly account for all contributing inputs, a crucial skill for accurate modeling. [@problem_id:1356799]", "problem": "In a signal processing simulation, a random input signal $P$ is generated from a uniform distribution over the continuous interval $[-1, 3]$. A non-linear amplifier processes this signal, producing an output signal $Y$ that is related to the input by the function $Y = P^2$. The behavior of the system depends on the probability distribution of the output signal. Determine the value of the probability density function of $Y$, denoted $f_Y(y)$, evaluated at $y=4$.", "solution": "Let $P$ be uniformly distributed on $[-1,3]$, so its probability density function is\n$$\nf_{P}(p)=\\begin{cases}\n\\frac{1}{4},  -1 \\leq p \\leq 3,\\\\\n0,  \\text{otherwise.}\n\\end{cases}\n$$\nThe output is $Y=P^{2}$. For a transformation $Y=g(P)$ with $g$ differentiable and one-to-one on branches, the density of $Y$ at $y$ is given by\n$$\nf_{Y}(y)=\\sum_{p_{i}:\\, g(p_{i})=y} \\frac{f_{P}(p_{i})}{|g'(p_{i})|},\n$$\nwhere the sum is over all roots $p_{i}$ in the support of $P$. Here $g(p)=p^{2}$ and $g'(p)=2p$. For $y>0$, the solutions to $p^{2}=y$ are $p=\\pm \\sqrt{y}$.\n\nWe evaluate at $y=4$. The roots are $p=2$ and $p=-2$. Among these, $p=2$ lies in $[-1,3]$ while $p=-2$ does not. Hence only $p=2$ contributes:\n$$\nf_{Y}(4)=\\frac{f_{P}(2)}{|g'(2)|}=\\frac{\\frac{1}{4}}{|2\\cdot 2|}=\\frac{1}{16}.\n$$", "answer": "$$\\boxed{\\frac{1}{16}}$$", "id": "1356799"}, {"introduction": "This final practice problem integrates several key concepts to model a realistic scenario from digital communications. Here, we analyze the power of a signal whose voltage follows a mixture distribution, representing different transmission modes. This exercise showcases the power of the Cumulative Distribution Function (CDF) method to handle complex transformations and provides insight into how these principles are applied in advanced engineering and data science applications. [@problem_id:1356802]", "problem": "In a simplified model for a digital communication system, a received voltage signal $X$ is measured. The signal's statistical properties depend on which of two transmission modes, Mode 1 or Mode 2, was used. The system operates in Mode 1 with a known probability $p$, where $0  p  1$. In this mode, the signal $X$ is a random variable following a normal distribution with mean $\\mu_1$ and variance $\\sigma_1^2 > 0$. With probability $1-p$, the system operates in Mode 2, where $X$ follows a normal distribution with mean $\\mu_2$ and variance $\\sigma_2^2 > 0$.\n\nThe overall Probability Density Function (PDF) of the signal $X$ is therefore a mixture of two normal distributions:\n$$f_X(x) = p\\cdot\\phi(x; \\mu_1, \\sigma_1^2) + (1-p)\\cdot\\phi(x; \\mu_2, \\sigma_2^2)$$\nwhere $\\phi(x; \\mu, \\sigma^2) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}}\\exp\\left(-\\frac{(x-\\mu)^2}{2\\sigma^2}\\right)$ is the PDF of a normal random variable.\n\nA signal processor computes the instantaneous power of the signal, which is proportional to the square of the voltage. We model this measured power as a new random variable $Y = X^2$.\n\nDetermine the PDF of $Y$, denoted $f_Y(y)$. Your final expression should be valid for $y > 0$ and expressed in terms of $y, p, \\mu_1, \\sigma_1, \\mu_2$, and $\\sigma_2$.", "solution": "We are asked to find the Probability Density Function (PDF) of $Y = X^2$, where $X$ is a random variable with a given mixture PDF $f_X(x)$. We can use the change of variable method. Since the transformation $g(x) = x^2$ is not monotonic for $x \\in (-\\infty, \\infty)$, we first find the Cumulative Distribution Function (CDF) of $Y$, denoted $F_Y(y)$.\n\nThe random variable $Y$ must be non-negative, since it is the square of a real random variable $X$. Therefore, $f_Y(y) = 0$ for $y  0$. For $y \\ge 0$, the CDF of $Y$ is given by:\n$$F_Y(y) = P(Y \\le y) = P(X^2 \\le y)$$\nThis inequality is equivalent to $-\\sqrt{y} \\le X \\le \\sqrt{y}$. Thus, we can express $F_Y(y)$ in terms of the CDF of $X$, $F_X(x)$:\n$$F_Y(y) = P(-\\sqrt{y} \\le X \\le \\sqrt{y}) = F_X(\\sqrt{y}) - F_X(-\\sqrt{y})$$\nTo find the PDF $f_Y(y)$, we differentiate the CDF $F_Y(y)$ with respect to $y$. Using the chain rule, where $F_X'(x) = f_X(x)$:\n$$f_Y(y) = \\frac{d}{dy}F_Y(y) = \\frac{d}{dy} \\left[ F_X(\\sqrt{y}) - F_X(-\\sqrt{y}) \\right]$$\n$$f_Y(y) = f_X(\\sqrt{y}) \\cdot \\frac{d}{dy}(\\sqrt{y}) - f_X(-\\sqrt{y}) \\cdot \\frac{d}{dy}(-\\sqrt{y})$$\n$$f_Y(y) = f_X(\\sqrt{y}) \\cdot \\frac{1}{2\\sqrt{y}} - f_X(-\\sqrt{y}) \\cdot \\left(-\\frac{1}{2\\sqrt{y}}\\right)$$\n$$f_Y(y) = \\frac{1}{2\\sqrt{y}} \\left[ f_X(\\sqrt{y}) + f_X(-\\sqrt{y}) \\right] \\quad \\text{for } y > 0$$\nNow we substitute the given mixture PDF for $f_X(x)$:\n$$f_X(x) = p\\cdot\\phi(x; \\mu_1, \\sigma_1^2) + (1-p)\\cdot\\phi(x; \\mu_2, \\sigma_2^2)$$\nSo, $f_Y(y)$ becomes:\n$$f_Y(y) = \\frac{1}{2\\sqrt{y}} \\left[ \\left(p\\phi(\\sqrt{y}; \\mu_1, \\sigma_1^2) + (1-p)\\phi(\\sqrt{y}; \\mu_2, \\sigma_2^2)\\right) + \\left(p\\phi(-\\sqrt{y}; \\mu_1, \\sigma_1^2) + (1-p)\\phi(-\\sqrt{y}; \\mu_2, \\sigma_2^2)\\right) \\right]$$\nWe can group the terms by the probabilities $p$ and $1-p$:\n$$f_Y(y) = p \\left[ \\frac{\\phi(\\sqrt{y}; \\mu_1, \\sigma_1^2) + \\phi(-\\sqrt{y}; \\mu_1, \\sigma_1^2)}{2\\sqrt{y}} \\right] + (1-p) \\left[ \\frac{\\phi(\\sqrt{y}; \\mu_2, \\sigma_2^2) + \\phi(-\\sqrt{y}; \\mu_2, \\sigma_2^2)}{2\\sqrt{y}} \\right]$$\nThis shows that the PDF of $Y$ is a mixture of the PDFs corresponding to the square of each individual normal component. Let's analyze one of these components, for a general normal distribution $X \\sim N(\\mu, \\sigma^2)$. The term in the bracket is:\n$$\\frac{1}{2\\sqrt{y}} \\left[\\phi(\\sqrt{y}; \\mu, \\sigma^2) + \\phi(-\\sqrt{y}; \\mu, \\sigma^2)\\right]$$\nSubstituting the formula for $\\phi(x; \\mu, \\sigma^2) = \\frac{1}{\\sigma\\sqrt{2\\pi}} \\exp\\left(-\\frac{(x-\\mu)^2}{2\\sigma^2}\\right)$:\n$$ \\frac{1}{2\\sqrt{y} \\cdot \\sigma\\sqrt{2\\pi}} \\left[ \\exp\\left(-\\frac{(\\sqrt{y}-\\mu)^2}{2\\sigma^2}\\right) + \\exp\\left(-\\frac{(-\\sqrt{y}-\\mu)^2}{2\\sigma^2}\\right) \\right]$$\nExpanding the squares in the exponents:\n$$(\\sqrt{y}-\\mu)^2 = y - 2\\mu\\sqrt{y} + \\mu^2$$\n$$(-\\sqrt{y}-\\mu)^2 = (\\sqrt{y}+\\mu)^2 = y + 2\\mu\\sqrt{y} + \\mu^2$$\nSubstituting these back:\n$$ \\frac{1}{2\\sigma\\sqrt{2\\pi y}} \\left[ \\exp\\left(-\\frac{y - 2\\mu\\sqrt{y} + \\mu^2}{2\\sigma^2}\\right) + \\exp\\left(-\\frac{y + 2\\mu\\sqrt{y} + \\mu^2}{2\\sigma^2}\\right) \\right]$$\nFactor out the common term $\\exp\\left(-\\frac{y+\\mu^2}{2\\sigma^2}\\right)$:\n$$ \\frac{1}{2\\sigma\\sqrt{2\\pi y}} \\exp\\left(-\\frac{y+\\mu^2}{2\\sigma^2}\\right) \\left[ \\exp\\left(\\frac{2\\mu\\sqrt{y}}{2\\sigma^2}\\right) + \\exp\\left(-\\frac{2\\mu\\sqrt{y}}{2\\sigma^2}\\right) \\right]$$\n$$ \\frac{1}{2\\sigma\\sqrt{2\\pi y}} \\exp\\left(-\\frac{y+\\mu^2}{2\\sigma^2}\\right) \\left[ \\exp\\left(\\frac{\\mu\\sqrt{y}}{\\sigma^2}\\right) + \\exp\\left(-\\frac{\\mu\\sqrt{y}}{\\sigma^2}\\right) \\right]$$\nUsing the definition of the hyperbolic cosine function, $\\cosh(z) = \\frac{\\exp(z) + \\exp(-z)}{2}$, the term in the brackets is $2\\cosh\\left(\\frac{\\mu\\sqrt{y}}{\\sigma^2}\\right)$.\n$$ \\frac{1}{2\\sigma\\sqrt{2\\pi y}} \\exp\\left(-\\frac{y+\\mu^2}{2\\sigma^2}\\right) \\cdot 2\\cosh\\left(\\frac{\\mu\\sqrt{y}}{\\sigma^2}\\right) = \\frac{1}{\\sigma\\sqrt{2\\pi y}} \\exp\\left(-\\frac{y+\\mu^2}{2\\sigma^2}\\right) \\cosh\\left(\\frac{\\mu\\sqrt{y}}{\\sigma^2}\\right)$$\nThis is the PDF for the square of a single normal random variable. Now we apply this result to both components of our mixture distribution for $f_Y(y)$:\nThe first component (with probability $p$) uses $\\mu_1$ and $\\sigma_1$.\nThe second component (with probability $1-p$) uses $\\mu_2$ and $\\sigma_2$.\nCombining them, we get the final expression for $f_Y(y)$ for $y>0$:\n$$ f_Y(y) = p \\left[ \\frac{1}{\\sigma_1\\sqrt{2\\pi y}} \\exp\\left(-\\frac{y+\\mu_1^2}{2\\sigma_1^2}\\right) \\cosh\\left(\\frac{\\mu_1\\sqrt{y}}{\\sigma_1^2}\\right) \\right] + (1-p) \\left[ \\frac{1}{\\sigma_2\\sqrt{2\\pi y}} \\exp\\left(-\\frac{y+\\mu_2^2}{2\\sigma_2^2}\\right) \\cosh\\left(\\frac{\\mu_2\\sqrt{y}}{\\sigma_2^2}\\right) \\right]$$\nThis can be written more compactly by factoring out the common term $1/\\sqrt{2\\pi y}$:\n$$ f_Y(y) = \\frac{1}{\\sqrt{2\\pi y}} \\left[ \\frac{p}{\\sigma_1} \\exp\\left(-\\frac{y+\\mu_1^2}{2\\sigma_1^2}\\right) \\cosh\\left(\\frac{\\mu_1\\sqrt{y}}{\\sigma_1^2}\\right) + \\frac{1-p}{\\sigma_2} \\exp\\left(-\\frac{y+\\mu_2^2}{2\\sigma_2^2}\\right) \\cosh\\left(\\frac{\\mu_2\\sqrt{y}}{\\sigma_2^2}\\right) \\right]$$", "answer": "$$\\boxed{\\frac{1}{\\sqrt{2\\pi y}} \\left[ \\frac{p}{\\sigma_1} \\exp\\left(-\\frac{y+\\mu_1^2}{2\\sigma_1^2}\\right) \\cosh\\left(\\frac{\\mu_1\\sqrt{y}}{\\sigma_1^2}\\right) + \\frac{1-p}{\\sigma_2} \\exp\\left(-\\frac{y+\\mu_2^2}{2\\sigma_2^2}\\right) \\cosh\\left(\\frac{\\mu_2\\sqrt{y}}{\\sigma_2^2}\\right) \\right]}$$", "id": "1356802"}]}