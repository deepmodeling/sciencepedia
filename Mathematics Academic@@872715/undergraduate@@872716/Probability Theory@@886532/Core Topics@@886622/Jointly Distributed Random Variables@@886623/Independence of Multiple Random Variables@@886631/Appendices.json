{"hands_on_practices": [{"introduction": "This first exercise demonstrates the most fundamental property of independent random variables. When multiple events are independent, the probability of them all occurring is simply the product of their individual probabilities. This problem [@problem_id:1365230] applies this core principle to a practical scenario in reliability engineering, calculating the survival probability of a system with redundant components.", "problem": "A critical navigation system for an interplanetary satellite is built with three identical, independent microcomputers. The operational lifetime of each microcomputer, measured in years, is modeled by an exponential random variable with a rate parameter of $\\lambda = 0.5$ per year. For mission success, it is highly desirable that the system maintains full redundancy for a significant duration. Calculate the probability that all three microcomputers are still functional after an operational period of 4 years.\n\nExpress your answer as a closed-form analytic expression.", "solution": "Let $T_{i}$ denote the operational lifetime of microcomputer $i$ for $i \\in \\{1,2,3\\}$. Each $T_{i}$ is exponentially distributed with rate $\\lambda=0.5$ per year. For an exponential random variable with rate $\\lambda$, the survival function is\n$$\n\\mathbb{P}(T_{i}t)=\\exp(-\\lambda t).\n$$\nAt $t=4$ years, the probability that one microcomputer is still functional is\n$$\n\\mathbb{P}(T_{i}4)=\\exp(-\\lambda \\cdot 4).\n$$\nBecause the three lifetimes are independent, the probability that all three are still functional after 4 years is the product of the individual survival probabilities:\n$$\n\\mathbb{P}(T_{1}4,\\,T_{2}4,\\,T_{3}4)=\\prod_{i=1}^{3}\\mathbb{P}(T_{i}4)=\\left[\\exp(-\\lambda \\cdot 4)\\right]^{3}=\\exp(-3\\lambda \\cdot 4).\n$$\nSubstituting $\\lambda=0.5$ yields\n$$\n\\exp(-3\\lambda \\cdot 4)=\\exp(-12 \\cdot 0.5)=\\exp(-6).\n$$\nThus, the closed-form probability that all three microcomputers are still functional after 4 years is $\\exp(-6)$.", "answer": "$$\\boxed{\\exp(-6)}$$", "id": "1365230"}, {"introduction": "Building on the concept of independence, this next problem explores a fascinating consequence when variables are also identically distributed (i.i.d.). We are asked to find the probability of a specific ordering among the random variables [@problem_id:1365242]. This scenario allows us to leverage powerful symmetry arguments, providing an elegant shortcut that bypasses complex integration and deepens our intuition for i.i.d. processes.", "problem": "Three independent servers, designated as Server A, Server B, and Server C, are programmed to perform a daily maintenance check at a random time within a specific one-hour window, which we can normalize to the interval $[0, 1]$. The exact time each server starts its check is modeled as an independent random variable, uniformly distributed on $[0, 1]$. Let $T_A$, $T_B$, and $T_C$ be the random variables representing the start times of the maintenance checks for Server A, Server B, and Server C, respectively.\n\nCalculate the probability that Server A starts its check first, Server B starts second, and Server C starts last. Express your answer as an exact fraction.", "solution": "Let $T_{A}, T_{B}, T_{C}$ be independent and identically distributed as $\\mathrm{Uniform}(0,1)$. The joint probability density function is\n$$\nf_{T_{A},T_{B},T_{C}}(t_{A},t_{B},t_{C})=\n\\begin{cases}\n1,  (t_{A},t_{B},t_{C}) \\in [0,1]^{3},\\\\\n0,  \\text{otherwise}.\n\\end{cases}\n$$\nWe want to find $\\mathbb{P}(T_{A}T_{B}T_{C})$, which by definition of probability for continuous random variables equals the volume of the region $\\{(t_{A},t_{B},t_{C}) \\in [0,1]^{3} : t_{A}t_{B}t_{C}\\}$ under the constant density $1$:\n$$\n\\mathbb{P}(T_{A}T_{B}T_{C})=\\int_{0}^{1}\\int_{0}^{t_C}\\int_{0}^{t_B} 1 \\, dt_A \\, dt_B \\, dt_C.\n$$\nCompute the integrals step by step:\n$$\n\\int_{0}^{t_B} 1 \\, dt_A = t_B,\n$$\n$$\n\\int_{0}^{t_C} t_B \\, dt_B = \\frac{t_C^{2}}{2},\n$$\n$$\n\\int_{0}^{1} \\frac{t_C^{2}}{2} \\, dt_C = \\frac{1}{2}\\cdot \\frac{1}{3} = \\frac{1}{6}.\n$$\nTherefore,\n$$\n\\mathbb{P}(T_{A}T_{B}T_{C})=\\frac{1}{6}.\n$$\nEquivalently, by symmetry of i.i.d. continuous variables, all $3!$ orderings are equally likely, so each has probability $\\frac{1}{3!}=\\frac{1}{6}$.", "answer": "$$\\boxed{\\frac{1}{6}}$$", "id": "1365242"}, {"introduction": "It is a common pitfall to assume that functions of independent variables are themselves independent. This final practice [@problem_id:1365233] serves as a crucial counterexample, demonstrating how simple, intuitive transformations like creating cumulative sums can introduce statistical dependence. We will use the concept of covariance to rigorously show that the resulting variables are not independent, reinforcing the need for careful verification.", "problem": "In a digital signal processing model, three sources of interference are modeled as independent random variables $X_1, X_2,$ and $X_3$. Each of these variables follows a continuous uniform distribution on the interval $[0, \\theta]$, where $\\theta$ is a known positive parameter representing the maximum interference amplitude.\n\nTo analyze the cumulative effect of this interference, a sequence of three new random variables, $U, V,$ and $W$, are constructed as follows:\n- $U = X_1$\n- $V = X_1 + X_2$\n- $W = X_1 + X_2 + X_3$\n\nDetermine which of the following statements correctly describes the statistical relationship between $U, V,$ and $W$.\n\nA. The variables $U, V,$ and $W$ are mutually independent.\n\nB. The variables $U$ and $V$ are independent, but the triplet $\\{U, V, W\\}$ is not mutually independent.\n\nC. The variables $V$ and $W$ are independent, but the triplet $\\{U, V, W\\}$ is not mutually independent.\n\nD. No pair of variables from the set $\\{U, V, W\\}$ (i.e., $(U,V)$, $(U,W)$, and $(V,W)$) is independent.\n\nE. The triplet $\\{U, V, W\\}$ is not mutually independent, but at least one pair selected from $\\{U, V, W\\}$ is independent.", "solution": "Let $X_{1}, X_{2}, X_{3}$ be independent and each uniformly distributed on $[0,\\theta]$ with $\\theta0$. Define $U=X_{1}$, $V=X_{1}+X_{2}$, and $W=X_{1}+X_{2}+X_{3}$. We use the fact that if two random variables are independent and have finite second moments, then their covariance is zero. Therefore, if we find a pair with nonzero covariance, that pair is not independent. The covariance is defined by\n$$\n\\text{Cov}(A,B)=\\mathbb{E}[AB]-\\mathbb{E}[A]\\mathbb{E}[B].\n$$\n\nFirst, consider $U$ and $V$. Compute\n$$\n\\text{Cov}(U,V)=\\text{Cov}(X_{1},X_{1}+X_{2})=\\text{Cov}(X_{1},X_{1})+\\text{Cov}(X_{1},X_{2}).\n$$\nSince $X_{1}$ and $X_{2}$ are independent, $\\text{Cov}(X_{1},X_{2})=0$, and $\\text{Cov}(X_{1},X_{1})=\\text{Var}(X_{1})$. Hence\n$$\n\\text{Cov}(U,V)=\\text{Var}(X_{1}).\n$$\nBecause $X_{1}$ is non-degenerate uniform on $[0,\\theta]$ with $\\theta0$, $\\text{Var}(X_{1})0$. Thus $\\text{Cov}(U,V)\\neq 0$, so $U$ and $V$ are not independent.\n\nNext, consider $U$ and $W$. Compute\n$$\n\\text{Cov}(U,W)=\\text{Cov}(X_{1},X_{1}+X_{2}+X_{3})=\\text{Cov}(X_{1},X_{1})+\\text{Cov}(X_{1},X_{2})+\\text{Cov}(X_{1},X_{3}).\n$$\nBy independence, $\\text{Cov}(X_{1},X_{2})=\\text{Cov}(X_{1},X_{3})=0$, so\n$$\n\\text{Cov}(U,W)=\\text{Var}(X_{1})0.\n$$\nThus $U$ and $W$ are not independent.\n\nFinally, consider $V$ and $W$. Compute\n$$\n\\text{Cov}(V,W)=\\text{Cov}(X_{1}+X_{2},X_{1}+X_{2}+X_{3})=\\text{Cov}(X_{1}+X_{2},X_{1}+X_{2})+\\text{Cov}(X_{1}+X_{2},X_{3}).\n$$\nIndependence gives $\\text{Cov}(X_{1}+X_{2},X_{3})=0$, and\n$$\n\\text{Cov}(X_{1}+X_{2},X_{1}+X_{2})=\\text{Var}(X_{1}+X_{2})=\\text{Var}(X_{1})+\\text{Var}(X_{2}),\n$$\nagain using independence. Therefore\n$$\n\\text{Cov}(V,W)=\\text{Var}(X_{1})+\\text{Var}(X_{2})0.\n$$\nHence $V$ and $W$ are not independent.\n\nWe have shown that every pair among $\\{U,V,W\\}$ has strictly positive covariance, therefore no pair is independent. Consequently, the triplet is not mutually independent. The correct choice is that no pair is independent.", "answer": "$$\\boxed{D}$$", "id": "1365233"}]}