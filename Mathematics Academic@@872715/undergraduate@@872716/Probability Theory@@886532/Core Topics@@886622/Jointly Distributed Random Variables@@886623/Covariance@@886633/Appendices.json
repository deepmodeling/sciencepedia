{"hands_on_practices": [{"introduction": "This first practice focuses on the powerful algebraic properties of covariance. Instead of computing expectations from scratch, we can often find elegant solutions by treating covariance as a bilinear operator. This exercise demonstrates how to manipulate sums and differences of random variables to find their covariance, a fundamental skill in statistical modeling and analysis. [@problem_id:1354332]", "problem": "In a communication system, two independent signals are received. Let the power of the first signal be represented by a random variable $X$ and the power of the second signal be represented by a random variable $Y$. It is known that $X$ and $Y$ are independent. The variance of the first signal's power is given as $\\text{Var}(X) = \\sigma_X^2$, and the variance of the second signal's power is given as $\\text{Var}(Y) = \\sigma_Y^2$.\n\nAn engineer is analyzing two new metrics derived from these signals: the total power, defined as $S = X + Y$, and the power difference, defined as $D = X - Y$.\n\nDetermine the covariance between the total power $S$ and the power difference $D$. Express your answer as a closed-form analytic expression in terms of $\\sigma_X^2$ and $\\sigma_Y^2$.", "solution": "We are given two random variables $X$ and $Y$ representing powers of two independent signals, with variances $\\text{Var}(X)=\\sigma_{X}^{2}$ and $\\text{Var}(Y)=\\sigma_{Y}^{2}$. Define $S=X+Y$ and $D=X-Y$. We seek $\\text{Cov}(S,D)$.\n\nBy the bilinearity of covariance, namely $\\text{Cov}(U+V,W)=\\text{Cov}(U,W)+\\text{Cov}(V,W)$ and $\\text{Cov}(U,aV)=a\\,\\text{Cov}(U,V)$ for any constant $a$, we write\n$$\n\\text{Cov}(S,D)=\\text{Cov}(X+Y,\\,X-Y)\n=\\text{Cov}(X,X)+\\text{Cov}(X,-Y)+\\text{Cov}(Y,X)+\\text{Cov}(Y,-Y).\n$$\nUsing $\\text{Cov}(U,U)=\\text{Var}(U)$ and $\\text{Cov}(U,-V)=-\\text{Cov}(U,V)$, we obtain\n$$\n\\text{Cov}(S,D)=\\text{Var}(X)-\\text{Cov}(X,Y)+\\text{Cov}(Y,X)-\\text{Var}(Y).\n$$\nSince $\\text{Cov}(X,Y)=\\text{Cov}(Y,X)$, the cross terms cancel:\n$$\n\\text{Cov}(S,D)=\\text{Var}(X)-\\text{Var}(Y)=\\sigma_{X}^{2}-\\sigma_{Y}^{2}.\n$$\nIndependence of $X$ and $Y$ implies $\\text{Cov}(X,Y)=0$, though in this derivation the cross terms already cancel, leaving the same result.", "answer": "$$\\boxed{\\sigma_{X}^{2}-\\sigma_{Y}^{2}}$$", "id": "1354332"}, {"introduction": "Moving from abstract properties to concrete calculations, this problem challenges you to compute covariance from its fundamental definition, $\\text{Cov}(X,Y) = \\mathbb{E}[XY] - \\mathbb{E}[X]\\mathbb{E}[Y]$. You will work with a joint probability density function defined over a geometric region. This exercise is essential for building intuition on how the geometry of the sample space influences the relationship between random variables. [@problem_id:1911471]", "problem": "Let $X$ and $Y$ be two continuous random variables. A point $(X, Y)$ is selected uniformly at random from a triangular region in the Cartesian plane. The vertices of this triangle are located at the coordinates $(0, 0)$, $(1, 0)$, and $(1, 1)$.\n\nDetermine the value of the covariance between $X$ and $Y$, denoted as $Cov(X, Y)$. Your final answer should be a single closed-form analytic expression.", "solution": "The triangular region with vertices at $(0,0)$, $(1,0)$, and $(1,1)$ is described by the set $D=\\{(x,y): 0 \\leq x \\leq 1,\\ 0 \\leq y \\leq x\\}$. Its area is\n$$\n|D|=\\frac{1}{2}.\n$$\nFor a uniform selection over $D$, the joint density is constant on $D$ and equals\n$$\nf_{X,Y}(x,y)=\\frac{1}{|D|}=2 \\quad \\text{for } (x,y)\\in D, \\text{ and } 0 \\text{ otherwise}.\n$$\nWe use the definition of covariance,\n$$\n\\operatorname{Cov}(X,Y)=\\operatorname{E}[XY]-\\operatorname{E}[X]\\operatorname{E}[Y].\n$$\nFirst compute $\\operatorname{E}[X]$:\n$$\n\\operatorname{E}[X]=\\iint_{D} x f_{X,Y}(x,y)\\,dx\\,dy\n=2\\int_{0}^{1}\\int_{0}^{x} x \\, dy \\, dx\n=2\\int_{0}^{1} x\\left[y\\right]_{0}^{x} dx\n=2\\int_{0}^{1} x^{2}\\,dx\n=\\frac{2}{3}.\n$$\nNext compute $\\operatorname{E}[Y]$:\n$$\n\\operatorname{E}[Y]=\\iint_{D} y f_{X,Y}(x,y)\\,dx\\,dy\n=2\\int_{0}^{1}\\int_{0}^{x} y \\, dy \\, dx\n=2\\int_{0}^{1} \\frac{x^{2}}{2}\\,dx\n=\\int_{0}^{1} x^{2}\\,dx\n=\\frac{1}{3}.\n$$\nNow compute $\\operatorname{E}[XY]$:\n$$\n\\operatorname{E}[XY]=\\iint_{D} xy \\, f_{X,Y}(x,y)\\,dx\\,dy\n=2\\int_{0}^{1}\\int_{0}^{x} xy \\, dy \\, dx\n=2\\int_{0}^{1} x \\left[\\frac{y^{2}}{2}\\right]_{0}^{x} dx\n=2\\int_{0}^{1} x \\cdot \\frac{x^{2}}{2}\\,dx\n=\\int_{0}^{1} x^{3}\\,dx\n=\\frac{1}{4}.\n$$\nSubstitute into the covariance formula:\n$$\n\\operatorname{Cov}(X,Y)=\\frac{1}{4}-\\left(\\frac{2}{3}\\right)\\left(\\frac{1}{3}\\right)=\\frac{1}{4}-\\frac{2}{9}=\\frac{9-8}{36}=\\frac{1}{36}.\n$$", "answer": "$$\\boxed{\\frac{1}{36}}$$", "id": "1911471"}, {"introduction": "Our final practice explores a crucial and often misunderstood aspect of covariance: a value of zero does not necessarily imply independence. This exercise presents a scenario where one random variable is a direct function of another, yet their covariance is zero. Solving this problem will deepen your understanding that covariance measures only the *linear* component of dependence between two variables. [@problem_id:1354397]", "problem": "An engineer is analyzing the thermal noise in a sensitive electronic component. The noise voltage, after being normalized, is modeled as a continuous random variable $X$. The Probability Density Function (PDF) of $X$ is found to be a triangular distribution given by:\n$$\nf_X(x) = \\begin{cases}\n    C(a - |x|)  \\text{for } |x| \\le a \\\\\n    0  \\text{otherwise}\n\\end{cases}\n$$\nwhere $a$ is a positive constant representing the maximum magnitude of the normalized noise, and $C$ is a normalization constant. The instantaneous power dissipated by the noise is proportional to the square of the voltage. The engineer models this normalized power as another random variable $Y = X^2$.\n\nTo understand the linear relationship between the noise voltage and the power it dissipates, the engineer needs to determine their covariance. Calculate the covariance, $\\text{Cov}(X, Y)$. Your final answer should be a numerical value.", "solution": "We are given that $X$ has the probability density function\n$$\nf_{X}(x)=\\begin{cases}\nC\\left(a-|x|\\right)  \\text{for }|x|\\leq a,\\\\\n0  \\text{otherwise},\n\\end{cases}\n$$\nwith $a>0$ and $C$ chosen so that $f_{X}$ integrates to one, and $Y=X^{2}$. We are asked for $\\text{Cov}(X,Y)$, where by definition\n$$\n\\text{Cov}(X,Y)=\\mathbb{E}[XY]-\\mathbb{E}[X]\\mathbb{E}[Y].\n$$\nSince $Y=X^{2}$, this becomes\n$$\n\\text{Cov}(X,Y)=\\mathbb{E}[X^{3}]-\\mathbb{E}[X]\\mathbb{E}[X^{2}].\n$$\n\nFirst, determine the normalization constant $C$ by enforcing $\\int_{-\\!a}^{a}f_{X}(x)\\,dx=1$:\n$$\n\\int_{-\\!a}^{a}C\\left(a-|x|\\right)\\,dx\n=2C\\int_{0}^{a}\\left(a-x\\right)\\,dx\n=2C\\left[a x-\\frac{x^{2}}{2}\\right]_{0}^{a}\n=2C\\left(a^{2}-\\frac{a^{2}}{2}\\right)\n=2C\\left(\\frac{a^{2}}{2}\\right)\n=C a^{2}.\n$$\nThus $C a^{2}=1$, so\n$$\nC=\\frac{1}{a^{2}}.\n$$\n\nNext, observe that $f_{X}(x)$ is an even function because $f_{X}(-x)=C\\left(a-|-x|\\right)=C\\left(a-|x|\\right)=f_{X}(x)$. Therefore all odd moments of $X$ that exist are zero. In particular,\n$$\n\\mathbb{E}[X]=\\int_{-\\!a}^{a}x\\,f_{X}(x)\\,dx=0, \\qquad \\mathbb{E}[X^{3}]=\\int_{-\\!a}^{a}x^{3}\\,f_{X}(x)\\,dx=0,\n$$\nsince each integrand is an odd function multiplied by an even function, yielding an overall odd integrand integrated over the symmetric interval $[-a,a]$.\n\nFor completeness, one may verify that $\\mathbb{E}[X^{2}]$ is finite:\n$$\n\\mathbb{E}[X^{2}]\n=\\int_{-\\!a}^{a}x^{2}f_{X}(x)\\,dx\n=2\\int_{0}^{a}x^{2}\\,C\\left(a-x\\right)\\,dx\n=2C\\left[\\int_{0}^{a}a x^{2}\\,dx-\\int_{0}^{a}x^{3}\\,dx\\right]\n=2C\\left(\\frac{a^{4}}{3}-\\frac{a^{4}}{4}\\right)\n=2C\\left(\\frac{a^{4}}{12}\\right)\n=\\frac{C a^{4}}{6}\n=\\frac{a^{2}}{6},\n$$\nusing $C=1/a^{2}$. This value is not needed for the covariance once $\\mathbb{E}[X]=0$ is established.\n\nTherefore,\n$$\n\\text{Cov}(X,Y)=\\mathbb{E}[X^{3}]-\\mathbb{E}[X]\\mathbb{E}[X^{2}]=0-0\\cdot \\mathbb{E}[X^{2}]=0.\n$$", "answer": "$$\\boxed{0}$$", "id": "1354397"}]}