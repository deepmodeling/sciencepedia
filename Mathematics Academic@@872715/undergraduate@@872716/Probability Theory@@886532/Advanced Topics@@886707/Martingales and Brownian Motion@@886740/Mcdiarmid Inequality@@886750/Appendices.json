{"hands_on_practices": [{"introduction": "McDiarmid's inequality is exceptionally useful for analyzing properties of random graphs. This exercise explores the number of 'source' vertices in a random directed graph, a fundamental structural property. By considering each potential edge as an independent random variable, you will practice applying the bounded differences method to a global graph statistic, providing a sharp concentration bound around its expected value [@problem_id:1372535].", "problem": "Consider a random directed graph, denoted as $D(n, p)$, constructed on a set of $n$ vertices labeled $\\{1, 2, \\dots, n\\}$. For every ordered pair of distinct vertices $(i, j)$ where $i \\neq j$, a directed edge from $i$ to $j$ is included in the graph with a probability $p \\in (0, 1)$, independently of all other edges.\n\nA vertex is defined as a \"source vertex\" if its in-degree is zero, meaning there are no directed edges pointing towards it. Let $X$ be the random variable representing the total number of source vertices in a randomly generated instance of $D(n, p)$.\n\nYour task is to derive a general upper bound for the probability that the number of source vertices, $X$, deviates from its expected value, $\\mathbb{E}[X]$, by at least a positive amount $t$. The final expression for this probability bound must be a closed-form analytic expression in terms of the number of vertices, $n$, and the deviation, $t$.", "solution": "Let the directed edges be represented by independent Bernoulli random variables $\\{Y_{ij}\\}_{i \\neq j}$ where $Y_{ij}=1$ if the edge $i \\to j$ is present and $Y_{ij}=0$ otherwise, each with parameter $p$. There are $m=n(n-1)$ such variables. For each vertex $v \\in \\{1,\\dots,n\\}$, define the indicator\n$$\nI_{v}=\\mathbf{1}\\{\\text{$v$ has in-degree }0\\}=\\prod_{u \\neq v}\\mathbf{1}\\{Y_{uv}=0\\}.\n$$\nThe total number of source vertices is\n$$\nX=\\sum_{v=1}^{n} I_{v}.\n$$\nBy independence of incoming edges to a fixed $v$, we have\n$$\n\\mathbb{E}[I_{v}]=\\prod_{u \\neq v}\\mathbb{P}(Y_{uv}=0)=(1-p)^{n-1},\n$$\nso linearity of expectation gives\n$$\n\\mathbb{E}[X]=\\sum_{v=1}^{n}\\mathbb{E}[I_{v}]=n(1-p)^{n-1}.\n$$\n\nWe now derive a concentration bound for $X$ around $\\mathbb{E}[X]$ using McDiarmid's bounded differences inequality. View $X$ as a function $f$ of the independent variables $\\{Y_{ij}\\}_{i \\neq j}$:\n$$\nX=f\\big(\\{Y_{ij}\\}_{i \\neq j}\\big).\n$$\nIf two edge configurations differ only in a single coordinate $Y_{ij}$, then only the in-degree of vertex $j$ can change, and hence only $I_{j}$ can change. Therefore the value of $X$ can change by at most $1$:\n$$\n|f(\\dots,Y_{ij},\\dots)-f(\\dots,Y_{ij}',\\dots)| \\leq 1 \\quad \\text{for all } i \\neq j.\n$$\nThus each coordinate has Lipschitz constant $c_{ij}=1$, and\n$$\n\\sum_{i \\neq j} c_{ij}^{2}=\\sum_{i \\neq j} 1^{2}=n(n-1)=m.\n$$\nBy McDiarmid's inequality, for all $t>0$,\n$$\n\\mathbb{P}\\big(|X-\\mathbb{E}[X]|\\geq t\\big) \\leq 2 \\exp\\!\\left(-\\frac{2t^{2}}{\\sum_{i \\neq j} c_{ij}^{2}}\\right)\n= 2 \\exp\\!\\left(-\\frac{2t^{2}}{n(n-1)}\\right).\n$$\nThis yields a closed-form upper bound in terms of $n$ and $t$, independent of $p$.", "answer": "$$\\boxed{2\\,\\exp\\!\\left(-\\frac{2t^{2}}{n(n-1)}\\right)}$$", "id": "1372535"}, {"introduction": "Moving beyond simple counting, McDiarmid's inequality demonstrates its power in the realm of stochastic optimization. This problem tackles the famous Traveling Salesperson Problem (TSP) where city locations are random, a model with deep connections to logistics and circuit design. You will learn to establish the bounded difference property for a complex function—the optimal tour length—using a clever geometric argument, revealing the remarkable stability of the solution [@problem_id:1372547].", "problem": "In the field of stochastic optimization, we are interested in the stability of solutions to problems with random inputs. Consider the Traveling Salesperson Problem (TSP) for a set of $n$ points, $X_1, X_2, \\dots, X_n$, chosen independently and uniformly at random from the unit square $[0, 1]^2$. Let $L_n = f(X_1, \\dots, X_n)$ be the length of the shortest possible tour that visits every point and returns to the origin. The value of $L_n$ is a random variable, and we wish to understand how much it can deviate from its expected value, $E[L_n]$.\n\nMcDiarmid's inequality provides a powerful tool for this. It states that if a function $f(x_1, \\dots, x_n)$ of independent random variables satisfies the bounded differences property, such that for any $i \\in \\{1, \\dots, n\\}$ and any values $x_1, \\dots, x_n, x'_i$ in the domain,\n$$ |f(x_1, \\dots, x_i, \\dots, x_n) - f(x_1, \\dots, x'_i, \\dots, x_n)| \\le c_i $$\nthen for any $t  0$, the following concentration inequality holds:\n$$ P(|f(X_1, \\dots, X_n) - E[f(X_1, \\dots, X_n)]| \\ge t) \\le 2\\exp\\left(-\\frac{2t^2}{\\sum_{i=1}^n c_i^2}\\right) $$\n\nYour task is to apply this inequality to the TSP length $L_n$. Determine an upper bound for the probability $P(|L_n - E[L_n]| \\ge t)$. Your final answer should be an analytical expression in terms of $n$ and $t$.", "solution": "Let $L_{n}=f(X_{1},\\dots,X_{n})$ be the length of the optimal Euclidean TSP tour through the set $\\{X_{1},\\dots,X_{n}\\}$ and the fixed origin in $[0,1]^{2}$. The random variables $X_{1},\\dots,X_{n}$ are independent, satisfying the independence assumption of McDiarmid's inequality.\n\nTo verify the bounded differences property, fix $i\\in\\{1,\\dots,n\\}$ and configurations $(x_{1},\\dots,x_{n})$ and $(x_{1},\\dots,x'_{i},\\dots,x_{n})$. Let $L$ be the optimal tour length for $(x_{1},\\dots,x_{n})$, and let $T$ be an optimal tour achieving length $L$. In $T$, the point $x_{i}$ has two tour neighbors, say $A$ and $B$ (each is either one of the other $x_{j}$ or the origin). Consider the tour $T'$ for the modified instance $(x_{1},\\dots,x'_{i},\\dots,x_{n})$ that preserves all adjacencies of $T$ except replacing the edges $(A,x_{i})$ and $(x_{i},B)$ by $(A,x'_{i})$ and $(x'_{i},B)$. Then the change in length satisfies\n$$\n\\text{len}(T')-\\text{len}(T)\n=\\big(d(A,x'_{i})-d(A,x_{i})\\big)+\\big(d(B,x'_{i})-d(B,x_{i})\\big),\n$$\nwhere $d(\\cdot,\\cdot)$ is the Euclidean distance. By the reverse triangle inequality, for any points $a,p,q$,\n$$\n\\big|d(a,p)-d(a,q)\\big|\\le d(p,q).\n$$\nApplying this twice yields\n$$\n\\text{len}(T')-\\text{len}(T)\\le d(x_{i},x'_{i})+d(x_{i},x'_{i})=2\\,d(x_{i},x'_{i}).\n$$\nSince the optimal length $L'$ for $(x_{1},\\dots,x'_{i},\\dots,x_{n})$ is at most $\\text{len}(T')$, we get $L'-L\\le 2\\,d(x_{i},x'_{i})$. By symmetry (interchanging the roles of $x_{i}$ and $x'_{i}$), we also obtain $L-L'\\le 2\\,d(x_{i},x'_{i})$. Therefore,\n$$\n\\big|f(x_{1},\\dots,x_{i},\\dots,x_{n})-f(x_{1},\\dots,x'_{i},\\dots,x_{n})\\big|\\le 2\\,d(x_{i},x'_{i}).\n$$\nBecause all points lie in $[0,1]^{2}$, the maximum possible distance is $d(x_{i},x'_{i})\\le \\sqrt{2}$, hence we can take\n$$\nc_{i}=2\\sqrt{2}\\quad\\text{for all }i\\in\\{1,\\dots,n\\}.\n$$\nThus $\\sum_{i=1}^{n}c_{i}^{2}=n\\,(2\\sqrt{2})^{2}=8n$. McDiarmid's inequality then gives, for any $t0$,\n$$\nP\\big(\\,|L_{n}-E[L_{n}]|\\ge t\\,\\big)\\le 2\\exp\\!\\left(-\\frac{2t^{2}}{\\sum_{i=1}^{n}c_{i}^{2}}\\right)\n=2\\exp\\!\\left(-\\frac{2t^{2}}{8n}\\right)\n=2\\exp\\!\\left(-\\frac{t^{2}}{4n}\\right).\n$$\nThis is the desired upper bound expressed in terms of $n$ and $t$.", "answer": "$$\\boxed{2\\exp\\!\\left(-\\frac{t^{2}}{4n}\\right)}$$", "id": "1372547"}, {"introduction": "Concentration inequalities are not just theoretical tools; they are essential for practical risk management in engineering and computer science. This problem models a common scenario in cloud computing: allocating jobs of random sizes to servers using the First Fit algorithm. Here, you will use a given property of the algorithm to apply McDiarmid's inequality directly, translating it into a concrete safety margin for resource provisioning [@problem_id:1372522].", "problem": "A cloud computing provider must allocate a sequence of $n=5000$ incoming jobs to a set of identical servers. Each server has a standardized resource capacity of 1. The sizes of the jobs, denoted by $X_1, X_2, \\dots, X_n$, are unpredictable and are modeled as independent and identically distributed random variables drawn from a continuous Uniform distribution $U[0, c]$ with $c=0.8$.\n\nThe allocation is performed using the First Fit (FF) algorithm: each job is sequentially placed into the first server (in the order of servers $1, 2, 3, \\dots$) that has enough remaining capacity. If a job cannot fit into any of the currently active servers, a new server is provisioned and the job is placed there.\n\nLet $N_{bins}$ represent the total number of servers used to accommodate all $n$ jobs. It is a known result from the analysis of algorithms that for any set of job sizes, changing the size of a single job will change the total number of servers required by at most 1.\n\nTo ensure service reliability, the provider wants to determine a \"safety buffer\" of servers. Specifically, they need to find the smallest integer $k$ which guarantees that the number of servers required will not exceed its expected value by more than $k$, with a failure probability of no more than $\\delta = 10^{-6}$.\n\nBased on this model, find the smallest integer $k$ such that $P(N_{bins}  E[N_{bins}] + k) \\le \\delta$.", "solution": "Let $f(X_{1},\\dots,X_{n})$ denote the number of servers $N_{bins}$ used by First Fit on the job sizes. It is given that for any set of inputs, changing a single job size can change $N_{bins}$ by at most $1$. Therefore, for each coordinate $i$, the bounded differences constant is $c_{i}=1$.\n\nSince the $X_{i}$ are independent, McDiarmid’s inequality applies. With $\\sum_{i=1}^{n} c_{i}^{2}=n$, McDiarmid’s inequality gives, for any $t0$,\n$$\n\\Pr\\!\\left(N_{bins}-\\mathbb{E}[N_{bins}] \\ge t\\right) \\le \\exp\\!\\left(-\\frac{2t^{2}}{n}\\right).\n$$\nTo ensure $\\Pr\\!\\left(N_{bins}  \\mathbb{E}[N_{bins}] + k\\right) \\le \\delta$, it suffices to choose $k$ such that\n$$\n\\exp\\!\\left(-\\frac{2k^{2}}{n}\\right) \\le \\delta,\n$$\nwhich is equivalent to\n$$\nk \\ge \\sqrt{\\frac{n}{2}\\,\\ln\\!\\left(\\frac{1}{\\delta}\\right)}.\n$$\nThe smallest integer satisfying this is\n$$\nk=\\left\\lceil \\sqrt{\\frac{n}{2}\\,\\ln\\!\\left(\\frac{1}{\\delta}\\right)} \\right\\rceil.\n$$\nSubstituting $n=5000$ and $\\delta=10^{-6}$,\n$$\nk=\\left\\lceil \\sqrt{\\frac{5000}{2}\\,\\ln\\!\\left(10^{6}\\right)} \\right\\rceil\n=\\left\\lceil \\sqrt{2500 \\cdot 6 \\ln 10} \\right\\rceil\n=\\left\\lceil 50 \\sqrt{6 \\ln 10} \\right\\rceil.\n$$\nNumerically, $50 \\sqrt{6 \\ln 10} \\approx 185.846\\ldots$, hence the smallest integer is $k=186$.", "answer": "$$\\boxed{186}$$", "id": "1372522"}]}