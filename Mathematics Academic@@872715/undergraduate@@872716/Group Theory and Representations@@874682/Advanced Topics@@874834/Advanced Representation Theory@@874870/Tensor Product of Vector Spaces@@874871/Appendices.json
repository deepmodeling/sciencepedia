{"hands_on_practices": [{"introduction": "To begin, we'll ground the abstract definition of a tensor product in a concrete calculation. This first practice focuses on the fundamental mechanics of computing the tensor product of two vectors, $v \\otimes w$, and expressing the result in a standard basis. This process reveals how the tensor product can be viewed as an outer product of the vectors' coordinate arrays, yielding a matrix of coefficients that represents the new tensor [@problem_id:1087743].", "problem": "Consider the real vector spaces $\\mathbb{R}^2$ and $\\mathbb{R}^3$ equipped with their standard bases. Let $v = (2, -1) \\in \\mathbb{R}^2$ and $w = (3, 0, -2) \\in \\mathbb{R}^3$. The tensor product space $\\mathbb{R}^2 \\otimes \\mathbb{R}^3$ has a standard basis induced by the bases of $\\mathbb{R}^2$ and $\\mathbb{R}^3$, where each basis element is a simple tensor $e_i \\otimes f_j$ for $i \\in \\{1,2\\}$, $j \\in \\{1,2,3\\}$. Here, $e_1 = (1,0)$, $e_2 = (0,1)$ form the standard basis of $\\mathbb{R}^2$, and $f_1 = (1,0,0)$, $f_2 = (0,1,0)$, $f_3 = (0,0,1)$ form the standard basis of $\\mathbb{R}^3$.\n\nCompute the tensor product $v \\otimes w$ and express it as a linear combination of the basis elements $\\{e_i \\otimes f_j\\}$ by providing the coefficient matrix $A$ such that:\n\n$$\nv \\otimes w = \\sum_{i=1}^{2} \\sum_{j=1}^{3} A_{ij}  (e_i \\otimes f_j).\n$$\n\nThe matrix $A$ should be written explicitly in the row-major form where the $(i,j)$-th entry corresponds to the coefficient of $e_i \\otimes f_j$.", "solution": "In component form, given $v = (v_1, v_2)$ and $w = (w_1, w_2, w_3)$, the coefficient of $e_i \\otimes f_j$ in $v \\otimes w$ is $v_i w_j$. This follows from the universal property of tensor products and the choice of standard bases.\n\nGiven $v = (2, -1)$ and $w = (3, 0, -2)$, we identify:\n- $v_1 = 2$, $v_2 = -1$\n- $w_1 = 3$, $w_2 = 0$, $w_3 = -2$\n\nThe coefficient matrix $A$ has entries $A_{ij} = v_i w_j$:\n- $A_{11} = v_1 w_1 = 2 \\cdot 3 = 6$\n- $A_{12} = v_1 w_2 = 2 \\cdot 0 = 0$\n- $A_{13} = v_1 w_3 = 2 \\cdot (-2) = -4$\n- $A_{21} = v_2 w_1 = (-1) \\cdot 3 = -3$\n- $A_{22} = v_2 w_2 = (-1) \\cdot 0 = 0$\n- $A_{23} = v_2 w_3 = (-1) \\cdot (-2) = 2$\n\nThus, the matrix $A$ is:\n\n$$\nA = \\begin{pmatrix}\nA_{11} & A_{12} & A_{13} \\\\\nA_{21} & A_{22} & A_{23}\n\\end{pmatrix} = \\begin{pmatrix}\n6 & 0 & -4 \\\\\n-3 & 0 & 2\n\\end{pmatrix}\n$$\n\nThis matrix represents $v \\otimes w$ in the standard basis $\\{e_i \\otimes f_j\\}$ of $\\mathbb{R}^2 \\otimes \\mathbb{R}^3$.", "answer": "The coefficient matrix for $v \\otimes w$ in the standard basis is:\n$$\n\\boxed{\\begin{pmatrix} 6 & 0 & -4 \\\\ -3 & 0 & 2 \\end{pmatrix}}\n$$", "id": "1087743"}, {"introduction": "Not every element in a tensor product space $V \\otimes W$ can be written as a simple product $v \\otimes w$; most are sums of such terms. This exercise tackles the crucial question of how to determine if a general tensor is 'simple' (or 'decomposable'), introducing a powerful criterion based on the rank of its coefficient matrix [@problem_id:1645203]. This distinction is fundamental, especially in quantum mechanics where it separates pure states from entangled states.", "problem": "Let $V$ be a vector space over the field of complex numbers, $\\mathbb{C}$, and let $i$ be the imaginary unit such that $i^2 = -1$. The tensor product of $V$ with itself is denoted by $V \\otimes V$. An element of $V \\otimes V$ is called a simple tensor (or a decomposable tensor) if it can be written in the form $u \\otimes w$ for some vectors $u, w \\in V$.\n\nLet $\\{v_1, v_2\\}$ be a set of two linearly independent vectors in $V$. Consider the tensor $T \\in V \\otimes V$ defined as:\n$$T = (2+i) v_1 \\otimes v_1 + v_1 \\otimes v_2 + \\alpha v_2 \\otimes v_1 - 3i v_2 \\otimes v_2$$\nDetermine the value of the scalar $\\alpha \\in \\mathbb{C}$ for which the tensor $T$ is a simple tensor. Select the correct option from the choices below.\n\nA. $3 + 6i$\n\nB. $3 - 6i$\n\nC. $-3 + 6i$\n\nD. $-3 - 6i$\n\nE. $1 - 5i$", "solution": "A tensor $T \\in V \\otimes V$ is simple if and only if there exist $u, w \\in V$ such that $T = u \\otimes w$. Since $v_1, v_2$ are linearly independent, we write $u = a v_1 + b v_2$ and $w = c v_1 + d v_2$ with $a, b, c, d \\in \\mathbb{C}$. Then\n$$\nu \\otimes w = ac\\, v_1 \\otimes v_1 + ad\\, v_1 \\otimes v_2 + bc\\, v_2 \\otimes v_1 + bd\\, v_2 \\otimes v_2.\n$$\nMatching coefficients with\n$$\nT = (2+i)\\, v_1 \\otimes v_1 + 1 \\cdot v_1 \\otimes v_2 + \\alpha\\, v_2 \\otimes v_1 - 3i\\, v_2 \\otimes v_2,\n$$\nwe obtain the system\n$$\nac = 2 + i,\\quad ad = 1,\\quad bc = \\alpha,\\quad bd = -3i.\n$$\nA necessary condition is obtained by noting that $(ac)(bd) = (ad)(bc)$, because both equal $abcd$. Therefore,\n$$\n(2+i)(-3i) = 1 \\cdot \\alpha \\quad \\Longrightarrow \\quad \\alpha = (2+i)(-3i).\n$$\nCompute the product using $i^2 = -1$:\n$$\n(2+i)(-3i) = 2(-3i) + i(-3i) = -6i - 3 i^2 = -6i + 3 = 3 - 6i.\n$$\nEquivalently, viewing $T$ via its coefficient matrix\n$$\n\\begin{pmatrix}\n2+i & 1\\\\\n\\alpha & -3i\n\\end{pmatrix},\n$$\n$T$ is simple if and only if this matrix has rank one, i.e., determinant zero:\n$$\n(2+i)(-3i) - \\alpha \\cdot 1 = 0 \\quad \\Longrightarrow \\quad \\alpha = 3 - 6i,\n$$\nwhich matches the previous derivation. This corresponds to option B.", "answer": "$$\\boxed{B}$$", "id": "1645203"}, {"introduction": "Beyond individual tensors, the tensor product construction allows us to build important new vector spaces with specific symmetries, such as the space of symmetric tensors. This practice connects the abstract algebra to a key application in quantum mechanics, where the symmetric subspace $S^k(V)$ describes systems of identical particles like bosons [@problem_id:1645149]. Mastering the calculation of this subspace's dimension is a key skill that uses combinatorial principles to count physical states.", "problem": "In quantum mechanics, a system of identical particles is described by a state vector in a tensor product space. For a system of $k$ identical bosons, where each particle's individual state is described by a vector in an $n$-dimensional complex vector space $V$, the combined state of the system must be symmetric under the interchange of any two particles. This constraint means the state vector for the entire system must belong to the subspace of symmetric tensors of rank $k$, denoted $S^k(V)$, within the full tensor product space $V^{\\otimes k}$.\n\nConsider a system composed of three identical bosons. The quantum state of each individual boson can be described as a linear combination of two orthogonal basis states, say $|0\\rangle$ and $|1\\rangle$. Therefore, the single-particle state space is a 2-dimensional complex vector space.\n\nDetermine the dimension of the state space for this three-boson system.", "solution": "For a system of $k$ identical bosons with single-particle space $V$ of dimension $n$, the allowed states lie in the symmetric tensor power $S^k(V) \\subset V^{\\otimes k}$. The dimension of this space equals the number of ways to distribute $k$ indistinguishable bosons among $n$ single-particle basis states, which is the number of $n$-tuples of nonnegative integers $(m_1,\\dots,m_n)$ satisfying\n$$\n\\sum_{i=1}^{n} m_i = k.\n$$\nBy the stars-and-bars principle, the number of such solutions is\n$$\n\\binom{k+n-1}{n-1} = \\binom{n+k-1}{k}.\n$$\nHere $n=2$ and $k=3$, so\n$$\n\\dim S^3(V) = \\binom{2+3-1}{3} = \\binom{4}{3} = 4.\n$$\nEquivalently, the occupation number solutions to $m_0+m_1=3$ with $m_0,m_1 \\in \\mathbb{Z}_{\\ge 0}$ are $(3,0)$, $(2,1)$, $(1,2)$, and $(0,3)$, giving $4$ linearly independent symmetric states.", "answer": "$$\\boxed{4}$$", "id": "1645149"}]}