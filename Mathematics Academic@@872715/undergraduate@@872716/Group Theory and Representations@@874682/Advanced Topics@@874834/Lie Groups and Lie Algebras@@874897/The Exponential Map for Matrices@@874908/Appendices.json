{"hands_on_practices": [{"introduction": "The infinite series defining the matrix exponential, $\\exp(X) = \\sum_{k=0}^{\\infty} \\frac{X^k}{k!}$, can seem daunting to compute directly. This practice explores a special class of matrices, known as nilpotent matrices, for which this infinite sum elegantly simplifies into a finite polynomial. This exercise [@problem_id:1647445] provides a direct hands-on experience with this fundamental simplification, which serves as a cornerstone for computing exponentials of more general matrices.", "problem": "Let $a, b,$ and $c$ be arbitrary real numbers. Consider the strictly upper triangular matrix $X$ given by:\n$$\nX = \\begin{pmatrix}\n0  a  b \\\\\n0  0  c \\\\\n0  0  0\n\\end{pmatrix}\n$$\nYour task is to compute the matrix exponential $Y = \\exp(X)$. Express your answer as a $3 \\times 3$ matrix whose entries are functions of $a, b,$ and $c$.", "solution": "We use the matrix exponential defined by the power series for any square matrix $X$:\n$$\n\\exp(X)=\\sum_{n=0}^{\\infty}\\frac{X^{n}}{n!}.\n$$\nSince $X$ is strictly upper triangular of size $3\\times 3$, it is nilpotent with $X^{3}=0$. Therefore the series truncates:\n$$\n\\exp(X)=I+X+\\frac{1}{2}X^{2}.\n$$\nCompute $X^{2}$ for\n$$\nX=\\begin{pmatrix}\n0  a  b \\\\\n0  0  c \\\\\n0  0  0\n\\end{pmatrix}.\n$$\nMatrix multiplication gives\n$$\nX^{2}=X\\cdot X=\\begin{pmatrix}\n0  0  ac \\\\\n0  0  0 \\\\\n0  0  0\n\\end{pmatrix},\n$$\nsince the only nonzero term arises in the $(1,3)$ entry as $X_{1,2}X_{2,3}=ac$. Consequently, $X^{3}=X^{2}X=0$ as expected.\n\nThus,\n$$\n\\exp(X)=I+X+\\frac{1}{2}X^{2}\n=\\begin{pmatrix}\n1  0  0 \\\\\n0  1  0 \\\\\n0  0  1\n\\end{pmatrix}\n+\\begin{pmatrix}\n0  a  b \\\\\n0  0  c \\\\\n0  0  0\n\\end{pmatrix}\n+\\frac{1}{2}\\begin{pmatrix}\n0  0  ac \\\\\n0  0  0 \\\\\n0  0  0\n\\end{pmatrix}\n=\\begin{pmatrix}\n1  a  b+\\frac{1}{2}ac \\\\\n0  1  c \\\\\n0  0  1\n\\end{pmatrix}.\n$$", "answer": "$$\\boxed{\\begin{pmatrix}\n1  a  b+\\frac{1}{2}ac \\\\\n0  1  c \\\\\n0  0  1\n\\end{pmatrix}}$$", "id": "1647445"}, {"introduction": "While not all matrices are nilpotent, their exponentials can still be systematically computed by breaking them down into simpler components. The Jordan-Chevalley decomposition allows us to write a matrix as the sum of a diagonal (or semi-simple) part and a nilpotent part. This exercise [@problem_id:1647460] focuses on a canonical Jordan block, demonstrating the powerful technique of leveraging the commuting property $\\exp(A+B) = \\exp(A)\\exp(B)$ to find the exponential. Mastering this method is the key to calculating the exponential of any arbitrary matrix.", "problem": "The matrix exponential for a square matrix $A$ is defined by the power series expansion $e^A = \\sum_{k=0}^{\\infty} \\frac{1}{k!} A^k$, where $A^0$ is defined as the identity matrix. This function is fundamental in the study of Lie groups and their corresponding Lie algebras.\n\nConsider the $3 \\times 3$ matrix $J$ given by:\n$$\nJ = \\begin{pmatrix}\n\\lambda  1  0 \\\\\n0  \\lambda  1 \\\\\n0  0  \\lambda\n\\end{pmatrix}\n$$\nwhere $\\lambda$ is an arbitrary complex number.\n\nYour task is to compute the matrix exponential $e^J$. The final result should be a $3 \\times 3$ matrix whose entries are functions of $\\lambda$.", "solution": "We start by decomposing $J$ into the sum of a scalar multiple of the identity and a nilpotent matrix. Define $I$ as the $3 \\times 3$ identity matrix and\n$$\nN = J - \\lambda I = \\begin{pmatrix}\n0  1  0 \\\\\n0  0  1 \\\\\n0  0  0\n\\end{pmatrix}.\n$$\nThen $J = \\lambda I + N$. The matrix $N$ is nilpotent of index $3$, since\n$$\nN^{2} = \\begin{pmatrix}\n0  0  1 \\\\\n0  0  0 \\\\\n0  0  0\n\\end{pmatrix}, \\quad N^{3} = 0.\n$$\nBecause $\\lambda I$ commutes with every matrix, in particular with $N$, we can use the property that if $A$ and $B$ commute, then $\\exp(A+B) = \\exp(A)\\exp(B)$. Therefore,\n$$\n\\exp(J) = \\exp(\\lambda I + N) = \\exp(\\lambda I)\\exp(N) = e^{\\lambda}\\exp(N).\n$$\nNext, we compute $\\exp(N)$ by its power series. Since $N^{3} = 0$, the series truncates:\n$$\n\\exp(N) = \\sum_{k=0}^{\\infty} \\frac{1}{k!} N^{k} = I + N + \\frac{1}{2} N^{2}.\n$$\nSubstituting the explicit forms of $I$, $N$, and $N^{2}$, we obtain\n$$\nI + N + \\frac{1}{2} N^{2} = \\begin{pmatrix}\n1  1  \\frac{1}{2} \\\\\n0  1  1 \\\\\n0  0  1\n\\end{pmatrix}.\n$$\nThus,\n$$\n\\exp(J) = e^{\\lambda}\\begin{pmatrix}\n1  1  \\frac{1}{2} \\\\\n0  1  1 \\\\\n0  0  1\n\\end{pmatrix}\n= \\begin{pmatrix}\ne^{\\lambda}  e^{\\lambda}  \\frac{1}{2}e^{\\lambda} \\\\\n0  e^{\\lambda}  e^{\\lambda} \\\\\n0  0  e^{\\lambda}\n\\end{pmatrix}.\n$$\nThis gives the matrix exponential in terms of $\\lambda$.", "answer": "$$\\boxed{\\begin{pmatrix}e^{\\lambda}e^{\\lambda}\\frac{1}{2}e^{\\lambda}\\\\0e^{\\lambda}e^{\\lambda}\\\\00e^{\\lambda}\\end{pmatrix}}$$", "id": "1647460"}, {"introduction": "After learning to compute the matrix exponential, a natural next step is to consider the inverse problem: finding the matrix logarithm. Given a matrix $A$, can we find a matrix $X$ such that $\\exp(X) = A$? This practice [@problem_id:1647471] introduces this concept by solving for $X$ in the straightforward case of a diagonal matrix. This not only reinforces the properties of the exponential map but also deepens your understanding by connecting it to the familiar scalar logarithm.", "problem": "The matrix exponential, $\\exp(X)$, for a square matrix $X$ is defined by the Taylor series expansion $\\exp(X) = \\sum_{k=0}^{\\infty} \\frac{1}{k!} X^k$.\n\nConsider the real 3x3 matrix $A$ defined as:\n$$\nA = \\begin{pmatrix}\n1  0  0 \\\\\n0  e^3  0 \\\\\n0  0  4\n\\end{pmatrix}\n$$\nFind a real 3x3 matrix $X$ such that $\\exp(X) = A$.", "solution": "We use the definition of the matrix exponential $\\exp(X)=\\sum_{k=0}^{\\infty}\\frac{1}{k!}X^{k}$. If $X$ is diagonal, say $X=\\operatorname{diag}(x_{1},x_{2},x_{3})$, then each power $X^{k}$ is diagonal with entries $x_{1}^{k},x_{2}^{k},x_{3}^{k}$ on the diagonal, so\n$$\n\\exp(X)=\\operatorname{diag}\\!\\left(\\sum_{k=0}^{\\infty}\\frac{x_{1}^{k}}{k!},\\sum_{k=0}^{\\infty}\\frac{x_{2}^{k}}{k!},\\sum_{k=0}^{\\infty}\\frac{x_{3}^{k}}{k!}\\right)=\\operatorname{diag}\\!\\left(\\exp(x_{1}),\\exp(x_{2}),\\exp(x_{3})\\right).\n$$\nThe given matrix is $A=\\operatorname{diag}(1,\\exp(3),4)$ (noting that $e^{3}=\\exp(3)$). To have $\\exp(X)=A$, it is sufficient to choose $X$ diagonal with entries $x_{1},x_{2},x_{3}$ satisfying the scalar equations\n$$\n\\exp(x_{1})=1,\\quad \\exp(x_{2})=\\exp(3),\\quad \\exp(x_{3})=4.\n$$\nSince $\\exp$ is bijective on $\\mathbb{R}$ with inverse $\\ln$, we obtain\n$$\nx_{1}=\\ln(1)=0,\\quad x_{2}=3,\\quad x_{3}=\\ln(4).\n$$\nTherefore, a valid real matrix is\n$$\nX=\\begin{pmatrix}\n0  0  0 \\\\\n0  3  0 \\\\\n0  0  \\ln(4)\n\\end{pmatrix},\n$$\nand indeed\n$$\n\\exp(X)=\\operatorname{diag}\\!\\left(\\exp(0),\\exp(3),\\exp(\\ln(4))\\right)=\\operatorname{diag}(1,\\exp(3),4)=A.\n$$", "answer": "$$\\boxed{\\begin{pmatrix}0  0  0 \\\\ 0  3  0 \\\\ 0  0  \\ln(4)\\end{pmatrix}}$$", "id": "1647471"}]}