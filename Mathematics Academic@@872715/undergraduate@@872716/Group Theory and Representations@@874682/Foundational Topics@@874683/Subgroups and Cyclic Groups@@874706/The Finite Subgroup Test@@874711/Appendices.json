{"hands_on_practices": [{"introduction": "This first exercise provides a direct and practical application of the Finite Subgroup Test. We will explore how the twin conditions of finiteness and closure under an operation force a non-empty set to contain both an identity element and all necessary inverses, thereby forming a subgroup. Working within the familiar multiplicative group of non-zero rational numbers, $(\\mathbb{Q}^*, \\cdot)$, this problem helps solidify the core logic behind the test itself [@problem_id:1647701].", "problem": "Let $(\\mathbb{Q}^*, \\cdot)$ denote the multiplicative group of non-zero rational numbers. Consider a non-empty, finite subset $H$ of $\\mathbb{Q}^*$ which is closed under the operation of multiplication. That is, for any two elements $a, b \\in H$, their product $ab$ is also in $H$.\n\nWhich of the following statements is a necessary consequence of these conditions?\n\nA. $H$ must be a subgroup of $(\\mathbb{Q}^*, \\cdot)$.\nB. It is possible for $H$ to not contain the identity element, $1$.\nC. $H$ could contain an element $x$ for which the multiplicative inverse $x^{-1}$ is not in $H$.\nD. It is possible for $H$ to contain the number $3$.\nE. The set $H = \\left\\{\\frac{1}{2}, \\frac{1}{4}\\right\\}$ is a valid example of such a set.", "solution": "We are given a non-empty, finite subset $H \\subset \\mathbb{Q}^{*}$ that is closed under multiplication. We analyze the structural consequences.\n\nFirst, we show that $1 \\in H$. Take any $x \\in H$. By closure under multiplication, the powers $x^{k} \\in H$ for all integers $k \\geq 1$, proven by induction: $x^{1} = x \\in H$, and if $x^{k} \\in H$ then $x^{k+1} = x^{k} \\cdot x \\in H$. Since $H$ is finite, there exist integers $m,n$ with $1 \\leq m  n$ such that $x^{m} = x^{n}$. Then\n$$\nx^{n-m} = x^{n} \\cdot x^{-m} = x^{m} \\cdot x^{-m} = 1.\n$$\nMoreover, by closure, $x^{n-m} \\in H$, hence $1 \\in H$.\n\nNext, we show that for every $x \\in H$, its inverse $x^{-1}$ is in $H$. From $x^{n-m} = 1$ above with $n-m \\geq 1$, we have\n$$\nx^{-1} = x^{n-m-1},\n$$\nand since $x^{k} \\in H$ for all $k \\geq 1$, it follows that $x^{-1} \\in H$. Therefore $H$ is closed under taking inverses.\n\nCombining closure under multiplication, the presence of the identity, and closure under inverses, $H$ satisfies the subgroup criteria in $(\\mathbb{Q}^{*}, \\cdot)$. Hence statement A must be true.\n\nWe now assess the remaining options:\n- B is false because we proved $1 \\in H$ is necessary.\n- C is false because we proved that for every $x \\in H$, $x^{-1} \\in H$.\n- D is false under the given finiteness condition. If $3 \\in H$, then by closure all powers $3^{k} \\in H$ for $k \\geq 1$. These are all distinct because $3^{i} = 3^{j}$ implies $3^{j-i} = 1$, which forces $i = j$. This yields an infinite subset of $H$, contradicting finiteness. Thus $3 \\notin H$ for any such finite $H$.\n- E is false because $H = \\{\\frac{1}{2}, \\frac{1}{4}\\}$ is not closed: $\\frac{1}{2} \\cdot \\frac{1}{4} = \\frac{1}{8} \\notin H$.\n\nTherefore, the only necessary consequence is that $H$ is a subgroup of $(\\mathbb{Q}^{*}, \\cdot)$, which corresponds to option A.", "answer": "$$\\boxed{A}$$", "id": "1647701"}, {"introduction": "Theorems in mathematics are built upon precise conditions, and overlooking even one can lead to incorrect conclusions. This practice problem serves as a critical examination of the boundary conditions of the Finite Subgroup Test, specifically the often-assumed \"non-empty\" property. By analyzing a finite, closed subset of vectors in $(\\mathbb{R}^n, +)$, you will discover why this hypothesis is essential and how its absence changes the entire landscape of possibilities [@problem_id:1647682].", "problem": "Consider the group $G = (\\mathbb{R}^n, +)$, where $\\mathbb{R}^n$ is the set of $n$-dimensional real vectors for some integer $n \\ge 1$, and $+$ is the standard component-wise vector addition. Let $H$ be a subset of $\\mathbb{R}^n$ that possesses the following two properties:\n1. $H$ is a finite set.\n2. $H$ is closed under vector addition (i.e., for any two vectors $\\mathbf{u}, \\mathbf{v} \\in H$, the vector sum $\\mathbf{u}+\\mathbf{v}$ is also in $H$).\n\nWhich of the following statements is the most accurate assessment of whether $H$ is necessarily a subgroup of $G$?\n\nA. Yes, because any finite subset of a group that is closed under the group operation is always a subgroup.\nB. Yes, because the given conditions imply that $H$ must be the trivial subgroup $\\{\\mathbf{0}\\}$.\nC. No, because it is not guaranteed that $H$ contains the identity element of $G$.\nD. No, because while $H$ must contain the identity element, it is not guaranteed to be closed under inverses.", "solution": "We work in the additive group $G=(\\mathbb{R}^{n},+)$.\n\n1. Suppose first that $H$ is nonempty. Pick any $\\mathbf{u}\\in H$. Because $H$ is closed under vector addition, for every positive integer $k$ the element\n$$\nk\\mathbf{u}=\\underbrace{\\mathbf{u}+\\cdots+\\mathbf{u}}_{k\\ \\text{times}}\n$$\nlies in $H$. Since $H$ is finite, there exist integers $mn\\geq 1$ such that $m\\mathbf{u}=n\\mathbf{u}$. Subtracting gives\n$$\n(m-n)\\mathbf{u}=\\mathbf{0}.\n$$\nIn the vector space $\\mathbb{R}^{n}$, the only solution to $k\\mathbf{x}=\\mathbf{0}$ with $k\\in\\mathbb{Z}\\setminus\\{0\\}$ is $\\mathbf{x}=\\mathbf{0}$, because the linear map $\\mathbf{x}\\mapsto k\\mathbf{x}$ has determinant $k^{n}\\neq 0$ and hence trivial kernel. Therefore $\\mathbf{u}=\\mathbf{0}$. Since $\\mathbf{u}$ was arbitrary in $H$, it follows that if $H$ is nonempty, then $H=\\{\\mathbf{0}\\}$, which is a subgroup of $G$.\n\n2. However, the hypotheses only assert that $H$ is finite and closed under addition; they do not assert that $H$ is nonempty. The empty set is finite and vacuously closed under addition, but it is not a subgroup because it does not contain the identity element $\\mathbf{0}$.\n\nTherefore, $H$ is not necessarily a subgroup of $G$ under the given assumptions. The most accurate reason among the options is that it is not guaranteed that $H$ contains the identity element of $G$.\n\nOption analysis:\n- A is false as stated because it omits the necessary nonemptiness condition (the empty set is a counterexample).\n- B would be true if $H$ were assumed nonempty, but as stated it fails because $H$ could be empty.\n- C correctly identifies the failure: the identity need not be present.\n- D is incorrect; in the only possible nonempty case $H=\\{\\mathbf{0}\\}$, closure under inverses holds trivially.\n\nHence the correct choice is C.", "answer": "$$\\boxed{C}$$", "id": "1647682"}, {"introduction": "The power of a theorem often lies not just in its primary statement, but in the deeper properties it helps uncover. This final practice moves beyond simply identifying subgroups to exploring the profound consequences for a finite group of matrices within $GL_n(\\mathbb{C})$. You will see how the Finite Subgroup Test becomes a gateway to powerful results from linear algebra, revealing necessary truths about diagonalizability and the nature of determinants for every matrix in the set [@problem_id:1647692].", "problem": "Let $S$ be a finite, non-empty subset of $GL_n(\\mathbb{C})$, the group of $n \\times n$ invertible matrices with complex entries. Suppose that for any two matrices $A, B \\in S$, their product $AB$ is also in $S$ (i.e., $S$ is closed under matrix multiplication).\n\nWhich one of the following statements about such a set $S$ is NOT necessarily true?\n\nA. The identity matrix $I_n$ is an element of $S$.\nB. For any matrix $M \\in S$, its inverse $M^{-1}$ is also an element of $S$.\nC. The determinant of every matrix in $S$ is a root of unity.\nD. Every matrix in $S$ is diagonalizable over $\\mathbb{C}$.\nE. All matrices in $S$ are simultaneously diagonalizable.", "solution": "Let $S$ be a finite, non-empty subset of $GL_{n}(\\mathbb{C})$ closed under matrix multiplication.\n\nFirst, fix $A \\in S$. By closure, all positive powers $A^{m}$ belong to $S$ by induction: $A^{1}=A \\in S$, and if $A^{m} \\in S$ then $A^{m+1}=A^{m}A \\in S$. Since $S$ is finite, the sequence $\\{A^{m}\\}_{m \\geq 1}$ takes only finitely many values, so there exist integers $1 \\leq i  j$ with $A^{i}=A^{j}$. Because $A$ is invertible in $GL_{n}(\\mathbb{C})$, multiply on the left by $A^{-i}$ (in $GL_{n}(\\mathbb{C})$) to get $A^{j-i}=I_{n}$. But $A^{j-i}$ is a product of copies of $A$, hence $A^{j-i} \\in S$ by closure. Therefore $I_{n} \\in S$. This proves statement A.\n\nNext, for any $A \\in S$, from $A^{j-i}=I_{n}$ above we have $A^{j-i-1}$ is an inverse of $A$, i.e., $A A^{j-i-1}=I_{n}$. In a group, right inverses are unique and equal to $A^{-1}$, hence $A^{-1}=A^{j-i-1} \\in S$ as a power of $A$. This proves statement B. Consequently, $S$ is a finite subgroup of $GL_{n}(\\mathbb{C})$.\n\nFor statement C, let $M \\in S$. Since $S$ is a finite group, $M$ has finite order: there exists $k \\in \\mathbb{N}$ with $M^{k}=I_{n}$. Taking determinants gives $(\\det M)^{k}=\\det(M^{k})=\\det(I_{n})=1$, so $\\det M$ is a root of unity. Thus C is true.\n\nFor statement D, again for $M \\in S$ with $M^{k}=I_{n}$, the minimal polynomial $m_{M}(x)$ divides $x^{k}-1$. Over $\\mathbb{C}$, $x^{k}-1$ splits completely into linear factors, and it is square-free because its derivative $(x^{k}-1)'=k x^{k-1}$ shares no common root with $x^{k}-1$ (the only potential common root would be $x=0$, which is not a root of $x^{k}-1$). Therefore $m_{M}(x)$ has no repeated roots, which implies $M$ is diagonalizable over $\\mathbb{C}$. Hence D is true.\n\nFor statement E, simultaneous diagonalizability over $\\mathbb{C}$ implies pairwise commutativity: if all matrices in $S$ are simultaneously diagonalizable, then there exists an invertible $U$ such that every $U^{-1}MU$ is diagonal; diagonal matrices commute, so the original matrices commute as well. However, there exist finite subgroups of $GL_{n}(\\mathbb{C})$ that are not abelian. For example, let $S$ be the subgroup of $GL_{3}(\\mathbb{C})$ consisting of all $3 \\times 3$ permutation matrices (isomorphic to the symmetric group on three letters). Take\n$$\nA=\\begin{pmatrix}\n0  1  0\\\\\n1  0  0\\\\\n0  0  1\n\\end{pmatrix}, \\quad\nB=\\begin{pmatrix}\n1  0  0\\\\\n0  0  1\\\\\n0  1  0\n\\end{pmatrix}.\n$$\nThen $A,B \\in S$, $A^{2}=I_{3}$ and $B^{2}=I_{3}$, so both are diagonalizable; yet $AB \\neq BA$, so they cannot be simultaneously diagonalizable (since simultaneous diagonalization would force commutativity). Thus E is not necessarily true.\n\nTherefore, the only statement that is not necessarily true is E.", "answer": "$$\\boxed{E}$$", "id": "1647692"}]}