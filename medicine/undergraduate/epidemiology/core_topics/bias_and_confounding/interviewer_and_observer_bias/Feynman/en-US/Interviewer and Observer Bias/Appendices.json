{
    "hands_on_practices": [
        {
            "introduction": "Understanding the impact of observer bias begins with quantifying its effect. This first exercise provides a clear, hypothetical scenario where the true association is known, allowing you to see precisely how differential misclassification of the outcome can distort the observed risk ratio . By calculating the observed risks based on given sensitivity and specificity values, you will gain a hands-on appreciation for the mechanics of information bias and its potential to mislead research conclusions.",
            "id": "4605343",
            "problem": "A cohort study evaluates a treatment by comparing the risk of a binary outcome in a treated group versus an untreated group. The true risks are known to be $0.30$ in the treated group and $0.20$ in the untreated group. Outcome status is ascertained by clinicians who are aware of treatment assignment, introducing observer bias: the sensitivity of outcome ascertainment is $0.95$ in the treated group and $0.80$ in the untreated group, while specificity is $0.98$ in both groups. Assume a very large sample size so that empirical proportions equal their corresponding probabilities.\n\nStarting from the core definitions of sensitivity and specificity for a binary test and the law of total probability, derive the observed risks in each group under this differential misclassification of the outcome and compute the observed risk ratio. Let the true risk ratio be defined as the ratio of true risks, and let the observed risk ratio be defined as the ratio of observed risks based on the misclassified outcomes. Define the absolute bias on the risk ratio scale as the difference between the observed risk ratio and the true risk ratio. \n\nWhat is the absolute bias? Round your answer to four significant figures. Report a pure number with no units.",
            "solution": "The problem statement is critically evaluated and deemed valid. It is scientifically grounded in epidemiological principles, well-posed with sufficient and consistent information, and objectively stated.\n\nLet us formally define the events and parameters.\nLet $T$ represent the event that an individual is in the treated group, and $U$ represent the event that an individual is in the untreated group.\nLet $D$ be the event that an individual truly has the outcome, and $\\bar{D}$ be the event that an individual truly does not have the outcome.\nLet $O$ be the event that the outcome is observed (i.e., a positive test or diagnosis), and $\\bar{O}$ be the event that the outcome is not observed.\n\nThe givens from the problem statement are:\nThe true risk in the treated group: $P(D|T) = 0.30$.\nThe true risk in the untreated group: $P(D|U) = 0.20$.\nThe sensitivity of outcome ascertainment in the treated group: $Se_T = P(O|D, T) = 0.95$.\nThe sensitivity of outcome ascertainment in the untreated group: $Se_U = P(O|D, U) = 0.80$.\nThe specificity of outcome ascertainment in both groups: $Sp = P(\\bar{O}|\\bar{D}) = 0.98$. The problem states this is the same for treated and untreated groups, so $P(\\bar{O}|\\bar{D}, T) = P(\\bar{O}|\\bar{D}, U) = 0.98$.\n\nFrom the given true risks, we can deduce the probabilities of not having the outcome:\nProbability of no outcome in the treated group: $P(\\bar{D}|T) = 1 - P(D|T) = 1 - 0.30 = 0.70$.\nProbability of no outcome in the untreated group: $P(\\bar{D}|U) = 1 - P(D|U) = 1 - 0.20 = 0.80$.\n\nFrom the given specificity, we can deduce the probability of a false positive ($FP$ rate), which is $1 - Sp$:\n$P(O|\\bar{D}) = 1 - Sp = 1 - 0.98 = 0.02$. This is also the same for both groups.\n\nFirst, we calculate the true risk ratio ($RR_{true}$), defined as the ratio of the true risks.\n$$RR_{true} = \\frac{P(D|T)}{P(D|U)} = \\frac{0.30}{0.20} = 1.5$$\n\nNext, we must find the observed risks in each group. The observed risk is the probability of an observed outcome, $P(O)$, within each group. We use the law of total probability. An observed outcome can occur in two disjoint ways: either the person truly has the outcome and is correctly identified (a true positive), or the person does not truly have the outcome but is incorrectly identified (a false positive).\n\nFor the treated group, the observed risk, $P(O|T)$, is:\n$$P(O|T) = P(O|D, T)P(D|T) + P(O|\\bar{D}, T)P(\\bar{D}|T)$$\nSubstituting the known values:\n$$P(O|T) = (Se_T) \\times P(D|T) + (1 - Sp) \\times P(\\bar{D}|T)$$\n$$P(O|T) = (0.95)(0.30) + (0.02)(0.70)$$\n$$P(O|T) = 0.285 + 0.014 = 0.299$$\n\nFor the untreated group, the observed risk, $P(O|U)$, is:\n$$P(O|U) = P(O|D, U)P(D|U) + P(O|\\bar{D}, U)P(\\bar{D}|U)$$\nSubstituting the known values:\n$$P(O|U) = (Se_U) \\times P(D|U) + (1 - Sp) \\times P(\\bar{D}|U)$$\n$$P(O|U) = (0.80)(0.20) + (0.02)(0.80)$$\n$$P(O|U) = 0.160 + 0.016 = 0.176$$\n\nNow, we can calculate the observed risk ratio ($RR_{obs}$), defined as the ratio of the observed risks.\n$$RR_{obs} = \\frac{P(O|T)}{P(O|U)} = \\frac{0.299}{0.176}$$\n$$RR_{obs} \\approx 1.69886363...$$\n\nThe problem asks for the absolute bias on the risk ratio scale, which is defined as the difference between the observed risk ratio and the true risk ratio.\n$$\\text{Absolute Bias} = RR_{obs} - RR_{true}$$\n$$\\text{Absolute Bias} = \\frac{0.299}{0.176} - 1.5$$\n$$\\text{Absolute Bias} \\approx 1.69886363... - 1.5$$\n$$\\text{Absolute Bias} \\approx 0.19886363...$$\n\nThe problem requires the answer to be rounded to four significant figures.\nThe first four significant figures of $0.19886363...$ are $1$, $9$, $8$, and $8$. The fifth significant figure is $6$, which is $ \\ge 5$, so we round up the fourth significant figure.\n$$\\text{Absolute Bias} \\approx 0.1989$$",
            "answer": "$$\\boxed{0.1989}$$"
        },
        {
            "introduction": "After seeing how observer bias can alter study results, the next logical step is to learn how to correct for it. This practice demonstrates that if the characteristics of the misclassification are known—often from a smaller validation study—we can work backward from the observed, biased data to estimate the true underlying risks . Mastering this back-calculation is a crucial skill for critically appraising published research and performing sensitivity analyses to assess the robustness of study findings.",
            "id": "4605378",
            "problem": "A prospective cohort study evaluates the effect of an exposure on a binary health outcome that is ascertained by interviewers who are aware of participants’ exposure status. A validation substudy provides estimates of differential misclassification of the outcome due to observer bias: among exposed participants, the outcome assessment has sensitivity (probability of correctly classifying a truly diseased individual) $Se_{1}$ and specificity (probability of correctly classifying a truly non-diseased individual) $Sp_{1}$; among unexposed participants, sensitivity is $Se_{0}$ and specificity is $Sp_{0}$. Let $A \\in \\{0,1\\}$ denote exposure, $Y \\in \\{0,1\\}$ the true outcome, and $Y^{\\ast} \\in \\{0,1\\}$ the observed (possibly misclassified) outcome. The observed risks of the recorded outcome are $\\tilde{p}_{1} = \\mathbb{P}(Y^{\\ast} = 1 \\mid A=1)$ for the exposed and $\\tilde{p}_{0} = \\mathbb{P}(Y^{\\ast} = 1 \\mid A=0)$ for the unexposed. Assume that the validation parameters apply to the full cohort and that there is no other source of bias.\n\nStarting from the fundamental definitions of sensitivity and specificity and the law of total probability, derive expressions to back-calculate the corrected risks $p_{1} = \\mathbb{P}(Y=1 \\mid A=1)$ and $p_{0} = \\mathbb{P}(Y=1 \\mid A=0)$ in terms of $(\\tilde{p}_{a}, Se_{a}, Sp_{a})$ for $a \\in \\{0,1\\}$. Then, using the values $Se_{1} = 0.90$, $Sp_{1} = 0.95$, $Se_{0} = 0.80$, $Sp_{0} = 0.95$, $\\tilde{p}_{1} = 0.33$, and $\\tilde{p}_{0} = 0.18$, compute the bias-corrected risk ratio defined as $RR = p_{1}/p_{0}$. Provide your final answer as a simplified exact fraction. No rounding is required.",
            "solution": "The problem is assessed to be valid. It is scientifically grounded in the principles of epidemiology, specifically concerning the correction of information bias (observer bias). The problem is well-posed, providing all necessary definitions, variables, and data for a unique solution. The language is objective and unambiguous.\n\nThe primary task is to derive an expression for the true risks of the outcome, $p_a = \\mathbb{P}(Y=1 \\mid A=a)$ for $a \\in \\{0,1\\}$, given the observed risks, $\\tilde{p}_a = \\mathbb{P}(Y^{\\ast}=1 \\mid A=a)$, and the parameters of differential outcome misclassification: sensitivities ($Se_0, Se_1$) and specificities ($Sp_0, Sp_1$).\n\nWe begin by applying the law of total probability to the observed risk, $\\tilde{p}_a$, conditioning on the true outcome status $Y$. For a given exposure status $A=a$, the probability of observing the outcome is the sum of the probability of observing it among truly diseased individuals and the probability of observing it among truly non-diseased individuals.\n\n$$ \\tilde{p}_a = \\mathbb{P}(Y^{\\ast}=1 \\mid A=a) = \\mathbb{P}(Y^{\\ast}=1 \\mid Y=1, A=a)\\mathbb{P}(Y=1 \\mid A=a) + \\mathbb{P}(Y^{\\ast}=1 \\mid Y=0, A=a)\\mathbb{P}(Y=0 \\mid A=a) $$\n\nWe can substitute the given definitions into this equation:\n- The true risk is $p_a = \\mathbb{P}(Y=1 \\mid A=a)$.\n- The probability of being truly non-diseased is $\\mathbb{P}(Y=0 \\mid A=a) = 1 - p_a$.\n- The sensitivity is $Se_a = \\mathbb{P}(Y^{\\ast}=1 \\mid Y=1, A=a)$.\n- The specificity is $Sp_a = \\mathbb{P}(Y^{\\ast}=0 \\mid Y=0, A=a)$. The probability of a false positive is therefore $1 - Sp_a = \\mathbb{P}(Y^{\\ast}=1 \\mid Y=0, A=a)$.\n\nSubstituting these terms into the equation yields:\n$$ \\tilde{p}_a = (Se_a)(p_a) + (1 - Sp_a)(1 - p_a) $$\n\nThis is a linear equation in $p_a$. We now solve for $p_a$ to derive the expression for the corrected risk.\n$$ \\tilde{p}_a = Se_a \\cdot p_a + 1 - Sp_a - p_a + Sp_a \\cdot p_a $$\n$$ \\tilde{p}_a = p_a (Se_a + Sp_a - 1) + 1 - Sp_a $$\n$$ \\tilde{p}_a - (1 - Sp_a) = p_a (Se_a + Sp_a - 1) $$\n$$ p_a = \\frac{\\tilde{p}_a - 1 + Sp_a}{Se_a + Sp_a - 1} $$\nThis is the general formula for the bias-corrected risk, $p_a$, in terms of the observed risk, $\\tilde{p}_a$, and the stratum-specific sensitivity, $Se_a$, and specificity, $Sp_a$. The denominator, $Se_a + Sp_a - 1$, must be non-zero for the correction to be possible.\n\nNow, we use this formula and the provided numerical values to calculate the corrected risks for the exposed ($p_1$) and unexposed ($p_0$) groups. The given values are:\n- $Se_1 = 0.90$\n- $Sp_1 = 0.95$\n- $\\tilde{p}_1 = 0.33$\n- $Se_0 = 0.80$\n- $Sp_0 = 0.95$\n- $\\tilde{p}_0 = 0.18$\n\nFirst, we calculate the corrected risk in the exposed group ($a=1$):\n$$ p_1 = \\frac{\\tilde{p}_1 + Sp_1 - 1}{Se_1 + Sp_1 - 1} = \\frac{0.33 + 0.95 - 1}{0.90 + 0.95 - 1} = \\frac{0.28}{0.85} $$\nTo express this as an exact fraction:\n$$ p_1 = \\frac{28/100}{85/100} = \\frac{28}{85} $$\n\nNext, we calculate the corrected risk in the unexposed group ($a=0$):\n$$ p_0 = \\frac{\\tilde{p}_0 + Sp_0 - 1}{Se_0 + Sp_0 - 1} = \\frac{0.18 + 0.95 - 1}{0.80 + 0.95 - 1} = \\frac{0.13}{0.75} $$\nTo express this as an exact fraction:\n$$ p_0 = \\frac{13/100}{75/100} = \\frac{13}{75} $$\n\nFinally, we compute the bias-corrected risk ratio, $RR = p_1 / p_0$.\n$$ RR = \\frac{p_1}{p_0} = \\frac{28/85}{13/75} $$\n$$ RR = \\frac{28}{85} \\times \\frac{75}{13} $$\nWe can simplify this expression. Note that $85 = 5 \\times 17$ and $75 = 5 \\times 15$.\n$$ RR = \\frac{28}{5 \\times 17} \\times \\frac{5 \\times 15}{13} = \\frac{28 \\times 15}{17 \\times 13} $$\nNow, we perform the multiplication:\n$$ 28 \\times 15 = 420 $$\n$$ 17 \\times 13 = 17 \\times (10 + 3) = 170 + 51 = 221 $$\nSo the risk ratio is:\n$$ RR = \\frac{420}{221} $$\nThe prime factors of the denominator are $13$ and $17$. The numerator $420 = 2^2 \\times 3 \\times 5 \\times 7$ is not divisible by $13$ or $17$. Thus, the fraction is in its simplest form.",
            "answer": "$$\\boxed{\\frac{420}{221}}$$"
        },
        {
            "introduction": "While correcting for bias is a powerful tool, preventing it is even better. A primary source of observer bias is inconsistency between data collectors. This exercise introduces a standard method for quantifying this consistency, or inter-rater reliability, using Cohen’s kappa coefficient ($\\kappa$) . By calculating $\\kappa$, you will learn how to measure the extent of agreement between two observers beyond what is expected by chance, a critical step in assessing data quality and validating measurement procedures.",
            "id": "4605389",
            "problem": "A population-based cross-sectional study is conducted to assess a binary outcome (present versus absent) for a respiratory symptom. To evaluate potential interviewer and observer bias, two trained interviewers independently classify each participant’s outcome. Agreement beyond chance is quantified using Cohen’s kappa, denoted by $\\kappa$, which is a measure used in Inter-Rater Reliability (IRR). \n\nFrom a sample of $N = 100$ participants, the joint classification counts are as follows:\n- Both interviewers classify as outcome present: $40$.\n- Both interviewers classify as outcome absent: $50$.\n- Interviewer $1$ classifies present while Interviewer $2$ classifies absent: $5$.\n- Interviewer $1$ classifies absent while Interviewer $2$ classifies present: $5$.\n\nStarting from fundamental definitions of agreement probability, compute the observed agreement proportion and the expected agreement proportion under independence of interviewers given the marginal distributions. Then, derive Cohen’s kappa $\\kappa$ from these quantities. Express your final answer as an exact fraction. Do not convert to a percentage.",
            "solution": "To compute Cohen's kappa, $\\kappa$, we first organize the provided data into a $2 \\times 2$ contingency table. Let 'Present' be the positive classification and 'Absent' be the negative classification for the respiratory symptom.\n\nThe counts are:\n$a$: Interviewer $1$ 'Present', Interviewer $2$ 'Present' = $40$\n$b$: Interviewer $1$ 'Present', Interviewer $2$ 'Absent' = $5$\n$c$: Interviewer $1$ 'Absent', Interviewer $2$ 'Present' = $5$\n$d$: Interviewer $1$ 'Absent', Interviewer $2$ 'Absent' = $50$\n\nThe total number of participants is $N = a+b+c+d = 40+5+5+50 = 100$.\n\nThe contingency table is:\n|                   | Interviewer 2: Present | Interviewer 2: Absent | Row Totals      |\n|-------------------|:----------------------:|:---------------------:|:---------------:|\n| **Int 1: Present**| $a = 40$               | $b = 5$               | $n_{1P} = 45$   |\n| **Int 1: Absent** | $c = 5$                | $d = 50$              | $n_{1A} = 55$   |\n| **Column Totals** | $n_{2P} = 45$          | $n_{2A} = 55$         | $N = 100$       |\n\nHere, $n_{1P}$ is the number of times Interviewer $1$ classified as 'Present', $n_{1A}$ as 'Absent', and similarly for Interviewer $2$ with $n_{2P}$ and $n_{2A}$.\n\nThe first step is to calculate the observed agreement proportion, $P_o$. This is the proportion of participants for whom the two interviewers' classifications agree. Agreement occurs in cells $a$ and $d$.\n$$P_o = \\frac{a+d}{N}$$\nSubstituting the given values:\n$$P_o = \\frac{40+50}{100} = \\frac{90}{100} = \\frac{9}{10}$$\n\nThe second step is to calculate the expected agreement proportion, $P_e$, which is the hypothetical probability of agreement by chance. This calculation assumes that the interviewers' ratings are independent, given their individual marginal distributions of classifications.\nThe probability that Interviewer $1$ classifies as 'Present' is $P_{1P} = \\frac{n_{1P}}{N} = \\frac{45}{100}$.\nThe probability that Interviewer $1$ classifies as 'Absent' is $P_{1A} = \\frac{n_{1A}}{N} = \\frac{55}{100}$.\nThe probability that Interviewer $2$ classifies as 'Present' is $P_{2P} = \\frac{n_{2P}}{N} = \\frac{45}{100}$.\nThe probability that Interviewer $2$ classifies as 'Absent' is $P_{2A} = \\frac{n_{2A}}{N} = \\frac{55}{100}$.\n\nUnder independence, the probability that both classify as 'Present' is the product of their individual probabilities:\n$$P_{e,Present} = P_{1P} \\times P_{2P} = \\left(\\frac{45}{100}\\right) \\times \\left(\\frac{45}{100}\\right)$$\nThe probability that both classify as 'Absent' is:\n$$P_{e,Absent} = P_{1A} \\times P_{2A} = \\left(\\frac{55}{100}\\right) \\times \\left(\\frac{55}{100}\\right)$$\nThe total expected agreement proportion $P_e$ is the sum of these probabilities:\n$$P_e = P_{e,Present} + P_{e,Absent} = \\left(\\frac{45}{100}\\right)^2 + \\left(\\frac{55}{100}\\right)^2$$\n$$P_e = \\frac{45^2 + 55^2}{100^2} = \\frac{2025 + 3025}{10000} = \\frac{5050}{10000} = \\frac{505}{1000} = \\frac{101}{200}$$\n\nFinally, Cohen's kappa coefficient, $\\kappa$, is defined as the ratio of the actual agreement beyond chance ($P_o - P_e$) to the maximum possible agreement beyond chance ($1 - P_e$).\n$$\\kappa = \\frac{P_o - P_e}{1 - P_e}$$\nSubstituting the calculated values for $P_o$ and $P_e$:\n$$P_o - P_e = \\frac{9}{10} - \\frac{101}{200} = \\frac{9 \\times 20}{10 \\times 20} - \\frac{101}{200} = \\frac{180}{200} - \\frac{101}{200} = \\frac{79}{200}$$\n$$1 - P_e = 1 - \\frac{101}{200} = \\frac{200}{200} - \\frac{101}{200} = \\frac{99}{200}$$\nNow, we compute $\\kappa$:\n$$\\kappa = \\frac{\\frac{79}{200}}{\\frac{99}{200}} = \\frac{79}{99}$$\nThe fraction $\\frac{79}{99}$ is in its simplest form, since $79$ is a prime number and does not divide $99$.",
            "answer": "$$\\boxed{\\frac{79}{99}}$$"
        }
    ]
}