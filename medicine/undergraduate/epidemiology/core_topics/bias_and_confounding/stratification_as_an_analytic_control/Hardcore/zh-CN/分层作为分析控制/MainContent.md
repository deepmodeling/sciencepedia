## 引言
在观察性研究中，我们如何才能确信所观察到的关联是真实的因果效应，而非由其他因素造成的假象？这是流行病学乃至所有经验科学面临的核心挑战。由于缺乏随机分配，研究中的暴露组与非暴露组在诸多方面可能存在系统性差异，这些差异即“混杂因素”，它们会扭曲我们对因果关系的判断。分层分析（Stratification）正是应对这一挑战最基本、最强大的分析工具之一。

本文旨在系统性地解析分层作为一种分析性控制方法的理论与实践。我们将深入探讨其背后的逻辑，以及它在揭示真实因果关系中的关键作用。

在接下来的内容中，我们将分三步展开：首先，在**“原理与机制”**一章，我们将剖析分层控制混杂的基本逻辑，介绍标准化的计算过程，并阐明其赖以成立的三个核心因果推断假设。接着，在**“应用与跨学科联系”**一章，我们将展示分层思想如何超越传统流行病学，在临床试验、基因组学研究和医疗质量改进等多个领域发挥关键作用，并从控制偏倚延伸至发现效应修饰。最后，通过**“动手实践”**环节，您将有机会通过解决具体问题，将理论知识转化为可操作的分析技能。通过这一结构化的学习路径，您将对分层这一核心科学工具有一个全面而深刻的理解。

## 原理与机制

在上一章引言中，我们明确了[观察性研究](@entry_id:174507)的核心挑战：由于缺乏随机分配，暴露组与非暴露组之间往往存在系统性差异，这些差异可能“混淆”我们对暴露与结局之间因果关系的判断。本章将深入探讨分层（stratification）作为一种核心的分析性控制方法，阐述其背后的原理、机制、理论假设以及在实践中遇到的挑战。分层不仅是一种强大的统计技术，更是一种清晰展示因果推断逻辑的思维方式。

### 分层：控制混杂的基本逻辑

想象一项[观察性研究](@entry_id:174507)，旨在探究某项暴露 $A$ 是否会导致结局 $Y$。然而，可能存在一个既影响暴露选择又独立影响结局的第三个变量 $C$，我们称之为**混杂因素（confounder）**。一个经典的混杂结构可以用[有向无环图](@entry_id:164045)（DAG）来表示：$A \leftarrow C \rightarrow Y$ 。在这个结构中，变量 $C$ 是 $A$ 和 $Y$ 的[共同原因](@entry_id:266381)。例如，在研究饮酒（$A$）与肺癌（$Y$）关系时，吸烟（$C$）就是一个典型的混杂因素，因为吸烟者更可能饮酒（$C \rightarrow A$），同时吸烟本身也会导致肺癌（$C \rightarrow Y$）。

这条经由 $C$ 的 $A \leftarrow C \rightarrow Y$ 路径被称为**后门路径（backdoor path）**。它在 $A$ 和 $Y$ 之间建立了一条非因果的关联通道。因此，我们观察到的 $A$ 与 $Y$ 的原始（crude）关联，实际上是真实因果效应（$A \rightarrow Y$）与这条后门路径所致的虚假关联的混合体。

**分层**的基本思想就是通过“切分”数据来阻断这条后门路径。具体来说，我们将研究人群按照混杂因素 $C$ 的不同水平（或称“层”，strata）进行划分。例如，我们可以将人群分为“吸烟者”层和“非吸烟者”层。在“吸烟者”这一层内部，所有人的 $C$ 值都是相同的（$C=1$），因此 $C$ 无法再作为变量来影响 $A$ 和 $Y$ 的关系；同样，在“非吸烟者”层内（$C=0$），$C$ 的影响也被固定了。通过在每个层内部分别比较暴露组和非暴露组的结局风险，我们就创造了“公平”的比较环境，从而消除了由 $C$ 引起的混杂。

### 分层分析的机制：从组内效应到标准化效应

在每个由混杂因素 $C$ 定义的层 $c$ 内部，我们可以计算**层内特异性效应量（stratum-specific effect measures）**。这些效应量是在一个[同质性](@entry_id:636502)更高的人群亚组中对暴露效应的估计。常用的效应量包括 ：

-   **风险差（Risk Difference, RD）**: $RD_c = P(Y=1 \mid A=1, C=c) - P(Y=1 \mid A=0, C=c)$
-   **风险比（Risk Ratio, RR）**: $RR_c = \frac{P(Y=1 \mid A=1, C=c)}{P(Y=1 \mid A=0, C=c)}$
-   **比值比（Odds Ratio, OR）**: $OR_c = \frac{P(Y=1 \mid A=1, C=c)/P(Y=0 \mid A=1, C=c)}{P(Y=1 \mid A=0, C=c)/P(Y=0 \mid A=0, C=c)}$

然而，我们通常希望得到一个能代表整个目标人群的单一、总结性的效应估计。这就需要**标准化（standardization）**。标准化的核心思想是：将各层内特异性的效应量，通过一个预设的“标准”人群中混杂因素的分布作为权重，进行加权平均，从而得到一个调整后的[边际效应](@entry_id:634982)。

最常用的标准化方法是**直接标准化**。假设我们想估计调整后的边际风险差。首先，我们分别计算在标准人群中，假如所有人都暴露（$A=1$）或所有人都未暴露（$A=0$）时的预期风险：

$R_1^{std} = \sum_{c} P(Y=1 \mid A=1, C=c) P_{std}(C=c)$

$R_0^{std} = \sum_{c} P(Y=1 \mid A=0, C=c) P_{std}(C=c)$

这里，$P_{std}(C=c)$ 是混杂因素 $C$ 在标准人群中的分布（权重）。这个标准人群可以是我们自己的研究人群，也可以是某个外部的目标人群（如全国人口）。然后，标准化的风险差就是这两个标准化风险之差：

$RD_{std} = R_1^{std} - R_0^{std} = \sum_{c} [P(Y=1 \mid A=1, C=c) - P(Y=1 \mid A=0, C=c)] P_{std}(C=c) = \sum_{c} RD_c \cdot P_{std}(C=c)$

这个公式清晰地表明，标准化风险差是层内特异性风险差以标准人群中各层占比为权重的加权平均值 。

通过一个例子可以更清楚地理解这一过程 。一项研究探讨高浓度细颗粒物（$A$）与哮喘发作（$Y$）的关系，社区社会经济地位（$C$）是一个混杂因素。在低社会经济地位（$C=0$）层，暴露组风险为 $0.30$，非暴露组为 $0.20$，风险差为 $0.10$。在高社会经济地位（$C=1$）层，暴露组风险为 $0.10$，非暴露组为 $0.05$，风险差为 $0.05$。研究总人群中，$C=0$ 和 $C=1$ 的比例分别为 $0.4$ 和 $0.6$。

如果我们忽略分层，计算出的**原始风险差（crude risk difference）**约为 $0.14$。然而，使用研究人群的 $C$ 分布作为标准进行标准化，得到的**标准化风险差（standardized risk difference）**为：
$RD_{std} = (0.10) \times 0.4 + (0.05) \times 0.6 = 0.04 + 0.03 = 0.07$。

原始风险差（$0.14$）与标准化风险差（$0.07$）之间的差异，正是由 $C$ 造成的混杂偏倚。原始估计高估了效应，因为暴露（$A=1$）更多地集中在本身哮喘风险就更高的低社会经济地位人群中。分层与标准化成功地校正了这种偏倚。这种原始关联与层内关联方向相反或差异巨大的现象，即是著名的**辛普森悖论（Simpson's Paradox）**。

### 因果推断的基石：分层分析的三个核心假设

分层与标准化之所以能够帮助我们从观察性数据中得到因果效应的有效估计，其背后依赖于三个不可或缺的核心假设 。

1.  **条件可交换性（Conditional Exchangeability）**: 在混杂因素 $C$ 的任何一个给定层内，暴露分配是随机的。用潜在结局（potential outcomes）的语言来说，即 $Y^a \perp A \mid C$。这意味着，在同一社会经济地位的人群中，那些碰巧暴露于高浓度颗粒物的人，和那些没有暴露的人，除了暴露本身外，在其他所有影响哮喘发作的未测量因素上都是可比的。这是“层内不存在未测量混杂”的假设，也是分层能够控制偏倚的根本前提。

2.  **正性（Positivity）**: 在混杂因素 $C$ 的每一个层内，都必须同时存在暴露者和非暴露者。即对于所有 $a$ 和 $c$，$P(A=a \mid C=c) > 0$。这个假设保证了在每个层内我们都有数据进行比较。如果某个社会经济地位的人群中完全没有人暴露，我们就无从知晓在该人群中暴露的效应是什么。

3.  **一致性（Consistency）**: 任何一个个体，其观察到的结局等于其在实际所接受的暴露水平下的潜在结局。即如果一个个体接受了暴露 $A=a$，那么他/她的观察结局 $Y$ 就等于其潜在结局 $Y^a$。这个假设将抽象的潜在结局与我们能实际观测到的数据联系起来。

在这三个假设的共同作用下，我们可以从数学上严谨地证明，一个不可观测的因果量（如平均因果风险差 $\mathbb{E}[Y^1 - Y^0]$）可以被一个完全由可观测数据构成的量（即我们前面定义的标准化风险差）所**识别（identified）**。其推导过程如下：

$\mathbb{E}[Y^a] = \sum_{c} \mathbb{E}[Y^a \mid C=c] P(C=c)$ （[全期望定律](@entry_id:265946)）

$= \sum_{c} \mathbb{E}[Y^a \mid A=a, C=c] P(C=c)$ （根据条件[可交换性](@entry_id:263314)）

$= \sum_{c} \mathbb{E}[Y \mid A=a, C=c] P(C=c)$ （根据一致性）

这个最终的表达式，即标准化公式（也称为g-formula），完全由观测数据构成，从而将因果推断建立在了坚实的理论基础之上。

### 分层分析的进阶议题

#### 效应修饰：识别异质性

在前面的例子中，低社会经济地位层的风险差是 $0.10$，而高社会经济地位层是 $0.05$。效应量在不同层之间存在差异，这种现象被称为**效应量修饰（Effect Measure Modification, EMM）**，或[交互作用](@entry_id:164533)（interaction）。

效应量修饰必须在特定的度量尺度上定义 。
-   当层内特异性**风险差**不同时（$RD_0 \neq RD_1$），我们称在**加法尺度（additive scale）**上存在效应修饰。
-   当层内特异性**风险比**不同时（$RR_0 \neq RR_1$），我们称在**乘法尺度（multiplicative scale）**上存在效应修饰。

一个效应可能在一个尺度上是同质的（homogeneous），而在另一个尺度上是异质的（heterogeneous）。例如，在某研究中，年轻工人的风险从 $0.05$ 增加到 $0.10$（$RD=0.05, RR=2.0$），而年长工人的风险从 $0.20$ 增加到 $0.40$（$RD=0.20, RR=2.0$）。在这个例子中，风险比在年龄组间保持不变，但在加法尺度上，暴露对年长工人的绝对风险影响远大于年轻工人 。

分层是揭示和描述效应量修饰的主要工具 。与混杂（一种需要被消除的偏倚）不同，效应量修饰是因果关系本身的真实特征，它揭示了暴露的效应在不同人群亚组中可能存在差异。报告效应量修饰对于公共卫生决策和临床实践至关重要，因为它有助于识别哪些人群从干预中获益最多或风险最高。

#### 比值的不可坍缩性

在使用比值比（OR）作为效应量时，存在一个独特的统计现象，即**不可坍缩性（non-collapsibility）** 。与风险差和风险比不同，即使某个变量 $Z$ 不是混杂因素（即 $Z$ 与暴露 $A$ 无关），在调整 $Z$ 前后，OR也可能发生变化。

具体来说，即使层内特异性的OR值是恒定的（例如，在每一层OR都等于2），并且暴露在各层间分布均衡（无混杂），合并各层数据后计算出的原始OR也通常不等于层内共同的OR值（例如，可能小于2）。这种差异并非由混杂引起，而是OR这个数学度量本身的性质所致。

这意味着，当使用逻辑回归等模型得到调整后的OR时，它估计的是一个**条件性（conditional）**效应，即在控制了模型中其他变量的条件下，暴露与结局比值的关系。而原始OR则是一个**边际性（marginal）**效应。调整前后的OR值发生变化，本身并不足以作为存在混杂的证据。理解这一点对于正确解释来自逻辑回归模型的结果至关重要。

#### 分层变量的选择：因果知识的运用

既然分层如此重要，我们应该选择哪些变量进行分层呢？答案必须基于我们对问题背后**[因果结构](@entry_id:159914)**的先验知识，而[有向无环图](@entry_id:164045)（DAG）为我们提供了系统化思考的框架。我们的目标是，通过对一组协变量 $\mathcal{S}$ 进行分层（或称“调整”），来阻断所有从暴露 $A$ 到结局 $Y$ 的后门路径 。

根据变量在因果图中的不同角色，我们有如下调整策略  ：
-   **混杂因素（Confounders）**: 必须调整。它们位于后门路径上（如 $A \leftarrow C \rightarrow Y$），调整它们可以阻断非因果关联，减少偏倚。
-   **中介因素（Mediators）**: 如果目标是估计**总因果效应**，则**绝对不能**调整。中介因素位于因果路径上（$A \rightarrow M \rightarrow Y$）。调整中介变量会阻断部分真实因果效应，从而改变我们估计的目标（变为直接效应）。
-   **对撞因子（Colliders）**: **绝对不能**调整。对撞因子是两个变量的共同效应（如 $A \rightarrow L \leftarrow Y$）。调整对撞因子会打开一条原本被阻断的非因果路径，从而**引入**偏倚，这种偏倚被称为对撞分层偏倚（collider-stratification bias）。
-   **[工具变量](@entry_id:142324)（Instrumental Variables）**: 通常不应作为调整变量。工具变量影响暴露但（除通过暴露外）不影响结局（如 $Z \rightarrow A \rightarrow Y$）。调整它们无助于控制混杂，反而可能在存在未测量混杂时放大偏倚。
-   **精确性变量（Precision Variables）**: 可以调整。这类变量仅与结局相关（$P \rightarrow Y$），但与暴露无关。调整它们虽然对于消除偏倚不是必需的，但可以通过减少结局在层内的变异性来提高效应估计的统计**精确性**（减小方差）。

因此，选择分层变量是一个需要深思熟虑的科学决策，而不是简单地将所有可用的变量都放入模型。“厨房水槽式”的调整策略是危险的，可能引入偏倚而非消除它。

### 分层在实践中的挑战

#### 正性假设的挑战与对策

正性假设要求在每个分析的层中都存在暴露者和非暴露者。在现实世界中，这个假设可能被违反，特别是**结构性正性违例（structural positivity violation）**。

例如，一项研究在养老院进行，旨在评估吸烟（$A$）对死亡率（$Y$）的影响，并按年龄组（$L$）分层。如果养老院有一项严格政策，禁止90岁及以上的居民吸烟，那么在“年龄$\ge 90$岁”这一层，吸烟者的数量将为零，即 $P(A=1 \mid L=\text{age} \ge 90) = 0$ 。

在这种情况下，我们无法从数据中直接估计出“假如90岁以上老人吸烟，他们的死亡风险会是多少”。因此，包含这一层的标准化公式无法计算，我们无法通过非参数分层的方法识别出**整个人群**的平均因果效应。

面对正性违例，研究者有几个选择：
1.  **更改目标人群**：将分析限制在满足正性假设的人群子集上（例如，只研究90岁以下的人群）。这是一个有效且诚实的方法，但结论的普适性会受到限制 。
2.  **参数模型外推**：使用[回归模型](@entry_id:163386)（如逻辑回归）在有数据的年龄组中拟合一个关于年龄、吸烟和死亡率之间关系的函数形式，然后利用这个模型去“外推”或预测在90岁以上人群中吸烟的效应。这种方法的有效性完全依赖于模型形式假设的正确性，而这个假设在没有数据支持的区域是无法被验证的。

#### 高维度的诅咒：[稀疏数据](@entry_id:636194)问题

当需要控制的混杂因素很多时，分层会面临**“[维度的诅咒](@entry_id:143920)”（curse of dimensionality）** 。假设我们需要同时对7个协变量进行分层，其中每个变量有2到10个类别不等。总的层数可能是这些类别数的乘积，例如 $4 \times 5 \times 3 \times 2 \times 10 \times 2 \times 3 = 7200$ 个独立的层。

如果研究的总样本量只有2000人，那么平均每个层里只有不到一个人（$2000/7200 \approx 0.28$）。绝大多数层会是空的，而那些非空的层也极不可能同时包含暴露者和非暴露者。这种情况被称为**数据稀疏（sparse data）**。稀疏性导致了实际上的正性违例，使得层内效应估计变得极不稳定甚至不可能。

为了解决这个问题，研究者开发了多种策略：
1.  **减少维度**：基于专业知识，谨慎选择最重要的混杂因素进行分层，或者将多分类变量进行有意义的合并（例如，将年龄分层从10个组减少到3个组）。这需要对研究领域的深入理解，以确保在简化分层的同时不会重新引入显著的混杂 。
2.  **倾向性评分（Propensity Score）**：倾向性评分 $e(x) = P(A=1 \mid X=x)$ 是一个介于0和1之间的标量，它概括了个体具有的所有协变量信息$X$而得到其接受暴露的[条件概率](@entry_id:151013)。一个重要的理论是，如果一组协变量$X$足以控制混杂，那么对单一维度的倾向性评分进行分层或调整，也足以控制由整个$X$向量引起的混杂。通过将一个高维的协变量向量“压缩”成一个一维的倾向性评分，我们可以极大地缓解[维度的诅咒](@entry_id:143920)，在保留混杂控制能力的同时，避免数据稀疏问题。

总之，分层是流行病学和因果推断中一个基础且功能强大的工具。它不仅是一种数据分析技术，更是一种帮助我们清晰思考混杂、效应修饰和因果识别等核心概念的框架。理解其原理、假设和局限性，对于进行严谨的[观察性研究](@entry_id:174507)至关重要。