## 引言
在流行病学研究和临床试验领域，随机化被公认为评估干预措施因果效应的“金标准”。它不仅仅是一种分[配方法](@entry_id:265480)，更是支撑科学结论可靠性的基石。通过一个严谨的概率过程，随机化旨在创建在所有已知和未知基线特征上都具有可比性的研究组，从而有效地控制混杂，使我们能够对干预效果做出无偏的估计。然而，从“抛硬币”这一简单概念到在复杂现实世界研究中成功实施一个稳健的随机化方案，其间存在着巨大的知识鸿沟。研究人员不仅需要理解为何要随机化，更需掌握如何根据具体的研究目标、伦理约束和现实条件，选择并正确执行最合适的随机化程序。

本文旨在系统性地梳理随机化程序的核心知识体系，带领读者深入探索这一关键方法论的理论深度与实践广度。
- 在“**原则与机制**”一章中，我们将回归本源，探讨随机化背后的因果推断逻辑，如潜结果框架与可交换性。同时，我们将详细解析简单随机化、区组随机化、[分层随机化](@entry_id:189937)等基本程序的运作机制、优缺点，并强调分配隐藏等保护措施的绝对重要性。
- 在“**应用与跨学科联系**”一章中，我们将视野扩展至更高级和复杂的场景，讨论[析因设计](@entry_id:166667)、自适应随机化、整群随机试验等前沿设计，并展示随机化原则如何跨越临床试验的边界，在实验室科学等领域发挥作用。此外，我们还将探讨随机化所根植的伦理基础，如临床均衡原则。
- 最后，在“**动手实践**”部分，你将有机会通过具体的计算和编程练习，亲手模拟和评估不同随机化方法的特性，从而将理论知识转化为可操作的技能。

通过这三个层层递进的章节，本文将为你构建一个关于随机化程序的完整知识框架，助你在未来的研究设计中做出更科学、更严谨的决策。

## 原则与机制

### 随机化的因果推理基本原理：[可交换性](@entry_id:263314)与无偏性

在流行病学研究和临床试验中，随机化是评估干预措施因果效应的基石。其核心目标并非随意分配，而是通过一个精心设计的概率过程，创建在所有基线特征上（无论是已知的还是未知的）具有可比性的治疗组和[对照组](@entry_id:188599)。这种可比性使我们能够对干预效果做出无偏估计。

为了从形式上理解这一点，我们采用**潜结果框架（potential outcomes framework）**。对于每一个研究对象，我们设想存在两个潜在一系列结果：$Y(1)$，即该对象接受治疗（treatment）后的结果；以及 $Y(0)$，即该对象接受对照（control）后的结果。对于任何一个个体，我们只能观测到这两个潜结果中的一个，这取决于其实际接受的分配。个体的因果效应定义为 $Y(1) - Y(0)$，而我们通常关心的是**平均因果效应（Average Causal Effect, ACE）**，即 $\mathbb{E}[Y(1) - Y(0)]$。

一个关键的挑战是，我们无法同时观测到同一个人的 $Y(1)$ 和 $Y(0)$。因此，我们转而比较治疗组的平均观测结果 $\mathbb{E}[Y | A=1]$ 和[对照组](@entry_id:188599)的平均观测结果 $\mathbb{E}[Y | A=0]$，其中 $A$ 是一个[指示变量](@entry_id:266428)，$A=1$ 表示分配至治疗组，$A=0$ 表示分配至[对照组](@entry_id:188599)。这两者的差值，即均值差异，能够无偏地估计平均因果效应的充分必要条件是**[可交换性](@entry_id:263314)（exchangeability）**成立。

**[可交换性](@entry_id:263314)**是指潜结果与治疗分配相互独立，形式化表示为 $(Y(0), Y(1)) \perp A$。直观上，这意味着治疗组和[对照组](@entry_id:188599)在接受干预之前是完全可比的；如果两组都未接受治疗，它们的平均结果将会相同，即 $\mathbb{E}[Y(0) | A=1] = \mathbb{E}[Y(0) | A=0]$。同理，如果两组都接受了治疗，它们的平均结果也会相同。在[可交换性](@entry_id:263314)成立的条件下，治疗组的平均观测结果等于群体的平均潜结果$Y(1)$，即 $\mathbb{E}[Y | A=1] = \mathbb{E}[Y(1) | A=1] = \mathbb{E}[Y(1)]$，[对照组](@entry_id:188599)亦然。因此，观测到的均值差异就等于平均因果效应：

$$
\mathbb{E}[Y | A=1] - \mathbb{E}[Y | A=0] = \mathbb{E}[Y(1)] - \mathbb{E}[Y(0)] = \mathbb{E}[Y(1) - Y(0)]
$$

随机化的伟大之处在于，它通过设计保证了可交换性。通过一个与研究对象所有内在属性（包括潜结果和所有基线协变量 $X$）无关的概率过程来分配治疗，我们从机制上打破了分配与潜结果之间的任何系统性关联。

值得强调的是，**可交换性**与**协变量平衡（covariate balance）**是两个不同的概念。随机化保证了在所有可能的随机分配中，任何基线协变量的分布在治疗组和[对照组](@entry_id:188599)之间是**期望上（in expectation）**平衡的。然而，在任何一次具体的试验中，由于纯粹的机遇，我们很可能会观察到某些协变量在组间的分布存在**有限样本不平衡（finite-sample imbalance）**。例如，在一个成功的随机试验中，我们可能偶然发现治疗组有 $60\%$ 的高风险参与者，而[对照组](@entry_id:188599)只有 $40\%$。 这种偶然的不平衡本身并不会破坏估计的**无偏性（unbiasedness）**，因为可交换性这一设计属性依然成立。然而，如果这个不平衡的协变量是结果的一个强预测因子，它会增加我们效应估计的**方差（variance）**，降低估计的**精确性（precision）**。

### 基本随机化程序

理解了随机化的“为何”，我们接下来探讨几种实现随机化的“如何”的基本程序。

#### 简单随机化

**简单随机化（Simple Randomization）**是最直接的方法，它为每个入组的参与者独立地进行一次概率分配，如同抛掷一枚硬币。在一个两臂试验中，每个参与者以概率 $p$（通常为 $0.5$）被分配到治疗组，以概率 $1-p$ 被分配到[对照组](@entry_id:188599)。

这种方法的关键特性是每个分配都是**[独立同分布](@entry_id:169067)（i.i.d.）**的[伯努利试验](@entry_id:268355)。因此，两名不同参与者 $i$ 和 $j$ 同时被分配到治疗组的概率就是 $p \times p = p^2$。 它的主要缺点是，虽然长期来看组别规模会[趋于平衡](@entry_id:150414)，但在有限样本中，尤其是样本量较小时，可能出现严重的数量不平衡。治疗组的总人数 $T$ 是一个服从二项分布 $T \sim \text{Binomial}(n, p)$ 的随机变量，其方差为 $np(1-p)$。 这种数量上的不平衡会降低[统计功效](@entry_id:197129)。

#### 完全随机化

**完全随机化（Complete Randomization）**解决了简单随机化中组别规模不确定的问题。在该设计中，研究者预先设定治疗组和[对照组](@entry_id:188599)的确切人数（例如，在一个总样本量为 $n$ 的试验中，规定治疗组有 $m$ 人）。然后，从 $n$ 名参与者中，所有可能的包含 $m$ 名治疗者的分配方案都以相等的概率被选择。

在完全随机化下，治疗组的总人数 $T$ 是一个固定值 $m$，其方差为 $0$。这确保了最终的组间数量绝对平衡。然而，这种设计也引入了分配间的**依赖性（dependency）**。知道一个人的分配情况会改变对另一个人分配情况的概率判断。例如，两名不同参与者 $i$ 和 $j$ 同时被分配到治疗组的概率不再是 $(m/n)^2$，而是 $\frac{m(m-1)}{n(n-1)}$，因为在为 $i$ 分配治疗后，只剩下 $m-1$ 个治疗名额和 $n-1$ 名待分配者。 完全随机化通常在所有参与者都已入组后一次性进行，不适用于序贯入组的试验。

#### 区组随机化

**区组随机化（Permuted Block Randomization）**结合了前两者的优点，是临床试验中最常用的方法之一。它旨在确保在整个入组期间，治疗组和[对照组](@entry_id:188599)的人数保持大致平衡。

该方法将整个随机序列划分为若干个**区组（blocks）**。在每个大小为 $b$ 的区组内部，精确地包含 $b/2$ 个治疗分配和 $b/2$ 个对照分配（对于 $1:1$ 分配）。这 $b$ 个分配的顺序在区组内被随机排列。

区组随机化有两个核心特性，其权衡取决于**区组大小（block size） $b$** 的选择：

1.  **平衡性**：区组随机化保证在任何时候，两组人数的最大不平衡量不会超过 $b/2$。当每个区组完成时，人数则完全相等。因此，较小的区组（如 $b=2, 4$）能提供更严格的即时平衡。
2.  **可预测性**：这是区组随机化的主要弱点。如果区组大小 $b$ 是固定的且为研究者所知，那么当一个区组即将填满时，下一个分配就可能变得容易预测。例如，在一个大小为 $4$ 的区组中，如果前 $3$ 个分配是“治疗-对照-治疗”，那么第 $4$ 个分配必然是“对照”。这种可预测性可能破坏分配隐藏。

为了克服可预测性的问题，一种常见的改进是使用**随机变化的区组大小**。例如，随机从一个集合（如 $\{4, 6, 8\}$）中抽取区组大小。这样，研究者便无法确切知道当前区组何时结束，从而大大降低了预测下一个分配的可能性，同时保留了区组随机化良好的平衡特性。

### 保护[随机过程](@entry_id:268487)：分配隐藏与设盲

随机化程序的数学完美性必须通过严格的操作实践来保护，否则其科学基础就会瓦解。其中两个最关键的概念是分配隐藏和设盲，它们虽然相关，但目标和作用时期截然不同。

**分配隐藏（Allocation Concealment）**是指保护随机序列，使得负责招募参与者的研究人员在决定一位合格参与者是否入组的最后一刻之前，无法知道或预测即将到来的治疗分配。其唯一目的是防止**选择偏倚（selection bias）**。 如果分配方案可被预知，招募者可能会（有意或无意地）根据他们对患者预后的判断来选择性地安排患者入组，从而将特定类型的患者（例如，病情更重或更轻的）不成比例地分配到某个组。这种行为破坏了随机化旨在建立的组间可比性，即破坏了 $A \perp X$ 的前提。

分配隐藏失败的后果是严重的。在一个设想的模型中，如果招募者预测下一个分配的准确率仅为 $60\%$（即比纯猜测好一点），并且他们利用这个信息将预后较差的患者尽量分入[对照组](@entry_id:188599)，将预后较好的患者分入治疗组，这种行为就足以引入显著的偏倚，导致组间基线风险评分产生系统性差异。

实现分配隐藏的可靠方法包括：
*   **中心化随机服务**：通过电话或安全的网络系统，由一个独立于研究现场的第三方提供分配。只有在参与者被确认合格且不可撤销地入组后，分配结果才被揭晓。
*   **按顺序编号、不透光、密封的信封（SNOSE）**：由数据中心预先准备，信封材质必须不透光，封口有防拆设计，且严格按顺序使用。

与此相对，**设盲（Blinding 或 Masking）**发生在随机分配**之后**，指的是对参与者、干预提供者、数据收集者或结局评估者隐瞒治疗分配信息。设盲的目的是防止**实施偏倚（performance bias）**和**衡量偏倚（detection bias）**。例如，未设盲的患者可能会因为知道自己服用的是安慰剂而改变其行为或报告症状的方式；未设盲的医生可能会给予治疗组患者额外的关注；未设盲的评估者可能会在衡量结局时有系统性的倾向。实现设盲的手段包括使用外观、味道和包装完全相同的安慰剂和活性药物等。

简而言之，分配隐藏保护随机化过程本身，发生在分配**之前或之时**；设盲保护数据的完整性，发生在分配**之后**。一个公开的分配列表完全违背了分配隐藏，但一个试验可以是“开放标签”（即不设盲）的，只要其分配隐藏做得无懈可击。

### 高级随机化设计：精确性与复杂情境

#### [分层随机化](@entry_id:189937)

当存在一个或多个已知对结局有强烈影响的基线变量时，**[分层随机化](@entry_id:189937)（Stratified Randomization）**是提升试验精确性的重要工具。这些强预后变量被称为**分层因素**，例如疾病严重程度、年龄组或在多中心试验中的不同**研究中心**。

其机制是，首先根据这些分层因素将所有参与者划分为互不重叠的**层（strata）**，然后在每一层内部独立地进行随机化（通常是区组随机化）。

[分层随机化](@entry_id:189937)的主要好处是**保证了关键预后变量在治疗组和[对照组](@entry_id:188599)之间的平衡**。如前所述，简单随机化仅保证期望上的平衡，偶然的不平衡会增加估计的方差。通过在设计中强制实现平衡，[分层随机化](@entry_id:189937)能够有效地从治疗效应估计的方差中**消除**由这些分层因素的组间不平衡所引起的变异部分。 例如，在存在显著时间趋势（如季节性变化或学习效应）的试验中，区组随机化本身就可以被视为一种对“入组时间”进行分层的策略，它通过在短暂的时间区组内强制平衡，有效控制了时间趋势对效应估计方差的贡献。

在分析分层随机试验时，通常采用加权平均的方法来合并各层内的效应估计，得到总体的平均治疗效应。例如，一个以各层样本量为权重的估计量 $\hat{\Delta} = \sum_{s=1}^{S} w_{s} ( \bar{Y}_{s1} - \bar{Y}_{s0} )$，其中 $w_{s} = N_{s}/N$，其方差为各层方差的加权和：

$$
\operatorname{Var}(\hat{\Delta}) = \sum_{s=1}^{S} \left( \frac{N_{s}}{N} \right)^{2} \left( \frac{\sigma_{s1}^{2}}{n_{s1}} + \frac{\sigma_{s0}^{2}}{n_{s0}} \right)
$$

其中 $n_{s1}, n_{s0}$ 是 $s$ 层内两组的样本量，$\sigma_{s1}^2, \sigma_{s0}^2$ 是层内的结局方差。

#### 协变量自适应随机化与形式化分配机制

[分层随机化](@entry_id:189937)是更广泛的一类设计——**协变量自适应随机化（Covariate-Adaptive Randomization）**——的特例。在这类设计中，下一个参与者的分配概率 $\pi(X)$ 可以取决于其自身的基线协变量向量 $X$ 以及之前已入组参与者的协变量和分配情况，目的是在多个协变量上动态地最小化不平衡。

在鲁宾因果模型（Rubin Causal Model）的框架下，**分配机制（assignment mechanism）**被形式化地定义为在给定所有预处理变量（包括协变量和所有潜结果）的条件下，治疗分配的[条件概率分布](@entry_id:163069)，即 $P(Z | X, Y(1), Y(0))$。一个设计被称为“随机化”的，意味着这个机制是研究者已知且预先设定的。

对于协变量自适应随机化，其设计关键在于分配概率仅依赖于可观测的协变量 $X$，而与不可观测的潜结果 $(Y(1), Y(0))$ 无关。这意味着分配机制具有如下形式：$P(Z | X, Y(1) , Y(0)) = \pi(X)$。这个属性，即分配在给定协变量 $X$ 的条件下与潜结果独立，正是**条件可忽略性（conditional ignorability）**的定义，记为 $(Y(1), Y(0)) \perp Z | X$。因此，一个设计良好的协变量自适应随机化程序，通过其内在机制，直接**构建**了进行无偏因果推断所需的核心假设。

#### 整群随机化与干预

在许多公共卫生干预中（如疫苗、健康教育、环境改造），一个人的结局很可能受到其社交网络中其他人的治疗状态的影响。这种现象称为**干预（interference）**或溢出效应，它违反了标准因果推断中的一个基本假设——**稳定单位治疗价值假设（Stable Unit Treatment Value Assumption, SUTVA）**。

当干预现象显著时，对个体进行随机化可能导致严重的“污染”：[对照组](@entry_id:188599)的个体会从其被治疗的朋友或邻居那里间接受益，从而稀释了观测到的治疗效果。在这种情况下，**整群随机化（Cluster Randomization）**成为一种有效的设计策略。该设计将社会单元（如村庄、学校、诊所）作为随机化的单位，即整个“群”被作为一个整体分配到治疗组或[对照组](@entry_id:188599)。

整群随机化通过将大部分互动（例如，一个村庄内80%的日常接触）限制在同一治疗臂内，从而**减轻**了组间的干预。然而，它通常无法**消除**干预，因为群组之间仍然存在互动（例如，村庄之间20%的跨村通勤）。因此，这种设计所估计的效应，不再是简单的个体直接效应，而是一个更复杂的、包含了直接效应和残留的间接（溢出）效应的**整群层面政策效应**。

### 随机化的数字骨干：序列的生成

在现代试验中，随机序列几乎都是由计算机生成的。这个过程的核心是**[伪随机数生成器](@entry_id:145648)（Pseudorandom Number Generator, PRNG）**。PRNG是一个确定性算法，它从一个初始值——**种子（seed）**——开始，生成一个看似随机的数字序列。

一个常见的误解是，只要PRNG生成的序列能通过标准的统计检验（如均匀性[卡方检验](@entry_id:174175)），它就适用于临床试验。这种观点是危险的。统计检验只评估序列的**分布特性**，而不能评估其**不可预测性**。

在临床试验的安全模型中，真正的威胁是可预测性。由于PRNG是确定性的，任何能够知道或猜到种子的人都可以完美地重现整个随机序列。如果种子本身很容易被猜到（例如，使用系统时间作为种子），那么分配隐藏就形同虚设。攻击者可以简单地尝试在试验列表生成时间附近的每一个秒数作为种子，直到生成的序列与已知的少数几个分配相匹配，从而破解整个未来的分配列表。

因此，为了确保随机化过程的健壮性，必须使用**[密码学安全伪随机数生成器](@entry_id:637842)（Cryptographically Secure PRNG, CSPRNG）**。CSPRNG的设计目标就是不可预测性，其核心特性是**下一位不可预测性（next-bit unpredictability）**：即使攻击者知道了序列中之前所有的数字，也无法以高于$50\%$的概率猜出下一个二进制位。这一特性直接对抗了试图通过观察早期分配来预测未来分配的选择偏倚威胁。此外，为CSPRNG提供种子的过程也必须安全，即使用来自物理过程的、不可预测的**高熵（high-entropy）**源（如硬件噪音、精确的键盘敲击间隔等）来生成种子。