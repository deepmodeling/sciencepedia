{
    "hands_on_practices": [
        {
            "introduction": "A primary strength of the cross-sectional study is its ability to efficiently estimate the prevalence of a condition or exposure in a well-defined population. This foundational exercise guides you through the essential calculations for turning raw sample data into a meaningful prevalence estimate with a measure of statistical uncertainty. By deriving the standard error and constructing a confidence interval, you will practice a core skill for any epidemiologist and gain a deeper appreciation for how sampling design influences the precision of your findings .",
            "id": "4639611",
            "problem": "A city health department conducts a cross-sectional survey to estimate the point prevalence of a binary chronic condition among adults at a single calendar time. The adult population size is $N = 120{,}000$. On the survey day, the department draws a simple random sample (SRS) without replacement of $n = 2{,}400$ adults from a complete roster. Each sampled adult is assessed for the condition, and $x = 312$ are found to have it. Treat the sampling as SRS without replacement and assume that the measurement is perfect (no misclassification) and there is no nonresponse.\n\nStarting only from the definition of prevalence as a population proportion, the fact that the sampling mechanism is SRS without replacement from a finite population, and the large-sample normal approximation for averages of independent or exchangeable binary variables, derive an expression for the approximate standard error of the sample prevalence that incorporates the finite population correction. Then use this to construct the approximate two-sided $95$ percent confidence interval (CI) for the population prevalence and compute the total width (upper limit minus lower limit) of this CI.\n\nReport only the total CI width as a decimal (not a percentage). Round your answer to four significant figures.",
            "solution": "Let $P$ be the true, unknown prevalence of the chronic condition in the finite population of $N$ adults. This is the parameter of interest. $P$ is the proportion of a binary characteristic, so it can be defined as the mean of indicator variables. Let $Y_i = 1$ if person $i$ has the condition and $Y_i = 0$ otherwise, for $i = 1, \\dots, N$. The population prevalence is $P = \\frac{1}{N} \\sum_{i=1}^{N} Y_i$.\n\nA simple random sample of size $n$ is drawn without replacement. Let $y_1, y_2, \\dots, y_n$ be the indicator variables for the individuals in the sample. The sample prevalence, $\\hat{p}$, is the natural estimator for $P$. It is the sample mean of the indicator variables:\n$$ \\hat{p} = \\frac{1}{n} \\sum_{j=1}^{n} y_j $$\nFrom the given data, a total of $x = 312$ individuals in the sample of size $n = 2{,}400$ have the condition. Thus, the sample prevalence is:\n$$ \\hat{p} = \\frac{x}{n} = \\frac{312}{2{,}400} = 0.13 $$\n\nThe problem requires deriving the standard error of $\\hat{p}$. According to the theory of simple random sampling without replacement, the variance of the sample mean, $\\hat{p}$, is given by:\n$$ \\text{Var}(\\hat{p}) = \\left( \\frac{N-n}{N} \\right) \\frac{S^2}{n} $$\nwhere $S^2$ is the finite population variance, defined as $S^2 = \\frac{1}{N-1} \\sum_{i=1}^{N} (Y_i - P)^2$. The term $\\frac{N-n}{N} = 1 - \\frac{n}{N}$ is the finite population correction (FPC) factor. For a binary variable $Y_i$, the population variance $S^2$ simplifies to:\n$$ S^2 = \\frac{N}{N-1} P(1-P) $$\nThe variance of $\\hat{p}$ is therefore $\\text{Var}(\\hat{p}) = \\left( \\frac{N-n}{N} \\right) \\frac{1}{n} \\frac{N}{N-1} P(1-P) = \\frac{N-n}{n(N-1)} P(1-P)$.\n\nTo construct a confidence interval, we need an estimate of this variance, which in turn requires an estimate of its square root, the standard error $\\text{SE}(\\hat{p})$. We can estimate the unknown variance term $P(1-P)$ using the sample data. A consistent estimator for the population variance $S^2$ is the sample variance $s^2$:\n$$ s^2 = \\frac{1}{n-1} \\sum_{j=1}^{n} (y_j - \\hat{p})^2 $$\nFor binary data, this simplifies to $s^2 = \\frac{n}{n-1} \\hat{p}(1-\\hat{p})$. By substituting $s^2$ for $S^2$ in the variance formula, we obtain an estimator for the variance of $\\hat{p}$:\n$$ \\widehat{\\text{Var}}(\\hat{p}) = \\left( 1 - \\frac{n}{N} \\right) \\frac{s^2}{n} = \\left( 1 - \\frac{n}{N} \\right) \\frac{1}{n} \\left( \\frac{n}{n-1} \\hat{p}(1-\\hat{p}) \\right) = \\left( 1 - \\frac{n}{N} \\right) \\frac{\\hat{p}(1-\\hat{p})}{n-1} $$\nThe approximate standard error of the sample prevalence, $\\text{SE}(\\hat{p})$, is the square root of this estimated variance:\n$$ \\text{SE}(\\hat{p}) = \\sqrt{\\widehat{\\text{Var}}(\\hat{p})} = \\sqrt{\\left( 1 - \\frac{n}{N} \\right) \\frac{\\hat{p}(1-\\hat{p})}{n-1}} $$\nThis expression incorporates the finite population correction as required.\n\nBased on the large-sample normal approximation, an approximate two-sided $95\\%$ confidence interval for the population prevalence $P$ is given by:\n$$ \\hat{p} \\pm z_{1-0.05/2} \\times \\text{SE}(\\hat{p}) $$\nwhere $z_{1-0.05/2} = z_{0.975}$ is the $0.975$ quantile of the standard normal distribution. The value of $z_{0.975}$ is approximately $1.96$.\n\nThe total width, $W$, of this confidence interval is the difference between the upper and lower bounds:\n$$ W = \\left( \\hat{p} + z_{0.975} \\text{SE}(\\hat{p}) \\right) - \\left( \\hat{p} - z_{0.975} \\text{SE}(\\hat{p}) \\right) = 2 z_{0.975} \\text{SE}(\\hat{p}) $$\nSubstituting the derived expression for the standard error:\n$$ W = 2 z_{0.975} \\sqrt{\\left( 1 - \\frac{n}{N} \\right) \\frac{\\hat{p}(1-\\hat{p})}{n-1}} $$\n\nNow, we substitute the given numerical values:\n- $N = 120{,}000$\n- $n = 2{,}400$\n- $\\hat{p} = 0.13$\n- $z_{0.975} \\approx 1.96$\n\nFirst, calculate the FPC factor:\n$$ 1 - \\frac{n}{N} = 1 - \\frac{2{,}400}{120{,}000} = 1 - 0.02 = 0.98 $$\nNext, calculate the variance component:\n$$ \\frac{\\hat{p}(1-\\hat{p})}{n-1} = \\frac{0.13 \\times (1-0.13)}{2{,}400-1} = \\frac{0.13 \\times 0.87}{2{,}399} = \\frac{0.1131}{2{,}399} $$\nNow, compute the standard error:\n$$ \\text{SE}(\\hat{p}) = \\sqrt{0.98 \\times \\frac{0.1131}{2{,}399}} = \\sqrt{0.98 \\times 0.00004714464...} = \\sqrt{0.00004620175...} \\approx 0.006797187 $$\nFinally, calculate the total width of the CI:\n$$ W = 2 \\times 1.96 \\times 0.006797187... = 3.92 \\times 0.006797187... \\approx 0.02664497... $$\nRounding the result to four significant figures, we get $0.02664$.",
            "answer": "$$\n\\boxed{0.02664}\n$$"
        },
        {
            "introduction": "While cross-sectional studies can compare prevalence between groups, these comparisons are highly susceptible to confounding, where a third variable distorts the apparent relationship between an exposure and an outcome. This practice problem presents a classic case of Simpson's Paradox, a situation where an association observed in the overall population is reversed within subgroups. By working through this example and applying direct standardization, you will learn to identify and correct for confounding, a critical skill for interpreting evidence from any observational study .",
            "id": "4639572",
            "problem": "A public health team uses a cross-sectional survey to compare the prevalence of a chronic respiratory condition between two occupational groups: solvent-exposed manufacturing workers (exposed) and office workers (unexposed). The survey classifies participants into two age strata: young and old. Cross-sectional data provide counts of existing cases at the time of survey, and the team seeks to understand how differences in age structure can produce Simpsonâ€™s paradox, where the crude association reverses direction after accounting for stratification.\n\nThe observed counts are:\n- Exposed, young: $200$ total, with $16$ cases.\n- Exposed, old: $800$ total, with $280$ cases.\n- Unexposed, young: $800$ total, with $80$ cases.\n- Unexposed, old: $200$ total, with $80$ cases.\n\nUse only core definitions:\n- Prevalence in a group is the proportion of existing cases in that group.\n- Conditional prevalence within a stratum is the proportion of cases within that stratum.\n- The law of total probability states that the prevalence in a population with stratum weights $\\{w_{1}, w_{2}\\}$ equals $w_{1} \\times \\text{(stratum $1$ prevalence)} + w_{2} \\times \\text{(stratum $2$ prevalence)}$.\n- Direct standardization computes the expected prevalence in each exposure group if both groups shared a common standard stratum distribution.\n\nLet the standard population assign equal weight to each age stratum: $w_{\\text{young}} = 0.5$ and $w_{\\text{old}} = 0.5$. Using the definitions above, compute the directly age-standardized prevalence ratio comparing exposed to unexposed. Express your final answer as a decimal, rounded to three significant figures.",
            "solution": "The solution requires calculating the age-standardized prevalence for both the exposed and unexposed groups and then finding their ratio. This process begins by calculating the stratum-specific prevalences.\n\nLet $P(C|E, Y)$ be the prevalence of the condition ($C$) among the exposed ($E$) who are young ($Y$). Similarly, we define $P(C|E, O)$, $P(C|U, Y)$, and $P(C|U, O)$ for the other three subgroups.\n\nThe stratum-specific prevalences are calculated as follows:\n1.  Prevalence in exposed, young group:\n    $$P(C|E, Y) = \\frac{C_{E,Y}}{N_{E,Y}} = \\frac{16}{200} = 0.08$$\n2.  Prevalence in exposed, old group:\n    $$P(C|E, O) = \\frac{C_{E,O}}{N_{E,O}} = \\frac{280}{800} = 0.35$$\n3.  Prevalence in unexposed, young group:\n    $$P(C|U, Y) = \\frac{C_{U,Y}}{N_{U,Y}} = \\frac{80}{800} = 0.10$$\n4.  Prevalence in unexposed, old group:\n    $$P(C|U, O) = \\frac{C_{U,O}}{N_{U,O}} = \\frac{80}{200} = 0.40$$\n\nNext, we apply the method of direct standardization. This involves creating a weighted average of the stratum-specific prevalences for each exposure group, using the weights from a common standard population. The problem specifies a standard population with equal weights for the young and old strata: $w_{\\text{young}} = 0.5$ and $w_{\\text{old}} = 0.5$.\n\nThe age-standardized prevalence for the exposed group, $P_{\\text{std, E}}$, is calculated using the law of total probability with the standard weights:\n$$P_{\\text{std, E}} = w_{\\text{young}} \\times P(C|E, Y) + w_{\\text{old}} \\times P(C|E, O)$$\n$$P_{\\text{std, E}} = (0.5 \\times 0.08) + (0.5 \\times 0.35) = 0.040 + 0.175 = 0.215$$\n\nSimilarly, the age-standardized prevalence for the unexposed group, $P_{\\text{std, U}}$, is:\n$$P_{\\text{std, U}} = w_{\\text{young}} \\times P(C|U, Y) + w_{\\text{old}} \\times P(C|U, O)$$\n$$P_{\\text{std, U}} = (0.5 \\times 0.10) + (0.5 \\times 0.40) = 0.050 + 0.200 = 0.250$$\n\nFinally, the directly age-standardized prevalence ratio (SPR) is the ratio of the standardized prevalence in the exposed group to that in the unexposed group.\n$$\\text{SPR} = \\frac{P_{\\text{std, E}}}{P_{\\text{std, U}}}$$\n$$\\text{SPR} = \\frac{0.215}{0.250} = 0.86$$\n\nThe problem requires the answer to be expressed as a decimal rounded to three significant figures. The value $0.86$ has two significant figures. To express it with three, we add a trailing zero.\n$$\\text{SPR} = 0.860$$\n\nThis result shows that after adjusting for the differing age structures of the two groups, the prevalence of the condition is lower in the exposed group than in the unexposed group, contrary to the crude (unadjusted) comparison which would suggest a harmful association. This reversal is a hallmark of Simpson's paradox.",
            "answer": "$$\n\\boxed{0.860}\n$$"
        },
        {
            "introduction": "Real-world data is rarely complete, and missing information is a significant limitation of cross-sectional studies that can threaten the validity of their findings. This hands-on exercise explores how different mechanisms of missing data can introduce bias into prevalence estimates. By mathematically deriving and then computing the bias of common handling strategies, such as complete-case analysis and simple imputation, you will gain a rigorous understanding of when and why these methods fail, particularly in the challenging case of data that is Missing Not At Random (MNAR) .",
            "id": "4639581",
            "problem": "A cross-sectional study measures a binary exposure $X \\in \\{0,1\\}$ and a binary outcome $Y \\in \\{0,1\\}$ at a single time point in a target population. The scientific goal is to estimate the true point prevalence of the outcome $Y$, denoted $P(Y=1)$. Let $P(X=1) = p_X$, $P(Y=1 \\mid X=1) = p_1$, and $P(Y=1 \\mid X=0) = p_0$. By the law of total probability, the true prevalence is $P(Y=1) = p_X \\, p_1 + (1 - p_X)\\, p_0$. However, due to nonresponse, the outcome $Y$ is only observed for a subset of individuals. Let $R \\in \\{0,1\\}$ be an indicator that $Y$ is observed ($R=1$) or missing ($R=0$). The observation mechanism is characterized by the conditional probabilities $P(R=1 \\mid X=x, Y=y) = r_{xy}$ for $x \\in \\{0,1\\}, y \\in \\{0,1\\}$. You must derive from first principles (using only fundamental definitions such as the law of total probability and conditional probability) the expected values of two estimators under the specified observation mechanisms:\n\n- The complete-case estimator, which uses only individuals with $R=1$ and computes the expected observed outcome proportion $P(Y=1 \\mid R=1)$.\n\n- The naive within-exposure single imputation estimator, which imputes missing $Y$ values within each exposure stratum $X=x$ using the observed conditional mean $P(Y=1 \\mid R=1, X=x)$, and then averages the within-stratum imputed means over $X$ via $P(X=x)$.\n\nYour program must, for each specified test case:\n- Compute the true prevalence $p = P(Y=1)$ using $p_X$, $p_1$, and $p_0$.\n- Compute the expected complete-case estimate $p_{\\mathrm{cc}} = P(Y=1 \\mid R=1)$ under the specified $r_{xy}$.\n- Compute the expected naive within-exposure single imputation estimate $p_{\\mathrm{imp}}$, which equals $\\sum_{x \\in \\{0,1\\}} P(X=x) \\, P(Y=1 \\mid R=1, X=x)$, where $P(Y=1 \\mid R=1, X=x)$ is determined by the observation mechanism and the joint distribution of $(X,Y)$.\n- Compute the biases $b_{\\mathrm{cc}} = p_{\\mathrm{cc}} - p$ and $b_{\\mathrm{imp}} = p_{\\mathrm{imp}} - p$.\nAll answers must be expressed as decimals (not percentages).\n\nUse the following common parameters across all test cases:\n- $p_X = 0.4$\n- $p_1 = 0.3$\n- $p_0 = 0.1$\n\nUse the following observation mechanism test suite (each line provides $(r_{00}, r_{01}, r_{10}, r_{11})$ in that order):\n- Test case $1$ (Missing Completely At Random (MCAR)): $(0.7, 0.7, 0.7, 0.7)$\n- Test case $2$ (Missing At Random (MAR) depending on $X$ only): $(0.5, 0.5, 0.9, 0.9)$\n- Test case $3$ (Missing Not At Random (MNAR) depending on $Y$ only; lower response if $Y=1$): $(0.95, 0.6, 0.95, 0.6)$\n- Test case $4$ (No missingness boundary): $(1.0, 1.0, 1.0, 1.0)$\n- Test case $5$ (Extreme MNAR; very low response if $Y=1$): $(0.9, 0.1, 0.9, 0.1)$\n\nYour program should output for each test case an ordered list of five floats $[p, p_{\\mathrm{cc}}, b_{\\mathrm{cc}}, p_{\\mathrm{imp}}, b_{\\mathrm{imp}}]$, each rounded to six decimal places. Aggregate all test cases into a single list in the same order as above.\n\nFinal output format: Your program should produce a single line containing a comma-separated list of the five results, enclosed in square brackets, where each result itself is a list in square brackets. For example: $[[a_1,a_2,a_3,a_4,a_5],[\\dots],\\dots]$ with each $a_i$ a float rounded to six decimal places. No extra text should be printed.\n\nNote on scientific realism and study design: Cross-sectional studies estimate $P(Y=1)$ at a single time point and cannot establish temporal ordering between $X$ and $Y$. Their strength for prevalence estimation is undermined by missing data. Under $R \\perp Y \\mid X$ (that is, Missing At Random given $X$), naive within-exposure single imputation using the observed conditional mean can recover unbiased prevalence, while the complete-case estimator can be biased if $R$ depends on $X$ and $X$ is associated with $Y$. Under $R$ depending on $Y$ (Missing Not At Random), both methods can be biased, illustrating a key limitation of cross-sectional designs in the presence of nonignorable missingness.",
            "solution": "The problem requires the derivation and calculation of the true prevalence of an outcome and the expected values of two estimators for this prevalence under various missing data mechanisms. The derivations must proceed from first principles.\n\nLet the binary exposure be $X \\in \\{0, 1\\}$ and the binary outcome be $Y \\in \\{0, 1\\}$. The observation of $Y$ is indicated by $R \\in \\{0, 1\\}$, where $R=1$ denotes that $Y$ is observed.\nThe given parameters are:\n- $P(X=1) = p_X$\n- $P(Y=1 \\mid X=1) = p_1$\n- $P(Y=1 \\mid X=0) = p_0$\n- $P(R=1 \\mid X=x, Y=y) = r_{xy}$\n\nFrom these, we can define complementary probabilities:\n- $P(X=0) = 1 - p_X$\n- $P(Y=0 \\mid X=1) = 1 - p_1$\n- $P(Y=0 \\mid X=0) = 1 - p_0$\n\nFirst, we derive the necessary joint probabilities $P(X=x, Y=y)$ using the definition of conditional probability, $P(A, B) = P(A \\mid B)P(B)$:\n$$P(X=1, Y=1) = P(Y=1 \\mid X=1)P(X=1) = p_1 p_X$$\n$$P(X=1, Y=0) = P(Y=0 \\mid X=1)P(X=1) = (1 - p_1) p_X$$\n$$P(X=0, Y=1) = P(Y=1 \\mid X=0)P(X=0) = p_0 (1 - p_X)$$\n$$P(X=0, Y=0) = P(Y=0 \\mid X=0)P(X=0) = (1 - p_0) (1 - p_X)$$\n\n**1. True Prevalence ($p$)**\nThe true prevalence of the outcome, $p = P(Y=1)$, is derived using the law of total probability, marginalizing over the exposure $X$:\n$$p = P(Y=1) = \\sum_{x \\in \\{0,1\\}} P(Y=1 \\mid X=x)P(X=x)$$\n$$p = P(Y=1 \\mid X=1)P(X=1) + P(Y=1 \\mid X=0)P(X=0)$$\n$$p = p_1 p_X + p_0 (1 - p_X)$$\nThis is the gold standard value against which the estimators will be compared.\n\n**2. Complete-Case Estimator ($p_{\\mathrm{cc}}$)**\nThe expected value of the complete-case estimator is the proportion of outcomes among the observed individuals, which is the conditional probability $p_{\\mathrm{cc}} = P(Y=1 \\mid R=1)$. Using the definition of conditional probability:\n$$p_{\\mathrm{cc}} = P(Y=1 \\mid R=1) = \\frac{P(Y=1, R=1)}{P(R=1)}$$\nWe must derive expressions for the numerator and denominator.\nThe numerator, $P(Y=1, R=1)$, is the joint probability of having the outcome and being observed. We find this by marginalizing over $X$:\n$$P(Y=1, R=1) = \\sum_{x \\in \\{0,1\\}} P(X=x, Y=1, R=1)$$\nUsing the chain rule, $P(A,B,C) = P(C \\mid A,B) P(A,B)$:\n$$P(Y=1, R=1) = P(R=1 \\mid X=1, Y=1)P(X=1, Y=1) + P(R=1 \\mid X=0, Y=1)P(X=0, Y=1)$$\n$$P(Y=1, R=1) = r_{11} (p_1 p_X) + r_{01} (p_0 (1 - p_X))$$\nThe denominator, $P(R=1)$, is the overall probability of being observed. We find this by marginalizing over both $X$ and $Y$:\n$$P(R=1) = \\sum_{x \\in \\{0,1\\}} \\sum_{y \\in \\{0,1\\}} P(X=x, Y=y, R=1)$$\n$$P(R=1) = P(R=1 \\mid X=1, Y=1)P(X=1, Y=1) + P(R=1 \\mid X=1, Y=0)P(X=1, Y=0) + P(R=1 \\mid X=0, Y=1)P(X=0, Y=1) + P(R=1 \\mid X=0, Y=0)P(X=0, Y=0)$$\n$$P(R=1) = r_{11} p_1 p_X + r_{10} (1 - p_1) p_X + r_{01} p_0 (1 - p_X) + r_{00} (1 - p_0) (1 - p_X)$$\nCombining these, the complete-case estimator is:\n$$p_{\\mathrm{cc}} = \\frac{r_{11} p_1 p_X + r_{01} p_0 (1 - p_X)}{r_{11} p_1 p_X + r_{10} (1 - p_1) p_X + r_{01} p_0 (1 - p_X) + r_{00} (1 - p_0) (1 - p_X)}$$\n\n**3. Naive Within-Exposure Single Imputation Estimator ($p_{\\mathrm{imp}}$)**\nThe expected value of this estimator is defined as $p_{\\mathrm{imp}} = \\sum_{x \\in \\{0,1\\}} P(X=x) \\, P(Y=1 \\mid R=1, X=x)$. This requires calculating the prevalence of the outcome within each exposure stratum, restricted to the observed subjects.\nFor the stratum $X=1$:\n$$P(Y=1 \\mid R=1, X=1) = \\frac{P(Y=1, R=1, X=1)}{P(R=1, X=1)}$$\nThe numerator is $P(R=1 \\mid Y=1, X=1)P(Y=1 \\mid X=1)P(X=1) = r_{11} p_1 p_X$. We need $P(R=1, X=1)$, found by marginalizing over $Y$:\n$$P(R=1, X=1) = P(R=1 \\mid Y=1, X=1)P(Y=1,X=1) + P(R=1 \\mid Y=0, X=1)P(Y=0,X=1)$$\n$$P(R=1, X=1) = r_{11} p_1 p_X + r_{10} (1-p_1) p_X = p_X (r_{11} p_1 + r_{10} (1-p_1))$$\nTherefore, the desired conditional probability is:\n$$P(Y=1 \\mid R=1, X=1) = \\frac{r_{11} p_1 p_X}{p_X (r_{11} p_1 + r_{10} (1-p_1))} = \\frac{r_{11} p_1}{r_{11} p_1 + r_{10}(1-p_1)}$$\nSimilarly, for the stratum $X=0$:\n$$P(Y=1 \\mid R=1, X=0) = \\frac{P(Y=1, R=1, X=0)}{P(R=1, X=0)}$$\n$$P(Y=1 \\mid R=1, X=0) = \\frac{r_{01} p_0 (1-p_X)}{(1-p_X)(r_{01} p_0 + r_{00}(1-p_0))} = \\frac{r_{01} p_0}{r_{01} p_0 + r_{00}(1-p_0)}$$\nSubstituting these into the formula for $p_{\\mathrm{imp}}$:\n$$p_{\\mathrm{imp}} = p_X \\left( \\frac{r_{11} p_1}{r_{11} p_1 + r_{10}(1-p_1)} \\right) + (1-p_X) \\left( \\frac{r_{01} p_0}{r_{01} p_0 + r_{00}(1-p_0)} \\right)$$\nThese expressions for $p$, $p_{\\mathrm{cc}}$, and $p_{\\mathrm{imp}}$ allow for direct calculation given the problem parameters.\n\n**4. Biases ($b_{\\mathrm{cc}}$ and $b_{\\mathrm{imp}}$)**\nThe biases of the two estimators are defined as the difference between their expected values and the true prevalence:\n$$b_{\\mathrm{cc}} = p_{\\mathrm{cc}} - p$$\n$$b_{\\mathrm{imp}} = p_{\\mathrm{imp}} - p$$\nThese formulae will be implemented to compute the required values for each test case.",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the epidemiology missing data problem for all specified test cases.\n    \"\"\"\n    # Common parameters across all test cases\n    pX = 0.4  # P(X=1)\n    p1 = 0.3  # P(Y=1 | X=1)\n    p0 = 0.1  # P(Y=1 | X=0)\n\n    # Observation mechanism test suite: (r00, r01, r10, r11)\n    test_cases = [\n        (0.7, 0.7, 0.7, 0.7),  # 1. MCAR\n        (0.5, 0.5, 0.9, 0.9),  # 2. MAR on X\n        (0.95, 0.6, 0.95, 0.6), # 3. MNAR on Y\n        (1.0, 1.0, 1.0, 1.0),  # 4. No missingness\n        (0.9, 0.1, 0.9, 0.1),   # 5. Extreme MNAR on Y\n    ]\n\n    # --- Pre-calculate constant probabilities ---\n    pX0 = 1 - pX # P(X=0)\n    \n    # Joint probabilities P(X=x, Y=y)\n    p_x1_y1 = p1 * pX\n    p_x1_y0 = (1 - p1) * pX\n    p_x0_y1 = p0 * pX0\n    p_x0_y0 = (1 - p0) * pX0\n    \n    # 1. True Prevalence (p)\n    p_true = p_x1_y1 + p_x0_y1\n    # Alternative calculation: p_true = p1 * pX + p0 * pX0\n\n    all_results = []\n\n    for case in test_cases:\n        r00, r01, r10, r11 = case\n\n        # 2. Complete-Case Estimator (p_cc)\n        # Numerator: P(Y=1, R=1) = r11*P(X=1,Y=1) + r01*P(X=0,Y=1)\n        p_y1_r1 = r11 * p_x1_y1 + r01 * p_x0_y1\n        \n        # Denominator: P(R=1) = sum_{x,y} r_xy * P(X=x,Y=y)\n        p_r1 = (r11 * p_x1_y1 + \n                r10 * p_x1_y0 + \n                r01 * p_x0_y1 + \n                r00 * p_x0_y0)\n\n        if p_r1 == 0:\n            p_cc = np.nan  # Or other appropriate value for this undefined case\n        else:\n            p_cc = p_y1_r1 / p_r1\n\n        # 3. Naive Within-Exposure Single Imputation Estimator (p_imp)\n        # Stratum X=1: P(Y=1 | R=1, X=1)\n        denom_imp_x1 = r11 * p1 + r10 * (1 - p1)\n        if denom_imp_x1 == 0:\n            p_y1_cond_r1_x1 = 0 # No observed subjects in this stratum to impute from\n        else:\n            p_y1_cond_r1_x1 = (r11 * p1) / denom_imp_x1\n        \n        # Stratum X=0: P(Y=1 | R=1, X=0)\n        denom_imp_x0 = r01 * p0 + r00 * (1 - p0)\n        if denom_imp_x0 == 0:\n            p_y1_cond_r1_x0 = 0 # No observed subjects in this stratum to impute from\n        else:\n            p_y1_cond_r1_x0 = (r01 * p0) / denom_imp_x0\n            \n        p_imp = pX * p_y1_cond_r1_x1 + pX0 * p_y1_cond_r1_x0\n\n        # 4. Biases\n        b_cc = p_cc - p_true\n        b_imp = p_imp - p_true\n        \n        # Store results for this case\n        result_list = [p_true, p_cc, b_cc, p_imp, b_imp]\n        \n        # Format the list of floats into strings with 6 decimal places\n        formatted_list = [f\"{v:.6f}\" for v in result_list]\n        \n        # Append the formatted list as a string \"[v1,v2,...]\"\n        all_results.append(f\"[{','.join(formatted_list)}]\")\n\n    # Final print statement in the exact required format\n    print(f\"[{','.join(all_results)}]\")\n\nsolve()\n\n```"
        }
    ]
}