{
    "hands_on_practices": [
        {
            "introduction": "A core challenge in designing any surveillance system is balancing the need to detect as many true cases as possible (sensitivity) with the need to avoid false alarms (specificity). One common strategy to increase case detection is to combine multiple data streams or tests. This practice explores the mathematical consequences of combining two independent diagnostic streams in parallel, where an alarm is triggered if either stream is positive.\n\nBy working through the calculations in this problem , you will gain a quantitative understanding of the critical trade-offs in surveillance design. You will see firsthand how this approach, while boosting overall sensitivity, can negatively impact specificity and, in low-prevalence settings, the Positive Predictive Value ($PPV$), which is the probability that an alarm represents a true case. This exercise is fundamental to appreciating why \"more data\" does not always lead to better predictive performance.",
            "id": "4592268",
            "problem": "A public health department operates an automated infectious disease surveillance system that issues an alarm when a decision rule is met. There is an existing primary stream that, at the current decision threshold, identifies infected cases with sensitivity $Se_{1}$ and identifies non-infected cases with specificity $Sp_{1}$. The system is deployed in a population with infection prevalence $\\pi$. The department considers adding a second, independent auxiliary stream characterized by low sensitivity and high specificity, with sensitivity $Se_{2}$ and specificity $Sp_{2}$. After addition, the decision threshold is held fixed so that the combined system issues an alarm if at least one of the two streams flags positive. Assume conditional independence of the streams given infection status (infected versus not infected). Use the following parameters: $Se_{1} = 0.85$, $Sp_{1} = 0.95$, $Se_{2} = 0.30$, $Sp_{2} = 0.99$, and $\\pi = 0.01$. Using fundamental definitions, compute the ratio $\\rho$ of the change in Positive Predictive Value (PPV) to the change in false alarm rate, where false alarm rate is defined as the probability of an alarm when infection is absent. Specifically, let $\\Delta PPV = PPV_{\\text{after}} - PPV_{\\text{before}}$ and $\\Delta FAR = FAR_{\\text{after}} - FAR_{\\text{before}}$, and define $\\rho = \\frac{\\Delta PPV}{\\Delta FAR}$. Express your answer as a decimal and round your final answer to four significant figures.",
            "solution": "The problem is evaluated to be scientifically grounded, well-posed, objective, and internally consistent. It is a standard problem in the evaluation of diagnostic or surveillance systems. I will proceed with a full solution.\n\nLet $I$ be the event that an individual is infected, and $I^c$ be the event that an individual is not infected. The prevalence of the infection is given as $\\pi = P(I) = 0.01$. Consequently, $P(I^c) = 1 - \\pi = 1 - 0.01 = 0.99$.\n\nLet $T_1$ be the event that the primary stream flags a case as positive, and $T_2$ be the event that the auxiliary stream flags a case as positive. The test results are assumed to be conditionally independent given the true infection status.\n\nThe fundamental definitions are:\n- Sensitivity ($Se$): $P(\\text{Test Positive} | I)$\n- Specificity ($Sp$): $P(\\text{Test Negative} | I^c)$\n- Positive Predictive Value ($PPV$): $P(I | \\text{Test Positive})$\n- False Alarm Rate ($FAR$): $P(\\text{Test Positive} | I^c)$. Note that $FAR = 1 - P(\\text{Test Negative} | I^c) = 1 - Sp$.\n\nThe given parameters are:\n- Primary stream: $Se_1 = 0.85$, $Sp_1 = 0.95$\n- Auxiliary stream: $Se_2 = 0.30$, $Sp_2 = 0.99$\n\n**1. Analysis of the System Before Adding the Auxiliary Stream (Primary Stream Only)**\n\nThe system \"before\" consists only of the primary stream. Let the total probability of a positive test be $P(T_1)$.\nThe false alarm rate before, $FAR_{\\text{before}}$, is the probability of a positive test from stream 1 given absence of infection:\n$$FAR_{\\text{before}} = P(T_1 | I^c) = 1 - Sp_1$$\nSubstituting the given value for $Sp_1$:\n$$FAR_{\\text{before}} = 1 - 0.95 = 0.05$$\n\nThe positive predictive value before, $PPV_{\\text{before}}$, is calculated using Bayes' theorem:\n$$PPV_{\\text{before}} = P(I | T_1) = \\frac{P(T_1 | I) P(I)}{P(T_1)}$$\nThe denominator $P(T_1)$ is found using the law of total probability:\n$$P(T_1) = P(T_1 | I) P(I) + P(T_1 | I^c) P(I^c)$$\n$$P(T_1) = Se_1 \\pi + (1 - Sp_1)(1 - \\pi)$$\nSubstituting the numerical values:\n$$P(T_1) = (0.85)(0.01) + (1 - 0.95)(1 - 0.01) = 0.0085 + (0.05)(0.99) = 0.0085 + 0.0495 = 0.058$$\nNow, we can compute $PPV_{\\text{before}}$:\n$$PPV_{\\text{before}} = \\frac{Se_1 \\pi}{P(T_1)} = \\frac{(0.85)(0.01)}{0.058} = \\frac{0.0085}{0.058}$$\n\n**2. Analysis of the System After Adding the Auxiliary Stream (Combined System)**\n\nThe combined system issues an alarm if at least one stream is positive. Let this event be $T_{\\text{comb}} = T_1 \\cup T_2$. We need to find the sensitivity ($Se_{\\text{comb}}$) and specificity ($Sp_{\\text{comb}}$) of this combined test.\n\nThe sensitivity of the combined system is:\n$$Se_{\\text{comb}} = P(T_1 \\cup T_2 | I) = 1 - P((T_1 \\cup T_2)^c | I) = 1 - P(T_1^c \\cap T_2^c | I)$$\nUsing conditional independence, $P(T_1^c \\cap T_2^c | I) = P(T_1^c | I) P(T_2^c | I)$.\nWe know $P(T_1^c | I) = 1 - P(T_1 | I) = 1 - Se_1$, and similarly $P(T_2^c | I) = 1 - Se_2$.\n$$Se_{\\text{comb}} = 1 - (1 - Se_1)(1 - Se_2)$$\nSubstituting the numerical values:\n$$Se_{\\text{comb}} = 1 - (1 - 0.85)(1 - 0.30) = 1 - (0.15)(0.70) = 1 - 0.105 = 0.895$$\n\nThe specificity of the combined system is:\n$$Sp_{\\text{comb}} = P((T_1 \\cup T_2)^c | I^c) = P(T_1^c \\cap T_2^c | I^c)$$\nUsing conditional independence, $P(T_1^c \\cap T_2^c | I^c) = P(T_1^c | I^c) P(T_2^c | I^c)$.\nWe know $P(T_1^c | I^c) = Sp_1$ and $P(T_2^c | I^c) = Sp_2$.\n$$Sp_{\\text{comb}} = Sp_1 Sp_2$$\nSubstituting the numerical values:\n$$Sp_{\\text{comb}} = (0.95)(0.99) = 0.9405$$\n\nNow, we compute the false alarm rate and PPV for the combined system.\nThe false alarm rate after, $FAR_{\\text{after}}$, is:\n$$FAR_{\\text{after}} = P(T_{\\text{comb}} | I^c) = 1 - Sp_{\\text{comb}} = 1 - 0.9405 = 0.0595$$\n\nThe positive predictive value after, $PPV_{\\text{after}}$, is:\n$$PPV_{\\text{after}} = P(I | T_{\\text{comb}}) = \\frac{P(T_{\\text{comb}} | I) P(I)}{P(T_{\\text{comb}})}$$\nThe denominator $P(T_{\\text{comb}})$ is:\n$$P(T_{\\text{comb}}) = P(T_{\\text{comb}} | I) P(I) + P(T_{\\text{comb}} | I^c) P(I^c)$$\n$$P(T_{\\text{comb}}) = Se_{\\text{comb}} \\pi + (1 - Sp_{\\text{comb}})(1 - \\pi)$$\nSubstituting the numerical values:\n$$P(T_{\\text{comb}}) = (0.895)(0.01) + (1 - 0.9405)(1 - 0.01) = 0.00895 + (0.0595)(0.99)$$\n$$P(T_{\\text{comb}}) = 0.00895 + 0.058905 = 0.067855$$\nNow, we can compute $PPV_{\\text{after}}$:\n$$PPV_{\\text{after}} = \\frac{Se_{\\text{comb}} \\pi}{P(T_{\\text{comb}})} = \\frac{(0.895)(0.01)}{0.067855} = \\frac{0.00895}{0.067855}$$\n\n**3. Calculation of the Ratio $\\rho$**\n\nFirst, we calculate the change in the false alarm rate, $\\Delta FAR$:\n$$\\Delta FAR = FAR_{\\text{after}} - FAR_{\\text{before}} = 0.0595 - 0.05 = 0.0095$$\n\nNext, we calculate the change in the positive predictive value, $\\Delta PPV$:\n$$\\Delta PPV = PPV_{\\text{after}} - PPV_{\\text{before}} = \\frac{0.00895}{0.067855} - \\frac{0.0085}{0.058}$$\nNumerically, this is:\n$$\\Delta PPV \\approx 0.1318989 - 0.1465517 = -0.0146528$$\n\nFinally, we compute the ratio $\\rho = \\frac{\\Delta PPV}{\\Delta FAR}$:\n$$\\rho = \\frac{-0.0146528}{0.0095} \\approx -1.54240$$\n\nRounding the result to four significant figures, we get $-1.542$.",
            "answer": "$$\\boxed{-1.542}$$"
        },
        {
            "introduction": "Surveillance data is only as good as its ability to reflect the reality of disease in the population. Sentinel surveillance networks, which collect data from a subset of healthcare providers, are a cost-effective monitoring tool, but they are rarely a perfect microcosm of the entire community. When participation in the network varies across different demographic groups, such as age strata, the raw data can present a skewed picture of disease incidence, a failure of the \"representativeness\" attribute.\n\nThis exercise  provides a hands-on opportunity to address this common source of bias. You will learn to apply coverage-adjusted weighting, a fundamental technique to correct for unrepresentative sampling in a stratified population. By comparing the naive, unadjusted incidence rate to the corrected rate, you will clearly see how failing to account for surveillance system structure can lead to significant underestimation or overestimation of the true disease burden.",
            "id": "4592233",
            "problem": "A regional Acute Respiratory Infection (ARI) sentinel physician network reports age-stratified new case counts over a $12$-week period. Because the network is not fully representative, the fraction of providers participating differs by age group. Assume that within each age group the risk of ARI among patients seen by participating providers is the same as among patients seen by non-participating providers, and that incidence is defined as the number of new cases divided by the population at risk over the period.\n\nData for the three age groups are:\n- Ages $0$–$17$: observed cases $80$, provider participation fraction $0.25$, population $52{,}000$.\n- Ages $18$–$64$: observed cases $220$, provider participation fraction $0.10$, population $130{,}000$.\n- Ages $\\geq 65$: observed cases $100$, provider participation fraction $0.40$, population $26{,}000$.\n\nUsing first principles:\n1. Estimate the coverage-adjusted weighted incidence per $100{,}000$ persons over the $12$-week period by inferring the total number of cases in the population for each age group from the observed counts and participation fractions, and aggregating across age groups relative to the total population.\n2. Compute the naive crude incidence per $100{,}000$ persons obtained by aggregating observed sentinel counts across age groups and dividing by the total population, ignoring differences in participation fractions.\n3. Let $R$ be the ratio of the naive crude incidence to the coverage-adjusted weighted incidence. Report $R$ as a unitless decimal.\n\nExpress all incidence rates per $100{,}000$ persons. Round the final ratio $R$ to four significant figures. Provide only the value of $R$ as your final answer.",
            "solution": "The problem requires the calculation of two types of incidence rates from sentinel surveillance data and their ratio. First, the problem is validated to be scientifically sound, well-posed, and objective. The provided data are sufficient and consistent.\n\nLet the three age groups be indexed by $i=1, 2, 3$, corresponding to ages $0$–$17$, $18$–$64$, and $\\geq 65$, respectively. The provided data for each group are:\n- Observed cases: $C_{obs,i}$\n- Provider participation fraction: $f_i$\n- Population size: $N_i$\n\nThe specific values are:\n- For $i=1$: $C_{obs,1}=80$, $f_1=0.25$, $N_1=52000$.\n- For $i=2$: $C_{obs,2}=220$, $f_2=0.10$, $N_2=130000$.\n- For $i=3$: $C_{obs,3}=100$, $f_3=0.40$, $N_3=26000$.\n\nThe problem states that incidence is defined as the number of new cases divided by the population at risk over the $12$-week period. It is also assumed that the risk of Acute Respiratory Infection (ARI) is homogeneous within each age group, regardless of whether patients are seen by participating or non-participating providers. This assumption allows us to estimate the total number of cases in each age group, $C_{total,i}$, by scaling the observed cases by the inverse of the participation fraction:\n$$C_{total,i} = \\frac{C_{obs,i}}{f_i}$$\n\nThe problem asks for three calculations in sequence.\n\n1.  **Coverage-adjusted weighted incidence ($I_{adj}$)**\n    This incidence rate is based on the total estimated cases for the entire population, adjusted for the incomplete coverage of the sentinel network.\n    The total estimated number of cases in the population is the sum of the estimated cases from each age group:\n    $$C_{total} = \\sum_{i=1}^{3} C_{total,i} = \\sum_{i=1}^{3} \\frac{C_{obs,i}}{f_i}$$\n    The total population at risk is the sum of the populations of the age groups:\n    $$N_{total} = \\sum_{i=1}^{3} N_i$$\n    The coverage-adjusted incidence rate per $100{,}000$ persons is therefore:\n    $$I_{adj} = \\left( \\frac{C_{total}}{N_{total}} \\right) \\times 100000 = \\left( \\frac{\\sum_{i=1}^{3} \\frac{C_{obs,i}}{f_i}}{\\sum_{i=1}^{3} N_i} \\right) \\times 100000$$\n\n2.  **Naive crude incidence ($I_{naive}$)**\n    This incidence rate is calculated by using only the observed case counts without adjustment for coverage.\n    The total number of observed cases is:\n    $$C_{obs,total} = \\sum_{i=1}^{3} C_{obs,i}$$\n    The naive crude incidence rate per $100{,}000$ persons is:\n    $$I_{naive} = \\left( \\frac{C_{obs,total}}{N_{total}} \\right) \\times 100000 = \\left( \\frac{\\sum_{i=1}^{3} C_{obs,i}}{\\sum_{i=1}^{3} N_i} \\right) \\times 100000$$\n\n3.  **Ratio $R$**\n    The ratio $R$ is defined as the naive crude incidence divided by the coverage-adjusted weighted incidence.\n    $$R = \\frac{I_{naive}}{I_{adj}} = \\frac{\\left( \\frac{\\sum_{i=1}^{3} C_{obs,i}}{\\sum_{i=1}^{3} N_i} \\right) \\times 100000}{\\left( \\frac{\\sum_{i=1}^{3} \\frac{C_{obs,i}}{f_i}}{\\sum_{i=1}^{3} N_i} \\right) \\times 100000}$$\n    The terms for the total population ($N_{total} = \\sum N_i$) and the scaling factor of $100000$ cancel out, simplifying the expression for $R$ to the ratio of the total observed cases to the total estimated cases:\n    $$R = \\frac{\\sum_{i=1}^{3} C_{obs,i}}{\\sum_{i=1}^{3} \\frac{C_{obs,i}}{f_i}} = \\frac{C_{obs,total}}{C_{total}}$$\n\nNow, we substitute the numerical values into the expression for $R$.\nFirst, calculate the numerator, the total number of observed cases:\n$$C_{obs,total} = 80 + 220 + 100 = 400$$\nNext, calculate the denominator, the total estimated number of cases:\n$$C_{total} = \\frac{80}{0.25} + \\frac{220}{0.10} + \\frac{100}{0.40}$$\n$$C_{total} = 320 + 2200 + 250 = 2770$$\nNow, we can compute the ratio $R$:\n$$R = \\frac{400}{2770} = \\frac{40}{277}$$\nAs a decimal, this value is:\n$$R \\approx 0.14440433213...$$\nThe problem requires the final answer to be rounded to four significant figures. The fifth significant figure is $0$, so we round down.\n$$R \\approx 0.1444$$\nThe value of $R$ being significantly less than $1$ indicates that the naive incidence, which ignores surveillance coverage, substantially underestimates the true population incidence estimated by the coverage-adjusted method. This is primarily due to the very low participation fraction ($f_2=0.10$) in the largest population group (ages $18$–$64$).",
            "answer": "$$\\boxed{0.1444}$$"
        },
        {
            "introduction": "The number of cases officially tallied by a surveillance system often represents only the \"tip of the iceberg.\" For every reported case, many other infections may go uncounted because individuals did not seek care, were not tested, or their positive test was not reported to health authorities. Estimating the true burden of disease requires us to model this entire cascade of events, often called the \"surveillance pyramid.\"\n\nThis advanced practice  guides you through a modern, sophisticated approach to this very challenge. You will construct a Bayesian model that integrates uncertainty at each stage of the surveillance pyramid—care seeking, testing, and reporting—to infer the total number of infections from the observed number of reported cases. Engaging with this problem will provide experience with a powerful method that moves beyond simple point estimates to produce a more complete and statistically rigorous picture of disease burden, including credible intervals that quantify our uncertainty.",
            "id": "4592145",
            "problem": "You are tasked with evaluating the sensitivity-related attribute of a public health surveillance system by inferring the total number of infections from reported cases, given stage-specific probabilities for care seeking, testing, and reporting. Consider a population in which each infection proceeds through three independent stages: care seeking, diagnostic testing (conditional on care seeking), and reporting (conditional on a positive test). Let the corresponding stage probabilities be $p_{\\mathrm{care}}$, $p_{\\mathrm{test}}$, and $p_{\\mathrm{report}}$, respectively. Assume the following generative model and priors:\n\n- The per-infection probability of being reported is $p = p_{\\mathrm{care}} \\cdot p_{\\mathrm{test}} \\cdot p_{\\mathrm{report}}$.\n- Given $I$ total infections and per-infection reporting probability $p$, the number of reported cases $R$ follows a binomial distribution $R \\mid I, p \\sim \\mathrm{Binomial}(I, p)$.\n- The stage probabilities are independent a priori and each follows a Beta distribution: $p_{\\mathrm{care}} \\sim \\mathrm{Beta}(\\alpha_{\\mathrm{care}}, \\beta_{\\mathrm{care}})$, $p_{\\mathrm{test}} \\sim \\mathrm{Beta}(\\alpha_{\\mathrm{test}}, \\beta_{\\mathrm{test}})$, and $p_{\\mathrm{report}} \\sim \\mathrm{Beta}(\\alpha_{\\mathrm{report}}, \\beta_{\\mathrm{report}})$.\n- The prior for the total number of infections $I$ is discrete uniform on the integer set $\\{R, R+1, \\dots, N_{\\max}\\}$, that is, $I \\sim \\mathrm{Uniform}\\{R, \\dots, N_{\\max}\\}$.\n\nYour goal is to compute, for each specified test case, the posterior distribution of $I$ given the observed $R$ and the stage-specific Beta priors, by integrating out the unknown $p$. From this posterior, compute the posterior mean of $I$ and the equal-tailed $0.95$ credible interval endpoints (i.e., the $0.025$ and $0.975$ quantiles). All quantities are unitless counts or probabilities; do not use any percentage symbols. Report the credible interval endpoints as numbers, not as percentages.\n\nFormulate your solution from first principles using Bayes’ theorem and properties of expectations and variances under independence. You may use any mathematically justified approximation to evaluate the integral over $p$ implied by the model, provided your method is numerically stable and consistent with the stated assumptions.\n\nImplement a program that processes the following test suite. Each test case is given as a tuple $(R, N_{\\max}, (\\alpha_{\\mathrm{care}}, \\beta_{\\mathrm{care}}), (\\alpha_{\\mathrm{test}}, \\beta_{\\mathrm{test}}), (\\alpha_{\\mathrm{report}}, \\beta_{\\mathrm{report}}))$:\n\n- Test case $1$ (general case):\n  - $R = 120$\n  - $N_{\\max} = 2000$\n  - $(\\alpha_{\\mathrm{care}}, \\beta_{\\mathrm{care}}) = (40, 60)$\n  - $(\\alpha_{\\mathrm{test}}, \\beta_{\\mathrm{test}}) = (70, 30)$\n  - $(\\alpha_{\\mathrm{report}}, \\beta_{\\mathrm{report}}) = (90, 10)$\n\n- Test case $2$ (boundary with zero reports):\n  - $R = 0$\n  - $N_{\\max} = 500$\n  - $(\\alpha_{\\mathrm{care}}, \\beta_{\\mathrm{care}}) = (30, 70)$\n  - $(\\alpha_{\\mathrm{test}}, \\beta_{\\mathrm{test}}) = (50, 50)$\n  - $(\\alpha_{\\mathrm{report}}, \\beta_{\\mathrm{report}}) = (80, 20)$\n\n- Test case $3$ (degenerate upper bound $N_{\\max} = R$):\n  - $R = 25$\n  - $N_{\\max} = 25$\n  - $(\\alpha_{\\mathrm{care}}, \\beta_{\\mathrm{care}}) = (60, 40)$\n  - $(\\alpha_{\\mathrm{test}}, \\beta_{\\mathrm{test}}) = (40, 60)$\n  - $(\\alpha_{\\mathrm{report}}, \\beta_{\\mathrm{report}}) = (50, 50)$\n\n- Test case $4$ (low overall reporting probability):\n  - $R = 50$\n  - $N_{\\max} = 2000$\n  - $(\\alpha_{\\mathrm{care}}, \\beta_{\\mathrm{care}}) = (20, 80)$\n  - $(\\alpha_{\\mathrm{test}}, \\beta_{\\mathrm{test}}) = (30, 70)$\n  - $(\\alpha_{\\mathrm{report}}, \\beta_{\\mathrm{report}}) = (50, 50)$\n\nFor each test case, compute:\n- The posterior mean of $I$.\n- The lower endpoint at cumulative probability $0.025$ of the posterior of $I$.\n- The upper endpoint at cumulative probability $0.975$ of the posterior of $I$.\n\nRound all three reported values to exactly $3$ decimal places for each test case.\n\nFinal output format:\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, where each test case result is itself a list of three numbers in the order $[\\text{posterior\\_mean}, \\text{lower\\_0.025}, \\text{upper\\_0.975}]$. For example, produce output of the form\n$[[m_1,\\ell_1,u_1],[m_2,\\ell_2,u_2],[m_3,\\ell_3,u_3],[m_4,\\ell_4,u_4]]$\nwith each $m_i$, $\\ell_i$, and $u_i$ rounded to $3$ decimal places.",
            "solution": "The objective is to compute the posterior distribution of the total number of infections, $I$, given the number of reported cases, $R$, and prior beliefs about the surveillance system's stage-specific probabilities. From this posterior distribution, we will calculate the posterior mean $E[I|R]$ and the endpoints of the equal-tailed $0.95$ credible interval.\n\nThe problem is structured as a hierarchical Bayesian model. According to Bayes' theorem, the posterior probability of $I$ given $R$ is proportional to the product of the likelihood of $R$ given $I$ and the prior probability of $I$:\n$$ P(I | R) = \\frac{P(R|I) P(I)}{P(R)} \\propto P(R|I) P(I) $$\nThe denominator, $P(R) = \\sum_{I'} P(R|I')P(I')$, is a normalizing constant.\n\nThe prior for $I$ is given as a discrete uniform distribution over the set $\\{R, R+1, \\dots, N_{\\max}\\}$.\n$$ P(I) = \\frac{1}{N_{\\max} - R + 1} \\quad \\text{for } I \\in \\{R, \\dots, N_{\\max}\\} $$\nSince $P(I)$ is constant for all possible values of $I$, it can be absorbed into the proportionality constant. Thus, the posterior is proportional to the marginal likelihood:\n$$ P(I|R) \\propto P(R|I) $$\n\nThe marginal likelihood, $P(R|I)$, is obtained by integrating over the unknown per-infection reporting probability, $p$:\n$$ P(R | I) = \\int_0^1 P(R | I, p) P(p) \\, dp $$\nThe problem states that the number of reported cases $R$ given $I$ and $p$ follows a binomial distribution:\n$$ R \\mid I, p \\sim \\mathrm{Binomial}(I, p) \\implies P(R|I,p) = \\binom{I}{R} p^R (1-p)^{I-R} $$\nThe prior on the reporting probability, $P(p)$, is determined by the model's structure. The probability $p$ is the product of three independent stage probabilities: $p = p_{\\mathrm{care}} \\cdot p_{\\mathrm{test}} \\cdot p_{\\mathrm{report}}$. Each of these stage probabilities follows a Beta distribution:\n$$ p_{\\mathrm{care}} \\sim \\mathrm{Beta}(\\alpha_{\\mathrm{care}}, \\beta_{\\mathrm{care}}) $$\n$$ p_{\\mathrm{test}} \\sim \\mathrm{Beta}(\\alpha_{\\mathrm{test}}, \\beta_{\\mathrm{test}}) $$\n$$ p_{\\mathrm{report}} \\sim \\mathrm{Beta}(\\alpha_{\\mathrm{report}}, \\beta_{\\mathrm{report}}) $$\nThe distribution of a product of independent Beta-distributed random variables does not have a simple closed-form expression. To proceed, we employ a mathematically justified approximation as permitted by the problem statement. We approximate the distribution of $p$ with a single Beta distribution, $p \\sim \\mathrm{Beta}(\\alpha_p, \\beta_p)$, by matching the first two moments (mean and variance) of the true distribution of $p$.\n\nLet $p_i$ be one of the stage probabilities, with $p_i \\sim \\mathrm{Beta}(\\alpha_i, \\beta_i)$. The $k$-th moment of $p_i$ is given by:\n$$ E[p_i^k] = \\prod_{j=0}^{k-1} \\frac{\\alpha_i+j}{\\alpha_i+\\beta_i+j} $$\nFor $k=1$, the mean is $E[p_i] = \\frac{\\alpha_i}{\\alpha_i+\\beta_i}$.\nFor $k=2$, the second moment is $E[p_i^2] = \\frac{\\alpha_i(\\alpha_i+1)}{(\\alpha_i+\\beta_i)(\\alpha_i+\\beta_i+1)}$.\n\nSince the stage probabilities are independent, the mean and second moment of their product $p$ are:\n$$ \\mu_p = E[p] = E[p_{\\mathrm{care}}] E[p_{\\mathrm{test}}] E[p_{\\mathrm{report}}] $$\n$$ E[p^2] = E[p_{\\mathrm{care}}^2] E[p_{\\mathrm{test}}^2] E[p_{\\mathrm{report}}^2] $$\nThe variance of $p$ is then $\\sigma_p^2 = \\mathrm{Var}(p) = E[p^2] - \\mu_p^2$.\n\nWe find the parameters $(\\alpha_p, \\beta_p)$ of the approximating Beta distribution by solving the moment equations:\n$$ \\mu_p = \\frac{\\alpha_p}{\\alpha_p + \\beta_p} $$\n$$ \\sigma_p^2 = \\frac{\\alpha_p \\beta_p}{(\\alpha_p + \\beta_p)^2 (\\alpha_p + \\beta_p + 1)} $$\nSolving for $\\alpha_p$ and $\\beta_p$ yields:\n$$ \\alpha_p = \\mu_p \\left( \\frac{\\mu_p (1-\\mu_p)}{\\sigma_p^2} - 1 \\right) $$\n$$ \\beta_p = (1-\\mu_p) \\left( \\frac{\\mu_p (1-\\mu_p)}{\\sigma_p^2} - 1 \\right) $$\nWith this approximation, $p \\sim \\mathrm{Beta}(\\alpha_p, \\beta_p)$, the problem reduces to a Beta-Binomial model. The marginal likelihood $P(R|I)$ is the probability mass function of a Beta-Binomial distribution:\n$$ P(R|I) = \\binom{I}{R} \\frac{\\mathrm{B}(R+\\alpha_p, I-R+\\beta_p)}{\\mathrm{B}(\\alpha_p, \\beta_p)} $$\nwhere $\\mathrm{B}(x,y) = \\frac{\\Gamma(x)\\Gamma(y)}{\\Gamma(x+y)}$ is the Beta function.\n\nThe unnormalized posterior for $I$ is proportional to $P(R|I)$. Ignoring terms constant in $I$:\n$$ P(I | R) \\propto \\binom{I}{R} \\mathrm{B}(R+\\alpha_p, I-R+\\beta_p) $$\n$$ P(I | R) \\propto \\frac{I!}{R!(I-R)!} \\frac{\\Gamma(R+\\alpha_p)\\Gamma(I-R+\\beta_p)}{\\Gamma(I+\\alpha_p+\\beta_p)} $$\nAgain dropping terms constant in $I$ ($R!$ and $\\Gamma(R+\\alpha_p)$), and using $\\Gamma(n+1)=n!$:\n$$ P(I | R) \\propto \\frac{\\Gamma(I+1)}{\\Gamma(I-R+1)} \\frac{\\Gamma(I-R+\\beta_p)}{\\Gamma(I+\\alpha_p+\\beta_p)} $$\nFor numerical stability, we compute the logarithm of this expression for each $I \\in \\{R, \\dots, N_{\\max}\\}$:\n$$ \\log(P(I|R))_{\\text{unnorm}} = \\log\\Gamma(I+1) - \\log\\Gamma(I-R+1) + \\log\\Gamma(I-R+\\beta_p) - \\log\\Gamma(I+\\alpha_p+\\beta_p) $$\nThese log-probabilities are then exponentiated and normalized to obtain the posterior probability mass function (PMF), $\\{P_I\\}_{I=R}^{N_{\\max}}$.\n\nFrom the posterior PMF, we compute the required statistics:\n1.  **Posterior Mean**: $E[I|R] = \\sum_{I=R}^{N_{\\max}} I \\cdot P_I$.\n2.  **Credible Interval**: We first compute the cumulative distribution function (CDF), $F(k) = \\sum_{I=R}^{k} P_I$. The $q$-quantile is defined as $\\inf\\{k \\mid F(k) \\ge q\\}$. The lower endpoint $\\ell$ is the $0.025$ quantile and the upper endpoint $u$ is the $0.975$ quantile.\n\nFor the special case where $N_{\\max} = R$, the support of $I$ is the single point $\\{R\\}$. The posterior is a point mass at $R$, so the mean, lower, and upper quantiles are all equal to $R$. For the case $R=0$, the expression for the log-posterior simplifies as the term $\\log\\Gamma(I+1) - \\log\\Gamma(I-0+1)$ becomes $0$.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.special import gammaln\n\ndef solve():\n    \"\"\"\n    Main function to run all test cases and print results.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # (R, N_max, [(alpha_care, beta_care), (alpha_test, beta_test), (alpha_report, beta_report)])\n        (120, 2000, [(40, 60), (70, 30), (90, 10)]),\n        (0, 500, [(30, 70), (50, 50), (80, 20)]),\n        (25, 25, [(60, 40), (40, 60), (50, 50)]),\n        (50, 2000, [(20, 80), (30, 70), (50, 50)])\n    ]\n\n    all_results = []\n    for case in test_cases:\n        R, N_max, alpha_betas = case\n        \n        # Calculate the posterior summaries for the current case.\n        mean, lower, upper = calculate_posterior_summary(R, N_max, alpha_betas)\n\n        # Round results to 3 decimal places as required.\n        result = [round(mean, 3), round(lower, 3), round(upper, 3)]\n        all_results.append(result)\n\n    # Final print statement in the exact required format '[[m1,l1,u1],[m2,l2,u2],...]'.\n    # str() of a list of lists will have spaces, e.g., '[[1, 2], [3, 4]]'.\n    # The required format has no spaces, so they are removed.\n    print(str(all_results).replace(\" \", \"\"))\n\ndef calculate_posterior_summary(R, N_max, alpha_betas):\n    \"\"\"\n    Computes the posterior mean and 95% credible interval for the total number of infections I.\n    \"\"\"\n    # Handle the degenerate case where N_max = R. The posterior is a point mass at R.\n    if N_max == R:\n        return float(R), float(R), float(R)\n\n    # Steps 1-3: Calculate moments for p = p_care * p_test * p_report using moment-matching.\n    mus = []\n    e_sqs = []\n    for alpha, beta in alpha_betas:\n        # Mean: E[X] = alpha / (alpha + beta)\n        mus.append(alpha / (alpha + beta))\n        # Second moment: E[X^2] = alpha*(alpha+1) / ((alpha+beta)*(alpha+beta+1))\n        e_sqs.append((alpha * (alpha + 1)) / ((alpha + beta) * (alpha + beta + 1)))\n    \n    mu_p = np.prod(mus)\n    e_p_sq = np.prod(e_sqs)\n    sigma_p_sq = e_p_sq - mu_p**2\n\n    # Step 4: Find parameters of the approximating Beta distribution for p.\n    # The condition nu > 0 requires mu_p * (1 - mu_p) > sigma_p_sq, which holds for non-degenerate\n    # distributions on (0,1). The check handles floating point inaccuracies.\n    if sigma_p_sq <= 0 or mu_p * (1 - mu_p) <= sigma_p_sq:\n        # This case suggests a distribution with zero or near-zero variance.\n        # We use a large precision 'nu' to model a highly concentrated Beta distribution.\n        nu = 1e12 \n    else:\n        nu = (mu_p * (1 - mu_p) / sigma_p_sq) - 1\n\n    alpha_p = mu_p * nu\n    beta_p = (1 - mu_p) * nu\n\n    # Step 5: Define the support for the posterior of I.\n    I_values = np.arange(R, N_max + 1, dtype=np.int64)\n\n    # Step 6: Calculate the log of the unnormalized posterior for each possible value of I.\n    # log Post(I) ~ log(binom(I,R)) + log(Beta-Binomial)\n    # Proportionality drops constant terms, simplifying to:\n    # gammaln(I+1) - gammaln(I-R+1) + gammaln(I-R+beta_p) - gammaln(I+alpha_p+beta_p)\n    if R > 0:\n        log_unnorm_post = (gammaln(I_values + 1) - gammaln(I_values - R + 1) +\n                           gammaln(I_values - R + beta_p) - gammaln(I_values + alpha_p + beta_p))\n    else:  # For R = 0, the first two Gamma terms cancel.\n        log_unnorm_post = (gammaln(I_values + beta_p) - gammaln(I_values + alpha_p + beta_p))\n\n    # Step 7: Normalize to get the posterior PMF, using stable softmax.\n    log_unnorm_post -= np.max(log_unnorm_post)\n    unnorm_post = np.exp(log_unnorm_post)\n    pmf = unnorm_post / np.sum(unnorm_post)\n\n    # Step 8: Calculate the posterior mean.\n    posterior_mean = np.sum(I_values * pmf)\n\n    # Step 9: Calculate the 95% credible interval endpoints (quantiles).\n    cdf = np.cumsum(pmf)\n    \n    # The q-quantile is inf{x: F(x) >= q}. np.searchsorted(side='left') finds this index.\n    lower_idx = np.searchsorted(cdf, 0.025, side='left')\n    lower_quantile = I_values[lower_idx]\n    \n    upper_idx = np.searchsorted(cdf, 0.975, side='left')\n    # Handle the case where the CDF never reaches 0.975; take the max value.\n    if upper_idx == len(I_values):\n        upper_idx = len(I_values) - 1\n    upper_quantile = I_values[upper_idx]\n\n    return posterior_mean, float(lower_quantile), float(upper_quantile)\n\nsolve()\n```"
        }
    ]
}