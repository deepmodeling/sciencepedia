{
    "hands_on_practices": [
        {
            "introduction": "The core principle of Regression Discontinuity Design is the detection of a \"jump\" at a cutoff. It can be tempting to apply a general-purpose smoothing technique, like Locally Weighted Scatterplot Smoothing (LOESS), across the entire dataset to visualize the underlying trend. This exercise demonstrates why such an approach is fundamentally misleading in an RD context, as a smoother designed to be continuous will inherently obscure or entirely miss the very discontinuity you aim to measure. By comparing the biased result from a global smoother to a principled local linear RD estimate, you will gain a crucial, hands-on understanding of what not to do .",
            "id": "3168530",
            "problem": "You are given a running variable $X$, an outcome $Y$, and a cutoff $c$. Consider the Regression Discontinuity (RD) setup in which the treatment indicator is $T = \\mathbf{1}\\{X \\ge c\\}$ and the outcome $Y$ follows a structural model $Y = g(X) + \\tau T + \\varepsilon$, where $g$ is a smooth baseline function, $\\tau$ is the target RD jump, and $\\varepsilon$ is noise. The RD estimand is defined by the difference of conditional expectations at the cutoff,\n$$\n\\tau = \\lim_{x \\downarrow c} \\mathbb{E}[Y \\mid X = x] - \\lim_{x \\uparrow c} \\mathbb{E}[Y \\mid X = x].\n$$\nYou will construct a synthetic example where applying Locally Weighted Scatterplot Smoothing (LOESS) across $X$ hides the discontinuity at $c$, and you will quantify the danger of global smoothers for RD.\n\nDefine the data generating process as follows:\n- The running variable is $X \\sim \\text{Uniform}([-1, 1])$ independently for each observation.\n- The baseline function is $g(x) = x^2$.\n- The cutoff is $c = 0$.\n- The true RD jump is $\\tau = 1$.\n- The noise is $\\varepsilon \\sim \\mathcal{N}(0, \\sigma^2)$ independently.\n\nDefine the LOESS predictor $\\hat{f}(x)$ as the solution of a weighted local linear regression at a target point $x_0$ using a fraction $s$ of nearest neighbors. For each $x_0$:\n1. Compute distances $d_i = |x_i - x_0|$ for all observed $x_i$.\n2. Let $k = \\lceil s n \\rceil$, where $n$ is the sample size, and let $d_{\\max}$ be the $k$-th smallest $d_i$.\n3. Define the tricube weights $w_i = \\left(1 - \\left(\\frac{d_i}{d_{\\max}}\\right)^3\\right)^3$ for $d_i \\le d_{\\max}$ and $w_i = 0$ otherwise.\n4. Fit the weighted local linear model $y_i = \\beta_0 + \\beta_1 x_i$ by minimizing $\\sum_i w_i (y_i - \\beta_0 - \\beta_1 x_i)^2$, and set $\\hat{f}(x_0) = \\hat{\\beta}_0 + \\hat{\\beta}_1 x_0$.\n\nSince LOESS fits a single smooth curve to data on both sides of the cutoff, the fitted function $\\hat{f}(x)$ is continuous in $x$. Consequently, the “visible” discontinuity measured as\n$$\n\\hat{J}_{\\text{LOESS}} = \\hat{f}(c + \\epsilon) - \\hat{f}(c - \\epsilon)\n$$\nfor a small $\\epsilon > 0$ is expected to be approximately $0$, regardless of the true jump $\\tau$, thereby hiding the discontinuity.\n\nAs a principled RD estimator, define the local linear RD estimator by fitting two separate ordinary least squares (OLS) regressions on either side of the cutoff within bandwidth $h$:\n- Left regression uses data with $x \\in [c - h, c)$ and fits $y = \\alpha_- + \\beta_- x$, yielding $\\hat{m}_-(c) = \\hat{\\alpha}_- + \\hat{\\beta}_- c$.\n- Right regression uses data with $x \\in [c, c + h]$ and fits $y = \\alpha_+ + \\beta_+ x$, yielding $\\hat{m}_+(c) = \\hat{\\alpha}_+ + \\hat{\\beta}_+ c$.\n- The RD estimate is $\\hat{\\tau} = \\hat{m}_+(c) - \\hat{m}_-(c)$.\n\nYour program must:\n1. Generate data for each test case using the specified parameters.\n2. Compute $\\hat{J}_{\\text{LOESS}}$ using the LOESS procedure described above with span $s$ and small offset $\\epsilon$.\n3. Compute the local linear RD estimate $\\hat{\\tau}$ using the bandwidth $h$.\n4. Compute the absolute biases $B_L = |\\hat{J}_{\\text{LOESS}} - \\tau|$ and $B_R = |\\hat{\\tau} - \\tau|$.\n5. For each test case, output the ratio $R = \\frac{B_L}{B_R}$.\n\nInterpretation: When $R$ is larger than $1$, the LOESS-based visible jump is more biased than the local linear RD estimate, illustrating the danger of global smoothers that enforce continuity across the cutoff and can hide true discontinuities.\n\nTest suite (each tuple is $(n, \\sigma, s, h, \\epsilon, \\text{seed})$):\n- Case $1$: $(500, 0.1, 0.9, 0.2, 0.001, 17)$.\n- Case $2$: $(500, 1.0, 0.9, 0.2, 0.001, 23)$.\n- Case $3$: $(300, 0.1, 0.5, 0.15, 0.001, 31)$.\n- Case $4$: $(300, 0.1, 0.2, 0.1, 0.001, 47)$.\n\nFinal output format: Your program should produce a single line of output containing the ratios for all test cases as a comma-separated list enclosed in square brackets, for example, $[\\text{result}_1,\\text{result}_2,\\text{result}_3,\\text{result}_4]$. No other output is permitted.",
            "solution": "The user-provided problem is a well-defined simulation exercise in the field of statistical learning and econometrics, specifically concerning Regression Discontinuity (RD) designs. The problem is scientifically sound, self-contained, and algorithmically specified. It asks for a comparison between two estimators of a discontinuity: one based on a global smoother (LOESS) that is known to perform poorly in this context, and another based on a principled local linear regression approach tailored for RD analysis.\n\nThe problem statement requires us to validate this theoretical behavior through a simulation. We will follow the specified steps for several test cases: data generation, estimation with both methods, and calculation of the ratio of their absolute biases.\n\n### Step 1: Data Generation\nFor each test case, we are given a sample size $n$, a noise standard deviation $\\sigma$, and a random seed. We generate the data according to the specified Data Generating Process (DGP):\n- The running variable $X$ is drawn from a uniform distribution on $[-1, 1]$.\n- The treatment assignment $T$ is deterministic based on $X$ and the cutoff $c = 0$, with $T = \\mathbf{1}\\{X \\ge c\\}$.\n- The outcome $Y$ is generated by the structural model $Y = g(X) + \\tau T + \\varepsilon$, where the baseline is $g(x) = x^2$, the true treatment effect (jump) is $\\tau = 1$, and the noise term $\\varepsilon$ is drawn from a normal distribution $\\mathcal{N}(0, \\sigma^2)$.\n\n### Step 2: Calculation of the LOESS-based Visible Jump $\\hat{J}_{\\text{LOESS}}$\nThe problem defines a \"visible\" jump based on Locally Weighted Scatterplot Smoothing (LOESS). LOESS fits a single smooth function $\\hat{f}(x)$ over the entire range of $X$, ignoring the discontinuity at the cutoff $c$. The procedure for calculating the LOESS prediction $\\hat{f}(x_0)$ at a target point $x_0$ is as follows:\n1.  For a given span parameter $s$, determine the number of nearest neighbors to use: $k = \\lceil sn \\rceil$.\n2.  Identify the $k$ data points $(x_i, y_i)$ closest to $x_0$ based on the distance $|x_i - x_0|$. Let the distance to the furthest of these neighbors be $d_{\\max}$.\n3.  Assign a tricube weight to each data point $i$: $w_i = \\left(1 - \\left(\\frac{|x_i - x_0|}{d_{\\max}}\\right)^3\\right)^3$ for points within the neighborhood ($|x_i - x_0| \\le d_{\\max}$) and $w_i = 0$ for all other points.\n4.  Fit a weighted local linear regression model, $y_i = \\beta_0 + \\beta_1 x_i + e_i$, by minimizing the weighted sum of squared residuals $\\sum_i w_i (y_i - \\beta_0 - \\beta_1 x_i)^2$.\n5.  The LOESS prediction at $x_0$ is $\\hat{f}(x_0) = \\hat{\\beta}_0 + \\hat{\\beta}_1 x_0$.\n\nThe \"visible jump\" is then calculated as the difference in the LOESS predictions at two points straddling the cutoff: $\\hat{J}_{\\text{LOESS}} = \\hat{f}(c + \\epsilon) - \\hat{f}(c - \\epsilon)$ for a small $\\epsilon>0$. Since $\\hat{f}(x)$ is a continuous function, this quantity is expected to be close to $0$.\n\n### Step 3: Calculation of the Local Linear RD Estimate $\\hat{\\tau}$\nThis is the standard, principled approach for RD estimation. It acknowledges the discontinuity by fitting separate models on either side of the cutoff $c$:\n1.  **Left of cutoff:** Using data where $x \\in [c-h, c)$, we fit an Ordinary Least Squares (OLS) regression $y = \\alpha_- + \\beta_- x$. The predicted value at the cutoff from the left is $\\hat{m}_-(c) = \\hat{\\alpha}_- + \\hat{\\beta}_- c$.\n2.  **Right of cutoff:** Using data where $x \\in [c, c+h]$, we fit another OLS regression $y = \\alpha_+ + \\beta_+ x$. The predicted value at the cutoff from the right is $\\hat{m}_+(c) = \\hat{\\alpha}_+ + \\hat{\\beta}_+ c$.\n3.  The RD estimate is the difference between these two predicted values: $\\hat{\\tau} = \\hat{m}_+(c) - \\hat{m}_-(c)$. Since $c=0$, this simplifies to $\\hat{\\tau} = \\hat{\\alpha}_+ - \\hat{\\alpha}_-$, the difference in the intercepts of the two local regressions.\n\n### Step 4: Bias and Ratio Calculation\nWith the true jump $\\tau=1$, we compute the absolute bias for both estimators:\n- LOESS bias: $B_L = |\\hat{J}_{\\text{LOESS}} - \\tau|$.\n- RD estimator bias: $B_R = |\\hat{\\tau} - \\tau|$.\n\nThe final output for each test case is the ratio of these biases, $R = B_L / B_R$. A large value of $R$ demonstrates that the LOESS-based method is significantly more biased and effectively hides the true discontinuity, confirming the \"danger of global smoothers\" in an RD context.\nThe entire process is implemented in the provided Python code, which iterates through the specified test cases and computes the ratio $R$ for each.",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the Regression Discontinuity problem by comparing a LOESS-based approach\n    with a standard local linear RD estimator.\n    \"\"\"\n\n    def _loess_predict(x0, X, Y, s):\n        \"\"\"\n        Computes the LOESS prediction for a single point x0 based on the provided\n        data (X, Y) and span s.\n        \"\"\"\n        n = len(X)\n        k = int(np.ceil(s * n))\n\n        # Clamp k to be within valid range [1, n] for array indexing.\n        if k > n: k = n\n        if k < 1: k = 1\n\n        # 1. Compute distances and find the k-th neighbor's distance (d_max).\n        distances = np.abs(X - x0)\n        sorted_distances = np.sort(distances)\n        d_max = sorted_distances[k-1]\n        \n        # 2. Define tricube weights.\n        weights = np.zeros(n)\n        if d_max > 0:\n            u = distances / d_max\n            mask = u <= 1.0\n            weights[mask] = (1 - u[mask]**3)**3\n        else:  # d_max is 0, only points at x0 get weight 1.\n            weights = (distances == 0).astype(float)\n\n        # 3. Fit weighted local linear model.\n        valid_mask = weights > 0\n        \n        # Fallback for insufficient data points within the window.\n        if np.sum(valid_mask) == 0:\n            return Y[np.argmin(distances)] # Return value of the single closest point.\n        \n        X_w = X[valid_mask]\n        Y_w = Y[valid_mask]\n        weights_w = weights[valid_mask]\n        \n        # If not enough unique X values, fall back to local constant model (weighted mean).\n        if len(np.unique(X_w)) < 2:\n            return np.average(Y_w, weights=weights_w)\n            \n        X_des = np.vstack([np.ones_like(X_w), X_w]).T\n        \n        # WLS can be solved by transforming to an OLS problem.\n        W_sqrt = np.sqrt(weights_w)\n        X_prime = X_des * W_sqrt[:, np.newaxis]\n        Y_prime = Y_w * W_sqrt\n        \n        # np.linalg.lstsq is robust and handles rank-deficient cases.\n        beta_hat = np.linalg.lstsq(X_prime, Y_prime, rcond=None)[0]\n        prediction = beta_hat[0] + beta_hat[1] * x0\n\n        return prediction\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # (n, sigma, s, h, epsilon, seed)\n        (500, 0.1, 0.9, 0.2, 0.001, 17),\n        (500, 1.0, 0.9, 0.2, 0.001, 23),\n        (300, 0.1, 0.5, 0.15, 0.001, 31),\n        (300, 0.1, 0.2, 0.1, 0.001, 47),\n    ]\n\n    results = []\n    for case in test_cases:\n        n, sigma, s, h, epsilon, seed = case\n        \n        # --- Parameter setup ---\n        c = 0.0\n        tau_true = 1.0\n        rng = np.random.default_rng(seed)\n\n        # --- Data Generation ---\n        X = rng.uniform(-1, 1, n)\n        T = (X >= c).astype(int)\n        g_X = X**2\n        noise = rng.normal(0, sigma, n)\n        Y = g_X + tau_true * T + noise\n        \n        # --- LOESS Calculation ---\n        f_hat_plus = _loess_predict(c + epsilon, X, Y, s)\n        f_hat_minus = _loess_predict(c - epsilon, X, Y, s)\n        J_loess = f_hat_plus - f_hat_minus\n\n        # --- Local Linear RD Estimator ---\n        # Left regression\n        mask_left = (X >= c - h) & (X < c)\n        X_left, Y_left = X[mask_left], Y[mask_left]\n        if len(X_left) < 2: raise ValueError(\"Not enough data points left of cutoff.\")\n        X_des_left = np.vstack([np.ones_like(X_left), X_left]).T\n        alpha_minus, beta_minus = np.linalg.lstsq(X_des_left, Y_left, rcond=None)[0]\n        m_hat_minus = alpha_minus + beta_minus * c\n\n        # Right regression\n        mask_right = (X >= c) & (X <= c + h)\n        X_right, Y_right = X[mask_right], Y[mask_right]\n        if len(X_right) < 2: raise ValueError(\"Not enough data points right of cutoff.\")\n        X_des_right = np.vstack([np.ones_like(X_right), X_right]).T\n        alpha_plus, beta_plus = np.linalg.lstsq(X_des_right, Y_right, rcond=None)[0]\n        m_hat_plus = alpha_plus + beta_plus * c\n        \n        tau_hat = m_hat_plus - m_hat_minus\n        \n        # --- Bias and Ratio Calculation ---\n        B_L = np.abs(J_loess - tau_true)\n        B_R = np.abs(tau_hat - tau_true)\n        \n        if B_R == 0.0:\n            R = 1.0 if B_L == 0.0 else np.inf\n        else:\n            R = B_L / B_R\n            \n        results.append(R)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "After learning about common pitfalls, this practice focuses on the correct implementation of a modern RDD estimator. You will implement the \"workhorse\" of RD analysis: a local linear regression using a pooled model with interactions, which efficiently estimates separate regression lines on each side of the cutoff. Furthermore, this exercise  introduces a vital practice in applied research—assessing the robustness of your findings by including a pre-treatment covariate in the model.",
            "id": "3168528",
            "problem": "Consider a sharp Regression Discontinuity Design (RDD) in a healthcare triage scenario where intensive care is assigned by a threshold rule. Let the running variable be the clinical risk score $X \\in \\mathbb{R}$, let the cutoff be $c \\in \\mathbb{R}$, and define the treatment indicator by $T = \\mathbb{1}\\{X \\geq c\\}$. The outcome $Y \\in \\{0,1\\}$ denotes mortality (with $Y=1$ indicating death), and the risk adjustment covariate $Z \\in \\mathbb{R}$ summarizes baseline risk. The causal estimand of interest is the local average treatment effect at the cutoff, namely the jump in the conditional expectation of $Y$ at $X=c$. Your task is to implement a local linear estimator using kernel-weighted least squares to estimate the discontinuity at the cutoff, both without and with risk adjustment by $Z$, and then assess robustness of the estimated effect to this adjustment.\n\nFundamental base for the design is as follows:\n- Let $Y(1)$ and $Y(0)$ denote the potential outcomes under treatment and control, respectively, and assume the Stable Unit Treatment Value Assumption (SUTVA). Under the sharp assignment mechanism $T=\\mathbb{1}\\{X \\ge c\\}$ and the continuity assumption that the conditional expectations $\\mathbb{E}[Y(0)\\mid X=x]$ and $\\mathbb{E}[Y(1)\\mid X=x]$ are continuous at $x=c$, the local average treatment effect at the cutoff equals the discontinuity in $\\mathbb{E}[Y\\mid X=x]$ at $x=c$.\n- A local linear estimator approximates the conditional expectations on either side of $c$ by linear functions in the centered running variable $R = X - c$, fitted within a bandwidth $h>0$ using kernel weights that downweight points farther from the cutoff.\n\nImplementation requirements:\n- Within a bandwidth $h$, use the triangular kernel weights $K(u) = (1 - |u|)\\mathbb{1}\\{|u|\\le 1\\}$ with $u = R/h$, so the point-wise weight is $w_i = (1 - |R_i|/h)\\mathbb{1}\\{|R_i|\\le h\\}$.\n- Fit the following local linear specification by weighted least squares on observations with $|R|\\le h$:\n  1. Unadjusted: regress $Y$ on the columns $(1, T, R, T\\cdot R)$ and take the coefficient on $T$ as the estimated discontinuity.\n  2. Risk-adjusted: regress $Y$ on $(1, T, R, T\\cdot R, Z)$ and again take the coefficient on $T$ as the estimated discontinuity.\n- For each test case, report three quantities: the unadjusted estimate (a float), the risk-adjusted estimate (a float), and a robustness indicator (a boolean) that equals true if the absolute difference between the adjusted and unadjusted estimates is less than or equal to a tolerance $\\delta>0$, and false otherwise.\n\nTest suite and inputs:\nFor each test case, you are given arrays for $X$, $Y$, $Z$, the cutoff $c$, the bandwidth $h$, and the robustness tolerance $\\delta$. The arrays are:\n\nTest case $1$ (happy path, moderate bandwidth):\n- $X = [\\,45,\\,47,\\,49,\\,50,\\,51,\\,53,\\,55,\\,46,\\,48,\\,52,\\,54,\\,44,\\,56,\\,57,\\,43,\\,58\\,]$\n- $Y = [\\,1,\\,1,\\,1,\\,0,\\,0,\\,0,\\,0,\\,1,\\,1,\\,0,\\,0,\\,1,\\,0,\\,0,\\,1,\\,0\\,]$\n- $Z = [\\,0.6,\\,0.5,\\,0.55,\\,0.58,\\,0.62,\\,0.65,\\,0.7,\\,0.52,\\,0.57,\\,0.63,\\,0.66,\\,0.48,\\,0.72,\\,0.74,\\,0.46,\\,0.76\\,]$\n- $c = 50$, $h = 5$, $\\delta = 0.05$.\n\nTest case $2$ (boundary case, small bandwidth):\n- $X = [\\,45,\\,47,\\,49,\\,50,\\,51,\\,53,\\,55,\\,46,\\,48,\\,52,\\,54,\\,44,\\,56,\\,57,\\,43,\\,58\\,]$\n- $Y = [\\,1,\\,1,\\,1,\\,0,\\,0,\\,0,\\,0,\\,1,\\,1,\\,0,\\,0,\\,1,\\,0,\\,0,\\,1,\\,0\\,]$\n- $Z = [\\,0.6,\\,0.5,\\,0.55,\\,0.58,\\,0.62,\\,0.65,\\,0.7,\\,0.52,\\,0.57,\\,0.63,\\,0.66,\\,0.48,\\,0.72,\\,0.74,\\,0.46,\\,0.76\\,]$\n- $c = 50$, $h = 2$, $\\delta = 0.10$.\n\nTest case $3$ (edge case, strong covariate influence):\n- $X = [\\,48,\\,49,\\,50,\\,51,\\,52,\\,53,\\,47,\\,46,\\,54,\\,55,\\,45,\\,56\\,]$\n- $Y = [\\,1,\\,1,\\,0,\\,0,\\,0,\\,0,\\,1,\\,1,\\,0,\\,0,\\,1,\\,0\\,]$\n- $Z = [\\,0.9,\\,0.85,\\,0.88,\\,0.86,\\,0.83,\\,0.8,\\,0.92,\\,0.95,\\,0.78,\\,0.75,\\,0.97,\\,0.74\\,]$\n- $c = 50$, $h = 6$, $\\delta = 0.08$.\n\nAlgorithmic specifications:\n- Construct the centered running variable $R = X - c$.\n- Compute weights $w_i = (1 - |R_i|/h)\\mathbb{1}\\{|R_i|\\le h\\}$ and restrict to observations with $w_i>0$.\n- Form the design matrix $D$ as described above for the unadjusted and adjusted models.\n- Compute the weighted least squares estimator using the Moore–Penrose pseudoinverse to handle near-singular matrices: estimate $\\hat{\\beta} = (D^{\\top} W D)^{+} D^{\\top} W Y$, where $W$ is the diagonal matrix of weights and $(\\cdot)^{+}$ denotes the pseudoinverse. Extract the coefficient on $T$ as the estimated discontinuity.\n\nFinal output format:\nYour program should produce a single line of output containing the concatenated results for all three test cases as a comma-separated list enclosed in square brackets. The order must be, for test case $1$ then test case $2$ then test case $3$: $[\\text{unadjusted}_1,\\text{adjusted}_1,\\text{robust}_1,\\text{unadjusted}_2,\\text{adjusted}_2,\\text{robust}_2,\\text{unadjusted}_3,\\text{adjusted}_3,\\text{robust}_3]$. The booleans must be printed as either true or false in the programming language’s native boolean representation, and the floats must be printed in decimal form. No physical units or angle units are involved. Percentages, if any, must be expressed as decimals.",
            "solution": "The problem is assessed to be **valid**. It is scientifically grounded in the principles of causal inference and statistical learning, specifically the Regression Discontinuity Design (RDD). The problem is well-posed, providing all necessary data, parameters, and a clear, mathematically sound algorithm for estimation. The language is objective and precise, and the setup is self-contained and consistent.\n\nThe task is to estimate the Local Average Treatment Effect (LATE) at the cutoff of a sharp RDD using a local linear estimator. This is performed under two specifications: an unadjusted model and a model adjusted for a risk covariate $Z$. The robustness of the estimate to this adjustment is then assessed. The estimation procedure is based on kernel-weighted least squares.\n\nThe step-by-step procedure is as follows:\n\n1.  **Data Filtering and Preparation**: For each observation $i$, we first compute the centered running variable $R_i = X_i - c$, where $X_i$ is the clinical risk score and $c$ is the cutoff. The analysis is restricted to a local neighborhood around the cutoff, defined by a bandwidth $h > 0$. The problem specifies using a triangular kernel, with weights given by $w_i = (1 - |R_i|/h)\\mathbb{1}\\{|R_i|\\le h\\}$. The instruction to \"restrict to observations with $w_i > 0$\" implies that only observations for which $|R_i| < h$ are included in the regression. For these selected observations, we define the treatment indicator $T_i = \\mathbb{1}\\{X_i \\geq c\\}$, which is $1$ if the observation is treated and $0$ otherwise.\n\n2.  **Unadjusted Local Linear RDD Estimation**: The first model estimates the treatment effect without adjusting for the covariate $Z$. We fit a weighted least squares (WLS) regression within the bandwidth. The model specification is:\n    $$\n    Y_i = \\beta_0 + \\tau T_i + \\beta_1 R_i + \\beta_2 (T_i \\cdot R_i) + \\epsilon_i\n    $$\n    This model fits separate linear trends on each side of the cutoff. The parameter $\\tau$ represents the jump in the intercept at the cutoff $c$ (where $R_i=0$), which is the RDD estimate of the LATE. The regressors are an intercept ($1$), the treatment indicator ($T$), the centered running variable ($R$), and an interaction term ($T \\cdot R$). The design matrix for the unadjusted model is $D_{\\text{unadj}} = [1, T, R, T \\cdot R]$.\n\n3.  **Risk-Adjusted Local Linear RDD Estimation**: The second model includes the baseline risk covariate $Z$ as an additional linear control. This is done to assess whether the treatment effect estimate is sensitive to the inclusion of other prognostic factors. The model specification is:\n    $$\n    Y_i = \\beta_0 + \\tau_{adj} T_i + \\beta_1 R_i + \\beta_2 (T_i \\cdot R_i) + \\beta_3 Z_i + \\nu_i\n    $$\n    The parameter of interest is again the coefficient on the treatment indicator, $\\tau_{adj}$. The inclusion of $Z$ can improve the precision of the estimate and test for robustness. The design matrix for the adjusted model is $D_{\\text{adj}} = [1, T, R, T \\cdot R, Z]$.\n\n4.  **Weighted Least Squares (WLS) Computation**: Both models are estimated using WLS. The vector of coefficients, $\\hat{\\beta}$, is calculated using the formula specified in the problem statement, which involves the Moore-Penrose pseudoinverse $(\\cdot)^{+}$ to ensure stability, particularly in cases with collinearity or few observations:\n    $$\n    \\hat{\\beta} = (D^{\\top} W D)^{+} D^{\\top} W Y\n    $$\n    Here, $Y$ is the vector of outcomes for the filtered observations, $D$ is the corresponding design matrix (either $D_{\\text{unadj}}$ or $D_{\\text{adj}}$), and $W$ is a diagonal matrix with the triangular kernel weights $w_i$ on its diagonal. The estimated treatment effect ($\\hat{\\tau}$ or $\\hat{\\tau}_{adj}$) is the second element of the resulting $\\hat{\\beta}$ vector, corresponding to the coefficient of the treatment indicator $T$.\n\n5.  **Robustness Assessment**: The final step is to compare the unadjusted estimate, $\\hat{\\tau}_{\\text{unadj}}$, with the risk-adjusted estimate, $\\hat{\\tau}_{\\text{adj}}$. The estimate is considered robust if the absolute difference between the two is within a given tolerance $\\delta$:\n    $$\n    \\text{robust} = (|\\hat{\\tau}_{\\text{adj}} - \\hat{\\tau}_{\\text{unadj}}| \\le \\delta)\n    $$\n    This provides a boolean indicator of the stability of the finding. For each test case, the final output will be the triplet $(\\hat{\\tau}_{\\text{unadj}}, \\hat{\\tau}_{\\text{adj}}, \\text{robust})$.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef _calculate_rdd_estimate(X: np.ndarray, Y: np.ndarray, Z: np.ndarray, c: float, h: float, adjusted: bool) -> float:\n    \"\"\"\n    Calculates the RDD estimate using local linear regression via WLS.\n    \"\"\"\n    # 1. Center the running variable\n    R = X - c\n    \n    # 2. Filter data to be strictly within the bandwidth (where weight w_i > 0)\n    mask = np.abs(R) < h\n    \n    # If no data points are within the bandwidth, return NaN.\n    if not np.any(mask):\n        return np.nan\n\n    R_filt = R[mask]\n    Y_filt = Y[mask]\n    X_filt = X[mask]\n    Z_filt = Z[mask]\n\n    # 3. Compute triangular kernel weights\n    weights = 1 - np.abs(R_filt) / h\n    W = np.diag(weights)\n\n    # 4. Construct the design matrix D\n    intercept = np.ones_like(R_filt)\n    T_filt = (X_filt >= c).astype(float)\n    TR_interaction = T_filt * R_filt\n\n    if adjusted:\n        # Columns: (1, T, R, T*R, Z)\n        D = np.stack([intercept, T_filt, R_filt, TR_interaction, Z_filt], axis=1)\n    else:\n        # Columns: (1, T, R, T*R)\n        D = np.stack([intercept, T_filt, R_filt, TR_interaction], axis=1)\n\n    # Check for underdetermined system (fewer obs than params)\n    # The use of pinv is specified to handle this case.\n    n_obs, n_params = D.shape\n    if n_obs == 0:\n        return np.nan\n\n    # 5. Compute the WLS estimator using the Moore-Penrose pseudoinverse\n    try:\n        D_T_W = D.T @ W\n        # The core formula: beta = (D'WD)^+ D'WY\n        pinv_term = np.linalg.pinv(D_T_W @ D)\n        beta_hat = pinv_term @ D_T_W @ Y_filt\n    except np.linalg.LinAlgError:\n        # This branch is unlikely with pinv but included for robustness\n        return np.nan\n\n    # 6. The RDD estimate is the coefficient on the treatment indicator T, which is the second regressor (index 1).\n    rdd_estimate = beta_hat[1]\n    \n    return rdd_estimate\n\n\ndef solve():\n    \"\"\"\n    Main function to run the test cases and print the results.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        {\n            \"X\": np.array([45, 47, 49, 50, 51, 53, 55, 46, 48, 52, 54, 44, 56, 57, 43, 58]),\n            \"Y\": np.array([1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0]),\n            \"Z\": np.array([0.6, 0.5, 0.55, 0.58, 0.62, 0.65, 0.7, 0.52, 0.57, 0.63, 0.66, 0.48, 0.72, 0.74, 0.46, 0.76]),\n            \"c\": 50.0,\n            \"h\": 5.0,\n            \"delta\": 0.05\n        },\n        {\n            \"X\": np.array([45, 47, 49, 50, 51, 53, 55, 46, 48, 52, 54, 44, 56, 57, 43, 58]),\n            \"Y\": np.array([1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0]),\n            \"Z\": np.array([0.6, 0.5, 0.55, 0.58, 0.62, 0.65, 0.7, 0.52, 0.57, 0.63, 0.66, 0.48, 0.72, 0.74, 0.46, 0.76]),\n            \"c\": 50.0,\n            \"h\": 2.0,\n            \"delta\": 0.10\n        },\n        {\n            \"X\": np.array([48, 49, 50, 51, 52, 53, 47, 46, 54, 55, 45, 56]),\n            \"Y\": np.array([1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0]),\n            \"Z\": np.array([0.9, 0.85, 0.88, 0.86, 0.83, 0.8, 0.92, 0.95, 0.78, 0.75, 0.97, 0.74]),\n            \"c\": 50.0,\n            \"h\": 6.0,\n            \"delta\": 0.08\n        }\n    ]\n\n    results = []\n    for case in test_cases:\n        X, Y, Z, c, h, delta = case[\"X\"], case[\"Y\"], case[\"Z\"], case[\"c\"], case[\"h\"], case[\"delta\"]\n\n        # Calculate unadjusted estimate\n        unadjusted_est = _calculate_rdd_estimate(X, Y, Z, c, h, adjusted=False)\n        \n        # Calculate risk-adjusted estimate\n        adjusted_est = _calculate_rdd_estimate(X, Y, Z, c, h, adjusted=True)\n        \n        # Assess robustness\n        is_robust = np.abs(adjusted_est - unadjusted_est) <= delta\n        \n        results.extend([unadjusted_est, adjusted_est, is_robust])\n\n    # Final print statement in the exact required format.\n    # str() converts booleans to 'True'/'False' and floats to decimal strings.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "A single point estimate, even when calculated correctly, is rarely sufficient to build a compelling causal argument. Credibility in RD analysis comes from demonstrating that the result is robust and not merely an artifact of specific analytical choices, such as the selected bandwidth or polynomial degree. This final practice  moves from implementation to strategic design, challenging you to identify the components of a rigorous and transparent sensitivity analysis that can withstand critical scrutiny.",
            "id": "4629776",
            "problem": "An epidemiologist evaluates the effect of a free influenza vaccination program targeting older adults, where eligibility is determined by age. Individuals with age at clinic visit denoted by running variable $X_i$ are eligible if $X_i \\ge c$, with cutoff $c = 65$. Let treatment status be $T_i = \\mathbf{1}\\{X_i \\ge c\\}$ and outcome $Y_i$ be an indicator for hospitalization during the subsequent influenza season. Assume a sharp design in which $T_i$ changes deterministically at $c$. The estimand of interest is the causal effect at the cutoff, defined as\n$$\n\\tau \\equiv \\lim_{x \\downarrow c} \\mathbb{E}[Y_i \\mid X_i = x] - \\lim_{x \\uparrow c} \\mathbb{E}[Y_i \\mid X_i = x],\n$$\nunder the regression discontinuity (RD) identification assumption that the conditional expectations of potential outcomes are continuous at $x = c$. A local polynomial RD estimator fits separate kernel-weighted polynomials of order $p$ on each side of $c$, with kernel weights $K\\!\\left(\\frac{X_i - c}{h}\\right)$ and bandwidth $h$, and constructs $\\hat{\\tau}$ from the difference of the estimated limits at $c$.\n\nTo assess the robustness of RD findings, the epidemiologist wishes to implement a sensitivity analysis that systematically varies bandwidths, kernels, and polynomial orders, while adhering to the RD identification framework and avoiding practices that induce specification search or violate core assumptions (such as global functional forms over the full support or asymmetric weighting across sides of the cutoff).\n\nWhich of the following protocols best meets this goal?\n\nA. Define a baseline mean squared error-optimal bandwidth $h^\\star$ obtained from the sample, and then estimate local polynomial RD effects over a grid of bandwidths $h \\in \\{0.8h^\\star, h^\\star, 1.2h^\\star, 1.6h^\\star\\}$ with symmetric windows around $c$. For each $h$, fit local linear ($p = 1$) and local quadratic ($p = 2$) specifications, centering the polynomial at $c$. For each $(h,p)$ pair, estimate using multiple kernels $K(u)$, including triangular $K(u) = (1 - |u|)\\mathbf{1}(|u| \\le 1)$, Epanechnikov $K(u) = \\frac{3}{4}(1 - u^2)\\mathbf{1}(|u| \\le 1)$, and uniform $K(u) = \\mathbf{1}(|u| \\le 1)$. Report $\\hat{\\tau}$, standard errors, and confidence intervals for each combination, assess visual stability of estimates across the grid, and conduct diagnostic checks: continuity of pre-treatment covariates at $c$, density of $X_i$ near $c$, and placebo outcomes. Do not alter $c$, and keep left and right bandwidths equal.\n\nB. Select the bandwidth $h$ that maximizes the absolute $t$-statistic of $\\hat{\\tau}$ and report only the specification with the largest statistical significance. Use a global cubic polynomial ($p = 3$) over the full support of $X_i$, a Gaussian kernel, and do not perform any diagnostic tests for manipulation of $X_i$ or continuity of covariates.\n\nC. Fix the bandwidth at the baseline value $h^\\star$ and polynomial order at local linear ($p = 1$). Vary only the kernel among triangular, Epanechnikov, and uniform, and compute a simple difference in means between $X_i \\in [c - h^\\star, c)$ and $X_i \\in [c, c + h^\\star]$ for each kernel, ignoring kernel weights in estimation and skipping diagnostic checks for covariates and density.\n\nD. Use local linear ($p = 1$) regression with a triangular kernel, and vary $h$ only on the treated side $X_i \\ge c$ over $h \\in \\{h^\\star, 1.5h^\\star\\}$, while fixing the control-side bandwidth at $h^\\star$. Center the polynomial at the sample mean of $X_i$ rather than at $c$, test for discontinuities in post-treatment outcomes, and report $\\hat{\\tau}$ for the chosen specifications.\n\nSelect the single best protocol from options A–D that systematically varies bandwidths, kernels, and polynomial orders to assess robustness while respecting RD assumptions and good epidemiologic practice.",
            "solution": "The problem statement is valid. It presents a standard scenario in epidemiology and econometrics for a sharp regression discontinuity (RD) design. All terms—running variable ($X_i$), cutoff ($c$), treatment status ($T_i$), outcome ($Y_i$), estimand ($\\tau$), identification assumption, and local polynomial estimation—are defined correctly and are consistent with established scientific literature. The goal is to identify the best protocol for a sensitivity analysis, a crucial step in applied research to ensure the robustness of findings. The constraints given for a good protocol (adherence to the RD framework, avoidance of specification search, and avoidance of violating core assumptions) are standard criteria for rigorous scientific inquiry. The problem is scientifically grounded, well-posed, and objective.\n\nThe objective of a regression discontinuity (RD) analysis is to estimate the causal effect of a treatment or intervention by exploiting a cutoff in a continuous variable that determines eligibility. The key identifying assumption is that, in the absence of the treatment, the expected outcome would be a continuous function of the running variable at the cutoff. The estimand of interest is the difference in the limits of the conditional expectation of the outcome on either side of the cutoff $c$:\n$$\n\\tau \\equiv \\lim_{x \\downarrow c} \\mathbb{E}[Y_i \\mid X_i = x] - \\lim_{x \\uparrow c} \\mathbb{E}[Y_i \\mid X_i = x]\n$$\nThis is typically estimated using local polynomial regression. A polynomial of order $p$ is fit to the data in a window of bandwidth $h$ around the cutoff $c$, separately on each side. The estimate $\\hat{\\tau}$ is the difference in the predicted values from these two regressions at the cutoff $c$.\n\nThe choice of the bandwidth $h$, the polynomial order $p$, and the kernel function $K(\\cdot)$ are critical \"tuning parameters\". An optimal bandwidth, $h^\\star$, is often chosen to minimize the mean squared error (MSE) of the estimator, balancing bias (from using observations far from $c$) and variance (from using too few observations). However, the resulting estimate $\\hat{\\tau}$ can be sensitive to these choices. A robust finding should be stable across a reasonable range of specifications.\n\nA sensitivity analysis, therefore, is not about finding the \"best\" or \"most significant\" result. It is about demonstrating that the conclusion is not an artifact of a single, arbitrary set of tuning parameters. A methodologically sound sensitivity analysis for an RD design should:\n1.  Systematically vary the main tuning parameters ($h$, $p$, $K$) around a sensible baseline (e.g., an MSE-optimal bandwidth).\n2.  Use local estimation methods, as the RD identification is a local property at the cutoff $c$. Global polynomials are generally inappropriate.\n3.  Report results for all tested specifications to demonstrate transparency and avoid \"p-hacking\" or specification searching.\n4.  Maintain symmetric and consistent estimation on both sides of the cutoff (e.g., same bandwidth, same polynomial order) to avoid introducing bias.\n5.  Include a set of standard diagnostic tests to check the validity of the RD assumptions, such as continuity of pre-treatment covariates and the absence of strategic sorting around the cutoff (manipulation of the running variable).\n\nWe will now evaluate each proposed protocol against these principles.\n\n**Option A Evaluation**\nThis protocol proposes to:\n-   Define a baseline MSE-optimal bandwidth $h^\\star$. This is a standard starting point.\n-   Systematically vary the bandwidth $h$ around this baseline: $\\{0.8h^\\star, h^\\star, 1.2h^\\star, 1.6h^\\star\\}$. This is a good practice to check sensitivity to bandwidth choice.\n-   Vary the polynomial order $p$ between local linear ($p=1$) and local quadratic ($p=2$). This is crucial, as the choice between $p=1$ and $p=2$ is a key decision with a bias-variance trade-off.\n-   Vary the kernel function $K(\\cdot)$ among standard choices (triangular, Epanechnikov, uniform). While the choice of kernel is often considered of secondary importance, including it makes the analysis more comprehensive.\n-   Maintain symmetry: \"symmetric windows\" and \"keep left and right bandwidths equal\". This adheres to best practices.\n-   Use correct centering: \"centering the polynomial at $c$\". This is methodologically correct for estimating the intercepts at the cutoff.\n-   Report all results: \"Report $\\hat{\\tau}$, standard errors, and confidence intervals for each combination\". This demonstrates transparency and is the opposite of specification searching.\n-   Perform essential diagnostic checks: \"continuity of pre-treatment covariates at $c$, density of $X_i$ near $c$, and placebo outcomes\". This is a hallmark of a rigorous RD analysis.\n\nThis protocol is a textbook example of a thorough and methodologically sound sensitivity analysis. It systematically explores the key analytical choices in a transparent manner while performing the necessary validity checks.\n\n**Verdict: Correct**\n\n**Option B Evaluation**\nThis protocol proposes to:\n-   Select the bandwidth $h$ that \"maximizes the absolute $t$-statistic of $\\hat{\\tau}$\". This is a clear case of specification searching or \"p-hacking,\" a practice that invalidates statistical inference by cherry-picking the result that appears most statistically significant.\n-   Use a \"global cubic polynomial ($p=3$) over the full support of $X_i$\". This violates the 'local' principle of RD analysis. Global polynomials are highly sensitive to misspecification and can produce badly biased estimates of the effect at the cutoff.\n-   \"report only the specification with the largest statistical significance\". This is further confirmation of p-hacking and a lack of transparency.\n-   \"do not perform any diagnostic tests\". Omitting these checks is a critical failure, as it means the validity of the entire RD design is not scrutinized.\n\nThis protocol represents a deliberate misuse of statistical methods to achieve a desired result and is scientifically unethical.\n\n**Verdict: Incorrect**\n\n**Option C Evaluation**\nThis protocol proposes to:\n-   Fix the bandwidth $h^\\star$ and polynomial order $p=1$. This severely limits the scope of the sensitivity analysis, as robustness to bandwidth and polynomial order choice is not assessed.\n-   \"compute a simple difference in means\". A simple difference in means within a window corresponds to a local constant regression ($p=0$), not a local linear regression ($p=1$) as claimed. A local linear regression fits a straight line on each side, which is known to have better bias properties at the boundary (the cutoff) than a local constant model.\n-   \"ignoring kernel weights in estimation\". The very definition of a kernel-weighted estimator is to use the weights. Ignoring them is methodologically incorrect, except for the special case of the uniform kernel. For triangular or Epanechnikov kernels, this would not be the correct procedure.\n-   \"skipping diagnostic checks\". As with option B, this is a major methodological flaw.\n\nThis protocol is both insufficient as a sensitivity analysis and methodologically flawed in its description of the estimation procedure.\n\n**Verdict: Incorrect**\n\n**Option D Evaluation**\nThis protocol proposes to:\n-   Use asymmetric bandwidths as a sensitivity check: \"vary $h$ only on the treated side ... while fixing the control-side bandwidth\". While data-driven methods can sometimes select different optimal bandwidths for each side, varying one while fixing the other is a non-standard and unprincipled way to conduct a sensitivity analysis. It violates the symmetry guideline mentioned in the problem statement itself as a practice to avoid.\n-   Center the polynomial at the \"sample mean of $X_i$ rather than at $c$\". This is a fundamental error. Local polynomial regression in RD is centered at the cutoff $c$ so that the intercept parameter of the regression directly estimates the conditional mean at the cutoff. Centering at the sample mean $\\bar{X}$ would mean the intercept estimates the conditional mean at $\\bar{X}$, making the extraction of the RD effect at $c$ unnecessarily complex and less stable.\n-   \"test for discontinuities in post-treatment outcomes\". This is not a diagnostic test; it is the primary analysis itself (estimating $\\tau$). Diagnostic tests assess the validity of the assumptions by checking for discontinuities in variables that *should not* be affected by the treatment, such as pre-treatment covariates or placebo outcomes. This part of the description shows a misunderstanding of RD diagnostics.\n\nThis protocol includes several fundamental methodological errors that would invalidate the analysis.\n\n**Verdict: Incorrect**\n\n**Conclusion**\nProtocol A is the only option that describes a comprehensive, transparent, and methodologically rigorous approach to assessing the robustness of regression discontinuity findings. It systematically varies the key tuning parameters, adheres to best practices like symmetric estimation and correct centering, and includes the critical diagnostic tests required to validate the design's assumptions. The other options contain severe flaws, ranging from scientific misconduct (B) to methodological errors (C, D) and insufficient rigor (C).",
            "answer": "$$\\boxed{A}$$"
        }
    ]
}