{
    "hands_on_practices": [
        {
            "introduction": "在流行病学研究中，偏差常常被视为对研究结论的无形威胁。然而，我们可以使用具体的工具来应对它。本实践将介绍一种巧妙的方法——阴性对照结局，通过检验一个已知与暴露没有因果关系的结局，我们可以估算出混杂偏倚的大小，并利用这个估计值来校准我们对主要结局的分析结果。这项练习将向您展示如何将一个带有偏倚的观测关联，转化为一个更可信的因果效应估计值 。",
            "id": "4625672",
            "problem": "一项观察性队列研究在一个固定的随访期内检验暴露 $E$ 与主要结局 $Y$ 之间的关联，此期间的失访可忽略不计。为了评估和校正未测量的混杂因素及其他系统误差，研究者还预先指定了一个阴性对照结局 (NCO)，记为 $Z$，其选择标准是 $E$ 到 $Z$ 之间不存在生物学上合理的因果路径。该分析使用以下基础流行病学定义：一个群体中的风险是指在随访期间经历该结局的个体比例，风险比是暴露组与非暴露组之间风险的比值。\n\n研究记录了以下计数：\n- 暴露组样本量 $n_{E} = 3000$，其中 $Y$ 的病例数为 $a_{Y} = 150$，$Z$ 的病例数为 $a_{Z} = 120$。\n- 非暴露组样本量 $n_{\\bar{E}} = 6000$，其中 $Y$ 的病例数为 $b_{Y} = 180$，$Z$ 的病例数为 $b_{Z} = 180$。\n\n假设以下条件成立：\n1. $E$ 对 $Z$ 的因果效应为空，因此 $Z$ 的真实因果风险比为 $RR_{Z}^{\\text{true}} = 1$。\n2. 一个单一的乘性偏倚因子 $B$（例如，由未测量的混杂或选择偏倚引起）对 $Y$ 和 $Z$ 的观测风险比产生相同的影响，因此对于每个结局 $O \\in \\{Y,Z\\}$，观测风险比满足 $RR_{O}^{\\text{obs}} = RR_{O}^{\\text{true}} \\times B$。\n3. 风险由暴露分层内的观测比例恰当地估计。\n\n仅使用上述核心定义和假设，通过使用阴性对照结局来检测和校准乘性偏倚，计算 $E \\rightarrow Y$ 的因果风险比的校准点估计值。将校准后的风险比报告为一个纯数字。将你的答案四舍五入至四位有效数字。",
            "solution": "该问题是有效的，因为其科学依据是定量偏倚分析的流行病学原理，问题提法得当，信息充分且一致，并且陈述客观。\n\n目标是计算暴露 $E$ 对结局 $Y$ 影响的因果风险比的校准点估计值，记为 $RR_{Y}^{\\text{true}}$。校准过程使用阴性对照结局 $Z$ 来执行。\n\n首先，我们将结局的风险定义为组内经历该结局的个体比例。令 $R_{O,E}$ 为暴露组 ($E$) 中结局 $O$ 的风险，$R_{O,\\bar{E}}$ 为非暴露组 ($\\bar{E}$) 中的风险。根据假设3，这些风险可以根据所提供的数据进行估计。\n\n已知条件如下：\n- 暴露组：$n_{E} = 3000$，其中 $Y$ 的病例数为 $a_{Y} = 150$，$Z$ 的病例数为 $a_{Z} = 120$。\n- 非暴露组：$n_{\\bar{E}} = 6000$，其中 $Y$ 的病例数为 $b_{Y} = 180$，$Z$ 的病例数为 $b_{Z} = 180$。\n\n我们计算每个暴露组中每个结局的观测风险：\n暴露组中结局 $Y$ 的风险为：\n$$R_{Y,E} = \\frac{a_{Y}}{n_{E}} = \\frac{150}{3000} = 0.05$$\n非暴露组中结局 $Y$ 的风险为：\n$$R_{Y,\\bar{E}} = \\frac{b_{Y}}{n_{\\bar{E}}} = \\frac{180}{6000} = 0.03$$\n暴露组中阴性对照结局 $Z$ 的风险为：\n$$R_{Z,E} = \\frac{a_{Z}}{n_{E}} = \\frac{120}{3000} = 0.04$$\n非暴露组中阴性对照结局 $Z$ 的风险为：\n$$R_{Z,\\bar{E}} = \\frac{b_{Z}}{n_{\\bar{E}}} = \\frac{180}{6000} = 0.03$$\n\n接下来，我们计算两种结局的观测风险比 ($RR^{\\text{obs}}$)。风险比是暴露组风险与非暴露组风险之比。\n结局 $Y$ 的观测风险比为：\n$$RR_{Y}^{\\text{obs}} = \\frac{R_{Y,E}}{R_{Y,\\bar{E}}} = \\frac{0.05}{0.03} = \\frac{5}{3}$$\n阴性对照结局 $Z$ 的观测风险比为：\n$$RR_{Z}^{\\text{obs}} = \\frac{R_{Z,E}}{R_{Z,\\bar{E}}} = \\frac{0.04}{0.03} = \\frac{4}{3}$$\n\n问题的核心在于关于偏倚因子 $B$ 的假设。假设2指出，一个乘性偏倚因子 $B$ 对两种结局的观测风险比产生相同的影响，使得对于 $O \\in \\{Y,Z\\}$，有 $RR_{O}^{\\text{obs}} = RR_{O}^{\\text{true}} \\times B$。\n\n我们使用阴性对照结局 $Z$ 来估计这个偏倚因子。对于结局 $Z$，关系式为：\n$$RR_{Z}^{\\text{obs}} = RR_{Z}^{\\text{true}} \\times B$$\n假设1指出，$Z$ 的真实因果风险比为1，即 $RR_{Z}^{\\text{true}} = 1$。将此代入方程可得：\n$$RR_{Z}^{\\text{obs}} = 1 \\times B = B$$\n因此，阴性对照结局的观测风险比提供了对偏倚因子 $B$ 的估计。\n$$B = RR_{Z}^{\\text{obs}} = \\frac{4}{3}$$\n\n现在我们可以用这个偏倚因子的估计值来校准主要结局 $Y$ 的观测风险比，并求出真实的因果风险比 $RR_{Y}^{\\text{true}}$。根据假设2，结局 $Y$ 的关系式为：\n$$RR_{Y}^{\\text{obs}} = RR_{Y}^{\\text{true}} \\times B$$\n为了求出校准后的（即真实的）风险比，我们重新整理这个方程：\n$$RR_{Y}^{\\text{true}} = \\frac{RR_{Y}^{\\text{obs}}}{B}$$\n代入计算出的 $RR_{Y}^{\\text{obs}}$ 和 $B$ 的值（其中 $B=RR_{Z}^{\\text{obs}}$）：\n$$RR_{Y}^{\\text{true}} = \\frac{RR_{Y}^{\\text{obs}}}{RR_{Z}^{\\text{obs}}} = \\frac{5/3}{4/3}$$\n$$RR_{Y}^{\\text{true}} = \\frac{5}{3} \\times \\frac{3}{4} = \\frac{5}{4}$$\n将此分数转换为小数，得到校准后风险比的点估计值：\n$$RR_{Y}^{\\text{true}} = 1.25$$\n题目要求答案四舍五入至四位有效数字。因此，我们将结果表示为 $1.250$。",
            "answer": "$$\\boxed{1.250}$$"
        },
        {
            "introduction": "并非所有的测量误差都会对研究结果产生相同的影响。本练习将深入探讨两种基本的测量误差模型——经典型（Classical）和伯克森型（Berkson）误差，并通过第一性原理推导，揭示它们如何以不同方式影响回归分析的结果。理解这两种模型的区别对于准确解读回归系数，以及判断在何种情况下测量误差会或不会导致偏倚至关重要 。",
            "id": "4625667",
            "problem": "考虑一项队列研究，其中连续暴露 $X$ 通过一个线性结构模型与连续结局 $Y$ 相关。观测到的暴露 $W$ 存在测量误差。考虑两种误差机制：\n\n- 经典测量误差：$W = X + U_{\\mathrm{C}}$，其中 $U_{\\mathrm{C}}$ 与 $X$ 独立，且与结局误差独立。\n- Berkson 测量误差：$X = W + U_{\\mathrm{B}}$，其中 $U_{\\mathrm{B}}$ 与 $W$ 独立，且与结局误差独立。\n\n假设结局的基础模型如下：$Y = \\beta_0 + \\beta_1 X + \\varepsilon$，其中 $\\varepsilon$ 是一个误差项，满足 $\\mathbb{E}[\\varepsilon \\mid X] = 0$。在朴素分析中，使用普通最小二乘法 (OLS) 将 $Y$ 对 $W$ 进行回归。朴素 OLS 斜率的期望值取决于测量误差机制以及 $X$、$W$ 和测量误差项的二阶矩结构。\n\n您必须使用的基本定义和性质：\n- 将 $Y$ 对 $W$ 回归的 OLS 斜率可以用二阶矩表示为 $\\beta_1^{\\ast} = \\dfrac{\\mathrm{Cov}(W,Y)}{\\mathrm{Var}(W)}$。\n- 随机变量的独立性意味着当 $A$ 和 $B$ 独立时，$\\mathrm{Cov}(A,B) = 0$。\n- 对于独立的随机变量 $A$ 和 $B$，$\\mathrm{Var}(A+B) = \\mathrm{Var}(A) + \\mathrm{Var}(B)$。\n\n任务：\n- 根据上述原理，在不使用任何快捷公式的情况下，推导出在每种测量误差机制下使用 $W$ 替代 $X$ 时的预期朴素 OLS 斜率 $\\beta_1^{\\ast}$。\n- 实现一个程序，对于每个测试用例，根据给定的真实斜率 $\\beta_1$、真实暴露的方差 $\\mathrm{Var}(X)$ 以及测量误差项的方差（经典误差 $U_{\\mathrm{C}}$ 或 Berkson 误差 $U_{\\mathrm{B}}$），计算预期的朴素 OLS 斜率 $\\beta_1^{\\ast}$。请注意，在 Berkson 情况下，预期的朴素斜率可能依赖也可能不依赖于误差方差；您的推导必须从第一性原理确定这种依赖关系。\n- 将结果以四舍五入到 $6$ 位小数的浮点数形式返回。\n\n每个测试用例的输入规范：\n- 一个表示误差机制的标签，为 \"classical\" 或 \"berkson\"。\n- 真实斜率 $\\beta_1$。\n- 方差 $\\mathrm{Var}(X)$。\n- 测量误差项的方差，对于经典误差记为 $\\mathrm{Var}(U_{\\mathrm{C}})$，对于 Berkson 误差记为 $\\mathrm{Var}(U_{\\mathrm{B}})$。\n\n测试套件：\n- 案例 $1$：经典误差，$\\beta_1 = 2.0$，$\\mathrm{Var}(X) = 4.0$，$\\mathrm{Var}(U_{\\mathrm{C}}) = 1.0$。\n- 案例 $2$：经典误差，$\\beta_1 = 2.0$，$\\mathrm{Var}(X) = 4.0$，$\\mathrm{Var}(U_{\\mathrm{C}}) = 0.0$。\n- 案例 $3$：Berkson 误差，$\\beta_1 = 2.0$，$\\mathrm{Var}(X) = 4.0$，$\\mathrm{Var}(U_{\\mathrm{B}}) = 1.0$。\n- 案例 $4$：经典误差，$\\beta_1 = -1.0$，$\\mathrm{Var}(X) = 9.0$，$\\mathrm{Var}(U_{\\mathrm{C}}) = 3.0$。\n- 案例 $5$：经典误差，$\\beta_1 = 1.5$，$\\mathrm{Var}(X) = 0.0$，$\\mathrm{Var}(U_{\\mathrm{C}}) = 2.0$。\n- 案例 $6$：Berkson 误差，$\\beta_1 = 1.2$，$\\mathrm{Var}(X) = 5.0$，$\\mathrm{Var}(U_{\\mathrm{B}}) = 100.0$。\n\n输出规范：\n- 您的程序应生成单行输出，其中包含用方括号括起来的逗号分隔的结果列表，例如 $\\left[ \\text{result}_1, \\text{result}_2, \\text{result}_3, \\dots \\right]$。\n- 每个结果都应该是一个浮点数，代表相应测试用例的预期朴素 OLS 斜率 $\\beta_1^{\\ast}$，并四舍五入到 $6$ 位小数。",
            "solution": "该问题已根据指定标准进行了验证。\n\n**第 1 步：提取已知条件**\n- 结局模型：$Y = \\beta_0 + \\beta_1 X + \\varepsilon$，其中 $\\varepsilon$ 是一个误差项，满足 $\\mathbb{E}[\\varepsilon \\mid X] = 0$。\n- 经典测量误差模型：$W = X + U_{\\mathrm{C}}$，其中 $U_{\\mathrm{C}}$ 与 $X$ 独立，且与结局误差 $\\varepsilon$ 独立。\n- Berkson 测量误差模型：$X = W + U_{\\mathrm{B}}$，其中 $U_{\\mathrm{B}}$ 与 $W$ 独立，且与结局误差 $\\varepsilon$ 独立。\n- 朴素 OLS 斜率定义：$\\beta_1^{\\ast} = \\dfrac{\\mathrm{Cov}(W,Y)}{\\mathrm{Var}(W)}$。\n- 基本性质：\n    1. 如果 $A$ 和 $B$ 独立，$\\mathrm{Cov}(A,B) = 0$。\n    2. 如果 $A$ 和 $B$ 独立，$\\mathrm{Var}(A+B) = \\mathrm{Var}(A) + \\mathrm{Var}(B)$。\n- 输入参数：误差机制类型（\"classical\" 或 \"berkson\"）、真实斜率 $\\beta_1$、真实暴露的方差 $\\mathrm{Var}(X)$ 以及测量误差的方差 $\\mathrm{Var}(U_{\\mathrm{C}})$ 或 $\\mathrm{Var}(U_{\\mathrm{B}})$。\n- 测试用例：\n    1. 经典误差，$\\beta_1 = 2.0$，$\\mathrm{Var}(X) = 4.0$，$\\mathrm{Var}(U_{\\mathrm{C}}) = 1.0$。\n    2. 经典误差，$\\beta_1 = 2.0$，$\\mathrm{Var}(X) = 4.0$，$\\mathrm{Var}(U_{\\mathrm{C}}) = 0.0$。\n    3. Berkson 误差，$\\beta_1 = 2.0$，$\\mathrm{Var}(X) = 4.0$，$\\mathrm{Var}(U_{\\mathrm{B}}) = 1.0$。\n    4. 经典误差，$\\beta_1 = -1.0$，$\\mathrm{Var}(X) = 9.0$，$\\mathrm{Var}(U_{\\mathrm{C}}) = 3.0$。\n    5. 经典误差，$\\beta_1 = 1.5$，$\\mathrm{Var}(X) = 0.0$，$\\mathrm{Var}(U_{\\mathrm{C}}) = 2.0$。\n    6. Berkson 误差，$\\beta_1 = 1.2$，$\\mathrm{Var}(X) = 5.0$，$\\mathrm{Var}(U_{\\mathrm{B}}) = 100.0$。\n\n**第 2 步：使用提取的已知条件进行验证**\n该问题具有科学依据，提法明确且客观。这是流行病学和计量经济学中一个关于测量误差后果的标准问题。所使用的模型和假设在该领域是标准的。推导所需的所有必要信息均已提供。测试用例定义明确，尽管案例 6 提出的参数（$\\mathrm{Var}(X)  \\mathrm{Var}(U_{\\mathrm{B}})$）与 Berkson 模型的物理可能性不一致，因为这将意味着观测变量 $W$ 的方差为负。然而，这并不影响问题的核心任务，即推导预期朴素斜率的通用公式并应用它。为 Berkson 情况推导出的公式不依赖于这些方差值，并且仍然是可计算的。因此，整个问题陈述是有效的。\n\n**第 3 步：结论与行动**\n问题有效。下面是一个完整的、有理据的解决方案。\n\n任务是从定义 $\\beta_1^{\\ast} = \\dfrac{\\mathrm{Cov}(W,Y)}{\\mathrm{Var}(W)}$ 出发，推导将结局 $Y$ 对带误差的暴露 $W$ 进行回归时的预期普通最小二乘法 (OLS) 斜率 $\\beta_1^{\\ast}$。我们将为经典和 Berkson 误差模型从第一性原理进行此推导。一个重要的初步结果是，假设 $\\mathbb{E}[\\varepsilon \\mid X] = 0$ 意味着 $\\mathrm{Cov}(X, \\varepsilon) = 0$。这是因为 $\\mathrm{Cov}(X, \\varepsilon) = \\mathbb{E}[X\\varepsilon] - \\mathbb{E}[X]\\mathbb{E}[\\varepsilon]$。根据全期望定律，$\\mathbb{E}[\\varepsilon] = \\mathbb{E}[\\mathbb{E}[\\varepsilon \\mid X]] = \\mathbb{E}[0] = 0$。同样，$\\mathbb{E}[X\\varepsilon] = \\mathbb{E}[\\mathbb{E}[X\\varepsilon \\mid X]] = \\mathbb{E}[X \\mathbb{E}[\\varepsilon \\mid X]] = \\mathbb{E}[X \\cdot 0] = 0$。因此，$\\mathrm{Cov}(X, \\varepsilon) = 0 - \\mathbb{E}[X] \\cdot 0 = 0$。\n\n**经典测量误差的推导**\n\n模型为 $Y = \\beta_0 + \\beta_1 X + \\varepsilon$ 和 $W = X + U_{\\mathrm{C}}$。关键假设是误差项 $U_{\\mathrm{C}}$ 与真实暴露 $X$ 和结局误差 $\\varepsilon$ 独立。\n\n首先，我们推导分子 $\\mathrm{Cov}(W,Y)$：\n$$\n\\mathrm{Cov}(W,Y) = \\mathrm{Cov}(X + U_{\\mathrm{C}}, \\beta_0 + \\beta_1 X + \\varepsilon)\n$$\n利用协方差的双线性性质：\n$$\n\\mathrm{Cov}(W,Y) = \\mathrm{Cov}(X, \\beta_0 + \\beta_1 X + \\varepsilon) + \\mathrm{Cov}(U_{\\mathrm{C}}, \\beta_0 + \\beta_1 X + \\varepsilon)\n$$\n展开两项：\n$$\n\\mathrm{Cov}(W,Y) = \\left[ \\mathrm{Cov}(X, \\beta_0) + \\mathrm{Cov}(X, \\beta_1 X) + \\mathrm{Cov}(X, \\varepsilon) \\right] + \\left[ \\mathrm{Cov}(U_{\\mathrm{C}}, \\beta_0) + \\mathrm{Cov}(U_{\\mathrm{C}}, \\beta_1 X) + \\mathrm{Cov}(U_{\\mathrm{C}}, \\varepsilon) \\right]\n$$\n利用协方差的性质和给定的独立性假设，可以简化如下：\n- $\\mathrm{Cov}(V, \\text{常数}) = 0$，所以 $\\mathrm{Cov}(X, \\beta_0)=0$ 和 $\\mathrm{Cov}(U_{\\mathrm{C}}, \\beta_0)=0$。\n- $\\mathrm{Cov}(V, aZ) = a \\, \\mathrm{Cov}(V,Z)$，所以 $\\mathrm{Cov}(X, \\beta_1 X) = \\beta_1 \\mathrm{Cov}(X,X) = \\beta_1 \\mathrm{Var}(X)$ 且 $\\mathrm{Cov}(U_{\\mathrm{C}}, \\beta_1 X) = \\beta_1 \\mathrm{Cov}(U_{\\mathrm{C}}, X)$。\n- 如前所述，$\\mathrm{Cov}(X, \\varepsilon) = 0$。\n- $U_{\\mathrm{C}}$ 与 $X$ 独立，所以 $\\mathrm{Cov}(U_{\\mathrm{C}}, X) = 0$。\n- $U_{\\mathrm{C}}$ 与 $\\varepsilon$ 独立，所以 $\\mathrm{Cov}(U_{\\mathrm{C}}, \\varepsilon) = 0$。\n\n将这些结果代回 $\\mathrm{Cov}(W,Y)$ 的表达式中：\n$$\n\\mathrm{Cov}(W,Y) = \\left[ 0 + \\beta_1 \\mathrm{Var}(X) + 0 \\right] + \\left[ 0 + \\beta_1 (0) + 0 \\right] = \\beta_1 \\mathrm{Var}(X)\n$$\n接下来，我们推导分母 $\\mathrm{Var}(W)$：\n$$\n\\mathrm{Var}(W) = \\mathrm{Var}(X + U_{\\mathrm{C}})\n$$\n由于 $X$ 和 $U_{\\mathrm{C}}$ 独立，它们的和的方差等于它们各自方差的和：\n$$\n\\mathrm{Var}(W) = \\mathrm{Var}(X) + \\mathrm{Var}(U_{\\mathrm{C}})\n$$\n结合分子和分母，我们得到预期的朴素斜率 $\\beta_1^{\\ast}$：\n$$\n\\beta_1^{\\ast} = \\frac{\\mathrm{Cov}(W,Y)}{\\mathrm{Var}(W)} = \\frac{\\beta_1 \\mathrm{Var}(X)}{\\mathrm{Var}(X) + \\mathrm{Var}(U_{\\mathrm{C}})}\n$$\n这个表达式表明，在经典误差模型下，朴素 OLS 斜率会偏向于零，这种现象被称为衰减偏误。$\\frac{\\mathrm{Var}(X)}{\\mathrm{Var}(X) + \\mathrm{Var}(U_{\\mathrm{C}})}$ 这一项是信度比，其值总是在 $0$ 和 $1$ 之间。\n\n**Berkson 测量误差的推导**\n\n模型为 $Y = \\beta_0 + \\beta_1 X + \\varepsilon$ 和 $X = W + U_{\\mathrm{B}}$。关键假设是误差项 $U_{\\mathrm{B}}$ 与观测到的暴露 $W$ 和结局误差 $\\varepsilon$ 独立。\n\n首先，我们推导分子 $\\mathrm{Cov}(W,Y)$：\n$$\n\\mathrm{Cov}(W,Y) = \\mathrm{Cov}(W, \\beta_0 + \\beta_1 X + \\varepsilon)\n$$\n利用双线性性质并代入 $X$ 的模型：\n$$\n\\mathrm{Cov}(W,Y) = \\mathrm{Cov}(W, \\beta_0) + \\mathrm{Cov}(W, \\beta_1 (W + U_{\\mathrm{B}})) + \\mathrm{Cov}(W, \\varepsilon)\n$$\n$$\n\\mathrm{Cov}(W,Y) = 0 + \\beta_1 \\mathrm{Cov}(W, W + U_{\\mathrm{B}}) + \\mathrm{Cov}(W, \\varepsilon)\n$$\n$$\n\\mathrm{Cov(W,Y)} = \\beta_1 \\left[ \\mathrm{Cov}(W,W) + \\mathrm{Cov}(W,U_{\\mathrm{B}}) \\right] + \\mathrm{Cov}(W, \\varepsilon)\n$$\n我们应用独立性假设：\n- $W$ 和 $U_{\\mathrm{B}}$ 独立，所以 $\\mathrm{Cov}(W, U_{\\mathrm{B}}) = 0$。\n- 为了计算 $\\mathrm{Cov}(W, \\varepsilon)$，我们注意到 $W = X - U_{\\mathrm{B}}$。因此，$\\mathrm{Cov}(W, \\varepsilon) = \\mathrm{Cov}(X-U_{\\mathrm{B}}, \\varepsilon) = \\mathrm{Cov}(X, \\varepsilon) - \\mathrm{Cov}(U_{\\mathrm{B}}, \\varepsilon)$。因为 $\\mathrm{Cov}(X, \\varepsilon)=0$ 且 $U_{\\mathrm{B}}$ 与 $\\varepsilon$ 独立，所以 $\\mathrm{Cov}(U_{\\mathrm{B}}, \\varepsilon)=0$。因此，$\\mathrm{Cov}(W, \\varepsilon)=0$。\n\n代入这些结果：\n$$\n\\mathrm{Cov}(W,Y) = \\beta_1 \\left[ \\mathrm{Var}(W) + 0 \\right] + 0 = \\beta_1 \\mathrm{Var}(W)\n$$\n分母就是 $\\mathrm{Var}(W)$。\n结合分子和分母，假设 $\\mathrm{Var}(W) \\neq 0$：\n$$\n\\beta_1^{\\ast} = \\frac{\\mathrm{Cov}(W,Y)}{\\mathrm{Var}(W)} = \\frac{\\beta_1 \\mathrm{Var}(W)}{\\mathrm{Var}(W)} = \\beta_1\n$$\n这个推导表明，在 Berkson 误差模型下，朴素 OLS 斜率是真实斜率 $\\beta_1$ 的无偏估计量。值得注意的是，该结果不依赖于真实暴露或测量误差的方差。\n\n关于 Berkson 模型物理约束的最后一点说明：由 $X = W + U_{\\mathrm{B}}$ 以及 $W$ 和 $U_{\\mathrm{B}}$ 的独立性，我们有 $\\mathrm{Var}(X) = \\mathrm{Var}(W) + \\mathrm{Var}(U_{\\mathrm{B}})$。由于方差必须为非负数，$\\mathrm{Var}(W) = \\mathrm{Var}(X) - \\mathrm{Var}(U_{\\mathrm{B}}) \\ge 0$，这意味着 $\\mathrm{Var}(X) \\ge \\mathrm{Var}(U_{\\mathrm{B}})$。测试案例 6 违反了此条件，其 $\\mathrm{Var}(X)=5.0$ 且 $\\mathrm{Var}(U_{\\mathrm{B}})=100.0$。虽然这代表了一个科学上不一致的场景，但推导出的数学公式 $\\beta_1^{\\ast} = \\beta_1$ 独立于这些方差值，因此仍然可以进行形式上的计算。",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Computes the expected naive OLS slope for a regression with measurement\n    error under either a classical or Berkson error model.\n    \"\"\"\n    test_cases = [\n        # (error_mechanism, beta1, var_x, var_u)\n        (\"classical\", 2.0, 4.0, 1.0),\n        (\"classical\", 2.0, 4.0, 0.0),\n        (\"berkson\", 2.0, 4.0, 1.0),\n        (\"classical\", -1.0, 9.0, 3.0),\n        (\"classical\", 1.5, 0.0, 2.0),\n        (\"berkson\", 1.2, 5.0, 100.0),\n    ]\n\n    results = []\n    for case in test_cases:\n        error_mech, beta1, var_x, var_u = case\n        \n        beta1_star = 0.0  # Initialize result\n        \n        if error_mech == \"classical\":\n            # For classical error, beta_1_star = beta1 * Var(X) / (Var(X) + Var(U_C)).\n            # The derivation shows this accounts for attenuation bias.\n            denominator = var_x + var_u\n            if denominator == 0:\n                # If Var(X) = 0 and Var(U_C) = 0, then Var(W) = 0.\n                # The regressor W is a constant. The numerator of the OLS slope\n                # formula is Cov(W, Y) = Cov(const, Y) = 0. The slope is \n                # indeterminate (0/0) but is conventionally treated as 0.\n                # The formula beta1 * var_x / ... also gives 0 if var_x is 0.\n                beta1_star = 0.0\n            else:\n                beta1_star = beta1 * (var_x / denominator)\n                \n        elif error_mech == \"berkson\":\n            # For Berkson error, the naive OLS slope is an unbiased estimator\n            # of the true slope, i.e., beta_1_star = beta1.\n            # This result holds regardless of the values of Var(X) and Var(U_B),\n            # as long as Var(W) is not zero.\n            beta1_star = beta1\n        \n        # Round the final result to 6 decimal places as required.\n        results.append(round(beta1_star, 6))\n\n    # Format the output as a comma-separated list in square brackets.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n\n```"
        },
        {
            "introduction": "对于那些我们未能测量或无法测量的混杂因素，我们该如何评估其潜在影响呢？最后的这个实践将引入E值（E-value）——一个强大的敏感性分析工具。E值可以量化“将一个观测到的关联完全归因于未测量混杂”所需的混杂强度。通过推导和计算E值，您将学会如何评估研究结果的稳健性，并为因果推断提供更有力的支持，这也呼应了 Bradford Hill 因果推断标准中的“关联强度”准则 。",
            "id": "4509156",
            "problem": "预防医学中的一项观察性队列研究旨在调查社区层面干预的慢性暴露是否与一种可预防慢性病发病率的降低有因果关系。在对一系列丰富的已测量协变量进行调整后，比较暴露组与非暴露组的估计风险比 (RR) 为 $RR_{\\text{obs}}=1.9$。研究人员从 Bradford Hill 标准的角度关注因果声明的可信度，并希望使用定量敏感性分析来评估其对于单个未测量混杂因素的稳健性。\n\n任务：\n- 从宏观层面解释，当可能存在未测量的混杂因素时，使用风险比尺度上的偏倚参数进行的定量敏感性分析如何有助于维持 Bradford Hill 标准下的可信度。您的解释应将量化潜在偏倚的作用与至少一个 Bradford Hill 观点联系起来。\n- 仅从风险比尺度上混杂的核心定义出发，并基于一个广泛接受的逻辑，即单个未测量混杂因素所能产生的最大偏倚可由其与暴露和结局的关联（均在风险比尺度上）的函数来界定，推导出一个未测量混杂因素需要与暴露和结局同时具有的最小等强度关联（记为 $x$）的闭式解析表达式，该关联足以将一个观察到的有害关联 $RR_{\\text{obs}}1$ 降低到真实的零效应（$RR_{\\text{true}}=1$）。这种最小等强度关联通常被概括为 E 值。\n- 使用您推导的表达式，计算 $RR_{\\text{obs}}=1.9$ 时的 E 值。将您的答案四舍五入至四位有效数字。以无单位的纯数字形式表达您的最终答案。",
            "solution": "定量敏感性分析通过明确参数化未测量混杂需要多强才能完全解释观察到的关联，从而在观察到的关联与因果解释之间架起了一座桥梁。在 Bradford Hill 标准的背景下，关联强度的观点是核心：更强的关联不太可能完全由未控制的混杂因素引起。通过量化将观察到的 $RR_{\\text{obs}}$ 移动到零效应（$RR_{\\text{true}}=1$）所需的未测量混杂的最小强度（在风险比尺度上），研究人员可以将此要求与经验上合理的混杂因素关联进行比较。如果根据领域知识和现有数据，所需的混杂强度大到不合理，那么因果解释的可信度不仅在关联强度方面得到加强，而且在连贯性和一致性方面也间接得到支持，因为观察到的关联在对未测量因素的假设进行合理扰动时表现出稳健性。\n\n我们现在从用于风险比尺度上未测量混杂的敏感性分析的第一性原理出发，推导 E 值。设 $U$ 表示单个未测量的混杂因素。在已测量协变量的条件下，定义以下在风险比尺度上的偏倚参数：\n- $RR_{EU}$ 是暴露与 $U$ 之间的关联，解释为比较暴露组与非暴露组中 $U$ 的患病率（或概率）的风险比。\n- $RR_{UD}$ 是 $U$ 与结局之间的关联，解释为在已测量协变量和暴露状态的各层内，比较 $U=1$ 与 $U=0$ 的结局风险的风险比，且假设 $U$ 对暴露没有因果效应。\n\n流行病学敏感性分析中一个经过充分检验的事实（源于 Cornfield 型不等式和乘法尺度的界定论证）是，由单个未测量混杂因素对观察到的风险比所产生的最大可能乘法偏倚，其上界可由 $RR_{EU}$ 和 $RR_{UD}$ 的函数来界定。将偏倚因子记为 $B$，因此\n$$\nRR_{\\text{obs}} \\leq B \\times RR_{\\text{true}},\n$$\n在最坏情况下等号成立，并且 $B$ 随 $RR_{EU}$ 和 $RR_{UD}$ 的增加而增加。对于风险比尺度，一个由单个未测量混杂因素引起的最大偏倚因子的标准且广泛接受的界限是\n$$\nB \\leq \\frac{RR_{EU}\\,RR_{UD}}{RR_{EU} + RR_{UD} - 1}.\n$$\n为了解释掉一个观察到的有害关联，我们需要最坏情况下的混杂能够将 $RR_{\\text{obs}}$ 降低到 $RR_{\\text{true}}=1$。在最保守（最坏情况）的场景下，这对应于要求\n$$\nB \\geq RR_{\\text{obs}}.\n$$\n我们寻求实现这一目标的最小等强度关联，这在最小化两个偏倚参数中较大者的意义上是保守的。因此，设置\n$$\nRR_{EU} = RR_{UD} = x,\n$$\n并施加最大偏倚等于观察风险比的条件：\n$$\n\\frac{x^{2}}{2x - 1} = RR_{\\text{obs}}.\n$$\n求解关于 $x$ 的方程，以 $RR_{\\text{obs}}$ 为变量，得到一个二次方程：\n$$\nx^{2} = RR_{\\text{obs}}(2x - 1) \\quad \\Longrightarrow \\quad x^{2} - 2RR_{\\text{obs}}\\,x + RR_{\\text{obs}} = 0.\n$$\n使用二次方程求根公式解 $x$，\n$$\nx = \\frac{2RR_{\\text{obs}} \\pm \\sqrt{4RR_{\\text{obs}}^{2} - 4RR_{\\text{obs}}}}{2}\n= RR_{\\text{obs}} \\pm \\sqrt{RR_{\\text{obs}}\\,(RR_{\\text{obs}} - 1)}.\n$$\n由于 $x$ 代表一个风险比且必须满足 $x \\geq 1$，所以相关的根是较大的那个。因此，将 $RR_{\\text{obs}}$ 移至 $1$ 所需的最小等强度关联——即 E 值——是\n$$\nx^{\\ast} \\equiv RR_{\\text{obs}} + \\sqrt{RR_{\\text{obs}}\\,(RR_{\\text{obs}} - 1)}.\n$$\n\n我们现在计算 $RR_{\\text{obs}}=1.9$ 时的 E 值：\n$$\nx^{\\ast} = 1.9 + \\sqrt{1.9\\,(1.9 - 1)} = 1.9 + \\sqrt{1.9 \\times 0.9} = 1.9 + \\sqrt{1.71}.\n$$\n计算平方根：\n$$\n\\sqrt{1.71} \\approx 1.307669683.\n$$\n因此，\n$$\nx^{\\ast} \\approx 1.9 + 1.307669683 = 3.207669683.\n$$\n四舍五入到四位有效数字，E 值为\n$$\n3.208.\n$$\n这个值表明，一个未测量的混杂因素需要在已测量的协变量之外，与暴露和结局均具有至少约为 $3.208$ 的风险比关联，才能完全解释观察到的 $RR_{\\text{obs}}=1.9$；如果根据领域知识，这样的关联是不太可能的，这就支持了 Bradford Hill 的关联强度观点，并增强了因果解释的可信度。",
            "answer": "$$\\boxed{3.208}$$"
        }
    ]
}