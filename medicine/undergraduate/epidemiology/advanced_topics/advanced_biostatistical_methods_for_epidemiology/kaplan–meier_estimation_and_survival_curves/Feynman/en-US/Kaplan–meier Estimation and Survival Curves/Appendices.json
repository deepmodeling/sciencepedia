{
    "hands_on_practices": [
        {
            "introduction": "This first practice will guide you through the fundamental mechanics of the Kaplan–Meier method. By working with a small, concrete dataset, you will manually calculate the survival probabilities and their standard errors at each event time, building the survival curve from the ground up . This exercise is crucial for demystifying the product-limit formula and understanding how censoring and tied events are handled in practice.",
            "id": "4605693",
            "problem": "A cohort study in epidemiology follows $8$ individuals from baseline to either a failure event (e.g., disease onset) or censoring. Times are recorded in months. For each individual $j$, let $t_j$ denote the observed follow-up time and $\\delta_j$ an indicator where $\\delta_j = 1$ if a failure event occurred at $t_j$ and $\\delta_j = 0$ if the observation was censored at $t_j$. The observed data are:\n- Individual $1$: $t_1 = 2$, $\\delta_1 = 1$.\n- Individual $2$: $t_2 = 4$, $\\delta_2 = 1$.\n- Individual $3$: $t_3 = 4$, $\\delta_3 = 1$.\n- Individual $4$: $t_4 = 5$, $\\delta_4 = 0$.\n- Individual $5$: $t_5 = 6$, $\\delta_5 = 1$.\n- Individual $6$: $t_6 = 7$, $\\delta_6 = 1$.\n- Individual $7$: $t_7 = 7$, $\\delta_7 = 0$.\n- Individual $8$: $t_8 = 9$, $\\delta_8 = 0$.\n\nAssume the following scientifically standard conventions:\n- The survival time $T$ is a nonnegative random variable, and the survival function $S(t)$ is defined as $S(t) = \\mathbb{P}(T > t)$.\n- The Kaplan–Meier product-limit estimator is used to estimate the survival function nonparametrically from right-censored data.\n- When failures and censorings occur at the same observed time $t$, process all failures at time $t$ before censorings at time $t$ when constructing risk sets and updating the survival estimate (the event-first convention).\n\nUsing only the standard definitions in survival analysis, perform the following tasks for the distinct failure times $t = 2, 4, 6, 7$:\n1. Compute the number at risk $n_i$ immediately prior to each distinct failure time $t_i$ and the number of failures $d_i$ at $t_i$.\n2. Compute the Kaplan–Meier estimator $\\hat{S}(t)$ just after each distinct failure time.\n3. Compute the Greenwood Standard Error (SE) of $\\hat{S}(t)$ at each distinct failure time.\n\nFinally, report the Greenwood Standard Error of the Kaplan–Meier estimator at $t = 7$ as a single numerical value. Round your answer to four significant figures. Do not include units in your final answer.",
            "solution": "### Step 1: Understand the Method\nThe Kaplan–Meier estimator, $\\hat{S}(t)$, is a non-parametric statistic used to estimate the survival function from time-to-event data. It is calculated as a product of conditional survival probabilities at each distinct failure time. The formula is:\n$$\n\\hat{S}(t) = \\prod_{i: t_i \\le t} \\left( 1 - \\frac{d_i}{n_i} \\right)\n$$\nwhere $t_i$ are the distinct failure times, $d_i$ is the number of failures at time $t_i$, and $n_i$ is the number of individuals at risk (alive and not censored) just prior to time $t_i$. By convention, $\\hat{S}(0) = 1$.\n\nThe Greenwood formula is used to estimate the variance of the Kaplan–Meier estimator. The variance of $\\hat{S}(t)$ is given by:\n$$\n\\text{Var}(\\hat{S}(t)) = [\\hat{S}(t)]^2 \\sum_{i: t_i \\le t} \\frac{d_i}{n_i(n_i - d_i)}\n$$\nThe standard error (SE) is the square root of the variance:\n$$\n\\text{SE}(\\hat{S}(t)) = \\sqrt{\\text{Var}(\\hat{S}(t))} = |\\hat{S}(t)| \\sqrt{\\sum_{i: t_i \\le t} \\frac{d_i}{n_i(n_i - d_i)}}\n$$\n\n### Step 2: Construct the Survival Table\nFirst, we order all observations by time and identify the distinct failure times.\nThe observations are at times $t = 2, 4, 4, 5, 6, 7, 7, 9$.\nThe distinct failure times are $t_{(1)} = 2$, $t_{(2)} = 4$, $t_{(3)} = 6$, and $t_{(4)} = 7$.\nThe total number of individuals at the start of the study is $N=8$.\n\n**1. Time $t_{(1)} = 2$**\n-   Number at risk $n_1 = 8$.\n-   Number of failures $d_1 = 1$.\n-   $\\hat{S}(2) = 1 \\times (1 - 1/8) = 7/8$.\n-   Variance term: $\\frac{d_1}{n_1(n_1 - d_1)} = \\frac{1}{8(7)} = \\frac{1}{56}$.\n-   After this time, $n_1 - d_1 = 7$ individuals remain in the risk set.\n\n**2. Time $t_{(2)} = 4$**\n-   Number at risk $n_2 = 7$.\n-   Number of failures $d_2 = 2$ (a tied event).\n-   $\\hat{S}(4) = \\hat{S}(2) \\times (1 - 2/7) = \\frac{7}{8} \\times \\frac{5}{7} = \\frac{5}{8}$.\n-   Variance term: $\\frac{d_2}{n_2(n_2 - d_2)} = \\frac{2}{7(5)} = \\frac{2}{35}$.\n-   After this time, $n_2 - d_2 = 5$ individuals remain. At $t=5$, one individual is censored, leaving $4$ in the risk set for the next event.\n\n**3. Time $t_{(3)} = 6$**\n-   Number at risk $n_3 = 4$.\n-   Number of failures $d_3 = 1$.\n-   $\\hat{S}(6) = \\hat{S}(4) \\times (1 - 1/4) = \\frac{5}{8} \\times \\frac{3}{4} = \\frac{15}{32}$.\n-   Variance term: $\\frac{d_3}{n_3(n_3 - d_3)} = \\frac{1}{4(3)} = \\frac{1}{12}$.\n-   After this time, $n_3 - d_3 = 3$ individuals remain.\n\n**4. Time $t_{(4)} = 7$**\n-   Number at risk $n_4 = 3$.\n-   At $t=7$, there is one failure and one censoring. Per the event-first convention, we process the failure using the risk set of $n_4=3$. So, $d_4 = 1$.\n-   $\\hat{S}(7) = \\hat{S}(6) \\times (1 - 1/3) = \\frac{15}{32} \\times \\frac{2}{3} = \\frac{30}{96} = \\frac{5}{16}$.\n-   Variance term: $\\frac{d_4}{n_4(n_4 - d_4)} = \\frac{1}{3(2)} = \\frac{1}{6}$.\n-   After the failure, one individual is censored. No further events occur.\n\n### Step 3: Compute the Greenwood Standard Error at $t=7$\nWe need to compute the cumulative sum of the variance terms up to $t=7$:\n$$\n\\sum_{i: t_i \\le 7} \\frac{d_i}{n_i(n_i - d_i)} = \\frac{1}{56} + \\frac{2}{35} + \\frac{1}{12} + \\frac{1}{6}\n$$\nFind a common denominator. LCM(56, 35, 12, 6) = 840.\n$$\n= \\frac{15}{840} + \\frac{48}{840} + \\frac{70}{840} + \\frac{140}{840} = \\frac{15+48+70+140}{840} = \\frac{273}{840}\n$$\nSimplify the fraction: $273 = 7 \\times 39 = 7 \\times 3 \\times 13$. $840 = 10 \\times 84 = 10 \\times 7 \\times 12$.\nSo, $\\frac{273}{840} = \\frac{7 \\times 3 \\times 13}{7 \\times 120} = \\frac{39}{120} = \\frac{13}{40}$.\nAlternatively, $\\frac{1}{56} + \\frac{2}{35} = \\frac{5+16}{280} = \\frac{21}{280} = \\frac{3}{40}$. And $\\frac{1}{12} + \\frac{1}{6} = \\frac{1+2}{12} = \\frac{3}{12} = \\frac{1}{4}$.\nSo the sum is $\\frac{3}{40} + \\frac{1}{4} = \\frac{3+10}{40} = \\frac{13}{40}$.\n\nNow, compute the variance of $\\hat{S}(7)$:\n$$\n\\text{Var}(\\hat{S}(7)) = [\\hat{S}(7)]^2 \\sum_{i: t_i \\le 7} \\frac{d_i}{n_i(n_i - d_i)} = \\left(\\frac{5}{16}\\right)^2 \\times \\frac{13}{40} = \\frac{25}{256} \\times \\frac{13}{40} = \\frac{5 \\times 13}{256 \\times 8} = \\frac{65}{2048}\n$$\nThe Greenwood SE is the square root of the variance:\n$$\n\\text{SE}(\\hat{S}(7)) = \\sqrt{\\frac{65}{2048}}\n$$\nFinally, compute the numerical value and round to four significant figures:\n$$\n\\text{SE}(\\hat{S}(7)) = \\sqrt{\\frac{65}{2048}} \\approx \\sqrt{0.03173828...} \\approx 0.1781524...\n$$\nRounding to four significant figures gives $0.1782$.",
            "answer": "$$\\boxed{0.1782}$$"
        },
        {
            "introduction": "While manual calculation is essential for understanding the theory, real-world epidemiological studies involve datasets far too large to analyze by hand. This next exercise challenges you to think algorithmically, translating the core concepts of survival analysis—such as risk sets, left truncation, and event times—into a computational procedure . Developing this skill is a bridge from theoretical knowledge to practical data analysis, a cornerstone of modern biostatistics.",
            "id": "4605689",
            "problem": "You are tasked with designing and implementing an algorithm, grounded in survival analysis principles, that constructs the risk set function and computes quantities needed for the Kaplan–Meier estimator. Each individual is represented by a triplet of entry time, exit time, and event indicator. Time is measured in days, and all outputs must be expressed in days or unitless counts as appropriate. The program you produce must implement the following definitions and conventions and generate outputs for a specified test suite.\n\nDefinitions and conventions:\n- Let there be $N$ individuals, indexed by $j \\in \\{1,2,\\dots,N\\}$. Each individual record consists of $(e_j, x_j, \\delta_j)$ where $e_j$ is the entry time (left truncation), $x_j$ is the exit time, and $\\delta_j \\in \\{0,1\\}$ is the event indicator, with $\\delta_j = 1$ indicating an event at time $x_j$ and $\\delta_j = 0$ indicating censoring at time $x_j$.\n- The risk set at time $t$, denoted $R(t)$, is the set of indices $j$ that satisfy $e_j \\le t \\le x_j$. This convention ensures that individuals who experience an event at time $t$ or are censored at time $t$ are counted as being at risk at time $t$ just prior to removal.\n- The distinct event times are the sorted unique values of $\\{x_j : \\delta_j = 1\\}$. Denote these times by $\\{t_i\\}_{i=1}^m$ where $m$ is the number of distinct event times.\n- For each event time $t_i$, define the risk set size as $n_i = |R(t_i)|$ and the number of events at that time as $d_i = \\sum_{j=1}^N \\mathbf{1}\\{x_j = t_i, \\delta_j = 1\\}$, where $\\mathbf{1}\\{\\cdot\\}$ is the indicator function.\n- All times must be treated in days. The outputs $t_i$ are in days (integers in this test suite), and $n_i$ and $d_i$ are unitless counts (integers).\n\nYour program must:\n- For each test case, compute the list of event times $\\{t_i\\}$, the corresponding risk set sizes $\\{n_i\\}$, and event counts $\\{d_i\\}$ according to the above definitions.\n- Use the inclusion rule $e_j \\le t_i \\le x_j$ for membership in $R(t_i)$.\n- Treat events as occurring at time $t_i$, and censored observations at time $t_i$ as remaining in the risk set at $t_i$ but not contributing to $d_i$.\n\nTest suite:\nProvide outputs for the following five test cases. In each case, the input is a list of records $(e_j, x_j, \\delta_j)$, with all times in days.\n\n- Test case $1$ (happy path with staggered entries, simultaneous events, and censoring):\n  - Records: $[(0,5,1), (0,7,0), (2,5,1), (4,6,1), (3,10,0), (5,8,1)]$.\n  - Expected distinct event times: $[5,6,8]$ in days.\n\n- Test case $2$ (no events; all censored):\n  - Records: $[(0,4,0), (1,3,0), (2,2,0)]$.\n  - Expected distinct event times: $[]$.\n\n- Test case $3$ (left truncation with ties at event times, including entry exactly at event time):\n  - Records: $[(0,4,1), (4,4,0), (2,6,1), (5,6,0), (6,6,1)]$.\n  - Expected distinct event times: $[4,6]$ in days.\n\n- Test case $4$ (boundary with event at time $0$):\n  - Records: $[(0,0,1), (0,1,0), (0,2,1)]$.\n  - Expected distinct event times: $[0,2]$ in days.\n\n- Test case $5$ (simultaneous events with late entry exactly at event time and early censoring):\n  - Records: $[(1,3,1), (2,3,1), (3,3,0), (0,1,0)]$.\n  - Expected distinct event times: $[3]$ in days.\n\nFinal output format specification:\n- For each test case, your program must produce a list of three lists: the list of event times $[t_1,\\dots,t_m]$, the corresponding list $[n_1,\\dots,n_m]$, and the corresponding list $[d_1,\\dots,d_m]$.\n- Aggregate the results for all test cases into a single line printed output containing a comma-separated list of these per-case lists, enclosed in square brackets. For example, a generic format is $[[[t_{1}^{(1)},\\dots],[n_{1}^{(1)},\\dots],[d_{1}^{(1)},\\dots]],[[t_{1}^{(2)},\\dots],[n_{1}^{(2)},\\dots],[d_{1}^{(2)},\\dots]],\\dots]$.\n- Because this output is intended for automated checking, ensure it is exactly one line with no additional text.\n\nYour task is to implement this algorithm and produce the specified output in Python. No user input is required; the test cases must be hard-coded in the program. The answers must be integers for times and counts. The program must be a complete, runnable implementation that adheres to the conventions above and produces the output for the test suite exactly in the specified format.",
            "solution": "The problem is valid. It presents a clear, well-defined task in computational biostatistics, specifically the calculation of quantities required for the Kaplan–Meier estimator in the presence of left-truncated (staggered entry) and right-censored survival data. The definitions provided for the risk set, event times, number at risk, and number of events are standard in survival analysis and are scientifically sound and internally consistent.\n\nThe objective is to develop an algorithm that processes a list of individual records, each represented by a triplet $(e_j, x_j, \\delta_j)$, where $e_j$ is the entry time, $x_j$ is the exit time, and $\\delta_j$ is an event indicator. For the given data, we must compute the set of distinct event times $\\{t_i\\}_{i=1}^m$, and for each event time $t_i$, the corresponding number of individuals at risk, $n_i$, and the number of events, $d_i$. These quantities are fundamental to constructing a Kaplan–Meier survival curve.\n\nThe algorithm proceeds in two primary stages:\n1.  Identification of distinct event times.\n2.  For each event time, calculation of the associated number of events and the size of the risk set.\n\nLet the total number of individuals be $N$, indexed by $j \\in \\{1, 2, \\dots, N\\}$.\n\n**1. Identification of Distinct Event Times, $\\{t_i\\}$**\n\nThe first step is to identify the specific time points at which events of interest occur. An event is indicated by $\\delta_j = 1$. The time of the event for individual $j$ is their exit time, $x_j$. We collect all such times from the dataset: $\\{x_j \\mid \\delta_j = 1\\}$. Since multiple events can occur at the same time, this collection may contain duplicate values. To obtain the set of distinct event times, we take the unique values from this collection and sort them in ascending chronological order. Let these sorted, unique event times be denoted by $t_1, t_2, \\dots, t_m$, where $m$ is the total number of distinct event times. If no events occur in the dataset (i.e., $\\delta_j = 0$ for all $j$), then this set is empty, so $m=0$.\n\n**2. Calculation of Event Counts $\\{d_i\\}$ and Risk Set Sizes $\\{n_i\\}$**\n\nFor each distinct event time $t_i$ identified in the first step, we must compute two quantities: $d_i$ and $n_i$.\n\n-   **Number of Events ($d_i$)**: The quantity $d_i$ is the total count of individuals who experience an event precisely at time $t_i$. This is calculated by iterating through all $N$ individuals and counting how many satisfy both conditions: their exit time $x_j$ is equal to $t_i$ and their event indicator $\\delta_j$ is $1$.\n    $$d_i = \\sum_{j=1}^N \\mathbf{1}\\{x_j = t_i \\text{ and } \\delta_j = 1\\}$$\n    where $\\mathbf{1}\\{\\cdot\\}$ is the indicator function, which is $1$ if the condition is true and $0$ otherwise.\n\n-   **Risk Set Size ($n_i$)**: The quantity $n_i$ represents the number of individuals who are at risk of experiencing the event at time $t_i$. The problem specifies the risk set at time $t$, $R(t)$, as the set of individuals $j$ for whom $e_j \\le t \\le x_j$. This definition correctly includes individuals who enter the study at or before time $t$ and are still under observation at time $t$. An individual exiting at time $t$ (due to an event or censoring) is considered to be at risk just prior to their exit, and thus is included in the risk set $R(t)$. Therefore, the size of the risk set at event time $t_i$, denoted $n_i$, is the cardinality of $R(t_i)$:\n    $$n_i = |R(t_i)| = \\sum_{j=1}^N \\mathbf{1}\\{e_j \\le t_i \\le x_j\\}$$\n\nBy iterating through each $t_i$ in the sorted list of distinct event times and performing these two calculations, we can construct the required lists $\\{t_i\\}$, $\\{n_i\\}$, and $\\{d_i\\}$.\n\n**Example Walkthrough: Test Case 1**\n\nLet's apply this algorithm to the first test case.\nThe records are $[(0,5,1), (0,7,0), (2,5,1), (4,6,1), (3,10,0), (5,8,1)]$.\n\n**Step 1: Find Event Times $\\{t_i\\}$**\n-   Individuals with events ($\\delta_j=1$) are $(0,5,1)$, $(2,5,1)$, $(4,6,1)$, and $(5,8,1)$.\n-   The corresponding event times are $\\{5, 5, 6, 8\\}$.\n-   The sorted unique event times are $\\{t_i\\} = [5, 6, 8]$. Thus, $t_1=5$, $t_2=6$, and $t_3=8$.\n\n**Step 2: Calculate $\\{d_i\\}$ and $\\{n_i\\}$**\n\n-   **For $t_1 = 5$**:\n    -   $d_1$: Count of events at time $5$. The records are $(0,5,1)$ and $(2,5,1)$. So, $d_1 = 2$.\n    -   $n_1$: Count of individuals at risk at time $5$ (condition: $e_j \\le 5 \\le x_j$).\n        -   $(0,5,1)$: $0 \\le 5 \\le 5$ (Yes)\n        -   $(0,7,0)$: $0 \\le 5 \\le 7$ (Yes)\n        -   $(2,5,1)$: $2 \\le 5 \\le 5$ (Yes)\n        -   $(4,6,1)$: $4 \\le 5 \\le 6$ (Yes)\n        -   $(3,10,0)$: $3 \\le 5 \\le 10$ (Yes)\n        -   $(5,8,1)$: $5 \\le 5 \\le 8$ (Yes)\n    -   Total count is $n_1 = 6$.\n\n-   **For $t_2 = 6$**:\n    -   $d_2$: Count of events at time $6$. The record is $(4,6,1)$. So, $d_2 = 1$.\n    -   $n_2$: Count of individuals at risk at time $6$ (condition: $e_j \\le 6 \\le x_j$).\n        -   $(0,7,0)$: $0 \\le 6 \\le 7$ (Yes)\n        -   $(4,6,1)$: $4 \\le 6 \\le 6$ (Yes)\n        -   $(3,10,0)$: $3 \\le 6 \\le 10$ (Yes)\n        -   $(5,8,1)$: $5 \\le 6 \\le 8$ (Yes)\n    -   Individuals $(0,5,1)$ and $(2,5,1)$ are no longer at risk as their $x_j=5  6$.\n    -   Total count is $n_2 = 4$.\n\n-   **For $t_3 = 8$**:\n    -   $d_3$: Count of events at time $8$. The record is $(5,8,1)$. So, $d_3 = 1$.\n    -   $n_3$: Count of individuals at risk at time $8$ (condition: $e_j \\le 8 \\le x_j$).\n        -   $(3,10,0)$: $3 \\le 8 \\le 10$ (Yes)\n        -   $(5,8,1)$: $5 \\le 8 \\le 8$ (Yes)\n    -   Individuals $(0,7,0)$, $(4,6,1)$ are no longer at risk as their $x_j  8$.\n    -   Total count is $n_3 = 2$.\n\nThe final result for this test case is the three lists: $t = [5, 6, 8]$, $n = [6, 4, 2]$, and $d = [2, 1, 1]$. The implementation will apply this exact logic to all provided test cases.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n# from scipy import ...\n\ndef solve():\n    \"\"\"\n    Computes distinct event times, risk set sizes, and event counts for survival data,\n    then formats the results for all test cases into a single-line string.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # Test case 1\n        [(0,5,1), (0,7,0), (2,5,1), (4,6,1), (3,10,0), (5,8,1)],\n        # Test case 2\n        [(0,4,0), (1,3,0), (2,2,0)],\n        # Test case 3\n        [(0,4,1), (4,4,0), (2,6,1), (5,6,0), (6,6,1)],\n        # Test case 4\n        [(0,0,1), (0,1,0), (0,2,1)],\n        # Test case 5\n        [(1,3,1), (2,3,1), (3,3,0), (0,1,0)],\n    ]\n\n    all_results = []\n    for records in test_cases:\n        # If there are no records, handle as a special case.\n        if not records:\n            all_results.append([[], [], []])\n            continue\n            \n        # Convert records to a NumPy array for efficient vectorized operations.\n        # Columns: 0=entry_time (e_j), 1=exit_time (x_j), 2=event_indicator (delta_j)\n        data = np.array(records, dtype=int)\n\n        # 1. Identify distinct event times (t_i)\n        # Filter for records where an event occurred (delta_j = 1).\n        event_mask = data[:, 2] == 1\n        # Extract the exit times (x_j) for these events.\n        event_times = data[event_mask, 1]\n        # Find the unique, sorted event times. np.unique conveniently sorts the result.\n        distinct_event_times = np.unique(event_times).tolist()\n\n        # If there are no events, the result is three empty lists.\n        if not distinct_event_times:\n            all_results.append([[], [], []])\n            continue\n\n        risk_set_sizes = []\n        event_counts = []\n        \n        # 2. For each distinct event time, calculate n_i and d_i\n        for t_i in distinct_event_times:\n            # Calculate d_i: number of events at t_i.\n            # This is the count of records where exit_time is t_i AND an event occurred.\n            d_i = np.sum((data[:, 1] == t_i)  (data[:, 2] == 1))\n            event_counts.append(int(d_i)) # Ensure it's a standard Python int\n\n            # Calculate n_i: number of individuals at risk at t_i.\n            # This is the count of records where entry_time = t_i = exit_time.\n            n_i = np.sum((data[:, 0] = t_i)  (t_i = data[:, 1]))\n            risk_set_sizes.append(int(n_i)) # Ensure it's a standard Python int\n            \n        all_results.append([\n            distinct_event_times,\n            risk_set_sizes,\n            event_counts\n        ])\n\n    # 3. Format the final output string exactly as specified.\n    # The output must be a single line, with no spaces between list elements.\n    case_strings = []\n    for res in all_results:\n        # res is a list of three lists: [[t_i...], [n_i...], [d_i...]]\n        t_str = f\"[{','.join(map(str, res[0]))}]\"\n        n_str = f\"[{','.join(map(str, res[1]))}]\"\n        d_str = f\"[{','.join(map(str, res[2]))}]\"\n        case_str = f\"[{t_str},{n_str},{d_str}]\"\n        case_strings.append(case_str)\n        \n    final_output_str = f\"[{','.join(case_strings)}]\"\n\n    print(final_output_str)\n\nsolve()\n```"
        },
        {
            "introduction": "Constructing a survival curve is only half the battle; interpreting it correctly is paramount for drawing valid scientific conclusions. This final practice presents a common scenario in clinical research where a direct comparison of median survival times is impossible because one group's survival is so favorable that the median is not reached during the study period . This exercise will sharpen your critical thinking skills, encouraging you to evaluate the limitations of common summary statistics and select more robust and appropriate methods for reporting study findings.",
            "id": "4605656",
            "problem": "A randomized trial in epidemiology compares two groups, a new therapy (Group T) and standard care (Group C), on time to a composite adverse outcome. Follow-up is administratively censored at $36$ months for all participants. The survival experience is summarized using the Kaplan–Meier estimator, which is the nonparametric product-limit estimator of the survival function $S(t) = \\mathbb{P}(T > t)$ under right censoring. The Kaplan–Meier curves show that Group C’s estimated survival curve decreases below $0.5$ at approximately $21$ months, while Group T’s estimated survival curve remains above $0.5$ throughout the $36$-month follow-up window. Investigators initially planned to report the difference in median survival times between groups.\n\nWhich option best interprets the situation and proposes an appropriate, scientifically sound nonparametric summary, given that one group’s Kaplan–Meier curve does not cross $0.5$ within the observed window?\n\nA. Report the difference in medians by substituting $36$ months for Group T’s median, treating the administrative censoring time as a conservative estimate of the median, since at least half the Group T participants outlasted $36$ months.\n\nB. Conclude that the median survival for Group T is not reached within $36$ months, so the difference in medians is not estimable from the observed data; instead, summarize group differences using the difference in restricted mean survival time up to a prespecified truncation time (e.g., $\\tau = 36$ months) and compare time-specific survival probabilities (e.g., $S(12)$, $S(24)$, $S(36)$).\n\nC. Fit a Cox proportional hazards model and report the hazard ratio as the primary summary, because hazard ratios do not require estimation of medians and thus avoid the problem of the Kaplan–Meier curve not crossing $0.5$.\n\nD. Estimate and compare mean survival times by extrapolating both Kaplan–Meier curves linearly to $0$ beyond $36$ months, since the area under the curve estimates the mean survival and linear extrapolation provides a simple completion of the tail.\n\nE. Compare the $25$th percentile survival times (the time by which $25\\%$ have had the event) across groups, since both curves cross $0.75$ within $36$ months, making lower quantiles better substitutes for medians in this situation.",
            "solution": "The problem asks for the most appropriate nonparametric summary for a clinical trial where the Kaplan–Meier curve for one group (Group T) does not reach the median survival ($S(t) \\le 0.5$) within the study's follow-up period. This means the median survival time for Group T is not estimable from the observed data.\n\n-   **Option A is incorrect.** Substituting the last observation time ($36$ months) for the median is a form of ad-hoc imputation. It is not a statistical estimate and has no theoretical justification. This approach understates the true median survival of Group T, as we only know the median is *greater than* $36$ months. Reporting a biased point estimate is scientifically unsound.\n\n-   **Option B is the correct and most comprehensive approach.** It correctly identifies that the median survival for Group T is not estimable and proposes two standard, robust alternatives.\n    1.  **Restricted Mean Survival Time (RMST):** The RMST up to a time $\\tau$ (e.g., $\\tau = 36$ months) is the area under the Kaplan–Meier curve from $t=0$ to $t=\\tau$. It represents the average event-free time during that window. The difference in RMST between two groups provides an intuitive summary of the average time gained or lost, and it is a valid measure even when medians are not estimable or when the proportional hazards assumption is violated.\n    2.  **Time-Specific Survival Probabilities:** Comparing the estimated survival probabilities at specific, clinically relevant time points (e.g., $S(12)$, $S(24)$, and $S(36)$) provides a clear, easy-to-interpret snapshot of the treatment effect over time. This is a standard reporting practice in clinical trials.\n\n-   **Option C is inappropriate as a primary summary of the nonparametric curves.** While the hazard ratio (HR) from a Cox model is a common effect measure, it is the result of a semi-parametric *model*, not a direct summary of the nonparametric Kaplan–Meier estimates. Furthermore, it relies on the proportional hazards assumption, which may not be valid (e.g., if the curves converge or diverge over time). Using an HR would be a shift in analytical strategy, not a solution to summarizing the existing curves.\n\n-   **Option D is incorrect.** Extrapolating the Kaplan–Meier curve beyond the last observation is highly speculative and assumption-dependent. There is no theoretical basis for a linear extrapolation of a survival curve, and such a method would likely produce a highly inaccurate estimate of the mean survival time. The proper way to handle this is to report the mean as restricted to the follow-up period (which is what RMST does).\n\n-   **Option E is a possible but suboptimal approach.** Comparing lower quantiles (like the $25^{th}$ percentile) is a valid way to compare the curves, as these points may be estimable for both groups. However, this focuses only on early events and discards information about the survival experience over the rest of the follow-up period. It is a much less complete summary than the RMST, which integrates information over the entire chosen time window.\n\nTherefore, option B presents the most methodologically sound and complete strategy for summarizing the findings in this common clinical trial scenario.",
            "answer": "$$\\boxed{B}$$"
        }
    ]
}