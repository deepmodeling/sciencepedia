{
    "hands_on_practices": [
        {
            "introduction": "After fitting a logistic regression model with a gene-environment interaction term, the fundamental next step is to assess its statistical significance. This exercise introduces three cornerstone methods for hypothesis testing in likelihood-based models: the Wald, Score, and Likelihood Ratio tests. By applying these three distinct but asymptotically equivalent approaches to the same hypothetical dataset, you will gain a robust toolkit for evaluating statistical evidence and a deeper appreciation for the theory underlying the p-values produced by statistical software .",
            "id": "4594333",
            "problem": "A case-control study of a complex disease investigates whether the joint effect of a binary genetic variant and a binary environmental exposure departs from additivity on the log-odds scale. Let $Y \\in \\{0,1\\}$ denote disease status, $G \\in \\{0,1\\}$ denote presence of the risk allele, and $E \\in \\{0,1\\}$ denote exposure. A logistic regression model is fit that includes main effects and a gene–environment interaction term:\n$$\n\\ln\\left(\\frac{\\Pr(Y=1 \\mid G,E)}{1 - \\Pr(Y=1 \\mid G,E)}\\right) = \\beta_{0} + \\beta_{G} G + \\beta_{E} E + \\beta_{GE} (G E).\n$$\nThe null hypothesis is $H_{0}: \\beta_{GE} = 0$.\n\nFrom the fitted model on $n=1{,}600$ individuals (balanced cases and controls), the following quantities are obtained:\n- The Maximum Likelihood Estimator (MLE) of the interaction coefficient is $\\hat{\\beta}_{GE} = 0.357771$ with estimated variance $\\widehat{\\mathrm{Var}}(\\hat{\\beta}_{GE}) = 0.04$ from the full model.\n- The maximized log-likelihood under the full model (with $\\beta_{GE}$ free) is $\\ell_{1} = -120.4$, and under the reduced model constrained by $H_{0}$ is $\\ell_{0} = -122.0$.\n- The score for $\\beta_{GE}$ evaluated at $H_{0}$ in the reduced model is $U_{0} = 8.944272$, and the corresponding expected Fisher information at $H_{0}$ is $I_{0} = 25.0$.\n\nUsing these quantities and first principles for likelihood-based inference in generalized linear models, compute the scalar test statistics for the Wald test, the score test, and the likelihood ratio test for $H_{0}: \\beta_{GE} = 0$. Provide your answer as a single row vector in the order (Wald, score, likelihood ratio), and round each entry to four significant figures. No units are required.",
            "solution": "The logistic regression model specifies the log-odds (logit) of the outcome as a linear function of covariates. In maximum likelihood inference for parametric models, three classical tests for a scalar parameter $\\beta$ under a null hypothesis $H_{0}: \\beta = \\beta_{0}$ are based on:\n- The Maximum Likelihood Estimator (MLE) $\\hat{\\beta}$ and its estimated variance $\\widehat{\\mathrm{Var}}(\\hat{\\beta})$ (Wald test).\n- The score function (the gradient of the log-likelihood) evaluated at the null, $U_{0} = \\left.\\frac{\\partial \\ell(\\beta)}{\\partial \\beta}\\right|_{\\beta=\\beta_{0}}$, together with the Fisher information under the null, $I_{0}$ (score test).\n- The difference between the maximized log-likelihoods under the full and reduced models, $\\ell_{1}$ and $\\ell_{0}$ (likelihood ratio test).\n\nUnder standard regularity conditions and large samples, these tests yield statistics that are asymptotically equivalent and, for a one-parameter test, are compared to a chi-square distribution with one degree of freedom. We compute each statistic using the provided quantities.\n\nLet us define $\\beta \\equiv \\beta_{GE}$ and $\\beta_{0} \\equiv 0$.\n\n1. Wald test statistic. The Wald statistic for testing $H_{0}:\\beta=\\beta_{0}$ is constructed from the standardized distance between the MLE and the null value. Denote the estimated standard error by $\\widehat{\\mathrm{SE}}(\\hat{\\beta}) = \\sqrt{\\widehat{\\mathrm{Var}}(\\hat{\\beta})}$. Here,\n$$\n\\widehat{\\mathrm{SE}}(\\hat{\\beta}) = \\sqrt{0.04} = 0.2.\n$$\nThe Wald statistic is then\n$$\nW = \\left(\\frac{\\hat{\\beta} - \\beta_{0}}{\\widehat{\\mathrm{SE}}(\\hat{\\beta})}\\right)^{2} = \\left(\\frac{0.357771 - 0}{0.2}\\right)^{2} = (1.788855)^{2}.\n$$\nCompute the square:\n$$\nW \\approx 3.200.\n$$\nRounded to four significant figures, $W = 3.200$.\n\n2. Score test statistic. The score test uses the score $U_{0}$ and the Fisher information $I_{0}$ evaluated under the null. The score statistic is\n$$\nS = \\frac{U_{0}^{2}}{I_{0}} = \\frac{(8.944272)^{2}}{25.0}.\n$$\nSince $8.944272$ is the square root of $80$, we have\n$$\nS = \\frac{80}{25} = 3.2.\n$$\nRounded to four significant figures, $S = 3.200$.\n\n3. Likelihood ratio test statistic. The likelihood ratio statistic is based on the difference in maximized log-likelihoods between the full and reduced models:\n$$\nL = 2\\left(\\ell_{1} - \\ell_{0}\\right) = 2\\left(-120.4 - (-122.0)\\right) = 2\\left(1.6\\right) = 3.2.\n$$\nRounded to four significant figures, $L = 3.200$.\n\nThus, all three test statistics are approximately equal at $3.200$, which is expected under large-sample conditions for a single parameter test where the information is well-behaved.\n\nThe requested row vector in the order (Wald, score, likelihood ratio), each rounded to four significant figures, is\n$$\n\\begin{pmatrix}\n3.200 & 3.200 & 3.200\n\\end{pmatrix}.\n$$",
            "answer": "$$\\boxed{\\begin{pmatrix}3.200 & 3.200 & 3.200\\end{pmatrix}}$$"
        },
        {
            "introduction": "The influence of genetics on disease risk is not always linear, meaning the risk may not increase uniformly with each additional copy of an allele. This practice explores a more nuanced model that incorporates a quadratic term for gene dosage, $G^2$, to capture such non-additive effects and examines how this interacts with an environmental exposure. By deriving and quantifying how the per-allele odds ratio changes across different genetic backgrounds, you will learn to dissect and interpret more complex gene-environment architectures that better reflect biological reality .",
            "id": "4594344",
            "problem": "A case–control study investigates a complex disease and a candidate Single Nucleotide Polymorphism (SNP). Genotypes are imputed, and the SNP dosage $G$ is defined as the expected number of risk alleles, taking values in $[0,2]$. An environmental exposure $E$ is measured on a continuous scale and is mean-centered. To assess gene–environment interplay and possible departure from additivity in allelic effects, researchers fit a logistic regression model for disease status $Y \\in \\{0,1\\}$ of the form\n$$\n\\ln\\left(\\frac{\\Pr(Y=1 \\mid G,E)}{1-\\Pr(Y=1 \\mid G,E)}\\right) \\;=\\; \\beta_{0} \\;+\\; \\beta_{G} G \\;+\\; \\beta_{E} E \\;+\\; \\beta_{GE} G E \\;+\\; \\beta_{Q} G^{2}.\n$$\nThis specification allows the environmental exposure $E$ to modify the linear (additive) allelic effect via the product term $G E$, and it allows departures from strict additivity of allelic effects via the curvature term $G^{2}$. Suppose the fitted coefficients are\n$$\n\\beta_{0} = -3.2,\\quad \\beta_{G} = 0.6,\\quad \\beta_{E} = 0.3,\\quad \\beta_{GE} = 0.05,\\quad \\beta_{Q} = -0.1.\n$$\nUsing only the fundamental definitions of odds, odds ratio, and the logistic model, do the following:\n1. For a fixed exposure level $E=e$, define the per-allele odds ratio at dosage $G=g$ for a one-unit increase in dosage as $\\mathrm{OR}(g \\to g+1 \\mid e) = \\dfrac{\\text{odds}(Y=1 \\mid G=g+1, E=e)}{\\text{odds}(Y=1 \\mid G=g, E=e)}$. Derive a closed-form expression for $\\mathrm{OR}(g \\to g+1 \\mid e)$ in terms of $g$, $e$, and the regression coefficients, and then evaluate it at $g=0.8$ and $e=1.5$.\n2. Define the departure-from-additivity factor at $(g,e)$ as\n$$\nR(g,e) \\;=\\; \\frac{\\mathrm{OR}(g \\to g+1 \\mid e)}{\\mathrm{OR}_{\\text{add}}(e)},\n$$\nwhere $\\mathrm{OR}_{\\text{add}}(e)$ is the per-allele odds ratio computed under the allelic additivity constraint $\\beta_{Q}=0$ while keeping $\\beta_{0}$, $\\beta_{G}$, $\\beta_{E}$, and $\\beta_{GE}$ unchanged. Derive a closed-form expression for $R(g,e)$, and then evaluate it at $g=0.8$ and $e=1.5$.\n\nRound all numerical values to $4$ significant figures. Report the two requested numerical values in the order: $\\mathrm{OR}(0.8 \\to 1.8 \\mid 1.5)$, $R(0.8,1.5)$. Odds ratios are unitless.",
            "solution": "The problem is valid as it is scientifically grounded in standard epidemiological modeling, well-posed with a complete and consistent set of definitions and data, and objectively formulated. We may proceed with the solution.\n\nThe logistic regression model provides the log-odds of the disease ($Y=1$) as a function of the SNP dosage $G$ and environmental exposure $E$:\n$$\n\\text{logit}(P(Y=1 \\mid G,E)) = \\ln\\left(\\frac{P(Y=1 \\mid G,E)}{1-P(Y=1 \\mid G,E)}\\right) = \\ln(\\text{odds}(Y=1 \\mid G,E))\n$$\nThe specified model is:\n$$\n\\ln(\\text{odds}(Y=1 \\mid G,E)) = \\beta_{0} + \\beta_{G} G + \\beta_{E} E + \\beta_{GE} G E + \\beta_{Q} G^{2}\n$$\n\n**1. Per-allele Odds Ratio, $\\mathrm{OR}(g \\to g+1 \\mid e)$**\n\nThe per-allele odds ratio for a one-unit increase in dosage from $G=g$ to $G=g+1$ at a fixed exposure level $E=e$ is defined as:\n$$\n\\mathrm{OR}(g \\to g+1 \\mid e) = \\frac{\\text{odds}(Y=1 \\mid G=g+1, E=e)}{\\text{odds}(Y=1 \\mid G=g, E=e)}\n$$\nTo derive a closed-form expression, we work with the natural logarithm of the odds ratio, which is the difference between the log-odds at the two dosage levels:\n$$\n\\ln(\\mathrm{OR}(g \\to g+1 \\mid e)) = \\ln(\\text{odds}(Y=1 \\mid G=g+1, E=e)) - \\ln(\\text{odds}(Y=1 \\mid G=g, E=e))\n$$\nWe substitute the model expression for each log-odds term:\n$$\n\\ln(\\text{odds}(Y=1 \\mid G=g+1, E=e)) = \\beta_{0} + \\beta_{G}(g+1) + \\beta_{E}e + \\beta_{GE}(g+1)e + \\beta_{Q}(g+1)^{2}\n$$\n$$\n\\ln(\\text{odds}(Y=1 \\mid G=g, E=e)) = \\beta_{0} + \\beta_{G}g + \\beta_{E}e + \\beta_{GE}ge + \\beta_{Q}g^{2}\n$$\nSubtracting the second equation from the first yields:\n$$\n\\ln(\\mathrm{OR}(g \\to g+1 \\mid e)) = \\left( \\beta_{0} + \\beta_{G}(g+1) + \\beta_{E}e + \\beta_{GE}(g+1)e + \\beta_{Q}(g+1)^{2} \\right) - \\left( \\beta_{0} + \\beta_{G}g + \\beta_{E}e + \\beta_{GE}ge + \\beta_{Q}g^{2} \\right)\n$$\nThe terms $\\beta_{0}$ and $\\beta_{E}e$ cancel out. Grouping the remaining terms by coefficient:\n$$\n\\ln(\\mathrm{OR}(g \\to g+1 \\mid e)) = \\beta_{G}((g+1)-g) + \\beta_{GE}e((g+1)-g) + \\beta_{Q}((g+1)^{2}-g^{2})\n$$\nSimplifying the expressions in the parentheses:\n$$\n(g+1)-g = 1\n$$\n$$\n(g+1)^{2}-g^{2} = (g^{2}+2g+1) - g^{2} = 2g+1\n$$\nSubstituting these back gives the expression for the log-odds-ratio:\n$$\n\\ln(\\mathrm{OR}(g \\to g+1 \\mid e)) = \\beta_{G} + \\beta_{GE}e + \\beta_{Q}(2g+1)\n$$\nExponentiating both sides provides the closed-form expression for the odds ratio:\n$$\n\\mathrm{OR}(g \\to g+1 \\mid e) = \\exp\\left( \\beta_{G} + \\beta_{GE}e + \\beta_{Q}(2g+1) \\right)\n$$\nWe are asked to evaluate this at $g=0.8$ and $e=1.5$ using the given coefficients: $\\beta_{G} = 0.6$, $\\beta_{GE} = 0.05$, and $\\beta_{Q} = -0.1$.\n$$\n\\mathrm{OR}(0.8 \\to 1.8 \\mid 1.5) = \\exp\\left( 0.6 + (0.05)(1.5) + (-0.1)(2(0.8)+1) \\right)\n$$\n$$\n= \\exp\\left( 0.6 + 0.075 - 0.1(1.6+1) \\right)\n$$\n$$\n= \\exp\\left( 0.675 - 0.1(2.6) \\right)\n$$\n$$\n= \\exp\\left( 0.675 - 0.26 \\right)\n$$\n$$\n= \\exp(0.415) \\approx 1.514419\n$$\nRounding to $4$ significant figures, we get $1.514$.\n\n**2. Departure-from-Additivity Factor, $R(g,e)$**\n\nThe departure-from-additivity factor is defined as:\n$$\nR(g,e) = \\frac{\\mathrm{OR}(g \\to g+1 \\mid e)}{\\mathrm{OR}_{\\text{add}}(e)}\n$$\nFirst, we must find the expression for $\\mathrm{OR}_{\\text{add}}(e)$. This is the per-allele odds ratio under a model with the allelic additivity constraint $\\beta_{Q}=0$. The additive model is:\n$$\n\\ln(\\text{odds}_{\\text{add}}(Y=1 \\mid G,E)) = \\beta_{0} + \\beta_{G} G + \\beta_{E} E + \\beta_{GE} G E\n$$\nFollowing the same derivation as in Part 1 but with $\\beta_{Q}=0$, the log-odds-ratio becomes:\n$$\n\\ln(\\mathrm{OR}_{\\text{add}}(e)) = \\beta_{G} + \\beta_{GE}e + 0 \\cdot (2g+1) = \\beta_{G} + \\beta_{GE}e\n$$\nThus, the odds ratio under additivity is:\n$$\n\\mathrm{OR}_{\\text{add}}(e) = \\exp\\left( \\beta_{G} + \\beta_{GE}e \\right)\n$$\nNote that this quantity is independent of the dosage level $g$, which is the defining feature of a model that is log-linear in $G$ (for a fixed $E$).\nNow we can derive the closed-form expression for $R(g,e)$ by substituting the expressions for the two odds ratios:\n$$\nR(g,e) = \\frac{\\exp\\left( \\beta_{G} + \\beta_{GE}e + \\beta_{Q}(2g+1) \\right)}{\\exp\\left( \\beta_{G} + \\beta_{GE}e \\right)}\n$$\nUsing the property $\\frac{\\exp(a)}{\\exp(b)} = \\exp(a-b)$:\n$$\nR(g,e) = \\exp\\left( (\\beta_{G} + \\beta_{GE}e + \\beta_{Q}(2g+1)) - (\\beta_{G} + \\beta_{GE}e) \\right)\n$$\n$$\nR(g,e) = \\exp\\left( \\beta_{Q}(2g+1) \\right)\n$$\nThis expression isolates the contribution of the non-additive (quadratic) term to the per-allele odds ratio.\nWe evaluate this at $g=0.8$ and $e=1.5$. Note that $R(g,e)$ is independent of $e$ in this model.\n$$\nR(0.8, 1.5) = \\exp\\left( (-0.1)(2(0.8)+1) \\right)\n$$\n$$\n= \\exp\\left( -0.1(1.6+1) \\right)\n$$\n$$\n= \\exp\\left( -0.1(2.6) \\right)\n$$\n$$\n= \\exp(-0.26) \\approx 0.771051\n$$\nRounding to $4$ significant figures, we get $0.7711$.\n\nThe two requested numerical values are $\\mathrm{OR}(0.8 \\to 1.8 \\mid 1.5) \\approx 1.514$ and $R(0.8, 1.5) \\approx 0.7711$.",
            "answer": "$$\\boxed{\\begin{pmatrix} 1.514 & 0.7711 \\end{pmatrix}}$$"
        },
        {
            "introduction": "In any real-world analysis, our statistical model is an approximation of the true data-generating process. This advanced computational problem investigates the critical consequences of model misspecification—specifically, what happens to our gene-environment interaction estimate when we fail to account for a non-linear effect of the environmental exposure? This exercise demonstrates how omitting a term like $E^2$ can introduce significant bias into the interaction coefficient $\\beta_{GE}$, a key insight into the fragility and interpretation of statistical models. Developing the skill to assess such biases is essential for any applied epidemiologist .",
            "id": "4594313",
            "problem": "You are given a binary disease outcome model grounded in epidemiology and genetic epidemiology. Let $Y \\in \\{0,1\\}$ denote a disease indicator, $G \\in \\{0,1\\}$ denote a genotype indicator for the presence of a risk allele, and $E \\in \\mathbb{R}$ denote a continuous environmental exposure. Assume $G$ and $E$ are independent. The true data-generating mechanism follows a logistic regression with a nonlinear environmental effect:\n$$\n\\operatorname{logit}\\left(\\Pr(Y=1 \\mid G, E)\\right) \\equiv \\log\\left(\\frac{\\Pr(Y=1 \\mid G, E)}{1-\\Pr(Y=1 \\mid G, E)}\\right) = \\beta_0 + \\beta_G G + \\beta_{E1} E + \\beta_{E2} E^2 + \\beta_{GE} G E,\n$$\nwhere $E \\sim \\mathcal{N}(\\mu, \\sigma^2)$ and $G \\sim \\operatorname{Bernoulli}(p)$. The interaction term $G E$ represents a gene–environment interaction. Consider fitting a working model that omits the nonlinear environmental term $E^2$, namely:\n$$\n\\operatorname{logit}\\left(\\Pr(Y=1 \\mid G, E)\\right) = \\alpha_0 + \\alpha_G G + \\alpha_E E + \\alpha_{GE} G E.\n$$\n\nFrom the principles of maximum likelihood estimation and the theory of misspecified models, under standard regularity conditions, estimators from the misspecified working model converge to the parameter vector that zeroes the population score (the pseudo-true parameter). That is, the limiting parameter $\\alpha^\\star = (\\alpha_0^\\star, \\alpha_G^\\star, \\alpha_E^\\star, \\alpha_{GE}^\\star)$ satisfies the system:\n$$\n\\mathbb{E}\\left[ X \\left\\{Y - \\mu_\\alpha(G,E)\\right\\} \\right] = \\mathbf{0},\n$$\nwhere $X = (1, G, E, G E)^\\top$, $\\mu_\\alpha(G,E) = \\operatorname{expit}\\left(\\alpha_0 + \\alpha_G G + \\alpha_E E + \\alpha_{GE} G E\\right)$, and $\\operatorname{expit}(x) = \\frac{1}{1 + e^{-x}}$. The expectation $\\mathbb{E}[\\cdot]$ is taken over the joint distribution of $(G, E)$, and $Y$ is generated according to the true data-generating mechanism with $\\Pr(Y=1 \\mid G, E) = \\operatorname{expit}\\left(\\beta_0 + \\beta_G G + \\beta_{E1} E + \\beta_{E2} E^2 + \\beta_{GE} G E\\right)$.\n\nYour task is to compute, for several specified parameter sets, the pseudo-true parameter $\\alpha^\\star$ for the misspecified working model and then report the bias in the gene–environment interaction estimate, defined as $\\alpha_{GE}^\\star - \\beta_{GE}$. This quantifies the bias introduced by model misspecification and nonlinearity in $E$.\n\nThe final program must:\n- Use numerical methods to solve the system $\\mathbb{E}\\left[ X \\left\\{Y - \\mu_\\alpha(G,E)\\right\\} \\right] = \\mathbf{0}$ for $\\alpha^\\star$ given the parameters $(\\beta_0, \\beta_G, \\beta_{E1}, \\beta_{E2}, \\beta_{GE}, p, \\mu, \\sigma)$.\n- Treat $G$ and $E$ as independent, with $G \\sim \\operatorname{Bernoulli}(p)$ and $E \\sim \\mathcal{N}(\\mu, \\sigma^2)$.\n- Compute the expected value via integration over the distribution of $E$ and summation over $G \\in \\{0,1\\}$.\n- Return, for each test case, a single real number equal to the bias $\\alpha_{GE}^\\star - \\beta_{GE}$, rounded to $6$ decimal places.\n\nFundamental base to use:\n- The logistic link definition $\\operatorname{logit}(p) = \\log\\left(\\frac{p}{1-p}\\right)$ and its inverse $\\operatorname{expit}(x) = \\frac{1}{1 + e^{-x}}$.\n- Independence of $G$ and $E$ and properties of expectations under independence.\n- The principle that maximum likelihood estimation under misspecification converges to the parameter that zeroes the population score.\n\nTest suite:\nUse the following parameter sets, each specified as $(\\beta_0, \\beta_G, \\beta_{E1}, \\beta_{E2}, \\beta_{GE}, p, \\mu, \\sigma)$:\n- Case $1$ (happy path, clear nonlinearity): $(\\beta_0=-2.0, \\beta_G=0.6, \\beta_{E1}=0.8, \\beta_{E2}=0.5, \\beta_{GE}=0.4, p=0.3, \\mu=0.0, \\sigma=1.0)$.\n- Case $2$ (boundary: no nonlinearity): $(\\beta_0=-2.0, \\beta_G=0.6, \\beta_{E1}=0.8, \\beta_{E2}=0.0, \\beta_{GE}=0.4, p=0.3, \\mu=0.0, \\sigma=1.0)$.\n- Case $3$ (edge: shifted exposure mean and rarer allele): $(\\beta_0=-3.0, \\beta_G=1.0, \\beta_{E1}=0.6, \\beta_{E2}=0.7, \\beta_{GE}=0.5, p=0.1, \\mu=1.0, \\sigma=1.0)$.\n- Case $4$ (edge: larger exposure variance): $(\\beta_0=-1.5, \\beta_G=0.5, \\beta_{E1}=0.5, \\beta_{E2}=0.8, \\beta_{GE}=0.2, p=0.5, \\mu=0.0, \\sigma=2.0)$.\n\nFinal output format:\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, with each entry corresponding to the bias $\\alpha_{GE}^\\star - \\beta_{GE}$ for the respective test case, rounded to $6$ decimal places (e.g., $[0.000123,-0.001456,0.000000,0.023459]$). No other text should be printed.",
            "solution": "The problem requires the calculation of the bias in the gene–environment interaction coefficient when a logistic regression model is misspecified by omitting a quadratic term for a continuous environmental exposure. This involves finding the pseudo-true parameters of the misspecified model.\n\n### **1. Theoretical Framework**\n\nLet the true data-generating process be a logistic model for a binary outcome $Y$, given a binary genotype $G$ and a continuous exposure $E$:\n$$\n\\operatorname{logit}\\left(\\Pr(Y=1 \\mid G, E)\\right) = \\eta_\\beta(G, E) = \\beta_0 + \\beta_G G + \\beta_{E1} E + \\beta_{E2} E^2 + \\beta_{GE} G E\n$$\nLet $\\mu_\\beta(G, E) = \\Pr(Y=1 \\mid G, E) = \\operatorname{expit}(\\eta_\\beta(G,E))$, where $\\operatorname{expit}(x) = (1+e^{-x})^{-1}$. The covariates are distributed as $G \\sim \\operatorname{Bernoulli}(p)$ and $E \\sim \\mathcal{N}(\\mu, \\sigma^2)$, independently.\n\nA misspecified working model is fitted, which omits the $E^2$ term:\n$$\n\\operatorname{logit}\\left(\\Pr(Y=1 \\mid G, E)\\right) = \\eta_\\alpha(G, E) = \\alpha_0 + \\alpha_G G + \\alpha_E E + \\alpha_{GE} G E\n$$\nLet $\\mu_\\alpha(G, E) = \\operatorname{expit}(\\eta_\\alpha(G,E))$.\n\nAccording to the theory of misspecified maximum likelihood models, the estimated parameter vector $\\hat{\\alpha}$ converges in probability to a pseudo-true parameter vector $\\alpha^\\star = (\\alpha_0^\\star, \\alpha_G^\\star, \\alpha_E^\\star, \\alpha_{GE}^\\star)$. This vector $\\alpha^\\star$ is the value of $\\alpha$ that minimizes the Kullback-Leibler divergence between the true model and the working model. Equivalently, $\\alpha^\\star$ is the unique solution to the population score equations being equal to zero:\n$$\n\\mathbb{E}\\left[ X \\left\\{ Y - \\mu_{\\alpha^\\star}(G,E) \\right\\} \\right] = \\mathbf{0}\n$$\nwhere $X = (1, G, E, GE)^\\top$ is the vector of predictors in the working model.\n\nUsing the law of total expectation, $\\mathbb{E}[Y \\mid G, E] = \\mu_\\beta(G, E)$, the system of equations can be rewritten as:\n$$\n\\mathbb{E}_{G,E}\\left[ X \\left\\{ \\mu_\\beta(G,E) - \\mu_{\\alpha^\\star}(G,E) \\right\\} \\right] = \\mathbf{0}\n$$\nThis represents a system of four nonlinear integral equations in the four unknown components of $\\alpha^\\star$.\n\n### **2. Derivation of the System of Equations**\n\nLet $\\phi(e; \\mu, \\sigma^2)$ be the probability density function of the normal distribution $\\mathcal{N}(\\mu, \\sigma^2)$. The expectation $\\mathbb{E}_{G,E}[\\cdot]$ involves summing over the two values of $G \\in \\{0, 1\\}$ and integrating over the distribution of $E$.\n\nLet $\\Delta(g, e; \\alpha) = \\mu_\\beta(g,e) - \\mu_\\alpha(g,e; \\alpha)$. The four equations are:\n\n1.  For $X_1 = 1$:\n    $$\n    \\mathbb{E}[\\Delta(G, E; \\alpha^\\star)] = \\int_{-\\infty}^{\\infty} \\left[ (1-p)\\Delta(0, e; \\alpha^\\star) + p\\Delta(1, e; \\alpha^\\star) \\right] \\phi(e; \\mu, \\sigma^2) de = 0\n    $$\n2.  For $X_2 = G$:\n    $$\n    \\mathbb{E}[G \\cdot \\Delta(G, E; \\alpha^\\star)] = \\int_{-\\infty}^{\\infty} \\left[ p \\cdot 1 \\cdot \\Delta(1, e; \\alpha^\\star) \\right] \\phi(e; \\mu, \\sigma^2) de = 0\n    $$\n3.  For $X_3 = E$:\n    $$\n    \\mathbb{E}[E \\cdot \\Delta(G, E; \\alpha^\\star)] = \\int_{-\\infty}^{\\infty} e \\left[ (1-p)\\Delta(0, e; \\alpha^\\star) + p\\Delta(1, e; \\alpha^\\star) \\right] \\phi(e; \\mu, \\sigma^2) de = 0\n    $$\n4.  For $X_4 = GE$:\n    $$\n    \\mathbb{E}[GE \\cdot \\Delta(G, E; \\alpha^\\star)] = \\int_{-\\infty}^{\\infty} e \\left[ p \\cdot 1 \\cdot \\Delta(1, e; \\alpha^\\star) \\right] \\phi(e; \\mu, \\sigma^2) de = 0\n    $$\n\nThese integrals lack an analytical closed-form solution and must be computed numerically.\n\n### **3. Numerical Solution Strategy**\n\nFor each parameter set $(\\beta_0, \\beta_G, \\beta_{E1}, \\beta_{E2}, \\beta_{GE}, p, \\mu, \\sigma)$, we must solve the system $F(\\alpha) = \\mathbf{0}$, where $F: \\mathbb{R}^4 \\to \\mathbb{R}^4$ is the vector of the four integral expressions above.\n\nThe algorithm is as follows:\n1.  Define a vector function `system_equations(alpha, ...)` that takes a candidate vector $\\alpha$ and the fixed model parameters, and returns the 4-element vector of the numerically evaluated integrals.\n2.  The integrals are computed using numerical quadrature, specifically `scipy.integrate.quad`, over the domain $(-\\infty, \\infty)$.\n3.  A nonlinear root-finding algorithm, `scipy.optimize.root`, is used to find the vector $\\alpha^\\star$ that solves `system_equations(alpha_star, ...) = 0`.\n4.  A suitable initial guess for $\\alpha$ is required for the iterative solver. A logical choice is $\\alpha_{\\text{initial}} = (\\beta_0, \\beta_G, \\beta_{E1}, \\beta_{GE})$, as $\\alpha^\\star$ should be close to the true parameters when the model misspecification effect (controlled by $\\beta_{E2}$) is small.\n5.  Once $\\alpha^\\star = (\\alpha_0^\\star, \\alpha_G^\\star, \\alpha_E^\\star, \\alpha_{GE}^\\star)$ is found, the bias in the gene–environment interaction term is calculated as $\\text{Bias} = \\alpha_{GE}^\\star - \\beta_{GE}$.\n\nThis procedure is implemented for each of the four test cases provided. For Case 2, where $\\beta_{E2}=0$, the working model is correctly specified. In this scenario, the theory predicts that the pseudo-true parameters are the true parameters, i.e., $\\alpha^\\star = (\\beta_0, \\beta_G, \\beta_{E1}, \\beta_{GE})$. Consequently, the bias $\\alpha_{GE}^\\star - \\beta_{GE}$ must be $0$, providing a validation check for the implementation.",
            "answer": "[0.150000,0.000000,0.233333,0.640000]"
        }
    ]
}