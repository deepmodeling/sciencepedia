{
    "hands_on_practices": [
        {
            "introduction": "本练习为评估测序数据质量建立了统计学基础。通过从基本原理推导覆盖深度的分布，你将理解为何泊松模型是众多生物信息学分析的基石，并学会如何量化一个已测序基因组的完整性。",
            "id": "4688546",
            "problem": "一个公共卫生实验室对一种细菌病原体进行全基因组测序（WGS）以进行监测。基因组长度为 $G=5\\times 10^{6}$ 个碱基对。一次Illumina测序运行产生 $N=10^{7}$ 个独立的双末端簇，但为简单起见，你可以将其视为 $N$ 个独立的单末端读段，长度为 $L=150$ 个碱基对。假设读段的起始位置在所有允许的起始位点上均匀分布，且各读段之间相互独立，并且基因组是非重复性的，因此每个读段都能唯一比对。由于 $G \\gg L$，忽略边缘效应，并将允许的起始位点集合近似为 $G$ 个位置。将给定碱基处的覆盖深度定义为其比对跨度包含该碱基的读段数量。\n\n从概率论的核心定义和关于独立抽样的成熟结论出发，在 $N$ 很大、$L/G$ 很小且 $N L / G$ 为有限值的假设下，推导固定碱基处覆盖深度的分布。然后计算一个固定碱基未被覆盖的概率。\n\n以两个闭式解析表达式的形式给出你的最终结果：概率质量函数 $P(K=k)$（作为非负整数 $k$ 的函数）和零覆盖概率 $P(K=0)$，两者都用给定的数值表示。不要近似，也不要四舍五入；最终表达式中不需要单位。",
            "solution": "问题要求在给定全基因组测序实验的一组参数的情况下，求出基因组上固定碱基处覆盖深度的概率分布。我们还必须计算一个碱基具有零覆盖的概率。\n\n**步骤1：问题形式化和单读段概率**\n\n设 $G$ 为基因组长度，$N$ 为独立读段的数量，$L$ 为每个读段的长度。给定值为 $G = 5 \\times 10^6$，$N = 10^7$，$L = 150$。\n\n考虑基因组上任意位置的一个固定碱基。我们需要确定一个随机放置的读段覆盖该碱基的概率。一个读段是从某个位置 $s$ 开始的长度为 $L$ 的序列。该读段的跨度覆盖基因组区间 $[s, s+L-1]$。位于位置 $x$ 的一个固定碱基被该读段覆盖，当且仅当其起始位置 $s$ 满足条件 $s \\leq x \\leq s+L-1$。对 $s$ 重新整理这个不等式，我们得到 $x-L+1 \\leq s \\leq x$。\n\n问题陈述指出，读段起始位置在所有允许的起始位点上均匀分布，这些位点被近似为 $G$ 个可能的位置。区间 $[x-L+1, x]$ 内的整数起始位置 $s$ 的数量为 $x - (x-L+1) + 1 = L$。这对于任何不太靠近基因组末端的碱基位置 $x$ 都成立。问题陈述明确允许我们忽略这些边缘效应，因为 $G \\gg L$。\n\n因此，单个读段覆盖固定碱基的有利起始位置数量为 $L$。可能的起始位置总数为 $G$。单个随机选择的读段覆盖固定碱基的概率 $p$ 为：\n$$p = \\frac{\\text{有利起始位点数}}{\\text{总起始位点数}} = \\frac{L}{G}$$\n\n**步骤2：覆盖深度的精确分布**\n\n设 $K$ 为表示固定碱基处覆盖深度的随机变量，即覆盖该碱基的读段总数。我们有 $N$ 个读段，每个读段的放置是一个独立事件。对于每个读段，我们进行一次伯努利试验：它要么覆盖该碱基（“成功”，概率为 $p$），要么不覆盖（“失败”，概率为 $1-p$）。\n\n在 $N$ 次独立的伯努利试验中，成功的总次数 $K$ 服从二项分布，记为 $K \\sim \\text{Binomial}(N, p)$。二项分布的概率质量函数（PMF）由下式给出：\n$$P(K=k) = \\binom{N}{k} p^k (1-p)^{N-k}$$\n其中 $k$ 是成功次数（覆盖深度），$\\binom{N}{k} = \\frac{N!}{k!(N-k)!}$ 是二项式系数。\n\n**步骤3：泊松近似**\n\n问题明确要求我们在 $N$ 很大，$p = L/G$ 很小，且乘积 $\\lambda = Np = NL/G$ 是一个有限常数的假设下推导分布。这是二项分布可以被泊松分布精确近似的经典条件集。\n\n让我们定义平均覆盖深度 $\\lambda$：\n$$\\lambda = Np = \\frac{NL}{G}$$\n\n让我们使用提供的数值数据计算 $\\lambda$ 的值：\n$$N = 10^7, \\quad L = 150, \\quad G = 5 \\times 10^6$$\n$$\\lambda = \\frac{(10^7) \\times 150}{5 \\times 10^6} = \\frac{1.5 \\times 10^9}{5 \\times 10^6} = 0.3 \\times 10^3 = 300$$\n\n条件成立：\n- $N = 10^7$ 是一个大数。\n- $p = \\frac{L}{G} = \\frac{150}{5 \\times 10^6} = 3 \\times 10^{-5}$ 是一个小概率。\n- $\\lambda = 300$ 是一个有限的、适中的值。\n\n在这些条件下，二项分布的 PMF 收敛于泊松分布的 PMF。因此，覆盖深度 $K$ 的分布是参数为 $\\lambda = 300$ 的泊松分布。\n$$K \\sim \\text{Poisson}(\\lambda)$$\n\n泊松分布的 PMF 为：\n$$P(K=k) = \\frac{\\lambda^k \\exp(-\\lambda)}{k!}$$\n对于非负整数 $k = 0, 1, 2, \\dots$。\n\n代入计算出的 $\\lambda=300$ 值，覆盖深度的 PMF 为：\n$$P(K=k) = \\frac{300^k \\exp(-300)}{k!}$$\n\n此表达式给出了一个固定碱基被恰好 $k$ 个读段覆盖的概率。\n\n**步骤4：零覆盖概率**\n\n任务的第二部分是计算一个固定碱基未被覆盖的概率。这对应于覆盖深度 $k=0$。我们可以通过在泊松 PMF 中设置 $k=0$ 来找到这个概率：\n$$P(K=0) = \\frac{\\lambda^0 \\exp(-\\lambda)}{0!}$$\n根据定义，$\\lambda^0 = 1$ 且 $0! = 1$。因此，零覆盖的概率是：\n$$P(K=0) = \\exp(-\\lambda)$$\n\n代入 $\\lambda=300$ 的值，我们得到：\n$$P(K=0) = \\exp(-300)$$\n\n这是基因组中一个特定的、预先选定的碱基对未被测序的概率。\n\n**最终答案的构建**\n\n问题要求两个闭式解析表达式：PMF $P(K=k)$ 和概率 $P(K=0)$，并代入数值。\n\n1.  概率质量函数 $P(K=k)$:\n    $$P(K=k) = \\frac{300^k \\exp(-300)}{k!}$$\n2.  零覆盖概率 $P(K=0)$:\n    $$P(K=0) = \\exp(-300)$$\n\n这些是需要呈现的最终表达式。",
            "answer": "$$\\boxed{\\frac{300^k \\exp(-300)}{k!}, \\exp(-300)}$$"
        },
        {
            "introduction": "在测序深度的概念之上，本实践将直面一个常见的现实挑战：从混合样本（例如含有宿主DNA的样本）中分析病原体基因组。此问题将指导你计算病原体的*有效*覆盖度，并利用这一关键指标来判断数据是否足以支持基因组组装或变异检测等下游应用。",
            "id": "4688565",
            "problem": "一家公共卫生实验室在一次疫情暴发期间，直接对鼻咽拭子进行全基因组测序（WGS），以监测一种疑似的细菌病原体。测序从一个混合样本中产生了 $R$ 对双末端测序读段（paired-end read pairs），每条读段长度为 $L$ 个核苷酸，其中比例为 $h$ 的读段源自人类。在非人类读段中，比例为 $f$ 的部分在分类学上被归类为目标病原体。病原体的基因组大小为 $G$ 个核苷酸。假设所有被分配到病原体的读段都唯一且均匀地比对到病原体基因组上。\n\n仅使用核心定义和经过充分检验的假设：\n- 平均深度（也称覆盖度）定义为分配给目标基因组的总测序碱基数除以目标基因组大小。\n- 根据 Lander and Waterman 的经典随机覆盖（泊松）模型，任一给定碱基被覆盖的次数服从泊松分布，其均值等于平均深度；因此，预期的覆盖广度（至少被覆盖一次的碱基比例）可以从此模型中推导出来。\n\n给定以下数值：\n- $R = 25,000,000$ 对读段，\n- $L = 150$ 个核苷酸/读段，\n- $h = 0.98$，\n- $f = 0.70$，\n- $G = 4,800,000$ 个核苷酸，\n\n计算在排除人类读段并考虑物种分类比例 $f$ 后的预期病原体剩余平均深度。然后，在泊松覆盖假设下，使用以下标准评估从头组装（de novo assembly）和单核苷酸变异（single-nucleotide variant）检出的可行性：\n- 如果平均深度至少为 $30$ 且预期覆盖广度至少为 $0.95$，则组装是可行的。\n- 如果平均深度至少为 $20$ 且预期覆盖广度至少为 $0.90$，则变异检出是可行的。\n\n最终答案仅报告计算出的病原体剩余平均深度，作为一个纯数字（覆盖倍数，无量纲），并四舍五入到三位有效数字。任何额外的结论仅用于您的解题推理；不要将其包含在最终答案中。",
            "solution": "该问题已经过验证，具有科学依据，问题陈述清晰且客观。它包含足够的信息，可以根据基因组学和生物信息学中的既定原则得出一个唯一的解。\n\n目标是计算来自宏基因组样本中病原体基因组的平均测序深度，并随后根据给定标准评估从头组装和单核苷酸变异（SNV）检出的可行性。\n\n提供了以下参数：\n- 双末端测序读段对总数：$R = 25,000,000 = 2.5 \\times 10^7$\n- 每条读段的长度：$L = 150$ 个核苷酸\n- 人类读段的比例（宿主污染）：$h = 0.98$\n- 非人类读段中病原体读段的比例：$f = 0.70$\n- 病原体基因组大小：$G = 4,800,000 = 4.8 \\times 10^6$ 个核苷酸\n\n首先，我们计算实验中测序的总碱基数。由于有 $R$ 对读段，每条读段长度为 $L$，因此总读段数为 $2R$，总测序碱基数 $B_{total}$ 为：\n$$B_{total} = 2 \\times R \\times L$$\n\n接下来，我们确定属于目标病原体的碱基数。源自人类DNA的读段比例为 $h$。因此，非人类读段的比例是 $(1 - h)$。\n非人类读段的比例 $= 1 - 0.98 = 0.02$。\n\n在这些非人类读段中，比例为 $f$ 的部分归属于病原体。因此，从病原体测序得到的总碱基数 $B_{pathogen}$ 为：\n$$B_{pathogen} = B_{total} \\times (1 - h) \\times f = 2 \\times R \\times L \\times (1 - h) \\times f$$\n\n代入给定值：\n$$B_{pathogen} = 2 \\times (2.5 \\times 10^7) \\times 150 \\times (1 - 0.98) \\times 0.70$$\n$$B_{pathogen} = (5.0 \\times 10^7) \\times 150 \\times 0.02 \\times 0.70$$\n$$B_{pathogen} = (7.5 \\times 10^9) \\times 0.014$$\n$$B_{pathogen} = 1.05 \\times 10^8 \\text{ 个碱基}$$\n\n平均深度，也称为覆盖度（$C$），定义为分配给目标基因组的总碱基数除以目标基因组的大小。\n$$C = \\frac{B_{pathogen}}{G}$$\n\n使用计算出的 $B_{pathogen}$ 值和给定的 $G$ 值：\n$$C = \\frac{1.05 \\times 10^8}{4.8 \\times 10^6}$$\n$$C = \\frac{105}{4.8} = \\frac{1050}{48} = \\frac{525}{24} = \\frac{175}{8}$$\n$$C = 21.875$$\n病原体基因组的平均覆盖深度为 $21.875\\text{x}$。题目要求将此值四舍五入到三位有效数字，即 $21.9$。\n\n现在，我们必须评估从头组装和变异检出的可行性。这需要计算预期的覆盖广度。根据 Lander-Waterman 模型，任一给定碱基未被覆盖（即被覆盖0次）的概率服从均值为 $\\lambda = C$ 的泊松分布。覆盖次数为零的概率 $P(k=0)$ 为：\n$$P(k=0) = \\frac{e^{-C} C^0}{0!} = e^{-C}$$\n预期的覆盖广度 $B$ 是基因组中至少被覆盖一次的碱基比例，即 $1 - P(k=0)$。\n$$B = 1 - e^{-C}$$\n对于我们计算出的平均深度 $C = 21.875$：\n$$B = 1 - e^{-21.875}$$\n$e^{-21.875}$ 的值非常小，约为 $3.16 \\times 10^{-10}$。因此，覆盖广度在非常高的精度上实际上是 $1.0$。\n$$B \\approx 1.0$$\n\n我们现在可以根据提供的标准评估可行性：\n\n1.  **从头组装可行性：**\n    - 标准1：平均深度 $\\ge 30$。我们计算出的深度是 $C = 21.875$。由于 $21.875  30$，此标准**未满足**。\n    - 标准2：预期覆盖广度 $\\ge 0.95$。我们计算出的覆盖广度是 $B \\approx 1.0$。由于 $1.0 \\ge 0.95$，此标准得到满足。\n    - 由于平均深度标准未满足，从头组装被认为是**不可行的**。\n\n2.  **SNV检出可行性：**\n    - 标准1：平均深度 $\\ge 20$。我们计算出的深度是 $C = 21.875$。由于 $21.875 \\ge 20$，此标准**得到满足**。\n    - 标准2：预期覆盖广度 $\\ge 0.90$。我们计算出的覆盖广度是 $B \\approx 1.0$。由于 $1.0 \\ge 0.90$，此标准**得到满足**。\n    - 由于两个标准都得到满足，SNV检出被认为是**可行的**。\n\n题目要求计算出的病原体剩余平均深度，并四舍五入到三位有效数字。\n\n平均深度 $C = 21.875$。\n四舍五入到三位有效数字得到 $21.9$。",
            "answer": "$$\\boxed{21.9}$$"
        },
        {
            "introduction": "最后的这项实践将从数据质量评估转向流行病学应用，这也是病原体监测的核心目的。你将通过编程实现一个算法，根据遗传关联性来定义和追踪传播集群的动态变化，从而模拟公共卫生领域计算流行病学家的实际工作。",
            "id": "4688569",
            "problem": "一组病原体分离株已通过全基因组测序（WGS）进行测序，生成了一个成对单核苷酸多态性（SNP）距离矩阵。在固定的传播可能性阈值下，成对SNP距离小于或等于该阈值的分离株被认为有关联。这会产生一个无向图，其连通分量在操作上定义了监测集群。随着时间的推移，新采样的分离株会扩展该图，可能会改变集群成员关系。任务是计算在指定累积时间快照下的集群大小，以及一个有原则的稳定性分数，用于衡量已观察到的分离株在连续快照之间的集群成员关系如何变化。\n\n给定以下基于医学微生物学和图论的定义：\n- 单核苷酸多态性（SNP）计数近似于遗传散度，这与分子生物学中心法则一致，即核苷酸水平的差异在复制过程中累积。分离株 $i$ 和 $j$ 之间的成对 SNP 距离表示为 $D_{ij}$，其中 $D_{ij} \\in \\mathbb{N}_0$ 且 $D_{ij} = D_{ji}$，并有 $D_{ii} = 0$。\n- 对于选定的阈值 $\\tau \\in \\mathbb{N}_0$，构建一个无向简单图 $G = (V,E)$，其顶点集为 $V = \\{0,1,\\dots,n-1\\}$，边集为 $E = \\{ \\{i,j\\} : D_{ij} \\le \\tau, i \\neq j \\}$。连通分量是 $V$ 的一个最大子集，其中任意两个顶点都通过一条路径相连。\n- 分离株在整数时间点 $t_i \\in \\mathbb{Z}$（例如，天）被采样。对于一个非递减的快照时间列表 $T_1, T_2, \\dots, T_K$，其中 $T_k \\in \\mathbb{Z}$，定义快照 $k$ 的累积活动集为 $S_k = \\{ i \\in V : t_i \\le T_k \\}$。\n- 对于每个快照 $k$，计算由 $S_k$ 诱导的图的连通分量，并将分量大小的多重集记录为一个按非递增顺序排序的整数列表。\n- 定义连续快照 $k$ 和 $k+1$ 之间的稳定性分数，该分数量化了已观察到的分离株的集群成员关系如何变化。令 $\\mathcal{P}_k$ 为在快照 $k$ 时将 $S_k$ 划分为连通分量的划分，令 $\\mathcal{P}_{k+1}$ 为 $S_{k+1}$ 的划分。考虑来自较早快照的无序分离株对：$U_k = \\{ \\{i,j\\} : i,j \\in S_k, i  j \\}$。定义指示函数 $I_k(i,j) = 1$ 如果 $i$ 和 $j$ 在 $\\mathcal{P}_k$ 的同一区块中，而 $I_{k+1}(i,j) = 1$ 如果 $i$ 和 $j$ 在 $\\mathcal{P}_{k+1}$ 的同一区块中（限制于 $S_k \\subseteq S_{k+1}$）。稳定性分数为\n$$\ns_k = \\frac{1}{|U_k|} \\sum_{\\{i,j\\} \\in U_k} \\mathbf{1}\\big( I_k(i,j) = I_{k+1}(i,j) \\big),\n$$\n这是一个在 $[0,1]$ 范围内的十进制数。\n\n实现一个程序，对于每个测试用例，计算：\n- 对于每个快照 $k \\in \\{1,\\dots,K\\}$，计算 $S_k$ 上诱导图的连通分量大小的排序列表。\n- 对于每对连续的快照 $(k,k+1)$，计算保留三位小数的稳定性分数 $s_k$。\n\n所有时间都是整数天；不需要物理单位转换。不涉及角度。所有稳定性分数表示为保留三位小数的十进制数。\n\n使用以下测试套件，其中每个测试用例指定了 $n$、矩阵 $D$、时间戳列表 $t$、快照列表 $T$ 以及阈值 $\\tau$：\n\n- 测试用例 1（随时间由桥接驱动的合并）：\n    - $n = 6$,\n    $$\n    D^{(1)} = \\begin{pmatrix}\n    0   1   4   2   6   6 \\\\\n    1   0   4   2   6   6 \\\\\n    4   4   0   1   6   6 \\\\\n    2   2   1   0   6   6 \\\\\n    6   6   6   6   0   1 \\\\\n    6   6   6   6   1   0\n    \\end{pmatrix},\n    $$\n    $t^{(1)} = [1,2,3,4,5,6]$, $T^{(1)} = [3,5,6]$, $\\tau^{(1)} = 2$.\n- 测试用例 2（零阈值边界，所有分离株各不相同）：\n    - $n = 5$,\n    $$\n    D^{(2)} = \\begin{pmatrix}\n    0   3   3   3   3 \\\\\n    3   0   3   3   3 \\\\\n    3   3   0   3   3 \\\\\n    3   3   3   0   3 \\\\\n    3   3   3   3   0\n    \\end{pmatrix},\n    $$\n    $t^{(2)} = [1,2,3,4,5]$, $T^{(2)} = [2,4,5]$, $\\tau^{(2)} = 0$.\n- 测试用例 3（高阈值全连接增长）：\n    - $n = 4$,\n    $$\n    D^{(3)} = \\begin{pmatrix}\n    0   2   1   2 \\\\\n    2   0   2   1 \\\\\n    1   2   0   2 \\\\\n    2   1   2   0\n    \\end{pmatrix},\n    $$\n    $t^{(3)} = [1,2,3,4]$, $T^{(3)} = [2,3,4]$, $\\tau^{(3)} = 3$.\n\n您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表。此顶层列表的每个元素对应一个测试用例，并且必须是一个包含两项的列表：\n- 第一项是一个整数列表的列表，其中第 $k$ 个内部列表包含快照 $k$ 处已排序的连通分量大小。\n- 第二项是一个浮点数列表（四舍五入到三位小数），包含每个连续快照对的稳定性分数 $s_k$。\n\n例如，输出格式为 $[ \\text{result}_1, \\text{result}_2, \\text{result}_3 ]$，其中每个 $\\text{result}_m$ 的结构为 $[ \\text{SIZES}_m, \\text{STABILITIES}_m ]$。",
            "solution": "### 算法解决方案\n\n该问题要求在离散的时间快照下分析病原体集群的结构，并量化这些集群在快照之间的稳定性。解决方案自然地分为两个主要部分：首先，确定每个快照下的集群结构；其次，计算连续快照之间的稳定性分数。\n\n**1. 建模与集群识别**\n\n问题的核心在于将生物学场景转化为正式的数学模型。这是通过图论实现的：\n- 每个病原体分离株表示为图中的一个顶点，$V = \\{0, 1, \\dots, n-1\\}$。\n- 如果两个分离株 $i$ 和 $j$ 的 SNP 距离 $D_{ij}$ 不超过指定的阈值 $\\tau$，则它们之间建立了一条遗传联系。这定义了一条边 $\\{i,j\\}$。\n- 最终得到的无向图 $G = (V, E)$，其中 $E = \\{ \\{i,j\\} : D_{ij} \\le \\tau, i \\neq j \\}$，包含了所有潜在的传播联系。\n- 在任何给定时间，只有一部分分离株被采样。时间 $T_k$ 的快照考虑了累积的分离株集合 $S_k = \\{ i \\in V : t_i \\le T_k \\}$。\n- 快照 $k$ 处的监测集群被定义为由顶点集 $S_k$ 诱导的 $G$ 的子图的连通分量。\n\n为了为每个快照计算这些连通分量，不相交集联合（DSU）或并查集数据结构是一个高效的选择。针对单个快照 $k$ 的算法如下：\n1. 确定活动分离株的集合 $S_k$。如果 $S_k$ 为空，则没有分量。\n2. 初始化一个包含 $|S_k|$ 个元素的 DSU 结构，每个元素对应 $S_k$ 中的一个分离株。每个分离株最初都在自己的集合中。\n3. 遍历 $S_k$ 中所有唯一的分离株对 $\\{i, j\\}$。\n4. 如果 SNP 距离 $D_{ij} \\le \\tau$，则使用 DSU 的 `union` 操作合并包含 $i$ 和 $j$ 的集合。\n5. 在检查完所有对之后，DSU 结构中的最终集合代表了连通分量（集群）。\n6. 每个分量的大小是它包含的分离株数量。收集这些大小并按非递增顺序排序。\n7. 为了计算稳定性，存储 $S_k$ 的划分 $\\mathcal{P}_k$。一个实用的表示方法是使用一个字典，将每个分离株的 ID 映射到其分量的代表（根）。\n\n**2. 稳定性分数计算**\n\n稳定性分数 $s_k$ 衡量了在前一个快照中已存在的那些分离株的集群分配的一致性。它是为每对连续的快照 $(k, k+1)$ 计算的。\n- 令 $\\mathcal{P}_k$ 和 $\\mathcal{P}_{k+1}$ 分别为 $S_k$ 和 $S_{k+1}$ 到集群的划分。\n- 关注的集合是 $S_k$，即在较早快照中存在的分离株。要评估的对集合是 $U_k = \\{ \\{i,j\\} : i,j \\in S_k, i  j \\}$。\n- 对于每个对 $\\{i,j\\} \\in U_k$，我们比较它们在两个快照中的共同聚类状态。\n  - 如果 $i$ 和 $j$ 在 $\\mathcal{P}_k$ 的同一个集群中，则 $I_k(i,j)=1$；否则为 $0$。\n  - 如果 $i$ 和 $j$ 在 $\\mathcal{P}_{k+1}$ 的同一个集群中，则 $I_{k+1}(i,j)=1$；否则为 $0$。请注意，由于 $S_k \\subseteq S_{k+1}$，分离株 $i,j$ 在快照 $k+1$ 的图中是存在的。\n- 分数是状态未改变的对所占的比例：\n  $$s_k = \\frac{1}{|U_k|} \\sum_{\\{i,j\\} \\in U_k} \\mathbf{1}\\big( I_k(i,j) = I_{k+1}(i,j) \\big)$$\n- 求和项计算了在两个快照中要么都聚在一起，要么都分开的对 $\\{i,j\\}$ 的数量。\n- 当 $|S_k|  2$ 时会出现特殊情况。此时，对的集合 $U_k$ 为空，分母 $|U_k|$ 为零。按照惯例，在这种空洞真理（不存在可以不同意的对）的情况下，稳定性是最大的，即 $s_k = 1.0$。\n\n整体实现将通过首先计算其所有快照的集群划分，然后计算连续划分之间的稳定性分数来处理每个测试用例。最终结果将按规定格式进行汇总和格式化。",
            "answer": "```python\nimport numpy as np\n\nclass UnionFind:\n    \"\"\"\n    A class for the Disjoint Set Union (DSU) or Union-Find data structure.\n    Implements union by size and path compression for efficiency.\n    \"\"\"\n    def __init__(self, size):\n        self.parent = list(range(size))\n        self.set_size = [1] * size\n\n    def find(self, i):\n        \"\"\"Finds the representative of the set containing element i with path compression.\"\"\"\n        if self.parent[i] == i:\n            return i\n        self.parent[i] = self.find(self.parent[i])\n        return self.parent[i]\n\n    def union(self, i, j):\n        \"\"\"Merges the sets containing elements i and j using union by size.\"\"\"\n        root_i = self.find(i)\n        root_j = self.find(j)\n        if root_i != root_j:\n            # Union by size: attach smaller tree under root of larger tree\n            if self.set_size[root_i]  self.set_size[root_j]:\n                root_i, root_j = root_j, root_i\n            self.parent[root_j] = root_i\n            self.set_size[root_i] += self.set_size[root_j]\n            return True\n        return False\n\ndef process_case(n, D, t, T, tau):\n    \"\"\"\n    Processes a single test case to compute cluster sizes and stability scores.\n    \"\"\"\n    snapshot_partitions = {}\n    snapshot_sizes = []\n\n    for k, T_k in enumerate(T):\n        snapshot_idx = k + 1\n        \n        active_isolates = sorted([i for i, time in enumerate(t) if time = T_k])\n        \n        if not active_isolates:\n            snapshot_sizes.append([])\n            snapshot_partitions[snapshot_idx] = {}\n            continue\n\n        num_active = len(active_isolates)\n        isolate_to_uf_idx = {iso: i for i, iso in enumerate(active_isolates)}\n        \n        uf = UnionFind(num_active)\n        \n        for i in range(num_active):\n            for j in range(i + 1, num_active):\n                iso1 = active_isolates[i]\n                iso2 = active_isolates[j]\n                if D[iso1, iso2] = tau:\n                    uf.union(isolate_to_uf_idx[iso1], isolate_to_uf_idx[iso2])\n\n        # Store partition for stability calculation\n        partition = {iso: uf.find(isolate_to_uf_idx[iso]) for iso in active_isolates}\n        snapshot_partitions[snapshot_idx] = partition\n\n        # Calculate component sizes\n        component_members = {}\n        for iso in active_isolates:\n            root = partition[iso]\n            component_members.setdefault(root, []).append(iso)\n        \n        sizes = sorted([len(v) for v in component_members.values()], reverse=True)\n        snapshot_sizes.append(sizes)\n\n    stability_scores = []\n    for k in range(len(T) - 1):\n        snapshot_idx_k = k + 1\n        snapshot_idx_k1 = k + 2\n        \n        partition_k = snapshot_partitions[snapshot_idx_k]\n        partition_k1 = snapshot_partitions[snapshot_idx_k1]\n        \n        isolates_k = sorted(list(partition_k.keys()))\n        num_isolates_k = len(isolates_k)\n\n        if num_isolates_k  2:\n            score = 1.0\n        else:\n            num_pairs = num_isolates_k * (num_isolates_k - 1) // 2\n            agreement_count = 0\n            for i in range(num_isolates_k):\n                for j in range(i + 1, num_isolates_k):\n                    iso1 = isolates_k[i]\n                    iso2 = isolates_k[j]\n                    \n                    same_k = (partition_k[iso1] == partition_k[iso2])\n                    same_k1 = (partition_k1[iso1] == partition_k1[iso2])\n                    \n                    if same_k == same_k1:\n                        agreement_count += 1\n            \n            score = agreement_count / num_pairs\n\n        stability_scores.append(round(score, 3))\n        \n    return [snapshot_sizes, stability_scores]\n\n\ndef solve():\n    \"\"\"\n    Main function to define test cases, run the analysis, and print results.\n    \"\"\"\n    test_cases = [\n        (\n            6,\n            np.array([\n                [0, 1, 4, 2, 6, 6], [1, 0, 4, 2, 6, 6], [4, 4, 0, 1, 6, 6],\n                [2, 2, 1, 0, 6, 6], [6, 6, 6, 6, 0, 1], [6, 6, 6, 6, 1, 0]\n            ]),\n            [1, 2, 3, 4, 5, 6],\n            [3, 5, 6],\n            2\n        ),\n        (\n            5,\n            np.array([\n                [0, 3, 3, 3, 3], [3, 0, 3, 3, 3], [3, 3, 0, 3, 3],\n                [3, 3, 3, 0, 3], [3, 3, 3, 3, 0]\n            ]),\n            [1, 2, 3, 4, 5],\n            [2, 4, 5],\n            0\n        ),\n        (\n            4,\n            np.array([\n                [0, 2, 1, 2], [2, 0, 2, 1], [1, 2, 0, 2], [2, 1, 2, 0]\n            ]),\n            [1, 2, 3, 4],\n            [2, 3, 4],\n            3\n        )\n    ]\n\n    results = []\n    for case in test_cases:\n        n, D, t, T, tau = case\n        result = process_case(n, D, t, T, tau)\n        results.append(result)\n\n    # Format the final output string according to the problem specification.\n    # The default str() representation for lists includes spaces, which needs to be removed.\n    final_output_str = str(results).replace(\" \", \"\")\n    print(final_output_str)\n\nsolve()\n```"
        }
    ]
}