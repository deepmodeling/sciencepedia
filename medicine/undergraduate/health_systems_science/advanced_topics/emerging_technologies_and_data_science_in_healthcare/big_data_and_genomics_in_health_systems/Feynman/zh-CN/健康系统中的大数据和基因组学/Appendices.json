{
    "hands_on_practices": [
        {
            "introduction": "在我们进入复杂的基因组分析之前，必须首先掌握如何评估我们数据的基本质量。下一代测序（NGS）技术并非完美，它生成的每个碱基都附有一个质量评分，即Phred质量分。这个练习将带你动手计算，将抽象的质量评分与实际测序错误联系起来，让你能够估算在一个全基因组 sequencing 项目中预期会遇到多少错误碱基 。这不仅是一项基础的生物信息学技能，更是规划后续数据清理和验证流程的关键一步。",
            "id": "4361966",
            "problem": "一项国家级精准健康计划正在使用新一代测序（NGS）技术，为一个群体队列生成全基因组数据，以用于临床决策支持。每个个体被分析的基因组大小为 $3 \\times 10^{9}$ 个碱基。卫生系统分析师需要估计错误碱基检出的预期负担，以规划下游的验证和质量控制工作流程。Phred质量分的定义为 $Q = -10 \\log_{10}(p_{\\text{err}})$，其中 $p_{\\text{err}}$ 是一个碱基检出为错误的概率。在一次典型的测序运行中，$0.85$ 的碱基检出质量为 $Q=30$，其余 $0.15$ 的质量为 $Q=20$。从伯努利试验的期望核心定义和上述Phred分数定义出发，推导一个公式，将Phred分数的分布与 $3 \\times 10^{9}$ 个碱基中预期的错误数联系起来，并计算此次运行中预期错误的碱基检出数。将你的最终答案以科学记数法表示，并四舍五入到三位有效数字。",
            "solution": "该问题经验证是自洽的、有科学依据且表述清晰的。解决问题所需的所有数据均已提供，相关定义（例如Phred分数）在基因组学领域是标准的，并且其前提是一致且符合物理现实的。该问题要求进行推导和计算，这是定量科学问题的标准格式。因此，我将提供完整的解题过程。\n\n主要目标是找到在总大小为 $N$ 的基因组序列中错误碱基检出的预期数量，记为 $E[X]$。让我们将每个碱基检出的正确性建模为一次独立的伯努利试验。对于从 $1$ 到 $N$ 的每个碱基 $i$，我们可以定义一个随机变量 $X_i$，使得：\n如果碱基检出是错误的，$X_i = 1$（概率为 $p_{\\text{err},i}$）。\n如果碱基检出是正确的，$X_i = 0$（概率为 $1 - p_{\\text{err},i}$）。\n\n这个随机变量的期望值为 $E[X_i] = 1 \\cdot p_{\\text{err},i} + 0 \\cdot (1 - p_{\\text{err},i}) = p_{\\text{err},i}$。\n\n在整个长度为 $N$ 的序列中，总错误数 $X$ 是这些单个随机变量的总和：\n$$X = \\sum_{i=1}^{N} X_i$$\n\n根据期望的线性性质，预期的总错误数是各个期望值的总和：\n$$E[X] = E\\left[\\sum_{i=1}^{N} X_i\\right] = \\sum_{i=1}^{N} E[X_i] = \\sum_{i=1}^{N} p_{\\text{err},i}$$\n\n问题陈述，碱基检出根据其Phred质量分 $Q$ 被分成几组。假设有 $k$ 个这样的组，每个组 $k$ 的特征是其质量分 $Q_k$，并包含总碱基的一部分，比例为 $f_k$。在每个组内，所有碱基具有相同的错误概率 $p_{\\text{err},k}$。第 $k$ 组中的总碱基数为 $N_k = f_k N$。\n\n错误概率的总和可以重构为对这些组的求和：\n$$E[X] = \\sum_{k} \\sum_{i \\in \\text{group } k} p_{\\text{err},i} = \\sum_{k} (N_k \\cdot p_{\\text{err},k})$$\n代入 $N_k = f_k N$：\n$$E[X] = \\sum_{k} (f_k N \\cdot p_{\\text{err},k}) = N \\sum_{k} (f_k \\cdot p_{\\text{err},k})$$\n\nPhred分数 $Q_k$ 和错误概率 $p_{\\text{err},k}$ 之间的关系由定义给出：\n$$Q_k = -10 \\log_{10}(p_{\\text{err},k})$$\n为了求出作为 $Q_k$ 函数的 $p_{\\text{err},k}$，我们重排这个方程：\n$$-\\frac{Q_k}{10} = \\log_{10}(p_{\\text{err},k})$$\n$$p_{\\text{err},k} = 10^{-Q_k/10}$$\n\n将这个 $p_{\\text{err},k}$ 的表达式代入我们关于 $E[X]$ 的方程，得到连接Phred分数分布与预期错误数的一般公式：\n$$E[X] = N \\sum_{k} f_k 10^{-Q_k/10}$$\n\n现在，我们将这个推导出的公式应用于问题中提供的具体数据。总碱基数为 $N = 3 \\times 10^9$。碱基被分为两组：\n第1组：比例 $f_1 = 0.85$，质量分 $Q_1 = 30$。\n第2组：比例 $f_2 = 0.15$，质量分 $Q_2 = 20$。\n\n首先，我们计算每组的错误概率：\n对于第1组：\n$$p_{\\text{err},1} = 10^{-Q_1/10} = 10^{-30/10} = 10^{-3} = 0.001$$\n对于第2组：\n$$p_{\\text{err},2} = 10^{-Q_2/10} = 10^{-20/10} = 10^{-2} = 0.01$$\n\n现在我们使用 $k=2$ 时预期错误数的公式：\n$$E[X] = N (f_1 p_{\\text{err},1} + f_2 p_{\\text{err},2})$$\n代入数值：\n$$E[X] = (3 \\times 10^9) \\left( (0.85)(10^{-3}) + (0.15)(10^{-2}) \\right)$$\n$$E[X] = (3 \\times 10^9) \\left( 0.00085 + 0.0015 \\right)$$\n$$E[X] = (3 \\times 10^9) \\left( 0.00235 \\right)$$\n为了进行最后的乘法，我们将 $0.00235$ 表示为科学记数法 $2.35 \\times 10^{-3}$：\n$$E[X] = (3 \\times 10^9) \\times (2.35 \\times 10^{-3})$$\n$$E[X] = (3 \\times 2.35) \\times 10^{(9-3)}$$\n$$E[X] = 7.05 \\times 10^6$$\n\n此次运行中预期错误的碱基检出数为 $7.05 \\times 10^6$。结果已按要求以三位有效数字的科学记数法表示。",
            "answer": "$$\\boxed{7.05 \\times 10^6}$$"
        },
        {
            "introduction": "在确保了单个碱基的质量后，我们需要将视野扩大到整个样本群体，检测可能影响分析结果的系统性偏差，即所谓的“批次效应”。当样本在不同时间、由不同仪器或使用不同批次的试剂处理时，就可能产生这种效应。本练习  介绍了一种强大的统计方法——主成分分析（PCA），用于从多个质量控制指标中诊断并量化这些隐藏的批次效应。通过这个实践，你将学会如何利用降维技术来识别数据中的非生物学变异，这是确保基因组研究结论可靠性的核心步骤。",
            "id": "4361937",
            "problem": "一个卫生系统测序实验室对患者样本进行全基因组测序（WGS），希望使用质量控制特征来诊断和量化由仪器和试剂批次引起的批次效应。对于 $n=120$ 个样本中的每一个，实验室记录了四个样本级别的质量指标：平均覆盖深度 $x_{1}$，插入片段大小中位数 $x_{2}$，一个GC含量偏倚指标 $x_{3}$，以及一个估计的污染比例 $x_{4}$。设 $X \\in \\mathbb{R}^{n \\times 4}$ 是数据矩阵，其列是这四个指标；每列都经过标准化，使得样本间的均值为零，方差为单位1（z-score化）。该实验室将使用主成分分析（PCA）来检测仪器或试剂特异性的聚类，并量化这四个指标的总方差中有多少可由批次解释。假设有两台仪器（仪器A和仪器B），每台仪器处理 $60$ 个样本，并且有三个试剂批次在这些仪器间均匀使用。\n\n对标准化数据（等效于样本相关性矩阵 $R = \\frac{1}{n-1} X^\\top X$）进行PCA后，观察到的特征值为 $\\lambda_{1} = 1.80$，$\\lambda_{2} = 1.20$，$\\lambda_{3} = 0.70$ 和 $\\lambda_{4} = 0.30$。因为各列是标准化的，所以总方差等于 $\\sum_{k=1}^{4} \\lambda_k = 4$。\n\n当PC1得分（样本在第一主成分上的投影）按仪器分组时，它们的组均值对于仪器A为 $\\bar{y}_{\\text{A}} = 0.6$，对于仪器B为 $\\bar{y}_{\\text{B}} = -0.6$；根据构造，PC1得分的总均值为 $\\bar{y} = 0$。假设在此数据中，试剂批次与PC1和PC2的关联可忽略不计。\n\n哪个选项最正确地指定了一个科学上合理的批次效应诊断计划，该计划使用这四个指标的PCA来检测仪器特异性聚类，并根据给定数据量化由仪器批次解释的四个指标的总方差比例？\n\nA. 标准化每个指标（$X$的列），对样本相关性矩阵进行PCA，将按仪器和试剂批次着色的PC得分可视化，然后使用单因素方差分析（ANOVA）正式检验PC得分与仪器的关联。将由仪器解释的四个指标的总方差比例量化为由仪器解释的PC方差部分，并按每个PC占总方差的份额加权；由于只有PC1显示出关联，这等于 $\\left(\\frac{\\lambda_{1}}{\\sum_{k} \\lambda_{k}}\\right) \\cdot \\frac{\\text{SSR}_{\\text{PC1}}}{\\text{SST}_{\\text{PC1}}}$，得出结果约 $0.091$ 或 $9.1\\%$。\n\nB. 对原始（未标准化）指标的协方差进行PCA以保留自然尺度，使用t检验测试PC载荷与仪器的关联，并将由仪器解释的方差比例报告为仅来自PC1的 $R^{2}$，约 $0.202$ 或 $20.2\\%$。\n\nC. 将每个样本（$X$的行）归一化为单位范数，对得到的协方差矩阵进行PCA，使用PC载荷与仪器的相关性来评估批次关联，并将由仪器解释的方差量化为PC1捕获的方差比例，即 $\\lambda_{1}/\\sum_{k} \\lambda_{k} = 0.45$ 或 $45\\%$。\n\nD. 标准化指标，对相关性矩阵进行PCA，使用k-均值（$k=2$）在PC空间中对样本进行聚类以恢复仪器分组，然后将由仪器解释的方差量化为PC1组均值的平方差除以指标总数，即 $\\left(\\bar{y}_{\\text{A}} - \\bar{y}_{\\text{B}}\\right)^{2}/4 = 0.36$ 或 $36\\%$。",
            "solution": "### 第1步：提取已知条件\n题目为全基因组测序（WGS）质量控制分析提供了以下信息：\n- 样本数量，$n = 120$。\n- 质量指标（特征）数量，$p = 4$。这些指标是平均覆盖深度（$x_1$）、插入片段大小中位数（$x_2$）、一个GC含量偏倚指标（$x_3$）和一个估计的污染比例（$x_4$）。\n- 数据矩阵为 $X \\in \\mathbb{R}^{n \\times 4}$，其中 $n=120$。\n- $X$ 的4个列都经过标准化，均值为零，方差为单位1（z-score化）。\n- 分析方法是主成分分析（PCA）。\n- 有两个仪器批次组：仪器A（$n_{\\text{A}} = 60$ 个样本）和仪器B（$n_{\\text{B}} = 60$ 个样本）。\n- PCA在标准化数据上进行，这等同于在样本相关性矩阵 $R = \\frac{1}{n-1} X^\\top X$ 上进行PCA。\n- 相关性矩阵的特征值给出为 $\\lambda_{1} = 1.80$，$\\lambda_{2} = 1.20$，$\\lambda_{3} = 0.70$ 和 $\\lambda_{4} = 0.30$。\n- 总方差是相关性矩阵的迹，$\\sum_{k=1}^{4} \\lambda_k = 1.80 + 1.20 + 0.70 + 0.30 = 4$，这等于变量的数量，符合标准化数据的预期。\n- 第一主成分（PC1）的得分，其组均值对于仪器A为 $\\bar{y}_{\\text{A}} = 0.6$，对于仪器B为 $\\bar{y}_{\\text{B}} = -0.6$。\n- PC1得分的总均值为 $\\bar{y} = 0$。\n- 假设试剂批次与PC1和PC2的关联可忽略不计。\n- 问题是找出最科学合理的计划，以诊断仪器特异性批次效应，并量化其解释的四个指标总方差的比例。\n\n### 第2步：使用提取的已知条件进行验证\n问题陈述在科学上是合理的，且提法恰当。\n- **科学依据充分**：在质量控制指标上使用PCA来识别批次效应是生物信息学和基因组学中一个标准且被广泛接受的做法。所列出的指标是测序数据中常见的。统计方法基于线性代数和方差分析的既定原则。\n- **提法恰当且完整**：问题提供了执行所需计算和评估所提方法论所需的所有数据和定义。数值是一致的（例如，$\\sum \\lambda_k = p$，以及PC1的对称组均值与相等的组大小一致）。\n- **客观性**：问题使用精确、客观和技术性的语言陈述。没有歧义或主观性陈述。\n- **真实性**：场景和数据对于一个基因组学核心设施来说是真实的。\n\n### 第3步：结论与行动\n问题有效。我将继续对选项进行全面推导和评估。\n\n### 基于原理的推导\n\n目标是量化原始四个指标中可归因于仪器批次效应的*总方差*的比例。标准化数据中的总方差是四个z-score化指标的方差之和，即 $1+1+1+1=4$。在PCA中，这个总方差等于相关性矩阵的特征值之和，$\\sum_{k=1}^{4} \\lambda_k = 4$。\n\nPCA将总方差分解为正交的主成分（PC）。第 $k$ 个主成分PC$k$捕获的方差由其特征值 $\\lambda_k$ 给出。PC$k$捕获的总方差比例为 $\\frac{\\lambda_k}{\\sum_{j=1}^{4} \\lambda_j}$。\n\n问题指出，仪器批次效应在PC得分中是可观察的，尤其是在PC1中。要量化PC1*内部*由仪器解释的方差量，我们可以使用方差分析（ANOVA）框架。由仪器因子解释的PC1得分（$y_1$）的方差比例由决定系数 $R^2_{\\text{PC1}}$ 给出，该系数是组间平方和（$\\text{SSR}_{\\text{PC1}}$）与总平方和（$\\text{SST}_{\\text{PC1}}$）的比率。\n\n1.  **计算PC1的总平方和（$\\text{SST}_{\\text{PC1}}$）**：\n    根据定义，第一主成分得分的方差是第一个特征值 $\\lambda_1$。\n    $$ \\text{Var}(y_1) = \\lambda_1 = 1.80 $$\n    总平方和与样本方差的关系为 $\\text{SST}_{\\text{PC1}} = (n-1)\\text{Var}(y_1)$。\n    $$ \\text{SST}_{\\text{PC1}} = (120-1) \\times 1.80 = 119 \\times 1.80 = 214.2 $$\n\n2.  **计算PC1的组间平方和（$\\text{SSR}_{\\text{PC1}}$）**：\n    这衡量了组均值之间的方差。\n    $$ \\text{SSR}_{\\text{PC1}} = n_{\\text{A}}(\\bar{y}_{\\text{A}} - \\bar{y})^2 + n_{\\text{B}}(\\bar{y}_{\\text{B}} - \\bar{y})^2 $$\n    使用给定的值 $n_{\\text{A}}=60$, $n_{\\text{B}}=60$, $\\bar{y}_{\\text{A}}=0.6$, $\\bar{y}_{\\text{B}}=-0.6$ 和 $\\bar{y}=0$:\n    $$ \\text{SSR}_{\\text{PC1}} = 60(0.6 - 0)^2 + 60(-0.6 - 0)^2 = 60(0.36) + 60(0.36) = 2 \\times 21.6 = 43.2 $$\n\n3.  **计算由仪器解释的PC1方差的比例**：\n    $$ R^2_{\\text{PC1}} = \\frac{\\text{SSR}_{\\text{PC1}}}{\\text{SST}_{\\text{PC1}}} = \\frac{43.2}{214.2} \\approx 0.20168 $$\n\n4.  **计算由仪器解释的总方差的比例**：\n    这是最终的目标量。它是PC1中由仪器解释的方差比例，按PC1本身所代表的总方差比例进行加权。问题暗示我们只应考虑PC1，因为它是被给定与仪器相关联的成分。\n    $$ \\text{比例} = \\left( \\frac{\\text{PC1的方差}}{\\text{总方差}} \\right) \\times \\left( \\frac{\\text{PC1中由仪器引起的方差}}{\\text{PC1的方差}} \\right) $$\n    $$ \\text{比例} = \\left( \\frac{\\lambda_1}{\\sum_{k=1}^{4} \\lambda_k} \\right) \\times R^2_{\\text{PC1}} = \\left( \\frac{1.80}{4.00} \\right) \\times \\frac{\\text{SSR}_{\\text{PC1}}}{\\text{SST}_{\\text{PC1}}} $$\n    $$ \\text{比例} = 0.45 \\times \\frac{43.2}{214.2} \\approx 0.45 \\times 0.20168 \\approx 0.090756 $$\n    这个值约等于 $0.091$，即 $9.1\\%$。\n\n### 逐项分析选项\n\n**A. 标准化每个指标（$X$的列），对样本相关性矩阵进行PCA，将按仪器和试剂批次着色的PC得分可视化，然后使用单因素方差分析（ANOVA）正式检验PC得分与仪器的关联。将由仪器解释的四个指标的总方差比例量化为由仪器解释的PC方差部分，并按每个PC占总方差的份额加权；由于只有PC1显示出关联，这等于 $\\left(\\frac{\\lambda_{1}}{\\sum_{k} \\lambda_{k}}\\right) \\cdot \\frac{\\text{SSR}_{\\text{PC1}}}{\\text{SST}_{\\text{PC1}}}$，得出结果约 $0.091$ 或 $9.1\\%$。**\n\n- **方法论**：此选项概述了标准、正确的流程。当指标具有不同尺度时，标准化变量（或使用相关性矩阵）至关重要。将PC得分可视化是正确的探索性步骤。在PC得分上使用ANOVA是与分类因子关联性的正确正式检验。量化总方差比例的公式也是正确的，因为它正确地将批次因子解释的PC内方差（$R^2_{\\text{PC1}}$）按该PC占总方差的比例（$\\lambda_1/\\sum\\lambda_k$）进行了加权。\n- **计算**：上面推导出的计算结果（$0.090756$）与选项中提供的值（$0.091$ 或 $9.1\\%$）相符。\n- **结论**：**正确**。\n\n**B. 对原始（未标准化）指标的协方差进行PCA以保留自然尺度，使用t检验测试PC载荷与仪器的关联，并将由仪器解释的方差比例报告为仅来自PC1的 $R^{2}$，约 $0.202$ 或 $20.2\\%$。**\n\n- **方法论**：此选项包含多个根本性错误。\n    1.  在此处对原始协方差矩阵进行PCA是不合适的。四个指标（覆盖度、插入片段大小、偏倚、污染）具有不同的单位和方差尺度。分析将被方差最大的指标所主导，而忽略其他指标中有意义的变异。\n    2.  检验PC*载荷*与样本级因子（仪器）的关联是错误的。载荷描述了变量对PC的贡献。PC*得分*是样本的投影，是正确的检验对象。\n    3.  将 $R^2_{\\text{PC1}} \\approx 0.202$ 报告为最终答案是错误的。这个值代表由仪器解释的*PC1的*方差比例，而不是*所有四个指标的总方差*的比例。它未能按PC1对总方差的贡献进行加权。\n- **结论**：**错误**。\n\n**C. 将每个样本（$X$的行）归一化为单位范数，对得到的协方差矩阵进行PCA，使用PC载荷与仪器的相关性来评估批次关联，并将由仪器解释的方差量化为PC1捕获的方差比例，即 $\\lambda_{1}/\\sum_{k} \\lambda_{k} = 0.45$ 或 $45\\%$。**\n\n- **方法论**：此选项同样包含多个根本性错误。\n    1.  对每个样本进行归一化（行归一化）不是此类PCA的标准程序。它混淆了一个样本在不同指标上的测量量级，这不是我们的目标。我们希望根据样本的特征值来比较样本，所以我们应该标准化特征（列）。\n    2.  与选项B一样，评估PC*载荷*与样本级因子的相关性在概念上是错误的。\n    3.  将效应量化为 $\\lambda_1 / \\sum\\lambda_k = 0.45$ 是不正确的。这仅仅是PC1捕获的总方差比例；它没有衡量该方差中有多少可归因于仪器批次效应。它将主导PC的存在与对其的解释混为一谈。\n- **结论**：**错误**。\n\n**D. 标准化指标，对相关性矩阵进行PCA，使用k-均值（$k=2$）在PC空间中对样本进行聚类以恢复仪器分组，然后将由仪器解释的方差量化为PC1组均值的平方差除以指标总数，即 $\\left(\\bar{y}_{\\text{A}} - \\bar{y}_{\\text{B}}\\right)^{2}/4 = 0.36$ 或 $36\\%$。**\n\n- **方法论**：初始步骤是正确的，但后续步骤存在缺陷。\n    1.  使用k-均值聚类是一种无监督方法。由于我们已经有了每个样本的仪器标签，这是一个监督问题。我们应该直接使用这些标签（如在ANOVA中），而不是试图用聚类来“恢复”它们。\n    2.  量化公式 $(\\bar{y}_{\\text{A}} - \\bar{y}_{\\text{B}})^{2}/4$ 是临时的，并且不基于任何方差分解的原则。它正确地计算出 $(0.6 - (-0.6))^2 / 4 = 1.2^2 / 4 = 1.44 / 4 = 0.36$，但该公式本身在统计上对于量化所解释的方差比例是无意义的。它没有考虑组内方差或总样本大小。\n- **结论**：**错误**。",
            "answer": "$$\\boxed{A}$$"
        },
        {
            "introduction": "将基因组大数据应用于临床的核心目标之一是构建能够预测疾病风险或治疗反应的精准模型。然而，当特征数量（如SNP）远大于样本数量（$p \\gg n$）时，一个巨大的陷阱便会出现：数据泄漏。它会导致模型看似完美，实则无法应用于新的病人。本练习  将指导你设计并理解“嵌套交叉验证”这一黄金标准流程。它能严格防止数据泄漏，从而在进行特征选择和模型调优的同时，为我们提供一个关于模型真实泛化能力的无偏估计，这是将任何预测模型从研究推向临床实践的必要前提。",
            "id": "4361973",
            "problem": "一个大型综合医疗系统将电子健康记录 (EHR) 数据与基因分型芯片数据相结合，以预测在开始使用他汀类药物后一年内发生相关不良反应的风险。您有一个由 $N=1{,}200$ 名成年患者组成的队列，其中二元结局的发生率约为 $25\\%$。对于每位患者，有 $p=50{,}000$ 个以次要等位基因计数编码的单核苷酸多态性 (SNP) 特征，以及 $q=20$ 个经过整理的临床协变量。基因分型分 $3$ 个批次进行。您计划训练一个带有弹性网络惩罚的惩罚逻辑回归模型，调整超参数 $\\alpha$ 和 $\\lambda$，并且您还将执行特征选择，包括方差过滤和带有错误发现率 (FDR) 控制的单变量关联过滤。您的目标是估计泛化性能，同时在特征选择和超参数调整过程中严格防止数据泄露。\n\n仅使用关于泛化误差估计、$p \\gg n$ 时的过拟合以及数据泄露（任何使用来自测试数据的信息来影响模型训练或选择的行为）的定义这些基本原则，选择能够正确防止数据泄露的嵌套交叉验证 (CV) 方案，并为在这种基因组学背景下内外层划分的大小提供合理的理由。\n\n哪个选项是最佳的？\n\nA. 使用外层 $K=5$ 折，按结局和基因分型批次进行分层；在此外层训练部分上使用内层 $L=5$ 折。在每个内层划分中，仅使用内层训练折来拟合所有预处理步骤（标准化）、方差过滤和基于 FDR 的单变量过滤，然后在内层循环中通过网格搜索来调整 $\\alpha$ 和 $\\lambda$。通过内层 CV 选择最佳流程，并在未动过的外层测试折上评估一次。对所有外层折的性能取平均。理由：当 $N=1{,}200$ 时，每个外层测试折大约有 $N/K \\approx 240$ 名患者；每个内层训练折大约有 $N \\cdot \\frac{K-1}{K} \\cdot \\frac{L-1}{L} \\approx 768$ 名患者，每个内层验证折大约有 $N \\cdot \\frac{K-1}{K} \\cdot \\frac{1}{L} \\approx 192$ 名患者。鉴于 $25\\%$ 的结局发生率，这能在每折中产生足够的阳性案例，并在外层估计的方差与计算负担之间取得平衡。\n\nB. 首先在整个数据集上对结局进行单变量关联检验，将 SNP 预过滤至前 $1{,}000$ 个特征，然后运行外层 $K=5$、内层 $L=5$ 的嵌套 CV，仅用于调整 $\\alpha$ 和 $\\lambda$。理由：对所有数据进行一次预过滤可以降低维度并稳定内层 CV，然后外层 CV 能提供一个无偏的性能估计。\n\nC. 使用外层 $K=10$ 和内层 $L=10$ 以最大化稳定性。在进行任何划分之前，使用在整个数据集上计算出的全局均值和方差对所有特征进行一次标准化，然后运行内层 CV 来调整 $\\alpha$ 和 $\\lambda$，并在外层折上进行评估。理由：更大的 $K$ 和 $L$ 可以减少估计的方差，而全局标准化可以避免各折之间的尺度漂移。\n\nD. 执行一次 $80/20$ 的训练集/测试集划分。在 $80\\%$ 的训练集内，使用 $L=5$ 折的内层 CV 进行特征选择和超参数调整。如果内层性能饱和，则使用 $20\\%$ 的测试集作为提前停止的合理性检查来微调阈值并重新调整。理由：在 $p \\gg n$ 的情况下，更大的训练集 ($80\\%$) 增加了特征选择的功效，而 $20\\%$ 的测试集确保了外部有效性，同时允许务实的提前停止以避免过拟合。\n\n在上述约束条件下，只有一个选项是完全正确的。请选择它。",
            "solution": "该问题要求评估针对一个高维 ($p \\gg n$) 分类任务的不同验证策略，其明确目标是在严格防止数据泄露的同时，获得对泛化性能的可靠估计。\n\n### 基本原则\n\n1.  **泛化误差**：主要目标是估计一个模型构建*过程*在新的、未见过的数据上的性能。这个过程包括所有从数据中学习的步骤：特征缩放、特征选择以及模型参数/超参数估计。\n2.  **数据泄露**：当来自测试集（为最终性能评估而保留的数据）的信息在模型训练或选择期间被使用（无论是否经过校正）时，就会发生这种关键错误。这会导致一个过于乐观的有偏性能估计，因为模型已在不经意间根据测试数据进行了调整。为了防止泄露，测试集必须只使用一次，用于对一个在完全不知晓测试集的情况下构建出的模型进行最终评估。\n3.  **高维数据 ($p \\gg n$)**：给定的问题有 $p=50,020$ 个预测变量（$50,000$ 个 SNP + $20$ 个临床变量）和 $N=1,200$ 个样本。在这种情况下，过拟合的风险极高。模型可以轻易地在训练数据中找到无法泛化的虚假相关性。因此，严格的验证至关重要。\n4.  **嵌套交叉验证 (CV)**：当建模流程本身涉及超参数调整或任何其他数据驱动的模型选择决策（例如，特征选择）时，这是估计泛化误差的标准方法。\n    *   **外层循环**将数据划分为 $K$ 折，以生成 $K$ 个独立的测试集。其目的是产生一个平均的、稳定的泛化误差估计。\n    *   **内层循环** *仅*在外层循环的训练数据上操作。其目的是为模型选择最优的超参数（这里是 $\\alpha$ 和 $\\lambda$）。\n    *   至关重要的是，整个流程，包括任何依赖于数据的特征预处理或选择（例如，拟合缩放器、运行单变量检验进行过滤），都必须在外层循环的每一折中重新执行，并且只使用该折的训练数据。\n\n### 逐项分析\n\n**A. 使用外层 $K=5$ 折，按结局和基因分型批次进行分层；在此外层训练部分上使用内层 $L=5$ 折。在每个内层划分中，仅使用内层训练折来拟合所有预处理步骤（标准化）、方差过滤和基于 FDR 的单变量过滤，然后在内层循环中通过网格搜索来调整 $\\alpha$ 和 $\\lambda$。通过内层 CV 选择最佳流程，并在未动过的外层测试折上评估一次。对所有外层折的性能取平均。理由：当 $N=1{,}200$ 时，每个外层测试折大约有 $N/K \\approx 240$ 名患者；每个内层训练折大约有 $N \\cdot \\frac{K-1}{K} \\cdot \\frac{L-1}{L} \\approx 768$ 名患者，每个内层验证折大约有 $N \\cdot \\frac{K-1}{K} \\cdot \\frac{1}{L} \\approx 192$ 名患者。鉴于 $25\\%$ 的结局发生率，这能在每折中产生足够的阳性案例，并在外层估计的方差与计算负担之间取得平衡。**\n\n这个选项描述了一个正确且严谨的嵌套交叉验证过程。\n1.  **防止泄露**：它正确地指明了所有依赖于数据的步骤（预处理、过滤、超参数调整）都被包含在验证结构之内。“未动过的外层测试折”仅在每个外层循环迭代中用于最终评估。这种结构严格防止了数据泄露。\n2.  **分层**：按结局和基因分型批次进行分层是最佳实践。按 $25\\%$ 的结局发生率进行分层可确保每个折都有代表性的阳性和阴性案例数量，这对于稳定的模型训练和评估至关重要。按批次分层有助于确保模型对基因分型过程中的技术伪影具有鲁棒性。\n3.  **理由**：所提供的理由是合理的。它正确地计算了各个折的样本量：\n    *   外层训练集大小: $N \\cdot (K-1)/K = 1,200 \\cdot 4/5 = 960$。\n    *   外层测试集大小: $N/K = 1,200/5 = 240$。\n    *   内层训练集大小: $960 \\cdot (L-1)/L = 960 \\cdot 4/5 = 768$。\n    *   内层验证集大小: $960/L = 960/5 = 192$。\n    在 $25\\%$ 的发生率下，最小的训练分区（内层训练集）中的阳性案例数为 $768 \\cdot 0.25 = 192$，最小的验证分区（内层验证集）中的阳性案例数为 $192 \\cdot 0.25 = 48$。这些是足够的样本量，可以避免模型拟合和评估中出现严重的不稳定性。$K=5$ 和 $L=5$ 的选择代表了在计算成本和性能估计的稳定性之间的一个标准且合理的平衡。\n\n**结论：正确。**\n\n**B. 首先在整个数据集上对结局进行单变量关联检验，将 SNP 预过滤至前 $1{,}000$ 个特征，然后运行外层 $K=5$、内层 $L=5$ 的嵌套 CV，仅用于调整 $\\alpha$ 和 $\\lambda$。理由：对所有数据进行一次预过滤可以降低维度并稳定内层 CV，然后外层 CV 能提供一个无偏的性能估计。**\n\n这个选项描述了一个常见但存在根本性缺陷的过程。最初的特征过滤步骤使用了整个数据集，包括结局标签。这意味着来自稍后将用作测试数据的样本的信息已经“泄露”到了特征选择过程中。这些特征被选中是因为它们在整个数据集中显示出关联。因此，交叉验证的性能将会有过于乐观的偏差，因为模型是在已经被用于做出关键建模决策的数据上进行评估的。其理由中声称这能提供一个“无偏的性能估计”是错误的。这是一个典型的数据泄露例子。\n\n**结论：不正确。**\n\n**C. 使用外层 $K=10$ 和内层 $L=10$ 以最大化稳定性。在进行任何划分之前，使用在整个数据集上计算出的全局均值和方差对所有特征进行一次标准化，然后运行内层 CV 来调整 $\\alpha$ 和 $\\lambda$，并在外层折上进行评估。理由：更大的 $K$ 和 $L$ 可以减少估计的方差，而全局标准化可以避免各折之间的尺度漂移。**\n\n这个过程也造成了数据泄露，尽管方式比选项 B 更为微妙。通过使用从*整个数据集*计算出的均值和方差来标准化所有特征，关于测试数据分布的信息（其均值和方差）在模型构建之前就被并入了训练数据中。一个严谨正确的程序必须*仅从*每个 CV 折的训练部分学习标准化参数（均值和方差），然后应用这些相同的参数来缩放该折的测试部分。尽管这种形式的泄露有时没有使用结局标签那么严重，但它仍然违反了严格分离的原则，并可能导致有偏的性能估计。关于避免“尺度漂移”的理由是对目标的误解；我们恰恰想要估计的是模型在新数据（可能存在这种漂移）上的性能。\n\n**结论：不正确。**\n\n**D. 执行一次 $80/20$ 的训练集/测试集划分。在 $80\\%$ 的训练集内，使用 $L=5$ 折的内层 CV 进行特征选择和超参数调整。如果内层性能饱和，则使用 $20\\%$ 的测试集作为提前停止的合理性检查来微调阈值并重新调整。理由：在 $p \\gg n$ 的情况下，更大的训练集 ($80\\%$) 增加了特征选择的功效，而 $20\\%$ 的测试集确保了外部有效性，同时允许务实的提前停止以避免过拟合。**\n\n这个选项明确建议滥用测试集。测试集是用于对已冻结、最终确定的模型进行一次性的最终评估。使用测试集来“微调阈值并重新调整”或作为“提前停止的合理性检查”意味着测试集不再是一个独立的保留集。它被用来指导建模过程，从而成为训练/验证循环的一部分。在这个 $20\\%$ 的集合上报告的任何性能指标都会有过于乐观的偏差。这是一种手动的数据泄露。此外，单次的训练/测试集划分提供的性能估计比 $K$ 折交叉验证方法具有更高的方差（即，更不可靠）。\n\n**结论：不正确。**\n\n### 总结\n\n只有选项 A 描述了一个方法论上合理的过程，它在一个复杂的高维建模流程中正确地实施了嵌套交叉验证以防止数据泄露。其他三个选项都包含导致泛化性能有偏估计的关键缺陷。",
            "answer": "$$\\boxed{A}$$"
        }
    ]
}