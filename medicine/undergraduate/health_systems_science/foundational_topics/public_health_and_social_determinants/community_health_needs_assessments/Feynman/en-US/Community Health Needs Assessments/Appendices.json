{
    "hands_on_practices": [
        {
            "introduction": "When comparing health outcomes between different communities, raw numbers can be deceiving. A community with a large elderly population will naturally have higher rates of age-related diseases than a younger community, even if the underlying health risks are lower. This practice introduces direct age standardization, a fundamental epidemiological tool that allows for fair comparisons by adjusting for differences in age structure, revealing the true underlying health patterns. ",
            "id": "4364090",
            "problem": "A Community Health Needs Assessment (CHNA) by a city health department seeks to compare the burden of asthma-related Emergency Department (ED) visits across communities while accounting for differences in age structure. To isolate underlying risk independent of age distribution, compute a directly age-standardized asthma ED visit rate for the city using the direct method with the 2000 United States standard population. Use the following information:\n\n- Age groups, city population denominators, and annual asthma ED visit counts:\n  - Ages $0$–$17$: population $= 52{,}000$, ED visits $= 780$.\n  - Ages $18$–$44$: population $= 95{,}000$, ED visits $= 600$.\n  - Ages $45$–$64$: population $= 61{,}000$, ED visits $= 500$.\n  - Ages $\\ge 65$: population $= 28{,}000$, ED visits $= 420$.\n\n- Use the 2000 United States standard population weights aggregated to the above age groups:\n  - Ages $0$–$17$: weight $w_1 = 0.26$.\n  - Ages $18$–$44$: weight $w_2 = 0.39$.\n  - Ages $45$–$64$: weight $w_3 = 0.23$.\n  - Ages $\\ge 65$: weight $w_4 = 0.12$.\n\nStarting from core definitions, compute the directly age-standardized annual rate of asthma ED visits per $10{,}000$ population. Then, under a large-sample Poisson assumption for ED visit counts and independence across age strata, construct a $95\\%$ confidence interval (CI) for the directly standardized rate.\n\nInstructions:\n- Express the final age-standardized rate and the lower and upper bounds of the $95\\%$ CI per $10{,}000$ population.\n- Round all three reported numbers to four significant figures.\n- Report your final result as three numbers in the order: standardized rate, lower bound, upper bound.",
            "solution": "The problem is assessed as valid for solution. It is scientifically grounded in standard epidemiological methods (direct age standardization), well-posed with all necessary information provided, and objective in its formulation. The provided standard population weights sum to $1$ ($0.26 + 0.39 + 0.23 + 0.12 = 1.00$), and all data are consistent and realistic. The requested calculations are standard procedures in biostatistics.\n\nLet the index $i$ represent the age stratum, where $i \\in \\{1, 2, 3, 4\\}$.\nThe given data are:\n- For stratum $i=1$ (Ages $0$–$17$): Count $C_1 = 780$, Population $N_1 = 52,000$, Standard Weight $w_1 = 0.26$.\n- For stratum $i=2$ (Ages $18$–$44$): Count $C_2 = 600$, Population $N_2 = 95,000$, Standard Weight $w_2 = 0.39$.\n- For stratum $i=3$ (Ages $45$–$64$): Count $C_3 = 500$, Population $N_3 = 61,000$, Standard Weight $w_3 = 0.23$.\n- For stratum $i=4$ (Ages $\\ge 65$): Count $C_4 = 420$, Population $N_4 = 28,000$, Standard Weight $w_4 = 0.12$.\n\nThe task is to compute the directly age-standardized rate (DASR) and its $95\\%$ confidence interval (CI).\n\nFirst, we calculate the age-specific rate, $r_i$, for each stratum $i$. The age-specific rate is the number of events (ED visits) divided by the population size in that stratum.\n$$r_i = \\frac{C_i}{N_i}$$\nThe rates for the four strata are:\n$$r_1 = \\frac{780}{52,000} = 0.015$$\n$$r_2 = \\frac{600}{95,000} \\approx 0.00631579$$\n$$r_3 = \\frac{500}{61,000} \\approx 0.00819672$$\n$$r_4 = \\frac{420}{28,000} = 0.015$$\n\nThe directly age-standardized rate is the weighted average of the age-specific rates, where the weights are from the standard population. The formula for the DASR is:\n$$\\text{DASR} = \\sum_{i=1}^{4} w_i r_i$$\nSubstituting the values:\n$$\\text{DASR} = (0.26)(0.015) + (0.39)\\left(\\frac{600}{95,000}\\right) + (0.23)\\left(\\frac{500}{61,000}\\right) + (0.12)(0.015)$$\n$$\\text{DASR} \\approx (0.26)(0.015) + (0.39)(0.00631579) + (0.23)(0.00819672) + (0.12)(0.015)$$\n$$\\text{DASR} \\approx 0.0039 + 0.00246316 + 0.00188525 + 0.0018$$\n$$\\text{DASR} \\approx 0.01004841$$\nTo express this rate per $10,000$ population, we multiply by $10,000$:\n$$\\text{DASR}_{\\text{per } 10,000} = 0.01004841 \\times 10,000 = 100.4841$$\n\nNext, we construct the $95\\%$ confidence interval for the DASR. Under the assumption that the event counts $C_i$ follow a Poisson distribution, the variance of the age-specific rate $r_i$ is estimated as:\n$$\\text{Var}(r_i) \\approx \\frac{C_i}{N_i^2}$$\nSince the age strata are independent, the variance of the DASR, which is a linear combination of the $r_i$, is the sum of the weighted variances:\n$$\\text{Var}(\\text{DASR}) = \\sum_{i=1}^{4} w_i^2 \\text{Var}(r_i) \\approx \\sum_{i=1}^{4} \\frac{w_i^2 C_i}{N_i^2}$$\nWe calculate this sum term by term:\n$$\\text{Var}(\\text{DASR}) \\approx \\frac{0.26^2 \\times 780}{52,000^2} + \\frac{0.39^2 \\times 600}{95,000^2} + \\frac{0.23^2 \\times 500}{61,000^2} + \\frac{0.12^2 \\times 420}{28,000^2}$$\n$$\\text{Var}(\\text{DASR}) \\approx \\frac{52.728}{2,704,000,000} + \\frac{91.26}{9,025,000,000} + \\frac{26.45}{3,721,000,000} + \\frac{6.048}{784,000,000}$$\n$$\\text{Var}(\\text{DASR}) \\approx 1.9485 \\times 10^{-8} + 1.0112 \\times 10^{-8} + 0.7108 \\times 10^{-8} + 0.7714 \\times 10^{-8}$$\n$$\\text{Var}(\\text{DASR}) \\approx 4.4419 \\times 10^{-8}$$\nThe standard error (SE) of the DASR is the square root of its variance:\n$$\\text{SE}(\\text{DASR}) = \\sqrt{\\text{Var}(\\text{DASR})} \\approx \\sqrt{4.4419 \\times 10^{-8}} \\approx 2.1076 \\times 10^{-4}$$\n\nFor a large sample, the $95\\%$ CI is constructed using the normal approximation:\n$$\\text{CI} = \\text{DASR} \\pm Z_{1-\\alpha/2} \\times \\text{SE}(\\text{DASR})$$\nFor a $95\\%$ CI, $\\alpha=0.05$, and the critical value is $Z_{0.975} = 1.96$.\nThe margin of error (ME) is:\n$$\\text{ME} = 1.96 \\times \\text{SE}(\\text{DASR}) \\approx 1.96 \\times 2.1076 \\times 10^{-4} \\approx 4.1309 \\times 10^{-4}$$\nThe lower and upper bounds of the CI for the DASR are:\n$$\\text{Lower Bound} = \\text{DASR} - \\text{ME} \\approx 0.01004841 - 0.00041309 = 0.00963532$$\n$$\\text{Upper Bound} = \\text{DASR} + \\text{ME} \\approx 0.01004841 + 0.00041309 = 0.01046150$$\n\nTo express these bounds per $10,000$ population, we multiply by $10,000$:\n$$\\text{Lower Bound}_{\\text{per } 10,000} = 0.00963532 \\times 10,000 = 96.3532$$\n$$\\text{Upper Bound}_{\\text{per } 10,000} = 0.01046150 \\times 10,000 = 104.6150$$\n\nFinally, we round the standardized rate and the CI bounds to four significant figures as instructed:\n- Standardized Rate: $100.4841 \\to 100.5$\n- Lower Bound: $96.3532 \\to 96.35$\n- Upper Bound: $104.6150 \\to 104.6$\n\nThe three requested numbers are the standardized rate, the lower bound, and the upper bound, all per $10,000$ population.",
            "answer": "$$\\boxed{\\begin{pmatrix} 100.5 & 96.35 & 104.6 \\end{pmatrix}}$$"
        },
        {
            "introduction": "How we define the boundaries of a \"community\" can significantly alter our understanding of its health needs. In this practice, you will explore the Modifiable Areal Unit Problem (MAUP), a critical concept in spatial epidemiology, by seeing how health event rates change when using different geographic units like ZIP codes versus census tracts. This exercise highlights that data are not neutral and that the choice of spatial denominator is a crucial methodological decision in any Community Health Needs Assessment. ",
            "id": "4364088",
            "problem": "A health system analyst is evaluating how different catchment definitions affect asthma event rate estimates during a Community Health Needs Assessment. The analyst compares catchments defined by Zone Improvement Plan (ZIP) code–based aggregations versus catchments defined by census tract–based aggregations. The foundational principle is the definition of an event rate: for a fixed observation window, the rate is the number of events divided by the population at risk and the duration of observation. Specifically, the event rate for asthma Emergency Department (ED) visits is computed as visits per $10{,}000$ person-years.\n\nFundamental base:\n- Definition of event rate: $r = \\dfrac{N}{P \\cdot T}$, where $N$ is the total number of events, $P$ is the population at risk, and $T$ is the duration in years.\n- Scaling to a conventional community health metric: visits per $10{,}000$ person-years, implemented via $r_{\\text{scaled}} = r \\cdot S$, where $S = 10{,}000$.\n- Well-tested observation in geographic epidemiology: changing the aggregation unit of the denominator (for example, ZIP code versus census tract) can change estimated rates because $P$ differs even if $N$ is held fixed, a phenomenon related to the Modifiable Areal Unit Problem.\n\nTask:\n- For each test case, you are given the same asthma ED numerator count $N$ and two denominators: $P_{\\text{zip}}$ for the ZIP code–based catchment and $P_{\\text{tract}}$ for the census tract–based catchment, along with the observation duration $T$ in years.\n- Compute the ZIP code–based rate $r_{\\text{zip}} = \\dfrac{N}{P_{\\text{zip}} \\cdot T} \\cdot S$ and the census tract–based rate $r_{\\text{tract}} = \\dfrac{N}{P_{\\text{tract}} \\cdot T} \\cdot S$, where $S = 10{,}000$.\n- Compute the change factor $F = \\dfrac{r_{\\text{tract}}}{r_{\\text{zip}}}$ to quantify how the denominator choice inflates or deflates the rate. Handle boundary conditions deterministically: if $r_{\\text{zip}} = 0$ and $r_{\\text{tract}} = 0$, define $F = 1$; if $r_{\\text{zip}} = 0$ and $r_{\\text{tract}} > 0$, define $F = +\\infty$; if $r_{\\text{zip}} > 0$ and $r_{\\text{tract}} = 0$, define $F = 0$.\n- Compute the absolute difference $D = \\left| r_{\\text{tract}} - r_{\\text{zip}} \\right|$ and determine whether it is at least the threshold $\\tau = 5$ visits per $10{,}000$ person-years. Output a boolean $B$ that is $\\text{True}$ if $D \\ge \\tau$ and $\\text{False}$ otherwise.\n\nUnits and numerical format:\n- All rates must be expressed in visits per $10{,}000$ person-years.\n- The outputs $r_{\\text{zip}}$, $r_{\\text{tract}}$, and $F$ must be rounded to $3$ decimal places in the final output. The boolean $B$ is not rounded.\n\nTest suite:\nProvide solutions for the following parameter sets $(N, P_{\\text{zip}}, P_{\\text{tract}}, T)$ where all quantities are positive integers except durations $T$ which are positive reals, and all populations represent persons:\n1. $(N, P_{\\text{zip}}, P_{\\text{tract}}, T) = (120, 50000, 35000, 1)$\n2. $(N, P_{\\text{zip}}, P_{\\text{tract}}, T) = (5, 800, 1200, 0.5)$\n3. $(N, P_{\\text{zip}}, P_{\\text{tract}}, T) = (0, 100000, 90000, 1)$\n4. $(N, P_{\\text{zip}}, P_{\\text{tract}}, T) = (300, 120000, 125000, 2)$\n5. $(N, P_{\\text{zip}}, P_{\\text{tract}}, T) = (45, 400000, 250000, 1.5)$\n\nFinal output specification:\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, with one sublist per test case. Each sublist must be in the order $[r_{\\text{zip}}, r_{\\text{tract}}, F, B]$ and contain the two rate floats rounded to $3$ decimal places, the change factor float rounded to $3$ decimal places (or $+\\infty$ as needed), and the boolean $B$.\n- Example of the required output structure: $[[r_{\\text{zip},1}, r_{\\text{tract},1}, F_1, B_1],[r_{\\text{zip},2}, r_{\\text{tract},2}, F_2, B_2],\\dots]$.",
            "solution": "The problem statement is evaluated as valid. It is scientifically grounded, well-posed, and objective. The problem describes a standard epidemiological calculation of event rates and investigates the effect of changing the denominator population, a concept related to the Modifiable Areal Unit Problem (MAUP) in geographic analysis. The inputs are clearly defined, the required calculations are specified through explicit formulas, and the output format is precise. There are no contradictions, ambiguities, or reliance on non-scientific claims.\n\nThe solution proceeds by applying the provided formulas to each test case.\n\nThe core formula for the event rate, scaled per $S = 10{,}000$ person-years, is given by:\n$$ r_{\\text{scaled}} = \\frac{N}{P \\cdot T} \\cdot S $$\nwhere $N$ is the number of events, $P$ is the population at risk, and $T$ is the observation duration in years.\n\nFor each test case, we are given a set of parameters $(N, P_{\\text{zip}}, P_{\\text{tract}}, T)$. We must compute four values: $r_{\\text{zip}}$, $r_{\\text{tract}}$, $F$, and $B$.\n\n1.  **ZIP Code-Based Rate ($r_{\\text{zip}}$)**:\n    This rate is calculated using the ZIP code-based population denominator, $P_{\\text{zip}}$.\n    $$ r_{\\text{zip}} = \\frac{N}{P_{\\text{zip}} \\cdot T} \\cdot 10000 $$\n\n2.  **Census Tract-Based Rate ($r_{\\text{tract}}$)**:\n    This rate is calculated using the census tract-based population denominator, $P_{\\text{tract}}$.\n    $$ r_{\\text{tract}} = \\frac{N}{P_{\\text{tract}} \\cdot T} \\cdot 10000 $$\n\n3.  **Change Factor ($F$)**:\n    The change factor $F$ is the ratio of the tract-based rate to the ZIP-based rate.\n    $$ F = \\frac{r_{\\text{tract}}}{r_{\\text{zip}}} $$\n    For the case where $N > 0$, both rates will be non-zero (since $P > 0$ and $T > 0$). We can simplify the expression for $F$:\n    $$ F = \\frac{\\frac{N}{P_{\\text{tract}} \\cdot T} \\cdot S}{\\frac{N}{P_{\\text{zip}} \\cdot T} \\cdot S} = \\frac{N \\cdot S}{P_{\\text{tract}} \\cdot T} \\cdot \\frac{P_{\\text{zip}} \\cdot T}{N \\cdot S} = \\frac{P_{\\text{zip}}}{P_{\\text{tract}}} $$\n    This simplification is numerically stable and avoids a division involving potentially small, calculated rates.\n    For the boundary case where $N=0$, both $r_{\\text{zip}}$ and $r_{\\text{tract}}$ are $0$. The problem defines $F=1$ in this scenario. The other boundary conditions ($F=+\\infty$ and $F=0$ due to one rate being zero while the other is not) are impossible given that both rates share the same numerator $N$ and have finite, positive denominators. Thus, our logic is: if $N=0$, then $F=1$; otherwise, $F = P_{\\text{zip}} / P_{\\text{tract}}$.\n\n4.  **Absolute Difference ($D$) and Threshold Boolean ($B$)**:\n    The absolute difference $D$ between the two rates is calculated as:\n    $$ D = \\left| r_{\\text{tract}} - r_{\\text{zip}} \\right| $$\n    A boolean value $B$ is determined by comparing $D$ against a specified threshold $\\tau = 5$ visits per $10{,}000$ person-years.\n    $$ B = (D \\ge 5) $$\n\nThe final numerical results for rates and the change factor must be rounded to $3$ decimal places for output.\n\nLet's demonstrate the calculation for the first test case: $(N, P_{\\text{zip}}, P_{\\text{tract}}, T) = (120, 50000, 35000, 1)$.\n- $r_{\\text{zip}} = \\dfrac{120}{50000 \\cdot 1} \\cdot 10000 = 0.0024 \\cdot 10000 = 24.0$\n- $r_{\\text{tract}} = \\dfrac{120}{35000 \\cdot 1} \\cdot 10000 \\approx 0.00342857 \\cdot 10000 \\approx 34.2857$\n- $F = \\dfrac{P_{\\text{zip}}}{P_{\\text{tract}}} = \\dfrac{50000}{35000} = \\dfrac{10}{7} \\approx 1.42857$\n- $D = |34.2857 - 24.0| = 10.2857$\n- $B = (10.2857 \\ge 5) = \\text{True}$\n\nAfter rounding to $3$ decimal places, the output for this specific case is $[24.000, 34.286, 1.429, \\text{True}]$. The same procedure is applied to all other test cases to generate the final result.",
            "answer": "[[24.000, 34.286, 1.429, True],[125.000, 83.333, 0.667, True],[0.000, 0.000, 1.000, False],[12.500, 12.000, 0.960, False],[0.750, 1.200, 1.600, False]]"
        },
        {
            "introduction": "After analyzing data and identifying numerous health issues, a CHNA's most challenging phase begins: prioritization. With limited resources, which needs should be addressed first? This practice guides you through building a Multi-Criteria Decision Analysis (MCDA) model, a structured framework used to synthesize diverse data points—from disease magnitude and severity to feasibility and community preferences—into a rational and transparent priority score. ",
            "id": "4364052",
            "problem": "A health system must prioritize community health needs using a multi-criteria decision analysis framework. Each health need is characterized by five criteria: magnitude, severity, disparity, feasibility, and community preference. The fundamental base for decision-making is a value function model rooted in utility theory: when attributes are mutually preferentially independent, an additive multi-attribute value function exists that rationally aggregates criterion-specific values.\n\nDefinitions and assumptions for the model are as follows:\n- Magnitude ($x_{\\text{mag}}$): the number of persons affected, measured in persons.\n- Severity ($x_{\\text{sev}}$): an expert rating on a bounded scale from $0$ to $10$.\n- Disparity ($x_{\\text{disp}}$): a dimensionless ratio of the rate in a target subpopulation to the rate in a reference population, with $x_{\\text{disp}} \\ge 1$.\n- Feasibility ($x_{\\text{feas}}$): an estimated probability of successful implementation in $[0,1]$, expressed as a decimal.\n- Community preference ($x_{\\text{pref}}$): the fraction of surveyed respondents who favor prioritization, in $[0,1]$, expressed as a decimal.\n\nLet $v_j(\\cdot)$ denote the criterion-specific value transformation that maps raw measurements to a commensurate scale in $[0,1]$ with monotone increasing preference (larger is better). The overall value (priority score) for need $i$ is modeled as\n$$\nU_i = \\sum_{j=1}^{5} w_j \\, v_j\\!\\left(x_{ij}\\right),\n$$\nwhere $w_j \\ge 0$ are criterion weights satisfying $\\sum_{j=1}^{5} w_j = 1$.\n\nYou must construct the following normalization scheme for commensurability:\n- For magnitude, use a logarithmically tempered min-max transform to address heavy-tailed counts:\n$$\nv_{\\text{mag}}(x) = \n\\begin{cases}\n\\dfrac{\\log(1+x) - \\log(1+x_{\\min})}{\\log(1+x_{\\max}) - \\log(1+x_{\\min})}, & \\text{if } \\log(1+x_{\\max}) \\neq \\log(1+x_{\\min}),\\\n$$8pt]\n0.5, & \\text{otherwise,}\n\\end{cases}\n$$\nwhere $x_{\\min}$ and $x_{\\max}$ are the minimum and maximum of the observed magnitude values in a given test case.\n- For severity, use linear scaling on its known bounds:\n$$\nv_{\\text{sev}}(s) = \\dfrac{s}{10}.\n$$\n- For disparity, use a logarithmically tempered min-max transform to account for multiplicative differences:\n$$\nv_{\\text{disp}}(r) = \n\\begin{cases}\n\\dfrac{\\log(r) - \\log(r_{\\min})}{\\log(r_{\\max}) - \\log(r_{\\min})}, & \\text{if } \\log(r_{\\max}) \\neq \\log(r_{\\min}),\\\n$$8pt]\n0.5, & \\text{otherwise,}\n\\end{cases}\n$$\nwhere $r_{\\min}$ and $r_{\\max}$ are the minimum and maximum of the observed disparity ratios in a given test case.\n- For feasibility, use identity on $[0,1]$:\n$$\nv_{\\text{feas}}(f) = f.\n$$\n- For community preference, use identity on $[0,1]$:\n$$\nv_{\\text{pref}}(p) = p.\n$$\n\nWhen any min-max denominator is zero (all observed values are equal for that criterion within a test case), define the normalized value as $0.5$ for all alternatives on that criterion. Use $0$-based indexing for needs, and break ties by choosing the smallest index.\n\nYour task is to implement this normalization scheme and compute $U_i$ for each need across the following test suite. For each test case, output the index of the single highest-priority need.\n\nTest suite:\n- Test case $1$ (weights $w = [0.3, 0.25, 0.2, 0.15, 0.1]$):\n  - Magnitude (persons): $[8500, 12000, 3000, 9500]$\n  - Severity ($0$–$10$): $[7.5, 6.0, 5.5, 8.0]$\n  - Disparity ratio ($\\ge 1$): $[1.8, 1.2, 2.5, 1.4]$\n  - Feasibility (decimal): $[0.7, 0.9, 0.6, 0.5]$\n  - Preference (decimal): $[0.65, 0.55, 0.80, 0.60]$\n- Test case $2$ (weights $w = [0.25, 0.20, 0.30, 0.15, 0.10]$):\n  - Magnitude (persons): $[50000, 900, 2500, 4000]$\n  - Severity ($0$–$10$): $[9.0, 4.0, 6.5, 7.0]$\n  - Disparity ratio ($\\ge 1$): $[1.1, 2.0, 3.2, 1.5]$\n  - Feasibility (decimal): $[0.4, 0.8, 0.6, 0.7]$\n  - Preference (decimal): $[0.50, 0.70, 0.60, 0.55]$\n- Test case $3$ (weights $w = [0.2, 0.2, 0.2, 0.2, 0.2]$):\n  - Magnitude (persons): $[2000, 2000, 2000, 2000]$\n  - Severity ($0$–$10$): $[5.0, 5.0, 5.0, 5.0]$\n  - Disparity ratio ($\\ge 1$): $[1.0, 1.0, 1.0, 1.0]$\n  - Feasibility (decimal): $[0.2, 0.4, 0.6, 0.8]$\n  - Preference (decimal): $[0.1, 0.2, 0.3, 0.4]$\n- Test case $4$ (weights $w = [0.35, 0.25, 0.20, 0.10, 0.10]$):\n  - Magnitude (persons): $[0, 750, 1500]$\n  - Severity ($0$–$10$): $[8.5, 7.0, 3.0]$\n  - Disparity ratio ($\\ge 1$): $[1.7, 1.3, 2.1]$\n  - Feasibility (decimal): $[0.3, 0.9, 0.2]$\n  - Preference (decimal): $[0.0, 0.6, 0.4]$\n\nYour program must compute the normalized criterion values, aggregate them via the weighted sum to obtain $U_i$ for each need in each test case, and then report the index of the highest $U_i$ per test case. Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (for example, $[0,2,1,3]$). No user input is required.",
            "solution": "The problem presents a multi-criteria decision analysis (MCDA) framework for prioritizing community health needs. The method is based on an additive multi-attribute value function, a standard technique in decision theory when the assumption of mutual preferential independence among criteria holds. Our task is to implement this model, calculate the priority score for each health need within several test cases, and identify the need with the highest score in each case.\n\nThe overall value, or priority score $U_i$, for a given health need $i$ is calculated as a weighted sum of its performance on five criteria:\n$$\nU_i = \\sum_{j=1}^{5} w_j \\, v_j\\!\\left(x_{ij}\\right)\n$$\nHere, $x_{ij}$ is the raw score of need $i$ on criterion $j$, $v_j(\\cdot)$ is a criterion-specific value function that normalizes the raw score to a common scale of $[0, 1]$, and $w_j$ is the weight of criterion $j$, with $w_j \\ge 0$ and $\\sum_j w_j = 1$. The criteria are magnitude ($x_{\\text{mag}}$), severity ($x_{\\text{sev}}$), disparity ($x_{\\text{disp}}$), feasibility ($x_{\\text{feas}}$), and community preference ($x_{\\text{pref}}$).\n\nThe process involves three main steps for each test case:\n1.  Apply the specified value functions $v_j(\\cdot)$ to normalize the raw data for each criterion across all competing health needs.\n2.  Aggregate the normalized values for each need using the provided weights to compute the total priority score $U_i$.\n3.  Identify the index of the health need with the maximum score $U_i$, using the smallest index as a tie-breaker.\n\nThe value functions $v_j(\\cdot)$ are defined as follows:\n\n**1. Magnitude ($v_{\\text{mag}}$):**\nFor the number of persons affected, $x$, a logarithmically tempered min-max normalization is employed. The transformation $x \\to \\log(1+x)$ is used to handle potentially heavy-tailed distributions of counts and to ensure the logarithm is defined for $x=0$.\nThe value function is:\n$$\nv_{\\text{mag}}(x) = \\frac{\\log(1+x) - \\log(1+x_{\\min})}{\\log(1+x_{\\max}) - \\log(1+x_{\\min})}\n$$\nwhere $x_{\\min}$ and $x_{\\max}$ are the minimum and maximum observed magnitude values within the set of needs being compared. If all needs have the same magnitude ($x_{\\min} = x_{\\max}$), the denominator becomes zero. In this case, the normalized value is defined as $0.5$ for all needs, representing a neutral or average contribution from this criterion.\n\n**2. Severity ($v_{\\text{sev}}$):**\nSeverity, $s$, is an expert rating on a fixed scale from $0$ to $10$. It is normalized using linear scaling with respect to its theoretical bounds:\n$$\nv_{\\text{sev}}(s) = \\frac{s}{10}\n$$\nThis transforms the score to the required $[0, 1]$ interval.\n\n**3. Disparity ($v_{\\text{disp}}$):**\nDisparity, $r$, is a ratio where multiplicative differences are more meaningful than additive ones. Thus, a logarithmic min-max normalization is used:\n$$\nv_{\\text{disp}}(r) = \\frac{\\log(r) - \\log(r_{\\min})}{\\log(r_{\\max}) - \\log(r_{\\min})}\n$$\nwhere $r_{\\min}$ and $r_{\\max}$ are the minimum and maximum observed disparity ratios. Since $r \\ge 1$, $\\log(r)$ is well-defined and non-negative. Similar to magnitude, if all disparity values are equal ($r_{\\min} = r_{\\max}$), the normalized value is set to $0.5$.\n\n**4. Feasibility ($v_{\\text{feas}}$) and Community Preference ($v_{\\text{pref}}$):**\nBoth feasibility, $f$, and community preference, $p$, are given as values in the interval $[0,1]$ (a probability and a fraction, respectively). As they are already on the desired common scale, the identity function is used for their value transformation:\n$$\nv_{\\text{feas}}(f) = f \\\\\nv_{\\text{pref}}(p) = p\n$$\n\n**Computational Procedure:**\nFor each test case, we will perform the following computations using vectorized operations for efficiency.\nLet the raw data for $N$ needs and $5$ criteria be represented by an $N \\times 5$ matrix of raw scores. We will generate an $N \\times 5$ matrix of normalized values, $V$, where each element $V_{ij} = v_j(x_{ij})$.\n1.  For the `magnitude` column, determine $x_{\\min}$ and $x_{\\max}$. Apply the $v_{\\text{mag}}$ formula to obtain the first column of $V$.\n2.  For the `severity` column, apply the $v_{\\text{sev}}$ formula to obtain the second column of $V$.\n3.  For the `disparity` column, determine $r_{\\min}$ and $r_{\\max}$. Apply the $v_{\\text{disp}}$ formula to obtain the third column of $V$.\n4.  The `feasibility` and `preference` columns directly form the fourth and fifth columns of $V$.\n5.  The priority scores for all needs are then computed in a single operation by taking the matrix-vector product of the normalized value matrix $V$ and the weight vector $w$:\n    $$\n    \\mathbf{U} = V \\mathbf{w}\n    $$\n    where $\\mathbf{U}$ is an $N \\times 1$ vector of priority scores.\n6.  Finally, we find the $0$-based index of the maximum value in the vector $\\mathbf{U}$. The `argmax` function, which returns the index of the first occurrence of the maximum value, naturally handles the specified tie-breaking rule. This process is repeated for each test case provided in the problem statement.",
            "answer": "[0,2,3,1]"
        }
    ]
}