{
    "hands_on_practices": [
        {
            "introduction": "In community trials, individuals are not independent; people within the same community often share environmental or social factors that make their health outcomes more similar to each other than to individuals in other communities. This exercise asks you to compute the Intraclass Correlation Coefficient ($\\rho$), which is the key metric used to quantify this similarity, from its fundamental variance components. Understanding and calculating $\\rho$ is the essential first step in correctly designing and analyzing any community trial, as it directly impacts statistical power and sample size.",
            "id": "4578645",
            "problem": "Consider a community-level intervention evaluated using a cluster randomized trial, where individuals are nested within community clusters. Suppose a continuous outcome is modeled by a random-intercept structure in which individual outcomes within the same cluster share a common random effect. The between-cluster variance is given by $\\sigma_{b}^{2} = 4$, and the within-cluster variance is given by $\\sigma_{w}^{2} = 16$. Using only the fundamental definitions of variance and covariance for a random-intercept model and the definition of the Intraclass Correlation Coefficient (ICC), compute the ICC, denoted $\\rho$. Provide $\\rho$ as an exact fraction. Then, based on the magnitude of $\\rho$, reason from first principles whether a cluster-level analysis of cluster means or an individual-level analysis with appropriate correction for clustering (for example, a linear mixed-effects model or Generalized Estimating Equations (GEE)) tends to be more statistically efficient for estimating a marginal treatment effect. No numerical result beyond $\\rho$ is required for the efficiency discussion, and no additional formulas are provided in the problem statement.",
            "solution": "The problem asks for two things: first, to compute the Intraclass Correlation Coefficient (ICC), denoted $\\rho$, for a given random-intercept model structure, and second, to reason about the relative statistical efficiency of cluster-level versus individual-level analysis based on the computed value of $\\rho$.\n\nLet $Y_{ij}$ represent the continuous outcome for individual $j$ (where $j=1, \\dots, m_i$) in cluster $i$ (where $i=1, \\dots, k$). The problem states that the outcome is modeled by a random-intercept structure. This model can be written as:\n$$Y_{ij} = \\mu + u_i + \\epsilon_{ij}$$\nHere, $\\mu$ is the overall mean outcome, $u_i$ is the random effect shared by all individuals in cluster $i$, and $\\epsilon_{ij}$ is the individual-level random error for person $j$ in cluster $i$.\n\nThe assumptions of the random-intercept model are:\n1. The cluster random effects $u_i$ are independent and identically distributed, with a mean of $E[u_i] = 0$ and a variance of $\\text{Var}(u_i) = \\sigma_{b}^{2}$. This is the between-cluster variance, given as $\\sigma_{b}^{2} = 4$.\n2. The individual-level errors $\\epsilon_{ij}$ are independent and identically distributed, with a mean of $E[\\epsilon_{ij}] = 0$ and a variance of $\\text{Var}(\\epsilon_{ij}) = \\sigma_{w}^{2}$. This is the within-cluster variance, given as $\\sigma_{w}^{2} = 16$.\n3. The random effects $u_i$ and the random errors $\\epsilon_{ij}$ are independent of each other for all $i$ and $j$.\n\nTo compute the ICC, we must first determine the total variance of an observation and the covariance between two distinct observations within the same cluster.\n\nThe total variance of a single observation $Y_{ij}$ is derived from its model definition. Since $\\mu$ is a constant and $u_i$ and $\\epsilon_{ij}$ are independent random variables:\n$$\\text{Var}(Y_{ij}) = \\text{Var}(\\mu + u_i + \\epsilon_{ij}) = \\text{Var}(u_i) + \\text{Var}(\\epsilon_{ij})$$\nSubstituting the given variance components, the total variance is:\n$$\\text{Var}(Y_{ij}) = \\sigma_{b}^{2} + \\sigma_{w}^{2}$$\n\nNext, we find the covariance between the outcomes of two different individuals, $j$ and $l$ ($j \\neq l$), from the same cluster $i$.\n$$\\text{Cov}(Y_{ij}, Y_{il}) = \\text{Cov}(\\mu + u_i + \\epsilon_{ij}, \\mu + u_i + \\epsilon_{il})$$\nUsing the properties of covariance and the independence assumptions (i.e., $\\text{Cov}(u_i, \\epsilon_{il}) = 0$, $\\text{Cov}(\\epsilon_{ij}, u_i) = 0$, and $\\text{Cov}(\\epsilon_{ij}, \\epsilon_{il}) = 0$ for $j \\neq l$):\n$$\\text{Cov}(Y_{ij}, Y_{il}) = \\text{Cov}(u_i, u_i) + \\text{Cov}(u_i, \\epsilon_{il}) + \\text{Cov}(\\epsilon_{ij}, u_i) + \\text{Cov}(\\epsilon_{ij}, \\epsilon_{il})$$\n$$\\text{Cov}(Y_{ij}, Y_{il}) = \\text{Var}(u_i) + 0 + 0 + 0 = \\sigma_{b}^{2}$$\nThe shared random effect $u_i$ is the sole source of covariance between two individuals in the same cluster.\n\nThe Intraclass Correlation Coefficient, $\\rho$, is defined as the correlation between two randomly selected individuals from the same randomly selected cluster. Using the fundamental definition of correlation:\n$$\\rho = \\text{Corr}(Y_{ij}, Y_{il}) = \\frac{\\text{Cov}(Y_{ij}, Y_{il})}{\\sqrt{\\text{Var}(Y_{ij})\\text{Var}(Y_{il})}}$$\nSince the variance is identical for all observations, $\\text{Var}(Y_{ij}) = \\text{Var}(Y_{il}) = \\sigma_{b}^{2} + \\sigma_{w}^{2}$, the formula simplifies to:\n$$\\rho = \\frac{\\text{Cov}(Y_{ij}, Y_{il})}{\\text{Var}(Y_{ij})} = \\frac{\\sigma_{b}^{2}}{\\sigma_{b}^{2} + \\sigma_{w}^{2}}$$\nThis equation shows that $\\rho$ represents the proportion of the total variance that is attributable to variance between clusters.\n\nSubstituting the given values $\\sigma_{b}^{2} = 4$ and $\\sigma_{w}^{2} = 16$:\n$$\\rho = \\frac{4}{4 + 16} = \\frac{4}{20} = \\frac{1}{5}$$\n\nThe second part of the problem requires reasoning about the statistical efficiency of a cluster-level analysis versus an individual-level analysis with correction for clustering.\nThe calculated ICC is $\\rho = \\frac{1}{5} = 0.2$. This value indicates that $20\\%$ of the total variance in the outcome is due to variation between clusters, while the remaining $80\\%$ is due to variation among individuals within the clusters.\n\nA cluster-level analysis first calculates a summary statistic (e.g., the mean) for each cluster and then performs the analysis on these cluster-level summaries. This method discards all individual-level, within-cluster variation.\nAn individual-level analysis (like a mixed-effects model or GEE) uses data from all individuals and explicitly accounts for the correlation structure (parameterized by $\\rho$) in the model.\n\nStatistical efficiency is related to the precision of the estimate of the treatment effect; a more efficient method yields an estimate with a smaller variance (and smaller standard error). The choice between the two methods hinges on how much information is lost by aggregating the data to the cluster level.\n\nIn this problem, the within-cluster variance ($\\sigma_{w}^{2} = 16$) is four times larger than the between-cluster variance ($\\sigma_{b}^{2} = 4$). This signifies that there is substantial heterogeneity among individuals within each cluster. This large within-cluster variation is an important source of information. A cluster-level analysis, by collapsing all individual data points in a cluster to a single mean, discards this substantial source of information. The analysis effectively throws away $80\\%$ of the variance structure. This loss of information leads to less precise estimates of the treatment effect, and thus lower statistical efficiency.\n\nIn contrast, an individual-level analysis with an appropriate correction for clustering utilizes all available data points. By modeling both the between-cluster and within-cluster components of variance, it leverages the full information content of the data. This allows for a more precise estimation of all model parameters, including the treatment effect. The resulting estimates will have smaller standard errors compared to those from a cluster-level analysis.\n\nTherefore, given that $\\rho = 0.2$ is not close to $1$ and the within-cluster variance is large, an individual-level analysis with correction for clustering tends to be more statistically efficient. A cluster-level analysis would only approach the efficiency of an individual-level analysis if $\\rho$ were very high (close to $1$), which would imply that individuals within a cluster are nearly identical ($\\sigma_{w}^{2} \\approx 0$) and provide redundant information. As this is not the case here, preserving the individual-level information is crucial for achieving greater statistical efficiency.",
            "answer": "$$\\boxed{\\frac{1}{5}}$$"
        },
        {
            "introduction": "After establishing that clustering introduces correlation (), the next critical question is how to quantify its impact on statistical precision. The design effect (DEFF) provides a direct measure of how much the variance of an estimate is inflated due to the clustered design compared to a simple random sample. This practice guides you through deriving the foundational formula for the DEFF and using it to calculate the \"effective sample size,\" revealing the true statistical power of a clustered sample.",
            "id": "4578618",
            "problem": "Consider a community randomized trial in which entire communities are randomized to intervention or control. Suppose there are $J$ communities, each contributing exactly $m$ individuals, for a total of $n=Jm$ individuals. Let $Y_{ij}$ denote an outcome measured on individual $j$ in community $i$. Assume each $Y_{ij}$ has the same variance $\\sigma^{2}$, observations from different communities are independent, and any two distinct individuals within the same community have a common covariance consistent with an intraclass correlation coefficient (ICC) $\\rho$, defined as the correlation between two distinct individuals in the same community. The design effect is defined as the ratio of the variance of the overall sample mean under this clustered sampling structure to the variance of the overall sample mean under simple random sampling of $n$ independent individuals.\n\nStarting from the definitions of variance and covariance, and the definition of the intraclass correlation coefficient, derive the design effect for equal cluster size $m$ and ICC $\\rho$. Then, for $m=15$, $\\rho=0.05$, and a total individual sample size of $n=600$, compute the design effect and the corresponding effective sample size, defined as the size of a simple random sample that would yield the same variance of the overall mean as the clustered sample. Round both numerical answers to four significant figures. Express the effective sample size as a unitless count.",
            "solution": "### Derivation of the Design Effect\nLet $\\bar{Y}$ denote the overall sample mean from the clustered sample. It is defined as:\n$$ \\bar{Y} = \\frac{1}{n} \\sum_{i=1}^{J} \\sum_{j=1}^{m} Y_{ij} $$\nThe variance of the overall mean, which we will denote $\\text{Var}(\\bar{Y}_{\\text{cluster}})$, is:\n$$ \\text{Var}(\\bar{Y}_{\\text{cluster}}) = \\text{Var}\\left(\\frac{1}{n} \\sum_{i=1}^{J} \\sum_{j=1}^{m} Y_{ij}\\right) = \\frac{1}{n^2} \\text{Var}\\left(\\sum_{i=1}^{J} \\sum_{j=1}^{m} Y_{ij}\\right) $$\nLet $T_i = \\sum_{j=1}^{m} Y_{ij}$ be the total outcome for cluster $i$. The grand sum can be written as $\\sum_{i=1}^{J} T_i$. Since observations from different communities are independent, the cluster totals $T_i$ are independent variables. The variance of a sum of independent variables is the sum of their variances:\n$$ \\text{Var}\\left(\\sum_{i=1}^{J} T_i\\right) = \\sum_{i=1}^{J} \\text{Var}(T_i) $$\nNext, we calculate the variance of a single cluster total, $\\text{Var}(T_i)$.\n$$ \\text{Var}(T_i) = \\text{Var}\\left(\\sum_{j=1}^{m} Y_{ij}\\right) $$\nUsing the general formula for the variance of a sum of correlated variables:\n$$ \\text{Var}\\left(\\sum_{j=1}^{m} Y_{ij}\\right) = \\sum_{j=1}^{m} \\text{Var}(Y_{ij}) + \\sum_{j=1}^{m} \\sum_{k \\neq j} \\text{Cov}(Y_{ij}, Y_{ik}) $$\nWe are given that $\\text{Var}(Y_{ij}) = \\sigma^2$. The ICC, $\\rho$, is defined as $\\rho = \\text{Corr}(Y_{ij}, Y_{ik})$ for $j \\neq k$. By definition of correlation,\n$$ \\rho = \\frac{\\text{Cov}(Y_{ij}, Y_{ik})}{\\sqrt{\\text{Var}(Y_{ij})\\text{Var}(Y_{ik})}} = \\frac{\\text{Cov}(Y_{ij}, Y_{ik})}{\\sigma^2} $$\nTherefore, the covariance between two distinct individuals in the same cluster is $\\text{Cov}(Y_{ij}, Y_{ik}) = \\rho \\sigma^2$.\nThe sum of variances within a cluster contains $m$ terms, each equal to $\\sigma^2$. The sum of covariances contains $m(m-1)$ terms, each equal to $\\rho \\sigma^2$.\nSubstituting these into the expression for $\\text{Var}(T_i)$:\n$$ \\text{Var}(T_i) = m\\sigma^2 + m(m-1)\\rho \\sigma^2 = m\\sigma^2 [1 + (m-1)\\rho] $$\nSince all clusters are identical in structure, this variance is the same for all $i$. The variance of the grand sum is:\n$$ \\sum_{i=1}^{J} \\text{Var}(T_i) = J \\cdot \\left(m \\sigma^2 [1 + (m-1)\\rho]\\right) $$\nGiven $n=Jm$, this becomes:\n$$ \\text{Var}\\left(\\sum_{i=1}^{J} T_i\\right) = n \\sigma^2 [1 + (m-1)\\rho] $$\nSubstituting this back into the formula for $\\text{Var}(\\bar{Y}_{\\text{cluster}})$:\n$$ \\text{Var}(\\bar{Y}_{\\text{cluster}}) = \\frac{1}{n^2} \\left( n \\sigma^2 [1 + (m-1)\\rho] \\right) = \\frac{\\sigma^2}{n} [1 + (m-1)\\rho] $$\nFor the denominator of the design effect, we consider the variance of the mean from a simple random sample (SRS) of size $n$. In an SRS, all observations are independent, so all covariances are zero.\n$$ \\text{Var}(\\bar{Y}_{\\text{SRS}}) = \\text{Var}\\left(\\frac{1}{n}\\sum_{k=1}^{n} Y_k\\right) = \\frac{1}{n^2} \\sum_{k=1}^{n} \\text{Var}(Y_k) = \\frac{1}{n^2} (n\\sigma^2) = \\frac{\\sigma^2}{n} $$\nThe design effect (DEFF) is the ratio of these two variances:\n$$ \\text{DEFF} = \\frac{\\text{Var}(\\bar{Y}_{\\text{cluster}})}{\\text{Var}(\\bar{Y}_{\\text{SRS}})} = \\frac{\\frac{\\sigma^2}{n} [1 + (m-1)\\rho]}{\\frac{\\sigma^2}{n}} = 1 + (m-1)\\rho $$\nThis is the derived expression for the design effect.\n\n### Numerical Calculation of Design Effect\nUsing the provided values $m=15$ and $\\rho=0.05$:\n$$ \\text{DEFF} = 1 + (15 - 1)(0.05) = 1 + (14)(0.05) = 1 + 0.7 = 1.7 $$\nRounded to four significant figures, the design effect is $1.700$.\n\n### Calculation of Effective Sample Size\nThe effective sample size, $n_{\\text{eff}}$, is the size of an equivalent simple random sample having the same variance of the mean as the clustered sample.\n$$ \\text{Var}(\\bar{Y}_{\\text{SRS with } n_{\\text{eff}}}) = \\text{Var}(\\bar{Y}_{\\text{cluster}}) $$\n$$ \\frac{\\sigma^2}{n_{\\text{eff}}} = \\frac{\\sigma^2}{n} [1 + (m-1)\\rho] = \\frac{\\sigma^2}{n} \\times \\text{DEFF} $$\nSolving for $n_{\\text{eff}}$ yields:\n$$ n_{\\text{eff}} = \\frac{n}{\\text{DEFF}} $$\nSubstituting the values $n=600$ and $\\text{DEFF}=1.7$:\n$$ n_{\\text{eff}} = \\frac{600}{1.7} \\approx 352.941176... $$\nRounding to four significant figures, the effective sample size is $352.9$.",
            "answer": "$$\\boxed{\\begin{pmatrix} 1.700 & 352.9 \\end{pmatrix}}$$"
        },
        {
            "introduction": "With a solid grasp of intraclass correlation () and its consequences as measured by the design effect (), you are now equipped to tackle one of the most crucial tasks in planning a study: sample size determination. This exercise challenges you to derive the formula for the required number of clusters from first principles, integrating concepts of statistical power, effect size, and the variance inflation due to clustering. Mastering this calculation is essential for designing effective and efficient community-level interventions that are adequately powered to detect a meaningful effect.",
            "id": "4513249",
            "problem": "A public health team is planning a parallel, two-arm Cluster Randomized Trial (CRT) to evaluate a community-level preventive intervention. Each community cluster contributes $m$ individuals on average, and the outcome is a continuous measure recorded on a scale where the individual-level variance is $\\sigma^{2}$. Within each cluster, individual outcomes are exchangeable with a common Intracluster Correlation Coefficient (ICC), denoted by $\\rho$, and independence is assumed across clusters. The intervention is expected to shift the arm means by a difference of $\\Delta$ on the measurement scale. The team will use a two-sided test with Type I error rate $\\alpha$ and desired power $1-\\beta$.\n\nStarting from first principles—namely, the variance and covariance rules for sums and averages under exchangeable correlation, and the large-sample normal approximation for the difference in two independent sample means—derive the analytical expression for the minimum number of clusters per arm required to detect the mean difference $\\Delta$ at the specified $(\\alpha, 1-\\beta)$. Then, compute this number for the following design parameters: $\\rho = 0.02$, $m = 40$, $\\sigma^{2} = 100$, $\\Delta = 5$, $\\alpha = 0.05$, and $1-\\beta = 0.80$. Report the smallest integer $k$ that satisfies your derived requirement. No rounding by significant figures is needed; provide the minimum integer that achieves the design targets.",
            "solution": "The problem asks for the minimum number of clusters per arm, $k$, required for a two-arm CRT. The derivation will be based on first principles, as requested.\n\nLet $Y_{ij}$ denote the continuous outcome for the $j$-th individual in the $i$-th cluster, where $i=1, \\dots, k$ for each arm and $j=1, \\dots, m$. We are given the following parameters:\n- The average number of individuals per cluster is $m$.\n- The individual-level variance is $\\text{Var}(Y_{ij}) = \\sigma^2$.\n- The Intracluster Correlation Coefficient (ICC) is $\\rho = \\text{Corr}(Y_{ij}, Y_{il})$ for $j \\neq l$.\n- The expected mean difference between arms is $\\Delta$.\n- The Type I error rate is $\\alpha$ (for a two-sided test).\n- The desired power is $1-\\beta$.\n\n**1. Variance of a Cluster Mean**\n\nFirst, we derive the variance of the mean outcome within a single cluster. The mean for cluster $i$ is $\\bar{Y}_i = \\frac{1}{m} \\sum_{j=1}^m Y_{ij}$.\nThe variance of this mean is:\n$$ \\text{Var}(\\bar{Y}_i) = \\text{Var}\\left(\\frac{1}{m} \\sum_{j=1}^m Y_{ij}\\right) = \\frac{1}{m^2} \\text{Var}\\left(\\sum_{j=1}^m Y_{ij}\\right) $$\nThe variance of the sum of these correlated random variables is the sum of their variances plus the sum of all covariances:\n$$ \\text{Var}\\left(\\sum_{j=1}^m Y_{ij}\\right) = \\sum_{j=1}^m \\text{Var}(Y_{ij}) + \\sum_{j \\neq l} \\text{Cov}(Y_{ij}, Y_{il}) $$\nThere are $m$ variance terms and $m(m-1)$ covariance terms. By definition, the covariance is $\\text{Cov}(Y_{ij}, Y_{il}) = \\rho \\sqrt{\\text{Var}(Y_{ij})\\text{Var}(Y_{il})} = \\rho \\sigma^2$.\nSubstituting this into the equation:\n$$ \\text{Var}\\left(\\sum_{j=1}^m Y_{ij}\\right) = m \\sigma^2 + m(m-1) \\rho \\sigma^2 = m\\sigma^2 [1 + (m-1)\\rho] $$\nTherefore, the variance of the cluster mean, which we denote as $\\sigma_c^2$, is:\n$$ \\sigma_c^2 = \\text{Var}(\\bar{Y}_i) = \\frac{1}{m^2} \\left( m\\sigma^2 [1 + (m-1)\\rho] \\right) = \\frac{\\sigma^2}{m} [1 + (m-1)\\rho] $$\nThe term $[1 + (m-1)\\rho]$ is known as the design effect or variance inflation factor (VIF), which quantifies how much the variance is inflated due to clustering.\n\n**2. Variance of the Difference in Arm Means**\n\nThe trial has two arms, Treatment ($T$) and Control ($C$), each with $k$ clusters. The overall mean for an arm is the average of its $k$ cluster means. For the treatment arm, this is $\\bar{Y}_T = \\frac{1}{k}\\sum_{i=1}^k \\bar{Y}_{iT}$.\nSince clusters are independent, the variance of the arm mean is:\n$$ \\text{Var}(\\bar{Y}_T) = \\text{Var}\\left(\\frac{1}{k}\\sum_{i=1}^k \\bar{Y}_{iT}\\right) = \\frac{1}{k^2} \\sum_{i=1}^k \\text{Var}(\\bar{Y}_{iT}) = \\frac{1}{k^2} (k \\sigma_c^2) = \\frac{\\sigma_c^2}{k} $$\nSimilarly, for the control arm, $\\text{Var}(\\bar{Y}_C) = \\frac{\\sigma_c^2}{k}$.\n\nThe statistic of interest is the difference in the two arm means, $D = \\bar{Y}_T - \\bar{Y}_C$. As the arms are independent, the variance of this difference is the sum of the variances:\n$$ \\text{Var}(D) = \\text{Var}(\\bar{Y}_T) + \\text{Var}(\\bar{Y}_C) = \\frac{\\sigma_c^2}{k} + \\frac{\\sigma_c^2}{k} = \\frac{2\\sigma_c^2}{k} $$\nSubstituting the expression for $\\sigma_c^2$:\n$$ \\text{Var}(D) = \\frac{2}{k} \\left( \\frac{\\sigma^2}{m} [1 + (m-1)\\rho] \\right) = \\frac{2\\sigma^2 [1 + (m-1)\\rho]}{mk} $$\nThe standard error of the difference is $SE(D) = \\sqrt{\\text{Var}(D)}$.\n\n**3. Power Calculation and Sample Size Derivation**\n\nWe use a large-sample normal approximation for the test statistic. The null and alternative hypotheses are:\n$H_0: \\mu_T - \\mu_C = 0$\n$H_A: |\\mu_T - \\mu_C| = \\Delta$\n\nThe test statistic under the null hypothesis is $Z = \\frac{D}{SE(D)}$, which is approximately distributed as a standard normal $N(0,1)$. For a two-sided test with Type I error rate $\\alpha$, we reject $H_0$ if $|Z| > z_{1-\\alpha/2}$, where $z_{q}$ is the $q$-th quantile of the standard normal distribution.\n\nPower ($1-\\beta$) is the probability of rejecting $H_0$ given that the true difference is $\\Delta$. Under $H_A$, the distribution of $D$ is approximately $N(\\Delta, \\text{Var}(D))$. The test statistic $\\frac{D - \\Delta}{SE(D)}$ is approximately $N(0,1)$.\n\nTo achieve power $1-\\beta$, we require:\n$P(\\text{Reject } H_0 | \\mu_T - \\mu_C = \\Delta) \\ge 1-\\beta$.\nThis is primarily driven by the upper tail of the test:\n$P\\left(\\frac{D}{SE(D)} > z_{1-\\alpha/2} \\bigg| \\mu_T - \\mu_C = \\Delta \\right) \\approx 1-\\beta$.\nWe standardize the expression under the alternative hypothesis:\n$$ P\\left(\\frac{D-\\Delta}{SE(D)} > z_{1-\\alpha/2} - \\frac{\\Delta}{SE(D)} \\right) \\approx 1-\\beta $$\nLet $Z' = \\frac{D-\\Delta}{SE(D)} \\sim N(0,1)$. Then $P(Z' > z_{1-\\alpha/2} - \\frac{\\Delta}{SE(D)}) \\approx 1-\\beta$.\nThe quantile function gives $z_{1-(1-\\beta)} = z_{\\beta} \\approx z_{1-\\alpha/2} - \\frac{\\Delta}{SE(D)}$.\nUsing the identity $z_{\\beta} = -z_{1-\\beta}$, we get $-z_{1-\\beta} \\approx z_{1-\\alpha/2} - \\frac{\\Delta}{SE(D)}$, which rearranges to the standard form:\n$$ \\frac{\\Delta}{SE(D)} \\approx z_{1-\\alpha/2} + z_{1-\\beta} $$\nTo ensure the power requirement is met, we use an inequality:\n$$ \\frac{\\Delta}{SE(D)} \\ge z_{1-\\alpha/2} + z_{1-\\beta} $$\nSquaring both sides and substituting $SE(D)^2 = \\text{Var}(D)$:\n$$ \\frac{\\Delta^2}{\\text{Var}(D)} \\ge (z_{1-\\alpha/2} + z_{1-\\beta})^2 $$\n$$ \\frac{\\Delta^2}{\\frac{2\\sigma^2 [1 + (m-1)\\rho]}{mk}} \\ge (z_{1-\\alpha/2} + z_{1-\\beta})^2 $$\n$$ \\frac{mk \\Delta^2}{2\\sigma^2 [1 + (m-1)\\rho]} \\ge (z_{1-\\alpha/2} + z_{1-\\beta})^2 $$\nFinally, we solve for $k$:\n$$ k \\ge \\frac{2\\sigma^2 [1 + (m-1)\\rho]}{m \\Delta^2} (z_{1-\\alpha/2} + z_{1-\\beta})^2 $$\nThis is the required analytical expression for the minimum number of clusters per arm.\n\n**4. Numerical Computation**\n\nWe are given the following parameters:\n- $\\rho = 0.02$\n- $m = 40$\n- $\\sigma^2 = 100$\n- $\\Delta = 5$\n- $\\alpha = 0.05$ (two-sided)\n- Power $1-\\beta = 0.80$\n\nFirst, we find the required quantiles from the standard normal distribution:\n- For $\\alpha=0.05$, $z_{1-\\alpha/2} = z_{1-0.025} = z_{0.975} \\approx 1.9600$.\n- For $1-\\beta=0.80$, $\\beta=0.20$, so $z_{1-\\beta} = z_{0.80} \\approx 0.8416$.\n\nNext, we calculate the design effect (VIF):\n$$ 1 + (m-1)\\rho = 1 + (40-1)(0.02) = 1 + (39)(0.02) = 1 + 0.78 = 1.78 $$\nNow, we substitute all values into the inequality for $k$:\n$$ k \\ge \\frac{2(100) [1.78]}{40 (5)^2} (1.9600 + 0.8416)^2 $$\n$$ k \\ge \\frac{200 \\times 1.78}{40 \\times 25} (2.8016)^2 $$\n$$ k \\ge \\frac{356}{1000} (7.84896256) $$\n$$ k \\ge 0.356 \\times 7.84896256 $$\n$$ k \\ge 2.79426... $$\nSince the number of clusters, $k$, must be an integer, we must take the smallest integer value that satisfies this condition. This is achieved by taking the ceiling of the result.\n$$ k = \\lceil 2.79426... \\rceil = 3 $$\nTherefore, a minimum of $3$ clusters per arm is required.",
            "answer": "$$\\boxed{3}$$"
        }
    ]
}