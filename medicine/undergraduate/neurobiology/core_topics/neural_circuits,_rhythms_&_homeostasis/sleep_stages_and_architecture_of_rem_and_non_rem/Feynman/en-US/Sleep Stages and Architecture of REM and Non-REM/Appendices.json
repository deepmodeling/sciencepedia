{
    "hands_on_practices": [
        {
            "introduction": "Understanding sleep architecture begins with quantifying the time spent in each stage and comparing it to what is considered typical. This foundational practice allows clinicians and researchers to identify potential irregularities in an individual's sleep pattern. In this exercise , you will use the chi-square goodness-of-fit test, a fundamental statistical tool, to determine if a given night of sleep aligns with established normative data for a healthy adult.",
            "id": "5061810",
            "problem": "A laboratory conducts an overnight polysomnography on a healthy $24$-year-old adult. The total sleep time recorded is $400$ minutes, partitioned into the four standard stages that constitute sleep architecture in humans: Non-Rapid Eye Movement (NREM) Stage $N1$, Stage $N2$, Stage $N3$, and Rapid Eye Movement (REM). The observed durations are: $N1 = 30$ minutes, $N2 = 210$ minutes, $N3 = 70$ minutes, and $REM = 90$ minutes.\n\nUse the widely observed normative adult sleep architecture, in which the expected proportions of total sleep time in these stages are $N1 = 0.05$, $N2 = 0.50$, $N3 = 0.20$, and $REM = 0.25$, respectively. Starting from the definition that expected time in each stage equals the expected proportion multiplied by total sleep time, compute the expected minutes in each stage. Then, using a chi-square goodness-of-fit test that compares observed category totals to expected totals under the null hypothesis that this individual follows the normative adult distribution, compute the chi-square test statistic.\n\nAssume that only these four stages exhaust the total sleep time for this calculation, and treat minutes as the counts for the categories.\n\nReport only the value of the chi-square test statistic as your final answer, rounded to three significant figures. Do not report any units with your final answer.",
            "solution": "Sleep architecture in healthy adults is commonly characterized by relatively stable proportions of total sleep time spent in the stages of Non-Rapid Eye Movement (NREM) Stage $N1$, Stage $N2$, Stage $N3$, and Rapid Eye Movement (REM). For this problem, the normative expected proportions are provided as $N1 = 0.05$, $N2 = 0.50$, $N3 = 0.20$, and $REM = 0.25$. The foundational principle we use is that expected category totals under a specified multinomial distribution equal the total count multiplied by each category’s probability. Here, counts are the minutes in each sleep stage, which are additive and exhaustive across categories by construction of total sleep time.\n\nLet the total sleep time be $T = 400$ minutes. Let the expected proportions be $p_{N1} = 0.05$, $p_{N2} = 0.50$, $p_{N3} = 0.20$, and $p_{REM} = 0.25$. Then the expected minutes in each stage are computed by\n$$\nE_{i} = p_{i} \\times T.\n$$\nThus,\n- For $N1$: \n$$\nE_{N1} = 0.05 \\times 400 = 20.\n$$\n- For $N2$: \n$$\nE_{N2} = 0.50 \\times 400 = 200.\n$$\n- For $N3$: \n$$\nE_{N3} = 0.20 \\times 400 = 80.\n$$\n- For $REM$:\n$$\nE_{REM} = 0.25 \\times 400 = 100.\n$$\n\nThe observed minutes are $O_{N1} = 30$, $O_{N2} = 210$, $O_{N3} = 70$, and $O_{REM} = 90$.\n\nTo compare observed to expected under the null hypothesis that the individual’s sleep stage distribution follows the normative adult proportions, we use the chi-square goodness-of-fit statistic, defined for $k$ categories as\n$$\n\\chi^{2} = \\sum_{i=1}^{k} \\frac{\\left(O_{i} - E_{i}\\right)^{2}}{E_{i}},\n$$\nwhere $O_{i}$ and $E_{i}$ are the observed and expected counts for category $i$. Here, $k = 4$.\n\nCompute each contribution:\n- For $N1$:\n$$\n\\frac{\\left(O_{N1} - E_{N1}\\right)^{2}}{E_{N1}} = \\frac{(30 - 20)^{2}}{20} = \\frac{100}{20} = 5.\n$$\n- For $N2$:\n$$\n\\frac{\\left(O_{N2} - E_{N2}\\right)^{2}}{E_{N2}} = \\frac{(210 - 200)^{2}}{200} = \\frac{100}{200} = 0.5.\n$$\n- For $N3$:\n$$\n\\frac{\\left(O_{N3} - E_{N3}\\right)^{2}}{E_{N3}} = \\frac{(70 - 80)^{2}}{80} = \\frac{100}{80} = 1.25.\n$$\n- For $REM$:\n$$\n\\frac{\\left(O_{REM} - E_{REM}\\right)^{2}}{E_{REM}} = \\frac{(90 - 100)^{2}}{100} = \\frac{100}{100} = 1.\n$$\n\nSum the contributions:\n$$\n\\chi^{2} = 5 + 0.5 + 1.25 + 1 = 7.75.\n$$\n\nThis value already has three significant figures. Therefore, the chi-square statistic rounded to three significant figures is $7.75$.",
            "answer": "$$\\boxed{7.75}$$"
        },
        {
            "introduction": "While stage percentages provide a static summary, the true nature of sleep lies in its dynamic flow from one stage to another. We can capture this dynamic behavior using a powerful mathematical framework known as a Markov chain, which models the probabilistic transitions between states. This exercise  challenges you to build a state-transition model from empirical data, justify its properties, and use it to predict the long-term, or stationary, distribution of sleep stages.",
            "id": "5061826",
            "problem": "A single-night hypnogram, sampled in $30$-second epochs over approximately $8$ hours, labels each epoch as one of the five canonical vigilance states $\\{ \\text{Wake (W)}, \\text{N1}, \\text{N2}, \\text{N3}, \\text{Rapid Eye Movement (REM)} \\}$. Consider modeling the epoch-to-epoch dynamics as a first-order, discrete-time Markov chain on the state space $\\mathcal{S} = \\{W, N1, N2, N3, REM\\}$, with transition matrix $P = [P_{ij}]_{i,j \\in \\mathcal{S}}$. From the annotated sequence, the following transition count matrix $C = [C_{ij}]_{i,j \\in \\mathcal{S}}$ is obtained, where $C_{ij}$ is the number of observed transitions from state $i$ to state $j$ between consecutive epochs (states ordered as $W$, $N1$, $N2$, $N3$, $REM$):\n$$\nC \\;=\\;\n\\begin{pmatrix}\n250 & 120 & 20 & 0 & 60 \\\\\n120 & 180 & 140 & 10 & 30 \\\\\n20 & 140 & 600 & 160 & 90 \\\\\n0 & 10 & 160 & 420 & 5 \\\\\n60 & 30 & 90 & 5 & 300\n\\end{pmatrix}.\n$$\nAssume that the Markov property (first order, time-homogeneous), the normalization constraints $\\sum_{j \\in \\mathcal{S}} P_{ij} = 1$ for each $i \\in \\mathcal{S}$, and nonnegativity $P_{ij} \\ge 0$ hold, and that maximum likelihood estimation is used to infer $P$ from $C$.\n\nTasks:\n1) Using the definitions of a discrete-time Markov chain and the principle of maximum likelihood under the above constraints, derive an explicit estimator for the transition probabilities $P_{ij}$ in terms of the counts $C_{ij}$ and appropriate normalizing quantities, and apply it to the provided $C$ to specify the state-transition model.\n2) Based on widely observed features of human sleep architecture (e.g., recurrent ultradian cycling, stage persistence, and adjacency relationships among stages) together with the empirical structure of $C$, justify that the inferred chain is ergodic by establishing irreducibility and aperiodicity.\n3) Using your estimated transition matrix, compute the stationary distribution $\\pi$ satisfying $\\pi = \\pi P$ and $\\sum_{i \\in \\mathcal{S}} \\pi_i = 1$. Report the stationary probability of the Rapid Eye Movement (REM) state, $\\pi_{\\mathrm{REM}}$, as an exact reduced fraction. Your final answer must be a single exact number with no units.",
            "solution": "We model the hypnogram as a first-order, time-homogeneous, discrete-time Markov chain over $\\mathcal{S} = \\{W, N1, N2, N3, REM\\}$ with transition matrix $P = [P_{ij}]$. The data provide transition counts $C_{ij}$ between consecutive epochs. Under the Markov model, the likelihood of the observed transitions factors into a product over transitions leaving each state, and the principle of maximum likelihood under the constraints $\\sum_{j} P_{ij} = 1$ and $P_{ij} \\ge 0$ yields a closed-form estimator.\n\nDerivation of the maximum-likelihood estimator: For a given row (origin state) $i \\in \\mathcal{S}$, the contribution to the likelihood from transitions originating at $i$ is multinomial with parameters $\\{P_{ij}\\}_{j \\in \\mathcal{S}}$ and counts $\\{C_{ij}\\}_{j \\in \\mathcal{S}}$. The log-likelihood for row $i$ is\n$$\n\\ell_i(P_{i\\cdot}) \\;=\\; \\sum_{j \\in \\mathcal{S}} C_{ij} \\ln P_{ij} \\quad \\text{subject to} \\quad \\sum_{j \\in \\mathcal{S}} P_{ij} = 1,\\; P_{ij} \\ge 0.\n$$\nUsing a Lagrange multiplier $\\lambda_i$ for the normalization constraint, the Lagrangian is\n$$\n\\mathcal{L}_i \\;=\\; \\sum_{j} C_{ij} \\ln P_{ij} + \\lambda_i \\left( 1 - \\sum_{j} P_{ij} \\right).\n$$\nSetting partial derivatives to zero gives\n$$\n\\frac{\\partial \\mathcal{L}_i}{\\partial P_{ij}} \\;=\\; \\frac{C_{ij}}{P_{ij}} - \\lambda_i \\;=\\; 0 \\;\\;\\Rightarrow\\;\\; P_{ij} \\;=\\; \\frac{C_{ij}}{\\lambda_i}.\n$$\nEnforcing $\\sum_{j} P_{ij} = 1$ yields\n$$\n\\sum_{j} \\frac{C_{ij}}{\\lambda_i} = 1 \\;\\;\\Rightarrow\\;\\; \\lambda_i \\;=\\; \\sum_{j} C_{ij} \\;\\equiv\\; r_i,\n$$\nwhere $r_i$ is the total number of observed transitions out of state $i$. Hence the maximum-likelihood estimator is\n$$\n\\widehat{P}_{ij} \\;=\\; \\frac{C_{ij}}{r_i}, \\quad \\text{where} \\quad r_i \\;=\\; \\sum_{j \\in \\mathcal{S}} C_{ij}.\n$$\n\nCompute the row sums $r_i$ from the provided $C$ (states ordered as $W, N1, N2, N3, REM$):\n- For $W$: \n$$\nr_{W} \\;=\\; C_{WW} + C_{W,N1} + C_{W,N2} + C_{W,N3} + C_{W,REM} \\;=\\; 250 + 120 + 20 + 0 + 60 \\;=\\; 450.\n$$\n- For $N1$: \n$$\nr_{N1} \\;=\\; 120 + 180 + 140 + 10 + 30 \\;=\\; 480.\n$$\n- For $N2$: \n$$\nr_{N2} \\;=\\; 20 + 140 + 600 + 160 + 90 \\;=\\; 1010.\n$$\n- For $N3$: \n$$\nr_{N3} \\;=\\; 0 + 10 + 160 + 420 + 5 \\;=\\; 595.\n$$\n- For $REM$: \n$$\nr_{REM} \\;=\\; 60 + 30 + 90 + 5 + 300 \\;=\\; 485.\n$$\nThus the estimated transition matrix entries are $\\widehat{P}_{ij} = C_{ij}/r_i$ for each $i,j \\in \\mathcal{S}$. For example, $\\widehat{P}_{W,N1} = 120/450$, $\\widehat{P}_{N2,N3} = 160/1010$, and so on.\n\nErgodicity justification: A discrete-time Markov chain is ergodic if it is irreducible and aperiodic.\n- Irreducibility: The chain is irreducible if every state communicates with every other state. From the counts, there are positive-probability transitions along the biologically plausible adjacency pathways reflecting typical sleep architecture: $W \\leftrightarrow N1$ (with $C_{W,N1} = 120$, $C_{N1,W} = 120$), $N1 \\leftrightarrow N2$ ($140$ each way), $N2 \\leftrightarrow N3$ ($160$ each way), and $N2 \\leftrightarrow REM$ ($90$ each way). There are also $W \\leftrightarrow REM$ transitions ($60$ each way) reflecting brief arousals out of Rapid Eye Movement (REM) sleep. Therefore, from any state, there exists a path of positive-probability transitions to any other state (e.g., $N3 \\to N2 \\to REM$; $REM \\to W \\to N1 \\to N2 \\to N3$), establishing irreducibility.\n- Aperiodicity: A state has period $d \\ge 1$ defined as the greatest common divisor of the lengths of all return times to the state. If $P_{ii} > 0$ for all $i$, then each state has a self-loop, implying the existence of return paths of length $1$, which forces period $1$. Here, $C_{ii} > 0$ for all $i \\in \\{W, N1, N2, N3, REM\\}$, hence $\\widehat{P}_{ii} = C_{ii}/r_i > 0$, so the chain is aperiodic. Therefore, the chain is ergodic.\n\nStationary distribution and $\\pi_{\\mathrm{REM}}$: The stationary distribution $\\pi$ satisfies $\\pi = \\pi \\widehat{P}$ and $\\sum_{i} \\pi_i = 1$. Observe that the off-diagonal counts are symmetric, i.e., $C_{ij} = C_{ji}$ for $i \\ne j$. Define $r_i = \\sum_{j} C_{ij}$ as above and consider the candidate distribution\n$$\n\\pi_i \\;=\\; \\frac{r_i}{\\sum_{k \\in \\mathcal{S}} r_k}.\n$$\nWe verify detailed balance:\n$$\n\\pi_i \\widehat{P}_{ij} \\;=\\; \\frac{r_i}{\\sum_{k} r_k} \\cdot \\frac{C_{ij}}{r_i} \\;=\\; \\frac{C_{ij}}{\\sum_{k} r_k}, \\qquad\n\\pi_j \\widehat{P}_{ji} \\;=\\; \\frac{r_j}{\\sum_{k} r_k} \\cdot \\frac{C_{ji}}{r_j} \\;=\\; \\frac{C_{ji}}{\\sum_{k} r_k}.\n$$\nSince $C_{ij} = C_{ji}$ for $i \\ne j$, detailed balance holds, so $\\pi$ is a stationary distribution. Because the chain is irreducible and aperiodic, the stationary distribution is unique, hence this $\\pi$ is the stationary distribution.\n\nCompute the normalization:\n$$\n\\sum_{k \\in \\mathcal{S}} r_k \\;=\\; r_W + r_{N1} + r_{N2} + r_{N3} + r_{REM} \\;=\\; 450 + 480 + 1010 + 595 + 485 \\;=\\; 3020.\n$$\nTherefore,\n$$\n\\pi_{\\mathrm{REM}} \\;=\\; \\frac{r_{REM}}{\\sum_{k} r_k} \\;=\\; \\frac{485}{3020} \\;=\\; \\frac{97}{604},\n$$\nwhere the fraction is reduced by dividing numerator and denominator by $5$. This gives the exact stationary probability of Rapid Eye Movement (REM) sleep under the estimated model.",
            "answer": "$$\\boxed{\\frac{97}{604}}$$"
        },
        {
            "introduction": "Sleep stages are not abstract labels; they are defined by distinct patterns in the brain's electrical activity recorded via electroencephalogram (EEG). One of the hallmark features of N2 sleep is the 'sleep spindle,' a brief burst of activity in the sigma frequency band. This advanced practice  moves from the macro-level hypnogram to the micro-level of raw signals, guiding you through the implementation of a computational algorithm to automatically detect these critical neurophysiological events.",
            "id": "5061816",
            "problem": "Implement an automatic sleep spindle detector based on amplitude envelopes derived from the Hilbert transform in the sigma band and evaluate event-level precision, recall, and F1-score on a labeled dataset synthesized according to first-principles signal processing definitions. The detector must operate on one-dimensional electroencephalogram-like time series and follow the definitions below. Your program must contain no user input and must print a single line: a comma-separated Python-like list containing the metrics for each test case flattened in order, rounded to three decimals, as specified under Final Output Format.\n\nDetector and evaluation must be derived from the following fundamental base, which you must implement exactly:\n\n1) Band-pass filtering and analytic signal for amplitude envelopes:\n- Let the discrete-time signal be $x[n]$ sampled at $f_s$ samples per second (hertz). Apply a zero-phase causal-invariant band-pass filter with passband $[f_1,f_2]$ hertz to obtain $x_b[n]$. Zero-phase can be implemented by forward-backward filtering of a time-invariant filter so that the net phase is approximately $0$.\n- Compute the analytic signal $z[n]$ of $x_b[n]$ using the Hilbert transform to obtain the complex-valued signal $z[n] = x_b[n] + j \\, \\mathcal{H}\\{x_b[n]\\}$, where $\\mathcal{H}\\{\\cdot\\}$ denotes the Hilbert transform and $j^2 = -1$.\n- The amplitude envelope is $a[n] = |z[n]|$.\n\n2) Data-adaptive hysteresis thresholds on the envelope:\n- Let $\\mu$ be the mean of $a[n]$ over the entire time series and let $\\sigma$ be its standard deviation. Given parameters $\\alpha$ and $\\beta$ with $0 < \\alpha < \\beta$, define the low threshold $T_{\\mathrm{low}} = \\mu + \\alpha \\sigma$ and the high threshold $T_{\\mathrm{high}} = \\mu + \\beta \\sigma$.\n- Define two Boolean sequences: $L[n]$ indicating $a[n] \\ge T_{\\mathrm{low}}$ and $H[n]$ indicating $a[n] \\ge T_{\\mathrm{high}}$.\n- A candidate event starts at any index $n_s$ where $H[n]$ transitions from false to true. Its provisional end $n_e$ is the first index after $n_s$ where $L[n]$ transitions from true to false. If such an $n_e$ does not exist before the signal ends at index $N-1$, set $n_e = N-1$.\n\n3) Duration constraints and merging:\n- Convert indices to times via $t = n / f_s$. Keep only events whose durations $d = (n_e - n_s + 1)/f_s$ satisfy $d_{\\min} \\le d \\le d_{\\max}$ for given $d_{\\min}$ and $d_{\\max}$ in seconds.\n- Merge any two consecutive events whose gap $g$ (in seconds) between the end of the first and the start of the second is $\\le \\Delta$ by replacing them with a single event from the start of the first to the end of the second. After merging, discard any event with duration $d > d_{\\max}$, and keep all with $d_{\\min} \\le d \\le d_{\\max}$.\n\n4) Event-level evaluation with intersection-over-union:\n- A ground-truth event is a closed time interval $G = [t_s, t_e]$ and a detected event is $D = [\\hat{t}_s, \\hat{t}_e]$. Define the intersection-over-union (IoU) as $\\mathrm{IoU}(D,G) = \\frac{|D \\cap G|}{|D \\cup G|}$, where $|\\cdot|$ denotes interval length in seconds.\n- Given an IoU threshold $\\theta$, perform greedy one-to-one matching as follows: iterate over detected events in any fixed order; for each detected event $D$, find the unmatched ground-truth event $G$ that maximizes $\\mathrm{IoU}(D,G)$; if the maximum is $\\ge \\theta$, mark both as matched (a true positive), otherwise mark $D$ as a false positive. After processing all detected events, any unmatched ground-truth events are false negatives.\n- Let $\\mathrm{TP}$ be the count of matched pairs, $\\mathrm{FP}$ the count of unmatched detected events, and $\\mathrm{FN}$ the count of unmatched ground-truth events. Define precision $P = \\frac{\\mathrm{TP}}{\\mathrm{TP}+\\mathrm{FP}}$ and recall $R = \\frac{\\mathrm{TP}}{\\mathrm{TP}+\\mathrm{FN}}$. If a denominator is $0$, define the corresponding ratio to be $1$. Define the F1-score $F_1 = \\frac{2PR}{P+R}$, and if $P+R=0$ define $F_1 = 0$.\n\nSignal synthesis for the labeled dataset:\n- For each test case, synthesize a signal of duration $T$ seconds at sampling rate $f_s$ as:\n  - A zero-mean Gaussian white noise background with standard deviation $s$.\n  - A set of labeled spindle events. Each spindle is a narrowband amplitude-modulated sinusoid with center frequency $f_c$ hertz, peak amplitude $A$, and Gaussian amplitude envelope $g(t) = \\exp\\!\\big(-\\frac{(t - t_0)^2}{2 \\sigma_g^2}\\big)$ with $t_0 = t_{\\mathrm{start}} + d/2$ and $\\sigma_g = d/6$, where $d$ is the specified event duration in seconds. The spindle contribution is $x_{\\mathrm{sp}}(t) = A \\, g(t) \\, \\sin(2 \\pi f_c t)$, added to the background. The labeled ground-truth interval for this spindle is $[t_{\\mathrm{start}}, \\, t_{\\mathrm{start}} + d]$.\n  - A set of unlabeled interfering bursts constructed identically but not counted as ground truth.\n- All randomness must be from a fixed-point seed $r$ per test for reproducibility of the Gaussian noise.\n- The passband for envelope computation is the sigma band $[f_1,f_2] = [11,16]$ hertz. Use a stable linear-time-invariant filter with zero-phase implementation.\n\nParameters and test suite:\n- Use the following detector parameters for all tests: $f_1 = 11$, $f_2 = 16$, $\\alpha = 1.0$, $\\beta = 2.0$, $d_{\\min} = 0.4$ seconds, $d_{\\max} = 2.0$ seconds, $\\Delta = 0.25$ seconds, $\\theta = 0.3$.\n- Use the following three test cases, each defined as $(f_s, T, r, s, \\text{spindles}, \\text{interference})$ where each event list contains tuples $(t_{\\mathrm{start}}, d, f_c, A)$; all times are in seconds and frequencies in hertz:\n  - Test $1$: $(200, \\, 20, \\, 123, \\, 1.0, \\, [(5.0, \\, 0.8, \\, 13.5, \\, 12.0), \\, (12.0, \\, 0.7, \\, 12.5, \\, 10.0)], \\, [])$.\n  - Test $2$: $(200, \\, 20, \\, 456, \\, 1.0, \\, [(0.1, \\, 0.6, \\, 13.0, \\, 11.0), \\, (19.3, \\, 0.6, \\, 14.0, \\, 11.0)], \\, [(9.0, \\, 1.0, \\, 16.0, \\, 8.0), \\, (6.0, \\, 0.4, \\, 10.0, \\, 8.0)])$.\n  - Test $3$: $(200, \\, 20, \\, 789, \\, 1.2, \\, [], \\, [(10.0, \\, 1.0, \\, 20.0, \\, 10.0)])$.\n\nAngle units: none are required. Physical units: all outputs are dimensionless. Time must be represented in seconds.\n\nFinal Output Format:\n- For each test case, compute precision $P$, recall $R$, and F1-score $F_1$, each rounded to three decimals. Aggregate the results for all tests into a single Python-like list as $[P_1, R_1, F_{1,1}, P_2, R_2, F_{1,2}, P_3, R_3, F_{1,3}]$ and print exactly this single line with no additional text.",
            "solution": "The solution involves a multi-stage computational pipeline. First, test signals are synthesized according to the problem specifications. Second, the spindle detection algorithm is applied to these signals. Finally, the detector's output is evaluated against the known ground-truth events. Below is a conceptual overview of the implementation provided in the answer.\n\n### Part 1: Signal Synthesis\n\nFor each test case, a one-dimensional time-series signal is created. The process starts with a background of zero-mean Gaussian white noise. Then, the specified sleep spindles and interfering bursts are added. Each of these events is modeled as an amplitude-modulated sinusoid:\n$$x_{\\mathrm{event}}(t) = A \\cdot g(t) \\cdot \\sin(2 \\pi f_c t)$$\nThe amplitude is modulated by a Gaussian envelope $g(t)$ centered within the event's duration:\n$$g(t) = \\exp\\!\\left(-\\frac{(t - t_0)^2}{2 \\sigma_g^2}\\right)$$\nwhere $t_0$ is the event's center time and $\\sigma_g$ controls its width. The time intervals for the specified spindle events constitute the ground-truth dataset for evaluation. Using a fixed random seed for each test case ensures that the noise is reproducible.\n\n### Part 2: Spindle Detection Algorithm\n\nThe detection algorithm processes the synthesized signal $x[n]$ through several steps:\n\n**2.1. Band-Pass Filtering and Envelope Extraction**\nThe signal is first filtered using a zero-phase digital filter to isolate the sigma band ($11-16$ Hz), producing $x_b[n]$. The analytic signal $z[n]$ of $x_b[n]$ is then computed using the Hilbert transform:\n$$z[n] = x_b[n] + j \\cdot \\mathcal{H}\\{x_b[n]\\}$$\nThe instantaneous amplitude envelope, $a[n]$, is the magnitude of this complex signal: $a[n] = |z[n]|$.\n\n**2.2. Data-Adaptive Hysteresis Thresholding**\nTwo thresholds are computed from the mean ($\\mu$) and standard deviation ($\\sigma$) of the envelope $a[n]$:\n- Low threshold: $T_{\\mathrm{low}} = \\mu + \\alpha \\sigma$\n- High threshold: $T_{\\mathrm{high}} = \\mu + \\beta \\sigma$\nCandidate events are identified where the envelope crosses the high threshold and remain active until it drops below the low threshold. This two-threshold approach prevents noise from prematurely terminating an event.\n\n**2.3. Duration Constraints and Merging**\nThe raw detected events are refined. First, events that are too short or too long (outside the $[d_{\\min}, d_{\\max}]$ range) are discarded. Then, any remaining events that are very close together (gap $\\le \\Delta$) are merged into a single, longer event. Finally, this merged list is filtered again by duration to ensure all final detected events meet the criteria.\n\n### Part 3: Performance Evaluation\n\nThe final set of detected events is compared to the ground-truth events using the Intersection-over-Union (IoU) metric. A greedy matching algorithm pairs each detected event to the best-matching ground-truth event. If the IoU for a pair is above the threshold $\\theta$, it is counted as a True Positive (TP). Detected events that cannot be matched are False Positives (FP), and ground-truth events that are missed are False Negatives (FN).\n\nFrom these counts, precision ($P = \\frac{\\mathrm{TP}}{\\mathrm{TP}+\\mathrm{FP}}$), recall ($R = \\frac{\\mathrm{TP}}{\\mathrm{TP}+\\mathrm{FN}}$), and the F1-score ($F_1 = \\frac{2PR}{P+R}$) are calculated to quantify the detector's performance.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy import signal\n\ndef synthesize_signal(fs, T, r, s, spindles_params, interference_params):\n    \"\"\"\n    Synthesizes a signal with a noise background, spindles, and interference.\n    \"\"\"\n    np.random.seed(r)\n    N = int(T * fs)\n    t = np.arange(N) / fs\n    \n    # Generate Gaussian white noise background\n    x = np.random.normal(loc=0.0, scale=s, size=N)\n    \n    ground_truth_events = []\n    \n    # Add spindle events\n    for t_start, d, f_c, A in spindles_params:\n        t0 = t_start + d / 2\n        sigma_g = d / 6\n        g_t = np.exp(-((t - t0)**2) / (2 * sigma_g**2))\n        x_sp = A * g_t * np.sin(2 * np.pi * f_c * t)\n        x += x_sp\n        ground_truth_events.append([t_start, t_start + d])\n        \n    # Add interference events\n    for t_start, d, f_c, A in interference_params:\n        t0 = t_start + d / 2\n        sigma_g = d / 6\n        g_t = np.exp(-((t - t0)**2) / (2 * sigma_g**2))\n        x_interf = A * g_t * np.sin(2 * np.pi * f_c * t)\n        x += x_interf\n        \n    return x, ground_truth_events\n\ndef detect_spindles(x, fs, f1, f2, alpha, beta, d_min, d_max, Delta_merge):\n    \"\"\"\n    Detects sleep spindles in a time series using the specified algorithm.\n    \"\"\"\n    N = len(x)\n\n    # 1. Band-pass filtering and analytic signal for amplitude envelope\n    sos = signal.butter(5, [f1, f2], btype='bandpass', fs=fs, output='sos')\n    x_b = signal.sosfiltfilt(sos, x)\n    analytic_signal = signal.hilbert(x_b)\n    a = np.abs(analytic_signal)\n\n    # 2. Data-adaptive hysteresis thresholds\n    mu = np.mean(a)\n    sigma = np.std(a)\n    T_low = mu + alpha * sigma\n    T_high = mu + beta * sigma\n    \n    L = a >= T_low\n    H = a >= T_high\n\n    # Find candidate event starts\n    H_diff = np.diff(H.astype(int), prepend=0)\n    start_indices = np.where(H_diff == 1)[0]\n    \n    raw_events = []\n    for n_s in start_indices:\n        # Find provisional end n_e\n        search_area = L[n_s + 1:]\n        false_indices_relative = np.where(search_area == False)[0]\n        \n        if len(false_indices_relative) > 0:\n            n_e = n_s + 1 + false_indices_relative[0]\n        else:\n            n_e = N - 1\n        \n        raw_events.append((n_s, n_e))\n\n    if not raw_events:\n        return []\n\n    # 3. Duration constraints and merging\n    # First duration filter\n    events_after_dur_filt = []\n    for n_s, n_e in raw_events:\n        duration = (n_e - n_s + 1) / fs\n        if d_min <= duration <= d_max:\n            # Convert to time, interval is [start_time, end_time)\n            events_after_dur_filt.append([n_s / fs, (n_e + 1) / fs])\n\n    if not events_after_dur_filt:\n        return []\n\n    events_after_dur_filt.sort(key=lambda x: x[0])\n\n    # Merging\n    merged_events = []\n    if events_after_dur_filt:\n        current_start, current_end = events_after_dur_filt[0]\n        for next_start, next_end in events_after_dur_filt[1:]:\n            gap = next_start - current_end\n            if gap <= Delta_merge:\n                current_end = max(current_end, next_end)\n            else:\n                merged_events.append([current_start, current_end])\n                current_start, current_end = next_start, next_end\n        merged_events.append([current_start, current_end])\n    \n    # Final duration filter\n    final_events = []\n    for start, end in merged_events:\n        duration = end - start\n        if d_min <= duration <= d_max:\n            final_events.append([start, end])\n            \n    return final_events\n\ndef evaluate_detection(detected_events, ground_truth_events, theta):\n    \"\"\"\n    Evaluates detection performance using IoU and greedy matching.\n    \"\"\"\n    def iou(d, g):\n        inter_start = max(d[0], g[0])\n        inter_end = min(d[1], g[1])\n        inter_len = max(0, inter_end - inter_start)\n        \n        if inter_len == 0:\n            return 0.0\n            \n        union_len = (d[1] - d[0]) + (g[1] - g[0]) - inter_len\n        return inter_len / union_len if union_len > 0 else 0.0\n\n    num_det = len(detected_events)\n    num_gt = len(ground_truth_events)\n    \n    gt_matched = [False] * num_gt\n    tp = 0\n    \n    detected_events.sort(key=lambda x: x[0])\n    \n    for d_event in detected_events:\n        best_iou = -1.0\n        best_gt_idx = -1\n        for j, g_event in enumerate(ground_truth_events):\n            if not gt_matched[j]:\n                current_iou = iou(d_event, g_event)\n                if current_iou > best_iou:\n                    best_iou = current_iou\n                    best_gt_idx = j\n        \n        if best_iou >= theta:\n            tp += 1\n            if best_gt_idx != -1:\n                gt_matched[best_gt_idx] = True\n\n    fp = num_det - tp\n    fn = num_gt - tp\n\n    # Calculate metrics with zero-denominator handling\n    precision = tp / (tp + fp) if (tp + fp) > 0 else 1.0\n    recall = tp / (tp + fn) if (tp + fn) > 0 else 1.0\n    \n    if (precision + recall) == 0:\n        f1 = 0.0\n    else:\n        f1 = 2 * (precision * recall) / (precision + recall)\n        \n    return precision, recall, f1\n\ndef solve():\n    \"\"\"\n    Main function to run test cases and print results.\n    \"\"\"\n    # Detector parameters (constant for all tests)\n    detector_params = {\n        'f1': 11, 'f2': 16,\n        'alpha': 1.0, 'beta': 2.0,\n        'd_min': 0.4, 'd_max': 2.0,\n        'Delta_merge': 0.25\n    }\n    eval_theta = 0.3\n\n    # Define the test cases\n    test_cases = [\n        {'fs': 200, 'T': 20, 'r': 123, 's': 1.0, \n         'spindles': [(5.0, 0.8, 13.5, 12.0), (12.0, 0.7, 12.5, 10.0)], \n         'interference': []},\n        {'fs': 200, 'T': 20, 'r': 456, 's': 1.0, \n         'spindles': [(0.1, 0.6, 13.0, 11.0), (19.3, 0.6, 14.0, 11.0)], \n         'interference': [(9.0, 1.0, 16.0, 8.0), (6.0, 0.4, 10.0, 8.0)]},\n        {'fs': 200, 'T': 20, 'r': 789, 's': 1.2, \n         'spindles': [], \n         'interference': [(10.0, 1.0, 20.0, 10.0)]}\n    ]\n\n    results = []\n    for case in test_cases:\n        # Synthesize signal and get ground truth\n        signal_data, gt_events = synthesize_signal(\n            case['fs'], case['T'], case['r'], case['s'], \n            case['spindles'], case['interference']\n        )\n        \n        # Run detection\n        detected_events = detect_spindles(\n            signal_data, case['fs'], **detector_params\n        )\n        \n        # Evaluate performance\n        p, r, f1 = evaluate_detection(detected_events, gt_events, eval_theta)\n        \n        results.extend([p, r, f1])\n\n    # Format and print the final output\n    formatted_results = [f\"{x:.3f}\" for x in results]\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```"
        }
    ]
}