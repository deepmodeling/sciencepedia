{
    "hands_on_practices": [
        {
            "introduction": "A core function of attention is to help us better distinguish between different objects in a cluttered scene. To understand how this works at a neural level, we need to quantify this improvement for a single neuron. Signal Detection Theory (SDT) provides a powerful framework for this, using the discriminability index $d'$ to measure how well an observer—or a neuron—can differentiate two signals. This exercise  demonstrates how common models of attention, which propose changes to a neuron's firing rate mean and variance, directly translate into an enhanced ability to discriminate between stimuli, providing a concrete link between neural modulation and perceptual improvement.",
            "id": "5039177",
            "problem": "A cortical neuron in visual area responds to two stimulus classes (a preferred stimulus and a non-preferred stimulus) with spike counts measured over a fixed observation window. Empirically, for this neuron and window, spike-count variability is well approximated by equal-variance Gaussian statistics for the two classes. Under this approximation, the discriminability index used in Signal Detection Theory (SDT) for two classes is defined in terms of the separation of their mean spike counts and their common standard deviation. Attention is hypothesized to modulate neural responses multiplicatively by increasing mean spike rates and decreasing variability. Specifically, assume that attention scales both class means by a factor of $(1+g)$ with $g=0.20$, and scales the common variance by a factor of $(1-v)$ with $v=0.15$. Under these assumptions and the equal-variance Gaussian model, derive from first principles how the discriminability index scales with these multiplicative changes. Then compute the multiplicative change factor in the discriminability index, $R$, defined as $R=d'_{\\mathrm{att}}/d'_{\\mathrm{base}}$, when $g=0.20$ and $v=0.15$. Express the final quantity as a dimensionless number rounded to four significant figures.",
            "solution": "The problem statement is evaluated as valid. It is scientifically grounded in the application of Signal Detection Theory (SDT) to a well-established model of attentional modulation in neuroscience. The problem is well-posed, with all necessary parameters and definitions provided for a unique solution. The language is objective and precise.\n\nWe are asked to derive the scaling of the discriminability index, $d'$, under attentional modulation and compute the resulting multiplicative change factor. The discriminability index for two responses drawn from Gaussian distributions with means $\\mu_1$ and $\\mu_2$ and a common standard deviation $\\sigma$ is defined as:\n$$\nd' = \\frac{|\\mu_1 - \\mu_2|}{\\sigma}\n$$\nIn this context, the two responses are the spike counts for a preferred and a non-preferred stimulus. Let $\\mu_p$ and $\\mu_n$ be the mean spike counts for the preferred and non-preferred stimuli, respectively. Without loss of generality, we assume $\\mu_p > \\mu_n$.\n\nFirst, we define the discriminability for the baseline (unattended) condition, denoted as $d'_{\\mathrm{base}}$. Let the baseline means be $\\mu_{p, \\mathrm{base}}$ and $\\mu_{n, \\mathrm{base}}$, and the common baseline variance be $\\sigma_{\\mathrm{base}}^2$. The baseline standard deviation is therefore $\\sigma_{\\mathrm{base}} = \\sqrt{\\sigma_{\\mathrm{base}}^2}$.\n$$\nd'_{\\mathrm{base}} = \\frac{\\mu_{p, \\mathrm{base}} - \\mu_{n, \\mathrm{base}}}{\\sigma_{\\mathrm{base}}}\n$$\n\nNext, we consider the attended condition. According to the problem, attention introduces multiplicative scaling. The means are scaled by a factor of $(1+g)$, and the variance is scaled by a factor of $(1-v)$. Let the parameters in the attended condition be denoted with the subscript 'att'.\n\nThe new means are given by:\n$$\n\\mu_{p, \\mathrm{att}} = \\mu_{p, \\mathrm{base}}(1+g)\n$$\n$$\n\\mu_{n, \\mathrm{att}} = \\mu_{n, \\mathrm{base}}(1+g)\n$$\nThe new variance is:\n$$\n\\sigma_{\\mathrm{att}}^2 = \\sigma_{\\mathrm{base}}^2(1-v)\n$$\nThe new standard deviation is the square root of the new variance:\n$$\n\\sigma_{\\mathrm{att}} = \\sqrt{\\sigma_{\\mathrm{base}}^2(1-v)} = \\sigma_{\\mathrm{base}}\\sqrt{1-v}\n$$\n\nNow we can write the expression for the discriminability index under attention, $d'_{\\mathrm{att}}$:\n$$\nd'_{\\mathrm{att}} = \\frac{\\mu_{p, \\mathrm{att}} - \\mu_{n, \\mathrm{att}}}{\\sigma_{\\mathrm{att}}}\n$$\nSubstituting the expressions for the attended parameters into this equation yields:\n$$\nd'_{\\mathrm{att}} = \\frac{\\mu_{p, \\mathrm{base}}(1+g) - \\mu_{n, \\mathrm{base}}(1+g)}{\\sigma_{\\mathrm{base}}\\sqrt{1-v}}\n$$\nWe can factor out $(1+g)$ from the numerator:\n$$\nd'_{\\mathrm{att}} = \\frac{(\\mu_{p, \\mathrm{base}} - \\mu_{n, \\mathrm{base}})(1+g)}{\\sigma_{\\mathrm{base}}\\sqrt{1-v}}\n$$\nTo reveal the scaling relationship, we can rearrange the terms to isolate the expression for $d'_{\\mathrm{base}}$:\n$$\nd'_{\\mathrm{att}} = \\left(\\frac{\\mu_{p, \\mathrm{base}} - \\mu_{n, \\mathrm{base}}}{\\sigma_{\\mathrm{base}}}\\right) \\cdot \\frac{1+g}{\\sqrt{1-v}}\n$$\nBy substituting the definition of $d'_{\\mathrm{base}}$, we derive the scaling law:\n$$\nd'_{\\mathrm{att}} = d'_{\\mathrm{base}} \\cdot \\frac{1+g}{\\sqrt{1-v}}\n$$\nThis equation represents the scaling of the discriminability index due to the multiplicative attentional modulation.\n\nThe problem requires us to compute the multiplicative change factor, $R$, defined as $R = d'_{\\mathrm{att}} / d'_{\\mathrm{base}}$. From the derived relationship, we find:\n$$\nR = \\frac{d'_{\\mathrm{att}}}{d'_{\\mathrm{base}}} = \\frac{1+g}{\\sqrt{1-v}}\n$$\nThe problem provides the specific values for the modulation parameters: $g=0.20$ and $v=0.15$. We substitute these values into the expression for $R$:\n$$\nR = \\frac{1+0.20}{\\sqrt{1-0.15}} = \\frac{1.20}{\\sqrt{0.85}}\n$$\nNow, we compute the numerical value:\n$$\nR \\approx \\frac{1.20}{0.9219544457} \\approx 1.30158098\n$$\nThe problem specifies that the final answer should be rounded to four significant figures. The first four significant figures are $1$, $3$, $0$, and $1$. The fifth digit is $5$, so we round up the fourth digit.\n$$\nR \\approx 1.302\n$$",
            "answer": "$$\\boxed{1.302}$$"
        },
        {
            "introduction": "Attention doesn't just enhance the representation of a target stimulus in isolation; it also shapes the processing of other, competing stimuli. The \"biased competition\" model of attention posits that attention biases the ongoing competition between stimuli for neural representation. This exercise explores divisive normalization, a canonical neural computation that provides a powerful mechanistic basis for this competition, wherein neurons mutually suppress one another through a shared normalization pool. By working through the calculations for a simplified two-neuron circuit , you will see precisely how directing attention to one stimulus not only boosts its corresponding neural response but also actively suppresses the response to an unattended competitor.",
            "id": "5039176",
            "problem": "In cortical circuits underlying selective attention, a well-supported computational description is divisive normalization, in which the response of a neuron selective for stimulus $i$ results from a balance between an excitatory drive and a pooled suppressive drive. Consider a minimal two-stimulus normalization circuit consistent with evidence from visual cortex and parietal areas: each neuron receives an excitatory input proportional to the stimulus drive and attentional gain, and a suppressive input from an inhibitory normalization pool that sums the attention-modulated drives of all stimuli through positive weights. A nonzero baseline term captures background activity and prevents division by zero. Formally, let the excitatory drive be $E_{i} = g_{i} s_{i}$, the normalization pool be $N_{i} = \\sum_{j} w_{ij} g_{j} s_{j}$ with $w_{ij} \\geq 0$, and the instantaneous firing rate be\n$$\nr_{i} = \\frac{E_{i}}{\\sigma + N_{i}}.\n$$\nYou are given two stimuli with drives $s_{1} = 10$ and $s_{2} = 8$, uniform normalization weights $w_{ij} = 1$, baseline $\\sigma = 2$, and an attentional gain targeting stimulus $1$ of $g_{1} = 1.4$. Assume the unattended stimulus has $g_{2} = 1$. \n\nStarting from the above definitions and the divisive normalization framework, derive expressions for $r_{1}$ and $r_{2}$ and compute their numerical values. Then, briefly interpret the competitive suppression experienced by the unattended stimulus in terms of the normalization pool and baseline. The final answer must consist of the pair $(r_{1}, r_{2})$ expressed as exact values without rounding, and you must not include units.",
            "solution": "The problem statement is assessed to be valid. It is scientifically grounded in the established divisive normalization model from computational neuroscience, is mathematically well-posed with all necessary parameters provided, and is expressed in objective, formal language. There are no contradictions, ambiguities, or factual unsoundness.\n\nThe instantaneous firing rate, $r_{i}$, of a neuron selective for stimulus $i$ is given by the divisive normalization equation:\n$$\nr_{i} = \\frac{E_{i}}{\\sigma + N_{i}}\n$$\nwhere $E_{i}$ is the excitatory drive, $N_{i}$ is the divisive normalization pool, and $\\sigma$ is a baseline term.\n\nThe excitatory drive for neuron $i$ is defined as $E_{i} = g_{i} s_{i}$, where $g_{i}$ is the attentional gain and $s_{i}$ is the stimulus drive.\nThe normalization pool for neuron $i$ is defined as $N_{i} = \\sum_{j} w_{ij} g_{j} s_{j}$, which sums the weighted, attention-modulated drives of all stimuli in the receptive field.\n\nWe are given a two-stimulus scenario ($i, j \\in \\{1, 2\\}$) with the following parameters:\n- Stimulus drives: $s_{1} = 10$, $s_{2} = 8$\n- Attentional gains: $g_{1} = 1.4$ (attended), $g_{2} = 1$ (unattended)\n- Normalization weights: $w_{ij} = 1$ for all $i, j$.\n- Baseline term: $\\sigma = 2$\n\nFirst, we derive the specific expressions for the excitatory drives, $E_{1}$ and $E_{2}$.\nUsing $E_{i} = g_{i} s_{i}$:\n$$\nE_{1} = g_{1} s_{1} = (1.4)(10) = 14\n$$\n$$\nE_{2} = g_{2} s_{2} = (1)(8) = 8\n$$\n\nNext, we derive the expression for the normalization pool. The problem states uniform weights $w_{ij}=1$. This implies that the normalization pool is identical for both neurons, i.e., $N_{1} = N_{2}$. Let us denote this common normalization pool by $N$.\n$$\nN = N_{1} = \\sum_{j=1}^{2} w_{1j} g_{j} s_{j} = w_{11} g_{1} s_{1} + w_{12} g_{2} s_{2}\n$$\n$$\nN = N_{2} = \\sum_{j=1}^{2} w_{2j} g_{j} s_{j} = w_{21} g_{1} s_{1} + w_{22} g_{2} s_{2}\n$$\nSubstituting $w_{ij} = 1$ for all $i,j$:\n$$\nN = (1) g_{1} s_{1} + (1) g_{2} s_{2} = g_{1} s_{1} + g_{2} s_{2}\n$$\nNow, we compute the numerical value of the normalization pool $N$:\n$$\nN = (1.4)(10) + (1)(8) = 14 + 8 = 22\n$$\n\nWith these components, we can compute the firing rates $r_{1}$ and $r_{2}$.\nFor neuron $1$ (attended):\n$$\nr_{1} = \\frac{E_{1}}{\\sigma + N} = \\frac{14}{2 + 22} = \\frac{14}{24} = \\frac{7}{12}\n$$\nFor neuron $2$ (unattended):\n$$\nr_{2} = \\frac{E_{2}}{\\sigma + N} = \\frac{8}{2 + 22} = \\frac{8}{24} = \\frac{1}{3}\n$$\n\nThe numerical values for the firing rates are $r_{1} = 7/12$ and $r_{2} = 1/3$.\n\nInterpretation of competitive suppression:\nThe response of the unattended neuron (neuron $2$) is given by $r_{2} = \\frac{E_{2}}{\\sigma + N} = \\frac{g_{2}s_{2}}{\\sigma + g_{1}s_{1} + g_{2}s_{2}}$. The denominator represents the total suppressive drive. It is composed of a constant baseline suppression $\\sigma$ and the stimulus-driven normalization pool $N = g_{1}s_{1} + g_{2}s_{2}$. Critically, the normalization pool sums the attention-modulated drives from *all* stimuli. When attention is directed to stimulus $1$, its gain $g_{1}$ is increased ($g_{1}=1.4$). This boosts the contribution of stimulus $1$ to the shared normalization pool ($g_{1}s_{1} = 14$). This larger pool value, $N=22$, divisively suppresses the responses of *all* neurons, including neuron $2$. Therefore, the enhanced excitatory drive of the attended stimulus leads to stronger suppression of the competing, unattended stimulus. This is the mechanism of competitive suppression within the divisive normalization framework. The baseline term $\\sigma$ adds a constant, non-stimulus-specific inhibition, ensuring the denominator is always greater than zero and setting a floor for the total suppressive effect.",
            "answer": "$$\n\\boxed{\\begin{pmatrix} \\frac{7}{12} & \\frac{1}{3} \\end{pmatrix}}\n$$"
        },
        {
            "introduction": "The brain represents information not through the activity of single neurons, but across the coordinated activity of large neural populations. Beyond changing the firing rates of individual neurons, attention also systematically alters how their trial-to-trial variabilities are related. The performance of a neural population code is limited not just by the noise of individual neurons, but also by the correlations in that noise across the population. This final practice problem  allows you to quantify the profound impact of reducing these \"noise correlations,\" a key effect of attention observed in cortex. You will derive how this change improves the discriminability of a simple population decoder, revealing a sophisticated mechanism for enhancing information processing at the population level.",
            "id": "5039157",
            "problem": "A widely observed effect of selective attention in cortex is a reduction in trial-to-trial noise correlations between neurons tuned to the same feature. Consider a population of $N = 100$ neurons with identical tuning to a single scalar stimulus dimension. For discriminating two nearby stimuli, each neuron’s mean response differs by the same amount $\\Delta \\mu$ between the two stimuli, and each neuron’s noise has the same standard deviation $\\sigma$. The pairwise Pearson correlation coefficient of the noise between any two distinct neurons is uniform and equal to $\\rho$. Assume attention reduces the correlation from $\\rho_{\\text{pre}} = 0.15$ before attention to $\\rho_{\\text{post}} = 0.05$ after attention, without changing $\\Delta \\mu$ or $\\sigma$.\n\nA downstream area uses a simple equal-weight linear readout $y$ that sums the population responses to form a decision variable. Let performance be quantified by the discriminability $d'$ in the framework of Signal Detection Theory (SDT), defined for a decision variable as the difference in its means across the two stimuli divided by its noise standard deviation.\n\nStarting from core definitions and well-tested facts about covariance and correlation of random variables, derive an expression for $d'$ of this simple equal-weight readout as a function of $N$, $\\Delta \\mu$, $\\sigma$, and $\\rho$, and then compute the predicted multiplicative improvement in decoder performance due to attention, defined as the ratio $d'_{\\text{post}}/d'_{\\text{pre}}$. Round your final numerical answer to three significant figures. Provide your final answer as a dimensionless multiplicative factor.",
            "solution": "The problem asks for a derivation of the discriminability $d'$ for a simple linear readout of a neural population and for the computation of the improvement in this metric due to an attention-induced change in noise correlations.\n\nFirst, we establish the statistical framework. Let $r_i$ be the response of neuron $i$ ($i=1, \\dots, N$), which is a random variable. The problem considers the discrimination of two stimuli, which we can label $s_1$ and $s_2$. The response of neuron $i$ to stimulus $s_k$ is $r_{i,k}$.\n\nThe givens are:\n- The number of neurons is $N = 100$.\n- The mean response of neuron $i$ to stimulus $s_k$ is $E[r_{i,k}] = \\mu_{i,k}$.\n- The difference in mean responses between the two stimuli is the same for all neurons: $\\Delta \\mu = \\mu_{i,2} - \\mu_{i,1}$.\n- The noise variance of each neuron's response is the same for all neurons and both stimuli: $\\text{Var}(r_{i,k}) = \\sigma^2$.\n- The noise correlation between any two distinct neurons $i$ and $j$ is uniform: $\\text{Corr}(r_{i,k}, r_{j,k}) = \\rho$ for $i \\neq j$.\n- From the definition of the Pearson correlation coefficient, the covariance is $\\text{Cov}(r_{i,k}, r_{j,k}) = \\rho \\sqrt{\\text{Var}(r_{i,k})} \\sqrt{\\text{Var}(r_{j,k})} = \\rho \\sigma^2$ for $i \\neq j$. Note that $\\text{Cov}(r_{i,k}, r_{i,k}) = \\text{Var}(r_{i,k}) = \\sigma^2$.\n\nThe decision variable $y$ is formed by a simple equal-weight linear sum of the population responses:\n$$y_k = \\sum_{i=1}^{N} r_{i,k}$$\nwhere $y_k$ is the decision variable for stimulus $s_k$.\n\nThe discriminability $d'$ is defined as the difference in the means of the decision variable, divided by its standard deviation:\n$$d' = \\frac{E[y_2] - E[y_1]}{\\sqrt{\\text{Var}(y)}}$$\nThe noise statistics ($\\sigma^2$, $\\rho$) are assumed to be independent of the stimulus being presented, so $\\text{Var}(y_1) = \\text{Var}(y_2) = \\text{Var}(y)$.\n\nWe first derive the numerator of $d'$, the difference in the mean of the readout. By linearity of expectation:\n$$E[y_k] = E\\left[\\sum_{i=1}^{N} r_{i,k}\\right] = \\sum_{i=1}^{N} E[r_{i,k}] = \\sum_{i=1}^{N} \\mu_{i,k}$$\nThe difference in means is:\n$$E[y_2] - E[y_1] = \\sum_{i=1}^{N} \\mu_{i,2} - \\sum_{i=1}^{N} \\mu_{i,1} = \\sum_{i=1}^{N} (\\mu_{i,2} - \\mu_{i,1})$$\nSince $\\Delta \\mu$ is the same for all $N$ neurons, this simplifies to:\n$$E[y_2] - E[y_1] = \\sum_{i=1}^{N} \\Delta \\mu = N \\Delta \\mu$$\n\nNext, we derive the denominator of $d'$, which is the standard deviation of the readout, $\\sigma_y = \\sqrt{\\text{Var}(y)}$. We must first find the variance of $y$. The variance of a sum of random variables is the sum of all entries in their covariance matrix:\n$$\\text{Var}(y) = \\text{Var}\\left(\\sum_{i=1}^{N} r_i\\right) = \\sum_{i=1}^{N}\\sum_{j=1}^{N} \\text{Cov}(r_i, r_j)$$\nWe can split this double summation into terms where $i=j$ (the diagonal terms) and terms where $i \\neq j$ (the off-diagonal terms):\n$$\\text{Var}(y) = \\sum_{i=1}^{N} \\text{Cov}(r_i, r_i) + \\sum_{i \\neq j} \\text{Cov}(r_i, r_j)$$\nThe first sum consists of $N$ variance terms, $\\text{Cov}(r_i, r_i) = \\text{Var}(r_i) = \\sigma^2$. The second sum consists of $N(N-1)$ covariance terms, $\\text{Cov}(r_i, r_j) = \\rho \\sigma^2$ for $i \\neq j$.\nSubstituting these into the equation for $\\text{Var}(y)$:\n$$\\text{Var}(y) = \\sum_{i=1}^{N} \\sigma^2 + \\sum_{i \\neq j} \\rho \\sigma^2 = N \\sigma^2 + N(N-1)\\rho \\sigma^2$$\nFactoring out $N \\sigma^2$ gives the variance of the readout:\n$$\\text{Var}(y) = N \\sigma^2 (1 + (N-1)\\rho)$$\nThe standard deviation of the readout is therefore:\n$$\\sigma_y = \\sqrt{N \\sigma^2 (1 + (N-1)\\rho)} = \\sigma \\sqrt{N(1 + (N-1)\\rho)}$$\n\nNow we can write the full expression for discriminability $d'$:\n$$d' = \\frac{N \\Delta \\mu}{\\sigma \\sqrt{N(1 + (N-1)\\rho)}}$$\nThis can be simplified:\n$$d' = \\frac{\\Delta \\mu}{\\sigma} \\frac{N}{\\sqrt{N}\\sqrt{1 + (N-1)\\rho}} = \\frac{\\Delta \\mu}{\\sigma} \\sqrt{\\frac{N}{1 + (N-1)\\rho}}$$\nThis is the required expression for $d'$ as a function of $N$, $\\Delta \\mu$, $\\sigma$, and $\\rho$.\n\nThe problem states that attention reduces the correlation from $\\rho_{\\text{pre}} = 0.15$ to $\\rho_{\\text{post}} = 0.05$, while $N$, $\\Delta \\mu$, and $\\sigma$ remain unchanged. We can write the expressions for $d'_{\\text{pre}}$ and $d'_{\\text{post}}$:\n$$d'_{\\text{pre}} = \\frac{\\Delta \\mu}{\\sigma} \\sqrt{\\frac{N}{1 + (N-1)\\rho_{\\text{pre}}}}$$\n$$d'_{\\text{post}} = \\frac{\\Delta \\mu}{\\sigma} \\sqrt{\\frac{N}{1 + (N-1)\\rho_{\\text{post}}}}$$\n\nThe multiplicative improvement is the ratio $d'_{\\text{post}} / d'_{\\text{pre}}$:\n$$\\frac{d'_{\\text{post}}}{d'_{\\text{pre}}} = \\frac{\\frac{\\Delta \\mu}{\\sigma} \\sqrt{\\frac{N}{1 + (N-1)\\rho_{\\text{post}}}}}{\\frac{\\Delta \\mu}{\\sigma} \\sqrt{\\frac{N}{1 + (N-1)\\rho_{\\text{pre}}}}}$$\nThe common factor $\\frac{\\Delta \\mu}{\\sigma}\\sqrt{N}$ cancels, leaving:\n$$\\frac{d'_{\\text{post}}}{d'_{\\text{pre}}} = \\frac{\\sqrt{\\frac{1}{1 + (N-1)\\rho_{\\text{post}}}}}{\\sqrt{\\frac{1}{1 + (N-1)\\rho_{\\text{pre}}}}} = \\sqrt{\\frac{1 + (N-1)\\rho_{\\text{pre}}}{1 + (N-1)\\rho_{\\text{post}}}}$$\n\nNow, we substitute the given numerical values: $N = 100$, $\\rho_{\\text{pre}} = 0.15$, and $\\rho_{\\text{post}} = 0.05$. Note that $N-1 = 99$.\n$$\\frac{d'_{\\text{post}}}{d'_{\\text{pre}}} = \\sqrt{\\frac{1 + (99)(0.15)}{1 + (99)(0.05)}}$$\nFirst, compute the numerator and denominator inside the square root:\n$$1 + (99)(0.15) = 1 + 14.85 = 15.85$$\n$$1 + (99)(0.05) = 1 + 4.95 = 5.95$$\nThe ratio is:\n$$\\frac{d'_{\\text{post}}}{d'_{\\text{pre}}} = \\sqrt{\\frac{15.85}{5.95}} \\approx \\sqrt{2.6638655...} \\approx 1.6321359...$$\nRounding the final answer to three significant figures, the predicted multiplicative improvement is $1.63$.",
            "answer": "$$\\boxed{1.63}$$"
        }
    ]
}