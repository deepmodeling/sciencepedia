{
    "hands_on_practices": [
        {
            "introduction": "我们如何量化单个神经元层面上的注意增益？信号检测论（Signal Detection Theory, SDT）通过衡量可辨别性指标 $d'$，为此提供了一个严谨的框架。在此练习中，您将把SDT应用于一个假设的神经元，以精确计算当注意增强其信号并降低其噪声时，它区分两种刺激的能力会提高多少。",
            "id": "5039177",
            "problem": "视觉皮层的一个神经元对两种刺激类别（一个偏好刺激和一个非偏好刺激）产生响应，其响应通过在固定的观察窗口内测量的放电计数来衡量。根据经验，对于该神经元和该观察窗口，两种类别的放电计数变异性可以很好地用等方差高斯统计来近似。在此近似下，信号检测理论（SDT）中用于区分两个类别的判别指数，是根据它们平均放电计数的差异和它们的共同标准差来定义的。假设注意力通过增加平均放电率和减少变异性来对神经响应进行乘法调制。具体来说，假设注意力将两个类别的平均值都乘以一个因子 $(1+g)$（其中 $g=0.20$），并将共同方差乘以一个因子 $(1-v)$（其中 $v=0.15$）。在这些假设和等方差高斯模型下，从第一性原理推导判别指数如何随这些乘法变化而缩放。然后，当 $g=0.20$ 和 $v=0.15$ 时，计算判别指数的乘法变化因子 $R$，定义为 $R=d'_{\\mathrm{att}}/d'_{\\mathrm{base}}$。将最终结果表示为一个无量纲数，并四舍五入到四位有效数字。",
            "solution": "问题陈述被评估为有效。它在科学上基于信号检测理论（SDT）在神经科学中一个成熟的注意力调制模型中的应用。问题设定良好，为得到唯一解提供了所有必要的参数和定义。语言客观而精确。\n\n我们被要求推导在注意力调制下判别指数 $d'$ 的缩放关系，并计算由此产生的乘法变化因子。对于从均值为 $\\mu_1$ 和 $\\mu_2$、共同标准差为 $\\sigma$ 的高斯分布中抽取的两个响应，其判别指数定义为：\n$$\nd' = \\frac{|\\mu_1 - \\mu_2|}{\\sigma}\n$$\n在此情境下，两个响应是偏好刺激和非偏好刺激的放电计数。设 $\\mu_p$ 和 $\\mu_n$ 分别为偏好和非偏好刺激的平均放电计数。不失一般性，我们假设 $\\mu_p > \\mu_n$。\n\n首先，我们定义基线（无注意力）条件下的判别能力，记为 $d'_{\\mathrm{base}}$。设基线平均值为 $\\mu_{p, \\mathrm{base}}$ 和 $\\mu_{n, \\mathrm{base}}$，共同基线方差为 $\\sigma_{\\mathrm{base}}^2$。因此，基线标准差为 $\\sigma_{\\mathrm{base}} = \\sqrt{\\sigma_{\\mathrm{base}}^2}$。\n$$\nd'_{\\mathrm{base}} = \\frac{\\mu_{p, \\mathrm{base}} - \\mu_{n, \\mathrm{base}}}{\\sigma_{\\mathrm{base}}}\n$$\n\n接下来，我们考虑有注意力的条件。根据问题描述，注意力引入了乘法缩放。平均值按因子 $(1+g)$ 缩放，方差按因子 $(1-v)$ 缩放。我们用下标 'att' 表示有注意力条件下的参数。\n\n新的平均值为：\n$$\n\\mu_{p, \\mathrm{att}} = \\mu_{p, \\mathrm{base}}(1+g)\n$$\n$$\n\\mu_{n, \\mathrm{att}} = \\mu_{n, \\mathrm{base}}(1+g)\n$$\n新的方差为：\n$$\n\\sigma_{\\mathrm{att}}^2 = \\sigma_{\\mathrm{base}}^2(1-v)\n$$\n新的标准差是新方差的平方根：\n$$\n\\sigma_{\\mathrm{att}} = \\sqrt{\\sigma_{\\mathrm{base}}^2(1-v)} = \\sigma_{\\mathrm{base}}\\sqrt{1-v}\n$$\n\n现在我们可以写出注意力条件下的判别指数 $d'_{\\mathrm{att}}$ 的表达式：\n$$\nd'_{\\mathrm{att}} = \\frac{\\mu_{p, \\mathrm{att}} - \\mu_{n, \\mathrm{att}}}{\\sigma_{\\mathrm{att}}}\n$$\n将注意力条件下的参数表达式代入此方程，得到：\n$$\nd'_{\\mathrm{att}} = \\frac{\\mu_{p, \\mathrm{base}}(1+g) - \\mu_{n, \\mathrm{base}}(1+g)}{\\sigma_{\\mathrm{base}}\\sqrt{1-v}}\n$$\n我们可以从分子中提出因子 $(1+g)$：\n$$\nd'_{\\mathrm{att}} = \\frac{(\\mu_{p, \\mathrm{base}} - \\mu_{n, \\mathrm{base}})(1+g)}{\\sigma_{\\mathrm{base}}\\sqrt{1-v}}\n$$\n为了揭示缩放关系，我们可以重新排列各项，以分离出 $d'_{\\mathrm{base}}$ 的表达式：\n$$\nd'_{\\mathrm{att}} = \\left(\\frac{\\mu_{p, \\mathrm{base}} - \\mu_{n, \\mathrm{base}}}{\\sigma_{\\mathrm{base}}}\\right) \\cdot \\frac{1+g}{\\sqrt{1-v}}\n$$\n通过代入 $d'_{\\mathrm{base}}$ 的定义，我们推导出缩放定律：\n$$\nd'_{\\mathrm{att}} = d'_{\\mathrm{base}} \\cdot \\frac{1+g}{\\sqrt{1-v}}\n$$\n这个方程表示了由于乘法性注意力调制导致的判别指数的缩放。\n\n问题要求我们计算乘法变化因子 $R$，定义为 $R = d'_{\\mathrm{att}} / d'_{\\mathrm{base}}$。根据推导出的关系，我们得到：\n$$\nR = \\frac{d'_{\\mathrm{att}}}{d'_{\\mathrm{base}}} = \\frac{1+g}{\\sqrt{1-v}}\n$$\n问题给出了调制参数的具体值：$g=0.20$ 和 $v=0.15$。我们将这些值代入 $R$ 的表达式中：\n$$\nR = \\frac{1+0.20}{\\sqrt{1-0.15}} = \\frac{1.20}{\\sqrt{0.85}}\n$$\n现在，我们计算数值：\n$$\nR \\approx \\frac{1.20}{0.9219544457} \\approx 1.30158098\n$$\n问题规定最终答案应四舍五入到四位有效数字。前四位有效数字是 $1$、$3$、$0$ 和 $1$。第五位数字是 $5$，所以我们将第四位数字向上取整。\n$$\nR \\approx 1.302\n$$",
            "answer": "$$\\boxed{1.302}$$"
        },
        {
            "introduction": "在杂乱的环境中，注意不仅必须增强相关信息，还必须抑制无关干扰。分裂归一化模型（divisive normalization model）是解释神经回路如何实现这种竞争性选择的主要理论。这项练习让您掌控一个简单的归一化电路，通过计算来亲身体验将注意引导至一个刺激如何主动抑制对竞争刺激的神经响应。",
            "id": "5039176",
            "problem": "在构成选择性注意基础的皮层回路中，一个得到充分支持的计算描述是分裂归一化（divisive normalization），其中对刺激 $i$ 具有选择性的神经元的响应，是由兴奋性驱动和汇集的抑制性驱动之间的平衡所决定的。考虑一个与来自视觉皮层和顶叶区域的证据一致的最小双刺激归一化回路：每个神经元接收一个与刺激驱动和注意增益成正比的兴奋性输入，以及一个来自抑制性归一化池的抑制性输入，该归一化池通过正权重对所有刺激的经注意调制的驱动进行求和。一个非零基线项捕捉了背景活动并防止了除零错误。形式上，令兴奋性驱动为 $E_{i} = g_{i} s_{i}$，归一化池为 $N_{i} = \\sum_{j} w_{ij} g_{j} s_{j}$（其中 $w_{ij} \\geq 0$），瞬时发放率为\n$$\nr_{i} = \\frac{E_{i}}{\\sigma + N_{i}}。\n$$\n给定两个刺激，其驱动分别为 $s_{1} = 10$ 和 $s_{2} = 8$，均匀的归一化权重 $w_{ij} = 1$，基线 $\\sigma = 2$，以及针对刺激1的注意增益 $g_{1} = 1.4$。假设未被注意的刺激其增益为 $g_{2} = 1$。\n\n从上述定义和分裂归一化框架出发，推导 $r_{1}$ 和 $r_{2}$ 的表达式并计算它们的数值。然后，结合归一化池和基线，简要解释未被注意的刺激所经历的竞争性抑制。最终答案必须是由该对 $(r_{1}, r_{2})$ 组成，表示为未经四舍五入的精确值，并且不得包含单位。",
            "solution": "经评估，问题陈述有效。其科学基础是计算神经科学中已确立的分裂归一化模型，数学上是适定的，并提供了所有必要的参数，且以客观、正式的语言表述。内容没有矛盾、歧义或事实性错误。\n\n对刺激 $i$ 具有选择性的神经元的瞬时发放率 $r_{i}$ 由分裂归一化方程给出：\n$$\nr_{i} = \\frac{E_{i}}{\\sigma + N_{i}}\n$$\n其中 $E_{i}$ 是兴奋性驱动， $N_{i}$ 是分裂归一化池，$\\sigma$ 是一个基线项。\n\n神经元 $i$ 的兴奋性驱动定义为 $E_{i} = g_{i} s_{i}$，其中 $g_{i}$ 是注意增益，$s_{i}$ 是刺激驱动。\n神经元 $i$ 的归一化池定义为 $N_{i} = \\sum_{j} w_{ij} g_{j} s_{j}$，它对感受野中所有刺激的加权的、经注意调制的驱动进行求和。\n\n给定一个双刺激情景 ($i, j \\in \\{1, 2\\}$)，参数如下：\n- 刺激驱动：$s_{1} = 10$，$s_{2} = 8$\n- 注意增益：$g_{1} = 1.4$ (被注意的)，$g_{2} = 1$ (未被注意的)\n- 归一化权重：对于所有 $i, j$，$w_{ij} = 1$。\n- 基线项：$\\sigma = 2$\n\n首先，我们推导兴奋性驱动 $E_{1}$ 和 $E_{2}$ 的具体表达式。\n使用 $E_{i} = g_{i} s_{i}$：\n$$\nE_{1} = g_{1} s_{1} = (1.4)(10) = 14\n$$\n$$\nE_{2} = g_{2} s_{2} = (1)(8) = 8\n$$\n\n接下来，我们推导归一化池的表达式。问题陈述指明了均匀权重 $w_{ij}=1$。这意味着两个神经元的归一化池是相同的，即 $N_{1} = N_{2}$。我们用 $N$ 表示这个共同的归一化池。\n$$\nN = N_{1} = \\sum_{j=1}^{2} w_{1j} g_{j} s_{j} = w_{11} g_{1} s_{1} + w_{12} g_{2} s_{2}\n$$\n$$\nN = N_{2} = \\sum_{j=1}^{2} w_{2j} g_{j} s_{j} = w_{21} g_{1} s_{1} + w_{22} g_{2} s_{2}\n$$\n将所有 $i,j$ 的 $w_{ij} = 1$ 代入：\n$$\nN = (1) g_{1} s_{1} + (1) g_{2} s_{2} = g_{1} s_{1} + g_{2} s_{2}\n$$\n现在，我们计算归一化池 $N$ 的数值：\n$$\nN = (1.4)(10) + (1)(8) = 14 + 8 = 22\n$$\n\n有了这些组成部分，我们可以计算发放率 $r_{1}$ 和 $r_{2}$。\n对于神经元1 (被注意的)：\n$$\nr_{1} = \\frac{E_{1}}{\\sigma + N} = \\frac{14}{2 + 22} = \\frac{14}{24} = \\frac{7}{12}\n$$\n对于神经元2 (未被注意的)：\n$$\nr_{2} = \\frac{E_{2}}{\\sigma + N} = \\frac{8}{2 + 22} = \\frac{8}{24} = \\frac{1}{3}\n$$\n\n发放率的数值为 $r_{1} = 7/12$ 和 $r_{2} = 1/3$。\n\n对竞争性抑制的解释：\n未被注意的神经元（神经元2）的响应由 $r_{2} = \\frac{E_{2}}{\\sigma + N} = \\frac{g_{2}s_{2}}{\\sigma + g_{1}s_{1} + g_{2}s_{2}}$ 给出。分母代表总抑制性驱动。它由一个恒定的基线抑制 $\\sigma$ 和刺激驱动的归一化池 $N = g_{1}s_{1} + g_{2}s_{2}$ 组成。关键在于，归一化池汇集了来自*所有*刺激的经注意调制的驱动。当注意力被导向刺激1时，其增益 $g_{1}$ 增加（$g_{1}=1.4$）。这提升了刺激1对共享归一化池的贡献（$g_{1}s_{1} = 14$）。这个更大的归一化池值（$N=22$）会除法式地抑制*所有*神经元（包括神经元2）的响应。因此，被注意刺激增强的兴奋性驱动导致了对与之竞争的、未被注意的刺激的更强抑制。这正是分裂归一化框架中竞争性抑制的机制。基线项 $\\sigma$ 增加了一个恒定的、非刺激特异性的抑制，确保分母始终大于零，并为总抑制效应设定了一个下限。",
            "answer": "$$\n\\boxed{\\begin{pmatrix} \\frac{7}{12} & \\frac{1}{3} \\end{pmatrix}}\n$$"
        },
        {
            "introduction": "大脑不是通过单个神经元来表征信息，而是通过大规模的神经元群体。注意最强大的效应之一可能就是优化这些群体编码信息的方式。在这个问题中，我们探讨降低噪声相关性（一种被广泛观察到的注意效应）的影响。您将计算由此带来的解码器性能提升，从而揭示协调整个神经元集合的活动如何能显著锐化其集体传递的信息。",
            "id": "5039157",
            "problem": "在皮层中，一个被广泛观察到的选择性注意效应是，对同一特征调谐的神经元之间的试次间噪声相关性会降低。考虑一个由 $N = 100$ 个神经元组成的群体，它们对单个标量刺激维度具有相同的调谐特性。为了区分两个相近的刺激，每个神经元对于这两个刺激的平均响应差异均为 $\\Delta \\mu$，且每个神经元的噪声具有相同的标准差 $\\sigma$。任意两个不同神经元之间噪声的成对皮尔逊相关系数是均匀的，等于 $\\rho$。假设注意将相关性从注意前的 $\\rho_{\\text{pre}} = 0.15$ 降低到注意后的 $\\rho_{\\text{post}} = 0.05$，而 $\\Delta \\mu$ 或 $\\sigma$ 不发生改变。\n\n一个下游脑区使用一个简单的等权重线性读出 $y$，它将群体响应相加形成一个决策变量。性能由信号检测论 (SDT) 框架中的可辨别性 $d'$ 来量化，其定义为决策变量在两种刺激下的均值之差除以其噪声标准差。\n\n从随机变量的协方差和相关性的核心定义和经过充分检验的事实出发，推导这个简单的等权重读出的 $d'$ 作为 $N$、$\\Delta \\mu$、$\\sigma$ 和 $\\rho$ 的函数表达式，然后计算由注意引起的解码器性能的预测乘法改进，定义为比率 $d'_{\\text{post}}/d'_{\\text{pre}}$。将您的最终数值答案四舍五入到三位有效数字。以无量纲乘法因子的形式提供您的最终答案。",
            "solution": "问题要求推导一个神经元群体的简单线性读出的可辨别性 $d'$，并计算由于注意引起的噪声相关性变化所带来的该指标的改进。\n\n首先，我们建立统计框架。设 $r_i$ 为神经元 $i$ ($i=1, \\dots, N$) 的响应，它是一个随机变量。该问题考虑的是区分两个刺激，我们可以将其标记为 $s_1$ 和 $s_2$。神经元 $i$ 对刺激 $s_k$ 的响应是 $r_{i,k}$。\n\n已知条件是：\n- 神经元数量为 $N = 100$。\n- 神经元 $i$ 对刺激 $s_k$ 的平均响应为 $E[r_{i,k}] = \\mu_{i,k}$。\n- 对所有神经元而言，两种刺激之间的平均响应差异是相同的：$\\Delta \\mu = \\mu_{i,2} - \\mu_{i,1}$。\n- 对所有神经元和两种刺激而言，每个神经元响应的噪声方差是相同的：$\\text{Var}(r_{i,k}) = \\sigma^2$。\n- 任意两个不同神经元 $i$ 和 $j$ 之间的噪声相关性是均匀的：对于 $i \\neq j$，$\\text{Corr}(r_{i,k}, r_{j,k}) = \\rho$。\n- 根据皮尔逊相关系数的定义，协方差为 $\\text{Cov}(r_{i,k}, r_{j,k}) = \\rho \\sqrt{\\text{Var}(r_{i,k})} \\sqrt{\\text{Var}(r_{j,k})} = \\rho \\sigma^2$ (对于 $i \\neq j$)。注意 $\\text{Cov}(r_{i,k}, r_{i,k}) = \\text{Var}(r_{i,k}) = \\sigma^2$。\n\n决策变量 $y$ 由群体响应的简单等权重线性和形成：\n$$y_k = \\sum_{i=1}^{N} r_{i,k}$$\n其中 $y_k$ 是刺激 $s_k$ 的决策变量。\n\n可辨别性 $d'$ 定义为决策变量均值之差除以其标准差：\n$$d' = \\frac{E[y_2] - E[y_1]}{\\sqrt{\\text{Var}(y)}}$$\n假设噪声统计量 ($\\sigma^2$, $\\rho$) 与所呈现的刺激无关，因此 $\\text{Var}(y_1) = \\text{Var}(y_2) = \\text{Var}(y)$。\n\n我们首先推导 $d'$ 的分子，即读出均值之差。根据期望的线性性质：\n$$E[y_k] = E\\left[\\sum_{i=1}^{N} r_{i,k}\\right] = \\sum_{i=1}^{N} E[r_{i,k}] = \\sum_{i=1}^{N} \\mu_{i,k}$$\n均值之差为：\n$$E[y_2] - E[y_1] = \\sum_{i=1}^{N} \\mu_{i,2} - \\sum_{i=1}^{N} \\mu_{i,1} = \\sum_{i=1}^{N} (\\mu_{i,2} - \\mu_{i,1})$$\n由于 $\\Delta \\mu$ 对所有 $N$ 个神经元都是相同的，这可以简化为：\n$$E[y_2] - E[y_1] = \\sum_{i=1}^{N} \\Delta \\mu = N \\Delta \\mu$$\n\n接下来，我们推导 $d'$ 的分母，即读出的标准差 $\\sigma_y = \\sqrt{\\text{Var}(y)}$。我们必须首先求出 $y$ 的方差。随机变量之和的方差是其协方差矩阵中所有项的总和：\n$$\\text{Var}(y) = \\text{Var}\\left(\\sum_{i=1}^{N} r_i\\right) = \\sum_{i=1}^{N}\\sum_{j=1}^{N} \\text{Cov}(r_i, r_j)$$\n我们可以将这个双重求和分解为 $i=j$ 的项（对角项）和 $i \\neq j$ 的项（非对角项）：\n$$\\text{Var}(y) = \\sum_{i=1}^{N} \\text{Cov}(r_i, r_i) + \\sum_{i \\neq j} \\text{Cov}(r_i, r_j)$$\n第一个和包含 $N$ 个方差项，$\\text{Cov}(r_i, r_i) = \\text{Var}(r_i) = \\sigma^2$。第二个和包含 $N(N-1)$ 个协方差项，对于 $i \\neq j$，$\\text{Cov}(r_i, r_j) = \\rho \\sigma^2$。\n将这些代入 $\\text{Var}(y)$ 的方程中：\n$$\\text{Var}(y) = N \\sigma^2 + N(N-1)\\rho \\sigma^2$$\n提出公因子 $N \\sigma^2$ 得到读出的方差：\n$$\\text{Var}(y) = N \\sigma^2 (1 + (N-1)\\rho)$$\n因此，读出的标准差为：\n$$\\sigma_y = \\sqrt{N \\sigma^2 (1 + (N-1)\\rho)} = \\sigma \\sqrt{N(1 + (N-1)\\rho)}$$\n\n现在我们可以写出可辨别性 $d'$ 的完整表达式：\n$$d' = \\frac{N \\Delta \\mu}{\\sigma \\sqrt{N(1 + (N-1)\\rho)}}$$\n这可以简化为：\n$$d' = \\frac{\\Delta \\mu}{\\sigma} \\frac{N}{\\sqrt{N}\\sqrt{1 + (N-1)\\rho}} = \\frac{\\Delta \\mu}{\\sigma} \\sqrt{\\frac{N}{1 + (N-1)\\rho}}$$\n这就是所要求的 $d'$ 作为 $N$、$\\Delta \\mu$、$\\sigma$ 和 $\\rho$ 的函数表达式。\n\n问题陈述，注意将相关性从 $\\rho_{\\text{pre}} = 0.15$ 降低到 $\\rho_{\\text{post}} = 0.05$，而 $N$、$\\Delta \\mu$ 和 $\\sigma$ 保持不变。我们可以写出 $d'_{\\text{pre}}$ 和 $d'_{\\text{post}}$ 的表达式：\n$$d'_{\\text{pre}} = \\frac{\\Delta \\mu}{\\sigma} \\sqrt{\\frac{N}{1 + (N-1)\\rho_{\\text{pre}}}}$$\n$$d'_{\\text{post}} = \\frac{\\Delta \\mu}{\\sigma} \\sqrt{\\frac{N}{1 + (N-1)\\rho_{\\text{post}}}}$$\n\n乘法改进是比率 $d'_{\\text{post}} / d'_{\\text{pre}}$：\n$$\\frac{d'_{\\text{post}}}{d'_{\\text{pre}}} = \\frac{\\frac{\\Delta \\mu}{\\sigma} \\sqrt{\\frac{N}{1 + (N-1)\\rho_{\\text{post}}}}}{\\frac{\\Delta \\mu}{\\sigma} \\sqrt{\\frac{N}{1 + (N-1)\\rho_{\\text{pre}}}}}$$\n公共因子 $\\frac{\\Delta \\mu}{\\sigma}\\sqrt{N}$ 消去，剩下：\n$$\\frac{d'_{\\text{post}}}{d'_{\\text{pre}}} = \\frac{\\sqrt{\\frac{1}{1 + (N-1)\\rho_{\\text{post}}}}}{\\sqrt{\\frac{1}{1 + (N-1)\\rho_{\\text{pre}}}}} = \\sqrt{\\frac{1 + (N-1)\\rho_{\\text{pre}}}{1 + (N-1)\\rho_{\\text{post}}}}$$\n\n现在，我们代入给定的数值：$N = 100$，$\\rho_{\\text{pre}} = 0.15$，以及 $\\rho_{\\text{post}} = 0.05$。注意 $N-1 = 99$。\n$$\\frac{d'_{\\text{post}}}{d'_{\\text{pre}}} = \\sqrt{\\frac{1 + (99)(0.15)}{1 + (99)(0.05)}}$$\n首先，计算平方根内的分子和分母：\n$$1 + (99)(0.15) = 1 + 14.85 = 15.85$$\n$$1 + (99)(0.05) = 1 + 4.95 = 5.95$$\n该比率为：\n$$\\frac{d'_{\\text{post}}}{d'_{\\text{pre}}} = \\sqrt{\\frac{15.85}{5.95}} \\approx \\sqrt{2.6638655...} \\approx 1.6321359...$$\n将最终答案四舍五入到三位有效数字，预测的乘法改进为 $1.63$。",
            "answer": "$$\\boxed{1.63}$$"
        }
    ]
}