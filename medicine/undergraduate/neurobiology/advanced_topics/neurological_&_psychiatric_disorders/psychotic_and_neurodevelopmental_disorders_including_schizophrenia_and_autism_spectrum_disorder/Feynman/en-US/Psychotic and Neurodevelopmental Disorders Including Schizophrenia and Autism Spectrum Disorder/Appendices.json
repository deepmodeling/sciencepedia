{
    "hands_on_practices": [
        {
            "introduction": "This practice introduces the classical twin study, a powerful method for disentangling genetic and environmental contributions to complex traits. By fitting a quantitative model to twin correlation data, you will learn how to estimate the heritability of traits associated with Autism Spectrum Disorder (ASD) and formally test hypotheses about the influence of the shared environment, moving from qualitative ideas about 'nature versus nurture' to a rigorous, data-driven framework. ",
            "id": "5054375",
            "problem": "You are given summary statistics from twin studies of social communication deficit scores in Autism Spectrum Disorder (ASD). The goal is to infer variance components under the classical twin model and formally test whether the shared environment contributes meaningfully to the ASD social deficit phenotype. Use the following fundamental base and assumptions from quantitative genetics and multivariate normal theory.\n\nFundamental definitions and assumptions:\n- Let the phenotype $Y$ have variance components $\\mathrm{A}$ (additive genetic), $\\mathrm{C}$ (shared environment), and $\\mathrm{E}$ (unique environment), such that $\\mathrm{Var}(Y) = \\mathrm{A} + \\mathrm{C} + \\mathrm{E}$ with all components nonnegative.\n- Monozygotic (MZ) twins share approximately $100\\,\\%$ of their additive genetic influences, and dizygotic (DZ) twins share approximately $50\\,\\%$ of their additive genetic influences. The genetic relatedness coefficient $r_g$ is $1$ for MZ twins and $0.5$ for DZ twins.\n- Under the classical twin model, the cross-twin covariance for a twin pair is $\\mathrm{Cov}(Y_1,Y_2) = r_g \\cdot \\mathrm{A} + \\mathrm{C}$, and each twin’s variance is $\\mathrm{Var}(Y) = \\mathrm{A} + \\mathrm{C} + \\mathrm{E}$.\n- Assume ASD social deficit scores are standardized within each study such that the observed within-twin variance is $1$. The observed twin-pair summary statistics per group are the intraclass correlation $r_{MZ}$ for monozygotic twin pairs and $r_{DZ}$ for dizygotic twin pairs, and the number of independent twin pairs $n_{MZ}$ and $n_{DZ}$, respectively.\n- Assume the bivariate twin scores are jointly multivariate normal. For a twin group with expected covariance matrix $\\Sigma$, the negative twice log-likelihood (up to a constant) for $n$ independent pairs with sample covariance matrix $S$ is given by $-2\\ell = n\\left(\\log|\\Sigma| + \\mathrm{tr}(S\\Sigma^{-1})\\right)$.\n\nTask:\n1. For each test case, treat the observed $2 \\times 2$ sample covariance matrix for each group as $S_{MZ} = \\begin{bmatrix} 1 & r_{MZ} \\\\ r_{MZ} & 1 \\end{bmatrix}$ and $S_{DZ} = \\begin{bmatrix} 1 & r_{DZ} \\\\ r_{DZ} & 1 \\end{bmatrix}$. Under the Additive genetic–Common environment–Unique environment (ACE) model, derive the expected covariance matrices for monozygotic and dizygotic twin pairs from the variance decomposition and genetic relatedness assumptions, and fit the parameters $\\mathrm{A}$, $\\mathrm{C}$, and $\\mathrm{E}$ by maximizing the joint log-likelihood across both groups subject to $\\mathrm{A} \\ge 0$, $\\mathrm{C} \\ge 0$, and $\\mathrm{E} \\ge 0$.\n2. Fit the nested Additive genetic–Unique environment (AE) model by constraining $\\mathrm{C} = 0$ and re-optimizing $\\mathrm{A}$ and $\\mathrm{E}$ under the same likelihood framework.\n3. Compute the likelihood ratio test statistic $D = \\left(-2\\ell_{\\mathrm{AE}}\\right) - \\left(-2\\ell_{\\mathrm{ACE}}\\right)$, which under the null hypothesis $\\mathrm{C} = 0$ is approximately $\\chi^2$-distributed with $1$ degree of freedom. Return the associated $p$-value and a boolean decision for whether the shared environment contributes meaningfully, defined as $p < 0.05$.\n4. Report the maximum likelihood estimates $\\hat{\\mathrm{A}}$, $\\hat{\\mathrm{C}}$, and $\\hat{\\mathrm{E}}$ for the ACE model, the $p$-value from the likelihood ratio test, and the boolean decision for each test case. Express all floating-point outputs rounded to three decimal places.\n\nTest suite:\n- Case $1$: $r_{MZ} = 0.70$, $r_{DZ} = 0.35$, $n_{MZ} = 150$, $n_{DZ} = 250$.\n- Case $2$: $r_{MZ} = 0.60$, $r_{DZ} = 0.50$, $n_{MZ} = 180$, $n_{DZ} = 180$.\n- Case $3$: $r_{MZ} = 0.25$, $r_{DZ} = 0.05$, $n_{MZ} = 120$, $n_{DZ} = 220$.\n- Case $4$: $r_{MZ} = 0.90$, $r_{DZ} = 0.45$, $n_{MZ} = 40$, $n_{DZ} = 60$.\n\nFinal output format:\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets. Each test case’s result must be a list of the form $[\\hat{\\mathrm{A}}, \\hat{\\mathrm{C}}, \\hat{\\mathrm{E}}, p, \\text{decision}]$, where $\\hat{\\mathrm{A}}$, $\\hat{\\mathrm{C}}$, $\\hat{\\mathrm{E}}$, and $p$ are floating-point numbers rounded to three decimals, and $\\text{decision}$ is a boolean. For example, the overall output should look like $[[a_1,c_1,e_1,p_1,\\text{True}],[a_2,c_2,e_2,p_2,\\text{False}],\\dots]$ with no spaces.",
            "solution": "The problem requires the application of quantitative genetic modeling to summary statistics from twin studies of Autism Spectrum Disorder (ASD). The objective is to estimate the contributions of additive genetics ($\\mathrm{A}$), shared environment ($\\mathrm{C}$), and unique environment ($\\mathrm{E}$) to the variance of social communication deficit scores. This is accomplished by fitting two competing models, the ACE and AE models, to the data using the method of maximum likelihood. A likelihood ratio test is then performed to formally assess the significance of the shared environmental component.\n\nThe foundation of the analysis is the classical twin model, which decomposes the total phenotypic variance $\\sigma^2_P$ into three components: $\\sigma^2_P = \\mathrm{A} + \\mathrm{C} + \\mathrm{E}$. The parameters $\\mathrm{A}$, $\\mathrm{C}$, and $\\mathrm{E}$ represent the absolute variances and are constrained to be non-negative: $\\mathrm{A} \\ge 0$, $\\mathrm{C} \\ge 0$, $\\mathrm{E} \\ge 0$.\n\nFrom this decomposition, we can specify the expected covariance matrices for monozygotic (MZ) and dizygotic (DZ) twin pairs. MZ twins share, on average, $100\\,\\%$ of their additive genetic material, while DZ twins share $50\\,\\%$. Both twin types, by definition, share their common environment. The unique environment is, by definition, uncorrelated between twins.\n\nThe expected total variance for any individual is $\\mathrm{Var}(Y) = \\mathrm{A} + \\mathrm{C} + \\mathrm{E}$.\nThe expected covariance for an MZ pair is $\\mathrm{Cov}(Y_{MZ1}, Y_{MZ2}) = 1.0 \\cdot \\mathrm{A} + 1.0 \\cdot \\mathrm{C}$.\nThe expected covariance for a DZ pair is $\\mathrm{Cov}(Y_{DZ1}, Y_{DZ2}) = 0.5 \\cdot \\mathrm{A} + 1.0 \\cdot \\mathrm{C}$.\n\nThis leads to the following theoretical covariance matrices for the ACE model:\n$$ \\Sigma_{MZ} = \\begin{pmatrix} \\mathrm{A}+\\mathrm{C}+\\mathrm{E} & \\mathrm{A}+\\mathrm{C} \\\\ \\mathrm{A}+\\mathrm{C} & \\mathrm{A}+\\mathrm{C}+\\mathrm{E} \\end{pmatrix} $$\n$$ \\Sigma_{DZ} = \\begin{pmatrix} \\mathrm{A}+\\mathrm{C}+\\mathrm{E} & 0.5\\mathrm{A}+\\mathrm{C} \\\\ 0.5\\mathrm{A}+\\mathrm{C} & \\mathrm{A}+\\mathrm{C}+\\mathrm{E} \\end{pmatrix} $$\n\nThe data are provided as sample intraclass correlations ($r_{MZ}, r_{DZ}$) and sample sizes ($n_{MZ}, n_{DZ}$). The phenotypic scores are standardized, so the sample variance is $1$. The sample covariance matrices are therefore:\n$$ S_{MZ} = \\begin{pmatrix} 1 & r_{MZ} \\\\ r_{MZ} & 1 \\end{pmatrix}, \\quad S_{DZ} = \\begin{pmatrix} 1 & r_{DZ} \\\\ r_{DZ} & 1 \\end{pmatrix} $$\n\nThe parameters of the models are estimated by minimizing the total negative twice log-likelihood ($-2\\ell$) across both twin groups. For a single group of $n$ pairs, with sample covariance matrix $S$ and model-predicted covariance matrix $\\Sigma$, this function is given by:\n$$ -2\\llap{\\raisebox{0.5ex}{$\\scriptstyle\\ell$}} = n \\left( \\log|\\Sigma| + \\mathrm{tr}(S\\Sigma^{-1}) \\right) $$\nThe total function to minimize is the sum for the MZ and DZ groups:\n$$ -2\\ell_{\\text{total}}(\\mathrm{A,C,E}) = n_{MZ} \\left(\\log|\\Sigma_{MZ}| + \\mathrm{tr}(S_{MZ}\\Sigma_{MZ}^{-1})\\right) + n_{DZ} \\left(\\log|\\Sigma_{DZ}| + \\mathrm{tr}(S_{DZ}\\Sigma_{DZ}^{-1})\\right) $$\nLet $v = \\mathrm{A}+\\mathrm{C}+\\mathrm{E}$, $c_{MZ} = \\mathrm{A}+\\mathrm{C}$, and $c_{DZ} = 0.5\\mathrm{A}+\\mathrm{C}$. The function to minimize is:\n$$ -2\\ell_{\\text{total}} = n_{MZ} \\left[ \\log(v^2 - c_{MZ}^2) + \\frac{2(v - r_{MZ}c_{MZ})}{v^2 - c_{MZ}^2} \\right] + n_{DZ} \\left[ \\log(v^2 - c_{DZ}^2) + \\frac{2(v - r_{DZ}c_{DZ})}{v^2 - c_{DZ}^2} \\right] $$\n\nThe estimation proceeds in two steps:\n1.  **ACE Model Fitting**: The parameters $\\mathrm{A}$, $\\mathrm{C}$, and $\\mathrm{E}$ are estimated by numerically minimizing the function $-2\\ell_{\\text{total}}(\\mathrm{A,C,E})$ subject to the non-negativity constraints. This yields the parameter estimates $\\hat{\\mathrm{A}}$, $\\hat{\\mathrm{C}}$, $\\hat{\\mathrm{E}}$ and the minimized log-likelihood value, $-2\\ell_{ACE}$.\n\n2.  **AE Model Fitting**: A nested, more parsimonious model is fitted by setting $\\mathrm{C}=0$. This AE model posits that only additive genetic and unique environmental factors influence the trait. The parameters $\\mathrm{A}$ and $\\mathrm{E}$ are estimated by minimizing $-2\\ell_{\\text{total}}(\\mathrm{A},0,\\mathrm{E})$, which gives the value $-2\\ell_{AE}$.\n\nTo test the hypothesis that the shared environment contributes meaningfully to the variance ($H_0: \\mathrm{C}=0$), we use the likelihood ratio test. The test statistic $D$ is the difference between the minimized negative log-likelihoods of the nested (AE) and full (ACE) models:\n$$ D = (-2\\ell_{AE}) - (-2\\ell_{ACE}) $$\nUnder the null hypothesis, this statistic is asymptotically distributed as a chi-squared ($\\chi^2$) variable. The degrees of freedom for the test is the difference in the number of free parameters between the two models, which is $3-2=1$. Thus, $D \\sim \\chi^2_1$.\n\nThe $p$-value is computed as the probability of observing a test statistic as extreme or more extreme than $D$ under the null distribution, i.e., $P(X \\ge D)$ where $X \\sim \\chi^2_1$. A $p$-value less than the significance level of $\\alpha=0.05$ leads to the rejection of the null hypothesis, indicating a statistically significant contribution of the shared environment.\n\nThe entire procedure is automated. For each test case, a numerical optimization algorithm (L-BFGS-B) is used to find the maximum likelihood estimates for both the ACE and AE models under the specified constraints. The LRT statistic and corresponding $p$-value are then computed to arrive at the final decision.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.optimize import minimize\nfrom scipy.stats import chi2\n\ndef solve():\n    \"\"\"\n    Solves the quantitative genetics problem for all test cases.\n    It fits ACE and AE models to twin correlation data, performs a\n    likelihood ratio test, and reports the results.\n    \"\"\"\n    \n    # Define the test cases from the problem statement.\n    test_cases = [\n        {'r_mz': 0.70, 'r_dz': 0.35, 'n_mz': 150, 'n_dz': 250},\n        {'r_mz': 0.60, 'r_dz': 0.50, 'n_mz': 180, 'n_dz': 180},\n        {'r_mz': 0.25, 'r_dz': 0.05, 'n_mz': 120, 'n_dz': 220},\n        {'r_mz': 0.90, 'r_dz': 0.45, 'n_mz': 40, 'n_dz': 60}\n    ]\n\n    def neg_log_likelihood(params, r_mz, r_dz, n_mz, n_dz, model_type):\n        \"\"\"\n        Calculates the total negative twice log-likelihood for ACE or AE models.\n        \"\"\"\n        if model_type == 'ACE':\n            A, C, E = params\n        elif model_type == 'AE':\n            A, E = params\n            C = 0.0\n        else:\n            raise ValueError(\"model_type must be 'ACE' or 'AE'\")\n        \n        # Enforce non-negativity constraint. Optimizer handles this via bounds,\n        # but good practice for robustness.\n        if A  0 or C  0 or E  0:\n            return np.inf\n\n        v = A + C + E # Total variance\n\n        # Handle singularity\n        if v  1e-9:\n            return np.inf\n\n        # MZ group calculations\n        c_mz = A + C\n        rho_mz_sq = (c_mz / v)**2\n        if rho_mz_sq >= 1.0: # Numerical stability\n            return np.inf\n        log_det_mz = np.log(v**2 * (1 - rho_mz_sq))\n        tr_term_mz = 2 * (v - r_mz * c_mz) / (v**2 * (1 - rho_mz_sq))\n        nll_mz = n_mz * (log_det_mz + tr_term_mz)\n\n        # DZ group calculations\n        c_dz = 0.5 * A + C\n        rho_dz_sq = (c_dz / v)**2\n        if rho_dz_sq >= 1.0: # Numerical stability\n            return np.inf\n        log_det_dz = np.log(v**2 * (1 - rho_dz_sq))\n        tr_term_dz = 2 * (v - r_dz * c_dz) / (v**2 * (1 - rho_dz_sq))\n        nll_dz = n_dz * (log_det_dz + tr_term_dz)\n\n        return nll_mz + nll_dz\n\n    results_as_strings = []\n    for case in test_cases:\n        r_mz, r_dz = case['r_mz'], case['r_dz']\n        n_mz, n_dz = case['n_mz'], case['n_dz']\n        \n        args = (r_mz, r_dz, n_mz, n_dz)\n\n        # --- ACE Model Fit ---\n        # Initial guess from Falconer's formulae (clipping C at 0)\n        a0 = 2 * (r_mz - r_dz)\n        c0 = r_mz - a0\n        if c0  0: c0=0\n        e0 = 1 - a0- c0\n        if e0  0: e0=0\n        initial_guess_ace = np.array([a0, c0, e0])\n        bounds_ace = [(0, None), (0, None), (0, None)]\n        \n        res_ace = minimize(\n            fun=neg_log_likelihood,\n            x0=initial_guess_ace,\n            args=(*args, 'ACE'),\n            method='L-BFGS-B',\n            bounds=bounds_ace\n        )\n        a_hat, c_hat, e_hat = res_ace.x\n        nll_ace = res_ace.fun\n\n        # --- AE Model Fit ---\n        initial_guess_ae = np.array([r_mz, 1.0 - r_mz])\n        bounds_ae = [(0, None), (0, None)]\n\n        res_ae = minimize(\n            fun=neg_log_likelihood,\n            x0=initial_guess_ae,\n            args=(*args, 'AE'),\n            method='L-BFGS-B',\n            bounds=bounds_ae\n        )\n        nll_ae = res_ae.fun\n        \n        # --- Likelihood Ratio Test ---\n        # Ensure LRT statistic is non-negative, accounting for potential\n        # tiny numerical floating point errors.\n        lrt_stat = max(0, nll_ae - nll_ace)\n        \n        # p-value from chi-squared distribution with 1 degree of freedom\n        p_value = chi2.sf(lrt_stat, df=1)\n        \n        # Decision\n        decision = p_value  0.05\n        \n        # Format and store result\n        res_str = f\"[{a_hat:.3f},{c_hat:.3f},{e_hat:.3f},{p_value:.3f},{decision}]\"\n        results_as_strings.append(res_str)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(results_as_strings)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "Building on the idea that genetic and environmental factors impact brain function, this exercise delves into the circuit level. You will analyze a simplified model of a cortical microcircuit to explore the concept of excitation-inhibition ($E/I$) balance, a leading hypothesis for the pathophysiology of both schizophrenia and ASD. By performing a stability analysis, you will mathematically determine the conditions under which the network transitions from stable, regulated activity to pathological runaway excitation. ",
            "id": "5054391",
            "problem": "Consider a $2$-population cortical microcircuit comprising an excitatory population and an inhibitory population. Let the population activity vector be $\\mathbf{r}(t) = \\begin{pmatrix} r_{\\mathrm{E}}(t) \\\\ r_{\\mathrm{I}}(t) \\end{pmatrix}$, where $r_{\\mathrm{E}}(t)$ and $r_{\\mathrm{I}}(t)$ are the instantaneous firing rates of excitatory and inhibitory neurons, respectively. Near a steady state, assume linearized dynamics driven by background fluctuations: \n$$\\frac{d\\mathbf{r}}{dt} = -\\mathbf{r} + g\\, W\\, \\mathbf{r} + \\boldsymbol{\\xi}(t),$$\nwhere $\\boldsymbol{\\xi}(t)$ represents zero-mean external stochastic input, $g  0$ is an effective synaptic gain that can be modulated by neurobiological factors such as N-Methyl-D-Aspartate (NMDA) receptor efficacy and Gamma-Aminobutyric Acid (GABA)ergic inhibition, and $W$ is the effective connectivity matrix capturing average coupling strengths between and within the two populations:\n$$\nW = \\begin{pmatrix}\nw_{\\mathrm{EE}}  -w_{\\mathrm{EI}} \\\\\nw_{\\mathrm{IE}}  -w_{\\mathrm{II}}\n\\end{pmatrix}.\n$$\nHere $w_{\\mathrm{EE}}  0$ is excitatory-to-excitatory coupling, $w_{\\mathrm{EI}}  0$ is inhibitory strength from inhibitory to excitatory (appearing with a negative sign in the matrix because inhibitory synapses reduce activity), $w_{\\mathrm{IE}}  0$ is excitatory-to-inhibitory coupling, and $w_{\\mathrm{II}}  0$ is inhibitory-to-inhibitory coupling. This minimal model is widely used to conceptualize excitation–inhibition balance and its perturbation in psychotic and neurodevelopmental disorders (for example, altered $g$ reflecting NMDA hypofunction in schizophrenia or changes in GABAergic interneuron efficacy in autism spectrum disorder).\n\nStarting from the definitions above and basic linear systems stability, compute the eigenvalues of $W$ and analytically determine the critical gain $g^{\\star}$ at which the largest real part of the eigenvalues of the linear operator $g\\, W - \\mathbf{I}$ crosses zero. Interpret this threshold as separating a regime where fluctuations produce balanced irregular activity (stable dynamics with noise-driven variability) from a regime of runaway excitation (unstable dynamics with diverging activity). Provide your derivation directly from the characteristic polynomial of $W$, and do not assume any numerical values. Report, as your final answer, the closed-form expression for $g^{\\star}$ in terms of $w_{\\mathrm{EE}}, w_{\\mathrm{EI}}, w_{\\mathrm{IE}}, w_{\\mathrm{II}}$. No rounding is required.",
            "solution": "The dynamics of the system can be rewritten as $\\frac{d\\mathbf{r}}{dt} = (gW - \\mathbf{I})\\mathbf{r} + \\boldsymbol{\\xi}(t)$, where $\\mathbf{I}$ is the identity matrix. The stability of this linear system is determined by the eigenvalues of the matrix $M = gW - \\mathbf{I}$. The system is stable if all eigenvalues of $M$ have a negative real part. The transition to instability, the critical point, occurs when the largest real part of an eigenvalue of $M$ crosses zero.\n\nLet $\\lambda_M$ be an eigenvalue of $M$ and $\\lambda_W$ be an eigenvalue of $W$. Then $\\lambda_M = g\\lambda_W - 1$. The stability boundary is where $\\text{Re}(\\lambda_M) = g \\text{Re}(\\lambda_W) - 1 = 0$. This implies that the critical gain $g^{\\star}$ at which instability occurs is given by $g^{\\star} = 1 / \\max(\\text{Re}(\\lambda_W))$, where the maximum is taken over all eigenvalues of $W$. We must therefore find the eigenvalues of $W$.\n\nThe characteristic polynomial of $W$ is given by $\\det(W - \\lambda \\mathbf{I}) = 0$:\n$$ (w_{\\mathrm{EE}} - \\lambda)(-w_{\\mathrm{II}} - \\lambda) - (-w_{\\mathrm{EI}})(w_{\\mathrm{IE}}) = 0 $$\n$$ \\lambda^2 - (w_{\\mathrm{EE}} - w_{\\mathrm{II}})\\lambda - (w_{\\mathrm{EE}}w_{\\mathrm{II}} + w_{\\mathrm{EI}}w_{\\mathrm{IE}}) = 0 $$\nThe roots of this quadratic equation, which are the eigenvalues $\\lambda_{W, \\pm}$ of $W$, are:\n$$ \\lambda_{W, \\pm} = \\frac{(w_{\\mathrm{EE}} - w_{\\mathrm{II}}) \\pm \\sqrt{(w_{\\mathrm{EE}} - w_{\\mathrm{II}})^2 + 4(w_{\\mathrm{EE}}w_{\\mathrm{II}} + w_{\\mathrm{EI}}w_{\\mathrm{IE}})}}{2} $$\nSimplifying the term under the square root (the discriminant $\\Delta$):\n$$ \\Delta = w_{\\mathrm{EE}}^2 - 2w_{\\mathrm{EE}}w_{\\mathrm{II}} + w_{\\mathrm{II}}^2 + 4w_{\\mathrm{EE}}w_{\\mathrm{II}} + 4w_{\\mathrm{EI}}w_{\\mathrm{IE}} = (w_{\\mathrm{EE}} + w_{\\mathrm{II}})^2 + 4w_{\\mathrm{EI}}w_{\\mathrm{IE}} $$\nSince all $w$ parameters are positive, the discriminant $\\Delta$ is always positive. This means the eigenvalues of $W$ are always real. Therefore, the largest real part of an eigenvalue is simply the larger of the two real eigenvalues, $\\lambda_{W, +}$:\n$$ \\max \\text{Re}(\\lambda_W) = \\lambda_{W, +} = \\frac{(w_{\\mathrm{EE}} - w_{\\mathrm{II}}) + \\sqrt{(w_{\\mathrm{EE}} + w_{\\mathrm{II}})^2 + 4w_{\\mathrm{EI}}w_{\\mathrm{IE}}}}{2} $$\nThe critical gain $g^{\\star}$ is the reciprocal of this value. For the system to become unstable for $g > 0$, we require $\\max \\text{Re}(\\lambda_W) > 0$. The expression above is guaranteed to be positive, as the square root term is larger than $|w_{\\mathrm{EE}} - w_{\\mathrm{II}}|$. Therefore, the critical gain is:\n$$ g^{\\star} = \\frac{1}{\\max \\text{Re}(\\lambda_W)} = \\frac{2}{(w_{\\mathrm{EE}} - w_{\\mathrm{II}}) + \\sqrt{(w_{\\mathrm{EE}} + w_{\\mathrm{II}})^2 + 4w_{\\mathrm{EI}}w_{\\mathrm{IE}}}} $$\nThis expression gives the critical gain at which the system loses stability, corresponding to the transition from a stable regime of balanced, noise-driven activity to an unstable regime of runaway excitation.",
            "answer": "$$\n\\boxed{\\frac{2}{(w_{\\mathrm{EE}} - w_{\\mathrm{II}}) + \\sqrt{(w_{\\mathrm{EE}} + w_{\\mathrm{II}})^2 + 4w_{\\mathrm{EI}}w_{\\mathrm{IE}}}}}\n$$"
        },
        {
            "introduction": "This final practice connects neurobiological theories to observable behavior through computational modeling. You will employ the Drift-Diffusion Model (DDM), a cornerstone of cognitive neuroscience, to dissect the components of perceptual decision-making. By fitting the model to hypothetical patient data and comparing competing hypotheses, you will learn to infer specific cognitive process deficits—such as slower evidence accumulation versus impaired response caution—providing a quantitative approach to characterizing clinical symptoms. ",
            "id": "5054340",
            "problem": "You are given a two-choice perceptual decision task scenario modeled by the Drift-Diffusion Model (DDM). The decision variable $X_t$ evolves according to the stochastic differential equation $dX_t = v \\, dt + s \\, dW_t$, where $v$ is the drift rate in units of evidence per second, $s$ is the diffusion (noise) scale in units of evidence per square root second, and $W_t$ is a standard Wiener process. The process starts at $X_0 = 0$ and terminates when $X_t$ hits either absorbing boundary at $+a$ or $-a$, where $a$ is the decision boundary in units of accumulated evidence. The observed reaction time is modeled as the sum of the decision time and a non-decision time $t_0$ (encoding and motor latencies) in seconds.\n\nStarting from the definition of the Drift-Diffusion Model as a one-dimensional stochastic process with absorbing boundaries, and using well-tested facts about first-passage probabilities and mean first-passage times for such processes, derive expressions for the predicted accuracy and mean reaction time as functions of $v$, $a$, $s$, and $t_0$. Implement these predictions in a program and use them to fit patient data under two competing hypotheses:\n\n- Model $\\mathcal{M}_v$: patients have a multiplicative change in drift rate $v_{\\text{patient}} = r_v \\, v_{\\text{control}}$ while keeping $a_{\\text{patient}} = a_{\\text{control}}$ and $t_{0,\\text{patient}} = t_{0,\\text{control}}$.\n- Model $\\mathcal{M}_a$: patients have a multiplicative change in boundary $a_{\\text{patient}} = r_a \\, a_{\\text{control}}$ while keeping $v_{\\text{patient}} = v_{\\text{control}}$ and $t_{0,\\text{patient}} = t_{0,\\text{control}}$.\n\nFor each model, estimate the single free parameter ($r_v$ for $\\mathcal{M}_v$ or $r_a$ for $\\mathcal{M}_a$) by minimizing the sum of squared errors between the model-predicted accuracy and mean reaction time and the observed patient values. Assume independent Gaussian observation noise for accuracy and reaction time and use the Akaike Information Criterion (AIC) $AIC = 2 k + n \\, \\ln(\\text{RSS}/n)$, where $k$ is the number of free parameters and $n$ is the number of observed quantities per case, to compare models. Decide in favor of the model with the smaller $AIC$, using the tie-breaking rule that $\\mathcal{M}_v$ is preferred if $AIC_{\\mathcal{M}_v} \\le AIC_{\\mathcal{M}_a}$.\n\nUse the following test suite. In all cases, the control baseline parameters are $v_{\\text{control}} = 1.0$ (evidence per second), $a_{\\text{control}} = 0.5$ (evidence), $t_{0,\\text{control}} = 0.27$ (seconds), and $s = 1.0$ (evidence per square root second). Patient observations are provided as accuracy (a decimal fraction between $0$ and $1$) and mean reaction time in seconds:\n\n- Case $1$ (happy path, drift reduction explanation expected): observed patient accuracy $= 0.668$, observed patient mean reaction time $= 0.510$ seconds.\n- Case $2$ (happy path, boundary alteration explanation expected): observed patient accuracy $= 0.802$, observed patient mean reaction time $= 0.693$ seconds.\n- Case $3$ (edge case, near-zero drift): observed patient accuracy $= 0.512$, observed patient mean reaction time $= 0.520$ seconds.\n- Case $4$ (speed-accuracy trade-off via lower boundary): observed patient accuracy $= 0.646$, observed patient mean reaction time $= 0.357$ seconds.\n\nAll times must be handled in seconds, and accuracies must be treated as decimal fractions.\n\nYour program should produce a single line of output containing the model selection decisions for the four cases as a comma-separated list of integers enclosed in square brackets. Use the mapping $0 \\rightarrow$ drift reduction preferred (Model $\\mathcal{M}_v$), $1 \\rightarrow$ boundary alteration preferred (Model $\\mathcal{M}_a$). For example, an output could look like $[0,1,0,1]$.\n\nThe required final output format is exactly one line with the list of integers in square brackets. No other text should be printed.",
            "solution": "The solution requires deriving the expressions for accuracy and mean reaction time from the Drift-Diffusion Model (DDM), then implementing a model-fitting procedure to compare two hypotheses about patient deficits.\n\n**1. Derivation of DDM Predictions**\n\nThe decision variable $X_t$ evolves according to $dX_t = v \\, dt + s \\, dW_t$, starting at $X_0 = 0$ with absorbing boundaries at $\\pm a$.\n\n**Accuracy ($P_{acc}$):**\nThe accuracy is the probability of the process hitting the correct boundary at $+a$ before the incorrect boundary at $-a$. For a Wiener process with drift, this first-passage probability is given by the well-known formula:\n$$ P_{acc} = \\frac{1}{1 + \\exp\\left(-\\frac{2va}{s^2}\\right)} $$\nThis formula correctly gives a chance performance of $P_{acc} = 0.5$ when the drift rate $v=0$.\n\n**Mean Reaction Time ($RT$):**\nThe observed reaction time is the sum of the decision time ($DT$) and a non-decision time ($t_0$). The mean decision time is the expected time for the process to hit either boundary. The solution to the relevant differential equation for the mean first-passage time from the origin is:\n$$ DT = \\frac{a}{v} \\tanh\\left(\\frac{va}{s^2}\\right) $$\nThis expression is indeterminate when $v=0$. In this case, we must take the limit as $v \\to 0$. Using the Taylor series for $\\tanh(x) \\approx x$ for small $x$, we get:\n$$ \\lim_{v\\to 0} DT = \\lim_{v\\to 0} \\frac{a}{v} \\left(\\frac{va}{s^2}\\right) = \\frac{a^2}{s^2} $$\nTherefore, the full expression for the mean reaction time is:\n$$ RT = t_0 + \\begin{cases} \\frac{a}{v} \\tanh\\left(\\frac{va}{s^2}\\right)  \\text{if } v \\neq 0 \\\\ \\frac{a^2}{s^2}  \\text{if } v = 0 \\end{cases} $$\n\n**2. Model Fitting and Comparison**\n\nFor each of the two models ($\\mathcal{M}_v$ with free parameter $r_v$ and $\\mathcal{M}_a$ with free parameter $r_a$), the respective parameter is estimated by numerically minimizing a cost function. The cost function is the Residual Sum of Squares (RSS) between the model's predictions and the observed patient data (accuracy and mean RT):\n$$ \\text{RSS} = (P_{acc,pred} - P_{acc,obs})^2 + (RT_{pred} - RT_{obs})^2 $$\nA one-dimensional optimization routine is used to find the parameter value ($r_v$ or $r_a$) that minimizes this RSS.\n\nThe two models are then compared using the Akaike Information Criterion (AIC):\n$$ AIC = 2k + n \\ln\\left(\\frac{\\text{RSS}}{n}\\right) $$\nHere, the number of free parameters is $k=1$ and the number of data points being fit is $n=2$ (accuracy and mean RT). The model with the lower AIC score is considered a better fit to the data, with the specified tie-breaking rule favoring the drift-rate model ($\\mathcal{M}_v$). The final Python code implements this entire procedure for each test case.",
            "answer": "```python\nimport numpy as np\nfrom scipy.optimize import minimize_scalar\n\ndef ddm_predict(v, a, s, t0):\n    \"\"\"\n    Calculates predicted accuracy and mean reaction time for the DDM.\n\n    Args:\n        v (float): Drift rate.\n        a (float): Decision boundary.\n        s (float): Diffusion scale (noise).\n        t0 (float): Non-decision time.\n\n    Returns:\n        tuple: A tuple containing (accuracy, mean_rt).\n    \"\"\"\n    # Accuracy\n    # To avoid potential overflow with large v*a, we handle it.\n    # The term exp(-2*v*a/s**2) is a logistic function argument.\n    arg = -2.0 * v * a / (s**2)\n    if arg > 700:  # np.exp(700) is large but manageable, np.exp(710) overflows\n        accuracy = 0.0\n    else:\n        accuracy = 1.0 / (1.0 + np.exp(arg))\n\n    # Mean Decision Time\n    if abs(v)  1e-9:\n        # Limit as v -> 0\n        mean_dt = a**2 / s**2\n    else:\n        tanh_arg = v * a / s**2\n        mean_dt = (a / v) * np.tanh(tanh_arg)\n    \n    mean_rt = mean_dt + t0\n    \n    return accuracy, mean_rt\n\ndef calculate_aic(rss, k, n):\n    \"\"\"Calculates the Akaike Information Criterion.\"\"\"\n    # Add a small epsilon to avoid log(0) if RSS is exactly zero\n    if rss  1e-30:\n        rss = 1e-30\n    return 2 * k + n * np.log(rss / n)\n\ndef solve():\n    \"\"\"\n    Main function to solve the DDM model comparison problem.\n    \"\"\"\n    v_control = 1.0\n    a_control = 0.5\n    t0_control = 0.27\n    s_control = 1.0\n    \n    test_cases = [\n        {'acc_obs': 0.668, 'rt_obs': 0.510},  # Case 1\n        {'acc_obs': 0.802, 'rt_obs': 0.693},  # Case 2\n        {'acc_obs': 0.512, 'rt_obs': 0.520},  # Case 3\n        {'acc_obs': 0.646, 'rt_obs': 0.357}   # Case 4\n    ]\n\n    results = []\n\n    for case in test_cases:\n        acc_obs, rt_obs = case['acc_obs'], case['rt_obs']\n\n        # --- Model M_v: Drift rate change ---\n        def objective_v(r_v):\n            v_patient = r_v * v_control\n            acc_pred, rt_pred = ddm_predict(v_patient, a_control, s_control, t0_control)\n            return (acc_pred - acc_obs)**2 + (rt_pred - rt_obs)**2\n\n        # We constrain the search to positive multipliers\n        res_v = minimize_scalar(objective_v, bounds=(1e-6, 10.0), method='bounded')\n        rss_v = res_v.fun\n        aic_v = calculate_aic(rss_v, k=1, n=2)\n\n        # --- Model M_a: Boundary change ---\n        def objective_a(r_a):\n            a_patient = r_a * a_control\n            acc_pred, rt_pred = ddm_predict(v_control, a_patient, s_control, t0_control)\n            return (acc_pred - acc_obs)**2 + (rt_pred - rt_obs)**2\n        \n        res_a = minimize_scalar(objective_a, bounds=(1e-6, 10.0), method='bounded')\n        rss_a = res_a.fun\n        aic_a = calculate_aic(rss_a, k=1, n=2)\n\n        # --- Model Comparison ---\n        # Tie-breaking rule: prefer M_v if AICs are equal\n        if aic_v = aic_a:\n            results.append(0)  # M_v is preferred\n        else:\n            results.append(1)  # M_a is preferred\n\n    # Print the final result in the specified format\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        }
    ]
}