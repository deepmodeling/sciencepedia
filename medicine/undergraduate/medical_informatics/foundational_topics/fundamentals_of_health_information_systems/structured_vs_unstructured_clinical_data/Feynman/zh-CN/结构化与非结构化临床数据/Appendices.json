{
    "hands_on_practices": [
        {
            "introduction": "理解结构化和非结构化数据之间差异的最佳方式，莫过于亲手尝试从这两种数据中检索信息。本练习提供了一个合成的电子健康记录（EHR）数据集，要求您分别使用对实验室值的精确结构化查询和对临床笔记的基于相关性的信息检索查询，来识别高钾血症患者。通过这个过程，您将直接体验到基于明确规则的逻辑与基于概率的文本匹配之间的核心区别。",
            "id": "4857063",
            "problem": "给定一个小型、合成的电子健康记录 (EHR) 数据集，其中包含一组患者的结构化实验室测量数据和非结构化临床笔记。任务是形式化两种检索策略来识别患有高钾血症的患者：一种策略操作于结构化实验室数据，另一种策略使用信息检索 (IR) 评分操作于非结构化临床笔记。您的程序必须从头开始实现这两种策略，并在一套参数设置的测试套件上计算比较指标。\n\n基本和核心定义：\n1. 结构化临床数据是关系形式的类型化字段。一条实验室记录是一个元组 $(p, c, v, u, t)$，其中 $p$ 是患者标识符，$c$ 是检测代码，$v$ 是数值检测值，$u$ 是单位，$t$ 是时间索引。对于血清钾，使用检测代码 $c = \\text{\"K\"}$ 和单位 $u = \\text{\"mmol/L\"}$。高钾血症定义为血清钾严格大于以 $\\text{mmol/L}$ 为单位的阈值 $T$。\n2. 非结构化临床数据是自由文本笔记。将每位患者的串联笔记视为一个文档 $D$。信息检索 (IR) 评分基于经过充分测试的组件：词频 (TF)、逆文档频率 (IDF) 和文档长度归一化。Okapi BM25 排序函数将这些组件与饱和度参数 $k_1$ 和长度归一化参数 $b$ 相结合。您的实现必须计算与这些组件一致的分数，且不依赖任何外部资源。\n3. 逆文档频率 (IDF) 是一个函数，它随着语料库大小 $N$ 的增加而增加，并随着词项 $t$ 的文档频率 $n_t$ 的增加而减少。使用一个仅依赖于 $N$ 和 $n_t$ 并且对这些变量单调的 IDF 形式。词频 (TF) 是词项 $t$ 在文档 $D$ 中的计数 $f(t, D)$。文档长度 $|D|$ 是 $D$ 中的词元（token）数量。平均文档长度 $\\overline{|D|}$ 是语料库的平均值。BM25 使用 $k_1$ 来饱和 TF，使用 $b$ 按文档长度进行归一化。一个文档的分数是由 $f(t,D)$, $N$, $n_t$, $|D|$, $\\overline{|D|}$, $k_1$ 和 $b$ 决定的各查询词项贡献的总和。\n\n数据集：\n- 患者: $p \\in \\{101, 102, 103, 104, 105\\}$。\n\n结构化实验室记录 $(p, c, v, u, t)$：\n- $(101, \\text{\"K\"}, 4.0, \\text{\"mmol/L\"}, 2)$, $(101, \\text{\"K\"}, 5.6, \\text{\"mmol/L\"}, 5)$, $(101, \\text{\"K\"}, 5.4, \\text{\"mmol/L\"}, 40)$.\n- $(102, \\text{\"K\"}, 5.5, \\text{\"mmol/L\"}, 3)$, $(102, \\text{\"K\"}, 5.7, \\text{\"mmol/L\"}, 60)$.\n- $(103, \\text{\"K\"}, 6.0, \\text{\"mmol/L\"}, 10)$.\n- $(104, \\text{\"K\"}, 5.3, \\text{\"mmol/L\"}, 4)$, $(104, \\text{\"K\"}, 5.9, \\text{\"mmol/L\"}, 200)$.\n- $(105, \\text{\"K\"}, \\text{no record})$。\n\n非结构化临床笔记（每位患者一个文档，词元化（tokenization）不区分大小写并移除标点符号）：\n- 患者 $101$: $\\text{\"patient has hyperkalemia and elevated potassium k 5.6 mmol l\"}$。\n- 患者 $102$: $\\text{\"potassium borderline high k 5.5 monitor\"}$。\n- 患者 $103$: $\\text{\"no evidence of hyperkalemia potassium normal\"}$。\n- 患者 $104$: $\\text{\"electrolyte panel shows mildly elevated k consider causes\"}$。\n- 患者 $105$: $\\text{\"history of hyperkalemia due to chronic kidney disease recurrent episodes\"}$。\n\n您的程序必须：\n1. 实现一个结构化查询，该查询返回满足以下条件的患者标识符 $p$ 的排序列表：存在一条实验室记录，其 $c = \\text{\"K\"}$，$u = \\text{\"mmol/L\"}$，时间 $t$ 在闭区间 $[t_{\\min}, t_{\\max}]$ 内，且值 $v$ 严格大于以 $\\text{mmol/L}$ 为单位的阈值 $T$。\n2. 实现一个 BM25 风格的 IR 评分方法，该方法：\n   - 对每个文档进行词元化，以计算整个语料库的 $f(t, D)$、 $|D|$ 和 $\\overline{|D|}$。\n   - 计算一个 IDF 值，该值随 $N$ 增加而增加，随 $n_t$ 增加而减少。\n   - 为查询词项列表 $Q$ 计算每个文档的 BM25 分数，该分数是带有参数 $k_1$ 和 $b$ 的词项贡献之和。\n   - 返回其 BM25 分数大于或等于阈值 $\\tau$（无量纲）的患者标识符 $p$ 的排序列表。\n3. 对于每个测试用例，计算重叠计数 $|S \\cap I|$ 和 Jaccard 指数 $J = \\dfrac{|S \\cap I|}{|S \\cup I|}$，结果为浮点数，四舍五入到四位小数，其中 $S$ 是结构化集合，$I$ 是 IR 集合。\n\n单位和表达式：\n- 高钾血症阈值 $T$ 必须以 $\\text{mmol/L}$ 为单位处理。\n- 所有角度都与本问题无关。\n- 将 Jaccard 指数表示为小数。\n\n测试套件：\n为以下参数集计算结果，每个参数集产生一个结果项，包含四个元素：结构化患者列表、IR 患者列表、重叠计数和 Jaccard 指数。\n1. $T = 5.5$ (单位 $\\text{mmol/L}$)，$(t_{\\min}, t_{\\max}) = (0, 30)$，$k_1 = 1.5$，$b = 0.75$，$\\tau = 1.0$，$Q = [\\text{\"hyperkalemia\"}, \\text{\"potassium\"}]$。\n2. $T = 5.5$ (单位 $\\text{mmol/L}$)，$(t_{\\min}, t_{\\max}) = (0, 7)$，$k_1 = 1.2$，$b = 0.75$，$\\tau = 2.0$，$Q = [\\text{\"hyperkalemia\"}]$。\n3. $T = 5.5$ (单位 $\\text{mmol/L}$)，$(t_{\\min}, t_{\\max}) = (0, 365)$，$k_1 = 0.9$，$b = 1.0$，$\\tau = 0.5$，$Q = [\\text{\"elevated\"}, \\text{\"potassium\"}]$。\n4. $T = 5.5$ (单位 $\\text{mmol/L}$)，$(t_{\\min}, t_{\\max}) = (0, 30)$，$k_1 = 0.1$，$b = 0.0$，$\\tau = 0.1$，$Q = [\\text{\"hyperkalemia\"}]$。\n\n最终输出格式：\n您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表，列表中的每个测试用例结果本身也是一个按上述顺序排列的列表。例如，一个有效的输出形状是 $\\text{`[[...],[...],[...],[...]]`}$，并且打印的输出中不能有空格。",
            "solution": "该问题陈述已经过严格验证，被认为是有效的。它在科学上基于医学信息学和信息检索的原理，问题提出得当，具有完整且一致的设定，并以客观、可形式化的语言表达。该任务要求实现两种截然不同的数据检索策略——一种基于结构化查询，另一种基于使用标准算法的非结构化文本分析——并对它们进行定量比较。尽管问题没有明确指出逆文档频率 (IDF) 的确切公式，但提及“Okapi BM25”强烈暗示应使用其标准范式。在该领域，这是一个合理且标准的解释。所有数据和参数都已提供，以确保存在唯一且可验证的解决方案。\n\n解决方案将通过首先形式化数据和两种检索方法，然后实现这些方法来为给定的测试套件计算所需的比较指标来制定。\n\n**1. 数据形式化**\n\n所提供的数据集由两部分组成，针对一组患者 $P = \\{101, 102, 103, 104, 105\\}$。\n\n- **结构化实验室数据**：一组元组 $(p, c, v, u, t)$，其中 $p \\in P$ 是患者标识符，$c$ 是检测代码，$v$ 是数值，$u$ 是单位，$t$ 是时间索引。对于此问题，我们关注的是血清钾，由 $c = \\text{\"K\"}$ 和 $u = \\text{\"mmol/L\"}$ 标识。\n\n- **非结构化临床笔记**：一组自由文本文档 $\\{D_p\\}_{p \\in P}$，其中每个 $D_p$ 代表患者 $p$ 的串联笔记。为处理此文本，应用了词元化程序：将文本转换为小写，根据空白字符分割成词元，并移除每个词元的首尾标点符号。\n\n**2. 结构化检索策略**\n\n此策略识别具有高钾血症实验室证据的患者。如果存在至少一条实验室记录 $(p', c, v, u, t)$ 满足以下条件，则患者 $p$ 被包含在结果集 $S$ 中：\n1. 患者标识符匹配：$p' = p$。\n2. 检测代码标识为血清钾：$c = \\text{\"K\"}$。\n3. 值 $v$ 超过给定阈值 $T$：$v > T$。\n4. 测量时间 $t$ 落在指定的闭区间 $[t_{\\min}, t_{\\max}]$ 内：$t_{\\min} \\le t \\le t_{\\max}$。\n\n最终输出 $S$ 是满足这些条件的唯一患者标识符的排序列表。\n\n**3. 非结构化检索策略 (Okapi BM25)**\n\n此策略根据患者临床笔记与查询的相关性来识别患者，相关性由 Okapi BM25 评分函数衡量。语料库总大小为 $N = |P| = 5$。\n\n首先，对笔记语料库进行预处理。对于每个文档 $D_p$，我们计算其长度 $|D_p|$（词元数量）。整个语料库的平均文档长度为 $\\overline{|D|} = \\frac{1}{N} \\sum_{p \\in P} |D_p|$。\n\n对于给定的查询 $Q$（一个词项列表），文档 $D$ 的 BM25 分数计算为每个查询词项 $t \\in Q$ 的贡献总和：\n$$\n\\text{Score}(D, Q) = \\sum_{t \\in Q} \\text{IDF}(t) \\cdot \\frac{f(t, D) \\cdot (k_1 + 1)}{f(t, D) + k_1 \\cdot \\left(1 - b + b \\cdot \\frac{|D|}{\\overline{|D|}}\\right)}\n$$\n该公式的各组成部分定义如下：\n\n- $f(t, D)$：词项 $t$ 在文档 $D$ 中的词频 (TF)，即 $t$ 在词元化后的文档中出现的次数。\n\n- $\\text{IDF}(t)$：词项 $t$ 的逆文档频率。根据标准 BM25 算法，其计算方式如下：\n$$\n\\text{IDF}(t) = \\ln\\left(\\frac{N - n_t + 0.5}{n_t + 0.5} + 1\\right)\n$$\n其中 $n_t$ 是词项 $t$ 的文档频率，即语料库中包含词项 $t$ 的文档数量。此公式正确反映了随 $N$ 增加而增加、随 $n_t$ 增加而减少的所需属性。\n\n- $k_1$：饱和度参数，通常在 $1.2$ 和 $2.0$ 之间。它控制 TF 项的贡献饱和速度。\n\n- $b$：长度归一化参数，通常约为 $0.75$。当 $b=0$ 时，忽略文档长度。当 $b=1$ 时，文档长度的影响被完全归一化。\n\n如果患者 $p$ 的文档 $D_p$ 的 BM25 分数大于或等于指定的阈值 $\\tau$：$\\text{Score}(D_p, Q) \\ge \\tau$，则该患者被包含在结果集 $I$ 中。最终输出 $I$ 是满足此条件的唯一患者标识符的排序列表。\n\n**4. 比较指标**\n\n为了比较两种检索策略，为每个测试用例计算以下指标，其中 $S$ 和 $I$ 分别是由结构化方法和 IR 方法返回的患者 ID 集合：\n\n- **重叠计数**：两种方法共同识别的患者数量，由两个集合交集的基数给出：$|S \\cap I|$。\n\n- **Jaccard 指数**：衡量两个集合相似度的指标，定义为交集的大小除以并集的大小：\n$$\nJ(S, I) = \\frac{|S \\cap I|}{|S \\cup I|}\n$$\n$J$ 的值是一个介于 0 和 1 之间（含两端）的浮点数，并将报告为四舍五入到四位小数。如果两个集合都为空，它们的并集也为空，Jaccard 指数定义为 $1.0$（尽管有些定义将其设为 $0$；这里我们考虑这将是 $0/0$ 的情况，但问题约束使得这种情况不太可能发生；如果 $S, I$ 为空，$J=0/0$ 是未定义的，但如果它们相等且为空，$J$ 可视为 $1$，让我们遵循标准的计算机科学路径，即空集的并集是空集，因此大小为 0，所以如果交集也为 0，则得出 $0/0$，大多数像 `sklearn` 这样的库将其定义为 $0.0$）。对于非空集合，其中 $S \\cup I$ 也非空，则不需担心除以零的问题。如果一个集合为空而另一个不为空，则 $J=0$。如果两个都为空，$S=I$，所以 $J=1$。但标准做法是当 $|S \\cup I|=0$ 时返回 $0$。如果并集为空，我们将返回 $0.0$。\n\n**5. 执行逻辑**\n\n程序将遍历提供的测试套件。对于每组参数 $(T, t_{\\min}, t_{\\max}, k_1, b, \\tau, Q)$，它将：\n1. 执行结构化查询以生成集合 $S$。\n2. 执行 IR 查询以生成集合 $I$。\n3. 计算重叠计数和 Jaccard 指数。\n4. 将这四个结果（$S$、$I$、重叠计数、Jaccard 指数）整理到一个列表中。\n最后，所有测试套件的结果将被汇总到一个单一列表中，并格式化为指定的字符串输出。",
            "answer": "```python\nimport numpy as np\nimport collections\nimport re\n\ndef solve():\n    \"\"\"\n    Main function to solve the problem, implementing structured and unstructured\n    retrieval strategies for identifying hyperkalemia and computing comparative metrics.\n    \"\"\"\n    #\n    # --- Data Definition ---\n    #\n    patient_ids = [101, 102, 103, 104, 105]\n    \n    # Structured laboratory records: (p, c, v, u, t)\n    lab_records = [\n        (101, \"K\", 4.0, \"mmol/L\", 2), (101, \"K\", 5.6, \"mmol/L\", 5), (101, \"K\", 5.4, \"mmol/L\", 40),\n        (102, \"K\", 5.5, \"mmol/L\", 3), (102, \"K\", 5.7, \"mmol/L\", 60),\n        (103, \"K\", 6.0, \"mmol/L\", 10),\n        (104, \"K\", 5.3, \"mmol/L\", 4), (104, \"K\", 5.9, \"mmol/L\", 200),\n    ]\n\n    # Unstructured clinical notes\n    notes = {\n        101: \"patient has hyperkalemia and elevated potassium k 5.6 mmol l\",\n        102: \"potassium borderline high k 5.5 monitor\",\n        103: \"no evidence of hyperkalemia potassium normal\",\n        104: \"electrolyte panel shows mildly elevated k consider causes\",\n        105: \"history of hyperkalemia due to chronic kidney disease recurrent episodes\",\n    }\n\n    #\n    # --- Test Suite ---\n    #\n    test_cases = [\n        {'T': 5.5, 't_min': 0, 't_max': 30, 'k1': 1.5, 'b': 0.75, 'tau': 1.0, 'Q': [\"hyperkalemia\", \"potassium\"]},\n        {'T': 5.5, 't_min': 0, 't_max': 7, 'k1': 1.2, 'b': 0.75, 'tau': 2.0, 'Q': [\"hyperkalemia\"]},\n        {'T': 5.5, 't_min': 0, 't_max': 365, 'k1': 0.9, 'b': 1.0, 'tau': 0.5, 'Q': [\"elevated\", \"potassium\"]},\n        {'T': 5.5, 't_min': 0, 't_max': 30, 'k1': 0.1, 'b': 0.0, 'tau': 0.1, 'Q': [\"hyperkalemia\"]},\n    ]\n\n    #\n    # --- Helper Functions ---\n    #\n\n    def tokenize(text):\n        \"\"\"Tokenizes text: lowercase, split by space, strip punctuation.\"\"\"\n        return [re.sub(r'^[^\\w\\s]+|[^\\w\\s]+$', '', token) for token in text.lower().split()]\n\n    def structured_query(records, T, t_min, t_max):\n        \"\"\"Performs a structured query on lab records.\"\"\"\n        found_pids = set()\n        for p, c, v, u, t in records:\n            if c == \"K\" and u == \"mmol/L\" and v > T and t_min = t = t_max:\n                found_pids.add(p)\n        return sorted(list(found_pids))\n\n    def ir_query(notes_data, pids, Q, k1, b, tau):\n        \"\"\"Performs an IR query using Okapi BM25.\"\"\"\n        \n        # 1. Preprocessing and Corpus Statistics\n        corpus = {p: tokenize(notes_data.get(p, '')) for p in pids}\n        doc_lengths = {p: len(tokens) for p, tokens in corpus.items()}\n        N = float(len(pids))\n        avg_doc_length = sum(doc_lengths.values()) / N if N > 0 else 0.0\n\n        tf = {p: collections.Counter(tokens) for p, tokens in corpus.items()}\n        \n        # 2. IDF calculation\n        doc_freq = collections.defaultdict(int)\n        for p in pids:\n            for term in set(corpus[p]):\n                if term in Q:\n                    doc_freq[term] += 1\n\n        idf = {}\n        for term in Q:\n            n_t = doc_freq[term]\n            idf_val = np.log(((N - n_t + 0.5) / (n_t + 0.5)) + 1)\n            idf[term] = idf_val\n\n        # 3. BM25 Score Calculation\n        scores = {}\n        for p in pids:\n            score = 0.0\n            doc_len = doc_lengths[p]\n            for term in Q:\n                if term in tf[p]:\n                    f_td = tf[p][term]\n                    \n                    numerator = f_td * (k1 + 1)\n                    denominator = f_td + k1 * (1 - b + b * (doc_len / avg_doc_length))\n                    \n                    tf_component = numerator / denominator\n                    score += idf[term] * tf_component\n            scores[p] = score\n        \n        # 4. Filtering and Sorting\n        result_pids = set()\n        for p, score in scores.items():\n            if score >= tau:\n                result_pids.add(p)\n                \n        return sorted(list(result_pids))\n\n    def calculate_metrics(S, I):\n        \"\"\"Calculates overlap count and Jaccard index.\"\"\"\n        set_S = set(S)\n        set_I = set(I)\n        \n        intersection = set_S.intersection(set_I)\n        union = set_S.union(set_I)\n        \n        overlap_count = len(intersection)\n        \n        if not union:\n            jaccard_index = 0.0\n        else:\n            jaccard_index = float(overlap_count) / len(union)\n        \n        return overlap_count, round(jaccard_index, 4)\n\n    #\n    # --- Main Execution Loop ---\n    #\n    all_results = []\n    for case in test_cases:\n        # Structured query\n        S = structured_query(lab_records, case['T'], case['t_min'], case['t_max'])\n        \n        # IR query\n        I = ir_query(notes, patient_ids, case['Q'], case['k1'], case['b'], case['tau'])\n\n        # Metrics\n        overlap, jaccard = calculate_metrics(S, I)\n        \n        # Format Jaccard to 4 decimal places string\n        jaccard_str = f\"{jaccard:.4f}\"\n        \n        # Instead of direct conversion of float, use the formatted string\n        # Convert the float to string in the final formatting\n        result_item_raw = [S, I, overlap, jaccard]\n        \n        # Manual string construction to match format exactly.\n        s_str = str(result_item_raw[0]).replace(\" \", \"\")\n        i_str = str(result_item_raw[1]).replace(\" \", \"\")\n        overlap_str = str(result_item_raw[2])\n        \n        all_results.append(f\"[{s_str},{i_str},{overlap_str},{jaccard_str}]\")\n\n    # Final print statement\n    print(f\"[{','.join(all_results)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "从数据中提取信息后，下一个关键步骤是评估其质量。本练习将一个用于识别诊断的自然语言处理（NLP）流程的性能与一个结构化数据字段的性能进行比较。通过计算和比较精确率、召回率和$F1$分数等指标，您将对这两种数据模态在准确性和错误类型上的权衡有一个定量的理解。",
            "id": "4857088",
            "problem": "评估一个临床自然语言处理 (NLP) 流程，该流程用于从非结构化临床记录中提取“已记录的慢性肾脏病”这一概念，并以专家病历审查作为参考标准。对于同一概念，电子健康记录 (EHR) 中包含一个结构化的问题列表字段。评估是在 $N = 500$ 次患者就诊记录上进行的。非结构化概念提取的混淆矩阵计数为 $TP = 190$，$FP = 35$，$TN = 245$ 和 $FN = 30$。另外，结构化字段的混淆矩阵计数为 $TP_{s} = 180$，$FP_{s} = 20$，$TN_{s} = 260$ 和 $FN_{s} = 40$。使用基于这些计数的分类指标的基本定义，计算非结构化提取的精确率、召回率、特异性和 $F1$ 分数，以及结构化字段的准确率。然后，将非结构化提取的 $F1$ 分数与结构化字段准确率之间的有符号差值 $\\Delta$ 定义为 $\\Delta = F1_{\\text{unstructured}} - \\text{accuracy}_{\\text{structured}}$。以小数形式报告 $\\Delta$，并将您的最终答案四舍五入到四位有效数字。",
            "solution": "该问题要求计算和比较从患者就诊数据中识别临床概念（“已记录的慢性肾脏病”）的两种不同方法的性能指标。第一种方法是使用自然语言处理 (NLP) 的非结构化数据提取流程，第二种是来自电子健康记录 (EHR) 的结构化数据字段。评估是针对一个包含 $N=500$ 次就诊记录的样本，并以参考标准（专家病历审查）为基准进行的。\n\n首先，我们必须验证问题的陈述。\n\n给定条件如下：\n总就诊次数，$N = 500$。\n\n对于非结构化概念提取：\n真阳性，$TP = 190$。\n假阳性，$FP = 35$。\n真阴性，$TN = 245$。\n假阴性，$FN = 30$。\n\n对于结构化问题列表字段：\n真阳性，$TP_s = 180$。\n假阳性，$FP_s = 20$。\n真阴性，$TN_s = 260$。\n假阴性，$FN_s = 40$。\n\n问题要求进行几项计算：\n1.  非结构化提取的精确率、召回率、特异性和 $F1$ 分数。\n2.  结构化字段的准确率。\n3.  有符号差值 $\\Delta = F1_{\\text{unstructured}} - \\text{accuracy}_{\\text{structured}}$。\n\n在继续之前，我们验证所提供数据的内部一致性。\n对于非结构化数据，混淆矩阵各项之和为 $TP + FP + TN + FN = 190 + 35 + 245 + 30 = 500$，与总就诊次数 $N$ 相符。\n对于结构化数据，其和为 $TP_s + FP_s + TN_s + FN_s = 180 + 20 + 260 + 40 = 500$，也与 $N$ 相符。\n此外，两次评估中参考标准里的实际阳性病例数必须一致。\n对于非结构化评估，参考标准中的阳性病例数为 $P = TP + FN = 190 + 30 = 220$。\n对于结构化评估，阳性病例数为 $P_s = TP_s + FN_s = 180 + 40 = 220$。\n实际阴性病例数也必须一致。\n对于非结构化评估，阴性病例数为 $N_{neg} = TN + FP = 245 + 35 = 280$。\n对于结构化评估，阴性病例数为 $N_{s,neg} = TN_s + FP_s = 260 + 20 = 280$。\n由于 $P = P_s$ 且 $N_{neg} = N_{s,neg}$，并且总就诊次数 $N$ 是一致的，因此该问题定义明确、自洽，并且在科学上基于标准的分类性能评估。该问题被认为是有效的。\n\n现在我们根据其基本定义进行计算。\n\n对于非结构化数据提取：\n预测为阳性的总病例数为 $TP + FP = 190 + 35 = 225$。\n实际为阳性的总病例数为 $TP + FN = 190 + 30 = 220$。\n实际为阴性的总病例数为 $TN + FP = 245 + 35 = 280$。\n\n精确率，衡量所有预测为阳性的病例中被正确预测的比例，其定义为：\n$$ \\text{Precision} = \\frac{TP}{TP + FP} $$\n代入非结构化提取的值：\n$$ \\text{Precision}_{\\text{unstructured}} = \\frac{190}{190 + 35} = \\frac{190}{225} $$\n\n召回率（或灵敏度），衡量实际为阳性的病例中被正确识别的比例，其定义为：\n$$ \\text{Recall} = \\frac{TP}{TP + FN} $$\n代入值：\n$$ \\text{Recall}_{\\text{unstructured}} = \\frac{190}{190 + 30} = \\frac{190}{220} $$\n\n特异性，衡量实际为阴性的病例中被正确识别的比例，其定义为：\n$$ \\text{Specificity} = \\frac{TN}{TN + FP} $$\n代入值：\n$$ \\text{Specificity}_{\\text{unstructured}} = \\frac{245}{245 + 35} = \\frac{245}{280} $$\n\n$F1$ 分数是精确率和召回率的调和平均数。其定义为：\n$$ F1 = 2 \\times \\frac{\\text{Precision} \\times \\text{Recall}}{\\text{Precision} + \\text{Recall}} $$\n使用混淆矩阵计数的更直接的公式是：\n$$ F1 = \\frac{2TP}{2TP + FP + FN} $$\n代入非结构化提取的值：\n$$ F1_{\\text{unstructured}} = \\frac{2 \\times 190}{2 \\times 190 + 35 + 30} = \\frac{380}{380 + 65} = \\frac{380}{445} $$\n\n接下来，我们计算结构化数据字段的准确率。\n准确率衡量所有正确预测（包括真阳性和真阴性）在总病例数中的比例。其定义为：\n$$ \\text{Accuracy} = \\frac{TP + TN}{TP + FP + TN + FN} = \\frac{TP + TN}{N} $$\n使用结构化字段的计数（$TP_s, TN_s$）和总就诊次数 $N$：\n$$ \\text{accuracy}_{\\text{structured}} = \\frac{TP_s + TN_s}{N} = \\frac{180 + 260}{500} = \\frac{440}{500} $$\n\n最后，我们被要求计算有符号差值 $\\Delta$：\n$$ \\Delta = F1_{\\text{unstructured}} - \\text{accuracy}_{\\text{structured}} $$\n代入我们导出的分数形式：\n$$ \\Delta = \\frac{380}{445} - \\frac{440}{500} $$\n为了计算最终值，我们将这些分数转换为它们的小数表示形式。\n$$ F1_{\\text{unstructured}} = \\frac{380}{445} \\approx 0.85393258... $$\n$$ \\text{accuracy}_{\\text{structured}} = \\frac{440}{500} = 0.88 $$\n现在，我们计算差值：\n$$ \\Delta \\approx 0.85393258 - 0.88 = -0.02606741... $$\n问题要求将此结果四舍五入到四位有效数字。第一个非零数字是百分位上的 $2$。四位有效数字是 $2$、$6$、$0$ 和 $6$。第五位有效数字是 $7$。由于 $7 \\geq 5$，我们将第四位有效数字向上取整。\n$$ \\Delta \\approx -0.02607 $$\n这是最终的数值答案。",
            "answer": "$$\\boxed{-0.02607}$$"
        },
        {
            "introduction": "现在，让我们将视野拓宽到系统设计和资源成本。本练习模拟了从标准化结构化模型（OMOP）中检索药物数据与从非结构化笔记中提取数据的查询复杂性。通过比较数据库连接（join）的数量与NLP流程的预期计算操作量，您将学会分析数据表示复杂性与数据检索复杂性之间的基本权衡。",
            "id": "4857095",
            "problem": "一个卫生系统将其药物数据存储在观察性医疗结果合作项目（OMOP）通用数据模型（CDM）中，同时也在电子健康记录（EHR）中存档非结构化的出院小结。你需要以成分级别检索单个患者的所有用药信息，并使用一个简单的操作代理来比较结构化和非结构化方法之间的相对查询复杂度。使用以下定义和假设。\n\n结构化（OMOP CDM）检索的定义和假设：\n- 在OMOP CDM中，用药暴露记录在表 $drug\\_exposure$ 中，使用字段 $drug\\_concept\\_id$。\n- 成分的归总是通过表 $concept\\_ancestor$ 表示的，该表通过字段 $descendant\\_concept\\_id$ 和 $ancestor\\_concept\\_id$ 将一个后代药物概念链接到其祖先成分概念。\n- 概念的人类可读名称在表 $concept$ 中，通过字段 $concept\\_name$ 存储。\n- 目标是为一个由 $person\\_id = p$ 标识的患者，检索所有成分级别的药物名称和暴露日期，且标准化程度仅需满足报告成分及其日期的最低要求。假设 $person\\_id$ 过滤可以直接应用于 $drug\\_exposure$ 表，并且只需要标准的成分名称。\n- 计算为实现上述目标所需的OMOP表之间的等值连接（equi-join）次数，要求在保证正确性的前提下最小化连接次数。\n\n非结构化（出院小结）检索的定义和假设：\n- 非结构化流程检查同一患者的 $n$ 份出院小结。\n- 对于每份出院小结，有 $q$ 的概率存在一个专门的“用药”部分，此时流程需要 $a$ 次操作来提取药物信息；否则，有 $(1-q)$ 的概率该部分不存在，流程需要 $b$ 次操作通过扫描整个文档来提取药物信息。\n- 假设各文档之间相互独立，并且每次“操作”计为一个单位的工作量。\n\n复杂度指数：\n- 将结构化查询复杂度定义为连接数 $J_{s}$。\n- 将非结构化期望操作数定义为所有 $n$ 份出院小结的期望操作总数 $O_{u}$，该值从第一性原理推导得出。\n- 将比较复杂度指数定义为比率 $R = \\frac{O_{u}}{J_{s}}$。\n\n数据：\n- 出院小结数量 $n = 3$。\n- 存在专门用药部分的概率 $q = 0.8$。\n- 如果存在该部分，操作数为 $a = 5$。\n- 如果不存在该部分，操作数为 $b = 20$。\n\n仅使用上述定义和假设，计算比率 $R$。报告一个实数值。不需要四舍五入。",
            "solution": "用户提供了一个有科学依据、定义明确且客观的问题。所有必要的数据和定义都已提供，没有矛盾或含糊之处。该问题是有效的。\n\n解决方案要求计算比较复杂度指数 $R$，它被定义为非结构化期望操作数 $O_u$ 与结构化查询复杂度 $J_s$ 的比值。我们必须分别计算 $J_s$ 和 $O_u$，然后求出它们的比值。\n\n首先，我们确定结构化查询复杂度 $J_s$，它被定义为从OMOP通用数据模型中检索指定数据所需的最少等值连接次数。目标是获取由 $person\\_id = p$ 标识的单个患者的所有成分级别的药物名称及其对应的暴露日期。\n\n1.  起点是 $drug\\_exposure$ 表，其中包含患者的用药暴露信息。我们对此表按特定患者 $person\\_id = p$ 进行筛选。该表为每个用药事件提供了 $drug\\_concept\\_id$ 及相关的暴露日期。\n\n2.  $drug\\_exposure$ 表中的 $drug\\_concept\\_id$ 代表所使用的具体药物，这些药物不一定是成分。为了找到每种药物的活性成分，我们必须使用 $concept\\_ancestor$ 表。该表将后代概念（如具体的药物制剂）映射到其祖先概念（如成分）。因此，需要在 $drug\\_exposure$ 表和 $concept\\_ancestor$ 表之间进行第一次连接。连接条件是 $drug\\_exposure.drug\\_concept\\_id = concept\\_ancestor.descendant\\_concept\\_id$。通过这次连接，我们可以为每次用药暴露检索到 $ancestor\\_concept\\_id$，其中这个祖先就是成分概念。\n\n3.  此时，我们有了成分的概念标识符（$ancestor\\_concept\\_id$）和暴露日期。最后的要求是获取该成分的人类可读名称。$concept$ 表存储了所有概念的名称。因此，需要进行第二次连接。我们将上一步的结果与 $concept$ 表进行连接，连接条件是 $concept\\_ancestor.ancestor\\_concept\\_id = concept.concept\\_id$。由此，我们可以选出 $concept\\_name$。\n\n这个两次连接的过程（$drug\\_exposure \\rightarrow concept\\_ancestor \\rightarrow concept$）是满足所有要求的最简序列。单次连接是不够的。例如，仅将 $drug\\_exposure$ 与 $concept$ 连接将得到所用药物的名称，而不是其成分。因此，结构化查询复杂度，即连接数，为 $J_s = 2$。\n\n接下来，我们计算非结构化期望操作数 $O_u$。这是从 $n$ 份出院小结中提取药物信息所需的总操作数的期望值。\n\n设 $X_i$ 为处理第 $i$ 份小结所需操作数的随机变量，其中 $i = 1, 2, \\ldots, n$。问题陈述，对于任何一份给定的小结：\n-   有 $q$ 的概率存在“用药”部分，操作数为 $a$。\n-   有 $(1-q)$ 的概率该部分不存在，操作数为 $b$。\n\n单份出院小结的期望操作数 $E[X_i]$ 由期望值的定义给出：\n$$E[X_i] = a \\cdot q + b \\cdot (1-q)$$\n所有 $n$ 个文档的总操作数是每个文档操作数的总和，即 $\\sum_{i=1}^{n} X_i$。总期望操作数 $O_u$ 是这个总和的期望值。根据期望的线性性质，并且由于每个文档的处理过程是独立同分布的：\n$$O_u = E\\left[\\sum_{i=1}^{n} X_i\\right] = \\sum_{i=1}^{n} E[X_i] = n \\cdot E[X_i]$$\n代入 $E[X_i]$ 的表达式：\n$$O_u = n(aq + b(1-q))$$\n我们已知以下数值：\n-   出院小结数量，$n = 3$。\n-   部分存在的概率，$q = 0.8$。\n-   如果部分存在，操作数，$a = 5$。\n-   如果部分不存在，操作数，$b = 20$。\n\n将这些值代入 $O_u$ 的方程中：\n$$O_u = 3 \\cdot (5 \\cdot 0.8 + 20 \\cdot (1-0.8))$$\n$$O_u = 3 \\cdot (5 \\cdot 0.8 + 20 \\cdot 0.2)$$\n$$O_u = 3 \\cdot (4 + 4)$$\n$$O_u = 3 \\cdot 8$$\n$$O_u = 24$$\n因此，非结构化期望操作数为 $O_u = 24$。\n\n最后，我们计算比较复杂度指数 $R$，即 $O_u$ 与 $J_s$ 的比值：\n$$R = \\frac{O_u}{J_s}$$\n使用我们计算出的值：\n$$R = \\frac{24}{2} = 12$$\n比率 $R$ 为 $12$。",
            "answer": "$$\\boxed{12}$$"
        }
    ]
}