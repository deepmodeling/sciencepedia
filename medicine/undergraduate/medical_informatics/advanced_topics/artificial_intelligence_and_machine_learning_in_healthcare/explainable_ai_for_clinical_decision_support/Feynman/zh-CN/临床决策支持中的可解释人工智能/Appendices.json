{
    "hands_on_practices": [
        {
            "introduction": "为了真正信任一种解释方法，理解其数学基础至关重要。本练习将引导你通过一个基本的线性模型，从第一性原理出发计算沙普利加性解释（SHAP）值，从而揭开其神秘面纱。通过这个过程，你将理解 SHAP 方法如何借鉴合作博弈论，将模型的预测结果公平地分配给各个特征。",
            "id": "4419874",
            "problem": "一家医院部署了一个临床决策支持系统 (CDSS)，该系统使用一个双特征线性模型来计算败血症风险评分。根据医学伦理指南，该模型必须向临床医生解释以进行安全审计。该模型由 $f(x)=w_{1}x_{1}+w_{2}x_{2}+b$ 给出，其中 $x=(x_{1},x_{2})$ 是标准化的患者特征，因此零向量是一个有意义的参考。解释方法是 SHapley 加性解释 (SHAP)，通过合作博弈论中的夏普利值实现，并将基线输入设置为零向量。考虑一个特定患者，其特征为 $x_{1}=1.5$，$x_{2}=-0.5$，模型参数为 $w_{1}=2$，$w_{2}=-3$，$b=1$。\n\n仅使用合作博弈论中的核心夏普利值定义，以及 SHAP 值的定义（即当缺失特征被设置为其基线值时，一个特征在所有联盟上的预期边际贡献），计算实例 $x=(x_{1},x_{2})$ 的精确 SHAP 值 $\\phi_{1}$ 和 $\\phi_{2}$。然后，通过将归因值求和并与模型输出相对于基线的差异 $f(x)-f(0)$ 进行比较，来验证效率特性。最后，计算标量差异\n$$D=\\left(\\phi_{1}+\\phi_{2}\\right)-\\left(f(x)-f(0)\\right).$$\n将 $D$ 表示为一个精确数值（不进行四舍五入）。不需要单位。",
            "solution": "用户提供了一个问题，要求计算一个双特征线性模型的 SHapley 加性解释 (SHAP) 值。该问题定义明确，在合作博弈论和可解释性人工智能领域具有科学依据。所有必要的参数和定义均已提供。该问题被认为是有效的。\n\n该模型是两个特征 $x_1$ 和 $x_2$ 的线性函数：\n$$f(x) = f(x_1, x_2) = w_1 x_1 + w_2 x_2 + b$$\n给定的参数为 $w_1 = 2$，$w_2 = -3$ 和 $b = 1$。特定的患者实例由特征向量 $x = (1.5, -0.5)$ 给出。\n\nSHAP 值是使用合作博弈论中的夏普利值定义的。这场博弈中的“参与者”是特征，$N = \\{1, 2\\}$。特征联盟 $S \\subseteq N$ 的“价值”是当联盟 $S$ 中的特征设置为实例 $x$ 的实际值，而不在 $S$ 中的特征设置为其基线值时的模型输出。问题指出基线是零向量，因此任何缺失的特征 $x_i$ 都被设置为 $0$。\n\n因此，价值函数 $v(S)$ 定义为模型输出 $f(x')$，其中如果 $i \\in S$，则 $x'_i = x_i$；如果 $i \\notin S$，则 $x'_i = 0$。让我们计算所有可能联盟的价值：\n\\begin{itemize}\n    \\item 对于空联盟 $S = \\emptyset$：两个特征都处于其基线值 ($0$)。\n    $$v(\\emptyset) = f(0, 0) = w_1(0) + w_2(0) + b = b = 1$$\n    \\item 对于联盟 $S = \\{1\\}$：特征 $x_1$ 存在，$x_2$ 处于基线值。\n    $$v(\\{1\\}) = f(x_1, 0) = w_1 x_1 + w_2(0) + b = 2(1.5) + 1 = 3 + 1 = 4$$\n    \\item 对于联盟 $S = \\{2\\}$：特征 $x_2$ 存在，$x_1$ 处于基线值。\n    $$v(\\{2\\}) = f(0, x_2) = w_1(0) + w_2 x_2 + b = -3(-0.5) + 1 = 1.5 + 1 = 2.5$$\n    \\item 对于大联盟 $S = \\{1, 2\\}$：两个特征都存在。\n    $$v(\\{1, 2\\}) = f(x_1, x_2) = w_1 x_1 + w_2 x_2 + b = 2(1.5) + (-3)(-0.5) + 1 = 3 + 1.5 + 1 = 5.5$$\n\\end{itemize}\n\n在一个有 $n$ 个参与者的博弈中，特征 $i$ 的夏普利值 $\\phi_i$ 定义为其对所有可能联盟的边际贡献的加权平均值：\n$$\\phi_i = \\sum_{S \\subseteq N \\setminus \\{i\\}} \\frac{|S|!(n - |S| - 1)!}{n!} [v(S \\cup \\{i\\}) - v(S)]$$\n在我们的例子中，$n=2$，所以公式可以简化。\n\n首先，我们计算特征 1 的 SHAP 值 $\\phi_1$。联盟 $S \\subseteq N \\setminus \\{1\\}$ 包括 $S = \\emptyset$ 和 $S = \\{2\\}$。\n对于 $S = \\emptyset$：$|S|=0$。权重因子是 $\\frac{0!(2-0-1)!}{2!} = \\frac{1 \\cdot 1}{2} = \\frac{1}{2}$。边际贡献是 $v(\\{1\\}) - v(\\emptyset)$。\n对于 $S = \\{2\\}$：$|S|=1$。权重因子是 $\\frac{1!(2-1-1)!}{2!} = \\frac{1 \\cdot 0!}{2} = \\frac{1}{2}$。边际贡献是 $v(\\{1, 2\\}) - v(\\{2\\})$。\n将这些贡献相加得到 $\\phi_1$：\n$$\\phi_1 = \\frac{1}{2} [v(\\{1\\}) - v(\\emptyset)] + \\frac{1}{2} [v(\\{1, 2\\}) - v(\\{2\\})]$$\n代入计算出的值：\n$$\\phi_1 = \\frac{1}{2} [4 - 1] + \\frac{1}{2} [5.5 - 2.5] = \\frac{1}{2}(3) + \\frac{1}{2}(3) = 1.5 + 1.5 = 3$$\n\n接下来，我们计算特征 2 的 SHAP 值 $\\phi_2$。联盟 $S \\subseteq N \\setminus \\{2\\}$ 包括 $S = \\emptyset$ 和 $S = \\{1\\}$。\n对于 $S = \\emptyset$：$|S|=0$。权重因子是 $\\frac{0!(2-0-1)!}{2!} = \\frac{1}{2}$。边际贡献是 $v(\\{2\\}) - v(\\emptyset)$。\n对于 $S = \\{1\\}$：$|S|=1$。权重因子是 $\\frac{1!(2-1-1)!}{2!} = \\frac{1}{2}$。边际贡献是 $v(\\{1, 2\\}) - v(\\{1\\})$。\n将这些贡献相加得到 $\\phi_2$：\n$$\\phi_2 = \\frac{1}{2} [v(\\{2\\}) - v(\\emptyset)] + \\frac{1}{2} [v(\\{1, 2\\}) - v(\\{1\\})]$$\n代入计算出的值：\n$$\\phi_2 = \\frac{1}{2} [2.5 - 1] + \\frac{1}{2} [5.5 - 4] = \\frac{1}{2}(1.5) + \\frac{1}{2}(1.5) = 0.75 + 0.75 = 1.5$$\n因此，SHAP 值为 $\\phi_1 = 3$ 和 $\\phi_2 = 1.5$。线性模型的一个已知属性是 $\\phi_i = w_i x_i$。我们来验证一下：$\\phi_1 = w_1 x_1 = 2(1.5) = 3$ 以及 $\\phi_2 = w_2 x_2 = (-3)(-0.5) = 1.5$。我们使用基本定义进行的计算与此属性一致。\n\n下一步是验证效率特性，该特性指出 SHAP 值的总和等于给定实例的模型输出与基线输出之间的差值：$\\phi_1 + \\phi_2 = f(x) - f(0)$。\nSHAP 值的总和是：\n$$\\phi_1 + \\phi_2 = 3 + 1.5 = 4.5$$\n模型输出的差异是：\n$$f(x) - f(0) = f(1.5, -0.5) - f(0, 0)$$\n我们已经将这些值计算为 $v(\\{1, 2\\})$ 和 $v(\\emptyset)$：\n$$f(x) - f(0) = 5.5 - 1 = 4.5$$\n由于 $4.5 = 4.5$，效率特性得到验证。\n\n最后，我们计算标量差异 $D$：\n$$D = (\\phi_1 + \\phi_2) - (f(x) - f(0))$$\n使用我们刚刚计算出的值：\n$$D = 4.5 - 4.5 = 0$$\n差异为零，这与夏普利值的效率特性所预期的一致。",
            "answer": "$$\n\\boxed{0}\n$$"
        },
        {
            "introduction": "除了 SHAP 之外，另一类强大的解释方法是基于梯度的。本练习将介绍积分梯度（Integrated Gradients, IG），该方法通过累积从基线输入到目标输入路径上的梯度来进行预测归因。通过将其应用于一个简单的非线性模型——修正线性单元（ReLU），你将为理解 IG 在神经网络等复杂模型中的工作原理建立直观认识。",
            "id": "4419848",
            "problem": "在临床决策支持 (CDS) 环境中，一个简化的仅审计模型被用于根据两个标准化的实验室特征对二元风险警报进行分类。为确保问责制符合医学伦理和人工智能 (AI) 安全规范，该系统必须通过积分梯度 (IG) 提供解释。考虑模型 $f(x)=\\max(0,w^\\top x)$，其中 $x\\in\\mathbb{R}^2$ 是两个输入特征，$w\\in\\mathbb{R}^2$ 是固定权重。这是一个带有单个线性预激活的修正线性单元 (ReLU) 输出层。基线是 $x'=\\mathbf{0}$。假设临床输入 $x$ 位于激活区域，即 $w^\\top x>0$。仅使用积分梯度的定义以及 ReLU 和线积分的性质，计算 $x$相对于基线 $x'$ 的积分梯度归因向量，并将其表示为 $w_1,w_2,x_1,x_2$ 的闭式函数。然后，从第一性原理出发，验证该归因对于此模型和基线满足完备性属性。将你的最终归因向量以单行矩阵的形式给出。不需要四舍五入。",
            "solution": "该问题是有效的，因为它在科学上基于可解释人工智能的原理，问题陈述清晰且提供了所有必要信息，并且是可数学形式化的。我们开始进行解答。\n\n对于输入向量 $x \\in \\mathbb{R}^n$ 的第 $i$ 个特征 $x_i$，相对于基线 $x' \\in \\mathbb{R}^n$ 的积分梯度 (IG) 归因定义为：\n$$IG_i(x) = (x_i - x'_i) \\int_{\\alpha=0}^{1} \\frac{\\partial f(x' + \\alpha(x - x'))}{\\partial x_i} \\, d\\alpha$$\n其中 $f$ 是模型函数。\n\n在这个问题中，我们被给定：\n- 模型：$f(x) = \\max(0, w^\\top x)$，其中 $x = \\begin{pmatrix} x_1 \\\\ x_2 \\end{pmatrix}$ 且 $w = \\begin{pmatrix} w_1 \\\\ w_2 \\end{pmatrix}$。\n- 输入 $x \\in \\mathbb{R}^2$。\n- 基线 $x' = \\mathbf{0} = \\begin{pmatrix} 0 \\\\ 0 \\end{pmatrix}$。\n- 输入位于 ReLU 激活区域的条件，即 $w^\\top x = w_1 x_1 + w_2 x_2 > 0$。\n\n首先，我们定义积分路径。从基线 $x'$ 到输入 $x$ 的路径是一条由 $\\alpha \\in [0, 1]$ 参数化的直线：\n$$\\gamma(\\alpha) = x' + \\alpha(x - x') = \\mathbf{0} + \\alpha(x - \\mathbf{0}) = \\alpha x$$\n沿此路径计算的函数值为：\n$$f(\\gamma(\\alpha)) = f(\\alpha x) = \\max(0, w^\\top (\\alpha x)) = \\max(0, \\alpha (w^\\top x))$$\n给定条件 $w^\\top x > 0$ 且在积分路径上 $\\alpha \\geq 0$，项 $\\alpha (w^\\top x)$ 始终为非负。\n$$ \\alpha (w^\\top x) \\geq 0 \\quad \\text{for } \\alpha \\in [0, 1] $$\n因此，对于路径上的任意点，$\\max$ 函数简化为：\n$$f(\\alpha x) = \\alpha (w^\\top x)$$\n这对所有 $\\alpha \\in [0, 1]$ 均成立。\n\n接下来，我们计算函数 $f$ 关于其参数的偏导数。设参数向量为 $y = \\begin{pmatrix} y_1 \\\\ y_2 \\end{pmatrix}$。函数为 $f(y) = \\max(0, w_1 y_1 + w_2 y_2)$。梯度 $\\nabla f(y)$ 是：\n$$\\frac{\\partial f(y)}{\\partial y_i} = \\frac{\\partial}{\\partial y_i} \\max(0, w^\\top y)$$\n使用链式法则，并注意到 $\\text{ReLU}(u)$ 的导数是赫维赛德阶跃函数 $H(u)$（其中当 $u>0$ 时 $H(u)=1$，当 $u\\leq 0$ 时 $H(u)=0$），我们有：\n$$\\frac{\\partial f(y)}{\\partial y_i} = H(w^\\top y) \\cdot \\frac{\\partial}{\\partial y_i}(w^\\top y) = H(w^\\top y) \\cdot w_i$$\n我们需要在积分路径上的点，即 $y = \\alpha x$ 处，计算这个偏导数。赫维赛德函数的参数变为 $w^\\top (\\alpha x) = \\alpha (w^\\top x)$。由于 $w^\\top x > 0$，对于所有 $\\alpha \\in (0, 1]$，此参数严格为正。在 $\\alpha=0$ 时，它为 $0$，此时导数未定义。然而，这一个单点不影响定积分的值。因此，对于积分域中几乎所有的 $\\alpha$，$H(\\alpha(w^\\top x)) = 1$。\n因此，沿路径计算的偏导数为：\n$$\\frac{\\partial f(\\alpha x)}{\\partial x_i} = w_i \\quad \\text{for } \\alpha \\in (0, 1]$$\nIG 公式中的被积函数相对于 $\\alpha$ 是常数。\n\n现在我们计算每个分量的 IG 归因，即 $i=1, 2$。\n项 $(x_i - x'_i)$ 变为 $(x_i - 0) = x_i$。\n\n对于 $i=1$：\n$$IG_1(x) = (x_1 - 0) \\int_{\\alpha=0}^{1} \\frac{\\partial f(\\alpha x)}{\\partial x_1} \\, d\\alpha = x_1 \\int_{\\alpha=0}^{1} w_1 \\, d\\alpha$$\n$$IG_1(x) = x_1 w_1 \\int_{\\alpha=0}^{1} d\\alpha = x_1 w_1 [\\alpha]_{\\alpha=0}^{\\alpha=1} = w_1 x_1 (1 - 0) = w_1 x_1$$\n\n对于 $i=2$：\n$$IG_2(x) = (x_2 - 0) \\int_{\\alpha=0}^{1} \\frac{\\partial f(\\alpha x)}{\\partial x_2} \\, d\\alpha = x_2 \\int_{\\alpha=0}^{1} w_2 \\, d\\alpha$$\n$$IG_2(x) = x_2 w_2 \\int_{\\alpha=0}^{1} d\\alpha = x_2 w_2 [\\alpha]_{\\alpha=0}^{\\alpha=1} = w_2 x_2 (1 - 0) = w_2 x_2$$\n\n积分梯度归因向量是 $\\begin{pmatrix} w_1 x_1 & w_2 x_2 \\end{pmatrix}$。\n\n任务的第二部分是验证该归因满足完备性属性。完备性属性指出，特征归因的总和等于模型在输入 $x$ 处的输出与在基线 $x'$ 处输出之差：\n$$\\sum_{i=1}^{n} IG_i(x) = f(x) - f(x')$$\n在我们的情况下，$n=2$。我们必须验证：\n$$IG_1(x) + IG_2(x) = f(x) - f(x')$$\n\n我们来计算左侧 (LHS)：\n$$\\text{LHS} = IG_1(x) + IG_2(x) = w_1 x_1 + w_2 x_2 = w^\\top x$$\n\n现在，我们来计算右侧 (RHS)：\n模型在输入 $x$ 处的输出为 $f(x) = \\max(0, w^\\top x)$。给定条件 $w^\\top x > 0$，这简化为：\n$$f(x) = w^\\top x$$\n模型在基线 $x' = \\mathbf{0}$ 处的输出为：\n$$f(x') = f(\\mathbf{0}) = \\max(0, w^\\top \\mathbf{0}) = \\max(0, 0) = 0$$\n因此，RHS 为：\n$$\\text{RHS} = f(x) - f(x') = w^\\top x - 0 = w^\\top x$$\n\n比较两侧，我们发现：\n$$\\text{LHS} = w^\\top x$$\n$$\\text{RHS} = w^\\top x$$\n由于 LHS = RHS，在给定条件下，该模型和基线的完备性属性从第一性原理得到验证。归因向量是 $\\begin{pmatrix} w_1 x_1 & w_2 x_2 \\end{pmatrix}$。",
            "answer": "$$ \\boxed{ \\begin{pmatrix} w_1 x_1 & w_2 x_2 \\end{pmatrix} } $$"
        },
        {
            "introduction": "在真实的临床环境中，我们常常会使用多种模型——有些模型简单且具有全局可解释性，而另一些则更复杂但更准确。本练习模拟了一个实际场景：来自简单全局模型和复杂局部模型的解释出现了分歧。通过量化这种差异，你将学会批判性地评估解释的忠实度，并理解为什么捕捉非线性风险（尤其对于非典型患者）可能需要更复杂的模型。",
            "id": "4839506",
            "problem": "一家医院评估用于糖尿病风险预测的全局线性分类器与局部解释方法之间的一致性，重点关注一个极端的患者画像。全局模型是一个正则化逻辑回归模型，它输出新发糖尿病的对数几率，其特征包括年龄（岁）、身体质量指数（BMI, $\\text{kg/m}^2$）和糖化血红蛋白（HbA1c, 百分比）。模型参数为全局系数 $w_{\\text{age}} = 0.015$、$w_{\\text{BMI}} = 0.08$ 和 $w_{\\text{HbA1c}} = 0.9$（单位均为每单位对数几率），以及一个截距（此处不需要）。考虑队列参考特征向量（用作归因基线）$x_{\\text{ref}} = (\\text{age}, \\text{BMI}, \\text{HbA1c}) = (50, 27, 6)$。对于一个极端患者，其特征向量为 $x^{\\ast} = (85, 42, 11)$。\n\n另外，一个梯度提升决策树风险模型通过 Shapley Additive Explanations (SHAP) 方法产生局部归因，这些归因以相同的对数几率尺度报告，并相对于相同的基线。对于该患者，SHAP 归因向量为 $\\phi = (\\phi_{\\text{age}}, \\phi_{\\text{BMI}}, \\phi_{\\text{HbA1c}}) = (0.4, 1.1, 5.3)$。\n\n从核心定义出发，通过将全局线性模型视为相对于基线的加性归因来构建全局线性贡献向量 $g$，即对于每个特征 $i \\in \\{\\text{age}, \\text{BMI}, \\text{HbA1c}\\}$，有 $g_{i} = w_{i}\\,(x^{\\ast}_{i} - x_{\\text{ref},i})$。然后定义差异向量 $d = g - \\phi$。最后，计算该差异的欧几里得范数，\n$$\nD = \\|d\\|_{2} = \\sqrt{d_{\\text{age}}^{2} + d_{\\text{BMI}}^{2} + d_{\\text{HbA1c}}^{2}}.\n$$\n报告 $D$ 的值，四舍五入到四位有效数字。在你的推理中，指明哪个特征对不匹配的贡献最大，并简要解释为什么在使用可解释人工智能（XAI）的临床决策支持中会出现这种不匹配。作为最终答案提交的唯一值是标量 $D$。",
            "solution": "该问题要求计算并解释对于一个特定的患者画像，来自全局线性模型的特征归因与来自复杂非线性模型的局部归因之间的差异。\n\n首先，我们核实问题陈述。\n所有数据和定义都已明确提供：\n- 全局模型系数：$w = (w_{\\text{age}}, w_{\\text{BMI}}, w_{\\text{HbA1c}}) = (0.015, 0.08, 0.9)$。\n- 队列参考特征向量：$x_{\\text{ref}} = (50, 27, 6)$。\n- 极端患者特征向量：$x^{\\ast} = (85, 42, 11)$。\n- SHAP 归因向量：$\\phi = (\\phi_{\\text{age}}, \\phi_{\\text{BMI}}, \\phi_{\\text{HbA1c}}) = (0.4, 1.1, 5.3)$。\n- 全局线性贡献向量 $g$、差异向量 $d$ 和差异范数 $D$ 的定义。\n\n该问题在科学上植根于用于医学信息学的可解释人工智能（XAI）领域，问题设定良好，包含所有必要信息，并且陈述客观。前提事实可靠，场景现实。因此，该问题是有效的，我们继续进行求解。\n\n解题过程包括问题陈述中定义的三个顺序计算步骤。\n\n1.  **构建全局线性贡献向量 $g$。**\n    在线性模型中，每个特征相对于基线 $x_{\\text{ref}}$ 的贡献是该特征的权重与其偏离基线的差值的乘积。首先，我们计算偏差向量 $\\Delta x = x^{\\ast} - x_{\\text{ref}}$。\n    $$\n    \\Delta x_{\\text{age}} = x^{\\ast}_{\\text{age}} - x_{\\text{ref,age}} = 85 - 50 = 35\n    $$\n    $$\n    \\Delta x_{\\text{BMI}} = x^{\\ast}_{\\text{BMI}} - x_{\\text{ref,BMI}} = 42 - 27 = 15\n    $$\n    $$\n    \\Delta x_{\\text{HbA1c}} = x^{\\ast}_{\\text{HbA1c}} - x_{\\text{ref,HbA1c}} = 11 - 6 = 5\n    $$\n    接下来，我们使用公式 $g_i = w_i \\, \\Delta x_i$ 计算全局线性贡献向量 $g$ 的分量。\n    $$\n    g_{\\text{age}} = w_{\\text{age}} \\cdot \\Delta x_{\\text{age}} = 0.015 \\times 35 = 0.525\n    $$\n    $$\n    g_{\\text{BMI}} = w_{\\text{BMI}} \\cdot \\Delta x_{\\text{BMI}} = 0.08 \\times 15 = 1.2\n    $$\n    $$\n    g_{\\text{HbA1c}} = w_{\\text{HbA1c}} \\cdot \\Delta x_{\\text{HbA1c}} = 0.9 \\times 5 = 4.5\n    $$\n    因此，全局线性贡献向量为 $g = (0.525, 1.2, 4.5)$。\n\n2.  **定义差异向量 $d$。**\n    差异向量 $d$ 是线性贡献向量 $g$ 与 SHAP 归因向量 $\\phi$ 之间的逐元素差。\n    $$\n    d = g - \\phi\n    $$\n    $$\n    d_{\\text{age}} = g_{\\text{age}} - \\phi_{\\text{age}} = 0.525 - 0.4 = 0.125\n    $$\n    $$\n    d_{\\text{BMI}} = g_{\\text{BMI}} - \\phi_{\\text{BMI}} = 1.2 - 1.1 = 0.1\n    $$\n    $$\n    d_{\\text{HbA1c}} = g_{\\text{HbA1c}} - \\phi_{\\text{HbA1c}} = 4.5 - 5.3 = -0.8\n    $$\n    差异向量为 $d = (0.125, 0.1, -0.8)$。\n\n3.  **计算差异的欧几里得范数 $D$。**\n    欧几里得范数 $D = \\|d\\|_2$ 计算为 $d$ 各分量平方和的平方根。\n    $$\n    D = \\sqrt{d_{\\text{age}}^{2} + d_{\\text{BMI}}^{2} + d_{\\text{HbA1c}}^{2}}\n    $$\n    $$\n    D = \\sqrt{(0.125)^{2} + (0.1)^{2} + (-0.8)^{2}}\n    $$\n    $$\n    D = \\sqrt{0.015625 + 0.01 + 0.64}\n    $$\n    $$\n    D = \\sqrt{0.665625} \\approx 0.81585844...\n    $$\n    四舍五入到四位有效数字，我们得到：\n    $$\n    D \\approx 0.8159\n    $$\n\n最后，我们找出对不匹配贡献最大的特征并解释结果。差异向量的平方分量为 $d^2 = (0.015625, 0.01, 0.64)$。最大的分量 $0.64$ 对应于 $d_{\\text{HbA1c}}$。因此，**糖化血红蛋白 (HbA1c) 是造成不匹配的最大贡献者**。\n\n对这种不匹配的解释在于两种模型之间的根本差异。全局线性模型假定每个特征都具有恒定的、可加性的效应。例如，它假设 HbA1c 每增加一个百分点，风险的对数几率就精确增加 $0.9$，而不管患者的年龄、BMI 或当前的 HbA1c 水平如何。向量 $g$ 代表了这种简化的线性归因。\n\n相比之下，梯度提升决策树模型能够学习复杂的非线性关系和特征交互作用。SHAP 归因向量 $\\phi$ 为这个复杂模型对特定患者 $x^{\\ast}$ 的预测提供了一个忠实的局部解释。一个大的差异，特别是对于 HbA1c 特征（$d_{\\text{HbA1c}} = -0.8$），表明线性模型的假设对于这个极端患者画像来说是严重不成立的。负号意味着线性模型的归因值（$4.5$）低估了 SHAP 的归因值（$5.3$）。这表明，对于一个 HbA1c 高达 $11\\%$、且年龄和 BMI 也很高的患者，HbA1c 的真实风险贡献（正如更复杂的模型所学到的）要大于简单的线性外推所预测的值。这可能是由于在高 HbA1c 水平下风险的非线性加速，或是风险因素之间的交互效应所致，这两种情况在临床数据中都很常见，但都是简单的线性模型无法捕捉的现象。这种差异凸显了 XAI 中的一个关键概念：一个全局的、简单的解释可能对于复杂模型的局部预测并不忠实，特别是对于处于数据分布极端的个体而言。",
            "answer": "$$\n\\boxed{0.8159}\n$$"
        }
    ]
}