{
    "hands_on_practices": [
        {
            "introduction": "学习型医疗系统依赖于数据驱动决策，因此数据质量至关重要。然而，数据质量并非一个单一的概念，其不同维度——如完整性、正确性和时效性——对临床结果的影响也各不相同。本练习  将指导你构建一个数据质量评分，其权重基于不同数据缺陷可能导致的预期损失，这体现了以患者为中心的学习型医疗系统的核心原则。",
            "id": "4861048",
            "problem": "一个医院网络运营着一个学习型健康系统 (LHS)，该系统根据电子健康记录 (EHR) 数据持续更新高血压管理规则。系统追踪四个数据质量维度，每个维度都在单位区间 $[0,1]$ 上进行度量：完整性 $q_{\\text{comp}}$、正确性 $q_{\\text{corr}}$、及时性 $q_{\\text{time}}$ 和一致性 $q_{\\text{cons}}$。在当前周期中，测量值分别为 $q_{\\text{comp}}=0.88$，$q_{\\text{corr}}=0.92$，$q_{\\text{time}}=0.75$ 和 $q_{\\text{cons}}=0.80$。\n\n为了使数据质量评估与LHS最小化数据驱动决策预期危害的目标保持一致，请考虑以下针对此临床领域和数据管道的经验支持事实：\n- 在一个典型的更新周期中，数据不完整性平均导致 $24$ 次错误分类，每次的预期效用损失为 $1.8$ 个单位。\n- 不正确的记录平均导致 $15$ 次错误分类，每次的预期效用损失为 $2.5$ 个单位。\n- 不及时的数据平均导致 $30$ 次延迟干预，每次的预期效用损失为 $1.2$ 个单位。\n- 跨站点的数据不一致性平均导致 $10$ 次可移植性失败，每次的预期效用损失为 $3.0$ 个单位。\n\n基于预期损失在独立来源上可累加，且在当前操作点附近每个质量维度的微小变化对预期损失的影响是一阶线性的决策理论基础，构建一个标量数据质量得分 $S \\in [0,1]$。该得分使用一个基于各维度对预期损失的边际贡献的合理加权方案来聚合这四个维度。根据给定的测量值计算得出 $S$。将您的最终得分四舍五入到四位有效数字，并表示为 0 和 1 之间的小数。",
            "solution": "该问题要求构建一个标量数据质量得分 $S$，该得分聚合了四个数据质量维度：完整性 ($q_{\\text{comp}}$)、正确性 ($q_{\\text{corr}}$)、及时性 ($q_{\\text{time}}$) 和一致性 ($q_{\\text{cons}}$)。聚合必须基于一个由各维度对总预期效用损失的边际贡献所证明的加权方案。得分 $S$ 必须在单位区间 $[0,1]$ 上。\n\n设四个质量维度表示为 $q_i$，其中 $i \\in \\{\\text{comp}, \\text{corr}, \\text{time}, \\text{cons}\\}$。每个 $q_i \\in [0,1]$，其中 $q_i=1$ 代表完美质量，$q_i=0$ 代表最差质量。总预期效用损失 $L_{\\text{total}}$ 据称是在独立来源上累加的。这意味着总损失采用加性模型，其中每个质量维度都对损失有贡献。\n$$L_{\\text{total}} = L_{\\text{comp}}(q_{\\text{comp}}) + L_{\\text{corr}}(q_{\\text{corr}}) + L_{\\text{time}}(q_{\\text{time}}) + L_{\\text{cons}}(q_{\\text{cons}})$$\n问题指出 $q_i$ 的微小变化对预期损失的影响是线性的。与此以及质量得分的性质相符的最简单模型是，来自维度 $i$ 的损失与其“缺陷”水平成正比，该缺陷水平可以定义为 $d_i = 1 - q_i$。因此，我们可以将每个维度 $i$ 的损失分量建模为：\n$$L_i(q_i) = K_i (1 - q_i)$$\n其中 $K_i$ 是一个常数，代表当质量最差时（$q_i=0$）的最大可能效用损失。这种线性形式完全符合问题的假设。\n\n常数 $K_i$ 可以从提供的经验数据中确定。这些值代表与每种数据质量故障相关的总预期损失。\n对于不完整性：\n损失是由于平均 $N_{\\text{comp}} = 24$ 次错误分类，每次的预期效用损失为 $U_{\\text{comp}} = 1.8$ 个单位。总潜在损失为：\n$$K_{\\text{comp}} = N_{\\text{comp}} \\times U_{\\text{comp}} = 24 \\times 1.8 = 43.2$$\n对于不正确性：\n损失是由于平均 $N_{\\text{corr}} = 15$ 次错误分类，每次的预期效用损失为 $U_{\\text{corr}} = 2.5$ 个单位。总潜在损失为：\n$$K_{\\text{corr}} = N_{\\text{corr}} \\times U_{\\text{corr}} = 15 \\times 2.5 = 37.5$$\n对于不及时性：\n损失是由于平均 $N_{\\text{time}} = 30$ 次延迟干预，每次的预期效用损失为 $U_{\\text{time}} = 1.2$ 个单位。总潜在损失为：\n$$K_{\\text{time}} = N_{\\text{time}} \\times U_{\\text{time}} = 30 \\times 1.2 = 36.0$$\n对于不一致性：\n损失是由于平均 $N_{\\text{cons}} = 10$ 次可移植性失败，每次的预期效用损失为 $U_{\\text{cons}} = 3.0$ 个单位。总潜在损失为：\n$$K_{\\text{cons}} = N_{\\text{cons}} \\times U_{\\text{cons}} = 10 \\times 3.0 = 30.0$$\n\n因此，总预期损失为：\n$$L_{\\text{total}}(q_{\\text{comp}}, q_{\\text{corr}}, q_{\\text{time}}, q_{\\text{cons}}) = \\sum_{i} K_i (1 - q_i)$$\n问题指明，聚合得分 $S$ 的加权方案应“基于它们对预期损失的边际贡献”。质量维度 $q_i$ 对总损失的边际贡献是其偏导数 $\\frac{\\partial L_{\\text{total}}}{\\partial q_i}$。\n$$\\frac{\\partial L_{\\text{total}}}{\\partial q_i} = \\frac{\\partial}{\\partial q_i} \\left( K_i (1 - q_i) \\right) = -K_i$$\n这个边际贡献的量级 $|\\frac{\\partial L_{\\text{total}}}{\\partial q_i}| = K_i$，表示提高质量得分 $q_i$ 以减少总损失的速率。因此，将这些量级用作聚合得分中每个质量维度的权重 $w_i$ 是合乎逻辑的。更高的 $K_i$ 意味着维度 $i$ 对总体效用损失的影响更大，因此在质量得分中应被赋予更高的权重。\n所以，我们设置权重 $w_i = K_i$：\n$w_{\\text{comp}} = 43.2$\n$w_{\\text{corr}} = 37.5$\n$w_{\\text{time}} = 36.0$\n$w_{\\text{cons}} = 30.0$\n\n标量数据质量得分 $S$ 被构建为各个质量维度得分的加权平均：\n$$S = \\frac{\\sum_{i} w_i q_i}{\\sum_{i} w_i} = \\frac{w_{\\text{comp}}q_{\\text{comp}} + w_{\\text{corr}}q_{\\text{corr}} + w_{\\text{time}}q_{\\text{time}} + w_{\\text{cons}}q_{\\text{cons}}}{w_{\\text{comp}} + w_{\\text{corr}} + w_{\\text{time}} + w_{\\text{cons}}}$$\n给定的质量维度测量值为：\n$q_{\\text{comp}} = 0.88$\n$q_{\\text{corr}} = 0.92$\n$q_{\\text{time}} = 0.75$\n$q_{\\text{cons}} = 0.80$\n\n首先，我们计算权重的总和：\n$$\\sum_{i} w_i = 43.2 + 37.5 + 36.0 + 30.0 = 146.7$$\n接下来，我们计算质量得分的加权和：\n$$\\sum_{i} w_i q_i = (43.2 \\times 0.88) + (37.5 \\times 0.92) + (36.0 \\times 0.75) + (30.0 \\times 0.80)$$\n$$\\sum_{i} w_i q_i = 38.016 + 34.5 + 27.0 + 24.0 = 123.516$$\n现在，我们计算得分 $S$：\n$$S = \\frac{123.516}{146.7} \\approx 0.84196319...$$\n问题要求将最终得分四舍五入到四位有效数字。\n$$S \\approx 0.8420$$\n该得分代表了数据质量的聚合度量，根据每个维度缺陷所造成的潜在危害进行加权，并且恰好位于指定的范围 $[0, 1]$ 内。",
            "answer": "$$\\boxed{0.8420}$$"
        },
        {
            "introduction": "一个成功的学习型医疗系统不仅需要能够学习，更需要快速学习。这个学习的速度，即“学习速率”，决定了系统将数据转化为实践改进的效率。本练习  将运用系统工程中的排队论等工具，帮助你对整个学习周期进行定量建模，从而识别限制系统学习速率的瓶颈所在。",
            "id": "4861076",
            "problem": "一家医院采用了学习型医疗系统（Learning Health System, LHS）的概念，在该系统中，通过将常规捕获的数据转化为已实施的变革的迭代循环，不断改进实践。考虑一个改进项目流经一个由六个阶段组成的顺序流水线。该医院的项目到达过程可以建模为齐次泊松过程，每个服务阶段（除预定的治理/培训阶段外）可以建模为马尔可夫到达/马尔可夫服务、单服务器队列（M/M/1）。这些阶段是：\n\n1. 数据摄入：到达率 $\\lambda_{1}$ 项/天，服务率 $\\mu_{1}$ 项/天。\n2. 数据整理与质量保证：到达率 $\\lambda_{2}$ 项/天，服务率 $\\mu_{2}$ 项/天。\n3. 分析与证据生成：到达率 $\\lambda_{3}$ 项/天，服务率 $\\mu_{3}$ 项/天。\n4. 证据审查委员会的治理审查：会议每 $T_{g}$ 天定期举行，超出预定时间门的队列可忽略不计；平均会议持续时间（一旦开始的服务时间）为 $t_{g}$ 天。\n5. 电子健康记录（EHR）配置与部署：到达率 $\\lambda_{5}$ 项/天，服务率 $\\mu_{5}$ 项/天。\n6. 临床医生培训与采纳：培训课程每 $T_{a}$ 天定期举行，平均培训持续时间为 $t_{a}$ 天；培训课程结束后，采纳立即生效。\n\n假设存在稳态流，其中项目的到达过程在整个顺序队列中保持泊松分布且速率相同，每个队列都是稳定的，满足 $\\lambda_{i}  \\mu_{i}$，并且预定的治理和培训阶段由于周期性定时而产生预期的门控延迟。对于一家大型教学医院，使用以下参数：\n\n- $\\lambda_{1} = \\lambda_{2} = \\lambda_{3} = \\lambda_{5} = 30$ 项/天,\n- $\\mu_{1} = 60$ 项/天, $\\mu_{2} = 36$ 项/天, $\\mu_{3} = 32$ 项/天, $\\mu_{5} = 40$ 项/天,\n- $T_{g} = 7$ 天, $t_{g} = 0.5$ 天,\n- $T_{a} = 14$ 天, $t_{a} = 1$ 天。\n\n从泊松到达、指数服务和稳态排队行为的基本定义出发，并在适当的情况下使用排队论和更新理论中经过充分检验的结论，推导从初始数据捕获到有效实践变革的预期总周期时间的封闭形式表达式，并使用给定参数对其进行数值评估。然后，根据您的推导，确定哪些阶段是限制学习速度的瓶颈，并根据利用率和预期延迟贡献解释原因。以天为单位表示最终周期时间。无需四舍五入；请提供精确值。",
            "solution": "问题陈述已经过验证，被认为是合理的。它在科学上基于排队论和更新理论，问题设定良好，参数充分且一致，表述客观。我们可以进行正式求解。\n\n该问题描述了一个模拟学习型医疗系统周期的六阶段顺序过程。由于期望的线性性质，一个项目通过整个系统的总预期周期时间 $E[T_{\\text{total}}]$ 是在每个单独阶段所花费的预期时间之和。\n$$E[T_{\\text{total}}] = \\sum_{i=1}^{6} E[T_i]$$\n我们根据所提供的模型分析每个阶段的预期时间。问题陈述指出，到达过程是一个齐次泊松过程，并且在通过顺序队列时保持泊松分布且速率相同。指定的到达率为 $\\lambda_1 = \\lambda_2 = \\lambda_3 = \\lambda_5 = 30$ 项/天。因此，我们可以定义一个全系统统一的到达率 $\\lambda = 30$ 项/天。\n\n**M/M/1 排队阶段分析（阶段 1、2、3、5）**\n\n阶段 $1$、$2$、$3$ 和 $5$ 被建模为 M/M/1 队列。到达过程在通过这些阶段时保持其泊松性质的假设由 Burke's Theorem 证明是合理的，该定理指出，一个稳定的 M/M/1 队列的离开过程也是一个与到达过程速率相同的泊松过程。\n\n对于一个稳定的 M/M/1 队列，其到达率为 $\\lambda$，服务率为 $\\mu$（其中 $\\lambda  \\mu$），一个项目在系统中花费的总预期时间（在队列中等待加上被服务的时间），即逗留时间 $W$，由以下公式给出：\n$$W = \\frac{1}{\\mu - \\lambda}$$\n我们将此公式应用于四个 M/M/1 阶段中的每一个。\n\n- **阶段 1 (数据摄入):**\n当 $\\lambda = 30$ 项/天，$\\mu_1 = 60$ 项/天时，预期时间为：\n$$E[T_1] = \\frac{1}{\\mu_1 - \\lambda} = \\frac{1}{60 - 30} = \\frac{1}{30} \\text{ 天}$$\n\n- **阶段 2 (数据整理):**\n当 $\\lambda = 30$ 项/天，$\\mu_2 = 36$ 项/天时，预期时间为：\n$$E[T_2] = \\frac{1}{\\mu_2 - \\lambda} = \\frac{1}{36 - 30} = \\frac{1}{6} \\text{ 天}$$\n\n- **阶段 3 (分析):**\n当 $\\lambda = 30$ 项/天，$\\mu_3 = 32$ 项/天时，预期时间为：\n$$E[T_3] = \\frac{1}{\\mu_3 - \\lambda} = \\frac{1}{32 - 30} = \\frac{1}{2} \\text{ 天}$$\n\n- **阶段 5 (EHR 配置):**\n当 $\\lambda = 30$ 项/天，$\\mu_5 = 40$ 项/天时，预期时间为：\n$$E[T_5] = \\frac{1}{\\mu_5 - \\lambda} = \\frac{1}{40 - 30} = \\frac{1}{10} \\text{ 天}$$\n\n**周期性门控阶段分析（阶段 4 和 6）**\n\n阶段 $4$ 和 $6$ 不是连续服务队列，而是周期性过程。到达这样一个阶段的项目必须等待下一个预定事件。\n\n对于一个事件以固定间隔 $T$ 发生、且到达过程遵循泊松过程的系统，更新理论的一个基本结果（通常与检查悖论相关）指出，从任意到达时刻到下一个事件的预期等待时间为 $\\frac{T}{2}$。在该阶段的总时间是这个等待时间加上活动本身的持续时间。\n\n- **阶段 4 (治理审查):**\n会议每 $T_g = 7$ 天定期举行。下一次会议的预期等待时间是 $\\frac{T_g}{2}$。会议的平均持续时间（服务时间）为 $t_g = 0.5$ 天。此阶段的总预期时间为：\n$$E[T_4] = \\frac{T_g}{2} + t_g = \\frac{7}{2} + 0.5 = 3.5 + 0.5 = 4 \\text{ 天}$$\n\n- **阶段 6 (临床医生培训):**\n培训课程每 $T_a = 14$ 天定期举行。下一次培训的预期等待时间是 $\\frac{T_a}{2}$。培训的持续时间是 $t_a = 1$ 天。此阶段的总预期时间为：\n$$E[T_6] = \\frac{T_a}{2} + t_a = \\frac{14}{2} + 1 = 7 + 1 = 8 \\text{ 天}$$\n\n**总预期周期时间**\n\n总预期周期时间的封闭形式表达式是每个阶段预期时间的总和：\n$$E[T_{\\text{total}}] = \\frac{1}{\\mu_1 - \\lambda} + \\frac{1}{\\mu_2 - \\lambda} + \\frac{1}{\\mu_3 - \\lambda} + \\left(\\frac{T_g}{2} + t_g\\right) + \\frac{1}{\\mu_5 - \\lambda} + \\left(\\frac{T_a}{2} + t_a\\right)$$\n代入推导出的值：\n$$E[T_{\\text{total}}] = E[T_1] + E[T_2] + E[T_3] + E[T_4] + E[T_5] + E[T_6]$$\n$$E[T_{\\text{total}}] = \\frac{1}{30} + \\frac{1}{6} + \\frac{1}{2} + 4 + \\frac{1}{10} + 8$$\n为了对分数部分求和，我们找到一个公分母，即 $30$：\n$$E[T_{\\text{total}}] = \\left(\\frac{1}{30} + \\frac{5}{30} + \\frac{15}{30} + \\frac{3}{30}\\right) + 4 + 8$$\n$$E[T_{\\text{total}}] = \\frac{1 + 5 + 15 + 3}{30} + 12 = \\frac{24}{30} + 12$$\n$$E[T_{\\text{total}}] = \\frac{4}{5} + 12 = 0.8 + 12 = 12.8 \\text{ 天}$$\n\n**瓶颈分析**\n\n瓶颈是指对总周期时间贡献过大或利用率过高的阶段，从而限制了整体的“学习速度”。我们基于延迟贡献和利用率两方面进行分析。\n\n1.  **延迟贡献：**\n    - $E[T_1] \\approx 0.033$ 天\n    - $E[T_2] \\approx 0.167$ 天\n    - $E[T_3] = 0.5$ 天\n    - $E[T_4] = 4.0$ 天\n    - $E[T_5] = 0.1$ 天\n    - $E[T_6] = 8.0$ 天\n    - 总计 = $12.8$ 天\n\n    对总延迟贡献最大的阶段是**阶段 6 (临床医生培训)**，贡献了 $8$ 天（占总时间的 $62.5\\%$），以及**阶段 4 (治理审查)**，贡献了 $4$ 天（占总时间的 $31.25\\%$）。这两个阶段加起来占了 $12.8$ 天中的 $12$ 天，即整个周期时间的 $93\\%$ 以上。这里的瓶颈效应是由长的周期性等待时间（$T_a/2 = 7$ 天和 $T_g/2 = 3.5$ 天）引起的。\n\n2.  **M/M/1 阶段的利用率分析：**\n    利用率 $\\rho_i = \\frac{\\lambda}{\\mu_i}$ 衡量一个服务阶段的繁忙程度。当 $\\rho_i \\to 1$ 时，队列长度和等待时间会非线性地增长至无穷大，使该阶段成为一个关键的故障点。\n    - $\\rho_1 = \\frac{30}{60} = 0.5$\n    - $\\rho_2 = \\frac{30}{36} = \\frac{5}{6} \\approx 0.833$\n    - $\\rho_3 = \\frac{30}{32} = \\frac{15}{16} = 0.9375$\n    - $\\rho_5 = \\frac{30}{40} = \\frac{3}{4} = 0.75$\n\n    在 M/M/1 队列中，**阶段 3 (分析)** 的利用率最高，为 $\\rho_3 = 0.9375$。这意味着它在其容量极限附近运行。虽然其当前的延迟贡献（$0.5$ 天）远小于门控阶段，但其高利用率使其成为连续服务流程中最重要的瓶颈。到达率 $\\lambda$ 的任何微小增加都会导致阶段 3 延迟的大幅增加，并且如果到达率增加超过 $32$ 项/天，它将是第一个变得不稳定的 M/M/1 阶段。\n\n**关于瓶颈的结论：**\n限制医院学习速度的主要瓶颈是周期性安排的阶段：**阶段 6 (临床医生培训)** 和 **阶段 4 (治理审查)**，因为它们对总周期时间有重大贡献。在流程驱动的阶段中，**阶段 3 (分析)** 由于其高利用率而成为一个关键瓶颈，使得系统的性能对其容量高度敏感。\n\n要求给出预期总周期时间的最终数值答案。\n$$E[T_{\\text{total}}] = 12.8 \\text{ 天}$$",
            "answer": "$$\\boxed{12.8}$$"
        },
        {
            "introduction": "学习型医疗系统的核心是持续的迭代改进，这通常通过“计划-执行-研究-行动”（PDSA）循环来实现。本练习  将带你完整地体验一次针对临床决策支持（CDS）警报的PDSA循环。你将学习如何系统地分析一个表现不佳的警报（“研究”），并使用精确率和召回率等关键指标来量化改进措施的效果，从而深刻理解数据如何驱动临床实践的持续优化。",
            "id": "4861105",
            "problem": "一家作为学习型医疗系统（LHS）运营的医院，正在对一个用于警示潜在有害药物-药物相互作用的临床决策支持（CDS）警报实施迭代改进周期。该警报的临床医生覆写率很高。作为“计划-执行-研究-行动”（PDSA）周期的一部分，您需要完成两项任务：(i) 概述一个严格的根本原因分析（RCA）流程，以识别警报性能不佳的驱动因素；以及 (ii) 计算在部署建议的修复措施后，关键信息检索指标如何变化。\n\n背景和数据收集如下。临床团队通过回顾性病历审查定义了一个金标准，以确定警报在何时是临床上适用的（阳性）与不适用的（阴性）。在每个时期，都会汇集一个相关的处方会话队列，并将每个警报判定为真阳性或假阳性；根据金标准阳性，将漏报的阳性计为假阴性。\n\n修复前（基线）时期：\n- 审查的相关处方会话总数：$N_{0} = 5{,}000$。\n- 金标准阳性（需要警报的病例）：$P_{0} = 300$。\n- 触发的警报数：$A_{0} = 1{,}500$。\n- 其中，真阳性：$TP_{0} = 120$，假阳性：$FP_{0} = 1{,}380$。\n- 因此，假阴性：$FN_{0} = P_{0} - TP_{0}$。\n\n修复后时期（在根据RCA计划实施了精确的触发逻辑和特定情境的抑制后；假设患病率在两个时期内保持稳定）：\n- 审查的相关处方会话总数：$N_{1} = 5{,}200$。\n- 金标准阳性：$P_{1} = 300$。\n- 触发的警报数：$A_{1} = 400$。\n- 其中，真阳性：$TP_{1} = 150$，假阳性：$FP_{1} = 250$。\n- 因此，假阴性：$FN_{1} = P_{1} - TP_{1}$。\n\n任务A（RCA设计）：简要概述在LHS框架内进行根本原因分析的核心组成部分，以诊断此CDS高覆写率的原因。您的概述应明确指出要查询的数据源和要检查的维度（例如，知识库的时效性、触发器的特异性、工作流程的时机、用户界面、患者特定因素），并应将发现与适合PDSA周期的可修改系统变更联系起来。此部分不进行任何计算。\n\n任务B（指标计算）：仅使用信息检索的基本定义，\n- 根据 $TP_{0}$、$FP_{0}$ 和 $FN_{0}$ 计算基线的精确率和召回率，\n- 根据 $TP_{1}$、$FP_{1}$ 和 $FN_{1}$ 计算修复后的精确率和召回率，\n- 然后计算修复前后的 $F_{1}$ 分数，即精确率和召回率的调和平均值，\n- 最后报告 $F_{1}$ 分数的绝对改进值，定义为 $F_{1,\\text{post}} - F_{1,\\text{pre}}$。\n\n将最终数值答案表示为小数，并四舍五入到四位有效数字。最终答案中不要包含任何单位。",
            "solution": "问题陈述已经过评估，并被确定为有效。它在科学上基于医学信息学和质量改进的原则，特别是学习型医疗系统（LHS）框架。该问题设定良好，为定量部分提供了所有必要数据，为定性部分提供了清晰、客观的说明。所提供的数据在所描述的临床背景下具有内部一致性和合理性。\n\n解决方案将分两部分呈现，对应问题中概述的两项任务。\n\n**任务A：根本原因分析（RCA）设计**\n\n严格的根本原因分析至关重要，它不仅仅是注意到高覆写率，而是要诊断导致警报性能不佳的潜在系统性问题。在LHS框架内，RCA作为“计划-执行-研究-行动”（PDSA）周期的“研究”阶段，为下一个“计划”阶段生成具体的、可操作的假设。此类RCA的核心组成部分概述如下。\n\n中心目标是理解导致大量假阳性（$FP_{0} = 1{,}380$）和相当数量的假阴性（$FN_{0} = 180$）的驱动因素，这些问题表现为警报疲劳、高覆写率和错失的安全机会。该分析必须是多维度的，探究临床决策支持（CDS）系统的各个方面及其与临床环境的相互作用。\n\n1.  **知识库与证据审查**：任何CDS警报的基础都是其知识库。\n    -   **维度**：证据的时效性、相互作用严重性评级的准确性，以及知识对本地患者群体的适用性。\n    -   **数据源**：必须对照当前权威的药理学纲要（如 Lexicomp、Micromedex）和原始文献，对DDI知识数据库本身进行审计。对 $FP_{0}$ 警报样本的审查可能会发现，其底层的DDI定义已经过时，或者按当前标准被认为临床意义不大。例如，某个相互作用可能基于理论机制，但几乎没有临床危害证据。\n    -   **与PDSA的联系**：研究发现可能导致更新、删除或重新分类知识库中的特定DDI规则。\n\n2.  **触发逻辑与情境特异性**：定义不佳的触发逻辑是导致精确率低的主要原因。\n    -   **维度**：过于笼统的触发器，缺乏患者特定或临床情境。这包括未能考虑给药途径（如局部vs.全身）、剂量、治疗持续时间或患者实验室值（如肾功能）。\n    -   **数据源**：对具有统计学意义的 $FP_{0}$ 病例样本进行深入的病历审查。对于每个病例，应分析来自电子健康记录（EHR）的结构化数据——如用药医嘱、实验室结果和患者人口统计信息——以识别模式。例如，分析可能显示，针对特定DDI的 $FP_{0}$ 警报中有 $70\\%$ 发生在一个药物是局部用药而另一个是口服药的情况下，这种相互作用的全身性风险可以忽略不计。\n    -   **与PDSA的联系**：这一分析直接为警报触发算法的优化提供了信息。“执行”阶段可能包括实施更复杂的规则，例如“如果药物A是局部用药则抑制警报”或“仅当钾水平  $5.0$ mmol/L 时触发警报”。\n\n3.  **工作流程整合与时机**：警报的有效性在很大程度上取决于它在何时以及如何呈现给用户。\n    -   **维度**：在工作流程中的时间点（例如，在医嘱录入期间 vs. 在医嘱签署时）、警报发生时临床医生的认知负荷，以及中断的适当性。\n    -   **数据源**：对临床医生进行直接观察（人种学方法）、“出声思考”可用性测试（临床医生在与系统交互时说出他们的想法），以及分析系统审计日志以重建导致警报及其后续覆写的用户操作序列。\n    -   **与PDSA的联系**：这些见解可能导致警报呈现方式的改变，例如将不太关键的警报推迟到摘要视图中显示，或将触发事件从“医嘱创建”更改为“医嘱签核”。\n\n4.  **用户界面（UI）与信息显示**：如果警报内容令人困惑或难以解读，无论其有效性如何，都将被忽略。\n    -   **维度**：所呈现信息的清晰度、建议的可操作性以及响应的便捷性。信息密度过高或缺乏明确的“下一步做什么”的建议都会导致覆写。\n    -   **数据源**：由人因工程专家对警报的用户界面进行启发式评估、对最终用户进行调查和访谈以收集关于警报设计的定性反馈，以及对替代显示格式进行A/B测试。\n    -   **与PDSA的联系**：这会促使重新设计用户界面以提高其清晰度和简洁性，例如，使用图形元素显示风险水平或提供一键式替代药物建议。\n\n通过系统地研究这些维度，LHS团队可以制定具体的、基于证据的干预措施。这些干预措施的成功与否随后在接下来的“研究”阶段进行衡量，如任务B所示。\n\n**任务B：指标计算**\n\nCDS警报的性能使用标准的信息检索指标进行量化：精确率（precision）、召回率（recall）和 $F_{1}$ 分数。\n\n基本定义如下：\n-   精确率 ($Pr$)：检索到的实例中相关的部分所占的比例。$Pr = \\frac{TP}{TP + FP}$。\n-   召回率 ($Re$)，或称灵敏度：所有相关实例中被检索出来的部分所占的比例。$Re = \\frac{TP}{TP + FN} = \\frac{TP}{P}$。\n-   $F_{1}$ 分数：精确率和召回率的调和平均值。$F_{1} = 2 \\times \\frac{Pr \\times Re}{Pr + Re}$。\n\n**修复前（基线）时期指标：**\n\n给定值为 $TP_{0} = 120$，$FP_{0} = 1{,}380$ 和 $P_{0} = 300$。\n首先，根据金标准阳性总数（$P_{0}$）和真阳性数（$TP_{0}$）计算假阴性数（$FN_{0}$）：\n$$FN_{0} = P_{0} - TP_{0} = 300 - 120 = 180$$\n现在，我们计算精确率（$Pr_{0}$）和召回率（$Re_{0}$）：\n$$Pr_{0} = \\frac{TP_{0}}{TP_{0} + FP_{0}} = \\frac{120}{120 + 1{,}380} = \\frac{120}{1{,}500} = 0.08$$\n$$Re_{0} = \\frac{TP_{0}}{TP_{0} + FN_{0}} = \\frac{120}{120 + 180} = \\frac{120}{300} = 0.4$$\n基线 $F_{1}$ 分数（$F_{1, \\text{pre}}$）为：\n$$F_{1, \\text{pre}} = 2 \\times \\frac{Pr_{0} \\times Re_{0}}{Pr_{0} + Re_{0}} = 2 \\times \\frac{0.08 \\times 0.4}{0.08 + 0.4} = 2 \\times \\frac{0.032}{0.48} = \\frac{0.064}{0.48} = \\frac{2}{15}$$\n\n**修复后时期指标：**\n\n给定值为 $TP_{1} = 150$，$FP_{1} = 250$ 和 $P_{1} = 300$。\n首先，计算假阴性数（$FN_{1}$）：\n$$FN_{1} = P_{1} - TP_{1} = 300 - 150 = 150$$\n现在，我们计算精确率（$Pr_{1}$）和召回率（$Re_{1}$）：\n$$Pr_{1} = \\frac{TP_{1}}{TP_{1} + FP_{1}} = \\frac{150}{150 + 250} = \\frac{150}{400} = 0.375$$\n$$Re_{1} = \\frac{TP_{1}}{TP_{1} + FN_{1}} = \\frac{150}{150 + 150} = \\frac{150}{300} = 0.5$$\n修复后 $F_{1}$ 分数（$F_{1, \\text{post}}$）为：\n$$F_{1, \\text{post}} = 2 \\times \\frac{Pr_{1} \\times Re_{1}}{Pr_{1} + Re_{1}} = 2 \\times \\frac{0.375 \\times 0.5}{0.375 + 0.5} = 2 \\times \\frac{0.1875}{0.875} = \\frac{0.375}{0.875} = \\frac{3}{7}$$\n\n**$F_{1}$ 分数的绝对改进值：**\n\n最后的计算是绝对改进值，定义为修复后和修复前 $F_{1}$ 分数之差。\n$$\\Delta F_{1} = F_{1, \\text{post}} - F_{1, \\text{pre}} = \\frac{3}{7} - \\frac{2}{15} = \\frac{3 \\times 15}{7 \\times 15} - \\frac{2 \\times 7}{15 \\times 7} = \\frac{45 - 14}{105} = \\frac{31}{105}$$\n为了提供数值答案，我们计算其小数值：\n$$\\frac{31}{105} \\approx 0.295238095...$$\n根据问题陈述要求四舍五入到四位有效数字，得到 $0.2952$。\n这一正向变化表明CDS警报的整体性能有了实质性改善，平衡了精确率（更少的假警报）和召回率（捕获更多真实事件）的提升。",
            "answer": "$$\\boxed{0.2952}$$"
        }
    ]
}