{
    "hands_on_practices": [
        {
            "introduction": "Before applying any complex de-identification techniques, it is crucial to understand the inherent properties of the data itself. This exercise guides you through a foundational analysis of equivalence classes using basic probability principles. By calculating the expected number of records that share a common set of quasi-identifiers, you will develop an intuition for the \"natural\" level of anonymity in a dataset and the factors that influence re-identification risk from the outset .",
            "id": "4834279",
            "problem": "A health system releases a de-identified dataset of $N=10{,}000$ patient records. The quasi-identifier is defined as the tuple of the generalized attributes: year of birth, sex, and three-digit Zone Improvement Plan (ZIP) code prefix. To reduce re-identification risk, date of birth has been generalized to year of birth, and full ZIP code has been generalized to the three-digit prefix.\n\nAssume the following scientifically grounded, idealized conditions for the purpose of analysis:\n- For each individual, year of birth is uniformly distributed over $100$ distinct values and is independent of the other attributes.\n- Sex is binary with equiprobable categories, independent of the other attributes.\n- The three-digit Zone Improvement Plan (ZIP) code prefix is uniformly distributed over $1{,}000$ distinct prefixes, independent of the other attributes.\n- Records are independently generated according to the same distributional assumptions.\n\nIn the framework of $k$-anonymity, the equivalence class for a record is the set of records that share exactly the same quasi-identifier values. Starting from first principles (basic probability rules and linearity of expectation), derive the expected size of the equivalence class containing a randomly selected record under the assumptions above. Express your final answer as an exact value. No rounding is required.",
            "solution": "The problem is first validated against the specified criteria.\n\n### Step 1: Extract Givens\n-   Total number of patient records: $N=10{,}000$.\n-   The quasi-identifier (QI) is the tuple: (year of birth, sex, three-digit Zone Improvement Plan (ZIP) code prefix).\n-   Year of birth is uniformly distributed over $D_Y = 100$ distinct values.\n-   Sex is binary with equiprobable categories, so it is uniformly distributed over $D_S = 2$ distinct values.\n-   The three-digit ZIP code prefix is uniformly distributed over $D_Z = 1{,}000$ distinct prefixes.\n-   The attributes are mutually independent.\n-   Records are independently generated according to the same distributional assumptions.\n-   The task is to derive the expected size of the equivalence class for a randomly selected record.\n\n### Step 2: Validate Using Extracted Givens\n-   **Scientifically Grounded:** The problem is based on established principles of probability theory and the concept of $k$-anonymity from the field of data privacy and medical informatics. The assumptions of uniform distributions and independence are explicitly stated as \"idealized conditions for the purpose of analysis,\" a standard practice in theoretical modeling.\n-   **Well-Posed:** The problem provides a complete probabilistic model and asks for a specific, well-defined quantity (an expected value). All necessary data ($N$, attribute distributions, independence) are provided to derive a unique solution.\n-   **Objective:** The problem is stated using precise, quantitative, and unbiased language.\n\n### Step 3: Verdict and Action\nThe problem is scientifically sound, well-posed, objective, and contains no internal contradictions or missing information. It is therefore deemed **valid**. The solution process will now proceed.\n\n#### Solution Derivation\n\nThe objective is to find the expected size of an equivalence class for a randomly selected record. An equivalence class is the set of all records sharing the same quasi-identifier (QI).\n\nFirst, we determine the size of the space of all possible quasi-identifiers. The QI is a tuple of three independent attributes.\n-   Number of distinct values for year of birth: $D_Y = 100$.\n-   Number of distinct values for sex: $D_S = 2$.\n-   Number of distinct values for the three-digit ZIP prefix: $D_Z = 1{,}000$.\n\nSince the attributes are independent, the total number of unique QIs, denoted by $M$, is the product of the number of values for each attribute:\n$$M = D_Y \\times D_S \\times D_Z = 100 \\times 2 \\times 1{,}000 = 200{,}000$$\n\nThe problem states that each attribute is uniformly distributed. Due to their independence, any specific QI tuple from the space of all possible QIs is equally likely. The probability, $p$, of a randomly generated record having any specific QI is:\n$$p = \\frac{1}{M} = \\frac{1}{200{,}000}$$\n\nLet the $N$ records in the dataset be denoted by $R_1, R_2, \\ldots, R_N$. The total number of records is $N = 10{,}000$. Let $QI(R_i)$ be the quasi-identifier for record $R_i$.\n\nWe wish to find the expected size of the equivalence class of a randomly selected record. Due to the assumption that all records are independently and identically distributed (i.i.d.), we can simplify the problem by considering the expected size of the equivalence class for a specific record, say $R_1$, without loss of generality. Let $K_1$ be the size of the equivalence class containing record $R_1$.\n\nThe size $K_1$ is the number of records in the dataset (including $R_1$ itself) that have the same QI as $R_1$. We can express $K_1$ using indicator functions:\n$$K_1 = \\sum_{j=1}^{N} I(QI(R_j) = QI(R_1))$$\nwhere $I(\\cdot)$ is the indicator function, which equals $1$ if its argument is true and $0$ otherwise.\n\nWe are asked to find the expected size, $E[K_1]$. Using the linearity of expectation, we have:\n$$E[K_1] = E\\left[\\sum_{j=1}^{N} I(QI(R_j) = QI(R_1))\\right] = \\sum_{j=1}^{N} E[I(QI(R_j) = QI(R_1))]$$\n\nThe expectation of an indicator function is the probability of the event it indicates:\n$$E[I(QI(R_j) = QI(R_1))] = P(QI(R_j) = QI(R_1))$$\nWe must evaluate this probability for two distinct cases.\n\n**Case 1: $j=1$**\nThe term is $P(QI(R_1) = QI(R_1))$. This is a certain event, so its probability is $1$.\n\n**Case 2: $j \\neq 1$**\nHere we need to find the probability that the QI of record $R_j$ matches the QI of record $R_1$. Since the records are generated independently, the value of $QI(R_1)$ does not affect the value of $QI(R_j)$.\nLet's condition on the value of $QI(R_1)$. Let $QI(R_1) = q$, where $q$ is some specific QI value. Since $R_j$ is generated independently, the probability that $QI(R_j)$ takes on this same value $q$ is $p = 1/M$. This reasoning holds for any specific value $q$ that $QI(R_1)$ might take.\nFormally, we can write:\n$$P(QI(R_j) = QI(R_1)) = \\sum_{q \\in \\mathcal{Q}} P(QI(R_j) = q \\text{ and } QI(R_1) = q)$$\nwhere $\\mathcal{Q}$ is the set of all possible QIs. Due to independence of the records:\n$$P(QI(R_j) = QI(R_1)) = \\sum_{q \\in \\mathcal{Q}} P(QI(R_j) = q) P(QI(R_1) = q)$$\nAs established, for any $q$, $P(QI(R_j)=q) = 1/M$ and $P(QI(R_1)=q) = 1/M$.\n$$P(QI(R_j) = QI(R_1)) = \\sum_{q \\in \\mathcal{Q}} \\left(\\frac{1}{M}\\right) \\left(\\frac{1}{M}\\right) = |\\mathcal{Q}| \\times \\frac{1}{M^2} = M \\times \\frac{1}{M^2} = \\frac{1}{M}$$\nSo, for any $j \\neq 1$, the probability of a QI match is $1/M$.\n\nNow, we can assemble the expectation $E[K_1]$. The sum $\\sum_{j=1}^{N}$ has one term where $j=1$ and $N-1$ terms where $j \\neq 1$.\n$$E[K_1] = P(QI(R_1) = QI(R_1)) + \\sum_{j=2}^{N} P(QI(R_j) = QI(R_1))$$\n$$E[K_1] = 1 + \\sum_{j=2}^{N} \\frac{1}{M}$$\nThe summation has $N-1$ identical terms.\n$$E[K_1] = 1 + (N-1) \\frac{1}{M}$$\n\nNow we substitute the numerical values for $N$ and $M$:\n-   $N = 10{,}000$\n-   $M = 200{,}000$\n\n$$E[K_1] = 1 + \\frac{10{,}000 - 1}{200{,}000} = 1 + \\frac{9{,}999}{200{,}000}$$\nTo express this as a single value, we compute the fraction:\n$$\\frac{9{,}999}{200{,}000} = 0.049995$$\nThis division is exact. Therefore, the expected size of the equivalence class is:\n$$E[K_1] = 1 + 0.049995 = 1.049995$$\nThis is the final exact value.",
            "answer": "$$\\boxed{1.049995}$$"
        },
        {
            "introduction": "Privacy models like $l$-diversity aim to enhance the protections of $k$-anonymity by ensuring diversity in sensitive attributes within each equivalence class. However, simply satisfying a rule does not guarantee privacy, especially when the underlying data distribution is imbalanced. This practice demonstrates a critical vulnerability known as a skewness attack, where an adversary can still make high-confidence inferences about individuals even in an $l$-diverse dataset. By quantifying this residual disclosure risk, you will learn to critically evaluate the practical security of a privacy model beyond its formal definition .",
            "id": "4834293",
            "problem": "A hospital releases an anonymized microdata file for research after generalizing quasi-identifiers (QIDs), specifically Age, ZIP code, and Sex, into ranges and prefixes. The data curator enforces distinct $l$-diversity with $l=3$ for the sensitive attribute $S$, defined here as the final diagnosis at discharge. The distinct $l$-diversity requirement states that within each equivalence class induced by the generalized QIDs, there are at least $l$ distinct values of $S$. Consider the following scientifically realistic scenario: the global distribution of $S$ in the population is heavily skewed toward a single value, consistent with epidemiological prevalence patterns. To make this concrete, let $S$ take values from $\\{\\text{Depression}, \\text{Type 2 Diabetes}, \\text{Human Immunodeficiency Virus (HIV) positive}\\}$, and suppose the anonymized dataset is partitioned into three equivalence classes by QID generalization with the following sensitive value counts:\n\n- Equivalence class $E_{1}$: $50$ records, with $45$ having $\\text{Depression}$, $3$ having $\\text{Type 2 Diabetes}$, and $2$ having $\\text{HIV positive}$.\n- Equivalence class $E_{2}$: $30$ records, with $24$ having $\\text{Depression}$, $3$ having $\\text{Type 2 Diabetes}$, and $3$ having $\\text{HIV positive}$.\n- Equivalence class $E_{3}$: $40$ records, with $32$ having $\\text{Depression}$, $4$ having $\\text{Type 2 Diabetes}$, and $4$ having $\\text{HIV positive}$.\n\nThe distinct $l$-diversity criterion with $l=3$ is satisfied in each equivalence class because all three diagnoses appear. However, a skewness attack exploits the global predominance of $\\text{Depression}$ and the concentration of $\\text{Depression}$ within each equivalence class to make highly confident inferences.\n\nAssume an adversary knows the generalized QIDs of a target and thus knows the target’s equivalence class but not the exact record, and adopts a Maximum A Posteriori (MAP) strategy: for an equivalence class $E_{i}$, the adversary guesses the sensitive value $v$ that maximizes $P(S=v \\mid E_{i})$. Define the residual disclosure risk $R$ for a uniformly randomly selected target as the dataset-wide expected MAP success probability, computed as the weighted average of the maximum posterior probabilities across equivalence classes.\n\nCompute $R$ as a single decimal number. Round your answer to four significant figures. No percentage sign should be used in the final answer.",
            "solution": "The user has provided a problem from the field of medical informatics, specifically concerning data privacy and anonymization. The problem is to be validated for its scientific soundness, consistency, and completeness before a solution is attempted.\n\n### Step 1: Extract Givens\n\n- **Anonymity Principle**: Distinct $l$-diversity, with $l=3$.\n- **Definition of Distinct $l$-diversity**: Each equivalence class must contain at least $l$ distinct values for the sensitive attribute $S$.\n- **Sensitive Attribute $S$**: Final diagnosis, with values from the set $\\{\\text{Depression}, \\text{Type 2 Diabetes}, \\text{Human Immunodeficiency Virus (HIV) positive}\\}$.\n- **Equivalence Classes**: The dataset is partitioned into three equivalence classes, $E_1$, $E_2$, and $E_3$.\n- **Data for $E_1$**: Total records $|E_1| = 50$. Counts for $S$: $45$ for $\\text{Depression}$, $3$ for $\\text{Type 2 Diabetes}$, $2$ for $\\text{HIV positive}$.\n- **Data for $E_2$**: Total records $|E_2| = 30$. Counts for $S$: $24$ for $\\text{Depression}$, $3$ for $\\text{Type 2 Diabetes}$, $3$ for $\\text{HIV positive}$.\n- **Data for $E_3$**: Total records $|E_3| = 40$. Counts for $S$: $32$ for $\\text{Depression}$, $4$ for $\\text{Type 2 Diabetes}$, $4$ for $\\text{HIV positive}$.\n- **Adversary Model**: The adversary knows the target's equivalence class and employs a Maximum A Posteriori (MAP) strategy.\n- **MAP Strategy**: For a given equivalence class $E_i$, the adversary guesses the sensitive value $v$ that maximizes the posterior probability $P(S=v \\mid E_i)$.\n- **Target Definition**: A uniformly randomly selected individual from the entire dataset.\n- **Metric to Compute**: Residual disclosure risk $R$, defined as the dataset-wide expected MAP success probability.\n- **Formula for $R$**: $R$ is the weighted average of the maximum posterior probabilities across all equivalence classes.\n- **Required Output Format**: A single decimal number rounded to four significant figures.\n\n### Step 2: Validate Using Extracted Givens\n\n- **Scientific Grounding**: The problem is grounded in the established principles of privacy-preserving data publishing, a subfield of computer science and medical informatics. The concepts of $l$-diversity, equivalence classes, quasi-identifiers, sensitive attributes, and inference attacks (like the skewness attack described) are standard and well-defined in the literature. The premise of skewed data distribution reflecting real-world epidemiological prevalence is scientifically sound. The problem is scientifically valid.\n- **Well-Posedness**: The problem provides all necessary numerical data (record counts for each diagnosis in each class) and a precise mathematical definition for the quantity to be computed ($R$). The calculation is deterministic and leads to a unique solution. The problem is well-posed.\n- **Objectivity**: The problem is stated using formal, unambiguous terminology from the relevant scientific domain. There are no subjective or value-laden statements. The problem is objective.\n- **Completeness and Consistency**: The data provided is complete and internally consistent. For each equivalence class, the sum of the counts of sensitive values equals the total number of records in that class (e.g., for $E_1$, $45 + 3 + 2 = 50$). The statement that distinct $l$-diversity with $l=3$ is satisfied is consistent with the data, as each class contains all three diagnoses. The problem is complete and consistent.\n\n### Step 3: Verdict and Action\n\nThe problem statement is valid. It is scientifically grounded, well-posed, objective, and internally consistent. A solution will now be derived.\n\n### Solution\n\nThe objective is to compute the residual disclosure risk, $R$, defined as the dataset-wide expected Maximum A Posteriori (MAP) success probability. The target individual is selected uniformly at random from the entire dataset.\n\nLet $N$ be the total number of records in the dataset. Let $N_i$ be the number of records in equivalence class $E_i$. The total number of records is the sum of records in each class:\n$$ N = N_1 + N_2 + N_3 = 50 + 30 + 40 = 120 $$\n\nThe probability that a uniformly randomly selected individual belongs to equivalence class $E_i$ is given by $P(E_i) = \\frac{N_i}{N}$.\n$$ P(E_1) = \\frac{50}{120} $$\n$$ P(E_2) = \\frac{30}{120} $$\n$$ P(E_3) = \\frac{40}{120} $$\n\nThe adversary uses a MAP strategy. For an individual in equivalence class $E_i$, the adversary's success probability is the maximum posterior probability of any sensitive value $v$, $\\max_{v} P(S=v \\mid E_i)$. This probability is calculated as the frequency of the most common sensitive value in that class.\n\nLet us calculate this maximum probability for each equivalence class:\n\nFor equivalence class $E_1$:\nThe counts of sensitive values are $\\{45, 3, 2\\}$ for a total of $N_1 = 50$ records. The posterior probabilities are:\n$$ P(S=\\text{Depression} \\mid E_1) = \\frac{45}{50} = 0.9 $$\n$$ P(S=\\text{Type 2 Diabetes} \\mid E_1) = \\frac{3}{50} = 0.06 $$\n$$ P(S=\\text{HIV positive} \\mid E_1) = \\frac{2}{50} = 0.04 $$\nThe maximum posterior probability for $E_1$ is:\n$$ \\max_{v} P(S=v \\mid E_1) = 0.9 $$\n\nFor equivalence class $E_2$:\nThe counts of sensitive values are $\\{24, 3, 3\\}$ for a total of $N_2 = 30$ records. The posterior probabilities are:\n$$ P(S=\\text{Depression} \\mid E_2) = \\frac{24}{30} = 0.8 $$\n$$ P(S=\\text{Type 2 Diabetes} \\mid E_2) = \\frac{3}{30} = 0.1 $$\n$$ P(S=\\text{HIV positive} \\mid E_2) = \\frac{3}{30} = 0.1 $$\nThe maximum posterior probability for $E_2$ is:\n$$ \\max_{v} P(S=v \\mid E_2) = 0.8 $$\n\nFor equivalence class $E_3$:\nThe counts of sensitive values are $\\{32, 4, 4\\}$ for a total of $N_3 = 40$ records. The posterior probabilities are:\n$$ P(S=\\text{Depression} \\mid E_3) = \\frac{32}{40} = 0.8 $$\n$$ P(S=\\text{Type 2 Diabetes} \\mid E_3) = \\frac{4}{40} = 0.1 $$\n$$ P(S=\\text{HIV positive} \\mid E_3) = \\frac{4}{40} = 0.1 $$\nThe maximum posterior probability for $E_3$ is:\n$$ \\max_{v} P(S=v \\mid E_3) = 0.8 $$\n\nThe residual disclosure risk $R$ is the expected value of these maximum probabilities, weighted by the probability of an individual belonging to each class. The formula is:\n$$ R = \\sum_{i=1}^{3} P(E_i) \\cdot \\max_{v} P(S=v \\mid E_i) $$\nSubstituting the values we have calculated:\n$$ R = P(E_1) \\cdot \\max_{v} P(S=v \\mid E_1) + P(E_2) \\cdot \\max_{v} P(S=v \\mid E_2) + P(E_3) \\cdot \\max_{v} P(S=v \\mid E_3) $$\n$$ R = \\left(\\frac{50}{120}\\right) \\cdot (0.9) + \\left(\\frac{30}{120}\\right) \\cdot (0.8) + \\left(\\frac{40}{120}\\right) \\cdot (0.8) $$\nWe can factor out $\\frac{1}{120}$:\n$$ R = \\frac{1}{120} \\left[ 50 \\cdot (0.9) + 30 \\cdot (0.8) + 40 \\cdot (0.8) \\right] $$\n$$ R = \\frac{1}{120} \\left[ 45 + 24 + 32 \\right] $$\n$$ R = \\frac{1}{120} \\left[ 101 \\right] $$\n$$ R = \\frac{101}{120} $$\n\nTo provide the answer as a decimal rounded to four significant figures, we perform the division:\n$$ R = 101 \\div 120 \\approx 0.841666... $$\nRounding to four significant figures gives:\n$$ R \\approx 0.8417 $$\nThis value represents the average probability that an adversary can correctly guess the sensitive diagnosis of a randomly chosen person in the dataset, given knowledge of their equivalence class. The high value of $R$ demonstrates the weakness of distinct $l$-diversity in the presence of skewed data, a phenomenon known as a skewness attack.",
            "answer": "$$\n\\boxed{0.8417}\n$$"
        },
        {
            "introduction": "The limitations of syntactic models like $k$-anonymity and $l$-diversity motivated the development of Differential Privacy (DP), a rigorous, mathematical framework that provides provable privacy guarantees regardless of an adversary's background knowledge. This exercise takes you into the engine room of DP by having you derive the parameters of the Laplace mechanism, one of its most fundamental tools. By calculating the precise amount of statistical noise needed to protect a query's output, you will gain a concrete understanding of how DP quantifies and enforces privacy .",
            "id": "4834309",
            "problem": "A hospital plans to publicly release a single aggregate statistic: the number of patients in a de-identified registry whose latest fasting plasma glucose exceeds a clinical threshold. To reduce the risk of re-identification from this counting query, the institution will use the Laplace mechanism from Differential Privacy (DP). Let the query be a function $f$ mapping a dataset $D$ to a nonnegative integer count. Consider neighboring datasets that differ by adding or removing one individual record. The hospital’s privacy office requires $\\epsilon$-Differential Privacy with target $\\epsilon = 0.5$. Assume the global sensitivity of the counting query is $\\Delta = 1$ under the specified neighboring relation.\n\nStarting from the definition of $\\epsilon$-Differential Privacy (DP) and the probability density function of the zero-mean Laplace distribution with scale parameter $b$, derive the smallest scale $b$ for the Laplace mechanism that guarantees $\\epsilon$-DP for a counting query of sensitivity $\\Delta$. Then, derive the standard deviation of the added Laplace noise as a function of $b$, and compute its value at the derived $b$.\n\nExpress your final answer as the ordered pair $(b, \\sigma)$, where $b$ is the minimal sufficient scale and $\\sigma$ is the standard deviation of the added noise, in that order. Do not round; give exact values without units.",
            "solution": "The user wants to solve a problem based on the principles of Differential Privacy, specifically using the Laplace mechanism. The task is to derive the necessary scale parameter $b$ for the Laplace noise and the corresponding standard deviation $\\sigma$ of that noise.\n\n### Step 1: Problem Validation\n\n**1.1. Extract Givens**\n- **Framework**: $\\epsilon$-Differential Privacy (DP).\n- **Query type**: A counting query, represented by a function $f$ mapping a dataset $D$ to a non-negative integer.\n- **Neighboring datasets**: Datasets that differ by the addition or removal of one individual record.\n- **Privacy parameter**: $\\epsilon = 0.5$.\n- **Global sensitivity**: $\\Delta = 1$ for the counting query under the specified neighboring relation.\n- **Mechanism**: The Laplace mechanism, which adds noise drawn from a zero-mean Laplace distribution with scale parameter $b$.\n- **Task**:\n    1. Derive the smallest scale $b$ that guarantees $\\epsilon$-DP.\n    2. Derive the standard deviation $\\sigma$ of the Laplace noise as a function of $b$.\n    3. Compute the numerical value of $\\sigma$ for the derived $b$.\n    4. Express the final answer as the ordered pair $(b, \\sigma)$.\n\n**1.2. Validate Using Extracted Givens**\n- **Scientific Grounding**: The problem is firmly rooted in the mathematical theory of Differential Privacy, a well-established and widely used framework in computer science and statistics for privacy-preserving data analysis. The Laplace mechanism, global sensitivity, and the $\\epsilon$-DP definition are all standard, rigorously defined concepts. The problem is scientifically sound.\n- **Well-Posedness**: The problem provides all necessary information ($\\epsilon$, $\\Delta$, the type of mechanism) to derive the requested quantities ($b$, $\\sigma$). The question is specific, and a unique, meaningful solution exists.\n- **Objectivity**: The problem statement is objective and uses precise, formal language. There are no subjective or ambiguous terms.\n\n**1.3. Verdict and Action**\nThe problem is valid. It is scientifically grounded, well-posed, and objective. I will proceed with the solution.\n\n### Step 2: Solution Derivation\n\nThe core of the problem lies in satisfying the definition of $\\epsilon$-Differential Privacy. A randomized mechanism $\\mathcal{M}$ provides $\\epsilon$-DP if for any two neighboring datasets $D_1$ and $D_2$, and for any set of possible outputs $S$, the following inequality holds:\n$$ \\Pr[\\mathcal{M}(D_1) \\in S] \\le \\exp(\\epsilon) \\cdot \\Pr[\\mathcal{M}(D_2) \\in S] $$\nFor mechanisms that produce a continuous output, this is often demonstrated by analyzing the ratio of the probability density functions (PDFs).\n\nThe Laplace mechanism $\\mathcal{M}$ perturbs the true output of a query $f(D)$ by adding noise drawn from a Laplace distribution. The noisy output is given by:\n$$ \\mathcal{M}(D) = f(D) + Y $$\nwhere $Y$ is a random variable following a zero-mean Laplace distribution, $Y \\sim \\text{Lap}(0, b)$. The PDF of this distribution is:\n$$ \\text{pdf}(y|b) = \\frac{1}{2b} \\exp\\left(-\\frac{|y|}{b}\\right) $$\nLet the noisy output be $z$. The probability of observing the output $z$ given the dataset $D$ is the probability that the noise $Y$ took the value $z - f(D)$. Therefore, the PDF for the output $z$ is:\n$$ \\Pr[\\mathcal{M}(D) = z] = \\frac{1}{2b} \\exp\\left(-\\frac{|z - f(D)|}{b}\\right) $$\n\nTo satisfy the $\\epsilon$-DP condition, we examine the ratio of probabilities for any two neighboring datasets $D_1$ and $D_2$ and any possible output $z$:\n$$ \\frac{\\Pr[\\mathcal{M}(D_1) = z]}{\\Pr[\\mathcal{M}(D_2) = z]} = \\frac{\\frac{1}{2b} \\exp\\left(-\\frac{|z - f(D_1)|}{b}\\right)}{\\frac{1}{2b} \\exp\\left(-\\frac{|z - f(D_2)|}{b}\\right)} $$\n$$ = \\exp\\left(-\\frac{|z - f(D_1)|}{b} + \\frac{|z - f(D_2)|}{b}\\right) $$\n$$ = \\exp\\left(\\frac{|z - f(D_2)| - |z - f(D_1)|}{b}\\right) $$\nBy the reverse triangle inequality, $|a| - |b| \\le |a - b|$. Let $a = z - f(D_2)$ and $b = z - f(D_1)$. Then:\n$$ |z - f(D_2)| - |z - f(D_1)| \\le |(z - f(D_2)) - (z - f(D_1))| = |f(D_1) - f(D_2)| $$\nThe global sensitivity $\\Delta$ is defined as the maximum possible value of this difference over all possible pairs of neighboring datasets:\n$$ \\Delta = \\max_{D_1, D_2} |f(D_1) - f(D_2)| $$\nSubstituting this into our inequality, we can bound the numerator of the exponent:\n$$ |z - f(D_2)| - |z - f(D_1)| \\le \\Delta $$\nTherefore, the ratio of probabilities is bounded by:\n$$ \\frac{\\Pr[\\mathcal{M}(D_1) = z]}{\\Pr[\\mathcal{M}(D_2) = z]} \\le \\exp\\left(\\frac{\\Delta}{b}\\right) $$\nTo satisfy the $\\epsilon$-DP definition, this upper bound must be less than or equal to $\\exp(\\epsilon)$:\n$$ \\exp\\left(\\frac{\\Delta}{b}\\right) \\le \\exp(\\epsilon) $$\nTaking the natural logarithm of both sides gives:\n$$ \\frac{\\Delta}{b} \\le \\epsilon $$\nTo find the smallest scale parameter $b$ that guarantees this condition, we choose the tightest possible bound, which is an equality:\n$$ \\frac{\\Delta}{b} = \\epsilon $$\nSolving for $b$, we obtain the minimal sufficient scale:\n$$ b = \\frac{\\Delta}{\\epsilon} $$\nThe problem states that the global sensitivity is $\\Delta = 1$ and the privacy parameter is $\\epsilon = 0.5$. Substituting these values:\n$$ b = \\frac{1}{0.5} = 2 $$\n\nNext, we need to find the standard deviation, $\\sigma$, of the added Laplace noise. The variance of a Laplace distribution with mean $\\mu$ and scale $b$, $\\text{Lap}(\\mu, b)$, is given by the formula:\n$$ \\text{Var}(Y) = 2b^2 $$\nThe standard deviation $\\sigma$ is the square root of the variance:\n$$ \\sigma = \\sqrt{\\text{Var}(Y)} = \\sqrt{2b^2} = b\\sqrt{2} $$\nThis gives the standard deviation as a function of the scale parameter $b$.\n\nFinally, we compute the numerical value of $\\sigma$ using the derived value of $b = 2$:\n$$ \\sigma = 2\\sqrt{2} $$\n\nThe requested answer is the ordered pair $(b, \\sigma)$. We have found $b=2$ and $\\sigma=2\\sqrt{2}$.",
            "answer": "$$\n\\boxed{\\begin{pmatrix} 2 & 2\\sqrt{2} \\end{pmatrix}}\n$$"
        }
    ]
}