{
    "hands_on_practices": [
        {
            "introduction": "At the core of patient matching lies the comparison of individual data fields, with patient names being a frequent source of error due to typos and variations. To move beyond a simple 'same/not same' comparison, we use string similarity metrics that quantify how close two strings are. This exercise  provides hands-on practice with two fundamental metrics, Jaro-Winkler similarity and Levenshtein distance, revealing how their underlying designs make them better suited for specific types of common data entry errors.",
            "id": "4851050",
            "problem": "A health system’s Master Patient Index is being audited to reduce duplicate records created by typographical errors in patient names. Consider the candidate name pair \"Micheal\" and \"Michael\" drawn from the same Electronic Health Record (EHR) encounter. Using only standard, widely accepted definitions from record linkage and string metric theory as the fundamental base, perform the following:\n\n1. Compute the Jaro–Winkler similarity between the two strings using the conventional Jaro–Winkler parameters: scaling factor $p = 0.1$ and a maximum common-prefix length cap of $4$ characters.\n2. Compute the Levenshtein distance between the two strings under the standard unit-cost model where insertion, deletion, and substitution each have cost $1$.\n3. Briefly reason from first principles why one of these metrics more faithfully captures common transposition errors in names during patient identification workflows.\n\nExpress the final numerical results as follows:\n- Provide the Jaro–Winkler similarity as an exact rational number if possible (no rounding).\n- Provide the Levenshtein distance as an integer.\n- Return the two results in a single row matrix in the order $\\bigl(\\text{Jaro–Winkler similarity}, \\text{Levenshtein distance}\\bigr)$.\n\nNo rounding is required, and no units are to be included in the final answer.",
            "solution": "This problem requires the computation and comparison of two standard string similarity metrics, Jaro–Winkler similarity and Levenshtein distance, for the pair of strings $s_1 = \\text{\"Micheal\"}$ and $s_2 = \\text{\"Michael\"}$. The analysis will be performed from first principles as defined in record linkage theory.\n\nLet the two strings be $s_1 = \\text{\"Micheal\"}$ and $s_2 = \\text{\"Michael\"}$. The lengths of the strings are $|s_1| = 7$ and $|s_2| = 7$.\n\n**1. Jaro–Winkler Similarity Computation**\n\nThe Jaro–Winkler similarity, $d_w$, is an enhancement of the Jaro similarity, $d_j$. We first compute the Jaro similarity.\n\nThe Jaro similarity is defined as:\n$$d_j = \\begin{cases} 0 & \\text{if } m = 0 \\\\ \\frac{1}{3} \\left( \\frac{m}{|s_1|} + \\frac{m}{|s_2|} + \\frac{m-t}{m} \\right) & \\text{if } m > 0 \\end{cases}$$\nwhere $m$ is the number of matching characters and $t$ is half the number of transpositions.\n\n*   **Matching Characters ($m$)**: Two characters from $s_1$ and $s_2$ are considered matching if they are the same and their positions are no farther than $\\left\\lfloor \\frac{\\max(|s_1|, |s_2|)}{2} \\right\\rfloor - 1$.\n    For these strings, the maximum distance is $\\lfloor \\frac{7}{2} \\rfloor - 1 = 3 - 1 = 2$.\n    - $s_1$: M i c h **e a** l\n    - $s_2$: M i c h **a e** l\n    We compare characters within the allowed distance:\n    - `M` in $s_1$ matches `M` in $s_2$ (distance $0$).\n    - `i` in $s_1$ matches `i` in $s_2$ (distance $0$).\n    - `c` in $s_1$ matches `c` in $s_2$ (distance $0$).\n    - `h` in $s_1$ matches `h` in $s_2$ (distance $0$).\n    - `e` in $s_1$ (pos 4) matches `e` in $s_2$ (pos 5) (distance $1 \\le 2$).\n    - `a` in $s_1$ (pos 5) matches `a` in $s_2$ (pos 4) (distance $1 \\le 2$).\n    - `l` in $s_1$ matches `l` in $s_2$ (distance $0$).\n    All $7$ characters from $s_1$ have a match in $s_2$. Thus, the number of matching characters is $m=7$.\n\n*   **Transpositions ($t$)**: A transposition is a pair of matching characters that appear in a different order in the two strings. We align the sequence of matching characters from each string.\n    - Sequence of matches from $s_1$: `(M, i, c, h, e, a, l)`\n    - Sequence of matches from $s_2$: `(M, i, c, h, a, e, l)`\n    By comparing these two sequences, we find that the characters at the 5th and 6th positions (`e`, `a`) are swapped. The number of characters that do not align is $2$. The number of transpositions $t$ is half this value.\n    Therefore, $t = \\frac{2}{2} = 1$.\n\n*   **Jaro Similarity ($d_j$)**: With $m=7$ and $t=1$:\n    $$d_j = \\frac{1}{3} \\left( \\frac{7}{7} + \\frac{7}{7} + \\frac{7 - 1}{7} \\right) = \\frac{1}{3} \\left( 1 + 1 + \\frac{6}{7} \\right) = \\frac{1}{3} \\left( \\frac{14+6}{7} \\right) = \\frac{1}{3} \\left( \\frac{20}{7} \\right) = \\frac{20}{21}$$\n\n*   **Jaro–Winkler Similarity ($d_w$)**: This metric refines the Jaro similarity by giving more favorable scores to strings that match from the beginning (a common prefix). The formula is:\n    $$d_w = d_j + (\\ell \\cdot p \\cdot (1 - d_j))$$\n    where $\\ell$ is the length of the common prefix at the start of the strings (capped at a maximum, here $4$), and $p$ is a scaling factor (here $p=0.1$).\n    - The common prefix of \"Micheal\" and \"Michael\" is \"Mich\", which has a length of $4$.\n    - The problem specifies a maximum prefix length cap of $4$, so we use $\\ell = 4$.\n    - The scaling factor is given as $p = 0.1$.\n    We can now compute $d_w$:\n    $$d_w = \\frac{20}{21} + \\left( 4 \\cdot 0.1 \\cdot \\left(1 - \\frac{20}{21}\\right) \\right) = \\frac{20}{21} + \\left( \\frac{4}{10} \\cdot \\frac{1}{21} \\right)$$\n    $$d_w = \\frac{20}{21} + \\frac{4}{210} = \\frac{200}{210} + \\frac{4}{210} = \\frac{204}{210}$$\n    Simplifying this fraction gives:\n    $$d_w = \\frac{204 \\div 6}{210 \\div 6} = \\frac{34}{35}$$\n\n**2. Levenshtein Distance Computation**\n\nThe Levenshtein distance is the minimum number of single-character edits (insertions, deletions, or substitutions) needed to change one string into the other. The cost for each operation is given as $1$. The difference between $s_1 = \\text{\"Micheal\"}$ and $s_2 = \\text{\"Michael\"}$ is the transposition of the adjacent characters 'e' and 'a'.\n\nStandard Levenshtein distance does not have a \"transposition\" as a fundamental operation with cost $1$. A transposition must be modeled using the available operations. There are two primary ways to transform \"Micheal\" into \"Michael\":\n\n*   **Method 1: Deletion and Insertion**\n    1.  Start with \"Micheal\".\n    2.  Delete the character 'e': `Micheal` $\\rightarrow$ `Michal`. This has a cost of $1$.\n    3.  Insert the character 'e' in the correct position: `Michal` $\\rightarrow$ `Michael`. This has a cost of $1$.\n    The total Levenshtein distance is $1 + 1 = 2$.\n\n*   **Method 2: Two Substitutions**\n    1.  Start with \"Micheal\".\n    2.  Substitute the 'e' at position 4 with 'a': `Micheal` $\\rightarrow$ `Michaal`. This has a cost of $1$.\n    3.  Substitute the 'a' at position 5 with 'e': `Michaal` $\\rightarrow$ `Michael`. This has a cost of $1$.\n    The total Levenshtein distance is $1 + 1 = 2$.\n\nBoth minimal edit paths yield a total cost of $2$. Thus, the Levenshtein distance is $2$.\n\n**3. Reasoning on Metric Suitability**\n\nThe error in \"Micheal\" versus \"Michael\" is a classic transposition error, which is very common in manual data entry. The two metrics treat this error fundamentally differently.\n\n*   **Jaro-Winkler Similarity**: This metric is explicitly designed to be sensitive to transpositions. The Jaro similarity formula, $d_j = \\frac{1}{3} (\\frac{m}{|s_1|} + \\frac{m}{|s_2|} + \\frac{m-t}{m})$, includes a term $\\frac{m-t}{m}$ that directly accounts for the ordering of matching characters. It recognizes that all characters are present ($m=7$), but penalizes the similarity score based on the number of transpositions ($t=1$). This results in a high similarity score ($d_j \\approx 0.952$, $d_w \\approx 0.971$), reflecting the fact that the two strings are very close and differ only by a common typing mistake.\n\n*   **Levenshtein Distance**: This metric does not have a primitive operation for transposition. It must model the change as two independent, single-character errors (a deletion and an insertion, or two substitutions). This results in a distance of $2$. In contrast, a single substitution (e.g., \"Michael\" vs. \"Michel\"), a single deletion (e.g., \"Michael\" vs. \"Michal\"), or a single insertion (e.g., \"Michael\" vs. \"Michaell\") would all result in a distance of $1$. By assigning a cost of $2$ to a simple transposition, Levenshtein distance treats this common error as being \"twice as bad\" as a simple substitution or indel, which may not align with its perceived severity in patient matching contexts.\n\n**Conclusion**: The Jaro-Winkler metric more faithfully captures the nature of common transposition errors. Its formulation inherently recognizes and provides a specific, nuanced penalty for character reordering, which is a frequent source of error in name transcription. This makes it particularly well-suited for tasks like patient identification where such typographical errors are prevalent.",
            "answer": "$$ \\boxed{\\begin{pmatrix} \\frac{34}{35} & 2 \\end{pmatrix}} $$"
        },
        {
            "introduction": "While comparing single fields is a necessary first step, robust patient identification requires us to combine evidence from multiple sources of information like names, dates of birth, and postal codes. The Fellegi-Sunter model provides a powerful probabilistic framework for this task, weighing the importance of agreement in each field based on its statistical power. In this practice , you will calculate a composite log-likelihood score for a patient pair, applying the core principles of this model to make a statistically-grounded match decision.",
            "id": "4851015",
            "problem": "A hospital system implements probabilistic patient identification following the Fellegi–Sunter framework under the conditional independence assumption of field agreements given the true match status. For each candidate pair of records, the system compares $3$ fields: first name, date of birth, and postal code, and assigns one of several agreement levels per field. For each field and level, the system specifies the $m$-probability (the probability of observing that level if the pair is a true match) and the $u$-probability (the probability of observing that level if the pair is a true non-match). The decision rule uses a two-threshold policy on the total log-likelihood ratio computed with the natural logarithm: accept as a link if the total log-likelihood ratio is at least the upper threshold, reject as a non-link if it is at most the lower threshold, and otherwise send to clerical review.\n\nThe fields, their agreement levels, and the corresponding $m$- and $u$-probabilities are:\n\n- First name:\n  - Exact: $m=0.92$, $u=0.04$\n  - Phonetic-only: $m=0.05$, $u=0.10$\n  - Disagree: $m=0.03$, $u=0.86$\n\n- Date of birth:\n  - Exact day–month–year: $m=0.985$, $u=0.002$\n  - Year-only agrees: $m=0.012$, $u=0.010$\n  - Disagree: $m=0.003$, $u=0.988$\n\n- Postal code:\n  - Exact $5$-character code: $m=0.90$, $u=0.06$\n  - Prefix-only agrees (first $3$ characters): $m=0.08$, $u=0.18$\n  - Disagree: $m=0.02$, $u=0.76$\n\nA particular candidate pair is observed to have the following agreement pattern:\n- First name: phonetic-only\n- Date of birth: exact day–month–year\n- Postal code: prefix-only\n\nThe system uses the following thresholds on the total log-likelihood ratio (natural logarithm): accept if at least $\\ln(100)$, reject if at most $\\ln(0.05)$, and otherwise review.\n\nUnder the standard conditional-independence model, compute the total log-likelihood ratio for this pair using the natural logarithm, and state the decision category implied by the thresholds. Report only the computed log-likelihood ratio as your final numeric answer, rounded to four significant figures. No units are required.",
            "solution": "This problem requires calculating the total log-likelihood ratio for a given candidate pair of records based on the Fellegi-Sunter model.\n\nThe log-likelihood ratio, or weight, for a specific agreement level on a single field $i$ is given by:\n$$\nW_i = \\ln\\left(\\frac{m_i}{u_i}\\right)\n$$\nwhere $m_i$ is the probability of observing that agreement level given the pair is a true match, and $u_i$ is the probability given the pair is a true non-match. The problem uses the natural logarithm ($\\ln$).\n\nUnder the assumption of conditional independence, the total log-likelihood ratio ($W_{total}$) is the sum of the individual weights for each of the three fields:\n$$\nW_{total} = W_{\\text{first name}} + W_{\\text{date of birth}} + W_{\\text{postal code}}\n$$\nThe candidate pair has the following observed agreements and corresponding probabilities:\n-   First name (phonetic-only): $m_{FN} = 0.05$, $u_{FN} = 0.10$.\n-   Date of birth (exact day–month–year): $m_{DOB} = 0.985$, $u_{DOB} = 0.002$.\n-   Postal code (prefix-only agrees): $m_{PC} = 0.08$, $u_{PC} = 0.18$.\n\nWe calculate the weight for each field:\n-   Weight for first name: $W_{FN} = \\ln\\left(\\frac{0.05}{0.10}\\right) = \\ln(0.5)$\n-   Weight for date of birth: $W_{DOB} = \\ln\\left(\\frac{0.985}{0.002}\\right) = \\ln(492.5)$\n-   Weight for postal code: $W_{PC} = \\ln\\left(\\frac{0.08}{0.18}\\right) = \\ln\\left(\\frac{4}{9}\\right)$\n\nThe total log-likelihood ratio is the sum of these weights:\n$$\nW_{total} = \\ln(0.5) + \\ln(492.5) + \\ln\\left(\\frac{4}{9}\\right)\n$$\nUsing the logarithm property $\\ln(a) + \\ln(b) = \\ln(ab)$, we combine the terms:\n$$\nW_{total} = \\ln\\left(0.5 \\times 492.5 \\times \\frac{4}{9}\\right) = \\ln\\left(\\frac{985}{9}\\right)\n$$\nNow, we compute the numerical value:\n$$\nW_{total} \\approx \\ln(109.444...) \\approx 4.695428\n$$\nRounding to four significant figures gives $W_{total} \\approx 4.695$.\n\nFor context, we can compare this value to the decision thresholds:\n-   Upper threshold: $T_{upper} = \\ln(100) \\approx 4.605$\n-   Lower threshold: $T_{lower} = \\ln(0.05) \\approx -2.996$\nSince $W_{total} > T_{upper}$, the decision rule is to accept the pair as a link. The problem asks for the computed log-likelihood ratio as the final numeric answer.",
            "answer": "$$\n\\boxed{4.695}\n$$"
        },
        {
            "introduction": "In real-world health systems with millions of patient records, comparing every possible pair is computationally prohibitive. To solve this scalability challenge, we use a technique called 'blocking', which efficiently groups records into smaller sets of likely candidates. This practice  delves into the critical trade-off of blocking, challenging you to use metrics like the Pair Reduction Ratio and Recall to evaluate and optimize a blocking strategy, thereby balancing computational efficiency with matching accuracy.",
            "id": "4851033",
            "problem": "A health system is performing probabilistic record linkage between two Electronic Health Record (EHR) repositories to identify duplicate patient representations across institutions. Repository A contains $12{,}000$ patient records and Repository B contains $8{,}000$ patient records collected over the same period. A gold-standard clerical review has identified $25{,}000$ true matching record pairs across the two repositories.\n\nThe team uses a baseline blocking scheme that groups records into blocks by the concatenation of a phonetic last-name code and year of birth, and compares only records within the same block. Under this baseline scheme, the system generates $3{,}840{,}000$ candidate record pairs and correctly retrieves $23{,}500$ of the gold-standard true matches.\n\nNext, the team considers a tunable family of blocking schemes parameterized by $k$, the number of initial letters from the last-name phonetic code included in the block key. Smaller $k$ values create coarser blocks (more candidate pairs, fewer missed matches), and larger $k$ values create finer blocks (fewer candidate pairs, more missed matches). For $k \\in \\{2,3,4\\}$, the observed outcomes are:\n- For $k=2$: candidate pairs $=5{,}760{,}000$; true matches retrieved $=24{,}250$.\n- For $k=3$: candidate pairs $=3{,}840{,}000$; true matches retrieved $=23{,}500$.\n- For $k=4$: candidate pairs $=2{,}400{,}000$; true matches retrieved $=22{,}250$.\n\nUsing standard definitions from record linkage and information retrieval, do the following:\n1. Compute the pair reduction ratio and the recall for the baseline blocking scheme described above. Express both as decimals, not as percentages, and do not round.\n2. Define a utility $U(k)=\\lambda \\,\\text{PRR}(k)+\\left(1-\\lambda\\right)\\,\\text{Recall}(k)$ with $\\lambda=0.55$, where $\\text{PRR}(k)$ is the pair reduction ratio under parameter $k$ and $\\text{Recall}(k)$ is the recall under parameter $k$. Using the outcomes listed for $k \\in \\{2,3,4\\}$ and the total number of possible cross-file pairs implied by the repository sizes, determine the value of $k$ in $\\{2,3,4\\}$ that maximizes $U(k)$.\n\nProvide only the optimal value of $k$ as your final answer. No rounding is required.",
            "solution": "The problem requires us to evaluate several blocking schemes and find the one that maximizes a given utility function. This involves calculating the pair reduction ratio (PRR) and recall for each scheme.\n\nFirst, we define the necessary terms and initial values:\n-   Number of records in Repository A: $N_A = 12,000$\n-   Number of records in Repository B: $N_B = 8,000$\n-   Total possible pairs: $N_{total} = N_A \\times N_B = 12,000 \\times 8,000 = 96,000,000$\n-   Total true matching pairs: $N_{true} = 25,000$\n\nThe key metrics are defined as:\n-   Pair Reduction Ratio (PRR): $\\text{PRR} = 1 - \\frac{N_{cand}}{N_{total}}$, where $N_{cand}$ is the number of candidate pairs.\n-   Recall: $\\text{Recall} = \\frac{N_{retrieved}}{N_{true}}$, where $N_{retrieved}$ is the number of true matches found.\n\nThe utility function to be maximized is $U(k) = \\lambda \\cdot \\text{PRR}(k) + (1-\\lambda) \\cdot \\text{Recall}(k)$, with $\\lambda = 0.55$.\nThus, $U(k) = 0.55 \\cdot \\text{PRR}(k) + 0.45 \\cdot \\text{Recall}(k)$.\n\nWe now calculate PRR, Recall, and the utility $U(k)$ for each value of $k \\in \\{2, 3, 4\\}$.\n\n**For $k=2$:**\n-   $N_{cand}(2) = 5,760,000$; $N_{retrieved}(2) = 24,250$\n-   $\\text{PRR}(2) = 1 - \\frac{5,760,000}{96,000,000} = 1 - 0.06 = 0.94$\n-   $\\text{Recall}(2) = \\frac{24,250}{25,000} = 0.97$\n-   $U(2) = (0.55 \\times 0.94) + (0.45 \\times 0.97) = 0.517 + 0.4365 = 0.9535$\n\n**For $k=3$ (Baseline):**\n-   $N_{cand}(3) = 3,840,000$; $N_{retrieved}(3) = 23,500$\n-   $\\text{PRR}(3) = 1 - \\frac{3,840,000}{96,000,000} = 1 - 0.04 = 0.96$\n-   $\\text{Recall}(3) = \\frac{23,500}{25,000} = 0.94$\n-   $U(3) = (0.55 \\times 0.96) + (0.45 \\times 0.94) = 0.528 + 0.423 = 0.951$\n\n**For $k=4$:**\n-   $N_{cand}(4) = 2,400,000$; $N_{retrieved}(4) = 22,250$\n-   $\\text{PRR}(4) = 1 - \\frac{2,400,000}{96,000,000} = 1 - 0.025 = 0.975$\n-   $\\text{Recall}(4) = \\frac{22,250}{25,000} = 0.89$\n-   $U(4) = (0.55 \\times 0.975) + (0.45 \\times 0.89) = 0.53625 + 0.4005 = 0.93675$\n\nFinally, we compare the calculated utility values:\n-   $U(2) = 0.9535$\n-   $U(3) = 0.9510$\n-   $U(4) = 0.93675$\n\nThe maximum utility value, $0.9535$, occurs when $k=2$. Therefore, the optimal value for the blocking parameter is $2$.",
            "answer": "$$\\boxed{2}$$"
        }
    ]
}