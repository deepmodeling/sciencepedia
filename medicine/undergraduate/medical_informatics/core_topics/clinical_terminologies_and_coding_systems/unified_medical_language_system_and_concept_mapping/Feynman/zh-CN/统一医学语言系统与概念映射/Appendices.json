{
    "hands_on_practices": [
        {
            "introduction": "在计算机能够“理解”医学文本之前，必须首先对其进行标准化处理。这个练习模拟了概念映射流程中的一个关键初始步骤：词汇规范化。通过这个练习，你将亲手处理一个真实的医学术语，应用一系列简化的规则来解决连字符和复数等书写变体，从而生成标准的词元候选项，为后续的术语匹配奠定基础。",
            "id": "4862362",
            "problem": "在一个与统一医学语言系统（UMLS）相符的概念映射流程中，词汇规范化在候选概念唯一标识符（CUI）查找之前应用。考虑一个简化的、有原则的规范化过程，其灵感来自词汇变体生成（LVG）和UMLS规范化字符串程序，使用以下规则作为基础：\n- 大小写转换：将所有字母字符转换为小写。\n- 连字符边界处理：对于字母标记之间的每个连字符，独立选择两种操作之一：要么用单个空格替换连字符，要么删除连字符并将相邻的字母序列连接起来。如果有 $H$ 个连字符，原则上会产生 $2^{H}$ 个不同的连字符处理变体。\n- 空白符分词：在连字符处理后，按空白符进行切分。\n- 规则英语复数名词的形态非屈折化：如果一个标记是通过在名词词基后附加单个末尾 $s$ 形成的规则复数，则通过移除末尾的 $s$ 将其替换为单数形式。对于下面的短语，唯一符合此规则的标记是“cancers”，它变为“cancer”。标记“lung”和“cell”已经是单数。不应用其他形态学处理。\n- 移除上述步骤产生的多余空白符。\n- 词元候选是应用这些规则组合后产生的以空格分隔的字符串。\n\n将此过程应用于输入短语：“non-small-cell lung cancers”。根据这些规则，计算生成的唯一词元候选的数量。仅提供计数作为最终答案。无需四舍五入，也无需单位。",
            "solution": "问题陈述已经过验证，被认为是合理的。这是一个在计算语言学和医学信息学领域中定义明确的问题，具有科学依据且内部一致。任务是通过应用一组指定的规则，枚举给定医学短语的所有唯一规范化形式，即词元候选。\n\n输入短语是“non-small-cell lung cancers”。规范化过程如下：\n\n1.  **大小写转换**：第一步是将所有字母字符转换为其小写等价形式。\n    输入短语 \"non-small-cell lung cancers.\" 变为 `non-small-cell lung cancers`。任何末尾的标点符号都将被丢弃，因为它不属于所描述的字母或空白符内容。\n\n2.  **连字符边界处理**：这是产生多个变体的关键步骤。字符串 `non-small-cell` 包含两个连字符。我们用 $H$ 表示连字符的数量。这里，$H=2$。根据规则，对于每个连字符，必须选择两种独立操作之一：\n    a) 用单个空格替换连字符。\n    b) 删除连字符并将相邻的标记连接起来。\n\n    由于对每个连字符的选择是独立的，此过程生成的不同字符串总数为 $2^H$。对于本题，这将产生 $2^2 = 4$ 个变体。让我们系统地枚举 `non-small-cell` 这一部分的变体：\n\n    -   **选择 1 (空格, 空格)**：第一个连字符被替换为空格，第二个连字符也被替换为空格。\n        `non-small-cell` $\\rightarrow$ `non small cell`\n    -   **选择 2 (空格, 删除)**：第一个连字符被替换为空格，第二个连字符被删除。\n        `non-small-cell` $\\rightarrow$ `non smallcell`\n    -   **选择 3 (删除, 空格)**：第一个连字符被删除，第二个连字符被替换为空格。\n        `non-small-cell` $\\rightarrow$ `nonsmall cell`\n    -   **选择 4 (删除, 删除)**：第一个连字符被删除，第二个连字符也被删除。\n        `non-small-cell` $\\rightarrow$ `nonsmallcell`\n\n    将小写短语的其余部分 ` lung cancers` 附加到这 $4$ 个变体中的每一个，我们得到以下中间字符串：\n    -   变体 A: `non small cell lung cancers`\n    -   变体 B: `non smallcell lung cancers`\n    -   变体 C: `nonsmall cell lung cancers`\n    -   变体 D: `nonsmallcell lung cancers`\n\n3.  **分词、非屈折化和重组**：将其余规则应用于这 $4$ 个变体中的每一个。\n    -   字符串通过按空白符切分来进行分词。\n    -   对每个标记应用形态非屈折化规则。问题指定只有标记 `cancers` 符合条件，它将被其单数形式 `cancer` 替换。所有其他标记（`non`, `small`, `cell`, `lung`, `smallcell`, `nonsmall`, `nonsmallcell`）不受影响。\n    -   处理后的标记被重新组合成一个以空格分隔的字符串。\n\n    让我们将此应用于这 $4$ 个变体中的每一个：\n\n    -   **变体 A**: `non small cell lung cancers`\n        -   标记: [`non`, `small`, `cell`, `lung`, `cancers`]\n        -   非屈折化: [`non`, `small`, `cell`, `lung`, `cancer`]\n        -   最终词元候选: `non small cell lung cancer`\n\n    -   **变体 B**: `non smallcell lung cancers`\n        -   标记: [`non`, `smallcell`, `lung`, `cancers`]\n        -   非屈折化: [`non`, `smallcell`, `lung`, `cancer`]\n        -   最终词元候选: `non smallcell lung cancer`\n\n    -   **变体 C**: `nonsmall cell lung cancers`\n        -   标记: [`nonsmall`, `cell`, `lung`, `cancers`]\n        -   非屈折化: [`nonsmall`, `cell`, `lung`, `cancer`]\n        -   最终词元候选: `nonsmall cell lung cancer`\n\n    -   **变体 D**: `nonsmallcell lung cancers`\n        -   标记: [`nonsmallcell`, `lung`, `cancers`]\n        -   非屈折化: [`nonsmallcell`, `lung`, `cancer`]\n        -   最终词元候选: `nonsmallcell lung cancer`\n\n4.  **计算唯一词元候选数量**：最后一步是计算生成的唯一字符串的数量。生成的四个词元候选是：\n    1.  `non small cell lung cancer`\n    2.  `non smallcell lung cancer`\n    3.  `nonsmall cell lung cancer`\n    4.  `nonsmallcell lung cancer`\n\n    通过检查，这四个字符串都是不同的。在连字符处理步骤中所做的组合选择产生了四个独特的前缀结构，随后对 `cancers` 到 `cancer` 的统一转换保留了它们的独特性。因此，唯一词元候选的总数为 $4$。",
            "answer": "$$\\boxed{4}$$"
        },
        {
            "introduction": "当术语被规范化后，下一步是将其与UMLS庞大的词汇库中的概念进行匹配。这个练习将引导你计算两个临床术语序列之间的编辑距离——一种衡量字符串相似度的常用指标。更重要的是，这个练习将揭示为何仅靠词汇层面的比较是不足够的，并阐明UMLS中的同义词信息在弥合语义鸿沟、实现精准映射方面所扮演的关键角色。",
            "id": "4862395",
            "problem": "在统一医学语言系统 (UMLS) 中，概念映射通常首先对输入术语和候选术语进行规范化，以使字符串比较具有科学意义。考虑一个输入的临床术语和一个候选概念名称。规范化流程应用以下广泛使用的预处理规则：将字母字符转换为小写、移除标点符号、折叠为 ASCII 字符、将空白符规范化为单个空格，并执行简单的词法规范化至基本形式；该流程不移除有意义的词元。规范化后，输入术语变为词元序列 $\\langle \\text{acute}, \\text{renal}, \\text{failure} \\rangle$，候选术语变为词元序列 $\\langle \\text{acute}, \\text{kidney}, \\text{failure} \\rangle$。\n\n使用序列上的 Levenshtein 距离的定义：它是将一个序列转换为另一个序列所需的最少单元素编辑操作（插入、删除或替换）次数，每次操作的成本为 $1$。计算两个规范化词元序列之间的 Levenshtein 距离 $d$。然后，从上述定义和 UMLS Metathesaurus 中的同义关系概念出发，解释当 UMLS 断言“renal”和“kidney”是同义词时，在候选选择过程中，编辑距离阈值 $t$ 如何与同义词扩展相互作用。\n\n以单个整数形式提供计算出的 Levenshtein 距离 $d$。无需四舍五入。以不带单位的数字形式表示最终答案。",
            "solution": "用户提供的问题是有效的，因为它科学地基于自然语言处理和医学信息学的原理，问题阐述清晰并包含了所有必要信息，且陈述客观。\n\n该问题要求分为两部分：首先，计算两个词元序列之间的 Levenshtein 距离；其次，解释该距离度量与来自统一医学语言系统 (UMLS) 的同义关系信息之间的相互作用。\n\n第 1 部分：计算 Levenshtein 距离\n\n两个规范化的词元序列如下：\n$S_1 = \\langle \\text{acute}, \\text{renal}, \\text{failure} \\rangle$\n$S_2 = \\langle \\text{acute}, \\text{kidney}, \\text{failure} \\rangle$\n\nLevenshtein 距离定义为将一个序列转换为另一个序列所需的最少单元素编辑操作（插入、删除或替换）次数。每次操作的成本为 $1$。在此上下文中，“元素”指的是词元（单词）。\n\n设序列 $S_1$ 的长度为 $m$，序列 $S_2$ 的长度为 $n$。此处，$m=3$ 且 $n=3$。\n\n我们可以通过观察两个序列的对齐来计算距离：\n$S_1: \\langle \\text{acute}, \\text{renal}, \\text{failure} \\rangle$\n$S_2: \\langle \\text{acute}, \\text{kidney}, \\text{failure} \\rangle$\n\n第一个词元 'acute' 相同。\n第三个词元 'failure' 相同。\n第二个词元 'renal' 和 'kidney' 不同。\n\n要将 $S_1$ 转换为 $S_2$，只需一次操作：将第二个位置的词元 'renal' 替换为词元 'kidney'。这次替换的成本为 $1$。不需要其他操作。因此，最小总成本，即 Levenshtein 距离 $d$，为 $1$。\n\n为了进行形式化验证，我们可以使用标准的动态规划方法。我们构建一个大小为 $(m+1) \\times (n+1)$ 的矩阵 $D$，即 $4 \\times 4$。条目 $D[i][j]$ 存储 $S_1$ 的前 $i$ 个词元与 $S_2$ 的前 $j$ 个词元之间的 Levenshtein 距离。\n\n递推关系为：\n$D[i][j] = \\min \\begin{cases} D[i-1][j] + 1  \\text{(删除)} \\\\ D[i][j-1] + 1  \\text{(插入)} \\\\ D[i-1][j-1] + C(S_1[i], S_2[j])  \\text{(替换)} \\end{cases}$\n其中，如果词元 $t_1$ 和 $t_2$ 相同，则替换成本 $C(t_1, t_2)$ 为 $0$，否则为 $1$。\n\n初始化的矩阵是：\n$$\n\\begin{pmatrix}\n0  1  2  3 \\\\\n1          \\\\\n2          \\\\\n3       \n\\end{pmatrix}\n$$\n\n逐个填充矩阵单元格：\n$D[1][1]$: $S_1[1]=\\text{'acute'}$, $S_2[1]=\\text{'acute'}$。成本为 $0$。$D[1][1] = \\min(D[0][1]+1, D[1][0]+1, D[0][0]+0) = \\min(2, 2, 0) = 0$。\n$D[2][2]$: $S_1[2]=\\text{'renal'}$, $S_2[2]=\\text{'kidney'}$。成本为 $1$。$D[2][2] = \\min(D[1][2]+1, D[2][1]+1, D[1][1]+1) = \\min(2, 2, 1) = 1$。\n$D[3][3]$: $S_1[3]=\\text{'failure'}$, $S_2[3]=\\text{'failure'}$。成本为 $0$。$D[3][3] = \\min(D[2][3]+1, D[3][2]+1, D[2][2]+0) = \\min(3, 3, 1) = 1$。\n\n完整的矩阵 $D$ 如下：\n$$\n\\begin{array}{c|cccc}\n  \\text{\"\"}  \\text{acute}  \\text{kidney}  \\text{failure} \\\\\n\\hline\n\\text{\"\"}  0  1  2  3 \\\\\n\\text{acute}  1  0  1  2 \\\\\n\\text{renal}  2  1  1  2 \\\\\n\\text{failure}  3  2  2  1\n\\end{array}\n$$\n右下角的值 $D[3][3]$ 即为 Levenshtein 距离。\n因此，计算出的距离为 $d=1$。\n\n第 2 部分：编辑距离阈值 ($t$) 与同义词扩展的相互作用\n\n在自动化概念映射中，输入术语会与来自像 UMLS 这样的术语系统中的大量候选概念名称进行比较。使用相似性或距离度量来为这些候选者评分。Levenshtein 距离是此类度量的常用选择。\n\n编辑距离阈值（用 $t$ 表示）是一个数值，用于筛选候选列表。仅当输入术语与候选名称之间的距离 $d$ 小于或等于该阈值时（即 $d \\le t$），候选概念才被视为潜在匹配。$t$ 的选择代表一种权衡：低阈值（例如 $t=0$）通过仅接受精确匹配来提高精确率，但会因拒绝相关变体而降低召回率。高阈值会提高召回率，但可能因包含许多不相关的候选者而降低精确率。\n\n在我们的具体问题中，$\\langle \\text{acute}, \\text{renal}, \\text{failure} \\rangle$ 和 $\\langle \\text{acute}, \\text{kidney}, \\text{failure} \\rangle$ 之间的 Levenshtein 距离为 $d=1$。这个距离完全源于词元 'renal' 和 'kidney' 之间的词汇差异。然而，在医学领域内，并且根据 UMLS Metathesaurus 的规定，这两个术语是同义词，指的是同一个解剖结构。因此，这两个短语在语义上是等价的。\n\n如果一个概念映射系统使用严格的阈值（例如 $t=0$）来仅查找精确匹配，它将无法将输入术语映射到候选概念，因为 $d=1 > t=0$。这突显了纯词汇距离度量的一个根本局限性：它们对语义等价不敏感。\n\n为了解决这个问题，来自 UMLS 的同义关系信息被整合到匹配过程中。这种与编辑距离阈值 $t$ 的相互作用可以通过两种主要方式实现：\n\n1.  **使用同义词规范化进行预处理**：在计算距离之前，将输入序列和候选序列中所有同义术语规范化为单一的规范形式。例如，'renal' 可以被系统地替换为 'kidney'。此步骤后，输入序列 $S_1$ 变为 $\\langle \\text{acute}, \\text{kidney}, \\text{failure} \\rangle$，现在与 $S_2$ 完全相同。规范化后的序列之间的 Levenshtein 距离变为 $d=0$。即使使用最严格的阈值 $t=0$，这个匹配现在也会被接受。\n\n2.  **考虑同义词的成本函数**：可以修改 Levenshtein 算法本身的成本函数以融入语义知识。替代统一的替换成本 $1$，使成本依赖于上下文。具体来说，将一个词元替换为其已知同义词的成本设置为 $0$。\n    替换成本函数变为：\n    如果 $t_1 = t_2$ 或者 $t_1$ 和 $t_2$ 是同义词，则 $C(t_1, t_2) = 0$。\n    否则 $C(t_1, t_2) = 1$。\n    在计算 $S_1$ 和 $S_2$ 之间的距离时，用 'kidney' 替换 'renal' 的成本将为 $0$。这同样导致最终的 Levenshtein 距离为 $d=0$。\n\n总之，编辑距离阈值 $t$ 设定了对词汇差异的容忍度。同义词扩展作为一种语义规范化形式，将语义等价性转换为词汇同一性（或距离为 $0$）。这确保了语义上相同的术语不会被距离度量所惩罚，即使在使用严格的阈值（$t=0$ 或 $t=1$）来过滤掉真正的词汇错误或不相关术语时，也能被正确匹配。这种整合对于在医学概念映射系统中实现高准确性至关重要。",
            "answer": "$$\n\\boxed{1}\n$$"
        },
        {
            "introduction": "在临床文本中，一个简单的缩写（如“MI”）可能有多种含义，这是自然语言处理中的一个核心挑战，即“歧义消解”。本练习将让你扮演一个概率分类器的角色，运用贝叶斯定理来解决这个问题。通过分析缩写周围的上下文词语，你将计算出每个可能含义的后验概率，从而以一种量化的、有原则的方式确定“MI”在特定语境下的最可能诊断。",
            "id": "4862370",
            "problem": "电子健康记录中的一句临床描述写道：“肌钙蛋白升高伴ST段抬高；手术计划包括瓣膜修复”，而歧义术语“MI”出现在同一部分。你正在为统一医学语言系统（UMLS）中的“MI”实现概念消歧。UMLS使用概念唯一标识符（CUI）来表示生物医学概念。对于“MI”，考虑了两个候选CUI：一个对应心肌梗死，另一个对应二尖瓣关闭不全。你将通过应用一个基于Bayes定理和朴素Bayes独立性假设的概率分类器，根据局部上下文词语来决定选择哪个候选概念。\n\n基本依据：\n- Bayes定理：对于一个概念 $C$ 和观察到的上下文 $W$，$P(C \\mid W) \\propto P(C) P(W \\mid C)$。\n- 朴素Bayes独立性假设：如果 $W = \\{w_1, w_2, \\dots, w_n\\}$ 是上下文词语，那么 $P(W \\mid C) = \\prod_{i=1}^{n} P(w_i \\mid C)$。\n\n假设上下文窗口 $W$ 由三个相邻词语 $\\{$“troponin,” “ST-elevation,” “valve”$\\}$ 组成，并且一个预训练的概念模型得出以下参数：\n- 类先验概率：$P(\\text{心肌梗死}) = 0.5$, $P(\\text{二尖瓣关闭不全}) = 0.5$。\n- 给定概念下词语的条件似然：\n  - $P(\\text{troponin} \\mid \\text{心肌梗死}) = 0.75$, $P(\\text{troponin} \\mid \\text{二尖瓣关闭不全}) = 0.05$。\n  - $P(\\text{ST-elevation} \\mid \\text{心肌梗死}) = 0.65$, $P(\\text{ST-elevation} \\mid \\text{二尖瓣关闭不全}) = 0.04$。\n  - $P(\\text{valve} \\mid \\text{心肌梗死}) = 0.15$, $P(\\text{valve} \\mid \\text{二尖瓣关闭不全}) = 0.55$。\n\n仅使用上述基本定律和定义，确定在朴素Bayes模型下“MI”的正确映射决策。选择唯一的最佳选项。\n\nA. 将“MI”映射到心肌梗死的CUI。\n\nB. 将“MI”映射到二尖瓣关闭不全的CUI。\n\nC. 推迟映射，因为在等同先验概率下证据不确定。\n\nD. 将“MI”映射到两个CUI，以在下游处理中保留歧义。",
            "solution": "用户提供了一个问题，需要在医学背景下应用朴素Bayes分类器进行概念消歧。\n\n### 第一步：提取已知条件\n\n问题陈述提供了以下信息：\n-   **任务**：在两个候选概念（心肌梗死和二尖瓣关闭不全）之间对术语“MI”进行消歧。\n-   **方法**：一个基于Bayes定理和朴素Bayes独立性假设的概率分类器。\n-   **候选概念**：$C_1 = \\text{心肌梗死}$, $C_2 = \\text{二尖瓣关闭不全}$。\n-   **上下文窗口 ($W$)**：相邻词语的集合 $W = \\{\\text{“troponin,” “ST-elevation,” “valve”}\\}$。令 $w_1 = \\text{“troponin”}$，$w_2 = \\text{“ST-elevation”}$，$w_3 = \\text{“valve”}$。\n-   **基本定律**：\n    -   Bayes定理：$P(C \\mid W) \\propto P(C) P(W \\mid C)$。\n    -   朴素Bayes独立性假设：$P(W \\mid C) = \\prod_{i=1}^{n} P(w_i \\mid C)$。\n-   **模型参数**：\n    -   类先验概率：$P(C_1) = P(\\text{心肌梗死}) = 0.5$, $P(C_2) = P(\\text{二尖瓣关闭不全}) = 0.5$。\n    -   $C_1$ 的条件似然：\n        -   $P(w_1 \\mid C_1) = P(\\text{troponin} \\mid \\text{心肌梗死}) = 0.75$。\n        -   $P(w_2 \\mid C_1) = P(\\text{ST-elevation} \\mid \\text{心肌梗死}) = 0.65$。\n        -   $P(w_3 \\mid C_1) = P(\\text{valve} \\mid \\text{心肌梗死}) = 0.15$。\n    -   $C_2$ 的条件似然：\n        -   $P(w_1 \\mid C_2) = P(\\text{troponin} \\mid \\text{二尖瓣关闭不全}) = 0.05$。\n        -   $P(w_2 \\mid C_2) = P(\\text{ST-elevation} \\mid \\text{二尖瓣关闭不全}) = 0.04$。\n        -   $P(w_3 \\mid C_2) = P(\\text{valve} \\mid \\text{二尖瓣关闭不全}) = 0.55$。\n-   **问题**：确定在该模型下“MI”的正确映射决策。\n\n### 第二步：使用提取的已知条件进行验证\n\n-   **科学依据**：该问题在医学信息学、自然语言处理和概率论的原理方面有充分的依据。使用朴素Bayes分类器进行词义消歧是一种标准且广泛应用的技术。临床关联（例如，肌钙蛋白/ST段抬高与心肌梗死，瓣膜与二尖瓣关闭不全）在医学上是正确的。统一医学语言系统（UMLS）和概念唯一标识符（CUI）是医学信息学领域的真实组成部分。\n-   **问题适定性**：该问题是适定的，提供了所有必要的数据（先验概率和条件概率）以及一个清晰、明确的目标。可以通过直接计算得出一个唯一的解。\n-   **客观性**：该问题使用精确、量化和客观的语言陈述，没有任何主观或模棱两可的元素。\n\n### 第三步：结论和行动\n\n问题陈述是**有效的**。它是一个清晰、自洽且科学合理的标准分类算法应用。我将继续进行解题推导。\n\n### 解题推导\n\n目标是确定在给定上下文词语 $W = \\{w_1, w_2, w_3\\}$ 的情况下，哪个概念 $C_1$（心肌梗死）或 $C_2$（二尖瓣关闭不全）更有可能。这是一个最大后验（MAP）估计问题，我们寻求能使后验概率 $P(C \\mid W)$ 最大化的概念 $C$。\n\n根据Bayes定理，后验概率由以下公式给出：\n$$P(C \\mid W) = \\frac{P(W \\mid C) P(C)}{P(W)}$$\n为了比较 $C_1$ 和 $C_2$ 的后验概率，我们可以比较它们的分子，因为分母 $P(W)$ 对两种情况都是一个常数。因此，我们的目标是找到使 $P(C) P(W \\mid C)$ 这个量最大化的概念 $C$。这通常被称为概念的得分。\n\n朴素Bayes独立性假设指出，上下文词集 $W$ 的条件概率是单个词语条件概率的乘积：\n$$P(W \\mid C) = P(w_1 \\mid C) \\times P(w_2 \\mid C) \\times P(w_3 \\mid C)$$\n\n我们现在计算每个候选概念的得分。\n\n**1. $C_1$（心肌梗死）的得分：**\n\n先验概率为 $P(C_1) = 0.5$。\n条件似然为：\n$$P(W \\mid C_1) = P(\\text{troponin} \\mid C_1) \\times P(\\text{ST-elevation} \\mid C_1) \\times P(\\text{valve} \\mid C_1)$$\n代入给定值：\n$$P(W \\mid C_1) = 0.75 \\times 0.65 \\times 0.15$$\n$$P(W \\mid C_1) = 0.4875 \\times 0.15 = 0.073125$$\n现在，我们计算 $C_1$ 的得分：\n$$\\text{得分}(C_1) = P(C_1) P(W \\mid C_1) = 0.5 \\times 0.073125 = 0.0365625$$\n\n**2. $C_2$（二尖瓣关闭不全）的得分：**\n\n先验概率为 $P(C_2) = 0.5$。\n条件似然为：\n$$P(W \\mid C_2) = P(\\text{troponin} \\mid C_2) \\times P(\\text{ST-elevation} \\mid C_2) \\times P(\\text{valve} \\mid C_2)$$\n代入给定值：\n$$P(W \\mid C_2) = 0.05 \\times 0.04 \\times 0.55$$\n$$P(W \\mid C_2) = 0.002 \\times 0.55 = 0.0011$$\n现在，我们计算 $C_2$ 的得分：\n$$\\text{得分}(C_2) = P(C_2) P(W \\mid C_2) = 0.5 \\times 0.0011 = 0.00055$$\n\n**3. 比较：**\n\n我们比较两个概念的得分：\n-   $\\text{得分}(C_1) = 0.0365625$\n-   $\\text{得分}(C_2) = 0.00055$\n\n由于 $\\text{得分}(C_1) > \\text{得分}(C_2)$（具体为 $0.0365625 > 0.00055$），朴素Bayes分类器选择心肌梗死作为“MI”在此上下文中最可能的含义。\n\n### 选项评估\n\n根据计算，模型的决策是将“MI”映射到心肌梗死的CUI。\n\n**A. 将“MI”映射到心肌梗死的CUI。**\n计算表明，心肌梗死的后验概率远高于二尖瓣关闭不全的后验概率（$0.0365625$ 对 $0.00055$）。因此，分类器的决策是选择心肌梗死。\n**结论：正确**。\n\n**B. 将“MI”映射到二尖瓣关闭不全的CUI。**\n二尖瓣关闭不全的后验概率显著低于心肌梗死的后验概率。该映射与朴素Bayes分类的结果相反。\n**结论：错误**。\n\n**C. 推迟映射，因为在等同先验概率下证据不确定。**\n先验概率相等（各为$0.5$），这意味着决策完全取决于条件似然 $P(W|C)$。心肌梗死的似然（$0.073125$）比二尖瓣关闭不全的似然（$0.0011$）大66倍以上。这个证据并非不确定；它强烈支持一个概念而不是另一个。推迟决策并没有模型输出的依据。\n**结论：错误**。\n\n**D. 将“MI”映射到两个CUI，以在下游处理中保留歧义。**\n如问题中所述，分类器的目标是做出决策或将术语“映射”到一个概念。根据设计，朴素Bayes分类器会选择唯一的、最可能的类别（即MAP估计）。虽然在某些系统架构中保留歧义是一种可能的策略，但它不是这个特定分类模型所指定的行动。问题要求的是*在朴素Bayes模型下*的决策，即解决歧义，而非保留歧义。\n**结论：错误**。",
            "answer": "$$\\boxed{A}$$"
        }
    ]
}