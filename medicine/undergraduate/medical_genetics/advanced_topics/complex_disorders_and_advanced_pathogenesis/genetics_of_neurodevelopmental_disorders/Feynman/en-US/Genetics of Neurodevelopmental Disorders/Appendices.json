{
    "hands_on_practices": [
        {
            "introduction": "While classical Mendelian genetics provides the foundational framework for risk calculation, real-world scenarios often involve additional layers of complexity. This exercise moves beyond the standard $1/4$ risk for an autosomal recessive condition by incorporating the possibility of a *de novo* mutation acting as a \"second hit.\" By tackling this hypothetical problem, you will learn how to synthesize principles of inheritance with molecular events to build a more comprehensive and accurate model of disease risk .",
            "id": "5040481",
            "problem": "A couple are known heterozygous carriers for the same pathogenic variant in a gene that causes a severe autosomal recessive neurodevelopmental disorder with complete penetrance. Assume Mendel’s First Law (law of segregation) applies, so each heterozygous parent transmits the pathogenic allele with probability $1/2$ and the non-pathogenic allele with probability $1/2$. The disorder manifests when a child possesses two pathogenic alleles in the same gene. In addition to inherited alleles, consider that a de novo inactivating mutation (“second hit”) can arise independently on any allele that is wild-type at this locus in the zygote with probability $r$ per allele, where $r=10^{-5}$. Assume independence of de novo events across alleles and independence from segregation, and that any biallelic inactivation yields disease expression due to complete penetrance.\n\nUsing only these principles and assumptions, derive from first principles the total probability that a child of this couple is affected by the disorder, by enumerating mutually exclusive inherited-genotype categories and adding the contributions from de novo second hits where relevant. Express the final probability as a decimal (not a percentage), and round to $6$ significant figures. Do not include any units in your answer.",
            "solution": "### Solution Derivation\nThe total probability of a child being affected, $P(\\text{affected})$, can be calculated by considering the mutually exclusive inherited genotypes and the probability of being affected within each genotype category. The Law of Total Probability states:\n$$P(\\text{affected}) = \\sum_{G} P(\\text{affected} | G) P(G)$$\nwhere $G$ represents the set of possible inherited genotypes $\\{AA, Aa, aa\\}$.\n\nFirst, we determine the probabilities of the three possible inherited genotypes from a cross between two heterozygous parents ($Aa \\times Aa$).\n-   Probability of inheriting genotype $AA$: $P(AA) = P(A \\text{ from father}) \\times P(A \\text{ from mother}) = \\frac{1}{2} \\times \\frac{1}{2} = \\frac{1}{4}$.\n-   Probability of inheriting genotype $Aa$: $P(Aa) = [P(A \\text{ from father}) \\times P(a \\text{ from mother})] + [P(a \\text{ from father}) \\times P(A \\text{ from mother})] = (\\frac{1}{2} \\times \\frac{1}{2}) + (\\frac{1}{2} \\times \\frac{1}{2}) = \\frac{1}{4} + \\frac{1}{4} = \\frac{1}{2}$.\n-   Probability of inheriting genotype $aa$: $P(aa) = P(a \\text{ from father}) \\times P(a \\text{ from mother}) = \\frac{1}{2} \\times \\frac{1}{2} = \\frac{1}{4}$.\nThe sum of these probabilities is $\\frac{1}{4} + \\frac{1}{2} + \\frac{1}{4} = 1$, as expected.\n\nNext, we calculate the conditional probability of being affected for each of these inherited genotypes, considering the possibility of *de novo* \"second hits\". Let $r = 10^{-5}$ be the per-allele probability of a *de novo* inactivating mutation on a wild-type allele.\n\n**Case 1: Inherited genotype is $aa$.**\nThe child inherits two pathogenic alleles. Due to complete penetrance, the child is affected with certainty. No *de novo* events are needed.\n$$P(\\text{affected} | aa) = 1$$\nThe contribution to the total probability from this case is:\n$$P(\\text{affected} \\cap aa) = P(\\text{affected} | aa) P(aa) = 1 \\times \\frac{1}{4} = \\frac{1}{4}$$\n\n**Case 2: Inherited genotype is $Aa$.**\nThe child inherits one pathogenic allele ($a$) and one wild-type allele ($A$). For the disorder to manifest (biallelic inactivation), the single wild-type allele $A$ must undergo a *de novo* inactivating mutation. The probability of this \"second hit\" is given as $r$.\n$$P(\\text{affected} | Aa) = r$$\nThe contribution to the total probability from this case is:\n$$P(\\text{affected} \\cap Aa) = P(\\text{affected} | Aa) P(Aa) = r \\times \\frac{1}{2} = \\frac{r}{2}$$\n\n**Case 3: Inherited genotype is $AA$.**\nThe child inherits two wild-type alleles ($A$). For the disorder to manifest, both wild-type alleles must independently undergo a *de novo* inactivating mutation. Since the *de novo* events are independent, the probability of both occurring is the product of their individual probabilities.\n$$P(\\text{affected} | AA) = r \\times r = r^2$$\nThe contribution to the total probability from this case is:\n$$P(\\text{affected} \\cap AA) = P(\\text{affected} | AA) P(AA) = r^2 \\times \\frac{1}{4} = \\frac{r^2}{4}$$\n\n**Total Probability**\nThe total probability of the child being affected is the sum of the probabilities from these three mutually exclusive cases:\n$$P(\\text{affected}) = P(\\text{affected} \\cap aa) + P(\\text{affected} \\cap Aa) + P(\\text{affected} \\cap AA)$$\n$$P(\\text{affected}) = \\frac{1}{4} + \\frac{r}{2} + \\frac{r^2}{4}$$\n\nNow, we substitute the numerical value $r=10^{-5}$:\n$$P(\\text{affected}) = \\frac{1}{4} + \\frac{10^{-5}}{2} + \\frac{(10^{-5})^2}{4}$$\n$$P(\\text{affected}) = 0.25 + \\frac{0.00001}{2} + \\frac{10^{-10}}{4}$$\n$$P(\\text{affected}) = 0.25 + 0.000005 + 0.000000000025$$\n$$P(\\text{affected}) = 0.250005000025$$\n\nThe problem requires the final answer to be rounded to $6$ significant figures. The first six significant figures are $2, 5, 0, 0, 0, 5$. The seventh digit is $0$, so we round down (i.e., truncate).\n$$P(\\text{affected}) \\approx 0.250005$$",
            "answer": "$$\n\\boxed{0.250005}\n$$"
        },
        {
            "introduction": "Identifying a novel gene responsible for a neurodevelopmental disorder is akin to finding a needle in a haystack, requiring the skillful integration of multiple lines of evidence. This practice places you in the role of a research geneticist evaluating two candidate genes by weighing two distinct but complementary pieces of information: a gene’s inherent intolerance to mutation (quantified by metrics like the LOEUF score) and the statistical excess of new mutations observed in patients. Mastering this thought process is essential for understanding how the scientific community builds a compelling case for gene-disease causality .",
            "id": "5040458",
            "problem": "A cohort of $N = 10{,}000$ trios affected by severe neurodevelopmental disorders is sequenced. Two genes, $G_X$ and $G_Y$, are evaluated. $G_X$ has a Loss-of-function Observed/Expected Upper bound Fraction (LOEUF) of $0.25$, and $G_Y$ has a LOEUF of $0.75$. Loss-of-function (LoF) variants are defined as variants that abrogate gene function (for example, frameshift, nonsense, canonical splice-site). Assume both genes have similar LoF mutational target sizes such that the per-trio de novo LoF mutation rate is $\\mu = 2.0 \\times 10^{-6}$ for each gene. In the cohort, $G_X$ has $k_X = 6$ de novo LoF variants observed, and $G_Y$ has $k_Y = 1$ de novo LoF variant observed.\n\nBase your reasoning on first principles:\n- The Central Dogma of Molecular Biology establishes that genes encode products whose dosage and function impact development; severe reduction in dosage due to LoF in dosage-sensitive (constrained) genes is more likely to produce disease.\n- Under neutrality, rare, independent events such as de novo mutations across trios are modeled by the Poisson distribution with mean $\\lambda = N \\mu$ per gene.\n- LOEUF quantifies depletion of LoF variants in large population datasets; lower LOEUF indicates stronger purifying selection against LoF and thus greater intolerance, consistent with dosage sensitivity.\n\nWhich option best justifies which gene is more plausible as a neurodevelopmental risk gene, integrating both LOEUF and de novo LoF enrichment evidence?\n\nA. $G_X$ is more plausible: its lower LOEUF ($0.25$) indicates stronger intolerance, and the observed $k_X = 6$ de novo LoF variants represent a highly significant enrichment over the Poisson expectation $\\lambda = 0.02$.\n\nB. $G_Y$ is more plausible: its higher LOEUF ($0.75$) indicates greater tolerance to LoF in the general population, making any observed de novo LoF more likely to be pathogenic.\n\nC. Neither gene is plausible: with only $k_X = 6$ and $k_Y = 1$ events, the sample is too small to infer risk relative to the expectation.\n\nD. Both genes are equally plausible: they have the same mutational target size and at least one de novo LoF event, so LOEUF differences are not informative.\n\nE. Undecidable from genetics alone: without brain-specific expression data, de novo enrichment and LOEUF cannot prioritize $G_X$ versus $G_Y$.",
            "solution": "### Solution Derivation\n\nThe problem asks to determine which gene, $G_X$ or $G_Y$, is a more plausible risk gene for neurodevelopmental disorders (NDDs), using two pieces of evidence:\n1.  **De novo LoF enrichment**: Comparing the observed number of de novo mutations in the NDD cohort to the number expected by chance.\n2.  **Gene constraint**: Using the LOEUF score, which reflects how intolerant a gene is to LoF variants in the general population.\n\n**Principle:** A strong candidate gene for a dominant disease (like many severe NDDs) is expected to show two key properties:\n1.  It should be intolerant to functional inactivation (i.e., be under strong purifying selection in the general population). This is measured by LOEUF. A low LOEUF indicates high intolerance.\n2.  It should harbor an excess of damaging de novo mutations in affected individuals compared to the expectation from the neutral mutation rate.\n\nLet's analyze each gene based on these principles.\n\n**1. De Novo Enrichment Analysis**\n\nThe problem states that under neutrality, the number of de novo LoF mutations in a cohort of size $N$ follows a Poisson distribution with mean $\\lambda = N \\mu$.\n\n*   Cohort size: $N = 10{,}000$\n*   Per-trio de novo LoF mutation rate for each gene: $\\mu = 2.0 \\times 10^{-6}$\n\nThe expected number of de novo LoF mutations for *each* gene is:\n$$ \\lambda = N \\mu = (10{,}000) \\times (2.0 \\times 10^{-6}) = 10^4 \\times 2.0 \\times 10^{-6} = 2.0 \\times 10^{-2} = 0.02 $$\n\nSo, under the null hypothesis (that mutations in these genes are not associated with NDDs), we expect to see about $0.02$ de novo LoF mutations in this cohort for each gene.\n\n**Analysis for Gene $G_X$:**\n*   Expected count: $\\lambda_X = 0.02$\n*   Observed count: $k_X = 6$\n\nThe observation of $k_X = 6$ is substantially higher than the expectation of $\\lambda_X = 0.02$. The probability of observing $6$ or more events by chance from a Poisson distribution with a mean of $0.02$ is vanishingly small. This constitutes a highly significant enrichment of de novo LoF mutations in $G_X$.\n\n**Analysis for Gene $G_Y$:**\n*   Expected count: $\\lambda_Y = 0.02$\n*   Observed count: $k_Y = 1$\n\nThe observation of $k_Y = 1$ is also higher than the expectation of $\\lambda_Y = 0.02$. The probability of observing $1$ or more events by chance is $P(X \\ge 1) = 1 - P(X = 0) = 1 - e^{-0.02} \\approx 0.0198$. This is statistically significant at a conventional $\\alpha = 0.05$ level, but far less significant than the result for $G_X$.\n\n**2. Gene Constraint Analysis (LOEUF)**\n\nThe problem provides LOEUF scores, which quantify intolerance to LoF. A lower LOEUF indicates stronger purifying selection and greater intolerance.\n\n**Analysis for Gene $G_X$:**\n*   $LOEUF_X = 0.25$.\nThis is a low LOEUF score, indicating the gene is highly constrained and intolerant to LoF. This is strong *a priori* evidence that $G_X$ is an important, dosage-sensitive gene where LoF mutations are likely to cause disease.\n\n**Analysis for Gene $G_Y$:**\n*   $LOEUF_Y = 0.75$.\nThis is a high LOEUF score, indicating that the gene is relatively tolerant to LoF variation. LoF variants in such genes are much less likely to cause severe dominant disorders.\n\n**3. Synthesis of Evidence**\n\n*   **Gene $G_X$**: Has extremely strong statistical enrichment ($k_X = 6$ vs. $\\lambda = 0.02$) and a biological prior (low LOEUF) that are concordant. Both point strongly towards $G_X$ being a risk gene.\n\n*   **Gene $G_Y$**: Has much weaker statistical evidence ($k_Y = 1$ vs. $\\lambda = 0.02$) and a conflicting biological prior (high LOEUF) that argues *against* it being a severe disease gene.\n\n**Conclusion**: Gene $G_X$ is the more plausible candidate. It has both highly significant enrichment of de novo LoF mutations in the disease cohort and a gene-level constraint metric (low LOEUF) that is characteristic of known NDD genes. Option A correctly summarizes this synthesis.",
            "answer": "$$\\boxed{A}$$"
        },
        {
            "introduction": "The power of whole-exome sequencing comes with a significant challenge: a single patient's exome contains thousands of genetic variants, the vast majority of which are harmless. The crucial task is to design a systematic pipeline to filter this massive dataset down to a single, causal variant. This exercise challenges you to construct such a pipeline for a family trio, using principles of population genetics, Mendelian inheritance, and functional prediction to solve a diagnostic puzzle, providing a hands-on look at how genomic data is translated into a clinically actionable diagnosis .",
            "id": "4354893",
            "problem": "A pediatric trio case (proband and both parents) undergoes Whole-Exome Sequencing (WES). The proband is a male with severe, early-onset neurodevelopmental features and no family history; both parents are unaffected. The clinical suspicion is of a highly penetrant, monogenic disorder. The observed prevalence of clinically similar disorders in the general population is approximately $p = \\dfrac{1}{50{,}000}$. You are asked to select the most scientifically justified variant filtration pipeline to prioritize truly pathogenic variants from the WES dataset, using the following pillars: allele frequency from population databases such as the Genome Aggregation Database (gnomAD), functional impact prediction (for example, identifying protein-truncating Loss-of-Function (LoF) variants and high Combined Annotation Dependent Depletion (CADD) scores), and Mendelian inheritance constraints (de novo autosomal dominant, hemizygous X-linked in males, or biallelic autosomal recessive).\n\nYour choice should be grounded in:\n- The Central Dogma of molecular biology, which establishes that changes in deoxyribonucleic acid (DNA) can alter ribonucleic acid (RNA) and protein and thereby cause disease.\n- Basic Mendelian genetics for dominant, recessive, and X-linked modes of inheritance.\n- Population genetics under Hardy-Weinberg Equilibrium (HWE), linking prevalence to allele frequency for rare diseases.\n- The empirical observation that severe, early-onset monogenic disorders are typically caused by high-effect variants under strong negative selection, making such variants extremely rare in reference populations.\n\nWhich pipeline best aligns with these principles?\n\nA. Filter out variants with gnomAD minor allele frequency (MAF) $\\geq 0.01$ and retain all missense or LoF variants with CADD $\\geq 20$. Require that candidates show de novo occurrence or biallelic inheritance in autosomal recessive models, and allow hemizygous X-linked variants in the male proband. Perform phenotype matching post hoc.\n\nB. Retain variants with gnomAD MAF $\\leq 0.05$ to avoid losing potentially common disease alleles; include synonymous variants because splice effects are unpredictable; ignore parental genotypes and rely primarily on CADD $\\geq 10$ to identify deleterious changes.\n\nC. Use gnomAD MAF thresholds informed by prevalence and inheritance: for suspected autosomal dominant de novo or X-linked disease in the male proband, require MAF $< 1 \\times 10^{-6}$; for autosomal recessive candidates, require per-allele MAF $< 1 \\times 10^{-3}$. Prioritize predicted LoF variants and damaging missense (for example, CADD $\\geq 20$) especially in genes with high Probability of Loss-of-function Intolerance (pLI $\\geq 0.9$). Enforce Mendelian constraints (de novo in the proband, hemizygous X-linked in the male, and biallelic recessive), exclude variants present in unaffected parents for dominant/X-linked models, and then perform phenotype-to-gene matching using Human Phenotype Ontology (HPO) terms.\n\nD. Only accept variants entirely absent from gnomAD (MAF $= 0$), restrict to stop-gain LoF variants, and require strict de novo status; ignore missense and splice defects to minimize false positives. Perform no phenotype matching to avoid bias.",
            "solution": "### Derivation of the Optimal Filtration Strategy\n\nThe goal is to design a filtration pipeline that maximizes the probability of identifying the single causal variant for a severe, highly penetrant, early-onset disorder, while minimizing the number of false-positive candidates. The provided case information (trio, phenotype, prevalence) is crucial for tailoring the strategy.\n\n1.  **Inheritance Model and Trio Analysis**: The family structure (unaffected parents, affected proband) is the most powerful filter. It strongly suggests three primary possibilities:\n    - **Autosomal Dominant (AD), *de novo***: The variant appeared for the first time in the proband and is absent in both parents.\n    - **X-linked (XL)**: The male proband has one copy of a variant on his X chromosome. This could be a *de novo* variant or inherited from an asymptomatic carrier mother.\n    - **Autosomal Recessive (AR)**: The proband inherited one pathogenic variant from his mother and a second pathogenic variant in the same gene from his father. The parents are heterozygous carriers and thus unaffected.\n\n2.  **Allele Frequency Filtering (Population Genetics)**: The specified disease prevalence of $p = 1/50{,}000$ allows for the estimation of maximum plausible allele frequencies ($q$).\n    - **For AD or XL models**: The causal allele must be exceptionally rare. A prevalence of $1/50{,}000$ corresponds to an allele frequency of $q \\approx 1 \\times 10^{-5}$. An aggressive minor allele frequency (MAF) filter, such as MAF $< 1 \\times 10^{-6}$ or even absent from population databases, is scientifically justified.\n    - **For AR models**: The prevalence is $p = q^2$, so $q = \\sqrt{p} = \\sqrt{1/50{,}000} \\approx 0.0045$. A MAF threshold of $< 1 \\times 10^{-3}$ ($0.1\\%$) or slightly higher is a reasonable filter for rare recessive causes.\n    - A single, one-size-fits-all MAF threshold is suboptimal. The strategy must be tailored to the inheritance model being tested.\n\n3.  **Functional Impact Prediction**: A severe disorder implies a high-impact variant. The pipeline should prioritize Loss-of-Function (LoF) variants (nonsense, frameshift, canonical splice-site) and missense variants predicted to be damaging by multiple algorithms (e.g., CADD $\\geq 20$). Prioritizing variants in genes already known to be intolerant to LoF (e.g., pLI $\\geq 0.9$) further strengthens the case for dominant candidate variants.\n\n4.  **Phenotype-Genotype Correlation**: A crucial final step is to compare the proband's clinical features with the known disease associations of the genes harboring candidate variants, often using tools like the Human Phenotype Ontology (HPO).\n\n### Evaluation of Options\n\n*   **Option A** is flawed because its single MAF threshold of $0.01$ is far too permissive for a suspected *de novo* dominant or X-linked variant, which would be much rarer.\n*   **Option B** is severely flawed. It uses an inappropriate MAF ($5\\%$), includes noisy data (synonymous variants), and discards the most powerful information (parental genotypes).\n*   **Option D** is overly restrictive. By only accepting variants with MAF $= 0$, only stop-gain variants, and only a *de novo* model, it risks missing true positives due to incomplete database coverage, other valid LoF variant types (frameshift, splice), pathogenic missense variants, and autosomal recessive inheritance. Ignoring phenotype matching is also clinically unsound.\n*   **Option C** correctly integrates all key principles. It uses nuanced, model-specific MAF thresholds based on population genetics. It prioritizes high-impact variants using multiple lines of evidence (variant type, CADD score, pLI score). It correctly applies all relevant Mendelian models using the trio data. Finally, it includes phenotype matching as an essential validation step. This represents the most comprehensive and scientifically justified approach.",
            "answer": "$$\\boxed{C}$$"
        }
    ]
}