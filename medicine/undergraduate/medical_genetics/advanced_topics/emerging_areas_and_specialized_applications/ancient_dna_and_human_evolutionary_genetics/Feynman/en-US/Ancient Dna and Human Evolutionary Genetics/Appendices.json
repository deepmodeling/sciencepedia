{
    "hands_on_practices": [
        {
            "introduction": "This problem presents a scenario that is both a classic teaching case and a genuine challenge for paleogeneticists: discovering a modern human DNA sequence mixed in with an ancient sample. This exercise challenges you to think like a detective and apply the principle of parsimony to evaluate competing hypotheses. Understanding how to spot and interpret contamination  is the first and most critical skill in ancient DNA analysis.",
            "id": "1468888",
            "problem": "A paleo-genetics team is analyzing a 50,000-year-old Neanderthal molar found in a Siberian cave. Their goal is to sequence the mitochondrial DNA (mtDNA), a small circular genome inherited maternally that is present in high copy numbers in cells, making it suitable for ancient DNA (aDNA) studies. The team extracts DNA from the tooth powder in an ultra-clean facility. They then use Polymerase Chain Reaction (PCR) to amplify a specific hypervariable region of the mtDNA, which is commonly used for identifying maternal lineages, or haplotypes.\n\nAfter sequencing the amplified DNA fragments, the analysis reveals two distinct and abundant haplotypes. Haplotype N is novel but shares a high degree of similarity with other published Neanderthal mtDNA sequences. Haplotype M, however, is a perfect match to the mtDNA haplotype of the lead researcher who performed the DNA extraction. Given this information, which of the following is the most scientifically sound explanation for the presence of Haplotype M in the sample?\n\nA. The Neanderthal individual was heteroplasmic, meaning they naturally possessed two distinct mtDNA lineages, one of which coincidentally matches a modern human.\n\nB. This finding provides definitive evidence for direct interbreeding between the maternal ancestor of this specific Neanderthal and an anatomically modern human.\n\nC. The sequence for Haplotype M is the result of random mutations introduced during the PCR amplification process that by chance accumulated to match the researcher's sequence.\n\nD. Both the Neanderthal and the modern researcher's maternal lineages underwent convergent evolution, independently arriving at an identical mtDNA sequence.\n\nE. The sample was contaminated with modern DNA from the lead researcher during sample handling or laboratory processing.",
            "solution": "We start by identifying the biological and methodological principles relevant to ancient DNA (aDNA) studies:\n- Mitochondrial DNA (mtDNA) is maternally inherited and typically exists as a single haplotype per individual, except in rare cases of heteroplasmy, where two closely related mtDNA variants may co-occur within an individual. Heteroplasmy usually involves a small number of variant sites rather than two fully distinct haplotypes.\n- aDNA is highly fragmented and chemically damaged (e.g., cytosine deamination), and such damage can reduce amplification efficiency.\n- PCR exponentially amplifies whatever template is present; even trace amounts of modern contaminant DNA, which is intact and undamaged, can outcompete authentic aDNA during amplification.\n- Contamination with modern human DNA is a pervasive risk in aDNA workflows and is often diagnosed by the occurrence of sequences that closely or exactly match the mtDNA of laboratory personnel.\n\nWe analyze the observations:\n- The sample yields two distinct and abundant mtDNA haplotypes: N (novel but Neanderthal-like) and M (a perfect match to the lead researcher).\n- The presence of a perfect match to a particular modern individual’s mtDNA, specifically the handler, is a hallmark of contamination.\n\nWe evaluate each option against established principles and the observations:\n- Option A (heteroplasmy): While heteroplasmy exists, it typically manifests as closely related variants, not two entirely distinct haplotypes where one is a perfect match to the modern handler. The probability that a Neanderthal’s secondary heteroplasmic haplotype exactly matches a specific modern human’s mtDNA across a hypervariable region is negligibly small. This is inconsistent with the observed perfect match to the researcher.\n- Option B (interbreeding): mtDNA is strictly maternally inherited; for a Neanderthal to carry modern human mtDNA, the maternal ancestor would have to be modern human. Even if such gene flow occurred, the chance that the mtDNA sequence would be an exact match to the contemporary researcher’s haplotype (rather than a related modern haplotype) is extremely small. Moreover, calling this “definitive evidence” is scientifically unjustified given the parsimonious explanation of contamination and the ubiquity of contamination in aDNA studies.\n- Option C (PCR errors): Random PCR misincorporation errors occur at low rates and would produce scattered mismatches, not a coherent haplotype that perfectly matches the researcher’s sequence. The probability that accumulated random errors transform a Neanderthal-like haplotype into an exact modern match across the amplified region is vanishingly small.\n- Option D (convergent evolution): Independent evolution leading to an identical mtDNA sequence over a hypervariable region is extraordinarily unlikely, especially to match the exact sequence of the handling researcher. Convergent evolution cannot plausibly account for a perfect haplotype identity at this resolution.\n- Option E (contamination): Modern human contamination, especially from personnel involved in extraction and PCR setup, is a well-known and frequent issue in aDNA research. The perfect identity of Haplotype M to the lead researcher’s mtDNA is direct, specific evidence pointing to contamination during handling or processing. The coexistence of a Neanderthal-like haplotype (N) and a modern human haplotype (M) in the same amplification is exactly what contamination would produce.\n\nBy parsimony and standard aDNA quality control logic, Option E is the most scientifically sound explanation.",
            "answer": "$$\\boxed{E}$$"
        },
        {
            "introduction": "While the previous problem highlighted the danger of contamination, this exercise demonstrates how we can actively fight back by leveraging the inherent properties of ancient molecules. Ancient DNA carries chemical \"scars\" from its long burial, known as post-mortem damage (PMD), which modern DNA lacks. By quantifying these damage patterns , we can create a powerful filter to distinguish authentic ancient sequences from modern contaminants, allowing us to resolve conflicting signals and confidently determine the true genetic information of an ancient individual.",
            "id": "5011615",
            "problem": "An Upper Paleolithic skeletal sample is sequenced using standard ancient DNA protocols. Mitochondrial DNA (mtDNA) is covered at approximately $100\\times$ mean depth, and nuclear DNA is covered at approximately $0.8\\times$. Post-Mortem Damage (PMD) is assessed via the fraction of terminal cytosine-to-thymine misincorporations. It is known from many studies that typical PMD fractions in genuinely ancient molecules are substantially elevated relative to modern contamination; for this sample you may treat the characteristic damage probabilities as approximately $\\delta_{\\text{ancient}} \\approx 0.20$ and $\\delta_{\\text{modern}} \\approx 0.01$ for terminal positions.\n\nHaplogroup-defining mtDNA positions are interrogated. Reads supporting alleles diagnostic of haplogroup U total $N_U = 1700$ with $k_U = 425$ showing terminal PMD, while reads supporting alleles diagnostic of haplogroup H total $N_H = 1000$ with $k_H = 10$ showing terminal PMD. The mtDNA consensus constructed without damage filtering calls haplogroup H because more total reads at diagnostic positions support H-compatible substitutions across the full set of positions.\n\nIndependent nuclear contamination is estimated in the following way. Genetic sex determination indicates the individual is male ($XY$), and the nuclear contamination estimate derived from X chromosome apparent heterozygosity yields $\\hat{c}_{\\text{nuc}} = 0.03$ with a $95\\%$ confidence interval $[0.01, 0.05]$. You may assume the contaminant molecules are predominantly modern and lack elevated PMD relative to endogenous ancient molecules.\n\nStarting only from these fundamentals:\n- mtDNA is clonally maternally inherited and a single individual should carry one mtDNA haplogroup; discordant haplogroup signals across defining sites imply mixture.\n- Ancient molecules exhibit elevated PMD relative to modern contamination.\n- In a male individual, heterozygosity on the X chromosome arises primarily from contamination because the endogenous X is hemizygous.\n- Contamination acts as mixture: observed allele frequencies reflect $(1 - c) \\times$ endogenous contributions plus $c \\times$ contaminant contributions.\n\nUse first-principles reasoning to reconcile the discordant mtDNA haplogroup signals and decide whether the sample should be excluded from downstream population genetic analyses. Choose the single best option.\n\nA. Accept the damage-unfiltered mtDNA consensus as haplogroup H and include the sample in all downstream analyses, because the nuclear contamination estimate $\\hat{c}_{\\text{nuc}}$ is below $0.05$.\n\nB. Infer that haplogroup U represents the endogenous mtDNA based on damage patterns, treat haplogroup H reads as modern contamination, and retain the individual for nuclear DNA analyses (preferably using PMD-filtered reads). Exclude or re-call the mtDNA haplogroup using only damage-enriched molecules before reporting.\n\nC. Exclude the sample entirely from all analyses because the mtDNA shows evidence of contamination that invalidates both mtDNA and nuclear DNA signals.\n\nD. Interpret the discordance between haplogroups U and H as within-individual heteroplasmy and include both mtDNA haplogroups and all nuclear data in downstream analyses without special filtering.",
            "solution": "The central issue is the presence of reads supporting two distinct mitochondrial DNA (mtDNA) haplogroups, U and H. Since an individual should possess only one mtDNA haplogroup, this observation indicates a mixture of DNA from at least two sources. The task is to determine which signal is endogenous and which is a contaminant.\n\nWe use the principle that ancient DNA exhibits elevated Post-Mortem Damage (PMD) compared to modern DNA. The characteristic PMD probabilities are given as $\\delta_{\\text{ancient}} \\approx 0.20$ and $\\delta_{\\text{modern}} \\approx 0.01$. We calculate the empirical PMD fraction for the reads supporting each haplogroup.\n\nFor reads supporting haplogroup U:\nThe empirical PMD fraction is $\\hat{\\delta}_U = \\frac{k_U}{N_U} = \\frac{425}{1700} = 0.25$.\nThis value is highly consistent with the expected PMD for ancient DNA ($\\approx 0.20$).\n\nFor reads supporting haplogroup H:\nThe empirical PMD fraction is $\\hat{\\delta}_H = \\frac{k_H}{N_H} = \\frac{10}{1000} = 0.01$.\nThis value is identical to the expected PMD for modern DNA ($0.01$).\n\nThis analysis provides overwhelming evidence that the haplogroup U signal originates from the endogenous, ancient individual, while the haplogroup H signal originates from modern contamination. The unfiltered consensus call of haplogroup H is therefore an artifact.\n\nThe nuclear DNA contamination is independently estimated at $\\hat{c}_{\\text{nuc}} = 0.03$ (3%), which is a low level often acceptable for analysis of rare samples. The presence of mtDNA contamination does not automatically invalidate nuclear data. Therefore, the appropriate action is to correct the mtDNA haplogroup assignment based on the PMD data and proceed with analyzing the nuclear genome, preferably using methods that account for or filter out contamination.\n\nBased on this reasoning:\n- **Option A** is incorrect because it accepts a demonstrably false mtDNA haplogroup call.\n- **Option B** is correct. It properly identifies the endogenous haplogroup (U) using PMD, correctly identifies the H signal as contamination, and rightly concludes that the nuclear DNA is valuable and can be analyzed with appropriate care.\n- **Option C** is too conservative. It unnecessarily discards valuable nuclear data that has a low, quantified level of contamination.\n- **Option D** is biologically implausible. It proposes heteroplasmy between distant haplogroups and ignores the starkly different PMD profiles, which contradict this hypothesis.\n\nThus, the most scientifically sound conclusion is described in Option B.",
            "answer": "$$\\boxed{B}$$"
        },
        {
            "introduction": "Beyond contamination, the sparse nature of ancient DNA presents its own analytical hurdles, as we rarely obtain enough sequencing reads to be confident about an individual's complete diploid genotype. This practice delves into the statistical consequences of low coverage, revealing the high probability of miscalling a heterozygote as a homozygote. Understanding this fundamental limitation  is key to appreciating why researchers often forego standard genotyping in favor of \"pseudo-haploid\" calls, a crucial workaround for robust population-level analyses.",
            "id": "5011595",
            "problem": "Ancient Deoxyribonucleic Acid (aDNA) studies often confront low sequencing coverage at individual genomic sites, which challenges diploid genotype inference. Consider a single bi-allelic locus that is truly heterozygous in an ancient human genome. Assume that each of the $c$ independent sequencing reads covering the locus samples one of the two alleles with equal probability $1/2$ and that read errors and mapping biases are negligible so that the per-read probability of reporting either allele is exactly $1/2$. A standard heterozygote detection rule calls a site as heterozygous if the observed minor-allele fraction lies within the interval $\\left[\\tau, 1 - \\tau\\right]$, with $0 < \\tau \\leq \\frac{1}{2}$, and otherwise calls the site as homozygous. Equivalently, if $X$ is the number of reads supporting one arbitrarily labeled allele, the site is called heterozygous only when $X \\in \\{t, t+1, \\dots, c - t\\}$, where $t = \\lceil \\tau c \\rceil$ is the minimum minor-allele count required.\n\nStarting from the binomial sampling model and the definition of the decision rule above, derive a closed-form expression, in terms of $c$ and $\\tau$, for the expected error rate defined as the probability that a truly heterozygous site is miscalled as homozygous under this rule. Express your final answer as a single analytic expression involving $c$ and $\\tau$ only. No numerical evaluation is required.\n\nThen, using the derived expression and reasoning from first principles, explain why pseudo-haploid calling (one randomly chosen read per site to represent the allele state) is preferred in low coverage ancient genomes for downstream population genetic analyses. You must base your explanation on the consequences of low $c$ for the heterozygote misclassification probability under the diploid calling rule described above. No additional formulas beyond the derived expression should be introduced.",
            "solution": "The problem requires two parts: first, a closed-form expression for the probability that a truly heterozygous site is miscalled as homozygous, and second, an explanation for the preference for pseudo-haploid calling in low-coverage studies based on this expression.\n\n**Part 1: Derivation of the Error Rate**\n\nLet the two alleles at a truly heterozygous locus be $A_1$ and $A_2$. We have $c$ independent sequencing reads, and the probability of sampling either allele is $1/2$. Let $X$ be the number of reads supporting allele $A_1$. $X$ follows a binomial distribution, $X \\sim \\text{Binomial}(c, 1/2)$, with a probability mass function $P(X=k) = \\binom{c}{k} (1/2)^c$.\n\nA site is miscalled as homozygous if the number of reads for the minor allele is less than a threshold $t = \\lceil \\tau c \\rceil$. This corresponds to observing $X < t$ or $X > c-t$. The total error probability, $P(\\text{error})$, is the sum of probabilities for these outcomes:\n$$P(\\text{error}) = P(X \\leq t-1) + P(X \\geq c-t+1)$$\nDue to the symmetry of the binomial distribution with $p=1/2$ (i.e., $\\binom{c}{k} = \\binom{c}{c-k}$), the two terms are equal: $P(X \\leq t-1) = P(X \\geq c-t+1)$.\nTherefore, we can write:\n$$P(\\text{error}) = 2 \\times P(X \\leq t-1) = 2 \\sum_{k=0}^{t-1} P(X=k)$$\nSubstituting the PMF:\n$$P(\\text{error}) = 2 \\sum_{k=0}^{t-1} \\binom{c}{k} \\left(\\frac{1}{2}\\right)^c$$\nFactoring out the constant term gives the final closed-form expression:\n$$P(\\text{error}) = 2^{1-c} \\sum_{k=0}^{\\lceil \\tau c \\rceil - 1} \\binom{c}{k}$$\nThis expression represents the probability of observing a number of minor allele reads less than the threshold $t$, multiplied by two to account for both alleles being potentially the minor one.\n\n**Part 2: Rationale for Pseudo-Haploid Calling**\n\nLow coverage in aDNA studies means that the number of reads, $c$, covering any given site is small. The derived expression reveals the consequences of a small $c$. When $c$ is small, random sampling variance is high. This means that even at a truly heterozygous site, it is highly probable to randomly sample reads representing only one of the two alleles (e.g., $X=0$ or $X=c$) or a highly skewed ratio of alleles.\n\nThe diploid calling rule requires a minimum count of the minor allele, $t = \\lceil \\tau c \\rceil$, to be observed. For low $c$, it is difficult to meet this criterion. For instance, if coverage $c=2$ and the threshold is $\\tau=1/3$, then $t = \\lceil 2/3 \\rceil = 1$. The site is called homozygous if $X=0$ or $X=2$. The error probability is $P(\\text{error}) = 2^{1-2}\\sum_{k=0}^{0} \\binom{2}{k} = (1/2)\\binom{2}{0} = 1/2$. A $50\\%$ error rate is extremely high. If coverage is $c=1$, it is impossible to meet any minor allele threshold $t \\ge 1$, so the error rate is $1$, meaning all heterozygotes are miscalled.\n\nThis systematic misclassification of true heterozygotes as homozygotes introduces a severe bias in downstream analyses. It leads to a significant underestimation of heterozygosity and genetic diversity, which in turn biases estimates of population differentiation, relatedness, and other key population genetic statistics.\n\nPseudo-haploid calling is a strategy to mitigate this bias. Instead of attempting to make a diploid genotype call, which is highly error-prone at low coverage, this method involves randomly selecting a single read at each site to represent the allele. At a truly heterozygous site, this procedure correctly samples one of the two alleles with probability $1/2$ each. While this approach discards information about the heterozygosity of an individual at a specific site, it provides an unbiased sample of alleles from that individual's genome. When data from many sites or many individuals are aggregated, the resulting allele frequencies are not systematically biased towards homozygosity. This makes the data more reliable for population-level inferences, where accurate allele frequency estimation is more critical than accurate individual diploid genotyping. Thus, the high heterozygote misclassification probability, quantified by our derived expression for low $c$, is the fundamental reason for preferring the less biased pseudo-haploid approach for low-coverage aDNA.",
            "answer": "$$\n\\boxed{2^{1-c} \\sum_{k=0}^{\\lceil \\tau c \\rceil - 1} \\binom{c}{k}}\n$$"
        }
    ]
}