{
    "hands_on_practices": [
        {
            "introduction": "在磁共振成像（MRI）中，傅里叶变换是连接图像域和k空间（频率域）的桥梁。帕塞瓦尔定理是傅里叶分析中的一个基本原则，它指出在酉傅里叶变换下，信号的总能量保持不变。这个性质至关重要，因为它确保了在k空间中测得的信号能量直接对应于最终图像的能量。本练习 () 将通过编写代码来数值验证这一关键的守恒定律，从而加深您对图像域和k空间之间内在联系的理解。",
            "id": "4870067",
            "problem": "你需要编写一个完整、可运行的程序，使用离散傅里叶变换（DFT）来测试图像域和频域（在磁共振成像（MRI）中通常称为k空间）之间的能量守恒。此任务旨在验证幺正变换下由基本原理帕塞瓦尔定理所预测的等式。\n\n请从以下在医学成像基础理论中标准的基本概念开始：\n\n1. 复数值信号或图像被建模为一维或二维的有限样本数组。对于长度为 $N$ 的一维信号，记为 $s[n] \\in \\mathbb{C}$，其中 $n \\in \\{0,1,\\dots,N-1\\}$；对于大小为 $M \\times N$ 的二维数组，记为 $s[m,n] \\in \\mathbb{C}$，其中 $m \\in \\{0,1,\\dots,M-1\\}$ 且 $n \\in \\{0,1,\\dots,N-1\\}$。\n\n2. 幺正离散傅里叶变换（DFT）定义如下\n$$\n\\hat{s}[k] = \\frac{1}{\\sqrt{N}} \\sum_{n=0}^{N-1} s[n] \\, e^{-i 2\\pi \\frac{n k}{N}}, \\quad k \\in \\{0,1,\\dots,N-1\\},\n$$\n对于一维情况，以及\n$$\n\\hat{s}[u,v] = \\frac{1}{\\sqrt{MN}} \\sum_{m=0}^{M-1} \\sum_{n=0}^{N-1} s[m,n] \\, e^{-i 2\\pi \\left( \\frac{m u}{M} + \\frac{n v}{N} \\right)}, \\quad (u,v) \\in \\{0,1,\\dots,M-1\\} \\times \\{0,1,\\dots,N-1\\},\n$$\n对于二维情况，其中 $i$ 是虚数单位，所有角度均以弧度为单位。\n\n3. 图像域中复数数组的能量定义为\n$$\nE_{\\text{image}} = \\sum_{n} |s[n]|^2 \\quad \\text{(一维)}, \\qquad E_{\\text{image}} = \\sum_{m} \\sum_{n} |s[m,n]|^2 \\quad \\text{(二维)},\n$$\nk空间中的能量定义为\n$$\nE_{\\text{k}} = \\sum_{k} |\\hat{s}[k]|^2 \\quad \\text{(一维)}, \\qquad E_{\\text{k}} = \\sum_{u} \\sum_{v} |\\hat{s}[u,v]|^2 \\quad \\text{(二维)}.\n$$\n\n你的程序必须实现以下功能：\n\n- 使用与上述DFT定义相对应的幺正快速傅里叶变换（FFT）实现（即标准正交归一化）。\n- 对于每个提供的测试用例，计算 $E_{\\text{image}}$ 和 $E_{\\text{k}}$ 并验证 $|E_{\\text{image}} - E_{\\text{k}}| \\le \\varepsilon$ 是否成立，容差 $\\varepsilon = 10^{-12}$。\n- 输出一个单行，其中包含一个用方括号括起来的、逗号分隔的布尔值列表。每个布尔值对应于相应测试用例的能量等式是否在容差范围内成立。例如，输出必须是 $[b_1,b_2,b_3,b_4]$ 的形式，其中每个 $b_j$ 是不带引号的 `True` 或 `False`。\n\n此问题不涉及物理单位；将所有量视为无量纲。任何三角函数中的所有角度都必须以弧度为单位。\n\n测试套件：\n\n对以下信号/图像进行上述计算：\n\n1. 长度为7的一维复信号：\n   - $s[0] = 1 + 2i$\n   - $s[1] = -0.5 + 0.25i$\n   - $s[2] = 0 + 0i$\n   - $s[3] = 3 - 4i$\n   - $s[4] = -2 + 0i$\n   - $s[5] = 0.1 + 0.2i$\n   - $s[6] = -1.5 - 0.5i$\n\n2. 由解析公式定义的大小为 $8 \\times 8$ 的二维复图像\n   $$\n   s[m,n] = \\exp\\!\\big(-\\alpha \\big((m - m_0)^2 + (n - n_0)^2\\big)\\big) + i \\, \\beta \\, \\sin\\!\\Big(2\\pi \\Big(\\frac{u_0 m}{M} + \\frac{v_0 n}{N}\\Big)\\Big),\n   $$\n   参数为 $M = 8$，$N = 8$，$\\alpha = 0.3$，$\\beta = 0.2$，$m_0 = 2.3$，$n_0 = 5.5$，$u_0 = 1.5$，$v_0 = 2.0$。所有三角函数角度均以弧度为单位。\n\n3. 长度为16、完全为零的一维复信号：\n   - 对于所有 $n \\in \\{0,1,\\dots,15\\}$，$s[n] = 0 + 0i$。\n\n4. 大小为 $10 \\times 12$、包含单个复冲激的二维复图像：\n   - 在 $(p,q) = (2,7)$ 处，$s[p,q] = 3 - 4i$，对于所有其他 $(m,n)$，$s[m,n] = 0 + 0i$。\n\n你的程序应生成单行输出，其中包含用方括号括起来的逗号分隔的结果列表（例如，$[b_1,b_2,b_3,b_4]$）。每个 $b_j$ 必须是一个布尔值，表示相应测试用例的 $|E_{\\text{image}} - E_{\\text{k}}| \\le 10^{-12}$ 是否成立。",
            "solution": "该问题要求针对几个测试用例，验证幺正离散傅里叶变换（DFT）的帕塞瓦尔定理。该定理是傅里叶分析和信号处理中的一个基本原理，它确立了信号的能量在幺正DFT下是守恒的。在医学成像中，特别是在磁共振成像（MRI）中，这对应于图像域和频域（或k空间）之间的能量相等。\n\n离散复数值信号 $s$ 的能量定义为其样本的模平方和。这等效于信号的 $L_2$ 范数的平方。对于长度为 $N$ 的一维信号 $s[n]$，其图像域能量为：\n$$\nE_{\\text{image}} = \\sum_{n=0}^{N-1} |s[n]|^2\n$$\n对于大小为 $M \\times N$ 的二维信号 $s[m,n]$，其能量为：\n$$\nE_{\\text{image}} = \\sum_{m=0}^{M-1} \\sum_{n=0}^{N-1} |s[m,n]|^2\n$$\n\n问题定义了一个幺正DFT。信号 $s$ 的变换结果是一个k空间信号 $\\hat{s}$。对于一维情况，变换为：\n$$\n\\hat{s}[k] = \\frac{1}{\\sqrt{N}} \\sum_{n=0}^{N-1} s[n] \\, e^{-i 2\\pi \\frac{n k}{N}}\n$$\n对于二维情况，变换为：\n$$\n\\hat{s}[u,v] = \\frac{1}{\\sqrt{MN}} \\sum_{m=0}^{M-1} \\sum_{n=0}^{N-1} s[m,n] \\, e^{-i 2\\pi \\left( \\frac{m u}{M} + \\frac{n v}{N} \\right)}\n$$\n归一化因子 $\\frac{1}{\\sqrt{N}}$ 和 $\\frac{1}{\\sqrt{MN}}$ 确保了该变换是幺正的。\n\nk空间中相应的能量计算方式与图像域能量类似：\n$$\nE_{\\text{k}} = \\sum_{k=0}^{N-1} |\\hat{s}[k]|^2 \\quad \\text{(一维)}\n$$\n$$\nE_{\\text{k}} = \\sum_{u=0}^{M-1} \\sum_{v=0}^{N-1} |\\hat{s}[u,v]|^2 \\quad \\text{(二维)}\n$$\n\n幺正DFT的帕塞瓦尔定理指出能量是守恒的，即 $E_{\\text{image}} = E_{\\text{k}}$。我们的任务是为四个不同的信号数值验证这个等式。由于浮点运算的性质，我们不期望精确相等，而是测试绝对差是否在一个小容差 $\\varepsilon = 10^{-12}$ 之内：\n$$\n|E_{\\text{image}} - E_{\\text{k}}| \\le \\varepsilon\n$$\n\n每个测试用例的计算步骤如下：\n1.  将输入信号 $s$ 构建为复数NumPy数组。\n2.  通过对 $s$ 中各元素的绝对值平方求和来计算图像域能量 $E_{\\text{image}}$。这可以通过 `numpy.sum(numpy.abs(s)**2)` 计算。\n3.  使用快速傅里叶变换（FFT）算法计算k空间表示 $\\hat{s}$。为了匹配问题中的幺正定义，必须使用NumPy的FFT函数（一维为 `numpy.fft.fft`，二维为 `numpy.fft.fft2`）中的 `norm=\"ortho\"` 选项。这将应用正确的标准正交缩放。\n4.  通过对 $\\hat{s}$ 中各元素的绝对值平方求和来计算k空间能量 $E_{\\text{k}}$。\n5.  使用指定的容差 $\\varepsilon$ 比较 $E_{\\text{image}}$ 和 $E_{\\text{k}}$。结果是一个布尔值，表示能量守恒原理是否成立。\n\n四个测试用例的实现如下：\n-   **情况1：** 直接从提供的值列表中创建一个长度为7的一维复信号。\n-   **情况2：** 以编程方式生成一个大小为 $8 \\times 8$ 的二维复图像。我们创建两个索引网格，$m \\in \\{0, \\dots, 7\\}$ 和 $n \\in \\{0, \\dots, 7\\}$，并对每个坐标对 $(m,n)$ 应用给定的解析公式。\n-   **情况3：** 创建一个长度为16的一维复信号，它是一个零数组。这是一个平凡的基本情况，其中两种能量预期都将精确为0。\n-   **情况4：** 创建一个大小为 $10 \\times 12$ 的二维复图像，它是一个零数组，在坐标 $(2,7)$ 处有一个单个非零值（一个复冲激）。\n\n程序将对所有四个情况执行此过程，并以指定格式报告布尔结果。",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Verifies Parseval's theorem for the unitary DFT on four test cases.\n    \"\"\"\n    \n    tolerance = 1e-12\n    results = []\n\n    # --- Test Case 1: 1D complex signal of length 7 ---\n    s1 = np.array([\n        1 + 2j,\n        -0.5 + 0.25j,\n        0 + 0j,\n        3 - 4j,\n        -2 + 0j,\n        0.1 + 0.2j,\n        -1.5 - 0.5j\n    ], dtype=np.complex128)\n    \n    # --- Test Case 2: 2D complex image of size 8x8 from formula ---\n    M2, N2 = 8, 8\n    alpha = 0.3\n    beta = 0.2\n    m0, n0 = 2.3, 5.5\n    u0, v0 = 1.5, 2.0\n    \n    m_indices, n_indices = np.meshgrid(np.arange(M2), np.arange(N2), indexing='ij')\n    \n    term1 = np.exp(-alpha * ((m_indices - m0)**2 + (n_indices - n0)**2))\n    term2 = 1j * beta * np.sin(2 * np.pi * (u0 * m_indices / M2 + v0 * n_indices / N2))\n    s2 = term1 + term2\n\n    # --- Test Case 3: 1D complex signal of length 16 (all zeros) ---\n    s3 = np.zeros(16, dtype=np.complex128)\n\n    # --- Test Case 4: 2D complex image 10x12 with a single impulse ---\n    M4, N4 = 10, 12\n    s4 = np.zeros((M4, N4), dtype=np.complex128)\n    s4[2, 7] = 3 - 4j\n    \n    signals = [s1, s2, s3, s4]\n\n    for s in signals:\n        # Calculate image domain energy\n        e_image = np.sum(np.abs(s)**2)\n\n        # Compute k-space representation using unitary FFT\n        if s.ndim == 1:\n            s_hat = np.fft.fft(s, norm=\"ortho\")\n        else: # s.ndim == 2\n            s_hat = np.fft.fft2(s, norm=\"ortho\")\n        \n        # Calculate k-space energy\n        e_k = np.sum(np.abs(s_hat)**2)\n        \n        # Verify if energy is preserved within tolerance\n        is_preserved = np.abs(e_image - e_k) = tolerance\n        results.append(is_preserved)\n\n    # Format the final output string\n    output_str = f\"[{','.join(map(str, results))}]\"\n    print(output_str)\n\nsolve()\n```"
        },
        {
            "introduction": "从k空间数据重建图像是一个典型的逆问题，而这些问题往往是“不适定的”，意味着微小的噪声可能会导致重建结果产生巨大的误差。本练习 () 探讨了一种经典的正则化方法——截断奇异值分解（TSVD），以稳定重建过程。通过亲手计算和分析，您将探索正则化中固有的偏差-方差权衡，这是统计估计和机器学习中的一个核心概念，并学习如何选择一个最优的截断水平来最小化总重建误差。",
            "id": "4870009",
            "problem": "考虑一个复值成像系统中的线性逆问题，其中测量值建模为 $y \\in \\mathbb{C}^m$，未知图像参数向量为 $x \\in \\mathbb{C}^n$，已知系统矩阵为 $A \\in \\mathbb{C}^{m \\times n}$，加性零均值复噪声为 $e \\in \\mathbb{C}^m$，其协方差为 $\\sigma^2 I_m$。正向模型为 $y = A x + e$。设 $A$ 的奇异值分解 (SVD) 为 $A = U \\Sigma V^{H}$，其中 $U \\in \\mathbb{C}^{m \\times m}$ 和 $V \\in \\mathbb{C}^{n \\times n}$ 是酉矩阵，$\\Sigma \\in \\mathbb{R}^{m \\times n}$ 是对角矩阵，其对角线上的非负奇异值为 $\\{\\sigma_i\\}$，$H$ 表示共轭转置。对于截断水平 $k$（$0 \\leq k \\leq r$，其中 $r$ 是 $A$ 的数值秩），截断SVD估计量定义为 $x_k = V_k \\Sigma_k^{-1} U_k^{H} y$，其中 $U_k \\in \\mathbb{C}^{m \\times k}$ 包含前 $k$ 个左奇异向量，$V_k \\in \\mathbb{C}^{n \\times k}$ 包含前 $k$ 个右奇异向量，$\\Sigma_k \\in \\mathbb{R}^{k \\times k}$ 的对角线上包含前 $k$ 个奇异值。\n\n从上述定义和线性估计量框架出发，推导截断SVD估计量的偏差、方差和期望平方重建误差 $E[\\|x_k - x\\|_2^2]$ 的表达式，这些表达式应是关于截断水平 $k$、奇异值 $\\{\\sigma_i\\}$、右奇异向量 $V_k$、未知向量 $x$ 和噪声方差 $\\sigma^2$ 的函数。您的推导必须基于酉矩阵、投影以及协方差为 $\\sigma^2 I_m$ 的复值随机向量的线性估计量的性质。\n\n然后，实现一个完整的程序，对下面列出的每个测试用例，计算：\n- 对从 $0$ 到 $r$ 的每个截断水平 $k$：\n    - 偏差平方项 $\\| (I_n - V_k V_k^{H}) x \\|_2^2$。\n    - 方差项 $\\sigma^2 \\sum_{i=1}^{k} \\sigma_i^{-2}$。\n    - 期望平方误差 $E[\\|x_k - x\\|_2^2]$，即偏差平方项与方差项之和。\n- 使期望平方误差最小化的截断水平 $k^\\star$（如果存在多个，选择最小的 $k$）。\n- 在 $k^\\star$ 处的期望平方误差，以及在 $k^\\star$ 处的偏差平方项和方差项。\n\n所有向量范数必须是欧几里得2-范数，所有涉及复数量的矩阵转置必须使用共轭转置操作。本问题不要求物理单位。本问题不使用角度。\n\n测试套件（每个用例提供 $A$、$x$ 和 $\\sigma^2$）：\n\n- 用例 1（对角，良态）：\n    - $m = n = 5$，\n    - $A = \\mathrm{diag}([1.0, 0.9, 0.8, 0.7, 0.6])$,\n    - $x = [1.0, -0.5, 0.7, -0.3, 0.2]^T$,\n    - $\\sigma^2 = 0.0001$。\n\n- 用例 2（对角，病态）：\n    - $m = n = 6$,\n    - $A = \\mathrm{diag}([5.0, 3.0, 1.5, 0.6, 0.3, 0.1])$,\n    - $x = [1.0, 1.0, 1.0, 1.0, 1.0, 1.0]^T$,\n    - $\\sigma^2 = 0.02$。\n\n- 用例 3（部分离散傅里叶变换，复值，欠定）：\n    - $m = 6$, $n = 8$,\n    - 令 $F \\in \\mathbb{C}^{8 \\times 8}$ 为酉离散傅里叶变换矩阵，其元素为 $F_{j\\ell} = \\frac{1}{\\sqrt{8}} \\exp\\left(-\\mathrm{i} \\frac{2\\pi}{8} j \\ell\\right)$，其中 $j,\\ell \\in \\{0,1,\\dots,7\\}$。\n    - $A$ 由 $F$ 的前 $6$ 行构成（即 $A \\in \\mathbb{C}^{6 \\times 8}$ 是行限制的酉矩阵）。\n    - $x = [1.0 + 0.0\\mathrm{i}, 0.0 + 1.0\\mathrm{i}, -1.0 + 0.0\\mathrm{i}, 0.0 - 1.0\\mathrm{i}, 0.5 + 0.0\\mathrm{i}, -0.5 + 0.0\\mathrm{i}, 0.0 + 0.25\\mathrm{i}, -0.25 + 0.0\\mathrm{i}]^T$,\n    - $\\sigma^2 = 0.1$。\n\n程序要求：\n- 对于每个测试用例，计算上述与截断水平相关的量，确定 $k^\\star$，并以指定的输出格式报告元组 $(k^\\star, E[\\|x_{k^\\star} - x\\|_2^2], \\| (I_n - V_{k^\\star} V_{k^\\star}^{H}) x \\|_2^2, \\sigma^2 \\sum_{i=1}^{k^\\star} \\sigma_i^{-2})$。\n- 最终输出中的浮点数必须四舍五入到 $6$ 位小数。\n- 最终输出格式必须是单行，包含一个用方括号括起来的逗号分隔列表，按顺序连接每个测试用例的四个值。具体而言，输出必须是 $[k_1^\\star,\\ \\text{mse}_1,\\ \\text{bias}_1,\\ \\text{var}_1,\\ k_2^\\star,\\ \\text{mse}_2,\\ \\text{bias}_2,\\ \\text{var}_2,\\ k_3^\\star,\\ \\text{mse}_3,\\ \\text{bias}_3,\\ \\text{var}_3]$ 的形式，其中 $k_j^\\star$ 是整数，其他每个值是四舍五入到 $6$ 位小数的浮点数。\n\n您的推导必须避免使用快捷公式，并从SVD、线性估计量、酉投影以及复值空间中协方差的定义出发。确保科学真实性和内部一致性。程序必须是自包含的，无需任何外部输入即可复现。",
            "solution": "本问题要求在线性逆问题的背景下，推导截断奇异值分解（TSVD）估计量的偏差、方差和期望平方误差，并随后进行数值实现。\n\n线性模型由 $y = Ax + e$ 给出，其中 $y \\in \\mathbb{C}^m$ 是测量值，$x \\in \\mathbb{C}^n$ 是未知向量，$A \\in \\mathbb{C}^{m \\times n}$ 是系统矩阵，$e \\in \\mathbb{C}^m$ 是零均值复加性噪声，其协方差为 $E[ee^H] = \\sigma^2 I_m$。\n\n$A$ 的奇异值分解（SVD）为 $A = U \\Sigma V^H$，其中 $U$ 和 $V$ 是酉矩阵，$\\Sigma$ 是一个实值 $m \\times n$ 对角矩阵，其非负奇异值为 $\\sigma_1 \\ge \\sigma_2 \\ge \\dots \\ge \\sigma_r  0$，其中 $r = \\text{rank}(A)$。我们可以将 $A$ 表示为外积之和：$A = \\sum_{i=1}^r \\sigma_i u_i v_i^H$，其中 $u_i$ 和 $v_i$ 分别是 $U$ 和 $V$ 的第 $i$ 列。\n\n对于截断水平 $k$（$0 \\le k \\le r$），TSVD估计量定义为 $x_k = V_k \\Sigma_k^{-1} U_k^H y$。这里，$V_k$ 由 $V$ 的前 $k$ 列组成，$U_k$ 由 $U$ 的前 $k$ 列组成，$\\Sigma_k$ 是一个 $k \\times k$ 对角矩阵，其对角线上是前 $k$ 个奇异值 $\\{\\sigma_1, \\dots, \\sigma_k\\}$。该估计量也可以使用 $A$ 的秩-$k$ 近似 $A_k = U_k \\Sigma_k V_k^H$ 的伪逆来表示，即 $x_k = A_k^\\dagger y$。\n\n### 偏差的推导\n\n估计量 $\\hat{\\theta}$ 的偏差定义为 $B(\\hat{\\theta}) = E[\\hat{\\theta}] - \\theta$。对于TSVD估计量 $x_k$，其偏差为 $B(x_k) = E[x_k] - x$。\n\n首先，我们计算估计量的期望值 $E[x_k]$：\n$$E[x_k] = E[V_k \\Sigma_k^{-1} U_k^H y]$$\n由于 $V_k$、$\\Sigma_k$ 和 $U_k$ 是确定性的，我们可以将期望算子移到内部：\n$$E[x_k] = V_k \\Sigma_k^{-1} U_k^H E[y]$$\n测量值 $y$ 的期望值为：\n$$E[y] = E[Ax + e] = A E[x] + E[e]$$\n由于 $x$ 是一个确定性（但未知）的向量，且噪声 $e$ 是零均值的（$E[e]=0$），我们有 $E[y] = Ax$。\n将此代回 $E[x_k]$ 的表达式中：\n$$E[x_k] = V_k \\Sigma_k^{-1} U_k^H (Ax)$$\n现在，我们代入 $A$ 的SVD：\n$$E[x_k] = (V_k \\Sigma_k^{-1} U_k^H) (U \\Sigma V^H) x$$\n乘积 $A_k^\\dagger A = (V_k \\Sigma_k^{-1} U_k^H)(U \\Sigma V^H)$ 可以很好地简化。\n$A_k^\\dagger A = V_k \\Sigma_k^{-1} U_k^H \\sum_{i=1}^r \\sigma_i u_i v_i^H = V_k \\Sigma_k^{-1} \\sum_{i=1}^k \\sigma_i (U_k^H u_i) v_i^H = V_k \\Sigma_k^{-1} \\sum_{i=1}^k \\sigma_i e_i v_i^H = V_k \\Sigma_k^{-1} \\Sigma_k V_k^H = V_k V_k^H$。\n因此，估计量的期望值为：\n$$E[x_k] = (V_k V_k^H) x$$\n矩阵 $P_k = V_k V_k^H$ 是到由前 $k$ 个右奇异向量张成的子空间上的正交投影算子。\n因此，偏差向量为：\n$$B(x_k) = E[x_k] - x = V_k V_k^H x - x = (V_k V_k^H - I_n) x$$\n偏差的平方是该向量的欧几里得范数的平方：\n$$\\|B(x_k)\\|_2^2 = \\|(V_k V_k^H - I_n) x\\|_2^2$$\n由于 $(I_n - V_k V_k^H)$ 是一个正交投影算子，这等价于 $\\|(I_n - V_k V_k^H)x\\|_2^2$。向量 $x$ 可以在右奇异向量基 $\\{v_i\\}_{i=1}^n$ 中展开为 $x = \\sum_{i=1}^n (v_i^H x) v_i$。投影 $V_k V_k^H x = \\sum_{i=1}^k v_i v_i^H x = \\sum_{i=1}^k (v_i^H x) v_i$。\n偏差向量为 $(V_k V_k^H - I_n)x = -\\sum_{i=k+1}^n (v_i^H x) v_i$。由于 $\\{v_i\\}$ 的标准正交性，其范数平方为：\n$$\\|B(x_k)\\|_2^2 = \\sum_{i=k+1}^n |v_i^H x|^2$$\n\n### 方差的推导\n\n向量估计量的方差是其协方差矩阵的迹，即 $\\text{Var}(x_k) = \\text{Tr}(\\text{Cov}(x_k))$。协方差矩阵为 $\\text{Cov}(x_k) = E[(x_k - E[x_k])(x_k - E[x_k])^H]$。\n首先，我们求出估计量的随机分量：\n$$x_k - E[x_k] = V_k \\Sigma_k^{-1} U_k^H y - V_k \\Sigma_k^{-1} U_k^H (Ax) = V_k \\Sigma_k^{-1} U_k^H (y - Ax) = V_k \\Sigma_k^{-1} U_k^H e$$\n现在，我们计算协方差矩阵：\n$$\\text{Cov}(x_k) = E[(V_k \\Sigma_k^{-1} U_k^H e) (V_k \\Sigma_k^{-1} U_k^H e)^H] = E[V_k \\Sigma_k^{-1} U_k^H e e^H U_k \\Sigma_k^{-1} V_k^H]$$\n将确定性矩阵移到期望之外：\n$$\\text{Cov}(x_k) = V_k \\Sigma_k^{-1} U_k^H E[e e^H] U_k \\Sigma_k^{-1} V_k^H$$\n代入 $E[e e^H] = \\sigma^2 I_m$：\n$$\\text{Cov}(x_k) = V_k \\Sigma_k^{-1} U_k^H (\\sigma^2 I_m) U_k \\Sigma_k^{-1} V_k^H = \\sigma^2 V_k \\Sigma_k^{-1} (U_k^H U_k) \\Sigma_k^{-1} V_k^H$$\n由于 $U_k$ 的列是标准正交的，$U_k^H U_k = I_k$。奇异值是实数，因此 $\\Sigma_k^{-1}$ 是自伴的。\n$$\\text{Cov}(x_k) = \\sigma^2 V_k \\Sigma_k^{-1} I_k \\Sigma_k^{-1} V_k^H = \\sigma^2 V_k \\Sigma_k^{-2} V_k^H$$\n方差是该矩阵的迹。利用迹的循环性质 $\\text{Tr}(ABC) = \\text{Tr}(CAB)$：\n$$\\text{Var}(x_k) = \\text{Tr}(\\sigma^2 V_k \\Sigma_k^{-2} V_k^H) = \\sigma^2 \\text{Tr}(\\Sigma_k^{-2} V_k^H V_k)$$\n由于 $V_k$ 的列是标准正交的，$V_k^H V_k = I_k$。\n$$\\text{Var}(x_k) = \\sigma^2 \\text{Tr}(\\Sigma_k^{-2})$$\n由于 $\\Sigma_k^{-2}$ 是一个对角矩阵，其对角元素为 $\\sigma_i^{-2}$（$i=1, \\dots, k$），所以迹是其对角元素之和：\n$$\\text{Var}(x_k) = \\sigma^2 \\sum_{i=1}^k \\frac{1}{\\sigma_i^2}$$\n\n### 期望平方误差（MSE）的推导\n\n期望平方误差，或称均方误差（MSE），是 $E[\\|x_k - x\\|_2^2]$。它可以分解为偏差和方差分量：\n$$E[\\|x_k - x\\|_2^2] = E[\\|(x_k - E[x_k]) + (E[x_k] - x)\\|_2^2]$$\n令零均值随机分量为 $\\tilde{x}_k = x_k - E[x_k]$，确定性偏差向量为 $B_k = E[x_k] - x$。\n$$E[\\|\\tilde{x}_k + B_k\\|_2^2] = E[(\\tilde{x}_k + B_k)^H (\\tilde{x}_k + B_k)] = E[\\tilde{x}_k^H \\tilde{x}_k + \\tilde{x}_k^H B_k + B_k^H \\tilde{x}_k + B_k^H B_k]$$\n根据期望的线性性质，且由于 $E[\\tilde{x}_k] = 0$：\n$$E[\\|\\tilde{x}_k + B_k\\|_2^2] = E[\\tilde{x}_k^H \\tilde{x}_k] + E[\\tilde{x}_k^H]B_k + B_k^H E[\\tilde{x}_k] + B_k^H B_k = E[\\|\\tilde{x}_k\\|_2^2] + \\|B_k\\|_2^2$$\n第一项是零均值分量的期望范数，即方差：\n$$E[\\|\\tilde{x}_k\\|_2^2] = E[\\|x_k - E[x_k]\\|_2^2] = E[\\text{Tr}((x_k-E[x_k])(x_k-E[x_k])^H)] = \\text{Tr}(\\text{Cov}(x_k)) = \\text{Var}(x_k)$$\n第二项是偏差向量的范数平方。\n因此，MSE是方差和偏差平方之和：\n$$E[\\|x_k - x\\|_2^2] = \\text{Var}(x_k) + \\|B(x_k)\\|_2^2$$\n代入推导出的表达式：\n$$E[\\|x_k - x\\|_2^2] = \\sigma^2 \\sum_{i=1}^k \\frac{1}{\\sigma_i^2} + \\sum_{i=k+1}^n |v_i^H x|^2$$\n这个最终表达式揭示了基本的偏差-方差权衡。随着截断水平 $k$ 的增加，偏差项（来自截断解空间的误差）减小，而方差项（来自噪声放大的误差）增加，特别是当小的奇异值 $\\sigma_i$ 被包含在求逆过程中时。最优的 $k^\\star$ 平衡了这两种相反的影响，以最小化总期望误差。\n对于 $k=0$ 的特殊情况，估计量为 $x_0 = 0$。方差的和为空，因此为 $0$。偏差的和从 $i=1$ 到 $n$，得到 $\\sum_{i=1}^n |v_i^H x|^2 = \\|x\\|_2^2$。MSE 为 $\\|x\\|_2^2$，这是正确的，因为 $E[\\|0-x\\|_2^2] = \\|x\\|_2^2$。",
            "answer": "```python\nimport numpy as np\nfrom scipy.linalg import dft\n\ndef solve():\n    \"\"\"\n    Main function to solve the problem for all test cases.\n    \"\"\"\n\n    def _compute_metrics_for_case(A, x, sigma_sq):\n        \"\"\"\n        Computes the optimal truncation k and associated metrics for a single case.\n        \"\"\"\n        m, n = A.shape\n        \n        # Perform SVD\n        # full_matrices=True is important to get the full V matrix for n-dim space\n        U, s, Vh = np.linalg.svd(A, full_matrices=True)\n        \n        # Determine numerical rank r\n        # The problem defines k up to r, so we consider only non-zero singular values.\n        # A small tolerance is used for numerical stability.\n        # Although the problems are designed to have clear ranks, this is robust.\n        r = np.sum(s > 1e-12)\n\n        k_values = range(r + 1)\n        mses = []\n        biases = []\n        variances = []\n        \n        # Pre-compute coefficients |v_i^H x|^2\n        # Vh contains rows v_i^H.\n        v_coeffs_sq = np.abs(Vh @ x)**2\n\n        for k in k_values:\n            if k == 0:\n                # For k=0, estimator is x0=0. Variance is 0. Bias^2 is ||x||^2.\n                # bias_sq = np.sum_{i=1..n} |v_i^H x|^2\n                bias_sq = np.sum(v_coeffs_sq)\n                var = 0.0\n            else:\n                # Bias term: sum_{i=k+1..n} |v_i^H x|^2\n                # In 0-based indexing, this is sum over elements from index k onwards.\n                bias_sq = np.sum(v_coeffs_sq[k:])\n                \n                # Variance term: sigma^2 * sum_{i=1..k} 1/sigma_i^2\n                # s contains singular values, s[:k] are the first k values\n                var = sigma_sq * np.sum(1.0 / s[:k]**2)\n\n            mse = bias_sq + var\n            mses.append(mse)\n            biases.append(bias_sq)\n            variances.append(var)\n\n        # Find the optimal truncation level k_star (smallest k in case of a tie)\n        k_star = np.argmin(mses)\n        \n        # Get metrics for k_star\n        min_mse = mses[k_star]\n        bias_at_k_star = biases[k_star]\n        var_at_k_star = variances[k_star]\n\n        return k_star, min_mse, bias_at_k_star, var_at_k_star\n\n    # --- Test Cases ---\n    \n    # Case 1: diagonal, well-conditioned\n    A1 = np.diag([1.0, 0.9, 0.8, 0.7, 0.6])\n    x1 = np.array([1.0, -0.5, 0.7, -0.3, 0.2])\n    sigma_sq1 = 0.0001\n\n    # Case 2: diagonal, ill-conditioned\n    A2 = np.diag([5.0, 3.0, 1.5, 0.6, 0.3, 0.1])\n    x2 = np.array([1.0, 1.0, 1.0, 1.0, 1.0, 1.0])\n    sigma_sq2 = 0.02\n\n    # Case 3: partial discrete Fourier transform, complex\n    F = dft(8, scale='sqrtn')\n    A3 = F[:6, :]\n    x3 = np.array([1.0 + 0.0j, 0.0 + 1.0j, -1.0 + 0.0j, 0.0 - 1.0j, \n                   0.5 + 0.0j, -0.5 + 0.0j, 0.0 + 0.25j, -0.25 + 0.0j])\n    sigma_sq3 = 0.1\n\n    test_cases = [\n        (A1, x1, sigma_sq1),\n        (A2, x2, sigma_sq2),\n        (A3, x3, sigma_sq3),\n    ]\n\n    all_results = []\n    for A, x, sigma_sq in test_cases:\n        k_star, mse, bias_sq, var = _compute_metrics_for_case(A, x, sigma_sq)\n        all_results.append(str(k_star))\n        all_results.append(f\"{mse:.6f}\")\n        all_results.append(f\"{bias_sq:.6f}\")\n        all_results.append(f\"{var:.6f}\")\n    \n    # Final print statement in the exact required format.\n    print(f\"[{','.join(all_results)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "现代医学成像技术，特别是压缩感知MRI，依赖于先进的迭代算法来从不完整的测量数据中重建出高质量的图像。这些方法通常通过在最小二乘法数据保真项中加入一个正则化项（如 $L_1$ 范数）来实现，以利用图像的稀疏性等先验知识。本练习 () 将指导您实现快速迭代收缩阈值算法（FISTA）的单步更新，这是一种功能强大的加速近端梯度方法。通过这个实践，您将亲身体验用于解决复杂优化问题的前沿技术。",
            "id": "4870062",
            "problem": "考虑一个用于复值医学成像的离散线性测量模型，其中复图像向量 $x \\in \\mathbb{C}^n$ 通过一个已知的线性算子（矩阵）$A \\in \\mathbb{C}^{m \\times n}$ 与测量向量 $y \\in \\mathbb{C}^m$ 相关联。一种标准的重建方法是最小化复合目标函数\n$$\nf(x) = \\frac{1}{2}\\|A x - y\\|_2^2 + \\lambda \\|x\\|_1,\n$$\n其中 $\\lambda \\in \\mathbb{R}_{\\ge 0}$ 是一个正则化参数，对于复数 $x$，$\\|x\\|_1$ 定义为 $\\|x\\|_1 = \\sum_{i=1}^n |x_i|$，其中 $|x_i|$ 表示第 $i$ 个元素的复数模。快速迭代收缩阈值算法（FISTA）(Fast Iterative Shrinkage-Thresholding Algorithm (FISTA)) 对此类复合目标函数执行加速近端梯度步。您的任务是为复值图像向量实现单次 FISTA 更新，并跟踪目标函数值在此次更新后是否减小。\n\n该实现必须遵守以下数学约束：\n\n- 使用标准的复值内积和相关的共轭转置。平滑数据保真项 $g(x)=\\frac{1}{2}\\|A x - y\\|_2^2$ 的梯度是关于复向量 $x$ 使用 $A$ 的共轭转置计算的。\n- 使用等于平滑项 $g(x)$ 梯度的 Lipschitz 常数 $L$ 的步长，其中 $L$ 等于 $A$ 的谱范数的平方，即 $L = \\|A\\|_2^2$。该值应从 $A$ 计算得出（不要硬编码 $L$）。\n- 应用一个保持相位的逐元素复数软阈值近端算子：对于复向量 $v$ 中的每个元素 $v_i$，阈值为 $\\tau$ 的近端映射定义为\n$$\n\\operatorname{soft}_\\tau(v_i) = \\begin{cases}\n0,  |v_i| \\le \\tau,\\\\\n\\left(1 - \\frac{\\tau}{|v_i|}\\right) v_i,  |v_i|  \\tau.\n\\end{cases}\n$$\n- 从给定的 $x_k$、$x_{k-1}$ 和 $t_{k-1}$ 开始，执行恰好一次加速近端梯度（FISTA）更新，生成 $x_{k+1}$ 和 $t_k$，并计算 $f(x_k)$ 和 $f(x_{k+1})$。\n\n您的程序必须实现上述内容，并为以下参数值测试套件生成结果：\n\n- 测试用例 1（正常路径，酉采样）：\n    - $n = 4$, $m = 4$。\n    - $A$ 是 $4 \\times 4$ 酉离散傅里叶变换（DFT）矩阵，其元素为\n      $A_{p,q} = \\frac{1}{\\sqrt{4}} \\exp\\left(-\\mathrm{i} \\frac{2\\pi p q}{4}\\right)$ for $p,q \\in \\{0,1,2,3\\}$。\n    - $y = [1 + 2\\mathrm{i},\\ -0.5 + 0.3\\mathrm{i},\\ 0.2 - 1.1\\mathrm{i},\\ 0 + 0\\mathrm{i}]$。\n    - $\\lambda = 0.3$。\n    - $x_k = [-0.2 + 0.1\\mathrm{i},\\ 0.7 - 0.4\\mathrm{i},\\ 0 + 0\\mathrm{i},\\ -0.3 + 0.9\\mathrm{i}]$。\n    - $x_{k-1} = [-0.1 + 0.0\\mathrm{i},\\ 0.5 - 0.5\\mathrm{i},\\ 0.1 - 0.2\\mathrm{i},\\ -0.4 + 0.8\\mathrm{i}]$。\n    - $t_{k-1} = 1.0$。\n- 测试用例 2（边界情况，零测量，单位前向模型）：\n    - $n = 4$, $m = 4$。\n    - $A$ 是 $4 \\times 4$ 单位矩阵。\n    - $y = [0 + 0\\mathrm{i},\\ 0 + 0\\mathrm{i},\\ 0 + 0\\mathrm{i},\\ 0 + 0\\mathrm{i}]$。\n    - $\\lambda = 1.0$。\n    - $x_k = [0.3 - 0.2\\mathrm{i},\\ -0.1 + 0.1\\mathrm{i},\\ 0.05 + 0.0\\mathrm{i},\\ -0.5 + 0.0\\mathrm{i}]$。\n    - $x_{k-1} = [0.3 - 0.2\\mathrm{i},\\ -0.1 + 0.1\\mathrm{i},\\ 0.05 + 0.0\\mathrm{i},\\ -0.5 + 0.0\\mathrm{i}]$。\n    - $t_{k-1} = 1.0$。\n- 测试用例 3（边缘情况，病态缩放）：\n    - $n = 3$, $m = 3$。\n    - $A$ 是对角线为 $[2.0,\\ 1.0,\\ 0.5]$ 的 $3 \\times 3$ 对角矩阵。\n    - $y = [0.5 + 0.0\\mathrm{i},\\ -1.0 + 0.5\\mathrm{i},\\ 0.2 - 0.3\\mathrm{i}]$。\n    - $\\lambda = 0.05$。\n    - $x_k = [0.1 + 0.2\\mathrm{i},\\ -0.3 + 0.4\\mathrm{i},\\ 0.5 - 0.6\\mathrm{i}]$。\n    - $x_{k-1} = [0.05 + 0.1\\mathrm{i},\\ -0.25 + 0.35\\mathrm{i},\\ 0.45 - 0.55\\mathrm{i}]$。\n    - $t_{k-1} = 1.0$。\n\n对于每个测试用例，计算目标函数值 $f(x_k)$ 和 $f(x_{k+1})$，以及一个指示目标函数是否减小的布尔值，即 $f(x_{k+1})  f(x_k)$ 是否成立。\n\n最终输出格式规范：\n您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表形式的结果，每个元素对应一个测试用例，并且本身是形式为 $[f(x_k), f(x_{k+1}), \\text{decreased}]$ 的列表。例如，输出应类似于 $[[a_1,b_1,c_1],[a_2,b_2,c_2],[a_3,b_3,c_3]]$，其中 $a_i$ 和 $b_i$ 是实数（浮点数），$c_i$ 是布尔值。不涉及角度或物理单位；所有输出均为无量纲量。",
            "solution": "该问题要求为医学成像中常见的复值逆问题实现单次迭代的快速迭代收缩阈值算法（FISTA）。我们还必须在更新前后评估目标函数，以检查其值是否减小。\n\n要最小化的目标函数具有复合形式 $f(x) = g(x) + h(x)$，其中：\n1.  $g(x) = \\frac{1}{2}\\|A x - y\\|_2^2$ 是数据保真项。该函数是凸的，并且具有 Lipschitz 连续梯度。这里，$x \\in \\mathbb{C}^n$ 是图像向量，$y \\in \\mathbb{C}^m$ 是测量向量，$A \\in \\mathbb{C}^{m \\times n}$ 是前向算子。范数 $\\| \\cdot \\|_2$ 是标准的欧几里得范数。\n2.  $h(x) = \\lambda \\|x\\|_1$ 是正则化项，用于促进解的稀疏性。参数 $\\lambda \\in \\mathbb{R}_{\\ge 0}$ 控制此正则化的强度。复数 $L_1$ 范数定义为 $\\|x\\|_1 = \\sum_{i=1}^n |x_i|$，其中 $|x_i|$ 是复数 $x_i$ 的模。此函数是凸函数，但并非处处可微，这排除了使用简单梯度下降法的可能性。\n\nFISTA 是一种非常适合此类复合目标函数的加速近端梯度法。单次迭代从前两次迭代的结果 $x_k$ 和 $x_{k-1}$ 计算出第 $(k+1)$ 次迭代的结果 $x_{k+1}$，包括以下步骤。\n\n**1. Lipschitz 常数和步长计算**\n\n平滑项 $g(x)$ 关于复向量 $x$ 的梯度由 $\\nabla g(x) = A^H(Ax - y)$ 给出，其中 $A^H$ 是 $A$ 的共轭转置。算法的梯度下降部分需要一个步长 $\\alpha$。为保证收敛，$\\alpha$ 应小于或等于 $\\nabla g(x)$ 的 Lipschitz 常数 $L$ 的倒数。常数 $L$ 由 $A$ 的谱范数的平方给出：\n$$\nL = \\|A^H A\\|_2 = \\|A\\|_2^2\n$$\n其中 $\\|A\\|_2$ 是 $A$ 的最大奇异值。我们将使用指定的步长 $\\alpha = 1/L$。\n\n**2. FISTA 更新序列**\n\n给定迭代结果 $x_k$ 和 $x_{k-1}$，以及一个动量参数 $t_{k-1}$，更新按以下方式进行：\n\n-   **动量参数更新**：首先，更新动量参数 $t_k$：\n    $$\n    t_k = \\frac{1 + \\sqrt{1 + 4 t_{k-1}^2}}{2}\n    $$\n    我们将 $t_{k-1}$ 作为初始状态的一部分给定。\n\n-   **外推步骤**：使用前两次迭代的结果计算一个中间外推点 $z_k$，为下降过程引入动量：\n    $$\n    z_k = x_k + \\frac{t_{k-1} - 1}{t_k}(x_k - x_{k-1})\n    $$\n\n-   **梯度下降和近端映射**：然后从外推点 $z_k$ 开始执行一个标准的近端梯度步。这包括对平滑部分 $g(x)$ 进行梯度下降步，然后对非平滑部分 $h(x)$ 应用近端算子。\n    $$\n    x_{k+1} = \\operatorname{prox}_{\\alpha h}\\left(z_k - \\alpha \\nabla g(z_k)\\right)\n    $$\n    $h(x) = \\lambda \\|x\\|_1$ 的近端算子是逐元素的复数软阈值算子。令 $\\tau = \\alpha \\lambda$ 为阈值。该操作为：\n    $$\n    x_{k+1} = \\operatorname{soft}_{\\alpha \\lambda}\\left(z_k - \\alpha A^H(A z_k - y)\\right)\n    $$\n    应用于复向量 $v$ 的复数软阈值函数 $\\operatorname{soft}_\\tau(\\cdot)$ 对每个元素 $v_i$ 的操作定义如下：\n    $$\n    \\operatorname{soft}_\\tau(v_i) = \\begin{cases}\n    0,  |v_i| \\le \\tau, \\\\\n    \\left(1 - \\frac{\\tau}{|v_i|}\\right) v_i,  |v_i|  \\tau.\n    \\end{cases}\n    $$\n    此操作将模大于 $\\tau$ 的元素的模向零收缩，并将模小于或等于 $\\tau$ 的元素精确地设置为零，同时保持非零元素的相位。\n\n**3. 目标函数评估**\n\n为满足问题要求，我们必须计算当前迭代结果 $x_k$ 和新迭代结果 $x_{k+1}$ 处的目标函数值：\n$$f(x_k) = \\frac{1}{2}\\|A x_k - y\\|_2^2 + \\lambda \\sum_{i=1}^n |x_{k,i}|$$\n$$f(x_{k+1}) = \\frac{1}{2}\\|A x_{k+1} - y\\|_2^2 + \\lambda \\sum_{i=1}^n |x_{k+1,i}|$$\n最后，我们通过检查布尔条件 $f(x_{k+1})  f(x_k)$ 来确定更新是否导致目标函数值的减小。\n\n该实现将对三个提供的测试用例中的每一个都遵循这些步骤。谱范数 $\\|A\\|_2$ 将使用标准线性代数例程进行数值计算。所有向量和矩阵运算都将使用复数算术。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the problem by performing a single FISTA update for three test cases\n    and evaluating the objective function.\n    \"\"\"\n\n    # Test case 1: Unitary DFT matrix\n    n1, m1 = 4, 4\n    p, q = np.meshgrid(np.arange(n1), np.arange(m1), indexing='ij')\n    A1 = (1 / np.sqrt(n1)) * np.exp(-1j * 2 * np.pi * p * q / n1)\n    y1 = np.array([1 + 2j, -0.5 + 0.3j, 0.2 - 1.1j, 0 + 0j], dtype=np.complex128)\n    lambda1 = 0.3\n    xk1 = np.array([-0.2 + 0.1j, 0.7 - 0.4j, 0 + 0j, -0.3 + 0.9j], dtype=np.complex128)\n    xk_minus_1_1 = np.array([-0.1 + 0.0j, 0.5 - 0.5j, 0.1 - 0.2j, -0.4 + 0.8j], dtype=np.complex128)\n    tk_minus_1_1 = 1.0\n\n    # Test case 2: Identity matrix, zero measurements\n    n2, m2 = 4, 4\n    A2 = np.eye(n2, dtype=np.complex128)\n    y2 = np.zeros(m2, dtype=np.complex128)\n    lambda2 = 1.0\n    xk2 = np.array([0.3 - 0.2j, -0.1 + 0.1j, 0.05 + 0.0j, -0.5 + 0.0j], dtype=np.complex128)\n    xk_minus_1_2 = xk2.copy()\n    tk_minus_1_2 = 1.0\n\n    # Test case 3: Diagonal scaling matrix\n    n3, m3 = 3, 3\n    A3 = np.diag(np.array([2.0, 1.0, 0.5], dtype=np.complex128))\n    y3 = np.array([0.5 + 0.0j, -1.0 + 0.5j, 0.2 - 0.3j], dtype=np.complex128)\n    lambda3 = 0.05\n    xk3 = np.array([0.1 + 0.2j, -0.3 + 0.4j, 0.5 - 0.6j], dtype=np.complex128)\n    xk_minus_1_3 = np.array([0.05 + 0.1j, -0.25 + 0.35j, 0.45 - 0.55j], dtype=np.complex128)\n    tk_minus_1_3 = 1.0\n    \n    test_cases = [\n        (A1, y1, lambda1, xk1, xk_minus_1_1, tk_minus_1_1),\n        (A2, y2, lambda2, xk2, xk_minus_1_2, tk_minus_1_2),\n        (A3, y3, lambda3, xk3, xk_minus_1_3, tk_minus_1_3),\n    ]\n\n    def objective_function(x, A, y, lambda_reg):\n        \"\"\"Computes the value of the composite objective function.\"\"\"\n        residual = A @ x - y\n        data_fidelity = 0.5 * np.linalg.norm(residual)**2\n        l1_norm = np.sum(np.abs(x))\n        return data_fidelity + lambda_reg * l1_norm\n\n    def complex_soft_threshold(v, tau):\n        \"\"\"Applies the complex soft-thresholding operator entry-wise.\"\"\"\n        v_abs = np.abs(v)\n        result = np.zeros_like(v, dtype=v.dtype)\n        \n        # Indices where magnitude is greater than the threshold\n        idx = v_abs > tau\n        \n        # Apply thresholding only to these elements to avoid division by zero\n        if np.any(idx):\n            factor = 1 - tau / v_abs[idx]\n            result[idx] = factor * v[idx]\n        \n        return result\n\n    def perform_fista_update(A, y, lambda_reg, xk, xk_minus_1, tk_minus_1):\n        \"\"\"Performs a single FISTA update and returns objective values.\"\"\"\n        \n        # 1. Compute Lipschitz constant and step size\n        L = np.linalg.norm(A, 2)**2\n        alpha = 1.0 / L\n\n        # Evaluate objective at current point xk\n        f_xk = objective_function(xk, A, y, lambda_reg)\n\n        # 2. FISTA update sequence\n        # Update momentum parameter\n        tk = (1.0 + np.sqrt(1.0 + 4.0 * tk_minus_1**2)) / 2.0\n        \n        # Extrapolation step\n        zk = xk + ((tk_minus_1 - 1.0) / tk) * (xk - xk_minus_1)\n\n        # Gradient of smooth term at zk\n        grad_g_zk = A.conj().T @ (A @ zk - y)\n        \n        # Argument for the proximal operator\n        prox_arg = zk - alpha * grad_g_zk\n        \n        # Proximal mapping (soft-thresholding)\n        threshold = alpha * lambda_reg\n        xk_plus_1 = complex_soft_threshold(prox_arg, threshold)\n\n        # Evaluate objective at new point xk+1\n        f_xk_plus_1 = objective_function(xk_plus_1, A, y, lambda_reg)\n        \n        # Check if objective decreased\n        decreased = f_xk_plus_1  f_xk\n        \n        return f_xk, f_xk_plus_1, decreased\n\n    results_data = []\n    for case in test_cases:\n        A, y, lambda_reg, xk, xk_minus_1, tk_minus_1 = case\n        f_xk, f_xk_plus_1, decreased = perform_fista_update(A, y, lambda_reg, xk, xk_minus_1, tk_minus_1)\n        results_data.append([f_xk, f_xk_plus_1, decreased])\n\n    # Format the final output string\n    formatted_results = []\n    for res in results_data:\n        f_xk, f_xk_plus_1, dec = res\n        # Use standard Python boolean string representation ('True'/'False')\n        dec_str = str(dec)\n        formatted_results.append(f\"[{f_xk},{f_xk_plus_1},{dec_str}]\")\n\n    print(f\"[{','.join(formatted_results)}]\")\n\n\nsolve()\n```"
        }
    ]
}