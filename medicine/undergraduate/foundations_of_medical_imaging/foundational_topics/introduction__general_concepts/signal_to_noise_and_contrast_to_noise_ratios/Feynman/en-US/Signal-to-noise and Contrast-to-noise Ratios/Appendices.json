{
    "hands_on_practices": [
        {
            "introduction": "In medical imaging, particularly in Magnetic Resonance Imaging (MRI), controlling the amount of noise is crucial for diagnostic quality. One of the most direct parameters an operator can adjust is the receiver bandwidth ($RBW$), which determines the range of frequencies the system listens to. This exercise explores the fundamental relationship between $RBW$ and the Signal-to-Noise Ratio ($SNR$), demonstrating the trade-off between acquisition speed and noise level. By deriving how noise depends on bandwidth, you will gain a core insight into optimizing MRI protocols .",
            "id": "4545322",
            "problem": "An image reconstruction pipeline for magnetic resonance imaging used in radiomics can be modeled at baseband as a linear time-invariant (LTI) receiver that demodulates the signal and applies a real-valued filter of adjustable receiver bandwidth (RBW). Consider a homogeneous phantom region in which the complex baseband signal at the receiver input can be written as $x(t) = s(t) + n(t)$, where $s(t)$ is a deterministic, band-limited component determined by excitation and relaxation, and $n(t)$ is Additive White Gaussian Noise (AWGN) with a two-sided, flat power spectral density $S_{0}$ (units of intensity squared per hertz). The receiver filter $H_{B}(f)$ has unity gain over a symmetric baseband of width $B$ hertz, is negligible outside that band, and all other acquisition parameters (flip angle, repetition time, echo time, voxel size, and coil loading) are held fixed. The Region of Interest (ROI) mean intensity is the expected value of the reconstructed magnitude signal, and the noise is characterized by the standard deviation of the background signal in a signal-free region.\n\na) Starting from the definitions of power spectral density and the output noise variance of an LTI system driven by stationary noise, derive how the output noise standard deviation depends on the receiver bandwidth $B$. Under the stated assumptions, argue whether the ROI mean intensity changes with $B$.\n\nb) An initial acquisition uses receiver bandwidth $B_{1} = 200 \\ \\mathrm{Hz/pixel}$ and yields a Signal-to-Noise Ratio (SNR) of $\\mathrm{SNR}_{1} = 40$ in the homogeneous ROI. A second acquisition uses $B_{2} = 800 \\ \\mathrm{Hz/pixel}$, with all other parameters unchanged and the signal spectrum fully contained within the passband for both bandwidths. Compute the new SNR, $\\mathrm{SNR}_{2}$. Express the final SNR as a pure number (dimensionless).",
            "solution": "The problem is validated as self-contained, scientifically grounded, well-posed, and objective. All necessary information is provided, the physical model is a standard and appropriate representation for analyzing noise in MRI systems, and the question is formally solvable.\n\n**Part a) Derivation of Noise Dependence and Argument for Signal Intensity**\n\nThe problem states that the input noise $n(t)$ is Additive White Gaussian Noise (AWGN) with a two-sided, flat power spectral density (PSD) $S_{0}$. The receiver is modeled as a linear time-invariant (LTI) system with a frequency response $H_{B}(f)$. For an LTI system, the PSD of the output noise, $S_{n,out}(f)$, is related to the PSD of the input noise, $S_{n,in}(f)$, by the equation:\n$$S_{n,out}(f) = S_{n,in}(f) |H_{B}(f)|^2$$\nIn this case, the input noise PSD is constant for all frequencies, $S_{n,in}(f) = S_{0}$.\n\nThe receiver filter $H_{B}(f)$ is described as an ideal rectangular (or \"brick-wall\") filter with unity gain over a symmetric baseband of width $B$ and zero gain otherwise. Mathematically, the magnitude of its frequency response is:\n$$|H_{B}(f)| = \\begin{cases} 1 & \\text{for } |f| \\le \\frac{B}{2} \\\\ 0 & \\text{for } |f| > \\frac{B}{2} \\end{cases}$$\n\nThe output noise power, which is the variance $\\sigma_{n,out}^2$ of the output noise signal, is the integral of the output noise PSD over all frequencies:\n$$\\sigma_{n,out}^2 = \\int_{-\\infty}^{\\infty} S_{n,out}(f) \\, df = \\int_{-\\infty}^{\\infty} S_{0} |H_{B}(f)|^2 \\, df$$\nSubstituting the definition of $|H_{B}(f)|$:\n$$\\sigma_{n,out}^2 = \\int_{-B/2}^{B/2} S_{0} \\cdot (1)^2 \\, df = S_{0} \\int_{-B/2}^{B/2} \\, df$$\nEvaluating the integral gives:\n$$\\sigma_{n,out}^2 = S_{0} \\left[ f \\right]_{-B/2}^{B/2} = S_{0} \\left( \\frac{B}{2} - \\left(-\\frac{B}{2}\\right) \\right) = S_{0} B$$\nThe output noise standard deviation, $\\sigma_{n,out}$, is the square root of the variance:\n$$\\sigma_{n,out} = \\sqrt{S_{0} B}$$\nThis derivation shows that the output noise standard deviation is directly proportional to the square root of the receiver bandwidth $B$, i.e., $\\sigma_{n,out} \\propto \\sqrt{B}$.\n\nNext, we consider the ROI mean intensity. The problem defines this as the expected value of the reconstructed magnitude signal. The reconstructed signal is the sum of the filtered deterministic signal component, $s_{out}(t)$, and the filtered noise component, $n_{out}(t)$. The crucial information provided is that the deterministic signal $s(t)$ is band-limited and its spectrum is fully contained within the passband for both bandwidths $B_1$ and $B_2$. This means that for any frequency $f$ where the Fourier transform of the signal, $S(f)$, is non-zero, the filter gain $|H_B(f)| = 1$. Consequently, the output signal's spectrum is $S_{out}(f) = S(f)H_B(f) = S(f)$. This implies that the output signal in the time domain, $s_{out}(t)$, is identical to the input signal $s(t)$ and does not change as the bandwidth $B$ is varied (as long as $B$ is wide enough, which is the given condition).\nThe ROI mean intensity is $I_{ROI} = E[|s_{out}(t) + n_{out}(t)|]$. Since $s_{out}(t)$ is deterministic and independent of $B$, and the noise $n_{out}(t)$ is a zero-mean process, the mean signal magnitude is primarily determined by the magnitude of $s_{out}(t)$. For high signal-to-noise ratios, the random fluctuations from noise have a negligible effect on the mean value of the magnitude. Therefore, under the stated assumptions, the ROI mean intensity is independent of the receiver bandwidth $B$.\n\n**Part b) Calculation of the New Signal-to-Noise Ratio (SNR)**\n\nThe Signal-to-Noise Ratio ($\\mathrm{SNR}$) is defined in the context of this problem as the ratio of the ROI mean intensity, $I_{ROI}$, to the background noise standard deviation, $\\sigma_{n,out}$.\n$$\\mathrm{SNR} = \\frac{I_{ROI}}{\\sigma_{n,out}}$$\nFrom Part (a), we established that $I_{ROI}$ is constant with respect to the receiver bandwidth $B$, and $\\sigma_{n,out} = \\sqrt{S_0 B}$. Therefore, we can write the SNR as:\n$$\\mathrm{SNR} = \\frac{I_{ROI}}{\\sqrt{S_0 B}}$$\nSince $I_{ROI}$ and $S_0$ are constants in this problem, the SNR is inversely proportional to the square root of the bandwidth:\n$$\\mathrm{SNR} \\propto \\frac{1}{\\sqrt{B}}$$\nWe can set up a ratio between the two acquisition scenarios:\n$$\\frac{\\mathrm{SNR}_{2}}{\\mathrm{SNR}_{1}} = \\frac{I_{ROI} / \\sqrt{S_0 B_2}}{I_{ROI} / \\sqrt{S_0 B_1}} = \\frac{\\sqrt{S_0 B_1}}{\\sqrt{S_0 B_2}} = \\sqrt{\\frac{B_1}{B_2}}$$\nWe are given the initial conditions: $B_1 = 200 \\ \\mathrm{Hz/pixel}$ and $\\mathrm{SNR}_1 = 40$. The new bandwidth is $B_2 = 800 \\ \\mathrm{Hz/pixel}$. We can now solve for $\\mathrm{SNR}_2$:\n$$\\mathrm{SNR}_{2} = \\mathrm{SNR}_{1} \\sqrt{\\frac{B_1}{B_2}}$$\nSubstituting the numerical values:\n$$\\mathrm{SNR}_{2} = 40 \\sqrt{\\frac{200}{800}} = 40 \\sqrt{\\frac{1}{4}} = 40 \\times \\frac{1}{2} = 20$$\nThe new Signal-to-Noise Ratio, $\\mathrm{SNR}_2$, is $20$.",
            "answer": "$$\\boxed{20}$$"
        },
        {
            "introduction": "Image processing techniques are often used to improve the visual quality of medical images. One common method is zero-filling, which adds zeros to the raw data in k-space to produce a smoother, less pixelated final image. While the resulting image may look better, does this process actually improve our ability to distinguish signal from noise? This practice challenges you to rigorously analyze the effect of zero-filling on the true Signal-to-Noise Ratio, providing a crucial lesson on the difference between visual interpolation and a genuine increase in information content .",
            "id": "4923452",
            "problem": "A one-dimensional Magnetic Resonance Imaging (MRI) experiment acquires a uniformly sampled set of $k$-space data $\\{K[m]\\}_{m=0}^{N-1}$, where each acquired sample obeys $K[m] = S[m] + \\eta[m]$. The deterministic signal component $S[m]$ is bandlimited to the acquired support, and the noise $\\eta[m]$ is zero-mean complex Gaussian, independent across $m$, with variance $\\operatorname{Var}(\\eta[m]) = \\sigma_{k}^{2}$ for every $m$. The image is reconstructed on an $N$-point grid by the unitary inverse Discrete Fourier Transform (DFT),\n$$\nx_{N}[n] = \\frac{1}{\\sqrt{N}}\\sum_{m=0}^{N-1} K[m] \\exp\\!\\left(i\\,\\frac{2\\pi m n}{N}\\right), \\quad n=0,1,\\dots,N-1.\n$$\nConsider now a zero-filling interpolation in $k$-space to size $M=\\alpha N$ for an integer $\\alpha>1$, defined by\n$$\nK_{\\mathrm{ZP}}[m] =\n\\begin{cases}\nK[m], & m=0,1,\\dots,N-1 \\\\\n0, & m=N,\\dots,M-1\n\\end{cases}\n$$\nfollowed by the $M$-point unitary inverse DFT to produce an oversampled image\n$$\nx_{M}[n] = \\frac{1}{\\sqrt{M}}\\sum_{m=0}^{M-1} K_{\\mathrm{ZP}}[m] \\exp\\!\\left(i\\,\\frac{2\\pi m n}{M}\\right), \\quad n=0,1,\\dots,M-1.\n$$\nDefine the signal-to-noise ratio (SNR) at a pixel as the ratio of the magnitude of the deterministic image component to the standard deviation of the noise in the complex image at that pixel. Using only the linearity of the inverse DFT, the independence and variance of the $k$-space noise, and the fact that the inverse DFT specified above is unitary, derive the closed-form expression for the ratio\n$$\nr(N,M) \\equiv \\frac{\\text{SNR of }x_{M}\\text{ at any pixel}}{\\text{SNR of }x_{N}\\text{ at any pixel}}\n$$\nas a function of $N$ and $M$ under zero-filling interpolation. Your derivation should begin from the stated definitions and properties without invoking any shortcut formulas. The scenario is scientifically realistic: $S[m]$ can be arbitrary within the acquired support so long as it is deterministic and bandlimited, and there is no additional apodization or filtering beyond zero-filling. The final answer must be a single analytic expression in terms of $N$ and $M$. No rounding is required. Explain, within your derivation, why zero-filling can make the image look smoother even though the true SNR does not increase.",
            "solution": "The problem statement is subjected to validation.\n\n### Step 1: Extract Givens\n- Acquired $k$-space data: $\\{K[m]\\}_{m=0}^{N-1}$\n- Data model: $K[m] = S[m] + \\eta[m]$\n- Signal component: $S[m]$ is deterministic and bandlimited to the acquired support.\n- Noise component: $\\eta[m]$ is zero-mean complex Gaussian, independent across $m$.\n- Noise variance in $k$-space: $\\operatorname{Var}(\\eta[m]) = \\sigma_{k}^{2}$ for all $m$.\n- $N$-point image reconstruction (unitary inverse DFT): $x_{N}[n] = \\frac{1}{\\sqrt{N}}\\sum_{m=0}^{N-1} K[m] \\exp\\!\\left(i\\,\\frac{2\\pi m n}{N}\\right)$, for $n=0,1,\\dots,N-1$.\n- Zero-filling factor: Integer $\\alpha > 1$, with new size $M=\\alpha N$.\n- Zero-filled $k$-space data: $K_{\\mathrm{ZP}}[m] = K[m]$ for $m=0,1,\\dots,N-1$ and $K_{\\mathrm{ZP}}[m]=0$ for $m=N,\\dots,M-1$.\n- $M$-point image reconstruction (unitary inverse DFT): $x_{M}[n] = \\frac{1}{\\sqrt{M}}\\sum_{m=0}^{M-1} K_{\\mathrm{ZP}}[m] \\exp\\!\\left(i\\,\\frac{2\\pi m n}{M}\\right)$, for $n=0,1,\\dots,M-1$.\n- Definition of SNR: The ratio of the magnitude of the deterministic image component to the standard deviation of the noise in the complex image at that pixel.\n- Desired quantity: The ratio $r(N,M) \\equiv \\frac{\\text{SNR of }x_{M}\\text{ at any pixel}}{\\text{SNR of }x_{N}\\text{ at any pixel}}$.\n- Derivation constraints: Use only linearity of the inverse DFT, independence and variance of the $k$-space noise, and unitarity of the inverse DFT.\n\n### Step 2: Validate Using Extracted Givens\nThe problem is scientifically grounded, well-posed, and objective. It describes a standard signal processing technique (zero-filling) in the context of MRI and asks for a quantitative comparison of signal-to-noise ratio. All terms are well-defined, and the provided information is internally consistent and sufficient for a unique solution. The model for signal and noise is a standard and physically realistic simplification used in the foundations of medical imaging. The problem is not trivial, as it requires a careful application of principles of Fourier analysis and statistics. The question is verifiable through mathematical derivation.\n\n### Step 3: Verdict and Action\nThe problem is valid. A complete solution will be provided.\n\nThe signal-to-noise ratio (SNR) at an image pixel is defined as the ratio of the magnitude of the deterministic signal component to the standard deviation of the noise at that pixel. We will derive this quantity for both the $N$-point image, $x_N[n]$, and the $M$-point zero-filled image, $x_M[n]$, and then compute their ratio.\n\nDue to the linearity of the inverse Discrete Fourier Transform (DFT), we can decompose the reconstructed images into their signal and noise components:\n$$x_N[n] = x_{N,S}[n] + x_{N,\\eta}[n]$$\n$$x_M[n] = x_{M,S}[n] + x_{M,\\eta}[n]$$\nwhere the signal components are $x_{N,S}[n] = \\mathcal{F}_N^{-1}\\{S\\}[n]$ and $x_{M,S}[n] = \\mathcal{F}_M^{-1}\\{S_{\\mathrm{ZP}}\\}[n]$, and the noise components are $x_{N,\\eta}[n] = \\mathcal{F}_N^{-1}\\{\\eta\\}[n]$ and $x_{M,\\eta}[n] = \\mathcal{F}_M^{-1}\\{\\eta_{\\mathrm{ZP}}\\}[n]$. The operators $\\mathcal{F}_N^{-1}$ and $\\mathcal{F}_M^{-1}$ denote the $N$-point and $M$-point unitary inverse DFTs, respectively.\n\nFirst, we analyze the noise properties in the image domain. For the $N$-point image, the noise component at pixel $n$ is:\n$$x_{N,\\eta}[n] = \\frac{1}{\\sqrt{N}}\\sum_{m=0}^{N-1} \\eta[m] \\exp\\left(i\\frac{2\\pi mn}{N}\\right)$$\nSince the $k$-space noise $\\eta[m]$ has zero mean, $E[\\eta[m]]=0$, the image-space noise also has zero mean:\n$$E[x_{N,\\eta}[n]] = \\frac{1}{\\sqrt{N}}\\sum_{m=0}^{N-1} E[\\eta[m]] \\exp\\left(i\\frac{2\\pi mn}{N}\\right) = 0$$\nThe variance of the complex noise at pixel $n$ is $\\sigma_{x_N,n}^2 = E[|x_{N,\\eta}[n]|^2]$.\n\\begin{align*} \\sigma_{x_N,n}^2 &= E\\left[ \\left(\\frac{1}{\\sqrt{N}}\\sum_{m=0}^{N-1} \\eta[m] e^{i\\frac{2\\pi mn}{N}}\\right) \\left(\\frac{1}{\\sqrt{N}}\\sum_{k=0}^{N-1} \\eta^*[k] e^{-i\\frac{2\\pi kn}{N}}\\right) \\right] \\\\ &= \\frac{1}{N} \\sum_{m=0}^{N-1} \\sum_{k=0}^{N-1} E[\\eta[m]\\eta^*[k]] e^{i\\frac{2\\pi(m-k)n}{N}}\\end{align*}\nGiven that the noise samples are independent with variance $\\sigma_k^2$, we have $E[\\eta[m]\\eta^*[k]] = E[|\\eta[m]|^2]\\delta_{mk} = \\sigma_k^2 \\delta_{mk}$, where $\\delta_{mk}$ is the Kronecker delta.\n$$\\sigma_{x_N,n}^2 = \\frac{1}{N} \\sum_{m=0}^{N-1} \\sum_{k=0}^{N-1} \\sigma_k^2 \\delta_{mk} e^{i\\frac{2\\pi(m-k)n}{N}} = \\frac{1}{N} \\sum_{m=0}^{N-1} \\sigma_k^2 = \\frac{N \\sigma_k^2}{N} = \\sigma_k^2$$\nThis result also follows directly from the fact that a unitary transform preserves the total variance (Parseval's theorem). The noise variance is uniform across all pixels, $\\sigma_{x_N}^2 = \\sigma_k^2$. The standard deviation of the noise in the $N$-point image is $\\sigma_{x_N} = \\sigma_k$.\n\nNext, we analyze the noise in the $M$-point zero-filled image. The zero-filled noise is $\\eta_{\\mathrm{ZP}}[m] = \\eta[m]$ for $m \\in \\{0, \\dots, N-1\\}$ and $0$ otherwise.\n$$x_{M,\\eta}[n] = \\frac{1}{\\sqrt{M}}\\sum_{m=0}^{M-1} \\eta_{\\mathrm{ZP}}[m] \\exp\\left(i\\frac{2\\pi mn}{M}\\right) = \\frac{1}{\\sqrt{M}}\\sum_{m=0}^{N-1} \\eta[m] \\exp\\left(i\\frac{2\\pi mn}{M}\\right)$$\nThe mean is again zero. The variance is:\n\\begin{align*} \\sigma_{x_M,n}^2 &= E\\left[ \\left(\\frac{1}{\\sqrt{M}}\\sum_{m=0}^{N-1} \\eta[m] e^{i\\frac{2\\pi mn}{M}}\\right) \\left(\\frac{1}{\\sqrt{M}}\\sum_{k=0}^{N-1} \\eta^*[k] e^{-i\\frac{2\\pi kn}{M}}\\right) \\right] \\\\ &= \\frac{1}{M} \\sum_{m=0}^{N-1} \\sum_{k=0}^{N-1} E[\\eta[m]\\eta^*[k]] e^{i\\frac{2\\pi(m-k)n}{M}} \\\\ &= \\frac{1}{M} \\sum_{m=0}^{N-1} \\sigma_k^2 = \\frac{N\\sigma_k^2}{M} \\end{align*}\nThe noise variance is also uniform across pixels in the $M$-point image, $\\sigma_{x_M}^2 = \\frac{N}{M}\\sigma_k^2$. The standard deviation of the noise in the $M$-point image is $\\sigma_{x_M} = \\sigma_k \\sqrt{\\frac{N}{M}}$.\n\nNow, we analyze the deterministic signal components. The problem asks for the ratio of SNRs \"at any pixel,\" which implies the ratio is independent of pixel location. This requires comparing pixels that correspond to the same physical location in the object. An $N$-point grid over a field-of-view (FOV) has pixel spacing $\\Delta x_N=\\text{FOV}/N$. An $M$-point grid has spacing $\\Delta x_M=\\text{FOV}/M$. A point at physical location $p = n_N \\Delta x_N$ in the first image corresponds to the point $p = n_M \\Delta x_M$ in the second. This leads to $n_M = n_N \\frac{\\Delta x_N}{\\Delta x_M} = n_N \\frac{M}{N}$. Since $M = \\alpha N$, the pixel $n$ in the $N$-point image corresponds to pixel $\\alpha n$ in the $M$-point image.\n\nThe signal at pixel $n$ of the $N$-point image is:\n$$x_{N,S}[n] = \\frac{1}{\\sqrt{N}}\\sum_{m=0}^{N-1} S[m] \\exp\\left(i\\frac{2\\pi mn}{N}\\right)$$\nThe signal at the corresponding pixel $\\alpha n$ of the $M$-point image is:\n$$x_{M,S}[\\alpha n] = \\frac{1}{\\sqrt{M}}\\sum_{m=0}^{M-1} S_{\\mathrm{ZP}}[m] \\exp\\left(i\\frac{2\\pi m(\\alpha n)}{M}\\right) = \\frac{1}{\\sqrt{M}}\\sum_{m=0}^{N-1} S[m] \\exp\\left(i\\frac{2\\pi m(\\alpha n)}{\\alpha N}\\right)$$\n$$x_{M,S}[\\alpha n] = \\frac{1}{\\sqrt{M}}\\sum_{m=0}^{N-1} S[m] \\exp\\left(i\\frac{2\\pi mn}{N}\\right)$$\nComparing the magnitudes of the signal components at corresponding locations:\n$$|x_{M,S}[\\alpha n]| = \\frac{1}{\\sqrt{M}}\\left|\\sum_{m=0}^{N-1} S[m] \\exp\\left(i\\frac{2\\pi mn}{N}\\right)\\right|$$\n$$|x_{N,S}[n]| = \\frac{1}{\\sqrt{N}}\\left|\\sum_{m=0}^{N-1} S[m] \\exp\\left(i\\frac{2\\pi mn}{N}\\right)\\right|$$\nThe ratio of the signal magnitudes is therefore:\n$$\\frac{|x_{M,S}[\\alpha n]|}{|x_{N,S}[n]|} = \\frac{1/\\sqrt{M}}{1/\\sqrt{N}} = \\sqrt{\\frac{N}{M}}$$\nThis ratio is independent of the pixel $n$ and the specific signal $S[m]$, as long as the signal is not zero at that location.\n\nWe can now formulate the SNRs. At pixel $n$ of the $N$-point image:\n$$\\text{SNR}_N[n] = \\frac{|x_{N,S}[n]|}{\\sigma_{x_N}} = \\frac{|x_{N,S}[n]|}{\\sigma_k}$$\nAt the corresponding pixel $\\alpha n$ of the $M$-point image:\n$$\\text{SNR}_M[\\alpha n] = \\frac{|x_{M,S}[\\alpha n]|}{\\sigma_{x_M}} = \\frac{|x_{N,S}[n]| \\sqrt{N/M}}{\\sigma_k \\sqrt{N/M}} = \\frac{|x_{N,S}[n]|}{\\sigma_k}$$\nThus, $\\text{SNR}_M[\\alpha n] = \\text{SNR}_N[n]$. The SNR at corresponding spatial locations is identical.\n\nThe ratio is then:\n$$r(N,M) = \\frac{\\text{SNR}_M[\\alpha n]}{\\text{SNR}_N[n]} = 1$$\n\nThe reason zero-filling can make an image look smoother, despite the SNR not increasing, lies in the nature of the interpolation. Zero-filling the $k$-space data from size $N$ to $M$ is mathematically equivalent to sinc interpolation of the image-domain data $x_N[n]$. The resulting image $x_M[n]$ contains points that lie on a smooth, bandlimited curve that passes through the original signal points $x_{N,S}[n]$. Displaying these finely-sampled points creates a visually smoother representation of the underlying continuous object, reducing the \"pixelated\" appearance. This visual enhancement is often misconstrued as an increase in resolution or SNR. However, no new information has been added to the $k$-space data. The noise is also interpolated. While the noise variance per pixel is reduced by a factor of $N/M$, the signal magnitude is also reduced by the same factor $\\sqrt{N/M}$ (due to the change in DFT normalization from $1/\\sqrt{N}$ to $1/\\sqrt{M}$), resulting in an unchanged SNR. This interpolation introduces correlations in the image noise, which means the noise itself also appears smoother (less \"white\"), contributing to the overall smoother aesthetic of the image. The fundamental ability to distinguish signal from noise at any given point, as quantified by the SNR, remains unchanged.",
            "answer": "$$\\boxed{1}$$"
        },
        {
            "introduction": "After exploring how specific acquisition and processing parameters affect $SNR$, we now ask a more fundamental question: for a given signal and noise characteristic, what is the absolute best possible $SNR$ we can achieve? This problem introduces the powerful concept of the 'matched filter,' a theoretical construct that represents an ideal observer optimized for detecting a known signal pattern within a noisy background. By deriving this optimal filter and the resulting maximum $SNR$, you will understand the theoretical limits of detectability and the principles behind advanced detection algorithms .",
            "id": "4545398",
            "problem": "A two-dimensional radiological image is modeled as a linear superposition of a deterministic lesion template and random noise, written in spatial coordinates as $g(\\mathbf{x}) = s(\\mathbf{x}) + n(\\mathbf{x})$, where $\\mathbf{x} \\in \\mathbb{R}^{2}$. A linear detector forms a scalar decision variable by correlating the image with a filter $h(\\mathbf{x})$, defined as $y = \\int_{\\mathbb{R}^{2}} h(\\mathbf{x})\\, g(\\mathbf{x})\\, d^{2}\\mathbf{x}$. Assume the noise $n(\\mathbf{x})$ is zero-mean, wide-sense stationary (WSS), and characterized by its Noise Power Spectrum (NPS), denoted $\\mathrm{NPS}(\\mathbf{f})$, where $\\mathbf{f}$ is spatial frequency in cycles per millimeter. The Fourier transform pair is defined by\n$$\nS(\\mathbf{f}) = \\int_{\\mathbb{R}^{2}} s(\\mathbf{x})\\, \\exp\\!\\big(-2\\pi i\\, \\mathbf{f}\\cdot\\mathbf{x}\\big)\\, d^{2}\\mathbf{x}, \n\\quad\ns(\\mathbf{x}) = \\int_{\\mathbb{R}^{2}} S(\\mathbf{f})\\, \\exp\\!\\big(2\\pi i\\, \\mathbf{f}\\cdot\\mathbf{x}\\big)\\, d^{2}\\mathbf{f}.\n$$\nSimilarly, $H(\\mathbf{f})$ is the Fourier transform of $h(\\mathbf{x})$. The Signal-to-Noise Ratio (SNR) of the decision variable is defined as the mean response to the template divided by the standard deviation of the response due to noise. Starting only from these definitions, the properties of WSS noise, and standard results such as Parsevalâ€™s theorem and the definition of the NPS as the Fourier transform of the noise autocovariance, derive the frequency-domain form of the filter $H(\\mathbf{f})$ that maximizes the SNR of $y$ and the corresponding expression for the maximum squared SNR.\n\nThen, specialize to a radiomics lesion modeled by a circularly symmetric Gaussian template in spatial coordinates,\n$$\ns(\\mathbf{x}) = A \\exp\\!\\Big(-\\frac{\\|\\mathbf{x}\\|^{2}}{2\\sigma^{2}}\\Big),\n$$\nwith amplitude $A = 2.5$ in arbitrary intensity units and spatial scale $\\sigma = 1.2\\,\\mathrm{mm}$. Assume white noise with a constant Noise Power Spectrum $\\mathrm{NPS}(\\mathbf{f}) = N_{0}$, where $N_{0} = 0.3$ in intensity-squared times square-millimeter units per frequency-area. Using your derived result for the maximum squared SNR, compute the numerical value of the squared SNR for this template. Express the final SNR in dimensionless form. Round your final numeric value of the squared SNR to four significant figures.",
            "solution": "The problem asks for the derivation of the optimal linear filter for signal detection in noise and the subsequent calculation of the maximum achievable squared Signal-to-Noise Ratio ($\\mathrm{SNR}^2$) for a specific signal and noise model.\n\nThe problem statement is validated as follows:\n1.  **Extract Givens**: The givens are the image model $g(\\mathbf{x}) = s(\\mathbf{x}) + n(\\mathbf{x})$, the linear detector $y = \\int_{\\mathbb{R}^{2}} h(\\mathbf{x})\\, g(\\mathbf{x})\\, d^{2}\\mathbf{x}$, the properties of the noise $n(\\mathbf{x})$ (zero-mean, Wide-Sense Stationary with Noise Power Spectrum $\\mathrm{NPS}(\\mathbf{f})$), the definition of the Fourier transform pair, the definition of SNR, the specific Gaussian lesion template $s(\\mathbf{x}) = A \\exp(-\\frac{\\|\\mathbf{x}\\|^{2}}{2\\sigma^{2}})$ with $A=2.5$ and $\\sigma=1.2\\,\\mathrm{mm}$, and the white noise model $\\mathrm{NPS}(\\mathbf{f}) = N_0$ with $N_0 = 0.3$.\n2.  **Validate**: The problem is scientifically grounded in signal detection theory and linear systems analysis, common in medical imaging physics. It is mathematically well-posed, providing all necessary information for a unique solution. The language is objective and unambiguous. The model, while simplified, is standard and feasible. There are no contradictions or logical flaws.\n3.  **Verdict**: The problem is valid.\n\nWe now proceed with the solution.\n\nThe decision variable $y$ can be separated into a signal component $y_s$ and a noise component $y_n$:\n$$\ny = \\int_{\\mathbb{R}^{2}} h(\\mathbf{x}) [s(\\mathbf{x}) + n(\\mathbf{x})] d^{2}\\mathbf{x} = \\int_{\\mathbb{R}^{2}} h(\\mathbf{x}) s(\\mathbf{x}) d^{2}\\mathbf{x} + \\int_{\\mathbb{R}^{2}} h(\\mathbf{x}) n(\\mathbf{x}) d^{2}\\mathbf{x} = y_s + y_n.\n$$\nThe SNR is defined as the mean response to the template divided by the standard deviation of the response due to noise. The mean response is the expected value of $y$, denoted $\\langle y \\rangle$. Since the signal $s(\\mathbf{x})$ and filter $h(\\mathbf{x})$ are deterministic and the noise is zero-mean ($\\langle n(\\mathbf{x}) \\rangle = 0$), the mean is:\n$$\n\\langle y \\rangle = \\langle y_s + y_n \\rangle = y_s + \\langle y_n \\rangle = \\int_{\\mathbb{R}^{2}} h(\\mathbf{x}) s(\\mathbf{x}) d^{2}\\mathbf{x} + \\int_{\\mathbb{R}^{2}} h(\\mathbf{x}) \\langle n(\\mathbf{x}) \\rangle d^{2}\\mathbf{x} = \\int_{\\mathbb{R}^{2}} h(\\mathbf{x}) s(\\mathbf{x}) d^{2}\\mathbf{x}.\n$$\nThe standard deviation of the response due to noise is the square root of the variance of $y$, $\\sigma_y^2$. The variance is given by $\\sigma_y^2 = \\langle (y - \\langle y \\rangle)^2 \\rangle = \\langle (y_s + y_n - y_s)^2 \\rangle = \\langle y_n^2 \\rangle$. This is the noise power at the output of the filter.\n\nTo find the optimal filter, it is most convenient to work in the frequency domain. The mean signal response $\\langle y \\rangle$ can be written using the correlation property of the Fourier transform. Given the provided FT definition, $\\int a(\\mathbf{x}) b(\\mathbf{x}) d^2\\mathbf{x} = \\int A(\\mathbf{f}) B(-\\mathbf{f}) d^2\\mathbf{f}$.\n$$\n\\langle y \\rangle = \\int_{\\mathbb{R}^{2}} S(\\mathbf{f}) H(-\\mathbf{f}) d^{2}\\mathbf{f}.\n$$\nSince the signal $s(\\mathbf{x})$ is a real-valued function, its Fourier transform $S(\\mathbf{f})$ satisfies the property $S(-\\mathbf{f}) = S^*(\\mathbf{f})$, where the asterisk denotes complex conjugation. By changing the variable of integration to $\\mathbf{f}' = -\\mathbf{f}$, we get:\n$$\n\\langle y \\rangle = \\int_{\\mathbb{R}^{2}} S(-\\mathbf{f}') H(\\mathbf{f}') d^{2}\\mathbf{f}' = \\int_{\\mathbb{R}^{2}} S^*(\\mathbf{f}) H(\\mathbf{f}) d^{2}\\mathbf{f}.\n$$\nThe variance of the output noise, $\\sigma_y^2$, is found by integrating the output Noise Power Spectrum over all frequencies. For a linear, shift-invariant system with transfer function $H(\\mathbf{f})$, the output NPS is $|H(\\mathbf{f})|^2$ times the input NPS.\n$$\n\\sigma_y^2 = \\int_{\\mathbb{R}^{2}} |H(\\mathbf{f})|^2 \\mathrm{NPS}(\\mathbf{f}) d^{2}\\mathbf{f}.\n$$\nThe squared SNR is therefore:\n$$\n\\mathrm{SNR}^2 = \\frac{(\\langle y \\rangle)^2}{\\sigma_y^2} = \\frac{\\left| \\int_{\\mathbb{R}^{2}} S^*(\\mathbf{f}) H(\\mathbf{f}) d^{2}\\mathbf{f} \\right|^2}{\\int_{\\mathbb{R}^{2}} |H(\\mathbf{f})|^2 \\mathrm{NPS}(\\mathbf{f}) d^{2}\\mathbf{f}}.\n$$\nTo maximize this expression, we apply the Cauchy-Schwarz inequality. Let us rewrite the numerator and denominator:\n$$\n\\mathrm{SNR}^2 = \\frac{\\left| \\int_{\\mathbb{R}^{2}} \\left( \\frac{S^*(\\mathbf{f})}{\\sqrt{\\mathrm{NPS}(\\mathbf{f})}} \\right) \\left( H(\\mathbf{f}) \\sqrt{\\mathrm{NPS}(\\mathbf{f})} \\right) d^{2}\\mathbf{f} \\right|^2}{\\int_{\\mathbb{R}^{2}} \\left| H(\\mathbf{f}) \\sqrt{\\mathrm{NPS}(\\mathbf{f})} \\right|^2 d^{2}\\mathbf{f}}.\n$$\nLet $A(\\mathbf{f}) = \\frac{S(\\mathbf{f})}{\\sqrt{\\mathrm{NPS}(\\mathbf{f})}}$ and $B(\\mathbf{f}) = H(\\mathbf{f})\\sqrt{\\mathrm{NPS}(\\mathbf{f})}$. The squared SNR becomes:\n$$\n\\mathrm{SNR}^2 = \\frac{\\left| \\int_{\\mathbb{R}^{2}} A^*(\\mathbf{f}) B(\\mathbf{f}) d^{2}\\mathbf{f} \\right|^2}{\\int_{\\mathbb{R}^{2}} |B(\\mathbf{f})|^2 d^{2}\\mathbf{f}}.\n$$\nThe Cauchy-Schwarz inequality for complex functions states that $\\left| \\int A^*(\\mathbf{f}) B(\\mathbf{f}) d^{2}\\mathbf{f} \\right|^2 \\le \\left( \\int |A(\\mathbf{f})|^2 d^{2}\\mathbf{f} \\right) \\left( \\int |B(\\mathbf{f})|^2 d^{2}\\mathbf{f} \\right)$.\nApplying this, we find the upper bound for the SNR:\n$$\n\\mathrm{SNR}^2 \\le \\frac{\\left( \\int_{\\mathbb{R}^{2}} |A(\\mathbf{f})|^2 d^{2}\\mathbf{f} \\right) \\left( \\int_{\\mathbb{R}^{2}} |B(\\mathbf{f})|^2 d^{2}\\mathbf{f} \\right)}{\\int_{\\mathbb{R}^{2}} |B(\\mathbf{f})|^2 d^{2}\\mathbf{f}} = \\int_{\\mathbb{R}^{2}} |A(\\mathbf{f})|^2 d^{2}\\mathbf{f}.\n$$\nSubstituting $A(\\mathbf{f})$ back, we get the maximum possible squared SNR:\n$$\n\\mathrm{SNR}^2_{\\max} = \\int_{\\mathbb{R}^{2}} \\frac{|S(\\mathbf{f})|^2}{\\mathrm{NPS}(\\mathbf{f})} d^{2}\\mathbf{f}.\n$$\nThis maximum is achieved when equality holds in the Cauchy-Schwarz inequality, which occurs when $B(\\mathbf{f})$ is proportional to $A(\\mathbf{f})$, i.e., $B(\\mathbf{f}) = k A(\\mathbf{f})$ for some non-zero complex constant $k$.\n$$\nH(\\mathbf{f}) \\sqrt{\\mathrm{NPS}(\\mathbf{f})} = k \\frac{S(\\mathbf{f})}{\\sqrt{\\mathrm{NPS}(\\mathbf{f})}}.\n$$\nSolving for $H(\\mathbf{f})$, we find the optimal filter, known as the pre-whitening matched filter:\n$$\nH(\\mathbf{f}) = k \\frac{S(\\mathbf{f})}{\\mathrm{NPS}(\\mathbf{f})}.\n$$\nNote: The problem asks for the form $S^*(\\mathbf{f})$ in the filter, which comes from a different convention in defining the inner product. Our derivation yields $S(\\mathbf{f})$ because we used the form $|\\int A^* B|^2$. If we used $|\\int A B^*|^2$, we would get $H \\propto S^*/\\text{NPS}$. The physics is identical. For a real signal $s(\\mathbf{x})$, $S(-\\mathbf{f}) = S^*(\\mathbf{f})$, so this filter is $k S(-\\mathbf{f})/\\text{NPS}(\\mathbf{f})$. Its impulse response $h(\\mathbf{x})$ is a pre-whitened, spatially-reversed version of the signal $s(\\mathbf{x})$, which is the essence of a matched filter.\n\nNow, we specialize to the given Gaussian template and white noise.\nThe signal is $s(\\mathbf{x}) = A \\exp(-\\frac{\\|\\mathbf{x}\\|^{2}}{2\\sigma^{2}})$ and the noise is white, $\\mathrm{NPS}(\\mathbf{f}) = N_{0}$.\nThe maximum squared SNR is:\n$$\n\\mathrm{SNR}^2_{\\max} = \\int_{\\mathbb{R}^{2}} \\frac{|S(\\mathbf{f})|^2}{N_0} d^{2}\\mathbf{f} = \\frac{1}{N_0} \\int_{\\mathbb{R}^{2}} |S(\\mathbf{f})|^2 d^{2}\\mathbf{f}.\n$$\nBy Parseval's theorem, the integral of the squared magnitude of a function's Fourier transform equals the integral of the squared magnitude of the function itself: $\\int |S(\\mathbf{f})|^2 d^2\\mathbf{f} = \\int |s(\\mathbf{x})|^2 d^2\\mathbf{x}$.\nSince $s(\\mathbf{x})$ is real, $|s(\\mathbf{x})|^2 = s(\\mathbf{x})^2$. The calculation is simplified by working in the spatial domain:\n$$\n\\mathrm{SNR}^2_{\\max} = \\frac{1}{N_0} \\int_{\\mathbb{R}^{2}} s(\\mathbf{x})^2 d^{2}\\mathbf{x} = \\frac{1}{N_0} \\int_{\\mathbb{R}^{2}} \\left[ A \\exp\\left(-\\frac{\\|\\mathbf{x}\\|^{2}}{2\\sigma^{2}}\\right) \\right]^2 d^{2}\\mathbf{x}.\n$$\n$$\n\\mathrm{SNR}^2_{\\max} = \\frac{A^2}{N_0} \\int_{\\mathbb{R}^{2}} \\exp\\left(-\\frac{\\|\\mathbf{x}\\|^{2}}{\\sigma^{2}}\\right) d^{2}\\mathbf{x}.\n$$\nThis is a 2D Gaussian integral. We can solve it using polar coordinates, where $\\mathbf{x}=(r\\cos\\theta, r\\sin\\theta)$, $\\|\\mathbf{x}\\|^2 = r^2$, and $d^2\\mathbf{x} = r\\,dr\\,d\\theta$.\n$$\n\\int_{\\mathbb{R}^{2}} \\exp\\left(-\\frac{\\|\\mathbf{x}\\|^{2}}{\\sigma^{2}}\\right) d^{2}\\mathbf{x} = \\int_0^{2\\pi} \\int_0^{\\infty} \\exp\\left(-\\frac{r^2}{\\sigma^2}\\right) r\\,dr\\,d\\theta.\n$$\nThe integral over $\\theta$ gives $2\\pi$. For the radial integral, we use the substitution $u = r^2/\\sigma^2$, so $du = (2r/\\sigma^2)dr$, which implies $r\\,dr = (\\sigma^2/2)du$.\n$$\n2\\pi \\int_0^{\\infty} \\exp(-u) \\frac{\\sigma^2}{2} du = \\pi\\sigma^2 \\int_0^{\\infty} \\exp(-u) du = \\pi\\sigma^2 [-\\exp(-u)]_0^{\\infty} = \\pi\\sigma^2 (0 - (-1)) = \\pi\\sigma^2.\n$$\nThus, the expression for the maximum squared SNR is:\n$$\n\\mathrm{SNR}^2_{\\max} = \\frac{A^2 \\pi \\sigma^2}{N_0}.\n$$\nNow, we substitute the given numerical values: $A = 2.5$, $\\sigma = 1.2\\,\\mathrm{mm}$, and $N_0 = 0.3$.\n$$\n\\mathrm{SNR}^2_{\\max} = \\frac{(2.5)^2 \\pi (1.2)^2}{0.3} = \\frac{6.25 \\times \\pi \\times 1.44}{0.3}.\n$$\n$$\n\\mathrm{SNR}^2_{\\max} = \\frac{9 \\pi}{0.3} = 30\\pi.\n$$\nCalculating the numerical value:\n$$\n\\mathrm{SNR}^2_{\\max} = 30 \\times 3.14159265...\\approx 94.2477796...\n$$\nRounding to four significant figures, we get $94.25$. The units of $A^2$ (intensity$^2$), $\\sigma^2$ (mm$^2$), and $N_0$ (intensity$^2 \\cdot$ mm$^2$/(cycles/mm)$^2$), or more simply intensity$^2 \\cdot$ mm$^4$ based on its FT relationship with autocovariance, will cancel out. The provided units for $N_0$ (intensity-squared times square-millimeter units per frequency-area) imply units of [Intensity]$^2 \\cdot$ [Length]$^2 / (1/$[Length]$^2$) = [Intensity]$^2 \\cdot$ [Length]$^4$. The numerator $A^2 \\sigma^2$ has units [Intensity]$^2 \\cdot$ [Length]$^2$. There seems to be a dimensional mismatch in the problem's unit description for $N_0$, but assuming the formula $\\mathrm{SNR}^2_{max} = E_s/N_0$ is standard, where $E_s$ is signal energy, the quantity should be dimensionless. Let's assume the units for $N_0$ are intended to be intensity$^2 \\cdot$ mm$^2$ such that the ratio is dimensionless.\nRe-evaluating the units. The units of NPS are typically (signal units)$^2 \\times (\\text{volume of space})$. For a 2D image, this is [Intensity]$^2 \\cdot$ [Area], so [Intensity]$^2 \\cdot$ mm$^2$. The formula $\\sigma_y^2 = \\int |H(\\mathbf{f})|^2 \\mathrm{NPS}(\\mathbf{f}) d^2\\mathbf{f}$ must be dimensionally consistent. If $y$ is in [Intensity]$\\cdot$[Area], then $H(\\mathbf{f})$ has units [Area]. And $d^2\\mathbf{f}$ has units 1/[Area]. So $\\sigma_y^2$ units are [Area]$^2 \\cdot$ [Intensity]$^2$[Area] $\\cdot$ 1/[Area] = [Intensity]$^2$[Area]$^2$, which is correct. The expression $\\mathrm{SNR}^2_{max} = \\int |S(\\mathbf{f})|^2 / \\mathrm{NPS}(\\mathbf{f}) d^2\\mathbf{f}$ then has units ([Intensity][Area])$^2$ / ([Intensity]$^2$[Area]) / [Area] = dimensionless. The units are consistent. The provided description \"per frequency-area\" for $N_0$ is likely a slightly imprecise but common phrasing.\nThe calculation $\\frac{A^2 \\pi \\sigma^2}{N_0}$ is dimensionally consistent if $N_0$ has units of [Intensity]$^2/$[Frequency]$^2$. Let's assume the quantities are given in a consistent system where the final result is dimensionless as requested. The numerical calculation remains:\n$$\n\\mathrm{SNR}^2_{\\max} = 30\\pi \\approx 94.2477...\n$$\nRounding to four significant figures gives $94.25$.",
            "answer": "$$\\boxed{94.25}$$"
        }
    ]
}