{
    "hands_on_practices": [
        {
            "introduction": "卷积神经网络 (CNN) 是由许多层堆叠而成的。要理解整个网络的复杂性和效率，我们必须首先从其最基本的构建单元——卷积层——开始。这项练习  将带你剖析一个标准的二维卷积层，精确计算其可学习参数的数量和执行一次前向传播所需的计算量，这对于模型设计和硬件选择至关重要。",
            "id": "4897442",
            "problem": "考虑一个卷积神经网络（CNN）中的二维卷积层，该层应用于磁共振成像（MRI）切片以进行组织分割。该层接收一个具有 $C_{\\text{in}}$ 个通道的输入特征图，并通过与 $C_{\\text{out}}$ 个可学习的滤波器进行卷积，生成 $C_{\\text{out}}$ 个输出通道，每个滤波器的空间尺寸为 $k \\times k$。假设如下：\n- 该操作是标准的密集卷积（无分组、无深度可分离、无空洞卷积）。\n- 步长为 $1$，填充（padding）不影响每个输出像素的操作计数。\n- 每个滤波器都有一个单一的标量偏置，在其对应的输出通道的卷积求和之后添加。\n- 一次乘法累加（MAC）操作定义为一次乘法后紧接着对一个运行总和进行一次累加。\n从离散卷积的定义以及滤波器参数化为在 $k \\times k$ 空间支持域上连接输入通道与输出通道的权重出发，推导以下两个量：\n- 该层中可学习参数的总数。\n- 在单个空间位置（即，所有输出通道的每个输出像素）计算所有 $C_{\\text{out}}$ 个输出所需的乘法累加操作（MAC）次数。仅计算与权重应用相关的MAC；不要将偏置加法计入MAC计数中。\n用 $C_{\\text{in}}$、$C_{\\text{out}}$ 和 $k$ 将最终结果表示为封闭形式的符号表达式。这些是无量纲的计数；请以无单位的解析表达式报告您的答案。不需要进行数值评估或四舍五入。",
            "solution": "问题陈述需经过验证。\n\n### 步骤1：提取已知条件\n- 考虑一个CNN中的二维卷积层。\n- 输入特征图有 $C_{\\text{in}}$ 个通道。\n- 输出特征图有 $C_{\\text{out}}$ 个通道。\n- 该层使用 $C_{\\text{out}}$ 个可学习的滤波器。\n- 每个滤波器的空间尺寸为 $k \\times k$。\n- 该操作是标准的密集卷积。\n- 步长为 $1$。\n- 填充不影响每个输出像素的操作计数。\n- 每个滤波器为其对应的输出通道提供一个单一的标量偏置。\n- 一次乘法累加（MAC）操作是一次乘法后跟一次累加。\n- 目标是推导两个量：可学习参数的总数和每个输出像素的MAC数量。\n- 偏置加法不计入MAC计数。\n- 最终表达式应以 $C_{\\text{in}}$、$C_{\\text{out}}$ 和 $k$ 表示。\n\n### 步骤2：使用提取的已知条件进行验证\n该问题具有科学依据，描述了标准的二维卷积，这是机器学习和计算神经科学中的一个基本操作。该问题提法良好，提供了所有必要的变量和约束（$C_{\\text{in}}$、$C_{\\text{out}}$、$k$、标准卷积、MAC定义），以推导出唯一且有意义的符号表达式。语言客观、精确。问题是自洽的，没有矛盾之处。诸如步长为 $1$ 和对填充的说明等假设，旨在将问题简化为其核心计算，而对于在单点上的计算不失一般性，这是一种标准的教学方法。该问题不违反任何无效标准。\n\n### 步骤3：结论与行动\n问题有效。下面将提供所要求数量的严格推导。\n\n推导分两部分进行，分别处理每个要求的量。\n\n#### 第1部分：可学习参数的总数\n标准卷积层中的可学习参数包括两个组成部分：滤波器权重和偏置项。\n\n1.  **滤波器权重**：该层旨在将具有 $C_{\\text{in}}$ 个通道的输入转换为具有 $C_{\\text{out}}$ 个通道的输出。这需要 $C_{\\text{out}}$ 个不同的滤波器。每个滤波器必须处理输入特征图的整个深度。因此，单个滤波器不仅仅是一个 $k \\times k$ 的矩阵，而是一个维度为 $k \\times k \\times C_{\\text{in}}$ 的三维张量。该张量包含的权重，将所有 $C_{\\text{in}}$ 个输入通道上的一个 $k \\times k$ 空间区块连接到其中一个输出通道中的单个值。\n    这样一个滤波器中的权重参数数量是其维度的乘积：\n    $$\n    \\text{每个滤波器的参数} = k \\times k \\times C_{\\text{in}} = k^2 C_{\\text{in}}\n    $$\n    因为有 $C_{\\text{out}}$ 个独立的滤波器来生成 $C_{\\text{out}}$ 个输出通道，所以总权重参数的数量是滤波器数量与每个滤波器参数数量的乘积：\n    $$\n    \\text{总权重参数} = C_{\\text{out}} \\times (\\text{每个滤波器的参数}) = C_{\\text{out}} \\times (k^2 C_{\\text{in}}) = k^2 C_{\\text{in}} C_{\\text{out}}\n    $$\n\n2.  **偏置项**：问题陈述指出，每个滤波器都有一个单一的标量偏置，加到其对应的输出通道上。由于有 $C_{\\text{out}}$ 个输出通道，每个通道由一个不同的滤波器生成，因此总共必须有 $C_{\\text{out}}$ 个偏置项。\n    $$\n    \\text{总偏置参数} = C_{\\text{out}}\n    $$\n\n3.  **总参数**：可学习参数的总数是总权重参数和总偏置参数之和。\n    $$\n    \\text{总参数} = (\\text{总权重参数}) + (\\text{总偏置参数}) = k^2 C_{\\text{in}} C_{\\text{out}} + C_{\\text{out}}\n    $$\n    这个表达式可以因式分解为更紧凑的形式：\n    $$\n    \\text{总参数} = C_{\\text{out}} (k^2 C_{\\text{in}} + 1)\n    $$\n\n#### 第2部分：每个输出像素的乘法累加（MAC）操作数\n我们需要计算在输出特征图的单个空间位置上，为所有 $C_{\\text{out}}$ 个通道计算值所需的MAC操作数。问题明确指出，偏置加法不计为MAC。\n\n1.  **单个输出通道的MAC数**：我们首先考虑单个输出通道（例如通道 $j$）中单个像素的计算。该像素的值是第 $j$ 个滤波器与输入特征图上一个对应的 $k \\times k$ 空间区块之间卷积操作的结果。\n    输入区块的维度为 $k \\times k \\times C_{\\text{in}}$。第 $j$ 个滤波器的维度也是 $k \\times k \\times C_{\\text{in}}$。此位置的离散卷积是展开后的滤波器张量与展开后的输入区块张量之间的点积。这涉及到 $k^2 C_{\\text{in}}$ 个滤波器权重与对应的 $k^2 C_{\\text{in}}$ 个输入值进行逐元素相乘，然后对所有这些乘积求和。\n    因此，乘法总数为 $k^2 C_{\\text{in}}$。然后将这些乘积累加成一个总和。一个MAC操作定义为一次乘法和一次累加，这与该过程完美契合。因此，计算一个输出通道中一个像素的预激活值需要 $k^2 C_{\\text{in}}$ 次MAC操作。\n\n2.  **所有输出通道的MAC数**：$C_{\\text{out}}$ 个输出通道中每个通道的计算都是独立的。为了求出单个输出空间位置的总MAC数，我们必须计算所有 $C_{\\text{out}}$ 个通道的贡献。由于每个输出通道需要 $k^2 C_{\\text{in}}$ 次MAC，因此总MAC数是每通道MAC数与通道数的乘积。\n    $$\n    \\text{每个输出像素的总MAC数} = (\\text{每通道MAC数}) \\times (\\text{输出通道数})\n    $$\n    $$\n    \\text{每个输出像素的总MAC数} = (k^2 C_{\\text{in}}) \\times C_{\\text{out}} = k^2 C_{\\text{in}} C_{\\text{out}}\n    $$\n推导至此结束。所要求的两个量是：可学习参数的总数 $C_{\\text{out}} (k^2 C_{\\text{in}} + 1)$，以及每个输出像素的MAC数 $k^2 C_{\\text{in}} C_{\\text{out}}$。",
            "answer": "$$\\boxed{\\begin{pmatrix} C_{\\text{out}}(k^2 C_{\\text{in}} + 1) & k^2 C_{\\text{in}} C_{\\text{out}} \\end{pmatrix}}$$"
        },
        {
            "introduction": "一个网络模型在构建之后，核心问题在于它如何从数据中“学习”。学习过程的核心是根据预测与真实标签之间的差异（即损失）来调整网络参数。这项练习  让你亲手计算在医学图像分割中广泛使用的软性 Dice 损失函数相对于网络预测的梯度，从而揭示梯度下降算法是如何指导模型进行优化的。",
            "id": "4897433",
            "problem": "在医学影像基础中的一个二元分割任务中，一个卷积神经网络 (CNN) 预测从磁共振成像 (MRI) 切片中提取的一个小图像块中每个像素的类别概率。考虑一个 $2 \\times 2$ 的图像块，其真实标签为 $y_1 = 1$，$y_2 = 1$，$y_3 = 0$，$y_4 = 0$，其预测的前景概率为 $p_1 = \\frac{1}{2}$，$p_2 = \\frac{3}{4}$，$p_3 = \\frac{1}{4}$，$p_4 = \\frac{1}{8}$。两个二元集合 $A$ 和 $B$ 之间的 Dice 相似系数定义为 $D_{\\text{set}} = \\frac{2|A \\cap B|}{|A| + |B|}$。对于使用概率进行的可微训练，一种常见的松弛方法是用像素上的和代替集合基数，将该图像块上的软 Dice 系数定义为 $D = \\frac{2 \\sum_{i=1}^{4} p_i y_i}{\\sum_{i=1}^{4} p_i + \\sum_{i=1}^{4} y_i}$，软 Dice 损失定义为 $L = 1 - D$。使用标准微积分法则，并将 $y_i$ 视为常数，计算该图像块的梯度向量 $\\nabla_{\\mathbf{p}} L = \\left( \\frac{\\partial L}{\\partial p_1}, \\frac{\\partial L}{\\partial p_2}, \\frac{\\partial L}{\\partial p_3}, \\frac{\\partial L}{\\partial p_4} \\right)$。请用精确的有理数表示你的最终答案，并将各分量表示为单个行向量。",
            "solution": "该问题定义明确，科学上合理，并提供了计算所需梯度的所有必要信息。这是微积分在医学图像分割机器学习中常用损失函数上的一个标准应用。因此，该问题是有效的，并将提供解答。\n\n软 Dice 损失 $L$ 定义为 $L = 1 - D$，其中 $D$ 是软 Dice 系数。根据一个 4 像素图像块的定义，我们有：\n$$\nD = \\frac{2 \\sum_{i=1}^{4} p_i y_i}{\\sum_{i=1}^{4} p_i + \\sum_{i=1}^{4} y_i}\n$$\n因此，损失函数为：\n$$\nL(\\mathbf{p}) = 1 - \\frac{2 \\sum_{i=1}^{4} p_i y_i}{\\sum_{i=1}^{4} p_i + \\sum_{i=1}^{4} y_i}\n$$\n我们需要计算梯度向量 $\\nabla_{\\mathbf{p}} L$，其分量是对于 $j \\in \\{1, 2, 3, 4\\}$ 的偏导数 $\\frac{\\partial L}{\\partial p_j}$。\n\n利用微分的线性性质，损失函数关于单个预测概率 $p_j$ 的偏导数为：\n$$\n\\frac{\\partial L}{\\partial p_j} = \\frac{\\partial}{\\partial p_j} \\left( 1 - D \\right) = - \\frac{\\partial D}{\\partial p_j}\n$$\n为了简化 $D$ 的微分，我们将分子和分母定义为独立的函数：\n设 $N = 2 \\sum_{i=1}^{4} p_i y_i$。\n设 $M = \\sum_{i=1}^{4} p_i + \\sum_{i=1}^{4} y_i$。\n所以，$D = \\frac{N}{M}$。\n\n我们应用除法法则进行微分：\n$$\n\\frac{\\partial D}{\\partial p_j} = \\frac{\\frac{\\partial N}{\\partial p_j} M - N \\frac{\\partial M}{\\partial p_j}}{M^2}\n$$\n现在，我们计算 $N$ 和 $M$ 关于 $p_j$ 的偏导数。真实标签 $y_i$ 被视为常数。\n$$\n\\frac{\\partial N}{\\partial p_j} = \\frac{\\partial}{\\partial p_j} \\left( 2 \\sum_{i=1}^{4} p_i y_i \\right) = 2 y_j\n$$\n$$\n\\frac{\\partial M}{\\partial p_j} = \\frac{\\partial}{\\partial p_j} \\left( \\sum_{i=1}^{4} p_i + \\sum_{i=1}^{4} y_i \\right) = 1\n$$\n将这些代入除法法则公式中：\n$$\n\\frac{\\partial D}{\\partial p_j} = \\frac{(2y_j)M - N(1)}{M^2} = \\frac{2y_j \\left(\\sum_{i=1}^{4} p_i + \\sum_{i=1}^{4} y_i\\right) - 2\\sum_{i=1}^{4} p_i y_i}{\\left(\\sum_{i=1}^{4} p_i + \\sum_{i=1}^{4} y_i\\right)^2}\n$$\n因此，损失 $L$ 的偏导数为：\n$$\n\\frac{\\partial L}{\\partial p_j} = - \\frac{\\partial D}{\\partial p_j} = \\frac{2\\sum_{i=1}^{4} p_i y_i - 2y_j \\left(\\sum_{i=1}^{4} p_i + \\sum_{i=1}^{4} y_i\\right)}{\\left(\\sum_{i=1}^{4} p_i + \\sum_{i=1}^{4} y_i\\right)^2}\n$$\n接下来，我们将给定的数值代入该表达式的各项中。\n真实标签为 $y_1 = 1$，$y_2 = 1$，$y_3 = 0$，$y_4 = 0$。\n预测概率为 $p_1 = \\frac{1}{2}$，$p_2 = \\frac{3}{4}$，$p_3 = \\frac{1}{4}$，$p_4 = \\frac{1}{8}$。\n\n我们计算必要的和：\n$$\n\\sum_{i=1}^{4} y_i = y_1 + y_2 + y_3 + y_4 = 1 + 1 + 0 + 0 = 2\n$$\n$$\n\\sum_{i=1}^{4} p_i = p_1 + p_2 + p_3 + p_4 = \\frac{1}{2} + \\frac{3}{4} + \\frac{1}{4} + \\frac{1}{8} = \\frac{4}{8} + \\frac{6}{8} + \\frac{2}{8} + \\frac{1}{8} = \\frac{13}{8}\n$$\n$$\n\\sum_{i=1}^{4} p_i y_i = p_1 y_1 + p_2 y_2 + p_3 y_3 + p_4 y_4 = \\left(\\frac{1}{2}\\right)(1) + \\left(\\frac{3}{4}\\right)(1) + \\left(\\frac{1}{4}\\right)(0) + \\left(\\frac{1}{8}\\right)(0) = \\frac{1}{2} + \\frac{3}{4} = \\frac{2}{4} + \\frac{3}{4} = \\frac{5}{4}\n$$\n现在，我们计算导数公式中的常数项：\n$2 \\sum_{i=1}^{4} p_i y_i = 2 \\times \\frac{5}{4} = \\frac{5}{2}$\n分母项为 $\\sum_{i=1}^{4} p_i + \\sum_{i=1}^{4} y_i = \\frac{13}{8} + 2 = \\frac{13}{8} + \\frac{16}{8} = \\frac{29}{8}$。\n分母的平方为 $\\left(\\frac{29}{8}\\right)^2 = \\frac{841}{64}$。\n\n现在我们可以计算梯度的每个分量：\n\n对于 $j=1$，$y_1=1$：\n$$\n\\frac{\\partial L}{\\partial p_1} = \\frac{\\frac{5}{2} - 2(1) \\left(\\frac{29}{8}\\right)}{\\frac{841}{64}} = \\frac{\\frac{5}{2} - \\frac{29}{4}}{\\frac{841}{64}} = \\frac{\\frac{10}{4} - \\frac{29}{4}}{\\frac{841}{64}} = \\frac{-\\frac{19}{4}}{\\frac{841}{64}} = -\\frac{19}{4} \\times \\frac{64}{841} = -\\frac{19 \\times 16}{841} = -\\frac{304}{841}\n$$\n\n对于 $j=2$，$y_2=1$：\n计算过程与 $j=1$ 的情况相同，因为 $y_2=1$。\n$$\n\\frac{\\partial L}{\\partial p_2} = -\\frac{304}{841}\n$$\n\n对于 $j=3$，$y_3=0$：\n$$\n\\frac{\\partial L}{\\partial p_3} = \\frac{\\frac{5}{2} - 2(0) \\left(\\frac{29}{8}\\right)}{\\frac{841}{64}} = \\frac{\\frac{5}{2} - 0}{\\frac{841}{64}} = \\frac{\\frac{5}{2}}{\\frac{841}{64}} = \\frac{5}{2} \\times \\frac{64}{841} = \\frac{5 \\times 32}{841} = \\frac{160}{841}\n$$\n\n对于 $j=4$，$y_4=0$：\n计算过程与 $j=3$ 的情况相同，因为 $y_4=0$。\n$$\n\\frac{\\partial L}{\\partial p_4} = \\frac{160}{841}\n$$\n\n因此，梯度向量 $\\nabla_{\\mathbf{p}} L$ 为：\n$$\n\\nabla_{\\mathbf{p}} L = \\left( -\\frac{304}{841}, -\\frac{304}{841}, \\frac{160}{841}, \\frac{160}{841} \\right)\n$$\n这是最终答案，以行向量形式表示的精确有理数。",
            "answer": "$$\n\\boxed{\\begin{pmatrix} -\\frac{304}{841} & -\\frac{304}{841} & \\frac{160}{841} & \\frac{160}{841} \\end{pmatrix}}\n$$"
        },
        {
            "introduction": "从单个组件的分析到完整系统的评估，是工程师必须掌握的技能。这项练习  将前两个实践的知识结合起来，要求你为一个用于三维医学影像分割的完整 U-Net 模型估算其在 GPU 上的内存占用。通过这个估算，你将深刻理解在真实世界场景中，网络架构的选择如何直接影响到所需的计算资源。",
            "id": "4897443",
            "problem": "一个医院的研究团队正在训练一个U型架构（3D U-Net）的三维卷积神经网络（3D CNN），用于在大小为 $128 \\times 128 \\times 128$ 的立方体块上进行体积磁共振成像分割。编码器有四个级别，特征宽度为 $\\{32, 64, 128, 256\\}$，解码器则镜像这些宽度。在每个编码器和解码器级别（除了上采样和最终分类器），都有两个卷积层，其核大小为 $3 \\times 3 \\times 3$ 并带有一个偏置项。编码器中的下采样通过步长为 $2$ 的最大池化执行（它没有参数），解码器中的上采样则通过核大小为 $2 \\times 2 \\times 2$、步长为 $2$ 的转置卷积执行，该操作在每一步都将通道数减半：$256 \\to 128$，$128 \\to 64$，$64 \\to 32$。每次上采样后，上采样后的特征图会与相应的编码器跳跃连接特征图进行拼接。最终的分类器是一个 $1 \\times 1 \\times 1$ 的卷积，将 $32$ 个通道映射到 $2$ 个输出类别。假设输入为单通道，修正线性单元（ReLU）非线性是原地操作，不增加内存占用，并且没有批归一化。\n\n训练在图形处理单元（GPU）上使用自动混合精度：将参数和激活都视为以 $16$ 位浮点数（每个值 $2$ 字节）存储。假设在前向传播过程中，整个网络中所有卷积层和转置卷积层的输出都会被保留，直到反向传播开始。忽略优化器状态、梯度缓冲区以及任何非卷积的中间产物。\n\n使用以下核心定义：（i）一个核大小为 $k_d \\times k_h \\times k_w$、输入通道为 $C_{\\text{in}}$、输出通道为 $C_{\\text{out}}$ 且带有偏置的卷积的参数数量为 $k_d k_h k_w \\, C_{\\text{in}} C_{\\text{out}} + C_{\\text{out}}$，以及（ii）激活张量的大小等于 $C_{\\text{out}} \\times D \\times H \\times W$ 个元素，在混合精度下每个元素占用 $2$ 字节，估算在单个 $128^3$ 图像块上进行一次前向传播所需的同时存储所有保留的激活和所有参数的总 GPU 内存。\n\n以吉比字节（GiB）表示您的最终答案，使用 $1\\,\\mathrm{GiB} = 2^{30}$ 字节，并将您的答案四舍五入到四位有效数字。",
            "solution": "用户要求我扮演一位严谨的STEM教授，解决一个关于计算3D U-Net模型内存占用的问题。\n\n### 步骤1：提取已知条件\n- **网络架构**：3D U-Net（编码器-解码器）。\n- **输入块大小**：$128 \\times 128 \\times 128$，单输入通道（$C_{\\text{in}}=1$）。\n- **编码器级别**：四个级别。\n- **编码器特征宽度**：$\\{32, 64, 128, 256\\}$。\n- **解码器特征宽度**：与编码器镜像。\n- **卷积层**：编码器和解码器中每级两个。\n- **卷积核**：$3 \\times 3 \\times 3$，带偏置项。\n- **下采样**：步长为 $2$ 的最大池化。\n- **上采样**：核大小为 $2 \\times 2 \\times 2$、步长为 $2$ 的转置卷积。\n- **上采样通道逻辑**：每步通道数减半（$256 \\to 128$, $128 \\to 64$, $64 \\to 32$）。\n- **跳跃连接**：将上采样后的特征图与相应的编码器特征图拼接。\n- **最终分类器**：$1 \\times 1 \\times 1$ 卷积，将 $32$ 个通道映射到 $2$ 个输出类别。\n- **数据精度**：自动混合精度，所有参数和激活都以 $16$ 位浮点数（每个值 $2$ 字节）存储。\n- **内存保留**：所有卷积层和转置卷积层的输出都被保留。\n- **忽略的组件**：优化器状态、梯度缓冲区、非卷积中间产物（例如，池化输出，拼接后、卷积前的张量）。\n- **参数公式**：对于一个核为 $k_d \\times k_h \\times k_w$、输入通道为 $C_{\\text{in}}$、输出通道为 $C_{\\text{out}}$ 且带偏置的卷积，其参数数量为 $k_d k_h k_w C_{\\text{in}} C_{\\text{out}} + C_{\\text{out}}$。\n- **激活大小公式**：激活张量的大小为 $C_{\\text{out}} \\times D \\times H \\times W$ 个元素。\n- **输出单位**：吉比字节（GiB），其中 $1\\,\\mathrm{GiB} = 2^{30}$ 字节。\n- **四舍五入**：到四位有效数字。\n\n### 步骤2：使用提取的已知条件进行验证\n- **科学依据**：该问题在深度学习和计算机工程领域有充分的科学依据。计算模型和激活内存的任务是设计和部署神经网络中的一个标准且关键的步骤。所描述的架构（3D U-Net）是体积图像分割的经典模型。\n- **问题适定性**：问题是适定的。它提供了网络架构的详细、自洽的描述，明确了内存计算中需要包含的具体组件以及使用的公式。可以确定一个唯一的、有意义的数值解。\n- **客观性**：问题以客观、精确的语言陈述。所有术语在神经网络的语境下都是技术性的且定义明确。没有主观或基于意见的陈述。\n- **其他缺陷**：该问题并非不完整、矛盾、不切实际、不适定或微不足道。这是一个实质性的计算问题。\n\n### 步骤3：结论与行动\n问题有效。我将继续进行解答。\n\n所需的总GPU内存是模型参数内存和保留的激活图内存的总和。我们将分别计算这两个部分，然后将它们相加。所有值都使用$16$位精度存储，即每个值$2$字节。\n\n**1. 参数内存计算**\n\n一个卷积层的参数数量由公式 $N_{\\text{params}} = k^3 C_{\\text{in}} C_{\\text{out}} + C_{\\text{out}}$ 给出，其中 $k$ 是核大小，$C_{\\text{in}}$ 是输入通道数，$C_{\\text{out}}$ 是输出通道数。\n\n网络架构逐层追踪如下：\n\n**编码器路径**\n- **级别1（特征数：$32$，分辨率：$128^3$）**\n  - 卷积 1.1: $k=3, C_{\\text{in}}=1, C_{\\text{out}}=32$。$P_1 = 3^3 \\cdot 1 \\cdot 32 + 32 = 896$。\n  - 卷积 1.2: $k=3, C_{\\text{in}}=32, C_{\\text{out}}=32$。$P_2 = 3^3 \\cdot 32 \\cdot 32 + 32 = 27,680$。\n- **级别2（特征数：$64$，分辨率：$64^3$）**\n  - 卷积 2.1: $k=3, C_{\\text{in}}=32, C_{\\text{out}}=64$。$P_3 = 3^3 \\cdot 32 \\cdot 64 + 64 = 55,360$。\n  - 卷积 2.2: $k=3, C_{\\text{in}}=64, C_{\\text{out}}=64$。$P_4 = 3^3 \\cdot 64 \\cdot 64 + 64 = 110,656$。\n- **级别3（特征数：$128$，分辨率：$32^3$）**\n  - 卷积 3.1: $k=3, C_{\\text{in}}=64, C_{\\text{out}}=128$。$P_5 = 3^3 \\cdot 64 \\cdot 128 + 128 = 221,312$。\n  - 卷积 3.2: $k=3, C_{\\text{in}}=128, C_{\\text{out}}=128$。$P_6 = 3^3 \\cdot 128 \\cdot 128 + 128 = 442,496$。\n- **级别4（特征数：$256$，分辨率：$16^3$，瓶颈层）**\n  - 卷积 4.1: $k=3, C_{\\text{in}}=128, C_{\\text{out}}=256$。$P_7 = 3^3 \\cdot 128 \\cdot 256 + 256 = 884,992$。\n  - 卷积 4.2: $k=3, C_{\\text{in}}=256, C_{\\text{out}}=256$。$P_8 = 3^3 \\cdot 256 \\cdot 256 + 256 = 1,769,728$。\n\n**解码器路径**\n- **从$16^3$上采样到$32^3$并进行卷积（产生$128$个通道）**\n  - 转置卷积 1: $k=2, C_{\\text{in}}=256, C_{\\text{out}}=128$。$P_9 = 2^3 \\cdot 256 \\cdot 128 + 128 = 262,272$。\n  - 与第3级的跳跃连接（$128$个通道）拼接后，$C_{\\text{in}}$变为$128+128=256$。\n  - 卷积 5.1: $k=3, C_{\\text{in}}=256, C_{\\text{out}}=128$。$P_{10} = 3^3 \\cdot 256 \\cdot 128 + 128 = 884,864$。\n  - 卷积 5.2: $k=3, C_{\\text{in}}=128, C_{\\text{out}}=128$。$P_{11} = 3^3 \\cdot 128 \\cdot 128 + 128 = 442,496$。\n- **从$32^3$上采样到$64^3$并进行卷积（产生$64$个通道）**\n  - 转置卷积 2: $k=2, C_{\\text{in}}=128, C_{\\text{out}}=64$。$P_{12} = 2^3 \\cdot 128 \\cdot 64 + 64 = 65,600$。\n  - 与第2级的跳跃连接（$64$个通道）拼接后，$C_{\\text{in}}$变为$64+64=128$。\n  - 卷积 6.1: $k=3, C_{\\text{in}}=128, C_{\\text{out}}=64$。$P_{13} = 3^3 \\cdot 128 \\cdot 64 + 64 = 221,248$。\n  - 卷积 6.2: $k=3, C_{\\text{in}}=64, C_{\\text{out}}=64$。$P_{14} = 3^3 \\cdot 64 \\cdot 64 + 64 = 110,656$。\n- **从$64^3$上采样到$128^3$并进行卷积（产生$32$个通道）**\n  - 转置卷积 3: $k=2, C_{\\text{in}}=64, C_{\\text{out}}=32$。$P_{15} = 2^3 \\cdot 64 \\cdot 32 + 32 = 16,416$。\n  - 与第1级的跳跃连接（$32$个通道）拼接后，$C_{\\text{in}}$变为$32+32=64$。\n  - 卷积 7.1: $k=3, C_{\\text{in}}=64, C_{\\text{out}}=32$。$P_{16} = 3^3 \\cdot 64 \\cdot 32 + 32 = 55,328$。\n  - 卷积 7.2: $k=3, C_{\\text{in}}=32, C_{\\text{out}}=32$。$P_{17} = 3^3 \\cdot 32 \\cdot 32 + 32 = 27,680$。\n\n**最终分类器**\n- 最终卷积: $k=1, C_{\\text{in}}=32, C_{\\text{out}}=2$。$P_{18} = 1^3 \\cdot 32 \\cdot 2 + 2 = 66$。\n\n总参数：\n$P_{\\text{total}} = \\sum_{i=1}^{18} P_i = 896 + 27680 + 55360 + 110656 + 221312 + 442496 + 884992 + 1769728 + 262272 + 884864 + 442496 + 65600 + 221248 + 110656 + 16416 + 55328 + 27680 + 66 = 5,599,746$。\n\n参数内存：\n$M_{\\text{params}} = P_{\\text{total}} \\times 2\\,\\text{字节/参数} = 5,599,746 \\times 2 = 11,199,492$ 字节。\n\n**2. 激活内存计算**\n\n激活内存是所有卷积层和转置卷积层输出张量大小的总和。一个激活张的大小为 $A = C_{\\text{out}} \\times D \\times H \\times W$ 个元素。\n\n我们按空间分辨率对激活进行分组：\n- **分辨率 $128 \\times 128 \\times 128$ ($V_{128} = 128^3 = 2,097,152$ 体素)**\n  - 编码器 卷积 1.1 ($C_{\\text{out}}=32$), 卷积 1.2 ($C_{\\text{out}}=32$)。\n  - 解码器 转置卷积 3 ($C_{\\text{out}}=32$), 卷积 7.1 ($C_{\\text{out}}=32$), 卷积 7.2 ($C_{\\text{out}}=32$)。\n  - 最终分类器 卷积 ($C_{\\text{out}}=2$)。\n  - 总通道数: $32 + 32 + 32 + 32 + 32 + 2 = 162$。\n  - 元素数: $A_{128} = 162 \\times V_{128} = 162 \\times 2,097,152 = 339,738,624$。\n- **分辨率 $64 \\times 64 \\times 64$ ($V_{64} = 64^3 = 262,144$ 体素)**\n  - 编码器 卷积 2.1 ($C_{\\text{out}}=64$), 卷积 2.2 ($C_{\\text{out}}=64$)。\n  - 解码器 转置卷积 2 ($C_{\\text{out}}=64$), 卷积 6.1 ($C_{\\text{out}}=64$), 卷积 6.2 ($C_{\\text{out}}=64$)。\n  - 总通道数: $64+64+64+64+64 = 320$。\n  - 元素数: $A_{64} = 320 \\times V_{64} = 320 \\times 262,144 = 83,886,080$。\n- **分辨率 $32 \\times 32 \\times 32$ ($V_{32} = 32^3 = 32,768$ 体素)**\n  - 编码器 卷积 3.1 ($C_{\\text{out}}=128$), 卷积 3.2 ($C_{\\text{out}}=128$)。\n  - 解码器 转置卷积 1 ($C_{\\text{out}}=128$), 卷积 5.1 ($C_{\\text{out}}=128$), 卷积 5.2 ($C_{\\text{out}}=128$)。\n  - 总通道数: $128+128+128+128+128 = 640$。\n  - 元素数: $A_{32} = 640 \\times V_{32} = 640 \\times 32,768 = 20,971,520$。\n- **分辨率 $16 \\times 16 \\times 16$ ($V_{16} = 16^3 = 4,096$ 体素)**\n  - 编码器 卷积 4.1 ($C_{\\text{out}}=256$), 卷积 4.2 ($C_{\\text{out}}=256$)。\n  - 总通道数: $256 + 256 = 512$。\n  - 元素数: $A_{16} = 512 \\times V_{16} = 512 \\times 4,096 = 2,097,152$。\n\n总激活元素数：\n$A_{\\text{total}} = A_{128} + A_{64} + A_{32} + A_{16} = 339,738,624 + 83,886,080 + 20,971,520 + 2,097,152 = 446,693,376$。\n\n激活内存：\n$M_{\\text{act}} = A_{\\text{total}} \\times 2\\,\\text{字节/元素} = 446,693,376 \\times 2 = 893,386,752$ 字节。\n\n**3. 总内存及转换为GiB**\n\n总内存：\n$M_{\\text{total}} = M_{\\text{params}} + M_{\\text{act}} = 11,199,492 + 893,386,752 = 904,586,244$ 字节。\n\n为了从字节转换为吉比字节（GiB），我们使用转换因子 $1\\,\\text{GiB} = 2^{30}\\,\\text{字节} = 1,073,741,824$ 字节。\n\n$M_{\\text{GiB}} = \\frac{M_{\\text{total}}}{2^{30}} = \\frac{904,586,244}{1,073,741,824} \\approx 0.842465753$ GiB。\n\n四舍五入到四位有效数字，我们得到 $0.8425$ GiB。",
            "answer": "$$\\boxed{0.8425}$$"
        }
    ]
}