{
    "hands_on_practices": [
        {
            "introduction": "The convolutional layer is the fundamental building block of any CNN. To design effective and efficient networks, it is crucial to understand their cost, both in terms of memory (learnable parameters) and computation (operations). This exercise provides a first-principles derivation of these two key metrics, giving you a foundational toolset for analyzing and comparing different layer configurations. ",
            "id": "4897442",
            "problem": "Consider a two-dimensional convolutional layer within a Convolutional Neural Network (CNN) applied to a Magnetic Resonance Imaging (MRI) slice for tissue segmentation. The layer receives an input feature map with $C_{\\text{in}}$ channels and produces $C_{\\text{out}}$ output channels by convolving with $C_{\\text{out}}$ learnable filters, each of spatial size $k \\times k$. Assume the following:\n- The operation is a standard dense convolution (no grouping, no depthwise separability, no dilation).\n- The stride is $1$ and padding does not affect the count of operations per output pixel.\n- Each filter has a single scalar bias that is added after the convolutional sum for its corresponding output channel.\n- A Multiply-Accumulate operation (MAC) is defined as one multiplication followed immediately by an accumulation into a running sum.\nStarting from the discrete convolution definition and the parameterization of filters as weights connecting input channels to output channels over the $k \\times k$ spatial support, derive two quantities:\n- The total number of learnable parameters in the layer.\n- The number of Multiply-Accumulate operations (MACs) required to compute all $C_{\\text{out}}$ outputs at a single spatial location (that is, per output pixel across all output channels). Count only MACs associated with the weight applications; do not include bias additions in the MAC count.\nExpress your final result as closed-form symbolic expressions in terms of $C_{\\text{in}}$, $C_{\\text{out}}$, and $k$. These are dimensionless counts; report your answer as analytic expressions without units. No numerical evaluation or rounding is required.",
            "solution": "The problem statement is subjected to validation.\n\n### Step 1: Extract Givens\n- A two-dimensional convolutional layer in a CNN is considered.\n- Input feature map has $C_{\\text{in}}$ channels.\n- Output feature map has $C_{\\text{out}}$ channels.\n- The layer uses $C_{\\text{out}}$ learnable filters.\n- Each filter has a spatial size of $k \\times k$.\n- The operation is a standard dense convolution.\n- The stride is $1$.\n- Padding does not affect the count of operations per output pixel.\n- Each filter has a single scalar bias for its corresponding output channel.\n- A Multiply-Accumulate (MAC) operation is one multiplication followed by one accumulation.\n- The objective is to derive two quantities: the total number of learnable parameters and the number of MACs per output pixel.\n- Bias additions are not included in the MAC count.\n- The final expressions should be in terms of $C_{\\text{in}}$, $C_{\\text{out}}$, and $k$.\n\n### Step 2: Validate Using Extracted Givens\nThe problem is scientifically grounded, describing a standard 2D convolution, a fundamental operation in machine learning and computational neuroscience. It is well-posed, providing all necessary variables and constraints ($C_{\\text{in}}$, $C_{\\text{out}}$, $k$, standard convolution, MAC definition) to derive unique, meaningful symbolic expressions. The language is objective and precise. The problem is self-contained and free of contradictions. The assumptions, such as stride of $1$ and the clarification on padding, serve to simplify the problem to its core calculation without loss of generality for the computation at a single point, which is a standard pedagogical approach. The problem does not violate any of the invalidity criteria.\n\n### Step 3: Verdict and Action\nThe problem is valid. A rigorous derivation of the requested quantities will now be provided.\n\nThe derivation proceeds in two parts, addressing each of the required quantities.\n\n#### Part 1: Total Number of Learnable Parameters\nThe learnable parameters in a standard convolutional layer consist of two components: the filter weights and the bias terms.\n\n1.  **Filter Weights**: The layer is designed to transform an input with $C_{\\text{in}}$ channels into an output with $C_{\\text{out}}$ channels. This requires $C_{\\text{out}}$ distinct filters. Each filter must process the entire depth of the input feature map. Therefore, a single filter is not merely a $k \\times k$ matrix, but a three-dimensional tensor with dimensions $k \\times k \\times C_{\\text{in}}$. This tensor contains the weights that connect a $k \\times k$ spatial patch across all $C_{\\text{in}}$ input channels to a single value in one of the output channels.\n    The number of weight parameters in one such filter is the product of its dimensions:\n    $$\n    \\text{Parameters per filter} = k \\times k \\times C_{\\text{in}} = k^2 C_{\\text{in}}\n    $$\n    Since there are $C_{\\text{out}}$ independent filters to produce the $C_{\\text{out}}$ output channels, the total number of weight parameters is the product of the number of filters and the parameters per filter:\n    $$\n    \\text{Total weight parameters} = C_{\\text{out}} \\times (\\text{Parameters per filter}) = C_{\\text{out}} \\times (k^2 C_{\\text{in}}) = k^2 C_{\\text{in}} C_{\\text{out}}\n    $$\n\n2.  **Bias Terms**: The problem states that each filter has a single scalar bias that is added to its corresponding output channel. Since there are $C_{\\text{out}}$ output channels, each produced by a different filter, there must be $C_{\\text{out}}$ bias terms in total.\n    $$\n    \\text{Total bias parameters} = C_{\\text{out}}\n    $$\n\n3.  **Total Parameters**: The total number of learnable parameters is the sum of the total weight parameters and the total bias parameters.\n    $$\n    \\text{Total Parameters} = (\\text{Total weight parameters}) + (\\text{Total bias parameters}) = k^2 C_{\\text{in}} C_{\\text{out}} + C_{\\text{out}}\n    $$\n    This expression can be factored to a more compact form:\n    $$\n    \\text{Total Parameters} = C_{\\text{out}} (k^2 C_{\\text{in}} + 1)\n    $$\n\n#### Part 2: Number of Multiply-Accumulate (MAC) Operations per Output Pixel\nWe are asked to find the number of MACs required to compute the values for all $C_{\\text{out}}$ channels at a single spatial location in the output feature map. The problem specifies that bias additions are not to be counted as MACs.\n\n1.  **MACs for a Single Output Channel**: Let us first consider the computation for a single pixel in a single output channel, say channel $j$. The value of this pixel is the result of the convolution operation between the $j$-th filter and a corresponding $k \\times k$ spatial patch of the input feature map.\n    The input patch has dimensions $k \\times k \\times C_{\\text{in}}$. The $j$-th filter also has dimensions $k \\times k \\times C_{\\text{in}}$. The discrete convolution at this location is a dot product between the flattened filter tensor and the flattened input patch tensor. This involves an element-wise multiplication of the $k^2 C_{\\text{in}}$ filter weights with the corresponding $k^2 C_{\\text{in}}$ input values, followed by the summation of all these products.\n    The total number of multiplications is therefore $k^2 C_{\\text{in}}$. These products are then accumulated into a single sum. The definition of a MAC operation as one multiplication and one accumulation fits this process perfectly. Thus, computing the pre-activation value for one pixel in one output channel requires $k^2 C_{\\text{in}}$ MAC operations.\n\n2.  **MACs for All Output Channels**: The computation for each of the $C_{\\text{out}}$ output channels is independent. To find the total number of MACs for a single output spatial location, we must calculate the contributions for all $C_{\\text{out}}$ channels. Since each output channel requires $k^2 C_{\\text{in}}$ MACs, the total number of MACs is the product of the MACs per channel and the number of channels.\n    $$\n    \\text{Total MACs per output pixel} = (\\text{MACs per channel}) \\times (\\text{Number of output channels})\n    $$\n    $$\n    \\text{Total MACs per output pixel} = (k^2 C_{\\text{in}}) \\times C_{\\text{out}} = k^2 C_{\\text{in}} C_{\\text{out}}\n    $$\nThis concludes the derivation. The two requested quantities are the total number of learnable parameters, $C_{\\text{out}} (k^2 C_{\\text{in}} + 1)$, and the number of MACs per output pixel, $k^2 C_{\\text{in}} C_{\\text{out}}$.",
            "answer": "$$\\boxed{\\begin{pmatrix} C_{\\text{out}}(k^2 C_{\\text{in}} + 1) & k^2 C_{\\text{in}} C_{\\text{out}} \\end{pmatrix}}$$"
        },
        {
            "introduction": "A neural network learns by minimizing a loss function that quantifies its error. In medical image segmentation, the Dice coefficient is a premier metric for performance, and its differentiable \"soft\" version is a powerful loss function. This practice takes you to the core of the learning process—backpropagation—by having you compute the gradient of the soft Dice loss, which is the signal that tells the network how to adjust its predictions to improve segmentation accuracy. ",
            "id": "4897433",
            "problem": "In a binary segmentation task in foundations of medical imaging, a Convolutional Neural Network (CNN) predicts class probabilities for each pixel of a small patch extracted from a Magnetic Resonance Imaging (MRI) slice. Consider a $2 \\times 2$ patch whose ground truth labels are $y_1 = 1$, $y_2 = 1$, $y_3 = 0$, $y_4 = 0$, and whose predicted foreground probabilities are $p_1 = \\frac{1}{2}$, $p_2 = \\frac{3}{4}$, $p_3 = \\frac{1}{4}$, $p_4 = \\frac{1}{8}$. The Dice similarity coefficient between two binary sets $A$ and $B$ is defined as $D_{\\text{set}} = \\frac{2|A \\cap B|}{|A| + |B|}$. For differentiable training with probabilities, a common relaxation replaces the set cardinalities with sums over pixels, defining the soft Dice coefficient on this patch as $D = \\frac{2 \\sum_{i=1}^{4} p_i y_i}{\\sum_{i=1}^{4} p_i + \\sum_{i=1}^{4} y_i}$ and the soft Dice loss as $L = 1 - D$. Using standard rules of calculus and treating $y_i$ as constants, compute the gradient vector $\\nabla_{\\mathbf{p}} L = \\left( \\frac{\\partial L}{\\partial p_1}, \\frac{\\partial L}{\\partial p_2}, \\frac{\\partial L}{\\partial p_3}, \\frac{\\partial L}{\\partial p_4} \\right)$ for this patch. Express your final answer as exact rational numbers, and present the components as a single row vector.",
            "solution": "The problem is well-defined, scientifically sound, and provides all necessary information to compute the requested gradient. It is a standard application of calculus to a common loss function used in machine learning for medical image segmentation. Therefore, the problem is valid and a solution will be provided.\n\nThe soft Dice loss, $L$, is defined as $L = 1 - D$, where $D$ is the soft Dice coefficient. Given the definitions for a patch of $4$ pixels, we have:\n$$\nD = \\frac{2 \\sum_{i=1}^{4} p_i y_i}{\\sum_{i=1}^{4} p_i + \\sum_{i=1}^{4} y_i}\n$$\nThe loss function is therefore:\n$$\nL(\\mathbf{p}) = 1 - \\frac{2 \\sum_{i=1}^{4} p_i y_i}{\\sum_{i=1}^{4} p_i + \\sum_{i=1}^{4} y_i}\n$$\nWe need to compute the gradient vector $\\nabla_{\\mathbf{p}} L$, whose components are the partial derivatives $\\frac{\\partial L}{\\partial p_j}$ for $j \\in \\{1, 2, 3, 4\\}$.\n\nUsing the linearity of differentiation, the partial derivative of the loss with respect to a single predicted probability $p_j$ is:\n$$\n\\frac{\\partial L}{\\partial p_j} = \\frac{\\partial}{\\partial p_j} \\left( 1 - D \\right) = - \\frac{\\partial D}{\\partial p_j}\n$$\nTo simplify the differentiation of $D$, we define the numerator and denominator as separate functions:\nLet $N = 2 \\sum_{i=1}^{4} p_i y_i$.\nLet $M = \\sum_{i=1}^{4} p_i + \\sum_{i=1}^{4} y_i$.\nSo, $D = \\frac{N}{M}$.\n\nWe apply the quotient rule for differentiation:\n$$\n\\frac{\\partial D}{\\partial p_j} = \\frac{\\frac{\\partial N}{\\partial p_j} M - N \\frac{\\partial M}{\\partial p_j}}{M^2}\n$$\nNow, we compute the partial derivatives of $N$ and $M$ with respect to $p_j$. The ground truth labels $y_i$ are treated as constants.\n$$\n\\frac{\\partial N}{\\partial p_j} = \\frac{\\partial}{\\partial p_j} \\left( 2 \\sum_{i=1}^{4} p_i y_i \\right) = 2 y_j\n$$\n$$\n\\frac{\\partial M}{\\partial p_j} = \\frac{\\partial}{\\partial p_j} \\left( \\sum_{i=1}^{4} p_i + \\sum_{i=1}^{4} y_i \\right) = 1\n$$\nSubstituting these into the quotient rule formula:\n$$\n\\frac{\\partial D}{\\partial p_j} = \\frac{(2y_j)M - N(1)}{M^2} = \\frac{2y_j \\left(\\sum_{i=1}^{4} p_i + \\sum_{i=1}^{4} y_i\\right) - 2\\sum_{i=1}^{4} p_i y_i}{\\left(\\sum_{i=1}^{4} p_i + \\sum_{i=1}^{4} y_i\\right)^2}\n$$\nTherefore, the partial derivative of the loss $L$ is:\n$$\n\\frac{\\partial L}{\\partial p_j} = - \\frac{\\partial D}{\\partial p_j} = \\frac{2\\sum_{i=1}^{4} p_i y_i - 2y_j \\left(\\sum_{i=1}^{4} p_i + \\sum_{i=1}^{4} y_i\\right)}{\\left(\\sum_{i=1}^{4} p_i + \\sum_{i=1}^{4} y_i\\right)^2}\n$$\nNext, we substitute the given numerical values into the terms of this expression.\nThe ground truth labels are $y_1 = 1$, $y_2 = 1$, $y_3 = 0$, $y_4 = 0$.\nThe predicted probabilities are $p_1 = \\frac{1}{2}$, $p_2 = \\frac{3}{4}$, $p_3 = \\frac{1}{4}$, $p_4 = \\frac{1}{8}$.\n\nWe calculate the necessary sums:\n$$\n\\sum_{i=1}^{4} y_i = y_1 + y_2 + y_3 + y_4 = 1 + 1 + 0 + 0 = 2\n$$\n$$\n\\sum_{i=1}^{4} p_i = p_1 + p_2 + p_3 + p_4 = \\frac{1}{2} + \\frac{3}{4} + \\frac{1}{4} + \\frac{1}{8} = \\frac{4}{8} + \\frac{6}{8} + \\frac{2}{8} + \\frac{1}{8} = \\frac{13}{8}\n$$\n$$\n\\sum_{i=1}^{4} p_i y_i = p_1 y_1 + p_2 y_2 + p_3 y_3 + p_4 y_4 = \\left(\\frac{1}{2}\\right)(1) + \\left(\\frac{3}{4}\\right)(1) + \\left(\\frac{1}{4}\\right)(0) + \\left(\\frac{1}{8}\\right)(0) = \\frac{1}{2} + \\frac{3}{4} = \\frac{2}{4} + \\frac{3}{4} = \\frac{5}{4}\n$$\nNow, we compute the constant terms in our derivative formula:\n$2 \\sum_{i=1}^{4} p_i y_i = 2 \\times \\frac{5}{4} = \\frac{5}{2}$\nThe denominator term is $\\sum_{i=1}^{4} p_i + \\sum_{i=1}^{4} y_i = \\frac{13}{8} + 2 = \\frac{13}{8} + \\frac{16}{8} = \\frac{29}{8}$.\nThe squared denominator is $\\left(\\frac{29}{8}\\right)^2 = \\frac{841}{64}$.\n\nNow we can compute each component of the gradient:\n\nFor $j=1$, $y_1=1$:\n$$\n\\frac{\\partial L}{\\partial p_1} = \\frac{\\frac{5}{2} - 2(1) \\left(\\frac{29}{8}\\right)}{\\frac{841}{64}} = \\frac{\\frac{5}{2} - \\frac{29}{4}}{\\frac{841}{64}} = \\frac{\\frac{10}{4} - \\frac{29}{4}}{\\frac{841}{64}} = \\frac{-\\frac{19}{4}}{\\frac{841}{64}} = -\\frac{19}{4} \\times \\frac{64}{841} = -\\frac{19 \\times 16}{841} = -\\frac{304}{841}\n$$\n\nFor $j=2$, $y_2=1$:\nThe calculation is identical to that for $j=1$ since $y_2=1$.\n$$\n\\frac{\\partial L}{\\partial p_2} = -\\frac{304}{841}\n$$\n\nFor $j=3$, $y_3=0$:\n$$\n\\frac{\\partial L}{\\partial p_3} = \\frac{\\frac{5}{2} - 2(0) \\left(\\frac{29}{8}\\right)}{\\frac{841}{64}} = \\frac{\\frac{5}{2} - 0}{\\frac{841}{64}} = \\frac{\\frac{5}{2}}{\\frac{841}{64}} = \\frac{5}{2} \\times \\frac{64}{841} = \\frac{5 \\times 32}{841} = \\frac{160}{841}\n$$\n\nFor $j=4$, $y_4=0$:\nThe calculation is identical to that for $j=3$ since $y_4=0$.\n$$\n\\frac{\\partial L}{\\partial p_4} = \\frac{160}{841}\n$$\n\nThe gradient vector $\\nabla_{\\mathbf{p}} L$ is therefore:\n$$\n\\nabla_{\\mathbf{p}} L = \\left( -\\frac{304}{841}, -\\frac{304}{841}, \\frac{160}{841}, \\frac{160}{841} \\right)\n$$\nThis is the final answer, expressed as exact rational numbers in a row vector.",
            "answer": "$$\n\\boxed{\\begin{pmatrix} -\\frac{304}{841} & -\\frac{304}{841} & \\frac{160}{841} & \\frac{160}{841} \\end{pmatrix}}\n$$"
        },
        {
            "introduction": "The power of a deep CNN lies in its ability to analyze an image at multiple scales, from fine details to broad context. The \"receptive field\" of a neuron quantifies the size of the input region that influences its output, defining its field of view. This exercise will guide you through calculating the receptive field for a realistic 3D U-Net architecture, providing a tangible understanding of how a network aggregates spatial information across its layers to build a contextual understanding of the image. ",
            "id": "4897471",
            "problem": "Consider a three-dimensional Convolutional Neural Network (CNN) of the U-Net family used for volumetric medical image segmentation. Focus only on the encoder (contracting) path, which operates on a voxel grid and is organized into $5$ resolution stages indexed by $i\\in\\{0,1,2,3,4\\}$. Each stage $i\\in\\{0,1,2,3,4\\}$ contains exactly two three-dimensional convolutions with kernel size $3\\times 3\\times 3$, unit stride $1$, no dilation, and zero-padding chosen so that spatial dimensions are preserved (the commonly used “same” padding). Between consecutive stages, there is three-dimensional max-pooling with kernel size $2\\times 2\\times 2$ and stride $2$ applied after the two convolutions of stages $0,1,2,3$; stage $4$ has no pooling. Thus, there are exactly $4$ downsampling operations by a factor of $2$.\n\nUse the foundational definition that the receptive field of a unit in a feature map is the set of input voxels that can influence it through the compositional action of local operations. In one spatial dimension, a convolution with kernel width $k$ aggregates over $k$ adjacent positions of its input, and a pooling operation with stride $s$ increases the spacing between positions that a unit depends on by a factor of $s$. Assume isotropy so the receptive field is cubic and characterized by a single side length along any spatial axis.\n\nCompute the side length $R$ (in voxels, along a single spatial axis) of the effective receptive field of a single unit at the output of the second convolution in stage $4$ with respect to the original input volume. Report $R$ as a single integer. No rounding is necessary. Express your final answer as a pure number without units in the final box.",
            "solution": "The problem is scientifically sound, well-posed, and provides a complete description of a standard deep learning architecture, allowing for a unique calculation of the receptive field. The question is directly relevant to understanding the behavior of Convolutional Neural Networks. The problem is valid, and a detailed solution is provided below.\n\nThe side length of the receptive field, $R$, can be calculated iteratively as we move through the network's layers. We will track two quantities:\n1.  $R$: The side length of the receptive field with respect to the original input volume.\n2.  $J$: The cumulative stride, or \"jump,\" which is the distance between the centers of adjacent receptive fields in the input space.\n\nThe update rules for a layer $i$ with kernel size $k_i$ and stride $s_i$ are:\n$$\nR_i = R_{i-1} + (k_i - 1) \\times J_{i-1}\n$$\n$$\nJ_i = J_{i-1} \\times s_i\n$$\nFor this calculation, a max-pooling layer with kernel size $k_p$ and stride $s_p$ is treated as an equivalent convolutional layer with $k=k_p$ and $s=s_p$. The input to the network is layer 0, with an initial receptive field size of a single voxel ($R_0=1$) and a cumulative stride of $1$ ($J_0=1$).\n\nWe will now trace these values through the encoder path of the network.\n\n**Initial State:**\n*   $R = 1$\n*   $J = 1$\n\n**Stage 0:** Consists of two convolutions ($k=3, s=1$) and one max-pooling ($k=2, s=2$).\n1.  After 1st convolution ($k=3, s=1$):\n    $R \\leftarrow 1 + (3-1) \\times 1 = 3$.\n    $J \\leftarrow 1 \\times 1 = 1$.\n2.  After 2nd convolution ($k=3, s=1$):\n    $R \\leftarrow 3 + (3-1) \\times 1 = 5$.\n    $J \\leftarrow 1 \\times 1 = 1$.\n3.  After max-pooling ($k=2, s=2$):\n    $R \\leftarrow 5 + (2-1) \\times 1 = 6$.\n    $J \\leftarrow 1 \\times 2 = 2$.\n\n**Stage 1:** Consists of two convolutions ($k=3, s=1$) and one max-pooling ($k=2, s=2$).\n1.  After 1st convolution ($k=3, s=1$):\n    $R \\leftarrow 6 + (3-1) \\times 2 = 10$.\n    $J \\leftarrow 2 \\times 1 = 2$.\n2.  After 2nd convolution ($k=3, s=1$):\n    $R \\leftarrow 10 + (3-1) \\times 2 = 14$.\n    $J \\leftarrow 2 \\times 1 = 2$.\n3.  After max-pooling ($k=2, s=2$):\n    $R \\leftarrow 14 + (2-1) \\times 2 = 16$.\n    $J \\leftarrow 2 \\times 2 = 4$.\n\n**Stage 2:** Consists of two convolutions ($k=3, s=1$) and one max-pooling ($k=2, s=2$).\n1.  After 1st convolution ($k=3, s=1$):\n    $R \\leftarrow 16 + (3-1) \\times 4 = 24$.\n    $J \\leftarrow 4 \\times 1 = 4$.\n2.  After 2nd convolution ($k=3, s=1$):\n    $R \\leftarrow 24 + (3-1) \\times 4 = 32$.\n    $J \\leftarrow 4 \\times 1 = 4$.\n3.  After max-pooling ($k=2, s=2$):\n    $R \\leftarrow 32 + (2-1) \\times 4 = 36$.\n    $J \\leftarrow 4 \\times 2 = 8$.\n\n**Stage 3:** Consists of two convolutions ($k=3, s=1$) and one max-pooling ($k=2, s=2$).\n1.  After 1st convolution ($k=3, s=1$):\n    $R \\leftarrow 36 + (3-1) \\times 8 = 52$.\n    $J \\leftarrow 8 \\times 1 = 8$.\n2.  After 2nd convolution ($k=3, s=1$):\n    $R \\leftarrow 52 + (3-1) \\times 8 = 68$.\n    $J \\leftarrow 8 \\times 1 = 8$.\n3.  After max-pooling ($k=2, s=2$):\n    $R \\leftarrow 68 + (2-1) \\times 8 = 76$.\n    $J \\leftarrow 8 \\times 2 = 16$.\n\n**Stage 4:** Consists of two convolutions ($k=3, s=1$). There is no final pooling layer.\n1.  After 1st convolution ($k=3, s=1$):\n    $R \\leftarrow 76 + (3-1) \\times 16 = 76 + 32 = 108$.\n    $J \\leftarrow 16 \\times 1 = 16$.\n2.  After 2nd convolution ($k=3, s=1$):\n    $R \\leftarrow 108 + (3-1) \\times 16 = 108 + 32 = 140$.\n    $J \\leftarrow 16 \\times 1 = 16$.\n\nThe final receptive field side length at the output of the second convolution in stage 4 is 140 voxels.",
            "answer": "$$ \\boxed{140} $$"
        }
    ]
}