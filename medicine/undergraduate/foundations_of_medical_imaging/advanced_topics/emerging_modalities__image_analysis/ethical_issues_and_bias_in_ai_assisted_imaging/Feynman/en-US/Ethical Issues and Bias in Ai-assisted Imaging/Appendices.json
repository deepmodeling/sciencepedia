{
    "hands_on_practices": [
        {
            "introduction": "Evaluating fairness in AI begins with a fundamental question: does the model make similar kinds of mistakes for different groups of people? The equalized odds criterion directly addresses this by requiring that the True Positive Rate ($TPR$) and False Positive Rate ($FPR$) are consistent across demographic subgroups. This practice provides a direct, hands-on opportunity to calculate and assess this crucial fairness metric using raw performance data from a hypothetical pneumothorax classifier .",
            "id": "4883791",
            "problem": "An Artificial Intelligence (AI)-assisted classifier is deployed to detect pneumothorax on chest radiographs. To assess whether the classifier satisfies the equalized odds fairness criterion across two demographic subgroups, denoted as subgroup $A$ and subgroup $B$, you are given the following held-out test set confusion matrix counts for each subgroup:\n\n- Subgroup $A$: $TP = 84$, $FN = 16$, $FP = 30$, $TN = 270$.\n- Subgroup $B$: $TP = 38$, $FN = 12$, $FP = 18$, $TN = 432$.\n\nHere, $TP$ denotes true positives, $FN$ denotes false negatives, $FP$ denotes false positives, and $TN$ denotes true negatives.\n\nStarting from first principles, use the standard definitions of the true positive rate $TPR$ and the false positive rate $FPR$, namely\n$$TPR = \\frac{TP}{TP+FN}$$\nand\n$$FPR = \\frac{FP}{FP+TN},$$\nto compute the subgroup rates. Then compute the absolute differences in these rates across subgroups, denoted as $\\Delta_{TPR}$ and $\\Delta_{FPR}$, and the scalar diagnostic fairness gap $E$ defined as the larger of the two absolute differences. The equalized odds criterion is considered satisfied within a tolerance $\\tau = 0.07$ if and only if both absolute differences are less than or equal to $\\tau$.\n\nReport the scalar value $E$ as an exact unitless decimal. No rounding is necessary. Also state in your reasoning whether the model satisfies equalized odds within the given tolerance $\\tau$, but your final reported answer must be only the scalar $E$.",
            "solution": "The problem is valid as it is scientifically grounded, well-posed, objective, and contains all necessary information for a unique solution. We begin by stating the given information and definitions.\n\nThe confusion matrix counts for two demographic subgroups, $A$ and $B$, are provided.\nFor subgroup $A$:\nTrue Positives, $TP_A = 84$\nFalse Negatives, $FN_A = 16$\nFalse Positives, $FP_A = 30$\nTrue Negatives, $TN_A = 270$\n\nFor subgroup $B$:\nTrue Positives, $TP_B = 38$\nFalse Negatives, $FN_B = 12$\nFalse Positives, $FP_B = 18$\nTrue Negatives, $TN_B = 432$\n\nThe problem defines the true positive rate ($TPR$) and false positive rate ($FPR$) as:\n$$TPR = \\frac{TP}{TP+FN}$$\n$$FPR = \\frac{FP}{FP+TN}$$\n\nThe equalized odds fairness criterion requires that the $TPR$ and $FPR$ are approximately equal across subgroups. Specifically, the criterion is satisfied if the absolute differences in these rates are both less than or equal to a given tolerance, $\\tau = 0.07$.\n\nFirst, we compute the $TPR$ and $FPR$ for subgroup $A$.\nThe total number of actual positive cases in subgroup $A$ is $P_A = TP_A + FN_A$.\n$$P_A = 84 + 16 = 100$$\nThe $TPR$ for subgroup $A$ is therefore:\n$$TPR_A = \\frac{TP_A}{TP_A + FN_A} = \\frac{84}{100} = 0.84$$\n\nThe total number of actual negative cases in subgroup $A$ is $N_A = FP_A + TN_A$.\n$$N_A = 30 + 270 = 300$$\nThe $FPR$ for subgroup $A$ is therefore:\n$$FPR_A = \\frac{FP_A}{FP_A + TN_A} = \\frac{30}{300} = 0.1$$\n\nNext, we compute the $TPR$ and $FPR$ for subgroup $B$.\nThe total number of actual positive cases in subgroup $B$ is $P_B = TP_B + FN_B$.\n$$P_B = 38 + 12 = 50$$\nThe $TPR$ for subgroup $B$ is therefore:\n$$TPR_B = \\frac{TP_B}{TP_B + FN_B} = \\frac{38}{50} = \\frac{76}{100} = 0.76$$\n\nThe total number of actual negative cases in subgroup $B$ is $N_B = FP_B + TN_B$.\n$$N_B = 18 + 432 = 450$$\nThe $FPR$ for subgroup $B$ is therefore:\n$$FPR_B = \\frac{FP_B}{FP_B + TN_B} = \\frac{18}{450} = \\frac{1}{25} = 0.04$$\n\nNow, we compute the absolute differences in these rates across the subgroups.\nThe absolute difference in the true positive rates is $\\Delta_{TPR}$:\n$$\\Delta_{TPR} = |TPR_A - TPR_B| = |0.84 - 0.76| = 0.08$$\n\nThe absolute difference in the false positive rates is $\\Delta_{FPR}$:\n$$\\Delta_{FPR} = |FPR_A - FPR_B| = |0.1 - 0.04| = 0.06$$\n\nThe scalar diagnostic fairness gap, $E$, is defined as the maximum of these two absolute differences:\n$$E = \\max(\\Delta_{TPR}, \\Delta_{FPR}) = \\max(0.08, 0.06) = 0.08$$\n\nFinally, we assess whether the equalized odds criterion is satisfied within the tolerance $\\tau = 0.07$. The criterion requires both $\\Delta_{TPR} \\le \\tau$ and $\\Delta_{FPR} \\le \\tau$.\nWe check the conditions:\n1. Is $\\Delta_{TPR} \\le 0.07$? We have $0.08 \\le 0.07$, which is false.\n2. Is $\\Delta_{FPR} \\le 0.07$? We have $0.06 \\le 0.07$, which is true.\n\nSince the condition $\\Delta_{TPR} \\le \\tau$ is not met, the classifier does not satisfy the equalized odds criterion for the given tolerance $\\tau = 0.07$. The problem asks for the scalar value $E$.",
            "answer": "$$\\boxed{0.08}$$"
        },
        {
            "introduction": "A model's intrinsic error rates do not tell the whole story of its fairness in practice. This exercise reveals a subtle but critical source of bias where group-specific disease prevalence can cause significant disparities in a model's real-world predictive power, even if the model is technically \"unbiased\" in its error rates. You will use Bayes' rule to derive and calculate how the Positive Predictive Value ($PPV$) and Negative Predictive Value ($NPV$) change with prevalence, highlighting a vital concept for ethical deployment .",
            "id": "4883822",
            "problem": "An Artificial Intelligence (AI) classifier is deployed to assist radiologists in triaging head computed tomography (CT) studies for intracranial hemorrhage. At a fixed decision threshold, the classifier’s operating characteristics are assumed stable across deployment sites and subgroups: True Positive Rate (TPR) $=0.90$ and False Positive Rate (FPR) $=0.12$. Two patient subgroups within a new health system differ in disease prevalence: subgroup $\\mathcal{X}$ (older patients) has prevalence $p_{\\mathcal{X}}=0.15$, and subgroup $\\mathcal{Y}$ (younger patients) has prevalence $p_{\\mathcal{Y}}=0.03$. \n\nStarting from the foundational definitions of conditional probability, the law of total probability, and Bayes’ rule, perform the following:\n\n1. Derive the Positive Predictive Value ($PPV$) and the Negative Predictive Value ($NPV$) as functions of $TPR$, $FPR$, and prevalence $p$ at a fixed threshold, expressed only in terms of $TPR$, $FPR$, and $p$.\n\n2. Compute the derivatives $\\frac{d\\,PPV}{dp}$ and $\\frac{d\\,NPV}{dp}$, and determine the sign of each derivative for $0<p<1$ under $0<TPR<1$ and $0<FPR<1$, interpreting how prevalence shifts across deployment sites can cause subgroup differences in $PPV$ and $NPV$ even when the decision threshold is fixed.\n\n3. Using the derived formulas, calculate $PPV_{\\mathcal{X}}$, $NPV_{\\mathcal{X}}$, $PPV_{\\mathcal{Y}}$, and $NPV_{\\mathcal{Y}}$. Then, define the combined predictive-parity disparity across subgroups at the fixed threshold as\n$$D=\\sqrt{\\left(PPV_{\\mathcal{X}}-PPV_{\\mathcal{Y}}\\right)^{2}+\\left(NPV_{\\mathcal{X}}-NPV_{\\mathcal{Y}}\\right)^{2}}.$$\nCompute $D$ numerically for the given parameters. Express the final value of $D$ in decimal form and round your answer to four significant figures. No unit is required.",
            "solution": "Let $D$ be the event that a patient has the disease (intracranial hemorrhage) and $D^c$ be the event that the patient does not have the disease. Let $T$ be the event that the AI classifier returns a positive result, and $T^c$ be the event that it returns a negative result. The prevalence of the disease is denoted by $p = P(D)$, which implies $P(D^c) = 1 - p$.\n\nThe operating characteristics of the classifier are given by the True Positive Rate, $TPR = P(T|D)$, and the False Positive Rate, $FPR = P(T|D^c)$. From these, we can also define the False Negative Rate, $FNR = P(T^c|D) = 1 - P(T|D) = 1 - TPR$, and the True Negative Rate, $TNR = P(T^c|D^c) = 1 - P(T|D^c) = 1 - FPR$.\n\n**1. Derivation of PPV and NPV**\n\nThe Positive Predictive Value ($PPV$) is the probability of having the disease given a positive test result, $PPV = P(D|T)$. The Negative Predictive Value ($NPV$) is the probability of not having the disease given a negative test result, $NPV = P(D^c|T^c)$. We derive these using Bayes' rule.\n\nFor $PPV$:\nAccording to Bayes' rule, $P(D|T) = \\frac{P(T|D)P(D)}{P(T)}$.\nThe term in the denominator, $P(T)$, is the overall probability of a positive test, which can be found using the law of total probability:\n$$P(T) = P(T|D)P(D) + P(T|D^c)P(D^c)$$\nSubstituting the given definitions:\n$$P(T) = (TPR)(p) + (FPR)(1-p)$$\nNow, substituting this back into the expression for $PPV$:\n$$PPV(p) = \\frac{P(T|D)P(D)}{P(T|D)P(D) + P(T|D^c)P(D^c)} = \\frac{(TPR)(p)}{(TPR)(p) + (FPR)(1-p)}$$\n\nFor $NPV$:\nAccording to Bayes' rule, $P(D^c|T^c) = \\frac{P(T^c|D^c)P(D^c)}{P(T^c)}$.\nThe term in the denominator, $P(T^c)$, is the overall probability of a negative test. Using the law of total probability:\n$$P(T^c) = P(T^c|D)P(D) + P(T^c|D^c)P(D^c)$$\nSubstituting the definitions of $FNR$ and $TNR$:\n$$P(T^c) = (1-TPR)(p) + (1-FPR)(1-p)$$\nNow, substituting this back into the expression for $NPV$:\n$$NPV(p) = \\frac{P(T^c|D^c)P(D^c)}{P(T^c|D)P(D) + P(T^c|D^c)P(D^c)} = \\frac{(1-FPR)(1-p)}{(1-TPR)(p) + (1-FPR)(1-p)}$$\n\n**2. Derivatives of PPV and NPV with respect to p**\n\nTo find the derivative of $PPV$ with respect to $p$, we use the quotient rule for differentiation.\nLet $u(p) = (TPR)p$ and $v(p) = (TPR)p + (FPR)(1-p) = (TPR - FPR)p + FPR$.\nThen $u'(p) = TPR$ and $v'(p) = TPR - FPR$.\n$$\\frac{d\\,PPV}{dp} = \\frac{u'(p)v(p) - u(p)v'(p)}{[v(p)]^2} = \\frac{(TPR)[(TPR - FPR)p + FPR] - (TPR)p[TPR - FPR]}{[(TPR)p + (FPR)(1-p)]^2}$$\n$$\\frac{d\\,PPV}{dp} = \\frac{(TPR)^2 p - (TPR)(FPR)p + (TPR)(FPR) - (TPR)^2 p + (TPR)(FPR)p}{[(TPR)p + (FPR)(1-p)]^2}$$\n$$\\frac{d\\,PPV}{dp} = \\frac{(TPR)(FPR)}{[(TPR)p + (FPR)(1-p)]^2}$$\nFor the conditions $0 < p < 1$, $0 < TPR < 1$, and $0 < FPR < 1$, the numerator $(TPR)(FPR)$ is positive. The denominator is a squared term representing $[P(T)]^2$. Since $P(T)$ cannot be zero under these conditions, the denominator is also positive. Therefore, $\\frac{d\\,PPV}{dp} > 0$. This indicates that $PPV$ is a monotonically increasing function of prevalence $p$. A higher prevalence in a subgroup leads to a higher $PPV$.\n\nTo find the derivative of $NPV$ with respect to $p$, we again use the quotient rule.\nLet $u(p) = (1-FPR)(1-p)$ and $v(p) = (1-TPR)p + (1-FPR)(1-p) = (FPR-TPR)p + (1-FPR)$.\nThen $u'(p) = -(1-FPR)$ and $v'(p) = FPR-TPR$.\n$$\\frac{d\\,NPV}{dp} = \\frac{u'(p)v(p) - u(p)v'(p)}{[v(p)]^2} = \\frac{-(1-FPR)[(FPR-TPR)p + (1-FPR)] - (1-FPR)(1-p)[FPR-TPR]}{[(1-TPR)p + (1-FPR)(1-p)]^2}$$\nFactor out $-(1-FPR)$ from the numerator:\n$$\\frac{d\\,NPV}{dp} = \\frac{-(1-FPR) \\left\\{ [(FPR-TPR)p + (1-FPR)] + (1-p)[-(TPR-FPR)] \\right\\}}{[P(T^c)]^2}$$\n$$\\frac{d\\,NPV}{dp} = \\frac{-(1-FPR) \\{ (FPR-TPR)p + (1-FPR) + (p-1)(TPR-FPR) \\}}{[P(T^c)]^2}$$\n$$\\frac{d\\,NPV}{dp} = \\frac{-(1-FPR) \\{ (FPR-TPR)p + 1-FPR + p(TPR-FPR) - (TPR-FPR) \\}}{[P(T^c)]^2}$$\n$$\\frac{d\\,NPV}{dp} = \\frac{-(1-FPR) \\{ 1 - FPR - TPR + FPR \\}}{[P(T^c)]^2} = \\frac{-(1-FPR)(1-TPR)}{[P(T^c)]^2}$$\n$$\\frac{d\\,NPV}{dp} = \\frac{-(1-TPR)(1-FPR)}{[(1-TPR)p + (1-FPR)(1-p)]^2}$$\nFor the conditions $0 < p < 1$, $0 < TPR < 1$, and $0 < FPR < 1$, the terms $(1-TPR)$ and $(1-FPR)$ are both positive. Thus, the numerator $-(1-TPR)(1-FPR)$ is negative. The denominator is $[P(T^c)]^2$, which is positive. Therefore, $\\frac{d\\,NPV}{dp} < 0$. This indicates that $NPV$ is a monotonically decreasing function of prevalence $p$. A higher prevalence in a subgroup leads to a lower $NPV$. This dependence of $PPV$ and $NPV$ on prevalence explains why predictive values can differ between subgroups even if the classifier's intrinsic properties ($TPR$, $FPR$) are constant.\n\n**3. Numerical Calculation and Disparity**\n\nGiven values: $TPR = 0.90$, $FPR = 0.12$, $p_{\\mathcal{X}} = 0.15$, $p_{\\mathcal{Y}} = 0.03$. Also, $1-TPR = 0.10$ and $1-FPR = 0.88$.\n\nFor subgroup $\\mathcal{X}$ (prevalence $p_{\\mathcal{X}} = 0.15$):\n$$PPV_{\\mathcal{X}} = \\frac{(0.90)(0.15)}{(0.90)(0.15) + (0.12)(1 - 0.15)} = \\frac{0.135}{0.135 + (0.12)(0.85)} = \\frac{0.135}{0.135 + 0.102} = \\frac{0.135}{0.237} \\approx 0.569620$$\n$$NPV_{\\mathcal{X}} = \\frac{(0.88)(1 - 0.15)}{(0.10)(0.15) + (0.88)(1 - 0.15)} = \\frac{(0.88)(0.85)}{0.015 + (0.88)(0.85)} = \\frac{0.748}{0.015 + 0.748} = \\frac{0.748}{0.763} \\approx 0.980341$$\n\nFor subgroup $\\mathcal{Y}$ (prevalence $p_{\\mathcal{Y}} = 0.03$):\n$$PPV_{\\mathcal{Y}} = \\frac{(0.90)(0.03)}{(0.90)(0.03) + (0.12)(1 - 0.03)} = \\frac{0.027}{0.027 + (0.12)(0.97)} = \\frac{0.027}{0.027 + 0.1164} = \\frac{0.027}{0.1434} \\approx 0.188285$$\n$$NPV_{\\mathcal{Y}} = \\frac{(0.88)(1 - 0.03)}{(0.10)(0.03) + (0.88)(1 - 0.03)} = \\frac{(0.88)(0.97)}{0.003 + (0.88)(0.97)} = \\frac{0.8536}{0.003 + 0.8536} = \\frac{0.8536}{0.8566} \\approx 0.996498$$\n\nNow, compute the predictive-parity disparity $D$:\n$$PPV_{\\mathcal{X}} - PPV_{\\mathcal{Y}} \\approx 0.569620 - 0.188285 = 0.381335$$\n$$NPV_{\\mathcal{X}} - NPV_{\\mathcal{Y}} \\approx 0.980341 - 0.996498 = -0.016157$$\n$$D = \\sqrt{(PPV_{\\mathcal{X}}-PPV_{\\mathcal{Y}})^{2}+(NPV_{\\mathcal{X}}-NPV_{\\mathcal{Y}})^{2}}$$\n$$D \\approx \\sqrt{(0.381335)^{2}+(-0.016157)^{2}} = \\sqrt{0.145416 + 0.000261} = \\sqrt{0.145677} \\approx 0.381677$$\nRounding to four significant figures, $D \\approx 0.3817$.",
            "answer": "$$\\boxed{0.3817}$$"
        },
        {
            "introduction": "This practice moves beyond binary outcomes to evaluate the trustworthiness of an AI's predicted probabilities, a concept known as calibration. For a model to be fair and reliable, its confidence scores must accurately reflect the true likelihood of a condition, and this reliability should not differ between demographic groups. You will learn to calculate the Expected Calibration Error (ECE) to quantify if a model's confidence is systematically misleading for one group over another, which has profound implications for clinical decision-making .",
            "id": "4883817",
            "problem": "An Artificial Intelligence (AI) system outputs predicted probabilities for pneumonia on chest radiographs. Ethical evaluation of such systems includes assessing whether the model is calibrated similarly across demographic groups, because differing calibration can propagate unequal downstream harms in triage and follow-up care. A model is calibrated within a group if, for individuals receiving a given score, the frequency of the outcome equals that score. In finite datasets, one approximates this by binning scores, computing in each bin the empirical outcome rate, comparing it to the average predicted probability in that bin, and averaging the absolute discrepancies across bins using bin frequencies as weights. This bin-wise, frequency-weighted average of absolute discrepancies is known as the within-group Expected Calibration Error (ECE).\n\nYou are given two self-identified demographic groups, $A$ and $B$, with group sizes $N_A$ and $N_B$, and the following binned summaries. For each bin $k$, $n_{g,k}$ is the number of cases in group $g \\in \\{A,B\\}$, $\\hat{p}_{g,k}$ is the average predicted probability in the bin, and $m_{g,k}$ is the number of positive outcomes in the bin. The empirical outcome rate in the bin is $p_{g,k} = m_{g,k}/n_{g,k}$.\n\nGroup $A$ has $N_A = 1000$ partitioned into $5$ bins:\n- Bin $1$: $n_{A,1} = 300$, $\\hat{p}_{A,1} = 0.10$, $m_{A,1} = 27$.\n- Bin $2$: $n_{A,2} = 250$, $\\hat{p}_{A,2} = 0.30$, $m_{A,2} = 80$.\n- Bin $3$: $n_{A,3} = 200$, $\\hat{p}_{A,3} = 0.50$, $m_{A,3} = 108$.\n- Bin $4$: $n_{A,4} = 150$, $\\hat{p}_{A,4} = 0.70$, $m_{A,4} = 108$.\n- Bin $5$: $n_{A,5} = 100$, $\\hat{p}_{A,5} = 0.88$, $m_{A,5} = 94$.\n\nGroup $B$ has $N_B = 800$ partitioned into $5$ bins:\n- Bin $1$: $n_{B,1} = 240$, $\\hat{p}_{B,1} = 0.12$, $m_{B,1} = 21$.\n- Bin $2$: $n_{B,2} = 200$, $\\hat{p}_{B,2} = 0.28$, $m_{B,2} = 70$.\n- Bin $3$: $n_{B,3} = 160$, $\\hat{p}_{B,3} = 0.52$, $m_{B,3} = 83$.\n- Bin $4$: $n_{B,4} = 120$, $\\hat{p}_{B,4} = 0.68$, $m_{B,4} = 78$.\n- Bin $5$: $n_{B,5} = 80$, $\\hat{p}_{B,5} = 0.90$, $m_{B,5} = 68$.\n\nUsing the definition above, compute the within-group Expected Calibration Error for each group and then compute the absolute difference between the two groups’ within-group Expected Calibration Errors. Provide only this absolute difference as your final answer. Express your answer as a decimal and round your answer to four significant figures. After computing, discuss whether the observed difference is more consistent with a fairness violation (systematic group-wise miscalibration) or with sampling variance, grounding your reasoning in fundamental probability (for example, binomial variation within bins) and without relying on any pre-packaged significance tests. Do not include any units in the final numeric answer.",
            "solution": "The problem requires the computation of the within-group Expected Calibration Error ($ECE_g$) for two demographic groups, $A$ and $B$, the absolute difference between these two values, and a discussion regarding the nature of this difference.\n\nThe within-group Expected Calibration Error for a group $g$ with total size $N_g$, partitioned into $K$ bins, is defined as:\n$$ECE_g = \\sum_{k=1}^{K} \\frac{n_{g,k}}{N_g} |\\hat{p}_{g,k} - p_{g,k}|$$\nwhere for each bin $k$, $n_{g,k}$ is the number of individuals, $\\hat{p}_{g,k}$ is the average predicted probability, $m_{g,k}$ is the number of positive outcomes, and $p_{g,k} = m_{g,k}/n_{g,k}$ is the empirical outcome rate.\n\nFirst, the calculation for Group $A$ is performed. The total group size is $N_A = 1000$ and there are $K=5$ bins.\nThe empirical outcome rates, $p_{A,k} = m_{A,k}/n_{A,k}$, for each bin are:\n- Bin $1$: $p_{A,1} = \\frac{27}{300} = 0.09$\n- Bin $2$: $p_{A,2} = \\frac{80}{250} = 0.32$\n- Bin $3$: $p_{A,3} = \\frac{108}{200} = 0.54$\n- Bin $4$: $p_{A,4} = \\frac{108}{150} = 0.72$\n- Bin $5$: $p_{A,5} = \\frac{94}{100} = 0.94$\n\nThe absolute discrepancies between the average predicted probabilities, $\\hat{p}_{A,k}$, and the empirical rates, $p_{A,k}$, are:\n- Bin $1$: $|\\hat{p}_{A,1} - p_{A,1}| = |0.10 - 0.09| = 0.01$\n- Bin $2$: $|\\hat{p}_{A,2} - p_{A,2}| = |0.30 - 0.32| = 0.02$\n- Bin $3$: $|\\hat{p}_{A,3} - p_{A,3}| = |0.50 - 0.54| = 0.04$\n- Bin $4$: $|\\hat{p}_{A,4} - p_{A,4}| = |0.70 - 0.72| = 0.02$\n- Bin $5$: $|\\hat{p}_{A,5} - p_{A,5}| = |0.88 - 0.94| = 0.06$\n\nThe $ECE_A$ is the weighted average of these discrepancies, with weights $w_{A,k} = n_{A,k}/N_A$:\n$$ECE_A = \\frac{300}{1000}(0.01) + \\frac{250}{1000}(0.02) + \\frac{200}{1000}(0.04) + \\frac{150}{1000}(0.02) + \\frac{100}{1000}(0.06)$$\n$$ECE_A = 0.3(0.01) + 0.25(0.02) + 0.2(0.04) + 0.15(0.02) + 0.1(0.06)$$\n$$ECE_A = 0.003 + 0.005 + 0.008 + 0.003 + 0.006 = 0.025$$\n\nSecond, the calculation for Group $B$ is performed. The total group size is $N_B = 800$ and there are $K=5$ bins.\nThe empirical outcome rates, $p_{B,k} = m_{B,k}/n_{B,k}$, for each bin are:\n- Bin $1$: $p_{B,1} = \\frac{21}{240} = 0.0875$\n- Bin $2$: $p_{B,2} = \\frac{70}{200} = 0.35$\n- Bin $3$: $p_{B,3} = \\frac{83}{160} = 0.51875$\n- Bin $4$: $p_{B,4} = \\frac{78}{120} = 0.65$\n- Bin $5$: $p_{B,5} = \\frac{68}{80} = 0.85$\n\nThe absolute discrepancies $|\\hat{p}_{B,k} - p_{B,k}|$ are:\n- Bin $1$: $|\\hat{p}_{B,1} - p_{B,1}| = |0.12 - 0.0875| = 0.0325$\n- Bin $2$: $|\\hat{p}_{B,2} - p_{B,2}| = |0.28 - 0.35| = 0.07$\n- Bin $3$: $|\\hat{p}_{B,3} - p_{B,3}| = |0.52 - 0.51875| = 0.00125$\n- Bin $4$: $|\\hat{p}_{B,4} - p_{B,4}| = |0.68 - 0.65| = 0.03$\n- Bin $5$: $|\\hat{p}_{B,5} - p_{B,5}| = |0.90 - 0.85| = 0.05$\n\nThe $ECE_B$ is the weighted average of these discrepancies, with weights $w_{B,k} = n_{B,k}/N_B$:\n$$ECE_B = \\frac{240}{800}(0.0325) + \\frac{200}{800}(0.07) + \\frac{160}{800}(0.00125) + \\frac{120}{800}(0.03) + \\frac{80}{800}(0.05)$$\n$$ECE_B = 0.3(0.0325) + 0.25(0.07) + 0.2(0.00125) + 0.15(0.03) + 0.1(0.05)$$\n$$ECE_B = 0.00975 + 0.0175 + 0.00025 + 0.0045 + 0.005 = 0.037$$\n\nFinally, the absolute difference between the two within-group ECEs is calculated:\n$$|ECE_A - ECE_B| = |0.025 - 0.037| = |-0.012| = 0.012$$\nExpressed to four significant figures, this value is $0.01200$.\n\nDiscussion:\nThe observed Expected Calibration Errors are $ECE_A = 0.025$ for Group $A$ and $ECE_B = 0.037$ for Group $B$. The absolute difference is $|ECE_A - ECE_B| = 0.012$. To assess whether this difference indicates a systematic fairness violation or is likely due to sampling variance, we must analyze the source of the calibration error.\n\nThe ECE metric quantifies the discrepancy between predicted probabilities, $\\hat{p}_{g,k}$, and empirical outcome rates, $p_{g,k}$. Even for a perfectly calibrated model where $\\hat{p}_{g,k}$ equals the true underlying outcome probability $\\pi_{g,k}$ for bin $k$, the empirical rate $p_{g,k} = m_{g,k}/n_{g,k}$ will deviate from $\\pi_{g,k}$ due to finite sample effects. The number of positive outcomes $m_{g,k}$ in a bin of size $n_{g,k}$ is a realization of a binomial random variable, $m_{g,k} \\sim \\text{Binomial}(n_{g,k}, \\pi_{g,k})$. The standard error of the empirical proportion $p_{g,k}$ is $SE(p_{g,k}) = \\sqrt{\\frac{\\pi_{g,k}(1-\\pi_{g,k})}{n_{g,k}}}$. A fairness violation in the form of systematic miscalibration would be suggested if the observed discrepancies $|\\hat{p}_{g,k} - p_{g,k}|$ are substantially larger than this expected random error, or if a systematic pattern of errors emerges, particularly if this pattern differs between groups. Under the null hypothesis of perfect calibration ($\\pi_{g,k} \\approx \\hat{p}_{g,k}$), we estimate this standard error as $SE \\approx \\sqrt{\\frac{\\hat{p}_{g,k}(1-\\hat{p}_{g,k})}{n_{g,k}}}$.\n\nAn analysis of per-bin discrepancies relative to their standard errors (SE) reveals the following:\n\nFor Group $A$:\n- Bin $1$: Discrepancy $|-0.010|$ vs. $SE \\approx 0.0173$ (i.e., $0.58 \\times SE$).\n- Bin $2$: Discrepancy $|+0.020|$ vs. $SE \\approx 0.0290$ (i.e., $0.69 \\times SE$).\n- Bin $3$: Discrepancy $|+0.040|$ vs. $SE \\approx 0.0354$ (i.e., $1.13 \\times SE$).\n- Bin $4$: Discrepancy $|+0.020|$ vs. $SE \\approx 0.0374$ (i.e., $0.53 \\times SE$).\n- Bin $5$: Discrepancy $|+0.060|$ vs. $SE \\approx 0.0325$ (i.e., $1.85 \\times SE$).\nFor Group $A$, most discrepancies are within one standard error of the mean. The largest is below two standard errors. This provides weak evidence for miscalibration on its own. However, the sign of the error $p_{A,k} - \\hat{p}_{A,k}$ is consistently positive for bins $2-5$, suggesting a tendency for the model to under-predict risk for this group at higher predicted probabilities.\n\nFor Group $B$:\n- Bin $1$: Discrepancy $|-0.0325|$ vs. $SE \\approx 0.0210$ (i.e., $1.55 \\times SE$).\n- Bin $2$: Discrepancy $|+0.0700|$ vs. $SE \\approx 0.0317$ (i.e., $2.21 \\times SE$).\n- Bin $3$: Discrepancy $|-0.00125|$ vs. $SE \\approx 0.0395$ (i.e., $0.03 \\times SE$).\n- Bin $4$: Discrepancy $|-0.0300|$ vs. $SE \\approx 0.0426$ (i.e., $0.70 \\times SE$).\n- Bin $5$: Discrepancy $|-0.0500|$ vs. $SE \\approx 0.0335$ (i.e., $1.49 \\times SE$).\nFor Group $B$, the discrepancy in Bin $2$ ($0.07$) is more than two standard errors from zero, which is strong evidence for local miscalibration. The discrepancies in Bins $1$ and $5$ are also notable (approximately $1.5$ standard errors). In contrast to Group $A$, the signs of the error $p_{B,k} - \\hat{p}_{B,k}$ are predominantly negative (in $4$ out of $5$ bins), suggesting a general tendency for the model to over-predict risk for Group $B$.\n\nIn conclusion, the difference in ECE between the groups appears to stem from more than just sampling variance. The larger ECE in Group $B$ is driven by substantial miscalibration in specific bins (notably Bin $2$). Crucially, the *pattern* of miscalibration differs between the groups: the model tends to under-predict risk for Group $A$ (positive errors) and over-predict risk for Group $B$ (negative errors). This differential behavior is a hallmark of a systematic fairness violation. While some level of ECE is always expected from sampling noise (and a slightly higher variance is expected for Group $B$ due to its smaller sample size), the combination of a discrepancy exceeding two standard errors in one group and opposing systematic error patterns between groups is more consistent with group-wise systematic miscalibration than with random statistical fluctuations alone.",
            "answer": "$$\\boxed{0.01200}$$"
        }
    ]
}