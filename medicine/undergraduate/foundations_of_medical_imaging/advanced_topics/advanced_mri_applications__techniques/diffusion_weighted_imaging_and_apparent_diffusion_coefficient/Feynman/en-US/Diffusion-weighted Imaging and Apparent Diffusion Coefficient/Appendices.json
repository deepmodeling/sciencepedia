{
    "hands_on_practices": [
        {
            "introduction": "Before diving into complex signal models, it's crucial to confirm that our measurements are physically meaningful. This exercise guides you through a dimensional analysis to verify that the Apparent Diffusion Coefficient (ADC) has the correct physical dimensions of diffusivity, $L^2 T^{-1}$. By connecting the abstract parameters of an MRI sequence to fundamental physical units, this practice builds a solid foundation for understanding what ADC truly represents .",
            "id": "4877690",
            "problem": "A single-refocused spin-echo Diffusion-Weighted Imaging (DWI) experiment uses two identical rectangular diffusion-sensitizing gradient pulses of amplitude $g$ and duration $\\delta$, separated by a time $\\Delta$. The gyromagnetic ratio $\\gamma$ has units $\\mathrm{rad}\\,\\mathrm{s}^{-1}\\,\\mathrm{T}^{-1}$ (radian is dimensionless), the gradient amplitude $g$ has units $\\mathrm{T}\\,\\mathrm{m}^{-1}$, and the timing parameters $\\delta$ and $\\Delta$ have units $\\mathrm{s}$. The measured signal attenuation in the Stejskal–Tanner model is an exponential with a dimensionless argument. Starting from the fundamental facts that (i) the accumulated magnetic resonance phase $\\phi$ from a gradient field is dimensionless and arises from the time integral of $\\gamma\\,g$ times position $x(t)$, and (ii) the mean squared displacement for Fickian diffusion obeys $\\langle r^{2}\\rangle \\propto D\\,t$ where $D$ is a diffusion coefficient and $t$ is time, use dimensional analysis to:\n\n- infer the dimensional form of the diffusion-weighting factor $b$ constructed from $\\gamma$, $g$, and gradient timing, without invoking any closed-form expression for $b$,\n- deduce the base-dimension form of the Apparent Diffusion Coefficient (ADC), denoted $D_{\\mathrm{app}}$, by enforcing that the exponential’s argument is dimensionless,\n- and verify consistency with the mean squared displacement per unit time.\n\nGive your final answer as a dimensional expression in terms of the base dimensions $L$ (length) and $T$ (time). Do not compute any numerical values. Express the final answer using only $L$ and $T$ symbols.",
            "solution": "The problem is valid as it is scientifically grounded in the principles of magnetic resonance imaging and diffusion physics, is well-posed with sufficient information for a dimensional analysis, and is expressed in objective, formal language. It is free from any of the invalidating flaws listed in the instructions.\n\nThe solution proceeds in three steps as requested by the problem statement: first, inferring the dimensional form of the $b$-factor; second, deducing the dimensional form of the Apparent Diffusion Coefficient ($D_{\\mathrm{app}}$); and third, verifying consistency with the physical definition of a diffusion coefficient.\n\n**Step 1: Infer the dimensional form of the diffusion-weighting factor $b$**\n\nThe problem requires us to find the dimensions of the $b$-factor, which is constructed from the gyromagnetic ratio $\\gamma$, the gradient amplitude $g$, and the gradient timing parameters (duration $\\delta$ and separation $\\Delta$).\n\nThe fundamental effect of a magnetic field gradient pulse in an MRI experiment is to encode spatial information into the phase of the transverse magnetization. The quantity that represents the strength of this spatial encoding is a wavevector, often denoted by $q$. This wavevector is created by the application of a gradient $g$ for a duration $\\delta$, mediated by the gyromagnetic ratio $\\gamma$. We can construct this quantity from the given parameters: $q$ is proportional to the product $\\gamma g \\delta$.\n\nLet's determine the dimensions of this wavevector $q$. We are given the following units:\n- Gyromagnetic ratio $\\gamma$: $[\\gamma] = \\mathrm{s}^{-1}\\,\\mathrm{T}^{-1}$. In base dimensions of Time ($T$) and Magnetic Field ($\\mathrm{Tesla}$), this is $T^{-1}\\,\\mathrm{Tesla}^{-1}$.\n- Gradient amplitude $g$: $[g] = \\mathrm{T}\\,\\mathrm{m}^{-1}$. In base dimensions of Length ($L$) and Magnetic Field ($\\mathrm{Tesla}$), this is $\\mathrm{Tesla}\\,L^{-1}$.\n- Gradient duration $\\delta$: $[\\delta] = \\mathrm{s}$, which is the base dimension $T$.\n\nThe dimensions of the wavevector $q$ are:\n$$[q] = [\\gamma] [g] [\\delta] = (T^{-1}\\,\\mathrm{Tesla}^{-1}) (\\mathrm{Tesla}\\,L^{-1}) (T)$$\nThe units of $\\mathrm{Tesla}$ and $T$ cancel out, leaving:\n$$[q] = L^{-1}$$\nThis is dimensionally consistent with a wavevector or spatial frequency, which confirms its physical interpretation.\n\nThe diffusion-weighting factor, $b$, quantifies the degree of sensitization to diffusion. This sensitization depends on the magnitude of the spatial encoding (related to $q$) and the time allowed for diffusion to occur, which is the separation time $\\Delta$. In a diffusion experiment, a phase distribution is first created by $q$. During the time $\\Delta$, particles diffuse, leading to a random displacement $\\Delta r$. This random displacement causes a random phase shift $\\Delta \\phi \\propto q \\cdot \\Delta r$. The signal loss is related to the variance of this phase shift, $\\langle (\\Delta \\phi)^2 \\rangle$.\n$$\\langle (\\Delta \\phi)^2 \\rangle \\propto \\langle (q \\cdot \\Delta r)^2 \\rangle = q^2 \\langle (\\Delta r)^2 \\rangle$$\nThe signal attenuation is given by $\\exp(-b D_{\\mathrm{app}})$. The dimensionless argument $b D_{\\mathrm{app}}$ must be proportional to this phase variance, $\\langle (\\Delta \\phi)^2 \\rangle$.\n$$b D_{\\mathrm{app}} \\propto q^2 \\langle (\\Delta r)^2 \\rangle$$\nFrom the problem's fundamental fact (ii), the mean squared displacement is $\\langle (\\Delta r)^2 \\rangle \\propto D_{\\mathrm{app}} \\Delta$. Substituting this into the proportionality:\n$$b D_{\\mathrm{app}} \\propto q^2 (D_{\\mathrm{app}} \\Delta)$$\nWe can cancel the common factor $D_{\\mathrm{app}}$ from both sides to find the proportionality for $b$:\n$$b \\propto q^2 \\Delta$$\nNow we can determine the dimensions of $b$:\n$$[b] = [q]^2 [\\Delta] = (L^{-1})^2 (T) = L^{-2} T$$\n\n**Step 2: Deduce the base-dimension form of the Apparent Diffusion Coefficient ($D_{\\mathrm{app}}$)**\n\nThe problem states that the signal attenuation in the Stejskal–Tanner model is an exponential, $S = S_0 \\exp(-b D_{\\mathrm{app}})$, with a dimensionless argument. For the argument $-b D_{\\mathrm{app}}$ to be dimensionless, the product of the dimensions of $b$ and $D_{\\mathrm{app}}$ must be a dimensionless quantity, which we can represent as $1$.\n$$[b] [D_{\\mathrm{app}}] = 1$$\nTherefore, the dimensions of $D_{\\mathrm{app}}$ must be the inverse of the dimensions of $b$.\n$$[D_{\\mathrm{app}}] = \\frac{1}{[b]} = \\frac{1}{L^{-2} T}$$\n$$[D_{\\mathrm{app}}] = L^2 T^{-1}$$\n\n**Step 3: Verify consistency with the mean squared displacement per unit time**\n\nThe final step is to verify that this derived dimensional form for $D_{\\mathrm{app}}$ is consistent with the physical definition of a diffusion coefficient given in fundamental fact (ii).\n\nFact (ii) states that for Fickian diffusion, the mean squared displacement $\\langle r^2 \\rangle$ is proportional to the diffusion coefficient $D$ and the elapsed time $t$:\n$$\\langle r^2 \\rangle \\propto D t$$\nWe can rearrange this proportionality to solve for the dimensions of $D$:\n$$[D] = \\frac{[\\langle r^2 \\rangle]}{[t]}$$\nThe mean squared displacement, $\\langle r^2 \\rangle$, is an average of a squared length, so its dimension is length squared: $[\\langle r^2 \\rangle] = L^2$.\nThe dimension of time $t$ is simply $T$.\nSubstituting these into the expression for the dimensions of $D$:\n$$[D] = \\frac{L^2}{T} = L^2 T^{-1}$$\nThis dimensional form for a diffusion coefficient, derived from its fundamental physical definition, is identical to the dimensional form of $D_{\\mathrm{app}}$ we deduced in Step 2. This confirms the complete dimensional consistency of the physical model. The quantity $D_{\\mathrm{app}}$ measured in the DWI experiment indeed has the physical dimensions of a diffusion coefficient.",
            "answer": "$$\\boxed{L^2 T^{-1}}$$"
        },
        {
            "introduction": "With the physical basis of ADC established, we now turn to the practical task of its estimation from noisy measurements. This problem demonstrates how to calculate ADC from a pair of diffusion-weighted signals and, critically, how measurement noise introduces a systematic bias into the estimate. Deriving this bias from first principles will give you a deeper insight into the challenges of quantitative imaging and the importance of accounting for noise in data analysis .",
            "id": "4877857",
            "problem": "A diffusion-weighted Magnetic Resonance Imaging (MRI) voxel is modeled by the Stejskal–Tanner signal equation, where the noiseless signal at diffusion-weighting factor $b$ is given by $S(b)=S_0 \\exp(-b\\,\\mathrm{ADC})$, with $S_0$ the unweighted signal and $\\mathrm{ADC}$ the Apparent Diffusion Coefficient (ADC). You acquire $2$ measurements at distinct, strictly positive diffusion-weighting factors $b_1$ and $b_2$ with $b_2>b_1>0$. The measured signals are $Y_1$ and $Y_2$, which are corrupted by additive, independent, zero-mean Gaussian noise of variance $\\sigma^2$, that is, $Y_i=S(b_i)+\\varepsilon_i$, with $\\varepsilon_i \\sim \\mathcal{N}(0,\\sigma^2)$ and independent across $i\\in\\{1,2\\}$. Assume a high signal-to-noise ratio (SNR) regime so that $Y_i>0$ almost surely and the logarithm of $Y_i$ is well-defined.\n\nStarting from fundamental definitions of logarithms and expectations, and without invoking any specialized estimator formulas beyond the given signal model, do the following:\n\n- Derive a two-point estimator $\\widehat{\\mathrm{ADC}}$ in terms of $Y_1$, $Y_2$, $b_1$, and $b_2$ by transforming the signal model appropriately.\n\n- Using a second-order Taylor expansion of the logarithm about the noiseless means $S(b_i)$ and keeping terms up to order $\\sigma^2$, derive the leading-order bias $\\mathbb{E}[\\widehat{\\mathrm{ADC}}]-\\mathrm{ADC}$ under the stated noise model. Simplify your expression so that it depends only on $b_1$, $b_2$, $\\sigma^2$, $S_0$, and $\\mathrm{ADC}$.\n\nProvide, as your final answer, the closed-form analytic expression for the leading-order bias. Use consistent SI units for $\\mathrm{ADC}$ (square meters per second). No numerical evaluation or rounding is required.",
            "solution": "The problem is scientifically grounded, well-posed, and objective. The provided information is self-contained and sufficient for deriving a unique solution. The model and assumptions are standard in the field of quantitative medical imaging. Therefore, the problem is deemed valid. We proceed with the derivation.\n\nThe problem is divided into two parts: first, the derivation of a two-point estimator for the Apparent Diffusion Coefficient ($\\mathrm{ADC}$), and second, the calculation of the leading-order bias of this estimator.\n\n**Part 1: Derivation of the Estimator $\\widehat{\\mathrm{ADC}}$**\n\nThe noiseless signal model is given by the Stejskal–Tanner equation:\n$$S(b) = S_0 \\exp(-b\\,\\mathrm{ADC})$$\nwhere $S_0$ is the signal at $b=0$, and $\\mathrm{ADC}$ is the apparent diffusion coefficient. We have two measurements at distinct, positive diffusion-weighting factors $b_1$ and $b_2$, with $b_2 > b_1 > 0$. The corresponding noiseless signals are:\n$$S_1 = S(b_1) = S_0 \\exp(-b_1\\,\\mathrm{ADC})$$\n$$S_2 = S(b_2) = S_0 \\exp(-b_2\\,\\mathrm{ADC})$$\n\nTo isolate the $\\mathrm{ADC}$, we can linearize the model by taking the natural logarithm of these equations:\n$$\\ln(S_1) = \\ln(S_0) - b_1\\,\\mathrm{ADC}$$\n$$\\ln(S_2) = \\ln(S_0) - b_2\\,\\mathrm{ADC}$$\nThis forms a system of two linear equations with two unknowns, $\\ln(S_0)$ and $\\mathrm{ADC}$. We can solve for $\\mathrm{ADC}$ by subtracting the second equation from the first:\n$$\\ln(S_1) - \\ln(S_2) = (\\ln(S_0) - b_1\\,\\mathrm{ADC}) - (\\ln(S_0) - b_2\\,\\mathrm{ADC})$$\n$$\\ln\\left(\\frac{S_1}{S_2}\\right) = -b_1\\,\\mathrm{ADC} + b_2\\,\\mathrm{ADC} = (b_2 - b_1)\\,\\mathrm{ADC}$$\nSince we are given $b_2 > b_1$, the term $(b_2 - b_1)$ is non-zero, and we can solve for $\\mathrm{ADC}$:\n$$\\mathrm{ADC} = \\frac{\\ln(S_1) - \\ln(S_2)}{b_2 - b_1}$$\nAn estimator $\\widehat{\\mathrm{ADC}}$ is constructed by replacing the unobservable noiseless signals $S_1$ and $S_2$ with the measured signals $Y_1$ and $Y_2$:\n$$\\widehat{\\mathrm{ADC}} = \\frac{\\ln(Y_1) - \\ln(Y_2)}{b_2 - b_1}$$\nThis is the required two-point estimator.\n\n**Part 2: Derivation of the Leading-Order Bias**\n\nThe bias of the estimator is defined as $\\mathbb{E}[\\widehat{\\mathrm{ADC}}] - \\mathrm{ADC}$. We first compute the expected value of the estimator, $\\mathbb{E}[\\widehat{\\mathrm{ADC}}]$. Using the linearity of the expectation operator:\n$$\\mathbb{E}[\\widehat{\\mathrm{ADC}}] = \\mathbb{E}\\left[\\frac{\\ln(Y_1) - \\ln(Y_2)}{b_2 - b_1}\\right] = \\frac{1}{b_2 - b_1} \\left( \\mathbb{E}[\\ln(Y_1)] - \\mathbb{E}[\\ln(Y_2)] \\right)$$\nThe problem states that the measured signal $Y_i$ is $Y_i = S(b_i) + \\varepsilon_i$, where $\\varepsilon_i \\sim \\mathcal{N}(0, \\sigma^2)$ are independent noise terms. The mean of $Y_i$ is $\\mathbb{E}[Y_i] = \\mathbb{E}[S_i + \\varepsilon_i] = S_i + \\mathbb{E}[\\varepsilon_i] = S_i$, where we use the shorthand $S_i = S(b_i)$.\n\nTo find an approximation for $\\mathbb{E}[\\ln(Y_i)]$, we use a second-order Taylor expansion of the function $f(y) = \\ln(y)$ around the mean value $y = S_i$:\n$$f(Y_i) \\approx f(S_i) + f'(S_i)(Y_i - S_i) + \\frac{1}{2}f''(S_i)(Y_i - S_i)^2$$\nThe derivatives of $f(y) = \\ln(y)$ are:\n$$f'(y) = \\frac{1}{y} \\quad \\implies \\quad f'(S_i) = \\frac{1}{S_i}$$\n$$f''(y) = -\\frac{1}{y^2} \\quad \\implies \\quad f''(S_i) = -\\frac{1}{S_i^2}$$\nSubstituting these into the Taylor expansion gives:\n$$\\ln(Y_i) \\approx \\ln(S_i) + \\frac{1}{S_i}(Y_i - S_i) - \\frac{1}{2S_i^2}(Y_i - S_i)^2$$\nNow, we take the expectation of this expression. Since $S_i$ is a constant:\n$$\\mathbb{E}[\\ln(Y_i)] \\approx \\mathbb{E}\\left[\\ln(S_i)\\right] + \\frac{1}{S_i}\\mathbb{E}[Y_i - S_i] - \\frac{1}{2S_i^2}\\mathbb{E}\\left[(Y_i - S_i)^2\\right]$$\nThe expectation terms involving the noise $\\varepsilon_i = Y_i - S_i$ are:\n$$\\mathbb{E}[Y_i - S_i] = \\mathbb{E}[\\varepsilon_i] = 0$$\n$$\\mathbb{E}\\left[(Y_i - S_i)^2\\right] = \\mathbb{E}[\\varepsilon_i^2] = \\mathrm{Var}(\\varepsilon_i) + (\\mathbb{E}[\\varepsilon_i])^2 = \\sigma^2 + 0^2 = \\sigma^2$$\nSubstituting these results back into the approximation for $\\mathbb{E}[\\ln(Y_i)]$:\n$$\\mathbb{E}[\\ln(Y_i)] \\approx \\ln(S_i) + \\frac{1}{S_i}(0) - \\frac{1}{2S_i^2}(\\sigma^2) = \\ln(S_i) - \\frac{\\sigma^2}{2S_i^2}$$\nThis approximation is accurate up to order $\\sigma^2$.\n\nNow we can compute the expectation of our estimator:\n$$\\mathbb{E}[\\widehat{\\mathrm{ADC}}] \\approx \\frac{1}{b_2 - b_1} \\left( \\left[\\ln(S_1) - \\frac{\\sigma^2}{2S_1^2}\\right] - \\left[\\ln(S_2) - \\frac{\\sigma^2}{2S_2^2}\\right] \\right)$$\nRearranging the terms within the parentheses:\n$$\\mathbb{E}[\\widehat{\\mathrm{ADC}}] \\approx \\frac{1}{b_2 - b_1} \\left( (\\ln(S_1) - \\ln(S_2)) + \\left(\\frac{\\sigma^2}{2S_2^2} - \\frac{\\sigma^2}{2S_1^2}\\right) \\right)$$\nSeparating the expression into two parts:\n$$\\mathbb{E}[\\widehat{\\mathrm{ADC}}] \\approx \\frac{\\ln(S_1) - \\ln(S_2)}{b_2 - b_1} + \\frac{\\sigma^2}{2(b_2 - b_1)} \\left(\\frac{1}{S_2^2} - \\frac{1}{S_1^2}\\right)$$\nThe first term is exactly the true value of $\\mathrm{ADC}$. Therefore, the leading-order bias is the second term:\n$$\\text{Bias} = \\mathbb{E}[\\widehat{\\mathrm{ADC}}] - \\mathrm{ADC} \\approx \\frac{\\sigma^2}{2(b_2 - b_1)} \\left(\\frac{1}{S_2^2} - \\frac{1}{S_1^2}\\right)$$\nFinally, we must express this bias in terms of the specified parameters: $b_1, b_2, \\sigma^2, S_0$, and $\\mathrm{ADC}$. We substitute the model equations for $S_1$ and $S_2$:\n$$S_1^2 = \\left(S_0 \\exp(-b_1\\,\\mathrm{ADC})\\right)^2 = S_0^2 \\exp(-2b_1\\,\\mathrm{ADC})$$\n$$S_2^2 = \\left(S_0 \\exp(-b_2\\,\\mathrm{ADC})\\right)^2 = S_0^2 \\exp(-2b_2\\,\\mathrm{ADC})$$\nSubstituting these into the bias expression:\n$$\\text{Bias} \\approx \\frac{\\sigma^2}{2(b_2 - b_1)} \\left(\\frac{1}{S_0^2 \\exp(-2b_2\\,\\mathrm{ADC})} - \\frac{1}{S_0^2 \\exp(-2b_1\\,\\mathrm{ADC})}\\right)$$\nFactoring out the common term $1/S_0^2$:\n$$\\text{Bias} \\approx \\frac{\\sigma^2}{2S_0^2(b_2 - b_1)} \\left(\\frac{1}{\\exp(-2b_2\\,\\mathrm{ADC})} - \\frac{1}{\\exp(-2b_1\\,\\mathrm{ADC})}\\right)$$\nUsing the property $1/\\exp(-x) = \\exp(x)$, we arrive at the final expression for the leading-order bias:\n$$\\text{Bias} \\approx \\frac{\\sigma^2}{2S_0^2(b_2 - b_1)} \\left(\\exp(2b_2\\,\\mathrm{ADC}) - \\exp(2b_1\\,\\mathrm{ADC})\\right)$$",
            "answer": "$$\\boxed{\\frac{\\sigma^{2}}{2S_{0}^{2}(b_2 - b_1)} \\left(\\exp(2b_2\\mathrm{ADC}) - \\exp(2b_1\\mathrm{ADC})\\right)}$$"
        },
        {
            "introduction": "Real-world data often presents puzzles that challenge our theoretical understanding, such as observing a physically impossible negative ADC value. This practice explores the origins of this common artifact, forcing a distinction between the true, non-negative physical quantity and its estimate, which can be corrupted by noise. By analyzing the causes and potential solutions, you will develop the critical thinking skills needed to troubleshoot and interpret quantitative maps derived from real MRI data .",
            "id": "4877795",
            "problem": "A research team acquires Diffusion-Weighted Imaging (DWI) using a Pulsed Gradient Spin-Echo (PGSE) sequence in Magnetic Resonance Imaging (MRI). They assume Gaussian diffusion so that displacements over a diffusion time are described by a zero-mean Gaussian distribution with a diffusion tensor that is a covariance-like object, and they use nonnegative diffusion encoding strength values $b \\ge 0$. They estimate the Apparent Diffusion Coefficient (ADC) by fitting a monoexponential decay model to the magnitude data across multiple $b$-values. In ideal, noise-free conditions, they assert that the ADC must be nonnegative; however, in their real data at finite Signal-to-Noise Ratio (SNR), they sometimes obtain negative ADC estimates in some voxels.\n\nWhich of the following statements are correct under these assumptions?\n\nA. Under the monoexponential model arising from Gaussian diffusion and nonnegative $b$, the noiseless signal is a nonincreasing function of $b$, the slope of $\\ln S$ versus $b$ is nonpositive, and the $\\mathrm{ADC}$, defined as the negative of that slope, is nonnegative; equivalently, the diffusion tensor is positive semidefinite so any directional apparent diffusivity is nonnegative.\n\nB. In magnitude-reconstructed data with Rician noise at low SNR, upward bias of low signals can make a higher-$b$ measurement spuriously exceed a lower-$b$ measurement, producing a positive fitted slope of $\\ln S$ versus $b$ and thus a negative ADC estimate, even though the true ADC is nonnegative.\n\nC. The most reliable way to prevent negative ADC estimates is to increase $b$ to drive the diffusion-weighted signal well below the noise floor, which removes bias in the logarithmic fit.\n\nD. Negative ADC estimates can be mitigated by using estimators that enforce $\\mathrm{ADC} \\ge 0$ or by fitting with a likelihood that models magnitude noise (for example, a noncentral chi likelihood), and by improving SNR through averaging or acquisition parameter adjustments.\n\nE. In media with restricted diffusion or anisotropy, a genuinely negative ADC is possible in the limit of infinite SNR because signal can increase with $b$ along directions of restriction.",
            "solution": "We begin from first principles of random motion and the formation of the diffusion-weighted signal. Under Gaussian diffusion, the displacement $\\Delta \\mathbf{r}$ over diffusion time has a zero-mean multivariate normal distribution with covariance proportional to time. The diffusion tensor $\\mathbf{D}$ summarizes how mean squared displacement scales with time along different directions, and is mathematically a covariance-rate matrix. By definition of a covariance, $\\mathbf{D}$ is positive semidefinite: for any vector $\\mathbf{n}$, one has $\\mathbf{n}^\\top \\mathbf{D} \\mathbf{n} \\ge 0$.\n\nIn a Pulsed Gradient Spin-Echo (PGSE) experiment, the normalized diffusion-weighted signal equals the characteristic function of the displacement distribution evaluated at an encoding wavevector proportional to the gradient sequence. For Gaussian displacements, the cumulant expansion truncates at second order, yielding the well-tested Stejskal–Tanner result that the signal attenuation depends only on the second cumulant (the covariance), and that attenuation is monotonic in the encoding strength. Specifically, if the gradient direction is $\\mathbf{n}$ with $\\|\\mathbf{n}\\|=1$, and the encoding strength is summarized by $b \\ge 0$, then in the noiseless monoexponential model one obtains\n$$\n\\frac{S(b)}{S(0)} = \\exp\\!\\left( - b \\, \\mathbf{n}^\\top \\mathbf{D}\\, \\mathbf{n} \\right).\n$$\nDefining the directional apparent diffusion coefficient as\n$$\n\\mathrm{ADC}(\\mathbf{n}) \\equiv \\mathbf{n}^\\top \\mathbf{D} \\, \\mathbf{n},\n$$\nthe monoexponential model is $S(b) = S(0)\\,\\exp(-b\\,\\mathrm{ADC}(\\mathbf{n}))$. Since $\\mathbf{D}$ is positive semidefinite, one has $\\mathrm{ADC}(\\mathbf{n}) \\ge 0$ for all $\\mathbf{n}$, and therefore $S(b)$ is a nonincreasing function of $b$ for $b \\ge 0$. Equivalently, the slope of $\\ln S(b)$ versus $b$ is $-\\,\\mathrm{ADC}(\\mathbf{n}) \\le 0$, so $\\mathrm{ADC}(\\mathbf{n}) \\ge 0$. In the isotropic monoexponential model, the scalar ADC is the same in all directions and remains nonnegative by the same argument.\n\nWe now address how negative ADC estimates can arise in practice when fitting to magnitude data at finite Signal-to-Noise Ratio (SNR). In MRI, complex receiver noise is approximately zero-mean Gaussian per channel. After magnitude reconstruction and sum-of-squares coil combination, the noise in each voxel magnitude is well modeled by a Rician or, more generally, a noncentral chi distribution. This distribution induces a positive bias in the magnitude at low SNR: $\\mathbb{E}[|S_{\\text{mag}}|] > |S_{\\text{true}}|$ when $|S_{\\text{true}}|$ is small relative to the noise standard deviation. Moreover, the logarithm is a nonlinear transform, and $\\mathbb{E}[\\ln S_{\\text{mag}}] \\ne \\ln \\mathbb{E}[S_{\\text{mag}}]$, so ordinary least squares on $\\ln S_{\\text{mag}}$ versus $b$ is biased and heteroscedastic.\n\nA simple two-point estimator using $b_1=0$ and $b_2>0$ is\n$$\n\\widehat{\\mathrm{ADC}} = \\frac{1}{b_2-b_1}\\,\\ln\\!\\left(\\frac{\\widehat{S}(b_1)}{\\widehat{S}(b_2)}\\right).\n$$\nIf noise causes $\\widehat{S}(b_2) > \\widehat{S}(b_1)$ in a finite sample (for example, if the low-$b$ measurement is perturbed downward and the high-$b$ measurement is perturbed upward, and the upward bias is larger at low SNR for high $b$), then the logarithm becomes negative and $\\widehat{\\mathrm{ADC}}<0$. Even across multiple $b$-values, heteroscedastic scatter in $\\ln S$ can yield a slightly positive fitted slope, producing negative ADC estimates, despite the true ADC being nonnegative.\n\nStrategies to handle negative ADC estimates include:\n- Constraining the fit to enforce $\\mathrm{ADC} \\ge 0$ (for example, nonnegative least squares or bound-constrained optimization).\n- Using maximum likelihood estimators tailored to magnitude noise (for example, a noncentral chi likelihood), or fitting complex data when available to restore Gaussian noise assumptions.\n- Improving SNR by averaging repeated acquisitions, increasing voxel size, optimizing echo time, or using appropriate coil combinations.\n- Avoiding pushing signals deep into the noise floor, which exacerbates Rician bias.\n\nWe now evaluate each option:\n\nA. This statement follows directly from the Gaussian diffusion model and the positive semidefiniteness of the diffusion tensor. In the noiseless monoexponential model with $b \\ge 0$, $S(b)$ decays monotonically, the slope of $\\ln S$ versus $b$ is nonpositive, and $\\mathrm{ADC} \\ge 0$. Verdict — Correct.\n\nB. Magnitude reconstruction induces Rician or noncentral chi noise with upward bias at low SNR. This can make a higher-$b$ measurement spuriously larger than a lower-$b$ measurement, yielding a positive fitted slope of $\\ln S$ and hence a negative ADC estimate. Verdict — Correct.\n\nC. Increasing $b$ to drive the signal below the noise floor worsens magnitude bias and increases the chance of model-mismatch in the log domain; it does not remove bias and can increase the frequency of negative ADC estimates under naive fitting. Verdict — Incorrect.\n\nD. Enforcing $\\mathrm{ADC} \\ge 0$ in the fit and using likelihoods appropriate for magnitude data (for example, noncentral chi), as well as improving SNR through averaging or acquisition optimization, are standard remedies that reduce or eliminate negative estimates without discarding data. Verdict — Correct.\n\nE. Restricted diffusion and anisotropy do not lead to genuinely negative ADC; the diffusion tensor remains positive semidefinite, so $\\mathbf{n}^\\top \\mathbf{D} \\mathbf{n} \\ge 0$ for any direction, and in the limit of infinite SNR the estimated ADC remains nonnegative. Verdict — Incorrect.",
            "answer": "$$\\boxed{ABD}$$"
        }
    ]
}