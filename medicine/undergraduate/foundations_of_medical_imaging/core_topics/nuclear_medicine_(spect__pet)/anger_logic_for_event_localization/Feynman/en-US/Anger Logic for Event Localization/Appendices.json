{
    "hands_on_practices": [
        {
            "introduction": "The Anger logic algorithm provides an elegant and robust method for determining the location of a scintillation event. At its core, the algorithm computes a weighted average of detector positions, where the weights are the signals from each detector. This exercise guides you through the process of deriving the Anger logic estimator from first principles and applying it to a concrete example, reinforcing the crucial concept of energy independence that makes this technique so effective in practice .",
            "id": "4861666",
            "problem": "A scintillation camera uses an array of nine Photomultiplier Tubes (PMTs) arranged on a square grid to localize gamma-ray interaction events. The PMT centers lie at coordinates $\\{(x_k,y_k)\\}$ on a $3 \\times 3$ grid with spacings of $2\\,\\text{cm}$, where $x_k \\in \\{-2,0,2\\}$ and $y_k \\in \\{-2,0,2\\}$, and the origin is at the central PMT. For a single event, each PMT $k$ produces a signal $V_k$ that is proportional to the number of photoelectrons produced by scintillation light, which in turn is proportional to the local light intensity integrated over the PMT’s acceptance. Assume the PMT response is linear in the incident light and that the event position estimate should be invariant under uniform scaling of all PMT signals by a positive constant.\n\nStarting from the fundamental facts that (i) the PMT signals $\\{V_k\\}$ are linear in the light intensity, (ii) the event localization estimator must be homogeneous of degree zero in $\\{V_k\\}$ to be energy independent, and (iii) in the limit of dense sampling, the spatial estimate should reduce to the centroid of the light distribution, derive a discrete estimator for the event coordinates $(x,y)$ in terms of $\\{(x_k,y_k),V_k\\}$. Then, for the specific PMT coordinate set\n$\\{(x_k,y_k)\\} = \\{(-2,2),(0,2),(2,2),(-2,0),(0,0),(2,0),(-2,-2),(0,-2),(2,-2)\\}$ (all in $\\text{cm}$),\nuse the following measured signals (in arbitrary units) generated by the event:\n$$\n\\{V_k\\} = \\{4,\\,8,\\,12,\\,6,\\,10,\\,14,\\,8,\\,12,\\,16\\}.\n$$\nCompute the event coordinates $(x,y)$ using your derived estimator and express your final position in $\\text{cm}$ as exact values. Finally, verify energy independence by comparing the estimator’s output for $\\{V_k\\}$ to that for $\\{\\alpha V_k\\}$ with $\\alpha>0$ without substituting any numerical value for $\\alpha$.",
            "solution": "The problem statement is evaluated for validity prior to attempting a solution.\n\n**Problem Validation**\n\n**Step 1: Extracted Givens**\n- A scintillation camera uses an array of nine Photomultiplier Tubes (PMTs).\n- PMT centers are at coordinates $\\{(x_k,y_k)\\}$ on a $3 \\times 3$ grid with spacings of $2\\,\\text{cm}$.\n- The coordinate set for the PMT centers is $x_k \\in \\{-2,0,2\\}$ and $y_k \\in \\{-2,0,2\\}$.\n- The origin is at the central PMT.\n- A single event produces signals $V_k$ from each PMT $k$.\n- Fundamental fact (i): PMT signals $\\{V_k\\}$ are linear in the light intensity.\n- Fundamental fact (ii): The event localization estimator must be homogeneous of degree zero in $\\{V_k\\}$ to be energy independent. This is equivalent to the position estimate being invariant under uniform scaling of all PMT signals by a positive constant $\\alpha > 0$.\n- Fundamental fact (iii): In the limit of dense sampling, the spatial estimate should reduce to the centroid of the light distribution.\n- The specific PMT coordinates are $\\{(x_k,y_k)\\} = \\{(-2,2),(0,2),(2,2),(-2,0),(0,0),(2,0),(-2,-2),(0,-2),(2,-2)\\}$ in units of $\\text{cm}$.\n- The measured signals are $\\{V_k\\} = \\{4,\\,8,\\,12,\\,6,\\,10,\\,14,\\,8,\\,12,\\,16\\}$ in arbitrary units.\n- The task is to derive a discrete estimator for $(x,y)$, compute the coordinates for the given data, and verify the energy independence property.\n\n**Step 2: Validation Using Extracted Givens**\n- **Scientifically Grounded:** The problem describes the principle of Anger logic, a foundational and widely used technique in medical imaging for event localization in gamma cameras. The assumptions of linear PMT response and the connection between the estimator's homogeneity and energy independence are standard and correct in this context.\n- **Well-Posed:** The problem provides all necessary information—the theoretical basis, PMT coordinates, and signal values—to derive the estimator and compute a unique position. The objectives are clearly stated.\n- **Objective:** The problem is phrased in precise, quantitative terms, free of subjective or ambiguous language.\n- **Completeness and Consistency:** The data are self-consistent. There are $9$ PMTs, $9$ coordinate pairs, and $9$ signal values. The coordinates match the description of a $3 \\times 3$ grid with $2\\,\\text{cm}$ spacing centered at the origin. The requirements are mutually consistent and lead to a standard, valid physical model.\n\n**Step 3: Verdict and Action**\nThe problem is scientifically sound, well-posed, and complete. It is a valid problem in the field of medical imaging physics. A solution will be provided.\n\n**Derivation of the Event Position Estimator**\n\nThe problem requires that in the limit of dense sampling, the estimator for the event coordinates $(\\hat{x}, \\hat{y})$ must approach the centroid of the continuous light intensity distribution, $I(\\vec{r})$, where $\\vec{r}=(x,y)$. The coordinates of the centroid of a continuous distribution are given by:\n$$\n\\hat{x}_{\\text{cont}} = \\frac{\\int x I(x,y) \\,dx\\,dy}{\\int I(x,y) \\,dx\\,dy}\n$$\n$$\n\\hat{y}_{\\text{cont}} = \\frac{\\int y I(x,y) \\,dx\\,dy}{\\int I(x,y) \\,dx\\,dy}\n$$\nThe detector array is discrete, consisting of $N$ PMTs. We can discretize these integrals by replacing them with sums over the PMT locations. The signal $V_k$ from the $k$-th PMT is stated to be linear in the local light intensity. We thus use $V_k$ as a weighting factor that is proportional to the light intensity sampled at the position $(x_k, y_k)$.\n\nThe denominator, $\\int I(x,y) \\,dx\\,dy$, represents the total light intensity, which is proportional to the total energy of the event. In the discrete approximation, this becomes the sum of all individual PMT signals, $\\sum_{k=1}^{N} V_k$.\n\nThe numerator for $\\hat{x}$, $\\int x I(x,y) \\,dx\\,dy$, is the first moment of the light distribution with respect to the $x$-axis. Its discrete counterpart is the weighted sum of the $x$-coordinates of the PMTs, where the weights are the signals: $\\sum_{k=1}^{N} x_k V_k$.\n\nSimilarly, the discrete approximation for the numerator of $\\hat{y}$ is $\\sum_{k=1}^{N} y_k V_k$.\n\nCombining these components yields the discrete estimator for the event coordinates, known as the Anger logic estimator:\n$$\n\\hat{x} = \\frac{\\sum_{k=1}^{N} x_k V_k}{\\sum_{k=1}^{N} V_k} \\quad \\text{and} \\quad \\hat{y} = \\frac{\\sum_{k=1}^{N} y_k V_k}{\\sum_{k=1}^{N} V_k}\n$$\nThis form satisfies the condition of being homogeneous of degree zero in $\\{V_k\\}$, which ensures energy independence, as will be explicitly verified later.\n\n**Calculation of Event Coordinates**\n\nWe are given $N=9$ PMTs. The coordinates $\\{(x_k, y_k)\\}$ and corresponding signals $\\{V_k\\}$ are provided. Let's list them systematically, indexing $k=1, \\dots, 9$ from top-left to bottom-right:\n1. $(x_1, y_1) = (-2, 2)$, $V_1 = 4$\n2. $(x_2, y_2) = (0, 2)$, $V_2 = 8$\n3. $(x_3, y_3) = (2, 2)$, $V_3 = 12$\n4. $(x_4, y_4) = (-2, 0)$, $V_4 = 6$\n5. $(x_5, y_5) = (0, 0)$, $V_5 = 10$\n6. $(x_6, y_6) = (2, 0)$, $V_6 = 14$\n7. $(x_7, y_7) = (-2, -2)$, $V_7 = 8$\n8. $(x_8, y_8) = (0, -2)$, $V_8 = 12$\n9. $(x_9, y_9) = (2, -2)$, $V_9 = 16$\n\nFirst, we compute the sum of the signals (the denominator):\n$$\n\\sum_{k=1}^{9} V_k = 4 + 8 + 12 + 6 + 10 + 14 + 8 + 12 + 16 = 90\n$$\n\nNext, we compute the weighted sum of the $x$-coordinates (the numerator for $\\hat{x}$):\n$$\n\\sum_{k=1}^{9} x_k V_k = (-2)(4) + (0)(8) + (2)(12) + (-2)(6) + (0)(10) + (2)(14) + (-2)(8) + (0)(12) + (2)(16)\n$$\n$$\n\\sum_{k=1}^{9} x_k V_k = -8 + 0 + 24 - 12 + 0 + 28 - 16 + 0 + 32 = 48\n$$\n\nNow, we compute the estimated $x$-coordinate:\n$$\n\\hat{x} = \\frac{\\sum x_k V_k}{\\sum V_k} = \\frac{48}{90} = \\frac{8 \\times 6}{15 \\times 6} = \\frac{8}{15}\n$$\n\nNext, we compute the weighted sum of the $y$-coordinates (the numerator for $\\hat{y}$):\n$$\n\\sum_{k=1}^{9} y_k V_k = (2)(4) + (2)(8) + (2)(12) + (0)(6) + (0)(10) + (0)(14) + (-2)(8) + (-2)(12) + (-2)(16)\n$$\n$$\n\\sum_{k=1}^{9} y_k V_k = 8 + 16 + 24 + 0 + 0 + 0 - 16 - 24 - 32 = 8 - 32 = -24\n$$\n\nFinally, we compute the estimated $y$-coordinate:\n$$\n\\hat{y} = \\frac{\\sum y_k V_k}{\\sum V_k} = \\frac{-24}{90} = \\frac{-4 \\times 6}{15 \\times 6} = -\\frac{4}{15}\n$$\nThe calculated event coordinates are $(\\hat{x}, \\hat{y}) = (\\frac{8}{15}, -\\frac{4}{15})$. The units are inherited from the PMT position units, which are $\\text{cm}$.\n\n**Verification of Energy Independence**\n\nThe problem requires verification that the estimator is invariant under a uniform scaling of signals. This corresponds to the property of being homogeneous of degree zero. Let the signals be scaled by a positive constant $\\alpha > 0$, representing a different event energy, such that the new signals are $V'_k = \\alpha V_k$. We compute the new position estimate $(\\hat{x}', \\hat{y}')$:\n$$\n\\hat{x}' = \\frac{\\sum_{k=1}^{N} x_k V'_k}{\\sum_{k=1}^{N} V'_k} = \\frac{\\sum_{k=1}^{N} x_k (\\alpha V_k)}{\\sum_{k=1}^{N} (\\alpha V_k)} = \\frac{\\alpha \\sum_{k=1}^{N} x_k V_k}{\\alpha \\sum_{k=1}^{N} V_k} = \\frac{\\sum_{k=1}^{N} x_k V_k}{\\sum_{k=1}^{N} V_k} = \\hat{x}\n$$\n$$\n\\hat{y}' = \\frac{\\sum_{k=1}^{N} y_k V'_k}{\\sum_{k=1}^{N} V'_k} = \\frac{\\sum_{k=1}^{N} y_k (\\alpha V_k)}{\\sum_{k=1}^{N} (\\alpha V_k)} = \\frac{\\alpha \\sum_{k=1}^{N} y_k V_k}{\\alpha \\sum_{k=1}^{N} V_k} = \\frac{\\sum_{k=1}^{N} y_k V_k}{\\sum_{k=1}^{N} V_k} = \\hat{y}\n$$\nSince $(\\hat{x}', \\hat{y}') = (\\hat{x}, \\hat{y})$, the estimated position is independent of the scaling factor $\\alpha$. This verifies the energy-independent nature of the Anger logic estimator.",
            "answer": "$$\n\\boxed{\\begin{pmatrix} \\frac{8}{15} & -\\frac{4}{15} \\end{pmatrix}}\n$$"
        },
        {
            "introduction": "While the basic Anger logic formula provides a good first approximation, real-world gamma cameras exhibit geometric distortions that can compromise image quality. This practice introduces a common and powerful technique used to correct these nonlinearities: polynomial mapping. By applying a pre-calibrated correction model to measured data and quantifying the remaining error, you will gain insight into the essential calibration steps that ensure the spatial accuracy of medical images .",
            "id": "4861639",
            "problem": "In a position-sensitive gamma camera, events are localized by Anger logic, which computes a centroid from Photomultiplier Tube (PMT) signals to produce measured coordinates $(x,y)$. Due to nonuniform light collection, PMT gain variations, and edge effects, the measured coordinates exhibit geometric distortion relative to the true physical coordinates $(X,Y)$. A standard calibration approach uses a low-order bivariate polynomial mapping to correct measured coordinates.\n\nConsider the following second-order polynomial calibration model that maps measured $(x,y)$ to corrected estimates $(\\hat{X},\\hat{Y})$:\n$$\n\\hat{X} \\;=\\; a_{0} \\;+\\; a_{1}\\,x \\;+\\; a_{2}\\,y \\;+\\; a_{3}\\,x^{2} \\;+\\; a_{4}\\,x\\,y \\;+\\; a_{5}\\,y^{2}, \\quad\n\\hat{Y} \\;=\\; b_{0} \\;+\\; b_{1}\\,x \\;+\\; b_{2}\\,y \\;+\\; b_{3}\\,x^{2} \\;+\\; b_{4}\\,x\\,y \\;+\\; b_{5}\\,y^{2}.\n$$\nThe coefficients are obtained from a prior calibration and are given by\n$$\na_{0}=0,\\; a_{1}=0.98,\\; a_{2}=-0.01,\\; a_{3}=0.001,\\; a_{4}=0.0005,\\; a_{5}=0,\n$$\n$$\nb_{0}=0,\\; b_{1}=0.02,\\; b_{2}=1.01,\\; b_{3}=0,\\; b_{4}=-0.0003,\\; b_{5}=0.001.\n$$\nYou are provided with measured positions $(x,y)$ in millimeters and their corresponding true positions $(X,Y)$ in millimeters for $4$ events:\n- Event $1$: measured $(x,y)=(0,0)$, true $(X,Y)=(0,0)$.\n- Event $2$: measured $(x,y)=(10,0)$, true $(X,Y)=(9.8,0.3)$.\n- Event $3$: measured $(x,y)=(0,10)$, true $(X,Y)=(0.0,10.0)$.\n- Event $4$: measured $(x,y)=(10,10)$, true $(X,Y)=(10.0,10.0)$.\n\nTasks:\n- Using the polynomial model above, compute the corrected positions $(\\hat{X},\\hat{Y})$ for each event.\n- Using the Euclidean distance between $(\\hat{X},\\hat{Y})$ and $(X,Y)$ for each event, compute the root-mean-square error (RMSE) over the $4$ events.\n\nExpress the RMSE in millimeters and round your answer to four significant figures.",
            "solution": "The problem requires the calculation of the root-mean-square error (RMSE) for a polynomial distortion correction model applied to data from a gamma camera. The analysis proceeds in two stages: first, computing the corrected coordinates $(\\hat{X}, \\hat{Y})$ for each of the $4$ events using the given model and coefficients; second, calculating the RMSE based on the Euclidean distance between these corrected coordinates and the provided true coordinates $(X, Y)$.\n\nThe polynomial correction model is given by:\n$$\n\\hat{X} \\;=\\; a_{0} \\;+\\; a_{1}\\,x \\;+\\; a_{2}\\,y \\;+\\; a_{3}\\,x^{2} \\;+\\; a_{4}\\,x\\,y \\;+\\; a_{5}\\,y^{2}\n$$\n$$\n\\hat{Y} \\;=\\; b_{0} \\;+\\; b_{1}\\,x \\;+\\; b_{2}\\,y \\;+\\; b_{3}\\,x^{2} \\;+\\; b_{4}\\,x\\,y \\;+\\; b_{5}\\,y^{2}\n$$\nThe provided coefficients are:\n$$\na_{0}=0,\\; a_{1}=0.98,\\; a_{2}=-0.01,\\; a_{3}=0.001,\\; a_{4}=0.0005,\\; a_{5}=0\n$$\n$$\nb_{0}=0,\\; b_{1}=0.02,\\; b_{2}=1.01,\\; b_{3}=0,\\; b_{4}=-0.0003,\\; b_{5}=0.001\n$$\nSubstituting these coefficients into the model equations yields:\n$$\n\\hat{X}(x,y) \\;=\\; 0.98x - 0.01y + 0.001x^{2} + 0.0005xy\n$$\n$$\n\\hat{Y}(x,y) \\;=\\; 0.02x + 1.01y - 0.0003xy + 0.001y^{2}\n$$\nWe now apply these correction formulas to the measured coordinates $(x,y)$ for each of the $4$ events.\n\n**Event 1:** Measured $(x_1, y_1) = (0, 0)$, True $(X_1, Y_1) = (0, 0)$.\nThe corrected coordinates $(\\hat{X}_1, \\hat{Y}_1)$ are:\n$$\n\\hat{X}_1 = 0.98(0) - 0.01(0) + 0.001(0)^2 + 0.0005(0)(0) = 0\n$$\n$$\n\\hat{Y}_1 = 0.02(0) + 1.01(0) - 0.0003(0)(0) + 0.001(0)^2 = 0\n$$\nThe corrected position is $(\\hat{X}_1, \\hat{Y}_1) = (0, 0)$.\nThe squared Euclidean error is $d_1^2 = (0 - 0)^2 + (0 - 0)^2 = 0$.\n\n**Event 2:** Measured $(x_2, y_2) = (10, 0)$, True $(X_2, Y_2) = (9.8, 0.3)$.\nThe corrected coordinates $(\\hat{X}_2, \\hat{Y}_2)$ are:\n$$\n\\hat{X}_2 = 0.98(10) - 0.01(0) + 0.001(10)^2 + 0.0005(10)(0) = 9.8 + 0.1 = 9.9\n$$\n$$\n\\hat{Y}_2 = 0.02(10) + 1.01(0) - 0.0003(10)(0) + 0.001(0)^2 = 0.2\n$$\nThe corrected position is $(\\hat{X}_2, \\hat{Y}_2) = (9.9, 0.2)$.\nThe squared Euclidean error is $d_2^2 = (\\hat{X}_2 - X_2)^2 + (\\hat{Y}_2 - Y_2)^2 = (9.9 - 9.8)^2 + (0.2 - 0.3)^2 = (0.1)^2 + (-0.1)^2 = 0.01 + 0.01 = 0.02$.\n\n**Event 3:** Measured $(x_3, y_3) = (0, 10)$, True $(X_3, Y_3) = (0.0, 10.0)$.\nThe corrected coordinates $(\\hat{X}_3, \\hat{Y}_3)$ are:\n$$\n\\hat{X}_3 = 0.98(0) - 0.01(10) + 0.001(0)^2 + 0.0005(0)(10) = -0.1\n$$\n$$\n\\hat{Y}_3 = 0.02(0) + 1.01(10) - 0.0003(0)(10) + 0.001(10)^2 = 10.1 + 0.1 = 10.2\n$$\nThe corrected position is $(\\hat{X}_3, \\hat{Y}_3) = (-0.1, 10.2)$.\nThe squared Euclidean error is $d_3^2 = (\\hat{X}_3 - X_3)^2 + (\\hat{Y}_3 - Y_3)^2 = (-0.1 - 0.0)^2 + (10.2 - 10.0)^2 = (-0.1)^2 + (0.2)^2 = 0.01 + 0.04 = 0.05$.\n\n**Event 4:** Measured $(x_4, y_4) = (10, 10)$, True $(X_4, Y_4) = (10.0, 10.0)$.\nThe corrected coordinates $(\\hat{X}_4, \\hat{Y}_4)$ are:\n$$\n\\hat{X}_4 = 0.98(10) - 0.01(10) + 0.001(10)^2 + 0.0005(10)(10) = 9.8 - 0.1 + 0.1 + 0.05 = 9.85\n$$\n$$\n\\hat{Y}_4 = 0.02(10) + 1.01(10) - 0.0003(10)(10) + 0.001(10)^2 = 0.2 + 10.1 - 0.03 + 0.1 = 10.37\n$$\nThe corrected position is $(\\hat{X}_4, \\hat{Y}_4) = (9.85, 10.37)$.\nThe squared Euclidean error is $d_4^2 = (\\hat{X}_4 - X_4)^2 + (\\hat{Y}_4 - Y_4)^2 = (9.85 - 10.0)^2 + (10.37 - 10.0)^2 = (-0.15)^2 + (0.37)^2 = 0.0225 + 0.1369 = 0.1594$.\n\nThe RMSE is defined as the square root of the mean of the squared errors:\n$$\nRMSE = \\sqrt{\\frac{1}{N} \\sum_{i=1}^{N} d_i^2}\n$$\nwith $N=4$.\n\nFirst, we sum the squared errors:\n$$\n\\sum_{i=1}^{4} d_i^2 = d_1^2 + d_2^2 + d_3^2 + d_4^2 = 0 + 0.02 + 0.05 + 0.1594 = 0.2294\n$$\nNext, we calculate the mean squared error (MSE):\n$$\nMSE = \\frac{1}{4} \\sum_{i=1}^{4} d_i^2 = \\frac{0.2294}{4} = 0.05735\n$$\nFinally, we compute the RMSE by taking the square root of the MSE:\n$$\nRMSE = \\sqrt{0.05735} \\approx 0.239478598...\n$$\nThe problem requires the answer to be rounded to four significant figures. The first four significant figures are $2$, $3$, $9$, and $4$. The fifth significant figure is $7$, which is greater than or equal to $5$, so we round up the fourth significant figure.\n$$\nRMSE \\approx 0.2395 \\text{ mm}\n$$",
            "answer": "$$\\boxed{0.2395}$$"
        },
        {
            "introduction": "After mastering the calculation of event positions and methods for their correction, a fundamental question arises: what is the ultimate limit to our measurement precision? This advanced exercise delves into the theoretical heart of the problem by using the Cramér-Rao Lower Bound to determine the best possible localization accuracy achievable. By relating this bound to physical parameters like the light spread ($\\sigma$) and the number of detected photons ($N$), you will understand how the detector's physical design dictates its fundamental performance limits .",
            "id": "4861646",
            "problem": "A planar scintillation detector used in Anger logic event localization comprises a dense array of identical Photomultiplier Tubes (PMTs). A single gamma interaction at true position $(x,y)$ on the entrance face produces a light distribution on the PMT plane that is well described by a normalized isotropic Gaussian point-spread function with standard deviation $\\sigma$. Assume the total expected number of detected photoelectrons per event is $N$, and that, conditioned on $(x,y)$, the photoelectron counts registered by disjoint infinitesimal sensor elements are independent Poisson random variables whose means equal the integral of $N$ times the point-spread function over the element area.\n\nModel the Gaussian point-spread function as\n$$\nf(u,v \\mid x,y) \\;=\\; \\frac{1}{2\\pi \\sigma^{2}} \\exp\\!\\left(-\\frac{(u-x)^{2} + (v-y)^{2}}{2\\sigma^{2}}\\right),\n$$\nso that the mean count density on the plane is $N f(u,v \\mid x,y)$, and the mean count in a small area element $\\Delta A$ around $(u,v)$ is $\\lambda(u,v)\\,\\Delta A$ with $\\lambda(u,v) = N f(u,v \\mid x,y)$.\n\nStarting from the definition of the log-likelihood for independent Poisson observations and the Fisher information matrix $I(\\theta)$ for a parameter vector $\\theta$ given by\n$$\nI_{jk}(\\theta) \\;=\\; \\mathbb{E}\\!\\left[-\\frac{\\partial^{2}}{\\partial \\theta_{j}\\,\\partial \\theta_{k}} \\ln L(\\theta)\\right], \\quad \\theta = (x,y),\n$$\nderive, in the continuous limit of infinitesimal sensor elements, the Fisher information matrix for $(x,y)$, and from it obtain the Cramér–Rao lower bound on the variance of any unbiased estimator of $x$ (note: by symmetry, the same bound applies to $y$). Express your final answer as a single closed-form analytic expression in terms of $\\sigma$ and $N$. Do not round your answer, and do not include units in the final boxed expression.",
            "solution": "The problem is valid as it is scientifically grounded in the principles of medical imaging and statistical estimation theory, is well-posed with all necessary information provided, and is expressed in objective, formal language. We may proceed with the solution.\n\nThe problem asks for the Cramér–Rao lower bound (CRLB) on the variance of an unbiased estimator of the event position $x$. The parameter vector is $\\theta = (x,y)$. The CRLB for the variance of an estimator of $x$, denoted $\\hat{x}$, is given by the $(1,1)$ element of the inverse of the Fisher Information Matrix (FIM), $I(x,y)$.\n\nThe observation model is an inhomogeneous Poisson process over the detector plane $(u,v)$. The intensity or mean rate density of this process is $\\lambda(u,v; x,y)$, which is parameterized by the true event position $(x,y)$.\n$$\n\\lambda(u,v; x,y) = N f(u,v \\mid x,y) = \\frac{N}{2\\pi \\sigma^{2}} \\exp\\!\\left(-\\frac{(u-x)^{2} + (v-y)^{2}}{2\\sigma^{2}}\\right)\n$$\nFor an inhomogeneous Poisson process, the log-likelihood functional for observing a set of photoelectron events (a realization of the process) is given, up to constants independent of the parameters $(x,y)$, by:\n$$\n\\ln L(x,y) = \\int_{\\mathbb{R}^2} \\ln(\\lambda(u,v; x,y)) \\, d\\mathcal{N}(u,v) - \\int_{\\mathbb{R}^2} \\lambda(u,v; x,y) \\, du \\, dv\n$$\nwhere $d\\mathcal{N}(u,v)$ represents the observed number of counts in the infinitesimal area $du \\, dv$. The Fisher information is given by $I_{jk} = \\mathbb{E}\\left[-\\frac{\\partial^{2} \\ln L}{\\partial \\theta_{j}\\,\\partial \\theta_{k}}\\right]$. For an inhomogeneous Poisson process, this expectation simplifies to a well-known integral form:\n$$\nI_{jk}(x,y) = \\int_{\\mathbb{R}^2} \\frac{1}{\\lambda(u,v; x,y)} \\frac{\\partial \\lambda(u,v; x,y)}{\\partial \\theta_j} \\frac{\\partial \\lambda(u,v; x,y)}{\\partial \\theta_k} \\, du \\, dv\n$$\nWe need to compute the components of the $2 \\times 2$ FIM where $\\theta_1=x$ and $\\theta_2=y$. Let's start by calculating the partial derivatives of $\\lambda(u,v; x,y)$ with respect to $x$ and $y$. First, we compute the derivative of the logarithm of $\\lambda$, which simplifies the calculation.\n$$\n\\ln \\lambda(u,v; x,y) = \\ln(N) - \\ln(2\\pi\\sigma^2) - \\frac{(u-x)^2 + (v-y)^2}{2\\sigma^2}\n$$\nThe partial derivative with respect to $x$ is:\n$$\n\\frac{\\partial \\ln \\lambda}{\\partial x} = \\frac{\\partial}{\\partial x} \\left( -\\frac{(u-x)^2}{2\\sigma^2} \\right) = - \\frac{2(u-x)(-1)}{2\\sigma^2} = \\frac{u-x}{\\sigma^2}\n$$\nUsing the chain rule, $\\frac{\\partial \\lambda}{\\partial x} = \\lambda \\frac{\\partial \\ln \\lambda}{\\partial x}$, we get:\n$$\n\\frac{\\partial \\lambda(u,v; x,y)}{\\partial x} = \\lambda(u,v; x,y) \\frac{u-x}{\\sigma^2}\n$$\nBy symmetry, the partial derivative with respect to $y$ is:\n$$\n\\frac{\\partial \\lambda(u,v; x,y)}{\\partial y} = \\lambda(u,v; x,y) \\frac{v-y}{\\sigma^2}\n$$\nNow we can compute the elements of the FIM. Let's start with $I_{xx}$.\n$$\nI_{xx} = \\int_{\\mathbb{R}^2} \\frac{1}{\\lambda} \\left(\\lambda \\frac{u-x}{\\sigma^2}\\right) \\left(\\lambda \\frac{u-x}{\\sigma^2}\\right) \\, du \\, dv = \\frac{1}{\\sigma^4} \\int_{\\mathbb{R}^2} (u-x)^2 \\lambda(u,v; x,y) \\, du \\, dv\n$$\nSubstituting $\\lambda = N f$:\n$$\nI_{xx} = \\frac{N}{\\sigma^4} \\int_{\\mathbb{R}^2} (u-x)^2 f(u,v \\mid x,y) \\, du \\, dv\n$$\nThe integral term is the definition of the second central moment (variance) of the coordinate $u$, where the joint probability density function of $(u,v)$ is $f(u,v \\mid x,y)$. This PDF is a 2D isotropic Gaussian centered at $(x,y)$, with variance $\\sigma^2$ along both the $u$ and $v$ axes. The variance of the marginal distribution for $u$ is therefore $\\sigma^2$.\n$$\n\\int_{\\mathbb{R}^2} (u-x)^2 f(u,v \\mid x,y) \\, du \\, dv = \\text{Var}(u) = \\sigma^2\n$$\nSubstituting this back into the expression for $I_{xx}$:\n$$\nI_{xx} = \\frac{N}{\\sigma^4} (\\sigma^2) = \\frac{N}{\\sigma^2}\n$$\nBy symmetry, the calculation for $I_{yy}$ is identical:\n$$\nI_{yy} = \\frac{N}{\\sigma^4} \\int_{\\mathbb{R}^2} (v-y)^2 f(u,v \\mid x,y) \\, du \\, dv = \\frac{N}{\\sigma^4}(\\sigma^2) = \\frac{N}{\\sigma^2}\n$$\nNext, we compute the off-diagonal term $I_{xy}$.\n$$\nI_{xy} = \\int_{\\mathbb{R}^2} \\frac{1}{\\lambda} \\left(\\lambda \\frac{u-x}{\\sigma^2}\\right) \\left(\\lambda \\frac{v-y}{\\sigma^2}\\right) \\, du \\, dv = \\frac{1}{\\sigma^4} \\int_{\\mathbb{R}^2} (u-x)(v-y) \\lambda(u,v; x,y) \\, du \\, dv\n$$\nSubstituting $\\lambda = N f$:\n$$\nI_{xy} = \\frac{N}{\\sigma^4} \\int_{\\mathbb{R}^2} (u-x)(v-y) f(u,v \\mid x,y) \\, du \\, dv\n$$\nThe integral term is the covariance between $u$ and $v$. Since the Gaussian PSF $f(u,v \\mid x,y)$ is isotropic (circularly symmetric), the random variables $u$ and $v$ are uncorrelated (and in this case, independent). Thus, their covariance is zero.\n$$\n\\int_{\\mathbb{R}^2} (u-x)(v-y) f(u,v \\mid x,y) \\, du \\, dv = \\text{Cov}(u,v) = 0\n$$\nTherefore, $I_{xy} = 0$. Since the FIM is symmetric, $I_{yx} = I_{xy} = 0$.\n\nThe Fisher Information Matrix is:\n$$\nI(x,y) = \\begin{pmatrix} I_{xx} & I_{xy} \\\\ I_{yx} & I_{yy} \\end{pmatrix} = \\begin{pmatrix} N/\\sigma^2 & 0 \\\\ 0 & N/\\sigma^2 \\end{pmatrix}\n$$\nThe Cramér–Rao lower bound on the variance of any unbiased estimator $\\hat{x}$ is the $(1,1)$ component of the inverse of the FIM, denoted as $(I^{-1})_{11}$.\nThe inverse of our diagonal FIM is straightforward to compute:\n$$\nI(x,y)^{-1} = \\begin{pmatrix} N/\\sigma^2 & 0 \\\\ 0 & N/\\sigma^2 \\end{pmatrix}^{-1} = \\begin{pmatrix} (N/\\sigma^2)^{-1} & 0 \\\\ 0 & (N/\\sigma^2)^{-1} \\end{pmatrix} = \\begin{pmatrix} \\sigma^2/N & 0 \\\\ 0 & \\sigma^2/N \\end{pmatrix}\n$$\nThe CRLB on the variance of $\\hat{x}$ is the $(1,1)$ element:\n$$\n\\text{Var}(\\hat{x}) \\ge (I^{-1})_{11} = \\frac{\\sigma^2}{N}\n$$\nBy symmetry, the same bound applies to the variance of any unbiased estimator of $y$: $\\text{Var}(\\hat{y}) \\ge \\frac{\\sigma^2}{N}$. The problem asks for the lower bound on the variance of the estimator of $x$.",
            "answer": "$$\\boxed{\\frac{\\sigma^{2}}{N}}$$"
        }
    ]
}