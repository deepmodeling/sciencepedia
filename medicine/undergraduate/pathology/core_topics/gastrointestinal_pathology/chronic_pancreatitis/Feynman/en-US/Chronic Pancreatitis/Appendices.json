{
    "hands_on_practices": [
        {
            "introduction": "The pathophysiology of chronic pancreatitis is deeply rooted in the failure of pancreatic ductal cells to secrete bicarbonate-rich fluid. This exercise  provides a hands-on opportunity to connect a specific molecular defect—reduced function of the CFTR channel—to its direct physiological consequence. By applying the Henderson-Hasselbalch equation, you will quantitatively determine how a decrease in CFTR activity leads to a drop in ductal fluid $pH$, a critical event that triggers downstream complications like enzyme inactivation and protein plug formation.",
            "id": "4345266",
            "problem": "In chronic pancreatitis, reduced function of the Cystic Fibrosis Transmembrane Conductance Regulator (CFTR) channel in pancreatic ductal epithelium impairs bicarbonate-rich fluid secretion, lowering the ductal fluid alkalinity. Consider a steady-state segment of pancreatic duct in which bicarbonate secretion is dominated by CFTR-mediated anion conductance. Use the following data and assumptions:\n\n- Baseline ductal bicarbonate concentration is $[\\text{HCO}_{3}^{-}]_{0} = 120$ mmol/L at a CFTR single-channel open probability $P_{o,0} = 0.70$ under constant secretin stimulation.\n- The dissolved carbon dioxide concentration in ductal fluid is constant at $[\\text{CO}_{2}] = 1.2$ mmol/L.\n- At $37\\,^{\\circ}\\text{C}$, the effective acid dissociation constant for the $\\text{CO}_{2}$–$\\text{HCO}_{3}^{-}$ buffer gives $pK_{a} = 6.1$.\n- The number of CFTR channels and driving forces are unchanged; CFTR “activity” is proportional to the open probability $P_{o}$. In the linear operating range, the steady-state ductal bicarbonate concentration scales proportionally with CFTR activity, so $[\\text{HCO}_{3}^{-}] \\propto P_{o}$, with all other transporters and flows unchanged.\n\nA disease flare reduces CFTR activity by $50\\%$ relative to baseline.\n\nUsing only fundamental acid–base equilibria and the above assumptions, calculate the new ductal fluid $pH$ after this reduction. Express your answer as a pure number (no units) and round your answer to four significant figures.",
            "solution": "The problem requires the calculation of the new ductal fluid pH after a pathological reduction in the activity of the Cystic Fibrosis Transmembrane Conductance Regulator (CFTR) channel. The solution is derived from the principles of acid-base equilibrium applied to the bicarbonate buffer system, which is governed by the Henderson-Hasselbalch equation.\n\nThe Henderson-Hasselbalch equation for the bicarbonate buffer system, using the concentration of dissolved carbon dioxide, $[\\text{CO}_{2}]$, is given by:\n$$\npH = pK_{a} + \\log_{10}\\left(\\frac{[\\text{HCO}_{3}^{-}]}{[\\text{CO}_{2}]}\\right)\n$$\nwhere $[\\text{HCO}_{3}^{-}]$ is the molar concentration of bicarbonate, $[\\text{CO}_{2}]$ is the molar concentration of dissolved carbon dioxide, and $pK_{a}$ is the effective acid dissociation constant.\n\nThe problem provides the following constants and initial conditions:\n- The effective acid dissociation constant: $pK_{a} = 6.1$.\n- The concentration of dissolved carbon dioxide, which remains constant: $[\\text{CO}_{2}] = 1.2 \\text{ mmol/L}$.\n- The baseline bicarbonate concentration: $[\\text{HCO}_{3}^{-}]_{0} = 120 \\text{ mmol/L}$.\n- The baseline CFTR single-channel open probability: $P_{o,0} = 0.70$.\n\nA crucial premise of the problem is that the steady-state ductal bicarbonate concentration, $[\\text{HCO}_{3}^{-}]$, is directly proportional to the CFTR activity. Let the CFTR activity be denoted by the variable $A$. The relationship is:\n$$\n[\\text{HCO}_{3}^{-}] \\propto A\n$$\nThis can be expressed with a proportionality constant, $k$, as:\n$$\n[\\text{HCO}_{3}^{-}] = k \\cdot A\n$$\nAt the baseline state, we have:\n$$\n[\\text{HCO}_{3}^{-}]_{0} = k \\cdot A_{0}\n$$\nwhere $A_{0}$ is the baseline CFTR activity.\n\nThe problem states that a disease flare reduces CFTR activity by $50\\%$ relative to the baseline. Therefore, the new activity, $A_{1}$, is:\n$$\nA_{1} = (1 - 0.50) \\cdot A_{0} = 0.50 \\cdot A_{0}\n$$\nDue to the direct proportionality, the new bicarbonate concentration, $[\\text{HCO}_{3}^{-}]_{1}$, is related to the new activity $A_{1}$:\n$$\n[\\text{HCO}_{3}^{-}]_{1} = k \\cdot A_{1} = k \\cdot (0.50 \\cdot A_{0}) = 0.50 \\cdot (k \\cdot A_{0})\n$$\nBy substituting $[\\text{HCO}_{3}^{-}]_{0} = k \\cdot A_{0}$, we find the new bicarbonate concentration in terms of the baseline concentration:\n$$\n[\\text{HCO}_{3}^{-}]_{1} = 0.50 \\cdot [\\text{HCO}_{3}^{-}]_{0}\n$$\nUsing the given baseline value, we can calculate the numerical value of the new bicarbonate concentration:\n$$\n[\\text{HCO}_{3}^{-}]_{1} = 0.50 \\times 120 \\text{ mmol/L} = 60 \\text{ mmol/L}\n$$\nNow, we can calculate the new ductal fluid pH, which we will denote as $pH_{1}$, by substituting the new bicarbonate concentration into the Henderson-Hasselbalch equation. The parameters for the new state are:\n- $[\\text{HCO}_{3}^{-}]_{1} = 60 \\text{ mmol/L}$\n- $[\\text{CO}_{2}] = 1.2 \\text{ mmol/L}$ (constant)\n- $pK_{a} = 6.1$\n\nThe calculation for the new pH is:\n$$\npH_{1} = pK_{a} + \\log_{10}\\left(\\frac{[\\text{HCO}_{3}^{-}]_{1}}{[\\text{CO}_{2}]}\\right)\n$$\n$$\npH_{1} = 6.1 + \\log_{10}\\left(\\frac{60}{1.2}\\right)\n$$\nThe ratio of the concentrations is:\n$$\n\\frac{60}{1.2} = 50\n$$\nSubstituting this ratio back into the equation for pH:\n$$\npH_{1} = 6.1 + \\log_{10}(50)\n$$\nTo evaluate this expression, we calculate the base-10 logarithm of $50$:\n$$\n\\log_{10}(50) \\approx 1.69897\n$$\nTherefore, the new pH is:\n$$\npH_{1} \\approx 6.1 + 1.69897 = 7.79897\n$$\nThe problem requires the answer to be rounded to four significant figures. Rounding the calculated value gives:\n$$\npH_{1} \\approx 7.799\n$$\nThis result demonstrates that a $50\\%$ reduction in CFTR-mediated bicarbonate secretion leads to a significant drop in the alkalinity of the pancreatic ductal fluid, a key feature in the pathophysiology of chronic pancreatitis.",
            "answer": "$$\\boxed{7.799}$$"
        },
        {
            "introduction": "One of the hallmark clinical manifestations of advanced chronic pancreatitis is exocrine insufficiency, leading to the malabsorption of nutrients, particularly fat. This problem  guides you through the process of quantifying fat malabsorption from clinical data by calculating the coefficient of fat absorption. Mastering this calculation, which is based on the fundamental principle of mass conservation, is crucial for assessing disease severity and titrating pancreatic enzyme replacement therapy in patients.",
            "id": "4608472",
            "problem": "A 48-year-old man with calcific chronic pancreatitis presents with persistent steatorrhea despite Pancreatic Enzyme Replacement Therapy (PERT). He undergoes a standardized fecal fat quantification while consuming a diet containing $100$ g of fat per day. Over a $72$-hour collection, the total fecal fat measured is $63$ g. Assume the patient is in metabolic steady state, non-fecal fat losses are negligible, and the measurement is accurate. Using mass conservation of dietary fat and the core definition that the fraction of ingested nutrient absorbed equals the absorbed amount divided by the ingested amount, derive the coefficient of fat absorption for fat from first principles and compute its numerical value as a unitless decimal. Round your answer to three significant figures. Do not use a percentage sign.",
            "solution": "The relevant framework is mass conservation for nutrient handling in a steady state. Let $I$ denote daily ingested fat, $F$ denote daily fecal fat excretion, and $A$ denote daily absorbed fat. Under steady-state conditions and neglecting non-fecal losses, the absorbed amount satisfies\n$$\nA = I - F.\n$$\nThe coefficient of fat absorption is the fraction of ingested fat that is absorbed, defined as\n$$\nC = \\frac{A}{I}.\n$$\nSubstituting the mass balance into the definition gives\n$$\nC = \\frac{I - F}{I} = 1 - \\frac{F}{I}.\n$$\nFrom the data, the standardized dietary intake is $I = 100$ g/day. The $72$-hour fecal fat is $63$ g, so the daily fecal fat excretion is\n$$\nF = \\frac{63\\ \\text{g}}{3\\ \\text{days}} = 21\\ \\text{g/day}.\n$$\nTherefore,\n$$\nC = 1 - \\frac{21}{100} = 1 - 0.21 = 0.79.\n$$\nRounded to three significant figures, the unitless decimal is $0.790$.\n\nInterpreting this in the clinical context of chronic pancreatitis: typical normal values on a $100$ g fat diet are approximately $C \\geq 0.93$, mild malabsorption is often considered around $0.85$ to $0.93$, and values below $0.85$ are consistent with moderate to severe fat malabsorption. A value of $0.79$ indicates moderate to severe malabsorption, supporting escalation of Pancreatic Enzyme Replacement Therapy (PERT), for example by increasing lipase units per meal and considering acid suppression to optimize intraluminal enzyme activity, alongside nutritional interventions. Surgical management remains reserved for indications such as intractable pain with ductal obstruction or complications, rather than for malabsorption alone.",
            "answer": "$$\\boxed{0.790}$$"
        },
        {
            "introduction": "Understanding the natural history and progression of a chronic illness is essential for both clinical management and patient counseling. This advanced practice  introduces a powerful quantitative tool, the Markov chain model, to describe the progression of chronic pancreatitis through various stages of severity. By estimating a state transition matrix from longitudinal patient data, you will gain insight into how computational methods can be used to model disease dynamics and predict long-term outcomes.",
            "id": "4345250",
            "problem": "You are tasked with constructing a discrete-time Markov chain model for the progression of chronic pancreatitis across disease states and estimating its state transition probability matrix from longitudinal patient trajectories. The biological context is that chronic pancreatitis typically progresses from early disease to complications, with occasional persistence within the same state; regression is rare and not assumed here unless present in the data. Your implementation must be derived from first principles: use the definition of a first-order Markov chain and derive the corresponding likelihood from independent transitions, then obtain the parameter estimates by principled optimization or by a well-justified Bayesian regularization. Do not assume any prepackaged formulas; instead, reason from the definitions to a correct estimator.\n\nModel specification:\n- States: There are $4$ states, ordered as Early ($\\mathsf{E}$), Moderate ($\\mathsf{M}$), Severe ($\\mathsf{S}$), and Complications ($\\mathsf{C}$). Encode these as integers $\\{0,1,2,3\\}$ in that order.\n- Time: Observations are equally spaced in discrete time. For each patient, you are given a sequence of state codes visited at successive times. From each patient sequence, extract all consecutive ordered pairs $(s_t \\to s_{t+1})$ to form observed one-step transitions. The final state of a sequence with no successor does not contribute a transition.\n\nEstimation objective:\n- Estimate a $4 \\times 4$ transition probability matrix $P$ with entries $p_{ij}$ equal to the probability of transitioning from state $i$ at time $t$ to state $j$ at time $t+1$, for $i,j \\in \\{0,1,2,3\\}$, such that each row sums to $1$.\n- Base your estimator on the following foundational principles:\n  - First-order Markov property: $\\mathbb{P}(s_{t+1} = j \\mid s_t = i, \\text{history}) = \\mathbb{P}(s_{t+1} = j \\mid s_t = i) = p_{ij}$.\n  - Independent sampling of transitions across patients and time, conditional on the current state.\n  - Maximum Likelihood Estimation (MLE): choose parameters that maximize the joint likelihood of observed transitions subject to the row-stochastic constraints.\n  - Optional regularization via Laplace smoothing: when specified, incorporate a symmetric pseudocount $\\alpha$ added to each possible destination in a row before renormalizing.\n  - Optional absorbing-state enforcement: when specified, enforce $\\mathsf{C}$ (state code $3$) to be absorbing by setting its row to a point mass at state $3$.\n\nEdge-case handling:\n- If a row has no observed outgoing transitions and the specified pseudocount $\\alpha$ is $0$, define that row to be the uniform distribution over the $4$ states to preserve a valid stochastic row. If absorbing-state enforcement is active and the row corresponds to state $3$, override the row to be absorbing, that is, $[0,0,0,1]$.\n\nYour program must implement the estimator that aligns with these principles and apply it to the following test suite. For each case, compute the $4 \\times 4$ transition matrix with entries rounded to four decimal places.\n\nTest suite (each case specifies a list of patient trajectories as lists of integer-encoded states, a pseudocount $\\alpha$, and whether to enforce state $\\mathsf{C}$ as absorbing):\n\n- Case $1$ (general progression, no absorbing enforcement): \n  - Trajectories:\n    - $[0,1,1,2,2,3]$\n    - $[0,0,1,1,2,3]$\n    - $[1,1,2,2,2,3]$\n    - $[0,1,2,2,3,3]$\n    - $[0,0,0,1,1,2]$\n  - Pseudocount $\\alpha = 0$\n  - Enforce absorbing for state $3$: false\n\n- Case $2$ (includes an apparent improvement from complications; enforce absorbing complications):\n  - Trajectories:\n    - $[0,1,2,3,2,2]$\n    - $[1,2,3,3]$\n    - $[0,0,1,2,3]$\n    - $[2,2,3]$\n  - Pseudocount $\\alpha = 0$\n  - Enforce absorbing for state $3$: true\n\n- Case $3$ (sparse data with no observed severe or complications transitions; use smoothing):\n  - Trajectories:\n    - $[0,0,0]$\n    - $[0,1,1]$\n    - $[1,1]$\n  - Pseudocount $\\alpha = 0.5$\n  - Enforce absorbing for state $3$: false\n\nOutput requirements:\n- For each case, return the estimated $4 \\times 4$ matrix as a list of $4$ row lists, each containing $4$ floats rounded to four decimals.\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, where the first element is the matrix for Case $1$, the second for Case $2$, and the third for Case $3$. For example, the printed structure must look like a list of $3$ matrices: $[[[\\cdot,\\cdot,\\cdot,\\cdot],\\ldots],[[\\cdot,\\cdot,\\cdot,\\cdot],\\ldots],[[\\cdot,\\cdot,\\cdot,\\cdot],\\ldots]]$. Do not include any explanatory text and do not print multiple lines.",
            "solution": "The problem requires the estimation of a state transition probability matrix for a discrete-time, first-order Markov chain model of chronic pancreatitis progression. The estimation is to be derived from foundational principles, specifically Maximum Likelihood Estimation (MLE), and implemented to handle several test cases with specified variations.\n\n### Problem Formulation and Model Specification\n\nThe system is modeled as a Markov chain with a finite state space $S = \\{0, 1, 2, 3\\}$, corresponding to the disease states: Early ($\\mathsf{E}$), Moderate ($\\mathsf{M}$), Severe ($\\mathsf{S}$), and Complications ($\\mathsf{C}$). The evolution of the system is governed by a $4 \\times 4$ transition probability matrix $P$, where each entry $p_{ij} = \\mathbb{P}(X_{t+1} = j \\mid X_t = i)$ represents the probability of transitioning from state $i$ to state $j$ in one time step. By definition, each row of $P$ must sum to $1$, i.e., $\\sum_{j=0}^{3} p_{ij} = 1$ for all $i \\in S$.\n\nThe input data consists of a set of patient trajectories, which are sequences of observed states at discrete, equally spaced time points.\n\n### Derivation of the Maximum Likelihood Estimator (MLE)\n\nThe estimation of the transition probabilities $p_{ij}$ is based on maximizing the likelihood of the observed transition data.\n\n1.  **Transition Counts**: First, we process the raw trajectory data to obtain transition counts. Let $N_{ij}$ be the total number of observed one-step transitions from state $i$ to state $j$ across all patients. Let $N_i = \\sum_{j=0}^{3} N_{ij}$ be the total number of observed transitions originating from state $i$.\n\n2.  **Likelihood Function**: The core assumptions are the first-order Markov property and the independence of transitions, conditional on the starting state. The transitions originating from a given state $i$ can be modeled as a series of independent trials, which results in a multinomial distribution for the counts $(N_{i0}, N_{i1}, N_{i2}, N_{i3})$. The likelihood of observing these counts, given the probabilities $(p_{i0}, p_{i1}, p_{i2}, p_{i3})$, is proportional to $\\prod_{j=0}^{3} p_{ij}^{N_{ij}}$.\n\n    The total likelihood $L(P)$ for all observed transitions is the product of the likelihoods for each starting state:\n    $$\n    L(P) = \\prod_{i=0}^{3} \\prod_{j=0}^{3} p_{ij}^{N_{ij}}\n    $$\n\n3.  **Log-Likelihood and Optimization**: Maximizing the likelihood is equivalent to maximizing the log-likelihood, $\\ell(P) = \\log L(P)$, which is a more tractable function:\n    $$\n    \\ell(P) = \\sum_{i=0}^{3} \\sum_{j=0}^{3} N_{ij} \\log p_{ij}\n    $$\n    This optimization problem is subject to the constraints that each row must be a valid probability distribution: $\\sum_{j=0}^{3} p_{ij} = 1$ and $p_{ij} \\ge 0$ for all $i, j$.\n\n    The log-likelihood function is a sum of terms, where each term depends only on the parameters of a single row. Therefore, we can maximize the likelihood for each row $i$ independently. For a given row $i$, we must maximize $\\sum_{j=0}^{3} N_{ij} \\log p_{ij}$ subject to $\\sum_{j=0}^{3} p_{ij} = 1$.\n\n    Using the method of Lagrange multipliers, we define the Lagrangian for row $i$:\n    $$\n    \\mathcal{L}_i(p_{i0}, \\dots, p_{i3}, \\lambda_i) = \\left( \\sum_{j=0}^{3} N_{ij} \\log p_{ij} \\right) - \\lambda_i \\left( \\left( \\sum_{j=0}^{3} p_{ij} \\right) - 1 \\right)\n    $$\n    Taking the partial derivative with respect to an arbitrary $p_{ik}$ and setting it to zero yields:\n    $$\n    \\frac{\\partial \\mathcal{L}_i}{\\partial p_{ik}} = \\frac{N_{ik}}{p_{ik}} - \\lambda_i = 0 \\implies p_{ik} = \\frac{N_{ik}}{\\lambda_i}\n    $$\n    Summing over $k$ and applying the constraint $\\sum_{k=0}^{3} p_{ik} = 1$:\n    $$\n    \\sum_{k=0}^{3} \\frac{N_{ik}}{\\lambda_i} = 1 \\implies \\frac{1}{\\lambda_i} \\sum_{k=0}^{3} N_{ik} = 1 \\implies \\lambda_i = \\sum_{k=0}^{3} N_{ik} = N_i\n    $$\n    Substituting $\\lambda_i = N_i$ back gives the MLE for the transition probability $p_{ij}$:\n    $$\n    \\hat{p}_{ij}^{\\text{MLE}} = \\frac{N_{ij}}{N_i} = \\frac{N_{ij}}{\\sum_{k=0}^{3} N_{ik}}\n    $$\n    This fundamental result states that the maximum likelihood estimate of the transition probability is simply the observed frequency of that transition.\n\n### Regularization with Laplace Smoothing\n\nThe problem specifies an optional regularization via a pseudocount $\\alpha$, a technique also known as Laplace smoothing or Additive smoothing. This is equivalent to finding the Maximum a Posteriori (MAP) estimate under a symmetric Dirichlet prior with concentration parameter $\\alpha$. The estimator is modified by adding the pseudocount $\\alpha$ to each observed count:\n$$\n\\hat{p}_{ij}^{\\text{MAP}} = \\frac{N_{ij} + \\alpha}{\\sum_{k=0}^{3} (N_{ik} + \\alpha)} = \\frac{N_{ij} + \\alpha}{N_i + 4\\alpha}\n$$\nThis prevents zero probabilities for unobserved transitions, which can be useful especially with sparse data.\n\n### Algorithmic Implementation\n\nThe estimation procedure is as follows:\n\n1.  **Count Transitions**: Initialize a $4 \\times 4$ integer matrix $N$ to zeros. Iterate through each patient trajectory. For each consecutive pair of states $(s_t, s_{t+1})$ in a trajectory, increment the count $N_{s_t, s_{t+1}}$.\n\n2.  **Estimate Probabilities**: Initialize a $4 \\times 4$ floating-point matrix $P$. For each row $i \\in \\{0, 1, 2, 3\\}$:\n    a. Calculate the total outgoing count $N_i = \\sum_{j=0}^{3} N_{ij}$.\n    b. **Handle Edge Case**: If $N_i = 0$ (no transitions from state $i$ were observed) and the pseudocount $\\alpha = 0$, the standard formula is undefined. In this specific scenario, the problem mandates setting row $i$ to a uniform distribution: $p_{ij} = 1/4 = 0.25$ for $j=0,1,2,3$.\n    c. **Standard Calculation**: Otherwise (if $N_i > 0$ or $\\alpha > 0$), calculate each element $p_{ij}$ of the row using the regularized estimator:\n       $$\n       p_{ij} = \\frac{N_{ij} + \\alpha}{N_i + 4\\alpha}\n       $$\n\n3.  **Enforce Absorbing State**: After computing the entire matrix $P$ according to the steps above, check if the `enforce_absorbing` flag for state $3$ is active. If it is, unconditionally override row $3$ of the matrix to be $[0, 0, 0, 1]$. This rule takes precedence over any calculation for row $3$ performed in the previous step. The problem statement includes a specific sub-rule for the $N_i=0, \\alpha=0$ case, which is that if `enforce_absorbing` is true and $i=3$, that row becomes $[0,0,0,1]$ instead of uniform. A cleaner implementation is to handle all $N_i=0, \\alpha=0$ rows as uniform initially, and then apply the absorbing state override to row $3$ at the very end if required, as this covers all cases for row $3$.\n\n4.  **Final Formatting**: Round all entries in the final matrix $P$ to four decimal places.\n\nThis procedure provides a robust method for estimating the transition matrix from first principles, incorporating the specified regularization and handling all edge cases as defined.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef estimate_transition_matrix(trajectories, alpha, enforce_absorbing):\n    \"\"\"\n    Estimates the state transition probability matrix for a discrete-time Markov chain.\n\n    Args:\n        trajectories (list[list[int]]): A list of patient trajectories.\n        alpha (float): The pseudocount for Laplace smoothing.\n        enforce_absorbing (bool): If True, state 3 is enforced as absorbing.\n\n    Returns:\n        list[list[float]]: The 4x4 estimated transition matrix, rounded to 4 decimals.\n    \"\"\"\n    num_states = 4\n    counts = np.zeros((num_states, num_states), dtype=int)\n\n    # Step 1: Count transitions from the data\n    for trajectory in trajectories:\n        for i in range(len(trajectory) - 1):\n            from_state = trajectory[i]\n            to_state = trajectory[i+1]\n            if 0 <= from_state < num_states and 0 <= to_state < num_states:\n                counts[from_state, to_state] += 1\n\n    # Step 2: Estimate probabilities from counts\n    P = np.zeros((num_states, num_states), dtype=float)\n    for i in range(num_states):\n        n_i = np.sum(counts[i, :])\n\n        # Handle the edge case of no outgoing transitions and zero alpha\n        if n_i == 0 and alpha == 0.0:\n            # Per problem spec, assign uniform distribution for this row.\n            # A special sub-case for state 3 is handled by the global override later.\n            P[i, :] = np.ones(num_states) / num_states\n        else:\n            # Standard calculation using MLE with Laplace smoothing\n            denominator = n_i + num_states * alpha\n            for j in range(num_states):\n                numerator = counts[i, j] + alpha\n                P[i, j] = numerator / denominator\n\n    # Step 3: Enforce absorbing state for state 3 if specified\n    if enforce_absorbing:\n        P[3, :] = 0.0\n        P[3, 3] = 1.0\n\n    # Step 4: Round to four decimal places\n    P_rounded = np.round(P, 4)\n    return P_rounded.tolist()\n\ndef solve():\n    \"\"\"\n    Runs the estimation for all test cases and prints the final result.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # Case 1\n        (\n            [\n                [0, 1, 1, 2, 2, 3],\n                [0, 0, 1, 1, 2, 3],\n                [1, 1, 2, 2, 2, 3],\n                [0, 1, 2, 2, 3, 3],\n                [0, 0, 0, 1, 1, 2],\n            ],\n            0.0,\n            False,\n        ),\n        # Case 2\n        (\n            [\n                [0, 1, 2, 3, 2, 2],\n                [1, 2, 3, 3],\n                [0, 0, 1, 2, 3],\n                [2, 2, 3],\n            ],\n            0.0,\n            True,\n        ),\n        # Case 3\n        (\n            [\n                [0, 0, 0],\n                [0, 1, 1],\n                [1, 1],\n            ],\n            0.5,\n            False,\n        ),\n    ]\n\n    results = []\n    for trajectories, alpha, enforce_absorbing in test_cases:\n        matrix = estimate_transition_matrix(trajectories, alpha, enforce_absorbing)\n        results.append(matrix)\n\n    # Format the final output string manually to avoid spaces\n    # Example format: [[[d,d,d,d],[d,d,d,d],...],[[...]],...]\n    matrix_strings = []\n    for matrix in results:\n        row_strings = []\n        for row in matrix:\n            row_strings.append(f\"[{','.join(map(str, row))}]\")\n        matrix_strings.append(f\"[{','.join(row_strings)}]\")\n    \n    print(f\"[{','.join(matrix_strings)}]\")\n\nsolve()\n```"
        }
    ]
}