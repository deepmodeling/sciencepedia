{
    "hands_on_practices": [
        {
            "introduction": "Before a new digital health device, like a consumer wearable, can be trusted for clinical decisions, its measurements must be compared against a 'gold standard'. The Bland-Altman method is a fundamental statistical tool for this validation, allowing us to quantify both the systematic error (bias) and the random variability between two measurement techniques. This practice will guide you through calculating and interpreting these key metrics to determine if a device meets clinical acceptability criteria .",
            "id": "4955177",
            "problem": "A telemedicine program evaluates a wrist-worn wearable’s heart rate readings against simultaneous measurements from a clinical-grade Electrocardiogram (ECG). For each of $n=12$ adults at rest, the wearable heart rate (in beats per minute, $\\mathrm{bpm}$) and the ECG heart rate (in $\\mathrm{bpm}$) were recorded as paired measurements: \n$$(\\text{Wearable}, \\text{ECG}) = (65, 62),\\ (74, 75),\\ (93, 88),\\ (66, 70),\\ (95, 95),\\ (82, 80),\\ (74, 76),\\ (88, 84),\\ (69, 72),\\ (91, 90),\\ (77, 78),\\ (83, 83).$$\nAssume the measurement error (wearable minus ECG) is approximately normally distributed across subjects and apply the Bland–Altman method to quantify agreement. Starting from fundamental statistical principles for measurement error assessment in clinical validation, compute:\n- the mean bias (defined as the average of wearable minus ECG differences), and \n- the two-sided $95\\%$ limits of agreement.\n\nThen, interpret clinical acceptability using the following predefined thresholds for resting heart rate monitoring in digital health: the wearable is considered clinically acceptable if the magnitude of the mean bias is less than or equal to $1\\,\\mathrm{bpm}$ and the two-sided $95\\%$ limits of agreement lie within $\\pm 5\\,\\mathrm{bpm}$ around zero.\n\nReport your final numeric results as a row vector in the order $[\\text{mean bias},\\ \\text{lower limit of agreement},\\ \\text{upper limit of agreement}]$. Round your answer to three significant figures. Express all intermediate and final quantities in $\\mathrm{bpm}$, but do not include units in the final boxed vector.",
            "solution": "The problem requires the application of the Bland–Altman method to assess the agreement between a wearable device and a clinical-grade ECG for heart rate measurement. The analysis is based on a set of $n=12$ paired measurements. The core of this method involves calculating the mean and standard deviation of the differences between the two measurement techniques.\n\nFirst, we define the difference, $d_i$, for each of the $i=1, \\dots, 12$ subjects as the wearable measurement minus the ECG measurement.\nLet the paired measurements be denoted by $(W_i, E_i)$. Then $d_i = W_i - E_i$. The calculated differences are:\n$d_1 = 65 - 62 = 3$\n$d_2 = 74 - 75 = -1$\n$d_3 = 93 - 88 = 5$\n$d_4 = 66 - 70 = -4$\n$d_5 = 95 - 95 = 0$\n$d_6 = 82 - 80 = 2$\n$d_7 = 74 - 76 = -2$\n$d_8 = 88 - 84 = 4$\n$d_9 = 69 - 72 = -3$\n$d_{10} = 91 - 90 = 1$\n$d_{11} = 77 - 78 = -1$\n$d_{12} = 83 - 83 = 0$\n\nThe set of differences is $\\{3, -1, 5, -4, 0, 2, -2, 4, -3, 1, -1, 0\\}$.\n\nThe first quantity to compute is the mean bias, which is the sample mean of these differences, denoted by $\\bar{d}$.\n$$\n\\bar{d} = \\frac{1}{n} \\sum_{i=1}^{n} d_i\n$$\nThe sum of the differences is:\n$$\n\\sum_{i=1}^{12} d_i = 3 + (-1) + 5 + (-4) + 0 + 2 + (-2) + 4 + (-3) + 1 + (-1) + 0 = 4\n$$\nTherefore, the mean bias is:\n$$\n\\bar{d} = \\frac{4}{12} = \\frac{1}{3} \\approx 0.3333... \\ \\mathrm{bpm}\n$$\n\nNext, we calculate the sample standard deviation of the differences, $s_d$. The formula for the sample standard deviation is:\n$$\ns_d = \\sqrt{\\frac{1}{n-1} \\sum_{i=1}^{n} (d_i - \\bar{d})^2}\n$$\nTo compute this, we can use the computational formula $\\sum_{i=1}^{n} (d_i - \\bar{d})^2 = \\sum_{i=1}^{n} d_i^2 - \\frac{(\\sum_{i=1}^{n} d_i)^2}{n}$.\nFirst, we find the sum of the squares of the differences:\n$$\n\\sum_{i=1}^{12} d_i^2 = 3^2 + (-1)^2 + 5^2 + (-4)^2 + 0^2 + 2^2 + (-2)^2 + 4^2 + (-3)^2 + 1^2 + (-1)^2 + 0^2\n$$\n$$\n\\sum_{i=1}^{12} d_i^2 = 9 + 1 + 25 + 16 + 0 + 4 + 4 + 16 + 9 + 1 + 1 + 0 = 86\n$$\nNow we can compute the sum of squared deviations:\n$$\n\\sum_{i=1}^{12} (d_i - \\bar{d})^2 = 86 - \\frac{4^2}{12} = 86 - \\frac{16}{12} = 86 - \\frac{4}{3} = \\frac{258 - 4}{3} = \\frac{254}{3}\n$$\nThe sample variance, $s_d^2$, is:\n$$\ns_d^2 = \\frac{1}{12-1} \\left( \\frac{254}{3} \\right) = \\frac{254}{33}\n$$\nThe sample standard deviation is:\n$$\ns_d = \\sqrt{\\frac{254}{33}} \\approx 2.7743... \\ \\mathrm{bpm}\n$$\n\nThe two-sided $95\\%$ limits of agreement (LOA) are defined to capture the interval within which $95\\%$ of future measurement differences are expected to lie. Assuming the differences are normally distributed, this interval is estimated from the sample data as $\\bar{d} \\pm 1.96 s_d$. The value $1.96$ is the z-score corresponding to the central $95\\%$ of a standard normal distribution.\n$$\n\\text{LOA} = \\bar{d} \\pm 1.96 s_d\n$$\nThe half-width of the agreement interval is:\n$$\n1.96 s_d = 1.96 \\times \\sqrt{\\frac{254}{33}} \\approx 1.96 \\times 2.7743... \\approx 5.4377... \\ \\mathrm{bpm}\n$$\nThe lower limit of agreement (LLA) is:\n$$\n\\text{LLA} = \\bar{d} - 1.96 s_d \\approx \\frac{1}{3} - 5.4377... \\approx 0.3333... - 5.4377... \\approx -5.1044... \\ \\mathrm{bpm}\n$$\nThe upper limit of agreement (ULA) is:\n$$\n\\text{ULA} = \\bar{d} + 1.96 s_d \\approx \\frac{1}{3} + 5.4377... \\approx 0.3333... + 5.4377... \\approx 5.7710... \\ \\mathrm{bpm}\n$$\nThe problem requires reporting the final numeric results rounded to three significant figures.\nMean bias $= 0.333 \\ \\mathrm{bpm}$.\nLower limit of agreement $= -5.10 \\ \\mathrm{bpm}$.\nUpper limit of agreement $= 5.77 \\ \\mathrm{bpm}$.\n\nFinally, we interpret the clinical acceptability based on the predefined thresholds.\n1. Magnitude of mean bias: $|\\bar{d}| \\approx |0.333| = 0.333 \\ \\mathrm{bpm}$. Since $0.333 \\le 1$, this criterion is met. The systematic bias is clinically acceptable.\n2. $95\\%$ limits of agreement: The interval is approximately $[-5.10, 5.77]$. The criterion requires this interval to lie within $\\pm 5 \\ \\mathrm{bpm}$ around zero, i.e., within $[-5, 5]$. The calculated lower limit ($-5.10$) is below $-5$ and the upper limit ($5.77$) is above $5$. Therefore, this criterion is not met.\n\nThe wearable shows an acceptably small systematic error (bias), but its random error (variability) is too large for it to be considered clinically acceptable under the specified criteria.\n\nThe final reportable values are the mean bias, the lower limit of agreement, and the upper limit of agreement, rounded to three significant figures.",
            "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n0.333 & -5.10 & 5.77\n\\end{pmatrix}\n}\n$$"
        },
        {
            "introduction": "Data from digital health apps often comes from a self-selected group of users, which can create hidden biases that lead to incorrect scientific conclusions. This exercise explores a counterintuitive form of selection bias known as 'collider bias', where conditioning on a common effect (like app usage) can create a spurious association between two otherwise independent variables. By working through this scenario, you will develop a critical lens for interpreting findings from real-world digital health datasets .",
            "id": "4955183",
            "problem": "A hospital system is piloting a smartphone telemedicine application to monitor patients with chronic disease. The informatics team wants to use app-collected data to infer associations that hold in the general patient population. Let $A$ denote age category ($A=1$ for young adults and $A=0$ for older adults), $D$ denote genetic risk status for a chronic disease ($D=1$ for high-risk genotype and $D=0$ otherwise), and $U$ denote app usage ($U=1$ if a patient uses the app, $U=0$ otherwise). Assume that in the general population $A$ and $D$ are independent with $P(A=1)=0.5$ and $P(D=1)=0.5$. App usage is affected by both $A$ and $D$, with the following selection mechanism:\n- $P(U=1 \\mid A=1, D=1) = 0.9$\n- $P(U=1 \\mid A=1, D=0) = 0.5$\n- $P(U=1 \\mid A=0, D=1) = 0.5$\n- $P(U=1 \\mid A=0, D=0) = 0.1$\n\nThe informatics team restricts their analysis to app users (i.e., conditions on $U=1$) and reports an apparent association between $A$ and $D$ among users.\n\nUsing only core definitions from probability (independence, conditional probability, and Bayes’ rule), and the epidemiologic concepts of selection bias and collider bias, determine which of the following statements are correct about this scenario in digital health research:\n\nA. In the full population (not restricted by $U$), $A$ and $D$ are independent, so $P(D=1 \\mid A=1)=P(D=1 \\mid A=0)=0.5$.\n\nB. Among app users ($U=1$), $P(D=1 \\mid A=1, U=1) < P(D=1 \\mid A=0, U=1)$, demonstrating that conditioning on app usage induces an association between $A$ and $D$.\n\nC. Among app users ($U=1$), the odds ratio between $A$ and $D$ equals $1$, indicating no association.\n\nD. Conditioning on $U=1$ is conditioning on a collider, because both $A$ and $D$ causally influence $U$; therefore, conditioning on $U=1$ can induce an association between $A$ and $D$ even if they are independent in the population.\n\nE. The induced association between $A$ and $D$ among users reflects a true causal effect of $A$ on $D$.\n\nF. Under the given numbers, the odds ratio between $A$ and $D$ among app users ($U=1$) equals $0.36$.\n\nSelect all that apply.",
            "solution": "### Step 1: Extract Givens\n-   Age category: $A=1$ for young adults, $A=0$ for older adults.\n-   Genetic risk status: $D=1$ for high-risk, $D=0$ for low-risk.\n-   App usage: $U=1$ if user, $U=0$ if not.\n-   In the general population, $A$ and $D$ are independent.\n-   Base probabilities: $P(A=1)=0.5$, so $P(A=0)=0.5$. $P(D=1)=0.5$, so $P(D=0)=0.5$.\n-   Conditional probabilities for app usage (the selection mechanism):\n    -   $P(U=1 \\mid A=1, D=1) = 0.9$\n    -   $P(U=1 \\mid A=1, D=0) = 0.5$\n    -   $P(U=1 \\mid A=0, D=1) = 0.5$\n    -   $P(U=1 \\mid A=0, D=0) = 0.1$\n-   The analysis is restricted to app users, i.e., conditioned on $U=1$.\n\n### Step 2: Validate Using Extracted Givens\nThe problem is subjected to validation.\n- **Scientifically Grounded**: The problem describes collider bias, a well-known concept in epidemiology and statistics. The setup with a common effect (app usage, $U$) influenced by two independent causes (age, $A$, and disease risk, $D$) is a canonical example. The question explores the consequences of conditioning on this collider, which is a scientifically sound and important topic in observational research.\n- **Well-Posed**: The problem provides all necessary probabilities and a clear set of statements to evaluate. The calculations are based on fundamental probability theory, leading to a unique and verifiable answer.\n- **Objective**: The problem is quantitative and its statements can be proven or disproven mathematically without ambiguity or subjectivity.\n\n### Step 3: Verdict and Action\nThe problem is valid. A complete solution will be provided.\n\n### Solution Derivation\n\nWe will evaluate each statement systematically.\n\n**Statement A: In the full population (not restricted by $U$), $A$ and $D$ are independent, so $P(D=1 \\mid A=1)=P(D=1 \\mid A=0)=0.5$.**\nThis statement is correct by the problem definition. It explicitly states that \"$A$ and $D$ are independent\" in the general population and $P(D=1)=0.5$. The definition of independence means that $P(D=1 \\mid A=1) = P(D=1) = 0.5$ and $P(D=1 \\mid A=0) = P(D=1) = 0.5$.\n**A is correct.**\n\n**Statement D: Conditioning on $U=1$ is conditioning on a collider, because both $A$ and $D$ causally influence $U$; therefore, conditioning on $U=1$ can induce an association between $A$ and $D$ even if they are independent in the population.**\nThe problem states that app usage ($U$) is \"affected by both $A$ and $D$\". This implies a causal structure $A \\rightarrow U \\leftarrow D$. In such a structure, the variable $U$ is a \"collider\" because two causal arrows collide into it. A fundamental rule of causal inference is that conditioning on a collider (or a descendant of a collider) can induce a statistical association between its parents ($A$ and $D$), even if they are marginally independent. This statement accurately describes the phenomenon of collider bias.\n**D is correct.**\n\nTo evaluate statements B, C, and F, we need to calculate the probabilities of $D$ given $A$ *among app users* (i.e., conditioned on $U=1$). We use Bayes' rule: $P(D=1 \\mid A, U=1) = \\frac{P(U=1 \\mid D=1, A)P(D=1 \\mid A)}{P(U=1 \\mid A)}$.\n\nFirst, we find the marginal probability of app usage for each age group, $P(U=1 \\mid A)$.\nFor young adults ($A=1$):\n$P(U=1 \\mid A=1) = P(U=1 \\mid A=1, D=1)P(D=1 \\mid A=1) + P(U=1 \\mid A=1, D=0)P(D=0 \\mid A=1)$\nSince $A$ and $D$ are independent, $P(D=1|A=1) = P(D=1) = 0.5$ and $P(D=0|A=1) = P(D=0) = 0.5$.\n$P(U=1 \\mid A=1) = (0.9)(0.5) + (0.5)(0.5) = 0.45 + 0.25 = 0.70$.\n\nFor older adults ($A=0$):\n$P(U=1 \\mid A=0) = P(U=1 \\mid A=0, D=1)P(D=1 \\mid A=0) + P(U=1 \\mid A=0, D=0)P(D=0 \\mid A=0)$\n$P(U=1 \\mid A=0) = (0.5)(0.5) + (0.1)(0.5) = 0.25 + 0.05 = 0.30$.\n\nNow, we calculate the conditional probabilities of disease risk among app users for each age group.\nFor young adult users ($A=1, U=1$):\n$P(D=1 \\mid A=1, U=1) = \\frac{P(U=1 \\mid A=1, D=1)P(D=1 \\mid A=1)}{P(U=1 \\mid A=1)} = \\frac{(0.9)(0.5)}{0.70} = \\frac{0.45}{0.70} = \\frac{45}{70} = \\frac{9}{14} \\approx 0.643$.\n\nFor older adult users ($A=0, U=1$):\n$P(D=1 \\mid A=0, U=1) = \\frac{P(U=1 \\mid A=0, D=1)P(D=1 \\mid A=0)}{P(U=1 \\mid A=0)} = \\frac{(0.5)(0.5)}{0.30} = \\frac{0.25}{0.30} = \\frac{25}{30} = \\frac{5}{6} \\approx 0.833$.\n\n**Statement B: Among app users ($U=1$), $P(D=1 \\mid A=1, U=1) < P(D=1 \\mid A=0, U=1)$, demonstrating that conditioning on app usage induces an association between $A$ and $D$.**\nWe check if $9/14 < 5/6$.\n$9 \\times 6 = 54$. $14 \\times 5 = 70$.\nSince $54  70$, the inequality $9/14  5/6$ is true. This shows an association has been induced, as the probability of having the high-risk genotype is different between young and old users.\n**B is correct.**\n\n**Statement C and F: Odds Ratio Calculation**\nThe odds ratio (OR) compares the odds of high-risk disease ($D=1$) in young users ($A=1, U=1$) to the odds of high-risk disease in old users ($A=0, U=1$).\nOdds for young users: $\\text{Odds}(D=1 \\mid A=1, U=1) = \\frac{P(D=1 \\mid A=1, U=1)}{P(D=0 \\mid A=1, U=1)} = \\frac{9/14}{1-9/14} = \\frac{9/14}{5/14} = \\frac{9}{5} = 1.8$.\nOdds for old users: $\\text{Odds}(D=1 \\mid A=0, U=1) = \\frac{P(D=1 \\mid A=0, U=1)}{P(D=0 \\mid A=0, U=1)} = \\frac{5/6}{1-5/6} = \\frac{5/6}{1/6} = 5$.\nOdds Ratio: $\\text{OR} = \\frac{\\text{Odds}(D=1 \\mid A=1, U=1)}{\\text{Odds}(D=1 \\mid A=0, U=1)} = \\frac{1.8}{5} = \\frac{18}{50} = \\frac{9}{25} = 0.36$.\n\n- **Statement C: Among app users ($U=1$), the odds ratio between $A$ and $D$ equals $1$, indicating no association.**\nThe odds ratio is $0.36$, not $1$. An odds ratio of $1$ would indicate no association. Since the OR is not $1$, this statement is incorrect.\n**C is incorrect.**\n\n- **Statement F: Under the given numbers, the odds ratio between $A$ and $D$ among app users ($U=1$) equals $0.36$.**\nOur calculation confirms this.\n**F is correct.**\n\n**Statement E: The induced association between $A$ and $D$ among users reflects a true causal effect of $A$ on $D$.**\nThis is incorrect. We know from the problem statement that $A$ and $D$ are independent in the general population. A person's age ($A$) does not cause their genotype ($D$). The association observed among app users is a statistical artifact created by selection bias (conditioning on the collider $U$), not a real causal relationship.\n**E is incorrect.**\n\nIn summary, the correct statements are A, B, D, and F.",
            "answer": "$$\\boxed{ABDF}$$"
        },
        {
            "introduction": "An AI model that is highly accurate on paper may not be useful in a real clinical setting, where the consequences of false alarms and missed diagnoses must be weighed carefully. Decision Curve Analysis (DCA) is a powerful framework that evaluates a model based on its 'net benefit', quantifying whether it leads to better decisions than simple strategies like treating all patients or treating none. This practice will teach you how to compute net benefit and use a decision curve to assess the true clinical utility of a predictive model .",
            "id": "4955199",
            "problem": "A telemedicine service uses a supervised classification model to estimate, for each remote consultation, the probability that a patient truly requires urgent same-day in-person evaluation. This risk estimate is used to decide whether to recommend in-person evaluation when the estimated risk exceeds a threshold. You are given a cohort of $N=30$ telemedicine encounters with model-predicted risks $\\{p_i\\}_{i=1}^{30}$ and binary outcomes $\\{y_i\\}_{i=1}^{30}$, where $y_i=1$ indicates that the patient truly required urgent same-day in-person evaluation and $y_i=0$ indicates that the patient did not. The pairs $(p_i,y_i)$ are:\n$(0.45,1)$, $(0.42,1)$, $(0.38,1)$, $(0.35,1)$, $(0.33,1)$, $(0.31,0)$, $(0.29,1)$, $(0.28,0)$, $(0.27,0)$, $(0.25,1)$, $(0.24,0)$, $(0.23,0)$, $(0.22,1)$, $(0.21,0)$, $(0.19,1)$, $(0.18,0)$, $(0.17,0)$, $(0.16,0)$, $(0.15,0)$, $(0.14,0)$, $(0.13,0)$, $(0.12,0)$, $(0.11,0)$, $(0.10,0)$, $(0.09,0)$, $(0.08,0)$, $(0.07,0)$, $(0.06,0)$, $(0.05,0)$, $(0.03,0)$.\n\nAdopt the decision rule “recommend in-person evaluation” if and only if $p_i \\ge t$, where $t$ is the risk threshold. Using the foundational definitions of confusion-matrix counts and the net benefit construct from Decision Curve Analysis (DCA), and starting from first principles of benefit and harm trade-offs at a risk threshold, perform the following:\n\n1. For thresholds $t \\in \\{0.1,\\,0.2,\\,0.3\\}$, compute the model’s net benefit at each $t$.\n2. Construct the corresponding decision curve conceptually by comparing the model’s net benefit to “treat-all” and “treat-none” strategies over the specified thresholds.\n3. Interpret whether the model provides clinical utility relative to “treat-all” and “treat-none” at each threshold.\n\nExpress the final numeric net benefits for the model at $t \\in \\{0.1,\\,0.2,\\,0.3\\}$ in “benefit units per $100$ patients,” and round each value to four significant figures. Do not include units in your final boxed answer.",
            "solution": "### Step 1: Extract Givens\n- Total number of telemedicine encounters: $N=30$.\n- Model-predicted risks and binary outcomes: A set of $30$ pairs $(p_i, y_i)$, where $p_i$ is the predicted risk and $y_i$ is the true outcome.\n- Outcome definition: $y_i=1$ if the patient required urgent same-day in-person evaluation, and $y_i=0$ otherwise.\n- The data pairs are:\n$(0.45,1)$, $(0.42,1)$, $(0.38,1)$, $(0.35,1)$, $(0.33,1)$, $(0.31,0)$, $(0.29,1)$, $(0.28,0)$, $(0.27,0)$, $(0.25,1)$, $(0.24,0)$, $(0.23,0)$, $(0.22,1)$, $(0.21,0)$, $(0.19,1)$, $(0.18,0)$, $(0.17,0)$, $(0.16,0)$, $(0.15,0)$, $(0.14,0)$, $(0.13,0)$, $(0.12,0)$, $(0.11,0)$, $(0.10,0)$, $(0.09,0)$, $(0.08,0)$, $(0.07,0)$, $(0.06,0)$, $(0.05,0)$, $(0.03,0)$.\n- Decision rule: Recommend in-person evaluation if and only if $p_i \\ge t$, where $t$ is the risk threshold.\n- Thresholds for analysis: $t \\in \\{0.1, 0.2, 0.3\\}$.\n- Required output:\n    1. Compute the model's net benefit for each threshold $t$.\n    2. Conceptually construct the decision curve.\n    3. Interpret the model's clinical utility relative to \"treat-all\" and \"treat-none\" strategies.\n    4. Express final net benefits in \"benefit units per $100$ patients,\" rounded to four significant figures.\n\n### Step 2: Validate Using Extracted Givens\nThe problem is subjected to validation.\n\n- **Scientifically Grounded**: The problem is based on Decision Curve Analysis (DCA), a well-established and widely used method for evaluating the clinical utility of prediction models and diagnostic tests. The concepts of supervised learning, confusion matrix counts (True Positives, False Positives), and net benefit are standard in biostatistics and medical informatics. The setup is scientifically sound.\n- **Well-Posed**: The problem provides a complete dataset and a clear, unambiguous set of tasks. The required quantities are well-defined within the framework of DCA. A unique solution can be determined through direct calculation.\n- **Objective**: The problem statement is quantitative and free of subjective, biased, or opinion-based language.\n\n### Step 3: Verdict and Action\nThe problem is valid. A complete solution will be provided.\n\n### Solution Derivation\n\n#### Foundational Principles of Decision Curve Analysis (DCA)\nDecision Curve Analysis is founded on the principle that the value of a predictive model depends on the trade-off between the benefits of correctly identifying positive cases (True Positives, TP) and the harms of incorrectly identifying negative cases as positive (False Positives, FP). A decision maker, such as a clinician, operates at an implicit or explicit risk threshold, $t$. This threshold represents the minimum probability of an event at which the decision maker would opt for an intervention (in this case, recommending an in-person evaluation).\n\nThe net benefit (NB) is constructed by quantifying this trade-off. The benefit of the intervention is realized for true positive cases. The harm of the intervention (e.g., costs, patient anxiety, unnecessary use of resources) is incurred for false positive cases. At a given threshold $t$, the harm of a false positive is weighted relative to the benefit of a true positive by the odds of the event at that threshold, which is $\\frac{t}{1-t}$. This ratio is the \"exchange rate\" between harms and benefits.\n\nThe net benefit for a population of size $N$ is defined as the total number of true positives minus the weighted total number of false positives, all scaled by the population size:\n$$\n\\text{NB}(t) = \\frac{\\text{TP}(t)}{N} - \\frac{\\text{FP}(t)}{N} \\left(\\frac{t}{1-t}\\right)\n$$\nwhere $\\text{TP}(t)$ and $\\text{FP}(t)$ are the number of true positives and false positives, respectively, when the decision threshold is $t$.\n\n#### Reference Strategies\nThe utility of a model is assessed by comparing its net benefit to that of two default strategies:\n1.  **Treat-None**: Never recommend in-person evaluation, regardless of risk. In this case, $\\text{TP} = 0$ and $\\text{FP} = 0$. The net benefit is always zero.\n    $$\n    \\text{NB}_{\\text{none}}(t) = 0\n    $$\n2.  **Treat-All**: Recommend in-person evaluation for all patients. Here, all patients with the condition are true positives, and all patients without the condition are false positives. Let $P$ be the total number of patients with the condition (positive outcomes) and $N_{neg}$ be the total number of patients without it.\n    $$\n    \\text{NB}_{\\text{all}}(t) = \\frac{P}{N} - \\frac{N_{neg}}{N} \\left(\\frac{t}{1-t}\\right)\n    $$\n\n#### Data Analysis and Counts\nFirst, we determine the total number of positive ($P$) and negative ($N_{neg}$) cases in the cohort of $N=30$ patients. By counting from the provided data:\n-   The number of patients with $y_i=1$ is $P=9$.\n-   The number of patients with $y_i=0$ is $N_{neg} = 30 - 9 = 21$.\nThe prevalence of the condition in this cohort is $\\frac{P}{N} = \\frac{9}{30} = 0.3$.\n\nNow we compute the confusion matrix counts ($\\text{TP}$ and $\\text{FP}$) for the model at each specified threshold $t$.\n\n**1. Analysis for Threshold $t=0.1$**\nA patient is recommended for evaluation if their predicted risk $p_i \\ge 0.1$.\n-   **True Positives ($\\text{TP}(0.1)$)**: Patients with $y_i=1$ and $p_i \\ge 0.1$.\n    The risks for all $9$ patients with $y_i=1$ are $\\{0.45, 0.42, 0.38, 0.35, 0.33, 0.29, 0.25, 0.22, 0.19\\}$, all of which are $\\ge 0.1$. Thus, $\\text{TP}(0.1) = 9$.\n-   **False Positives ($\\text{FP}(0.1)$)**: Patients with $y_i=0$ and $p_i \\ge 0.1$.\n    The risks for patients with $y_i=0$ that are $\\ge 0.1$ are $\\{0.31, 0.28, 0.27, 0.24, 0.23, 0.21, 0.18, 0.17, 0.16, 0.15, 0.14, 0.13, 0.12, 0.11, 0.10\\}$. Counting these gives $\\text{FP}(0.1) = 15$.\n-   **Net Benefit of the Model**:\n    $$\n    \\text{NB}_{\\text{model}}(0.1) = \\frac{9}{30} - \\frac{15}{30} \\left(\\frac{0.1}{1-0.1}\\right) = 0.3 - 0.5 \\left(\\frac{0.1}{0.9}\\right) = 0.3 - 0.5 \\left(\\frac{1}{9}\\right) = \\frac{2.7 - 0.5}{9} = \\frac{2.2}{9} \\approx 0.24444\n    $$\n\n**2. Analysis for Threshold $t=0.2$**\nA patient is recommended for evaluation if $p_i \\ge 0.2$.\n-   **True Positives ($\\text{TP}(0.2)$)**: Patients with $y_i=1$ and $p_i \\ge 0.2$.\n    The positive case with $p_i=0.19$ is now excluded. Thus, $\\text{TP}(0.2) = 8$.\n-   **False Positives ($\\text{FP}(0.2)$)**: Patients with $y_i=0$ and $p_i \\ge 0.2$.\n    The risks for patients with $y_i=0$ that are $\\ge 0.2$ are $\\{0.31, 0.28, 0.27, 0.24, 0.23, 0.21\\}$. This gives $\\text{FP}(0.2) = 6$.\n-   **Net Benefit of the Model**:\n    $$\n    \\text{NB}_{\\text{model}}(0.2) = \\frac{8}{30} - \\frac{6}{30} \\left(\\frac{0.2}{1-0.2}\\right) = \\frac{8}{30} - \\frac{6}{30} \\left(\\frac{0.2}{0.8}\\right) = \\frac{1}{30} \\left(8 - 6 \\times \\frac{1}{4}\\right) = \\frac{1}{30} (8 - 1.5) = \\frac{6.5}{30} = \\frac{13}{60} \\approx 0.21667\n    $$\n\n**3. Analysis for Threshold $t=0.3$**\nA patient is recommended for evaluation if $p_i \\ge 0.3$.\n-   **True Positives ($\\text{TP}(0.3)$)**: Patients with $y_i=1$ and $p_i \\ge 0.3$.\n    The risks for positive cases $\\ge 0.3$ are $\\{0.45, 0.42, 0.38, 0.35, 0.33\\}$. Thus, $\\text{TP}(0.3) = 5$.\n-   **False Positives ($\\text{FP}(0.3)$)**: Patients with $y_i=0$ and $p_i \\ge 0.3$.\n    The only risk for a negative case $\\ge 0.3$ is $0.31$. Thus, $\\text{FP}(0.3) = 1$.\n-   **Net Benefit of the Model**:\n    $$\n    \\text{NB}_{\\text{model}}(0.3) = \\frac{5}{30} - \\frac{1}{30} \\left(\\frac{0.3}{1-0.3}\\right) = \\frac{5}{30} - \\frac{1}{30} \\left(\\frac{0.3}{0.7}\\right) = \\frac{1}{30} \\left(5 - \\frac{3}{7}\\right) = \\frac{1}{30} \\left(\\frac{35-3}{7}\\right) = \\frac{32}{210} = \\frac{16}{105} \\approx 0.15238\n    $$\n\n#### Decision Curve and Clinical Utility Interpretation\n\nTo interpret the clinical utility, we compare the model's net benefit to the net benefit of the \"treat-all\" and \"treat-none\" strategies at each threshold.\n-   $\\text{NB}_{\\text{none}}(t) = 0$ for all $t$.\n-   $\\text{NB}_{\\text{all}}(t) = \\frac{9}{30} - \\frac{21}{30} \\left(\\frac{t}{1-t}\\right) = 0.3 - 0.7 \\left(\\frac{t}{1-t}\\right)$.\n    -   $\\text{NB}_{\\text{all}}(0.1) = 0.3 - 0.7(\\frac{0.1}{0.9}) = 0.3 - \\frac{0.7}{9} \\approx 0.3 - 0.07778 = 0.22222$\n    -   $\\text{NB}_{\\text{all}}(0.2) = 0.3 - 0.7(\\frac{0.2}{0.8}) = 0.3 - 0.7(0.25) = 0.3 - 0.175 = 0.125$\n    -   $\\text{NB}_{\\text{all}}(0.3) = 0.3 - 0.7(\\frac{0.3}{0.7}) = 0.3 - 0.3 = 0$\n\n**Conceptual Decision Curve and Interpretation:**\n\nA decision curve plots the net benefit (y-axis) against the risk threshold $t$ (x-axis). We can summarize our findings for the three thresholds:\n\n| Threshold ($t$) | $\\text{NB}_{\\text{model}}(t)$ | $\\text{NB}_{\\text{all}}(t)$ | $\\text{NB}_{\\text{none}}(t)$ |\n|:---------------:|:-------------------------:|:----------------------:|:-----------------------:|\n| $0.1$           | $\\approx 0.244$         | $\\approx 0.222$      | $0$                     |\n| $0.2$           | $\\approx 0.217$         | $0.125$                | $0$                     |\n| $0.3$           | $\\approx 0.152$         | $0$                    | $0$                     |\n\n-   At threshold $t=0.1$: $\\text{NB}_{\\text{model}}(0.1)  \\text{NB}_{\\text{all}}(0.1)  \\text{NB}_{\\text{none}}(0.1)$. The model provides the highest net benefit. This means that for a decision-maker who believes that foregoing an in-person visit for $9$ patients who don't need one is equivalent in value to securing a visit for $1$ patient who does (i.e., odds $1:9$, corresponding to $t=0.1$), using the model is the best strategy.\n-   At threshold $t=0.2$: $\\text{NB}_{\\text{model}}(0.2)  \\text{NB}_{\\text{all}}(0.2)  \\text{NB}_{\\text{none}}(0.2)$. The model's superiority is even more pronounced. A decision-maker with a threshold of $20\\%$ (willing to accept $1$ unnecessary visit for every $4$ necessary ones) gains more by using the model than by recommending visits for all or for none.\n-   At threshold $t=0.3$: $\\text{NB}_{\\text{model}}(0.3)  \\text{NB}_{\\text{all}}(0.3) = \\text{NB}_{\\text{none}}(0.3)$. At this threshold, which matches the sample prevalence, the \"treat-all\" strategy offers no benefit over \"treat-none\". The model, however, offers a substantial positive net benefit, making it clearly the most valuable strategy.\n\nConceptually, the decision curve for the model would be a line connecting the points $(0.1, 0.244)$, $(0.2, 0.217)$, and $(0.3, 0.152)$. This curve lies consistently above the line for the \"treat-all\" strategy and the horizontal line at $y=0$ for the \"treat-none\" strategy. This demonstrates that the model has clinical utility across this range of risk thresholds.\n\n#### Final Answer Calculation\nThe problem asks for the net benefits for the model, expressed in units per $100$ patients and rounded to four significant figures. This requires multiplying the per-patient NB values by $100$.\n\n-   For $t=0.1$: $\\text{NB}_{\\text{model}} \\times 100 = 0.24444... \\times 100 = 24.444... \\approx 24.44$\n-   For $t=0.2$: $\\text{NB}_{\\text{model}} \\times 100 = 0.21666... \\times 100 = 21.666... \\approx 21.67$\n-   For $t=0.3$: $\\text{NB}_{\\text{model}} \\times 100 = 0.15238... \\times 100 = 15.238... \\approx 15.24$\n\nThese three values represent the final answer.",
            "answer": "$$\n\\boxed{\\begin{pmatrix} 24.44  21.67  15.24 \\end{pmatrix}}\n$$"
        }
    ]
}