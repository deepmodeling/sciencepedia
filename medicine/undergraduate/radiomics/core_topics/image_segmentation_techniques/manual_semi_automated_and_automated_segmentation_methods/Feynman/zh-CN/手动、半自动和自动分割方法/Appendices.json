{
    "hands_on_practices": [
        {
            "introduction": "在临床应用中，要信任一个自动分割算法，我们首先必须能够量化其结果与人类专家描绘的“金标准”之间的一致性。本练习介绍了一种基本的比较指标——对称体积差异，并挑战你批判性地思考病灶边界的微小变化将如何影响我们从中提取的放射组学特征的稳定性和可靠性。理解这种关联是构建稳健且可复现的放射组学模型的第一步。",
            "id": "4550673",
            "problem": "一个影像组学流程比较了通过不同方法获取的、针对同一个病灶的两个三维二值分割掩膜：一个掩膜由手动勾画产生，另一个由自动化算法生成。这两个掩膜定义在相同的成像网格上，具有相同的体素尺寸。它们的体积通过计算感兴趣区域（ROI）内所有体素的体积之和得出，测量结果为 $V_{\\text{manual}} = 120$ 毫升和 $V_{\\text{auto}} = 108$ 毫升。假设该病灶没有可用的真实体积（ground-truth volume），并且应使用一种对称的、无参考的体积百分比差异概念来表征两个掩膜之间的不一致性，请确定这两个掩膜之间的体积百分比差异。请将最终值以小数形式表示，不带百分号，并将答案四舍五入至四位有效数字。\n\n然后，基于掩膜体积和影像组学特征计算的基本定义进行推理，定性地解释这种量级的不一致性预计将如何影响基于强度的一阶特征和形状特征的稳定性，假设所有其他预处理步骤（如重采样和强度归一化）保持不变。在定性讨论中，您无需提供任何额外的数值；请专注于基于计算出的差异所带来的概念性影响。",
            "solution": "该问题要求分两部分作答：首先，定量计算两个分割掩膜之间的对称体积百分比差异；其次，定性解释这种差异如何影响特定类别影像组学特征的稳定性。\n\n首先，我们解决问题的定量部分。给定两个分割掩膜的体积，一个为手动勾画，一个为自动生成：\n$V_{\\text{manual}} = 120$ 毫升\n$V_{\\text{auto}} = 108$ 毫升\n\n问题要求一个“对称的、无参考的体积百分比差异”概念。标准的百分比差异，例如 $\\frac{|V_1 - V_2|}{V_1}$，是不对称的，因为它取决于选择哪个体积作为参考（$V_1$）。对称百分比差异通过一个同等对待两种测量的项来归一化绝对差异。最常见的对称公式在分母中使用两个测量值的平均值。设对称体积差异表示为 $\\Delta_V$。公式为：\n$$ \\Delta_V = \\frac{|V_{\\text{manual}} - V_{\\text{auto}}|}{\\frac{1}{2}(V_{\\text{manual}} + V_{\\text{auto}})} $$\n该度量将差异表示为平均体积的一部分，提供了一种平衡的度量方式来衡量不一致性，而不会偏向任何一种分割方法，这在没有真实值可用的情况下是合适的。\n\n将给定值代入公式：\n$$ \\Delta_V = \\frac{|120 - 108|}{\\frac{1}{2}(120 + 108)} $$\n$$ \\Delta_V = \\frac{12}{\\frac{1}{2}(228)} $$\n$$ \\Delta_V = \\frac{12}{114} $$\n\n为了将其表示为四舍五入到四位有效数字的小数，我们进行除法运算：\n$$ \\Delta_V = 0.105263157... $$\n四舍五入到四位有效数字，我们得到：\n$$ \\Delta_V \\approx 0.1053 $$\n该值对应于 $10.53\\%$ 的对称体积差异。\n\n接下来，我们对这种体积差异对影像组学特征稳定性的影响进行定性解释。$10.53\\%$ 这样量级的体积差异表明，在勾画的感兴趣区域（ROI）中存在着不可忽视的不一致。这种不一致源于一组体素，它们被包含在一个掩膜中，却被排除在另一个之外。影像组学特征的稳定性是指其对此类分割变化的鲁棒性。\n\n对基于强度的一阶特征的影响：\n一阶特征描述了ROI内体素强度的统计分布，由强度直方图计算得出。例子包括均值、方差、偏度和峰度。这些特征是基于ROI内所有体素 $i$ 的强度值集合 $\\{I_i\\}$ 来计算的。ROI边界的改变直接改变了这个体素集合。$10.53\\%$ 的体积差异意味着存在大量有争议的体素，主要位于病灶的边界上。\n\n对一阶特征的影响关键取决于这些有争议的体素相对于病灶核心的强度特征。\n1.  如果病灶相对同质，并且与周围组织有清晰、明确的边界，那么有争议的边界体素的强度可能与病灶核心内的强度有显著差异。例如，包含较暗的瘤周组织会降低平均强度，并可能增加方差。\n2.  像偏度（衡量直方图不对称性）和峰度（衡量拖尾性）这样的高阶矩对异常值尤其敏感。在边界处包含或排除少量具有极端强度值的体素，可能会对这些特征产生不成比例的影响，从而导致高度不稳定性。\n因此，这种规模的体积差异预计会给一阶统计特征带来显著的不稳定性，特别是对于异质性病灶或边界定义不清的病灶，这些情况下分割不一致性最为明显。\n\n对形状特征的影响：\n形状特征量化了ROI的几何形状，与体素强度无关。例子包括体积、表面积、球形度和紧凑度。根据其定义，这些特征直接从分割掩膜中导出。\n1.  `体积`特征本身受到直接影响；我们已经通过计算量化了其不稳定性，显示出 $10.53\\%$ 的对称差异。\n2.  `表面积`是通过对ROI边界上体素的暴露面面积求和来计算的。边界体素的变化直接改变了表面积。自动化分割有时会产生比手动分割更不平滑（更“锯齿状”）的边界，即使体积相似，也可能导致计算出的表面积有显著差异。有争议的体素直接造成了这种差异。\n3.  作为表面积和体积比值的特征，例如`球形度` ($\\propto \\frac{V^{2/3}}{A}$) 和 `紧凑度` ($\\propto \\frac{V}{A^{3/2}}$)，将会非常不稳定。由于分子（$V$）和分母（$A$，表面积）都是掩膜几何形状的函数且都不稳定，它们的比值的不稳定性会加剧。$10.53\\%$ 的体积变化，加上表面积可能存在的更大百分比变化，将导致这些复杂形状描述子的可重复性很差。\n\n总之，$10.53\\%$ 的对称体积差异是相当大的，这表明基于强度的一阶特征，以及特别是形状特征，在手动和自动分割方法之间很可能表现出较差的稳定性和可重复性。",
            "answer": "$$\\boxed{0.1053}$$"
        },
        {
            "introduction": "半自动分割方法在人类直觉与计算优化之间建立了强大的协同作用。本练习深入探讨了一种流行的半自动方法——图割（Graph Cut）的内部机制，将其简化为一个易于管理的小型网格。你将亲手计算并体会到，用户的“涂鸦”提示（指定前景和背景）如何作为硬性约束，在能量最小化框架中引导算法找到一个既能拟合图像数据又能保持区域平滑的最佳边界。",
            "id": "4550588",
            "problem": "一个在单一二维切片上运行的放射组学流程，使用用户涂鸦提示和二元图割 (GC) 优化来应用半自动分割。涂鸦被视为硬约束：临床医生将左上角的体素标记为前景（病灶），将右下角的体素标记为背景（非病灶）。该切片被抽象为一个由四个体素组成的网格，索引为 $\\{(1,1),(1,2),(2,1),(2,2)\\}$，其中 $(1,1)$ 表示左上角的体素，$(2,2)$ 表示右下角的体素。在最大后验 (MAP) 框架和带有 Potts 正则化器的二元马尔可夫随机场 (MRF) 下，分割过程旨在最小化能量\n$$\nE(\\mathbf{L}) \\;=\\; \\sum_{i} D_{i}(L_{i}) \\;+\\; \\sum_{(i,j)\\in\\mathcal{N}} w_{ij}\\,\\big[ L_{i} \\neq L_{j} \\big],\n$$\n其中 $\\mathbf{L}$ 是标记场，对于前景 $F$ 和背景 $B$，有 $L_{i}\\in\\{F,B\\}$；$D_{i}(\\cdot)$ 是从放射组学强度模型的负对数似然导出的一元数据项；$\\mathcal{N}$ 是网格上的 4-邻域系统；$w_{ij}>0$ 是成对平滑权重；如果标记不同，则 $[L_{i}\\neq L_{j}]$ 为 $1$，否则为 $0$。通过将错误标记的一元项设置为 $+\\infty$ 来强制执行涂鸦约束，从而使这些分配变得不可行。\n\n一元项指定如下\n$$\nD_{(1,1)}(F)=0,\\quad D_{(1,1)}(B)=+\\infty,\\qquad\nD_{(1,2)}(F)=3,\\quad D_{(1,2)}(B)=2,\n$$\n$$\nD_{(2,1)}(F)=4,\\quad D_{(2,1)}(B)=1,\\qquad\nD_{(2,2)}(F)=+\\infty,\\quad D_{(2,2)}(B)=0.\n$$\n成对邻域 $\\mathcal{N}$ 包括相邻体素之间的四个无向边：\n$$\n(1,1)\\text{--}(1,2),\\quad (1,1)\\text{--}(2,1),\\quad (1,2)\\text{--}(2,2),\\quad (2,1)\\text{--}(2,2),\n$$\n每条边上的 Potts 惩罚为 $w_{ij}=2$。\n\n计算遵守涂鸦约束的最优分割的最小能量值 $E^{\\star}$。请用一个实数表示最终答案。不需要四舍五入。",
            "solution": "该问题要求在带有 Potts 正则化和硬涂鸦约束的二元马尔可夫随机场 (MRF) 下，推导最优分割能量 $E^{\\star}$，这等价于对于子模成对项，在相关的图割 (GC) 构建中求最小 $s$-$t$ 割容量。我们从最大后验 (MAP) 原理和 MRF 建模假设出发。\n\n基本原理：在放射组学分割中，最大后验 (MAP) 估计器最小化负对数后验概率。在似然项满足条件独立性假设且先验为带有 Potts 模型的马尔可夫随机场 (MRF) 的情况下，需要最小化的能量为\n$$\nE(\\mathbf{L}) \\;=\\; \\sum_{i} D_{i}(L_{i}) \\;+\\; \\sum_{(i,j)\\in\\mathcal{N}} w_{ij}\\,\\big[ L_{i} \\neq L_{j} \\big],\n$$\n其中 $D_{i}(L_{i})$ 是一元数据项，成对的 Potts 惩罚 $w_{ij}$ 通过惩罚标记不连续性来编码边界平滑度。通过将错误标记的一元项设置为 $+\\infty$ 来强制执行涂鸦约束，从而排除不可行的标记方案。\n\n我们现在为给定的 $2\\times 2$ 网格实例化该模型。我们将体素表示为 $A=(1,1)$、$B=(1,2)$、$C=(2,1)$ 和 $D=(2,2)$。涂鸦约束强制 $A$ 为前景 ($F$)，$D$ 为背景 ($B$)。因此，\n$$\nL_{A}=F,\\qquad L_{D}=B.\n$$\n剩下的自由变量是 $L_{B}$ 和 $L_{C}$，每个都可以在 $\\{F,B\\}$ 中取值。邻域集 $\\mathcal{N}$ 由以下四条边组成：\n$$\n(A,B),\\quad (A,C),\\quad (B,D),\\quad (C,D),\n$$\n每条边的 $w_{ij}=2$。\n\n我们对 $(L_{B},L_{C})$ 的所有可行分配计算 $E(\\mathbf{L})$：\n\n1. 情况 $(L_{B},L_{C})=(F,F)$。\n一元项：\n$$\nD_{B}(F)=3,\\quad D_{C}(F)=4,\n$$\n且根据约束有 $D_{A}(F)=0$，$D_{D}(B)=0$。一元项总和：\n$$\nU_{1}=0+3+4+0=7.\n$$\n成对项（Potts 惩罚 $w=2$）：\n- $(A,B)$：$F$ vs $F$ $\\Rightarrow$ 无惩罚，贡献为 $0$。\n- $(A,C)$：$F$ vs $F$ $\\Rightarrow$ $0$。\n- $(B,D)$：$F$ vs $B$ $\\Rightarrow$ 惩罚为 $2$。\n- $(C,D)$：$F$ vs $B$ $\\Rightarrow$ 惩罚为 $2$。\n成对项总和：\n$$\nP_{1}=2+2=4.\n$$\n总能量：\n$$\nE_{1}=U_{1}+P_{1}=7+4=11.\n$$\n\n2. 情况 $(L_{B},L_{C})=(F,B)$。\n一元项：\n$$\nD_{B}(F)=3,\\quad D_{C}(B)=1,\n$$\n一元项总和：\n$$\nU_{2}=0+3+1+0=4.\n$$\n成对项：\n- $(A,B)$：$F$ vs $F$ $\\Rightarrow$ $0$。\n- $(A,C)$：$F$ vs $B$ $\\Rightarrow$ $2$。\n- $(B,D)$：$F$ vs $B$ $\\Rightarrow$ $2$。\n- $(C,D)$：$B$ vs $B$ $\\Rightarrow$ $0$。\n成对项总和：\n$$\nP_{2}=2+2=4.\n$$\n总能量：\n$$\nE_{2}=U_{2}+P_{2}=4+4=8.\n$$\n\n3. 情况 $(L_{B},L_{C})=(B,F)$。\n一元项：\n$$\nD_{B}(B)=2,\\quad D_{C}(F)=4,\n$$\n一元项总和：\n$$\nU_{3}=0+2+4+0=6.\n$$\n成对项：\n- $(A,B)$：$F$ vs $B$ $\\Rightarrow$ $2$。\n- $(A,C)$：$F$ vs $F$ $\\Rightarrow$ $0$。\n- $(B,D)$：$B$ vs $B$ $\\Rightarrow$ $0$。\n- $(C,D)$：$F$ vs $B$ $\\Rightarrow$ $2$。\n成对项总和：\n$$\nP_{3}=2+2=4.\n$$\n总能量：\n$$\nE_{3}=U_{3}+P_{3}=6+4=10.\n$$\n\n4. 情况 $(L_{B},L_{C})=(B,B)$。\n一元项：\n$$\nD_{B}(B)=2,\\quad D_{C}(B)=1,\n$$\n一元项总和：\n$$\nU_{4}=0+2+1+0=3.\n$$\n成对项：\n- $(A,B)$：$F$ vs $B$ $\\Rightarrow$ $2$。\n- $(A,C)$：$F$ vs $B$ $\\Rightarrow$ $2$。\n- $(B,D)$：$B$ vs $B$ $\\Rightarrow$ $0$。\n- $(C,D)$：$B$ vs $B$ $\\Rightarrow$ $0$。\n成对项总和：\n$$\nP_{4}=2+2=4.\n$$\n总能量：\n$$\nE_{4}=U_{4}+P_{4}=3+4=7.\n$$\n\n比较四种可行分配的能量，\n$$\nE_{1}=11,\\quad E_{2}=8,\\quad E_{3}=10,\\quad E_{4}=7,\n$$\n最小值为\n$$\nE^{\\star}=7,\n$$\n由 $(L_{B},L_{C})=(B,B)$ 以及约束标签 $L_{A}=F$，$L_{D}=B$ 实现。这个最优能量等于此带有硬涂鸦的二元 Potts 模型的等效 GC 公式中的最小 $s$-$t$ 割容量。\n\n因此，最优分割的最小能量值为 $7$。",
            "answer": "$$\\boxed{7}$$"
        },
        {
            "introduction": "现代的自动分割模型，特别是基于深度学习的模型，其输出通常是一个概率图，而非最终的二值掩模。一个关键的后续步骤是通过选择一个最佳阈值，将这个概率图转换为最优的分割结果。本练习让你亲身实践这一过程，要求你实现一个高效算法，以找到能够最大化戴斯相似系数（Dice Similarity Coefficient, DSC）的阈值——这是评估分割准确性的黄金标准。",
            "id": "4550608",
            "problem": "给定一个表示自动分割输出的离散概率图和一个表示手动分割的二进制真值掩模。对于一个固定的阈值，通过将每个概率大于或等于该阈值的元素分类为阳性，否则分类为阴性，可以得到一个二进制预测掩模。预测与真值之间的相似性使用 Sørensen–Dice 系数来衡量。从基本原理出发，考虑一个由 $i \\in \\{1,2,\\dots,N\\}$ 索引的数据集的以下定义：\n- 概率图为 $p_i \\in [0,1]$。\n- 真值掩模为 $g_i \\in \\{0,1\\}$。\n- 对于阈值 $t \\in \\mathbb{R}$，定义预测标签 $\\hat{g}_i(t) = 1$（如果 $p_i \\ge t$），否则 $\\hat{g}_i(t) = 0$。\n- 令 $TP(t)$ 表示在阈值 $t$ 时的真阳性数量，即 $TP(t) = \\sum_{i=1}^{N} \\mathbf{1}\\big(\\hat{g}_i(t) = 1 \\wedge g_i = 1\\big)$，其中 $\\mathbf{1}(\\cdot)$ 是指示函数。类似地，令 $FP(t)$ 表示假阳性，$FN(t)$ 表示假阴性。\n- Sørensen–Dice 系数定义为 $D(t) = \\dfrac{2\\,TP(t)}{2\\,TP(t) + FP(t) + FN(t)}$。使用恒等式 $FP(t) = \\sum_{i=1}^{N} \\mathbf{1}\\big(\\hat{g}_i(t) = 1 \\wedge g_i = 0\\big)$，$FN(t) = \\sum_{i=1}^{N} \\mathbf{1}\\big(\\hat{g}_i(t) = 0 \\wedge g_i = 1\\big)$，以及 $\\sum_{i=1}^{N} g_i = |G|$，可推导出 $D(t)$ 等价地表示为 $D(t) = \\dfrac{2\\,TP(t)}{|\\hat{G}(t)| + |G|}$，其中 $|\\hat{G}(t)|$ 是在阈值 $t$ 时预测为阳性的数量，$|G|$ 是真值为阳性的数量。\n- 边界情况约定：如果 $|G| = 0$，则当 $|\\hat{G}(t)| = 0$ 时定义 $D(t) = 1$，当 $|\\hat{G}(t)| > 0$ 时定义 $D(t) = 0$。\n\n你的任务是编写一个完整、可运行的程序，对每个测试用例，计算在定义域 $t \\in [0,1]$ 上使 $D(t)$ 最大化的阈值，并加入一个代表空预测集的额外候选阈值 $t_{\\emptyset} = 1.0 + 10^{-6}$（这确保了对于所有 $p_i \\in [0,1]$ 都有 $p_i  t_{\\emptyset}$）。在所有能达到最大 $D(t)$ 的阈值中，返回 $[0,1]$ 内的最小阈值；当最大化值对应于空预测集时，返回 $t_{\\emptyset}$。你必须通过使用排序和累积计数，来论证避免对密集阈值网格进行朴素扫描的计算优化方法，以实现每个测试用例最多 $\\mathcal{O}(N \\log N)$ 的时间复杂度，其中 $N$ 是元素数量。\n\n你必须实现以下测试套件，每个用例以列表形式提供：\n\n- 用例 1：$p = [0.1, 0.9, 0.8, 0.2, 0.7]$, $g = [0, 1, 1, 0, 0]$。\n- 用例 2：$p = [0.2, 0.3, 0.8, 0.99]$, $g = [0, 0, 0, 0]$。\n- 用例 3：$p = [0.3, 0.3, 0.3, 0.3, 0.3]$, $g = [1, 0, 1, 0, 0]$。\n- 用例 4：$p = [0.6, 0.55, 0.54, 0.1, 0.09]$, $g = [1, 0, 1, 0, 0]$。\n- 用例 5：$p = [1.0, 0.0, 1.0, 0.0]$, $g = [1, 0, 0, 1]$。\n\n程序要求：\n- 程序必须为每个用例计算在指定的平局打破规则下使 $D(t)$ 最大化的阈值。\n- 最终输出必须是包含逗号分隔列表的单行，每个阈值四舍五入到 $6$ 位小数。该列表必须用方括号括起来，例如 $[0.123456,0.500000,1.000001]$。\n- 不允许外部输入；直接在程序内部使用上面定义的测试套件。\n\n优化论证要求：\n- 推导并实现一个算法，该算法仅在由 $p$ 中唯一概率值给出的一组有限候选阈值（按规则 $p_i \\ge t$ 解释）加上极端值 $t=0$ 和 $t = t_{\\emptyset}$ 上评估 $D(t)$；证明这些候选值足以捕捉所有不同的预测掩模，从而捕捉所有不同的 $D(t)$ 值。\n- 与对 $[0,1]$ 上 $M$ 个阈值（其中 $M \\gg N$）进行朴素密集扫描相比，论证其计算复杂度的改进。\n\n你的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表形式的结果（例如，$[result1,result2,result3,result4,result5]$），其中每个 $resultk$ 是用例 $k$ 的阈值，格式为浮点数并四舍五入到 $6$ 位小数。",
            "solution": "该问题要求找到一个阈值 $t$，对于给定的概率图 $p$ 和真值二进制掩模 $g$，该阈值可以使 Sørensen–Dice 系数 $D(t)$ 最大化。需要考虑的阈值域为 $t \\in [0,1]$，并附有一个代表空预测集的特殊候选值 $t_{\\emptyset} = 1.0 + 10^{-6}$。\n\nSørensen–Dice 系数定义为：\n$$\nD(t) = \\frac{2\\,TP(t)}{2\\,TP(t) + FP(t) + FN(t)}\n$$\n其中 $TP(t)$、$FP(t)$ 和 $FN(t)$ 分别是在阈值 $t$ 时的真阳性、假阳性和假阴性的数量。使用恒等式 $2\\,TP(t) + FP(t) + FN(t) = (TP(t)+FP(t)) + (TP(t)+FN(t)) = |\\hat{G}(t)| + |G|$，其中 $|\\hat{G}(t)|$ 是预测为阳性的元素数量，$|G|$ 是真值中阳性元素总数，该系数可以写为：\n$$\nD(t) = \\frac{2\\,TP(t)}{|\\hat{G}(t)| + |G|}\n$$\n对于元素 $i$，其预测标签 $\\hat{g}_i(t) = 1$（如果其概率 $p_i \\ge t$），否则为 $\\hat{g}_i(t) = 0$。\n\n寻找最优阈值的一种朴素方法是在覆盖 $[0,1]$ 的密集网格上评估 $M$ 个阈值的 $D(t)$。对于每个阈值，计算 $TP(t)$ 和 $|\\hat{G}(t)|$ 都需要遍历所有 $N$ 个元素，导致计算复杂度为 $\\mathcal{O}(MN)$。如果为了确保足够的精度而使 $M$ 很大，这种方法的成本会高得令人望而却步。问题要求采用一种更高效的方法，其复杂度最多为 $\\mathcal{O}(N \\log N)$。\n\n### 优化与算法设计\n\n高效算法的关键在于对 $D(t)$ 行为的一个关键观察。预测掩模 $\\hat{G}(t)$，以及随之变化的 $TP(t)$、$|\\hat{G}(t)|$ 和 $D(t)$ 的值，都是关于 $t$ 的分段常数函数。这些函数的值仅在阈值 $t$ 穿过其中一个概率值 $\\{p_i\\}_{i=1}^N$ 时才会改变。\n具体来说，对于任何两个阈值 $t_a$ 和 $t_b$，如果区间 $(t_a, t_b]$ 内不包含任何 $p_i$，那么对于所有 $t \\in (t_a, t_b]$，预测为阳性的集合 $\\hat{G}(t) = \\{i | p_i \\ge t\\}$ 都保持不变。这意味着 $D(t)$ 在这样的区间上是恒定的。\n\n因此，要找到 $D(t)$ 的最大值，只需在一组有限的、可能引起预测掩模变化的候选阈值上对其进行评估即可。这些候选阈值是输入图 $p$ 中存在的唯一概率值。此外，我们必须考虑边界情况：一个将所有元素预测为阳性的阈值（例如 $t=0$）和一个不将任何元素预测为阳性的阈值。问题指定了 $t_{\\emptyset} = 1.0 + 10^{-6}$ 作为空预测的候选值。因此，完整的候选阈值集合是 $\\mathcal{T} = \\text{unique}(\\{p_i\\}) \\cup \\{0, t_{\\emptyset}\\}$。\n\n即使有了这个简化的候选集（最多 $N+2$ 个阈值），为每个候选值天真地重新计算 $D(t)$ 也会需要 $\\mathcal{O}(N)$ 的工作量，如果所有 $p_i$ 都唯一，最坏情况下的复杂度将达到 $\\mathcal{O}(N^2)$。\n\n为了达到期望的 $\\mathcal{O}(N \\log N)$ 复杂度，我们采用了一种扫描线算法。该算法流程如下：\n1.  **排序**：将（概率，真值）对，即 $(p_i, g_i)$，根据概率 $p_i$ 按降序排序。这一步是主要开销，耗时 $\\mathcal{O}(N \\log N)$。\n2.  **初始化**：我们处理边界情况。\n    -   如果真值为空（$|G| = \\sum g_i = 0$），问题定义了对于空预测（$|\\hat{G}(t)|=0$），$D(t)=1$，否则 $D(t)=0$。最大的 $D(t)$ 是 $1$，通过空预测实现。根据问题要求，在这种情况下我们返回 $t_{\\emptyset}$。\n    -   对于 $|G|0$，空预测产生 $TP(t)=0$ 和 $|\\hat{G}(t)|=0$，因此 $D(t)=0$。我们将迄今为止找到的最佳分数初始化为 `best_dice` $= 0$，对应阈值为 `best_thresh` $= t_{\\emptyset}$。\n3.  **扫描与更新**：我们遍历排序后的点列表。这个过程模拟了将阈值 $t$ 从一个大于1的值向下扫描到0。当我们遇到排序列表中的每个点 $(p_j, g_j)$ 时，我们将其添加到预测为阳性的集合中。我们维护真阳性（$TP$）和假阳性（$FP$）的运行计数。\n    -   对于处理的每个点 $(p_i, g_i)$，如果 $g_i=1$ 则增加 $TP$，如果 $g_i=0$ 则增加 $FP$。\n    -   处理完一个点（或一批具有相同概率值的点 $p_i$）后，我们就得到了对应于阈值 $t = p_i$ 的预测集的统计数据。预测为阳性的数量 $|\\hat{G}(p_i)|$ 是迄今为止处理过的点的计数。\n    -   我们计算 $D(p_i) = \\frac{2 \\cdot TP}{|\\hat{G}(p_i)| + |G|}$。\n    -   将这个新的 Dice 分数与迄今为止找到的最佳分数进行比较。如果它更大，我们就更新 `best_dice` 和 `best_thresh` 为当前的分数和阈值（$p_i$）。如果分数相等，我们仅在当前阈值 $p_i$ 更小的情况下更新 `best_thresh`，以满足平局打破规则。\n4.  **最终确定**：循环评估了对应于 $p$ 中每个唯一值的阈值的 Dice 分数。还需要进行最后一次检查。循环完成后 $TP$ 和 $FP$ 的状态对应于所有元素都被预测为阳性。对于任何阈值 $t \\in [0, \\min(p)]$（如果 $\\min(p)0$），都会达到此状态。产生此状态的最小阈值是 $t=0$。因此，我们计算这个“全阳性”状态的 Dice 分数，如果此分数更好，或者分数相等但阈值 $t=0$ 小于当前的 `best_thresh`，则更新我们的最佳结果。\n\n这种扫描线方法在初始排序后对每个点处理一次，在每个不同的概率水平上更新计数和计算 Dice 分数都只需常数时间。因此，总复杂度由排序操作主导，从而得到一个高效的 $\\mathcal{O}(N \\log N)$ 算法，该算法能够根据问题标准正确地确定最优阈值。",
            "answer": "```python\nimport numpy as np\n\ndef find_best_threshold(p_list, g_list):\n    \"\"\"\n    Computes the threshold that maximizes the Sørensen–Dice coefficient.\n    \n    This function implements an O(N log N) sweep-line algorithm.\n    \"\"\"\n    p = np.array(p_list, dtype=float)\n    g = np.array(g_list, dtype=int)\n    \n    t_emptyset = 1.0 + 1e-6\n    \n    total_g = np.sum(g)\n    N = len(p)\n\n    # Edge Case: As per the problem, if the ground truth is empty, the optimal\n    # Dice score is 1, achieved with an empty prediction set. The required\n    # threshold to return is t_emptyset.\n    if total_g == 0:\n        return t_emptyset\n\n    # Combine probabilities and ground truth labels into a structured array\n    # and sort them in descending order based on probability.\n    pg = np.array(list(zip(p, g)), dtype=[('p', float), ('g', int)])\n    pg_sorted = np.sort(pg, order='p')[::-1]\n    \n    # Initialize with the empty prediction case. For t  max(p), the prediction\n    # set is empty, yielding TP=0, |G_hat|=0, and thus Dice=0.\n    # The problem specifies returning t_emptyset for this case if it's optimal.\n    best_dice = 0.0\n    best_thresh = t_emptyset\n    \n    tp = 0\n    fp = 0\n    \n    # Sweep through the sorted probabilities\n    for i in range(N):\n        p_val = pg_sorted['p'][i]\n        g_val = pg_sorted['g'][i]\n        \n        if g_val == 1:\n            tp += 1\n        else:\n            fp += 1\n            \n        # To handle tied probabilities correctly, we only calculate Dice\n        # at the end of a block of points with the same probability.\n        is_last_in_block = (i == N - 1) or (pg_sorted['p'][i+1] != p_val)\n        \n        if is_last_in_block:\n            num_pred_pos = i + 1\n            \n            # Denominator: |G_hat(t)| + |G|. Since total_g  0, this is never zero.\n            dice = (2.0 * tp) / (num_pred_pos + total_g)\n            \n            current_thresh = p_val\n            \n            # Update if we found a better Dice score, or an equal score\n            # with a smaller threshold.\n            if dice  best_dice:\n                best_dice = dice\n                best_thresh = current_thresh\n            elif dice == best_dice:\n                best_thresh = min(best_thresh, current_thresh)\n\n    # After the loop, the counts (tp, fp) are for the \"all positive\" prediction set.\n    # This set is achieved for any threshold t = min(p). The smallest such\n    # threshold is 0. We must check if t=0 gives an optimal or better result.\n    all_pos_dice = (2.0 * tp) / (N + total_g)\n    \n    if all_pos_dice  best_dice:\n        # best_dice = all_pos_dice # not strictly needed, just best_thresh matters\n        best_thresh = 0.0\n    elif all_pos_dice == best_dice:\n        best_thresh = min(best_thresh, 0.0)\n        \n    return best_thresh\n\ndef solve():\n    \"\"\"\n    Main function to run test cases and print results.\n    \"\"\"\n    test_cases = [\n        ([0.1, 0.9, 0.8, 0.2, 0.7], [0, 1, 1, 0, 0]),\n        ([0.2, 0.3, 0.8, 0.99], [0, 0, 0, 0]),\n        ([0.3, 0.3, 0.3, 0.3, 0.3], [1, 0, 1, 0, 0]),\n        ([0.6, 0.55, 0.54, 0.1, 0.09], [1, 0, 1, 0, 0]),\n        ([1.0, 0.0, 1.0, 0.0], [1, 0, 0, 1])\n    ]\n\n    results = []\n    for p, g in test_cases:\n        threshold = find_best_threshold(p, g)\n        results.append(f\"{threshold:.6f}\")\n\n    print(f\"[{','.join(results)}]\")\n\nsolve()\n\n```"
        }
    ]
}