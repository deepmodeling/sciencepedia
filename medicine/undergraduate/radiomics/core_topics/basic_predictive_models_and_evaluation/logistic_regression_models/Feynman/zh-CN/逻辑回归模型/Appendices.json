{
    "hands_on_practices": [
        {
            "introduction": "逻辑回归模型的核心在于它如何将预测变量的线性组合与事件发生的概率联系起来。为了真正掌握并应用一个模型，我们必须能够将其数学输出转化为有意义的、可解释的量，例如患病概率或风险比。本练习将带您深入模型内部，练习从模型的线性预测值（即对数几率）计算出关键的解释指标——几率（odds）和预测概率（predicted probability），并理解如何利用几率比（odds ratio）来解释单个影像组学特征对预测结果的影响。",
            "id": "4974080",
            "problem": "给定一个适用于医疗事件数据的二元结果模型，其中患者的事件指标 $Y \\in \\{0,1\\}$ 在给定预测变量向量 $\\mathbf{x} = (x_1,\\dots,x_k)$ 的条件下的条件概率为 $p(\\mathbf{x}) = \\mathbb{P}(Y=1 \\mid \\mathbf{x})$。假设使用逻辑回归模型，其基本关系定义为事件的对数优势（logit）与预测变量呈线性关系：$$\\log\\left(\\frac{p(\\mathbf{x})}{1 - p(\\mathbf{x})}\\right) = \\beta_0 + \\sum_{j=1}^{k} \\beta_j x_j,$$ 其中 $\\beta_0$ 是截距，$(\\beta_1,\\dots,\\beta_k)$ 是回归系数。请仅从该定义以及优势（odds）是概率与其补数之比的定义出发，推导如何为给定的患者预测变量和指定的系数向量计算拟合优势和预测概率。然后，考虑在保持所有其他预测变量固定的情况下，将单个预测变量 $x_j$ 增加一个单位，并推导由此引起的优势的乘法变化（即优势比），将其表示为 $\\beta_j$ 的函数。\n\n您的任务是实现一个程序，为下面的每个测试用例计算：\n- 在给定的预测变量向量 $\\mathbf{x}$ 和系数下的拟合优势 $O(\\mathbf{x})$，\n- 预测概率 $p(\\mathbf{x})$，\n- 在保持其他预测变量固定的情况下，指定预测变量索引 $j$ 增加一个单位时的优势比。\n\n所有计算输出必须是实数。本问题中没有物理单位。您的程序必须将每个浮点输出四舍五入到恰好六位小数。\n\n测试套件：\n- 案例 1: $\\beta = (-2.0, 0.6, 0.4)$，$\\mathbf{x} = (2.0, 1.5)$，$j = 1$。\n- 案例 2: $\\beta = (1.0, 2.0, -0.5, 0.3)$，$\\mathbf{x} = (3.0, -2.0, 5.0)$，$j = 2$。\n- 案例 3: $\\beta = (0.0, -3.0)$，$\\mathbf{x} = (2.0)$，$j = 1$。\n- 案例 4: $\\beta = (0.0, 0.0, 0.0)$，$\\mathbf{x} = (10.0, -5.0)$，$j = 2$。\n\n解释和索引说明：\n- 对于每个案例，$\\beta_0$ 是截距，其后是与 $\\mathbf{x}$ 的分量按顺序对应的 $(\\beta_1,\\dots,\\beta_k)$。\n- 索引 $j$ 指的是与 $x_j$ 相关的预测变量系数 $\\beta_j$，对预测变量使用基于 1 的索引（不包括截距）。\n\n最终输出格式：\n- 您的程序应生成单行输出，其中包含所有测试用例的结果，格式为由方括号括起来的、以逗号分隔的列表的列表。\n- 对于每个案例，输出一个形式为 $[O(\\mathbf{x}), p(\\mathbf{x}), \\text{OR}_j]$ 的列表，其中 $\\text{OR}_j$ 是 $x_j$ 增加一个单位时的优势比。\n- 每个数字必须四舍五入到恰好六位小数。\n- 格式示例（仅为说明）：$[[a_{11},a_{12},a_{13}],[a_{21},a_{22},a_{23}],\\dots]$，其中每个 $a_{mn}$ 都是一个有六位小数的浮点数。\n\n您的程序必须在没有任何用户输入或外部文件的情况下运行，并且必须仅计算并打印四个指定案例的结果，格式必须与上述完全一致。",
            "solution": "该问题陈述经评估有效。它在科学上基于广义线性模型（特别是逻辑回归）的既定理论。问题定义明确，提供了所有必要的数据和定义，以便为每个测试用例推导出唯一且有意义的解决方案。语言客观而精确。\n\n该任务要求在逻辑回归模型中推导和计算三个关键量：拟合优势、预测概率和优势比。我们从模型的基本定义开始。\n\n逻辑回归模型假定预测变量 $\\mathbf{x} = (x_1, \\dots, x_k)$ 与结果概率 $p(\\mathbf{x}) = \\mathbb{P}(Y=1 \\mid \\mathbf{x})$ 的对数优势之间存在线性关系。该关系表示为：\n$$\n\\log\\left(\\frac{p(\\mathbf{x})}{1 - p(\\mathbf{x})}\\right) = \\beta_0 + \\sum_{j=1}^{k} \\beta_j x_j\n$$\n其中 $\\beta_0$ 是截距，$\\boldsymbol{\\beta} = (\\beta_1, \\dots, \\beta_k)$ 是预测变量系数向量。为方便起见，我们将此方程的右侧定义为线性预测器，通常表示为 $\\eta(\\mathbf{x})$：\n$$\n\\eta(\\mathbf{x}) = \\beta_0 + \\sum_{j=1}^{k} \\beta_j x_j = \\beta_0 + \\boldsymbol{\\beta}^T \\mathbf{x}\n$$\n\n**1. 拟合优势 $O(\\mathbf{x})$ 的推导**\n\n事件的优势定义为事件发生的概率与不发生概率之比。\n$$\nO(\\mathbf{x}) = \\frac{p(\\mathbf{x})}{1 - p(\\mathbf{x})}\n$$\n将此定义代入基本模型方程，我们得到：\n$$\n\\log(O(\\mathbf{x})) = \\eta(\\mathbf{x})\n$$\n为了求解优势 $O(\\mathbf{x})$，我们对该方程两边取指数，利用指数函数是自然对数的反函数这一事实：\n$$\nO(\\mathbf{x}) = \\exp(\\log(O(\\mathbf{x}))) = \\exp(\\eta(\\mathbf{x}))\n$$\n因此，通过对线性预测器取指数来计算拟合优势。\n$$\nO(\\mathbf{x}) = \\exp\\left(\\beta_0 + \\sum_{j=1}^{k} \\beta_j x_j\\right)\n$$\n\n**2. 预测概率 $p(\\mathbf{x})$ 的推导**\n\n为了求出预测概率 $p(\\mathbf{x})$，我们从优势的定义 $O(\\mathbf{x}) = \\frac{p(\\mathbf{x})}{1 - p(\\mathbf{x})}$ 开始，通过代数方法求解 $p(\\mathbf{x})$。\n$$\n\\begin{aligned}\nO(\\mathbf{x}) (1 - p(\\mathbf{x})) &= p(\\mathbf{x}) \\\\\nO(\\mathbf{x}) - O(\\mathbf{x}) p(\\mathbf{x}) &= p(\\mathbf{x}) \\\\\nO(\\mathbf{x}) &= p(\\mathbf{x}) + O(\\mathbf{x}) p(\\mathbf{x}) \\\\\nO(\\mathbf{x}) &= p(\\mathbf{x}) (1 + O(\\mathbf{x})) \\\\\np(\\mathbf{x}) &= \\frac{O(\\mathbf{x})}{1 + O(\\mathbf{x})}\n\\end{aligned}\n$$\n代入我们推导出的 $O(\\mathbf{x}) = \\exp(\\eta(\\mathbf{x}))$ 表达式，我们得到以线性预测器表示的预测概率：\n$$\np(\\mathbf{x}) = \\frac{\\exp(\\eta(\\mathbf{x}))}{1 + \\exp(\\eta(\\mathbf{x}))}\n$$\n这个函数通常被称为逻辑斯谛函数或 sigmoid 函数。通过将分子和分母同除以 $\\exp(\\eta(\\mathbf{x}))$，可以得到一个等价且通常在数值上更稳定的形式：\n$$\np(\\mathbf{x}) = \\frac{1}{\\exp(-\\eta(\\mathbf{x})) + 1}\n$$\n\n**3. 优势比 $\\text{OR}_j$ 的推导**\n\n预测变量 $x_j$ 的优势比（$OR$）是在保持所有其他预测变量不变的情况下，$x_j$ 每增加一个单位，优势变化的因子。设 $\\mathbf{x}$ 为原始预测变量向量 $(x_1, \\dots, x_j, \\dots, x_k)$，设 $\\mathbf{x}'$ 为 $x_j$ 增加一后的向量：$(x_1, \\dots, x_j + 1, \\dots, x_k)$。\n\n在 $\\mathbf{x}$ 处的优势是：\n$$\nO(\\mathbf{x}) = \\exp\\left(\\beta_0 + \\sum_{i=1}^{k} \\beta_i x_i\\right)\n$$\n在 $\\mathbf{x}'$ 处的优势是：\n$$\nO(\\mathbf{x}') = \\exp\\left(\\beta_0 + \\sum_{i \\neq j} \\beta_i x_i + \\beta_j(x_j + 1)\\right) = \\exp\\left(\\beta_0 + \\sum_{i=1}^{k} \\beta_i x_i + \\beta_j\\right)\n$$\n优势比 $\\text{OR}_j$ 是这两个优势的比值：\n$$\n\\text{OR}_j = \\frac{O(\\mathbf{x}')}{O(\\mathbf{x})} = \\frac{\\exp\\left(\\beta_0 + \\sum_{i=1}^{k} \\beta_i x_i + \\beta_j\\right)}{\\exp\\left(\\beta_0 + \\sum_{i=1}^{k} \\beta_i x_i\\right)}\n$$\n利用指数的性质 $\\frac{e^{a+b}}{e^a} = e^b$，我们可以简化表达式：\n$$\n\\text{OR}_j = \\exp\\left(\\left(\\beta_0 + \\sum_{i=1}^{k} \\beta_i x_i + \\beta_j\\right) - \\left(\\beta_0 + \\sum_{i=1}^{k} \\beta_i x_i\\right)\\right) = \\exp(\\beta_j)\n$$\n这是一个关键结果：预测变量 $x_j$ 每增加一个单位的优势比就是其对应系数 $\\beta_j$ 的指数。它是一个常数，不依赖于任何预测变量 $\\mathbf{x}$ 的值。\n\n**计算算法**\n\n对于每个由系数向量 $\\boldsymbol{\\beta}_{\\text{full}} = (\\beta_0, \\beta_1, \\dots, \\beta_k)$、预测变量向量 $\\mathbf{x} = (x_1, \\dots, x_k)$ 和预测变量索引 $j$ 指定的测试用例，算法如下：\n1.  计算线性预测器：$\\eta(\\mathbf{x}) = \\beta_0 + \\sum_{i=1}^{k} \\beta_i x_i$。这可以通过计算预测变量系数 $(\\beta_1, \\dots, \\beta_k)$ 与 $\\mathbf{x}$ 的点积，然后加上截距 $\\beta_0$ 来高效完成。\n2.  计算拟合优势：$O(\\mathbf{x}) = \\exp(\\eta(\\mathbf{x}))$。\n3.  计算预测概率：$p(\\mathbf{x}) = \\frac{O(\\mathbf{x})}{1 + O(\\mathbf{x})}$。\n4.  计算优势比：$\\text{OR}_j = \\exp(\\beta_j)$。问题对 $j$ 使用基于 1 的索引，因此 $\\beta_j$ 指的是 $x_j$ 的系数。在使用基于 0 的索引的数组时，这将是完整系数向量中索引为 $j$ 的元素。\n5.  将三个结果 $O(\\mathbf{x})$、$p(\\mathbf{x})$ 和 $\\text{OR}_j$ 中的每一个都四舍五入到恰好六位小数，作为最终输出。",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Computes fitted odds, predicted probability, and an odds ratio for a logistic\n    regression model across several test cases.\n    \"\"\"\n\n    # Test cases defined as tuples of (beta_vector, x_vector, j_index).\n    # beta_vector is (beta_0, beta_1, ..., beta_k).\n    # x_vector is (x_1, ..., x_k).\n    # j_index is 1-based for the predictor of interest.\n    test_cases = [\n        # Case 1: beta = (-2.0, 0.6, 0.4), x = (2.0, 1.5), j = 1\n        ((-2.0, 0.6, 0.4), (2.0, 1.5), 1),\n        # Case 2: beta = (1.0, 2.0, -0.5, 0.3), x = (3.0, -2.0, 5.0), j = 2\n        ((1.0, 2.0, -0.5, 0.3), (3.0, -2.0, 5.0), 2),\n        # Case 3: beta = (0.0, -3.0), x = (2.0), j = 1\n        ((0.0, -3.0), (2.0,), 1),\n        # Case 4: beta = (0.0, 0.0, 0.0), x = (10.0, -5.0), j = 2\n        ((0.0, 0.0, 0.0), (10.0, -5.0), 2)\n    ]\n\n    all_results = []\n    for case in test_cases:\n        beta_tuple, x_tuple, j = case\n\n        # Convert tuples to numpy arrays for vectorized operations\n        beta = np.array(beta_tuple)\n        x = np.array(x_tuple)\n\n        # Decompose beta into intercept and predictor coefficients\n        beta_0 = beta[0]\n        beta_predictors = beta[1:]\n\n        # 1. Calculate the linear predictor (eta)\n        # eta = beta_0 + sum(beta_i * x_i)\n        eta = beta_0 + np.dot(beta_predictors, x)\n\n        # 2. Calculate the fitted odds\n        # O(x) = exp(eta)\n        odds = np.exp(eta)\n\n        # 3. Calculate the predicted probability\n        # p(x) = O(x) / (1 + O(x))\n        prob = odds / (1 + odds)\n\n        # 4. Calculate the odds ratio for a one-unit increase in x_j\n        # OR_j = exp(beta_j)\n        # The problem uses 1-based indexing for j, which corresponds to\n        # the coefficient beta[j] in our 0-indexed beta array.\n        odds_ratio = np.exp(beta[j])\n\n        # Store the results for this case. The problem requires rounding to\n        # exactly six decimal places, which we achieve using f-string formatting.\n        all_results.append([odds, prob, odds_ratio])\n\n    # Format the final output string as a list of lists of numbers\n    # with each number formatted to exactly six decimal places.\n    formatted_cases = []\n    for result_set in all_results:\n        o, p, or_j = result_set\n        formatted_cases.append(f\"[{o:.6f},{p:.6f},{or_j:.6f}]\")\n\n    print(f\"[{','.join(formatted_cases)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "在影像组学研究中，我们常常会提取大量特征，其中一些特征之间可能存在高度相关性，这种现象被称为“多重共线性”（multicollinearity）。多重共线性会使模型系数的估计变得不稳定，从而影响我们对单个特征重要性的解读。本练习将介绍一个关键的诊断工具——方差膨胀因子（Variance Inflation Factor, VIF），并指导您如何通过计算它来量化特征之间的共线性程度，为构建更稳健、更可信的预测模型提供依据。",
            "id": "4549628",
            "problem": "一个放射组学流程从肺结节的计算机断层扫描图像中提取标准化的定量特征，以训练一个使用带有 logit 连接函数的逻辑回归模型的二元分类器。设三个标准化的预测变量为 $x_1$（灰度共生矩阵 (GLCM) 对比度）、$x_2$（灰度游程矩阵 (GLRLM) 长游程强调）和 $x_3$（邻域灰度差分矩阵 (NGTDM) 粗糙度）。这些特征在 $n=120$ 个训练案例中被标准化为零均值和单位方差，其经验相关矩阵为\n$$\nR \\;=\\;\n\\begin{pmatrix}\n1  & 0.85 & 0.3 \\\\\n0.85 & 1 & 0.25 \\\\\n0.3 & 0.25 & 1\n\\end{pmatrix}.\n$$\n为在模型拟合前评估多重共线性，请仅使用特征相关结构计算每个预测变量的方差膨胀因子（VIF）。将每个 VIF 值四舍五入至四位有效数字。根据常规的 $5$ 的不稳定性阈值，解释是否有任何特征可能因需要提高模型稳定性而被移除。对于最终答案，仅以单行矩阵的形式报告 $(x_1, x_2, x_3)$ 的 VIF 值，并四舍五入至四位有效数字；任何解释性说明必须只出现在您的解题过程中。",
            "solution": "该问题是有效的，因为它具有科学依据、提法明确且客观。它提供了一套完整且一致的数据，用于执行与放射组学领域相关的标准统计计算。\n\n在多重回归模型中，一个预测变量的方差膨胀因子（$VIF$）量化了由于与其他预测变量的多重共线性，其估计系数的方差被放大的程度。对于第 $j$ 个预测变量 $x_j$，其 $VIF_j$ 定义为：\n$$\nVIF_j = \\frac{1}{1 - R_j^2}\n$$\n其中 $R_j^2$ 是将 $x_j$ 对模型中所有其他预测变量进行线性回归得到的决定系数。\n\n当预测变量被标准化（均值为 $0$ 且单位方差）时，可以直接从预测变量的相关矩阵 $R$ 计算 $VIF$。具体来说，第 $j$ 个预测变量的 $VIF$ 值，$VIF_j$，是相关矩阵的逆矩阵 $R^{-1}$ 的第 $j$ 个对角元素。\n$$\nVIF_j = (R^{-1})_{jj}\n$$\n问题提供了三个标准化预测变量 $x_1$、$x_2$ 和 $x_3$ 的相关矩阵：\n$$\nR =\n\\begin{pmatrix}\n1  & 0.85 & 0.3 \\\\\n0.85 & 1 & 0.25 \\\\\n0.3 & 0.25 & 1\n\\end{pmatrix}\n$$\n为了找到 $R^{-1}$ 的对角元素，我们使用涉及伴随矩阵和行列式的矩阵求逆公式：\n$$\nR^{-1} = \\frac{1}{\\det(R)} \\text{adj}(R)\n$$\n其中 $\\text{adj}(R)$ 是 $R$ 的代数余子式矩阵的转置。$R^{-1}$ 的对角元素由下式给出：\n$$\n(R^{-1})_{jj} = \\frac{C_{jj}}{\\det(R)}\n$$\n其中 $C_{jj}$ 是对角元素 $R_{jj}$ 的代数余子式。\n\n首先，我们计算 $R$ 的行列式：\n$$\n\\det(R) = 1 \\begin{vmatrix} 1  & 0.25 \\\\ 0.25 & 1 \\end{vmatrix} - 0.85 \\begin{vmatrix} 0.85 & 0.25 \\\\ 0.3 & 1 \\end{vmatrix} + 0.3 \\begin{vmatrix} 0.85 & 1 \\\\ 0.3 & 0.25 \\end{vmatrix}\n$$\n$$\n\\det(R) = 1(1 \\cdot 1 - 0.25 \\cdot 0.25) - 0.85(0.85 \\cdot 1 - 0.25 \\cdot 0.3) + 0.3(0.85 \\cdot 0.25 - 1 \\cdot 0.3)\n$$\n$$\n\\det(R) = 1(1 - 0.0625) - 0.85(0.85 - 0.075) + 0.3(0.2125 - 0.3)\n$$\n$$\n\\det(R) = 0.9375 - 0.85(0.775) + 0.3(-0.0875)\n$$\n$$\n\\det(R) = 0.9375 - 0.65875 - 0.02625 = 0.2525\n$$\n现在我们计算对角元素的代数余子式。\n对于 $x_1$，所需的代数余子式为 $C_{11}$：\n$$\nC_{11} = (-1)^{1+1} \\begin{vmatrix} 1  & 0.25 \\\\ 0.25 & 1 \\end{vmatrix} = 1 - (0.25)^2 = 1 - 0.0625 = 0.9375\n$$\n$x_1$ 的 $VIF$ 为：\n$$\nVIF_1 = \\frac{C_{11}}{\\det(R)} = \\frac{0.9375}{0.2525} \\approx 3.712871287...\n$$\n对于 $x_2$，所需的代数余子式为 $C_{22}$：\n$$\nC_{22} = (-1)^{2+2} \\begin{vmatrix} 1  & 0.3 \\\\ 0.3 & 1 \\end{vmatrix} = 1 - (0.3)^2 = 1 - 0.09 = 0.91\n$$\n$x_2$ 的 $VIF$ 为：\n$$\nVIF_2 = \\frac{C_{22}}{\\det(R)} = \\frac{0.91}{0.2525} \\approx 3.603960396...\n$$\n对于 $x_3$，所需的代数余子式为 $C_{33}$：\n$$\nC_{33} = (-1)^{3+3} \\begin{vmatrix} 1  & 0.85 \\\\ 0.85 & 1 \\end{vmatrix} = 1 - (0.85)^2 = 1 - 0.7225 = 0.2775\n$$\n$x_3$ 的 $VIF$ 为：\n$$\nVIF_3 = \\frac{C_{33}}{\\det(R)} = \\frac{0.2775}{0.2525} \\approx 1.099009901...\n$$\n按要求将这些值四舍五入至四位有效数字：\n$$\nVIF_1 \\approx 3.713\n$$\n$$\nVIF_2 \\approx 3.604\n$$\n$$\nVIF_3 \\approx 1.099\n$$\n问题指定了一个常规的不稳定性阈值 $VIF > 5$。将我们的结果与此阈值进行比较，我们发现所有三个预测变量的 $VIF$ 值都低于 $5$。\n$$\nVIF_1 = 3.713 < 5\n$$\n$$\nVIF_2 = 3.604 < 5\n$$\n$$\nVIF_3 = 1.099 < 5\n$$\n因此，根据这一特定标准，没有任何特征会因为过度多重共线性而被考虑移除。然而，值得注意的是，预测变量 $x_1$ 和 $x_2$ 显示出中等偏高的 $VIF$ 值，这是它们强相关性（$r=0.85$）的直接结果。虽然没有超过 $5$ 的阈值，但这种程度的共线性仍可能对模型系数的稳定性和可解释性产生影响。预测变量 $x_3$ 与其他两个预测变量显示出非常低的多重共线性，这体现在其 $VIF$ 值非常接近于 $1$。",
            "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n3.713 & 3.604 & 1.099\n\\end{pmatrix}\n}\n$$"
        },
        {
            "introduction": "建立一个预测模型只是第一步，更关键的挑战在于如何公正地评估其在未来新数据上的表现。一个常见的陷阱是“数据泄露”（data leakage），它会导致模型性能被过分高估，使得模型在实际应用中表现不佳。本练习旨在解决这一核心问题，通过引导您设计一个严谨的“嵌套交叉验证”（nested cross-validation）方案，来确保模型的超参数选择和性能评估过程是分开的，从而获得对模型泛化能力无偏的估计。这是构建可靠机器学习模型的黄金标准。",
            "id": "4549456",
            "problem": "一项放射组学研究旨在使用$\\ell_2$正则化的逻辑回归模型对计算机断层扫描（CT）图像上的肺结节进行分类。设数据集包含$N=240$名患者，其中有$N_+=96$个恶性结节和$N_-=144$个良性结节（阳性率约为$40\\%$）。每位患者有$d=120$个定量放射组学特征。逻辑回归通过logistic (sigmoid)函数$\\sigma(z)$来对条件概率$P(y=1\\mid x)$进行建模，其中$\\sigma(z)=\\frac{1}{1+e^{-z}}$，且$z=\\beta_0+x^\\top\\beta$。$\\ell_2$正则化拟合通过添加一个项$\\lambda\\lVert\\beta\\rVert_2^2$来惩罚较大的系数，其中$\\lambda>0$是待选择的正则化强度。\n\n您的任务是设计一个科学合理的嵌套交叉验证（CV）方案，以从候选网格$\\Lambda=\\{10^{-3},10^{-2},10^{-1},1,10\\}$（因此有$M=5$个候选值）中选择超参数$\\lambda$，并使用受试者工作特征曲线下面积（AUROC）来估计泛化性能。该设计必须满足以下所有条件：\n\n- 使用外部$K$折分层交叉验证进行无偏性能估计，其中$K=5$。\n- 在每个外部训练划分内部，使用内部$L$折分层交叉验证进行超参数选择，其中$L=3$。\n- 在每次训练/验证集划分中，仅使用该划分训练部分的统计量$\\mu_j$和$\\sigma_j$对特征进行z-score标准化，即对于特征$j$，变换为$\\tilde{x}_j=(x_j-\\mu_j)/\\sigma_j$，并将相同的变换应用于相应的验证或测试部分；不要在当前训练分区之外的任何数据上计算$\\mu_j$或$\\sigma_j$。\n- 基于在$L$个内折上平均的内折验证AUROC来选择$\\lambda\\in\\Lambda$，并仅在使用选定的$\\lambda$在完整的外部训练数据上重新拟合模型后，在留出的外折测试集上估计性能。\n- 通过在内折和外折中都进行分层，保持大约$40\\%$的阳性率。\n\n哪个选项正确地指定了一个满足所有标准的有效嵌套CV方案，并陈述了该方案下所需的模型拟合总次数？\n\nA. 使用外部$K=5$折分层交叉验证。对每个外折划分，仅在外部训练数据上运行内部$L=3$折分层交叉验证。在每个内部训练折中，使用该内部训练数据拟合z-score标准化，并将其应用于内部验证数据；用每个$\\lambda\\in\\Lambda$训练逻辑回归模型，计算验证AUROC，并在$L$个折上取平均以选择最佳的$\\lambda$。然后，在整个外部训练数据上重新拟合z-score标准化，用选定的$\\lambda$在外部训练数据上重新训练逻辑回归模型，并在留出的外折测试集上评估AUROC。汇总$K$个外折的AUROC。这总共需要 $K\\cdot(L\\cdot M+1)=5\\cdot(3\\cdot 5+1)=5\\cdot 16=80$ 次模型拟合。\n\nB. 使用所有$N=240$名患者的数据一次性计算z-score标准化。使用外部$K=5$折，但对于每个外折划分，通过在外折测试集上评估AUROC来选择$\\lambda$（无内部交叉验证）。在合并的外部训练集和测试集上重新训练模型，并在同一测试集上报告AUROC。这需要 $K\\cdot M=5\\cdot 5=25$ 次模型拟合。\n\nC. 使用单次$K=5$折分层交叉验证。对于每个$\\lambda\\in\\Lambda$，在$K$个训练折中的每一个上进行训练，并在每个对应的测试折上评估AUROC，然后选择使$K$个测试折上的平均AUROC最大化的$\\lambda$。将同一个平均AUROC作为最终性能报告。这需要 $K\\cdot M=5\\cdot 5=25$ 次模型拟合。\n\nD. 使用外部$K=5$折分层交叉验证和内部$L=3$折非分层交叉验证。在内循环中，对于每个$\\lambda\\in\\Lambda$，选择使内部训练损失最小化的$\\lambda$（而不是验证AUROC）。仅将在内部验证折上的平均AUROC作为性能报告；不在完整外部训练折上重新拟合，也不在留出的外折测试集上评估。这需要 $K\\cdot L\\cdot M=5\\cdot 3\\cdot 5=75$ 次模型拟合。\n\n选择唯一一个正确构建了嵌套CV方案并说明了该方案下正确的模型拟合总次数的最佳选项。",
            "solution": "该问题在科学上是合理的、定义明确的且客观的，它描述了一种标准的、最佳实践的机器学习方法论，用于获得模型泛化性能的无偏估计，同时进行超参数调整。\n\n**嵌套交叉验证（Nested Cross-Validation）原理**\n\n嵌套交叉验证的目的是通过将超参数选择过程与最终性能评估过程严格分开，来避免信息泄露，从而获得对模型泛化能力（即在全新数据上的表现）的无偏估计。它包含两个循环：\n\n1.  **外循环 (Outer Loop)**：其唯一目的是评估模型的最终性能。它将整个数据集划分为 $K$ 个折。在每一轮中，一个折被用作外部测试集（完全不接触），另外 $K-1$ 个折被用作外部训练集。这个过程重复 $K$ 次。\n2.  **内循环 (Inner Loop)**：其唯一目的是为外循环的每一轮选择最佳的超参数（本例中为 $\\lambda$）。它只作用于外循环提供的外部训练集。这个外部训练集被进一步划分为 $L$ 个折。对于每个候选超参数 $\\lambda \\in \\Lambda$，模型在 $L-1$ 个内折上进行训练，并在剩余的内折（内部验证集）上进行评估。这个过程重复 $L$ 次，然后对每个 $\\lambda$ 的性能指标（本例中为AUROC）进行平均。平均性能最好的那个 $\\lambda$ 被选为该外循环的最佳超参数。\n\n**关键步骤和要求分析**\n\n- **分层 (Stratification)**：由于存在类别不平衡（$40\\%$ 阳性率），在外循环和内循环中都使用分层抽样至关重要，以确保每个折都保持与原始数据集相似的类别比例。\n- **标准化 (Standardization)**：为防止数据泄露，z-score标准化的参数（均值 $\\mu_j$ 和标准差 $\\sigma_j$）必须*仅*从相应的*训练*数据中计算。在内循环中，这意味着在每个内部训练折上计算参数，并将其应用于内部验证折。在外循环的最终评估阶段，参数从整个外部训练集上计算，并应用于外部测试集。\n- **性能评估**：在内循环选出最佳 $\\lambda$ 后，模型需要使用这个 $\\lambda$ 在*整个外部训练集*上重新训练。然后，这个最终模型的性能才在从未见过的外部测试集上进行评估。最终的泛化性能是 $K$ 个外折测试集上性能的平均值。\n\n**模型拟合次数计算**\n\n- **内循环**：对于外循环的每一轮（共 $K$ 轮），内循环需要测试 $M$ 个超参数。由于内循环本身是 $L$ 折交叉验证，因此对每个超参数都要拟合 $L$ 次模型。所以内循环总共需要 $L \\times M$ 次模型拟合。\n- **外循环**：在内循环为某一外折选定最佳 $\\lambda$ 后，需要额外进行 1 次模型拟合：在整个外部训练集上用这个最佳 $\\lambda$ 重新训练模型。\n- **总次数**：每个外折需要 $(L \\times M) + 1$ 次拟合。由于有 $K$ 个外折，总拟合次数为 $K \\times ((L \\times M) + 1)$。\n- **代入数值**：$K=5$, $L=3$, $M=5$。总拟合次数 = $5 \\times (3 \\times 5 + 1) = 5 \\times (15 + 1) = 5 \\times 16 = 80$。\n\n**选项分析**\n\n- **A**: 此选项准确地描述了上述所有步骤：使用嵌套分层CV，正确的标准化流程以防止数据泄露，正确的超参数选择标准（平均验证AUROC），以及在外折上进行最终性能评估。模型拟合次数的计算也完全正确。**因此，此选项正确。**\n- **B**: 此选项存在两个致命缺陷：1) 在整个数据集上一次性进行标准化，导致测试数据的信息泄露到训练过程中。2) 使用外折测试集来选择超参数 $\\lambda$，这会导致对性能的严重乐观偏倚，因为模型是针对测试集进行优化的。\n- **C**: 此选项描述的是简单的（非嵌套）交叉验证，而不是嵌套交叉验证。它使用测试集来选择最佳 $\\lambda$，然后报告在同一测试集上的平均性能。这同样会导致乐观的、有偏的性能估计，因为它报告的是“最佳”性能，而不是泛化性能。\n- **D**: 此选项有多个错误：1) 内循环不分层，这对于不平衡数据是不合适的。2) 它使用内部训练损失来选择 $\\lambda$，这通常会导致过拟合，而不是选择泛化能力最好的模型。3) 它错误地报告内部验证性能作为最终结果，并且省略了关键的外部测试步骤。4) 模型拟合次数计算错误。\n\n**结论**\n\n选项A是唯一一个正确描述了稳健的嵌套交叉验证方案并正确计算了所需模型拟合总数的选项。",
            "answer": "$$\\boxed{A}$$"
        }
    ]
}