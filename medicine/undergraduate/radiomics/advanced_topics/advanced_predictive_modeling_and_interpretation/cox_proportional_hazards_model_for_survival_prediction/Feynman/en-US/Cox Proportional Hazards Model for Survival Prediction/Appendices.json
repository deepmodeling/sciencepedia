{
    "hands_on_practices": [
        {
            "introduction": "The heart of the Cox proportional hazards model is the partial likelihood, which is constructed by considering which individuals were at risk of an event at the precise moment an event occurred. This exercise provides essential practice in identifying the \"risk set,\" a foundational concept for understanding how the model is estimated. You will learn to apply the precise rules for handling real-world data complexities like staggered study entry (left-truncation) and incomplete follow-up (right-censoring) to determine who is eligible for comparison at different time points .",
            "id": "4534781",
            "problem": "In a radiomics study of non-small-cell lung cancer, a cohort of $3$ patients is modeled using the Cox proportional hazards (PH) model, where the hazard for patient $i$ with radiomic feature vector $\\mathbf{x}_{i}$ is $h(t \\mid \\mathbf{x}_{i}) = h_{0}(t) \\exp(\\boldsymbol{\\beta}^{\\top}\\mathbf{x}_{i})$, with $h_{0}(t)$ the baseline hazard and $\\boldsymbol{\\beta}$ a coefficient vector. Due to staggered entry arising from imaging availability (left-truncation) and incomplete follow-up (right-censoring), each patient $i$ is characterized by an entry time $a_{i}$, an observed end time $y_{i}$, and an event indicator $\\delta_{i} \\in \\{0,1\\}$, where $\\delta_{i} = 1$ indicates an event at time $y_{i}$ and $\\delta_{i} = 0$ indicates right-censoring at time $y_{i}$. The observed times are: patient $1$ with $a_{1} = 0$, $y_{1} = 3$, $\\delta_{1} = 1$; patient $2$ with $a_{2} = 2$, $y_{2} = 5$, $\\delta_{2} = 0$; patient $3$ with $a_{3} = 4$, $y_{3} = 6$, $\\delta_{3} = 1$.\n\nAssume the standard survival analysis convention for right-censoring with left-truncation: at any time $t$, an individual is considered at risk if they have entered the study by time $t$ and have not experienced an event nor been censored prior to time $t$. Using this convention, determine the sizes of the risk sets $|R(3)|$ and $|R(5)|$, where $R(t)$ denotes the set of individuals at risk at time $t$. Report your answer as the ordered pair $\\left(|R(3)|, |R(5)|\\right)$ as exact integers. No rounding is required.",
            "solution": "The user has provided a valid problem statement from the field of survival analysis, a sub-discipline of statistics frequently applied in medical research fields such as radiomics. The problem is well-posed, scientifically grounded, and contains all necessary information to arrive at a unique, verifiable solution.\n\nThe core of this problem is the correct construction of the risk set, $R(t)$, at a given time $t$. The problem provides the standard definition for survival data subject to left-truncation (staggered entry) and right-censoring. An individual $i$ is in the risk set $R(t)$ if and only if they have entered the study at or before time $t$ and are still under observation (i.e., have not yet experienced an event or been censored) at time $t$.\n\nLet the data for patient $i$ be the triplet $(a_{i}, y_{i}, \\delta_{i})$, where $a_{i}$ is the entry time, $y_{i}$ is the time of event or censoring, and $\\delta_{i}$ is the event indicator. Based on the provided definition, patient $i$ is a member of the risk set $R(t)$ if the following two conditions are satisfied:\n1. The patient has entered the study: $a_{i} \\le t$.\n2. The patient has not yet experienced an event or been censored: $y_{i} \\ge t$.\n\nThe interval during which patient $i$ is at risk is thus $[a_{i}, y_{i}]$. We are given data for $3$ patients:\n- Patient $1$: $(a_{1}, y_{1}, \\delta_{1}) = (0, 3, 1)$. This patient is at risk during the time interval $[0, 3]$.\n- Patient $2$: $(a_{2}, y_{2}, \\delta_{2}) = (2, 5, 0)$. This patient is at risk during the time interval $[2, 5]$.\n- Patient $3$: $(a_{3}, y_{3}, \\delta_{3}) = (4, 6, 1)$. This patient is at risk during the time interval $[4, 6]$.\n\nThe problem requires the calculation of the size of the risk set, denoted $|R(t)|$, at two specific time points: $t=3$ and $t=5$.\n\nFirst, let's determine the size of the risk set at $t=3$, which is $|R(3)|$. We check the conditions for each patient:\n- Patient $1$: The risk interval is $[0, 3]$. Since $0 \\le 3$ and $3 \\ge 3$, patient $1$ is in the risk set $R(3)$.\n- Patient $2$: The risk interval is $[2, 5]$. Since $2 \\le 3$ and $5 \\ge 3$, patient $2$ is in the risk set $R(3)$.\n- Patient $3$: The risk interval is $[4, 6]$. Since the entry time is $a_{3}=4$, which is after $t=3$, the condition $a_{3} \\le 3$ is not met. Therefore, patient $3$ is not in the risk set $R(3)$.\nThe set of individuals at risk at $t=3$ is thus $R(3) = \\{1, 2\\}$. The size of this set is $|R(3)| = 2$.\n\nNext, we determine the size of the risk set at $t=5$, which is $|R(5)|$. We again check the conditions for each patient:\n- Patient $1$: The risk interval is $[0, 3]$. The event for this patient occurred at $y_{1}=3$, which is before $t=5$. The condition $y_{1} \\ge 5$ is not met. Therefore, patient $1$ is not in the risk set $R(5)$.\n- Patient $2$: The risk interval is $[2, 5]$. Since $2 \\le 5$ and $5 \\ge 5$, patient $2$ is in the risk set $R(5)$. Note that this patient is censored at time $5$, so they are considered at risk at exactly time $5$, but will not be at risk for any time $t > 5$.\n- Patient $3$: The risk interval is $[4, 6]$. Since $4 \\le 5$ and $6 \\ge 5$, patient $3$ is in the risk set $R(5)$.\nThe set of individuals at risk at $t=5$ is thus $R(5) = \\{2, 3\\}$. The size of this set is $|R(5)| = 2$.\n\nThe problem asks for the ordered pair $(|R(3)|, |R(5)|)$. Based on our calculations, this pair is $(2, 2)$.",
            "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n2 & 2\n\\end{pmatrix}\n}\n$$"
        },
        {
            "introduction": "Fitting a Cox model yields estimates for the log-hazard ratio coefficients, $\\hat{\\boldsymbol{\\beta}}$, but a point estimate alone is incomplete without a measure of its uncertainty. The hazard ratio, $\\exp(\\beta_k)$, is the most common measure of a feature's effect, and understanding its confidence interval is crucial for robust scientific interpretation. This practice  guides you through the standard method for calculating this interval, a vital skill for reading research papers and reporting your own findings, while highlighting common pitfalls to avoid.",
            "id": "4534726",
            "problem": "A radiomics study uses Computed Tomography (CT) features to predict time-to-event outcomes with the Cox Proportional Hazards (PH) model. For a patient with covariate vector $\\mathbf{x}$ and a radiomic texture feature $x_k$, the hazard function is modeled by $h(t \\mid \\mathbf{x}) = h_0(t)\\exp(\\mathbf{x}^\\top \\boldsymbol{\\beta})$, where $h_0(t)$ is the baseline hazard and $\\boldsymbol{\\beta}$ are unknown regression coefficients. The hazard ratio associated with a one-unit increase in the feature $x_k$ is $\\exp(\\beta_k)$. Suppose the model is fit via partial likelihood and the estimator of $\\beta_k$, denoted $\\hat{\\beta}_k$, has an estimated variance $\\widehat{\\mathrm{Var}}(\\hat{\\beta}_k)$ obtained from the inverse observed information. Under standard large-sample regularity, $\\hat{\\beta}_k$ is approximately normal. In a cohort of lung cancer patients, for a texture feature $x_k$, the fit yields $\\hat{\\beta}_k = 0.40$ and $\\widehat{\\mathrm{Var}}(\\hat{\\beta}_k) = 0.0225$. Let $\\alpha = 0.05$. Which option correctly constructs the $100(1-\\alpha)\\%$ Confidence Interval (CI) for the hazard ratio $\\exp(\\beta_k)$ using $\\widehat{\\mathrm{Var}}(\\hat{\\beta}_k)$, and gives its numerical value?\n\nA. $[\\exp(\\hat{\\beta}_k - z_{1-\\alpha/2}\\sqrt{\\widehat{\\mathrm{Var}}(\\hat{\\beta}_k)}),\\ \\exp(\\hat{\\beta}_k + z_{1-\\alpha/2}\\sqrt{\\widehat{\\mathrm{Var}}(\\hat{\\beta}_k)})] = [1.11,\\ 2.00]$.\n\nB. $[\\exp(\\hat{\\beta}_k - z_{1-\\alpha/2}\\widehat{\\mathrm{Var}}(\\hat{\\beta}_k)),\\ \\exp(\\hat{\\beta}_k + z_{1-\\alpha/2}\\widehat{\\mathrm{Var}}(\\hat{\\beta}_k))] = [1.43,\\ 1.56]$.\n\nC. $[\\exp(\\hat{\\beta}_k) - z_{1-\\alpha/2}\\sqrt{\\widehat{\\mathrm{Var}}(\\hat{\\beta}_k)},\\ \\exp(\\hat{\\beta}_k) + z_{1-\\alpha/2}\\sqrt{\\widehat{\\mathrm{Var}}(\\hat{\\beta}_k)}] = [1.20,\\ 1.79]$.\n\nD. $[\\exp(\\hat{\\beta}_k - z_{1-\\alpha}\\sqrt{\\widehat{\\mathrm{Var}}(\\hat{\\beta}_k)}),\\ \\exp(\\hat{\\beta}_k + z_{1-\\alpha}\\sqrt{\\widehat{\\mathrm{Var}}(\\hat{\\beta}_k)})] = [1.17,\\ 1.91]$.",
            "solution": "The problem statement is scientifically and statistically sound. It presents a standard task in survival analysis: constructing a confidence interval for a hazard ratio derived from a Cox proportional hazards model. All necessary information is provided, and the problem is well-posed.\n\nThe goal is to construct a $100(1-\\alpha)\\%$ confidence interval (CI) for the hazard ratio $HR = \\exp(\\beta_k)$.\nThe given data are:\n- The point estimate for the log-hazard coefficient: $\\hat{\\beta}_k = 0.40$.\n- The estimated variance of the estimator: $\\widehat{\\mathrm{Var}}(\\hat{\\beta}_k) = 0.0225$.\n- The significance level: $\\alpha = 0.05$.\n\nThe problem states that the estimator $\\hat{\\beta}_k$ is approximately normally distributed. This is a standard result from the large-sample theory of maximum partial likelihood estimation. Therefore, we first construct a confidence interval for the parameter $\\beta_k$ and then transform it to obtain a CI for $\\exp(\\beta_k)$.\n\nStep 1: Construct the $100(1-\\alpha)\\%$ CI for $\\beta_k$.\nThe general formula for a two-sided CI for a normally distributed estimator is:\n$$ \\text{CI}_{\\beta_k} = \\left[ \\hat{\\beta}_k - z_{1-\\alpha/2} \\cdot \\mathrm{SE}(\\hat{\\beta}_k), \\quad \\hat{\\beta}_k + z_{1-\\alpha/2} \\cdot \\mathrm{SE}(\\hat{\\beta}_k) \\right] $$\nwhere $\\mathrm{SE}(\\hat{\\beta}_k)$ is the standard error of the estimator and $z_{1-\\alpha/2}$ is the upper $1-\\alpha/2$ quantile of the standard normal distribution.\n\nFirst, we calculate the standard error ($\\mathrm{SE}$) from the given variance:\n$$ \\mathrm{SE}(\\hat{\\beta}_k) = \\sqrt{\\widehat{\\mathrm{Var}}(\\hat{\\beta}_k)} = \\sqrt{0.0225} = 0.15 $$\n\nNext, we find the critical value $z_{1-\\alpha/2}$. With $\\alpha = 0.05$, we need the $1 - 0.05/2 = 0.975$ quantile of the standard normal distribution.\n$$ z_{0.975} \\approx 1.96 $$\n\nNow, we can compute the $95\\%$ CI for $\\beta_k$:\n$$ \\text{CI}_{\\beta_k} = [0.40 - 1.96 \\times 0.15, \\quad 0.40 + 1.96 \\times 0.15] $$\n$$ \\text{CI}_{\\beta_k} = [0.40 - 0.294, \\quad 0.40 + 0.294] $$\n$$ \\text{CI}_{\\beta_k} = [0.106, \\quad 0.694] $$\n\nStep 2: Transform the CI for $\\beta_k$ to a CI for the hazard ratio $HR = \\exp(\\beta_k)$.\nThe exponential function $f(x) = \\exp(x)$ is strictly increasing and monotonic. Therefore, we can obtain the CI for $HR$ by applying the function to the endpoints of the CI for $\\beta_k$. This method, known as the transformation method (or log-transformation method in this context), preserves the coverage probability.\nThe general form of the CI for the hazard ratio is:\n$$ \\text{CI}_{\\exp(\\beta_k)} = \\left[ \\exp\\left(\\hat{\\beta}_k - z_{1-\\alpha/2}\\sqrt{\\widehat{\\mathrm{Var}}(\\hat{\\beta}_k)}\\right), \\quad \\exp\\left(\\hat{\\beta}_k + z_{1-\\alpha/2}\\sqrt{\\widehat{\\mathrm{Var}}(\\hat{\\beta}_k)}\\right) \\right] $$\n\nUsing the calculated interval for $\\beta_k$:\n$$ \\text{Lower Bound} = \\exp(0.106) \\approx 1.11183 $$\n$$ \\text{Upper Bound} = \\exp(0.694) \\approx 2.00171 $$\n\nRounding to two decimal places, the $95\\%$ CI for the hazard ratio is $[1.11, 2.00]$.\n\nNow, we evaluate each option:\n\nA. $[\\exp(\\hat{\\beta}_k - z_{1-\\alpha/2}\\sqrt{\\widehat{\\mathrm{Var}}(\\hat{\\beta}_k)}),\\ \\exp(\\hat{\\beta}_k + z_{1-\\alpha/2}\\sqrt{\\widehat{\\mathrm{Var}}(\\hat{\\beta}_k)})] = [1.11,\\ 2.00]$.\nThis option presents the correct formula for constructing the CI for the hazard ratio by first finding the CI on the log-hazard (linear predictor) scale and then exponentiating the endpoints. The numerical calculation, as derived above, is also correct.\nVerdict: **Correct**.\n\nB. $[\\exp(\\hat{\\beta}_k - z_{1-\\alpha/2}\\widehat{\\mathrm{Var}}(\\hat{\\beta}_k)),\\ \\exp(\\hat{\\beta}_k + z_{1-\\alpha/2}\\widehat{\\mathrm{Var}}(\\hat{\\beta}_k))] = [1.43,\\ 1.56]$.\nThis option incorrectly uses the variance, $\\widehat{\\mathrm{Var}}(\\hat{\\beta}_k)$, instead of the standard error, $\\sqrt{\\widehat{\\mathrm{Var}}(\\hat{\\beta}_k)}$, when constructing the interval on the log-hazard scale. The margin of error must have the same units as the estimator, which requires using the standard error. The formula isdimensionally and statistically incorrect.\nVerdict: **Incorrect**.\n\nC. $[\\exp(\\hat{\\beta}_k) - z_{1-\\alpha/2}\\sqrt{\\widehat{\\mathrm{Var}}(\\hat{\\beta}_k)},\\ \\exp(\\hat{\\beta}_k) + z_{1-\\alpha/2}\\sqrt{\\widehat{\\mathrm{Var}}(\\hat{\\beta}_k)}] = [1.20,\\ 1.79]$.\nThis option incorrectly constructs a symmetric CI around the point estimate of the hazard ratio, $\\exp(\\hat{\\beta}_k)$. The estimator $\\exp(\\hat{\\beta}_k)$ follows a log-normal distribution, not a normal distribution. A symmetric confidence interval on this scale is inappropriate and can lead to lower bounds less than $0$. The correct approach is to construct the CI on the scale where normality holds (the $\\beta_k$ scale) and then transform.\nVerdict: **Incorrect**.\n\nD. $[\\exp(\\hat{\\beta}_k - z_{1-\\alpha}\\sqrt{\\widehat{\\mathrm{Var}}(\\hat{\\beta}_k)}),\\ \\exp(\\hat{\\beta}_k + z_{1-\\alpha}\\sqrt{\\widehat{\\mathrm{Var}}(\\hat{\\beta}_k)})] = [1.17,\\ 1.91]$.\nThis option uses an incorrect critical value, $z_{1-\\alpha}$, for a two-sided $100(1-\\alpha)\\%$ CI. A two-sided interval requires splitting the total error probability $\\alpha$ into two tails of size $\\alpha/2$, necessitating the use of the critical value $z_{1-\\alpha/2}$. Using $z_{1-\\alpha}$ (here, $z_{0.95} \\approx 1.645$) would correspond to a $100(1-2\\alpha)\\% = 90\\%$ CI, not a $95\\%$ CI.\nVerdict: **Incorrect**.",
            "answer": "$$\\boxed{A}$$"
        },
        {
            "introduction": "One of the most effective ways to achieve a deep understanding of a statistical model is to learn how to generate data from it. This advanced practice challenges you to build a simulation of the Cox model from first principles, using the technique of inverse transform sampling. By deriving and implementing the algorithm , you will solidify your grasp of the fundamental relationship between the baseline hazard, covariates, the cumulative hazard, and the resulting survival function, providing a truly generative perspective on how the model works.",
            "id": "4534752",
            "problem": "You are given the task of implementing a simulation to generate survival times for patients represented by radiomic features using the Cox Proportional Hazards (PH) model. The Cox Proportional Hazards model specifies that the hazard function conditioned on a covariate vector of radiomic features is proportional to a baseline hazard. You must derive and implement inverse transform sampling for survival time generation based on fundamental definitions of survival and hazard functions.\n\nStart from the following foundational definitions and facts:\n- The hazard function conditioned on covariates is defined as $h(t \\mid \\boldsymbol{x}) = h_0(t)\\exp(\\boldsymbol{x}^{\\top}\\boldsymbol{\\beta})$, where $h_0(t)$ is the baseline hazard function and $\\boldsymbol{x}$ is the covariate vector.\n- The cumulative hazard function is defined as $H(t) = \\int_{0}^{t} h(s)\\,\\mathrm{d}s$ and the survival function is related to the cumulative hazard by $S(t) = \\exp(-H(t))$.\n- Inverse transform sampling requires drawing a uniform random variable $U$ with $U \\sim \\mathrm{Uniform}(0,1)$ and solving $S(T \\mid \\boldsymbol{x}) = U$ for $T$.\n\nYou must:\n- Derive the required inverse mapping using the above base to generate a survival time $T$ in months from a specified baseline cumulative hazard and a linear predictor $\\boldsymbol{x}^{\\top}\\boldsymbol{\\beta}$.\n- Implement the inverse transform algorithm for three scientifically common baseline cumulative hazard families:\n  1. Exponential baseline: $H_0(t) = \\lambda t$ with rate parameter $\\lambda$ in months$^{-1}$.\n  2. Weibull baseline: $H_0(t) = \\left(\\dfrac{t}{\\lambda}\\right)^{\\kappa}$ with scale parameter $\\lambda$ in months and shape parameter $\\kappa$ dimensionless.\n  3. Piecewise-constant baseline hazard with $h_0(t)$ equal to constant rates on consecutive intervals that cover $[0,\\infty)$, producing a piecewise-linear baseline cumulative hazard $H_0(t)$ that is invertible by segment selection.\n\nExpress the final survival times in months. Round each generated survival time to $6$ decimal places. The algorithm must be deterministic by using provided uniform values $U$ for inverse transform sampling (no random generation is needed).\n\nImplement your program to compute survival times for the following test suite of parameter values. Each test case consists of the baseline hazard specification, the covariate vector $\\boldsymbol{x}$, the coefficient vector $\\boldsymbol{\\beta}$, and the uniform variable $U$.\n\nTest Suite:\n- Case $1$ (Exponential baseline):\n  - Baseline parameters: $\\lambda = 0.05$ months$^{-1}$.\n  - Covariates: $\\boldsymbol{x} = [0.5,-0.2,1.0]$.\n  - Coefficients: $\\boldsymbol{\\beta} = [0.3,0.1,-0.4]$.\n  - Uniform: $U = 0.25$.\n- Case $2$ (Weibull baseline):\n  - Baseline parameters: $\\lambda = 12$ months, $\\kappa = 1.5$.\n  - Covariates: $\\boldsymbol{x} = [-1.0,0.0,2.0]$.\n  - Coefficients: $\\boldsymbol{\\beta} = [0.2,-0.5,0.3]$.\n  - Uniform: $U = 0.8$.\n- Case $3$ (Piecewise-constant baseline hazard, first interval result):\n  - Baseline hazard rates and interval endpoints: $h_0(t)=0.02$ for $t \\in [0,6]$ months, $h_0(t)=0.10$ for $t \\in (6,18]$ months, $h_0(t)=0.03$ for $t \\in (18,\\infty)$ months.\n  - Covariates: $\\boldsymbol{x} = [2.0,1.0,-0.5]$.\n  - Coefficients: $\\boldsymbol{\\beta} = [0.05,0.4,0.6]$.\n  - Uniform: $U = 0.999$.\n- Case $4$ (Exponential baseline, large linear predictor edge):\n  - Baseline parameters: $\\lambda = 0.01$ months$^{-1}$.\n  - Covariates: $\\boldsymbol{x} = [10.0,-10.0,5.0]$.\n  - Coefficients: $\\boldsymbol{\\beta} = [0.5,-0.4,0.2]$.\n  - Uniform: $U = 0.5$.\n- Case $5$ (Weibull baseline, very small $U$ edge):\n  - Baseline parameters: $\\lambda = 24$ months, $\\kappa = 2.0$.\n  - Covariates: $\\boldsymbol{x} = [1.5,-0.5,0.2]$.\n  - Coefficients: $\\boldsymbol{\\beta} = [-0.3,0.7,-0.1]$.\n  - Uniform: $U = 10^{-12}$.\n- Case $6$ (Piecewise-constant baseline hazard, later interval result):\n  - Baseline hazard rates and interval endpoints: $h_0(t)=0.02$ for $t \\in [0,6]$ months, $h_0(t)=0.10$ for $t \\in (6,18]$ months, $h_0(t)=0.03$ for $t \\in (18,\\infty)$ months.\n  - Covariates: $\\boldsymbol{x} = [2.0,1.0,-0.5]$.\n  - Coefficients: $\\boldsymbol{\\beta} = [0.05,0.4,0.6]$.\n  - Uniform: $U = 0.01$.\n\nYour program should produce a single line of output containing the survival times for the $6$ cases, in months, each rounded to $6$ decimal places, as a comma-separated list enclosed in square brackets. For example, the output format must be exactly like $[t_1,t_2,t_3,t_4,t_5,t_6]$, where each $t_i$ is a float representing the survival time in months for case $i$.",
            "solution": "The problem requires the derivation and implementation of an algorithm to generate survival times from a Cox Proportional Hazards (PH) model using inverse transform sampling. The solution proceeds by first deriving a general formula for the survival time $T$ and then specializing this formula for three common baseline hazard families: Exponential, Weibull, and Piecewise-constant.\n\n**1. General Derivation of Inverse Transform Sampling for the Cox PH Model**\n\nThe Cox Proportional Hazards model is defined by the hazard function for an individual with a covariate vector $\\boldsymbol{x}$:\n$$h(t \\mid \\boldsymbol{x}) = h_0(t)\\exp(\\boldsymbol{x}^{\\top}\\boldsymbol{\\beta})$$\nwhere $h_0(t)$ is the baseline hazard function, $\\boldsymbol{\\beta}$ is a vector of coefficients, and $\\boldsymbol{x}^{\\top}\\boldsymbol{\\beta}$ is the linear predictor. For notational convenience, let the linear predictor be $\\eta = \\boldsymbol{x}^{\\top}\\boldsymbol{\\beta}$.\n\nThe cumulative hazard function, $H(t \\mid \\boldsymbol{x})$, is the integral of the hazard function from $0$ to $t$:\n$$H(t \\mid \\boldsymbol{x}) = \\int_{0}^{t} h(s \\mid \\boldsymbol{x}) \\, \\mathrm{d}s = \\int_{0}^{t} h_0(s)\\exp(\\eta) \\, \\mathrm{d}s$$\nSince $\\exp(\\eta)$ is constant with respect to the integration variable $s$, we can factor it out:\n$$H(t \\mid \\boldsymbol{x}) = \\exp(\\eta) \\int_{0}^{t} h_0(s) \\, \\mathrm{d}s = \\exp(\\eta) H_0(t)$$\nwhere $H_0(t) = \\int_{0}^{t} h_0(s) \\, \\mathrm{d}s$ is the baseline cumulative hazard function.\n\nThe survival function, $S(t \\mid \\boldsymbol{x})$, gives the probability of surviving beyond time $t$ and is related to the cumulative hazard function as:\n$$S(t \\mid \\boldsymbol{x}) = \\exp(-H(t \\mid \\boldsymbol{x})) = \\exp(-H_0(t)\\exp(\\eta))$$\n\nInverse transform sampling is a method to generate a random sample $T$ from a distribution whose cumulative distribution function is $F(t)$. It works by generating a uniform random number $U \\sim \\mathrm{Uniform}(0,1)$ and solving $F(T)=U$ for $T$. In survival analysis, it is more convenient to work with the survival function $S(t) = 1-F(t)$. If $U \\sim \\mathrm{Uniform}(0,1)$, then $1-U$ is also distributed as $\\mathrm{Uniform}(0,1)$. Thus, we can equivalently solve $S(T)=U$ for $T$.\n\nSetting $S(T \\mid \\boldsymbol{x}) = U$:\n$$U = \\exp(-H_0(T)\\exp(\\eta))$$\nTo solve for $T$, we invert this equation step-by-step:\n\\begin{align*}\n\\ln(U) &= -H_0(T)\\exp(\\eta) \\\\\n-\\ln(U) &= H_0(T)\\exp(\\eta) \\\\\nH_0(T) &= -\\ln(U)\\exp(-\\eta)\n\\end{align*}\nFinally, we apply the inverse of the baseline cumulative hazard function, $H_0^{-1}$, to both sides to isolate $T$:\n$$T = H_0^{-1}(-\\ln(U)\\exp(-\\eta))$$\nThis is the general formula. The specific form of $T$ depends on the choice of the baseline cumulative hazard function $H_0(t)$ and its inverse $H_0^{-1}$. Let's define the quantity $V = -\\ln(U)\\exp(-\\eta)$. The problem reduces to finding $T = H_0^{-1}(V)$.\n\n**2. Derivation for Specific Baseline Hazard Families**\n\n**A. Exponential Baseline Hazard**\nThe exponential baseline gives a constant baseline hazard $h_0(t) = \\lambda$. The baseline cumulative hazard is:\n$$H_0(t) = \\int_{0}^{t} \\lambda \\, \\mathrm{d}s = \\lambda t$$\nTo find the inverse function $H_0^{-1}$, we set $y = H_0(t) = \\lambda t$ and solve for $t$:\n$$t = \\frac{y}{\\lambda} \\implies H_0^{-1}(y) = \\frac{y}{\\lambda}$$\nSubstituting $V$ into this inverse function gives the survival time $T$:\n$$T = H_0^{-1}(V) = \\frac{V}{\\lambda} = \\frac{-\\ln(U)\\exp(-\\eta)}{\\lambda}$$\n\n**B. Weibull Baseline Hazard**\nFor the Weibull distribution, the baseline cumulative hazard is parameterized by a shape $\\kappa$ and scale $\\lambda$:\n$$H_0(t) = \\left(\\frac{t}{\\lambda}\\right)^{\\kappa}$$\nTo find the inverse $H_0^{-1}$, we set $y = (t/\\lambda)^{\\kappa}$ and solve for $t$:\n\\begin{align*}\ny^{1/\\kappa} &= \\frac{t}{\\lambda} \\\\\nt &= \\lambda y^{1/\\kappa} \\implies H_0^{-1}(y) = \\lambda y^{1/\\kappa}\n\\end{align*}\nSubstituting $V$ into this inverse function gives the survival time $T$:\n$$T = H_0^{-1}(V) = \\lambda V^{1/\\kappa} = \\lambda \\left(-\\ln(U)\\exp(-\\eta)\\right)^{1/\\kappa}$$\n\n**C. Piecewise-Constant Baseline Hazard**\nIn this case, the baseline hazard $h_0(t)$ is a step function, constant over a set of disjoint time intervals that partition $[0, \\infty)$. Let the time points defining the intervals be $0 = \\tau_0 < \\tau_1 < \\dots < \\tau_m$, and let the constant hazard in the $i$-th interval $(\\tau_{i-1}, \\tau_i]$ be $c_i$.\n\nThe baseline cumulative hazard $H_0(t)$ is a continuous, piecewise-linear function. For $t$ in the $i$-th interval, i.e., $t \\in (\\tau_{i-1}, \\tau_i]$, $H_0(t)$ is calculated as:\n$$H_0(t) = H_0(\\tau_{i-1}) + c_i(t - \\tau_{i-1})$$\nwhere $H_0(\\tau_{i-1})$ is the cumulative hazard at the end of the previous interval, with $H_0(\\tau_0) = H_0(0) = 0$.\n\nTo find $T = H_0^{-1}(V)$, we must first identify which interval $i$ contains $T$. This is accomplished by comparing the value of $V$ with the pre-calculated values of the cumulative hazard at the interval boundaries, $H_0(\\tau_j)$ for $j=0, 1, \\dots, m-1$. If we find that $H_0(\\tau_{i-1}) < V \\le H_0(\\tau_i)$, then we know $T$ lies in the interval $(\\tau_{i-1}, \\tau_i]$.\n\nWe can then invert the linear equation for that interval to find $T$:\n\\begin{align*}\nV &= H_0(\\tau_{i-1}) + c_i(T - \\tau_{i-1}) \\\\\nV - H_0(\\tau_{i-1}) &= c_i(T - \\tau_{i-1}) \\\\\n\\frac{V - H_0(\\tau_{i-1})}{c_i} &= T - \\tau_{i-1} \\\\\nT &= \\tau_{i-1} + \\frac{V - H_0(\\tau_{i-1})}{c_i}\n\\end{align*}\nThis formula applies for all intervals, including the first, where $\\tau_0=0$ and $H_0(\\tau_0)=0$. For the last interval $(\\tau_{m-1}, \\infty)$, the condition is $V > H_0(\\tau_{m-1})$.",
            "answer": "```python\nimport numpy as np\n\ndef _calculate_exponential_time(params, x, beta, u):\n    \"\"\"\n    Calculates survival time for an exponential baseline hazard.\n    \n    Formula: T = (-log(U) * exp(-eta)) / lambda\n    \"\"\"\n    lambda_param = params['lambda']\n    eta = np.dot(x, beta)\n    \n    # Using np.log and np.exp for numerical stability\n    # `u` is a single scalar value.\n    if u <= 0 or u >= 1:\n        # Handle edge cases for log(u)\n        if u <= 0: return np.inf\n        if u >= 1: return 0.0\n\n    neg_log_u = -np.log(u)\n    exp_neg_eta = np.exp(-eta)\n    \n    time = (neg_log_u * exp_neg_eta) / lambda_param\n    return time\n\ndef _calculate_weibull_time(params, x, beta, u):\n    \"\"\"\n    Calculates survival time for a Weibull baseline hazard.\n    \n    Formula: T = lambda * (-log(U) * exp(-eta))^(1/kappa)\n    \"\"\"\n    lambda_param = params['lambda']\n    kappa_param = params['kappa']\n    eta = np.dot(x, beta)\n    \n    if u <= 0 or u >= 1:\n        if u <= 0: return np.inf\n        if u >= 1: return 0.0\n\n    neg_log_u = -np.log(u)\n    exp_neg_eta = np.exp(-eta)\n    \n    base = neg_log_u * exp_neg_eta\n    time = lambda_param * np.power(base, 1.0 / kappa_param)\n    return time\n\ndef _calculate_piecewise_time(params, x, beta, u):\n    \"\"\"\n    Calculates survival time for a piecewise-constant baseline hazard.\n    \n    Formula: T = tau_{i-1} + (V - H_0(tau_{i-1})) / c_i\n    where V = -log(U) * exp(-eta)\n    \"\"\"\n    rates = params['rates']\n    endpoints = params['endpoints']\n    eta = np.dot(x, beta)\n    \n    if u <= 0 or u >= 1:\n        if u <= 0: return np.inf\n        if u >= 1: return 0.0\n\n    V = -np.log(u) * np.exp(-eta)\n    \n    # Breakpoints for intervals\n    tau_points = [0] + endpoints\n    \n    # Pre-calculate cumulative hazard at each breakpoint\n    H0_at_tau = [0.0]\n    current_H0 = 0.0\n    for i in range(len(rates) - 1): # Iterate through bounded intervals\n        interval_duration = tau_points[i+1] - tau_points[i]\n        current_H0 += rates[i] * interval_duration\n        H0_at_tau.append(current_H0)\n\n    # Find the correct interval and calculate time\n    for i in range(len(H0_at_tau)):\n        H0_prev = H0_at_tau[i]\n        tau_prev = tau_points[i]\n        \n        # Check if V falls into the next interval\n        # The next breakpoint is H0_at_tau[i+1] if it exists\n        if i + 1 < len(H0_at_tau):\n            H0_next = H0_at_tau[i+1]\n            if V <= H0_next:\n                time = tau_prev + (V - H0_prev) / rates[i]\n                return time\n        else:\n            # This is the last, unbounded interval\n            time = tau_prev + (V - H0_prev) / rates[i]\n            return time\n    \n    # Should not be reached with valid inputs\n    return np.nan\n\n\ndef solve():\n    \"\"\"\n    Main function to solve the problem for all test cases.\n    \"\"\"\n    test_cases = [\n        # Case 1 (Exponential baseline)\n        {\n            \"type\": \"exponential\",\n            \"params\": {\"lambda\": 0.05},\n            \"x\": np.array([0.5, -0.2, 1.0]),\n            \"beta\": np.array([0.3, 0.1, -0.4]),\n            \"U\": 0.25,\n        },\n        # Case 2 (Weibull baseline)\n        {\n            \"type\": \"weibull\",\n            \"params\": {\"lambda\": 12, \"kappa\": 1.5},\n            \"x\": np.array([-1.0, 0.0, 2.0]),\n            \"beta\": np.array([0.2, -0.5, 0.3]),\n            \"U\": 0.8,\n        },\n        # Case 3 (Piecewise-constant baseline hazard, first interval result)\n        {\n            \"type\": \"piecewise\",\n            \"params\": {\"rates\": [0.02, 0.10, 0.03], \"endpoints\": [6, 18]},\n            \"x\": np.array([2.0, 1.0, -0.5]),\n            \"beta\": np.array([0.05, 0.4, 0.6]),\n            \"U\": 0.999,\n        },\n        # Case 4 (Exponential baseline, large linear predictor edge)\n        {\n            \"type\": \"exponential\",\n            \"params\": {\"lambda\": 0.01},\n            \"x\": np.array([10.0, -10.0, 5.0]),\n            \"beta\": np.array([0.5, -0.4, 0.2]),\n            \"U\": 0.5,\n        },\n        # Case 5 (Weibull baseline, very small U edge)\n        {\n            \"type\": \"weibull\",\n            \"params\": {\"lambda\": 24, \"kappa\": 2.0},\n            \"x\": np.array([1.5, -0.5, 0.2]),\n            \"beta\": np.array([-0.3, 0.7, -0.1]),\n            \"U\": 1e-12,\n        },\n        # Case 6 (Piecewise-constant baseline hazard, later interval result)\n        {\n            \"type\": \"piecewise\",\n            \"params\": {\"rates\": [0.02, 0.10, 0.03], \"endpoints\": [6, 18]},\n            \"x\": np.array([2.0, 1.0, -0.5]),\n            \"beta\": np.array([0.05, 0.4, 0.6]),\n            \"U\": 0.01,\n        },\n    ]\n\n    results = []\n    \n    # Dispatcher mapping\n    solvers = {\n        \"exponential\": _calculate_exponential_time,\n        \"weibull\": _calculate_weibull_time,\n        \"piecewise\": _calculate_piecewise_time,\n    }\n\n    for case in test_cases:\n        solver_func = solvers[case[\"type\"]]\n        time = solver_func(case[\"params\"], case[\"x\"], case[\"beta\"], case[\"U\"])\n        results.append(round(time, 6))\n\n    # Format the final output string exactly as required.\n    # Using format specifier for consistent 6 decimal places.\n    formatted_results = [f\"{r:.6f}\" for r in results]\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```"
        }
    ]
}