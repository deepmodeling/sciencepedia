{
    "hands_on_practices": [
        {
            "introduction": "在任何稳健性分析中，数据质量保证是至关重要的第一步。该练习将指导您使用基于中位数绝对偏差（Median Absolute Deviation, MAD）的稳健统计方法，来识别和处理重复测量中的异常值，这是确保后续稳定性指标计算准确性的关键预处理步骤 。通过这项实践，您将掌握如何构建一个基础且高效的自动化质量控制流程。",
            "id": "4538489",
            "problem": "你的任务是为影像组学特征的稳健性评估实现一个强大的异常值检测和质量控制程序。设定是，在采集或分割扰动的情况下，对单个影像组学特征进行重复测量，并通过移除异常值并检查剩余测量值的变异性来评估其稳健性。你的程序必须是一个完整的、可运行的程序，对预定义的测试套件执行分析，并以指定格式输出结果。\n\n使用的基本原理：\n- 一组实数 $x_1,\\dots,x_n$ 的中位数是指一个值 $m$，使得至少一半的数据不大于 $m$，且至少一半的数据不小于 $m$。\n- 中位数绝对偏差 (MAD) 定义为 $\\operatorname{MAD} = \\operatorname{median}(|x_i - m|)$，其中 $m$ 是样本的中位数。\n- 对于一个标准差为 $\\sigma$ 的正态分布变量，中位数绝对偏差的期望值与 $\\sigma$ 成正比。比例常数是一个标准正态随机变量绝对值的中位数，该值等于一个正常数，通常近似为 $c \\approx 0.67448975$。这产生了标准正态一致性关系。\n- 样本均值为 $\\bar{x} = \\frac{1}{n} \\sum_{i=1}^{n} x_i$，无偏样本标准差为 $s = \\sqrt{\\frac{1}{n-1}\\sum_{i=1}^{n} (x_i - \\bar{x})^2}$（对于 $n \\ge 2$）。\n- 变异系数 (CV) 定义为 $\\operatorname{CV} = \\frac{s}{|\\bar{x}|}$，它是一个无量纲的量，用于量化相对变异性。\n\n需要实现的算法要求：\n1. 对于每个特征测量向量 $x = [x_1,\\dots,x_n]$，使用一个稳健的Z分数来检测异常值。该Z分数通过使用中位数绝对偏差 (MAD) 和标准正态一致性常数来缩放与中位数的偏差来定义。如果 $\\operatorname{MAD} > 0$，计算稳健Z分数，并将绝对稳健Z分数超过给定阈值 $\\tau_z$ 的测量值 $x_i$ 标记为异常值。\n2. 如果 $\\operatorname{MAD} = 0$，则回退到基于四分位距 (IQR) 的规则：计算第一和第三四分位数 $Q_1$ 和 $Q_3$，以及四分位距 $\\operatorname{IQR} = Q_3 - Q_1$，如果观测值 $x_i$ 满足 $x_i  Q_1 - k \\cdot \\operatorname{IQR}$ 或 $x_i > Q_3 + k \\cdot \\operatorname{IQR}$（其中 $k = 1.5$），则将其标记为异常值。如果 $\\operatorname{IQR} = 0$，该规则简化为标记任何在区间 $[Q_1, Q_3]$ 之外的 $x_i$。\n3. 移除异常值，并计算剩余观测值的比例 $f = \\frac{n_{\\text{remain}}}{n}$。同时，使用无偏样本标准差 $s$ 和样本均值的绝对值 $|\\bar{x}|$ 计算剩余观测值的样本变异系数 $\\operatorname{CV}$。如果 $n_{\\text{remain}}  2$ 或 $|\\bar{x}| = 0$，则为决策目的将 $\\operatorname{CV}$ 视为 $+\\infty$。\n4. 一个特征通过质量控制当且仅当同时满足以下两个条件：$f \\ge p_{\\min}$ 和 $\\operatorname{CV} \\le \\tau_{\\text{cv}}$。\n\n你的程序必须精确实现上述逻辑，并评估以下测试套件，其中每个测试用例是一个元组，包含特征向量 $x$、稳健Z分数阈值 $\\tau_z$、变异系数阈值 $\\tau_{\\text{cv}}$ 以及异常值移除后要求保留的最小比例 $p_{\\min}$。所有数值均为实数，任何小数阈值都应解释为纯小数，而非百分比。\n\n测试套件：\n- 案例 A（典型情况，变异性小，无异常值）：$x = [0.99, 1.02, 1.01, 0.98, 1.00, 1.03, 0.97]$, $\\tau_z = 3.5$, $\\tau_{\\text{cv}} = 0.025$, $p_{\\min} = 0.8$。\n- 案例 B（两个严重异常值，剩余比例足够）：$x = [1.00, 0.99, 1.01, 1.02, 0.98, 3.00, -1.50]$, $\\tau_z = 3.5$, $\\tau_{\\text{cv}} = 0.03$, $p_{\\min} = 0.7$。\n- 案例 C（若干中等偏差，严格的异常值阈值导致剩余比例低）：$x = [1.00, 1.00, 1.00, 2.00, -3.00, 2.20, -2.50]$, $\\tau_z = 1.0$, $\\tau_{\\text{cv}} = 0.10$, $p_{\\min} = 0.8$。\n- 案例 D（中位数绝对偏差为零，存在极端值；回退到四分位距规则）：$x = [5.00, 5.00, 5.00, 5.00, 5.00, 10.00, -10.00]$, $\\tau_z = 3.5$, $\\tau_{\\text{cv}} = 0.001$, $p_{\\min} = 0.7$。\n- 案例 E（均值接近零，导致变异系数无界）：$x = [0.01, -0.01, 0.02, -0.02, 0.00, 0.005, -0.005]$, $\\tau_z = 3.5$, $\\tau_{\\text{cv}} = 1.0$, $p_{\\min} = 1.0$。\n- 案例 F（所有值相同）：$x = [2.50, 2.50, 2.50, 2.50]$, $\\tau_z = 3.5$, $\\tau_{\\text{cv}} = 0.001$, $p_{\\min} = 1.0$。\n\n输出规范：\n- 对每个案例，输出一个布尔值，指示该特征是否根据上述规则通过质量控制。\n- 你的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表的结果，例如 $[{\\tt True},{\\tt False},\\dots]$，每个测试用例一个条目，按所给顺序排列。\n- 此问题不涉及物理单位。",
            "solution": "该问题要求实现一个统计程序，用于评估影像组学特征的稳健性。这是通过从一组重复测量中移除异常值后，量化特征的稳定性来实现的。该过程包括两个主要阶段：稳健的异常值检测和剩余数据点的稳定性分析。一个特征被认为是稳健的，前提是它在异常值移除后，剩余数据的比例和变异系数都满足标准。\n\n对于给定的特征测量向量 $x = [x_1, x_2, \\dots, x_n]$，其分析过程如下：\n\n**1. 异常值检测**\n\n异常值检测采用两级方法，优先使用一种对极端值存在具有弹性的稳健统计方法。\n\n**1.1. 中位数绝对偏差 (MAD) 方法**\n\n识别异常值的主要方法是基于中位数绝对偏差 (MAD)，这是一种稳健的统计离散度度量。首先，计算样本中位数 $m$。\n$$\nm = \\operatorname{median}(x)\n$$\n然后，MAD 计算为与样本中位数绝对偏差的中位数：\n$$\n\\operatorname{MAD} = \\operatorname{median}(|x_i - m|)\n$$\n如果 $\\operatorname{MAD} > 0$，我们可以定义一个稳健Z分数，也称为修正Z分数。该分数使用从 MAD 推导出的标准差的稳健估计来标准化与中位数的偏差。对于正态分布，标准差 $\\sigma$ 可以通过 $\\hat{\\sigma} = \\operatorname{MAD}/c$ 来估计，其中 $c \\approx 0.67448975$ 是一个一致性常数，等于标准正态变量绝对值的中位数。因此，每个测量值 $x_i$ 的稳健Z分数为：\n$$\nz_{\\text{robust}, i} = \\frac{x_i - m}{\\hat{\\sigma}} = \\frac{c \\cdot (x_i - m)}{\\operatorname{MAD}}\n$$\n如果一个测量值 $x_i$ 的绝对稳健Z分数超过预定阈值 $\\tau_z$，则将其标记为异常值：\n$$\n|z_{\\text{robust}, i}| > \\tau_z\n$$\n\n**1.2. 四分位距 (IQR) 回退方法**\n\n在 $\\operatorname{MAD} = 0$ 的情况下（通常发生在超过一半的数据点相同时），稳健Z分数是未定义的。对于这些情况，算法将回退到由 John Tukey 提出的广泛使用的 IQR 方法。首先，计算数据的第一四分位数（$Q_1$，第25百分位数）和第三四分位数（$Q_3$，第75百分位数）。四分位距是它们之间的差：\n$$\n\\operatorname{IQR} = Q_3 - Q_1\n$$\n如果一个测量值 $x_i$ 位于以下定义的范围之外，则被识别为异常值：\n$$\nx_i  Q_1 - k \\cdot \\operatorname{IQR} \\quad \\text{或} \\quad x_i > Q_3 + k \\cdot \\operatorname{IQR}\n$$\n其中问题指定常数 $k=1.5$。如果 $\\operatorname{IQR}=0$，此规则正确地简化为标记任何不等于值 $Q_1=Q_3$ 的点。\n\n**2. 异常值移除后的稳定性分析**\n\n在识别并移除所有异常值后，使用剩余的 $n_{\\text{remain}}$ 个数据点评估特征的稳定性。\n\n**2.1. 剩余观测值比例 ($f$)**\n\n非异常值的数据点比例计算如下：\n$$\nf = \\frac{n_{\\text{remain}}}{n}\n$$\n这个量度量了测量值的一致性。低比例表示存在大量异常值，因此再现性差。\n\n**2.2. 变异系数 (CV)**\n\n剩余数据的相对变异性通过样本变异系数 ($\\operatorname{CV}$) 来量化。首先，计算过滤后数据的样本均值 $\\bar{x}$ 和无偏样本标准差 $s$：\n$$\n\\bar{x} = \\frac{1}{n_{\\text{remain}}} \\sum_{i=1}^{n_{\\text{remain}}} x_{i, \\text{filtered}}\n$$\n$$\ns = \\sqrt{\\frac{1}{n_{\\text{remain}}-1}\\sum_{i=1}^{n_{\\text{remain}}} (x_{i, \\text{filtered}} - \\bar{x})^2}\n$$\n然后 CV 是标准差与均值绝对值的比率：\n$$\n\\operatorname{CV} = \\frac{s}{|\\bar{x}|}\n$$\nCV 的计算定义了特殊条件。如果剩余数据点的数量 $n_{\\text{remain}}  2$，则样本标准差未定义。如果样本均值 $\\bar{x} = 0$，则 CV 在数学上未定义。在这两种情况下，为了决策目的，CV 被功能性地视为无穷大 ($+\\infty$)，代表最大的变异性。\n\n**3. 质量控制决策**\n\n一个特征被认为是稳健的并通过质量控制检查，当且仅当满足以下两个条件：\n1.  剩余观测值的比例不小于最小阈值 $p_{\\min}$：$f \\ge p_{\\min}$。\n2.  剩余观测值的变异系数不超过最大阈值 $\\tau_{\\text{cv}}$：$\\operatorname{CV} \\le \\tau_{\\text{cv}}$。\n\n这个算法框架提供了一个基于既定统计原理的、严谨的、自动化的程序，用于评估特征的稳健性。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to run the test suite for radiomic feature robustness analysis.\n    \"\"\"\n    \n    def evaluate_feature_robustness(x, tau_z, tau_cv, p_min):\n        \"\"\"\n        Performs outlier detection and quality control for a single feature vector.\n\n        Args:\n            x (list): A list of feature measurements.\n            tau_z (float): The threshold for the robust z-score.\n            tau_cv (float): The threshold for the coefficient of variation.\n            p_min (float): The minimum required fraction of remaining observations.\n\n        Returns:\n            bool: True if the feature passes quality control, False otherwise.\n        \"\"\"\n        x_arr = np.array(x, dtype=np.float64)\n        n = len(x_arr)\n\n        if n == 0:\n            # An empty feature vector has no data remaining.\n            # It fails unless p_min is 0, but CV is still infinite.\n            # Assuming it fails.\n            return p_min == 0\n\n        # Constants for outlier detection\n        c = 0.67448975  # Normal distribution consistency constant for MAD\n        k = 1.5         # Multiplier for IQR rule\n\n        # 1. Compute median and Median Absolute Deviation (MAD)\n        m = np.median(x_arr)\n        # Calculate absolute deviations from the median\n        abs_dev = np.abs(x_arr - m)\n        mad = np.median(abs_dev)\n\n        # 2. Detect outliers based on MAD or IQR\n        if mad > 0:\n            # Primary method: Robust z-score using MAD\n            # The robust z-score is c * (x_i - m) / MAD\n            robust_z_scores = c * abs_dev / mad\n            is_outlier = robust_z_scores > tau_z\n        else:\n            # Fallback method: Interquartile Range (IQR) rule\n            q1 = np.percentile(x_arr, 25)\n            q3 = np.percentile(x_arr, 75)\n            iqr = q3 - q1\n            lower_bound = q1 - k * iqr\n            upper_bound = q3 + k * iqr\n            is_outlier = (x_arr  lower_bound) | (x_arr > upper_bound)\n        \n        # 3. Filter data and compute stability metrics\n        x_filtered = x_arr[~is_outlier]\n        n_remain = len(x_filtered)\n\n        # Compute fraction of remaining observations\n        f = n_remain / n if n > 0 else 0\n\n        # Compute Coefficient of Variation (CV)\n        cv = np.inf  # Default to infinity as per problem spec\n        if n_remain >= 2:\n            mean_filtered = np.mean(x_filtered)\n            # Check for mean being close to zero to avoid division by zero\n            if not np.isclose(mean_filtered, 0):\n                std_filtered = np.std(x_filtered, ddof=1) # Unbiased sample std dev\n                cv = std_filtered / np.abs(mean_filtered)\n        \n        # 4. Apply quality control criteria\n        passes_f_check = f >= p_min\n        passes_cv_check = cv = tau_cv\n        \n        return passes_f_check and passes_cv_check\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # Case A (typical, small variability, no outliers)\n        ([0.99, 1.02, 1.01, 0.98, 1.00, 1.03, 0.97], 3.5, 0.025, 0.8),\n        # Case B (two gross outliers, sufficient remaining fraction)\n        ([1.00, 0.99, 1.01, 1.02, 0.98, 3.00, -1.50], 3.5, 0.03, 0.7),\n        # Case C (several moderate deviations, strict outlier threshold)\n        ([1.00, 1.00, 1.00, 2.00, -3.00, 2.20, -2.50], 1.0, 0.10, 0.8),\n        # Case D (zero MAD; fallback to IQR rule)\n        ([5.00, 5.00, 5.00, 5.00, 5.00, 10.00, -10.00], 3.5, 0.001, 0.7),\n        # Case E (mean near zero causing unbounded CV)\n        ([0.01, -0.01, 0.02, -0.02, 0.00, 0.005, -0.005], 3.5, 1.0, 1.0),\n        # Case F (all values identical)\n        ([2.50, 2.50, 2.50, 2.50], 3.5, 0.001, 1.0),\n    ]\n\n    results = []\n    for params in test_cases:\n        x_data, z_thresh, cv_thresh, p_min_thresh = params\n        result = evaluate_feature_robustness(x_data, z_thresh, cv_thresh, p_min_thresh)\n        results.append(result)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "当放射组学数据来自不同扫描设备或医疗机构时，系统性的“批次效应”会严重影响特征的可比性，进而降低模型的泛化能力。本练习将引导您从基本统计原理出发，推导并实施一种常见的特征调和（harmonization）方法，以校正这些批次间差异 。掌握这项技能对于在多中心研究中构建可靠和可推广的预测模型至关重要。",
            "id": "4538487",
            "problem": "构建一个程序，对跨多个采集批次测量的单个放射组学特征执行和谐化和批次效应校正，并评估校正前后的鲁棒性和稳定性。该程序必须从均值和方差的基本统计定义以及加性-乘性批次效应模型入手。假设基础如下：对于批次 $b_i$ 中的受试者 $s_i$，测量得到一个观测到的标量特征值 $x_i$，且批次会引起位置和尺度的偏移。设全局均值为 $\\mu$，全局标准差为 $\\sigma$，批次 $k$ 的批次特定均值和标准差分别表示为 $\\mu_k$ 和 $\\sigma_k$。假设每个批次使用一个仿射变换进行和谐化，其约束条件是使每个批次变换后的分布具有与其他批次相同的全局均值和方差。使用均值和方差的总体定义。为处理批次标准差为零的边界情况，使用一个严格为正的稳定化参数 $\\varepsilon$ 以避免除以零。\n\n您的任务是：\n- 从基本原理以及对均值和方差的约束出发，推导批次仿射变换，该变换将每个 $x_i$ 映射到一个和谐化值 $x_i^{(h)}$，使得对于每个批次 $k$，$\\mathbb{E}[x^{(h)} \\mid b=k] = \\mu$ 且 $\\operatorname{Var}(x^{(h)} \\mid b=k) = \\sigma^2$。使用加性-乘性批次效应模型以及期望和方差的定义来确定变换参数。\n- 使用推导出的仿射形式和稳定化参数 $\\varepsilon = 10^{-8}$ 实现和谐化，方法是在任何出现除以 $\\sigma_k$ 的地方，用 $\\max(\\sigma_k, \\varepsilon)$ 替换除数 $\\sigma_k$。\n- 使用按批次解释的方差比率（通过平方和定义）来量化和谐化前后的批次效应。设总平方和为 $SS_{\\text{tot}} = \\sum_{i=1}^{N} (x_i - \\mu)^2$，批次间平方和为 $SS_{\\text{bet}} = \\sum_{k} n_k (\\mu_k - \\mu)^2$，其中 $n_k$ 是批次 $k$ 中的观测数量。将批次解释的方差分数定义为 $\\eta^2 = SS_{\\text{bet}} / SS_{\\text{tot}}$。如果 $SS_{\\text{tot}} = 0$，则定义 $\\eta^2 = 0$。\n- 使用受试者内平均绝对差异量化受试者内部的稳定性。对于每个受试者标签 $s$，令 $I_s$ 为其重复测量的索引集。将该受试者的平均绝对差异定义为所有无序不同对 $(i,j)$（其中 $i,j \\in I_s$）的 $|x_i - x_j|$ 的平均值。将总体受试者内平均绝对差异定义为各受试者平均绝对差异的平均值。在和谐化前后都计算此值。\n- 定义一个布尔改进标准，当且仅当批次解释的方差分数下降，且受试者内平均绝对差异的增加不超过数值容差时，该标准为真。具体来说，设 $\\tau = 10^{-12}$，并设置 $\\text{improved} = (\\eta^2_{\\text{post}}  \\eta^2_{\\text{pre}}) \\land (D_{\\text{post}} \\le D_{\\text{pre}} + \\tau)$，其中 $D$ 表示受试者内平均绝对差异。\n\n实现该程序以处理以下测试套件。每个测试用例是一个元组 $(x, b, s)$，包含一个观测值列表 $x$，一个等长的批次标签列表 $b$，以及一个等长的受试者标签列表 $s$。每个测试用例的列表如下：\n\n- 测试用例 1（理想路径，两个批次具有明显的位置-尺度效应，每个受试者有两次采集）：\n  - $x = [-1.55, -1.22, -1.02, -0.71, -0.51, 3.52, 4.21, 5.03, 5.70, 6.51]$\n  - $b = [0, 0, 0, 0, 0, 1, 1, 1, 1, 1]$\n  - $s = [0, 1, 2, 3, 4, 0, 1, 2, 3, 4]$\n- 测试用例 2（边界条件，一个批次的方差为零）：\n  - $x = [5.00, 5.00, 5.00, 6.00, 8.00, 10.00]$\n  - $b = [0, 0, 0, 1, 1, 1]$\n  - $s = [0, 1, 2, 0, 1, 2]$\n- 测试用例 3（边缘案例，仅单个批次）：\n  - $x = [1.00, 2.00, 3.00, 1.10, 1.90, 3.05]$\n  - $b = [0, 0, 0, 0, 0, 0]$\n  - $s = [0, 1, 2, 0, 1, 2]$\n- 测试用例 4（异常值压力测试，一个批次中存在强异常值）：\n  - $x = [2.00, 2.50, 3.00, 3.50, 2.20, 2.60, 3.10, 50.00]$\n  - $b = [0, 0, 0, 0, 1, 1, 1, 1]$\n  - $s = [0, 1, 2, 3, 0, 1, 2, 3]$\n\n对于每个测试用例，您的程序必须：\n- 计算和谐化前的批次解释方差分数 $\\eta^2_{\\text{pre}}$。\n- 使用您推导出的、带有稳定化参数 $\\varepsilon = 10^{-8}$ 的仿射变换对 $x$ 进行和谐化，得到 $x^{(h)}$。\n- 计算和谐化后的批次解释方差分数 $\\eta^2_{\\text{post}}$。\n- 计算和谐化前后的受试者内平均绝对差异 $D_{\\text{pre}}$ 和 $D_{\\text{post}}$。\n- 使用 $\\tau = 10^{-12}$ 计算布尔值 $\\text{improved}$。\n\n最终输出格式：\n- 您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表。每个测试用例的结果必须是形式为 $[\\eta^2_{\\text{pre}}, \\eta^2_{\\text{post}}, \\text{improved}, D_{\\text{pre}}, D_{\\text{post}}]$ 的列表。例如，总体输出应类似于 $[[\\text{case1}], [\\text{case2}], [\\text{case3}], [\\text{case4}]]$，其中每个 $\\text{case}i$ 是按指定顺序包含五个量的列表。所有数值均为实数；布尔值为 $\\text{True}$ 或 $\\text{False}$。不涉及单位。",
            "solution": "该问题是有效的，因为它基于科学的统计原理，定义清晰，包含所有必要的定义和数据，并且表述客观。我们将继续进行解答。\n\n### 第一部分：仿射和谐化变换的推导\n\n目标是找到一个批次特定的仿射变换 $x_i^{(h)} = f_k(x_i)$，它将来自批次 $k$ 的观测值 $x_i$ 映射到一个和谐化值 $x_i^{(h)}$。对于每个批次 $k$，该变换必须满足两个约束条件：\n1. 批次 $k$ 中和谐化值的条件期望必须等于原始数据的全局均值 $\\mu$。\n   $$ \\mathbb{E}[x^{(h)} \\mid b=k] = \\mu $$\n2. 批次 $k$ 中和谐化值的条件方差必须等于原始数据的全局方差 $\\sigma^2$。\n   $$ \\operatorname{Var}(x^{(h)} \\mid b=k) = \\sigma^2 $$\n\n设批次 $k$ 的仿射变换形式为：\n$$ x_i^{(h)} = a_k x_i + c_k $$\n其中 $a_k$ 和 $c_k$ 分别是批次 $k$ 的缩放系数和平移系数。\n\n**应用期望约束：**\n\n我们对变换方程取期望，条件是数据来自批次 $k$：\n$$ \\mathbb{E}[x_i^{(h)} \\mid b_i=k] = \\mathbb{E}[a_k x_i + c_k \\mid b_i=k] $$\n利用期望算子的线性性质 $\\mathbb{E}[aX+c] = a\\mathbb{E}[X]+c$：\n$$ \\mathbb{E}[x_i^{(h)} \\mid b_i=k] = a_k \\mathbb{E}[x_i \\mid b_i=k] + c_k $$\n根据定义，批次 $k$ 中 $x_i$ 的条件期望是批次均值，即 $\\mu_k = \\mathbb{E}[x_i \\mid b_i=k]$。代入此定义和约束 $\\mathbb{E}[x^{(h)} \\mid b=k] = \\mu$，我们得到第一个关联 $a_k$ 和 $c_k$ 的方程：\n$$ \\mu = a_k \\mu_k + c_k $$\n由此，我们可以用缩放系数 $a_k$ 表示平移系数 $c_k$：\n$$ c_k = \\mu - a_k \\mu_k \\quad (*)$$\n\n**应用方差约束：**\n\n接下来，我们应用方差约束。我们计算变换的方差，条件是数据来自批次 $k$：\n$$ \\operatorname{Var}(x_i^{(h)} \\mid b_i=k) = \\operatorname{Var}(a_k x_i + c_k \\mid b_i=k) $$\n利用方差的性质 $\\operatorname{Var}(aX+c) = a^2 \\operatorname{Var}(X)$：\n$$ \\operatorname{Var}(x_i^{(h)} \\mid b_i=k) = a_k^2 \\operatorname{Var}(x_i \\mid b_i=k) $$\n根据定义，批次 $k$ 中 $x_i$ 的条件方差是批次方差，即 $\\sigma_k^2 = \\operatorname{Var}(x_i \\mid b_i=k)$。代入此定义和约束 $\\operatorname{Var}(x^{(h)} \\mid b=k) = \\sigma^2$，我们得到第二个方程：\n$$ \\sigma^2 = a_k^2 \\sigma_k^2 $$\n解出缩放系数 $a_k$，并选择正根以保持值的相对顺序，我们得到：\n$$ a_k = \\frac{\\sigma}{\\sigma_k} \\quad (**) $$\n这里假设 $\\sigma_k > 0$。$\\sigma_k=0$ 的情况将由稳定化参数 $\\varepsilon$ 处理。\n\n**变换的最终形式：**\n\n现在我们将 $(**)$ 中 $a_k$ 的表达式代入 $(*)$ 中 $c_k$ 的表达式：\n$$ c_k = \\mu - \\left(\\frac{\\sigma}{\\sigma_k}\\right) \\mu_k $$\n最后，我们将 $a_k$ 和 $c_k$ 的表达式都代入仿射变换方程：\n$$ x_i^{(h)} = \\left(\\frac{\\sigma}{\\sigma_k}\\right) x_i + \\left(\\mu - \\frac{\\sigma \\mu_k}{\\sigma_k}\\right) $$\n该表达式可以重排成一个更直观的形式：\n$$ x_i^{(h)} = \\frac{\\sigma}{\\sigma_k} (x_i - \\mu_k) + \\mu $$\n该变换首先在每个批次内对数据进行标准化（通过减去批次均值 $\\mu_k$ 并除以批次标准差 $\\sigma_k$），使其均值为 $0$、标准差为 $1$。然后，它将结果乘以全局标准差 $\\sigma$ 并加上全局均值 $\\mu$，从而将批次特定的分布映射到目标分布，该目标分布的均值为 $\\mu$，方差为 $\\sigma^2$。\n\n为处理 $\\sigma_k = 0$ 的边界条件，问题指定使用稳定化参数 $\\varepsilon=10^{-8}$。除数 $\\sigma_k$ 被替换为 $\\max(\\sigma_k, \\varepsilon)$。最终的、稳定化的变换为：\n$$ x_i^{(h)} = \\sigma \\left(\\frac{x_i - \\mu_k}{\\max(\\sigma_k, \\varepsilon)}\\right) + \\mu $$\n\n### 第二部分：量化指标的实现\n\n实现所需指标的逻辑直接源于它们的定义。\n\n**批次解释的方差分数 ($\\eta^2$)：**\n计算公式为 $\\eta^2 = SS_{\\text{bet}} / SS_{\\text{tot}}$。\n- 总平方和：$SS_{\\text{tot}} = \\sum_{i=1}^{N} (x_i - \\mu)^2$，其中 $\\mu$ 是全局均值， $N$ 是总样本数。这等价于 $N \\times \\operatorname{Var}_{\\text{pop}}(x)$。\n- 批次间平方和：$SS_{\\text{bet}} = \\sum_{k} n_k (\\mu_k - \\mu)^2$，其中求和遍历所有唯一批次 $k$，$n_k$ 是批次 $k$ 的样本数，$\\mu_k$ 是批次 $k$ 的均值。\n- 对原始数据 $x$ 执行此计算得到 $\\eta^2_{\\text{pre}}$，对和谐化数据 $x^{(h)}$ 执行此计算得到 $\\eta^2_{\\text{post}}$。对于和谐化后的计算，全局和批次特定的均值需要从和谐化数据 $x^{(h)}$ 中重新计算。\n\n**受试者内平均绝对差异 ($D$)：**\n此指标量化了同一受试者测量的稳定性。\n1.  按受试者标签 $s$ 对所有测量值进行分组。\n2.  对于每个至少有两次测量的受试者，找出其测量值的所有唯一对 $(x_i, x_j)$。\n3.  对于每个这样的对，计算绝对差 $|x_i - x_j|$。\n4.  对于每个受试者，计算这些绝对差的平均值。这就是该受试者的平均绝对差异。\n5.  总体指标 $D$ 是这些各受试者平均绝对差异的平均值。\n- 此计算在 $x$（用于 $D_{\\text{pre}}$）和 $x^{(h)}$（用于 $D_{\\text{post}}$）上都执行。\n\n**改进标准：**\n当以下两个条件都满足时，布尔标志 `improved` 设置为 `True`，表示成功减轻了批次效应，且未降低受试者级别测量的一致性：\n1.  批次解释的方差分数下降：$\\eta^2_{\\text{post}}  \\eta^2_{\\text{pre}}$。\n2.  受试者内平均绝对差异的增加不超过一个小的数值容差 $\\tau = 10^{-12}$：$D_{\\text{post}} \\le D_{\\text{pre}} + \\tau$。\n\n实现将把这些推导和定义应用于提供的每个测试用例。",
            "answer": "```python\nimport numpy as np\nfrom itertools import combinations\n\ndef solve():\n    \"\"\"\n    Main function to process all test cases and print the final results.\n    \"\"\"\n    test_cases = [\n        # Test Case 1: Happy path\n        (\n            [-1.55, -1.22, -1.02, -0.71, -0.51, 3.52, 4.21, 5.03, 5.70, 6.51],\n            [0, 0, 0, 0, 0, 1, 1, 1, 1, 1],\n            [0, 1, 2, 3, 4, 0, 1, 2, 3, 4]\n        ),\n        # Test Case 2: Boundary condition (zero variance batch)\n        (\n            [5.00, 5.00, 5.00, 6.00, 8.00, 10.00],\n            [0, 0, 0, 1, 1, 1],\n            [0, 1, 2, 0, 1, 2]\n        ),\n        # Test Case 3: Edge case (single batch)\n        (\n            [1.00, 2.00, 3.00, 1.10, 1.90, 3.05],\n            [0, 0, 0, 0, 0, 0],\n            [0, 1, 2, 0, 1, 2]\n        ),\n        # Test Case 4: Outlier stress test\n        (\n            [2.00, 2.50, 3.00, 3.50, 2.20, 2.60, 3.10, 50.00],\n            [0, 0, 0, 0, 1, 1, 1, 1],\n            [0, 1, 2, 3, 0, 1, 2, 3]\n        ),\n    ]\n\n    all_results = [process_case(x, b, s) for x, b, s in test_cases]\n    \n    # Format the final output string\n    def format_result(res):\n        eta2_pre, eta2_post, improved, d_pre, d_post = res\n        return f\"[{eta2_pre},{eta2_post},{improved},{d_pre},{d_post}]\"\n\n    output_str = \"[\" + \",\".join([format_result(res) for res in all_results]) + \"]\"\n    print(output_str)\n\n\ndef process_case(x_list, b_list, s_list):\n    \"\"\"\n    Performs harmonization and computes all required metrics for a single test case.\n    \"\"\"\n    x = np.array(x_list, dtype=np.float64)\n    b = np.array(b_list)\n    s = np.array(s_list)\n    epsilon = 1e-8\n    tau = 1e-12\n\n    # --- Metric Calculation Helper Functions ---\n\n    def calculate_eta_sq(values, batches):\n        \"\"\"Computes the fraction of variance explained by batch (eta-squared).\"\"\"\n        if values.size == 0:\n            return 0.0\n        \n        mu_global = np.mean(values)\n        ss_tot = np.sum((values - mu_global)**2)\n        \n        if ss_tot == 0:\n            return 0.0\n        \n        ss_bet = 0.0\n        unique_batches = np.unique(batches)\n        for k in unique_batches:\n            batch_values = values[batches == k]\n            n_k = batch_values.size\n            mu_k = np.mean(batch_values)\n            ss_bet += n_k * (mu_k - mu_global)**2\n            \n        return ss_bet / ss_tot\n\n    def calculate_within_subject_diff(values, subjects):\n        \"\"\"Computes the mean absolute within-subject difference.\"\"\"\n        subject_data = {}\n        for i, sid in enumerate(subjects):\n            if sid not in subject_data:\n                subject_data[sid] = []\n            subject_data[sid].append(values[i])\n        \n        subject_mean_diffs = []\n        for sid, s_values in subject_data.items():\n            if len(s_values)  2:\n                continue\n            \n            pair_diffs = [abs(p[0] - p[1]) for p in combinations(s_values, 2)]\n            if pair_diffs:\n                subject_mean_diffs.append(np.mean(pair_diffs))\n        \n        if not subject_mean_diffs:\n            return 0.0\n        \n        return np.mean(subject_mean_diffs)\n    \n    # --- Pre-Harmonization Analysis ---\n    \n    eta2_pre = calculate_eta_sq(x, b)\n    d_pre = calculate_within_subject_diff(x, s)\n\n    # --- Harmonization ---\n\n    x_h = np.copy(x)\n    unique_batches = np.unique(b)\n\n    if len(unique_batches) > 1:\n        mu_global_orig = np.mean(x)\n        sigma_global_orig = np.std(x) # ddof=0 for population std dev\n\n        for k in unique_batches:\n            batch_mask = (b == k)\n            x_k = x[batch_mask]\n            \n            mu_k = np.mean(x_k)\n            sigma_k = np.std(x_k)\n            \n            # The derived transformation with stabilization\n            divisor = max(sigma_k, epsilon)\n            x_h[batch_mask] = sigma_global_orig * (x_k - mu_k) / divisor + mu_global_orig\n    # If only one batch, x_h remains a copy of x, as harmonization is an identity op.\n\n    # --- Post-Harmonization Analysis ---\n    \n    eta2_post = calculate_eta_sq(x_h, b)\n    d_post = calculate_within_subject_diff(x_h, s)\n    \n    # --- Improvement Criterion ---\n    \n    improved = (eta2_post  eta2_pre) and (d_post = d_pre + tau)\n    \n    return [eta2_pre, eta2_post, improved, d_pre, d_post]\n\nif __name__ == '__main__':\n    solve()\n```"
        },
        {
            "introduction": "特征层面的不稳定性最终会如何影响临床预测模型的可靠性？本练习通过一个具体的逻辑回归模型，运用泰勒展开的数学原理，来量化测量误差如何传播并最终导致模型预测概率的不确定性 。这个计算实践深刻地揭示了为何特征的稳健性与稳定性是构建可信赖放射组学模型的根本前提。",
            "id": "4538483",
            "problem": "一个放射组学实验室使用从感兴趣区域（ROI）中提取的三个标准化影像特征，构建了一个恶性肿瘤二元分类器，其中ROI代表感兴趣区域（Region of Interest）。该分类器是一个逻辑斯蒂预测模型，其线性预测器 $\\eta$ 和预测概率 $p$ 定义为 $\\eta = \\beta_{0} + \\beta_{1} x_{1} + \\beta_{2} x_{2} + \\beta_{3} x_{3}$ 和 $p = \\frac{1}{1 + \\exp(-\\eta)}$。对于某位特定患者，真实的标准化特征值为 $x_{1} = 0.5$、$x_{2} = -1.0$ 和 $x_{3} = 0.8$。学习到的系数为 $\\beta_{0} = -1.2$、$\\beta_{1} = 0.8$、$\\beta_{2} = -0.5$ 和 $\\beta_{3} = 0.3$。\n\n由于不同评估者之间存在分割变异性，每个测量特征 $x_{i}^{\\text{meas}}$ 与其真实值 $x_{i}$ 之间存在一个加性测量误差 $e_{i}$，因此 $x_{i}^{\\text{meas}} = x_{i} + e_{i}$。误差向量 $\\mathbf{e} = (e_{1}, e_{2}, e_{3})^{\\top}$ 被建模为一个零均值随机向量，其协方差矩阵为\n$$\n\\Sigma_{e} = \\begin{pmatrix}\n0.04   0.012   -0.002 \\\\\n0.012  0.09    0.006 \\\\\n-0.002 0.006   0.01\n\\end{pmatrix}.\n$$\n\n从逻辑斯蒂模型的定义出发，围绕真实特征向量使用一阶泰勒展开，并结合随机向量的期望、方差和协方差的性质，推导预测概率平方变化期望值的主阶近似，即\n$$\n\\mathbb{E}\\!\\left[\\left(p\\!\\left(\\mathbf{x} + \\mathbf{e}\\right) - p\\!\\left(\\mathbf{x}\\right)\\right)^{2}\\right],\n$$\n并计算给定患者的该值。计算给定参数下的数值。请以小数形式表示最终答案，并四舍五入到四位有效数字。无需单位。",
            "solution": "问题要求计算由于特征 $\\mathbf{x}$ 中的测量误差 $\\mathbf{e}$ 导致的预测概率平方变化的期望值 $\\mathbb{E}\\!\\left[\\left(p(\\mathbf{x} + \\mathbf{e}) - p(\\mathbf{x})\\right)^{2}\\right]$ 的主阶近似。分析过程是对函数 $p(\\mathbf{y})$ 在真实特征向量 $\\mathbf{x}$ 周围应用一阶泰勒展开。\n\n设 $p(\\mathbf{y})$ 为输入特征向量 $\\mathbf{y} = (y_1, y_2, y_3)^\\top$ 的预测概率。测量的特征向量为 $\\mathbf{x}^{\\text{meas}} = \\mathbf{x} + \\mathbf{e}$，其中 $\\mathbf{x}$ 是真实特征向量，$\\mathbf{e}$ 是随机误差向量。\n\n$p(\\mathbf{x} + \\mathbf{e})$ 关于 $\\mathbf{x}$ 的一阶泰勒展开式为：\n$$\np(\\mathbf{x} + \\mathbf{e}) \\approx p(\\mathbf{x}) + \\nabla p(\\mathbf{x})^\\top \\mathbf{e}\n$$\n其中 $\\nabla p(\\mathbf{x})$ 是函数 $p$ 在点 $\\mathbf{x}$ 处求得的梯度。\n\n预测概率的变化量，我们记为 $\\Delta p$，可以近似为：\n$$\n\\Delta p = p(\\mathbf{x} + \\mathbf{e}) - p(\\mathbf{x}) \\approx \\nabla p(\\mathbf{x})^\\top \\mathbf{e}\n$$\n需要计算的量是这个变化量平方的期望值：\n$$\n\\mathbb{E}[(\\Delta p)^2] \\approx \\mathbb{E}\\left[\\left(\\nabla p(\\mathbf{x})^\\top \\mathbf{e}\\right)^2\\right]\n$$\n真实特征向量 $\\mathbf{x}$ 是一个固定的非随机量。因此，梯度 $\\nabla p(\\mathbf{x})$ 是一个常数向量。我们将此常数向量记为 $\\mathbf{g} = \\nabla p(\\mathbf{x})$。表达式变为：\n$$\n\\mathbb{E}[(\\Delta p)^2] \\approx \\mathbb{E}\\left[(\\mathbf{g}^\\top \\mathbf{e})^2\\right]\n$$\n项 $\\mathbf{g}^\\top \\mathbf{e}$ 是一个标量随机变量。设 $S = \\mathbf{g}^\\top \\mathbf{e}$。我们感兴趣的是 $\\mathbb{E}[S^2]$。我们知道，对于任何随机变量 $S$，其方差由 $\\text{Var}(S) = \\mathbb{E}[S^2] - (\\mathbb{E}[S])^2$ 给出。\n\n我们来计算 $S$ 的期望值：\n$$\n\\mathbb{E}[S] = \\mathbb{E}[\\mathbf{g}^\\top \\mathbf{e}] = \\mathbf{g}^\\top \\mathbb{E}[\\mathbf{e}]\n$$\n问题指出误差向量 $\\mathbf{e}$ 是一个零均值随机向量，所以 $\\mathbb{E}[\\mathbf{e}] = \\mathbf{0}$。因此，\n$$\n\\mathbb{E}[S] = \\mathbf{g}^\\top \\mathbf{0} = 0\n$$\n由此可知 $\\mathbb{E}[S^2] = \\text{Var}(S)$。线性组合 $S = \\mathbf{g}^\\top \\mathbf{e}$ 的方差由以下二次型给出：\n$$\n\\text{Var}(S) = \\mathbf{g}^\\top \\text{Cov}(\\mathbf{e}) \\mathbf{g} = \\mathbf{g}^\\top \\Sigma_e \\mathbf{g}\n$$\n其中 $\\Sigma_e$ 是误差向量 $\\mathbf{e}$ 的协方差矩阵。\n所以，主阶近似为：\n$$\n\\mathbb{E}[(\\Delta p)^2] \\approx (\\nabla p(\\mathbf{x}))^\\top \\Sigma_e (\\nabla p(\\mathbf{x}))\n$$\n接下来，我们必须求梯度向量 $\\mathbf{g} = \\nabla p(\\mathbf{x})$。预测概率 $p$ 是通过逻辑斯蒂（sigmoid）函数 $p = (1 + \\exp(-\\eta))^{-1}$ 与线性预测器 $\\eta$ 相关联的函数。线性预测器为 $\\eta = \\beta_0 + \\sum_{i=1}^3 \\beta_i x_i$。\n\n使用链式法则，$p$ 对特征 $x_i$ 的偏导数为：\n$$\n\\frac{\\partial p}{\\partial x_i} = \\frac{d p}{d \\eta} \\frac{\\partial \\eta}{\\partial x_i}\n$$\n导数为：\n$$\n\\frac{\\partial \\eta}{\\partial x_i} = \\beta_i\n$$\n$$\n\\frac{d p}{d \\eta} = \\frac{d}{d\\eta} (1 + \\exp(-\\eta))^{-1} = -1(1 + \\exp(-\\eta))^{-2}(-\\exp(-\\eta)) = \\frac{\\exp(-\\eta)}{(1 + \\exp(-\\eta))^2}\n$$\n逻辑斯蒂函数的一个著名性质是其导数可以表示为 $p(1-p)$。证明如下：\n$$\n\\frac{d p}{d \\eta} = \\left(\\frac{1}{1 + \\exp(-\\eta)}\\right) \\left(\\frac{\\exp(-\\eta)}{1 + \\exp(-\\eta)}\\right) = p \\left(\\frac{1 + \\exp(-\\eta) - 1}{1 + \\exp(-\\eta)}\\right) = p \\left(1 - \\frac{1}{1 + \\exp(-\\eta)}\\right) = p(1-p)\n$$\n因此，偏导数为：\n$$\n\\frac{\\partial p}{\\partial x_i} = p(\\mathbf{x})(1-p(\\mathbf{x}))\\beta_i\n$$\n所以，梯度向量 $\\nabla p(\\mathbf{x})$ 为：\n$$\n\\nabla p(\\mathbf{x}) = p(\\mathbf{x})(1-p(\\mathbf{x})) \\begin{pmatrix} \\beta_1 \\\\ \\beta_2 \\\\ \\beta_3 \\end{pmatrix} = p(\\mathbf{x})(1-p(\\mathbf{x})) \\boldsymbol{\\beta}\n$$\n其中 $\\boldsymbol{\\beta} = (\\beta_1, \\beta_2, \\beta_3)^\\top$。\n\n将此梯度代回我们的近似公式中：\n$$\n\\mathbb{E}[(\\Delta p)^2] \\approx \\left( p(\\mathbf{x})(1-p(\\mathbf{x})) \\boldsymbol{\\beta} \\right)^\\top \\Sigma_e \\left( p(\\mathbf{x})(1-p(\\mathbf{x})) \\boldsymbol{\\beta} \\right)\n= \\left( p(\\mathbf{x})(1-p(\\mathbf{x})) \\right)^2 \\boldsymbol{\\beta}^\\top \\Sigma_e \\boldsymbol{\\beta}\n$$\n现在，我们使用提供的数据计算数值。\n给定数据如下：\n$\\mathbf{x} = (0.5, -1.0, 0.8)^\\top$\n$\\beta_0 = -1.2$，$\\beta_1 = 0.8$，$\\beta_2 = -0.5$，$\\beta_3 = 0.3$，所以 $\\boldsymbol{\\beta} = (0.8, -0.5, 0.3)^\\top$。\n$$\n\\Sigma_{e} = \\begin{pmatrix}\n0.04   0.012   -0.002 \\\\\n0.012  0.09    0.006 \\\\\n-0.002 0.006   0.01\n\\end{pmatrix}\n$$\n首先，在真实特征向量 $\\mathbf{x}$ 处计算 $\\eta$ 和 $p$：\n$$\n\\eta(\\mathbf{x}) = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + \\beta_3 x_3 = -1.2 + (0.8)(0.5) + (-0.5)(-1.0) + (0.3)(0.8)\n$$\n$$\n\\eta(\\mathbf{x}) = -1.2 + 0.4 + 0.5 + 0.24 = -1.2 + 1.14 = -0.06\n$$\n$$\np(\\mathbf{x}) = \\frac{1}{1 + \\exp(-\\eta)} = \\frac{1}{1 + \\exp(-(-0.06))} = \\frac{1}{1 + \\exp(0.06)}\n$$\n使用计算器，$\\exp(0.06) \\approx 1.0618365$。\n$$\np(\\mathbf{x}) \\approx \\frac{1}{1 + 1.0618365} = \\frac{1}{2.0618365} \\approx 0.48500287\n$$\n接下来，我们计算标量因子 $(p(1-p))^2$：\n$$\np(\\mathbf{x})(1-p(\\mathbf{x})) \\approx 0.48500287 \\times (1 - 0.48500287) = 0.48500287 \\times 0.51499713 \\approx 0.2497753\n$$\n$$\n\\left( p(\\mathbf{x})(1-p(\\mathbf{x})) \\right)^2 \\approx (0.2497753)^2 \\approx 0.0623877\n$$\n接下来，我们计算二次型 $\\boldsymbol{\\beta}^\\top \\Sigma_e \\boldsymbol{\\beta}$：\n首先，计算 $\\Sigma_e \\boldsymbol{\\beta}$：\n$$\n\\begin{pmatrix}\n0.04   0.012   -0.002 \\\\\n0.012  0.09    0.006 \\\\\n-0.002 0.006   0.01\n\\end{pmatrix}\n\\begin{pmatrix}\n0.8 \\\\\n-0.5 \\\\\n0.3\n\\end{pmatrix}\n=\n\\begin{pmatrix}\n(0.04)(0.8) + (0.012)(-0.5) + (-0.002)(0.3) \\\\\n(0.012)(0.8) + (0.09)(-0.5) + (0.006)(0.3) \\\\\n(-0.002)(0.8) + (0.006)(-0.5) + (0.01)(0.3)\n\\end{pmatrix}\n=\n\\begin{pmatrix}\n0.032 - 0.006 - 0.0006 \\\\\n0.0096 - 0.045 + 0.0018 \\\\\n-0.0016 - 0.003 + 0.003\n\\end{pmatrix}\n=\n\\begin{pmatrix}\n0.0254 \\\\\n-0.0336 \\\\\n-0.0016\n\\end{pmatrix}\n$$\n然后，计算 $\\boldsymbol{\\beta}^\\top (\\Sigma_e \\boldsymbol{\\beta})$：\n$$\n\\begin{pmatrix} 0.8  -0.5  0.3 \\end{pmatrix}\n\\begin{pmatrix}\n0.0254 \\\\\n-0.0336 \\\\\n-0.0016\n\\end{pmatrix}\n= (0.8)(0.0254) + (-0.5)(-0.0336) + (0.3)(-0.0016)\n$$\n$$\n= 0.02032 + 0.0168 - 0.00048 = 0.03712 - 0.00048 = 0.03664\n$$\n最后，我们将两部分相乘得到结果：\n$$\n\\mathbb{E}[(\\Delta p)^2] \\approx (0.0623877) \\times (0.03664) \\approx 0.00228585\n$$\n将结果四舍五入到四位有效数字，得到 $0.002286$。",
            "answer": "$$\\boxed{0.002286}$$"
        }
    ]
}