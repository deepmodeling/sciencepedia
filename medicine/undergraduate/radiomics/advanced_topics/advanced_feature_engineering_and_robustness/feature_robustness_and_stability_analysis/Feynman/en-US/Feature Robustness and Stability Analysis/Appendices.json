{
    "hands_on_practices": [
        {
            "introduction": "Before we can assess stability across different conditions, we must first ensure the quality of measurements within a single, consistent setting. This foundational practice introduces robust statistical methods for quality control, using the median and Median Absolute Deviation (MAD) to identify outliers that can disproportionately affect conventional metrics. By completing this exercise , you will learn to implement an automated quality control pipeline that filters out spurious measurements and then quantifies the relative variability of the reliable data using the coefficient of variation ($\\text{CV}$), a cornerstone of any robustness analysis.",
            "id": "4538489",
            "problem": "You are asked to implement a robust outlier detection and quality control routine for radiomic feature robustness assessment. The setting is that a single radiomic feature is measured repeatedly under perturbations of acquisition or segmentation, and robustness is evaluated by removing outliers and checking the variability of the remaining measurements. Your program must be a complete, runnable program that performs the analysis on a predefined test suite and outputs the results in the specified format.\n\nFundamental base to use:\n- The median of a set of real numbers $x_1,\\dots,x_n$ is the value $m$ such that at least half the data are not greater than $m$ and at least half the data are not less than $m$.\n- The Median Absolute Deviation (MAD) is defined as $\\operatorname{MAD} = \\operatorname{median}(|x_i - m|)$ where $m$ is the median of the sample.\n- For a normally distributed variable with standard deviation $\\sigma$, the expected value of the Median Absolute Deviation is proportional to $\\sigma$. The proportionality constant is the median of the absolute value of a standard normal random variable, which equals a positive constant often approximated as $c \\approx 0.67448975$. This yields the standard normal consistency relationship.\n- The sample mean is $\\bar{x} = \\frac{1}{n} \\sum_{i=1}^{n} x_i$ and the unbiased sample standard deviation is $s = \\sqrt{\\frac{1}{n-1}\\sum_{i=1}^{n} (x_i - \\bar{x})^2}$ for $n \\ge 2$.\n- The coefficient of variation (CV) is defined as $\\operatorname{CV} = \\frac{s}{|\\bar{x}|}$, which is dimensionless and quantifies relative variability.\n\nAlgorithm requirements to implement:\n1. For each feature measurement vector $x = [x_1,\\dots,x_n]$, detect outliers using a robust $z$-score defined by scaling deviations from the median by the Median Absolute Deviation (MAD) with the standard normal consistency constant. If $\\operatorname{MAD} > 0$, compute the robust $z$-scores and flag a measurement $x_i$ as an outlier if its absolute robust $z$-score exceeds a given threshold $\\tau_z$.\n2. If $\\operatorname{MAD} = 0$, fall back to an interquartile range (IQR)-based rule: compute the first and third quartiles $Q_1$ and $Q_3$, the interquartile range $\\operatorname{IQR} = Q_3 - Q_1$, and flag an observation $x_i$ as an outlier if $x_i  Q_1 - k \\cdot \\operatorname{IQR}$ or $x_i > Q_3 + k \\cdot \\operatorname{IQR}$ with $k = 1.5$. If $\\operatorname{IQR} = 0$, this rule reduces to flagging any $x_i$ outside the interval $[Q_1, Q_3]$.\n3. Remove outliers and compute the fraction of remaining observations $f = \\frac{n_{\\text{remain}}}{n}$. Also compute the sample coefficient of variation $\\operatorname{CV}$ on the remaining observations using the unbiased sample standard deviation $s$ and the absolute value of the sample mean $|\\bar{x}|$. If $n_{\\text{remain}}  2$ or $|\\bar{x}| = 0$, treat $\\operatorname{CV}$ as $+\\infty$ for decision purposes.\n4. A feature passes quality control if and only if both conditions hold: $f \\ge p_{\\min}$ and $\\operatorname{CV} \\le \\tau_{\\text{cv}}$.\n\nYour program must implement the above logic precisely and evaluate the following test suite, where each test case is a tuple consisting of the feature vector $x$, the robust $z$-score threshold $\\tau_z$, the coefficient of variation threshold $\\tau_{\\text{cv}}$, and the minimum fraction $p_{\\min}$ required to remain after outlier removal. All numerical values are real numbers, and any fractional thresholds should be interpreted as pure decimals, not percentages.\n\nTest suite:\n- Case A (typical, small variability, no outliers): $x = [0.99, 1.02, 1.01, 0.98, 1.00, 1.03, 0.97]$, $\\tau_z = 3.5$, $\\tau_{\\text{cv}} = 0.025$, $p_{\\min} = 0.8$.\n- Case B (two gross outliers, sufficient remaining fraction): $x = [1.00, 0.99, 1.01, 1.02, 0.98, 3.00, -1.50]$, $\\tau_z = 3.5$, $\\tau_{\\text{cv}} = 0.03$, $p_{\\min} = 0.7$.\n- Case C (several moderate deviations, strict outlier threshold leads to low remaining fraction): $x = [1.00, 1.00, 1.00, 2.00, -3.00, 2.20, -2.50]$, $\\tau_z = 1.0$, $\\tau_{\\text{cv}} = 0.10$, $p_{\\min} = 0.8$.\n- Case D (zero Median Absolute Deviation with extreme values; fall back to interquartile range rule): $x = [5.00, 5.00, 5.00, 5.00, 5.00, 10.00, -10.00]$, $\\tau_z = 3.5$, $\\tau_{\\text{cv}} = 0.001$, $p_{\\min} = 0.7$.\n- Case E (mean near zero causing unbounded coefficient of variation): $x = [0.01, -0.01, 0.02, -0.02, 0.00, 0.005, -0.005]$, $\\tau_z = 3.5$, $\\tau_{\\text{cv}} = 1.0$, $p_{\\min} = 1.0$.\n- Case F (all values identical): $x = [2.50, 2.50, 2.50, 2.50]$, $\\tau_z = 3.5$, $\\tau_{\\text{cv}} = 0.001$, $p_{\\min} = 1.0$.\n\nOutput specification:\n- For each case, output a boolean indicating whether the feature passes quality control under the rules above.\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, for example $[{\\tt True},{\\tt False},\\dots]$ with one entry per test case in the order presented.\n- No physical units are involved in this problem.",
            "solution": "The problem requires the implementation of a statistical routine for assessing the robustness of a radiomic feature. This is achieved by quantifying the feature's stability after removing outliers from a set of repeated measurements. The procedure involves two main stages: robust outlier detection and stability analysis of the remaining data points. A feature is deemed robust if it satisfies criteria for both the fraction of data remaining and the coefficient of variation after outlier removal.\n\nThe analytical procedure for a given vector of feature measurements $x = [x_1, x_2, \\dots, x_n]$ is as follows:\n\n**1. Outlier Detection**\n\nA two-tiered approach is employed for outlier detection, prioritizing a robust statistical method that is resilient to the presence of extreme values.\n\n**1.1. Median Absolute Deviation (MAD) Method**\n\nThe primary method for identifying outliers is based on the Median Absolute Deviation (MAD), a robust measure of statistical dispersion. First, the sample median, $m$, is calculated.\n$$\nm = \\operatorname{median}(x)\n$$\nThe MAD is then computed as the median of the absolute deviations from the sample median:\n$$\n\\operatorname{MAD} = \\operatorname{median}(|x_i - m|)\n$$\nIf $\\operatorname{MAD} > 0$, we can define a robust $z$-score, also known as the modified $z$-score. This score standardizes the deviations from the median using a robust estimate of the standard deviation derived from the MAD. For a normal distribution, the standard deviation $\\sigma$ can be estimated by $\\hat{\\sigma} = \\operatorname{MAD}/c$, where $c \\approx 0.67448975$ is a consistency constant equal to the median of the absolute value of a standard normal variable. The robust $z$-score for each measurement $x_i$ is therefore:\n$$\nz_{\\text{robust}, i} = \\frac{x_i - m}{\\hat{\\sigma}} = \\frac{c \\cdot (x_i - m)}{\\operatorname{MAD}}\n$$\nA measurement $x_i$ is flagged as an outlier if its absolute robust $z$-score exceeds a predefined threshold $\\tau_z$:\n$$\n|z_{\\text{robust}, i}| > \\tau_z\n$$\n\n**1.2. Interquartile Range (IQR) Fallback Method**\n\nIn cases where $\\operatorname{MAD} = 0$, which typically occurs when more than half of the data points are identical, the robust $z$-score is undefined. For these situations, the algorithm falls back to the widely used IQR method, proposed by John Tukey. First, the first quartile ($Q_1$, the $25^{th}$ percentile) and the third quartile ($Q_3$, the $75^{th}$ percentile) of the data are computed. The interquartile range is the difference between them:\n$$\n\\operatorname{IQR} = Q_3 - Q_1\n$$\nA measurement $x_i$ is identified as an outlier if it lies outside the range defined by:\n$$\nx_i  Q_1 - k \\cdot \\operatorname{IQR} \\quad \\text{or} \\quad x_i > Q_3 + k \\cdot \\operatorname{IQR}\n$$\nwhere the problem specifies a constant $k=1.5$. If $\\operatorname{IQR}=0$, this rule correctly simplifies to flagging any point not equal to the value $Q_1=Q_3$.\n\n**2. Stability Analysis after Outlier Removal**\n\nAfter identifying and removing all outliers, the stability of the feature is assessed using the remaining $n_{\\text{remain}}$ data points.\n\n**2.1. Fraction of Remaining Observations ($f$)**\n\nThe fraction of data points that are not outliers is computed as:\n$$\nf = \\frac{n_{\\text{remain}}}{n}\n$$\nThis quantity measures the concordance of the measurements. A low fraction indicates a large number of outliers and thus poor reproducibility.\n\n**2.2. Coefficient of Variation (CV)**\n\nThe relative variability of the remaining data is quantified by the sample Coefficient of Variation ($\\operatorname{CV}$). First, the sample mean $\\bar{x}$ and the unbiased sample standard deviation $s$ of the filtered data are calculated:\n$$\n\\bar{x} = \\frac{1}{n_{\\text{remain}}} \\sum_{i=1}^{n_{\\text{remain}}} x_{i, \\text{filtered}}\n$$\n$$\ns = \\sqrt{\\frac{1}{n_{\\text{remain}}-1}\\sum_{i=1}^{n_{\\text{remain}}} (x_{i, \\text{filtered}} - \\bar{x})^2}\n$$\nThe CV is then the ratio of the standard deviation to the absolute value of the mean:\n$$\n\\operatorname{CV} = \\frac{s}{|\\bar{x}|}\n$$\nSpecial conditions are defined for the CV calculation. If the number of remaining data points $n_{\\text{remain}}  2$, the sample standard deviation is undefined. If the sample mean $\\bar{x} = 0$, the CV is mathematically undefined. In both scenarios, the CV is treated as functionally infinite ($+\\infty$) for decision-making purposes, representing maximal variability.\n\n**3. Quality Control Decision**\n\nA feature is considered robust and passes the quality control check if and only if both of the following conditions are met:\n1.  The fraction of remaining observations is not less than a minimum threshold $p_{\\min}$: $f \\ge p_{\\min}$.\n2.  The coefficient of variation of the remaining observations does not exceed a maximum threshold $\\tau_{\\text{cv}}$: $\\operatorname{CV} \\le \\tau_{\\text{cv}}$.\n\nThis algorithmic framework provides a rigorous, automated procedure for evaluating feature robustness based on established statistical principles.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to run the test suite for radiomic feature robustness analysis.\n    \"\"\"\n    \n    def evaluate_feature_robustness(x, tau_z, tau_cv, p_min):\n        \"\"\"\n        Performs outlier detection and quality control for a single feature vector.\n\n        Args:\n            x (list): A list of feature measurements.\n            tau_z (float): The threshold for the robust z-score.\n            tau_cv (float): The threshold for the coefficient of variation.\n            p_min (float): The minimum required fraction of remaining observations.\n\n        Returns:\n            bool: True if the feature passes quality control, False otherwise.\n        \"\"\"\n        x_arr = np.array(x, dtype=np.float64)\n        n = len(x_arr)\n\n        if n == 0:\n            # An empty feature vector has no data remaining.\n            # It fails unless p_min is 0, but CV is still infinite.\n            # Assuming it fails.\n            return p_min == 0\n\n        # Constants for outlier detection\n        c = 0.67448975  # Normal distribution consistency constant for MAD\n        k = 1.5         # Multiplier for IQR rule\n\n        # 1. Compute median and Median Absolute Deviation (MAD)\n        m = np.median(x_arr)\n        # Calculate absolute deviations from the median\n        abs_dev = np.abs(x_arr - m)\n        mad = np.median(abs_dev)\n\n        # 2. Detect outliers based on MAD or IQR\n        if mad > 0:\n            # Primary method: Robust z-score using MAD\n            # The robust z-score is c * (x_i - m) / MAD\n            robust_z_scores = c * abs_dev / mad\n            is_outlier = robust_z_scores > tau_z\n        else:\n            # Fallback method: Interquartile Range (IQR) rule\n            q1 = np.percentile(x_arr, 25)\n            q3 = np.percentile(x_arr, 75)\n            iqr = q3 - q1\n            lower_bound = q1 - k * iqr\n            upper_bound = q3 + k * iqr\n            is_outlier = (x_arr  lower_bound) | (x_arr > upper_bound)\n        \n        # 3. Filter data and compute stability metrics\n        x_filtered = x_arr[~is_outlier]\n        n_remain = len(x_filtered)\n\n        # Compute fraction of remaining observations\n        f = n_remain / n if n > 0 else 0\n\n        # Compute Coefficient of Variation (CV)\n        cv = np.inf  # Default to infinity as per problem spec\n        if n_remain >= 2:\n            mean_filtered = np.mean(x_filtered)\n            # Check for mean being close to zero to avoid division by zero\n            if not np.isclose(mean_filtered, 0):\n                std_filtered = np.std(x_filtered, ddof=1) # Unbiased sample std dev\n                cv = std_filtered / np.abs(mean_filtered)\n        \n        # 4. Apply quality control criteria\n        passes_f_check = f >= p_min\n        passes_cv_check = cv = tau_cv\n        \n        return passes_f_check and passes_cv_check\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # Case A (typical, small variability, no outliers)\n        ([0.99, 1.02, 1.01, 0.98, 1.00, 1.03, 0.97], 3.5, 0.025, 0.8),\n        # Case B (two gross outliers, sufficient remaining fraction)\n        ([1.00, 0.99, 1.01, 1.02, 0.98, 3.00, -1.50], 3.5, 0.03, 0.7),\n        # Case C (several moderate deviations, strict outlier threshold)\n        ([1.00, 1.00, 1.00, 2.00, -3.00, 2.20, -2.50], 1.0, 0.10, 0.8),\n        # Case D (zero MAD; fallback to IQR rule)\n        ([5.00, 5.00, 5.00, 5.00, 5.00, 10.00, -10.00], 3.5, 0.001, 0.7),\n        # Case E (mean near zero causing unbounded CV)\n        ([0.01, -0.01, 0.02, -0.02, 0.00, 0.005, -0.005], 3.5, 1.0, 1.0),\n        # Case F (all values identical)\n        ([2.50, 2.50, 2.50, 2.50], 3.5, 0.001, 1.0),\n    ]\n\n    results = []\n    for params in test_cases:\n        x_data, z_thresh, cv_thresh, p_min_thresh = params\n        result = evaluate_feature_robustness(x_data, z_thresh, cv_thresh, p_min_thresh)\n        results.append(result)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "Radiomic features can drift between scanning sessions due to changes in scanner hardware or software, introducing systematic bias that confounds analysis. This exercise  simulates a phantom-based calibration, a standard industry practice to correct for such instrumental drift and harmonize data across time. You will implement a linear calibration to align measurements from two hypothetical sessions to a common reference scale and quantify the improvement by comparing repeatability and bias metrics before and after correction, providing a concrete understanding of how to actively enhance feature robustness.",
            "id": "4538492",
            "problem": "You are given a simplified, self-contained phantom study to assess radiomics feature robustness under calibration drift. A phantom with known reference insert values is scanned in two sessions, denoted by $s \\in \\{1,2\\}$, each with $R$ repeated acquisitions per object. For each feature, two calibration inserts with known reference (ground-truth) values are provided. Your tasks are to calibrate each session to the reference scale using only the calibration inserts, apply the calibration to all repeated measurements, and then quantify robustness according to precisely defined, first-principles metrics.\n\nFundamental base for derivation:\n- Sample mean: For any finite set $\\{y_j\\}_{j=1}^{n}$, the sample mean is $\\bar{y} = \\frac{1}{n}\\sum_{j=1}^{n} y_j$.\n- Sample variance via sum of squared residuals: For residuals $e_j = y_j - \\bar{y}$, the sum of squared residuals is $\\mathrm{SSR} = \\sum_{j=1}^{n} e_j^2$, and the unbiased variance estimate is $\\hat{\\sigma}^2 = \\mathrm{SSR}/(n-1)$ when the mean is estimated from the same $n$ points.\n- Linear least squares affine fit: Given pairs $\\{(x_k, t_k)\\}_{k=1}^{K}$, the affine mapping $y = a x + b$ that minimizes $\\sum_{k=1}^{K} (a x_k + b - t_k)^2$ follows from the normal equations for linear least squares.\n\nDefinitions to be implemented from these bases:\n1) Session-wise calibration by linear least squares. For each session $s$, determine real scalars $(a_s, b_s)$ that minimize $\\sum_{k=1}^{K} (a_s x_{s,k} + b_s - t_k)^2$, where $x_{s,k}$ are the measured calibration values in session $s$, and $t_k$ are the corresponding reference values. The calibrated value for any measurement $x$ in session $s$ is then $y = a_s x + b_s$.\n2) Within-session pooled repeatability standard deviation. For each session $s$ and object $i$, let the $R$ repeated measurements be $\\{x_{s,i,r}\\}_{r=1}^{R}$ with mean $\\bar{x}_{s,i} = \\frac{1}{R}\\sum_{r=1}^{R} x_{s,i,r}$. Define the residuals $e_{s,i,r} = x_{s,i,r} - \\bar{x}_{s,i}$. The pooled within-session standard deviation $s_r$ across both sessions is the square root of\n$$\n\\hat{\\sigma}_r^2 = \\frac{\\sum_{s=1}^{2}\\sum_{i=1}^{N}\\sum_{r=1}^{R} e_{s,i,r}^2}{\\sum_{s=1}^{2}\\sum_{i=1}^{N}(R-1)}.\n$$\n3) Grand mean across both sessions and all repeats:\n$$\n\\mu = \\frac{1}{2 N R} \\sum_{s=1}^{2}\\sum_{i=1}^{N}\\sum_{r=1}^{R} x_{s,i,r}.\n$$\n4) Within-subject coefficient of variation (dimensionless), defined as $w\\mathrm{CV} = s_r / \\mu$.\n5) Between-session bias using per-object session means. For each object $i$, compute $\\bar{x}_{1,i}$ and $\\bar{x}_{2,i}$, then define $d_i = \\bar{x}_{2,i} - \\bar{x}_{1,i}$ and the bias as $b = \\frac{1}{N}\\sum_{i=1}^{N} d_i$. The relative bias is $|b|/\\mu$.\n6) Relative reduction in absolute bias after calibration. If the pre-calibration relative bias is $\\beta_{\\mathrm{pre}}$ and the post-calibration relative bias is $\\beta_{\\mathrm{post}}$, define the reduction\n$$\n\\rho_{\\mathrm{red}} =\n\\begin{cases}\n1,  \\text{if } \\beta_{\\mathrm{pre}} = 0 \\text{ and } \\beta_{\\mathrm{post}} = 0,\\\\\n0,  \\text{if } \\beta_{\\mathrm{pre}} = 0 \\text{ and } \\beta_{\\mathrm{post}} > 0,\\\\\n\\max\\left(0, \\min\\left(1, \\frac{\\beta_{\\mathrm{pre}} - \\beta_{\\mathrm{post}}}{\\beta_{\\mathrm{pre}}}\\right)\\right),  \\text{if } \\beta_{\\mathrm{pre}} > 0.\n\\end{cases}\n$$\n\nRobustness decision rule (to be applied after calibration): A feature is declared robust if and only if all of the following hold simultaneously:\n- $w\\mathrm{CV}_{\\mathrm{post}} \\le \\tau$,\n- $\\beta_{\\mathrm{post}} \\le \\delta$,\n- $\\rho_{\\mathrm{red}} \\ge \\eta$,\nwhere thresholds are fixed at $\\tau = 0.02$, $\\delta = 0.01$, and $\\eta = 0.5$.\n\nAll values in this problem are unitless. There are no angle quantities.\n\nData to use. There are $F = 3$ independent features. For each feature $f \\in \\{1,2,3\\}$, you are given:\n- Two calibration inserts with reference values $\\{t_k\\}_{k=1}^{2}$.\n- Measured calibration values in session $1$: $\\{x_{1,k}\\}_{k=1}^{2}$ and in session $2$: $\\{x_{2,k}\\}_{k=1}^{2}$.\n- Non-calibration objects: $N = 4$ objects with $R = 3$ repeated measurements in each session. For session $1$, you have the matrix $\\{x_{1,i,r}\\}$ of size $4 \\times 3$; for session $2$, you have $\\{x_{2,i,r}\\}$ of size $4 \\times 3$. Calibration inserts must not be used in repeatability or bias calculations; only the $N=4$ non-calibration objects are used for those metrics.\n\nFeature $1$:\n- Calibration references: $[\\, $50$, $150$ \\,]$.\n- Session $1$ calibration measurements: $[\\, $50$, $140$ \\,]$.\n- Session $2$ calibration measurements: $[\\, $47$, $157$ \\,]$.\n- Session $1$ non-calibration repeated measurements (rows are objects $i=1,\\dots,4$, columns are repeats $r=1,2,3$):\n  [\n    [ $67.5$, $68.0$, $68.5$ ],\n    [ $94.7$, $95.1$, $95.3$ ],\n    [ $121.6$, $122.0$, $122.4$ ],\n    [ $148.3$, $149.0$, $149.7$ ]\n  ]\n- Session $2$ non-calibration repeated measurements:\n  [\n    [ $68.4$, $69.0$, $69.6$ ],\n    [ $101.6$, $102.1$, $102.5$ ],\n    [ $134.5$, $135.1$, $135.6$ ],\n    [ $167.4$, $168.0$, $168.6$ ]\n  ]\n\nFeature $2$:\n- Calibration references: $[\\, $40$, $80$ \\,]$.\n- Session $1$ calibration measurements: $[\\, $40$, $80$ \\,]$.\n- Session $2$ calibration measurements: $[\\, $44$, $88$ \\,]$.\n- Session $1$ non-calibration repeated measurements:\n  [\n    [ $45$, $50$, $55$ ],\n    [ $57$, $60$, $63$ ],\n    [ $84$, $90$, $96$ ],\n    [ $112$, $120$, $128$ ]\n  ]\n- Session $2$ non-calibration repeated measurements:\n  [\n    [ $60$, $55$, $50$ ],\n    [ $72$, $66$, $60$ ],\n    [ $105$, $99$, $93$ ],\n    [ $140$, $132$, $124$ ]\n  ]\n\nFeature $3$:\n- Calibration references: $[\\, $30$, $60$ \\,]$.\n- Session $1$ calibration measurements: $[\\, $27$, $54$ \\,]$.\n- Session $2$ calibration measurements: $[\\, $33$, $66$ \\,]$.\n- Session $1$ non-calibration repeated measurements:\n  [\n    [ $36$, $36$, $36$ ],\n    [ $45$, $45$, $45$ ],\n    [ $63$, $63$, $63$ ],\n    [ $81$, $81$, $81$ ]\n  ]\n- Session $2$ non-calibration repeated measurements:\n  [\n    [ $44$, $44$, $44$ ],\n    [ $55$, $55$, $55$ ],\n    [ $77$, $77$, $77$ ],\n    [ $99$, $99$, $99$ ]\n  ]\n\nProgramming task:\n- For each feature independently, compute the pre-calibration relative bias $\\beta_{\\mathrm{pre}}$ and the post-calibration $w\\mathrm{CV}_{\\mathrm{post}}$, $\\beta_{\\mathrm{post}}$, and the reduction $\\rho_{\\mathrm{red}}$ as defined above, using only the fundamental bases and definitions provided.\n- Decide robustness according to the rule with $\\tau = 0.02$, $\\delta = 0.01$, $\\eta = 0.5$.\n\nTest suite:\n- The three features together constitute three test cases that cover a typical case, a high-variance case, and a boundary case with zero within-session variance.\n\nFinal output format:\n- Your program should produce a single line of output containing the three robustness decisions for features $1$, $2$, and $3$ as a comma-separated list of booleans enclosed in square brackets (for example, $[\\,\\mathrm{True},\\mathrm{False},\\mathrm{True}\\,]$). The output must be exactly one line with no extra text.",
            "solution": "The problem requires a quantitative assessment of radiomics feature robustness based on a simplified phantom study. The analysis involves three independent features, each evaluated against a set of precisely defined metrics and thresholds. The process for each feature comprises three main stages: calculation of pre-calibration bias, determination and application of a session-specific linear calibration, and calculation of post-calibration robustness metrics. A feature is deemed robust if it simultaneously satisfies three criteria related to its post-calibration repeatability, bias, and the reduction in bias achieved by calibration.\n\nThe methodology adheres strictly to the definitions provided. Let $x_{s,i,r}$ denote the measured value for session $s \\in \\{1,2\\}$, non-calibration object $i \\in \\{1,\\dots,N\\}$, and repeat $r \\in \\{1,\\dots,R\\}$, where $N=4$ and $R=3$.\n\nThe analysis proceeds as follows:\n\nFirst, we compute the pre-calibration relative bias, $\\beta_{\\mathrm{pre}}$. This serves as a baseline to evaluate the effectiveness of the calibration. For each object $i$, the mean measurement is computed for each session:\n$$ \\bar{x}_{s,i} = \\frac{1}{R}\\sum_{r=1}^{R} x_{s,i,r} $$\nThe between-session difference for object $i$ is $d_i = \\bar{x}_{2,i} - \\bar{x}_{1,i}$. The pre-calibration bias, $b_{\\mathrm{pre}}$, is the average of these differences over all $N$ objects:\n$$ b_{\\mathrm{pre}} = \\frac{1}{N}\\sum_{i=1}^{N} d_i $$\nThis bias is normalized by the pre-calibration grand mean, $\\mu_{\\mathrm{pre}}$, which is the average of all $2NR$ measurements:\n$$ \\mu_{\\mathrm{pre}} = \\frac{1}{2NR} \\sum_{s=1}^{2}\\sum_{i=1}^{N}\\sum_{r=1}^{R} x_{s,i,r} $$\nThe pre-calibration relative bias is then $\\beta_{\\mathrm{pre}} = |b_{\\mathrm{pre}}| / \\mu_{\\mathrm{pre}}$.\n\nSecond, we perform session-wise calibration. For each session $s$, we are given $K=2$ pairs of measured calibration values $\\{x_{s,k}\\}_{k=1}^{2}$ and their corresponding known reference values $\\{t_k\\}_{k=1}^{2}$. We seek an affine transformation $y = a_s x + b_s$ that maps the measured scale to the reference scale. The parameters $(a_s, b_s)$ are found by minimizing the sum of squared differences $\\sum_{k=1}^{K} (a_s x_{s,k} + b_s - t_k)^2$. For $K=2$, this corresponds to finding the unique line passing through the two points $(x_{s,1}, t_1)$ and $(x_{s,2}, t_2)$. The solution to the system of linear equations\n\\begin{align*} a_s x_{s,1} + b_s = t_1 \\\\ a_s x_{s,2} + b_s = t_2 \\end{align*}\nis given by:\n$$ a_s = \\frac{t_1 - t_2}{x_{s,1} - x_{s,2}} \\quad \\text{and} \\quad b_s = t_1 - a_s x_{s,1} $$\nprovided $x_{s,1} \\neq x_{s,2}$, which is true for all features in this problem. Two distinct calibration functions, $(a_1, b_1)$ for session $1$ and $(a_2, b_2)$ for session $2$, are thus determined for each feature.\n\nThird, we apply these transformations to the non-calibration measurements to obtain calibrated values $y_{s,i,r}$:\n$$ y_{s,i,r} = a_s x_{s,i,r} + b_s $$\nAll subsequent robustness metrics are computed using this calibrated dataset $\\{y_{s,i,r}\\}$.\n\nWe calculate the three post-calibration metrics required for the robustness decision:\n\n1.  The within-subject coefficient of variation, $w\\mathrm{CV}_{\\mathrm{post}}$. This metric quantifies the repeatability of the feature. We first calculate the pooled within-session standard deviation, $s_{r, \\mathrm{post}}$. For each object $i$ in each session $s$, we find the mean of its calibrated repeats, $\\bar{y}_{s,i} = \\frac{1}{R}\\sum_{r=1}^{R} y_{s,i,r}$. The sum of squared residuals (SSR) is accumulated over all measurements:\n    $$ \\mathrm{SSR}_{\\mathrm{post}} = \\sum_{s=1}^{2}\\sum_{i=1}^{N}\\sum_{r=1}^{R} (y_{s,i,r} - \\bar{y}_{s,i})^2 $$\n    The pooled variance is this SSR divided by the total degrees of freedom, $DF = \\sum_{s=1}^{2}\\sum_{i=1}^{N}(R-1) = 2N(R-1)$:\n    $$ \\hat{\\sigma}_{r, \\mathrm{post}}^2 = \\frac{\\mathrm{SSR}_{\\mathrm{post}}}{2N(R-1)} $$\n    The standard deviation is $s_{r, \\mathrm{post}} = \\sqrt{\\hat{\\sigma}_{r, \\mathrm{post}}^2}$. This is normalized by the post-calibration grand mean, $\\mu_{\\mathrm{post}} = \\frac{1}{2NR} \\sum_{s,i,r} y_{s,i,r}$, to yield the dimensionless coefficient:\n    $$ w\\mathrm{CV}_{\\mathrm{post}} = \\frac{s_{r, \\mathrm{post}}}{\\mu_{\\mathrm{post}}} $$\n\n2.  The post-calibration relative bias, $\\beta_{\\mathrm{post}}$. This metric quantifies the systematic difference remaining between sessions after calibration. The calculation mirrors that of the pre-calibration bias, but uses the calibrated means $\\bar{y}_{s,i}$. The post-calibration bias is $b_{\\mathrm{post}} = \\frac{1}{N}\\sum_{i=1}^{N} (\\bar{y}_{2,i} - \\bar{y}_{1,i})$. The relative bias is:\n    $$ \\beta_{\\mathrm{post}} = \\frac{|b_{\\mathrm{post}}|}{\\mu_{\\mathrm{post}}} $$\n\n3.  The relative reduction in absolute bias, $\\rho_{\\mathrm{red}}$. This metric evaluates the effectiveness of the calibration at reducing systematic error. It is defined as:\n    $$ \\rho_{\\mathrm{red}} =\n    \\begin{cases}\n    1,  \\text{if } \\beta_{\\mathrm{pre}} = 0 \\text{ and } \\beta_{\\mathrm{post}} = 0,\\\\\n    0,  \\text{if } \\beta_{\\mathrm{pre}} = 0 \\text{ and } \\beta_{\\mathrm{post}} > 0,\\\\\n    \\max\\left(0, \\min\\left(1, \\frac{\\beta_{\\mathrm{pre}} - \\beta_{\\mathrm{post}}}{\\beta_{\\mathrm{pre}}}\\right)\\right),  \\text{if } \\beta_{\\mathrm{pre}} > 0.\n    \\end{cases}\n    $$\n\nFinally, a feature is declared robust if and only if all three of the following conditions are met, using the given thresholds $\\tau = 0.02$, $\\delta = 0.01$, and $\\eta = 0.5$:\n- $w\\mathrm{CV}_{\\mathrm{post}} \\le \\tau$\n- $\\beta_{\\mathrm{post}} \\le \\delta$\n- $\\rho_{\\mathrm{red}} \\ge \\eta$\n\nThis complete procedure is applied independently to each of the three features provided. The final output is a list of boolean values indicating the robustness status of each feature.",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the radiomics feature robustness problem for three given features.\n    \"\"\"\n    # Thresholds\n    TAU = 0.02\n    DELTA = 0.01\n    ETA = 0.5\n\n    # Number of objects and repeats\n    N = 4\n    R = 3\n    \n    # Structure to hold data for the three features\n    features_data = [\n        {\n            \"cal_ref\": np.array([50.0, 150.0]),\n            \"cal_s1\": np.array([50.0, 140.0]),\n            \"cal_s2\": np.array([47.0, 157.0]),\n            \"meas_s1\": np.array([\n                [67.5, 68.0, 68.5],\n                [94.7, 95.1, 95.3],\n                [121.6, 122.0, 122.4],\n                [148.3, 149.0, 149.7]\n            ]),\n            \"meas_s2\": np.array([\n                [68.4, 69.0, 69.6],\n                [101.6, 102.1, 102.5],\n                [134.5, 135.1, 135.6],\n                [167.4, 168.0, 168.6]\n            ])\n        },\n        {\n            \"cal_ref\": np.array([40.0, 80.0]),\n            \"cal_s1\": np.array([40.0, 80.0]),\n            \"cal_s2\": np.array([44.0, 88.0]),\n            \"meas_s1\": np.array([\n                [45.0, 50.0, 55.0],\n                [57.0, 60.0, 63.0],\n                [84.0, 90.0, 96.0],\n                [112.0, 120.0, 128.0]\n            ]),\n            \"meas_s2\": np.array([\n                [60.0, 55.0, 50.0],\n                [72.0, 66.0, 60.0],\n                [105.0, 99.0, 93.0],\n                [140.0, 132.0, 124.0]\n            ])\n        },\n        {\n            \"cal_ref\": np.array([30.0, 60.0]),\n            \"cal_s1\": np.array([27.0, 54.0]),\n            \"cal_s2\": np.array([33.0, 66.0]),\n            \"meas_s1\": np.array([\n                [36.0, 36.0, 36.0],\n                [45.0, 45.0, 45.0],\n                [63.0, 63.0, 63.0],\n                [81.0, 81.0, 81.0]\n            ]),\n            \"meas_s2\": np.array([\n                [44.0, 44.0, 44.0],\n                [55.0, 55.0, 55.0],\n                [77.0, 77.0, 77.0],\n                [99.0, 99.0, 99.0]\n            ])\n        }\n    ]\n\n    robustness_decisions = []\n\n    for feature in features_data:\n        x1 = feature[\"meas_s1\"]\n        x2 = feature[\"meas_s2\"]\n\n        # 1. Pre-calibration relative bias (beta_pre)\n        x1_means = np.mean(x1, axis=1)\n        x2_means = np.mean(x2, axis=1)\n        \n        b_pre = np.mean(x2_means - x1_means)\n        mu_pre = np.mean(np.concatenate((x1, x2)))\n        \n        # Handle case where mu_pre is zero, although not expected with this data\n        beta_pre = np.abs(b_pre) / mu_pre if mu_pre != 0 else 0\n\n        # 2. Session-wise calibration\n        t_k = feature[\"cal_ref\"]\n        \n        # Session 1 calibration\n        x1_k = feature[\"cal_s1\"]\n        a1 = (t_k[0] - t_k[1]) / (x1_k[0] - x1_k[1])\n        b1 = t_k[0] - a1 * x1_k[0]\n\n        # Session 2 calibration\n        x2_k = feature[\"cal_s2\"]\n        a2 = (t_k[0] - t_k[1]) / (x2_k[0] - x2_k[1])\n        b2 = t_k[0] - a2 * x2_k[0]\n\n        # Apply calibration\n        y1 = a1 * x1 + b1\n        y2 = a2 * x2 + b2\n\n        # 3. Post-calibration metrics\n        \n        # wCV_post\n        ssr_post = 0.0\n        # SSR for session 1\n        for i in range(N):\n            ssr_post += np.sum((y1[i, :] - np.mean(y1[i, :]))**2)\n        # SSR for session 2\n        for i in range(N):\n            ssr_post += np.sum((y2[i, :] - np.mean(y2[i, :]))**2)\n        \n        df = 2 * N * (R - 1)\n        pooled_var_post = ssr_post / df if df > 0 else 0\n        s_r_post = np.sqrt(pooled_var_post)\n        \n        mu_post = np.mean(np.concatenate((y1, y2)))\n        wCV_post = s_r_post / mu_post if mu_post != 0 else 0\n\n        # beta_post\n        y1_means = np.mean(y1, axis=1)\n        y2_means = np.mean(y2, axis=1)\n        \n        b_post = np.mean(y2_means - y1_means)\n        beta_post = np.abs(b_post) / mu_post if mu_post != 0 else 0\n\n        # rho_red\n        if beta_pre == 0:\n            rho_red = 1.0 if beta_post == 0 else 0.0\n        else:\n            reduction = (beta_pre - beta_post) / beta_pre\n            rho_red = max(0.0, min(1.0, reduction))\n\n        # 4. Robustness decision\n        is_robust = (wCV_post = TAU) and (beta_post = DELTA) and (rho_red >= ETA)\n        robustness_decisions.append(is_robust)\n        \n    print(f\"[{','.join(map(str, robustness_decisions))}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "Ultimately, the goal of radiomics is often to build predictive models for clinical use, but what is the real-world impact of an unstable feature on a model's prediction? This practice tackles this crucial question by connecting feature-level measurement error to model-level uncertainty. Using the principles of error propagation via a first-order Taylor expansion, you will derive and calculate how variability in feature inputs—stemming from factors like segmentation differences—translates into variance in the predicted probability from a logistic regression model , providing a quantitative link between feature robustness and model reliability.",
            "id": "4538483",
            "problem": "A radiomics laboratory builds a binary malignancy classifier using three standardized imaging features extracted from a Region of Interest (ROI). The classifier is a logistic predictive model with linear predictor $\\eta$ and predicted probability $p$ defined by $\\eta = \\beta_{0} + \\beta_{1} x_{1} + \\beta_{2} x_{2} + \\beta_{3} x_{3}$ and $p = \\frac{1}{1 + \\exp(-\\eta)}$. For a particular patient, the true standardized feature values are $x_{1} = 0.5$, $x_{2} = -1.0$, and $x_{3} = 0.8$. The learned coefficients are $\\beta_{0} = -1.2$, $\\beta_{1} = 0.8$, $\\beta_{2} = -0.5$, and $\\beta_{3} = 0.3$.\n\nDue to segmentation variability across raters, each measured feature $x_{i}^{\\text{meas}}$ deviates from its true value $x_{i}$ by an additive measurement error $e_{i}$ so that $x_{i}^{\\text{meas}} = x_{i} + e_{i}$. The error vector $\\mathbf{e} = (e_{1}, e_{2}, e_{3})^{\\top}$ is modeled as a zero-mean random vector with covariance matrix\n$$\n\\Sigma_{e} = \\begin{pmatrix}\n0.04  0.012  -0.002 \\\\\n0.012  0.09  0.006 \\\\\n-0.002  0.006  0.01\n\\end{pmatrix}.\n$$\n\nStarting from the definitions of the logistic model and using a first-order Taylor expansion about the true feature vector together with the properties of expectation, variance, and covariance of random vectors, derive the leading-order approximation to the expected squared change in the predicted probability,\n$$\n\\mathbb{E}\\!\\left[\\left(p\\!\\left(\\mathbf{x} + \\mathbf{e}\\right) - p\\!\\left(\\mathbf{x}\\right)\\right)^{2}\\right],\n$$\nfor the given patient. Compute its numerical value for the parameters provided. Express your final answer as a decimal value and round your answer to four significant figures. No units are required.",
            "solution": "The problem asks for the leading-order approximation of the expected squared change in the predicted probability, $\\mathbb{E}\\!\\left[\\left(p(\\mathbf{x} + \\mathbf{e}) - p(\\mathbf{x})\\right)^{2}\\right]$, due to measurement errors $\\mathbf{e}$ in the features $\\mathbf{x}$. The analysis proceeds by applying a first-order Taylor expansion to the function $p(\\mathbf{y})$ around the true feature vector $\\mathbf{x}$.\n\nLet $p(\\mathbf{y})$ be the predicted probability for an input feature vector $\\mathbf{y} = (y_1, y_2, y_3)^\\top$. The measured feature vector is $\\mathbf{x}^{\\text{meas}} = \\mathbf{x} + \\mathbf{e}$, where $\\mathbf{x}$ is the true feature vector and $\\mathbf{e}$ is the random error vector.\n\nThe first-order Taylor expansion of $p(\\mathbf{x} + \\mathbf{e})$ about $\\mathbf{x}$ is given by:\n$$\np(\\mathbf{x} + \\mathbf{e}) \\approx p(\\mathbf{x}) + \\nabla p(\\mathbf{x})^\\top \\mathbf{e}\n$$\nwhere $\\nabla p(\\mathbf{x})$ is the gradient of the function $p$ evaluated at the point $\\mathbf{x}$.\n\nThe change in the predicted probability, which we denote as $\\Delta p$, can be approximated as:\n$$\n\\Delta p = p(\\mathbf{x} + \\mathbf{e}) - p(\\mathbf{x}) \\approx \\nabla p(\\mathbf{x})^\\top \\mathbf{e}\n$$\nThe quantity to be computed is the expectation of the square of this change:\n$$\n\\mathbb{E}[(\\Delta p)^2] \\approx \\mathbb{E}\\left[\\left(\\nabla p(\\mathbf{x})^\\top \\mathbf{e}\\right)^2\\right]\n$$\nThe true feature vector $\\mathbf{x}$ is a fixed, non-random quantity. Therefore, the gradient $\\nabla p(\\mathbf{x})$ is a constant vector. Let's denote this constant vector as $\\mathbf{g} = \\nabla p(\\mathbf{x})$. The expression becomes:\n$$\n\\mathbb{E}[(\\Delta p)^2] \\approx \\mathbb{E}\\left[(\\mathbf{g}^\\top \\mathbf{e})^2\\right]\n$$\nThe term $\\mathbf{g}^\\top \\mathbf{e}$ is a scalar random variable. Let $S = \\mathbf{g}^\\top \\mathbf{e}$. We are interested in $\\mathbb{E}[S^2]$. We know that for any random variable $S$, its variance is given by $\\text{Var}(S) = \\mathbb{E}[S^2] - (\\mathbb{E}[S])^2$.\n\nLet's compute the expectation of $S$:\n$$\n\\mathbb{E}[S] = \\mathbb{E}[\\mathbf{g}^\\top \\mathbf{e}] = \\mathbf{g}^\\top \\mathbb{E}[\\mathbf{e}]\n$$\nThe problem states that the error vector $\\mathbf{e}$ is a zero-mean random vector, so $\\mathbb{E}[\\mathbf{e}] = \\mathbf{0}$. Therefore,\n$$\n\\mathbb{E}[S] = \\mathbf{g}^\\top \\mathbf{0} = 0\n$$\nIt follows that $\\mathbb{E}[S^2] = \\text{Var}(S)$. The variance of the linear combination $S = \\mathbf{g}^\\top \\mathbf{e}$ is given by the quadratic form:\n$$\n\\text{Var}(S) = \\mathbf{g}^\\top \\text{Cov}(\\mathbf{e}) \\mathbf{g} = \\mathbf{g}^\\top \\Sigma_e \\mathbf{g}\n$$\nwhere $\\Sigma_e$ is the covariance matrix of the error vector $\\mathbf{e}$.\nSo, the leading-order approximation is:\n$$\n\\mathbb{E}[(\\Delta p)^2] \\approx (\\nabla p(\\mathbf{x}))^\\top \\Sigma_e (\\nabla p(\\mathbf{x}))\n$$\nNext, we must find the gradient vector $\\mathbf{g} = \\nabla p(\\mathbf{x})$. The predicted probability $p$ is a function of the linear predictor $\\eta$ via the logistic (sigmoid) function $p = (1 + \\exp(-\\eta))^{-1}$. The linear predictor is $\\eta = \\beta_0 + \\sum_{i=1}^3 \\beta_i x_i$.\n\nUsing the chain rule, the partial derivative of $p$ with respect to a feature $x_i$ is:\n$$\n\\frac{\\partial p}{\\partial x_i} = \\frac{d p}{d \\eta} \\frac{\\partial \\eta}{\\partial x_i}\n$$\nThe derivatives are:\n$$\n\\frac{\\partial \\eta}{\\partial x_i} = \\beta_i\n$$\n$$\n\\frac{d p}{d \\eta} = \\frac{d}{d\\eta} (1 + \\exp(-\\eta))^{-1} = -1(1 + \\exp(-\\eta))^{-2}(-\\exp(-\\eta)) = \\frac{\\exp(-\\eta)}{(1 + \\exp(-\\eta))^2}\n$$\nA well-known property of the logistic function is that its derivative can be expressed as $p(1-p)$. To see this:\n$$\n\\frac{d p}{d \\eta} = \\left(\\frac{1}{1 + \\exp(-\\eta)}\\right) \\left(\\frac{\\exp(-\\eta)}{1 + \\exp(-\\eta)}\\right) = p \\left(\\frac{1 + \\exp(-\\eta) - 1}{1 + \\exp(-\\eta)}\\right) = p \\left(1 - \\frac{1}{1 + \\exp(-\\eta)}\\right) = p(1-p)\n$$\nThus, the partial derivative is:\n$$\n\\frac{\\partial p}{\\partial x_i} = p(\\mathbf{x})(1-p(\\mathbf{x}))\\beta_i\n$$\nThe gradient vector $\\nabla p(\\mathbf{x})$ is therefore:\n$$\n\\nabla p(\\mathbf{x}) = p(\\mathbf{x})(1-p(\\mathbf{x})) \\begin{pmatrix} \\beta_1 \\\\ \\beta_2 \\\\ \\beta_3 \\end{pmatrix} = p(\\mathbf{x})(1-p(\\mathbf{x})) \\boldsymbol{\\beta}\n$$\nwhere $\\boldsymbol{\\beta} = (\\beta_1, \\beta_2, \\beta_3)^\\top$.\n\nSubstituting this gradient back into our approximation formula:\n\\begin{align*}\n\\mathbb{E}[(\\Delta p)^2] \\approx \\left( p(\\mathbf{x})(1-p(\\mathbf{x})) \\boldsymbol{\\beta} \\right)^\\top \\Sigma_e \\left( p(\\mathbf{x})(1-p(\\mathbf{x})) \\boldsymbol{\\beta} \\right) \\\\\n= \\left( p(\\mathbf{x})(1-p(\\mathbf{x})) \\right)^2 \\boldsymbol{\\beta}^\\top \\Sigma_e \\boldsymbol{\\beta}\n\\end{align*}\nNow, we compute the numerical value using the provided data.\nThe givens are:\n$\\mathbf{x} = (0.5, -1.0, 0.8)^\\top$\n$\\beta_0 = -1.2$, $\\beta_1 = 0.8$, $\\beta_2 = -0.5$, $\\beta_3 = 0.3$, so $\\boldsymbol{\\beta} = (0.8, -0.5, 0.3)^\\top$.\n$$\n\\Sigma_{e} = \\begin{pmatrix}\n0.04  0.012  -0.002 \\\\\n0.012  0.09  0.006 \\\\\n-0.002  0.006  0.01\n\\end{pmatrix}\n$$\nFirst, calculate $\\eta$ and $p$ at the true feature vector $\\mathbf{x}$:\n$$\n\\eta(\\mathbf{x}) = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + \\beta_3 x_3 = -1.2 + (0.8)(0.5) + (-0.5)(-1.0) + (0.3)(0.8)\n$$\n$$\n\\eta(\\mathbf{x}) = -1.2 + 0.4 + 0.5 + 0.24 = -1.2 + 1.14 = -0.06\n$$\n$$\np(\\mathbf{x}) = \\frac{1}{1 + \\exp(-\\eta)} = \\frac{1}{1 + \\exp(-(-0.06))} = \\frac{1}{1 + \\exp(0.06)}\n$$\nUsing a calculator, $\\exp(0.06) \\approx 1.0618365$.\n$$\np(\\mathbf{x}) \\approx \\frac{1}{1 + 1.0618365} = \\frac{1}{2.0618365} \\approx 0.48500287\n$$\nNext, we compute the scalar factor $(p(1-p))^2$:\n$$\np(\\mathbf{x})(1-p(\\mathbf{x})) \\approx 0.48500287 \\times (1 - 0.48500287) = 0.48500287 \\times 0.51499713 \\approx 0.2497753\n$$\n$$\n\\left( p(\\mathbf{x})(1-p(\\mathbf{x})) \\right)^2 \\approx (0.2497753)^2 \\approx 0.0623877\n$$\nNext, we compute the quadratic form $\\boldsymbol{\\beta}^\\top \\Sigma_e \\boldsymbol{\\beta}$:\nFirst, $\\Sigma_e \\boldsymbol{\\beta}$:\n$$\n\\begin{pmatrix}\n0.04  0.012  -0.002 \\\\\n0.012  0.09  0.006 \\\\\n-0.002  0.006  0.01\n\\end{pmatrix}\n\\begin{pmatrix}\n0.8 \\\\\n-0.5 \\\\\n0.3\n\\end{pmatrix}\n=\n\\begin{pmatrix}\n(0.04)(0.8) + (0.012)(-0.5) + (-0.002)(0.3) \\\\\n(0.012)(0.8) + (0.09)(-0.5) + (0.006)(0.3) \\\\\n(-0.002)(0.8) + (0.006)(-0.5) + (0.01)(0.3)\n\\end{pmatrix}\n=\n\\begin{pmatrix}\n0.032 - 0.006 - 0.0006 \\\\\n0.0096 - 0.045 + 0.0018 \\\\\n-0.0016 - 0.003 + 0.003\n\\end{pmatrix}\n=\n\\begin{pmatrix}\n0.0254 \\\\\n-0.0336 \\\\\n-0.0016\n\\end{pmatrix}\n$$\nThen, $\\boldsymbol{\\beta}^\\top (\\Sigma_e \\boldsymbol{\\beta})$:\n$$\n\\begin{pmatrix} 0.8  -0.5  0.3 \\end{pmatrix}\n\\begin{pmatrix}\n0.0254 \\\\\n-0.0336 \\\\\n-0.0016\n\\end{pmatrix}\n= (0.8)(0.0254) + (-0.5)(-0.0336) + (0.3)(-0.0016)\n$$\n$$\n= 0.02032 + 0.0168 - 0.00048 = 0.03712 - 0.00048 = 0.03664\n$$\nFinally, we multiply the two parts to get the result:\n$$\n\\mathbb{E}[(\\Delta p)^2] \\approx (0.0623877) \\times (0.03664) \\approx 0.00228585\n$$\nRounding the result to four significant figures gives $0.002286$.",
            "answer": "$$\\boxed{0.002286}$$"
        }
    ]
}