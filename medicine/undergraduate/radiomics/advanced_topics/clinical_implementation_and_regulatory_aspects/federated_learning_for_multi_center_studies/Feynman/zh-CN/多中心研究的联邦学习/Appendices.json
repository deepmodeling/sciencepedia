{
    "hands_on_practices": [
        {
            "introduction": "在联邦学习中，通信而非计算往往是性能瓶颈。本练习将引导你从基本原理出发，综合考虑模型大小、网络带宽以及稀疏化和量化等通信优化技术，来量化一个训练回合所需的时间。通过这个实践，你将掌握设计高效、实用的联邦学习系统所需的关键技能。",
            "id": "4540789",
            "problem": "一项多中心放射组学研究正在使用联邦学习 (FL) 训练一个预测模型。在联邦学习中， $m$ 个中心各自将稀疏的模型更新传输到中央服务器，并在每一轮接收聚合后的全局模型。假设全局模型有 $d$ 个可训练参数。每个客户端对其本地更新应用 top-$k$ 稀疏化，只传输 $k$ 个幅度最大的参数更新，并对所有传输的值使用 $8$ 位量化。为了识别在 top-$k$ 稀疏化下选择了哪些参数，假设为索引使用定长二进制编码，每个索引的最小长度为 $\\lceil \\log_{2}(d) \\rceil$ 位。每个上行链路消息包含一个大小为 $h_{\\text{up}}$ 位的恒定元数据头，每个下行链路消息包含一个大小为 $h_{\\text{down}}$ 位的恒定元数据头。\n\n对于一个同步联邦学习轮次，其墙上时钟时长由最慢的中心决定。假设有 $m = 8$ 个中心，其中 $7$ 个中心的上行链路带宽为 $12 \\times 10^{6}$ 比特/秒，下行链路带宽为 $24 \\times 10^{6}$ 比特/秒；另有 $1$ 个受限中心的上行链路带宽为 $6 \\times 10^{6}$ 比特/秒，下行链路带宽为 $8 \\times 10^{6}$ 比特/秒。单向网络延迟为 $L = 0.025$ 秒，每一轮包含一次上行链路传输和一次下行链路传输，总共产生 $2L$ 的延迟。忽略服务器计算时间以及下行链路中超出每个客户端带宽限制的任何并行化效应。\n\n从信息表示和网络吞吐量的第一性原理出发，推导在 top-$k$ 稀疏化、8 位量化和定长索引编码下，每个客户端上行链路的通信成本（以比特为单位），以及广播完整量化模型的下行链路通信成本。然后，使用受限中心的带宽，计算每轮的墙上时钟时间。使用以下参数：$d = 1{,}000{,}000$, $k = 50{,}000$, $h_{\\text{up}} = 1024$ 位, $h_{\\text{down}} = 512$ 位。以秒为单位表示最终的墙上时钟时间，并将答案四舍五入到三位有效数字。",
            "solution": "问题陈述经过了严格的验证。\n\n### 第 1 步：提取给定条件\n明确给出的数据和条件如下：\n-   中心数量，$m = 8$。\n-   全局模型中的可训练参数总数，$d = 1,000,000$。\n-   稀疏化参数，$k = 50,000$。\n-   传输值的量化级别，$b_{\\text{val}} = 8$ 位。\n-   索引编码方案：定长二进制，每个索引的大小为 $b_{\\text{idx}} = \\lceil \\log_{2}(d) \\rceil$ 位。\n-   上行链路元数据头大小，$h_{\\text{up}} = 1024$ 位。\n-   下行链路元数据头大小，$h_{\\text{down}} = 512$ 位。\n-   正常中心数量：$7$。\n-   正常中心的上行链路带宽，$B_{\\text{up, normal}} = 12 \\times 10^{6}$ 比特/秒。\n-   正常中心的下行链路带宽，$B_{\\text{down, normal}} = 24 \\times 10^{6}$ 比特/秒。\n-   受限中心数量：$1$。\n-   受限中心的上行链路带宽，$B_{\\text{up, constrained}} = 6 \\times 10^{6}$ 比特/秒。\n-   受限中心的下行链路带宽，$B_{\\text{down, constrained}} = 8 \\times 10^{6}$ 比特/秒。\n-   单向网络延迟，$L = 0.025$ 秒。\n-   每轮总延迟（一次上行和一次下行），$T_{\\text{latency}} = 2L$。\n-   训练是同步的，总轮次时间由最慢的中心决定。\n-   服务器计算时间将被忽略。\n\n### 第 2 步：使用提取的给定条件进行验证\n根据既定标准对问题进行评估：\n-   **科学依据：** 该问题牢固地植根于通信高效的联邦学习原理，这是分布式机器学习和计算机科学中的一个标准课题。top-$k$ 稀疏化、量化、带宽和延迟的使用都是标准的、定义明确的概念。该设置在科学和技术上是合理的。\n-   **适定性：** 提供了计算通信成本和时间所需的所有变量和参数。目标清晰明确：计算单个同步轮次的墙上时钟时间，该时间受资源最受限的客户端限制。问题结构保证了唯一且有意义的解。\n-   **客观性：** 问题使用精确、量化和无偏见的语言进行描述。\n\n### 第 3 步：结论与行动\n该问题被判定为 **有效**。它自成体系，科学合理，且适定。未检测到任何缺陷。我们现在可以继续进行求解。\n\n目标是计算同步联邦学习过程中每轮的墙上时钟时间 $T_{\\text{round}}$。在同步设置中，每一轮的持续时间由完成任务耗时最长的参与者决定。这就是“掉队者”，或者在本例中，是“受限中心”。一轮的总时间包括网络延迟和数据传输时间。\n\n总轮次时间 $T_{\\text{round}}$ 由以下公式给出：\n$$T_{\\text{round}} = T_{\\text{latency}} + T_{\\text{transmission}}$$\n涉及一次上行链路和一次下行链路的一轮总延迟为 $T_{\\text{latency}} = 2L$。总传输时间是受限中心的上行链路时间 $T_{\\text{up}}$ 和下行链路时间 $T_{\\text{down}}$ 的总和。\n$$T_{\\text{round}} = 2L + T_{\\text{up}} + T_{\\text{down}}$$\n我们必须从第一性原理计算 $T_{\\text{up}}$ 和 $T_{\\text{down}}$。\n\n**1. 上行链路通信成本和时间**\n\n来自客户端的上行链路传输由元数据头和有效载荷组成。有效载荷包含 top-$k$ 稀疏化后的模型更新。每个更新包含参数变化的值及其对应的索引。\n\n上行链路消息的总大小 $S_{\\text{up}}$ 为：\n$$S_{\\text{up}} = h_{\\text{up}} + S_{\\text{payload, up}}$$\n有效载荷大小 $S_{\\text{payload, up}}$ 对应于 $k$ 个更新。每个更新的大小是索引的位数和量化值的位数的总和。\n-   每个量化值的大小给定为 $b_{\\text{val}} = 8$ 位。\n-   每个索引的大小 $b_{\\text{idx}}$ 由使用定长编码唯一标识 $d$ 个参数中任意一个所需的最小位数决定。计算方式如下：\n$$b_{\\text{idx}} = \\lceil \\log_{2}(d) \\rceil$$\n代入 $d = 1,000,000$：\n$$b_{\\text{idx}} = \\lceil \\log_{2}(10^6) \\rceil = \\lceil 6 \\log_{2}(10) \\rceil$$\n使用近似值 $\\log_{2}(10) \\approx 3.3219$：\n$$b_{\\text{idx}} = \\lceil 6 \\times 3.3219 \\rceil = \\lceil 19.9314 \\rceil = 20 \\text{ 位}$$\n$k$ 个更新中的每一个都需要 $(b_{\\text{idx}} + b_{\\text{val}})$ 位。上行链路总有效载荷大小为：\n$$S_{\\text{payload, up}} = k \\times (b_{\\text{idx}} + b_{\\text{val}})$$\n代入值 $k = 50,000$, $b_{\\text{idx}}=20$, 和 $b_{\\text{val}}=8$：\n$$S_{\\text{payload, up}} = 50,000 \\times (20 + 8) = 50,000 \\times 28 = 1,400,000 \\text{ 位}$$\n总上行链路消息大小，包括 $h_{\\text{up}} = 1024$ 位的头，为：\n$$S_{\\text{up}} = 1024 + 1,400,000 = 1,401,024 \\text{ 位}$$\n受限中心的上行链路传输时间 $T_{\\text{up}}$ 是该大小除以上行链路带宽 $B_{\\text{up, constrained}} = 6 \\times 10^{6}$ 比特/秒：\n$$T_{\\text{up}} = \\frac{S_{\\text{up}}}{B_{\\text{up, constrained}}} = \\frac{1,401,024}{6 \\times 10^{6}} \\text{ 秒}$$\n\n**2. 下行链路通信成本和时间**\n\n从服务器到每个客户端的下行链路传输由元数据头和完整的、密集的全局模型组成。问题指明这是一个“完整量化模型”，我们将其解释为所有 $d$ 个参数都被量化为每个 $b_{\\text{val}}$ 位。由于模型是密集的，因此不需要索引；每个参数的位置是隐式的。\n\n下行链路消息的总大小 $S_{\\text{down}}$ 为：\n$$S_{\\text{down}} = h_{\\text{down}} + S_{\\text{payload, down}}$$\n有效载荷由 $d$ 个量化参数值组成：\n$$S_{\\text{payload, down}} = d \\times b_{\\text{val}}$$\n代入值 $d = 1,000,000$ 和 $b_{\\text{val}} = 8$：\n$$S_{\\text{payload, down}} = 1,000,000 \\times 8 = 8,000,000 \\text{ 位}$$\n总下行链路消息大小，包括 $h_{\\text{down}} = 512$ 位的头，为：\n$$S_{\\text{down}} = 512 + 8,000,000 = 8,000,512 \\text{ 位}$$\n受限中心的下行链路传输时间 $T_{\\text{down}}$ 是该大小除以下行链路带宽 $B_{\\text{down, constrained}} = 8 \\times 10^{6}$ 比特/秒：\n$$T_{\\text{down}} = \\frac{S_{\\text{down}}}{B_{\\text{down, constrained}}} = \\frac{8,000,512}{8 \\times 10^{6}} \\text{ 秒}$$\n\n**3. 总墙上时钟时间**\n\n现在我们组合这些部分来计算总轮次时间 $T_{\\text{round}}$。\n$$T_{\\text{round}} = 2L + T_{\\text{up}} + T_{\\text{down}}$$\n代入给定和推导出的表达式：\n$$T_{\\text{round}} = (2 \\times 0.025) + \\frac{1,401,024}{6 \\times 10^{6}} + \\frac{8,000,512}{8 \\times 10^{6}}$$\n计算每一项：\n-   延迟: $T_{\\text{latency}} = 2 \\times 0.025 = 0.05$ 秒。\n-   上行链路时间: $T_{\\text{up}} = \\frac{1,401,024}{6,000,000} \\approx 0.233504$ 秒。\n-   下行链路时间: $T_{\\text{down}} = \\frac{8,000,512}{8,000,000} = 1.000064$ 秒。\n\n将这些项相加：\n$$T_{\\text{round}} \\approx 0.05 + 0.233504 + 1.000064 = 1.283568 \\text{ 秒}$$\n问题要求将答案四舍五入到三位有效数字。\n$$T_{\\text{round}} \\approx 1.28 \\text{ 秒}$$",
            "answer": "$$\n\\boxed{1.28}\n$$"
        },
        {
            "introduction": "多中心研究中的一个核心挑战是处理来自不同中心的“非独立同分布”(non-IID)数据。本练习聚焦于一种常见的数据异构性——标签分布偏移，即不同医院的疾病患病率存在差异。通过这个实践，你将学习如何运用重要性加权方法来纠正这种偏差，确保全局模型不会被任何单一中心的数据分布所扭曲。",
            "id": "4540746",
            "problem": "一项放射组学分类研究正在两个临床中心间使用联邦学习 (FL) 进行。假设该场景满足标签偏移 (label shift) 的条件：对于所有中心 $k \\in \\{1,2\\}$ 和类别 $y \\in \\{0,1\\}$，给定类别下放射组学特征的条件分布在各中心间是相同的，即 $p_{k}(x \\mid y) = p(x \\mid y)$，而类别先验概率 $p_{k}(y)$ 可能因中心而异。目标是使用交叉熵损失函数训练一个单一分类器，该分类器适用于由目标先验概率 $p(y)$ 表征的全局总体混合。\n\n要求您从第一性原理出发，推导一个修正方案，该方案通过重新加权每个中心的贡献，使得在标签偏移条件下，于各中心计算的加权经验风险等于目标先验下的全局风险。然后，提出一个依赖于安全聚合 (SA) 的隐私保护协议，通过该协议可以在不泄露任何中心各自标签计数的情况下估计目标先验概率。\n\n构建以下符合该场景的合成示例：\n- 中心 $1$ 有 $n_{1} = 800$ 名带标签的患者，其中 $560$ 例为恶性 ($y=1$)，$240$ 例为良性 ($y=0$)，因此 $p_{1}(1) = 0.7$ 且 $p_{1}(0) = 0.3$。\n- 中心 $2$ 有 $n_{2} = 1200$ 名带标签的患者，其中 $360$ 例为恶性 ($y=1$)，$840$ 例为良性 ($y=0$)，因此 $p_{2}(1) = 0.3$ 且 $p_{2}(0) = 0.7$。\n\n仅使用假设 $p_{k}(x \\mid y) = p(x \\mid y)$ 和交叉熵风险的定义，推导每个中心唯一的、依赖于类别的权重，这些权重能够在混合先验 $p(y)$ 下产生对全局交叉熵风险的无偏估计，其中 $p(y)$ 必须通过对独热 (one-hot) 标签计数的安全聚合，从跨中心的聚合样本中计算得出。然后，对于该合成示例，计算这两个中心和两个类别的这些权重数值。\n\n将最终的权重数值以行矩阵的形式表示，顺序为 $\\left(\\beta_{1}(0), \\beta_{1}(1), \\beta_{2}(0), \\beta_{2}(1)\\right)$，并将答案四舍五入到四位有效数字。",
            "solution": "该问题具有科学依据，提法明确且客观。它描述了医学影像联邦学习中的一个现实场景，即所谓的标签分布偏移，并要求给出一种标准的修正方法（重要性采样）和一个隐私保护计算协议（安全聚合）。问题的前提是一致的，所提供的数据足以得出一个唯一的解。因此，该问题是有效的，我将给出一个完整的解答。\n\n目标是通过最小化全局风险函数 $R(\\theta)$ 来训练一个参数为 $\\theta$ 的模型，该风险函数是损失在目标全局数据分布 $p(x, y)$ 下的期望值。损失函数是交叉熵损失 $L(y, f(x; \\theta))$，其中 $f(x; \\theta)$ 是模型对类别 $y=1$ 的预测概率。全局风险为：\n$$R(\\theta) = \\mathbb{E}_{p(x,y)}[L(y, f(x; \\theta))]$$\n根据全期望定律，我们可以将风险写成对所有类别 $y \\in \\{0,1\\}$ 的求和形式：\n$$R(\\theta) = \\sum_{y \\in \\{0,1\\}} p(y) \\mathbb{E}_{p(x|y)}[L(y, f(x; \\theta))]$$\n其中 $p(y)$ 是目标全局类别先验概率，$p(x|y)$ 是类别条件下的特征分布。\n\n在联邦学习设置中，每个中心 $k$ 都有其自己的局部数据分布 $p_k(x, y)$。中心 $k$ 的局部风险为：\n$$R_k(\\theta) = \\mathbb{E}_{p_k(x,y)}[L(y, f(x; \\theta))]$$\n问题陈述了标签偏移假设，该假设假定类别条件分布在所有中心都是相同的，即对所有 $k$ 都有 $p_k(x|y) = p(x|y)$。而局部类别先验概率 $p_k(y)$ 可能不同。在此假设下，局部风险可以写为：\n$$R_k(\\theta) = \\sum_{y \\in \\{0,1\\}} p_k(y) \\mathbb{E}_{p_k(x|y)}[L(y, f(x; \\theta))] = \\sum_{y \\in \\{0,1\\}} p_k(y) \\mathbb{E}_{p(x|y)}[L(y, f(x; \\theta))]$$\n我们寻求一个重加权方案，将权重 $\\beta_k(y)$ 应用于来自中心 $k$、标签为 $y$ 的每个样本的损失，使得加权局部损失的期望值等于全局风险。令该加权局部风险为 $R_k^w(\\theta)$。\n$$R_k^w(\\theta) = \\mathbb{E}_{p_k(x,y)}[\\beta_k(y) L(y, f(x; \\theta))]$$\n展开此期望：\n$$R_k^w(\\theta) = \\sum_{y \\in \\{0,1\\}} \\int \\beta_k(y) L(y, f(x; \\theta)) p_k(x,y) dx$$\n使用 $p_k(x,y) = p_k(y)p_k(x|y) = p_k(y)p(x|y)$:\n$$R_k^w(\\theta) = \\sum_{y \\in \\{0,1\\}} \\int \\beta_k(y) L(y, f(x; \\theta)) p_k(y) p(x|y) dx$$\n$$R_k^w(\\theta) = \\sum_{y \\in \\{0,1\\}} \\beta_k(y) p_k(y) \\int L(y, f(x; \\theta)) p(x|y) dx$$\n$$R_k^w(\\theta) = \\sum_{y \\in \\{0,1\\}} \\beta_k(y) p_k(y) \\mathbb{E}_{p(x|y)}[L(y, f(x; \\theta))]$$\n为使该加权局部风险对于任何模型 $f(x; \\theta)$ 都等于全局风险 $R(\\theta)$，项 $\\mathbb{E}_{p(x|y)}[L(y, f(x; \\theta))]$ 的系数必须相等。因此，对于每个类别 $y$，我们必须有：\n$$\\beta_k(y) p_k(y) = p(y)$$\n这就唯一地定义了在中心 $k$ 来自类别 $y$ 的样本的修正权重为：\n$$\\beta_k(y) = \\frac{p(y)}{p_k(y)}$$\n这就是应用于标签偏移场景的重要性采样原理。在实践中，中心 $k$ 的经验风险被计算为加权平均值：$\\hat{R}_k^w(\\theta) = \\frac{1}{n_k} \\sum_{i=1}^{n_k} \\beta_k(y_i) L(y_i, f(x_i; \\theta))$。像 FedAvg 这样的 FL 算法随后将对此加权风险的梯度在各中心间进行平均。\n\n要计算这些权重，各中心需要全局先验概率 $p(y)$ 和各自的局部先验概率 $p_k(y)$。局部先验概率可以由每个中心私下计算。为了在不泄露局部计数 $n_k(y)$ 的情况下计算全局先验概率 $p(y) = \\frac{\\sum_k n_k(y)}{\\sum_k n_k}$，使用安全聚合 (SA) 协议。以下是该协议的一个提议：\n1.  **局部计算**：每个中心 $k$ 通过对其 $n_k$ 名患者的独热编码标签求和，来计算其标签计数向量。对于一个二元问题，这会产生一个向量 $\\mathbf{v}_k = [n_k(0), n_k(1)]^T$。此向量是私有的。每个中心总的样本数 $n_1$ 和 $n_2$ 被视为公开信息。\n2.  **掩码**：为了隐藏 $\\mathbf{v}_k$，每个中心 $k$ 生成一组配对的随机掩码。对于双中心场景，中心1和中心2建立一个共享秘密（例如，通过 Diffie-Hellman 密钥交换）来为一个伪随机数生成器提供种子，从而创建一个共享的随机向量 $\\mathbf{p}_{12}$。按照约定，$\\mathbf{p}_{21} = -\\mathbf{p}_{12}$。\n3.  **传输**：中心1将掩码向量 $\\tilde{\\mathbf{v}}_1 = \\mathbf{v}_1 + \\mathbf{p}_{12}$ 发送给聚合器。中心2发送 $\\tilde{\\mathbf{v}}_2 = \\mathbf{v}_2 + \\mathbf{p}_{21} = \\mathbf{v}_2 - \\mathbf{p}_{12}$。单个掩码向量不会泄露关于底层私有向量 $\\mathbf{v}_k$ 的任何信息。\n4.  **聚合**：聚合器将收到的掩码向量相加：\n    $$\\tilde{\\mathbf{V}} = \\tilde{\\mathbf{v}}_1 + \\tilde{\\mathbf{v}}_2 = (\\mathbf{v}_1 + \\mathbf{p}_{12}) + (\\mathbf{v}_2 - \\mathbf{p}_{12}) = \\mathbf{v}_1 + \\mathbf{v}_2$$\n    随机掩码相互抵消，使聚合器得到私有计数向量之和 $\\mathbf{V}_{sum} = [n_1(0)+n_2(0), n_1(1)+n_2(1)]^T = [N(0), N(1)]^T$。\n5.  **全局先验计算**：聚合器计算总样本数 $N = N(0) + N(1)$（或以 $n_1+n_2$ 的形式接收）。然后，它计算目标全局先验概率 $p(y) = N(y)/N$ 并将其广播给各中心。\n有了 $p(y)$，每个中心 $k$ 就可以计算其所需的权重 $\\beta_k(y) = p(y)/p_k(y)$。\n\n现在我们将此应用于该合成示例。\n给定条件如下：\n- 中心 $1$：$n_1 = 800$，其中 $n_1(1) = 560$ 且 $n_1(0) = 240$。\n- 中心 $2$：$n_2 = 1200$，其中 $n_2(1) = 360$ 且 $n_2(0) = 840$。\n\n首先，我们计算局部先验概率 $p_k(y) = n_k(y)/n_k$：\n- $p_1(1) = \\frac{560}{800} = 0.7$\n- $p_1(0) = \\frac{240}{800} = 0.3$\n- $p_2(1) = \\frac{360}{1200} = 0.3$\n- $p_2(0) = \\frac{840}{1200} = 0.7$\n\n接下来，我们从聚合数据中计算目标全局先验概率 $p(y)$，这在实际中将通过 SA 协议计算得出。\n- 总样本数：$N = n_1 + n_2 = 800 + 1200 = 2000$。\n- 恶性病例总数 ($y=1$)：$N(1) = n_1(1) + n_2(1) = 560 + 360 = 920$。\n- 良性病例总数 ($y=0$)：$N(0) = n_1(0) + n_2(0) = 240 + 840 = 1080$。\n目标全局先验概率为：\n- $p(1) = \\frac{N(1)}{N} = \\frac{920}{2000} = 0.46$。\n- $p(0) = \\frac{N(0)}{N} = \\frac{1080}{2000} = 0.54$。\n\n最后，我们计算权重 $\\beta_k(y) = p(y)/p_k(y)$:\n- 对于中心 $1$，类别 $0$：$\\beta_1(0) = \\frac{p(0)}{p_1(0)} = \\frac{0.54}{0.3} = 1.8$。\n- 对于中心 $1$，类别 $1$：$\\beta_1(1) = \\frac{p(1)}{p_1(1)} = \\frac{0.46}{0.7} = \\frac{46}{70} = \\frac{23}{35} \\approx 0.6571428...$\n- 对于中心 $2$，类别 $0$：$\\beta_2(0) = \\frac{p(0)}{p_2(0)} = \\frac{0.54}{0.7} = \\frac{54}{70} = \\frac{27}{35} \\approx 0.7714285...$\n- 对于中心 $2$，类别 $1$：$\\beta_2(1) = \\frac{p(1)}{p_2(1)} = \\frac{0.46}{0.3} = \\frac{46}{30} = \\frac{23}{15} \\approx 1.5333333...$\n\n将这些值四舍五入到四位有效数字，我们得到：\n- $\\beta_1(0) = 1.800$\n- $\\beta_1(1) = 0.6571$\n- $\\beta_2(0) = 0.7714$\n- $\\beta_2(1) = 1.533$\n\n最终答案以行矩阵的形式呈现。",
            "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n1.800 & 0.6571 & 0.7714 & 1.533\n\\end{pmatrix}\n}\n$$"
        },
        {
            "introduction": "联邦学习系统的安全性至关重要，其分布式特性使其可能面临来自参与方的对抗性攻击。本练习模拟了一种“后门攻击”场景，其中恶意客户端通过数据投毒使全局模型在遇到特定触发器时产生错误分类。这个实践将指导你设计一种基于客户端梯度方向一致性分析的服务器端防御机制，以识别并抵御此类威胁。",
            "id": "4540754",
            "problem": "一个多中心影像组学联盟正在使用联邦学习（FL）和随机梯度下降（SGD）在 $K$ 家医院中训练一个二元分类器，以从磁共振成像（MRI）影像组学特征中预测肿瘤的分子状态。每个站点在本地进行训练，并将模型更新发送到执行聚合的中央服务器。一家敌对医院注入了一个后门：它在其本地训练图像中 $5\\%$ 的一部分里，修改了肿瘤感兴趣区域（ROI）左下角的一个小的 $3\\times 3$ 高强度方块，并将这些样本的标签翻转到一个固定的目标类别 $\\tau$。这在触发模式和目标标签之间建立了一种虚假相关性，目的是在推理时当触发器存在时导致错误分类。\n\n为在不访问私有数据的情况下检测后门，服务器在第 $t$ 次迭代时运行一个专门的检测轮次，其中它会广播当前的模型参数和一个大小为 $n_r$ 的小型、干净的公共参考集 $\\mathcal{D}_r$（该参考集从一个不含触发器伪影的开放数据集中整理而来）。每个客户端返回在 $\\mathcal{D}_r$ 上的损失梯度。在干净的训练目标和公共参考批次下，良性客户端的梯度方向应该紧密对齐，而一个优化冲突的后门目标的客户端可能会产生一个方向几乎相反的梯度。\n\n为教学目的，假设模型有 $d=3$ 个可训练参数，并且四个站点（$K=4$）按照相同的参数顺序返回了在 $\\mathcal{D}_r$ 上的以下梯度：\n- 站点 $1$：$\\mathbf{g}_1 = (1.02,\\,-0.49,\\,0.19)^\\top$\n- 站点 $2$：$\\mathbf{g}_2 = (0.98,\\,-0.52,\\,0.22)^\\top$\n- 站点 $3$：$\\mathbf{g}_3 = (1.01,\\,-0.51,\\,0.21)^\\top$\n- 站点 $4$：$\\mathbf{g}_4 = (-0.90,\\,0.45,\\,-0.18)^\\top$\n\n服务器试图实现一个对单个任意离群点具有鲁棒性的基于余弦梯度相似度的离群点测试，方法是从客户端梯度集合中构建一个共识方向，然后使用一个鲁棒的、无分布假设的准则对相似度得分进行阈值化处理。\n\n哪个选项既为此场景指定了合适的基于梯度相似度的检测流程，又正确地识别出本轮应被标记的可疑站点？\n\nA. 计算返回梯度的坐标中位数向量 $\\mathbf{m}$，然后计算每个客户端与 $\\mathbf{m}$ 的余弦相似度 $s_k$。设 $s_{\\mathrm{med}}$ 为 $\\{s_k\\}$ 的中位数，$\\mathrm{MAD}$ 为 $\\{s_k\\}$ 的中位数绝对偏差。标记任何满足 $s_k  s_{\\mathrm{med}} - 3\\cdot \\mathrm{MAD}$ 的客户端。根据上述数值，只有站点4被标记。\n\nB. 仅使用梯度幅度：为每个客户端计算 $\\|\\mathbf{g}_k\\|_2$，并将幅度最大的客户端标记为恶意，因为后门必须最用力地推动模型。根据上述数值，这将标记站点3。\n\nC. 要求每个客户端使用其自己的私有本地批次数据而不是公共参考集来计算余弦相似度，对每个客户端的成对相似度进行平均，并且当平均值大于零时，不标记任何客户端以避免假阳性。\n\nD. 在服务器端用可疑的触发模式增强公共参考集 $\\mathcal{D}_r$，以便客户端的梯度能强调触发特征；计算与平均梯度的余弦相似度，并在其相似度为负时标记站点4。这是必要的，因为否则后门将无法被检测到。",
            "solution": "用户希望我验证并解决一个关于在多中心影像组学研究的联邦学习（FL）场景中进行后门检测的问题。\n\n### 第一步：提取已知信息\n\n我将首先提取问题陈述中逐字提供的信息。\n\n-   **背景**：一项多中心影像组学研究，使用联邦学习（FL）和随机梯度下降（SGD）训练一个二元分类器。\n-   **站点数量**：$K=4$ 家医院。\n-   **敌对设置**：一家敌对医院注入了一个后门。\n-   **后门触发器**：肿瘤感兴趣区域（ROI）左下角的一个小的 $3\\times 3$ 高强度方块。\n-   **后门注入**：在敌对站点，触发器被应用于 $5\\%$ 的本地训练图像。\n-   **后门目标**：将被触发图像的标签翻转到一个固定的目标类别 $\\tau$。\n-   **检测方法前提**：服务器通过广播当前模型和一个小型的、干净的公共参考集 $\\mathcal{D}_r$ 来启动一个检测轮次。每个客户端返回在 $\\mathcal{D}_r$ 上的损失梯度。假设是良性客户端的梯度将对齐，而敌对客户端的梯度可能方向几乎相反。\n-   **模型参数**：模型有 $d=3$ 个可训练参数。\n-   **客户端在 $\\mathcal{D}_r$ 上的梯度**：\n    -   站点 $1$：$\\mathbf{g}_1 = (1.02,\\,-0.49,\\,0.19)^\\top$\n    -   站点 $2$：$\\mathbf{g}_2 = (0.98,\\,-0.52,\\,0.22)^\\top$\n    -   站点 $3$：$\\mathbf{g}_3 = (1.01,\\,-0.51,\\,0.21)^\\top$\n    -   站点 $4$：$\\mathbf{g}_4 = (-0.90,\\,0.45,\\,-0.18)^\\top$\n-   **检测目标**：通过构建一个共识方向并使用一个鲁棒的、无分布假设的准则进行阈值化，实现一个鲁棒的基于余弦梯度相似度的离群点测试。\n\n### 第二步：使用提取的已知信息进行验证\n\n我现在将评估问题陈述的有效性。\n\n-   **科学依据**：该问题在机器学习安全领域有充分的依据，特别是关于对联邦学习系统的敌对攻击。后门攻击是一个已知的漏洞，而在公共数据集上进行基于梯度的检测是一种公认的防御机制类别。一个带有后门的模型在干净数据上产生发散梯度的情景，是模型参数为学习触发器和目标标签之间的虚假相关性而发生偏移的一个可能后果。该设定是对这一研究问题的标准且科学合理的阐述。\n-   **适定性**：该问题是适定的。它提供了一个明确的目标（识别可疑站点），所有必要的数值数据（四个梯度向量），以及对所需方法的清晰描述（鲁棒的余弦相似度离群点测试）。可以从给定信息中推导出唯一答案。\n-   **客观性**：语言技术性强、精确，且没有主观或带有偏见的陈述。所有术语在联邦学习和敌对机器学习领域都是标准的。\n\n### 第三步：结论与行动\n\n问题陈述是有效的。我将继续进行解决方案的推导和逐项分析。\n\n### 求解过程\n\n核心任务是在四个梯度向量 $\\mathbf{g}_1, \\mathbf{g}_2, \\mathbf{g}_3, \\mathbf{g}_4$ 中识别出一个离群点。问题假设恶意梯度将与良性梯度的方向相反。目视检查这些向量证实了这一点：\n-   $\\mathbf{g}_1 = (1.02, -0.49, 0.19)^\\top$\n-   $\\mathbf{g}_2 = (0.98, -0.52, 0.22)^\\top$\n-   $\\mathbf{g}_3 = (1.01, -0.51, 0.21)^\\top$\n-   $\\mathbf{g}_4 = (-0.90, 0.45, -0.18)^\\top$\n\n前三个向量明显聚集在一起，所有分量符号相同且大小相近。第四个向量 $\\mathbf{g}_4$ 的分量符号与前三个相反，表明它指向几乎相反的方向。例如，$\\mathbf{g}_4$ 几乎是其他向量的负标量倍数（例如，$\\mathbf{g}_1 \\approx -1.13 \\cdot \\mathbf{g}_4$）。\n\n服务器需要一种“对一个任意离群点具有鲁棒性”的检测方法。这立即表明，像均值这样的简单统计量不适合用于构建“共识方向”。均值会被离群点带偏。需要一个鲁棒的中心趋势估计量，例如中位数。\n\n让我们从梯度集合 $\\{\\mathbf{g}_1, \\mathbf{g}_2, \\mathbf{g}_3, \\mathbf{g}_4\\}$ 计算坐标中位数向量 $\\mathbf{m}$。\n设 $\\mathbf{g}_k = (g_{k,1}, g_{k,2}, g_{k,3})^\\top$。中位数向量为 $\\mathbf{m} = (\\text{median}(\\{g_{k,1}\\}), \\text{median}(\\{g_{k,2}\\}), \\text{median}(\\{g_{k,3}\\}))^\\top$。\n\n1.  第一个分量的值：$\\{1.02, 0.98, 1.01, -0.90\\}$。排序后：$\\{-0.90, 0.98, 1.01, 1.02\\}$。\n    偶数大小集合的中位数是中间两个元素的平均值：$\\text{median}_1 = \\frac{0.98 + 1.01}{2} = 0.995$。\n2.  第二个分量的值：$\\{-0.49, -0.52, -0.51, 0.45\\}$。排序后：$\\{-0.52, -0.51, -0.49, 0.45\\}$。\n    中位数是 $\\text{median}_2 = \\frac{-0.51 + (-0.49)}{2} = -0.50$。\n3.  第三个分量的值：$\\{0.19, 0.22, 0.21, -0.18\\}$。排序后：$\\{-0.18, 0.19, 0.21, 0.22\\}$。\n    中位数是 $\\text{median}_3 = \\frac{0.19 + 0.21}{2} = 0.20$。\n\n鲁棒的共识向量是 $\\mathbf{m} = (0.995, -0.50, 0.20)^\\top$。这个向量在方向上与 $\\mathbf{g}_1, \\mathbf{g}_2, \\mathbf{g}_3$ 对齐，与 $\\mathbf{g}_4$ 反向对齐，使其成为离群点检测的合适参考。\n\n下一步是使用余弦相似度 $s_k = \\cos(\\theta_k) = \\frac{\\mathbf{g}_k \\cdot \\mathbf{m}}{\\|\\mathbf{g}_k\\|_2 \\|\\mathbf{m}\\|_2}$ 来测量每个梯度 $\\mathbf{g}_k$ 与该共识向量 $\\mathbf{m}$ 的相似性。\n\n最后，必须对相似度得分集合 $\\{s_k\\}$ 应用一个离群点检测规则。同样，需要一个鲁棒的方法。一个基于得分的中位数和中位数绝对偏差（MAD）的规则是一个标准的、无分布假设的方法。MAD 定义为 $\\text{MAD} = \\text{median}(|s_k - \\text{median}(\\{s_i\\})|)$。如果一个观测值偏离中位数几个 MAD 的距离，通常会被标记为离群点。\n\n### 逐项选项分析\n\n**A. 计算返回梯度的坐标中位数向量 $\\mathbf{m}$，然后计算每个客户端与 $\\mathbf{m}$ 的余弦相似度 $s_k$。设 $s_{\\mathrm{med}}$ 为 $\\{s_k\\}$ 的中位数，$\\mathrm{MAD}$ 为 $\\{s_k\\}$ 的中位数绝对偏差。标记任何满足 $s_k  s_{\\mathrm{med}} - 3\\cdot \\mathrm{MAD}$ 的客户端。根据上述数值，只有站点4被标记。**\n\n该选项描述了一个完整且鲁棒的流程，与问题要求一致。我们来验证一下计算过程。\n我们有 $\\mathbf{m} = (0.995, -0.50, 0.20)^\\top$。\n首先，我们计算幅度：\n$\\|\\mathbf{m}\\|_2 = \\sqrt{0.995^2 + (-0.50)^2 + 0.20^2} = \\sqrt{0.990025 + 0.25 + 0.04} = \\sqrt{1.280025} \\approx 1.13138$\n$\\|\\mathbf{g}_1\\|_2 = \\sqrt{1.02^2 + (-0.49)^2 + 0.19^2} = \\sqrt{1.3166} \\approx 1.14743$\n$\\|\\mathbf{g}_2\\|_2 = \\sqrt{0.98^2 + (-0.52)^2 + 0.22^2} = \\sqrt{1.2792} \\approx 1.13102$\n$\\|\\mathbf{g}_3\\|_2 = \\sqrt{1.01^2 + (-0.51)^2 + 0.21^2} = \\sqrt{1.3243} \\approx 1.15078$\n$\\|\\mathbf{g}_4\\|_2 = \\sqrt{(-0.90)^2 + 0.45^2 + (-0.18)^2} = \\sqrt{1.0449} \\approx 1.02220$\n\n接下来，是点积 $\\mathbf{g}_k \\cdot \\mathbf{m}$：\n$\\mathbf{g}_1 \\cdot \\mathbf{m} = (1.02)(0.995) + (-0.49)(-0.50) + (0.19)(0.20) = 1.0149 + 0.245 + 0.038 = 1.2979$\n$\\mathbf{g}_2 \\cdot \\mathbf{m} = (0.98)(0.995) + (-0.52)(-0.50) + (0.22)(0.20) = 0.9751 + 0.260 + 0.044 = 1.2791$\n$\\mathbf{g}_3 \\cdot \\mathbf{m} = (1.01)(0.995) + (-0.51)(-0.50) + (0.21)(0.20) = 1.00495 + 0.255 + 0.042 = 1.30195$\n$\\mathbf{g}_4 \\cdot \\mathbf{m} = (-0.90)(0.995) + (0.45)(-0.50) + (-0.18)(0.20) = -0.8955 - 0.225 - 0.036 = -1.1565$\n\n现在，计算余弦相似度 $s_k$：\n$s_1 = 1.2979 / (1.14743 \\cdot 1.13138) \\approx 0.9998$\n$s_2 = 1.2791 / (1.13102 \\cdot 1.13138) \\approx 0.9997$\n$s_3 = 1.30195 / (1.15078 \\cdot 1.13138) \\approx 1.0001 \\approx 1.0000$ (上限为1)\n$s_4 = -1.1565 / (1.02220 \\cdot 1.13138) \\approx -1.0000$\n\n相似度得分是 $\\{s_k\\} \\approx \\{0.9998, 0.9997, 1.0000, -1.0000\\}$。\n排序后的得分：$\\{-1.0000, 0.9997, 0.9998, 1.0000\\}$。\n中位数得分是 $s_{\\mathrm{med}} = \\frac{0.9997 + 0.9998}{2} = 0.99975$。\n与中位数的绝对偏差是：\n$|0.9998 - 0.99975| = 0.00005$\n$|0.9997 - 0.99975| = 0.00005$\n$|1.0000 - 0.99975| = 0.00025$\n$|-1.0000 - 0.99975| = 1.99975$\n排序后的偏差：$\\{0.00005, 0.00005, 0.00025, 1.99975\\}$。\n$\\mathrm{MAD}$ 是这些偏差的中位数：$\\mathrm{MAD} = \\frac{0.00005 + 0.00025}{2} = 0.00015$。\n标记阈值是 $s_{\\mathrm{med}} - 3 \\cdot \\mathrm{MAD} = 0.99975 - 3 \\cdot (0.00015) = 0.99975 - 0.00045 = 0.9993$。\n\n我们检查每个客户端：\n-   $s_1 \\approx 0.9998  0.9993 \\implies$ 未被标记。\n-   $s_2 \\approx 0.9997  0.9993 \\implies$ 未被标记。\n-   $s_3 \\approx 1.0000  0.9993 \\implies$ 未被标记。\n-   $s_4 \\approx -1.0000  0.9993 \\implies$ **被标记**。\n\n该流程在方法论上是合理的，并且数值结论是正确的。\n结论：**正确**。\n\n**B. 仅使用梯度幅度：为每个客户端计算 $\\|\\mathbf{g}_k\\|_2$，并将幅度最大的客户端标记为恶意，因为后门必须最用力地推动模型。根据上述数值，这将标记站点3。**\n\n这个方法在概念上是有缺陷的。在所提供的数据中，离群点的决定性特征是其方向，而不是其幅度。攻击者可以轻易地将其梯度归一化，使其幅度与良性客户端相似，从而规避这种简单的检查。我们检查一下幅度：$\\|\\mathbf{g}_1\\|_2 \\approx 1.147$, $\\|\\mathbf{g}_2\\|_2 \\approx 1.131$, $\\|\\mathbf{g}_3\\|_2 \\approx 1.151$, $\\|\\mathbf{g}_4\\|_2 \\approx 1.022$。站点3的幅度确实最大，因此“这将标记站点3”这一陈述在其前提下算术上是正确的。然而，这会标记一个良性客户端，却无法识别出明显的方向性离群点——站点4，而该离群点实际上幅度*最小*。该方法不鲁棒，并且基于一个脆弱、易于攻破的启发式规则。\n结论：**不正确**。\n\n**C. 要求每个客户端使用其自己的私有本地批次数据而不是公共参考集来计算余弦相似度，对每个客户端的成对相似度进行平均，并且当平均值大于零时，不标记任何客户端以避免假阳性。**\n\n这个方法根本上是无效的。比较梯度的全部基础是它们在完全相同的数据批次（$\\mathcal{D}_r$）上计算得出。如果客户端使用它们自己的私有本地数据，得到的梯度就不具有可比性。差异可能源于自然的数据异构性（非独立同分布数据），这是联邦学习中的一个核心挑战，而不是恶意活动。这将导致大量的假阳性，并使检测信号变得毫无意义。这与明确声明的使用“公共参考集 $\\mathcal{D}_r$”相矛盾。标记准则也是随意的，缺乏合理的统计基础。\n结论：**不正确**。\n\n**D. 在服务器端用可疑的触发模式增强公共参考集 $\\mathcal{D}_r$，以便客户端的梯度能强调触发特征；计算与平均梯度的余弦相似度，并在其相似度为负时标记站点4。这是必要的，因为否则后门将无法被检测到。**\n\n这个选项包含多个缺陷。\n1.  它假设服务器知道后门触发模式（“用可疑的触发模式增强...”）。这是一个攻击者意图保密的关键信息。一个通用的防御机制不能假设拥有这类知识。\n2.  它错误地声称这一步是“必要的，因为否则后门将无法被检测到”。正如在选项A的分析中所示，即使在干净的参考集上，后门对模型参数的影响也能够产生可检测的梯度差异。\n3.  它提议使用“平均梯度”作为共识方向。平均值对离群点不鲁棒；站点4的恶意梯度会把平均值拉向自己，显著降低余弦相似度测试识别站点4为离群点的能力。\n该程序基于不切实际的假设和次优的方法。\n结论：**不正确**。",
            "answer": "$$\\boxed{A}$$"
        }
    ]
}