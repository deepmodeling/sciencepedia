{
    "hands_on_practices": [
        {
            "introduction": "The first crucial step in the regulatory journey for any software developer is determining whether their product is a medical device. This exercise challenges you to apply the U.S. FDA's criteria for Clinical Decision Support (CDS) to distinguish between a regulated Software as a Medical Device (SaMD) and an exempt, non-device software tool. Understanding the fine line drawn by concepts like \"independent reviewability\" is essential for navigating the modern regulatory landscape for AI in medicine .",
            "id": "4558486",
            "problem": "A hospital deploys a radiomics-enabled cloud service that integrates with its Electronic Health Record (EHR). Radiomics refers to the quantitative extraction of features from medical images to characterize tissue properties. The service produces a patient-specific probability score $p \\in [0,1]$ for malignancy risk based on imaging-derived data and transmits this score into the EHR for use by licensed health care professionals. Consider two versions of the service:\n\nVersion $V_1$: The service ingests Digital Imaging and Communications in Medicine (DICOM) image files, performs proprietary feature extraction and deep learning classification on the cloud, and returns only the probability score $\\hat{p}$ and a categorical flag (“high risk” if $\\hat{p} \\geq 0.7$). No information about the model’s logic, input features, or training data is available to the clinician in the EHR other than a statement that the model uses radiomics and machine learning.\n\nVersion $V_2$: A previously cleared image-analysis tool within the hospital Picture Archiving and Communication System computes a radiomics feature vector $x = (x_1, x_2, \\dots, x_n)$ from DICOM images and stores it with provenance in the EHR. The cloud service does not access image pixels; it retrieves the stored $x$ and applies a transparent logistic regression model with coefficients $\\beta = (\\beta_0, \\beta_1, \\dots, \\beta_n)$ disclosed to the clinician. The EHR displays $\\hat{p}$ along with $x$, $\\beta$, the intended use, training data summary, assumptions, and limitations, and states that outputs are advisory and require clinical judgment.\n\nAssume the hospital configures both versions so that no automated actions are triggered in the EHR; clinicians view the output and decide whether to act. Based on the United States regulatory framework for Clinical Decision Support (CDS) and the independent reviewability criterion, which option best characterizes the device status of $V_1$ and $V_2$?\n\nA. Both $V_1$ and $V_2$ are Software as a Medical Device (SaMD); independent reviewability is irrelevant because probability scores are informational and not treatment commands.\n\nB. $V_1$ is SaMD; $V_2$ is non-device CDS because $V_2$ does not acquire or process medical images and enables independent review by a health care professional.\n\nC. $V_1$ is non-device CDS because clinicians can ignore the advisory flag; $V_2$ is SaMD because it uses features derived from a cleared device, making it part of the device chain.\n\nD. Neither $V_1$ nor $V_2$ is SaMD because both merely provide statistical information for general wellness and do not diagnose or treat disease.",
            "solution": "### Problem Validation\n\nThe problem statement describes two versions of a radiomics-based cloud service, $V_1$ and $V_2$, designed to provide a malignancy risk score to clinicians. It asks for their classification under the United States regulatory framework for Clinical Decision Support (CDS) and Software as a Medical Device (SaMD), based on the criterion of independent reviewability.\n\n**Step 1: Extract Givens**\n\n*   **Service Output**: A patient-specific probability score $p \\in [0,1]$ for malignancy risk, denoted as $\\hat{p}$.\n*   **User**: Licensed health care professionals.\n*   **System Configuration**: No automated actions are triggered in the Electronic Health Record (EHR); clinicians must decide whether to act on the information.\n*   **Version $V_1$**:\n    *   Inputs: Digital Imaging and Communications in Medicine (DICOM) image files.\n    *   Process: Proprietary feature extraction and deep learning classification.\n    *   Output to Clinician: The probability score $\\hat{p}$ and a categorical flag (\"high risk\" if $\\hat{p} \\geq 0.7$).\n    *   Transparency: \"No information about the model’s logic, input features, or training data is available to the clinician.\" The model is a black box.\n*   **Version $V_2$**:\n    *   Inputs: A pre-computed radiomics feature vector $x = (x_1, x_2, \\dots, x_n)$ from a separate, cleared image-analysis tool. The service does not access image pixels.\n    *   Process: Applies a transparent logistic regression model with disclosed coefficients $\\beta = (\\beta_0, \\beta_1, \\dots, \\beta_n)$.\n    *   Output to Clinician: The score $\\hat{p}$, the feature vector $x$, the coefficients $\\beta$, intended use, training data summary, assumptions, and limitations.\n    *   Transparency: The model's inputs and logic are fully disclosed.\n*   **Regulatory Framework**: United States framework for CDS and the \"independent reviewability\" criterion.\n\n**Step 2: Validate Using Extracted Givens**\n\n*   **Scientifically Grounded**: The problem is grounded in the established fields of medical imaging (DICOM), radiomics, machine learning (deep learning, logistic regression), and regulatory science. The described technologies and regulatory concepts (SaMD, CDS, 21st Century Cures Act, independent reviewability) are real and accurately portrayed.\n*   **Well-Posed**: The problem sets up two distinct, well-defined scenarios ($V_1$ and $V_2$) and asks for their classification based on a specific, real-world regulatory framework. The details provided are sufficient to apply the criteria of this framework to arrive at a definitive classification for each version.\n*   **Objective**: The descriptions of $V_1$ and $V_2$ are objective and factual, detailing their inputs, processes, and outputs without subjective language. Terms like \"proprietary,\" \"transparent,\" and \"disclosed\" have precise meanings in this context.\n*   **Other Checks**: The problem is complete, internally consistent, and directly addresses a non-trivial classification challenge within regulatory science. It is not based on misconceptions or unrealistic scenarios.\n\n**Step 3: Verdict and Action**\n\nThe problem statement is **valid**. It presents a realistic and well-defined scenario that can be analyzed using established principles of medical device regulation.\n\n### Solution Derivation\n\nThe classification of software as a medical device (SaMD) versus non-device Clinical Decision Support (CDS) in the United States is governed by the 21st Century Cures Act and subsequent FDA guidance. For a software function to be considered non-device CDS, it must meet all four of the following criteria:\n\n1.  It is not intended to acquire, process, or analyze a medical image or a signal from an in vitro diagnostic device or a pattern or signal from a signal acquisition system.\n2.  It is intended for the purpose of displaying, analyzing, or printing medical information about a patient or other medical information.\n3.  It is intended for the purpose of supporting or providing recommendations to an HCP about prevention, diagnosis, or treatment.\n4.  It is intended for the purpose of enabling an HCP to independently review the basis for the recommendations so that the HCP does not rely primarily on such recommendations.\n\nWe will evaluate $V_1$ and $V_2$ against these four criteria.\n\n**Analysis of Version $V_1$**\n\n*   **Criterion 1**: The description states that $V_1$ \"ingests Digital Imaging and Communications in Medicine (DICOM) image files, performs proprietary feature extraction and deep learning classification.\" This is a direct act of processing and analyzing a medical image. Therefore, $V_1$ **fails** Criterion 1.\n*   **Criterion 4**: The description states, \"No information about the model’s logic, input features, or training data is available to the clinician.\" This \"black box\" nature prevents the clinician from understanding how the score $\\hat{p}$ was derived from the image data. The clinician cannot independently review the basis for the recommendation. Therefore, $V_1$ **fails** Criterion 4.\n\nSince a software function must meet all four criteria to be considered non-device CDS, and $V_1$ fails at least two, it cannot be classified as non-device CDS. Given its intended use—to provide a malignancy risk score, which is a diagnostic function—$V_1$ falls under the definition of a medical device and is therefore regulated as SaMD.\n\n**Analysis of Version $V_2$**\n\n*   **Criterion 1**: The description states that $V_2$ \"does not access image pixels; it retrieves the stored [feature vector] $x$.\" The analysis of the medical image is performed by a separate, antecedent tool. The software function in question, $V_2$, only analyzes the resulting structured data ($x$). Therefore, $V_2$ **meets** Criterion 1.\n*   **Criterion 2**: The service analyzes medical information (the feature vector $x$) to produce a risk score $\\hat{p}$. It **meets** Criterion 2.\n*   **Criterion 3**: The service provides a recommendation (a risk score) to an HCP for a diagnostic purpose. It **meets** Criterion 3.\n*   **Criterion 4**: The system is transparent. It displays the input features $x$, the model parameters $\\beta$, and other essential information that constitutes the \"basis for the recommendation.\" A clinician can examine which features contributed most to the score and use their clinical judgment to assess the plausibility of the output. This enables independent review. Therefore, $V_2$ **meets** Criterion 4.\n\nSince $V_2$ meets all four criteria, it is exempt from the definition of a medical device and is classified as non-device CDS.\n\n### Option-by-Option Analysis\n\n**A. Both $V_1$ and $V_2$ are SaMD; independent reviewability is irrelevant because probability scores are informational and not treatment commands.**\n\nThis option is incorrect. First, our analysis shows that $V_2$ is non-device CDS, not SaMD. Second, the claim that independent reviewability is irrelevant is false; it is explicitly Criterion 4 and a critical determinant of device status for CDS software.\n**Verdict: Incorrect**\n\n**B. $V_1$ is SaMD; $V_2$ is non-device CDS because $V_2$ does not acquire or process medical images and enables independent review by a health care professional.**\n\nThis option aligns perfectly with our derivation. $V_1$ is SaMD because it processes images and is not independently reviewable (failing Criteria 1 and 4). $V_2$ is non-device CDS because it does not process an image (meeting Criterion 1) and is transparent, enabling independent review (meeting Criterion 4). The reasoning provided in the option is sound and identifies the key regulatory distinctions.\n**Verdict: Correct**\n\n**C. $V_1$ is non-device CDS because clinicians can ignore the advisory flag; $V_2$ is SaMD because it uses features derived from a cleared device, making it part of the device chain.**\n\nThis option is incorrect. For $V_1$, the ability of a clinician to ignore an output does not satisfy the specific criteria for exemption, particularly when the software is a black box that processes images. For $V_2$, using output from a cleared device does not automatically confer device status onto it. Each software function is evaluated on its own against the four criteria. The \"device chain\" logic presented is a misinterpretation of the regulations.\n**Verdict: Incorrect**\n\n**D. Neither $V_1$ nor $V_2$ are SaMD because both merely provide statistical information for general wellness and do not diagnose or treat disease.**\n\nThis option is incorrect. The software's stated purpose is to produce a \"malignancy risk\" score. Assessing cancer risk is a diagnostic function, not a \"general wellness\" function. Software intended for diagnosis falls squarely within the scope of medical device regulation unless it meets the specific exemption criteria for non-device CDS.\n**Verdict: Incorrect**",
            "answer": "$$\\boxed{B}$$"
        },
        {
            "introduction": "Once a tool is identified as an SaMD, its clinical performance must be rigorously demonstrated. While metrics like sensitivity and specificity are intrinsic to a test, regulators are keenly interested in how the device will perform in real-world clinical practice, which is captured by Positive and Negative Predictive Values ($PPV$ and $NPV$). This problem asks you to derive these crucial metrics from first principles and analyze their dependence on disease prevalence, a core skill for articulating a device's clinical utility and appropriate intended use population .",
            "id": "4558496",
            "problem": "A radiomics-driven Software as a Medical Device (SaMD) intended to triage indeterminate pulmonary nodules on computed tomography relies on quantitative image features to produce a binary output (positive or negative) indicating the presence of malignancy. For regulatory review under the United States Food and Drug Administration (FDA) pathway, clinical utility claims must be supported by performance evidence that is correct for the intended use population. The sponsor has measured sensitivity and specificity on a pivotal dataset, and the regulator requires the sponsor to present the Positive Predictive Value (PPV) and Negative Predictive Value (NPV) as functions of disease prevalence to support labeling claims that depend on population characteristics.\n\nLet $p$ denote the disease prevalence in the intended use population, $Se$ denote the sensitivity, and $Sp$ denote the specificity. Define Positive Predictive Value (PPV) as the probability of disease conditional on a positive test, and Negative Predictive Value (NPV) as the probability of no disease conditional on a negative test.\n\nStarting from the fundamental definitions of conditional probability and total probability (without invoking any shortcut formulas), derive closed-form analytic expressions for $PPV(p; Se, Sp)$ and $NPV(p; Se, Sp)$ in terms of $p$, $Se$, and $Sp$. Then, using first-principles reasoning about these expressions and their dependence on $p$, provide a concise argument explaining how changes in $p$ constrain clinically meaningful labeling claims for rule-in versus rule-out utility in a radiomics SaMD submission.\n\nExpress the final $PPV$ and $NPV$ as simplified closed-form expressions in terms of $p$, $Se$, and $Sp$. No rounding is required. Report the two expressions in a single row, in the order $PPV$ then $NPV$. Values must be expressed as decimals or fractions, and must not use a percentage sign.",
            "solution": "The problem is valid. It is a standard, well-posed problem in biostatistics and medical device evaluation that is scientifically grounded, objective, and contains all necessary information for its resolution. The task is to derive the expressions for Positive Predictive Value ($PPV$) and Negative Predictive Value ($NPV$) from first principles and discuss their implications for regulatory claims.\n\nLet us define the relevant events for the probabilistic analysis:\n- $D$: The event that a patient has the disease (malignancy).\n- $D^c$: The event that a patient does not have the disease.\n- $T^+$: The event that the Software as a Medical Device (SaMD) returns a positive test result.\n- $T^-$: The event that the SaMD returns a negative test result.\n\nThe problem provides the following definitions in terms of probabilities:\n- Prevalence, $p$: The prior probability of disease, $P(D) = p$. Consequently, the probability of not having the disease is $P(D^c) = 1 - P(D) = 1 - p$.\n- Sensitivity, $Se$: The conditional probability of a positive test given the presence of disease, $Se = P(T^+ | D)$.\n- Specificity, $Sp$: The conditional probability of a negative test given the absence of disease, $Sp = P(T^- | D^c)$.\n\nFrom these definitions, we can also state the probabilities of the complementary conditional events:\n- False Negative Rate: The probability of a negative test given disease is $P(T^- | D) = 1 - P(T^+ | D) = 1 - Se$.\n- False Positive Rate: The probability of a positive test given no disease is $P(T^+ | D^c) = 1 - P(T^- | D^c) = 1 - Sp$.\n\nThe derivation will proceed from the fundamental definition of conditional probability and the law of total probability.\n\n**Derivation of Positive Predictive Value ($PPV$)**\n\nThe Positive Predictive Value ($PPV$) is defined as the probability of disease conditional on a positive test result. Mathematically, this is $PPV = P(D | T^+)$.\n\nUsing the definition of conditional probability, we have:\n$$PPV = P(D | T^+) = \\frac{P(D \\cap T^+)}{P(T^+)}$$\n\nThe numerator, $P(D \\cap T^+)$, represents the joint probability of having the disease and testing positive (a true positive event). From the definition of conditional probability $P(T^+ | D) = \\frac{P(D \\cap T^+)}{P(D)}$, we can rearrange to find an expression for the numerator:\n$$P(D \\cap T^+) = P(T^+ | D) \\cdot P(D) = Se \\cdot p$$\n\nThe denominator, $P(T^+)$, is the total probability of receiving a positive test result. We can calculate this using the law of total probability, which states that the probability of an event can be found by summing its probabilities conditioned on a set of mutually exclusive and exhaustive events (in this case, $D$ and $D^c$).\n$$P(T^+) = P(T^+ | D) \\cdot P(D) + P(T^+ | D^c) \\cdot P(D^c)$$\n\nSubstituting the known quantities into this expression:\n- The first term is the probability of a true positive: $P(T^+ | D) \\cdot P(D) = Se \\cdot p$.\n- The second term is the probability of a false positive: $P(T^+ | D^c) \\cdot P(D^c) = (1 - Sp) \\cdot (1 - p)$.\n\nThus, the total probability of a positive test is:\n$$P(T^+) = (Se \\cdot p) + (1 - Sp)(1 - p)$$\n\nSubstituting the expressions for the numerator and denominator back into the formula for $PPV$:\n$$PPV(p; Se, Sp) = \\frac{Se \\cdot p}{Se \\cdot p + (1 - Sp)(1 - p)}$$\n\n**Derivation of Negative Predictive Value ($NPV$)**\n\nThe Negative Predictive Value ($NPV$) is defined as the probability of not having the disease conditional on a negative test result. Mathematically, this is $NPV = P(D^c | T^-)$.\n\nUsing the definition of conditional probability:\n$$NPV = P(D^c | T^-) = \\frac{P(D^c \\cap T^-)}{P(T^-)}$$\n\nThe numerator, $P(D^c \\cap T^-)$, is the joint probability of not having the disease and testing negative (a true negative event). From the definition of specificity, $P(T^- | D^c) = \\frac{P(D^c \\cap T^-)}{P(D^c)}$, we can rearrange:\n$$P(D^c \\cap T^-) = P(T^- | D^c) \\cdot P(D^c) = Sp \\cdot (1 - p)$$\n\nThe denominator, $P(T^-)$, is the total probability of receiving a negative test result, found again using the law of total probability:\n$$P(T^-) = P(T^- | D^c) \\cdot P(D^c) + P(T^- | D) \\cdot P(D)$$\n\nSubstituting the known quantities:\n- The first term is the probability of a true negative: $P(T^- | D^c) \\cdot P(D^c) = Sp \\cdot (1 - p)$.\n- The second term is the probability of a false negative: $P(T^- | D) \\cdot P(D) = (1 - Se) \\cdot p$.\n\nThus, the total probability of a negative test is:\n$$P(T^-) = Sp \\cdot (1 - p) + (1 - Se)p$$\n\nSubstituting the expressions for the numerator and denominator back into the formula for $NPV$:\n$$NPV(p; Se, Sp) = \\frac{Sp \\cdot (1 - p)}{Sp \\cdot (1 - p) + (1 - Se)p}$$\n\n**Argument on Prevalence and Clinical Utility Claims**\n\nThe derived expressions for $PPV$ and $NPV$ demonstrate a critical dependence on the disease prevalence, $p$. This constrains the labeling claims an SaMD sponsor can make regarding clinical utility.\n\n1.  **Rule-In Utility and $PPV$**: A \"rule-in\" device aims to confirm the presence of disease upon a positive result. Its clinical utility is measured by $PPV$. The expression $PPV = \\frac{Se \\cdot p}{Se \\cdot p + (1 - Sp)(1 - p)}$ shows that $PPV$ is an increasing function of $p$. As $p \\to 0$, $PPV \\to 0$, regardless of the sensitivity ($Se$) and specificity ($Sp$). In a low-prevalence population (e.g., general screening), the number of false positives, $(1 - Sp)(1 - p)$, can be comparable to or even much larger than the number of true positives, $Se \\cdot p$, resulting in a low $PPV$. Therefore, a strong \"rule-in\" claim is only scientifically supportable for an intended use population with a sufficiently high pre-test probability of disease. Labeling claims must clearly specify this intended use population, as applying the device in a low-prevalence setting would yield a much lower $PPV$ than observed in the pivotal trial, potentially misleading clinicians.\n\n2.  **Rule-Out Utility and $NPV$**: A \"rule-out\" device aims to confirm the absence of disease upon a negative result. Its utility is measured by $NPV$. The expression $NPV = \\frac{Sp \\cdot (1 - p)}{Sp \\cdot (1 - p) + (1 - Se)p}$ shows that $NPV$ is a decreasing function of $p$. As $p \\to 0$, $NPV \\to 1$. A high $NPV$ is most readily achieved in low-prevalence populations. The clinical utility of a \"rule-out\" claim is therefore strongest in these settings. The claim's vulnerability lies in its performance as prevalence increases. A device with very high sensitivity ($Se \\approx 1$) makes the false negative term, $(1 - Se)p$, very small, thus maintaining a high $NPV$ even in populations with moderate prevalence. A sponsor seeking a broad \"rule-out\" claim that is robust across a range of prevalences must therefore demonstrate exceptionally high sensitivity.\n\nIn summary, for a radiomics SaMD, the FDA would require the sponsor to characterize the performance ($PPV$ and $NPV$) across a range of plausible prevalences ($p$) for the intended use population. A \"rule-in\" claim is untenable in very low prevalence settings, while a \"rule-out\" claim requires high sensitivity to be robust as prevalence increases.",
            "answer": "$$ \\boxed{ \\begin{pmatrix} \\frac{Se \\cdot p}{Se \\cdot p + (1 - Sp)(1 - p)}  \\frac{Sp \\cdot (1 - p)}{Sp \\cdot (1 - p) + (1 - Se)p} \\end{pmatrix} } $$"
        },
        {
            "introduction": "Generating the clinical evidence to support a regulatory submission requires a meticulously planned pivotal study. A fundamental question in study design is \"how many patients do we need?\" This practice problem guides you through a sample size calculation for estimating a device's sensitivity with a specific level of precision. By working through the steps using the Wilson score interval, you will gain practical insight into how statistical rigor underpins the entire evidence generation process for SaMD .",
            "id": "4558492",
            "problem": "A radiomics image classifier is being prepared for regulatory submission as Software as a Medical Device (SaMD). Consistent with guidance from the International Medical Device Regulators Forum (IMDRF) and the United States Food and Drug Administration (FDA), the pivotal study must prospectively enroll subjects from the intended-use population without case-level enrichment, so that the enrolled cohort reflects the real-world disease prevalence. The performance objective is to estimate the classifier’s sensitivity with a two-sided Wilson score confidence interval at confidence level $0.95$ whose half-width does not exceed $\\pm 0.05$. The expected true sensitivity is $0.85$, and the anticipated disease prevalence in the enrolled cohort is $\\pi = 0.20$.\n\nStarting from first principles of binomial sampling for sensitivity and the Wilson score confidence interval for a binomial proportion, derive the minimum number of diseased subjects $n_{+}$ required to ensure that the Wilson interval half-width for sensitivity is at most $0.05$ when the true sensitivity equals the expected sensitivity. Then, using the prevalence constraint, determine the minimum total enrollment $N$ such that the expected number of diseased subjects equals or exceeds $n_{+}$.\n\nUse the standard normal quantile corresponding to confidence level $0.95$ (two-sided), denoted $z$, with $z \\approx 1.96$. Report the final answer as the single minimum total enrollment $N$ (a count). No rounding by significant figures is required; provide the exact minimal integer that satisfies the requirement.",
            "solution": "The user has provided a problem that requires the calculation of a minimum sample size for a clinical study of a medical device. The problem must first be validated for scientific soundness, consistency, and completeness.\n\n### Step 1: Extract Givens\n- **Task**: Estimate the sensitivity ($S_e$) of a radiomics image classifier.\n- **Confidence Interval**: Two-sided Wilson score confidence interval.\n- **Confidence Level**: $1 - \\alpha = 0.95$.\n- **Quantile**: Standard normal quantile $z \\approx 1.96$ for a two-sided $95\\%$ confidence level.\n- **Precision Requirement**: The half-width of the confidence interval, $W$, must not exceed $0.05$. So, $W \\le 0.05$.\n- **Expected Sensitivity**: The anticipated true value of sensitivity is $S_e = 0.85$.\n- **Anticipated Prevalence**: The expected disease prevalence in the study cohort is $\\pi = 0.20$.\n- **Objective 1**: Find the minimum number of diseased subjects, $n_{+}$, required to meet the precision requirement.\n- **Objective 2**: Find the minimum total number of enrolled subjects, $N$, such that the expected number of diseased subjects is at least $n_{+}$.\n\n### Step 2: Validate Using Extracted Givens\n- **Scientifically Grounded**: The problem is rooted in standard biostatistical methods for clinical trial design. The use of sensitivity as a performance metric, the Wilson score confidence interval for a binomial proportion, and the calculation of sample size based on a desired precision are all established and fundamental concepts in regulatory science and statistics. The scenario described is realistic for planning a pivotal study for a Software as a Medical Device (SaMD).\n- **Well-Posed**: The problem provides all necessary information to calculate the required sample sizes. The objectives are clearly stated and lead to a unique, well-defined integer solution.\n- **Objective**: The problem is stated using precise, unambiguous technical terminology. There are no subjective or opinion-based components.\n\n### Step 3: Verdict and Action\nThe problem is valid. It is scientifically sound, well-posed, objective, and contains all necessary information for a solution. I will proceed with the derivation.\n\n### Derivation of the Solution\n\nThe solution proceeds in two parts. First, we determine the minimum number of diseased subjects ($n_{+}$) needed to achieve the desired confidence interval width for sensitivity. Second, we calculate the total cohort size ($N$) required to expect at least this number of diseased subjects, given the disease prevalence.\n\n**Part 1: Minimum Number of Diseased Subjects ($n_{+}$) for Sensitivity Estimation**\n\nSensitivity ($S_e$) is a binomial proportion, estimated as $\\hat{S_e} = \\frac{TP}{n_{+}}$, where $TP$ is the number of true positive classifications and $n_{+}$ is the total number of subjects with the disease.\n\nThe Wilson score confidence interval for a proportion $p$ based on $n$ trials is given by:\n$$ \\frac{\\hat{p} + \\frac{z^2}{2n} \\pm z \\sqrt{\\frac{\\hat{p}(1-\\hat{p})}{n} + \\frac{z^2}{4n^2}}}{1 + \\frac{z^2}{n}} $$\nThe half-width ($W$) of this interval is the term following the $\\pm$ sign:\n$$ W = \\frac{z \\sqrt{\\frac{\\hat{p}(1-\\hat{p})}{n} + \\frac{z^2}{4n^2}}}{1 + \\frac{z^2}{n}} $$\nIn our context, the proportion is sensitivity ($p \\rightarrow S_e$) and the number of trials is the number of diseased subjects ($n \\rightarrow n_{+}$). For sample size planning, we use the expected sensitivity, $S_e = 0.85$, in place of the yet-to-be-observed estimate $\\hat{S_e}$. The requirement is $W \\le 0.05$.\nLet's substitute the known values into the inequality for the half-width:\n- $S_e = 0.85$\n- $z = 1.96$\n- $W_{max} = 0.05$\n\n$$ \\frac{1.96 \\sqrt{\\frac{0.85(1-0.85)}{n_{+}} + \\frac{1.96^2}{4n_{+}^2}}}{1 + \\frac{1.96^2}{n_{+}}} \\le 0.05 $$\nTo solve for $n_{+}$, we rearrange the inequality:\n$$ 1.96 \\sqrt{\\frac{0.1275}{n_{+}} + \\frac{3.8416}{4n_{+}^2}} \\le 0.05 \\left(1 + \\frac{3.8416}{n_{+}}\\right) $$\n$$ 1.96 \\sqrt{\\frac{0.1275}{n_{+}} + \\frac{0.9604}{n_{+}^2}} \\le 0.05 + \\frac{0.19208}{n_{+}} $$\nSquaring both sides (which is permissible as all terms are positive):\n$$ (1.96)^2 \\left(\\frac{0.1275}{n_{+}} + \\frac{0.9604}{n_{+}^2}\\right) \\le \\left(0.05 + \\frac{0.19208}{n_{+}}\\right)^2 $$\n$$ 3.8416 \\left(\\frac{0.1275}{n_{+}} + \\frac{0.9604}{n_{+}^2}\\right) \\le (0.05)^2 + 2(0.05)\\left(\\frac{0.19208}{n_{+}}\\right) + \\left(\\frac{0.19208}{n_{+}}\\right)^2 $$\n$$ \\frac{0.489804}{n_{+}} + \\frac{3.68961264}{n_{+}^2} \\le 0.0025 + \\frac{0.019208}{n_{+}} + \\frac{0.0368947264}{n_{+}^2} $$\nTo solve for $n_{+}$, we multiply the entire inequality by $n_{+}^2$ (which is positive) and rearrange the terms to form a quadratic inequality of the form $an_{+}^2 + bn_{+} + c \\ge 0$:\n$$ 0.489804 n_{+} + 3.68961264 \\le 0.0025 n_{+}^2 + 0.019208 n_{+} + 0.0368947264 $$\n$$ 0 \\le 0.0025 n_{+}^2 + (0.019208 - 0.489804) n_{+} + (0.0368947264 - 3.68961264) $$\n$$ 0 \\le 0.0025 n_{+}^2 - 0.470596 n_{+} - 3.6527179136 $$\nWe find the roots of the corresponding quadratic equation $0.0025 n_{+}^2 - 0.470596 n_{+} - 3.6527179136 = 0$ using the quadratic formula, $n_{+} = \\frac{-b \\pm \\sqrt{b^2 - 4ac}}{2a}$:\n- $a = 0.0025$\n- $b = -0.470596$\n- $c = -3.6527179136$\n\n$$ b^2 - 4ac = (-0.470596)^2 - 4(0.0025)(-3.6527179136) $$\n$$ b^2 - 4ac = 0.221460592016 + 0.036527179136 = 0.257987771152 $$\n$$ \\sqrt{b^2 - 4ac} \\approx 0.50792595 $$\nThe roots are:\n$$ n_{+} = \\frac{0.470596 \\pm 0.50792595}{2(0.0025)} = \\frac{0.470596 \\pm 0.50792595}{0.005} $$\nSince $n_{+}$ must be a positive number, we take the positive root:\n$$ n_{+} = \\frac{0.470596 + 0.50792595}{0.005} = \\frac{0.97852195}{0.005} \\approx 195.70439 $$\nThe inequality $an_{+}^2 + bn_{+} + c \\ge 0$ holds for $n_{+}$ greater than or equal to the larger root. Therefore, we must have $n_{+} \\ge 195.70439$. As the number of subjects must be an integer, we take the smallest integer satisfying this condition, which is the ceiling of the value:\n$$ n_{+} = \\lceil 195.70439 \\rceil = 196 $$\nSo, a minimum of $196$ diseased subjects are required.\n\n**Part 2: Minimum Total Enrollment ($N$)**\n\nThe problem states that the study cohort must reflect the real-world disease prevalence, given as $\\pi = 0.20$. The expected number of diseased subjects, $E[n_{+}]$, in a total cohort of size $N$ is given by:\n$$ E[n_{+}] = N \\pi $$\nThe requirement is that this expected number must be at least the minimum required number of diseased subjects, $n_{+}$, which we found to be $196$.\n$$ E[n_{+}] \\ge n_{+} $$\n$$ N \\pi \\ge 196 $$\nSubstituting $\\pi = 0.20$:\n$$ N(0.20) \\ge 196 $$\nSolving for $N$:\n$$ N \\ge \\frac{196}{0.20} $$\n$$ N \\ge 980 $$\nThe minimum total enrollment $N$ must be an integer. Since the lower bound is exactly an integer, the minimum total enrollment is $980$.",
            "answer": "$$ \\boxed{980} $$"
        }
    ]
}