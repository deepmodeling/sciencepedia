{
    "hands_on_practices": [
        {
            "introduction": "医学影像（如MRI扫描）在不同轴向上常具有不同的分辨率，这一特性被称为各向异性。本练习将挑战你设计一个能够适应这种特性而无需通过重采样扭曲数据的3D CNN架构。通过精心选择步长、空洞率和卷积核形状，你将学习如何构建能感知数据底层物理空间的模型，并计算其最终的感受野。",
            "id": "4534271",
            "problem": "一个端到端的放射组学流程处理三维磁共振成像（MRI）体数据，其体素间距沿 $(x,y,z)$ 轴具有各向异性，为 $(1.0, 1.0, 5.0)$ 毫米。考虑一个三层三维卷积神经网络（CNN），其目的是为下游的监督学习提取特征。您必须设计一个步幅和扩张方案，该方案在不重采样输入体数据的情况下，遵循采集的各向异性。该设计必须满足以下所有约束条件，这些约束条件反映了在此类设置中的标准工程选择：\n\n- 在第一层使用单位步幅 $(1,1,1)$，以保留输入端的高频细节。\n- 在三层网络中实现总共为 $4$ 的平面内下采样因子，仅应用于 $x$ 和 $y$ 轴，而 $z$ 轴方向无下采样。具体来说，在三层中的两层使用步幅 $(2,2,1)$，在剩下的一层使用单位步幅 $(1,1,1)$。\n- 为遵循切片间的各向异性，在平面内感受野（以物理单位计）达到至少一个切片厚度之前，禁止任何切片间的混合。具体来说，在任何前一层平面内感受野（以物理单位计）严格小于 $5$ 毫米的层中，沿 $z$ 轴的卷积核深度应为 $1$（即 $k_{z}=1$）；从前一层平面内感受野（以物理单位计）至少为 $5$ 毫米的第一层开始，沿 $z$ 轴的卷积核深度应为 $3$（即 $k_{z}=3$）。\n- 沿所有轴使用与上述约束一致的最小正整数扩张率。\n\n假设所有卷积核沿 $x$ 和 $y$ 轴的空间尺寸均为 $3$（即 $k_{x}=k_{y}=3$），选择零填充以使输出与输入中心体素对齐，并且没有跳跃连接。在推导各层感受野增长时，独立处理每个空间轴。\n\n仅使用在步幅和扩张卷积复合下感受野增长的基本定义，确定在您设计的方案下，第三层之后沿每个轴的最终有效感受野范围（以物理单位毫米计）。为清晰起见，将沿给定轴的有效感受野范围定义为：能够影响该轴上单个输出元素的最小连续输入段的物理长度，其值等于该轴上感受野内的输入体素数量乘以该轴上的体素间距。\n\n最终答案以行向量 $\\begin{pmatrix} R_{x}  R_{y}  R_{z} \\end{pmatrix}$ 的形式表示，单位为毫米。无需四舍五入。",
            "solution": "问题陈述具有科学依据、适定、客观且内部一致。唯一解所需的所有数据和约束均已提供。该问题是在医学成像的实际设计场景中应用卷积神经网络基本原理的一个有效练习。因此，有必要提供完整解答。\n\n问题的核心是根据一组约束条件确定一个三层3D CNN的设计参数——具体来说是每一层的步幅、卷积核尺寸和扩张率——然后计算由此产生的有效感受野。沿单个轴在第 $i$ 层后的有效感受野 $R_i$（以体素为单位）可以递归计算。设 $R_{i-1}$ 为前一层后的感受野（$R_0=1$），$k_i$ 为第 $i$ 层的卷积核尺寸，$d_i$ 为第 $i$ 层的扩张率，$S_{i-1}$ 为截至第 $i-1$ 层的累积步幅乘积，定义为 $S_{i-1} = \\prod_{j=1}^{i-1} s_j$（$S_0 = 1$）。递归公式为：\n$$R_i = R_{i-1} + (k_i - 1) d_i S_{i-1}$$\n我们将对每个空间轴 $(x, y, z)$ 独立应用此公式。最终以物理单位表示的感受野范围是感受野的体素数乘以相应的体素间距。\n\n给定的参数是：\n- 体素间距: $v = (v_x, v_y, v_z) = (1.0, 1.0, 5.0)$ 毫米。\n- 层数: $3$。\n- 平面内卷积核尺寸: $k_{ix} = k_{iy} = 3$，其中 $i \\in \\{1, 2, 3\\}$。\n\n我们逐层确定参数并计算感受野的增长。\n\n**步骤 1：确定网络参数**\n\n**第1层：**\n- **步幅 ($s_1$)：** 问题要求在第一层使用单位步幅。因此，$s_1 = (s_{1x}, s_{1y}, s_{1z}) = (1, 1, 1)$。\n- **扩张率 ($d_1$)：** 问题要求使用最小的正整数扩张率。在没有其他约束强制要求更大值的情况下，最小正整数为 $1$。因此，$d_1 = (d_{1x}, d_{1y}, d_{1z}) = (1, 1, 1)$。\n- **卷积核尺寸 ($k_1$)：** 给定 $k_{1x}=3$ 和 $k_{1y}=3$。对于 $k_{1z}$，我们必须评估各向异性约束。第1层的“前一层平面内感受野”是输入的感受野，即单个体素。其物理尺寸为 $\\max(1 \\cdot v_x, 1 \\cdot v_y) = \\max(1.0, 1.0) = 1.0$ 毫米。由于 $1.0  5.0$，约束要求无切片间混合。因此，$k_{1z} = 1$。\n- **第1层参数：** $s_1=(1,1,1)$, $d_1=(1,1,1)$, $k_1=(3,3,1)$。\n\n**第2层：**\n- **步幅 ($s_2$)：** 平面内总下采样因子必须为 $4$，通过在三层中的两层使用步幅 $(2,2,1)$ 实现。由于第1层使用单位步幅，因此第2层和第3层必须使用步幅 $(2,2,1)$。所以，$s_2 = (s_{2x}, s_{2y}, s_{2z}) = (2, 2, 1)$。\n- **扩张率 ($d_2$)：** 使用最小正整数，因此 $d_2 = (d_{2x}, d_{2y}, d_{2z}) = (1, 1, 1)$。\n- **卷积核尺寸 ($k_2$)：** 给定 $k_{2x}=3$ 和 $k_{2y}=3$。为了确定 $k_{2z}$，我们首先需要第1层后的平面内感受野。\n  - 第2层之前的累积步幅乘积为 $S_1 = s_1 = (1,1,1)$。\n  - 第1层后的感受野（以体素为单位）($R_1$)：\n    - $R_{1x} = R_0 + (k_{1x}-1)d_{1x}S_0 = 1 + (3-1) \\cdot 1 \\cdot 1 = 3$。\n    - $R_{1y} = R_0 + (k_{1y}-1)d_{1y}S_0 = 1 + (3-1) \\cdot 1 \\cdot 1 = 3$。\n  - 前一层的平面内物理感受野是 $\\max(R_{1x} \\cdot v_x, R_{1y} \\cdot v_y) = \\max(3 \\cdot 1.0, 3 \\cdot 1.0) = 3.0$ 毫米。由于 $3.0  5.0$，约束要求 $k_{2z} = 1$。\n- **第2层参数：** $s_2=(2,2,1)$, $d_2=(1,1,1)$, $k_2=(3,3,1)$。\n\n**第3层：**\n- **步幅 ($s_3$)：** 如上所述，$s_3 = (s_{3x}, s_{3y}, s_{3z}) = (2, 2, 1)$。平面内总步幅乘积为 $s_{1x}s_{2x}s_{3x} = 1 \\cdot 2 \\cdot 2 = 4$，满足约束。\n- **扩张率 ($d_3$)：** 使用最小正整数，因此 $d_3 = (d_{3x}, d_{3y}, d_{3z}) = (1, 1, 1)$。\n- **卷积核尺寸 ($k_3$)：** 给定 $k_{3x}=3$ 和 $k_{3y}=3$。为了确定 $k_{3z}$，我们首先需要第2层后的平面内感受野。\n  - 第3层之前的累积步幅乘积为 $S_2 = (s_{1x}s_{2x}, s_{1y}s_{2y}, s_{1z}s_{2z}) = (1 \\cdot 2, 1 \\cdot 2, 1 \\cdot 1) = (2, 2, 1)$。\n  - 第2层后的感受野（以体素为单位）($R_2$)：\n    - $R_{2x} = R_{1x} + (k_{2x}-1)d_{2x}S_{1x} = 3 + (3-1) \\cdot 1 \\cdot 1 = 5$。\n    - $R_{2y} = R_{1y} + (k_{2y}-1)d_{2y}S_{1y} = 3 + (3-1) \\cdot 1 \\cdot 1 = 5$。\n  - 前一层的平面内物理感受野是 $\\max(R_{2x} \\cdot v_x, R_{2y} \\cdot v_y) = \\max(5 \\cdot 1.0, 5 \\cdot 1.0) = 5.0$ 毫米。“严格小于 $5$ 毫米”的条件现在不成立。规则规定，从前一层感受野“至少为 $5$ 毫米”的第一层开始使用 $k_z=3$。这个条件在第3层首次满足。因此，$k_{3z} = 3$。\n- **第3层参数：** $s_3=(2,2,1)$, $d_3=(1,1,1)$, $k_3=(3,3,3)$。\n\n**步骤 2：计算最终感受野**\n\n现在我们使用上面确定的参数计算最终的感受野（以体素为单位），$R_3$。\n\n**沿x轴：**\n- $R_{0x}=1$\n- $R_{1x}=3$\n- $R_{2x}=5$\n- $R_{3x} = R_{2x} + (k_{3x}-1)d_{3x}S_{2x} = 5 + (3-1) \\cdot 1 \\cdot 2 = 5 + 4 = 9$。\n\n**沿y轴：**\n- $R_{0y}=1$\n- $R_{1y}=3$\n- $R_{2y}=5$\n- 根据与x轴的对称性，$R_{3y} = 9$。\n\n**沿z轴：**\n- 我们必须从头开始计算感受野的增长。\n- $R_{0z}=1$。\n- 第1层: $R_{1z} = R_{0z} + (k_{1z}-1)d_{1z}S_{0z} = 1 + (1-1) \\cdot 1 \\cdot 1 = 1$。\n- 第2层: $R_{2z} = R_{1z} + (k_{2z}-1)d_{2z}S_{1z} = 1 + (1-1) \\cdot 1 \\cdot 1 = 1$。\n- 第3层: $R_{3z} = R_{2z} + (k_{3z}-1)d_{3z}S_{2z} = 1 + (3-1) \\cdot 1 \\cdot 1 = 1 + 2 = 3$。\n\n最终的感受野（以体素为单位）是 $R_3 = (R_{3x}, R_{3y}, R_{3z}) = (9, 9, 3)$。\n\n**步骤 3：转换为物理单位**\n\n问题要求以物理单位（毫米）表示的最终有效感受野范围。我们将体素数量乘以体素间距 $v = (1.0, 1.0, 5.0)$ 毫米。\n- 沿x轴的范围: $R_x = R_{3x} \\cdot v_x = 9 \\cdot 1.0 = 9.0$ 毫米。\n- 沿y轴的范围: $R_y = R_{3y} \\cdot v_y = 9 \\cdot 1.0 = 9.0$ 毫米。\n- 沿z轴的范围: $R_z = R_{3z} \\cdot v_z = 3 \\cdot 5.0 = 15.0$ 毫米。\n\n最终有效感受野范围是 $(9.0, 9.0, 15.0)$ 毫米。",
            "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n9.0  9.0  15.0\n\\end{pmatrix}\n}\n$$"
        },
        {
            "introduction": "构建一个可靠的端到端模型，不仅需要强大的架构，更需要严谨的评估方法。本练习将探讨放射组学中一个关键但微妙的陷阱：因患者数据划分不当而导致的数据泄漏。你将分析为何标准交叉验证会产生具有误导性的乐观结果，并学习应用稳健的、以患者为单位的数据划分策略，以确保模型的性能能够泛化到新的未知患者。",
            "id": "4534196",
            "problem": "您正在为一个基于医学影像的二元放射组学任务训练一个端到端的卷积神经网络（CNN）。对于每个索引为 $p \\in \\{1,\\dots,P\\}$ 的患者，您有一个3D体积和一个单一的患者级别标签 $y_p \\in \\{0,1\\}$。您从每位患者身上提取索引为 $i \\in \\{1,\\dots,n_p\\}$ 的2D切片或3D图块，得到观测值 $(x_{p,i}, y_p)$。假设存在一个数据生成过程，其中包含一个患者特异性潜因子 $\\theta_p$（编码肿瘤表型、采集方案、扫描仪、预处理的特殊情况），并且患者内部的观测值在给定 $\\theta_p$ 的条件下满足条件独立性：对于固定的 $p$，$(x_{p,i} \\mid \\theta_p)$ 在 $i$ 上是独立的，但边缘上，对于 $i \\neq i'$，$(x_{p,i})$ 和 $(x_{p,i'})$ 通过 $\\theta_p$ 呈正相关。在不同患者之间，$(\\theta_p)$ 是独立同分布的。\n\n设一个学习算法通过在训练集 $\\mathcal{S}_{\\text{train}}$ 上进行经验风险最小化来生成模型 $f$，最小化经验风险 $\\hat{R}(f;\\mathcal{S}_{\\text{train}}) = \\frac{1}{n_{\\text{train}}} \\sum_{(x,y) \\in \\mathcal{S}_{\\text{train}}} \\ell(f(x),y)$，其中损失函数 $\\ell$ 是有界的。标准的k折交叉验证（CV）是在样本独立同分布（i.i.d.）的假设下估计泛化误差的。考虑一下，如果按切片或图块随机划分（这样来自同一患者的切片可能同时出现在训练集和验证集中），与按患者划分（这样没有患者会贡献于多个折）相比，会发生什么情况。\n\n仅使用独立性、经验风险的核心定义以及交叉验证中有效风险估计的i.i.d.假设，推断患者内相关性对估计的泛化误差的影响。然后，在这个基于CNN的端到端放射组学设置中，确定以下哪些陈述正确描述了泄露风险和稳健的划分策略。选择所有适用项。\n\nA. 如果按切片划分，使得来自同一患者的切片可能同时出现在训练集和验证集中，CNN可以学习到与 $\\theta_p$ 相关的患者特异性因素（例如扫描仪特有的强度模式），导致验证损失相对于在真正未见患者上的表现被乐观地低估。一个稳健的替代方案是使用患者标识符作为分组依据的分组k折交叉验证，这样每个患者都恰好只出现在一个折中。\n\nB. 如果您提取重叠的图块，但确保来自同一患者的图块不会跨越训练集和验证集，数据泄露仍然存在，因为来自不同患者的图块在视觉上可能相似；因此，唯一稳健的策略是避免任何形式的交叉验证，并在用于训练的相同数据上进行评估。\n\nC. 按切片进行分层划分，以匹配每个折中阳性切片的比例，可以保证训练样本和验证样本的独立性，从而消除泄露，即使来自同一患者的切片出现在多个折中。\n\nD. 在患者是i.i.d.的假设下，留一患者交叉验证（Leave-One-Patient-Out CV）可以对新患者的误差产生一个近似无偏的估计；为避免在模型选择过程中发生泄露，应在一个同样按患者划分的内层循环中调整超参数（嵌套交叉验证）。\n\nE. 在图块上训练CNN时，可以在划分数据集之前计算全局预处理统计量（例如，用于强度归一化的均值和标准差），因为这些统计量与标签无关，不会导致数据泄露。",
            "solution": "问题陈述描述了医学图像分析中的一个常见场景，即机器学习模型在具有层次结构的数据上进行训练。具体来说，多个观测值（切片或图块）来自单个主体（患者），这导致了主体内相关性。核心任务是在存在这种相关性的情况下，评估关于不同交叉验证策略有效性的陈述。\n\n### 问题验证\n\n**步骤1：提取给定条件**\n- **领域**：用于二元放射组学任务的端到端卷积神经网络（CNN）。\n- **数据来源**：医学图像。\n- **数据结构**：\n    - 有 $P$ 个患者，索引为 $p \\in \\{1,\\dots,P\\}$。\n    - 每个患者 $p$ 有一个单一的患者级别标签 $y_p \\in \\{0,1\\}$。\n    - 从每个患者 $p$ 中，提取 $n_p$ 个观测值（2D切片或3D图块），索引为 $i \\in \\{1,\\dots,n_p\\}$。\n    - 每个观测值是一对 $(x_{p,i}, y_p)$，其中标签 $y_p$ 对来自患者 $p$ 的所有观测值都是恒定的。\n- **数据生成过程**：\n    - 每个患者 $p$ 都存在一个患者特异性潜因子 $\\theta_p$。\n    - 在一个患者 $p$ 内部，给定 $\\theta_p$，观测值 $(x_{p,i} \\mid \\theta_p)$ 在 $i$ 上是条件独立的。\n    - 边缘上，对于一个固定的患者 $p$，当 $i \\neq i'$ 时，观测值 $(x_{p,i})$ 和 $(x_{p,i'})$ 由于共同因子 $\\theta_p$ 而正相关。\n    - 在不同患者之间，潜因子 $(\\theta_p)$ 是独立同分布（i.i.d.）的。这意味着不同的患者是i.i.d.单元。\n- **学习算法**：\n    - 在训练集 $\\mathcal{S}_{\\text{train}}$ 上进行经验风险最小化。\n    - 目标是最小化经验风险 $\\hat{R}(f;\\mathcal{S}_{\\text{train}}) = \\frac{1}{n_{\\text{train}}} \\sum_{(x,y) \\in \\mathcal{S}_{\\text{train}}} \\ell(f(x),y)$。\n    - 损失函数 $\\ell$ 是有界的。\n- **评估背景**：\n    - 使用标准的k折交叉验证（CV）来估计泛化误差。\n    - 标准的CV程序假设样本是i.i.d.的。\n- **问题**：推断患者内相关性对泛化误差估计的影响，并确定关于数据泄露和稳健划分策略的正确陈述。\n\n**步骤2：使用提取的给定条件进行验证**\n该问题陈述在科学上和方法论上都是合理的。\n- **科学依据**：这个前提非常现实。在医学成像中，来自同一患者（甚至同一扫描仪）的数据共享一些特征（例如，解剖结构、图像纹理、噪声模式、重建伪影），这些特征在其他患者的数据中是不存在的。使用潜因子 $\\theta_p$ 的概念是对此类层次相关性进行建模的一种标准且适当的方式。\n- **定义明确**：问题定义清晰。它为数据建立了一个明确的统计模型，并要求在此模型下分析一个标准的机器学习评估程序（交叉验证）。违反i.i.d.假设的后果是统计学习理论中的一个核心主题。\n- **客观性**：问题使用精确、客观和形式化的数学语言陈述。它避免了模糊性和主观性。\n\n**步骤3：结论与行动**\n问题是有效的。它描述了将机器学习应用于结构化数据时的一个典型挑战，并且没有缺陷。可以进行求解过程。\n\n### 推导与选项分析\n\n交叉验证的基本原则是估计在新未见数据上的预期预测误差（泛化误差）。为了使这个估计是无偏的，验证集必须在统计上独立于训练集。问题指出，患者是i.i.d.的，但一个患者内部的观测值（切片/图块）不是。因此，患者是数据的独立单元。任何有效的交叉验证划分方案都必须尊重这种独立性，这意味着来自单个患者的所有数据必须只属于一个折。\n\n如果通过在切片/图块级别进行划分而违反了这一原则，训练集和验证集将包含相关的样本。例如，如果切片 $x_{p,i}$ 在训练集中，而切片 $x_{p,j}$（来自同一患者 $p$）在验证集中，模型 $f$ 可以从 $x_{p,i}$ 中学到与 $\\theta_p$ 相关的患者特异性、不可泛化的特征，并利用这些“泄露”的信息对 $x_{p,j}$ 做出更容易的预测。这导致验证误差被人为地降低，这种现象称为数据泄露，从而导致对模型在真正新患者上的性能产生乐观的偏置估计。\n\n**选项 A：如果按切片划分，使得来自同一患者的切片可能同时出现在训练集和验证集中，CNN可以学习到与 $\\theta_p$ 相关的患者特异性因素（例如扫描仪特有的强度模式），导致验证损失相对于在真正未见患者上的表现被乐观地低估。一个稳健的替代方案是使用患者标识符作为分组依据的分组k折交叉验证，这样每个患者都恰好只出现在一个折中。**\n\n这个陈述是对问题及其解决方案的精确而准确的描述。\n1.  **问题描述**：按切片/图块划分允许来自同一患者的相关数据同时存在于训练集和验证集中。CNN足够强大，可以学习到患者特异性的潜因子 $\\theta_p$（例如，扫描仪伪影、特定的组织纹理）。这使得模型能够“识别”验证集中的患者，而不是学习与标签 $y_p$ 相关的可泛化特征。这导致验证损失低于真实的泛化误差，从而产生乐观偏差。\n2.  **建议的解决方案**：分组k折交叉验证（也称为按主体或按患者的交叉验证）将来自单个患者的所有数据视为一个不可分割的组。通过将每个患者组精确地分配到一个折中，它确保了训练集和验证集由不相交的患者集组成。由于患者是i.i.d.的，这使得训练折和验证折是独立的，满足了对泛化误差进行无偏估计的核心要求。\n这个陈述完全符合层次结构数据的统计学习原理。\n\n**结论：正确。**\n\n**选项 B：如果您提取重叠的图块，但确保来自同一患者的图块不会跨越训练集和验证集，数据泄露仍然存在，因为来自不同患者的图块在视觉上可能相似；因此，唯一稳健的策略是避免任何形式的交叉验证，并在用于训练的相同数据上进行评估。**\n\n这个陈述在根本上是错误的。\n第一个条件，“确保来自同一患者的图块不会跨越训练集和验证集”，描述了*正确*的按患者划分的策略。声称数据泄露仍然发生是因为“来自不同患者的图块在视觉上可能相似”，这是对数据泄露和机器学习目标的误解。模型*应该*在来自不同患者的视觉相似的图块中寻找能够区分类别 $y=0$ 和 $y=1$ 的模式。这是学习任务，而不是一种泄露。当关于验证集样本的信息（超出了在一般群体中可获得的信息）存在于训练集中时，才会发生泄露。最后的结论，即应该“在用于训练的相同数据上进行评估”，是衡量训练误差的定义，而训练误差是众所周知的一个糟糕且有偏的泛化性能估计器。\n\n**结论：不正确。**\n\n**选项 C：按切片进行分层划分，以匹配每个折中阳性切片的比例，可以保证训练样本和验证样本的独立性，从而消除泄露，即使来自同一患者的切片出现在多个折中。**\n\n这个陈述混淆了分层与确保独立性。分层是一种技术，用于确保每个折具有相似的目标变量（或其他重要特征）的分布，从而减少交叉验证估计器的方差。然而，它不解决样本相关的问题。如果来自同一患者的切片出现在多个折中，那么无论切片标签是否平衡，这些折都不是独立的。通过 $\\theta_p$ 的相关性持续存在，数据泄露也同样存在。因此，在这种情况下，按切片进行分层并不能保证独立性，也不能消除泄露。\n\n**结论：不正确。**\n\n**选项 D：在患者是i.i.d.的假设下，留一患者交叉验证（LOPO-CV）可以对新患者的误差产生一个近似无偏的估计；为避免在模型选择过程中发生泄露，应在一个同样按患者划分的内层循环中调整超参数（嵌套交叉验证）。**\n\n这个陈述正确地描述了两个先进且稳健的评估概念。\n1.  **留一患者交叉验证（LOPO-CV）**：这是分组k折交叉验证的一个特例，其中折数 $k$ 等于患者数 $P$。在每次迭代中，留出一个患者用于验证，模型在其余 $P-1$ 个患者上进行训练。由于患者是i.i.d.的，这个过程提供了对新患者泛化误差的近似无偏估计（尽管它可能有高方差）。\n2.  **用于超参数调整的嵌套交叉验证**：当使用交叉验证来选择超参数时，在相同数据上报告最佳模型的性能会导致乐观偏差，因为超参数对该数据的特定分区“过拟合”了。为了获得对*整个建模流程*（包括超参数选择）性能的无偏估计，需要使用嵌套交叉验证。外层循环划分患者用于最终的误差估计。内层循环仅在外层循环的训练集上操作，进行另一次按患者的划分来选择最佳超参数。这确保了超参数选择过程永远不会看到外层循环的验证数据，从而防止了信息泄露。\n\n**结论：正确。**\n\n**选项 E：在图块上训练CNN时，可以在划分数据集之前计算全局预处理统计量（例如，用于强度归一化的均值和标准差），因为这些统计量与标签无关，不会导致数据泄露。**\n\n这个陈述描述了一种微妙但明确的数据泄露形式。任何数据驱动的预处理步骤都必须专门在训练数据上“拟合”。如果像用于归一化的均值和标准差这样的统计量是在整个数据集（训练+验证+测试）上计算的，那么来自验证集和测试集的信息就已经“泄露”到了训练过程中。模型在已经使用其将被评估的数据的属性进行缩放的数据上进行训练。这违反了验证集应被视为未见数据的原则。虽然影响可能很小，但这违反了正确的协议，并可能导致乐观的性能估计。正确的程序是仅在训练折上计算均值和标准差，然后将这个固定的变换应用于验证折和测试折。声称这样做是“安全的”因为它是“标签无关的”是错误的；泄露是关于信息，而不仅仅是标签。\n\n**结论：不正确。**",
            "answer": "$$\\boxed{AD}$$"
        },
        {
            "introduction": "端到端模型常被称为“黑箱”，但我们有技术可以窥探其内部并理解其推理过程。本练习将介绍梯度加权类激活映射（Grad-CAM），这是一种强大的可视化方法，用于展示CNN为做出预测而关注图像的哪些部分。你将推导Grad-CAM公式并将其应用于一个具体案例，从而获得使AI模型更加透明和可解释的实践经验。",
            "id": "4534276",
            "problem": "考虑一个端到端的放射组学系统，其中训练一个三维卷积神经网络（CNN）以根据输入的体积图像块预测目标临床终点的标量 pre-softmax 类别分数 $y$。设最后一个卷积块输出 $K$ 个特征图 $\\{A^{k}\\}_{k=1}^{K}$，其中每个 $A^{k}$ 由空间坐标 $(i,j,l)$ 索引，维度为 $I \\times J \\times L$。定义 $Z = I \\cdot J \\cdot L$。梯度加权类激活映射（Grad-CAM）方法根据 $y$ 对特征图的偏导数为每个通道分配一个重要性权重，并生成一个空间热力图，其正值表示对预测有积极贡献的区域。\n\n从链式求导法则和 $y$ 相对于激活值 $\\{A^{k}\\}$ 的一阶泰勒展开出发，推导 Grad-CAM 热力图的封闭形式表达式，该表达式应使用特征图 $\\{A^{k}\\}$ 和一个通过对偏导数 $\\frac{\\partial y}{\\partial A^{k}_{i,j,l}}$ 在空间索引 $(i,j,l)$ 上进行全局平均而构建的逐通道标量权重来表示。证明使用修正非线性单元以仅保留最终热力图中积极贡献区域的合理性。您的推导应基于关于 CNN 中反向传播和激活重要性的公认事实，而不是假设任何预先指定的最终公式。\n\n然后，针对一个代表体积放射组学 CNN 的特定案例，令 $K = 2$，$I = 2$，$J = 2$，$L = 1$，因此 $Z = 4$。假设特征图为\n$$\nA^{1} = \\begin{pmatrix}\n1  -2 \\\\\n0  3\n\\end{pmatrix}, \\quad\nA^{2} = \\begin{pmatrix}\n-1  2 \\\\\n1  -2\n\\end{pmatrix},\n$$\n由 $(i,j,l)$ 索引，其中所有条目的 $l=1$。且 pre-softmax 分数 $y$ 相对于激活值的偏导数为\n$$\n\\frac{\\partial y}{\\partial A^{1}} = \\begin{pmatrix}\n4  -1 \\\\\n2  0\n\\end{pmatrix}, \\quad\n\\frac{\\partial y}{\\partial A^{2}} = \\begin{pmatrix}\n-2  1 \\\\\n-1  2\n\\end{pmatrix}.\n$$\n计算由全局平均通道权重和修正非线性单元在体素 $(i,j,l) = (1,1,1)$ 处产生的 Grad-CAM 热力图值。您的最终数值答案应为精确值，不进行四舍五入。\n\n最后，解释在体积放射组学的背景下，选择提取特征图 $\\{A^{k}\\}$ 的卷积层如何影响最终的 Grad-CAM 热力图，讨论其在分辨率、语义特异性和梯度可靠性方面的影响。您的解释应有科学依据且自洽，但最终答案必须是上面要求的单一数值，不带单位。",
            "solution": "问题陈述被认为是有效的。它在科学上基于深度学习和模型可解释性的原理，特别是梯度加权类激活映射（Grad-CAM）方法。该问题是适定的，为计算唯一解提供了所有必要的定义和数值数据。语言客观，设置内部一致且可形式化。\n\n我们的任务是推导 Grad-CAM 热力图的表达式，然后计算其在特定情况下的值。推导必须源于应用于神经网络的微积分基本原理。\n\n首先，我们推导 Grad-CAM 热力图的一般形式。pre-softmax 类别分数 $y$ 是最后一个卷积层特征图 $\\{A^{k}\\}_{k=1}^{K}$ 中激活值的标量函数。在特征图 $k$ 中体素 $(i,j,l)$ 处的特定激活值（表示为 $A^{k}_{i,j,l}$）对分数 $y$ 的影响由偏导数 $\\frac{\\partial y}{\\partial A^{k}_{i,j,l}}$ 捕获。这个梯度是通过反向传播计算的。\n\n将 $y$ 在某个基线（例如，零激活值）附近进行一阶泰勒展开，可以将分数近似为激活值的线性函数，其中梯度作为系数：\n$$ y \\approx y_0 + \\sum_{k=1}^{K} \\sum_{i=1}^{I} \\sum_{j=1}^{J} \\sum_{l=1}^{L} \\frac{\\partial y}{\\partial A^{k}_{i,j,l}} A^{k}_{i,j,l} $$\nGrad-CAM 通过首先确定整个特征图（或通道）$k$ 的“重要性”来简化这种高维关系。这是通过将空间梯度信息压缩成单个标量权重 $\\alpha_k$ 来实现的。根据问题规定，这个权重是通过对该通道的梯度执行全局平均池化来获得的：\n$$ \\alpha_k = \\frac{1}{Z} \\sum_{i=1}^{I} \\sum_{j=1}^{J} \\sum_{l=1}^{L} \\frac{\\partial y}{\\partial A^{k}_{i,j,l}} $$\n这里，$Z = I \\cdot J \\cdot L$ 是一个特征图中空间位置（体素）的总数。这个权重 $\\alpha_k$ 代表通道 $k$ 对分数 $y$ 每单位激活值的平均贡献。\n\n然后，Grad-CAM 热力图 $L_{\\text{Grad-CAM}}$ 被构建为特征图的加权线性组合，其权重是刚刚定义的 $\\alpha_k$ 值。这个中间“原始”热力图在特定体素 $(i,j,l)$ 处的值为：\n$$ L_{\\text{raw}}(i,j,l) = \\sum_{k=1}^{K} \\alpha_k A^{k}_{i,j,l} $$\n这个表达式将由通道重要性 $\\alpha_k$ 捕获的高级语义信息定位到由特征图 $A^k$ 定义的空间网格上。$L_{\\text{raw}}$ 中的高正值表示对应的体素在对类别分数 $y$ 有强正向影响的特征图中被强烈激活。\n\n最后，问题指出应用了修正非线性单元来仅保留有积极贡献的区域。这对应于应用修正线性单元（ReLU）函数，它将所有负值设置为零。因此，最终的 Grad-CAM 热力图是：\n$$ L_{\\text{Grad-CAM}}(i,j,l) = \\text{ReLU}(L_{\\text{raw}}(i,j,l)) = \\max(0, L_{\\text{raw}}(i,j,l)) $$\n这一步骤的理由是，我们通常感兴趣的是可视化输入的哪些部分为感兴趣的类别提供了积极的证据。$L_{\\text{raw}}$ 中的负值可能含糊不清，它可能源于负权重通道中的正激活，也可能源于正权重通道中的负激活。通过将这些值过滤掉，生成的热力图仅突出显示支持预测的区域。\n\n现在，我们将此推导应用于所提供的特定案例。\n已知条件是：\n- 通道数：$K=2$。\n- 特征图维度：$I=2$，$J=2$，$L=1$。\n- 每个图的体素总数：$Z = I \\cdot J \\cdot L = 2 \\cdot 2 \\cdot 1 = 4$。\n- 特征图：\n$$ A^{1} = \\begin{pmatrix} 1  -2 \\\\ 0  3 \\end{pmatrix}, \\quad A^{2} = \\begin{pmatrix} -1  2 \\\\ 1  -2 \\end{pmatrix} $$\n- 分数相对于特征图的梯度：\n$$ \\frac{\\partial y}{\\partial A^{1}} = \\begin{pmatrix} 4  -1 \\\\ 2  0 \\end{pmatrix}, \\quad \\frac{\\partial y}{\\partial A^{2}} = \\begin{pmatrix} -2  1 \\\\ -1  2 \\end{pmatrix} $$\n\n首先，我们计算通道重要性权重 $\\alpha_1$ 和 $\\alpha_2$。\n对于通道 $k=1$：\n$$ \\alpha_1 = \\frac{1}{4} \\sum_{i,j,l} \\frac{\\partial y}{\\partial A^{1}_{i,j,l}} = \\frac{1}{4} (4 + (-1) + 2 + 0) = \\frac{5}{4} $$\n对于通道 $k=2$：\n$$ \\alpha_2 = \\frac{1}{4} \\sum_{i,j,l} \\frac{\\partial y}{\\partial A^{2}_{i,j,l}} = \\frac{1}{4} ((-2) + 1 + (-1) + 2) = \\frac{0}{4} = 0 $$\n\n接下来，我们计算指定体素 $(i,j,l) = (1,1,1)$ 处的原始热力图值 $L_{\\text{raw}}$。这对应于给定矩阵中第一行第一列的元素（假设 $i$ 和 $j$ 是 1-based 索引，并且 $l=1$ 是隐式的）。\n从给定的矩阵中，$(1,1,1)$ 处的激活值为：\n- $A^{1}_{1,1,1} = 1$\n- $A^{2}_{1,1,1} = -1$\n\n原始热力图值为：\n$$ L_{\\text{raw}}(1,1,1) = \\alpha_1 A^{1}_{1,1,1} + \\alpha_2 A^{2}_{1,1,1} = \\left(\\frac{5}{4}\\right)(1) + (0)(-1) = \\frac{5}{4} $$\n\n最后，我们应用 ReLU 函数得到最终的 Grad-CAM 值：\n$$ L_{\\text{Grad-CAM}}(1,1,1) = \\text{ReLU}\\left(\\frac{5}{4}\\right) = \\max\\left(0, \\frac{5}{4}\\right) = \\frac{5}{4} $$\nGrad-CAM 热力图在体素 $(1,1,1)$ 处的值是 $\\frac{5}{4}$。\n\n关于卷积层的选择，存在一个空间分辨率和语义特异性之间的基本权衡。\n- **更深的层（靠近输出）：** 由于重复的下采样（例如，池化、步幅卷积），这些层的特征图具有低空间分辨率。然而，它们捕获了与临床终点高度相关的高级、复杂的语义特征（例如，肿瘤纹理、器官形态）。从深层生成的 Grad-CAM 热力图会比较粗糙，但具有很高的类别区分性，能有效地定位网络学到的抽象概念。这些层的梯度通常更“干净”，因为它们更接近损失函数。\n- **更浅的层（靠近输入）：** 这些层具有高空间分辨率，保留了输入图像的精细细节。然而，它们捕获的是像边缘、角点和简单纹理这样的低级特征，这些特征的语义丰富度较低。从浅层生成的热力图在位置上会很详细和精确，但可能会突出显示与感兴趣类别不特定的特征（例如，突出显示所有边缘，而不仅仅是病灶的边缘）。\n在体积放射组学的背景下，热力图最常由最后一个卷积层生成。这是因为主要目标是理解网络编码的哪些高级放射组学模式正在驱动预测。空间分辨率的损失是为了获得对模型决策过程的卓越语义洞察力而可接受的权衡。",
            "answer": "$$\\boxed{\\frac{5}{4}}$$"
        }
    ]
}