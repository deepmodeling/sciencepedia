{
    "hands_on_practices": [
        {
            "introduction": "在统计建模中，我们常常面临一个核心权衡：模型的拟合优度与复杂性。一个更复杂的模型几乎总能更好地拟合现有数据，但这可能会导致过拟合，使其对新数据的预测能力下降。本练习将引导您计算和比较两种最常用的模型选择准则——赤池信息准则 (AIC) 和贝叶斯信息准则 (BIC)，并探讨它们在模型选择目标上的根本差异：AIC 侧重于预测准确性，而 BIC 侧重于识别“真实”模型。",
            "id": "4815010",
            "problem": "一项生物样本库队列研究使用Cox比例风险模型来研究心血管事件的发生时间结局。在包含 $n=600$ 个观测事件的同一数据集上拟合了两个嵌套模型。模型 $\\mathcal{M}_1$ 包含 $k_1=8$ 个协变量；模型 $\\mathcal{M}_2$ 在 $\\mathcal{M}_1$ 的基础上增加了 $4$ 个协变量，总共有 $k_2=12$ 个。最大化的对数偏似然分别为 $\\ell_{p,1}=-420.5$ 和 $\\ell_{p,2}=-418.0$。假设最大似然估计和模型选择的常规渐近正则性条件成立。\n\n从第一性原理出发：\n- 使用Kullback–Leibler (KL) 散度作为样本外预测差异期望的度量，并利用经典的偏差校正论证，推导出一个旨在最小化基于似然的模型的预期预测损失的大样本准则。\n- 使用带有正则先验的贝叶斯边际似然（模型证据）和Laplace近似，通过将对数证据近似到跨模型共有的一个加性常数，推导出一个旨在进行模型识别的大样本准则。\n\n在Cox模型的设定下，将偏似然的有效样本量取为事件数，因此在任何与样本量相关的项中使用 $n=600$ ，并将 $k$ 取为线性预测器中的回归系数数量（不包括基线风险）。使用它们的最大化对数偏似然和参数计数，为 $\\mathcal{M}_1$ 和 $\\mathcal{M}_2$ 计算这两个准则。然后，说明每个准则偏好哪个模型，并从预测与识别的目标角度，解释如何解读两种准则不一致的情况。\n\n将您的数值结果以行向量 $(\\mathrm{AIC}_1,\\mathrm{AIC}_2,\\mathrm{BIC}_1,\\mathrm{BIC}_2)$ 的形式报告，四舍五入到 $4$ 位有效数字。",
            "solution": "该问题要求从第一性原理推导赤池信息准则（Akaike Information Criterion, AIC）和贝叶斯信息准则（Bayesian Information Criterion, BIC），将它们应用于两个嵌套的Cox比例风险模型，并解释它们各自的目标。这是一个定义明确且具有科学依据的问题。\n\n问题的已知条件是：\n- 有效样本量（事件数）：$n=600$。\n- 模型 $\\mathcal{M}_1$：协变量数量 $k_1=8$。\n- 模型 $\\mathcal{M}_2$：协变量数量 $k_2=12$。\n- 模型 $\\mathcal{M}_1$ 的最大化对数偏似然：$\\ell_{p,1} = -420.5$。\n- 模型 $\\mathcal{M}_2$ 的最大化对数偏似然：$\\ell_{p,2} = -418.0$。\n\n**赤池信息准则（AIC）的推导**\n\nAIC的目标是选择一个能为新数据提供最佳预测性能的模型。这被表述为找到一个模型，该模型能够最小化真实数据生成分布与拟合模型之间的预期信息损失，该损失由Kullback-Leibler（KL）散度衡量。\n\n设数据的真实未知概率分布为 $f(x)$。设 $g(x|\\theta)$ 是一个由维度为 $k$ 的向量 $\\theta$ 参数化的模型族。从 $g$ 到 $f$ 的KL散度定义为：\n$$ D_{KL}(f || g(\\cdot|\\theta)) = \\int f(x) \\ln\\left(\\frac{f(x)}{g(x|\\theta)}\\right) dx = \\mathbb{E}_{f}[\\ln f(x)] - \\mathbb{E}_{f}[\\ln g(x|\\theta)] $$\n由于 $\\mathbb{E}_{f}[\\ln f(x)]$ 相对于模型 $g$ 是一个常数，最小化KL散度等价于最大化模型的期望对数似然 $\\mathbb{E}_{f}[\\ln g(x|\\theta)]$。\n\n设 $\\hat{\\theta}_{obs}$ 是从一个大小为 $n$ 的观测数据集 $y_{obs}$ 中获得的 $\\theta$ 的最大似然估计（MLE）。我们希望估计的量是这个拟合模型在一个从相同真实分布 $f$ 中抽取的新的独立数据集 $y_{new}$ 上的预期预测准确度。这个量是 $\\mathbb{E}_{y_{new}}[\\ln g(y_{new}|\\hat{\\theta}_{obs})]$。\n\n样本内最大化对数似然 $\\ell(\\hat{\\theta}_{obs}) = \\ln g(y_{obs}|\\hat{\\theta}_{obs})$ 是对这个目标量的一个过于乐观的有偏估计。作为AIC核心的偏差校正论证量化了这种乐观性。在标准正则性条件下，对于大样本 $n$，Hirotugu Akaike 证明了：\n$$ \\mathbb{E}_{y_{obs}} \\left[ \\mathbb{E}_{y_{new}}[\\ln g(y_{new}|\\hat{\\theta}_{obs})] - \\ell(\\hat{\\theta}_{obs}) \\right] \\approx -k $$\n左边的项是样本内对数似然作为样本外预测对数似然估计量的期望乐观度。期望 $\\mathbb{E}_{y_{obs}}$ 是对所有可能的样本量为 $n$ 的训练集取的。这表明对于数据的单次实现，目标预测量 $\\mathbb{E}_{y_{new}}[\\ln g(y_{new}|\\hat{\\theta}_{obs})]$ 的一个近似无偏估计量是经过偏差校正的对数似然：\n$$ \\ell(\\hat{\\theta}_{obs}) - k $$\nAIC的定义是将这个量乘以 $-2$。乘以 $-2$ 将AIC置于离差（deviance）尺度上，因此较小的值表示相对于模型复杂度的更好拟合。\n$$ \\mathrm{AIC} = -2 (\\ell(\\hat{\\theta}_{obs}) - k) = -2\\ell(\\hat{\\theta}_{obs}) + 2k $$\n在Cox模型的背景下，对数似然被最大化对数偏似然 $\\ell_p$ 所取代。\n\n**贝叶斯信息准则（BIC）的推导**\n\nBIC的目标是基于其后验概率，从一组候选模型中识别出“真实”的数据生成模型。根据贝叶斯定理，给定数据 $y$，模型 $\\mathcal{M}_i$ 的后验概率为：\n$$ P(\\mathcal{M}_i|y) = \\frac{P(y|\\mathcal{M}_i) P(\\mathcal{M}_i)}{\\sum_j P(y|\\mathcal{M}_j) P(\\mathcal{M}_j)} $$\n假设所有模型的先验概率相等（$P(\\mathcal{M}_i) = P(\\mathcal{M}_j)$），选择具有最高后验概率的模型等同于选择具有最高边际似然或“模型证据” $P(y|\\mathcal{M})$ 的模型。BIC是 $-2 \\ln P(y|\\mathcal{M})$ 的一个大样本近似。\n\n边际似然是通过对给定模型 $\\mathcal{M}$ 的参数 $\\theta$（维度为 $k$）的先验分布进行似然积分得到的：\n$$ P(y|\\mathcal{M}) = \\int P(y|\\theta, \\mathcal{M}) P(\\theta|\\mathcal{M}) d\\theta = \\int \\exp(\\ln(P(y|\\theta, \\mathcal{M})P(\\theta|\\mathcal{M}))) d\\theta $$\n令 $q(\\theta) = \\ln(P(y|\\theta, \\mathcal{M})P(\\theta|\\mathcal{M})) = \\ell(\\theta|y) + \\ln P(\\theta|\\mathcal{M})$，其中 $\\ell(\\theta|y)$ 是对数似然。我们使用Laplace近似来评估这个在大样本量 $n$ 下的积分。我们将 $q(\\theta)$ 在其众数（对于大样本 $n$ 可由MLE $\\hat{\\theta}$ 近似）附近进行泰勒级数展开：\n$$ q(\\theta) \\approx q(\\hat{\\theta}) + (\\theta - \\hat{\\theta})^T \\nabla q(\\hat{\\theta}) + \\frac{1}{2}(\\theta - \\hat{\\theta})^T \\nabla^2 q(\\hat{\\theta}) (\\theta - \\hat{\\theta}) $$\n在MLE $\\hat{\\theta}$ 处，对数似然的梯度为零。假设一个正则先验，其影响很小，则 $\\nabla q(\\hat{\\theta}) \\approx 0$。展开式简化为：\n$$ q(\\theta) \\approx q(\\hat{\\theta}) - \\frac{1}{2}(\\theta - \\hat{\\theta})^T H (\\theta - \\hat{\\theta}) $$\n其中 $H = -\\nabla^2 q(\\hat{\\theta})$ 是在众数处计算的Hessian矩阵的负值。对于大样本 $n$，$H$ 可以很好地由观测到的Fisher信息矩阵 $I(\\hat{\\theta})$ 近似。\n积分变为：\n$$ P(y|\\mathcal{M}) \\approx \\exp(q(\\hat{\\theta})) \\int \\exp\\left(-\\frac{1}{2}(\\theta - \\hat{\\theta})^T H (\\theta - \\hat{\\theta})\\right) d\\theta $$\n该积分是多元高斯分布的归一化常数，即 $(2\\pi)^{k/2} (\\det H)^{-1/2}$。因此：\n$$ P(y|\\mathcal{M}) \\approx P(y|\\hat{\\theta}, \\mathcal{M}) P(\\hat{\\theta}|\\mathcal{M}) (2\\pi)^{k/2} (\\det H)^{-1/2} $$\n取对数：\n$$ \\ln P(y|\\mathcal{M}) \\approx \\ell(\\hat{\\theta}) + \\ln P(\\hat{\\theta}|\\mathcal{M}) + \\frac{k}{2} \\ln(2\\pi) - \\frac{1}{2} \\ln(\\det H) $$\n对于大样本 $n$，Fisher信息矩阵 $I(\\hat{\\theta})$ 的元素是 $O(n)$ 阶的，所以其行列式 $\\det H \\approx \\det I(\\hat{\\theta})$ 是 $O(n^k)$ 阶的。因此，$\\ln(\\det H) \\approx k \\ln(n) + O(1)$。先验项 $\\ln P(\\hat{\\theta}|\\mathcal{M})$ 和 $\\ln(2\\pi)$ 项是 $O(1)$ 阶的。舍去所有不随 $n$ 增长（或增长速度慢于 $\\ln(n)$）的项，我们得到近似式：\n$$ \\ln P(y|\\mathcal{M}) \\approx \\ell(\\hat{\\theta}) - \\frac{k}{2}\\ln(n) $$\nBIC的定义是将其乘以 $-2$：\n$$ \\mathrm{BIC} = -2\\ell(\\hat{\\theta}) + k\\ln(n) $$\n同样，对于Cox模型，$\\ell(\\hat{\\theta})$ 被 $\\ell_p$ 所取代。\n\n**模型 $\\mathcal{M}_1$ 和 $\\mathcal{M}_2$ 的计算**\n\n我们已知 $n=600$, $k_1=8$, $\\ell_{p,1}=-420.5$, $k_2=12$, 以及 $\\ell_{p,2}=-418.0$。\n首先，我们计算 $\\ln(n) = \\ln(600) \\approx 6.3969$。\n\n对于模型 $\\mathcal{M}_1$：\n$$ \\mathrm{AIC}_1 = -2\\ell_{p,1} + 2k_1 = -2(-420.5) + 2(8) = 841.0 + 16 = 857.0 $$\n$$ \\mathrm{BIC}_1 = -2\\ell_{p,1} + k_1\\ln(n) = -2(-420.5) + 8\\ln(600) \\approx 841.0 + 8(6.3969) \\approx 841.0 + 51.1752 = 892.1752 $$\n\n对于模型 $\\mathcal{M}_2$：\n$$ \\mathrm{AIC}_2 = -2\\ell_{p,2} + 2k_2 = -2(-418.0) + 2(12) = 836.0 + 24 = 860.0 $$\n$$ \\mathrm{BIC}_2 = -2\\ell_{p,2} + k_2\\ln(n) = -2(-418.0) + 12\\ln(600) \\approx 836.0 + 12(6.3969) \\approx 836.0 + 76.7628 = 912.7628 $$\n\n将结果四舍五入到 $4$ 位有效数字，我们得到：\n$\\mathrm{AIC}_1 = 857.0$\n$\\mathrm{AIC}_2 = 860.0$\n$\\mathrm{BIC}_1 = 892.2$\n$\\mathrm{BIC}_2 = 912.8$\n\n**模型偏好与解释**\n\n对于AIC和BIC，值越低表示模型越受偏好。\n- **AIC偏好**：由于 $\\mathrm{AIC}_1=857.0  \\mathrm{AIC}_2=860.0$，AIC准则偏好更简单的模型 $\\mathcal{M}_1$。\n- **BIC偏好**：由于 $\\mathrm{BIC}_1=892.2  \\mathrm{BIC}_2=912.8$，BIC准则也偏好更简单的模型 $\\mathcal{M}_1$。\n\n在这个例子中，两个准则的结论一致。然而，问题要求解释如何解读它们可能不一致的情况。不一致通常发生在AIC偏好更复杂的模型而BIC偏好更简单的模型时。这是因为对于任何样本量 $n > e^2 \\approx 7.39$，BIC的惩罚项 $k\\ln(n)$ 都大于AIC的惩罚项 $2k$。在本问题中，$\\ln(600) \\approx 6.4$，所以BIC对复杂度的惩罚比AIC严厉三倍多。\n\n- **AIC目标的解释（预测）**：AIC旨在选择一个在未来数据上具有最佳预测准确度的模型。它是渐近有效的，这意味着如果真实的潜在现实是无限维的（即没有简单的有限参数模型是完全“真实”的），AIC倾向于选择能提供最佳有限维近似的模型。它可能会在模型中保留一个参数，即使该参数不属于假设的“真实”生成模型，只要它能提供轻微但真实的预测能力提升。\n\n- **BIC目标的解释（识别）**：BIC旨在从候选模型集合中识别出“真实”模型。它是一致的，这意味着随着样本量 $n \\to \\infty$，BIC选择真实模型（如果该模型在候选集中）的概率趋近于1。其更强的惩罚反映了更高的举证责任：数据中必须有充分的证据（似然值的大幅增加）才能证明增加更多参数是合理的，并得出更复杂的模型是真实模型的结论。\n\n- **解释不一致**：如果AIC选择了 $\\mathcal{M}_2$ 而BIC选择了 $\\mathcal{M}_1$，这将意味着 $\\mathcal{M}_2$ 中额外的4个协变量足以提高对数似然，从而被认为对预测有用（根据AIC），但不足以提供强有力的证据表明 $\\mathcal{M}_2$ 是对真实潜在数据生成过程的更好表示（根据BIC）。它们之间的选择将取决于研究目标：如果目标是建立最佳的预测风险评分，可能会选择AIC偏好的模型。如果目标是建立一个更简约的、解释性的模型，只识别那些得到最有力支持的风险因素，那么BIC偏好的模型将是选择。",
            "answer": "$$ \\boxed{ \\begin{pmatrix} 857.0  860.0  892.2  912.8 \\end{pmatrix} } $$"
        },
        {
            "introduction": "在使用 AIC 或 BIC 等信息准则时，正确计算模型中的参数数量 $k$ 是至关重要的一步，但这一点常常被忽视。模型中的约束条件（如和为零约束）或固定值的偏置项（offset）都会减少模型的有效参数数量。本练习将通过一个实际的生物统计学案例，帮助您精确识别广义线性模型中的有效自由参数个数，从而确保模型选择的准确性。",
            "id": "4928632",
            "problem": "一项临床监测研究使用带对数连接函数的泊松广义线性模型来建模 $J=5$ 家医院的院内感染计数。对于医院 $j$ 的患者 $i$，平均计数 $ \\mu_{ij} $ 通过以下方式建模：\n$$\n\\log(\\mu_{ij}) = \\alpha + \\beta X_{ij} + \\gamma_j + \\log(E_{ij}),\n$$\n其中 $X_{ij}$ 是一个测量的风险评分，$E_{ij}$ 是暴露时间（一个作为偏移量纳入的已知量），$\\gamma_j$ 是一个受和为零可识别性约束 $\\sum_{j=1}^{5} \\gamma_j = 0$ 的医院特定效应，$\\alpha$ 是一个全局截距。第二个候选模型利用先前的监测知识，通过将一个已知常数 $r_0$ 纳入偏移量并移除截距来固定基线率：\n$$\n\\log(\\mu_{ij}) = \\beta X_{ij} + \\gamma_j + \\log(E_{ij}) + \\log(r_0),\n$$\n$\\gamma_j$ 具有相同的和为零约束。两个模型都通过最大似然法进行拟合。\n\n设第一个模型的最大化对数似然为 $\\hat{\\ell}_1 = -120.3$，第二个模型的最大化对数似然为 $\\hat{\\ell}_2 = -119.1$。对于每个模型，生物统计学家必须确定反映在所述约束和偏移量处理下参数空间有效维数的适当参数数量 $k$，然后计算赤池信息准则 (AIC) 以比较模型。\n\n哪个选项正确地指出了两个模型的有效参数数量 $k$ 和相应的 AIC 值？\n\nA) 模型 $1$：$k=6$，$\\mathrm{AIC}_1 = 252.6$；模型 $2$：$k=5$，$\\mathrm{AIC}_2 = 248.2$。\n\nB) 模型 $1$：$k=7$（将偏移量计为一个参数），$\\mathrm{AIC}_1 = 254.6$；模型 $2$：$k=6$，$\\mathrm{AIC}_2 = 250.2$。\n\nC) 模型 $1$：$k=5$（和为零施加了两个约束），$\\mathrm{AIC}_1 = 250.6$；模型 $2$：$k=4$，$\\mathrm{AIC}_2 = 246.2$。\n\nD) 模型 $1$：$k=6$，$\\mathrm{AIC}_1 = 252.6$；模型 $2$：$k=6$（截距尽管在偏移量中固定，但仍被计算在内），$\\mathrm{AIC}_2 = 250.2$。",
            "solution": "### 步骤1：提取已知信息\n问题提供了以下信息：\n-   医院数量：$J=5$。\n-   模型1（带截距 $\\alpha$）：\n    $$ \\log(\\mu_{ij}) = \\alpha + \\beta X_{ij} + \\gamma_j + \\log(E_{ij}) $$\n-   模型2（不带截距 $\\alpha$，使用已知常数 $r_0$）：\n    $$ \\log(\\mu_{ij}) = \\beta X_{ij} + \\gamma_j + \\log(E_{ij}) + \\log(r_0) $$\n-   对两个模型，医院特定效应都存在和为零的可识别性约束：\n    $$ \\sum_{j=1}^{5} \\gamma_j = 0 $$\n-   $E_{ij}$ 是一个已知量，$\\log(E_{ij})$ 是一个偏移量。\n-   $r_0$ 是一个已知常数。\n-   模型通过最大似然法进行拟合。\n-   模型1的最大化对数似然：$\\hat{\\ell}_1 = -120.3$。\n-   模型2的最大化对数似然：$\\hat{\\ell}_2 = -119.1$。\n-   任务是为每个模型找到有效参数数量 $k$，并计算赤池信息准则 (AIC)。\n\n### 步骤2：使用提取的已知信息进行验证\n问题陈述具有科学依据、提法明确且客观。\n-   **科学依据**：该问题描述了一项标准的生物统计学分析，使用了泊松广义线性模型，这是计数数据建模的基石。对数连接函数、用于暴露的偏移量、为保证可识别性而带和为零约束的固定效应，以及使用AIC进行模型比较等概念，都是统计学领域中基本且公认的。\n-   **提法明确**：该问题提供了得出唯一解所需的所有必要组成部分。模型、约束以及最大化对数似然值都得到了清晰的说明。AIC的定义是标准的。核心任务，即确定有效参数数量，是一个明确定义的统计学问题。\n-   **客观性**：问题使用统计学中常见、精确、无歧义的术语进行陈述。不存在主观或基于意见的元素。\n\n该问题不违反任何无效性标准。这是一个有效、可解的生物统计学问题。\n\n### 步骤3：推导解答\n\n赤池信息准则 (AIC) 定义为：\n$$ \\mathrm{AIC} = 2k - 2\\hat{\\ell} $$\n其中 $k$ 是模型中估计参数的数量，$\\hat{\\ell}$ 是对数似然函数的最大化值。解决此问题的关键是正确确定每个模型的有效参数数量 $k$。\n\n**模型1的分析**\n\n第一个模型是：\n$$ \\log(\\mu_{ij}) = \\alpha + \\beta X_{ij} + \\gamma_j + \\log(E_{ij}) $$\n需要通过最大似然法估计的参数是：\n1.  全局截距 $\\alpha$。这是 $1$ 个参数。\n2.  风险评分的系数 $\\beta$。这是 $1$ 个参数。\n3.  医院特定效应 $\\gamma_1, \\gamma_2, \\gamma_3, \\gamma_4, \\gamma_5$。共有 $J=5$ 个这样的项。\n\n粗略来看，这会是 $1 + 1 + 5 = 7$ 个参数。然而，这些参数受到约束 $\\sum_{j=1}^{5} \\gamma_j = 0$ 的限制。这是一个单一的线性约束，使自由参数的数量减少了 $1$。如果我们知道任意 $4$ 个 $\\gamma_j$ 的值，第 $5$ 个就自动确定了。例如，$\\gamma_5 = -(\\gamma_1 + \\gamma_2 + \\gamma_3 + \\gamma_4)$。因此，这 $5$ 个医院效应 $\\gamma_j$ 只对模型贡献了 $J-1 = 5-1=4$ 个有效参数。\n\n项 $\\log(E_{ij})$ 是一个偏移量。根据定义，偏移量是一个系数固定为 $1$ 的预测变量，它不是从数据中估计出来的。因此，它不计入估计参数的数量 $k$。\n\n模型1的总有效参数数量为：\n$$ k_1 = (\\text{对应 } \\alpha) + (\\text{对应 } \\beta) + (\\text{对应 } \\gamma_j \\text{ 集合}) = 1 + 1 + (5-1) = 6 $$\n在 $k_1 = 6$ 和给定的最大化对数似然 $\\hat{\\ell}_1 = -120.3$ 的情况下，模型1的 AIC 为：\n$$ \\mathrm{AIC}_1 = 2k_1 - 2\\hat{\\ell}_1 = 2(6) - 2(-120.3) = 12 + 240.6 = 252.6 $$\n\n**模型2的分析**\n\n第二个模型是：\n$$ \\log(\\mu_{ij}) = \\beta X_{ij} + \\gamma_j + \\log(E_{ij}) + \\log(r_0) $$\n在这个模型中，截距 $\\alpha$ 已被移除。增加了项 $\\log(r_0)$，其中 $r_0$ 是一个已知常数。这意味着 $\\log(r_0)$ 不是一个需要估计的参数；它是偏移量的一部分，现在的偏移量是 $\\log(E_{ij}) + \\log(r_0)$。\n\n需要通过最大似然法估计的参数是：\n1.  风险评分的系数 $\\beta$。这是 $1$ 个参数。\n2.  医院特定效应 $\\gamma_1, \\ldots, \\gamma_5$，它们仍然受到约束 $\\sum_{j=1}^{5} \\gamma_j = 0$ 的限制。与模型1中一样，它们贡献了 $J-1 = 4$ 个有效参数。\n\n模型2的总有效参数数量为：\n$$ k_2 = (\\text{对应 } \\beta) + (\\text{对应 } \\gamma_j \\text{ 集合}) = 1 + (5-1) = 5 $$\n在 $k_2 = 5$ 和给定的最大化对数似然 $\\hat{\\ell}_2 = -119.1$ 的情况下，模型2的 AIC 为：\n$$ \\mathrm{AIC}_2 = 2k_2 - 2\\hat{\\ell}_2 = 2(5) - 2(-119.1) = 10 + 238.2 = 248.2 $$\n\n**结果总结：**\n-   模型1：$k_1 = 6$，$\\mathrm{AIC}_1 = 252.6$。\n-   模型2：$k_2 = 5$，$\\mathrm{AIC}_2 = 248.2$。\n\n### 逐项分析选项\n\n**A) 模型 $1$：$k=6$，$\\mathrm{AIC}_1 = 252.6$；模型 $2$：$k=5$，$\\mathrm{AIC}_2 = 248.2$。**\n该选项与我们为两个模型推导出的结果完全匹配。\n-   模型1：$k_1 = 1(\\alpha) + 1(\\beta) + (5-1)(\\gamma_j) = 6$。$\\mathrm{AIC}_1 = 2(6) - 2(-120.3) = 252.6$。\n-   模型2：$k_2 = 1(\\beta) + (5-1)(\\gamma_j) = 5$。$\\mathrm{AIC}_2 = 2(5) - 2(-119.1) = 248.2$。\n**结论：正确。**\n\n**B) 模型 $1$：$k=7$（将偏移量计为一个参数），$\\mathrm{AIC}_1 = 254.6$；模型 $2$：$k=6$，$\\mathrm{AIC}_2 = 250.2$。**\n这个选项基于对什么构成估计参数的误解。偏移量是一个系数固定为1的已知量；它不是被估计的，因此不计入 $k$。该选项还通过忽略和为零的约束，错误地计算了 $\\gamma_j$ 集合的参数数量。对于模型1，它似乎计算了 $k_1 = 1(\\alpha) + 1(\\beta) + 5(\\gamma_j) = 7$。对于模型2，它计算了 $k_2 = 1(\\beta) + 5(\\gamma_j) = 6$。这两个计数都是错误的。\n**结论：错误。**\n\n**C) 模型 $1$：$k=5$（和为零施加了两个约束），$\\mathrm{AIC}_1 = 250.6$；模型 $2$：$k=4$，$\\mathrm{AIC}_2 = 246.2$。**\n该选项错误地指出和为零的约束施加了两个约束。方程 $\\sum_{j=1}^{5} \\gamma_j = 0$ 是一个单一的线性约束，它将自由度减少1，而不是2。因此，参数数量 $k_1=5$ 和 $k_2=4$ 是错误的。\n**结论：错误。**\n\n**D) 模型 $1$：$k=6$，$\\mathrm{AIC}_1 = 252.6$；模型 $2$：$k=6$（截距尽管在偏移量中固定，但仍被计算在内），$\\mathrm{AIC}_2 = 250.2$。**\n该选项正确分析了模型1。然而，它对模型2的分析是有缺陷的。其理由“截距尽管在偏移量中固定，但仍被计算在内”是毫无意义的。在模型2中，参数 $\\alpha$ 被移除，并被一个已知常数 $\\log(r_0)$ 替代。一个已知常数不是一个估计参数，不计入 $k$。模型2的正确参数数量是 $k_2=5$，而不是 $k_2=6$。\n**结论：错误。**",
            "answer": "$$\\boxed{A}$$"
        },
        {
            "introduction": "虽然 AIC 是一个强大的模型选择工具，但其推导基于大样本理论，在样本量较小或参数数量相对于样本量较多时，其性能可能会有所折扣。为了解决这一问题，学者们提出了修正的赤池信息准则 (AICc)，它对小样本情况下的偏差进行了校正。通过本练习，您将亲手计算标准 AIC 和 AICc 惩罚项之间的差异，从而直观地理解 AICc 为何在小样本情况下是更优的选择，以及何时应当使用它。",
            "id": "4928685",
            "problem": "一位生物统计学家对一项独立受试者研究的二元结果拟合了一个带有逻辑斯蒂连接函数的广义线性模型（GLM）。样本量为 $n=60$。该模型包含 $k=10$ 个未知参数（包括截距项）。拟合模型的最大化对数似然值为 $\\hat{\\ell}=-36.7$。使用将模型选择与期望的Kullback–Leibler散度联系起来的核心原理，确定该模型的赤池信息准则（AIC）和校正的赤池信息准则（AICc）。然后，对于此模型规模和样本量，量化AICc与AIC所隐含的惩罚项之间的差异。将此惩罚项差异作为您的最终答案，并四舍五入到四位有效数字。",
            "solution": "该问题要求计算对于一个给定的广义线性模型，校正的赤池信息准则（AICc）和标准赤池信息准则（AIC）的惩罚项之间的差异。\n\n首先，我们来定义AIC。赤池信息准则是一种广泛用于模型选择的度量标准。它建立在估计拟合模型与未知的真实数据生成过程之间的期望相对Kullback-Leibler（KL）散度的原理之上。AIC的公式为：\n$$\nAIC = -2 \\hat{\\ell} + 2k\n$$\n其中 $\\hat{\\ell}$ 是模型对数似然函数的最大化值，而 $k$ 是模型中估计参数的数量。项 $-2 \\hat{\\ell}$ 是拟合优度的度量，而项 $2k$ 是对模型复杂度的惩罚。因此，AIC的惩罚项为：\n$$\nP_{AIC} = 2k\n$$\n\nAIC是期望KL散度的渐近无偏估计量。然而，对于小样本量，其性能可能不是最优的。校正的赤池信息准则（AICc）通过引入一个更大的惩罚项来调整这种小样本偏差。AICc的公式为：\n$$\nAICc = AIC + \\frac{2k(k+1)}{n-k-1}\n$$\n其中 $n$ 是样本量。通过代入AIC的表达式，我们可以将AICc写为：\n$$\nAICc = -2 \\hat{\\ell} + 2k + \\frac{2k(k+1)}{n-k-1}\n$$\n从这个表达式中，我们可以将AICc的总惩罚项识别为加到拟合优度项 $-2 \\hat{\\ell}$ 上的量：\n$$\nP_{AICc} = 2k + \\frac{2k(k+1)}{n-k-1}\n$$\n当样本量与参数数量的比值 $n/k$ 很小时（一个常见的经验法则是当 $n/k  40$ 时），这个校正项的影响变得更大。\n\n问题要求计算AICc与AIC所隐含的惩罚项之间的差异。我们将此差异表示为 $\\Delta P$，即：\n$$\n\\Delta P = P_{AICc} - P_{AIC}\n$$\n代入惩罚项的表达式：\n$$\n\\Delta P = \\left( 2k + \\frac{2k(k+1)}{n-k-1} \\right) - (2k)\n$$\n这可以简化为校正项本身：\n$$\n\\Delta P = \\frac{2k(k+1)}{n-k-1}\n$$\n\n问题提供了以下数值：\n- 样本量：$n = 60$\n- 未知参数数量：$k = 10$\n- 最大化对数似然值：$\\hat{\\ell} = -36.7$\n\n请注意，计算惩罚项的差异不需要最大化对数似然值 $\\hat{\\ell}$，因为这个差异仅取决于 $n$ 和 $k$。\n\n现在我们可以将给定的 $n$ 和 $k$ 值代入 $\\Delta P$ 的表达式中：\n$$\n\\Delta P = \\frac{2(10)(10+1)}{60-10-1}\n$$\n$$\n\\Delta P = \\frac{2(10)(11)}{49}\n$$\n$$\n\\Delta P = \\frac{220}{49}\n$$\n现在，我们计算其数值：\n$$\n\\Delta P \\approx 4.489795918...\n$$\n问题要求答案四舍五入到四位有效数字。前四位有效数字是 $4$、$4$、$8$ 和 $9$。第五位数字是 $7$，大于或等于 $5$，所以我们将第四位有效数字向上舍入。将 $9$ 向上舍入得到 $0$，并向前一位进 $1$。\n$$\n\\Delta P \\approx 4.490\n$$\n末尾的零是有效数字，必须包含在内，以表示四位有效数字的精度。这个值代表了对于一个有 $k=10$ 个参数和样本量为 $n=60$ 的模型，AICc相比AIC所施加的额外惩罚。",
            "answer": "$$\n\\boxed{4.490}\n$$"
        }
    ]
}