{
    "hands_on_practices": [
        {
            "introduction": "决策树通过分裂节点来创建更“纯净”的子节点。本练习将带您深入“纯净度”的数学核心，比较两种最常见的分类度量标准：基尼不纯度（Gini impurity）和香农熵（Shannon entropy）。通过分析它们的数学特性，您将对为何在某些情况下（尤其是在处理含噪声的真实世界数据时）会偏好其中一种度量标准，建立更深刻的直觉 。",
            "id": "4910439",
            "problem": "一个生物统计团队正在使用随机森林（RF）为临床结果开发一个二元分类器，其中随机森林（RF）表示在自助采样样本上训练并采用随机化特征选择的决策树集成。考虑训练过程中决策树内的单个节点。设疾病阳性标签的估计类别比例用 $p \\in (0,1)$ 表示，因此疾病阴性标签的比例为 $1-p$。节点不纯度可以用基尼不纯度或香农熵来衡量，使用它们的基本定义：\n- 对于具有概率 $\\{p_{k}\\}_{k=1}^{K}$ 的 $K$ 个类别，基尼不纯度为 $G = \\sum_{k=1}^{K} p_{k} (1 - p_{k})$。\n- 对于具有概率 $\\{p_{k}\\}_{k=1}^{K}$ 的 $K$ 个类别，香农熵（使用自然对数）为 $H = - \\sum_{k=1}^{K} p_{k} \\ln p_{k}$。\n\n任务：\n1. 将这些定义特化到二元情况 $K=2$，以推导出 $G$ 和 $H$ 作为 $p$ 的显式函数。\n2. 使用微积分和在 $p = \\tfrac{1}{2}$ 附近的泰勒展开，分析 $G(p)$ 和 $H(p)$ 在 $p=\\tfrac{1}{2}$ 附近的曲率。特别地，计算二阶导数 $G''(\\tfrac{1}{2})$ 和 $H''(\\tfrac{1}{2})$，并解释它们的相等性或差异。\n3. 为了量化在含噪声临床标签下 $p=\\tfrac{1}{2}$ 附近的高阶曲率和敏感性，计算 $H$ 在 $p=\\tfrac{1}{2}$ 处的四阶导数，记为 $H^{(4)}(\\tfrac{1}{2})$。将 $H^{(4)}(\\tfrac{1}{2})$ 的精确值作为你的最终答案。\n\n所有中间数学步骤都用精确符号形式表示。最终答案是 $H^{(4)}(\\tfrac{1}{2})$ 的单个精确数值。不需要四舍五入。",
            "solution": "我们从基本定义开始。对于二元情况，有两个类别，其概率分别为 $p_{1} = p$ 和 $p_{0} = 1 - p$。\n\n1. 二元形式的推导。\n\n- 基尼不纯度：\n\n$$\nG(p) \\;=\\; \\sum_{k \\in \\{0,1\\}} p_{k} (1 - p_{k}) \\;=\\; p(1-p) + (1-p)p \\;=\\; 2p(1-p).\n$$\n\n等价地，由于 $G = 1 - \\sum_{k} p_{k}^{2}$，可以验证 $G(p) = 1 - \\left( p^{2} + (1-p)^{2} \\right) = 2p(1-p)$。\n\n- 香农熵（自然对数）：\n\n$$\nH(p) \\;=\\; -\\sum_{k \\in \\{0,1\\}} p_{k} \\ln p_{k} \\;=\\; -\\left[ p \\ln p + (1-p)\\ln(1-p) \\right].\n$$\n\n\n这就确定了对于二元分类，$G(p) = 2p(1-p)$ 和 $H(p) = -\\left[ p \\ln p + (1-p)\\ln(1-p) \\right]$。\n\n2. 在 $p = \\tfrac{1}{2}$ 附近的曲率。\n\n- 对于 $G(p) = 2p(1-p) = 2p - 2p^{2}$，其导数为：\n\n$$\nG'(p) \\;=\\; 2 - 4p, \n\\qquad\nG''(p) \\;=\\; -4.\n$$\n\n因此，\n\n$$\nG''\\!\\left( \\tfrac{1}{2} \\right) \\;=\\; -4.\n$$\n\n\n- 对于 $H(p) = -\\left[ p \\ln p + (1-p)\\ln(1-p) \\right]$，求导：\n\n$$\nH'(p) \\;=\\; \\ln(1-p) - \\ln p \\;=\\; \\ln\\!\\left( \\frac{1-p}{p} \\right),\n$$\n\n\n$$\nH''(p) \\;=\\; -\\frac{1}{1-p} - \\frac{1}{p} \\;=\\; -\\frac{1}{p(1-p)}.\n$$\n\n因此，\n\n$$\nH''\\!\\left( \\tfrac{1}{2} \\right) \\;=\\; -\\frac{1}{\\left( \\tfrac{1}{2} \\right)\\left( \\tfrac{1}{2} \\right)} \\;=\\; -4.\n$$\n\n因此，$G''\\!\\left( \\tfrac{1}{2} \\right) = H''\\!\\left( \\tfrac{1}{2} \\right) = -4$，表明在 $p = \\tfrac{1}{2}$ 附近具有相同的局部二次曲率。\n\n为了评估在含噪声标签的情况下可能重要的高阶敏感性，我们考察 H 的高阶导数。\n\n3. 计算 $H^{(4)}\\!\\left( \\tfrac{1}{2} \\right)$。\n\n根据上面的结果，\n\n$$\nH''(p) \\;=\\; -\\frac{1}{p(1-p)}.\n$$\n\n求导得到三阶导数：\n\n$$\nH'''(p) \\;=\\; -\\frac{\\mathrm{d}}{\\mathrm{d}p} \\left[ \\frac{1}{p(1-p)} \\right] \n\\;=\\; \\frac{1 - 2p}{p^{2}(1-p)^{2}}.\n$$\n\n再求导一次得到四阶导数：\n\n$$\nH^{(4)}(p) \\;=\\; \\frac{\\mathrm{d}}{\\mathrm{d}p} \\left[ \\frac{1 - 2p}{p^{2}(1-p)^{2}} \\right].\n$$\n\n令 $N(p) = 1 - 2p$ 和 $D(p) = p^{2}(1-p)^{2}$。那么 $H^{(4)}(p) = \\frac{N'(p) D(p) - N(p) D'(p)}{D(p)^{2}}$。在 $p = \\tfrac{1}{2}$ 时，我们有 $N\\!\\left( \\tfrac{1}{2} \\right) = 0$，$N'\\!\\left( \\tfrac{1}{2} \\right) = -2$，以及 $D\\!\\left( \\tfrac{1}{2} \\right) = \\left( \\tfrac{1}{2} \\right)^{2} \\left( \\tfrac{1}{2} \\right)^{2} = \\tfrac{1}{16}$。因此，\n\n$$\nH^{(4)}\\!\\left( \\tfrac{1}{2} \\right) \n\\;=\\; \\frac{N'\\!\\left( \\tfrac{1}{2} \\right) D\\!\\left( \\tfrac{1}{2} \\right) - N\\!\\left( \\tfrac{1}{2} \\right) D'\\!\\left( \\tfrac{1}{2} \\right)}{D\\!\\left( \\tfrac{1}{2} \\right)^{2}}\n\\;=\\; \\frac{(-2)\\left( \\tfrac{1}{16} \\right) - 0}{\\left( \\tfrac{1}{16} \\right)^{2}}\n\\;=\\; \\frac{-\\tfrac{1}{8}}{\\tfrac{1}{256}}\n\\;=\\; -32.\n$$\n\n\n通过在 $p = \\tfrac{1}{2}$ 附近对 $p = \\tfrac{1}{2} + x$ 进行泰勒展开的等价验证得到\n\n$$\nH\\!\\left( \\tfrac{1}{2} + x \\right) \\;=\\; \\ln 2 \\;-\\; 2 x^{2} \\;-\\; \\frac{4}{3} x^{4} \\;+\\; O\\!\\left( x^{6} \\right),\n$$\n\n这意味着 $H''\\!\\left( \\tfrac{1}{2} \\right) = -4$ 并且 $H^{(4)}\\!\\left( \\tfrac{1}{2} \\right) = 4! \\left( -\\tfrac{4}{3} \\right) = -32$，与直接求导的结果一致。\n\n对于 $p = \\tfrac{1}{2}$ 附近含噪声的临床标签的解释：两种标准都具有相同的二次曲率（$-4$），表明对于接近平衡的节点，它们的行为非常相似。然而，熵的负四阶导数 $H^{(4)}\\!\\left( \\tfrac{1}{2} \\right) = -32$，而基尼不纯度的四阶导数为零（因为它是一个精确的二次函数），这表明当 $p$ 偏离 $\\tfrac{1}{2}$ 时，熵比基尼不纯度下降得稍快。这可能使得熵对 $p$ 的微小波动（例如，由标签噪声引起的）更敏感，而基尼不纯度在该情况下可能稍微更稳定。在实践中，两者在接近平衡时表现相似，但这种高阶差异提供了一个理论基础，即为了增强对临床标签中由噪声引起的小偏差的鲁棒性，更倾向于选择基尼不纯度。",
            "answer": "$$\\boxed{-32}$$"
        },
        {
            "introduction": "回归树的核心机制是寻找能最大程度减少因变量方差的分裂点。本练习提供了一个动手实践的机会，让您使用平方误差损失函数来量化一个潜在分裂点所带来的风险降低。您将执行与 CART 算法完全相同的计算步骤来判断一个分裂是否值得，从而将抽象的“不纯度降低”概念具体化 。",
            "id": "4910518",
            "problem": "一家医院的生物统计团队正在构建一个由回归树组成的随机森林 (RF) 模型，用于通过协变量 $\\left(X_{1},\\dots,X_{p}\\right)$ 预测成年人的收缩压。对于某棵特定的树，在其当前的根节点处，该团队考虑对协变量 $X_{2}$（身体质量指数）进行一次候选分裂。结果变量 $Y$ 是以毫米汞柱 (mmHg) 为单位测量的收缩压。模型使用平方损失。此节点处的数据集包含 $n=10$ 名患者的观测对 $\\left(X_{2}, Y\\right)$：\n- 患者 1：$\\left(X_{2}=22.0,\\;Y=118\\right)$\n- 患者 2：$\\left(X_{2}=24.5,\\;Y=130\\right)$\n- 患者 3：$\\left(X_{2}=29.0,\\;Y=142\\right)$\n- 患者 4：$\\left(X_{2}=26.0,\\;Y=126\\right)$\n- 患者 5：$\\left(X_{2}=31.0,\\;Y=150\\right)$\n- 患者 6：$\\left(X_{2}=27.5,\\;Y=134\\right)$\n- 患者 7：$\\left(X_{2}=28.0,\\;Y=138\\right)$\n- 患者 8：$\\left(X_{2}=23.0,\\;Y=120\\right)$\n- 患者 9：$\\left(X_{2}=34.0,\\;Y=160\\right)$\n- 患者 10：$\\left(X_{2}=25.0,\\;Y=132\\right)$\n\n候选分裂的阈值为 $t=27.0$，将 $X_{2}\\leq t$ 的观测值分到左子节点 $L$，将 $X_{2}>t$ 的观测值分到右子节点 $R$。在平方损失下，任意节点 $N$ 的经验风险定义为\n$$\nR_{N} \\;=\\; \\frac{1}{n_{N}}\\sum_{i\\in N}\\left(Y_{i}-\\bar{Y}_{N}\\right)^{2},\n$$\n其中 $n_{N}$ 是节点 $N$ 中的观测数量，$\\bar{Y}_{N}$ 是节点 $N$ 中 $Y$ 的样本均值。由分裂引起的经验风险减少量为\n$$\n\\Delta \\;=\\; R_{\\text{parent}} \\;-\\; \\left(\\frac{n_{L}}{n}R_{L}\\;+\\;\\frac{n_{R}}{n}R_{R}\\right).\n$$\n\n假设随机森林使用的最小不纯度减少参数为 $\\lambda=10$（单位：平方毫米汞柱/样本），因此当且仅当 $\\Delta>\\lambda$ 时，该分裂才被接受。计算对于这个在 $t=27.0$ 对 $X_{2}$ 进行的候选分裂的净增益\n$$\nG \\;=\\; \\Delta \\;-\\; \\lambda。\n$$\n将 $G$ 的最终数值答案以平方毫米汞柱/样本为单位表示，并四舍五入到四位有效数字。",
            "solution": "我们从平方损失下的经验风险的定义开始。对于一个节点 $N$，经验风险为\n$$\nR_{N} \\;=\\; \\frac{1}{n_{N}}\\sum_{i\\in N}\\left(Y_{i}-\\bar{Y}_{N}\\right)^{2}。\n$$\n这是节点内的均方误差 (MSE)。在所有可能的 $\\mu$ 中，使 $\\frac{1}{n_{N}}\\sum_{i\\in N}\\left(Y_{i}-\\mu\\right)^{2}$ 最小化的值 $\\bar{Y}_{N}$ 是样本均值。这可以通过对 $\\mu$ 求导得出：\n$$\n\\frac{\\partial}{\\partial \\mu}\\left[\\frac{1}{n_{N}}\\sum_{i\\in N}\\left(Y_{i}-\\mu\\right)^{2}\\right]\n\\;=\\; \\frac{1}{n_{N}}\\sum_{i\\in N}\\left(-2\\right)\\left(Y_{i}-\\mu\\right)\n\\;=\\; -\\frac{2}{n_{N}}\\left(\\sum_{i\\in N}Y_{i}-n_{N}\\mu\\right),\n$$\n令其为零可得 $\\mu=\\bar{Y}_{N}$。因此，计算 $R_{N}$ 需要 $\\bar{Y}_{N}$ 和离差平方和。\n\n为了高效地计算离差平方和，我们使用恒等式\n$$\n\\sum_{i\\in N}\\left(Y_{i}-\\bar{Y}_{N}\\right)^{2}\n\\;=\\;\n\\sum_{i\\in N}Y_{i}^{2} \\;-\\; n_{N}\\,\\bar{Y}_{N}^{2},\n$$\n该恒等式可通过展开平方项并利用 $\\sum_{i\\in N} (Y_{i}-\\bar{Y}_{N}) = 0$ 推导得出。\n\n我们首先根据 $X_{2}$ 的分裂阈值 $t=27.0$ 来划分数据：\n- 左子节点 $L$ ($X_{2}\\leq 27.0$)：患者 $1,2,4,8,10$，其 $Y$ 值为 $\\{118,130,126,120,132\\}$，$n_{L}=5$。\n- 右子节点 $R$ ($X_{2}>27.0$)：患者 $3,5,6,7,9$，其 $Y$ 值为 $\\{142,150,134,138,160\\}$，$n_{R}=5$。\n父节点包含所有 $n=10$ 名患者。\n\n计算父节点的均值 $\\bar{Y}_{\\text{parent}}$：\n$$\n\\sum_{i=1}^{10} Y_{i} \\;=\\; 118+130+142+126+150+134+138+120+160+132 \\;=\\; 1350,\n$$\n所以\n$$\n\\bar{Y}_{\\text{parent}} \\;=\\; \\frac{1350}{10} \\;=\\; 135.\n$$\n计算父节点的 $\\sum Y_{i}^{2}$：\n$$\n118^{2}=13924,\\;\\;130^{2}=16900,\\;\\;142^{2}=20164,\\;\\;126^{2}=15876,\\;\\;150^{2}=22500,\n$$\n$$\n134^{2}=17956,\\;\\;138^{2}=19044,\\;\\;120^{2}=14400,\\;\\;160^{2}=25600,\\;\\;132^{2}=17424.\n$$\n将这些值相加，\n$$\n\\sum_{i=1}^{10} Y_{i}^{2} \\;=\\; 183788.\n$$\n因此，父节点的离差平方和（误差平方和，$\\text{SSE}_{\\text{parent}}$）是\n$$\n\\text{SSE}_{\\text{parent}} \\;=\\; \\sum_{i=1}^{10} Y_{i}^{2} - n\\,\\bar{Y}_{\\text{parent}}^{2}\n\\;=\\; 183788 \\;-\\; 10\\times 135^{2}\n\\;=\\; 183788 \\;-\\; 182250\n\\;=\\; 1538.\n$$\n因此父节点的风险是\n$$\nR_{\\text{parent}} \\;=\\; \\frac{\\text{SSE}_{\\text{parent}}}{n} \\;=\\; \\frac{1538}{10} \\;=\\; 153.8.\n$$\n\n计算左子节点的均值和 $\\text{SSE}_{L}$：\n$$\n\\sum_{i\\in L} Y_{i} \\;=\\; 118+130+126+120+132 \\;=\\; 626,\n\\quad\n\\bar{Y}_{L} \\;=\\; \\frac{626}{5} \\;=\\; 125.2,\n$$\n$$\n\\sum_{i\\in L} Y_{i}^{2} \\;=\\; 13924+16900+15876+14400+17424 \\;=\\; 78524,\n$$\n所以\n$$\n\\text{SSE}_{L} \\;=\\; 78524 \\;-\\; 5\\times (125.2)^{2}.\n$$\n计算 $(125.2)^{2}$：\n$$\n(125.2)^{2} \\;=\\; 15675.04,\n$$\n因此\n$$\n\\text{SSE}_{L} \\;=\\; 78524 \\;-\\; 5\\times 15675.04 \\;=\\; 78524 \\;-\\; 78375.2 \\;=\\; 148.8,\n$$\n并且\n$$\nR_{L} \\;=\\; \\frac{\\text{SSE}_{L}}{n_{L}} \\;=\\; \\frac{148.8}{5} \\;=\\; 29.76.\n$$\n\n计算右子节点的均值和 $\\text{SSE}_{R}$：\n$$\n\\sum_{i\\in R} Y_{i} \\;=\\; 142+150+134+138+160 \\;=\\; 724,\n\\quad\n\\bar{Y}_{R} \\;=\\; \\frac{724}{5} \\;=\\; 144.8,\n$$\n$$\n\\sum_{i\\in R} Y_{i}^{2} \\;=\\; 20164+22500+17956+19044+25600 \\;=\\; 105264,\n$$\n所以\n$$\n\\text{SSE}_{R} \\;=\\; 105264 \\;-\\; 5\\times (144.8)^{2}.\n$$\n计算 $(144.8)^{2}$：\n$$\n(144.8)^{2} \\;=\\; 20967.04,\n$$\n因此\n$$\n\\text{SSE}_{R} \\;=\\; 105264 \\;-\\; 5\\times 20967.04 \\;=\\; 105264 \\;-\\; 104835.2 \\;=\\; 428.8,\n$$\n并且\n$$\nR_{R} \\;=\\; \\frac{\\text{SSE}_{R}}{n_{R}} \\;=\\; \\frac{428.8}{5} \\;=\\; 85.76.\n$$\n\n计算经验风险的减少量 $\\Delta$：\n$$\n\\Delta \\;=\\; R_{\\text{parent}} \\;-\\; \\left(\\frac{n_{L}}{n}R_{L}\\;+\\;\\frac{n_{R}}{n}R_{R}\\right)\n\\;=\\; 153.8 \\;-\\; \\left(\\frac{5}{10}\\times 29.76 \\;+\\; \\frac{5}{10}\\times 85.76\\right).\n$$\n评估加权子节点风险：\n$$\n\\frac{5}{10}\\times 29.76 \\;=\\; 14.88,\\qquad \\frac{5}{10}\\times 85.76 \\;=\\; 42.88,\n$$\n所以\n$$\n\\frac{n_{L}}{n}R_{L}\\;+\\;\\frac{n_{R}}{n}R_{R} \\;=\\; 14.88+42.88 \\;=\\; 57.76,\n$$\n并且\n$$\n\\Delta \\;=\\; 153.8 \\;-\\; 57.76 \\;=\\; 96.04.\n$$\n\n在最小不纯度减少参数 $\\lambda=10$ 的情况下，净增益为\n$$\nG \\;=\\; \\Delta \\;-\\; \\lambda \\;=\\; 96.04 \\;-\\; 10 \\;=\\; 86.04.\n$$\n因为 $G>0$，根据随机森林的准则，该分裂将被接受。根据题目要求，我们报告的 $G$ 值应四舍五入到四位有效数字。数值 $86.04$ 已经有四位有效数字。",
            "answer": "$$\\boxed{86.04}$$"
        },
        {
            "introduction": "随机森林的一个关键优势是能够生成袋外（Out-Of-Bag, OOB）预测，它为模型性能提供了一种无偏估计，而无需独立的测试集。这个高级练习将挑战您使用这些 OOB 预测，超越简单的准确率，去评估模型在不同人群子组间的公平性。通过从零开始实现性能指标的计算，您将掌握在生物统计学中负责任地评估和部署机器学习模型的关键技能 。",
            "id": "4910502",
            "problem": "给定一个二元分类场景，该场景源于一个决策树集成模型（如随机森林）。每个观测值都有一个正类的袋外 (OOB) 预测概率、一个真实的二元标签以及一个分类人口子群标签。您的任务是编写一个完整的、可运行的程序，该程序从基本原理出发，使用基于混淆矩阵的比率和均方损失的定义，根据 OOB 预测概率计算分组性能指标，然后计算两个指定人口子群之间的绝对差异。\n\n在您的推理和实现中需要使用的定义：\n- 一个观测值的袋外 (OOB) 预测概率，是在自助采样过程中，未在该观测值上训练的那些树的平均预测概率，它被视为对该观测值预测的无偏估计。\n- 给定一个分类阈值 $\\tau$，根据规则 $\\hat{y}_i = 1$ (如果 $p_i \\ge \\tau$) 和 $\\hat{y}_i = 0$ (其它情况)，将 OOB 预测概率 $p_i$ 转换为预测类别 $\\hat{y}_i$。\n- 对于任何子群，从该子群的 $\\{\\hat{y}_i, y_i\\}$ 中定义混淆矩阵计数：真阳性、假阳性、真阴性、假阴性。根据这些计数，使用它们的标准定义推导出真阳性率、假阳性率和阳性预测值。\n- 将任何子群的 Brier 分数定义为该子群内预测概率与真实标签之间的均方误差。\n\n您的程序必须实现以下功能，并将其应用于下面提供的每个测试用例：\n1. 分别为子群 $\\mathrm{A}$ 和子群 $\\mathrm{B}$ 计算以下四个指标：\n   - 真阳性率，\n   - 假阳性率，\n   - 阳性预测值，\n   - Brier 分数。\n2. 计算子群 $\\mathrm{A}$ 和子群 $\\mathrm{B}$ 之间每个指标的绝对差异（即子群指标之差的绝对值）。\n3. 需要强制执行的边界情况约定：\n   - 如果某个子群的比率定义中任何分母为零，则该子群的该比率定义为 $0$。\n   - 所有绝对差异必须是非负实数。\n\n输入规范已在程序中固定（无用户输入）。使用以下测试套件，其中数组按 OOB 预测概率、真实标签、子群标签和阈值 $\\tau$ 的顺序给出：\n- 测试用例 1：\n  - OOB 预测概率：$[0.9, 0.4, 0.7, 0.2, 0.8, 0.3]$\n  - 真实标签：$[1, 0, 1, 0, 1, 0]$\n  - 子群：$[\\mathrm{A}, \\mathrm{A}, \\mathrm{A}, \\mathrm{B}, \\mathrm{B}, \\mathrm{B}]$\n  - 阈值：$\\tau = 0.5$\n- 测试用例 2：\n  - OOB 预测概率：$[0.6, 0.2, 0.7, 0.9, 0.1]$\n  - 真实标签：$[0, 0, 1, 1, 0]$\n  - 子群：$[\\mathrm{A}, \\mathrm{A}, \\mathrm{B}, \\mathrm{B}, \\mathrm{B}]$\n  - 阈值：$\\tau = 0.5$\n- 测试用例 3：\n  - OOB 预测概率：$[0.4, 0.6, 0.3, 0.9, 0.2]$\n  - 真实标签：$[0, 1, 0, 1, 0]$\n  - 子群：$[\\mathrm{A}, \\mathrm{A}, \\mathrm{B}, \\mathrm{B}, \\mathrm{B}]$\n  - 阈值：$\\tau = 0.0$\n- 测试用例 4：\n  - OOB 预测概率：$[1.0, 0.8, 0.2, 0.7, 0.99, 0.95]$\n  - 真实标签：$[1, 0, 0, 0, 1, 1]$\n  - 子群：$[\\mathrm{A}, \\mathrm{A}, \\mathrm{A}, \\mathrm{B}, \\mathrm{B}, \\mathrm{B}]$\n  - 阈值：$\\tau = 1.0$\n\n对于每个测试用例，您的程序必须按以下顺序输出包含四个浮点数的列表：\n$[$ $\\mathrm{A}$ 和 $\\mathrm{B}$ 之间的真阳性率绝对差异, 假阳性率绝对差异, 阳性预测值绝对差异, Brier 分数绝对差异 $]$。\n\n最终输出格式：\n- 您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表。所有测试用例的结果按顺序连接成一个扁平列表。每个浮点结果必须四舍五入到小数点后恰好 $6$ 位。例如，一个包含两个测试用例的有效输出应如下所示 $[0.125000,0.500000,0.000000,0.031250,0.333333,0.000000,0.200000,0.100000]$。",
            "solution": "该问题是有效的。它提出了一个在生物统计学和机器学习模型评估领域中定义明确的任务，该任务基于标准的、可形式化的定义。所有必要的数据和参数都已提供，约束条件一致，并且没有科学或逻辑上的缺陷。\n\n此问题要求为一个二元分类器计算几项按人口子群分层的标准性能指标，并随后计算这些指标在表示为 $\\mathrm{A}$ 和 $\\mathrm{B}$ 的两个组之间的绝对差异。这些指标包括真阳性率 ($TPR$)、假阳性率 ($FPR$)、阳性预测值 ($PPV$) 和 Brier 分数 ($BS$)。\n\n首先，我们对定义进行形式化。设子群 $G$ 的数据集包含 $N_G$ 个观测值，其中每个观测值 $i$ 都有一个袋外 (OOB) 预测概率 $p_i$、一个真实标签 $y_i \\in \\{0, 1\\}$ 和一个子群标签。对于给定的分类阈值 $\\tau$，预测标签 $\\hat{y}_i$ 由以下规则确定：\n$$\n\\hat{y}_i = \\begin{cases} 1  \\text{if } p_i \\ge \\tau \\\\ 0  \\text{if } p_i  \\tau \\end{cases}\n$$\n\n子群 $G$ 的性能指标源自真阳性 ($TP_G$)、假阳性 ($FP_G$)、真阴性 ($TN_G$) 和假阴性 ($FN_G$) 的计数：\n- $TP_G = \\sum_{i \\in G} \\mathbf{1}(y_i = 1 \\text{ and } \\hat{y}_i = 1)$\n- $FP_G = \\sum_{i \\in G} \\mathbf{1}(y_i = 0 \\text{ and } \\hat{y}_i = 1)$\n- $TN_G = \\sum_{i \\in G} \\mathbf{1}(y_i = 0 \\text{ and } \\hat{y}_i = 0)$\n- $FN_G = \\sum_{i \\in G} \\mathbf{1}(y_i = 1 \\text{ and } \\hat{y}_i = 0)$\n其中 $\\mathbf{1}(\\cdot)$ 是指示函数。\n\n然后，这些比率定义如下：\n- **真阳性率 (灵敏度/召回率)**：$TPR_G = \\frac{TP_G}{TP_G + FN_G}$。分母是子群 $G$ 中实际正例的总数。\n- **假阳性率**：$FPR_G = \\frac{FP_G}{FP_G + TN_G}$。分母是子群 $G$ 中实际负例的总数。\n- **阳性预测值 (精确率)**：$PPV_G = \\frac{TP_G}{TP_G + FP_G}$。分母是子群 $G$ 中预测为正例的总数。\n\n根据问题规范，如果这些分母中的任何一个为零，则相应的比率定义为 $0$。\n\n子群 $G$ 的 **Brier 分数** 是预测概率与真实标签之间的均方误差：\n$$\nBS_G = \\frac{1}{N_G} \\sum_{i \\in G} (p_i - y_i)^2\n$$\n其中 $N_G$ 是子群 $G$ 中的个体数量。\n\n最后，每个指标 $M \\in \\{TPR, FPR, PPV, BS\\}$ 的绝对差异计算为 $\\Delta_{M} = |M_A - M_B|$。\n\n现在我们将这些定义应用于每个测试用例。\n\n**测试用例 1**：\n- 数据：$p = [0.9, 0.4, 0.7, 0.2, 0.8, 0.3]$，$y = [1, 0, 1, 0, 1, 0]$，子群 = $[\\mathrm{A}, \\mathrm{A}, \\mathrm{A}, \\mathrm{B}, \\mathrm{B}, \\mathrm{B}]$，$\\tau = 0.5$。\n- 子群 A 数据：$p_A = [0.9, 0.4, 0.7]$，$y_A = [1, 0, 1]$。当 $\\tau=0.5$ 时，$\\hat{y}_A=[1, 0, 1]$。\n- A 组计数：$TP_A=2, FP_A=0, TN_A=1, FN_A=0$。\n- A 组指标：$TPR_A = \\frac{2}{2+0} = 1$。$FPR_A = \\frac{0}{0+1} = 0$。$PPV_A = \\frac{2}{2+0} = 1$。$BS_A = \\frac{1}{3}((0.9-1)^2 + (0.4-0)^2 + (0.7-1)^2) = \\frac{0.01+0.16+0.09}{3} = \\frac{0.26}{3}$。\n- 子群 B 数据：$p_B = [0.2, 0.8, 0.3]$，$y_B = [0, 1, 0]$。当 $\\tau=0.5$ 时，$\\hat{y}_B=[0, 1, 0]$。\n- B 组计数：$TP_B=1, FP_B=0, TN_B=2, FN_B=0$。\n- B 组指标：$TPR_B = \\frac{1}{1+0} = 1$。$FPR_B = \\frac{0}{0+2} = 0$。$PPV_B = \\frac{1}{1+0} = 1$。$BS_B = \\frac{1}{3}((0.2-0)^2 + (0.8-1)^2 + (0.3-0)^2) = \\frac{0.04+0.04+0.09}{3} = \\frac{0.17}{3}$。\n- 差异：$\\Delta_{TPR} = |1-1|=0$。$\\Delta_{FPR} = |0-0|=0$。$\\Delta_{PPV} = |1-1|=0$。$\\Delta_{BS} = |\\frac{0.26}{3} - \\frac{0.17}{3}| = \\frac{0.09}{3} = 0.03$。\n\n**测试用例 2**：\n- 数据：$p = [0.6, 0.2, 0.7, 0.9, 0.1]$，$y = [0, 0, 1, 1, 0]$，子群 = $[\\mathrm{A}, \\mathrm{A}, \\mathrm{B}, \\mathrm{B}, \\mathrm{B}]$，$\\tau = 0.5$。\n- 子群 A 数据：$p_A = [0.6, 0.2]$，$y_A = [0, 0]$。当 $\\tau=0.5$ 时，$\\hat{y}_A=[1, 0]$。\n- A 组计数：$TP_A=0, FP_A=1, TN_A=1, FN_A=0$。\n- A 组指标：实际正例 $TP_A+FN_A=0 \\implies TPR_A=0$。$FPR_A=\\frac{1}{1+1}=0.5$。$PPV_A=\\frac{0}{0+1}=0$。$BS_A = \\frac{1}{2}((0.6-0)^2 + (0.2-0)^2) = \\frac{0.36+0.04}{2} = 0.2$。\n- 子群 B 数据：$p_B = [0.7, 0.9, 0.1]$，$y_B = [1, 1, 0]$。当 $\\tau=0.5$ 时，$\\hat{y}_B=[1, 1, 0]$。\n- B 组计数：$TP_B=2, FP_B=0, TN_B=1, FN_B=0$。\n- B 组指标：$TPR_B = \\frac{2}{2+0}=1$。$FPR_B = \\frac{0}{0+1}=0$。$PPV_B=\\frac{2}{2+0}=1$。$BS_B = \\frac{1}{3}((0.7-1)^2 + (0.9-1)^2 + (0.1-0)^2) = \\frac{0.09+0.01+0.01}{3} = \\frac{0.11}{3}$。\n- 差异：$\\Delta_{TPR} = |0-1|=1$。$\\Delta_{FPR} = |0.5-0|=0.5$。$\\Delta_{PPV} = |0-1|=1$。$\\Delta_{BS} = |0.2 - \\frac{0.11}{3}| = |\\frac{0.6-0.11}{3}| = \\frac{0.49}{3} \\approx 0.163333$。\n\n**测试用例 3**：\n- 数据：$p = [0.4, 0.6, 0.3, 0.9, 0.2]$，$y = [0, 1, 0, 1, 0]$，子群 = $[\\mathrm{A}, \\mathrm{A}, \\mathrm{B}, \\mathrm{B}, \\mathrm{B}]$，$\\tau = 0.0$。\n- 由于所有概率都 $\\ge 0$，因此所有 $\\hat{y_i}=1$。\n- 子群 A 数据：$p_A=[0.4, 0.6]$，$y_A=[0, 1]$。$\\hat{y}_A=[1, 1]$。\n- A 组计数：$TP_A=1, FP_A=1, TN_A=0, FN_A=0$。\n- A 组指标：$TPR_A=\\frac{1}{1+0}=1$。$FPR_A=\\frac{1}{1+0}=1$。$PPV_A=\\frac{1}{1+1}=0.5$。$BS_A = \\frac{1}{2}((0.4-0)^2+(0.6-1)^2) = \\frac{0.16+0.16}{2}=0.16$。\n- 子群 B 数据：$p_B=[0.3, 0.9, 0.2]$，$y_B=[0, 1, 0]$。$\\hat{y}_B=[1, 1, 1]$。\n- B 组计数：$TP_B=1, FP_B=2, TN_B=0, FN_B=0$。\n- B 组指标：$TPR_B=\\frac{1}{1+0}=1$。$FPR_B=\\frac{2}{2+0}=1$。$PPV_B=\\frac{1}{1+2}=\\frac{1}{3}$。$BS_B = \\frac{1}{3}((0.3-0)^2+(0.9-1)^2+(0.2-0)^2) = \\frac{0.09+0.01+0.04}{3} = \\frac{0.14}{3}$。\n- 差异：$\\Delta_{TPR} = |1-1|=0$。$\\Delta_{FPR} = |1-1|=0$。$\\Delta_{PPV} = |0.5 - \\frac{1}{3}| = \\frac{1}{6} \\approx 0.166667$。$\\Delta_{BS} = |0.16 - \\frac{0.14}{3}| = |\\frac{0.48-0.14}{3}| = \\frac{0.34}{3} \\approx 0.113333$。\n\n**测试用例 4**：\n- 数据：$p = [1.0, 0.8, 0.2, 0.7, 0.99, 0.95]$，$y = [1, 0, 0, 0, 1, 1]$，子群 = $[\\mathrm{A}, \\mathrm{A}, \\mathrm{A}, \\mathrm{B}, \\mathrm{B}, \\mathrm{B}]$，$\\tau = 1.0$。\n- 仅当 $p \\ge 1.0$ 时，预测值为 $1$。\n- 子群 A 数据：$p_A=[1.0, 0.8, 0.2]$，$y_A=[1, 0, 0]$。$\\hat{y}_A=[1, 0, 0]$。\n- A 组计数：$TP_A=1, FP_A=0, TN_A=2, FN_A=0$。\n- A 组指标：$TPR_A=\\frac{1}{1+0}=1$。$FPR_A=\\frac{0}{0+2}=0$。$PPV_A=\\frac{1}{1+0}=1$。$BS_A = \\frac{1}{3}((1.0-1)^2+(0.8-0)^2+(0.2-0)^2) = \\frac{0+0.64+0.04}{3} = \\frac{0.68}{3}$。\n- 子群 B 数据：$p_B=[0.7, 0.99, 0.95]$，$y_B=[0, 1, 1]$。$\\hat{y}_B=[0, 0, 0]$。\n- B 组计数：$TP_B=0, FP_B=0, TN_B=1, FN_B=2$。\n- B 组指标：$TPR_B=\\frac{0}{0+2}=0$。$FPR_B=\\frac{0}{0+1}=0$。预测正例 $TP_B+FP_B=0 \\implies PPV_B=0$。$BS_B = \\frac{1}{3}((0.7-0)^2+(0.99-1)^2+(0.95-1)^2) = \\frac{0.49+0.0001+0.0025}{3} = \\frac{0.4926}{3}$。\n- 差异：$\\Delta_{TPR} = |1-0|=1$。$\\Delta_{FPR} = |0-0|=0$。$\\Delta_{PPV} = |1-0|=1$。$\\Delta_{BS} = |\\frac{0.68}{3} - \\frac{0.4926}{3}| = \\frac{0.1874}{3} \\approx 0.062467$。\n\n以下程序实现了这些计算。",
            "answer": "```python\nimport numpy as np\n\ndef calculate_metrics(probs, labels, threshold):\n    \"\"\"\n    Computes performance metrics for a single subgroup.\n\n    Args:\n        probs (np.ndarray): Predicted probabilities for the positive class.\n        labels (np.ndarray): True binary labels (0 or 1).\n        threshold (float): Classification threshold.\n\n    Returns:\n        tuple: A tuple containing (tpr, fpr, ppv, brier_score).\n    \"\"\"\n    if len(labels) == 0:\n        return 0.0, 0.0, 0.0, 0.0\n\n    # Brier Score computation\n    brier_score = np.mean((probs - labels) ** 2)\n\n    # Convert probabilities to predicted labels\n    predicted_labels = (probs >= threshold).astype(int)\n\n    # Confusion matrix counts\n    tp = np.sum((predicted_labels == 1)  (labels == 1))\n    fp = np.sum((predicted_labels == 1)  (labels == 0))\n    tn = np.sum((predicted_labels == 0)  (labels == 0))\n    fn = np.sum((predicted_labels == 0)  (labels == 1))\n\n    # Denominators for the rates\n    actual_positives = tp + fn\n    actual_negatives = fp + tn\n    predicted_positives = tp + fp\n\n    # True Positive Rate (TPR)\n    tpr = tp / actual_positives if actual_positives  0 else 0.0\n\n    # False Positive Rate (FPR)\n    fpr = fp / actual_negatives if actual_negatives  0 else 0.0\n\n    # Positive Predictive Value (PPV)\n    ppv = tp / predicted_positives if predicted_positives  0 else 0.0\n\n    return tpr, fpr, ppv, brier_score\n\ndef solve():\n    \"\"\"\n    Main function to process test cases and compute disparities.\n    \"\"\"\n    test_cases = [\n        (np.array([0.9, 0.4, 0.7, 0.2, 0.8, 0.3]),\n         np.array([1, 0, 1, 0, 1, 0]),\n         np.array(['A', 'A', 'A', 'B', 'B', 'B']),\n         0.5),\n        (np.array([0.6, 0.2, 0.7, 0.9, 0.1]),\n         np.array([0, 0, 1, 1, 0]),\n         np.array(['A', 'A', 'B', 'B', 'B']),\n         0.5),\n        (np.array([0.4, 0.6, 0.3, 0.9, 0.2]),\n         np.array([0, 1, 0, 1, 0]),\n         np.array(['A', 'A', 'B', 'B', 'B']),\n         0.0),\n        (np.array([1.0, 0.8, 0.2, 0.7, 0.99, 0.95]),\n         np.array([1, 0, 0, 0, 1, 1]),\n         np.array(['A', 'A', 'A', 'B', 'B', 'B']),\n         1.0)\n    ]\n\n    all_results = []\n    for probs, labels, subgroups, threshold in test_cases:\n        # Filter data for subgroup A\n        mask_a = subgroups == 'A'\n        probs_a = probs[mask_a]\n        labels_a = labels[mask_a]\n\n        # Filter data for subgroup B\n        mask_b = subgroups == 'B'\n        probs_b = probs[mask_b]\n        labels_b = labels[mask_b]\n\n        # Calculate metrics for each subgroup\n        tpr_a, fpr_a, ppv_a, bs_a = calculate_metrics(probs_a, labels_a, threshold)\n        tpr_b, fpr_b, ppv_b, bs_b = calculate_metrics(probs_b, labels_b, threshold)\n\n        # Calculate absolute disparities\n        disp_tpr = abs(tpr_a - tpr_b)\n        disp_fpr = abs(fpr_a - fpr_b)\n        disp_ppv = abs(ppv_a - ppv_b)\n        disp_bs = abs(bs_a - bs_b)\n        \n        case_results = [disp_tpr, disp_fpr, disp_ppv, disp_bs]\n        all_results.extend(case_results)\n\n    # Format the final output string\n    formatted_results = [f\"{res:.6f}\" for res in all_results]\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```"
        }
    ]
}