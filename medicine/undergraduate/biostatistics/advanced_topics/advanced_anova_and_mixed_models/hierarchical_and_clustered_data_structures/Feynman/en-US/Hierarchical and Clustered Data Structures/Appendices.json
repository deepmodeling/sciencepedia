{
    "hands_on_practices": [
        {
            "introduction": "Before applying complex statistical methods, a crucial first step in analyzing hierarchical data is to quantify the degree of dependency. The Intraclass Correlation Coefficient (ICC) measures the proportion of total variance in an outcome that can be attributed to differences between clusters. This exercise  provides hands-on practice in calculating the ICC from the variance components of a random-intercepts model, a fundamental skill for assessing whether specialized hierarchical models are truly necessary.",
            "id": "4915039",
            "problem": "A public health study investigates systolic blood pressure measured for individuals nested within clinics, where clinics are treated as clusters. Let $Y_{ij}$ denote the continuous outcome for individual $i$ in clinic $j$. Consider the random-intercepts linear mixed model $Y_{ij}=\\mu+b_{j}+\\varepsilon_{ij}$, where $b_{j}$ are independent and identically distributed as mean $0$ and variance $\\sigma_{b}^{2}$, and $\\varepsilon_{ij}$ are independent and identically distributed as mean $0$ and variance $\\sigma_{w}^{2}$, with $b_{j}$ independent of $\\varepsilon_{ij}$. Using restricted maximum likelihood estimation, the between-clinic variance is estimated as $\\hat{\\sigma}_{b}^{2}=0.8$ and the within-clinic variance is estimated as $\\hat{\\sigma}_{w}^{2}=1.2$ (both on the original squared units of the outcome). Based on the core definition of the intraclass correlation coefficient (ICC), defined as the correlation between two randomly chosen individuals from the same clinic under this model, compute the estimated ICC and briefly interpret its magnitude in terms of cluster cohesion. Express the final numerical answer for the ICC as a unitless decimal rounded to $4$ significant figures.",
            "solution": "The problem statement is evaluated and deemed valid. It is scientifically grounded in the principles of mixed-effects statistical modeling, is well-posed with all necessary information provided, and is expressed in objective, unambiguous language.\n\nThe problem describes a random-intercepts linear mixed model for a continuous outcome $Y_{ij}$ (systolic blood pressure for individual $i$ in clinic $j$):\n$$ Y_{ij} = \\mu + b_j + \\varepsilon_{ij} $$\nIn this model:\n- $\\mu$ is the overall mean systolic blood pressure.\n- $b_j$ is the random intercept for clinic $j$, representing the deviation of clinic $j$'s mean from the overall mean $\\mu$. These random effects are assumed to be independent and identically distributed (i.i.d.) with a mean of $0$ and a variance of $\\sigma_{b}^{2}$, which is the between-clinic variance.\n- $\\varepsilon_{ij}$ is the random error for individual $i$ within clinic $j$, representing the deviation of individual $i$'s measurement from their clinic's mean. These errors are assumed to be i.i.d. with a mean of $0$ and a variance of $\\sigma_{w}^{2}$, the within-clinic variance.\n- The random effects $b_j$ and the errors $\\varepsilon_{ij}$ are assumed to be independent of each other.\n\nThe intraclass correlation coefficient (ICC), denoted by $\\rho$, is defined in this context as the correlation between the outcomes of two different individuals, say $i$ and $k$ where $i \\neq k$, randomly chosen from the same clinic $j$. Mathematically, this is expressed as:\n$$ \\rho = \\text{Corr}(Y_{ij}, Y_{kj}) $$\nThe standard formula for the correlation between two random variables $X$ and $Z$ is $\\text{Corr}(X, Z) = \\frac{\\text{Cov}(X, Z)}{\\sqrt{\\text{Var}(X)\\text{Var}(Z)}}$. Applying this to our model:\n$$ \\rho = \\frac{\\text{Cov}(Y_{ij}, Y_{kj})}{\\sqrt{\\text{Var}(Y_{ij})\\text{Var}(Y_{kj})}} $$\n\nTo calculate $\\rho$, we must first find the total variance of a single observation, $\\text{Var}(Y_{ij})$, and the covariance between two observations from the same cluster, $\\text{Cov}(Y_{ij}, Y_{kj})$.\n\nThe total variance of $Y_{ij}$ is found by taking the variance of the model equation. Since $\\mu$ is a constant, $\\text{Var}(\\mu) = 0$. Due to the independence of $b_j$ and $\\varepsilon_{ij}$, the variance of their sum is the sum of their variances:\n$$ \\text{Var}(Y_{ij}) = \\text{Var}(\\mu + b_j + \\varepsilon_{ij}) = \\text{Var}(b_j) + \\text{Var}(\\varepsilon_{ij}) = \\sigma_{b}^{2} + \\sigma_{w}^{2} $$\nThis expression, $\\sigma_{b}^{2} + \\sigma_{w}^{2}$, is the total variance of the outcome.\n\nThe covariance between the outcomes of two different individuals $i$ and $k$ ($i \\neq k$) within the same clinic $j$ is:\n$$ \\text{Cov}(Y_{ij}, Y_{kj}) = \\text{Cov}(\\mu + b_j + \\varepsilon_{ij}, \\mu + b_j + \\varepsilon_{kj}) $$\nUsing the properties of covariance, and noting that the shared term between the two expressions is the clinic's random effect $b_j$:\n$$ \\text{Cov}(Y_{ij}, Y_{kj}) = \\text{Cov}(b_j, b_j) + \\text{Cov}(b_j, \\varepsilon_{kj}) + \\text{Cov}(\\varepsilon_{ij}, b_j) + \\text{Cov}(\\varepsilon_{ij}, \\varepsilon_{kj}) $$\nBased on the model assumptions:\n- $\\text{Cov}(b_j, b_j) = \\text{Var}(b_j) = \\sigma_{b}^{2}$.\n- $\\text{Cov}(b_j, \\varepsilon_{kj}) = 0$ and $\\text{Cov}(\\varepsilon_{ij}, b_j) = 0$ due to the independence of random effects and errors.\n- $\\text{Cov}(\\varepsilon_{ij}, \\varepsilon_{kj}) = 0$ for $i \\neq k$ because the errors for distinct individuals are independent.\nTherefore, the covariance simplifies to:\n$$ \\text{Cov}(Y_{ij}, Y_{kj}) = \\sigma_{b}^{2} $$\nThe covariance between two members of the same cluster is equal to the between-cluster variance. This is the source of the correlation within clusters.\n\nSubstituting the expressions for variance and covariance into the formula for $\\rho$:\n$$ \\rho = \\frac{\\sigma_{b}^{2}}{\\sqrt{(\\sigma_{b}^{2} + \\sigma_{w}^{2})(\\sigma_{b}^{2} + \\sigma_{w}^{2})}} = \\frac{\\sigma_{b}^{2}}{\\sigma_{b}^{2} + \\sigma_{w}^{2}} $$\nThe ICC is the proportion of the total variance that is due to the variation between clusters.\n\nThe problem provides the restricted maximum likelihood (REML) estimates for the variance components: $\\hat{\\sigma}_{b}^{2} = 0.8$ (between-clinic) and $\\hat{\\sigma}_{w}^{2} = 1.2$ (within-clinic). We use these estimates to compute the estimated ICC, $\\hat{\\rho}$:\n$$ \\hat{\\rho} = \\frac{\\hat{\\sigma}_{b}^{2}}{\\hat{\\sigma}_{b}^{2} + \\hat{\\sigma}_{w}^{2}} = \\frac{0.8}{0.8 + 1.2} = \\frac{0.8}{2.0} = 0.4 $$\nThe problem requires the answer to be expressed as a decimal rounded to $4$ significant figures.\n$$ \\hat{\\rho} = 0.4000 $$\n\nAn ICC of $0.4$ indicates a moderate degree of similarity, or \"cohesion,\" among individuals within the same clinic. Specifically, it means that an estimated $40\\%$ of the total variability in systolic blood pressure measurements can be attributed to systematic differences between the clinics. This level of correlation is non-negligible and confirms that observations from the same clinic are not independent, justifying the use of a mixed-effects model over a simpler model like ordinary least squares regression that assumes independence of all observations. A higher ICC would imply stronger clustering (individuals within a clinic are very alike), while an ICC near $0$ would imply that the clinic grouping has little to no effect on the outcome.",
            "answer": "$$\\boxed{0.4000}$$"
        },
        {
            "introduction": "In a multilevel setting, the association between a predictor and an outcome can be complex; it may operate differently for individuals within the same cluster compared to the average differences between clusters. By decomposing a predictor into its within-cluster and between-cluster components, we can disentangle these effects and avoid misleading interpretations like the ecological fallacy. This practice  guides you through the process of estimating and comparing these separate effects, revealing a more nuanced understanding of the data's structure.",
            "id": "4915003",
            "problem": "A multicenter observational study investigates the association between a circulating inflammatory biomarker, denoted by $X$, and systolic blood pressure, denoted by $Y$, across clinics. Patients are nested within clinics, forming a clustered data structure. The goal is to decompose the biomarker’s association into a within-clinic component and a between-clinic component and then assess whether these two components have different associations with the outcome.\n\nYou are provided patient-level measurements for $3$ clinics, each with $2$ patients:\n- Clinic $1$: biomarker values $X$: $2$, $4$; blood pressures $Y$: $95$, $106$.\n- Clinic $2$: biomarker values $X$: $5$, $7$; blood pressures $Y$: $123$, $137$.\n- Clinic $3$: biomarker values $X$: $3$, $9$; blood pressures $Y$: $114$, $145$.\n\nLet patients be indexed by $i$ and clinics by $j$. Compute the clinic-specific biomarker mean $\\bar{X}_{j}$ for each clinic and the overall biomarker mean $\\bar{X}$ across all patients. Define the within-clinic biomarker component by $W_{ij} = X_{ij} - \\bar{X}_{j}$ and define the between-clinic biomarker component by $B_{ij} = \\bar{X}_{j} - \\bar{X}$ (the clinic mean centered by the overall mean). Consider the linear model\n$$Y_{ij} = \\alpha + \\beta_{W} W_{ij} + \\beta_{B} B_{ij} + \\varepsilon_{ij},$$\nfit using Ordinary Least Squares (OLS). Using the data above and the definitions of $W_{ij}$ and $B_{ij}$, estimate the within-clinic effect $\\beta_{W}$ and the between-clinic effect $\\beta_{B}$, and then test whether these two effects are equal via a Student’s $t$-statistic for the null hypothesis $H_{0}: \\beta_{W} = \\beta_{B}$ based on the OLS fit.\n\nReport the value of the $t$-statistic as a unitless quantity. Round your final answer to four significant figures.",
            "solution": "The problem asks us to perform a contextual effects analysis by decomposing a predictor into its within-clinic and between-clinic components, fitting a linear model using these components, and testing for a difference between their effects.\n\n**Step 1: Calculate Component Variables**\n\nFirst, we organize the provided data and compute the necessary means and predictor components. The data consists of $n=6$ observations across $j=1, 2, 3$ clinics.\n\n- **Clinic 1**: $X_{11}=2, Y_{11}=95$; $X_{21}=4, Y_{21}=106$. The clinic mean is $\\bar{X}_1 = (2+4)/2 = 3$.\n- **Clinic 2**: $X_{12}=5, Y_{12}=123$; $X_{22}=7, Y_{22}=137$. The clinic mean is $\\bar{X}_2 = (5+7)/2 = 6$.\n- **Clinic 3**: $X_{13}=3, Y_{13}=114$; $X_{23}=9, Y_{23}=145$. The clinic mean is $\\bar{X}_3 = (3+9)/2 = 6$.\n\nThe overall mean of the biomarker across all patients is $\\bar{X} = (2+4+5+7+3+9)/6 = 30/6 = 5$.\n\nNow, we compute the within-clinic ($W_{ij} = X_{ij} - \\bar{X}_j$) and between-clinic ($B_{ij} = \\bar{X}_j - \\bar{X}$) components for each patient:\n- Patient (1,1): $W_{11} = 2-3 = -1$; $B_{11} = 3-5 = -2$.\n- Patient (2,1): $W_{21} = 4-3 = 1$; $B_{21} = 3-5 = -2$.\n- Patient (1,2): $W_{12} = 5-6 = -1$; $B_{12} = 6-5 = 1$.\n- Patient (2,2): $W_{22} = 7-6 = 1$; $B_{22} = 6-5 = 1$.\n- Patient (1,3): $W_{13} = 3-6 = -3$; $B_{13} = 6-5 = 1$.\n- Patient (2,3): $W_{23} = 9-6 = 3$; $B_{23} = 6-5 = 1$.\n\n**Step 2: Fit the OLS Model**\n\nThe model is $Y_{ij} = \\alpha + \\beta_{W} W_{ij} + \\beta_{B} B_{ij} + \\varepsilon_{ij}$. By construction, the predictors $W$ and $B$ are orthogonal to each other and to the intercept term. This simplifies the OLS estimation. The coefficients for the within-clinic and between-clinic effects can be estimated as:\n- $\\hat{\\beta}_{W} = \\frac{\\sum W_{ij} Y_{ij}}{\\sum W_{ij}^2}$\n- $\\hat{\\beta}_{B} = \\frac{\\sum B_{ij} Y_{ij}}{\\sum B_{ij}^2}$\n\nWe compute the necessary sums:\n- $\\sum W_{ij}^2 = (-1)^2 + 1^2 + (-1)^2 + 1^2 + (-3)^2 + 3^2 = 22$.\n- $\\sum B_{ij}^2 = (-2)^2 + (-2)^2 + 1^2 + 1^2 + 1^2 + 1^2 = 12$.\n- $\\sum W_{ij} Y_{ij} = (-1)(95) + (1)(106) + (-1)(123) + (1)(137) + (-3)(114) + (3)(145) = 118$.\n- $\\sum B_{ij} Y_{ij} = (-2)(95) + (-2)(106) + (1)(123) + (1)(137) + (1)(114) + (1)(145) = 117$.\n\nNow, we can estimate the coefficients:\n- $\\hat{\\beta}_{W} = \\frac{118}{22} = \\frac{59}{11}$.\n- $\\hat{\\beta}_{B} = \\frac{117}{12} = \\frac{39}{4}$.\n\n**Step 3: Test the Hypothesis $H_0: \\beta_W = \\beta_B$**\n\nWe want to test the null hypothesis $H_0: \\beta_W - \\beta_B = 0$. The $t$-statistic is $t = \\frac{(\\hat{\\beta}_W - \\hat{\\beta}_B)}{\\text{SE}(\\hat{\\beta}_W - \\hat{\\beta}_B)}$.\nThe difference in estimated coefficients is $\\hat{\\beta}_W - \\hat{\\beta}_B = \\frac{59}{11} - \\frac{39}{4} = \\frac{236 - 429}{44} = -\\frac{193}{44}$.\n\nTo find the standard error, we first need the residual variance, $\\hat{\\sigma}^2 = \\frac{\\text{RSS}}{n-p}$, where $n=6$ and the number of parameters is $p=3$ ($\\alpha, \\beta_W, \\beta_B$). The degrees of freedom is $df = 6-3=3$. The Residual Sum of Squares (RSS) is $\\text{RSS} = \\sum(Y_{ij} - \\bar{Y})^2 - (\\hat{\\beta}_W\\sum W_{ij}Y_{ij} + \\hat{\\beta}_B\\sum B_{ij}Y_{ij})$.\n- Total Sum of Squares (centered): $\\sum(Y_{ij} - \\bar{Y})^2 = \\sum Y_{ij}^2 - n\\bar{Y}^2 = 88180 - 6(120^2) = 1780$.\n- Regression Sum of Squares: $\\hat{\\beta}_W\\sum W_{ij}Y_{ij} + \\hat{\\beta}_B\\sum B_{ij}Y_{ij} = \\frac{59}{11}(118) + \\frac{39}{4}(117) = \\frac{78041}{44}$.\n- $\\text{RSS} = 1780 - \\frac{78041}{44} = \\frac{78320 - 78041}{44} = \\frac{279}{44}$.\n- $\\hat{\\sigma}^2 = \\frac{\\text{RSS}}{df} = \\frac{279/44}{3} = \\frac{93}{44}$.\n\nThe variance of the difference of coefficients is $\\text{Var}(\\hat{\\beta}_W - \\hat{\\beta}_B) = \\text{Var}(\\hat{\\beta}_W) + \\text{Var}(\\hat{\\beta}_B)$ because the predictors are orthogonal.\n- $\\text{Var}(\\hat{\\beta}_W) = \\frac{\\hat{\\sigma}^2}{\\sum W_{ij}^2} = \\frac{93/44}{22} = \\frac{93}{968}$.\n- $\\text{Var}(\\hat{\\beta}_B) = \\frac{\\hat{\\sigma}^2}{\\sum B_{ij}^2} = \\frac{93/44}{12} = \\frac{93}{528}$.\n- $\\text{Var}(\\hat{\\beta}_W - \\hat{\\beta}_B) = \\frac{93}{968} + \\frac{93}{528} = \\frac{93}{44} \\left( \\frac{1}{22} + \\frac{1}{12} \\right) = \\frac{93}{44} \\left( \\frac{17}{132} \\right) = \\frac{527}{1936}$.\nThe standard error is $\\text{SE}(\\hat{\\beta}_W - \\hat{\\beta}_B) = \\sqrt{\\frac{527}{1936}} = \\frac{\\sqrt{527}}{44}$.\n\nFinally, the $t$-statistic is:\n$$ t = \\frac{-\\frac{193}{44}}{\\frac{\\sqrt{527}}{44}} = -\\frac{193}{\\sqrt{527}} \\approx -\\frac{193}{22.95648} \\approx -8.40722 $$\nRounding to four significant figures, the $t$-statistic is -8.407. This large negative value indicates a statistically significant difference between the within-clinic and between-clinic effects of the biomarker on the $t$-distribution with 3 degrees of freedom, with the between-clinic association being much stronger than the within-clinic one.",
            "answer": "$$\n\\boxed{-8.407}\n$$"
        },
        {
            "introduction": "When moving from linear to non-linear hierarchical models, such as logistic regression, the interpretation of coefficients requires special care. The odds ratio measured for individuals within a specific cluster (the conditional or cluster-specific effect) is systematically different from the odds ratio measured across the entire population (the marginal or population-averaged effect). This advanced exercise  explores the non-collapsibility of the odds ratio, guiding you to derive the approximate mathematical relationship between the conditional effect from a Generalized Linear Mixed Model (GLMM) and its attenuated marginal counterpart, a vital concept for correctly interpreting many biostatistical studies.",
            "id": "4915054",
            "problem": "A biostatistics study records a binary outcome $Y_{ij} \\in \\{0,1\\}$ for patient $i$ in hospital $j$, along with a binary exposure $X_{ij} \\in \\{0,1\\}$. Suppose the data are plausibly generated from a hierarchical Generalized Linear Mixed Model (GLMM) with a logit link and a random intercept, where the conditional model for $Y_{ij}$ given the hospital-specific random effect $u_{j}$ is\n$$\n\\operatorname{logit}\\left\\{ \\Pr\\left(Y_{ij}=1 \\mid X_{ij}, u_{j}\\right) \\right\\} = \\alpha + \\beta X_{ij} + u_{j},\n$$\nwith $u_{j} \\sim \\mathcal{N}(0, \\sigma^{2})$ independent of $X_{ij}$. A fitted model yields estimates $\\hat{\\beta} = 1.10$ and $\\hat{\\sigma}^{2} = 0.60$. The conditional (cluster-specific) odds ratio for the exposure is $\\exp(\\beta)$.\n\nStarting from core definitions of the odds ratio, the logit link, and properties of normal mixtures, derive an approximate population-averaged (marginal) odds ratio for the exposure by analytically marginalizing over the random intercept distribution and invoking a principled approximation justified by distributional properties. Then, compute its numerical value using the provided estimates $\\hat{\\beta}$ and $\\hat{\\sigma}^{2}$, and briefly explain why the marginal odds ratio is attenuated relative to the conditional odds ratio in this random-intercept logistic setting.\n\nRound your final numerical odds ratio to four significant figures. No units are required in your answer.",
            "solution": "The problem requires the derivation of an approximate population-averaged (marginal) odds ratio from a given conditional (cluster-specific) hierarchical logistic model, the computation of its value from provided estimates, and an explanation for the attenuation compared to the conditional odds ratio.\n\nThe conditional model is defined for a binary outcome $Y_{ij} \\in \\{0,1\\}$ for patient $i$ in hospital $j$, with a binary exposure $X_{ij} \\in \\{0,1\\}$. The model is specified as a Generalized Linear Mixed Model (GLMM) with a logit link and a random intercept $u_j$:\n$$\n\\operatorname{logit}\\left\\{ \\Pr\\left(Y_{ij}=1 \\mid X_{ij}, u_{j}\\right) \\right\\} = \\alpha + \\beta X_{ij} + u_{j}\n$$\nwhere $u_{j} \\sim \\mathcal{N}(0, \\sigma^{2})$ are independent and identically distributed random effects for each hospital $j$. The fitted model provides the estimates $\\hat{\\beta} = 1.10$ and $\\hat{\\sigma}^{2} = 0.60$.\n\nFirst, we establish the definitions of the conditional and marginal odds ratios.\n\nThe conditional odds ratio (OR) is defined for a fixed level of the random effect $u_j$. The log-odds for an individual with exposure $X_{ij}=1$ in hospital $j$ are $\\alpha + \\beta(1) + u_j$. The log-odds for an individual with exposure $X_{ij}=0$ in the same hospital are $\\alpha + \\beta(0) + u_j$. The conditional log-odds ratio is the difference between these log-odds:\n$$\n\\text{log-OR}_{\\text{conditional}} = (\\alpha + \\beta + u_j) - (\\alpha + u_j) = \\beta\n$$\nThe conditional odds ratio is therefore $\\text{OR}_{\\text{conditional}} = \\exp(\\beta)$, which is constant across all hospitals.\n\nThe marginal odds ratio is defined based on the marginal probabilities, $\\Pr(Y_{ij}=1 \\mid X_{ij})$, which are obtained by averaging, or marginalizing, over the distribution of the random intercepts $u_j$.\nLet $P(X_{ij}) = \\Pr(Y_{ij}=1 \\mid X_{ij})$. By definition,\n$$\nP(X_{ij}) = E_{u_j}\\left[ \\Pr\\left(Y_{ij}=1 \\mid X_{ij}, u_j\\right) \\right]\n$$\nThe conditional probability is given by the inverse logit function, $\\Lambda(z) = 1/(1+\\exp(-z))$:\n$$\n\\Pr\\left(Y_{ij}=1 \\mid X_{ij}, u_j\\right) = \\Lambda(\\alpha + \\beta X_{ij} + u_j) = \\frac{\\exp(\\alpha + \\beta X_{ij} + u_j)}{1 + \\exp(\\alpha + \\beta X_{ij} + u_j)}\n$$\nThe marginal probability is the integral of this conditional probability weighted by the probability density function of $u_j$, which is a normal distribution $\\mathcal{N}(0, \\sigma^2)$:\n$$\nP(X_{ij}) = \\int_{-\\infty}^{\\infty} \\frac{\\exp(\\alpha + \\beta X_{ij} + u)}{1 + \\exp(\\alpha + \\beta X_{ij} + u)} \\frac{1}{\\sqrt{2\\pi\\sigma^2}} \\exp\\left(-\\frac{u^2}{2\\sigma^2}\\right) du\n$$\nThis integral, known as a logistic-normal integral, does not have a closed-form analytical solution. Therefore, we must use a principled approximation as requested.\n\nA powerful and principled method for deriving such an approximation stems from the latent variable interpretation of the logistic regression model. The conditional model is equivalent to postulating a latent continuous variable $Y_{ij}^*$ such that:\n$$\nY_{ij}^* = \\alpha + \\beta X_{ij} + u_j + \\epsilon_{ij}\n$$\nand $Y_{ij}=1$ if and only if $Y_{ij}^* > 0$. The error term $\\epsilon_{ij}$ follows a standard logistic distribution with mean $0$ and variance $\\pi^2/3$. These errors are assumed to be independent of $u_j$ and $X_{ij}$.\n\nTo find the marginal model, we consider the composite error term $v_{ij} = u_j + \\epsilon_{ij}$. The latent variable model for the marginal relationship is:\n$$\nY_{ij}^* = \\alpha + \\beta X_{ij} + v_{ij}\n$$\nSince $u_j$ and $\\epsilon_{ij}$ are independent, the variance of the composite error term is the sum of their variances:\n$$\n\\operatorname{Var}(v_{ij}) = \\operatorname{Var}(u_j) + \\operatorname{Var}(\\epsilon_{ij}) = \\sigma^2 + \\frac{\\pi^2}{3}\n$$\nThe distribution of $v_{ij}$ is the convolution of a normal and a logistic distribution, which is not itself a logistic distribution. The approximation consists of approximating the distribution of $v_{ij}$ by a logistic distribution with a different scale parameter, $s_{marginal}$. A logistic distribution with mean $0$ and scale parameter $s$ has a variance of $s^2\\pi^2/3$. We match the variance of the approximating logistic distribution to the true variance of $v_{ij}$:\n$$\ns_{marginal}^2 \\frac{\\pi^2}{3} = \\sigma^2 + \\frac{\\pi^2}{3}\n$$\nSolving for $s_{marginal}^2$ yields:\n$$\ns_{marginal}^2 = \\frac{\\sigma^2 + \\pi^2/3}{\\pi^2/3} = 1 + \\frac{3\\sigma^2}{\\pi^2}\n$$\nSo, the scale of the approximating marginal logistic distribution is $s_{marginal} = \\sqrt{1 + 3\\sigma^2/\\pi^2}$.\nThe response probability in the marginal model is $\\Pr(Y_{ij}=1 \\mid X_{ij}) \\approx \\Pr(Y_{ij}^* > 0)$, which, under the scaled logistic approximation for $v_{ij}$, is:\n$$\nP(X_{ij}) \\approx \\Pr(v_{ij} > -(\\alpha + \\beta X_{ij})) \\approx \\Lambda\\left(\\frac{\\alpha + \\beta X_{ij}}{s_{marginal}}\\right)\n$$\nThis gives an approximate marginal logistic model:\n$$\n\\operatorname{logit}\\left\\{ \\Pr(Y_{ij}=1 \\mid X_{ij}) \\right\\} \\approx \\frac{\\alpha}{s_{marginal}} + \\frac{\\beta}{s_{marginal}} X_{ij} = \\alpha^* + \\beta^* X_{ij}\n$$\nThe marginal log-odds ratio is $\\beta^* = \\beta/s_{marginal}$. Therefore, the approximate marginal odds ratio is:\n$$\n\\text{OR}_{\\text{marginal}} \\approx \\exp(\\beta^*) = \\exp\\left(\\frac{\\beta}{\\sqrt{1 + 3\\sigma^2/\\pi^2}}\\right)\n$$\nNow, we compute the numerical value using the provided estimates $\\hat{\\beta} = 1.10$ and $\\hat{\\sigma}^2 = 0.60$.\nFirst, calculate the attenuation factor $s_{marginal}$ with the estimated variance:\n$$\ns_{marginal} = \\sqrt{1 + \\frac{3\\hat{\\sigma}^2}{\\pi^2}} = \\sqrt{1 + \\frac{3(0.60)}{\\pi^2}} = \\sqrt{1 + \\frac{1.8}{\\pi^2}}\n$$\nUsing $\\pi \\approx 3.14159265$, we have $\\pi^2 \\approx 9.8696044$.\n$$\ns_{marginal} \\approx \\sqrt{1 + \\frac{1.8}{9.8696044}} \\approx \\sqrt{1 + 0.182378} \\approx \\sqrt{1.182378} \\approx 1.087372\n$$\nNext, we compute the approximate marginal log-odds ratio, $\\hat{\\beta}^*$:\n$$\n\\hat{\\beta}^* \\approx \\frac{\\hat{\\beta}}{s_{marginal}} \\approx \\frac{1.10}{1.087372} \\approx 1.011614\n$$\nFinally, we compute the marginal odds ratio:\n$$\n\\text{OR}_{\\text{marginal}} \\approx \\exp(\\hat{\\beta}^*) \\approx \\exp(1.011614) \\approx 2.74996\n$$\nRounding to four significant figures, the marginal odds ratio is $2.750$.\n\nThe reason for the attenuation of the marginal odds ratio relative to the conditional odds ratio can be explained both mathematically and conceptually.\nMathematically, the attenuation factor $s_{marginal} = \\sqrt{1 + 3\\sigma^2/\\pi^2}$ is strictly greater than $1$ whenever the between-cluster variance $\\sigma^2$ is greater than $0$. Consequently, the magnitude of the marginal log-odds ratio, $|\\beta^*| = |\\beta|/s_{marginal}$, is smaller than the magnitude of the conditional log-odds ratio, $|\\beta|$. This means $\\exp(\\beta^*)$ is closer to $1$ (the null value for an odds ratio) than $\\exp(\\beta)$. The degree of attenuation increases as the between-cluster heterogeneity, $\\sigma^2$, increases. If $\\sigma^2=0$, then $s_{marginal}=1$, $\\beta^*=\\beta$, and the conditional and marginal effects are identical, as expected.\n\nConceptually, this attenuation is a manifestation of a statistical phenomenon known as non-collapsibility of the odds ratio, which arises from the non-linearity of the logit link function. The conditional odds ratio measures the association between exposure $X$ and outcome $Y$ within a specific group (hospital $j$) where the baseline risk is held constant. The marginal odds ratio, in contrast, measures the association in the overall population, which is a mixture of different groups with varying baseline risks (as determined by the random effects $u_j$). When we marginalize over the distribution of $u_j$, we are averaging the non-linear probability function $\\Lambda(\\alpha + \\beta X_{ij} + u_j)$ over the different baseline risks. Due to Jensen's inequality applied to the non-linear logistic function, this averaging process results in a marginal relationship between $X$ and $Y$ that is weaker than the conditional relationship inside any given stratum. This heterogeneity in baseline risk across clusters partially confounds the exposure-outcome relationship at the population level, leading to an attenuated marginal odds ratio.",
            "answer": "$$\\boxed{2.750}$$"
        }
    ]
}