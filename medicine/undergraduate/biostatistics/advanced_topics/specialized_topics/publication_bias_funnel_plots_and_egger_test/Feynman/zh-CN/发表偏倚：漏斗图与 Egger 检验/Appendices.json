{
    "hands_on_practices": [
        {
            "introduction": "漏斗图是评估发表偏倚的主要视觉工具，但其解读可能受到个别研究的严重影响。本练习将通过一个具体案例，探讨一个高精度（即标准误极小）的研究如何不成比例地影响漏斗图的形态和Egger检验的结果。通过亲手计算并对比包含与排除该研究时的差异，你将深刻理解杠杆点在元分析诊断中的关键作用。",
            "id": "4943807",
            "problem": "荟萃分析收集研究特异性效应估计值 $\\hat{\\theta}_i$ 及其标准误 (SE) $\\mathrm{SE}_i$。漏斗图将 $\\hat{\\theta}_i$ 置于横轴，$\\mathrm{SE}_i$ 置于纵轴；在没有小研究效应的情况下，散点图应大致对称于合并效应，并随着 $\\mathrm{SE}_i$ 的减小而变窄。Egger检验通过将标准化正态离差对精密度进行回归，并检验拟合的截距是否与零有差异，来评估漏斗图的不对称性。\n\n考虑以下具有 $(\\hat{\\theta}_i, \\mathrm{SE}_i)$ 对的 $10$ 项研究：\n- 研究 $1$：$(0.20, 0.35)$\n- 研究 $2$：$(0.20, 0.33)$\n- 研究 $3$：$(0.20, 0.31)$\n- 研究 $4$：$(0.20, 0.29)$\n- 研究 $5$：$(0.20, 0.34)$\n- 研究 $6$：$(0.20, 0.32)$\n- 研究 $7$：$(0.20, 0.30)$\n- 研究 $8$：$(0.20, 0.36)$\n- 研究 $9$：$(0.20, 0.28)$\n- 研究 $10$：$(0.45, 0.05)$\n\n任务：\n- 使用最小二乘法的基本原理，计算包含全部 $10$ 项研究的数据集以及排除研究 $10$ 的子集的 Egger 回归截距。在拟合回归之前，明确用 $(\\hat{\\theta}_i, \\mathrm{SE}_i)$ 定义标准化正态离差 $z_i$ 和精密度 $x_i$。\n- 基于这些计算和最小二乘法的几何原理，定性解释单个极小的 $\\mathrm{SE}_i$ 如何能够在视觉上锚定漏斗图（通过设定纵向标尺和制造明显的不对称性），并在 Egger 回归中产生高杠杆作用。\n- 选择所有关于高精度离群值的影响以及评估和减轻夸大的不对称性的稳健可视化策略的正确陈述。\n\n选项：\nA. 在全部 $10$ 项研究的数据集中，Egger 截距显著不为 $0$，而移除高精度离群值会使截距更接近 $0$；这表明锚定效应如何夸大了表观的不对称性。\n\nB. 使用漏斗图的留一法叠加图并在各面板间固定 $\\mathrm{SE}$ 轴的范围是稳健的可视化策略，它们通过防止单个极端的 $\\mathrm{SE}_i$ 决定标尺并揭示其影响，从而减少锚定效应。\n\nC. 将漏斗图的 $\\mathrm{SE}$ 轴转换为对数刻度会完全消除极端 $\\mathrm{SE}_i$ 对 Egger 检验的影响，因为 Egger 回归是在对数值上执行的。\n\nD. $\\hat{\\theta}_i/\\mathrm{SE}_i$ 对 $1/\\mathrm{SE}_i$ 的放射图（Galbraith图）可以直观地标记出单个有影响的高精度点，并提供了一种与标准漏斗图相比更稳健的评估小研究效应的视角。\n\nE. 从显示和所有分析中剔除离群值是一种客观的解决方案，因为离群值总是人为误差。",
            "solution": "该问题陈述是生物统计学中的一个有效练习，具体涉及荟萃分析的诊断。它具有科学依据、问题设定良好且客观。所有进行计算和解释所需的数据和定义都已提供。\n\n任务是分析一项高精度研究对荟萃分析的影响，重点关注漏斗图和用于检验小研究效应的 Egger 检验。\n\n首先，我们定义 Egger 线性回归的变量。该回归模型评估研究特异性效应大小与其精密度之间的关系。\n因变量是标准化正态离差，即效应估计值除以其标准误：\n$$z_i = \\frac{\\hat{\\theta}_i}{\\mathrm{SE}_i}$$\n自变量是效应估计值的精密度，即标准误的倒数：\n$$x_i = \\frac{1}{\\mathrm{SE}_i}$$\nEgger 回归模型是使用普通最小二乘法 (OLS) 对 $z_i$ 与 $x_i$ 进行的简单线性回归：\n$$z_i = \\beta_0 + \\beta_1 x_i + \\epsilon_i$$\nEgger 检验正式检验原假设 $H_0: \\beta_0 = 0$。一个非零的截距 $\\beta_0$被视为存在小研究效应（如发表偏倚）的证据。截距的 OLS 估计量由 $\\hat{\\beta}_0 = \\bar{z} - \\hat{\\beta}_1 \\bar{x}$ 给出，其中 $\\hat{\\beta}_1 = \\frac{\\sum_{i=1}^{n}(x_i - \\bar{x})(z_i - \\bar{z})}{\\sum_{i=1}^{n}(x_i - \\bar{x})^2}$。\n\n**对全部 $10$ 项研究进行计算**\n\n我们首先计算所有 $n=10$ 项研究的 $(x_i, z_i)$ 对。\n- 研究 1：$(x_1, z_1) = (1/0.35, 0.20/0.35) \\approx (2.857, 0.571)$\n- 研究 2：$(x_2, z_2) = (1/0.33, 0.20/0.33) \\approx (3.030, 0.606)$\n- 研究 3：$(x_3, z_3) = (1/0.31, 0.20/0.31) \\approx (3.226, 0.645)$\n- 研究 4：$(x_4, z_4) = (1/0.29, 0.20/0.29) \\approx (3.448, 0.690)$\n- 研究 5：$(x_5, z_5) = (1/0.34, 0.20/0.34) \\approx (2.941, 0.588)$\n- 研究 6：$(x_6, z_6) = (1/0.32, 0.20/0.32) \\approx (3.125, 0.625)$\n- 研究 7：$(x_7, z_7) = (1/0.30, 0.20/0.30) \\approx (3.333, 0.667)$\n- 研究 8：$(x_8, z_8) = (1/0.36, 0.20/0.36) \\approx (2.778, 0.556)$\n- 研究 9：$(x_9, z_9) = (1/0.28, 0.20/0.28) \\approx (3.571, 0.714)$\n- 研究 10：$(x_{10}, z_{10}) = (1/0.05, 0.45/0.05) = (20.000, 9.000)$\n\n使用这些值，我们计算 OLS 回归的汇总统计量：\n- $\\sum_{i=1}^{10} x_i \\approx 48.309$，因此 $\\bar{x} \\approx 4.831$\n- $\\sum_{i=1}^{10} z_i \\approx 14.662$，因此 $\\bar{z} \\approx 1.466$\n- $\\sum_{i=1}^{10} (x_i - \\bar{x})^2 \\approx 232.06$\n- $\\sum_{i=1}^{10} (x_i - \\bar{x})(z_i - \\bar{z}) \\approx 115.42$\n\n现在我们可以计算斜率和截距：\n- $\\hat{\\beta}_1 = \\frac{115.42}{232.06} \\approx 0.4974$\n- $\\hat{\\beta}_0 = \\bar{z} - \\hat{\\beta}_1 \\bar{x} \\approx 1.466 - (0.4974 \\times 4.831) \\approx 1.466 - 2.403 = -0.937$\n\n包含全部 $10$ 项研究的数据集的 Egger 截距约为 $-0.94$。\n\n**对排除研究 $10$ 的子集进行计算**\n\n对于前 $9$ 项研究，存在一个独特的条件：效应估计值 $\\hat{\\theta}_i$ 恒为 $0.20$。\n让我们分析这个子集（$i=1, \\dots, 9$）中 $z_i$ 和 $x_i$ 之间的关系：\n$$z_i = \\frac{\\hat{\\theta}_i}{\\mathrm{SE}_i} = \\frac{0.20}{\\mathrm{SE}_i} = 0.20 \\times \\left(\\frac{1}{\\mathrm{SE}_i}\\right) = 0.20 x_i$$\n这意味着所有 $9$ 个数据点 $(x_i, z_i)$ 都完全落在一条通过原点 $(0,0)$、斜率为 $0.20$ 的直线上。当数据点完全落在一条直线上时，OLS 回归将恢复出这条精确的直线。模型为 $z_i = \\hat{\\beta}_0 + \\hat{\\beta}_1 x_i$。残差平方和 $\\sum (z_i - (\\hat{\\beta}_0 + \\hat{\\beta}_1 x_i))^2$ 被最小化。如果我们代入真实关系，我们得到 $\\sum (0.20 x_i - (\\hat{\\beta}_0 + \\hat{\\beta}_1 x_i))^2$。如果我们选择 $\\hat{\\beta}_0 = 0$ 和 $\\hat{\\beta}_1 = 0.20$，这个和恰好为零。由于平方和不能为负，这是唯一的最小值。\n因此，对于研究 $1-9$ 的子集，Egger 截距恰好为 $\\hat{\\beta}_0 = 0$。\n\n**影响的定性解释**\n\n像研究 $10$ ($\\mathrm{SE}_{10} = 0.05$) 这样具有极小标准误的单个研究会产生深远的影响。\n- **在漏斗图中的视觉锚定：** 标准漏斗图将 $\\hat{\\theta}_i$（x轴）与 $\\mathrm{SE}_i$（y轴）进行绘制。研究 $1-9$ 的 $\\mathrm{SE}_i$ 值聚集在 $0.28$ 和 $0.36$ 之间。研究 $10$ 的 $\\mathrm{SE}_{10} = 0.05$。为了显示所有点，y轴必须从低于 $0.05$ 延伸到高于 $0.36$。这迫使九项研究被挤压在图顶部的狭窄带内，而研究 $10$ 则单独位于底部。由于 $\\hat{\\theta}_{10}=0.45$ 与 $\\hat{\\theta}_{1-9}=0.20$ 不同，这个位于 $(0.45, 0.05)$ 的单一点造成了视觉上显著的不对称，给人一种漏斗图倾斜的印象。\n- **在 Egger 回归中的高杠杆作用：** 回归中的杠杆作用指的是数据点 x 值的影响力。x 值远离均值 $\\bar{x}$ 的点具有高杠杆作用。在 Egger 回归中，$x_i=1/\\mathrm{SE}_i$。对于研究 $1-9$，$x_i$ 的范围大约在 $2.78$ 到 $3.57$ 之间。对于研究 $10$，$x_{10} = 1/0.05 = 20$。这个值与其他点的集群相距甚远，赋予了研究 $10$ 极高的杠杆作用。OLS 回归线被强烈地拉向这个高杠杆点。正如我们计算的，其他 $9$ 个点意味着截距为 $0$。而这个高杠杆点 $(20, 9)$ 将回归线向下拉，迫使截距变为显著的负值（$\\approx -0.94$）。因此，这个单一的研究在其他研究中不存在不对称性的情况下，制造出了不对称性的强烈统计证据。\n\n**选项评估**\n\nA. **在全部 $10$ 项研究的数据集中，Egger 截距显著不为 $0$，而移除高精度离群值会使截距更接近 $0$；这表明锚定效应如何夸大了表观的不对称性。** 我们的计算显示，完整数据集的截距为 $\\hat{\\beta}_0 \\approx -0.94$，这显著不为 $0$。移除研究 $10$ 后，截距变为精确的 $0$。该陈述正确地将这一数学结果与锚定和夸大的不对称性概念联系起来。**结论：正确。**\n\nB. **使用漏斗图的留一法叠加图并在各面板间固定 $\\mathrm{SE}$ 轴的范围是稳健的可视化策略，它们通过防止单个极端的 $\\mathrm{SE}_i$ 决定标尺并揭示其影响，从而减少锚定效应。** 留一法分析是识别影响点的标准方法。通过依次省略每个研究来生成图表或统计数据，可以量化每个研究的影响。在这些诊断图中固定轴范围至关重要；这可以防止在移除影响点时图表重新调整标尺，从而使其对整体视觉模式的影响立即可见。这些确实是诊断影响的稳健策略。**结论：正确。**\n\nC. **将漏斗图的 $\\mathrm{SE}$ 轴转换为对数刻度会完全消除极端 $\\mathrm{SE}_i$ 对 Egger 检验的影响，因为 Egger 回归是在对数值上执行的。** 这个陈述在两方面是错误的。首先，虽然在对数刻度上绘制 $\\mathrm{SE}_i$ 可以通过分散具有小 $\\mathrm{SE}_i$ 的点来改善可视化效果，但它不会改变用于 Egger 检验计算的底层数据。Egger 回归是在 $z_i=\\hat{\\theta}_i/\\mathrm{SE}_i$ 和 $x_i=1/\\mathrm{SE}_i$ 上进行的，而不是在它们的对数或 $\\mathrm{SE}_i$ 的对数上进行的。因此，改变绘图刻度并不会“消除对统计检验的影响”。其次，关于回归是在对数值上执行的说法对于标准的 Egger 检验是错误的。**结论：不正确。**\n\nD. **$\\hat{\\theta}_i/\\mathrm{SE}_i$ 对 $1/\\mathrm{SE}_i$ 的放射图（Galbraith图）可以直观地标记出单个有影响的高精度点，并提供了一种与标准漏斗图相比更稳健的评估小研究效应的视角。** 该陈述描述了 $z_i=\\hat{\\theta}_i/\\mathrm{SE}_i$ 对 $x_i=1/\\mathrm{SE}_i$ 的图。这正是进行 Egger 回归的图，也称为 Galbraith 图或放射图。在这样的图中，像研究 $10$ 这样的高精度点将具有非常大的 x 坐标（$x_{10}=20$），使其在横轴上成为一个明显的离群点。这使其高杠杆作用在视觉上显而易见。与标准漏斗图相比，该图是评估异质性和元回归模型拟合度的稳健且通常更受青睐的替代方法。**结论：正确。**\n\nE. **从显示和所有分析中剔除离群值是一种客观的解决方案，因为离群值总是人为误差。** 这个陈述提出了一个强烈且错误的观点。自动移除离群值并非客观做法，这可能相当于数据操纵。离群值可能是错误的结果，但也可能是一个有效且信息量极高的结果（例如，来自一项大型、高质量的试验）。“离群值总是人为误差”的断言在科学上是毫无根据的。正确的程序是进行敏感性分析——报告包含和不包含影响点时的结果——并调查其极端性的原因，而不是毫无理由地将其丢弃。**结论：不正确。**\n\n最终的正确陈述是 A、B 和 D。",
            "answer": "$$\\boxed{ABD}$$"
        },
        {
            "introduction": "标准的Egger检验在很多情况下都适用，但针对不同类型的数据（如二元结果），我们需要更精确的统计模型。本练习将引导你从似然理论的第一性原理出发，推导针对二元数据设计的Harbord修正版Egger检验，并理解其统计学基础。随后，你将把这个推导出的模型应用于一组实际数据，从而将理论与实践紧密结合起来。",
            "id": "4943837",
            "problem": "对于具有二元结局的随机对照试验进行的元分析，通常使用Egger检验来诊断小样本效应，其方法是将标准化效应与其精确度进行回归。对于像对数比值比这样的二元结局，Harbord的修正方法将标准化效应$Z_i$替换为从每个研究的$2\\times 2$列联表构建的标准化有效分数。从似然理论的基本原理出发，考虑对数比值比参数$\\theta$以及研究$i$的有效分数$U_i(\\theta)$，其Fisher信息为$I_i(\\theta)$。在共同效应模型下，当$\\theta$接近0时，经过充分检验的关系式 $E[U_i(\\theta)] \\approx \\theta\\,I_i(0)$ 和 $\\mathrm{Var}[U_i(0)] = I_i(0)$ 成立。对于一个具有单元格计数$(a_i,b_i;c_i,d_i)$的$2\\times 2$研究，将在$\\theta=0$处的Cochran–Mantel–Haenszel (CMH)有效分数及其方差定义为\n$$\nS_i \\equiv a_i - \\frac{n_{1i} y_i}{n_i},\\quad\nV_i \\equiv \\frac{n_{1i} n_{0i}\\, y_i\\, (n_i - y_i)}{n_i^{2}\\,(n_i - 1)},\n$$\n其中$n_{1i} = a_i + b_i$，$n_{0i} = c_i + d_i$，$n_i = n_{1i} + n_{0i}$，以及$y_i = a_i + c_i$。请利用这些事实推导出标准化分数$Z_i \\equiv S_i/\\sqrt{V_i}$关于$\\theta$和$V_i$的期望，并解释这如何引出将$Z_i$对$V_i$的某个函数进行线性回归，从而通过截距来评估小样本效应的方法。然后，使用以下六项研究的数据，计算所推导的Harbord型回归的普通最小二乘截距$\\hat{\\alpha}$。将最终答案四舍五入至四位有效数字。\n\n六项试验的数据（每个项目给出$(a_i,b_i;c_i,d_i)$）：\n- 研究 $1$：$(20,30;\\,15,35)$\n- 研究 $2$：$(28,52;\\,14,56)$\n- 研究 $3$：$(18,42;\\,8,32)$\n- 研究 $4$：$(45,45;\\,44,66)$\n- 研究 $5$：$(21,49;\\,34,46)$\n- 研究 $6$：$(10,30;\\,12,48)$",
            "solution": "该问题要求两件事：第一，推导标准化有效分数$Z_i$的期望值，并解释这如何引出用于检验小样本效应的线性回归（Harbord检验）；第二，为给定的包含六项研究的数据集计算此回归的截距。\n\n首先，我们来解决推导和理据部分。研究$i$的标准化分数定义为$Z_i \\equiv S_i/\\sqrt{V_i}$。我们希望求出其期望$E[Z_i]$。在用于$2 \\times 2$列联表的条件似然框架中，方差$V_i$仅取决于列联表的边际总和。这些边际量被视为辅助统计量，这意味着在对比值比$\\theta$进行推断时，它们被认为是固定的。因此，我们可以将商的期望近似为期望的商：\n$$ E[Z_i] = E\\left[\\frac{S_i}{\\sqrt{V_i}}\\right] \\approx \\frac{E[S_i]}{\\sqrt{V_i}} $$\n问题陈述$S_i$是在$\\theta=0$处的Cochran–Mantel–Haenszel (CMH)有效分数，它对应于似然理论中的有效分数$U_i(0)$。$E[S_i]$的期望是在真实、可能非零的共同效应量$\\theta$下计算的。似然理论中的一个标准结果（通过分数函数的一阶泰勒级数展开得到）表明，在真实参数值$\\theta$下，于零假设值（此处为$\\theta=0$）处评估的分数函数的期望约与$\\theta$成正比。问题给出的关系是$E[U_i(\\theta)] \\approx \\theta\\,I_i(0)$。这个记法有些模糊不清；标准结果是在真实参数$\\theta$下，零假设处分数的期望为$E_{\\theta}[U_i(0)] \\approx \\theta I_i(0)$，其中$I_i(0)$是在零假设下评估的Fisher信息。我们采用这种标准解释继续进行。\n\n由于$S_i$等同于$U_i(0)$，我们有：\n$$ E[S_i] \\approx \\theta I_i(0) $$\n问题还提供了两个关键事实：$\\mathrm{Var}[U_i(0)] = I_i(0)$，以及$V_i$的公式，它是$S_i$在零假设（$\\theta=0$）下以列联表边际为条件的精确方差。因此，在这种情况下，$V_i$是$I_i(0)$的自然估计量。用$V_i$替代$I_i(0)$：\n$$ E[S_i] \\approx \\theta V_i $$\n现在，我们可以求出标准化分数$Z_i$的期望：\n$$ E[Z_i] \\approx \\frac{\\theta V_i}{\\sqrt{V_i}} = \\theta \\sqrt{V_i} $$\n这个推导出的关系是引出回归分析的核心理据。它表明，在没有偏倚的情况下，标准化分数$Z_i$的期望值与$\\sqrt{V_i}$成正比。$\\sqrt{V_i}$这一项可以解释为研究的精确度，因为它是对数比值比的近似标准误的倒数（$1/\\sqrt{I_i(0)}$）。\n\n小样本效应，如发表偏倚，假定研究中观察到的效应可能与其规模或精确度系统性相关。例如，较小的研究（精确度较低）如果显示出夸大的效应，可能更容易被发表。这引入了一种偏倚，可以通过在关系式中添加一个常数项来建模。因此，我们提出线性回归模型：\n$$ E[Z_i] = \\alpha + \\beta \\sqrt{V_i} $$\n在这个模型中，$\\beta$对应于总体治疗效应$\\theta$。截距$\\alpha$代表系统性偏倚。如果没有小样本效应，我们期望$\\alpha=0$，回归线应该通过原点。一个统计上显著的非零截距$\\hat{\\alpha}$被解释为存在小样本效应的证据。将标准化分数$Z_i$对其精确度$\\sqrt{V_i}$进行回归，是Harbord检验用于二元结局小样本效应的基础。\n\n接下来，我们使用提供的六项研究数据，计算该回归的普通最小二乘（OLS）截距$\\hat{\\alpha}$。对于每项研究$i$，我们必须计算必要的量。令$X_i = \\sqrt{V_i}$为自变量，$Y_i = Z_i = S_i/\\sqrt{V_i}$为因变量。\n\n对$N=6$的每项研究的计算总结如下：\n1.  研究 $1$：$(a_1,b_1;c_1,d_1) = (20,30;15,35)$。$n_{11}=50, n_{01}=50, n_1=100, y_1=35$。\n    $S_1 = 20 - \\frac{50 \\times 35}{100} = 2.5$。\n    $V_1 = \\frac{50 \\times 50 \\times 35 \\times 65}{100^2 \\times 99} \\approx 5.74495$。\n    $X_1 = \\sqrt{V_1} \\approx 2.39686$。 $Y_1 = Z_1 = S_1/X_1 \\approx 1.04303$。\n2.  研究 $2$：$(a_2,b_2;c_2,d_2) = (28,52;14,56)$。$n_{12}=80, n_{02}=70, n_2=150, y_2=42$。\n    $S_2 = 28 - \\frac{80 \\times 42}{150} = 5.6$。\n    $V_2 = \\frac{80 \\times 70 \\times 42 \\times 108}{150^2 \\times 149} \\approx 7.57690$。\n    $X_2 = \\sqrt{V_2} \\approx 2.75262$。 $Y_2 = Z_2 = S_2/X_2 \\approx 2.03442$。\n3.  研究 $3$：$(a_3,b_3;c_3,d_3) = (18,42;8,32)$。$n_{13}=60, n_{03}=40, n_3=100, y_3=26$。\n    $S_3 = 18 - \\frac{60 \\times 26}{100} = 2.4$。\n    $V_3 = \\frac{60 \\times 40 \\times 26 \\times 74}{100^2 \\times 99} \\approx 4.66424$。\n    $X_3 = \\sqrt{V_3} \\approx 2.15969$。 $Y_3 = Z_3 = S_3/X_3 \\approx 1.11127$。\n4.  研究 $4$：$(a_4,b_4;c_4,d_4) = (45,45;44,66)$。$n_{14}=90, n_{04}=110, n_4=200, y_4=89$。\n    $S_4 = 45 - \\frac{90 \\times 89}{200} = 4.95$。\n    $V_4 = \\frac{90 \\times 110 \\times 89 \\times 111}{200^2 \\times 199} \\approx 12.27524$。\n    $X_4 = \\sqrt{V_4} \\approx 3.50360$。 $Y_4 = Z_4 = S_4/X_4 \\approx 1.41284$。\n5.  研究 $5$：$(a_5,b_5;c_5,d_5) = (21,49;34,46)$。$n_{15}=70, n_{05}=80, n_5=150, y_5=55$。\n    $S_5 = 21 - \\frac{70 \\times 55}{150} = -\\frac{14}{3} \\approx -4.66667$。\n    $V_5 = \\frac{70 \\times 80 \\times 55 \\times 95}{150^2 \\times 149} \\approx 8.72782$。\n    $X_5 = \\sqrt{V_5} \\approx 2.95429$。 $Y_5 = Z_5 = S_5/X_5 \\approx -1.57963$。\n6.  研究 $6$：$(a_6,b_6;c_6,d_6) = (10,30;12,48)$。$n_{16}=40, n_{06}=60, n_6=100, y_6=22$。\n    $S_6 = 10 - \\frac{40 \\times 22}{100} = 1.2$。\n    $V_6 = \\frac{40 \\times 60 \\times 22 \\times 78}{100^2 \\times 99} = 4.16$。\n    $X_6 = \\sqrt{V_6} \\approx 2.03961$。 $Y_6 = Z_6 = S_6/X_6 \\approx 0.58835$。\n\n我们需要以下总和来进行OLS计算（$N=6$）：\n$\\sum_{i=1}^N X_i \\approx 15.80667$\n$\\sum_{i=1}^N Y_i \\approx 4.61028$\n$\\sum_{i=1}^N X_i^2 = \\sum_{i=1}^N V_i \\approx 43.14915$\n$\\sum_{i=1}^N X_i Y_i = \\sum_{i=1}^N (\\sqrt{V_i}) (S_i/\\sqrt{V_i}) = \\sum_{i=1}^N S_i = 2.5 + 5.6 + 2.4 + 4.95 - \\frac{14}{3} + 1.2 \\approx 11.98333$\n\n均值为：\n$\\bar{X} = \\frac{1}{N} \\sum X_i \\approx \\frac{15.80667}{6} \\approx 2.63444$\n$\\bar{Y} = \\frac{1}{N} \\sum Y_i \\approx \\frac{4.61028}{6} \\approx 0.76838$\n\nOLS斜率估计$\\hat{\\beta}$为：\n$$ \\hat{\\beta} = \\frac{\\sum (X_i - \\bar{X})(Y_i - \\bar{Y})}{\\sum (X_i - \\bar{X})^2} = \\frac{(\\sum X_i Y_i) - N \\bar{X} \\bar{Y}}{(\\sum X_i^2) - N \\bar{X}^2} $$\n$$ \\hat{\\beta} \\approx \\frac{11.98333 - 6 \\times (2.63444) \\times (0.76838)}{43.14915 - 6 \\times (2.63444)^2} \\approx \\frac{11.98333 - 12.14545}{43.14915 - 41.64195} = \\frac{-0.16212}{1.50720} \\approx -0.10756 $$\nOLS截距估计$\\hat{\\alpha}$为：\n$$ \\hat{\\alpha} = \\bar{Y} - \\hat{\\beta} \\bar{X} $$\n$$ \\hat{\\alpha} \\approx 0.76838 - (-0.10756) \\times (2.63444) \\approx 0.76838 + 0.28335 \\approx 1.05173 $$\n将结果四舍五入到四位有效数字，我们得到$1.052$。",
            "answer": "$$\\boxed{1.052}$$"
        },
        {
            "introduction": "在检测到发表偏倚后，一个自然的问题是如何校正它对合并效应量的影响。“剪补法”（Trim-and-Fill）提供了一种直观的非参数方法来应对这个问题。本练习将引导你完成剪补法的完整流程：识别并“修剪”不对称一侧的极端研究，估算缺失研究的数量并“填充”它们的镜像，最终得出一个校正后的效应量。",
            "id": "4943871",
            "problem": "一位研究人员对 $k=8$ 项研究进行了一项固定效应元分析，这些研究报告了观察到的效应估计值 $\\hat{\\theta}_{i}$ 及其对应的标准误 $\\text{SE}_{i}$。估计值和标准误如下：\n\n- 研究 $1$：$\\hat{\\theta}_{1}=0.20$，$\\text{SE}_{1}=0.05$\n- 研究 $2$：$\\hat{\\theta}_{2}=0.22$，$\\text{SE}_{2}=0.06$\n- 研究 $3$：$\\hat{\\theta}_{3}=0.18$，$\\text{SE}_{3}=0.08$\n- 研究 $4$：$\\hat{\\theta}_{4}=0.24$，$\\text{SE}_{4}=0.10$\n- 研究 $5$：$\\hat{\\theta}_{5}=0.30$，$\\text{SE}_{5}=0.12$\n- 研究 $6$：$\\hat{\\theta}_{6}=0.40$，$\\text{SE}_{6}=0.15$\n- 研究 $7$：$\\hat{\\theta}_{7}=0.50$，$\\text{SE}_{7}=0.20$\n- 研究 $8$：$\\hat{\\theta}_{8}=0.55$，$\\text{SE}_{8}=0.25$\n\n假设采用逆方差权重的固定效应模型，并考虑用于检验小样本研究效应的 Egger 回归检验和漏斗图对称性概念。应用剪补法（trim-and-fill）程序，如果 Egger 回归表明存在与缺失较小的负向研究一致的不对称性，则该程序在右侧进行修剪，从修剪后的数据集中估计中心，并通过填充与被修剪研究具有相同 $\\text{SE}_{i}$ 的镜像研究来补全。然后，在增广数据集（所有观察到的研究加上填充的估算研究）上重新计算合并估计值。\n\n使用上述数据，计算剪补法调整后的合并效应。将最终调整后的合并效应四舍五入至四位有效数字。效应量无需物理单位。在您的推理中，讨论剪补法调整相对于漏斗图不对称性和 Egger 检验的偏倚特性。",
            "solution": "用户提供了一个生物统计学问题，要求应用剪补法程序对元分析数据集进行处理，以校正潜在的发表偏倚。\n\n### 第 1 步：提取已知条件\n- 研究数量：$k=8$\n- 模型：采用逆方差权重的固定效应元分析。\n- 偏倚检验：Egger 回归。\n- 校正程序：剪补法。\n- 对于 $i=1, \\dots, 8$ 的数据：\n  - 研究 $1$：$\\hat{\\theta}_{1}=0.20$，$\\text{SE}_{1}=0.05$\n  - 研究 $2$：$\\hat{\\theta}_{2}=0.22$，$\\text{SE}_{2}=0.06$\n  - 研究 $3$：$\\hat{\\theta}_{3}=0.18$，$\\text{SE}_{3}=0.08$\n  - 研究 $4$：$\\hat{\\theta}_{4}=0.24$，$\\text{SE}_{4}=0.10$\n  - 研究 $5$：$\\hat{\\theta}_{5}=0.30$，$\\text{SE}_{5}=0.12$\n  - 研究 $6$：$\\hat{\\theta}_{6}=0.40$，$\\text{SE}_{6}=0.15$\n  - 研究 $7$：$\\hat{\\theta}_{7}=0.50$，$\\text{SE}_{7}=0.20$\n  - 研究 $8$：$\\hat{\\theta}_{8}=0.55$，$\\text{SE}_{8}=0.25$\n- 最终答案精度：四舍五入至四位有效数字。\n\n### 第 2 步：使用提取的已知条件进行验证\n该问题具有科学依据，提法明确且客观。它概述了元分析中评估和调整发表偏倚的标准程序。所提供的数据是完整且一致的。术语“剪补法程序”指的是由 Duval 和 Tweedie 建立的成熟算法，问题提供了足够的信息来应用它。“如果 Egger 回归表明存在不对称性，则在右侧进行修剪”的指令与数据中效应量和标准误之间的正相关性一致，这表明漏斗图左侧（负向或不显著）的研究存在缺失。该问题有效。\n\n### 第 3 步：结论与行动\n该问题有效。我将继续进行解答。\n\n### 详细解答\n\n剪补法是一种非参数方法，用于估计发表偏倚对元分析的影响。其操作原理是估计漏斗图中缺失的研究数量，估算它们的值，然后重新计算合并效应。\n\n**第 1 部分：初始合并效应与不对称性评估**\n\n首先，我们使用逆方差固定效应模型计算初始合并效应估计值 $\\hat{\\theta}_{FE}$。每项研究 $i$ 的权重是其方差的倒数，即 $w_i = 1/\\text{SE}_i^2$。合并效应为 $\\hat{\\theta}_{FE} = \\frac{\\sum_{i=1}^{k} w_i \\hat{\\theta}_i}{\\sum_{i=1}^{k} w_i}$。\n\n权重为：\n- $w_1 = 1/0.05^2 = 400$\n- $w_2 = 1/0.06^2 \\approx 277.78$\n- $w_3 = 1/0.08^2 = 156.25$\n- $w_4 = 1/0.10^2 = 100$\n- $w_5 = 1/0.12^2 \\approx 69.44$\n- $w_6 = 1/0.15^2 \\approx 44.44$\n- $w_7 = 1/0.20^2 = 25$\n- $w_8 = 1/0.25^2 = 16$\n\n权重之和为 $\\sum w_i \\approx 400 + 277.78 + 156.25 + 100 + 69.44 + 44.44 + 25 + 16 \\approx 1088.91$。\n加权效应之和为 $\\sum w_i \\hat{\\theta}_i \\approx 400(0.20) + 277.78(0.22) + \\dots + 16(0.55) \\approx 253.15$。\n初始合并效应为 $\\hat{\\theta}_{FE} \\approx 253.15 / 1088.91 \\approx 0.23248$。\n\n问题指出，Egger 回归表明存在与缺失较小的负向研究一致的不对称性。这对应于标准化效应与精密度（precision）的 Egger 回归中的正截距，表明精度较低（$\\text{SE}$ 较大）的研究倾向于报告较大的正向效应。这为通过从效应分布的右侧（正向）修剪研究来应用剪补法程序提供了依据。\n\n**第 2 部分：估计要修剪的研究数量 ($k_0$)**\n\n标准的剪补法算法使用一个基于秩的估计量 $L_0$ 来确定要修剪的研究数量 $k_0$。\n1.  围绕初始合并估计值对效应量进行中心化：$\\hat{\\theta}_i^* = \\hat{\\theta}_i - \\hat{\\theta}_{FE}$。\n    - $\\hat{\\theta}_1^* = 0.20 - 0.23248 = -0.03248$\n    - $\\hat{\\theta}_2^* = 0.22 - 0.23248 = -0.01248$\n    - $\\hat{\\theta}_3^* = 0.18 - 0.23248 = -0.05248$\n    - $\\hat{\\theta}_4^* = 0.24 - 0.23248 = 0.00752$\n    - $\\hat{\\theta}_5^* = 0.30 - 0.23248 = 0.06752$\n    - $\\hat{\\theta}_6^* = 0.40 - 0.23248 = 0.16752$\n    - $\\hat{\\theta}_7^* = 0.50 - 0.23248 = 0.26752$\n    - $\\hat{\\theta}_8^* = 0.55 - 0.23248 = 0.31752$\n2.  根据中心化效应的绝对值 $|\\hat{\\theta}_i^*|$ 对研究进行排序：\n    - 秩 1: $|\\hat{\\theta}_4^*|=0.00752$\n    - 秩 2: $|\\hat{\\theta}_2^*|=0.01248$\n    - 秩 3: $|\\hat{\\theta}_1^*|=0.03248$\n    - 秩 4: $|\\hat{\\theta}_3^*|=0.05248$\n    - 秩 5: $|\\hat{\\theta}_5^*|=0.06752$\n    - 秩 6: $|\\hat{\\theta}_6^*|=0.16752$\n    - 秩 7: $|\\hat{\\theta}_7^*|=0.26752$\n    - 秩 8: $|\\hat{\\theta}_8^*|=0.31752$\n3.  将具有正中心化效应的研究（$\\hat{\\theta}_4^*, \\hat{\\theta}_5^*, \\hat{\\theta}_6^*, \\hat{\\theta}_7^*, \\hat{\\theta}_8^*$）的秩相加：\n    $T^+ = \\text{Rank}(\\hat{\\theta}_4^*) + \\text{Rank}(\\hat{\\theta}_5^*) + \\text{Rank}(\\hat{\\theta}_6^*) + \\text{Rank}(\\hat{\\theta}_7^*) + \\text{Rank}(\\hat{\\theta}_8^*) = 1 + 5 + 6 + 7 + 8 = 27$。\n4.  计算估计量 $L_0$：\n    $$ L_0 = \\frac{4T^+ - k(k+1)}{2k-1} = \\frac{4(27) - 8(8+1)}{2(8)-1} = \\frac{108 - 72}{15} = \\frac{36}{15} = 2.4 $$\n5.  要修剪的研究数量 $k_0$ 是与 $L_0$ 最接近的整数。如果 $L_0 < 0$，则 $k_0=0$。此处，$k_0 = \\text{round}(2.4) = 2$。\n\n**第 3 部分：修剪、填充和重新估计合并效应**\n\n当 $k_0=2$ 时，我们从分布的右侧修剪掉两个具有最极端正效应量的研究。它们是研究 7 ($\\hat{\\theta}_7=0.50$) 和研究 8 ($\\hat{\\theta}_8=0.55$)。\n\n接下来，我们使用剩余的 $k - k_0 = 6$ 项研究（研究 1-6）计算调整后的合并效应 $\\hat{\\theta}_{adj}$。\n修剪后数据集（研究 1-6）的权重之和为：\n$\\sum_{i=1}^6 w_i = 400 + \\frac{1}{0.06^2} + 156.25 + 100 + \\frac{1}{0.12^2} + \\frac{1}{0.15^2} = \\frac{12575}{12} \\approx 1047.9167$\n修剪后数据集的加权效应之和为：\n$\\sum_{i=1}^6 w_i \\hat{\\theta}_i = 400(0.2) + \\frac{0.22}{0.06^2} + 156.25(0.18) + 100(0.24) + \\frac{0.30}{0.12^2} + \\frac{0.40}{0.15^2} = \\frac{16693}{72} \\approx 231.8472$\n基于修剪后数据集的调整后合并效应为：\n$$ \\hat{\\theta}_{adj} = \\frac{\\sum_{i=1}^6 w_i \\hat{\\theta}_i}{\\sum_{i=1}^6 w_i} = \\frac{16693/72}{12575/12} = \\frac{16693}{6 \\times 12575} = \\frac{16693}{75450} \\approx 0.2212458 $$\n该程序现在通过估算 $k_0=2$ 个缺失的研究来“填充”漏斗图。估算的研究与被修剪的研究具有相同的标准误，但其效应量围绕 $\\hat{\\theta}_{adj}$ 呈镜像对称。\n- 估算研究 1（对应被修剪的研究 7）：$\\text{SE}_{\\text{fill},1} = 0.20$，$\\hat{\\theta}_{\\text{fill},1} = 2\\hat{\\theta}_{adj} - \\hat{\\theta}_7 \\approx 2(0.221246) - 0.50 = -0.057508$\n- 估算研究 2（对应被修剪的研究 8）：$\\text{SE}_{\\text{fill},2} = 0.25$，$\\hat{\\theta}_{\\text{fill},2} = 2\\hat{\\theta}_{adj} - \\hat{\\theta}_8 \\approx 2(0.221246) - 0.55 = -0.107508$\n\n最终调整后的合并效应是根据包含所有 8 项原始研究和 2 项估算研究的增广数据集计算得出的。剪补法的一个重要特性是，这个包含 $k+k_0$ 项研究的增广数据集的最终合并效应，在数学上与从包含 $k-k_0$ 项研究的修剪后数据集计算出的合并效应是相同的。因此，最终调整后的合并效应为 $\\hat{\\theta}_{adj}$。\n\n$$ \\hat{\\theta}_{\\text{final}} = \\hat{\\theta}_{adj} \\approx 0.2212458 $$\n四舍五入至四位有效数字，调整后的合并效应为 $0.2212$。\n\n**关于偏倚特性的讨论**\n初始合并效应 $\\hat{\\theta}_{FE} \\approx 0.2325$ 可能因发表偏倚而偏高，发表偏倚是指系统性地倾向于发表具有统计学显著性结果的研究，而非不显著结果的研究。这种偏倚通常导致较大效应量的过度代表，尤其是在统计功效较低的小型研究中，从而引起漏斗图不对称。Egger 检验可正式检测这种不对称性。\n\n剪补法程序试图校正这种偏倚。通过识别并修剪图中过度代表一侧的最极端研究，并在另一侧估算其“缺失”的对应研究，该方法创建了一个更对称的效应分布。调整后的合并估计值 $\\hat{\\theta}_{\\text{final}} \\approx 0.2212$ 低于初始估计值，反映了对假定的向上偏倚的校正。在假设观察到的不对称性确实是由发表偏倚引起的情况下，这个调整后的值被认为是真实潜在效应的一个更合理的估计。然而，剪补法本身并非没有局限性；其准确性取决于其假设的有效性。如果漏斗图的不对称性是由发表偏倚以外的因素（例如，真实的异质性）引起的，该方法可能会产生误导性的“校正”。因此，最好将其视为一种敏感性分析，用以衡量发表偏倚的潜在影响。",
            "answer": "$$\n\\boxed{0.2212}\n$$"
        }
    ]
}