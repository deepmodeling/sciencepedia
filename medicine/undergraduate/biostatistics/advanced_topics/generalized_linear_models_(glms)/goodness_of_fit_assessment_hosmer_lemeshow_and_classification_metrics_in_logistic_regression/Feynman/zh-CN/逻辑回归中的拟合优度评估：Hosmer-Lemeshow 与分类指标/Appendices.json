{
    "hands_on_practices": [
        {
            "introduction": "在线性回归中，$R^2$ 统计量提供了一个直接的度量，用于衡量模型解释结果变异的程度。但是，在我们转而对概率进行建模的逻辑斯谛回归中，应如何量化模型的解释力呢？这个练习  介绍了伪 $R^2$ (pseudo-$R^2$) 指标，它们旨在通过比较你拟合的模型与基线（零）模型的似然 (likelihood) 来回答这个问题。你将推导并计算常用的 Cox–Snell 和 Nagelkerke $R^2$ 统计量，从而更深入地理解它们的构建原理、解释方式，以及为何它们是总结模型性能的重要工具。",
            "id": "4914507",
            "problem": "一家医院的生物统计团队为一个二元结果拟合了一个逻辑回归模型，该结果表明患者是否出现术后并发症。他们使用最大似然估计（MLE）估计了一个仅含截距项的模型（零模型）和一个富含预测变量的模型（拟合模型）。假设结果是独立的伯努利分布。样本量为 $n=200$，零模型的对数似然为 $\\ell_{0}=-138.4$，拟合模型的对数似然为 $\\ell_{m}=-124.1$。\n\n从独立伯努利似然的定义 $L=\\prod_{i=1}^{n} p_{i}^{y_{i}}(1-p_{i})^{1-y_{i}}$ 及其对数出发，推导用 $n$、$\\ell_{0}$ 和 $\\ell_{m}$ 表示的 Cox–Snell 伪 $R^{2}$ 和 Nagelkerke 伪 $R^{2}$ 的表达式。使用这些定义和饱和模型的概念，解释为什么在逻辑回归中 Cox–Snell 的度量没有以 $1$ 为上界，而 Nagelkerke 的度量有。\n\n然后，使用你推导出的公式以及给定的 $n$、$\\ell_{0}$ 和 $\\ell_{m}$ 的值，计算 Nagelkerke 伪 $R^{2}$。将你的最终数值答案四舍五入到四位有效数字，并以小数形式表示（不要使用百分号）。",
            "solution": "该问题要求推导和解释逻辑回归中使用的两种伪 $R^2$ 度量，然后进行数值计算。该问题具有科学依据，论述清晰，并包含所有必要信息。因此，该问题被认为是有效的。\n\n分析的基础是 $n$ 次独立伯努利试验的似然函数。给定观测结果 $y_i \\in \\{0, 1\\}$ 和模型预测概率 $p_i$，似然 $L$ 为：\n$$L = \\prod_{i=1}^{n} p_{i}^{y_{i}}(1-p_{i})^{1-y_{i}}$$\n对数似然（记作 $\\ell$）是似然的自然对数：\n$$\\ell = \\ln(L) = \\sum_{i=1}^{n} [y_i \\ln(p_i) + (1-y_i) \\ln(1-p_i)]$$\n问题为样本量 $n=200$ 提供了两个模型的最大化对数似然：零模型（仅含截距项），$\\ell_0 = -138.4$，以及拟合模型，$\\ell_m = -124.1$。\n\n首先，我们推导 Cox–Snell 和 Nagelkerke 伪 $R^2$ 度量的表达式。这些度量旨在通过比较拟合模型（$L_m$）与零模型（$L_0$）的似然，来模拟线性回归中的决定系数 $R^2$。\n\nCox–Snell 伪 $R^2$，记作 $R^2_{CS}$，定义为：\n$$R^2_{CS} = 1 - \\left(\\frac{L_0}{L_m}\\right)^{2/n}$$\n为了用给定的对数似然表示它，我们使用属性 $\\ln(L_0/L_m) = \\ell_0 - \\ell_m$。对两边取指数，得到 $L_0/L_m = \\exp(\\ell_0 - \\ell_m)$。将此代入 $R^2_{CS}$ 的定义中：\n$$R^2_{CS} = 1 - \\left(\\exp(\\ell_0 - \\ell_m)\\right)^{2/n} = 1 - \\exp\\left(\\frac{2(\\ell_0 - \\ell_m)}{n}\\right)$$\n这就是用 $n$、$\\ell_0$ 和 $\\ell_m$ 表示的 Cox–Snell 伪 $R^2$ 的所求表达式。\n\n接下来，我们讨论为什么 Cox–Snell 度量没有以 $1$ 为上界。任何伪 $R^2$ 度量的上界在拟合模型为“饱和模型”时达到，饱和模型是能完美拟合数据的模型。对于 $n$ 个独立的伯努利结果，饱和模型将拥有与观测数量一样多的参数，从而实现完美拟合。在这样的模型中，对于每个观测值 $y_i$，其预测概率 $p_i$ 将为 $p_i=y_i$。单个观测值的似然是 $p_i^{y_i}(1-p_i)^{1-y_i}$。如果 $y_i=1$，该项为 $1^1(0)^0$。如果 $y_i=0$，该项为 $0^0(1)^1$。使用约定 $0^0=1$，饱和模型中每个观测值的似然都是 $1$。因此，饱和模型的总似然为 $L_{sat} = \\prod_{i=1}^{n} 1 = 1$。相应的对数似然为 $\\ell_{sat} = \\ln(1) = 0$。\n\n$L_m$ 的最大可能值为 $L_{sat} = 1$。将此代入 $R^2_{CS}$ 的定义中，得到该度量的最大可达值：\n$$\\max(R^2_{CS}) = 1 - \\left(\\frac{L_0}{L_{sat}}\\right)^{2/n} = 1 - \\left(\\frac{L_0}{1}\\right)^{2/n} = 1 - (L_0)^{2/n}$$\n由于零模型（它假设所有结果具有单一概率）不能完美拟合数据，其似然 $L_0$ 严格小于 $1$。因此，$(L_0)^{2/n}$ 是一个正值，这意味着 $\\max(R^2_{CS})  1$。这就是为什么 Cox–Snell 度量没有以 $1$ 为上界；其可达到的最大值是数据依赖的，并且总是小于 $1$。\n\nNagelkerke 伪 $R^2$，记作 $R^2_N$，被提出来纠正这个局限性，其方法是将 Cox–Snell 度量除以其最大可能值进行归一化：\n$$R^2_N = \\frac{R^2_{CS}}{\\max(R^2_{CS})} = \\frac{1 - (L_0/L_m)^{2/n}}{1 - (L_0)^{2/n}}$$\n通过这种构造，当拟合模型是饱和模型（$L_m = 1$）时，分子变得与分母相等，且 $R^2_N = 1$。因此，Nagelkerke 度量以 $1$ 为上界，其范围为 $[0, 1]$。\n\n为了推导用对数似然表示的 $R^2_N$ 表达式，我们代入指数形式：\n$$(L_0/L_m)^{2/n} = \\exp\\left(\\frac{2(\\ell_0 - \\ell_m)}{n}\\right)$$\n$$(L_0)^{2/n} = (\\exp(\\ell_0))^{2/n} = \\exp\\left(\\frac{2\\ell_0}{n}\\right)$$\n将这些代入 $R^2_N$ 的公式中，得到：\n$$R^2_N = \\frac{1 - \\exp\\left(\\frac{2(\\ell_0 - \\ell_m)}{n}\\right)}{1 - \\exp\\left(\\frac{2\\ell_0}{n}\\right)}$$\n这就是所求的 Nagelkerke 伪 $R^2$ 的表达式。\n\n最后，我们使用给定的数据计算 $R^2_N$ 的数值：$n=200$，$\\ell_0=-138.4$，$\\ell_m=-124.1$。\n\n首先，我们计算指数中的各项：\n- 分子指数项: $\\frac{2(\\ell_0 - \\ell_m)}{n} = \\frac{2(-138.4 - (-124.1))}{200} = \\frac{2(-14.3)}{200} = \\frac{-28.6}{200} = -0.143$\n- 分母指数项: $\\frac{2\\ell_0}{n} = \\frac{2(-138.4)}{200} = \\frac{-276.8}{200} = -1.384$\n\n现在，将这些值代入 $R^2_N$ 的公式中：\n$$R^2_N = \\frac{1 - \\exp(-0.143)}{1 - \\exp(-1.384)}$$\n我们计算指数函数的值：\n$$\\exp(-0.143) \\approx 0.8667528$$\n$$\\exp(-1.384) \\approx 0.2505705$$\n将这些数值代回 $R^2_N$ 的表达式中：\n$$R^2_N \\approx \\frac{1 - 0.8667528}{1 - 0.2505705} = \\frac{0.1332472}{0.7494295} \\approx 0.1778005$$\n将结果四舍五入到四位有效数字，得到 $0.1778$。",
            "answer": "$$\\boxed{0.1778}$$"
        },
        {
            "introduction": "一个具有良好解释力的模型是一个很好的起点，但在许多应用中，我们需要信任它预测出的具体概率值。这就是校准 (calibration) 的概念：一个预测的 $30\\%$ 风险是否真的对应于该组对象中 $30\\%$ 的实际事件发生率？这个关键的练习  将引导你手动计算评估校准度的几个关键指标，包括基于熵的对数损失 (log-loss)、Brier 分数，以及广泛使用的 Hosmer-Lemeshow 拟合优度检验统计量。完成此练习将巩固你对如何量化评估模型是否经过良好校准的理解。",
            "id": "4914555",
            "problem": "一个生物统计学团队针对 $n=20$ 名患者的一个二元临床结局 $y_{i} \\in \\{0,1\\}$ 拟合了一个逻辑回归模型，并获得了预测概率 $\\hat{p}_{i} \\in (0,1)$。该模型使用从第一性原理推导出的拟合优度和分类质量指标进行评估。\n\n从独立观测值的伯努利似然及其对数出发，将基于熵的分类质量度量定义为每个观测值的负平均对数似然。同时，也考虑预测概率与结果之间的均方误差。使用这些基础为下述数据集计算这两个指标，并通过二次近似来讨论它们之间的局部关系。\n\n此外，通过将患者按 $\\hat{p}_{i}$ 排序分为 $G=5$ 个大小相等的风险组，并比较每组内事件的观测计数与期望计数，使用 Hosmer–Lemeshow (HL) 拟合优度统计量来评估模型的校准度。请使用标准的 HL 分组程序和 Pearson 型分组统计量。\n\n数据集以患者 $i=1,\\dots,20$ 的有序对 $(\\hat{p}_{i}, y_{i})$ 形式给出：\n$(0.05,0)$, $(0.08,0)$, $(0.10,0)$, $(0.12,1)$, $(0.18,0)$, $(0.22,0)$, $(0.25,1)$, $(0.28,0)$, $(0.32,0)$, $(0.35,1)$, $(0.45,1)$, $(0.50,0)$, $(0.55,1)$, $(0.60,1)$, $(0.65,0)$, $(0.70,1)$, $(0.78,1)$, $(0.82,1)$, $(0.88,1)$, $(0.92,1)$.\n\n任务：\n- 从伯努利似然推导出基于熵的每个观测值的负平均对数似然，并为该数据集计算其值。\n- 将 Brier 分数定义为 $\\hat{p}_{i}$ 和 $y_{i}$ 之间的均方差，并为该数据集计算其值。\n- 使用围绕正确分类的二阶泰勒展开，解释基于熵的度量与 Brier 分数之间的局部关系。\n- 为 $G=5$ 个等大小的分组（按 $\\hat{p}_{i}$ 排序）计算 Hosmer–Lemeshow 统计量，展示期望计数、观测计数以及每组对该统计量的贡献。\n\n最后，报告单个量 $R$，其定义为基于熵的负平均对数似然与 Brier 分数之比。将 $R$ 四舍五入至四位有效数字。无需单位，并将任何中间比例或概率以小数形式（而非百分比）表示。",
            "solution": "该问题是有效的，因为它科学地基于已确立的生物统计学原理，问题陈述清晰，包含所有必要数据和明确目标，并以精确、客观的语言表达。\n\n### 第1部分：基于熵的负平均对数似然\n\n该模型用于 $i=1, \\dots, n$ 个独立患者的二元结局 $y_i \\in \\{0, 1\\}$。事件 ($y_i=1$) 的预测概率为 $\\hat{p}_i$。观测到结果 $y_i$ 的概率由伯努利概率质量函数给出：\n$$ P(Y_i = y_i | \\hat{p}_i) = \\hat{p}_i^{y_i} (1-\\hat{p}_i)^{1-y_i} $$\n对于 $n$ 个独立观测值，总似然是各个概率的乘积：\n$$ L(\\{\\hat{p}_i\\}; \\{y_i\\}) = \\prod_{i=1}^{n} \\hat{p}_i^{y_i} (1-\\hat{p}_i)^{1-y_i} $$\n对数似然 $\\ell$ 是似然的自然对数：\n$$ \\ell = \\ln(L) = \\sum_{i=1}^{n} \\ln\\left( \\hat{p}_i^{y_i} (1-\\hat{p}_i)^{1-y_i} \\right) = \\sum_{i=1}^{n} [y_i \\ln(\\hat{p}_i) + (1-y_i) \\ln(1-\\hat{p}_i)] $$\n基于熵的分类质量度量（我们表示为 $E$）被定义为每个观测值的负平均对数似然。这也被称为交叉熵损失。\n$$ E = -\\frac{1}{n} \\ell = -\\frac{1}{n} \\sum_{i=1}^{n} [y_i \\ln(\\hat{p}_i) + (1-y_i) \\ln(1-\\hat{p}_i)] $$\n为了计算给定数据集的该值，我们有 $n=20$。我们将总和分为两部分：一部分用于 $y_i=1$ 的观测值，另一部分用于 $y_i=0$ 的观测值。\n\n对于 $y_i=1$ 的情况（11个观测值）：\n$$ \\sum_{y_i=1} \\ln(\\hat{p}_i) = \\ln(0.12) + \\ln(0.25) + \\ln(0.35) + \\ln(0.45) + \\ln(0.55) + \\ln(0.60) + \\ln(0.70) + \\ln(0.78) + \\ln(0.82) + \\ln(0.88) + \\ln(0.92) \\approx -7.478345 $$\n对于 $y_i=0$ 的情况（9个观测值）：\n$$ \\sum_{y_i=0} \\ln(1-\\hat{p}_i) = \\ln(1-0.05) + \\ln(1-0.08) + \\ln(1-0.10) + \\ln(1-0.18) + \\ln(1-0.22) + \\ln(1-0.28) + \\ln(1-0.32) + \\ln(1-0.50) + \\ln(1-0.65) \\approx -3.144083 $$\n总对数似然为 $\\ell \\approx -7.478345 - 3.144083 = -10.622428$。\n基于熵的度量为：\n$$ E = -\\frac{1}{20} (-10.622428) \\approx 0.5311214 $$\n\n### 第2部分：Brier分数（均方误差）\n\nBrier 分数 $BS$ 定义为预测概率 $\\hat{p}_i$ 与实际结果 $y_i$ 之间的均方差。\n$$ BS = \\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\hat{p}_i)^2 $$\n为该数据集（$n=20$）计算其值：\n对于 $y_i=1$ 的情况：\n$$ \\sum_{y_i=1} (1-\\hat{p}_i)^2 = (1-0.12)^2 + (1-0.25)^2 + \\dots + (1-0.92)^2 = 0.88^2 + 0.75^2 + 0.65^2 + 0.55^2 + 0.45^2 + 0.40^2 + 0.30^2 + 0.22^2 + 0.18^2 + 0.12^2 + 0.08^2 = 2.616 $$\n对于 $y_i=0$ 的情况：\n$$ \\sum_{y_i=0} (0-\\hat{p}_i)^2 = (0.05)^2 + (0.08)^2 + \\dots + (0.65)^2 = 0.05^2 + 0.08^2 + 0.10^2 + 0.18^2 + 0.22^2 + 0.28^2 + 0.32^2 + 0.50^2 + 0.65^2 = 0.953 $$\n总平方和为 $2.616 + 0.953 = 3.569$。\nBrier 分数为：\n$$ BS = \\frac{1}{20} (3.569) = 0.17845 $$\n\n### 第3部分：熵与Brier分数的局部关系\n\n让我们分析单个观测值的熵度量损失 $E_i$ 和 Brier 分数损失 $BS_i$。\n$$ E_i = -[y_i \\ln(\\hat{p}_i) + (1-y_i) \\ln(1-\\hat{p}_i)] $$\n$$ BS_i = (y_i - \\hat{p}_i)^2 $$\n我们研究 $E_i$ 在“正确分类”附近的局部行为，这意味着预测概率 $\\hat{p}_i$ 非常接近真实结果 $y_i$。设偏差为 $\\epsilon = |y_i - \\hat{p}_i|$，其中 $\\epsilon \\to 0^+$。\n\n情况1：$y_i=1$。正确分类意味着 $\\hat{p}_i \\to 1$。令 $\\hat{p}_i = 1-\\epsilon$。\n熵损失为 $E_i = -\\ln(1-\\epsilon)$。\nBrier 分数为 $BS_i = (1 - (1-\\epsilon))^2 = \\epsilon^2$。\n使用 $-\\ln(1-\\epsilon)$ 在 $\\epsilon=0$ 附近的二阶泰勒展开：\n$$ E_i = - \\left( -\\epsilon - \\frac{\\epsilon^2}{2} - O(\\epsilon^3) \\right) = \\epsilon + \\frac{\\epsilon^2}{2} + O(\\epsilon^3) $$\n情况2：$y_i=0$。正确分类意味着 $\\hat{p}_i \\to 0$。令 $\\hat{p}_i = \\epsilon$。\n熵损失为 $E_i = -\\ln(1-\\epsilon)$。\nBrier 分数为 $BS_i = (0 - \\epsilon)^2 = \\epsilon^2$。\n泰勒展开是相同的：\n$$ E_i = \\epsilon + \\frac{\\epsilon^2}{2} + O(\\epsilon^3) $$\n在两种情况下，对于一个小的偏差 $\\epsilon = |y_i - \\hat{p}_i|$，我们有 $BS_i = \\epsilon^2$。将 $\\epsilon = \\sqrt{BS_i}$ 代入 $E_i$ 的展开式中：\n$$ E_i \\approx \\sqrt{BS_i} + \\frac{1}{2} BS_i $$\n这种关系表明，对于非常接近真实结果的预测，熵损失主要由一个关于 $\\epsilon$ 的线性项（$\\sqrt{BS_i}$）主导，而 Brier 分数是二次的（$\\epsilon^2$）。这意味着熵损失比 Brier 分数更严厉地惩罚小的预测误差。\n\n### 第4部分：Hosmer–Lemeshow 统计量\n\n我们将患者按 $\\hat{p}_i$ 排序，并形成 $G=5$ 个大小相等的分组，每组大小为 $n_g = 20/5=4$。对于每组 $g$，我们计算观测到的事件数（$O_g = \\sum y_i$）和期望的事件数（$E_g = \\sum \\hat{p}_i$）。Hosmer-Lemeshow 统计量 $H$ 是一个根据这些计数计算出的 Pearson 型卡方统计量：\n$$ H = \\sum_{g=1}^{G} \\left[ \\frac{(O_g - E_g)^2}{E_g} + \\frac{((n_g - O_g) - (n_g - E_g))^2}{n_g - E_g} \\right] $$\n计算过程总结在下表中。\n\n| 分组 (g) | 患者（按索引 $i$） | 预测概率 ($\\hat{p}_i$) | 结局 ($y_i$) | $n_g$ | $O_g$ | $E_g$ | $O_g-E_g$ | 对 $H$ 的贡献 |\n| :---: | :---: | :--- | :--- | :---: | :---: | :---: | :---: | :---: |\n| 1 | 1-4 | $0.05, 0.08, 0.10, 0.12$ | $0, 0, 0, 1$ | 4 | 1 | 0.35 | 0.65 | $\\frac{0.65^2}{0.35} + \\frac{(-0.65)^2}{3.65} \\approx 1.32290$ |\n| 2 | 5-8 | $0.18, 0.22, 0.25, 0.28$ | $0, 0, 1, 0$ | 4 | 1 | 0.93 | 0.07 | $\\frac{0.07^2}{0.93} + \\frac{(-0.07)^2}{3.07} \\approx 0.00687$ |\n| 3 | 9-12 | $0.32, 0.35, 0.45, 0.50$ | $0, 1, 1, 0$ | 4 | 2 | 1.62 | 0.38 | $\\frac{0.38^2}{1.62} + \\frac{(-0.38)^2}{2.38} \\approx 0.14981$ |\n| 4 | 13-16 | $0.55, 0.60, 0.65, 0.70$ | $1, 1, 0, 1$ | 4 | 3 | 2.50 | 0.50 | $\\frac{0.50^2}{2.50} + \\frac{(-0.50)^2}{1.50} \\approx 0.26667$ |\n| 5 | 17-20 | $0.78, 0.82, 0.88, 0.92$ | $1, 1, 1, 1$ | 4 | 4 | 3.40 | 0.60 | $\\frac{0.60^2}{3.40} + \\frac{(-0.60)^2}{0.60} \\approx 0.70588$ |\n\n将各组的贡献相加：\n$$ H \\approx 1.32290 + 0.00687 + 0.14981 + 0.26667 + 0.70588 \\approx 2.45213 $$\n\n### 第5部分：最终比率计算\n\n最后的任务是计算基于熵的负平均对数似然与 Brier 分数之比 $R$。\n$$ R = \\frac{E}{BS} = \\frac{0.5311214}{0.17845} \\approx 2.976296 $$\n四舍五入到四位有效数字，我们得到：\n$$ R \\approx 2.976 $$",
            "answer": "$$\n\\boxed{2.976}\n$$"
        },
        {
            "introduction": "理解的最终考验是将概念转化为代码的能力。这个练习  将带你从手动计算过渡到建立一个完整的、基于模拟的模型评估工作流程，这也反映了真实世界中数据分析项目的过程。你将编写代码来拟合模型、计算拟合优度统计量，最重要的是，你将使用强大的参数自助法 (parametric bootstrap) 程序来评估统计显著性，这种方法通常比传统的近似方法更为可靠。这个总结性的练习将使你能够从第一性原理出发，对逻辑斯谛回归模型进行严谨且可重现的验证。",
            "id": "4914521",
            "problem": "考虑一个二元响应设定，其中观测值为 $\\{(y_i, x_i)\\}_{i=1}^n$，$y_i \\in \\{0,1\\}$ 且 $x_i \\in \\mathbb{R}^p$。逻辑斯谛回归模型假设 $\\Pr(Y_i = 1 \\mid x_i) = \\sigma(x_i^\\top \\beta)$，其中逻辑斯谛函数为 $\\sigma(u) = 1/(1+\\exp(-u))$。参数 $\\beta \\in \\mathbb{R}^{p+1}$（包括一个截距项）通过优化伯努利对数似然进行最大似然估计。为了数值稳定性，您可以包含一个小的 $\\ell_2$（岭）惩罚项，但推断目标仍是由无惩罚的伯努利似然所隐含的目标。\n\n在拟合模型并获得 $\\hat{\\beta}$ 后，您的任务是评估拟合优度，执行 Hosmer–Lemeshow 分组检验，并计算分类指标，所有这些都需要基于其基本原理进行严谨的构建：\n\n1. 通过最大化伯努利对数似然来拟合逻辑斯谛回归模型，以获得 $\\hat{\\beta}$ 和预测概率 $\\hat{p}_i = \\sigma(x_i^\\top \\hat{\\beta})$。\n2. 使用伯努利方差模型，通过标准化残差构建皮尔逊型拟合优度统计量 $X^2$。该统计量必须从残差形式 $(y_i - \\hat{p}_i)$ 和模型下的方差 $\\hat{p}_i(1-\\hat{p}_i)$ 导出。\n3. 实现参数自助法（parametric bootstrap）以评估在拟合模型下 $X^2$ 的抽样分布。具体方法是：生成自助法结果 $y_i^\\ast \\sim \\operatorname{Bernoulli}(\\hat{p}_i)$，对每个自助法数据集重新拟合逻辑斯谛模型以获得新的预测概率 $\\hat{p}_i^\\ast$，然后重新计算自助法统计量 $X^{2\\ast}$。使用右尾比例 $\\Pr^\\ast(X^{2\\ast} \\ge X^2)$ 作为自助法 $p$ 值。\n4. 实现 Hosmer–Lemeshow (HL) 检验。首先根据 $\\hat{p}_i$ 的分位数将观测值分为 $G$ 个组（分组时应使各组大小尽可能相等）。对每个组，计算观测事件数和模型期望事件数，并使用组水平上的二项方差导出 HL 统计量。使用自由度为 $G-2$ 的卡方近似来计算 HL 的 $p$ 值。\n5. 对于给定的分类阈值 $t \\in (0,1)$，使用拟合的 $\\hat{p}_i$ 和经验结果 $y_i$ 计算准确率、灵敏度（真阳性率）和特异度（真阴性率）。如果任何比率的分母为零，则遵循适用于混淆矩阵的传统极限定义，将相应的比率视为实数。\n\n您的程序必须实现上述原则性步骤，并评估以下测试套件。在每种情况下，生成带有截距项和独立标准正态预测变量的协变量 $x_i$，然后根据具有指定系数的已知逻辑斯谛模型生成结果 $y_i$。使用指定的随机数生成器种子以确保可复现性。具体而言，对于每个测试用例，执行以下操作：\n- 生成 $n$ 个独立的 $p$ 维预测变量，其条目从标准正态分布中抽取，前置一个值为 $1$ 的截距项以形成 $(p+1)$ 维协变量向量，并计算真实概率 $p_i^{\\text{true}} = \\sigma(x_i^\\top \\beta_{\\text{true}})$。\n- 生成经验结果 $y_i \\sim \\operatorname{Bernoulli}(p_i^{\\text{true}})$。\n- 将逻辑斯谛模型拟合到 $(x_i, y_i)$ 以获得 $\\hat{\\beta}$ 和 $\\hat{p}_i$。\n- 计算 $X^2$、其使用 $B$ 次重复的自助法 $p$ 值、使用 $G$ 个组的 HL 统计量及其卡方 $p$ 值，以及在阈值 $t$ 下的准确率、灵敏度和特异度。\n\n测试套件参数集：\n- 情况 A（一般情况）：seed $= 42$, $n = 200$, $p = 2$, $\\beta_{\\text{true}} = [-1.0, 0.8, -0.5]$, $G = 10$, $B = 300$, $t = 0.5$。\n- 情况 B（稀有事件）：seed $= 314$, $n = 150$, $p = 2$, $\\beta_{\\text{true}} = [-3.0, 1.2, 0.0]$, $G = 8$, $B = 300$, $t = 0.3$。\n- 情况 C（中度极端情况）：seed $= 7$, $n = 120$, $p = 3$, $\\beta_{\\text{true}} = [-0.5, 1.5, -1.0, 0.5]$, $G = 6$, $B = 250$, $t = 0.5$。\n\n输出规范：\n- 对于每个测试用例，按以下顺序返回一个包含七个实数的列表：$[X^2, p_{\\text{boot}}, H_{\\text{HL}}, p_{\\text{HL}}, \\text{accuracy}, \\text{sensitivity}, \\text{specificity}]$。\n- 您的程序应生成单行输出，其中包含所有测试用例的结果，形式为一个以逗号分隔的、由各用例列表组成的列表，并用方括号括起来，不含空格。例如，输出应类似于 $[[r_{11},r_{12},\\dots,r_{17}],[r_{21},\\dots,r_{27}],[r_{31},\\dots,r_{37}]]$，其中每个 $r_{jk}$ 是一个实数。所有实数均以小数形式表示（而非百分比）。\n\n所有量均为无单位量。不涉及角度。整个计算必须是自包含的，并且可以根据上述规范和提供的种子进行复现。",
            "solution": "用户提供的问题是在生物统计学中一个明确定义的任务，要求实现一个完整的逻辑斯谛回归分析工作流程，从模型拟合到拟合优度评估和性能评价。该问题具有科学依据，内部一致，并且不需要超出所提供信息之外的任何信息。所概述的步骤是标准的统计程序。关于用于数值稳定性的微小 $\\ell_2$ 惩罚项大小的一个次要模糊之处，通过选择一个标准的较小值来解决，这与问题的意图一致。该问题被认为是有效的，下面给出了一个完整的解决方案。\n\n问题的核心是使用逻辑斯谛回归模型来分析二元响应 $y_i \\in \\{0, 1\\}$ 作为协变量 $x_i \\in \\mathbb{R}^p$ 的函数。模型中包含一个截距项，因此协变量向量是 $(p+1)$ 维的。模型假设正向结果（$y_i=1$）的概率由下式给出：\n$$\n\\Pr(Y_i = 1 \\mid x_i) = p_i = \\sigma(x_i^\\top \\beta) = \\frac{1}{1 + \\exp(-x_i^\\top \\beta)}\n$$\n其中 $\\beta \\in \\mathbb{R}^{p+1}$ 是模型系数的向量。\n\n**1. 逻辑斯谛回归模型拟合**\n\n系数 $\\hat{\\beta}$ 通过最大化观测数据的对数似然来估计。对于 $n$ 个独立观测，似然函数是伯努利概率的乘积：\n$$\nL(\\beta) = \\prod_{i=1}^n p_i^{y_i} (1-p_i)^{1-y_i}\n$$\n对数似然为：\n$$\n\\ell(\\beta) = \\log L(\\beta) = \\sum_{i=1}^n \\left[ y_i \\log(p_i) + (1-y_i) \\log(1-p_i) \\right]\n$$\n为了增强数值稳定性，特别是在数据中出现近乎完美分离的情况下，会增加一个小的 $\\ell_2$（岭）惩罚项。带惩罚的对数似然是：\n$$\n\\ell_{\\text{pen}}(\\beta) = \\ell(\\beta) - \\frac{\\lambda}{2} \\|\\beta\\|_2^2\n$$\n其中 $\\lambda$ 是一个小的正则化参数。我们寻求 $\\hat{\\beta} = \\arg\\max_{\\beta} \\ell_{\\text{pen}}(\\beta)$，这等同于最小化负的带惩罚的对数似然，$J(\\beta) = - \\ell_{\\text{pen}}(\\beta)$。\n\n我们使用牛顿-拉弗森算法（Newton-Raphson algorithm），这是一种利用二阶信息的迭代优化方法。更新规则是：\n$$\n\\beta_{k+1} = \\beta_k - H_k^{-1} g_k\n$$\n其中 $g_k = \\nabla J(\\beta_k)$ 是梯度，$H_k = \\nabla^2 J(\\beta_k)$ 是目标函数的海森矩阵（Hessian），两者均在 $\\beta_k$ 处求值。\n\n梯度是：\n$$\ng(\\beta) = \\nabla J(\\beta) = - \\nabla \\ell_{\\text{pen}}(\\beta) = - \\left( \\sum_{i=1}^n (y_i - p_i) x_i - \\lambda \\beta \\right) = X^\\top(p-y) + \\lambda\\beta\n$$\n海森矩阵是：\n$$\nH(\\beta) = \\nabla^2 J(\\beta) = - \\nabla^2 \\ell_{\\text{pen}}(\\beta) = X^\\top W X + \\lambda I\n$$\n其中 $X$ 是 $n \\times (p+1)$ 的设计矩阵，$y$ 是结果向量，$p$ 是概率向量 $\\sigma(X\\beta)$，$I$ 是单位矩阵，$W$ 是一个对角矩阵，其对角线元素为 $W_{ii} = p_i(1-p_i)$。迭代从一个初始猜测（通常是 $\\beta_0 = 0$）开始，并持续到收敛。一旦找到 $\\hat{\\beta}$，拟合概率就是 $\\hat{p}_i = \\sigma(x_i^\\top \\hat{\\beta})$。\n\n**2. 皮尔逊拟合优度统计量 ($X^2$)**\n\n皮尔逊型拟合优度统计量 $X^2$ 用于衡量观测结果与预测概率之间的差异。它是皮尔逊残差平方和：\n$$\nX^2 = \\sum_{i=1}^n \\frac{(y_i - \\hat{p}_i)^2}{\\hat{p}_i(1-\\hat{p}_i)}\n$$\n分母 $\\hat{p}_i(1-\\hat{p}_i)$ 是伯努利随机变量 $Y_i$ 的估计方差。$X^2$ 值较大表明模型拟合不佳。\n\n**3. 用于 $X^2$ p值的参数自助法**\n\n$X^2$ 的理论渐近分布（通常是 $\\chi^2_{n-p-1}$）在实践中往往是一个不佳的近似。参数自助法为评估在拟合模型正确假设下 $X^2$ 的抽样分布提供了一种更准确的方法。该过程如下：\n1.  将模型拟合到原始数据 $(X, y)$ 以获得 $\\hat{\\beta}$ 和 $\\hat{p}$。计算观测到的统计量 $X^2$。\n2.  对于 $B$ 次自助法重复中的每一次：\n    a. 生成一个自助法样本结果 $y^\\ast$，其中每个 $y_i^\\ast \\sim \\operatorname{Bernoulli}(\\hat{p}_i)$。\n    b. 将逻辑斯谛回归模型拟合到自助法数据 $(X, y^\\ast)$ 以获得新的估计值 $\\hat{\\beta}^\\ast$ 和 $\\hat{p}^\\ast$。\n    c. 计算自助法统计量 $X^{2\\ast} = \\sum_{i=1}^n \\frac{(y_i^\\ast - \\hat{p}_i^\\ast)^2}{\\hat{p}_i^\\ast(1-\\hat{p}_i^\\ast)}$。\n3.  自助法 p值是自助法统计量大于或等于观测统计量的比例：\n$$\np_{\\text{boot}} = \\frac{1}{B} \\sum_{j=1}^B \\mathbb{I}(X^{2\\ast}_j \\ge X^2)\n$$\n\n**4. Hosmer–Lemeshow (HL) 检验**\n\nHosmer-Lemeshow 检验是另一种拟合优度检验，它根据观测值的预测概率对其进行分组。\n1.  根据拟合概率 $\\hat{p}_i$ 对观测值进行排序。\n2.  将数据划分为 $G$ 个大小尽可能相等的组。\n3.  对于每个组 $g \\in \\{1, \\dots, G\\}$，我们计算：\n    -   $N_g$：第 $g$ 组中的受试者数量。\n    -   $O_g = \\sum_{i \\in g} y_i$：观测到的事件数（结果 $y_i=1$）。\n    -   $E_g = \\sum_{i \\in g} \\hat{p}_i$：模型下预期的事件数。\n4.  HL 统计量作为一个皮尔逊型卡方统计量计算，作用于一个 $2 \\times G$ 的表格，该表格包含观测计数和期望计数（各组间的事件与非事件）：\n$$\nH_{\\text{HL}} = \\sum_{g=1}^G \\frac{(O_g - E_g)^2}{N_g \\bar{p}_g (1-\\bar{p}_g)}\n$$\n其中 $\\bar{p}_g = E_g / N_g$ 是第 $g$ 组的平均估计概率。分母是 $N_g$ 次伯努利试验总和的方差，使用平均概率 $\\bar{p}_g$ 进行近似。\n5.  在模型校准良好的零假设下，$H_{\\text{HL}}$ 近似服从自由度为 $G-2$ 的卡方分布。p值 $p_{\\text{HL}}$ 由此分布计算得出：$p_{\\text{HL}} = \\Pr(\\chi_{G-2}^2 \\ge H_{\\text{HL}})$。\n\n**5. 分类指标**\n\n给定一个分类阈值 $t$，如果 $\\hat{p}_i \\ge t$，则一个观测值被分类为阳性（$\\hat{y}_i=1$），否则为阴性（$\\hat{y}_i=0$）。性能通过一个混淆矩阵进行评估，该矩阵统计了：\n-   真阳性 (TP): $\\sum_i \\mathbb{I}(\\hat{y}_i = 1 \\text{ and } y_i = 1)$\n-   真阴性 (TN): $\\sum_i \\mathbb{I}(\\hat{y}_i = 0 \\text{ and } y_i = 0)$\n-   假阳性 (FP): $\\sum_i \\mathbb{I}(\\hat{y}_i = 1 \\text{ and } y_i = 0)$\n-   假阴性 (FN): $\\sum_i \\mathbb{I}(\\hat{y}_i = 0 \\text{ and } y_i = 1)$\n\n根据这些值，我们计算：\n-   **准确率**：正确分类的比例。\n    $$ \\text{Accuracy} = \\frac{TP + TN}{TP + TN + FP + FN} $$\n-   **灵敏度** (真阳性率, 召回率): 被正确识别的实际阳性样本的比例。\n    $$ \\text{Sensitivity} = \\frac{TP}{TP + FN} $$\n-   **特异度** (真阴性率): 被正确识别的实际阴性样本的比例。\n    $$ \\text{Specificity} = \\frac{TN}{TN + FP} $$\n如果分母为零（即，对于灵敏度没有实际阳性样本，或对于特异度没有实际阴性样本），则相应的比率取为 $0.0$，因为没有实例可以被正确分类。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.stats import chi2\n\ndef solve():\n    \"\"\"\n    Main function to run the specified test suite for logistic regression analysis.\n    \"\"\"\n\n    LAMBDA_REG = 1e-6 # Small L2 regularization parameter\n\n    def _sigmoid(u):\n        \"\"\"Numerically stable logistic sigmoid function.\"\"\"\n        return 1.0 / (1.0 + np.exp(-u))\n\n    def _fit_logistic_regression(X, y, max_iter=25, tol=1e-8):\n        \"\"\"\n        Fits a logistic regression model using Newton-Raphson.\n\n        Args:\n            X (np.ndarray): Design matrix of shape (n_samples, n_features+1).\n            y (np.ndarray): Response vector of shape (n_samples,).\n            max_iter (int): Maximum number of iterations.\n            tol (float): Convergence tolerance for log-likelihood change.\n\n        Returns:\n            tuple: A tuple containing:\n                - np.ndarray: Estimated coefficients beta_hat.\n                - np.ndarray: Predicted probabilities p_hat.\n        \"\"\"\n        n_samples, n_features = X.shape\n        beta = np.zeros(n_features)\n        \n        # Penalize all coefficients, including intercept, for stability\n        I_reg = np.eye(n_features) * LAMBDA_REG\n\n        # Newton-Raphson iterations\n        ll_old = -np.inf\n        for _ in range(max_iter):\n            u = X @ beta\n            p = _sigmoid(u)\n            \n            # Avoid p=0 or p=1 for numerical stability in W\n            p = np.clip(p, 1e-10, 1 - 1e-10)\n\n            # Gradient and Hessian of negative penalized log-likelihood\n            grad = X.T @ (p - y) + LAMBDA_REG * beta\n            W = np.diag(p * (1 - p))\n            hessian = X.T @ W @ X + I_reg\n\n            # Update step\n            try:\n                # Use psuedo-inverse for more stability\n                step = np.linalg.pinv(hessian) @ grad\n                beta = beta - step\n            except np.linalg.LinAlgError:\n                break # Stop if Hessian is singular\n\n            # Check for convergence\n            ll_new = np.sum(y * np.log(p) + (1 - y) * np.log(1 - p)) - 0.5 * LAMBDA_REG * np.dot(beta, beta)\n            if np.abs(ll_new - ll_old)  tol:\n                break\n            ll_old = ll_new\n            \n        final_p = _sigmoid(X @ beta)\n        return beta, final_p\n\n    test_cases = [\n        {'seed': 42, 'n': 200, 'p': 2, 'beta_true': [-1.0, 0.8, -0.5], 'G': 10, 'B': 300, 't': 0.5},\n        {'seed': 314, 'n': 150, 'p': 2, 'beta_true': [-3.0, 1.2, 0.0], 'G': 8, 'B': 300, 't': 0.3},\n        {'seed': 7, 'n': 120, 'p': 3, 'beta_true': [-0.5, 1.5, -1.0, 0.5], 'G': 6, 'B': 250, 't': 0.5},\n    ]\n\n    all_results = []\n\n    for case in test_cases:\n        seed, n, p, beta_true, G, B, t = case.values()\n        \n        # Reproducibility\n        rng = np.random.default_rng(seed)\n\n        # Generate data\n        X_cov = rng.standard_normal((n, p))\n        X = np.hstack([np.ones((n, 1)), X_cov])\n        beta_true = np.array(beta_true)\n        p_true = _sigmoid(X @ beta_true)\n        y = rng.binomial(1, p_true)\n\n        # 1. Fit the model\n        beta_hat, p_hat = _fit_logistic_regression(X, y)\n        \n        # Clip p_hat to avoid division by zero in stats\n        p_hat_clipped = np.clip(p_hat, 1e-10, 1 - 1e-10)\n\n        # 2. Pearson Chi-squared statistic\n        X2 = np.sum((y - p_hat)**2 / (p_hat_clipped * (1 - p_hat_clipped)))\n\n        # 3. Parametric Bootstrap\n        bootstrap_stats = []\n        for _ in range(B):\n            y_boot = rng.binomial(1, p_hat)\n            try:\n                _, p_boot = _fit_logistic_regression(X, y_boot)\n                p_boot_clipped = np.clip(p_boot, 1e-10, 1 - 1e-10)\n                X2_boot = np.sum((y_boot - p_boot)**2 / (p_boot_clipped * (1 - p_boot_clipped)))\n                bootstrap_stats.append(X2_boot)\n            except np.linalg.LinAlgError:\n                # Skip if a bootstrap fit fails\n                continue\n        \n        if len(bootstrap_stats) > 0:\n            p_boot = np.mean(np.array(bootstrap_stats) >= X2)\n        else:\n            p_boot = np.nan # Should not happen with regularization\n\n        # 4. Hosmer-Lemeshow Test\n        sorted_indices = np.argsort(p_hat)\n        groups = np.array_split(sorted_indices, G)\n        \n        hl_stat = 0.0\n        for group_indices in groups:\n            y_group = y[group_indices]\n            p_hat_group = p_hat[group_indices]\n            N_g = len(y_group)\n            O_g = np.sum(y_group)\n            E_g = np.sum(p_hat_group)\n            \n            # Using the formulation based on binomial variance at group level\n            avg_p_g = E_g / N_g if N_g > 0 else 0\n            denom = N_g * avg_p_g * (1 - avg_p_g)\n            \n            if denom > 1e-9: # Avoid division by zero\n                hl_stat += (O_g - E_g)**2 / denom\n        \n        p_hl = chi2.sf(hl_stat, df=G - 2)\n\n        # 5. Classification Metrics\n        y_pred = (p_hat >= t).astype(int)\n        \n        # Confusion matrix elements\n        tp = np.sum((y_pred == 1)  (y == 1))\n        tn = np.sum((y_pred == 0)  (y == 0))\n        fp = np.sum((y_pred == 1)  (y == 0))\n        fn = np.sum((y_pred == 0)  (y == 1))\n\n        accuracy = (tp + tn) / n\n        \n        sensitivity_denom = tp + fn\n        sensitivity = tp / sensitivity_denom if sensitivity_denom > 0 else 0.0\n        \n        specificity_denom = tn + fp\n        specificity = tn / specificity_denom if specificity_denom > 0 else 0.0\n        \n        case_results = [X2, p_boot, hl_stat, p_hl, accuracy, sensitivity, specificity]\n        all_results.append(case_results)\n    \n    # Final print statement in the exact required format.\n    print(str(all_results).replace(' ', ''))\n\nsolve()\n```"
        }
    ]
}