{
    "hands_on_practices": [
        {
            "introduction": "The most intuitive way to measure agreement is to calculate the percentage of times raters concur, but this simple metric can be misleadingly high. Cohen's kappa (${\\kappa}$) provides a more robust assessment by correcting for agreement that would be expected to occur purely by chance. This foundational exercise  will guide you through the process of computing kappa from first principles, helping you to build a solid understanding of the critical difference between observed agreement and chance-corrected agreement.",
            "id": "4917600",
            "problem": "A hospital quality study evaluates the inter-rater reliability (IRR) of two board-certified radiologists classifying computed tomography scans as either \"lesion present\" or \"lesion absent.\" Across a set of $200$ independent scans, the following joint outcomes were recorded:\n- Both radiologists recorded \"lesion present\" for $56$ scans.\n- Radiologist A recorded \"lesion present\" and Radiologist B recorded \"lesion absent\" for $24$ scans.\n- Radiologist A recorded \"lesion absent\" and Radiologist B recorded \"lesion present\" for $14$ scans.\n- Both radiologists recorded \"lesion absent\" for $106$ scans.\n\nUsing only fundamental definitions, proceed as follows:\n1. Define the observed proportion of agreement, denoted $P_{o}$, from the joint outcomes in the $2 \\times 2$ table.\n2. Under the assumption that each radiologist’s label assignment is statistically independent of the other’s (conditional on the case), derive the expected proportion of agreement $P_{e}$ from the marginal label probabilities.\n3. Construct a chance-corrected agreement index that is $0$ when $P_{o} = P_{e}$ and $1$ when $P_{o} = 1$, and use it to compute Cohen’s kappa $\\kappa$.\n\nCompute the raw agreement $P_{o}$ as a decimal and briefly compare it to the chance-corrected agreement embodied in $\\kappa$ to illustrate the role of chance correction. Round your final value of Cohen’s $\\kappa$ to four significant figures. Provide only the final numerical value of $\\kappa$ as your answer.",
            "solution": "The goal is to quantify agreement between two raters beyond chance. The foundational quantities for a $2 \\times 2$ classification table are the observed proportion of agreement $P_{o}$ and the expected proportion of agreement $P_{e}$ under independence of rater assignments given the marginal label probabilities.\n\nFirst, we compute the observed proportion of agreement $P_{o}$. Agreement occurs when both raters assign the same label. Let the total number of cases be $N$. From the data, the diagonal counts are $56$ (both \"lesion present\") and $106$ (both \"lesion absent\"), with $N = 200$. Therefore,\n$$\nP_{o} \\equiv \\frac{\\text{number of agreements}}{N} = \\frac{56 + 106}{200} = \\frac{162}{200} = 0.81.\n$$\n\nSecond, we derive the expected proportion of agreement $P_{e}$ under the assumption that the two raters’ label assignments are statistically independent, conditional on the case. Under independence, the probability that both assign \"lesion present\" equals the product of their marginal probabilities of assigning \"lesion present\"; similarly for \"lesion absent.\"\n\nCompute the marginal probabilities:\n- Radiologist A: \"present\" total is $56 + 24 = 80$, so $P(\\text{A present}) = \\frac{80}{200} = 0.4$; \"absent\" total is $14 + 106 = 120$, so $P(\\text{A absent}) = \\frac{120}{200} = 0.6$.\n- Radiologist B: \"present\" total is $56 + 14 = 70$, so $P(\\text{B present}) = \\frac{70}{200} = 0.35$; \"absent\" total is $24 + 106 = 130$, so $P(\\text{B absent}) = \\frac{130}{200} = 0.65$.\n\nUnder independence,\n$$\nP_{e} \\equiv P(\\text{both present}) + P(\\text{both absent}) \n= \\left(\\frac{80}{200}\\right)\\left(\\frac{70}{200}\\right) + \\left(\\frac{120}{200}\\right)\\left(\\frac{130}{200}\\right)\n= (0.4)(0.35) + (0.6)(0.65)\n= 0.14 + 0.39\n= 0.53.\n$$\n\nThird, we construct a chance-corrected agreement index that satisfies two properties:\n- It equals $0$ when observed agreement equals expected agreement, $P_{o} = P_{e}$.\n- It equals $1$ when observed agreement is perfect, $P_{o} = 1$.\n\nLet the above-chance agreement be $P_{o} - P_{e}$. The maximum attainable above-chance agreement is $1 - P_{e}$ (since $P_{o}$ cannot exceed $1$). A natural normalization is to divide by this maximum, yielding\n$$\n\\kappa \\equiv \\frac{P_{o} - P_{e}}{1 - P_{e}}.\n$$\nThis quantity is known as Cohen’s kappa.\n\nSubstitute the computed values:\n$$\n\\kappa = \\frac{0.81 - 0.53}{1 - 0.53} = \\frac{0.28}{0.47} \\approx 0.5957446809\\ldots\n$$\nRounded to four significant figures, \n$$\n\\kappa \\approx 0.5957.\n$$\n\nInterpretation and comparison to raw agreement: The raw observed agreement is $P_{o} = 0.81$, but a substantial portion of this agreement is attributable to chance under the observed marginals, with $P_{e} = 0.53$. Cohen’s $\\kappa \\approx 0.5957$ quantifies the proportion of the potential agreement beyond chance that was actually achieved, demonstrating how chance correction yields a lower value than the raw agreement when marginal label distributions are imbalanced or when chance agreement is high.",
            "answer": "$$\\boxed{0.5957}$$"
        },
        {
            "introduction": "While kappa is a powerful tool, its interpretation requires careful consideration of the context, especially when dealing with outcomes that are very rare or very common. This problem  delves into a counter-intuitive phenomenon known as the \"kappa paradox,\" where high raw agreement can paradoxically lead to a low kappa value. By analyzing a diagnostic scenario with a rare disease, you will quantify how skewed category distributions can inflate the level of chance agreement, thereby developing a more nuanced and critical approach to interpreting reliability statistics.",
            "id": "4917670",
            "problem": "A diagnostic study investigates agreement between two independent raters classifying the presence of a rare disease (binary outcome: Positive/Negative) on a cohort of $N=200$ subjects. The joint classifications are as follows:\n- Both raters say Positive: $1$\n- Rater A says Positive and Rater B says Negative: $5$\n- Rater A says Negative and Rater B says Positive: $3$\n- Both raters say Negative: $191$\n\nThese counts imply highly skewed marginal distributions for the Positive category. Using only foundational definitions of observed agreement and of chance agreement under independence derived from the marginal distributions, compute the inter-rater agreement coefficient known as Cohen’s kappa, then quantify the discrepancy between the observed agreement and kappa by the scalar\n$$\\Delta = p_o - \\kappa,$$\nwhere $p_o$ is the observed agreement probability and $\\kappa$ is Cohen’s kappa. Round your final value of $\\Delta$ to four significant figures. Report only the value of $\\Delta$ with no units or additional text.",
            "solution": "The problem is first validated for scientific soundness, completeness, and clarity. The problem statement provides all necessary data for the calculation of Cohen's kappa coefficient: the total number of subjects, $N$, and the full breakdown of joint classifications by two raters in a $2 \\times 2$ contingency table format. The definitions and required calculations are standard in the field of biostatistics for assessing inter-rater reliability. The problem is well-posed, scientifically grounded, and contains no ambiguities or contradictions. Therefore, it is deemed valid, and a solution can be constructed.\n\nThe problem requires the computation of the discrepancy, $\\Delta$, between the observed agreement probability, $p_o$, and Cohen's kappa coefficient, $\\kappa$. We begin by organizing the given data into a standard $2 \\times 2$ contingency table. Let the two outcomes be 'Positive' (Pos) and 'Negative' (Neg).\n\nThe counts are as follows:\n- Cell $a$: Rater A classifies as Pos, Rater B classifies as Pos. $a = 1$.\n- Cell $b$: Rater A classifies as Pos, Rater B classifies as Neg. $b = 5$.\n- Cell $c$: Rater A classifies as Neg, Rater B classifies as Pos. $c = 3$.\n- Cell $d$: Rater A classifies as Neg, Rater B classifies as Neg. $d = 191$.\n\nThe total number of subjects is $N = a + b + c + d = 1 + 5 + 3 + 191 = 200$.\n\nThe contingency table is:\n$$\n\\begin{array}{c|cc|c}\n & \\text{Rater B: Pos} & \\text{Rater B: Neg} & \\text{Total} \\\\\n\\hline\n\\text{Rater A: Pos} & a = 1 & b = 5 & a+b = 6 \\\\\n\\text{Rater A: Neg} & c = 3 & d = 191 & c+d = 194 \\\\\n\\hline\n\\text{Total} & a+c = 4 & b+d = 196 & N = 200\n\\end{array}\n$$\n\nFirst, we calculate the observed proportional agreement, $p_o$. This is the sum of the proportions of cases where both raters agreed. Agreement occurs in cells $a$ (both Positive) and $d$ (both Negative).\n$$\np_o = \\frac{a + d}{N}\n$$\nSubstituting the given values:\n$$\np_o = \\frac{1 + 191}{200} = \\frac{192}{200} = 0.96\n$$\n\nNext, we calculate the expected probability of agreement by chance, $p_e$. This is calculated based on the marginal totals, under the assumption of statistical independence between the two raters' judgments. The probability of both raters classifying a subject as Positive by chance is the product of their individual probabilities of classifying as Positive. Similarly for the Negative classification.\n\nThe probability that Rater A classifies as Positive is $P_{A,Pos} = \\frac{a+b}{N} = \\frac{6}{200} = 0.03$.\nThe probability that Rater A classifies as Negative is $P_{A,Neg} = \\frac{c+d}{N} = \\frac{194}{200} = 0.97$.\n\nThe probability that Rater B classifies as Positive is $P_{B,Pos} = \\frac{a+c}{N} = \\frac{4}{200} = 0.02$.\nThe probability that Rater B classifies as Negative is $P_{B,Neg} = \\frac{b+d}{N} = \\frac{196}{200} = 0.98$.\n\nThe probability of chance agreement on 'Positive' is $P_{\\text{chance,Pos}} = P_{A,Pos} \\times P_{B,Pos}$.\nThe probability of chance agreement on 'Negative' is $P_{\\text{chance,Neg}} = P_{A,Neg} \\times P_{B,Neg}$.\n\nThe total expected chance agreement, $p_e$, is the sum of these probabilities:\n$$\np_e = (P_{A,Pos} \\times P_{B,Pos}) + (P_{A,Neg} \\times P_{B,Neg})\n$$\n$$\np_e = \\left(\\frac{a+b}{N}\\right)\\left(\\frac{a+c}{N}\\right) + \\left(\\frac{c+d}{N}\\right)\\left(\\frac{b+d}{N}\\right)\n$$\nSubstituting the numerical values:\n$$\np_e = \\left(\\frac{6}{200}\\right)\\left(\\frac{4}{200}\\right) + \\left(\\frac{194}{200}\\right)\\left(\\frac{196}{200}\\right)\n$$\n$$\np_e = (0.03)(0.02) + (0.97)(0.98) = 0.0006 + 0.9506 = 0.9512\n$$\n\nNow, we compute Cohen's kappa coefficient, $\\kappa$, which measures the agreement corrected for chance. The formula is:\n$$\n\\kappa = \\frac{p_o - p_e}{1 - p_e}\n$$\nSubstituting the calculated values of $p_o$ and $p_e$:\n$$\n\\kappa = \\frac{0.96 - 0.9512}{1 - 0.9512} = \\frac{0.0088}{0.0488}\n$$\n$$\n\\kappa \\approx 0.180327868...\n$$\n\nFinally, we compute the required discrepancy, $\\Delta$, defined as $\\Delta = p_o - \\kappa$.\n$$\n\\Delta = 0.96 - 0.180327868...\n$$\n$$\n\\Delta \\approx 0.779672131...\n$$\n\nThe problem requires rounding the final value of $\\Delta$ to four significant figures.\nThe value is $\\Delta \\approx 0.779672131...$. The first four significant figures are $7, 7, 9, 6$. The fifth significant figure is $7$, which is $5$ or greater, so we round up the fourth digit.\n$$\n\\Delta \\approx 0.7797\n$$\nThis result highlights the \"kappa paradox,\" where a high observed agreement ($p_o = 0.96$) can be accompanied by a low kappa value ($\\kappa \\approx 0.18$) due to highly skewed marginal distributions, which produce a high probability of chance agreement ($p_e \\approx 0.95$). The discrepancy $\\Delta$ is large, indicating that most of the observed agreement is attributable to chance under the model's assumptions.",
            "answer": "$$\n\\boxed{0.7797}\n$$"
        },
        {
            "introduction": "Reliability statistics are not just for evaluating past performance; they are essential tools for prospectively designing efficient and effective studies. This advanced practice problem  introduces Generalizability Theory, a flexible framework that allows researchers to pinpoint and quantify multiple sources of measurement error simultaneously. You will step into the role of a study designer, using variance estimates from a pilot study to forecast how reliability will change with varying numbers of raters and occasions, ultimately optimizing the future study's design to maximize reliability within a fixed budget.",
            "id": "4917664",
            "problem": "A biostatistics team is planning a study to assess a clinical severity score for patients using multiple raters on multiple occasions. The facets are raters and occasions, both treated as random and exchangeable. A fully crossed Generalizability Theory (GT) design is envisioned where each person is rated by $n_r$ raters on $n_o$ occasions, and the reliability of interest is for the relative ranking of persons based on their mean score across raters and occasions (inter-rater and intra-rater reliability combined).\n\nFrom a prior Generalizability (G) study with $n_r = 4$ raters and $n_o = 2$ occasions, variance components were estimated under a random-effects model:\n- Person variance: $\\sigma_{p}^{2} = 18$.\n- Rater variance: $\\sigma_{r}^{2} = 1.5$.\n- Occasion variance: $\\sigma_{o}^{2} = 2.0$.\n- Rater-by-occasion variance: $\\sigma_{ro}^{2} = 0.5$.\n- Person-by-rater variance: $\\sigma_{pr}^{2} = 6$.\n- Person-by-occasion variance: $\\sigma_{po}^{2} = 9$.\n- Person-by-rater-by-occasion plus residual variance: $\\sigma_{pro,e}^{2} = 12$.\n\nAssume $n_r$ and $n_o$ are positive integers. The study cost per additional rater per person is $c_{r} = 100$, the cost per additional occasion per person is $c_{o} = 80$, and the available per-person budget is $B = 640$.\n\nUsing core definitions from Generalizability Theory (GT), derive from first principles the predicted reliability for relative decisions (the generalizability coefficient for relative decisions) of the person mean across $n_r$ raters and $n_o$ occasions as a function of $n_r$ and $n_o$. Then, under the budget constraint $c_{r} n_{r} + c_{o} n_{o} \\leq B$, determine the design that maximizes this predicted reliability among all admissible integer pairs $(n_r, n_o)$, and report the maximal predicted value of the generalizability coefficient. Express your final result as a decimal and round your answer to four significant figures. No units are required.",
            "solution": "The user wants to find the optimal study design $(n_r, n_o)$ that maximizes the generalizability coefficient for relative decisions under a budget constraint, and to report this maximum value.\n\n### Step 1: Extract Givens\nThe problem provides the following information:\n- The study design is a fully crossed $p \\times r \\times o$ (person by rater by occasion) random-effects model.\n- Variance components from a prior G-study:\n    - Person variance: $\\sigma_{p}^{2} = 18$.\n    - Rater variance: $\\sigma_{r}^{2} = 1.5$.\n    - Occasion variance: $\\sigma_{o}^{2} = 2.0$.\n    - Rater-by-occasion variance: $\\sigma_{ro}^{2} = 0.5$.\n    - Person-by-rater variance: $\\sigma_{pr}^{2} = 6$.\n    - Person-by-occasion variance: $\\sigma_{po}^{2} = 9$.\n    - Person-by-rater-by-occasion plus residual variance: $\\sigma_{pro,e}^{2} = 12$.\n- D-study (decision study) parameters:\n    - Number of raters: $n_r$.\n    - Number of occasions: $n_o$.\n    - $n_r$ and $n_o$ must be positive integers.\n- Cost and budget constraints:\n    - Cost per rater per person: $c_{r} = 100$.\n    - Cost per occasion per person: $c_{o} = 80$.\n    - Total available budget per person: $B = 640$.\n\n### Step 2: Validate Using Extracted Givens\n1.  **Scientific or Factual Soundness**: The problem is grounded in Generalizability Theory (GT), a well-established statistical framework for assessing reliability. The model ($p \\times r \\times o$ random effects), the concept of variance components, and the use of a G-study to inform a D-study optimization are all standard and correct applications of GT. The provided variance components are non-negative, as required. The problem is scientifically sound.\n2.  **Well-Posed**: The problem asks to derive an expression for the reliability (the generalizability coefficient) and then maximize it subject to a linear inequality constraint. The variables to be optimized, $n_r$ and $n_o$, are restricted to be positive integers, which makes the feasible set finite and non-empty. An optimal solution is guaranteed to exist.\n3.  **Objective**: The problem is stated in precise, objective language using standard terminology from biostatistics and GT. There are no subjective or ambiguous statements.\n4.  **Completeness**: All necessary information (variance components for the reliability formula, cost parameters, and budget for the constraint) is provided.\n\n### Step 3: Verdict and Action\nThe problem is valid as it is scientifically grounded, well-posed, objective, and complete. I will proceed with a full solution.\n\n### Derivation of the Generalizability Coefficient\nIn Generalizability Theory, the reliability of relative decisions is quantified by the generalizability coefficient, denoted $E\\rho^2$. It is defined as the ratio of the universe score variance to the expected observed score variance. For a relative decision, this is equivalent to the ratio of universe score variance to the sum of universe score variance and relative error variance.\n\nThe universe score variance is the variance of the object of measurement, which in this case is the person. Thus, the universe score variance is $\\sigma_{p}^{2}$.\n$$ \\sigma_{\\text{universe}}^2 = \\sigma_p^2 $$\n\nThe relative error variance, $\\sigma_{\\delta}^2$, for a D-study with $n_r$ raters and $n_o$ occasions is composed of the variance components corresponding to interactions with the person facet, scaled by the number of conditions sampled for the other facets. The sources of error that affect the relative ranking of persons are those involving interaction with the person facet ($p$).\n$$ \\sigma_{\\delta}^2 = \\frac{\\sigma_{pr}^{2}}{n_r} + \\frac{\\sigma_{po}^{2}}{n_o} + \\frac{\\sigma_{pro,e}^{2}}{n_r n_o} $$\nThe main effects of rater ($\\sigma_r^2$), occasion ($\\sigma_o^2$), and their interaction ($\\sigma_{ro}^2$) do not contribute to the relative error variance because they affect all persons equally, thus not altering their relative scores.\n\nThe generalizability coefficient for relative decisions, which we denote as $G(n_r, n_o)$, is therefore:\n$$ G(n_r, n_o) = \\frac{\\sigma_p^2}{\\sigma_p^2 + \\sigma_{\\delta}^2} = \\frac{\\sigma_p^2}{\\sigma_p^2 + \\frac{\\sigma_{pr}^2}{n_r} + \\frac{\\sigma_{po}^2}{n_o} + \\frac{\\sigma_{pro,e}^2}{n_r n_o}} $$\nSubstituting the given variance components:\n$$ G(n_r, n_o) = \\frac{18}{18 + \\frac{6}{n_r} + \\frac{9}{n_o} + \\frac{12}{n_r n_o}} $$\n\n### Optimization under Budget Constraint\nThe goal is to maximize $G(n_r, n_o)$ subject to the budget constraint and integer conditions.\nThe budget constraint is:\n$$ c_r n_r + c_o n_o \\le B $$\nSubstituting the given values:\n$$ 100 n_r + 80 n_o \\le 640 $$\nDividing by $20$ simplifies the inequality to:\n$$ 5 n_r + 4 n_o \\le 32 $$\nWe also have the constraints that $n_r$ and $n_o$ are positive integers, i.e., $n_r \\ge 1$ and $n_o \\ge 1$.\n\nTo maximize $G(n_r, n_o)$, we must minimize its denominator, which is equivalent to minimizing the relative error term:\n$$ E(n_r, n_o) = \\frac{6}{n_r} + \\frac{9}{n_o} + \\frac{12}{n_r n_o} $$\nSince $E(n_r, n_o)$ is a decreasing function of both $n_r$ and $n_o$, the optimal solution will lie on the upper-right boundary of the feasible region defined by the constraints. We can find all admissible integer pairs $(n_r, n_o)$ satisfying $5n_r + 4n_o \\le 32$ where $n_r \\ge 1, n_o \\ge 1$, and then evaluate $E(n_r, n_o)$ for each to find the minimum.\n\nLet's enumerate the feasible pairs:\n- If $n_r = 1$: $5(1) + 4n_o \\le 32 \\implies 4n_o \\le 27 \\implies n_o \\le 6.75$. Feasible $n_o \\in \\{1, 2, 3, 4, 5, 6\\}$.\n- If $n_r = 2$: $5(2) + 4n_o \\le 32 \\implies 4n_o \\le 22 \\implies n_o \\le 5.5$. Feasible $n_o \\in \\{1, 2, 3, 4, 5\\}$.\n- If $n_r = 3$: $5(3) + 4n_o \\le 32 \\implies 4n_o \\le 17 \\implies n_o \\le 4.25$. Feasible $n_o \\in \\{1, 2, 3, 4\\}$.\n- If $n_r = 4$: $5(4) + 4n_o \\le 32 \\implies 4n_o \\le 12 \\implies n_o \\le 3$. Feasible $n_o \\in \\{1, 2, 3\\}$.\n- If $n_r = 5$: $5(5) + 4n_o \\le 32 \\implies 4n_o \\le 7 \\implies n_o \\le 1.75$. Feasible $n_o \\in \\{1\\}$.\n- If $n_r = 6$: $5(6) + 4n_o \\le 32 \\implies 4n_o \\le 2 \\implies n_o \\le 0.5$. No feasible $n_o \\ge 1$.\n\nNow, we calculate the error term $E(n_r, n_o)$ for the pairs along the \"northeast\" boundary of this feasible set, as these are the most likely candidates for minimizing the error.\n- For $(n_r, n_o) = (1, 6)$: $E(1, 6) = \\frac{6}{1} + \\frac{9}{6} + \\frac{12}{1 \\cdot 6} = 6 + 1.5 + 2 = 9.5$.\n- For $(n_r, n_o) = (2, 5)$: $E(2, 5) = \\frac{6}{2} + \\frac{9}{5} + \\frac{12}{2 \\cdot 5} = 3 + 1.8 + 1.2 = 6.0$.\n- For $(n_r, n_o) = (3, 4)$: $E(3, 4) = \\frac{6}{3} + \\frac{9}{4} + \\frac{12}{3 \\cdot 4} = 2 + 2.25 + 1 = 5.25$.\n- For $(n_r, n_o) = (4, 3)$: $E(4, 3) = \\frac{6}{4} + \\frac{9}{3} + \\frac{12}{4 \\cdot 3} = 1.5 + 3 + 1 = 5.5$.\n- For $(n_r, n_o) = (5, 1)$: $E(5, 1) = \\frac{6}{5} + \\frac{9}{1} + \\frac{12}{5 \\cdot 1} = 1.2 + 9 + 2.4 = 12.6$.\n\nComparing the values of $E(n_r, n_o)$, the minimum value is $5.25$, which occurs for the design $(n_r, n_o) = (3, 4)$. This design uses a budget of $100(3) + 80(4) = 300 + 320 = 620$, which is within the allowed budget of $640$. Any other feasible pair not on this boundary will have smaller $n_r$ and/or $n_o$ values and thus a larger error term $E$. For example, $E(3,3) = \\frac{6}{3} + \\frac{9}{3} + \\frac{12}{9} \\approx 2+3+1.33 = 6.33 > 5.25$.\n\nThe optimal design is $n_r = 3$ raters and $n_o = 4$ occasions.\n\n### Calculation of Maximal Predicted Reliability\nWe now calculate the maximal generalizability coefficient using the optimal design $(3, 4)$ and the minimum error value $E(3, 4) = 5.25$.\n$$ G_{\\text{max}} = G(3, 4) = \\frac{18}{18 + E(3, 4)} = \\frac{18}{18 + 5.25} = \\frac{18}{23.25} $$\n$$ G_{\\text{max}} \\approx 0.774193548... $$\nRounding the result to four significant figures, we get $0.7742$.",
            "answer": "$$\n\\boxed{0.7742}\n$$"
        }
    ]
}