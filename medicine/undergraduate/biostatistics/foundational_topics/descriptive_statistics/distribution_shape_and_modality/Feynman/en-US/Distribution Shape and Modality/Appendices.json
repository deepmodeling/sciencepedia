{
    "hands_on_practices": [
        {
            "introduction": "Understanding the central tendency of a distribution is fundamental, and the mode represents its most frequent value or peak. This exercise provides foundational practice in using calculus to derive the mode of a continuous probability distribution from its probability density function (PDF). By analyzing the versatile Gamma distribution, you will see how its shape and modality are directly controlled by its parameters. ",
            "id": "4909555",
            "problem": "A biostatistician models a positive-valued biomarker by a Gamma distribution with shape parameter $\\alpha>0$ and scale parameter $\\theta>0$. The Gamma probability density function (probability density function (PDF)) is defined for $x>0$ by\n$$\nf(x;\\alpha,\\theta)=\\frac{x^{\\alpha-1}\\exp(-x/\\theta)}{\\Gamma(\\alpha)\\,\\theta^{\\alpha}}.\n$$\nStarting from the fundamental definition of the mode as the value of $x$ that maximizes the PDF over its domain, derive the location of the mode as a function of $\\alpha$ and $\\theta$ by first principles. Then use your derivation to classify the distribution’s modality when $\\alpha\\leq 1$ compared to when $\\alpha>1$.\n\nProvide the final answer as a single closed-form analytic expression giving the mode $m(\\alpha,\\theta)$ in terms of $\\alpha$ and $\\theta$, written piecewise over the regimes $\\alpha\\leq 1$ and $\\alpha>1$. No numerical rounding is required, and no units should be included in the final expression.",
            "solution": "The problem statement is evaluated to be valid. It is scientifically grounded in probability theory, well-posed, and objective. It presents a standard problem in mathematical statistics without any factual unsoundness, ambiguity, or contradiction.\n\nThe objective is to find the mode of a Gamma distribution, which is the value of the random variable $x$ that maximizes the probability density function (PDF). The domain of the biomarker is given as positive, so we are seeking the maximum of $f(x;\\alpha,\\theta)$ for $x \\in (0, \\infty)$. The PDF is given by:\n$$\nf(x;\\alpha,\\theta)=\\frac{x^{\\alpha-1}\\exp(-x/\\theta)}{\\Gamma(\\alpha)\\,\\theta^{\\alpha}}\n$$\nwhere the shape parameter $\\alpha > 0$ and the scale parameter $\\theta > 0$.\n\nTo find the maximum of $f(x;\\alpha,\\theta)$, it is often more convenient to find the maximum of its natural logarithm, $\\ln(f(x;\\alpha,\\theta))$, since the logarithm is a strictly increasing function. Maximizing $\\ln(f(x))$ will yield the same value of $x$ that maximizes $f(x)$. Let $L(x) = \\ln(f(x;\\alpha,\\theta))$.\n$$\nL(x) = \\ln\\left(\\frac{x^{\\alpha-1}\\exp(-x/\\theta)}{\\Gamma(\\alpha)\\,\\theta^{\\alpha}}\\right)\n$$\nUsing the properties of logarithms, we can expand this expression:\n$$\nL(x) = (\\alpha-1)\\ln(x) - \\frac{x}{\\theta} - \\ln(\\Gamma(\\alpha)) - \\alpha\\ln(\\theta)\n$$\nThe terms $-\\ln(\\Gamma(\\alpha)) - \\alpha\\ln(\\theta)$ are constants with respect to $x$. To find the value of $x$ that maximizes $L(x)$, we take the first derivative of $L(x)$ with respect to $x$ and set it to zero.\n$$\n\\frac{dL}{dx} = \\frac{d}{dx}\\left( (\\alpha-1)\\ln(x) - \\frac{x}{\\theta} - \\text{constant} \\right) = \\frac{\\alpha-1}{x} - \\frac{1}{\\theta}\n$$\nSetting the derivative equal to zero gives the location of any critical points in the domain $x>0$:\n$$\n\\frac{\\alpha-1}{x} - \\frac{1}{\\theta} = 0\n$$\n$$\n\\frac{\\alpha-1}{x} = \\frac{1}{\\theta}\n$$\nIf $\\alpha-1 \\neq 0$, we can solve for $x$:\n$$\nx = \\theta(\\alpha-1)\n$$\nThis critical point is only physically meaningful if it lies within the domain of the distribution, which requires $x > 0$. Since $\\theta > 0$, this condition is met if and only if $\\alpha-1 > 0$, or $\\alpha > 1$.\n\nNow, we must determine if this critical point corresponds to a maximum, a minimum, or a saddle point. We use the second derivative test. The second derivative of $L(x)$ with respect to $x$ is:\n$$\n\\frac{d^2L}{dx^2} = \\frac{d}{dx}\\left( (\\alpha-1)x^{-1} - \\frac{1}{\\theta} \\right) = -(\\alpha-1)x^{-2} = -\\frac{\\alpha-1}{x^2}\n$$\nFor the critical point to be a local maximum, the second derivative evaluated at that point must be negative. Given that $x^2$ is always positive for $x > 0$, the sign of the second derivative is determined by the sign of $-(\\alpha-1)$.\nIf $\\alpha > 1$, then $\\alpha-1 > 0$, and $\\frac{d^2L}{dx^2} = -\\frac{\\alpha-1}{x^2} < 0$.\nThis confirms that for $\\alpha > 1$, the function has a unique local maximum at $x = \\theta(\\alpha-1)$. Since this is the only critical point in the domain $(0, \\infty)$ and the function $f(x)$ approaches $0$ as $x \\to 0^+$ (since $\\alpha-1 > 0$) and as $x \\to \\infty$, this local maximum is the global maximum.\nTherefore, for $\\alpha > 1$, the mode of the distribution is $m = \\theta(\\alpha-1)$. The distribution is unimodal with its peak located in the interior of its support.\n\nNext, we must analyze the cases where $\\alpha \\leq 1$.\n\nCase 1: $\\alpha = 1$.\nIn this case, the first derivative of the log-PDF is:\n$$\n\\frac{dL}{dx} = \\frac{1-1}{x} - \\frac{1}{\\theta} = -\\frac{1}{\\theta}\n$$\nSince $\\theta > 0$, the derivative $\\frac{dL}{dx}$ is a negative constant for all $x > 0$. This implies that the function $L(x)$ (and thus $f(x)$) is strictly decreasing over its entire domain $(0, \\infty)$. For a function that is strictly decreasing on $(0, \\infty)$, the maximum value is approached as $x$ approaches the left boundary of the domain, $x \\to 0^+$. Thus, the mode is located at $x=0$. In this case, the Gamma distribution simplifies to the Exponential distribution, which is known to have its mode at $x=0$.\n\nCase 2: $0 < \\alpha < 1$.\nIn this case, the term $\\alpha-1$ is negative. The first derivative is:\n$$\n\\frac{dL}{dx} = \\frac{\\alpha-1}{x} - \\frac{1}{\\theta}\n$$\nSince $\\alpha-1 < 0$, $x > 0$, and $\\theta > 0$, both terms $\\frac{\\alpha-1}{x}$ and $-\\frac{1}{\\theta}$ are negative. Their sum is therefore always negative for all $x \\in (0, \\infty)$.\n$$\n\\frac{dL}{dx} < 0 \\quad \\text{for all } x>0\n$$\nAs in the case where $\\alpha=1$, the function $f(x)$ is strictly decreasing over its entire domain. The maximum is again approached as $x \\to 0^+$. The mode is therefore located at $x=0$. In this regime, the PDF has a vertical asymptote at $x=0$, as $x^{\\alpha-1} \\to \\infty$ when $x \\to 0^+$ for $\\alpha < 1$.\n\nIn summary, we can classify the modality based on the value of $\\alpha$:\n- If $\\alpha > 1$, the distribution is unimodal with a unique mode at $m = \\theta(\\alpha-1)$. The PDF starts at $0$, rises to a peak, and then decays.\n- If $0 < \\alpha \\leq 1$, the PDF is strictly decreasing from its maximum value (or supremum) at $x=0$. The mode is at $m=0$. This includes the exponential distribution ($\\alpha=1$) and other J-shaped distributions.\n\nCombining these results, we can write the location of the mode, $m(\\alpha, \\theta)$, as a piecewise function of the parameters $\\alpha$ and $\\theta$:\n$$\nm(\\alpha, \\theta) = \\begin{cases} \\theta(\\alpha-1) & \\text{if } \\alpha > 1 \\\\ 0 & \\text{if } 0 < \\alpha \\leq 1 \\end{cases}\n$$\nThis expression provides the complete solution as requested.",
            "answer": "$$\n\\boxed{\n\\begin{cases}\n\\theta(\\alpha-1) & \\text{if } \\alpha > 1 \\\\\n0 & \\text{if } 0 < \\alpha \\leq 1\n\\end{cases}\n}\n$$"
        },
        {
            "introduction": "While many classic distributions have modes that can be found with simple algebra, modern statistical models often require more advanced techniques. This practice introduces the skew-normal distribution, a flexible model for asymmetric data, where finding the mode involves a combination of calculus and numerical methods. You will learn to set up the necessary equation and then use computational tools to solve for the peak of the distribution. ",
            "id": "4909546",
            "problem": "Consider the skew-normal distribution with location parameter $\\mu \\in \\mathbb{R}$, scale parameter $\\sigma \\in (0,\\infty)$, and skewness parameter $\\lambda \\in \\mathbb{R}$. Its probability density function (PDF) is defined as\n$$\nf(x;\\mu,\\sigma,\\lambda) \\;=\\; \\frac{2}{\\sigma}\\,\\varphi\\!\\left(\\frac{x-\\mu}{\\sigma}\\right)\\,\\Phi\\!\\left(\\lambda\\,\\frac{x-\\mu}{\\sigma}\\right),\n$$\nwhere $\\varphi(z) = \\frac{1}{\\sqrt{2\\pi}}\\,\\exp\\!\\left(-\\frac{z^2}{2}\\right)$ is the standard normal PDF and $\\Phi(z) = \\int_{-\\infty}^{z} \\varphi(t)\\,dt$ is the standard normal cumulative distribution function (CDF). Starting from the definitions of $\\varphi$ and $\\Phi$, and the fundamental principle that the mode of a continuous distribution occurs at a stationary point of its PDF, your tasks are:\n- Explain the distribution’s modality under the transformation $z = \\frac{x-\\mu}{\\sigma}$ and the behavior of the first derivative $f'(x)$.\n- Derive conditions on the skewness parameter $\\lambda$ that guarantee unimodality solely from properties of $\\varphi$ and $\\Phi$ (do not invoke any pre-packaged results about the skew-normal distribution).\n- Compute the mode numerically by solving the first-derivative equation $f'(x)=0$.\n\nYou must implement a program that, for each parameter set in the test suite below, computes the mode by numerically solving $f'(x)=0$ with respect to $x$ and returns the mode in the original scale. You must not assume any closed-form expression for the mode.\n\nUse the following test suite of parameter triples $(\\mu,\\sigma,\\lambda)$:\n- Case $1$: $(\\mu,\\sigma,\\lambda) = (0,1,0)$.\n- Case $2$: $(\\mu,\\sigma,\\lambda) = (0,1,3)$.\n- Case $3$: $(\\mu,\\sigma,\\lambda) = (2,0.5,-2)$.\n- Case $4$: $(\\mu,\\sigma,\\lambda) = (10,2,5)$.\n- Case $5$: $(\\mu,\\sigma,\\lambda) = (0,1,-7)$.\n\nDesign your numerical procedure using only the first derivative condition, with adequate safeguards for convergence. Express all results as real numbers rounded to $6$ decimal places.\n\nFinal output format requirement: Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, in the order of the test suite, for example, $[m_1,m_2,m_3,m_4,m_5]$, where each $m_i$ is the computed mode rounded to $6$ decimal places.",
            "solution": "The problem requires an analysis of the modality of the skew-normal distribution and a numerical computation of its mode for several parameter sets. The validation and solution process are as follows.\n\n### **Problem Validation**\n\n**Step 1: Extract Givens**\n- **Distribution:** Skew-normal distribution.\n- **Parameters:** Location $\\mu \\in \\mathbb{R}$, scale $\\sigma \\in (0,\\infty)$, skewness $\\lambda \\in \\mathbb{R}$.\n- **Probability Density Function (PDF):**\n$$ f(x;\\mu,\\sigma,\\lambda) \\;=\\; \\frac{2}{\\sigma}\\,\\varphi\\!\\left(\\frac{x-\\mu}{\\sigma}\\right)\\,\\Phi\\!\\left(\\lambda\\,\\frac{x-\\mu}{\\sigma}\\right) $$\n- **Component Functions:**\n    - Standard normal PDF: $\\varphi(z) = \\frac{1}{\\sqrt{2\\pi}}\\,\\exp\\!\\left(-\\frac{z^2}{2}\\right)$.\n    - Standard normal CDF: $\\Phi(z) = \\int_{-\\infty}^{z} \\varphi(t)\\,dt$.\n- **Core Principle:** The mode of a continuous distribution occurs at a stationary point of its PDF, where the first derivative is zero ($f'(x) = 0$).\n- **Transformation:** $z = \\frac{x-\\mu}{\\sigma}$.\n- **Tasks:**\n    1. Explain modality using the transformation and the first derivative $f'(x)$.\n    2. Derive conditions on $\\lambda$ that guarantee unimodality.\n    3. Numerically compute the mode by solving $f'(x)=0$ for the given test cases.\n- **Test Suite:**\n    - Case $1$: $(\\mu,\\sigma,\\lambda) = (0,1,0)$.\n    - Case $2$: $(\\mu,\\sigma,\\lambda) = (0,1,3)$.\n    - Case $3$: $(\\mu,\\sigma,\\lambda) = (2,0.5,-2)$.\n    - Case $4$: $(\\mu,\\sigma,\\lambda) = (10,2,5)$.\n    - Case $5$: $(\\mu,\\sigma,\\lambda) = (0,1,-7)$.\n\n**Step 2: Validate Using Extracted Givens**\n- **Scientific Grounding:** The problem is scientifically and mathematically sound. The skew-normal distribution is a well-established probability distribution in statistics. The definitions of the normal PDF and CDF are correct, and the principle of finding a mode via the first derivative is a fundamental concept in calculus.\n- **Well-Posedness:** The problem is well-posed. It asks for the derivation of an equation for the mode and its numerical solution. As will be shown, the skew-normal distribution is unimodal for all values of its parameters, guaranteeing a unique solution for the mode.\n- **Objectivity:** The problem is stated in precise, objective mathematical language, free from ambiguity or subjective claims.\n\nAll validation criteria are met. The problem is free from the flaws listed in the instructions (e.g., scientific unsoundness, incompleteness, ambiguity).\n\n**Step 3: Verdict and Action**\nThe problem is valid. A complete solution will now be developed.\n\n### **Solution Derivation**\n\nThe mode of the distribution is the value of $x$ that maximizes the PDF $f(x;\\mu,\\sigma,\\lambda)$. This is equivalent to maximizing the logarithm of the PDF, $\\ln f(x)$, as the logarithm is a strictly monotonic function. Maximization involves finding the point(s) where the first derivative is zero.\n\n**1. Standardization and Log-PDF**\nTo simplify the analysis, we perform the suggested change of variables: $z = \\frac{x-\\mu}{\\sigma}$. The random variable $Z$ follows a standard skew-normal distribution (with $\\mu=0, \\sigma=1$). Its PDF, $g(z)$, is given by:\n$$ g(z) = \\sigma f(\\mu+\\sigma z, \\mu, \\sigma, \\lambda) = 2 \\varphi(z) \\Phi(\\lambda z) $$\nThe mode of $X$, denoted $x_m$, is related to the mode of $Z$, denoted $z_m$, by the linear transformation $x_m = \\mu + \\sigma z_m$. We can therefore find $z_m$ first.\n\nLet's work with the log-likelihood of the standardized PDF, $l(z) = \\ln g(z)$:\n$$ l(z) = \\ln(2) + \\ln(\\varphi(z)) + \\ln(\\Phi(\\lambda z)) $$\nSubstituting the definition of $\\varphi(z)$:\n$$ l(z) = \\ln(2) - \\frac{1}{2}\\ln(2\\pi) - \\frac{z^2}{2} + \\ln(\\Phi(\\lambda z)) $$\n\n**2. First Derivative and the Equation for the Mode**\nTo find the mode $z_m$, we differentiate $l(z)$ with respect to $z$ and set the result to zero. We use the chain rule and the facts that $\\frac{d}{dz}\\varphi(z) = -z\\varphi(z)$ and, by the Fundamental Theorem of Calculus, $\\frac{d}{du}\\Phi(u) = \\varphi(u)$.\n$$ l'(z) = \\frac{d}{dz} \\left( -\\frac{z^2}{2} + \\ln(\\Phi(\\lambda z)) \\right) = -z + \\frac{1}{\\Phi(\\lambda z)} \\cdot \\frac{d}{dz}(\\Phi(\\lambda z)) $$\n$$ l'(z) = -z + \\frac{1}{\\Phi(\\lambda z)} \\cdot \\varphi(\\lambda z) \\cdot \\lambda = -z + \\lambda \\frac{\\varphi(\\lambda z)}{\\Phi(\\lambda z)} $$\nSetting $l'(z_m) = 0$ gives the equation for the standardized mode $z_m$:\n$$ -z_m + \\lambda \\frac{\\varphi(\\lambda z_m)}{\\Phi(\\lambda z_m)} = 0 $$\nor equivalently, the equation to be solved numerically:\n$$ z_m \\Phi(\\lambda z_m) - \\lambda \\varphi(\\lambda z_m) = 0 $$\n\n**3. Modality Analysis**\nThe number of modes is the number of solutions to the equation $l'(z)=0$. A distribution is unimodal if this equation has exactly one solution. A sufficient condition for unimodality is that the log-PDF is strictly concave, i.e., $l''(z) < 0$ for all $z \\in \\mathbb{R}$.\n\nLet's compute the second derivative of $l(z)$:\n$$ l''(z) = \\frac{d}{dz} \\left( -z + \\lambda \\frac{\\varphi(\\lambda z)}{\\Phi(\\lambda z)} \\right) $$\nLet $r(u) = \\frac{\\varphi(u)}{\\Phi(u)}$. The equation is $l'(z) = -z + \\lambda r(\\lambda z)$. So, $l''(z) = -1 + \\lambda \\cdot [r'(\\lambda z) \\cdot \\lambda] = -1 + \\lambda^2 r'(\\lambda z)$.\nThe derivative of $r(u)$ is:\n$$ r'(u) = \\frac{\\varphi'(u)\\Phi(u) - \\varphi(u)\\varphi(u)}{(\\Phi(u))^2} = \\frac{-u\\varphi(u)\\Phi(u)-\\varphi(u)^2}{(\\Phi(u))^2} = -r(u)u - (r(u))^2 = -r(u)(u+r(u)) $$\nSubstituting this back into the expression for $l''(z)$:\n$$ l''(z) = -1 - \\lambda^2 r(\\lambda z)(\\lambda z + r(\\lambda z)) $$\nIt is a known, though non-trivial, property of the standard normal distribution that the function $u+r(u) = u + \\frac{\\varphi(u)}{\\Phi(u)}$ is strictly positive for all $u \\in \\mathbb{R}$. Since $\\lambda^2 \\ge 0$ and $r(\\lambda z) = \\frac{\\varphi(\\lambda z)}{\\Phi(\\lambda z)} > 0$, the entire term $\\lambda^2 r(\\lambda z)(\\lambda z + r(\\lambda z))$ is non-negative.\nTherefore:\n$$ l''(z) = -1 - (\\text{a non-negative term}) \\le -1 $$\nThis proves that $l''(z) < 0$ for all $z \\in \\mathbb{R}$ (unless $\\lambda=0$, where $l''(z)=-1$). The strict concavity of the log-PDF implies that there is a unique maximum.\nConsequently, the skew-normal distribution is **unimodal for all values of the skewness parameter $\\lambda \\in \\mathbb{R}$**. The condition guaranteeing unimodality is simply that $\\lambda$ be any real number.\n\n**4. Numerical Procedure**\nFor each parameter set $(\\mu, \\sigma, \\lambda)$, we must find the mode $x_m$.\n- If $\\lambda = 0$, the PDF simplifies to the normal distribution $f(x) = \\frac{1}{\\sigma\\sqrt{2\\pi}}e^{-(x-\\mu)^2/(2\\sigma^2)}$. The mode is equal to the mean, $x_m = \\mu$.\n- If $\\lambda \\ne 0$, we must numerically find the unique root $z_m$ of the equation $h(z, \\lambda) = z \\Phi(\\lambda z) - \\lambda \\varphi(\\lambda z) = 0$. We can use a root-finding algorithm, such as Brent's method, which is efficient and robust if provided with a bracket $[a, b]$ where $h(a)$ and $h(b)$ have opposite signs.\n    - We noted from $l'(z) = -z + \\lambda r(\\lambda z)$ that at the mode $z_m = \\lambda r(\\lambda z_m)$. Since $r(\\cdot) > 0$, the sign of $z_m$ is the same as the sign of $\\lambda$.\n    - A known bound for the standardized mode is $|z_m| < \\sqrt{2/\\pi} \\approx 0.798$. A search interval like $[-2, 2]$ is more than sufficient.\n- Once $z_m$ is found, the mode in the original scale is calculated as $x_m = \\mu + \\sigma z_m$.\n\nThe implementation will use `scipy.optimize.root_scalar` to solve for $z_m$ and `scipy.stats.norm` to provide the $\\varphi$ and $\\Phi$ functions.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.stats import norm\nfrom scipy.optimize import root_scalar\n\ndef solve():\n    \"\"\"\n    Computes the mode of the skew-normal distribution for several parameter sets.\n\n    The mode is found by numerically solving the equation derived from setting the\n    first derivative of the log-PDF to zero.\n    \"\"\"\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # (mu, sigma, lambda)\n        (0.0, 1.0, 0.0),\n        (0.0, 1.0, 3.0),\n        (2.0, 0.5, -2.0),\n        (10.0, 2.0, 5.0),\n        (0.0, 1.0, -7.0),\n    ]\n\n    results = []\n    for mu, sigma, lam in test_cases:\n        # Case 1: lambda = 0. The distribution is normal, mode = mean = mu.\n        if lam == 0.0:\n            x_mode = mu\n        else:\n            # For lambda != 0, we must find the root of h(z) = 0, where h(z)\n            # is derived from the derivative of the standardized log-PDF.\n            # h(z) = -z + lambda * phi(lambda*z) / Phi(lambda*z)\n            # We solve the equivalent form:\n            # -z * Phi(lambda*z) + lambda * phi(lambda*z) = 0\n            def h(z, lambda_val):\n                \"\"\"The function whose root is the standardized mode.\"\"\"\n                arg = lambda_val * z\n                # Using scipy's norm.cdf for Phi and norm.pdf for phi\n                return -z * norm.cdf(arg) + lambda_val * norm.pdf(arg)\n\n            # A robust search bracket for the root z_m. The standardized mode\n            # z_m has the same sign as lambda and is known to be bounded,\n            # |z_m|  sqrt(2/pi) approx 0.8. A bracket of [-2, 2] is safe.\n            # We can use a tighter bracket based on the sign of lambda.\n            if lam > 0:\n                bracket = [0.0, 2.0]\n            else: # lam  0\n                bracket = [-2.0, 0.0]\n\n            # Use SciPy's root_scalar to find the standardized mode z_m.\n            # Brent's method is efficient and guaranteed to converge if the\n            # function values at the bracket endpoints have opposite signs.\n            # h(0) = lambda*phi(0) has the same sign as lambda.\n            # For lambda > 0, h(0) > 0 and h(z) -> -inf as z -> inf.\n            # For lambda  0, h(0)  0 and h(z) -> +inf as z -> -inf.\n            # The chosen brackets ensure a root is contained.\n            sol = root_scalar(h, args=(lam,), bracket=bracket, method='brentq')\n            z_mode = sol.root\n\n            # Convert the standardized mode back to the original scale\n            x_mode = mu + sigma * z_mode\n\n        # Append the result rounded to 6 decimal places.\n        results.append(f\"{x_mode:.6f}\")\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n\n```"
        },
        {
            "introduction": "Translating theoretical concepts like modality to real data is not always straightforward, as our tools for visualization can introduce their own biases. This exercise demonstrates how the choice of bin width in a histogram—a common tool for assessing distribution shape—can create misleading impressions of multimodality. By comparing two standard binning rules on a small dataset, you will gain critical insight into the pitfalls of empirical data analysis. ",
            "id": "4909562",
            "problem": "A biostatistics researcher is evaluating modality (the number of local maxima) in empirical distributions using histograms constructed from small samples of a single unimodal population. Consider the following sample of residual biomarker $z$-scores from a pilot study: $-3$, $-0.2$, $0$, $0.1$, $0.2$, $0.3$, $0.4$, $3$. Let $n$ denote the sample size, $\\bar{x}$ the sample mean, $s$ the sample standard deviation, and $\\mathrm{IQR}$ the interquartile range defined as $Q_{3} - Q_{1}$ with quartiles computed by the median-of-halves method for even $n$ (that is, after ordering the data, $Q_{1}$ is the median of the lower half and $Q_{3}$ is the median of the upper half, using the average of the two middle points when needed). The researcher plans to compare histograms constructed with the Scott rule and the Freedman–Diaconis rule. Histograms are to be constructed with the following conventions: bins are left-closed and right-open except that the last bin is right-closed, the bin origin is at the sample minimum $x_{(1)}$, and successive bins are formed by adding a constant width $h$ according to the rule in use.\n\nUsing the standard definitions of the Scott rule and the Freedman–Diaconis rule, construct both histograms for the given sample. Define a histogram “mode” as any bin whose count is strictly greater than the counts of its adjacent bin(s); for edge bins, compare only to the single adjacent bin. Compute the number of modes in each histogram, then compute the difference “Freedman–Diaconis modes minus Scott modes.” Express the final difference as an integer. No rounding is required.",
            "solution": "The problem is validated as scientifically grounded, well-posed, and objective. It presents a clear computational task based on standard principles of biostatistics. All required data, definitions, and rules are provided, making the problem self-contained and solvable.\n\nThe solution proceeds by first calculating the necessary sample statistics, then applying the Scott and Freedman–Diaconis rules to determine bin widths, constructing the corresponding histograms, and finally identifying the number of modes in each according to the stated definition.\n\nThe sample data provided is the set of $z$-scores $X = \\{-3, -0.2, 0, 0.1, 0.2, 0.3, 0.4, 3\\}$.\nThe sample size is $n=8$.\n\nFirst, we order the data to facilitate calculations: $x_{(1)} = -3$, $x_{(2)} = -0.2$, $x_{(3)} = 0$, $x_{(4)} = 0.1$, $x_{(5)} = 0.2$, $x_{(6)} = 0.3$, $x_{(7)} = 0.4$, $x_{(8)} = 3$.\nThe sample minimum is $x_{(1)} = -3$.\n\nThe sample mean $\\bar{x}$ is calculated as:\n$$ \\bar{x} = \\frac{1}{n} \\sum_{i=1}^{n} x_i = \\frac{1}{8} (-3 - 0.2 + 0 + 0.1 + 0.2 + 0.3 + 0.4 + 3) = \\frac{0.8}{8} = 0.1 $$\n\nThe sample standard deviation $s$ is calculated using the formula $s = \\sqrt{\\frac{1}{n-1} \\sum_{i=1}^{n} (x_i - \\bar{x})^2}$.\nThe sum of squared deviations from the mean is:\n$$ \\sum_{i=1}^{8} (x_i - 0.1)^2 = (-3.1)^2 + (-0.3)^2 + (-0.1)^2 + (0)^2 + (0.1)^2 + (0.2)^2 + (0.3)^2 + (2.9)^2 $$\n$$ \\sum (x_i - 0.1)^2 = 9.61 + 0.09 + 0.01 + 0 + 0.01 + 0.04 + 0.09 + 8.41 = 18.26 $$\nThus, the sample variance $s^2$ is $\\frac{18.26}{7}$.\nThe sample standard deviation is $s = \\sqrt{\\frac{18.26}{7}}$.\n\nNext, we compute the quartiles, $Q_1$ and $Q_3$, using the median-of-halves method. For $n=8$, the sample is split into two halves of $4$ data points each.\nLower half: $\\{-3, -0.2, 0, 0.1\\}$\nUpper half: $\\{0.2, 0.3, 0.4, 3\\}$\n$Q_1$ is the median of the lower half, which is the average of its two middle values:\n$$ Q_1 = \\frac{-0.2 + 0}{2} = -0.1 $$\n$Q_3$ is the median of the upper half, which is the average of its two middle values:\n$$ Q_3 = \\frac{0.3 + 0.4}{2} = 0.35 $$\nThe interquartile range $\\mathrm{IQR}$ is:\n$$ \\mathrm{IQR} = Q_3 - Q_1 = 0.35 - (-0.1) = 0.45 $$\n\nWith these statistics, we can calculate the bin widths. For both rules, we need $n^{1/3} = 8^{1/3} = 2$.\n\nFor the Scott rule:\n$$ h_{\\mathrm{Scott}} = \\frac{3.49 s}{n^{1/3}} = \\frac{3.49 \\sqrt{\\frac{18.26}{7}}}{2} \\approx \\frac{3.49 \\times 1.6151}{2} \\approx 2.8184 $$\nFor the Freedman–Diaconis rule:\n$$ h_{\\mathrm{FD}} = \\frac{2 \\cdot \\mathrm{IQR}}{n^{1/3}} = \\frac{2 \\times 0.45}{2} = 0.45 $$\n\nNow, we construct each histogram. The origin is the sample minimum $x_{(1)} = -3$.\n\n**Scott Histogram Construction**\nThe bin width is $h_{\\mathrm{Scott}} \\approx 2.8184$.\n- Bin 1: $[-3, -3 + 2.8184) = [-3, -0.1816)$. This bin contains the data points $-3$ and $-0.2$. The count is $2$.\n- Bin 2: $[-0.1816, -0.1816 + 2.8184) = [-0.1816, 2.6368)$. This bin contains the data points $0, 0.1, 0.2, 0.3, 0.4$. The count is $5$.\n- Bin 3: $[2.6368, 2.6368 + 2.8184) = [2.6368, 5.4552)$. This bin contains the data point $3$. The count is $1$.\nThe histogram bins and counts are:\n- $B_{\\mathrm{Scott}, 1}$: Count = $2$\n- $B_{\\mathrm{Scott}, 2}$: Count = $5$\n- $B_{\\mathrm{Scott}, 3}$: Count = $1$\nTo find the number of modes, we apply the definition: a bin's count must be strictly greater than its adjacent bin(s).\n- $B_{\\mathrm{Scott}, 1}$ (edge bin): Count is $2$. Adjacent count is $5$. $2  5$ is false. Not a mode.\n- $B_{\\mathrm{Scott}, 2}$ (interior bin): Count is $5$. Adjacent counts are $2$ and $1$. $5  2$ and $5  1$ are both true. This is a mode.\n- $B_{\\mathrm{Scott}, 3}$ (edge bin): Count is $1$. Adjacent count is $5$. $1  5$ is false. Not a mode.\nThe Scott histogram has $1$ mode.\n\n**Freedman–Diaconis Histogram Construction**\nThe bin width is $h_{\\mathrm{FD}} = 0.45$. The origin is at $-3$. We determine the bin for each data point $x$ by calculating the bin index $j = \\lfloor \\frac{x - (-3)}{0.45} \\rfloor$.\n- $x=-3$: $j = \\lfloor \\frac{-3+3}{0.45} \\rfloor = 0$.\n- $x=-0.2$: $j = \\lfloor \\frac{-0.2+3}{0.45} \\rfloor = \\lfloor 6.22...\\rfloor = 6$.\n- $x=0$: $j = \\lfloor \\frac{0+3}{0.45} \\rfloor = \\lfloor 6.66...\\rfloor = 6$.\n- $x=0.1$: $j = \\lfloor \\frac{0.1+3}{0.45} \\rfloor = \\lfloor 6.88...\\rfloor = 6$.\n- $x=0.2$: $j = \\lfloor \\frac{0.2+3}{0.45} \\rfloor = \\lfloor 7.11...\\rfloor = 7$.\n- $x=0.3$: $j = \\lfloor \\frac{0.3+3}{0.45} \\rfloor = \\lfloor 7.33...\\rfloor = 7$.\n- $x=0.4$: $j = \\lfloor \\frac{0.4+3}{0.45} \\rfloor = \\lfloor 7.55...\\rfloor = 7$.\n- $x=3$: $j = \\lfloor \\frac{3+3}{0.45} \\rfloor = \\lfloor 13.33...\\rfloor = 13$.\nThe histogram spans from bin $0$ to bin $13$. The sequence of counts for bins $B_{\\mathrm{FD},0}, B_{\\mathrm{FD},1}, \\dots, B_{\\mathrm{FD},13}$ is:\n$[1, 0, 0, 0, 0, 0, 3, 3, 0, 0, 0, 0, 0, 1]$\nTo find the number of modes, we apply the definition:\n- $B_{\\mathrm{FD}, 0}$ (edge bin): Count is $1$. Adjacent count is $0$. $1  0$ is true. This is a mode.\n- $B_{\\mathrm{FD}, 1}$ to $B_{\\mathrm{FD}, 5}$: Counts are $0$. Not modes.\n- $B_{\\mathrm{FD}, 6}$ (interior bin): Count is $3$. Adjacent counts are $0$ and $3$. $3  0$ is true, but $3  3$ is false. Not a mode.\n- $B_{\\mathrm{FD}, 7}$ (interior bin): Count is $3$. Adjacent counts are $3$ and $0$. $3  3$ is false, but $3  0$ is true. Not a mode.\n- $B_{\\mathrm{FD}, 8}$ to $B_{\\mathrm{FD}, 12}$: Counts are $0$. Not modes.\n- $B_{\\mathrm{FD}, 13}$ (edge bin): Count is $1$. Adjacent count is $0$. $1  0$ is true. This is a mode.\nThe Freedman–Diaconis histogram has $2$ modes.\n\n**Final Calculation**\nThe problem asks for the difference: Freedman–Diaconis modes minus Scott modes.\nNumber of Freedman–Diaconis modes = $2$.\nNumber of Scott modes = $1$.\nDifference = $2 - 1 = 1$.\nThe result is an integer, and no rounding was performed in the final steps.",
            "answer": "$$\\boxed{1}$$"
        }
    ]
}