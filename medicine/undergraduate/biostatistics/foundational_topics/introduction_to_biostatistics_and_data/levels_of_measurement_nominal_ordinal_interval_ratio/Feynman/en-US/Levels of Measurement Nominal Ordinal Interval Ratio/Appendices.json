{
    "hands_on_practices": [
        {
            "introduction": "Understanding the level of measurement of your data is the first step toward sound statistical analysis. This practice focuses on ordinal data, where values have a clear order but the intervals between them are not necessarily equal . You will calculate appropriate descriptive statistics like the median and interquartile range, and contrast them with the sample mean to understand why the latter can be misleading for this type of data.",
            "id": "4922396",
            "problem": "A clinical trial records an ordinal symptom severity score for patients on a scale with categories $0$ (none), $1$ (mild), $2$ (moderate), $3$ (marked), and $4$ (severe). Two independent treatment groups, Group A and Group B, each have $24$ patients. The counts of patients in each category are:\n\n- Group A counts across categories $0,1,2,3,4$: $(3,4,9,6,2)$.\n- Group B counts across categories $0,1,2,3,4$: $(1,3,7,8,5)$.\n\nUsing only the order properties of the ordinal scale and the core definitions of quantiles, proceed as follows:\n\n1. Define the $p$-th quantile $Q_{p}$ for an ordinal variable as the smallest category $c$ whose cumulative proportion is at least $p$. Using this definition, compute the median $Q_{0.5}$ and the interquartile range $[Q_{0.25}, Q_{0.75}]$ for each group. Do not interpolate between categories; report quantiles as category codes.\n2. Treating the category codes $0,1,2,3,4$ as numerical labels, compute the sample mean for each group and then compute the difference in means (Group B minus Group A). Then, explain why this mean difference is not interpretable on an ordinal scale without additional assumptions about the scale’s structure.\n\nAs your final numeric answer, report only the median category code for Group A.",
            "solution": "The problem is subjected to validation before a solution is attempted.\n\n### Step 1: Extract Givens\n- **Scale Type**: Ordinal symptom severity score.\n- **Categories**: $0$ (none), $1$ (mild), $2$ (moderate), $3$ (marked), $4$ (severe).\n- **Groups**: Two independent treatment groups, Group A and Group B.\n- **Sample Sizes**: $n_A = 24$ patients, $n_B = 24$ patients.\n- **Group A Counts**: For categories $0, 1, 2, 3, 4$, the counts are $(3, 4, 9, 6, 2)$.\n- **Group B Counts**: For categories $0, 1, 2, 3, 4$, the counts are $(1, 3, 7, 8, 5)$.\n- **Quantile Definition**: The $p$-th quantile $Q_{p}$ for an ordinal variable is defined as the smallest category $c$ whose cumulative proportion is at least $p$. No interpolation is to be used.\n- **Task 1**: Compute the median ($Q_{0.5}$) and the interquartile range ($[Q_{0.25}, Q_{0.75}]$) for each group using the provided definition.\n- **Task 2**: Treat category codes as numerical labels to compute the sample mean for each group, find the difference in means (Group B minus Group A), and explain why this difference is not interpretable for an ordinal scale.\n\n### Step 2: Validate Using Extracted Givens\n- **Scientifically Grounded**: The problem is based on fundamental concepts in biostatistics, specifically the levels of measurement (nominal, ordinal, interval, ratio) and the appropriate descriptive statistics for each. The distinction between ordinal data (where only order is meaningful) and interval/ratio data (where arithmetic operations like calculating a mean are meaningful) is a cornerstone of statistical methodology. The provided definition for an ordinal quantile is a standard, non-interpolated method. The problem is scientifically sound.\n- **Well-Posed**: The problem provides all necessary data (counts, sample sizes, category labels) and a clear, unambiguous definition for calculating quantiles. The tasks are specific and lead to unique, verifiable answers. The problem is self-contained and consistent.\n- **Objective**: The problem is stated using precise, objective language without any subjective or opinion-based assertions.\n\n### Step 3: Verdict and Action\nThe problem is valid as it is scientifically grounded, well-posed, and objective. A full solution will be provided.\n\n### Solution\n\n**Part 1: Ordinal Quantiles**\n\nThe $p$-th quantile, $Q_{p}$, is the smallest category $c$ for which the cumulative proportion $F(c)$ is greater than or equal to $p$, i.e., $Q_p = \\min\\{c_i \\mid F(c_i) \\geq p\\}$. We first compute the cumulative frequencies and cumulative proportions for each group.\n\n**For Group A:**\nThe sample size is $n_A = 24$. The counts for categories $c = 0, 1, 2, 3, 4$ are $(3, 4, 9, 6, 2)$.\n\nThe cumulative frequencies are:\n- Category $0$: $3$\n- Category $1$: $3 + 4 = 7$\n- Category $2$: $7 + 9 = 16$\n- Category $3$: $16 + 6 = 22$\n- Category $4$: $22 + 2 = 24$\n\nThe cumulative proportions, $F_A(c)$, are:\n- $F_A(0) = 3/24 = 0.125$\n- $F_A(1) = 7/24 \\approx 0.2917$\n- $F_A(2) = 16/24 \\approx 0.6667$\n- $F_A(3) = 22/24 \\approx 0.9167$\n- $F_A(4) = 24/24 = 1.0$\n\nNow, we find the quantiles for Group A:\n- **First Quartile ($Q_{0.25, A}$)**: We seek the smallest category $c$ where $F_A(c) \\geq 0.25$. Since $F_A(0) = 0.125 < 0.25$ and $F_A(1) \\approx 0.2917 \\geq 0.25$, the smallest such category is $1$. Thus, $Q_{0.25, A} = 1$.\n- **Median ($Q_{0.5, A}$)**: We seek the smallest category $c$ where $F_A(c) \\geq 0.5$. Since $F_A(1) \\approx 0.2917 < 0.5$ and $F_A(2) \\approx 0.6667 \\geq 0.5$, the smallest such category is $2$. Thus, $Q_{0.5, A} = 2$.\n- **Third Quartile ($Q_{0.75, A}$)**: We seek the smallest category $c$ where $F_A(c) \\geq 0.75$. Since $F_A(2) \\approx 0.6667 < 0.75$ and $F_A(3) \\approx 0.9167 \\geq 0.75$, the smallest such category is $3$. Thus, $Q_{0.75, A} = 3$.\n\nThe interquartile range for Group A is the interval $[Q_{0.25, A}, Q_{0.75, A}]$, which is $[1, 3]$.\n\n**For Group B:**\nThe sample size is $n_B = 24$. The counts for categories $c = 0, 1, 2, 3, 4$ are $(1, 3, 7, 8, 5)$.\n\nThe cumulative frequencies are:\n- Category $0$: $1$\n- Category $1$: $1 + 3 = 4$\n- Category $2$: $4 + 7 = 11$\n- Category $3$: $11 + 8 = 19$\n- Category $4$: $19 + 5 = 24$\n\nThe cumulative proportions, $F_B(c)$, are:\n- $F_B(0) = 1/24 \\approx 0.0417$\n- $F_B(1) = 4/24 \\approx 0.1667$\n- $F_B(2) = 11/24 \\approx 0.4583$\n- $F_B(3) = 19/24 \\approx 0.7917$\n- $F_B(4) = 24/24 = 1.0$\n\nNow, we find the quantiles for Group B:\n- **First Quartile ($Q_{0.25, B}$)**: We seek the smallest category $c$ where $F_B(c) \\geq 0.25$. Since $F_B(1) \\approx 0.1667 < 0.25$ and $F_B(2) \\approx 0.4583 \\geq 0.25$, the smallest such category is $2$. Thus, $Q_{0.25, B} = 2$.\n- **Median ($Q_{0.5, B}$)**: We seek the smallest category $c$ where $F_B(c) \\geq 0.5$. Since $F_B(2) \\approx 0.4583 < 0.5$ and $F_B(3) \\approx 0.7917 \\geq 0.5$, the smallest such category is $3$. Thus, $Q_{0.5, B} = 3$.\n- **Third Quartile ($Q_{0.75, B}$)**: We seek the smallest category $c$ where $F_B(c) \\geq 0.75$. Since $F_B(2) \\approx 0.4583 < 0.75$ and $F_B(3) \\approx 0.7917 \\geq 0.75$, the smallest such category is $3$. Thus, $Q_{0.75, B} = 3$.\n\nThe interquartile range for Group B is the interval $[Q_{0.25, B}, Q_{0.75, B}]$, which is $[2, 3]$.\n\n**Part 2: Mean Difference and its Interpretation**\n\nWe are instructed to treat the category codes $x_i = \\{0, 1, 2, 3, 4\\}$ as numerical values to compute the sample means. The sample mean $\\bar{x}$ is given by $\\bar{x} = \\frac{1}{n} \\sum_{i} f_i x_i$, where $f_i$ is the frequency of category $x_i$.\n\n**Mean for Group A ($\\bar{x}_A$):**\n$$ \\bar{x}_A = \\frac{(3 \\times 0) + (4 \\times 1) + (9 \\times 2) + (6 \\times 3) + (2 \\times 4)}{24} = \\frac{0 + 4 + 18 + 18 + 8}{24} = \\frac{48}{24} = 2 $$\n\n**Mean for Group B ($\\bar{x}_B$):**\n$$ \\bar{x}_B = \\frac{(1 \\times 0) + (3 \\times 1) + (7 \\times 2) + (8 \\times 3) + (5 \\times 4)}{24} = \\frac{0 + 3 + 14 + 24 + 20}{24} = \\frac{61}{24} $$\n\n**Difference in Means:**\n$$ \\Delta\\bar{x} = \\bar{x}_B - \\bar{x}_A = \\frac{61}{24} - 2 = \\frac{61}{24} - \\frac{48}{24} = \\frac{13}{24} $$\n\n**Explanation of Non-Interpretability:**\nThe calculation of a sample mean involves arithmetic operations (addition and division). These operations are only meaningful for data measured on an interval or ratio scale, where the intervals between consecutive values are equal and quantifiable.\n\nThe symptom severity score is an ordinal scale. This means we know that category $2$ (moderate) is more severe than category $1$ (mild), and category $1$ is more severe than category $0$ (none). However, we do not know if the increase in severity from 'none' to 'mild' is the same as the increase from 'mild' to 'moderate'. The \"distances\" between the categories are undefined.\n\nBy assigning the numerical labels $0, 1, 2, 3, 4$ and calculating a mean, we are making a strong, implicit assumption that the scale is, in fact, an interval scale. That is, we assume the difference in severity between any two adjacent categories is a constant unit. This assumption is not justified by the problem description. The labels are just ordered placeholders.\n\nIf we were to choose a different set of numerical labels that preserve the order, for instance $\\{0, 1, 5, 6, 10\\}$, the resulting means and their difference would change, despite the underlying ordinal data being identical. Because the result depends on an arbitrary and unsubstantiated choice of numerical mapping, the calculated mean difference of $\\frac{13}{24}$ is not a meaningful or interpretable measure of the difference in central tendency between the two groups. It is an artifact of treating ordinal data as interval data. Proper analysis for ordinal data would rely on non-parametric methods like the Mann-Whitney U test or ordinal logistic regression, which respect the ordered nature of the categories without assuming equal intervals.",
            "answer": "$$\n\\boxed{2}\n$$"
        },
        {
            "introduction": "A key principle in measurement theory is that a meaningful conclusion should not change if we transform the data in a way that preserves its core properties. This exercise presents a striking scenario where analyzing ordinal pain scores with an inappropriate statistic—the sample mean—leads to contradictory results after a valid transformation . By working through this paradox, you will gain a deeper appreciation for why statistics for ordinal data must be based solely on rank order.",
            "id": "4922405",
            "problem": "A biostatistics team evaluates an analgesic using a post-treatment pain score recorded on a discrete scale from $0$ to $10$. Clinical experts affirm that this pain scale is ordinal: the only meaningful information is the ordering of scores, and any strictly increasing transformation of scores preserves the measurement content. Consider two randomized groups with the following observed pain scores:\nControl group $C$: $[3,4,5,6,7]$,\nTreatment group $T$: $[0,1,2,3,10]$.\nTwo analyses are proposed on these same data:\nAnalysis A computes the difference in sample means $\\bar{x}_{T}-\\bar{x}_{C}$ on the raw scale.\nAnalysis B applies a strictly increasing transformation $f(s)=s^{3}$ to every score and then computes the mean difference $\\overline{f(s)}_{T}-\\overline{f(s)}_{C}$.\nCarry out both analyses and identify whether they lead to conflicting conclusions about whether the analgesic reduces pain. Using only the foundational definitions of levels of measurement and their admissible transformations, determine which conclusion is meaningful by checking transformation invariance under strictly increasing transformations. Finally, to summarize the treatment effect in a way that is appropriate for an ordinal scale, compute the probability of superiority\n$$\\theta=\\Pr(S_{T}<S_{C})+\\tfrac{1}{2}\\Pr(S_{T}=S_{C}),$$\nwhere $S_{T}$ and $S_{C}$ are independent draws from the treatment and control distributions represented by the observed samples, and each pairwise comparison is weighted equally. Express your final numerical value for $\\theta$ as a decimal rounded to four significant figures.",
            "solution": "The problem statement is first validated according to the specified criteria.\n\n### Problem Validation\n\n**Step 1: Extract Givens**\n-   A post-treatment pain score is recorded on a discrete scale from $0$ to $10$.\n-   The scale is defined as ordinal, meaning only the ordering of scores is meaningful.\n-   Any strictly increasing transformation of scores preserves the measurement content.\n-   Control group scores, $C$: $[3, 4, 5, 6, 7]$.\n-   Treatment group scores, $T$: $[0, 1, 2, 3, 10]$.\n-   Analysis A: Compute the difference in sample means on the raw scale, $\\bar{x}_{T}-\\bar{x}_{C}$.\n-   Analysis B: Apply a strictly increasing transformation $f(s)=s^{3}$ and compute the difference in means of the transformed scores, $\\overline{f(s)}_{T}-\\overline{f(s)}_{C}$.\n-   Task 1: Carry out both analyses and identify if they lead to conflicting conclusions.\n-   Task 2: Determine which conclusion is meaningful by checking transformation invariance.\n-   Task 3: Compute the probability of superiority, $\\theta=\\Pr(S_{T}<S_{C})+\\tfrac{1}{2}\\Pr(S_{T}=S_{C})$, where $S_{T}$ and $S_{C}$ are independent random draws from the empirical distributions of the treatment and control samples, respectively.\n-   Final answer format: $\\theta$ expressed as a decimal rounded to four significant figures.\n\n**Step 2: Validate Using Extracted Givens**\n-   **Scientifically Grounded**: The problem is grounded in the fundamental statistical theory of measurement scales, a core concept in biostatistics. The distinction between ordinal and interval data and its implications for choice of analysis is a critical topic. The methods used (mean difference, non-parametric alternative) are standard.\n-   **Well-Posed**: The data are provided, the analytical procedures are explicitly defined, and the final quantity to be computed has a precise mathematical definition. The problem leads to a unique and meaningful solution.\n-   **Objective**: The problem is stated using precise, objective, and standard statistical terminology.\n-   **Completeness and Consistency**: The problem is self-contained and provides all necessary information. There are no internal contradictions.\n-   **Realism and Feasibility**: The scenario (evaluating an analgesic with a pain scale) and the data are realistic. The calculations are feasible.\n-   **Structure and Clarity**: The problem is well-structured, guiding the analysis from a demonstration of a methodological flaw to the application of a correct method.\n\n**Step 3: Verdict and Action**\nThe problem is deemed **valid**. It is a well-formulated exercise in biostatistical reasoning that tests foundational concepts of measurement theory. The solution process will now proceed.\n\n### Solution\n\nThe task is to analyze the provided data using two different methods, assess the validity of their conclusions based on measurement theory, and then apply an appropriate method for ordinal data.\n\n**Analysis A: Difference in Sample Means on the Raw Scale**\n\nThe control group data are $C = [3, 4, 5, 6, 7]$. The sample size is $n_C = 5$.\nThe sample mean for the control group is:\n$$ \\bar{x}_C = \\frac{3+4+5+6+7}{5} = \\frac{25}{5} = 5 $$\nThe treatment group data are $T = [0, 1, 2, 3, 10]$. The sample size is $n_T = 5$.\nThe sample mean for the treatment group is:\n$$ \\bar{x}_T = \\frac{0+1+2+3+10}{5} = \\frac{16}{5} = 3.2 $$\nThe difference in sample means is:\n$$ \\bar{x}_T - \\bar{x}_C = 3.2 - 5 = -1.8 $$\nThe negative result indicates that the average pain score in the treatment group is lower than in the control group. This suggests that the analgesic is effective at reducing pain.\n\n**Analysis B: Difference in Sample Means on Transformed Scores**\n\nThe analysis is repeated after applying the strictly increasing transformation $f(s) = s^3$ to each score.\nThe transformed control group data are $f(C) = [3^3, 4^3, 5^3, 6^3, 7^3] = [27, 64, 125, 216, 343]$.\nThe mean of the transformed control scores is:\n$$ \\overline{f(s)}_C = \\frac{27+64+125+216+343}{5} = \\frac{775}{5} = 155 $$\nThe transformed treatment group data are $f(T) = [0^3, 1^3, 2^3, 3^3, 10^3] = [0, 1, 8, 27, 1000]$.\nThe mean of the transformed treatment scores is:\n$$ \\overline{f(s)}_T = \\frac{0+1+8+27+1000}{5} = \\frac{1036}{5} = 207.2 $$\nThe difference in the means of the transformed scores is:\n$$ \\overline{f(s)}_T - \\overline{f(s)}_C = 207.2 - 155 = 52.2 $$\nThe positive result indicates that the average of the transformed pain scores in the treatment group is higher than in the control group. This suggests that the analgesic is not effective, and could even be detrimental.\n\n**Conflict and Meaningfulness of Conclusions**\n\nAnalysis A concludes that the treatment lowers pain scores ($\\bar{x}_T < \\bar{x}_C$), while Analysis B concludes that the treatment increases pain scores ($\\overline{f(s)}_T > \\overline{f(s)}_C$). These conclusions are contradictory.\n\nThe problem states the pain scale is **ordinal**. For an ordinal scale, the numerical values serve only to rank the observations. The magnitude of the differences between scale points is not meaningful. The admissible transformations for an ordinal scale are any strictly increasing monotonic functions, as these preserve the ordering of the data. The function $f(s) = s^3$ is a valid admissible transformation for non-negative scores.\n\nA conclusion or statistical statement about ordinal data is considered \"meaningful\" only if its truth value remains invariant under all such admissible transformations. Here, the statement \"the mean of the treatment group is lower than the mean of the control group\" is true for the raw scores but false for the transformed scores. Because the conclusion depends on the arbitrary numerical assignment to the ordered categories (i.e., it is not invariant), the comparison of arithmetic means is not a meaningful operation for ordinal data. The arithmetic mean is a statistic appropriate for interval or ratio scales, where additivity and differences are well-defined. Therefore, neither the conclusion from Analysis A nor Analysis B is valid, as the underlying method is inappropriate for the data's level of measurement.\n\n**Appropriate Analysis for Ordinal Data: Probability of Superiority**\n\nA meaningful comparison of two groups with ordinal data can be made using a non-parametric statistic that depends only on the ordering of the scores. The probability of superiority, $\\theta$, is one such measure. It is defined as:\n$$ \\theta = \\Pr(S_T < S_C) + \\frac{1}{2}\\Pr(S_T = S_C) $$\nwhere $S_T$ and $S_C$ are scores drawn randomly from the treatment and control populations, respectively. We estimate these probabilities from the samples by considering all possible pairwise comparisons. The total number of pairs $(s_i, s_j)$ with $s_i \\in T$ and $s_j \\in C$ is $n_T \\times n_C = 5 \\times 5 = 25$.\n\nWe enumerate the outcomes for each score in $T$ compared against all scores in $C$:\n-   $s_T = 0$: is less than $3, 4, 5, 6, 7$. ($5$ cases of $S_T < S_C$)\n-   $s_T = 1$: is less than $3, 4, 5, 6, 7$. ($5$ cases of $S_T < S_C$)\n-   $s_T = 2$: is less than $3, 4, 5, 6, 7$. ($5$ cases of $S_T < S_C$)\n-   $s_T = 3$: is equal to $3$, and less than $4, 5, 6, 7$. ($1$ case of $S_T = S_C$, $4$ cases of $S_T < S_C$)\n-   $s_T = 10$: is greater than $3, 4, 5, 6, 7$. ($5$ cases of $S_T > S_C$)\n\nTallying these outcomes:\n-   Number of pairs where $S_T < S_C$: $5 + 5 + 5 + 4 = 19$.\n-   Number of pairs where $S_T = S_C$: $1$.\n-   Number of pairs where $S_T > S_C$: $5$.\nThe sum is $19+1+5 = 25$, which is the total number of pairs.\n\nThe probabilities are estimated as:\n$$ \\Pr(S_T < S_C) = \\frac{19}{25} $$\n$$ \\Pr(S_T = S_C) = \\frac{1}{25} $$\nNow we compute $\\theta$:\n$$ \\theta = \\frac{19}{25} + \\frac{1}{2} \\left( \\frac{1}{25} \\right) = \\frac{19}{25} + \\frac{1}{50} = \\frac{38}{50} + \\frac{1}{50} = \\frac{39}{50} $$\nConverting to a decimal, $\\theta = 0.78$. Rounding to four significant figures as requested gives $0.7800$.\nThis value of $\\theta$ can be interpreted as the probability that a randomly chosen subject from the treatment group will have a lower (better) pain score than a randomly chosen subject from the control group, with ties being split. Since $\\theta = 0.7800 > 0.5$, this provides a meaningful conclusion that the analgesic is effective. This conclusion is invariant under any strictly increasing transformation.",
            "answer": "$$\n\\boxed{0.7800}\n$$"
        },
        {
            "introduction": "While ordinal scales focus on order, interval and ratio scales allow for quantitative comparisons of differences and magnitudes. This exercise uses the familiar conversion between Celsius and Fahrenheit temperature scales—a perfect example of an affine transformation—to explore the formal properties that define interval-level measurement . You will determine which statistical conclusions are preserved during this conversion and which are not, clarifying the crucial distinction between interval and ratio scales.",
            "id": "4922421",
            "problem": "In a clinical monitoring study, oral temperature measurements of $n = 8$ patients were recorded in degrees Celsius, denoted by the vector $C = (c_{1}, \\dots, c_{8})$, where the observed values are $36.6$, $37.0$, $37.8$, $38.1$, $36.9$, $39.0$, $38.4$, and $37.3$. To report results to a collaborating laboratory that uses degrees Fahrenheit, the team converts each measurement using the exact affine transformation $$F = \\frac{9}{5}C + 32,$$ where the multiplication and addition act componentwise on $C$.\n\nUsing the core definitions of the four levels of measurement—nominal, ordinal, interval, and ratio—jointly with the mathematical properties of affine transformations of the form $$Y = aX + b,$$ determine which classes of statistical statements are preserved when moving from $C$ to $F$ and which are not. Your reasoning must start from the formal definitions of these scale types and the transformation structure without appealing to shortcuts.\n\nThen, compute the Pearson product-moment correlation coefficient $r$ between the Celsius vector $C$ and its Fahrenheit transform $F$ using the exact conversion specified above. Round your final numeric answer to four significant figures. No units are required in the final answer.",
            "solution": "The problem presents two distinct tasks: first, to analyze the invariance of statistical statements under an affine transformation between temperature scales, based on the definitions of levels of measurement; and second, to compute the Pearson product-moment correlation coefficient between the original and transformed data vectors.\n\n### Part 1: Analysis of Measurement Scale Invariance\n\nThe foundation of this analysis rests upon the formal definitions of the four levels of measurement (nominal, ordinal, interval, ratio) and the class of transformations that leave the structure of each scale invariant. The transformation from Celsius ($C$) to Fahrenheit ($F$) is given by the positive affine transformation $F = aC + b$, where $a = \\frac{9}{5} > 0$ and $b = 32$.\n\n1.  **Nominal Scale:** A nominal scale categorizes data without any intrinsic order. The only permissible formal relation is equality ($=$) or inequality ($\\neq$). A statement is preserved if the transformation is one-to-one. For any two measurements $c_i$ and $c_j$, if $c_i = c_j$, then $f_i = \\frac{9}{5}c_i + 32 = \\frac{9}{5}c_j + 32 = f_j$. Conversely, if $f_i = f_j$, then $\\frac{9}{5}c_i + 32 = \\frac{9}{5}c_j + 32$, which implies $\\frac{9}{5}c_i = \\frac{9}{5}c_j$ and thus $c_i = c_j$. The transformation is a bijection. Therefore, statements of identity and distinctness (e.g., \"patient A's temperature is the same as patient B's\") are preserved.\n\n2.  **Ordinal Scale:** An ordinal scale possesses the properties of a nominal scale but adds a meaningful order relation ($<$, $>$). Statements are preserved if the transformation is strictly monotonic. Let $c_i < c_j$. Since the coefficient $a = \\frac{9}{5}$ is positive, multiplying the inequality by $a$ preserves its direction: $\\frac{9}{5}c_i < \\frac{9}{5}c_j$. Adding the constant $b=32$ to both sides also preserves the inequality: $\\frac{9}{5}c_i + 32 < \\frac{9}{5}c_j + 32$, which is $f_i < f_j$. The transformation is strictly monotonically increasing. Consequently, all statements concerning order (e.g., \"patient A is hotter than patient B\") are preserved.\n\n3.  **Interval Scale:** An interval scale has the properties of an ordinal scale, and additionally, the differences between values are meaningful and comparable. The hallmark of an interval scale is the invariance of ratios of intervals under positive affine transformations ($Y = aX+b$, $a>0$). Let's examine the ratio of two intervals in Celsius, $\\frac{c_j - c_i}{c_l - c_k}$. The corresponding values in Fahrenheit are $f_i = ac_i+b$, $f_j = ac_j+b$, $f_k = ac_k+b$, and $f_l = ac_l+b$. The new ratio of intervals is:\n$$ \\frac{f_j - f_i}{f_l - f_k} = \\frac{(ac_j + b) - (ac_i + b)}{(ac_l + b) - (ac_k + b)} = \\frac{a(c_j - c_i)}{a(c_l - c_k)} = \\frac{c_j - c_i}{c_l - c_k} $$\nSince the ratio of intervals is unchanged, all statistical statements that rely on this property are preserved. This includes statements about the equality of differences (e.g., \"The temperature increase from patient A to patient B is the same as from patient C to patient D\") and the relative magnitude of differences. The Celsius scale is itself an interval scale, as its zero point is arbitrary (freezing point of water, not absolute absence of thermal energy). The transformation to Fahrenheit, another interval scale, is precisely the type that preserves interval properties.\n\n4.  **Ratio Scale:** A ratio scale possesses all the properties of an interval scale, plus a true, non-arbitrary zero point. This absolute zero allows for meaningful ratios of values. The class of transformations that preserves a ratio scale is the positive scalar transformation ($Y = aX$, $a>0$). The given transformation, $F = \\frac{9}{5}C + 32$, includes an additive constant $b=32 \\neq 0$. Let's examine the ratio of two values, $\\frac{c_j}{c_i}$. The corresponding ratio in Fahrenheit is:\n$$ \\frac{f_j}{f_i} = \\frac{\\frac{9}{5}c_j + 32}{\\frac{9}{5}c_i + 32} $$\nIn general, $\\frac{\\frac{9}{5}c_j + 32}{\\frac{9}{5}c_i + 32} \\neq \\frac{c_j}{c_i}$. For instance, a temperature of $20^\\circ C$ is not \"twice as hot\" as $10^\\circ C$ in a thermodynamic sense. This statement is not preserved upon conversion: $f(20) = 68^\\circ F$ and $f(10)=50^\\circ F$, and $\\frac{68}{50} = 1.36 \\neq 2$. The presence of the additive constant $b$ breaks the invariance of value ratios. Therefore, statistical statements that depend on a true zero and meaningful ratios of values are not preserved.\n\nIn summary, statements that are valid for nominal, ordinal, and interval scales are preserved under the Celsius to Fahrenheit conversion. Statements that require a ratio scale are not.\n\n### Part 2: Calculation of the Pearson Correlation Coefficient\n\nThe Pearson product-moment correlation coefficient $r$ between two variables, here denoted $C$ and $F$, is defined as:\n$$ r_{CF} = \\frac{\\text{cov}(C, F)}{\\sigma_C \\sigma_F} $$\nwhere $\\text{cov}(C, F)$ is the covariance of $C$ and $F$, and $\\sigma_C$ and $\\sigma_F$ are their respective standard deviations.\n\nThe problem specifies a perfect linear relationship between $F$ and $C$: $F = aC + b$, with $a = \\frac{9}{5}$ and $b = 32$. We can determine the correlation coefficient by using the properties of covariance and variance under linear transformations, without needing to perform calculations on the specific data points provided.\n\nLet $c_i$ represent the individual measurements in Celsius and $f_i = ac_i + b$ be the corresponding measurements in Fahrenheit.\nThe covariance is given by $\\text{cov}(C, F) = E[(C - E[C])(F - E[F])]$.\nWe know that $E[F] = E[aC+b] = aE[C] + b$.\nSubstituting this into the covariance formula:\n$$ \\text{cov}(C, F) = E[(C - E[C])((aC + b) - (aE[C] + b))] $$\n$$ \\text{cov}(C, F) = E[(C - E[C])(a(C - E[C]))] $$\n$$ \\text{cov}(C, F) = a E[(C - E[C])^2] = a \\cdot \\text{var}(C) = a \\sigma_C^2 $$\nThe variance of $F$ is:\n$$ \\text{var}(F) = \\text{var}(aC + b) = a^2 \\text{var}(C) = a^2 \\sigma_C^2 $$\nThe standard deviation of $F$ is therefore:\n$$ \\sigma_F = \\sqrt{a^2 \\sigma_C^2} = |a| \\sqrt{\\sigma_C^2} = |a| \\sigma_C $$\nNow, we substitute these expressions for $\\text{cov}(C, F)$ and $\\sigma_F$ back into the formula for $r_{CF}$:\n$$ r_{CF} = \\frac{a \\sigma_C^2}{\\sigma_C (|a| \\sigma_C)} = \\frac{a \\sigma_C^2}{|a| \\sigma_C^2} = \\frac{a}{|a|} $$\nThis general result shows that the correlation coefficient between a variable and its affine transform depends only on the sign of the scaling coefficient $a$.\nFor the given transformation, $a = \\frac{9}{5}$, which is a positive value.\n$$ r_{CF} = \\frac{\\frac{9}{5}}{|\\frac{9}{5}|} = \\frac{\\frac{9}{5}}{\\frac{9}{5}} = 1 $$\nThe correlation coefficient is exactly $1$, indicating a perfect positive linear relationship. The data points $(c_i, f_i)$ lie perfectly on a line with a positive slope. The specific numerical values for the temperatures are not required to deduce this result.\n\nThe problem asks for the numerical answer to be rounded to four significant figures. An exact value of $1$ expressed to four significant figures is $1.000$.",
            "answer": "$$\n\\boxed{1.000}\n$$"
        }
    ]
}