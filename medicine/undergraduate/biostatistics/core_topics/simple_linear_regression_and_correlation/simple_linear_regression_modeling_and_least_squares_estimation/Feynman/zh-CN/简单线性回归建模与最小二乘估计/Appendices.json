{
    "hands_on_practices": [
        {
            "introduction": "在统计建模中，对模型进行重新参数化（例如，通过中心化预测变量）是一种常用技巧，它有助于我们更深入地理解模型参数的解释及其统计特性。本练习将引导你探索将预测变量进行中心化的效果，特别是揭示为何在样本均值处进行中心化对截距的估计尤其有利。通过这个过程，你将理解模型形式的选择如何影响我们对参数估计稳定性的评估。",
            "id": "4952529",
            "problem": "一项生物统计学研究探讨了 $n$ 个个体中连续生物标志物响应 $Y$ 与连续暴露量 $x$ 之间的线性关系。假设采用简单线性回归模型\n$$\nY_i \\;=\\; \\beta_0 \\;+\\; \\beta_1 x_i \\;+\\; \\varepsilon_i,\\quad i=1,\\dots,n,\n$$\n其中 $\\varepsilon_i$ 是独立同分布的 (i.i.d.)，满足 $\\mathbb{E}[\\varepsilon_i]=0$ 和 $\\operatorname{Var}(\\varepsilon_i)=\\sigma^2$，并令 $\\bar{x}=\\frac{1}{n}\\sum_{i=1}^n x_i$ 以及 $S_{xx}=\\sum_{i=1}^n (x_i-\\bar{x})^2$。考虑通过定义 $z_i=x_i-c$ 将预测变量以任意常数 $c\\in\\mathbb{R}$ 为中心进行中心化，然后重新拟合模型并估计\n$$\nY_i \\;=\\; \\alpha_c \\;+\\; \\beta_1^{(c)} z_i \\;+\\; \\varepsilon_i.\n$$\n仅从最小二乘法的定义和给定的假设出发，推导重新拟合后的截距 $\\hat{\\alpha}_c$ 和斜率 $\\hat{\\beta}_1^{(c)}$ 与原始最小二乘估计量 $\\hat{\\beta}_0$ 和 $\\hat{\\beta}_1$ 之间的关系，并根据条件均值 $\\mathbb{E}[Y\\mid x=c]$ 解释 $\\hat{\\alpha}_c$ 的含义。然后，求出 $\\operatorname{Var}(\\hat{\\alpha}_c)$ 作为 $c$, $\\bar{x}$, $S_{xx}$, $n$ 和 $\\sigma^2$ 的函数的显式表达式，并确定在所有实数 $c$ 中使 $\\operatorname{Var}(\\hat{\\alpha}_c)$ 最小的中心化值 $c$。\n\n你的最终答案必须是使 $\\operatorname{Var}(\\hat{\\alpha}_c)$ 最小的 $c$ 值的单个解析表达式。不需要进行数值四舍五入，最终答案中也不应包含单位。",
            "solution": "首先将根据指定标准对问题陈述进行验证。\n\n### 问题验证\n\n#### 第 1 步：提取已知条件\n已知条件如下：\n- 原始简单线性回归模型：$Y_i = \\beta_0 + \\beta_1 x_i + \\varepsilon_i$，其中 $i=1,\\dots,n$。\n- 误差项 $\\varepsilon_i$ 是独立同分布的 (i.i.d.)。\n- 误差项的期望值：$\\mathbb{E}[\\varepsilon_i]=0$。\n- 误差项的方差：$\\operatorname{Var}(\\varepsilon_i)=\\sigma^2$。\n- 预测变量的样本均值：$\\bar{x}=\\frac{1}{n}\\sum_{i=1}^n x_i$。\n- 预测变量的离差平方和：$S_{xx}=\\sum_{i=1}^n (x_i-\\bar{x})^2$。\n- 重新拟合的模型使用中心化的预测变量 $z_i=x_i-c$，其中 $c\\in\\mathbb{R}$ 是一个任意常数。\n- 重新拟合的模型方程：$Y_i = \\alpha_c + \\beta_1^{(c)} z_i + \\varepsilon_i$。\n- 任务是从最小二乘法的定义出发，推导估计量之间的关系，解释新截距的含义，推导其方差，并找到使该方差最小的 $c$ 值。\n\n#### 第 2 步：使用提取的已知条件进行验证\n根据科学性、良态性（well-posed）和客观性标准对问题进行评估。\n- **科学性**：该问题是线性模型理论的核心，是生物统计学和统计学中的一个基本课题。它探讨了在简单重参数化（平移预测变量）下最小二乘估计量的性质。所有假设，如零均值和等方差的独立同分布误差，在此背景下都是标准的。该问题在科学上和数学上都是合理的。\n- **良态性**：问题定义清晰。它要求推导估计量之间的关系、参数的统计解释、方差函数的推导以及该函数的优化。这些都是线性回归理论中标准的、可回答的问题。存在一个唯一且有意义的解，并且可以从所提供的信息中推导出来。\n- **客观性**：问题使用精确、形式化的数学语言陈述。它没有任何歧义、主观性或基于观点的主张。\n\n#### 第 3 步：结论与行动\n问题有效。它是线性回归理论中一个标准的、良态的练习。现在开始求解过程。\n\n### 解题过程\n\n第一步是陈述原始模型 $Y_i = \\beta_0 + \\beta_1 x_i + \\varepsilon_i$ 参数的普通最小二乘 (OLS) 估计量。OLS 估计量（记为 $\\hat{\\beta}_0$ 和 $\\hat{\\beta}_1$）是使残差平方和 $S(\\beta_0, \\beta_1) = \\sum_{i=1}^n (Y_i - \\beta_0 - \\beta_1 x_i)^2$ 最小化的值。从正规方程 $\\frac{\\partial S}{\\partial \\beta_0}=0$ 和 $\\frac{\\partial S}{\\partial \\beta_1}=0$ 推导出的标准解为：\n$$\n\\hat{\\beta}_1 = \\frac{\\sum_{i=1}^n (x_i - \\bar{x})(Y_i - \\bar{Y})}{\\sum_{i=1}^n (x_i - \\bar{x})^2} = \\frac{S_{xy}}{S_{xx}}\n$$\n$$\n\\hat{\\beta}_0 = \\bar{Y} - \\hat{\\beta}_1 \\bar{x}\n$$\n其中 $\\bar{Y} = \\frac{1}{n}\\sum_{i=1}^n Y_i$ 且 $S_{xy} = \\sum_{i=1}^n (x_i - \\bar{x})(Y_i - \\bar{Y})$。\n\n接下来，我们考虑重新拟合的模型 $Y_i = \\alpha_c + \\beta_1^{(c)} z_i + \\varepsilon_i$，其中 $z_i = x_i - c$。该模型的 OLS 估计量 $\\hat{\\alpha}_c$ 和 $\\hat{\\beta}_1^{(c)}$ 是通过最小化 $S(\\alpha_c, \\beta_1^{(c)}) = \\sum_{i=1}^n (Y_i - \\alpha_c - \\beta_1^{(c)} z_i)^2$ 找到的。遵循相同的步骤，估计量为：\n$$\n\\hat{\\beta}_1^{(c)} = \\frac{\\sum_{i=1}^n (z_i - \\bar{z})(Y_i - \\bar{Y})}{\\sum_{i=1}^n (z_i - \\bar{z})^2}\n$$\n$$\n\\hat{\\alpha}_c = \\bar{Y} - \\hat{\\beta}_1^{(c)} \\bar{z}\n$$\n其中 $\\bar{z} = \\frac{1}{n} \\sum_{i=1}^n z_i = \\frac{1}{n} \\sum_{i=1}^n (x_i - c) = (\\frac{1}{n} \\sum_{i=1}^n x_i) - c = \\bar{x} - c$。\n\n为了关联这些估计量，我们注意到离差项 $z_i - \\bar{z}$ 为 $(x_i - c) - (\\bar{x} - c) = x_i - \\bar{x}$。将此代入 $\\hat{\\beta}_1^{(c)}$ 的表达式中：\n$$\n\\hat{\\beta}_1^{(c)} = \\frac{\\sum_{i=1}^n (x_i - \\bar{x})(Y_i - \\bar{Y})}{\\sum_{i=1}^n (x_i - \\bar{x})^2} = \\hat{\\beta}_1\n$$\n这表明斜率系数的最小二乘估计量对于预测变量的位置平移是不变的。\n\n现在，我们求截距估计量 $\\hat{\\alpha}_c$ 的关系：\n$$\n\\hat{\\alpha}_c = \\bar{Y} - \\hat{\\beta}_1^{(c)} \\bar{z} = \\bar{Y} - \\hat{\\beta}_1 (\\bar{x} - c) = (\\bar{Y} - \\hat{\\beta}_1 \\bar{x}) + \\hat{\\beta}_1 c\n$$\n认识到 $\\hat{\\beta}_0 = \\bar{Y} - \\hat{\\beta}_1 \\bar{x}$，我们有：\n$$\n\\hat{\\alpha}_c = \\hat{\\beta}_0 + \\hat{\\beta}_1 c\n$$\n重新拟合模型的截距是原始截距、原始斜率和中心化常数 $c$ 的线性函数。\n\n$\\hat{\\alpha}_c$ 的解释源于其定义。在模型 $Y_i = \\alpha_c + \\beta_1^{(c)} z_i + \\varepsilon_i$ 中，截距 $\\hat{\\alpha}_c$ 是当预测变量 $z$ 为零时响应 $Y$ 的预测值。条件 $z=0$ 等价于 $x-c=0$，即 $x=c$。因此，$\\hat{\\alpha}_c$ 是 $Y$ 在 $x=c$ 处的预测值。这可以从原始拟合的回归线 $\\hat{Y} = \\hat{\\beta}_0 + \\hat{\\beta}_1 x$ 中看出。将其在 $x=c$ 处求值得到 $\\hat{Y}|_{x=c} = \\hat{\\beta}_0 + \\hat{\\beta}_1 c$，这正是我们为 $\\hat{\\alpha}_c$ 推导出的表达式。因此，$\\hat{\\alpha}_c$ 是在给定 $x=c$ 条件下 $Y$ 的条件均值的估计量，即 $\\hat{\\alpha}_c = \\hat{\\mathbb{E}}[Y \\mid x=c]$。\n\n为了求 $\\hat{\\alpha}_c$ 的方差，我们使用表达式 $\\hat{\\alpha}_c = \\hat{\\beta}_0 + c \\hat{\\beta}_1$。其方差为：\n$$\n\\operatorname{Var}(\\hat{\\alpha}_c) = \\operatorname{Var}(\\hat{\\beta}_0 + c \\hat{\\beta}_1) = \\operatorname{Var}(\\hat{\\beta}_0) + c^2 \\operatorname{Var}(\\hat{\\beta}_1) + 2c \\operatorname{Cov}(\\hat{\\beta}_0, \\hat{\\beta}_1)\n$$\n我们需要 OLS 估计量 $\\hat{\\beta}_0$ 和 $\\hat{\\beta}_1$ 的方差和协方差。将预测变量 $x_i$ 视为固定常数，则估计量是随机变量 $Y_i$ 的线性组合。\n$\\hat{\\beta}_1 = \\sum_{i=1}^n k_i Y_i$，其中 $k_i = \\frac{x_i - \\bar{x}}{S_{xx}}$。\n$$\n\\operatorname{Var}(\\hat{\\beta}_1) = \\operatorname{Var}\\left(\\sum_{i=1}^n k_i Y_i\\right) = \\sum_{i=1}^n k_i^2 \\operatorname{Var}(Y_i) = \\sum_{i=1}^n k_i^2 \\sigma^2 = \\sigma^2 \\sum_{i=1}^n \\left(\\frac{x_i - \\bar{x}}{S_{xx}}\\right)^2 = \\frac{\\sigma^2}{S_{xx}^2} \\sum_{i=1}^n (x_i - \\bar{x})^2 = \\frac{\\sigma^2 S_{xx}}{S_{xx}^2} = \\frac{\\sigma^2}{S_{xx}}\n$$\n$\\hat{\\beta}_0 = \\bar{Y} - \\bar{x}\\hat{\\beta}_1$。\n$\\bar{Y}$ 和 $\\hat{\\beta}_1$ 之间的协方差为：\n$$\n\\operatorname{Cov}(\\bar{Y}, \\hat{\\beta}_1) = \\operatorname{Cov}\\left(\\frac{1}{n}\\sum_{j=1}^n Y_j, \\sum_{i=1}^n k_i Y_i\\right) = \\frac{1}{n} \\sum_{i=1}^n k_i \\operatorname{Var}(Y_i) = \\frac{\\sigma^2}{n} \\sum_{i=1}^n k_i = \\frac{\\sigma^2}{n} \\frac{\\sum_{i=1}^n(x_i - \\bar{x})}{S_{xx}} = 0\n$$\n由于 $\\operatorname{Cov}(\\bar{Y}, \\hat{\\beta}_1) = 0$，$\\bar{Y}$ 和 $\\hat{\\beta}_1$ 是不相关的。这简化了余下的计算。\n$$\n\\operatorname{Var}(\\hat{\\beta}_0) = \\operatorname{Var}(\\bar{Y} - \\bar{x}\\hat{\\beta}_1) = \\operatorname{Var}(\\bar{Y}) + \\bar{x}^2 \\operatorname{Var}(\\hat{\\beta}_1) - 2\\bar{x}\\operatorname{Cov}(\\bar{Y}, \\hat{\\beta}_1) = \\frac{\\sigma^2}{n} + \\bar{x}^2 \\frac{\\sigma^2}{S_{xx}} - 0 = \\sigma^2 \\left(\\frac{1}{n} + \\frac{\\bar{x}^2}{S_{xx}}\\right)\n$$\n协方差为：\n$$\n\\operatorname{Cov}(\\hat{\\beta}_0, \\hat{\\beta}_1) = \\operatorname{Cov}(\\bar{Y} - \\bar{x}\\hat{\\beta}_1, \\hat{\\beta}_1) = \\operatorname{Cov}(\\bar{Y}, \\hat{\\beta}_1) - \\bar{x}\\operatorname{Var}(\\hat{\\beta}_1) = 0 - \\bar{x}\\frac{\\sigma^2}{S_{xx}} = -\\frac{\\sigma^2 \\bar{x}}{S_{xx}}\n$$\n将这些表达式代入 $\\operatorname{Var}(\\hat{\\alpha}_c)$ 的公式中：\n$$\n\\operatorname{Var}(\\hat{\\alpha}_c) = \\sigma^2 \\left(\\frac{1}{n} + \\frac{\\bar{x}^2}{S_{xx}}\\right) + c^2 \\left(\\frac{\\sigma^2}{S_{xx}}\\right) + 2c \\left(-\\frac{\\sigma^2 \\bar{x}}{S_{xx}}\\right)\n$$\n$$\n\\operatorname{Var}(\\hat{\\alpha}_c) = \\sigma^2 \\left[ \\frac{1}{n} + \\frac{\\bar{x}^2}{S_{xx}} - \\frac{2c\\bar{x}}{S_{xx}} + \\frac{c^2}{S_{xx}} \\right]\n$$\n$$\n\\operatorname{Var}(\\hat{\\alpha}_c) = \\sigma^2 \\left[ \\frac{1}{n} + \\frac{c^2 - 2c\\bar{x} + \\bar{x}^2}{S_{xx}} \\right]\n$$\n这简化为显式表达式：\n$$\n\\operatorname{Var}(\\hat{\\alpha}_c) = \\sigma^2 \\left[ \\frac{1}{n} + \\frac{(c - \\bar{x})^2}{S_{xx}} \\right]\n$$\n最后，为了找到使 $\\operatorname{Var}(\\hat{\\alpha}_c)$ 最小化的 $c$ 值，我们分析这个关于 $c$ 的函数。各项 $\\sigma^2$、$n$ 和 $S_{xx}$ 都是正常数（假设 $S_{xx} > 0$，即并非所有 $x_i$ 都相同，这是拟合斜率的必要条件）。第一项 $\\sigma^2/n$ 相对于 $c$ 是常数。第二项 $\\sigma^2 \\frac{(c - \\bar{x})^2}{S_{xx}}$ 取决于 $c$。由于 $(c - \\bar{x})^2 \\ge 0$，该项是非负的，其最小值为 0。当 $c - \\bar{x} = 0$ 时达到这个最小值，这意味着 $c = \\bar{x}$。\n或者，我们可以使用微积分。令 $f(c) = \\operatorname{Var}(\\hat{\\alpha}_c)$。我们求关于 $c$ 的导数：\n$$\n\\frac{d}{dc}f(c) = \\frac{d}{dc} \\left( \\sigma^2 \\left[ \\frac{1}{n} + \\frac{(c - \\bar{x})^2}{S_{xx}} \\right] \\right) = \\frac{\\sigma^2}{S_{xx}} \\cdot 2(c-\\bar{x})\n$$\n将导数设为零以找到临界点：\n$$\n\\frac{2\\sigma^2}{S_{xx}}(c-\\bar{x}) = 0\n$$\n这意味着 $c - \\bar{x} = 0$，所以 $c = \\bar{x}$。二阶导数是 $\\frac{d^2}{dc^2}f(c) = \\frac{2\\sigma^2}{S_{xx}} > 0$，这证实了 $c=\\bar{x}$ 对应一个最小值。\n因此，当预测变量在其样本均值 $\\bar{x}$ 处中心化时，估计的截距的方差最小。",
            "answer": "$$\\boxed{\\bar{x}}$$"
        },
        {
            "introduction": "估计回归系数仅仅是分析的第一步；我们还必须量化这些估计值的不确定性。本练习将深入探讨斜率和截距项标准误的推导，揭示样本量、预测变量的离散程度以及误差大小等因素如何影响我们估计的精度。随后，你将把这些理论公式应用于一个实际的生物统计学数据集，从而将理论与实践联系起来。",
            "id": "4952531",
            "problem": "一个临床生物统计学团队研究收缩压与年龄之间的关系。设响应变量为收缩压 $y_i$（单位：毫米汞柱，mmHg），预测变量为年龄 $x_i$（单位：年）。假设采用经典的简单线性回归模型，误差项独立同分布且服从正态分布，\n$$\nY_i \\;=\\; \\beta_0 \\;+\\; \\beta_1 x_i \\;+\\; \\varepsilon_i,\\quad \\varepsilon_i \\sim \\text{Normal}(0,\\sigma^2),\\quad i=1,\\dots,n,\n$$\n并且参数通过普通最小二乘法（OLS）进行估计。\n\n对于 $n=8$ 个个体，观测数据为\n$$\n(x_i,y_i) \\in \\{(20,113),\\,(30,117),\\,(40,118.5),\\,(50,126),\\,(60,129),\\,(70,136.5),\\,(80,138),\\,(90,142)\\}.\n$$\n\n任务：\n- 从模型定义和最小化 $\\sum_{i=1}^{n}(y_i-\\beta_0-\\beta_1 x_i)^2$ 所得的正规方程出发，在所述假设下推导 OLS 斜率和截距估计量的抽样方差，并由此推导它们的标准误。用量 $n$、$\\bar{x}$ 和 $\\sum_{i=1}^{n}(x_i-\\bar{x})^2$ 来表示你的推导过程。解释各项对标准误大小的贡献。\n- 然后，对于给定的数据集，使用无偏误差方差估计量\n$$\n\\hat{\\sigma}^2 \\;=\\; \\frac{\\sum_{i=1}^{n} e_i^2}{n-2},\\quad e_i = y_i - \\hat{y}_i,\n$$\n计算标准误的数值，其中 $\\hat{y}_i$ 是 OLS 拟合值。报告斜率的标准误（单位：毫米汞柱/年）和截距的标准误（单位：毫米汞柱）。将你的两个数值答案四舍五入到四位有效数字。以有序对 $(SE(\\hat{\\beta}_1),\\,SE(\\hat{\\beta}_0))$ 的形式提供你的最终数值答案。",
            "solution": "该问题具有科学依据，提法明确，客观，并包含了推导所需公式和计算数值所需的全部信息。我们开始解答，解答分为理论推导和数值计算两部分。\n\n### 第一部分：抽样方差和标准误的推导\n\n经典的简单线性回归模型由下式给出\n$$Y_i = \\beta_0 + \\beta_1 x_i + \\varepsilon_i$$\n其中误差项 $\\varepsilon_i$ 是独立同分布（i.i.d.）的，服从 $\\text{Normal}(0,\\sigma^2)$ 分布，对于 $i=1,\\dots,n$。普通最小二乘法（OLS）估计量 $\\hat{\\beta}_0$ 和 $\\hat{\\beta}_1$ 是使残差平方和 $S(\\beta_0, \\beta_1) = \\sum_{i=1}^{n} (y_i - \\beta_0 - \\beta_1 x_i)^2$ 最小化的 $\\beta_0$ 和 $\\beta_1$ 的值。\n\n为了找到最小值，我们对 $S$ 分别求关于 $\\beta_0$ 和 $\\beta_1$ 的偏导数，并令它们为零。这就得到了正规方程：\n$$ \\frac{\\partial S}{\\partial \\beta_0} = -2 \\sum_{i=1}^{n} (y_i - \\hat{\\beta}_0 - \\hat{\\beta}_1 x_i) = 0 \\implies \\sum_{i=1}^{n} y_i = n \\hat{\\beta}_0 + \\hat{\\beta}_1 \\sum_{i=1}^{n} x_i $$\n$$ \\frac{\\partial S}{\\partial \\beta_1} = -2 \\sum_{i=1}^{n} x_i(y_i - \\hat{\\beta}_0 - \\hat{\\beta}_1 x_i) = 0 \\implies \\sum_{i=1}^{n} x_i y_i = \\hat{\\beta}_0 \\sum_{i=1}^{n} x_i + \\hat{\\beta}_1 \\sum_{i=1}^{n} x_i^2 $$\n\n从第一个正规方程出发，两边除以 $n$，我们得到 $\\bar{y} = \\hat{\\beta}_0 + \\hat{\\beta}_1 \\bar{x}$，这给出了截距估计量作为斜率估计量的函数：\n$$ \\hat{\\beta}_0 = \\bar{y} - \\hat{\\beta}_1 \\bar{x} $$\n\n将 $\\hat{\\beta}_0$ 的这个表达式代入第二个正规方程：\n$$ \\sum x_i y_i = (\\bar{y} - \\hat{\\beta}_1 \\bar{x}) \\sum x_i + \\hat{\\beta}_1 \\sum x_i^2 $$\n$$ \\sum x_i y_i = \\bar{y} (n\\bar{x}) - \\hat{\\beta}_1 \\bar{x} (n\\bar{x}) + \\hat{\\beta}_1 \\sum x_i^2 $$\n$$ \\sum x_i y_i - n\\bar{x}\\bar{y} = \\hat{\\beta}_1 \\left( \\sum x_i^2 - n\\bar{x}^2 \\right) $$\n使用记号 $S_{xy} = \\sum (x_i-\\bar{x})(y_i-\\bar{y}) = \\sum x_i y_i - n\\bar{x}\\bar{y}$ 和 $S_{xx} = \\sum (x_i-\\bar{x})^2 = \\sum x_i^2 - n\\bar{x}^2$，我们解出 $\\hat{\\beta}_1$：\n$$ \\hat{\\beta}_1 = \\frac{\\sum (x_i-\\bar{x})(y_i-\\bar{y})}{\\sum (x_i-\\bar{x})^2} = \\frac{S_{xy}}{S_{xx}} $$\n\n为了求 $\\hat{\\beta}_1$ 的方差，我们将其表示为随机变量 $Y_i$ 的线性组合。注意 $\\sum (x_i-\\bar{x})\\bar{Y} = \\bar{Y} \\sum(x_i-\\bar{x}) = 0$。\n$$ \\hat{\\beta}_1 = \\frac{\\sum (x_i-\\bar{x})(Y_i-\\bar{Y})}{S_{xx}} = \\frac{\\sum (x_i-\\bar{x})Y_i - \\sum (x_i-\\bar{x})\\bar{Y}}{S_{xx}} = \\frac{\\sum (x_i-\\bar{x})Y_i}{S_{xx}} = \\sum_{i=1}^{n} c_i Y_i $$\n其中常数为 $c_i = \\frac{x_i-\\bar{x}}{S_{xx}}$。\n由于 $Y_i$ 是独立的，且 $\\text{Var}(Y_i) = \\sigma^2$，$\\hat{\\beta}_1$ 的方差为：\n$$ \\text{Var}(\\hat{\\beta}_1) = \\text{Var}\\left(\\sum_{i=1}^{n} c_i Y_i\\right) = \\sum_{i=1}^{n} c_i^2 \\text{Var}(Y_i) = \\sigma^2 \\sum_{i=1}^{n} c_i^2 $$\n我们计算常数的平方和：\n$$ \\sum_{i=1}^{n} c_i^2 = \\sum_{i=1}^{n} \\left( \\frac{x_i-\\bar{x}}{S_{xx}} \\right)^2 = \\frac{1}{S_{xx}^2} \\sum_{i=1}^{n} (x_i-\\bar{x})^2 = \\frac{S_{xx}}{S_{xx}^2} = \\frac{1}{S_{xx}} $$\n因此，斜率估计量的抽样方差为：\n$$ \\text{Var}(\\hat{\\beta}_1) = \\frac{\\sigma^2}{\\sum_{i=1}^n (x_i - \\bar{x})^2} $$\n\n接下来，我们求 $\\hat{\\beta}_0 = \\bar{Y} - \\hat{\\beta}_1 \\bar{x}$ 的方差。\n$$ \\text{Var}(\\hat{\\beta}_0) = \\text{Var}(\\bar{Y} - \\hat{\\beta}_1\\bar{x}) = \\text{Var}(\\bar{Y}) + \\bar{x}^2 \\text{Var}(\\hat{\\beta}_1) - 2\\bar{x} \\text{Cov}(\\bar{Y}, \\hat{\\beta}_1) $$\n我们有 $\\text{Var}(\\bar{Y}) = \\text{Var}(\\frac{1}{n}\\sum Y_i) = \\frac{1}{n^2} \\sum \\text{Var}(Y_i) = \\frac{n\\sigma^2}{n^2} = \\frac{\\sigma^2}{n}$。\n协方差项为：\n$$ \\text{Cov}(\\bar{Y}, \\hat{\\beta}_1) = \\text{Cov}\\left(\\sum_{i=1}^n \\frac{1}{n} Y_i, \\sum_{j=1}^n c_j Y_j\\right) = \\sum_{i=1}^n \\frac{1}{n} c_i \\text{Var}(Y_i) = \\frac{\\sigma^2}{n} \\sum_{i=1}^n c_i $$\n因为当 $i \\neq j$ 时，$\\text{Cov}(Y_i, Y_j)=0$。$c_i$ 常数的和为：\n$$ \\sum_{i=1}^n c_i = \\sum_{i=1}^n \\frac{x_i-\\bar{x}}{S_{xx}} = \\frac{1}{S_{xx}} \\sum_{i=1}^n (x_i-\\bar{x}) = 0 $$\n因此，$\\text{Cov}(\\bar{Y}, \\hat{\\beta}_1) = 0$。斜率估计量 $\\hat{\\beta}_1$ 与响应变量的样本均值 $\\bar{Y}$ 不相关。\n将这些结果代回到 $\\hat{\\beta}_0$ 的方差公式中：\n$$ \\text{Var}(\\hat{\\beta}_0) = \\frac{\\sigma^2}{n} + \\bar{x}^2 \\frac{\\sigma^2}{\\sum (x_i-\\bar{x})^2} = \\sigma^2 \\left( \\frac{1}{n} + \\frac{\\bar{x}^2}{\\sum_{i=1}^n (x_i-\\bar{x})^2} \\right) $$\n\n估计量的标准误（$SE$）是其估计抽样方差的平方根。方差 $\\sigma^2$ 是未知的，通过无偏估计量 $\\hat{\\sigma}^2 = \\frac{\\sum e_i^2}{n-2}$ 进行估计，其中 $e_i = y_i - \\hat{y}_i$ 是残差。\n斜率估计量的标准误为：\n$$ SE(\\hat{\\beta}_1) = \\sqrt{\\frac{\\hat{\\sigma}^2}{\\sum_{i=1}^n (x_i-\\bar{x})^2}} = \\frac{\\hat{\\sigma}}{\\sqrt{\\sum_{i=1}^n (x_i-\\bar{x})^2}} $$\n截距估计量的标准误为：\n$$ SE(\\hat{\\beta}_0) = \\sqrt{\\hat{\\sigma}^2 \\left( \\frac{1}{n} + \\frac{\\bar{x}^2}{\\sum_{i=1}^n (x_i-\\bar{x})^2} \\right)} = \\hat{\\sigma} \\sqrt{\\frac{1}{n} + \\frac{\\bar{x}^2}{\\sum_{i=1}^n (x_i-\\bar{x})^2}} $$\n\n各项的解释：\n- 对于 $SE(\\hat{\\beta}_0)$ 和 $SE(\\hat{\\beta}_1)$，标准误都与 $\\hat{\\sigma}$（误差项的估计标准差）成正比。围绕回归线的残差变异性越大，意味着参数估计的不确定性越大。\n- 对于 $SE(\\hat{\\beta}_1)$，项 $\\sum (x_i-\\bar{x})^2$ 位于分母中。该项衡量了预测变量值 $x_i$ 的散布或离散程度。$x_i$ 的散布范围越大，为估计斜率提供了更稳定的“杠杆臂”，从而减小其标准误。\n- 对于 $SE(\\hat{\\beta}_0)$，项 $\\frac{1}{n}$ 反映了估计平均响应水平的不确定性；这种不确定性随着样本量 $n$ 的增加而减小。项 $\\frac{\\bar{x}^2}{\\sum (x_i-\\bar{x})^2}$ 反映了将回归线从数据中心（$\\bar{x}$）外推到 y 轴（$x=0$）所带来的不确定性。当 $\\bar{x}$ 远离 0 时，此外推误差较大；当 $x_i$ 的散布范围较大时，此外推误差较小。\n\n### 第二部分：给定数据集的数值计算\n\n首先，我们根据数据计算必要的摘要统计量，其中 $n=8$。\n$$ x_i: \\{20, 30, 40, 50, 60, 70, 80, 90\\} $$\n$$ y_i: \\{113, 117, 118.5, 126, 129, 136.5, 138, 142\\} $$\n\n$$ \\sum_{i=1}^8 x_i = 440 \\implies \\bar{x} = \\frac{440}{8} = 55 \\text{ 年} $$\n$$ \\sum_{i=1}^8 y_i = 1020 \\implies \\bar{y} = \\frac{1020}{8} = 127.5 \\text{ 毫米汞柱} $$\n\n接下来，我们计算平方和：\n$$ S_{xx} = \\sum_{i=1}^8 (x_i - \\bar{x})^2 = \\sum x_i^2 - n\\bar{x}^2 = (20^2 + \\dots + 90^2) - 8(55^2) = 28400 - 8(3025) = 28400 - 24200 = 4200 $$\n$$ S_{xy} = \\sum_{i=1}^8 (x_i - \\bar{x})(y_i - \\bar{y}) = \\sum x_i y_i - n\\bar{x}\\bar{y} = (20 \\cdot 113 + \\dots + 90 \\cdot 142) - 8(55)(127.5) = 57925 - 56100 = 1825 $$\n$$ S_{yy} = \\sum_{i=1}^8 (y_i - \\bar{y})^2 = \\sum y_i^2 - n\\bar{y}^2 = (113^2 + \\dots + 142^2) - 8(127.5^2) = 130857.5 - 8(16256.25) = 130857.5 - 130050 = 807.5 $$\n\n现在，计算 OLS 估计值：\n$$ \\hat{\\beta}_1 = \\frac{S_{xy}}{S_{xx}} = \\frac{1825}{4200} = \\frac{73}{168} \\approx 0.43452 $$\n$$ \\hat{\\beta}_0 = \\bar{y} - \\hat{\\beta}_1 \\bar{x} = 127.5 - \\left(\\frac{1825}{4200}\\right)(55) \\approx 103.601 $$\n\n接下来，计算误差平方和（$SSE$）和误差方差的无偏估计量 $\\hat{\\sigma}^2$：\n$$ SSE = \\sum e_i^2 = S_{yy} - \\frac{S_{xy}^2}{S_{xx}} = 807.5 - \\frac{(1825)^2}{4200} = 807.5 - \\frac{3330625}{4200} \\approx 807.5 - 792.9940476 = 14.5059524 $$\n为保证精度，使用分数进行计算：\n$$ SSE = \\frac{1615}{2} - \\frac{133225}{168} = \\frac{135660 - 133225}{168} = \\frac{2435}{168} $$\n无偏方差估计量为：\n$$ \\hat{\\sigma}^2 = \\frac{SSE}{n-2} = \\frac{2435/168}{8-2} = \\frac{2435}{168 \\times 6} = \\frac{2435}{1008} \\approx 2.41567 $$\n\n最后，我们计算标准误：\n对于斜率 $\\hat{\\beta}_1$：\n$$ SE(\\hat{\\beta}_1) = \\sqrt{\\frac{\\hat{\\sigma}^2}{S_{xx}}} = \\sqrt{\\frac{2435/1008}{4200}} = \\sqrt{\\frac{2435}{1008 \\times 4200}} = \\sqrt{\\frac{2435}{4233600}} \\approx 0.0239825 $$\n四舍五入到四位有效数字，$SE(\\hat{\\beta}_1) \\approx 0.02398$ 毫米汞柱/年。\n\n对于截距 $\\hat{\\beta}_0$：\n$$ SE(\\hat{\\beta}_0) = \\sqrt{\\hat{\\sigma}^2 \\left(\\frac{1}{n} + \\frac{\\bar{x}^2}{S_{xx}}\\right)} = \\sqrt{\\frac{2435}{1008} \\left(\\frac{1}{8} + \\frac{55^2}{4200}\\right)} $$\n$$ SE(\\hat{\\beta}_0) = \\sqrt{\\frac{2435}{1008} \\left(\\frac{1}{8} + \\frac{3025}{4200}\\right)} = \\sqrt{\\frac{2435}{1008} \\left(\\frac{525+3025}{4200}\\right)} = \\sqrt{\\frac{2435}{1008} \\left(\\frac{3550}{4200}\\right)} = \\sqrt{\\frac{2435}{1008} \\left(\\frac{71}{84}\\right)} $$\n$$ SE(\\hat{\\beta}_0) = \\sqrt{\\frac{172885}{84672}} \\approx \\sqrt{2.04185} \\approx 1.428933 $$\n四舍五入到四位有效数字，$SE(\\hat{\\beta}_0) \\approx 1.429$ 毫米汞柱。\n\n所求的有序对为 $(SE(\\hat{\\beta}_1), SE(\\hat{\\beta}_0))$。",
            "answer": "$$ \\boxed{(0.02398, 1.429)} $$"
        },
        {
            "introduction": "在回归分析中，并非所有数据点都具有相同的影响力；某些观测值可能对回归结果产生不成比例的影响。这个动手练习通过一个精心构建的例子，生动地展示了单个高杠杆的“影响力点”如何能戏剧性地改变甚至逆转回归斜率的符号。通过计算关键的诊断统计量（如杠杆值和库克距离），你将获得识别和量化这类数据点影响的实用技能。",
            "id": "4952475",
            "problem": "一位生物统计学家正在使用带截距的简单线性回归模型，对标准化每日钠摄入量与标准化收缩压之间的关系进行建模。设模型为 $Y = \\beta_{0} + \\beta_{1} X + \\varepsilon$，其中 $Y$ 是标准化收缩压，$X$ 是标准化每日钠摄入量（z-分数），$\\varepsilon$ 是一个均值为 $0$ 且方差恒定的随机误差项。该生物统计学家从 $5$ 名受试者的数据开始：\n- 受试者 $1$：$(x_{1}, y_{1}) = (-1, -1)$\n- 受试者 $2$：$(x_{2}, y_{2}) = \\left(-\\frac{1}{2}, -\\frac{1}{2}\\right)$\n- 受试者 $3$：$(x_{3}, y_{3}) = (0, 0)$\n- 受试者 $4$：$(x_{4}, y_{4}) = \\left(\\frac{1}{2}, \\frac{1}{2}\\right)$\n- 受试者 $5$：$(x_{5}, y_{5}) = (1, 1)$\n\n她对这 $5$ 名受试者的数据拟合简单线性回归模型，并记录下斜率估计值 $\\hat{\\beta}_{1}^{(5)}$。\n\n然后，她增加第 $6$ 名受试者，其钠摄入量极高但血压较低：\n- 受试者 $6$：$(x_{6}, y_{6}) = (4, -2)$\n\n她对全部 $6$ 名受试者的数据重新拟合模型，并记录下新的斜率 $\\hat{\\beta}_{1}^{(6)}$。使用帽子矩阵和库克距离（Cook's $D$）的标准定义，计算在 $6$ 名受试者拟合模型下，受试者 $6$ 的杠杆值 $h_{66}$ 以及量化受试者 $6$ 影响力的库克距离 $D_{6}$。\n\n提供精确值（不要四舍五入），并将最终答案表示为一个行矩阵，按顺序包含 $\\hat{\\beta}_{1}^{(5)}$、$\\hat{\\beta}_{1}^{(6)}$、$h_{66}$ 和 $D_{6}$。",
            "solution": "该问题陈述是生物统计学中一个定义明确的标准练习，特别是在简单线性回归诊断的应用方面。它提供了所有必要的数据，并清楚地定义了需要计算的量。该问题具有科学依据，客观，并且没有内部矛盾或歧义。因此，这是一个有效的问题。\n\n任务是计算四个量：初始 $5$ 名受试者的回归斜率 $\\hat{\\beta}_{1}^{(5)}$；全部 $6$ 名受试者的斜率 $\\hat{\\beta}_{1}^{(6)}$；第 $6$ 名受试者的杠杆值 $h_{66}$；以及第 $6$ 名受试者的库克距离 $D_{6}$。\n\n**第1部分：计算初始5名受试者的斜率 $\\hat{\\beta}_{1}^{(5)}$**\n\n简单线性回归模型为 $Y = \\beta_{0} + \\beta_{1} X + \\varepsilon$。斜率 $\\hat{\\beta}_{1}$ 的最小二乘估计由以下公式给出：\n$$ \\hat{\\beta}_{1} = \\frac{\\sum_{i=1}^{n} (x_i - \\bar{x})(y_i - \\bar{y})}{\\sum_{i=1}^{n} (x_i - \\bar{x})^2} $$\n对于前 $n=5$ 名受试者，数据为 $(x_1, y_1) = (-1, -1)$、$(x_2, y_2) = (-\\frac{1}{2}, -\\frac{1}{2})$、$(x_3, y_3) = (0, 0)$、$(x_4, y_4) = (\\frac{1}{2}, \\frac{1}{2})$ 和 $(x_5, y_5) = (1, 1)$。\n\n首先，我们计算样本均值 $\\bar{x}^{(5)}$ 和 $\\bar{y}^{(5)}$：\n$$ \\bar{x}^{(5)} = \\frac{1}{5} \\sum_{i=1}^{5} x_i = \\frac{1}{5} \\left( -1 - \\frac{1}{2} + 0 + \\frac{1}{2} + 1 \\right) = \\frac{0}{5} = 0 $$\n$$ \\bar{y}^{(5)} = \\frac{1}{5} \\sum_{i=1}^{5} y_i = \\frac{1}{5} \\left( -1 - \\frac{1}{2} + 0 + \\frac{1}{2} + 1 \\right) = \\frac{0}{5} = 0 $$\n由于均值为零，斜率估计的公式简化为：\n$$ \\hat{\\beta}_{1}^{(5)} = \\frac{\\sum_{i=1}^{5} x_i y_i}{\\sum_{i=1}^{5} x_i^2} $$\n我们计算必要的和：\n$$ \\sum_{i=1}^{5} x_i y_i = (-1)(-1) + \\left(-\\frac{1}{2}\\right)\\left(-\\frac{1}{2}\\right) + (0)(0) + \\left(\\frac{1}{2}\\right)\\left(\\frac{1}{2}\\right) + (1)(1) = 1 + \\frac{1}{4} + 0 + \\frac{1}{4} + 1 = \\frac{5}{2} $$\n$$ \\sum_{i=1}^{5} x_i^2 = (-1)^2 + \\left(-\\frac{1}{2}\\right)^2 + 0^2 + \\left(\\frac{1}{2}\\right)^2 + 1^2 = 1 + \\frac{1}{4} + 0 + \\frac{1}{4} + 1 = \\frac{5}{2} $$\n因此，斜率是：\n$$ \\hat{\\beta}_{1}^{(5)} = \\frac{5/2}{5/2} = 1 $$\n\n**第2部分：计算全部6名受试者的斜率 $\\hat{\\beta}_{1}^{(6)}$**\n\n现在我们加入第 $6$ 名受试者 $(x_6, y_6) = (4, -2)$。数据集有 $n=6$ 个数据点。我们计算新的样本均值：\n$$ \\bar{x}^{(6)} = \\frac{1}{6} \\sum_{i=1}^{6} x_i = \\frac{1}{6} \\left( (\\sum_{i=1}^{5} x_i) + x_6 \\right) = \\frac{1}{6}(0 + 4) = \\frac{4}{6} = \\frac{2}{3} $$\n$$ \\bar{y}^{(6)} = \\frac{1}{6} \\sum_{i=1}^{6} y_i = \\frac{1}{6} \\left( (\\sum_{i=1}^{5} y_i) + y_6 \\right) = \\frac{1}{6}(0 - 2) = -\\frac{2}{6} = -\\frac{1}{3} $$\n我们需要计算 $\\sum_{i=1}^{6} (x_i - \\bar{x}^{(6)})(y_i - \\bar{y}^{(6)})$ 和 $\\sum_{i=1}^{6} (x_i - \\bar{x}^{(6)})^2$。我们可以使用计算公式 $\\sum(x_i-\\bar{x})(y_i-\\bar{y}) = \\sum x_iy_i - n\\bar{x}\\bar{y}$。\n$$ \\sum_{i=1}^{6} x_i y_i = \\left( \\sum_{i=1}^{5} x_i y_i \\right) + x_6 y_6 = \\frac{5}{2} + (4)(-2) = \\frac{5}{2} - 8 = -\\frac{11}{2} $$\n$\\hat{\\beta}_{1}^{(6)}$ 的分子是：\n$$ \\sum_{i=1}^{6} (x_i - \\bar{x}^{(6)})(y_i - \\bar{y}^{(6)}) = \\sum_{i=1}^{6} x_i y_i - 6 \\bar{x}^{(6)} \\bar{y}^{(6)} = -\\frac{11}{2} - 6 \\left(\\frac{2}{3}\\right) \\left(-\\frac{1}{3}\\right) = -\\frac{11}{2} + \\frac{12}{9} = -\\frac{11}{2} + \\frac{4}{3} = \\frac{-33+8}{6} = -\\frac{25}{6} $$\n对于分母，我们使用 $\\sum(x_i-\\bar{x})^2 = \\sum x_i^2 - n\\bar{x}^2$：\n$$ \\sum_{i=1}^{6} x_i^2 = \\left( \\sum_{i=1}^{5} x_i^2 \\right) + x_6^2 = \\frac{5}{2} + 4^2 = \\frac{5}{2} + 16 = \\frac{37}{2} $$\n$\\hat{\\beta}_{1}^{(6)}$ 的分母是：\n$$ \\sum_{i=1}^{6} (x_i - \\bar{x}^{(6)})^2 = \\sum_{i=1}^{6} x_i^2 - 6 (\\bar{x}^{(6)})^2 = \\frac{37}{2} - 6 \\left(\\frac{2}{3}\\right)^2 = \\frac{37}{2} - 6 \\left(\\frac{4}{9}\\right) = \\frac{37}{2} - \\frac{8}{3} = \\frac{111 - 16}{6} = \\frac{95}{6} $$\n新的斜率是：\n$$ \\hat{\\beta}_{1}^{(6)} = \\frac{-25/6}{95/6} = -\\frac{25}{95} = -\\frac{5}{19} $$\n\n**第3部分：计算受试者6的杠杆值 $h_{66}$**\n\n第 $i$ 个数据点的杠杆值 $h_{ii}$ 衡量其对拟合值的影响。对于简单线性回归，它由以下公式给出：\n$$ h_{ii} = \\frac{1}{n} + \\frac{(x_i - \\bar{x})^2}{\\sum_{j=1}^{n} (x_j - \\bar{x})^2} $$\n我们需要为 $n=6$ 数据集中的第 $6$ 名受试者（$i=6$）计算这个值。\n使用第2部分中计算出的值：\n- $n = 6$\n- $x_6 = 4$\n- $\\bar{x}^{(6)} = \\frac{2}{3}$\n- $\\sum_{j=1}^{6} (x_j - \\bar{x}^{(6)})^2 = \\frac{95}{6}$\n首先，我们求 $(x_6 - \\bar{x}^{(6)})^2$：\n$$ (x_6 - \\bar{x}^{(6)})^2 = \\left(4 - \\frac{2}{3}\\right)^2 = \\left(\\frac{12-2}{3}\\right)^2 = \\left(\\frac{10}{3}\\right)^2 = \\frac{100}{9} $$\n现在我们计算 $h_{66}$：\n$$ h_{66} = \\frac{1}{6} + \\frac{100/9}{95/6} = \\frac{1}{6} + \\frac{100}{9} \\cdot \\frac{6}{95} = \\frac{1}{6} + \\frac{100 \\cdot 2}{3 \\cdot 95} = \\frac{1}{6} + \\frac{200}{285} $$\n将第二项的分子和分母同除以 $5$ 来简化：$\\frac{200}{285} = \\frac{40}{57}$。\n$$ h_{66} = \\frac{1}{6} + \\frac{40}{57} = \\frac{19}{114} + \\frac{80}{114} = \\frac{99}{114} $$\n将分数同除以 $3$ 来简化：\n$$ h_{66} = \\frac{33}{38} $$\n\n**第4部分：计算受试者6的库克距离 $D_6$**\n\n库克距离 $D_i$ 衡量删除第 $i$ 个观测值对回归系数的影响。一个标准公式是：\n$$ D_i = \\frac{e_i^2}{p \\cdot \\text{MSE}} \\frac{h_{ii}}{(1-h_{ii})^2} $$\n其中 $e_i$ 是第 $i$ 个点的残差，$p$ 是估计参数的数量（对于 $\\beta_0, \\beta_1$，$p=2$），MSE 是均方误差（Mean Squared Error）。\n\n首先，我们需要 $n=6$ 的拟合模型来计算残差 $e_6$。截距估计值为：\n$$ \\hat{\\beta}_{0}^{(6)} = \\bar{y}^{(6)} - \\hat{\\beta}_{1}^{(6)} \\bar{x}^{(6)} = -\\frac{1}{3} - \\left(-\\frac{5}{19}\\right)\\left(\\frac{2}{3}\\right) = -\\frac{1}{3} + \\frac{10}{57} = \\frac{-19+10}{57} = -\\frac{9}{57} = -\\frac{3}{19} $$\n拟合的回归线是 $\\hat{y} = -\\frac{3}{19} - \\frac{5}{19}x$。\n$x_6=4$ 的拟合值是：\n$$ \\hat{y}_6 = -\\frac{3}{19} - \\frac{5}{19}(4) = -\\frac{3}{19} - \\frac{20}{19} = -\\frac{23}{19} $$\n第 $6$ 名受试者的残差是：\n$$ e_6 = y_6 - \\hat{y}_6 = -2 - \\left(-\\frac{23}{19}\\right) = \\frac{-38+23}{19} = -\\frac{15}{19} $$\n接下来，我们计算误差平方和（SSE）和均方误差（MSE）。\n$$ \\text{SSE} = \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2 = \\sum_{i=1}^{6} (y_i - \\bar{y}^{(6)})^2 - (\\hat{\\beta}_{1}^{(6)})^2 \\sum_{i=1}^{6} (x_i - \\bar{x}^{(6)})^2 $$\n我们需要 $\\sum_{i=1}^{6} (y_i - \\bar{y}^{(6)})^2 = \\sum y_i^2 - n(\\bar{y}^{(6)})^2$。\n$$ \\sum_{i=1}^{6} y_i^2 = \\left(\\sum_{i=1}^{5} y_i^2\\right) + y_6^2 = \\left( (-1)^2 + (-\\frac{1}{2})^2 + 0^2 + (\\frac{1}{2})^2 + 1^2 \\right) + (-2)^2 = \\left(1 + \\frac{1}{4} + 0 + \\frac{1}{4} + 1\\right) + 4 = \\frac{5}{2} + 4 = \\frac{13}{2} $$\n$$ \\sum_{i=1}^{6} (y_i - \\bar{y}^{(6)})^2 = \\frac{13}{2} - 6\\left(-\\frac{1}{3}\\right)^2 = \\frac{13}{2} - 6\\left(\\frac{1}{9}\\right) = \\frac{13}{2} - \\frac{2}{3} = \\frac{39-4}{6} = \\frac{35}{6} $$\n现在，为确保精度，使用一个替代公式计算 SSE：\n$$ \\text{SSE} = \\sum_{i=1}^{6} (y_i - \\bar{y}^{(6)})^2 - \\hat{\\beta}_{1}^{(6)} \\sum_{i=1}^{6} (x_i - \\bar{x}^{(6)})(y_i - \\bar{y}^{(6)}) = \\frac{35}{6} - \\left(-\\frac{5}{19}\\right) \\left(-\\frac{25}{6}\\right) = \\frac{35}{6} - \\frac{125}{114} = \\frac{35 \\times 19}{114} - \\frac{125}{114} = \\frac{665 - 125}{114} = \\frac{540}{114} = \\frac{90}{19} $$\nMSE是SSE除以自由度（$n-p = 6-2 = 4$）：\n$$ \\text{MSE} = \\frac{\\text{SSE}}{n-p} = \\frac{90/19}{4} = \\frac{90}{76} = \\frac{45}{38} $$\n我们有了计算 $D_6$ 的所有组成部分：\n- $e_6^2 = \\left(-\\frac{15}{19}\\right)^2 = \\frac{225}{361}$\n- $p=2$\n- $\\text{MSE} = \\frac{45}{38}$\n- $h_{66} = \\frac{33}{38}$\n- $1-h_{66} = 1 - \\frac{33}{38} = \\frac{5}{38}$\n- $(1-h_{66})^2 = \\left(\\frac{5}{38}\\right)^2 = \\frac{25}{1444}$\n\n将这些值代入库克距离公式：\n$$ D_6 = \\frac{e_6^2}{p \\cdot \\text{MSE}} \\frac{h_{66}}{(1-h_{66})^2} = \\frac{\\frac{225}{361}}{2 \\cdot \\frac{45}{38}} \\cdot \\frac{\\frac{33}{38}}{\\frac{25}{1444}} $$\n我们来计算各个部分。注意 $361 = 19^2$，$38=2 \\times 19$ 以及 $1444=38^2=(2 \\times 19)^2$。\n$$ D_6 = \\frac{\\frac{225}{19^2}}{\\frac{90}{38}} \\cdot \\frac{\\frac{33}{38}}{\\frac{25}{38^2}} = \\left(\\frac{225}{19^2} \\cdot \\frac{38}{90}\\right) \\cdot \\left(\\frac{33}{38} \\cdot \\frac{38^2}{25}\\right) $$\n$$ D_6 = \\left(\\frac{225}{19^2} \\cdot \\frac{2 \\cdot 19}{90}\\right) \\cdot \\left(\\frac{33 \\cdot 38}{25}\\right) = \\left(\\frac{225 \\cdot 2}{19 \\cdot 90}\\right) \\cdot \\left(\\frac{33 \\cdot 38}{25}\\right) $$\n由于 $225 = 2.5 \\times 90$，第一个括号内的部分变为 $\\frac{2.5 \\times 2}{19} = \\frac{5}{19}$。\n$$ D_6 = \\frac{5}{19} \\cdot \\frac{33 \\cdot 38}{25} = \\frac{5}{19} \\cdot \\frac{33 \\cdot (2 \\cdot 19)}{25} = \\frac{5 \\cdot 33 \\cdot 2}{25} = \\frac{10 \\cdot 33}{25} = \\frac{2 \\cdot 33}{5} = \\frac{66}{5} $$\n\n**结果总结**\n所需的四个值为：\n1. $\\hat{\\beta}_{1}^{(5)} = 1$\n2. $\\hat{\\beta}_{1}^{(6)} = -\\frac{5}{19}$\n3. $h_{66} = \\frac{33}{38}$\n4. $D_6 = \\frac{66}{5}$\n这些将按要求以行矩阵的形式呈现。",
            "answer": "$$ \\boxed{ \\begin{pmatrix} 1  -\\frac{5}{19}  \\frac{33}{38}  \\frac{66}{5} \\end{pmatrix} } $$"
        }
    ]
}