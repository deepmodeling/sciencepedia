{
    "hands_on_practices": [
        {
            "introduction": "掌握相关性推断的第一步是能够使用Fisher Z变换为相关系数 $\\rho$ 构建置信区间。这个练习将带你走过标准计算流程，并引入一个针对小样本情况的重要偏差校正方法。通过这个实践，你将学会如何处理实际数据分析中的基本但至关重要的任务，并理解小样本偏差对结果的影响 ()。",
            "id": "4915699",
            "problem": "一项临床研究调查了在一个由$n=12$名独立患者组成的样本中，同时测量的连续生物标志物与连续临床严重程度评分之间的关联。假设配对测量值来自一个具有未知总体相关性$\\rho$的二元正态分布。观测到的样本皮尔逊相关系数为$r=0.70$。使用基于Fisher $z$变换及其小样本偏差性质的相关性大样本推断框架：\n\n1. 使用标准的Fisher $z$方法为$\\rho$构建一个$95\\%$的置信区间（CI）。\n2. 使用偏差校正的Fisher $z$方法为$\\rho$构建一个$95\\%$的CI，该方法移除了变换尺度上的一阶小样本偏差。\n3. 计算两个CI的宽度，并确定每个CI是否包含合理真实相关值$\\rho_0=0.65$。\n4. 将偏差校正CI的宽度与标准CI的宽度之比报告为一个单一数字。将最终报告的比率四舍五入至四位有效数字。",
            "solution": "该问题要求基于来自大小为$n$的样本的相关系数$r$，为总体相关系数$\\rho$构建并比较两种类型的置信区间。其基本理论是Fisher $z$变换，该变换能稳定方差，并将相关系数的抽样分布转换为近似正态分布。\n\n提供的数据和参数如下：\n- 样本量：$n=12$\n- 样本皮尔逊相关系数：$r=0.70$\n- 置信水平：$95\\%$，对应于双侧区间的标准正态临界值$z_{\\alpha/2} = z_{0.025}$。该值为$z_{0.025} \\approx 1.95996$。\n- 用于评估的假设真实相关性：$\\rho_0=0.65$。\n\n这个问题具有科学依据，提法恰当，客观且完整。所有必要信息均已提供，所要求的方法是生物统计学中用于相关系数推断的标准技术。因此，该问题是有效的。\n\n**1. $\\rho$的标准95%置信区间**\n\n标准方法使用Fisher $z$变换，定义为$z = \\arctanh(r)$。变换后的变量$z$近似服从均值为$\\zeta = \\arctanh(\\rho)$，标准差（我们称之为标准误）为$\\sigma_z = \\frac{1}{\\sqrt{n-3}}$的正态分布。\n\n首先，我们计算变换后的样本相关系数$z$：\n$$z = \\arctanh(r) = \\arctanh(0.70) = \\frac{1}{2} \\ln\\left(\\frac{1+0.70}{1-0.70}\\right) = \\frac{1}{2} \\ln\\left(\\frac{1.7}{0.3}\\right) \\approx 0.86730$$\n\n接下来，我们计算标准误$SE(z)$：\n$$SE(z) = \\frac{1}{\\sqrt{n-3}} = \\frac{1}{\\sqrt{12-3}} = \\frac{1}{\\sqrt{9}} = \\frac{1}{3}$$\n\n变换后的总体参数$\\zeta$的$95\\%$置信区间由$z \\pm z_{0.025} \\cdot SE(z)$给出。\n$$CI_{\\zeta} = 0.86730 \\pm 1.95996 \\times \\frac{1}{3} = 0.86730 \\pm 0.65332$$\n这给出$\\zeta$的区间为$[0.21398, 1.52062]$。\n\n为了获得$\\rho$的置信区间，我们将逆变换$\\rho = \\tanh(\\zeta)$应用于$CI_{\\zeta}$的下限和上限。\n$$ \\rho_L = \\tanh(0.21398) \\approx 0.21102 $$\n$$ \\rho_U = \\tanh(1.52062) \\approx 0.90897 $$\n$\\rho$的标准$95\\%$ CI大约为$[0.2110, 0.9090]$。\n\n**2. $\\rho$的偏差校正95%置信区间**\n\nFisher $z$变换存在小样本偏差。$z$的期望值约为$E[z] \\approx \\zeta + \\frac{\\rho}{2(n-1)}$。为了校正这一点，我们可以从我们的样本$z$中减去偏差项的估计值。偏差校正后的$\\zeta$估计值为$z_{adj} = z - \\frac{r}{2(n-1)}$。\n\n首先，我们计算估计的偏差：\n$$ \\text{Bias}(z) \\approx \\frac{r}{2(n-1)} = \\frac{0.70}{2(12-1)} = \\frac{0.70}{22} \\approx 0.03182 $$\n\n接下来，我们求出调整后的$z$值：\n$$ z_{adj} = 0.86730 - 0.03182 = 0.83548 $$\n\n现在，$\\zeta$的置信区间以$z_{adj}$为中心，使用相同的标准误和误差范围：\n$$ CI_{\\zeta, corr} = z_{adj} \\pm z_{0.025} \\cdot SE(z) = 0.83548 \\pm 0.65332 $$\n这给出偏差校正后$\\zeta$的区间为$[0.18216, 1.48880]$。\n\n我们将这些界限变换回$\\rho$尺度：\n$$ \\rho_{L, corr} = \\tanh(0.18216) \\approx 0.18025 $$\n$$ \\rho_{U, corr} = \\tanh(1.48880) \\approx 0.90302 $$\n偏差校正的$95\\%$ CI for $\\rho$ 大约为 $[0.1803, 0.9030]$。\n\n**3. CI宽度及是否包含$\\rho_0 = 0.65$**\n\n我们计算两个置信区间的宽度。\n标准CI的宽度为：\n$$ W_{std} = \\rho_U - \\rho_L = 0.90897 - 0.21102 = 0.69795 $$\n\n偏差校正CI的宽度为：\n$$ W_{corr} = \\rho_{U, corr} - \\rho_{L, corr} = 0.90302 - 0.18025 = 0.72277 $$\n\n校正将$z$尺度上的区间中心向$0$移动。由于$\\tanh$函数的非线性性质（它在$z=0$附近不那么陡峭），这种移动导致在$\\rho$尺度上产生一个更宽的置信区间。\n\n接下来，我们检查每个区间是否包含$\\rho_0=0.65$。\n- 标准CI：$[0.2110, 0.9090]$。因为$0.2110 \\le 0.65 \\le 0.9090$，所以$\\rho_0$包含在标准CI中。\n- 偏差校正CI：$[0.1803, 0.9030]$。因为$0.1803 \\le 0.65 \\le 0.9030$，所以$\\rho_0$也包含在偏差校正的CI中。\n\n**4. CI宽度之比**\n\n最后，我们计算偏差校正CI的宽度与标准CI的宽度之比。\n$$ \\text{Ratio} = \\frac{W_{corr}}{W_{std}} = \\frac{0.72277}{0.69795} \\approx 1.03556 $$\n\n四舍五入到四位有效数字，该比率为$1.036$。",
            "answer": "$$\n\\boxed{1.036}\n$$"
        },
        {
            "introduction": "Fisher Z变换的有效性很大程度上依赖于数据服从二元正态分布的假设。这个练习将探讨一个关键的实际问题：当数据明显不满足正态性时我们该怎么办？通过这个思想实验，你将学会如何选择一种原则性的数据转换策略，从而使得经典的推断工具能够被合理地应用 ()。",
            "id": "4915681",
            "problem": "一个生物统计学团队研究两种血清生物标志物（表示为 $X$ 和 $Y$）之间的关联，这两种标志物是在 $n=120$ 名独立患者中测量的。探索性分析显示，每个边缘分布都是连续的、严格为正的，并且具有明显的重尾右偏。散点图表明存在单调递增的关联，但由于偏度，其等高线呈非椭圆形。研究人员希望使用经典的 Fisher $z$ 方法报告 $X$ 和 $Y$ 的 Pearson 相关性的 $95\\%$ 置信区间，但他们担心该方法所依赖的常规大样本正态近似需要近似的双变量正态性，而这一点在此处是值得怀疑的。\n\n从以下基本事实出发：(i) Pearson 相关性衡量线性关联，并且对于非线性边缘变换不具有不变性；(ii) Fisher 基于 $z$ 的推断是在双变量正态模型下导出的，在该模型中，经 Fisher 变换的样本相关性近似服从正态分布，其方差仅取决于 $n$；以及 (iii) 严格单调的边缘变换会保留基于秩次的依赖结构，但会改变高阶矩和边缘形状。请选择最合适的单一变换策略，以证明在这种非正态设置下使用基于 Fisher $z$ 的推断是合理的。你的选择必须基于一个原则，即在保持潜在单调依赖性的同时，使变换后的边缘分布近似正态，从而使 Fisher $z$ 方法背后的假设得到近似满足。\n\n哪个选项最能实现这一目标并提供正确的理由？\n\nA. 对每个边缘应用基于秩次的逆正态变换（边缘正态得分），然后在变换后的变量上计算 Pearson 相关性，并对该相关性应用 Fisher $z$ 变换。理由：严格单调、基于秩次的边缘变换保留了 copula（依赖结构）。在高斯 copula 模型下，变换后的数据对具有近似双变量正态的边缘和椭圆依赖性，因此方差近似为 $1/(n-3)$ 的 Fisher $z$ 推断是合适的。\n\nB. 将 $X$ 和 $Y$ 标准化，使其样本均值为 $0$，样本方差为 $1$，然后计算 Pearson 相关性并应用 Fisher $z$ 变换。理由：标准化与中心极限定理相结合，使数据近似正态，从而使 Fisher $z$ 方法合法化。\n\nC. 用 Spearman 秩相关替换 Pearson 相关性，以减少对边缘非正态性的敏感度，然后对 Spearman 相关性应用 Fisher $z$ 变换。理由：秩次对偏度具有稳健性，并且 Fisher $z$ 变换适用于任何相关性度量。\n\nD. 对 $X$ 和 $Y$ 应用相同的严格递增非线性变换（例如，对数变换），直到直方图在视觉上看起来对称，然后计算 Pearson 相关性并应用 Fisher $z$ 变换。理由：任何单调变换都保留相关性，因此使直方图看起来对称足以使 Fisher $z$ 方法有效。\n\nE. 保持数据在原始尺度上，计算 Pearson 相关性，但使用非参数自助法来估计 Fisher $z$ 统计量的抽样分布。理由：自助法使得 Fisher $z$ 统计量在任何边缘分布下都近似正态，因此常规的 Fisher 区间是有效的。",
            "solution": "该问题要求找到最合适的变换策略，以证明使用 Fisher $z$ 变换来构建两个生物标志物 $X$ 和 $Y$ 之间 Pearson 相关性的置信区间是合理的。数据包含 $n=120$ 对观测值，且已知边缘分布是非正态的（连续、严格为正、右偏、重尾）。\n\n首先，我们回顾一下 Fisher $z$ 变换的基本原理。给定从一个双变量正态分布（总体相关性为 $\\rho$）中抽取的样本量为 $n$ 的样本计算出的 Pearson 样本相关系数 $r$，Fisher $z$ 变换定义为：\n$$z = \\frac{1}{2} \\ln \\left( \\frac{1+r}{1-r} \\right) = \\text{arctanh}(r)$$\n关键结果是，在双变量正态性假设下，$z$ 的抽样分布近似为正态分布，即使对于较小的 $n$ 也是如此：\n$$z \\sim \\mathcal{N}\\left( \\text{arctanh}(\\rho), \\frac{1}{n-3} \\right)$$\n这允许为 $\\text{arctanh}(\\rho)$ 构建一个 $(1-\\alpha) \\times 100\\%$ 的置信区间，形式为 $z \\pm z_{\\alpha/2} \\frac{1}{\\sqrt{n-3}}$，然后可以通过逆变换得到 $\\rho$ 的置信区间。\n\n这里的关键问题是，题目明确指出 $X$ 和 $Y$ 的数据是非正态的，这使得该程序所依赖的基本假设失效。因此，目标是找到一种变换策略，使数据尽可能地符合双变量正态假设，同时保留其潜在的依赖结构。\n\n根据 Sklar 定理，任何连续的多元分布都可以分解为其边缘分布和一个描述变量间依赖结构的 copula。对分布的边缘应用严格单调的变换不会改变其 copula。因此，我们可以将边缘分布改变为更理想的形式（例如，正态分布），同时保留其内在的依赖结构。\n\n问题指出存在“单调递增关联”。我们寻求一种变换，既能保留这种基于秩次的依赖结构，又能使边缘分布呈正态性。实现这一目标的一个强大方法是基于秩次的逆正态变换，也称为获取正态得分。对于每个变量，比如 $X$，观测值 $x_1, x_2, \\dots, x_n$ 被其正态得分所取代。这种变换的一个常见版本是 $x'_i = \\Phi^{-1}\\left(\\frac{\\text{rank}(x_i)}{n+1}\\right)$，其中 $\\Phi^{-1}$ 是标准正态分布的分位数函数（逆累积分布函数），分母调整为 $n+1$ 以避免在 $1$ 处求值。经过此变换后，新的变量，比如 $X'$ 和 $Y'$，其边缘分布根据构造将近似为标准正态分布。\n\n如果 $(X, Y)$ 的原始依赖结构 (copula) 是一个高斯 copula，那么变换后的变量 $(X', Y')$ 将近似服从双变量正态分布。这是应用 Fisher $z$ 变换的理想情景。然后，我们可以计算变换后数据的 Pearson 相关性 $r' = \\text{corr}(X', Y')$，并继续进行经典的 Fisher $z$ 推断，因为它的假设现在已近似满足。\n\n有了这个理论框架，我们现在来评估给定的选项。\n\nA. 对每个边缘应用基于秩次的逆正态变换（边缘正态得分），然后在变换后的变量上计算 Pearson 相关性，并对该相关性应用 Fisher $z$ 变换。理由：严格单调、基于秩次的边缘变换保留了 copula（依赖结构）。在高斯 copula 模型下，变换后的数据对具有近似双变量正态的边缘和椭圆依赖性，因此方差近似为 $1/(n-3)$ 的 Fisher $z$ 推断是合适的。\n这个选项精确地描述了上面推导出的过程。该变换诱导了近似的边缘正态性。其理由正确地指出，这种基于秩次的单调变换保留了 copula。它正确地注意到，如果底层的 copula 是高斯 copula，变换后的数据将近似呈双变量正态分布，这正是经典 Fisher $z$ 方法有效所需的确切条件。那么，近似为 $1/(n-3)$ 的方差是合适的。这是一个理论上合理且在统计学上符合原则的方法。\n结论：**正确**。\n\nB. 将 $X$ 和 $Y$ 标准化，使其样本均值为 $0$，样本方差为 $1$，然后计算 Pearson 相关性并应用 Fisher $z$ 变换。理由：标准化与中心极限定理相结合，使数据近似正态，从而使 Fisher $z$ 方法合法化。\n这个选项存在根本性缺陷。标准化是一种线性变换，$X_{\\text{std}} = (X - \\mu_X)/\\sigma_X$。线性变换不会改变分布的形状；一个右偏分布在标准化后仍然是右偏的。其理由援引了中心极限定理 (CLT)，该定理指出*样本均值*的分布随着样本量的增加而趋于正态。CLT 并未说明数据本身的分布。因此，该程序未能解决边缘分布的非正态性问题。\n结论：**不正确**。\n\nC. 用 Spearman 秩相关替换 Pearson 相关性，以减少对边缘非正态性的敏感度，然后对 Spearman 相关性应用 Fisher $z$ 变换。理由：秩次对偏度具有稳健性，并且 Fisher $z$ 变换适用于任何相关性度量。\n虽然改用 Spearman 秩相关 $r_S$ 是一种有效的稳健策略，但后续步骤的理由是错误的。Fisher $z$ 变换及其相关的方差公式 $1/(n-3)$ 是专门为在双变量正态性假设下的 Pearson 相关系数 $r$ 推导出来的。它并不普遍适用于任何相关性度量。虽然存在针对 $r_S$ 的类似方差稳定变换，但其方差近似为 $1.06/(n-3)$，而不是 $1/(n-3)$。直接将经典的 Fisher 机制应用于 $r_S$ 是不正确的。\n结论：**不正确**。\n\nD. 对 $X$ 和 $Y$ 应用相同的严格递增非线性变换（例如，对数变换），直到直方图在视觉上看起来对称，然后计算 Pearson 相关性并应用 Fisher $z$ 变换。理由：任何单调变换都保留相关性，因此使直方图看起来对称足以使 Fisher $z$ 方法有效。\n该选项的理由中有两个重大错误。首先，“任何单调变换都保留相关性”是错误的。Pearson 相关性衡量的是*线性*关联，并且在非线性变换下不是不变的；即，通常情况下，对于非线性函数 $g$，$\\text{corr}(g(X), g(Y)) \\ne \\text{corr}(X,Y)$。保留不变的是基于秩次的相关性。其次，“使直方图看起来对称足以”也是错误的。实现边缘正态性是双变量正态性的一个必要但不充分的条件。依赖结构 (copula) 可能仍然是非高斯的。选项 A 的方法比这种临时的视觉方法更有原则性，且此处的理由在事实上是不正确的。\n结论：**不正确**。\n\nE. 保持数据在原始尺度上，计算 Pearson 相关性，但使用非参数自助法来估计 Fisher $z$ 统计量的抽样分布。理由：自助法使得 Fisher $z$ 统计量在任何边缘分布下都近似正态，因此常规的 Fisher 区间是有效的。\n这个选项描述了一个有效的替代推断程序（自助法），但它没有完成指定的任务，即找到一种*证明使用经典 Fisher's z 推断是合理的*变换策略。此外，其提供的理由具有误导性。自助法并不会“使”统计量正态化；它提供的是对统计量真实抽样分布的一个经验近似，无论其形状如何。然后，人们通常会使用这个经验分布的百分位数来构建置信区间（例如，百分位数自助区间），该区间可以是不对称的，并且与依赖于对称正态近似的“常规 Fisher 区间”不同。自助法是绕过经典方法假设的一种方式，而不是满足这些假设的一种方式。\n结论：**不正确**。\n\n总之，选项 A 提出了唯一与现代统计理论完全一致、能够处理这一特定问题的方法和理由。它正确地识别了一种有原则的变换，直接解决了违反正态性假设的问题，从而使后续使用经典 Fisher $z$ 程序变得合理。",
            "answer": "$$\\boxed{A}$$"
        },
        {
            "introduction": "虽然Fisher Z变换是经典的频率派统计工具，但现代统计学也提供了其他的推断框架。这个练习将向你介绍一种贝叶斯方法来解决同样的问题，它将先验知识与数据证据相结合，形成对相关系数的后验认知。通过完成这个计算任务，你将了解Fisher Z变换如何在一个不同的推断范式中发挥作用，并将其结果与标准方法进行比较 ()。",
            "id": "4915717",
            "problem": "您正在分析二元正态模型假设下两个连续生物标志物之间的相关性。设未知总体相关系数为 $\\rho$，从大小为 $n$ 的样本中观测到的样本相关系数为 $r$。在大样本中，Fisher z 变换用于稳定样本相关系数的抽样分布。考虑一个贝叶斯框架，其中对变换后的参数 $\\theta = \\operatorname{arctanh}(\\rho)$ 指定一个均值为 $\\mu_0$、方差为 $\\sigma_0^2$ 的正态先验。假设 Fisher 变换后的统计量具有近似高斯行为，其方差取决于 $n$。\n\n您的任务是实现一个完整的分析，过程如下，并严格遵守从核心定义和经过充分检验的近似推导，而不是使用任何简化公式：\n\n- 从二元正态模型和 Fisher z 变换的定义出发，形式化地构建变换后数量的似然，并将其与指定的正态先验结合，以获得 $\\theta$ 的后验分布。\n- 使用得到的 $\\theta$ 的后验分布，通过对 $\\theta$ 的后验分布下的期望进行数值计算，求出 $\\rho = \\tanh(\\theta)$ 的后验均值。\n- 独立地，通过对应用于观测样本相关系数 $r$ 的 Fisher z 变换进行反演，计算 $\\rho$ 的点估计。\n- 对每个测试用例，报告一个包含三个条目的列表，其中包含 $\\rho$ 的后验均值、$\\rho$ 的反变换估计以及它们的差值，所有值均为实数。\n\n实现您的程序来处理以下测试集，其中每个元组为 $(n, r, \\mu_0, \\sigma_0)$，所有量均为纯数学单位（不涉及物理单位）：\n\n- 测试用例 1：$(n=40, r=0.35, \\mu_0=0, \\sigma_0=1.0)$\n- 测试用例 2：$(n=10, r=0.95, \\mu_0=0, \\sigma_0=1.0)$\n- 测试用例 3：$(n=40, r=-0.35, \\mu_0=0, \\sigma_0=1.0)$\n- 测试用例 4：$(n=40, r=0.35, \\mu_0=0, \\sigma_0=1000.0)$\n- 测试用例 5：$(n=40, r=0.35, \\mu_0=0, \\sigma_0=0.31622776601683794)$\n\n您的程序应生成单行输出，包含一个用方括号括起来的逗号分隔列表。外层列表中的每个元素对应一个测试用例，并且必须是一个三元列表 $[\\text{posterior\\_mean\\_}\\rho,\\;\\text{back\\_transformed\\_}\\rho,\\;\\text{difference}]$。例如，对于两个测试用例，输出必须类似于 $[[x_1,y_1,z_1],[x_2,y_2,z_2]]$，所有条目均为实数（浮点值）。",
            "solution": "用户提供的问题陈述已经过分析，并被认为是有效的。它在科学上基于生物统计学的既定原则，特别是使用 Fisher z 变换对相关系数进行贝叶斯推断。该问题是适定的，所有必要信息均已提供，或可从标准统计近似的上下文中合理推断。\n\n解决方案按以下步骤进行：首先，我们通过为变换后的参数定义似然和先验来形式化贝叶斯模型。其次，我们推导后验分布。第三，我们详细说明通过数值积分计算原始相关参数 $\\rho$ 的后验均值的过程。最后，我们确定用于比较的点估计以及需要报告的差值。\n\n### 1. 贝叶斯模型构建\n\n设 $\\rho$ 为总体相关系数，是来自二元正态分布的一个感兴趣的参数。设 $r$ 是从大小为 $n$ 的样本中计算出的样本相关系数。Fisher z 变换对参数定义为 $\\theta = \\operatorname{arctanh}(\\rho)$，对统计量定义为 $z = \\operatorname{arctanh}(r)$。\n\n**似然函数**\n\n问题陈述要求假设 Fisher 变换后的统计量具有近似高斯行为。大样本理论中一个公认的结果是，$z$ 近似服从正态分布，其均值等于变换后的总体参数 $\\theta$，方差是样本量 $n$ 的函数。该方差的标准、经过充分检验的近似值为 $\\frac{1}{n-3}$。此近似在 $n > 3$ 时有效。\n\n因此，$z$ 在给定 $\\theta$ 下的抽样分布为：\n$$\nz \\mid \\theta, n \\sim \\mathcal{N}\\left(\\theta, \\frac{1}{n-3}\\right)\n$$\n$\\theta$ 的似然函数是该正态分布的概率密度函数（PDF），视为 $\\theta$ 的函数：\n$$\nL(\\theta \\mid z, n) \\propto \\exp\\left( -\\frac{(z - \\theta)^2}{2 \\left(\\frac{1}{n-3}\\right)} \\right) = \\exp\\left( -\\frac{n-3}{2}(z - \\theta)^2 \\right)\n$$\n这可以解释为 $\\theta$ 的高斯似然，其中“数据”是 $z$，方差已知为 $\\frac{1}{n-3}$。\n\n**先验分布**\n\n问题指定了变换后参数 $\\theta$ 的一个正态先验分布：\n$$\n\\theta \\sim \\mathcal{N}(\\mu_0, \\sigma_0^2)\n$$\n先验 PDF 为：\n$$\np(\\theta) \\propto \\exp\\left( -\\frac{(\\theta - \\mu_0)^2}{2\\sigma_0^2} \\right)\n$$\n\n### 2. 后验分布的推导\n\n$\\theta$ 的后验分布通过应用贝叶斯定理获得：\n$$\np(\\theta \\mid z, n) \\propto L(\\theta \\mid z, n) \\cdot p(\\theta)\n$$\n$$\np(\\theta \\mid z, n) \\propto \\exp\\left( -\\frac{n-3}{2}(\\theta-z)^2 \\right) \\cdot \\exp\\left( -\\frac{(\\theta-\\mu_0)^2}{2\\sigma_0^2} \\right)\n$$\n两个高斯 PDF（或与其成比例的函数）的乘积是另一个与高斯 PDF 成比例的函数。我们可以通过检查指数项来找到得到的后验正态分布 $\\theta \\mid z, n \\sim \\mathcal{N}(\\mu_{\\text{post}}, \\sigma_{\\text{post}}^2)$ 的参数。指数项是 $\\theta$ 的一个二次函数：\n$$\n-\\frac{1}{2} \\left[ (n-3)(\\theta-z)^2 + \\frac{(\\theta-\\mu_0)^2}{\\sigma_0^2} \\right]\n$$\n展开 $\\theta$ 的二次项：\n$$\n\\theta^2\\left(n-3 + \\frac{1}{\\sigma_0^2}\\right) - 2\\theta\\left((n-3)z + \\frac{\\mu_0}{\\sigma_0^2}\\right) + \\text{const.}\n$$\n此表达式的形式为 $\\frac{\\theta^2}{ \\sigma_{\\text{post}}^2} - \\frac{2\\theta\\mu_{\\text{post}}}{ \\sigma_{\\text{post}}^2} + \\text{const.}$。通过匹配项，我们可以确定后验精度（方差的倒数）和均值。\n\n后验精度 $\\frac{1}{\\sigma_{\\text{post}}^2}$ 是数据精度和先验精度的和：\n$$\n\\frac{1}{\\sigma_{\\text{post}}^2} = (n-3) + \\frac{1}{\\sigma_0^2} \\quad \\implies \\quad \\sigma_{\\text{post}}^2 = \\left( (n-3) + \\frac{1}{\\sigma_0^2} \\right)^{-1}\n$$\n后验均值 $\\mu_{\\text{post}}$ 是数据估计值 $z$ 和先验均值 $\\mu_0$ 的精度加权平均：\n$$\n\\mu_{\\text{post}} = \\sigma_{\\text{post}}^2 \\left( (n-3)z + \\frac{\\mu_0}{\\sigma_0^2} \\right)\n$$\n因此，$\\theta$ 的后验分布被完全刻画为 $\\mathcal{N}(\\mu_{\\text{post}}, \\sigma_{\\text{post}}^2)$。\n\n### 3. $\\rho$ 的后验均值计算\n\n我们主要感兴趣的量是原始相关参数 $\\rho$ 的后验均值。由于 $\\rho = \\tanh(\\theta)$，我们需要计算 $\\tanh(\\theta)$ 关于 $\\theta$ 后验分布的期望：\n$$\nE[\\rho \\mid z, n] = E[\\tanh(\\theta) \\mid z, n] = \\int_{-\\infty}^{\\infty} \\tanh(\\theta) \\cdot p(\\theta \\mid z, n) \\, d\\theta\n$$\n代入后验 PDF，我们得到：\n$$\nE[\\rho \\mid z, n] = \\int_{-\\infty}^{\\infty} \\tanh(\\theta) \\frac{1}{\\sqrt{2\\pi\\sigma_{\\text{post}}^2}} \\exp\\left(-\\frac{(\\theta - \\mu_{\\text{post}})^2}{2\\sigma_{\\text{post}}^2}\\right) \\, d\\theta\n$$\n该积分没有闭式解析解。根据指示，必须对其进行数值评估。我们将使用数值积分法为每个测试用例计算此值。\n\n### 4. 反变换估计与差值\n\n为了比较，我们计算一个直接从样本相关系数 $r$ 导出的 $\\rho$ 的点估计。这涉及对 $r$ 应用 Fisher 变换，然后立即对其进行反演：\n$$\n\\hat{\\rho}_{\\text{bt}} = \\tanh(\\operatorname{arctanh}(r)) = r\n$$\n这其实就是样本相关系数本身，它在频率学派框架中作为最大似然估计。\n\n最后，贝叶斯后验均值与此反变换估计之间的差值计算如下：\n$$\n\\text{Difference} = E[\\rho \\mid z, n] - \\hat{\\rho}_{\\text{bt}}\n$$\n这个差值量化了先验分布对 $\\rho$ 最终估计值的影响。\n\n实施过程将首先为每个测试用例计算 $z = \\operatorname{arctanh}(r)$，然后计算后验参数 $\\mu_{\\text{post}}$ 和 $\\sigma_{\\text{post}}^2$，最后使用数值积分来找到 $E[\\rho \\mid z, n]$。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nimport scipy.stats\nimport scipy.integrate\n\ndef solve():\n    \"\"\"\n    Computes Bayesian and frequentist-style estimates for the correlation\n    coefficient based on Fisher's z-transformation framework.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    # Each tuple is (n, r, mu_0, sigma_0)\n    test_cases = [\n        (40, 0.35, 0, 1.0),\n        (10, 0.95, 0, 1.0),\n        (40, -0.35, 0, 1.0),\n        (40, 0.35, 0, 1000.0),\n        (40, 0.35, 0, 0.31622776601683794),\n    ]\n\n    results = []\n    \n    for case in test_cases:\n        n, r, mu_0, sigma_0 = case\n\n        # 1. Transform the sample correlation coefficient r\n        # This is the \"observed data\" in the transformed space.\n        z = np.arctanh(r)\n\n        # 2. Derive the parameters of the posterior distribution for theta.\n        # The likelihood variance is 1 / (n-3).\n        # The prior variance is sigma_0^2.\n        \n        # Check for n > 3, as the variance approx. requires it.\n        # All test cases satisfy this.\n        if n = 3:\n            # This case is not in the test suite but is a necessary check.\n            raise ValueError(\"Sample size n must be greater than 3.\")\n\n        data_precision = n - 3\n        prior_precision = 1 / (sigma_0**2)\n\n        # Posterior precision is the sum of data and prior precisions.\n        posterior_precision = data_precision + prior_precision\n        posterior_variance = 1 / posterior_precision\n\n        # Posterior mean is the precision-weighted average of the data\n        # estimate (z) and the prior mean (mu_0).\n        posterior_mean = posterior_variance * (data_precision * z + prior_precision * mu_0)\n        \n        posterior_std_dev = np.sqrt(posterior_variance)\n\n        # 3. Compute the posterior mean of rho = tanh(theta) by numerical integration.\n        # The expectation is E[tanh(theta)] where theta ~ N(posterior_mean, posterior_variance).\n        \n        # Define the integrand: tanh(theta) * posterior_pdf(theta)\n        integrand = lambda theta: np.tanh(theta) * scipy.stats.norm.pdf(\n            theta, loc=posterior_mean, scale=posterior_std_dev\n        )\n\n        # Numerically integrate from -inf to +inf\n        posterior_mean_rho, _ = scipy.integrate.quad(integrand, -np.inf, np.inf)\n\n        # 4. Compute the back-transformed point estimate of rho.\n        # This is simply tanh(arctanh(r)) = r.\n        back_transformed_rho = r\n        \n        # 5. Compute the difference.\n        difference = posterior_mean_rho - back_transformed_rho\n        \n        results.append([posterior_mean_rho, back_transformed_rho, difference])\n    \n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        }
    ]
}