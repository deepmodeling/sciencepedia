{
    "hands_on_practices": [
        {
            "introduction": "While a significant $F$-statistic in a one-way ANOVA indicates that not all group means are equal, it doesn't quantify the magnitude of the differences. To understand the practical importance of an effect, we calculate an effect size like eta-squared ($\\eta^2$). This first exercise will guide you through deriving and calculating $\\eta^2$ directly from a reported $F$-statistic and its degrees of freedom, demonstrating how much of the data's variability is captured by the group differences .",
            "id": "4909886",
            "problem": "A biostatistics team conducts a one-way analysis of variance (ANOVA) to compare a continuous biomarker across $3$ treatment groups. The published summary reports an $F$-statistic of $F=12.0$ with numerator degrees of freedom (degrees of freedom for the effect) $df_{\\text{effect}}=2$ and denominator degrees of freedom (degrees of freedom for the error) $df_{\\text{error}}=40$. Starting from the foundational definitions of analysis of variance (ANOVA)—namely, that the sum of squares for the effect and for the error partition the modeled variability, that the mean square (MS) for a source equals its sum of squares divided by its degrees of freedom, and that the $F$-statistic equals the ratio of the mean square for the effect to the mean square for the error—derive the partial eta-squared $\\eta_{p}^{2}$ for the reported effect from first principles. Interpret partial eta-squared $\\eta_{p}^{2}$ as the proportion of model variability attributable to the effect when considering only the effect and error components.\n\nThen, to illustrate the relationship between the $F$-statistic, degrees of freedom, and the sums of squares, adopt an arbitrary scaling by setting the error mean square to $MS_{\\text{error}}=1$, and under this scaling back-calculate the corresponding $SS_{\\text{effect}}$ and $SS_{\\text{error}}$ that are consistent with the reported $F$, $df_{\\text{effect}}$, and $df_{\\text{error}}$. Use these to verify your derived expression for $\\eta_{p}^{2}$.\n\nReport only the numerical value of $\\eta_{p}^{2}$ as your final answer. Express your final answer as a decimal and round to four significant figures.",
            "solution": "The problem will be validated by first extracting the given information and then assessing its scientific validity and completeness.\n\n**Step 1: Extract Givens**\n-   The analysis is a one-way analysis of variance (ANOVA).\n-   Number of treatment groups: $3$.\n-   $F$-statistic: $F=12.0$.\n-   Numerator degrees of freedom (effect): $df_{\\text{effect}}=2$.\n-   Denominator degrees of freedom (error): $df_{\\text{error}}=40$.\n-   Foundational definitions:\n    -   The sum of squares for the effect ($SS_{\\text{effect}}$) and the sum of squares for the error ($SS_{\\text{error}}$) partition the modeled variability.\n    -   Mean Square (MS): $MS = \\frac{SS}{df}$.\n    -   $F$-statistic: $F = \\frac{MS_{\\text{effect}}}{MS_{\\text{error}}}$.\n-   Definition of partial eta-squared ($\\eta_p^2$): the proportion of model variability attributable to the effect when considering only the effect and error components. This implies $\\eta_p^2 = \\frac{SS_{\\text{effect}}}{SS_{\\text{effect}} + SS_{\\text{error}}}$.\n-   A verification task is required: Set $MS_{\\text{error}}=1$, back-calculate $SS_{\\text{effect}}$ and $SS_{\\text{error}}$, and use them to confirm the $\\eta_p^2$ value.\n-   The final answer for $\\eta_p^2$ must be a decimal rounded to four significant figures.\n\n**Step 2: Validate Using Extracted Givens**\nThe problem is scientifically grounded, well-posed, and objective.\n-   **Scientific Grounding:** The problem is based on the fundamental principles of ANOVA, a standard and universally accepted statistical method. The provided definitions for $MS$, $F$, and $\\eta_p^2$ are correct. The number of groups ($k=3$) is consistent with the degrees of freedom for the effect, as $df_{\\text{effect}} = k-1 = 3-1 = 2$.\n-   **Well-Posedness:** All necessary information ($F$, $df_{\\text{effect}}$, $df_{\\text{error}}$) is provided to derive a unique value for $\\eta_p^2$. The instructions are clear and lead to a single, verifiable solution.\n-   **Objectivity:** The problem is posed using precise, standard statistical terminology, free of any subjective or ambiguous language.\n\n**Step 3: Verdict and Action**\nThe problem is deemed **valid**. The solution process will now proceed.\n\nThe objective is to derive an expression for partial eta-squared, $\\eta_p^2$, in terms of the $F$-statistic and its associated degrees of freedom, and then to calculate its value.\n\nFrom the provided definition, partial eta-squared is the proportion of the sum of squares of the effect relative to the sum of the sum of squares of the effect and the sum of squares of the error. Mathematically, this is:\n$$ \\eta_p^2 = \\frac{SS_{\\text{effect}}}{SS_{\\text{effect}} + SS_{\\text{error}}} $$\nTo express this in terms of the given quantities, we use the foundational definitions of ANOVA. The $F$-statistic is the ratio of the mean square for the effect to the mean square for the error:\n$$ F = \\frac{MS_{\\text{effect}}}{MS_{\\text{error}}} $$\nThe mean squares are, in turn, defined as the sums of squares divided by their respective degrees of freedom:\n$$ MS_{\\text{effect}} = \\frac{SS_{\\text{effect}}}{df_{\\text{effect}}} \\quad \\text{and} \\quad MS_{\\text{error}} = \\frac{SS_{\\text{error}}}{df_{\\text{error}}} $$\nSubstituting these into the expression for the $F$-statistic gives:\n$$ F = \\frac{SS_{\\text{effect}} / df_{\\text{effect}}}{SS_{\\text{error}} / df_{\\text{error}}} $$\nFrom this equation, we can isolate the ratio of the sums of squares:\n$$ \\frac{SS_{\\text{effect}}}{SS_{\\text{error}}} = F \\cdot \\frac{df_{\\text{effect}}}{df_{\\text{error}}} $$\nNow, we return to the definition of $\\eta_p^2$. To relate it to this ratio, we can divide the numerator and the denominator of the $\\eta_p^2$ expression by $SS_{\\text{error}}$:\n$$ \\eta_p^2 = \\frac{SS_{\\text{effect}} / SS_{\\text{error}}}{(SS_{\\text{effect}} / SS_{\\text{error}}) + (SS_{\\text{error}} / SS_{\\text{error}})} = \\frac{SS_{\\text{effect}} / SS_{\\text{error}}}{(SS_{\\text{effect}} / SS_{\\text{error}}) + 1} $$\nSubstituting the expression for the ratio of sums of squares we derived from the $F$-statistic:\n$$ \\eta_p^2 = \\frac{F \\cdot \\frac{df_{\\text{effect}}}{df_{\\text{error}}}}{F \\cdot \\frac{df_{\\text{effect}}}{df_{\\text{error}}} + 1} $$\nTo simplify this expression, we multiply the numerator and the denominator by $df_{\\text{error}}$:\n$$ \\eta_p^2 = \\frac{F \\cdot df_{\\text{effect}}}{F \\cdot df_{\\text{effect}} + df_{\\text{error}}} $$\nThis is the general formula for partial eta-squared derived from first principles.\n\nWe can now substitute the given numerical values: $F=12.0$, $df_{\\text{effect}}=2$, and $df_{\\text{error}}=40$.\n$$ \\eta_p^2 = \\frac{12.0 \\times 2}{(12.0 \\times 2) + 40} = \\frac{24}{24 + 40} = \\frac{24}{64} $$\nSimplifying the fraction gives:\n$$ \\eta_p^2 = \\frac{3 \\times 8}{8 \\times 8} = \\frac{3}{8} = 0.375 $$\n\nNext, we perform the requested verification. We adopt an arbitrary scaling by setting the error mean square to $MS_{\\text{error}} = 1$.\nUsing the definition of the $F$-statistic, we can find the corresponding mean square for the effect:\n$$ MS_{\\text{effect}} = F \\cdot MS_{\\text{error}} = 12.0 \\times 1 = 12.0 $$\nNow, we back-calculate the sums of squares that are consistent with these mean squares and the given degrees of freedom:\n$$ SS_{\\text{effect}} = MS_{\\text{effect}} \\cdot df_{\\text{effect}} = 12.0 \\times 2 = 24 $$\n$$ SS_{\\text{error}} = MS_{\\text{error}} \\cdot df_{\\text{error}} = 1 \\times 40 = 40 $$\nUsing these sums of squares, we can calculate $\\eta_p^2$ directly from its fundamental definition:\n$$ \\eta_p^2 = \\frac{SS_{\\text{effect}}}{SS_{\\text{effect}} + SS_{\\text{error}}} = \\frac{24}{24 + 40} = \\frac{24}{64} = 0.375 $$\nThis result matches the value calculated using the derived formula, thereby verifying its correctness.\n\nThe problem requires the final answer to be rounded to four significant figures. The exact value is $0.375$. To express this with four significant figures, we write it as $0.3750$.\nThis value of $\\eta_p^2 = 0.3750$ means that $37.5\\%$ of the variability in the model (composed of effect and error) is attributable to the treatment group effect.",
            "answer": "$$\\boxed{0.3750}$$"
        },
        {
            "introduction": "When we move to multi-factor experiments, like a two-way ANOVA, we are interested in the effect of each factor as well as their interaction. In an ideal balanced design, the variance explained by each component is independent and additive. This exercise demonstrates this fundamental principle of variance partitioning by having you calculate the eta-squared ($\\eta^2$) for each effect from their respective sums of squares and see how they combine to form the overall model's explanatory power, $R^2$ .",
            "id": "4909895",
            "problem": "A biostatistics team conducts a balanced two-factor experiment to investigate variability in a continuous biomarker. Factor $A$ has fixed levels representing diet patterns, factor $B$ has fixed levels representing physical activity categories, and their interaction is considered. The study design is balanced across all cells, and a standard two-way Analysis of Variance (ANOVA) is used. The sums of squares reported from the fitted model are: total sum of squares $SS_T = 2400$, main effect sum of squares for factor $A$, $SS_A = 600$, main effect sum of squares for factor $B$, $SS_B = 300$, and interaction sum of squares $SS_{AB} = 200$.\n\nStarting from the core definition that an effect size in ANOVA quantifies the proportion of the total variability attributable to a particular source, and that the overall model’s explanatory power is quantified by the proportion of the total variability explained by all modeled sources collectively, derive and compute the effect size measure eta-squared $\\eta^2$ for each modeled source ($A$, $B$, and $A \\times B$) and the model coefficient of determination ($R^2$). Then, interpret whether there is any discrepancy between the sum of the eta-squared values for the individual sources and the model $R^2$ in this balanced two-way ANOVA context.\n\nReport all numerical values as exact fractions. No rounding is required. The interpretation should be included in your derivation, but the final answer must only contain the requested numerical results.",
            "solution": "The problem is valid as it is scientifically grounded in the principles of Analysis of Variance (ANOVA), is well-posed with sufficient and consistent data, and is expressed in objective language.\n\nThe analysis begins from the fundamental definitions of effect size measures in the context of ANOVA. The Total Sum of Squares, $SS_T$, represents the total variability in the collected data. The given value is $SS_T = 2400$.\n\nThe effect size measure eta-squared, denoted by $\\eta^2$, quantifies the proportion of the total variability that is attributable to a specific source of variation (a factor or an interaction). Its definition is:\n$$ \\eta^2_{\\text{source}} = \\frac{SS_{\\text{source}}}{SS_T} $$\nwhere $SS_{\\text{source}}$ is the sum of squares for the specific source.\n\nWe apply this definition to each of the modeled sources provided in the problem: factor $A$, factor $B$, and the interaction $A \\times B$.\n\nFor factor $A$, the sum of squares is $SS_A = 600$. The corresponding eta-squared is:\n$$ \\eta^2_A = \\frac{SS_A}{SS_T} = \\frac{600}{2400} = \\frac{1}{4} $$\nThis indicates that factor $A$ (diet patterns) accounts for $25\\%$ of the total variability in the biomarker.\n\nFor factor $B$, the sum of squares is $SS_B = 300$. The corresponding eta-squared is:\n$$ \\eta^2_B = \\frac{SS_B}{SS_T} = \\frac{300}{2400} = \\frac{3}{24} = \\frac{1}{8} $$\nThis indicates that factor $B$ (physical activity categories) accounts for $12.5\\%$ of the total variability.\n\nFor the interaction effect $A \\times B$, the sum of squares is $SS_{AB} = 200$. The corresponding eta-squared is:\n$$ \\eta^2_{AB} = \\frac{SS_{AB}}{SS_T} = \\frac{200}{2400} = \\frac{2}{24} = \\frac{1}{12} $$\nThis indicates that the interaction between diet and physical activity accounts for approximately $8.33\\%$ of the total variability.\n\nNext, we address the overall model's explanatory power, quantified by the coefficient of determination, $R^2$. $R^2$ is defined as the proportion of the total variability explained by all modeled sources collectively. This is the ratio of the model sum of squares, $SS_{\\text{model}}$, to the total sum of squares, $SS_T$.\n$$ R^2 = \\frac{SS_{\\text{model}}}{SS_T} $$\nThe model sum of squares, $SS_{\\text{model}}$, is the total variation captured by the ANOVA model, which includes all factors and their interactions. A critical piece of information is that the experiment has a **balanced design**. In a balanced ANOVA, the sums of squares for the different effects (main effects and interactions) are orthogonal. This implies that they represent non-overlapping sources of variance, and their sum equals the total sum of squares explained by the model.\nTherefore, for this balanced design, the model sum of squares is simply the sum of the sums of squares for each effect included in the model:\n$$ SS_{\\text{model}} = SS_A + SS_B + SS_{AB} $$\nUsing the given values:\n$$ SS_{\\text{model}} = 600 + 300 + 200 = 1100 $$\nNow, we can compute the coefficient of determination, $R^2$:\n$$ R^2 = \\frac{SS_{\\text{model}}}{SS_T} = \\frac{1100}{2400} = \\frac{11}{24} $$\nThis means the model as a whole (diet, activity, and their interaction) explains approximately $45.83\\%$ of the total variability in the biomarker.\n\nFinally, we interpret the relationship between the sum of the individual eta-squared values and the model $R^2$. Let us calculate the sum:\n$$ \\eta^2_A + \\eta^2_B + \\eta^2_{AB} = \\frac{1}{4} + \\frac{1}{8} + \\frac{1}{12} $$\nTo sum these fractions, we find a common denominator, which is $24$:\n$$ \\frac{6}{24} + \\frac{3}{24} + \\frac{2}{24} = \\frac{6+3+2}{24} = \\frac{11}{24} $$\nWe observe that:\n$$ \\eta^2_A + \\eta^2_B + \\eta^2_{AB} = R^2 $$\nIn this balanced two-way ANOVA context, there is no discrepancy. The sum of the eta-squared values for the individual sources is exactly equal to the model's overall coefficient of determination, $R^2$. This is a direct mathematical consequence of the orthogonality of the sums of squares in a balanced design. The total explained variance, $SS_{\\text{model}}$, is cleanly partitioned among the factors and their interaction, and this additive partitioning carries over directly to the proportions of total variance (the $\\eta^2$ values). It is important to note that this simple additive relationship does not hold for unbalanced designs, where the sums of squares for the effects are correlated and do not sum to the model sum of squares.\n\nThe computed numerical results are: $\\eta^2_A = \\frac{1}{4}$, $\\eta^2_B = \\frac{1}{8}$, $\\eta^2_{AB} = \\frac{1}{12}$, and $R^2 = \\frac{11}{24}$.",
            "answer": "$$\n\\boxed{\\begin{pmatrix} \\frac{1}{4} & \\frac{1}{8} & \\frac{1}{12} & \\frac{11}{24} \\end{pmatrix}}\n$$"
        },
        {
            "introduction": "In multi-factor ANOVA, we often want to isolate the effect of a single factor, removing the influence of others. This is where partial eta-squared ($\\eta_p^2$) becomes essential, as it measures the proportion of variance an effect explains from the total variance minus that explained by other effects in the model. This exercise provides a practical scenario where you will compute $\\eta_p^2$ from a reported $F$-statistic, a common task when critically evaluating the magnitude of effects in complex studies .",
            "id": "4909896",
            "problem": "A biostatistics research team evaluates a biomarker response in a randomized study with four dosage conditions (factor A with $4$ levels) measured across multiple clinic sites (factor B with $s$ levels). They fit a fixed-effects two-way Analysis of Variance (ANOVA) model with the interaction term, using ordinary least squares and the standard residual term as the error for the $F$-test of factor A. The ANOVA summary for factor A reports an omnibus $F$-statistic of $F=5.4$ with degrees of freedom $\\mathrm{df}_{A}=3$ and residual degrees of freedom $\\mathrm{df}_{\\text{error}}=96$. Using only these reported quantities and starting from the definitions of sums of squares, mean squares, and the $F$-statistic, compute the partial eta-squared $\\,\\eta_{p}^{2}\\,$ for factor A. Then, briefly comment on what this value means in the context of variance explained by factor A in the presence of the other model terms. Provide your numerical value as a decimal rounded to four significant figures.",
            "solution": "The problem is valid as it is scientifically grounded in the principles of Analysis of Variance (ANOVA), is well-posed with sufficient and consistent information, and is expressed in objective, formal language. We are asked to compute the partial eta-squared, $\\eta_{p}^{2}$, for factor A and interpret its meaning, given the results from a two-way fixed-effects ANOVA.\n\nThe given quantities are:\n- The omnibus $F$-statistic for factor A: $F_A = 5.4$.\n- The degrees of freedom for factor A: $\\mathrm{df}_A = 3$.\n- The residual (error) degrees of freedom: $\\mathrm{df}_{\\text{error}} = 96$.\n\nWe begin by stating the fundamental definitions. In an ANOVA framework, the $F$-statistic for a given factor (in this case, factor A) is defined as the ratio of the Mean Square for that factor to the Mean Square for the error term.\n\nThe Mean Square for factor A, denoted $MS_A$, is the Sum of Squares for factor A, $SS_A$, divided by its degrees of freedom, $\\mathrm{df}_A$:\n$$MS_A = \\frac{SS_A}{\\mathrm{df}_A}$$\n\nThe Mean Square for error, denoted $MS_{\\text{error}}$, is the Sum of Squares for error, $SS_{\\text{error}}$, divided by its degrees of freedom, $\\mathrm{df}_{\\text{error}}$:\n$$MS_{\\text{error}} = \\frac{SS_{\\text{error}}}{\\mathrm{df}_{\\text{error}}}$$\n\nThe $F$-statistic for factor A is therefore:\n$$F_A = \\frac{MS_A}{MS_{\\text{error}}} = \\frac{SS_A / \\mathrm{df}_A}{SS_{\\text{error}} / \\mathrm{df}_{\\text{error}}}$$\n\nPartial eta-squared, $\\eta_p^2$, for a specific factor is defined as the proportion of variance attributable to that factor, after partialling out (controlling for) the other factors in the model. It is the ratio of the sum of squares for the factor of interest to the sum of the sum of squares for that factor and the sum of squares for the error term. For factor A, this is:\n$$\\eta_{p, A}^{2} = \\frac{SS_A}{SS_A + SS_{\\text{error}}}$$\n\nTo compute $\\eta_{p, A}^{2}$ from the given $F_A$, $\\mathrm{df}_A$, and $\\mathrm{df}_{\\text{error}}$, we must derive a relationship between these quantities. We can manipulate the definition of $\\eta_{p, A}^{2}$ by dividing both the numerator and the denominator by $SS_{\\text{error}}$:\n$$\\eta_{p, A}^{2} = \\frac{SS_A / SS_{\\text{error}}}{(SS_A / SS_{\\text{error}}) + (SS_{\\text{error}} / SS_{\\text{error}})} = \\frac{SS_A / SS_{\\text{error}}}{(SS_A / SS_{\\text{error}}) + 1}$$\n\nNext, we rearrange the formula for the $F$-statistic to express the ratio $SS_A / SS_{\\text{error}}$:\n$$F_A = \\frac{SS_A / \\mathrm{df}_A}{SS_{\\text{error}} / \\mathrm{df}_{\\text{error}}} \\implies F_A \\cdot \\frac{\\mathrm{df}_A}{\\mathrm{df}_{\\text{error}}} = \\frac{SS_A}{SS_{\\text{error}}}$$\n\nSubstituting this expression for $SS_A / SS_{\\text{error}}$ back into our developing formula for $\\eta_{p, A}^{2}$ yields a complicated form. A more elegant approach is to start from the definition of $\\eta_{p, A}^{2}$ and divide the numerator and denominator by a different quantity. Let's rewrite the expression for $\\eta_{p, A}^{2}$ and divide the numerator and denominator by themselves; a more useful algebraic manipulation is to use the relationships with the $F$-statistic. The most direct path is to recognize:\n$SS_A = MS_A \\cdot \\mathrm{df}_A$\n$SS_{\\text{error}} = MS_{\\text{error}} \\cdot \\mathrm{df}_{\\text{error}}$\n\nSubstituting these into the definition of $\\eta_{p, A}^{2}$:\n$$\\eta_{p, A}^{2} = \\frac{MS_A \\cdot \\mathrm{df}_A}{MS_A \\cdot \\mathrm{df}_A + MS_{\\text{error}} \\cdot \\mathrm{df}_{\\text{error}}}$$\nNow, we can divide the numerator and the denominator by $MS_{\\text{error}}$:\n$$\\eta_{p, A}^{2} = \\frac{(MS_A / MS_{\\text{error}}) \\cdot \\mathrm{df}_A}{(MS_A / MS_{\\text{error}}) \\cdot \\mathrm{df}_A + (MS_{\\text{error}} / MS_{\\text{error}}) \\cdot \\mathrm{df}_{\\text{error}}}$$\nSince $F_A = MS_A / MS_{\\text{error}}$ and $MS_{\\text{error}} / MS_{\\text{error}} = 1$, we arrive at the standard computational formula:\n$$\\eta_{p, A}^{2} = \\frac{F_A \\cdot \\mathrm{df}_A}{F_A \\cdot \\mathrm{df}_A + \\mathrm{df}_{\\text{error}}}$$\n\nNow we can substitute the given values into this formula:\n$F_A = 5.4$\n$\\mathrm{df}_A = 3$\n$\\mathrm{df}_{\\text{error}} = 96$\n\n$$\\eta_{p, A}^{2} = \\frac{5.4 \\times 3}{(5.4 \\times 3) + 96} = \\frac{16.2}{16.2 + 96} = \\frac{16.2}{112.2}$$\n\nCalculating the final value:\n$$\\eta_{p, A}^{2} \\approx 0.1443850267...$$\n\nRounding to four significant figures as requested gives $0.1444$.\n\n**Interpretation:**\nThe partial eta-squared value of $\\eta_{p, A}^{2} \\approx 0.1444$ represents the proportion of variance in the biomarker response that is uniquely associated with the factor A (dosage condition), after controlling for the variance explained by factor B (clinic site) and the $A \\times B$ interaction. Specifically, it means that approximately $14.44\\%$ of the variance that is not explained by factor B or the interaction is accounted for by the different dosage levels. In the context of conventional effect size benchmarks (e.g., Cohen's guidelines where values around $0.01$, $0.06$, and $0.14$ are considered small, medium, and large, respectively), this value indicates a large effect size for factor A.",
            "answer": "$$\\boxed{0.1444}$$"
        }
    ]
}