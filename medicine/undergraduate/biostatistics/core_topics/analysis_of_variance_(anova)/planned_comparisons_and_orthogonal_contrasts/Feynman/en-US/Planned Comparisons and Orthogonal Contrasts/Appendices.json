{
    "hands_on_practices": [
        {
            "introduction": "The first step in applying planned comparisons is to translate a specific scientific hypothesis into a precise mathematical construct. This exercise provides foundational practice in this critical skill. You will learn how to formulate the coefficients of a linear contrast that directly corresponds to a research question—in this case, comparing a high-dose treatment to the average effect of lower-dose treatments. By then deriving the variance of this contrast, you are building the theoretical bedrock required for conducting hypothesis tests and constructing confidence intervals, as explored in subsequent practices .",
            "id": "4937602",
            "problem": "A randomized biostatistics trial evaluates a continuous biomarker response across three dose groups: low, medium, and high. Let the group sample sizes be $n_{L}$, $n_{M}$, and $n_{H}$, respectively. Denote the group sample means by $\\bar{Y}_{L}$, $\\bar{Y}_{M}$, and $\\bar{Y}_{H}$. Assume responses within and across groups are independent, each with a common variance $\\sigma^{2}$, and that each $\\bar{Y}_{i}$ is an unbiased estimator of its corresponding group mean.\n\nAs part of a set of planned comparisons, you aim to compare the high-dose group mean to the average of the low- and medium-dose group means using a single contrast on the group means. Construct the contrast that encodes this comparison, verify that it satisfies the defining property of a contrast (the coefficients sum to zero), and derive the variance of this contrast under the homoscedastic independent group model. Express the final variance as a single closed-form analytic expression in terms of $n_{L}$, $n_{M}$, $n_{H}$, and $\\sigma^{2}$. No rounding is required.",
            "solution": "The problem will first be validated for scientific soundness, self-consistency, and clarity before a solution is attempted.\n\n### Problem Validation\n\n**Step 1: Extract Givens**\n- A biostatistics trial evaluates a continuous biomarker response.\n- There are three dose groups: low (L), medium (M), and high (H).\n- The group sample sizes are $n_{L}$, $n_{M}$, and $n_{H}$.\n- The group sample means are $\\bar{Y}_{L}$, $\\bar{Y}_{M}$, and $\\bar{Y}_{H}$.\n- Responses within and across groups are independent.\n- Each response has a common variance $\\sigma^{2}$ (homoscedasticity).\n- Each sample mean $\\bar{Y}_{i}$ is an unbiased estimator of its corresponding true group mean $\\mu_{i}$ (where $i \\in \\{L, M, H\\}$).\n- The objective is to construct a contrast comparing the high-dose group mean to the average of the low- and medium-dose group means.\n- The task requires constructing the contrast, verifying its defining property, and deriving its variance.\n\n**Step 2: Validate Using Extracted Givens**\n- **Scientifically Grounded**: The problem is well-grounded in the theory of linear models and analysis of variance (ANOVA), specifically in the topic of planned comparisons and orthogonal contrasts. The assumptions of independence, homoscedasticity, and unbiased estimators are standard in this context.\n- **Well-Posed**: The problem is well-posed. It asks for the derivation of a specific quantity (the variance of a particular contrast) based on a complete set of given parameters and assumptions. A unique, meaningful solution exists.\n- **Objective**: The language is precise, technical, and free of subjective or ambiguous terminology.\n- **Completeness and Consistency**: The problem provides all necessary information to construct the contrast and derive its variance. There are no missing definitions or contradictory statements. The setup is a standard one in biostatistics.\n\n**Step 3: Verdict and Action**\nThe problem is deemed valid. It is a standard, well-defined problem in statistical theory. A solution will now be derived.\n\n### Solution Derivation\n\nA linear contrast, denoted $\\psi$, is a linear combination of group means $\\mu_i$ whose coefficients sum to zero. The estimator for this contrast, $\\hat{\\psi}$, is the same linear combination of the sample means $\\bar{Y}_i$.\nLet the three groups be indexed by $i \\in \\{L, M, H\\}$. A general contrast on the means is defined by:\n$$\n\\hat{\\psi} = \\sum_{i \\in \\{L, M, H\\}} c_i \\bar{Y}_i\n$$\nwhere the coefficients $c_i$ must satisfy the condition:\n$$\n\\sum_{i \\in \\{L, M, H\\}} c_i = 0\n$$\n\nThe problem specifies the comparison of the high-dose group mean, $\\mu_H$, to the average of the low- and medium-dose group means, $\\frac{\\mu_L + \\mu_M}{2}$. This comparison can be expressed as the difference:\n$$\n\\psi = \\mu_H - \\frac{\\mu_L + \\mu_M}{2}\n$$\nRearranging this expression into the form $\\sum c_i \\mu_i$ gives:\n$$\n\\psi = (1)\\mu_H - \\frac{1}{2}\\mu_L - \\frac{1}{2}\\mu_M\n$$\nThe corresponding estimator, $\\hat{\\psi}$, using the sample means is:\n$$\n\\hat{\\psi} = (1)\\bar{Y}_H - \\frac{1}{2}\\bar{Y}_L - \\frac{1}{2}\\bar{Y}_M\n$$\nThe coefficients for this contrast are therefore $c_L = -\\frac{1}{2}$, $c_M = -\\frac{1}{2}$, and $c_H = 1$.\n\nNext, we verify that these coefficients satisfy the defining property of a contrast. The sum of the coefficients is:\n$$\nc_L + c_M + c_H = \\left(-\\frac{1}{2}\\right) + \\left(-\\frac{1}{2}\\right) + 1 = -1 + 1 = 0\n$$\nThe condition is satisfied, confirming that $\\hat{\\psi}$ is a valid statistical contrast.\n\nFinally, we derive the variance of this contrast, $\\text{Var}(\\hat{\\psi})$. The general formula for the variance of a linear combination of independent random variables is:\n$$\n\\text{Var}\\left(\\sum_i c_i X_i\\right) = \\sum_i c_i^2 \\text{Var}(X_i)\n$$\nThe problem states that the responses across groups are independent. Consequently, the sample means $\\bar{Y}_L$, $\\bar{Y}_M$, and $\\bar{Y}_H$ are independent random variables. Applying the variance formula to our contrast $\\hat{\\psi}$:\n$$\n\\text{Var}(\\hat{\\psi}) = \\text{Var}\\left(c_L \\bar{Y}_L + c_M \\bar{Y}_M + c_H \\bar{Y}_H\\right) = c_L^2 \\text{Var}(\\bar{Y}_L) + c_M^2 \\text{Var}(\\bar{Y}_M) + c_H^2 \\text{Var}(\\bar{Y}_H)\n$$\nThe variance of a sample mean $\\bar{Y}_i$ calculated from $n_i$ independent observations, each with variance $\\sigma^2$, is given by:\n$$\n\\text{Var}(\\bar{Y}_i) = \\frac{\\sigma^2}{n_i}\n$$\nSubstituting the specific variances for each group mean, we have:\n$$\n\\text{Var}(\\hat{\\psi}) = c_L^2 \\left(\\frac{\\sigma^2}{n_L}\\right) + c_M^2 \\left(\\frac{\\sigma^2}{n_M}\\right) + c_H^2 \\left(\\frac{\\sigma^2}{n_H}\\right)\n$$\nNow, we substitute the values of the coefficients $c_L = -\\frac{1}{2}$, $c_M = -\\frac{1}{2}$, and $c_H = 1$:\n$$\n\\text{Var}(\\hat{\\psi}) = \\left(-\\frac{1}{2}\\right)^2 \\frac{\\sigma^2}{n_L} + \\left(-\\frac{1}{2}\\right)^2 \\frac{\\sigma^2}{n_M} + (1)^2 \\frac{\\sigma^2}{n_H}\n$$\nSquaring the coefficients yields:\n$$\n\\text{Var}(\\hat{\\psi}) = \\frac{1}{4} \\frac{\\sigma^2}{n_L} + \\frac{1}{4} \\frac{\\sigma^2}{n_M} + 1 \\cdot \\frac{\\sigma^2}{n_H}\n$$\nFactoring out the common term $\\sigma^2$, we arrive at the final closed-form analytic expression for the variance of the contrast:\n$$\n\\text{Var}(\\hat{\\psi}) = \\sigma^2 \\left( \\frac{1}{4n_L} + \\frac{1}{4n_M} + \\frac{1}{n_H} \\right)\n$$\nThis expression represents the variance of the specified contrast in terms of the group sample sizes and the common population variance.",
            "answer": "$$\n\\boxed{\\sigma^2 \\left(\\frac{1}{4n_L} + \\frac{1}{4n_M} + \\frac{1}{n_H}\\right)}\n$$"
        },
        {
            "introduction": "Moving from theory to application, this practice demonstrates how to use a planned contrast to perform statistical inference on experimental data. While a general ANOVA might tell you that not all group means are equal, a planned contrast allows you to answer a much more specific question about the magnitude and significance of a pre-specified comparison. This exercise will guide you through calculating a point estimate, its standard error, and ultimately a confidence interval, providing a tangible range for the true effect. The final step, interpreting the interval, is a crucial skill for communicating statistical findings in a meaningful scientific context.",
            "id": "4937539",
            "problem": "A single-factor design was used to compare four dietary sodium interventions on the change in systolic blood pressure (in millimeters of mercury, $\\mathrm{mm\\,Hg}$) after $8$ weeks. Let the four groups be labeled $A$, $B$, $C$, and $D$. Assume the standard one-way Analysis of Variance (ANOVA) model with independent and normally distributed outcomes in each group, a common error variance across groups, and equal group sizes. Specifically, suppose each group has $n_i = 16$ participants, the sample means of change are $\\bar{Y}_A = -5$, $\\bar{Y}_B = -3$, $\\bar{Y}_C = -9$, and $\\bar{Y}_D = -10$ (negative values indicate reductions), and the residual mean square (mean square error) from the ANOVA is $\\mathrm{MSE} = 36$.\n\nA planned comparison was prespecified to compare the average of the two lower-sodium groups $C$ and $D$ versus the average of the two moderate-sodium groups $A$ and $B$. Define the contrast\n$$\nL \\;=\\; \\frac{1}{2}\\mu_C + \\frac{1}{2}\\mu_D \\;-\\; \\frac{1}{2}\\mu_A \\;-\\; \\frac{1}{2}\\mu_B,\n$$\nwith corresponding estimator\n$$\n\\hat{L} \\;=\\; \\frac{1}{2}\\bar{Y}_C + \\frac{1}{2}\\bar{Y}_D \\;-\\; \\frac{1}{2}\\bar{Y}_A \\;-\\; \\frac{1}{2}\\bar{Y}_B.\n$$\n\nAssume the $t$-critical value for a $95\\%$ confidence level with $\\mathrm{df} = 60$ degrees of freedom is $t_{0.975,60} = 2.000$.\n\nUsing the ANOVA assumptions and the planned contrast above, construct the $95\\%$ confidence interval for $L$ and briefly interpret the interval in terms of the planned comparison. Then, report the margin-of-error (the half-width of the confidence interval), rounded to four significant figures. Express interval endpoints and the margin-of-error in $\\mathrm{mm\\,Hg}$.",
            "solution": "### Step 1: Extract Givens\n-   Number of groups, $k=4$ (labeled $A$, $B$, $C$, $D$).\n-   Sample size per group, $n_i = 16$ for all $i \\in \\{A, B, C, D\\}$.\n-   Sample means of change in systolic blood pressure: $\\bar{Y}_A = -5 \\, \\mathrm{mm\\,Hg}$, $\\bar{Y}_B = -3 \\, \\mathrm{mm\\,Hg}$, $\\bar{Y}_C = -9 \\, \\mathrm{mm\\,Hg}$, $\\bar{Y}_D = -10 \\, \\mathrm{mm\\,Hg}$.\n-   Residual mean square (Mean Square Error): $\\mathrm{MSE} = 36$.\n-   ANOVA model assumptions: independent, normally distributed outcomes; common error variance; equal group sizes.\n-   Planned contrast parameter: $L = \\frac{1}{2}\\mu_C + \\frac{1}{2}\\mu_D - \\frac{1}{2}\\mu_A - \\frac{1}{2}\\mu_B$.\n-   Planned contrast estimator: $\\hat{L} = \\frac{1}{2}\\bar{Y}_C + \\frac{1}{2}\\bar{Y}_D - \\frac{1}{2}\\bar{Y}_A - \\frac{1}{2}\\bar{Y}_B$.\n-   Confidence level: $95\\%$.\n-   Degrees of freedom for the t-distribution: $\\mathrm{df} = 60$.\n-   Critical value: $t_{0.975,60} = 2.000$.\n\n### Step 2: Validate Using Extracted Givens\n-   **Scientifically Grounded**: The problem is a standard application of planned contrasts within a one-way ANOVA framework, a core topic in biostatistics and experimental design. All concepts are well-established.\n-   **Well-Posed**: The problem is well-posed. It provides all necessary information to calculate the confidence interval and margin of error. The total sample size is $N = \\sum n_i = 4 \\times 16 = 64$. The error degrees of freedom are $N-k = 64 - 4 = 60$, which matches the provided $\\mathrm{df}=60$. The contrast is properly defined with coefficients that sum to zero: $c_A + c_B + c_C + c_D = -1/2 - 1/2 + 1/2 + 1/2 = 0$.\n-   **Objective**: The problem is stated with precise, objective language and quantitative data. No subjective claims are present.\n-   **Completeness**: The problem is self-contained and provides all data and parameters required for the solution. No essential information is missing.\n-   **Consistency**: The givens are internally consistent. The calculation of degrees of freedom from the sample sizes matches the provided value.\n\n### Step 3: Verdict and Action\nThe problem is valid. It is a standard, well-posed problem in biostatistics that is scientifically sound and complete. I will proceed with the solution.\n\nThe objective is to compute the $95\\%$ confidence interval for the planned contrast $L$ and its margin of error. The general form of a confidence interval for a linear contrast $L = \\sum_{i=1}^{k} c_i \\mu_i$ is given by:\n$$ \\hat{L} \\pm t_{1-\\alpha/2, N-k} \\times \\mathrm{SE}(\\hat{L}) $$\nwhere $\\hat{L}$ is the point estimate of the contrast, $t_{1-\\alpha/2, N-k}$ is the critical value from the t-distribution, and $\\mathrm{SE}(\\hat{L})$ is the standard error of the estimate.\n\nFirst, we calculate the point estimate, $\\hat{L}$. The coefficients of the contrast are $c_A = -1/2$, $c_B = -1/2$, $c_C = 1/2$, and $c_D = 1/2$.\n$$ \\hat{L} = c_A \\bar{Y}_A + c_B \\bar{Y}_B + c_C \\bar{Y}_C + c_D \\bar{Y}_D $$\nSubstituting the given sample means:\n$$ \\hat{L} = \\left(-\\frac{1}{2}\\right)(-5) + \\left(-\\frac{1}{2}\\right)(-3) + \\left(\\frac{1}{2}\\right)(-9) + \\left(\\frac{1}{2}\\right)(-10) $$\n$$ \\hat{L} = 2.5 + 1.5 - 4.5 - 5.0 $$\n$$ \\hat{L} = 4.0 - 9.5 = -5.5 $$\n\nNext, we calculate the standard error of the estimator, $\\mathrm{SE}(\\hat{L})$. The formula for the standard error is:\n$$ \\mathrm{SE}(\\hat{L}) = \\sqrt{\\mathrm{MSE} \\sum_{i=1}^{k} \\frac{c_i^2}{n_i}} $$\nThe samples sizes are equal, $n_i = 16$ for all groups. We first compute the sum of squared coefficients divided by their respective sample sizes:\n$$ \\sum_{i=1}^{k} \\frac{c_i^2}{n_i} = \\frac{(-1/2)^2}{16} + \\frac{(-1/2)^2}{16} + \\frac{(1/2)^2}{16} + \\frac{(1/2)^2}{16} $$\n$$ \\sum_{i=1}^{k} \\frac{c_i^2}{n_i} = \\frac{1/4}{16} + \\frac{1/4}{16} + \\frac{1/4}{16} + \\frac{1/4}{16} = 4 \\times \\frac{1/4}{16} = \\frac{1}{16} $$\nNow we can compute the standard error using the given $\\mathrm{MSE} = 36$:\n$$ \\mathrm{SE}(\\hat{L}) = \\sqrt{36 \\times \\frac{1}{16}} = \\sqrt{\\frac{36}{16}} = \\frac{\\sqrt{36}}{\\sqrt{16}} = \\frac{6}{4} = 1.5 $$\n\nThe margin of error (ME) is the half-width of the confidence interval. It is calculated as the product of the critical t-value and the standard error.\n$$ \\mathrm{ME} = t_{0.975,60} \\times \\mathrm{SE}(\\hat{L}) $$\nUsing the given critical value $t_{0.975,60} = 2.000$:\n$$ \\mathrm{ME} = 2.000 \\times 1.5 = 3.0 $$\nThe problem requires this value to be rounded to four significant figures, which is $3.000$.\n\nNow we construct the $95\\%$ confidence interval for $L$:\n$$ \\text{CI for } L = \\hat{L} \\pm \\mathrm{ME} $$\n$$ \\text{CI for } L = -5.5 \\pm 3.0 $$\nThe lower bound of the interval is $-5.5 - 3.0 = -8.5$.\nThe upper bound of the interval is $-5.5 + 3.0 = -2.5$.\nSo, the $95\\%$ confidence interval for $L$ is $[-8.5, -2.5] \\, \\mathrm{mm\\,Hg}$.\n\nInterpretation of the interval: The contrast $L = \\frac{1}{2}(\\mu_C + \\mu_D) - \\frac{1}{2}(\\mu_A + \\mu_B)$ represents the true difference between the average blood pressure reduction in the low-sodium groups ($C$ and $D$) and the average reduction in the moderate-sodium groups ($A$ and $B$). The $95\\%$ confidence interval for this difference is $[-8.5, -2.5] \\, \\mathrm{mm\\,Hg}$. Since the entire interval is negative and does not contain $0$, we are $95\\%$ confident that the average blood pressure reduction in the low-sodium groups is significantly greater than the average reduction in the moderate-sodium groups. Specifically, we are $95\\%$ confident that the additional average reduction in systolic blood pressure for the low-sodium groups is between $2.5 \\, \\mathrm{mm\\,Hg}$ and $8.5 \\, \\mathrm{mm\\,Hg}$ compared to the moderate-sodium groups.\n\nThe question asks for the margin-of-error, rounded to four significant figures.\nThe calculated margin of error is $3.0$. Expressed with four significant figures, this is $3.000$.",
            "answer": "$$\n\\boxed{3.000}\n$$"
        },
        {
            "introduction": "Real-world data rarely conforms perfectly to the idealized assumptions of our statistical models. This advanced practice introduces a powerful, modern technique—Monte Carlo simulation—to investigate what happens when assumptions like equal variances (homoscedasticity) are violated. By programming a simulation, you will gain hands-on experience assessing the reliability of the standard pooled-variance $t$-test and see how a robust alternative, the Welch-type $t$-test, performs under challenging conditions. This exercise goes beyond textbook formulas to build a deeper, more intuitive understanding of how statistical tests behave in practice, a crucial skill for any conscientious researcher .",
            "id": "4937595",
            "problem": "You are given a one-way group design with $g$ treatment groups. Let $Y_{ij}$ denote the observed response for subject $j$ in group $i$, with $i \\in \\{1,\\dots,g\\}$ and $j \\in \\{1,\\dots,n_i\\}$. Consider the linear model $Y_{ij} = \\mu_i + \\varepsilon_{ij}$, where $\\mu_i$ is the group-specific mean and $\\varepsilon_{ij}$ are independent errors satisfying $E[\\varepsilon_{ij}] = 0$. In classical analysis of variance, the homoscedasticity assumption states that $\\operatorname{Var}(\\varepsilon_{ij}) = \\sigma^2$ for all $i,j$. In practice, the assumption may be violated, with variance heterogeneity modeled as $\\operatorname{Var}(\\varepsilon_{ij}) = \\sigma_i^2$ that may differ across groups.\n\nA planned contrast is defined by a coefficient vector $\\mathbf{c} = (c_1,\\dots,c_g)$ satisfying $\\sum_{i=1}^g c_i = 0$. The null hypothesis for a planned contrast is $H_0: \\sum_{i=1}^g c_i \\mu_i = 0$. Orthogonality of planned contrasts is defined by $\\sum_{i=1}^g c_i d_i = 0$ for two contrasts $\\mathbf{c}$ and $\\mathbf{d}$ when the design is balanced, and by $\\sum_{i=1}^g n_i c_i d_i = 0$ when the design is unbalanced.\n\nType I error is the probability of rejecting a true null hypothesis. Under variance heterogeneity, a test that assumes homoscedasticity can have its Type I error inflated or deflated. Your task is to assess the sensitivity of planned contrasts to variance model misspecification via two approaches:\n- Monte Carlo simulation under the null hypothesis to estimate empirical Type I error for each contrast using two test procedures: a pooled-variance contrast $t$-test that assumes homoscedasticity, and a heteroscedasticity-aware Welch-type contrast $t$-test.\n- An analytical upper bound on the Type I error for the pooled-variance contrast test using a variance inflation factor and the Chebyshev inequality.\n\nYou must implement a program that, for each test case in the suite below:\n1. Simulates $S$ independent replicates under $H_0$ by generating $Y_{ij} \\sim \\mathcal{N}(0,\\sigma_i^2)$ for each group $i$ and subject $j$, with $S$ specified in the test case. For reproducibility, use the given random seed.\n2. For each replicate, computes the sample mean $\\bar{Y}_i$ and sample variance $s_i^2$ within each group $i$.\n3. For each planned contrast $\\mathbf{c}$:\n   - Computes the pooled-variance contrast $t$-statistic $T_{\\text{pooled}} = L / \\widehat{\\operatorname{SE}}_{\\text{pooled}}$ with $L = \\sum_{i=1}^g c_i \\bar{Y}_i$ and $\\widehat{\\operatorname{SE}}_{\\text{pooled}} = \\sqrt{s_p^2 \\sum_{i=1}^g c_i^2 / n_i}$, where $s_p^2$ is the pooled within-group variance computed across all groups in the replicate. Uses degrees of freedom $N - g$, with $N = \\sum_{i=1}^g n_i$, and obtains a two-sided $p$-value from the Student $t$ distribution. Records whether $p  \\alpha$ for significance level $\\alpha$.\n   - Computes the Welch-type heteroscedastic contrast $t$-statistic $T_{\\text{Welch}} = L / \\sqrt{\\sum_{i=1}^g c_i^2 s_i^2 / n_i}$, and approximates its degrees of freedom by matching second moments across groups using the Satterthwaite approach. Uses a two-sided $p$-value from the Student $t$ distribution with these approximate degrees of freedom. Records whether $p  \\alpha$.\n   - After $S$ replicates, estimates empirical Type I error for both methods as the fraction of replicates with $p  \\alpha$ under $H_0$.\n   - Computes the analytical upper bound on Type I error for the pooled-variance method using Chebyshev's inequality and the variance inflation factor $R$ defined as the ratio between the true variance of $L$ under heteroscedasticity and the model-based variance under the homoscedastic pooled assumption (using the expected pooled variance as a proxy). Use the two-sided critical value from the Student $t$ distribution at level $\\alpha/2$ with $N-g$ degrees of freedom to form the bound $P(|T_{\\text{pooled}}| \\ge t_{\\text{crit}}) \\le \\min\\{1, R / t_{\\text{crit}}^2\\}$.\n\nUse the following test suite. Each test case specifies $(g, \\mathbf{n}, \\boldsymbol{\\sigma}, \\mathcal{C}, \\alpha, S, \\text{seed})$, where $g$ is the number of groups, $\\mathbf{n}$ is the list of group sizes, $\\boldsymbol{\\sigma}$ is the list of group standard deviations, $\\mathcal{C}$ is the list of planned contrasts, $\\alpha$ is the significance level, $S$ is the number of simulation replicates, and $\\text{seed}$ is the random seed. For all lists, ensure the dimension equals $g$.\n\n- Case $1$ (balanced, homoscedastic, orthogonal contrasts): $g = 4$, $\\mathbf{n} = [\\,20,\\,20,\\,20,\\,20\\,]$, $\\boldsymbol{\\sigma} = [\\,1,\\,1,\\,1,\\,1\\,]$, $\\mathcal{C} = \\left\\{\\,[\\,1,\\,-1,\\,0,\\,0\\,],\\;[\\,0,\\,0,\\,1,\\,-1\\,],\\;[\\,\\tfrac{1}{2},\\,\\tfrac{1}{2},\\,-\\tfrac{1}{2},\\,-\\tfrac{1}{2}\\,]\\,\\right\\}$, $\\alpha = 0.05$, $S = 20000$, $\\text{seed} = 12345$.\n- Case $2$ (balanced, mild heteroscedasticity): $g = 4$, $\\mathbf{n} = [\\,20,\\,20,\\,20,\\,20\\,]$, $\\boldsymbol{\\sigma} = [\\,1,\\,1.5,\\,1,\\,2\\,]$, $\\mathcal{C} = \\left\\{\\,[\\,1,\\,-1,\\,0,\\,0\\,],\\;[\\,0,\\,0,\\,1,\\,-1\\,],\\;[\\,\\tfrac{1}{2},\\,\\tfrac{1}{2},\\,-\\tfrac{1}{2},\\,-\\tfrac{1}{2}\\,]\\,\\right\\}$, $\\alpha = 0.05$, $S = 20000$, $\\text{seed} = 12345$.\n- Case $3$ (unbalanced, moderate heteroscedasticity): $g = 4$, $\\mathbf{n} = [\\,10,\\,30,\\,10,\\,30\\,]$, $\\boldsymbol{\\sigma} = [\\,1,\\,2,\\,1,\\,2\\,]$, $\\mathcal{C} = \\left\\{\\,[\\,1,\\,-1,\\,0,\\,0\\,],\\;[\\,0,\\,0,\\,1,\\,-1\\,],\\;[\\,\\tfrac{1}{2},\\,\\tfrac{1}{2},\\,-\\tfrac{1}{2},\\,-\\tfrac{1}{2}\\,]\\,\\right\\}$, $\\alpha = 0.05$, $S = 20000$, $\\text{seed} = 12345$.\n- Case $4$ (unbalanced, extreme heteroscedasticity): $g = 4$, $\\mathbf{n} = [\\,5,\\,50,\\,5,\\,50\\,]$, $\\boldsymbol{\\sigma} = [\\,0.5,\\,3,\\,0.5,\\,3\\,]$, $\\mathcal{C} = \\left\\{\\,[\\,1,\\,-1,\\,0,\\,0\\,],\\;[\\,0,\\,0,\\,1,\\,-1\\,],\\;[\\,\\tfrac{1}{2},\\,\\tfrac{1}{2},\\,-\\tfrac{1}{2},\\,-\\tfrac{1}{2}\\,]\\,\\right\\}$, $\\alpha = 0.05$, $S = 20000$, $\\text{seed} = 12345$.\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets. Each item corresponds to one test case and is itself a comma-separated list of the per-contrast triplets $[\\,\\text{pooled},\\,\\text{Welch},\\,\\text{bound}\\,]$, in the same order as $\\mathcal{C}$. For example, the output format is\n`[\\,[\\,[x_{11},x_{12},x_{13}],\\,[x_{21},x_{22},x_{23}],\\,[x_{31},x_{32},x_{33}]\\,],\\,[\\,[\\dots],\\,[\\dots],\\,[\\dots]\\,],\\,[\\dots],\\,[\\dots]\\,]`,\nwhere each $x_{ab}$ is a real number printed as a decimal. No units are involved in this task. Ensure that the final printed line contains no spaces.",
            "solution": "The problem provided is a valid and well-posed exercise in biostatistics, specifically concerning the performance of planned contrasts under violations of the homoscedasticity assumption in a one-way analysis of variance (ANOVA) design. All provided definitions, formulas, and parameters are scientifically sound, consistent, and standard within the field. The task is to evaluate the Type I error rate of a classical pooled-variance t-test and a heteroscedasticity-robust Welch-type t-test for planned contrasts via Monte Carlo simulation, and to compute an analytical upper bound for the Type I error of the pooled test using Chebyshev's inequality.\n\nThe solution will be implemented by creating a Python program that iterates through each specified test case. For each case, the program will perform the following steps:\n\n1.  **Parameter Setup**: The parameters for each test case—number of groups $g$, group sample sizes $\\mathbf{n} = (n_1, \\dots, n_g)$, group standard deviations $\\boldsymbol{\\sigma} = (\\sigma_1, \\dots, \\sigma_g)$, planned contrasts $\\mathcal{C}$, significance level $\\alpha$, number of simulations $S$, and the random seed—are extracted. The group variances are computed as $\\sigma_i^2$.\n\n2.  **Monte Carlo Simulation**: To estimate the empirical Type I error rates, we simulate $S$ datasets under the null hypothesis $H_0: \\sum_{i=1}^g c_i \\mu_i = 0$. The simplest way to ensure $H_0$ is true for any contrast is to set all group means $\\mu_i=0$.\n    - A modern random number generator is seeded for reproducibility.\n    - For each of the $S$ replicates, we generate data for each group $i$ by drawing $n_i$ samples from a normal distribution $\\mathcal{N}(0, \\sigma_i^2)$. This process is vectorized for computational efficiency by generating a matrix of random samples for all replicates and groups simultaneously.\n    - From the simulated data, we compute the sample mean $\\bar{Y}_i$ and sample variance $s_i^2$ for each group within each of the $S$ replicates.\n\n3.  **Statistical Tests**: For each replicate and for each planned contrast vector $\\mathbf{c} = (c_1, \\dots, c_g)$, we perform two types of t-tests.\n    - The linear combination of sample means is calculated as $L = \\sum_{i=1}^g c_i \\bar{Y}_i$.\n\n    - **Pooled-Variance t-Test**: This test assumes homoscedasticity ($\\sigma_1^2 = \\dots = \\sigma_g^2 = \\sigma^2$).\n        - The pooled variance, $s_p^2$, which estimates the common variance $\\sigma^2$, is calculated for each replicate:\n          $$s_p^2 = \\frac{\\sum_{i=1}^g (n_i - 1) s_i^2}{\\sum_{i=1}^g (n_i - 1)} = \\frac{\\sum_{i=1}^g (n_i - 1) s_i^2}{N - g}$$\n          where $N = \\sum_{i=1}^g n_i$ is the total sample size.\n        - The standard error of $L$ is estimated as $\\widehat{\\operatorname{SE}}_{\\text{pooled}} = \\sqrt{s_p^2 \\sum_{i=1}^g \\frac{c_i^2}{n_i}}$.\n        - The test statistic is $T_{\\text{pooled}} = L / \\widehat{\\operatorname{SE}}_{\\text{pooled}}$.\n        - The two-sided $p$-value is obtained from the Student's t-distribution with $N - g$ degrees of freedom.\n\n    - **Welch-Type t-Test**: This test does not assume homoscedasticity.\n        - The standard error of $L$ is estimated as $\\widehat{\\operatorname{SE}}_{\\text{Welch}} = \\sqrt{\\sum_{i=1}^g \\frac{c_i^2 s_i^2}{n_i}}$.\n        - The test statistic is $T_{\\text{Welch}} = L / \\widehat{\\operatorname{SE}}_{\\text{Welch}}$.\n        - The degrees of freedom are approximated using the Satterthwaite formula for a linear combination of sample means:\n          $$ \\text{df}_{\\text{Welch}} = \\frac{\\left(\\sum_{i=1}^g \\frac{c_i^2 s_i^2}{n_i}\\right)^2}{\\sum_{i=1}^g \\frac{\\left(\\frac{c_i^2 s_i^2}{n_i}\\right)^2}{n_i - 1}} $$\n        - The two-sided $p$-value is obtained from the Student's t-distribution with $\\text{df}_{\\text{Welch}}$ degrees of freedom. Numerical robustness is ensured by handling potential divisions by zero, though unlikely with the given data.\n\n4.  **Empirical Type I Error**: For each contrast and each test method, the empirical Type I error rate is computed as the proportion of the $S$ replicates for which the calculated $p$-value is less than the specified significance level $\\alpha = 0.05$.\n\n5.  **Analytical Upper Bound**: The analytical upper bound on the Type I error for the pooled-variance test is calculated for each contrast.\n    - First, we determine the critical value $t_{\\text{crit}}$ from the Student's t-distribution such that $P(|T| > t_{\\text{crit}}) = \\alpha$ for a t-variate $T$ with $N-g$ degrees of freedom. This corresponds to the $1 - \\alpha/2$ quantile.\n    - Next, we compute the variance inflation factor $R$. This is the ratio of the true variance of $L$ under heteroscedasticity to the expected value of its estimated variance under the misspecified homoscedastic model.\n      - The true variance of $L$ is $\\operatorname{Var}_{\\text{true}}(L) = \\operatorname{Var}\\left(\\sum_{i=1}^g c_i \\bar{Y}_i\\right) = \\sum_{i=1}^g c_i^2 \\frac{\\sigma_i^2}{n_i}$.\n      - The expected value of the pooled variance estimator is $E[s_p^2] = \\frac{\\sum_{i=1}^g (n_i - 1) \\sigma_i^2}{N - g}$.\n      - The expected model-based variance of $L$ is $E[\\widehat{\\operatorname{Var}}_{\\text{model}}(L)] = E[s_p^2] \\sum_{i=1}^g \\frac{c_i^2}{n_i}$.\n      - The variance inflation factor is thus $R = \\operatorname{Var}_{\\text{true}}(L) / E[\\widehat{\\operatorname{Var}}_{\\text{model}}(L)]$.\n    - The upper bound is then given by Chebyshev's inequality, approximated as $P(|T_{\\text{pooled}}| \\ge t_{\\text{crit}}) \\le \\min(1, R / t_{\\text{crit}}^2)$.\n\n6.  **Output Formatting**: The results for each test case—comprising a list of triplets (empirical pooled Type I error, empirical Welch Type I error, analytical bound) for each contrast—are collected. These are then formatted into a single, continuous string of nested lists with no whitespace, as per the problem specification, before being printed.",
            "answer": "```python\nimport numpy as np\nfrom scipy.stats import t\nimport json\n\ndef solve():\n    \"\"\"\n    Solves the biostatistics problem by performing Monte Carlo simulations and\n    analytical calculations for planned contrasts under different variance structures.\n    \"\"\"\n    test_cases = [\n        (4, [20, 20, 20, 20], [1.0, 1.0, 1.0, 1.0], [[1, -1, 0, 0], [0, 0, 1, -1], [0.5, 0.5, -0.5, -0.5]], 0.05, 20000, 12345),\n        (4, [20, 20, 20, 20], [1.0, 1.5, 1.0, 2.0], [[1, -1, 0, 0], [0, 0, 1, -1], [0.5, 0.5, -0.5, -0.5]], 0.05, 20000, 12345),\n        (4, [10, 30, 10, 30], [1.0, 2.0, 1.0, 2.0], [[1, -1, 0, 0], [0, 0, 1, -1], [0.5, 0.5, -0.5, -0.5]], 0.05, 20000, 12345),\n        (4, [5, 50, 5, 50], [0.5, 3.0, 0.5, 3.0], [[1, -1, 0, 0], [0, 0, 1, -1], [0.5, 0.5, -0.5, -0.5]], 0.05, 20000, 12345),\n    ]\n\n    all_results = []\n\n    for case in test_cases:\n        g, n_list, sigma_list, C_list, alpha, S, seed = case\n        \n        n = np.array(n_list, dtype=float)\n        sigmas = np.array(sigma_list, dtype=float)\n        contrasts = np.array(C_list, dtype=float)\n        true_variances = sigmas**2\n        \n        N = np.sum(n)\n        df_pooled = N - g\n\n        # --- Monte Carlo Simulation ---\n        rng = np.random.default_rng(seed)\n\n        group_means = np.zeros((S, g))\n        group_vars = np.zeros((S, g))\n\n        for i in range(g):\n            data = rng.normal(loc=0, scale=sigmas[i], size=(S, int(n[i])))\n            group_means[:, i] = np.mean(data, axis=1)\n            group_vars[:, i] = np.var(data, axis=1, ddof=1)\n        \n        sum_of_ss_weighted = np.sum((n - 1) * group_vars, axis=1)\n        s_p_squared = sum_of_ss_weighted / df_pooled\n\n        case_results = []\n        for c_vec in contrasts:\n            # L = sum(c_i * Y_bar_i) for each simulation\n            L = np.sum(c_vec * group_means, axis=1)\n            \n            # --- Pooled t-test ---\n            c_n_term_pooled_sum = np.sum(c_vec**2 / n)\n            se_pooled = np.sqrt(s_p_squared * c_n_term_pooled_sum)\n            t_pooled = np.divide(L, se_pooled, out=np.zeros_like(L), where=se_pooled>1e-12)\n            p_pooled = 2 * t.sf(np.abs(t_pooled), df=df_pooled)\n            type1_pooled = np.sum(p_pooled  alpha) / S\n            \n            # --- Welch-type t-test ---\n            var_welch_terms = (c_vec**2 / n) * group_vars\n            var_welch = np.sum(var_welch_terms, axis=1)\n            se_welch = np.sqrt(var_welch)\n            t_welch = np.divide(L, se_welch, out=np.zeros_like(L), where=se_welch>1e-12)\n\n            # Satterthwaite degrees of freedom\n            num_df_welch = var_welch**2\n            den_df_welch = np.sum(var_welch_terms**2 / (n - 1), axis=1)\n            \n            df_welch = np.ones_like(L)\n            valid_df_idx = den_df_welch > 1e-12\n            df_welch[valid_df_idx] = num_df_welch[valid_df_idx] / den_df_welch[valid_df_idx]\n\n            # Use vectorized p-value calculation\n            p_welch = 2 * t.sf(np.abs(t_welch), df=df_welch)\n            type1_welch = np.sum(p_welch  alpha) / S\n\n            # --- Analytical Upper Bound ---\n            t_crit = t.ppf(1 - alpha / 2, df=df_pooled)\n            \n            # Variance inflation factor R\n            var_true_L = np.sum(c_vec**2 * true_variances / n)\n            expected_sp_sq = np.sum((n - 1) * true_variances) / df_pooled\n            expected_var_L_model = expected_sp_sq * np.sum(c_vec**2 / n)\n            \n            R = np.divide(var_true_L, expected_var_L_model, out=np.zeros_like(var_true_L), where=expected_var_L_model > 1e-12)\n            \n            bound = min(1.0, R / t_crit**2)\n            \n            case_results.append([type1_pooled, type1_welch, bound])\n            \n        all_results.append(case_results)\n\n    # Format the final output string to have no spaces\n    print(json.dumps(all_results, separators=(',', ':')))\n\nsolve()\n```"
        }
    ]
}