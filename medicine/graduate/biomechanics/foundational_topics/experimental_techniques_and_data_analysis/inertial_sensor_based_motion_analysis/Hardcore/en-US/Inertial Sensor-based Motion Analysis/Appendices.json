{
    "hands_on_practices": [
        {
            "introduction": "Before inertial sensor data can be used for motion tracking, it must be calibrated to correct for inherent sensor errors. This first practice focuses on the magnetometer, which is crucial for heading estimation but is highly susceptible to environmental and device-specific distortions . You will derive the widely-used ellipsoid fitting method to compensate for hard-iron ($b_m$) and soft-iron ($A$) effects, a fundamental step in transforming distorted sensor readings into a clean measurement of the Earth's magnetic field.",
            "id": "4180076",
            "problem": "A triaxial magnetometer embedded in a wearable Inertial Measurement Unit (IMU) is used to measure the local geomagnetic field during slow rotations in a magnetically homogeneous indoor environment. Let the ideal, dimensionless, normalized geomagnetic field vector be denoted by $m \\in \\mathbb{R}^{3}$ with $|m| = 1$. The magnetometer measurement model in the device frame is\n$$\nm_{m} = A\\,m + b_{m} + \\varepsilon,\n$$\nwhere $A \\in \\mathbb{R}^{3 \\times 3}$ is an unknown full-rank matrix capturing soft-iron distortions and axis scale/misalignment, $b_{m} \\in \\mathbb{R}^{3}$ is an unknown hard-iron bias, and $\\varepsilon$ is measurement noise with zero mean. Assume the rotations sufficiently excite all orientations so that $m$ traverses the unit sphere.\n\n1) Starting from the above model and the definition $|m|=1$, show that, in the noise-free case, the set of measurements $m_{m}$ lie on an ellipsoid that satisfies\n$$\n\\left(m_{m} - b_{m}\\right)^{\\top} W \\left(m_{m} - b_{m}\\right) = 1,\n$$\nfor some symmetric positive definite matrix $W \\in \\mathbb{R}^{3 \\times 3}$. Express $W$ in terms of $A$.\n\n2) Write the ellipsoid equation in the expanded quadratic form\n$$\nm_{m}^{\\top} Q\\, m_{m} + 2\\, q^{\\top} m_{m} + q_{0} = 0,\n$$\nwith $Q \\in \\mathbb{R}^{3 \\times 3}$ symmetric, $q \\in \\mathbb{R}^{3}$, and $q_{0} \\in \\mathbb{R}$. Define the algebraic residual for a sample $m_{m}^{(i)}$ and pose the least-squares problem that minimizes the sum of squared algebraic residuals over $N$ samples, subject to a normalization constraint that avoids the trivial all-zero solution. Formulate explicitly a suitable linear design matrix and the corresponding generalized eigenvalue problem whose solution yields $\\left(Q, q, q_{0}\\right)$ up to a nonzero scale.\n\n3) Given a fitted triplet $\\left(Q, q, q_{0}\\right)$ with $Q$ symmetric positive definite, derive expressions to recover the hard-iron bias $b_{m}$ and the shape matrix $W$ in the centered ellipsoid form $\\left(m_{m} - b_{m}\\right)^{\\top} W \\left(m_{m} - b_{m}\\right) = 1$. Your derivation must ensure the unit right-hand side by an explicit scaling from the algebraic fit. Then, derive how to obtain a calibration matrix $A$ such that the calibrated measurements\n$$\nm_{c} \\triangleq A^{-1}\\left(m_{m} - b_{m}\\right)\n$$\nsatisfy $|m_{c}| = 1$, using only the requirement that $W$ be symmetric positive definite. State a unique choice for $A$ based on a matrix factorization of $W$.\n\n4) Now consider the following six noise-free measurements (in arbitrary units) obtained by holding the device so that the true field $m$ aligns with the device axes at the six cardinal directions. The measured vectors are:\n$$\n\\begin{aligned}\n\\text{Along } +x:  m_{m}^{(1)} = \\begin{pmatrix} 1.25 \\\\ -0.02 \\\\ 0.03 \\end{pmatrix}, \\quad\n\\text{Along } -x:  m_{m}^{(2)} = \\begin{pmatrix} -1.15 \\\\ -0.02 \\\\ 0.03 \\end{pmatrix},\\\\\n\\text{Along } +y:  m_{m}^{(3)} = \\begin{pmatrix} 0.05 \\\\ 0.78 \\\\ 0.03 \\end{pmatrix}, \\quad\n\\text{Along } -y:  m_{m}^{(4)} = \\begin{pmatrix} 0.05 \\\\ -0.82 \\\\ 0.03 \\end{pmatrix},\\\\\n\\text{Along } +z:  m_{m}^{(5)} = \\begin{pmatrix} 0.05 \\\\ -0.02 \\\\ 1.03 \\end{pmatrix}, \\quad\n\\text{Along } -z:  m_{m}^{(6)} = \\begin{pmatrix} 0.05 \\\\ -0.02 \\\\ -0.97 \\end{pmatrix}.\n\\end{aligned}\n$$\nUsing the derivation from parts $1$–$3$, compute the determinant of the calibration matrix $A$ obtained by choosing $A$ as the inverse of the Cholesky factor of $W$. Express your final answer as a dimensionless value rounded to four significant figures.",
            "solution": "We proceed from first principles of the affine measurement model and quadratic forms.\n\n1) The measurement model is $m_{m} = A m + b_{m} + \\varepsilon$. In the noise-free case with $\\varepsilon = 0$, we have $m_{m} - b_{m} = A m$. Left-multiplying by $A^{-1}$ gives $A^{-1}\\left(m_{m} - b_{m}\\right) = m$. Because $|m| = 1$, we obtain\n$$\n\\left\\|A^{-1}\\left(m_{m} - b_{m}\\right)\\right\\|^{2} = 1.\n$$\nEquivalently,\n$$\n\\left(m_{m} - b_{m}\\right)^{\\top} \\left(A^{-T} A^{-1}\\right) \\left(m_{m} - b_{m}\\right) = 1.\n$$\nThus, the set of measurements $m_{m}$ lies on the ellipsoid with shape matrix\n$$\nW = A^{-T} A^{-1},\n$$\nwhich is symmetric positive definite because $A$ is full rank.\n\n2) Any centered ellipsoid equation can be written in expanded quadratic form\n$$\nm_{m}^{\\top} Q\\, m_{m} + 2\\, q^{\\top} m_{m} + q_{0} = 0,\n$$\nwith $Q = Q^{\\top}$, $q \\in \\mathbb{R}^{3}$, and $q_{0} \\in \\mathbb{R}$. For a given sample $m_{m}^{(i)} \\in \\mathbb{R}^{3}$, the algebraic residual is\n$$\nr_{i} \\triangleq \\left(m_{m}^{(i)}\\right)^{\\top} Q\\, m_{m}^{(i)} + 2\\, q^{\\top} m_{m}^{(i)} + q_{0}.\n$$\nWith $N$ samples, we stack parameters into a vector $\\theta \\in \\mathbb{R}^{10}$ representing the independent entries of $Q$, $q$, and $q_{0}$. One convenient parametrization maps\n$$\n\\theta \\triangleq \\begin{pmatrix} q_{xx}  q_{yy}  q_{zz}  q_{yz}  q_{xz}  q_{xy}  q_{x}  q_{y}  q_{z}  q_{0} \\end{pmatrix}^{\\top},\n$$\nwhere $Q = \\begin{pmatrix} q_{xx}  q_{xy}  q_{xz} \\\\ q_{xy}  q_{yy}  q_{yz} \\\\ q_{xz}  q_{yz}  q_{zz} \\end{pmatrix}$ and $q = \\begin{pmatrix} q_{x} \\\\ q_{y} \\\\ q_{z} \\end{pmatrix}$. For each sample $m_{m}^{(i)} = \\begin{pmatrix} x_{i} \\\\ y_{i} \\\\ z_{i} \\end{pmatrix}$, the residual can be written linearly in $\\theta$ as\n$$\nr_{i} = d_{i}^{\\top} \\theta,\n$$\nwith the $10 \\times 1$ data vector\n$$\nd_{i} \\triangleq \\begin{pmatrix} x_{i}^{2} \\\\ y_{i}^{2} \\\\ z_{i}^{2} \\\\ 2 y_{i} z_{i} \\\\ 2 x_{i} z_{i} \\\\ 2 x_{i} y_{i} \\\\ 2 x_{i} \\\\ 2 y_{i} \\\\ 2 z_{i} \\\\ 1 \\end{pmatrix}.\n$$\nStacking $d_{i}^{\\top}$ as rows yields the design matrix $D \\in \\mathbb{R}^{N \\times 10}$. The least-squares problem minimizing the sum of squared algebraic residuals is\n$$\n\\min_{\\theta \\neq 0} \\; \\| D \\theta \\|_{2}^{2} \\quad \\text{subject to a normalization constraint on } \\theta,\n$$\nto avoid the trivial $\\theta = 0$ solution. A common normalization is to constrain a positive-definiteness–related quadratic form in the block $Q$; one practical choice is to enforce\n$$\n\\operatorname{trace}(Q) = 1,\n$$\nwhich can be written as a linear constraint $c^{\\top} \\theta = 1$ with $c = \\begin{pmatrix} 1  1  1  0  0  0  0  0  0  0 \\end{pmatrix}^{\\top}$. Using a Lagrange multiplier $\\lambda$, the constrained minimizer satisfies the Karush–Kuhn–Tucker conditions\n$$\nD^{\\top} D \\, \\theta = \\lambda \\, c, \\quad c^{\\top} \\theta = 1.\n$$\nEquivalently, one may eliminate the explicit linear constraint by posing a generalized eigenvalue problem. Define a symmetric constraint matrix $C \\in \\mathbb{R}^{10 \\times 10}$ that penalizes scaling in the top-left $3 \\times 3$ block corresponding to $Q$, for example\n$$\nC \\triangleq \\operatorname{diag}(1, 1, 1, 0, 0, 0, 0, 0, 0, 0).\n$$\nThen solve\n$$\n\\left(D^{\\top} D\\right) \\theta = \\lambda \\, C \\, \\theta,\n$$\nand select the generalized eigenvector $\\theta$ associated with the smallest positive generalized eigenvalue $\\lambda$ subject to the condition that the recovered $Q$ is positive definite. This yields $\\left(Q, q, q_{0}\\right)$ up to a nonzero scalar factor, which will be fixed in the next step.\n\n3) Matching the centered ellipsoid form\n$$\n\\left(m_{m} - b_{m}\\right)^{\\top} W \\left(m_{m} - b_{m}\\right) = 1\n$$\nto the expanded quadratic form gives\n$$\nQ = W, \\quad q = -W b_{m}, \\quad q_{0} = b_{m}^{\\top} W b_{m} - 1.\n$$\nFor any nonzero scaling of $\\left(Q, q, q_{0}\\right)$ returned by the algebraic fit with $Q$ symmetric positive definite, we first recover the bias as the center of the quadric\n$$\nb_{m} = - Q^{-1} q.\n$$\nSubstituting into the quadratic form yields\n$$\nm_{m}^{\\top} Q\\, m_{m} + 2\\, q^{\\top} m_{m} + q_{0} = \\left(m_{m} - b_{m}\\right)^{\\top} Q \\left(m_{m} - b_{m}\\right) - \\left(b_{m}^{\\top} Q b_{m} - q_{0}\\right).\n$$\nDefine the scalar\n$$\n\\alpha \\triangleq b_{m}^{\\top} Q b_{m} - q_{0}.\n$$\nTo enforce the unit right-hand side, set\n$$\nW = \\frac{Q}{\\alpha}.\n$$\nThen, by construction,\n$$\n\\left(m_{m} - b_{m}\\right)^{\\top} W \\left(m_{m} - b_{m}\\right) = 1.\n$$\nBecause $W$ is symmetric positive definite, we may factor it as a Cholesky factorization\n$$\nW = L^{\\top} L,\n$$\nwith $L$ upper triangular and invertible. A unique and numerically stable choice for the calibration matrix is then\n$$\nA = L^{-1},\n$$\nwhich ensures that the calibrated measurements satisfy\n$$\n|m_{c}|^{2} = \\left\\|A^{-1}\\left(m_{m} - b_{m}\\right)\\right\\|^{2} = \\left(m_{m} - b_{m}\\right)^{\\top} A^{-T} A^{-1} \\left(m_{m} - b_{m}\\right) = \\left(m_{m} - b_{m}\\right)^{\\top} W \\left(m_{m} - b_{m}\\right) = 1.\n$$\n\n4) For the six given measurements, we can exploit the symmetry of the cardinal directions. Let $m_{m}^{(+x)}$ and $m_{m}^{(-x)}$ denote the measurements along $+x$ and $-x$, and analogously for $y$ and $z$. The ellipsoid center satisfies\n$$\nb_{m} = \\frac{1}{2}\\left(m_{m}^{(+x)} + m_{m}^{(-x)}\\right) = \\frac{1}{2}\\left(m_{m}^{(+y)} + m_{m}^{(-y)}\\right) = \\frac{1}{2}\\left(m_{m}^{(+z)} + m_{m}^{(-z)}\\right),\n$$\nwhich yields, componentwise,\n$$\n\\begin{aligned}\nb_{x} = \\frac{1}{2}\\left(1.25 + \\left(-1.15\\right)\\right) = \\frac{1}{2}\\left(0.10\\right) = 0.05,\\\\\nb_{y} = \\frac{1}{2}\\left(-0.02 + \\left(-0.02\\right)\\right) = -0.02,\\\\\nb_{z} = \\frac{1}{2}\\left(0.03 + 0.03\\right) = 0.03.\n\\end{aligned}\n$$\nThus,\n$$\nb_{m} = \\begin{pmatrix} 0.05 \\\\ -0.02 \\\\ 0.03 \\end{pmatrix}.\n$$\nThe offsets from the center along each principal axis give the semi-axis lengths of the ellipsoid in measurement space, which equal the diagonal entries of $A$ when $A$ is diagonal. Specifically,\n$$\n\\begin{aligned}\n\\Delta x = \\left(1.25 - 0.05\\right) = 1.20, \\quad \\text{and } \\left(-1.15 - 0.05\\right) = -1.20,\\\\\n\\Delta y = \\left(0.78 - \\left(-0.02\\right)\\right) = 0.80, \\quad \\text{and } \\left(-0.82 - \\left(-0.02\\right)\\right) = -0.80,\\\\\n\\Delta z = \\left(1.03 - 0.03\\right) = 1.00, \\quad \\text{and } \\left(-0.97 - 0.03\\right) = -1.00.\n\\end{aligned}\n$$\nTherefore, the centered ellipsoid has principal semi-axis lengths $s_{x} = 1.20$, $s_{y} = 0.80$, and $s_{z} = 1.00$, aligned with the device axes. In this axis-aligned case, the shape matrix and calibration matrices are diagonal:\n$$\nW = \\operatorname{diag}\\!\\left(\\frac{1}{s_{x}^{2}}, \\frac{1}{s_{y}^{2}}, \\frac{1}{s_{z}^{2}}\\right) = \\operatorname{diag}\\!\\left(\\frac{1}{1.20^{2}}, \\frac{1}{0.80^{2}}, \\frac{1}{1.00^{2}}\\right),\n$$\nand its Cholesky factor is $L = \\operatorname{diag}\\!\\left(\\frac{1}{1.20}, \\frac{1}{0.80}, \\frac{1}{1.00}\\right)$. Thus the chosen calibration matrix is\n$$\nA = L^{-1} = \\operatorname{diag}\\!\\left(1.20, 0.80, 1.00\\right).\n$$\nThe requested determinant is\n$$\n\\det(A) = 1.20 \\times 0.80 \\times 1.00 = 0.96.\n$$\nRounding to four significant figures, the dimensionless determinant is $0.9600$.",
            "answer": "$$\\boxed{0.9600}$$"
        },
        {
            "introduction": "While gyroscopes are the primary sensor for tracking orientation changes, they suffer from a persistent bias ($\\boldsymbol{b}_{\\omega}$) that leads to cumulative drift error. This exercise demonstrates a fundamental technique to mitigate this issue: estimating and removing the bias using data from brief static intervals detected during movement . By applying principles of statistical estimation, you will quantify the performance of this method and understand how the accuracy of the bias estimate depends on the amount of available data.",
            "id": "4180126",
            "problem": "A three-axis Inertial Measurement Unit (IMU) gyroscope is mounted on a human shank during quiet standing in a biomechanics laboratory. The gyroscope output is modeled at discrete sample index $k$ by the additive measurement model\n$$\n\\boldsymbol{\\omega}_{m}(k) = \\boldsymbol{\\omega}(k) + \\boldsymbol{b}_{\\omega} + \\boldsymbol{n}(k),\n$$\nwhere $\\boldsymbol{\\omega}_{m}(k) \\in \\mathbb{R}^{3}$ is the measured angular velocity, $\\boldsymbol{\\omega}(k) \\in \\mathbb{R}^{3}$ is the true angular velocity, $\\boldsymbol{b}_{\\omega} \\in \\mathbb{R}^{3}$ is a constant bias vector over the experiment, and $\\boldsymbol{n}(k) \\in \\mathbb{R}^{3}$ is zero-mean, independent, identically distributed Gaussian noise with covariance matrix $\\boldsymbol{\\Sigma}_{\\omega} = \\mathrm{diag}(\\sigma_{x}^{2}, \\sigma_{y}^{2}, \\sigma_{z}^{2})$. Short static intervals are detected in real time by thresholding the Euclidean norm of the measured angular velocity over a moving window: a window is flagged static if the average of $\\|\\boldsymbol{\\omega}_{m}\\|$ over the window is less than a threshold $\\gamma$. Within a detected static interval, the biomechanics assumption is that the segment is not rotating, i.e., $\\boldsymbol{\\omega}(k) = \\boldsymbol{0}$ for all samples $k$ in that interval.\n\nYou are asked to develop and analyze a statistically principled estimator for the gyroscope bias $\\boldsymbol{b}_{\\omega}$ using data from the detected static intervals. Formulate an estimator using samples collected across all detected static intervals and derive, from first principles, the variance of this estimator in terms of the total number of samples aggregated from all static intervals and the noise covariance parameters. Then compute the mean squared error (defined as the trace of the estimator covariance) for the following specific experimental configuration:\n\n- Sampling frequency $f_{s} = 100\\,\\mathrm{Hz}$.\n- Noise standard deviations per axis are $\\sigma_{x} = 0.005\\,\\mathrm{rad/s}$, $\\sigma_{y} = 0.006\\,\\mathrm{rad/s}$, and $\\sigma_{z} = 0.004\\,\\mathrm{rad/s}$.\n- Five detected static intervals with durations $T_{1} = 0.30\\,\\mathrm{s}$, $T_{2} = 0.25\\,\\mathrm{s}$, $T_{3} = 0.20\\,\\mathrm{s}$, $T_{4} = 0.15\\,\\mathrm{s}$, and $T_{5} = 0.40\\,\\mathrm{s}$.\n\nAssume independence of noise across samples and axes and that the detection step identifies intervals correctly without further truncation of samples inside each interval. Express the final mean squared error in $(\\mathrm{rad/s})^{2}$ and round your answer to four significant figures. The final answer must be a single real number.",
            "solution": "The problem asks for the formulation and analysis of an estimator for the gyroscope bias vector $\\boldsymbol{b}_{\\omega}$ using data from detected static intervals. The final goal is to compute the mean squared error (MSE) of this estimator for a given experimental configuration.\n\nFirst, we establish the measurement model during the static intervals. The problem states that for a static interval, the true angular velocity is zero, i.e., $\\boldsymbol{\\omega}(k) = \\boldsymbol{0}$ for any sample index $k$ within such an interval. The general measurement model is given as:\n$$\n\\boldsymbol{\\omega}_{m}(k) = \\boldsymbol{\\omega}(k) + \\boldsymbol{b}_{\\omega} + \\boldsymbol{n}(k)\n$$\nSubstituting the static condition $\\boldsymbol{\\omega}(k) = \\boldsymbol{0}$, the model simplifies to:\n$$\n\\boldsymbol{\\omega}_{m}(k) = \\boldsymbol{b}_{\\omega} + \\boldsymbol{n}(k)\n$$\nHere, we are tasked with estimating the constant vector $\\boldsymbol{b}_{\\omega}$ from a series of noisy measurements $\\boldsymbol{\\omega}_{m}(k)$. The noise $\\boldsymbol{n}(k)$ is given to be zero-mean, independent, and identically distributed (i.i.d.) Gaussian noise with covariance $\\boldsymbol{\\Sigma}_{\\omega}$.\n\nA statistically principled estimator for a constant vector corrupted by additive zero-mean noise is the sample mean of the measurements. This estimator is the Maximum Likelihood Estimator (MLE) for a constant mean in Gaussian noise, and it is also the Best Linear Unbiased Estimator (BLUE). We aggregate all samples from all detected static intervals. Let the total number of samples be $N$. We can denote the sequence of these collected measurements as $\\{\\boldsymbol{\\omega}_{m}(j)\\}_{j=1}^{N}$. The estimator for $\\boldsymbol{b}_{\\omega}$, denoted as $\\hat{\\boldsymbol{b}}_{\\omega}$, is:\n$$\n\\hat{\\boldsymbol{b}}_{\\omega} = \\frac{1}{N} \\sum_{j=1}^{N} \\boldsymbol{\\omega}_{m}(j)\n$$\nNext, we derive the variance, which for a vector estimator is its covariance matrix, $\\mathrm{Cov}(\\hat{\\boldsymbol{b}}_{\\omega})$. First, let's find the expected value of the estimator to check for bias.\n$$\nE[\\hat{\\boldsymbol{b}}_{\\omega}] = E\\left[\\frac{1}{N} \\sum_{j=1}^{N} \\boldsymbol{\\omega}_{m}(j)\\right] = \\frac{1}{N} \\sum_{j=1}^{N} E[\\boldsymbol{\\omega}_{m}(j)]\n$$\nFor each measurement $j$, $E[\\boldsymbol{\\omega}_{m}(j)] = E[\\boldsymbol{b}_{\\omega} + \\boldsymbol{n}(j)] = E[\\boldsymbol{b}_{\\omega}] + E[\\boldsymbol{n}(j)]$. Since $\\boldsymbol{b}_{\\omega}$ is a constant vector, $E[\\boldsymbol{b}_{\\omega}] = \\boldsymbol{b}_{\\omega}$. The noise is zero-mean, so $E[\\boldsymbol{n}(j)] = \\boldsymbol{0}$. Thus, $E[\\boldsymbol{\\omega}_{m}(j)] = \\boldsymbol{b}_{\\omega}$.\nSubstituting this back into the expression for $E[\\hat{\\boldsymbol{b}}_{\\omega}]$:\n$$\nE[\\hat{\\boldsymbol{b}}_{\\omega}] = \\frac{1}{N} \\sum_{j=1}^{N} \\boldsymbol{b}_{\\omega} = \\frac{1}{N} (N \\boldsymbol{b}_{\\omega}) = \\boldsymbol{b}_{\\omega}\n$$\nThe estimator is unbiased.\n\nNow we compute the covariance matrix of the estimator.\n$$\n\\mathrm{Cov}(\\hat{\\boldsymbol{b}}_{\\omega}) = \\mathrm{Var}(\\hat{\\boldsymbol{b}}_{\\omega}) = \\mathrm{Var}\\left(\\frac{1}{N} \\sum_{j=1}^{N} \\boldsymbol{\\omega}_{m}(j)\\right)\n$$\nBecause the noise samples $\\boldsymbol{n}(j)$ are independent across the sample index $j$, the measurements $\\boldsymbol{\\omega}_{m}(j)$ are also independent. The variance of a sum of independent random vectors is the sum of their variances.\n$$\n\\mathrm{Cov}(\\hat{\\boldsymbol{b}}_{\\omega}) = \\frac{1}{N^2} \\sum_{j=1}^{N} \\mathrm{Var}(\\boldsymbol{\\omega}_{m}(j))\n$$\nThe variance of a single measurement is $\\mathrm{Var}(\\boldsymbol{\\omega}_{m}(j)) = \\mathrm{Var}(\\boldsymbol{b}_{\\omega} + \\boldsymbol{n}(j))$. Since $\\boldsymbol{b}_{\\omega}$ is constant, it does not affect the variance. Therefore, $\\mathrm{Var}(\\boldsymbol{\\omega}_{m}(j)) = \\mathrm{Var}(\\boldsymbol{n}(j)) = \\boldsymbol{\\Sigma}_{\\omega}$.\nSubstituting this into the covariance expression for the estimator:\n$$\n\\mathrm{Cov}(\\hat{\\boldsymbol{b}}_{\\omega}) = \\frac{1}{N^2} \\sum_{j=1}^{N} \\boldsymbol{\\Sigma}_{\\omega} = \\frac{1}{N^2} (N \\boldsymbol{\\Sigma}_{\\omega}) = \\frac{1}{N} \\boldsymbol{\\Sigma}_{\\omega}\n$$\nThe problem defines the Mean Squared Error (MSE) as the trace of the estimator's covariance matrix.\n$$\n\\mathrm{MSE} = \\mathrm{Tr}(\\mathrm{Cov}(\\hat{\\boldsymbol{b}}_{\\omega})) = \\mathrm{Tr}\\left(\\frac{1}{N} \\boldsymbol{\\Sigma}_{\\omega}\\right) = \\frac{1}{N} \\mathrm{Tr}(\\boldsymbol{\\Sigma}_{\\omega})\n$$\nThe noise covariance matrix is given as $\\boldsymbol{\\Sigma}_{\\omega} = \\mathrm{diag}(\\sigma_{x}^{2}, \\sigma_{y}^{2}, \\sigma_{z}^{2})$.\nThe trace of this matrix is the sum of its diagonal elements:\n$$\n\\mathrm{Tr}(\\boldsymbol{\\Sigma}_{\\omega}) = \\sigma_{x}^{2} + \\sigma_{y}^{2} + \\sigma_{z}^{2}\n$$\nSo, the final expression for the MSE is:\n$$\n\\mathrm{MSE} = \\frac{\\sigma_{x}^{2} + \\sigma_{y}^{2} + \\sigma_{z}^{2}}{N}\n$$\nNow we compute the numerical value for the given configuration. First, we find the total number of samples, $N$. The number of samples $N_i$ in an interval of duration $T_i$ with sampling frequency $f_s$ is $N_i = T_i \\times f_s$.\nThe durations of the five static intervals are $T_1 = 0.30\\,\\mathrm{s}$, $T_2 = 0.25\\,\\mathrm{s}$, $T_3 = 0.20\\,\\mathrm{s}$, $T_4 = 0.15\\,\\mathrm{s}$, and $T_5 = 0.40\\,\\mathrm{s}$. The sampling frequency is $f_s = 100\\,\\mathrm{Hz}$.\nThe number of samples from each interval is:\n$N_1 = 0.30 \\times 100 = 30$\n$N_2 = 0.25 \\times 100 = 25$\n$N_3 = 0.20 \\times 100 = 20$\n$N_4 = 0.15 \\times 100 = 15$\n$N_5 = 0.40 \\times 100 = 40$\nThe total number of samples is the sum:\n$N = N_1 + N_2 + N_3 + N_4 + N_5 = 30 + 25 + 20 + 15 + 40 = 130$.\n\nNext, we calculate the trace of the noise covariance matrix, $\\mathrm{Tr}(\\boldsymbol{\\Sigma}_{\\omega})$. The noise standard deviations are given as $\\sigma_{x} = 0.005\\,\\mathrm{rad/s}$, $\\sigma_{y} = 0.006\\,\\mathrm{rad/s}$, and $\\sigma_{z} = 0.004\\,\\mathrm{rad/s}$.\nThe variances are:\n$\\sigma_{x}^{2} = (0.005)^{2} = 0.000025 = 2.5 \\times 10^{-5}\\,(\\mathrm{rad/s})^{2}$\n$\\sigma_{y}^{2} = (0.006)^{2} = 0.000036 = 3.6 \\times 10^{-5}\\,(\\mathrm{rad/s})^{2}$\n$\\sigma_{z}^{2} = (0.004)^{2} = 0.000016 = 1.6 \\times 10^{-5}\\,(\\mathrm{rad/s})^{2}$\nThe trace is the sum of these variances:\n$$\n\\mathrm{Tr}(\\boldsymbol{\\Sigma}_{\\omega}) = (2.5 + 3.6 + 1.6) \\times 10^{-5} = 7.7 \\times 10^{-5}\\,(\\mathrm{rad/s})^{2}\n$$\nFinally, we compute the MSE:\n$$\n\\mathrm{MSE} = \\frac{\\mathrm{Tr}(\\boldsymbol{\\Sigma}_{\\omega})}{N} = \\frac{7.7 \\times 10^{-5}}{130} \\approx 5.9230769... \\times 10^{-7}\\,(\\mathrm{rad/s})^{2}\n$$\nRounding the result to four significant figures as requested gives $5.923 \\times 10^{-7}$.",
            "answer": "$$\n\\boxed{5.923 \\times 10^{-7}}\n$$"
        },
        {
            "introduction": "Effective sensor fusion requires not only accurate sensor models but also the ability to reject outlier measurements that violate those models. This final practice addresses the challenge of transient magnetic disturbances, which can severely corrupt heading estimates if not handled properly . You will design a statistical gating mechanism based on the Mahalanobis distance, a powerful tool for anomaly detection within a Kalman filtering framework, ensuring the robustness of your orientation estimator.",
            "id": "4180109",
            "problem": "A wearable Inertial Measurement Unit (IMU) comprising a tri-axial accelerometer, gyroscope, and magnetometer is mounted on the thorax to estimate heading (yaw) during indoor walking. The IMU runs an attitude Extended Kalman Filter (EKF) that fuses gyroscope and accelerometer with magnetometer measurements to bound yaw drift. The EKF uses a magnetometer update only when a statistical gate indicates the local magnetic environment is undisturbed.\n\nAssume the following physically realistic model. Let the navigation frame be the North-East-Down frame, and let the true unit Earth magnetic field direction in the navigation frame be the known vector $\\mathbf{b}^{n} \\in \\mathbb{R}^{3}$ with $|\\mathbf{b}^{n}| = 1$. The EKF has a current attitude estimate $\\widehat{\\mathbf{R}}_{n}^{b} \\in \\mathrm{SO}(3)$ that rotates vectors from the navigation frame to the body frame, and a small attitude estimation error parameterized by a body-frame small-angle vector $\\delta \\boldsymbol{\\theta} \\in \\mathbb{R}^{3}$, with $\\delta \\boldsymbol{\\theta} \\sim \\mathcal{N}(\\mathbf{0}, \\mathbf{P}_{\\theta})$. The predicted body-frame unit magnetic direction is $\\mathbf{h} = \\widehat{\\mathbf{R}}_{n}^{b} \\mathbf{b}^{n}$, where $|\\mathbf{h}| = 1$.\n\nThe magnetometer provides a measurement of the body-frame magnetic field that is normalized to unit length, yielding $\\mathbf{m}^{b} \\in \\mathbb{R}^{3}$ with $|\\mathbf{m}^{b}| \\approx 1$. In the absence of local disturbances, model the measurement (after normalization and bias compensation) as\n$$\n\\mathbf{m}^{b} \\approx \\mathbf{h} - [\\mathbf{h}]_{\\times} \\, \\delta \\boldsymbol{\\theta} + \\mathbf{v},\n$$\nwhere $[\\mathbf{h}]_{\\times} \\in \\mathbb{R}^{3 \\times 3}$ is the skew-symmetric matrix such that $[\\mathbf{h}]_{\\times} \\mathbf{x} = \\mathbf{h} \\times \\mathbf{x}$ for any $\\mathbf{x} \\in \\mathbb{R}^{3}$, and $\\mathbf{v} \\sim \\mathcal{N}(\\mathbf{0}, \\mathbf{R}_{m})$ is zero-mean measurement noise. Local magnetic disturbances add an unknown perturbation $\\mathbf{d}$ to the right-hand side, which may be non-Gaussian and time-varying. To avoid improper updates when disturbed, the EKF gates magnetometer updates using a residual constructed to be insensitive to magnitude changes and only sensitive to directional inconsistencies.\n\nDefine the orthogonal projector onto the tangent plane of the unit sphere at $\\mathbf{h}$ as $\\mathbf{P}(\\mathbf{h}) = \\mathbf{I}_{3} - \\mathbf{h} \\mathbf{h}^{\\top}$. Consider the residual\n$$\n\\mathbf{r} = \\mathbf{P}(\\mathbf{h}) \\left( \\mathbf{m}^{b} - \\mathbf{h} \\right),\n$$\nand assume that under undisturbed conditions ($\\mathbf{d} = \\mathbf{0}$), this residual can be linearized as\n$$\n\\mathbf{r} \\approx \\mathbf{H} \\, \\delta \\boldsymbol{\\theta} + \\mathbf{w}, \\quad \\text{with} \\quad \\mathbf{H} = - \\mathbf{P}(\\mathbf{h}) [\\mathbf{h}]_{\\times}, \\quad \\mathbf{w} = \\mathbf{P}(\\mathbf{h}) \\mathbf{v}.\n$$\nLet the undisturbed residual covariance be $\\mathbf{S} = \\mathbf{H} \\mathbf{P}_{\\theta} \\mathbf{H}^{\\top} + \\mathbf{P}(\\mathbf{h}) \\mathbf{R}_{m} \\mathbf{P}(\\mathbf{h})$. Because $\\mathbf{r}$ lies in the two-dimensional tangent plane, the effective residual has two degrees of freedom.\n\nStarting from fundamental kinematic linearization and Gaussian residual modeling, derive a statistically principled gating criterion based on the Mahalanobis norm of $\\mathbf{r}$ that maintains a false alarm probability (erroneously declaring a disturbance) of $\\alpha = 0.01$ under undisturbed conditions. Your derivation must justify the residual’s distribution and the number of degrees of freedom used in the gate. Then, compute the numerical value of the corresponding gating threshold for the Mahalanobis statistic. Round your final answer to four significant figures. Express the final answer as a dimensionless number.",
            "solution": "The problem requires the derivation of a statistically principled gating criterion for magnetometer measurements in an Extended Kalman Filter (EKF). The goal is to compute the numerical threshold for a Mahalanobis test statistic that ensures a false alarm probability of $\\alpha = 0.01$.\n\nThe gating procedure is a hypothesis test. The null hypothesis, $H_0$, is that the local magnetic environment is undisturbed ($\\mathbf{d}=\\mathbf{0}$). The alternative hypothesis, $H_1$, is that a disturbance is present ($\\mathbf{d} \\neq \\mathbf{0}$). A false alarm occurs when we reject $H_0$ even though it is true. The probability of this event is denoted by $\\alpha$.\n\nUnder the null hypothesis, the measurement residual $\\mathbf{r}$ is modeled as a linear transformation of zero-mean Gaussian random vectors. The attitude estimation error is given as $\\delta \\boldsymbol{\\theta} \\sim \\mathcal{N}(\\mathbf{0}, \\mathbf{P}_{\\theta})$ and the magnetometer measurement noise is $\\mathbf{v} \\sim \\mathcal{N}(\\mathbf{0}, \\mathbf{R}_{m})$. The linearized residual is given as $\\mathbf{r} \\approx \\mathbf{H} \\, \\delta \\boldsymbol{\\theta} + \\mathbf{w}$, where $\\mathbf{H} = - \\mathbf{P}(\\mathbf{h}) [\\mathbf{h}]_{\\times}$ and $\\mathbf{w} = \\mathbf{P}(\\mathbf{h}) \\mathbf{v}$. Since linear transformations of Gaussian random vectors result in a Gaussian random vector, the residual $\\mathbf{r}$ under $H_0$ is a zero-mean Gaussian random vector, $\\mathbf{r} \\sim \\mathcal{N}(\\mathbf{0}, \\mathbf{S})$. The covariance matrix $\\mathbf{S}$ is given by $\\mathbf{S} = \\mathbf{H} \\mathbf{P}_{\\theta} \\mathbf{H}^{\\top} + \\mathbf{P}(\\mathbf{h}) \\mathbf{R}_{m} \\mathbf{P}(\\mathbf{h})$.\n\nThe gating criterion is based on the Mahalanobis squared distance of the residual, defined as the test statistic $\\gamma$:\n$$\n\\gamma = \\mathbf{r}^{\\top} \\mathbf{S}^{\\dagger} \\mathbf{r}\n$$\nwhere $\\mathbf{S}^{\\dagger}$ is the Moore-Penrose pseudoinverse of the covariance matrix $\\mathbf{S}$.\n\nA fundamental theorem in statistics states that if a random vector $\\mathbf{x} \\in \\mathbb{R}^{n}$ follows a multivariate normal distribution $\\mathcal{N}(\\mathbf{0}, \\mathbf{\\Sigma})$ where the covariance matrix $\\mathbf{\\Sigma}$ has rank $k \\leq n$, then the quadratic form $\\mathbf{x}^{\\top} \\mathbf{\\Sigma}^{\\dagger} \\mathbf{x}$ follows a chi-squared distribution with $k$ degrees of freedom, denoted $\\chi^{2}(k)$.\n\nTo apply this theorem, we must determine the rank of the covariance matrix $\\mathbf{S}$. The residual vector is defined as $\\mathbf{r} = \\mathbf{P}(\\mathbf{h}) (\\mathbf{m}^{b} - \\mathbf{h})$. The matrix $\\mathbf{P}(\\mathbf{h}) = \\mathbf{I}_{3} - \\mathbf{h} \\mathbf{h}^{\\top}$ is an orthogonal projector. Its purpose is to project a vector onto the plane orthogonal to the unit vector $\\mathbf{h}$. The dimension of this plane is $2$. Consequently, any vector $\\mathbf{r}$ in the image of $\\mathbf{P}(\\mathbf{h})$ must lie within this two-dimensional subspace. The covariance matrix $\\mathbf{S}$ of such a random vector will be rank-deficient, with a rank of at most $2$. Assuming the uncertainty from $\\mathbf{P}_{\\theta}$ and $\\mathbf{R}_{m}$ is not degenerate with respect to this plane, the rank of $\\mathbf{S}$ will be exactly $2$. The problem statement confirms this by stating that \"the effective residual has two degrees of freedom.\" Therefore, the test statistic $\\gamma$ follows a chi-squared distribution with $k=2$ degrees of freedom:\n$$\n\\gamma \\sim \\chi^{2}(2)\n$$\nThe gating rule is to reject the measurement update if the observed statistic $\\gamma$ exceeds a certain threshold, $\\tau$. We seek to find the value of $\\tau$ such that the probability of a false alarm is $\\alpha = 0.01$. This is expressed as:\n$$\nP(\\gamma  \\tau | H_0) = \\alpha\n$$\nThis is equivalent to finding the value $\\tau$ for which the cumulative distribution function (CDF) of the $\\chi^{2}(2)$ distribution equals $1-\\alpha$. Let $F_{\\chi^{2}(k)}(x)$ be the CDF of the chi-squared distribution with $k$ degrees of freedom. We must solve for $\\tau$ in:\n$$\nF_{\\chi^{2}(2)}(\\tau) = 1 - \\alpha\n$$\nThe probability density function (PDF) of a $\\chi^{2}(k)$ distribution is $f(x;k) = \\frac{1}{2^{k/2} \\Gamma(k/2)} x^{k/2-1} \\exp(-x/2)$. For $k=2$, the Gamma function term is $\\Gamma(2/2)=\\Gamma(1)=1$. The PDF simplifies to:\n$$\nf(x;2) = \\frac{1}{2^{1} \\cdot 1} x^{1-1} \\exp(-x/2) = \\frac{1}{2}\\exp(-x/2)\n$$\nThis is the PDF of an exponential distribution with a rate parameter $\\lambda = 1/2$. The CDF for $x \\geq 0$ is found by integration:\n$$\nF_{\\chi^{2}(2)}(x) = \\int_{0}^{x} \\frac{1}{2}\\exp(-t/2) \\, dt = \\left[ -\\exp(-t/2) \\right]_{0}^{x} = 1 - \\exp(-x/2)\n$$\nWe can now solve for the threshold $\\tau$:\n$$\n1 - \\exp(-\\tau/2) = 1 - \\alpha\n$$\n$$\n\\exp(-\\tau/2) = \\alpha\n$$\nTaking the natural logarithm of both sides:\n$$\n-\\frac{\\tau}{2} = \\ln(\\alpha)\n$$\n$$\n\\tau = -2 \\ln(\\alpha)\n$$\nSubstituting the given false alarm probability $\\alpha = 0.01$:\n$$\n\\tau = -2 \\ln(0.01)\n$$\nThis can be calculated as:\n$$\n\\tau = -2 \\ln(10^{-2}) = -2 (-2 \\ln(10)) = 4 \\ln(10)\n$$\nUsing the value $\\ln(10) \\approx 2.30258509...$:\n$$\n\\tau \\approx 4 \\times 2.30258509... \\approx 9.21034037...\n$$\nThe problem requires the final answer to be rounded to four significant figures. The resulting dimensionless value for the gating threshold is $9.210$.\nThe gating criterion is therefore: if $\\mathbf{r}^{\\top} \\mathbf{S}^{\\dagger} \\mathbf{r}  9.210$, declare a disturbance and reject the magnetometer measurement.",
            "answer": "$$\n\\boxed{9.210}\n$$"
        }
    ]
}