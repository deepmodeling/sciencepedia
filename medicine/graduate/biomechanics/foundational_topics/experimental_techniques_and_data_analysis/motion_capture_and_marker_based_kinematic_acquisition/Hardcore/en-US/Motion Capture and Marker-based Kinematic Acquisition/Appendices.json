{
    "hands_on_practices": [
        {
            "introduction": "The foundation of optical motion capture is stereopsis: reconstructing three-dimensional information from two-dimensional images. This exercise guides you through the fundamental principles of stereo camera geometry to understand how measurement uncertainty in the image plane propagates to uncertainty in the reconstructed depth. By deriving this relationship, you will gain a quantitative understanding of how system design parameters, such as the baseline separation between cameras, directly influence the accuracy of three-dimensional data acquisition .",
            "id": "4192313",
            "problem": "In a calibrated optical motion capture system using two rectified pinhole cameras observing a single retroreflective marker, each camera’s optical axis is parallel, and the camera centers are separated by a horizontal baseline. The world coordinate frame is attached to the left camera center, with the baseline along the world $X$-axis and the optical axes aligned with the world $Z$-axis. The marker lies at depth $Z$ and projects to horizontal image coordinates $u_L$ and $u_R$ in the left and right cameras, respectively. The cameras are rectified so that the epipolar lines are horizontal and the disparity $d$ is defined as $d = u_L - u_R$. Assume a pinhole model and small, unbiased, independent, identically distributed Gaussian measurement noise in the horizontal image coordinates of each camera with standard deviation $\\sigma_{\\text{pix}}$ (in pixels).\n\nGiven:\n- Baseline length $b$ (in meters),\n- Camera focal length in object space $f_c$ (in meters),\n- Square pixel pitch $p$ (in meters per pixel), so the focal length in pixel units is $f_{\\text{pix}} = f_c / p$,\n- An operating depth $Z$ (in meters),\n- Per-camera horizontal localization noise standard deviation $\\sigma_{\\text{pix}}$ (in pixels),\n\nderive from first principles the first-order approximation for the variance of the reconstructed depth $\\operatorname{Var}(Z)$ as a function of $b$, $f_{\\text{pix}}$, $Z$, and the disparity variance $\\operatorname{Var}(d)$. Then, using independence of left and right measurements, express $\\operatorname{Var}(d)$ in terms of $\\sigma_{\\text{pix}}$. Finally, evaluate the depth variance numerically for the following scientifically plausible parameters:\n- $b = 1.0$ $\\text{m}$,\n- $f_c = 20 \\times 10^{-3}$ $\\text{m}$,\n- $p = 5 \\times 10^{-6}$ $\\text{m/pixel}$,\n- $Z = 5.0$ $\\text{m}$,\n- $\\sigma_{\\text{pix}} = 0.10$ $\\text{pixels}$.\n\nExpress the final variance in $\\text{m}^2$ and round your answer to three significant figures.",
            "solution": "We begin with the rectified stereo pinhole geometry. For a point with world coordinates $(X,Y,Z)$, the horizontal image coordinates in the left and right cameras, denoted $x_L$ and $x_R$ in sensor-length units, satisfy the pinhole relations\n$$\nx_L = \\frac{f X}{Z}, \\quad x_R = \\frac{f (X - b)}{Z},\n$$\nwhere $f$ is the focal length expressed in the same length units as $x_L$ and $x_R$, and $b$ is the baseline along the horizontal axis between camera centers. The disparity in sensor-length units is\n$$\nd_{\\ell} = x_L - x_R = \\frac{f X}{Z} - \\frac{f (X - b)}{Z} = \\frac{f b}{Z}.\n$$\nIf the pixel pitch is $p$ (meters per pixel), then the pixel-domain disparity $d$ and pixel-domain focal length $f_{\\text{pix}}$ are\n$$\nd = \\frac{d_{\\ell}}{p}, \\quad f_{\\text{pix}} = \\frac{f}{p}.\n$$\nThus,\n$$\nd = \\frac{f b}{p Z} = \\frac{f_{\\text{pix}} b}{Z}.\n$$\nSolving for $Z$ in terms of $d$ gives the reconstruction formula\n$$\nZ(d) = \\frac{f_{\\text{pix}} b}{d}.\n$$\n\nTo propagate disparity uncertainty into depth uncertainty, apply first-order (linear) uncertainty propagation for a differentiable function of a scalar random variable. If $Z = g(d)$ and $d$ has small variance, then\n$$\n\\operatorname{Var}(Z) \\approx \\left(\\frac{\\partial g}{\\partial d}\\right)^{2} \\operatorname{Var}(d).\n$$\nHere $g(d) = \\frac{f_{\\text{pix}} b}{d}$, so\n$$\n\\frac{\\partial Z}{\\partial d} = - \\frac{f_{\\text{pix}} b}{d^{2}}.\n$$\nIt is useful to re-express the derivative in terms of $Z$ itself. Using $d = \\frac{f_{\\text{pix}} b}{Z}$, we have\n$$\n\\frac{\\partial Z}{\\partial d} = - \\frac{f_{\\text{pix}} b}{\\left(\\frac{f_{\\text{pix}} b}{Z}\\right)^{2}} = - \\frac{Z^{2}}{f_{\\text{pix}} b}.\n$$\nTherefore, the depth variance as a function of disparity variance is\n$$\n\\operatorname{Var}(Z) \\approx \\left(\\frac{Z^{2}}{f_{\\text{pix}} b}\\right)^{2} \\operatorname{Var}(d) = \\frac{Z^{4}}{f_{\\text{pix}}^{2} b^{2}} \\operatorname{Var}(d).\n$$\n\nNext, relate the disparity variance to per-camera pixel localization noise. Let the measured horizontal pixel coordinates be\n$$\nU_L = u_L^{\\ast} + \\epsilon_L, \\quad U_R = u_R^{\\ast} + \\epsilon_R,\n$$\nwhere $u_L^{\\ast}$ and $u_R^{\\ast}$ are the noise-free coordinates and $\\epsilon_L, \\epsilon_R$ are independent, zero-mean Gaussian noises with $\\operatorname{Var}(\\epsilon_L) = \\operatorname{Var}(\\epsilon_R) = \\sigma_{\\text{pix}}^{2}$. The measured disparity is $D = U_L - U_R$, hence\n$$\n\\operatorname{Var}(D) = \\operatorname{Var}(U_L) + \\operatorname{Var}(U_R) - 2\\,\\operatorname{Cov}(U_L,U_R).\n$$\nIndependence implies $\\operatorname{Cov}(U_L,U_R) = 0$, so\n$$\n\\operatorname{Var}(d) = \\operatorname{Var}(D) = \\sigma_{\\text{pix}}^{2} + \\sigma_{\\text{pix}}^{2} = 2 \\sigma_{\\text{pix}}^{2}.\n$$\n\nCombining, the first-order depth variance is\n$$\n\\operatorname{Var}(Z) \\approx \\frac{Z^{4}}{f_{\\text{pix}}^{2} b^{2}} \\cdot 2 \\sigma_{\\text{pix}}^{2}.\n$$\n\nNow evaluate numerically for the given parameters. Compute $f_{\\text{pix}}$ from $f_c$ and $p$:\n$$\nf_{\\text{pix}} = \\frac{f_c}{p} = \\frac{20 \\times 10^{-3}}{5 \\times 10^{-6}} = 4000.\n$$\nGiven $b = 1.0$, $Z = 5.0$, and $\\sigma_{\\text{pix}} = 0.10$, we have\n$$\n\\operatorname{Var}(d) = 2 \\sigma_{\\text{pix}}^{2} = 2 \\times (0.10)^{2} = 0.02,\n$$\nand\n$$\n\\operatorname{Var}(Z) \\approx \\frac{(5.0)^{4}}{(4000)^{2} (1.0)^{2}} \\times 0.02.\n$$\nCompute the factors:\n$$\n(5.0)^{4} = 625, \\quad (4000)^{2} = 16{,}000{,}000,\n$$\nso\n$$\n\\operatorname{Var}(Z) \\approx \\frac{625}{16{,}000{,}000} \\times 0.02 = 3.90625 \\times 10^{-5} \\times 0.02 = 7.8125 \\times 10^{-7}.\n$$\nTherefore, the depth variance is\n$$\n\\operatorname{Var}(Z) \\approx 7.8125 \\times 10^{-7} \\ \\text{m}^{2}.\n$$\nRounding to three significant figures yields\n$$\n\\operatorname{Var}(Z) \\approx 7.81 \\times 10^{-7} \\ \\text{m}^{2}.\n$$",
            "answer": "$$\\boxed{7.81 \\times 10^{-7}}$$"
        },
        {
            "introduction": "While the ideal pinhole model provides a powerful first approximation, real-world camera lenses introduce geometric distortions that can systematically bias three-dimensional reconstructions if not properly corrected. This practice moves from the random error analysis of the previous problem to an analysis of systematic bias, focusing on the common issue of radial lens distortion. Through a guided simulation, you will quantify how neglecting distortion during camera calibration leads to significant errors in triangulated marker positions, especially for markers viewed at the periphery of the image .",
            "id": "4192373",
            "problem": "Consider a marker-based kinematic acquisition scenario with two synchronized perspective cameras observing a single marker. Each camera obeys the pinhole model for the mapping from three-dimensional world coordinates to two-dimensional image coordinates, and both cameras share identical intrinsic parameters. The cameras are mounted such that their optical axes are approximately aligned with the world $z$-axis. Let the left camera have rotation matrix $R_1 = I$ and center $C_1 = (0,0,0)$, and the right camera have rotation matrix $R_2$ equal to a yaw rotation about the world $y$-axis by a small angle $\\phi$ (specified below, in radians) and center $C_2 = (B,0,0)$, where $B$ is the inter-camera baseline. Use the following intrinsic parameters: focal length $f = 1200$ pixels, principal point $(c_x, c_y) = (960, 540)$ pixels, and square pixels. The image resolution is $1920 \\times 1080$ pixels. Use a Brown-Conrady radial distortion model defined on normalized image coordinates.\n\nFundamental base and definitions:\n- Pinhole projection maps a three-dimensional point $X = (X, Y, Z)$ in world coordinates to normalized camera coordinates via $x_n = X_{\\text{cam}}/Z_{\\text{cam}}$ and $y_n = Y_{\\text{cam}}/Z_{\\text{cam}}$, where $X_{\\text{cam}} = R(X - C)$, with $R$ the camera rotation and $C$ the camera center. Pixel coordinates are then $u = f x_n + c_x$ and $v = f y_n + c_y$.\n- Brown-Conrady radial distortion modifies normalized coordinates $(x_n, y_n)$ to distorted coordinates $(x_d, y_d)$ such that $x_d = x_n s(r)$ and $y_d = y_n s(r)$, where $s(r) = 1 + k_1 r^2 + k_2 r^4$ and $r^2 = x_n^2 + y_n^2$.\n- Motion capture systems triangulate the three-dimensional position by intersecting the two viewing rays. If $d_1$ and $d_2$ are the unit direction vectors (in world coordinates) of rays from camera centers $C_1$ and $C_2$ that go through the measured pixel coordinates, then the closest points on the lines $L_1(s_1) = C_1 + s_1 d_1$ and $L_2(s_2) = C_2 + s_2 d_2$ solve a least-squares intersection, yielding an estimated point $\\hat{X}$ as the midpoint of the closest approach.\n\nTask:\nWrite a program that quantifies how neglecting radial distortion in calibration biases the three-dimensional reconstruction. For each test case, do the following:\n1. Generate the two distorted image measurements $(u_{d,i}, v_{d,i})$ for cameras $i \\in \\{1,2\\}$ by forward projecting the ground-truth world point using the pinhole model on normalized coordinates followed by Brown-Conrady radial distortion with coefficients $(k_1, k_2)$, then converting to pixels with $(f, c_x, c_y)$.\n2. Reconstruct the three-dimensional point $\\hat{X}$ by triangulation assuming an ideal pinhole model with no distortion, i.e., treat $(u_{d,i}, v_{d,i})$ as if they were undistorted pinhole measurements. Construct unit rays in each camera’s local frame from normalized coordinates $(x_{u,i}, y_{u,i}) = \\left((u_{d,i} - c_x)/f, (v_{d,i} - c_y)/f\\right)$ and map them to world coordinates using $R_i^\\top$. Intersect the rays by computing the midpoint of the pair of closest points.\n3. Compute two error metrics:\n   - Reprojection error at the periphery: For each camera, reproject $\\hat{X}$ using the ideal pinhole model (no distortion), yielding $(u_{\\text{pin},i}, v_{\\text{pin},i})$. Measure the Euclidean reprojection residual $e_i = \\sqrt{(u_{d,i} - u_{\\text{pin},i})^2 + (v_{d,i} - v_{\\text{pin},i})^2}$ in pixels. Identify the camera with the larger radial distance from the principal point, $r_{\\text{px},i} = \\sqrt{(u_{d,i} - c_x)^2 + (v_{d,i} - c_y)^2}$, and report the corresponding reprojection error $e_{\\text{peri}}$ for that camera (in pixels).\n   - Depth bias: Compute the absolute error in depth, $\\Delta Z = | \\hat{Z} - Z_{\\text{true}} |$, in meters, where $\\hat{Z}$ is the $z$-coordinate of the reconstructed point and $Z_{\\text{true}}$ is the ground-truth depth.\n\nUse the following fixed parameters for all cases:\n- Baseline $B = 0.25$ meters.\n- Yaw angle $\\phi = 3\\pi/180$ radians.\n- Focal length $f = 1200$ pixels.\n- Principal point $(c_x, c_y) = (960, 540)$ pixels.\n\nTest suite:\nEach test case is a tuple $(X, Y, Z, k_1, k_2)$ with coordinates in meters and distortion coefficients dimensionless, where $Z$ is the ground-truth depth. The four cases are:\n- Case 1 (baseline, zero distortion, centered): $(0.0, 0.0, 3.0, 0.0, 0.0)$.\n- Case 2 (moderate distortion, centered): $(0.0, 0.0, 3.0, -0.2, 0.05)$.\n- Case 3 (moderate distortion, horizontal periphery): $(2.1, 0.0, 3.0, -0.2, 0.05)$.\n- Case 4 (strong distortion, combined horizontal and vertical periphery): $(2.1, 1.2, 3.0, -0.35, 0.10)$.\n\nAngle unit specification: All angles are in radians.\n\nOutput specification:\nFor each test case, return a two-element list $[e_{\\text{peri}}, \\Delta Z]$ where $e_{\\text{peri}}$ is in pixels and $\\Delta Z$ is in meters. Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, in the order of the test suite, with each per-case result itself enclosed in square brackets. For example, the output should look like $[[e_1,\\Delta Z_1],[e_2,\\Delta Z_2],[e_3,\\Delta Z_3],[e_4,\\Delta Z_4]]$.",
            "solution": "The solution begins from the pinhole camera model, which provides the mapping from world coordinates to normalized image coordinates, and then to pixel coordinates via multiplication by the focal length and addition of the principal point. Let a three-dimensional point in world coordinates be denoted by $X = (X, Y, Z)^\\top$. For camera $i$ with rotation $R_i$ and center $C_i$, the camera-frame coordinates are given by\n$$\nX_{\\text{cam}, i} = R_i \\left( X - C_i \\right).\n$$\nDefining $X_{\\text{cam}, i} = (X_i, Y_i, Z_i)$, the normalized undistorted pinhole coordinates are\n$$\nx_{n,i} = \\frac{X_i}{Z_i}, \\quad y_{n,i} = \\frac{Y_i}{Z_i}.\n$$\nThe Brown-Conrady radial distortion on normalized coordinates is given by\n$$\nr_i^2 = x_{n,i}^2 + y_{n,i}^2, \\quad s(r_i) = 1 + k_1 r_i^2 + k_2 r_i^4,\n$$\nand the distorted normalized coordinates are\n$$\nx_{d,i} = x_{n,i} \\, s(r_i), \\quad y_{d,i} = y_{n,i} \\, s(r_i).\n$$\nConverting to pixel coordinates with focal length $f$ and principal point $(c_x, c_y)$ yields\n$$\nu_{d,i} = f \\, x_{d,i} + c_x, \\quad v_{d,i} = f \\, y_{d,i} + c_y.\n$$\nThese $(u_{d,i}, v_{d,i})$ are the synthetic measurements produced by the forward model when distortion is present.\n\nThe reconstruction is performed under the false assumption of no distortion. Thus, we form undistorted normalized coordinates by inverting only the pinhole mapping:\n$$\nx_{u,i} = \\frac{u_{d,i} - c_x}{f}, \\quad y_{u,i} = \\frac{v_{d,i} - c_y}{f}.\n$$\nIn camera coordinates, the ray direction toward the point is proportional to\n$$\n\\tilde{d}_{\\text{cam}, i} = \\begin{bmatrix} x_{u,i} \\\\ y_{u,i} \\\\ 1 \\end{bmatrix},\n$$\nwhich we normalize to unit length,\n$$\nd_{\\text{cam}, i} = \\frac{\\tilde{d}_{\\text{cam}, i}}{\\|\\tilde{d}_{\\text{cam}, i}\\|_2}.\n$$\nTo express the rays in world coordinates, we apply the inverse rotation:\n$$\nd_i = R_i^\\top \\, d_{\\text{cam}, i}.\n$$\nThe rays in world coordinates are thus\n$$\nL_1(s_1) = C_1 + s_1 d_1, \\quad L_2(s_2) = C_2 + s_2 d_2.\n$$\nThe closest points on these skew lines solve the standard least-squares line-line intersection problem. Define\n$$\nw_0 = C_1 - C_2, \\quad a = d_1^\\top d_1, \\quad b = d_1^\\top d_2, \\quad c = d_2^\\top d_2, \\quad d = d_1^\\top w_0, \\quad e = d_2^\\top w_0.\n$$\nAssuming the lines are not exactly parallel (so that $a c - b^2 \\neq 0$), the optimal parameters are\n$$\ns_1^\\star = \\frac{b e - c d}{a c - b^2}, \\quad s_2^\\star = \\frac{a e - b d}{a c - b^2}.\n$$\nThe reconstructed three-dimensional position is taken as the midpoint of the two closest points:\n$$\n\\hat{X} = \\frac{1}{2}\\left( \\left(C_1 + s_1^\\star d_1\\right) + \\left(C_2 + s_2^\\star d_2\\right) \\right),\n$$\nwith depth $\\hat{Z}$ equal to the $z$-component of $\\hat{X}$.\n\nTo quantify the modeling bias, we compute two metrics.\n\nFirst, the periphery reprojection error. We reproject $\\hat{X}$ into each camera using the ideal pinhole mapping (no distortion):\n$$\n\\hat{X}_{\\text{cam}, i} = R_i \\left( \\hat{X} - C_i \\right), \\quad \\hat{x}_{n,i} = \\frac{\\hat{X}_{\\text{cam}, i,x}}{\\hat{X}_{\\text{cam}, i,z}}, \\quad \\hat{y}_{n,i} = \\frac{\\hat{X}_{\\text{cam}, i,y}}{\\hat{X}_{\\text{cam}, i,z}},\n$$\nand then\n$$\nu_{\\text{pin}, i} = f \\, \\hat{x}_{n,i} + c_x, \\quad v_{\\text{pin}, i} = f \\, \\hat{y}_{n,i} + c_y.\n$$\nThe residual in pixels for camera $i$ is\n$$\ne_i = \\sqrt{(u_{d,i} - u_{\\text{pin}, i})^2 + (v_{d,i} - v_{\\text{pin}, i})^2}.\n$$\nWe identify the more peripheral view by the larger radial pixel distance\n$$\nr_{\\text{px}, i} = \\sqrt{(u_{d,i} - c_x)^2 + (v_{d,i} - c_y)^2},\n$$\nand report\n$$\ne_{\\text{peri}} = \\max\\{ e_1 \\text{ if } r_{\\text{px},1} \\ge r_{\\text{px},2}, \\; e_2 \\text{ otherwise} \\}.\n$$\n\nSecond, the depth bias is the absolute difference between the reconstructed depth and the ground-truth depth:\n$$\n\\Delta Z = \\left| \\hat{Z} - Z_{\\text{true}} \\right|.\n$$\n\nScientific rationale: Ignoring distortion treats curved rays as if they were straight through the ideal pinhole model, which perturbs the direction vectors used in triangulation. The perturbation grows with the radial distance $r$ since the distortion scale $s(r)$ departs more from unity as $r$ increases. This yields a systematic bias in the intersection of rays, causing depth errors that depend on baseline $B$, viewing geometry via $R_i$, and the nonlinearity of the distortion function. The reprojection residual under an ideal pinhole model is a direct measure of the mismatch between the model and the distorted measurements and is expected to be negligible at the center ($r \\approx 0$) and large at the periphery (large $r$).\n\nAlgorithmic steps implemented in the program:\n1. For each test case $(X, Y, Z, k_1, k_2)$, compute distorted pixel measurements for both cameras using the pinhole projection on normalized coordinates followed by Brown-Conrady radial distortion, then convert to pixels.\n2. Form undistorted normalized coordinates from the distorted pixels as if no distortion were present. Construct unit ray directions in camera frames and rotate them into world coordinates.\n3. Solve for the closest points on the pair of rays using the least-squares intersection formulas to obtain $\\hat{X}$ and its depth $\\hat{Z}$.\n4. Compute the per-camera reprojection residuals under the ideal pinhole model and select the residual for the camera with the larger radial pixel distance from the principal point as $e_{\\text{peri}}$.\n5. Compute the depth bias $\\Delta Z$ as the absolute difference between $\\hat{Z}$ and $Z$.\n6. Output, for each test case, the pair $[e_{\\text{peri}}, \\Delta Z]$ in the specified format.\n\nAll angles are handled in radians; we set the yaw angle to $\\phi = 3\\pi/180$. The baseline $B$ is $0.25$ meters. Distortion coefficients are dimensionless and applied to normalized coordinates, ensuring scientific realism across periphery and center cases. The test suite includes a zero-distortion boundary case, centered moderate distortion, horizontal periphery under moderate distortion, and combined horizontal and vertical periphery under strong distortion, offering coverage across key facets of the reconstruction bias due to neglecting distortion.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef rotation_y(phi):\n    \"\"\"Rotation matrix about the world y-axis by angle phi (radians).\"\"\"\n    c = np.cos(phi)\n    s = np.sin(phi)\n    return np.array([[ c, 0.0,  s],\n                     [0.0, 1.0, 0.0],\n                     [-s, 0.0,  c]], dtype=float)\n\ndef project_with_radial_distortion(X_world, R, C, f, cx, cy, k1, k2):\n    \"\"\"\n    Project X_world into pixel coordinates using pinhole model on normalized\n    coordinates followed by Brown-Conrady radial distortion (k1, k2).\n    \"\"\"\n    X_cam = R @ (X_world - C)\n    Xc, Yc, Zc = X_cam\n    x_n = Xc / Zc\n    y_n = Yc / Zc\n    r2 = x_n * x_n + y_n * y_n\n    s = 1.0 + k1 * r2 + k2 * (r2 * r2)\n    x_d = x_n * s\n    y_d = y_n * s\n    u = f * x_d + cx\n    v = f * y_d + cy\n    return np.array([u, v], dtype=float)\n\ndef ray_from_pixel_no_distortion(u, v, f, cx, cy, R, C):\n    \"\"\"\n    Construct unit ray direction in world coordinates assuming an ideal pinhole (no distortion).\n    \"\"\"\n    x_u = (u - cx) / f\n    y_u = (v - cy) / f\n    d_cam = np.array([x_u, y_u, 1.0], dtype=float)\n    d_cam /= np.linalg.norm(d_cam)\n    # Map direction from camera to world by inverse rotation\n    d_world = R.T @ d_cam\n    # Ray originates at camera center C\n    return d_world\n\ndef triangulate_midpoint(C1, d1, C2, d2):\n    \"\"\"\n    Triangulate via closest-point midpoint of two skew rays:\n    L1(s1) = C1 + s1 d1, L2(s2) = C2 + s2 d2.\n    \"\"\"\n    w0 = C1 - C2\n    a = np.dot(d1, d1)\n    b = np.dot(d1, d2)\n    c = np.dot(d2, d2)\n    d = np.dot(d1, w0)\n    e = np.dot(d2, w0)\n    denom = a * c - b * b\n    if np.abs(denom) < 1e-12:\n        # Rays are nearly parallel; fall back to average of projecting from one ray\n        s1 = -d / a if np.abs(a) > 1e-12 else 0.0\n        p1 = C1 + s1 * d1\n        # Project p1 onto second ray\n        # s2 = argmin ||(C2 + s2 d2) - p1||^2 => s2 = d2·(p1 - C2)\n        s2 = np.dot(d2, (p1 - C2))\n        p2 = C2 + s2 * d2\n        return 0.5 * (p1 + p2)\n    s1 = (b * e - c * d) / denom\n    s2 = (a * e - b * d) / denom\n    p1 = C1 + s1 * d1\n    p2 = C2 + s2 * d2\n    return 0.5 * (p1 + p2)\n\ndef pinhole_reproject(X_world, R, C, f, cx, cy):\n    \"\"\"Reproject a 3D point using an ideal pinhole model (no distortion).\"\"\"\n    X_cam = R @ (X_world - C)\n    Xc, Yc, Zc = X_cam\n    x_n = Xc / Zc\n    y_n = Yc / Zc\n    u = f * x_n + cx\n    v = f * y_n + cy\n    return np.array([u, v], dtype=float)\n\ndef solve():\n    # Intrinsics\n    f = 1200.0\n    cx, cy = 960.0, 540.0\n    # Extrinsics\n    B = 0.25  # meters\n    phi = 3.0 * np.pi / 180.0  # radians\n    R1 = np.eye(3)\n    C1 = np.array([0.0, 0.0, 0.0], dtype=float)\n    R2 = rotation_y(phi)\n    C2 = np.array([B, 0.0, 0.0], dtype=float)\n\n    # Define the test cases from the problem statement.\n    # Each case: (X, Y, Z, k1, k2)\n    test_cases = [\n        (0.0, 0.0, 3.0, 0.0, 0.0),           # Case 1: baseline, zero distortion, centered\n        (0.0, 0.0, 3.0, -0.2, 0.05),         # Case 2: moderate distortion, centered\n        (2.1, 0.0, 3.0, -0.2, 0.05),         # Case 3: moderate distortion, horizontal periphery\n        (2.1, 1.2, 3.0, -0.35, 0.10),        # Case 4: strong distortion, combined periphery\n    ]\n\n    results = []\n    for X, Y, Z, k1, k2 in test_cases:\n        X_world_true = np.array([X, Y, Z], dtype=float)\n\n        # Forward projection with distortion for both cameras\n        uvd1 = project_with_radial_distortion(X_world_true, R1, C1, f, cx, cy, k1, k2)\n        uvd2 = project_with_radial_distortion(X_world_true, R2, C2, f, cx, cy, k1, k2)\n\n        # Construct rays assuming no distortion\n        d1 = ray_from_pixel_no_distortion(uvd1[0], uvd1[1], f, cx, cy, R1, C1)\n        d2 = ray_from_pixel_no_distortion(uvd2[0], uvd2[1], f, cx, cy, R2, C2)\n\n        # Triangulate midpoint\n        X_hat = triangulate_midpoint(C1, d1, C2, d2)\n        Z_hat = X_hat[2]\n\n        # Reproject using ideal pinhole\n        upin1 = pinhole_reproject(X_hat, R1, C1, f, cx, cy)\n        upin2 = pinhole_reproject(X_hat, R2, C2, f, cx, cy)\n\n        # Reprojection residuals per camera (compare to distorted observations)\n        e1 = np.linalg.norm(uvd1 - upin1)\n        e2 = np.linalg.norm(uvd2 - upin2)\n\n        # Peripheral camera selection by larger radial pixel distance from principal point\n        rpx1 = np.linalg.norm(uvd1 - np.array([cx, cy], dtype=float))\n        rpx2 = np.linalg.norm(uvd2 - np.array([cx, cy], dtype=float))\n        e_peri = e1 if rpx1 >= rpx2 else e2\n\n        # Depth bias\n        dZ = abs(Z_hat - Z)\n\n        # Append result as [reproj_error_px, depth_error_m]\n        results.append([float(e_peri), float(dZ)])\n\n    # Final print statement in the exact required format.\n    # Single line output: list of per-case [e_peri, dZ]\n    print(f\"[{','.join('[' + ','.join(map(str, pair)) + ']' for pair in results)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "Ultimately, the goal of motion capture in biomechanics is not just to locate markers in space, but to compute meaningful kinematic variables like joint angles and axes. This final practice bridges the gap between three-dimensional marker data and its biomechanical interpretation by exploring how errors in landmark positions propagate to these derived quantities. You will conduct a sensitivity analysis to determine how misplacement of anatomical landmarks—a common issue due to soft tissue artifact—affects the computed orientation of a joint axis, providing critical insight into the reliability of your kinematic analysis .",
            "id": "4192315",
            "problem": "You will implement a complete, runnable program that quantifies how misplacement of anatomical landmarks alters a joint axis defined from marker-based kinematics. The context is the knee flexion-extension axis defined by medial and lateral epicondyle landmarks in three-dimensional motion capture. Start from fundamental definitions of vectors in three-dimensional Euclidean space and the definition of an angle between unit vectors via the dot product. Use first principles to derive a sensitivity analysis that maps small landmark perturbations to small angular deviations of the unit axis vector.\n\nDefinitions and assumptions:\n- The joint axis is defined by two anatomical landmarks: a lateral epicondyle position $\\mathbf{L}\\in\\mathbb{R}^3$ and a medial epicondyle position $\\mathbf{M}\\in\\mathbb{R}^3$, both expressed in meters in a global Cartesian coordinate system.\n- The baseline axis direction is $\\mathbf{u}=\\dfrac{\\mathbf{L}-\\mathbf{M}}{\\|\\mathbf{L}-\\mathbf{M}\\|}$, where $\\|\\cdot\\|$ is the Euclidean norm.\n- A misplacement of the landmarks is modeled as small additive perturbations $\\delta\\mathbf{L}$ and $\\delta\\mathbf{M}$ (in meters), producing a perturbed axis direction $\\tilde{\\mathbf{u}}$ computed from $\\mathbf{L}+\\delta\\mathbf{L}$ and $\\mathbf{M}+\\delta\\mathbf{M}$ by the same definition.\n- The angular deviation $\\theta$ between the baseline and perturbed axes is defined by $\\theta=\\arccos\\!\\left(\\mathbf{u}^\\top \\tilde{\\mathbf{u}}\\right)$ in radians. For reporting, you must express angular quantities in degrees to six decimal places.\n- Perform a first-order sensitivity analysis of the unit axis direction with respect to each coordinate of $\\mathbf{L}$ and $\\mathbf{M}$. Treat the three standard coordinate directions as the orthonormal basis vectors in $\\mathbb{R}^3$.\n\nYour tasks for each test case:\n1. Compute the baseline unit axis $\\mathbf{u}$ from the provided $\\mathbf{L}$ and $\\mathbf{M}$.\n2. Compute a worst-case small-angle bound (in degrees) for isotropic landmark misplacement when each landmark perturbation satisfies $\\|\\delta\\mathbf{L}\\|\\le \\varepsilon$ and $\\|\\delta\\mathbf{M}\\|\\le \\varepsilon$ (with $\\varepsilon$ given in meters). Use first principles and linearization to obtain a bound that depends on $\\varepsilon$ and the baseline separation $\\|\\mathbf{L}-\\mathbf{M}\\|$. Express the bound in degrees, rounded to six decimal places.\n3. Compute coordinate-wise first-order sensitivities (in radians per meter) of the axis angle with respect to infinitesimal displacements along the $x$, $y$, and $z$ directions for each landmark. From these values, report the maximum and minimum sensitivity magnitudes across all six coordinates $\\{L_x,L_y,L_z,M_x,M_y,M_z\\}$, each rounded to six decimal places.\n4. Compute the actual angular deviation (in degrees) between $\\mathbf{u}$ and the perturbed axis $\\tilde{\\mathbf{u}}$ using the exact dot-product definition for the specific perturbations $\\delta\\mathbf{L}$ and $\\delta\\mathbf{M}$ provided. Round to six decimal places.\n\nAngle unit requirement: All angle outputs must be in degrees, rounded to six decimal places. Sensitivities must be in radians per meter, rounded to six decimal places. All lengths are in meters.\n\nTest suite:\nProvide the following three test cases to your program unchanged. Each case is a tuple $(\\mathbf{L},\\mathbf{M},\\varepsilon,\\delta\\mathbf{L},\\delta\\mathbf{M})$ with vectors in meters:\n- Case $1$ (axis nearly aligned to the global $x$-axis):\n  - $\\mathbf{L}=[\\,0.08,\\,0.0,\\,0.0\\,]$\n  - $\\mathbf{M}=[\\,0.0,\\,0.0,\\,0.0\\,]$\n  - $\\varepsilon=0.005$\n  - $\\delta\\mathbf{L}=[\\,0.002,\\,-0.001,\\,0.0005\\,]$\n  - $\\delta\\mathbf{M}=[\\,0.0005,\\,0.0015,\\,-0.0005\\,]$\n- Case $2$ (axis at approximately $45^\\circ$ in the $xy$-plane):\n  - $\\mathbf{L}=[\\,0.0565685424949238,\\,0.0565685424949238,\\,0.0\\,]$\n  - $\\mathbf{M}=[\\,0.0,\\,0.0,\\,0.0\\,]$\n  - $\\varepsilon=0.005$\n  - $\\delta\\mathbf{L}=[\\,0.003,\\,-0.002,\\,0.001\\,]$\n  - $\\delta\\mathbf{M}=[\\,-0.001,\\,0.002,\\,-0.002\\,]$\n- Case $3$ (shorter separation, oblique in $xz$ with offset):\n  - $\\mathbf{L}=[\\,0.050,\\,-0.010,\\,0.025\\,]$\n  - $\\mathbf{M}=[\\,0.020,\\,-0.010,\\,0.015\\,]$\n  - $\\varepsilon=0.005$\n  - $\\delta\\mathbf{L}=[\\,-0.0015,\\,0.001,\\,-0.001\\,]$\n  - $\\delta\\mathbf{M}=[\\,0.001,\\,-0.001,\\,0.0015\\,]$\n\nFinal output format:\nYour program should produce a single line of output containing the results for the three test cases as a comma-separated list enclosed in square brackets, where each test case contributes an inner list of four floating-point numbers in the following order: $[\\text{worst\\_case\\_deg},\\text{max\\_sensitivity\\_rad\\_per\\_m},\\text{min\\_sensitivity\\_rad\\_per\\_m},\\text{actual\\_deg}]$. For example, the overall format must be:\n$[[a_1,b_1,c_1,d_1],[a_2,b_2,c_2,d_2],[a_3,b_3,c_3,d_3]]$\nwith each value rounded to six decimal places.",
            "solution": "The problem is valid as it is scientifically grounded in vector calculus and biomechanical modeling, well-posed with all necessary data provided, and objective in its definitions. We shall proceed with a complete solution derived from first principles.\n\nLet the positions of the lateral and medial epicondyle landmarks be $\\mathbf{L} \\in \\mathbb{R}^3$ and $\\mathbf{M} \\in \\mathbb{R}^3$, respectively. The vector connecting these landmarks is defined as $\\mathbf{v} = \\mathbf{L} - \\mathbf{M}$. The scalar distance between them is the Euclidean norm of this vector, $d = \\|\\mathbf{v}\\| = \\|\\mathbf{L} - \\mathbf{M}\\|$. The baseline unit axis vector $\\mathbf{u}$ is then defined as the normalization of $\\mathbf{v}$:\n$$ \\mathbf{u} = \\frac{\\mathbf{v}}{d} = \\frac{\\mathbf{L} - \\mathbf{M}}{\\|\\mathbf{L} - \\mathbf{M}\\|} $$\n\nThe landmarks are subject to small additive perturbations, $\\delta\\mathbf{L}$ and $\\delta\\mathbf{M}$, resulting in perturbed positions $\\tilde{\\mathbf{L}} = \\mathbf{L} + \\delta\\mathbf{L}$ and $\\tilde{\\mathbf{M}} = \\mathbf{M} + \\delta\\mathbf{M}$. The perturbed vector $\\tilde{\\mathbf{v}}$ and its unit vector $\\tilde{\\mathbf{u}}$ are:\n$$ \\tilde{\\mathbf{v}} = \\tilde{\\mathbf{L}} - \\tilde{\\mathbf{M}} = (\\mathbf{L} - \\mathbf{M}) + (\\delta\\mathbf{L} - \\delta\\mathbf{M}) = \\mathbf{v} + \\delta\\mathbf{v} $$\n$$ \\tilde{\\mathbf{u}} = \\frac{\\tilde{\\mathbf{v}}}{\\|\\tilde{\\mathbf{v}}\\|} $$\nwhere we define the composite perturbation vector $\\delta\\mathbf{v} = \\delta\\mathbf{L} - \\delta\\mathbf{M}$. The angular deviation between the baseline axis $\\mathbf{u}$ and the perturbed axis $\\tilde{\\mathbf{u}}$ is given by $\\theta = \\arccos(\\mathbf{u}^\\top \\tilde{\\mathbf{u}})$.\n\n### Task 1: Baseline Unit Axis $\\mathbf{u}$\nThis is a direct computation using the formula $\\mathbf{u} = (\\mathbf{L} - \\mathbf{M}) / \\|\\mathbf{L} - \\mathbf{M}\\|$. This value serves as the basis for all subsequent calculations.\n\n### Task 2: Worst-Case Small-Angle Bound\nFor small angular deviations, the angle $\\theta$ in radians is well-approximated by the magnitude of the change in the unit vector, $\\theta \\approx \\|\\tilde{\\mathbf{u}} - \\mathbf{u}\\|$. We perform a first-order Taylor expansion of $\\mathbf{u}(\\mathbf{v}) = \\mathbf{v}/\\|\\mathbf{v}\\|$ around $\\mathbf{v}$ to find the first-order change $\\delta\\mathbf{u} = \\tilde{\\mathbf{u}} - \\mathbf{u}$.\n\nThe Jacobian of $\\mathbf{u}$ with respect to $\\mathbf{v}$ is:\n$$ \\frac{\\partial \\mathbf{u}}{\\partial \\mathbf{v}^\\top} = \\frac{\\partial}{\\partial \\mathbf{v}^\\top} \\left( \\frac{\\mathbf{v}}{\\|\\mathbf{v}\\|} \\right) = \\frac{1}{\\|\\mathbf{v}\\|} \\frac{\\partial \\mathbf{v}}{\\partial \\mathbf{v}^\\top} - \\frac{\\mathbf{v}}{\\|\\mathbf{v}\\|^2} \\frac{\\partial \\|\\mathbf{v}\\|}{\\partial \\mathbf{v}^\\top} = \\frac{1}{d} I - \\frac{\\mathbf{v}}{d^2} \\frac{\\mathbf{v}^\\top}{d} = \\frac{1}{d} (I - \\mathbf{u}\\mathbf{u}^\\top) $$\nwhere $I$ is the $3 \\times 3$ identity matrix. The first-order change $\\delta\\mathbf{u}$ is thus:\n$$ \\delta\\mathbf{u} \\approx \\frac{\\partial \\mathbf{u}}{\\partial \\mathbf{v}^\\top} \\delta\\mathbf{v} = \\frac{1}{d} (I - \\mathbf{u}\\mathbf{u}^\\top) \\delta\\mathbf{v} = \\frac{1}{d} (\\delta\\mathbf{v} - (\\mathbf{u}^\\top \\delta\\mathbf{v})\\mathbf{u}) $$\nThe vector $\\delta\\mathbf{u}$ represents the component of $\\delta\\mathbf{v}/d$ that is orthogonal to $\\mathbf{u}$. For small angles, the angular error $\\theta$ is approximately the magnitude of this vector:\n$$ \\theta \\approx \\|\\delta\\mathbf{u}\\| = \\frac{1}{d} \\| \\delta\\mathbf{v} - (\\mathbf{u}^\\top \\delta\\mathbf{v})\\mathbf{u} \\| = \\frac{\\|\\delta\\mathbf{v}_{\\perp}\\|}{d} $$\nwhere $\\delta\\mathbf{v}_{\\perp}$ is the component of $\\delta\\mathbf{v}$ orthogonal to $\\mathbf{u}$.\n\nTo find the worst-case bound, we must maximize $\\theta$ subject to the constraints $\\|\\delta\\mathbf{L}\\| \\le \\varepsilon$ and $\\|\\delta\\mathbf{M}\\| \\le \\varepsilon$. The magnitude of $\\delta\\mathbf{v}$ is bounded by the triangle inequality:\n$$ \\|\\delta\\mathbf{v}\\| = \\|\\delta\\mathbf{L} - \\delta\\mathbf{M}\\| \\le \\|\\delta\\mathbf{L}\\| + \\|\\delta\\mathbf{M}\\| \\le \\varepsilon + \\varepsilon = 2\\varepsilon $$\nThe magnitude of the orthogonal component, $\\|\\delta\\mathbf{v}_{\\perp}\\|$, is maximized when the vector $\\delta\\mathbf{v}$ itself is maximized in magnitude and oriented orthogonally to $\\mathbf{u}$. The maximum magnitude of $\\|\\delta\\mathbf{v}\\|$ is $2\\varepsilon$, achieved when $\\delta\\mathbf{L}$ and $\\delta\\mathbf{M}$ are antiparallel (e.g., $\\delta\\mathbf{L} = \\varepsilon\\mathbf{w}$ and $\\delta\\mathbf{M} = -\\varepsilon\\mathbf{w}$ for some unit vector $\\mathbf{w}$). If we choose $\\mathbf{w}$ to be orthogonal to $\\mathbf{u}$, then $\\delta\\mathbf{v} = 2\\varepsilon\\mathbf{w}$ is entirely orthogonal to $\\mathbf{u}$, thus maximizing $\\|\\delta\\mathbf{v}_{\\perp}\\|$ at $2\\varepsilon$.\nThe worst-case angle bound is therefore:\n$$ \\theta_{\\text{bound}} = \\frac{2\\varepsilon}{d} = \\frac{2\\varepsilon}{\\|\\mathbf{L} - \\mathbf{M}\\|} $$\nThis result, in radians, must be converted to degrees for reporting.\n\n### Task 3: Coordinate-Wise First-Order Sensitivities\nWe seek the sensitivity of the axis angle with respect to an infinitesimal displacement in each of the six coordinates $\\{L_x, L_y, L_z, M_x, M_y, M_z\\}$. The sensitivity with respect to a coordinate, say $L_x$, is the rate of change of angle $\\theta$ with respect to a change in $L_x$. For an infinitesimal displacement $\\delta L_x$ along the $x$-axis, $\\delta\\mathbf{L} = [\\delta L_x, 0, 0]^\\top = \\delta L_x \\mathbf{e}_x$ and $\\delta\\mathbf{M} = \\mathbf{0}$, giving $\\delta\\mathbf{v} = \\delta L_x \\mathbf{e}_x$.\n\nThe resulting infinitesimal angle change $\\delta\\theta$ is:\n$$ \\delta\\theta \\approx \\|\\delta\\mathbf{u}\\| = \\left\\| \\frac{1}{d} (I - \\mathbf{u}\\mathbf{u}^\\top)(\\delta L_x \\mathbf{e}_x) \\right\\| = \\frac{|\\delta L_x|}{d} \\|\\mathbf{e}_x - (\\mathbf{u}^\\top\\mathbf{e}_x)\\mathbf{u}\\| $$\nThe term inside the norm is the component of the basis vector $\\mathbf{e}_x$ orthogonal to $\\mathbf{u}$. Its magnitude is $\\sqrt{\\|\\mathbf{e}_x\\|^2 - (\\mathbf{u}^\\top\\mathbf{e}_x)^2} = \\sqrt{1 - u_x^2}$, since $\\mathbf{e}_x$ and $\\mathbf{u}$ are unit vectors. The sensitivity $S_{L_x}$ is the limit of the ratio $\\delta\\theta / |\\delta L_x|$ as $\\delta L_x \\to 0$:\n$$ S_{L_x} = \\frac{\\sqrt{1 - u_x^2}}{d} $$\nBy symmetry, the sensitivities for the $y$ and $z$ coordinates of $\\mathbf{L}$ are:\n$$ S_{L_y} = \\frac{\\sqrt{1 - u_y^2}}{d}, \\quad S_{L_z} = \\frac{\\sqrt{1 - u_z^2}}{d} $$\nFor a perturbation of a coordinate of $\\mathbf{M}$, say $M_x$, we have $\\delta\\mathbf{M} = [\\delta M_x, 0, 0]^\\top$ and $\\delta\\mathbf{L} = \\mathbf{0}$, so $\\delta\\mathbf{v} = -\\delta M_x \\mathbf{e}_x$. Since the magnitude calculation for $\\delta\\theta$ depends on $\\|\\delta\\mathbf{v}\\|$, the negative sign does not affect the result. Therefore, the sensitivities with respect to the coordinates of $\\mathbf{M}$ are identical to those for $\\mathbf{L}$:\n$$ S_{M_x} = S_{L_x}, \\quad S_{M_y} = S_{L_y}, \\quad S_{M_z} = S_{L_z} $$\nThe maximum and minimum sensitivity magnitudes must be found from the set $\\{S_{L_x}, S_{L_y}, S_{L_z}\\}$.\n\n### Task 4: Actual Angular Deviation\nThis task requires a direct computation without approximation. Given the specific perturbations $\\delta\\mathbf{L}$ and $\\delta\\mathbf{M}$:\n1.  Compute the perturbed landmark positions: $\\tilde{\\mathbf{L}} = \\mathbf{L} + \\delta\\mathbf{L}$ and $\\tilde{\\mathbf{M}} = \\mathbf{M} + \\delta\\mathbf{M}$.\n2.  Compute the perturbed axis vector: $\\tilde{\\mathbf{v}} = \\tilde{\\mathbf{L}} - \\tilde{\\mathbf{M}}$.\n3.  Normalize to find the perturbed unit axis: $\\tilde{\\mathbf{u}} = \\tilde{\\mathbf{v}} / \\|\\tilde{\\mathbf{v}}\\|$.\n4.  Compute the dot product between the baseline axis $\\mathbf{u}$ and the perturbed axis $\\tilde{\\mathbf{u}}$. To prevent numerical errors, this value should be clipped to the valid range $[-1, 1]$.\n5.  Calculate the angle in radians: $\\theta = \\arccos(\\mathbf{u}^\\top\\tilde{\\mathbf{u}})$.\n6.  Convert the final angle to degrees.\n\nThe implementation will follow these derived formulas for each test case.",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the biomechanical sensitivity analysis problem for three test cases.\n    \"\"\"\n    \n    # Test cases: tuple of (L, M, eps, dL, dM)\n    # Vectors are in meters.\n    test_cases = [\n        # Case 1\n        (\n            np.array([0.08, 0.0, 0.0]),\n            np.array([0.0, 0.0, 0.0]),\n            0.005,\n            np.array([0.002, -0.001, 0.0005]),\n            np.array([0.0005, 0.0015, -0.0005])\n        ),\n        # Case 2\n        (\n            np.array([0.0565685424949238, 0.0565685424949238, 0.0]),\n            np.array([0.0, 0.0, 0.0]),\n            0.005,\n            np.array([0.003, -0.002, 0.001]),\n            np.array([-0.001, 0.002, -0.002])\n        ),\n        # Case 3\n        (\n            np.array([0.050, -0.010, 0.025]),\n            np.array([0.020, -0.010, 0.015]),\n            0.005,\n            np.array([-0.0015, 0.001, -0.001]),\n            np.array([0.001, -0.001, 0.0015])\n        )\n    ]\n\n    all_results_str = []\n\n    for L, M, eps, dL, dM in test_cases:\n        # Task 1: Compute baseline unit axis u\n        v = L - M\n        d = np.linalg.norm(v)\n        \n        # Handle case where L=M, though not in test data.\n        if d == 0:\n            # Axis is undefined, can't proceed. In a real scenario, this would raise an error.\n            # For this problem, we assume d > 0 based on test cases.\n            u = np.array([0.0, 0.0, 0.0])\n        else:\n            u = v / d\n\n        # Task 2: Compute worst-case small-angle bound\n        # Formula: theta_bound = 2 * eps / d\n        if d > 0:\n            worst_case_rad = (2 * eps) / d\n        else:\n            worst_case_rad = np.inf\n        worst_case_deg = np.rad2deg(worst_case_rad)\n\n        # Task 3: Compute coordinate-wise first-order sensitivities\n        if d > 0:\n            # Sensitivities are sqrt(1-u_i^2)/d for i=x,y,z\n            sensitivities = [np.sqrt(1 - u_comp**2) / d for u_comp in u]\n            max_sensitivity_rad_per_m = max(sensitivities)\n            min_sensitivity_rad_per_m = min(sensitivities)\n        else:\n            max_sensitivity_rad_per_m = np.inf\n            min_sensitivity_rad_per_m = np.inf\n\n        # Task 4: Compute actual angular deviation\n        L_tilde = L + dL\n        M_tilde = M + dM\n        v_tilde = L_tilde - M_tilde\n        d_tilde = np.linalg.norm(v_tilde)\n\n        if d > 0 and d_tilde > 0:\n            u_tilde = v_tilde / d_tilde\n            # Dot product can be slightly outside [-1, 1] due to floating point error\n            dot_product = np.clip(np.dot(u, u_tilde), -1.0, 1.0)\n            actual_rad = np.arccos(dot_product)\n            actual_deg = np.rad2deg(actual_rad)\n        else:\n            actual_deg = 0.0 # Or undefined; 0 if no change.\n\n        # Store results for this case\n        case_results = [\n            worst_case_deg,\n            max_sensitivity_rad_per_m,\n            min_sensitivity_rad_per_m,\n            actual_deg\n        ]\n        \n        # Format the sublist as a string [val1,val2,val3,val4]\n        sub_list_str = f\"[{','.join([f'{x:.6f}' for x in case_results])}]\"\n        all_results_str.append(sub_list_str)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(all_results_str)}]\")\n\nsolve()\n\n```"
        }
    ]
}