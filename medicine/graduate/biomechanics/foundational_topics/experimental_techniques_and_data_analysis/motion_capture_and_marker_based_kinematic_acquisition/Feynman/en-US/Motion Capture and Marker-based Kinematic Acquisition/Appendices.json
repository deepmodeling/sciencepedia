{
    "hands_on_practices": [
        {
            "introduction": "The foundation of accurate marker-based kinematics is a precise camera model that can map 3D world points to 2D image coordinates and back. This exercise explores the consequences of a common simplification: ignoring lens distortion. By simulating a stereo camera setup , you will quantify how neglecting radial distortion introduces systematic biases in 3D reconstruction, providing a tangible understanding of why meticulous camera calibration is critical for scientific-grade motion analysis.",
            "id": "4192373",
            "problem": "Consider a marker-based kinematic acquisition scenario with two synchronized perspective cameras observing a single marker. Each camera obeys the pinhole model for the mapping from three-dimensional world coordinates to two-dimensional image coordinates, and both cameras share identical intrinsic parameters. The cameras are mounted such that their optical axes are approximately aligned with the world $z$-axis. Let the left camera have rotation matrix $R_1 = I$ and center $C_1 = (0,0,0)$, and the right camera have rotation matrix $R_2$ equal to a yaw rotation about the world $y$-axis by a small angle $\\phi$ (specified below, in radians) and center $C_2 = (B,0,0)$, where $B$ is the inter-camera baseline. Use the following intrinsic parameters: focal length $f = 1200$ pixels, principal point $(c_x, c_y) = (960, 540)$ pixels, and square pixels. The image resolution is $1920 \\times 1080$ pixels. Use a Brown-Conrady radial distortion model defined on normalized image coordinates.\n\nFundamental basis and definitions:\n- Pinhole projection maps a three-dimensional point $\\mathbf{X} = (X, Y, Z)$ in world coordinates to normalized camera coordinates via $x_n = X_{\\text{cam}}/Z_{\\text{cam}}$ and $y_n = Y_{\\text{cam}}/Z_{\\text{cam}}$, where $\\mathbf{X}_{\\text{cam}} = R(\\mathbf{X} - \\mathbf{C})$, with $R$ the camera rotation and $\\mathbf{C}$ the camera center. Pixel coordinates are then $u = f x_n + c_x$ and $v = f y_n + c_y$.\n- Brown-Conrady radial distortion modifies normalized coordinates as $(x_d, y_d) = (x_n, y_n)s(r)$ where $s(r) = 1 + k_1 r^2 + k_2 r^4$ and $r^2 = x_n^2 + y_n^2$. Distorted pixel coordinates are $u_d = f x_d + c_x$ and $v_d = f y_d + c_y$.\n- Motion capture systems triangulate the three-dimensional position by intersecting the two viewing rays. If $\\mathbf{d}_1$ and $\\mathbf{d}_2$ are the unit direction vectors (in world coordinates) of rays from camera centers $\\mathbf{C}_1$ and $\\mathbf{C}_2$ that go through the measured pixel coordinates, then the closest points on the lines $L_1(s_1) = \\mathbf{C}_1 + s_1 \\mathbf{d}_1$ and $L_2(s_2) = \\mathbf{C}_2 + s_2 \\mathbf{d}_2$ solve a least-squares intersection, yielding an estimated point $\\hat{X}$ as the midpoint of the closest approach.\n\nTask:\nWrite a program that quantifies how neglecting radial distortion in calibration biases the three-dimensional reconstruction. For each test case, do the following:\n1. Generate the two distorted image measurements $(u_{d,i}, v_{d,i})$ for cameras $i \\in \\{1,2\\}$ by forward projecting the ground-truth world point using the pinhole model on normalized coordinates followed by Brown-Conrady radial distortion with coefficients $(k_1, k_2)$, then converting to pixels with $(f, c_x, c_y)$.\n2. Reconstruct the three-dimensional point $\\hat{X}$ by triangulation assuming an ideal pinhole model with no distortion, i.e., treat $(u_{d,i}, v_{d,i})$ as if they were undistorted pinhole measurements. Construct unit rays in each camera’s local frame from normalized coordinates $(x_{u,i}, y_{u,i}) = \\left((u_{d,i} - c_x)/f, (v_{d,i} - c_y)/f\\right)$ and map them to world coordinates using $R_i^\\top$. Intersect the rays by computing the midpoint of the pair of closest points.\n3. Compute two error metrics:\n   - Reprojection error at the periphery: For each camera, reproject $\\hat{X}$ using the ideal pinhole model (no distortion), yielding $(u_{\\text{pin},i}, v_{\\text{pin},i})$. Measure the Euclidean reprojection residual $e_i = \\sqrt{(u_{d,i} - u_{\\text{pin},i})^2 + (v_{d,i} - v_{\\text{pin},i})^2}$ in pixels. Identify the camera with the larger radial distance from the principal point, $r_{\\text{px},i} = \\sqrt{(u_{d,i} - c_x)^2 + (v_{d,i} - c_y)^2}$, and report the corresponding reprojection error $e_{\\text{peri}}$ for that camera (in pixels).\n   - Depth bias: Compute the absolute error in depth, $\\Delta Z = | \\hat{Z} - Z_{\\text{true}} |$, in meters, where $\\hat{Z}$ is the $z$-coordinate of the reconstructed point and $Z_{\\text{true}}$ is the ground-truth depth.\n\nUse the following fixed parameters for all cases:\n- Baseline $B = 0.25$ meters.\n- Yaw angle $\\phi = 3\\pi/180$ radians.\n- Focal length $f = 1200$ pixels.\n- Principal point $(c_x, c_y) = (960, 540)$ pixels.\n\nTest suite:\nEach test case is a tuple $(X, Y, Z, k_1, k_2)$ with coordinates in meters and distortion coefficients dimensionless, where $Z$ is the ground-truth depth. The four cases are:\n- Case 1 (baseline, zero distortion, centered): $(0.0, 0.0, 3.0, 0.0, 0.0)$.\n- Case 2 (moderate distortion, centered): $(0.0, 0.0, 3.0, -0.2, 0.05)$.\n- Case 3 (moderate distortion, horizontal periphery): $(2.1, 0.0, 3.0, -0.2, 0.05)$.\n- Case 4 (strong distortion, combined horizontal and vertical periphery): $(2.1, 1.2, 3.0, -0.35, 0.10)$.\n\nAngle unit specification: All angles are in radians.\n\nOutput specification:\nFor each test case, return a two-element list $[e_{\\text{peri}}, \\Delta Z]$ where $e_{\\text{peri}}$ is in pixels and $\\Delta Z$ is in meters. Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, in the order of the test suite, with each per-case result itself enclosed in square brackets. For example, the output should look like $[[e_1,\\Delta Z_1],[e_2,\\Delta Z_2],[e_3,\\Delta Z_3],[e_4,\\Delta Z_4]]$.",
            "solution": "The solution begins from the pinhole camera model, which provides the mapping from world coordinates to normalized image coordinates, and then to pixel coordinates via multiplication by the focal length and addition of the principal point. Let a three-dimensional point in world coordinates be denoted by $\\mathbf{X} = (X, Y, Z)^\\top$. For camera $i$ with rotation $R_i$ and center $\\mathbf{C}_i$, the camera-frame coordinates are given by\n$$\n\\mathbf{X}_{\\text{cam}, i} = R_i \\left( \\mathbf{X} - \\mathbf{C}_i \\right).\n$$\nDefining $\\mathbf{X}_{\\text{cam}, i} = (X_i, Y_i, Z_i)$, the normalized undistorted pinhole coordinates are\n$$\nx_{n,i} = \\frac{X_i}{Z_i}, \\quad y_{n,i} = \\frac{Y_i}{Z_i}.\n$$\nThe Brown-Conrady radial distortion on normalized coordinates is given by\n$$\nr_i^2 = x_{n,i}^2 + y_{n,i}^2, \\quad s(r_i) = 1 + k_1 r_i^2 + k_2 r_i^4,\n$$\nand the distorted normalized coordinates are\n$$\nx_{d,i} = x_{n,i} \\, s(r_i), \\quad y_{d,i} = y_{n,i} \\, s(r_i).\n$$\nConverting to pixel coordinates with focal length $f$ and principal point $(c_x, c_y)$ yields\n$$\nu_{d,i} = f \\, x_{d,i} + c_x, \\quad v_{d,i} = f \\, y_{d,i} + c_y.\n$$\nThese $(u_{d,i}, v_{d,i})$ are the synthetic measurements produced by the forward model when distortion is present.\n\nThe reconstruction is performed under the false assumption of no distortion. Thus, we form undistorted normalized coordinates by inverting only the pinhole mapping:\n$$\nx_{u,i} = \\frac{u_{d,i} - c_x}{f}, \\quad y_{u,i} = \\frac{v_{d,i} - c_y}{f}.\n$$\nIn camera coordinates, the ray direction toward the point is proportional to\n$$\n\\tilde{\\mathbf{d}}_{\\text{cam}, i} = \\begin{bmatrix} x_{u,i} \\\\ y_{u,i} \\\\ 1 \\end{bmatrix},\n$$\nwhich we normalize to unit length,\n$$\n\\mathbf{d}_{\\text{cam}, i} = \\frac{\\tilde{\\mathbf{d}}_{\\text{cam}, i}}{\\|\\tilde{\\mathbf{d}}_{\\text{cam}, i}\\|_2}.\n$$\nTo express the rays in world coordinates, we apply the inverse rotation:\n$$\n\\mathbf{d}_i = R_i^\\top \\, \\mathbf{d}_{\\text{cam}, i}.\n$$\nThe rays in world coordinates are thus\n$$\nL_1(s_1) = \\mathbf{C}_1 + s_1 \\mathbf{d}_1, \\quad L_2(s_2) = \\mathbf{C}_2 + s_2 \\mathbf{d}_2.\n$$\nThe closest points on these skew lines solve the standard least-squares line-line intersection problem. Define\n$$\n\\mathbf{w}_0 = \\mathbf{C}_1 - \\mathbf{C}_2, \\quad a = \\mathbf{d}_1^\\top \\mathbf{d}_1, \\quad b = \\mathbf{d}_1^\\top \\mathbf{d}_2, \\quad c = \\mathbf{d}_2^\\top \\mathbf{d}_2, \\quad d = \\mathbf{d}_1^\\top \\mathbf{w}_0, \\quad e = \\mathbf{d}_2^\\top \\mathbf{w}_0.\n$$\nAssuming the lines are not exactly parallel (so that $a c - b^2 \\neq 0$), the optimal parameters are\n$$\ns_1^\\star = \\frac{b e - c d}{a c - b^2}, \\quad s_2^\\star = \\frac{a e - b d}{a c - b^2}.\n$$\nThe reconstructed three-dimensional position is taken as the midpoint of the two closest points:\n$$\n\\hat{\\mathbf{X}} = \\frac{1}{2}\\left( \\left(\\mathbf{C}_1 + s_1^\\star \\mathbf{d}_1\\right) + \\left(\\mathbf{C}_2 + s_2^\\star \\mathbf{d}_2\\right) \\right),\n$$\nwith depth $\\hat{Z}$ equal to the $z$-component of $\\hat{\\mathbf{X}}$.\n\nTo quantify the modeling bias, we compute two metrics.\n\nFirst, the periphery reprojection error. We reproject $\\hat{\\mathbf{X}}$ into each camera using the ideal pinhole mapping (no distortion):\n$$\n\\hat{\\mathbf{X}}_{\\text{cam}, i} = R_i \\left( \\hat{\\mathbf{X}} - \\mathbf{C}_i \\right), \\quad \\hat{x}_{n,i} = \\frac{\\hat{X}_{\\text{cam}, i,x}}{\\hat{X}_{\\text{cam}, i,z}}, \\quad \\hat{y}_{n,i} = \\frac{\\hat{X}_{\\text{cam}, i,y}}{\\hat{X}_{\\text{cam}, i,z}},\n$$\nand then\n$$\nu_{\\text{pin}, i} = f \\, \\hat{x}_{n,i} + c_x, \\quad v_{\\text{pin}, i} = f \\, \\hat{y}_{n,i} + c_y.\n$$\nThe residual in pixels for camera $i$ is\n$$\ne_i = \\sqrt{(u_{d,i} - u_{\\text{pin}, i})^2 + (v_{d,i} - v_{\\text{pin}, i})^2}.\n$$\nWe identify the more peripheral view by the larger radial pixel distance\n$$\nr_{\\text{px}, i} = \\sqrt{(u_{d,i} - c_x)^2 + (v_{d,i} - c_y)^2},\n$$\nand report $e_{\\text{peri}}$, the reprojection error corresponding to the camera with the larger radial pixel distance.\n\nSecond, the depth bias is the absolute difference between the reconstructed depth and the ground-truth depth:\n$$\n\\Delta Z = \\left| \\hat{Z} - Z_{\\text{true}} \\right|.\n$$\n\nScientific rationale: Ignoring distortion treats curved rays as if they were straight through the ideal pinhole model, which perturbs the direction vectors used in triangulation. The perturbation grows with the radial distance $r$ since the distortion scale $s(r)$ departs more from unity as $r$ increases. This yields a systematic bias in the intersection of rays, causing depth errors that depend on baseline $B$, viewing geometry via $R_i$, and the nonlinearity of the distortion function. The reprojection residual under an ideal pinhole model is a direct measure of the mismatch between the model and the distorted measurements and is expected to be negligible at the center ($r \\approx 0$) and large at the periphery (large $r$).\n\nAlgorithmic steps implemented in the program:\n1. For each test case $(X, Y, Z, k_1, k_2)$, compute distorted pixel measurements for both cameras using the pinhole projection on normalized coordinates followed by Brown-Conrady radial distortion, then convert to pixels.\n2. Form undistorted normalized coordinates from the distorted pixels as if no distortion were present. Construct unit ray directions in camera frames and rotate them into world coordinates.\n3. Solve for the closest points on the pair of rays using the least-squares intersection formulas to obtain $\\hat{\\mathbf{X}}$ and its depth $\\hat{Z}$.\n4. Compute the per-camera reprojection residuals under the ideal pinhole model and select the residual for the camera with the larger radial pixel distance from the principal point as $e_{\\text{peri}}$.\n5. Compute the depth bias $\\Delta Z$ as the absolute difference between $\\hat{Z}$ and $Z$.\n6. Output, for each test case, the pair $[e_{\\text{peri}}, \\Delta Z]$ in the specified format.\n\nAll angles are handled in radians; we set the yaw angle to $\\phi = 3\\pi/180$. The baseline $B$ is $0.25$ meters. Distortion coefficients are dimensionless and applied to normalized coordinates, ensuring scientific realism across periphery and center cases. The test suite includes a zero-distortion boundary case, centered moderate distortion, horizontal periphery under moderate distortion, and combined horizontal and vertical periphery under strong distortion, offering coverage across key facets of the reconstruction bias due to neglecting distortion.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef rotation_y(phi):\n    \"\"\"Rotation matrix about the world y-axis by angle phi (radians).\"\"\"\n    c = np.cos(phi)\n    s = np.sin(phi)\n    return np.array([[ c, 0.0,  s],\n                     [0.0, 1.0, 0.0],\n                     [-s, 0.0,  c]], dtype=float)\n\ndef project_with_radial_distortion(X_world, R, C, f, cx, cy, k1, k2):\n    \"\"\"\n    Project X_world into pixel coordinates using pinhole model on normalized\n    coordinates followed by Brown-Conrady radial distortion (k1, k2).\n    \"\"\"\n    X_cam = R @ (X_world - C)\n    Xc, Yc, Zc = X_cam\n    x_n = Xc / Zc\n    y_n = Yc / Zc\n    r2 = x_n * x_n + y_n * y_n\n    s = 1.0 + k1 * r2 + k2 * (r2 * r2)\n    x_d = x_n * s\n    y_d = y_n * s\n    u = f * x_d + cx\n    v = f * y_d + cy\n    return np.array([u, v], dtype=float)\n\ndef ray_from_pixel_no_distortion(u, v, f, cx, cy, R, C):\n    \"\"\"\n    Construct unit ray direction in world coordinates assuming an ideal pinhole (no distortion).\n    \"\"\"\n    x_u = (u - cx) / f\n    y_u = (v - cy) / f\n    d_cam = np.array([x_u, y_u, 1.0], dtype=float)\n    d_cam /= np.linalg.norm(d_cam)\n    # Map direction from camera to world by inverse rotation\n    d_world = R.T @ d_cam\n    # Ray originates at camera center C\n    return d_world\n\ndef triangulate_midpoint(C1, d1, C2, d2):\n    \"\"\"\n    Triangulate via closest-point midpoint of two skew rays:\n    L1(s1) = C1 + s1 d1, L2(s2) = C2 + s2 d2.\n    \"\"\"\n    w0 = C1 - C2\n    a = np.dot(d1, d1)\n    b = np.dot(d1, d2)\n    c = np.dot(d2, d2)\n    d = np.dot(d1, w0)\n    e = np.dot(d2, w0)\n    denom = a * c - b * b\n    if np.abs(denom) < 1e-12:\n        # Rays are nearly parallel; fall back to average of projecting from one ray\n        s1 = -d / a if np.abs(a) > 1e-12 else 0.0\n        p1 = C1 + s1 * d1\n        # Project p1 onto second ray\n        # s2 = argmin ||(C2 + s2 d2) - p1||^2 => s2 = d2·(p1 - C2)\n        s2 = np.dot(d2, (p1 - C2))\n        p2 = C2 + s2 * d2\n        return 0.5 * (p1 + p2)\n    s1 = (b * e - c * d) / denom\n    s2 = (a * e - b * d) / denom\n    p1 = C1 + s1 * d1\n    p2 = C2 + s2 * d2\n    return 0.5 * (p1 + p2)\n\ndef pinhole_reproject(X_world, R, C, f, cx, cy):\n    \"\"\"Reproject a 3D point using an ideal pinhole model (no distortion).\"\"\"\n    X_cam = R @ (X_world - C)\n    Xc, Yc, Zc = X_cam\n    x_n = Xc / Zc\n    y_n = Yc / Zc\n    u = f * x_n + cx\n    v = f * y_n + cy\n    return np.array([u, v], dtype=float)\n\ndef solve():\n    # Intrinsics\n    f = 1200.0\n    cx, cy = 960.0, 540.0\n    # Extrinsics\n    B = 0.25  # meters\n    phi = 3.0 * np.pi / 180.0  # radians\n    R1 = np.eye(3)\n    C1 = np.array([0.0, 0.0, 0.0], dtype=float)\n    R2 = rotation_y(phi)\n    C2 = np.array([B, 0.0, 0.0], dtype=float)\n\n    # Define the test cases from the problem statement.\n    # Each case: (X, Y, Z, k1, k2)\n    test_cases = [\n        (0.0, 0.0, 3.0, 0.0, 0.0),           # Case 1: baseline, zero distortion, centered\n        (0.0, 0.0, 3.0, -0.2, 0.05),         # Case 2: moderate distortion, centered\n        (2.1, 0.0, 3.0, -0.2, 0.05),         # Case 3: moderate distortion, horizontal periphery\n        (2.1, 1.2, 3.0, -0.35, 0.10),        # Case 4: strong distortion, combined periphery\n    ]\n\n    results = []\n    for X, Y, Z, k1, k2 in test_cases:\n        X_world_true = np.array([X, Y, Z], dtype=float)\n\n        # Forward projection with distortion for both cameras\n        uvd1 = project_with_radial_distortion(X_world_true, R1, C1, f, cx, cy, k1, k2)\n        uvd2 = project_with_radial_distortion(X_world_true, R2, C2, f, cx, cy, k1, k2)\n\n        # Construct rays assuming no distortion\n        d1 = ray_from_pixel_no_distortion(uvd1[0], uvd1[1], f, cx, cy, R1, C1)\n        d2 = ray_from_pixel_no_distortion(uvd2[0], uvd2[1], f, cx, cy, R2, C2)\n\n        # Triangulate midpoint\n        X_hat = triangulate_midpoint(C1, d1, C2, d2)\n        Z_hat = X_hat[2]\n\n        # Reproject using ideal pinhole\n        upin1 = pinhole_reproject(X_hat, R1, C1, f, cx, cy)\n        upin2 = pinhole_reproject(X_hat, R2, C2, f, cx, cy)\n\n        # Reprojection residuals per camera (compare to distorted observations)\n        e1 = np.linalg.norm(uvd1 - upin1)\n        e2 = np.linalg.norm(uvd2 - upin2)\n\n        # Peripheral camera selection by larger radial pixel distance from principal point\n        rpx1 = np.linalg.norm(uvd1 - np.array([cx, cy], dtype=float))\n        rpx2 = np.linalg.norm(uvd2 - np.array([cx, cy], dtype=float))\n        e_peri = e1 if rpx1 >= rpx2 else e2\n\n        # Depth bias\n        dZ = abs(Z_hat - Z)\n\n        # Append result as [reproj_error_px, depth_error_m]\n        results.append([float(e_peri), float(dZ)])\n\n    # Final print statement in the exact required format.\n    # Single line output: list of per-case [e_peri, dZ]\n    print(f\"[{','.join('[' + ','.join(map(str, pair)) + ']' for pair in results)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "Once we have accurate 3D marker coordinates, the next step is to derive meaningful biomechanical variables, such as joint axes. However, the placement of markers on anatomical landmarks is subject to error from sources like soft tissue artifact and palpation inconsistency. This hands-on problem  guides you through a sensitivity analysis to quantify how small landmark perturbations propagate into significant errors in the calculated joint axis orientation, highlighting the crucial link between experimental procedure and the reliability of kinematic outcomes.",
            "id": "4192315",
            "problem": "You will implement a complete, runnable program that quantifies how misplacement of anatomical landmarks alters a joint axis defined from marker-based kinematics. The context is the knee flexion-extension axis defined by medial and lateral epicondyle landmarks in three-dimensional motion capture. Start from fundamental definitions of vectors in three-dimensional Euclidean space and the definition of an angle between unit vectors via the dot product. Use first principles to derive a sensitivity analysis that maps small landmark perturbations to small angular deviations of the unit axis vector.\n\nDefinitions and assumptions:\n- The joint axis is defined by two anatomical landmarks: a lateral epicondyle position $\\mathbf{L}\\in\\mathbb{R}^3$ and a medial epicondyle position $\\mathbf{M}\\in\\mathbb{R}^3$, both expressed in meters in a global Cartesian coordinate system.\n- The baseline axis direction is $\\mathbf{u}=\\dfrac{\\mathbf{L}-\\mathbf{M}}{\\|\\mathbf{L}-\\mathbf{M}\\|}$, where $\\|\\cdot\\|$ is the Euclidean norm.\n- A misplacement of the landmarks is modeled as small additive perturbations $\\delta\\mathbf{L}$ and $\\delta\\mathbf{M}$ (in meters), producing a perturbed axis direction $\\tilde{\\mathbf{u}}$ computed from $\\mathbf{L}+\\delta\\mathbf{L}$ and $\\mathbf{M}+\\delta\\mathbf{M}$ by the same definition.\n- The angular deviation $\\theta$ between the baseline and perturbed axes is defined by $\\theta=\\arccos\\!\\left(\\mathbf{u}^\\top \\tilde{\\mathbf{u}}\\right)$ in radians. For reporting, you must express angular quantities in degrees to six decimal places.\n- Perform a first-order sensitivity analysis of the unit axis direction with respect to each coordinate of $\\mathbf{L}$ and $\\mathbf{M}$. Treat the three standard coordinate directions as the orthonormal basis vectors in $\\mathbb{R}^3$.\n\nYour tasks for each test case:\n1. Compute the baseline unit axis $\\mathbf{u}$ from the provided $\\mathbf{L}$ and $\\mathbf{M}$.\n2. Compute a worst-case small-angle bound (in degrees) for isotropic landmark misplacement when each landmark perturbation satisfies $\\|\\delta\\mathbf{L}\\|\\le \\varepsilon$ and $\\|\\delta\\mathbf{M}\\|\\le \\varepsilon$ (with $\\varepsilon$ given in meters). Use first principles and linearization to obtain a bound that depends on $\\varepsilon$ and the baseline separation $\\|\\mathbf{L}-\\mathbf{M}\\|$. Express the bound in degrees, rounded to six decimal places.\n3. Compute coordinate-wise first-order sensitivities (in radians per meter) of the axis angle with respect to infinitesimal displacements along the $x$, $y$, and $z$ directions for each landmark. From these values, report the maximum and minimum sensitivity magnitudes across all six coordinates $\\{L_x,L_y,L_z,M_x,M_y,M_z\\}$, each rounded to six decimal places.\n4. Compute the actual angular deviation (in degrees) between $\\mathbf{u}$ and the perturbed axis $\\tilde{\\mathbf{u}}$ using the exact dot-product definition for the specific perturbations $\\delta\\mathbf{L}$ and $\\delta\\mathbf{M}$ provided. Round to six decimal places.\n\nAngle unit requirement: All angle outputs must be in degrees, rounded to six decimal places. Sensitivities must be in radians per meter, rounded to six decimal places. All lengths are in meters.\n\nTest suite:\nProvide the following three test cases to your program unchanged. Each case is a tuple $(\\mathbf{L},\\mathbf{M},\\varepsilon,\\delta\\mathbf{L},\\delta\\mathbf{M})$ with vectors in meters:\n- Case $1$ (axis nearly aligned to the global $x$-axis):\n  - $\\mathbf{L}=[\\,0.08,\\,0.0,\\,0.0\\,]$\n  - $\\mathbf{M}=[\\,0.0,\\,0.0,\\,0.0\\,]$\n  - $\\varepsilon=0.005$\n  - $\\delta\\mathbf{L}=[\\,0.002,\\,-0.001,\\,0.0005\\,]$\n  - $\\delta\\mathbf{M}=[\\,0.0005,\\,0.0015,\\,-0.0005\\,]$\n- Case $2$ (axis at approximately $45^\\circ$ in the $xy$-plane):\n  - $\\mathbf{L}=[\\,0.0565685424949238,\\,0.0565685424949238,\\,0.0\\,]$\n  - $\\mathbf{M}=[\\,0.0,\\,0.0,\\,0.0\\,]$\n  - $\\varepsilon=0.005$\n  - $\\delta\\mathbf{L}=[\\,0.003,\\,-0.002,\\,0.001\\,]$\n  - $\\delta\\mathbf{M}=[\\,-0.001,\\,0.002,\\,-0.002\\,]$\n- Case $3$ (shorter separation, oblique in $xz$ with offset):\n  - $\\mathbf{L}=[\\,0.050,\\,-0.010,\\,0.025\\,]$\n  - $\\mathbf{M}=[\\,0.020,\\,-0.010,\\,0.015\\,]$\n  - $\\varepsilon=0.005$\n  - $\\delta\\mathbf{L}=[\\,-0.0015,\\,0.001,\\,-0.001\\,]$\n  - $\\delta\\mathbf{M}=[\\,0.001,\\,-0.001,\\,0.0015\\,]$\n\nFinal output format:\nYour program should produce a single line of output containing the results for the three test cases as a comma-separated list enclosed in square brackets, where each test case contributes an inner list of four floating-point numbers in the following order: $[\\text{worst\\_case\\_deg},\\text{max\\_sensitivity\\_rad\\_per\\_m},\\text{min\\_sensitivity\\_rad\\_per\\_m},\\text{actual\\_deg}]$. For example, the overall format must be:\n$[[a_1,b_1,c_1,d_1],[a_2,b_2,c_2,d_2],[a_3,b_3,c_3,d_3]]$\nwith each value rounded to six decimal places.",
            "solution": "The problem is valid as it is scientifically grounded in vector calculus and biomechanical modeling, well-posed with all necessary data provided, and objective in its definitions. We shall proceed with a complete solution derived from first principles.\n\nLet the positions of the lateral and medial epicondyle landmarks be $\\mathbf{L} \\in \\mathbb{R}^3$ and $\\mathbf{M} \\in \\mathbb{R}^3$, respectively. The vector connecting these landmarks is defined as $\\mathbf{v} = \\mathbf{L} - \\mathbf{M}$. The scalar distance between them is the Euclidean norm of this vector, $d = \\|\\mathbf{v}\\| = \\|\\mathbf{L} - \\mathbf{M}\\|$. The baseline unit axis vector $\\mathbf{u}$ is then defined as the normalization of $\\mathbf{v}$:\n$$ \\mathbf{u} = \\frac{\\mathbf{v}}{d} = \\frac{\\mathbf{L} - \\mathbf{M}}{\\|\\mathbf{L} - \\mathbf{M}\\|} $$\n\nThe landmarks are subject to small additive perturbations, $\\delta\\mathbf{L}$ and $\\delta\\mathbf{M}$, resulting in perturbed positions $\\tilde{\\mathbf{L}} = \\mathbf{L} + \\delta\\mathbf{L}$ and $\\tilde{\\mathbf{M}} = \\mathbf{M} + \\delta\\mathbf{M}$. The perturbed vector $\\tilde{\\mathbf{v}}$ and its unit vector $\\tilde{\\mathbf{u}}$ are:\n$$ \\tilde{\\mathbf{v}} = \\tilde{\\mathbf{L}} - \\tilde{\\mathbf{M}} = (\\mathbf{L} - \\mathbf{M}) + (\\delta\\mathbf{L} - \\delta\\mathbf{M}) = \\mathbf{v} + \\delta\\mathbf{v} $$\n$$ \\tilde{\\mathbf{u}} = \\frac{\\tilde{\\mathbf{v}}}{\\|\\tilde{\\mathbf{v}}\\|} $$\nwhere we define the composite perturbation vector $\\delta\\mathbf{v} = \\delta\\mathbf{L} - \\delta\\mathbf{M}$. The angular deviation between the baseline axis $\\mathbf{u}$ and the perturbed axis $\\tilde{\\mathbf{u}}$ is given by $\\theta = \\arccos(\\mathbf{u}^\\top \\tilde{\\mathbf{u}})$.\n\n### Task 1: Baseline Unit Axis $\\mathbf{u}$\nThis is a direct computation using the formula $\\mathbf{u} = (\\mathbf{L} - \\mathbf{M}) / \\|\\mathbf{L} - \\mathbf{M}\\|$. This value serves as the basis for all subsequent calculations.\n\n### Task 2: Worst-Case Small-Angle Bound\nFor small angular deviations, the angle $\\theta$ in radians is well-approximated by the magnitude of the change in the unit vector, $\\theta \\approx \\|\\tilde{\\mathbf{u}} - \\mathbf{u}\\|$. We perform a first-order Taylor expansion of $\\mathbf{u}(\\mathbf{v}) = \\mathbf{v}/\\|\\mathbf{v}\\|$ around $\\mathbf{v}$ to find the first-order change $\\delta\\mathbf{u} = \\tilde{\\mathbf{u}} - \\mathbf{u}$.\n\nThe Jacobian of $\\mathbf{u}$ with respect to $\\mathbf{v}$ is:\n$$ \\frac{\\partial \\mathbf{u}}{\\partial \\mathbf{v}^\\top} = \\frac{\\partial}{\\partial \\mathbf{v}^\\top} \\left( \\frac{\\mathbf{v}}{\\|\\mathbf{v}\\|} \\right) = \\frac{1}{\\|\\mathbf{v}\\|} \\frac{\\partial \\mathbf{v}}{\\partial \\mathbf{v}^\\top} - \\frac{\\mathbf{v}}{\\|\\mathbf{v}\\|^2} \\frac{\\partial \\|\\mathbf{v}\\|}{\\partial \\mathbf{v}^\\top} = \\frac{1}{d} I - \\frac{\\mathbf{v}}{d^2} \\frac{\\mathbf{v}^\\top}{d} = \\frac{1}{d} (I - \\mathbf{u}\\mathbf{u}^\\top) $$\nwhere $I$ is the $3 \\times 3$ identity matrix. The first-order change $\\delta\\mathbf{u}$ is thus:\n$$ \\delta\\mathbf{u} \\approx \\frac{\\partial \\mathbf{u}}{\\partial \\mathbf{v}^\\top} \\delta\\mathbf{v} = \\frac{1}{d} (I - \\mathbf{u}\\mathbf{u}^\\top) \\delta\\mathbf{v} = \\frac{1}{d} (\\delta\\mathbf{v} - (\\mathbf{u}^\\top \\delta\\mathbf{v})\\mathbf{u}) $$\nThe vector $\\delta\\mathbf{u}$ represents the component of $\\delta\\mathbf{v}/d$ that is orthogonal to $\\mathbf{u}$. For small angles, the angular error $\\theta$ is approximately the magnitude of this vector:\n$$ \\theta \\approx \\|\\delta\\mathbf{u}\\| = \\frac{1}{d} \\| \\delta\\mathbf{v} - (\\mathbf{u}^\\top \\delta\\mathbf{v})\\mathbf{u} \\| = \\frac{\\|\\delta\\mathbf{v}_{\\perp}\\|}{d} $$\nwhere $\\delta\\mathbf{v}_{\\perp}$ is the component of $\\delta\\mathbf{v}$ orthogonal to $\\mathbf{u}$.\n\nTo find the worst-case bound, we must maximize $\\theta$ subject to the constraints $\\|\\delta\\mathbf{L}\\| \\le \\varepsilon$ and $\\|\\delta\\mathbf{M}\\| \\le \\varepsilon$. The magnitude of $\\delta\\mathbf{v}$ is bounded by the triangle inequality:\n$$ \\|\\delta\\mathbf{v}\\| = \\|\\delta\\mathbf{L} - \\delta\\mathbf{M}\\| \\le \\|\\delta\\mathbf{L}\\| + \\|\\delta\\mathbf{M}\\| \\le \\varepsilon + \\varepsilon = 2\\varepsilon $$\nThe magnitude of the orthogonal component, $\\|\\delta\\mathbf{v}_{\\perp}\\|$, is maximized when the vector $\\delta\\mathbf{v}$ itself is maximized in magnitude and oriented orthogonally to $\\mathbf{u}$. The maximum magnitude of $\\|\\delta\\mathbf{v}\\|$ is $2\\varepsilon$, achieved when $\\delta\\mathbf{L}$ and $\\delta\\mathbf{M}$ are antiparallel (e.g., $\\delta\\mathbf{L} = \\varepsilon\\mathbf{w}$ and $\\delta\\mathbf{M} = -\\varepsilon\\mathbf{w}$ for some unit vector $\\mathbf{w}$). If we choose $\\mathbf{w}$ to be orthogonal to $\\mathbf{u}$, then $\\delta\\mathbf{v} = 2\\varepsilon\\mathbf{w}$ is entirely orthogonal to $\\mathbf{u}$, thus maximizing $\\|\\delta\\mathbf{v}_{\\perp}\\|$ at $2\\varepsilon$.\nThe worst-case angle bound is therefore:\n$$ \\theta_{\\text{bound}} = \\frac{2\\varepsilon}{d} = \\frac{2\\varepsilon}{\\|\\mathbf{L} - \\mathbf{M}\\|} $$\nThis result, in radians, must be converted to degrees for reporting.\n\n### Task 3: Coordinate-Wise First-Order Sensitivities\nWe seek the sensitivity of the axis angle with respect to an infinitesimal displacement in each of the six coordinates $\\{L_x, L_y, L_z, M_x, M_y, M_z\\}$. The sensitivity with respect to a coordinate, say $L_x$, is the rate of change of angle $\\theta$ with respect to a change in $L_x$. For an infinitesimal displacement $\\delta L_x$ along the $x$-axis, $\\delta\\mathbf{L} = [\\delta L_x, 0, 0]^\\top = \\delta L_x \\mathbf{e}_x$ and $\\delta\\mathbf{M} = \\mathbf{0}$, giving $\\delta\\mathbf{v} = \\delta L_x \\mathbf{e}_x$.\n\nThe resulting infinitesimal angle change $\\delta\\theta$ is:\n$$ \\delta\\theta \\approx \\|\\delta\\mathbf{u}\\| = \\left\\| \\frac{1}{d} (I - \\mathbf{u}\\mathbf{u}^\\top)(\\delta L_x \\mathbf{e}_x) \\right\\| = \\frac{|\\delta L_x|}{d} \\|\\mathbf{e}_x - (\\mathbf{u}^\\top\\mathbf{e}_x)\\mathbf{u}\\| $$\nThe term inside the norm is the component of the basis vector $\\mathbf{e}_x$ orthogonal to $\\mathbf{u}$. Its magnitude is $\\sqrt{\\|\\mathbf{e}_x\\|^2 - (\\mathbf{u}^\\top\\mathbf{e}_x)^2} = \\sqrt{1 - u_x^2}$, since $\\mathbf{e}_x$ and $\\mathbf{u}$ are unit vectors. The sensitivity $S_{L_x}$ is the limit of the ratio $\\delta\\theta / |\\delta L_x|$ as $\\delta L_x \\to 0$:\n$$ S_{L_x} = \\frac{\\sqrt{1 - u_x^2}}{d} $$\nBy symmetry, the sensitivities for the $y$ and $z$ coordinates of $\\mathbf{L}$ are:\n$$ S_{L_y} = \\frac{\\sqrt{1 - u_y^2}}{d}, \\quad S_{L_z} = \\frac{\\sqrt{1 - u_z^2}}{d} $$\nFor a perturbation of a coordinate of $\\mathbf{M}$, say $M_x$, we have $\\delta\\mathbf{M} = [\\delta M_x, 0, 0]^\\top$ and $\\delta\\mathbf{L} = \\mathbf{0}$, so $\\delta\\mathbf{v} = -\\delta M_x \\mathbf{e}_x$. Since the magnitude calculation for $\\delta\\theta$ depends on $\\|\\delta\\mathbf{v}\\|$, the negative sign does not affect the result. Therefore, the sensitivities with respect to the coordinates of $\\mathbf{M}$ are identical to those for $\\mathbf{L}$:\n$$ S_{M_x} = S_{L_x}, \\quad S_{M_y} = S_{L_y}, \\quad S_{M_z} = S_{L_z} $$\nThe maximum and minimum sensitivity magnitudes must be found from the set $\\{S_{L_x}, S_{L_y}, S_{L_z}\\}$.\n\n### Task 4: Actual Angular Deviation\nThis task requires a direct computation without approximation. Given the specific perturbations $\\delta\\mathbf{L}$ and $\\delta\\mathbf{M}$:\n1.  Compute the perturbed landmark positions: $\\tilde{\\mathbf{L}} = \\mathbf{L} + \\delta\\mathbf{L}$ and $\\tilde{\\mathbf{M}} = \\mathbf{M} + \\delta\\mathbf{M}$.\n2.  Compute the perturbed axis vector: $\\tilde{\\mathbf{v}} = \\tilde{\\mathbf{L}} - \\tilde{\\mathbf{M}}$.\n3.  Normalize to find the perturbed unit axis: $\\tilde{\\mathbf{u}} = \\tilde{\\mathbf{v}} / \\|\\tilde{\\mathbf{v}}\\|$.\n4.  Compute the dot product between the baseline axis $\\mathbf{u}$ and the perturbed axis $\\tilde{\\mathbf{u}}$. To prevent numerical errors, this value should be clipped to the valid range $[-1, 1]$.\n5.  Calculate the angle in radians: $\\theta = \\arccos(\\mathbf{u}^\\top\\tilde{\\mathbf{u}})$.\n6.  Convert the final angle to degrees.\n\nThe implementation will follow these derived formulas for each test case.",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the biomechanical sensitivity analysis problem for three test cases.\n    \"\"\"\n    \n    # Test cases: tuple of (L, M, eps, dL, dM)\n    # Vectors are in meters.\n    test_cases = [\n        # Case 1\n        (\n            np.array([0.08, 0.0, 0.0]),\n            np.array([0.0, 0.0, 0.0]),\n            0.005,\n            np.array([0.002, -0.001, 0.0005]),\n            np.array([0.0005, 0.0015, -0.0005])\n        ),\n        # Case 2\n        (\n            np.array([0.0565685424949238, 0.0565685424949238, 0.0]),\n            np.array([0.0, 0.0, 0.0]),\n            0.005,\n            np.array([0.003, -0.002, 0.001]),\n            np.array([-0.001, 0.002, -0.002])\n        ),\n        # Case 3\n        (\n            np.array([0.050, -0.010, 0.025]),\n            np.array([0.020, -0.010, 0.015]),\n            0.005,\n            np.array([-0.0015, 0.001, -0.001]),\n            np.array([0.001, -0.001, 0.0015])\n        )\n    ]\n\n    all_results_str = []\n\n    for L, M, eps, dL, dM in test_cases:\n        # Task 1: Compute baseline unit axis u\n        v = L - M\n        d = np.linalg.norm(v)\n        \n        # Handle case where L=M, though not in test data.\n        if d == 0:\n            # Axis is undefined, can't proceed. In a real scenario, this would raise an error.\n            # For this problem, we assume d > 0 based on test cases.\n            u = np.array([0.0, 0.0, 0.0])\n        else:\n            u = v / d\n\n        # Task 2: Compute worst-case small-angle bound\n        # Formula: theta_bound = 2 * eps / d\n        if d > 0:\n            worst_case_rad = (2 * eps) / d\n        else:\n            worst_case_rad = np.inf\n        worst_case_deg = np.rad2deg(worst_case_rad)\n\n        # Task 3: Compute coordinate-wise first-order sensitivities\n        if d > 0:\n            # Sensitivities are sqrt(1-u_i^2)/d for i=x,y,z\n            sensitivities = [np.sqrt(1 - u_comp**2) / d for u_comp in u]\n            max_sensitivity_rad_per_m = max(sensitivities)\n            min_sensitivity_rad_per_m = min(sensitivities)\n        else:\n            max_sensitivity_rad_per_m = np.inf\n            min_sensitivity_rad_per_m = np.inf\n\n        # Task 4: Compute actual angular deviation\n        L_tilde = L + dL\n        M_tilde = M + dM\n        v_tilde = L_tilde - M_tilde\n        d_tilde = np.linalg.norm(v_tilde)\n\n        if d > 0 and d_tilde > 0:\n            u_tilde = v_tilde / d_tilde\n            # Dot product can be slightly outside [-1, 1] due to floating point error\n            dot_product = np.clip(np.dot(u, u_tilde), -1.0, 1.0)\n            actual_rad = np.arccos(dot_product)\n            actual_deg = np.rad2deg(actual_rad)\n        else:\n            actual_deg = 0.0 # Or undefined; 0 if no change.\n\n        # Store results for this case\n        case_results = [\n            worst_case_deg,\n            max_sensitivity_rad_per_m,\n            min_sensitivity_rad_per_m,\n            actual_deg\n        ]\n        \n        # Format the sublist as a string [val1,val2,val3,val4]\n        sub_list_str = f\"[{','.join([f'{x:.6f}' for x in case_results])}]\"\n        all_results_str.append(sub_list_str)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(all_results_str)}]\")\n\nsolve()\n\n```"
        },
        {
            "introduction": "Real-world motion capture is rarely perfect; markers are frequently occluded, creating gaps in their trajectories. While interpolation is a common tool for filling these gaps, it is not a perfect solution and can introduce subtle artifacts. This exercise  provides a controlled simulation to analyze how marker dropout and reconstruction via interpolation affect kinematic accuracy, demonstrating that errors are often amplified when computing derivatives such as angular velocity, a critical consideration for any dynamic analysis.",
            "id": "4192317",
            "problem": "You are given a synthetic two-dimensional marker-based segment model representing a limb segment in biomechanics. The segment is defined by a joint center and two markers placed at equal distances along the segment line: a proximal marker and a distal marker. The segment length is fixed. The true motion is governed by smooth functions of time. You must analyze the effect of marker dropout on computed kinematics by introducing gaps of varying lengths into the distal marker trajectory, reconstructing the missing data via interpolation, and evaluating the reconstruction error relative to the complete data. The task is fully specified below.\n\nAssume a sampling frequency of $f_s = 120\\,\\text{Hz}$ and a duration of $T = 5\\,\\text{s}$, giving $N = f_s \\cdot T = 600$ samples. Let the time vector be $t_n = n / f_s$ for $n = 0, 1, \\dots, N-1$, with sampling interval $\\Delta t = 1/f_s$. All angles must be expressed in radians, linear quantities in meters, and angular velocities in radians per second.\n\nDefine the joint center position $\\mathbf{C}(t)$ and segment orientation $\\theta(t)$ by the following smooth functions:\n- $\\mathbf{C}(t) = \\big(C_x(t), C_y(t)\\big)$, where $C_x(t) = 0.50\\,\\sin\\!\\big(2\\pi \\cdot 0.40 \\cdot t\\big)$ and $C_y(t) = 0.80 + 0.10\\,\\cos\\!\\big(2\\pi \\cdot 0.60 \\cdot t\\big)$.\n- $\\theta(t) = \\theta_0 + A\\,\\sin\\!\\big(2\\pi b t\\big) + B\\,\\sin\\!\\big(2\\pi c t\\big)$, with $\\theta_0 = 0.50$, $A = 0.60$, $b = 1.50$, $B = 0.20$, and $c = 3.00$.\n\nLet the segment length be $L = 0.40\\,\\text{m}$. Define the proximal and distal marker positions by\n$$\n\\mathbf{P}(t) = \\mathbf{C}(t) - \\frac{L}{2} \\begin{bmatrix}\\cos\\theta(t) \\\\ \\sin\\theta(t)\\end{bmatrix}, \\quad\n\\mathbf{D}(t) = \\mathbf{C}(t) + \\frac{L}{2} \\begin{bmatrix}\\cos\\theta(t) \\\\ \\sin\\theta(t)\\end{bmatrix}.\n$$\nThe true segment orientation recovered from markers is $\\phi(t) = \\mathrm{atan2}\\!\\big(D_y(t) - P_y(t), D_x(t) - P_x(t)\\big)$, which equals $\\theta(t)$ by construction. The true angular velocity is $\\omega(t) = \\frac{d\\theta}{dt} = 2\\pi A b \\cos\\!\\big(2\\pi b t\\big) + 2\\pi B c \\cos\\!\\big(2\\pi c t\\big)$.\n\nIntroduce dropout gaps into the distal marker only. For each test case, set $\\mathbf{D}(t)$ to missing for a contiguous block of frames indexed by $n = s, s+1, \\dots, s+\\ell-1$ (inclusive), where $s$ is the gap start index and $\\ell$ is the gap length in frames. Reconstruct the missing distal marker coordinates $\\mathbf{\\hat D}(t)$ by performing shape-preserving piecewise cubic interpolation (a monotone Piecewise Cubic Hermite Interpolating Polynomial) on $D_x(t)$ and $D_y(t)$ with respect to time, using all available non-missing samples and extrapolating where necessary at boundary cases. Use the proximal marker $\\mathbf{P}(t)$ without dropout.\n\nFrom the reconstructed trajectory, compute the reconstructed orientation $\\hat\\phi(t) = \\mathrm{atan2}\\!\\big(\\hat D_y(t) - P_y(t), \\hat D_x(t) - P_x(t)\\big)$ and the reconstructed angular velocity $\\hat\\omega(t)$ via numerical differentiation using a second-order accurate central difference for interior points and first-order differences at the boundaries, which is equivalent to a standard gradient operator with uniform spacing $\\Delta t$.\n\nDefine the Root Mean Square Error (RMSE) for a signal $x(t)$ relative to the true signal $x_{\\text{true}}(t)$ as\n$$\n\\mathrm{RMSE}(x) = \\sqrt{\\frac{1}{N}\\sum_{n=0}^{N-1}\\left(x(t_n)-x_{\\text{true}}(t_n)\\right)^2}.\n$$\nFor position error, use the Euclidean norm at each time:\n$$\n\\mathrm{RMSE}(\\mathbf{D}) = \\sqrt{\\frac{1}{N}\\sum_{n=0}^{N-1}\\left[\\big(\\hat D_x(t_n)-D_x(t_n)\\big)^2 + \\big(\\hat D_y(t_n)-D_y(t_n)\\big)^2\\right]}.\n$$\nFor the orientation error, compute the wrapped difference $\\Delta\\phi(t) = \\mathrm{atan2}\\!\\big(\\sin(\\hat\\phi(t)-\\phi(t)), \\cos(\\hat\\phi(t)-\\phi(t))\\big)$ to respect angular periodicity, and then compute $\\mathrm{RMSE}(\\phi)$ from $\\Delta\\phi(t)$. For angular velocity, use $\\mathrm{RMSE}(\\omega)$ computed from $\\hat\\omega(t)$ and $\\omega(t)$.\n\nImplement the above and evaluate the following test suite of dropout scenarios, each specified by a start index $s$ and a length $\\ell$ (in frames):\n- Case $1$: $s = 180$, $\\ell = 12$.\n- Case $2$: $s = 0$, $\\ell = 60$.\n- Case $3$: $s = 360$, $\\ell = 120$.\n- Case $4$: $s = 540$, $\\ell = 60$.\n\nFor each case, compute the three RMSE values: position RMSE in meters, orientation RMSE in radians, and angular velocity RMSE in radians per second. Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, with the three floats for each case concatenated in order. The final output must therefore have length $3 \\times 4 = 12$, in the order\n$$\n\\big[\\mathrm{RMSE}(\\mathbf{D})_{\\text{case 1}},\\, \\mathrm{RMSE}(\\phi)_{\\text{case 1}},\\, \\mathrm{RMSE}(\\omega)_{\\text{case 1}},\\, \\mathrm{RMSE}(\\mathbf{D})_{\\text{case 2}},\\, \\mathrm{RMSE}(\\phi)_{\\text{case 2}},\\, \\mathrm{RMSE}(\\omega)_{\\text{case 2}},\\, \\mathrm{RMSE}(\\mathbf{D})_{\\text{case 3}},\\, \\mathrm{RMSE}(\\phi)_{\\text{case 3}},\\, \\mathrm{RMSE}(\\omega)_{\\text{case 3}},\\, \\mathrm{RMSE}(\\mathbf{D})_{\\text{case 4}},\\, \\mathrm{RMSE}(\\phi)_{\\text{case 4}},\\, \\mathrm{RMSE}(\\omega)_{\\text{case 4}}\\big].\n$$\nThe line must contain no spaces.",
            "solution": "The problem is valid. It presents a well-defined simulation study in biomechanics, grounded in established principles of kinematics and signal processing. All parameters, equations, and evaluation metrics are specified with sufficient precision to permit a unique and verifiable solution.\n\nThe solution is developed in five principal stages:\n1.  **Generation of Ground Truth Kinematics**: First, we generate the complete, noise-free kinematic data that serve as the \"ground truth.\" This involves discretizing the provided continuous functions over the specified time domain.\n2.  **Simulation of Data Loss**: For each test case, we simulate marker dropout by introducing a contiguous gap of a specified length and start time into the distal marker's trajectory data.\n3.  **Data Reconstruction**: The missing data points in the gapped distal marker trajectory are reconstructed using a shape-preserving piecewise cubic Hermite interpolating polynomial (PCHIP).\n4.  **Calculation of Reconstructed Kinematics**: From the reconstructed distal marker data and the complete proximal marker data, we compute the reconstructed segment orientation and angular velocity.\n5.  **Error Quantification**: Finally, we quantify the impact of the data loss and reconstruction by calculating the Root Mean Square Error (RMSE) for the reconstructed marker position, segment orientation, and segment angular velocity, comparing each to its respective ground truth signal.\n\nHere is a detailed breakdown of the methodology for each stage.\n\n**1. Ground Truth Generation**\nThe simulation is based on a sampling frequency $f_s = 120\\,\\text{Hz}$ over a duration of $T = 5\\,\\text{s}$, resulting in $N = f_s T = 600$ discrete time samples. The time vector is $t = [t_0, t_1, \\dots, t_{N-1}]$, where $t_n = n \\Delta t$ and the sampling interval is $\\Delta t = 1/f_s$.\n\nThe ground truth kinematics are defined by:\n-   Joint center position: $\\mathbf{C}(t) = \\big(C_x(t), C_y(t)\\big)$, where $C_x(t) = 0.50\\,\\sin(2\\pi \\cdot 0.40 \\cdot t)$ and $C_y(t) = 0.80 + 0.10\\,\\cos(2\\pi \\cdot 0.60 \\cdot t)$.\n-   Segment orientation: $\\theta(t) = 0.50 + 0.60\\,\\sin(2\\pi \\cdot 1.50 \\cdot t) + 0.20\\,\\sin(2\\pi \\cdot 3.00 \\cdot t)$.\n-   Analytical angular velocity: The time derivative of orientation, $\\omega(t) = \\frac{d\\theta}{dt} = 2\\pi(0.60)(1.50)\\cos(2\\pi \\cdot 1.50 \\cdot t) + 2\\pi(0.20)(3.00)\\cos(2\\pi \\cdot 3.00 \\cdot t)$.\n\nFrom these, the proximal marker $\\mathbf{P}(t)$ and distal marker $\\mathbf{D}(t)$ positions are calculated. Given the segment length $L = 0.40\\,\\text{m}$, the positions are determined by placing the markers at a distance of $L/2$ from the joint center along the segment's axis:\n$$\n\\mathbf{P}(t) = \\mathbf{C}(t) - \\frac{L}{2}\\mathbf{u}(t) \\quad \\text{and} \\quad \\mathbf{D}(t) = \\mathbf{C}(t) + \\frac{L}{2}\\mathbf{u}(t)\n$$\nwhere $\\mathbf{u}(t) = [\\cos\\theta(t), \\sin\\theta(t)]^T$ is the unit vector oriented along the segment. The true segment orientation can be recovered from the marker positions via $\\phi(t) = \\mathrm{atan2}(D_y(t) - P_y(t), D_x(t) - P_x(t))$, which equals $\\theta(t)$ by construction.\n\n**2. Simulation of Data Loss**\nFor each test case defined by a start frame index $s$ and gap length $\\ell$, the time-series data for both components of the distal marker, $D_x(t_n)$ and $D_y(t_n)$, are set to a \"Not a Number\" (NaN) value for all indices $n$ from $s$ to $s+\\ell-1$. The proximal marker data $\\mathbf{P}(t)$ remains complete.\n\n**3. Data Reconstruction via PCHIP**\nThe core of the reconstruction process is the use of `scipy.interpolate.PchipInterpolator`. This method is chosen because it is designed to preserve the monotonicity of the original data, preventing the artificial oscillations (overshoots) that can be introduced by standard cubic splines. This property is particularly valuable when interpolating physical data like marker trajectories.\nTwo separate interpolators are constructed: one for the $x$-component and one for the $y$-component of the distal marker trajectory. Each interpolator is built using the time stamps ($t_n$) and corresponding coordinate values from all available (non-NaN) data points. For test cases where the gap occurs at the beginning or end of the trial, the interpolator is configured to extrapolate, providing estimates for the missing data outside the domain of the known points. The interpolators are then evaluated over the full time vector $t$ to produce the complete reconstructed distal marker trajectory, $\\mathbf{\\hat D}(t) = (\\hat D_x(t), \\hat D_y(t))$.\n\n**4. Calculation of Reconstructed Kinematics**\nWith the reconstructed distal marker trajectory $\\mathbf{\\hat D}(t)$ and the true proximal marker trajectory $\\mathbf{P}(t)$, the reconstructed segment orientation $\\hat\\phi(t)$ is computed for all time points:\n$$\n\\hat\\phi(t) = \\mathrm{atan2}(\\hat D_y(t) - P_y(t), \\hat D_x(t) - P_x(t))\n$$\nThe reconstructed angular velocity $\\hat\\omega(t)$ is then determined by numerically differentiating $\\hat\\phi(t)$ with respect to time. A critical prerequisite for differentiation is to handle the circular nature of angles. The `atan2` function returns values in the range $(-\\pi, \\pi]$, which can lead to artificial discontinuities (e.g., a jump from $\\pi$ to $-\\pi$). To obtain a physically meaningful velocity, the angle time-series $\\hat\\phi(t)$ is first \"unwrapped\" to produce a continuous phase angle. The numerical differentiation is then performed on this unwrapped angle signal using `numpy.gradient` with the known time step $\\Delta t$. This function implements a second-order accurate central difference for interior points and less accurate first-order forward/backward differences at the boundaries, as specified.\n\n**5. Error Quantification**\nThe accuracy of the reconstruction is evaluated by computing the RMSE between the reconstructed signals and the ground truth signals over the entire duration $T$.\n-   **Position RMSE**: The error is the square root of the mean squared Euclidean distance between the reconstructed marker position $\\mathbf{\\hat D}(t)$ and the true position $\\mathbf{D}(t)$:\n    $$\n    \\mathrm{RMSE}(\\mathbf{D}) = \\sqrt{\\frac{1}{N}\\sum_{n=0}^{N-1}\\left( (\\hat D_x(t_n)-D_x(t_n))^2 + (\\hat D_y(t_n)-D_y(t_n))^2 \\right)}\n    $$\n-   **Orientation RMSE**: To correctly handle the $2\\pi$ periodicity of angles, the error is calculated based on the shortest angle between $\\hat\\phi(t_n)$ and $\\phi(t_n)$. This is achieved by computing the wrapped difference $\\Delta\\phi(t_n) = \\mathrm{atan2}(\\sin(\\hat\\phi(t_n)-\\phi(t_n)), \\cos(\\hat\\phi(t_n)-\\phi(t_n)))$. The RMSE is then:\n    $$\n    \\mathrm{RMSE}(\\phi) = \\sqrt{\\frac{1}{N}\\sum_{n=0}^{N-1}(\\Delta\\phi(t_n))^2}\n    $$\n-   **Angular Velocity RMSE**: This is a direct RMSE calculation between the reconstructed signal $\\hat\\omega(t)$ and the analytical ground truth $\\omega(t)$:\n    $$\n    \\mathrm{RMSE}(\\omega) = \\sqrt{\\frac{1}{N}\\sum_{n=0}^{N-1}(\\hat\\omega(t_n) - \\omega(t_n))^2}\n    $$\nThese three RMSE values are calculated for each of the four specified gap scenarios, providing a quantitative measure of how different gap characteristics (location and duration) affect kinematic accuracy.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.interpolate import PchipInterpolator\n\ndef solve():\n    \"\"\"\n    Solves the biomechanics marker dropout simulation problem.\n    \"\"\"\n    # ------------------\n    # 1. Define Givens and Generate Ground Truth\n    # ------------------\n    \n    # System parameters\n    f_s = 120.0  # Sampling frequency in Hz\n    T = 5.0      # Duration in seconds\n    N = int(f_s * T) # Number of samples\n    delta_t = 1.0 / f_s # Sampling interval\n    L = 0.40     # Segment length in meters\n\n    # Motion function parameters\n    theta_0 = 0.50\n    A = 0.60\n    b = 1.50\n    B = 0.20\n    c = 3.00\n\n    # Time vector\n    t = np.arange(N) * delta_t\n\n    # True joint center position C(t)\n    Cx_t = 0.50 * np.sin(2 * np.pi * 0.40 * t)\n    Cy_t = 0.80 + 0.10 * np.cos(2 * np.pi * 0.60 * t)\n    C_t = np.vstack((Cx_t, Cy_t)).T\n\n    # True segment orientation theta(t)\n    theta_t = theta_0 + A * np.sin(2 * np.pi * b * t) + B * np.sin(2 * np.pi * c * t)\n\n    # True analytical angular velocity omega(t)\n    omega_t = 2 * np.pi * A * b * np.cos(2 * np.pi * b * t) + \\\n              2 * np.pi * B * c * np.cos(2 * np.pi * c * t)\n\n    # True unit vector along the segment\n    u_t = np.vstack((np.cos(theta_t), np.sin(theta_t))).T\n\n    # True proximal and distal marker positions P(t) and D(t)\n    P_t = C_t - (L / 2) * u_t\n    D_t = C_t + (L / 2) * u_t\n\n    # True orientation from markers (equals theta_t by construction)\n    phi_t = np.arctan2(D_t[:, 1] - P_t[:, 1], D_t[:, 0] - P_t[:, 0])\n    \n    # Test cases: (start_index, length_in_frames)\n    test_cases = [\n        (180, 12),\n        (0, 60),\n        (360, 120),\n        (540, 60),\n    ]\n\n    results = []\n    \n    # ------------------\n    # 2. Process each test case\n    # ------------------\n    for s, l in test_cases:\n        # Create gapped distal marker data\n        D_gapped_x = D_t[:, 0].copy()\n        D_gapped_y = D_t[:, 1].copy()\n        \n        gap_indices = np.arange(s, min(s + l, N))\n        D_gapped_x[gap_indices] = np.nan\n        D_gapped_y[gap_indices] = np.nan\n        \n        # Identify non-missing data points for interpolation\n        known_indices = np.where(~np.isnan(D_gapped_x))[0]\n        t_known = t[known_indices]\n        Dx_known = D_t[known_indices, 0]\n        Dy_known = D_t[known_indices, 1]\n        \n        # Reconstruct missing data using PCHIP interpolation\n        interp_x = PchipInterpolator(t_known, Dx_known, extrapolate=True)\n        interp_y = PchipInterpolator(t_known, Dy_known, extrapolate=True)\n        \n        D_hat_x = interp_x(t)\n        D_hat_y = interp_y(t)\n        \n        # Calculate reconstructed kinematics\n        # Reconstructed orientation\n        phi_hat_t = np.arctan2(D_hat_y - P_t[:, 1], D_hat_x - P_t[:, 0])\n        \n        # Reconstructed angular velocity (differentiate unwrapped angle)\n        phi_hat_unwrapped = np.unwrap(phi_hat_t)\n        omega_hat_t = np.gradient(phi_hat_unwrapped, delta_t)\n\n        # ------------------\n        # 3. Calculate and store RMSE values\n        # ------------------\n        \n        # Position RMSE\n        pos_sq_err = (D_hat_x - D_t[:, 0])**2 + (D_hat_y - D_t[:, 1])**2\n        rmse_pos = np.sqrt(np.mean(pos_sq_err))\n        \n        # Orientation RMSE (using wrapped difference)\n        orient_diff = phi_hat_t - phi_t\n        orient_wrapped_diff = np.arctan2(np.sin(orient_diff), np.cos(orient_diff))\n        rmse_orient = np.sqrt(np.mean(orient_wrapped_diff**2))\n\n        # Angular Velocity RMSE\n        ang_vel_sq_err = (omega_hat_t - omega_t)**2\n        rmse_ang_vel = np.sqrt(np.mean(ang_vel_sq_err))\n        \n        results.extend([rmse_pos, rmse_orient, rmse_ang_vel])\n\n    # ------------------\n    # 4. Format and print the final output\n    # ------------------\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        }
    ]
}