{
    "hands_on_practices": [
        {
            "introduction": "The passive mechanical response of muscle and fascia is markedly nonlinear, a property known as strain-stiffening. This means the tissue becomes stiffer as it is stretched, which is crucial for providing both flexibility at low strains and robust protection against overstretching at high strains. To quantify this behavior, we must distinguish between the average stiffness over a range of strain (the secant modulus) and the instantaneous stiffness at a specific point (the tangent modulus). This exercise  provides a hands-on calculation to help you differentiate these two important measures using a common exponential stress-strain model.",
            "id": "4197239",
            "problem": "In passive uniaxial tensile testing of human crural fascia, the Cauchy stress–engineering strain response can be captured over small-to-moderate strains by the convex exponential relation $\\sigma(\\epsilon)=A\\big(\\exp(B\\epsilon)-1\\big)$, where $\\sigma$ is stress, $\\epsilon$ is engineering strain, $A$ is a stiffness scale, and $B$ is a nonlinearity parameter. Consider a specimen whose fitted parameters are $A=4.5\\,\\text{kPa}$ and $B=15$ (dimensionless). Using standard continuum mechanics definitions of the tangent modulus (instantaneous slope of the stress–strain curve) and the secant modulus (average slope from the origin), determine both moduli at $\\epsilon=0.1$. Express both moduli in kilopascals ($\\text{kPa}$) and round your answers to four significant figures. Then, interpret the differences between these moduli in terms of the nonlinearity of the tissue’s passive response. Your final numeric answers must be provided for the moduli only, without interpretation, while the interpretation should be included in your reasoning.",
            "solution": "The problem is deemed valid as it is scientifically grounded in continuum mechanics and biomechanics, is well-posed with all necessary information provided, and is expressed in objective, formal language.\n\nThe passive stress-strain relationship for the crural fascia is given by the constitutive equation:\n$$\n\\sigma(\\epsilon) = A(\\exp(B\\epsilon) - 1)\n$$\nwhere $\\sigma$ is the Cauchy stress, $\\epsilon$ is the engineering strain, and the material parameters are given as $A = 4.5 \\, \\text{kPa}$ and $B = 15$. We are asked to determine the tangent modulus and the secant modulus at a strain of $\\epsilon = 0.1$.\n\nFirst, we define the tangent modulus, $E_t$. The tangent modulus is the instantaneous slope of the stress-strain curve at a specific point, which is mathematically defined as the first derivative of the stress with respect to strain.\n$$\nE_t(\\epsilon) = \\frac{d\\sigma}{d\\epsilon}\n$$\nWe compute this derivative from the given stress function:\n$$\nE_t(\\epsilon) = \\frac{d}{d\\epsilon} \\left[ A(\\exp(B\\epsilon) - 1) \\right] = A \\frac{d}{d\\epsilon} \\left[ \\exp(B\\epsilon) - 1 \\right]\n$$\nApplying the chain rule for differentiation, we find:\n$$\nE_t(\\epsilon) = A (B \\exp(B\\epsilon) - 0) = AB \\exp(B\\epsilon)\n$$\nNow, we evaluate the tangent modulus at the specified strain, $\\epsilon = 0.1$.\n$$\nE_t(0.1) = AB \\exp(B \\times 0.1) = (4.5 \\, \\text{kPa})(15) \\exp(15 \\times 0.1)\n$$\n$$\nE_t(0.1) = 67.5 \\exp(1.5) \\, \\text{kPa}\n$$\nCalculating the numerical value:\n$$\nE_t(0.1) \\approx 67.5 \\times 4.48168907 = 302.514012... \\, \\text{kPa}\n$$\nRounding to four significant figures, the tangent modulus is $302.5 \\, \\text{kPa}$.\n\nSecond, we define the secant modulus, $E_s$. The secant modulus represents the average stiffness from the origin $(\\epsilon_1=0, \\sigma_1=0)$ to a specific point on the curve $(\\epsilon_2=\\epsilon, \\sigma_2=\\sigma(\\epsilon))$. It is the slope of the chord connecting these two points.\n$$\nE_s(\\epsilon) = \\frac{\\sigma(\\epsilon) - \\sigma(0)}{\\epsilon - 0} = \\frac{\\sigma(\\epsilon)}{\\epsilon}\n$$\nNote that $\\sigma(0) = A(\\exp(B \\times 0) - 1) = A(1-1) = 0$, which is consistent with the material being in an unstressed state at zero strain.\nSubstituting the expression for $\\sigma(\\epsilon)$:\n$$\nE_s(\\epsilon) = \\frac{A(\\exp(B\\epsilon) - 1)}{\\epsilon}\n$$\nNow, we evaluate the secant modulus at the specified strain, $\\epsilon = 0.1$.\n$$\nE_s(0.1) = \\frac{A(\\exp(B \\times 0.1) - 1)}{0.1} = \\frac{4.5 \\, \\text{kPa} (\\exp(15 \\times 0.1) - 1)}{0.1}\n$$\n$$\nE_s(0.1) = 45 (\\exp(1.5) - 1) \\, \\text{kPa}\n$$\nCalculating the numerical value:\n$$\nE_s(0.1) \\approx 45 \\times (4.48168907 - 1) = 45 \\times 3.48168907 = 156.676008... \\, \\text{kPa}\n$$\nRounding to four significant figures, the secant modulus is $156.7 \\, \\text{kPa}$.\n\nFinally, we interpret the difference between the two moduli. At $\\epsilon = 0.1$, we found $E_t \\approx 302.5 \\, \\text{kPa}$ and $E_s \\approx 156.7 \\, \\text{kPa}$. The tangent modulus is significantly greater than the secant modulus ($E_t > E_s$). This is characteristic of a material with a \"strain-stiffening\" response. The stress-strain curve is convex, meaning it curves upward. The convexity can be confirmed by examining the second derivative of stress with respect to strain:\n$$\n\\frac{d^2\\sigma}{d\\epsilon^2} = \\frac{d}{d\\epsilon}(AB \\exp(B\\epsilon)) = AB^2 \\exp(B\\epsilon)\n$$\nSince $A > 0$ and $B > 0$, the second derivative is always positive, confirming the strict convexity of the stress-strain curve. For a convex function passing through the origin, the slope of the tangent line at any point $\\epsilon > 0$ is always greater than the slope of the secant line from the origin to that point.\nIn physical terms, the secant modulus $E_s$ represents the average stiffness of the tissue over the strain range from $0$ to $0.1$. The tangent modulus $E_t$ represents the material's instantaneous stiffness at the specific strain of $0.1$. The fact that $E_t$ is nearly double $E_s$ indicates that the tissue becomes markedly stiffer as it is stretched. This nonlinear, strain-stiffening behavior is a critical functional property of many biological soft tissues like fascia, ligaments, and tendons.",
            "answer": "$$\n\\boxed{\\begin{pmatrix} 302.5 & 156.7 \\end{pmatrix}}\n$$"
        },
        {
            "introduction": "Beyond nonlinear elasticity, the mechanical response of biological soft tissues is also time-dependent, a property known as viscoelasticity. This means that the stress in the material depends not only on the current strain but also on the history of how that strain was applied. A key consequence of viscoelasticity is energy dissipation, or hysteresis, where mechanical energy is lost (typically as heat) during a cycle of loading and unloading. This exercise  uses the classic Kelvin–Voigt model to derive and quantify the energy dissipated during a sinusoidal strain cycle, providing insight into the tissue's damping characteristics.",
            "id": "4197271",
            "problem": "A passive muscle–fascia segment under small uniaxial strain can be idealized as a Kelvin–Voigt element, which consists of a linear elastic spring of modulus $E$ in parallel with a linear viscous dashpot of viscosity $\\eta$. Consider a homogeneous sample of volume $V$ subjected to a prescribed sinusoidal strain history $ \\epsilon(t) = \\epsilon_{0} \\sin(\\omega t) $ over time $t$, where $\\epsilon_{0}$ is the strain amplitude and $\\omega$ is the angular frequency. Using the definitions of linear elasticity ($ \\sigma_{\\text{spring}} = E \\epsilon $), Newtonian viscosity ($ \\sigma_{\\text{dashpot}} = \\eta\\, d\\epsilon/dt $), and the mechanical work per unit volume performed on the material $ w = \\oint \\sigma \\, d\\epsilon $ over one complete loading–unloading cycle, derive from first principles an explicit analytic expression for the total mechanical energy dissipated by hysteresis in one cycle. Then evaluate this energy for the parameter values $ E = 80\\,\\mathrm{kPa} $, $ \\eta = 1.5\\,\\mathrm{kPa \\cdot s} $, $ \\epsilon_{0} = 0.06 $, $ \\omega = 10\\,\\mathrm{rad/s} $, and $ V = 1.0 \\times 10^{-6}\\,\\mathrm{m^{3}} $. Round your final numerical result to four significant figures. Express the final energy in Joules (J).",
            "solution": "The problem is first validated and found to be self-contained, scientifically grounded, and well-posed. The provided physical model and parameters are consistent and realistic for the context of biomechanics. We can therefore proceed with the derivation.\n\nThe passive muscle–fascia segment is modeled as a Kelvin–Voigt element. In this model, a linear elastic spring and a linear viscous dashpot are arranged in parallel. For elements in parallel, the strain $\\epsilon$ is the same across both components, and the total stress $\\sigma$ is the sum of the individual stresses.\n\nThe total stress $\\sigma(t)$ at any time $t$ is given by:\n$$\n\\sigma(t) = \\sigma_{\\text{spring}}(t) + \\sigma_{\\text{dashpot}}(t)\n$$\nThe constitutive relations for the spring and dashpot are provided:\n$$\n\\sigma_{\\text{spring}}(t) = E \\epsilon(t)\n$$\n$$\n\\sigma_{\\text{dashpot}}(t) = \\eta \\frac{d\\epsilon(t)}{dt}\n$$\nwhere $E$ is the elastic modulus and $\\eta$ is the viscosity.\n\nSubstituting these into the total stress equation gives the governing constitutive equation for the Kelvin–Voigt model:\n$$\n\\sigma(t) = E \\epsilon(t) + \\eta \\frac{d\\epsilon(t)}{dt}\n$$\nThe problem specifies a sinusoidal strain history:\n$$\n\\epsilon(t) = \\epsilon_{0} \\sin(\\omega t)\n$$\nwhere $\\epsilon_{0}$ is the strain amplitude and $\\omega$ is the angular frequency.\n\nTo find the stress, we first need the time derivative of the strain, which represents the strain rate:\n$$\n\\frac{d\\epsilon(t)}{dt} = \\frac{d}{dt} \\left( \\epsilon_{0} \\sin(\\omega t) \\right) = \\epsilon_{0} \\omega \\cos(\\omega t)\n$$\nNow, we substitute the expressions for $\\epsilon(t)$ and $d\\epsilon/dt$ into the equation for total stress:\n$$\n\\sigma(t) = E \\left( \\epsilon_{0} \\sin(\\omega t) \\right) + \\eta \\left( \\epsilon_{0} \\omega \\cos(\\omega t) \\right)\n$$\n$$\n\\sigma(t) = \\epsilon_{0} \\left( E \\sin(\\omega t) + \\eta \\omega \\cos(\\omega t) \\right)\n$$\nThe mechanical energy dissipated by hysteresis in one cycle is equivalent to the net work done on the material over that cycle. The work done per unit volume, $w$, over one complete cycle is given by the integral:\n$$\nw = \\oint \\sigma \\, d\\epsilon\n$$\nOne complete cycle corresponds to the time interval from $t=0$ to $t=T$, where $T$ is the period, $T = 2\\pi/\\omega$. We can express the differential $d\\epsilon$ in terms of $dt$ using the chain rule: $d\\epsilon = \\frac{d\\epsilon}{dt} dt$.\n$$\nw = \\int_{0}^{T} \\sigma(t) \\frac{d\\epsilon}{dt} dt = \\int_{0}^{2\\pi/\\omega} \\sigma(t) \\frac{d\\epsilon}{dt} dt\n$$\nSubstituting the expressions for $\\sigma(t)$ and $d\\epsilon/dt$:\n$$\nw = \\int_{0}^{2\\pi/\\omega} \\left[ E \\epsilon_{0} \\sin(\\omega t) + \\eta \\epsilon_{0} \\omega \\cos(\\omega t) \\right] \\left( \\epsilon_{0} \\omega \\cos(\\omega t) \\right) dt\n$$\nExpanding the integrand gives:\n$$\nw = \\int_{0}^{2\\pi/\\omega} \\left( E \\epsilon_{0}^2 \\omega \\sin(\\omega t) \\cos(\\omega t) + \\eta \\epsilon_{0}^2 \\omega^2 \\cos^2(\\omega t) \\right) dt\n$$\nWe can separate this into two integrals:\n$$\nw = E \\epsilon_{0}^2 \\omega \\int_{0}^{2\\pi/\\omega} \\sin(\\omega t) \\cos(\\omega t) dt + \\eta \\epsilon_{0}^2 \\omega^2 \\int_{0}^{2\\pi/\\omega} \\cos^2(\\omega t) dt\n$$\nThe first integral represents the work done by the elastic component. Using the trigonometric identity $\\sin(2\\theta) = 2\\sin(\\theta)\\cos(\\theta)$:\n$$\n\\int_{0}^{2\\pi/\\omega} \\sin(\\omega t) \\cos(\\omega t) dt = \\frac{1}{2} \\int_{0}^{2\\pi/\\omega} \\sin(2\\omega t) dt = \\frac{1}{2} \\left[ -\\frac{\\cos(2\\omega t)}{2\\omega} \\right]_{0}^{2\\pi/\\omega}\n$$\n$$\n= -\\frac{1}{4\\omega} \\left[ \\cos(4\\pi) - \\cos(0) \\right] = -\\frac{1}{4\\omega} (1 - 1) = 0\n$$\nAs expected, the net work done by the ideal elastic component over a closed cycle is zero. The energy is stored during loading and fully recovered during unloading.\n\nThe second integral represents the work done by the viscous component, which is dissipated as heat. Using the identity $\\cos^2(\\theta) = \\frac{1 + \\cos(2\\theta)}{2}$:\n$$\n\\int_{0}^{2\\pi/\\omega} \\cos^2(\\omega t) dt = \\int_{0}^{2\\pi/\\omega} \\frac{1 + \\cos(2\\omega t)}{2} dt = \\frac{1}{2} \\left[ t + \\frac{\\sin(2\\omega t)}{2\\omega} \\right]_{0}^{2\\pi/\\omega}\n$$\n$$\n= \\frac{1}{2} \\left[ \\left(\\frac{2\\pi}{\\omega} + \\frac{\\sin(4\\pi)}{2\\omega}\\right) - (0 + 0) \\right] = \\frac{1}{2} \\left( \\frac{2\\pi}{\\omega} \\right) = \\frac{\\pi}{\\omega}\n$$\nThe dissipated energy per unit volume, $w_{diss}$, is therefore:\n$$\nw_{diss} = w = 0 + \\eta \\epsilon_{0}^2 \\omega^2 \\left( \\frac{\\pi}{\\omega} \\right) = \\pi \\eta \\omega \\epsilon_{0}^2\n$$\nThis is the analytical expression for the energy dissipated per unit volume per cycle. To find the total energy dissipated, $W_{diss}$, we multiply by the sample volume $V$:\n$$\nW_{diss} = w_{diss} \\cdot V = \\pi \\eta \\omega \\epsilon_{0}^2 V\n$$\nNow, we substitute the given numerical values into this expression. First, we ensure all units are in the base SI system.\n$E = 80\\,\\mathrm{kPa} = 80 \\times 10^3\\,\\mathrm{Pa}$ (This value is not needed for the dissipation calculation)\n$\\eta = 1.5\\,\\mathrm{kPa \\cdot s} = 1.5 \\times 10^3\\,\\mathrm{Pa \\cdot s}$\n$\\epsilon_{0} = 0.06$\n$\\omega = 10\\,\\mathrm{rad/s}$\n$V = 1.0 \\times 10^{-6}\\,\\mathrm{m^3}$\n\n$$\nW_{diss} = \\pi (1.5 \\times 10^3\\,\\mathrm{Pa \\cdot s}) (10\\,\\mathrm{s^{-1}}) (0.06)^2 (1.0 \\times 10^{-6}\\,\\mathrm{m^3})\n$$\nThe units are $(\\mathrm{Pa \\cdot s}) \\cdot (\\mathrm{s^{-1}}) \\cdot (\\mathrm{m^3}) = \\mathrm{Pa \\cdot m^3} = (\\mathrm{N/m^2}) \\cdot \\mathrm{m^3} = \\mathrm{N \\cdot m} = \\mathrm{J}$, as required.\n$$\nW_{diss} = \\pi \\times (1.5 \\times 10^3) \\times 10 \\times (3.6 \\times 10^{-3}) \\times (1.0 \\times 10^{-6}) \\,\\mathrm{J}\n$$\n$$\nW_{diss} = \\pi \\times (1.5 \\times 10^4) \\times (3.6 \\times 10^{-3}) \\times 10^{-6} \\,\\mathrm{J}\n$$\n$$\nW_{diss} = \\pi \\times (1.5 \\times 3.6) \\times 10^{4-3-6} \\,\\mathrm{J}\n$$\n$$\nW_{diss} = \\pi \\times 5.4 \\times 10^{-5} \\,\\mathrm{J}\n$$\n$$\nW_{diss} \\approx 16.9646 \\times 10^{-5} \\,\\mathrm{J} = 1.69646 \\times 10^{-4} \\,\\mathrm{J}\n$$\nRounding the result to four significant figures gives $1.696 \\times 10^{-4}\\,\\mathrm{J}$.",
            "answer": "$$\n\\boxed{1.696 \\times 10^{-4}}\n$$"
        },
        {
            "introduction": "Theoretical models, such as the exponential and viscoelastic models explored previously, are powerful tools for understanding tissue mechanics, but their practical utility hinges on our ability to connect them to experimental reality. This involves fitting the model's parameters to measured stress-strain data. This computational practice  guides you through the essential steps of nonlinear least squares regression to estimate the parameters of an exponential model from a set of data points. Crucially, it also introduces the method for calculating confidence intervals for these parameters, a vital step in assessing the reliability of your model and its predictions.",
            "id": "4197305",
            "problem": "Consider uniaxial extension measurements of the passive stress–strain response of a muscle–fascia specimen. Let engineering strain be denoted by $\\varepsilon$ (dimensionless) and Cauchy stress be denoted by $\\sigma$ (in kilopascals, kPa). A widely used phenomenological model for passive stiffness is the exponential form\n$$\n\\sigma(\\varepsilon; A, B) = A\\left(e^{B \\varepsilon} - 1\\right),\n$$\nwhere $A$ (in kPa) scales the stress magnitude and $B$ (dimensionless) controls the nonlinearity. Assume measurement errors in stress are independent and identically distributed (i.i.d.) Gaussian with zero mean and constant variance across strains. Starting from first principles of least squares, construct a procedure to estimate $A$ and $B$ by minimizing the sum of squared residuals between measured stresses and model predictions and then assess $95\\%$ confidence intervals for both $A$ and $B$ based on a local linearization of the model at the optimum.\n\nYour program must implement the following steps using only the provided data for each test case:\n1. Formulate the nonlinear least squares objective over the parameter vector $(A, B)$.\n2. Compute the parameter estimates $(\\hat{A}, \\hat{B})$ via a suitable iterative method that uses the model and its sensitivity to parameters.\n3. Using the Jacobian of the residuals evaluated at $(\\hat{A}, \\hat{B})$, compute an estimate of the parameter covariance matrix under the i.i.d. Gaussian error assumption.\n4. Report the $95\\%$ confidence intervals (defined as estimate $\\pm$ critical value times standard error) for both $\\hat{A}$ and $\\hat{B}$, where the critical value is taken from the Student's $t$ distribution with degrees of freedom equal to the number of data points minus the number of parameters.\n\nAll answers for $A$ and its confidence interval bounds must be expressed in kPa. All answers for $B$ and its confidence interval bounds must be expressed as dimensionless numbers.\n\nUse the following test suite of measured strain–stress pairs, provided as lists of $(\\varepsilon_i, \\sigma_i)$ with stress in kPa and strain dimensionless:\n\nTest case 1 (muscle-like specimen, moderate nonlinearity):\n- Data points:\n  - $(0.00, 0.000000)$\n  - $(0.02, 2.356833)$\n  - $(0.04, 6.101896)$\n  - $(0.06, 9.465426)$\n  - $(0.08, 15.206491)$\n  - $(0.10, 20.519382)$\n  - $(0.12, 27.841403)$\n  - $(0.15, 42.080269)$\n  - $(0.18, 59.995770)$\n  - $(0.22, 96.700162)$\n  - $(0.26, 149.264857)$\n  - $(0.30, 227.826443)$\n\nTest case 2 (fascia-like specimen, higher nonlinearity):\n- Data points:\n  - $(0.00, 0.000000)$\n  - $(0.01, 3.344346)$\n  - $(0.02, 9.066586)$\n  - $(0.03, 13.420137)$\n  - $(0.04, 22.288664)$\n  - $(0.05, 27.692062)$\n  - $(0.06, 39.593606)$\n  - $(0.08, 63.313900)$\n  - $(0.10, 102.792940)$\n  - $(0.13, 185.627600)$\n  - $(0.16, 339.285400)$\n  - $(0.20, 706.964680)$\n\nTest case 3 (edge case: low strain range and small sample size):\n- Data points:\n  - $(0.00, 0.000000)$\n  - $(0.01, 0.524692)$\n  - $(0.02, 0.999975)$\n  - $(0.03, 1.617739)$\n  - $(0.05, 2.738870)$\n\nYour program should produce a single line of output containing, for each test case in order, a list of six floating point values $[\\hat{A}, \\hat{B}, A_{\\text{low}}, A_{\\text{high}}, B_{\\text{low}}, B_{\\text{high}}]$, where $A_{\\text{low}}$ and $A_{\\text{high}}$ are the lower and upper bounds of the $95\\%$ confidence interval for $A$ (in kPa), and $B_{\\text{low}}$ and $B_{\\text{high}}$ are the corresponding bounds for $B$ (dimensionless). Aggregate the three test case results into a single comma-separated list enclosed in square brackets. For example, the final output format must be exactly\n$$\n[\\,[\\hat{A}_1,\\hat{B}_1,A_{\\text{low},1},A_{\\text{high},1},B_{\\text{low},1},B_{\\text{high},1}],\\,[\\hat{A}_2,\\hat{B}_2,A_{\\text{low},2},A_{\\text{high},2},B_{\\text{low},2},B_{\\text{high},2}],\\,[\\hat{A}_3,\\hat{B}_3,A_{\\text{low},3},A_{\\text{high},3},B_{\\text{low},3},B_{\\text{high},3}]\\,]\n$$\nwhere each numeric entry is a floating point number. The printed line must contain no additional text.",
            "solution": "The user's request is a valid problem in numerical optimization and statistical inference, specifically nonlinear regression analysis applied to a biomechanics model. The problem is scientifically grounded, well-posed, objective, and contains all necessary information for a unique solution.\n\n### Principle-Based Design\n\nThe task is to estimate the parameters $A$ and $B$ of the exponential stress-strain model $\\sigma(\\varepsilon) = A(e^{B\\varepsilon} - 1)$ and to determine their $95\\%$ confidence intervals, given experimental data. This is a classic nonlinear least squares (NLLS) problem. The solution is structured according to the following principles.\n\n#### 1. Nonlinear Least Squares (NLLS) Formulation\n\nThe fundamental principle is to find the parameter values $(\\hat{A}, \\hat{B})$ that best fit the model to the measured data $(\\varepsilon_i, \\sigma_i)$, where $i=1, \\dots, n$. \"Best fit\" is defined in the sense of least squares, which assumes that the measurement errors are independent and identically distributed (i.i.d.) Gaussian random variables with zero mean. The goal is to minimize the sum of the squared residuals (RSS), which is the sum of the squared differences between the observed stresses $\\sigma_i$ and the stresses predicted by the model $\\sigma(\\varepsilon_i; A, B)$.\n\nThe objective function to minimize is the RSS, denoted by $S(A, B)$:\n$$\nS(A, B) = \\sum_{i=1}^{n} \\left[ \\sigma_i - \\sigma(\\varepsilon_i; A, B) \\right]^2 = \\sum_{i=1}^{n} r_i(A, B)^2\n$$\nwhere $r_i(A, B) = \\sigma_i - A(e^{B\\varepsilon_i} - 1)$ is the $i$-th residual. Let $\\mathbf{p} = [A, B]^T$ be the vector of parameters. The objective is to find $\\hat{\\mathbf{p}} = \\arg\\min_{\\mathbf{p}} S(\\mathbf{p})$.\n\n#### 2. Iterative Optimization Algorithm\n\nUnlike linear least squares, NLLS problems generally do not have a closed-form solution. They must be solved iteratively. The Gauss-Newton algorithm and its variants (e.g., Levenberg-Marquardt) are standard methods. These algorithms start with an initial guess $\\mathbf{p}_0$ and iteratively generate a sequence of parameter estimates $\\mathbf{p}_k$ that converge to the minimum $\\hat{\\mathbf{p}}$.\n\nThe core of these methods is a local linear approximation of the model. At each iteration $k$, the update step $\\Delta\\mathbf{p}$ is found by solving a linear least squares problem. The Gauss-Newton update rule is given by:\n$$\n\\mathbf{p}_{k+1} = \\mathbf{p}_k + \\Delta\\mathbf{p}_k \\quad \\text{where} \\quad (\\mathbf{J}_k^T \\mathbf{J}_k) \\Delta\\mathbf{p}_k = \\mathbf{J}_k^T \\mathbf{r}_k\n$$\nHere, $\\mathbf{r}_k$ is the vector of residuals evaluated at $\\mathbf{p}_k$, and $\\mathbf{J}_k$ is the Jacobian matrix of the *model function* with respect to the parameters, also evaluated at $\\mathbf{p}_k$. The elements of the Jacobian are the model's sensitivities to parameter changes:\n$$\n\\mathbf{J}_{ij} = \\frac{\\partial \\sigma(\\varepsilon_i; \\mathbf{p})}{\\partial p_j}\n$$\nFor our model, the two columns of the Jacobian matrix $\\mathbf{J}$ are:\n$$\n\\frac{\\partial \\sigma}{\\partial A} = e^{B\\varepsilon_i} - 1\n$$\n$$\n\\frac{\\partial \\sigma}{\\partial B} = A \\varepsilon_i e^{B\\varepsilon_i}\n$$\nThe implementation will utilize the `scipy.optimize.least_squares` function, which employs a robust trust-region reflective algorithm, a sophisticated variant of the Gauss-Newton approach. We will supply the analytic Jacobian to ensure accuracy and efficiency.\n\n#### 3. Confidence Interval Estimation\n\nAfter finding the optimal parameters $\\hat{\\mathbf{p}} = [\\hat{A}, \\hat{B}]^T$, we assess the uncertainty of these estimates by constructing confidence intervals. This is based on the statistical properties of the least squares estimator under the assumption of i.i.d. Gaussian errors.\n\nThe procedure relies on linearizing the model around the optimal solution $\\hat{\\mathbf{p}}$. In this linearized regime, the estimator $\\hat{\\mathbf{p}}$ is approximately normally distributed. The covariance matrix of the parameter estimates, $\\mathbf{C}$, quantifies their uncertainty and correlation. It is estimated by:\n$$\n\\mathbf{C} = s^2 (\\mathbf{J}^T \\mathbf{J})^{-1}\n$$\nwhere:\n- $\\mathbf{J}$ is the Jacobian matrix of the model, evaluated at the optimal parameters $\\hat{\\mathbf{p}}$. Note that some libraries work with the Jacobian of the residuals, $\\mathbf{J}_r = -\\mathbf{J}$. Since $\\mathbf{J}_r^T\\mathbf{J}_r = \\mathbf{J}^T\\mathbf{J}$, the formula remains the same.\n- $s^2$ is the unbiased estimate of the error variance $\\sigma_{\\text{error}}^2$. It is calculated from the minimum sum of squared residuals, $S(\\hat{\\mathbf{p}})$:\n  $$\n  s^2 = \\frac{S(\\hat{\\mathbf{p}})}{n-p}\n  $$\n  where $n$ is the number of data points and $p$ is the number of parameters (here, $p=2$). The term $n-p$ represents the degrees of freedom.\n\nThe diagonal elements of the covariance matrix, $C_{11}$ and $C_{22}$, are the estimated variances of $\\hat{A}$ and $\\hat{B}$, respectively. The standard error (SE) for each parameter is the square root of its variance:\n$$\n\\text{SE}(\\hat{A}) = \\sqrt{C_{11}} \\quad \\text{and} \\quad \\text{SE}(\\hat{B}) = \\sqrt{C_{22}}\n$$\n\nA $(1-\\alpha) \\times 100\\%$ confidence interval for a parameter estimate $\\hat{p}_j$ is constructed as:\n$$\n\\left[ \\hat{p}_j - t_{1-\\alpha/2, n-p} \\cdot \\text{SE}(\\hat{p}_j), \\quad \\hat{p}_j + t_{1-\\alpha/2, n-p} \\cdot \\text{SE}(\\hat{p}_j) \\right]\n$$\nHere, $t_{1-\\alpha/2, n-p}$ is the critical value from the Student's $t$-distribution for a confidence level of $1-\\alpha$ (for $95\\%$ confidence, $\\alpha=0.05$) and $n-p$ degrees of freedom. The use of the $t$-distribution is appropriate because the error variance $\\sigma_{\\text{error}}^2$ was estimated from the data.\n\nThe implementation will execute these steps for each test case to compute the parameter estimates and their corresponding $95\\%$ confidence intervals.",
            "answer": "```python\nimport numpy as np\nfrom scipy.optimize import least_squares\nfrom scipy.stats import t\n\ndef solve():\n    \"\"\"\n    Solves for the parameters and confidence intervals for a series of\n    nonlinear regression problems based on a biomechanical model.\n    \"\"\"\n    test_cases = [\n        # Test case 1\n        [\n            (0.00, 0.000000), (0.02, 2.356833), (0.04, 6.101896),\n            (0.06, 9.465426), (0.08, 15.206491), (0.10, 20.519382),\n            (0.12, 27.841403), (0.15, 42.080269), (0.18, 59.995770),\n            (0.22, 96.700162), (0.26, 149.264857), (0.30, 227.826443)\n        ],\n        # Test case 2\n        [\n            (0.00, 0.000000), (0.01, 3.344346), (0.02, 9.066586),\n            (0.03, 13.420137), (0.04, 22.288664), (0.05, 27.692062),\n            (0.06, 39.593606), (0.08, 63.313900), (0.10, 102.792940),\n            (0.13, 185.627600), (0.16, 339.285400), (0.20, 706.964680)\n        ],\n        # Test case 3\n        [\n            (0.00, 0.000000), (0.01, 0.524692), (0.02, 0.999975),\n            (0.03, 1.617739), (0.05, 2.738870)\n        ]\n    ]\n\n    all_results = []\n    for case_data in test_cases:\n        data_points = np.array(case_data, dtype=float)\n        epsilon = data_points[:, 0]\n        sigma_obs = data_points[:, 1]\n\n        def model(params, eps):\n            A, B = params\n            return A * (np.exp(B * eps) - 1)\n\n        def residuals(params, eps, sig):\n            return sig - model(params, eps)\n\n        def jacobian_residuals(params, eps, sig):\n            A, B = params\n            jac = np.empty((len(eps), 2), dtype=float)\n            exp_term = np.exp(B * eps)\n            jac[:, 0] = -(exp_term - 1)\n            jac[:, 1] = -A * eps * exp_term\n            return jac\n        \n        # Initial guess for parameters [A, B]\n        # A simple, fixed guess is often sufficient for a robust solver.\n        # Bounds ensure physically plausible (non-negative) parameters.\n        p0 = [10.0, 10.0]\n        bounds = ([0, 0], [np.inf, np.inf])\n\n        # Perform nonlinear least squares optimization\n        res = least_squares(\n            residuals, \n            p0, \n            jac=jacobian_residuals, \n            args=(epsilon, sigma_obs),\n            method='trf',\n            bounds=bounds\n        )\n        A_hat, B_hat = res.x\n        \n        # Calculate confidence intervals\n        n = len(epsilon)  # number of data points\n        p = len(p0)       # number of parameters\n\n        dof = n - p # degrees of freedom\n        \n        # Sum of squared residuals at the optimum\n        S_min = np.sum(res.fun**2)\n        \n        # Estimate of the error variance\n        s2 = S_min / dof\n        \n        # Jacobian of residuals evaluated at the solution\n        Jr = res.jac\n        \n        A_low, A_high, B_low, B_high = (np.nan,) * 4\n        try:\n            # Check for singularity/ill-conditioning\n            if np.linalg.cond(Jr.T @ Jr) < 1e15:\n                # Parameter covariance matrix\n                cov_matrix = s2 * np.linalg.inv(Jr.T @ Jr)\n                \n                # Standard errors of parameters\n                se = np.sqrt(np.diag(cov_matrix))\n                se_A, se_B = se\n\n                # Critical value from Student's t-distribution for 95% CI\n                alpha = 0.05\n                t_crit = t.ppf(1 - alpha / 2, df=dof)\n\n                # Confidence intervals\n                A_low = A_hat - t_crit * se_A\n                A_high = A_hat + t_crit * se_A\n                B_low = B_hat - t_crit * se_B\n                B_high = B_hat + t_crit * se_B\n        except (np.linalg.LinAlgError, ValueError):\n            # If matrix is singular or sqrt(negative) (numerical artifact),\n            # CIs cannot be computed. np.nan will be used.\n            pass\n\n        case_results = [A_hat, B_hat, A_low, A_high, B_low, B_high]\n        all_results.append(case_results)\n\n    # Format the final output string exactly as specified\n    # The format requires a list of lists, with no spaces.\n    outer_list_str = []\n    for res_list in all_results:\n        # Use str() which is sufficient for float representation\n        inner_list_str = f\"[{','.join(map(str, res_list))}]\"\n        outer_list_str.append(inner_list_str)\n    \n    final_output_str = f\"[{','.join(outer_list_str)}]\"\n    print(final_output_str)\n\nsolve()\n```"
        }
    ]
}