{
    "hands_on_practices": [
        {
            "introduction": "The transformation of a neural command into a biochemically active state within a muscle is a complex process. To make this tractable, biomechanists often rely on phenomenological models, and the first-order linear differential equation is a cornerstone of this approach. This first practice challenges you to derive the classic step response of muscle activation from this fundamental equation . Mastering this derivation provides a deep understanding of the activation time constant, $\\tau$, and how it governs the speed of force development, conceptually separating it from the pure time lag of the electromechanical delay.",
            "id": "4193492",
            "problem": "A skeletal muscle’s activation state is modeled as a dimensionless variable $a(t)$, with $0 \\leq a(t) \\leq 1$, representing the fraction of available cross-bridge binding sites effectively engaged. Empirical and biophysical considerations (for example, rate-limited calcium binding and deactivation kinetics) motivate a first-order activation dynamics model in which the rate of change of $a(t)$ is proportional to the difference between the neural drive $u(t)$ (dimensionless, with $0 \\leq u(t) \\leq 1$) and the current activation $a(t)$. This leads to the ordinary differential equation\n$$\\frac{d a(t)}{d t} = \\frac{u(t) - a(t)}{\\tau}, \\quad t \\geq 0,$$\nwhere $\\tau > 0$ is a constant time scale parameter. Suppose the initial activation is $a(0) = a_0$, and the neural drive is held constant for $t \\geq 0$ as $u(t) = u_0$, with $0 \\leq u_0 \\leq 1$. Assume that the electromechanical delay (EMD) is a separate phenomenon that affects the onset of force generation relative to activation or electromyography (EMG) onset, and does not alter the state equation above for $a(t)$.\n\nStarting from the given model and the definitions of the variables, derive the closed-form expression for the time course $a(t)$ for $t \\geq 0$. In your derivation, use only standard methods for solving linear first-order ordinary differential equations and fundamental definitions (for example, the definition of a time constant as the characteristic time of exponential relaxation toward steady state in a first-order system), and explicitly state the physical meaning of the parameters $a_0$ and $\\tau$ in this context, clarifying how $\\tau$ differs conceptually from the electromechanical delay. \n\nProvide your final expression for $a(t)$ in terms of $a_0$, $u_0$, $t$, and $\\tau$. Express the final answer as a single closed-form analytic expression. No rounding is required, and no units should be included in the final expression.",
            "solution": "The problem provides a first-order ordinary differential equation (ODE) modeling the activation dynamics of a skeletal muscle. The task is to solve this ODE for a specific input condition and interpret the parameters involved.\n\nFirst, the validity of the problem statement is examined.\n\nThe provided model is:\n$$\n\\frac{d a(t)}{d t} = \\frac{u(t) - a(t)}{\\tau}, \\quad t \\geq 0\n$$\nwhere $a(t)$ is the dimensionless activation state ($0 \\leq a(t) \\leq 1$), $u(t)$ is the dimensionless neural drive ($0 \\leq u(t) \\leq 1$), and $\\tau$ is a positive time constant ($\\tau > 0$). The initial condition is given as $a(0) = a_0$. The neural drive is specified to be a constant step input, $u(t) = u_0$ for $t \\geq 0$.\n\nThis problem is scientifically grounded, as this first-order linear model is a standard and widely accepted representation of muscle activation dynamics in the field of biomechanics, often attributed to Zajac (1989). The problem is well-posed, constituting a standard initial value problem for a linear first-order ODE with a constant forcing term, which guarantees a unique solution. The language is objective and the setup is complete and consistent. Therefore, the problem is valid, and we may proceed with the solution.\n\nWith the constant neural drive $u(t) = u_0$, the ODE becomes:\n$$\n\\frac{d a(t)}{d t} = \\frac{u_0 - a(t)}{\\tau}\n$$\nThis equation is a linear first-order ODE. It can be rewritten in the standard form $\\frac{da(t)}{dt} + P(t)a(t) = Q(t)$:\n$$\n\\frac{d a(t)}{d t} + \\frac{1}{\\tau} a(t) = \\frac{u_0}{\\tau}\n$$\nThis equation is separable, which provides a direct method for solution. We separate the variables $a$ and $t$:\n$$\n\\frac{da}{u_0 - a} = \\frac{dt}{\\tau}\n$$\nWe integrate both sides of the equation. The left side is integrated with respect to $a$ and the right side with respect to $t$:\n$$\n\\int \\frac{1}{u_0 - a} da = \\int \\frac{1}{\\tau} dt\n$$\nPerforming the integration yields:\n$$\n-\\ln|u_0 - a| = \\frac{t}{\\tau} + C\n$$\nwhere $C$ is the constant of integration. We can solve for $a(t)$:\n$$\n\\ln|u_0 - a| = -\\frac{t}{\\tau} - C\n$$\n$$\n|u_0 - a| = \\exp\\left(-\\frac{t}{\\tau} - C\\right) = \\exp(-C) \\exp\\left(-\\frac{t}{\\tau}\\right)\n$$\nLet $K = \\pm \\exp(-C)$ be a new constant. This allows us to remove the absolute value:\n$$\nu_0 - a(t) = K \\exp\\left(-\\frac{t}{\\tau}\\right)\n$$\n$$\na(t) = u_0 - K \\exp\\left(-\\frac{t}{\\tau}\\right)\n$$\nNow, we apply the initial condition $a(0) = a_0$ to determine the constant $K$:\n$$\na(0) = u_0 - K \\exp\\left(-\\frac{0}{\\tau}\\right)\n$$\n$$\na_0 = u_0 - K \\exp(0) = u_0 - K\n$$\nSolving for $K$ gives:\n$$\nK = u_0 - a_0\n$$\nSubstituting this expression for $K$ back into the general solution for $a(t)$, we obtain the final closed-form expression:\n$$\na(t) = u_0 - (u_0 - a_0) \\exp\\left(-\\frac{t}{\\tau}\\right)\n$$\nThis expression can also be written by regrouping the terms:\n$$\na(t) = u_0(1 - \\exp\\left(-\\frac{t}{\\tau}\\right)) + a_0 \\exp\\left(-\\frac{t}{\\tau}\\right)\n$$\nThis equation describes the time course of muscle activation $a(t)$ starting from an initial state $a_0$ and moving toward a new steady-state level $u_0$ in response to a constant neural drive.\n\nNext, we address the physical meaning of the parameters $a_0$ and $\\tau$.\nThe parameter $a_0$ is, by definition, the value of the activation state at time $t=0$, i.e., $a_0 = a(0)$. It represents the initial fraction of engaged cross-bridge binding sites at the moment the new, constant neural drive $u_0$ is applied. Its value is between $0$ and $1$.\n\nThe parameter $\\tau$ is the time constant of the first-order system. It characterizes the rate at which the activation state $a(t)$ approaches its final steady-state value, $u_0$. To see this, consider the difference between the final activation $u_0$ and the current activation $a(t)$:\n$$\nu_0 - a(t) = (u_0 - a_0) \\exp\\left(-\\frac{t}{\\tau}\\right)\n$$\nAt time $t = \\tau$, this difference becomes:\n$$\nu_0 - a(\\tau) = (u_0 - a_0) \\exp(-1) \\approx 0.368 (u_0 - a_0)\n$$\nThis means that after one time constant, $\\tau$, the gap between the current activation and the final activation has decayed to approximately $36.8\\%$ of the initial gap. Equivalently, the system has completed $1 - \\exp(-1) \\approx 0.632$ (or $63.2\\%$) of the total change from its initial value $a_0$ to its target value $u_0$. Therefore, $\\tau$ quantifies the intrinsic speed of the biochemical processes (like calcium release, binding, and reuptake) governing the build-up or decay of the activation state. A larger $\\tau$ signifies a slower, more sluggish activation response.\n\nFinally, we clarify how $\\tau$ differs conceptually from the electromechanical delay (EMD).\nThe activation time constant, $\\tau$, is a parameter that defines the *shape* of the exponential response curve of the internal state variable $a(t)$. It describes the continuous, rate-limited process of cross-bridge formation in response to a neural signal. The change in $a(t)$ begins at $t=0$ and evolves according to the `exp` term governed by $\\tau$.\nThe electromechanical delay (EMD), in contrast, is fundamentally a time *latency* or *lag*. It represents the finite time that elapses between the onset of the muscle's electrical activity (myoelectric signal, related to $u(t)$) and the onset of measurable external force production. This delay is not captured by the ODE for $a(t)$ itself but is a consequence of several serial processes, including: ($1$) propagation of the action potential along the sarcolemma and t-tubules, ($2$) release of calcium ions from the sarcoplasmic reticulum and their diffusion to troponin (excitation-contraction coupling), and, critically, ($3$) the stretching of the series elastic component (SEC) of the muscle-tendon unit. The contractile elements must first take up the slack in the tendon before any force is transmitted to the skeleton.\nIn summary, $\\tau$ describes the *rate* of change of the internal activation state, and governs the shape of the rise/fall of $a(t)$. EMD is a pure time *delay* before the mechanical effects of this activation (i.e., force) become externally apparent. They are distinct physical phenomena.",
            "answer": "$$\n\\boxed{u_0 + (a_0 - u_0) \\exp\\left(-\\frac{t}{\\tau}\\right)}\n$$"
        },
        {
            "introduction": "The electromechanical delay (EMD) is not a single event, but a cascade of processes. After the muscle fibers are activated, the force they generate must be transmitted through compliant tissues before it can be measured externally. This exercise isolates a critical component of this cascade: the mechanical delay caused by stretching the tendon . By modeling the tendon as a viscoelastic Kelvin-Voigt element, you will derive an analytical expression for the time it takes to take up tendon slack, providing a tangible link between tissue material properties ($K$ and $\\eta$) and a key functional parameter of neuromuscular performance.",
            "id": "4193521",
            "problem": "A muscle–tendon unit transmits force to a rigid bone. The tendon is modeled as a linear Kelvin–Voigt element consisting of a linear elastic spring of stiffness $K$ in parallel with a linear viscous dashpot of viscosity $\\eta$. The muscle generates a step increase in active force $F_{m}(t)$ from zero to a constant value $F_{0}$ at time $t=0$, i.e., $F_{m}(t)=F_{0}$ for $t \\geq 0$ and $F_{m}(t)=0$ for $t<0$. The tendon has an initial slack extension $x_{s}>0$, meaning that the bone only experiences nonzero transmitted force after the tendon extension $x(t)$ reaches $x_{s}$. The tendon is assumed one-dimensional, massless, and its distal end is attached to the rigid bone so that any extension is taken entirely by the tendon.\n\nStarting from fundamental constitutive definitions and balance laws appropriate for one-dimensional viscoelastic elements, derive an analytical expression for the mechanical delay $t_{d}$ attributable solely to tendon stretch under the step in muscle force, defined as the time at which the tendon extension first satisfies $x(t_{d})=x_{s}$. Assume $F_{0}>K x_{s}$ so that the slack can be fully taken up. Express your final analytical expression for $t_{d}$ in seconds. No numerical evaluation is required.",
            "solution": "The provided problem is scientifically grounded, well-posed, and objective. It describes a standard scenario in biomechanics using a simplified but valid physical model (the Kelvin-Voigt model for a viscoelastic tendon). The governing equations, initial conditions, and the objective are clearly defined. The constraint $F_{0} > K x_{s}$ ensures a meaningful physical solution exists, confirming that the tendon extension will indeed reach the slack length $x_s$. We may therefore proceed with the derivation.\n\nThe tendon is modeled as a Kelvin-Voigt element, which consists of a linear elastic spring with stiffness $K$ and a linear viscous dashpot with viscosity $\\eta$ arranged in parallel. For elements in parallel, the total force transmitted by the element is the sum of the forces in each component, and each component undergoes the same displacement (extension), $x(t)$.\n\nThe force in the spring, $F_{K}$, is given by Hooke's Law:\n$$ F_{K}(t) = K x(t) $$\nThe force in the dashpot, $F_{\\eta}$, is proportional to the rate of extension:\n$$ F_{\\eta}(t) = \\eta \\frac{dx(t)}{dt} = \\eta \\dot{x}(t) $$\nThe total force transmitted by the tendon, $F_{tendon}(t)$, is the sum of these two forces:\n$$ F_{tendon}(t) = F_{K}(t) + F_{\\eta}(t) = K x(t) + \\eta \\dot{x}(t) $$\nAccording to Newton's laws and the problem statement, this total tendon force must balance the active force generated by the muscle, $F_{m}(t)$. This gives the governing differential equation for the tendon extension $x(t)$:\n$$ \\eta \\frac{dx(t)}{dt} + K x(t) = F_{m}(t) $$\nThe muscle force is given as a step function: $F_{m}(t) = 0$ for $t < 0$ and $F_{m}(t) = F_{0}$ for $t \\geq 0$. We are interested in the system's response for $t \\geq 0$. Before the force is applied ($t < 0$), the system is at rest with no extension, so the initial condition is $x(0) = 0$. The viscosity of the dashpot prevents an instantaneous change in extension, so $x(0) = 0$ holds at the moment the force is applied.\n\nFor $t \\geq 0$, the governing equation becomes a first-order, linear, non-homogeneous ordinary differential equation with constant coefficients:\n$$ \\eta \\frac{dx}{dt} + K x = F_{0} $$\nThe general solution to this equation is the sum of the homogeneous solution, $x_{h}(t)$, and a particular solution, $x_{p}(t)$.\n\nFirst, we solve the homogeneous equation:\n$$ \\eta \\frac{dx_{h}}{dt} + K x_{h} = 0 $$\nRearranging and integrating yields:\n$$ \\frac{dx_{h}}{x_{h}} = -\\frac{K}{\\eta} dt \\implies \\int \\frac{1}{x_{h}} dx_{h} = \\int -\\frac{K}{\\eta} dt $$\n$$ \\ln|x_{h}| = -\\frac{K}{\\eta}t + C_{1} $$\n$$ x_{h}(t) = A \\exp\\left(-\\frac{K}{\\eta}t\\right) $$\nwhere $A$ is an arbitrary constant of integration.\n\nNext, we find a particular solution, $x_{p}(t)$. Since the non-homogeneous term $F_{0}$ is a constant, we assume a constant particular solution of the form $x_{p}(t) = C$. Substituting this into the differential equation:\n$$ \\eta \\frac{d(C)}{dt} + K C = F_{0} $$\n$$ 0 + K C = F_{0} \\implies C = \\frac{F_{0}}{K} $$\nThus, the particular solution is the steady-state extension $x_{p}(t) = \\frac{F_{0}}{K}$.\n\nThe general solution for the extension $x(t)$ is:\n$$ x(t) = x_{h}(t) + x_{p}(t) = A \\exp\\left(-\\frac{K}{\\eta}t\\right) + \\frac{F_{0}}{K} $$\nWe use the initial condition $x(0) = 0$ to determine the constant $A$:\n$$ x(0) = A \\exp(0) + \\frac{F_{0}}{K} = A + \\frac{F_{0}}{K} = 0 $$\n$$ A = -\\frac{F_{0}}{K} $$\nSubstituting the value of $A$ back into the general solution gives the specific solution for the tendon extension as a function of time for $t \\geq 0$:\n$$ x(t) = \\frac{F_{0}}{K} - \\frac{F_{0}}{K} \\exp\\left(-\\frac{K}{\\eta}t\\right) $$\n$$ x(t) = \\frac{F_{0}}{K} \\left(1 - \\exp\\left(-\\frac{K}{\\eta}t\\right)\\right) $$\nThe mechanical delay, $t_{d}$, is defined as the time at which the tendon extension first reaches the slack extension, $x_{s}$. We find $t_{d}$ by setting $x(t_{d}) = x_{s}$:\n$$ x_{s} = \\frac{F_{0}}{K} \\left(1 - \\exp\\left(-\\frac{K}{\\eta}t_{d}\\right)\\right) $$\nWe now solve this equation for $t_{d}$. The condition $F_{0} > K x_{s}$ ensures that $x_{s} < F_{0}/K$, so a real, positive solution for $t_d$ exists.\n$$ \\frac{K x_{s}}{F_{0}} = 1 - \\exp\\left(-\\frac{K}{\\eta}t_{d}\\right) $$\n$$ \\exp\\left(-\\frac{K}{\\eta}t_{d}\\right) = 1 - \\frac{K x_{s}}{F_{0}} $$\n$$ \\exp\\left(-\\frac{K}{\\eta}t_{d}\\right) = \\frac{F_{0} - K x_{s}}{F_{0}} $$\nTaking the natural logarithm of both sides:\n$$ -\\frac{K}{\\eta}t_{d} = \\ln\\left(\\frac{F_{0} - K x_{s}}{F_{0}}\\right) $$\nTo solve for $t_{d}$, we multiply by $-\\frac{\\eta}{K}$:\n$$ t_{d} = -\\frac{\\eta}{K} \\ln\\left(\\frac{F_{0} - K x_{s}}{F_{0}}\\right) $$\nUsing the logarithmic identity $-\\ln(a/b) = \\ln(b/a)$, we can write the expression in a more conventional form:\n$$ t_{d} = \\frac{\\eta}{K} \\ln\\left(\\frac{F_{0}}{F_{0} - K x_{s}}\\right) $$\nThis is the final analytical expression for the mechanical delay $t_{d}$. The ratio $\\eta/K$ has units of time, and the argument of the logarithm is dimensionless, so the expression is dimensionally consistent.",
            "answer": "$$\\boxed{\\frac{\\eta}{K} \\ln\\left(\\frac{F_{0}}{F_{0} - K x_{s}}\\right)}$$"
        },
        {
            "introduction": "Theoretical models provide the framework, but biomechanics is an empirical science. In a real-world setting, parameters like the electromechanical delay are not given; they must be estimated from noisy experimental data such as electromyography (EMG) and force recordings. This advanced computational practice moves from analytical derivation to system identification . You will implement a Maximum A Posteriori (MAP) estimator to find the most probable EMD, and further explore how to make your estimation robust to inevitable data outliers by contrasting a standard Gaussian noise model with a heavy-tailed Student's $t$ model, a crucial skill for modern research.",
            "id": "4193629",
            "problem": "You are given a discrete-time model for the transformation from electromyography (EMG) to muscle force that captures muscle activation dynamics and electromechanical delay. Let the EMG input be a known nonnegative sequence $x[n]$ sampled at interval $dt$ seconds, and let the force output be $y[n]$ measured at the same sampling interval. Assume a linear time-invariant activation dynamics modeled by an exponential impulse response $h[n]$ with time constant $T_a$, and an unknown electromechanical delay $\\tau$ seconds that acts as a pure time shift applied to the EMG input before activation dynamics. The observable relationship is modeled as\n$$\ny[n] = k \\,\\big( (x[n - \\tau/dt] \\star h[n]) \\big) + \\varepsilon[n],\n$$\nwhere $k$ is an unknown scalar gain, $\\star$ denotes discrete-time convolution, and $\\varepsilon[n]$ is zero-mean noise with known variance $\\sigma^2$. You should assume a Gaussian prior on the electromechanical delay parameter $\\tau$ with mean $\\mu_\\tau$ and variance $\\sigma_\\tau^2$, truncated to the interval $[\\tau_{\\min}, \\tau_{\\max}]$. The activation impulse response is specified by\n$$\nh[n] = \\exp\\!\\left(-\\frac{n \\, dt}{T_a}\\right), \\quad n \\ge 0,\n$$\nused within a finite support up to $5$ time constants. The model assumes the delay $\\tau$ aligns to the discrete sampling grid (i.e., a multiple of $dt$), and convolution results are truncated to the observation length $N$.\n\nStarting from the definitions of discrete-time convolution and Bayes' rule, and using the known Gaussian noise variance $\\sigma^2$, derive the maximum a posteriori (MAP) estimator for the electromechanical delay $\\tau$. Treat the scalar gain $k$ as a nuisance parameter and eliminate it by profiling the likelihood for each candidate $\\tau$. Then, analyze robustness to outliers by repeating the MAP estimation under a heavy-tailed noise model that assumes independent and identically distributed Student’s $t$-distributed residuals with degrees of freedom $\\nu$ and scale parameter satisfying the same $\\sigma^2$ interpretation (i.e., the variance used in the Gaussian case serves as the scale parameter in the Student’s $t$ likelihood). For the Student’s $t$ model, optimize over $k$ numerically for each candidate $\\tau$.\n\nYour program must perform the following steps:\n- For a candidate set of delays $\\{\\tau_i\\}$ on a uniform grid over $[\\tau_{\\min}, \\tau_{\\max}]$ in steps of $dt$, compute the log-posterior under the Gaussian noise model by combining the Gaussian log-likelihood with the Gaussian prior on $\\tau$, and select the $\\tau$ that maximizes the posterior (the MAP estimate). Express $\\tau$ in seconds.\n- For the same candidate set $\\{\\tau_i\\}$, compute the log-posterior under the Student’s $t$ noise model with degrees of freedom $\\nu$, by numerically maximizing the likelihood over $k$ for each $\\tau$ (e.g., via scalar optimization of the negative log-likelihood), adding the same Gaussian prior on $\\tau$, and selecting the MAP estimate. Express $\\tau$ in seconds.\n- Discuss, in your solution, why the Student’s $t$ model is more robust to outliers than the Gaussian model.\n\nAll physical quantities must use coherent units. Specifically, express all electromechanical delay estimates in seconds, rounded to $6$ decimal places.\n\nTest Suite:\n- Case $1$ (nominal noise): $N = 1000$, $dt = 0.001 \\,\\text{s}$, $T_a = 0.040 \\,\\text{s}$, $\\tau_{\\min} = 0.010 \\,\\text{s}$, $\\tau_{\\max} = 0.120 \\,\\text{s}$, $\\mu_\\tau = 0.080 \\,\\text{s}$, $\\sigma_\\tau = 0.020 \\,\\text{s}$, $\\tau_{\\text{true}} = 0.050 \\,\\text{s}$, $k_{\\text{true}} = 2.0$, $\\sigma^2 = 0.0025$, EMG input $x[n]$ constructed as a sum of three Gaussian pulses centered at times $t = 0.200 \\,\\text{s}$, $t = 0.500 \\,\\text{s}$, and $t = 0.750 \\,\\text{s}$, with amplitudes $1.0$, $0.8$, and $1.2$, and widths $0.020 \\,\\text{s}$, $0.030 \\,\\text{s}$, and $0.015 \\,\\text{s}$ respectively. The force $y[n]$ is generated from the stated model with Gaussian noise of variance $\\sigma^2$ and no outliers. Use Student’s $t$ degrees of freedom $\\nu = 3$.\n- Case $2$ (outliers): Same as Case $1$ but add five outliers to the force sequence $y[n]$ at indices $100$, $250$, $600$, $850$, and $900$, with additive offsets of $\\pm 2.0$ newtons chosen deterministically as $[+2.0, -2.0, +2.0, -2.0, +2.0]$. Use the same $\\nu = 3$.\n- Case $3$ (boundary delay): $N = 1000$, $dt = 0.001 \\,\\text{s}$, $T_a = 0.040 \\,\\text{s}$, $\\tau_{\\min} = 0.010 \\,\\text{s}$, $\\tau_{\\max} = 0.120 \\,\\text{s}$, $\\mu_\\tau = 0.080 \\,\\text{s}$, $\\sigma_\\tau = 0.020 \\,\\text{s}$, $\\tau_{\\text{true}} = 0.012 \\,\\text{s}$, $k_{\\text{true}} = 2.5$, $\\sigma^2 = 0.0025$, EMG input $x[n]$ constructed as a sum of three Gaussian pulses centered at times $t = 0.150 \\,\\text{s}$, $t = 0.420 \\,\\text{s}$, and $t = 0.820 \\,\\text{s}$, with amplitudes $1.1$, $0.9$, and $1.0$, and widths $0.018 \\,\\text{s}$, $0.025 \\,\\text{s}$, and $0.020 \\,\\text{s}$ respectively. The force $y[n]$ is generated from the stated model with Gaussian noise of variance $\\sigma^2$ and no outliers. Use the same $\\nu = 3$.\n\nFinal Output Format:\nYour program should produce a single line of output containing a list of lists. Each inner list corresponds to a test case in order, and contains two floating-point numbers: the Gaussian-MAP delay estimate and the Student’s $t$-MAP delay estimate, both in seconds and rounded to six decimal places. For example, the output format must be\n`[ [\\tau_{\\text{Gaussian,1}}, \\tau_{\\text{Student-}t,1}], [\\tau_{\\text{Gaussian,2}}, \\tau_{\\text{Student-}t,2}], [\\tau_{\\text{Gaussian,3}}, \\tau_{\\text{Student-}t,3}] ]`.",
            "solution": "The user-provided problem is valid as it is scientifically grounded in biomechanics and statistical signal processing, well-posed, objective, and contains all necessary information to derive and implement a solution.\n\n### 1. Theoretical Framework for MAP Estimation\n\nThe problem requires the estimation of an electromechanical delay, $\\tau$, from an observed force signal $y[n]$ and a known electromyography (EMG) input signal $x[n]$. The relationship is modeled as a linear time-invariant system with an unknown gain $k$ and a time shift $\\tau$. The discrete-time model is given by:\n$$\ny[n] = k \\cdot (x_\\tau \\star h)[n] + \\varepsilon[n]\n$$\nwhere $x_\\tau[n] = x[n - \\tau/dt]$ represents the EMG signal shifted by the delay $\\tau$, $h[n]$ is the impulse response of muscle activation dynamics, $\\star$ denotes discrete-time convolution, and $\\varepsilon[n]$ is additive noise. The delay $\\tau$ is assumed to be a discrete multiple of the sampling interval $dt$.\n\nLet the convolved and shifted signal be denoted as $u_\\tau[n] = (x_\\tau \\star h)[n]$. In vector form, the model is $\\mathbf{y} = k \\mathbf{u}_\\tau + \\boldsymbol{\\varepsilon}$.\n\nWe aim to find the maximum a posteriori (MAP) estimate of $\\tau$. According to Bayes' rule, the posterior probability of $\\tau$ given the data $\\mathbf{y}$ is:\n$$\np(\\tau | \\mathbf{y}) \\propto p(\\mathbf{y} | \\tau) p(\\tau)\n$$\nMaximizing the posterior is equivalent to maximizing its logarithm:\n$$\n\\tau_{\\text{MAP}} = \\arg\\max_{\\tau} \\left( \\log p(\\mathbf{y} | \\tau) + \\log p(\\tau) \\right)\n$$\nThe problem specifies a truncated Gaussian prior on $\\tau$ with mean $\\mu_\\tau$ and variance $\\sigma_\\tau^2$ over the interval $[\\tau_{\\min}, \\tau_{\\max}]$. For any candidate delay $\\tau$ within this interval, the log-prior term is:\n$$\n\\log p(\\tau) = -\\frac{(\\tau - \\mu_\\tau)^2}{2\\sigma_\\tau^2} + C_{\\text{prior}}\n$$\nwhere the constant $C_{\\text{prior}}$ can be ignored during optimization.\n\nThe gain $k$ is treated as a nuisance parameter and is eliminated by profiling the likelihood. This involves maximizing the likelihood with respect to $k$ for each fixed $\\tau$, yielding an estimate $\\hat{k}(\\tau)$, and then evaluating the likelihood at this value:\n$$\nL_{\\text{prof}}(\\tau) = p(\\mathbf{y} | \\tau, \\hat{k}(\\tau))\n$$\nThe log-posterior to be maximized over the set of candidate delays $\\{\\tau_i\\}$ is therefore:\n$$\n\\log p(\\tau_i | \\mathbf{y}) \\propto \\log L_{\\text{prof}}(\\tau_i) - \\frac{(\\tau_i - \\mu_\\tau)^2}{2\\sigma_\\tau^2}\n$$\n\n### 2. Gaussian Noise Model\n\nUnder the assumption of i.i.d. Gaussian noise, $\\varepsilon[n] \\sim \\mathcal{N}(0, \\sigma^2)$, the log-likelihood is:\n$$\n\\log p(\\mathbf{y} | \\tau, k) = -\\frac{N}{2}\\log(2\\pi\\sigma^2) - \\frac{1}{2\\sigma^2} \\sum_{n=0}^{N-1} (y[n] - k u_\\tau[n])^2\n$$\nTo find the profile likelihood, we first find $\\hat{k}(\\tau)$ by maximizing this expression with respect to $k$. This is a standard least-squares problem. Setting the derivative with respect to $k$ to zero gives:\n$$\n\\frac{\\partial}{\\partial k} \\log p(\\mathbf{y} | \\tau, k) = \\frac{1}{\\sigma^2} \\sum_{n=0}^{N-1} (y[n] - k u_\\tau[n]) u_\\tau[n] = 0\n$$\nSolving for $k$ yields the maximum likelihood estimate for a given $\\tau$:\n$$\n\\hat{k}(\\tau) = \\frac{\\sum_{n=0}^{N-1} y[n] u_\\tau[n]}{\\sum_{n=0}^{N-1} u_\\tau[n]^2} = \\frac{\\mathbf{y}^T \\mathbf{u}_\\tau}{\\mathbf{u}_\\tau^T \\mathbf{u}_\\tau}\n$$\nSubstituting $\\hat{k}(\\tau)$ back into the log-likelihood gives the profiled log-likelihood. Ignoring constant terms that do not depend on $\\tau$:\n$$\n\\log L_{\\text{prof}}(\\tau) \\propto -\\frac{1}{2\\sigma^2} \\sum_{n=0}^{N-1} (y[n] - \\hat{k}(\\tau) u_\\tau[n])^2 = -\\frac{SSR(\\tau)}{2\\sigma^2}\n$$\nwhere $SSR(\\tau)$ is the sum of squared residuals for delay $\\tau$. The MAP estimate for $\\tau$ under the Gaussian model is thus:\n$$\n\\tau_{\\text{MAP-G}} = \\arg\\max_{\\tau \\in \\{\\tau_i\\}} \\left( -\\frac{SSR(\\tau)}{2\\sigma^2} - \\frac{(\\tau - \\mu_\\tau)^2}{2\\sigma_\\tau^2} \\right)\n$$\n\n### 3. Student's $t$ Noise Model\n\nFor the heavy-tailed noise model, the residuals $\\varepsilon[n]$ are assumed to be i.i.d. following a Student's $t$-distribution with $\\nu$ degrees of freedom and a scale parameter $s$. The problem specifies that the scale parameter relates to the Gaussian noise variance as $s^2 = \\sigma^2$. The probability density function is:\n$$\np(\\varepsilon | \\nu, \\sigma) = \\frac{\\Gamma((\\nu+1)/2)}{\\Gamma(\\nu/2) \\sqrt{\\pi\\nu} \\sigma} \\left(1 + \\frac{1}{\\nu} \\left(\\frac{\\varepsilon}{\\sigma}\\right)^2\\right)^{-(\\nu+1)/2}\n$$\nThe log-likelihood for the entire signal is:\n$$\n\\log p(\\mathbf{y} | \\tau, k) = \\sum_{n=0}^{N-1} \\log p(y[n] - k u_\\tau[n] | \\nu, \\sigma)\n$$\nIgnoring constant terms, this simplifies to:\n$$\n\\log p(\\mathbf{y} | \\tau, k) \\propto -\\frac{\\nu+1}{2} \\sum_{n=0}^{N-1} \\log\\left(1 + \\frac{(y[n] - k u_\\tau[n])^2}{\\nu \\sigma^2}\\right)\n$$\nUnlike the Gaussian case, an analytical solution for $\\hat{k}(\\tau)$ that maximizes this expression does not exist. We must find $\\hat{k}(\\tau)$ for each candidate $\\tau$ via numerical optimization. We seek:\n$$\n\\hat{k}(\\tau) = \\arg\\max_k \\left( -\\sum_{n=0}^{N-1} \\log\\left(1 + \\frac{(y[n] - k u_\\tau[n])^2}{\\nu \\sigma^2}\\right) \\right)\n$$\nOnce $\\hat{k}(\\tau)$ is found numerically for each $\\tau_i$, the profiled log-likelihood $\\log L_{\\text{prof}}(\\tau_i) = \\log p(\\mathbf{y} | \\tau_i, \\hat{k}(\\tau_i))$ is computed. The MAP estimate is then:\n$$\n\\tau_{\\text{MAP-T}} = \\arg\\max_{\\tau \\in \\{\\tau_i\\}} \\left( \\log L_{\\text{prof}}(\\tau) - \\frac{(\\tau - \\mu_\\tau)^2}{2\\sigma_\\tau^2} \\right)\n$$\n\n### 4. Robustness to Outliers\n\nThe Student's $t$-distribution is more robust to outliers than the Gaussian distribution due to its heavier tails. This robustness originates from the penalty it assigns to large errors (residuals).\nThe negative log-likelihood contribution from a single data point with residual $r_n = y[n] - k u_\\tau[n]$ behaves differently for the two models:\n-   For the **Gaussian model**, the penalty is proportional to $r_n^2$. This quadratic penalty grows very rapidly with the magnitude of the residual. An outlier, which creates a large $r_n$, will exert a disproportionately large influence on the total cost function. The optimization process will adjust the model parameters significantly to reduce this single large squared error, potentially at the expense of fitting the rest of the data, thus skewing the estimate.\n-   For the **Student's $t$ model**, the penalty is proportional to $\\log(1 + r_n^2/(\\nu\\sigma^2))$. For large residuals, this penalty grows logarithmically ($\\approx 2 \\log|r_n|$), which is much slower than the quadratic growth of the Gaussian penalty. Consequently, the influence of an outlier is effectively down-weighted. The model fitting is less affected by a few aberrant data points and is instead driven by the structure of the bulk of the data, leading to a more robust parameter estimate. The degrees of freedom, $\\nu$, control the \"heaviness\" of the tails: smaller $\\nu$ values result in heavier tails and greater robustness.\n\n### 5. Algorithmic Implementation\n\nThe estimation process is implemented as follows:\n1.  For each test case, generate the EMG signal $x[n]$ and the corresponding force signal $y[n]$ according to the specified parameters, including noise and any outliers. The muscle activation impulse response $h[n] = \\exp(-n dt/T_a)$ is computed over a finite support of $5 T_a$.\n2.  A uniform grid of candidate delays $\\{\\tau_i\\}$ is created over the range $[\\tau_{\\min}, \\tau_{\\max}]$ with a step size of $dt$.\n3.  For each candidate delay $\\tau_i$:\n    a. The model predictor signal $u_{\\tau_i}[n]$ is computed by shifting $x[n]$ by the corresponding discrete amount and convolving the result with $h[n]$. The convolution output is truncated to the signal length $N$.\n    b. **Gaussian MAP**: The optimal gain $\\hat{k}(\\tau_i)$ is computed analytically. This is used to calculate the sum of squared residuals $SSR(\\tau_i)$ and subsequently the log-posterior for the Gaussian model.\n    c. **Student's $t$ MAP**: The optimal gain $\\hat{k}(\\tau_i)$ is found by numerically minimizing the negative log-likelihood function with respect to $k$. The resulting profiled log-likelihood is combined with the log-prior to obtain the log-posterior for the Student's $t$ model.\n4.  The delays $\\tau_{\\text{MAP-G}}$ and $\\tau_{\\text{MAP-T}}$ are identified as the candidates that maximize their respective log-posterior distributions. The final values are reported in seconds.",
            "answer": "```python\nimport numpy as np\nfrom scipy import optimize\n\ndef generate_signals(N, dt, Ta, tau_true, k_true, sigma_sq, x_params, outliers=None, seed=42):\n    \"\"\"Generates the EMG and Force signals for a given test case.\"\"\"\n    t = np.arange(N) * dt\n    \n    # Generate EMG signal x[n] from a sum of Gaussian pulses\n    x = np.zeros(N)\n    for amp, center, width in x_params:\n        x += amp * np.exp(-((t - center)**2) / (2 * width**2))\n\n    # Generate impulse response h[n]\n    n_h = int(np.ceil(5 * Ta / dt))\n    h_idx = np.arange(n_h)\n    h = np.exp(-h_idx * dt / Ta)\n\n    # Generate the clean force signal y_clean[n]\n    d_true = int(round(tau_true / dt))\n    x_shifted = np.zeros(N)\n    if d_true < N:\n        x_shifted[d_true:] = x[:N - d_true]\n    \n    u_true = np.convolve(x_shifted, h, mode='full')[:N]\n    y_clean = k_true * u_true\n\n    # Generate noisy force signal y[n]\n    rng = np.random.default_rng(seed)\n    noise = rng.normal(0, np.sqrt(sigma_sq), N)\n    y = y_clean + noise\n\n    # Add outliers if specified\n    if outliers:\n        indices, values = outliers\n        y[indices] += values\n        \n    return x, y, h\n\ndef estimate_delay_gaussian(x, y, h, dt, tau_candidates, N, mu_tau, sigma_tau, sigma_sq):\n    \"\"\"MAP estimation of delay tau using the Gaussian noise model.\"\"\"\n    log_posteriors = np.zeros_like(tau_candidates)\n    sigma_tau_sq = sigma_tau**2\n    \n    for i, tau in enumerate(tau_candidates):\n        d = int(round(tau / dt))\n        x_shifted = np.zeros(N)\n        if d < N:\n            x_shifted[d:] = x[:N - d]\n        \n        u_tau = np.convolve(x_shifted, h, mode='full')[:N]\n        \n        u_tau_T_y = np.dot(u_tau, y)\n        u_tau_T_u_tau = np.dot(u_tau, u_tau)\n        \n        if u_tau_T_u_tau < 1e-9:\n             k_hat = 0.0\n        else:\n             k_hat = u_tau_T_y / u_tau_T_u_tau\n            \n        residuals = y - k_hat * u_tau\n        SSR = np.dot(residuals, residuals)\n        \n        log_likelihood = -SSR / (2 * sigma_sq)\n        log_prior = -(tau - mu_tau)**2 / (2 * sigma_tau_sq)\n        \n        log_posteriors[i] = log_likelihood + log_prior\n        \n    best_idx = np.argmax(log_posteriors)\n    return tau_candidates[best_idx]\n\ndef estimate_delay_student_t(x, y, h, dt, tau_candidates, N, mu_tau, sigma_tau, sigma_sq, nu):\n    \"\"\"MAP estimation of delay tau using the Student's t noise model.\"\"\"\n    log_posteriors = np.zeros_like(tau_candidates)\n    sigma_tau_sq = sigma_tau**2\n    \n    def neg_log_lik_t(k, y_obs, u_model, nu_val, sigma_sq_val):\n        residuals = y_obs - k * u_model\n        return np.sum(np.log(1 + residuals**2 / (nu_val * sigma_sq_val)))\n\n    for i, tau in enumerate(tau_candidates):\n        d = int(round(tau / dt))\n        x_shifted = np.zeros(N)\n        if d < N:\n            x_shifted[d:] = x[:N - d]\n        \n        u_tau = np.convolve(x_shifted, h, mode='full')[:N]\n\n        # Numerically optimize for k\n        res = optimize.minimize_scalar(\n            neg_log_lik_t, \n            args=(y, u_tau, nu, sigma_sq),\n            method='bounded',\n            bounds=(0, 10)  # Assume a reasonable positive gain\n        )\n        \n        min_neg_log_lik = res.fun\n        \n        # Profiled log-likelihood (ignoring constants independent of tau)\n        log_likelihood = -0.5 * (nu + 1) * min_neg_log_lik\n        log_prior = -(tau - mu_tau)**2 / (2 * sigma_tau_sq)\n        \n        log_posteriors[i] = log_likelihood + log_prior\n\n    best_idx = np.argmax(log_posteriors)\n    return tau_candidates[best_idx]\n\ndef run_case(params):\n    \"\"\"Runs a single test case.\"\"\"\n    # Unpack parameters\n    N, dt, Ta, tau_min, tau_max, mu_tau, sigma_tau, tau_true, k_true, sigma_sq, x_params, nu, outliers = params\n    \n    # Generate signals\n    x, y, h = generate_signals(N, dt, Ta, tau_true, k_true, sigma_sq, x_params, outliers)\n    \n    # Create candidate delays\n    d_min = int(round(tau_min/dt))\n    d_max = int(round(tau_max/dt))\n    tau_candidates = np.arange(d_min, d_max + 1) * dt\n    \n    # Estimate delay for both models\n    tau_g = estimate_delay_gaussian(x, y, h, dt, tau_candidates, N, mu_tau, sigma_tau, sigma_sq)\n    tau_t = estimate_delay_student_t(x, y, h, dt, tau_candidates, N, mu_tau, sigma_tau, sigma_sq, nu)\n    \n    return tau_g, tau_t\n\ndef solve():\n    \"\"\"Main function to solve the problem for the given test suite.\"\"\"\n    test_cases = [\n        # Case 1: Nominal noise\n        (1000, 0.001, 0.040, 0.010, 0.120, 0.080, 0.020, 0.050, 2.0, 0.0025,\n         [(1.0, 0.200, 0.020), (0.8, 0.500, 0.030), (1.2, 0.750, 0.015)], 3, None),\n        # Case 2: Outliers\n        (1000, 0.001, 0.040, 0.010, 0.120, 0.080, 0.020, 0.050, 2.0, 0.0025,\n         [(1.0, 0.200, 0.020), (0.8, 0.500, 0.030), (1.2, 0.750, 0.015)], 3,\n         ([100, 250, 600, 850, 900], [2.0, -2.0, 2.0, -2.0, 2.0])),\n        # Case 3: Boundary delay\n        (1000, 0.001, 0.040, 0.010, 0.120, 0.080, 0.020, 0.012, 2.5, 0.0025,\n         [(1.1, 0.150, 0.018), (0.9, 0.420, 0.025), (1.0, 0.820, 0.020)], 3, None)\n    ]\n\n    results = []\n    for params in test_cases:\n        tau_g, tau_t = run_case(params)\n        results.append([round(tau_g, 6), round(tau_t, 6)])\n\n    # Format the output string exactly as required\n    print(str(results).replace(\" \", \"\"))\n\nsolve()\n```"
        }
    ]
}