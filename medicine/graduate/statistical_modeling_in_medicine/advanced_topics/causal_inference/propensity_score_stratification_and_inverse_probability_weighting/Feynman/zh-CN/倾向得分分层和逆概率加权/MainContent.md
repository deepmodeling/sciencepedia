## 引言
在医学和[公共卫生](@entry_id:273864)领域，评估治疗或干预措施的真实效果是研究的核心任务。虽然[随机对照试验](@entry_id:909406)（R[CT](@entry_id:747638)）是确定因果关系的黄金标准，但在许多情况下，由于伦理、成本或可行性等原因，我们只能依赖于[观察性研究](@entry_id:906079)数据，如电子病历或全国性健康调查。然而，这些数据天然存在一个致命缺陷：[混杂偏倚](@entry_id:635723)。即接受不同干预措施的个体在研究开始前就可能存在系统性差异，导致我们无法区分观察到的结局差异究竟是源于干预本身还是这些固有的不同。

为了解决这一难题，统计学家开发了精妙的工具来从观察性数据中“挖掘”因果效应，其中倾向性得分（Propensity Score）方法是最为强大和流行的一种。本文旨在系统性地介绍两种核心的倾向性得分技术：[分层](@entry_id:907025)法和[逆概率加权](@entry_id:900254)（IPTW）。通过学习本文，您将能够理解如何在非随机数据中，通过巧妙地调整[数据结构](@entry_id:262134)来模拟一场“伪随机试验”，从而获得更可信的因果结论。

本文将分为三个部分。首先，在“原则与机制”一章中，我们将深入探讨倾[向性](@entry_id:144651)得分的理论基石，明确不同的因果问题，理解控制混杂的核心假设，并揭示倾[向性](@entry_id:144651)得分是如何将高维度的混杂问题简化为一维问题的“魔法”。接着，在“应用与跨学科连接”一章中，我们将走出理论，探索这些方法如何在临床研究、[公共卫生](@entry_id:273864)、[生物信息学](@entry_id:146759)等多个领域解决实际问题，包括应对[适应症混杂](@entry_id:921749)、[时变混杂](@entry_id:920381)等高级挑战。最后，在“动手实践”部分，您将通过具体练习，巩固从模型构建、平衡性诊断到效应估计的全流程操作，将理论[知识转化](@entry_id:893170)为实践技能。

## 原则与机制

在上一章中，我们已经了解了在医学[观察性研究](@entry_id:906079)中估计因果效应的挑战。简单地比较接受治疗和未接受治疗的两组患者，往往会得出误导性的结论，因为这两组患者在接受治疗前可能就已经存在系统性差异。那么，我们如何才能在非随机分配的数据中，拨开混杂的迷雾，窥见治疗效果的真相呢？本章将深入探讨支撑这一过程的核心原则与关键机制，特别是倾向性得分（Propensity Score）这一巧妙工具的魔力。

### 我们究竟想回答什么问题？

在开始任何分析之前，最重要的一步是明确我们要回答的具体问题。这听起来似乎显而易见，但在因果推断中，问题的细微差别会导向完全不同的分析路径和临床解释。在评估一项治疗时，我们至少可以提出三种核心问题，它们对应着三种不同的“[效应量](@entry_id:907012)”（estimands）。

假设我们正在研究一种新型[抗高血压药物](@entry_id:912190)。$Y(1)$ 代表患者服用新药后的潜在健康结局，$Y(0)$ 代表其接受常规治疗的潜在结局。

1.  **平均治疗效应（Average Treatment Effect, ATE）**: $\mathrm{ATE} = \mathbb{E}[Y(1) - Y(0)]$。
    这个问题问的是：如果我们把整个符合条件的患者群体（无论他们实际上是否服用了新药）随机分成两半，一半服用新药，一半接受常规治疗，那么两组结局的平[均差](@entry_id:138238)异会是多少？ATE衡量的是对**整个目标人群**的普适性效应。这对于[卫生政策制定](@entry_id:921145)者来说至关重要，比如决定是否将新药纳入国家医保目录，因为它关系到该疗法在全体民众中的潜在平均获益。

2.  **接受治疗者的平均治疗效应（Average Treatment Effect on the Treated, ATT）**: $\mathrm{ATT} = \mathbb{E}[Y(1) - Y(0) \mid A=1]$。
    这个问题更具针对性：对于那些**实际上已经服用了新药**的患者，这种药物带给他们的平均获益是多少？在现实世界中，医生可能倾向于给风险更高的患者使用新药。ATT正是为了评估在这种“选择性给药”的真实临床实践下，药物对实际使用它的那部分人群产生的效果。这对于评估现有临床策略的有效性、决定是否继续为某类患者提供该治疗具有直接意义 。

3.  **未接受治疗者的平均治疗效应（Average Treatment Effect on the Controls, [ATC](@entry_id:907449)）**: $\mathrm{ATC} = \mathbb{E}[Y(1) - Y(0) \mid A=0]$。
    这个问题则着眼于未来：对于那些**目前没有服用新药**的患者，如果让他们开始服用，他们会获得多大的平均效益？当考虑将一种药物推广到更广泛、风险可能更低的人群时，[ATC](@entry_id:907449)就变得非常重要。它帮助我们预测扩大治疗覆盖范围可能带来的效果。

这三个[效应量](@entry_id:907012)在数值上可能完全不同，因为接受治疗和未接受治疗的患者群体本身就可能存在差异。选择哪个[效应量](@entry_id:907012)，取决于你的研究目的和决策情境。明确了目标，我们才能选择正确的工具去实现它。

### 观测研究的“原罪”：[混杂偏倚](@entry_id:635723)

为什么我们不能直接计算接受治疗组的平均结局与未接受治疗组的平均结局之差呢？这就是观测性研究的“原罪”——**混杂（confounding）**。

想象一下，新药因为效果强劲但副作用也更明显，医生们倾向于将其开给血压极高、常规药物难以控制的重症患者。而那些病情较轻的患者则继续使用常规治疗。一年后，我们发现服用新药的这组患者，其心血管事件发生率仍然高于常规治疗组。我们能得出“新药有害”的结论吗？显然不能。因为服用新药的这组患者，他们的“起点”就更差。他们的不良结局很可能是由其本身更严重的病情导致的，而非药物所致。这种既与治疗选择有关（病情重所以用新药），又与结局有关（病情重所以结局差）的基线变量（这里指“病情严重程度”），就是**[混杂变量](@entry_id:261683)（confounder）**。

用潜在结局的语言来说，我们想比较的是 $\mathbb{E}[Y(1)]$ 和 $\mathbb{E}[Y(0)]$。但在观测数据中，我们能直接计算的却是 $\mathbb{E}[Y \mid A=1]$ 和 $\mathbb{E}[Y \mid A=0]$。由于“病情更重的人更可能接受新药”，我们知道 $\mathbb{E}[Y \mid A=1]$ 其实是重症患者群体服用新药后的结局，而 $\mathbb{E}[Y \mid A=0]$ 则是轻症患者群体接受常规治疗的结局。这就像比较苹果和橙子，我们无法从这种比较中分离出治疗本身的净效应。

### 游戏规则：让比较变得公平的三个基本假设

要从观测数据中得到有效的因果结论，我们必须接受一套“游戏规则”，也就是三个核心的**可识别性假设（identifiability assumptions）**。这些假设是不可直接验证的，它们构成了我们进行因果推断的逻辑基石。只有相信它们在我们的研究场景中成立，后续的分析才有意义 。

1.  **一致性（Consistency）**：个体的实际观测结局，等于其接受相应治疗下的潜在结局。即如果患者 $i$ 接受了治疗（$A_i=1$），那么我们观测到的结局 $Y_i$ 就是他的潜在结局 $Y_i(1)$。这个假设将我们无法观测的潜在结局世界与我们能够观测的现实世界联系起来。它看似理所当然，但排除了诸如“药物剂量不同”、“[患者依从性](@entry_id:900416)不一”等多种治疗版本导致效果不一的复杂情况。

2.  **[条件可交换性](@entry_id:896124)（Conditional Exchangeability）**：这个假设是控制混杂的核心，也常被称为“无未测混杂（no unmeasured confounding）”。它声明，一旦我们控制了所有重要的基线[混杂变量](@entry_id:261683)（用一个向量 $X$ 表示），那么在拥有相同 $X$ 值的患者亚组内，治疗分配 $A$ 就与潜在结局 $\{Y(0), Y(1)\}$ 相互独立了。换句话说，对于两个具有完全相同基线特征（年龄、性别、病史、各项生理指标都一样）的患者，无论他们最终是接受了新药还是常规治疗，他们的潜在健康风险都是相似的。在这个亚组里，治疗分配可以被视为“近似随机”的。这就为我们“比较苹果和苹果”提供了可能。

3.  **正性（Positivity）**：对于任何类型的患者（即对于任何一组基线特征 $X$ 的取值），他既有可能接受治疗，也有可能不接受治疗。形式上，即 $0  \Pr(A=1 \mid X=x)  1$。这个假设保证了对于我们想研究的任何一类患者，都能在数据中找到接受治疗和未接受治疗的参照对象。如果某个亚组的患者（比如有某种严重禁忌症的患者）医生**绝不会**给他们使用新药（即 $\Pr(A=1 \mid X=x)=0$），那么我们就永远无法从数据中得知新药对他们会产生什么效果，因为我们缺少事实依据。这种情况下，因果效应在该亚组中是**不可识别**的 。

有了这三条规则，理论上我们就可以通过在[混杂变量](@entry_id:261683) $X$ 的每个水平上分别比较治疗组和[对照组](@entry_id:747837)，然后将结果加权平均，从而得到无偏的因果效应估计。

### 倾向性得分的“魔法”：驯服高[维度的诅咒](@entry_id:143920)

理论是美好的，但现实是骨感的。[混杂变量](@entry_id:261683) $X$ 通常不是一个，而是一整个向量，可能包含数十个甚至上百个变量（年龄、性别、几十项血液检查结果、各种[合并症](@entry_id:899271)等）。想要找到在所有这些变量上都“完全相同”的患者来进行匹配，几乎是不可能的。这就是所谓的“**维度诅咒（curse of dimensionality）**”。

就在这时，统计学家 Paul Rosenbaum 和 Donald Rubin 在 1983 年提出了一个堪称“魔法”的解决方案：**倾[向性](@entry_id:144651)得分（Propensity Score）**。

倾[向性](@entry_id:144651)得分 $e(X)$ 被定义为在给定一系列基线[协变](@entry_id:634097)量 $X$ 的条件下，一个个体接受治疗（$A=1$）的条件概率：
$$
e(X) = \Pr(A=1 \mid X)
$$
这个得分本身是一个介于 $0$ 和 $1$ 之间的单一数值。它的神奇之处在于，它是一个**[平衡得分](@entry_id:911689)（balancing score）**。Rosenbaum 和 Rubin 证明了一个惊人的定理：在倾[向性](@entry_id:144651)得分值相同的个体之间，治疗分配与整个高维协变量向量 $X$ 是独立的，即 $X \perp A \mid e(X)$ 。

这意味着什么呢？这意味着，我们不再需要在数十个协变量上进行匹配，我们只需要在**倾[向性](@entry_id:144651)得分这个一维标量上进行匹配**即可！如果两个患者，一个接受了治疗，一个未接受治疗，但他们具有相同的倾向性得分，那么我们就可以期望他们的基线[协变](@entry_id:634097)量 $X$ 的整体[分布](@entry_id:182848)是相似的。倾向性得分就像一个“万能匹配器”，它将所有与治疗选择有关的信息从高维的 $X$ 中压缩到了一个单一的维度上，极大地简化了问题。

更进一步，如果[条件可交换性](@entry_id:896124)在 $X$ 上成立，那么它在 $e(X)$ 上也成立。也就是说，只要控制了倾[向性](@entry_id:144651)得分，治疗分配就与潜在结局无关。这为我们提供了两种强大的策略来估计因果效应。

不过，这里有一个微妙但重要的点：倾[向性](@entry_id:144651)得分完美地总结了关于**治疗分配**的信息，但它不一定能完美地总结关于**疾病结局**的信息 。一个变量可能对预测结局非常重要（强预后变量），但与治疗选择关系不大。在将 $X$ 压缩到 $e(X)$ 的过程中，这类变量的特定信息可能会丢失。这虽然不影响我们获得无偏的因果效应估计，但可能会影响估计的**精度（efficiency）**。这就像是用一个巧妙的滤镜看世界，滤镜能帮你消除背景的杂色（混杂），但可能会让图像的某些细节变得不那么锐利（损失精度）。

### 驾驭得分：两大核心策略

有了倾向性得分这个强大的工具，我们如何实际应用它来调整混杂呢？主要有两种流行的方法：[分层](@entry_id:907025)法和[逆概率加权](@entry_id:900254)。

#### 策略一：[分层](@entry_id:907025)法——构建公平的“竞技场”

[分层](@entry_id:907025)法（Stratification）是最直观的方法之一。它的思想是：既然倾向性得分相同的人是可比的，那我们就把得分相近的人放在一起比较。

具体操作是，我们首先为研究中的每个受试者计算出其估计的倾向性得分 $\hat{e}(X)$（通常通过 logistic [回归模型](@entry_id:163386)）。然后，我们将所有受试者按照他们的倾向性得分从低到高排序，并像切蛋糕一样将他们切成 $K$ 个组，或称“层”（strata）。例如，最常见的做法是分为 5 层（即按五[分位数](@entry_id:178417)切分），每层包含总人数的 20% 。

在每一层内部，患者的倾[向性](@entry_id:144651)得分都非常接近，因此他们的基线[协变](@entry_id:634097)量[分布](@entry_id:182848)也应该是**近似平衡**的 。注意，这里的平衡只是近似的，因为层内得分仍有变异。现在，每一层都像一个小的、近似随机的试验“竞技场”。我们可以在每一层内部分别计算治疗组和对照组的结局差异，得到一个层特异的治疗效应。最后，我们将这 $K$ 个层特异的效应加权平均（权重通常是每层的人数占比），就得到了对总体治疗效应（如 ATE）的估计。

为什么常常选择 $K=5$ 呢？这源于统计学家 Cochran 的一项经典研究，他发现在处理单个[正态分布](@entry_id:154414)的混杂因素时，分为 5 层可以消除约 90% 的偏倚。Rosenbaum 和 Rubin 的工作表明，这个“经验法则”在倾[向性](@entry_id:144651)得分的场景下也常常表现得相当不错 。选择 $K$ 的过程其实是一个**偏倚-[方差](@entry_id:200758)权衡（bias-variance trade-off）**。层数越多，层内得分越同质，偏倚越小；但每层的[样本量](@entry_id:910360)也越小，导致估计的[方差](@entry_id:200758)增大，结果不稳定。$K=5$ 通常被认为是在中等大小的数据集中，平衡偏倚和[方差](@entry_id:200758)的一个实用折中。

#### 策略二：[逆概率加权](@entry_id:900254)——创造一个“平行宇宙”

[逆概率加权](@entry_id:900254)（Inverse Probability of Treatment Weighting, IPTW）是另一种更灵活、也更抽象的方法。它的核心思想是通过加权，人工创造一个“伪人群”（pseudo-population），在这个伪人群中，治疗分配与所有基线[协变](@entry_id:634097)量无关，从而消除混杂。

我们来思考一下权重是如何设计的。权重 $w_i$ 的设计原则是：让每个个体“代表”多少和他/她相似的人。

-   **对于 ATE**：我们希望伪人群中，治疗组和对照组的协变量[分布](@entry_id:182848)都与**原始总人群**相同。
    -   对于一个接受了治疗（$A_i=1$）的患者，他在现实中被治疗的概率是 $\hat{e}(X_i)$。为了在伪人群中消除治疗选择的影响，我们要给他一个权重 $w_i = 1/\hat{e}(X_i)$。如果一个患者本“不该”接受治疗（$\hat{e}(X_i)$很小），却接受了，那他就是个“意外”，在伪人群中，他需要被赋予很大的权重，来代表所有像他一样本该不被治疗但被我们假设为接受了治疗的人。
    -   同理，对于一个未接受治疗（$A_i=0$）的患者，他的权重是 $w_i = 1/(1-\hat{e}(X_i))$。
    通过这种方式，我们给那些“反常”的（即接受了低概率治疗）个体更高的权重，给“常规”的个体更低的权重，最终创造出一个[协变](@entry_id:634097)量[分布](@entry_id:182848)在两组间完全平衡的伪人群 。

-   **对于 ATT**：我们的目标是评估在**实际接受治疗的人群中**的效果。这意味着，接受治疗的那组人就是我们的黄金标准，我们不需要改变他们。我们只需要创造一个“[反事实](@entry_id:923324)”的对照组，让这个对照组的协变量[分布](@entry_id:182848)看起来和治疗组一模一样。
    -   因此，对于所有接受了治疗的患者（$A_i=1$），他们的权重就是 $w_i^{ATT} = 1$。
    -   对于未接受治疗的患者（$A_i=0$），我们需要给他们加权，让他们能“模仿”治疗组的[协变](@entry_id:634097)量[分布](@entry_id:182848)。这个权重恰好是 $w_i^{ATT} = \hat{e}(X_i) / (1-\hat{e}(X_i))$ 。这个权重也被称为“比值（odds）”。

在加权后的伪人群里，简单的组间差异比较就能得到对目标因果效应的无偏估计。

### 当理想照进现实：正性假设的挑战

无论是[分层](@entry_id:907025)还是加权，这些方法的顺利实施都依赖于我们之前提到的“游戏规则”，尤其是**正性假设**。但在真实世界的数据中，正性假设常常面临挑战，这被称为**实际的正性违例（practical positivity violations）** 。

当某些患者的倾向性得分非常接近 $0$ 或 $1$ 时，问题就出现了。例如，一个患者的 $\hat{e}(X_i)=0.01$，这意味着根据他的特征，他有 99% 的可能性不接受治疗。但如果他**实际上接受了治疗**（$A_i=1$），那么在计算 ATE 的 IPTW 中，他的权重将是 $1/0.01 = 100$！这意味着这一个患者的结局将在很大程度上影响整个治疗组的平均结局。如果这个患者恰好出现了一个极端的不良事件，那么整个分析结果都可能被他一个人“带偏”。

这种极端权重会导致估计量的**[方差](@entry_id:200758)急剧膨胀**，使得结果极不稳定，并且对倾向性得分模型的微小误差也异常敏感。这就像试图用一根手指撬动地球，理论上可行，但实践中极其脆弱 。

面对这种困境，研究者们发展了几种应对策略：

1.  **使用[稳定权重](@entry_id:894842)（Stabilized Weights）**：[稳定权重](@entry_id:894842)在标准权重的分子上乘以一个常数（治疗的[边际概率](@entry_id:201078)），例如 $w_i^{\text{stab}} = \Pr(A=1)/\hat{e}(X_i)$。这可以减小权重的整体变异性，但并不能从根本上解决分母接近于零的问题。它能让“撬地球”的手指变得粗壮一些，但问题本质未变 。

2.  **截断或修整（Trimming or Winsorizing）**：一个更激进的方法是，直接丢弃那些倾[向性](@entry_id:144651)得分极端（例如，小于 0.01 或大于 0.99）的患者，或者将他们的极端权重“[拉回](@entry_id:160816)”到一个设定的上限。这样做可以极大地提高估计的稳定性。但代价是，我们不再是在估计原始目标人群的平均效应了。我们的研究结论只适用于那些治疗和对照倾[向性](@entry_id:144651)“重叠”较好的人群。我们通过牺牲一部分**普遍性**（generalizability）换取了结果的**稳健性**（robustness）。这是一种有意识的取舍：回答一个范围更窄但更可信的问题  。

总而言之，从明确因果问题，到理解混杂的挑战，再到运用倾向性得分这一精妙工具通过[分层](@entry_id:907025)或加权来解决问题，我们完成了一次从理论到实践的旅程。然而，我们也必须清醒地认识到，这些方法并非万能药，它们依赖于我们无法完全验证的假设，并且在实践中会遇到各种挑战。一个严谨的分析者，不仅要懂得如何使用这些工具，更要懂得它们的局限性，并通过各种诊断和敏感性分析来审视自己结论的强度。