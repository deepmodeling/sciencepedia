{
    "hands_on_practices": [
        {
            "introduction": "倾向性评分匹配最直接的应用之一是估计处理对处理组的平均效应（Average Treatment effect on the Treated, ATT）。本练习将通过一个小型假设数据集，引导您完成核心计算，该数据集由经过匹配的处理-对照配对组成。这有助于巩固匹配如何创建一个与处理组具有相似基线特征的可比较对照组，从而估计因果效应的直观理解 ()。",
            "id": "4830538",
            "problem": "一项基于医院的观察性队列研究评估了一种降脂疗法（$A=1$）相对于常规护理（$A=0$）对6个月内低密度脂蛋白胆固醇（LDL-C）降低量的影响，该降低量以 $\\mathrm{mg/dL}$ 为单位测量。设每位患者的潜在结果为 $Y(1)$ 和 $Y(0)$，并假设满足稳定单位治疗价值假设（SUTVA）和强可忽略性，即对于 $a \\in \\{0,1\\}$，在给定协变量 $X$ 的条件下，$Y(a) \\perp A \\mid X$，并且不存在未测量的混杂因素。倾向性得分为 $e(X) = \\Pr(A=1 \\mid X)$，匹配是在共同支撑域上，对处理组单位，采用最近邻方法在 logit 倾向性得分上进行，并使用一个保守的卡尺。科学目标是估计处理组平均处理效应（ATT）。\n\n从潜在结果框架的基本原理和倾向性得分的平衡性质出发，形式化通过对处理组单位进行匹配所针对的参数，并解释为什么在所述假设下，对估计的倾向性得分进行最近邻匹配（具有适当的共同支撑域和卡尺）可以识别该参数。然后，使用下面给出的匹配的处理-对照配对，通过计算对内结果差异在处理组单位上的平均值，来计算此参数的样本配对估计量。\n\n该研究产生了 $n_T = 5$ 个匹配对（每个处理组单位对应一个对照组单位），观察到的6个月LDL-C降低量（单位：$\\mathrm{mg/dL}$）如下：\n- 配对1：处理组 $Y^{\\mathrm{obs}} = 38.4$，匹配对照组 $Y^{\\mathrm{obs}} = 25.6$。\n- 配对2：处理组 $Y^{\\mathrm{obs}} = 22.1$，匹配对照组 $Y^{\\mathrm{obs}} = 15.9$。\n- 配对3：处理组 $Y^{\\mathrm{obs}} = 41.0$，匹配对照组 $Y^{\\mathrm{obs}} = 27.3$。\n- 配对4：处理组 $Y^{\\mathrm{obs}} = 35.2$，匹配对照组 $Y^{\\mathrm{obs}} = 29.0$。\n- 配对5：处理组 $Y^{\\mathrm{obs}} = 30.5$，匹配对照组 $Y^{\\mathrm{obs}} = 18.1$。\n\n将最终估计值报告为处理组减去匹配对照组差异的标量平均值，以 $\\mathrm{mg/dL}$ 表示。将您的答案四舍五入到四位有效数字。",
            "solution": "该问题要求给出处理组平均处理效应（ATT）的形式化定义，解释如何通过倾向性得分匹配来识别它，并计算一个样本估计值。此问题在因果推断框架内是良定的，并且具有科学依据。\n\n首先，我们形式化目标参数，即处理组平均处理效应（ATT）。设 $Y(1)$ 为患者接受降脂疗法（$A=1$）时的潜在结果（LDL-C降低量），$Y(0)$ 为接受常规护理（$A=0$）时的潜在结果。ATT 定义为对于实际接受治疗的个体子群体，治疗的期望因果效应：\n$$\n\\text{ATT} = E[Y(1) - Y(0) \\mid A=1]\n$$\n根据期望的线性性质，这可以写成：\n$$\n\\text{ATT} = E[Y(1) \\mid A=1] - E[Y(0) \\mid A=1]\n$$\n第一项 $E[Y(1) \\mid A=1]$ 是处理组在接受治疗时的期望结果。根据稳定单位治疗价值假设（SUTVA），接受治疗的个体的观察结果就是其在治疗下的潜在结果，即如果 $A=1$，则 $Y^{\\mathrm{obs}} = Y(1)$。因此，这一项可以直接从数据中识别，并可以通过处理组中观察结果的样本均值来估计：$E[Y^{\\mathrm{obs}} \\mid A=1]$。\n\n第二项 $E[Y(0) \\mid A=1]$ 是处理组在对照条件下的期望结果。这是一个反事实量，因为我们无法观察到接受治疗的个体如果接受了对照处理其结果会是怎样。它的识别是观察性研究中的核心挑战。\n\n识别是在所述的强可忽略性假设 $Y(a) \\perp A \\mid X$（对于 $a \\in \\{0,1\\}$）下实现的，这意味着在给定观察到的协变量集合 $X$ 的条件下，处理分配 $A$ 与潜在结果 $Y(a)$ 是独立的。对于我们感兴趣的反事实均值，这意味着：\n$$\nE[Y(0) \\mid A=1, X] = E[Y(0) \\mid A=0, X]\n$$\n这个方程表明，在由协变量 $X$ 定义的层内，处理组和对照组在对照条件下的期望潜在结果是相同的。方程的右侧是可观察的，因为对于对照组（$A=0$），$Y^{\\mathrm{obs}} = Y(0)$。因此，$E[Y(0) \\mid A=0, X] = E[Y^{\\mathrm{obs}} \\mid A=0, X]$。\n\n为了获得处理人群的整体反事实均值，我们对处理组（$A=1$）中协变量 $X$ 的分布进行平均：\n$$\nE[Y(0) \\mid A=1] = E_{X \\mid A=1} [E[Y(0) \\mid A=1, X]]\n$$\n代入从可忽略性假设得到的结果：\n$$\nE[Y(0) \\mid A=1] = E_{X \\mid A=1} [E[Y(0) \\mid A=0, X]] = E_{X \\mid A=1} [E[Y^{\\mathrm{obs}} \\mid A=0, X]]\n$$\n这个表达式表明，处理组的反事实均值可以通过获取对照组受试者的结果，并对其进行重新加权或标准化，以匹配处理组受试者的协变量分布来识别。\n\n倾向性得分匹配是实现这种标准化的一种方法。倾向性得分 $e(X) = \\Pr(A=1 \\mid X)$ 具有一个由 Rosenbaum 和 Rubin 建立的关键平衡性质：在以倾向性得分为条件的-情况下，协变量 $X$ 的分布在处理组和对照组之间是相同的。这个性质允许我们用对标量 $e(X)$ 的条件来代替对多维 $X$ 的条件。强可忽略性假设 $Y(a) \\perp A \\mid X$ 意味着在以倾向性得分为条件的-情况下也具有类似的可忽略性：$Y(a) \\perp A \\mid e(X)$。\n\n因此，我们可以写出：\n$$\nE[Y(0) \\mid A=1, e(X)] = E[Y(0) \\mid A=0, e(X)] = E[Y^{\\mathrm{obs}} \\mid A=0, e(X)]\n$$\n对处理组进行匹配的操作方式是，为每个处理组个体 $i$ 找到一个具有几乎相同倾向性得分 $e(X_i) \\approx e(X_{j(i)})$ 的对照组个体 $j(i)$。这个过程创建了一个匹配的对照组，该组由于其倾向性得分分布与处理组相似，其协变量 $X$ 的分布也相似。因此，这个匹配对照组中结果的简单平均值为 $E_{X \\mid A=1} [E[Y^{\\mathrm{obs}} \\mid A=0, X]]$ 提供了一个无偏估计，这正是我们的目标反事实均值 $E[Y(0) \\mid A=1]$。\n\n因此，ATT 可通过以下方式识别：\n$$\n\\text{ATT} = E[Y^{\\mathrm{obs}} \\mid A=1] - E[Y^{\\mathrm{obs}}_{\\text{matched controls}}]\n$$\nATT 的样本配对估计量是此表达式的样本类比。对于一组 $n_T$ 个处理组个体，每个个体都与一个唯一的对照组个体匹配，其估计量是对内差异的平均值：\n$$\n\\widehat{\\text{ATT}} = \\frac{1}{n_T} \\sum_{i=1}^{n_T} (Y_i^{\\mathrm{obs, treated}} - Y_{j(i)}^{\\mathrm{obs, control}})\n$$\n其中 $Y_{j(i)}^{\\mathrm{obs, control}}$ 是与第 $i$ 个处理组单位匹配的对照组单位的观察结果。\n\n现在，我们使用提供的 $n_T = 5$ 对数据来计算这个估计量。\n每对的差异是：\n- 配对1：$\\Delta_1 = 38.4 - 25.6 = 12.8$\n- 配对2：$\\Delta_2 = 22.1 - 15.9 = 6.2$\n- 配对3：$\\Delta_3 = 41.0 - 27.3 = 13.7$\n- 配对4：$\\Delta_4 = 35.2 - 29.0 = 6.2$\n- 配对5：$\\Delta_5 = 30.5 - 18.1 = 12.4$\n\n样本 ATT 是这些差异的平均值：\n$$\n\\widehat{\\text{ATT}} = \\frac{1}{5} \\sum_{i=1}^{5} \\Delta_i = \\frac{12.8 + 6.2 + 13.7 + 6.2 + 12.4}{5}\n$$\n$$\n\\widehat{\\text{ATT}} = \\frac{51.3}{5} = 10.26\n$$\n问题要求将答案四舍五入到四位有效数字。计算出的值 $10.26$ 已经有四位有效数字。\n\n处理组平均处理效应的最终估计值为 $10.26 \\, \\mathrm{mg/dL}$。",
            "answer": "$$\\boxed{10.26}$$"
        },
        {
            "introduction": "在掌握了ATT的估计后，我们将视野拓宽到对整个人群的平均处理效应（Average Treatment Effect, ATE）。本练习介绍倾向性评分分层法，作为一对一匹配的另一种选择。它将演示如何通过整合不同人群分层中的效应，来计算总体的ATE估计值，这对于评估一项干预或政策的广泛影响至关重要 ()。",
            "id": "4830519",
            "problem": "一项临床有效性研究使用观察性队列数据来估计启用一种新的降压疗法对$6$个月内收缩压变化产生的因果效应。设二元处理指标为 $T \\in \\{0,1\\}$，基线协变量为 $X$，结局变量为 $Y$，定义为从基线到$6$个月时收缩压的变化，单位为毫米汞柱 (mmHg)，负值表示血压降低。假设稳定单元处理值假设 (SUTVA) 和强可忽略性成立，即 $(Y(0),Y(1)) \\perp T \\mid X$ 和正值性，其中 $Y(0)$ 和 $Y(1)$ 分别表示在控制和处理下的潜在结果。倾向性得分为 $e(X) = \\Pr(T=1 \\mid X)$。\n\n该研究估计了 $e(X)$，并使用估计的倾向性得分的五分位数将样本分层为 $K$ 个子类（因此 $K=5$）。在每个子类 $k \\in \\{1,2,3,4,5\\}$ 中，处理组和控制组的样本量分别为 $N_{1k}$ 和 $N_{0k}$，处理组和控制组中 $Y$ 的观测样本均值分别为 $\\bar{Y}_{1k}$ 和 $\\bar{Y}_{0k}$。数据如下，其中所有计数和均值在科学上都是合理的，并源自该队列：\n\n- 五分位数组 $k=1$：$N_{1,1} = 40$， $N_{0,1} = 160$， $\\bar{Y}_{1,1} = -12.4$， $\\bar{Y}_{0,1} = -8.7$。\n- 五分位数组 $k=2$：$N_{1,2} = 60$， $N_{0,2} = 140$， $\\bar{Y}_{1,2} = -10.2$， $\\bar{Y}_{0,2} = -7.9$。\n- 五分位数组 $k=3$：$N_{1,3} = 110$， $N_{0,3} = 90$， $\\bar{Y}_{1,3} = -9.5$， $\\bar{Y}_{0,3} = -6.1$。\n- 五分位数组 $k=4$：$N_{1,4} = 150$， $N_{0,4} = 50$， $\\bar{Y}_{1,4} = -8.0$， $\\bar{Y}_{0,4} = -5.0$。\n- 五分位数组 $k=5$：$N_{1,5} = 180$， $N_{0,5} = 20$， $\\bar{Y}_{1,5} = -7.1$， $\\bar{Y}_{0,5} = -3.4$。\n\n令 $N_k = N_{1k} + N_{0k}$ 且 $N = \\sum_{k=1}^{5} N_k$。从观察性因果推断的基本有效原理出发，定义将倾向性得分分层为 $K$ 个子类（如五分位数组）的方法。使用这些原理，推导子类 $k$ 的层内均值差估计量，以及针对研究样本中平均处理效应 (ATE) 的跨子类加权汇总方法。然后使用所提供的数据计算得出的 ATE 估计值。最终答案以毫米汞柱 (mmHg) 表示，并四舍五入到四位有效数字。",
            "solution": "该问题提法明确，有科学依据，并提供了使用倾向性得分分层估计平均处理效应 (ATE) 所需的所有信息。我们将首先根据因果推断的基本原理推导估计量，然后将其应用于所提供的数据。\n\n目标是估计平均处理效应 (ATE)，其定义为在整个总体上，处理下的潜在结果 ($Y(1)$) 与控制下的潜在结果 ($Y(0)$) 之间的期望差异：\n$$\n\\tau_{ATE} = E[Y(1) - Y(0)]\n$$\n在观察性研究中，我们无法直接观察到同一个体的 $Y(1)$ 和 $Y(0)$。对处理组和控制组进行朴素比较，$E[Y \\mid T=1] - E[Y \\mid T=0]$，通常由于混杂而存在偏倚，其中影响处理分配 $T$ 的协变量 $X$ 同时也影响结局变量 $Y$。\n\n问题陈述了**强可忽略性**假设，该假设包含两部分：\n$1$. 无混杂性：$(Y(0), Y(1)) \\perp T \\mid X$。这意味着在给定基线协变量 $X$ 的条件下，处理分配 $T$ 与潜在结果无关。\n$2$. 正值性（或重叠性）：$0  \\Pr(T=1 \\mid X)  1$。这确保对于任何一组协变量 $X$，被分到处理组或控制组的概率都非零。\n\n在无混杂性条件下，我们可以识别条件期望潜在结果：\n$$\nE[Y(t) \\mid X] = E[Y(t) \\mid T=t, X] = E[Y \\mid T=t, X] \\quad \\text{for } t \\in \\{0,1\\}\n$$\n然后，ATE可以表示为对协变量 $X$ 分布的期望：\n$$\n\\tau_{ATE} = E_X[E[Y(1) \\mid X] - E[Y(0) \\mid X]] = E_X[E[Y \\mid T=1, X] - E[Y \\mid T=0, X]]\n$$\n直接对高维向量 $X$ 进行条件化通常是不切实际的。Rosenbaum 和 Rubin (1983) 表明，对一维倾向性得分 $e(X) = \\Pr(T=1 \\mid X)$ 进行条件化足以消除混杂偏倚，因为它是一个平衡得分。具体来说，如果 $(Y(0), Y(1)) \\perp T \\mid X$ 成立，那么 $(Y(0), Y(1)) \\perp T \\mid e(X)$ 也成立。\n\n**倾向性得分分层**\n该方法通过将总体根据估计的倾向性得分 $\\hat{e}(X)$ 的分位数划分为 $K$ 个层，来近似对连续倾向性得分 $e(X)$ 的条件化。在每个层 $k$ 内，个体的倾向性得分相似，因此其协变量 $X$ 的分布在处理组和控制组之间预期是近似平衡的。\n\n**层内估计量**\n在给定的层 $k$ 内，无混杂性假设被认为近似成立。因此，层 $k$ 内的平均处理效应，记为 $\\tau_k$，可以通过该层中处理组受试者和控制组受试者之间均值结局的简单差异来估计。\n$$\n\\tau_k = E[Y(1) - Y(0) \\mid \\text{subject in stratum } k]\n$$\n其基于样本的估计量是**层内均值差估计量**：\n$$\n\\hat{\\tau}_k = \\bar{Y}_{1k} - \\bar{Y}_{0k}\n$$\n其中 $\\bar{Y}_{1k}$ 是层 $k$ 中一个处理单元的结局样本均值，$\\bar{Y}_{0k}$ 是层 $k$ 中一个控制单元的结局样本均值。\n\n**汇总以估计 ATE**\n总体 ATE 是各层特定处理效应的加权平均值，其中权重是每个层中总样本量的比例。\n根据全期望定律，ATE可以写为：\n$$\n\\tau_{ATE} = \\sum_{k=1}^K \\Pr(\\text{stratum } k) \\cdot E[Y(1) - Y(0) \\mid \\text{stratum } k] = \\sum_{k=1}^K \\Pr(\\text{stratum } k) \\cdot \\tau_k\n$$\n我们通过用样本比例替代概率，用层特定估计量 $\\hat{\\tau}_k$ 替代 $\\tau_k$ 来估计这个值。令 $N_k = N_{1k} + N_{0k}$ 为层 $k$ 中的受试者数量，$N = \\sum_{k=1}^K N_k$ 为总样本量。研究样本中 ATE 的估计量为：\n$$\n\\hat{\\tau}_{ATE} = \\sum_{k=1}^K \\frac{N_k}{N} \\hat{\\tau}_k = \\sum_{k=1}^K \\frac{N_{1k} + N_{0k}}{N} (\\bar{Y}_{1k} - \\bar{Y}_{0k})\n$$\n\n**计算**\n我们有 $K=5$ 个层（五分位数）的数据。我们首先计算每个层中的受试者总数和总样本量。\n- 层 $k=1$：$N_1 = N_{1,1} + N_{0,1} = 40 + 160 = 200$\n- 层 $k=2$：$N_2 = N_{1,2} + N_{0,2} = 60 + 140 = 200$\n- 层 $k=3$：$N_3 = N_{1,3} + N_{0,3} = 110 + 90 = 200$\n- 层 $k=4$：$N_4 = N_{1,4} + N_{0,4} = 150 + 50 = 200$\n- 层 $k=5$：$N_5 = N_{1,5} + N_{0,5} = 180 + 20 = 200$\n\n总样本量为 $N = \\sum_{k=1}^5 N_k = 200 + 200 + 200 + 200 + 200 = 1000$。\n\n每个层的权重为 $\\frac{N_k}{N} = \\frac{200}{1000} = \\frac{1}{5} = 0.2$。由于各层是五分位数且包含相同数量的受试者，所以权重都相等。\n\n接下来，我们计算层内均值差 $\\hat{\\tau}_k$：\n- 层 $k=1$：$\\hat{\\tau}_1 = \\bar{Y}_{1,1} - \\bar{Y}_{0,1} = -12.4 - (-8.7) = -3.7$\n- 层 $k=2$：$\\hat{\\tau}_2 = \\bar{Y}_{1,2} - \\bar{Y}_{0,2} = -10.2 - (-7.9) = -2.3$\n- 层 $k=3$：$\\hat{\\tau}_3 = \\bar{Y}_{1,3} - \\bar{Y}_{0,3} = -9.5 - (-6.1) = -3.4$\n- 层 $k=4$：$\\hat{\\tau}_4 = \\bar{Y}_{1,4} - \\bar{Y}_{0,4} = -8.0 - (-5.0) = -3.0$\n- 层 $k=5$：$\\hat{\\tau}_5 = \\bar{Y}_{1,5} - \\bar{Y}_{0,5} = -7.1 - (-3.4) = -3.7$\n\n最后，我们计算 ATE 估计值，即这些层特定效应的加权平均值：\n$$\n\\hat{\\tau}_{ATE} = \\sum_{k=1}^5 \\frac{N_k}{N} \\hat{\\tau}_k = \\frac{1}{5} \\sum_{k=1}^5 \\hat{\\tau}_k\n$$\n$$\n\\hat{\\tau}_{ATE} = \\frac{1}{5} (-3.7 - 2.3 - 3.4 - 3.0 - 3.7)\n$$\n$$\n\\hat{\\tau}_{ATE} = \\frac{1}{5} (-16.1)\n$$\n$$\n\\hat{\\tau}_{ATE} = -3.22\n$$\n问题要求将答案四舍五入到四位有效数字。计算值为 $-3.22$。为了用四位有效数字表示，我们写作 $-3.220$。负号表示该疗法与收缩压的降低相关，这与预期相符。该疗法估计的平均因果效应是使血压降低 $3.220$ mmHg。",
            "answer": "$$\n\\boxed{-3.220}\n$$"
        },
        {
            "introduction": "正确构建倾向性评分模型与计算本身同样重要，而变量选择是其中的关键。本练习将通过模拟，揭示一个在变量选择中常见但反直觉的陷阱——对撞偏倚（M-bias 或 collider bias）。您将亲手验证，错误地将一个“对撞变量”纳入模型，即使它看起来与结果或处理相关，也可能打开一条虚假的关联路径，从而严重扭曲因果效应的估计 ()。",
            "id": "3162896",
            "problem": "要求您在统计学习中因果推断的潜在结果框架内，设计并实现一个基于模拟的演示，以展示倾向性得分匹配（PSM）中的M偏差。\n\n从以下基本概念开始：在潜在结果框架下，平均处理效应（ATE）被定义为处理组和控制组潜在结果之间的平均差异，而倾向性得分是在给定观测协变量条件下接受处理的概率。对撞因子（collider）是一个由两个（或多个）变量引起的变量；以对撞因子为条件，可能会在原本独立的两个原因之间引入伪统计关联（M偏差），如果这些原因沿着不同路径影响结果和处理，这将导致因果效应估计产生偏差。\n\n使用有向无环图（DAG）概念，构建一个体现典型M偏差结构的数据生成过程（DGP）。该DAG如下：存在潜变量 $U$ 和 $V$ ，使得 $U$ 影响处理 $T$ 但不影响结果 $Y$，$V$ 影响结果 $Y$ 但不影响处理 $T$，而对撞因子 $C$ 同时受 $U$ 和 $V$ 的影响。此外，还有一个观测协变量 $X$。其结构方程如下：\n- 潜变量原因：$U \\sim \\mathcal{N}(0,1)$, $V \\sim \\mathcal{N}(0,1)$。\n- 观测协变量：$X \\sim \\mathcal{N}(0,1)$。\n- 对撞因子：$C = \\gamma_U U + \\gamma_V V + \\varepsilon_C$，其中 $\\varepsilon_C \\sim \\mathcal{N}(0,1)$。\n- 处理分配：$T \\sim \\text{Bernoulli}(\\text{logit}^{-1}(\\alpha_0 + \\alpha_U U + \\alpha_X X))$，其中 $\\text{logit}^{-1}(z) = \\frac{1}{1 + e^{-z}}$。\n- 结果：$Y = \\beta_T T + \\beta_V V + \\beta_X X + \\varepsilon_Y$，其中 $\\varepsilon_Y \\sim \\mathcal{N}(0,1)$。\n\n在此DGP下，真实的平均处理效应（ATE）等于 $\\beta_T$。\n\n您的程序必须为每个测试用例执行以下操作：\n1. 根据上述DGP模拟 $N$ 个独立观测值。\n2. 使用逻辑回归（最大似然法）为 $T$ 估计两个倾向性得分模型，每个模型都包含一个截距项：\n   - 错误模型（包含对撞因子）：协变量 $\\{X, C\\}$。\n   - 正确模型（排除对撞因子）：协变量 $\\{X\\}$。\n3. 对于每个拟合的倾向性得分，使用有放回的最近邻匹配，并对倾向性得分的绝对差异设置一个卡尺（caliper）。具体来说：\n   - 对每个处理单元，在倾向性得分距离上找到最近的单个控制单元；如果距离小于或等于卡尺值，则将该配对纳入。\n   - 对每个控制单元，在倾向性得分距离上找到最近的单个处理单元；如果距离小于或等于卡尺值，则将该配对纳入。\n   - 通过对从两个方向形成的所有可用匹配对差异 $Y_{\\text{treated}} - Y_{\\text{control}}$ 进行平均，计算匹配后的平均处理效应估计值（这种对称匹配估计量近似于平均处理效应，而不仅仅是处理组的平均处理效应）。\n   - 如果没有配对满足卡尺条件，则在没有任何卡尺（即 caliper $= +\\infty$）的情况下重新运行最近邻匹配。\n4. 计算每个匹配估计量相对于真实ATE的偏差：\n   - 包含对撞因子的偏差：$b_{\\text{incl}} = \\widehat{\\text{ATE}}_{\\text{incl}} - \\beta_T$。\n   - 排除对撞因子的偏差：$b_{\\text{excl}} = \\widehat{\\text{ATE}}_{\\text{excl}} - \\beta_T$。\n   - 因包含对撞因子而产生的超额绝对偏差：$\\Delta = |b_{\\text{incl}}| - |b_{\\text{excl}}|$。\n5. 将所有测试用例的结果汇总到单行输出中，格式为逗号分隔的各用例三元组列表，其中每个三元组是一个方括号内的列表 $[b_{\\text{incl}}, b_{\\text{excl}}, \\Delta]$。完整的输出必须用方括号括起来。例如：$[[b_1^{\\text{incl}}, b_1^{\\text{excl}}, \\Delta_1],[b_2^{\\text{excl}}, b_2^{\\text{excl}}, \\Delta_2]]$。\n\n测试套件和参数：\n为以下四个测试用例实现该过程。使用指定的随机种子以确保可复现性。\n\n- 案例1（基线，中等强度对撞因子）：\n  - $N = 4000$, $\\alpha_0 = 0$, $\\alpha_U = 1.0$, $\\alpha_X = 0.5$, $\\beta_T = 2.0$, $\\beta_V = 1.0$, $\\beta_X = 0.0$, $\\gamma_U = 0.8$, $\\gamma_V = 0.8$, 卡尺 $= 0.05$, 种子 $= 42$。\n\n- 案例2（边界，无对撞因子效应）：\n  - $N = 4000$, $\\alpha_0 = 0$, $\\alpha_U = 1.0$, $\\alpha_X = 0.5$, $\\beta_T = 2.0$, $\\beta_V = 1.0$, $\\beta_X = 0.0$, $\\gamma_U = 0.0$, $\\gamma_V = 0.0$, 卡尺 $= 0.05$, 种子 $= 1$。\n\n- 案例3（强对撞因子影响）：\n  - $N = 4000$, $\\alpha_0 = 0$, $\\alpha_U = 1.2$, $\\alpha_X = 0.5$, $\\beta_T = 2.0$, $\\beta_V = 1.0$, $\\beta_X = 0.0$, $\\gamma_U = 2.5$, $\\gamma_V = 2.5$, 卡尺 $= 0.05$, 种子 $= 7$。\n\n- 案例4（小样本，中等强度对撞因子）：\n  - $N = 600$, $\\alpha_0 = 0$, $\\alpha_U = 1.0$, $\\alpha_X = 0.5$, $\\beta_T = 2.0$, $\\beta_V = 1.0$, $\\beta_X = 0.0$, $\\gamma_U = 1.0$, $\\gamma_V = 1.0$, 卡尺 $= 0.07$, 种子 $= 123$。\n\n最终输出格式：\n您的程序应生成单行输出，其中包含结果，格式为逗号分隔的各用例三元组列表，每个三元组本身是方括号内的逗号分隔列表，整个输出用方括号括起来。例如：$[[r_{11},r_{12},r_{13}],[r_{21},r_{22},r_{23}],[r_{31},r_{32},r_{33}],[r_{41},r_{42},r_{43}]]$。每个 $r_{ij}$ 必须是浮点数。",
            "solution": "问题陈述已经过验证，被认为是有效的。它提出了一个在因果推断和统计学习领域中结构良好、有科学依据的模拟练习。其目标是在倾向性得分匹配（PSM）的背景下，展示M偏差——一种因对对撞因子变量进行条件化而产生的特定类型的偏差。所有参数、模型和程序都已明确定义，从而可以实现可复现的计算解决方案。\n\n### 理论框架\n\n该问题植根于因果推断的潜在结果框架。目标是估计平均处理效应（ATE），定义为 $\\mathbb{E}[Y(1) - Y(0)]$，其中 $Y(1)$ 和 $Y(0)$ 分别是处理和控制下的潜在结果。数据生成过程（DGP）由一组与有向无环图（DAG）相对应的结构方程指定。该DAG的核心是“M型结构”：\n1. 一个未观测变量 $U$ 是处理 $T$ 的原因（$U \\rightarrow T$）。\n2. 另一个未观测变量 $V$ 是结果 $Y$ 的原因（$V \\rightarrow Y$）。\n3. $U$ 和 $V$ 是独立的，即它们之间没有路径。\n4. $U$ 和 $V$ 都是观测变量 $C$（即对撞因子）的原因（$U \\rightarrow C \\leftarrow V$）。\n\n在这种结构中，$T$ 和 $Y$ 并不通过涉及 $U$ 和 $V$ 的路径相关联，因为路径 $T \\leftarrow U \\rightarrow C \\leftarrow V \\rightarrow Y$ 被对撞因子 $C$ 阻断了。然而，如果以对撞因子 $C$ 为条件（例如，在回归模型中包含它），这条路径就会被打开，从而在 $U$ 和 $V$ 之间引入伪统计关联。处理原因（$U$）和结果原因（$V$）之间的这种伪关联，在 $T$ 和 $Y$ 之间产生了一种非因果的统计关联，从而导致对因果效应的估计产生偏差。\n\n指定的数据生成过程（DGP）如下：\n- 潜变量原因：$U \\sim \\mathcal{N}(0,1)$, $V \\sim \\mathcal{N}(0,1)$。\n- 观测协变量：$X \\sim \\mathcal{N}(0,1)$。\n- 对撞因子：$C = \\gamma_U U + \\gamma_V V + \\varepsilon_C$，其中 $\\varepsilon_C \\sim \\mathcal{N}(0,1)$。\n- 处理分配：$T \\sim \\text{Bernoulli}(\\text{logit}^{-1}(\\alpha_0 + \\alpha_U U + \\alpha_X X))$。\n- 结果：$Y = \\beta_T T + \\beta_V V + \\beta_X X + \\varepsilon_Y$，其中 $\\varepsilon_Y \\sim \\mathcal{N}(0,1)$。\n\n真实的ATE由系数 $\\beta_T$ 给出。变量 $X$ 作为处理的一个观测预测因子被包含在内（$X \\rightarrow T$）。在给定的测试用例中，$\\beta_X=0$，所以 $X$ 不是一个混杂因子（即，不存在开放的后门路径 $T \\leftarrow X \\rightarrow Y$）。尽管如此，将处理的预测因子包含在倾向性得分模型中是标准做法。“正确”的倾向性得分模型包含那些能阻断 $T$ 和 $Y$ 之间所有后门路径且不会打开新路径的预测因子。在这里，这意味着要对 $X$ 进行调整，但关键是不能对对撞因子 $C$ 进行调整。\n\n### 模拟与估计过程\n\n对于每个测试用例，执行以下步骤：\n\n1.  **数据生成**：根据结构方程和指定参数模拟一个包含 $N$ 个观测值的数据集。固定的随机种子确保了可复现性。变量 $U, V, X, \\varepsilon_C, \\varepsilon_Y$ 从标准正态分布中抽取。然后根据其定义构建对撞因子 $C$、二元处理变量 $T$ 和连续结果变量 $Y$。\n\n2.  **倾向性得分估计**：倾向性得分 $e(Z) = P(T=1|Z)$ 使用两种不同的逻辑回归模型进行估计，其中 $Z$ 是协变量集合。模型系数通过使用数值优化算法（BFGS）最大化对数似然函数来估计。\n    - **错误模型**：在协变量集合 $Z = \\{X, C\\}$ 中包含对撞因子 $C$。估计的倾向性得分为 $\\hat{e}_{\\text{incl}}(X, C)$。由于对对撞因子进行了条件化，预计该模型会产生有偏结果。\n    - **正确模型**：排除对撞因子，协变量集合为 $Z = \\{X\\}$。估计的倾向性得分为 $\\hat{e}_{\\text{excl}}(X)$。该模型避免了M偏差。\n\n3.  **通过匹配估计ATE**：对于两个估计出的倾向性得分，分别使用带卡尺和有放回的对称最近邻匹配来计算ATE的匹配估计值。\n    - **对称匹配**：为了估计ATE（而不是ATT或ATC），从两个方向寻找匹配。对每个处理单元，找到倾向性得分距离最近的控制单元。对称地，对每个控制单元，找到倾向性得分距离最近的处理单元。\n    - **卡尺**：仅当一对单元的倾向性得分绝对差在指定的卡尺值内时，才被视为有效匹配。\n    - **回退机制**：如果没有配对满足卡尺条件，则使用无限大的卡尺（即不考虑距离，直接寻找最近邻）重复该过程。\n    - **估计量**：ATE被估计为在两个匹配方向上找到的所有有效匹配对的结果差异 $Y_{\\text{treated}} - Y_{\\text{control}}$ 的简单算术平均值。\n\n4.  **偏差分析**：通过计算每个估计量的偏差来评估其性能，偏差即估计值与真实ATE（$\\beta_T$）之间的差异。\n    - 偏差（包含对撞因子）：$b_{\\text{incl}} = \\widehat{\\text{ATE}}_{\\text{incl}} - \\beta_T$。\n    - 偏差（排除对撞因子）：$b_{\\text{excl}} = \\widehat{\\text{ATE}}_{\\text{excl}} - \\beta_T$。\n    - 超额绝对偏差：$\\Delta = |b_{\\text{incl}}| - |b_{\\text{excl}}|$。正的 $\\Delta$ 值表明包含对撞因子放大了估计偏差，从而证明了M偏差的有害影响。\n\n预计模拟将显示，当对撞因子路径强度（$\\gamma_U, \\gamma_V$）非零时，$|b_{\\text{incl}}|$ 会显著大于 $|b_{\\text{excl}}|$，并且这个差异 $\\Delta$ 会随着对撞因子强度的增加而增大。当 $\\gamma_U = \\gamma_V = 0$ 时，M型结构不存在，两个模型都应产生相似的、低偏差的估计，从而导致 $\\Delta$ 接近于零。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.optimize import minimize\nfrom scipy.special import expit\n\ndef _logistic_regression(X_design, y_obs):\n    \"\"\"\n    Performs logistic regression using maximum likelihood estimation.\n    \"\"\"\n    def neg_log_likelihood(beta, X, y):\n        \"\"\"\n        Calculates the negative log-likelihood for a logistic model.\n        Uses np.logaddexp for numerical stability.\n        L = sum(y*z - log(1+exp(z))) where z = X @ beta\n        \"\"\"\n        linear_pred = X @ beta\n        log_likelihood = np.sum(y * linear_pred - np.logaddexp(0, linear_pred))\n        return -log_likelihood\n\n    initial_beta = np.zeros(X_design.shape[1])\n    result = minimize(\n        neg_log_likelihood,\n        initial_beta,\n        args=(X_design, y_obs),\n        method='BFGS'\n    )\n    return result.x\n\ndef _perform_matching(T, Y, ps, caliper):\n    \"\"\"\n    Performs symmetric nearest-neighbor matching and computes the ATE estimate.\n    \"\"\"\n    def find_matches(source_indices, target_indices, ps, T_full, Y_full, caliper_val):\n        \"\"\"Helper to find matches for a source group from a target group.\"\"\"\n        ps_source = ps[source_indices]\n        ps_target = ps[target_indices]\n        \n        # Sort target for efficient search\n        sort_map = np.argsort(ps_target)\n        ps_target_sorted = ps_target[sort_map]\n        \n        # Find insertion points for all source PSs into the sorted target PSs\n        insert_points = np.searchsorted(ps_target_sorted, ps_source)\n        \n        matched_diffs = []\n        for i, ps_s in enumerate(ps_source):\n            idx = insert_points[i]\n            \n            best_dist = np.inf\n            best_match_target_original_idx = -1\n\n            # Candidate 1: at insertion point\n            if idx  len(ps_target_sorted):\n                dist = np.abs(ps_s - ps_target_sorted[idx])\n                if dist  best_dist:\n                    best_dist = dist\n                    best_match_target_original_idx = target_indices[sort_map[idx]]\n\n            # Candidate 2: at insertion point - 1\n            if idx  0:\n                dist = np.abs(ps_s - ps_target_sorted[idx-1])\n                if dist  best_dist:\n                    best_dist = dist\n                    best_match_target_original_idx = target_indices[sort_map[idx-1]]\n\n            source_original_idx = source_indices[i]\n            if best_match_target_original_idx != -1 and best_dist = caliper_val:\n                if T_full[source_original_idx] == 1: # Source is treated\n                    y_diff = Y_full[source_original_idx] - Y_full[best_match_target_original_idx]\n                else: # Source is control\n                    y_diff = Y_full[best_match_target_original_idx] - Y_full[source_original_idx]\n                matched_diffs.append(y_diff)\n        return matched_diffs\n\n    treated_indices = np.where(T == 1)[0]\n    control_indices = np.where(T == 0)[0]\n\n    # Guard against empty treatment/control groups\n    if len(treated_indices) == 0 or len(control_indices) == 0:\n        return np.nan\n\n    # Run with the given caliper\n    all_diffs = []\n    # T - C matching\n    all_diffs.extend(find_matches(treated_indices, control_indices, ps, T, Y, caliper))\n    # C - T matching\n    all_diffs.extend(find_matches(control_indices, treated_indices, ps, T, Y, caliper))\n    \n    # If no matches found, re-run with infinite caliper\n    if not all_diffs:\n        all_diffs.extend(find_matches(treated_indices, control_indices, ps, T, Y, np.inf))\n        all_diffs.extend(find_matches(control_indices, treated_indices, ps, T, Y, np.inf))\n        \n    return np.mean(all_diffs) if all_diffs else np.nan\n\ndef solve():\n    \"\"\"\n    Main function to run the M-bias simulation across all test cases.\n    \"\"\"\n    test_cases = [\n        {'N': 4000, 'alpha_0': 0.0, 'alpha_U': 1.0, 'alpha_X': 0.5, 'beta_T': 2.0, \n         'beta_V': 1.0, 'beta_X': 0.0, 'gamma_U': 0.8, 'gamma_V': 0.8, \n         'caliper': 0.05, 'seed': 42},\n        {'N': 4000, 'alpha_0': 0.0, 'alpha_U': 1.0, 'alpha_X': 0.5, 'beta_T': 2.0, \n         'beta_V': 1.0, 'beta_X': 0.0, 'gamma_U': 0.0, 'gamma_V': 0.0, \n         'caliper': 0.05, 'seed': 1},\n        {'N': 4000, 'alpha_0': 0.0, 'alpha_U': 1.2, 'alpha_X': 0.5, 'beta_T': 2.0, \n         'beta_V': 1.0, 'beta_X': 0.0, 'gamma_U': 2.5, 'gamma_V': 2.5, \n         'caliper': 0.05, 'seed': 7},\n        {'N': 600, 'alpha_0': 0.0, 'alpha_U': 1.0, 'alpha_X': 0.5, 'beta_T': 2.0, \n         'beta_V': 1.0, 'beta_X': 0.0, 'gamma_U': 1.0, 'gamma_V': 1.0, \n         'caliper': 0.07, 'seed': 123}\n    ]\n\n    results = []\n    for params in test_cases:\n        # Set seed for reproducibility\n        rng = np.random.default_rng(params['seed'])\n        N = params['N']\n\n        # 1. Simulate data according to the DGP\n        U = rng.normal(size=N)\n        V = rng.normal(size=N)\n        X = rng.normal(size=N)\n        eps_C = rng.normal(size=N)\n        C = params['gamma_U'] * U + params['gamma_V'] * V + eps_C\n        \n        linear_pred_T = params['alpha_0'] + params['alpha_U'] * U + params['alpha_X'] * X\n        prob_T = expit(linear_pred_T)\n        T = rng.binomial(1, prob_T)\n        \n        eps_Y = rng.normal(size=N)\n        Y = params['beta_T'] * T + params['beta_V'] * V + params['beta_X'] * X + eps_Y\n\n        # 2. Estimate two propensity score models\n        # Incorrect model (including collider)\n        X_incl = np.c_[np.ones(N), X, C]\n        coeffs_incl = _logistic_regression(X_incl, T)\n        ps_incl = expit(X_incl @ coeffs_incl)\n\n        # Correct model (excluding collider)\n        X_excl = np.c_[np.ones(N), X]\n        coeffs_excl = _logistic_regression(X_excl, T)\n        ps_excl = expit(X_excl @ coeffs_excl)\n        \n        # 3. Perform matching and estimate ATE for both models\n        ate_incl = _perform_matching(T, Y, ps_incl, params['caliper'])\n        ate_excl = _perform_matching(T, Y, ps_excl, params['caliper'])\n        \n        # 4. Compute bias\n        true_ate = params['beta_T']\n        b_incl = ate_incl - true_ate\n        b_excl = ate_excl - true_ate\n        \n        # 5. Compute excess absolute bias\n        delta = np.abs(b_incl) - np.abs(b_excl)\n        \n        results.append([b_incl, b_excl, delta])\n\n    # Final print statement in the exact required format.\n    output_str = \",\".join([f\"[{r[0]},{r[1]},{r[2]}]\" for r in results])\n    print(f\"[{output_str}]\")\n\nsolve()\n```"
        }
    ]
}