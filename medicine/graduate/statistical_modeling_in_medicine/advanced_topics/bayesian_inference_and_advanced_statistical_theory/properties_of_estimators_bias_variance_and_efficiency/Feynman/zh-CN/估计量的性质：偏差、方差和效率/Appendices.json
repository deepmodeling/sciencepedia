{
    "hands_on_practices": [
        {
            "introduction": "本练习探讨了一个经典问题：为什么我们在计算样本方差时要除以 $n-1$？我们将直接计算方差的最大似然估计量 (MLE) 的偏差，并将其均方误差 (MSE) 与无偏估计量进行比较。这个过程为了解统计建模中的核心概念——偏差-方差权衡——提供了一个具体的例子 ()。",
            "id": "4831014",
            "problem": "一个生物统计学团队在分析独立患者中连续生物标志物的变异性时，假设重复测量值 $X_{1},\\dots,X_{n}$ 是来自正态分布 $N(\\mu,\\sigma^{2})$ 的独立同分布样本，其中均值 $\\mu$ 和方差 $\\sigma^{2}$ 未知。考虑方差的两个估计量：最大似然估计量 (MLE)，定义为 $\\hat{\\sigma}^{2}_{\\mathrm{MLE}}=\\frac{1}{n}\\sum_{i=1}^{n}\\left(X_{i}-\\bar{X}\\right)^{2}$，以及分母为 $n-1$ 的无偏样本方差，定义为 $\\hat{\\sigma}^{2}_{U}=\\frac{1}{n-1}\\sum_{i=1}^{n}\\left(X_{i}-\\bar{X}\\right)^{2}$，其中 $\\bar{X}=\\frac{1}{n}\\sum_{i=1}^{n}X_{i}$。从偏差、方差和均方误差的定义出发，并利用正态模型的标准分布性质（特别是中心化正态变量平方和的缩放形式服从的卡方分布），推导 $\\hat{\\sigma}^{2}_{\\mathrm{MLE}}$ 作为 $n$ 和 $\\sigma^{2}$ 函数的精确有限样本偏差。然后，对于有限的 $n$，比较 $\\hat{\\sigma}^{2}_{\\mathrm{MLE}}$ 与 $\\hat{\\sigma}^{2}_{U}$ 的均方误差，并讨论在均方误差意义下哪个估计量更有效，以及当 $n\\to\\infty$ 时两个估计量是否都具有一致性。仅报告 $\\hat{\\sigma}^{2}_{\\mathrm{MLE}}$ 的精确有限样本偏差作为你的最终答案。无需四舍五入。",
            "solution": "该问题是有效的，因为它具有科学依据、提法明确、客观且完整。这是数理统计中一个关于正态分布方差估计量性质的标准问题。我们开始求解。\n\n设重复测量值为 $X_{1}, \\dots, X_{n}$，它们是来自正态分布 $N(\\mu, \\sigma^{2})$ 的独立同分布 (i.i.d.) 随机变量。样本均值为 $\\bar{X} = \\frac{1}{n}\\sum_{i=1}^{n}X_{i}$。\n\n方差 $\\sigma^{2}$ 的两个估计量如下：\n1. 最大似然估计量 (MLE): $\\hat{\\sigma}^{2}_{\\mathrm{MLE}} = \\frac{1}{n}\\sum_{i=1}^{n}(X_{i} - \\bar{X})^{2}$。\n2. 无偏样本方差: $\\hat{\\sigma}^{2}_{U} = \\frac{1}{n-1}\\sum_{i=1}^{n}(X_{i} - \\bar{X})^{2}$。\n\n我们将根据这些估计量的偏差、方差、均方误差 (MSE) 和一致性来分析它们。参数 $\\theta$ 的估计量 $\\hat{\\theta}$ 的偏差定义为 $\\mathrm{Bias}(\\hat{\\theta}) = E[\\hat{\\theta}] - \\theta$。MSE 定义为 $\\mathrm{MSE}(\\hat{\\theta}) = E[(\\hat{\\theta} - \\theta)^{2}]$，可以分解为 $\\mathrm{MSE}(\\hat{\\theta}) = \\mathrm{Var}(\\hat{\\theta}) + (\\mathrm{Bias}(\\hat{\\theta}))^{2}$。\n\n统计理论中关于正态分布样本的一个基本结果（具体来说，是 Cochran 定理的一个推论）是，量 $\\frac{1}{\\sigma^{2}}\\sum_{i=1}^{n}(X_{i} - \\bar{X})^{2}$ 服从自由度为 $n-1$ 的卡方分布。我们将其记为：\n$$ \\frac{\\sum_{i=1}^{n}(X_{i} - \\bar{X})^{2}}{\\sigma^{2}} \\sim \\chi^{2}_{n-1} $$\n一个服从自由度为 $k$ 的卡方分布的随机变量 $Y \\sim \\chi^{2}_{k}$，其期望值为 $E[Y] = k$，方差为 $\\mathrm{Var}(Y) = 2k$。\n\n首先，我们推导 $\\hat{\\sigma}^{2}_{\\mathrm{MLE}}$ 的精确有限样本偏差。为此，我们首先计算其期望值。\n$$ E[\\hat{\\sigma}^{2}_{\\mathrm{MLE}}] = E\\left[\\frac{1}{n}\\sum_{i=1}^{n}(X_{i} - \\bar{X})^{2}\\right] = \\frac{1}{n}E\\left[\\sum_{i=1}^{n}(X_{i} - \\bar{X})^{2}\\right] $$\n我们可以用服从 $\\chi^{2}_{n-1}$ 分布的变量来重写平方和：\n$$ \\sum_{i=1}^{n}(X_{i} - \\bar{X})^{2} = \\sigma^{2} \\left( \\frac{\\sum_{i=1}^{n}(X_{i} - \\bar{X})^{2}}{\\sigma^{2}} \\right) $$\n该和的期望值为：\n$$ E\\left[\\sum_{i=1}^{n}(X_{i} - \\bar{X})^{2}\\right] = \\sigma^{2} E\\left[ \\frac{\\sum_{i=1}^{n}(X_{i} - \\bar{X})^{2}}{\\sigma^{2}} \\right] = \\sigma^{2} (n-1) $$\n因为一个 $\\chi^{2}_{n-1}$ 变量的期望值是其自由度 $n-1$。\n将此结果代回 $E[\\hat{\\sigma}^{2}_{\\mathrm{MLE}}]$ 的表达式中：\n$$ E[\\hat{\\sigma}^{2}_{\\mathrm{MLE}}] = \\frac{1}{n} (n-1)\\sigma^{2} = \\frac{n-1}{n}\\sigma^{2} $$\n因此，$\\hat{\\sigma}^{2}_{\\mathrm{MLE}}$ 的偏差是：\n$$ \\mathrm{Bias}(\\hat{\\sigma}^{2}_{\\mathrm{MLE}}) = E[\\hat{\\sigma}^{2}_{\\mathrm{MLE}}] - \\sigma^{2} = \\frac{n-1}{n}\\sigma^{2} - \\sigma^{2} = \\left(\\frac{n-1}{n} - 1\\right)\\sigma^{2} = -\\frac{1}{n}\\sigma^{2} $$\n这就是所求的 MLE 的有限样本偏差。它是一个有偏估计量，平均而言会低估真实方差。\n\n接下来，我们比较 $\\hat{\\sigma}^{2}_{\\mathrm{MLE}}$ 和 $\\hat{\\sigma}^{2}_{U}$ 的均方误差 (MSE)。\n首先，我们验证 $\\hat{\\sigma}^{2}_{U}$ 的无偏性：\n$$ E[\\hat{\\sigma}^{2}_{U}] = E\\left[\\frac{1}{n-1}\\sum_{i=1}^{n}(X_{i} - \\bar{X})^{2}\\right] = \\frac{1}{n-1}E\\left[\\sum_{i=1}^{n}(X_{i} - \\bar{X})^{2}\\right] = \\frac{1}{n-1}(n-1)\\sigma^{2} = \\sigma^{2} $$\n由于 $E[\\hat{\\sigma}^{2}_{U}] = \\sigma^{2}$，其偏差为 $\\mathrm{Bias}(\\hat{\\sigma}^{2}_{U}) = 0$。\n\n为了计算 MSE，我们需要估计量的方差。我们利用 $\\mathrm{Var}(\\chi^{2}_{k}) = 2k$ 这个事实。\n$\\hat{\\sigma}^{2}_{U}$ 的方差是：\n$$ \\mathrm{Var}(\\hat{\\sigma}^{2}_{U}) = \\mathrm{Var}\\left(\\frac{1}{n-1}\\sum_{i=1}^{n}(X_{i} - \\bar{X})^{2}\\right) = \\mathrm{Var}\\left(\\frac{\\sigma^{2}}{n-1} \\cdot \\frac{\\sum_{i=1}^{n}(X_{i} - \\bar{X})^{2}}{\\sigma^{2}}\\right) $$\n$$ \\mathrm{Var}(\\hat{\\sigma}^{2}_{U}) = \\left(\\frac{\\sigma^{2}}{n-1}\\right)^{2} \\mathrm{Var}(\\chi^{2}_{n-1}) = \\frac{\\sigma^{4}}{(n-1)^{2}} \\cdot 2(n-1) = \\frac{2\\sigma^{4}}{n-1} $$\n由于 $\\hat{\\sigma}^{2}_{U}$ 是无偏的，其 MSE 等于其方差：\n$$ \\mathrm{MSE}(\\hat{\\sigma}^{2}_{U}) = \\mathrm{Var}(\\hat{\\sigma}^{2}_{U}) + (\\mathrm{Bias}(\\hat{\\sigma}^{2}_{U}))^{2} = \\frac{2\\sigma^{4}}{n-1} + 0^{2} = \\frac{2\\sigma^{4}}{n-1} $$\n\n现在来看 $\\hat{\\sigma}^{2}_{\\mathrm{MLE}}$。注意 $\\hat{\\sigma}^{2}_{\\mathrm{MLE}} = \\frac{n-1}{n}\\hat{\\sigma}^{2}_{U}$。\n$\\hat{\\sigma}^{2}_{\\mathrm{MLE}}$ 的方差是：\n$$ \\mathrm{Var}(\\hat{\\sigma}^{2}_{\\mathrm{MLE}}) = \\mathrm{Var}\\left(\\frac{n-1}{n}\\hat{\\sigma}^{2}_{U}\\right) = \\left(\\frac{n-1}{n}\\right)^{2} \\mathrm{Var}(\\hat{\\sigma}^{2}_{U}) = \\frac{(n-1)^{2}}{n^{2}} \\cdot \\frac{2\\sigma^{4}}{n-1} = \\frac{2(n-1)\\sigma^{4}}{n^{2}} $$\n$\\hat{\\sigma}^{2}_{\\mathrm{MLE}}$ 的 MSE 是其方差与偏差平方之和：\n$$ \\mathrm{MSE}(\\hat{\\sigma}^{2}_{\\mathrm{MLE}}) = \\mathrm{Var}(\\hat{\\sigma}^{2}_{\\mathrm{MLE}}) + (\\mathrm{Bias}(\\hat{\\sigma}^{2}_{\\mathrm{MLE}}))^{2} = \\frac{2(n-1)\\sigma^{4}}{n^{2}} + \\left(-\\frac{\\sigma^{2}}{n}\\right)^{2} $$\n$$ \\mathrm{MSE}(\\hat{\\sigma}^{2}_{\\mathrm{MLE}}) = \\frac{2(n-1)\\sigma^{4}}{n^{2}} + \\frac{\\sigma^{4}}{n^{2}} = \\frac{(2n - 2 + 1)\\sigma^{4}}{n^{2}} = \\frac{(2n-1)\\sigma^{4}}{n^{2}} $$\n为了比较 MSE，我们考察当 $n \\ge 2$ 时的差值 $\\mathrm{MSE}(\\hat{\\sigma}^{2}_{U}) - \\mathrm{MSE}(\\hat{\\sigma}^{2}_{\\mathrm{MLE}})$：\n$$ \\frac{2\\sigma^{4}}{n-1} - \\frac{(2n-1)\\sigma^{4}}{n^{2}} = \\sigma^{4}\\left(\\frac{2}{n-1} - \\frac{2n-1}{n^{2}}\\right) = \\sigma^{4}\\left(\\frac{2n^{2} - (2n-1)(n-1)}{n^{2}(n-1)}\\right) $$\n$$ = \\sigma^{4}\\left(\\frac{2n^{2} - (2n^{2} - 3n + 1)}{n^{2}(n-1)}\\right) = \\sigma^{4}\\left(\\frac{3n - 1}{n^{2}(n-1)}\\right) $$\n对于任何样本大小 $n \\ge 2$，$\\frac{3n-1}{n^{2}(n-1)}$ 这一项是严格为正的。因此，$\\mathrm{MSE}(\\hat{\\sigma}^{2}_{U}) > \\mathrm{MSE}(\\hat{\\sigma}^{2}_{\\mathrm{MLE}})$。这表明对于任何有限样本大小，$\\hat{\\sigma}^{2}_{\\mathrm{MLE}}$ 的均方误差都小于 $\\hat{\\sigma}^{2}_{U}$。在 MSE 意义上，$\\hat{\\sigma}^{2}_{\\mathrm{MLE}}$ 是更有效的估计量。这说明了经典的偏差-方差权衡：通过接受一个小的偏差，MLE 获得了更低的方差，从而导致整体上更小的 MSE。\n\n最后，我们讨论一致性。如果一个估计量 $\\hat{\\theta}_{n}$ 当 $n \\to \\infty$ 时依概率收敛于 $\\theta$，则称其对于 $\\theta$ 是一致的。一致性的一个充分条件是当 $n \\to \\infty$ 时，偏差和方差都趋于零。\n对于 $\\hat{\\sigma}^{2}_{\\mathrm{MLE}}$：\n$$ \\lim_{n\\to\\infty} \\mathrm{Bias}(\\hat{\\sigma}^{2}_{\\mathrm{MLE}}) = \\lim_{n\\to\\infty} \\left(-\\frac{\\sigma^{2}}{n}\\right) = 0 $$\n$$ \\lim_{n\\to\\infty} \\mathrm{Var}(\\hat{\\sigma}^{2}_{\\mathrm{MLE}}) = \\lim_{n\\to\\infty} \\frac{2(n-1)\\sigma^{4}}{n^{2}} = \\lim_{n\\to\\infty} \\left(\\frac{2\\sigma^{4}}{n} - \\frac{2\\sigma^{4}}{n^{2}}\\right) = 0 $$\n由于其偏差和方差都趋于零，$\\hat{\\sigma}^{2}_{\\mathrm{MLE}}$ 是 $\\sigma^{2}$ 的一个一致估计量。\n\n对于 $\\hat{\\sigma}^{2}_{U}$：\n$$ \\lim_{n\\to\\infty} \\mathrm{Bias}(\\hat{\\sigma}^{2}_{U}) = \\lim_{n\\to\\infty} 0 = 0 $$\n$$ \\lim_{n\\to\\infty} \\mathrm{Var}(\\hat{\\sigma}^{2}_{U}) = \\lim_{n\\to\\infty} \\frac{2\\sigma^{4}}{n-1} = 0 $$\n由于其偏差恒为零且方差趋于零，$\\hat{\\sigma}^{2}_{U}$ 也是 $\\sigma^{2}$ 的一个一致估计量。\n\n因此，两个估计量都是一致的。渐近地，当 $n \\to \\infty$ 时，联系这两个估计量的因子 $\\frac{n-1}{n}$ 趋近于1，因此它们变得等价。",
            "answer": "$$\\boxed{-\\frac{\\sigma^{2}}{n}}$$"
        },
        {
            "introduction": "即使我们从一个无偏估计量开始，对其应用一个非线性函数通常也会导致对转换后参数的估计产生偏差。本练习将通过对数优势比（logit）变换来展示这一重要原理，该变换在逻辑回归中至关重要 ()。我们将使用泰勒级数展开来近似计算偏差，这是一种被称为“德尔塔方法”的广泛应用技术。",
            "id": "4981389",
            "problem": "一项医疗安全监测研究跟踪 $n$ 名独立患者在固定的随访期内是否各自经历了一次二元不良事件。设 $X_1,\\dots,X_n$ 是独立同分布的随机变量，且 $X_i \\sim \\text{Bernoulli}(p)$，其中 $p \\in (0,1)$ 是不良事件的真实概率。用于下游风险沟通的目标参数是对数优势比 $\\theta = \\ln\\!\\big(p/(1-p)\\big)$。最大似然估计量 (MLE) 是 $\\hat{p} = \\bar{X} = n^{-1} \\sum_{i=1}^{n} X_i$，对数优势比的插入式估计量是 $\\hat{\\theta} = \\ln\\!\\big(\\hat{p}/(1-\\hat{p})\\big)$。\n\n任务：\n1. 从期望和独立性的定义出发，证明 $\\hat{p}$ 是 $p$ 的无偏估计量。\n2. 假设 $p \\in (0,1)$ 且仅考虑事件 $\\{0  \\hat{p}  1\\}$ 以确保 $\\hat{\\theta}$ 有明确定义；注意，对于固定的 $p \\in (0,1)$，当 $n \\to \\infty$ 时，$\\mathbb{P}(0  \\hat{p}  1) \\to 1$。通过将变换 $g(x) = \\ln\\!\\big(x/(1-x)\\big)$ 在 $x=p$ 周围展开至二阶，并使用期望中的主非零项，推导出截至 $1/n$ 阶的主阶渐近偏差 $\\mathbb{E}[\\hat{\\theta}] - \\theta$，并将其明确表示为 $p$ 和 $n$ 的符号函数。\n\n请提供一个关于 $p$ 和 $n$ 的单一闭式解析表达式作为主阶渐近偏差的最终答案。无需进行数值四舍五入，也不涉及单位。",
            "solution": "问题陈述已经过验证，被认为是统计理论中一个有效的、适定的问题。它具有科学依据，内容自洽且客观。因此，我们可以进行完整解答。\n\n该问题分为两个任务。我们将按顺序解决它们。\n\n**任务1：证明 $\\hat{p}$ 是 $p$ 的无偏估计量。**\n\n如果一个估计量的期望值等于真实的参数值，则该估计量是无偏的。在这里，我们必须证明 $\\mathbb{E}[\\hat{p}] = p$。\n\n$p$ 的估计量由样本均值给出，即 $\\hat{p} = \\bar{X} = n^{-1} \\sum_{i=1}^{n} X_i$。\n$\\hat{p}$ 的期望是：\n$$\n\\mathbb{E}[\\hat{p}] = \\mathbb{E}\\left[\\frac{1}{n} \\sum_{i=1}^{n} X_i\\right]\n$$\n根据期望算子的线性性质，我们可以将常数因子 $1/n$ 和求和符号移到期望之外：\n$$\n\\mathbb{E}[\\hat{p}] = \\frac{1}{n} \\sum_{i=1}^{n} \\mathbb{E}[X_i]\n$$\n问题陈述指出 $X_1, \\dots, X_n$ 是来自参数为 $p$ 的伯努利分布的独立同分布 (i.i.d.) 随机变量，即 $X_i \\sim \\text{Bernoulli}(p)$。对于伯努利随机变量，其概率质量函数为 $\\mathbb{P}(X_i = 1) = p$ 和 $\\mathbb{P}(X_i = 0) = 1-p$。根据定义，每个 $X_i$ 的期望值为：\n$$\n\\mathbb{E}[X_i] = 1 \\cdot \\mathbb{P}(X_i = 1) + 0 \\cdot \\mathbb{P}(X_i = 0) = 1 \\cdot p + 0 \\cdot (1-p) = p\n$$\n由于所有的 $X_i$ 都是同分布的，所以对于所有 $i \\in \\{1, \\dots, n\\}$，都有 $\\mathbb{E}[X_i] = p$。将此结果代入 $\\mathbb{E}[\\hat{p}]$ 的表达式中：\n$$\n\\mathbb{E}[\\hat{p}] = \\frac{1}{n} \\sum_{i=1}^{n} p\n$$\n该和包含 $n$ 个相同的项 $p$，所以 $\\sum_{i=1}^{n} p = n p$。\n$$\n\\mathbb{E}[\\hat{p}] = \\frac{1}{n} (n p) = p\n$$\n由于 $\\mathbb{E}[\\hat{p}] = p$，根据定义，估计量 $\\hat{p}$ 是参数 $p$ 的无偏估计量。这就完成了第一个任务。\n\n**任务2：推导 $\\hat{\\theta}$ 的主阶渐近偏差。**\n\n目标参数是对数优势比 $\\theta = \\ln(p/(1-p))$，其估计量是 $\\hat{\\theta} = \\ln(\\hat{p}/(1-\\hat{p}))$。这可以写成 $\\hat{\\theta} = g(\\hat{p})$，其中变换函数是 $g(x) = \\ln(x/(1-x))$。\n\n$\\hat{\\theta}$ 的偏差定义为 $\\text{Bias}(\\hat{\\theta}) = \\mathbb{E}[\\hat{\\theta}] - \\theta$。为了找到此偏差的渐近表达式，我们使用函数 $g(\\hat{p})$ 在点 $\\hat{p} = p$ 附近的泰勒级数展开。问题指定展开到二阶。\n$$\ng(\\hat{p}) \\approx g(p) + g'(p)(\\hat{p}-p) + \\frac{1}{2}g''(p)(\\hat{p}-p)^2\n$$\n首先，我们必须求出 $g(x) = \\ln(x) - \\ln(1-x)$ 的一阶和二阶导数。\n一阶导数是：\n$$\ng'(x) = \\frac{d}{dx} [\\ln(x) - \\ln(1-x)] = \\frac{1}{x} - \\frac{1}{1-x}(-1) = \\frac{1}{x} + \\frac{1}{1-x} = \\frac{(1-x)+x}{x(1-x)} = \\frac{1}{x(1-x)}\n$$\n二阶导数是：\n$$\ng''(x) = \\frac{d}{dx} [x^{-1} + (1-x)^{-1}] = -x^{-2} + (-1)(1-x)^{-2}(-1) = -x^{-2} + (1-x)^{-2} = \\frac{1}{(1-x)^2} - \\frac{1}{x^2}\n$$\n合并 $g''(x)$ 的项：\n$$\ng''(x) = \\frac{x^2 - (1-x)^2}{x^2(1-x)^2} = \\frac{x^2 - (1 - 2x + x^2)}{x^2(1-x)^2} = \\frac{2x-1}{x^2(1-x)^2}\n$$\n现在，我们在 $x=p$ 处计算这些导数的值：\n- $g(p) = \\ln(p/(1-p)) = \\theta$\n- $g'(p) = \\frac{1}{p(1-p)}$\n- $g''(p) = \\frac{2p-1}{p^2(1-p)^2}$\n\n将这些代入泰勒展开式得到：\n$$\n\\hat{\\theta} = g(\\hat{p}) \\approx \\theta + \\left(\\frac{1}{p(1-p)}\\right)(\\hat{p}-p) + \\frac{1}{2}\\left(\\frac{2p-1}{p^2(1-p)^2}\\right)(\\hat{p}-p)^2\n$$\n为了求 $\\hat{\\theta}$ 的近似期望值，我们对这个表达式取期望。问题假设我们在事件 $\\{0  \\hat{p}  1\\}$ 上，在该事件上 $\\hat{\\theta}$ 有明确定义。\n$$\n\\mathbb{E}[\\hat{\\theta}] \\approx \\mathbb{E}\\left[\\theta + \\frac{1}{p(1-p)}(\\hat{p}-p) + \\frac{2p-1}{2p^2(1-p)^2}(\\hat{p}-p)^2\\right]\n$$\n利用期望的线性性质：\n$$\n\\mathbb{E}[\\hat{\\theta}] \\approx \\theta + \\frac{1}{p(1-p)}\\mathbb{E}[\\hat{p}-p] + \\frac{2p-1}{2p^2(1-p)^2}\\mathbb{E}[(\\hat{p}-p)^2]\n$$\n我们需要计算这两个期望项：\n- $\\mathbb{E}[\\hat{p}-p]$ 是 $\\hat{p}$ 的偏差。如任务1所示，$\\hat{p}$ 是无偏的，所以 $\\mathbb{E}[\\hat{p}] = p$。因此，$\\mathbb{E}[\\hat{p}-p] = \\mathbb{E}[\\hat{p}] - p = p - p = 0$。\n- 根据定义，$\\mathbb{E}[(\\hat{p}-p)^2]$ 是 $\\hat{p}$ 的方差，记作 $\\text{Var}(\\hat{p})$，因为它的均值是 $p$。\n\n我们现在计算 $\\text{Var}(\\hat{p})$：\n$$\n\\text{Var}(\\hat{p}) = \\text{Var}\\left(\\frac{1}{n} \\sum_{i=1}^{n} X_i\\right) = \\frac{1}{n^2} \\text{Var}\\left(\\sum_{i=1}^{n} X_i\\right)\n$$\n由于 $X_i$ 是独立的，和的方差是方差的和：\n$$\n\\text{Var}(\\hat{p}) = \\frac{1}{n^2} \\sum_{i=1}^{n} \\text{Var}(X_i)\n$$\n对于伯努利($p$)变量，方差为 $\\text{Var}(X_i) = p(1-p)$。由于这些变量是同分布的：\n$$\n\\text{Var}(\\hat{p}) = \\frac{1}{n^2} \\sum_{i=1}^{n} p(1-p) = \\frac{1}{n^2} [n p(1-p)] = \\frac{p(1-p)}{n}\n$$\n将这些结果代回 $\\mathbb{E}[\\hat{\\theta}]$ 的近似表达式中：\n$$\n\\mathbb{E}[\\hat{\\theta}] \\approx \\theta + \\frac{1}{p(1-p)}(0) + \\frac{2p-1}{2p^2(1-p)^2}\\left(\\frac{p(1-p)}{n}\\right)\n$$\n简化第二项：\n$$\n\\mathbb{E}[\\hat{\\theta}] \\approx \\theta + \\frac{(2p-1)p(1-p)}{2n p^2(1-p)^2} = \\theta + \\frac{2p-1}{2n p(1-p)}\n$$\n渐近偏差是 $\\mathbb{E}[\\hat{\\theta}] - \\theta$。从上面的表达式中，我们找到偏差的主阶项：\n$$\n\\text{Bias}(\\hat{\\theta}) = \\mathbb{E}[\\hat{\\theta}] - \\theta \\approx \\frac{2p-1}{2np(1-p)}\n$$\n这个表达式是 $1/n$ 阶的。泰勒展开中的高阶项，例如涉及 $\\mathbb{E}[(\\hat{p}-p)^3]$ 的项，将贡献 $1/n^2$ 阶或更小阶的项，这证实了我们得到的是主阶渐近偏差。\n\n所要求的最终答案是这个主阶渐近偏差的闭式解析表达式。",
            "answer": "$$\n\\boxed{\\frac{2p-1}{2np(1-p)}}\n$$"
        },
        {
            "introduction": "当我们面对一个有偏的估计量时，尤其是一个形式复杂（如比率）的估计量，我们能否系统地校正其偏差？本练习介绍了刀切法 (jackknife)，这是一种功能强大的重采样技术，可用于估计和减少偏差 ()。你将推导出一个比率的刀切法偏差校正估计量，这在卫生经济学等领域是一种常见的统计量。",
            "id": "4981405",
            "problem": "一个卫生经济学团队正在分析来自多中心观察性队列的患者层面数据，以估计一项新的慢性病管理计划的增量成本效果比（ICER）。对于每位患者 $i \\in \\{1,\\dots,n\\}$，令 $C_{i} \\in (0,\\infty)$ 表示年总医疗成本，令 $Q_{i} \\in (0,\\infty)$ 表示以质量调整生命年（QALY）衡量的相应年效果。假设 $\\{(C_{i},Q_{i})\\}_{i=1}^{n}$ 是从一个具有有限二阶矩和严格正均值的联合分布中抽取的独立同分布样本。考虑平滑统计量\n$$\n\\hat{\\theta} \\;=\\; \\frac{\\bar{C}}{\\bar{Q}}, \\quad \\text{其中} \\quad \\bar{C} \\;=\\; \\frac{1}{n}\\sum_{i=1}^{n} C_{i}, \\quad \\bar{Q} \\;=\\; \\frac{1}{n}\\sum_{i=1}^{n} Q_{i}.\n$$\n科学目标是在上述假设下，降低 $\\hat{\\theta}$ 的主阶偏差，同时保持其一致性和一阶有效性。\n\n定义留一法均值\n$$\n\\bar{C}_{(i)} \\;=\\; \\frac{1}{n-1}\\sum_{\\substack{j=1 \\\\ j \\neq i}}^{n} C_{j}, \n\\qquad\n\\bar{Q}_{(i)} \\;=\\; \\frac{1}{n-1}\\sum_{\\substack{j=1 \\\\ j \\neq i}}^{n} Q_{j},\n$$\n及相关的留一法重抽样样本\n$$\n\\hat{\\theta}_{(i)} \\;=\\; \\frac{\\bar{C}_{(i)}}{\\bar{Q}_{(i)}}, \n\\qquad\n\\bar{\\hat{\\theta}}_{(\\cdot)} \\;=\\; \\frac{1}{n}\\sum_{i=1}^{n} \\hat{\\theta}_{(i)}.\n$$\n从偏差的定义和统计量映射 $(\\bar{C},\\bar{Q}) \\mapsto \\bar{C}/\\bar{Q}$ 的平滑性出发，用 $n$、$\\hat{\\theta}$ 和 $\\hat{\\theta}_{(i)}$ 来推导 $\\hat{\\theta}$ 的 $\\mathcal{O}(n^{-1})$ 阶偏差的刀切法估计。然后，使用此偏差估计来构建刀切法偏差校正估计量 $\\hat{\\theta}_{JK}$。将您的最终估计量表示为包含 $n$、$\\hat{\\theta}$ 和 $\\{\\hat{\\theta}_{(i)}\\}_{i=1}^{n}$ 的单一闭式解析表达式。不需要数值近似；在最终答案框中提供不含单位的精确表达式。",
            "solution": "用户希望推导比率统计量的刀切法偏差校正估计量。\n\n### 步骤1：提取已知条件\n- 数据：$\\{(C_{i},Q_{i})\\}_{i=1}^{n}$ 是独立同分布（i.i.d.）的随机变量。\n- 定义域：$C_{i} \\in (0,\\infty)$, $Q_{i} \\in (0,\\infty)$。\n- 矩：联合分布具有有限二阶矩。均值 $\\mu_C = E[C_i]$ 和 $\\mu_Q = E[Q_i]$ 严格为正。\n- 目标估计量：$\\hat{\\theta} \\;=\\; \\frac{\\bar{C}}{\\bar{Q}}$，其中 $\\bar{C} \\;=\\; \\frac{1}{n}\\sum_{i=1}^{n} C_{i}$ 且 $\\bar{Q} \\;=\\; \\frac{1}{n}\\sum_{i=1}^{n} Q_{i}$。\n- 留一法均值：$\\bar{C}_{(i)} \\;=\\; \\frac{1}{n-1}\\sum_{j \\neq i} C_{j}$ 且 $\\bar{Q}_{(i)} \\;=\\; \\frac{1}{n-1}\\sum_{j \\neq i} Q_{j}$。\n- 留一法重抽样样本：$\\hat{\\theta}_{(i)} \\;=\\; \\frac{\\bar{C}_{(i)}}{\\bar{Q}_{(i)}}$。\n- 重抽样样本均值：$\\bar{\\hat{\\theta}}_{(\\cdot)} \\;=\\; \\frac{1}{n}\\sum_{i=1}^{n} \\hat{\\theta}_{(i)}$。\n- 任务：推导 $\\hat{\\theta}$ 的 $\\mathcal{O}(n^{-1})$ 阶偏差的刀切法估计，并用它来构建刀切法偏差校正估计量 $\\hat{\\theta}_{JK}$。\n\n### 步骤2：使用提取的已知条件进行验证\n- **科学依据**：该问题在统计理论中有充分的依据，特别是在用于估计量偏差-方差分析的重抽样方法领域。刀切法是一种标准的、严格定义的技术。其应用背景——在卫生经济学中估计增量成本效果比（ICER）——是比率估计量及其偏差校正的常见且适当的用例。\n- **适定性**：该问题是适定的。所有术语都有数学定义。假设（独立同分布抽样、有限二阶矩、正均值）是标准的，并且足以进行所需的理论推导（例如，确保泰勒级数展开和大数定律的有效性）。目标是推导一个具有唯一解的特定公式。\n- **客观性**：该问题以精确、客观的数学语言陈述，没有任何主观或模棱两可的主张。\n\n该问题不违反任何无效性标准。它是数理统计学中的一个标准且正式的问题。\n\n### 步骤3：结论与行动\n该问题是有效的。现在开始求解过程。\n\n### 刀切法估计量的推导\n\n目标参数是真实均值的比率，$\\theta = \\frac{\\mu_C}{\\mu_Q} = \\frac{E[C_i]}{E[Q_i]}$。估计量 $\\hat{\\theta} = \\bar{C}/\\bar{Q}$ 是样本均值的函数。由于比率函数 $f(x,y)=x/y$ 的非线性，估计量的期望不等于期望的函数，即 $E[\\hat{\\theta}] \\neq E[\\bar{C}]/E[\\bar{Q}] = \\mu_C/\\mu_Q$。这种差异导致了偏差。\n\n对于像 $\\hat{\\theta}$ 这样基于样本量为 $n$ 的平滑统计量，其偏差可以通过 $n^{-1}$ 的幂次渐近展开式表示：\n$$\n\\text{Bias}(\\hat{\\theta}) = E[\\hat{\\theta}] - \\theta = \\frac{b_1}{n} + \\frac{b_2}{n^2} + \\mathcal{O}(n^{-3})\n$$\n其中 $b_1, b_2, \\dots$ 是依赖于 $(C_i, Q_i)$ 基础分布的矩但不依赖于 $n$ 的常数。目标是估计并移除主阶偏差项 $\\frac{b_1}{n}$。\n\n刀切法程序通过每次系统地剔除一个观测值来生成估计量的重抽样样本 $\\hat{\\theta}_{(i)}$。每个 $\\hat{\\theta}_{(i)}$ 都是基于样本量为 $n-1$ 的 $\\theta$ 的估计量。因此，其偏差具有相同的函数形式，只是将 $n$ 替换为 $n-1$：\n$$\n\\text{Bias}(\\hat{\\theta}_{(i)}) = E[\\hat{\\theta}_{(i)}] - \\theta = \\frac{b_1}{n-1} + \\frac{b_2}{(n-1)^2} + \\mathcal{O}((n-1)^{-3})\n$$\n由于原始数据 $\\{ (C_i, Q_i) \\}_{i=1}^n$ 是独立同分布的，所以所有留一法统计量 $\\hat{\\theta}_{(i)}$ 都是同分布的。因此，它们的期望都相等。\n\n让我们考虑这些重抽样样本的均值 $\\bar{\\hat{\\theta}}_{(\\cdot)}$ 的期望：\n$$\nE[\\bar{\\hat{\\theta}}_{(\\cdot)}] = E\\left[\\frac{1}{n}\\sum_{i=1}^{n} \\hat{\\theta}_{(i)}\\right] = \\frac{1}{n}\\sum_{i=1}^{n} E[\\hat{\\theta}_{(i)}] = E[\\hat{\\theta}_{(1)}]\n$$\n代入偏差展开式，我们得到：\n$$\nE[\\bar{\\hat{\\theta}}_{(\\cdot)}] = \\theta + \\frac{b_1}{n-1} + \\mathcal{O}(n^{-2})\n$$\n\n刀切法通过考虑留一法估计量的平均值与全样本估计量之间的差来估计 $\\hat{\\theta}$ 的偏差。偏差的刀切法估计量定义为：\n$$\n\\widehat{\\text{Bias}}_{JK}(\\hat{\\theta}) = (n-1) \\left( \\bar{\\hat{\\theta}}_{(\\cdot)} - \\hat{\\theta} \\right)\n$$\n为验证这是一个合理的偏差估计量，我们可以检验其期望：\n$$\nE[\\widehat{\\text{Bias}}_{JK}(\\hat{\\theta})] = (n-1) \\left( E[\\bar{\\hat{\\theta}}_{(\\cdot)}] - E[\\hat{\\theta}] \\right)\n$$\n代入期望的展开式：\n$$\nE[\\widehat{\\text{Bias}}_{JK}(\\hat{\\theta})] = (n-1) \\left( \\left(\\theta + \\frac{b_1}{n-1} + \\mathcal{O}(n^{-2})\\right) - \\left(\\theta + \\frac{b_1}{n} + \\mathcal{O}(n^{-2})\\right) \\right)\n$$\n$$\nE[\\widehat{\\text{Bias}}_{JK}(\\hat{\\theta})] = (n-1) \\left( \\frac{b_1}{n-1} - \\frac{b_1}{n} \\right) + \\mathcal{O}(n^{-1})\n$$\n$$\nE[\\widehat{\\text{Bias}}_{JK}(\\hat{\\theta})] = (n-1) \\left( \\frac{b_1 n - b_1 (n-1)}{n(n-1)} \\right) + \\mathcal{O}(n^{-1})\n$$\n$$\nE[\\widehat{\\text{Bias}}_{JK}(\\hat{\\theta})] = (n-1) \\left( \\frac{b_1}{n(n-1)} \\right) + \\mathcal{O}(n^{-1}) = \\frac{b_1}{n} + \\mathcal{O}(n^{-1})\n$$\n由于 $E[\\widehat{\\text{Bias}}_{JK}(\\hat{\\theta})] = \\text{Bias}(\\hat{\\theta}) + \\mathcal{O}(n^{-2})$，这证实了 $\\widehat{\\text{Bias}}_{JK}(\\hat{\\theta})$ 是主阶偏差项的估计量，其自身的偏差阶数为 $\\mathcal{O}(n^{-2})$。\n\n刀切法偏差校正估计量 $\\hat{\\theta}_{JK}$ 是通过从原始估计量中减去估计的偏差来构建的：\n$$\n\\hat{\\theta}_{JK} = \\hat{\\theta} - \\widehat{\\text{Bias}}_{JK}(\\hat{\\theta})\n$$\n$$\n\\hat{\\theta}_{JK} = \\hat{\\theta} - (n-1) \\left( \\bar{\\hat{\\theta}}_{(\\cdot)} - \\hat{\\theta} \\right)\n$$\n我们现在简化这个表达式以获得最终的闭式形式。\n$$\n\\hat{\\theta}_{JK} = \\hat{\\theta} - (n-1)\\bar{\\hat{\\theta}}_{(\\cdot)} + (n-1)\\hat{\\theta}\n$$\n$$\n\\hat{\\theta}_{JK} = (1 + n - 1)\\hat{\\theta} - (n-1)\\bar{\\hat{\\theta}}_{(\\cdot)}\n$$\n$$\n\\hat{\\theta}_{JK} = n\\hat{\\theta} - (n-1)\\bar{\\hat{\\theta}}_{(\\cdot)}\n$$\n问题要求用 $n$、$\\hat{\\theta}$ 和重抽样样本集合 $\\{\\hat{\\theta}_{(i)}\\}_{i=1}^{n}$ 来表示最终答案。我们代入 $\\bar{\\hat{\\theta}}_{(\\cdot)}$ 的定义：\n$$\n\\bar{\\hat{\\theta}}_{(\\cdot)} = \\frac{1}{n}\\sum_{i=1}^{n} \\hat{\\theta}_{(i)}\n$$\n这给出了刀切法偏差校正估计量的最终表达式：\n$$\n\\hat{\\theta}_{JK} = n\\hat{\\theta} - (n-1) \\left( \\frac{1}{n} \\sum_{i=1}^{n} \\hat{\\theta}_{(i)} \\right)\n$$\n$$\n\\hat{\\theta}_{JK} = n\\hat{\\theta} - \\frac{n-1}{n} \\sum_{i=1}^{n} \\hat{\\theta}_{(i)}\n$$\n这个估计量也可以解释为“伪值” $\\tilde{\\theta}_i = n\\hat{\\theta} - (n-1)\\hat{\\theta}_{(i)}$ 的平均值。根据设计，$\\hat{\\theta}_{JK}$ 的偏差阶数为 $\\mathcal{O}(n^{-2})$，这比原始估计量的 $\\mathcal{O}(n^{-1})$ 阶偏差有所改进。",
            "answer": "$$\\boxed{n\\hat{\\theta} - \\frac{n-1}{n}\\sum_{i=1}^{n} \\hat{\\theta}_{(i)}}$$"
        }
    ]
}