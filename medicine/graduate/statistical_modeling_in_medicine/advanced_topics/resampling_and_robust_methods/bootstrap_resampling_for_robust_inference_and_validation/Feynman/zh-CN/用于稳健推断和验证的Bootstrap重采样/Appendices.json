{
    "hands_on_practices": [
        {
            "introduction": "本练习提供了对自助法 (bootstrap) 原理的基础性动手实践。通过估计样本中位数（一种稳健但解析上难以处理的统计量）的标准误，您将直接接触从经验分布函数中重抽样的核心机制。这项实践对于具体理解自助法如何近似统计量的抽样分布至关重要。",
            "id": "4954777",
            "problem": "给定独立同分布的患者生物标志物测量值，建模为来自未知连续分布 $F$ 的实现 $\\{x_1,\\dots,x_n\\}$。您的任务是实现一个基于核心定义的非参数重抽样程序，以近似样本中位数的抽样分布，并计算经验累积分布函数（ECDF）。具体来说，您必须使用基于定义的经验分布 $\\hat F_n$ 作为重抽样机制，并通过从 $\\hat F_n$ 中有放回地抽取自助样本来模拟样本中位数的抽样分布。对于每个测试用例，您必须计算两个量：在指定查询点处评估的 $\\hat F_n(x)$ 的值，以及样本中位数的标准误差的自助法估计。\n\n推导和算法设计的基本依据必须明确依赖于核心定义和事实：经验累积分布函数（ECDF）的定义，样本中位数作为绝对偏差之和的最小化器和顺序统计量的定义，以及通过从 $\\hat F_n$ 重抽样来近似抽样分布的自助法原理。\n\n为每个测试用例实现以下内容：\n- 在查询点列表处计算 ECDF $\\hat F_n(x)$ 的值。不使用任何快捷公式，通过应用其定义（即计算不超过 $x$ 的观测样本的比例）来获得 $\\hat F_n(x)$。\n- 通过从观测样本中有放回地重复抽取 $n$ 个值（等同于从 $\\hat F_n$ 抽样），计算每个重抽样样本的中位数，然后使用分母 $B-1$ 将这些自助法中位数的样本标准差作为标准误差的估计值，来模拟样本中位数的自助法抽样分布。其中 $B$ 是自助法重复的次数。对于偶数 $n$，样本中位数必须定义为两个中心顺序统计量的平均值。\n- 使用指定的伪随机数生成器种子以确保可复现性。\n\n您的程序必须使用以下测试套件，每个测试用例由 $(\\text{样本}, \\text{查询}, B, \\text{种子})$ 描述：\n- 案例 1（一般偏态，正生物标志物值）：样本 $[1.8, 2.5, 3.0, 3.2, 4.1, 5.5, 7.0, 9.2, 14.8, 26.3]$，查询 $[2.0, 4.0, 10.0, 20.0]$，$B=5000$，种子 $314159$。\n- 案例 2（偶数样本量，在零附近有重复值）：样本 $[0.12, 0.15, 0.15, 0.20, 0.22, 0.35]$，查询 $[0.15, 0.21, 0.40]$，$B=7000$，种子 $271828$。\n- 案例 3（退化的常数值）：样本 $[5.0, 5.0, 5.0, 5.0, 5.0]$，查询 $[4.9, 5.0, 5.1]$，$B=4000$，种子 $444$。\n- 案例 4（小样本，含严重异常值）：样本 $[1.0, 2.0, 100.0]$，查询 $[1.0, 50.0, 100.0]$，$B=8000$，种子 $1234567$。\n\n所有生物标志物值和派生量均为无单位实数。对于每个测试用例，产生两个输出：\n- 一个浮点数列表，包含按给定顺序在相应查询点上评估的 ECDF 值 $\\hat F_n(x)$。\n- 一个浮点数，即基于 $B$ 次重复的样本中位数标准误差的自助法估计值。\n\n您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表。列表中的每个元素对应一个测试用例，并且本身是一个形式为 $[\\text{ecdf\\_values\\_list}, \\text{standard\\_error\\_float}]$ 的双元素列表。例如，最终输出格式必须是 $[[\\text{ecdf\\_case1}, \\text{se\\_case1}],[\\text{ecdf\\_case2}, \\text{se\\_case2}],\\dots]$，不含任何附加文本。",
            "solution": "该问题要求实现两个基本的非参数统计程序：计算经验累积分布函数（ECDF）和使用自助法（bootstrap method）估计样本中位数的标准误差。本解决方案旨在严格遵守所提供的第一性原理和定义。\n\n**第一部分：经验累积分布函数（ECDF）的计算**\n\nECDF，记作 $\\hat{F}_n(x)$，是真实潜在累积分布函数 $F(x)$ 的一种非参数估计。根据定义，对于一个大小为 $n$ 的给定样本 $\\{x_1, x_2, \\dots, x_n\\}$，在点 $x$ 处的 ECDF 是小于或等于 $x$ 的样本观测值的比例。其形式化表示为：\n$$\n\\hat{F}_n(x) = \\frac{1}{n} \\sum_{i=1}^{n} I(x_i \\le x)\n$$\n其中 $I(\\cdot)$ 是指示函数，如果其参数为真，则值为 $1$，否则为 $0$。\n\n为查询点列表计算 $\\hat{F}_n(x)$ 的算法直接遵循此定义，正如题目所要求。对于所提供列表中的每个查询点 $q$，该程序会遍历样本中的所有数据点 $x_i$。维护一个计数器，对于每个满足条件 $x_i \\le q$ 的 $x_i$，计数器加一。然后将最终计数除以总样本量 $n$，得到 $\\hat{F}_n(q)$ 的值。对所有查询点重复此过程。此方法避免了任何特定于库的“快捷”函数，而是从第一性原理实现了计数定义。\n\n**第二部分：样本中位数标准误差的自助法估计**\n\n第二个任务是估计样本中位数的标准误差，这是衡量样本中位数作为总体中位数估计量变异性的一个指标。当潜在的总体分布 $F$ 未知时，自助法是一种功能强大的重抽样技术，用于近似统计量的抽样分布。\n\n**样本中位数**\n我们感兴趣的统计量是样本中位数，记作 $\\hat{m}$。对于一个按非递减顺序排序的样本 $x_{(1)} \\le x_{(2)} \\le \\dots \\le x_{(n)}$，样本中位数根据样本量 $n$ 来定义。\n- 如果 $n$ 是奇数，中位数是中心值，$\\hat{m} = x_{(\\lceil n/2 \\rceil)}$。在基于 0 的索引中，这是 $x_{( (n-1)/2 )}$。\n- 如果 $n$ 是偶数，中位数是两个中心值的平均值，$\\hat{m} = \\frac{1}{2} (x_{(n/2)} + x_{(n/2+1)})$。在基于 0 的索引中，这对应于 $\\frac{1}{2}(x_{(n/2 - 1)} + x_{(n/2)})$。\n这个定义是标准的，并由诸如 `numpy.median` 之类的函数实现。\n\n**自助法原理和算法**\n自助法程序通过利用经验分布 $\\hat{F}_n$ 来近似未知的抽样分布。其核心假设是，从样本中重抽样类似于从总体中抽取新样本。算法流程如下：\n1. **重抽样**：生成大量的自助样本，数量为 $B$。每个自助样本，记作 $\\{x_1^*, \\dots, x_n^*\\}$，是通过从原始样本 $\\{x_1, \\dots, x_n\\}$ 中*有放回地*抽取 $n$ 个元素创建的。这个过程等同于从原始样本点上的离散均匀分布中抽样，这也是由 $\\hat{F}_n$ 定义的机制。\n2. **统计量计算**：对于 $B$ 个自助样本中的每一个，计算其样本中位数。这将得到一个包含 $B$ 个自助中位数的集合：$\\{m_1^*, m_2^*, \\dots, m_B^*\\}$。这个集合经验地近似了样本中位数的抽样分布。\n3. **标准误差估计**：样本中位数的标准误差是其抽样分布的标准差。此标准误差的自助法估计 $SE_{boot}(\\hat{m})$，是计算 $B$ 个自助中位数的样本标准差。问题指定使用 $B-1$ 作为分母，这对应于方差的无偏估计公式：\n    $$\n    SE_{boot}(\\hat{m}) = \\sqrt{ \\frac{1}{B-1} \\sum_{j=1}^{B} (m_j^* - \\bar{m}^*)^2 }\n    $$\n    其中 $\\bar{m}^* = \\frac{1}{B} \\sum_{j=1}^{B} m_j^*$ 是自助中位数的平均值。\n\n**实现细节**\n实现使用了 `numpy` 库来进行高效的数值运算。使用 `numpy.random.default_rng(seed)` 并为每个测试用例指定种子来初始化伪随机数生成器，确保了自助法重抽样过程的可复现性。`rng.choice` 函数用于有放回地抽样。`numpy.median` 函数用于计算每个自助样本的中位数，而带有参数 `ddof=1` 的 `numpy.std` 函数用于计算最终的标准误差估计，从而正确地实现了 $B-1$ 分母。这种方法将自助法的理论原理与一个稳健且可复现的计算算法相结合。",
            "answer": "```python\nimport numpy as np\n# No other libraries are permitted.\n# scipy is listed in the problem preamble but not needed for this solution.\n\ndef compute_ecdf_values(sample, queries):\n    \"\"\"\n    Computes the ECDF for a set of query points based on a sample,\n    adhering to the definition of counting observations.\n\n    Args:\n        sample (np.ndarray): The observed data points.\n        queries (np.ndarray): The points at which to evaluate the ECDF.\n\n    Returns:\n        list: A list of floats representing the ECDF values at the query points.\n    \"\"\"\n    n = sample.shape[0]\n    if n == 0:\n        return [0.0] * len(queries)\n    \n    ecdf_vals = []\n    for x in queries:\n        # Count how many samples are less than or equal to x\n        count = np.sum(sample = x)\n        ecdf_vals.append(count / n)\n    return ecdf_vals\n\ndef compute_bootstrap_se_median(sample, B, seed):\n    \"\"\"\n    Computes the bootstrap standard error of the sample median.\n\n    Args:\n        sample (np.ndarray): The observed data points.\n        B (int): The number of bootstrap replicates.\n        seed (int): The seed for the pseudo-random number generator.\n\n    Returns:\n        float: The bootstrap estimate of the standard error of the sample median.\n    \"\"\"\n    n = sample.shape[0]\n    if n == 0:\n        return 0.0\n\n    # Initialize the random number generator for reproducibility\n    rng = np.random.default_rng(seed)\n    \n    # Store bootstrap medians\n    bootstrap_medians = np.zeros(B)\n    \n    # Perform B bootstrap resamples\n    for i in range(B):\n        # Draw a sample of size n with replacement from the original sample\n        bootstrap_sample = rng.choice(sample, size=n, replace=True)\n        # Compute and store the median of the bootstrap sample\n        bootstrap_medians[i] = np.median(bootstrap_sample)\n        \n    # The standard error is the sample standard deviation of the bootstrap medians.\n    # The parameter ddof=1 ensures the denominator in the variance calculation is B-1.\n    se = np.std(bootstrap_medians, ddof=1)\n    \n    return se\n\ndef solve():\n    \"\"\"\n    Main function to process all test cases and print the final result.\n    \"\"\"\n    test_cases = [\n        {'sample': [1.8, 2.5, 3.0, 3.2, 4.1, 5.5, 7.0, 9.2, 14.8, 26.3], 'queries': [2.0, 4.0, 10.0, 20.0], 'B': 5000, 'seed': 314159},\n        {'sample': [0.12, 0.15, 0.15, 0.20, 0.22, 0.35], 'queries': [0.15, 0.21, 0.40], 'B': 7000, 'seed': 271828},\n        {'sample': [5.0, 5.0, 5.0, 5.0, 5.0], 'queries': [4.9, 5.0, 5.1], 'B': 4000, 'seed': 444},\n        {'sample': [1.0, 2.0, 100.0], 'queries': [1.0, 50.0, 100.0], 'B': 8000, 'seed': 1234567},\n    ]\n\n    results = []\n    for case in test_cases:\n        # It's good practice to convert lists to numpy arrays for numerical processing\n        sample = np.array(case['sample'])\n        queries = np.array(case['queries'])\n        B = case['B']\n        seed = case['seed']\n        \n        # Task 1: Compute ECDF values\n        ecdf_results = compute_ecdf_values(sample, queries)\n        \n        # Task 2: Compute bootstrap standard error of the median\n        se_median = compute_bootstrap_se_median(sample, B, seed)\n        \n        results.append([ecdf_results, se_median])\n\n    # The required output format is a single line, comma-separated list of lists.\n    # str() on a list produces the desired representation '[...]'\n    # We join these string representations with commas.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "在掌握了基本概念之后，本练习将自助法重抽样应用于医学诊断中的一个关键任务：评估受试者工作特征曲线下面积 (AUC) 的不确定性。您将实施分层重抽样——这是对病例对照研究数据的一项关键调整——以构建基于百分位数的置信区间。此练习展示了自助法如何为现实世界临床评估中使用的复杂、非标准统计量提供稳健的推断。",
            "id": "4954664",
            "problem": "给定一个医学研究中常见的双类别诊断情境，其中包含患病个体和非患病个体的连续测试分数。目标是使用非参数、分层自助重抽样方法，为受试者工作特征曲线下面积 (AUC) 构建一个自助法置信区间。受试者工作特征曲线下面积 (AUC) 定义为，随机选择的患病个体的分数超过随机选择的非患病个体分数的概率，其中平局情况贡献一半的 credit。使用百分位数自助法来估计 AUC 的双侧置信区间，该方法基于患者层面的重抽样。\n\n请基于以下经过充分检验的定义和事实进行推导：\n- 受试者工作特征 (ROC) 曲线绘制了当决策阈值变化时，真阳性率 (TPR) 相对于假阳性率 (FPR) 的关系图；受试者工作特征曲线下面积 (AUC) 是患病和非患病个体测试分数联合分布的一个泛函，可以解释为对 ROC 曲线的积分，或关于成对比较的概率陈述。\n- 非参数自助重抽样通过从经验分布中进行有放回的重复重抽样，来近似一个统计量的抽样分布。在病例-对照医学研究中，重抽样应按类别分层，以保留类别条件的经验分布。\n\n实现以下任务：\n1. 对于每个测试用例，模拟患病和非患病个体的测试分数。对于患病个体，从均值为 $\\mu_1$、方差为 $\\sigma_1^2$ 的正态分布中抽取独立的分数。对于非患病个体，从均值为 $\\mu_0$、方差为 $\\sigma_0^2$ 的正态分布中抽取独立的分数。使用固定的随机种子 $s=12345$，以确保结果是可复现的。如果指定了舍入精度 $r$，则将每个模拟分数四舍五入到 $r$ 的最接近的倍数（这将引入平局）。\n2. 使用成对比较的解释来计算经验 AUC：它是所有患病与非患病配对中，患病分数大于非患病分数的比例，平局情况贡献一半的 credit。该经验估计量必须与基于秩次的 Wilcoxon-Mann-Whitney 公式一致，并且必须能适当地处理平局。\n3. 使用百分位数法构建一个 $(1-\\alpha)$ 自助法置信区间：\n   - 执行 $B$ 次自助法重复。在每次重复中，在患病组内有放回地重抽样至样本量 $n_1$，在非患病组内有放回地重抽样至样本量 $n_0$（分层重抽样），然后计算重抽样数据的 AUC。\n   - 令 $\\hat{F}_B$ 为 $B$ 个自助 AUC 值的经验分布。下界是 $\\hat{F}_B$ 的 $\\alpha/2$ 分位数，上界是 $\\hat{F}_B$ 的 $(1-\\alpha/2)$ 分位数。\n4. 对于每个测试用例，返回构成置信下界和上界的两个数字。将这两个数字表示为四舍五入到 $6$ 位小数的十进制浮点数。\n\n您的程序应生成单行输出，其中包含用方括号括起来的逗号分隔列表形式的结果，每个测试用例贡献一个包含下界和上界的双元素列表。例如：$[ [\\text{lower}_1,\\text{upper}_1],[\\text{lower}_2,\\text{upper}_2],\\dots ]$。\n\n使用以下测试套件（所有数字均为确保可复现性和覆盖不同场景而指定）：\n- 测试用例 $1$（中等类别平衡和分离度的一般情况）：$n_1=120$， $n_0=150$， $\\mu_1=1.0$， $\\sigma_1=1.0$， $\\mu_0=0.0$， $\\sigma_0=1.0$， $B=4000$， $\\alpha=0.05$，无舍入。\n- 测试用例 $2$（类别高度不平衡，中等分离度）：$n_1=40$， $n_0=400$， $\\mu_1=0.8$， $\\sigma_1=1.2$， $\\mu_0=0.2$， $\\sigma_0=1.2$， $B=3000$， $\\alpha=0.05$，无舍入。\n- 测试用例 $3$（小样本量，由舍入引起平局）：$n_1=12$， $n_0=10$， $\\mu_1=0.0$， $\\sigma_1=1.0$， $\\mu_0=0.0$， $\\sigma_0=1.0$，舍入精度 $r=0.1$， $B=5000$， $\\alpha=0.10$。\n- 测试用例 $4$（近乎完美的分离度）：$n_1=60$， $n_0=60$， $\\mu_1=2.5$， $\\sigma_1=0.5$， $\\mu_0=-0.5$， $\\sigma_0=0.5$， $B=3000$， $\\alpha=0.05$，无舍入。\n\n所有浮点输出必须四舍五入到 $6$ 位小数并表示为十进制数（而非分数），不涉及物理单位。不涉及角度。最终打印的行必须严格为上述指定的单个括号列表。",
            "solution": "该问题陈述已经过仔细验证，并被确定为有效。它具有科学依据，提问得当，客观，并包含了进行求解所需的所有必要信息。没有发现科学、逻辑或形式上的缺陷。\n\n目标是为受试者工作特征曲线下面积 (AUC) 计算一个双侧 $(1-\\alpha)$ 百分位数自助法置信区间。这项任务在医学诊断测试的评估中很常见，其中从一组患有某种疾病的个体（病例）和一组未患该疾病的个体（对照）中收集测试分数。\n\n### 原理一：ROC 曲线下面积 (AUC)\n\nAUC 是衡量诊断测试性能的一个汇总指标。来自患病个体的测试分数 $X$ 服从分布 $F_1$，而来自非患病个体的分数 $Y$ 服从分布 $F_0$。AUC 正式定义为随机选择的患病个体的分数高于随机选择的非患病个体分数的概率。当可能出现平局时，通常给予一半的 credit。\n\n$$\nAUC = P(X  Y) + \\frac{1}{2} P(X = Y)\n$$\n\n给定一个来自患病个体的 $n_1$ 个分数样本 $\\{x_i\\}_{i=1}^{n_1}$ 和一个来自非患病个体的 $n_0$ 个分数样本 $\\{y_j\\}_{j=1}^{n_0}$，AUC 的一个非参数估计，记为 $\\widehat{AUC}$，是所有可能的 $(x_i, y_j)$ 对中 $x_i$ 大于 $y_j$ 的比例，加上它们相等情况的比例的一半。\n\n$$\n\\widehat{AUC} = \\frac{1}{n_1 n_0} \\sum_{i=1}^{n_1} \\sum_{j=1}^{n_0} \\Psi(x_i, y_j)\n$$\n\n其中评分函数 $\\Psi(a,b)$ 定义为：\n\n$$\n\\Psi(a,b) = \\begin{cases} 1  \\text{if } a  b \\\\ \\frac{1}{2}  \\text{if } a = b \\\\ 0  \\text{if } a  b \\end{cases}\n$$\n\n该估计量等价于归一化的 Wilcoxon-Mann-Whitney U 统计量。一种计算 $\\widehat{AUC}$ 的高效方法是使用秩次。首先，将所有 $N = n_1 + n_0$ 个分数合并并从 $1$ 到 $N$ 进行排序。如果出现平局，则为每个平局分数分配平均秩次（中值秩次）。令 $R_i$ 为第 $i$ 个患病分数 $x_i$ 在合并样本中的秩次。患病组的 U 统计量 $U_1$ 是这些秩次的总和，并根据可能的最小秩次和进行调整：\n\n$$\nU_1 = \\left( \\sum_{i=1}^{n_1} R_i \\right) - \\frac{n_1(n_1+1)}{2}\n$$\n\n然后，AUC 估计量由下式给出：\n\n$$\n\\widehat{AUC} = \\frac{U_1}{n_1 n_0}\n$$\n\n这种基于秩次的公式能够正确处理平局，并且在计算上优于朴素的 $O(n_1 n_0)$ 成对比较方法，其复杂度通常为 $O(N \\log N)$，因为涉及到排序以确定秩次。\n\n### 原理二：分层自助重抽样\n\n自助法是一种强大的重抽样技术，用于近似统计量的抽样分布。为了构建 AUC 的置信区间，我们需要了解 $\\widehat{AUC}$ 在从潜在总体 $F_1$ 和 $F_0$ 中抽取的不同样本之间会如何变化。由于我们只能接触到经验分布 $\\hat{F}_1$（来自 $\\{x_i\\}$）和 $\\hat{F}_0$（来自 $\\{y_j\\}$），我们使用它们作为真实分布的代理。\n\n对于病例-对照数据，使用**分层重抽样**至关重要。这意味着我们独立地从患病组和非患病组中进行重抽样，并保持每组的原始样本量。这尊重了研究设计，并确保我们的自助样本模拟了原始数据采集过程的结构。\n\nAUC 的分层自助法程序如下：\n对于 $b = 1, 2, \\ldots, B$：\n1.  通过从原始样本 $\\{x_i\\}_{i=1}^{n_1}$ 中有放回地抽取 $n_1$ 个分数，生成一个患病分数的自助样本 $X_b^*$。\n2.  通过从原始样本 $\\{y_j\\}_{j=1}^{n_0}$ 中有放回地抽取 $n_0$ 个分数，生成一个非患病分数的自助样本 $Y_b^*$。\n3.  使用基于秩次的方法，对 $X_b^*$ 和 $Y_b^*$ 计算该自助法重复的 AUC，即 $\\widehat{AUC}_b^*$。\n\n这个过程产生了一个包含 $B$ 个自助 AUC 值的集合，$\\{\\widehat{AUC}_1^*, \\widehat{AUC}_2^*, \\ldots, \\widehat{AUC}_B^*\\}$，它作为 $\\widehat{AUC}$ 抽样分布的经验近似。\n\n### 原理三：百分位数置信区间\n\n百分位数法是一种直接从自助分布构建置信区间的方法。一个 $(1-\\alpha)$ 置信区间是通过取排序后的自助法重复样本的分位数构成的。\n\n-   置信区间的下界是自助分布 $\\{\\widehat{AUC}_b^*\\}$ 的 $(\\alpha/2)$ 分位数。\n-   上界是 $(1-\\alpha/2)$ 分位数。\n\n例如，对于一个 $95\\%$ 的置信区间（$\\alpha=0.05$），其界限是排序后的自助 AUC 列表的第 $2.5$ 个和第 $97.5$ 个百分位数。\n\n### 算法解决方案\n对于每个测试用例，整体算法按以下步骤进行：\n1.  **数据生成**：使用固定的随机种子 $s=12345$ 以保证可复现性，为患病组模拟 $n_1$ 个来自 $N(\\mu_1, \\sigma_1^2)$ 的分数，为非患病组模拟 $n_0$ 个来自 $N(\\mu_0, \\sigma_0^2)$ 的分数。如果指定了舍入精度 $r$，则将每个分数四舍五入到 $r$ 的最接近的倍数。此步骤明确地在数据中引入平局，以测试 AUC 计算的稳健性。\n2.  **自助法循环**：执行 $B$ 次迭代。在每次迭代中：\n    a.  进行有放回的分层重抽样，为患病组和非患病组创建自助样本。\n    b.  使用高效的基于秩次的方法计算重抽样数据的 $\\widehat{AUC}$。\n    c.  存储计算出的 $\\widehat{AUC}_b^*$。\n3.  **置信区间计算**：完成 $B$ 次迭代后，计算收集到的自助 AUC 值的 $\\alpha/2$ 和 $(1-\\alpha/2)$ 分位数。这些分位数构成了置信区间的下界和上界。\n4.  **格式化**：将得到的界限四舍五入到 $6$ 位小数并按指定格式输出。\n\n该程序能够稳健地估计 AUC 的置信区间，正确处理分层数据和存在平局的情况。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy import stats\n\ndef solve():\n    \"\"\"\n    Solves the problem of constructing bootstrap confidence intervals for AUC\n    for a series of test cases.\n    \"\"\"\n\n    test_cases = [\n        # Test case 1 (general case with moderate class balance and separation)\n        {'n1': 120, 'n0': 150, 'mu1': 1.0, 'sigma1': 1.0, 'mu0': 0.0, 'sigma0': 1.0, 'B': 4000, 'alpha': 0.05, 'r': None},\n        # Test case 2 (high class imbalance, modest separation)\n        {'n1': 40, 'n0': 400, 'mu1': 0.8, 'sigma1': 1.2, 'mu0': 0.2, 'sigma0': 1.2, 'B': 3000, 'alpha': 0.05, 'r': None},\n        # Test case 3 (small sample size with ties induced by rounding)\n        {'n1': 12, 'n0': 10, 'mu1': 0.0, 'sigma1': 1.0, 'mu0': 0.0, 'sigma0': 1.0, 'r': 0.1, 'B': 5000, 'alpha': 0.10},\n        # Test case 4 (near perfect separation)\n        {'n1': 60, 'n0': 60, 'mu1': 2.5, 'sigma1': 0.5, 'mu0': -0.5, 'sigma0': 0.5, 'B': 3000, 'alpha': 0.05, 'r': None},\n    ]\n\n    # Fixed random seed for reproducibility\n    seed = 12345\n    rng = np.random.default_rng(seed)\n\n    def calculate_auc(diseased_scores, non_diseased_scores):\n        \"\"\"\n        Calculates the AUC using the Wilcoxon-Mann-Whitney U-statistic formulation,\n        which is efficient and correctly handles ties.\n        \"\"\"\n        n1 = len(diseased_scores)\n        n0 = len(non_diseased_scores)\n\n        if n1 == 0 or n0 == 0:\n            return 0.5\n\n        # Combine scores and calculate ranks\n        all_scores = np.concatenate((diseased_scores, non_diseased_scores))\n        ranks = stats.rankdata(all_scores, method='average')\n\n        # Sum of ranks for the diseased group\n        sum_ranks_diseased = np.sum(ranks[:n1])\n\n        # Calculate U statistic for the diseased group\n        u_stat = sum_ranks_diseased - (n1 * (n1 + 1)) / 2\n        \n        # AUC is the normalized U statistic\n        auc = u_stat / (n1 * n0)\n        return auc\n\n    results = []\n    for case in test_cases:\n        n1, n0 = case['n1'], case['n0']\n        mu1, sigma1 = case['mu1'], case['sigma1']\n        mu0, sigma0 = case['mu0'], case['sigma0']\n        B, alpha, r = case['B'], case['alpha'], case['r']\n        \n        # 1. Simulate test scores\n        diseased_scores = rng.normal(loc=mu1, scale=sigma1, size=n1)\n        non_diseased_scores = rng.normal(loc=mu0, scale=sigma0, size=n0)\n\n        # Apply rounding if resolution 'r' is specified\n        if r is not None and r > 0:\n            diseased_scores = np.round(diseased_scores / r) * r\n            non_diseased_scores = np.round(non_diseased_scores / r) * r\n\n        # 3. Construct bootstrap confidence interval\n        bootstrap_aucs = np.zeros(B)\n        for i in range(B):\n            # Stratified resampling with replacement\n            resampled_diseased = rng.choice(diseased_scores, size=n1, replace=True)\n            resampled_non_diseased = rng.choice(non_diseased_scores, size=n0, replace=True)\n            \n            # Compute AUC for the resampled data\n            bootstrap_aucs[i] = calculate_auc(resampled_diseased, resampled_non_diseased)\n            \n        # Calculate percentile confidence interval\n        lower_quantile = alpha / 2\n        upper_quantile = 1 - alpha / 2\n        \n        ci_lower = np.quantile(bootstrap_aucs, lower_quantile)\n        ci_upper = np.quantile(bootstrap_aucs, upper_quantile)\n        \n        results.append([ci_lower, ci_upper])\n\n    # Format the final output string to precisely 6 decimal places.\n    formatted_results = []\n    for lower, upper in results:\n        formatted_results.append(f\"[{lower:.6f},{upper:.6f}]\")\n    \n    # Final print statement in the exact required format.\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "一名出色的统计学家不仅会应用方法，更会理解其局限性。这最后一个练习使用蒙特卡洛模拟来批判性地评估自助法百分位区间的性能。通过在不同数据分布（对称与偏态）下，将其真实覆盖率与名义覆盖率进行比较，您将对该方法的可靠性及其表现最佳的条件获得关键的洞察。",
            "id": "4954794",
            "problem": "您需要编写一个完整、可运行的程序，使用蒙特卡洛模拟来评估当基础分布为对称与偏态时，自助法百分位数区间对样本中位数是否能达到名义覆盖率。该程序必须仅使用概率论和统计学中的定义和经过充分检验的事实，从第一性原理出发实现以下内容。\n\n假设从一个未知的分布函数 $F$ 中抽取独立同分布 (i.i.d.) 的观测值作为样本。对于给定的样本大小 $n$，将样本表示为 $\\{X_1,\\dots,X_n\\}$，样本中位数表示为 $\\hat{m}$。自助法原理通过从观测样本中进行有放回重抽样来近似 $\\hat{m}$ 的抽样分布。具体来说，给定一个观测样本，生成 $B$ 个大小均为 $n$ 的独立同分布自助法重抽样样本，计算每个重抽样样本的样本中位数以获得 $\\{\\hat{m}^{\\ast}_1,\\dots,\\hat{m}^{\\ast}_B\\}$，然后通过取经验分位数形成名义水平为 $1-\\alpha$ 的百分位数置信区间（Confidence Interval (CI)）：\n$$\n[\\hat{q}_{\\alpha/2},\\hat{q}_{1-\\alpha/2}],\n$$\n其中 $\\hat{q}_p$ 是 $\\{\\hat{m}^{\\ast}_b\\}_{b=1}^B$ 的经验 $p$-分位数。经验分位数需通过顺序统计量之间的标准线性插值计算：如果 $\\tilde{m}^{\\ast}_{(1)} \\le \\cdots \\le \\tilde{m}^{\\ast}_{(B)}$ 是排序后的自助法中位数，且 $p \\in (0,1)$，定义 $h=(B-1)p+1$，令 $k=\\lfloor h \\rfloor$，$t = h-k$，并设\n$$\n\\hat{q}_p = \\tilde{m}^{\\ast}_{(k)} + t\\left(\\tilde{m}^{\\ast}_{(k+1)} - \\tilde{m}^{\\ast}_{(k)}\\right),\n$$\n约定 $\\tilde{m}^{\\ast}_{(B+1)}=\\tilde{m}^{\\ast}_{(B)}$。水平为 $1-\\alpha$ 的覆盖率是指真实总体中位数 $m$ 落在随机区间 $[\\hat{q}_{\\alpha/2},\\hat{q}_{1-\\alpha/2}]$ 内的概率。\n\n您的任务是，对于几个真实中位数 $m$ 已知的分布，通过蒙特卡洛模拟来近似这个覆盖概率。对于每个测试用例，执行以下操作：\n- 重复 $R$ 次：\n  - 从指定的分布中生成一个大小为 $n$ 的独立同分布样本。\n  - 使用 $B$ 个自助法重抽样样本，按上述定义计算中位数的百分位数置信区间。\n  - 记录 $m \\in [\\hat{q}_{\\alpha/2},\\hat{q}_{1-\\alpha/2}]$ 是否成立，使用闭区间，即如果 $m \\ge \\hat{q}_{\\alpha/2}$ 且 $m \\le \\hat{q}_{1-\\alpha/2}$，则计为覆盖。\n- 经验覆盖率则是在 $R$ 次重复中，覆盖发生的次数所占的比例。\n\n使用以下基本原理：\n- 从固定分布 $F$ 进行独立同分布 (i.i.d.) 抽样。\n- 样本中位数的定义。\n- 作为统计量抽样分布的经验近似的自助法重抽样方案。\n- 通过分位数定义置信区间。\n- 基本的极限定理，如大数定律，以证明蒙特卡洛模拟在大 $R$ 值下的近似质量（您无需证明这些定律）。\n\n为以下参数值的测试套件实现模拟，该套件涵盖对称轻尾、对称重尾和偏态分布，以及一个大样本场景：\n- 测试用例 $1$（对称，轻尾）：均值为 $0$、标准差为 $1$ 的正态分布，记为 $\\mathcal{N}(0,1)$。使用 $n=40$，$\\alpha=0.05$，$B=300$，$R=400$。真实中位数为 $m=0$。\n- 测试用例 $2$（对称，重尾）：位置为 $0$、尺度为 $1$ 的拉普拉斯分布。使用 $n=40$，$\\alpha=0.05$，$B=300$，$R=400$。真实中位数为 $m=0$。\n- 测试用例 $3$（偏态，中小样本）：率 $\\lambda=1$ 的指数分布。使用 $n=40$，$\\alpha=0.05$，$B=300$，$R=400$。真实中位数为 $m=(\\log 2)/\\lambda$。\n- 测试用例 $4$（偏态，大样本）：率 $\\lambda=1$ 的指数分布。使用 $n=120$，$\\alpha=0.05$，$B=200$，$R=300$。真实中位数为 $m=(\\log 2)/\\lambda$。\n\n所有随机变量的生成都必须使用固定的种子 $s=1729$ 以确保可复现性。不涉及角度。不适用物理单位。将所有覆盖率结果表示为 $[0,1]$ 范围内的小数。\n\n程序输入：无。程序输出：单行，包含一个由四个浮点数组成的列表，表示测试用例 1 到 4 的经验覆盖率，按顺序排列，每个数都四舍五入到恰好三位小数。格式必须是单行：\n\"[c1,c2,c3,c4]\"\n其中 $c1$，$c2$，$c3$ 和 $c4$ 分别是四个测试用例的四舍五入后的经验覆盖率，无附加文本或空格。",
            "solution": "用户提供了一个来自计算统计学领域的有效、定义明确的问题陈述。该问题在科学上基于已建立的统计理论，即使用自助法重抽样构建置信区间，并使用蒙特卡洛模拟评估其性能。所有参数、定义和程序都已足够精确地指定，以允许一个唯一且可复现的解决方案。任务是实现此模拟，以评估在不同基础分布下，样本中位数的自助法百分位数区间的覆盖概率。\n\n正如要求，解决方案是根据第一性原理开发的。该算法是通过将统计学定义直接转化为计算过程来构建的。\n\n主要目标是估计置信区间的覆盖概率。对于一个参数 $\\theta$ 的 $(1-\\alpha)$ 置信区间的构建程序，其覆盖概率是在重复抽样中，计算出的区间包含 $\\theta$ 真实值的概率。如果这个概率等于 $1-\\alpha$，则称一个程序达到了名义覆盖水平。\n\n感兴趣的参数是总体中位数，记为 $m$。此参数的估计量是样本中位数 $\\hat{m}$，根据从分布 $F$ 中抽取的独立同分布 (i.i.d.) 样本 $\\{X_1, \\dots, X_n\\}$ 计算得出。\n\n置信区间是使用自助法百分位数方法构建的。自助法的基本思想是通过模拟来近似统计量（例如 $\\hat{m}$）的抽样分布。由于真实的总体分布 $F$ 是未知的，我们使用从观测样本中派生出的经验分布函数作为代理。程序如下：\n1.  从原始样本 $\\{X_1, \\dots, X_n\\}$ 中，通过*有放回*抽样，抽取一个大小为 $n$ 的“自助法重抽样样本” $\\{X_1^\\ast, \\dots, X_n^\\ast\\}$。\n2.  为此重抽样样本计算感兴趣的统计量。这里，我们计算样本中位数，记为 $\\hat{m}^\\ast$。\n3.  重复步骤 1 和 2 共 $B$ 次（$B$ 为一个大数），以获得一组自助法统计量 $\\{\\hat{m}^\\ast_1, \\dots, \\hat{m}^\\ast_B\\}$。这个集合作为 $\\hat{m}$ 抽样分布的经验近似。\n\n$(1-\\alpha)$ 百分位置信区间是通过取自助法分布的经验 $\\alpha/2$ 和 $1-\\alpha/2$ 分位数形成的。设排序后的自助法中位数为 $\\tilde{m}^\\ast_{(1)} \\leq \\tilde{m}^\\ast_{(2)} \\leq \\dots \\leq \\tilde{m}^\\ast_{(B)}$。问题指定了一种通过线性插值计算经验 $p$-分位数 $\\hat{q}_p$ 的精确方法。给定一个概率 $p \\in (0,1)$，我们首先找到一个位置索引 $h = (B-1)p+1$。令 $k = \\lfloor h \\rfloor$ 为整数部分，$t = h - k$ 为小数部分。则分位数由以下公式给出：\n$$\n\\hat{q}_p = \\tilde{m}^\\ast_{(k)} + t(\\tilde{m}^\\ast_{(k+1)} - \\tilde{m}^\\ast_{(k)})\n$$\n问题指定了约定 $\\tilde{m}^\\ast_{(B+1)} = \\tilde{m}^\\ast_{(B)}$，这确保了当 $k=B$ 时公式是良定义的。置信区间则由 $[\\hat{q}_{\\alpha/2}, \\hat{q}_{1-\\alpha/2}]$ 给出。\n\n为了评估该区间的性能，我们使用蒙特卡洛模拟来估计其覆盖概率。这引入了第二层模拟。对于单个测试用例的总体算法是：\n1.  初始化一个覆盖计数器为 $0$。固定参数：样本大小 $n$，显著性水平 $\\alpha$，自助法重抽样次数 $B$，蒙特卡洛重复次数 $R$，基础分布 $F$ 及其真实中位数 $m$。\n2.  开始外层循环，该循环将运行 $R$ 次。每次迭代代表一个完整的实验。\n    a.  从真实分布 $F$ 中生成一个大小为 $n$ 的原始样本 $\\{X_1, \\dots, X_n\\}$。\n    b.  开始内层循环（自助法程序），该循环将运行 $B$ 次。\n        i. 通过从原始样本中有放回地抽取 $n$ 个元素来创建一个自助法重抽样样本。\n        ii. 计算此重抽样样本的中位数。\n        iii. 存储这个自助法中位数。\n    c. 内层循环结束后，已收集到所有 $B$ 个自助法中位数 $\\{\\hat{m}^\\ast_1, \\dots, \\hat{m}^\\ast_B\\}$。\n    d. 对自助法中位数进行排序，以获得顺序统计量 $\\tilde{m}^\\ast_{(1)}, \\dots, \\tilde{m}^\\ast_{(B)}$。\n    e. 使用指定的线性插值公式计算置信区间的下界和上界，即 $\\hat{q}_{\\alpha/2}$ 和 $\\hat{q}_{1-\\alpha/2}$。\n    f. 检查真实中位数 $m$ 是否包含在此计算出的区间内，即 $m \\in [\\hat{q}_{\\alpha/2}, \\hat{q}_{1-\\alpha/2}]$ 是否成立。\n    g. 如果发生覆盖，则将覆盖计数器加一。\n3.  外层循环完成后，估计的覆盖概率是覆盖计数器的总数除以蒙特卡洛重复次数 $R$。\n\n此模拟针对四个测试用例进行，旨在揭示自助法百分位数区间的特性：\n-   **用例 1：正态分布 $\\mathcal{N}(0,1)$**。这是一个对称的轻尾分布。中位数的抽样分布是对称的，预计自助法会表现良好。覆盖率应接近名义水平 $1-\\alpha = 0.95$。\n-   **用例 2：拉普拉斯分布**。这是一个对称的重尾分布。样本中位数对于拉普拉斯分布的中心是一个特别有效的估计量。预计性能会很好。\n-   **用例 3：指数分布，$n=40$**。该分布是偏态的。中位数的抽样分布也将是偏态的。对于偏态分布，特别是在样本量较小的情况下，标准的百分位数自助法区间通常会表现出系统性偏差和覆盖不足。我们预计覆盖率将显著低于 $0.95$。\n-   **用例 4：指数分布，$n=120$**。这是相同的偏态分布，但样本量更大。随着 $n$ 的增加，由于中心极限定理，中位数的抽样分布变得更加对称。因此，我们预计自助法的性能会得到改善，覆盖率应比用例 3 更接近 $0.95$。\n\n使用固定的随机种子来确保为样本和重抽样样本生成的伪随机数的可复现性，从而得到一个确定性的最终输出。实现将使用 `numpy` 库进行数值运算和随机数生成。分位数的计算将根据问题的定义明确实现，以确保完全忠实于规范。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Performs a Monte Carlo simulation to assess the coverage of bootstrap \n    percentile intervals for the sample median across different distributions.\n    \"\"\"\n\n    # Set the global random seed for reproducibility.\n    SEED = 1729\n    rng = np.random.default_rng(SEED)\n\n    def _calculate_quantile(sorted_data, p):\n        \"\"\"\n        Computes the empirical p-quantile using linear interpolation as specified.\n\n        Args:\n            sorted_data (np.ndarray): A 1D numpy array of data, already sorted.\n            p (float): The probability for the quantile, in (0, 1).\n\n        Returns:\n            float: The calculated quantile.\n        \"\"\"\n        B = len(sorted_data)\n        \n        # Calculate the position index h = (B-1)p + 1.\n        h = (B - 1) * p + 1.0\n        \n        # Get integer and fractional parts of h.\n        k = int(h)\n        t = h - k\n        \n        # Convert 1-based k to 0-based index.\n        idx_k = k - 1\n        \n        # Get the value at the k-th order statistic.\n        val_k = sorted_data[idx_k]\n        \n        # Handle the edge case where k is the last element index.\n        # The convention is m*(B+1) = m*(B), making the difference term zero.\n        if k == B:\n            return val_k\n        else:\n            # Get the value at the (k+1)-th order statistic.\n            idx_k_plus_1 = k\n            val_k_plus_1 = sorted_data[idx_k_plus_1]\n            \n            # Apply the linear interpolation formula.\n            return val_k + t * (val_k_plus_1 - val_k)\n\n    def run_simulation(dist_func, true_median, n, alpha, B, R, local_rng):\n        \"\"\"\n        Runs the full simulation for one test case.\n\n        Args:\n            dist_func (callable): A function that takes size n and returns a random sample.\n            true_median (float): The true population median.\n            n (int): The sample size.\n            alpha (float): The significance level.\n            B (int): The number of bootstrap resamples.\n            R (int): The number of Monte Carlo repetitions.\n            local_rng (np.random.Generator): The random number generator instance.\n\n        Returns:\n            float: The empirical coverage probability.\n        \"\"\"\n        coverage_count = 0\n        \n        # Outer loop for Monte Carlo replications.\n        for _ in range(R):\n            # 1. Generate an i.i.d. sample of size n.\n            sample = dist_func(n, local_rng)\n            \n            bootstrap_medians = np.empty(B)\n            \n            # Inner loop for bootstrap resampling.\n            for i in range(B):\n                # 2. Generate a bootstrap resample.\n                resample = local_rng.choice(sample, size=n, replace=True)\n                \n                # 3. Compute and store the median of the resample.\n                bootstrap_medians[i] = np.median(resample)\n            \n            # 4. Sort the bootstrap medians to get order statistics.\n            bootstrap_medians.sort()\n            \n            # 5. Compute the percentile confidence interval.\n            lower_quantile = alpha / 2.0\n            upper_quantile = 1.0 - (alpha / 2.0)\n            \n            ci_lower = _calculate_quantile(bootstrap_medians, lower_quantile)\n            ci_upper = _calculate_quantile(bootstrap_medians, upper_quantile)\n            \n            # 6. Check for coverage.\n            if ci_lower = true_median = ci_upper:\n                coverage_count += 1\n                \n        # 7. Calculate empirical coverage.\n        return coverage_count / R\n\n    # Define random variate generation functions\n    dist_normal = lambda size, r: r.normal(loc=0, scale=1, size=size)\n    dist_laplace = lambda size, r: r.laplace(loc=0, scale=1, size=size)\n    # Numpy's exponential uses scale = 1/lambda. Rate lambda=1 means scale=1.\n    dist_exponential = lambda size, r: r.exponential(scale=1, size=size)\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # Case 1: Normal(0, 1)\n        {'name': 'Normal', 'dist': dist_normal, 'median': 0.0, 'n': 40, 'alpha': 0.05, 'B': 300, 'R': 400},\n        # Case 2: Laplace(0, 1)\n        {'name': 'Laplace', 'dist': dist_laplace, 'median': 0.0, 'n': 40, 'alpha': 0.05, 'B': 300, 'R': 400},\n        # Case 3: Exponential(1), small n\n        {'name': 'Exponential_40', 'dist': dist_exponential, 'median': np.log(2), 'n': 40, 'alpha': 0.05, 'B': 300, 'R': 400},\n        # Case 4: Exponential(1), large n\n        {'name': 'Exponential_120', 'dist': dist_exponential, 'median': np.log(2), 'n': 120, 'alpha': 0.05, 'B': 200, 'R': 300},\n    ]\n\n    results = []\n    for case in test_cases:\n        coverage = run_simulation(\n            dist_func=case['dist'],\n            true_median=case['median'],\n            n=case['n'],\n            alpha=case['alpha'],\n            B=case['B'],\n            R=case['R'],\n            local_rng=rng\n        )\n        results.append(coverage)\n\n    # Format the results as specified: rounded to exactly three decimal places.\n    formatted_results = [f\"{res:.3f}\" for res in results]\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```"
        }
    ]
}