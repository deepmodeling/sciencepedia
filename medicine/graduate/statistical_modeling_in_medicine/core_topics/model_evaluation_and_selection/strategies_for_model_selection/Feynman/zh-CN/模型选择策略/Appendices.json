{
    "hands_on_practices": [
        {
            "introduction": "在模型构建中，我们经常面临一个核心的权衡：模型的简约性与预测能力。赤池信息准则 ($AIC$) 和贝叶斯信息准则 ($BIC$) 是解决这一问题的两大常用工具，但它们背后蕴含着不同的建模哲学。本练习将通过一个在医学研究中至关重要的生存分析场景，帮助你深入理解 $AIC$ 和 $BIC$ 在模型选择上的根本差异，以及这些差异如何反映出预测与科学发现这两种不同的目标 。",
            "id": "4815133",
            "problem": "一个医院系统进行了一项基于登记的队列研究，以评估2型糖尿病患者因心力衰竭首次住院的时间。分析人员使用偏似然将两个嵌套的Cox比例风险模型拟合到事件发生时间数据上。模型$\\mathcal{M}_{0}$包括基线协变量：年龄、性别、种族、吸烟状况和估算的肾小球滤过率。模型$\\mathcal{M}_{1}$额外添加了$d$个连续协变量：五个代表炎症和心肌应激的循环生物标志物。\n\n设$n$表示具有完整随访和协变量的患者数量，$k_{0}$为模型$\\mathcal{M}_{0}$中的自由参数数量，$k_{1}$为模型$\\mathcal{M}_{1}$中的自由参数数量，且$d = k_{1} - k_{0}$。设$\\ell_{0}$和$\\ell_{1}$分别表示模型$\\mathcal{M}_{0}$和$\\mathcal{M}_{1}$的最大化偏对数似然，并定义改善量为$\\Delta \\ell = \\ell_{1} - \\ell_{0}$。在本研究中，样本量为$n = 1200$，添加的参数数量为$d = 5$，观测到的改善量为$\\Delta \\ell = 10$。\n\n从信息论风险最小化和贝叶斯模型证据近似的基本原则出发，推导在赤池信息准则（AIC）和贝叶斯信息准则（BIC）下，选择$\\mathcal{M}_{1}$优于$\\mathcal{M}_{0}$的决策条件。使用这些条件来确定在此情景下AIC是否选择较大模型以及BIC是否选择较小模型，并从循证医学中的预测目标与识别目标角度解释这些决策。\n\n最后，对于给定的$n$和$d$值，计算两个决策阈值之间的数值差距——即BIC偏好$\\mathcal{M}_{1}$所需的最大化偏对数似然改善量与AIC偏好$\\mathcal{M}_{1}$所需的改善量之差。以自然对数单位报告此差距，并四舍五入到四位有效数字。",
            "solution": "我们考虑嵌套模型$\\mathcal{M}_{0}$和$\\mathcal{M}_{1}$，其中$\\mathcal{M}_{1}$增加了$d = k_{1} - k_{0}$个协变量。Cox比例风险模型通过偏似然进行估计，我们用$\\ell$表示其最大化的对数值。虽然对于所有数据生成特征而言，偏似然并非完全似然，但在比例风险模型的大样本模型选择中，通常的做法是将$\\ell$类比为对数似然。\n\n我们从两个基本基础出发：\n\n1. 信息论风险最小化：赤池信息准则（AIC）源于对候选模型与数据生成机制之间预期Kullback–Leibler散度的渐近无偏估计。经典结果是，对于一个有$k$个自由参数的模型，需要最小化的准则是\n$$\n\\mathrm{AIC} = -2 \\ell + 2 k.\n$$\n对于嵌套比较，其差值为\n$$\n\\Delta \\mathrm{AIC} = \\mathrm{AIC}_{1} - \\mathrm{AIC}_{0} = \\left(-2 \\ell_{1} + 2 k_{1}\\right) - \\left(-2 \\ell_{0} + 2 k_{0}\\right) = -2 (\\ell_{1} - \\ell_{0}) + 2 (k_{1} - k_{0}) = -2 \\Delta \\ell + 2 d.\n$$\n如果$\\Delta \\mathrm{AIC}  0$，AIC偏好$\\mathcal{M}_{1}$，这就得出了决策条件\n$$\n-2 \\Delta \\ell + 2 d  0 \\quad \\Longleftrightarrow \\quad \\Delta \\ell > d.\n$$\n\n2. 贝叶斯模型证据近似：贝叶斯信息准则（BIC）源于在固定维度的正则先验下对边际似然的拉普拉斯近似，其目标是最小化\n$$\n\\mathrm{BIC} = -2 \\ell + k \\ln n.\n$$\n因此，其差值为\n$$\n\\Delta \\mathrm{BIC} = \\mathrm{BIC}_{1} - \\mathrm{BIC}_{0} = -2 \\Delta \\ell + d \\ln n.\n$$\n如果$\\Delta \\mathrm{BIC}  0$，BIC偏好$\\mathcal{M}_{1}$，这就得出了决策条件\n$$\n-2 \\Delta \\ell + d \\ln n  0 \\quad \\Longleftrightarrow \\quad \\Delta \\ell > \\frac{d \\ln n}{2}.\n$$\n\n这些决策条件将观测到的最大化偏对数似然改善量$\\Delta \\ell$与两个阈值进行比较：\n- AIC阈值: $T_{\\mathrm{AIC}} = d$,\n- BIC阈值: $T_{\\mathrm{BIC}} = \\frac{d \\ln n}{2}$.\n\n给定$n = 1200$, $d = 5$ 和 $\\Delta \\ell = 10$，我们计算：\n$$\nT_{\\mathrm{AIC}} = d = 5,\n$$\n以及\n$$\nT_{\\mathrm{BIC}} = \\frac{d \\ln n}{2} = \\frac{5 \\ln(1200)}{2}.\n$$\n我们使用$\\ln(12) + \\ln(100)$来计算$\\ln(1200)$，其中$\\ln(12) \\approx 2.484906649788$且$\\ln(100) \\approx 4.605170185988$，得到\n$$\n\\ln(1200) \\approx 7.090076835776.\n$$\n因此，\n$$\nT_{\\mathrm{BIC}} \\approx \\frac{5 \\times 7.090076835776}{2} \\approx 17.72519208944.\n$$\n\n我们将$\\Delta \\ell = 10$与这些阈值进行比较：\n- 对于AIC：$\\Delta \\ell = 10 > T_{\\mathrm{AIC}} = 5$，所以AIC偏好$\\mathcal{M}_{1}$。\n- 对于BIC：$\\Delta \\ell = 10  T_{\\mathrm{BIC}} \\approx 17.7252$，所以BIC偏好$\\mathcal{M}_{0}$。\n\n在循证医学中的解释：赤池信息准则基于最小化预期样本外Kullback–Leibler散度，优先考虑预测准确性，并且容忍包含即使只是适度改善拟合度的变量。因此，AIC选择较大的模型$\\mathcal{M}_{1}$，这与风险分层等预测目标相一致，在此类目标中，校准度和区分度的增量改进受到重视。贝叶斯信息准则在正则性条件下近似对数后验模型概率，施加一个随样本量增加而增强的惩罚项，从而偏好简约性以识别数据生成结构。因此，BIC选择较小的模型$\\mathcal{M}_{0}$，这与识别目标相符，该目标在推断机制或选择最小充分预测因子集时，强调较少的协变量和对过拟合的稳健性。\n\n最后，我们计算两个决策阈值之间的差距：\n$$\n\\text{Gap} = T_{\\mathrm{BIC}} - T_{\\mathrm{AIC}} = \\frac{d \\ln n}{2} - d.\n$$\n代入$d = 5$和$n = 1200$，\n$$\n\\text{Gap} = \\frac{5 \\ln(1200)}{2} - 5 \\approx 17.72519208944 - 5 = 12.72519208944.\n$$\n四舍五入到四位有效数字，差距为$12.73$自然对数单位。",
            "answer": "$$\\boxed{12.73}$$"
        },
        {
            "introduction": "选出一个“最佳”模型后，下一步是严格评估其预测性能，尤其是在医学领域，概率预测的质量至关重要。简单的准确率指标往往不足以全面衡量模型的好坏，而 Brier 分数及其分解为此提供了深刻的洞见。通过这个练习，你将学习如何将模型的整体预测误差分解为校准度（预测的可靠性）和辨别力（区分不同风险群体的能力），从而更精细地评价和比较模型 。",
            "id": "4985110",
            "problem": "一个医院系统正在比较两种用于评估同一目标人群院内死亡率的概率性风险模型。对于随机抽取的一名患者，设其二元结果为 $Y \\in \\{0,1\\}$，并设一个模型产生的概率预测为 $\\hat{p} \\in [0,1]$。Brier 分数 $\\mathrm{BS}$ 定义为对二元结果的概率预测的期望平方误差，即 $\\mathrm{BS} = \\mathbb{E}\\big[(Y - \\hat{p})^{2}\\big]$。请仅使用诸如全期望定律和全方差定律等基本概率恒等式，将 $\\mathrm{BS}$ 分解为一个反映校准误差的项、一个反映区分度（也称为解析度）的项，以及一个仅取决于 $Y=1$ 的边际流行率的项。\n\n两种模型都应用于相同的患者人群，其预测结果分为如下三个层。对于模型 $\\mathcal{A}$，其预测值 $\\hat{p}_{\\mathcal{A}}$ 分别以 $\\{0.5, 0.3, 0.2\\}$ 的概率取值为 $\\{0.05, 0.20, 0.60\\}$。给定预测值，真实的条件结果概率 $\\pi_{\\mathcal{A}}(\\hat{p}_{\\mathcal{A}})$ 按相同顺序对这些层取值为 $\\{0.10, 0.18, 0.48\\}$。对于模型 $\\mathcal{B}$，其预测值 $\\hat{p}_{\\mathcal{B}}$ 以相同的概率 $\\{0.5, 0.3, 0.2\\}$ 取值为 $\\{0.12, 0.24, 0.34\\}$，并且模型 $\\mathcal{B}$ 是完全校准的，即在每个层中都有 $\\pi_{\\mathcal{B}}(\\hat{p}_{\\mathcal{B}}) = \\hat{p}_{\\mathcal{B}}$。\n\n假设数据生成过程使得对于每个模型，$Y=1$ 的边际流行率等于真实条件概率 $\\pi(\\hat{p})$ 对应的分层加权平均值。使用您推导出的分解式，计算每个模型的期望 Brier 分数，然后计算差值\n$$\n\\Delta = \\mathbb{E}\\big[(Y - \\hat{p}_{\\mathcal{A}})^{2}\\big] - \\mathbb{E}\\big[(Y - \\hat{p}_{\\mathcal{B}})^{2}\\big].\n$$\n将您最终的 $\\Delta$ 数值答案四舍五入到四位有效数字。答案以概率尺度上的无单位小数表示（不要使用百分号）。",
            "solution": "**第一部分：Brier 分数的分解**\n\nBrier 分数（$\\mathrm{BS}$）定义为对二元结果 $Y \\in \\{0, 1\\}$ 的概率预测 $\\hat{p}$ 的期望平方误差。\n$$\n\\mathrm{BS} = \\mathbb{E}\\big[(Y - \\hat{p})^{2}\\big]\n$$\n设 $\\pi(\\hat{p})$ 为给定预测的真实条件结果概率，即 $\\pi(\\hat{p}) = P(Y=1 | \\hat{p}) = \\mathbb{E}[Y | \\hat{p}]$。我们可以在平方项内部加上和减去 $\\pi(\\hat{p})$：\n$$\n\\mathrm{BS} = \\mathbb{E}\\big[ ( (Y - \\pi(\\hat{p})) + (\\pi(\\hat{p}) - \\hat{p}) )^{2} \\big]\n$$\n展开平方项得到三项：\n$$\n\\mathrm{BS} = \\mathbb{E}\\big[ (Y - \\pi(\\hat{p}))^2 \\big] + \\mathbb{E}\\big[ (\\pi(\\hat{p}) - \\hat{p})^2 \\big] + 2 \\mathbb{E}\\big[ (Y - \\pi(\\hat{p}))(\\pi(\\hat{p}) - \\hat{p}) \\big]\n$$\n我们使用全期望定律分析交叉项，可以证明其为 $0$。因此，Brier 分数的分解简化为：\n$$\n\\mathrm{BS} = \\mathbb{E}\\big[ (\\pi(\\hat{p}) - \\hat{p})^2 \\big] + \\mathbb{E}\\big[ (Y - \\pi(\\hat{p}))^2 \\big]\n$$\n第一项 $\\mathbb{E}\\big[ (\\pi(\\hat{p}) - \\hat{p})^2 \\big]$ 是 **校准误差**（也称为可靠性）。\n\n第二项可以进一步分解。设 $\\bar{y} = P(Y=1)$ 为结果的边际流行率。可以证明：\n$$\n\\mathbb{E}\\big[ (Y - \\pi(\\hat{p}))^2 \\big] = \\bar{y}(1-\\bar{y}) - \\mathrm{Var}(\\pi(\\hat{p}))\n$$\n项 $\\mathrm{Var}(\\pi(\\hat{p})) = \\mathbb{E}[(\\pi(\\hat{p}) - \\bar{y})^2]$ 是 **解析度**（或区分度）。项 $\\bar{y}(1-\\bar{y})$ 是 **不确定性**。\n\n综合所有部分，完整的分解式为：\n$$\n\\mathrm{BS} = \\underbrace{\\mathbb{E}\\big[(\\hat{p} - \\pi(\\hat{p}))^2\\big]}_{\\text{校准}} - \\underbrace{\\mathbb{E}\\big[(\\pi(\\hat{p}) - \\bar{y})^2\\big]}_{\\text{解析度}} + \\underbrace{\\bar{y}(1-\\bar{y})}_{\\text{不确定性}}\n$$\n\n**第二部分：模型 $\\mathcal{A}$ 和 $\\mathcal{B}$ 的计算**\n\n期望是作为离散预测层上的加权平均来计算的。设 $w_i$、$\\hat{p}_i$ 和 $\\pi_i$ 分别为第 $i$ 层的概率、预测值和真实条件概率。\n\n首先，我们确定边际流行率 $\\bar{y}$：\n$$\n\\bar{y} = \\mathbb{E}[\\pi_{\\mathcal{A}}(\\hat{p}_{\\mathcal{A}})] = \\sum_{i=1}^{3} w_i \\pi_{\\mathcal{A},i} = (0.5)(0.10) + (0.3)(0.18) + (0.2)(0.48) = 0.05 + 0.054 + 0.096 = 0.20\n$$\n不确定性分量对两个模型是共同的：\n$$\n\\mathrm{UNC} = \\bar{y}(1-\\bar{y}) = 0.20(1 - 0.20) = 0.16\n$$\n\n**模型 $\\mathcal{A}$ 的 Brier 分数：**\n1.  校准（$\\mathrm{CAL}_{\\mathcal{A}}$）：\n$$\n\\mathrm{CAL}_{\\mathcal{A}} = \\mathbb{E}\\big[(\\hat{p}_{\\mathcal{A}} - \\pi_{\\mathcal{A}}(\\hat{p}_{\\mathcal{A}}))^2\\big] = 0.5(0.05 - 0.10)^2 + 0.3(0.20 - 0.18)^2 + 0.2(0.60 - 0.48)^2\n$$\n$$\n\\mathrm{CAL}_{\\mathcal{A}} = 0.5(0.0025) + 0.3(0.0004) + 0.2(0.0144) = 0.00125 + 0.00012 + 0.00288 = 0.00425\n$$\n2.  解析度（$\\mathrm{RES}_{\\mathcal{A}}$）：\n$$\n\\mathrm{RES}_{\\mathcal{A}} = \\mathbb{E}\\big[(\\pi_{\\mathcal{A}}(\\hat{p}_{\\mathcal{A}}) - \\bar{y})^2\\big] = 0.5(0.10 - 0.20)^2 + 0.3(0.18 - 0.20)^2 + 0.2(0.48 - 0.20)^2\n$$\n$$\n\\mathrm{RES}_{\\mathcal{A}} = 0.5(0.01) + 0.3(0.0004) + 0.2(0.0784) = 0.005 + 0.00012 + 0.01568 = 0.0208\n$$\n3.  Brier 分数（$\\mathrm{BS}_{\\mathcal{A}}$）：\n$$\n\\mathrm{BS}_{\\mathcal{A}} = \\mathrm{CAL}_{\\mathcal{A}} - \\mathrm{RES}_{\\mathcal{A}} + \\mathrm{UNC} = 0.00425 - 0.0208 + 0.16 = 0.14345\n$$\n\n**模型 $\\mathcal{B}$ 的 Brier 分数：**\n1.  校准（$\\mathrm{CAL}_{\\mathcal{B}}$）：模型 $\\mathcal{B}$ 是完全校准的，因此 $\\mathrm{CAL}_{\\mathcal{B}} = 0$。\n2.  解析度（$\\mathrm{RES}_{\\mathcal{B}}$）：\n$$\n\\mathrm{RES}_{\\mathcal{B}} = \\mathbb{E}[(\\hat{p}_{\\mathcal{B}} - \\bar{y})^2] = 0.5(0.12 - 0.20)^2 + 0.3(0.24 - 0.20)^2 + 0.2(0.34 - 0.20)^2\n$$\n$$\n\\mathrm{RES}_{\\mathcal{B}} = 0.5(0.0064) + 0.3(0.0016) + 0.2(0.0196) = 0.0032 + 0.00048 + 0.00392 = 0.0076\n$$\n3.  Brier 分数（$\\mathrm{BS}_{\\mathcal{B}}$）：\n$$\n\\mathrm{BS}_{\\mathcal{B}} = \\mathrm{CAL}_{\\mathcal{B}} - \\mathrm{RES}_{\\mathcal{B}} + \\mathrm{UNC} = 0 - 0.0076 + 0.16 = 0.1524\n$$\n\n**Brier 分数的差异：**\n所需的差异是 $\\Delta = \\mathrm{BS}_{\\mathcal{A}} - \\mathrm{BS}_{\\mathcal{B}}$。\n$$\n\\Delta = 0.14345 - 0.1524 = -0.00895\n$$\n问题要求答案四舍五入到四位有效数字。为了用四位有效数字表示，我们在末尾添加一个零：\n$$\n\\Delta \\approx -0.008950\n$$",
            "answer": "$$\\boxed{-0.008950}$$"
        },
        {
            "introduction": "模型选择的终点不一定是挑选出单一的最佳模型。本练习将介绍一种更高级的策略——模型堆叠（stacking），它通过智能地结合多个竞争模型的预测，创建一个性能更优的集成模型。你将学习如何利用交叉验证的输出来优化模型权重，从而最大化集成模型的预测准确性，这在现代预测建模中是一项非常强大且实用的技术 。",
            "id": "4985108",
            "problem": "给定三个相互竞争的逻辑斯蒂模型，它们为一项二元医学结果输出预测概率，同时还提供了$K$折交叉验证 (CV) 的验证预测，这些预测是通过在$K-1$个折上训练并在留出的折上进行预测而生成的。考虑通过构建一个集成来堆叠这些模型，该集成对每个观测值$i$预测一个概率 $p_i(\\mathbf{w}) = \\sum_{m=1}^{3} w_m p_{im}$，其中$p_{im}$是模型$m$对观测值$i$的CV预测概率，$\\mathbf{w} = (w_1,w_2,w_3)$是满足$\\sum_{m=1}^{3} w_m = 1$和$w_m \\ge 0$约束的非负堆叠权重。假设二元结果服从标准的伯努利对数似然，并且数据集被划分为$K$个折，使得所有折上的验证预测的并集恰好覆盖所有观测值一次。\n\n基本原理：\n- 对于给定的预测概率$p_i$，二元结果$y_i \\in \\{0,1\\}$的伯努利似然为$L_i = p_i^{y_i} (1-p_i)^{1-y_i}$，其对数似然为$\\ell_i = y_i \\log(p_i) + (1-y_i) \\log(1-p_i)$。\n- 在$K$折交叉验证 (CV) 中，每个观测值都由一个在其所在折的补集上训练的模型精确预测一次，CV对数似然是所有验证预测的对数似然之和。\n\n您的任务是计算堆叠权重$\\mathbf{w}$，以在单纯形约束下最大化集成预测的总CV对数似然，并评估集成模型相较于最佳单一模型（三个模型中总CV对数似然最高的那个）的性能。\n\n程序需求解的优化目标：\n- 最大化凹目标函数 $\\sum_{i=1}^{n} \\left[ y_i \\log\\left(\\sum_{m=1}^{3} w_m p_{im}\\right) + (1-y_i) \\log\\left(1-\\sum_{m=1}^{3} w_m p_{im}\\right) \\right]$，约束条件为 $\\sum_{m=1}^{3} w_m = 1$ 和 $w_m \\ge 0$（对于$m=1,2,3$）。在实现中，通过使用$\\varepsilon$级别的下限和上限将概率裁剪到远离$0$和$1$的范围，以确保数值稳定性；使用$\\varepsilon = 10^{-12}$。\n\n测试套件：\n- 提供了三个案例。每个案例都包括二元结果向量$\\mathbf{y}$、CV预测概率矩阵$\\mathbf{P} \\in \\mathbb{R}^{n \\times 3}$（列对应三个模型），以及一个折分配向量$\\mathbf{f}$，指示每个观测值在CV中所处的折。请注意，提供$\\mathbf{f}$是为了信息的完整性；由于$\\mathbf{P}$包含了所有观测值的CV预测，因此集成目标可以作为所有观测值的总和来计算。\n\n案例1（均衡结果，互补模型，$K=5$，$n=20$）：\n$$\n\\mathbf{y}^{(1)} = [0,1,0,1, \\; 0,0,1,1, \\; 0,1,0,1, \\; 0,0,1,1, \\; 0,1,0,1]\n$$\n$$\n\\mathbf{P}_1^{(1)} = [0.15,0.70,0.25,0.80, \\; 0.20,0.30,0.75,0.85, \\; 0.10,0.65,0.35,0.78, \\; 0.22,0.28,0.72,0.88, \\; 0.18,0.69,0.40,0.83]\n$$\n$$\n\\mathbf{P}_2^{(1)} = [0.10,0.60,0.20,0.65, \\; 0.15,0.25,0.70,0.80, \\; 0.12,0.58,0.30,0.70, \\; 0.18,0.35,0.68,0.82, \\; 0.20,0.63,0.32,0.75]\n$$\n$$\n\\mathbf{P}_3^{(1)} = [0.30,0.55,0.40,0.60, \\; 0.28,0.40,0.62,0.70, \\; 0.25,0.50,0.45,0.65, \\; 0.22,0.45,0.60,0.72, \\; 0.26,0.48,0.52,0.68]\n$$\n$$\n\\mathbf{f}^{(1)} = [1,1,1,1, \\; 2,2,2,2, \\; 3,3,3,3, \\; 4,4,4,4, \\; 5,5,5,5]\n$$\n\n案例2（一个主导模型，$K=5$，$n=15$）：\n$$\n\\mathbf{y}^{(2)} = [1,1,0, \\; 0,1,1, \\; 0,0,1, \\; 1,0,1, \\; 0,1,1]\n$$\n$$\n\\mathbf{P}_1^{(2)} = [0.96,0.94,0.08, \\; 0.09,0.97,0.95, \\; 0.07,0.06,0.93, \\; 0.98,0.10,0.96, \\; 0.05,0.97,0.95]\n$$\n$$\n\\mathbf{P}_2^{(2)} = [0.70,0.72,0.30, \\; 0.40,0.75,0.76, \\; 0.35,0.25,0.68, \\; 0.78,0.32,0.74, \\; 0.28,0.77,0.73]\n$$\n$$\n\\mathbf{P}_3^{(2)} = [0.60,0.62,0.65, \\; 0.55,0.58,0.59, \\; 0.52,0.57,0.60, \\; 0.61,0.55,0.62, \\; 0.58,0.59,0.60]\n$$\n$$\n\\mathbf{f}^{(2)} = [1,1,1, \\; 2,2,2, \\; 3,3,3, \\; 4,4,4, \\; 5,5,5]\n$$\n\n案例3（两个相同模型，$K=5$，$n=10$）：\n$$\n\\mathbf{y}^{(3)} = [0,1, \\; 0,1, \\; 0,1, \\; 0,1, \\; 0,1]\n$$\n$$\n\\mathbf{P}_1^{(3)} = [0.20,0.80, \\; 0.22,0.78, \\; 0.18,0.82, \\; 0.25,0.75, \\; 0.21,0.79]\n$$\n$$\n\\mathbf{P}_2^{(3)} = [0.20,0.80, \\; 0.22,0.78, \\; 0.18,0.82, \\; 0.25,0.75, \\; 0.21,0.79]\n$$\n$$\n\\mathbf{P}_3^{(3)} = [0.45,0.55, \\; 0.50,0.50, \\; 0.48,0.52, \\; 0.46,0.54, \\; 0.49,0.51]\n$$\n$$\n\\mathbf{f}^{(3)} = [1,1, \\; 2,2, \\; 3,3, \\; 4,4, \\; 5,5]\n$$\n\n程序要求：\n- 实现一个例程，在每个案例中，通过最大化集成预测的总CV对数似然来计算堆叠权重$\\mathbf{w}$，并需满足单纯形约束，使用一个合适的约束优化器。\n- 计算集成模型和每个单一模型的总CV对数似然；通过总CV对数似然确定最佳单一模型，并计算集成模型相比于最佳单一模型的对数似然提升。\n- 数值稳定性：在计算对数之前，将所有概率$p$裁剪到$[10^{-12}, 1-10^{-12}]$区间内。\n- 输出规格：对于每个案例，生成一个列表$[w_1,w_2,w_3,\\ell_{\\text{ens}},\\ell_{\\text{best}},\\Delta]$，其中$\\ell_{\\text{ens}}$是集成的总CV对数似然，$\\ell_{\\text{best}}$是三个单一模型中最高的总CV对数似然，$\\Delta = \\ell_{\\text{ens}} - \\ell_{\\text{best}}$。所有数字必须是浮点数，并四舍五入到6位小数。\n- 最终输出格式：您的程序应生成单行输出，其中包含一个由逗号分隔并用方括号括起来的结果列表。外层列表应包含上述三个按案例划分的列表（例如，$[[\\dots],[\\dots],[\\dots]]$）。\n\n不涉及物理单位；所有量均为无量纲的概率和对数似然。角度不适用。百分比（若有）必须以小数形式表示。数值答案必须与程序生成的最后一行完全一致。",
            "solution": "该问题要求我们找到三个逻辑斯蒂模型集成的最佳堆叠权重，以最大化总交叉验证（CV）对数似然。这是一个约束优化问题。\n\n设观测值为 $n$ 个，模型数量为 $M=3$。给定一个二元结果向量 $\\mathbf{y} \\in \\{0, 1\\}^n$ 和一个 $n \\times 3$ 的CV预测概率矩阵 $\\mathbf{P}$，其中 $P_{im}$ 是模型 $m$ 对结果 $y_i$ 赋的概率。\n\n集成模型对观测值 $i$ 的预测是基础模型预测的加权平均值：\n$$\np_i(\\mathbf{w}) = \\sum_{m=1}^{3} w_m P_{im}\n$$\n其中 $\\mathbf{w} = (w_1, w_2, w_3)^T$ 是堆叠权重向量。权重必须满足单纯形约束：\n$$\n\\sum_{m=1}^{3} w_m = 1 \\quad \\text{且} \\quad w_m \\ge 0 \\quad \\text{对于 } m=1, 2, 3\n$$\n\n目标是最大化集成模型在所有 $n$ 个观测值上的总伯努利对数似然。单个观测值 $i$ 的对数似然由以下公式给出：\n$$\n\\ell_i(\\mathbf{w}) = y_i \\log(p_i(\\mathbf{w})) + (1-y_i) \\log(1 - p_i(\\mathbf{w}))\n$$\n总对数似然是所有观测值的对数似然之和：\n$$\nL(\\mathbf{w}) = \\sum_{i=1}^{n} \\ell_i(\\mathbf{w}) = \\sum_{i=1}^{n} \\left[ y_i \\log\\left(\\sum_{m=1}^{3} w_m P_{im}\\right) + (1-y_i) \\log\\left(1 - \\sum_{m=1}^{3} w_m P_{im}\\right) \\right]\n$$\n\n这是一个凸优化问题，因为目标函数 $L(\\mathbf{w})$ 是凹函数（因为它是凹函数对数与 $\\mathbf{w}$ 的仿射函数复合后的和），并且约束集（一个标准单纯形）是凸集。我们可以通过在给定约束条件下最小化负对数似然 $-L(\\mathbf{w})$ 来解决此问题。\n\n解题步骤如下：\n1.  **定义目标函数：** 我们实现一个函数，用于计算给定权重向量 $\\mathbf{w}$、结果向量 $\\mathbf{y}$ 和预测矩阵 $\\mathbf{P}$ 时的负总对数似然 $-L(\\mathbf{w})$。为确保数值稳定性，预测概率 $p_i(\\mathbf{w})$ 在取对数前被裁剪到区间 $[\\varepsilon, 1-\\varepsilon]$ 内，其中 $\\varepsilon = 10^{-12}$。所有观测值的集成预测可以通过矩阵向量乘积 $\\mathbf{p}(\\mathbf{w}) = \\mathbf{P}\\mathbf{w}$ 高效计算。\n\n2.  **设置并求解优化问题：** 我们使用一个数值优化器来找到最小化负对数似然的权重 $\\mathbf{w}^*$。`scipy.optimize.minimize` 函数是合适的，可使用 'SLSQP' (Sequential Least Squares Programming) 方法，该方法可以处理等式和不等式约束。\n    - 权重的初始猜测值可以设置为均匀值 $\\mathbf{w}_0 = (1/3, 1/3, 1/3)^T$。\n    - 每个权重的边界设置为 $w_m \\ge 0$，这对应于 `(0, None)`。\n    - 等式约束为 $\\sum_{m=1}^{3} w_m - 1 = 0$。\n\n3.  **评估性能：** 找到最优权重 $\\mathbf{w}^*$ 后，我们计算所需的性能指标：\n    - 最大化的集成对数似然 $\\ell_{\\text{ens}} = L(\\mathbf{w}^*)$。\n    - 三个独立模型中每个模型的对数似然 $\\ell_{\\text{single},m} = \\sum_{i=1}^{n} [y_i \\log(P_{im}) + (1-y_i) \\log(1 - P_{im})]$，其中 $m \\in \\{1, 2, 3\\}$。\n    - 表现最佳的单一模型的对数似然 $\\ell_{\\text{best}} = \\max(\\ell_{\\text{single},1}, \\ell_{\\text{single},2}, \\ell_{\\text{single},3})$。\n    - 集成模型相对于最佳单一模型的提升量 $\\Delta = \\ell_{\\text{ens}} - \\ell_{\\text{best}}$。\n\n4.  **处理测试案例：** 将此完整过程应用于提供的三个测试案例中的每一个。每个案例的最终结果，包括列表 $[w_1^*, w_2^*, w_3^*, \\ell_{\\text{ens}}, \\ell_{\\text{best}}, \\Delta]$，将被四舍五入到六位小数并格式化为指定的输出结构。请注意，计算中不需要折分配向量 $\\mathbf{f}$，因为预测矩阵 $\\mathbf{P}$ 已包含完整的折外预测集合。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.optimize import minimize\n\ndef solve():\n    \"\"\"\n    Computes optimal stacking weights for logistic models and evaluates ensemble performance.\n    \"\"\"\n    \n    # Define the test cases from the problem statement.\n    test_cases = [\n        # Case 1\n        (\n            np.array([0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1]),\n            np.stack([\n                np.array([0.15, 0.70, 0.25, 0.80, 0.20, 0.30, 0.75, 0.85, 0.10, 0.65, 0.35, 0.78, 0.22, 0.28, 0.72, 0.88, 0.18, 0.69, 0.40, 0.83]),\n                np.array([0.10, 0.60, 0.20, 0.65, 0.15, 0.25, 0.70, 0.80, 0.12, 0.58, 0.30, 0.70, 0.18, 0.35, 0.68, 0.82, 0.20, 0.63, 0.32, 0.75]),\n                np.array([0.30, 0.55, 0.40, 0.60, 0.28, 0.40, 0.62, 0.70, 0.25, 0.50, 0.45, 0.65, 0.22, 0.45, 0.60, 0.72, 0.26, 0.48, 0.52, 0.68])\n            ], axis=1)\n        ),\n        # Case 2\n        (\n            np.array([1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1]),\n            np.stack([\n                np.array([0.96, 0.94, 0.08, 0.09, 0.97, 0.95, 0.07, 0.06, 0.93, 0.98, 0.10, 0.96, 0.05, 0.97, 0.95]),\n                np.array([0.70, 0.72, 0.30, 0.40, 0.75, 0.76, 0.35, 0.25, 0.68, 0.78, 0.32, 0.74, 0.28, 0.77, 0.73]),\n                np.array([0.60, 0.62, 0.65, 0.55, 0.58, 0.59, 0.52, 0.57, 0.60, 0.61, 0.55, 0.62, 0.58, 0.59, 0.60])\n            ], axis=1)\n        ),\n        # Case 3\n        (\n            np.array([0, 1, 0, 1, 0, 1, 0, 1, 0, 1]),\n            np.stack([\n                np.array([0.20, 0.80, 0.22, 0.78, 0.18, 0.82, 0.25, 0.75, 0.21, 0.79]),\n                np.array([0.20, 0.80, 0.22, 0.78, 0.18, 0.82, 0.25, 0.75, 0.21, 0.79]),\n                np.array([0.45, 0.55, 0.50, 0.50, 0.48, 0.52, 0.46, 0.54, 0.49, 0.51])\n            ], axis=1)\n        ),\n    ]\n\n    epsilon = 1e-12\n    all_results = []\n\n    def calculate_log_likelihood(y, p, eps):\n        p_clipped = np.clip(p, eps, 1 - eps)\n        log_likelihood = np.sum(y * np.log(p_clipped) + (1 - y) * np.log(1 - p_clipped))\n        return log_likelihood\n\n    def objective_function(w, y, P, eps):\n        p_ensemble = P @ w\n        return -calculate_log_likelihood(y, p_ensemble, eps)\n\n    for y, P in test_cases:\n        # Define constraints and bounds for the optimizer\n        constraints = ({'type': 'eq', 'fun': lambda w: np.sum(w) - 1})\n        bounds = [(0, None), (0, None), (0, None)]\n        \n        # Initial guess for the weights\n        w0 = np.array([1/3, 1/3, 1/3])\n        \n        # Perform the optimization to find optimal weights\n        opt_result = minimize(\n            objective_function, \n            w0, \n            args=(y, P, epsilon),\n            method='SLSQP', \n            bounds=bounds, \n            constraints=constraints\n        )\n        \n        w_opt = opt_result.x\n        \n        # Calculate ensemble log-likelihood with optimal weights\n        l_ens = calculate_log_likelihood(y, P @ w_opt, epsilon)\n        \n        # Calculate log-likelihood for each single model\n        l_models = [calculate_log_likelihood(y, P[:, i], epsilon) for i in range(3)]\n        \n        # Find the best single model log-likelihood\n        l_best = max(l_models)\n        \n        # Calculate the improvement of the ensemble over the best single model\n        delta = l_ens - l_best\n        \n        # Assemble the results for the current case\n        case_result = [\n            w_opt[0], w_opt[1], w_opt[2],\n            l_ens, l_best, delta\n        ]\n        all_results.append(case_result)\n\n    # Format the final output string as per specifications\n    final_string_parts = []\n    for case_res in all_results:\n        formatted_nums = [f\"{x:.6f}\" for x in case_res]\n        part = f\"[{','.join(formatted_nums)}]\"\n        final_string_parts.append(part)\n    \n    final_output_string = f\"[{','.join(final_string_parts)}]\"\n    print(final_output_string)\n\nsolve()\n```"
        }
    ]
}