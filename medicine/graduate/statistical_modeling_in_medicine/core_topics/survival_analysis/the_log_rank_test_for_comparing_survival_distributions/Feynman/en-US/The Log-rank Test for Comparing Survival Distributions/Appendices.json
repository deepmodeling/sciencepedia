{
    "hands_on_practices": [
        {
            "introduction": "To truly understand the log-rank test, we must first build its engine. This exercise guides you through the essential step-by-step calculation of the test statistic from summary data. By computing the observed minus expected events and the corresponding variance at each event time, you will see exactly how information is aggregated to compare survival distributions .",
            "id": "4608348",
            "problem": "An epidemiology study follows two independent cohorts, Group A and Group B, to compare time-to-event outcomes using survival analysis. Assume that at any distinct event time, conditional on the risk set composition just before that time, the allocation of observed events across groups is governed by sampling without replacement from the pooled risk set under the null hypothesis of equal hazard functions. This corresponds to a score test in the Cox Proportional Hazards (CPH) model and yields the classical log-rank test.\n\nThere are three distinct event times, with the following risk set sizes and observed numbers of events in each group at each time:\n- At time $t_1$: Group A has $10$ at risk and Group B has $10$ at risk; observed events are $1$ in Group A and $0$ in Group B.\n- At time $t_2$: Group A has $8$ at risk and Group B has $9$ at risk; observed events are $1$ in Group A and $2$ in Group B.\n- At time $t_3$: Group A has $6$ at risk and Group B has $7$ at risk; observed events are $0$ in Group A and $3$ in Group B.\n\nBetween event times, some individuals may be censored; the given risk set sizes already account for prior events and censoring.\n\nUsing the log-rank framework based on the null of equal hazards, compute the log-rank score $U$ for Group A, its variance $V$, and the standardized statistic $Z = U / \\sqrt{V}$. Justify the expected value and variance used at each event time from first principles. Round the final standardized statistic $Z$ to four significant figures. No units are required. Briefly interpret the value of $Z$ in terms of whether there is evidence of a difference in hazards between the two groups, but provide only the value of $Z$ as your final answer.",
            "solution": "The fundamental basis for the log-rank test is the null hypothesis of equal hazard functions across groups. Under this null, at any distinct event time $t_j$, conditional on the pooled risk set just prior to $t_j$, the $d_j$ events observed at $t_j$ are allocated across the two groups as if drawn without replacement from the $n_j$ individuals at risk. This implies a hypergeometric model for the number of events from Group A at $t_j$, denoted $O_{A,j}$, with parameters:\n- Population size $n_j = n_{A,j} + n_{B,j}$,\n- Number of “successes” (Group A at risk) $n_{A,j}$,\n- Sample size $d_j$ (number of events at $t_j$).\n\nFor a hypergeometric random variable,\n$$\n\\mathbb{E}[O_{A,j}] = d_j \\frac{n_{A,j}}{n_j},\n\\quad\n\\mathrm{Var}(O_{A,j}) = d_j \\frac{n_{A,j}}{n_j} \\left(1 - \\frac{n_{A,j}}{n_j}\\right) \\frac{n_j - d_j}{n_j - 1}.\n$$\nEquivalently,\n$$\n\\mathrm{Var}(O_{A,j}) = \\frac{d_j (n_j - d_j) n_{A,j} n_{B,j}}{n_j^2 (n_j - 1)}.\n$$\n\nThe log-rank score $U$ for Group A is the sum over event times of observed minus expected events:\n$$\nU = \\sum_{j=1}^{3} \\left(O_{A,j} - \\mathbb{E}[O_{A,j}]\\right),\n$$\nand the variance is\n$$\nV = \\sum_{j=1}^{3} \\mathrm{Var}(O_{A,j}).\n$$\nThe standardized statistic is $Z = U / \\sqrt{V}$, which is approximately standard normal by large-sample theory (Central Limit Theorem (CLT) applied to the score test in the Cox Proportional Hazards (CPH) model).\n\nWe now compute these quantities at each time.\n\nTime $t_1$:\n- Risk sets: $n_{A,1} = 10$, $n_{B,1} = 10$, $n_1 = 20$.\n- Events: $d_1 = 1$, with $O_{A,1} = 1$.\n- Expected:\n$$\n\\mathbb{E}[O_{A,1}] = d_1 \\frac{n_{A,1}}{n_1} = 1 \\cdot \\frac{10}{20} = \\frac{1}{2}.\n$$\n- Variance:\n$$\n\\mathrm{Var}(O_{A,1}) = \\frac{d_1 (n_1 - d_1) n_{A,1} n_{B,1}}{n_1^2 (n_1 - 1)} = \\frac{1 \\cdot 19 \\cdot 10 \\cdot 10}{20^2 \\cdot 19} = \\frac{1}{4}.\n$$\n- Contribution to $U$: $O_{A,1} - \\mathbb{E}[O_{A,1}] = 1 - \\frac{1}{2} = \\frac{1}{2}$.\n\nTime $t_2$:\n- Risk sets: $n_{A,2} = 8$, $n_{B,2} = 9$, $n_2 = 17$.\n- Events: $d_2 = 3$, with $O_{A,2} = 1$.\n- Expected:\n$$\n\\mathbb{E}[O_{A,2}] = d_2 \\frac{n_{A,2}}{n_2} = 3 \\cdot \\frac{8}{17} = \\frac{24}{17}.\n$$\n- Variance:\n$$\n\\mathrm{Var}(O_{A,2}) = \\frac{d_2 (n_2 - d_2) n_{A,2} n_{B,2}}{n_2^2 (n_2 - 1)} = \\frac{3 \\cdot 14 \\cdot 8 \\cdot 9}{17^2 \\cdot 16} = \\frac{3024}{4624} = \\frac{189}{289}.\n$$\n- Contribution to $U$: $O_{A,2} - \\mathbb{E}[O_{A,2}] = 1 - \\frac{24}{17} = -\\frac{7}{17}$.\n\nTime $t_3$:\n- Risk sets: $n_{A,3} = 6$, $n_{B,3} = 7$, $n_3 = 13$.\n- Events: $d_3 = 3$, with $O_{A,3} = 0$.\n- Expected:\n$$\n\\mathbb{E}[O_{A,3}] = d_3 \\frac{n_{A,3}}{n_3} = 3 \\cdot \\frac{6}{13} = \\frac{18}{13}.\n$$\n- Variance:\n$$\n\\mathrm{Var}(O_{A,3}) = \\frac{d_3 (n_3 - d_3) n_{A,3} n_{B,3}}{n_3^2 (n_3 - 1)} = \\frac{3 \\cdot 10 \\cdot 6 \\cdot 7}{13^2 \\cdot 12} = \\frac{1260}{2028} = \\frac{105}{169}.\n$$\n- Contribution to $U$: $O_{A,3} - \\mathbb{E}[O_{A,3}] = 0 - \\frac{18}{13} = -\\frac{18}{13}$.\n\nSumming across times,\n$$\nU = \\left( \\frac{1}{2} \\right) + \\left( -\\frac{7}{17} \\right) + \\left( -\\frac{18}{13} \\right)\n= \\frac{1}{2} - \\frac{7}{17} - \\frac{18}{13}\n= \\frac{221 - 182 - 612}{442}\n= -\\frac{573}{442}.\n$$\nNumerically, $U \\approx -1.2963800905$.\n\nSimilarly,\n$$\nV = \\left( \\frac{1}{4} \\right) + \\left( \\frac{189}{289} \\right) + \\left( \\frac{105}{169} \\right).\n$$\nNumerically,\n$$\n\\frac{1}{4} = 0.25,\\quad \\frac{189}{289} \\approx 0.6539792388,\\quad \\frac{105}{169} \\approx 0.6213017751,\n$$\nso\n$$\nV \\approx 0.25 + 0.6539792388 + 0.6213017751 = 1.5252810139.\n$$\nTherefore,\n$$\nZ = \\frac{U}{\\sqrt{V}} \\approx \\frac{-1.2963800905}{\\sqrt{1.5252810139}} \\approx \\frac{-1.2963800905}{1.235022672} \\approx -1.049681.\n$$\nRounded to four significant figures, $Z \\approx -1.050$.\n\nInterpretation: The standardized log-rank statistic is close to zero in magnitude (approximately $-1.05$), which under the standard normal approximation corresponds to a two-sided tail probability near $0.29$. There is no strong evidence against the null hypothesis of equal hazards between Group A and Group B based on this small dataset.\n\nOnly the value of $Z$ is required as the final answer, rounded as specified.",
            "answer": "$$\\boxed{-1.050}$$"
        },
        {
            "introduction": "The log-rank test is most powerful when the hazard ratio between groups is constant over time, an assumption known as proportional hazards. This practice explores the important scenario where this assumption fails and the hazard functions cross . By analyzing how contributions to the test statistic from different time periods can cancel each other out, you will develop a critical perspective on the test's limitations and its sensitivity to the pattern of survival differences.",
            "id": "4990713",
            "problem": "A two-arm randomized clinical trial compares a novel therapy (group 1) with standard care (group 2). Let $S_1(t)$ and $S_2(t)$ denote the survival functions, and suppose the hazard functions $h_1(t)$ and $h_2(t)$ cross exactly once at time $t^\\star$, with $h_1(t) < h_2(t)$ for $t < t^\\star$ and $h_1(t) > h_2(t)$ for $t > t^\\star$. Consider the log-rank test, which compares the observed and expected number of events in group 1 across distinct event times under the null hypothesis of equal hazards. At each distinct event time $t_j$, let $O_1(t_j)$ be the observed number of events in group 1 and $E_1(t_j)$ be the expected number of events in group 1 under the null, computed conditional on the risk set at $t_j$. The log-rank numerator is the unweighted sum $\\sum_j \\{O_1(t_j) - E_1(t_j)\\}$ over all distinct event times.\n\nTo make concrete the qualitative behavior around the crossing, suppose there are two sets of tied event times arising from discretized assessment schedules:\n- An early tied set at time $t_E < t^\\star$ with total events $d_E$ among a risk set of sizes $n_{1E}$ in group 1 and $n_{2E}$ in group 2, where the observed event count in group 1 is $d_{1E}$.\n- A late tied set at time $t_L > t^\\star$ with total events $d_L$ among a risk set of sizes $n_{1L}$ in group 1 and $n_{2L}$ in group 2, where the observed event count in group 1 is $d_{1L}$.\n\nAssume the following plausible values at the starts of these tied sets: $n_{1E} = 95$, $n_{2E} = 95$, $d_E = 20$, $d_{1E} = 7$; and $n_{1L} = 70$, $n_{2L} = 60$, $d_L = 25$, $d_{1L} = 16$. No additional events occur outside these tied sets. Under the null hypothesis of equal hazards, events within a tied set are exchangeable across individuals in the risk set.\n\nWhich statement best characterizes the sign pattern of $O_1(t_j) - E_1(t_j)$ across time and the consequence for the unweighted log-rank numerator $\\sum_j \\{O_1(t_j) - E_1(t_j)\\}$ in this crossing-hazards scenario?\n\nA. Because $h_1(t) < h_2(t)$ for $t < t^\\star$ and $h_1(t) > h_2(t)$ for $t > t^\\star$, the early contributions $O_1(t_j) - E_1(t_j)$ tend to be negative and the late contributions tend to be positive, leading to cancellation in the unweighted sum and a reduced magnitude of the overall test statistic.\n\nB. Because $h_1(t) < h_2(t)$ for $t < t^\\star$ and $h_1(t) > h_2(t)$ for $t > t^\\star$, the early contributions $O_1(t_j) - E_1(t_j)$ tend to be positive and the late contributions tend to be negative, leading to reinforcement in the unweighted sum and an increased magnitude of the overall test statistic.\n\nC. Differences in risk set sizes across time imply that late contributions necessarily dominate, so cancellation of early and late contributions cannot occur when hazards cross once.\n\nD. The log-rank test automatically reweights time periods to neutralize the effect of a single crossing, so the unweighted sum is unaffected by sign changes across time and the test retains full sensitivity.",
            "solution": "The core of the problem lies in understanding the contribution to the log-rank test statistic, $O_1(t_j) - E_1(t_j)$, at different time points under the specified crossing-hazards scenario. The log-rank test assesses the null hypothesis $H_0: h_1(t) = h_2(t)$ for all $t$.\n\nUnder this null hypothesis, the risk of an event at time $t_j$ is the same for all individuals in the risk set, regardless of their group. The expected number of events in group 1, $E_1(t_j)$, is calculated based on this principle. It is the total number of events at $t_j$, $d_j$, multiplied by the proportion of the total risk set that belongs to group 1. The formula is:\n$$ E_1(t_j) = d_j \\frac{n_{1j}}{n_{1j} + n_{2j}} $$\nwhere $n_{1j}$ and $n_{2j}$ are the number of subjects at risk in group 1 and group 2 just prior to time $t_j$.\n\n**Analysis at the Early Time Point ($t_E < t^\\star$):**\nAt this time, the problem states that $h_1(t) < h_2(t)$. This means that individuals in group 1 have a lower instantaneous risk of an event than individuals in group 2. Consequently, we would anticipate observing *fewer* events in group 1 than what would be expected if the risks were equal. Thus, we expect $O_1(t_E) < E_1(t_E)$, which implies that the contribution $O_1(t_E) - E_1(t_E)$ should be negative.\n\nLet's verify this with the provided numerical values:\n- Observed events in group 1: $O_1(t_E) = d_{1E} = 7$.\n- Expected events in group 1: $E_1(t_E) = d_E \\frac{n_{1E}}{n_{1E} + n_{2E}} = 20 \\times \\frac{95}{95 + 95} = 20 \\times 0.5 = 10$.\n- The contribution to the log-rank numerator at $t_E$ is: $O_1(t_E) - E_1(t_E) = 7 - 10 = -3$.\nAs predicted, this contribution is negative.\n\n**Analysis at the Late Time Point ($t_L > t^\\star$):**\nAt this time, the problem states that $h_1(t) > h_2(t)$. This means that individuals in group 1 now have a *higher* instantaneous risk of an event than individuals in group 2. Consequently, we would anticipate observing *more* events in group 1 than expected under the null hypothesis. Thus, we expect $O_1(t_L) > E_1(t_L)$, which implies that the contribution $O_1(t_L) - E_1(t_L)$ should be positive.\n\nLet's verify this with the provided numerical values:\n- Observed events in group 1: $O_1(t_L) = d_{1L} = 16$.\n- Expected events in group 1: $E_1(t_L) = d_L \\frac{n_{1L}}{n_{1L} + n_{2L}} = 25 \\times \\frac{70}{70 + 60} = 25 \\times \\frac{70}{130} \\approx 13.46$.\n- The contribution to the log-rank numerator at $t_L$ is: $O_1(t_L) - E_1(t_L) = 16 - 13.46 \\approx 2.54$.\nAs predicted, this contribution is positive.\n\n**Overall Consequence for the Log-Rank Numerator:**\nThe total log-rank numerator is the sum of these contributions: $\\sum_j \\{O_1(t_j) - E_1(t_j)\\} = -3 + 2.54 = -0.46$. The early negative contribution and the late positive contribution partially cancel each other out. This results in a sum that is close to zero, which reduces the power of the test to detect a true difference between the survival distributions when hazards cross.\n\n**Evaluation of Options:**\n- **A:** This statement correctly identifies that early contributions are negative and late contributions are positive, leading to cancellation and reduced power. This matches our derivation.\n- **B:** This statement incorrectly reverses the signs of the contributions and falsely claims reinforcement instead of cancellation.\n- **C:** This statement incorrectly claims that late contributions necessarily dominate and that cancellation cannot occur. Our calculation shows this is false.\n- **D:** This statement incorrectly describes the standard (unweighted) log-rank test. It is precisely because it is unweighted that it loses power with crossing hazards. Weighted log-rank tests exist to address this, but that is not what is being used here.\n\nTherefore, statement A is the only correct characterization.",
            "answer": "$$\\boxed{A}$$"
        },
        {
            "introduction": "Bridging the gap from theory to practice is a crucial skill in statistical modeling. This final exercise challenges you to move beyond manual calculation and design a complete algorithm for computing the log-rank test's core components from raw survival data . By defining the procedure for handling event times, risk sets, and ties, you will solidify your understanding and gain insight into how statistical software implements this fundamental survival analysis tool.",
            "id": "4990751",
            "problem": "Consider a clinical survival dataset consisting of independent subjects indexed by $i$ with observed follow-up time $T_i \\ge 0$, event indicator $\\delta_i \\in \\{0,1\\}$ where $\\delta_i = 1$ denotes an event and $\\delta_i = 0$ denotes right-censoring, and a categorical group label $g_i \\in \\{0,1,\\dots,G-1\\}$ for $G$ disjoint groups. Define the ordered set of distinct event times $\\{t_j\\}_{j=1}^J$ where for each $j$ there exists at least one subject with $\\delta_i = 1$ and $T_i = t_j$. For each $t_j$, define the risk set size $n_j$ as the number of subjects with $T_i \\ge t_j$, the number of events $d_j$ as the number of subjects with $\\delta_i = 1$ and $T_i = t_j$, and for each group $g \\in \\{0,1,\\dots,G-1\\}$ the group-specific risk set size $n_{gj}$ as the number of subjects with $g_i = g$ and $T_i \\ge t_j$, and the group-specific number of events $d_{gj}$ as the number of subjects with $g_i = g$, $\\delta_i = 1$, and $T_i = t_j$. Under the null hypothesis of equal hazard functions across groups, at each event time $t_j$ the expected number of events in group $g$ is given by $E_{gj} = d_j \\cdot \\frac{n_{gj}}{n_j}$. The log-rank test constructs the aggregated difference $O_g - E_g = \\sum_{j=1}^J (d_{gj} - E_{gj})$ for each group $g$.\n\nYour task is to implement an algorithm that, given arrays of group labels, event indicators, and times, computes $n_j$, $d_j$, $n_{gj}$, $d_{gj}$ at each $t_j$, and returns the aggregated $O_g - E_g$ for each group $g$ across all $j \\in \\{1,\\dots,J\\}$. The algorithm must treat ties as follows: if multiple events occur at the same time $t_j$, then $d_j$ equals the number of events at $t_j$; if censoring occurs at time $t_j$, censored subjects are included in the risk set at $t_j$ because they satisfy $T_i \\ge t_j$, but they do not contribute to $d_j$. Subjects who experience events or are censored at $t_j$ are included in the risk set at $t_j$ when computing $n_j$ and $n_{gj}$.\n\nUse the following test suite, where the time unit is months (units are provided for context, but your outputs are dimensionless counts or differences and therefore do not require unit specification):\n\n- Test case $1$ (two groups, mixed events and censoring with ties and censoring at the same event time):\n  - Times $\\mathbf{t} = (5,8,12,12,15,17,20,22,22,25)$\n  - Events $\\boldsymbol{\\delta} = (1,0,1,1,0,1,0,1,0,1)$\n  - Groups $\\mathbf{g} = (0,0,1,1,0,1,0,1,0,0)$\n\n- Test case $2$ (boundary case: no events, all censored):\n  - Times $\\mathbf{t} = (3,7,10,12)$\n  - Events $\\boldsymbol{\\delta} = (0,0,0,0)$\n  - Groups $\\mathbf{g} = (0,1,0,1)$\n\n- Test case $3$ (one group has no events but is at risk):\n  - Times $\\mathbf{t} = (4,7,9,12,15,18)$\n  - Events $\\boldsymbol{\\delta} = (1,1,1,0,0,0)$\n  - Groups $\\mathbf{g} = (0,0,0,1,1,1)$\n\n- Test case $4$ (three groups with multiple ties and mixed censoring):\n  - Times $\\mathbf{t} = (2,2,5,5,5,8,10,10,10,12)$\n  - Events $\\boldsymbol{\\delta} = (1,0,1,1,0,0,1,0,1,0)$\n  - Groups $\\mathbf{g} = (0,1,0,1,2,2,0,1,2,2)$\n\nYour program must compute, for each test case, the vector of aggregated differences $(O_g - E_g)$ for all groups $g$, ordered by increasing group label. The final output must aggregate the results of all test cases into a single line as a comma-separated list enclosed in square brackets, where each entry is the result vector for one test case. For example, the output format should be $[ \\text{result}_1, \\text{result}_2, \\text{result}_3, \\text{result}_4 ]$ with each $\\text{result}_k$ itself represented as a list in standard programming notation. The outputs must be real numbers (floats), and no other units or symbols should be printed.",
            "solution": "The task is to compute the aggregated observed-minus-expected event count, $O_g - E_g$, for each group $g$ in a survival dataset, a core component of the log-rank test. The log-rank test is a hypothesis test used to compare the survival distributions of two or more groups. It operates under the null hypothesis $H_0$ that there is no difference in the hazard functions (and thus survival functions) between the groups.\n\nThe fundamental principle is to perform a comparison at each distinct time an event occurs. At each such time, $t_j$, we tabulate the number of subjects at risk of an event and the number of subjects who actually experience an event, stratified by group. Under $H_0$, the events that occur at $t_j$ should be distributed among the groups in proportion to their respective sizes within the risk set at that moment. The test statistic aggregates the deviations from this expectation across all event times.\n\nThe algorithm proceeds as follows:\n\n1.  **Identify Distinct Event Times**: First, we must identify the unique time points $\\{t_j\\}_{j=1}^J$ where at least one event ($\\delta_i=1$) occurred. Censoring times that do not coincide with an event time are not used to form the set $\\{t_j\\}$. The set is sorted in ascending order. If no events occur in the dataset, this set is empty, and the calculation terminates with all $O_g - E_g$ values equal to $0$.\n\n2.  **Initialize Aggregators**: We initialize a vector of accumulators for the $O_g - E_g$ values, one for each group $g \\in \\{0, 1, \\dots, G-1\\}$, to zero. Let this vector be denoted by $\\mathbf{S}$.\n\n3.  **Iterate Through Event Times**: For each distinct event time $t_j$ in the sorted set from Step 1:\n    a.  **Determine the Risk Set**: The risk set at time $t_j$ consists of all subjects $i$ who have not yet experienced an event or been censored prior to $t_j$. This is equivalent to finding all subjects with an observed time $T_i \\ge t_j$. The total number of individuals in this set is $n_j$.\n    b.  **Count Events**: The total number of events occurring at time $t_j$ is counted. This is the number of subjects $i$ with $T_i=t_j$ and $\\delta_i=1$. This count is denoted $d_j$.\n    c.  **Stratify by Group**: For each group $g$:\n        i.  Count the number of subjects from group $g$ in the risk set. This is $n_{gj}$, the count of subjects with $g_i=g$ and $T_i \\ge t_j$.\n        ii. Count the number of subjects from group $g$ who experience an event at time $t_j$. This is the observed count $d_{gj}$, which is the number of subjects with $g_i=g$, $T_i=t_j$, and $\\delta_i=1$.\n    d.  **Calculate Expected Events**: For each group $g$, the expected number of events under the null hypothesis is calculated using the formula $E_{gj} = d_j \\cdot \\frac{n_{gj}}{n_j}$. This formula assumes that from the $n_j$ subjects at risk, the $d_j$ events are drawn without replacement, and the probability of any given subject experiencing an event is equal regardless of group.\n    e.  **Update Aggregators**: For each group $g$, the difference $d_{gj} - E_{gj}$ is calculated and added to the corresponding accumulator in the vector $\\mathbf{S}$. That is, $S_g \\leftarrow S_g + (d_{gj} - E_{gj})$.\n\n4.  **Final Result**: After iterating through all unique event times, the vector $\\mathbf{S}$ contains the final aggregated values $(O_g - E_g)$ for each group $g$. A property of this calculation is that the sum of the components must be zero, i.e., $\\sum_{g=0}^{G-1} (O_g - E_g) = 0$, because at each time $t_j$, $\\sum_g d_{gj} = d_j$ and $\\sum_g E_{gj} = \\sum_g d_j \\frac{n_{gj}}{n_j} = \\frac{d_j}{n_j} \\sum_g n_{gj} = \\frac{d_j}{n_j} n_j = d_j$. This serves as a useful consistency check.\n\nThis procedure correctly handles ties in event times (by counting all events at $t_j$ in $d_j$) and censoring at event times (by including such subjects in the risk set $n_j$ but not in the event count $d_j$), as specified by the problem statement.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to run the log-rank O-E calculation for all test cases.\n    \"\"\"\n    \n    # Define the test cases from the problem statement.\n    test_cases = [\n        # Test case 1 (two groups, mixed events and censoring with ties)\n        (\n            np.array([5, 8, 12, 12, 15, 17, 20, 22, 22, 25]),\n            np.array([1, 0, 1, 1, 0, 1, 0, 1, 0, 1]),\n            np.array([0, 0, 1, 1, 0, 1, 0, 1, 0, 0])\n        ),\n        # Test case 2 (boundary case: no events, all censored)\n        (\n            np.array([3, 7, 10, 12]),\n            np.array([0, 0, 0, 0]),\n            np.array([0, 1, 0, 1])\n        ),\n        # Test case 3 (one group has no events but is at risk)\n        (\n            np.array([4, 7, 9, 12, 15, 18]),\n            np.array([1, 1, 1, 0, 0, 0]),\n            np.array([0, 0, 0, 1, 1, 1])\n        ),\n        # Test case 4 (three groups with multiple ties and mixed censoring)\n        (\n            np.array([2, 2, 5, 5, 5, 8, 10, 10, 10, 12]),\n            np.array([1, 0, 1, 1, 0, 0, 1, 0, 1, 0]),\n            np.array([0, 1, 0, 1, 2, 2, 0, 1, 2, 2])\n        )\n    ]\n\n    results = []\n    for t_i, delta_i, g_i in test_cases:\n        result = _calculate_log_rank_o_minus_e(t_i, delta_i, g_i)\n        results.append(result)\n\n    # Final print statement in the exact required format.\n    # Convert each inner list to string for the final join.\n    print(f\"[{','.join(map(str, results))}]\")\n\n\ndef _calculate_log_rank_o_minus_e(times, events, groups):\n    \"\"\"\n    Computes the aggregated observed minus expected (O - E) counts for each group.\n\n    Args:\n        times (np.ndarray): Array of observed follow-up times.\n        events (np.ndarray): Array of event indicators (1=event, 0=censored).\n        groups (np.ndarray): Array of group labels.\n\n    Returns:\n        list: A list of floats representing the O-E value for each group,\n              ordered by group index.\n    \"\"\"\n    \n    if len(groups) == 0:\n        return []\n\n    # Determine the number of groups, G. Assumes group labels are 0-indexed.\n    num_groups = np.max(groups) + 1 if groups.size > 0 else 0\n    \n    # Initialize the vector of aggregated differences (O_g - E_g) for each group.\n    o_minus_e = np.zeros(num_groups)\n\n    # Identify the unique time points where at least one event occurred.\n    event_mask = (events == 1)\n    if not np.any(event_mask):\n      # If no events, O-E is 0 for all groups.\n      return o_minus_e.tolist()\n      \n    unique_event_times = np.unique(times[event_mask])\n\n    # Iterate through each unique event time t_j.\n    for t_j in unique_event_times:\n        # Identify subjects at risk at time t_j.\n        # A subject is at risk if their observation time is >= t_j.\n        at_risk_mask = (times >= t_j)\n        \n        # Calculate n_j: total number of subjects at risk at t_j.\n        n_j = np.sum(at_risk_mask)\n\n        # Identify events that occurred exactly at time t_j.\n        events_at_t_j_mask = (times == t_j)  event_mask\n        \n        # Calculate d_j: total number of events at t_j.\n        d_j = np.sum(events_at_t_j_mask)\n\n        if n_j == 0:\n            continue # Should not happen if d_j > 0\n\n        # For each group, calculate d_gj, n_gj and update O-E.\n        for g in range(num_groups):\n            # Mask for subjects in the current group g.\n            in_group_g_mask = (groups == g)\n            \n            # Calculate n_gj: number of subjects in group g at risk at t_j.\n            n_gj = np.sum(at_risk_mask  in_group_g_mask)\n            \n            # Calculate d_gj: number of events in group g at t_j.\n            d_gj = np.sum(events_at_t_j_mask  in_group_g_mask)\n\n            # Calculate E_gj: expected number of events in group g at t_j.\n            e_gj = d_j * (n_gj / n_j) if n_j > 0 else 0.0\n\n            # Accumulate the difference (d_gj - E_gj) for group g.\n            o_minus_e[g] += (d_gj - e_gj)\n            \n    return o_minus_e.tolist()\n\nsolve()\n```"
        }
    ]
}