{
    "hands_on_practices": [
        {
            "introduction": "While introductory texts often rely on large-sample normal approximations for sample size calculations, a rigorous approach for studies with unknown variance requires the noncentral $t$-distribution. This is especially critical in early-phase medical studies where sample sizes are inherently small. This hands-on exercise guides you through deriving the exact power function for a one-sample $t$-test and implementing a numerical algorithm to find the required sample size, bridging the gap between statistical theory and computational practice .",
            "id": "4979726",
            "problem": "A one-sample mean comparison in a clinical pharmacology study is to be analyzed under the Gaussian sampling model with unknown variance. Let $\\{X_i\\}_{i=1}^n$ be independent and identically distributed with $X_i \\sim \\mathcal{N}(\\mu,\\sigma^2)$, where $\\sigma^2$ is unknown. Consider testing the null hypothesis $H_0:\\mu=\\mu_0$ versus the two-sided alternative $H_1:\\mu\\neq\\mu_0$ using the usual Student $t$ statistic constructed from the sample mean and the unbiased sample variance. Define the standardized effect size $d=(\\mu_1-\\mu_0)/\\sigma$, where $\\mu_1$ is the true mean under the alternative, and the target power $\\pi\\in(0,1)$ at type I error level $\\alpha\\in(0,1)$.\n\nStarting only from the following fundamental facts: (i) if $Z\\sim\\mathcal{N}(0,1)$ and $U\\sim\\chi^2_\\nu$ are independent, then the central Student $t$ variable is $T=Z/\\sqrt{U/\\nu}$; (ii) under a nonzero mean shift, the ratio $T_\\text{alt}=(Z+\\delta)/\\sqrt{U/\\nu}$ has a noncentral Student $t$ distribution with degrees of freedom $\\nu$ and noncentrality parameter $\\delta$; (iii) for the one-sample $t$ statistic with $n$ observations from $\\mathcal{N}(\\mu,\\sigma^2)$, the degrees of freedom are $\\nu=n-1$ and, under $H_1:\\mu=\\mu_1$, the noncentrality parameter equals $\\delta(n)=\\sqrt{n}\\,d$, derive an expression for the power $\\mathsf{Power}(n)$ of the two-sided $t$-test as a function of $n$, $\\alpha$, and $d$ in terms of the cumulative distribution function of the noncentral Student $t$ distribution. Then, design and implement a numerical algorithm that finds the smallest integer $n\\geq 2$ such that $\\mathsf{Power}(n)\\geq \\pi$.\n\nYour implementation must adhere to the following computational and output requirements:\n- You must use the exact noncentral Student $t$ distribution for finite $n$; no asymptotic or normal approximations are permitted.\n- All angles are irrelevant. No physical units are involved. All probabilities must be specified and interpreted as decimals in $(0,1)$.\n- If $d=0$, conclude what happens to $\\mathsf{Power}(n)$ for any finite $n$ and handle this edge case consistently in your algorithm: if $\\pi>\\alpha$, declare that no finite $n$ can achieve the target power; if $\\pi\\leq \\alpha$, return the smallest valid $n$.\n- Your algorithm must be monotonicity-aware and must return the minimal $n$ that achieves the target power. It should bracket and then invert $\\mathsf{Power}(n)$ over the integers by a provably terminating search procedure.\n\nTest suite. Your program must compute the minimal $n$ for each of the following parameter sets $(d,\\alpha,\\pi)$ for a two-sided test:\n- Case $1$: $(d,\\alpha,\\pi)=(0.5,0.05,0.8)$.\n- Case $2$: $(d,\\alpha,\\pi)=(0.2,0.05,0.8)$.\n- Case $3$: $(d,\\alpha,\\pi)=(1.0,0.05,0.9)$.\n- Case $4$: $(d,\\alpha,\\pi)=(0.0,0.05,0.8)$.\n- Case $5$: $(d,\\alpha,\\pi)=(0.5,0.10,0.5)$.\n\nFinal output format. Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets. For the five cases above, output $[n_1,n_2,n_3,n_4,n_5]$, where $n_j$ is the minimal integer sample size for case $j$, and where $n_4$ must be a floating-point infinity if no finite sample size can achieve the requested power, written as a floating-point value so that it appears as $inf$ when printed by the programming language.",
            "solution": "The problem is valid as it is scientifically grounded in established statistical theory, well-posed, and objective. It provides a complete and consistent set of definitions and constraints necessary for deriving a unique and meaningful solution. The task is a standard problem in statistical power analysis that requires a rigorous application of statistical distribution theory and numerical methods.\n\nWe begin by deriving the power function for the specified one-sample, two-sided Student's $t$-test.\n\nThe test statistic is given by $T = \\frac{\\bar{X} - \\mu_0}{S/\\sqrt{n}}$, where $\\bar{X}$ is the sample mean and $S^2$ is the unbiased sample variance from a sample of size $n$.\n\nUnder the null hypothesis, $H_0: \\mu = \\mu_0$, the sample is drawn from $\\mathcal{N}(\\mu_0, \\sigma^2)$. The test statistic $T$ follows a central Student's $t$-distribution with $\\nu = n-1$ degrees of freedom, denoted $T \\sim t_{n-1}$.\n\nThe test is two-sided with a type I error rate of $\\alpha$. We reject $H_0$ if $|T| > c$, where $c$ is the critical value. This critical value is the upper $\\alpha/2$ quantile of the central $t$-distribution with $n-1$ degrees of freedom. We define $c(n) \\equiv t_{1-\\alpha/2, n-1}$, where $t_{q, \\nu}$ is the $q$-th quantile of the $t_\\nu$ distribution. The rejection region is thus $T < -c(n)$ or $T > c(n)$.\n\nThe power of the test, $\\mathsf{Power}(n)$, is the probability of rejecting $H_0$ when the alternative hypothesis, $H_1: \\mu = \\mu_1$, is true.\n$$\n\\mathsf{Power}(n) = P\\left( |T| > c(n) \\mid H_1 \\right) = P\\left( T > c(n) \\mid H_1 \\right) + P\\left( T < -c(n) \\mid H_1 \\right)\n$$\nTo evaluate this probability, we must determine the distribution of $T$ under $H_1$. We can rewrite the statistic as:\n$$\nT = \\frac{\\bar{X} - \\mu_0}{S/\\sqrt{n}} = \\frac{(\\bar{X} - \\mu_1) + (\\mu_1 - \\mu_0)}{S/\\sqrt{n}}\n$$\nDividing the numerator and denominator by $\\sigma/\\sqrt{n}$ gives:\n$$\nT = \\frac{\\frac{\\bar{X} - \\mu_1}{\\sigma/\\sqrt{n}} + \\frac{\\mu_1 - \\mu_0}{\\sigma/\\sqrt{n}}}{S/\\sigma} = \\frac{\\frac{\\bar{X} - \\mu_1}{\\sigma/\\sqrt{n}} + \\sqrt{n} \\frac{\\mu_1 - \\mu_0}{\\sigma}}{S/\\sigma}\n$$\nFollowing the provided facts:\n(i) $Z = \\frac{\\bar{X} - \\mu_1}{\\sigma/\\sqrt{n}} \\sim \\mathcal{N}(0,1)$ under $H_1$.\n(ii) By Cochran's theorem, $U = \\frac{(n-1)S^2}{\\sigma^2} \\sim \\chi^2_{n-1}$ and is independent of $Z$. Thus, $S/\\sigma = \\sqrt{U/(n-1)}$.\n(iii) The standardized effect size is $d = (\\mu_1 - \\mu_0)/\\sigma$. The noncentrality parameter is $\\delta(n) = \\sqrt{n} d$.\n\nSubstituting these into the expression for $T$, we have:\n$$\nT = \\frac{Z + \\delta(n)}{\\sqrt{U/\\nu}} \\quad \\text{where } \\nu = n-1\n$$\nThis is the canonical form of a noncentral Student's $t$-distributed random variable. Thus, under $H_1$, $T$ follows a noncentral Student's $t$-distribution with $\\nu = n-1$ degrees of freedom and noncentrality parameter $\\delta(n) = \\sqrt{n} d$. We denote this distribution $t_{n-1, \\delta(n)}$.\n\nLet $F_{t, \\nu, \\delta}(\\cdot)$ be the cumulative distribution function (CDF) of the noncentral $t$-distribution with $\\nu$ degrees of freedom and noncentrality parameter $\\delta$. The power is then:\n$$\n\\mathsf{Power}(n) = P(T_{alt} > c(n)) + P(T_{alt} < -c(n))\n$$\nwhere $T_{alt} \\sim t_{n-1, \\sqrt{n}d}$. This can be expressed using the CDF as:\n$$\n\\mathsf{Power}(n) = (1 - F_{t, n-1, \\sqrt{n}d}(c(n))) + F_{t, n-1, \\sqrt{n}d}(-c(n))\n$$\nwhere $c(n) = t_{1-\\alpha/2, n-1}$. This is the desired expression for power as a function of $n$, $\\alpha$, and $d$.\n\nFor the edge case where the effect size $d=0$, the noncentrality parameter $\\delta(n) = \\sqrt{n} \\cdot 0 = 0$. A noncentral $t$-distribution with a noncentrality parameter of zero is identical to the central $t$-distribution. Therefore, under $H_1$ with $d=0$ (which is equivalent to $H_0$), the statistic $T \\sim t_{n-1}$. The power calculation becomes:\n$$\n\\mathsf{Power}(n) = P(|T| > t_{1-\\alpha/2, n-1} \\mid T \\sim t_{n-1})\n$$\nBy definition of the critical value, this probability is exactly $\\alpha$. So, for $d=0$, $\\mathsf{Power}(n) = \\alpha$ for any $n \\ge 2$. To achieve a target power $\\pi$, we require $\\alpha \\ge \\pi$.\n- If $\\pi > \\alpha$, no finite sample size $n$ can satisfy the condition. The required sample size is infinite.\n- If $\\pi \\le \\alpha$, the condition is met for all valid sample sizes. The problem asks for the smallest integer $n \\ge 2$, so the answer is $n=2$.\n\nTo find the smallest integer $n \\ge 2$ such that $\\mathsf{Power}(n) \\ge \\pi$, we design a numerical algorithm. For any fixed $d \\neq 0$ and $\\alpha$, $\\mathsf{Power}(n)$ is a monotonically increasing function of $n$. This monotonicity allows for an efficient search. Our algorithm consists of two phases:\n\n1.  **Bracketing Phase**: We must find an interval $[n_{low}, n_{high}]$ that is guaranteed to contain the solution. We start with $n_{low} = 2$. If $\\mathsf{Power}(2) \\ge \\pi$, then $n=2$ is the solution. Otherwise, we establish an upper bound by starting with $n_{high} = 4$ and repeatedly doubling it ($n_{high} \\leftarrow 2 \\cdot n_{high}$) until we find an $n_{high}$ such that $\\mathsf{Power}(n_{high}) \\ge \\pi$. At each step, we update $n_{low}$ with the previous value of $n_{high}$. This process efficiently finds a bracket $(n_{low}, n_{high}]$ containing the smallest solution.\n\n2.  **Search Phase**: Once the bracket is established, we use a binary search over the integers in the range $[n_{low}, n_{high}]$ to find the minimum $n$ satisfying the power requirement. Let the search range be `[low, high]`. In each step, we compute the power at the midpoint, `mid = (low + high) // 2`.\n    - If $\\mathsf{Power}(mid) \\ge \\pi$, then `mid` is a potential solution, and we try to find a smaller one by setting `high = mid`.\n    - If $\\mathsf{Power}(mid) < \\pi`, then `mid` is too small, and the solution must be larger. We set `low = mid + 1`.\n    The search terminates when `low` equals `high`, which will be the smallest integer $n$ in the bracket that achieves the target power $\\pi$. Since the bracket was constructed to bound the true minimum $n$, this value is the overall smallest required sample size. This two-phase search is provably terminating and correct due to the monotonicity of the power function.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.stats import t, nct\n\ndef calculate_power(n, d, alpha):\n    \"\"\"\n    Calculates the exact power of a two-sided one-sample t-test.\n\n    Args:\n        n (int): The sample size.\n        d (float): The standardized effect size, (mu1 - mu0) / sigma.\n        alpha (float): The significance level (type I error rate).\n\n    Returns:\n        float: The power of the test.\n    \"\"\"\n    if n < 2:\n        return 0.0\n\n    # Degrees of freedom for the t-test\n    nu = n - 1\n\n    # Critical value from the central t-distribution for a two-sided test.\n    # ppf is the percent point function (inverse of CDF, or quantile function).\n    critical_value = t.ppf(1 - alpha / 2.0, df=nu)\n\n    # Noncentrality parameter under the alternative hypothesis\n    delta = d * np.sqrt(n)\n\n    # Power is the probability of rejecting H0 when H1 is true.\n    # Under H1, the test statistic follows a noncentral t-distribution.\n    # Power = P(T_alt > c) + P(T_alt < -c)\n    # where c is the critical_value and T_alt has a noncentral t-distribution.\n    # nct.cdf(x, df, nc) is the CDF of the noncentral t-distribution.\n    power = 1.0 - nct.cdf(critical_value, df=nu, nc=delta) + nct.cdf(-critical_value, df=nu, nc=delta)\n\n    return power\n\ndef find_min_sample_size(d, alpha, pi):\n    \"\"\"\n    Finds the smallest integer sample size n >= 2 that achieves the target power.\n\n    This function implements a monotonicity-aware search algorithm, first bracketing\n    the solution and then using binary search to find the exact integer.\n\n    Args:\n        d (float): The standardized effect size.\n        alpha (float): The significance level.\n        pi (float): The target power.\n\n    Returns:\n        int or float: The minimal sample size, or np.inf if no finite size exists.\n    \"\"\"\n    # Handle the edge case where the effect size is zero.\n    if d == 0:\n        # If d=0, the power is always equal to alpha for any n >= 2.\n        # A solution exists only if the target power is not greater than alpha.\n        if pi > alpha:\n            return np.inf\n        else:\n            # If power >= pi is achievable, the smallest valid n is 2.\n            return 2\n\n    # A minimal sample size of n=2 is required for variance calculation.\n    # Check if n=2 already meets the power requirement.\n    if calculate_power(2, d, alpha) >= pi:\n        return 2\n\n    # Bracketing phase: Find an interval [n_low, n_high] that contains the solution.\n    # We expand the interval exponentially until power(n_high) >= pi.\n    n_low = 2\n    n_high = 4\n    while calculate_power(n_high, d, alpha) < pi:\n        n_low = n_high\n        n_high *= 2\n        # Safety stop for unreasonable sample sizes\n        if n_high > 10**7:\n            raise OverflowError(\"Sample size search exceeded 10,000,000.\")\n\n    # Search phase: Use binary search to find the smallest integer n in the bracket.\n    # The solution is known to be in the range [n_low, n_high].\n    low = n_low\n    high = n_high\n    \n    # This binary search variant finds the first element in a sorted sequence\n    # that satisfies the condition (i.e., power >= pi).\n    while low < high:\n        mid = (low + high) // 2\n        if calculate_power(mid, d, alpha) < pi:\n            low = mid + 1\n        else:\n            high = mid\n            \n    # The loop terminates when low == high, which is the smallest n satisfying the condition.\n    return low\n\ndef solve():\n    \"\"\"\n    Main function to solve the problem for the given test cases.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    # Each case is a tuple: (d, alpha, pi)\n    test_cases = [\n        (0.5, 0.05, 0.8),  # Case 1\n        (0.2, 0.05, 0.8),  # Case 2\n        (1.0, 0.05, 0.9),  # Case 3\n        (0.0, 0.05, 0.8),  # Case 4\n        (0.5, 0.10, 0.5),  # Case 5\n    ]\n\n    results = []\n    for d, alpha, pi in test_cases:\n        result = find_min_sample_size(d, alpha, pi)\n        results.append(result)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "The objective of a clinical trial—whether to prove a new therapy is better (superiority) or simply not unacceptably worse (non-inferiority)—has profound implications for its design and required sample size. This exercise explores this critical distinction for a binary endpoint, a common scenario in medical research. By working through these calculations, you will gain practical insight into how the choice of a non-inferiority margin, $\\Delta$, becomes a primary driver of sample size, often with non-intuitive and dramatic consequences .",
            "id": "4979728",
            "problem": "A sponsor is designing randomized, parallel-group clinical trials for a binary endpoint (e.g., clinical cure) with equal allocation between a new therapy and a control. Based on prior evidence, the control group cure proportion is expected to be $0.70$. The sponsor is considering either a superiority trial or a noninferiority (NI) trial on the same endpoint. Assume large-sample normal approximations for the difference of two independent binomial proportions, equal group sizes, and that sample size is chosen to control a one-sided Type I error probability $\\alpha = 0.025$ with power $1-\\beta = 0.90$ against a specified alternative. Use the standard normal quantiles $z_{1-0.025} \\approx 1.96$ and $z_{0.90} \\approx 1.28$. Ignore continuity corrections and finite-sample adjustments. \n\nConsider the following planning assumptions:\n- Superiority design: null hypothesis that the new therapy is not better than control on absolute risk difference, with the alternative targeting an absolute improvement from $0.70$ to $0.75$.\n- Noninferiority design: null hypothesis that the new therapy is worse than control by more than a margin $\\Delta > 0$ on absolute risk difference, with the alternative planning scenario $p_T = p_C = 0.70$ (true equality), evaluated at margins $\\Delta \\in \\{0.10, 0.05, 0.03\\}$.\n\nWhich of the following statements are correct under these assumptions?\n\nA. For the superiority design targeting an absolute improvement from $0.70$ to $0.75$, the required per-group sample size is approximately $n \\approx 1{,}670$, whereas the corresponding noninferiority design with $\\Delta = 0.05$ and $p_T = p_C = 0.70$ requires a slightly larger per-group $n$.\n\nB. Halving the noninferiority margin from $\\Delta = 0.10$ to $\\Delta = 0.05$ approximately doubles the required per-group $n$ when $p_T = p_C = 0.70$.\n\nC. For noninferiority with $\\Delta = 0.03$, $p_T = p_C = 0.70$, $\\alpha = 0.025$ (one-sided), and power $0.90$, the per-group $n$ will be on the order of about $4{,}900$, which is roughly $11$ times larger than for $\\Delta = 0.10$ under the same assumptions.\n\nD. Holding the same absolute effect in the denominator and the same nuisance proportions, replacing a one-sided noninferiority test at $\\alpha = 0.025$ with a two-sided superiority test at total $\\alpha = 0.05$ strictly reduces the required $n$ because the critical value is smaller.",
            "solution": "The user wants me to validate and solve a biostatistics problem concerning sample size calculations for clinical trials.\n\n### Problem Validation\n\n**Step 1: Extract Givens**\n- **Trial type**: Randomized, parallel-group clinical trials with equal allocation ($n_T = n_C = n$).\n- **Endpoint**: Binary.\n- **Control group proportion**: Expected $p_C = 0.70$.\n- **Statistical method**: Large-sample normal approximation for the difference of two independent binomial proportions.\n- **Type I error**: One-sided $\\alpha = 0.025$.\n- **Power**: $1-\\beta = 0.90$.\n- **Normal quantiles**: $z_{1-\\alpha} = z_{0.975} \\approx 1.96$; $z_{1-\\beta} = z_{0.90} \\approx 1.28$.\n- **Simplifying assumptions**: No continuity corrections or finite-sample adjustments.\n- **Superiority design**:\n    - Null hypothesis $H_0: p_T - p_C \\le 0$.\n    - Alternative for power calculation: $p_C = 0.70$, $p_T = 0.75$.\n- **Noninferiority (NI) design**:\n    - Null hypothesis $H_0: p_T - p_C \\le -\\Delta$ for a margin $\\Delta > 0$.\n    - Alternative for power calculation: $p_T = p_C = 0.70$.\n    - Margins considered: $\\Delta \\in \\{0.10, 0.05, 0.03\\}$.\n\n**Step 2: Validate Using Extracted Givens**\nThe problem is scientifically grounded, well-posed, and objective. It outlines a standard biostatistical task: calculating and comparing sample sizes for superiority and noninferiority trials. The data provided are complete and consistent for applying the standard large-sample formulas. The assumptions ($p_C$, effect sizes, margins, error rates) are all within a realistic range for clinical trial planning. There are no contradictions, ambiguities, or violations of scientific principles.\n\n**Step 3: Verdict and Action**\nThe problem is **valid**. I will proceed with the solution.\n\n### Derivation and Option Evaluation\n\nThe general formula for the per-group sample size $n$ for comparing two proportions $p_T$ and $p_C$ from independent groups of equal size, using a one-sided test with significance level $\\alpha$ and power $1-\\beta$, is given by:\n$$ n = \\frac{(z_{1-\\alpha} \\sqrt{V_0} + z_{1-\\beta} \\sqrt{V_A})^2}{(\\delta_A - \\delta_0)^2} $$\nwhere $\\delta_0$ is the boundary of the null hypothesis on the difference $p_T - p_C$, $\\delta_A$ is the assumed true difference under the alternative hypothesis, $V_0$ is the pooled variance term under the null, and $V_A$ is the pooled variance term under the alternative. A common and standard simplification, which we will employ as implied by the problem's setup, is to assume the variance is constant and evaluated at the alternative hypothesis values, such that $V_0 \\approx V_A = p_{TA}(1-p_{TA}) + p_{CA}(1-p_{CA})$, where $p_{TA}$ and $p_{CA}$ are the proportions under the alternative.\n\nThe simplified formula becomes:\n$$ n = \\frac{(z_{1-\\alpha} + z_{1-\\beta})^2 (p_{TA}(1-p_{TA}) + p_{CA}(1-p_{CA}))}{(\\delta_A - \\delta_0)^2} $$\nWe are given $z_{1-\\alpha} = z_{0.975} \\approx 1.96$ and $z_{1-\\beta} = z_{0.90} \\approx 1.28$. Therefore, the term $(z_{1-\\alpha} + z_{1-\\beta})^2 \\approx (1.96 + 1.28)^2 = (3.24)^2 = 10.4976$.\n\n**1. Superiority Design Calculation**\n- Null hypothesis: $H_0: p_T - p_C \\le 0$, so $\\delta_0 = 0$.\n- Alternative for power: $p_{CA}=0.70$ and $p_{TA}=0.75$.\n- The difference under the alternative is $\\delta_A = p_{TA} - p_{CA} = 0.75 - 0.70 = 0.05$.\n- The variance term is $V_A = p_{TA}(1-p_{TA}) + p_{CA}(1-p_{CA}) = 0.75(1-0.75) + 0.70(1-0.70) = 0.75(0.25) + 0.70(0.30) = 0.1875 + 0.21 = 0.3975$.\n- The per-group sample size $n_{sup}$ is:\n$$ n_{sup} = \\frac{(1.96 + 1.28)^2 \\times 0.3975}{(0.05)^2} = \\frac{10.4976 \\times 0.3975}{0.0025} = \\frac{4.172796}{0.0025} = 1669.1184 $$\nSo, $n_{sup} \\approx 1670$.\n\n**2. Noninferiority Design Calculation**\n- Null hypothesis: $H_0: p_T - p_C \\le -\\Delta$, so $\\delta_0 = -\\Delta$.\n- Alternative for power: $p_{TA} = p_{CA} = 0.70$.\n- The difference under the alternative is $\\delta_A = p_{TA} - p_{CA} = 0.70 - 0.70 = 0$.\n- The denominator of the sample size formula is $(\\delta_A - \\delta_0)^2 = (0 - (-\\Delta))^2 = \\Delta^2$.\n- The variance term is $V_A = p_{TA}(1-p_{TA}) + p_{CA}(1-p_{CA}) = 0.70(1-0.70) + 0.70(1-0.70) = 2 \\times (0.70 \\times 0.30) = 2 \\times 0.21 = 0.42$.\n- The per-group sample size $n_{NI}$ is:\n$$ n_{NI} = \\frac{(1.96 + 1.28)^2 \\times 0.42}{\\Delta^2} = \\frac{10.4976 \\times 0.42}{\\Delta^2} = \\frac{4.4090}{ ( \\Delta^2)} $$\nThis general formula for NI trials under these assumptions will be used to evaluate the options.\n\n---\n**Option-by-Option Analysis**\n\n**A. For the superiority design targeting an absolute improvement from $0.70$ to $0.75$, the required per-group sample size is approximately $n \\approx 1{,}670$, whereas the corresponding noninferiority design with $\\Delta = 0.05$ and $p_T = p_C = 0.70$ requires a slightly larger per-group $n$.**\n- The first part of the statement claims $n_{sup} \\approx 1{,}670$. Our calculation yielded $n_{sup} \\approx 1669.1$, which rounds to $1670$. This is correct.\n- For the second part, we calculate the noninferiority sample size for $\\Delta = 0.05$:\n$$ n_{NI}(\\Delta=0.05) = \\frac{4.4090}{(0.05)^2} = \\frac{4.4090}{0.0025} = 1763.6 $$\nSo, $n_{NI} \\approx 1764$.\n- Comparing the two, $1764 > 1670$. The NI design requires a larger sample size. The reason is that the effect size in the denominator is the same in magnitude ($0.05$ vs $\\Delta=0.05$), but the variance term for the NI calculation ($0.42$) is larger than for the superiority calculation ($0.3975$). The statement is factually accurate.\n- **Verdict: Correct.**\n\n**B. Halving the noninferiority margin from $\\Delta = 0.10$ to $\\Delta = 0.05$ approximately doubles the required per-group $n$ when $p_T = p_C = 0.70$.**\n- Our sample size formula for the NI design is $n_{NI} \\propto \\frac{1}{\\Delta^2}$.\n- Let $n_1$ be the sample size for $\\Delta_1 = 0.10$ and $n_2$ be the sample size for $\\Delta_2 = 0.05$.\n- Halving the margin means $\\Delta_2 = \\Delta_1 / 2$.\n- The ratio of sample sizes is $\\frac{n_2}{n_1} = \\frac{1/\\Delta_2^2}{1/\\Delta_1^2} = \\left(\\frac{\\Delta_1}{\\Delta_2}\\right)^2 = \\left(\\frac{\\Delta_1}{\\Delta_1/2}\\right)^2 = 2^2 = 4$.\n- Thus, halving the NI margin quadruples the required sample size, it does not double it.\n- Explicitly:\n    - $n_{NI}(\\Delta=0.10) = \\frac{4.4090}{(0.10)^2} = 440.9 \\approx 441$.\n    - $n_{NI}(\\Delta=0.05) = 1763.6 \\approx 1764$.\n    - The ratio is $1764 / 441 = 4$.\n- The statement is false.\n- **Verdict: Incorrect.**\n\n**C. For noninferiority with $\\Delta = 0.03$, $p_T = p_C = 0.70$, $\\alpha = 0.025$ (one-sided), and power $0.90$, the per-group $n$ will be on the order of about $4{,}900$, which is roughly $11$ times larger than for $\\Delta = 0.10$ under the same assumptions.**\n- First, we calculate the sample size for $\\Delta = 0.03$:\n$$ n_{NI}(\\Delta=0.03) = \\frac{4.4090}{(0.03)^2} = \\frac{4.4090}{0.0009} = 4898.88... $$\nThis value, $n \\approx 4899$, is indeed \"on the order of about $4{,}900$\". The first part is correct.\n- Second, we compare this to the sample size for $\\Delta=0.10$, which we calculated as $n_{NI}(\\Delta=0.10) \\approx 441$.\n- The ratio is $\\frac{n_{NI}(\\Delta=0.03)}{n_{NI}(\\Delta=0.10)} = \\frac{4898.88...}{440.9} \\approx 11.11$.\n- This is \"roughly $11$ times larger\".\n- Alternatively, using the proportionality: Ratio $= \\left(\\frac{\\Delta_1}{\\Delta_2}\\right)^2 = \\left(\\frac{0.10}{0.03}\\right)^2 = \\left(\\frac{10}{3}\\right)^2 = \\frac{100}{9} \\approx 11.11$.\n- Both parts of the statement are accurate.\n- **Verdict: Correct.**\n\n**D. Holding the same absolute effect in the denominator and the same nuisance proportions, replacing a one-sided noninferiority test at $\\alpha = 0.025$ with a two-sided superiority test at total $\\alpha = 0.05$ strictly reduces the required $n$ because the critical value is smaller.**\n- Let's analyze the components of the sample size formula that are affected. The formula is driven by the term $(z_{\\text{critical}} + z_{\\text{power}})^2$.\n- Case 1: One-sided test at $\\alpha = 0.025$. The relevant quantile for the Type I error is $z_{1-\\alpha} = z_{1-0.025} = z_{0.975} \\approx 1.96$.\n- Case 2: Two-sided test at total $\\alpha = 0.05$. This means the alpha risk is split into two tails, each of size $\\alpha/2 = 0.025$. For an upper-tail rejection region, the critical value is $z_{1-\\alpha/2} = z_{1-0.025} = z_{0.975} \\approx 1.96$.\n- The critical values for the Type I error component are identical in both scenarios ($z_{0.975}$). The power component ($z_{1-\\beta}$) is also the same. Therefore, the multiplier $(z_{1-\\alpha} + z_{1-\\beta})^2$ for the one-sided test is identical to the multiplier $(z_{1-\\alpha/2} + z_{1-\\beta})^2$ for the two-sided test.\n- Since all other components of the formula (\"absolute effect in the denominator and the same nuisance proportions\") are held constant by the problem's premise, the required sample size $n$ will be identical, not strictly reduced.\n- The reasoning provided (\"because the critical value is smaller\") is false. The relevant critical value is the same in both cases.\n- **Verdict: Incorrect.**",
            "answer": "$$\\boxed{AC}$$"
        },
        {
            "introduction": "Efficient study designs are paramount for conducting ethical and feasible medical research. This practice problem explores the power of the crossover design, where each subject serves as their own control, to dramatically increase statistical efficiency when analyzing count data, such as the rate of recurrent infections. You will apply the method of conditional inference to eliminate subject-specific nuisance parameters and derive the sample size from first principles, highlighting how sophisticated statistical modeling directly leads to more powerful and economical trials .",
            "id": "4979687",
            "problem": "A randomized two-period crossover study will compare a new prophylactic regimen against standard care on the rate of recurrent acute infection episodes in a chronic-disease population. Each subject will contribute two observation periods of equal length $T$, one on new prophylaxis and one on standard care, with the order randomized. Let $Y_{i1}$ and $Y_{i2}$ denote the event counts for subject $i$ in the prophylaxis and standard-care periods, respectively. Assume the following generative model rooted in first principles:\n\n- Conditional on an unobserved subject-specific baseline intensity $\\lambda_i$, events within each period arise from a Poisson process, and the two periods are conditionally independent.\n- The mean counts satisfy $\\mathbb{E}[Y_{i1} \\mid \\lambda_i] = \\lambda_i T \\exp(\\beta/2)$ and $\\mathbb{E}[Y_{i2} \\mid \\lambda_i] = \\lambda_i T \\exp(-\\beta/2)$, where $\\beta = \\ln(\\theta)$ is the log rate ratio comparing prophylaxis to standard care.\n\nPlanning values from prior data suggest $\\mathbb{E}[\\lambda_i] = m = 0.04$ events per day, with each period of length $T = 60$ days. The study aims to detect a clinically meaningful rate ratio $\\theta = 0.75$ at a two-sided type I error $\\alpha = 0.05$ with power $1 - \\beta_{\\text{power}} = 0.90$.\n\nUsing the conditional Poisson approach that conditions on the within-subject total $S_i = Y_{i1} + Y_{i2}$ to eliminate the nuisance $\\lambda_i$, derive from first principles a Wald test for $H_0\\!:\\, \\beta = 0$ and obtain the expected Fisher information per pair under the alternative. Then compute the minimum integer number of matched pairs $n$ required to achieve the stated power.\n\nFinally, for design insight, suppose that in an unpaired two-arm parallel design with equal allocation, subject-level heterogeneity induces negative binomial variation with variance function $\\operatorname{Var}(Y) = \\mu \\{1 + \\phi \\mu\\}$ and overdispersion parameter $\\phi = 0.5$. Using the same $m$, $T$, and $\\theta$, compute the ratio of per-total-subject information (one matched pair in the paired design versus two independent subjects, one per arm, in the unpaired design). Explain the efficiency gain or loss implied by this ratio.\n\nReport as your final numeric answer only the smallest integer $n$ that achieves the target power. Do not include any additional quantities in your final answer.",
            "solution": "The problem statement is critically validated and found to be valid. It is scientifically grounded in established statistical theory for clinical trial design, specifically for crossover studies with count data. The problem is well-posed, with a complete and consistent set of givens, allowing for the derivation of a unique and meaningful solution. The terminology is objective and precise.\n\nThe first step is to derive the statistical model for the conditional analysis. Let $Y_{i1}$ and $Y_{i2}$ be the event counts for subject $i$ in the prophylaxis and standard care periods, respectively. The period length is $T$. Conditional on a subject-specific baseline rate $\\lambda_i$, the counts are independent Poisson variables:\n$Y_{i1} \\mid \\lambda_i \\sim \\text{Poisson}(\\mu_{i1})$ with $\\mu_{i1} = \\lambda_i T \\exp(\\beta/2)$\n$Y_{i2} \\mid \\lambda_i \\sim \\text{Poisson}(\\mu_{i2})$ with $\\mu_{i2} = \\lambda_i T \\exp(-\\beta/2)$\nwhere $\\beta = \\ln(\\theta)$ is the log rate ratio.\n\nTo eliminate the nuisance parameter $\\lambda_i$, we condition on the total count for subject $i$, $S_i = Y_{i1} + Y_{i2}$. The distribution of $S_i$ conditional on $\\lambda_i$ is also Poisson, as it is the sum of two independent Poisson variables:\n$S_i \\mid \\lambda_i \\sim \\text{Poisson}(\\mu_{i1} + \\mu_{i2})$.\nThe conditional distribution of $Y_{i1}$ given $S_i=s_i$ is:\n$$ P(Y_{i1}=y_{i1} \\mid S_i=s_i) = \\frac{P(Y_{i1}=y_{i1}, Y_{i2}=s_i-y_{i1})}{P(S_i=s_i)} $$\nConditional on $\\lambda_i$, this probability becomes:\n$$ P(Y_{i1}=y_{i1} \\mid S_i=s_i, \\lambda_i) = \\frac{P(Y_{i1}=y_{i1} \\mid \\lambda_i) P(Y_{i2}=s_i-y_{i1} \\mid \\lambda_i)}{P(S_i=s_i \\mid \\lambda_i)} $$\n$$ = \\frac{ \\frac{\\exp(-\\mu_{i1})\\mu_{i1}^{y_{i1}}}{y_{i1}!} \\frac{\\exp(-\\mu_{i2})\\mu_{i2}^{s_i-y_{i1}}}{(s_i-y_{i1})!} }{ \\frac{\\exp(-(\\mu_{i1}+\\mu_{i2}))(\\mu_{i1}+\\mu_{i2})^{s_i}}{s_i!} } $$\n$$ = \\frac{s_i!}{y_{i1}!(s_i-y_{i1})!} \\frac{\\mu_{i1}^{y_{i1}}\\mu_{i2}^{s_i-y_{i1}}}{(\\mu_{i1}+\\mu_{i2})^{s_i}} = \\binom{s_i}{y_{i1}} p^{y_{i1}} (1-p)^{s_i-y_{i1}} $$\nwhere the probability $p$ is:\n$$ p = \\frac{\\mu_{i1}}{\\mu_{i1}+\\mu_{i2}} = \\frac{\\lambda_i T \\exp(\\beta/2)}{\\lambda_i T \\exp(\\beta/2) + \\lambda_i T \\exp(-\\beta/2)} = \\frac{\\exp(\\beta/2)}{\\exp(\\beta/2) + \\exp(-\\beta/2)} $$\nThis simplifies to $p = \\frac{1}{1 + \\exp(-\\beta)}$, which is the logistic function. Crucially, $p$ does not depend on $\\lambda_i$, so the conditional distribution is free of the nuisance parameter. Thus, for each subject $i$ with total count $S_i > 0$, the conditional distribution is Binomial: $Y_{i1} \\mid S_i=s_i \\sim \\text{Binomial}(s_i, p)$.\n\nThe log-likelihood for subject $i$ based on this conditional distribution is:\n$$ l_i(\\beta) = \\ln\\binom{S_i}{Y_{i1}} + Y_{i1}\\ln(p) + (S_i-Y_{i1})\\ln(1-p) $$\n$$ l_i(\\beta) = \\text{const} + Y_{i1}\\beta - S_i\\ln(1+\\exp(\\beta)) $$\nThe score function (first derivative) for subject $i$ is:\n$$ U_i(\\beta) = \\frac{\\partial l_i}{\\partial \\beta} = Y_{i1} - S_i \\frac{\\exp(\\beta)}{1+\\exp(\\beta)} = Y_{i1} - S_i p $$\nThe Fisher information for subject $i$, conditional on $S_i$, is:\n$$ I_i(\\beta \\mid S_i) = -\\frac{\\partial^2 l_i}{\\partial \\beta^2} = S_i \\frac{\\partial p}{\\partial \\beta} = S_i p(1-p) $$\nA Wald test for $H_0: \\beta=0$ is based on the test statistic $W = \\frac{\\hat{\\beta}}{\\text{se}(\\hat{\\beta})}$, where $\\hat{\\beta}$ is the maximum likelihood estimate of $\\beta$ from the full conditional likelihood $L(\\beta) = \\sum_i l_i(\\beta)$, and $\\text{se}(\\hat{\\beta}) = \\left(\\sum_i I_i(\\hat{\\beta} \\mid S_i)\\right)^{-1/2}$. The test rejects $H_0$ if $|W| > z_{1-\\alpha/2}$.\n\nNext, we derive the expected Fisher information per matched pair, $I_1(\\beta)$. This is the expectation of $I_i(\\beta \\mid S_i)$ over the distribution of $S_i$:\n$$ I_1(\\beta) = \\mathbb{E}[I_i(\\beta \\mid S_i)] = \\mathbb{E}[S_i p(1-p)] = \\mathbb{E}[S_i] p(1-p) $$\nThe expectation of $S_i$ is found by first conditioning on $\\lambda_i$:\n$$ \\mathbb{E}[S_i \\mid \\lambda_i] = \\mu_{i1} + \\mu_{i2} = \\lambda_i T (\\exp(\\beta/2) + \\exp(-\\beta/2)) = 2\\lambda_i T \\cosh(\\beta/2) $$\nTaking the expectation over $\\lambda_i$, and using $\\mathbb{E}[\\lambda_i] = m$:\n$$ \\mathbb{E}[S_i] = 2mT\\cosh(\\beta/2) $$\nThe term $p(1-p)$ simplifies to:\n$$ p(1-p) = \\frac{\\exp(\\beta/2)}{\\exp(\\beta/2) + \\exp(-\\beta/2)} \\frac{\\exp(-\\beta/2)}{\\exp(\\beta/2) + \\exp(-\\beta/2)} = \\frac{1}{(\\exp(\\beta/2) + \\exp(-\\beta/2))^2} = \\frac{1}{4\\cosh^2(\\beta/2)} $$\nCombining these gives the expected information per pair:\n$$ I_1(\\beta) = 2mT\\cosh(\\beta/2) \\cdot \\frac{1}{4\\cosh^2(\\beta/2)} = \\frac{mT}{2\\cosh(\\beta/2)} $$\nUnder the alternative hypothesis, $\\theta_A = 0.75$, so $\\beta_A = \\ln(0.75)$.\n$$ \\cosh(\\beta_A/2) = \\frac{\\exp(\\ln(0.75)/2) + \\exp(-\\ln(0.75)/2)}{2} = \\frac{\\sqrt{0.75} + 1/\\sqrt{0.75}}{2} = \\frac{\\sqrt{3}/2 + 2/\\sqrt{3}}{2} = \\frac{7}{4\\sqrt{3}} $$\nThe information under the alternative is:\n$$ I_1(\\beta_A) = \\frac{mT}{2(7/(4\\sqrt{3}))} = \\frac{2\\sqrt{3}mT}{7} $$\n\nThe sample size $n$ required to achieve power $1-\\beta_{\\text{power}}$ for a two-sided test at level $\\alpha$ is given by the standard formula for a Wald test:\n$$ n = \\frac{(z_{1-\\alpha/2} + z_{1-\\beta_{\\text{power}}})^2}{\\beta_A^2 I_1(\\beta_A)} $$\nWe are given $\\alpha=0.05$ and $1-\\beta_{\\text{power}}=0.90$, which yields $z_{1-\\alpha/2}=z_{0.975} \\approx 1.96$ and $z_{1-\\beta_{\\text{power}}}=z_{0.90} \\approx 1.2816$.\nThe planning values are $m=0.04$ events/day and $T=60$ days. The effect size is $\\beta_A = \\ln(0.75) \\approx -0.28768$.\nThe information per pair under the alternative is:\n$$ I_1(\\beta_A) = \\frac{2\\sqrt{3}(0.04)(60)}{7} = \\frac{4.8\\sqrt{3}}{7} \\approx 1.18765 $$\nPlugging these values into the sample size formula:\n$$ n = \\frac{(1.96 + 1.2816)^2}{(\\ln(0.75))^2 \\left(\\frac{4.8\\sqrt{3}}{7}\\right)} \\approx \\frac{(3.2416)^2}{(-0.28768)^2(1.18765)} \\approx \\frac{10.508}{0.08276 \\times 1.18765} \\approx \\frac{10.508}{0.09827} \\approx 106.93 $$\nSince the number of pairs must be an integer, we take the ceiling, which gives $n=107$.\n\nFinally, for design insight, we compute the ratio of information. The information from one matched pair in the paired design is $I_{\\text{paired}} = I_1(\\beta_A) \\approx 1.1877$.\nFor the unpaired design, we have two independent subjects, one in each arm, with counts following a negative binomial distribution with variance $\\operatorname{Var}(Y) = \\mu(1+\\phi\\mu)$ and $\\phi=0.5$. The means are $\\mu_1 = mT\\exp(\\beta/2)$ and $\\mu_2 = mT\\exp(-\\beta/2)$. The Fisher information for $\\beta$ from these two subjects is:\n$$ I_{\\text{unpaired}}(\\beta) = \\left(\\frac{d\\mu_1}{d\\beta}\\right)^2 \\frac{1}{\\operatorname{Var}(Y_1)} + \\left(\\frac{d\\mu_2}{d\\beta}\\right)^2 \\frac{1}{\\operatorname{Var}(Y_2)} $$\nWith $\\frac{d\\mu_1}{d\\beta} = \\frac{1}{2}\\mu_1$ and $\\frac{d\\mu_2}{d\\beta} = -\\frac{1}{2}\\mu_2$, this becomes:\n$$ I_{\\text{unpaired}}(\\beta) = \\frac{1}{4} \\left( \\frac{\\mu_1}{1+\\phi\\mu_1} + \\frac{\\mu_2}{1+\\phi\\mu_2} \\right) $$\nUnder the alternative, $mT=2.4$, $\\beta_A=\\ln(0.75)$, $\\phi=0.5$.\n$\\mu_1 = 2.4 \\sqrt{0.75} = 1.2\\sqrt{3} \\approx 2.0785$.\n$\\mu_2 = 2.4 / \\sqrt{0.75} = 1.6\\sqrt{3} \\approx 2.7713$.\n$$ I_{\\text{unpaired}}(\\beta_A) \\approx \\frac{1}{4} \\left( \\frac{2.0785}{1+0.5(2.0785)} + \\frac{2.7713}{1+0.5(2.7713)} \\right) \\approx \\frac{1}{4} \\left( \\frac{2.0785}{2.03925} + \\frac{2.7713}{2.38565} \\right) \\approx 0.5452 $$\nThe ratio of per-total-subject information is:\n$$ \\text{Ratio} = \\frac{I_{\\text{paired}}}{I_{\\text{unpaired}}} \\approx \\frac{1.1877}{0.5452} \\approx 2.18 $$\nThis ratio greater than $2$ indicates a substantial efficiency gain for the crossover design. For the same number of total observations (e.g., $1$ pair vs $2$ individuals), the crossover study provides more than twice the statistical information about the treatment effect. This gain is due to the paired design's ability to eliminate between-subject variability ($\\lambda_i$) by making within-subject comparisons. The large overdispersion parameter $\\phi=0.5$ in the parallel design model signifies high between-subject variability, which inflates the variance of estimates and reduces information, making the crossover design comparatively much more efficient.",
            "answer": "$$\n\\boxed{107}\n$$"
        }
    ]
}