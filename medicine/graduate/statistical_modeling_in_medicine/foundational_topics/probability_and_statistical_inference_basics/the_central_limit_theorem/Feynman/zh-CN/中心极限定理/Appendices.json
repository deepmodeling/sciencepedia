{
    "hands_on_practices": [
        {
            "introduction": "理解中心极限定理（Central Limit Theorem, CLT）的第一步是掌握样本均值的变异性。本练习将引导我们从第一性原理出发，推导独立同分布（i.i.d.）数据下样本均值的方差公式。这个基础性的推导不仅揭示了为何样本量越大，估计越精确，也为理解中心极限定理中标准误的由来奠定了坚实的数学基础。",
            "id": "4986781",
            "problem": "一家临床实验室正在验证一种用于测量住院患者全身性炎症生物标志物的高通量检测方法。设 $X_1, X_2, \\ldots, X_n$ 表示对 $n$ 名不同患者的生物标志物测量值，假设这些测量值是独立同分布的（i.i.d.），具有有限均值 $E[X_i] = \\mu$ 和有限方差 $\\operatorname{Var}(X_i) = \\sigma^2$。研究团队将报告样本均值 $\\bar{X}_n = \\frac{1}{n}\\sum_{i=1}^{n} X_i$ 以及基于中心极限定理（CLT）的 $\\mu$ 的大样本置信区间。\n\n仅从期望和方差的核心定义、独立性意味着期望可分解的性质，以及中心极限定理（CLT）在二阶矩有限时为适当标准化的平均值提供正态近似这一公认事实出发，从第一性原理推导样本均值 $\\bar{X}_n$ 的方差，而不使用任何预先记忆的方差公式。然后，将此推导与在这种医学背景下大样本均值置信区间所基于的标准误联系起来，解释为什么在中心极限定理下标准误会随着 $n$ 的变化而变化。\n\n以 $\\sigma$ 和 $n$ 的闭式解析表达式给出 $\\operatorname{Var}(\\bar{X}_n)$ 的最终答案。在最终的方框表达式中不要包含任何单位。不需要进行数值四舍五入。",
            "solution": "题目要求从第一性原理出发，为一组独立同分布（i.i.d.）的随机变量 $X_1, X_2, \\ldots, X_n$ 推导样本均值的方差 $\\operatorname{Var}(\\bar{X}_n)$。给定对于所有 $i \\in \\{1, \\ldots, n\\}$，$E[X_i] = \\mu$ 和 $\\operatorname{Var}(X_i) = \\sigma^2$ 都是有限的。推导过程必须仅依赖于期望和方差的核心定义以及独立性性质。\n\n首先，我们陈述样本均值 $\\bar{X}_n$ 的定义：\n$$\n\\bar{X}_n = \\frac{1}{n}\\sum_{i=1}^{n} X_i\n$$\n任何随机变量 $Y$ 的方差的核心定义为 $\\operatorname{Var}(Y) = E[(Y - E[Y])^2]$。要将此定义应用于 $\\bar{X}_n$，我们必须首先确定其期望 $E[\\bar{X}_n]$。\n\n利用期望算子的线性性质，即对于常数 $a, b$ 和随机变量 $Y, Z$，有 $E[aY + bZ] = aE[Y] + bE[Z]$，我们可以如下计算 $E[\\bar{X}_n]$：\n$$\nE[\\bar{X}_n] = E\\left[\\frac{1}{n}\\sum_{i=1}^{n} X_i\\right]\n$$\n项 $\\frac{1}{n}$ 是一个常数，可以从期望中提取出来：\n$$\nE[\\bar{X}_n] = \\frac{1}{n} E\\left[\\sum_{i=1}^{n} X_i\\right]\n$$\n和的期望等于期望的和：\n$$\nE[\\bar{X}_n] = \\frac{1}{n} \\sum_{i=1}^{n} E[X_i]\n$$\n由于随机变量是同分布的，均值为 $\\mu$，因此对于所有 $i$ 都有 $E[X_i] = \\mu$。将此代入表达式可得：\n$$\nE[\\bar{X}_n] = \\frac{1}{n} \\sum_{i=1}^{n} \\mu = \\frac{1}{n} (n\\mu) = \\mu\n$$\n因此，样本均值 $\\bar{X}_n$ 是总体均值 $\\mu$ 的一个无偏估计量。\n\n现在我们可以继续推导方差 $\\operatorname{Var}(\\bar{X}_n)$。使用方差的定义，令 $Y = \\bar{X}_n$ 且 $E[Y] = \\mu$：\n$$\n\\operatorname{Var}(\\bar{X}_n) = E\\left[ (\\bar{X}_n - E[\\bar{X}_n])^2 \\right] = E\\left[ (\\bar{X}_n - \\mu)^2 \\right]\n$$\n代入 $\\bar{X}_n$ 的定义：\n$$\n\\bar{X}_n - \\mu = \\left(\\frac{1}{n}\\sum_{i=1}^{n} X_i\\right) - \\mu = \\frac{1}{n}\\left(\\sum_{i=1}^{n} X_i - n\\mu\\right) = \\frac{1}{n}\\sum_{i=1}^{n} (X_i - \\mu)\n$$\n将此表达式平方，我们得到：\n$$\n(\\bar{X}_n - \\mu)^2 = \\left( \\frac{1}{n}\\sum_{i=1}^{n} (X_i - \\mu) \\right)^2 = \\frac{1}{n^2} \\left( \\sum_{i=1}^{n} (X_i - \\mu) \\right)^2\n$$\n平方和可以展开为一个双重求和，将索引相等和不相等的项分开：\n$$\n\\left( \\sum_{i=1}^{n} (X_i - \\mu) \\right)^2 = \\sum_{i=1}^{n} \\sum_{j=1}^{n} (X_i - \\mu)(X_j - \\mu) = \\sum_{i=1}^{n} (X_i - \\mu)^2 + \\sum_{i \\neq j} (X_i - \\mu)(X_j - \\mu)\n$$\n现在，我们将其代回方差的表达式中，并应用期望算子：\n$$\n\\operatorname{Var}(\\bar{X}_n) = E\\left[ \\frac{1}{n^2} \\left( \\sum_{i=1}^{n} (X_i - \\mu)^2 + \\sum_{i \\neq j} (X_i - \\mu)(X_j - \\mu) \\right) \\right]\n$$\n利用期望的线性性质，我们得到：\n$$\n\\operatorname{Var}(\\bar{X}_n) = \\frac{1}{n^2} \\left( E\\left[\\sum_{i=1}^{n} (X_i - \\mu)^2\\right] + E\\left[\\sum_{i \\neq j} (X_i - \\mu)(X_j - \\mu)\\right] \\right)\n$$\n$$\n\\operatorname{Var}(\\bar{X}_n) = \\frac{1}{n^2} \\left( \\sum_{i=1}^{n} E[(X_i - \\mu)^2] + \\sum_{i \\neq j} E[(X_i - \\mu)(X_j - \\mu)] \\right)\n$$\n让我们分别计算这两个期望项。\n对于第一项，根据方差的定义，$E[(X_i - \\mu)^2] = \\operatorname{Var}(X_i) = \\sigma^2$。由于这对所有 $i$ 都成立：\n$$\n\\sum_{i=1}^{n} E[(X_i - \\mu)^2] = \\sum_{i=1}^{n} \\sigma^2 = n\\sigma^2\n$$\n对于包含 $i \\neq j$ 的交叉乘积的第二项，我们使用给定的性质，即随机变量 $X_i$ 和 $X_j$ 是独立的。这意味着随机变量 $(X_i - \\mu)$ 和 $(X_j - \\mu)$ 也是独立的。对于独立的随机变量，其乘积的期望可以分解为各自期望的乘积：\n$$\nE[(X_i - \\mu)(X_j - \\mu)] = E[X_i - \\mu] \\cdot E[X_j - \\mu] \\quad \\text{for } i \\neq j\n$$\n我们知道对于任何 $k$，$E[X_k - \\mu] = E[X_k] - E[\\mu] = \\mu - \\mu = 0$。\n因此，对于任何 $i \\neq j$ 的配对：\n$$\nE[(X_i - \\mu)(X_j - \\mu)] = 0 \\cdot 0 = 0\n$$\n由于和 $\\sum_{i \\neq j}$ 中的每个交叉乘积项的期望都为零，所以整个和为零。\n\n将这些结果代回 $\\operatorname{Var}(\\bar{X}_n)$ 的方程中：\n$$\n\\operatorname{Var}(\\bar{X}_n) = \\frac{1}{n^2} (n\\sigma^2 + 0) = \\frac{n\\sigma^2}{n^2} = \\frac{\\sigma^2}{n}\n$$\n这就完成了从第一性原理推导样本均值方差的过程。\n\n现在，与中心极限定理（CLT）和标准误的联系就直接了。CLT 指出，对于足够大的样本量 $n$，标准化样本均值的分布近似于标准正态分布：\n$$\n\\frac{\\bar{X}_n - \\mu}{\\sqrt{\\operatorname{Var}(\\bar{X}_n)}} \\xrightarrow{d} N(0, 1)\n$$\n分母 $\\sqrt{\\operatorname{Var}(\\bar{X}_n)}$ 是 $\\bar{X}_n$ 抽样分布的标准差，定义为均值的**标准误**，记作 $\\text{SE}(\\bar{X}_n)$。根据我们的推导，我们有 $\\operatorname{Var}(\\bar{X}_n) = \\frac{\\sigma^2}{n}$，所以标准误是：\n$$\n\\text{SE}(\\bar{X}_n) = \\sqrt{\\frac{\\sigma^2}{n}} = \\frac{\\sigma}{\\sqrt{n}}\n$$\n这个量是构建 $\\mu$ 的大样本置信区间的基础。例如，一个 $95\\%$ 的置信区间大约是 $\\bar{X}_n \\pm 1.96 \\cdot \\frac{\\sigma}{\\sqrt{n}}$（如果 $\\sigma$ 已知）或 $\\bar{X}_n \\pm 1.96 \\cdot \\frac{s}{\\sqrt{n}}$（使用样本标准差 $s$ 作为 $\\sigma$ 的估计）。\n\n该推导解释了标准误随样本量 $n$ 变化的规律。方差 $\\operatorname{Var}(\\bar{X}_n)$ 与 $n$ 成反比。这是因为对 $n$ 个变量求平均引入了一个比例因子 $\\frac{1}{n}$，这在方差计算中变成了 $\\frac{1}{n^2}$。同时，各个独立测量值方差之和贡献了一个与 $n$ 成正比的项（具体来说是 $n\\sigma^2$）。这些效应的比率 $\\frac{n\\sigma^2}{n^2}$ 导致了 $\\frac{1}{n}$ 的依赖关系。因此，作为方差平方根的标准误，其变化规律为 $\\frac{1}{\\sqrt{n}}$。这种变化规律反映了这样一个事实：随着平均的独立测量次数增多，随机误差倾向于相互抵消，从而得到对真实均值 $\\mu$ 更精确的估计。为了使估计的精度加倍（即，将标准误减半），样本量 $n$ 必须增加到原来的四倍，这是设计临床研究和其他实验时的关键考量。",
            "answer": "$$\\boxed{\\frac{\\sigma^2}{n}}$$"
        },
        {
            "introduction": "在临床研究中，配对设计（例如，比较干预前后的效果）极为常见，其统计分析的核心正是中心极限定理的应用。本练习旨在将理论与实践相结合，探讨配对差异均值的渐近正态性。通过这个练习，你将不仅证明均值的渐近性质，还将运用Slutsky定理来论证“学生化”（studentization）的合理性，即在构建检验统计量时使用样本标准差替代未知的总体标准差的理论依据。",
            "id": "4986800",
            "problem": "一项纵向临床研究在一个包含 $n$ 名患者的队列中，测量了一项干预前后的连续生物标志物。对于患者 $i$，将其干预前测量值记为 $X_{i}$，干预后测量值记为 $Y_{i}$。假设配对样本 $\\{(X_{i},Y_{i})\\}_{i=1}^{n}$ 在患者间是独立同分布（i.i.d.）的，对内依赖性任意，并且存在 $\\delta>0$ 使得 $\\mathbb{E}(|X_{1}|^{2+\\delta})  \\infty$ 和 $\\mathbb{E}(|Y_{1}|^{2+\\delta})  \\infty$。定义配对差值 $D_{i}=X_{i}-Y_{i}$，并令 $\\bar{D}_{n}=\\frac{1}{n}\\sum_{i=1}^{n}D_{i}$ 表示差值的样本均值。令 $\\mu_{D}=\\mathbb{E}(D_{1})$，并令 $S_{D}^{2}=\\frac{1}{n-1}\\sum_{i=1}^{n}(D_{i}-\\bar{D}_{n})^{2}$ 表示差值的样本方差。\n\n从独立性、期望和方差的核心定义出发，并且仅使用经过充分检验的概率论事实，例如 Lindeberg–Feller 中心极限定理（CLT）和 Slutsky 定理，完成以下任务：\n\n1. 在给定的矩假设下，建立 $\\sqrt{n}(\\bar{D}_{n}-\\mu_{D})$ 的渐近正态性，并明确说明矩条件在验证 $\\{D_{i}\\}$ 所需的中心极限定理条件中的作用。\n2. 通过证明在相同假设下，$T_{n}=\\sqrt{n}(\\bar{D}_{n}-\\mu_{D})/S_{D}$ 在分布上收敛于一个标准正态随机变量，来证明学生化（studentization）的合理性，并解释为什么 $S_{D}^{2}$ 的相合性对于得出此结论是充分的。\n3. 另外假设 $\\operatorname{Var}(X_{1})=\\sigma_{X}^{2}$，$\\operatorname{Var}(Y_{1})=\\sigma_{Y}^{2}$ 以及 $\\operatorname{Cov}(X_{1},Y_{1})=\\sigma_{XY}$。用 $\\sigma_{X}^{2}$、$\\sigma_{Y}^{2}$ 和 $\\sigma_{XY}$ 推导出 $\\sqrt{n}(\\bar{D}_{n}-\\mu_{D})$ 的渐近方差的显式闭式表达式。\n\n请将第3项所要求的渐近方差以单一闭式解析表达式的形式作为最终答案。不需要数值近似；不要四舍五入。不需要单位。",
            "solution": "在尝试解答之前，将对问题进行验证。\n\n### 第1步：提取已知条件\n- 一个包含 $n$ 名患者的队列。\n- 患者 $i$ 的干预前测量值：$X_{i}$。\n- 患者 $i$ 的干预后测量值：$Y_{i}$。\n- 配对样本 $\\{(X_{i},Y_{i})\\}_{i=1}^{n}$ 是独立同分布（i.i.d.）的。\n- $X_{i}$ 和 $Y_{i}$ 之间存在任意的对内依赖性。\n- 存在一个常数 $\\delta  0$，使得 $\\mathbb{E}(|X_{1}|^{2+\\delta})  \\infty$ 且 $\\mathbb{E}(|Y_{1}|^{2+\\delta})  \\infty$。\n- 配对差值：$D_{i} = X_{i} - Y_{i}$。\n- 差值的样本均值：$\\bar{D}_{n} = \\frac{1}{n}\\sum_{i=1}^{n}D_{i}$。\n- 差值的真实均值：$\\mu_{D} = \\mathbb{E}(D_{1})$。\n- 差值的样本方差：$S_{D}^{2} = \\frac{1}{n-1}\\sum_{i=1}^{n}(D_{i}-\\bar{D}_{n})^{2}$。\n- 第3部分的附加假设：$\\operatorname{Var}(X_{1}) = \\sigma_{X}^{2}$，$\\operatorname{Var}(Y_{1}) = \\sigma_{Y}^{2}$，以及 $\\operatorname{Cov}(X_{1},Y_{1}) = \\sigma_{XY}$。\n\n### 第2步：使用提取的已知条件进行验证\n对问题陈述进行有效性审查。\n- **科学基础：** 该问题是渐近统计理论中的一个标准练习，具体应用于配对数据的分析，这是临床研究中的常见情景。所使用的概念——中心极限定理（CLT）、Slutsky 定理、矩条件和样本统计量——都是数理统计的基本支柱。该问题在科学上和数学上都是合理的。\n- **适定性：** 问题清晰地分为三个不同部分，每个部分都有明确的目标。假设被明确陈述，并且足以推导出每个部分的唯一、有意义的解。\n- **客观性：** 语言正式、精确，没有任何主观或含糊的术语。\n- **缺陷分析：**\n  1.  **科学或事实不健全：** 无。前提和所需的推导在理论统计学中是标准的。\n  2.  **不可形式化或不相关：** 问题在数学上是明确定义的，并且与中心极限定理及其在生物统计学中的应用直接相关。\n  3.  **设置不完整或矛盾：** 问题提供了所有必要的信息。矩条件 $\\mathbb{E}(|X_1|^{2+\\delta})  \\infty$ 是一个较强但标准的条件，用于确保某些理论结果（如 Lindeberg 中心极限定理）的适用性。没有矛盾之处。\n  4.  **不切实际或不可行：** 该模型代表了配对设计实验中数据的常见且现实的简化。\n  5.  **病态或结构不良：** 问题是适定的，可以导出一个唯一且稳定的解。\n  6.  **伪深刻、琐碎或同义反复：** 问题需要一个严谨的、多步骤的推导，涉及概率论中非平凡的概念。\n  7.  **超出科学可验证性：** 所有推导在数学上都是可证明的。\n\n### 第3步：结论与行动\n问题有效。将提供完整解答。\n\n***\n\n### 解答\n\n本题探讨了配对差值样本均值的渐近性质，这是双样本配对数据统计推断的基石。我们将依次解答这三个部分。\n\n首先，我们定义随机变量 $D_{i}$ 的性质。由于配对样本 $(X_{i}, Y_{i})$ 对于 $i=1, \\dots, n$ 是独立同分布的，因此差值 $D_{i}=X_{i}-Y_{i}$ 也构成一个独立同分布的随机变量序列。\n\n$D_i$ 的均值为 $\\mathbb{E}(D_{i}) = \\mathbb{E}(X_{i} - Y_{i})$。根据期望的线性性质，$\\mathbb{E}(D_{i}) = \\mathbb{E}(X_{i}) - \\mathbb{E}(Y_{i})$。由于样本对是同分布的，这对所有 $i$ 都是一个常数，我们记为 $\\mu_D = \\mathbb{E}(D_{1})$。$2+\\delta$ 阶矩的存在意味着所有更低阶的矩，包括一阶矩，都是有限的。\n\n$D_i$ 的方差为 $\\operatorname{Var}(D_i) = \\operatorname{Var}(X_i - Y_i)$。我们记 $\\sigma_{D}^{2} = \\operatorname{Var}(D_1)$。我们必须验证这个方差是有限的。条件 $\\mathbb{E}(|X_{1}|^{2+\\delta})  \\infty$ 意味着 $\\mathbb{E}(X_{1}^{2})  \\infty$，同样地 $\\mathbb{E}(Y_{1}^{2})  \\infty$。使用三角不等式和 $c_r$-不等式（$|a+b|^p \\le 2^{p-1}(|a|^p+|b|^p)$），我们有 $\\mathbb{E}(D_1^2) = \\mathbb{E}((X_1-Y_1)^2) \\le \\mathbb{E}((|X_1|+|Y_1|)^2) = \\mathbb{E}(X_1^2 + Y_1^2 + 2|X_1 Y_1|)$。根据 Cauchy-Schwarz 不等式，$\\mathbb{E}(|X_1 Y_1|) \\le \\sqrt{\\mathbb{E}(X_1^2)\\mathbb{E}(Y_1^2)}$，这是有限的。因此，$\\mathbb{E}(D_1^2)$ 是有限的，方差 $\\sigma_{D}^{2} = \\mathbb{E}(D_1^2) - \\mu_D^2$ 也是有限的。\n\n**1. $\\sqrt{n}(\\bar{D}_{n}-\\mu_{D})$ 的渐近正态性**\n\n我们的目标是对独立同分布序列 $\\{D_i\\}_{i=1}^n$ 应用中心极限定理。经典的（Lindeberg-Lévy）中心极限定理要求变量是独立同分布的，且具有有限的均值和方差。我们已经证明了 $\\{D_i\\}$ 具备这些性质。因此，中心极限定理直接适用。\n该定理指出 $\\frac{\\sum_{i=1}^{n}(D_i - \\mu_D)}{\\sqrt{n\\sigma_D^2}} \\xrightarrow{d} N(0,1)$，其中 $\\xrightarrow{d}$ 表示依分布收敛。\n整理该项，我们得到 $\\frac{\\sqrt{n}(\\frac{1}{n}\\sum_{i=1}^{n}D_i - \\mu_D)}{\\sigma_D} = \\frac{\\sqrt{n}(\\bar{D}_n - \\mu_D)}{\\sigma_D} \\xrightarrow{d} N(0,1)$。\n这等价于表述 $\\sqrt{n}(\\bar{D}_n - \\mu_D) \\xrightarrow{d} N(0, \\sigma_D^2)$。因此，序列 $\\sqrt{n}(\\bar{D}_n - \\mu_D)$ 是渐近正态的，其均值为 $0$，渐近方差为 $\\sigma_D^2$。\n\n问题特别要求使用 Lindeberg-Feller 中心极限定理以及矩条件 $\\mathbb{E}(|D_1|^{2+\\delta})  \\infty$ 的作用进行解释。对于一个独立随机变量序列 $\\{Z_i\\}$，其 $\\mathbb{E}(Z_i)=0$ 且方差 $\\sigma_i^2$ 有限，Lindeberg 条件为：\n对于任意 $\\epsilon  0$，$\\lim_{n \\to \\infty} \\frac{1}{s_n^2} \\sum_{i=1}^n \\mathbb{E} \\left[ Z_i^2 \\cdot \\mathbb{I}(|Z_i|  \\epsilon s_n) \\right] = 0$，其中 $s_n^2 = \\sum_{i=1}^n \\sigma_i^2$。\n\n在我们的情况下，令 $Z_i = D_i - \\mu_D$。这些变量是独立同分布的，且 $\\mathbb{E}(Z_i)=0$，$\\operatorname{Var}(Z_i) = \\sigma_D^2$。所以，$s_n^2 = n\\sigma_D^2$。Lindeberg 条件变为：\n$$ \\lim_{n \\to \\infty} \\frac{1}{n\\sigma_D^2} \\sum_{i=1}^n \\mathbb{E} \\left[ (D_i - \\mu_D)^2 \\cdot \\mathbb{I}(|D_i - \\mu_D|  \\epsilon \\sqrt{n}\\sigma_D) \\right] = 0 $$\n由于各项是同分布的，这可以简化为：\n$$ \\lim_{n \\to \\infty} \\frac{1}{\\sigma_D^2} \\mathbb{E} \\left[ (D_1 - \\mu_D)^2 \\cdot \\mathbb{I}(|D_1 - \\mu_D|  \\epsilon \\sqrt{n}\\sigma_D) \\right] = 0 $$\n更强的矩条件 $\\mathbb{E}(|X_{1}|^{2+\\delta})  \\infty$ 和 $\\mathbb{E}(|Y_{1}|^{2+\\delta})  \\infty$ 意味着 $\\mathbb{E}(|D_1|^{2+\\delta})  \\infty$（根据 $c_r$-不等式）。令 $W = D_1 - \\mu_D$。那么 $\\mathbb{E}(|W|^{2+\\delta})$ 也是有限的。我们可以用它来对期望进行界定：\n$$ \\mathbb{E} \\left[ W^2 \\cdot \\mathbb{I}(|W|  C_n) \\right] \\text{ 其中 } C_n = \\epsilon \\sqrt{n}\\sigma_D \\to \\infty $$\n$$ \\mathbb{E} \\left[ W^2 \\cdot \\frac{|W|^\\delta}{|W|^\\delta} \\cdot \\mathbb{I}(|W|  C_n) \\right] \\le \\mathbb{E} \\left[ W^2 \\cdot \\frac{|W|^\\delta}{C_n^\\delta} \\cdot \\mathbb{I}(|W|  C_n) \\right] = \\frac{1}{C_n^\\delta} \\mathbb{E} \\left[ |W|^{2+\\delta} \\cdot \\mathbb{I}(|W|  C_n) \\right] $$\n这可以进一步界定为 $\\frac{1}{C_n^\\delta} \\mathbb{E} \\left[ |W|^{2+\\delta} \\right]$。\n由于 $\\mathbb{E} \\left[ |W|^{2+\\delta} \\right]  \\infty$ 且 $C_n^\\delta = (\\epsilon\\sigma_D)^\\delta n^{\\delta/2} \\to \\infty$（当 $n \\to \\infty$），整个表达式收敛到 $0$。这验证了 Lindeberg 条件。存在一个 $2+\\delta$（其中 $\\delta0$）阶矩，提供了一种机制来证明尾部积分消失，从而满足中心极限定理的要求。\n\n**2. 学生化的合理性证明**\n\n我们需要证明 $T_n = \\frac{\\sqrt{n}(\\bar{D}_{n}-\\mu_{D})}{S_{D}}$ 依分布收敛于一个标准正态变量 $N(0,1)$。这个过程被称为学生化（studentization），它涉及将归一化因子中未知的总体标准差 $\\sigma_D$ 替换为其样本估计值 $S_D$。这种替换的有效性取决于 Slutsky 定理。\n\nSlutsky 定理指出，如果 $A_n \\xrightarrow{d} A$ 并且 $B_n \\xrightarrow{p} c$（其中 $c$ 是一个常数，$\\xrightarrow{p}$ 表示依概率收敛），那么 $A_n / B_n \\xrightarrow{d} A / c$。\n\n从第1部分，我们确定 $A_n = \\sqrt{n}(\\bar{D}_n - \\mu_D)$，并且我们知道 $A_n \\xrightarrow{d} A \\sim N(0, \\sigma_D^2)$。\n我们确定 $B_n = S_D$。要应用 Slutsky 定理，我们必须证明 $S_D$ 依概率收敛于常数 $\\sigma_D$。这等价于证明其平方 $S_D^2$ 依概率收敛于 $\\sigma_D^2$。也就是说，我们必须证明 $S_D^2$ 是 $\\sigma_D^2$ 的一个相合估计量。\n\n样本方差是 $S_D^2 = \\frac{1}{n-1}\\sum_{i=1}^{n}(D_{i}-\\bar{D}_{n})^{2}$。这可以重写为：\n$$ S_D^2 = \\frac{n}{n-1} \\left( \\frac{1}{n}\\sum_{i=1}^n D_i^2 - \\bar{D}_n^2 \\right) $$\n当 $n \\to \\infty$ 时，因子 $\\frac{n}{n-1} \\to 1$。\n变量 $D_i$ 是独立同分布的，具有有限的均值 $\\mu_D$。因此，根据弱大数定律（WLLN），样本均值依概率收敛于总体均值：$\\bar{D}_n \\xrightarrow{p} \\mu_D$。\n变量 $D_i^2$ 也是独立同分布的，并且我们已经证明 $\\mathbb{E}(D_1^2)  \\infty$。因此，根据弱大数定律，它们的样本均值也依概率收敛于总体均值：$\\frac{1}{n}\\sum_{i=1}^n D_i^2 \\xrightarrow{p} \\mathbb{E}(D_1^2)$。\n\n根据连续映射定理，如果 $g$ 是一个连续函数，则 $Z_n \\xrightarrow{p} c \\implies g(Z_n) \\xrightarrow{p} g(c)$。应用此定理，$\\bar{D}_n^2 \\xrightarrow{p} \\mu_D^2$。\n使用依概率收敛的性质组合这些结果：\n$$ S_D^2 = \\left(\\frac{n}{n-1}\\right) \\left( \\frac{1}{n}\\sum_{i=1}^n D_i^2 - \\bar{D}_n^2 \\right) \\xrightarrow{p} (1) \\cdot (\\mathbb{E}(D_1^2) - \\mu_D^2) = \\sigma_D^2 $$\n因此，$S_D^2$ 是 $\\sigma_D^2$ 的一个相合估计量。这正是所需要的。$S_D^2$ 的相合性是充分的。\n再次应用连续映射定理（使用平方根函数，它对非负值是连续的），$S_D = \\sqrt{S_D^2} \\xrightarrow{p} \\sqrt{\\sigma_D^2} = \\sigma_D$（假设 $\\sigma_D^2  0$）。\n\n现在我们应用 Slutsky 定理：\n$$ T_n = \\frac{A_n}{B_n} = \\frac{\\sqrt{n}(\\bar{D}_{n}-\\mu_{D})}{S_{D}} \\xrightarrow{d} \\frac{N(0, \\sigma_D^2)}{\\sigma_D} \\sim N\\left(\\frac{0}{\\sigma_D}, \\frac{\\sigma_D^2}{\\sigma_D^2}\\right) \\sim N(0,1) $$\n这完成了证明。$S_D^2$（以及 $S_D$）的相合性使其在极限情况下可以被视为一个常数，确保了最终的统计量具有一个无参数的标准正态分布。\n\n**3. 渐近方差的显式表达式**\n\n根据定义，$\\sqrt{n}(\\bar{D}_n - \\mu_D)$ 的渐近方差是第1部分中建立的极限正态分布的方差。这个方差是 $\\sigma_D^2 = \\operatorname{Var}(D_1)$。我们需要用 $\\sigma_{X}^{2} = \\operatorname{Var}(X_{1})$、$\\sigma_{Y}^{2} = \\operatorname{Var}(Y_{1})$ 和 $\\sigma_{XY} = \\operatorname{Cov}(X_{1},Y_{1})$ 来表示它。\n\n利用方差的性质，我们有：\n$$ \\sigma_D^2 = \\operatorname{Var}(D_1) = \\operatorname{Var}(X_1 - Y_1) $$\n两个随机变量差的方差公式为 $\\operatorname{Var}(A-B) = \\operatorname{Var}(A) + \\operatorname{Var}(B) - 2\\operatorname{Cov}(A,B)$。将此公式应用于 $A=X_1$ 和 $B=Y_1$：\n$$ \\operatorname{Var}(X_1 - Y_1) = \\operatorname{Var}(X_1) + \\operatorname{Var}(Y_1) - 2\\operatorname{Cov}(X_1, Y_1) $$\n代入给定的记号：\n$$ \\sigma_D^2 = \\sigma_{X}^{2} + \\sigma_{Y}^{2} - 2\\sigma_{XY} $$\n该表达式即为 $\\sqrt{n}(\\bar{D}_n - \\mu_D)$ 的渐近方差的显式闭式形式。",
            "answer": "$$\\boxed{\\sigma_{X}^{2} + \\sigma_{Y}^{2} - 2\\sigma_{XY}}$$"
        },
        {
            "introduction": "中心极限定理的威力远不止于样本均值，它可以通过“德尔塔方法”（Delta method）扩展到对参数函数的推断。本练习将以泊松分布为例，展示如何估计参数$\\lambda$的函数$g(\\lambda) = e^{-\\lambda}$（即观测值为零的概率）的渐近方差。掌握这一方法对于在医学统计中进行更复杂的推断至关重要，例如估计风险比、优势比或其他衍生指标的置信区间。",
            "id": "852589",
            "problem": "考虑一个由 $n$ 个独立同分布（i.i.d.）的随机变量 $X_1, X_2, \\dots, X_n$ 组成的序列，每个变量都服从参数为未知 $\\lambda  0$ 的泊松分布。其概率质量函数（PMF）为 $P(X=k) = \\frac{e^{-\\lambda} \\lambda^k}{k!}$，其中 $k = 0, 1, 2, \\dots$。\n\n我们感兴趣的是估计从该分布中新观测到的值为零的概率。这个概率是参数 $\\lambda$ 的一个函数，由 $g(\\lambda) = P(X=0) = e^{-\\lambda}$ 给出。\n\n令 $\\hat{\\theta}_n$ 为我们感兴趣的参数 $\\theta = g(\\lambda)$ 的最大似然估计量（MLE）。根据最大似然估计理论和中心极限定理，估计量 $\\hat{\\theta}_n$ 是渐近正态的。具体来说，$\\sqrt{n}(\\hat{\\theta}_n - \\theta)$ 的分布收敛到一个均值为 0、方差为某个值 $V$ 的正态分布。这个方差 $V$ 通常被称为估计量的渐近方差。\n\n推导此渐近方差 $V$ 关于参数 $\\lambda$ 的闭式表达式。",
            "solution": "1. 相关函数和估计量\n我们有 $g(\\lambda)=P(X=0)=e^{-\\lambda}$ 以及最大似然估计量（MLE）$\\hat\\lambda=\\overline X$。 根据 delta 方法，\n$$\\sqrt{n}\\bigl(\\hat\\theta-\\theta\\bigr)\\xrightarrow{d}N\\!\\Bigl(0,\\;\\frac{[g'(\\lambda)]^2}{I(\\lambda)}\\Bigr)$$\n其中 $\\theta=g(\\lambda)$。\n\n2. 计算导数 $g'(\\lambda)$\n$$g'(\\lambda)=\\frac{d}{d\\lambda}e^{-\\lambda}=-\\,e^{-\\lambda},\\qquad [g'(\\lambda)]^2=e^{-2\\lambda}。$$\n\n3. 泊松分布($\\lambda$)的费雪信息\n单个观测值的对数似然函数是 $\\ell(\\lambda)= -\\lambda+X\\ln\\lambda-\\ln(X!)$。因此\n$$\\frac{\\partial^2\\ell}{\\partial\\lambda^2}=-\\frac{X}{\\lambda^2},\\qquad I(\\lambda)=-E\\Bigl[\\frac{\\partial^2\\ell}{\\partial\\lambda^2}\\Bigr]\n=E\\bigl[X\\bigr]/\\lambda^2=\\lambda/\\lambda^2=\\frac1\\lambda。$$\n\n4. 渐近方差 $V$\n代入 delta 方法的方差公式：\n$$V=\\frac{[g'(\\lambda)]^2}{I(\\lambda)}=\\frac{e^{-2\\lambda}}{1/\\lambda}=\\lambda\\,e^{-2\\lambda}。$$",
            "answer": "$$\\boxed{\\lambda\\,e^{-2\\lambda}}$$"
        }
    ]
}