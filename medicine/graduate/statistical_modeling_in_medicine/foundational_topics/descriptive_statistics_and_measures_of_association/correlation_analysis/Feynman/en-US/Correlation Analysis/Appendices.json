{
    "hands_on_practices": [
        {
            "introduction": "While the Pearson coefficient excels at measuring linear association, relationships in medical data are often monotonic but non-linear, and the presence of outliers can heavily influence the result. Spearman's rank correlation offers a robust, non-parametric alternative by evaluating the association based on data ranks instead of their raw values. This exercise  provides essential hands-on practice in computing this coefficient, focusing on the critical skill of managing tied ranks, a frequent occurrence in clinical scoring and measurements.",
            "id": "4957615",
            "problem": "A rheumatology research team conducts a pilot study to assess the monotonic association between serum C-reactive protein (CRP) in milligrams per liter and a clinician-rated Disease Activity Score (DAS). CRP is an inflammatory biomarker and DAS is an ordinal index of disease severity. The sample consists of $n=12$ patients, with observed pairs $(x_i, y_i)$, where $x_i$ is CRP and $y_i$ is DAS:\n- Patient $1$: $(x_1, y_1) = (4.2, 2)$\n- Patient $2$: $(x_2, y_2) = (7.8, 3)$\n- Patient $3$: $(x_3, y_3) = (4.2, 2)$\n- Patient $4$: $(x_4, y_4) = (12.5, 5)$\n- Patient $5$: $(x_5, y_5) = (9.0, 5)$\n- Patient $6$: $(x_6, y_6) = (7.8, 3)$\n- Patient $7$: $(x_7, y_7) = (20.0, 7)$\n- Patient $8$: $(x_8, y_8) = (3.1, 1)$\n- Patient $9$: $(x_9, y_9) = (15.4, 6)$\n- Patient $10$: $(x_{10}, y_{10}) = (20.0, 7)$\n- Patient $11$: $(x_{11}, y_{11}) = (9.0, 4)$\n- Patient $12$: $(x_{12}, y_{12}) = (11.2, 4)$\n\nUsing the nonparametric definition of Spearman rank correlation, compute the Spearman rank correlation coefficient between CRP and DAS for these $12$ patients, handling ties by assigning midranks. Round your final answer to four significant figures. The final answer is dimensionless and must be expressed as a decimal.",
            "solution": "The problem requires the computation of the Spearman rank correlation coefficient, denoted $\\rho_s$, for a given dataset of $n=12$ paired observations. The Spearman correlation is a nonparametric measure of monotonic association, defined as the Pearson correlation coefficient calculated on the ranks of the data. For two variables $X$ and $Y$ with corresponding ranks $R(X)$ and $R(Y)$, the formula for $\\rho_s$ is:\n$$ \\rho_s = \\frac{\\sum_{i=1}^{n} (R(x_i) - \\bar{R}_x)(R(y_i) - \\bar{R}_y)}{\\sqrt{\\sum_{i=1}^{n} (R(x_i) - \\bar{R}_x)^2 \\sum_{i=1}^{n} (R(y_i) - \\bar{R}_y)^2}} $$\nwhere $R(x_i)$ and $R(y_i)$ are the ranks of the $i$-th observations $x_i$ and $y_i$, respectively, and $\\bar{R}_x$ and $\\bar{R}_y$ are the mean ranks. The problem specifies that ties should be handled by assigning midranks.\n\nThe first step is to rank the data for both variables, C-reactive protein (CRP), $x$, and Disease Activity Score (DAS), $y$.\n\n**Step 1: Ranking the CRP data ($x_i$)**\nThe observed CRP values are:\n$4.2, 7.8, 4.2, 12.5, 9.0, 7.8, 20.0, 3.1, 15.4, 20.0, 9.0, 11.2$.\nSorting these values in ascending order:\n$3.1, 4.2, 4.2, 7.8, 7.8, 9.0, 9.0, 11.2, 12.5, 15.4, 20.0, 20.0$.\nWe assign ranks, using the average rank (midrank) for tied values:\n- $3.1$: rank $1$\n- $4.2$ (2 values): ranks $2, 3$. Midrank is $\\frac{2+3}{2} = 2.5$.\n- $7.8$ (2 values): ranks $4, 5$. Midrank is $\\frac{4+5}{2} = 4.5$.\n- $9.0$ (2 values): ranks $6, 7$. Midrank is $\\frac{6+7}{2} = 6.5$.\n- $11.2$: rank $8$\n- $12.5$: rank $9$\n- $15.4$: rank $10$\n- $20.0$ (2 values): ranks $11, 12$. Midrank is $\\frac{11+12}{2} = 11.5$.\n\n**Step 2: Ranking the DAS data ($y_i$)**\nThe observed DAS values are:\n$2, 3, 2, 5, 5, 3, 7, 1, 6, 7, 4, 4$.\nSorting these values in ascending order:\n$1, 2, 2, 3, 3, 4, 4, 5, 5, 6, 7, 7$.\nWe assign midranks for tied values:\n- $1$: rank $1$\n- $2$ (2 values): ranks $2, 3$. Midrank is $\\frac{2+3}{2} = 2.5$.\n- $3$ (2 values): ranks $4, 5$. Midrank is $\\frac{4+5}{2} = 4.5$.\n- $4$ (2 values): ranks $6, 7$. Midrank is $\\frac{6+7}{2} = 6.5$.\n- $5$ (2 values): ranks $8, 9$. Midrank is $\\frac{8+9}{2} = 8.5$.\n- $6$: rank $10$\n- $7$ (2 values): ranks $11, 12$. Midrank is $\\frac{11+12}{2} = 11.5$.\n\n**Step 3: Calculating Sums for the Correlation Formula**\nFor a sample of size $n=12$, the sum of ranks from $1$ to $12$ is $\\frac{12(12+1)}{2} = 78$. The mean rank for both variables is $\\bar{R}_x = \\bar{R}_y = \\frac{78}{12} = 6.5$.\n\nWe now construct a table to compute the necessary sums of squares and cross-products of deviations from the mean rank. Let $S_{xx} = \\sum_{i=1}^{n} (R(x_i) - \\bar{R}_x)^2$, $S_{yy} = \\sum_{i=1}^{n} (R(y_i) - \\bar{R}_y)^2$, and $S_{xy} = \\sum_{i=1}^{n} (R(x_i) - \\bar{R}_x)(R(y_i) - \\bar{R}_y)$. The table below details these calculations.\n\n| Patient $i$ | $x_i$ | $y_i$ | $R(x_i)$ | $R(y_i)$ | $R(x_i) - 6.5$ | $R(y_i) - 6.5$ | $(R(x_i) - 6.5)(R(y_i) - 6.5)$ | $(R(x_i) - 6.5)^2$ | $(R(y_i) - 6.5)^2$ |\n|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|\n| $1$ | $4.2$ | $2$ | $2.5$ | $2.5$ | $-4.0$ | $-4.0$ | $16.00$ | $16.00$ | $16.00$ |\n| $2$ | $7.8$ | $3$ | $4.5$ | $4.5$ | $-2.0$ | $-2.0$ | $4.00$ | $4.00$ | $4.00$ |\n| $3$ | $4.2$ | $2$ | $2.5$ | $2.5$ | $-4.0$ | $-4.0$ | $16.00$ | $16.00$ | $16.00$ |\n| $4$ | $12.5$ | $5$ | $9.0$ | $8.5$ | $2.5$ | $2.0$ | $5.00$ | $6.25$ | $4.00$ |\n| $5$ | $9.0$ | $5$ | $6.5$ | $8.5$ | $0.0$ | $2.0$ | $0.00$ | $0.00$ | $4.00$ |\n| $6$ | $7.8$ | $3$ | $4.5$ | $4.5$ | $-2.0$ | $-2.0$ | $4.00$ | $4.00$ | $4.00$ |\n| $7$ | $20.0$ | $7$ | $11.5$ | $11.5$ | $5.0$ | $5.0$ | $25.00$ | $25.00$ | $25.00$ |\n| $8$ | $3.1$ | $1$ | $1.0$ | $1.0$ | $-5.5$ | $-5.5$ | $30.25$ | $30.25$ | $30.25$ |\n| $9$ | $15.4$ | $6$ | $10.0$ | $10.0$ | $3.5$ | $3.5$ | $12.25$ | $12.25$ | $12.25$ |\n| $10$| $20.0$ | $7$ | $11.5$ | $11.5$ | $5.0$ | $5.0$ | $25.00$ | $25.00$ | $25.00$ |\n| $11$| $9.0$ | $4$ | $6.5$ | $6.5$ | $0.0$ | $0.0$ | $0.00$ | $0.00$ | $0.00$ |\n| $12$| $11.2$ | $4$ | $8.0$ | $6.5$ | $1.5$ | $0.0$ | $0.00$ | $2.25$ | $0.00$ |\n| **Sum** | | | | | $0.0$ | $0.0$ | $\\mathbf{137.50}$ | $\\mathbf{141.00}$ | $\\mathbf{140.50}$ |\n\nFrom the table, we have the required sums:\n$S_{xy} = 137.5$\n$S_{xx} = 141.0$\n$S_{yy} = 140.5$\n\n**Step 4: Final Calculation**\nSubstituting these values into the formula for $\\rho_s$:\n$$ \\rho_s = \\frac{S_{xy}}{\\sqrt{S_{xx} S_{yy}}} = \\frac{137.5}{\\sqrt{141.0 \\times 140.5}} $$\nNow, we compute the product in the denominator:\n$$ 141.0 \\times 140.5 = 19810.5 $$\nThen, we find the square root:\n$$ \\sqrt{19810.5} \\approx 140.749778 $$\nFinally, we compute the coefficient:\n$$ \\rho_s = \\frac{137.5}{140.749778} \\approx 0.976915 $$\nThe problem asks for the answer to be rounded to four significant figures.\n$$ \\rho_s \\approx 0.9769 $$\nThis high positive value indicates a very strong positive monotonic association between serum CRP levels and the clinician-rated Disease Activity Score in this sample of patients.",
            "answer": "$$\\boxed{0.9769}$$"
        },
        {
            "introduction": "A central challenge in medical statistics is to differentiate genuine association from spurious correlation driven by confounding variables. The observed, or marginal, correlation between an exposure and an outcome can be deeply misleading if a common cause influences both. This practice  walks you through the derivation and implementation of formulas for marginal and conditional correlation, offering a clear, numerical demonstration of how confounding can mask, inflate, or even reverse a true underlying effect.",
            "id": "4957630",
            "problem": "Consider a stylized linear-Gaussian causal model frequently used in statistical modeling in medicine to study confounding. Let $X$ denote a continuous exposure (for instance, a biomarker level), $Y$ denote a continuous outcome (for instance, a clinical risk score), and $Z$ denote a continuous confounder (for instance, disease severity). The data-generating mechanism is specified by the structural equations\n$$\nX \\;=\\; a\\,Z \\;+\\; \\varepsilon_x,\\qquad Y \\;=\\; b\\,X \\;+\\; c\\,Z \\;+\\; \\varepsilon_y,\n$$\nwhere $Z \\sim \\mathcal{N}(0,\\sigma_Z^2)$, $\\varepsilon_x \\sim \\mathcal{N}(0,\\sigma_x^2)$, and $\\varepsilon_y \\sim \\mathcal{N}(0,\\sigma_y^2)$ are mutually independent random variables. All parameters $a$, $b$, $c$, $\\sigma_Z$, $\\sigma_x$, and $\\sigma_y$ are real-valued, with $\\sigma_Z>0$, $\\sigma_x>0$, and $\\sigma_y>0$. The task is to contrast the marginal correlation between $X$ and $Y$ with the conditional correlation between $X$ and $Y$ given $Z$ and to identify confounding-induced sign disagreements.\n\nStarting from the core probabilistic definitions only, derive expressions needed to compute the following population quantities:\n- The marginal covariance $\\mathrm{Cov}(X,Y)$ and the marginal variances $\\mathrm{Var}(X)$ and $\\mathrm{Var}(Y)$ from the laws of expectation and independence, where $\\mathrm{Cov}(U,V) = \\mathbb{E}\\!\\left[(U-\\mathbb{E}[U])(V-\\mathbb{E}[V])\\right]$ and $\\mathrm{Var}(U)=\\mathrm{Cov}(U,U)$.\n- The marginal correlation $\\rho_{XY} = \\dfrac{\\mathrm{Cov}(X,Y)}{\\sqrt{\\mathrm{Var}(X)\\,\\mathrm{Var}(Y)}}$.\n- The conditional expectations $\\mathbb{E}[X\\mid Z]$ and $\\mathbb{E}[Y\\mid Z]$ and the corresponding residuals $R_X = X - \\mathbb{E}[X\\mid Z]$ and $R_Y = Y - \\mathbb{E}[Y\\mid Z]$.\n- The conditional correlation $\\rho_{XY\\mid Z}$ defined as the correlation between the residuals, i.e., $\\rho_{XY\\mid Z} = \\dfrac{\\mathrm{Cov}(R_X,R_Y)}{\\sqrt{\\mathrm{Var}(R_X)\\,\\mathrm{Var}(R_Y)}}$.\n\nYou must not invoke or quote any pre-packaged \"shortcut\" formulas beyond the above core definitions, and you must use only properties of linearity of expectation, independence of the noise terms, and the normality assumptions as needed for algebraic simplification. The final formulas should be expressed in terms of the parameters $a$, $b$, $c$, $\\sigma_Z$, $\\sigma_x$, and $\\sigma_y$ only, and must not depend on any sample size.\n\nYour program must implement these derived formulas exactly and, for each parameter set in the following test suite, compute three outputs: the marginal correlation $\\rho_{XY}$, the conditional correlation $\\rho_{XY\\mid Z}$, and a boolean indicator $D$ of sign disagreement defined by\n$$\nD \\;=\\; \\big(\\mathrm{sign}(\\rho_{XY}) \\neq \\mathrm{sign}(\\rho_{XY\\mid Z})\\big),\n$$\nwhere $\\mathrm{sign}(u) \\in \\{-1,0,+1\\}$ is the standard sign function. For numerical stability, treat any real number $u$ with $|u|<10^{-12}$ as $0$ when applying the sign function.\n\nTest suite parameter sets (each set specifies $(a,b,c,\\sigma_Z,\\sigma_x,\\sigma_y)$):\n1. Happy path with moderate confounding: $a=0.8$, $b=0.6$, $c=0.3$, $\\sigma_Z=1.5$, $\\sigma_x=1.2$, $\\sigma_y=0.9$.\n2. No confounding baseline: $a=0$, $b=0.5$, $c=0$, $\\sigma_Z=2.0$, $\\sigma_x=1.0$, $\\sigma_y=1.0$.\n3. Pure confounding creating spurious association: $a=1.0$, $b=0$, $c=0.8$, $\\sigma_Z=1.0$, $\\sigma_x=1.0$, $\\sigma_y=1.0$.\n4. Confounding-induced sign reversal (Simpson-type behavior): $a=2.0$, $b=0.2$, $c=-1.5$, $\\sigma_Z=2.0$, $\\sigma_x=0.7$, $\\sigma_y=0.5$.\n5. Opposing direct effect and confounding: $a=1.0$, $b=-0.4$, $c=1.0$, $\\sigma_Z=1.5$, $\\sigma_x=0.8$, $\\sigma_y=0.8$.\n\nRequired output format:\n- Your program should produce a single line of output containing a comma-separated list of results, enclosed in square brackets.\n- Each test case result must be a three-element list $[\\rho_{XY},\\rho_{XY\\mid Z},D]$, where the first two elements are real numbers rounded to six decimal places (as decimals, not percentages).\n- The final output should therefore look like\n$$\n\\big[ [r_{1},q_{1},d_{1}], [r_{2},q_{2},d_{2}], [r_{3},q_{3},d_{3}], [r_{4},q_{4},d_{4}], [r_{5},q_{5},d_{5}] \\big],\n$$\nwith no additional text.\n\nYour solution must be universally applicable as described and must not rely on any external data or input. No physical units or angle units are involved in this problem. The focus is exclusively on population-level correlations implied by the specified linear-Gaussian model.",
            "solution": "The problem requires deriving and implementing formulas for marginal and conditional correlation in a linear-Gaussian structural equation model.\n\nThe structural equations are:\n$$\nX \\;=\\; a\\,Z \\;+\\; \\varepsilon_x\n$$\n$$\nY \\;=\\; b\\,X \\;+\\; c\\,Z \\;+\\; \\varepsilon_y\n$$\nThe exogenous variables are mutually independent with distributions $Z \\sim \\mathcal{N}(0,\\sigma_Z^2)$, $\\varepsilon_x \\sim \\mathcal{N}(0,\\sigma_x^2)$, and $\\varepsilon_y \\sim \\mathcal{N}(0,\\sigma_y^2)$.\n\n**1. Derivation of Marginal Moments and Correlation**\n\nFirst, we determine the expectations of $X$ and $Y$. Using the linearity of expectation and the fact that $\\mathbb{E}[Z]=0$, $\\mathbb{E}[\\varepsilon_x]=0$, and $\\mathbb{E}[\\varepsilon_y]=0$:\n$$\n\\mathbb{E}[X] \\;=\\; \\mathbb{E}[a\\,Z + \\varepsilon_x] \\;=\\; a\\,\\mathbb{E}[Z] + \\mathbb{E}[\\varepsilon_x] \\;=\\; a(0) + 0 \\;=\\; 0\n$$\nTo find $\\mathbb{E}[Y]$, we first substitute the expression for $X$ into the equation for $Y$:\n$$\nY \\;=\\; b(a\\,Z + \\varepsilon_x) + c\\,Z + \\varepsilon_y \\;=\\; (ab+c)Z + b\\varepsilon_x + \\varepsilon_y\n$$\nNow, we take the expectation:\n$$\n\\mathbb{E}[Y] \\;=\\; \\mathbb{E}[(ab+c)Z + b\\varepsilon_x + \\varepsilon_y] \\;=\\; (ab+c)\\mathbb{E}[Z] + b\\mathbb{E}[\\varepsilon_x] + \\mathbb{E}[\\varepsilon_y] \\;=\\; 0\n$$\nSince both means are $0$, the variances are $\\mathrm{Var}(U) = \\mathbb{E}[U^2]$ and the covariance is $\\mathrm{Cov}(U,V) = \\mathbb{E}[UV]$.\n\nNext, we derive the variances. Since $Z$ and $\\varepsilon_x$ are independent:\n$$\n\\mathrm{Var}(X) \\;=\\; \\mathrm{Var}(a\\,Z + \\varepsilon_x) \\;=\\; a^2\\mathrm{Var}(Z) + \\mathrm{Var}(\\varepsilon_x) \\;=\\; a^2\\sigma_Z^2 + \\sigma_x^2\n$$\nSimilarly, for $\\mathrm{Var}(Y)$, using the expression $Y = (ab+c)Z + b\\varepsilon_x + \\varepsilon_y$ and the mutual independence of $Z, \\varepsilon_x, \\varepsilon_y$:\n$$\n\\mathrm{Var}(Y) \\;=\\; \\mathrm{Var}((ab+c)Z + b\\varepsilon_x + \\varepsilon_y) \\;=\\; (ab+c)^2\\mathrm{Var}(Z) + b^2\\mathrm{Var}(\\varepsilon_x) + \\mathrm{Var}(\\varepsilon_y)\n$$\n$$\n\\mathrm{Var}(Y) \\;=\\; (ab+c)^2\\sigma_Z^2 + b^2\\sigma_x^2 + \\sigma_y^2\n$$\nNow, we derive the covariance $\\mathrm{Cov}(X,Y) = \\mathbb{E}[XY]$:\n$$\n\\mathrm{Cov}(X,Y) \\;=\\; \\mathbb{E}[(aZ + \\varepsilon_x)((ab+c)Z + b\\varepsilon_x + \\varepsilon_y)]\n$$\nBy linearity of expectation and independence, all cross-product terms have an expectation of $0$. We are left with:\n$$\n\\mathrm{Cov}(X,Y) \\;=\\; a(ab+c)\\mathbb{E}[Z^2] + b\\mathbb{E}[\\varepsilon_x^2]\n$$\nSince $\\mathbb{E}[Z^2]=\\mathrm{Var}(Z)=\\sigma_Z^2$ and $\\mathbb{E}[\\varepsilon_x^2]=\\mathrm{Var}(\\varepsilon_x)=\\sigma_x^2$:\n$$\n\\mathrm{Cov}(X,Y) \\;=\\; a(ab+c)\\sigma_Z^2 + b\\sigma_x^2 \\;=\\; (a^2b + ac)\\sigma_Z^2 + b\\sigma_x^2\n$$\nThe marginal correlation $\\rho_{XY}$ is then given by:\n$$\n\\rho_{XY} = \\frac{\\mathrm{Cov}(X,Y)}{\\sqrt{\\mathrm{Var}(X)\\,\\mathrm{Var}(Y)}} = \\frac{(a^2b + ac)\\sigma_Z^2 + b\\sigma_x^2}{\\sqrt{(a^2\\sigma_Z^2 + \\sigma_x^2)((ab+c)^2\\sigma_Z^2 + b^2\\sigma_x^2 + \\sigma_y^2)}}\n$$\n\n**2. Derivation of Conditional Moments and Correlation**\n\nWe first find the conditional expectations $\\mathbb{E}[X|Z]$ and $\\mathbb{E}[Y|Z]$.\n$$\n\\mathbb{E}[X \\mid Z=z] \\;=\\; \\mathbb{E}[aZ + \\varepsilon_x \\mid Z=z] \\;=\\; az + \\mathbb{E}[\\varepsilon_x] \\;=\\; az\n$$\nThus, as a random variable, $\\mathbb{E}[X \\mid Z] = aZ$.\n$$\n\\mathbb{E}[Y \\mid Z=z] \\;=\\; \\mathbb{E}[bX+cZ+\\varepsilon_y \\mid Z=z] \\;=\\; b\\mathbb{E}[X \\mid Z=z] + cz + \\mathbb{E}[\\varepsilon_y] \\;=\\; b(az) + cz \\;=\\; (ab+c)z\n$$\nAs a random variable, $\\mathbb{E}[Y \\mid Z] = (ab+c)Z$.\n\nNext, we define the residuals $R_X = X - \\mathbb{E}[X\\mid Z]$ and $R_Y = Y - \\mathbb{E}[Y\\mid Z]$.\n$$\nR_X \\;=\\; (aZ + \\varepsilon_x) - aZ \\;=\\; \\varepsilon_x\n$$\n$$\nR_Y \\;=\\; ((ab+c)Z + b\\varepsilon_x + \\varepsilon_y) - (ab+c)Z \\;=\\; b\\varepsilon_x + \\varepsilon_y\n$$\nThe conditional correlation $\\rho_{XY\\mid Z}$ is the correlation between these residuals. We compute their moments. $\\mathbb{E}[R_X]=0$ and $\\mathbb{E}[R_Y]=0$. The variances are:\n$$\n\\mathrm{Var}(R_X) \\;=\\; \\mathrm{Var}(\\varepsilon_x) \\;=\\; \\sigma_x^2\n$$\n$$\n\\mathrm{Var}(R_Y) \\;=\\; \\mathrm{Var}(b\\varepsilon_x + \\varepsilon_y) \\;=\\; b^2\\mathrm{Var}(\\varepsilon_x) + \\mathrm{Var}(\\varepsilon_y) \\;=\\; b^2\\sigma_x^2 + \\sigma_y^2\n$$\nThe covariance is:\n$$\n\\mathrm{Cov}(R_X, R_Y) \\;=\\; \\mathbb{E}[R_X R_Y] \\;=\\; \\mathbb{E}[\\varepsilon_x(b\\varepsilon_x + \\varepsilon_y)] \\;=\\; b\\mathbb{E}[\\varepsilon_x^2] \\;=\\; b\\sigma_x^2\n$$\nFinally, the conditional correlation $\\rho_{XY\\mid Z}$ is:\n$$\n\\rho_{XY\\mid Z} = \\frac{\\mathrm{Cov}(R_X,R_Y)}{\\sqrt{\\mathrm{Var}(R_X)\\,\\mathrm{Var}(R_Y)}} = \\frac{b\\sigma_x^2}{\\sqrt{\\sigma_x^2 (b^2\\sigma_x^2 + \\sigma_y^2)}}\n$$\nThis simplifies to:\n$$\n\\rho_{XY\\mid Z} = \\frac{b\\sigma_x}{\\sqrt{b^2\\sigma_x^2 + \\sigma_y^2}}\n$$\n\n**Summary of Formulas for Implementation:**\n- $\\rho_{XY} = \\frac{(a^2b + ac)\\sigma_Z^2 + b\\sigma_x^2}{\\sqrt{(a^2\\sigma_Z^2 + \\sigma_x^2)((ab+c)^2\\sigma_Z^2 + b^2\\sigma_x^2 + \\sigma_y^2)}}$\n- $\\rho_{XY\\mid Z} = \\frac{b\\sigma_x}{\\sqrt{b^2\\sigma_x^2 + \\sigma_y^2}}}$\n- $D = (\\mathrm{sign}(\\rho_{XY}) \\neq \\mathrm{sign}(\\rho_{XY\\mid Z}))$, with $\\mathrm{sign}(u)=0$ for $|u|<10^{-12}$.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Implements the derived formulas to compute marginal and conditional correlations \n    for a linear-Gaussian causal model and identifies confounding-induced sign disagreements.\n    \"\"\"\n    test_cases = [\n        # 1. Happy path with moderate confounding\n        (0.8, 0.6, 0.3, 1.5, 1.2, 0.9),\n        # 2. No confounding baseline\n        (0.0, 0.5, 0.0, 2.0, 1.0, 1.0),\n        # 3. Pure confounding creating spurious association\n        (1.0, 0.0, 0.8, 1.0, 1.0, 1.0),\n        # 4. Confounding-induced sign reversal (Simpson-type behavior)\n        (2.0, 0.2, -1.5, 2.0, 0.7, 0.5),\n        # 5. Opposing direct effect and confounding\n        (1.0, -0.4, 1.0, 1.5, 0.8, 0.8),\n    ]\n\n    results = []\n    \n    def custom_sign(u, tol=1e-12):\n        \"\"\"\n        Custom sign function with a tolerance for zero. Returns -1, 0, or 1.\n        \"\"\"\n        if abs(u)  tol:\n            return 0\n        return int(np.sign(u))\n\n    for case in test_cases:\n        a, b, c, sigma_z, sigma_x, sigma_y = case\n        \n        var_z = sigma_z**2\n        var_x_noise = sigma_x**2\n        var_y_noise = sigma_y**2\n        \n        # --- Marginal Correlation Calculation ---\n        var_x = a**2 * var_z + var_x_noise\n        var_y = (a * b + c)**2 * var_z + b**2 * var_x_noise + var_y_noise\n        cov_xy = (a**2 * b + a * c) * var_z + b * var_x_noise\n        rho_xy = cov_xy / np.sqrt(var_x * var_y)\n        \n        # --- Conditional Correlation Calculation ---\n        denominator_cond = np.sqrt(b**2 * var_x_noise + var_y_noise)\n        if denominator_cond == 0:\n             rho_xy_cond_z = 0.0\n        else:\n             rho_xy_cond_z = (b * sigma_x) / np.sqrt(b**2 * var_x_noise + var_y_noise)\n\n        # --- Sign Disagreement Check ---\n        sign_rho_xy = custom_sign(rho_xy)\n        sign_rho_xy_cond_z = custom_sign(rho_xy_cond_z)\n        disagreement = sign_rho_xy != sign_rho_xy_cond_z\n        \n        results.append([rho_xy, rho_xy_cond_z, disagreement])\n\n    # --- Format and Print Output ---\n    formatted_results = []\n    for r_xy, r_xy_z, d in results:\n        formatted_results.append(f\"[{r_xy:.6f},{r_xy_z:.6f},{d}]\")\n    \n    final_output_string = f\"[{','.join(formatted_results)}]\"\n    \n    print(final_output_string)\n\nsolve()\n```"
        },
        {
            "introduction": "Clinical and epidemiological studies often follow participants over time, generating time-to-event data that are frequently incomplete due to right-censoring. Calculating a correlation coefficient using these observed, potentially shortened times yields biased and unreliable estimates. This advanced exercise  introduces a powerful and principled solution, Inverse Probability of Censoring Weighting (IPCW), to accurately estimate the correlation between a biomarker and the true, latent survival time, equipping you with a vital technique for modern biostatistics.",
            "id": "4957617",
            "problem": "Consider a cohort study in medicine where a continuous biomarker $X$ is measured at baseline and a time-to-event outcome $T$ is subject to right-censoring by a censoring time $C$. For patient $i$, the observed data consist of $Z_i = \\min(T_i, C_i)$ and $\\Delta_i = \\mathbf{1}\\{T_i \\le C_i\\}$. The goal is to estimate the Pearson correlation between the biomarker $X$ and the latent survival time $T$, expressed as a dimensionless decimal.\n\nStarting from the fundamental definition of Pearson correlation, the correlation between random variables $X$ and $T$ is\n$$\n\\rho_{X,T} = \\frac{\\operatorname{Cov}(X,T)}{\\sqrt{\\operatorname{Var}(X)} \\sqrt{\\operatorname{Var}(T)}},\n$$\nwhere $\\operatorname{Cov}(X,T) = \\mathbb{E}[XT] - \\mathbb{E}[X]\\mathbb{E}[T]$, and $\\operatorname{Var}(X) = \\mathbb{E}[(X - \\mathbb{E}[X])^2]$, $\\operatorname{Var}(T) = \\mathbb{E}[T^2] - (\\mathbb{E}[T])^2$. Because $T$ is right-censored, direct sample estimates of $\\mathbb{E}[T]$, $\\mathbb{E}[T^2]$, and $\\mathbb{E}[XT]$ are biased unless censoring is handled appropriately. Assume the standard independent censoring condition that $C$ is independent of $T$ given no covariates (that is, unconditional independence), and the positivity condition that the censoring survival function $G(t) = \\mathbb{P}(C \\ge t)$ satisfies $G(t)  0$ on the time interval of interest.\n\nUnder independent censoring, a principled approach is the Inverse Probability of Censoring Weighting (IPCW). The IPCW identity implies that for any measurable function $g$, \n$$\n\\mathbb{E}[g(T)] = \\mathbb{E}\\!\\left[\\frac{\\Delta \\, g(Z)}{G(Z)}\\right],\n$$\nwhich follows from iterated expectations and the fact that $\\mathbb{P}(\\Delta = 1 \\mid T) = \\mathbb{P}(C \\ge T) = G(T)$ under independence. Replacing $G$ by a consistent estimator $\\widehat{G}$ yields consistent estimators of the required expectations for correlation:\n$$\n\\widehat{\\mathbb{E}}[T] = \\frac{1}{n}\\sum_{i=1}^n \\frac{\\Delta_i Z_i}{\\widehat{G}(Z_i)}, \\quad\n\\widehat{\\mathbb{E}}[T^2] = \\frac{1}{n}\\sum_{i=1}^n \\frac{\\Delta_i Z_i^2}{\\widehat{G}(Z_i)}, \\quad\n\\widehat{\\mathbb{E}}[XT] = \\frac{1}{n}\\sum_{i=1}^n \\frac{\\Delta_i X_i Z_i}{\\widehat{G}(Z_i)},\n$$\nand the empirical mean and variance of $X$ are\n$$\n\\widehat{\\mathbb{E}}[X] = \\frac{1}{n}\\sum_{i=1}^n X_i, \\quad\n\\widehat{\\operatorname{Var}}(X) = \\frac{1}{n}\\sum_{i=1}^n \\bigl(X_i - \\widehat{\\mathbb{E}}[X]\\bigr)^2.\n$$\nDefine the truncation time $t^\\star$ as the largest observed time such that $\\widehat{G}(t^\\star)  0$. To respect positivity and avoid division by zero, only terms with $Z_i \\le t^\\star$ and $\\widehat{G}(Z_i)  0$ are included in the above sums; if $\\Delta_i = 0$ then the term contributes $0$.\n\nTo estimate $G$, use the Kaplan–Meier estimator for the censoring survival function. Construct the censoring dataset by taking observed times as $Z_i$ and indicator of censoring events as $1 - \\Delta_i$. The Kaplan–Meier survival estimate at time $t$ is\n$$\n\\widehat{G}(t) = \\prod_{u \\le t} \\left(1 - \\frac{d(u)}{r(u)}\\right),\n$$\nwhere $d(u)$ is the number of censoring events at time $u$ (that is, the count of $i$ with $Z_i = u$ and $\\Delta_i = 0$), and $r(u)$ is the number at risk just before time $u$ (that is, the count of $i$ with $Z_i \\ge u$).\n\nImplement this IPCW estimator of $\\rho_{X,T}$ that:\n- Computes $\\widehat{G}(t)$ using Kaplan–Meier on the censoring process.\n- Determines $t^\\star = \\max\\{ t : \\widehat{G}(t)  0 \\}$.\n- Computes $\\widehat{\\rho}_{X,T}$ using the formulas above with truncation by $t^\\star$.\n\nIf $\\widehat{\\operatorname{Var}}(X) \\le 0$ or $\\widehat{\\operatorname{Var}}(T) \\le 0$, define the correlation estimate to be not-a-number (NaN).\n\nYour program must compute the IPCW correlation estimates for the following test suite of four cases. In all cases, time is measured in months and the correlation is dimensionless; report results as decimals.\n\n- Test case $1$ (moderate censoring, mixed times and biomarker): \n  $X_1 = [0.2, 0.35, 0.9, 0.4, 0.6, 0.55, 0.3, 0.8, 0.65, 0.85, 0.15, 1.0]$, \n  $Z_1 = [5, 8, 10, 7, 10, 8, 6, 14, 9, 13, 4, 12]$, \n  $\\Delta_1 = [1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0]$.\n\n- Test case $2$ (heavy late censoring): \n  $X_2 = [1.2, 0.5, 0.9, 0.7, 1.1, 0.4, 1.3, 0.6, 0.8, 0.95]$, \n  $Z_2 = [18, 10, 16, 14, 20, 9, 22, 12, 15, 17]$, \n  $\\Delta_2 = [0, 1, 0, 0, 0, 1, 0, 1, 0, 0]$.\n\n- Test case $3$ (no censoring baseline): \n  $X_3 = [0.1, 0.2, 0.4, 0.5, 0.7, 0.9]$, \n  $Z_3 = [3, 4, 6, 7, 9, 11]$, \n  $\\Delta_3 = [1, 1, 1, 1, 1, 1]$.\n\n- Test case $4$ (ties and early censoring): \n  $X_4 = [2.2, 1.8, 2.0, 2.5, 1.5, 1.7, 2.3, 1.9]$, \n  $Z_4 = [5, 5, 5, 6, 6, 7, 7, 7]$, \n  $\\Delta_4 = [0, 1, 0, 1, 0, 0, 1, 0]$.\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, with each float rounded to $6$ decimal places. For example, produce an output of the form $[r_1, r_2, r_3, r_4]$, where each $r_j$ is the IPCW correlation estimate for test case $j$.",
            "solution": "The problem requires the implementation of an Inverse Probability of Censoring Weighting (IPCW) estimator for the Pearson correlation coefficient between a biomarker $X$ and a right-censored survival time $T$. The procedure is as follows.\n\nFirst, we must acknowledge that standard sample estimates for moments involving $T$ (e.g., sample mean) are biased due to censoring. The IPCW method corrects this bias by up-weighting the contributions of uncensored individuals to compensate for the information lost from censored individuals. The weight for an uncensored observation $i$ with event time $Z_i$ is the inverse of the probability of remaining uncensored up to that time, $\\mathbb{P}(C \\ge Z_i) = G(Z_i)$.\n\nThe core of the methodology lies in estimating this censoring survival function, $G(t)$. The problem specifies using the Kaplan-Meier (KM) estimator. To estimate the survival function of the censoring time $C$, we treat censoring as the \"event\" of interest. The data for this estimation are the pairs $(Z_i, 1-\\Delta_i)$, where $1-\\Delta_i = 1$ indicates a censoring. The Kaplan-Meier formula is given by:\n$$\n\\widehat{G}(t) = \\prod_{u \\le t} \\left(1 - \\frac{d(u)}{r(u)}\\right)\n$$\nwhere the product is taken over distinct censoring times $u$ less than or equal to $t$. Here, $d(u)$ is the number of individuals censored at time $u$ (i.e., those with $Z_i=u$ and $\\Delta_i=0$), and $r(u)$ is the number of individuals at risk of being censored at time $u$ (i.e., all those with observed times $Z_i \\ge u$). A step-by-step implementation involves computing this product for each required time point $Z_i$.\n\nA crucial aspect for numerical stability is the positivity assumption, which dictates that we should only use weights where the denominator $\\widehat{G}(Z_i)$ is non-zero. To enforce this, a truncation time $t^\\star$ is defined as the largest observed time $t$ for which $\\widehat{G}(t)$ is strictly positive. All subsequent calculations of expectations involving $T$ are restricted to uncensored individuals whose event time $Z_i$ does not exceed $t^\\star$.\n\nWith the estimated weights $W_i = 1/\\widehat{G}(Z_i)$ for each uncensored individual $i$, we can compute the unbiased estimates of the moments of $T$. For a function $g(T)$, its expectation is estimated as:\n$$\n\\widehat{\\mathbb{E}}[g(T)] = \\frac{1}{n} \\sum_{i=1, \\Delta_i=1, Z_i \\le t^\\star}^{n} \\frac{g(Z_i)}{\\widehat{G}(Z_i)}\n$$\nWe apply this formula for $g(T) = T$, $g(T) = T^2$, and (by extension) $g(T) = X \\cdot T$. The latter requires a bivariate extension of the IPCW principle, which under independent censoring simplifies to the provided formula for $\\widehat{\\mathbb{E}}[XT]$. The moments of $X$, which is fully observed, are estimated using standard empirical formulas (sample mean and sample variance with $1/n$ normalization).\n\nFinally, these estimated moments are assembled into the Pearson correlation formula. Let $\\widehat{\\mathbb{E}}[T]$, $\\widehat{\\mathbb{E}}[T^2]$, $\\widehat{\\mathbb{E}}[XT]$, $\\widehat{\\mathbb{E}}[X]$, and $\\widehat{\\operatorname{Var}}(X)$ be the estimates computed as described. We calculate:\n$$\n\\widehat{\\operatorname{Var}}(T) = \\widehat{\\mathbb{E}}[T^2] - (\\widehat{\\mathbb{E}}[T])^2\n$$\n$$\n\\widehat{\\operatorname{Cov}}(X,T) = \\widehat{\\mathbb{E}}[XT] - \\widehat{\\mathbb{E}}[X]\\widehat{\\mathbb{E}}[T]\n$$\nThe estimated correlation is then:\n$$\n\\widehat{\\rho}_{X,T} = \\frac{\\widehat{\\operatorname{Cov}}(X,T)}{\\sqrt{\\widehat{\\operatorname{Var}}(X)} \\sqrt{\\widehat{\\operatorname{Var}}(T)}}\n$$\nIt is a known issue that for small samples, the estimated variance $\\widehat{\\operatorname{Var}}(T)$ can be negative. The problem correctly specifies that if either $\\widehat{\\operatorname{Var}}(X)$ or $\\widehat{\\operatorname{Var}}(T)$ is non-positive, the correlation should be considered undefined (NaN).",
            "answer": "```python\nimport numpy as np\n\ndef calculate_ipcw_corr(X, Z, Delta):\n    \"\"\"\n    Computes the IPCW estimator of the Pearson correlation between a fully observed\n    variable X and a right-censored time-to-event variable T.\n\n    Args:\n        X (list or np.ndarray): The continuous biomarker values.\n        Z (list or np.ndarray): The observed times, min(T, C).\n        Delta (list or np.ndarray): The event indicators, 1 if event, 0 if censored.\n\n    Returns:\n        float: The estimated Pearson correlation, or np.nan if variance is non-positive.\n    \"\"\"\n    n = len(X)\n    X = np.asarray(X, dtype=float)\n    Z = np.asarray(Z, dtype=float)\n    Delta = np.asarray(Delta, dtype=int)\n    censor_indicator = 1 - Delta\n\n    # Step 1: Compute Kaplan-Meier estimator for the censoring survival function G(t).\n    # We need to compute G_hat(Z_i) for each subject i.\n    G_hat_at_Z = np.ones_like(Z, dtype=float)\n    unique_censor_times = np.unique(Z[censor_indicator == 1])\n\n    for i in range(n):\n        t_query = Z[i]\n        prob_survival = 1.0\n        \n        # Product over distinct censoring times u = t_query\n        for t_censor in unique_censor_times:\n            if t_censor = t_query:\n                # Count censorings at t_censor\n                d_u = np.sum((Z == t_censor)  (censor_indicator == 1))\n                # Count at risk at t_censor\n                r_u = np.sum(Z >= t_censor)\n                \n                if r_u > 0:\n                    prob_survival *= (1.0 - d_u / r_u)\n                else: \n                    # If risk set is 0, survival probability drops to 0\n                    prob_survival = 0.0\n                    break\n        G_hat_at_Z[i] = prob_survival\n\n    # Step 2: Determine the truncation time t_star.\n    # t_star is the largest observed time Z_i with a positive censoring survival probability.\n    valid_indices = G_hat_at_Z > 0\n    if not np.any(valid_indices):\n        t_star = -1.0  # Ensures all terms are excluded if G_hat is always 0.\n    else:\n        t_star = np.max(Z[valid_indices])\n\n    # Step 3: Compute moments. Standard for X, IPCW for T.\n    # Moments for X using all data\n    E_X = np.mean(X)\n    Var_X = np.var(X) # numpy.var uses 1/n normalization by default\n\n    # IPCW-weighted moments for T\n    E_T_sum = 0.0\n    E_T2_sum = 0.0\n    E_XT_sum = 0.0\n    \n    for i in range(n):\n        if Delta[i] == 1 and Z[i] = t_star:\n            g_hat_zi = G_hat_at_Z[i]\n            if g_hat_zi > 0:\n                weight = 1.0 / g_hat_zi\n                E_T_sum += Z[i] * weight\n                E_T2_sum += (Z[i]**2) * weight\n                E_XT_sum += X[i] * Z[i] * weight\n\n    E_T = E_T_sum / n\n    E_T2 = E_T2_sum / n\n    E_XT = E_XT_sum / n\n    \n    # Step 4: Assemble the correlation coefficient\n    Var_T = E_T2 - E_T**2\n    \n    if Var_X = 0 or Var_T = 0:\n        return np.nan\n        \n    Cov_XT = E_XT - E_X * E_T\n    \n    denominator = np.sqrt(Var_X) * np.sqrt(Var_T)\n    if denominator == 0:\n        # This should be caught by the Var_X/Var_T checks, but included for robustness.\n        return np.nan \n        \n    rho = Cov_XT / denominator\n    \n    return rho\n\ndef solve():\n    \"\"\"\n    Main function to run the test cases and print the results.\n    \"\"\"\n    test_cases = [\n        {\n            \"X\": [0.2, 0.35, 0.9, 0.4, 0.6, 0.55, 0.3, 0.8, 0.65, 0.85, 0.15, 1.0],\n            \"Z\": [5, 8, 10, 7, 10, 8, 6, 14, 9, 13, 4, 12],\n            \"Delta\": [1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0]\n        },\n        {\n            \"X\": [1.2, 0.5, 0.9, 0.7, 1.1, 0.4, 1.3, 0.6, 0.8, 0.95],\n            \"Z\": [18, 10, 16, 14, 20, 9, 22, 12, 15, 17],\n            \"Delta\": [0, 1, 0, 0, 0, 1, 0, 1, 0, 0]\n        },\n        {\n            \"X\": [0.1, 0.2, 0.4, 0.5, 0.7, 0.9],\n            \"Z\": [3, 4, 6, 7, 9, 11],\n            \"Delta\": [1, 1, 1, 1, 1, 1]\n        },\n        {\n            \"X\": [2.2, 1.8, 2.0, 2.5, 1.5, 1.7, 2.3, 1.9],\n            \"Z\": [5, 5, 5, 6, 6, 7, 7, 7],\n            \"Delta\": [0, 1, 0, 1, 0, 0, 1, 0]\n        }\n    ]\n\n    results = []\n    for case in test_cases:\n        result = calculate_ipcw_corr(case[\"X\"], case[\"Z\"], case[\"Delta\"])\n        results.append(result)\n\n    # Format output to 6 decimal places as required.\n    formatted_results = [f\"{r:.6f}\" for r in results]\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```"
        }
    ]
}