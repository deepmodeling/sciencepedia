{
    "hands_on_practices": [
        {
            "introduction": "This practice grounds our exploration in the ideal scenario: the randomized controlled trial (RCT). By leveraging the potential outcomes framework, you will see how the powerful assumption of exchangeability, induced by randomization, allows us to directly estimate the causal Average Treatment Effect ($ATE$) from observed data. This exercise  is fundamental for connecting the abstract principles of causal inference to the concrete analysis of experimental data.",
            "id": "4980051",
            "problem": "A two-arm, parallel-group randomized controlled trial compares an investigational therapy, indexed by $T=1$, to standard care, indexed by $T=0$, for reducing the occurrence of a binary clinical outcome $Y$ observed within $30$ days, where $Y=1$ indicates the event occurred and $Y=0$ indicates the event did not occur. Let the potential outcomes be $Y(1)$ and $Y(0)$, defined as the values $Y$ would take under treatment $T=1$ and $T=0$, respectively. The observed arm-specific mean outcomes are $E[Y\\mid T=1]=0.62$ and $E[Y\\mid T=0]=0.50$. Using the potential outcomes framework and principles of experimental design, including exchangeability induced by randomization, consistency under the Stable Unit Treatment Value Assumption (SUTVA), and positivity, derive an expression for the causal Average Treatment Effect (ATE) $E[Y(1)-Y(0)]$ in terms of observable quantities in this trial, then compute its numerical value from the provided data. Interpret this value as an absolute risk difference for the $30$-day outcome. Express your final answer as a single decimal number (no percentage sign). Use exact arithmetic; no rounding is required.",
            "solution": "The Average Treatment Effect (ATE) is defined by the expected difference in potential outcomes:\n$$ATE = E[Y(1) - Y(0)]$$\nBy the linearity of expectation, this can be written as:\n$$ATE = E[Y(1)] - E[Y(0)]$$\nThe problem states that this is a randomized controlled trial. A successful randomization ensures **exchangeability**, meaning the potential outcomes are independent of the treatment assignment ($T$). Formally, this is written as $(Y(1), Y(0)) \\perp T$. This implies that the expected potential outcome under treatment is the same regardless of which group we look at:\n$$E[Y(1) | T=1] = E[Y(1) | T=0] = E[Y(1)]$$\n$$E[Y(0) | T=1] = E[Y(0) | T=0] = E[Y(0)]$$\nThe **consistency** assumption (part of SUTVA) links potential outcomes to observed outcomes. It states that an individual's observed outcome $Y$ is their potential outcome under the treatment they actually received, i.e., $Y = Y(T)$. This means for the treated group, $Y = Y(1)$, and for the control group, $Y = Y(0)$.\n\nCombining these principles allows us to express the unobservable ATE in terms of observable quantities:\n1. The observed mean outcome in the treatment group is $E[Y \\mid T=1]$. By consistency, this is $E[Y(1) \\mid T=1]$. By exchangeability, this equals $E[Y(1)]$.\n2. The observed mean outcome in the control group is $E[Y \\mid T=0]$. By consistency, this is $E[Y(0) \\mid T=0]$. By exchangeability, this equals $E[Y(0)]$.\n\nTherefore, the ATE is simply the difference in the observed mean outcomes between the two arms of the trial:\n$$ATE = E[Y \\mid T=1] - E[Y \\mid T=0]$$\nThe problem provides the following data:\n- $E[Y \\mid T=1] = 0.62$\n- $E[Y \\mid T=0] = 0.50$\n\nSubstituting these values, we compute the ATE:\n$$ATE = 0.62 - 0.50 = 0.12$$\nThis value represents an absolute risk difference. The investigational therapy causes a $0.12$ (or 12 percentage point) increase in the absolute risk of the clinical outcome within 30 days compared to standard care.",
            "answer": "$$\n\\boxed{0.12}\n$$"
        },
        {
            "introduction": "A well-analyzed study begins with a well-conceived design. This practice  moves from estimating effects to the crucial planning phase of an experimental study: determining the required sample size. By deriving the sample size formula from first principles, you will gain a deeper appreciation for the interplay between statistical power, effect size, and the probabilities of Type I ($\\alpha$) and Type II ($\\beta$) errors, ensuring your future trials are both ethical and efficient.",
            "id": "4980114",
            "problem": "A clinical research team plans an individually randomized, parallel-group superiority trial (an experimental study) to compare a new intervention versus usual care on a binary clinical endpoint observed at a fixed follow-up time. Let the true event probability in the intervention arm be $p_{1}$ and in the control arm be $p_{0}$. The primary analysis tests the null hypothesis $H_{0}: p_{1} = p_{0}$ against the two-sided alternative $H_{1}: p_{1} \\neq p_{0}$ at type I error $\\alpha$, using a large-sample score test under equal allocation with $n$ patients per group. The study is powered to detect a prespecified difference $\\Delta = p_{1} - p_{0} > 0$ with power $1 - \\beta$.\n\nStarting from the binomial model for independent outcomes in each arm, the Central Limit Theorem (CLT) implies that the difference in sample proportions is approximately normal. Using this as the fundamental base, derive the per-group sample size $n$ that ensures the two-sided score test has power at least $1 - \\beta$ to detect $\\Delta$ at type I error $\\alpha$. Your derivation must begin from the distributional approximations implied by the CLT and the null and alternative variances appropriate to the score test, and then algebraically solve for $n$ in terms of $p_{0}$, $p_{1}$, $\\alpha$, and $\\beta$. Denote by $\\Phi$ the cumulative distribution function of the Standard Normal Distribution (SND), and by $\\Phi^{-1}$ its quantile function.\n\nThen, compute the required per-group sample size for $p_{1} = 0.30$, $p_{0} = 0.20$, $\\alpha = 0.05$ (two-sided), and power $0.80$ using your derived expression. Report the smallest integer total sample size $N_{\\text{total}} = 2n$ that achieves the target power. Do not use percentage signs; express all probabilities as decimals.",
            "solution": "The problem is valid as it is scientifically grounded, self-contained, and well-posed within the established framework of statistical hypothesis testing for clinical trials.\n\nWe begin by formally defining the components of the problem. Let $X_1$ and $X_0$ be the number of events in the intervention and control arms, respectively. Under the specified model, these are independent random variables with binomial distributions: $X_1 \\sim \\text{Binomial}(n, p_1)$ and $X_0 \\sim \\text{Binomial}(n, p_0)$. The corresponding sample proportions are $\\hat{p}_1 = X_1/n$ and $\\hat{p}_0 = X_0/n$. The null and alternative hypotheses are $H_0: p_1 = p_0$ and $H_1: p_1 \\neq p_0$.\n\nThe score test is based on a test statistic evaluated under the null hypothesis. Under $H_0$, there is a common event probability, say $p$, which is estimated by the pooled proportion:\n$$\n\\hat{p}_{\\text{pool}} = \\frac{X_1 + X_0}{n + n} = \\frac{\\hat{p}_1 + \\hat{p}_0}{2}\n$$\nThe variance of the difference in proportions, $\\hat{p}_1 - \\hat{p}_0$, under the assumption that $H_0$ is true, is $\\text{Var}(\\hat{p}_1 - \\hat{p}_0 | H_0) = \\frac{p(1-p)}{n} + \\frac{p(1-p)}{n} = \\frac{2p(1-p)}{n}$. The score test statistic standardizes the observed difference using an estimate of this variance based on $\\hat{p}_{\\text{pool}}$:\n$$\nZ_{\\text{score}} = \\frac{\\hat{p}_1 - \\hat{p}_0}{\\sqrt{\\frac{2\\hat{p}_{\\text{pool}}(1-\\hat{p}_{\\text{pool}})}{n}}}\n$$\nUnder $H_0$, $Z_{\\text{score}}$ follows approximately a Standard Normal Distribution, $N(0,1)$. For a two-sided test with a type I error rate of $\\alpha$, we reject $H_0$ if $|Z_{\\text{score}}| > \\Phi^{-1}(1 - \\alpha/2)$, where $\\Phi^{-1}$ is the quantile function of the Standard Normal Distribution.\n\nPower is the probability of correctly rejecting $H_0$ when the alternative hypothesis $H_1$ is true. For sample size planning, we consider the specific alternative where the true probabilities are $p_1$ and $p_0$. We require the power to be at least $1-\\beta$. Under $H_1$, the expected value of $\\hat{p}_{\\text{pool}}$ is $E[\\hat{p}_{\\text{pool}}] = \\frac{p_1+p_0}{2}$. Let's denote this average probability as $\\bar{p} = \\frac{p_1+p_0}{2}$. For large $n$, $\\hat{p}_{\\text{pool}}$ will be close to $\\bar{p}$. Therefore, for the purpose of power calculation, we approximate the denominator of the score statistic using $\\bar{p}$ instead of the random $\\hat{p}_{\\text{pool}}$.\n\nThe rejection rule is thus approximated as:\n$$\n\\left| \\frac{\\hat{p}_1 - \\hat{p}_0}{\\sqrt{\\frac{2\\bar{p}(1-\\bar{p})}{n}}} \\right| > \\Phi^{-1}(1 - \\alpha/2)\n$$\nWe are designing the study to detect a difference $\\Delta = p_1 - p_0 > 0$. In this case, the power is dominated by the upper tail of the rejection region. The power is approximately:\n$$\n\\text{Power} = P\\left( \\frac{\\hat{p}_1 - \\hat{p}_0}{\\sqrt{\\frac{2\\bar{p}(1-\\bar{p})}{n}}} > \\Phi^{-1}(1 - \\alpha/2) \\;\\middle|\\; H_1 \\right) = 1-\\beta\n$$\nThis is equivalent to:\n$$\nP\\left( \\hat{p}_1 - \\hat{p}_0 > \\Phi^{-1}(1 - \\alpha/2) \\sqrt{\\frac{2\\bar{p}(1-\\bar{p})}{n}} \\;\\middle|\\; H_1 \\right) = 1-\\beta\n$$\nTo evaluate this probability, we must standardize the random variable $\\hat{p}_1 - \\hat{p}_0$ using its true distribution under $H_1$. By the Central Limit Theorem, $\\hat{p}_1 - \\hat{p}_0$ is approximately normally distributed with mean $E[\\hat{p}_1 - \\hat{p}_0] = p_1 - p_0$ and variance $\\text{Var}(\\hat{p}_1 - \\hat{p}_0) = \\text{Var}(\\hat{p}_1) + \\text{Var}(\\hat{p}_0) = \\frac{p_1(1-p_1)}{n} + \\frac{p_0(1-p_0)}{n}$.\n\nLet $Z$ be a standard normal random variable. Standardizing the inequality gives:\n$$\nP\\left( \\frac{(\\hat{p}_1 - \\hat{p}_0) - (p_1-p_0)}{\\sqrt{\\frac{p_1(1-p_1) + p_0(1-p_0)}{n}}} > \\frac{\\Phi^{-1}(1 - \\alpha/2)\\sqrt{\\frac{2\\bar{p}(1-\\bar{p})}{n}} - (p_1-p_0)}{\\sqrt{\\frac{p_1(1-p_1) + p_0(1-p_0)}{n}}} \\right) = 1-\\beta\n$$\nThe left side is $P(Z > \\text{some value})$. For this probability to equal $1-\\beta$, the argument must be equal to $\\Phi^{-1}(\\beta) = -\\Phi^{-1}(1-\\beta)$.\n$$\n\\frac{\\Phi^{-1}(1 - \\alpha/2)\\sqrt{2\\bar{p}(1-\\bar{p})}\\frac{1}{\\sqrt{n}} - (p_1-p_0)}{\\sqrt{p_1(1-p_1) + p_0(1-p_0)}\\frac{1}{\\sqrt{n}}} = -\\Phi^{-1}(1-\\beta)\n$$\nMultiplying the terms by $\\sqrt{n}$ and rearranging yields:\n$$\n\\Phi^{-1}(1 - \\alpha/2)\\sqrt{2\\bar{p}(1-\\bar{p})} - \\sqrt{n}(p_1-p_0) = -\\Phi^{-1}(1-\\beta)\\sqrt{p_1(1-p_1) + p_0(1-p_0)}\n$$\nNow, we solve for $\\sqrt{n}$:\n$$\n\\sqrt{n}(p_1-p_0) = \\Phi^{-1}(1 - \\alpha/2)\\sqrt{2\\bar{p}(1-\\bar{p})} + \\Phi^{-1}(1-\\beta)\\sqrt{p_1(1-p_1) + p_0(1-p_0)}\n$$\n$$\n\\sqrt{n} = \\frac{\\Phi^{-1}(1 - \\alpha/2)\\sqrt{2\\bar{p}(1-\\bar{p})} + \\Phi^{-1}(1-\\beta)\\sqrt{p_1(1-p_1) + p_0(1-p_0)}}{p_1-p_0}\n$$\nSquaring both sides gives the final expression for the per-group sample size $n$:\n$$\nn = \\frac{\\left( \\Phi^{-1}(1 - \\alpha/2)\\sqrt{2\\bar{p}(1-\\bar{p})} + \\Phi^{-1}(1-\\beta)\\sqrt{p_1(1-p_1) + p_0(1-p_0)} \\right)^2}{(p_1-p_0)^2}\n$$\nwhere $\\bar{p} = (p_0+p_1)/2$.\n\nWe now compute the required sample size for the given parameters: $p_1 = 0.30$, $p_0 = 0.20$, $\\alpha = 0.05$, and power $1-\\beta = 0.80$.\nThis implies $\\beta = 0.20$. The effect size is $\\Delta = p_1 - p_0 = 0.10$.\nThe required quantiles from the Standard Normal Distribution are:\n$$\n\\Phi^{-1}(1 - \\alpha/2) = \\Phi^{-1}(1 - 0.05/2) = \\Phi^{-1}(0.975) \\approx 1.95996\n$$\n$$\n\\Phi^{-1}(1-\\beta) = \\Phi^{-1}(1-0.20) = \\Phi^{-1}(0.80) \\approx 0.84162\n$$\nNext, we compute the variance components. The average proportion $\\bar{p}$ is:\n$$\n\\bar{p} = \\frac{0.20 + 0.30}{2} = 0.25\n$$\nThe variance term corresponding to the score test's null hypothesis structure is:\n$$\n2\\bar{p}(1-\\bar{p}) = 2(0.25)(1-0.25) = 2(0.25)(0.75) = 0.375\n$$\nThe variance term corresponding to the true distribution under the alternative hypothesis is:\n$$\np_1(1-p_1) + p_0(1-p_0) = 0.30(0.70) + 0.20(0.80) = 0.21 + 0.16 = 0.37\n$$\nSubstituting these values into the derived formula for $n$:\n$$\nn = \\frac{\\left( 1.95996 \\sqrt{0.375} + 0.84162 \\sqrt{0.37} \\right)^2}{(0.10)^2}\n$$\n$$\nn \\approx \\frac{\\left( 1.95996 \\times 0.61237 + 0.84162 \\times 0.60828 \\right)^2}{0.01}\n$$\n$$\nn \\approx \\frac{\\left( 1.20023 + 0.51194 \\right)^2}{0.01} = \\frac{(1.71217)^2}{0.01} \\approx \\frac{2.93153}{0.01} \\approx 293.153\n$$\nSince the sample size must be an integer, we take the ceiling of this value to ensure the power is at least $0.80$.\n$$\nn = \\lceil 293.153 \\rceil = 294\n$$\nThis is the required sample size per group. The total sample size is $N_{\\text{total}} = 2n$.\n$$\nN_{\\text{total}} = 2 \\times 294 = 588\n$$\nThus, the smallest total sample size that achieves the target power is $588$.",
            "answer": "$$\\boxed{588}$$"
        },
        {
            "introduction": "While RCTs are the gold standard, many research questions can only be addressed through observational studies. This practice  explores the matched case-control design, a powerful strategy for controlling confounding when randomization is not possible. You will derive the conditional odds ratio, discovering how the design choice of matching directly dictates the analytical approach—conditional likelihood—which elegantly removes nuisance parameters and focuses the analysis on the most informative data.",
            "id": "4980052",
            "problem": "A hospital-based investigation studies the association between a binary exposure $X \\in \\{0,1\\}$ (e.g., an indicator of recent use of a specific medication) and a rare disease $Y \\in \\{0,1\\}$ using a $1{:}1$ matched case-control design. Matching is performed on age, sex, and hospital unit to control for confounding, and each matched stratum (pair) contains exactly one case $(Y=1)$ and one control $(Y=0)$. Let there be $M$ matched pairs indexed by $j=1,\\dots,M$. Within each pair $j$, denote the exposure indicators of the case and control by $X_{j1}$ and $X_{j0}$, respectively.\n\nAssume the standard conditional logistic regression model for a matched pair with a pair-specific intercept, that is,\n$$\n\\Pr(Y_{ji}=1 \\mid X_{ji}, \\alpha_j) = \\frac{\\exp(\\alpha_j + \\beta X_{ji})}{1 + \\exp(\\alpha_j + \\beta X_{ji})},\n$$\nfor $i \\in \\{0,1\\}$, where $\\alpha_j$ captures the pair-specific baseline risk and $\\beta$ is the log odds ratio parameter for the effect of exposure $X$ on disease $Y$. Given this setup and conditioning on the observed matched structure (exactly one case and one control per pair), the conditional likelihood contribution of a matched pair depends only on whether it is discordant for exposure $(X_{j1} \\neq X_{j0})$ or concordant $(X_{j1} = X_{j0})$.\n\nA matched case-control study is conducted with $M=200$ pairs. Among these, $60$ pairs are discordant with $(X_{j1}=1, X_{j0}=0)$, and $40$ pairs are discordant with $(X_{j1}=0, X_{j0}=1)$. The remaining pairs are concordant for exposure. Based on the conditional likelihood implied by the model above and fundamental definitions of odds and odds ratios, derive the conditional maximum likelihood estimator for the odds ratio $\\exp(\\beta)$ in terms of the discordant pair counts, and then compute its value using the data provided. Express your final answer as a single real number. No rounding is required.",
            "solution": "The parameter of interest is the odds ratio (OR), $\\exp(\\beta)$, where $\\beta$ is the log odds ratio from the conditional logistic model:\n$$ \\Pr(Y_{ji}=1 \\mid X_{ji}, \\alpha_j) = \\frac{\\exp(\\alpha_j + \\beta X_{ji})}{1 + \\exp(\\alpha_j + \\beta X_{ji})} $$\nThe odds of disease for an individual with exposure $X$ in stratum $j$ is $\\exp(\\alpha_j + \\beta X)$. The odds ratio comparing an exposed ($X=1$) to an unexposed ($X=0$) individual within the same stratum is:\n$$ OR = \\frac{\\exp(\\alpha_j + \\beta \\cdot 1)}{\\exp(\\alpha_j + \\beta \\cdot 0)} = \\exp(\\beta) $$\nTo estimate $\\beta$ without having to estimate the many nuisance parameters $\\alpha_j$, we use a conditional likelihood approach. We condition on the fact that each pair $j$ contains exactly one case ($Y=1$) and one control ($Y=0$), and we condition on the set of observed exposures within that pair, $\\{X_{j1}, X_{j0}\\}$.\n\nThe conditional probability that the individual with exposure $X_{j1}$ is the case and the one with exposure $X_{j0}$ is the control is:\n$$ L_j(\\beta) = \\Pr(\\text{outcome pattern} \\mid \\text{exposures for pair } j) = \\frac{\\exp(\\alpha_j + \\beta X_{j1})}{\\exp(\\alpha_j + \\beta X_{j1}) + \\exp(\\alpha_j + \\beta X_{j0})} $$\nThe nuisance parameter $\\alpha_j$ is eliminated by factoring $\\exp(\\alpha_j)$ from the numerator and denominator:\n$$ L_j(\\beta) = \\frac{\\exp(\\beta X_{j1})}{\\exp(\\beta X_{j1}) + \\exp(\\beta X_{j0})} $$\nThe total conditional likelihood, $L(\\beta)$, is the product of these contributions over all $M$ pairs. However, only pairs with discordant exposures contribute to the estimation of $\\beta$:\n\n1.  **Concordant Pairs** ($X_{j1} = X_{j0}$): The likelihood contribution is $L_j(\\beta) = \\frac{\\exp(\\beta X_{j1})}{\\exp(\\beta X_{j1}) + \\exp(\\beta X_{j1})} = \\frac{1}{2}$. These pairs provide no information about $\\beta$.\n\n2.  **Discordant Pairs** ($X_{j1} \\neq X_{j0}$):\n    *   Case exposed, control unexposed ($X_{j1}=1, X_{j0}=0$): Let there be $n_{10}$ such pairs. The contribution is $L_j(\\beta) = \\frac{\\exp(\\beta)}{\\exp(\\beta) + 1}$.\n    *   Case unexposed, control exposed ($X_{j1}=0, X_{j0}=1$): Let there be $n_{01}$ such pairs. The contribution is $L_j(\\beta) = \\frac{\\exp(0)}{\\exp(0) + \\exp(\\beta)} = \\frac{1}{1 + \\exp(\\beta)}$.\n\nThe conditional likelihood function is therefore based only on the discordant pairs:\n$$ L(\\beta) = \\left( \\frac{\\exp(\\beta)}{1 + \\exp(\\beta)} \\right)^{n_{10}} \\left( \\frac{1}{1 + \\exp(\\beta)} \\right)^{n_{01}} $$\nThe log-likelihood is:\n$$ \\ell(\\beta) = \\ln(L(\\beta)) = n_{10}\\beta - (n_{10} + n_{01}) \\ln(1 + \\exp(\\beta)) $$\nTo find the maximum likelihood estimator (MLE), we take the derivative with respect to $\\beta$ and set it to zero:\n$$ \\frac{d\\ell}{d\\beta} = n_{10} - (n_{10} + n_{01}) \\frac{\\exp(\\beta)}{1 + \\exp(\\beta)} = 0 $$\nSolving for $\\exp(\\beta)$:\n$$ n_{10}(1 + \\exp(\\beta)) = (n_{10} + n_{01}) \\exp(\\beta) $$\n$$ n_{10} + n_{10} \\exp(\\beta) = n_{10} \\exp(\\beta) + n_{01} \\exp(\\beta) $$\n$$ n_{10} = n_{01} \\exp(\\beta) $$\nThis gives the MLE for the odds ratio:\n$$ \\widehat{OR} = \\exp(\\hat{\\beta}) = \\frac{n_{10}}{n_{01}} $$\nThe estimator is simply the ratio of the two types of discordant pairs.\n\nUsing the data provided:\n-   Number of pairs with an exposed case and unexposed control: $n_{10} = 60$.\n-   Number of pairs with an unexposed case and exposed control: $n_{01} = 40$.\n\nThe estimated odds ratio is:\n$$ \\widehat{OR} = \\frac{60}{40} = 1.5 $$",
            "answer": "$$\n\\boxed{1.5}\n$$"
        }
    ]
}