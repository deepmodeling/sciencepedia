{
    "hands_on_practices": [
        {
            "introduction": "The first step in any quantitative analysis of eye movements is accurate calibration. This exercise guides you through the fundamental process of converting raw VNG camera data, measured in pixels, into clinically meaningful angular units of degrees. You will not only calculate the core calibration factor but also learn to assess the system's performance by quantifying its linearity with a root-mean-square error, a crucial step for ensuring data quality.",
            "id": "5085376",
            "problem": "A vestibular function laboratory calibrates a horizontal eye position trace in videonystagmography (VNG) using a projected dot stimulus at known azimuthal angles. Under the small-angle approximation for ocular rotations, the horizontal gaze angle $\\,\\theta\\,$ (in degrees) is linearly related to the measured horizontal pupil-center displacement $\\,p\\,$ (in pixels) by $\\,\\theta \\approx g\\,p\\,$, where $\\,g\\,$ is the degrees-per-pixel calibration factor. The calibration is anchored by a single-step presentation in which a target at $\\,\\Delta\\theta = 15^{\\circ}\\,$ produces a measured displacement $\\,\\Delta p = 120\\,$ pixels. You then test linearity across multiple target positions using the same recording, with target azimuths and measured displacements as follows:\n- Target at $-30^{\\circ}$ yields $p=-242$.\n- Target at $-15^{\\circ}$ yields $p=-118$.\n- Target at $0^{\\circ}$ yields $p=1$.\n- Target at $+15^{\\circ}$ yields $p=121$.\n- Target at $+30^{\\circ}$ yields $p=239$.\n\nAssume the central fixation at $0^{\\circ}$ defines the zero of $\\,\\theta\\,$ and that the mapping has zero intercept fixed by this origin. Starting from the definition that, for small rotations, $\\,\\tan(\\theta)\\approx\\theta\\,$ (in radians) and a constant optical scale converts angular change to image-plane displacement, justify the linear model $\\,\\theta \\approx g\\,p\\,$ and determine $\\,g\\,$ from the anchor step. Then use this $\\,g\\,$ to convert each measured $\\,p\\,$ into an estimated angle $\\,\\hat{\\theta} = g\\,p\\,$ and quantify linearity by computing the root-mean-square (RMS) angular error\n$$\n\\theta_{\\mathrm{RMS}} \\equiv \\sqrt{\\frac{1}{N}\\sum_{i=1}^{N}\\bigl(\\hat{\\theta}_{i}-\\theta_{i}\\bigr)^{2}},\n$$\nwhere $\\,\\theta_{i}\\,$ are the known target angles and $\\,N=5\\,$ is the number of targets. Report as your final answer the value of $\\,\\theta_{\\mathrm{RMS}}\\,$ expressed in degrees. Round your answer to four significant figures. State angles in degrees; do not convert to radians.",
            "solution": "The problem statement has been critically examined and is found to be valid. It is scientifically grounded in the principles of ocular biomechanics and optical measurement, is well-posed with sufficient and consistent data, and is formulated objectively. We may therefore proceed with a rigorous solution.\n\nThe problem requires three main steps: first, to justify the linear relationship between gaze angle and measured pupil displacement; second, to calculate the calibration factor from the given anchor step; and third, to quantify the linearity of the system by computing the root-mean-square (RMS) error over a set of test measurements.\n\n**1. Justification of the Linear Model**\n\nThe relationship between the angle of an object in the visual field and the position of its image on a sensor is fundamentally governed by trigonometry. For a simple pinhole camera or a lens system with effective focal length $f_{\\text{eff}}$, an object at an angle $\\theta$ from the optical axis produces an image at a displacement $d$ from the sensor's center given by $d = f_{\\text{eff}} \\tan(\\theta)$.\n\nIn the context of videonystagmography (VNG), a camera records the eye's movement. As the eye rotates by an angle $\\theta$ to fixate on a target, the pupil center (and other features) displaces in the camera's image. This displacement, denoted by $p$ in pixels, is proportional to the physical displacement on the sensor. Therefore, we can write:\n$$\np = k_{\\text{opt}} \\tan(\\theta)\n$$\nwhere $k_{\\text{opt}}$ is an overall scaling constant, in units of pixels, that depends on the geometry of the setup (e.g., eye-to-camera distance) and the camera's optical properties.\n\nThe problem states that we must use the small-angle approximation. For small angles $\\theta$ measured in radians, we have $\\tan(\\theta) \\approx \\theta$. Substituting this into the equation above yields a linear relationship:\n$$\np \\approx k_{\\text{opt}} \\theta_{\\text{rad}}\n$$\nwhere $\\theta_{\\text{rad}}$ is the angle in radians. The problem, however, specifies the gaze angle $\\theta$ in degrees. The conversion between radians and degrees is $\\theta_{\\text{rad}} = \\theta_{\\text{deg}} \\cdot \\frac{\\pi}{180}$. Substituting this conversion gives:\n$$\np \\approx k_{\\text{opt}} \\left( \\theta_{\\text{deg}} \\frac{\\pi}{180} \\right)\n$$\nTo obtain the model specified in the problem, $\\theta \\approx g p$, we rearrange the expression to solve for $\\theta_{\\text{deg}}$:\n$$\n\\theta_{\\text{deg}} \\approx \\left( \\frac{180}{k_{\\text{opt}}\\pi} \\right) p\n$$\nThis is precisely the linear model $\\theta \\approx g p$, where the calibration factor $g$ is a constant defined as $g \\equiv \\frac{180}{k_{\\text{opt}}\\pi}$. Its units are degrees per pixel. This justifies the use of a linear model for small ocular rotations.\n\n**2. Determination of the Calibration Factor, $g$**\n\nThe calibration factor $g$ is determined from the provided anchor step. A target stimulus presented at an angle of $\\Delta\\theta = 15^{\\circ}$ produces a measured pupil displacement of $\\Delta p = 120$ pixels. The problem assumes a zero intercept, meaning $\\theta=0^{\\circ}$ corresponds to a reference $p \\approx 0$. Thus, we can relate the absolute values directly using the linear model $\\theta = g p$:\n$$\n15 = g \\cdot 120\n$$\nSolving for $g$, we find:\n$$\ng = \\frac{15}{120} = \\frac{1}{8} = 0.125 \\text{ degrees/pixel}\n$$\n\n**3. Calculation of the Root-Mean-Square (RMS) Angular Error**\n\nWith the calibration factor $g=0.125$ established, we can now use the model $\\hat{\\theta}_{i} = g p_{i}$ to estimate the gaze angle for each of the $N=5$ test measurements. The test data are the pairs $(\\theta_i, p_i)$:\n\\begin{itemize}\n    \\item $i=1$: $\\theta_1 = -30^{\\circ}$, $p_1 = -242$\n    \\item $i=2$: $\\theta_2 = -15^{\\circ}$, $p_2 = -118$\n    \\item $i=3$: $\\theta_3 = 0^{\\circ}$, $p_3 = 1$\n    \\item $i=4$: $\\theta_4 = 15^{\\circ}$, $p_4 = 121$\n    \\item $i=5$: $\\theta_5 = 30^{\\circ}$, $p_5 = 239$\n\\end{itemize}\nWe calculate the estimated angle $\\hat{\\theta}_i = 0.125 \\cdot p_i$ for each data point:\n\\begin{itemize}\n    \\item $\\hat{\\theta}_1 = 0.125 \\times (-242) = -30.25^{\\circ}$\n    \\item $\\hat{\\theta}_2 = 0.125 \\times (-118) = -14.75^{\\circ}$\n    \\item $\\hat{\\theta}_3 = 0.125 \\times 1 = 0.125^{\\circ}$\n    \\item $\\hat{\\theta}_4 = 0.125 \\times 121 = 15.125^{\\circ}$\n    \\item $\\hat{\\theta}_5 = 0.125 \\times 239 = 29.875^{\\circ}$\n\\end{itemize}\nNext, we will find the error for each measurement, which is the difference between the estimated angle and the true target angle, $e_i = \\hat{\\theta}_i - \\theta_i$:\n\\begin{itemize}\n    \\item $e_1 = -30.25 - (-30) = -0.25^{\\circ}$\n    \\item $e_2 = -14.75 - (-15) = 0.25^{\\circ}$\n    \\item $e_3 = 0.125 - 0 = 0.125^{\\circ}$\n    \\item $e_4 = 15.125 - 15 = 0.125^{\\circ}$\n    \\item $e_5 = 29.875 - 30 = -0.125^{\\circ}$\n\\end{itemize}\nThe RMS angular error is defined as $\\theta_{\\mathrm{RMS}} = \\sqrt{\\frac{1}{N}\\sum_{i=1}^{N}(\\hat{\\theta}_{i}-\\theta_{i})^{2}}$. First, we compute the sum of the squared errors:\n$$\n\\sum_{i=1}^{5} e_i^2 = (-0.25)^2 + (0.25)^2 + (0.125)^2 + (0.125)^2 + (-0.125)^2\n$$\n$$\n\\sum_{i=1}^{5} e_i^2 = 0.0625 + 0.0625 + 0.015625 + 0.015625 + 0.015625\n$$\n$$\n\\sum_{i=1}^{5} e_i^2 = 2 \\times 0.0625 + 3 \\times 0.015625 = 0.125 + 0.046875 = 0.171875\n$$\nThe units of this sum are degrees$^2$. Now, we calculate the mean squared error (MSE) by dividing by the number of measurements, $N=5$:\n$$\n\\text{MSE} = \\frac{1}{5} \\sum_{i=1}^{5} e_i^2 = \\frac{0.171875}{5} = 0.034375 \\text{ degrees}^2\n$$\nFinally, the RMS error is the square root of the MSE:\n$$\n\\theta_{\\mathrm{RMS}} = \\sqrt{0.034375} \\approx 0.18540496... \\text{ degrees}\n$$\nThe problem requires the result to be rounded to four significant figures.\n$$\n\\theta_{\\mathrm{RMS}} \\approx 0.1854 \\text{ degrees}\n$$\nThis value quantifies the average deviation of the measured eye positions from the predictions of the idealized linear model based on the single-point calibration.",
            "answer": "$$\n\\boxed{0.1854}\n$$"
        },
        {
            "introduction": "Clinical recordings are rarely perfect and are often contaminated by physiological artifacts such as eye blinks. This practice challenges you to think critically about robust signal processing, evaluating different strategies for automatically detecting and masking blink artifacts in both VNG and ENG data . The goal is to develop a method that preserves the integrity of the underlying physiological signal, which is essential for accurate slow-phase velocity estimation.",
            "id": "5085318",
            "problem": "An otoneurology laboratory records horizontal eye position during bithermal caloric testing using both videonystagmography (VNG) and electronystagmography (ENG) simultaneously. Videonystagmography (VNG) provides a sampled eye position time series $x_{\\mathrm{VNG}}[n]$ and a per-sample pupil-confidence metric $c[n] \\in [0,1]$, while electronystagmography (ENG) provides a sampled corneo-retinal potential derived eye position proxy $x_{\\mathrm{ENG}}[n]$. Both series are sampled at frequency $f_{s}$ and indexed by integer time $n$ with sampling interval $\\Delta t = 1/f_{s}$. The laboratory seeks to implement an automated algorithm to detect and mask blink artifacts without distorting slow-phase velocity estimation.\n\nAssume the following fundamental bases and constraints:\n\n- A discrete-time velocity estimate can be obtained from eye position $x[n]$ by the first difference definition of derivative, $v[n] \\approx \\dfrac{x[n]-x[n-1]}{\\Delta t} = f_{s}\\,\\Delta x[n]$, where $\\Delta x[n] = x[n]-x[n-1]$.\n- In VNG, a blink occludes the pupil so that pupil tracking fails, reflected as $c[n] \\rightarrow 0$, and re-acquisition upon eyelid reopening may produce a sudden jump in reported position due to re-locking to the pupil image, observed as a step in $x_{\\mathrm{VNG}}[n]$.\n- In ENG, the blink produces a large, brief, sharp transient in the corneo-retinal potential due to eyelid movement over the cornea, observed as a high-slope spike in $x_{\\mathrm{ENG}}[n]$ that exceeds physiologic eye movement slopes.\n- Physiologic constraints: typical slow-phase velocities are $\\lvert v \\rvert \\lesssim 100\\,\\mathrm{deg/s}$, saccadic peak velocities rarely exceed $\\sim 800$ to $1000\\,\\mathrm{deg/s}$, and true saccades occur over durations of $\\gtrsim 10\\,\\mathrm{ms}$; blink transients are briefer and can produce apparent slopes exceeding these ranges.\n- Noise in $v[n]$ is approximately stationary over short windows. A robust scale estimator for a zero-mean Gaussian-like distribution is the median absolute deviation (MAD) of $v[n]$, with $\\hat{\\sigma}_{v} \\approx 1.4826 \\,\\mathrm{MAD}(v)$.\n\nThe laboratory requires that the algorithm:\n\n(i) identifies blink artifacts in ENG as large, sharp transients without misclassifying physiologic saccades and slow phases,\n\n(ii) identifies blink artifacts in VNG as loss of pupil tracking and the associated step upon re-acquisition,\n\n(iii) masks contaminated samples with a small symmetric padding to include eyelid closing and reopening, and\n\n(iv) estimates slow-phase velocity by fitting on uncontaminated data only, avoiding bias from masking operations.\n\nWhich of the following automated detection and masking strategies best satisfies these requirements, grounded in the above definitions and constraints?\n\nA. Compute a discrete velocity $v_{\\mathrm{ENG}}[n] = f_{s}\\,(x_{\\mathrm{ENG}}[n]-x_{\\mathrm{ENG}}[n-1])$ and a robust scale $\\hat{\\sigma}_{v}$ over a sliding window. Flag ENG samples as blink if $\\lvert v_{\\mathrm{ENG}}[n] \\rvert > k \\,\\hat{\\sigma}_{v}$ with $k$ chosen so that $k\\,\\hat{\\sigma}_{v}$ lies well above physiologic saccade peaks but sensitive to brief spikes; additionally require that flagged suprathreshold samples occur over a duration $< \\tau_{\\max}$ to distinguish from true saccades. For VNG, mark as blink any contiguous run where $c[n] < c_{\\min}$ and also extend the blink interval to include any adjacent step in $x_{\\mathrm{VNG}}[n]$ detected by a robust step detector based on large $\\lvert \\Delta x_{\\mathrm{VNG}}[n] \\rvert$ outliers relative to a MAD-derived threshold. Merge overlapping VNG and ENG blink intervals and apply symmetric padding of $T_{\\mathrm{pre}}$ and $T_{\\mathrm{post}}$ seconds (converted to samples via $f_{s}$). Exclude masked samples from slow-phase velocity estimation and estimate slow-phase velocity using robust linear regression on unmasked segments; permit interpolation across masked intervals only for plotting, not for velocity estimation.\n\nB. Apply a low-pass finite impulse response filter with cutoff at $f_{c}$ to both $x_{\\mathrm{VNG}}[n]$ and $x_{\\mathrm{ENG}}[n]$ to remove high-frequency content from blinks. Identify blinks as any remaining peak in the filtered velocity $v[n]$ exceeding a fixed threshold, and then compute slow-phase velocity on the filtered and unmasked series to preserve continuity.\n\nC. In VNG, detect blinks by thresholding decreases in pupil diameter; in ENG, detect blinks by absolute amplitude excursions of $x_{\\mathrm{ENG}}[n]$ exceeding a fixed microvolt threshold. Replace all detected blink segments by linear interpolation to maintain continuity, and compute velocities on the interpolated series to avoid gaps.\n\nD. Treat any detected saccade with amplitude $> 20\\,\\mathrm{deg}$ as a blink to ensure blinks are not missed and delete any trial containing at least one such event; compute slow-phase velocity only from trials without deletions to avoid contamination.\n\nAnswer with the single best choice.",
            "solution": "The problem statement is evaluated for validity prior to attempting a solution.\n\n### Problem Validation\n\n**Step 1: Extract Givens**\n\n*   **Signals**: Videonystagmography (VNG) provides eye position $x_{\\mathrm{VNG}}[n]$ and pupil-confidence $c[n] \\in [0,1]$. Electronystagmography (ENG) provides eye position proxy $x_{\\mathrm{ENG}}[n]$.\n*   **Sampling**: Both signals are sampled at frequency $f_{s}$, with sampling interval $\\Delta t = 1/f_{s}$ and integer time index $n$.\n*   **Velocity Definition**: Discrete velocity is $v[n] \\approx \\dfrac{x[n]-x[n-1]}{\\Delta t} = f_{s}\\,\\Delta x[n]$, where $\\Delta x[n] = x[n]-x[n-1]$.\n*   **VNG Artifacts**: A blink causes pupil occlusion ($c[n] \\rightarrow 0$) and may produce a step in $x_{\\mathrm{VNG}}[n]$ upon re-acquisition.\n*   **ENG Artifacts**: A blink produces a large, brief, sharp transient in $x_{\\mathrm{ENG}}[n]$, appearing as a high-slope spike that exceeds physiologic eye movement slopes.\n*   **Physiologic Constraints**: Slow-phase velocity $\\lvert v \\rvert \\lesssim 100\\,\\mathrm{deg/s}$. Saccadic peak velocity is $\\sim 800$ to $1000\\,\\mathrm{deg/s}$. Saccade duration is $\\gtrsim 10\\,\\mathrm{ms}$. Blink transients are briefer and can have higher apparent slopes.\n*   **Noise Statistics**: Noise in $v[n]$ is short-term stationary. A robust scale estimate is $\\hat{\\sigma}_{v} \\approx 1.4826 \\,\\mathrm{MAD}(v)$.\n*   **Algorithm Requirements**:\n    (i) Identify ENG blink transients without misclassifying saccades.\n    (ii) Identify VNG blinks via low confidence and position steps.\n    (iii) Mask contaminated samples with padding.\n    (iv) Estimate slow-phase velocity on uncontaminated data only, avoiding bias from masking.\n\n**Step 2: Validate Using Extracted Givens**\n\nThe problem statement is analyzed against the validation criteria.\n\n*   **Scientifically Grounded**: The problem is based on established principles of otoneurology and biomedical signal processing. The descriptions of VNG and ENG operation, the characteristics of blink artifacts in each modality, and the specified physiological parameters for eye movements are all factually correct and standard in the field.\n*   **Well-Posed**: The question is clearly formulated, asking for the *best* strategy among given options to satisfy a well-defined set of four requirements. The problem provides sufficient information to make this judgment.\n*   **Objective**: The language is precise and quantitative. The terms used (e.g., MAD, robust linear regression, first difference) are standard and unambiguous.\n*   **Consistency and Completeness**: The provided information is internally consistent. For example, the distinction between the brief, high-slope nature of an ENG blink spike and the longer duration of a physiological saccade is a key piece of information that a valid algorithm must use. The setup is complete for the task of evaluating the proposed strategies.\n\n**Step 3: Verdict and Action**\n\nThe problem statement is **valid**. It is scientifically sound, well-posed, objective, and provides a clear and consistent set of constraints and goals. The solution phase will now proceed.\n\n### Solution Derivation and Option Evaluation\n\nThe optimal strategy must satisfy all four requirements laid out in the problem statement, leveraging the distinct characteristics of blink artifacts in VNG and ENG recordings.\n\n**Requirement (i)** is to detect the large, sharp transients of ENG blinks while distinguishing them from physiological saccades. The problem states that blink transients are briefer and can have higher slopes than saccades. This necessitates a detection method sensitive to very high velocity spikes and that also considers the duration of the event. A fixed velocity threshold is fragile because noise levels can vary. A robust, adaptive threshold based on the signal's own statistics, such as the median absolute deviation (MAD), is superior. Therefore, a method combining a MAD-based velocity threshold with a duration check is ideal.\n\n**Requirement (ii)** is to detect VNG blinks, defined by pupil tracking failure ($c[n] \\rightarrow 0$) and potential position steps upon signal re-acquisition. The strategy must therefore monitor the confidence signal $c[n]$ for drops below a threshold and also detect large, sudden changes in the position signal $x_{\\mathrm{VNG}}[n]$.\n\n**Requirement (iii)** is to mask the full blink artifact. Blinks are not instantaneous events; they involve eyelid closing and opening. Therefore, once a blink is detected, the mask should be extended forwards and backwards in time by a small padding interval to ensure the entire contaminated segment is removed. Combining evidence from both VNG and ENG makes the detection more reliable.\n\n**Requirement (iv)** is to estimate slow-phase velocity (SPV) without bias from the artifacts or the masking procedure. SPV is the slope of the eye position trace during the slow phase of nystagmus. Calculating velocity from data that has been artificially generated (e.g., via linear interpolation) will introduce a constant velocity segment, which severely biases the SPV estimate. The correct procedure is to perform a fit (e.g., robust linear regression) *only* on the raw data samples that have been identified as uncontaminated.\n\nWith these principles established, we evaluate each option.\n\n**Option A Analysis**\n*   **ENG Detection**: This option proposes computing $v_{\\mathrm{ENG}}[n]$ and flagging samples where $\\lvert v_{\\mathrm{ENG}}[n] \\rvert > k \\,\\hat{\\sigma}_{v}$. Using the robust scale estimate $\\hat{\\sigma}_{v}$ based on MAD makes the threshold adaptive and resilient to outliers, which is excellent. Crucially, it adds a duration constraint ($\\tau_{\\max}$) to distinguish brief blink spikes from longer saccades. This directly and effectively satisfies **Requirement (i)**.\n*   **VNG Detection**: It proposes flagging segments where $c[n] < c_{\\min}$ and also detecting adjacent steps in $x_{\\mathrm{VNG}}[n]$ using a robust, MAD-based method. This correctly uses the two key indicators of VNG blinks described in the problem statement, fulfilling **Requirement (ii)**.\n*   **Masking**: It suggests merging blink intervals from both VNG and ENG and applying symmetric padding ($T_{\\mathrm{pre}}$, $T_{\\mathrm{post}}$). This leverages all available information for robust detection and correctly accounts for the finite duration of a blink, satisfying **Requirement (iii)**.\n*   **SPV Estimation**: It explicitly states to exclude masked samples and use robust linear regression on the remaining unmasked segments. It correctly forbids using interpolated data for velocity estimation, thereby preventing bias. This perfectly satisfies **Requirement (iv)**.\n\nThis strategy is comprehensive and methodologically sound, addressing all requirements with appropriate techniques.\n**Verdict: Correct**\n\n**Option B Analysis**\nThis option proposes a low-pass filter as the primary tool. A low-pass filter is designed to remove high-frequency content. Blink artifacts in ENG are described as \"brief, sharp transient[s]\" with \"high-slope,\" which are high-frequency events. Applying a low-pass filter will smear and attenuate the very features that make a blink detectable, making it *more difficult* to distinguish from physiological signals. This violates the principle behind **Requirement (i)**. Furthermore, if velocity is computed on the filtered signal where the blink artifact is now smeared but not removed, the resulting SPV estimate will be biased, violating **Requirement (iv)**.\n**Verdict: Incorrect**\n\n**Option C Analysis**\n*   **VNG Detection**: It proposes thresholding pupil diameter. The problem states tracking *confidence* $c[n]$ drops to zero, which is a more direct and reliable indicator of pupil occlusion than a change in measured diameter that may or may not be reported accurately just before occlusion.\n*   **ENG Detection**: It proposes thresholding the absolute amplitude of $x_{\\mathrm{ENG}}[n]$. This is a fundamentally flawed method. The absolute position of the eye is irrelevant to the blink artifact; the artifact is a transient *superimposed* on any position. This method would fail to detect blinks near the center of the oculomotor range and could falsely flag large-amplitude, slow movements. It fails to detect the \"high-slope spike\" characteristic and thus fails **Requirement (i)**.\n*   **SPV Estimation**: It proposes replacing blink segments with linear interpolation and computing velocities on this modified series. This is a critical error. The derivative of a linearly interpolated segment is a constant, which introduces a significant and artificial bias into the velocity signal and any subsequent SPV analysis. This directly violates **Requirement (iv)**.\n**Verdict: Incorrect**\n\n**Option D Analysis**\nThis option proposes treating any saccade with amplitude $> 20\\,\\mathrm{deg}$ as a blink. This conflates a normal physiological event (a large saccade, i.e., the fast phase of nystagmus) with a non-physiological artifact (a blink). This fundamentally violates **Requirement (i)**, which is to distinguish blinks from physiological movements. The proposed action of deleting the entire trial is excessively destructive and would likely result in the rejection of most valid clinical data, as caloric nystagmus routinely contains fast phases of this magnitude.\n**Verdict: Incorrect**\n\n**Conclusion**\nOption A proposes a sophisticated and correct algorithm that is fully consistent with the principles of signal processing and the specific phenomenological details provided in the problem statement. It uses robust statistical methods, combines information from multiple modalities, correctly distinguishes artifacts from physiological signals, and avoids introducing bias in the final estimation. The other options contain fundamental methodological flaws.",
            "answer": "$$\\boxed{A}$$"
        },
        {
            "introduction": "Beyond physiological artifacts, instrumental errors like goggle slippage can introduce significant bias into VNG recordings. This advanced problem demonstrates a modern solution using sensor fusion, where data from inertial measurement units (IMUs) is combined with camera data to correct for goggle motion . By applying the principles of rigid-body kinematics, you will learn to calculate the true eye-in-head velocity, isolating it from the contaminating effects of equipment movement.",
            "id": "5085355",
            "problem": "A patient undergoes Videonystagmography (VNG) during caloric testing. The test uses infrared camera goggles mounted on the face to track the pupil and infer ocular rotation relative to the goggle. An integrated inertial measurement unit (IMU) is embedded in the goggle, and a second IMU is secured rigidly to the mastoid to track head motion. The clinical goal is to estimate the eye’s angular velocity relative to the head, rather than relative to the goggle, and thereby remove artifact from goggle slippage. Assume axes are aligned so that yaw is the only significant component and the rightward yaw direction is positive. The following instantaneous measurements are obtained at one time point:\n- VNG camera-derived eye yaw angular velocity relative to the goggle, $\\,\\omega_{EG}\\,$, equals $12$ deg/s to the right.\n- Goggle IMU yaw angular velocity relative to an inertial frame (space), $\\,\\omega_{GS}\\,$, equals $-3$ deg/s (leftward).\n- Head IMU yaw angular velocity relative to space, $\\,\\omega_{HS}\\,$, equals $-5$ deg/s (leftward).\n\nFundamental bases you may use include:\n- The measurement model of VNG: pupil tracking yields eye rotation relative to the camera-goggle, i.e., $\\,\\omega_{EG}\\,$.\n- Rigid-body angular velocity composition: for bodies $X$, $Y$, and $Z$, relative angular velocities satisfy $\\,\\omega_{XY} = \\omega_{XZ} - \\omega_{YZ}\\,$.\n- Electronystagmography (ENG) electrodes measure corneo-retinal potential relative to the head and are not affected by goggle slippage, but VNG is.\n\nAnalyze how goggle motion relative to the head introduces false eye movement signals in VNG and choose the option that correctly:\n1) expresses the relationship needed to compute the eye’s angular velocity relative to the head from the available measurements, \n2) explains why goggle motion contaminates the VNG signal, and \n3) gives the corrected slow-phase velocity at this instant.\n\nA. The eye’s yaw angular velocity relative to the head is $\\,\\omega_{EH} = \\omega_{EG} + (\\omega_{GS} - \\omega_{HS})\\,$, because goggle-head relative rotation $\\,\\omega_{GH}\\,$ adds to the eye-goggle relative motion to produce eye-head motion. Goggle slippage makes $\\,\\omega_{GH} \\neq 0\\,$, so the camera’s $\\,\\omega_{EG}\\,$ is biased. Using the given values, the corrected slow-phase velocity is $\\,12 + (-3 - (-5)) = 14\\,$ deg/s to the right, after expressing all rates in a common axis and compensating IMU biases.\n\nB. The eye’s yaw angular velocity relative to the head is $\\,\\omega_{EH} = \\omega_{EG} - \\omega_{GS} - \\omega_{HS}\\,$, because both IMU rates should be subtracted from the video rate to remove motion. This yields $\\,12 - (-3) - (-5) = 20\\,$ deg/s to the right.\n\nC. The eye’s yaw angular velocity relative to the head is $\\,\\omega_{EH} = \\omega_{EG} - \\omega_{HS}\\,$, because head motion alone corrupts the camera measurement. This yields $\\,12 - (-5) = 17\\,$ deg/s to the right.\n\nD. Goggle motion does not significantly affect VNG because translational accelerations dominate; thus the best estimate is to ignore IMUs and take the camera rate, $\\,\\omega_{EH} \\approx \\omega_{EG} = 12\\,$ deg/s to the right.\n\nE. The eye’s yaw angular velocity relative to the head is $\\,\\omega_{EH} = \\omega_{EG} + \\omega_{GS} + \\omega_{HS}\\,$, because all rotation sources add. This yields $\\,12 + (-3) + (-5) = 4\\,$ deg/s to the right.",
            "solution": "Begin with the definitions of the measured quantities and the rigid-body kinematic relations. The videonystagmography camera yields the eye’s angular velocity relative to the goggle, $\\,\\omega_{EG}\\,$. The inertial measurement units provide angular velocities of the goggle and head with respect to space, $\\,\\omega_{GS}\\,$ and $\\,\\omega_{HS}\\,$, respectively. The desired quantity is the eye’s angular velocity relative to the head, $\\,\\omega_{EH}\\,$.\n\nThe fundamental rigid-body angular velocity composition rule states that for bodies $X$, $Y$, and $Z$,\n$$\n\\omega_{XY} = \\omega_{XZ} - \\omega_{YZ}.\n$$\nSetting $X=G$, $Y=H$, $Z=S$ (space), gives the goggle’s angular velocity relative to the head:\n$$\n\\omega_{GH} = \\omega_{GS} - \\omega_{HS}.\n$$\nSimilarly, setting $X=E$, $Y=H$, $Z=G$ gives the eye’s angular velocity relative to the head in terms of eye relative to goggle and goggle relative to head:\n$$\n\\omega_{EH} = \\omega_{EG} + \\omega_{GH}.\n$$\nCombining these two results yields:\n$$\n\\omega_{EH} = \\omega_{EG} + (\\omega_{GS} - \\omega_{HS}).\n$$\n\nThis relation captures exactly how goggle motion relative to the head introduces false eye movement signals in VNG: the VNG camera tracks the pupil in the goggle frame, so any nonzero goggle-head angular velocity $\\,\\omega_{GH}\\,$ is indistinguishable from true ocular rotation unless corrected. If the goggle slips relative to the head, $\\,\\omega_{GH} \\neq 0\\,$, and the video-derived $\\,\\omega_{EG}\\,$ is biased with an artifact equal to $\\,\\omega_{GH}\\,$. By measuring both $\\,\\omega_{GS}\\,$ and $\\,\\omega_{HS}\\,$ with IMUs and differencing them, one recovers $\\,\\omega_{GH}\\,$ and can add it to $\\,\\omega_{EG}\\,$ to obtain $\\,\\omega_{EH}\\,$. In practice, rates must be expressed in a common coordinate frame, IMU biases and scale factors should be estimated (e.g., via calibration during a brief period of steady gaze and stationary head), and sampling rates should be synchronized or appropriately resampled.\n\nNumerically, for the given values:\n$$\n\\omega_{GH} = \\omega_{GS} - \\omega_{HS} = -3 - (-5) = +2 \\,\\, \\text{deg/s (rightward)},\n$$\nand hence\n$$\n\\omega_{EH} = \\omega_{EG} + \\omega_{GH} = 12 + 2 = 14 \\,\\, \\text{deg/s (rightward)}.\n$$\n\nOption-by-option analysis:\n- Option A: Uses the correct kinematic composition $\\,\\omega_{EH} = \\omega_{EG} + (\\omega_{GS} - \\omega_{HS})\\,$ derived from first principles. It correctly interprets goggle slippage as $\\,\\omega_{GH}\\,$ and produces the correct numerical result of $\\,14\\,$ deg/s to the right, with appropriate notes on axis alignment and bias handling. Verdict — Correct.\n\n- Option B: Proposes $\\,\\omega_{EH} = \\omega_{EG} - \\omega_{GS} - \\omega_{HS}\\,$. This incorrectly treats both IMU rates as artifacts to subtract, which violates the composition $\\,\\omega_{GH} = \\omega_{GS} - \\omega_{HS}\\,$ and yields the wrong sign structure. The numerical result $\\,20\\,$ deg/s is inconsistent with the correct derivation. Verdict — Incorrect.\n\n- Option C: Uses only the head IMU: $\\,\\omega_{EH} = \\omega_{EG} - \\omega_{HS}\\,$. This ignores goggle motion and confounds head rotation in space with goggle-head slippage; it cannot isolate $\\,\\omega_{GH}\\,$ unless $\\,\\omega_{GS} \\approx \\omega_{HS}\\,$, which is not guaranteed during slippage. The numerical result $\\,17\\,$ deg/s is therefore incorrect for the stated measurements. Verdict — Incorrect.\n\n- Option D: Asserts that translational accelerations dominate and that goggle motion is negligible, recommending $\\,\\omega_{EH} \\approx \\omega_{EG}\\,$. This contradicts the given nonzero $\\,\\omega_{GS} - \\omega_{HS}\\,$ and the rigid-body rotational contamination mechanism; moreover, VNG’s pupil tracking is primarily sensitive to rotational motion, not translation. The $\\,12\\,$ deg/s estimate is biased. Verdict — Incorrect.\n\n- Option E: Proposes $\\,\\omega_{EH} = \\omega_{EG} + \\omega_{GS} + \\omega_{HS}\\,$, which incorrectly adds both IMU rates and violates the derived relative velocity relation. The numerical result $\\,4\\,$ deg/s is inconsistent with the correct kinematics. Verdict — Incorrect.",
            "answer": "$$\\boxed{A}$$"
        }
    ]
}