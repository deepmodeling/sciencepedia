{
    "hands_on_practices": [
        {
            "introduction": "A crucial first step in studying intra-tumor heterogeneity is designing an experiment with enough statistical power to detect rare cell populations that may drive cancer progression. This exercise guides you through a sample size calculation, grounding the abstract goal of detection in concrete statistical principles. By incorporating realistic experimental factors like doublet rates ($d$) and assay sensitivity ($s$), you will learn to determine the minimum number of cells required to identify a subclone with high confidence .",
            "id": "4381140",
            "problem": "You are designing a single-cell DNA sequencing (scDNA-seq) experiment to detect an intra-tumor subclone present at frequency $f$ among tumor cells. Cells are captured into libraries in droplets that yield either singlets with probability $1 - d$ or doublets with probability $d$, where $d$ is the doublet rate. A subclone cell, if present in a capture, is correctly genotyped with assay sensitivity $s$ (that is, the probability of correctly calling the subclone in that capture is $s$ for each subclone cell). Assume independent, identically distributed captures and that cells are sampled uniformly at random from the tumor cell population, with negligible non-tumor contamination.\n\nStarting only from the definition of Bernoulli trials, the binomial model for independent trials, and the rule that the probability of at least one success in $n$ trials equals one minus the probability of zero successes, derive the minimal number of captured single-cell libraries $n$ such that the probability of detecting the subclone at least once is strictly greater than $0.99$. Use the following scientifically realistic parameters: $f = 0.005$, $d = 0.20$, and $s = 0.90$. Report your result as the minimal integer $n$ that satisfies the condition. No units are required.",
            "solution": "The user wants to find the minimal number of captured single-cell libraries, $n$, required to ensure the probability of detecting a subclone at least once is strictly greater than $0.99$.\n\n### Step 1: Extract Givens\n- Subclone frequency: $f = 0.005$\n- Doublet rate: $d = 0.20$\n- Probability of a singlet: $1 - d = 0.80$\n- Assay sensitivity for a subclone cell: $s = 0.90$\n- Number of captured single-cell libraries: $n$\n- Target probability of detection: $P(\\text{detection}) > 0.99$\n- Assumptions: Independent and identically distributed captures; uniform random sampling of cells.\n\n### Step 2: Validate Using Extracted Givens\nThe problem is scientifically grounded in the field of single-cell genomics, using standard terminology and realistic parameters. It is a well-posed statistical problem that asks for a minimum integer satisfying a probability-based inequality. The problem is self-contained, objective, and does not violate any scientific or mathematical principles. Therefore, the problem is valid.\n\n### Step 3: Proceed to Solution\n\nLet $E$ be the event that the subclone is detected at least once in $n$ independent library captures. The problem asks for the minimum integer $n$ such that $P(E) > 0.99$.\n\nAs the captures are independent and identically distributed, we can model this process as $n$ Bernoulli trials. The problem requires us to use the complement rule, which states that the probability of at least one success is equal to one minus the probability of zero successes.\nLet $p_{succ}$ be the probability of detecting the subclone in a single library capture. Then the probability of failing to detect the subclone in a single capture is $p_{fail} = 1 - p_{succ}$.\nThe probability of failing to detect the subclone in all $n$ independent captures is $(p_{fail})^n$.\nTherefore, the probability of at least one detection is:\n$$P(E) = 1 - (p_{fail})^n$$\nWe are given the condition $P(E) > 0.99$.\n$$1 - (p_{fail})^n > 0.99$$\n$$(p_{fail})^n < 0.01$$\nTaking the natural logarithm of both sides:\n$$n \\ln(p_{fail}) < \\ln(0.01)$$\nSince $p_{fail}$ is a probability strictly between $0$ and $1$, its logarithm, $\\ln(p_{fail})$, is negative. Dividing by a negative number reverses the inequality:\n$$n > \\frac{\\ln(0.01)}{\\ln(p_{fail})}$$\n\nThe next step is to derive the expression for $p_{fail}$. A captured library can be either a singlet or a doublet. Let $S$ be the event that a library is a singlet, and $T$ be the event that it is a doublet. We are given $P(S) = 1-d$ and $P(T) = d$.\nUsing the law of total probability, the probability of failure is:\n$$p_{fail} = P(\\text{fail}|\\text{S})P(S) + P(\\text{fail}|\\text{T})P(T)$$\n\nFirst, we determine the probability of failure for a single, randomly sampled cell. A detection event for a cell occurs if and only if the cell is from the subclone (probability $f$) and it is correctly genotyped (probability $s$). The probability of a successful detection from one random cell is thus $f \\times s$.\nThe probability of failure for a single random cell (i.e., this cell does not lead to a detection) is $1 - fs$. This failure can happen in two ways: either the cell is not a subclone cell (with probability $1-f$), or it is a subclone cell but the assay fails to detect it (with probability $f(1-s)$). The total probability of no detection from a single cell is $(1-f) + f(1-s) = 1 - f + f - fs = 1 - fs$.\n\nNow we can calculate the conditional probabilities of failure for singlets and doublets.\n1.  For a singlet library (event $S$): It contains one cell. The library fails to yield a detection if that one cell fails to yield a detection.\n    $$P(\\text{fail}|\\text{S}) = 1 - fs$$\n2.  For a doublet library (event $T$): It contains two independently sampled cells. The library fails to yield a detection only if *both* cells fail to yield a detection. Since the cells are independent, the probability of this is:\n    $$P(\\text{fail}|\\text{T}) = (1 - fs) \\times (1 - fs) = (1 - fs)^2$$\n\nNow, substitute these back into the expression for $p_{fail}$:\n$$p_{fail} = (1 - fs)(1 - d) + (1 - fs)^2 d$$\nWe can factor out a $(1 - fs)$ term:\n$$p_{fail} = (1 - fs) [ (1 - d) + d(1 - fs) ]$$\n$$p_{fail} = (1 - fs) [ 1 - d + d - dfs ]$$\n$$p_{fail} = (1 - fs)(1 - dfs)$$\n\nWe are given the parameter values: $f = 0.005$, $s = 0.90$, and $d = 0.20$.\nFirst, calculate the product $fs$:\n$$fs = 0.005 \\times 0.90 = 0.0045$$\nNext, calculate the product $dfs$:\n$$dfs = 0.20 \\times 0.0045 = 0.0009$$\nNow we can calculate $p_{fail}$:\n$$p_{fail} = (1 - 0.0045)(1 - 0.0009) = (0.9955)(0.9991) = 0.99460445$$\n\nFinally, we substitute this value into the inequality for $n$:\n$$n > \\frac{\\ln(0.01)}{\\ln(0.99460445)}$$\nUsing the values of the natural logarithms:\n$$\\ln(0.01) \\approx -4.605170$$\n$$\\ln(0.99460445) \\approx -0.00540966$$\n$$n > \\frac{-4.605170}{-0.00540966} \\approx 851.285$$\nSince $n$ must be strictly greater than $851.285$ and must be an integer, the minimal number of captured libraries required is $852$.",
            "answer": "$$\\boxed{852}$$"
        },
        {
            "introduction": "Once single-cell genotypes are obtained, a primary goal is to reconstruct the tumor's evolutionary tree. This practice explores the perfect phylogeny model, a key assumption that simplifies this task, and its practical application through the four-gamete test. You will analyze a hypothetical dataset to identify violations of this model and reason about their likely sources, such as Allelic Dropout (ADO) or doublets, developing essential skills for data quality control and interpretation .",
            "id": "4381080",
            "problem": "Consider a binary genotype matrix from Single-Cell DNA sequencing assaying four Single-Nucleotide Variants (SNVs) $(s_1,s_2,s_3,s_4)$ across nine cells $(c_1,\\dots,c_9)$. Each cell’s genotype vector $\\mathbf{g}(c_i)$ lists the presence $(1)$ or absence $(0)$ of each SNV in the fixed order $(s_1,s_2,s_3,s_4)$. The observed genotypes are:\n$\\mathbf{g}(c_1)=(0,0,0,0)$,\n$\\mathbf{g}(c_2)=(1,0,0,0)$,\n$\\mathbf{g}(c_3)=(1,1,0,0)$,\n$\\mathbf{g}(c_4)=(1,0,1,0)$,\n$\\mathbf{g}(c_5)=(1,1,0,1)$,\n$\\mathbf{g}(c_6)=(1,0,0,1)$,\n$\\mathbf{g}(c_7)=(0,0,0,1)$,\n$\\mathbf{g}(c_8)=(1,1,1,0)$,\n$\\mathbf{g}(c_9)=(0,1,0,0)$.\n\nAssume the Infinite Sites Model (ISM), which states each SNV arises at most once in the tumor phylogeny and never reverts. Under the ISM, the perfect phylogeny constraint implies that for any pair of SNVs $(s_i,s_j)$, the distribution of two-locus haplotypes across cells cannot contain all four combinations $(00,01,10,11)$; this is commonly tested by the four-gamete test.\n\nSingle-cell assays are subject to errors including Allelic Dropout (ADO; false negatives turning $1 \\to 0$), False Positives (FP; false positives turning $0 \\to 1$), and doublets (two cells captured together producing an elementwise logical OR of their true genotypes). Copy Number Variation (CNV) can also perturb genotypes but is not directly modeled here.\n\nTasks:\n- Starting from the ISM and the definition of the four-gamete test, determine the number $V$ of SNV pairs among the $\\binom{4}{2}=6$ possible pairs whose observed two-locus haplotype distributions across $(c_1,\\dots,c_9)$ contain all four gametes $(00,01,10,11)$, thereby violating perfect phylogeny.\n- In your derivation, identify any cell whose genotype is exactly the elementwise logical OR of two other cells’ genotypes and explain how such a configuration can introduce an $(11)$ haplotype for an otherwise incompatible pair, consistent with a doublet. Also, use first-principles reasoning to discuss whether the remaining violations are more parsimoniously explained by Allelic Dropout (ADO), False Positives (FP), or Copy Number Variation (CNV).\n\nReport the exact integer value of $V$ with no rounding and no units.",
            "solution": "We begin from the Infinite Sites Model (ISM), which posits that each Single-Nucleotide Variant (SNV) occurs at most once without back-mutation. Under the ISM, a perfect phylogeny exists if and only if, for every pair of binary characters (here, SNVs), the observed two-locus haplotypes across sampled cells do not contain all four combinations $(00,01,10,11)$. This is formalized by the four-gamete test: the presence of all four gametes for any pair indicates a violation of perfect phylogeny consistency with the ISM.\n\nWe have four SNVs $(s_1,s_2,s_3,s_4)$ and nine cells $(c_1,\\dots,c_9)$ with genotypes:\n$\\mathbf{g}(c_1)=(0,0,0,0)$,\n$\\mathbf{g}(c_2)=(1,0,0,0)$,\n$\\mathbf{g}(c_3)=(1,1,0,0)$,\n$\\mathbf{g}(c_4)=(1,0,1,0)$,\n$\\mathbf{g}(c_5)=(1,1,0,1)$,\n$\\mathbf{g}(c_6)=(1,0,0,1)$,\n$\\mathbf{g}(c_7)=(0,0,0,1)$,\n$\\mathbf{g}(c_8)=(1,1,1,0)$,\n$\\mathbf{g}(c_9)=(0,1,0,0)$.\n\nWe examine each of the $\\binom{4}{2}=6$ SNV pairs and compile the set of observed two-locus haplotypes across the nine cells. A pair violates perfect phylogeny if and only if the set includes all four gametes $(00,01,10,11)$.\n\nCompute gametes for each pair:\n\n1. Pair $(s_1,s_2)$: extract $(s_1,s_2)$ from each cell.\n- $c_1:(0,0)$,\n- $c_2:(1,0)$,\n- $c_3:(1,1)$,\n- $c_4:(1,0)$,\n- $c_5:(1,1)$,\n- $c_6:(1,0)$,\n- $c_7:(0,0)$,\n- $c_8:(1,1)$,\n- $c_9:(0,1)$.\nObserved set is $\\{(0,0),(1,0),(1,1),(0,1)\\}$, i.e., all four gametes. Thus $(s_1,s_2)$ violates the four-gamete test.\n\n2. Pair $(s_1,s_3)$:\n- $c_1:(0,0)$,\n- $c_2:(1,0)$,\n- $c_3:(1,0)$,\n- $c_4:(1,1)$,\n- $c_5:(1,0)$,\n- $c_6:(1,0)$,\n- $c_7:(0,0)$,\n- $c_8:(1,1)$,\n- $c_9:(0,0)$.\nObserved set is $\\{(0,0),(1,0),(1,1)\\}$. The gamete $(0,1)$ is absent. This pair is compatible and does not violate perfect phylogeny.\n\n3. Pair $(s_1,s_4)$:\n- $c_1:(0,0)$,\n- $c_2:(1,0)$,\n- $c_3:(1,0)$,\n- $c_4:(1,0)$,\n- $c_5:(1,1)$,\n- $c_6:(1,1)$,\n- $c_7:(0,1)$,\n- $c_8:(1,0)$,\n- $c_9:(0,0)$.\nObserved set is $\\{(0,0),(1,0),(1,1),(0,1)\\}$, i.e., all four gametes. Thus $(s_1,s_4)$ violates the four-gamete test.\n\n4. Pair $(s_2,s_3)$:\n- $c_1:(0,0)$,\n- $c_2:(0,0)$,\n- $c_3:(1,0)$,\n- $c_4:(0,1)$,\n- $c_5:(1,0)$,\n- $c_6:(0,0)$,\n- $c_7:(0,0)$,\n- $c_8:(1,1)$,\n- $c_9:(1,0)$.\nObserved set is $\\{(0,0),(1,0),(0,1),(1,1)\\}$, i.e., all four gametes. Thus $(s_2,s_3)$ violates the four-gamete test.\n\n5. Pair $(s_2,s_4)$:\n- $c_1:(0,0)$,\n- $c_2:(0,0)$,\n- $c_3:(1,0)$,\n- $c_4:(0,0)$,\n- $c_5:(1,1)$,\n- $c_6:(0,1)$,\n- $c_7:(0,1)$,\n- $c_8:(1,0)$,\n- $c_9:(1,0)$.\nObserved set is $\\{(0,0),(1,0),(0,1),(1,1)\\}$, i.e., all four gametes. Thus $(s_2,s_4)$ violates the four-gamete test.\n\n6. Pair $(s_3,s_4)$:\n- $c_1:(0,0)$,\n- $c_2:(0,0)$,\n- $c_3:(0,0)$,\n- $c_4:(1,0)$,\n- $c_5:(0,1)$,\n- $c_6:(0,1)$,\n- $c_7:(0,1)$,\n- $c_8:(1,0)$,\n- $c_9:(0,0)$.\nObserved set is $\\{(0,0),(1,0),(0,1)\\}$. The gamete $(1,1)$ is absent. This pair is compatible and does not violate perfect phylogeny.\n\nCounting violations, the pairs $(s_1,s_2)$, $(s_1,s_4)$, $(s_2,s_3)$, and $(s_2,s_4)$ violate the four-gamete test. Therefore, the number of violating pairs is\n$$\nV=4.\n$$\n\nDiagnosis of likely sources of violations:\n- Doublet identification via logical OR: A doublet, under elementwise logical OR, can introduce the $(1,1)$ gamete for a pair that otherwise would not exhibit it under a perfect phylogeny. Inspect $\\mathbf{g}(c_8)=(1,1,1,0)$. Note that\n$$\n\\mathbf{g}(c_8)=\\mathbf{g}(c_3)\\,\\text{OR}\\,\\mathbf{g}(c_4)=(1,1,0,0)\\,\\text{OR}\\,(1,0,1,0)=(1,1,1,0),\n$$\nexactly. This is parsimoniously explained by a doublet comprising one cell from the $(s_2)$ branch and one from the $(s_3)$ branch. Its presence introduces the $(1,1)$ haplotype for $(s_2,s_3)$, contributing directly to the four-gamete violation observed for $(s_2,s_3)$.\n- Allelic Dropout (ADO; false negatives $1 \\to 0$): Cells $\\mathbf{g}(c_9)=(0,1,0,0)$ and $\\mathbf{g}(c_6)=(1,0,0,1)$ can be parsimoniously attributed to dropout events relative to nearby genotypes with additional $1$s. For instance, $\\mathbf{g}(c_9)$ is consistent with dropping $s_1$ in $\\mathbf{g}(c_3)$, yielding the $(0,1)$ gamete for $(s_1,s_2)$ and completing the four-gamete set for that pair. Similarly, $\\mathbf{g}(c_6)$ is consistent with dropping $s_2$ from $\\mathbf{g}(c_5)$, yielding the $(0,1)$ haplotype for $(s_2,s_4)$.\n- False Positives (FP; $0 \\to 1$): $\\mathbf{g}(c_7)=(0,0,0,1)$ is plausibly explained by a false positive at $s_4$ on an otherwise ancestral background, providing the $(0,1)$ gamete for $(s_1,s_4)$ and helping complete the four-gamete set for that pair.\n- Copy Number Variation (CNV): While CNV can generate complex genotype patterns, the specific signatures here (exact logical OR equalities and isolated single-locus gains or losses) are more parsimoniously attributable to doublets (for $\\mathbf{g}(c_8)$) and single-locus ADO/FP (for $\\mathbf{g}(c_6)$, $\\mathbf{g}(c_7)$, and $\\mathbf{g}(c_9)$), without requiring CNV-induced multi-locus changes.\n\nIn summary, applying the four-gamete test yields $V=4$ violating pairs, with at least one violation strongly attributable to a doublet (via $\\mathbf{g}(c_8)$) and others consistent with Allelic Dropout and False Positives.",
            "answer": "$$\\boxed{4}$$"
        },
        {
            "introduction": "Beyond single-nucleotide variants, copy number variations (CNVs) are a critical dimension of intra-tumor heterogeneity. This exercise introduces the Hidden Markov Model (HMM), a powerful computational tool for inferring these hidden CNV states from sequential read-depth data along a chromosome. By applying the forward-backward algorithm, you will gain insight into how probabilistic models can de-noise complex genomic data to reveal underlying biological segments and quantify features like the expected number of copy number changes .",
            "id": "4381103",
            "problem": "You are given a mathematical formalization of Hidden Markov Models (HMMs) for inferring Copy Number Variation (CNV) segments in single-cell DNA sequencing data and computing posterior probabilities of copy number transitions. Consider a sequence of genomic bins per cell, where each bin has an observation corresponding to normalized read depth. We model the hidden state at bin index $t$ as a discrete copy number $s_t \\in \\{1,2,3,\\dots\\}$ and the observation at bin index $t$ as $o_t$. The HMM is defined by the following components: the initial state distribution $\\boldsymbol{\\pi}$, the state transition matrix $A$ with entries $a_{ij} = \\mathbb{P}(s_t = j \\mid s_{t-1} = i)$, and the emission likelihoods $b_t(i) = \\mathbb{P}(o_t \\mid s_t = i)$ provided per bin $t$ and state $i$. All probabilities are real numbers in the interval $[0,1]$ and the matrices are row-stochastic where appropriate.\n\nStarting from the standard HMM definitions grounded in the Markov property and Bayes' rule, use the forward-backward algorithm with scaling to compute the following quantities:\n- The forward variables $\\alpha_t(j) \\propto \\mathbb{P}(o_0, o_1, \\dots, o_t, s_t = j)$, recursively defined by\n$$\n\\alpha_0(j) = \\boldsymbol{\\pi}(j) \\, b_0(j), \\quad\n\\alpha_t(j) = b_t(j) \\sum_{i} \\alpha_{t-1}(i) \\, a_{ij} \\quad \\text{for } t \\geq 1,\n$$\nwith per-time scaling to maintain numerical stability.\n- The backward variables $\\beta_t(i) \\propto \\mathbb{P}(o_{t+1}, o_{t+2}, \\dots, o_{T-1} \\mid s_t = i)$, recursively defined by\n$$\n\\beta_{T-1}(i) = 1, \\quad\n\\beta_t(i) = \\sum_{j} a_{ij} \\, b_{t+1}(j) \\, \\beta_{t+1}(j) \\quad \\text{for } 0 \\leq t \\leq T-2,\n$$\nwith per-time scaling consistent with the forward pass.\n- The pairwise posterior (two-slice marginal) for transitions between adjacent bins,\n$$\n\\xi_t(i,j) = \\mathbb{P}(s_t = i, s_{t+1} = j \\mid o_0, o_1, \\dots, o_{T-1})\n\\propto \\alpha_t(i) \\, a_{ij} \\, b_{t+1}(j) \\, \\beta_{t+1}(j),\n$$\nnormalized so that $\\sum_{i}\\sum_{j}\\xi_t(i,j) = 1$ for each $t$.\n- The marginal posterior per bin,\n$$\n\\gamma_t(i) = \\mathbb{P}(s_t = i \\mid o_0, o_1, \\dots, o_{T-1}) \\propto \\alpha_t(i) \\, \\beta_t(i),\n$$\nnormalized so that $\\sum_{i}\\gamma_t(i) = 1$ for each $t$.\n\nDefine the expected number of copy number transitions (changes) across the sequence as\n$$\nE_{\\text{transitions}} = \\sum_{t=0}^{T-2} \\sum_{i \\neq j} \\xi_t(i,j),\n$$\nwhich is the expectation of the count of adjacent-bin state changes under the posterior. Infer CNV segments per cell by assigning at each bin $t$ the state $\\hat{s}_t = \\arg\\max_{i} \\gamma_t(i)$ and segmenting contiguous runs of identical assigned states.\n\nImplement a program that, for each test case below, computes $E_{\\text{transitions}}$ using the above definitions and algorithms. The program must also internally infer CNV segments per cell via $\\gamma_t(i)$ and $\\hat{s}_t$ as described, although only $E_{\\text{transitions}}$ is required in the output.\n\nTest Suite:\n- Test Case $1$ (general case with three states):\n    - States: copy numbers $\\{1,2,3\\}$.\n    - Initial distribution $\\boldsymbol{\\pi} = [0.1, 0.8, 0.1]$.\n    - Transition matrix\n    $$\n    A = \\begin{bmatrix}\n    0.90 & 0.08 & 0.02 \\\\\n    0.06 & 0.90 & 0.04 \\\\\n    0.03 & 0.07 & 0.90\n    \\end{bmatrix}.\n    $$\n    - Emission likelihoods per bin $t=0,1,\\dots,5$:\n    $$\n    \\begin{aligned}\n    b_0 &= [0.2, 0.7, 0.1], \\\\\n    b_1 &= [0.3, 0.6, 0.1], \\\\\n    b_2 &= [0.1, 0.4, 0.5], \\\\\n    b_3 &= [0.05, 0.35, 0.60], \\\\\n    b_4 &= [0.1, 0.5, 0.4], \\\\\n    b_5 &= [0.2, 0.7, 0.1].\n    \\end{aligned}\n    $$\n- Test Case $2$ (boundary case: single bin):\n    - States: copy numbers $\\{1,2,3\\}$.\n    - Initial distribution $\\boldsymbol{\\pi} = [0.4, 0.4, 0.2]$.\n    - Transition matrix\n    $$\n    A = \\begin{bmatrix}\n    0.85 & 0.10 & 0.05 \\\\\n    0.10 & 0.80 & 0.10 \\\\\n    0.05 & 0.10 & 0.85\n    \\end{bmatrix}.\n    $$\n    - Emission likelihoods per bin $t=0$:\n    $$\n    b_0 = [0.2, 0.5, 0.3].\n    $$\n- Test Case $3$ (uniform transitions, alternating emissions):\n    - States: copy numbers $\\{1,2,3\\}$.\n    - Initial distribution $\\boldsymbol{\\pi} = [1/3, 1/3, 1/3]$.\n    - Transition matrix\n    $$\n    A = \\begin{bmatrix}\n    1/3 & 1/3 & 1/3 \\\\\n    1/3 & 1/3 & 1/3 \\\\\n    1/3 & 1/3 & 1/3\n    \\end{bmatrix}.\n    $$\n    - Emission likelihoods per bin $t=0,1,2,3,4$:\n    $$\n    \\begin{aligned}\n    b_0 &= [0.9, 0.05, 0.05], \\\\\n    b_1 &= [0.05, 0.9, 0.05], \\\\\n    b_2 &= [0.05, 0.05, 0.9], \\\\\n    b_3 &= [0.9, 0.05, 0.05], \\\\\n    b_4 &= [0.05, 0.9, 0.05].\n    \\end{aligned}\n    $$\n- Test Case $4$ (two-state model, strong self-transitions, alternating emissions):\n    - States: copy numbers $\\{1,3\\}$.\n    - Initial distribution $\\boldsymbol{\\pi} = [0.5, 0.5]$.\n    - Transition matrix\n    $$\n    A = \\begin{bmatrix}\n    0.95 & 0.05 \\\\\n    0.05 & 0.95\n    \\end{bmatrix}.\n    $$\n    - Emission likelihoods per bin $t=0,1,2,3$:\n    $$\n    \\begin{aligned}\n    b_0 &= [0.8, 0.2], \\\\\n    b_1 &= [0.2, 0.8], \\\\\n    b_2 &= [0.8, 0.2], \\\\\n    b_3 &= [0.2, 0.8].\n    \\end{aligned}\n    $$\n\nYour program must, for each test case, compute $E_{\\text{transitions}}$ as a real number and produce a single line of output containing the results as a comma-separated list enclosed in square brackets, with each value rounded to six decimal places. For example, the output format must be exactly `[result_1,result_2,result_3,result_4]`.\nNo physical units are involved. Angles are not applicable. Percentages must not be used; all outputs are decimals. Ensure scientific realism by adhering to the HMM definitions and probability constraints. The solution must be fully self-contained and runnable without any external input or files.",
            "solution": "The problem statement is assessed to be **valid**. It presents a well-defined computational task grounded in the established mathematical framework of Hidden Markov Models (HMMs), specifically the forward-backward algorithm. All parameters, definitions, and constraints are provided, are scientifically sound, and are internally consistent. The task is to compute the expected number of state transitions for given HMM parameters, a standard quantity derived from the model's posterior probabilities.\n\nThe solution requires the implementation of the forward-backward algorithm with scaling to ensure numerical stability. The core task is to compute the pairwise posterior probabilities $\\xi_t(i,j)$ and then sum the probabilities of all state changes across the sequence.\n\nLet the number of hidden states be $N$ and the number of observations (bins) be $T$. The HMM is parameterized by the initial state distribution $\\boldsymbol{\\pi}$ (an $N$-element vector), the state transition matrix $A$ (an $N \\times N$ matrix), and the emission likelihoods $B$ (a $T \\times N$ matrix where $B_{ti} = b_t(i) = \\mathbb{P}(o_t \\mid s_t=i)$).\n\n**1. Forward Pass with Scaling**\n\nThe raw forward variables $\\alpha_t(j)$ can become vanishingly small for large $t$, leading to numerical underflow. To prevent this, a scaling procedure is employed. We define scaled forward variables $\\hat{\\alpha}_t(j)$ and scaling coefficients $c_t$.\n\nThe process begins at $t=0$:\n$$\n\\alpha_0(j) = \\boldsymbol{\\pi}(j) b_0(j)\n$$\nThe first scaling coefficient $c_0$ is the sum of these initial values, which normalizes the distribution:\n$$\nc_0 = \\sum_{j=0}^{N-1} \\alpha_0(j)\n$$\nThe scaled variable $\\hat{\\alpha}_0(j)$ is then:\n$$\n\\hat{\\alpha}_0(j) = \\frac{\\alpha_0(j)}{c_0} = \\mathbb{P}(s_0=j \\mid o_0)\n$$\nFor subsequent time steps $t=1, 2, \\dots, T-1$, the recursion proceeds by first calculating the unscaled variable and then normalizing:\n$$\n\\alpha_t(j) = b_t(j) \\sum_{i=0}^{N-1} \\hat{\\alpha}_{t-1}(i) a_{ij}\n$$\n$$\nc_t = \\sum_{j=0}^{N-1} \\alpha_t(j)\n$$\n$$\n\\hat{\\alpha}_t(j) = \\frac{\\alpha_t(j)}{c_t}\n$$\nThe scaling factor $c_t = \\mathbb{P}(o_t \\mid o_0, \\dots, o_{t-1})$ represents the conditional probability of the current observation given all past observations. The log-likelihood of the entire observation sequence is $\\log \\mathbb{P}(O) = \\sum_{t=0}^{T-1} \\log(c_t)$.\n\n**2. Backward Pass with Scaling**\n\nA consistent scaling must be applied to the backward variables $\\beta_t(i)$. We define scaled backward variables $\\hat{\\beta}_t(i)$ that are scaled by the same factors $c_t$ from the forward pass.\n\nThe recursion starts at the end of the sequence, $t=T-1$, with a base case:\n$$\n\\hat{\\beta}_{T-1}(i) = 1 \\quad \\text{for all } i \\in \\{0, \\dots, N-1\\}\n$$\nThe recursion then proceeds backward from $t=T-2$ down to $0$:\n$$\n\\hat{\\beta}_t(i) = \\frac{1}{c_{t+1}} \\sum_{j=0}^{N-1} a_{ij} b_{t+1}(j) \\hat{\\beta}_{t+1}(j)\n$$\nThis definition ensures that the product of the scaled forward and backward variables directly yields the normalized marginal posterior probability.\n\n**3. Posterior Probabilities**\n\nWith the scaled variables $\\hat{\\alpha}$ and $\\hat{\\beta}$, the key posterior probabilities can be calculated efficiently.\n\nThe marginal posterior probability of being in state $i$ at time $t$, $\\gamma_t(i) = \\mathbb{P}(s_t=i \\mid O)$, is given by the simple product:\n$$\n\\gamma_t(i) = \\hat{\\alpha}_t(i) \\hat{\\beta}_t(i)\n$$\nThis quantity is already normalized, i.e., $\\sum_i \\gamma_t(i) = 1$.\n\nThe pairwise posterior probability of a transition from state $i$ to state $j$ between time $t$ and $t+1$, $\\xi_t(i,j) = \\mathbb{P}(s_t=i, s_{t+1}=j \\mid O)$, is calculated as:\n$$\n\\xi_t(i,j) = \\frac{\\mathbb{P}(s_t=i, s_{t+1}=j, O)}{\\mathbb{P}(O)} = \\frac{\\alpha_t(i) a_{ij} b_{t+1}(j) \\beta_{t+1}(j)}{\\sum_{i'}\\sum_{j'} \\alpha_t(i') a_{i'j'} b_{t+1}(j') \\beta_{t+1}(j')}\n$$\nExpressed in terms of our scaled variables, this simplifies to:\n$$\n\\xi_t(i,j) = \\frac{\\hat{\\alpha}_t(i) a_{ij} b_{t+1}(j) \\hat{\\beta}_{t+1}(j)}{c_{t+1}}\n$$\nThis is also correctly normalized such that $\\sum_{i}\\sum_{j}\\xi_t(i,j) = 1$ for each $t$.\n\n**4. Expected Number of Transitions**\n\nThe expected number of copy number transitions, $E_{\\text{transitions}}$, is the sum of probabilities of all non-self-transitions over all adjacent time steps.\n$$\nE_{\\text{transitions}} = \\sum_{t=0}^{T-2} \\mathbb{P}(\\text{transition at } t) = \\sum_{t=0}^{T-2} \\sum_{i \\neq j} \\xi_t(i,j)\n$$\nThis can be computed as:\n$$\nE_{\\text{transitions}} = \\sum_{t=0}^{T-2} \\left( 1 - \\sum_{i=0}^{N-1} \\xi_t(i,i) \\right)\n$$\nFor a sequence of length $T=1$ (a single bin), the sum for $E_{\\text{transitions}}$ is over an empty set of indices ($t$ from $0$ to $-1$), so the result is $0$.\n\nThe implementation will follow these steps for each test case, using NumPy for efficient vectorized and matrix operations.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef calculate_E_transitions(pi, A, B):\n    \"\"\"\n    Computes the expected number of state transitions for an HMM using the\n    scaled forward-backward algorithm.\n\n    Args:\n        pi (np.array): Initial state distribution (N,).\n        A (np.array): State transition matrix (N, N).\n        B (np.array): Emission likelihoods matrix (T, N).\n\n    Returns:\n        float: The expected number of transitions.\n    \"\"\"\n    T = B.shape[0]  # Number of observations/bins\n    N = A.shape[0]  # Number of states\n\n    # For a sequence of length 1, no transitions can occur.\n    if T = 1:\n        return 0.0\n\n    # Allocate memory\n    alpha_hat = np.zeros((T, N))\n    beta_hat = np.zeros((T, N))\n    c = np.zeros(T)\n\n    # --- Forward pass (alpha) ---\n    # t = 0\n    alpha_0_unscaled = pi * B[0, :]\n    c[0] = np.sum(alpha_0_unscaled)\n    if c[0] == 0.0:\n        # If the probability of the first observation is zero under all initial states,\n        # the entire sequence has zero probability.\n        return 0.0\n    alpha_hat[0, :] = alpha_0_unscaled / c[0]\n\n    # t = 1 to T-1\n    for t in range(1, T):\n        alpha_t_unscaled = B[t, :] * (alpha_hat[t-1, :] @ A)\n        c[t] = np.sum(alpha_t_unscaled)\n        if c[t] == 0.0:\n            # Sequence has zero probability from this point onwards.\n            return 0.0\n        alpha_hat[t, :] = alpha_t_unscaled / c[t]\n        \n    # --- Backward pass (beta) ---\n    # t = T-1\n    beta_hat[T-1, :] = 1.0\n\n    # t = T-2 down to 0\n    for t in range(T - 2, -1, -1):\n        # The scaling factor c[t+1] is guaranteed to be non-zero due to the forward pass checks.\n        beta_hat[t, :] = (A @ (B[t+1, :] * beta_hat[t+1, :])) / c[t+1]\n\n    # --- Calculate total expected transitions ---\n    total_transitions = 0.0\n    for t in range(T - 1):\n        # Calculate the unnormalized pairwise posterior xi_t(i,j)\n        numerator_xi = np.outer(alpha_hat[t, :], B[t+1, :] * beta_hat[t+1, :]) * A\n        \n        # Normalize to get xi_t(i,j). The normalization constant is c[t+1].\n        xi_t = numerator_xi / c[t+1]\n        \n        # The sum of probabilities of transitions is the sum of off-diagonal elements.\n        # This is equivalent to 1 minus the sum of diagonal elements (self-transitions).\n        transitions_at_t = np.sum(xi_t) - np.sum(np.diag(xi_t))\n        total_transitions += transitions_at_t\n        \n    return total_transitions\n\ndef solve():\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # Test Case 1: general case with three states\n        (\n            np.array([0.1, 0.8, 0.1]),\n            np.array([\n                [0.90, 0.08, 0.02],\n                [0.06, 0.90, 0.04],\n                [0.03, 0.07, 0.90]\n            ]),\n            np.array([\n                [0.2, 0.7, 0.1],\n                [0.3, 0.6, 0.1],\n                [0.1, 0.4, 0.5],\n                [0.05, 0.35, 0.60],\n                [0.1, 0.5, 0.4],\n                [0.2, 0.7, 0.1]\n            ])\n        ),\n        # Test Case 2: boundary case: single bin\n        (\n            np.array([0.4, 0.4, 0.2]),\n            np.array([\n                [0.85, 0.10, 0.05],\n                [0.10, 0.80, 0.10],\n                [0.05, 0.10, 0.85]\n            ]),\n            np.array([\n                [0.2, 0.5, 0.3]\n            ])\n        ),\n        # Test Case 3: uniform transitions, alternating emissions\n        (\n            np.array([1/3, 1/3, 1/3]),\n            np.array([\n                [1/3, 1/3, 1/3],\n                [1/3, 1/3, 1/3],\n                [1/3, 1/3, 1/3]\n            ]),\n            np.array([\n                [0.9, 0.05, 0.05],\n                [0.05, 0.9, 0.05],\n                [0.05, 0.05, 0.9],\n                [0.9, 0.05, 0.05],\n                [0.05, 0.9, 0.05]\n            ])\n        ),\n        # Test Case 4: two-state model, strong self-transitions\n        (\n            np.array([0.5, 0.5]),\n            np.array([\n                [0.95, 0.05],\n                [0.05, 0.95]\n            ]),\n            np.array([\n                [0.8, 0.2],\n                [0.2, 0.8],\n                [0.8, 0.2],\n                [0.2, 0.8]\n            ])\n        )\n    ]\n    \n    results = []\n    for case in test_cases:\n        pi, A, B = case\n        result = calculate_E_transitions(pi, A, B)\n        results.append(f\"{result:.6f}\")\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(results)}]\")\n\nsolve()\n```"
        }
    ]
}