{
    "hands_on_practices": [
        {
            "introduction": "A foundational challenge in multi-omics is harmonizing data from different genomic assays onto a common set of features, such as genes. This practice guides you through the essential task of transforming segment-level Copy Number Variation (CNV) data into a gene-level dosage metric, a crucial step for integrating structural variations with gene expression. By mastering the manipulation of genomic intervals and strand-specific definitions, you will build a core competency for preparing diverse data types for integrative analysis .",
            "id": "4362440",
            "problem": "You are tasked with implementing a principled multi-omics data integration routine that transforms segment-level Copy Number Variation (CNV) into gene-level dosage while aligning genomic coordinates to gene annotations with strand awareness, and then computes a dosage-adjusted Ribonucleic Acid sequencing (RNA-seq) expression measure. Ground your approach in fundamental definitions of genomic intervals, base-pair measures, and the central dogma of molecular biology stating that Deoxyribonucleic Acid (DNA) content influences Ribonucleic Acid (RNA) abundance. The algorithm must be derived solely from these bases without using any shortcut formulas.\n\nDefinitions and assumptions:\n\n- A CNV segmentation on a chromosome is a set of non-overlapping half-open intervals $[s_i,e_i)$, each interval equipped with a unitless copy-number ratio $r_i$, representing a multiplicative change relative to diploid dosage. The coordinates $s_i$ and $e_i$ are in base pairs (bp); $r_i$ is unitless.\n\n- A gene annotation consists of a set of exonic intervals $[a_j,b_j)$, a strand indicator $d \\in \\{+1,-1\\}$ (where $+1$ denotes the forward strand and $-1$ denotes the reverse strand), and base pair coordinates. All coordinates are in base pairs (bp).\n\n- The transcription start site (TSS) is defined from the exons with strand awareness: for $d=+1$, $\\mathrm{TSS}=\\min_j a_j$, and for $d=-1$, $\\mathrm{TSS}=\\max_j b_j$.\n\n- A promoter window of length $L_p$ bp is defined upstream of the TSS in transcriptional direction: for $d=+1$, the promoter interval is $[\\max(1,\\mathrm{TSS}-L_p),\\mathrm{TSS})$, while for $d=-1$, it is $(\\mathrm{TSS},\\mathrm{TSS}+L_p]$, which in half-open convention becomes $[\\mathrm{TSS},\\mathrm{TSS}+L_p)$. The lower genomic bound is $1$ bp; truncate promoter intervals that would go below $1$ bp accordingly.\n\n- The gene body region for dosage aggregation is the union of all exonic intervals. When exons overlap, the union operation must be applied before aggregation to avoid double counting.\n\n- For any genomic interval $I$, define a function $r(x)$ that equals the CNV ratio $r_i$ on positions $x$ covered by segment $i$, and equals baseline $1$ (unitless) where $x$ is not covered by any CNV segment. The gene-level DNA dosage over an interval is the mean of $r(x)$ over the interval with respect to the counting measure on base pairs (i.e., the length-weighted average across base pairs). No closed-form shortcut should be assumed; derive this from the definition of averages and interval overlaps.\n\n- Let $w_e$ and $w_p$ be non-negative weights that sum to $1$, combining the exonic region average and the promoter region average to form the gene-level dosage $D$. The exonic average contributes with weight $w_e$, and the promoter average contributes with weight $w_p$.\n\n- Let $E$ be a strictly positive RNA-seq expression value that is already normalized to be dimensionless and comparable across genes. Assume a first-order model in which expected expression scales in proportion to DNA dosage, and define dosage-adjusted expression as $X=E/D$ (unitless).\n\nYour program must, for each provided test case, compute the gene-level dosage $D$ and then the dosage-adjusted expression $X$. All positions are in base pairs (bp). All ratios ($r_i$, $D$, $X$) and expression $E$ are dimensionless. Angles are not involved. Outputs must be floats.\n\nUse the following explicit half-open interval convention for all coordinates: $[u,v)$ denotes bp positions $x$ such that $u \\le x < v$. Overlap length between intervals $[u_1,v_1)$ and $[u_2,v_2)$ is $\\max(0,\\min(v_1,v_2)-\\max(u_1,u_2))$ in bp.\n\nTest suite specification:\n\nFor each test case, you are given CNV segments as tuples $(s_i,e_i,r_i)$, exonic intervals as tuples $(a_j,b_j)$, the strand $d$, the promoter length $L_p$, the weights $(w_e,w_p)$, and the RNA expression $E$. Compute the scalar $X=E/D$ for each case.\n\n- Test case $1$ (happy path, forward strand, multiple exons spanning CNV boundaries):\n  - CNV segments: $(1000,5000,1.2)$, $(5000,8000,0.8)$, $(12000,14000,1.1)$.\n  - Exons: $(4500,5200)$, $(7000,7500)$.\n  - Strand: $d=+1$.\n  - Promoter length: $L_p=1000$ bp.\n  - Weights: $w_e=0.7$, $w_p=0.3$.\n  - Expression: $E=8.0$.\n\n- Test case $2$ (reverse strand, promoter downstream, exon overlaps across a CNV boundary):\n  - CNV segments: $(9000,11000,1.5)$, $(11000,13000,0.7)$.\n  - Exons: $(10400,10600)$, $(10800,11200)$.\n  - Strand: $d=-1$.\n  - Promoter length: $L_p=500$ bp.\n  - Weights: $w_e=0.6$, $w_p=0.4$.\n  - Expression: $E=4.5$.\n\n- Test case $3$ (no CNV overlap anywhere, baseline applies):\n  - CNV segments: $(10000,15000,1.1)$.\n  - Exons: $(3000,3200)$, $(3500,3600)$.\n  - Strand: $d=+1$.\n  - Promoter length: $L_p=400$ bp.\n  - Weights: $w_e=0.8$, $w_p=0.2$.\n  - Expression: $E=2.0$.\n\n- Test case $4$ (promoter truncation at genomic lower bound, forward strand):\n  - CNV segments: $(1,1000,0.9)$, $(1000,2000,1.0)$.\n  - Exons: $(1500,1600)$, $(1700,1900)$.\n  - Strand: $d=+1$.\n  - Promoter length: $L_p=1000$ bp.\n  - Weights: $w_e=0.5$, $w_p=0.5$.\n  - Expression: $E=3.0$.\n\nFinal output format:\n\nYour program should produce a single line of output containing the dosage-adjusted expression results $X$ for test cases $1$ through $4$ as a comma-separated list enclosed in square brackets, in the order of the test cases (e.g., $[x_1,x_2,x_3,x_4]$). Each $x_i$ must be a float. No other text should be printed.",
            "solution": "The problem requires the implementation of a multi-omics integration algorithm to compute a dosage-adjusted gene expression value, $X$. The approach is grounded in fundamental genomic principles. The calculation proceeds in four main stages: first, identifying the relevant genomic regions (exons and promoter); second, computing the average Deoxyribonucleic Acid (DNA) dosage for each region based on Copy Number Variation (CNV) data; third, combining these regional dosages into a single gene-level dosage, $D$; and fourth, using this dosage to adjust the observed Ribonucleic Acid (RNA) expression value, $E$. All genomic coordinates are 1-based and are treated as half-open intervals $[u, v)$, representing base pair positions $x$ such that $u \\le x < v$.\n\nFirst, we must delineate the two genomic regions of interest for dosage calculation: the gene body (comprising all exons) and the promoter region. The gene body's genomic footprint is the union of all its exonic intervals, $[a_j, b_j)$. As specified, to prevent double-counting of overlapping exonic base pairs, these intervals must first be merged into a minimal set of disjoint intervals, denoted $\\{[a'_k, b'_k)\\}$. The total length of the exonic region is $L_e = \\sum_k (b'_k - a'_k)$.\n\nThe promoter region is an interval of length $L_p$ located immediately upstream of the Transcription Start Site (TSS). The TSS's position depends on the gene's strand, $d$. For a forward-strand gene ($d=+1$), the TSS is the minimum start coordinate of all its exons, $\\mathrm{TSS} = \\min_j a_j$. The promoter is then the interval $[\\max(1, \\mathrm{TSS} - L_p), \\mathrm{TSS})$. The $\\max(1, \\dots)$ function ensures the promoter coordinate does not fall below the genomic lower bound of $1$. For a reverse-strand gene ($d=-1$), the TSS corresponds to the maximum end coordinate of its exons, $\\mathrm{TSS} = \\max_j b_j$, and transcription proceeds in the direction of decreasing coordinates. The upstream promoter region is therefore at higher coordinates, defined by the interval $[\\mathrm{TSS}, \\mathrm{TSS} + L_p)$. The length of the promoter region is $L_{pr} = L_p$, unless truncated at the genomic start.\n\nThe second stage is to compute the average DNA dosage for a given genomic region. A region $R$ is defined by a set of disjoint intervals $\\{I_k\\}_{k=1}^M$, with total length $L_R = \\sum_k \\text{length}(I_k)$. The CNV profile is given by a set of segments $\\{C_i\\}_{i=1}^N$, where each segment $C_i = [s_i, e_i)$ has an associated copy number ratio $r_i$. Any base pair position $x$ not covered by a CNV segment is assumed to have a baseline diploid ratio of $1$. The dosage at a position $x$, $r(x)$, is thus $r_i$ if $x \\in C_i$ for some $i$, and $1$ otherwise. The average dosage over region $R$, $D_R$, is the length-weighted average of $r(x)$ over all base pairs in $R$. This is derived from first principles as follows:\n$$\nD_R = \\frac{1}{L_R} \\int_{x \\in R} r(x) \\, dx\n$$\nSince $R$ is a union of disjoint intervals $I_k$, and the base pair measure is discrete, this integral becomes a sum over the lengths of intersections. For a single interval $I_k \\in R$, the total contribution to the numerator is the sum of lengths of its sub-intervals, each weighted by the corresponding CNV ratio. The length of the intersection between $I_k$ and a CNV segment $C_i$ is $\\ell_{k,i} = \\max(0, \\min(\\text{end}(I_k), e_i) - \\max(\\text{start}(I_k), s_i))$. The portion of $I_k$ not covered by any CNV segment has length $\\text{length}(I_k) - \\sum_i \\ell_{k,i}$. The integrated dosage over $I_k$ is thus:\n$$\n\\int_{I_k} r(x) \\, dx = \\left( \\text{length}(I_k) - \\sum_{i=1}^N \\ell_{k,i} \\right) \\cdot 1 + \\sum_{i=1}^N \\ell_{k,i} \\cdot r_i\n$$\nThe average dosage $D_R$ is the sum of these values over all intervals $k$ in region $R$, divided by the total length $L_R$. We apply this formula to compute the average exonic dosage, $D_{exon}$, using the merged exonic intervals for $R$, and the average promoter dosage, $D_{promoter}$, using the single promoter interval. If a region has zero length (e.g., $L_p=0$), its dosage is defined as $1$.\n\nThird, the gene-level dosage, $D$, is calculated as a weighted average of the exonic and promoter dosages:\n$$\nD = w_e \\cdot D_{exon} + w_p \\cdot D_{promoter}\n$$\nwhere $w_e$ and $w_p$ are the provided non-negative weights summing to $1$.\n\nFinally, the dosage-adjusted expression, $X$, is computed by normalizing the observed RNA expression value, $E$, by the gene-level DNA dosage, $D$. This reflects the first-order assumption that RNA abundance is proportional to the quantity of its DNA template.\n$$\nX = \\frac{E}{D}\n$$\n\nLet's apply this to Test Case 1:\n- CNV segments: $(1000, 5000, 1.2)$, $(5000, 8000, 0.8)$, $(12000, 14000, 1.1)$.\n- Exons: $(4500, 5200)$, $(7000, 7500)$. Strand $d=+1$.\n- Parameters: $L_p=1000$, $w_e=0.7$, $w_p=0.3$, $E=8.0$.\n\n1.  **Genomic Regions**:\n    - Exonic region $R_e$: The exons are disjoint, forming the set of intervals $\\{[4500, 5200), [7000, 7500)\\}$. Total length $L_e = (5200-4500) + (7500-7000) = 700 + 500 = 1200$ bp.\n    - Promoter region $R_p$: For $d=+1$, $\\mathrm{TSS} = \\min(4500, 7000) = 4500$. The promoter is $[\\max(1, 4500-1000), 4500) = [3500, 4500)$. Its length is $L_{pr} = 1000$ bp.\n\n2.  **Average Dosages**:\n    - $D_{exon}$:\n        - For interval $[4500, 5200)$: length $700$. Overlaps CNV $[1000, 5000)$ for $500$ bp (ratio $1.2$) and CNV $[5000, 8000)$ for $200$ bp (ratio $0.8$). Weighted sum: $500 \\cdot 1.2 + 200 \\cdot 0.8 = 600 + 160 = 760$.\n        - For interval $[7000, 7500)$: length $500$. Overlaps CNV $[5000, 8000)$ for $500$ bp (ratio $0.8$). Weighted sum: $500 \\cdot 0.8 = 400$.\n        - Total weighted sum for exons is $760 + 400 = 1160$. $D_{exon} = 1160 / 1200 = 29/30 \\approx 0.9667$.\n    - $D_{promoter}$:\n        - For interval $[3500, 4500)$: length $1000$. Fully overlaps CNV $[1000, 5000)$ (ratio $1.2$).\n        - Weighted sum: $1000 \\cdot 1.2 = 1200$. $D_{promoter} = 1200 / 1000 = 1.2$.\n\n3.  **Gene-Level Dosage $D$**:\n    - $D = 0.7 \\cdot (29/30) + 0.3 \\cdot 1.2 = 0.6766... + 0.36 = 1.0366...$\n\n4.  **Dosage-Adjusted Expression $X$**:\n    - $X = 8.0 / 1.0366... \\approx 7.71704$.\nThis principled, step-by-step derivation is implemented for all test cases.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to solve the multi-omics data integration problem.\n    It processes each test case to compute the dosage-adjusted expression.\n    \"\"\"\n    \n    test_cases = [\n        {\n            \"cnv_segments\": [(1000, 5000, 1.2), (5000, 8000, 0.8), (12000, 14000, 1.1)],\n            \"exons\": [(4500, 5200), (7000, 7500)],\n            \"strand\": 1,\n            \"L_p\": 1000,\n            \"weights\": (0.7, 0.3),\n            \"E\": 8.0,\n        },\n        {\n            \"cnv_segments\": [(9000, 11000, 1.5), (11000, 13000, 0.7)],\n            \"exons\": [(10400, 10600), (10800, 11200)],\n            \"strand\": -1,\n            \"L_p\": 500,\n            \"weights\": (0.6, 0.4),\n            \"E\": 4.5,\n        },\n        {\n            \"cnv_segments\": [(10000, 15000, 1.1)],\n            \"exons\": [(3000, 3200), (3500, 3600)],\n            \"strand\": 1,\n            \"L_p\": 400,\n            \"weights\": (0.8, 0.2),\n            \"E\": 2.0,\n        },\n        {\n            \"cnv_segments\": [(1, 1000, 0.9), (1000, 2000, 1.0)],\n            \"exons\": [(1500, 1600), (1700, 1900)],\n            \"strand\": 1,\n            \"L_p\": 1000,\n            \"weights\": (0.5, 0.5),\n            \"E\": 3.0,\n        },\n    ]\n\n    results = []\n    for case in test_cases:\n        result = compute_adjusted_expression(\n            case[\"cnv_segments\"],\n            case[\"exons\"],\n            case[\"strand\"],\n            case[\"L_p\"],\n            case[\"weights\"],\n            case[\"E\"],\n        )\n        results.append(result)\n\n    print(f\"[{','.join(map(str, results))}]\")\n\ndef merge_intervals(intervals):\n    \"\"\"\n    Merges overlapping or adjacent intervals.\n    Input: a list of (start, end) tuples.\n    Output: a list of merged, disjoint (start, end) tuples.\n    \"\"\"\n    if not intervals:\n        return []\n    \n    # Sort intervals by their start coordinate\n    intervals.sort(key=lambda x: x[0])\n    \n    merged = []\n    current_start, current_end = intervals[0]\n    \n    for next_start, next_end in intervals[1:]:\n        if next_start < current_end:  # Overlap or adjacency\n            current_end = max(current_end, next_end)\n        else:\n            merged.append((current_start, current_end))\n            current_start, current_end = next_start, next_end\n            \n    merged.append((current_start, current_end))\n    return merged\n\ndef calculate_average_dosage(region_intervals, cnv_segments):\n    \"\"\"\n    Calculates the length-weighted average dosage for a given genomic region.\n    The region is defined by a list of disjoint intervals.\n    \"\"\"\n    total_length = 0.0\n    total_weighted_sum = 0.0\n    \n    for reg_start, reg_end in region_intervals:\n        length = float(reg_end - reg_start)\n        if length == 0:\n            continue\n        \n        total_length += length\n        \n        # Calculate overlaps with CNV segments\n        weighted_sum_for_interval = 0.0\n        covered_length = 0.0\n        \n        for cnv_start, cnv_end, cnv_ratio in cnv_segments:\n            overlap_start = max(reg_start, cnv_start)\n            overlap_end = min(reg_end, cnv_end)\n            \n            overlap_length = float(max(0, overlap_end - overlap_start))\n            \n            if overlap_length > 0:\n                weighted_sum_for_interval += overlap_length * cnv_ratio\n                covered_length += overlap_length\n        \n        # Add contribution from baseline (ratio=1.0) regions\n        uncovered_length = length - covered_length\n        weighted_sum_for_interval += uncovered_length * 1.0\n        \n        total_weighted_sum += weighted_sum_for_interval\n\n    if total_length == 0:\n        return 1.0  # Baseline dosage if region is empty\n    \n    return total_weighted_sum / total_length\n\ndef compute_adjusted_expression(cnv_segments, exons, strand, L_p, weights, E):\n    \"\"\"\n    Computes dosage-adjusted expression for a single gene.\n    \"\"\"\n    w_e, w_p = weights\n    \n    # 1. Define Exonic Region and calculate dosage\n    merged_exons = merge_intervals(exons)\n    if not merged_exons:\n        # If no exons, TSS is undefined, and D_exon defaults to 1.\n        D_exon = 1.0\n        TSS = None # This case is not expected per problem description\n    else:\n        D_exon = calculate_average_dosage(merged_exons, cnv_segments)\n    \n        # 2. Define Promoter Region and calculate dosage\n        if strand == 1:\n            TSS = min(e[0] for e in exons)\n            promo_start = max(1, TSS - L_p)\n            promo_end = TSS\n        else: # strand == -1\n            TSS = max(e[1] for e in exons)\n            promo_start = TSS\n            promo_end = TSS + L_p\n            \n    if L_p == 0:\n        D_promoter = 1.0\n    else:\n        promoter_interval = [(promo_start, promo_end)]\n        D_promoter = calculate_average_dosage(promoter_interval, cnv_segments)\n\n    # 3. Calculate final gene-level dosage D\n    D = w_e * D_exon + w_p * D_promoter\n\n    # Handle case where D is zero to avoid division by zero, although biologically unlikely\n    if D == 0:\n        return float('inf') # Or another defined error value\n\n    # 4. Calculate dosage-adjusted expression X\n    X = E / D\n    \n    return X\n\n\nsolve()\n\n```"
        },
        {
            "introduction": "The quality and reliability of multi-omics integration are critically dependent on rigorous quality control (QC) to identify and handle anomalous samples. This exercise demonstrates how to construct a robust QC pipeline that systematically flags outliers using both Principal Component Analysis (PCA) leverage scores and robust statistical metrics. Implementing this practice will provide you with a practical framework for ensuring the integrity of your dataset before downstream modeling .",
            "id": "5033985",
            "problem": "You are tasked with constructing a quality control pipeline for multi-omics integration in translational medicine that detects outlier samples across omics using Principal Component Analysis (PCA) leverage scores and Median Absolute Deviation (MAD) thresholds applied to key quality metrics. The pipeline must be implemented as a complete, runnable program that takes no input and produces a single line of output. The program must compute outlier indices for a provided test suite.\n\nFoundational base and definitions to use:\n- Let an omics data matrix be denoted by $X \\in \\mathbb{R}^{n \\times p}$ with $n$ samples (rows) and $p$ features (columns). Each column of $X$ must be standardized to zero mean and unit variance before subsequent computations.\n- Principal Component Analysis (PCA) can be defined via the Singular Value Decomposition (SVD), $X = U \\Sigma V^\\top$, where $U \\in \\mathbb{R}^{n \\times r}$ and $V \\in \\mathbb{R}^{p \\times r}$ have orthonormal columns, $\\Sigma \\in \\mathbb{R}^{r \\times r}$ is diagonal with nonnegative singular values, and $r = \\operatorname{rank}(X)$.\n- For a chosen number of components $k$, with $k \\leq p$, define the projection onto the top-$k$ left singular subspace by $U_k \\in \\mathbb{R}^{n \\times k}$, the first $k$ columns of $U$ if $r \\geq k$, and by $U_k \\in \\mathbb{R}^{n \\times r}$ otherwise. The PCA leverage for sample $i$ is the diagonal element of the projection matrix onto this subspace, $h_i = \\sum_{j=1}^{\\min(k, r)} U_{ij}^2$.\n- The projection matrix $H_k = U_k U_k^\\top$ is symmetric and idempotent, and satisfies $\\operatorname{trace}(H_k) = \\min(k, r)$. Therefore, the mean leverage equals $\\operatorname{trace}(H_k)/n = \\min(k, r)/n$. A leverage-based outlier can be defined by comparing $h_i$ to a threshold $\\alpha \\cdot \\min(k, r)/n$, with amplification factor $\\alpha > 1$.\n- For a quality metric vector $q \\in \\mathbb{R}^n$, define $\\operatorname{median}(q)$, the median absolute deviations $d_i = |q_i - \\operatorname{median}(q)|$, $\\operatorname{MAD}(q) = \\operatorname{median}(d)$, and the robust scaled deviation $z_i = d_i / (c \\cdot \\operatorname{MAD}(q))$ with $c = 1.4826$ (the consistency constant under normality). A metric-based outlier is any $i$ for which $z_i$ exceeds a threshold $t$.\n- Integrated across omics: given $O$ omics matrices $\\{X^{(o)}\\}_{o=1}^O$, define for each sample $i$ the count of leverage exceedances across omics, $C^{\\text{lev}}_i$, and the count of metric exceedances across the provided metrics, $C^{\\text{met}}_i$. A sample $i$ is flagged as an integrated outlier if either $C^{\\text{lev}}_i \\geq \\theta$ or $C^{\\text{met}}_i \\geq \\phi$, for given integer thresholds $\\theta$ and $\\phi$.\n\nImplementation requirements:\n- Standardize each omics matrix column-wise to zero mean and unit variance; if a column has zero variance, treat its standardized values as all zeros.\n- Compute PCA leverage using the SVD-based definition above with $U_k$ and $h_i$.\n- Compute quality metric outliers using the MAD-based robust deviations. If $\\operatorname{MAD}(q) = 0$, define no outliers for that metric unless any $q_i \\neq \\operatorname{median}(q)$; under that latter condition, treat those with $q_i \\neq \\operatorname{median}(q)$ as outliers.\n- Use $0$-based indexing for reporting outlier sample indices.\n\nTest suite:\n- Test Case $1$ (general multi-omics with a clear outlier in one omic and metrics):\n    - Number of samples: $n = 6$; number of omics: $O = 3$; components $k = 2$; leverage amplification $\\alpha = 2.0$; leverage count threshold $\\theta = 1$; metric threshold $t = 3.0$; metric count threshold $\\phi = 1$.\n    - Genomics matrix $X^{(1)}$ ($6 \\times 4$):\n      $\n      \\begin{bmatrix}\n      0.5 & 1.0 & -0.3 & 0.2 \\\\\n      0.6 & 0.8 & -0.1 & 0.0 \\\\\n      0.4 & 1.1 & -0.2 & 0.1 \\\\\n      0.5 & 0.9 & -0.3 & 0.2 \\\\\n      0.6 & 1.0 & -0.2 & 0.3 \\\\\n      0.5 & 0.95 & -0.25 & 0.15\n      \\end{bmatrix}\n      $\n    - Transcriptomics matrix $X^{(2)}$ ($6 \\times 5$):\n      $\n      \\begin{bmatrix}\n      10 & 12 & 9 & 11 & 10 \\\\\n      11 & 12 & 9 & 10 & 11 \\\\\n      10 & 11 & 10 & 11 & 10 \\\\\n      10 & 12 & 9 & 11 & 10 \\\\\n      11 & 11 & 9 & 10 & 12 \\\\\n      10 & 12 & 10 & 11 & 11\n      \\end{bmatrix}\n      $\n    - Proteomics matrix $X^{(3)}$ ($6 \\times 3$):\n      $\n      \\begin{bmatrix}\n      0 & 0 & 1 \\\\\n      0 & 0 & 1 \\\\\n      0 & 0 & 1 \\\\\n      10 & 10 & 1 \\\\\n      0 & 0 & 1 \\\\\n      0 & 0 & 1\n      \\end{bmatrix}\n      $\n    - Quality metrics:\n      - Metric $1$ (e.g., RNA quality): $[8.0,\\, 8.2,\\, 7.9,\\, 3.0,\\, 8.1,\\, 8.0]$\n      - Metric $2$ (e.g., library size): $[5{,}000{,}000,\\, 5{,}100{,}000,\\, 4{,}900{,}000,\\, 1{,}000{,}000,\\, 5{,}200{,}000,\\, 5{,}000{,}000]$\n    - Expected behavior: a single integrated outlier corresponding to the outlying proteomics sample and metrics.\n- Test Case $2$ (boundary condition: zero-variance features and no metric deviations):\n    - $n = 4$, $O = 2$, $k = 2$, $\\alpha = 2.0$, $\\theta = 1$, $t = 3.0$, $\\phi = 1$.\n    - Omics matrices $X^{(1)} = X^{(2)} = \\begin{bmatrix}1 & 2 & 3 \\\\ 1 & 2 & 3 \\\\ 1 & 2 & 3 \\\\ 1 & 2 & 3 \\end{bmatrix}$\n    - Quality metrics:\n      - Metric $1$: $[10,\\, 10,\\, 10,\\, 10]$\n      - Metric $2$: $[100,\\, 100,\\, 100,\\, 100]$\n    - Expected behavior: no integrated outliers.\n- Test Case $3$ (edge case: outliers only via metrics):\n    - $n = 5$, $O = 2$, $k = 2$, $\\alpha = 2.0$, $\\theta = 2$, $t = 3.0$, $\\phi = 2$.\n    - Omics matrices:\n      - $X^{(1)} = \\begin{bmatrix} 1 & 2 \\\\ 1 & 2 \\\\ 1.1 & 1.9 \\\\ 0.9 & 2.1 \\\\ 1 & 2 \\end{bmatrix}$\n      - $X^{(2)} = \\begin{bmatrix} 5 & 5 \\\\ 5 & 5 \\\\ 5.1 & 4.9 \\\\ 4.9 & 5.1 \\\\ 5 & 5 \\end{bmatrix}$\n    - Quality metrics:\n      - Metric $1$: $[0.1,\\, 5.0,\\, 0.2,\\, 0.1,\\, 0.0]$\n      - Metric $2$: $[100,\\, 1000,\\, 105,\\, 98,\\, 97]$\n    - Expected behavior: a single integrated outlier via metrics (second sample).\nOutput specification:\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets. Each result must be a list of $0$-based indices of samples flagged as integrated outliers for the corresponding test case. For example, an output of the form $[[i\\_1, i\\_2],[\\,], [j]]$ is valid. The final output must be printed exactly as a single Python list literal of lists on one line, with no additional text.",
            "solution": "The problem statement has been validated and is deemed valid. It is scientifically grounded in established statistical methods (Principal Component Analysis leverage, Median Absolute Deviation), well-posed with a deterministic algorithm, objective in its language, and complete in its specification of data and parameters. The problem is a formalizable and relevant task in the quality control of multi-omics data within translational medicine. There are no contradictions, no violations of scientific principles, and no ambiguities that would prevent a unique, verifiable solution.\n\nHere follows a complete, reasoned solution.\n\n### **Algorithmic Procedure**\n\nThe quality control pipeline identifies outlier samples by integrating two distinct types of statistical measures across multiple omics datasets and quality metric vectors: PCA-based leverage scores and MAD-based robust deviations. The procedure for a given test case is as follows.\n\n**1. Initialization**\nLet $n$ be the number of samples. Two integer vectors are initialized to store outlier counts for each sample:\n- $C^{\\text{lev}} \\in \\mathbb{Z}^n$, initialized to zeros, to count leverage-based outlier flags.\n- $C^{\\text{met}} \\in \\mathbb{Z}^n$, initialized to zeros, to count metric-based outlier flags.\n\n**2. Leverage-Based Outlier Detection (per omics dataset)**\nFor each of the $O$ omics data matrices $X^{(o)} \\in \\mathbb{R}^{n \\times p}$, where $o \\in \\{1, \\dots, O\\}$:\n\n**a. Standardization:**\nEach column $j$ of $X^{(o)}$ is standardized to have a mean of $0$ and a standard deviation of $1$. Let $X^{(o)}_{:,j}$ be the $j$-th column. Its mean $\\mu_j$ and standard deviation $\\sigma_j$ are computed. The standardized column $X'^{(o)}_{:,j}$ is given by:\n$$\nX'^{(o)}_{i,j} = \\begin{cases} (X^{(o)}_{i,j} - \\mu_j) / \\sigma_j & \\text{if } \\sigma_j > 0 \\\\ 0 & \\text{if } \\sigma_j = 0 \\end{cases}\n$$\nThis creates the standardized matrix $X'^{(o)}$.\n\n**b. Singular Value Decomposition (SVD):**\nThe SVD of the standardized matrix is computed: $X'^{(o)} = U^{(o)} \\Sigma^{(o)} (V^{(o)})^\\top$. Here, $U^{(o)} \\in \\mathbb{R}^{n \\times n}$ is the matrix of left singular vectors.\n\n**c. Rank and Component Selection:**\nThe rank of the matrix, $r^{(o)} = \\operatorname{rank}(X'^{(o)})$, is determined. This corresponds to the number of non-zero singular values. The number of principal components to consider is $k' = \\min(k, r^{(o)})$, where $k$ is the user-specified number of components. We define $U_{k'}^{(o)}$ as the matrix containing the first $k'$ columns of $U^{(o)}$.\n\n**d. Leverage Calculation:**\nThe leverage score $h_i^{(o)}$ for each sample $i \\in \\{1, \\dots, n\\}$ is the sum of the squares of the elements in the $i$-th row of $U_{k'}^{(o)}$:\n$$\nh_i^{(o)} = \\sum_{j=1}^{k'} (U^{(o)}_{ij})^2\n$$\n\n**e. Outlier Flagging:**\nA leverage threshold $\\tau_{\\text{lev}}^{(o)}$ is calculated based on the mean leverage:\n$$\n\\tau_{\\text{lev}}^{(o)} = \\frac{\\alpha \\cdot k'}{n}\n$$\nwhere $\\alpha$ is the given amplification factor. If a sample's leverage $h_i^{(o)}$ exceeds this threshold, its leverage outlier count $C^{\\text{lev}}_i$ is incremented:\n$$\n\\text{if } h_i^{(o)} > \\tau_{\\text{lev}}^{(o)}, \\text{ then } C^{\\text{lev}}_i \\leftarrow C^{\\text{lev}}_i + 1\n$$\n\n**3. Metric-Based Outlier Detection (per quality metric)**\nFor each provided quality metric vector $q \\in \\mathbb{R}^n$:\n\n**a. Median and Median Absolute Deviation (MAD):**\nThe median of the metric, $m = \\operatorname{median}(q)$, is calculated. The absolute deviations from the median, $d_i = |q_i - m|$, are computed for all samples. The MAD is the median of these absolute deviations: $\\operatorname{MAD}(q) = \\operatorname{median}(d)$.\n\n**b. Outlier Flagging:**\nThe method for flagging outliers depends on the value of $\\operatorname{MAD}(q)$:\n- If $\\operatorname{MAD}(q) > 0$: The robust scaled deviation $z_i$ is calculated for each sample:\n  $$\n  z_i = \\frac{d_i}{c \\cdot \\operatorname{MAD}(q)} = \\frac{|q_i - \\operatorname{median}(q)|}{1.4826 \\cdot \\operatorname{MAD}(q)}\n  $$\n  If $z_i$ exceeds the metric threshold $t$, the sample's metric outlier count $C^{\\text{met}}_i$ is incremented.\n- If $\\operatorname{MAD}(q) = 0$: Any sample $i$ for which the metric value $q_i$ is not equal to the median $m$ is considered an outlier. For each such sample, $C^{\\text{met}}_i$ is incremented. If all $q_i$ are equal to the median, no outliers are flagged for this metric.\n\n**4. Integrated Outlier Identification**\nAfter processing all omics matrices and quality metrics, the final outlier status of each sample $i$ is determined by comparing its accumulated counts $C^{\\text{lev}}_i$ and $C^{\\text{met}}_i$ with the respective integer thresholds $\\theta$ and $\\phi$:\n$$\n\\text{Sample } i \\text{ is an integrated outlier if } (C^{\\text{lev}}_i \\geq \\theta) \\text{ or } (C^{\\text{met}}_i \\geq \\phi)\n$$\nThe 0-based indices of all samples satisfying this condition are collected as the final result for the test case.\n\n---\n### **Application to Test Cases**\n\n**Test Case 1**\n- Parameters: $n=6, O=3, k=2, \\alpha=2.0, \\theta=1, t=3.0, \\phi=1$.\n- **Leverage:**\n  - For $X^{(1)}$ and $X^{(2)}$, the data points are relatively homogeneous. After standardization, the SVD yields leverage scores where no single sample dominates. The ranks are $r^{(1)}=4$ and $r^{(2)}=5$. Then $k' = \\min(2,4)=2$ and $k'=\\min(2,5)=2$. The thresholds are $\\tau_{\\text{lev}}^{(1)} = 2.0 \\cdot 2 / 6 \\approx 0.667$ and $\\tau_{\\text{lev}}^{(2)} = 2.0 \\cdot 2 / 6 \\approx 0.667$. All calculated $h_i^{(1)}$ and $h_i^{(2)}$ values are found to be below this threshold.\n  - For $X^{(3)}$, the 4th sample (index $3$) is anomalous: $[10, 10, 1]$. After standardization, the matrix rank is $r^{(3)}=1$. Thus, $k'=\\min(2,1)=1$. The leverage threshold is $\\tau_{\\text{lev}}^{(3)} = 2.0 \\cdot 1 / 6 \\approx 0.333$. The leverage scores are approximately $h^{(3)} = [0.038, 0.038, 0.038, 0.769, 0.038, 0.038]$. Only $h_3^{(3)} \\approx 0.769 > 0.333$.\n  - The leverage counts are $C^{\\text{lev}} = [0, 0, 0, 1, 0, 0]$.\n- **Metrics:**\n  - Metric 1: $q = [8.0, 8.2, 7.9, 3.0, 8.1, 8.0]$. The median is $8.0$. Deviations are $[0.0, 0.2, 0.1, 5.0, 0.1, 0.0]$. The MAD is $0.1$. The z-score for sample 4 (index 3) is $z_3 = 5.0 / (1.4826 \\cdot 0.1) \\approx 33.72 > 3.0$.\n  - Metric 2: $q = [5\\text{e}6, 5.1\\text{e}6, 4.9\\text{e}6, 1\\text{e}6, 5.2\\text{e}6, 5\\text{e}6]$. The median is $5\\text{e}6$. MAD is $1\\text{e}5$. The z-score for sample 4 is $z_3 = 4\\text{e}6 / (1.4826 \\cdot 1\\text{e}5) \\approx 26.98 > 3.0$.\n  - The metric counts are $C^{\\text{met}} = [0, 0, 0, 2, 0, 0]$.\n- **Integration:**\n  - For sample 4 (index 3): $C^{\\text{lev}}_3=1 \\geq \\theta=1$ and $C^{\\text{met}}_3=2 \\geq \\phi=1$. The sample is an outlier.\n  - For all other samples $i \\neq 3$, $C^{\\text{lev}}_i=0 < 1$ and $C^{\\text{met}}_i=0 < 1$. They are not outliers.\n- **Result:** `[3]`\n\n**Test Case 2**\n- Parameters: $n=4, O=2, k=2, \\alpha=2.0, \\theta=1, t=3.0, \\phi=1$.\n- **Leverage:**\n  - Both $X^{(1)}$ and $X^{(2)}$ consist of identical rows. Each column has a standard deviation of $0$.\n  - Per the rule, both standardized matrices $X'^{(1)}$ and $X'^{(2)}$ are zero matrices.\n  - The rank of a zero matrix is $r=0$. Thus $k'=\\min(2, 0)=0$.\n  - The leverage scores $h_i$ are all $0$, and the threshold $\\tau_{\\text{lev}}$ is also $0$. The condition $h_i > \\tau_{\\text{lev}}$ is never met.\n  - The leverage counts are $C^{\\text{lev}} = [0, 0, 0, 0]$.\n- **Metrics:**\n  - Both metric vectors, $[10, 10, 10, 10]$ and $[100, 100, 100, 100]$, consist of identical values.\n  - For both, the median is the constant value, all deviations are $0$, and thus the MAD is $0$.\n  - The special case for $\\operatorname{MAD}=0$ applies. Since no $q_i$ differs from the median, no outliers are flagged.\n  - The metric counts are $C^{\\text{met}} = [0, 0, 0, 0]$.\n- **Integration:**\n  - For all samples, $C^{\\text{lev}}_i=0$ and $C^{\\text{met}}_i=0$. The conditions $C^{\\text{lev}}_i \\geq 1$ or $C^{\\text{met}}_i \\geq 1$ are never met.\n- **Result:** `[]`\n\n**Test Case 3**\n- Parameters: $n=5, O=2, k=2, \\alpha=2.0, \\theta=2, t=3.0, \\phi=2$.\n- **Leverage:**\n  - The matrices $X^{(1)}$ and $X^{(2)}$ consist of very similar samples.\n  - For $X^{(1)}$, $r^{(1)}=2, k'=2$. $\\tau_{\\text{lev}}^{(1)} = 2.0 \\cdot 2 / 5 = 0.8$. All $h_i^{(1)}$ are below this threshold.\n  - For $X^{(2)}$, $r^{(2)}=2, k'=2$. $\\tau_{\\text{lev}}^{(2)} = 2.0 \\cdot 2 / 5 = 0.8$. All $h_i^{(2)}$ are below this threshold.\n  - No sample is flagged as a leverage outlier in any omic. The leverage counts are $C^{\\text{lev}} = [0, 0, 0, 0, 0]$.\n- **Metrics:**\n  - Metric 1: $q = [0.1, 5.0, 0.2, 0.1, 0.0]$. Median is $0.1$. MAD is $0.1$. The z-score for sample 2 (index 1) is $z_1 = 4.9 / (1.4826 \\cdot 0.1) \\approx 33.05 > 3.0$. Sample 2 is an outlier.\n  - Metric 2: $q = [100, 1000, 105, 98, 97]$. Median is $100$. MAD is $3$. The z-score for sample 2 is $z_1 = 900 / (1.4826 \\cdot 3) \\approx 202.41 > 3.0$. Sample 2 is an outlier.\n  - The metric counts are $C^{\\text{met}} = [0, 2, 0, 0, 0]$.\n- **Integration:**\n  - The thresholds are high: $\\theta=2, \\phi=2$.\n  - For sample 2 (index 1): $C^{\\text{lev}}_1=0 < \\theta=2$, but $C^{\\text{met}}_1=2 \\geq \\phi=2$. The sample is an outlier.\n  - For all other samples, counts are too low.\n- **Result:** `[1]`",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.linalg import svd\n\ndef solve():\n    \"\"\"\n    Main function to run the multi-omics outlier detection pipeline on a predefined test suite.\n    \"\"\"\n    \n    test_cases = [\n        # Test Case 1\n        {\n            \"params\": {\"n\": 6, \"O\": 3, \"k\": 2, \"alpha\": 2.0, \"theta\": 1, \"t\": 3.0, \"phi\": 1},\n            \"omics_data\": [\n                np.array([\n                    [0.5, 1.0, -0.3, 0.2],\n                    [0.6, 0.8, -0.1, 0.0],\n                    [0.4, 1.1, -0.2, 0.1],\n                    [0.5, 0.9, -0.3, 0.2],\n                    [0.6, 1.0, -0.2, 0.3],\n                    [0.5, 0.95, -0.25, 0.15]\n                ]),\n                np.array([\n                    [10, 12, 9, 11, 10],\n                    [11, 12, 9, 10, 11],\n                    [10, 11, 10, 11, 10],\n                    [10, 12, 9, 11, 10],\n                    [11, 11, 9, 10, 12],\n                    [10, 12, 10, 11, 11]\n                ]),\n                np.array([\n                    [0, 0, 1],\n                    [0, 0, 1],\n                    [0, 0, 1],\n                    [10, 10, 1],\n                    [0, 0, 1],\n                    [0, 0, 1]\n                ])\n            ],\n            \"quality_metrics\": [\n                np.array([8.0, 8.2, 7.9, 3.0, 8.1, 8.0]),\n                np.array([5_000_000, 5_100_000, 4_900_000, 1_000_000, 5_200_000, 5_000_000])\n            ]\n        },\n        # Test Case 2\n        {\n            \"params\": {\"n\": 4, \"O\": 2, \"k\": 2, \"alpha\": 2.0, \"theta\": 1, \"t\": 3.0, \"phi\": 1},\n            \"omics_data\": [\n                np.array([[1, 2, 3], [1, 2, 3], [1, 2, 3], [1, 2, 3]]),\n                np.array([[1, 2, 3], [1, 2, 3], [1, 2, 3], [1, 2, 3]])\n            ],\n            \"quality_metrics\": [\n                np.array([10, 10, 10, 10]),\n                np.array([100, 100, 100, 100])\n            ]\n        },\n        # Test Case 3\n        {\n            \"params\": {\"n\": 5, \"O\": 2, \"k\": 2, \"alpha\": 2.0, \"theta\": 2, \"t\": 3.0, \"phi\": 2},\n            \"omics_data\": [\n                np.array([[1, 2], [1, 2], [1.1, 1.9], [0.9, 2.1], [1, 2]]),\n                np.array([[5, 5], [5, 5], [5.1, 4.9], [4.9, 5.1], [5, 5]])\n            ],\n            \"quality_metrics\": [\n                np.array([0.1, 5.0, 0.2, 0.1, 0.0]),\n                np.array([100, 1000, 105, 98, 97])\n            ]\n        }\n    ]\n\n    results = []\n    \n    for case in test_cases:\n        params = case[\"params\"]\n        n = params[\"n\"]\n        k = params[\"k\"]\n        alpha = params[\"alpha\"]\n        theta = params[\"theta\"]\n        t = params[\"t\"]\n        phi = params[\"phi\"]\n        \n        c_lev = np.zeros(n, dtype=int)\n        c_met = np.zeros(n, dtype=int)\n\n        # Leverage-based outlier detection\n        for X in case[\"omics_data\"]:\n            # Standardize matrix\n            mean = np.mean(X, axis=0)\n            std = np.std(X, axis=0)\n            X_std = np.zeros_like(X, dtype=float)\n            for j in range(X.shape[1]):\n                if std[j] > 1e-9: # Use tolerance for float comparison\n                    X_std[:, j] = (X[:, j] - mean[j]) / std[j]\n            \n            # SVD and rank\n            try:\n                U, s, Vh = svd(X_std, full_matrices=False)\n                # Rank is number of singular values greater than a tolerance\n                rank = np.linalg.matrix_rank(X_std)\n            except np.linalg.LinAlgError:\n                # SVD can fail on some ill-conditioned matrices, though unlikely here\n                continue\n\n            num_components = min(k, rank)\n            if num_components == 0:\n                continue\n\n            # Leverage calculation\n            U_k = U[:, :num_components]\n            h = np.sum(U_k**2, axis=1)\n            \n            # Leverage outlier flagging\n            leverage_threshold = alpha * num_components / n\n            c_lev[h > leverage_threshold] += 1\n\n        # Metric-based outlier detection\n        c_consistency = 1.4826\n        for q in case[\"quality_metrics\"]:\n            median_q = np.median(q)\n            deviations = np.abs(q - median_q)\n            mad_q = np.median(deviations)\n\n            if mad_q > 1e-9: # Use tolerance for float comparison\n                z_scores = deviations / (c_consistency * mad_q)\n                c_met[z_scores > t] += 1\n            else:\n                # Special case for MAD == 0\n                c_met[q != median_q] += 1\n        \n        # Integrated outlier identification\n        integrated_outliers = np.where((c_lev >= theta) | (c_met >= phi))[0].tolist()\n        results.append(integrated_outliers)\n\n    # Final print statement must produce the exact single-line format.\n    # The format `f\"[{','.join(map(str, results))}]\"` is explicitly requested,\n    -    # resulting in a string like '[[3],[],[1]]'.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "Advanced integrative models can exploit the inherent structure of multi-omics data to improve predictive accuracy and yield more interpretable biological insights. This practice delves into building a predictive model using an overlapping group lasso penalty, a sophisticated regularization technique that encourages sparsity at both the gene and modality levels. By implementing the associated proximal gradient algorithm, you will gain hands-on experience with cutting-edge machine learning methods for multi-omics biomarker discovery .",
            "id": "4362368",
            "problem": "Consider a precision medicine setting where the goal is to predict a continuous clinical outcome from multi-omics features measured per gene across three modalities: Copy Number Variation (CNV), messenger ribonucleic acid (mRNA) expression, and Deoxyribonucleic Acid (DNA) methylation. Let $X \\in \\mathbb{R}^{n \\times p}$ denote the design matrix with $n$ samples and $p$ features. We consider $n = 8$ patients and $p = 9$ features, ordered by modality blocks across $3$ genes as follows: CNV for genes $1,2,3$ (columns $0,1,2$), mRNA expression for genes $1,2,3$ (columns $3,4,5$), DNA methylation for genes $1,2,3$ (columns $6,7,8$). The features are organized into overlapping groups to reflect two biologically coherent structures: (i) gene-wise groups across modalities and (ii) modality-wise groups across genes.\n\nYou are given the explicit data matrix $X$ and a deterministic target vector $y$ constructed with a known ground-truth coefficient vector $\\beta^\\star \\in \\mathbb{R}^p$ as $y = X \\beta^\\star$. The matrix $X$ (rows stacked) and the vector $\\beta^\\star$ are:\n- $X \\in \\mathbb{R}^{8 \\times 9}$ with rows:\n  - Row $1$: $[1, 0, -1, 0.5, -1.2, 0.3, 0.8, 0.1, 0.2]$\n  - Row $2$: $[0, 1, 1, 1.0, 0.3, -0.4, 0.6, 0.2, 0.9]$\n  - Row $3$: $[-1, -1, 0, -0.7, 0.5, 1.2, 0.1, 0.4, 0.3]$\n  - Row $4$: $[2, 0, 1, 0.2, -0.3, -0.5, 0.9, 0.7, 0.5]$\n  - Row $5$: $[0, -2, 1, 1.5, 0.7, 0.0, 0.2, 0.8, 0.6]$\n  - Row $6$: $[1, 1, 0, -0.4, 1.1, -1.3, 0.3, 0.5, 0.4]$\n  - Row $7$: $[-1, 2, -1, 0.0, -0.6, 0.9, 0.4, 0.6, 0.7]$\n  - Row $8$: $[0, 0, 2, 0.8, -0.9, 0.4, 0.5, 0.2, 0.1]$\n- $\\beta^\\star = [0.3, 0.0, -0.2, 1.0, 0.0, 0.5, -0.8, 0.0, 0.2]^\\top$\n- $y = X \\beta^\\star$\n\nDefine the following overlapping groups $\\mathcal{G}$ that reflect gene-level integration across modalities and modality-level integration across genes:\n- Gene-wise groups across modalities:\n  - $G_{\\text{gene},1} = \\{0, 3, 6\\}$\n  - $G_{\\text{gene},2} = \\{1, 4, 7\\}$\n  - $G_{\\text{gene},3} = \\{2, 5, 8\\}$\n- Modality-wise groups across genes:\n  - $G_{\\text{CNV}} = \\{0, 1, 2\\}$\n  - $G_{\\text{Expr}} = \\{3, 4, 5\\}$\n  - $G_{\\text{Meth}} = \\{6, 7, 8\\}$\n\nLet the weight for each group $g \\in \\mathcal{G}$ be $\\alpha_g = \\sqrt{|g|}$, where $|g|$ denotes the cardinality of group $g$. The overlapping group lasso penalty is\n$$\n\\Omega(w) \\;=\\; \\sum_{g \\in \\mathcal{G}} \\alpha_g \\, \\|w_g\\|_2,\n$$\nwhere $w_g$ denotes the subvector of $w \\in \\mathbb{R}^p$ indexed by $g$. The objective to minimize is the penalized empirical risk for linear regression with squared loss,\n$$\nF_\\lambda(w) \\;=\\; \\frac{1}{2n}\\,\\|X w - y\\|_2^2 \\;+\\; \\lambda\\,\\Omega(w),\n$$\nwith regularization parameter $\\lambda \\ge 0$ and $n = 8$.\n\nFundamental base and definitions to use:\n- The squared loss $f(w) = \\frac{1}{2n}\\|X w - y\\|_2^2$ has $\\nabla f(w) = \\frac{1}{n} X^\\top (X w - y)$ and is convex with $\\nabla f$ being $L$-Lipschitz where $L = \\lambda_{\\max}\\!\\left(\\frac{1}{n}X^\\top X\\right)$.\n- The proximal operator of a convex function $\\phi$ is $\\operatorname{prox}_{\\tau \\phi}(v) = \\arg\\min_{x} \\left\\{\\frac{1}{2}\\|x-v\\|_2^2 + \\tau \\phi(x)\\right\\}$ for $\\tau > 0$.\n- For a group $\\ell_2$-norm on indices $g$, $\\phi_g(x) = \\alpha_g \\|x_g\\|_2$, the proximal operator acts as block soft-thresholding on $x_g$ while leaving $x_{-g}$ unchanged.\n\nTasks:\n- Mathematically specify the overlapping group lasso penalty $\\Omega(w)$ using the provided groups and weights, and give the explicit gradient of the smooth loss $f(w)$.\n- Design a proximal gradient algorithm with Nesterov acceleration (Fast Iterative Shrinkage-Thresholding Algorithm) to minimize $F_\\lambda(w)$. Because the groups overlap, the proximal mapping of $\\tau \\lambda \\Omega$ is not separable across coordinates. Use a cyclic Dykstra scheme over the groupwise proximal operators $\\operatorname{prox}_{\\tau \\lambda \\alpha_g \\|\\cdot\\|_{2,g}}$ to compute $\\operatorname{prox}_{\\tau \\lambda \\Omega}$; each groupwise proximal step should perform block soft-thresholding only on the coordinates in $g$ and act as the identity elsewhere. Assume a fixed stepsize $t = 1/L$ with $L = \\lambda_{\\max}\\!\\left(\\frac{1}{n}X^\\top X\\right)$.\n\nProgram requirements:\n- Implement the accelerated proximal gradient method with the cyclic Dykstra proximal subroutine for the overlapping penalty. Initialize at $w^{(0)} = 0$. Use stopping criterion $\\|w^{(k+1)} - w^{(k)}\\|_2 \\le \\varepsilon \\max\\{1, \\|w^{(k)}\\|_2\\}$ with tolerance $\\varepsilon = 10^{-8}$ or a cap of $1000$ iterations, whichever occurs first. For the Dykstra inner loop, use a tolerance of $10^{-10}$ or a cap of $500$ inner iterations per outer iteration.\n- Test suite: run the solver for the regularization parameters $\\lambda \\in \\{0.0, 0.05, 0.2, 10.0\\}$.\n- For each $\\lambda$, compute the final objective value $F_\\lambda(w_\\lambda)$ at the converged solution $w_\\lambda$.\n- Final output format: your program should produce a single line containing a list of the four objective values as floats, in the order of the test suite, each rounded to exactly six digits after the decimal point, printed as a comma-separated list enclosed in square brackets (e.g., $[0.123456,1.234567,2.345678,3.456789]$).",
            "solution": "The user has provided a well-posed problem in computational statistics, specifically focused on solving a linear regression problem regularized with an overlapping group lasso penalty. All data, definitions, and algorithmic requirements are explicitly stated and are scientifically and mathematically sound.\n\n**Problem Statement Formalization**\n\nThe problem is to find a coefficient vector $w \\in \\mathbb{R}^p$ that minimizes the objective function $F_\\lambda(w)$, which is a composite of a smooth loss function and a non-smooth penalty function:\n$$\nF_\\lambda(w) \\;=\\; f(w) \\;+\\; \\lambda\\,\\Omega(w)\n$$\nwhere:\n- $n=8$ is the number of samples and $p=9$ is the number of features.\n- The loss function is the empirical squared error: $f(w) = \\frac{1}{2n}\\|X w - y\\|_2^2$, with $X \\in \\mathbb{R}^{n \\times p}$ and $y \\in \\mathbb{R}^n$ being the given data matrix and target vector, respectively.\n- The penalty function is the overlapping group lasso penalty: $\\Omega(w) = \\sum_{g \\in \\mathcal{G}} \\alpha_g \\|w_g\\|_2$.\n- $\\lambda \\ge 0$ is a non-negative regularization parameter.\n\n**1. Penalty Term and Loss Gradient Specification**\n\nFirst, we fully specify the components of the objective function using the provided information.\n\nThe set of groups $\\mathcal{G}$ consists of six groups in total:\n- Gene-wise groups: $G_{\\text{gene},1} = \\{0, 3, 6\\}$, $G_{\\text{gene},2} = \\{1, 4, 7\\}$, $G_{\\text{gene},3} = \\{2, 5, 8\\}$.\n- Modality-wise groups: $G_{\\text{CNV}} = \\{0, 1, 2\\}$, $G_{\\text{Expr}} = \\{3, 4, 5\\}$, $G_{\\text{Meth}} = \\{6, 7, 8\\}$.\n\nThe cardinality $|g|$ for each group $g \\in \\mathcal{G}$ is $3$. The weight for each group is therefore $\\alpha_g = \\sqrt{|g|} = \\sqrt{3}$. The penalty function is explicitly given by:\n$$\n\\Omega(w) = \\sqrt{3} \\left( \\|w_{\\{0,3,6\\}}\\|_2 + \\|w_{\\{1,4,7\\}}\\|_2 + \\|w_{\\{2,5,8\\}}\\|_2 + \\|w_{\\{0,1,2\\}}\\|_2 + \\|w_{\\{3,4,5\\}}\\|_2 + \\|w_{\\{6,7,8\\}}\\|_2 \\right)\n$$\nwhere $w_g$ is the subvector of $w$ with indices in $g$.\n\nThe loss function $f(w)$ is smooth and convex. Its gradient is given by:\n$$\n\\nabla f(w) = \\frac{1}{n} X^\\top (Xw - y)\n$$\nThis gradient is Lipschitz continuous with a constant $L = \\lambda_{\\max}\\!\\left(\\frac{1}{n}X^\\top X\\right)$, where $\\lambda_{\\max}(\\cdot)$ denotes the maximum eigenvalue of a matrix.\n\n**2. Algorithm Design: Accelerated Proximal Gradient with Dykstra's Scheme**\n\nTo minimize the composite objective function $F_\\lambda(w)$, we employ an accelerated proximal gradient method, specifically the Fast Iterative Shrinkage-Thresholding Algorithm (FISTA). The core of each FISTA iteration is the computation of the proximal operator of the penalty term, $\\operatorname{prox}_{\\tau \\Omega}(\\cdot)$. Since the penalty $\\Omega(w)$ is a sum of norms on overlapping groups of variables, its proximal operator is not separable and cannot be computed in closed form. We use Dykstra's projection algorithm to compute it iteratively.\n\n**2.1. FISTA (Outer Loop)**\n\nThe algorithm maintains two sequences of iterates, a primary sequence $z^{(k)}$ and an accelerated sequence $w^{(k)}$.\n- **Initialization**:\n  - $z^{(0)} = \\mathbf{0} \\in \\mathbb{R}^p$\n  - $w^{(0)} = z^{(0)}$\n  - $\\theta_0 = 1$\n  - Step size $t = 1/L$ where $L = \\lambda_{\\max}(\\frac{1}{n}X^\\top X)$.\n- **Iteration $k=0, 1, \\dots$**:\n  1. Compute the gradient at the accelerated point: $g^{(k)} = \\nabla f(w^{(k)}) = \\frac{1}{n} X^\\top (Xw^{(k)} - y)$.\n  2. Perform a gradient descent step: $v^{(k)} = w^{(k)} - t \\cdot g^{(k)}$.\n  3. Apply the proximal operator for the entire penalty term: $z^{(k+1)} = \\operatorname{prox}_{t \\lambda \\Omega}(v^{(k)})$. This step is computed using the Dykstra's algorithm described below.\n  4. Update the momentum parameter: $\\theta_{k+1} = \\frac{1 + \\sqrt{1 + 4\\theta_k^2}}{2}$.\n  5. Compute the next accelerated point: $w^{(k+1)} = z^{(k+1)} + \\frac{\\theta_k - 1}{\\theta_{k+1}} (z^{(k+1)} - z^{(k)})$.\n- **Termination**: The loop terminates when $\\|w^{(k+1)} - w^{(k)}\\|_2 \\le \\varepsilon \\max\\{1, \\|w^{(k)}\\|_2\\}$ for a tolerance $\\varepsilon = 10^{-8}$, or after $1000$ iterations.\n\n**2.2. Dykstra's Algorithm for the Proximal Operator (Inner Loop)**\n\nThe key step $z^{(k+1)} = \\operatorname{prox}_{t \\lambda \\Omega}(v^{(k)})$ seeks to solve:\n$$\n\\operatorname{prox}_{t \\lambda \\Omega}(v) = \\arg\\min_{x \\in \\mathbb{R}^p} \\left\\{ \\frac{1}{2}\\|x-v\\|_2^2 + t \\lambda \\sum_{g \\in \\mathcal{G}} \\alpha_g \\|x_g\\|_2 \\right\\}\n$$\nLet $\\phi_g(x) = \\alpha_g \\|x_g\\|_2$ and $\\tau = t \\lambda$. The problem is to compute $\\operatorname{prox}_{\\tau \\sum_g \\phi_g}(v)$. Dykstra's algorithm achieves this by cyclically applying the proximal operator of each individual group penalty.\n- **Initialization**:\n  - Let $M=|\\mathcal{G}|=6$ be the number of groups.\n  - $x_{(0)} = v$.\n  - Initialize auxiliary variables (residuals) $p_{g,(0)} = \\mathbf{0} \\in \\mathbb{R}^p$ for each group $g \\in \\mathcal{G}$.\n- **Iteration $j=0, 1, \\dots$**:\n  1. Let $x_{\\text{prev}} = x_{(j)}$.\n  2. Perform a cycle through all groups $g \\in \\mathcal{G}$:\n     - Argument for the proximal operator: $u_g = x_{(j)} + p_{g,(j)}$.\n     - Apply group-wise proximal operator: $x'_{g} = \\operatorname{prox}_{\\tau \\phi_g}(u_g)$.\n     - Update the auxiliary variable: $p_{g,(j+1)} = u_g - x'_{g}$.\n     - Update the iterate for the next group in the cycle: $x_{(j)} \\leftarrow x'_{g}$.\n  3. After one full cycle, the main iterate is updated: $x_{(j+1)} = x_{(j)}$.\n- **Termination**: The inner loop terminates when $\\|x_{(j+1)} - x_{(j)}\\|_2$ is smaller than a tolerance of $10^{-10}$, or after $500$ iterations. The final $x_{(j+1)}$ is the result of the proximal mapping.\n\n**2.3. Group-wise Proximal Operator**\n\nThe proximal operator for a single group $g$, $\\operatorname{prox}_{\\tau \\phi_g}(u)$, performs block soft-thresholding. It updates the components of $u$ belonging to group $g$ and leaves other components unchanged. Let $z = \\operatorname{prox}_{\\tau \\phi_g}(u)$.\n- For indices $j \\in g$:\n  $$\n  z_g = u_g \\cdot \\max \\left(0, 1 - \\frac{\\tau \\alpha_g}{\\|u_g\\|_2} \\right) = \\left(1 - \\frac{\\tau \\alpha_g}{\\|u_g\\|_2} \\right)_+ u_g\n  $$\n  This operation shrinks the subvector $u_g$ towards the origin. If $\\|u_g\\|_2 \\le \\tau \\alpha_g$, then $z_g$ becomes a zero vector.\n- For indices $j \\notin g$, $z_j = u_j$.\n\nBy combining these componentsFISTA for acceleration, Dykstra's algorithm for handling the overlapping penalties, and block soft-thresholding for each group's proximal operatorwe can effectively minimize the objective function $F_\\lambda(w)$. The implementation will follow these mathematical specifications.",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to solve the overlapping group lasso problem for the given test suite.\n    \"\"\"\n    #\n    # Step 1: Define problem data from the problem statement.\n    #\n    X = np.array([\n        [1.0, 0.0, -1.0, 0.5, -1.2, 0.3, 0.8, 0.1, 0.2],\n        [0.0, 1.0, 1.0, 1.0, 0.3, -0.4, 0.6, 0.2, 0.9],\n        [-1.0, -1.0, 0.0, -0.7, 0.5, 1.2, 0.1, 0.4, 0.3],\n        [2.0, 0.0, 1.0, 0.2, -0.3, -0.5, 0.9, 0.7, 0.5],\n        [0.0, -2.0, 1.0, 1.5, 0.7, 0.0, 0.2, 0.8, 0.6],\n        [1.0, 1.0, 0.0, -0.4, 1.1, -1.3, 0.3, 0.5, 0.4],\n        [-1.0, 2.0, -1.0, 0.0, -0.6, 0.9, 0.4, 0.6, 0.7],\n        [0.0, 0.0, 2.0, 0.8, -0.9, 0.4, 0.5, 0.2, 0.1],\n    ])\n\n    beta_star = np.array([0.3, 0.0, -0.2, 1.0, 0.0, 0.5, -0.8, 0.0, 0.2])\n    n, p = X.shape\n    y = X @ beta_star\n    \n    # Define groups\n    groups = [\n        [0, 3, 6],  # Gene 1\n        [1, 4, 7],  # Gene 2\n        [2, 5, 8],  # Gene 3\n        [0, 1, 2],  # CNV modality\n        [3, 4, 5],  # mRNA modality\n        [6, 7, 8],  # Methylation modality\n    ]\n    \n    # Calculate group weights\n    group_weights = [np.sqrt(len(g)) for g in groups]\n    \n    #\n    # Step 2: Define helper functions for the optimization algorithm.\n    #\n    \n    def soft_threshold(u_g, threshold):\n        \"\"\"Block soft-thresholding for a single group.\"\"\"\n        norm_u_g = np.linalg.norm(u_g)\n        if norm_u_g == 0:\n            return np.zeros_like(u_g)\n        \n        scale = 1 - threshold / norm_u_g\n        return u_g * max(0, scale)\n\n    def dykstra_prox(v, tau, tol=1e-10, max_iter=500):\n        \"\"\"\n        Computes the proximal operator for the sum of group lasso penalties using\n        Dykstra's cyclic projection algorithm.\n        \"\"\"\n        x = v.copy()\n        residuals = np.zeros((len(groups), p))\n        \n        for _ in range(max_iter):\n            x_prev = x.copy()\n            for i, (g_indices, g_weight) in enumerate(zip(groups, group_weights)):\n                # Proximal argument\n                u = x + residuals[i]\n                \n                # Apply block soft-thresholding\n                x_prox = u.copy()\n                u_g = u[g_indices]\n                threshold = tau * g_weight\n                x_prox[g_indices] = soft_threshold(u_g, threshold)\n                \n                # Update residual and iterate\n                residuals[i] = u - x_prox\n                x = x_prox\n                \n            if np.linalg.norm(x - x_prev) <= tol:\n                break\n        return x\n\n    def calculate_objective(w, lambda_reg):\n        \"\"\"Calculates the value of the objective function F_lambda(w).\"\"\"\n        loss = (1 / (2 * n)) * np.linalg.norm(X @ w - y)**2\n        penalty = 0.0\n        for g_indices, g_weight in zip(groups, group_weights):\n            penalty += g_weight * np.linalg.norm(w[g_indices])\n        return loss + lambda_reg * penalty\n\n    def solve_fista_dykstra(lambda_reg, tol=1e-8, max_iter=1000):\n        \"\"\"\n        Solves the overlapping group lasso problem using FISTA with Dykstra's algorithm.\n        \"\"\"\n        # Lipschitz constant and step size\n        L = np.linalg.eigvalsh(X.T @ X / n).max()\n        step_size = 1.0 / L\n\n        # FISTA initialization\n        w = np.zeros(p)\n        z = np.zeros(p)\n        theta = 1.0\n\n        for k in range(max_iter):\n            w_prev = w.copy()\n            z_prev = z.copy()\n            \n            # Gradient step from the accelerated point w\n            grad = (1.0 / n) * X.T @ (X @ w - y)\n            v = w - step_size * grad\n            \n            # Proximal step using Dykstra's algorithm\n            z = dykstra_prox(v, step_size * lambda_reg)\n            \n            # Nesterov momentum update\n            theta_prev = theta\n            theta = (1.0 + np.sqrt(1.0 + 4.0 * theta_prev**2)) / 2.0\n            \n            # Update the accelerated point\n            w = z + ((theta_prev - 1.0) / theta) * (z - z_prev)\n            \n            # Check for convergence on the 'w' iterate\n            stop_crit_val = np.linalg.norm(w - w_prev)\n            stop_crit_threshold = tol * max(1.0, np.linalg.norm(w_prev))\n\n            # Special case for lambda=0: objective can be zero\n            if lambda_reg == 0 and calculate_objective(w, lambda_reg) < 1e-12:\n                break\n                \n            if stop_crit_val <= stop_crit_threshold:\n                break\n        \n        return w\n        \n    #\n    # Step 3: Run the test suite and collect results.\n    #\n    test_suite = [0.0, 0.05, 0.2, 10.0]\n    results = []\n\n    for lambda_reg in test_suite:\n        w_final = solve_fista_dykstra(lambda_reg)\n        objective_value = calculate_objective(w_final, lambda_reg)\n        results.append(f\"{objective_value:.6f}\")\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(results)}]\")\n\nsolve()\n```"
        }
    ]
}