{
    "hands_on_practices": [
        {
            "introduction": "The reliability of any sequencing result begins with the quality of the individual base calls. This exercise provides a foundational understanding of the Phred quality score ($Q$-score), the universal metric for basecalling accuracy. By working through this problem, you will learn to translate this logarithmic score into a tangible quantity—the expected number of errors in a transcript—a critical skill for evaluating data quality and the impact of bioinformatic pipeline improvements. ",
            "id": "4356052",
            "problem": "In a precision oncology assay using long-read native Ribonucleic Acid (RNA) sequencing by Oxford Nanopore Technologies (ONT), a laboratory is evaluating whether to upgrade its basecalling model. For a representative full-length messenger RNA (mRNA) target of length $L=10000$ nucleotides, the current pipeline yields an average per-base quality score (Q-score) of $Q_{A}=10$. A proposed model upgrade is expected to raise the average per-base Q-score to $Q_{B}=15$. Assume that per-base errors are independent across positions within a read and that the per-base error probability is uniform across the read.\n\nStarting from the standard definition connecting the quality score to the per-base error probability and the basic probabilistic model for independent errors along a sequence, compute the expected absolute decrease in the number of mismatched bases per read when moving from pipeline $A$ to pipeline $B$. Express your final answer as the number of expected mismatches per read and round your answer to four significant figures.",
            "solution": "The problem asks for the expected absolute decrease in the number of mismatched bases per read when upgrading a sequencing pipeline. To solve this, we must first relate the provided quality scores ($Q$-scores) to the per-base error probabilities.\n\nThe Phred quality score, $Q$, is defined in terms of the probability of an incorrect base call, $P_e$, by the following logarithmic relationship:\n$$\nQ = -10 \\log_{10}(P_e)\n$$\nThis equation can be rearranged to solve for the per-base error probability, $P_e$, as a function of the Q-score, $Q$:\n$$\n-\\frac{Q}{10} = \\log_{10}(P_e)\n$$\n$$\nP_e = 10^{-Q/10}\n$$\nWe are given two different pipelines, A (current) and B (proposed), with average per-base Q-scores $Q_A = 10$ and $Q_B = 15$, respectively. We can calculate the per-base error probability for each pipeline.\n\nFor pipeline A:\n$$\nP_{e,A} = 10^{-Q_A/10} = 10^{-10/10} = 10^{-1} = 0.1\n$$\nThis means that for the current pipeline, there is a $1$ in $10$ chance of an error at any given base.\n\nFor pipeline B:\n$$\nP_{e,B} = 10^{-Q_B/10} = 10^{-15/10} = 10^{-1.5}\n$$\nThis is the per-base error probability for the proposed upgraded pipeline.\n\nThe problem states that the mRNA target has a length of $L = 10000$ nucleotides and that per-base errors are independent and uniformly distributed. The number of errors in a read can be modeled as a sum of Bernoulli trials, one for each nucleotide position. The expected number of mismatched bases (errors), $E$, in a read of length $L$ is the product of the length and the per-base error probability $P_e$:\n$$\nE = L \\times P_e\n$$\nUsing this formula, we can calculate the expected number of errors for both pipelines.\n\nExpected number of errors for pipeline A:\n$$\nE_A = L \\times P_{e,A} = 10000 \\times 0.1 = 1000\n$$\nSo, on average, a read of length $10000$ nucleotides generated by pipeline A is expected to contain $1000$ errors.\n\nExpected number of errors for pipeline B:\n$$\nE_B = L \\times P_{e,B} = 10000 \\times 10^{-1.5}\n$$\nWe can simplify this expression:\n$$\nE_B = 10^4 \\times 10^{-1.5} = 10^{4 - 1.5} = 10^{2.5} = 10^2 \\times 10^{0.5} = 100 \\sqrt{10}\n$$\nNumerically, $\\sqrt{10} \\approx 3.16227766$. Therefore:\n$$\nE_B \\approx 100 \\times 3.16227766 = 316.227766\n$$\n\nThe problem asks for the expected absolute decrease in the number of mismatched bases per read, which is the difference between the expected number of errors from pipeline A and pipeline B.\n$$\n\\Delta E = E_A - E_B\n$$\nSubstituting the calculated values:\n$$\n\\Delta E = 1000 - 100 \\sqrt{10}\n$$\nNow, we compute the numerical value:\n$$\n\\Delta E \\approx 1000 - 316.227766 = 683.772234\n$$\nThe problem requires the final answer to be rounded to four significant figures. The first four significant figures are $6$, $8$, $3$, and $7$. The fifth digit is $7$, so we round up the fourth digit.\n$$\n\\Delta E \\approx 683.8\n$$\nThus, upgrading the basecalling model from pipeline A to pipeline B is expected to decrease the number of mismatched bases by approximately $683.8$ per read of length $10000$.",
            "answer": "$$\n\\boxed{683.8}\n$$"
        },
        {
            "introduction": "One of the most powerful applications of long-read sequencing is its ability to resolve the full structure of complex transcript isoforms, which is often impossible with short reads. This practice moves beyond qualitative descriptions to build a quantitative, probabilistic model demonstrating this advantage. You will explore how read length directly impacts the ability to span multiple exon-exon junctions, thereby reducing isoform ambiguity and enabling more accurate transcript catalogs. ",
            "id": "4356011",
            "problem": "In long-read native Ribonucleic Acid (RNA) sequencing for precision medicine and genomic diagnostics, resolving transcript isoforms often requires that a single read span all discriminative exon-exon junctions. Consider a simple exon-junction model in which there are exactly $3$ discriminative junctions separating isoforms within a local transcript region. Assume the distances between adjacent discriminative junctions are independent and identically distributed exponential random variables with mean $\\mu = 300$ base pairs (bp), reflecting a junction density that is approximately stationary along the transcript. Under this model, the total span $D$ needed to cover all $3$ junctions (that is, from the most $5'$ of the three junctions to the most $3'$ of the three junctions) is the sum of $2$ independent exponential variables and thus follows a gamma distribution with shape parameter $2$ and rate $\\lambda = 1/\\mu$.\n\nAssume a read of fixed length $L$ is positioned with a translation-invariant uniform offset relative to the discriminative region, so that conditional on $D=d \\leq L$, the probability that the read spans all junctions equals the fraction of possible offsets that fully contain the interval of width $d$, namely $(L-d)/L$, and is $0$ otherwise. Let $p_{\\mathrm{span}}(L)$ denote the resulting expectation of this probability over the distribution of $D$. Define the per-read isoform ambiguity as $A(L) = 1 - p_{\\mathrm{span}}(L)$.\n\nCompute the expected reduction in isoform ambiguity when the mean read length increases from $L_{1} = 150$ bp (short-read regime) to $L_{2} = 2000$ bp (long-read regime), under the assumptions above and neglecting transcript boundary effects. Report the reduction as the single real number\n$$\\Delta A \\equiv A(L_{1}) - A(L_{2}) = p_{\\mathrm{span}}(L_{2}) - p_{\\mathrm{span}}(L_{1}).$$\nUse $\\mu = 300$ bp, and treat $L_{1}$ and $L_{2}$ as exact fixed lengths. Round your final answer to four significant figures and express it as a unitless decimal fraction.",
            "solution": "The user wants to compute the reduction in isoform ambiguity, $\\Delta A$, when increasing read length from $L_1 = 150$ bp to $L_2 = 2000$ bp.\n\nFirst, we formalize the problem based on the provided information. The reduction in ambiguity is defined as:\n$$ \\Delta A = A(L_1) - A(L_2) $$\nwhere $A(L) = 1 - p_{\\mathrm{span}}(L)$ is the isoform ambiguity for a read of length $L$. Substituting this definition, we get:\n$$ \\Delta A = (1 - p_{\\mathrm{span}}(L_1)) - (1 - p_{\\mathrm{span}}(L_2)) = p_{\\mathrm{span}}(L_2) - p_{\\mathrm{span}}(L_1) $$\nOur primary task is to derive an expression for $p_{\\mathrm{span}}(L)$, the probability that a read of length $L$ spans all $3$ discriminative junctions.\n\nThe total span $D$ required to cover all $3$ junctions is the sum of the $2$ distances between them. These distances are given as independent and identically distributed exponential random variables with mean $\\mu = 300$ bp. The sum of $k$ i.i.d. exponential random variables with rate $\\lambda$ follows a gamma distribution with shape parameter $k$ and rate parameter $\\lambda$. Here, $k=2$ and the rate $\\lambda$ is the reciprocal of the mean $\\mu$:\n$$ \\lambda = \\frac{1}{\\mu} = \\frac{1}{300} \\, \\text{bp}^{-1} $$\nThe probability density function (PDF) of the total span $D$ is given by the gamma distribution PDF for $d \\ge 0$:\n$$ f_D(d) = \\frac{\\lambda^k d^{k-1} \\exp(-\\lambda d)}{\\Gamma(k)} $$\nWith $k=2$ and $\\Gamma(2) = 1! = 1$, the PDF simplifies to:\n$$ f_D(d) = \\lambda^2 d \\exp(-\\lambda d) $$\n\nThe problem states that for a given span $D=d$, the probability that a read of length $L$ fully contains this span is $(L-d)/L$ if $d \\le L$, and $0$ if $d > L$.\nThe overall spanning probability, $p_{\\mathrm{span}}(L)$, is the expectation of this conditional probability over the distribution of $D$:\n$$ p_{\\mathrm{span}}(L) = \\mathbb{E}[P(\\text{span} | D)] = \\int_{0}^{\\infty} P(\\text{span} | D=d) f_D(d) \\, \\mathrm{d}d $$\nGiven the conditional probability, the integral's upper limit is $L$:\n$$ p_{\\mathrm{span}}(L) = \\int_{0}^{L} \\frac{L-d}{L} f_D(d) \\, \\mathrm{d}d $$\nSubstituting the PDF $f_D(d)$:\n$$ p_{\\mathrm{span}}(L) = \\int_{0}^{L} \\left(1 - \\frac{d}{L}\\right) (\\lambda^2 d \\exp(-\\lambda d)) \\, \\mathrm{d}d $$\nWe can split this into two parts:\n$$ p_{\\mathrm{span}}(L) = \\lambda^2 \\int_{0}^{L} d \\exp(-\\lambda d) \\, \\mathrm{d}d - \\frac{\\lambda^2}{L} \\int_{0}^{L} d^2 \\exp(-\\lambda d) \\, \\mathrm{d}d $$\nThese integrals can be solved using integration by parts. A more direct approach is to relate them to the cumulative distribution function (CDF) and partial expectation of the gamma distribution.\nLet's define $p_{\\mathrm{span}}(L) = \\int_0^L f_D(d) \\, \\mathrm{d}d - \\frac{1}{L}\\int_0^L d f_D(d) \\, \\mathrm{d}d$.\nThe first term is the CDF of the Gamma($k=2, \\lambda$) distribution, $F_D(L) = P(D \\le L)$. For integer $k$, the CDF is $F_D(L; k, \\lambda) = 1 - \\exp(-\\lambda L) \\sum_{j=0}^{k-1} \\frac{(\\lambda L)^j}{j!}$.\nFor $k=2$:\n$$ F_D(L) = 1 - \\exp(-\\lambda L) \\left( \\frac{(\\lambda L)^0}{0!} + \\frac{(\\lambda L)^1}{1!} \\right) = 1 - \\exp(-\\lambda L)(1 + \\lambda L) $$\nThe second term involves the integral $\\int_0^L d^2 \\exp(-\\lambda d) \\, \\mathrm{d}d$. Using integration by parts, $\\int u \\, \\mathrm{d}v = uv - \\int v \\, \\mathrm{d}u$:\nLet $u = d^n$ and $\\mathrm{d}v = \\exp(-\\lambda d)\\mathrm{d}d$. The general indefinite integral is:\n$$ \\int d^n \\exp(-\\lambda d) \\, \\mathrm{d}d = -\\frac{\\exp(-\\lambda d)}{\\lambda^{n+1}} \\sum_{i=0}^{n} \\frac{n!}{(n-i)!} (\\lambda d)^{n-i} $$\nFor $n=1$: $\\int d \\exp(-\\lambda d) \\, \\mathrm{d}d = -\\frac{\\exp(-\\lambda d)}{\\lambda^2}(\\lambda d + 1)$.\nFor $n=2$: $\\int d^2 \\exp(-\\lambda d) \\, \\mathrm{d}d = -\\frac{\\exp(-\\lambda d)}{\\lambda^3}(\\lambda^2 d^2 + 2\\lambda d + 2)$.\n\nEvaluating the definite integrals from $0$ to $L$:\n$$ \\int_{0}^{L} d \\exp(-\\lambda d) \\, \\mathrm{d}d = \\left[ -\\frac{\\exp(-\\lambda d)}{\\lambda^2}(\\lambda d + 1) \\right]_{0}^{L} = \\frac{1}{\\lambda^2} - \\frac{\\exp(-\\lambda L)}{\\lambda^2}(\\lambda L + 1) $$\n$$ \\int_{0}^{L} d^2 \\exp(-\\lambda d) \\, \\mathrm{d}d = \\left[ -\\frac{\\exp(-\\lambda d)}{\\lambda^3}(\\lambda^2 d^2 + 2\\lambda d + 2) \\right]_{0}^{L} = \\frac{2}{\\lambda^3} - \\frac{\\exp(-\\lambda L)}{\\lambda^3}(\\lambda^2 L^2 + 2\\lambda L + 2) $$\nSubstituting these back into the expression for $p_{\\mathrm{span}}(L)$:\n$$ p_{\\mathrm{span}}(L) = \\lambda^2 \\left( \\frac{1}{\\lambda^2} - \\frac{\\exp(-\\lambda L)}{\\lambda^2}(\\lambda L + 1) \\right) - \\frac{\\lambda^2}{L} \\left( \\frac{2}{\\lambda^3} - \\frac{\\exp(-\\lambda L)}{\\lambda^3}(\\lambda^2 L^2 + 2\\lambda L + 2) \\right) $$\n$$ p_{\\mathrm{span}}(L) = \\left( 1 - \\exp(-\\lambda L)(\\lambda L + 1) \\right) - \\frac{2}{\\lambda L} \\left( 1 - \\exp(-\\lambda L)\\left(\\frac{\\lambda^2 L^2}{2} + \\lambda L + 1\\right) \\right) $$\nThis simplifies to a more elegant form. Let's re-group the terms from the expanded integrals:\n$$ p_{\\mathrm{span}}(L) = 1 - (\\lambda L+1)\\exp(-\\lambda L) - \\frac{2}{\\lambda L} + \\frac{\\exp(-\\lambda L)}{\\lambda L}(\\lambda^2 L^2 + 2\\lambda L + 2) $$\n$$ p_{\\mathrm{span}}(L) = 1 - (\\lambda L+1)\\exp(-\\lambda L) - \\frac{2}{\\lambda L} + \\exp(-\\lambda L)(\\lambda L + 2 + \\frac{2}{\\lambda L}) $$\n$$ p_{\\mathrm{span}}(L) = 1 - \\lambda L \\exp(-\\lambda L) - \\exp(-\\lambda L) - \\frac{2}{\\lambda L} + \\lambda L \\exp(-\\lambda L) + 2 \\exp(-\\lambda L) + \\frac{2}{\\lambda L} \\exp(-\\lambda L) $$\n$$ p_{\\mathrm{span}}(L) = 1 - \\frac{2}{\\lambda L} + \\exp(-\\lambda L) + \\frac{2}{\\lambda L} \\exp(-\\lambda L) $$\n$$ p_{\\mathrm{span}}(L) = 1 - \\frac{2}{\\lambda L}(1 - \\exp(-\\lambda L)) + \\exp(-\\lambda L) $$\n\nNow we can compute $p_{\\mathrm{span}}(L)$ for $L_1=150$ bp and $L_2=2000$ bp.\nThe parameter $\\lambda = 1/300$ bp$^{-1}$.\n\nFor $L_1 = 150$ bp:\nThe dimensionless product is $\\lambda L_1 = \\frac{1}{300} \\times 150 = 0.5$.\n$$ p_{\\mathrm{span}}(L_1) = 1 - \\frac{2}{0.5}(1 - \\exp(-0.5)) + \\exp(-0.5) $$\n$$ p_{\\mathrm{span}}(L_1) = 1 - 4(1 - \\exp(-0.5)) + \\exp(-0.5) = 1 - 4 + 4\\exp(-0.5) + \\exp(-0.5) $$\n$$ p_{\\mathrm{span}}(L_1) = 5\\exp(-0.5) - 3 $$\n\nFor $L_2 = 2000$ bp:\nThe dimensionless product is $\\lambda L_2 = \\frac{1}{300} \\times 2000 = \\frac{20}{3}$.\n$$ p_{\\mathrm{span}}(L_2) = 1 - \\frac{2}{20/3}(1 - \\exp(-20/3)) + \\exp(-20/3) $$\n$$ p_{\\mathrm{span}}(L_2) = 1 - \\frac{6}{20}(1 - \\exp(-20/3)) + \\exp(-20/3) = 1 - 0.3 + 0.3\\exp(-20/3) + \\exp(-20/3) $$\n$$ p_{\\mathrm{span}}(L_2) = 0.7 + 1.3\\exp(-20/3) $$\n\nThe required quantity is $\\Delta A = p_{\\mathrm{span}}(L_2) - p_{\\mathrm{span}}(L_1)$.\n$$ \\Delta A = (0.7 + 1.3\\exp(-20/3)) - (5\\exp(-0.5) - 3) $$\n$$ \\Delta A = 3.7 + 1.3\\exp(-20/3) - 5\\exp(-0.5) $$\n\nNow we substitute the numerical values for the exponential functions:\n$\\exp(-0.5) \\approx 0.6065306597$\n$\\exp(-20/3) \\approx 0.0012712499$\n\n$$ p_{\\mathrm{span}}(L_1) \\approx 5 \\times 0.6065306597 - 3 = 3.0326532985 - 3 = 0.0326532985 $$\n$$ p_{\\mathrm{span}}(L_2) \\approx 0.7 + 1.3 \\times 0.0012712499 = 0.7 + 0.0016526249 = 0.7016526249 $$\n\n$$ \\Delta A \\approx 0.7016526249 - 0.0326532985 = 0.6689993264 $$\n\nRounding the result to four significant figures, we get $0.6690$.",
            "answer": "$$\\boxed{0.6690}$$"
        },
        {
            "introduction": "A unique capability of native RNA sequencing is the direct detection of RNA modifications, offering a window into the epitranscriptome. This advanced exercise tackles the challenge of quantifying modification levels, or stoichiometry, from probabilistic read-level data. You will implement a sophisticated Bayesian model to estimate stoichiometry and its uncertainty, reflecting the cutting-edge analyses that are driving new discoveries in gene regulation. ",
            "id": "4355991",
            "problem": "Consider a single transcriptomic site profiled by long-read native Ribonucleic Acid (RNA) sequencing, where each read aligned over the site yields an estimated probability of base modification. Let there be $n$ reads. For read $i$, let $p_i \\in [0,1]$ denote the probability that the base is modified for that read. Introduce latent Bernoulli variables $Z_i \\in \\{0,1\\}$ indicating whether read $i$ is truly modified. The modification stoichiometry is defined as the mean of these Bernoulli indicators, that is, $\\theta = \\frac{1}{n} \\sum_{i=1}^{n} Z_i$. The task is to construct a principled estimator of $\\theta$ and a Bayesian credible interval given a prior belief.\n\nFundamental base:\n- By definition, for a Bernoulli random variable $Z_i$, the expectation is $\\mathbb{E}[Z_i] = \\Pr(Z_i = 1)$.\n- Under a Bayesian model where the per-site stoichiometry parameter $\\theta \\in (0,1)$ has a Beta prior $\\text{Beta}(\\alpha,\\beta)$ with shape parameters $\\alpha > 0$ and $\\beta > 0$, and data are Bernoulli outcomes, the Beta family is conjugate to the Bernoulli likelihood.\n- The per-read probabilities $p_i$ are well-calibrated estimates of $\\Pr(Z_i = 1 \\mid \\text{read data})$ obtained from a validated modification caller for long-read native Ribonucleic Acid (RNA) sequencing.\n\nYour program must, for each test case, do the following from first principles:\n1. Use linearity of expectation to construct a point estimate of the stoichiometry as the expectation of the mean of Bernoulli indicators, expressed in terms of $\\{p_i\\}_{i=1}^n$.\n2. Using a Bayesian treatment with a $\\text{Beta}(\\alpha,\\beta)$ prior on the unknown stoichiometry parameter and the notion of conjugacy for Bernoulli data, derive a posterior distribution for the stoichiometry that integrates the uncertainty in $\\{Z_i\\}_{i=1}^n$ using the available $\\{p_i\\}_{i=1}^n$ without thresholding them to binary calls. Then compute the central credible interval at level $0.95$ for the stoichiometry, defined by the lower and upper quantiles at probabilities $\\frac{1-0.95}{2}$ and $1-\\frac{1-0.95}{2}$ of the posterior distribution, respectively.\n3. Report, for each test case, three real numbers: the point estimate, the lower bound, and the upper bound of the credible interval. All probabilities must be expressed as decimals, not with a percent sign.\n\nScientific realism constraints:\n- You must treat reads as conditionally independent given the stoichiometry and read-level signals, and use the per-read probabilities $\\{p_i\\}$ as probabilistic evidence about $\\{Z_i\\}$ rather than thresholding to hard calls. Do not assume that all $p_i$ are identical.\n- The prior $\\text{Beta}(\\alpha,\\beta)$ must be proper, that is, with $\\alpha > 0$ and $\\beta > 0$.\n\nTest suite and required outputs:\nYour program should compute and aggregate results for the following set of test cases. For each case, the program should output the point estimate, the lower bound, and the upper bound of the $0.95$ credible interval, rounded to $6$ decimal places.\n\n- Test case $1$: $\\{p_i\\} = [0.92, 0.87, 0.76, 0.61, 0.55, 0.33, 0.20, 0.10]$, $\\alpha = 1.0$, $\\beta = 1.0$.\n- Test case $2$: $\\{p_i\\} = [0.02, 0.03, 0.01, 0.04, 0.00]$, $\\alpha = 0.5$, $\\beta = 0.5$.\n- Test case $3$: $\\{p_i\\} = [1.0, 0.99, 1.0, 0.98, 1.0, 0.97]$, $\\alpha = 1.0$, $\\beta = 9.0$.\n- Test case $4$: $\\{p_i\\}$ is a list of $100$ probabilities consisting of $50$ entries equal to $0.3$ followed by $50$ entries equal to $0.7$, with $\\alpha = 20.0$, $\\beta = 20.0$.\n- Test case $5$: $\\{p_i\\} = [0.0, 1.0]$, $\\alpha = 0.1$, $\\beta = 0.1$.\n\nFinal output format:\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets. For each test case, output the three values in order: point estimate, lower bound, upper bound. Concatenate these triplets in the order of the test cases so the final output is a flat list, for example, $[x_1,y_1,z_1,x_2,y_2,z_2,\\dots]$. All values must be rounded to $6$ decimal places. No other text should be printed.",
            "solution": "The problem asks for the construction of a point estimator and a Bayesian credible interval for RNA modification stoichiometry, based on probabilistic outputs from a long-read native RNA sequencer.\n\n### Problem Validation\nThe problem is scientifically and mathematically well-posed. It describes a realistic scenario in bioinformatics where evidence is probabilistic rather than deterministic. The formulation involves standard statistical concepts: latent variables, expectation, and Bayesian inference with conjugate priors. A minor ambiguity exists in the dual use of the symbol $\\theta$ to refer to both a sample statistic and a model parameter. However, the problem text provides specific instructions for calculating each required quantity, which resolves this ambiguity. Task 1 specifies using linearity of expectation on the sample definition of stoichiometry, while Task 2 specifies a Bayesian treatment for an \"unknown stoichiometry parameter\" with a given prior. These distinct instructions allow for a coherent and principled solution. Therefore, the problem is deemed valid.\n\n### Principle-Based Solution Derivation\n\nLet $n$ be the number of sequencing reads covering a specific transcriptomic site. For each read $i \\in \\{1, \\dots, n\\}$, let $Z_i$ be a latent Bernoulli random variable where $Z_i=1$ if the base is truly modified and $Z_i=0$ otherwise. The sequencer provides probabilities $p_i$, which are well-calibrated estimates of $\\Pr(Z_i=1 | \\text{read data}_i)$. Our belief about the latent variable $Z_i$ is thus encapsulated by a Bernoulli distribution with parameter $p_i$, i.e., $\\Pr(Z_i=1) = p_i$.\n\n#### 1. Point Estimate of Stoichiometry\n\nThe problem defines the stoichiometry as the sample mean of the latent modification indicators:\n$$\n\\theta_{sample} = \\frac{1}{n} \\sum_{i=1}^{n} Z_i\n$$\nWe are instructed to construct a point estimate for this quantity using the linearity of expectation. The expectation of $\\theta_{sample}$ is:\n$$\n\\mathbb{E}[\\theta_{sample}] = \\mathbb{E}\\left[\\frac{1}{n} \\sum_{i=1}^{n} Z_i\\right]\n$$\nBy linearity of expectation, this becomes:\n$$\n\\mathbb{E}[\\theta_{sample}] = \\frac{1}{n} \\sum_{i=1}^{n} \\mathbb{E}[Z_i]\n$$\nThe expectation of a Bernoulli random variable $Z_i$ is the probability of success, $\\Pr(Z_i=1)$. As given, the best estimate for this probability is $p_i$. Thus, $\\mathbb{E}[Z_i] = p_i$.\nSubstituting this into the equation, we obtain the point estimator, which we denote $\\hat{\\theta}$:\n$$\n\\hat{\\theta} = \\frac{1}{n} \\sum_{i=1}^{n} p_i\n$$\nThis estimator is the arithmetic mean of the per-read modification probabilities.\n\n#### 2. Bayesian Credible Interval for the Stoichiometry Parameter\n\nFor the credible interval, we adopt a Bayesian framework for the underlying, unobserved site-wide stoichiometry parameter, which we denote $\\theta_{param} \\in (0,1)$. This parameter represents the true modification rate at the site. We assume that, given $\\theta_{param}$, the true modification statuses $Z_i$ are independent and identically distributed Bernoulli trials: $Z_i | \\theta_{param} \\sim \\text{Bernoulli}(\\theta_{param})$.\n\nThe prior belief about this parameter is given as a Beta distribution:\n$$\n\\theta_{param} \\sim \\text{Beta}(\\alpha, \\beta)\n$$\nThe probability density function (PDF) of the prior is $P(\\theta_{param}) \\propto \\theta_{param}^{\\alpha-1}(1-\\theta_{param})^{\\beta-1}$.\n\nThe likelihood of observing a specific set of binary outcomes $\\mathbf{Z} = (Z_1, \\dots, Z_n)$ given the parameter $\\theta_{param}$ is:\n$$\nP(\\mathbf{Z} | \\theta_{param}) = \\prod_{i=1}^{n} P(Z_i | \\theta_{param}) = \\prod_{i=1}^{n} \\theta_{param}^{Z_i} (1-\\theta_{param})^{1-Z_i} = \\theta_{param}^{\\sum Z_i} (1-\\theta_{param})^{n-\\sum Z_i}\n$$\nDue to the conjugacy of the Beta prior and Bernoulli likelihood, the posterior distribution of $\\theta_{param}$ given the outcomes $\\mathbf{Z}$ is also a Beta distribution:\n$$\n\\theta_{param} | \\mathbf{Z} \\sim \\text{Beta}\\left(\\alpha + \\sum_{i=1}^{n} Z_i, \\beta + n - \\sum_{i=1}^{n} Z_i\\right)\n$$\nHowever, the latent variables $Z_i$ are not observed directly. Instead, we have the probabilities $p_i$. The problem requires us to \"integrate the uncertainty in $\\{Z_i\\}$\". A principled and computationally tractable method for this is to update the prior using the *expected* values of the sufficient statistics. The sufficient statistics are the number of modified reads, $S = \\sum_{i=1}^n Z_i$, and the number of unmodified reads, $F = \\sum_{i=1}^n (1-Z_i)$.\n\nTheir expectations, conditioned on the evidence $\\{p_i\\}$, are:\n$$\n\\mathbb{E}[S | \\{p_i\\}] = \\sum_{i=1}^{n} \\mathbb{E}[Z_i | p_i] = \\sum_{i=1}^{n} p_i\n$$\n$$\n\\mathbb{E}[F | \\{p_i\\}] = \\sum_{i=1}^{n} \\mathbb{E}[1-Z_i | p_i] = \\sum_{i=1}^{n} (1-p_i) = n - \\sum_{i=1}^{n} p_i\n$$\nThis use of expected or \"soft\" counts yields an approximate posterior distribution for $\\theta_{param}$. We update the hyperparameters of the Beta prior with these expected counts:\n$$\n\\alpha_{post} = \\alpha + \\mathbb{E}[S | \\{p_i\\}] = \\alpha + \\sum_{i=1}^{n} p_i\n$$\n$$\n\\beta_{post} = \\beta + \\mathbb{E}[F | \\{p_i\\}] = \\beta + n - \\sum_{i=1}^{n} p_i\n$$\nThe resulting posterior distribution for the stoichiometry parameter is:\n$$\n\\theta_{param} | \\{p_i\\} \\sim \\text{Beta}(\\alpha_{post}, \\beta_{post})\n$$\nA central credible interval at a confidence level of $1-\\gamma$ (here, $0.95$) is defined by the $\\gamma/2$ and $1-\\gamma/2$ quantiles of this posterior distribution. For a $0.95$ credible interval, we need the $0.025$ and $0.975$ quantiles. Let $F_{\\text{Beta}}^{-1}(\\cdot; a, b)$ be the percent point function (the inverse of the CDF) for a Beta distribution with shape parameters $a$ and $b$. The lower bound ($L$) and upper bound ($U$) of the interval are:\n$$\nL = F_{\\text{Beta}}^{-1}(0.025; \\alpha_{post}, \\beta_{post})\n$$\n$$\nU = F_{\\text{Beta}}^{-1}(0.975; \\alpha_{post}, \\beta_{post})\n$$\nThese values will be computed for each test case using numerical libraries.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.stats import beta as beta_dist\n\ndef solve():\n    \"\"\"\n    Solves the RNA modification stoichiometry problem for a suite of test cases.\n    \"\"\"\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        {\n            \"p_i\": [0.92, 0.87, 0.76, 0.61, 0.55, 0.33, 0.20, 0.10],\n            \"alpha\": 1.0,\n            \"beta\": 1.0\n        },\n        {\n            \"p_i\": [0.02, 0.03, 0.01, 0.04, 0.00],\n            \"alpha\": 0.5,\n            \"beta\": 0.5\n        },\n        {\n            \"p_i\": [1.0, 0.99, 1.0, 0.98, 1.0, 0.97],\n            \"alpha\": 1.0,\n            \"beta\": 9.0\n        },\n        {\n            \"p_i\": [0.3] * 50 + [0.7] * 50,\n            \"alpha\": 20.0,\n            \"beta\": 20.0\n        },\n        {\n            \"p_i\": [0.0, 1.0],\n            \"alpha\": 0.1,\n            \"beta\": 0.1\n        }\n    ]\n\n    results = []\n    \n    #\n    # The confidence level for the credible interval is 0.95.\n    # The quantiles are (1 - 0.95) / 2 and 1 - (1 - 0.95) / 2.\n    #\n    credible_interval_level = 0.95\n    lower_quantile = (1.0 - credible_interval_level) / 2.0\n    upper_quantile = 1.0 - lower_quantile\n\n    for case in test_cases:\n        p_i = np.array(case[\"p_i\"])\n        alpha_prior = case[\"alpha\"]\n        beta_prior = case[\"beta\"]\n\n        n = len(p_i)\n        sum_p_i = np.sum(p_i)\n\n        # 1. Calculate the point estimate of stoichiometry.\n        # This is the arithmetic mean of the per-read probabilities.\n        # It is the expectation of the sample stoichiometry theta = (1/n) * sum(Z_i).\n        point_estimate = sum_p_i / n if n > 0 else 0.0\n\n        # 2. Derive the posterior distribution and compute the credible interval.\n        # The posterior is approximated by a Beta distribution where the prior\n        # parameters are updated with the expected counts of modified (sum_p_i)\n        # and unmodified (n - sum_p_i) reads.\n        alpha_post = alpha_prior + sum_p_i\n        beta_post = beta_prior + (n - sum_p_i)\n\n        # 3. Compute the lower and upper bounds of the 95% central credible interval.\n        # This is done by finding the 0.025 and 0.975 quantiles of the posterior Beta distribution.\n        lower_bound = beta_dist.ppf(lower_quantile, alpha_post, beta_post)\n        upper_bound = beta_dist.ppf(upper_quantile, alpha_post, beta_post)\n\n        # Append the formatted results\n        results.extend([\n            round(point_estimate, 6),\n            round(lower_bound, 6),\n            round(upper_bound, 6)\n        ])\n\n    # Final print statement in the exact required format.\n    # e.g., [x1,y1,z1,x2,y2,z2,...]\n    formatted_results = [f\"{val:.6f}\" for val in results]\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```"
        }
    ]
}