## 引言
拷贝数变异（Copy Number Variations, CNVs）是人类基因组结构变异的重要组成部分，涉及大片段DNA序列的缺失、重复或更复杂的重排。这些变异深刻影响着基因功能和表达调控，是导致多种[遗传性疾病](@entry_id:273195)、发育障碍以及癌症发生发展的关键驱动因素。因此，开发能够准确、灵敏地从海量基因组数据中识别这些变异的计算方法，对于基础生物学研究和临床[精准医疗](@entry_id:152668)都具有至关重要的意义。

然而，从高通量测序（NGS）数据中检测CNV面临着巨大的挑战。原始测序信号是真实的生物学变异与由实验流程引入的各种技术噪声和系统性偏倚混合的产物。本文旨在解决这一核心问题：我们如何建立一套严谨的算法框架，以有效地“去伪存真”，从复杂的测[序数](@entry_id:150084)据中精确地解读出基因组的拷贝数状态？

为了系统性地解答这一问题，本文将分为三个核心部分。在“原理与机制”一章中，我们将深入剖析CNV检测的根本原理，探讨用于量化拷贝数的关键数据信号，并详细介绍为克服技术偏倚而设计的关键[数据预处理](@entry_id:197920)、归一化策略和[统计模型](@entry_id:755400)。接下来，在“应用与跨学科连接”一章中，我们将展示这些算法如何在[临床遗传学](@entry_id:260917)、精准肿瘤学和药物基因组学等领域发挥关键作用，将理论转化为改变患者诊疗的实际工具。最后，在“动手实践”部分，读者将有机会通过解决具体计算问题，亲手实现和应用这些核心算法。

现在，让我们从基础出发，深入探索从原始测[序数](@entry_id:150084)据推断拷贝数变异的计算原理与核心机制。

## 原理与机制

继前一章对[拷贝数变异](@entry_id:176528)（CNV）的生物学意义和临床重要性进行宏观介绍之后，本章将深入探讨检测CNV的计算原理和核心机制。我们的目标是建立一个坚实的理论框架，理解如何从原始的基因组测序数据中，通过一系列严谨的[统计建模](@entry_id:272466)和算法处理，最终推断出基因组上特定区段的拷贝数状态。这一过程的核心挑战在于，如何将微弱的生物信号从巨大的技术噪声中精确地分离出来。

### 从测序数据推断拷贝数的基本原理

基于高通量测序技术检测CNV的根本前提是：在理想情况下，测序读段（reads）在基因组上的分布密度与该区域DNA分子的拷贝数成正比。 换言之，一个发生拷贝数增加的区域，在测序文库中会贡献更多的DNA模板，因此我们期望捕获到更多的测序读段；反之，一个发生拷贝数删失的区域，则会表现出读段数量的相应减少。这一简单而深刻的原理构成了大多数CNV检测算法的基石。为了量化这一关系，我们主要依赖于以下几种关键的数据信号：

1.  **[读段深度](@entry_id:178601)（Read Depth, RD）**：这是最直接的信号。通过将基因组划分为成千上万个连续的窗口（bins），并统计落在每个窗口内的读段数量，我们可以获得一个沿染色体位置变化的“[读段深度](@entry_id:178601)”剖面。这个剖面直观地反映了基因组拷贝数的相对变化。

2.  **[B等位基因频率](@entry_id:164385)（B-Allele Frequency, BAF）**：在二倍体生物中，许多[单核苷酸多态性](@entry_id:173601)（SNP）位点是杂合的，即同时拥有一个参考等位基因（A）和一个备选等位基因（B）。在这些位点，支持B等位基因的读段所占的比例，即BAF，理论上应为 $0.5$。当拷贝数发生变化时，等位基因的平衡被打破，BA[F值](@entry_id:178445)会偏离 $0.5$，从而为拷贝数状态提供独立于[读段深度](@entry_id:178601)的证据。

3.  **裂读（Split Reads, SR）与异常配对读段（Discordant Read Pairs, RP）**：这些信号主要用于精确定位结构变异的断点。当一个读段跨越一个CNV的边界时，它可能会被“分裂”成两部分，分别比对到断点两侧，形成裂读。对于[双末端测序](@entry_id:272784)，如果一对读段之间的距离或方向与预期不符（例如，相距过远或方向相反），则构成了异常配对读段。这些信号是存在结构性重排的强力证据。

综合利用这些信号，我们便能构建一幅关于基因组结构的全景图。例如，在一个假设的 $200\,\mathrm{kb}$ 区域 $R_1$ 中，如果观测到平均[读段深度](@entry_id:178601)是正常[二倍体](@entry_id:268054)区域的 $1.5$ 倍，同时该区域内杂合SNP位点的BA[F值](@entry_id:178445)聚集在 $1/3$ 和 $2/3$ 附近，这便强烈指示该区域发生了一次重复事件，总拷贝数（CN）从 $2$ 变成了 $3$。相反，在另一个区域 $R_2$，若[读段深度](@entry_id:178601)与正常水平无异，但其边界处富集了大量的裂读和方向异常的读段对，则很可能指示了一次拷贝数中性的[结构变异](@entry_id:173359)，如倒位。

### 理想与现实：变异来源与技术偏倚

尽管基本原理清晰，但真实世界的测序数据远非理想。观测到的[读段深度](@entry_id:178601)信号实际上是**生物学变异**（我们真正关心的CNV）与多种**技术性变异**（噪声和系统性偏倚）混合的产物。成功检测CNV的关键，就在于精确地识别和校正这些技术性变异。

#### 理想模型

在最理想的情况下，我们可以将基因组划分为一系列窗口 $i$，并假设窗口 $i$ 内的读段起始位点计数 $X_i$ 服从**泊松分布（Poisson distribution）**，即 $X_i \sim \text{Poisson}(\lambda_i)$。其[期望值](@entry_id:150961)（或称速率参数） $\lambda_i$ 直接与该窗口的真实拷贝数 $c_i$ 和总测序深度成正比。

#### 现实世界的复杂性

然而，多种技术因素会系统性地扭曲 $\lambda_i$ 与 $c_i$ 之间的纯粹比例关系：

*   **GC含量偏倚（GC-Content Bias）**：在文库构建过程中，PCR扩增的效率以及测序过程本身，都对DNA片段的[GC含量](@entry_id:275315)敏感。通常，[GC含量](@entry_id:275315)过高或过低的区域测序效率较低，导致其[读段深度](@entry_id:178601)被系统性地低估。这种效应与真实的拷贝数无关，但若不加校正，会在[全基因组](@entry_id:195052)范围内制造出大量貌似缺失或重复的假象。 

*   **可比对性偏倚（Mappability Artifacts）**：基因组中存在大量重复序列区域（如[着丝粒](@entry_id:146562)、端粒、[节段性重复](@entry_id:200990)区）。源自这些区域的短读段由于序列不唯一，无法被精确地比对回其原始位置，或者[比对质量](@entry_id:170584)分很低。这导致低可比对性（low mappability）区域的有效读段计数系统性偏减，极易被误判为拷贝数删失。 

*   **PCR重复（PCR Duplicates）**：在PCR扩增步骤中，同一个DNA模板分子可能被多次复制。如果不加区分地计数所有这些读段，就会人为地夸大该区域的信号，导致读段计数的方差超出泊松分布的预期（即**过离散 (overdispersion)**），并可能产生假的扩增信号。 

*   **文库制备与批次效应（Library Preparation and Batch Effects）**：不同的样本、不同的实验批次或不同的测序通道之间，文库的产量和测序效率可能存在显著差异。例如，同一个样本在两个不同的测序通道上运行时，可能会观察到整体[读段深度](@entry_id:178601)存在 $1.3$ 倍的差异。如果不进行恰当的样本间归一化，这种纯粹的技术差异会被误解为大规模的生物学事件，如整条染色体的[非整倍性](@entry_id:137510)。 

### [数据预处理](@entry_id:197920)与归一化：驯服噪声

为了从混杂的原始信号中恢复真实的拷贝数信息，必须进行一系列精细的预处理和归一化步骤。其总体目标是尽可能地消除上述技术性偏倚，使得校正后的信号能更好地满足 $\mathbb{E}[X_i] \propto c_i$ 的理想模型。

#### 标准预处理流程

一个严谨的CNV检测流程始于对原始测[序数](@entry_id:150084)据的精细处理，主要包括以下步骤 ：
1.  **序列比对**：使用高精度的比对软件将测序[读段比对](@entry_id:265329)到[参考基因组](@entry_id:269221)上，并为每次比对给出一个**[比对质量](@entry_id:170584)分数（Mapping Quality, MAPQ）**。该分数以Phred标度量化了比对位置错误的概率。
2.  **过滤低质量比对**：移除MAPQ值较低的读段（例如， $Q  20$，对应 $1\%$ 的错误率），因为这些读段的位置不确定，会给后续的定量分析引入噪声。
3.  **标记和移除PCR重复**：识别并移除那些具有完全相同的起始、终止坐标和链方向的读段对，因为它们极有可能源于同一个原始DNA分子的PCR扩增产物。
4.  **基因组分箱（Binning）**：将基因组划分为固定宽度的窗口（例如 $1\,\mathrm{kb}$ 或 $10\,\mathrm{kb}$），并统计每个窗口内的有效读段数。

#### 偏倚校正的数学模型与策略

经过上述处理后，我们可以构建一个更精细的数学模型来描述窗口 $i$ 的期望读段数 $\lambda_i$ ：
$$ \lambda_i = S \cdot c_i \cdot w_i \cdot m_i^{(L)} \cdot h(g_i) $$
其中：
*   $c_i$ 是我们希望求解的真实拷贝数因子。
*   $w_i$ 是窗口宽度。
*   $m_i^{(L)}$ 是窗口 $i$ 的**可比对性分数**，代表该窗口内能够产生唯一比对的有效起始位点的比例。
*   $h(g_i)$ 是一个描述GC含量 $g_i$ 对读段数影响的偏倚函数。
*   $S$ 是一个全局尺度因子，与总测序深度相关。

校正的目标就是估计并移除 $m_i^{(L)}$ 和 $h(g_i)$ 的影响。

*   **可比对性校正**：低可比对性 $u_i$ (一个与 $m_i^{(L)}$ 相关的度量) 会导致观测读段数 $X_i$ 被低估。校正的逻辑是，将观测到的读段数进行“放大”，以补偿那些因无法唯一比对而“丢失”的信号。校正权重 $w_i$ 应为可比对性分数的倒数，即 $w_i = 1/u_i$。例如，一个可比对性为 $0.5$ 的区域，其期望读段数只有完全可比对区域的一半。因此，为了得到可比较的信号，应将其观测读段[数乘](@entry_id:155971)以 $2$。如果不进行此校正，一个真实的[二倍体](@entry_id:268054)、低可比对性区域（如窗口B: $u_B=0.5, X_B=55$；窗口C: $u_C=0.1, X_C=12$）与一个[期望值](@entry_id:150961)为 $100$ 的基线相比，会显示出极低的计数值，从而被错误地判断为删失事件，导致[假阳性率](@entry_id:636147)的急剧膨胀。

*   **GC含量校正**：通常通过对基因组中被认为是拷贝数中性的区域（例如，整个基因组的大部分常染色质区域）进行[回归分析](@entry_id:165476)来实现。通过拟合[读段深度](@entry_id:178601)与[GC含量](@entry_id:275315)之间的关系（例如，使用LOESS[局部回归](@entry_id:637970)），可以为每个[GC含量](@entry_id:275315)值估计一个校正因子，然后用该因子调整每个窗口的读段计数。

*   **基于参考队列的归一化（Cohort-based Normalization）**：对于靶向测序（如[全外显子组测序](@entry_id:141959)，WES），由于捕获效率在不同外显子之间存在巨大差异，简单的GC和可比对性校正往往不够。此时，一种更强大的策略是利用一个“参考队列”，即一组同时处理的、假定为拷贝数正常的样本。通过对这个队列的数据进行建模（例如，使用奇异值分解(SVD)或负二项[广义线性模型](@entry_id:171019)(NB-GLM)），可以经验性地学习到每个目标区域（如外显子）固有的、系统性的技术偏倚（即模型中的 $\beta_e$ 项）。然后，将待测样本的读段数与这个从参考队列中建立的“期望剖面”进行比较，从而获得一个更干净的、方差更稳定的信号。这种方法还能有效缓解因实验批次不同而引入的[批次效应](@entry_id:265859)。 

### 信号解读与基因组分段

经过一系列复杂的预处理和归一化之后，我们得到了一条沿着染色体变化的、相对“干净”的信号。下一步是如何从这条连续但仍有噪声的信号中，识别出离散的、具有生物学意义的CNV区段。

#### 对数比率（Log-Ratio）信号

为了方便比较和可视化，校正后的[读段深度](@entry_id:178601)通常被转换为相对于二倍体基线的**对数比率（log-ratio）**。计算公式为 $L_i = \log_2(\frac{\text{Observed}_i}{\text{Expected}_i})$。在这个变换下：
*   拷贝数正常的区域，其 $L_i$ 值在 $0$ 附近波动。
*   拷贝数增加的区域（如扩增），其 $L_i$ 值为正。
*   拷贝数减少的区域（如删失），其 $L_i$ 值为负。

例如，一个非杂合的单拷贝删失（CN=1），其理论log-ratio为 $\log_2(1/2) = -1$。一个单拷贝扩增（CN=3），其理论log-ratio为 $\log_2(3/2) \approx 0.58$。

#### 等位基因特异性分析的力量

单独使用[读段深度](@entry_id:178601)信号有时会产生歧义。例如，信号的降低可能源于真实的拷贝数删失，也可能源于前面提到的未完全校正的技术偏倚。此时，**[B等位基因频率](@entry_id:164385)（BAF）**提供了至关重要的正交信息。通过联合分析[读段深度](@entry_id:178601)和BAF，我们可以极大地提高CNV检测的准确性和分辨率，特别是对于**等位基因特异性拷贝数（Allele-Specific Copy Number, ASCN）**的推断。

考虑以下几种情况的典型信号特征  ：
*   **正常[二倍体](@entry_id:268054) (CN=2, AB)**: Log-ratio $\approx 0$, BAF $\approx 0.5$.
*   **杂合性删失 (CN=1, A或B)**: Log-ratio $\approx -1$, BAF $\approx 0$ 或 $1$. 这种情况也称为**[杂合性丢失](@entry_id:184588)（Loss of Heterozygosity, LOH）**。
*   **单拷贝扩增 (CN=3, AAB或ABB)**: Log-ratio $\approx 0.58$, BAF $\approx 1/3$ 或 $2/3$.
*   **拷贝数中性LOH (CN=2, AA或BB)**: Log-ratio $\approx 0$, BAF $\approx 0$ 或 $1$.

通过构建一个联合模型（例如，[隐马尔可夫模型](@entry_id:141989) HMM），我们可以区分这些不同的状态。例如，仅凭BA[F值](@entry_id:178445)接近 $0$ 或 $1$ 无法区分杂合性删失和拷贝数中性LOH，但前者同时伴随着log-ratio的显著下降，而后者log-ratio保持在 $0$ 附近。这种联合分析是现代CNV检测算法，尤其是在[癌症基因组学](@entry_id:143632)中，不可或缺的一环。

#### 基因组分段：从噪声点到离散事件

最后一步是将沿基因组的、带有噪声的log-ratio（以及BAF）散点图，划分成若干个**拷贝数恒定的连续片段（piecewise-constant segments）**。这个过程在统计信号处理中被称为**[变点检测](@entry_id:634570)（change-point detection）**。其目标是找到基因组上的精确位置，在这些位置上，信号的均值发生了统计上显著的变化。

**循环二元分割（Circular Binary Segmentation, CBS）**是实现这一目标的最经典和广泛应用的算法之一。 其核心思想如下：
1.  对于任意一段待分析的染色体序列，CBS首先将其视为一个环形，即首尾相连。这样做是为了避免在序列两端进行统计检验时产生边界效应。
2.  然后，算法会遍历所有可能的子片段（由起点 $s$ 和终点 $t$ 定义），并计算每个子片段的均值与该子片段之外所有点的均值之间的差异。这个差异通常用一个类似于t检验的统计量来衡量。
3.  CBS找到使该差异统计量达到最大值的那个子片段。这个“最不寻常”的子片段是潜在的CNV区域的最佳候选。
4.  为了评估这个最大差异是否具有[统计显著性](@entry_id:147554)（即不仅仅是随机噪声所致），算法通过对数据进行多次随机重排（permutation）来构建一个零假设下的统计量分布，并计算观测到的最大差异的p值。
5.  如果p值显著，算法就接受这两个变点（即最大差异子片段的起、终点），并将原始的[线性序](@entry_id:146781)列在这两个点处分割成三段。然后，对新产生的子片段重复（递归地）执行上述整个过程。
6.  这个递归分割的过程持续进行，直到在任何子片段中都无法找到更多统计上显著的变点为止。最终，整个染色体就被划分成了一系列拷贝数均一的区段。

### 高阶主题与生物学背景

在真实生物样本中，情况往往更为复杂。细胞群体的异质性是CNV检测中一个普遍而重要的挑战。

#### [嵌合体](@entry_id:264354)与亚克隆

在许多生物学场景中，并非样本中的所有细胞都携带相同的CNV。这种仅存在于一部分细胞中的变异被称为**嵌合（mosaic）**或**亚克隆（subclonal）**变异。

假设一个拷贝数删失（$C_{-} = 1$）事件存在于比例为 $f$ 的细胞中，而其余 $1-f$ 比例的细胞在该位点是正常的（$C_0=2$）。由于我们进行的是**宏测序（bulk sequencing）**，得到的信号是所有细胞贡献的DNA的平均结果。因此，观测到的平均拷贝数 $\bar{C}$ 是一个线性混合体：
$$ \bar{C} = f \cdot C_{-} + (1 - f) \cdot C_{0} = f \cdot 1 + (1 - f) \cdot 2 = 2 - f $$
对应的log-ratio信号为：
$$ L = \log_{2}\! \left(\frac{\bar{C}}{C_{0}}\right) = \log_{2}\! \left(\frac{2-f}{2}\right) = \log_{2}\! \left(1 - \frac{f}{2}\right) $$
可以看到，当 $0 \lt f \lt 1$ 时, log-ratio值 $L$ 介于 $-1$ (对应于 $f=1$ 的克隆性删失) 和 $0$ (对应于 $f=0$ 的无删失) 之间。这意味着嵌合现象会**削弱信号的振幅**，使其更接近于背景噪声，从而增加了检测的难度。其根本原因在于，在进行非线性的对数变换之前，正常细胞的信号“稀释”了变异细胞的信号。

#### 肿瘤基因组学应用：纯度与倍性

[细胞异质性](@entry_id:262569)在癌症研究中尤为突出。肿瘤样本通常是癌细胞与各种正常细胞（如免疫细胞、基质细胞）的混合物。癌细胞本身的基因组也可能高度不稳定和异质。为了准确解读肿瘤的CNV，必须考虑以下两个关键参数 ：

*   **肿瘤纯度（Tumor Purity, $p$）**：指样本中癌细胞所占的比例。
*   **肿瘤倍性（Tumor Ploidy, $P_{\mathrm{tumor}}$）**：指癌细胞基因组的平均拷贝数。

与嵌合体类似，观测到的绝对拷贝数 $C_{\mathrm{obs}}$ 是正常细胞（拷贝数为2）和癌细胞（拷贝数为 $C_{\mathrm{tumor}}$）的线性混合：
$$ C_{\mathrm{obs}} = (1 - p) \cdot 2 + p \cdot C_{\mathrm{tumor}} $$
这个简单的公式揭示了一个深刻的难题：我们只有一个观测值 $C_{\mathrm{obs}}$，却需要求解两个未知数 $p$ 和 $C_{\mathrm{tumor}}$。这意味着从单一的信号振幅推断拷贝数状态存在固有的**模糊性**。例如，一个观测到的绝对拷贝数为 $2.5$ 的区段，可能对应于一个纯度为 $0.5$、癌细胞拷贝数为 $3$ 的样本，也可能对应于一个纯度为 $0.25$、癌细胞拷贝数为 $4$ 的样本，因为：
$$ (1-0.5)\cdot2 + 0.5\cdot3 = 2.5 $$
$$ (1-0.25)\cdot2 + 0.25\cdot4 = 2.5 $$
这种不确定性是肿瘤CNV分析中的一个核心挑战。为了解决这个问题，先进的算法通常需要联合利用BAF[等位基因频率](@entry_id:146872)信息，通过全局优化来同时估计肿瘤纯度、倍性以及各个区段的等位基因特异性拷贝数。