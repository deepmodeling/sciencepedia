{
    "hands_on_practices": [
        {
            "introduction": "在表观遗传学研究中，精确量化不同类型的DNA修饰至关重要。传统的亚硫酸氢盐测序（Bisulfite Sequencing, BS）无法区分功能可能截然相反的5-甲基胞嘧啶（5mC）和5-羟甲基胞嘧啶（5hmC）。本练习将引导你应用氧化亚硫酸氢盐测序（oxBS）这一巧妙的实验技术，通过结合两种测序数据，将原始的测序读数转化为对这些关键表观遗传标记的精确定量估计。这个过程完美地展示了如何利用基础的概率论和统计推断，从复杂的实验数据中解码出清晰的生物学信号。",
            "id": "4337409",
            "problem": "一个临床基因组学实验室应用亚硫酸氢盐测序 (BS) 和氧化亚硫酸氢盐测序 (oxBS) 来量化一个药理基因组学相关基因启动子中单个胞嘧啶-磷酸-鸟嘌呤 (CpG) 位点的胞嘧啶修饰。在 BS 中，5-甲基胞嘧啶和 5-羟甲基胞嘧啶受到保护并被读取为胞嘧啶，而未修饰的胞嘧啶则被转化并读取为胸腺嘧啶。在 oxBS 中，5-羟甲基胞嘧啶被选择性地氧化并随后被转化，因此受保护的胞嘧啶检出仅代表 5-甲基胞嘧啶。设该位点 5-甲基胞嘧啶的真实比例为 $\\theta_{m}$，5-羟甲基胞嘧啶的真实比例为 $\\theta_{h}$，未修饰胞嘧啶的真实比例为 $\\theta_{u}$，且 $\\theta_{m} + \\theta_{h} + \\theta_{u} = 1$。假设转化和氧化化学反应是理想的，并且各次读取是独立的。\n\n在此 CpG 位点，实验室观察到以下读数计数：\n- BS: 总读数为 $n_{\\mathrm{BS}} = 120$，其中 $x_{\\mathrm{BS}} = 90$ 被检出为胞嘧啶，$n_{\\mathrm{BS}} - x_{\\mathrm{BS}} = 30$ 被检出为胸腺嘧啶。\n- oxBS: 总读数为 $n_{\\mathrm{ox}} = 100$，其中 $x_{\\mathrm{ox}} = 60$ 被检出为胞嘧啶，$n_{\\mathrm{ox}} - x_{\\mathrm{ox}} = 40$ 被检出为胸腺嘧啶。\n\n将每个实验的胞嘧啶检出计数建模为一个二项随机变量，其成功概率等于上述化学反应条件下相应受保护的组分比例。从这些定义和二项模型出发，推导此 CpG 位点 5-羟甲基胞嘧啶比例 $\\theta_{h}$ 的最大似然估计，以及一个基于独立二项分布比例之差的大样本正态近似的双侧 $0.95$ 水平置信区间。将最终数值结果以小数形式表示，点估计和两个置信界限均四舍五入至四位有效数字。在最终答案中，按 $\\hat{\\theta}_{h}$、下界、上界的顺序报告这三个数。",
            "solution": "问题要求根据亚硫酸氢盐测序 (BS) 和氧化亚硫酸氢盐测序 (oxBS) 实验的数据，推导特定 CpG 位点上 5-羟甲基胞嘧啶比例 $\\theta_h$ 的最大似然估计 (MLE) 和一个 $0.95$ 水平的置信区间。\n\n首先，我们按规定将每个实验的概率模型形式化。每个实验中的胞嘧啶检出数被建模为一个二项随机变量。设 $p_{\\mathrm{BS}}$ 为在 BS 实验中观测到胞嘧啶的概率，$p_{\\mathrm{ox}}$ 为在 oxBS 实验中观测到胞嘧啶的概率。\n\n根据问题描述：\n在 BS 中，5-甲基胞嘧啶（比例 $\\theta_m$）和 5-羟甲基胞嘧啶（比例 $\\theta_h$）都免于转化并被读取为胞嘧啶。因此，检出为胞嘧啶的概率是这些比例的总和：\n$$p_{\\mathrm{BS}} = \\theta_{m} + \\theta_{h}$$\n在 oxBS 中，5-羟甲基胞嘧啶被氧化和转化，而只有 5-甲基胞嘧啶受到保护。因此，检出为胞嘧啶的概率是：\n$$p_{\\mathrm{ox}} = \\theta_{m}$$\n未修饰胞嘧啶的比例 $\\theta_u$ 通过约束条件 $\\theta_{m} + \\theta_{h} + \\theta_{u} = 1$ 相关联。在 BS 中读取为胸腺嘧啶的概率是 $1 - p_{\\mathrm{BS}} = \\theta_u$，在 oxBS 中是 $1 - p_{\\mathrm{ox}} = \\theta_h + \\theta_u$。\n\n设 $X_{\\mathrm{BS}}$ 和 $X_{\\mathrm{ox}}$ 分别为 BS 和 oxBS 实验中胞嘧啶检出数的随机变量。模型如下：\n$$X_{\\mathrm{BS}} \\sim \\mathrm{Binomial}(n_{\\mathrm{BS}}, p_{\\mathrm{BS}})$$\n$$X_{\\mathrm{ox}} \\sim \\mathrm{Binomial}(n_{\\mathrm{ox}}, p_{\\mathrm{ox}})$$\n其中观测数据为 $n_{\\mathrm{BS}} = 120$，$x_{\\mathrm{BS}} = 90$，$n_{\\mathrm{ox}} = 100$，$x_{\\mathrm{ox}} = 60$。\n\n基于观测值 $x$，二项分布 $\\mathrm{Binomial}(n, p)$ 的成功概率 $p$ 的最大似然估计由 $\\hat{p} = \\frac{x}{n}$ 给出。将此应用于我们的两个独立实验，我们得到 $p_{\\mathrm{BS}}$ 和 $p_{\\mathrm{ox}}$ 的最大似然估计：\n$$\\hat{p}_{\\mathrm{BS}} = \\frac{x_{\\mathrm{BS}}}{n_{\\mathrm{BS}}} = \\frac{90}{120} = 0.75$$\n$$\\hat{p}_{\\mathrm{ox}} = \\frac{x_{\\mathrm{ox}}}{n_{\\mathrm{ox}}} = \\frac{60}{100} = 0.60$$\n\n我们主要感兴趣的参数是 $\\theta_h$。我们可以将 $\\theta_h$ 表示为 $p_{\\mathrm{BS}}$ 和 $p_{\\mathrm{ox}}$ 的函数：\n$$\\theta_{h} = (\\theta_{m} + \\theta_{h}) - \\theta_{m} = p_{\\mathrm{BS}} - p_{\\mathrm{ox}}$$\n根据最大似然估计的不变性，参数函数的最大似然估计等于在各参数的最大似然估计值上计算该函数。因此，$\\theta_h$ 的最大似然估计是：\n$$\\hat{\\theta}_{h} = \\hat{p}_{\\mathrm{BS}} - \\hat{p}_{\\mathrm{ox}}$$\n代入数值：\n$$\\hat{\\theta}_{h} = 0.75 - 0.60 = 0.15$$\n\n接下来，我们为 $\\theta_h$ 构建一个双侧 $0.95$ 水平的置信区间。问题指定对两个独立二项分布比例之差使用大样本正态近似。这种置信区间的一般形式是：\n点估计 ± (临界值) × (标准误)\n点估计是 $\\hat{\\theta}_{h} = \\hat{p}_{\\mathrm{BS}} - \\hat{p}_{\\mathrm{ox}}$。该估计的标准误 $\\mathrm{SE}(\\hat{\\theta}_h)$ 是从两个独立样本比例之差的方差推导出来的。\n$$\\mathrm{Var}(\\hat{\\theta}_h) = \\mathrm{Var}(\\hat{p}_{\\mathrm{BS}} - \\hat{p}_{\\mathrm{ox}}) = \\mathrm{Var}(\\hat{p}_{\\mathrm{BS}}) + \\mathrm{Var}(\\hat{p}_{\\mathrm{ox}})$$\n样本比例 $\\hat{p}$ 的方差为 $\\frac{p(1-p)}{n}$。我们用样本比例 $\\hat{p}$ 代替真实比例 $p$ 来估计此方差。估计的标准误为：\n$$\\widehat{\\mathrm{SE}}(\\hat{\\theta}_h) = \\sqrt{\\frac{\\hat{p}_{\\mathrm{BS}}(1-\\hat{p}_{\\mathrm{BS}})}{n_{\\mathrm{BS}}} + \\frac{\\hat{p}_{\\mathrm{ox}}(1-\\hat{p}_{\\mathrm{ox}})}{n_{\\mathrm{ox}}}}$$\n代入数值：\n$$\\widehat{\\mathrm{SE}}(\\hat{\\theta}_h) = \\sqrt{\\frac{0.75(1-0.75)}{120} + \\frac{0.60(1-0.60)}{100}}$$\n$$\\widehat{\\mathrm{SE}}(\\hat{\\theta}_h) = \\sqrt{\\frac{0.75 \\times 0.25}{120} + \\frac{0.60 \\times 0.40}{100}} = \\sqrt{\\frac{0.1875}{120} + \\frac{0.24}{100}}$$\n$$\\widehat{\\mathrm{SE}}(\\hat{\\theta}_h) = \\sqrt{0.0015625 + 0.0024} = \\sqrt{0.0039625} \\approx 0.062948$$\n\n对于一个 $0.95$ 水平的置信区间，置信水平为 $1-\\alpha = 0.95$，因此 $\\alpha = 0.05$。临界值是对应于上尾概率 $\\alpha/2 = 0.025$ 的 z-分数，即 $z_{1-\\alpha/2} = z_{0.975}$。从标准正态分布可知，该值为 $z_{0.975} \\approx 1.96$。\n\n误差范围 (ME) 为：\n$$\\mathrm{ME} = z_{0.975} \\times \\widehat{\\mathrm{SE}}(\\hat{\\theta}_h) \\approx 1.96 \\times 0.062948 \\approx 0.123378$$\n$\\theta_h$ 的置信区间为 $\\hat{\\theta}_{h} \\pm \\mathrm{ME}$：\n$$0.15 \\pm 0.123378$$\n下界为：\n$$L = 0.15 - 0.123378 = 0.026622$$\n上界为：\n$$U = 0.15 + 0.123378 = 0.273378$$\n\n最后，我们按要求将点估计和置信界限四舍五入到四位有效数字。\n- 点估计：$\\hat{\\theta}_{h} = 0.15$。保留四位有效数字，为 $0.1500$。\n- 下界：$0.026622...$ 四舍五入为 $0.02662$。\n- 上界：$0.273378...$ 四舍五入为 $0.2734$。\n\n5-羟甲基胞嘧啶比例的最大似然估计为 $\\hat{\\theta}_{h} \\approx 0.1500$，其 $0.95$ 水平的置信区间约为 $(0.02662, 0.2734)$。\n其他比例的估计和区间可以类似地推导得出：$\\hat{\\theta}_m = \\hat{p}_{\\mathrm{ox}} = 0.6000$ 且 $\\hat{\\theta}_u = 1 - \\hat{p}_{\\mathrm{BS}} = 1 - 0.75 = 0.2500$。所有估计值均为非负数，这与它们作为比例的定义是一致的。",
            "answer": "$$\\boxed{\\begin{pmatrix} 0.1500  0.02662  0.2734 \\end{pmatrix}}$$"
        },
        {
            "introduction": "一旦我们能够量化单个样本的甲基化水平，下一个核心科学问题便是比较不同组别（例如，疾病组与对照组）之间是否存在显著差异。然而，由于生物学重复和技术重复之间存在额外的变异，简单的统计检验（如卡方检验或t检验）直接应用于测序数据时，往往会产生大量假阳性结果，这一现象被称为“过度离散”（overdispersion）。本练习将指导你构建一个更稳健的统计模型——贝塔-二项分布检验——来解决此问题，这是在全基因组亚硫酸氢盐测序（WGBS）数据分析中准确识别差异甲基化区域的基石 。",
            "id": "4337386",
            "problem": "您正在为用于精准肿瘤学队列的全基因组亚硫酸氢盐测序数据设计一种用于差异性DNA甲基化的位点特异性检验。对于每个胞嘧啶-磷酸-鸟嘌呤（CpG）位点 $s \\in \\{1,\\dots,m\\}$，对于分配到组 $g \\in \\{0,1\\}$（对照组 $g=0$ 和病例组 $g=1$）的每个样本 $j$，您观察到在 $n_{sj}$ 个总读数中有 $y_{sj}$ 个甲基化读数。生物和技术异质性在重复样本中引起了超二项变异，这必须建模为过度离散。您必须在每个CpG位点推导出一个考虑了过度离散的、有效的基于似然的假设检验，然后描述如何使用 Benjamini–Hochberg (BH) 程序来控制 $m$ 个位点上的错误发现率（FDR）。您的推导应从亚硫酸氢盐读数的二项抽样的基本定义和一个成熟的过度离散模型开始；它应明确说明原假设和备择假设、检验统计量的形式、如何获得其零分布，以及一个有原则的多重检验控制程序。\n\n哪个选项给出了这样一种贝塔-二项检验的正确、自洽的推导，以及BH FDR控制的正确纲要？\n\nA. 将 $y_{sj} \\mid p_{sg}$ 建模为 $\\mathrm{Binomial}(n_{sj}, p_{sg})$，其中 $p_{sg}$ 是位点-组特异性的甲基化比例。为捕捉生物学重复样本间的过度离散，令 $p_{sg} \\sim \\mathrm{Beta}(\\alpha_{g}, \\beta_{g})$。那么 $y_{sj}$ 的边际分布是贝塔-二项分布，其概率质量函数为\n$$\n\\Pr(Y=y \\mid n,\\alpha,\\beta) \\;=\\; \\binom{n}{y} \\frac{B(y+\\alpha,\\,n-y+\\beta)}{B(\\alpha,\\beta)},\n$$\n其中 $B(\\cdot,\\cdot)$ 是贝塔函数。在位点 $s$，定义原假设 $H_{0}$ 为跨组共享参数，$H_{0}\\!:\\,(\\alpha_{0},\\beta_{0})=(\\alpha_{1},\\beta_{1})=(\\alpha,\\beta)$，备择假设为 $H_{1}\\!:\\,(\\alpha_{0},\\beta_{0}) \\neq (\\alpha_{1},\\beta_{1})$。在参数向量 $\\theta$ 下的位点特异性对数似然是所有样本的贝塔-二项对数概率之和。分别在 $H_{0}$ 和 $H_{1}$ 下通过数值最大化获得最大似然估计 $\\widehat{\\theta}_{0}$ 和 $\\widehat{\\theta}_{1}$。使用似然比统计量\n$$\nT_{s} \\;=\\; 2\\Big(\\ell_{1,s}(\\widehat{\\theta}_{1}) - \\ell_{0,s}(\\widehat{\\theta}_{0})\\Big),\n$$\n在 $H_{0}$ 下，该统计量渐近服从自由度为2的 $\\chi^{2}$ 分布，因为 $H_{1}$ 增加了2个自由参数。计算位点特异性p值 $p_{s}=\\Pr(\\chi^{2}_{2}\\ge T_{s})$。为了在水平 $q$ 控制FDR，收集所有 $m$ 个位点特异性p值，将它们排序为 $p_{(1)}\\le \\cdots \\le p_{(m)}$，找到满足 $p_{(k)} \\le (k/m)\\,q$ 的最大 $k$，并宣称具有最小 $k$ 个p值的位点是显著的。效应大小可以由组均值 $\\mu_{g}=\\alpha_{g}/(\\alpha_{g}+\\beta_{g})$ 来概括。\n\nB. 在每组内汇总样本的计数，并在每个位点检验单个二项比例差异，不考虑过度离散：$Y_{s0}=\\sum_{j:g=0} y_{sj}$（总数为 $N_{s0}=\\sum_{j:g=0} n_{sj}$）对 $Y_{s1}=\\sum_{j:g=1} y_{sj}$（总数为 $N_{s1}=\\sum_{j:g=1} n_{sj}$）。使用合并正态近似来处理比例差异，从而获得每个位点的z检验p值。通过宣称p值满足 $p_{s} \\le q/m$ 的位点是显著的来控制多重性。\n\nC. 将甲基化读数视为具有暴露偏移量的泊松计数，且不考虑过度离散：$y_{sj} \\sim \\mathrm{Poisson}(n_{sj}\\lambda_{g})$，并使用来自具有对数连接函数的泊松广义线性模型的偏差检验来检验 $H_{0}\\!:\\,\\lambda_{0}=\\lambda_{1}$。使用得到的偏差p值，并应用相同的每个假设的截断值 $p_{s} \\le q$ 来控制FDR。\n\nD. 使用贝塔-二项模型来模拟过度离散，但在两个假设下都假设一个共同的离散度。用均值 $\\mu_{g} \\in (0,1)$ 和共享的过度离散度 $\\rho \\in (0,1)$ 来参数化每个组 $g$。检验 $H_{0}\\!:\\,\\mu_{0}=\\mu_{1}$（共享 $\\rho$）对 $H_{1}\\!:\\,\\mu_{0}\\neq \\mu_{1}$（共享 $\\rho$），使用似然比检验，其渐近服从自由度为1的 $\\chi^{2}$ 分布。对于多重检验，对p值进行排序，并宣称满足 $p_{(k)} \\le q/(m-k+1)$ 的位点是显著的。\n\n只有一个选项是完全正确的。",
            "solution": "用户希望对问题陈述进行批判性验证，然后对解决方案进行严谨的推导，并对所有提供的选项进行评估。\n\n### 问题验证\n\n**第一步：提取已知条件**\n-   **领域**：全基因组亚硫酸氢盐测序（WGBS）数据中差异性DNA甲基化的统计检验。\n-   **数据**：对于每个CpG位点 $s \\in \\{1,\\dots,m\\}$ 和组 $g \\in \\{0,1\\}$（对照组和病例组）中的样本 $j$，我们观察到 $y_{sj}$（甲基化读数数量）和 $n_{sj}$（总读数）。\n-   **核心约束**：模型必须考虑生物学重复样本间的超二项变异（过度离散）。\n-   **任务**：\n    1.  推导一个有效的基于似然的假设检验，该检验考虑了过度离散。\n    2.  描述使用 Benjamini–Hochberg (BH) 程序控制所有 $m$ 个位点上的错误发现率（FDR）的方法。\n    3.  推导必须源于基本原理：二项抽样和成熟的过度离散模型。\n    4.  推导必须明确说明：原假设和备择假设、检验统计量、其零分布和多重检验程序。\n\n**第二步：使用提取的已知条件进行验证**\n-   **科学依据**：该问题在统计基因组学和生物信息学领域有坚实的基础。将WGBS数据描述为总读数中的甲基化读数计数（$n_{sj}$ 中的 $y_{sj}$）是标准做法。由于生物和技术因素，此类数据显示出过度离散（超二项变异）这一观察，是一个关键且普遍承认的特征，必须加以处理才能进行有效推断。使用像贝塔-二项模型这样的分层模型是处理这种过度离散的经典方法。Benjamini-Hochberg 程序是控制高通量基因组学实验中错误发现率的标准方法。问题陈述在科学上和统计上都是合理的。\n-   **适定性**：该问题是适定的。它清楚地定义了数据结构、核心统计挑战（过度离散）、推断目标（差异甲基化的假设检验），以及有效解决方案所需的组成部分（模型、假设、检验统计量、零分布、FDR控制）。存在一个唯一且标准的统计框架来解决此问题。\n-   **客观性**：语言精确、技术性强，没有任何主观性或模糊性。\n\n**缺陷清单评估**：\n1.  **科学或事实上的不健全**：无。前提在事实上是正确的。\n2.  **不可形式化或不相关**：无。该问题是一个形式化的统计任务。\n3.  **不完整或矛盾的设置**：无。该问题提供了推导所需统计程序的所有必要概念组件。\n4.  **不切实际或不可行**：无。所描述的分析是现代计算生物学中的一项常规任务。\n5.  **不适定或结构不良**：无。存在一个标准的、稳定的解决方案。\n6.  **伪深刻、琐碎或同义反复**：无。该问题涉及非平凡的统计建模（分层模型、似然理论）和多重检验理论。\n7.  **超出科学可验证性**：无。这些方法是标准的和可验证的。\n\n**第三步：结论与行动**\n问题陈述是**有效的**。用户对完整推导和选项评估的要求将得到满足。\n\n### 解题推导\n\n该问题要求一个位点特异性的差异甲基化假设检验，该检验要考虑过度离散，并随后进行FDR控制。\n\n**1. 建模过度离散的二项数据**\n在单个CpG位点 $s$ 和单个样本 $j$ 中，给定总读数 $n_{sj}$ 和真实甲基化比例 $p_{sj}$，甲基化读数 $y_{sj}$ 的数量适合用二项分布来建模：\n$$ y_{sj} \\mid p_{sj} \\sim \\mathrm{Binomial}(n_{sj}, p_{sj}) $$\n问题指出存在过度离散，这意味着比例 $p_{sj}$ 在一个组 $g$ 内不是恒定的。相反，它们根据某个分布从一个样本到另一个样本变化。对比例分布进行建模的一个标准且有原则的选择是贝塔分布。对于给定的位点 $s$，我们假设对于组 $g$ 中的所有样本 $j$，比例 $p_{sj}$ 是从一个由形状参数 $\\alpha_{sg}$ 和 $\\beta_{sg}$ 参数化的共同贝塔分布中抽取的：\n$$ p_{sj} \\sim \\mathrm{Beta}(\\alpha_{sg}, \\beta_{sg}), \\quad \\text{对于 } g \\text{ 组中的 } j $$\n这种分层结构（二项数据模型，比例上的贝塔先验）为观测计数 $y_{sj}$ 导出了一个边际分布，称为贝塔-二项分布。其概率质量函数（PMF）通过对潜在比例 $p$ 进行积分来推导：\n$$ \\Pr(Y=y \\mid n, \\alpha, \\beta) = \\int_0^1 \\Pr(Y=y \\mid n, p) \\cdot f(p \\mid \\alpha, \\beta) \\, dp $$\n$$ = \\int_0^1 \\left[ \\binom{n}{y} p^y (1-p)^{n-y} \\right] \\left[ \\frac{p^{\\alpha-1} (1-p)^{\\beta-1}}{B(\\alpha, \\beta)} \\right] \\, dp $$\n$$ = \\binom{n}{y} \\frac{1}{B(\\alpha, \\beta)} \\int_0^1 p^{y+\\alpha-1} (1-p)^{n-y+\\beta-1} \\, dp $$\n该积分是贝塔函数 $B(y+\\alpha, n-y+\\beta)$ 的定义。因此，\n$$ \\Pr(Y=y \\mid n, \\alpha, \\beta) = \\binom{n}{y} \\frac{B(y+\\alpha, n-y+\\beta)}{B(\\alpha, \\beta)} $$\n\n**2. 假设检验框架**\n我们想在位点 $s$ 检验组0（对照组）和组1（病例组）之间甲基化的差异。这种差异由底层贝塔分布的参数捕捉。\n\n-   **原假设 ($H_0$)**：两组的甲基化分布相同。这意味着对于一个未公开的位点 $s$，贝塔分布的参数是相同的：\n    $$ H_{0,s}: (\\alpha_{s0}, \\beta_{s0}) = (\\alpha_{s1}, \\beta_{s1}) $$\n-   **备择假设 ($H_1$)**：甲基化分布不同。这意味着参数集不相同：\n    $$ H_{1,s}: (\\alpha_{s0}, \\beta_{s0}) \\neq (\\alpha_{s1}, \\beta_{s1}) $$\n\n**3. 似然比检验（LRT）**\n作为一种基于似然的检验，LRT是自然的选择。对于给定的位点 $s$，对数似然是所有样本的贝塔-二项分布的对数PMF之和。\n-   在 $H_1$ 下，我们为组0拟合独立的参数 $(\\alpha_{s0}, \\beta_{s0})$，为组1拟合独立的参数 $(\\alpha_{s1}, \\beta_{s1})$。最大化后的对数似然是 $\\ell_{1,s}(\\widehat{\\theta}_1)$，其中 $\\widehat{\\theta}_1 = (\\widehat{\\alpha}_{s0}, \\widehat{\\beta}_{s0}, \\widehat{\\alpha}_{s1}, \\widehat{\\beta}_{s1})$ 是最大似然估计（MLEs）。总参数数量为4。\n-   在 $H_0$ 下，我们为所有样本拟合一组共享的参数 $(\\alpha_s, \\beta_s)$。最大化后的对数似然是 $\\ell_{0,s}(\\widehat{\\theta}_0)$，其中 $\\widehat{\\theta}_0 = (\\widehat{\\alpha}_s, \\widehat{\\beta}_s)$ 是MLEs。总参数数量为2。\n\n位点 $s$ 的LRT统计量为：\n$$ T_s = 2 \\left( \\ell_{1,s}(\\widehat{\\theta}_1) - \\ell_{0,s}(\\widehat{\\theta}_0) \\right) $$\n根据威尔克斯定理，在 $H_0$ 下，$T_s$ 渐近服从卡方（$\\chi^2$）分布。自由度（$df$）是备择模型和零模型之间自由参数数量的差。这里，$df = 4 - 2 = 2$。\n位点 $s$ 的p值则计算为 $p_s = \\Pr(\\chi^2_{2} \\ge T_s)$。\n\n**4. 多重检验校正：Benjamini-Hochberg (BH) 程序**\n我们执行 $m$ 个独立或弱相关的检验。为了将错误发现率（FDR）控制在目标水平 $q$，我们应用BH程序：\n1.  收集所有 $m$ 个位点的p值：$p_1, p_2, \\dots, p_m$。\n2.  将这些p值按升序排序：$p_{(1)} \\le p_{(2)} \\le \\dots \\le p_{(m)}$。\n3.  找到满足 $p_{(k)} \\le \\frac{k}{m} q$ 的最大整数 $k$。\n4.  宣称与p值 $p_{(1)}, \\dots, p_{(k)}$ 对应的CpG位点是统计上显著的（即差异甲基化的）。\n\n### 逐项分析\n\n**A. 将 $y_{sj} \\mid p_{sg}$ 建模为 $\\mathrm{Binomial}(n_{sj}, p_{sg})$，其中 $p_{sg}$ 是位点-组特异性的甲基化比例。为捕捉生物学重复样本间的过度离散，令 $p_{sg} \\sim \\mathrm{Beta}(\\alpha_{g}, \\beta_{g})$。边际分布... 于是为贝塔-二项... 使用似然比统计量 $T_{s} = 2\\Big(\\ell_{1,s}(\\widehat{\\theta}_{1}) - \\ell_{0,s}(\\widehat{\\theta}_{0})\\Big)$，其在 $H_{0}$ 下渐近服从自由度为2的 $\\chi^{2}$ 分布... 为了在水平 $q$ 控制FDR，收集所有 $m$ 个位点特异性p值，将它们排序为 $p_{(1)}\\le \\cdots \\le p_{(m)}$，找到满足 $p_{(k)} \\le (k/m)\\,q$ 的最大 $k$，并宣称具有最小 $k$ 个p值的位点是显著的...**\n-   **分析**：该选项完美匹配上述原则性推导。它正确地将贝塔-二项模型确定为贝塔-二项分层结构产生的边际分布。它以其最普遍的形式正确地阐述了原假设和备择假设。它正确地指明了似然比检验统计量及其渐近零分布为自由度为2的 $\\chi^2$ 分布。最后，它提供了对Benjamini-Hochberg程序的精确和正确的描述以控制FDR。提及组均值 $\\mu_g = \\alpha_g / (\\alpha_g + \\beta_g)$ 也是一个正确的解释。\n-   **结论**：**正确**。\n\n**B. 在每组内汇总样本的计数...在每个位点检验单个二项比例差异，不考虑过度离散...使用合并正态近似来处理比例差异...通过宣称p值满足 $p_{s} \\le q/m$ 的位点是显著的来控制多重性。**\n-   **分析**：这种方法根本上是有缺陷的。汇总样本计数（即创建“伪重复”）完全忽略了样本间的变异性，而这种变异性正是问题明确要求建模的过度离散的来源。这会导致无效的小标准误和假阳性率的大幅膨胀。此外，所描述的多重检验校正 $p_s \\le q/m$ 是Bonferroni校正，它控制的是族系误差率（FWER），而不是问题所要求的错误发现率（FDR）。\n-   **结论**：**不正确**。\n\n**C. 将甲基化读数视为具有暴露偏移量的泊松计数，且不考虑过度离散...使用来自泊松广义线性模型的偏差检验来检验 $H_{0}\\!:\\,\\lambda_{0}=\\lambda_{1}$...使用得到的偏差p值，并应用相同的每个假设的截断值 $p_{s} \\le q$ 来控制FDR。**\n-   **分析**：该选项因多个原因而有缺陷。首先，它提出了泊松模型，对于具有固定总数的计数来说，它不如二项模型合适。其次，它明确指出“不考虑过度离散”，直接违反了问题的关键要求。标准的泊松模型假设方差等于均值，而这些数据是过度离散的。第三，对多重检验控制的描述——“应用相同的每个假设的截断值 $p_{s} \\le q$ 来控制FDR”——是完全错误的。这个程序在多个检验中不控制FDR或任何有意义的错误率；它相当于根本不进行校正。\n-   **结论**：**不正确**。\n\n**D. 使用贝塔-二项模型来模拟过度离散，但在两个假设下都假设一个共同的离散度...检验 $H_{0}\\!:\\,\\mu_{0}=\\mu_{1}$（共享 $\\rho$）对 $H_{1}\\!:\\,\\mu_{0}\\neq \\mu_{1}$（共享 $\\rho$），使用似然比检验，其渐近服从自由度为1的 $\\chi^{2}$ 分布。对于多重检验，对p值进行排序，并宣称满足 $p_{(k)} \\le q/(m-k+1)$ 的位点是显著的。**\n-   **分析**：这个选项描述了一种有效且常见的差异甲基化统计检验。该检验比选项A中的检验更具限制性，它仅关注均值变化，同时假设过度离散度恒定。该模型的LRT正确地具有 $df = (\\text{H}_1\\text{的参数}) - (\\text{H}_0\\text{的参数}) = (\\mu_0, \\mu_1, \\rho) - (\\mu, \\rho) = 3 - 2 = 1$，因此 $\\chi^2_1$ 零分布是正确的。然而，最后一步就问题陈述而言是有缺陷的。所描述的多重检验程序，即找到满足 $p_{(k)} \\le q/(m-k+1)$ 的 $k$，是Benjamini-Yekutieli (BY) 程序，它比Benjamini-Hochberg (BH) 程序更保守。问题明确指定使用Benjamini–Hochberg (BH) 程序。\n-   **结论**：**不正确**。",
            "answer": "$$\\boxed{A}$$"
        },
        {
            "introduction": "在表观遗传学研究中，发现统计上显著的甲基化差异仅仅是第一步。为了理解其生物学功能和意义，我们必须将其与基因表达等其他组学数据进行整合分析。本练习模拟了一个真实世界中的生物信息学分析流程，旨在从肿瘤和正常组织的多组学数据中，筛选出因启动子区域高度甲基化而被沉默的候选抑癌基因。通过这个实践，你将学习如何综合运用多种统计检验、效应量评估和多重检验校正方法，将来自不同数据源的证据串联起来，构建一个具有说服力的生物学假说 。",
            "id": "4337352",
            "problem": "现提供配对的启动子DNA甲基化和基因表达谱数组，这些数据是针对多个基因，在肿瘤和正常组织队列中测量的。这些数组按测试用例和基因分组。对于每个基因，都有肿瘤甲基化值、正常甲基化值、肿瘤表达值、正常表达值，以及一个指示抑制性组蛋白修饰（组蛋白H3赖氨酸27三甲基化，记为Histone H3K27me3）是否存在的二元指示符。\n\n推导的基本依据：\n- 表观遗传调控将启动子DNA甲基化与转录沉默联系起来。启动子高甲基化通常与转录产出减少相关，尤其是在具有肿瘤抑制作用的基因中。\n- 基因表达遵循分子生物学的中心法则，其中信使核糖核酸（mRNA）的丰度反映了转录水平。\n- 甲基化值是有界的份数测量值，通常表示为无量纲区间 $[0,1]$ 内的beta值。\n- 统计检验和多重假设校正使用成熟的频率派方法。\n\n使用的定义：\n- 如果一个基因的启动子甲基化在肿瘤中比在正常组织中高出一个具有实际意义的量，基因表达在肿瘤中比在正常组织中低一个具有实际意义的量，并且在肿瘤样本中启动子甲基化与肿瘤基因表达之间存在负相关关系，则该基因被认为是候选的甲基化沉默的肿瘤抑制基因。对甲基化分布使用非参数检验，对表达差异使用参数检验，并对每个测试用例进行多重假设校正。\n- 在每个测试用例中，对所有基因的甲基化和表达 $p$ 值使用 Benjamini–Hochberg 伪发现率（FDR）校正。\n\n决策阈值（在所有测试用例中一致应用）：\n- 甲基化效应大小阈值：平均差异 $\\Delta \\beta \\geq 0.2$，其中 $\\Delta \\beta = \\overline{\\beta}_{\\text{tumor}} - \\overline{\\beta}_{\\text{normal}}$。Beta值必须作为 $[0,1]$ 区间内的小数处理，而不是百分比。\n- 甲基化显著性：双边Mann–Whitney $U$ 检验的 $p$ 值，经FDR校正后的 $q$ 值 $\\leq 0.05$。\n- 表达效应大小阈值：以2为底的对数倍数变化 $\\log_{2}\\left(\\overline{E}_{\\text{tumor}} + \\epsilon\\right) - \\log_{2}\\left(\\overline{E}_{\\text{normal}} + \\epsilon\\right) \\leq -1.0$，其中 $\\epsilon = 10^{-3}$ 以避免除以零。\n- 表达显著性：双边Welch’s $t$ 检验（不等方差）的 $p$ 值，经FDR校正后的 $q$ 值 $\\leq 0.05$。\n- 相关性标准：Spearman等级相关系数 $\\rho \\leq -0.5$，双边相关性 $p$ 值 $\\leq 0.05$，仅在肿瘤样本中计算，将每个肿瘤的启动子甲基化值与其肿瘤表达值配对。\n- 高置信度分类：满足上述所有标准且存在组蛋白H3K27me3的基因被标记为高置信度；否则，仅为标准置信度。\n\n算法要求：\n- 对于每个测试用例，计算每个基因的 $\\Delta \\beta$、甲基化的Mann–Whitney $U$ 检验 $p$ 值、表达的以2为底的对数倍数变化、表达的Welch’s $t$ 检验 $p$ 值、肿瘤甲基化与肿瘤表达之间的Spearman $\\rho$ 相关系数，以及相关的相关性 $p$ 值。在测试用例内部，对甲基化和表达的 $p$ 值分别应用 Benjamini–Hochberg 程序以获得 $q$ 值。\n- 如果一个基因满足所有三个条件：肿瘤中甲基化水平更高（效应和校正后的显著性）、肿瘤中表达水平更低（效应和校正后的显著性），以及肿瘤中存在负相关（效应和显著性），则将其标记为标准置信度的命中基因。如果组蛋白H3K27me3存在，则额外将其标记为高置信度的命中基因。\n\n直接在程序中实现的输入（测试套件）：\n- 测试用例 $1$ 包含 $4$ 个基因，每个基因有 $6$ 个肿瘤样本和 $6$ 个正常样本。每个基因的数组（肿瘤甲基化、正常甲基化、肿瘤表达、正常表达）和组蛋白指示符：\n  - 基因 $0$：肿瘤甲基化 $[0.80,0.82,0.83,0.85,0.86,0.88]$，正常甲基化 $[0.12,0.18,0.15,0.22,0.17,0.19]$，肿瘤表达 $[2.6,2.4,2.3,2.1,2.0,1.9]$，正常表达 $[6.0,6.5,5.8,6.2,6.4,6.1]$，组蛋白 $1$ (真)。\n  - 基因 $1$：肿瘤甲基化 $[0.60,0.62,0.61,0.59,0.58,0.62]$，正常甲基化 $[0.40,0.42,0.41,0.39,0.38,0.42]$，肿瘤表达 $[6.0,5.8,6.1,5.9,6.2,6.0]$，正常表达 $[5.5,5.7,5.4,5.6,5.5,5.6]$，组蛋白 $0$ (假)。\n  - 基因 $2$：肿瘤甲基化 $[0.74,0.75,0.76,0.77,0.78,0.79]$，正常甲基化 $[0.20,0.21,0.22,0.22,0.23,0.24]$，肿瘤表达 $[2.0,2.1,2.2,2.3,2.4,2.5]$，正常表达 $[6.0,6.1,6.2,6.3,6.1,6.2]$，组蛋白 $1$ (真)。\n  - 基因 $3$：肿瘤甲基化 $[0.70,0.72,0.74,0.75,0.71,0.73]$，正常甲基化 $[0.25,0.27,0.26,0.28,0.24,0.26]$，肿瘤表达 $[3.0,2.8,2.6,2.5,2.7,2.6]$，正常表达 $[5.5,5.2,5.1,5.3,5.4,5.2]$，组蛋白 $0$ (假)。\n- 测试用例 $2$ 包含 $3$ 个基因，每个基因有 $6$ 个肿瘤样本和 $6$ 个正常样本：\n  - 基因 $0$：肿瘤甲基化 $[0.60,0.61,0.62,0.59,0.58,0.60]$，正常甲基化 $[0.40,0.41,0.42,0.39,0.38,0.40]$，肿瘤表达 $[4.0,3.9,4.1,3.8,4.0,3.9]$，正常表达 $[4.2,4.1,4.2,4.3,4.1,4.2]$，组蛋白 $1$ (真)。\n  - 基因 $1$：肿瘤甲基化 $[0.85,0.83,0.84,0.86,0.87,0.85]$，正常甲基化 $[0.30,0.29,0.31,0.28,0.32,0.30]$，肿瘤表达 $[2.5,2.4,2.3,2.2,2.1,2.0]$，正常表达 $[5.0,5.1,5.2,5.1,5.0,5.2]$，组蛋白 $0$ (假)。\n  - 基因 $2$：肿瘤甲基化 $[0.77,0.78,0.79,0.80,0.81,0.82]$，正常甲基化 $[0.20,0.21,0.19,0.22,0.21,0.20]$，肿瘤表达 $[0.20,0.18,0.15,0.12,0.10,0.08]$，正常表达 $[3.0,3.2,3.1,3.3,3.2,3.1]$，组蛋白 $1$ (真)。\n- 测试用例 $3$ 包含 $3$ 个基因，每个基因有 $3$ 个肿瘤样本和 $3$ 个正常样本：\n  - 基因 $0$：肿瘤甲基化 $[0.70,0.72,0.74]$，正常甲基化 $[0.40,0.42,0.41]$，肿瘤表达 $[3.0,2.8,2.6]$，正常表达 $[5.0,5.2,5.1]$，组蛋白 $0$ (假)。\n  - 基因 $1$：肿瘤甲基化 $[0.68,0.70,0.69]$，正常甲基化 $[0.50,0.49,0.51]$，肿瘤表达 $[4.5,4.6,4.4]$，正常表达 $[4.6,4.5,4.4]$，组蛋白 $0$ (假)。\n  - 基因 $2$：肿瘤甲基化 $[0.85,0.87,0.86]$，正常甲基化 $[0.30,0.32,0.31]$，肿瘤表达 $[1.5,1.4,1.6]$，正常表达 $[5.0,4.8,4.9]$，组蛋白 $1$ (真)。\n\n程序要求：\n- 按照规定实现流程，计算每个测试用例中每个基因的标志，并为每个测试用例返回两个列表：第一个列表包含满足标准置信度标准的基因的整数索引（升序排列）；第二个列表包含满足高置信度标准的基因的整数索引（升序排列）。\n- 最终输出格式：您的程序应生成单行输出，其中包含一个逗号分隔的各测试用例结果列表，每个测试用例的结果本身是一个包含两个整数列表的双元素列表，并且输出字符串中没有任何空格。例如，如果第一个测试用例产生标准置信度基因 $[0,3]$ 和高置信度基因 $[0]$，第二个测试用例产生标准置信度基因 $[1]$ 和高置信度基因 $[]$，则单行输出应采用确切格式 $[[[0,3],[0]],[[1],[]],...]$。\n\n注意：所有类似百分比的量必须表示为小数或分数，不能使用百分号。此问题中没有物理单位或角度。确保数值计算严格遵守所述的阈值和程序。",
            "solution": "该问题在科学和数学上是适定的，为从配对的甲基化和表达数据中识别候选的甲基化沉默基因提供了完整的数据集、定义和程序要求。该问题是有效的。解决方案需要系统地实现一个多步骤的生物信息学流程，包括统计检验、效应大小计算和多重假设校正。其核心原理植根于分子生物学（基因表达的表观遗传调控）和生物统计学。\n\n解决方案的步骤如下：\n首先，对于每个测试用例，我们必须处理所有基因以收集必要的统计数据。对于每个基因，我们执行三种类型的分析：差异甲基化、差异表达和相关性分析。\n\n1.  **差异甲基化分析**：\n    -   效应大小是肿瘤样本和正常样本之间平均甲基化水平的差异，$\\Delta \\beta = \\overline{\\beta}_{\\text{tumor}} - \\overline{\\beta}_{\\text{normal}}$。\n    -   统计显著性通过双边Mann-Whitney $U$检验确定，这是一种非参数检验，适用于在数据可能不服从正态分布时比较两个独立组。该检验产生一个甲基化的 $p$ 值，即 $p_{\\text{meth}}$。\n\n2.  **差异表达分析**：\n    -   效应大小是以2为底的对数倍数变化，计算公式为 $\\log_{2}\\left(\\overline{E}_{\\text{tumor}} + \\epsilon\\right) - \\log_{2}\\left(\\overline{E}_{\\text{normal}} + \\epsilon\\right)$。加入一个小的常数 $\\epsilon = 10^{-3}$ 是为了避免出现 $\\log(0)$ 的问题。对基因表达数据使用对数尺度是标准做法，因为它有助于使偏态分布正常化，并对称地表示上调和下调。\n    -   统计显著性通过双边Welch's $t$检验评估。这种参数检验适用于比较两个独立组的均值，并且不假设方差相等，使其比标准的Student's $t$检验更为稳健。该检验产生一个表达的 $p$ 值，即 $p_{\\text{expr}}$。\n\n3.  **相关性分析**：\n    -   在肿瘤队列中，启动子甲基化与基因表达之间的关系使用Spearman's rank correlation coefficient, $\\rho$ 进行量化。这种非参数度量评估了两个变量之间单调关系的强度和方向。\n    -   计算一个 $p$ 值，即 $p_{\\text{corr}}$，以检验观察到的相关性的显著性。\n\n在为单个测试用例中的所有基因计算完这些统计数据后，我们必须进行多重假设检验校正。这一点至关重要，因为执行大量统计检验会增加偶然观察到显著结果（第一类错误）的概率。\n\n4.  **多重假设校正**：\n    -   应用Benjamini-Hochberg (BH) 程序来控制伪发现率（FDR）。FDR是被拒绝的原假设中实际为假阳性的预期比例。\n    -   BH程序独立地应用于测试用例中所有基因的 $p_{\\text{meth}}$ 值集和 $p_{\\text{expr}}$ 值集。这将原始 $p$ 值转换为经FDR校正的 $q$ 值，即 $q_{\\text{meth}}$ 和 $q_{\\text{expr}}$。\n    -   从一组 $m$ 个 $p$ 值计算 $q$ 值的步骤如下：\n        i.  将 $p$ 值按升序排序：$p_{(1)} \\le p_{(2)} \\le \\dots \\le p_{(m)}$。\n        ii. 计算每个秩次 $i$ 的BH校正 $p$ 值，公式为 $q_{(i)}^{\\text{raw}} = \\frac{p_{(i)} \\cdot m}{i}$。\n        iii. 为确保单调性，对于秩次 $i$，最终的 $q$ 值为 $q_{(i)} = \\min(q_{(i+1)}, q_{(i)}^{\\text{raw}})$（其中 $i = m-1, \\dots, 1$），且 $q_{(m)} = q_{(m)}^{\\text{raw}}$。更简单地说，$q_{(i)}$ 是从秩次 $i$ 到 $m$ 的原始校正 $p$ 值的累积最小值。\n    -   恢复原始顺序，以便将每个基因与其正确的 $q$ 值关联起来。请注意，在此问题的设计中，相关性 $p$ 值 $p_{\\text{corr}}$ 不进行多重检验校正，因为它是一个基因层面的过滤器。\n\n最后，我们应用决策阈值对每个基因进行分类。\n\n5.  **分类**：\n    -   如果一个基因满足以下所有标准，则被标记为**标准置信度**的命中基因：\n        a. **甲基化高调控**：$\\Delta\\beta \\geq 0.2$ **且** $q_{\\text{meth}} \\leq 0.05$。\n        b. **表达下调**：$\\log_2(\\text{倍数变化}) \\leq -1.0$ **且** $q_{\\text{expr}} \\leq 0.05$。\n        c. **负相关**：$\\rho \\leq -0.5$ **且** $p_{\\text{corr}} \\leq 0.05$。\n    -   如果一个基因是标准置信度的命中基因，**并且**它存在抑制性组蛋白标记 H3K27me3（由二元标志 $1$ 指示），则被标记为**高置信度**的命中基因。\n\n整个流程独立地应用于每个测试用例。最终输出的结构是为每个测试用例呈现标准置信度和高置信度基因索引的列表。",
            "answer": "```python\nimport numpy as np\nfrom scipy import stats\n\ndef benjamini_hochberg(p_values):\n    \"\"\"\n    Performs the Benjamini-Hochberg FDR correction.\n\n    Args:\n        p_values (list or np.ndarray): A list of p-values.\n\n    Returns:\n        np.ndarray: An array of FDR-adjusted q-values, in the same order as the input p_values.\n    \"\"\"\n    p_values = np.asarray(p_values)\n    m = len(p_values)\n    if m == 0:\n        return np.array([])\n    \n    # Sort p-values and keep track of original indices\n    original_indices = np.argsort(p_values)\n    sorted_p_values = p_values[original_indices]\n    \n    # Calculate q-values\n    q_values = np.zeros(m)\n    for i, p_val in enumerate(sorted_p_values):\n        rank = i + 1\n        q_values[i] = (p_val * m) / rank\n    \n    # Enforce monotonicity\n    # q_i = min(q_{i+1}, q_i) for i = m-1 ... 1\n    # This is equivalent to taking the cumulative minimum from the end of the sorted list\n    q_values = np.minimum.accumulate(q_values[::-1])[::-1]\n    \n    # Restore original order\n    final_q_values = np.zeros(m)\n    final_q_values[original_indices] = q_values\n    \n    # Clamp values to be at most 1.0\n    return np.clip(final_q_values, a_min=None, a_max=1.0)\n\ndef solve():\n    \"\"\"\n    Main function to run the epigenetic analysis pipeline on the provided test cases.\n    \"\"\"\n    # Input data structured as:\n    # list of test cases -> list of genes -> tuple of (tumor_meth, normal_meth, tumor_expr, normal_expr, histone_flag)\n    test_cases = [\n        # Test case 1\n        [\n            (np.array([0.80,0.82,0.83,0.85,0.86,0.88]), np.array([0.12,0.18,0.15,0.22,0.17,0.19]), np.array([2.6,2.4,2.3,2.1,2.0,1.9]), np.array([6.0,6.5,5.8,6.2,6.4,6.1]), 1),\n            (np.array([0.60,0.62,0.61,0.59,0.58,0.62]), np.array([0.40,0.42,0.41,0.39,0.38,0.42]), np.array([6.0,5.8,6.1,5.9,6.2,6.0]), np.array([5.5,5.7,5.4,5.6,5.5,5.6]), 0),\n            (np.array([0.74,0.75,0.76,0.77,0.78,0.79]), np.array([0.20,0.21,0.22,0.22,0.23,0.24]), np.array([2.0,2.1,2.2,2.3,2.4,2.5]), np.array([6.0,6.1,6.2,6.3,6.1,6.2]), 1),\n            (np.array([0.70,0.72,0.74,0.75,0.71,0.73]), np.array([0.25,0.27,0.26,0.28,0.24,0.26]), np.array([3.0,2.8,2.6,2.5,2.7,2.6]), np.array([5.5,5.2,5.1,5.3,5.4,5.2]), 0),\n        ],\n        # Test case 2\n        [\n            (np.array([0.60,0.61,0.62,0.59,0.58,0.60]), np.array([0.40,0.41,0.42,0.39,0.38,0.40]), np.array([4.0,3.9,4.1,3.8,4.0,3.9]), np.array([4.2,4.1,4.2,4.3,4.1,4.2]), 1),\n            (np.array([0.85,0.83,0.84,0.86,0.87,0.85]), np.array([0.30,0.29,0.31,0.28,0.32,0.30]), np.array([2.5,2.4,2.3,2.2,2.1,2.0]), np.array([5.0,5.1,5.2,5.1,5.0,5.2]), 0),\n            (np.array([0.77,0.78,0.79,0.80,0.81,0.82]), np.array([0.20,0.21,0.19,0.22,0.21,0.20]), np.array([0.20,0.18,0.15,0.12,0.10,0.08]), np.array([3.0,3.2,3.1,3.3,3.2,3.1]), 1),\n        ],\n        # Test case 3\n        [\n            (np.array([0.70,0.72,0.74]), np.array([0.40,0.42,0.41]), np.array([3.0,2.8,2.6]), np.array([5.0,5.2,5.1]), 0),\n            (np.array([0.68,0.70,0.69]), np.array([0.50,0.49,0.51]), np.array([4.5,4.6,4.4]), np.array([4.6,4.5,4.4]), 0),\n            (np.array([0.85,0.87,0.86]), np.array([0.30,0.32,0.31]), np.array([1.5,1.4,1.6]), np.array([5.0,4.8,4.9]), 1),\n        ]\n    ]\n\n    # --- Decision Thresholds ---\n    METH_EFFECT_THRESHOLD = 0.2\n    Q_VALUE_THRESHOLD = 0.05\n    EXPR_EFFECT_THRESHOLD = -1.0\n    CORR_EFFECT_THRESHOLD = -0.5\n    CORR_P_VALUE_THRESHOLD = 0.05\n    EPSILON = 1e-3\n\n    overall_results = []\n\n    for case_data in test_cases:\n        num_genes = len(case_data)\n        \n        # Lists to store per-gene statistics for the current test case\n        meth_p_values = []\n        expr_p_values = []\n        gene_stats = []\n\n        # Step 1: Calculate all stats for each gene\n        for gene_idx in range(num_genes):\n            t_meth, n_meth, t_expr, n_expr, histone_flag = case_data[gene_idx]\n\n            # Methylation analysis\n            delta_beta = np.mean(t_meth) - np.mean(n_meth)\n            _, meth_p = stats.mannwhitneyu(t_meth, n_meth, alternative='two-sided')\n            meth_p_values.append(meth_p)\n\n            # Expression analysis\n            mean_t_expr = np.mean(t_expr)\n            mean_n_expr = np.mean(n_expr)\n            log2fc = np.log2(mean_t_expr + EPSILON) - np.log2(mean_n_expr + EPSILON)\n            _, expr_p = stats.ttest_ind(t_expr, n_expr, equal_var=False, alternative='two-sided')\n            expr_p_values.append(expr_p)\n            \n            # Correlation analysis\n            spearman_rho, spearman_p = stats.spearmanr(t_meth, t_expr)\n\n            gene_stats.append({\n                'delta_beta': delta_beta,\n                'log2fc': log2fc,\n                'spearman_rho': spearman_rho,\n                'spearman_p': spearman_p,\n                'histone_flag': histone_flag\n            })\n\n        # Step 2: Apply Benjamini-Hochberg correction\n        meth_q_values = benjamini_hochberg(meth_p_values)\n        expr_q_values = benjamini_hochberg(expr_p_values)\n\n        # Step 3: Classify genes based on thresholds\n        standard_confidence_indices = []\n        high_confidence_indices = []\n\n        for gene_idx in range(num_genes):\n            stats_dict = gene_stats[gene_idx]\n            \n            meth_hyper = (stats_dict['delta_beta'] >= METH_EFFECT_THRESHOLD) and (meth_q_values[gene_idx] = Q_VALUE_THRESHOLD)\n            expr_down = (stats_dict['log2fc'] = EXPR_EFFECT_THRESHOLD) and (expr_q_values[gene_idx] = Q_VALUE_THRESHOLD)\n            neg_corr = (stats_dict['spearman_rho'] = CORR_EFFECT_THRESHOLD) and (stats_dict['spearman_p'] = CORR_P_VALUE_THRESHOLD)\n\n            if meth_hyper and expr_down and neg_corr:\n                standard_confidence_indices.append(gene_idx)\n                if stats_dict['histone_flag'] == 1:\n                    high_confidence_indices.append(gene_idx)\n        \n        overall_results.append([sorted(standard_confidence_indices), sorted(high_confidence_indices)])\n\n    # Format output string\n    output_str = str(overall_results).replace(\" \", \"\")\n    print(output_str)\n\nsolve()\n```"
        }
    ]
}