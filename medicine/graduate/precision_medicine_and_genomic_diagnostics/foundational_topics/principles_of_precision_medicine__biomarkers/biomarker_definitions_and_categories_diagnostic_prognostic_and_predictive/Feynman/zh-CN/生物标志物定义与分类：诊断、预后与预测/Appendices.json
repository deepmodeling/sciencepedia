{
    "hands_on_practices": [
        {
            "introduction": "生物标志物的核心价值在于其能够更新我们对患者临床状态的判断。将灵敏度 $sens$ 和特异性 $spec$ 等统计指标转化为对个体患者疾病可能性的具体、量化的评估，是精准医学中的一项基本技能。本练习将通过从第一性原理推导和应用贝叶斯定理的赔率 (odds) 形式，来巩固这一关键的诊断推理过程 ()。",
            "id": "4319496",
            "problem": "一种连续的无细胞脱氧核糖核酸（cfDNA）甲基化特征，由标量生物标志物 $B$ 表示，正在一个有症状队列中作为结直肠癌的诊断性生物标志物进行评估。在精准医疗和基因组诊断学中使用的生物标志物分类法中，诊断性生物标志物指示当前疾病状态的存在与否，预后性生物标志物对独立于治疗的未来结局风险进行分层，而预测性生物标志物则评估差异化的治疗反应。在这里，$B$ 用于分类疾病状态而非未来风险或治疗反应，并且基于受试者工作特征（ROC）分析（Receiver Operating Characteristic (ROC)）选择一个阈值 $t^{\\ast}$，以产生一个二元检测结果：如果 $B \\ge t^{\\ast}$ 则为 $T^{+}$，否则为 $T^{-}$。\n\n在一个外部队列上验证的阈值 $t^{\\ast}$ 下，观察到的灵敏度和特异度分别为 $sens = 0.83$ 和 $spec = 0.91$，其中灵敏度定义为 $P(T^{+}\\mid D)$，特异度定义为 $P(T^{-}\\mid \\neg D)$，$D$ 表示事件“存在疾病”，$\\neg D$ 表示“不存在疾病”。对于某特定患者，一个校准良好的临床风险模型在进行生物标志物测量前提供了疾病的先验概率 $P(D) = 0.18$。\n\n请仅从灵敏度、特异度和贝叶斯定理的基本定义出发，(i) 推导阳性似然比 $LR^{+}$ 和阴性似然比 $LR^{-}$ 关于 $sens$ 和 $spec$ 的表达式，以及 (ii) 推导贝叶斯定理的比值形式，该形式将检验后比值与检验前比值及相应的似然比联系起来。然后，使用这些推导出的结果，计算该患者在阈值 $t^{\\ast}$ 下获得阳性检测结果后的检验后比值 $odds(D\\mid T^{+})$。\n\n将 $odds(D\\mid T^{+})$ 的最终数值答案表示为一个无单位比率，并四舍五入至四位有效数字。",
            "solution": "该问题陈述被评估为有效。它在科学上基于生物统计学和医学诊断的既定原则，提法得当，提供了所有必要信息，并且在语言和定义上是客观的。所提供的数据（$sens=0.83$，$spec=0.91$，$P(D)=0.18$）内部一致，并且对于一个真实世界的临床情景是合理的。该问题是贝叶斯推断的一个标准的、非平凡的应用，按要求需要从第一性原理进行严格推导。\n\n解题过程首先推导所需的似然比和贝叶斯定理比值形式的表达式，然后应用这些结果计算最终的数值答案。\n\n(i) 似然比的推导\n\n阳性似然比 $LR^{+}$ 定义为患病人群中出现阳性检测结果的概率与非患病人群中出现阳性检测结果的概率之比。\n$$LR^{+} \\equiv \\frac{P(T^{+}\\mid D)}{P(T^{+}\\mid \\neg D)}$$\n分子由灵敏度 $sens$ 的定义给出：\n$$P(T^{+}\\mid D) = sens$$\n分母 $P(T^{+}\\mid \\neg D)$ 是假阳性率。它可以用特异度 $spec$ 来表示。根据定义，特异度是在非患病人群中检测结果为阴性的概率：\n$$spec = P(T^{-}\\mid \\neg D)$$\n由于在任何给定条件下（此处为 $\\neg D$），检测结果必须是阳性（$T^{+}$）或阴性（$T^{-}$），它们的概率之和必须为 $1$：\n$$P(T^{+}\\mid \\neg D) + P(T^{-}\\mid \\neg D) = 1$$\n解出 $P(T^{+}\\mid \\neg D)$ 可得：\n$$P(T^{+}\\mid \\neg D) = 1 - P(T^{-}\\mid \\neg D) = 1 - spec$$\n将分子和分母的表达式代回 $LR^{+}$ 的定义，得到所需的表达式：\n$$LR^{+} = \\frac{sens}{1 - spec}$$\n\n类似地，阴性似然比 $LR^{-}$ 定义为患病人群中出现阴性检测结果的概率与非患病人群中出现阴性检测结果的概率之比。\n$$LR^{-} \\equiv \\frac{P(T^{-}\\mid D)}{P(T^{-}\\mid \\neg D)}$$\n分母直接由特异度的定义给出：\n$$P(T^{-}\\mid \\neg D) = spec$$\n分子 $P(T^{-}\\mid D)$ 是假阴性率。它可以用灵敏度来表示。对于患病人群（$D$），阳性和阴性检测结果的概率之和必须为 $1$：\n$$P(T^{+}\\mid D) + P(T^{-}\\mid D) = 1$$\n解出 $P(T^{-}\\mid D)$ 可得：\n$$P(T^{-}\\mid D) = 1 - P(T^{+}\\mid D) = 1 - sens$$\n将这些分子和分母的表达式代入 $LR^{-}$ 的定义，得到最终表达式：\n$$LR^{-} = \\frac{1 - sens}{spec}$$\n\n(ii) 贝叶斯定理比值形式的推导\n\n事件 $A$ 的比值（odds）定义为该事件发生的概率与不发生的概率之比，即 $odds(A) = \\frac{P(A)}{P(\\neg A)}$。因此，在给定阳性检测结果 $T^{+}$ 的情况下，疾病的检验后比值为：\n$$odds(D\\mid T^{+}) = \\frac{P(D\\mid T^{+})}{P(\\neg D\\mid T^{+})}$$\n我们应用贝叶斯定理来寻找分子和分母的表达式。对于分子：\n$$P(D\\mid T^{+}) = \\frac{P(T^{+}\\mid D)P(D)}{P(T^{+})}$$\n对于分母：\n$$P(\\neg D\\mid T^{+}) = \\frac{P(T^{+}\\mid \\neg D)P(\\neg D)}{P(T^{+})}$$\n将这些代入比值表达式，两个表达式分母中的共同项 $P(T^{+})$ 被消掉：\n$$odds(D\\mid T^{+}) = \\frac{\\frac{P(T^{+}\\mid D)P(D)}{P(T^{+})}}{\\frac{P(T^{+}\\mid \\neg D)P(\\neg D)}{P(T^{+})}} = \\frac{P(T^{+}\\mid D)P(D)}{P(T^{+}\\mid \\neg D)P(\\neg D)}$$\n这个表达式可以重组，将似然概率与先验概率分开：\n$$odds(D\\mid T^{+}) = \\left(\\frac{P(T^{+}\\mid D)}{P(T^{+}\\mid \\neg D)}\\right) \\left(\\frac{P(D)}{P(\\neg D)}\\right)$$\n第一项是阳性似然比 $LR^{+}$ 的定义。第二项是疾病的检验前（或先验）比值 $odds(D)$ 的定义。因此，我们得到了贝叶斯定理的比值形式：\n$$odds(D\\mid T^{+}) = LR^{+} \\times odds(D)$$\n这个基本关系表明，检验后比值等于检验前比值乘以与检测结果相对应的似然比。\n\n(iii) 计算检验后比值 $odds(D\\mid T^{+})$\n\n利用推导出的结果，我们现在可以计算该患者的检验后比值。\n首先，我们根据给定的先验概率 $P(D) = 0.18$ 计算检验前比值 $odds(D)$。\n无疾病的概率为 $P(\\neg D) = 1 - P(D) = 1 - 0.18 = 0.82$。\n检验前比值为：\n$$odds(D) = \\frac{P(D)}{P(\\neg D)} = \\frac{0.18}{0.82}$$\n接下来，我们使用给定的灵敏度 $sens = 0.83$ 和特异度 $spec = 0.91$ 计算阳性似然比 $LR^{+}$。\n$$LR^{+} = \\frac{sens}{1 - spec} = \\frac{0.83}{1 - 0.91} = \\frac{0.83}{0.09}$$\n最后，我们使用贝叶斯定理的比值形式计算检验后比值：\n$$odds(D\\mid T^{+}) = LR^{+} \\times odds(D) = \\left(\\frac{0.83}{0.09}\\right) \\times \\left(\\frac{0.18}{0.82}\\right)$$\n计算过程如下：\n$$odds(D\\mid T^{+}) = \\frac{0.83 \\times 0.18}{0.09 \\times 0.82} = \\frac{0.1494}{0.0738}$$\n$$odds(D\\mid T^{+}) \\approx 2.024389...$$\n将结果四舍五入到四位有效数字，得到 $2.024$。",
            "answer": "$$\\boxed{2.024}$$"
        },
        {
            "introduction": "在开发结合了多个特征的复杂生物标志物模型时，一个核心挑战是避免过拟合，即模型对训练数据的拟合效果远好于其对新数据的预测能力。这种“乐观”的性能评估可能会误导临床决策。本计算实践将指导你使用自助法 (bootstrap) 重采样技术来量化并校正这种过拟合导致的乐观偏差，从而对模型的泛化能力做出更稳健的评估 ()。",
            "id": "4319570",
            "problem": "您将执行一项形式化任务，该任务基于精准医疗和基因组诊断中的生物标志物模型评估。在此背景下，生物标志物可以扮演不同角色：诊断性生物标志物在特定时间点区分疾病与非疾病状态，预后性生物标志物分层独立于治疗的基线风险，而预测性生物标志物则指示特定治疗的差异化益处。用于诊断性或预测性生物标志物的分类模型通常依赖于对二元临床状态的概率性预测。对此类模型的排序性能进行严格度量的一个指标是受试者工作特征曲线下面积 (AUC)，其可以表示为随机选择的正例样本获得比随机选择的负例样本更高模型分数的概率。在训练数据上测得的表观（样本内）性能容易出现过拟合。可以采用基于重采样的方法（如自助法重采样）来估计和校正乐观度（即表观性能相对于新数据性能的预期膨胀）。\n\n基本原理：\n- 令 $X \\in \\mathbb{R}^{n \\times p}$ 表示一个包含 $n$ 个样本和 $p$ 个特征的设计矩阵。令 $y \\in \\{0,1\\}^n$ 表示二元结果，代表与生物标志物相关的临床状态存在 ($1$) 或不存在 ($0$)。\n- 考虑一个带有参数 $\\beta \\in \\mathbb{R}^{p+1}$（包括一个截距）的逻辑回归模型，为样本 $i$ 生成预测概率 $\\hat{p}_i = s\\!\\left(\\beta_0 + \\sum_{j=1}^{p} x_{ij}\\beta_j \\right)$，其中 $s(z) = 1/(1+e^{-z})$ 是逻辑函数。参数通过最大化正则化似然或等价地最小化正则化负对数似然来估计\n$$\n\\mathcal{L}(\\beta; X, y, \\lambda) = -\\sum_{i=1}^{n} \\left[ y_i \\log \\hat{p}_i + (1-y_i)\\log(1-\\hat{p}_i) \\right] + \\frac{\\lambda}{2}\\sum_{j=1}^{p} \\beta_j^2,\n$$\n其中 $\\lambda \\ge 0$ 是一个应用于非截距系数的 $L_2$ 惩罚权重，以减轻不稳定性并减少过拟合。\n- 对于一个分数向量 $r \\in \\mathbb{R}^n$，受试者工作特征曲线下面积 (AUC) 定义为随机选择的正样本得分高于随机选择的负样本得分的概率，其中平局的权重为一半。这可以通过源自Wilcoxon-Mann-Whitney统计量的基于秩的公式计算。\n- 自助法原理通过从观测数据定义的经验分布中有放回地重采样来近似抽样分布下的期望值。基于自助法的乐观度估计过程为：在每个自助样本上训练一个模型，并比较其在自助样本上与原始样本上的性能。\n\n任务：\n实现一个程序，对每个测试用例执行以下步骤：\n1. 按如下方式生成合成数据 $(X,y)$。对于给定的 $n$、$p$、系数向量 $\\beta^* \\in \\mathbb{R}^{p}$ 和截距 $\\beta_0^* \\in \\mathbb{R}$，抽取具有独立标准正态分布条目的 $X$。计算线性预测器 $z_i = \\beta_0^* + \\sum_{j=1}^{p} x_{ij}\\beta_j^*$，并对 $i=1,\\dots,n$ 独立地抽样结果 $y_i \\sim \\text{Bernoulli}(s(z_i))$，其中 $s(\\cdot)$ 是逻辑函数。使用指定的随机种子以确保可复现性。\n2. 通过使用数值优化器最小化关于 $\\beta$ 的 $\\mathcal{L}(\\beta; X, y, \\lambda)$ 来拟合一个惩罚逻辑回归模型。惩罚项必须排除截距。\n3. 通过使用拟合模型在 $X$ 上生成预测概率，然后使用正确处理平局的基于秩的方法计算相对于 $y$ 的AUC，来计算原始数据上的表观AUC。如果没有正样本或负样本，则将AUC定义为非数值。\n4. 执行 $B$ 次自助法重采样：\n   - 对于每个自助法复制 $b \\in \\{1,\\dots,B\\}$，从 $\\{1,\\dots,n\\}$ 中有放回地抽取大小为 $n$ 的索引自助样本，得到 $(X^{(b)}, y^{(b)})$。\n   - 在 $(X^{(b)}, y^{(b)})$ 上拟合惩罚逻辑回归以获得参数 $\\hat{\\beta}^{(b)}$。\n   - 使用来自 $\\hat{\\beta}^{(b)}$ 的预测在 $(X^{(b)}, y^{(b)})$ 上计算 $AUC_{\\text{boot}}^{(b)}$。\n   - 使用来自 $\\hat{\\beta}^{(b)}$ 的预测在 $(X, y)$ 上计算 $AUC_{\\text{orig}}^{(b)}$。\n   - 将复制 $b$ 的乐观度定义为 $AUC_{\\text{boot}}^{(b)} - AUC_{\\text{orig}}^{(b)}$。如果由于自助样本中的类别退化导致任一AUC为非数值，则将该复制从乐观度平均值计算中排除。\n5. 将乐观度校正的AUC计算为表观AUC减去在有效自助法复制上计算的平均乐观度。\n6. 返回每个测试用例的乐观度校正的AUC，结果为四舍五入到 $6$ 位小数的十进制数。\n\n您的程序必须精确实现上述过程，并基于秩处理能感知平局的AUC计算。它必须使用一个惩罚逻辑回归，其中 $L_2$ 惩罚权重 $\\lambda$ 仅应用于非截距系数。如果所有自助法复制都因类别退化而无效，则为该测试用例返回非数值指示符。\n\n测试套件：\n使用以下四个测试用例，每个用例由一个元组 $(\\text{seed}, n, p, \\beta^*, \\beta_0^*, \\lambda, B)$ 指定：\n- 用例 1: $(42, 120, 3, [0.6, -0.4, 0.8], -0.2, 1.0, 200)$。\n- 用例 2: $(314, 100, 2, [2.5, -2.0], 0.0, 2.0, 150)$。\n- 用例 3: $(7, 35, 4, [0.2, 0.1, -0.1, 0.0], -0.1, 0.5, 100)$。\n- 用例 4: $(2021, 200, 5, [0.3, 0.0, -0.2, 0.1, 0.05], -2.0, 1.0, 200)$。\n\n答案规格：\n- 对每个测试用例，按上述方法计算乐观度校正的AUC，并四舍五入到 $6$ 位小数。\n- 将每个最终答案表示为十进制数（而不是百分比）。\n- 您的程序应生成单行输出，其中包含用方括号括起来的逗号分隔列表形式的结果（例如，$[0.731245,0.892310,0.501234,0.763210]$）。不要打印任何其他文本。",
            "solution": "我们首先将生物标志物的背景与一个形式化的统计学习问题联系起来。诊断性生物标志物区分病例与对照组，预测性生物标志物指示治疗益处；两者通常都通过二元分类性能进行评估。受试者工作特征曲线下面积 (AUC) 量化了模型的排序能力：给定分数 $r \\in \\mathbb{R}^n$ 和标签 $y \\in \\{0,1\\}^n$，它等于随机选择的正例分数超过随机选择的负例分数的概率，其中平局贡献一半权重。这可以通过源自Wilcoxon-Mann-Whitney公式的基于秩的统计量计算。\n\n当模型捕捉到训练数据中的特异性噪声时，就会发生过拟合，这会夸大表观性能（即在用于训练的同一数据上测量的性能）。自助法原理通过从经验分布中进行重采样来近似期望值，从而提供了一种估计和校正这种膨胀（乐观度）的方法。\n\n基于原理的推导与算法设计：\n1. 模型与估计。对于二元结果，我们通过逻辑函数 $s(z) = 1/(1+e^{-z})$ 来建模条件概率。对于具有特征 $x_i \\in \\mathbb{R}^p$ 的样本 $i$，模型为 $\\hat{p}_i = s\\!\\left(\\beta_0 + \\sum_{j=1}^p x_{ij}\\beta_j\\right)$。参数 $\\beta = (\\beta_0,\\ldots,\\beta_p)$ 通过最小化正则化负对数似然来估计：\n   $$\n   \\mathcal{L}(\\beta; X, y, \\lambda) = -\\sum_{i=1}^n \\left[ y_i \\log \\hat{p}_i + (1-y_i)\\log(1-\\hat{p}_i) \\right] + \\frac{\\lambda}{2}\\sum_{j=1}^p \\beta_j^2,\n   $$\n   此式包含对非截距系数 $\\beta_j$（$j \\ge 1$）的 $L_2$ 惩罚。这种惩罚减少了参数估计的方差，在信号强或数据有限时稳定学习过程，从而在估计阶段直接对抗过拟合。\n\n   $\\mathcal{L}$ 关于 $\\beta$ 的梯度是通过对逻辑损失进行微分得到的。记 $\\hat{p} = s(X\\tilde{\\beta})$，其中 $X$ 增广了一个全为1的列来编码截距，$\\tilde{\\beta}$ 是完整的参数向量，则梯度为\n   $$\n   \\nabla \\mathcal{L}(\\beta) = X^\\top(\\hat{p} - y) + \\lambda \\cdot (0, \\beta_1, \\ldots, \\beta_p)^\\top,\n   $$\n   其中截距的梯度没有惩罚项。这使得可以通过拟牛顿法如限制内存的Broyden-Fletcher-Goldfarb-Shanno (L-BFGS) 进行高效优化。\n\n2. 通过秩计算AUC。令 $r \\in \\mathbb{R}^n$ 为预测概率。用 $n_+$ 和 $n_-$ 表示正例和负例的数量。令 $\\text{rank}(r)$ 提供考虑了平局的平均秩。则\n   $$\n   \\text{AUC}(r, y) = \\frac{\\sum_{i: y_i = 1} \\text{rank}(r_i) - \\frac{n_+(n_+ + 1)}{2}}{n_+ n_-},\n   $$\n   前提是 $n_+ \\ge 1$ 和 $n_- \\ge 1$，否则其为未定义（非数值）。此表达式在代数上等价于 $\\mathbb{P}(r^+ > r^-)$ 的经验估计加上一半的平局概率。\n\n3. 自助法乐观度校正。自助法通过从观测数据中有放回地重采样来近似抽样分布下的期望值。对于乐观度估计，我们：\n   - 通过从 $\\{1,\\ldots,n\\}$ 中有放回地抽样 $n$ 个索引来抽取自助样本 $(X^{(b)}, y^{(b)})$。\n   - 在每个自助样本上训练模型以获得 $\\hat{\\beta}^{(b)}$。\n   - 使用来自 $\\hat{\\beta}^{(b)}$ 的预测，计算自助样本上的 $AUC_{\\text{boot}}^{(b)}$ 和原始样本上的 $AUC_{\\text{orig}}^{(b)}$。\n   - 将每个复制 $b$ 的乐观度定义为 $AUC_{\\text{boot}}^{(b)} - AUC_{\\text{orig}}^{(b)}$，排除任一AUC未定义的复制。\n   在所有复制中平均乐观度，可以得到表观性能预期膨胀的估计。表观AUC是通过在原始样本上训练并在同一样本上评估来计算的。从表观AUC中减去平均乐观度，得到乐观度校正的AUC：\n   $$\n   \\text{AUC}_{\\text{corrected}} \\approx \\text{AUC}_{\\text{apparent}} - \\mathbb{E}[\\text{optimism}],\n   $$\n   其中期望由自助法平均值近似。这种校正通过定量地移除表观性能中可能由拟合噪声而非信号引起的部分，从而减轻了过拟合，因此能更好地近似未来数据的样本外性能。\n\n4. 用于可测试性的数据生成。对于每个测试用例，使用提供的种子生成具有独立标准正态条目的 $X$，计算 $z_i = \\beta_0^* + \\sum_{j} x_{ij} \\beta_j^*$，并抽样 $y_i \\sim \\text{Bernoulli}(s(z_i))$。这种构造在科学上是现实的，与广义线性模型一致，并能在不同信号强度和类别不平衡下进行受控评估。\n\n算法摘要：\n- 对于每个测试用例 $(\\text{seed}, n, p, \\beta^*, \\beta_0^*, \\lambda, B)$:\n  1. 生成 $(X, y)$；拟合惩罚逻辑回归以获得 $\\hat{\\beta}$；计算 $\\text{AUC}_{\\text{apparent}}$。\n  2. 对于 $b = 1,\\ldots,B$：进行自助法重采样索引；在 $(X^{(b)}, y^{(b)})$ 上拟合；计算 $AUC_{\\text{boot}}^{(b)}$ 和 $AUC_{\\text{orig}}^{(b)}$；如果两个AUC都已定义，则记录乐观度。\n  3. 计算有效复制的平均乐观度，并从 $\\text{AUC}_{\\text{apparent}}$ 中减去它，得到 $\\text{AUC}_{\\text{corrected}}$。\n  4. 将 $\\text{AUC}_{\\text{corrected}}$ 四舍五入到 $6$ 位小数。\n\n最终的程序遵循这些原则，生成一行包含指定测试套件的乐观度校正AUC值的输出。通过减少性能估计中的偏差，乐观度校正直接解决了生物标志物模型开发中的过拟合问题，从而增强了精准医疗中诊断性或预测性生物标志物声明的可靠性。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.optimize import minimize\nfrom scipy.stats import rankdata\n\ndef sigmoid(z):\n    return 1.0 / (1.0 + np.exp(-z))\n\ndef fit_logistic_l2(X, y, lam):\n    \"\"\"\n    Fit penalized logistic regression with L2 penalty on non-intercept coefficients.\n    X: shape (n, p), features (no intercept column).\n    y: shape (n,), binary labels 0/1.\n    lam: float, L2 penalty weight.\n    Returns beta of shape (p+1,), including intercept as beta[0].\n    \"\"\"\n    n, p = X.shape\n    # Augment X with intercept column\n    X_aug = np.hstack([np.ones((n, 1)), X])\n\n    # Objective: regularized negative log-likelihood\n    def nll(beta):\n        z = X_aug @ beta\n        p_hat = sigmoid(z)\n        # Numerical stability: clip p_hat to avoid log(0)\n        eps = 1e-12\n        p_hat = np.clip(p_hat, eps, 1 - eps)\n        # Penalize non-intercept coefficients\n        penalty = 0.5 * lam * np.sum(beta[1:] ** 2)\n        return -np.sum(y * np.log(p_hat) + (1 - y) * np.log(1 - p_hat)) + penalty\n\n    # Gradient of the objective\n    def grad(beta):\n        z = X_aug @ beta\n        p_hat = sigmoid(z)\n        # Gradient from likelihood\n        g = X_aug.T @ (p_hat - y)\n        # Add penalty gradient (excluding intercept)\n        g[1:] += lam * beta[1:]\n        return g\n\n    # Initialize beta to zeros\n    beta0 = np.zeros(p + 1, dtype=float)\n    # Optimize using L-BFGS-B\n    res = minimize(nll, beta0, jac=grad, method=\"L-BFGS-B\")\n    return res.x\n\ndef auc_rank(scores, y):\n    \"\"\"\n    Compute AUC using rank-based method that handles ties.\n    Returns np.nan if there are no positives or no negatives.\n    \"\"\"\n    y = np.asarray(y)\n    scores = np.asarray(scores)\n    pos_mask = (y == 1)\n    neg_mask = (y == 0)\n    n_pos = np.sum(pos_mask)\n    n_neg = np.sum(neg_mask)\n    if n_pos == 0 or n_neg == 0:\n        return np.nan\n    ranks = rankdata(scores, method='average')\n    sum_ranks_pos = np.sum(ranks[pos_mask])\n    auc = (sum_ranks_pos - n_pos * (n_pos + 1) / 2.0) / (n_pos * n_neg)\n    return float(auc)\n\ndef bootstrap_optimism_corrected_auc(X, y, lam, B, rng):\n    \"\"\"\n    Compute optimism-corrected AUC via bootstrap resampling.\n    X: (n, p), y: (n,), lam: L2 penalty weight, B: number of bootstraps.\n    rng: numpy Generator for reproducibility.\n    \"\"\"\n    # Apparent fit\n    beta_app = fit_logistic_l2(X, y, lam)\n    p_app = sigmoid(np.hstack([np.ones((X.shape[0], 1)), X]) @ beta_app)\n    auc_app = auc_rank(p_app, y)\n\n    # Bootstrap optimism\n    n = X.shape[0]\n    optimisms = []\n    for b in range(B):\n        idx = rng.integers(0, n, size=n)\n        Xb = X[idx]\n        yb = y[idx]\n        # Fit on bootstrap sample\n        beta_b = fit_logistic_l2(Xb, yb, lam)\n        # AUC on bootstrap sample\n        pb_boot = sigmoid(np.hstack([np.ones((Xb.shape[0], 1)), Xb]) @ beta_b)\n        auc_boot = auc_rank(pb_boot, yb)\n        # AUC on original sample using bootstrap-fitted model\n        pb_orig = sigmoid(np.hstack([np.ones((X.shape[0], 1)), X]) @ beta_b)\n        auc_orig = auc_rank(pb_orig, y)\n        if not (np.isnan(auc_boot) or np.isnan(auc_orig)):\n            optimisms.append(auc_boot - auc_orig)\n    if len(optimisms) == 0 or np.isnan(auc_app):\n        return np.nan\n    mean_optimism = float(np.mean(optimisms))\n    corrected = auc_app - mean_optimism\n    # Bound within [0,1] for numerical sanity (AUC is in [0,1])\n    corrected = min(max(corrected, 0.0), 1.0)\n    return corrected\n\ndef generate_data(seed, n, p, beta_star, beta0_star):\n    \"\"\"\n    Generate synthetic data X, y with standard normal features and logistic Bernoulli responses.\n    \"\"\"\n    rng = np.random.default_rng(seed)\n    X = rng.normal(loc=0.0, scale=1.0, size=(n, p))\n    z = beta0_star + X @ np.asarray(beta_star)\n    prob = sigmoid(z)\n    y = rng.binomial(1, prob, size=n).astype(int)\n    return X, y, rng\n\ndef solve():\n    # Define the test cases from the problem statement.\n    # Each case: (seed, n, p, beta_star, beta0_star, lambda, B)\n    test_cases = [\n        (42, 120, 3, [0.6, -0.4, 0.8], -0.2, 1.0, 200),\n        (314, 100, 2, [2.5, -2.0], 0.0, 2.0, 150),\n        (7, 35, 4, [0.2, 0.1, -0.1, 0.0], -0.1, 0.5, 100),\n        (2021, 200, 5, [0.3, 0.0, -0.2, 0.1, 0.05], -2.0, 1.0, 200),\n    ]\n\n    results = []\n    for seed, n, p, beta_star, beta0_star, lam, B in test_cases:\n        X, y, rng = generate_data(seed, n, p, beta_star, beta0_star)\n        corrected_auc = bootstrap_optimism_corrected_auc(X, y, lam, B, rng)\n        # Round to 6 decimals as required\n        if np.isnan(corrected_auc):\n            results.append(\"nan\")\n        else:\n            results.append(f\"{np.round(corrected_auc, 6):.6f}\")\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        }
    ]
}