{
    "hands_on_practices": [
        {
            "introduction": "生物标志物的核心价值在于其能够为临床决策提供信息。本练习将基础的诊断性能指标（如灵敏度和特异度）与贝叶斯定理相结合，演示了如何利用生物标志物检测结果来更新患者的疾病概率。通过从第一性原理推导验后几率，您将掌握将群体水平的统计数据应用于个体患者风险评估的关键技能，这是精准医疗中定量临床推理的基石 。",
            "id": "4319496",
            "problem": "一种连续的游离脱氧核糖核酸 (cfDNA) 甲基化特征，由标量生物标志物 $B$ 表示，正在一个有症状队列中作为结直肠癌的诊断性生物标志物进行评估。在精准医疗和基因组诊断学中使用的生物标志物分类法中，诊断性生物标志物指示当前疾病状态的存在与否，预后性生物标志物对独立于治疗的未来结局风险进行分层，而预测性生物标志物则估计差异性治疗反应。在这里，$B$ 用于分类疾病状态，而非未来风险或治疗反应。基于受试者工作特征 (ROC) 分析选择一个阈值 $t^{\\ast}$，如果 $B \\ge t^{\\ast}$，则产生二元检验结果 $T^{+}$，否则为 $T^{-}$。\n\n在一个外部队列上验证的阈值 $t^{\\ast}$ 下，观察到的灵敏度和特异度分别为 $sens = 0.83$ 和 $spec = 0.91$。其中，灵敏度定义为 $P(T^{+}\\mid D)$，特异度定义为 $P(T^{-}\\mid \\neg D)$，$D$ 表示事件“患病”，$\\neg D$ 表示“未患病”。对于某特定患者，一个校准良好的临床风险模型在生物标志物测量前提供了疾病的先验概率 $P(D) = 0.18$。\n\n仅从灵敏度和特异度的基本定义以及 Bayes 定理出发，(i) 推导阳性似然比 $LR^{+}$ 和阴性似然比 $LR^{-}$ 关于 $sens$ 和 $spec$ 的表达式，以及 (ii) 推导 Bayes 定理的比值形式，该形式将检验后比值与检验前比值和相应的似然比联系起来。然后，利用这些推导出的结果，计算该患者在阈值 $t^{\\ast}$ 下得到阳性检验结果后的检验后比值 $odds(D\\mid T^{+})$。\n\n将 $odds(D\\mid T^{+})$ 的最终数值答案表示为无单位的比率，并四舍五入到四位有效数字。",
            "solution": "问题陈述经评估有效。它在科学上基于生物统计学和医学诊断学的既定原则，提法得当，提供了所有必要信息，并且其语言和定义是客观的。所提供的数据（$sens=0.83$，$spec=0.91$，$P(D)=0.18$）内部一致，且对于真实世界的临床场景是合理的。该问题是 Bayes 推断的一个标准的、非平凡的应用，按要求需要从第一性原理进行严格推导。\n\n解决方案首先推导所需的似然比表达式和 Bayes 定理的比值形式，然后应用这些结果来计算最终的数值答案。\n\n(i) 似然比的推导\n\n阳性似然比 $LR^{+}$ 定义为患病人群中出现阳性检验结果的概率与非患病人群中出现阳性检验结果的概率之比。\n$$LR^{+} \\equiv \\frac{P(T^{+}\\mid D)}{P(T^{+}\\mid \\neg D)}$$\n分子由灵敏度 $sens$ 的定义给出：\n$$P(T^{+}\\mid D) = sens$$\n分母 $P(T^{+}\\mid \\neg D)$ 是假阳性率。它可以用特异度 $spec$ 来表示。根据定义，特异度是在非患病人群中出现阴性检验结果的概率：\n$$spec = P(T^{-}\\mid \\neg D)$$\n因为对于任何给定的条件（这里是 $\\neg D$），检验结果必须是阳性（$T^{+}$）或阴性（$T^{-}$），所以它们的概率之和必须为$1$：\n$$P(T^{+}\\mid \\neg D) + P(T^{-}\\mid \\neg D) = 1$$\n求解 $P(T^{+}\\mid \\neg D)$ 得：\n$$P(T^{+}\\mid \\neg D) = 1 - P(T^{-}\\mid \\neg D) = 1 - spec$$\n将分子和分母的表达式代回 $LR^{+}$ 的定义中，得到所需的表达式：\n$$LR^{+} = \\frac{sens}{1 - spec}$$\n\n类似地，阴性似然比 $LR^{-}$ 定义为患病人群中出现阴性检验结果的概率与非患病人群中出现阴性检验结果的概率之比。\n$$LR^{-} \\equiv \\frac{P(T^{-}\\mid D)}{P(T^{-}\\mid \\neg D)}$$\n分母由特异度的定义直接给出：\n$$P(T^{-}\\mid \\neg D) = spec$$\n分子 $P(T^{-}\\mid D)$ 是假阴性率。它可以用灵敏度来表示。对于患病人群（$D$），阳性和阴性检验结果的概率之和必须为$1$：\n$$P(T^{+}\\mid D) + P(T^{-}\\mid D) = 1$$\n求解 $P(T^{-}\\mid D)$ 得：\n$$P(T^{-}\\mid D) = 1 - P(T^{+}\\mid D) = 1 - sens$$\n将这些分子和分母的表达式代入 $LR^{-}$ 的定义中，得到最终表达式：\n$$LR^{-} = \\frac{1 - sens}{spec}$$\n\n(ii) Bayes 定理比值形式的推导\n\n事件 $A$ 的比值定义为该事件发生的概率与不发生的概率之比，即 $odds(A) = \\frac{P(A)}{P(\\neg A)}$。因此，给定阳性检验结果 $T^{+}$ 后，疾病的检验后比值为：\n$$odds(D\\mid T^{+}) = \\frac{P(D\\mid T^{+})}{P(\\neg D\\mid T^{+})}$$\n我们应用 Bayes 定理来找出分子和分母的表达式。对于分子：\n$$P(D\\mid T^{+}) = \\frac{P(T^{+}\\mid D)P(D)}{P(T^{+})}$$\n对于分母：\n$$P(\\neg D\\mid T^{+}) = \\frac{P(T^{+}\\mid \\neg D)P(\\neg D)}{P(T^{+})}$$\n将这些代入比值表达式中，两个表达式分母中的公共项 $P(T^{+})$ 被消去：\n$$odds(D\\mid T^{+}) = \\frac{\\frac{P(T^{+}\\mid D)P(D)}{P(T^{+})}}{\\frac{P(T^{+}\\mid \\neg D)P(\\neg D)}{P(T^{+})}} = \\frac{P(T^{+}\\mid D)P(D)}{P(T^{+}\\mid \\neg D)P(\\neg D)}$$\n这个表达式可以重新组合，将似然度与先验概率分开：\n$$odds(D\\mid T^{+}) = \\left(\\frac{P(T^{+}\\mid D)}{P(T^{+}\\mid \\neg D)}\\right) \\left(\\frac{P(D)}{P(\\neg D)}\\right)$$\n第一项是阳性似然比 $LR^{+}$ 的定义。第二项是检验前（或先验）疾病比值 $odds(D)$ 的定义。因此，我们得到了 Bayes 定理的比值形式：\n$$odds(D\\mid T^{+}) = LR^{+} \\times odds(D)$$\n这个基本关系表明，检验后比值等于检验前比值乘以与检验结果相对应的似然比。\n\n(iii) 检验后比值 $odds(D\\mid T^{+})$ 的计算\n\n使用推导出的结果，我们现在可以计算该患者的检验后比值。\n首先，我们根据给定的先验概率 $P(D) = 0.18$ 计算检验前比值 $odds(D)$。\n未患病的概率为 $P(\\neg D) = 1 - P(D) = 1 - 0.18 = 0.82$。\n检验前比值为：\n$$odds(D) = \\frac{P(D)}{P(\\neg D)} = \\frac{0.18}{0.82}$$\n接下来，我们使用提供的灵敏度 $sens = 0.83$ 和特异度 $spec = 0.91$ 计算阳性似然比 $LR^{+}$。\n$$LR^{+} = \\frac{sens}{1 - spec} = \\frac{0.83}{1 - 0.91} = \\frac{0.83}{0.09}$$\n最后，我们使用 Bayes 定理的比值形式计算检验后比值：\n$$odds(D\\mid T^{+}) = LR^{+} \\times odds(D) = \\left(\\frac{0.83}{0.09}\\right) \\times \\left(\\frac{0.18}{0.82}\\right)$$\n计算过程如下：\n$$odds(D\\mid T^{+}) = \\frac{0.83 \\times 0.18}{0.09 \\times 0.82} = \\frac{0.1494}{0.0738}$$\n$$odds(D\\mid T^{+}) \\approx 2.024389...$$\n将结果四舍五入到四位有效数字，得到 $2.024$。",
            "answer": "$$\\boxed{2.024}$$"
        },
        {
            "introduction": "在真实的临床研究中，由于伦理或成本等限制，并非所有受试者都能接受金标准检测，这会导致验证偏倚 (verification bias)。本练习模拟了这一常见挑战，要求您运用逆概率加权 (inverse probability weighting, IPW) 方法来校正偏倚，从而获得无偏的灵敏度和特异度估计。这项实践将使您深入理解评估生物标志物时可能遇到的系统性误差，并掌握一种重要的统计校正技术，以确保研究结果的有效性 。",
            "id": "4319561",
            "problem": "一种癌症基因组诊断生物标志物正在被评估其作为诊断生物标志物的效用，用以区分患病个体与非患病个体。二元生物标志物检测结果由 $T \\in \\{+,-\\}$ 表示，由确定的参考标准（例如，全外显子组测序）决定的疾病状态由 $D \\in \\{1,0\\}$ 表示，其中 $D=1$ 表示存在疾病。受试者根据标准临床特征被分入检测前临床风险层 $S \\in \\{\\mathrm{High}, \\mathrm{Low}\\}$。由于伦理和后勤限制，参考标准并未应用于所有筛选的受试者，导致部分验证。是否进行验证的决定基于 $S$ 和 $T$，且接受参考标准的概率 $\\pi_{s,t} = \\Pr(\\text{verified} \\mid S=s, T=t)$ 从研究设计中是已知的。假设参考标准是完美的，并且在给定 $(S,T)$ 的情况下，$D$ 的缺失是随机缺失（missing at random），即 $D \\perp \\!\\!\\! \\perp \\text{verified} \\mid (S,T)$。\n\n在接受了参考标准的受试者中，观察到以下计数：\n- 高风险, $T=+$: $n_{\\mathrm{H},+}^{V} = 360$，其中 $d_{\\mathrm{H},+} = 300$ 为 $D=1$，且 $\\pi_{\\mathrm{H},+} = 0.9$。\n- 高风险, $T=-$: $n_{\\mathrm{H},-}^{V} = 240$，其中 $d_{\\mathrm{H},-} = 48$ 为 $D=1$，且 $\\pi_{\\mathrm{H},-} = 0.6$。\n- 低风险, $T=+$: $n_{\\mathrm{L},+}^{V} = 250$，其中 $d_{\\mathrm{L},+} = 125$ 为 $D=1$，且 $\\pi_{\\mathrm{L},+} = 0.5$。\n- 低风险, $T=-$: $n_{\\mathrm{L},-}^{V} = 200$，其中 $d_{\\mathrm{L},-} = 10$ 为 $D=1$，且 $\\pi_{\\mathrm{L},-} = 0.2$。\n\n从基本定义 敏感度 = $\\Pr(T=+ \\mid D=1)$ 和 特异度 = $\\Pr(T=- \\mid D=0)$ 出发，并利用给定缺失假设下的概率定律，推导一个逆概率加权估计量来校正验证偏倚，并应用它来计算敏感度和特异度的无偏估计。然后计算校正后的尤登指数 $J$，其定义为 $J = \\text{敏感度} + \\text{特异度} - 1$。将 $J$ 的最终值以小数形式报告，并将答案四舍五入到四位有效数字。",
            "solution": "### 步骤1：提取已知信息\n问题提供以下信息：\n-   一个二元生物标志物检测结果 $T \\in \\{+,-\\}$。\n-   一个二元疾病状态 $D \\in \\{1,0\\}$，其中 $D=1$ 表示患病。\n-   一个检测前临床风险分层 $S \\in \\{\\mathrm{High}, \\mathrm{Low}\\}$。\n-   疾病状态 $D$ 的验证是部分的。设 $V$ 为验证的指示变量，如果已验证则 $V=1$，否则 $V=0$。\n-   验证的概率取决于风险层 $S$ 和检测结果 $T$，由 $\\pi_{s,t} = \\Pr(V=1 \\mid S=s, T=t)$ 给出。\n-   一个假设，即在给定风险层和检测结果的情况下，疾病状态是随机缺失（MAR）的：$D \\perp \\!\\!\\! \\perp V \\mid (S,T)$。\n-   $D$ 的参考标准是完美的。\n-   从已验证样本中观察到的计数和验证概率：\n    1.  对于 $(S=\\mathrm{High}, T=+)$：已验证的受试者数量 $n_{\\mathrm{H},+}^{V} = 360$，患病受试者数量 $d_{\\mathrm{H},+} = 300$，以及验证概率 $\\pi_{\\mathrm{H},+} = 0.9$。\n    2.  对于 $(S=\\mathrm{High}, T=-)$：$n_{\\mathrm{H},-}^{V} = 240$，$d_{\\mathrm{H},-} = 48$，以及 $\\pi_{\\mathrm{H},-} = 0.6$。\n    3.  对于 $(S=\\mathrm{Low}, T=+)$：$n_{\\mathrm{L},+}^{V} = 250$，$d_{\\mathrm{L},+} = 125$，以及 $\\pi_{\\mathrm{L},+} = 0.5$。\n    4.  对于 $(S=\\mathrm{Low}, T=-)$：$n_{\\mathrm{L},-}^{V} = 200$，$d_{\\mathrm{L},-} = 10$，以及 $\\pi_{\\mathrm{L},-} = 0.2$。\n-   定义：\n    -   敏感度 = $\\Pr(T=+ \\mid D=1)$\n    -   特异度 = $\\Pr(T=- \\mid D=0)$\n    -   尤登指数 $J$：$J = \\text{敏感度} + \\text{特异度} - 1$。\n-   目标：推导一个逆概率加权（IPW）估计量用于敏感度和特异度，以校正验证偏倚，并计算校正后的尤登指数 $J$。\n\n### 步骤2：使用提取的已知信息进行验证\n该问题在科学上和数学上都是合理的。它描述了诊断测试评估中的一个常见场景，称为验证偏倚，即疾病的“金标准”测试并未应用于所有参与者。提出的校正方法，逆概率加权（IPW），是处理随机缺失（MAR）数据的标准且适当的统计技术，这是一个明确说明的假设。所有必要的数据和定义都已提供，并且没有矛盾或含糊之处。问题提法得当且客观。\n\n### 步骤3：结论与行动\n问题有效。将提供完整解答。\n\n### 解题推导\n目标是估计敏感度 $\\text{Se} = \\Pr(T=+ \\mid D=1)$ 和特异度 $\\text{Sp} = \\Pr(T=- \\mid D=0)$。这些可以使用来自完整（但部分未观察到）研究总体的计数来表示：\n$$\n\\text{Se} = \\frac{N_{T=+, D=1}}{N_{D=1}} \\quad \\text{和} \\quad \\text{Sp} = \\frac{N_{T=-, D=0}}{N_{D=0}}\n$$\n其中 $N_{t,d}$ 是检测结果为 $t$ 且疾病状态为 $d$ 的受试者数量，而 $N_d$ 是疾病状态为 $d$ 的受试者总数。\n\n由于验证偏倚，我们不能直接使用来自已验证样本的计数。随机缺失假设 $D \\perp \\!\\!\\! \\perp V \\mid (S,T)$ 允许我们使用逆概率加权来估计完整总体的计数。IPW的原理是，每个已验证的受试者不仅代表其自身，还代表了来自同一层 $(s,t)$ 的另外 $\\frac{1}{\\pi_{s,t}} - 1$ 名未验证的受试者。因此，每个已验证的受试者被赋予一个权重 $w_{s,t} = \\frac{1}{\\pi_{s,t}}$。\n\n我们可以通过对风险层 $S$ 的观察受试者的加权计数求和，来估计混淆矩阵（$T \\times D$）四个单元格中每个单元格的总计数。\n\n我们将来自层 $(s,t)$ 的已验证样本中观察到的患病受试者数量表示为 $d_{s,t}$，非患病受试者数量表示为 $h_{s,t} = n_{s,t}^V - d_{s,t}$。\n\n估计的真阳性（$D=1, T=+$）总数为：\n$$\n\\hat{N}_{TP} = \\sum_{s \\in \\{\\mathrm{H,L}\\}} \\frac{d_{s,+}}{\\pi_{s,+}} = \\frac{d_{\\mathrm{H},+}}{\\pi_{\\mathrm{H},+}} + \\frac{d_{\\mathrm{L},+}}{\\pi_{\\mathrm{L},+}}\n$$\n估计的假阴性（$D=1, T=-$）总数为：\n$$\n\\hat{N}_{FN} = \\sum_{s \\in \\{\\mathrm{H,L}\\}} \\frac{d_{s,-}}{\\pi_{s,-}} = \\frac{d_{\\mathrm{H},-}}{\\pi_{\\mathrm{H},-}} + \\frac{d_{\\mathrm{L},-}}{\\pi_{\\mathrm{L},-}}\n$$\n估计的假阳性（$D=0, T=+$）总数为：\n$$\n\\hat{N}_{FP} = \\sum_{s \\in \\{\\mathrm{H,L}\\}} \\frac{n_{s,+}^V - d_{s,+}}{\\pi_{s,+}} = \\frac{n_{\\mathrm{H},+}^V - d_{\\mathrm{H},+}}{\\pi_{\\mathrm{H},+}} + \\frac{n_{\\mathrm{L},+}^V - d_{\\mathrm{L},+}}{\\pi_{\\mathrm{L},+}}\n$$\n估计的真阴性（$D=0, T=-$）总数为：\n$$\n\\hat{N}_{TN} = \\sum_{s \\in \\{\\mathrm{H,L}\\}} \\frac{n_{s,-}^V - d_{s,-}}{\\pi_{s,-}} = \\frac{n_{\\mathrm{H},-}^V - d_{\\mathrm{H},-}}{\\pi_{\\mathrm{H},-}} + \\frac{n_{\\mathrm{L},-}^V - d_{\\mathrm{L},-}}{\\pi_{\\mathrm{L},-}}\n$$\n\n由此，我们可以估计患病和非患病个体的总数：\n$$\n\\hat{N}_{D=1} = \\hat{N}_{TP} + \\hat{N}_{FN}\n$$\n$$\n\\hat{N}_{D=0} = \\hat{N}_{FP} + \\hat{N}_{TN}\n$$\n那么，敏感度和特异度的IPW估计量为：\n$$\n\\widehat{\\text{Se}} = \\frac{\\hat{N}_{TP}}{\\hat{N}_{D=1}} \\quad \\text{和} \\quad \\widehat{\\text{Sp}} = \\frac{\\hat{N}_{TN}}{\\hat{N}_{D=0}}\n$$\n\n### 计算\n首先，我们将给定值代入估计计数的公式中。\n-   高风险数据 ($S=\\mathrm{H}$):\n    -   $T=+$: $n_{\\mathrm{H},+}^V=360, d_{\\mathrm{H},+}=300, n_{\\mathrm{H},+}^V-d_{\\mathrm{H},+}=60, \\pi_{\\mathrm{H},+}=0.9$\n    -   $T=-$: $n_{\\mathrm{H},-}^V=240, d_{\\mathrm{H},-}=48, n_{\\mathrm{H},-}^V-d_{\\mathrm{H},-}=192, \\pi_{\\mathrm{H},-}=0.6$\n-   低风险数据 ($S=\\mathrm{L}$):\n    -   $T=+$: $n_{\\mathrm{L},+}^V=250, d_{\\mathrm{L},+}=125, n_{\\mathrm{L},+}^V-d_{\\mathrm{L},+}=125, \\pi_{\\mathrm{L},+}=0.5$\n    -   $T=-$: $n_{\\mathrm{L},-}^V=200, d_{\\mathrm{L},-}=10, n_{\\mathrm{L},-}^V-d_{\\mathrm{L},-}=190, \\pi_{\\mathrm{L},-}=0.2$\n\n估计的计数为：\n$$\n\\hat{N}_{TP} = \\frac{300}{0.9} + \\frac{125}{0.5} = \\frac{1000}{3} + 250 = \\frac{1000 + 750}{3} = \\frac{1750}{3}\n$$\n$$\n\\hat{N}_{FN} = \\frac{48}{0.6} + \\frac{10}{0.2} = 80 + 50 = 130\n$$\n$$\n\\hat{N}_{FP} = \\frac{60}{0.9} + \\frac{125}{0.5} = \\frac{200}{3} + 250 = \\frac{200 + 750}{3} = \\frac{950}{3}\n$$\n$$\n\\hat{N}_{TN} = \\frac{192}{0.6} + \\frac{190}{0.2} = 320 + 950 = 1270\n$$\n\n接下来，我们计算估计的患病和非患病个体的总数：\n$$\n\\hat{N}_{D=1} = \\hat{N}_{TP} + \\hat{N}_{FN} = \\frac{1750}{3} + 130 = \\frac{1750 + 390}{3} = \\frac{2140}{3}\n$$\n$$\n\\hat{N}_{D=0} = \\hat{N}_{FP} + \\hat{N}_{TN} = \\frac{950}{3} + 1270 = \\frac{950 + 3810}{3} = \\frac{4760}{3}\n$$\n\n现在，我们计算估计的敏感度和特异度：\n$$\n\\widehat{\\text{Se}} = \\frac{\\hat{N}_{TP}}{\\hat{N}_{D=1}} = \\frac{1750/3}{2140/3} = \\frac{1750}{2140} = \\frac{175}{214}\n$$\n$$\n\\widehat{\\text{Sp}} = \\frac{\\hat{N}_{TN}}{\\hat{N}_{D=0}} = \\frac{1270}{4760/3} = \\frac{1270 \\times 3}{4760} = \\frac{3810}{4760} = \\frac{381}{476}\n$$\n\n最后，我们计算校正后的尤登指数 $J$：\n$$\n\\hat{J} = \\widehat{\\text{Se}} + \\widehat{\\text{Sp}} - 1 = \\frac{175}{214} + \\frac{381}{476} - 1\n$$\n为了计算该值，我们将分数转换为小数：\n$$\n\\widehat{\\text{Se}} \\approx 0.817757009...\n$$\n$$\n\\widehat{\\text{Sp}} \\approx 0.800420168...\n$$\n$$\n\\hat{J} \\approx 0.817757009 + 0.800420168 - 1 = 1.618177177 - 1 = 0.618177177...\n$$\n将结果四舍五入到四位有效数字，得到 $0.6182$。",
            "answer": "$$\n\\boxed{0.6182}\n$$"
        },
        {
            "introduction": "现代生物标志物通常是基于多维数据（如基因组学数据）构建的复杂预测模型。这类模型在训练数据上的表现（即表观性能）往往过于乐观，存在过拟合风险。本练习将指导您通过编程实现一种强大的验证技术——自助法 (bootstrap) 重抽样，以估计并校正模型的“乐观度”，从而获得更接近真实世界性能的曲线下面积 (AUC) 值。这项计算实践对于任何开发或评估复杂生物标志物模型的研究者来说，都是一项必不可少的技能，以确保模型的稳健性和泛化能力 。",
            "id": "4319570",
            "problem": "您将执行一项正式任务，该任务基于精准医疗和基因组诊断中的生物标志物模型评估。在此背景下，生物标志物可以扮演不同角色：诊断性生物标志物在特定时间点区分患病与非患病状态，预后性生物标志物在不考虑治疗的情况下对基线风险进行分层，而预测性生物标志物则指示特定治疗的差异化获益。用于诊断性或预测性生物标志物的分类模型通常依赖于对二元临床状态的概率性预测。对此类模型排序性能的一个严格度量是受试者工作特征曲线下面积（AUC），它可以表示为随机选择的阳性样本获得比随机选择的阴性样本更高模型分数的概率。在训练数据上测得的表观（样本内）性能容易出现过拟合。基于重采样的方法，如自助法重采样（bootstrap resampling），可用于估计和校正乐观偏倚（optimism）（即表观性能相对于新数据上性能的预期膨胀）。\n\n基本原理：\n- 令 $X \\in \\mathbb{R}^{n \\times p}$ 表示一个包含 $n$ 个样本和 $p$ 个特征的设计矩阵。令 $y \\in \\{0,1\\}^n$ 表示二元结果，代表与生物标志物相关的临床状态存在（$1$）或不存在（$0$）。\n- 考虑一个逻辑回归模型，其参数为 $\\beta \\in \\mathbb{R}^{p+1}$（包括一个截距项），为样本 $i$ 生成预测概率 $\\hat{p}_i = s\\!\\left(\\beta_0 + \\sum_{j=1}^{p} x_{ij}\\beta_j \\right)$，其中 $s(z) = 1/(1+e^{-z})$ 是逻辑斯谛函数。参数通过最大化正则化似然或等价地最小化正则化负对数似然来估计\n$$\n\\mathcal{L}(\\beta; X, y, \\lambda) = -\\sum_{i=1}^{n} \\left[ y_i \\log \\hat{p}_i + (1-y_i)\\log(1-\\hat{p}_i) \\right] + \\frac{\\lambda}{2}\\sum_{j=1}^{p} \\beta_j^2,\n$$\n其中 $\\lambda \\ge 0$ 是一个应用于非截距项系数的 $L_2$ 惩罚权重，以减轻不稳定性并减少过拟合。\n- 对于一个分数向量 $r \\in \\mathbb{R}^n$，受试者工作特征曲线下面积（AUC）定义为随机选择的阳性样本得分高于随机选择的阴性样本得分的概率，其中平局情况贡献一半权重。这可以通过源自 Wilcoxon-Mann-Whitney 统计量的基于秩的公式来计算。\n- 自助法原理通过从观测数据定义的经验分布中进行有放回的重采样来近似抽样分布下的期望。基于自助法的乐观偏倚估计通过在每个自助样本上训练模型，并比较其在自助样本与原始样本上的性能来进行。\n\n任务：\n实现一个程序，对每个测试用例执行以下步骤：\n1. 按如下方式生成合成数据 $(X,y)$。对于给定的 $n$、$p$、系数向量 $\\beta^* \\in \\mathbb{R}^{p}$ 和截距 $\\beta_0^* \\in \\mathbb{R}$，从独立标准正态分布中抽取 $X$。计算线性预测值 $z_i = \\beta_0^* + \\sum_{j=1}^{p} x_{ij}\\beta_j^*$，并对 $i=1,\\dots,n$ 独立采样结果 $y_i \\sim \\text{Bernoulli}(s(z_i))$，其中 $s(\\cdot)$ 是逻辑斯谛函数。使用指定的随机种子以确保可复现性。\n2. 使用数值优化器，通过最小化关于 $\\beta$ 的 $\\mathcal{L}(\\beta; X, y, \\lambda)$ 来拟合一个带惩罚的逻辑回归模型。惩罚项必须排除截距项。\n3. 在原始数据上计算表观 AUC，方法是使用拟合模型在 $X$ 上生成预测概率，然后使用能够正确处理平局情况的基于秩的方法计算其相对于 $y$ 的 AUC。如果没有阳性样本或没有阴性样本，则将 AUC 定义为非数值（not-a-number）。\n4. 执行 $B$ 次自助法重采样：\n   - 对于每个自助法重复 $b \\in \\{1,\\dots,B\\}$，从 $\\{1,\\dots,n\\}$ 中有放回地抽取大小为 $n$ 的索引自助样本，得到 $(X^{(b)}, y^{(b)})$。\n   - 在 $(X^{(b)}, y^{(b)})$ 上拟合带惩罚的逻辑回归模型以获得参数 $\\hat{\\beta}^{(b)}$。\n   - 使用来自 $\\hat{\\beta}^{(b)}$ 的预测，在 $(X^{(b)}, y^{(b)})$ 上计算 $AUC_{\\text{boot}}^{(b)}$。\n   - 使用来自 $\\hat{\\beta}^{(b)}$ 的预测，在 $(X, y)$ 上计算 $AUC_{\\text{orig}}^{(b)}$。\n   - 将重复 $b$ 的乐观偏倚定义为 $AUC_{\\text{boot}}^{(b)} - AUC_{\\text{orig}}^{(b)}$。如果由于自助样本中的类别退化（class degeneracy）导致任一 AUC 为非数值，则在计算乐观偏倚均值时排除该重复。\n5. 将表观 AUC 减去在有效自助法重复上计算出的平均乐观偏倚，从而计算出经乐观偏倚校正的 AUC。\n6. 对每个测试用例，返回经乐观偏倚校正的 AUC，结果为四舍五入到 $6$ 位小数的十进制数。\n\n您的程序必须精确实现上述过程，并处理基于秩且能感知平局情况的 AUC 计算。它必须使用带 $L_2$ 惩罚的逻辑回归，惩罚权重 $\\lambda$ 仅应用于非截距项系数。如果所有自助法重复由于类别退化而无效，则为该测试用例返回非数值指示符。\n\n测试套件：\n使用以下四个测试用例，每个用例由一个元组 $(\\text{seed}, n, p, \\beta^*, \\beta_0^*, \\lambda, B)$ 指定：\n- 用例 1：$(42, 120, 3, [0.6, -0.4, 0.8], -0.2, 1.0, 200)$。\n- 用例 2：$(314, 100, 2, [2.5, -2.0], 0.0, 2.0, 150)$。\n- 用例 3：$(7, 35, 4, [0.2, 0.1, -0.1, 0.0], -0.1, 0.5, 100)$。\n- 用例 4：$(2021, 200, 5, [0.3, 0.0, -0.2, 0.1, 0.05], -2.0, 1.0, 200)$。\n\n答案规格：\n- 对于每个测试用例，按上述方法计算经乐观偏倚校正的 AUC，并四舍五入到 $6$ 位小数。\n- 将每个最终答案表示为十进制数（而非百分比）。\n- 您的程序应生成单行输出，其中包含用方括号括起来的逗号分隔的结果列表（例如，$[0.731245,0.892310,0.501234,0.763210]$）。不要打印任何其他文本。",
            "solution": "我们首先将生物标志物的背景与一个正式的统计学习问题联系起来。诊断性生物标志物区分病例和对照组，预测性生物标志物指示治疗效益；两者通常都通过二元分类性能进行评估。受试者工作特征曲线下面积（AUC）量化了模型的排序能力：给定分数 $r \\in \\mathbb{R}^n$ 和标签 $y \\in \\{0,1\\}^n$，它等于随机选择的阳性样本得分超过随机选择的阴性样本得分的概率，其中平局情况贡献一半权重。这可以通过源自 Wilcoxon-Mann-Whitney 公式的基于秩的统计量来计算。\n\n当模型捕捉到训练数据中的特有噪声时，就会发生过拟合，从而夸大了表观性能（在用于训练的同一数据上测量的性能）。自助法原理提供了一种方法，通过重采样来近似经验分布下的期望，从而估计和校正这种性能膨胀（乐观偏倚）。\n\n基于原理的推导和算法设计：\n1. 模型与估计。对于二元结果，我们通过逻辑斯谛函数 $s(z) = 1/(1+e^{-z})$ 对条件概率进行建模。对于具有特征 $x_i \\in \\mathbb{R}^p$ 的样本 $i$，模型为 $\\hat{p}_i = s\\!\\left(\\beta_0 + \\sum_{j=1}^p x_{ij}\\beta_j\\right)$。参数 $\\beta = (\\beta_0,\\ldots,\\beta_p)$ 通过最小化正则化负对数似然来估计\n   $$\n   \\mathcal{L}(\\beta; X, y, \\lambda) = -\\sum_{i=1}^n \\left[ y_i \\log \\hat{p}_i + (1-y_i)\\log(1-\\hat{p}_i) \\right] + \\frac{\\lambda}{2}\\sum_{j=1}^p \\beta_j^2,\n   $$\n   该式包含一个对非截距项系数 $\\beta_j$（$j \\ge 1$）的 $L_2$ 惩罚。此惩罚减少了参数估计的方差，从而稳定了学习过程，尤其是在信号强或数据有限的情况下，进而在估计阶段直接对抗过拟合。\n\n   $\\mathcal{L}$ 关于 $\\beta$ 的梯度是通过对逻辑斯谛损失进行微分得到的。记 $\\hat{p} = s(X\\tilde{\\beta})$，其中 $X$ 增广了一个全为 1 的列以编码截距项，$\\tilde{\\beta}$ 是完整的参数向量，则梯度为\n   $$\n   \\nabla \\mathcal{L}(\\beta) = X^\\top(\\hat{p} - y) + \\lambda \\cdot (0, \\beta_1, \\ldots, \\beta_p)^\\top,\n   $$\n   其中截距项的梯度没有惩罚项。这使得可以通过诸如限制内存的 Broyden-Fletcher-Goldfarb-Shanno（L-BFGS）等拟牛顿法进行高效优化。\n\n2. 通过秩计算 AUC。令 $r \\in \\mathbb{R}^n$ 为预测概率。用 $n_+$ 和 $n_-$ 表示阳性和阴性样本的数量。令 $\\text{rank}(r)$ 提供考虑了平局情况的平均秩。则\n   $$\n   \\text{AUC}(r, y) = \\frac{\\sum_{i: y_i = 1} \\text{rank}(r_i) - \\frac{n_+(n_+ + 1)}{2}}{n_+ n_-},\n   $$\n   条件是 $n_+ \\ge 1$ 且 $n_- \\ge 1$，否则其未定义（非数值）。该表达式在代数上等价于 $\\mathbb{P}(r^+ > r^-)$ 的经验估计值加上平局概率的一半。\n\n3. 自助法乐观偏倚校正。自助法通过从观测数据中有放回地重采样来近似抽样分布下的期望。对于乐观偏倚估计，我们：\n   - 通过从 $\\{1,\\ldots,n\\}$ 中有放回地抽样 $n$ 个索引，来抽取自助样本 $(X^{(b)}, y^{(b)})$。\n   - 在每个自助样本上训练模型以获得 $\\hat{\\beta}^{(b)}$。\n   - 使用来自 $\\hat{\\beta}^{(b)}$ 的预测，在自助样本上计算 $AUC_{\\text{boot}}^{(b)}$，在原始样本上计算 $AUC_{\\text{orig}}^{(b)}$。\n   - 将每个重复 $b$ 的乐观偏倚定义为 $AUC_{\\text{boot}}^{(b)} - AUC_{\\text{orig}}^{(b)}$，排除任一 AUC 未定义的重复。\n   对所有重复的乐观偏倚取平均，可以得到表观性能预期膨胀的估计值。表观 AUC 是通过在原始样本上训练并在同一批样本上评估来计算的。从表观 AUC 中减去平均乐观偏倚，即可得到经乐观偏倚校正的 AUC：\n   $$\n   \\text{AUC}_{\\text{corrected}} \\approx \\text{AUC}_{\\text{apparent}} - \\mathbb{E}[\\text{optimism}],\n   $$\n   其中期望值由自助法均值近似。这种校正通过定量地移除表观性能中可能由拟合噪声而非信号引起的部分来减轻过拟合，从而更好地近似未来数据上预期的样本外性能。\n\n4. 为可测试性生成数据。对于每个测试用例，使用提供的种子生成具有独立标准正态条目的 $X$，计算 $z_i = \\beta_0^* + \\sum_{j} x_{ij} \\beta_j^*$，并抽样 $y_i \\sim \\text{Bernoulli}(s(z_i))$。这种构造在科学上是现实的，与广义线性模型一致，并能在不同的信号强度和类别不平衡情况下进行受控评估。\n\n算法总结：\n- 对于每个测试用例 $(\\text{seed}, n, p, \\beta^*, \\beta_0^*, \\lambda, B)$：\n  1. 生成 $(X, y)$；拟合带惩罚的逻辑回归以获得 $\\hat{\\beta}$；计算 $\\text{AUC}_{\\text{apparent}}$。\n  2. 对于 $b = 1,\\ldots,B$：对索引进行自助法重采样；在 $(X^{(b)}, y^{(b)})$ 上拟合；计算 $AUC_{\\text{boot}}^{(b)}$ 和 $AUC_{\\text{orig}}^{(b)}$；如果两个 AUC 都有定义，则记录乐观偏倚。\n  3. 计算有效重复的平均乐观偏倚，并从 $\\text{AUC}_{\\text{apparent}}$ 中减去它，得到 $\\text{AUC}_{\\text{corrected}}$。\n  4. 将 $\\text{AUC}_{\\text{corrected}}$ 四舍五入到 $6$ 位小数。\n\n最终程序遵循这些原则，生成包含指定测试套件的经乐观偏倚校正的 AUC 值的单行输出。乐观偏倚校正通过减少性能估计中的偏差，直接解决了生物标志物模型开发中的过拟合问题，从而增强了精准医疗中诊断性或预测性生物标志物声明的可靠性。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.optimize import minimize\nfrom scipy.stats import rankdata\n\ndef sigmoid(z):\n    return 1.0 / (1.0 + np.exp(-z))\n\ndef fit_logistic_l2(X, y, lam):\n    \"\"\"\n    Fit penalized logistic regression with L2 penalty on non-intercept coefficients.\n    X: shape (n, p), features (no intercept column).\n    y: shape (n,), binary labels 0/1.\n    lam: float, L2 penalty weight.\n    Returns beta of shape (p+1,), including intercept as beta[0].\n    \"\"\"\n    n, p = X.shape\n    # Augment X with intercept column\n    X_aug = np.hstack([np.ones((n, 1)), X])\n\n    # Objective: regularized negative log-likelihood\n    def nll(beta):\n        z = X_aug @ beta\n        p_hat = sigmoid(z)\n        # Numerical stability: clip p_hat to avoid log(0)\n        eps = 1e-12\n        p_hat = np.clip(p_hat, eps, 1 - eps)\n        # Penalize non-intercept coefficients\n        penalty = 0.5 * lam * np.sum(beta[1:] ** 2)\n        return -np.sum(y * np.log(p_hat) + (1 - y) * np.log(1 - p_hat)) + penalty\n\n    # Gradient of the objective\n    def grad(beta):\n        z = X_aug @ beta\n        p_hat = sigmoid(z)\n        # Gradient from likelihood\n        g = X_aug.T @ (p_hat - y)\n        # Add penalty gradient (excluding intercept)\n        g[1:] += lam * beta[1:]\n        return g\n\n    # Initialize beta to zeros\n    beta0 = np.zeros(p + 1, dtype=float)\n    # Optimize using L-BFGS-B\n    res = minimize(nll, beta0, jac=grad, method=\"L-BFGS-B\")\n    return res.x\n\ndef auc_rank(scores, y):\n    \"\"\"\n    Compute AUC using rank-based method that handles ties.\n    Returns np.nan if there are no positives or no negatives.\n    \"\"\"\n    y = np.asarray(y)\n    scores = np.asarray(scores)\n    pos_mask = (y == 1)\n    neg_mask = (y == 0)\n    n_pos = np.sum(pos_mask)\n    n_neg = np.sum(neg_mask)\n    if n_pos == 0 or n_neg == 0:\n        return np.nan\n    ranks = rankdata(scores, method='average')\n    sum_ranks_pos = np.sum(ranks[pos_mask])\n    auc = (sum_ranks_pos - n_pos * (n_pos + 1) / 2.0) / (n_pos * n_neg)\n    return float(auc)\n\ndef bootstrap_optimism_corrected_auc(X, y, lam, B, rng):\n    \"\"\"\n    Compute optimism-corrected AUC via bootstrap resampling.\n    X: (n, p), y: (n,), lam: L2 penalty weight, B: number of bootstraps.\n    rng: numpy Generator for reproducibility.\n    \"\"\"\n    # Apparent fit\n    beta_app = fit_logistic_l2(X, y, lam)\n    p_app = sigmoid(np.hstack([np.ones((X.shape[0], 1)), X]) @ beta_app)\n    auc_app = auc_rank(p_app, y)\n\n    # Bootstrap optimism\n    n = X.shape[0]\n    optimisms = []\n    for b in range(B):\n        idx = rng.integers(0, n, size=n)\n        Xb = X[idx]\n        yb = y[idx]\n        # Fit on bootstrap sample\n        beta_b = fit_logistic_l2(Xb, yb, lam)\n        # AUC on bootstrap sample\n        pb_boot = sigmoid(np.hstack([np.ones((Xb.shape[0], 1)), Xb]) @ beta_b)\n        auc_boot = auc_rank(pb_boot, yb)\n        # AUC on original sample using bootstrap-fitted model\n        pb_orig = sigmoid(np.hstack([np.ones((X.shape[0], 1)), X]) @ beta_b)\n        auc_orig = auc_rank(pb_orig, y)\n        if not (np.isnan(auc_boot) or np.isnan(auc_orig)):\n            optimisms.append(auc_boot - auc_orig)\n    if len(optimisms) == 0 or np.isnan(auc_app):\n        return np.nan\n    mean_optimism = float(np.mean(optimisms))\n    corrected = auc_app - mean_optimism\n    # Bound within [0,1] for numerical sanity (AUC is in [0,1])\n    corrected = min(max(corrected, 0.0), 1.0)\n    return corrected\n\ndef generate_data(seed, n, p, beta_star, beta0_star):\n    \"\"\"\n    Generate synthetic data X, y with standard normal features and logistic Bernoulli responses.\n    \"\"\"\n    rng = np.random.default_rng(seed)\n    X = rng.normal(loc=0.0, scale=1.0, size=(n, p))\n    z = beta0_star + X @ np.asarray(beta_star)\n    prob = sigmoid(z)\n    y = rng.binomial(1, prob, size=n).astype(int)\n    return X, y, rng\n\ndef solve():\n    # Define the test cases from the problem statement.\n    # Each case: (seed, n, p, beta_star, beta0_star, lambda, B)\n    test_cases = [\n        (42, 120, 3, [0.6, -0.4, 0.8], -0.2, 1.0, 200),\n        (314, 100, 2, [2.5, -2.0], 0.0, 2.0, 150),\n        (7, 35, 4, [0.2, 0.1, -0.1, 0.0], -0.1, 0.5, 100),\n        (2021, 200, 5, [0.3, 0.0, -0.2, 0.1, 0.05], -2.0, 1.0, 200),\n    ]\n\n    results = []\n    for seed, n, p, beta_star, beta0_star, lam, B in test_cases:\n        X, y, rng = generate_data(seed, n, p, beta_star, beta0_star)\n        corrected_auc = bootstrap_optimism_corrected_auc(X, y, lam, B, rng)\n        # Round to 6 decimals as required\n        if np.isnan(corrected_auc):\n            results.append(\"nan\")\n        else:\n            results.append(f\"{np.round(corrected_auc, 6):.6f}\")\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        }
    ]
}