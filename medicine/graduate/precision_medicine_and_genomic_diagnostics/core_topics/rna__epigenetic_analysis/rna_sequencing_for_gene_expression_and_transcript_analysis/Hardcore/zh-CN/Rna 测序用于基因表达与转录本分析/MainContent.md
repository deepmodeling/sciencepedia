## 引言
RNA测序（[RNA-seq](@entry_id:140811)）技术已经彻底改变了我们理解生命过程的方式。与相对静态的基因组不同，转录组是细胞在特定时间和条件下基因活动的动态快照，它直接反映了细胞的功能状态、对环境的响应以及[疾病的分子基础](@entry_id:139686)。因此，准确地测量和解读转录组信息对于基础研究和精准医疗都至关重要。然而，从复杂的生物样本中获得可靠的基因表达数据，并将其转化为有意义的生物学洞见，是一个涉及多步骤、充满挑战的过程。本文旨在系统性地梳理这一过程，为读者提供一份从核心原理到前沿应用的全面指南。

在接下来的内容中，我们将分三个章节深入探讨RNA-seq的世界。首先，在“原理与机制”一章中，我们将详细剖析RNA-seq的完整工作流程，从如何根据不同RNA分子的生物学特性选择最优的文库构建策略，到如何通过复杂的[生物信息学算法](@entry_id:262928)处理测序读数，再到如何运用严谨的统计学校正方法获得可比较的基因表达谱。接着，在“应用与交叉学科联系”一章中，我们将展示这些基础原理如何在真实世界的科研和临床场景中发挥作用，例如解析复杂的剪接事件、诊断[遗传病](@entry_id:273195)、发现致[癌基因](@entry_id:138565)融合，以及在单细胞和合成生物学等前沿领域的创新应用。最后，“动手实践”部分将提供一系列精心设计的问题，帮助读者巩固关键概念，将理论知识转化为解决实际问题的能力。通过这一结构化的学习路径，我们希望能为您驾驭RNA-seq这一强大工具奠定坚实的基础。

## 原理与机制

本章旨在深入探讨[RNA测序](@entry_id:178187)（RNA-seq）的核心原理与关键机制。我们将遵循从生物样本到量化数据的完整工作流程，系统性地阐述如何从复杂的细胞转录本中捕获信息，如何处理和解读测序数据，以及如何通过严谨的统计学校正来获得可靠的基因表达谱。本章内容将为后续章节中关于[差异表达分析](@entry_id:266370)、变异检测和临床应用等高级主题奠定坚实的理论基础。

### 从[转录组](@entry_id:274025)到文库：捕获RNA图景

[RNA测序](@entry_id:178187)的起点是细胞内的RNA分子群体，即**转录组（transcriptome）**。与相对稳定的基因组不同，转录组是高度动态的，反映了特定细胞在特定时间点的基因活动状态。它包含了多种多样的RNA分子，每种分子都源于独特的[生物合成途径](@entry_id:176750)，并具有不同的功能。为了准确地测量基因表达，我们必须首先了解这些RNA分子的多样性，并选择合适的实验策略来捕获它们。

#### 转录组的多样性

根据分子生物学的中心法则，基因信息从DNA流向RNA，再到蛋白质。然而，转录组远不止是蛋白质编码的信使。它是一个包含了多种编码和[非编码RNA](@entry_id:268179)的复杂集合。理解它们的生物合成（biogenesis）特征是设计[RNA-seq](@entry_id:140811)实验的关键。

*   **信使RNA（messenger RNA, mRNA）**：由[RNA聚合酶II](@entry_id:147941)转录，是[蛋白质合成](@entry_id:147414)的直接模板。其标志性特征是在细胞核内经历**`$5'$`端加帽（5' capping）**、**剪接（splicing）**（切除内含子）以及**`$3'$`端切割和[多聚腺苷酸化](@entry_id:275325)（cleavage and polyadenylation）**（加上一条poly(A)尾巴）等一系列加工过程。成熟的mRNA被输出到细胞质中进行翻译。其`$3'$`端的[poly(A)尾](@entry_id:274750)巴是富集mRNA最常用的“抓手”。

*   **[长链非编码RNA](@entry_id:180617)（long non-coding RNA, lncRNA）**：长度超过200个核苷酸，但不被翻译成蛋白质。许多lncRNA同样由RNA聚合酶II转录，并经历与mRNA类似的加工过程，包括剪接和加帽。然而，一个关键区别在于，相当一部分lncRNA不具有[poly(A)尾](@entry_id:274750)巴。因此，若要全面分析[lncRNA](@entry_id:194588)，仅依赖于[poly(A)尾](@entry_id:274750)巴的捕获方法会遗漏大量信息。

*   **前体信使RNA（precursor messenger RNA, pre-mRNA）**：这是位于细胞核内的初级转录本，尚未完成剪接，因此同时包含**外显子（exons）**和**内含子（introns）**。分析pre-mRNA可以提供关于[基因转录](@entry_id:155521)和[剪接动力学](@entry_id:755237)的信息。由于它们主要存在于细胞核中且未被完全加工，其测序信号通常表现为大量的[内含子](@entry_id:144362)读数。

*   **[环状RNA](@entry_id:173494)（circular RNA, [circRNA](@entry_id:191128)）**：通过一种称为**[反向剪接](@entry_id:187945)（back-splicing）**的特殊剪接事件形成。在这一过程中，一个剪接供体位点与上游的一个剪接受体位点连接，形成一个共价闭合的环状结构。这种结构使得[circRNA](@entry_id:191128)没有自由的`$5'$`或`$3'$`末端，因此不具有`$5'$`帽子和poly(A)尾巴。这一特性使其对以降解线性RNA为主的**[核糖核酸酶R](@entry_id:195852)（Ribonuclease R, [RNase R](@entry_id:195852)）**具有抗性。

基于这些独特的生物学特征，研究人员可以设计出优先捕获特定RNA类别的测序方案。

#### 文库构建策略：选择与富集

由于细胞总RNA中约80-90%是**[核糖体RNA](@entry_id:149305)（ribosomal RNA, rRNA）**，如果不进行富集，绝大多数测序资源将被浪费在这些信息量较低的分子上。因此，文库构建的核心步骤之一是选择感兴趣的RNA。

*   **多聚[腺苷](@entry_id:186491)酸选择法（Poly(A) Selection）**：该方法利用oligo(dT)（[胸腺](@entry_id:183673)嘧啶脱氧核苷酸寡聚体）与mRNA及其他带[poly(A)尾](@entry_id:274750)巴的RNA（如部分[lncRNA](@entry_id:194588)）的`$3'$`端[poly(A)尾](@entry_id:274750)巴特异性结合，从而将它们从总RNA中分离出来。这是研究成熟mRNA表达谱最常用和经济高效的方法。然而，它的局限性也很明显：它无法捕获不带[poly(A)尾](@entry_id:274750)巴的RNA（如[组蛋白](@entry_id:196283)mRNA、大部分[circRNA](@entry_id:191128)和一部分[lncRNA](@entry_id:194588)），并且对RNA样本的完整性要求较高。对于部分降解的RNA（如来自福尔马林固定石蜡包埋（FFPE）组织的RNA），由于RNA链断裂，可能导致转录本的`$5'$`端信息丢失，从而产生强烈的**`$3'$`端偏好性（3'-end bias）** 。

*   **[核糖体RNA](@entry_id:149305)去除法（rRNA Depletion）**：该方法通过特异性探针与rRNA杂交并将其移除，或使用酶降解rRNA，从而保留细胞中几乎所有其他类型的转录本。这种方法被称为**总[RNA测序](@entry_id:178187)（total RNA-seq）**，它能够提供一个更全面的转录组视图，同时捕获带poly(A)和不带poly(A)的RNA，包括pre-mRNA（表现为[内含子](@entry_id:144362)读数增加）和各种[非编码RNA](@entry_id:268179)。由于它不依赖于[poly(A)尾](@entry_id:274750)巴的完整性，因此对于降解样本（如FFPE）更为稳健。其缺点是成本较高，且可能存在rRNA去除不完全或非特异性去除其他RNA的问题。

*   **靶向富集法（Targeted Enrichment）**：对于特定的临床应用，如检测已知的致病基因或[融合基因](@entry_id:273099)，可以使用**捕获法（capture-based enrichment）**。该方法设计一系列与目标转录本（或其外显子）互补的探针，通过[杂交捕获](@entry_id:262603)目标RNA片段。这种方法的优势在于能够以极高的深度测序感兴趣的基因，从而提高检测灵敏度，并且同样适用于降解样本。其局限性在于只能分析探针设计所覆盖的基因面板，并且覆盖度可能受探针性能和[GC含量](@entry_id:275315)的影响而不均匀。

*   **`$3'$`端标签计数法（3' Tag Counting）**：这类方法（如QuantSeq）也利用[oligo(dT)引物](@entry_id:202920)，但其设计目的是仅捕获每个转录本`$3'$`端附近的一个短片段（“标签”）。通过这种方式，每个原始转录本只产生一个可计数的信号，从而避免了因转录本长度不同而导致的计数偏好（即**基因长度偏好性（gene-length bias）**）。这种方法对于纯粹的基因表达定量非常高效，但由于只测序`$3'$`端，它无法提供关于剪接、同源异构体（isoform）或转录本内部变异的信息。

#### 保留链特异性信息：链特异性RNA-seq

转录本是从DNA双链中的一条链转录而来的。在基因组的密集区域，来自不同链的基因可能相互重叠。为了准确地将读数（read）分配给其来源转录本，并研究反义转录等生物学现象，保留原始RNA分子的链方向信息至关重要。这通过**链特异性（strand-specific）**文库构建方法实现。

两种主流的链特异性建库策略是dUTP法和定向接头法。理解它们如何工作，能帮助我们解读比对结果中的读数方向。在[Illumina](@entry_id:201471)平台的[双端测序](@entry_id:272784)中，读数1（**Read 1, R1**）和读数2（**Read 2, R2**）测序的是同一个DNA片段的两条互补链，因此它们比对到[参考基因组](@entry_id:269221)上时必然位于相反的链上。

*   **dUTP法**：该方法在合成第二条cDNA链时，使用**脱氧尿嘧啶三磷酸（dUTP）**代替常规的**脱氧[胸腺](@entry_id:183673)嘧啶三磷酸（dTTP）**。这样，新合成的第二条链就含有尿嘧啶（U）。在后续的PCR扩增前，使用**[尿嘧啶DNA糖基化酶](@entry_id:187473)（Uracil-DNA Glycosylase, UDG）**处理，该酶能够特异性地切除含有尿嘧啶的DNA链，使其无法被扩增。因此，最终的测序文库绝大部分来源于第一条cDNA链。由于第一条cDNA链是原始RNA的反向互补链，对于一个注释在基因组正链（+）上的基因，其R1读数将比对到负链（-），而R2读数将比对到正链（+）。因此，**R1读数的比对方向与转录本的链方向相反**。

*   **定向接头法（Directional Adapter Method）**：该方法在RNA片段化的两端连接不同的测序接头。例如，在RNA的`$5'$`端连接接头α，`$3'$`端连接接头β。通过精心设计的引物和扩增策略，可以确保R1测序总是从接头α一端开始，从而其序列方向与原始RNA分子的`$5' \rightarrow 3'$`方向一致。对于一个注释在基因组正链（+）上的基因，其R1读数将同样比对到正链（+），而R2读数则比对到负链（-）。因此，**R1读数的比对方向与转录本的链方向相同**。

在分析软件中，这两种链特异性信息通常分别被称为“反向（reverse）”和“正向（forward）”链型，正确设置此参数对于基因表达的准确定量至关重要。

#### 校正扩增偏好：[唯一分子标识符](@entry_id:192673)（UMIs）

在文库构建过程中，PCR扩增是必需的步骤，但它会引入偏好：一些分子可能被过量扩增，而另一些则扩增不足。这导致最终的读数计数并不能准确反映样本中原始分子的数量。为了解决这个问题，**[唯一分子标识符](@entry_id:192673)（Unique Molecular Identifiers, UMIs）**应运而生。

UMI是一段短的（通常为6-12个碱基）随机寡核苷酸序列。其核心原理是在PCR扩增**之前**，为每一个原始的RNA（或其[反转录](@entry_id:141572)的cDNA）分子连接上一个独特的UMI标签。这样一来，源自同一个原始分子的所有PCR扩增产物都将共享相同的UMI序列和相同的基因组比对坐标。在数据分析时，我们可以将具有相同比对起始位置和相同UMI序列的所有读数视为**PCR重复（PCR duplicates）**，并将它们合并为一次计数。这样，我们统计的就不再是测序读数的数量，而是样本中原始分子的数量，从而得到更准确的定量结果。

然而，这个过程也面临挑战。测序过程本身会引入错误，导致一个真实的UMI序列可能在测序后呈现为多个略有不同的序列。例如，一个丰度极高的UMI（如`ACATGCTTGA`，观察到34次）旁边，可能会出现一个或几个仅相差一个碱基且丰度极低的UMI（如`ACATGCTTGG`，观察到2次）。考虑到测序错误率（例如，每碱基$p=0.005$），后者极有可能是前者在测序过程中产生的错误变体，而非一个独立的原始分子。因此，成熟的UMI处理算法通常会将这些序列差异极小（如[汉明距离](@entry_id:157657)为1）且丰度悬殊的UMI群体进行聚类，并将它们归为一个原始分子。

另一个需要考虑的理论问题是**UMI碰撞（UMI collision）**，即两个不同的原始分子偶然被标记上相同的UMI。幸运的是，UMI的[序列空间](@entry_id:153584)非常巨大。例如，一个长度为$L=10$的UMI，其可能的序列种类有$4^{10} \approx 10^6$种。对于一个特定基因座上数量有限的几个分子（如4个），它们获得相同UMI的概率极低（约为$6/4^{10}$），可以忽略不计。因此，经过错误校正后的[UMI去重](@entry_id:756286)，能够为基因表达提供接近“数字级”的精确计数。

### 从测序仪到基因组：处理与比对读数

从测序仪获得的原始数据是一系列包含碱基序列及其质量信息的[FASTQ](@entry_id:201775)文件。为了从中提取生物学意义，必须经过严格的质量控制和精确的基因组比对。

#### 评估读数质量：Phred质量值

测序仪对每个碱基的识别都存在一定的不确定性，这种不确定性通过**Phred质量值（Phred quality score, Q）**来量化。$Q$值是碱基识别[错误概率](@entry_id:267618)$p$的对数转换，其定义为：
$$ Q = -10 \log_{10}(p) $$
反之，[错误概率](@entry_id:267618)$p$可以由$Q$值得出：
$$ p = 10^{-Q/10} $$
例如，$Q=20$表示[错误概率](@entry_id:267618)为$10^{-2}$（1%），即碱基准确率为99%；$Q=30$表示[错误概率](@entry_id:267618)为$10^{-3}$（0.1%），准确率为99.9%。

通常，读数的质量会从`$5'$`端到`$3'$`端逐渐下降。低质量的碱基会引入错误的错配信息，干扰下游的比对和[变异检测](@entry_id:177461)。因此，一个标准的预处理步骤是**质量剪裁（quality trimming）**，即从读数的末端去除质量低于某一阈值（如$Q \lt 20$）的碱基。

这一操作是一个权衡。一方面，它能显著减少数据中的错误碱[基数](@entry_id:754020)量。例如，在一个包含$2 \times 10^9$个碱基的数据集中，去除占总量10%但错误率高达$3.16 \times 10^{-2}$（$Q=15$）的低质量碱基，可以将总预期错误数从约$9.85 \times 10^6$降低到约$3.53 \times 10^6$。这能减少比对时的虚假错配，提高比对的准确率，尤其是在跨越剪接点时，并增加单核苷酸变异（SNV）检测的**精确度（precision）**。另一方面，剪裁会缩短读数长度，甚至可能丢弃整个读数。这会降低对低表达转录本的覆盖度，从而影响检测的**灵敏度（sensitivity）**。此外，如果剪裁导致跨越剪接点的“锚定”序列过短，也可能影响剪接点的发现。

#### 将剪接读数比对至基因组

[RNA-seq](@entry_id:140811)的核心生物信息学挑战是将源自成熟mRNA的短读数准确地比对回[参考基因组](@entry_id:269221)上。由于内含子已被切除，一个跨越两个外显子的读数在基因组上对应的位置是不连续的，中间可能隔着数万甚至数十万个碱基的[内含子](@entry_id:144362)。能够处理这种“分裂比对（split alignment）”的算法被称为**[剪接比对](@entry_id:196404)器（spliced aligner）**。

现代高效的[剪接比对](@entry_id:196404)器（如STAR, HISAT2）大多采用**种子-延伸（seed-and-extend）**策略，并结合了压缩的基因组索引，如**[FM索引](@entry_id:273589)（Ferragina-Manzini index）**。

1.  **种子发现**：算法首先在读数中快速寻找能与基因组完全匹配的短序列，即“种子”。由于[FM索引](@entry_id:273589)能极快地定位精确匹配，这个过程非常高效。为了应对测序错误和剪接点，通常会在一个读数中寻找多个种子。

2.  **种子链合与延伸**：算法接着尝试将来自同一个读数的、在基因组上共线（即位于同一条染色体和同一条链上，且顺序一致）的种子“链接”起来。关键在于，它允许种子之间在基因组上存在巨大的间隙。

3.  **剪接感知评分**：这是[剪接比对](@entry_id:196404)的精髓。当算法尝试填补两个种子之间的间隙时，它需要区分这是一个真正的[内含子](@entry_id:144362)，还是一个大的缺失（deletion）或比对错误。为此，算法会采用一个特殊的**剪接评分模型**：
    *   它对一个大的间隙（潜在的内含子）施加一个与长度基本无关的开放罚分，而不是像处理普通缺失那样按长度累加罚分。
    *   它会检查间隙的边界是否符合已知的**剪接基序（splice motifs）**。在人类中，绝大多数内含子的边界是`GT-AG`（供体-受体）二[核苷](@entry_id:195320)酸。如果一个分裂比对的间隙恰好符合这个基序（或其他次要基序如`GC-AG`），它将获得一个显著的得分奖励。
    *   它还会考虑内含子的长度是否在生物学上合理的范围内（例如，50 bp到500,000 bp）。

4.  **新剪接点的发现**：当一个读数被成功地分裂比对到两个外显子上时，它就为这两个外显子之间的剪接点提供了直接证据。为了可靠地发现**新的剪接点（novel splice junctions）**，算法通常需要满足几个条件：该剪接点必须被多个独立的、高质量的分裂读数所支持；每个支持读数在剪接点两边都必须有足够长的比对“锚定”序列（如8个碱基以上）；并且所有支持读数都应指向同一个链方向和剪接基序。

### 从比对到丰度：定量与归一化

比对完成后，下一步是将这些信息转化为可量化的基因或转录本丰度值，并进行适当的校正，以确保在样本内部和样本之间具有可比性。

#### 基因与转录本的定量

定量的目标是估计每个基因或转录本异构体在原始RNA样本中的相对丰度。

*   **基于比对的计数**：传统方法是简单地计算比对到每个基因的外显子区域的读数（或片段）数量。这对于基因水平的分析是直接且稳健的。然而，当一个读数可以比对到多个基因（如基因家族）或一个基因的多个异构体时，如何分配这些**多重映射（multi-mapping）**读数就成了一个难题。

*   **免比对定量（伪比对）**：为了克服传统比对的计算瓶颈并更好地处理异构体定量问题，**伪比对（pseudoalignment）**方法（如kallisto, Salmon）被开发出来。其核心思想是，我们不需要知道一个读数在转录本上的确切碱基位置，只需要知道它**可能源于哪些转录本**。
    1.  该方法首先为所有已知的转录本序列建立一个基于**[k-mer](@entry_id:166084)**（长度为k的短序列）的索引。这个索引将每个[k-mer](@entry_id:166084)映射到包含它的所有转录本集合。
    2.  对于一个给定的测序读数，算法会查找其包含的所有[k-mer](@entry_id:166084)，并对它们各自对应的转录本集合取**交集**。这个最终的交集就是与该读数**兼容（compatible）**的转录本集合。
    3.  所有产生相同兼容集的读数被归入同一个**[等价类](@entry_id:156032)（equivalence class）**。我们只需统计每个等价类中的读数数量，即**转录本兼容性计数（transcript compatibility counts, TCCs）**。
    4.  在转录本表达丰度的生成混合模型下，这些TCCs构成了估计各异构体表达比例的**充分统计量**。通过**[期望最大化](@entry_id:273892)（Expectation-Maximization, EM）**等算法，可以高效地从TCCs中解析出每个异构体的丰度。

    由于伪比对避免了计算成本高昂的逐碱基动态规划比对，而是代之以快速的[哈希表](@entry_id:266620)查找和[集合运算](@entry_id:143311)，其速度比传统比对快几个数量级。

#### 样本内归一化：校正长度与测序深度

原始的读数计数（raw counts）不能直接用于比较不同基因或不同样本的表达水平，因为它受到两个主要技术因素的干扰：**转录本长度**和**测序深度（library size）**。更长的转录本在相同的表达水平下会产生更多的读数片段；[测序深度](@entry_id:178191)更高的样本也会产生更多的总读数。

*   **RPKM/FPKM**：**每千碱基每百万读数（Reads Per Kilobase per Million mapped reads, RPKM）**或其[双端测序](@entry_id:272784)版本**每千碱基每百万片段（Fragments Per Kilobase per Million mapped fragments, FPKM）**，是最早提出的归一化单位。其计算公式为：
    $$ \text{FPKM}_g = \frac{C_g \cdot 10^9}{N \cdot L_g} $$
    其中，$C_g$是基因$g$的片段计数，$L_g$是其[有效长度](@entry_id:184361)（以bp为单位），$N$是样本的总映射片段数。FPKM试图同时校正[测序深度](@entry_id:178191)（除以$N/10^6$）和基因长度（除以$L_g/1000$）。

*   **TPM**：**[每百万转录本](@entry_id:170576)（Transcripts Per Million, TPM）**是目前更受推荐的表达量单位。其[计算顺序](@entry_id:749112)与FPKM相反：
    1.  首先，用每个基因的读数计数$C_g$除以其长度$L_g$，得到一个与长度无关的比率$q_g = C_g/L_g$。这个值可以被看作是与转录本[摩尔浓度](@entry_id:139283)成正比的量。
    2.  然后，将一个样本中所有基因的$q_g$值相加，得到总和$S = \sum_h q_h$。
    3.  最后，将每个基因的$q_g$作为总和$S$的一部分进行缩放，并乘以一百万：
    $$ \text{TPM}_g = \frac{q_g}{S} \cdot 10^6 = \frac{C_g/L_g}{\sum_h (C_h/L_h)} \cdot 10^6 $$

    **TPM与FPKM的关键区别**在于，根据TPM的定义，一个样本中所有基因的TPM值之和恒为$10^6$。这使得[TPM](@entry_id:170576)成为一个真正的**组学内部比例（compositional）**度量，其值直接反映了某个基因的转录本在总转录本群体中的[相对丰度](@entry_id:754219)。而一个样本中所有基因的FPKM值之和（$\sum_g \text{FPKM}_g$）并不是一个常数，它依赖于该样本中基因长度的加权平均表达丰度。因此，FPKM值在不同样本间的直接比较缺乏坚实的统计学基础，而[TPM](@entry_id:170576)值则具有更好的样本间可比性。

#### 样本间归一化：处理批次效应与混杂因素

尽管TPM提供了更好的样本内相对丰度度量，但对于严谨的[差异表达分析](@entry_id:266370)，我们通常需要对原始计数值进行更复杂的**样本间归一化（between-sample normalization）**。这是因为RNA-seq数据是相对的、组合性的：一个样本中某些基因表达量的急剧增加，会“稀释”其他所有基因的相对比例，即使后者的绝对丰度并未改变。我们需要找到一个稳健的“学校正因子”或**规格化因子（size factor）**来调整每个样本的库大小，以进行公平比较。

在进行样本间归一化时，必须仔细区分两类主要的变异来源：

*   **[批次效应](@entry_id:265859)（Batch Effect）**：这是纯粹的技术性变异，源于样本在不同“批次”中处理。批次可以指不同的测序仪、不同的试剂批号、不同的实验日期或不同的操作人员。[批次效应](@entry_id:265859)会系统性地改变基因的测量值，但它与研究的生物学问题（如疾病状态）是**独立**的。在一个设计良好的实验中，病例和对照样本应均衡地分布在各个批次中。此时，[批次效应](@entry_id:265859)虽然会增加数据噪声、降低[统计功效](@entry_id:197129)，但不会对差异表达的估计产生偏倚。我们可以在[统计模型](@entry_id:755400)中将其作为一个协变量进行校正，或者使用像ComBat这样的工具进行移除。

*   **混杂因素（Confounder）**：混杂因素是一个变量，它既与我们关心的生物学分组（如疾病状态）**相关**，又独立地影响基因表达的测量值。例如，如果病例样本的平均年龄显著高于[对照组](@entry_id:188599)，而年龄本身又影响基因表达，那么年龄就是一个混杂因素。如果不加以校正，年龄对基因表达的影响就会被错误地归因于疾病状态，导致[差异表达分析](@entry_id:266370)结果产生偏倚。一个更微妙的例子是，如果所有病例样本都在一个测序中心处理，而所有对照样本都在另一个中心处理，那么“测序中心”这个技术变量就与“疾病状态”这个生物学变量完全**混淆（confounded）**了。在这种情况下，“测序中心”不再是一个纯粹的[批次效应](@entry_id:265859)，而是一个混杂因素，其影响在统计上无法与疾病的影响分离开来。

基于这些概念，发展出了多种样本间归一化策略，它们基于不同的假设：

*   **TMM和RLE方法**：**M值的修剪均值（Trimmed Mean of M-values, TMM）**（用于edgeR）和**相对对数表达（Relative Log Expression, RLE）**（用于[DESeq2](@entry_id:167268)）是两种最常用的方法。它们都基于一个核心假设：**样本间大部分基因的表达水平是不变的，或者上下调的基因大致对称**。TMM通过计算基因在样本间表达变化的对数倍数（M值），并移除极端值后，来计算一个稳健的加权平均值作为校正因子。RLE则通过计算每个基因相对于所有样本中该基因表达量[几何均值](@entry_id:275527)的偏离，并取这些偏离值的中位数作为校正因子。这两种方法对于处理由少数几个高表达[基因驱动](@entry_id:153412)的**组分偏移（compositional bias）**非常有效。然而，当一个生物学过程导致**大规模、非对称**的基因表达变化时（例如，整体转录水平上调），这两种方法的假设被打破，它们会错误地将这种全局性的生物学变化“归一化”掉。

*   **基于稳定子集的方法**：当全局表达变化存在时，我们需要一个不受生物学状态影响的“锚点”来进行归一化。
    *   **[ERCC外参](@entry_id:749069)（Spike-ins）**：在RNA提取前，向每个样本中加入等量的、已知浓度的合成RNA分子（ERCC spike-ins）。由于其加入量是恒定的，它们在测序结果中的计数变化只反映技术性变异（如提取效率、测序深度）。使用这些外参计算规格化因子，是保留真实全局生物学变化的黄金标准。
    *   **管家基因（Housekeeping Genes）**：如果没有外参，可以使用一组已知在该生物学条件下表达稳定的**管家基因**作为内部参照。这种方法的有效性完全取决于所选基因集的稳定性。

因此，选择合适的归一化策略至关重要。对于存在大规模全局上调的样本（Cohort X），应优先使用[ERCC外参](@entry_id:749069)。对于存在少数基因驱动的组分偏移的样本（Cohort Y），TMM或RLE是理想选择。对于同时存在全局变化和组分偏移的复杂情况（Cohort Z），如果没有外参，使用经过验证的稳定管家基因集是最佳的替代方案。