## 引言
全基因组测序（Whole Genome Sequencing, WGS）是现代生物医学研究的基石，它以前所未有的分辨率揭示了生命的遗传蓝图。从理解罕见病的根源到绘制癌症的突变全景，WGS正驱动着[精准医疗](@entry_id:152668)时代的到来。然而，从DNA样本到可行的临床见解，其过程涉及复杂的多步流程，每个环节都充满了挑战和细微差别。对于研究人员和临床医生而言，仅仅了解WGS能做什么是不够的，更关键的是要深入理解它是如何工作的，以及其结果的可靠性边界在哪里。

本文旨在系统性地剖析[全基因组测序](@entry_id:169777)的方法论与应用。我们将从第一章 **“原理与机制”** 开始，深入探讨从文库制备到数据解读的核心科学原理和计算模型。接着，在第二章 **“应用与跨学科交叉”** 中，我们将通过真实世界的案例，展示WGS如何在临床诊断、肿瘤学、药物基因组学及人类演化研究等多个领域发挥变革性作用。最后，通过一系列 **“动手实践”** 练习，您将有机会亲手应用所学知识，巩固对关键计算概念的理解。本文将为您构建一个从理论基础到前沿应用的完整知识框架，引领您深入探索WGS的强大能力及其在科学发现中的核心地位。

## 原理与机制

本章旨在系统性阐述[全基因组测序](@entry_id:169777)（Whole Genome Sequencing, WGS）从样本处理到数据解读全流程中的核心科学原理与关键技术机制。我们将遵循数据生成的逻辑顺序，逐一剖析文库构建、测序化学、[序列比对](@entry_id:172191)、质量控制及[变异检测](@entry_id:177461)等环节，为读者构建一个坚实而深入的理论框架。

### 数据生成：从DNA到[数字信号](@entry_id:188520)

基因组测序的第一步是将物理的DNA分子转化为可供计算机分析的数字序列信息。这一过程涉及精密的文库制备和复杂的测序化学反应。

#### 文库制备：测序的基础

在测序之前，必须将基因组DNA制备成**测序文库（sequencing library）**。该过程通常包括将DNA随机打断成特定长度的片段，并在片段两端连接上已知的**接头（adapter）**序列。文库构建策略对测[序数](@entry_id:150084)据的质量和最终的分析结果有着深远影响。一个关键的选择在于是否使用**聚合酶链式反应（Polymerase Chain Reaction, PCR）**进行扩增。

**无PCR（PCR-free）文库制备**直接对连接接头后的DNA片段进行测序。这种方法的显著优势在于最大程度地减少了人为引入的偏好。其覆盖度分布更接近理想的**泊松分布**，即基因组上各个位点的覆盖度方差约等于其均值，表现出较高的**覆盖均一性（coverage uniformity）**。由于避免了PCR过程中对不同序列的差异化扩增效率，由鸟嘌呤-胞嘧啶（Guanine-Cytosine, GC）含量极端区域导致的**GC偏好（GC-bias）**被显著削弱。此外，**重复读段（duplicate reads）**——即来源于同一个原始DNA分子的多个测序读段——的比率较低，主要由测序过程中的光学重复或文库复杂度不足时的随机[过采样](@entry_id:270705)导致。文库中因连接错误产生的**[嵌合体](@entry_id:264354)（chimeric reads）**——即一个读段对的两个末端比对到基因组上不相邻的位置——是主要的噪音来源，但其发生率相对较低。

相比之下，**PCR扩增文库制备**在连接接头后，通过数轮PCR循环来增加DNA量。这种方法对起始DNA量的要求较低，但引入了多种偏好和噪音。首先，PCR的“[马太效应](@entry_id:273799)”导致覆盖度分布呈现**过离散（overdispersion）**现象，即方差远大于均值，使得在相同的平均覆盖度下，基因组中出现更多覆盖过低甚至没有覆盖的区域。其次，PCR扩增效率对GC含量敏感，会系统性地低估GC含量极端区域的序列，造成覆盖度的“凹陷”。最后，PCR是**重复读段**的主要来源，并会通过**模板跳跃（template switching）**引入额外的**嵌合体**。这些嵌合体在后续分析中可能被误判为结构变异的信号。尽管**[唯一分子标识符](@entry_id:192673)（Unique Molecular Identifiers, UMI）**技术可以在数据分析层面识别并去除PCR重复，但它们仍然消耗了宝贵的测序通量，降低了**有效唯一覆盖度（effective unique coverage）**。

对于需要精确检测插入缺失（indels）和[结构变异](@entry_id:173359)（Structural Variants, SVs）的临床应用，如肿瘤基因组学，无PCR文库通常是更优选择。其更高的覆盖均一性保证了变异断点区域能被充分测序，而更低的[嵌合体](@entry_id:264354)率则降低了[结构变异检测](@entry_id:171635)的[假阳性](@entry_id:635878)背景，从而提高了检测的灵敏度和特异性。当然，其代价是通常需要更多的起始DNA样本。

#### 可逆末端终止测序法：短读长基因组学的主力

目前，主导短读长测序市场的技术是基于**可逆末端终止子（reversible-terminator）的[合成测序法](@entry_id:185545)（Sequencing by Synthesis, SBS）**。其核心原理是通过模拟DNA的天然复制过程，在每个循环中精确地识别并记录一个碱基。整个过程在一个布满DNA**簇（cluster）**的**流通池（flow cell）**上进行，每个簇包含源自同一个DNA片段的成千上万个拷贝。

一个典型的SBS测序循环包含以下步骤：
1.  **碱基掺入**：向流通池中加入[DNA聚合酶](@entry_id:147287)和四种特殊的脱氧核糖[核苷](@entry_id:195320)三磷酸（dNTPs）。每种dNTP（A, C, G, T）都带有一个独特的、可被激光激发的**[荧光基团](@entry_id:202467)（fluorophore）**，并且其$3'$羟基被一个可化学裂解的**可逆终止基团（reversible blocking group）**所封闭。聚合酶根据模板链的[碱基互补配对](@entry_id:139633)原则，将一个对应的dNTP添加到正在合成的DNA链上。由于$3'$-OH被封闭，链的延伸会立即停止，确保每个循环只添加一个碱基。
2.  **[荧光成像](@entry_id:171928)**：洗去未掺入的dNTPs后，用特定波长的激光激发流通池。每个簇因刚刚掺入的dNTP而发出特定颜色的荧光。高分辨率相机捕捉整个流通池的荧光信号，通过图像分析即可判断每个簇在该循环中掺入的碱基类型。
3.  **化学裂解**：通过化学反应，同时切除附着在刚掺入碱基上的荧光基团和$3'$端的终止基团。这一步至关重要，因为它使$3'$羟基得以再生，为下一轮的碱基掺入做好了准备。
4.  **清洗与重复**：洗去裂解反应的化学试剂后，即可开始下一个测序循环。

然而，这一精巧的化学过程并非完美无瑕。随着测序循环的增加，簇内数以万计的DNA分子会逐渐失同步，主要表现为两种错误模式：
-   **移相（Phasing）**：指在某个循环中，一小部分分子的碱基掺入失败，导致它们比簇中的主体分子**落后（lagging）**了一个碱基。其[单循环](@entry_id:176547)发生概率定义为$\alpha$。
-   **超前（Pre-phasing）**：指一小部分分子因$3'$终止基团过早脱落或掺入了未被有效终止的dNTP，导致在单个循环中掺入了超过一个碱基，从而**领先（leading）**于主体分子。其[单循环](@entry_id:176547)发生概率定义为$\beta$。

这两种错误是累积性的。经过$t$个循环后，簇内仍然保持[完全同步](@entry_id:267706)的分子（即“同相”分子）的比例，在$\alpha$和$\beta$为[互斥事件](@entry_id:265118)的假设下，可表示为$f_{\text{in}}(t) = (1 - \alpha - \beta)^t$。在第$t$个循环中，成像系统接收到的荧光信号是一个混合体：主体信号来自同相分子（发出对应碱基$b_t$的荧光），同时夹杂着来自落后分子（发出$b_{t-1}$的荧光）和领先分子（发出$b_{t+1}$的荧光）的串扰信号。随着$t$的增加，$f_{\text{in}}(t)$呈指数下降，串扰信号逐渐增强，[信噪比](@entry_id:271196)恶化，最终限制了SBS技术的有效读长，并表现为读段末端碱基质量值的系统性下降。

#### [纳米孔测序](@entry_id:136932)：一种长读长新范式

与SBS技术不同，**[纳米孔测序](@entry_id:136932)（nanopore sequencing）**代表了第三代测序技术，它直接对单个DNA分子进行测序，能够产生数千甚至数百万个碱基的超长读段。其核心是一个嵌入在绝缘膜中的**蛋白质[纳米孔](@entry_id:191311)**。

其物理原理如下：
1.  **离子电流**：在纳米孔两侧施加电压，驱动电解质[溶液中的离子](@entry_id:143907)（如$K^+$和$Cl^-$）穿过孔道，形成一个稳定的**基线[离子电流](@entry_id:170309)（open-pore current）**。
2.  **电流调制**：在马达蛋白的引导下，一条[单链DNA](@entry_id:162691)分子以一定的速率穿过[纳米孔](@entry_id:191311)。当DNA碱基位于孔道最狭窄的**感应区（sensing region）**时，它会占据部分空间并与孔壁相互作用，从而排斥一部分离子，短暂地阻碍电流通过。
3.  **信号解读**：不同的DNA碱基（或连续的$k$-mers）因其大小、形状和化学性质的差异，对[离子电流](@entry_id:170309)的阻碍程度也不同，产生特征性的**电流信号**。通过高频采样并解读这些电流信号的波动，就可以推断出穿过[纳米孔](@entry_id:191311)的DNA序列。

基于这一原理，我们可以建立一个简化的电阻模型来理解。将[纳米孔](@entry_id:191311)视为一个电阻器，其电阻$R = \frac{L}{\sigma A}$，其中$L$为长度，$\sigma$为电导率，$A$为[截面](@entry_id:143872)积。当一个碱基占据感应区时，它等效于将孔道分为两段串联的电阻。被占据的一小段长度为$\ell$，其有效[截面](@entry_id:143872)积因[空间排斥](@entry_id:169266)而减小（例如，减少$\phi$倍），有效电导率因局部介电环境和离子[水化层](@entry_id:269646)变化而改变（例如，变为$\beta$倍）。因此，总电阻增加，总电流$I = V/R$下降，形成**电流阻断（current blockade）**。

[纳米孔测序](@entry_id:136932)的一个革命性优势是能够**直接检测碱基修饰**。例如，**[5-甲基胞嘧啶](@entry_id:193056)（5-methylcytosine, 5mC）**是哺乳动物基因组中最重要的[表观遗传](@entry_id:143805)修饰之一。与普通胞嘧啶（C）相比，5mC多了一个[电中性](@entry_id:157680)的甲基基团。这个额外的基团增大了分子的体积（增大了[空间排斥](@entry_id:169266)效应$\phi$），并增强了局部的疏水性，改变了局部介[电常数](@entry_id:272823)和离子分布（降低了有效电导率$\beta$）。根据电阻模型，这两个效应都会导致被占据区域的电阻变得更大，从而产生一个比胞嘧啶更深、更持久的电[流阻](@entry_id:262242)断信号。通过训练特定的[机器学习模型](@entry_id:262335)来识别这些特征性的电流信号差异，[纳米孔测序](@entry_id:136932)无需进行亚硫酸氢盐转化等化学处理，就能在测序的同时直接读出DNA链上的甲基化状态。

### 数据处理：从原始读段到比对信息

获得原始测序读段后，下一个核心任务是确定它们在基因组中的来源位置。这一过程称为**比对（alignment）**或**映射（mapping）**。

#### 基因组坐标系：参考基因组的选择

比对的前提是拥有一个**参考基因组（reference genome）**作为“地图”。人类参考基因组并非来自单一个体，而是一个**单倍体-镶嵌体（haploid-mosaic）**表示，即在每个位置上只呈现一个碱基，但整个序列是多个个体来源的拼接。

**GRCh38（Genome Reference Consortium Human build 38）**是当前广泛使用的人类参考基因组版本。它包含：
-   **主染色体装配（primary assembly）**：构成标准坐标系的染色体序列（1-22, X, Y, M）。
-   **替代基因座[重叠群](@entry_id:177271)（ALT contigs）**：为那些在人群中高度多态或结构复杂的区域（如人类白细胞抗原HLA区域）提供的额外单倍型序列。它们独立于主染色体，旨在减少**参考偏好（reference bias）**。
-   **诱饵序列（decoy sequences）**：一组非染色体序列，用于吸附那些源自基因组中未解析区域、重复序列或常见病毒（如EBV）的读段，防止它们错误地比对到主染色体上，从而降低[假阳性](@entry_id:635878)变异。

[参考基因组](@entry_id:269221)的选择直接影响比对结果。以一个高度多态的[HLA基因](@entry_id:175412)为例，假设一个样本的真实单倍型与GRCh38主序列差异较大（例如，发散度$d_L = 0.02$），而基因组中存在一个与其更相似的[旁系同源基因](@entry_id:263736)（与主参考序列发散度$d_P = 0.01$）。在只使用主参考序列进行比对时，源自该[HLA基因](@entry_id:175412)的短读段（如$150$ bp）在比对到其真实来源时会产生更多的错配（错配数约$(d_L + e)r$，其中$e$为测序错误率，$r$为读长），而在比对到[旁系同源基因](@entry_id:263736)时错配数更少（约$(d_P+e)r$）。因此，比对软件会倾向于将这些读[段错误](@entry_id:754628)地定位到旁系同源基因上，导致真实HLA区域的覆盖度降低，甚至无法检出变异。这就是典型的参考偏好。当引入ALT contigs后，如果其中包含一个与样本单倍型非常相似的序列（例如，发散度$d_L^{\text{ALT}} = 0.005$），那么[读段比对](@entry_id:265329)到该ALT contig上的错配数将是最低的，从而纠正了比对错误，恢复了正确的基因分型。

**T2T-CHM13**是新一代的**[端粒](@entry_id:138077)到[端粒](@entry_id:138077)（Telomere-to-Telomere）**完整人类基因组。它首次实现了对所有人类染色体的无间隙组装，填补了包括着丝粒在内的所有复杂区域。然而，T2T-CHM13本质上仍是一个单一个体的、近乎纯合的单倍体序列。尽管其完整性极大地改善了对[结构变异](@entry_id:173359)和重复序列的分析，但它本身并不能解决多态性位点的参考偏好问题。对于一个与CHM13单倍型差异较大的样本，参考偏好依然存在，这凸显了未来向**[泛基因组](@entry_id:149997)（pangenome）**或**[图基因组](@entry_id:190943)（graph genome）**参考过渡的必要性。

#### 比对过程：将读段映射至参考

将数亿条读段与长达30亿碱基的[参考基因组](@entry_id:269221)进行比对，是一个巨大的计算挑战。现代比对算法普遍采用**“种子-延伸”（seed-and-extend）**策略。
1.  **播种（Seeding）**：首先在读段中快速识别出一个或多个短的、与参考基因组完全匹配的子序列，称为**种子（seeds）**。这一步需要极高的效率。基于**[Burrows-Wheeler变换](@entry_id:269666)（BWT）**和**FM-index**的索引技术为此提供了完美的解决方案。BWT是一种对字符串的可逆重排，它能将相似的上下文聚集在一起。FM-index在此基础上增加了辅助数据结构，使得查找一个长度为$m$的模式（种子）在参考基因组中的所有出现位置的时间复杂度仅为$O(m)$，而与[参考基因组](@entry_id:269221)的巨大长度$n$无关。
2.  **延伸（Extension）**：找到种子锚点后，算法会从种子位置向两侧延伸，对读段和参考序列之间的区域进行更精细的动态规划比对（如[Smith-Waterman算法](@entry_id:179006)），允许错配和缺口（插入/缺失）的存在，以找到一个得分最高的[局部比对](@entry_id:164979)。比对的打分系统通常使用**仿射缺口罚分（affine-gap penalty）**，即对一个缺口的罚分由一个较高的**缺口开放罚分（gap open penalty）**和一个较低的**缺口延伸罚分（gap extension penalty）**组成。

不同的比对软件在这一框架下有各自的优化。**BWA-MEM**是经典的短读长比对工具，它利用FM-index高效地查找**超大最大精确匹配（supermaximal exact matches）**作为种子，并通过带状动态规划进行延伸。**minimap2**则是长读长比对领域的标杆，它采用**最小化器（minimizer）**的稀疏播种策略，并通过高效的**链式比对（chaining）**算法连接跨度很远的种子。为了更好地处理长读段中常见的大型[插入缺失](@entry_id:173062)，minimap2使用了一种**凹形长缺口罚分（concave long-gap cost）**模型，使得对一个几千碱基长的单个大缺口的罚分，要比将其断裂成两个独立比对的罚分更优。这种设计使得minimap2能够生成跨越大型结构变异的连续比对，而BWA-MEM等传统短读长比对器在面对这种大缺口时，往往会因为超出其延伸算法的搜索范围而选择将读段**软剪切（soft-clip）**或报告为两个**补充比对（supplementary alignment）**。

#### 评估[比对质量](@entry_id:170584)：覆盖度及其意义

比对完成后，需要评估测序数据的质量。**覆盖度（Coverage）**是其中最重要的指标，它包含多个层面的含义：
-   **覆盖深度（Coverage Depth）**：指基因组中某个特定碱基位置被测序读段覆盖的次数。例如，“$30\times$覆盖”意味着平均每个碱基被$30$个读段覆盖。
-   **覆盖广度（Coverage Breadth）**：指基因组中被至少一定数量读段覆盖的区域所占的百分比。例如，“$95\%$的碱基达到$\ge 20\times$覆盖”。
-   **覆盖均一性（Coverage Uniformity）**：衡量覆盖深度在整个基因组中分布的均匀程度。

这三个指标共同决定了[变异检测](@entry_id:177461)的**临床灵敏度**。仅仅知道**平均深度**是不够的。考虑两个平均深度同为$30\times$的测序结果：运行X中$95\%$的碱基达到$\ge 20\times$覆盖，而运行Y中只有$80\%$的碱基达到该水平。这意味着运行Y的覆盖均一性更差，有更多区域处于较低深度。对于检测一个杂合单核苷酸变异（SNV），假设检出需要至少4个支持变异的读段，那么在$10\times$深度下检出的概率远低于在$20\times$或$30\times$深度下。因此，尽管平均深度相同，运行X的整体SNV检出能力将显著高于运行Y。

对于基于[读段深度](@entry_id:178601)变化来检测的**[拷贝数变异](@entry_id:176528)（Copy Number Variants, CNVs）**，均一性则更为关键。CNV检测算法通常通过计算大基因组窗口（如数千碱基）内的平均深度来推断拷贝数。如果数据本身在窗口间的深度波动很大（即均一性差，归一化后变异系数高），这种噪音就会掩盖真实的拷贝数变化信号，从而降低CNV的检测灵敏度。因此，一个局部碱基覆盖度指标很好的测序，如果存在大范围的系统性偏好（如GC偏好），仍可能不适合进行CNV分析。

### 数据解读：变异的发现与注释

比对完成的数据是解读基因组信息的起点。接下来的任务是从中识别出样本相对于参考基因组的差异，即**变异（variants）**。

#### 变异检出的统计基础

在比对文件中，一个位点上可能同时存在与参考序列相同和不同的碱基。判断这是否构成一个真实的变异，而不是测序或比对错误，依赖于一个严谨的[统计模型](@entry_id:755400)。这个模型的核心是两个**Phred[质量分数](@entry_id:161575)**：
-   **碱基[质量分数](@entry_id:161575)（Base Quality, $Q_b$）**：由测序仪根据荧光信号强度等信息给出，衡量的是单个碱基被错误识别的概率。其定义为$Q_b = -10\log_{10}(p_b)$，其中$p_b$是碱基识别错误的概率。例如，$Q_b=30$意味着错误率为$1/1000$。
-   **[比对质量](@entry_id:170584)分数（Mapping Quality, $Q_m$）**：由比对软件给出，衡量的是整个读段被错误地放置在当前位置的概率。其定义为$Q_m = -10\log_{10}(p_m)$，其中$p_m$是比对错误的概率。高$Q_m$值（如$\ge 20$）表示该读段的比对位置是可信的。

这两个[质量分数](@entry_id:161575)在计算一个位点上特定**基因型（genotype）**（如AA, AG, GG）的**似然性（likelihood）**——$P(\text{数据}|\text{基因型})$——时，扮演着不同但互补的角色。对于单个读段的贡献，其似然性是一个**[混合模型](@entry_id:266571)**：
$P(\text{观测碱基}|\text{基因型}) = (1-p_m) \times P(\text{观测碱基}|\text{基因型, 正确比对}) + p_m \times \frac{1}{4}$
这个公式的含义是：该读段的贡献是两种情况的加权平均。第一种情况是读段被正确比对（概率为$1-p_m$），此时观测到的碱基是真是假由碱基质量$p_b$决定。第二种情况是读段被错误比对（概率为$p_m$），此时它提供的碱基信息是随机噪音，对于任何基因型来说概率都是$1/4$。通过整合所有覆盖该位点的读段的似然性，[变异检测](@entry_id:177461)工具（variant caller）可以计算出不同基因型的后验概率，并做出最终的判断。

#### 识别小变异：SNVs与[Indel](@entry_id:173062)s

**单核苷酸变异（Single Nucleotide Variant, SNV）**是基因组中最常见的变异类型，指单个碱基的替换。**小插入和缺失（small insertions and deletions, indels）**则是指长度通常小于50 bp的序列增减。这些变异的标准报告格式是**VCF（Variant Call Format）**。

在[VCF格式](@entry_id:756453)中，indels的表示有一个至关重要的**标准化（normalization）**规则：对于一个在重复序列区域内的indel，必须将其**左对齐（left-aligned）**并以最**简约（parsimonious）**的方式表示。例如，在一个`ATTTTC`的参考序列中，T的同聚物区域（`TTTT`）内发生了一个T的插入。这个插入可以表示在`TTTT`中的任何位置，但标准化的表示要求将其移动到最左边的可能位置。其VCF记录将以T同聚物前的`A`作为锚点，`POS`为`A`的位置，`REF`为`A`，`ALT`为`AT`。同样，如果是一个T的删除，标准表示也是以`A`为锚点，`REF`为`AT`，`ALT`为`A`。这个规则确保了同一个变异在不同分析流程中能有一致的表示，是变异注释和比较的基石。

在肿瘤基因组分析中，一个核心任务是区分**胚系变异（germline variants）**和**体细胞变异（somatic variants）**。这通常通过比对成对的肿瘤和癌旁正常组织样本来实现。**变异[等位基因频率](@entry_id:146872)（Variant Allele Fraction, VAF）**——即支持变异的读段数占总读段数的比例——是关键指标。
-   一个杂合的胚系变异，在正常组织样本中的VAF期望为$0.5$，在肿瘤组织中也接近$0.5$（除非发生[杂合性丢失](@entry_id:184588)）。
-   一个克隆性的、二倍体区域的杂合体细胞变异，在正常组织样本中应不存在（VAF $\approx 0$），而在肿瘤样本中的期望VAF约为$\pi \times 0.5$，其中$\pi$是**肿瘤纯度（tumor purity）**。例如，一个纯度为$40\%$的肿瘤样本，其克隆杂合体细胞变异的VAF期望为$0.4 \times 0.5 = 0.2$。利用这一关系，可以从测序数据中准确地区分两类变异。

#### 检测大尺度基因组变化：[结构变异](@entry_id:173359)

**[结构变异](@entry_id:173359)（Structural Variants, SVs）**是指基因组中较大片段（通常定义为$\ge 50$ bp）的改变。主要类型包括**缺失（deletions）**、**重复（duplications）**、**倒位（inversions）**和**易位（translocations）**。在短读长测[序数](@entry_id:150084)据中，检测SVs依赖于多种证据的综合分析：
-   **[读段深度](@entry_id:178601)信号（Read-depth evidence）**：拷贝数的增减会直接导致覆盖深度的变化。大片段的缺失会导致覆盖深度下降，而重复则会导致其上升。这种信号适用于检测较大规模的非平衡性SVs，但其断点分辨率较低。
-   **异常读段对（Discordant read pairs）**：配对末端测序（paired-end sequencing）的DNA片段长度（即**插入片段大小，insert size**）遵循一个已知的分布。当一个读段对跨越一个SV断点时，其比对后的行为会变得“异常”。例如，跨越一个缺失的读段对，其两端比对到[参考基因组](@entry_id:269221)上的距离会大于预期的插入片段大小；跨越一个倒位断点的读段对，其两端的比对方向会异常（如从正常的FR方向变为FF或RR方向）；而跨越一个染色体间易位的读段对，其两端会比对到不同的染色体上。
-   **裂读（Split reads）**：当一条测序读段恰好跨越一个SV的断点时，它的一部分会比对到断点的一侧，而另一部分则比对到断点另一侧的序列上。这种“裂开”的读段能够提供SV断点的**单碱基分辨率**位置信息。

例如，对于一个$300$ bp的杂合缺失，在一个$35\times$覆盖的测[序数](@entry_id:150084)据中，我们可以预期同时观察到三种信号：缺失区域内的覆盖深度下降约$50\%$；大量跨越该区域的读段对表现出比正常值大约$300$ bp的插入片段大小；在缺失的两个断点处，会出现多个裂读信号，精确地标示出缺失的边界。对这些信号的综合建模与分析是当前从短读长数据中准确检出SVs的核心策略。

### [从头组装](@entry_id:172264)：无参考下的基因组构建

在没有高质量参考基因组（例如，测序一个新物种）或参考基因组不适用（例如，肿瘤中发生复杂重排）的情况下，需要进行**[从头组装](@entry_id:172264)（de novo assembly）**，即直接从测序读段拼接出基因组序列。

两种经典的组装框架是**“重叠-布局-一致性”（Overlap-Layout-Consensus, OLC）**和**[德布鲁因图](@entry_id:263552)（de Bruijn Graph, DBG）**。OLC以读段为[基本单位](@entry_id:148878)，计算它们之间的重叠关系来构建图，主要用于错误率较高但读段很长的测序数据。DBG则是短读长数据组装的主流方法。在DBG中，所有读段首先被打碎成长度为$k$的子串，称为**[k-mer](@entry_id:166084)s**。然后构建一个图，其中节点代表长度为$k-1$的子串，而边则代表连接了其前缀和后缀节点的[k-mer](@entry_id:166084)。基因组序列对应于图中的一条或多条路径（理想情况下是一条**[欧拉路径](@entry_id:260928)**）。

在DBG组装中，**$k$值的选择至关重要**，它是一个在重复解析、错误容忍和[图连通性](@entry_id:266834)之间的权衡：
1.  **重复解析**：为了能够唯一地解析一段重复序列，k-mer的长度$k$必须大于该重复序列的长度。如果$k$小于等于重复序列长度，所有来自该重复区的[k-mer](@entry_id:166084)s都会变得相同，导致图在该处形成一个无法唯一遍历的“结”或“环”，使组装中断或产生歧义。
2.  **错误容忍与[信噪比](@entry_id:271196)**：测序错误会产生大量的伪[k-mer](@entry_id:166084)s，它们通常丰度很低（只出现一两次）。而来自基因组真实序列的[k-mer](@entry_id:166084)s，其期望丰度约等于测序覆盖度$C$。为了有效区分信号和噪音，真实k-mers的丰度必须足够高。然而，一个[k-mer](@entry_id:166084)是无错误的概率为$(1-e)^k$，其中$e$是单碱基错误率。$k$值越大，这个概率越低，意味着越多的真实k-mers会因包含错误而被当作噪音丢弃，从而削弱了图的连通性。
3.  **图的连通性**：为了得到连续的组装结果，[德布鲁因图](@entry_id:263552)必须保持连通。如果$k$值过大，一方面会导致大量[k-mer](@entry_id:166084)s因错误而丢失，另一方面，每条读段能产生的[k-mer](@entry_id:166084)s数量（$L-k+1$）也会减少。这两者都会增加图中出现“断点”的风险，导致组装结果变得破碎。

因此，选择$k$值是一个优化问题。例如，对于读长$L=150$ bp、错误率$e=0.005$、覆盖度$C=40$的数据，且已知基因组中常见重复序列长度在$45$ bp左右，一个合理的$k$值应略大于$45$（如$k \approx 55$）。这个选择既能跨越大部分常见重复，又能在可接受的错误率下保持足够高的k-mer覆盖度，从而在重复解析和[图连通性](@entry_id:266834)之间取得良好平衡。选择过小的$k$（如$21$）将无法解决重复问题，而选择过大的$k$（如$149$）则会导致图因错误累积而彻底破碎。