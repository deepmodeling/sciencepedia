{
    "hands_on_practices": [
        {
            "introduction": "在分析基因组之前，我们必须首先理解测序数据是如何“覆盖”它的。这个练习将引导你从第一性原理出发，构建基础的统计模型。通过此练习 ，你将学会推导预期的测序覆盖度，并预测基因组中可能被遗漏的部分的比例，这对于规划任何测序项目都至关重要。",
            "id": "4397193",
            "problem": "在一次用于精准肿瘤学的随机鸟枪法全基因组测序实验中，一个大小为 $G$ 碱基对的单倍体人类基因组通过生成 $N$ 个长度均为 $L$ 碱基对的单端读段进行测序。假设读段沿着基因组均匀且独立地随机分布，其起始位置在所有可能的位置上是等可能的。假设 $G \\gg L$，因此边界效应可以忽略不计，并且不存在比对偏好。某个基因组位置的覆盖深度定义为与该位置重叠的读段数量。\n\n仅从以下基本原理出发：\n- 中心法则阐明，测序报告了基因组位置上的核苷酸内容，而覆盖深度则是在一个碱基上进行独立观测的次数。\n- 在均匀独立放置的假设下，给定读段覆盖某一特定碱基的概率等于能导致重叠的起始位置所占的比例，并且覆盖某一碱基的读段数量是一系列独立 Bernoulli 试验的总和。\n- 对于大量试验中的稀有事件，参数为 $(n, p)$ 的二项分布可以由均值为 $\\lambda = n p$ 的泊松分布近似。\n\n任务：\n1. 推导任意碱基上的期望覆盖深度，用 $G$、$N$ 和 $L$ 表示。\n2. 使用一个由上述假设所支持的适当极限论证，推导给定碱基未被覆盖（覆盖深度为零）的概率，用期望覆盖深度表示。\n3. 对于大小为 $G = 3.0 \\times 10^{9}$ 碱基对的基因组，使用 $N = 8.0 \\times 10^{7}$ 个长度为 $L = 150$ 碱基对的读段，计算给定碱基未被覆盖的概率。将最终概率四舍五入到四位有效数字，并以不带单位的小数形式表示。",
            "solution": "该问题要求推导随机鸟枪法测序实验中的关键指标，并进行后续的数值计算。此问题被验证为是自洽的、有科学依据且提法得当的。我们将按顺序完成这三个任务。\n\n### 任务1：推导期望覆盖深度\n\n设 $G$ 为单倍体基因组的大小（单位：碱基对），$N$ 为读段总数，$L$ 为每个读段的长度（单位：碱基对）。读段是均匀且独立地随机放置的。我们需要求出任意一个碱基的期望覆盖深度。我们用 $\\lambda$ 表示期望覆盖深度。\n\n考虑基因组内位置 $k$ 上的一个任意碱基。现在，考虑一个长度为 $L$ 的单次读段。该读段的起始位置是从所有可能的起始位置中均匀随机选择的。假设在一个离散模型中，读段从特定的碱基位置开始，那么存在 $G$ 个可能的起始位置，索引从 1 到 $G$。问题陈述中提到边界效应可以忽略不计，这等同于假设基因组是环状的，或者 $G \\gg L$ 允许我们忽略线性基因组末端附近碱基的边缘情况。\n\n一个从位置 $s$ 开始的长度为 $L$ 的读段将覆盖区间 $[s, s+L-1]$ 内的所有碱基。为了使我们位于位置 $k$ 的特定碱基被这个读段覆盖，其位置 $k$ 必须落在这个区间内，即 $s \\le k \\le s+L-1$。这个不等式可以重排以定义“成功的”起始位置 $s$ 的范围：$k-L+1 \\le s \\le k$。\n\n满足此条件的整数起始位置 $s$ 的数量为 $(k) - (k-L+1) + 1 = L$。由于读段总共有 $G$ 个可能的起始位置，且每个位置都是等可能的，因此单个随机放置的读段覆盖位置 $k$ 处特定碱基的概率 $p$ 是有利结果数与总结果数的比值：\n$$p = \\frac{L}{G}$$\n鉴于没有边界效应的假设，这个概率对于任何碱基 $k$ 都是相同的。\n\n现在，我们考虑所有 $N$ 个读段。每个读段的放置都是一个独立事件。位置 $k$ 的总覆盖深度，我们称之为 $C_k$，是覆盖该位置的读段总数。我们可以定义 $N$ 个独立的 Bernoulli 随机变量 $X_i$（其中 $i=1, \\dots, N$），如果读段 $i$ 覆盖碱基 $k$，则 $X_i=1$，否则 $X_i=0$。每次试验的成功概率是 $P(X_i=1) = p = L/G$。\n\n总覆盖深度是这些变量的和：$C_k = \\sum_{i=1}^{N} X_i$。根据期望的线性性质，期望覆盖深度 $\\lambda$ 为：\n$$\\lambda = E[C_k] = E\\left[\\sum_{i=1}^{N} X_i\\right] = \\sum_{i=1}^{N} E[X_i]$$\n单个 Bernoulli 变量 $X_i$ 的期望是其成功概率，即 $E[X_i] = p = L/G$。因此，\n$$\\lambda = \\sum_{i=1}^{N} p = Np = \\frac{NL}{G}$$\n这就是任意碱基上的期望覆盖深度。\n\n### 任务2：推导未覆盖碱基的概率\n\n给定碱基的覆盖深度 $C_k$ 是 $N$ 次独立同分布的 Bernoulli 试验的总和，每次试验的成功概率为 $p=L/G$。因此，随机变量 $C_k$ 服从二项分布：$C_k \\sim \\text{Binomial}(N, p)$。观察到覆盖深度恰好为 $k$ 的概率是 $P(C_k=k) = \\binom{N}{k} p^k (1-p)^{N-k}$。\n\n问题陈述指导我们使用一个极限论证。在典型的全基因组测序实验中，读段数量 $N$ 非常大（在百万到十亿的量级），而单个读段覆盖特定碱基的概率 $p=L/G$ 非常小（因为 $G$ 相对于 $L$ 非常大）。这种情景——大量试验伴随小成功概率——是二项分布可以被泊松分布精确近似的经典条件。\n\n近似的泊松分布的参数是其均值 $\\lambda$，该均值必须等于它所近似的二项分布的均值。如任务1中所推导，这个均值是 $\\lambda = Np = NL/G$。\n\n令 $K$ 为表示特定碱基覆盖深度的随机变量，服从均值为 $\\lambda$ 的泊松分布。泊松分布的概率质量函数是：\n$$P(K=k) = \\frac{\\lambda^k \\exp(-\\lambda)}{k!}$$\n其中 $k$ 是事件发生的次数（即覆盖深度）。\n\n我们要求的是给定碱基未被覆盖的概率。这对应于覆盖深度为零的情况，即 $k=0$。将 $k=0$ 代入泊松概率质量函数，得到：\n$$P(K=0) = \\frac{\\lambda^0 \\exp(-\\lambda)}{0!}$$\n利用对任何 $\\lambda$ 都有 $\\lambda^0=1$ 以及 $0!=1$ 这两个事实，我们得到：\n$$P(K=0) = \\exp(-\\lambda)$$\n这就是给定碱基未被覆盖的概率，用期望覆盖深度 $\\lambda$ 来表示。\n\n### 任务3：数值计算\n\n给定一个人类基因组测序实验的以下数值：\n- 基因组大小 $G = 3.0 \\times 10^{9}$ 碱基对。\n- 读段数量 $N = 8.0 \\times 10^{7}$ 个读段。\n- 读段长度 $L = 150$ 碱基对。\n\n首先，我们使用任务1中推导的公式计算期望覆盖深度 $\\lambda$：\n$$\\lambda = \\frac{NL}{G} = \\frac{(8.0 \\times 10^{7}) \\times 150}{3.0 \\times 10^{9}}$$\n$$\\lambda = \\frac{1200 \\times 10^{7}}{3.0 \\times 10^{9}} = \\frac{1.2 \\times 10^{10}}{3.0 \\times 10^{9}} = \\frac{12.0}{3.0} = 4.0$$\n期望覆盖深度是 $\\lambda=4.0$。\n\n接下来，我们使用任务2中的公式来计算给定碱基未被覆盖的概率 $P(K=0)$：\n$$P(K=0) = \\exp(-\\lambda) = \\exp(-4.0)$$\n现在我们计算其数值：\n$$P(K=0) \\approx 0.0183156388...$$\n问题要求将此概率四舍五入到四位有效数字。前四位有效数字是 $1$、$8$、$3$ 和 $1$。第五位有效数字是 $5$，因此我们将第四位有效数字向上舍入。\n$$P(K=0) \\approx 0.01832$$\n这就是最终的数值答案。",
            "answer": "$$\\boxed{0.01832}$$"
        },
        {
            "introduction": "在获得测序数据后，下一步是在特定位点上对其进行解释。这项练习  深入探讨了遗传变异检测的核心逻辑。通过应用贝叶斯定理，你将学习如何整合关于等位基因频率的先验知识、观测到的读数数据以及测序错误率，从而计算出最可能的基因型，实现从原始数据到可靠生物学结论的跨越。",
            "id": "4397190",
            "problem": "一个二倍体人类基因组中的双等位基因单核苷酸位点通过全基因组测序（WGS）进行测序。你观察到总共有 $n = 40$ 条独立的、高质量的读数（reads）覆盖了该位点，其中 $k = 18$ 条报告了备选等位基因，$n - k = 22$ 条报告了参考等位基因。假设每碱基的对称测序错误率为 $\\epsilon = 10^{-3}$，即来自真实参考等位基因的读数被误读为备选等位基因的概率为 $\\epsilon$，而来自真实备选等位基因的读数被误读为参考等位基因的概率也为 $\\epsilon$。假设从两条染色体中对等位基因的抽样是无偏的，并且各读数之间相互独立。\n\n给定在相关的祖源匹配种群中，备选等位基因的种群等位基因频率为 $f = 0.01$。在哈迪-温伯格平衡（Hardy–Weinberg equilibrium）的条件下，使用此 $f$ 值为三种二倍体基因型 $G \\in \\{ \\text{纯合参考型}, \\text{杂合型}, \\text{纯合备选型} \\}$ 设置基因型先验概率。使用贝叶斯法则（Bayes' rule），并结合一个基于上述错误过程的二项抽样模型，计算在给定数据 $(n, k)$ 的情况下每种基因型的后验概率，并确定哪种基因型最可能。\n\n只需报告最可能基因型的后验概率，以小数形式表示并四舍五入到 $4$ 位有效数字。无需单位。",
            "solution": "用户希望使用贝叶斯推断解决一个基因组诊断学问题。\n\n### 步骤1：提取已知条件\n- 读数总数：$n = 40$。\n- 报告备选等位基因的读数数量：$k = 18$。\n- 报告参考等位基因的读数数量：$n - k = 22$。\n- 对称测序错误率：$\\epsilon = 10^{-3}$。\n- 备选等位基因的种群等位基因频率：$f = 0.01$。\n- 基因型：$G \\in \\{ \\text{纯合参考型}, \\text{杂合型}, \\text{纯合备选型} \\}$。我们分别将其表示为 $G_0$、$G_1$ 和 $G_2$。\n- 模型假设如下：\n    1. 基因型先验概率遵循哈迪-温伯格平衡。\n    2. 读数计数遵循二项抽样模型。\n    3. 读数相互独立。\n    4. 从两条染色体中对等位基因的抽样是无偏的。\n\n### 步骤2：使用提取的已知条件进行验证\n该问题具有科学依据，属于基因组学中变异检测（variant calling）的标准实践范畴。它使用了哈迪-温伯格平衡和带有二项式似然的贝叶斯推断等既定原则，这些都是统计遗传学的基础。该问题定义明确，提供了所有必要的参数（$n$, $k$, $\\epsilon$, $f$）和一个清晰的目标。语言精确客观。没有矛盾、信息缺失或违反科学原则的地方。因此，该问题被认定为有效。\n\n### 步骤3：结论与行动\n问题有效。我现在将进行完整解答。\n\n### 求解推导\n目标是计算三种可能基因型的后验概率 $P(G|D)$，其中 $G$ 是基因型，$D$ 是观测数据 $(n=40, k=18)$。我们使用贝叶斯法则：\n$$P(G_i|D) = \\frac{P(D|G_i) P(G_i)}{\\sum_{j=0}^{2} P(D|G_j) P(G_j)}$$\n对于 $i \\in \\{0, 1, 2\\}$，其中 $G_0 = \\text{纯合参考型}$，$G_1 = \\text{杂合型}$，以及 $G_2 = \\text{纯合备选型}$。\n\n#### 1. 基因型先验概率, $P(G_i)$\n在哈迪-温伯格平衡下，基因型频率由等位基因频率决定。备选等位基因的频率给定为 $f = 0.01$。参考等位基因的频率为 $1-f = 0.99$。\n三种基因型的先验概率为：\n-   $P(G_0) = P(\\text{纯合参考型}) = (1-f)^2 = (0.99)^2 = 0.9801$。\n-   $P(G_1) = P(\\text{杂合型}) = 2f(1-f) = 2(0.01)(0.99) = 0.0198$。\n-   $P(G_2) = P(\\text{纯合备选型}) = f^2 = (0.01)^2 = 0.0001$。\n先验概率之和为 $0.9801 + 0.0198 + 0.0001 = 1.0000$。\n\n#### 2. 似然, $P(D|G_i)$\n在 $n$ 个总读数中观测到 $k$ 个备选读数的似然遵循二项分布：\n$$P(D|G_i) = P(k|n, \\theta_{G_i}) = \\binom{n}{k} \\theta_{G_i}^k (1-\\theta_{G_i})^{n-k}$$\n其中 $\\theta_{G_i}$ 是在给定基因型 $G_i$ 的情况下，单个读数为备选等位基因的概率。\n\n- 对于 $G_0$ (纯合参考型, 基因型 RR): 两条染色体都携带参考等位基因。只有在发生测序错误时才能观测到备选读数。因此，一个读数为备选的概率是 $\\theta_{G_0} = \\epsilon$。\n- 对于 $G_1$ (杂合型, 基因型 RA): 一条染色体是参考型，一条是备选型。假设从两条染色体中进行无偏抽样，一个读数有 $0.5$ 的概率来自参考染色体，有 $0.5$ 的概率来自备选染色体。\n    - 读出备选等位基因的概率是：$P(\\text{读自A})P(\\text{无错误}) + P(\\text{读自R})P(\\text{有错误}) = 0.5 \\times (1-\\epsilon) + 0.5 \\times \\epsilon = 0.5$。\n    - 因此，$\\theta_{G_1} = 0.5$。\n- 对于 $G_2$ (纯合备选型, 基因型 AA): 两条染色体都携带备选等位基因。只有在发生错误时才能观测到参考读数。一个读数为备选的概率是 $\\theta_{G_2} = 1-\\epsilon$。\n\n代入给定值 $n=40$, $k=18$, 和 $\\epsilon=10^{-3}$：\n- $\\theta_{G_0} = 0.001$。\n- $\\theta_{G_1} = 0.5$。\n- $\\theta_{G_2} = 1 - 0.001 = 0.999$。\n\n似然函数为：\n- $P(D|G_0) = \\binom{40}{18} (0.001)^{18} (0.999)^{22}$。\n- $P(D|G_1) = \\binom{40}{18} (0.5)^{18} (0.5)^{22} = \\binom{40}{18} (0.5)^{40}$。\n- $P(D|G_2) = \\binom{40}{18} (0.999)^{18} (0.001)^{22}$。\n\n#### 3. 后验概率, $P(G_i|D)$\n我们需要计算未归一化的后验概率，它与似然和先验的乘积 $P(D|G_i)P(G_i)$ 成正比。项 $\\binom{40}{18}$ 是一个公因子，在比较相对大小时可以省略。\n\n- $G_0$的未归一化后验概率：$T_0 \\propto (0.001)^{18}(0.999)^{22} \\times 0.9801$。\n- $G_1$的未归一化后验概率：$T_1 \\propto (0.5)^{40} \\times 0.0198$。\n- $G_2$的未归一化后验概率：$T_2 \\propto (0.999)^{18}(0.001)^{22} \\times 0.0001$。\n\n观测到的备选等位基因比例为 $k/n = 18/40 = 0.45$。这个值非常接近 $\\theta_{G_1}=0.5$，而与 $\\theta_{G_0}=0.001$ 和 $\\theta_{G_2}=0.999$ 相差甚远。这表明似然 $P(D|G_1)$ 将远大于 $P(D|G_0)$ 和 $P(D|G_2)$。$G_0$ 的先验概率最大，但 $G_0$ 的似然项极小，包含一个因子 $(10^{-3})^{18} = 10^{-54}$。$G_1$ 的先验概率较小，但其似然要大得多。$G_2$ 的先验概率和似然都非常小。因此，我们预期杂合基因型 $G_1$ 是最可能的。\n\n最可能的基因型 $G_1$ 的后验概率为：\n$$P(G_1|D) = \\frac{P(D|G_1)P(G_1)}{P(D|G_0)P(G_0) + P(D|G_1)P(G_1) + P(D|G_2)P(G_2)}$$\n分子和分母同除以 $P(D|G_1)P(G_1)$：\n$$P(G_1|D) = \\frac{1}{\\frac{P(D|G_0)P(G_0)}{P(D|G_1)P(G_1)} + 1 + \\frac{P(D|G_2)P(G_2)}{P(D|G_1)P(G_1)}}$$\n我们来计算这两个比率。二项式系数 $\\binom{40}{18}$ 会被约掉。\n\n比率1：\n$$\\frac{P(D|G_0)P(G_0)}{P(D|G_1)P(G_1)} = \\frac{(0.001)^{18}(0.999)^{22} \\times (0.99)^2}{(0.5)^{40} \\times 2(0.01)(0.99)} = \\frac{(0.001)^{18}(0.999)^{22} \\times 0.99}{(0.5)^{40} \\times 0.02}$$\n- 分子： $(10^{-3})^{18} \\times (0.999)^{22} \\times 0.99 \\approx 10^{-54} \\times 0.9782 \\times 0.99 \\approx 9.684 \\times 10^{-55}$。\n- 分母： $(0.5)^{40} \\times 0.02 \\approx (9.095 \\times 10^{-13}) \\times 0.02 \\approx 1.819 \\times 10^{-14}$。\n- 比率1： $\\frac{9.684 \\times 10^{-55}}{1.819 \\times 10^{-14}} \\approx 5.324 \\times 10^{-41}$。\n\n比率2：\n$$\\frac{P(D|G_2)P(G_2)}{P(D|G_1)P(G_1)} = \\frac{(0.999)^{18}(0.001)^{22} \\times (0.01)^2}{(0.5)^{40} \\times 2(0.01)(0.99)} = \\frac{(0.999)^{18}(0.001)^{22} \\times 0.01}{(0.5)^{40} \\times 1.98}$$\n- 分子： $(0.999)^{18} \\times (10^{-3})^{22} \\times 0.01 \\approx 0.9822 \\times 10^{-66} \\times 10^{-2} \\approx 9.822 \\times 10^{-69}$。\n- 分母： $(0.5)^{40} \\times 1.98 \\approx (9.095 \\times 10^{-13}) \\times 1.98 \\approx 1.801 \\times 10^{-12}$。\n- 比率2： $\\frac{9.822 \\times 10^{-69}}{1.801 \\times 10^{-12}} \\approx 5.454 \\times 10^{-57}$。\n\n两个比率都极其小，这证实了 $G_1$ 的未归一化后验概率占主导地位。\n现在，我们计算 $G_1$ 的后验概率：\n$$P(G_1|D) = \\frac{1}{1 + 5.324 \\times 10^{-41} + 5.454 \\times 10^{-57}}$$\n对于任何实际有效数字位数，这个值都与 $1$ 无法区分。\n$P(G_1|D) \\approx 1 - 5.324 \\times 10^{-41}$。\n四舍五入到 $4$ 位有效数字，我们得到 $1.000$。\n\n最可能的基因型是杂合型（$G_1$），其后验概率极度接近1。\n四舍五入到4位有效数字的概率是 $1.000$。",
            "answer": "$$\\boxed{1.000}$$"
        },
        {
            "introduction": "除了单核苷酸变异，全基因组测序数据还能揭示大规模的结构变化，如缺失和重复。这个动手编码练习  将指导你实现一个隐马尔可夫模型 (HMM)，这是一种完成此类任务的强大算法。你将学习如何整合多个数据轨道（读数深度和B等位基因频率）来分割基因组并识别拷贝数变异，包括像拷贝数中性杂合性缺失 (copy-neutral loss-of-heterozygosity) 这样的挑战性情况。",
            "id": "4397184",
            "problem": "给定两个通过全基因组测序获得的全基因组信号轨迹：读取深度和B等位基因频率。每个区间的读取深度是经过标准归一化后，映射到某个基因组区间的读取数量。每个区间的B等位基因频率（BAF）是在已知的杂合单核苷酸多态性位点上，支持备择等位基因的读取所占的比例。为了将基因组分割成拷贝数或等位基因状态恒定的区域，你必须设计并实现一个隐马尔可夫模型（HMM），其隐藏状态表示拷贝数状态，其发射联合使用深度和BAF不平衡性。\n\n基本依据和假设：\n- 一个区间内的读取计数源于许多独立的抽样事件；根据中心极限定理，每个区间的归一化深度 $D_t$ 可以很好地用一个高斯分布来近似，其均值与拷贝数成正比。设 $D_t \\sim \\mathcal{N}(\\mu_{d}(X_t), \\sigma_{d}(X_t)^2)$。\n- 在杂合位点上的B等位基因频率被建模为二项分布比例，其期望取决于等位基因的构成。在每个区间内对许多位点进行聚合后，与0.5（等位基因平衡）的偏差近似为高斯分布。定义不平衡性特征 $B_t = |BAF_t - 0.5|$，并将其建模为 $B_t \\sim \\mathcal{N}(\\mu_{b}(X_t), \\sigma_{b}(X_t)^2)$。\n- 隐马尔可夫模型（HMM）具有一个离散的隐藏状态 $X_t \\in \\{\\text{CN1}, \\text{CN2}, \\text{CN3}, \\text{LOH}\\}$，其中CN1表示半合子缺失，CN2表示二倍体平衡，CN3表示单拷贝增加，LOH表示拷贝数中性杂合性丢失。给定状态，发射是条件独立的：$p(D_t, B_t \\mid X_t) = p(D_t \\mid X_t) \\cdot p(B_t \\mid X_t)$，其中因子如上所述为高斯分布。\n\n假阳性控制要求：\n- 设期望的每区间假阳性断点率为 $\\alpha$（以小数表示）。为了惩罚虚假的状态变化，使用一个同质转移模型，其中自转移概率为 $P(X_t = s \\mid X_{t-1} = s) = 1 - p_t$，而转移到任何其他状态 $s' \\neq s$ 的概率均等，为 $P(X_t = s' \\mid X_{t-1} = s) = \\frac{p_t}{K-1}$，其中 $K$ 是状态数。根据 $\\alpha$ 和发射分离度选择 $p_t$。一个有原则的惩罚由对数先验比率阈值 $$\\tau = \\log\\left(\\frac{1-p_t}{p_t/(K-1)}\\right),$$ 捕获，维特比算法在比较路径时会隐式应用此阈值。对于较小的 $\\alpha$，设置 $p_t = \\alpha$ 会产生一个保守的转移壁垒，从而减少无变化片段中的假阳性断点。\n\n任务：\n- 实现一个HMM，该模型包含上述四种状态和下面给出的高斯发射参数。使用维特比算法从跨区间的 $(D_t, B_t)$ 中推断出最可能的状态序列。\n- 将深度和BAF轨迹作为独立的高斯因子整合到发射似然中，这样即使在 $D_t$ 未改变时，也能通过 $B_t$ 识别出拷贝数中性杂合性丢失（LOH）。\n- 将转移参数 $p_t$ 调整到一个较小的值以控制假阳性断点率。使用 $K = 4$ 和 $\\alpha = 0.001$，并设置 $p_t = \\alpha$。初始状态分布应在 $K$ 个状态上是均匀的。\n\n使用的发射参数（均值和标准差）：\n- CN1：$\\mu_{d} = 0.5$，$\\sigma_{d} = 0.05$；$\\mu_{b} = 0.45$，$\\sigma_{b} = 0.05$。\n- CN2：$\\mu_{d} = 1.0$，$\\sigma_{d} = 0.07$；$\\mu_{b} = 0.00$，$\\sigma_{b} = 0.02$。\n- CN3：$\\mu_{d} = 1.5$，$\\sigma_{d} = 0.07$；$\\mu_{b} = 0.17$，$\\sigma_{b} = 0.05$。\n- LOH：$\\mu_{d} = 1.0$，$\\sigma_{d} = 0.07$；$\\mu_{b} = 0.45$，$\\sigma_{b} = 0.05$。\n\n分割输出规范：\n- 在计算出最可能的状态路径后，将断点数定义为满足 $X_t \\neq X_{t-1}$（其中 $t \\geq 2$）的索引 $t$ 的数量。\n- 你的程序必须使用上述参数和固定的伪随机种子来模拟带有高斯噪声的合成测试用例，以保证可复现性。\n\n测试套件：\n- 案例1（理想路径）：$200$个CN2区间，接着$100$个CN3区间，然后$200$个CN2区间。\n- 案例2（边界无变化）：仅$500$个CN2区间。\n- 案例3（拷贝数中性LOH）：$150$个CN2区间，接着$50$个LOH区间，然后$150$个CN2区间。\n- 案例4（微小缺失）：$100$个CN2区间，接着$60$个CN1区间，然后$100$个CN2区间。\n\n对于每个案例，通过从相应的高斯发射参数中抽样来生成 $(D_t, B_t)$。使用固定的种子以确保输出是确定性的。\n\n要求的最终输出格式：\n- 你的程序应生成单行输出，其中包含用方括号括起来的逗号分隔的结果列表（例如，\"[result1,result2,result3,result4]\"）。每个结果是对应测试用例（按1到4的顺序）推断出的断点整数数量。\n\n所有比率或概率都用小数表示，不要使用百分号。本问题中不需要物理单位。",
            "solution": "该问题要求设计并实现一个隐马尔可夫模型（HMM），用以将基因组信号轨迹（特别是归一化读取深度和B等位基因频率）分割成具有不同拷贝数状态的区域。给定一个观测序列，推断最可能的隐藏状态序列是通过维特比算法完成的。\n\n首先，我们根据提供的规范来形式化HMM。一个HMM由一组状态、一个初始状态概率分布、一个状态转移概率矩阵和定义了在给定状态下观测到某个观测值的似然的发射概率所定义。\n\n- **状态 ($X_t$)**：基因组区间 $t$ 的隐藏状态属于集合 $S = \\{\\text{CN1}, \\text{CN2}, \\text{CN3}, \\text{LOH}\\}$。我们可以将它们映射为整数索引以便计算：$S = \\{0, 1, 2, 3\\}$。状态总数为 $K=4$。\n\n- **观测值 ($O_t$)**：区间 $t$ 的观测值是一个二维向量 $O_t = (D_t, B_t)$，其中 $D_t$ 是归一化读取深度，$B_t$ 是B等位基因频率不平衡性，定义为 $B_t = |BAF_t - 0.5|$。\n\n- **初始状态分布 ($\\pi$)**：第一个区间（$t=1$）的状态概率分布在所有 $K$ 个状态上是均匀的。\n$$ \\pi_i = P(X_1 = i) = \\frac{1}{K} = \\frac{1}{4} \\quad \\text{for } i \\in \\{0, 1, 2, 3\\} $$\n\n- **转移概率 ($A$)**：该模型使用一个同质转移概率矩阵，意味着从状态 $i$ 转移到状态 $j$ 的概率与时间 $t$ 无关。停留在同一状态的概率是 $1 - p_t$，转移到任何其他 $K-1$ 个状态之一的概率是均匀的 $\\frac{p_t}{K-1}$。假阳性率为 $\\alpha = 0.001$，并设置 $p_t = \\alpha$：\n$$ A_{ij} = P(X_t = j \\mid X_{t-1} = i) = \\begin{cases} 1 - p_t  \\text{if } j=i \\\\ \\frac{p_t}{K-1}  \\text{if } j \\neq i \\end{cases} $$\n代入数值 $p_t = 0.001$ 和 $K=4$：\n$$ A_{ij} = \\begin{cases} 0.999  \\text{if } j=i \\\\ \\frac{0.001}{3}  \\text{if } j \\neq i \\end{cases} $$\n这种结构严重惩罚状态变化，这对于控制假阳性断点是期望的。\n\n- **发射概率 ($b_i(O_t)$)**：发射概率是在隐藏状态为 $X_t=i$ 的条件下，观测到 $O_t=(D_t, B_t)$ 的似然。问题规定，给定状态，深度和不平衡性特征是条件独立的，并且每个特征都服从高斯分布。\n$$ b_i(O_t) = p(D_t, B_t \\mid X_t=i) = p(D_t \\mid X_t=i) \\cdot p(B_t \\mid X_t=i) $$\n每个因子都是一个高斯概率密度函数（PDF）：\n$$ p(y \\mid X_t=i) = \\mathcal{N}(y; \\mu_{y,i}, \\sigma_{y,i}^2) = \\frac{1}{\\sqrt{2\\pi\\sigma_{y,i}^2}} \\exp\\left(-\\frac{(y - \\mu_{y,i})^2}{2\\sigma_{y,i}^2}\\right) $$\n其中 $y$ 可以是 $D_t$ 或 $B_t$，$(\\mu_{y,i}, \\sigma_{y,i})$ 是对应特征 $y$ 和状态 $i$ 的均值和标准差。针对 $K=4$ 个状态中的每一个，都提供了具体的发射参数 $(\\mu_d, \\sigma_d, \\mu_b, \\sigma_b)$。\n\n任务的核心是找到最可能生成给定观测序列 $\\mathbf{O} = (O_1, \\dots, O_T)$ 的状态序列 $\\mathbf{X}^* = (X_1^*, \\dots, X_T^*)$。这是通过使用维特比算法实现的。为了防止长序列的小概率乘积导致数值下溢，该算法使用对数概率来实现。\n\n维特比算法分三步进行：\n\n1.  **初始化 ($t=1$)**：我们计算从每个状态 $i$ 开始并观测到 $O_1$ 的对数概率。我们定义一个矩阵 $V_{i,t}$ 来存储在时间 $t$ 结束于状态 $i$ 的任何路径的最大对数概率。\n$$ V_{i,1} = \\log(\\pi_i) + \\log(b_i(O_1)) \\quad \\text{for } i \\in \\{0, 1, 2, 3\\} $$\n一个回溯指针矩阵 $\\psi_{i,t}$ 被初始化以存储最优的前驱状态。对于 $t=1$，它不是必需的，所以我们可以设置 $\\psi_{i,1} = 0$。\n\n2.  **递归 ($t=2, \\dots, T$)**：对于每个后续的时间步 $t$ 和每个状态 $j$，我们找到使路径概率最大化的前一个状态 $i$。值 $V_{j,t}$ 是在时间 $t$ 到达状态 $j$ 的最佳路径的对数概率，它是在时间 $t$ 处于状态 $j$ 的对数发射概率与在时间 $t-1$ 从任何状态 $i$ 到达状态 $j$ 的最大对数概率之和。\n$$ V_{j,t} = \\max_{i \\in S} \\left( V_{i, t-1} + \\log(A_{ij}) \\right) + \\log(b_j(O_t)) $$\n在时间 $t$ 状态 $j$ 的回溯指针记录了产生这个最大值的状态 $i$。\n$$ \\psi_{j,t} = \\arg\\max_{i \\in S} \\left( V_{i, t-1} + \\log(A_{ij}) \\right) $$\n\n3.  **终止和路径回溯**：在完成直到时间 $T$ 的递归后，最优的最终状态 $X_T^*$ 是具有最高总对数概率的状态。\n$$ X_T^* = \\arg\\max_{j \\in S} (V_{j,T}) $$\n最优路径的其余部分通过使用回溯指针从 $t=T-1$ 向下追溯到 $1$ 来恢复。\n$$ X_t^* = \\psi_{X_{t+1}^*, t+1} \\quad \\text{for } t=T-1, T-2, \\dots, 1 $$\n\n最终的实现将首先为指定的四个测试用例生成合成数据。对于每个区间，根据案例定义分配一个状态，并使用固定的随机种子从相应的高斯分布中抽取观测值 $(D_t, B_t)$ 以保证可复现性。然后将维特比算法应用于这些观测序列，以推断出最可能的状态路径。最后，通过计算 $t \\in \\{2, \\dots, T\\}$ 中满足 $X_t^* \\neq X_{t-1}^*$ 的实例数量来计算断点数。此过程客观地评估了模型在不同场景下（包括连续区域、拷贝数变化和拷贝数中性LOH）正确分割基因组的能力。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.stats import norm\n\ndef solve():\n    \"\"\"\n    Implements an HMM with a Viterbi decoder to segment simulated genomic data,\n    and reports the number of breakpoints found for several test cases.\n    \"\"\"\n\n    # --- HMM Parameters ---\n    # Four states: 0:CN1, 1:CN2, 2:CN3, 3:LOH\n    K = 4\n    STATES = np.arange(K)\n\n    # Emission parameters: (mu_d, sigma_d, mu_b, sigma_b) for each state\n    EMISSION_PARAMS = [\n        (0.5, 0.05, 0.45, 0.05),  # CN1\n        (1.0, 0.07, 0.00, 0.02),  # CN2\n        (1.5, 0.07, 0.17, 0.05),  # CN3\n        (1.0, 0.07, 0.45, 0.05),  # LOH\n    ]\n\n    # Initial state probabilities (uniform)\n    pi = np.full(K, 1.0 / K)\n    log_pi = np.log(pi)\n\n    # Transition probabilities\n    alpha = 0.001\n    p_t = alpha\n    log_A = np.full((K, K), np.log(p_t / (K - 1)))\n    np.fill_diagonal(log_A, np.log(1 - p_t))\n\n    # --- Test Cases ---\n    test_cases_defs = [\n        # Case 1: Happy path\n        # 200 bins CN2, then 100 bins CN3, then 200 bins CN2\n        {'name': 'Case 1', 'segments': [(200, 1), (100, 2), (200, 1)]},\n        # Case 2: Boundary no-change\n        # 500 bins CN2 only\n        {'name': 'Case 2', 'segments': [(500, 1)]},\n        # Case 3: Copy-neutral LOH\n        # 150 bins CN2, then 50 bins LOH, then 150 bins CN2\n        {'name': 'Case 3', 'segments': [(150, 1), (50, 3), (150, 1)]},\n        # Case 4: Subtle loss\n        # 100 bins CN2, then 60 bins CN1, then 100 bins CN2\n        {'name': 'Case 4', 'segments': [(100, 1), (60, 0), (100, 1)]},\n    ]\n\n    # Fixed seed for reproducibility\n    rng = np.random.default_rng(seed=123)\n    \n    results = []\n\n    for case in test_cases_defs:\n        # 1. Generate synthetic data\n        true_states = []\n        for length, state_idx in case['segments']:\n            true_states.extend([state_idx] * length)\n        true_states = np.array(true_states)\n        \n        T = len(true_states)\n        observations = np.zeros((T, 2)) # Columns: D, B\n\n        for t in range(T):\n            state = true_states[t]\n            mu_d, sigma_d, mu_b, sigma_b = EMISSION_PARAMS[state]\n            observations[t, 0] = rng.normal(loc=mu_d, scale=sigma_d)\n            observations[t, 1] = rng.normal(loc=mu_b, scale=sigma_b)\n\n        # 2. Viterbi Algorithm\n        \n        # Pre-compute all log emission probabilities\n        log_emission_probs = np.zeros((T, K))\n        for t in range(T):\n            obs_d, obs_b = observations[t]\n            for s in STATES:\n                mu_d, sigma_d, mu_b, sigma_b = EMISSION_PARAMS[s]\n                log_p_d = norm.logpdf(obs_d, loc=mu_d, scale=sigma_d)\n                log_p_b = norm.logpdf(obs_b, loc=mu_b, scale=sigma_b)\n                log_emission_probs[t, s] = log_p_d + log_p_b\n        \n        # Viterbi matrices\n        V = np.zeros((T, K))  # Viterbi log-probability matrix\n        psi = np.zeros((T, K), dtype=int)  # Backpointer matrix\n\n        # Initialization step (t=0)\n        V[0, :] = log_pi + log_emission_probs[0, :]\n        psi[0, :] = 0\n\n        # Recursion step (t=1 to T-1)\n        for t in range(1, T):\n            for j in STATES:\n                v_t_minus_1 = V[t-1, :]\n                trans_prob_to_j = log_A[:, j]\n                log_prob_sequence = v_t_minus_1 + trans_prob_to_j\n                \n                psi[t, j] = np.argmax(log_prob_sequence)\n                V[t, j] = np.max(log_prob_sequence) + log_emission_probs[t, j]\n\n        # Termination and Backtracking\n        path = np.zeros(T, dtype=int)\n        path[T-1] = np.argmax(V[T-1, :])\n        \n        for t in range(T-2, -1, -1):\n            path[t] = psi[t+1, path[t+1]]\n\n        # 3. Calculate breakpoints\n        breakpoints = np.sum(path[:-1] != path[1:])\n        results.append(breakpoints)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        }
    ]
}