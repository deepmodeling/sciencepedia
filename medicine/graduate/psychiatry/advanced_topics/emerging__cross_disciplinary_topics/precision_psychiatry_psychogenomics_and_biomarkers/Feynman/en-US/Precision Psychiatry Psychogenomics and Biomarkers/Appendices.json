{
    "hands_on_practices": [
        {
            "introduction": "A cornerstone of modern psychogenomics is the Genome-Wide Association Study (GWAS), which simultaneously tests millions of genetic variants for association with a trait. To avoid being overwhelmed by false positives, a stringent statistical threshold is necessary. This first exercise  demonstrates how the canonical genome-wide significance threshold of $p \\lt 5 \\times 10^{-8}$ is derived from first principles, using the Bonferroni correction to control the Family-Wise Error Rate (FWER) across the millions of tests conducted in a typical GWAS.",
            "id": "4743122",
            "problem": "A research team in precision psychiatry is conducting a Genome-Wide Association Study (GWAS) of Major Depressive Disorder (MDD) using imputed genotypes across the autosomes in individuals of primarily European ancestry. After linkage disequilibrium (LD) pruning, they argue that the effective number of independent common variant tests is approximately $10^{6}$. They want to define a genome-wide significance threshold that controls the Family-Wise Error Rate (FWER) at $\\alpha = 0.05$ across the genome. Using only fundamental multiple-testing principles and the null property that valid per-variant $p$-values are uniformly distributed on $[0,1]$ under no association, which statement best defines the genome-wide significance threshold and most accurately justifies the canonical choice of $5 \\times 10^{-8}$?\n\nA. Define the threshold as the per-variant $p$-value $t$ at which the expected number of false positives across the genome equals $1$. With $m = 10^{6}$ tests, this gives $m t = 1$, so $t = 10^{-6}$. This is the standard genome-wide threshold because it ensures, on average, one false positive per study.\n\nB. Define the threshold as the per-variant $p$-value $t$ chosen to control the FWER via the Bonferroni inequality: $\\Pr\\left(\\bigcup_{i=1}^{m}\\{p_i \\le t\\}\\right) \\le \\sum_{i=1}^{m}\\Pr(p_i \\le t) = m t \\le \\alpha$. Setting $m = 10^{6}$ and $\\alpha = 0.05$ yields $t = \\alpha/m = 5 \\times 10^{-8}$. This uses the null-uniform $p$-value property and remains valid (conservative) under LD, with $m$ taken as the effective number of independent tests.\n\nC. Define the threshold as the smallest $p$-value observed in phenotype-permuted data such that the False Discovery Rate (FDR) is approximately $0.05$. With $m = 10^{6}$ tests, this typically gives $t \\approx 5 \\times 10^{-8}$, because FDR and FWER converge for large $m$.\n\nD. Define the threshold using the Šidák correction under independence: choose $t$ such that $1 - (1 - t)^{m} = \\alpha$. For $m = 10^{6}$ and $\\alpha = 0.05$, this gives $t = 1 - (1 - 0.05)^{1/10^{6}} \\approx 5.129 \\times 10^{-8}$. Therefore, $5 \\times 10^{-8}$ cannot be justified by Bonferroni but instead only by permutation studies.\n\nE. Because common variants are correlated by LD, Bonferroni control fails, so a less stringent threshold such as $t = 10^{-6}$ is preferable to maintain statistical power while still controlling the FWER at $\\alpha = 0.05$ across $m = 10^{6}$ effective tests.",
            "solution": "The problem statement is critically validated before proceeding to a solution.\n\n### Step 1: Extract Givens\n-   Study type: Genome-Wide Association Study (GWAS) of Major Depressive Disorder (MDD).\n-   Data source: Imputed genotypes across autosomes in individuals of primarily European ancestry.\n-   Statistical adjustment: Linkage disequilibrium (LD) pruning has been performed.\n-   Effective number of independent tests: $m \\approx 10^{6}$.\n-   Desired error rate to control: Family-Wise Error Rate (FWER).\n-   Significance level for FWER: $\\alpha = 0.05$.\n-   Assumed property of p-values under the null hypothesis: $p$-values are uniformly distributed on the interval $[0,1]$.\n-   Question: To identify the statement that best defines the genome-wide significance threshold and most accurately justifies the canonical choice of $5 \\times 10^{-8}$.\n\n### Step 2: Validate Using Extracted Givens\n-   **Scientifically Grounded**: The problem is set within the standard framework of a GWAS, a cornerstone of modern genetics and precision psychiatry. All concepts, including LD, FWER, Bonferroni correction, and the uniform distribution of null $p$-values, are fundamental principles of statistics and statistical genetics. The effective number of tests being approximately $10^6$ for European populations is a well-established heuristic in the field, used to justify the standard significance threshold. The problem is factually and scientifically sound.\n-   **Well-Posed**: The problem is clearly defined. It provides a set of parameters ($m=10^6$, $\\alpha=0.05$) and a clear objective (control FWER) and asks for the derivation and justification of a specific statistical threshold ($5 \\times 10^{-8}$). A unique, stable, and meaningful solution can be derived from the provided information using established statistical theory.\n-   **Objective**: The language is precise, technical, and free of subjective or biased statements. It uses standard, unambiguous terminology from the relevant scientific disciplines.\n\nThe problem does not exhibit any of the invalidity flaws listed in the instructions (e.g., it is not unsound, incomplete, unrealistic, or ill-posed).\n\n### Step 3: Verdict and Action\nThe problem statement is **valid**. A solution will be derived.\n\n### Derivation of the Genome-Wide Significance Threshold\n\nThe primary goal is to control the Family-Wise Error Rate (FWER) at a level of $\\alpha = 0.05$. The FWER is defined as the probability of making one or more Type I errors (false positives) across all hypotheses tested. Let $m$ be the number of independent tests, and let $t$ be the per-test significance threshold. A Type I error for test $i$ occurs if its $p$-value, $p_i$, is less than or equal to $t$ when the null hypothesis for test $i$ is true.\n\nThe FWER is the probability of the union of these events:\n$$ \\text{FWER} = \\Pr\\left(\\bigcup_{i=1}^{m} \\{p_i \\le t\\}\\right) $$\nTo control this, we can use the Bonferroni correction, which is based on Boole's inequality (also known as the union bound). Boole's inequality states that for any collection of events $A_1, A_2, \\dots, A_m$:\n$$ \\Pr\\left(\\bigcup_{i=1}^{m} A_i\\right) \\le \\sum_{i=1}^{m} \\Pr(A_i) $$\nApplying this to the FWER calculation:\n$$ \\text{FWER} = \\Pr\\left(\\bigcup_{i=1}^{m} \\{p_i \\le t\\}\\right) \\le \\sum_{i=1}^{m} \\Pr(p_i \\le t) $$\nThe problem states that under the null hypothesis, $p$-values are uniformly distributed on the interval $[0,1]$. For a random variable $P \\sim U(0,1)$, the probability $\\Pr(P \\le t)$ is equal to $t$ for any $t \\in [0,1]$. Therefore, assuming all tests are performed under the null hypothesis (the most conservative scenario for FWER control):\n$$ \\Pr(p_i \\le t) = t $$\nSubstituting this into the inequality gives:\n$$ \\text{FWER} \\le \\sum_{i=1}^{m} t = m \\cdot t $$\nTo control the FWER at level $\\alpha$, we enforce the condition that this upper bound is less than or equal to $\\alpha$:\n$$ m \\cdot t \\le \\alpha $$\nThe most stringent per-test threshold $t$ that satisfies this is found by setting the terms equal:\n$$ t = \\frac{\\alpha}{m} $$\nUsing the given values:\n-   Effective number of independent tests, $m = 10^{6}$.\n-   Desired FWER, $\\alpha = 0.05$.\n\nThe required per-test significance threshold is:\n$$ t = \\frac{0.05}{10^{6}} = 5 \\times 10^{-8} $$\nThis derivation, based on the Bonferroni correction applied to an effective number of independent tests, provides the theoretical justification for the canonical genome-wide significance threshold of $5 \\times 10^{-8}$.\n\n### Option-by-Option Analysis\n\n**A. Define the threshold as the per-variant $p$-value $t$ at which the expected number of false positives across the genome equals $1$. With $m = 10^{6}$ tests, this gives $m t = 1$, so $t = 10^{-6}$. This is the standard genome-wide threshold because it ensures, on average, one false positive per study.**\n\nThe expected number of false positives under the global null hypothesis is $E[V] = \\sum_{i=1}^{m} \\Pr(p_i \\le t) = m \\cdot t$. Setting $E[V]=1$ gives $mt=1$, so $t=1/m = 10^{-6}$. This calculation is correct. However, this procedure does not control the FWER at $\\alpha=0.05$. The FWER is $\\Pr(V \\ge 1)$. For independent tests, the number of false positives $V$ follows a binomial distribution $B(m,t)$. For small $t$ and large $m$, this can be approximated by a Poisson distribution with mean $\\lambda = mt$. If we set $\\lambda=1$, the FWER is $\\Pr(V \\ge 1) = 1 - \\Pr(V=0) = 1 - e^{-\\lambda} = 1 - e^{-1} \\approx 0.632$. This is far greater than the desired $\\alpha=0.05$. Furthermore, the statement incorrectly identifies $10^{-6}$ as the standard threshold.\n**Verdict: Incorrect.**\n\n**B. Define the threshold as the per-variant $p$-value $t$ chosen to control the FWER via the Bonferroni inequality: $\\Pr\\left(\\bigcup_{i=1}^{m}\\{p_i \\le t\\}\\right) \\le \\sum_{i=1}^{m}\\Pr(p_i \\le t) = m t \\le \\alpha$. Setting $m = 10^{6}$ and $\\alpha = 0.05$ yields $t = \\alpha/m = 5 \\times 10^{-8}$. This uses the null-uniform $p$-value property and remains valid (conservative) under LD, with $m$ taken as the effective number of independent tests.**\n\nThis statement correctly identifies the Bonferroni correction as the method for controlling FWER. It presents the correct mathematical inequality, $\\text{FWER} \\le mt$. It correctly uses the given parameters $m=10^6$ and $\\alpha=0.05$ to calculate the threshold $t = 0.05 / 10^6 = 5 \\times 10^{-8}$. It correctly notes that this relies on the uniform null $p$-value distribution. Finally, it accurately describes the role of LD: the Bonferroni correction is always conservative (provides a valid upper bound), and using the *effective* number of tests is the standard approach to make the correction more accurate and less overly conservative than using the total number of variants. This option provides a complete and accurate justification.\n**Verdict: Correct.**\n\n**C. Define the threshold as the smallest $p$-value observed in phenotype-permuted data such that the False Discovery Rate (FDR; False Discovery Rate) is approximately $0.05$. With $m = 10^{6}$ tests, this typically gives $t \\approx 5 \\times 10^{-8}$, because FDR and FWER converge for large $m$.**\n\nThis statement contains multiple errors. First, the problem asks to control the FWER, not the FDR. FWER and FDR are different metrics with different properties; controlling FWER at $\\alpha$ is much stricter than controlling FDR at $\\alpha$. Second, the claim that FDR and FWER converge for large $m$ is false. They measure different quantities and behave differently. Third, while phenotype permutation is a valid method to control FWER (by finding the 5th percentile of the distribution of genome-wide minimum $p$-values), this option incorrectly links it to FDR control. A threshold controlling FDR at $0.05$ would be substantially less stringent (i.e., a larger $p$-value) than one controlling FWER at $0.05$.\n**Verdict: Incorrect.**\n\n**D. Define the threshold using the Šidák correction under independence: choose $t$ such that $1 - (1 - t)^{m} = \\alpha$. For $m = 10^{6}$ and $\\alpha = 0.05$, this gives $t = 1 - (1 - 0.05)^{1/10^{6}} \\approx 5.129 \\times 10^{-8}$. Therefore, $5 \\times 10^{-8}$ cannot be justified by Bonferroni but instead only by permutation studies.**\n\nThe Šidák correction formula and the calculation are correct. The threshold is indeed approximately $5.129 \\times 10^{-8}$. However, the conclusion drawn is fallacious. The Bonferroni threshold, $t = \\alpha/m = 5 \\times 10^{-8}$, is an excellent and slightly more conservative approximation of the Šidák threshold. The statement that $5 \\times 10^{-8}$ \"cannot be justified by Bonferroni\" is directly contradicted by the simple calculation $0.05/10^6$. In fact, the Bonferroni calculation is precisely the most common justification given for the $5 \\times 10^{-8}$ value due to its simplicity and conservative nature.\n**Verdict: Incorrect.**\n\n**E. Because common variants are correlated by LD, Bonferroni control fails, so a less stringent threshold such as $t = 10^{-6}$ is preferable to maintain statistical power while still controlling the FWER at $\\alpha = 0.05$ across $m = 10^{6}$ effective tests.**\n\nThis statement is fundamentally flawed. First, Bonferroni control does not \"fail\" with correlated tests; it becomes overly conservative, meaning the true FWER is even lower than the nominal level $\\alpha$. The inequality $\\text{FWER} \\le mt$ always holds. Second, the problem statement specifies that $m=10^6$ is the *effective number of independent tests*, a heuristic explicitly designed to account for LD and make the Bonferroni correction more accurate. Third, and most critically, a threshold of $t = 10^{-6}$ does not control the FWER at $\\alpha = 0.05$ for $m=10^6$ tests. As calculated for option A, the Bonferroni bound would be $m \\cdot t = 10^6 \\times 10^{-6} = 1$, and the actual FWER would be approximately $0.632$, not $0.05$.\n**Verdict: Incorrect.**",
            "answer": "$$\\boxed{B}$$"
        },
        {
            "introduction": "Once a genetic variant is found to be significantly associated with a psychiatric outcome, a crucial next step is to quantify its effect size. A key metric is the proportion of variance in the trait's liability that the variant explains. This practice  delves into this calculation, introducing the real-world complexity of population stratification and showing how the law of total variance is used to correctly compute the variance explained in a sample of mixed ancestry. This skill is vital for interpreting the magnitude of genetic effects and understanding how population structure can influence genetic studies.",
            "id": "4743194",
            "problem": "A pharmacogenomic study in precision psychiatry investigates a biallelic Single-Nucleotide Polymorphism (SNP) that influences the liability to remission with a selective serotonin reuptake inhibitor. Assume a standard additive liability model in which the binary clinical outcome arises from a continuous liability with unit variance, and the SNP contributes additively to the liability. Specifically, let the liability be $Y = \\mu + \\beta G + \\epsilon$, where $G \\in \\{0,1,2\\}$ is the minor-allele count, $\\beta$ is the per-allele effect on the liability scale, and $\\epsilon$ is residual variation independent of $G$ chosen such that $\\operatorname{Var}(Y) = 1$. The study sample is a mixture of two ancestries with different minor allele frequencies but the same causal effect size on the liability scale:\n- Ancestry $A$ has population weight $w_A = 0.6$ and minor allele frequency $p_A = 0.15$.\n- Ancestry $B$ has population weight $w_B = 0.4$ and minor allele frequency $p_B = 0.35$.\nAssume within each ancestry Hardy–Weinberg Equilibrium (HWE) holds and random mating occurs, there is no dominance deviation, no gene–environment interaction, and no linkage disequilibrium with other causal variants. The per-allele effect on the liability scale is $\\beta = 0.20$. Starting from the definitions of variance, the additive genetic model, and the law of total variance, derive and compute the variance in liability explained by this SNP in the pooled sample as a decimal fraction. Round your answer to four significant figures.",
            "solution": "The problem asks for the variance in liability explained by a single-nucleotide polymorphism (SNP) in a pooled sample from two different ancestries.\n\nThe liability $Y$ is given by the additive model:\n$$Y = \\mu + \\beta G + \\epsilon$$\nwhere $G$ is the minor-allele count, $\\beta$ is the per-allele effect size, and $\\epsilon$ is the residual variation independent of $G$. The variance in liability explained by the SNP is the variance of the genetic component of the liability, which is $\\operatorname{Var}(\\beta G)$. Since $\\beta$ is a constant, this is equal to $\\beta^2 \\operatorname{Var}(G)$. Our task is to compute this value for the pooled sample.\n\nThe pooled sample is a mixture of two ancestries, $A$ and $B$. Let $S$ be a random variable representing the ancestry of an individual, such that $S \\in \\{A, B\\}$. The problem states the population weights are $w_A = P(S=A) = 0.6$ and $w_B = P(S=B) = 0.4$.\n\nTo find the variance of the genotype score $G$ in the pooled sample, we use the Law of Total Variance:\n$$\\operatorname{Var}(G) = E[\\operatorname{Var}(G|S)] + \\operatorname{Var}(E[G|S])$$\n\nWe will compute each term separately.\n\nFirst Term: $E[\\operatorname{Var}(G|S)]$\nThis term represents the average of the within-ancestry variances, weighted by the population frequencies.\n$$E[\\operatorname{Var}(G|S)] = \\operatorname{Var}(G|S=A) \\cdot P(S=A) + \\operatorname{Var}(G|S=B) \\cdot P(S=B)$$\n$$E[\\operatorname{Var}(G|S)] = \\operatorname{Var}_A(G) \\cdot w_A + \\operatorname{Var}_B(G) \\cdot w_B$$\nWithin each ancestry, the problem states that Hardy-Weinberg Equilibrium (HWE) holds. For a biallelic locus with minor allele frequency $p$, the genotype count $G \\in \\{0, 1, 2\\}$ follows a Binomial distribution for the number of minor alleles, $G \\sim \\operatorname{Binomial}(2, p)$. The variance of a binomial distribution $\\operatorname{Binomial}(n, p)$ is $np(1-p)$. Therefore, the variance of $G$ within an ancestry with minor allele frequency $p_i$ is given by:\n$$\\operatorname{Var}(G|S=i) = 2p_i(1-p_i)$$\nFor ancestry $A$, the minor allele frequency is $p_A = 0.15$. The variance of $G$ is:\n$$\\operatorname{Var}_A(G) = 2p_A(1-p_A) = 2(0.15)(1 - 0.15) = 2(0.15)(0.85) = 0.255$$\nFor ancestry $B$, the minor allele frequency is $p_B = 0.35$. The variance of $G$ is:\n$$\\operatorname{Var}_B(G) = 2p_B(1-p_B) = 2(0.35)(1 - 0.35) = 2(0.35)(0.65) = 0.455$$\nNow we can compute the weighted average:\n$$E[\\operatorname{Var}(G|S)] = (0.255)(0.6) + (0.455)(0.4) = 0.153 + 0.182 = 0.335$$\n\nSecond Term: $\\operatorname{Var}(E[G|S])$\nThis term represents the variance between the expected genotype counts of the two ancestries. We first need to compute the expected value of $G$ for each ancestry. For a Binomial distribution $G \\sim \\operatorname{Binomial}(2, p)$, the mean is $E[G] = 2p$.\nFor ancestry $A$:\n$$E[G|S=A] = 2p_A = 2(0.15) = 0.3$$\nFor ancestry $B$:\n$$E[G|S=B] = 2p_B = 2(0.35) = 0.7$$\nLet $X$ be the random variable $E[G|S]$. $X$ takes the value $0.3$ with probability $w_A = 0.6$ and the value $0.7$ with probability $w_B = 0.4$. We compute the variance of $X$ using the formula $\\operatorname{Var}(X) = E[X^2] - (E[X])^2$.\nFirst, the mean of $X$:\n$$E[X] = E[E[G|S]] = (0.3)(0.6) + (0.7)(0.4) = 0.18 + 0.28 = 0.46$$\nNext, the expectation of $X^2$:\n$$E[X^2] = (0.3^2)(0.6) + (0.7^2)(0.4) = (0.09)(0.6) + (0.49)(0.4) = 0.054 + 0.196 = 0.25$$\nNow, the variance of $X$:\n$$\\operatorname{Var}(E[G|S]) = \\operatorname{Var}(X) = E[X^2] - (E[X])^2 = 0.25 - (0.46)^2 = 0.25 - 0.2116 = 0.0384$$\n\nTotal Variance of $G$:\nNow we sum the two components to find the total variance of $G$ in the pooled sample:\n$$\\operatorname{Var}(G) = E[\\operatorname{Var}(G|S)] + \\operatorname{Var}(E[G|S]) = 0.335 + 0.0384 = 0.3734$$\n\nVariance Explained by the SNP:\nFinally, we compute the variance in liability explained by the SNP, which is $\\beta^2 \\operatorname{Var}(G)$. The problem gives the per-allele effect size as $\\beta = 0.20$.\n$$\\beta^2 = (0.20)^2 = 0.04$$\nThe variance explained is:\n$$\\operatorname{Var}(\\beta G) = \\beta^2 \\operatorname{Var}(G) = (0.04)(0.3734) = 0.014936$$\nThe problem requires the answer to be rounded to four significant figures. The first four significant figures are $1$, $4$, $9$, $3$. The next digit is $6$, so we round up the fourth significant figure.\n$$0.014936 \\approx 0.01494$$\nThis is the variance in liability explained by the SNP in the pooled sample.",
            "answer": "$$\\boxed{0.01494}$$"
        },
        {
            "introduction": "Precision psychiatry extends beyond DNA to other molecular biomarkers, such as messenger RNA (mRNA) levels from transcriptomic studies. When searching for gene expression signatures of a disorder, we again face a massive multiple testing problem. This final exercise  provides practical experience with the core analytical steps in biomarker discovery, from calculating the log-fold change in expression to applying the Benjamini–Hochberg procedure to control the False Discovery Rate (FDR). Mastering this procedure is essential for robustly interpreting any high-throughput 'omics' dataset.",
            "id": "4743128",
            "problem": "A consortium study in precision psychiatry integrates psychogenomic measurements and blood-derived messenger ribonucleic acid (mRNA) biomarkers to identify transcriptional signatures associated with Major Depressive Disorder (MDD). Suppose the normalized transcript abundance (in arbitrary units comparable across samples, after library-size and composition normalization) for the serotonin transporter gene SLC6A4 is measured in $n_{\\text{cases}} = 8$ MDD cases and $n_{\\text{controls}} = 8$ matched controls. The case group values are $[5.1, 4.8, 5.7, 6.0, 4.9, 5.3, 5.6, 5.0]$ and the control group values are $[3.8, 4.1, 3.9, 4.2, 3.7, 3.8, 4.0, 3.9]$. Treat these as independent measurements of steady-state expression, consistent with the Central Dogma of molecular biology and standard transcriptomics quantification, and let $\\bar{x}_{\\text{cases}}$ and $\\bar{x}_{\\text{controls}}$ denote the sample means for SLC6A4 in cases and controls, respectively.\n\nSeparately, a differential expression pipeline produced gene-level hypothesis test $p$-values for $m = 10$ candidate MDD biomarker genes (including SLC6A4), based on appropriate model-based statistics. The ten genes and their corresponding raw $p$-values are:\nSLC6A4: $0.0042$; FKBP5: $0.0018$; BDNF: $0.010$; NR3C1: $0.040$; COMT: $0.070$; MAOA: $0.090$; CACNA1C: $0.020$; HTR2A: $0.030$; DRD2: $0.050$; CRH: $0.060$.\n\nStarting from fundamental definitions of sample means, logarithms, and the concept of the False Discovery Rate (FDR), do the following:\n- Compute the differential expression log-fold change $\\log_{2}\\!\\left(\\frac{\\bar{x}_{\\text{cases}}}{\\bar{x}_{\\text{controls}}}\\right)$ for SLC6A4.\n- Adjust the ten raw $p$-values using the Benjamini–Hochberg FDR procedure to obtain $q$-values, and then identify the $q$-value corresponding to SLC6A4.\n\nReport only the Benjamini–Hochberg $q$-value for SLC6A4 as your final answer. Round your final answer to four significant figures. No units are required for the final answer.",
            "solution": "We first formalize the required computations. Let the case values for SLC6A4 be denoted by $\\{x_{1}^{\\text{cases}}, \\dots, x_{8}^{\\text{cases}}\\}$ and the control values by $\\{x_{1}^{\\text{controls}}, \\dots, x_{8}^{\\text{controls}}\\}$. The sample means are\n$$\n\\bar{x}_{\\text{cases}} = \\frac{1}{8} \\sum_{i=1}^{8} x_{i}^{\\text{cases}}, \\quad\n\\bar{x}_{\\text{controls}} = \\frac{1}{8} \\sum_{i=1}^{8} x_{i}^{\\text{controls}}.\n$$\nThe log-fold change is defined as\n$$\n\\log_{2}\\!\\left(\\frac{\\bar{x}_{\\text{cases}}}{\\bar{x}_{\\text{controls}}}\\right) = \\frac{\\ln\\!\\left(\\bar{x}_{\\text{cases}}/\\bar{x}_{\\text{controls}}\\right)}{\\ln(2)}.\n$$\n\nFor multiple hypothesis testing, the False Discovery Rate (FDR) is the expected proportion of false positives among rejected hypotheses. The Benjamini–Hochberg (BH) procedure controls FDR at a desired level by ranking raw $p$-values in ascending order, $p_{(1)} \\le p_{(2)} \\le \\cdots \\le p_{(m)}$, and then computing adjusted values\n$$\nq_{(i)} = \\min\\!\\left( \\frac{m}{i} \\, p_{(i)}, \\, q_{(i+1)} \\right),\n$$\nwith $q_{(m)} = p_{(m)}$, ensuring the monotonicity $q_{(1)} \\le q_{(2)} \\le \\cdots \\le q_{(m)}$. The $q$-value for a given gene is the BH-adjusted value mapped back to its original label.\n\nStep 1: Compute $\\bar{x}_{\\text{cases}}$ and $\\bar{x}_{\\text{controls}}$ for SLC6A4.\nThe case values are $[5.1, 4.8, 5.7, 6.0, 4.9, 5.3, 5.6, 5.0]$. Summing,\n$$\n5.1 + 4.8 = 9.9, \\quad 9.9 + 5.7 = 15.6, \\quad 15.6 + 6.0 = 21.6, \\quad 21.6 + 4.9 = 26.5,\n$$\n$$\n26.5 + 5.3 = 31.8, \\quad 31.8 + 5.6 = 37.4, \\quad 37.4 + 5.0 = 42.4.\n$$\nThus,\n$$\n\\bar{x}_{\\text{cases}} = \\frac{42.4}{8} = 5.3.\n$$\nThe control values are $[3.8, 4.1, 3.9, 4.2, 3.7, 3.8, 4.0, 3.9]$. Summing,\n$$\n3.8 + 4.1 = 7.9, \\quad 7.9 + 3.9 = 11.8, \\quad 11.8 + 4.2 = 16.0, \\quad 16.0 + 3.7 = 19.7,\n$$\n$$\n19.7 + 3.8 = 23.5, \\quad 23.5 + 4.0 = 27.5, \\quad 27.5 + 3.9 = 31.4.\n$$\nThus,\n$$\n\\bar{x}_{\\text{controls}} = \\frac{31.4}{8} = 3.925.\n$$\nTherefore, the ratio of means is\n$$\n\\frac{\\bar{x}_{\\text{cases}}}{\\bar{x}_{\\text{controls}}} = \\frac{5.3}{3.925} = \\frac{5300}{3925} = \\frac{212}{157}.\n$$\nThe log-fold change is\n$$\n\\log_{2}\\!\\left(\\frac{\\bar{x}_{\\text{cases}}}{\\bar{x}_{\\text{controls}}}\\right) = \\log_{2}\\!\\left(\\frac{212}{157}\\right) = \\frac{\\ln(212/157)}{\\ln(2)}.\n$$\nFor intuition, $\\frac{212}{157} \\approx 1.350955$, so the log-fold change is positive, indicating higher expression in cases than controls.\n\nStep 2: Apply Benjamini–Hochberg to obtain $q$-values and identify SLC6A4’s $q$-value.\nWe have $m = 10$ raw $p$-values:\n$$\n\\text{SLC6A4}: 0.0042; \\quad \\text{FKBP5}: 0.0018; \\quad \\text{BDNF}: 0.010; \\quad \\text{NR3C1}: 0.040; \\quad \\text{COMT}: 0.070;\n$$\n$$\n\\text{MAOA}: 0.090; \\quad \\text{CACNA1C}: 0.020; \\quad \\text{HTR2A}: 0.030; \\quad \\text{DRD2}: 0.050; \\quad \\text{CRH}: 0.060.\n$$\nOrder them ascending:\n$$\np_{(1)} = 0.0018, \\quad p_{(2)} = 0.0042, \\quad p_{(3)} = 0.010, \\quad p_{(4)} = 0.020, \\quad p_{(5)} = 0.030,\n$$\n$$\np_{(6)} = 0.040, \\quad p_{(7)} = 0.050, \\quad p_{(8)} = 0.060, \\quad p_{(9)} = 0.070, \\quad p_{(10)} = 0.090.\n$$\nCompute initial BH adjusted values $\\tilde{q}_{(i)} = \\frac{m}{i} p_{(i)}$:\n$$\n\\tilde{q}_{(1)} = \\frac{10}{1} \\cdot 0.0018 = 0.018, \\quad \\tilde{q}_{(2)} = \\frac{10}{2} \\cdot 0.0042 = 0.021,\n$$\n$$\n\\tilde{q}_{(3)} = \\frac{10}{3} \\cdot 0.010 \\approx 0.033333\\ldots,\n$$\n$$\n\\tilde{q}_{(4)} = \\frac{10}{4} \\cdot 0.020 = 0.050, \\quad \\tilde{q}_{(5)} = \\frac{10}{5} \\cdot 0.030 = 0.060,\n$$\n$$\n\\tilde{q}_{(6)} = \\frac{10}{6} \\cdot 0.040 \\approx 0.066666\\ldots, \\quad \\tilde{q}_{(7)} = \\frac{10}{7} \\cdot 0.050 \\approx 0.071428\\ldots,\n$$\n$$\n\\tilde{q}_{(8)} = \\frac{10}{8} \\cdot 0.060 = 0.075, \\quad \\tilde{q}_{(9)} = \\frac{10}{9} \\cdot 0.070 \\approx 0.077777\\ldots,\n$$\n$$\n\\tilde{q}_{(10)} = \\frac{10}{10} \\cdot 0.090 = 0.090.\n$$\nNow enforce monotonicity by setting\n$$\nq_{(10)} = \\tilde{q}_{(10)} = 0.090,\n$$\nand for $i = 9, 8, \\dots, 1$,\n$$\nq_{(i)} = \\min\\!\\left( \\tilde{q}_{(i)}, \\, q_{(i+1)} \\right).\n$$\nBecause the sequence $\\tilde{q}_{(i)}$ computed above is already non-decreasing, we obtain\n$$\nq_{(1)} = 0.018, \\quad q_{(2)} = 0.021, \\quad q_{(3)} \\approx 0.033333\\ldots, \\quad q_{(4)} = 0.050, \\quad q_{(5)} = 0.060,\n$$\n$$\nq_{(6)} \\approx 0.066666\\ldots, \\quad q_{(7)} \\approx 0.071428\\ldots, \\quad q_{(8)} = 0.075, \\quad q_{(9)} \\approx 0.077777\\ldots, \\quad q_{(10)} = 0.090.\n$$\nMap back to gene labels. SLC6A4 corresponds to $p = 0.0042$, which is the second smallest, i.e., $p_{(2)}$. Therefore, the BH $q$-value for SLC6A4 is\n$$\nq_{\\text{SLC6A4}} = q_{(2)} = 0.021.\n$$\n\nRounding to four significant figures, $q_{\\text{SLC6A4}} = 0.02100$.",
            "answer": "$$\\boxed{0.02100}$$"
        }
    ]
}