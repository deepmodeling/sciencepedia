{
    "hands_on_practices": [
        {
            "introduction": "精神病学领域的人工智能模型常常为高风险患者生成警报。然而，一个在纸面上准确率很高的模型，在实践中可能会产生误导，尤其是当所预测的病症非常罕见时。这项练习深入探讨了灵敏度、特异度和患病率等关键概念，并应用贝叶斯定理来推导阳性预测值（$PPV$）。\n\n通过解决这个问题 ，您将具体理解为何低患病率会显著降低模型的阳性预测值，从而导致大量的假阳性警报。这项技能对于批判性地评估人工智能筛查工具，以及规划能够有效处理警报量而又不至于耗尽临床资源的后续工作流程至关重要。",
            "id": "4689968",
            "problem": "一个综合医疗保健系统部署了一个人工智能（AI）风险分层模型，用于筛查成年基础保健患者在未来$6$个月内发生自杀未遂的风险。在一个按时间划分且能代表目标部署人群的留出测试集上，该模型在固定的警报阈值下运行，达到了$0.85$的灵敏度（sensitivity）和$0.95$的特异度（specificity）。独立的监测数据表明，该人群中$6$个月的自杀未遂发生率（预测期内的患病率）为 $\\pi = 0.02$。请仅使用灵敏度、特异度和患病率的核心定义以及贝叶斯定理，从第一性原理推导阳性预测值（PPV）的表达式，其中PPV定义为在收到阳性警报的情况下，患者在$6$个月内确实会发生自杀未遂的概率。然后计算此场景下的PPV数值。将最终的PPV表示为四舍五入到$4$位有效数字的小数。最后，简要地用文字解释，如果该模型用于触发外展服务，这个PPV对临床分诊和资源分配意味着什么，无需计算任何额外的数值。",
            "solution": "该问题是有效的，因为它科学地基于生物统计学的既定原则，问题表述清晰，信息充分且一致，并且陈述客观。\n\n任务是推导阳性预测值（PPV）的表达式，计算其在给定场景下的数值，并解释结果。\n\n我们定义以下事件：\n- $S$：患者在$6$个月内发生自杀未遂的事件。\n- $S^c$：患者在$6$个月内未发生自杀未遂的事件。\n- $A$：AI模型为患者生成阳性警报的事件。\n- $A^c$：AI模型未为患者生成阳性警报的事件。\n\n根据问题陈述，我们得到以下概率：\n- 自杀未遂的患病率（发生率）为 $\\pi = P(S) = 0.02$。\n- 模型的灵敏度是给定发生自杀未遂的情况下出现阳性警报的概率，即 $P(A|S) = 0.85$。\n- 模型的特异度是给定未发生自杀未遂的情况下出现阴性警报的概率，即 $P(A^c|S^c) = 0.95$。\n\n根据患病率的定义，患者未发生自杀未遂的概率为 $P(S^c) = 1 - P(S) = 1 - \\pi = 1 - 0.02 = 0.98$。\n根据特异度的定义，我们可以推导出假阳性率（FPR），即在未发生自杀未遂的情况下出现阳性警报的概率：\n$P(A|S^c) = 1 - P(A^c|S^c) = 1 - 0.95 = 0.05$。\n\n阳性预测值（PPV）定义为在测试结果为阳性（警报）的情况下，患者确实有该状况（自杀未遂）的概率。用我们的符号表示，即为 $P(S|A)$。\n\n我们使用贝叶斯定理从第一性原理推导PPV的表达式：\n$$P(S|A) = \\frac{P(A|S)P(S)}{P(A)}$$\n\n分母 $P(A)$ 是收到阳性警报的边际概率。我们可以使用全概率定律，对互斥且穷举的事件 $S$ 和 $S^c$ 求和来计算它：\n$$P(A) = P(A|S)P(S) + P(A|S^c)P(S^c)$$\n\n将 $P(A)$ 的这个表达式代入贝叶斯定理，得到PPV的完整表达式：\n$$PPV = P(S|A) = \\frac{P(A|S)P(S)}{P(A|S)P(S) + P(A|S^c)P(S^c)}$$\n\n这可以用灵敏度、特异度和患病率（$\\pi$）来表示：\n$$PPV = \\frac{(\\text{灵敏度}) \\times \\pi}{(\\text{灵敏度}) \\times \\pi + (1 - \\text{特异度}) \\times (1 - \\pi)}$$\n这就是从第一性原理进行的必要推导。\n\n接下来，我们通过代入给定值来计算PPV的数值：\n- $\\text{灵敏度} = 0.85$\n- $\\text{特异度} = 0.95$\n- $\\pi = 0.02$\n\n分子是：\n$P(A|S)P(S) = 0.85 \\times 0.02 = 0.017$。\n\n分母是：\n$P(A) = P(A|S)P(S) + P(A|S^c)P(S^c) = (0.85 \\times 0.02) + ((1 - 0.95) \\times (1 - 0.02))$\n$P(A) = (0.017) + (0.05 \\times 0.98)$\n$P(A) = 0.017 + 0.049 = 0.066$。\n\n现在，我们可以计算PPV：\n$$PPV = \\frac{0.017}{0.066} = \\frac{17}{66} \\approx 0.257575...$$\n\n四舍五入到$4$位有效数字，PPV为 $0.2576$。\n\n最后，我们解释这个PPV对临床分诊和资源分配的意义。$0.2576$的PPV意味着，在所有从AI模型收到阳性警报的患者中，只有大约$25.8\\%$的人会在随后的$6$个月内真正发生自杀未遂。其余的大多数，约$74.2\\%$，是假阳性。\n\n在临床上，这意味着一个阳性警报不能被视为高风险的最终确认。相反，它应被视为一个需要进一步、更详细临床评估的信号。如果模型的警报用于触发外展服务，那么外展方案必须设计成能够处理大量的假阳性。对于模型正确识别的每一个真正的高风险个体，外展工作人员将需要与大约三个并非真正处于高风险的个体进行接触（因为 $(1-0.2576)/0.2576 \\approx 2.88$）。这对资源分配具有重大影响。一个高效的二次筛查流程至关重要，以避免精神卫生服务负担过重，并防止临床医生出现“警报疲劳”，即频繁的假警报可能导致警报被忽略。模型的价值在于丰富一个亚群以进行有针对性的筛查，而不是取代临床判断。",
            "answer": "$$\\boxed{0.2576}$$"
        },
        {
            "introduction": "虽然二元分类（例如，高风险 vs. 低风险）很有用，但现代人工智能模型通常能提供更精细的输出：个体化的风险概率。评估这些概率性预测需要超越简单准确率的度量标准。本练习介绍了两个核心指标：用于衡量整体概率准确性的布里尔分数（Brier score）和用于评估模型预测概率是否可靠的校准斜率（calibration slope）。\n\n完成这项练习  将教会您如何量化模型的辨别能力及其校准度——即，预测的 $20\\%$ 风险是否真正对应于 $20\\%$ 的事件发生率。这对于使用模型输出来向患者传达风险，或根据风险大小做出决策至关重要。",
            "id": "4689987",
            "problem": "一个人工智能模型为一个由10名接受门诊治疗的成年人组成的留出队列，输出了未来 $30$ 天内重度抑郁症复发的个性化预测概率。对于每位患者 $i$，模型的预测概率为 $p_i \\in (0,1)$，观测结果为 $y_i \\in \\{0,1\\}$，其中 $y_i=1$ 表示在随访期间复发。预测和结果如下：\n- 患者 $1$–$6$：$p_i = 0.20$。其中，患者 $1$ 和 $3$ 复发（$y_1 = 1$, $y_3 = 1$），患者 $2$、$4$、$5$ 和 $6$ 未复发（$y_2 = 0$, $y_4 = 0$, $y_5 = 0$, $y_6 = 0$）。\n- 患者 $7$–$10$：$p_i = 0.65$。其中，患者 $7$、$8$ 和 $10$ 复发（$y_7 = 1$, $y_8 = 1$, $y_{10} = 1$），患者 $9$ 未复发（$y_9 = 0$）。\n\n仅从核心定义出发：\n- Brier分数是 $n$ 个患者的预测概率 $p_i$ 和观测结果 $y_i$ 之间的均方误差。\n- 校准斜率通过逻辑斯谛校准定义：将 $y_i$ 对预测概率的对数优势比进行逻辑斯谛回归拟合，即用线性预测器 $\\alpha + \\beta \\,\\text{logit}(p_i)$ 来建模 $\\Pr(y_i=1 \\mid \\text{logit}(p_i))$，其中 $\\text{logit}(p) = \\ln\\!\\left(\\frac{p}{1-p}\\right)$，并取斜率 $\\beta$ 的最大似然估计。\n\n使用以上定义和数据，计算：\n1. 该队列的Brier分数。\n2. 校准斜率 $\\beta$。\n\n然后，从临床角度简要解释这两个量在抑郁症复发风险预测中的意义，重点关注总体准确性以及模型的概率是过于极端还是过于保守。按顺序报告Brier分数和校准斜率的最终数值结果，每个结果均保留四位有效数字。无需单位。",
            "solution": "问题陈述被评估为具有科学依据、问题明确且客观。它提供了计算所要求数量的所有必要数据和定义。该问题是统计模型评估指标（Brier分数和校准斜率）在给定数据集上的标准应用。满足有效问题的所有条件。\n\n问题要求基于一个由 $n=10$ 名患者组成的队列的预测概率和观测结果，计算两个量：Brier分数和校准斜率。\n\n首先，我们计算Brier分数。Brier分数定义为预测概率 $p_i$ 与观测结果 $y_i$ 之间的均方误差。其公式为：\n$$ BS = \\frac{1}{n} \\sum_{i=1}^{n} (p_i - y_i)^2 $$\n数据以两组形式提供。\n对于患者 $1$ 到 $6$，预测概率为 $p_i = 0.20$。\n- 其中两名患者（$i=1, 3$）复发，因此他们的结果为 $y_i=1$。他们对平方误差和的贡献各为 $(0.20 - 1)^2 = (-0.80)^2 = 0.64$。\n- 其中四名患者（$i=2, 4, 5, 6$）未复发，因此他们的结果为 $y_i=0$。他们各自的贡献为 $(0.20 - 0)^2 = (0.20)^2 = 0.04$。\n第一组的总平方误差和为 $2 \\times 0.64 + 4 \\times 0.04 = 1.28 + 0.16 = 1.44$。\n\n对于患者 $7$ 到 $10$，预测概率为 $p_i = 0.65$。\n- 其中三名患者（$i=7, 8, 10$）复发，因此他们的结果为 $y_i=1$。他们各自的贡献为 $(0.65 - 1)^2 = (-0.35)^2 = 0.1225$。\n- 一名患者（$i=9$）未复发，因此她的结果为 $y_i=0$。她的贡献为 $(0.65 - 0)^2 = (0.65)^2 = 0.4225$。\n第二组的总平方误差和为 $3 \\times 0.1225 + 1 \\times 0.4225 = 0.3675 + 0.4225 = 0.79$。\n\n所有 $n=10$ 名患者的总平方误差和为 $1.44 + 0.79 = 2.23$。\nBrier分数是该和的平均值：\n$$ BS = \\frac{2.23}{10} = 0.223 $$\n保留四位有效数字，Brier分数为 $0.2230$。\n\n其次，我们计算校准斜率 $\\beta$。这是通过将结果 $y_i$ 对预测概率的对数优势比 $x_i = \\text{logit}(p_i) = \\ln\\left(\\frac{p_i}{1-p_i}\\right)$ 进行逻辑斯谛回归模型拟合得到的。该模型为 $\\Pr(y_i=1 \\mid x_i) = \\sigma(\\alpha + \\beta x_i)$，其中 $\\sigma(z) = (1+\\exp(-z))^{-1}$ 是 sigmoid 函数。\n\n数据可以根据预测变量 $x_i$ 的两个不同值聚合成两组。\nA组：$p_A = 0.20$。预测变量为 $x_A = \\text{logit}(0.20) = \\ln\\left(\\frac{0.20}{0.80}\\right) = \\ln(0.25) = -\\ln(4)$。该组有 $n_A=6$ 名患者，其中 $k_A=2$ 人复发。观测到的复发频率为 $f_A = k_A/n_A = 2/6 = 1/3$。\nB组：$p_B = 0.65$。预测变量为 $x_B = \\text{logit}(0.65) = \\ln\\left(\\frac{0.65}{0.35}\\right) = \\ln\\left(\\frac{13}{7}\\right)$。该组有 $n_B=4$ 名患者，其中 $k_B=3$ 人复发。观测到的复发频率为 $f_B = k_B/n_B = 3/4$。\n\n对于具有分类预测变量的逻辑斯谛回归，如果每个类别都包含两种结果（$0$ 和 $1$），则该模型是饱和的。每组概率的最大似然估计 $\\hat{\\pi}_A$ 和 $\\hat{\\pi}_B$ 等于观测频率。\n$$ \\hat{\\pi}_A = f_A = \\frac{1}{3} $$\n$$ \\hat{\\pi}_B = f_B = \\frac{3}{4} $$\n这些拟合概率必须满足逻辑斯谛模型方程：\n$$ \\text{logit}(\\hat{\\pi}_A) = \\alpha + \\beta x_A $$\n$$ \\text{logit}(\\hat{\\pi}_B) = \\alpha + \\beta x_B $$\n我们得到一个关于 $\\alpha$ 和 $\\beta$ 的二元线性方程组：\n1. $\\text{logit}(1/3) = \\ln\\left(\\frac{1/3}{2/3}\\right) = \\ln(1/2) = -\\ln(2) = \\alpha + \\beta (-\\ln(4))$\n2. $\\text{logit}(3/4) = \\ln\\left(\\frac{3/4}{1/4}\\right) = \\ln(3) = \\alpha + \\beta \\ln(13/7)$\n\n为了求出 $\\beta$，我们将第二个方程减去第一个方程：\n$$ \\ln(3) - (-\\ln(2)) = (\\alpha + \\beta \\ln(13/7)) - (\\alpha - \\beta \\ln(4)) $$\n$$ \\ln(3) + \\ln(2) = \\beta (\\ln(13/7) + \\ln(4)) $$\n$$ \\ln(6) = \\beta \\ln\\left(\\frac{13}{7} \\times 4\\right) $$\n$$ \\ln(6) = \\beta \\ln\\left(\\frac{52}{7}\\right) $$\n求解 $\\beta$：\n$$ \\beta = \\frac{\\ln(6)}{\\ln(52/7)} $$\n现在我们计算其数值：\n$$ \\beta \\approx \\frac{1.791759}{2.005318} \\approx 0.893504 $$\n保留四位有效数字，校准斜率为 $\\beta = 0.8935$。\n\n最后，我们解释这些结果。\n- Brier分数是衡量总体准确性的指标，值越低越好。$0.2230$ 的分数表明存在一定程度的预测误差。作为比较，一个总是预测队列中总体复发率（$\\bar{y} = 5/10 = 0.5$）的朴素模型，其Brier分数为 $\\frac{1}{10}[5 \\times (0.5-1)^2 + 5 \\times (0.5-0)^2] = 0.25$。该模型的分数 $0.2230$ 略好于这个朴素基准，表明它具有一定的预测价值，但价值有限。\n\n- 校准斜率评估模型的概率是否经过良好校准。一个完美校准的模型的斜率为 $\\beta=1$。\n  - 斜率 $\\beta > 1$ 意味着模型的概率过于保守（置信度不足）。\n  - 斜率 $\\beta  1$ 意味着模型的概率过于极端（过度自信）。\n我们计算出的斜率为 $\\beta=0.8935$，小于 $1$。这表明模型过度自信。其在对数优势比尺度上的预测分布范围（$\\Delta_{\\text{pred}} = \\text{logit}(0.65)-\\text{logit}(0.20) = \\ln(52/7) \\approx 2.005$）比在相同尺度上观测结果的分布范围（$\\Delta_{\\text{obs}} = \\text{logit}(3/4)-\\text{logit}(1/3) = \\ln(6) \\approx 1.792$）更宽。这意味着模型夸大了两组之间的风险差异。尽管原始概率（$0.20$ 和 $0.65$）相对于观测频率（$1/3 \\approx 0.33$ 和 $3/4 = 0.75$）可能显得保守，但斜率参数 $\\beta1$ 表明，在logit尺度上，预测过于极端，需要向其均值“收缩”才能得到更好的校准。\n\n最终数值结果是Brier分数 $0.2230$ 和校准斜率 $0.8935$。",
            "answer": "$$\n\\boxed{\\begin{pmatrix} 0.2230  0.8935 \\end{pmatrix}}\n$$"
        },
        {
            "introduction": "许多强大的人工智能模型，如梯度提升机或深度神经网络，常被批评为“黑箱”。为了在精神病学这样的高风险领域负责任地部署它们，我们必须能够理解它们为何做出特定的预测。这项基于编程的练习将指导您从头开始实现两种强大的、模型无关的可解释性技术：置换特征重要性（Permutation Feature Importance, PFI）和部分依赖图（Partial Dependence Plots, PDP）。\n\n这项动手练习  揭示了如何探查一个复杂模型，以确定哪些临床特征最具影响力，以及模型的风险预测如何随着特定特征值的变化而变化。这些技能对于验证模型的临床合理性、识别潜在偏见以及在临床医生和患者之间建立信任是不可或缺的。",
            "id": "4690017",
            "problem": "您将处理一个精神病学领域的二元分类任务：使用训练好的梯度提升集成模型，通过临床特征预测近期的躁狂症发作。您的目标是，从第一性原理出发，为两个具有临床显著性的特征实现排列特征重要性（Permutation Feature Importance, PFI）的计算，并为这两个特征实现一维部分依赖图（Partial Dependence Plot, PDP）。您必须使用二元概率预测、用于概率的逻辑斯蒂链接函数、用于期望的经验均值、作为条件独立性度量的排列，以及梯度提升模型的加法形式等定义。\n\n背景与基本原理：\n- 梯度提升分类器可以表示为对数几率（logit）尺度上的一个加法模型：对于一个特征向量 $\\mathbf{x} \\in \\mathbb{R}^d$，其对数几率为 $F(\\mathbf{x}) = b_0 + \\sum_{m=1}^{M} \\nu \\, T_m(\\mathbf{x})$，其中 $b_0$ 是截距，$\\nu$ 是学习率，$T_m$ 是第 $m$ 棵回归树，它为 $\\mathbf{x}$ 输出一个实数值的叶节点分数。\n- 躁狂症的预测概率由逻辑斯蒂链接函数给出：$p(\\mathbf{x}) = \\sigma(F(\\mathbf{x})) = \\frac{1}{1 + e^{-F(\\mathbf{x})}}$，该函数将任何实数值的对数几率映射到 $(0,1)$ 区间内的一个值。\n- 对于一个数据集 $\\{(\\mathbf{x}_i, y_i)\\}_{i=1}^N$（其中 $y_i \\in \\{0,1\\}$），其经验平均交叉熵（对数损失）为 $\\frac{1}{N}\\sum_{i=1}^N \\left[-y_i \\log p(\\mathbf{x}_i) - (1 - y_i) \\log \\left(1 - p(\\mathbf{x}_i)\\right)\\right]$，它在给定预测概率 $p(\\mathbf{x}_i)$ 的情况下衡量预测性能。\n- 特征j的排列特征重要性（PFI）定义为：当特征j的值在样本间被随机排列时，损失的期望增加量。这种排列会破坏该特征与目标之间的关联，同时保持其边际分布。形式上，令 $\\pi$ 表示对 $\\{1,\\dots,N\\}$ 的一个随机排列，$\\mathbf{x}_i^{(j \\leftarrow x_{\\pi(i),j})}$ 表示将 $\\mathbf{x}_i$ 的第j个特征替换为排列后的值 $x_{\\pi(i),j}$，则PFI为 $I_j = \\mathbb{E}_\\pi\\left[\\frac{1}{N}\\sum_{i=1}^N \\ell\\left(y_i, p\\left(\\mathbf{x}_i^{(j \\leftarrow x_{\\pi(i),j})}\\right)\\right)\\right] - \\frac{1}{N}\\sum_{i=1}^N \\ell\\left(y_i, p(\\mathbf{x}_i)\\right)$，其中 $\\ell$ 是对数损失。您将通过对多次独立排列进行平均来经验性地近似这个期望值。\n- 特征j的一维部分依赖图（PDP）在值v处的定义为 $PD_j(v) = \\mathbb{E}_{\\mathbf{X}_{-j}}\\left[p\\left(v, \\mathbf{X}_{-j}\\right)\\right]$，这可以通过数据集上的经验平均来估计：$PD_j(v) \\approx \\frac{1}{N}\\sum_{i=1}^N p\\left(\\mathbf{x}_i^{(j \\leftarrow v)}\\right)$。\n\n模型、特征与数据：\n- 特征顺序固定如下：\n  - 索引0：睡眠时长（单位：小时），记为 $x_0$。\n  - 索引1：药物依從性，表示为 $[0,1]$ 内的小数，记为 $x_1$。\n  - 索引2：年龄（单位：岁），记为 $x_2$。\n  - 索引3：先前躁狂发作次数，记为 $x_3$。\n  - 索引4：共病评分（非负整数），记为 $x_4$。\n- 训练好的梯度提升模型参数如下：\n  - 截距 $b_0 = -0.3$。\n  - 学习率 $\\nu = 0.25$。\n  - 决策树数量 $M = 3$，每棵树由轴对齐的分割和叶节点定义如下（所有分割都遵循“若 $x_j  \\tau$ 则走向左侧，否则走向右侧”的形式）：\n    - 树 1：\n      - 节点0：对特征0以阈值6.5进行分割，左子节点为1，右子节点为2。\n      - 节点1：对特征1以阈值0.6进行分割，左叶节点值为+0.8，右叶节点值为+0.3。\n      - 节点2：对特征3以阈值2.5进行分割，左叶节点值为-0.2，右叶节点值为+0.4。\n    - 树 2：\n      - 节点0：对特征1以阈值0.4进行分割，左叶节点值为+0.5，右子节点为1。\n      - 节点1：对特征0以阈值7.5进行分割，左叶节点值为+0.2，右叶节点值为-0.3。\n    - 树 3：\n      - 节点0：对特征4以阈值3.5进行分割，左叶节点值为-0.1，右子节点为1。\n      - 节点1：对特征0以阈值5.5进行分割，左叶节点值为+0.6，右叶节点值为+0.0。\n  - 集成模型在对数几率尺度上的输出为 $F(\\mathbf{x}) = b_0 + \\nu \\sum_{m=1}^{3} T_m(\\mathbf{x})$，概率为 $p(\\mathbf{x}) = \\sigma(F(\\mathbf{x}))$。\n- 数据集 $\\{(\\mathbf{x}_i, y_i)\\}_{i=1}^{12}$：\n  - 行 0: $(x_0, x_1, x_2, x_3, x_4, y) = (4.5, 0.2, 24, 3, 5, 1)$。\n  - 行 1: $(5.0, 0.3, 31, 1, 2, 1)$。\n  - 行 2: $(6.0, 0.7, 40, 0, 1, 0)$。\n  - 行 3: $(7.0, 0.9, 52, 0, 0, 0)$。\n  - 行 4: $(8.0, 0.8, 45, 2, 4, 0)$。\n  - 行 5: $(5.5, 0.5, 28, 2, 3, 1)$。\n  - 行 6: $(9.0, 0.4, 36, 1, 2, 0)$。\n  - 行 7: $(6.5, 0.6, 33, 3, 6, 1)$。\n  - 行 8: $(4.0, 0.9, 29, 4, 5, 1)$。\n  - 行 9: $(7.5, 0.2, 50, 0, 1, 0)$。\n  - 行 10: $(6.0, 0.3, 42, 2, 2, 1)$。\n  - 行 11: $(8.5, 1.0, 60, 0, 0, 0)$。\n\n任务：\n1. 精确实现指定的模型 $F(\\mathbf{x})$ 和 $p(\\mathbf{x})$。使用上文定义的经验平均交叉熵（对数损失）。对于边界处的概率 $p(\\mathbf{x})$，应用数值裁剪以确保其严格位于 $(0,1)$ 区间内。\n2. 计算数据集上的基线平均对数损失。\n3. 计算以下特征的排列特征重要性（PFI）：\n   - 特征索引0（睡眠时长，单位：小时）。\n   - 特征索引1（药物依从性，小数表示）。\n   对于给定的独立排列重复次数 $R$ 和随机种子 $s$，通过对 $R$ 次独立随机排列（使用指定的种子以保证可复现性）的平均对数损失进行平均来近似期望值，然后减去基线平均对数损失。将PFI报告为非负浮点数（如果数值噪声产生一个微小的负值，则按原样保留四舍五入后的值）。\n4. 计算以下特征的一维部分依赖图（PDP）估计值：\n   - 特征索引0，在网格值 $[5.0, 6.5, 8.0]$ 小时处进行评估。\n   - 特征索引1，在网格值 $[0.2, 0.6, 0.9]$（小数）处进行评估。\n   对于每个网格值 $v$，通过将所有样本的该特征替换为 $v$ 来构造修改后的输入，为每个样本评估 $p(\\mathbf{x})$，然后在所有样本上取平均以估计 $PD_j(v)$。\n\n测试套件：\n- 您必须针对以下三种情况进行计算，每种情况由一对 $(R, s)$ 定义，其中 $R$ 是排列重复次数，$s$ 是随机种子：\n  - 情况 1: $(R, s) = (1, 11)$。\n  - 情况 2: $(R, s) = (7, 123)$。\n  - 情况 3: $(R, s) = (25, 9871)$。\n- 对于每种情况，生成一个包含以下内容的结果列表：\n  - 基线平均对数损失（浮点数）。\n  - 睡眠时长的PFI（浮点数）。\n  - 药物依从性的PFI（浮点数）。\n  - 睡眠时长在 $[5.0, 6.5, 8.0]$ 处的PDP值（浮点数列表）。\n  - 药物依从性在 $[0.2, 0.6, 0.9]$ 处的PDP值（浮点数列表）。\n- 所有浮点数必须四舍五入到 $6$ 位小数。输出中不含物理单位；概率和损失是无量纲的，药物依从性是一个小数。\n\n最终输出格式：\n- 您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表形式的结果，每个元素对应于上述顺序的一个情况。每种情况本身必须是所描述的五个项目的列表。例如，整体输出必须具有以下形式：\n  \"[[baseline,PFI_sleep,PFI_adherence,[PD_sleep_values],[PD_adherence_values]],[...case2...],[...case3...]]\"\n所有数值都四舍五入到 $6$ 位小数，不含多余的空格或文本。",
            "solution": "用户要求为一个指定的梯度提升模型实现排列特征重要性（PFI）和部分依赖图（PDP）。此任务涉及一系列步骤，从模型实现到应用这些可解释性技术，最终为三个不同的测试用例输出格式化的结果。整个过程基于机器学习的基本原理。\n\n首先，我们必须形式化预测模型。梯度提升分类器是一个由 $M=3$ 棵回归树组成的加法集成模型。对于一个给定的特征向量 $\\mathbf{x} \\in \\mathbb{R}^5$，模型在对数几率（logit）尺度上的输出由下式给出：\n$$F(\\mathbf{x}) = b_0 + \\nu \\sum_{m=1}^{M} T_m(\\mathbf{x})$$\n其中截距为 $b_0 = -0.3$，学习率为 $\\nu = 0.25$，$T_m(\\mathbf{x})$ 是第 $m$ 棵树的实数值输出。每棵树的决策规则都明确定义为轴对齐的分割，形式为“$x_j  \\tau$”。\n\n各个树函数的实现如下：\n-   $T_1(\\mathbf{x})$:\n    - 若 $x_0  6.5$：如果 $x_1  0.6$，输出为 $0.8$；否则输出为 $0.3$。\n    - 若 $x_0 \\geq 6.5$：如果 $x_3  2.5$，输出为 $-0.2$；否则输出为 $0.4$。\n-   $T_2(\\mathbf{x})$:\n    - 若 $x_1  0.4$：输出为 $0.5$。\n    - 若 $x_1 \\geq 0.4$：如果 $x_0  7.5$，输出为 $0.2$；否则输出为 $-0.3$。\n-   $T_3(\\mathbf{x})$:\n    - 若 $x_4  3.5$：输出为 $-0.1$。\n    - 若 $x_4 \\geq 3.5$：如果 $x_0  5.5$，输出为 $0.6$；否则输出为 $0.0$。\n\n躁狂症的预测概率 $p(\\mathbf{x})$ 是通过将逻辑斯蒂（sigmoid）函数 $\\sigma(\\cdot)$ 应用于对数几率输出来获得的：\n$$p(\\mathbf{x}) = \\sigma(F(\\mathbf{x})) = \\frac{1}{1 + e^{-F(\\mathbf{x})}}$$\n该函数将实数值的对数几率 $F(\\mathbf{x})$ 映射到区间 $(0, 1)$ 内，表示一个概率。\n\n为了评估模型性能，我们使用二元交叉熵，也称为对数损失。对于单个观测值 $(\\mathbf{x}_i, y_i)$，其中 $y_i \\in \\{0, 1\\}$ 是真实标签，损失为：\n$$\\ell(y_i, p(\\mathbf{x}_i)) = -y_i \\log(p(\\mathbf{x}_i)) - (1 - y_i) \\log(1 - p(\\mathbf{x}_i))$$\n为确保当 $p(\\mathbf{x}_i)$ 接近 $0$ 或 $1$ 时的数值稳定性，在传递给对数函数之前，会将概率值裁剪到一个小的区间 $[\\epsilon, 1-\\epsilon]$ 内（例如，对于一个小的 $\\epsilon  0$，如 $10^{-15}$）。模型在数据集 $\\{(\\mathbf{x}_i, y_i)\\}_{i=1}^N$ 上的总体性能是经验平均对数损失，它作为我们的基线损失。\n\n定义好模型和损失函数后，我们可以继续进行可解释性计算。\n\n**排列特征重要性（PFI）**衡量的是在某个特征的值被随机排列后模型误差的增加量。这个过程打破了该特征与目标变量之间的关系。对于特征 $j$，PFI 的计算如下：\n1.  计算原始数据集上的基线损失 $L_{base} = \\frac{1}{N}\\sum_{i=1}^N \\ell(y_i, p(\\mathbf{x}_i))$。\n2.  对于 $R$ 次重复：\n    a.  生成样本索引 $\\{1, \\dots, N\\}$ 的一个随机排列 $\\pi$。\n    b.  创建一个新数据集，其中第 $j$ 个特征列根据 $\\pi$进行排列。也就是说，对于每个样本 $i$，新的特征向量是 $\\mathbf{x}_i' = \\mathbf{x}_i^{(j \\leftarrow x_{\\pi(i),j})}$。\n    c.  计算这个新数据集上的平均对数损失 $L_{permuted}$。\n3.  对所有 $R$ 次重复的排列损失取平均，得到 $\\bar{L}_{permuted}$。\n4.  特征 $j$ 的PFI是两者之差：$I_j = \\bar{L}_{permuted} - L_{base}$。\n较高的PFI值表明模型在进行预测时更依赖该特征。随机种子 $s$ 确保排列在不同运行中是可复现的。\n\n**部分依赖图（PDP）**显示了单个特征对机器学习模型预测结果的边际效应。对于特征 $j$ 和感兴趣网格中的特定值 $v$，PDP值的估计方法如下：\n1.  通过将特征 $j$ 的整个列替换为常数值 $v$ 来创建一个修改后的数据集。对于每个原始样本 $\\mathbf{x}_i$，我们构造 $\\mathbf{x}_i' = \\mathbf{x}_i^{(j \\leftarrow v)}$。\n2.  对于每个修改后的样本 $\\mathbf{x}_i'$，计算模型的预测概率 $p(\\mathbf{x}_i')$。\n3.  PDP值是这些概率在数据集中所有 $N$ 个样本上的平均值：\n$$PD_j(v) \\approx \\frac{1}{N}\\sum_{i=1}^N p\\left(\\mathbf{x}_i^{(j \\leftarrow v)}\\right)$$\n对该特征指定网格中的每个值重复此过程，从而得到一组点，这些点可以绘制出来以可视化特征的影响。\n\n最终的算法流程是，首先将数据集和模型参数定义为常量。然后遍历三个指定的测试用例 $(R, s)$。在每次迭代中，计算基线损失，然后计算睡眠时长（$j=0$）和药物依从性（$j=1$）的PFI，最后计算这两个特征在各自网格上的PDP值。所有浮点结果在格式化为最终要求的字符串输出之前，都四舍五入到六位小数。",
            "answer": "```python\nimport numpy as np\nfrom typing import List, Tuple, Dict, Any\n\ndef solve():\n    \"\"\"\n    Main function to perform all calculations for the problem statement.\n    \"\"\"\n    # Define model, data, and problem parameters\n    b0 = -0.3\n    nu = 0.25\n    \n    data = np.array([\n        [4.5, 0.2, 24, 3, 5, 1],\n        [5.0, 0.3, 31, 1, 2, 1],\n        [6.0, 0.7, 40, 0, 1, 0],\n        [7.0, 0.9, 52, 0, 0, 0],\n        [8.0, 0.8, 45, 2, 4, 0],\n        [5.5, 0.5, 28, 2, 3, 1],\n        [9.0, 0.4, 36, 1, 2, 0],\n        [6.5, 0.6, 33, 3, 6, 1],\n        [4.0, 0.9, 29, 4, 5, 1],\n        [7.5, 0.2, 50, 0, 1, 0],\n        [6.0, 0.3, 42, 2, 2, 1],\n        [8.5, 1.0, 60, 0, 0, 0]\n    ])\n    X = data[:, :-1]\n    y = data[:, -1]\n    N = X.shape[0]\n    epsilon = 1e-15\n\n    pdp_grids = {\n        0: [5.0, 6.5, 8.0],\n        1: [0.2, 0.6, 0.9]\n    }\n\n    test_cases = [\n        (1, 11),\n        (7, 123),\n        (25, 9871)\n    ]\n    \n    # Helper functions for the model and calculations\n    def _T1(x: np.ndarray) -> float:\n        if x[0]  6.5:\n            return 0.8 if x[1]  0.6 else 0.3\n        else:\n            return -0.2 if x[3]  2.5 else 0.4\n\n    def _T2(x: np.ndarray) -> float:\n        if x[1]  0.4:\n            return 0.5\n        else:\n            return 0.2 if x[0]  7.5 else -0.3\n\n    def _T3(x: np.ndarray) -> float:\n        if x[4]  3.5:\n            return -0.1\n        else:\n            return 0.6 if x[0]  5.5 else 0.0\n\n    def get_prediction(x: np.ndarray) -> float:\n        tree_sum = _T1(x) + _T2(x) + _T3(x)\n        logit = b0 + nu * tree_sum\n        return 1.0 / (1.0 + np.exp(-logit))\n\n    def get_log_loss(y_true: float, p_pred: float) -> float:\n        p_clipped = np.clip(p_pred, epsilon, 1 - epsilon)\n        return -y_true * np.log(p_clipped) - (1 - y_true) * np.log(1 - p_clipped)\n\n    # Main loop for test cases\n    all_results = []\n    for R, s in test_cases:\n        # 1. Calculate baseline loss\n        base_predictions = np.array([get_prediction(row) for row in X])\n        base_losses = np.array([get_log_loss(y[i], base_predictions[i]) for i in range(N)])\n        baseline_loss = np.mean(base_losses)\n        \n        # 2. Calculate PFI for features 0 and 1\n        pfi_results = {}\n        for feature_idx in [0, 1]:\n            rng = np.random.default_rng(seed=s)\n            permuted_losses = []\n            for _ in range(R):\n                X_permuted = X.copy()\n                permuted_indices = rng.permutation(N)\n                X_permuted[:, feature_idx] = X[permuted_indices, feature_idx]\n                \n                perm_predictions = np.array([get_prediction(row) for row in X_permuted])\n                perm_losses = np.array([get_log_loss(y[i], perm_predictions[i]) for i in range(N)])\n                permuted_losses.append(np.mean(perm_losses))\n            \n            mean_permuted_loss = np.mean(permuted_losses)\n            pfi = mean_permuted_loss - baseline_loss\n            pfi_results[feature_idx] = pfi\n\n        # 3. Calculate PDP for features 0 and 1\n        pdp_results = {}\n        for feature_idx in [0, 1]:\n            grid = pdp_grids[feature_idx]\n            pdp_values = []\n            for value in grid:\n                X_modified = X.copy()\n                X_modified[:, feature_idx] = value\n                \n                mod_predictions = np.array([get_prediction(row) for row in X_modified])\n                pdp_values.append(np.mean(mod_predictions))\n            pdp_results[feature_idx] = pdp_values\n\n        # 4. Assemble and round the results for the current case\n        case_result = [\n            round(baseline_loss, 6),\n            round(pfi_results[0], 6),\n            round(pfi_results[1], 6),\n            [round(v, 6) for v in pdp_results[0]],\n            [round(v, 6) for v in pdp_results[1]]\n        ]\n        all_results.append(case_result)\n        \n    # 5. Format the final output string\n    def format_list(lst):\n        return f\"[{','.join(map(str, lst))}]\"\n\n    case_strings = []\n    for case_res in all_results:\n        bl, pfi0, pfi1, pdp0, pdp1 = case_res\n        case_str = f\"[{bl},{pfi0},{pfi1},{format_list(pdp0)},{format_list(pdp1)}]\"\n        case_strings.append(case_str)\n        \n    final_output = f\"[{','.join(case_strings)}]\"\n    print(final_output)\n\nsolve()\n```"
        }
    ]
}