{
    "hands_on_practices": [
        {
            "introduction": "神经可塑性不仅体现在现有突触强度的功能性变化上，还包括突触的物理生成与消除，即结构可塑性。树突棘的周转是结构可塑性的一个核心方面，它对学习、记忆和精神疾病的病理生理过程至关重要。本练习将运用随机过程中的“生灭过程”模型，来描述树突棘群体的动态平衡。通过推导，你将理解在持续的形成和修剪过程中，树突棘密度如何达到一个稳态，这为了解大脑结构在微观尺度上的动态稳定性提供了数学基础。",
            "id": "4732886",
            "problem": "在与精神病学中的神经可塑性相关的树突棘周转背景下，将皮层锥体神经元顶端树突段上的树突棘群体建模为连续时间生灭过程。设 $N(t)$ 表示长度为 $L$ 的树突段上在时间 $t$ 的棘数量。假设：\n\n1. 棘形成事件是独立的，并作为一个泊松过程发生，其恒定风险率与树突段长度成正比，速率为 $\\lambda L$（单位：棘 $\\mu\\mathrm{m}^{-1}\\,\\mathrm{day}^{-1}$ 乘以 $\\mu\\mathrm{m}$ 得到 棘 $\\mathrm{day}^{-1}$）。\n2. 棘修剪事件独立地影响每个现有的棘，每个棘带有单个风险率 $\\mu$（单位：$\\mathrm{day}^{-1}$），因此当有 $n$ 个棘时，总修剪速率为 $\\mu n$。\n3. 该过程满足马尔可夫性质并且是时间齐次的。\n\n从连续时间马尔可夫生灭过程的基本定义和关于概率 $P(N(t)=n)$ 的柯尔莫哥洛夫前向（主）方程出发，推导控制平均棘数量 $\\bar{N}(t) = \\mathbb{E}[N(t)]$ 时间演化的常微分方程。利用此方程，以 $\\lambda$ 和 $\\mu$ 的形式，求得稳态平均棘密度 $\\rho^{*} = \\lim_{t\\to\\infty} \\bar{N}(t)/L$ 的解析表达式。\n\n然后，对于长度为 $L = 200\\,\\mu\\mathrm{m}$ 的树突段，形成速率为 $\\lambda = 0.028$ 棘 $\\mu\\mathrm{m}^{-1}\\,\\mathrm{day}^{-1}$，每个棘的修剪速率为 $\\mu = 0.019\\,\\mathrm{day}^{-1}$ 的情况，数值计算 $\\rho^{*}$。将最终数值答案四舍五入到四位有效数字。以每微米棘数为单位表示最终的棘密度。",
            "solution": "首先验证问题陈述，以确保其科学基础扎实、提法恰当、客观且内容完整。\n\n### 第1步：提取给定条件\n-   **模型**：树突段上树突棘数量 $N(t)$ 的连续时间生灭过程。\n-   **变量**：$N(t)$ 是时间 $t$ 时的棘数量。\n-   **参数**：$L$ 是树突段的长度。\n-   **出生率（棘形成）**：对所有 $n \\geq 0$，$\\lambda_n = \\lambda L$。形成过程是一个速率恒定的泊松过程，与当前的棘数量 $n$ 无关。\n-   **死亡率（棘修剪）**：对所有 $n \\geq 1$，$\\mu_n = \\mu n$，且 $\\mu_0 = 0$。$n$ 个现有棘中的每一个都有一个独立的修剪风险率 $\\mu$。\n-   **假设**：该过程是一个时间齐次的连续时间马尔可夫过程。\n-   **目标1**：推导平均棘数量 $\\bar{N}(t) = \\mathbb{E}[N(t)]$ 的常微分方程(ODE)。\n-   **目标2**：找到稳态平均棘密度 $\\rho^{*} = \\lim_{t\\to\\infty} \\bar{N}(t)/L$ 的解析表达式。\n-   **目标3**：根据给定参数数值计算 $\\rho^{*}$：\n    -   $L = 200\\,\\mu\\mathrm{m}$\n    -   $\\lambda = 0.028$ 棘 $\\mu\\mathrm{m}^{-1}\\,\\mathrm{day}^{-1}$\n    -   $\\mu = 0.019\\,\\mathrm{day}^{-1}$\n-   **取整说明**：最终数值答案应四舍五入到四位有效数字。\n\n### 第2步：使用提取的给定条件进行验证\n-   **科学基础**：该问题使用了一个标准且公认的数学模型（生灭过程，具体来说是M/M/$\\infty$排队模型）来描述一个被深入研究的生物现象（树突棘周转）。这是计算神经科学中的一种常用方法，并且在科学上是有效的。\n-   **提法恰当**：问题陈述清晰，包含了所有必要的参数和假设。出生率和死亡率都有定义，确保了平均值及其稳态存在唯一且稳定的解。\n-   **客观性**：问题是用精确的、定量的语言表述的，没有主观性。\n-   **一致性与完整性**：所给单位是一致的：$\\lambda L$ 的单位是 $(\\text{棘}\\,\\mu\\mathrm{m}^{-1}\\,\\mathrm{day}^{-1}) \\times \\mu\\mathrm{m} = \\text{棘}\\,\\mathrm{day}^{-1}$，这是一个速率。修剪速率 $\\mu n$ 的单位是 $\\mathrm{day}^{-1} \\times \\text{棘} = \\text{棘}\\,\\mathrm{day}^{-1}$。推导和计算所需的所有信息都已给出。\n\n### 第3步：结论与行动\n问题是有效的。现在开始解题过程。\n\n### 解题推导\n\n该过程是一个连续时间马尔可夫生灭过程，状态 $n$ 代表棘的数量。设 $P_n(t) = P(N(t)=n)$ 是在时间 $t$ 有 $n$ 个棘的概率。这些概率的时间演化由柯尔莫哥洛夫前向方程（也称为主方程）控制：\n$$ \\frac{d P_n(t)}{dt} = \\lambda_{n-1} P_{n-1}(t) + \\mu_{n+1} P_{n+1}(t) - (\\lambda_n + \\mu_n) P_n(t), \\quad \\text{for } n \\ge 1 $$\n$$ \\frac{d P_0(t)}{dt} = \\mu_1 P_1(t) - \\lambda_0 P_0(t) $$\n使用给定的出生率和死亡率 $\\lambda_n = \\lambda L$ 和 $\\mu_n = \\mu n$：\n$$ \\frac{d P_n(t)}{dt} = \\lambda L P_{n-1}(t) + \\mu (n+1) P_{n+1}(t) - (\\lambda L + \\mu n) P_n(t), \\quad \\text{for } n \\ge 1 $$\n$$ \\frac{d P_0(t)}{dt} = \\mu P_1(t) - \\lambda L P_0(t) $$\n\n主要目标是找到平均棘数量 $\\bar{N}(t) = \\mathbb{E}[N(t)] = \\sum_{n=0}^{\\infty} n P_n(t)$ 的常微分方程。我们对 $\\bar{N}(t)$ 关于时间求导：\n$$ \\frac{d\\bar{N}(t)}{dt} = \\frac{d}{dt} \\sum_{n=0}^{\\infty} n P_n(t) = \\sum_{n=0}^{\\infty} n \\frac{dP_n(t)}{dt} $$\n对于生灭过程，一个普遍的结论是，平均值的变化率等于期望出生率与期望死亡率之差：\n$$ \\frac{d\\bar{N}(t)}{dt} = \\mathbb{E}[\\lambda_{N(t)}] - \\mathbb{E}[\\mu_{N(t)}] $$\n我们计算这个特定问题的期望速率：\n期望出生率为：\n$$ \\mathbb{E}[\\lambda_{N(t)}] = \\mathbb{E}[\\lambda L] = \\sum_{n=0}^{\\infty} (\\lambda L) P_n(t) = \\lambda L \\sum_{n=0}^{\\infty} P_n(t) $$\n由于所有概率之和为 $1$，这可以简化为：\n$$ \\mathbb{E}[\\lambda_{N(t)}] = \\lambda L $$\n期望死亡率为：\n$$ \\mathbb{E}[\\mu_{N(t)}] = \\mathbb{E}[\\mu N(t)] = \\sum_{n=0}^{\\infty} (\\mu n) P_n(t) = \\mu \\sum_{n=0}^{\\infty} n P_n(t) $$\n根据定义，$\\sum_{n=0}^{\\infty} n P_n(t) = \\bar{N}(t)$。因此：\n$$ \\mathbb{E}[\\mu_{N(t)}] = \\mu \\bar{N}(t) $$\n将这些期望速率代入平均值时间演化的一般方程中，我们得到 $\\bar{N}(t)$ 的常微分方程：\n$$ \\frac{d\\bar{N}(t)}{dt} = \\lambda L - \\mu \\bar{N}(t) $$\n这就是所求的控制平均棘数量的常微分方程。\n\n接下来，我们确定稳态平均棘数量 $\\bar{N}^* = \\lim_{t\\to\\infty} \\bar{N}(t)$。在稳态下，平均数量不再变化，所以 $\\frac{d\\bar{N}(t)}{dt} = 0$。将常微分方程的左侧设为零：\n$$ 0 = \\lambda L - \\mu \\bar{N}^* $$\n求解 $\\bar{N}^*$：\n$$ \\mu \\bar{N}^* = \\lambda L $$\n$$ \\bar{N}^* = \\frac{\\lambda L}{\\mu} $$\n问题要求的是稳态平均棘密度 $\\rho^{*}$，其定义为 $\\rho^{*} = \\bar{N}^*/L$。代入 $\\bar{N}^*$ 的表达式：\n$$ \\rho^{*} = \\frac{1}{L} \\left( \\frac{\\lambda L}{\\mu} \\right) = \\frac{\\lambda}{\\mu} $$\n这就是稳态平均棘密度的解析表达式。正如预期的那样，该密度与树突段长度 $L$ 无关，是棘周转动力学的一个内在属性。\n\n最后，我们使用提供的参数值数值计算 $\\rho^{*}$：\n-   $\\lambda = 0.028$ 棘 $\\mu\\mathrm{m}^{-1}\\,\\mathrm{day}^{-1}$\n-   $\\mu = 0.019\\,\\mathrm{day}^{-1}$\n计算此值不需要长度 $L = 200\\,\\mu\\mathrm{m}$。\n$$ \\rho^{*} = \\frac{0.028}{0.019} \\approx 1.4736842... \\text{ 棘 } \\mu\\mathrm{m}^{-1} $$\n按要求将结果四舍五入到四位有效数字：\n$$ \\rho^{*} \\approx 1.474 \\text{ 棘 } \\mu\\mathrm{m}^{-1} $$",
            "answer": "$$\n\\boxed{1.474}\n$$"
        },
        {
            "introduction": "理解神经可塑性的最终目标之一，是揭示细胞层面的机制如何涌现为复杂的认知功能及其障碍。这个综合性练习将作为本章的顶点项目，要求你构建一个功能性的神经回路计算模型。通过这个模拟，你将亲手探索成人神经发生（表现为具有高度可塑性的未成熟神经元）在记忆编码和干扰中所扮演的角色，这是一个与抑郁症等精神疾病中认知功能改变密切相关的前沿课题。这个练习将理论、建模与编程实践融为一体，是连接微观机制与宏观功能的桥梁。",
            "id": "4732943",
            "problem": "您的任务是设计并实现一个可复现的模拟，用于定量评估在 leaky integrate-and-fire（漏放电）网络中，添加具有增强突触可塑性的未成熟颗粒细胞如何影响记忆干扰。该模拟需要能捕捉与精神病学相关的核心神经可塑性机制。模拟必须基于以下第一性原理。\n\n从标准的漏放电神经元模型开始。每个输出神经元的阈下膜电位动态由以下公式建模：\n$$\n\\frac{dV_j(t)}{dt} = -\\frac{V_j(t) - V_{\\mathrm{rest}}}{\\tau_m} + G \\cdot I_{\\mathrm{syn},j}(t),\n$$\n其中，$V_j(t)$ 是输出神经元 $j$ 在时间 $t$ 的膜电位，$V_{\\mathrm{rest}}$ 是静息电位，$\\tau_m$ 是膜时间常数，$G$ 是将突触电流转换为电压的增益因子，$I_{\\mathrm{syn},j}(t)$ 是突触电流。当 $V_j(t)$ 超过阈值 $V_{\\mathrm{th},j}$ 时，会发出一个脉冲；脉冲后，$V_j(t)$ 被设置为 $V_{\\mathrm{reset}}$ 并维持一个不应期。所有时间量必须以毫秒 (ms) 表示，膜电位以毫伏 (mV) 表示。\n\n突触电流是突触前脉冲的标准滤波器：\n$$\nI_{\\mathrm{syn},j}(t) = \\sum_{i=1}^{M} w_{ji} \\, x_i(t),\n$$\n其中，$M$ 是输入单元的数量，$w_{ji}$ 是从输入单元 $i$ 到输出神经元 $j$ 的突触权重，$x_i(t)$ 是突触前单元 $i$ 的突触轨迹，遵循：\n$$\n\\frac{dx_i(t)}{dt} = -\\frac{x_i(t)}{\\tau_{\\mathrm{syn}}} + s_i(t),\n$$\n其中 $s_i(t)\\in\\{0,1\\}$ 表示在时间步 $t$ 的突触前脉冲序列，$\\tau_{\\mathrm{syn}}$ 是突触时间常数。\n\n突触可塑性必须使用基于配对的脉冲时间依赖可塑性 (Spike-Timing Dependent Plasticity, STDP) 来实现，这是一种经过充分检验的学习规则。对突触前和突触后活动使用指数衰减的资格迹 (eligibility traces)：\n$$\n\\frac{dE^{\\mathrm{pre}}_i(t)}{dt} = -\\frac{E^{\\mathrm{pre}}_i(t)}{\\tau_+} + s_i(t), \\quad\n\\frac{dE^{\\mathrm{post}}_j(t)}{dt} = -\\frac{E^{\\mathrm{post}}_j(t)}{\\tau_-} + s^{\\mathrm{post}}_j(t),\n$$\n其中 $s^{\\mathrm{post}}_j(t)\\in\\{0,1\\}$ 表示神经元 $j$ 在时间步 $t$ 的一个脉冲，$\\tau_+$ 和 $\\tau_-$ 分别是长时程增强和长时程抑制的时间常数。在一个呈现窗口内的权重更新为：\n$$\n\\Delta w_{ji} = A^{(+)}_j \\sum_t s^{\\mathrm{post}}_j(t) \\, E^{\\mathrm{pre}}_i(t) \\;-\\; A^{(-)}_j \\sum_t E^{\\mathrm{post}}_j(t) \\, s_i(t),\n$$\n其中 $A^{(+)}_j$ 和 $A^{(-)}_j$ 分别是神经元 $j$ 的长时程增强 (LTP) 和长时程抑制 (LTD) 幅度。突触权重是非负且有界的：\n$$\nw_{ji} \\leftarrow \\min\\left\\{\\max\\{w_{ji} + \\Delta w_{ji} - \\lambda w_{ji},\\, 0\\},\\, w_{\\max}\\right\\},\n$$\n其中 $\\lambda$ 是一个小的衰减项，$w_{\\max}$ 是最大权重。\n\n将未成熟颗粒细胞定义为与成熟颗粒细胞相比，具有更高可塑性和更低脉冲阈值的输出神经元。具体来说，对于未成熟神经元 $j$，设置：\n$$\nA^{(+)}_j = \\gamma \\, A^{(+)}_{\\mathrm{base}},\\quad A^{(-)}_j = \\gamma \\, A^{(-)}_{\\mathrm{base}},\\quad V_{\\mathrm{th},j} = V_{\\mathrm{th},\\mathrm{imm}},\n$$\n对于成熟神经元 $j$，设置：\n$$\nA^{(+)}_j = A^{(+)}_{\\mathrm{base}},\\quad A^{(-)}_j = A^{(-)}_{\\mathrm{base}},\\quad V_{\\mathrm{th},j} = V_{\\mathrm{th},\\mathrm{mat}}.\n$$\n此处 $\\gamma1$ 是未成熟神经元的可塑性缩放因子，$A^{(+)}_{\\mathrm{base}}$ 和 $A^{(-)}_{\\mathrm{base}}$ 是基础幅度，$V_{\\mathrm{th},\\mathrm{imm}}$ 和 $V_{\\mathrm{th},\\mathrm{mat}}$ 分别是未成熟和成熟神经元的脉冲阈值。\n\n记忆干扰的操作化定义为对不同输入模式产生放电的输出集合之间的平均 Jaccard 重叠度。对于模式 $p$，令 $S_p$ 为在检索过程中至少放电一次的输出神经元集合。对于模式 $p\\neq q$，定义 Jaccard 重叠度为：\n$$\nO_{pq} = \\frac{|S_p \\cap S_q|}{|S_p \\cup S_q|},\n$$\n当 $|S_p \\cup S_q|=0$ 时，$O_{pq}=0$。干扰指数是所有无序对的平均值：\n$$\nI = \\frac{2}{P(P-1)} \\sum_{1 \\le p  q \\le P} O_{pq}\n$$\n您的最终任务是提交一个 Python 脚本，其中包含一个名为 `solve()` 的函数。此函数必须执行以下操作：\n1.  对四种情况运行模拟，参数为：\n    *   (N=100, M=50, N_imm=30, gamma=2.0, P=6, c=0.2, seed=123)\n    *   (N=100, M=50, N_imm=0, gamma=2.0, P=6, c=0.2, seed=124)\n    *   (N=120, M=60, N_imm=60, gamma=3.0, P=8, c=0.3, seed=125)\n    *   (N=140, M=60, N_imm=50, gamma=2.5, P=12, c=0.4, seed=126)\n2.  对于每种情况，计算**干扰指数的变化**，$\\Delta I = I_{\\mathrm{immature}} - I_{\\mathrm{baseline}}$。**基线条件**定义为将**所有**神经元（包括未成熟神经元）视为成熟神经元来运行模拟（即，对所有神经元，$A^{(+)}=A^{(+)}_{\\mathrm{base}}$，$A^{(-)}=A^{(-)}_{\\mathrm{base}}$，$V_{\\mathrm{th}}=V_{\\mathrm{th},\\mathrm{mat}}$），同时使用与未成熟情况相同的**初始权重**和**输入模式**。\n3.  `solve` 函数不应接受任何参数，并且必须将结果作为包含四个浮点值的列表打印到标准输出，每个值四舍五入到三位小数，格式为 `[val1,val2,val3,val4]`。\n\n**参数值：**\n*   $V_{\\mathrm{rest}}=-65.0$ mV, $V_{\\mathrm{reset}}=-65.0$ mV, $V_{\\mathrm{th},\\mathrm{mat}}=-52.0$ mV, $V_{\\mathrm{th},\\mathrm{imm}}=-55.0$ mV\n*   $\\tau_m=20.0$ ms, $\\tau_{\\mathrm{syn}}=5.0$ ms, $\\tau_+=20.0$ ms, $\\tau_-=20.0$ ms\n*   $G=3.0$ mV, $\\lambda=0.001$, $w_{\\max}=0.1$\n*   $A^{(+)}_{\\mathrm{base}}=0.0005$, $A^{(-)}_{\\mathrm{base}}=0.0006$\n*   模拟时间步长 $dt=1.0$ ms，每个模式呈现时间 $T=150$ ms\n*   输入模式中活动单元的比例 $p_{\\mathrm{act}}=0.2$\n*   活动单元的高放电率 $r_{\\mathrm{high}}=20$ Hz，非活动单元的低放电率 $r_{\\mathrm{low}}=2$ Hz\n*   不应期为 3.0 ms",
            "solution": "用户想要一个可复现的模拟，以研究脉冲神经网络中未成熟神经元对记忆干扰的影响。\n\n### 第 1 步：提取给定信息\n\n*   **神经元模型 (漏放电):**\n    *   动力学: $\\frac{dV_j(t)}{dt} = -\\frac{V_j(t) - V_{\\mathrm{rest}}}{\\tau_m} + G \\cdot I_{\\mathrm{syn},j}(t)$\n    *   脉冲条件: $V_j(t)$ 超过 $V_{\\mathrm{th},j}$。\n    *   脉冲后重置: $V_j(t) \\to V_{\\mathrm{reset}}$ 并维持一个不应期。\n*   **突触输入模型:**\n    *   突触电流: $I_{\\mathrm{syn},j}(t) = \\sum_{i=1}^{M} w_{ji} \\, x_i(t)$\n    *   突触前轨迹: $\\frac{dx_i(t)}{dt} = -\\frac{x_i(t)}{\\tau_{\\mathrm{syn}}} + s_i(t)$, 其中 $s_i(t)\\in\\{0,1\\}$。\n*   **可塑性模型 (STDP):**\n    *   突触前资格迹: $\\frac{dE^{\\mathrm{pre}}_i(t)}{dt} = -\\frac{E^{\\mathrm{pre}}_i(t)}{\\tau_+} + s_i(t)$\n    *   突触后资格迹: $\\frac{dE^{\\mathrm{post}}_j(t)}{dt} = -\\frac{E^{\\mathrm{post}}_j(t)}{\\tau_-} + s^{\\mathrm{post}}_j(t)$\n    *   权重更新规则 (每窗口): $\\Delta w_{ji} = A^{(+)}_j \\sum_t s^{\\mathrm{post}}_j(t) \\, E^{\\mathrm{pre}}_i(t) - A^{(-)}_j \\sum_t E^{\\mathrm{post}}_j(t) \\, s_i(t)$\n    *   权重动力学: $w_{ji} \\leftarrow \\min\\left\\{\\max\\{w_{ji} + \\Delta w_{ji} - \\lambda w_{ji},\\, 0\\},\\, w_{\\max}\\right\\}$\n*   **神经元类型 (未成熟 vs. 成熟):**\n    *   未成熟: $A^{(+)}_j = \\gamma \\, A^{(+)}_{\\mathrm{base}}$, $A^{(-)}_j = \\gamma \\, A^{(-)}_{\\mathrm{base}}$, $V_{\\mathrm{th},j} = V_{\\mathrm{th},\\mathrm{imm}}$\n    *   成熟: $A^{(+)}_j = A^{(+)}_{\\mathrm{base}}$, $A^{(-)}_j = A^{(-)}_{\\mathrm{base}}$, $V_{\\mathrm{th},j} = V_{\\mathrm{th},\\mathrm{mat}}$\n*   **干扰度量:**\n    *   模式 $p$ 的输出集合: $S_p = \\{\\text{至少放电一次的神经元}\\}$\n    *   Jaccard 重叠度: $O_{pq} = |S_p \\cap S_q| / |S_p \\cup S_q|$\n    *   干扰指数: $I = \\frac{2}{P(P-1)} \\sum_{1 \\le p  q \\le P} O_{pq}$\n*   **任务:**\n    *   编写一个名为 `solve()` 的 Python 函数。\n    *   运行 4 个指定的测试用例。\n    *   为每个用例计算 $\\Delta I = I_{\\mathrm{immature}} - I_{\\mathrm{baseline}}$。\n    *   打印一个包含 4 个浮点数的列表，四舍五入到三位小数。\n*   **模拟计划:**\n    1.  **参数定义**: 将所有固定的神经元、突触和模拟参数实现为常量。\n    2.  **输入生成**:\n        *   创建一个函数 `generate_patterns(M, P, p_act, c, rng)`，用于生成 P 个相关的输入模式。\n        *   创建一个函数 `generate_spikes(patterns, T, dt, r_high, r_low, rng)`，用于将这些二元模式转换为泊松脉冲序列。\n    3.  **网络模拟**:\n        *   创建一个主函数 `run_network(params, W_init, spike_trains)`，用于在给定参数集下运行完整的模拟（训练和检索）。\n        *   使用欧拉法离散化微分方程。\n        *   实现离散时间下的 STDP 资格迹和权重更新。\n        *   在每个模式呈现后，应用权重更新，包括衰减和边界。\n        *   在训练所有模式后，运行一个单独的检索阶段（关闭可塑性），以记录每个模式的脉冲神经元集合 ($S_p$)。\n    4.  **度量计算**: 创建一个函数 `calculate_interference(S_list, P)`，用于计算平均 Jaccard 重叠度。\n    5.  **主求解器**:\n        *   实现 `solve()` 函数。\n        *   循环遍历四个测试用例。\n        *   对于每个用例，生成输入模式和脉冲序列。\n        *   生成一个随机的初始权重矩阵 `W_init`。\n        *   运行基线模拟 (所有神经元都是成熟的)。\n        *   运行未成熟模拟 (N_imm 个神经元具有未成熟属性)。\n        *   计算 $\\Delta I$。\n        *   收集结果并以指定格式打印。",
            "answer": "```python\nimport numpy as np\n\n# Fixed model constants as specified in the problem\nCONSTANTS = {\n    'V_rest': -65.0, 'V_reset': -65.0, 'V_th_mat': -52.0, 'V_th_imm': -55.0,\n    'tau_m': 20.0, 'tau_syn': 5.0, 'tau_plus': 20.0, 'tau_minus': 20.0,\n    'G': 3.0, 'lambda_w': 0.001, 'w_max': 0.1,\n    'A_plus_base': 0.0005, 'A_minus_base': 0.0006,\n    'dt': 1.0, 'T': 150.0, 'p_act': 0.2,\n    'r_high': 20.0, 'r_low': 2.0, 'refractory_period': 3.0\n}\n\ndef generate_patterns(M, P, p_act, c, rng):\n    \"\"\"Generates P correlated binary input patterns of size M.\"\"\"\n    num_active = int(p_act * M)\n    num_common = int(c * p_act * M)\n    num_unique = num_active - num_common\n\n    all_indices = np.arange(M)\n    if num_common > M: num_common = M\n    common_indices = rng.choice(all_indices, size=num_common, replace=False)\n    \n    remaining_indices = np.setdiff1d(all_indices, common_indices, assume_unique=True)\n    \n    patterns = []\n    for _ in range(P):\n        p = np.zeros(M, dtype=bool)\n        p[common_indices] = True\n        if num_unique > 0:\n            if num_unique > len(remaining_indices):\n                unique_indices = rng.choice(remaining_indices, size=len(remaining_indices), replace=False)\n            else:\n                unique_indices = rng.choice(remaining_indices, size=num_unique, replace=False)\n            p[unique_indices] = True\n        patterns.append(p)\n        \n    return np.array(patterns)\n\ndef generate_spikes(patterns, T, dt, r_high, r_low, rng):\n    \"\"\"Generates Poisson spike trains for each pattern.\"\"\"\n    P, M = patterns.shape\n    num_steps = int(T / dt)\n    \n    p_high = r_high * dt / 1000.0\n    p_low = r_low * dt / 1000.0\n    \n    spike_trains = []\n    for p_idx in range(P):\n        pattern = patterns[p_idx]\n        probs = np.where(pattern, p_high, p_low)\n        spikes = rng.random((num_steps, M))  probs\n        spike_trains.append(spikes)\n        \n    return spike_trains\n\ndef calculate_interference(S_list, P):\n    \"\"\"Calculates the average Jaccard overlap.\"\"\"\n    if P  2:\n        return 0.0\n    \n    overlaps = []\n    for i in range(P):\n        for j in range(i + 1, P):\n            set_p = S_list[i]\n            set_q = S_list[j]\n            \n            intersection = len(set_p.intersection(set_q))\n            union = len(set_p.union(set_q))\n            \n            if union == 0:\n                overlaps.append(0.0)\n            else:\n                overlaps.append(intersection / union)\n    \n    return np.mean(overlaps) if overlaps else 0.0\n\ndef run_network(sim_params, W_init, spike_trains):\n    \"\"\"Runs the full network simulation for one configuration.\"\"\"\n    N, M, P = sim_params['N'], sim_params['M'], sim_params['P']\n    V_th, A_plus, A_minus = sim_params['V_th'], sim_params['A_plus'], sim_params['A_minus']\n    \n    dt, T = CONSTANTS['dt'], CONSTANTS['T']\n    num_steps = int(T / dt)\n    \n    # Pre-calculate decay factors for efficiency\n    k_m = np.exp(-dt / CONSTANTS['tau_m'])\n    k_syn = np.exp(-dt / CONSTANTS['tau_syn'])\n    k_plus = np.exp(-dt / CONSTANTS['tau_plus'])\n    k_minus = np.exp(-dt / CONSTANTS['tau_minus'])\n    refractory_steps = int(CONSTANTS['refractory_period'] / dt)\n    \n    # Initialize weights\n    W = np.copy(W_init)\n\n    # --- Training Phase ---\n    for p_idx in range(P):\n        spikes_pattern = spike_trains[p_idx]\n        \n        V = np.full(N, CONSTANTS['V_rest'])\n        ref_counters = np.zeros(N, dtype=int)\n        x_trace, E_pre, E_post = np.zeros(M), np.zeros(M), np.zeros(N)\n        \n        LTP_contrib = np.zeros((N, M))\n        LTD_contrib = np.zeros((N, M))\n        \n        for t in range(num_steps):\n            x_trace *= k_syn\n            E_pre *= k_plus\n            E_post *= k_minus\n            \n            pre_spike_indices = np.where(spikes_pattern[t, :])[0]\n            if pre_spike_indices.size > 0:\n                LTD_contrib[:, pre_spike_indices] += E_post[:, np.newaxis]\n                x_trace[pre_spike_indices] += 1.0\n                E_pre[pre_spike_indices] += 1.0\n\n            I_syn = W @ x_trace\n            \n            not_in_ref = (ref_counters == 0)\n            V = V * k_m + (CONSTANTS['V_rest'] + CONSTANTS['G'] * I_syn) * (1 - k_m)\n            V[~not_in_ref] = CONSTANTS['V_reset']\n            \n            ref_counters[ref_counters > 0] -= 1\n            \n            post_spike_indices = np.where((V > V_th)  not_in_ref)[0]\n            if post_spike_indices.size > 0:\n                LTP_contrib[post_spike_indices, :] += E_pre\n                E_post[post_spike_indices] += 1.0\n                V[post_spike_indices] = CONSTANTS['V_reset']\n                ref_counters[post_spike_indices] = refractory_steps\n\n        delta_W = A_plus[:, np.newaxis] * LTP_contrib - A_minus[:, np.newaxis] * LTD_contrib\n        W += delta_W - CONSTANTS['lambda_w'] * W\n        W = np.clip(W, 0, CONSTANTS['w_max'])\n\n    # --- Retrieval Phase ---\n    S_list = []\n    for p_idx in range(P):\n        spikes_pattern = spike_trains[p_idx]\n        \n        V = np.full(N, CONSTANTS['V_rest'])\n        ref_counters = np.zeros(N, dtype=int)\n        x_trace = np.zeros(M)\n        output_spikes_this_pattern = np.zeros(N, dtype=bool)\n\n        for t in range(num_steps):\n            x_trace *= k_syn\n            pre_spike_indices = np.where(spikes_pattern[t, :])[0]\n            if pre_spike_indices.size > 0:\n                x_trace[pre_spike_indices] += 1.0\n                \n            I_syn = W @ x_trace\n            not_in_ref = (ref_counters == 0)\n\n            V = V * k_m + (CONSTANTS['V_rest'] + CONSTANTS['G'] * I_syn) * (1 - k_m)\n            V[~not_in_ref] = CONSTANTS['V_reset']\n            \n            ref_counters[ref_counters > 0] -= 1\n            \n            post_spike_indices = np.where((V > V_th)  not_in_ref)[0]\n            if post_spike_indices.size > 0:\n                output_spikes_this_pattern[post_spike_indices] = True\n                V[post_spike_indices] = CONSTANTS['V_reset']\n                ref_counters[post_spike_indices] = refractory_steps\n\n        S_list.append(set(np.where(output_spikes_this_pattern)[0]))\n        \n    return calculate_interference(S_list, P)\n\ndef solve():\n    test_cases = [\n        # N, M, N_imm, gamma, P, c, seed\n        (100, 50, 30, 2.0, 6, 0.2, 123),\n        (100, 50, 0, 2.0, 6, 0.2, 124),\n        (120, 60, 60, 3.0, 8, 0.3, 125),\n        (140, 60, 50, 2.5, 12, 0.4, 126),\n    ]\n\n    results = []\n    for case in test_cases:\n        N, M, N_imm, gamma, P, c, seed = case\n        \n        rng = np.random.default_rng(seed)\n        \n        patterns = generate_patterns(M, P, CONSTANTS['p_act'], c, rng)\n        spike_trains = generate_spikes(patterns, CONSTANTS['T'], CONSTANTS['dt'], CONSTANTS['r_high'], CONSTANTS['r_low'], rng)\n        W_init = rng.uniform(0, 0.01, size=(N, M))\n\n        # --- Baseline run (all mature) ---\n        params_base = {\n            'N': N, 'M': M, 'P': P,\n            'V_th': np.full(N, CONSTANTS['V_th_mat']),\n            'A_plus': np.full(N, CONSTANTS['A_plus_base']),\n            'A_minus': np.full(N, CONSTANTS['A_minus_base'])\n        }\n        I_baseline = run_network(params_base, W_init, spike_trains)\n        \n        # --- Immature run ---\n        V_th_imm = np.full(N, CONSTANTS['V_th_mat'])\n        A_plus_imm = np.full(N, CONSTANTS['A_plus_base'])\n        A_minus_imm = np.full(N, CONSTANTS['A_minus_base'])\n        \n        if N_imm > 0:\n            immature_indices = np.arange(N_imm) # Designate first N_imm as immature\n            V_th_imm[immature_indices] = CONSTANTS['V_th_imm']\n            A_plus_imm[immature_indices] = gamma * CONSTANTS['A_plus_base']\n            A_minus_imm[immature_indices] = gamma * CONSTANTS['A_minus_base']\n        \n        params_imm = {\n            'N': N, 'M': M, 'P': P,\n            'V_th': V_th_imm,\n            'A_plus': A_plus_imm,\n            'A_minus': A_minus_imm\n        }\n        I_immature = run_network(params_imm, W_init, spike_trains)\n\n        delta_I = I_immature - I_baseline\n        results.append(round(delta_I, 3))\n\n    print(f\"[{','.join(f'{r:.3f}' for r in results)}]\")\n\nsolve()\n```"
        }
    ]
}