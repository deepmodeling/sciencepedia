{
    "hands_on_practices": [
        {
            "introduction": "The first step in operationalizing the diathesis-stress model is translating its theoretical constructs into concrete, quantitative predictions. This practice provides a direct application of the model using logistic regression, a cornerstone of modern biostatistics, to forecast an individual's risk of developing a major depressive episode. By working through this exercise , you will learn how to combine a person's genetic vulnerability (diathesis) and life stress exposure to calculate a specific probability, bridging the gap between abstract theory and personalized risk assessment.",
            "id": "4765949",
            "problem": "A prospective cohort study of first-onset major depressive episode over a $12$-month period is modeled under the diathesis-stress framework, which posits that the probability of onset depends on an individual's vulnerability (diathesis) and exposure to stress. In this cohort, diathesis is operationalized as a standardized Polygenic Risk Score (PRS) in standard deviation units, and stress exposure is summarized as a continuous stress index $S$ on a validated $0$ to $3$ scale. To link predictors to onset probability, the study uses a logistic regression consistent with the diathesis-stress model and a Gene-by-Environment (GxE) interaction:\n$$\n\\mathrm{logit}(p) \\equiv \\ln\\!\\left(\\frac{p}{1-p}\\right) = \\beta_{0} + \\beta_{G}\\,PRS + \\beta_{S}\\,S + \\beta_{G\\times E}\\,PRS\\cdot S,\n$$\nwhere $p$ is the probability of episode onset within $12$ months.\n\nSuppose the population-representative training data for this cohort yielded the following coefficients: $\\beta_{0} = -3.2$, $\\beta_{G} = 0.45$, $\\beta_{S} = 0.55$, and $\\beta_{G\\times E} = 0.20$. For an individual with $PRS = 1.2$ and $S = 2.0$:\n\n1. Starting from the core definitions of the diathesis-stress framework and the properties of the logistic link, derive the analytic expression for the predicted onset probability $p$ in terms of the linear predictor and the inverse-logit transformation, then compute its numerical value for the given $PRS$ and $S$.\n2. Briefly interpret the clinical relevance of the resulting probability with respect to the baseline risk implied by $\\beta_{0}$ and the sign of $\\beta_{G\\times E}$.\n\nExpress the predicted probability $p$ as a unitless scalar in $[0,1]$ and round your final numerical answer to four significant figures.",
            "solution": "The user has provided a problem that requires the calculation and interpretation of a probability from a logistic regression model within the context of psychiatric epidemiology.\n\n### Step 1: Extract Givens\n\nThe problem provides the following information:\n-   **Model:** A logistic regression model for the probability ($p$) of a first-onset major depressive episode.\n-   **Model Equation:** $\\mathrm{logit}(p) \\equiv \\ln\\!\\left(\\frac{p}{1-p}\\right) = \\beta_{0} + \\beta_{G}\\,PRS + \\beta_{S}\\,S + \\beta_{G\\times E}\\,PRS\\cdot S$.\n-   **Predictors:**\n    -   $PRS$: Standardized Polygenic Risk Score.\n    -   $S$: Continuous stress index on a scale from $0$ to $3$.\n-   **Coefficients:**\n    -   $\\beta_{0} = -3.2$\n    -   $\\beta_{G} = 0.45$\n    -   $\\beta_{S} = 0.55$\n    -   $\\beta_{G\\times E} = 0.20$\n-   **Individual's Data:**\n    -   $PRS = 1.2$\n    -   $S = 2.0$\n-   **Tasks:**\n    1.  Derive the analytic expression for $p$ and compute its numerical value.\n    2.  Interpret the clinical relevance of the result with respect to baseline risk and the sign of $\\beta_{G\\times E}$.\n-   **Output requirement:** The final numerical probability $p$ should be rounded to four significant figures.\n\n### Step 2: Validate Using Extracted Givens\n\nThe problem is subjected to validation against the established criteria.\n\n-   **Scientific Grounding:** The problem is scientifically sound. The diathesis-stress model is a cornerstone of etiological theories in psychopathology. Logistic regression is the standard statistical method for modeling binary outcomes such as disease onset. The use of a Gene-by-Environment (G$\\times$E) interaction term ($\\beta_{G\\times E}\\,PRS\\cdot S$) is a standard and appropriate way to mathematically operationalize the diathesis-stress hypothesis. The given values for coefficients and predictors are within a plausible range for such a study.\n-   **Well-Posedness:** The problem is well-posed. It provides a specific mathematical model, all the necessary parameters ($\\beta$ coefficients) and input variables ($PRS$, $S$), and asks for a direct calculation and a constrained interpretation. A unique, stable, and meaningful solution exists.\n-   **Objectivity:** The problem is stated in objective, quantitative terms, free from bias or subjective claims.\n\nThe problem exhibits none of the invalidity flaws. It is a straightforward application of a standard biostatistical model.\n\n### Step 3: Verdict and Action\n\nThe problem is deemed **valid**. A solution will be provided.\n\n### Solution Derivation\n\n**Part 1: Derivation of the Onset Probability**\n\nThe logistic regression model defines the log-odds of the outcome (episode onset) as a linear combination of the predictors. Let the linear predictor be denoted by $\\eta$.\n$$\n\\eta = \\beta_{0} + \\beta_{G}\\,PRS + \\beta_{S}\\,S + \\beta_{G\\times E}\\,PRS\\cdot S\n$$\nThe core model equation is:\n$$\n\\ln\\left(\\frac{p}{1-p}\\right) = \\eta\n$$\nTo derive the analytic expression for the probability $p$, we must solve this equation for $p$. This involves applying the inverse-logit (or logistic sigmoid) transformation. First, we exponentiate both sides of the equation:\n$$\n\\exp\\left[\\ln\\left(\\frac{p}{1-p}\\right)\\right] = \\exp(\\eta)\n$$\n$$\n\\frac{p}{1-p} = \\exp(\\eta)\n$$\nNow, we solve for $p$:\n$$\np = (1-p) \\exp(\\eta)\n$$\n$$\np = \\exp(\\eta) - p \\exp(\\eta)\n$$\n$$\np + p \\exp(\\eta) = \\exp(\\eta)\n$$\n$$\np(1 + \\exp(\\eta)) = \\exp(\\eta)\n$$\n$$\np = \\frac{\\exp(\\eta)}{1 + \\exp(\\eta)}\n$$\nThis is the required analytic expression for $p$. An equivalent and often more numerically stable form is obtained by dividing the numerator and denominator by $\\exp(\\eta)$:\n$$\np = \\frac{1}{\\exp(-\\eta) + 1}\n$$\nThe predicted onset probability $p$ is therefore given by:\n$$\np = \\frac{1}{1 + \\exp(-(\\beta_{0} + \\beta_{G}\\,PRS + \\beta_{S}\\,S + \\beta_{G\\times E}\\,PRS\\cdot S))}\n$$\nNow, we compute the numerical value for the given individual. First, we calculate the linear predictor $\\eta$:\n$$\n\\eta = -3.2 + (0.45)(1.2) + (0.55)(2.0) + (0.20)(1.2)(2.0)\n$$\n$$\n\\eta = -3.2 + 0.54 + 1.10 + 0.48\n$$\n$$\n\\eta = -3.2 + 2.12\n$$\n$$\n\\eta = -1.08\n$$\nNow, we substitute this value of $\\eta$ into the expression for $p$:\n$$\np = \\frac{1}{1 + \\exp(-(-1.08))} = \\frac{1}{1 + \\exp(1.08)}\n$$\nUsing a calculator, $\\exp(1.08) \\approx 2.944683$.\n$$\np \\approx \\frac{1}{1 + 2.944683} = \\frac{1}{3.944683} \\approx 0.253496\n$$\nRounding to four significant figures, the predicted probability is $p = 0.2535$.\n\n**Part 2: Interpretation of Clinical Relevance**\n\n1.  **Baseline Risk:** The intercept $\\beta_0 = -3.2$ represents the log-odds of developing a major depressive episode for an individual with reference values for all predictors. Assuming the reference is $PRS = 0$ and $S = 0$, the baseline probability is $p_{baseline} = (1 + \\exp(-\\beta_0))^{-1} = (1 + \\exp(3.2))^{-1} \\approx 0.039$. This represents a baseline $12$-month risk of about $3.9\\%$ in the absence of measured genetic risk and stress. The calculated probability of $p \\approx 0.2535$ (or $25.35\\%$) for the individual in question is substantially higher (approximately $6.5$ times) than this baseline risk.\n\n2.  **Interaction Effect ($\\beta_{G\\times E}$):** The coefficient for the interaction term, $\\beta_{G\\times E} = 0.20$, is positive. This positive sign is the mathematical formalization of the diathesis-stress hypothesis. It signifies a synergistic interaction, meaning that the effect of stress on the risk of depression is greater for individuals with higher genetic vulnerability (higher $PRS$), and conversely, the effect of genetic vulnerability is amplified in the presence of stress. In this case, the individual has both high genetic risk ($PRS=1.2$) and high stress ($S=2.0$). The positive interaction term adds a value of $\\beta_{G\\times E} \\cdot PRS \\cdot S = (0.20)(1.2)(2.0) = 0.48$ to the log-odds ($\\eta$), which increases the predicted probability above and beyond what would be expected from the sum of the individual main effects of genes and stress. This demonstrates that the combination of this person's genetic diathesis and stress exposure creates a risk that is multiplicatively, not just additively, increased.",
            "answer": "$$\n\\boxed{0.2535}\n$$"
        },
        {
            "introduction": "A key theoretical distinction in etiological models is how different risk factors combine. Do they simply add up, as suggested by a basic additive model, or does one factor amplify the effect of another, as proposed by the diathesis-stress framework's focus on interaction? This practice  directly confronts this question by asking you to calculate risk indices for a group of individuals under both an additive and a multiplicative model. By comparing the resulting risk rankings, you will gain insight into how these different structural assumptions can lead to profoundly different clinical prioritizations.",
            "id": "4766023",
            "problem": "A core premise of the diathesis-stress framework in psychiatry is that the probability of disorder onset increases monotonically with both a stable vulnerability (diathesis) and exposure to environmental stress. Two widely used structural assumptions for how vulnerability and stress combine are additive and multiplicative formulations. In an additive specification, a risk index increases linearly with diathesis and stress. In a multiplicative specification, the joint effect is captured by their product, reflecting an interaction consistent with the diathesis-stress model's emphasis on synergistic amplification. For comparing individual-level predictions across model forms, only the rank ordering of a monotone risk index is needed, because any strictly increasing transformation preserves rank.\n\nConsider five research participants indexed by $i \\in \\{1,2,3,4,5\\}$ with measured diathesis $D_i$ (a nonnegative, dimensionless temperament vulnerability score) and recent stress $S_i$ (a nonnegative count of weighted major life events in the past year). The observed values are:\n- Participant $1$: $D_1 = 2.0$, $S_1 = 4$\n- Participant $2$: $D_2 = 1.0$, $S_2 = 2$\n- Participant $3$: $D_3 = 3.0$, $S_3 = 1$\n- Participant $4$: $D_4 = 0.5$, $S_4 = 5$\n- Participant $5$: $D_5 = 1.5$, $S_5 = 3$\n\nDefine the additive-model risk index as $r_A(i) = \\beta_D D_i + \\beta_S S_i$ with coefficients $\\beta_D = 0.9$ and $\\beta_S = 0.5$. Define the multiplicative-model risk index as $r_M(i) = D_i \\times S_i$. Assume there are no ties in the resulting risk indices.\n\nUsing the above, compute the additive-model and multiplicative-model predicted risk indices for each participant, obtain the two induced rank orderings, and then quantify the agreement between these two rankings using Kendall's tau coefficient, defined as\n$$\\tau = \\frac{C - D}{\\binom{n}{2}},$$\nwhere $n$ is the number of participants, $C$ is the number of concordant pairs, and $D$ is the number of discordant pairs between the two rankings. Express your final answer for $\\tau$ as an exact value (no rounding). No units are required.",
            "solution": "The problem has been validated and is determined to be a well-posed, scientifically grounded, and objective quantitative exercise. All necessary information is provided, the data are consistent, and the required calculations follow established mathematical and statistical principles.\n\nThe first step is to compute the risk indices for each of the $n=5$ participants under the two specified models: the additive model, $r_A(i)$, and the multiplicative model, $r_M(i)$.\n\nThe additive-model risk index is defined as $r_A(i) = \\beta_D D_i + \\beta_S S_i$, with given coefficients $\\beta_D = 0.9$ and $\\beta_S = 0.5$. The data for the five participants $(D_i, S_i)$ are:\n- Participant $1$: $D_1 = 2.0$, $S_1 = 4$\n- Participant $2$: $D_2 = 1.0$, $S_2 = 2$\n- Participant $3$: $D_3 = 3.0$, $S_3 = 1$\n- Participant $4$: $D_4 = 0.5$, $S_4 = 5$\n- Participant $5$: $D_5 = 1.5$, $S_5 = 3$\n\nCalculating $r_A(i)$ for each participant:\n- $r_A(1) = (0.9)(2.0) + (0.5)(4) = 1.8 + 2.0 = 3.8$\n- $r_A(2) = (0.9)(1.0) + (0.5)(2) = 0.9 + 1.0 = 1.9$\n- $r_A(3) = (0.9)(3.0) + (0.5)(1) = 2.7 + 0.5 = 3.2$\n- $r_A(4) = (0.9)(0.5) + (0.5)(5) = 0.45 + 2.5 = 2.95$\n- $r_A(5) = (0.9)(1.5) + (0.5)(3) = 1.35 + 1.5 = 2.85$\n\nThe multiplicative-model risk index is defined as $r_M(i) = D_i \\times S_i$.\nCalculating $r_M(i)$ for each participant:\n- $r_M(1) = 2.0 \\times 4 = 8.0$\n- $r_M(2) = 1.0 \\times 2 = 2.0$\n- $r_M(3) = 3.0 \\times 1 = 3.0$\n- $r_M(4) = 0.5 \\times 5 = 2.5$\n- $r_M(5) = 1.5 \\times 3 = 4.5$\n\nThe problem statement assumes no ties in the risk indices. The set of additive scores is $\\{3.8, 1.9, 3.2, 2.95, 2.85\\}$, and the set of multiplicative scores is $\\{8.0, 2.0, 3.0, 2.5, 4.5\\}$. Both sets contain distinct values, so the assumption is confirmed.\n\nNext, we determine the rank ordering for each model, from lowest risk (rank $1$) to highest risk (rank $5$).\n\nFor the additive model, the sorted scores are:\n$1.9$ (Participant $2$) $<$ $2.85$ (Participant $5$) $<$ $2.95$ (Participant $4$) $<$ $3.2$ (Participant $3$) $<$ $3.8$ (Participant $1$).\nThe rank ordering, denoted $R_A$, for participants $(1, 2, 3, 4, 5)$ is $(5, 1, 4, 3, 2)$.\n\nFor the multiplicative model, the sorted scores are:\n$2.0$ (Participant $2$) $<$ $2.5$ (Participant $4$) $<$ $3.0$ (Participant $3$) $<$ $4.5$ (Participant $5$) $<$ $8.0$ (Participant $1$).\nThe rank ordering, denoted $R_M$, for participants $(1, 2, 3, 4, 5)$ is $(5, 1, 3, 2, 4)$.\n\nTo calculate Kendall's tau, $\\tau$, we need to count the number of concordant pairs ($C$) and discordant pairs ($D$) between the two rankings. A pair of participants $(i, j)$ is concordant if their ranks are in the same order in both rankings (i.e., $R_A(i) < R_A(j)$ and $R_M(i) < R_M(j)$, or $R_A(i) > R_A(j)$ and $R_M(i) > R_M(j)$). The pair is discordant if their ranks are in the opposite order. The total number of pairs of participants is $\\binom{n}{2} = \\binom{5}{2} = \\frac{5 \\times 4}{2} = 10$.\n\nLet's list the paired ranks $(R_A(i), R_M(i))$ for each participant $i$:\n- Participant $1$: $(5, 5)$\n- Participant $2$: $(1, 1)$\n- Participant $3$: $(4, 3)$\n- Participant $4$: $(3, 2)$\n- Participant $5$: $(2, 4)$\n\nWe now examine all $10$ pairs of participants:\n1. Pair $(1, 2)$: Ranks are $(5, 5)$ and $(1, 1)$. Since $5>1$ and $5>1$, the pair is concordant.\n2. Pair $(1, 3)$: Ranks are $(5, 5)$ and $(4, 3)$. Since $5>4$ and $5>3$, the pair is concordant.\n3. Pair $(1, 4)$: Ranks are $(5, 5)$ and $(3, 2)$. Since $5>3$ and $5>2$, the pair is concordant.\n4. Pair $(1, 5)$: Ranks are $(5, 5)$ and $(2, 4)$. Since $5>2$ and $5>4$, the pair is concordant.\n5. Pair $(2, 3)$: Ranks are $(1, 1)$ and $(4, 3)$. Since $1<4$ and $1<3$, the pair is concordant.\n6. Pair $(2, 4)$: Ranks are $(1, 1)$ and $(3, 2)$. Since $1<3$ and $1<2$, the pair is concordant.\n7. Pair $(2, 5)$: Ranks are $(1, 1)$ and $(2, 4)$. Since $1<2$ and $1<4$, the pair is concordant.\n8. Pair $(3, 4)$: Ranks are $(4, 3)$ and $(3, 2)$. Since $4>3$ and $3>2$, the pair is concordant.\n9. Pair $(3, 5)$: Ranks are $(4, 3)$ and $(2, 4)$. Since $4>2$ but $3<4$, the pair is discordant.\n10. Pair $(4, 5)$: Ranks are $(3, 2)$ and $(2, 4)$. Since $3>2$ but $2<4$, the pair is discordant.\n\nFrom this analysis, we have $C=8$ concordant pairs and $D=2$ discordant pairs. The total number of pairs is $C+D = 8+2=10$, which matches $\\binom{5}{2}$.\n\nFinally, we compute Kendall's tau coefficient using the formula $\\tau = \\frac{C - D}{\\binom{n}{2}}$.\nSubstituting the values:\n$$ \\tau = \\frac{8 - 2}{10} = \\frac{6}{10} $$\nSimplifying the fraction gives:\n$$ \\tau = \\frac{3}{5} $$\nThis value represents the degree of rank-order agreement between the additive and multiplicative models for this specific dataset.",
            "answer": "$$ \\boxed{\\frac{3}{5}} $$"
        },
        {
            "introduction": "In clinical science, competing theories are ultimately tested against data. This advanced practice moves beyond simple comparison to formal model selection, a crucial skill for any researcher. Using the powerful technique of $k$-fold cross-validation , you will empirically determine whether an additive Biopsychosocial model or an interactive Diathesis-Stress model offers better out-of-sample predictive performance. This exercise simulates the process of data-driven decision-making, showing how to select the most robust and generalizable model to guide clinical insights and future research.",
            "id": "4766024",
            "problem": "You are given two competing probabilistic models for predicting binary clinical outcomes that are grounded in psychiatric theory. The first is the Biopsychosocial Model, which posits that biological, psychological, and social variables each contribute additively to the risk of disorder. The second is the Diathesis-Stress Model, which posits that vulnerability (diathesis) and environmental stress interact multiplicatively to shape risk. Your task is to implement $k$-fold cross-validation of logistic regression for each model, compute out-of-sample predictive performance via average per-sample negative log-likelihood, and decide which model should guide clinical decision-making for each provided test case.\n\nFundamental definitions and assumptions:\n- Let $y_i \\in \\{0,1\\}$ denote the binary outcome for individual $i$, where $y_i = 1$ represents the occurrence of a depressive episode and $y_i = 0$ represents its absence.\n- Let $\\sigma(z)$ be the logistic (sigmoid) function defined by $\\sigma(z) = \\dfrac{1}{1 + e^{-z}}$.\n- For a given design matrix $\\mathbf{X} \\in \\mathbb{R}^{n \\times p}$ and parameter vector $\\mathbf{w} \\in \\mathbb{R}^{p}$, the logistic regression model specifies $p_i = \\mathbb{P}(y_i=1 \\mid \\mathbf{x}_i) = \\sigma(\\mathbf{x}_i^\\top \\mathbf{w})$.\n- The negative log-likelihood (cross-entropy loss) for logistic regression on a dataset $\\{(\\mathbf{x}_i,y_i)\\}_{i=1}^n$ is given by\n$$\n\\mathcal{L}(\\mathbf{w}) = \\sum_{i=1}^n \\left[\\log\\left(1 + e^{\\mathbf{x}_i^\\top \\mathbf{w}}\\right) - y_i \\cdot \\mathbf{x}_i^\\top \\mathbf{w}\\right].\n$$\n- In $k$-fold cross-validation, the dataset indices are partitioned into $k$ disjoint folds of (approximately) equal size; for each fold $j$, parameters $\\mathbf{w}^{(j)}$ are fit on the complement folds, and the loss $\\mathcal{L}^{(j)}$ is evaluated on fold $j$. The out-of-sample performance is the average per-sample loss across all held-out folds,\n$$\n\\overline{\\mathcal{L}} = \\frac{1}{n} \\sum_{j=1}^k \\sum_{i \\in \\text{fold } j} \\left[\\log\\left(1 + e^{\\mathbf{x}_i^\\top \\mathbf{w}^{(j)}}\\right) - y_i \\cdot \\mathbf{x}_i^\\top \\mathbf{w}^{(j)}\\right].\n$$\n\nCompeting models:\n- Biopsychosocial Model (additive): Biological ($B$), Psychological ($P$), and Social ($S$) variables contribute additively via\n$$\n\\mathbb{P}(y=1 \\mid B,P,S) = \\sigma\\left(\\beta_0 + \\beta_B \\cdot B + \\beta_P \\cdot P + \\beta_S \\cdot S\\right).\n$$\n- Diathesis-Stress Model (interaction): Diathesis $D$ is a linear combination of biological and psychological factors ($D = w_B \\cdot B + w_P \\cdot P$), stress $T$ is the social factor ($T=S$), and risk depends on their additive and multiplicative interaction via\n$$\n\\mathbb{P}(y=1 \\mid D,T) = \\sigma\\left(\\alpha_0 + \\alpha_D \\cdot D + \\alpha_T \\cdot T + \\alpha_{DT} \\cdot D \\cdot T\\right).\n$$\n\nData generation:\n- For each test case, synthetic data are generated as follows. Draw $B$ and $P$ jointly from a bivariate normal distribution with correlation $\\rho$ via $B = \\mu_B + \\sigma_B \\cdot Z_1$, $P = \\mu_P + \\sigma_P \\cdot (\\rho \\cdot Z_1 + \\sqrt{1-\\rho^2} \\cdot Z_2)$, where $Z_1, Z_2 \\sim \\mathcal{N}(0,1)$ are independent. Draw $S$ independently as $S = \\mu_S + \\sigma_S \\cdot Z_3$ with $Z_3 \\sim \\mathcal{N}(0,1)$ independent of $Z_1$ and $Z_2$.\n- Compute $D = w_B \\cdot B + w_P \\cdot P$ and $T = S$. For the specified ground-truth model in each test case, compute the linear predictor $z$ (either additive in $B,P,S$ or interaction in $D,T,D \\cdot T$), then draw $y \\sim \\text{Bernoulli}(\\sigma(z))$ independently across individuals.\n\nCross-validation and decision rule:\n- For each model, perform $k$-fold cross-validation logistic regression using only training folds to compute any data standardization. The evaluation metric is average per-sample negative log-likelihood $\\overline{\\mathcal{L}}$ on held-out folds. Prefer the model with smaller $\\overline{\\mathcal{L}}$.\n- To decide which model guides clinical decision-making, output an integer for each test case: output $1$ if the Biopsychosocial Model has the lower out-of-sample loss, and output $2$ if the Diathesis-Stress Model has the lower out-of-sample loss. In case the difference in losses is less than a small tolerance $\\epsilon$ (use $\\epsilon = 10^{-6}$), choose the Biopsychosocial Model (output $1$) to favor the simpler additive structure.\n\nTest suite:\nImplement the above for the following test cases, each specified by sample size $n$, folds $k$, correlation $\\rho$, diathesis weights $(w_B,w_P)$, and ground-truth coefficients. Use the provided random seeds for reproducibility of index shuffling and data generation.\n\n- Case $1$ (additive ground truth):\n  - $n = 800$, $k = 5$, $\\rho = 0.2$, $(w_B,w_P) = (0.7,0.3)$, seed $= 17$.\n  - Feature scales: $(\\mu_B,\\mu_P,\\mu_S) = (0,0,0)$, $(\\sigma_B,\\sigma_P,\\sigma_S) = (1,1,1)$.\n  - Ground-truth additive coefficients: $(\\beta_0,\\beta_B,\\beta_P,\\beta_S) = (-1.0, 0.8, 0.6, 0.5)$.\n\n- Case $2$ (interaction ground truth):\n  - $n = 1200$, $k = 5$, $\\rho = 0.1$, $(w_B,w_P) = (0.6,0.4)$, seed $= 23$.\n  - Feature scales: $(\\mu_B,\\mu_P,\\mu_S) = (0,0,0)$, $(\\sigma_B,\\sigma_P,\\sigma_S) = (1,1,1)$.\n  - Ground-truth interaction coefficients: $(\\alpha_0,\\alpha_D,\\alpha_T,\\alpha_{DT}) = (-2.0, 1.0, 0.3, 1.2)$.\n\n- Case $3$ (small sample additive ground truth):\n  - $n = 60$, $k = 3$, $\\rho = 0.0$, $(w_B,w_P) = (0.5,0.5)$, seed $= 99$.\n  - Feature scales: $(\\mu_B,\\mu_P,\\mu_S) = (0,0,0)$, $(\\sigma_B,\\sigma_P,\\sigma_S) = (1,1,1)$.\n  - Ground-truth additive coefficients: $(\\beta_0,\\beta_B,\\beta_P,\\beta_S) = (-0.5, 0.5, 0.4, 0.4)$.\n\n- Case $4$ (high correlation interaction ground truth):\n  - $n = 1000$, $k = 5$, $\\rho = 0.9$, $(w_B,w_P) = (0.5,0.5)$, seed $= 202$.\n  - Feature scales: $(\\mu_B,\\mu_P,\\mu_S) = (0,0,0)$, $(\\sigma_B,\\sigma_P,\\sigma_S) = (1,1,1)$.\n  - Ground-truth interaction coefficients: $(\\alpha_0,\\alpha_D,\\alpha_T,\\alpha_{DT}) = (-1.5, 0.9, 0.3, 0.8)$.\n\nFinal output format:\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (e.g., $[result_1,result_2,result_3,result_4]$). Each element must be an integer $1$ or $2$ as defined by the decision rule above, ordered by the cases listed ($1$ through $4$). No other text should be printed.",
            "solution": "The problem requires a comparison of two psychiatric models, the Biopsychosocial (BPS) and Diathesis-Stress (DS) models, using a $k$-fold cross-validation framework. The decision of which model is superior for a given dataset hinges on the out-of-sample predictive performance, measured by the average per-sample negative log-likelihood. The overall process for each test case involves data generation, followed by model fitting and evaluation via cross-validation, and concluding with a model selection decision.\n\nFirst, for each test case, synthetic data is generated according to the provided specifications. A random number generator is initialized with the given seed to ensure reproducibility of both the data and the subsequent partitioning for cross-validation. The biological ($B$), psychological ($P$), and social ($S$) variables are drawn from Gaussian distributions. Specifically, $B$ and $P$ are drawn from a bivariate normal distribution with means $(\\mu_B, \\mu_P)$, standard deviations $(\\sigma_B, \\sigma_P)$, and correlation $\\rho$. This is achieved by generating independent standard normal variables $Z_1, Z_2 \\sim \\mathcal{N}(0,1)$ and setting $B = \\mu_B + \\sigma_B Z_1$ and $P = \\mu_P + \\sigma_P (\\rho Z_1 + \\sqrt{1-\\rho^2} Z_2)$. The social variable $S = \\mu_S + \\sigma_S Z_3$ is drawn from a normal distribution with $Z_3 \\sim \\mathcal{N}(0,1)$ being independent of $Z_1$ and $Z_2$. The binary outcome $y_i \\in \\{0, 1\\}$ for each of the $n$ individuals is then generated from a Bernoulli distribution, $y_i \\sim \\text{Bernoulli}(p_i)$, where the probability $p_i$ is determined by the logistic function $p_i = \\sigma(z_i) = (1 + e^{-z_i})^{-1}$. The linear predictor $z_i$ is computed based on the specified ground-truth model for the case, which can be either the additive BPS model or the interaction-based DS model.\n\nThe two competing models are both special cases of logistic regression.\n1.  **Biopsychosocial (BPS) Model**: This is an additive model where the linear predictor $z$ is a function of $B$, $P$, and $S$. The probability of a positive outcome is $\\mathbb{P}(y=1) = \\sigma(\\beta_0 + \\beta_B B + \\beta_P P + \\beta_S S)$. The features for this model are simply $(B, P, S)$, and we fit the coefficients $(\\beta_0, \\beta_B, \\beta_P, \\beta_S)$.\n2.  **Diathesis-Stress (DS) Model**: This model includes a multiplicative interaction term. First, a 'diathesis' variable $D$ is constructed as a specified linear combination of the biological and psychological factors, $D = w_B B + w_P P$, and a 'stress' variable $T$ is equated to the social factor, $T = S$. The probability of a positive outcome is then given by $\\mathbb{P}(y=1) = \\sigma(\\alpha_0 + \\alpha_D D + \\alpha_T T + \\alpha_{DT} D \\cdot T)$. The features for this model are $(D, T, D \\cdot T)$, and we fit the coefficients $(\\alpha_0, \\alpha_D, \\alpha_T, \\alpha_{DT})$.\n\nThe core of the task is to perform $k$-fold cross-validation for each model. The dataset of $n$ samples is randomly partitioned into $k$ disjoint folds of approximately equal size. For each fold $j \\in \\{1, \\dots, k\\}$, that fold is held out as the validation set, while the remaining $k-1$ folds constitute the training set.\n\nFor each model, and for each of the $k$ splits:\n- The features of the model are constructed.\n- A critical step is feature standardization. The means and standard deviations of the features are computed *only from the training set*. These statistics are then used to standardize both the training and the validation set features (by subtracting the mean and dividing by the standard deviation). This procedure correctly prevents information leakage from the validation set into the training process. A constant feature (standard deviation of $0$) is handled by not scaling it.\n- An intercept term (a column of ones) is added to the standardized feature matrix of the training set.\n- The logistic regression parameters $\\mathbf{w}$ are estimated by minimizing the negative log-likelihood (NLL), or cross-entropy loss, on the training data. The NLL for parameters $\\mathbf{w}$ on a dataset $\\{(\\mathbf{x}_i,y_i)\\}_{i=1}^m$ is\n$$ \\mathcal{L}(\\mathbf{w}) = \\sum_{i=1}^m \\left[\\log\\left(1 + e^{\\mathbf{x}_i^\\top \\mathbf{w}}\\right) - y_i (\\mathbf{x}_i^\\top \\mathbf{w})\\right]. $$\nThis is a convex optimization problem, which is solved efficiently using the BFGS algorithm. The algorithm's performance is enhanced by providing the analytical gradient of the NLL function:\n$$ \\nabla_{\\mathbf{w}} \\mathcal{L}(\\mathbf{w}) = \\sum_{i=1}^m \\left(\\sigma(\\mathbf{x}_i^\\top \\mathbf{w}) - y_i\\right) \\mathbf{x}_i = \\mathbf{X}^\\top (\\sigma(\\mathbf{X}\\mathbf{w}) - \\mathbf{y}). $$\n- Once the parameters $\\mathbf{w}^{(j)}$ are fitted on the training data of fold $j$, the NLL is calculated on the corresponding held-out validation set using these parameters.\n\nAfter iterating through all $k$ folds, the total NLL for each model is the sum of the NLLs from each of the $k$ validation sets. This total loss is then divided by the total number of samples, $n$, to obtain the average per-sample out-of-sample NLL, $\\overline{\\mathcal{L}}$.\n\nFinally, a decision is made by comparing $\\overline{\\mathcal{L}}_{\\text{BPS}}$ and $\\overline{\\mathcal{L}}_{\\text{DS}}$. The DS model is chosen (output $2$) only if its loss is strictly lower than the BPS model's loss by a margin greater than a tolerance $\\epsilon = 10^{-6}$. That is, if $\\overline{\\mathcal{L}}_{\\text{BPS}} > \\overline{\\mathcal{L}}_{\\text{DS}} + \\epsilon$. Otherwise, the simpler BPS model is chosen (output $1$), favoring parsimony in cases of near-equal performance. This procedure is repeated for all specified test cases.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.optimize import minimize\n\ndef _nll(w, X, y):\n    \"\"\"\n    Calculates the negative log-likelihood for logistic regression.\n    The formula is sum(log(1 + exp(z)) - y*z), which is numerically\n    stabilized using logaddexp(0, z) for log(1 + exp(z)).\n    \"\"\"\n    z = X @ w\n    loss = np.sum(np.logaddexp(0, z) - y * z)\n    return loss\n\ndef _grad_nll(w, X, y):\n    \"\"\"\n    Calculates the gradient of the negative log-likelihood.\n    The formula is X.T @ (p - y), where p is the predicted probability.\n    \"\"\"\n    z = X @ w\n    # Sigmoid function, numerically stable for large negative z\n    p = 1 / (1 + np.exp(-z))\n    grad = X.T @ (p - y)\n    return grad\n\ndef fit_logistic_regression(X, y):\n    \"\"\"\n    Fits a logistic regression model.\n    Assumes X already includes an intercept column.\n    \"\"\"\n    num_features = X.shape[1]\n    w0 = np.zeros(num_features)\n    \n    res = minimize(\n        _nll,\n        w0,\n        args=(X, y),\n        jac=_grad_nll,\n        method='BFGS'\n    )\n    \n    return res.x\n\ndef run_single_case(n, k, rho, w_diathesis, feature_scales, ground_truth, seed):\n    \"\"\"\n    Runs a single test case for model comparison.\n    \"\"\"\n    # 1. Setup Random Number Generator for reproducibility\n    rng = np.random.default_rng(seed)\n\n    # 2. Generate Synthetic Data\n    mus = feature_scales['mus']\n    sigmas = feature_scales['sigmas']\n    \n    z1 = rng.normal(0, 1, size=n)\n    z2 = rng.normal(0, 1, size=n)\n    z3 = rng.normal(0, 1, size=n)\n    \n    B = mus[0] + sigmas[0] * z1\n    P = mus[1] + sigmas[1] * (rho * z1 + np.sqrt(1 - rho**2) * z2)\n    S = mus[2] + sigmas[2] * z3\n    \n    if ground_truth['type'] == 'additive':\n        beta0, betaB, betaP, betaS = ground_truth['coefs']\n        z_true = beta0 + betaB * B + betaP * P + betaS * S\n    else:  # 'interaction'\n        w_b, w_p = w_diathesis\n        D = w_b * B + w_p * P\n        T = S\n        alpha0, alphaD, alphaT, alphaDT = ground_truth['coefs']\n        z_true = alpha0 + alphaD * D + alphaT * T + alphaDT * D * T\n\n    p_true = 1 / (1 + np.exp(-z_true))\n    y = rng.binomial(1, p_true, size=n)\n    \n    # 3. K-Fold Cross-Validation\n    indices = np.arange(n)\n    rng.shuffle(indices)\n    folds = np.array_split(indices, k)\n    \n    total_loss_bps = 0.0\n    total_loss_ds = 0.0\n    \n    w_b, w_p = w_diathesis\n\n    for i in range(k):\n        val_indices = folds[i]\n        train_indices = np.concatenate([folds[j] for j in range(k) if i != j])\n        y_train, y_val = y[train_indices], y[val_indices]\n\n        # --- Biopsychosocial Model ---\n        X_train_feats_bps = np.column_stack((B[train_indices], P[train_indices], S[train_indices]))\n        \n        mean_bps = np.mean(X_train_feats_bps, axis=0)\n        std_bps = np.std(X_train_feats_bps, axis=0)\n        std_bps[std_bps == 0] = 1.0 # Prevent division by zero\n        \n        X_train_std_bps = (X_train_feats_bps - mean_bps) / std_bps\n        X_train_int_bps = np.insert(X_train_std_bps, 0, 1, axis=1)\n        w_bps = fit_logistic_regression(X_train_int_bps, y_train)\n\n        X_val_feats_bps = np.column_stack((B[val_indices], P[val_indices], S[val_indices]))\n        X_val_std_bps = (X_val_feats_bps - mean_bps) / std_bps\n        X_val_int_bps = np.insert(X_val_std_bps, 0, 1, axis=1)\n        total_loss_bps += _nll(w_bps, X_val_int_bps, y_val)\n\n        # --- Diathesis-Stress Model ---\n        D_train = w_b * B[train_indices] + w_p * P[train_indices]\n        T_train = S[train_indices]\n        DT_train = D_train * T_train\n        X_train_feats_ds = np.column_stack((D_train, T_train, DT_train))\n        \n        mean_ds = np.mean(X_train_feats_ds, axis=0)\n        std_ds = np.std(X_train_feats_ds, axis=0)\n        std_ds[std_ds == 0] = 1.0\n        \n        X_train_std_ds = (X_train_feats_ds - mean_ds) / std_ds\n        X_train_int_ds = np.insert(X_train_std_ds, 0, 1, axis=1)\n        w_ds = fit_logistic_regression(X_train_int_ds, y_train)\n        \n        D_val = w_b * B[val_indices] + w_p * P[val_indices]\n        T_val = S[val_indices]\n        DT_val = D_val * T_val\n        X_val_feats_ds = np.column_stack((D_val, T_val, DT_val))\n        \n        X_val_std_ds = (X_val_feats_ds - mean_ds) / std_ds\n        X_val_int_ds = np.insert(X_val_std_ds, 0, 1, axis=1)\n        total_loss_ds += _nll(w_ds, X_val_int_ds, y_val)\n        \n    # 4. Final Comparison\n    avg_loss_bps = total_loss_bps / n\n    avg_loss_ds = total_loss_ds / n\n    epsilon = 1e-6\n\n    if avg_loss_bps > avg_loss_ds + epsilon:\n        return 2\n    else:\n        return 1\n\ndef solve():\n    test_cases = [\n        {\n            'n': 800, 'k': 5, 'rho': 0.2, 'w_diathesis': (0.7, 0.3), 'seed': 17,\n            'feature_scales': {'mus': (0, 0, 0), 'sigmas': (1, 1, 1)},\n            'ground_truth': {'type': 'additive', 'coefs': (-1.0, 0.8, 0.6, 0.5)}\n        },\n        {\n            'n': 1200, 'k': 5, 'rho': 0.1, 'w_diathesis': (0.6, 0.4), 'seed': 23,\n            'feature_scales': {'mus': (0, 0, 0), 'sigmas': (1, 1, 1)},\n            'ground_truth': {'type': 'interaction', 'coefs': (-2.0, 1.0, 0.3, 1.2)}\n        },\n        {\n            'n': 60, 'k': 3, 'rho': 0.0, 'w_diathesis': (0.5, 0.5), 'seed': 99,\n            'feature_scales': {'mus': (0, 0, 0), 'sigmas': (1, 1, 1)},\n            'ground_truth': {'type': 'additive', 'coefs': (-0.5, 0.5, 0.4, 0.4)}\n        },\n        {\n            'n': 1000, 'k': 5, 'rho': 0.9, 'w_diathesis': (0.5, 0.5), 'seed': 202,\n            'feature_scales': {'mus': (0, 0, 0), 'sigmas': (1, 1, 1)},\n            'ground_truth': {'type': 'interaction', 'coefs': (-1.5, 0.9, 0.3, 0.8)}\n        }\n    ]\n    \n    results = []\n    for case in test_cases:\n        result = run_single_case(**case)\n        results.append(result)\n        \n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        }
    ]
}