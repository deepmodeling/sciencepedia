{
    "hands_on_practices": [
        {
            "introduction": "The binomial model is a cornerstone of quantal analysis, offering a more general description of neurotransmitter release than the simple Poisson model. By deriving the Fano factor for amplitude, you will learn to mathematically dissect how variability arises from two distinct sources: the stochastic nature of vesicle release and the intrinsic fluctuations in quantal size. This practice is fundamental for interpreting experimental data where both factors are at play .",
            "id": "4012413",
            "problem": "Consider a synapse with $M$ statistically identical release sites. At each presynaptic action potential, each site independently releases at most one synaptic vesicle with probability $p$ (Bernoulli release), and failure otherwise. Let the postsynaptic amplitude contributed by a single released vesicle be a random variable $Q$ (the quantal amplitude), with finite mean $E[Q]=\\mu_{q}$ and variance $\\mathrm{Var}(Q)=\\sigma_{q}^{2}$. Assume $\\{Q_{i}\\}_{i=1}^{M}$ are independent and identically distributed (i.i.d.) copies of $Q$, and independent of the release indicators $\\{R_{i}\\}_{i=1}^{M}$, where $R_{i}\\in\\{0,1\\}$ denotes whether site $i$ released a vesicle on that trial.\n\nThe total postsynaptic amplitude on a trial is\n$$\nA \\;=\\; \\sum_{i=1}^{M} R_{i}\\,Q_{i}.\n$$\nDefine the Fano factor for amplitude as $F_{A}=\\mathrm{Var}(A)/E[A]$. Using only fundamental probabilistic definitions and properties of variance and expectation for independent random variables, derive a closed-form expression for $F_{A}$ in terms of $\\mu_{q}$, $\\sigma_{q}^{2}$, $M$, and $p$, and interpret how the resulting expression separates contributions from quantal amplitude variability versus release-count variability.\n\nThen specialize to the case of fixed quantal size, where $Q$ is deterministic and equal to a constant $q$ (so $\\sigma_{q}^{2}=0$ and $\\mu_{q}=q$), and compute the resulting $F_{A}$ under binomial release. Express your final answer as a single closed-form analytic expression. No rounding is required, and no units are requested; report the answer symbolically.",
            "solution": "The problem is first subjected to a validation check.\n\n### Step 1: Extract Givens\n- Number of release sites: $M$\n- Release probability per site: $p$\n- Release at each site is an independent Bernoulli trial.\n- Quantal amplitude per vesicle: A random variable $Q$ with mean $E[Q]=\\mu_{q}$ and variance $\\mathrm{Var}(Q)=\\sigma_{q}^{2}$.\n- Individual quantal amplitudes are i.i.d.: $\\{Q_{i}\\}_{i=1}^{M}$ are i.i.d. copies of $Q$.\n- Release indicators: $R_{i}\\in\\{0,1\\}$ for $i=1, \\dots, M$.\n- Independence: $\\{Q_{i}\\}$ and $\\{R_{i}\\}$ are independent collections of random variables.\n- Total postsynaptic amplitude: $A = \\sum_{i=1}^{M} R_{i}\\,Q_{i}$.\n- Definition of Fano factor: $F_{A}=\\mathrm{Var}(A)/E[A]$.\n- Special case: $Q$ is a deterministic constant $q$, which implies $\\mu_{q}=q$ and $\\sigma_{q}^{2}=0$.\n\n### Step 2: Validate Using Extracted Givens\n- **Scientifically Grounded:** The problem describes the binomial model of synaptic transmission, a foundational and widely used model in computational neuroscience for describing quantal release. The model is based on established biophysical and statistical principles.\n- **Well-Posed:** The problem provides all necessary definitions, variables, and statistical properties ($M, p, \\mu_q, \\sigma_q^2$, independence, i.i.d. conditions) to uniquely determine the Fano factor. The task is clear and leads to a unique analytical solution.\n- **Objective:** The problem is stated in precise, mathematical language, free from subjectivity or ambiguity.\n\n### Step 3: Verdict and Action\nThe problem is valid as it is scientifically sound, self-contained, and well-posed. A complete solution will be provided.\n\nThe objective is to derive the Fano factor for the total postsynaptic amplitude, $F_{A} = \\mathrm{Var}(A)/E[A]$. This requires calculating the expectation $E[A]$ and the variance $\\mathrm{Var}(A)$.\n\nFirst, we calculate the expectation of the total amplitude $A = \\sum_{i=1}^{M} R_{i}Q_{i}$. By the linearity of expectation:\n$$\nE[A] = E\\left[\\sum_{i=1}^{M} R_{i}Q_{i}\\right] = \\sum_{i=1}^{M} E[R_{i}Q_{i}]\n$$\nSince for each site $i$, the release indicator $R_i$ and the quantal amplitude $Q_i$ are independent, the expectation of their product is the product of their expectations:\n$$\nE[R_{i}Q_{i}] = E[R_{i}]E[Q_{i}]\n$$\nThe release indicator $R_i$ follows a Bernoulli distribution with probability of success $p$. Therefore, its expectation is $E[R_{i}] = 1 \\cdot P(R_i=1) + 0 \\cdot P(R_i=0) = p$. The expectation of the quantal amplitude is given as $E[Q_{i}] = \\mu_q$.\nSubstituting these back, we get:\n$$\nE[R_{i}Q_{i}] = p \\mu_q\n$$\nSince all $M$ sites are identical, the total expectation is:\n$$\nE[A] = \\sum_{i=1}^{M} p \\mu_q = M p \\mu_q\n$$\nNext, we calculate the variance of $A$. We can use the law of total variance, which states $\\mathrm{Var}(X) = E[\\mathrm{Var}(X|Y)] + \\mathrm{Var}(E[X|Y])$. Let $N = \\sum_{i=1}^{M} R_i$ be the total number of vesicles released in a trial. Since each $R_i$ is an independent Bernoulli trial with probability $p$, $N$ follows a binomial distribution, $N \\sim \\mathrm{Binomial}(M,p)$. The mean and variance of $N$ are $E[N]=Mp$ and $\\mathrm{Var}(N)=Mp(1-p)$.\n\nWe condition the amplitude $A$ on the number of released vesicles $N$. Given $N=k$, the total amplitude is the sum of $k$ i.i.d. quantal amplitudes:\n$$\nA|_{N=k} = \\sum_{j=1}^{k} Q_{j}\n$$\nThe conditional expectation of $A$ given $N=k$ is:\n$$\nE[A|N=k] = E\\left[\\sum_{j=1}^{k} Q_{j}\\right] = \\sum_{j=1}^{k} E[Q_{j}] = k \\mu_q\n$$\nSo, the random variable $E[A|N]$ is $N\\mu_q$.\nThe conditional variance of $A$ given $N=k$ is:\n$$\n\\mathrm{Var}(A|N=k) = \\mathrm{Var}\\left(\\sum_{j=1}^{k} Q_{j}\\right) = \\sum_{j=1}^{k} \\mathrm{Var}(Q_{j}) = k \\sigma_q^2\n$$\nThe last step follows because the $Q_j$ are independent. So, the random variable $\\mathrm{Var}(A|N)$ is $N\\sigma_q^2$.\n\nNow we apply the law of total variance:\n$$\n\\mathrm{Var}(A) = E[\\mathrm{Var}(A|N)] + \\mathrm{Var}(E[A|N])\n$$\nThe first term is:\n$$\nE[\\mathrm{Var}(A|N)] = E[N\\sigma_q^2] = \\sigma_q^2 E[N] = \\sigma_q^2 (Mp) = Mp\\sigma_q^2\n$$\nThe second term is:\n$$\n\\mathrm{Var}(E[A|N]) = \\mathrm{Var}(N\\mu_q) = \\mu_q^2 \\mathrm{Var}(N) = \\mu_q^2 (Mp(1-p))\n$$\nCombining these two terms gives the total variance of the amplitude:\n$$\n\\mathrm{Var}(A) = Mp\\sigma_q^2 + Mp(1-p)\\mu_q^2\n$$\nNow we compute the Fano factor $F_{A}$:\n$$\nF_{A} = \\frac{\\mathrm{Var}(A)}{E[A]} = \\frac{Mp\\sigma_q^2 + Mp(1-p)\\mu_q^2}{Mp\\mu_q}\n$$\nWe can separate this into two terms by dividing each term in the numerator by the denominator:\n$$\nF_{A} = \\frac{Mp\\sigma_q^2}{Mp\\mu_q} + \\frac{Mp(1-p)\\mu_q^2}{Mp\\mu_q} = \\frac{\\sigma_q^2}{\\mu_q} + (1-p)\\mu_q\n$$\nThis is the general expression for the Fano factor of the synaptic amplitude.\n\n**Interpretation:**\nThe expression $F_A = \\frac{\\sigma_q^2}{\\mu_q} + (1-p)\\mu_q$ elegantly separates the sources of variability.\n- The first term, $\\frac{\\sigma_q^2}{\\mu_q}$, depends only on the moments of the quantal amplitude distribution ($Q$). It represents the contribution from the variability of the response to a single vesicle. This term is sometimes written as $\\text{CV}_q^2 \\mu_q$, where $\\text{CV}_q = \\sigma_q / \\mu_q$ is the coefficient of variation of the quantal size.\n- The second term, $(1-p)\\mu_q$, reflects the contribution from the stochasticity of vesicle release. The number of released vesicles, $N$, is a binomial random variable with Fano factor $F_N = \\mathrm{Var}(N)/E[N] = (Mp(1-p))/(Mp) = 1-p$. Thus, the second term is precisely $F_N \\mu_q$, which is the Fano factor of the release count, scaled by the mean quantal amplitude.\n\nFinally, we specialize to the case of fixed quantal size. In this case, the quantal amplitude $Q$ is a deterministic constant $q$. This implies its mean is $\\mu_q = q$ and its variance is $\\sigma_q^2 = 0$.\nSubstituting these values into our general expression for $F_A$:\n$$\nF_{A} = \\frac{0}{q} + (1-p)q = 0 + (1-p)q = q(1-p)\n$$\nIn this simplified scenario, all variability comes from the binomial process of vesicle release, and the Fano factor of the amplitude is simply the Fano factor of the release count ($1-p$) multiplied by the constant amplitude of each quantum ($q$).",
            "answer": "$$\n\\boxed{q(1-p)}\n$$"
        },
        {
            "introduction": "While the binomial model is general, many synapses operate in a low-release-probability regime where it simplifies to the Poisson model, which represents the law of rare events. This exercise explores this important limit, demonstrating how a simple statistical measure—the Fano factor—becomes a powerful diagnostic tool. You will prove that the Fano factor equals the quantal size, a classic result used to test the hypothesis of fixed quantal size during manipulations of release probability .",
            "id": "4012460",
            "problem": "A single synapse is modeled as a large population of $N$ independent release sites, each of which releases a vesicle during a presynaptic action potential with a small probability $p$, producing a postsynaptic current contribution of fixed quantal size $q$ measured in picoamperes (pA). Assume linear summation and negligible receptor saturation and desensitization so that, if $K$ vesicles release in a trial, the excitatory postsynaptic current (EPSC) amplitude is $A = q K$. In the limit of large $N$ and small $p$ with $N p = \\lambda$ held fixed, the law of rare events implies that the vesicle count $K$ is distributed according to a Poisson distribution with mean $\\lambda$.\n\nStarting only from the definitions of the Poisson distribution and the standard definitions of expectation and variance, and the scaling properties of expectation and variance for deterministic linear transformations of random variables, derive closed-form expressions for $E[A]$, $\\mathrm{Var}(A)$, and the Fano factor of the amplitude, $F_{A} = \\mathrm{Var}(A)/E[A]$. Explain, based on the dependency of $F_{A}$ on $\\lambda$ and $q$, how $F_{A}$ can be used as a diagnostic for fixed quantal size in experimental manipulations that change $\\lambda$ by altering release probability while leaving $q$ unchanged.\n\nProvide the final answer as the closed-form expression for $F_{A}$ and, because $F_{A}$ has the same physical units as amplitude, express your answer in picoamperes (pA). No numerical rounding is required. The final answer must be a single analytic expression.",
            "solution": "The problem statement is first validated against the required criteria.\n\n### Step 1: Extract Givens\n- A synapse has a large number of independent release sites, $N$.\n- The probability of release at each site is small, $p$.\n- The contribution of a single vesicle is a fixed quantal size $q$, measured in picoamperes (pA).\n- The total excitatory postsynaptic current (EPSC) amplitude is $A = qK$, where $K$ is the number of vesicles released. This assumes linear summation and negligible saturation/desensitization.\n- In the limit of large $N$ and small $p$, with $Np = \\lambda$ held fixed, the number of released vesicles $K$ follows a Poisson distribution with mean $\\lambda$.\n- The task is to derive expressions for $E[A]$, $\\mathrm{Var}(A)$, and the Fano factor $F_{A} = \\mathrm{Var}(A)/E[A]$.\n- The derivation must use only the definition of the Poisson distribution, the definitions of expectation and variance, and the scaling properties of expectation and variance for linear transformations of random variables.\n- The task also requires an explanation of how $F_{A}$ can be used as a diagnostic tool.\n- The final answer is the expression for $F_A$.\n\n### Step 2: Validate Using Extracted Givens\n- **Scientifically Grounded**: The problem describes the quantal hypothesis of neurotransmitter release and its statistical modeling using the Poisson distribution. This is a foundational and scientifically well-established model in synaptic physiology and computational neuroscience. The assumptions are standard for a first-order analysis. The problem is scientifically sound.\n- **Well-Posed**: The problem is clearly defined. It provides a statistical model ($K \\sim \\mathrm{Poisson}(\\lambda)$) and a deterministic relationship ($A = qK$) and asks for the derivation of well-defined statistical measures ($E[A]$, $\\mathrm{Var}(A)$, $F_A$). A unique, stable, and meaningful solution exists.\n- **Objective**: The problem is stated in precise, objective, and quantitative language, free of subjective claims.\n- **Completeness and Consistency**: All necessary information for the derivation is provided. The constraints on the derivation (starting from first principles) are explicit. There are no contradictions. The instruction regarding the units of the final answer is unusual but physically consistent with the derived result, as the Fano factor will be shown to have units of current.\n- **Other criteria**: The problem is not unrealistic, ill-posed, trivial, or outside the realm of scientific verifiability. It is a standard textbook-level problem in theoretical neuroscience.\n\n### Step 3: Verdict and Action\nThe problem is valid. A complete solution will be provided.\n\n### Solution Derivation\n\nThe problem requires deriving the expectation, variance, and Fano factor of the EPSC amplitude $A$, starting from the first principles of a Poisson process. The number of released vesicles, $K$, is a random variable following a Poisson distribution with mean $\\lambda$. The probability mass function (PMF) for $K$ is:\n$$\nP(K=k) = \\frac{\\lambda^k \\exp(-\\lambda)}{k!} \\quad \\text{for } k = 0, 1, 2, \\dots\n$$\n\nFirst, we must derive the expectation, $E[K]$, and variance, $\\mathrm{Var}(K)$, for the Poisson-distributed variable $K$.\n\nThe expectation $E[K]$ is defined as:\n$$\nE[K] = \\sum_{k=0}^{\\infty} k \\cdot P(K=k) = \\sum_{k=0}^{\\infty} k \\frac{\\lambda^k \\exp(-\\lambda)}{k!}\n$$\nThe term for $k=0$ is $0$, so the sum can start from $k=1$:\n$$\nE[K] = \\sum_{k=1}^{\\infty} k \\frac{\\lambda^k \\exp(-\\lambda)}{k!} = \\sum_{k=1}^{\\infty} \\frac{\\lambda^k \\exp(-\\lambda)}{(k-1)!}\n$$\nFactoring out $\\lambda$ and $\\exp(-\\lambda)$:\n$$\nE[K] = \\lambda \\exp(-\\lambda) \\sum_{k=1}^{\\infty} \\frac{\\lambda^{k-1}}{(k-1)!}\n$$\nLet $j = k-1$. As $k$ goes from $1$ to $\\infty$, $j$ goes from $0$ to $\\infty$.\n$$\nE[K] = \\lambda \\exp(-\\lambda) \\sum_{j=0}^{\\infty} \\frac{\\lambda^j}{j!}\n$$\nThe summation is the Taylor series expansion for $\\exp(\\lambda)$, so $\\sum_{j=0}^{\\infty} \\frac{\\lambda^j}{j!} = \\exp(\\lambda)$.\n$$\nE[K] = \\lambda \\exp(-\\lambda) \\exp(\\lambda) = \\lambda\n$$\nThis confirms that the mean of the Poisson distribution is indeed $\\lambda$.\n\nNext, we derive the variance $\\mathrm{Var}(K) = E[K^2] - (E[K])^2$. We already have $E[K]$, so we need to find $E[K^2]$. It is convenient to first calculate $E[K(K-1)]$:\n$$\nE[K(K-1)] = \\sum_{k=0}^{\\infty} k(k-1) \\frac{\\lambda^k \\exp(-\\lambda)}{k!}\n$$\nThe terms for $k=0$ and $k=1$ are $0$, so the sum starts from $k=2$:\n$$\nE[K(K-1)] = \\sum_{k=2}^{\\infty} k(k-1) \\frac{\\lambda^k \\exp(-\\lambda)}{k!} = \\sum_{k=2}^{\\infty} \\frac{\\lambda^k \\exp(-\\lambda)}{(k-2)!}\n$$\nFactoring out $\\lambda^2$ and $\\exp(-\\lambda)$:\n$$\nE[K(K-1)] = \\lambda^2 \\exp(-\\lambda) \\sum_{k=2}^{\\infty} \\frac{\\lambda^{k-2}}{(k-2)!}\n$$\nLet $j = k-2$. As $k$ goes from $2$ to $\\infty$, $j$ goes from $0$ to $\\infty$.\n$$\nE[K(K-1)] = \\lambda^2 \\exp(-\\lambda) \\sum_{j=0}^{\\infty} \\frac{\\lambda^j}{j!} = \\lambda^2 \\exp(-\\lambda) \\exp(\\lambda) = \\lambda^2\n$$\nNow we can find $E[K^2]$ using the relation $E[K^2] = E[K(K-1) + K] = E[K(K-1)] + E[K]$.\n$$\nE[K^2] = \\lambda^2 + \\lambda\n$$\nFinally, we can calculate the variance of $K$:\n$$\n\\mathrm{Var}(K) = E[K^2] - (E[K])^2 = (\\lambda^2 + \\lambda) - (\\lambda)^2 = \\lambda\n$$\nA key property of the Poisson distribution is that its variance is equal to its mean.\n\nNow, we use these results for $K$ to find the statistical properties of the EPSC amplitude, $A$, using the linear relationship $A=qK$, where $q$ is a constant.\n\nThe expectation of $A$ is found using the scaling property of expectation, $E[c X] = c E[X]$:\n$$\nE[A] = E[qK] = qE[K] = q\\lambda\n$$\n\nThe variance of $A$ is found using the scaling property of variance, $\\mathrm{Var}(c X) = c^2 \\mathrm{Var}(X)$:\n$$\n\\mathrm{Var}(A) = \\mathrm{Var}(qK) = q^2\\mathrm{Var}(K) = q^2\\lambda\n$$\n\nFinally, we derive the Fano factor of the amplitude, $F_A$:\n$$\nF_{A} = \\frac{\\mathrm{Var}(A)}{E[A]} = \\frac{q^2\\lambda}{q\\lambda} = q\n$$\n\n### Explanation of the Diagnostic Use of the Fano Factor\n\nThe derived result, $F_A = q$, is a powerful statement. It indicates that under the assumptions of the simple Poisson model of synaptic release (large $N$, small and uniform $p$, constant quantal size $q$), the Fano factor of the EPSC amplitude distribution is exactly equal to the quantal size, $q$.\n\nThis relationship provides a direct experimental diagnostic. Many experimental manipulations, such as changing the extracellular calcium concentration or applying certain neuromodulators, are known to alter the presynaptic release probability, $p$. Since the mean number of released vesicles is $\\lambda = Np$, a change in $p$ will cause a corresponding change in $\\lambda$. Consequently, both the mean amplitude $E[A] = q\\lambda$ and the variance of the amplitude $\\mathrm{Var}(A) = q^2\\lambda$ will change.\n\nHowever, if the quantal size $q$ (the postsynaptic response to a single vesicle) is a fixed property of the synapse that does not change with the presynaptic manipulation, then the Fano factor $F_A$ should remain constant across these different experimental conditions, because $F_A = q$.\n\nTherefore, an experimenter can measure the distribution of EPSC amplitudes under various conditions that alter the mean release rate $\\lambda$. For each condition, they can compute the mean $E[A]$ and variance $\\mathrm{Var}(A)$. A plot of $\\mathrm{Var}(A)$ versus $E[A]$ should yield a straight line passing through the origin. The slope of this line is $\\frac{\\mathrm{Var}(A)}{E[A]} = F_A$. If this slope is constant across conditions, it provides strong evidence for the hypothesis that quantal size $q$ is fixed and release is governed by simple Poisson statistics. The value of this constant slope provides a direct estimate of the quantal size $q$. Any deviation from a constant Fano factor would imply a violation of the model's assumptions, such as non-uniform release probabilities, changes in $q$ itself, or more complex release statistics.\n\nThe problem's prompt regarding units is physically correct. If $q$ is in picoamperes (pA), then $E[A]$ is in pA and $\\mathrm{Var}(A)$ is in $\\mathrm{pA}^2$. The Fano factor $F_A = \\mathrm{Var}(A)/E[A]$ thus has units of $\\mathrm{pA}^2/\\mathrm{pA} = \\mathrm{pA}$, the same as the quantal size $q$.",
            "answer": "$$\n\\boxed{q}\n$$"
        },
        {
            "introduction": "Theoretical models provide a clean framework, but real experimental data are always subject to measurement limitations and noise. This practice confronts a common and critical challenge: the inability to detect very small synaptic events that are buried in noise, a problem known as truncation. By deriving the moments of a truncated Gaussian distribution, you will gain a rigorous understanding of how this experimental constraint systematically biases estimates of quantal parameters, a crucial consideration for accurate data analysis .",
            "id": "4012454",
            "problem": "A single synapse is repeatedly stimulated under voltage clamp, and the peak excitatory postsynaptic current is measured for each trial. Let the true quantal amplitude per vesicle, denoted by $Q$, vary across trials due to vesicle size and receptor state fluctuations. Assume $Q$ is well approximated by a Gaussian random variable $Q \\sim \\mathcal{N}(\\mu_{q}, \\sigma_{q}^{2})$. Let the measurement noise, denoted by $N$, be independent of $Q$ and Gaussian $N \\sim \\mathcal{N}(0, \\sigma_{n}^{2})$. The observed peak amplitude per trial is then $A = Q + N$. Trials are labeled as detected if the measured peak exceeds a fixed detection threshold $T$, that is, if $A \\geq T$; otherwise, the trial is labeled as a failure and discarded.\n\nUsing only fundamental definitions of probability density functions, cumulative distribution functions, and conditional expectation, explain why thresholding at $T$ biases the estimated quantal size distribution when one analyzes only detected events. Then, starting from first principles and without invoking shortcut formulas, derive the exact expressions for the conditional mean and conditional variance of the truncated observed amplitude distribution, $\\mathbb{E}[A \\mid A \\geq T]$ and $\\mathrm{Var}(A \\mid A \\geq T)$, in terms of $\\mu_{q}$, $\\sigma_{q}$, $\\sigma_{n}$, and $T$. Express your final results using the standard normal probability density function $\\phi(x)$ and cumulative distribution function $\\Phi(x)$, defined by $\\phi(x) = \\frac{1}{\\sqrt{2\\pi}} \\exp\\!\\big(-\\frac{x^{2}}{2}\\big)$ and $\\Phi(x) = \\int_{-\\infty}^{x} \\phi(u)\\, du$.\n\nProvide your final answer as a single closed-form analytic expression containing both the conditional mean and conditional variance arranged as a row in a $1 \\times 2$ matrix. No numerical rounding is required, and no units should be included in your final expressions.",
            "solution": "The problem statement is scientifically grounded, well-posed, objective, and internally consistent. It presents a standard, solvable problem in computational neuroscience and statistics concerning the moments of a truncated normal distribution. All necessary variables and conditions are provided for a formal derivation.\n\nFirst, we address the qualitative question of why thresholding biases the estimated quantal size distribution. The observed amplitude $A$ is the sum of the true quantal amplitude $Q$ and measurement noise $N$. The distribution of $A$ is a complete probability distribution, in this case, a Gaussian. When an experimenter only analyzes trials for which the measured amplitude $A$ exceeds a threshold $T$ (i.e., $A \\geq T$), they are performing a post-selection of the data. This selection process discards all data points in the lower tail of the distribution of $A$, specifically those in the interval $(-\\infty, T)$. The resulting dataset is no longer a sample from the original distribution of $A$, but rather from a new, conditional distribution truncated at $T$.\n\nBy its very nature, truncating a distribution from below and discarding the lower values systematically removes observations that are smaller than the threshold. This necessarily increases the sample mean of the remaining observations. The mean of the truncated distribution, $\\mathbb{E}[A \\mid A \\geq T]$, will be greater than the mean of the original distribution, $\\mathbb{E}[A]$. An estimate of the mean quantal size based on this selected, truncated sample will therefore be biased, resulting in an overestimation of the true mean quantal size, $\\mu_q$. The variance of the sample is also affected, as the shape of the distribution is fundamentally altered by the truncation.\n\nNow, we proceed with the formal derivation of the conditional mean and variance.\n\nThe true quantal amplitude $Q$ and the measurement noise $N$ are given as independent Gaussian random variables:\n$Q \\sim \\mathcal{N}(\\mu_{q}, \\sigma_{q}^{2})$\n$N \\sim \\mathcal{N}(0, \\sigma_{n}^{2})$\n\nThe observed peak amplitude is $A = Q + N$. Since the sum of independent Gaussian random variables is also a Gaussian random variable, the distribution of $A$ is Gaussian.\nThe mean of $A$ is $\\mu_{A} = \\mathbb{E}[A] = \\mathbb{E}[Q + N] = \\mathbb{E}[Q] + \\mathbb{E}[N] = \\mu_{q} + 0 = \\mu_{q}$.\nThe variance of $A$ is $\\sigma_{A}^{2} = \\mathrm{Var}(A) = \\mathrm{Var}(Q + N) = \\mathrm{Var}(Q) + \\mathrm{Var}(N) = \\sigma_{q}^{2} + \\sigma_{n}^{2}$, since $Q$ and $N$ are independent.\nThus, $A \\sim \\mathcal{N}(\\mu_{A}, \\sigma_{A}^{2})$, where $\\mu_{A} = \\mu_{q}$ and $\\sigma_{A}^{2} = \\sigma_{q}^{2} + \\sigma_{n}^{2}$.\nThe probability density function (PDF) of $A$ is:\n$$f_{A}(a) = \\frac{1}{\\sqrt{2\\pi}\\sigma_{A}} \\exp\\left(-\\frac{(a-\\mu_{A})^{2}}{2\\sigma_{A}^{2}}\\right)$$\nWe are interested in the distribution of $A$ conditional on the event $A \\geq T$. The probability of this event is:\n$$P(A \\geq T) = \\int_{T}^{\\infty} f_{A}(a) \\, da$$\nTo evaluate this, we standardize the variable $A$. Let $Z = \\frac{A - \\mu_{A}}{\\sigma_{A}}$, where $Z \\sim \\mathcal{N}(0, 1)$. The condition $A \\geq T$ becomes $Z \\geq \\frac{T - \\mu_{A}}{\\sigma_{A}}$. Let's define the normalized threshold $\\alpha = \\frac{T - \\mu_{A}}{\\sigma_{A}}$.\nThen, $P(A \\geq T) = P(Z \\geq \\alpha) = \\int_{\\alpha}^{\\infty} \\phi(z) \\, dz = 1 - \\Phi(\\alpha)$, where $\\phi(z)$ and $\\Phi(z)$ are the standard normal PDF and CDF, respectively.\n\nThe conditional PDF of $A$ given $A \\geq T$ is:\n$$f_{A|A \\geq T}(a) = \\begin{cases} \\frac{f_{A}(a)}{P(A \\geq T)} & \\text{if } a \\geq T \\\\ 0 & \\text{if } a < T \\end{cases} = \\frac{f_{A}(a)}{1 - \\Phi(\\alpha)} \\quad \\text{for } a \\geq T$$\nThe conditional mean $\\mathbb{E}[A \\mid A \\geq T]$ is calculated by definition:\n$$\\mathbb{E}[A \\mid A \\geq T] = \\int_{-\\infty}^{\\infty} a f_{A|A \\geq T}(a) \\, da = \\frac{1}{1 - \\Phi(\\alpha)} \\int_{T}^{\\infty} a f_{A}(a) \\, da$$\nWe evaluate the integral $\\int_{T}^{\\infty} a f_{A}(a) \\, da$ using the substitution $a = \\sigma_{A}z + \\mu_{A}$, so $da = \\sigma_{A}dz$. The lower limit of integration becomes $\\alpha = (T-\\mu_A)/\\sigma_A$.\n$$ \\int_{T}^{\\infty} a f_{A}(a) \\, da = \\int_{\\alpha}^{\\infty} (\\sigma_{A}z + \\mu_{A}) \\frac{1}{\\sqrt{2\\pi}\\sigma_{A}} \\exp\\left(-\\frac{z^{2}}{2}\\right) (\\sigma_{A}dz) $$\n$$ = \\int_{\\alpha}^{\\infty} (\\sigma_{A}z + \\mu_{A}) \\phi(z) \\, dz = \\sigma_{A} \\int_{\\alpha}^{\\infty} z \\phi(z) \\, dz + \\mu_{A} \\int_{\\alpha}^{\\infty} \\phi(z) \\, dz $$\nThe first integral is $\\int z \\phi(z) dz = \\int \\frac{z}{\\sqrt{2\\pi}} \\exp(-z^{2}/2) dz = -\\frac{1}{\\sqrt{2\\pi}} \\exp(-z^{2}/2) = -\\phi(z)$. So, $\\int_{\\alpha}^{\\infty} z \\phi(z) \\, dz = [-\\phi(z)]_{\\alpha}^{\\infty} = 0 - (-\\phi(\\alpha)) = \\phi(\\alpha)$.\nThe second integral is $\\int_{\\alpha}^{\\infty} \\phi(z) \\, dz = 1 - \\Phi(\\alpha)$.\nSubstituting these back:\n$$ \\int_{T}^{\\infty} a f_{A}(a) \\, da = \\sigma_{A}\\phi(\\alpha) + \\mu_{A}(1 - \\Phi(\\alpha)) $$\nTherefore, the conditional mean is:\n$$ \\mathbb{E}[A \\mid A \\geq T] = \\frac{\\sigma_{A}\\phi(\\alpha) + \\mu_{A}(1 - \\Phi(\\alpha))}{1 - \\Phi(\\alpha)} = \\mu_{A} + \\sigma_{A} \\frac{\\phi(\\alpha)}{1 - \\Phi(\\alpha)} $$\nNext, we derive the conditional variance $\\mathrm{Var}(A \\mid A \\geq T) = \\mathbb{E}[A^{2} \\mid A \\geq T] - (\\mathbb{E}[A \\mid A \\geq T])^{2}$. We first need the conditional second moment, $\\mathbb{E}[A^{2} \\mid A \\geq T]$.\n$$ \\mathbb{E}[A^{2} \\mid A \\geq T] = \\frac{1}{1 - \\Phi(\\alpha)} \\int_{T}^{\\infty} a^{2} f_{A}(a) \\, da $$\nWe evaluate the integral $\\int_{T}^{\\infty} a^{2} f_{A}(a) \\, da$ with the same substitution:\n$$ \\int_{T}^{\\infty} a^{2} f_{A}(a) \\, da = \\int_{\\alpha}^{\\infty} (\\sigma_{A}z + \\mu_{A})^{2} \\phi(z) \\, dz $$\n$$ = \\int_{\\alpha}^{\\infty} (\\sigma_{A}^{2}z^{2} + 2\\mu_{A}\\sigma_{A}z + \\mu_{A}^{2}) \\phi(z) \\, dz $$\n$$ = \\sigma_{A}^{2} \\int_{\\alpha}^{\\infty} z^{2} \\phi(z) \\, dz + 2\\mu_{A}\\sigma_{A} \\int_{\\alpha}^{\\infty} z \\phi(z) \\, dz + \\mu_{A}^{2} \\int_{\\alpha}^{\\infty} \\phi(z) \\, dz $$\nWe need to evaluate $\\int_{\\alpha}^{\\infty} z^{2} \\phi(z) \\, dz$. We use integration by parts with $u=z$ and $dv = z\\phi(z)dz$. Then $du=dz$ and $v=-\\phi(z)$.\n$$ \\int_{\\alpha}^{\\infty} z^{2} \\phi(z) \\, dz = [-z\\phi(z)]_{\\alpha}^{\\infty} - \\int_{\\alpha}^{\\infty} (-\\phi(z)) \\, dz = \\alpha\\phi(\\alpha) + \\int_{\\alpha}^{\\infty} \\phi(z) \\, dz = \\alpha\\phi(\\alpha) + 1 - \\Phi(\\alpha) $$\nSubstituting the results for the three integrals:\n$$ \\int_{T}^{\\infty} a^{2} f_{A}(a) \\, da = \\sigma_{A}^{2}(\\alpha\\phi(\\alpha) + 1 - \\Phi(\\alpha)) + 2\\mu_{A}\\sigma_{A}\\phi(\\alpha) + \\mu_{A}^{2}(1 - \\Phi(\\alpha)) $$\nSo, the conditional second moment is:\n$$ \\mathbb{E}[A^{2} \\mid A \\geq T] = \\frac{1}{1 - \\Phi(\\alpha)} \\left[ \\sigma_{A}^{2}(\\alpha\\phi(\\alpha) + 1 - \\Phi(\\alpha)) + 2\\mu_{A}\\sigma_{A}\\phi(\\alpha) + \\mu_{A}^{2}(1 - \\Phi(\\alpha)) \\right] $$\n$$ = \\sigma_{A}^{2}\\left(1 + \\frac{\\alpha\\phi(\\alpha)}{1 - \\Phi(\\alpha)}\\right) + 2\\mu_{A}\\sigma_{A}\\frac{\\phi(\\alpha)}{1 - \\Phi(\\alpha)} + \\mu_{A}^{2} $$\nNow we find the variance:\n$$ \\mathrm{Var}(A \\mid A \\geq T) = \\mathbb{E}[A^{2} \\mid A \\geq T] - (\\mathbb{E}[A \\mid A \\geq T])^{2} $$\n$$ = \\left[ \\sigma_{A}^{2}\\left(1 + \\frac{\\alpha\\phi(\\alpha)}{1 - \\Phi(\\alpha)}\\right) + 2\\mu_{A}\\sigma_{A}\\frac{\\phi(\\alpha)}{1 - \\Phi(\\alpha)} + \\mu_{A}^{2} \\right] - \\left[ \\mu_{A} + \\sigma_{A} \\frac{\\phi(\\alpha)}{1 - \\Phi(\\alpha)} \\right]^{2} $$\n$$ = \\left[ \\sigma_{A}^{2} + \\sigma_{A}^{2}\\frac{\\alpha\\phi(\\alpha)}{1 - \\Phi(\\alpha)} + 2\\mu_{A}\\sigma_{A}\\frac{\\phi(\\alpha)}{1 - \\Phi(\\alpha)} + \\mu_{A}^{2} \\right] - \\left[ \\mu_{A}^{2} + 2\\mu_{A}\\sigma_{A}\\frac{\\phi(\\alpha)}{1 - \\Phi(\\alpha)} + \\sigma_{A}^{2} \\left(\\frac{\\phi(\\alpha)}{1 - \\Phi(\\alpha)}\\right)^{2} \\right] $$\nAfter cancellations, we are left with:\n$$ \\mathrm{Var}(A \\mid A \\geq T) = \\sigma_{A}^{2} + \\sigma_{A}^{2}\\frac{\\alpha\\phi(\\alpha)}{1 - \\Phi(\\alpha)} - \\sigma_{A}^{2} \\left(\\frac{\\phi(\\alpha)}{1 - \\Phi(\\alpha)}\\right)^{2} $$\n$$ = \\sigma_{A}^{2} \\left[ 1 + \\frac{\\alpha\\phi(\\alpha)}{1 - \\Phi(\\alpha)} - \\left(\\frac{\\phi(\\alpha)}{1 - \\Phi(\\alpha)}\\right)^{2} \\right] $$\nFinally, we substitute back $\\mu_{A} = \\mu_{q}$, $\\sigma_{A}^{2} = \\sigma_{q}^{2} + \\sigma_{n}^{2}$, and $\\alpha = \\frac{T - \\mu_{q}}{\\sqrt{\\sigma_{q}^{2} + \\sigma_{n}^{2}}}$.\nThe conditional mean is:\n$$ \\mathbb{E}[A \\mid A \\geq T] = \\mu_{q} + \\sqrt{\\sigma_{q}^{2} + \\sigma_{n}^{2}} \\cdot \\frac{\\phi\\left(\\frac{T - \\mu_{q}}{\\sqrt{\\sigma_{q}^{2} + \\sigma_{n}^{2}}}\\right)}{1-\\Phi\\left(\\frac{T - \\mu_{q}}{\\sqrt{\\sigma_{q}^{2} + \\sigma_{n}^{2}}}\\right)} $$\nThe conditional variance is:\n$$ \\mathrm{Var}(A \\mid A \\geq T) = (\\sigma_{q}^{2} + \\sigma_{n}^{2}) \\left[ 1 + \\left(\\frac{T - \\mu_{q}}{\\sqrt{\\sigma_{q}^{2} + \\sigma_{n}^{2}}}\\right)\\frac{\\phi\\left(\\frac{T - \\mu_{q}}{\\sqrt{\\sigma_{q}^{2} + \\sigma_{n}^{2}}}\\right)}{1 - \\Phi\\left(\\frac{T - \\mu_{q}}{\\sqrt{\\sigma_{q}^{2} + \\sigma_{n}^{2}}}\\right)} - \\left(\\frac{\\phi\\left(\\frac{T - \\mu_{q}}{\\sqrt{\\sigma_{q}^{2} + \\sigma_{n}^{2}}}\\right)}{1 - \\Phi\\left(\\frac{T - \\mu_{q}}{\\sqrt{\\sigma_{q}^{2} + \\sigma_{n}^{2}}}\\right)}\\right)^{2} \\right] $$\nThese expressions provide the exact truncated moments as requested.",
            "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n\\mu_{q} + \\sqrt{\\sigma_{q}^{2} + \\sigma_{n}^{2}} \\frac{\\phi\\left(\\frac{T - \\mu_{q}}{\\sqrt{\\sigma_{q}^{2} + \\sigma_{n}^{2}}}\\right)}{1 - \\Phi\\left(\\frac{T - \\mu_{q}}{\\sqrt{\\sigma_{q}^{2} + \\sigma_{n}^{2}}}\\right)} & (\\sigma_{q}^{2} + \\sigma_{n}^{2}) \\left[ 1 + \\frac{T - \\mu_{q}}{\\sqrt{\\sigma_{q}^{2} + \\sigma_{n}^{2}}} \\frac{\\phi\\left(\\frac{T - \\mu_{q}}{\\sqrt{\\sigma_{q}^{2} + \\sigma_{n}^{2}}}\\right)}{1 - \\Phi\\left(\\frac{T - \\mu_{q}}{\\sqrt{\\sigma_{q}^{2} + \\sigma_{n}^{2}}}\\right)} - \\left( \\frac{\\phi\\left(\\frac{T - \\mu_{q}}{\\sqrt{\\sigma_{q}^{2} + \\sigma_{n}^{2}}}\\right)}{1 - \\Phi\\left(\\frac{T - \\mu_{q}}{\\sqrt{\\sigma_{q}^{2} + \\sigma_{n}^{2}}}\\right)} \\right)^{2} \\right]\n\\end{pmatrix}\n}\n$$"
        }
    ]
}