{
    "hands_on_practices": [
        {
            "introduction": "海马索引理论的核心在于，一个紧凑的海马“索引”能够与广泛分布的皮层特征建立连接。这个练习将探讨赫布可塑性（Hebbian plasticity）作为建立这些连接的基本学习规则，并量化随着更多记忆的存储，这些突触连接的总体强度如何增长，从而帮助我们理解索引的物理基础。通过的计算，您可以深入了解记忆存储如何具体地改变神经回路的连接权重。",
            "id": "3988866",
            "problem": "考虑一个简化的海马索引理论模型，其中一个由 $N_{H}$ 个海马索引单元组成的群体与一个由 $N_{C}$ 个特征单元组成的分布式皮层群体相互绑定。每个事件 $p \\in \\{1,\\dots,P\\}$ 由一个海马索引向量 $h^{(p)} \\in \\{0,1\\}^{N_{H}}$ 和一个皮层模式向量 $x^{(p)} \\in \\{0,1\\}^{N_{C}}$ 表示。假设以下基础建模假设，这些假设基于 Hebbian 假设以及在皮层和海马体中的稀疏编码观察：\n\n- 对于每个事件 $p$，每个分量 $h_{i}^{(p)}$ 和 $x_{j}^{(p)}$ 都是一个独立的伯努利随机变量，取值为 $1$ 的概率为 $a \\in (0,1)$，否则为 $0$。这些变量在索引 $i$、$j$ 和事件 $p$ 之间相互独立。\n- 突触权重初始化为 $0$，并根据一个 Hebbian 外积法则在每个事件中更新一次，该法则将活跃的海马索引与同时活跃的皮层特征绑定起来：\n$$\n\\Delta W_{CH} \\;=\\; \\eta \\, h^{(p)} \\big(x^{(p)}\\big)^{\\top} ,\n$$\n其中 $W_{CH} \\in \\mathbb{R}^{N_{H} \\times N_{C}}$ 且 $\\eta > 0$ 是一个学习率。回忆时的海马到皮层重激活可以通过 $x_{\\mathrm{reinst}} \\,=\\, W_{CH}^{\\top} h$ 产生，这与 $W_{CH}$ 通过其转置存储海马到皮层的绑定是一致的。\n\n仅从这些假设出发，推导在存储了 $P$ 个统计独立的事件后，权重矩阵的弗罗贝尼乌斯范数平方的期望值的解析表达式：\n$$\n\\mathbb{E}\\!\\left[\\left\\| W_{CH}^{(P)} \\right\\|_{F}^{2}\\right] ,\n$$\n该表达式应为 $N_{H}$、$N_{C}$、$\\eta$、$P$ 和 $a$ 的函数。请用闭合形式表达你的最终答案。不需要进行数值近似或四舍五入。",
            "solution": "问题陈述是计算神经科学中一个有效且适定的问题。所有变量、参数和统计假设都得到了清晰的定义，从而可以进行严谨的数学推导。我现在开始进行求解。\n\n目标是计算在 $P$ 个事件之后权重矩阵 $W_{CH}^{(P)}$ 的弗罗贝尼乌斯范数平方的期望值。权重矩阵由从初始状态 $W_{CH}^{(0)} = 0$ 开始的更新累加给出：\n$$\nW_{CH}^{(P)} = \\sum_{p=1}^{P} \\eta \\, h^{(p)} (x^{(p)})^{\\top}\n$$\n其中 $\\eta$ 是学习率，$h^{(p)} \\in \\{0,1\\}^{N_H}$ 是事件 $p$ 的海马索引向量，$x^{(p)} \\in \\{0,1\\}^{N_C}$ 是皮层模式向量。权重矩阵的分量为：\n$$\nW_{CH, ij}^{(P)} = \\eta \\sum_{p=1}^{P} h_i^{(p)} x_j^{(p)}\n$$\n对于 $i \\in \\{1,\\dots,N_H\\}$ 和 $j \\in \\{1,\\dots,N_C\\}$。\n\n$W_{CH}^{(P)}$ 的弗罗贝尼乌斯范数平方是其所有元素平方的总和：\n$$\n\\left\\| W_{CH}^{(P)} \\right\\|_{F}^{2} = \\sum_{i=1}^{N_H} \\sum_{j=1}^{N_C} \\left( W_{CH, ij}^{(P)} \\right)^2\n$$\n我们需要求解期望值 $\\mathbb{E}\\!\\left[\\left\\| W_{CH}^{(P)} \\right\\|_{F}^{2}\\right]$。利用期望算子的线性性质，我们可以写出：\n$$\n\\mathbb{E}\\!\\left[\\left\\| W_{CH}^{(P)} \\right\\|_{F}^{2}\\right] = \\mathbb{E}\\!\\left[ \\sum_{i=1}^{N_H} \\sum_{j=1}^{N_C} \\left( W_{CH, ij}^{(P)} \\right)^2 \\right] = \\sum_{i=1}^{N_H} \\sum_{j=1}^{N_C} \\mathbb{E}\\!\\left[ \\left( W_{CH, ij}^{(P)} \\right)^2 \\right]\n$$\n问题陈述指出，对于所有的 $i, j, p$，向量分量 $h_i^{(p)}$ 和 $x_j^{(p)}$ 都是独立同分布（i.i.d.）的伯努利随机变量。因此，权重 $W_{CH, ij}^{(P)}$ 的统计特性对于所有索引对 $(i,j)$ 都是相同的。这意味着期望值 $\\mathbb{E}\\!\\left[ \\left( W_{CH, ij}^{(P)} \\right)^2 \\right]$ 对于所有的 $i, j$ 都是一个常数。因此我们可以简化这个和式：\n$$\n\\mathbb{E}\\!\\left[\\left\\| W_{CH}^{(P)} \\right\\|_{F}^{2}\\right] = N_H N_C \\, \\mathbb{E}\\!\\left[ \\left( W_{CH, ij}^{(P)} \\right)^2 \\right]\n$$\n现在，我们来计算单个权重元素平方的期望值：\n$$\n\\mathbb{E}\\!\\left[ \\left( W_{CH, ij}^{(P)} \\right)^2 \\right] = \\mathbb{E}\\!\\left[ \\left( \\eta \\sum_{p=1}^{P} h_i^{(p)} x_j^{(p)} \\right)^2 \\right] = \\eta^2 \\, \\mathbb{E}\\!\\left[ \\left( \\sum_{p=1}^{P} h_i^{(p)} x_j^{(p)} \\right)^2 \\right]\n$$\n展开这个和的平方：\n$$\n\\left( \\sum_{p=1}^{P} h_i^{(p)} x_j^{(p)} \\right)^2 = \\left( \\sum_{p=1}^{P} h_i^{(p)} x_j^{(p)} \\right) \\left( \\sum_{q=1}^{P} h_i^{(q)} x_j^{(q)} \\right) = \\sum_{p=1}^{P} \\sum_{q=1}^{P} h_i^{(p)} x_j^{(p)} h_i^{(q)} x_j^{(q)}\n$$\n取期望值得到：\n$$\n\\mathbb{E}\\!\\left[ \\left( \\sum_{p=1}^{P} h_i^{(p)} x_j^{(p)} \\right)^2 \\right] = \\sum_{p=1}^{P} \\sum_{q=1}^{P} \\mathbb{E}\\!\\left[ h_i^{(p)} h_i^{(q)} x_j^{(p)} x_j^{(q)} \\right]\n$$\n我们可以将这个双重求和分为两种情况：$p=q$ 的对角项和 $p \\neq q$ 的非对角项。\n\n情况 1: $p=q$。\n这些项的形式为 $\\mathbb{E}\\!\\left[ h_i^{(p)} h_i^{(p)} x_j^{(p)} x_j^{(p)} \\right] = \\mathbb{E}\\!\\left[ (h_i^{(p)})^2 (x_j^{(p)})^2 \\right]$。\n变量 $h_i^{(p)}$ 和 $x_j^{(p)}$ 是伯努利随机变量，取值于 $\\{0,1\\}$。因此，$(h_i^{(p)})^2 = h_i^{(p)}$ 且 $(x_j^{(p)})^2 = x_j^{(p)}$。期望值变为 $\\mathbb{E}\\!\\left[ h_i^{(p)} x_j^{(p)} \\right]$。\n由于 $h_i^{(p)}$ 和 $x_j^{(p)}$ 是独立的，$\\mathbb{E}\\!\\left[ h_i^{(p)} x_j^{(p)} \\right] = \\mathbb{E}\\!\\left[ h_i^{(p)} \\right] \\mathbb{E}\\!\\left[ x_j^{(p)} \\right]$。\n已知 $P(h_i^{(p)}=1) = a$ 且 $P(x_j^{(p)}=1) = a$，它们的期望值都是 $a$。\n所以，对于 $p=q$，期望值为 $a \\cdot a = a^2$。共有 $P$ 个这样的对角项。\n\n情况 2: $p \\neq q$。\n这些项的形式为 $\\mathbb{E}\\!\\left[ h_i^{(p)} h_i^{(q)} x_j^{(p)} x_j^{(q)} \\right]$。\n问题陈述指出，所有随机变量在索引 $i, j$ 和事件 $p$ 上都是独立的。因此，期望值中的所有四个随机变量都是相互独立的。\n$$\n\\mathbb{E}\\!\\left[ h_i^{(p)} h_i^{(q)} x_j^{(p)} x_j^{(q)} \\right] = \\mathbb{E}\\!\\left[ h_i^{(p)} \\right] \\mathbb{E}\\!\\left[ h_i^{(q)} \\right] \\mathbb{E}\\!\\left[ x_j^{(p)} \\right] \\mathbb{E}\\!\\left[ x_j^{(q)} \\right]\n$$\n每个期望值都等于 $a$。所以，总的期望值为 $a \\cdot a \\cdot a \\cdot a = a^4$。\n共有 $P^2 - P = P(P-1)$ 个 $p \\neq q$ 的非对角项。\n\n结合这两种情况，我们得到：\n$$\n\\mathbb{E}\\!\\left[ \\left( \\sum_{p=1}^{P} h_i^{(p)} x_j^{(p)} \\right)^2 \\right] = \\sum_{p=q} a^2 + \\sum_{p \\neq q} a^4 = P \\cdot a^2 + P(P-1) \\cdot a^4\n$$\n将此结果代回到 $\\mathbb{E}\\!\\left[ \\left( W_{CH, ij}^{(P)} \\right)^2 \\right]$ 的表达式中：\n$$\n\\mathbb{E}\\!\\left[ \\left( W_{CH, ij}^{(P)} \\right)^2 \\right] = \\eta^2 \\left[ P a^2 + P(P-1) a^4 \\right]\n$$\n最后，我们乘以 $N_H N_C$ 以获得弗罗贝尼乌斯范数平方的期望值：\n$$\n\\mathbb{E}\\!\\left[\\left\\| W_{CH}^{(P)} \\right\\|_{F}^{2}\\right] = N_H N_C \\eta^2 \\left[ P a^2 + P(P-1) a^4 \\right]\n$$\n这就是作为给定参数函数的最终闭合形式表达式。",
            "answer": "$$\n\\boxed{N_{H} N_{C} \\eta^{2} \\left[ P a^{2} + P(P-1) a^{4} \\right]}\n$$"
        },
        {
            "introduction": "为了让索引发挥作用，大脑必须能够从部分线索中恢复完整的索引，这一过程称为模式完成（pattern completion）。这个练习深入探讨了海马CA3区作为自联想网络的角色，并研究了其存储容量如何受到其神经结构（例如连接的稀疏性）的限制。通过分析中的模型，您可以探索在生物学约束下，记忆系统性能的关键决定因素。",
            "id": "3988853",
            "problem": "考虑海马索引理论中的一个 Cornu Ammonis 区域 3 (CA3) 模型，该模型表示为一个由 $N$ 个具有随机稀疏递归连接的兴奋性神经元组成的递归自联想网络。从神经元 $j$ 到神经元 $i$ 的每个有向突触以概率 $c \\in (0,1]$ 独立存在，由 $C_{ij} \\in \\{0,1\\}$ 编码，其中 $\\mathbb{P}(C_{ij}=1)=c$。该网络存储了 $P=\\alpha N$ 个独立的二进制记忆模式 $\\{\\xi_i^{\\mu}\\}_{\\mu=1}^{P}$，编码水平为 $a \\in (0,1)$，其中对于每个 $\\mu$ 和 $i$，$\\xi_i^{\\mu} \\in \\{0,1\\}$ 且 $\\mathbb{P}(\\xi_i^{\\mu}=1)=a$。\n\n突触强度由带有稀释归一化增益的协方差 Hebbian 法则设定\n$$\nJ_{ij} \\;=\\; \\frac{1}{c\\,N\\,a(1-a)}\\,C_{ij}\\,\\sum_{\\mu=1}^{P}\\big(\\xi_i^{\\mu}-a\\big)\\big(\\xi_j^{\\mu}-a\\big), \\quad J_{ii}=0.\n$$\n检索动力学在零温下是确定性的，其阈值被选择以维持编码水平 $a$：状态为 $s_i \\in \\{0,1\\}$，局部场为 $h_i=\\sum_{j}J_{ij}\\,s_j$，并有一个隐式阈值 $\\theta$ 在稳态下强制 $\\frac{1}{N}\\sum_i s_i=a$。\n\n定义与提示模式 $\\nu$ 的重叠度为 $m=\\frac{1}{N a(1-a)}\\sum_i (\\xi_i^{\\nu}-a)s_i$，并考虑在 $a$、$c$ 和 $\\alpha$ 固定的情况下的热力学极限 $N\\to\\infty$。假设随机稀释和模式允许通过中心极限定理 (CLT) 对串扰进行高斯近似，并且在临界存储负载 $\\alpha_c$ 时，吸引盆连续收缩至零重叠度 $m\\to 0^{+}$。\n\n从上述定义以及中心极限定理的第一性原理和将局部场分解为信号项加串扰噪声项的平均场分解出发，执行以下操作：\n\n1) 在 $N\\to\\infty$ 的极限下，计算在检索模式 $\\nu$ 期间，一个神经元上的串扰噪声的方差如何随连接度 $c$ 和负载 $\\alpha$ 变化。\n\n2) 使用在吸引盆边界 $m\\to 0^{+}$ 处的信噪比稳定性判据，论证在连接度为 $c$ 时的临界负载 $\\alpha_c(c)$ 如何与全连接基准 $\\alpha_c(1)$ 相关，保持 $a$ 和所有其他参数固定，并假设在两种情况下的临界状态都需要相同的稳定性裕度。\n\n您的最终答案必须是关于 $\\alpha_c(c)$ 的一个单一闭式表达式，用 $c$ 和 $\\alpha_c(1)$ 表示。不要推导或报告 $\\alpha_c(1)$ 本身。无需进行数值四舍五入。将最终答案表示为无单位的解析表达式。",
            "solution": "用户提供了一个问题陈述，描述了一个用于海马体 CA3 区域的模型，该模型是一个稀疏连接的递归自联想神经网络。任务是分析其存储容量。\n\n### 步骤 1：问题验证\n\n首先，我将按照所需协议验证问题陈述。\n\n#### 已知条件提取\n- 网络模型: $N$ 个兴奋性神经元，递归自联想。\n- 连接性: 随机、稀疏、有向。$C_{ij} \\in \\{0,1\\}$ 且 $\\mathbb{P}(C_{ij}=1)=c$。\n- 记忆模式: $P=\\alpha N$ 个独立的二进制模式 $\\{\\xi_i^{\\mu}\\}$。\n- 模式统计: $\\xi_i^{\\mu} \\in \\{0,1\\}$ 且 $\\mathbb{P}(\\xi_i^{\\mu}=1)=a$。\n- 突触权重: $J_{ij} = \\frac{1}{c\\,N\\,a(1-a)}\\,C_{ij}\\,\\sum_{\\mu=1}^{P}\\big(\\xi_i^{\\mu}-a\\big)\\big(\\xi_j^{\\mu}-a\\big)$, 且 $J_{ii}=0$。\n- 网络动力学: 确定性，零温。状态 $s_i \\in \\{0,1\\}$。\n- 局部场: $h_i=\\sum_{j}J_{ij}\\,s_j$。\n- 约束条件: 隐式阈值 $\\theta$ 在稳态下强制平均活动度为 $\\frac{1}{N}\\sum_i s_i=a$。\n- 重叠度定义: $m=\\frac{1}{Na(1-a)}\\sum_i (\\xi_i^{\\nu}-a)s_i$。\n- 极限: 在 $a$、$c$ 和 $\\alpha$ 固定的情况下，热力学极限 $N\\to\\infty$。\n- 假设:\n    1. 串扰可通过中心极限定理 (CLT) 近似为高斯噪声。\n    2. 临界存储负载 $\\alpha_c$ 是指吸引盆收缩至零重叠度的地方，即 $m\\to 0^{+}$。\n\n#### 验证评估\n- **科学基础**: 该问题描述了 Hopfield 模型的一个变体，该变体适用于稀疏连接和稀疏编码，是计算神经科学中研究联想记忆的标准且成熟的模型。所使用的概念，如协方差法则、平均场理论、信噪比分析以及中心极限定理 (CLT) 的使用，都是该领域的标准技术。该问题在科学上是合理的。\n- **适定性**: 该问题是适定的。它提供了所有必要的定义、假设和约束，以便从数学上推导出所要求的关系。任务陈述清晰，并且在模型的框架内可以导出一个唯一的解。\n- **客观性**: 语言正式、精确且客观。\n\n该问题没有表现出任何列出的缺陷（例如，科学上不合理、信息缺失、模糊性）。这是一个应用于神经科学的标准理论物理问题，尽管比较复杂。\n\n#### 结论\n问题有效。我现在将着手解决。\n\n### 步骤 2：解的推导\n\n问题的核心是分析神经元局部场中的信噪比。当该比率降至稳定检索所需的阈值以下时，即达到临界存储容量。我们将首先计算噪声的方差（任务 1），然后用它来找出临界负载的标度关系（任务 2）。\n\n设网络尝试检索模式 $\\nu$。网络状态为 $\\{s_j\\}$，其与目标模式 $\\{\\xi_j^\\nu\\}$ 的重叠度为 $m$。神经元 $i$ 的局部场由 $h_i = \\sum_{j \\neq i} J_{ij} s_j$ 给出。我们可以将此场分解为与正在检索的模式 $\\nu$ 相关的信号分量，以及来自所有其他存储模式的串扰噪声分量。\n\n代入 $J_{ij}$ 的表达式：\n$$\nh_i = \\sum_{j \\neq i} \\frac{1}{cNa(1-a)}C_{ij}\\sum_{\\mu=1}^{P}(\\xi_i^\\mu-a)(\\xi_j^\\mu-a)s_j\n$$\n让我们将 $\\mu=\\nu$ 的项从和式中分离出来：\n$$\nh_i = \\frac{\\xi_i^\\nu-a}{cNa(1-a)}\\sum_{j \\neq i}C_{ij}(\\xi_j^\\nu-a)s_j + \\sum_{\\mu \\ne \\nu}^{P} \\frac{\\xi_i^\\mu-a}{cNa(1-a)}\\sum_{j \\neq i}C_{ij}(\\xi_j^\\mu-a)s_j\n$$\n该表达式的形式为 $h_i = S_i + Z_i$，其中 $S_i$ 是信号，$Z_i$ 是串扰噪声。\n\n#### 信号与噪声分析\n在以重叠度 $m$ 检索模式 $\\nu$ 的稳态下，神经元 $j$ 的平均状态与模式位 $\\xi_j^\\nu$ 相关。可以证明，在 $\\xi_j^\\nu$ 条件下 $s_j$ 的均值为 $\\mathbb{E}[s_j|\\xi_j^\\nu]=a+m(\\xi_j^\\nu-a)$。利用这一点，在连接性和模式的统计特性上对信号项 $S_i$ 取期望，得到：\n$$\n\\mathbb{E}[S_i] = \\frac{\\xi_i^\\nu-a}{cNa(1-a)}\\mathbb{E}\\left[\\sum_{j \\neq i}C_{ij}(\\xi_j^\\nu-a)s_j\\right]\n$$\n求和项的期望为 $\\sum_{j \\neq i} \\mathbb{E}[C_{ij}] \\mathbb{E}[(\\xi_j^\\nu-a)s_j]$。我们有 $\\mathbb{E}[C_{ij}]=c$。第二个期望是 $\\mathbb{E}[(\\xi_j^\\nu-a)(a+m(\\xi_j^\\nu-a))] = m \\mathbb{E}[(\\xi_j^\\nu-a)^2] = m a(1-a)$。\n对 $j \\neq i$ 求和（约 $N$ 项），我们得到 $\\approx N \\cdot c \\cdot m a(1-a)$。\n$$\n\\mathbb{E}[S_i] \\approx \\frac{\\xi_i^\\nu-a}{cNa(1-a)} \\cdot cNma(1-a) = m(\\xi_i^\\nu-a)\n$$\n如预期的那样，信号与重叠度 $m$ 成正比。\n\n噪声项为 $Z_i = \\sum_{\\mu \\ne \\nu} Z_i^\\mu$，其中 $Z_i^\\mu = \\frac{\\xi_i^\\mu-a}{cNa(1-a)}\\sum_{j \\neq i}C_{ij}(\\xi_j^\\mu-a)s_j$。\n由于对于不同的 $\\mu$，模式 $\\{\\xi^\\mu\\}$ 是独立的，并且 $s_j$ 仅依赖于模式 $\\nu$，因此对于 $\\mu \\neq \\nu$ 的项 $Z_i^\\mu$ 是均值为零的独立随机变量。根据中心极限定理（正如问题陈述所假设的），它们的和 $Z_i$ 是一个均值为零、方差等于各项方差之和的高斯随机变量。\n$$\n\\mathrm{Var}(Z_i) = \\mathbb{E}[Z_i^2] = \\sum_{\\mu \\ne \\nu} \\mathbb{E}[(Z_i^\\mu)^2] = (P-1)\\mathbb{E}[(Z_i^\\mu)^2]\n$$\n对于任何 $\\mu \\neq \\nu$。我们来计算 $\\mathbb{E}[(Z_i^\\mu)^2]$：\n$$\n\\mathbb{E}[(Z_i^\\mu)^2] = \\mathbb{E}\\left[ \\left( \\frac{\\xi_i^\\mu-a}{cNa(1-a)}\\sum_{j \\neq i}C_{ij}(\\xi_j^\\mu-a)s_j \\right)^2 \\right]\n$$\n首先对模式 $\\xi^\\mu$ 的统计特性进行平均，分子变为 $\\mathbb{E}[(\\xi_i^\\mu-a)^2] = a(1-a)$。该项变为：\n$$\n\\mathbb{E}[(Z_i^\\mu)^2] = \\frac{a(1-a)}{\\left(cNa(1-a)\\right)^2} \\mathbb{E}\\left[ \\left(\\sum_{j \\neq i}C_{ij}(\\xi_j^\\mu-a)s_j\\right)^2 \\right]\n$$\n我们来评估内部求和的方差。对 $j$ 的求和中的各项对于不同的 $j$ 是独立的。因此，和的方差是方差的和：\n$$\n\\mathbb{E}\\left[ \\left(\\sum_{j \\neq i}C_{ij}(\\xi_j^\\mu-a)s_j\\right)^2 \\right] = \\sum_{j \\neq i} \\mathbb{E}\\left[ (C_{ij}(\\xi_j^\\mu-a)s_j)^2 \\right]\n$$\n由于 $C_{ij} \\in \\{0,1\\}$，因此 $C_{ij}^2=C_{ij}$。对于 $\\mu \\neq \\nu$，变量 $C_{ij}$、$\\xi_j^\\mu$ 和 $s_j$ 都是独立的。\n$$\n\\mathbb{E}[C_{ij}^2(\\xi_j^\\mu-a)^2s_j^2] = \\mathbb{E}[C_{ij}] \\mathbb{E}[(\\xi_j^\\mu-a)^2] \\mathbb{E}[s_j^2]\n$$\n我们有 $\\mathbb{E}[C_{ij}]=c$ 和 $\\mathbb{E}[(\\xi_j^\\mu-a)^2] = a(1-a)$。在极限 $m \\to 0^+$下，状态 $s_j$ 实质上是一个具有给定编码水平 $a$ 的随机模式。因此，$s_j$ 是一个伯努利变量，满足 $\\mathbb{P}(s_j=1)=a$，这意味着 $\\mathbb{E}[s_j^2]=\\mathbb{E}[s_j]=a$。\n对 $N-1 \\approx N$ 个这样的项求和得到：\n$$\n\\sum_{j \\neq i} c \\cdot a(1-a) \\cdot a = (N-1)ca^2(1-a) \\approx Nca^2(1-a)\n$$\n将其代回，\n$$\n\\mathbb{E}[(Z_i^\\mu)^2] \\approx \\frac{a(1-a)}{\\left(cNa(1-a)\\right)^2} \\left( Nca^2(1-a) \\right) = \\frac{Nca^3(1-a)^2}{c^2N^2a^2(1-a)^2} = \\frac{a}{cN}\n$$\n现在，我们通过对 $P-1 \\approx P=\\alpha N$ 个模式求和来找到总噪声方差：\n$$\n\\sigma^2 \\equiv \\mathrm{Var}(Z_i) = (\\alpha N) \\cdot \\frac{a}{cN} = \\frac{\\alpha a}{c}\n$$\n这就完成了任务 1。串扰噪声的方差与负载 $\\alpha$ 成线性关系，与连接度 $c$ 成反比。\n\n#### 临界负载关系\n对于任务 2，我们使用信噪比稳定性判据。在吸引盆的边界（$m \\to 0^+$），网络维持非零重叠度的能力由局部场 $h_i \\approx m(\\xi_i^\\nu-a) + Z_i$ 的性质决定。这里 $Z_i$ 是方差为 $\\sigma^2 = \\frac{\\alpha a}{c}$ 的高斯噪声。\n\n一项涉及网络动力学下重叠度 $m$ 的自洽方程的形式分析导出了一个临界条件。这个条件在 $m\\to 0^+$ 处进行评估，确定了临界存储负载 $\\alpha_c$。该条件是 $m$ 的更新函数的增益必须为 1，即 $F'(0)=1$ 其中 $m_{new} = F(m_{old})$。该分析表明，当噪声标准差 $\\sigma$ 达到一个仅依赖于编码水平 $a$ 和神经元传递函数，而不依赖于 $\\alpha$ 或 $c$ 的特定值 $\\sigma_c$ 时，达到临界状态。问题陈述通过“假设在两种情况下的临界状态都需要相同的稳定性裕度”来概括这一点，这等同于陈述 $\\sigma_c$ 是一个常数。\n\n在临界负载 $\\alpha_c(c)$ 时，噪声方差为 $\\sigma_c^2 = \\frac{\\alpha_c(c) a}{c}$。根据稳定性判据，这个值必须等于某个仅依赖于 $a$ 但不依赖于 $c$ 的常数 $K$：\n$$\n\\frac{\\alpha_c(c) a}{c} = K\n$$\n现在，考虑全连接基准，其中 $c=1$。临界负载为 $\\alpha_c(1)$。同样的稳定性判据适用：\n$$\n\\frac{\\alpha_c(1) a}{1} = K\n$$\n通过令常数 $K$ 的两个表达式相等，我们得到：\n$$\n\\frac{\\alpha_c(c) a}{c} = \\alpha_c(1) a\n$$\n由于 $a \\in (0,1)$，所以 $a \\neq 0$，我们可以将两边同时除以 $a$：\n$$\n\\frac{\\alpha_c(c)}{c} = \\alpha_c(1)\n$$\n解出 $\\alpha_c(c)$ 即可得到最终关系：\n$$\n\\alpha_c(c) = c \\cdot \\alpha_c(1)\n$$\n稀疏连接网络的临界存储容量与连接度参数 $c$ 成线性标度关系。",
            "answer": "$$ \\boxed{c\\,\\alpha_c(1)} $$"
        },
        {
            "introduction": "索引并非凭空产生，而是根据代表经验“地点”与“内容”的输入计算得出的，其中来自内嗅皮层（entorhinal cortex）网格细胞的空间信息是一个主要来源。这个问题模拟了这些空间输入如何为不同位置创建独特的神经编码。通过解决，您将探索大脑如何为不同环境生成截然不同的编码集（一种称为“重映射”的现象），从而有效避免记忆间的干扰。",
            "id": "3988822",
            "problem": "考虑一种海马索引理论的形式化模型，其中海马体通过线性读出由内侧内嗅皮层（MEC）的网格细胞构建的空间基，来存储用于情景绑定的索引代码。设一维环境坐标为 $s \\in [0,L]$，并假设有 $M$ 个独立的网格模块，索引为 $j \\in \\{1,\\dots,M\\}$。模块 $j$ 在位置 $s$ 处的网格响应由 $g_{j}(s;\\phi_{j}) = \\cos(k_{j} s + \\phi_{j})$ 给出，其中 $k_{j} = \\frac{2\\pi}{\\lambda_{j}}$ 且 $\\lambda_{j} > 0$ 是模块 $j$ 的网格周期，而 $\\phi_{j} \\in [0,2\\pi)$ 是其相位。将各模块的响应堆叠成 $M$ 维网格代码 $g(s;\\phi) = \\big(g_{1}(s;\\phi_{1}),\\dots,g_{M}(s;\\phi_{M})\\big)^{\\top}$。情境 $c$ 的海马索引代码为 $h(s;c) = W g(s;\\phi^{(c)})$，其中 $W \\in \\mathbb{R}^{N \\times M}$ 是一个固定的满列秩读出矩阵，$\\phi^{(c)}$ 是情境 $c$ 的相位向量。\n\n将两个情境 $c$ 和 $c'$ 之间的全局重映射定义为应用于所有模块的统一相位偏移：存在一个单一的 $\\delta \\in [0,2\\pi)$，使得对所有 $j$ 都有 $\\phi^{(c')}_{j} = \\phi^{(c)}_{j} + \\delta$。为了量化索引代码中的跨情境干扰，同时抽离读出矩阵 $W$ 的影响，我们考虑干扰泛函\n$$\nJ(\\delta) = \\frac{1}{M} \\sum_{j=1}^{M} \\left( \\frac{1}{L} \\int_{0}^{L} g_{j}\\big(s;\\phi^{(c)}_{j}\\big)\\, g_{j}\\big(s;\\phi^{(c)}_{j}+\\delta\\big)\\, \\mathrm{d}s \\right)^{2}.\n$$\n假设以下基本条件：\n- $L$ 是每个 $\\lambda_{j}$ 的整数倍，或者 $s$ 在 $[0,L]$ 上均匀采样，且 $L$ 足够大，可以在多个基本周期上进行平均。\n- 网格周期 $\\{\\lambda_{j}\\}_{j=1}^{M}$ 两两不公度。\n- 读出矩阵 $W$ 具有满列秩且不依赖于情境。\n\n从这些假设和 $J(\\delta)$ 的定义出发，推导 $J(\\delta)$ 的闭式表达式，并确定全局相位偏移 $\\delta^{\\star}$ 的值，该值在约束条件下最小化 $J(\\delta)$，约束条件是：每个情境内的不同情景绑定在映射 $s \\mapsto h(s;c)$ 几乎处处保持单射的意义下被保留。以弧度为单位给出 $\\delta^{\\star}$ 的最终答案。无需四舍五入。以弧度表示角度。",
            "solution": "问题要求推导干扰泛函 $J(\\delta)$ 的闭式表达式，并求出在单射性约束下最小化此泛函的全局相位偏移 $\\delta^{\\star}$ 的值。\n\n首先，我们验证问题陈述的有效性。\n**第1步：提取已知条件**\n- 环境坐标：$s \\in [0,L]$。\n- 网格模块数量：$M$，索引为 $j \\in \\{1,\\dots,M\\}$。\n- 模块 $j$ 的网格响应：$g_{j}(s;\\phi_{j}) = \\cos(k_{j} s + \\phi_{j})$。\n- 波数：$k_{j} = \\frac{2\\pi}{\\lambda_{j}}$，其中 $\\lambda_{j} > 0$ 是网格周期。\n- 相位：$\\phi_{j} \\in [0,2\\pi)$。\n- 网格代码向量：$g(s;\\phi) = \\big(g_{1}(s;\\phi_{1}),\\dots,g_{M}(s;\\phi_{M})\\big)^{\\top}$。\n- 海马索引代码：$h(s;c) = W g(s;\\phi^{(c)})$，其中 $W \\in \\mathbb{R}^{N \\times M}$ 是一个固定的读出矩阵。\n- 全局重映射：对所有 $j$，$\\phi^{(c')}_{j} = \\phi^{(c)}_{j} + \\delta$，其中 $\\delta \\in [0,2\\pi)$。\n- 干扰泛函：$J(\\delta) = \\frac{1}{M} \\sum_{j=1}^{M} \\left( \\frac{1}{L} \\int_{0}^{L} g_{j}\\big(s;\\phi^{(c)}_{j}\\big)\\, g_{j}\\big(s;\\phi^{(c)}_{j}+\\delta\\big)\\, \\mathrm{d}s \\right)^{2}$。\n- 基本条件：\n    1. $L$ 是每个 $\\lambda_{j}$ 的整数倍，或者 $L$ 足够大以进行空间平均。\n    2. 网格周期 $\\{\\lambda_{j}\\}_{j=1}^{M}$ 两两不公度。\n    3. 读出矩阵 $W$ 具有满列秩且不依赖于情境。\n- 最小化的约束条件：映射 $s \\mapsto h(s;c)$ 必须几乎处处保持单射。\n\n**第2步：使用提取的已知条件进行验证**\n该问题在计算神经科学领域有科学依据，特别是它使用了一个标准的网格细胞和海马索引的形式化模型。问题中的术语都有精确的数学定义，且问题是自洽的。所提供的假设是此类分析中的标准假设，并且对于获得一个易于处理的解是必要的。关于单射性的约束是网格编码理论的一个关键特征，其中不公度的周期确保了网格代码向量的状态空间轨迹不会自相交，从而允许对位置进行唯一编码。必须评估此约束与最小化的相关性，但其存在不会使问题结构失效。该问题是适定的、客观的，并且没有违反任何无效性标准。\n\n**第3步：结论与行动**\n问题有效。我们开始求解。\n\n首先，我们推导 $J(\\delta)$ 的闭式表达式。该泛函定义为：\n$$\nJ(\\delta) = \\frac{1}{M} \\sum_{j=1}^{M} \\left( \\frac{1}{L} \\int_{0}^{L} g_{j}\\big(s;\\phi^{(c)}_{j}\\big)\\, g_{j}\\big(s;\\phi^{(c)}_{j}+\\delta\\big)\\, \\mathrm{d}s \\right)^{2}\n$$\n我们来分析单个模块 $j$ 的积分项，记为 $I_j(\\delta)$：\n$$\nI_j(\\delta) = \\frac{1}{L} \\int_{0}^{L} g_{j}\\big(s;\\phi^{(c)}_{j}\\big)\\, g_{j}\\big(s;\\phi^{(c)}_{j}+\\delta\\big)\\, \\mathrm{d}s\n$$\n代入 $g_j(s;\\phi)$ 的定义，我们得到：\n$$\nI_j(\\delta) = \\frac{1}{L} \\int_{0}^{L} \\cos(k_{j} s + \\phi^{(c)}_{j}) \\cos(k_{j} s + \\phi^{(c)}_{j} + \\delta) \\, \\mathrm{d}s\n$$\n我们使用积化和差三角恒等式 $\\cos(A)\\cos(B) = \\frac{1}{2}(\\cos(A-B) + \\cos(A+B))$。\n令 $A = k_{j} s + \\phi^{(c)}_{j} + \\delta$ 且 $B = k_{j} s + \\phi^{(c)}_{j}$。则 $A-B = \\delta$ 且 $A+B = 2k_{j} s + 2\\phi^{(c)}_{j} + \\delta$。\n积分变为：\n$$\nI_j(\\delta) = \\frac{1}{L} \\int_{0}^{L} \\frac{1}{2} \\left[ \\cos(\\delta) + \\cos(2k_{j} s + 2\\phi^{(c)}_{j} + \\delta) \\right] \\mathrm{d}s\n$$\n我们可以将积分分成两部分：\n$$\nI_j(\\delta) = \\frac{1}{2L} \\left[ \\int_{0}^{L} \\cos(\\delta) \\, \\mathrm{d}s + \\int_{0}^{L} \\cos(2k_{j} s + 2\\phi^{(c)}_{j} + \\delta) \\, \\mathrm{d}s \\right]\n$$\n对于第一个积分，$\\cos(\\delta)$ 是关于 $s$ 的常数，因此 $\\int_{0}^{L} \\cos(\\delta) \\, \\mathrm{d}s = L \\cos(\\delta)$。\n对于第二个积分，我们有：\n$$\n\\int_{0}^{L} \\cos(2k_{j} s + 2\\phi^{(c)}_{j} + \\delta) \\, \\mathrm{d}s = \\left[ \\frac{\\sin(2k_{j} s + 2\\phi^{(c)}_{j} + \\delta)}{2k_{j}} \\right]_{0}^{L}\n$$\n其计算结果为：\n$$\n\\frac{1}{2k_{j}} \\left[ \\sin(2k_{j}L + 2\\phi^{(c)}_{j} + \\delta) - \\sin(2\\phi^{(c)}_{j} + \\delta) \\right]\n$$\n这里我们必须使用基本条件，即 $L$ 是每个周期 $\\lambda_j$ 的整数倍。设 $L = n_j \\lambda_j$，其中 $n_j$ 为某个整数。由于 $k_j = \\frac{2\\pi}{\\lambda_j}$，因此 $k_j L = \\frac{2\\pi}{\\lambda_j} (n_j \\lambda_j) = 2\\pi n_j$。\n因此，$2k_j L = 4\\pi n_j$，它是 $2\\pi$ 的整数倍。由于正弦函数的周期为 $2\\pi$，我们有 $\\sin(4\\pi n_j + \\theta) = \\sin(\\theta)$。第二个积分的表达式简化为：\n$$\n\\frac{1}{2k_{j}} \\left[ \\sin(2\\phi^{(c)}_{j} + \\delta) - \\sin(2\\phi^{(c)}_{j} + \\delta) \\right] = 0\n$$\n在另一个假设（$L$ 足够大）下，结果也相同，因为一个振荡函数在多个周期上的积分平均值为零。\n因此，第二个积分为零，我们剩下：\n$$\nI_j(\\delta) = \\frac{1}{2L} [L \\cos(\\delta) + 0] = \\frac{1}{2} \\cos(\\delta)\n$$\n这个结果与模块索引 $j$ 和初始相位 $\\phi^{(c)}_j$ 无关。现在我们将其代回 $J(\\delta)$ 的表达式中：\n$$\nJ(\\delta) = \\frac{1}{M} \\sum_{j=1}^{M} \\left( \\frac{1}{2} \\cos(\\delta) \\right)^{2} = \\frac{1}{M} \\sum_{j=1}^{M} \\frac{1}{4} \\cos^2(\\delta)\n$$\n由于求和项是常数，所以和是该项的 $M$ 倍：\n$$\nJ(\\delta) = \\frac{1}{M} \\cdot M \\cdot \\frac{1}{4} \\cos^2(\\delta) = \\frac{1}{4} \\cos^2(\\delta)\n$$\n这就是干扰泛函 $J(\\delta)$ 的闭式表达式。\n\n接下来，我们必须找到最小化 $J(\\delta)$ 的值 $\\delta^{\\star}$。这等价于在 $\\delta \\in [0, 2\\pi)$ 的范围内最小化 $\\cos^2(\\delta)$。函数 $\\cos^2(\\delta)$ 是非负的，其最小值为 0。这个最小值在 $\\cos(\\delta) = 0$ 时出现。在区间 $[0, 2\\pi)$ 内满足此条件的 $\\delta$ 值为 $\\delta = \\frac{\\pi}{2}$ 和 $\\delta = \\frac{3\\pi}{2}$。\n\n最后，我们考虑映射 $s \\mapsto h(s;c)$ 必须几乎处处保持单射的约束条件。任何情境 $c$ 的代码是 $h(s;c) = W g(s;\\phi^{(c)})$。由于 $W$ 具有满列秩，因此 $h$ 相对于 $s$ 的单射性等价于网格代码 $g(s;\\phi^{(c)})$ 的单射性。从位置 $s$ 到向量空间 $\\mathbb{R}^M$ 的网格代码映射的单射性是由基本条件——网格周期 $\\{\\lambda_j\\}$ 两两不公度——来保证的（几乎处处）。这确保了当 $s$ 变化时，$g(s;\\phi^{(c)})$ 所描绘的轨迹不会自相交。\n应用全局相位偏移 $\\delta$ 只是同时改变了所有模块的轨迹起始相位。它不会改变频率 $\\{k_j\\}$ 或它们的不公度性。因此，对于任何 $\\delta$ 值，保证单射性的轨迹的几何属性都被保留。因此，所有可能的 $\\delta$ 值都满足该约束，包括那两个最小化 $J(\\delta)$ 的值。\n\n问题要求的是“一个值” $\\delta^{\\star}$，这暗示着单一答案。按照惯例，在没有其他标准的情况下，选择最小的正角度。$\\frac{\\pi}{2}$ 和 $\\frac{3\\pi}{2}$ 都能导致两种情境的表征之间最大程度的去相关（平均意义上的正交），从而最小化干扰。我们选择主值。\n\n因此，最小化干扰的全局相位偏移值为 $\\delta^{\\star} = \\frac{\\pi}{2}$。",
            "answer": "$$\n\\boxed{\\frac{\\pi}{2}}\n$$"
        }
    ]
}