{
    "hands_on_practices": [
        {
            "introduction": "索引理论的核心在于，突触连接将海马区的索引与皮层特征联系在一起。本练习提供了一个动手计算，旨在探索一个简单的、生物学上合理的赫布学习规则（Hebbian learning rule）如何加强这些连接。通过计算突触权重的增长，我们可以深入了解记忆形成的物理基础。",
            "id": "3988866",
            "problem": "考虑一个简化的海马索引理论模型，其中一个包含 $N_{H}$ 个海马索引单元的群体与一个包含 $N_{C}$ 个特征单元的分布式皮层群体相结合。每个事件 $p \\in \\{1,\\dots,P\\}$ 由一个海马索引向量 $h^{(p)} \\in \\{0,1\\}^{N_{H}}$ 和一个皮层模式向量 $x^{(p)} \\in \\{0,1\\}^{N_{C}}$ 表示。假设以下基础建模假设，这些假设基于 Hebbian 公设以及在皮层和海马体中观察到的稀疏编码现象：\n\n- 对于每个事件 $p$，每个分量 $h_{i}^{(p)}$ 和 $x_{j}^{(p)}$ 都是一个独立的伯努利随机变量，其值为 $1$ 的概率为 $a \\in (0,1)$，否则为 $0$。这些变量在索引 $i$、$j$ 和事件 $p$ 之间是相互独立的。\n- 突触权重初始化为 $0$，并根据一个 Hebbian 外积规则在每个事件中更新一次。该规则将活跃的海马索引与同时活跃的皮层特征绑定在一起：\n$$\n\\Delta W_{CH} \\;=\\; \\eta \\, h^{(p)} \\big(x^{(p)}\\big)^{\\top} ,\n$$\n其中 $W_{CH} \\in \\mathbb{R}^{N_{H} \\times N_{C}}$ 并且 $\\eta > 0$ 是学习率。在回忆时，海马到皮层的复现可以通过 $x_{\\mathrm{reinst}} \\,=\\, W_{CH}^{\\top} h$ 产生，这与 $W_{CH}$ 通过其转置矩阵存储海马到皮层的绑定是一致的。\n\n仅从这些假设出发，推导在存储了 $P$ 个统计独立的事件后，权重矩阵的弗罗贝尼乌斯范数平方的期望值的解析表达式：\n$$\n\\mathbb{E}\\!\\left[\\left\\| W_{CH}^{(P)} \\right\\|_{F}^{2}\\right] ,\n$$\n该表达式应为 $N_{H}$、$N_{C}$、$\\eta$、$P$ 和 $a$ 的函数。请以封闭形式给出最终答案。不需要进行数值近似或四舍五入。",
            "solution": "该问题陈述是计算神经科学领域中一个有效且适定的问题。所有变量、参数和统计假设都已明确定义，从而可以进行严谨的数学推导。现在我将开始进行解答。\n\n目标是计算在 $P$ 个事件之后权重矩阵 $W_{CH}^{(P)}$ 的弗罗贝尼乌斯范数平方的期望值。权重矩阵由从初始状态 $W_{CH}^{(0)} = 0$ 开始的更新累积给出：\n$$\nW_{CH}^{(P)} = \\sum_{p=1}^{P} \\eta \\, h^{(p)} (x^{(p)})^{\\top}\n$$\n其中 $\\eta$ 是学习率，$h^{(p)} \\in \\{0,1\\}^{N_H}$ 是事件 $p$ 的海马索引向量，$x^{(p)} \\in \\{0,1\\}^{N_C}$ 是事件 $p$ 的皮层模式向量。权重矩阵的分量为：\n$$\nW_{CH, ij}^{(P)} = \\eta \\sum_{p=1}^{P} h_i^{(p)} x_j^{(p)}\n$$\n对于 $i \\in \\{1,\\dots,N_H\\}$ 和 $j \\in \\{1,\\dots,N_C\\}$。\n\n$W_{CH}^{(P)}$ 的弗罗贝尼乌斯范数平方是其所有元素平方的总和：\n$$\n\\left\\| W_{CH}^{(P)} \\right\\|_{F}^{2} = \\sum_{i=1}^{N_H} \\sum_{j=1}^{N_C} \\left( W_{CH, ij}^{(P)} \\right)^2\n$$\n我们需要求解期望值 $\\mathbb{E}\\!\\left[\\left\\| W_{CH}^{(P)} \\right\\|_{F}^{2}\\right]$。利用期望算子的线性性质，我们可以写出：\n$$\n\\mathbb{E}\\!\\left[\\left\\| W_{CH}^{(P)} \\right\\|_{F}^{2}\\right] = \\mathbb{E}\\!\\left[ \\sum_{i=1}^{N_H} \\sum_{j=1}^{N_C} \\left( W_{CH, ij}^{(P)} \\right)^2 \\right] = \\sum_{i=1}^{N_H} \\sum_{j=1}^{N_C} \\mathbb{E}\\!\\left[ \\left( W_{CH, ij}^{(P)} \\right)^2 \\right]\n$$\n问题陈述指出，对于所有的 $i, j, p$，向量分量 $h_i^{(p)}$ 和 $x_j^{(p)}$ 是独立同分布 (i.i.d.) 的伯努利随机变量。因此，对于所有索引对 $(i,j)$，权重 $W_{CH, ij}^{(P)}$ 的统计特性都是相同的。这意味着期望值 $\\mathbb{E}\\!\\left[ \\left( W_{CH, ij}^{(P)} \\right)^2 \\right]$ 对于所有的 $i, j$ 都是一个常数。因此我们可以简化这个求和：\n$$\n\\mathbb{E}\\!\\left[\\left\\| W_{CH}^{(P)} \\right\\|_{F}^{2}\\right] = N_H N_C \\, \\mathbb{E}\\!\\left[ \\left( W_{CH, ij}^{(P)} \\right)^2 \\right]\n$$\n现在，我们来计算单个权重元素平方的期望值：\n$$\n\\mathbb{E}\\!\\left[ \\left( W_{CH, ij}^{(P)} \\right)^2 \\right] = \\mathbb{E}\\!\\left[ \\left( \\eta \\sum_{p=1}^{P} h_i^{(p)} x_j^{(p)} \\right)^2 \\right] = \\eta^2 \\, \\mathbb{E}\\!\\left[ \\left( \\sum_{p=1}^{P} h_i^{(p)} x_j^{(p)} \\right)^2 \\right]\n$$\n展开这个和的平方：\n$$\n\\left( \\sum_{p=1}^{P} h_i^{(p)} x_j^{(p)} \\right)^2 = \\left( \\sum_{p=1}^{P} h_i^{(p)} x_j^{(p)} \\right) \\left( \\sum_{q=1}^{P} h_i^{(q)} x_j^{(q)} \\right) = \\sum_{p=1}^{P} \\sum_{q=1}^{P} h_i^{(p)} x_j^{(p)} h_i^{(q)} x_j^{(q)}\n$$\n取期望值得到：\n$$\n\\mathbb{E}\\!\\left[ \\left( \\sum_{p=1}^{P} h_i^{(p)} x_j^{(p)} \\right)^2 \\right] = \\sum_{p=1}^{P} \\sum_{q=1}^{P} \\mathbb{E}\\!\\left[ h_i^{(p)} h_i^{(q)} x_j^{(p)} x_j^{(q)} \\right]\n$$\n我们可以将这个双重求和分为两种情况：对角项（$p=q$）和非对角项（$p \\neq q$）。\n\n情况 1：$p=q$。\n这些项的形式为 $\\mathbb{E}\\!\\left[ h_i^{(p)} h_i^{(p)} x_j^{(p)} x_j^{(p)} \\right] = \\mathbb{E}\\!\\left[ (h_i^{(p)})^2 (x_j^{(p)})^2 \\right]$。\n变量 $h_i^{(p)}$ 和 $x_j^{(p)}$ 是伯努利随机变量，取值为 $\\{0,1\\}$。因此，$(h_i^{(p)})^2 = h_i^{(p)}$ 且 $(x_j^{(p)})^2 = x_j^{(p)}$。期望值变为 $\\mathbb{E}\\!\\left[ h_i^{(p)} x_j^{(p)} \\right]$。\n由于 $h_i^{(p)}$ 和 $x_j^{(p)}$ 是独立的，所以 $\\mathbb{E}\\!\\left[ h_i^{(p)} x_j^{(p)} \\right] = \\mathbb{E}\\!\\left[ h_i^{(p)} \\right] \\mathbb{E}\\!\\left[ x_j^{(p)} \\right]$。\n鉴于 $P(h_i^{(p)}=1) = a$ 和 $P(x_j^{(p)}=1) = a$，它们的期望值都是 $a$。\n因此，对于 $p=q$ 的情况，期望值为 $a \\cdot a = a^2$。共有 $P$ 个这样的对角项。\n\n情况 2：$p \\neq q$。\n这些项的形式为 $\\mathbb{E}\\!\\left[ h_i^{(p)} h_i^{(q)} x_j^{(p)} x_j^{(q)} \\right]$。\n问题陈述指出，所有随机变量在索引 $i, j$ 和事件 $p$ 之间是相互独立的。因此，期望值中的所有四个随机变量都是相互独立的。\n$$\n\\mathbb{E}\\!\\left[ h_i^{(p)} h_i^{(q)} x_j^{(p)} x_j^{(q)} \\right] = \\mathbb{E}\\!\\left[ h_i^{(p)} \\right] \\mathbb{E}\\!\\left[ h_i^{(q)} \\right] \\mathbb{E}\\!\\left[ x_j^{(p)} \\right] \\mathbb{E}\\!\\left[ x_j^{(q)} \\right]\n$$\n每个期望值都等于 $a$。所以，总期望值为 $a \\cdot a \\cdot a \\cdot a = a^4$。\n当 $p \\neq q$ 时，有 $P^2 - P = P(P-1)$ 个非对角项。\n\n综合这两种情况，我们得到：\n$$\n\\mathbb{E}\\!\\left[ \\left( \\sum_{p=1}^{P} h_i^{(p)} x_j^{(p)} \\right)^2 \\right] = \\sum_{p=q} a^2 + \\sum_{p \\neq q} a^4 = P \\cdot a^2 + P(P-1) \\cdot a^4\n$$\n将此结果代回到 $\\mathbb{E}\\!\\left[ \\left( W_{CH, ij}^{(P)} \\right)^2 \\right]$ 的表达式中：\n$$\n\\mathbb{E}\\!\\left[ \\left( W_{CH, ij}^{(P)} \\right)^2 \\right] = \\eta^2 \\left[ P a^2 + P(P-1) a^4 \\right]\n$$\n最后，我们乘以 $N_H N_C$ 来获得弗罗贝尼乌斯范数平方的期望值：\n$$\n\\mathbb{E}\\!\\left[\\left\\| W_{CH}^{(P)} \\right\\|_{F}^{2}\\right] = N_H N_C \\eta^2 \\left[ P a^2 + P(P-1) a^4 \\right]\n$$\n这就是作为给定参数函数的最终封闭形式表达式。",
            "answer": "$$\n\\boxed{N_{H} N_{C} \\eta^{2} \\left[ P a^{2} + P(P-1) a^{4} \\right]}\n$$"
        },
        {
            "introduction": "一个记忆系统只有在能够存储相当数量的独特记忆且不产生灾难性干扰时才是有用的。本实践深入探讨了存储容量这一关键问题，使用了一个海马体CA3区的模型。你将分析网络连接性如何影响“串扰”噪声的量，并最终决定网络能够可靠存储和检索的最大模式数量。",
            "id": "3988853",
            "problem": "考虑一个海马体索引理论中的海马体CA3区模型，该模型表示为一个由$N$个兴奋性神经元组成的循环自联想网络，具有随机稀疏的循环连接。从神经元$j$到神经元$i$的每个有向突触独立地以概率$c \\in (0,1]$存在，由$C_{ij} \\in \\{0,1\\}$编码，其中$\\mathbb{P}(C_{ij}=1)=c$。该网络存储了$P=\\alpha N$个独立的二元记忆模式$\\{\\xi_i^{\\mu}\\}_{\\mu=1}^{P}$，编码水平为$a \\in (0,1)$，其中对于每个$\\mu$和$i$，$\\xi_i^{\\mu} \\in \\{0,1\\}$且$\\mathbb{P}(\\xi_i^{\\mu}=1)=a$。\n\n突触强度由协方差赫布规则设定，并带有稀释归一化增益\n$$\nJ_{ij} \\;=\\; \\frac{1}{c\\,N\\,a(1-a)}\\,C_{ij}\\,\\sum_{\\mu=1}^{P}\\big(\\xi_i^{\\mu}-a\\big)\\big(\\xi_j^{\\mu}-a\\big), \\quad J_{ii}=0.\n$$\n在零温度下，检索动力学是确定性的，其阈值被选择以维持编码水平$a$：状态为$s_i \\in \\{0,1\\}$，局部场为$h_i=\\sum_{j}J_{ij}\\,s_j$，并有一个隐式阈值$\\theta$在稳态时强制$\\frac{1}{N}\\sum_i s_i=a$。\n\n定义与提示模式$\\nu$的重叠度为$m=\\frac{1}{N a(1-a)}\\sum_i (\\xi_i^{\\nu}-a)s_i$，并考虑在固定的$a$、$c$和$\\alpha$下的热力学极限$N\\to\\infty$。假设随机稀释和模式允许通过中心极限定理（CLT）对串扰进行高斯近似，并且在临界存储负载$\\alpha_c$处，吸引盆连续收缩至零重叠度$m\\to 0^{+}$。\n\n从以上定义以及中心极限定理（CLT）和将局部场分解为信号项加串扰噪声项的平均场分解的第一性原理出发，执行以下操作：\n\n1) 在$N\\to\\infty$的极限下，计算在检索模式$\\nu$期间，神经元处串扰噪声的方差如何随连接度$c$和负载$\\alpha$而变化。\n\n2) 在吸引盆边界$m\\to 0^{+}$处，使用信噪比稳定性判据，论证在连接度为$c$时的临界负载$\\alpha_c(c)$与全连接基准$\\alpha_c(1)$之间的关系，保持$a$和所有其他参数固定，并假设在两种情况下的临界点都需要相同的稳定性余量。\n\n你的最终答案必须是关于$\\alpha_c(c)$的一个单一闭式表达式，用$c$和$\\alpha_c(1)$表示。不要推导或报告$\\alpha_c(1)$本身。不需要进行数值舍入。将最终答案表示为一个无单位的解析表达式。",
            "solution": "用户提供了一个问题陈述，描述了一个海马体CA3区的模型，该模型是一个稀疏连接的循环自联想神经网络。任务是分析其存储容量。\n\n### 步骤1：问题验证\n\n首先，我将根据要求的协议验证问题陈述。\n\n#### 已知条件提取\n- 网络模型：$N$个兴奋性神经元，循环自联想。\n- 连接性：随机、稀疏、有向。$C_{ij} \\in \\{0,1\\}$，其中$\\mathbb{P}(C_{ij}=1)=c$。\n- 记忆模式：$P=\\alpha N$个独立的二元模式$\\{\\xi_i^{\\mu}\\}$。\n- 模式统计：$\\xi_i^{\\mu} \\in \\{0,1\\}$，其中$\\mathbb{P}(\\xi_i^{\\mu}=1)=a$。\n- 突触权重：$J_{ij} = \\frac{1}{c\\,N\\,a(1-a)}\\,C_{ij}\\,\\sum_{\\mu=1}^{P}\\big(\\xi_i^{\\mu}-a\\big)\\big(\\xi_j^{\\mu}-a\\big)$，其中$J_{ii}=0$。\n- 网络动力学：确定性，零温度。状态$s_i \\in \\{0,1\\}$。\n- 局部场：$h_i=\\sum_{j}J_{ij}\\,s_j$。\n- 约束：隐式阈值$\\theta$在稳态时强制平均活动$\\frac{1}{N}\\sum_i s_i=a$。\n- 重叠度定义：$m=\\frac{1}{Na(1-a)}\\sum_i (\\xi_i^{\\nu}-a)s_i$。\n- 极限：在固定的$a$、$c$和$\\alpha$下的热力学极限$N\\to\\infty$。\n- 假设：\n    1. 串扰可以通过中心极限定理（CLT）近似为高斯噪声。\n    2. 临界存储负载$\\alpha_c$是吸引盆收缩至零重叠度（即$m\\to 0^{+}$）的地方。\n\n#### 验证评估\n- **科学基础**：该问题描述了Hopfield模型的一个变体，适用于稀疏连接和稀疏编码，这是计算神经科学中研究联想记忆的一个标准且成熟的模型。所使用的概念，如协方差规则、平均场理论、信噪比分析和中心极限定理（CLT）的使用，都是该领域的标准技术。它在科学上是合理的。\n- **适定性**：该问题是适定的。它提供了所有必要的定义、假设和约束，以数学方式推导出所要求的关系。任务陈述清晰，并在模型框架内导向一个唯一的解。\n- **客观性**：语言正式、精确且客观。\n\n该问题没有表现出任何列出的缺陷（例如，科学上不合理、信息缺失、含糊不清）。这是一个标准的、尽管复杂的、应用于神经科学的理论物理问题。\n\n#### 结论\n该问题有效。我现在将继续进行解答。\n\n### 步骤2：解的推导\n\n问题的核心是分析神经元局部场中的信噪比。当该比率降至稳定检索所需阈值以下时，达到临界存储容量。我们将首先计算噪声的方差（任务1），然后用它来找出临界负载的标度关系（任务2）。\n\n假设网络试图检索模式$\\nu$。网络状态为$\\{s_j\\}$，其与目标模式$\\{\\xi_j^\\nu\\}$的重叠度为$m$。神经元$i$处的局部场由$h_i = \\sum_{j \\neq i} J_{ij} s_j$给出。我们可以将此场分解为一个信号分量（与被检索的模式$\\nu$相关）和一个来自所有其他存储模式的串扰噪声分量。\n\n代入$J_{ij}$的表达式：\n$$\nh_i = \\sum_{j \\neq i} \\frac{1}{cNa(1-a)}C_{ij}\\sum_{\\mu=1}^{P}(\\xi_i^\\mu-a)(\\xi_j^\\mu-a)s_j\n$$\n让我们将$\\mu=\\nu$的项从和式中分离出来：\n$$\nh_i = \\frac{\\xi_i^\\nu-a}{cNa(1-a)}\\sum_{j \\neq i}C_{ij}(\\xi_j^\\nu-a)s_j + \\sum_{\\mu \\ne \\nu}^{P} \\frac{\\xi_i^\\mu-a}{cNa(1-a)}\\sum_{j \\neq i}C_{ij}(\\xi_j^\\mu-a)s_j\n$$\n这个表达式的形式为$h_i = S_i + Z_i$，其中$S_i$是信号，$Z_i$是串扰噪声。\n\n#### 信号与噪声分析\n在以重叠度$m$检索模式$\\nu$的稳态下，神经元$j$的平均状态与模式位$\\xi_j^\\nu$相关。可以证明，在给定$\\xi_j^\\nu$的条件下，$s_j$的均值为$\\mathbb{E}[s_j|\\xi_j^\\nu]=a+m(\\xi_j^\\nu-a)$。利用这一点，信号项$S_i$在连接性和模式的统计上的期望变为：\n$$\n\\mathbb{E}[S_i] = \\frac{\\xi_i^\\nu-a}{cNa(1-a)}\\mathbb{E}\\left[\\sum_{j \\neq i}C_{ij}(\\xi_j^\\nu-a)s_j\\right]\n$$\n求和项的期望是$\\sum_{j \\neq i} \\mathbb{E}[C_{ij}] \\mathbb{E}[(\\xi_j^\\nu-a)s_j]$。我们有$\\mathbb{E}[C_{ij}]=c$。第二个期望是$\\mathbb{E}[(\\xi_j^\\nu-a)(a+m(\\xi_j^\\nu-a))] = m \\mathbb{E}[(\\xi_j^\\nu-a)^2] = m a(1-a)$。\n对$j \\neq i$（约$N$项）求和，我们得到$\\approx N \\cdot c \\cdot m a(1-a)$。\n$$\n\\mathbb{E}[S_i] \\approx \\frac{\\xi_i^\\nu-a}{cNa(1-a)} \\cdot cNma(1-a) = m(\\xi_i^\\nu-a)\n$$\n信号与重叠度$m$成正比，这与预期相符。\n\n噪声项是$Z_i = \\sum_{\\mu \\ne \\nu} Z_i^\\mu$，其中$Z_i^\\mu = \\frac{\\xi_i^\\mu-a}{cNa(1-a)}\\sum_{j \\neq i}C_{ij}(\\xi_j^\\mu-a)s_j$。\n由于对于不同的$\\mu$，模式$\\{\\xi^\\mu\\}$是独立的，并且$s_j$仅依赖于模式$\\nu$，所以对于$\\mu \\neq \\nu$的项$Z_i^\\mu$是均值为零的独立随机变量。根据中心极限定理（如问题陈述所述），它们的和$Z_i$是一个均值为零的高斯随机变量，其方差等于各个方差之和。\n$$\n\\mathrm{Var}(Z_i) = \\mathbb{E}[Z_i^2] = \\sum_{\\mu \\ne \\nu} \\mathbb{E}[(Z_i^\\mu)^2] = (P-1)\\mathbb{E}[(Z_i^\\mu)^2]\n$$\n对于任何$\\mu \\neq \\nu$。我们来计算$\\mathbb{E}[(Z_i^\\mu)^2]$：\n$$\n\\mathbb{E}[(Z_i^\\mu)^2] = \\mathbb{E}\\left[ \\left( \\frac{\\xi_i^\\mu-a}{cNa(1-a)}\\sum_{j \\neq i}C_{ij}(\\xi_j^\\mu-a)s_j \\right)^2 \\right]\n$$\n首先对模式$\\xi^\\mu$的统计进行平均，分子变为$\\mathbb{E}[(\\xi_i^\\mu-a)^2] = a(1-a)$。该项变为：\n$$\n\\mathbb{E}[(Z_i^\\mu)^2] = \\frac{a(1-a)}{\\left(cNa(1-a)\\right)^2} \\mathbb{E}\\left[ \\left(\\sum_{j \\neq i}C_{ij}(\\xi_j^\\mu-a)s_j\\right)^2 \\right]\n$$\n让我们评估内部和的方差。对$j$求和的各项对于不同的$j$是独立的。因此，和的方差是方差的和：\n$$\n\\mathbb{E}\\left[ \\left(\\sum_{j \\neq i}C_{ij}(\\xi_j^\\mu-a)s_j\\right)^2 \\right] = \\sum_{j \\neq i} \\mathbb{E}\\left[ (C_{ij}(\\xi_j^\\mu-a)s_j)^2 \\right]\n$$\n由于$C_{ij} \\in \\{0,1\\}$，所以$C_{ij}^2=C_{ij}$。对于$\\mu \\neq \\nu$，变量$C_{ij}$、$\\xi_j^\\mu$和$s_j$都是独立的。\n$$\n\\mathbb{E}[C_{ij}^2(\\xi_j^\\mu-a)^2s_j^2] = \\mathbb{E}[C_{ij}] \\mathbb{E}[(\\xi_j^\\mu-a)^2] \\mathbb{E}[s_j^2]\n$$\n我们有$\\mathbb{E}[C_{ij}]=c$和$\\mathbb{E}[(\\xi_j^\\mu-a)^2] = a(1-a)$。在极限$m \\to 0^+$下，状态$s_j$本质上是一个具有给定编码水平$a$的随机模式。因此，$s_j$是一个伯努利变量，其中$\\mathbb{P}(s_j=1)=a$，这意味着$\\mathbb{E}[s_j^2]=\\mathbb{E}[s_j]=a$。\n对$N-1 \\approx N$个这样的项求和为：\n$$\n\\sum_{j \\neq i} c \\cdot a(1-a) \\cdot a = (N-1)ca^2(1-a) \\approx Nca^2(1-a)\n$$\n将此代回，\n$$\n\\mathbb{E}[(Z_i^\\mu)^2] \\approx \\frac{a(1-a)}{\\left(cNa(1-a)\\right)^2} \\left( Nca^2(1-a) \\right) = \\frac{Nca^3(1-a)^2}{c^2N^2a^2(1-a)^2} = \\frac{a}{cN}\n$$\n现在，我们通过对$P-1 \\approx P=\\alpha N$个模式求和来找到总噪声方差：\n$$\n\\sigma^2 \\equiv \\mathrm{Var}(Z_i) = (\\alpha N) \\cdot \\frac{a}{cN} = \\frac{\\alpha a}{c}\n$$\n这就完成了任务1。串扰噪声的方差与负载$\\alpha$成线性关系，与连接度$c$成反比。\n\n#### 临界负载关系\n对于任务2，我们使用信噪比稳定性判据。在吸引盆的边界（$m \\to 0^+$），网络维持非零重叠度的能力由局部场$h_i \\approx m(\\xi_i^\\nu-a) + Z_i$的性质决定。这里$Z_i$是方差为$\\sigma^2 = \\frac{\\alpha a}{c}$的高斯噪声。\n\n检索状态的稳定性要求信号相对于噪声足够强。一个涉及网络动力学下重叠度$m$的自洽方程的形式分析导出了一个临界条件。这个条件在$m\\to 0^+$处进行评估，确定了临界存储负载$\\alpha_c$。该条件是$m$的更新函数的增益必须为1，即$F'(0)=1$，其中$m_{new} = F(m_{old})$。该分析表明，当噪声标准差$\\sigma$达到一个仅依赖于编码水平$a$和神经传递函数，而不依赖于$\\alpha$或$c$的特定值$\\sigma_c$时，达到临界状态。问题陈述通过“假设在两种情况下的临界点都需要相同的稳定性余量”来概括这一点，这等同于声明$\\sigma_c$是恒定的。\n\n在临界负载$\\alpha_c(c)$处，噪声方差为$\\sigma_c^2 = \\frac{\\alpha_c(c) a}{c}$。\n根据稳定性判据，该值必须等于某个依赖于$a$但不依赖于$c$的常数$K$：\n$$\n\\frac{\\alpha_c(c) a}{c} = K\n$$\n现在，考虑全连接基准，其中$c=1$。临界负载是$\\alpha_c(1)$。同样的稳定性判据适用：\n$$\n\\frac{\\alpha_c(1) a}{1} = K\n$$\n通过令常数$K$的两个表达式相等，我们得到：\n$$\n\\frac{\\alpha_c(c) a}{c} = \\alpha_c(1) a\n$$\n由于$a \\in (0,1)$，$a \\neq 0$，我们可以将两边都除以$a$：\n$$\n\\frac{\\alpha_c(c)}{c} = \\alpha_c(1)\n$$\n解出$\\alpha_c(c)$得到最终关系：\n$$\n\\alpha_c(c) = c \\cdot \\alpha_c(1)\n$$\n稀疏连接网络的临界存储容量与连接度参数$c$成线性关系。",
            "answer": "$$ \\boxed{c\\,\\alpha_c(1)} $$"
        },
        {
            "introduction": "为了有效发挥作用，“昨天午餐”的海马索引必须与“今天午餐”的索引有所不同。本练习探讨了一个前沿假说，即大脑如何利用内嗅皮层（entorhinal cortex）中网格细胞（grid cells）的输入来生成这些独特的、依赖于上下文的索引。你将数学上形式化“全局重映射”（global remapping）的概念，并确定大脑如何为不同环境创建最大程度不同（即正交）的神经编码，以最小化干扰。",
            "id": "3988822",
            "problem": "考虑海马索引理论的一种形式化，其中海马体通过线性读出来自内侧内嗅皮层 (MEC) 网格细胞构建的空间基，从而存储用于情景绑定的索引编码。设一维环境坐标为 $s \\in [0,L]$，并假设有 $M$ 个独立的网格模块，由 $j \\in \\{1,\\dots,M\\}$ 索引。模块 $j$ 在位置 $s$ 的网格响应由 $g_{j}(s;\\phi_{j}) = \\cos(k_{j} s + \\phi_{j})$ 给出，其中 $k_{j} = \\frac{2\\pi}{\\lambda_{j}}$，$\\lambda_{j} > 0$ 是模块 $j$ 的网格周期，$\\phi_{j} \\in [0,2\\pi)$ 是其相位。将模块响应堆叠成 M 维网格编码 $g(s;\\phi) = \\big(g_{1}(s;\\phi_{1}),\\dots,g_{M}(s;\\phi_{M})\\big)^{\\top}$。上下文 $c$ 的海马索引编码为 $h(s;c) = W g(s;\\phi^{(c)})$，其中 $W \\in \\mathbb{R}^{N \\times M}$ 是一个具有满列秩的固定读出矩阵，$\\phi^{(c)}$ 是上下文 $c$ 的相位向量。\n\n将两个上下文 $c$ 和 $c'$ 之间的全局重映射定义为应用于所有模块的统一相位偏移：存在一个单一的 $\\delta \\in [0,2\\pi)$，使得对所有 $j$ 都有 $\\phi^{(c')}_{j} = \\phi^{(c)}_{j} + \\delta$。为了量化索引编码中的上下文间干扰，同时抽象掉读出矩阵 $W$，考虑干扰泛函\n$$\nJ(\\delta) = \\frac{1}{M} \\sum_{j=1}^{M} \\left( \\frac{1}{L} \\int_{0}^{L} g_{j}\\big(s;\\phi^{(c)}_{j}\\big)\\, g_{j}\\big(s;\\phi^{(c)}_{j}+\\delta\\big)\\, \\mathrm{d}s \\right)^{2}.\n$$\n假设以下基本条件：\n- $L$ 是每个 $\\lambda_{j}$ 的整数倍，或者 $s$ 在 $[0,L]$ 上均匀采样，且 $L$ 足够大，可以在多个基本周期上取平均。\n- 网格周期 $\\{\\lambda_{j}\\}_{j=1}^{M}$ 是两两不可通约的。\n- 读出矩阵 $W$ 具有满列秩且不依赖于上下文。\n\n从这些假设和 $J(\\delta)$ 的定义出发，推导 $J(\\delta)$ 的闭式表达式，并确定全局相位偏移 $\\delta^{\\star}$ 的值，该值在“每个上下文内的不同情景绑定在映射 $s \\mapsto h(s;c)$ 几乎处处保持单射的意义上得以保留”这一约束下，最小化 $J(\\delta)$。请以弧度为单位提供 $\\delta^{\\star}$ 的最终答案。无需四舍五入。以弧度表示角度。",
            "solution": "问题要求推导干扰泛函 $J(\\delta)$ 的闭式表达式，并求出在单射性约束下最小化该泛函的全局相位偏移 $\\delta^{\\star}$ 的值。\n\n首先，我们验证问题陈述的有效性。\n**步骤1：提取已知条件**\n- 环境坐标：$s \\in [0,L]$。\n- 网格模块数量：$M$，由 $j \\in \\{1,\\dots,M\\}$ 索引。\n- 模块 $j$ 的网格响应：$g_{j}(s;\\phi_{j}) = \\cos(k_{j} s + \\phi_{j})$。\n- 波数：$k_{j} = \\frac{2\\pi}{\\lambda_{j}}$，其中 $\\lambda_{j} > 0$ 是网格周期。\n- 相位：$\\phi_{j} \\in [0,2\\pi)$。\n- 网格编码向量：$g(s;\\phi) = \\big(g_{1}(s;\\phi_{1}),\\dots,g_{M}(s;\\phi_{M})\\big)^{\\top}$。\n- 海马索引编码：$h(s;c) = W g(s;\\phi^{(c)})$，其中 $W \\in \\mathbb{R}^{N \\times M}$ 是一个固定的读出矩阵。\n- 全局重映射：对所有 $j$，$\\phi^{(c')}_{j} = \\phi^{(c)}_{j} + \\delta$，其中 $\\delta \\in [0,2\\pi)$。\n- 干扰泛函：$J(\\delta) = \\frac{1}{M} \\sum_{j=1}^{M} \\left( \\frac{1}{L} \\int_{0}^{L} g_{j}\\big(s;\\phi^{(c)}_{j}\\big)\\, g_{j}\\big(s;\\phi^{(c)}_{j}+\\delta\\big)\\, \\mathrm{d}s \\right)^{2}$。\n- 基本条件：\n    1. $L$ 是每个 $\\lambda_{j}$ 的整数倍，或 $L$ 足够大以进行空间平均。\n    2. 网格周期 $\\{\\lambda_{j}\\}_{j=1}^{M}$ 两两不可通约。\n    3. 读出矩阵 $W$ 具有满列秩且与上下文无关。\n- 最小化的约束条件：映射 $s \\mapsto h(s;c)$ 必须几乎处处保持单射。\n\n**步骤2：使用提取的已知条件进行验证**\n该问题在计算神经科学领域具有科学依据，特别是使用了一个标准的网格细胞和海马索引的形式化模型。术语在数学上定义精确，问题是自洽的。所提供的假设是此类分析中的标准假设，对于得到一个可解的解法是必要的。关于单射性的约束是网格编码理论的一个关键特征，其中不可通约的周期确保了网格编码向量的状态空间轨迹不会自相交，从而允许对位置进行唯一编码。必须评估此约束与最小化的相关性，但它的包含并未使问题结构无效。该问题是适定的、客观的，并且没有违反任何无效性标准。\n\n**步骤3：结论与行动**\n问题有效。我们继续进行求解。\n\n首先，我们推导 $J(\\delta)$ 的闭式表达式。该泛函定义为：\n$$\nJ(\\delta) = \\frac{1}{M} \\sum_{j=1}^{M} \\left( \\frac{1}{L} \\int_{0}^{L} g_{j}\\big(s;\\phi^{(c)}_{j}\\big)\\, g_{j}\\big(s;\\phi^{(c)}_{j}+\\delta\\big)\\, \\mathrm{d}s \\right)^{2}\n$$\n我们先分析单个模块 $j$ 的积分项，记为 $I_j(\\delta)$：\n$$\nI_j(\\delta) = \\frac{1}{L} \\int_{0}^{L} g_{j}\\big(s;\\phi^{(c)}_{j}\\big)\\, g_{j}\\big(s;\\phi^{(c)}_{j}+\\delta\\big)\\, \\mathrm{d}s\n$$\n代入 $g_j(s;\\phi)$ 的定义，我们得到：\n$$\nI_j(\\delta) = \\frac{1}{L} \\int_{0}^{L} \\cos(k_{j} s + \\phi^{(c)}_{j}) \\cos(k_{j} s + \\phi^{(c)}_{j} + \\delta) \\, \\mathrm{d}s\n$$\n我们使用积化和差三角恒等式 $\\cos(A)\\cos(B) = \\frac{1}{2}(\\cos(A-B) + \\cos(A+B))$。\n设 $A = k_{j} s + \\phi^{(c)}_{j} + \\delta$ 和 $B = k_{j} s + \\phi^{(c)}_{j}$。则 $A-B = \\delta$ 且 $A+B = 2k_{j} s + 2\\phi^{(c)}_{j} + \\delta$。\n积分变为：\n$$\nI_j(\\delta) = \\frac{1}{L} \\int_{0}^{L} \\frac{1}{2} \\left[ \\cos(\\delta) + \\cos(2k_{j} s + 2\\phi^{(c)}_{j} + \\delta) \\right] \\mathrm{d}s\n$$\n我们可以将积分分成两部分：\n$$\nI_j(\\delta) = \\frac{1}{2L} \\left[ \\int_{0}^{L} \\cos(\\delta) \\, \\mathrm{d}s + \\int_{0}^{L} \\cos(2k_{j} s + 2\\phi^{(c)}_{j} + \\delta) \\, \\mathrm{d}s \\right]\n$$\n对于第一个积分，$\\cos(\\delta)$ 是关于 $s$ 的常数，所以 $\\int_{0}^{L} \\cos(\\delta) \\, \\mathrm{d}s = L \\cos(\\delta)$。\n对于第二个积分，我们有：\n$$\n\\int_{0}^{L} \\cos(2k_{j} s + 2\\phi^{(c)}_{j} + \\delta) \\, \\mathrm{d}s = \\left[ \\frac{\\sin(2k_{j} s + 2\\phi^{(c)}_{j} + \\delta)}{2k_{j}} \\right]_{0}^{L}\n$$\n计算结果为：\n$$\n\\frac{1}{2k_{j}} \\left[ \\sin(2k_{j}L + 2\\phi^{(c)}_{j} + \\delta) - \\sin(2\\phi^{(c)}_{j} + \\delta) \\right]\n$$\n这里我们必须使用基本条件，即 $L$ 是每个周期 $\\lambda_j$ 的整数倍。设 $L = n_j \\lambda_j$ 对某个整数 $n_j$ 成立。由于 $k_j = \\frac{2\\pi}{\\lambda_j}$，可得 $k_j L = \\frac{2\\pi}{\\lambda_j} (n_j \\lambda_j) = 2\\pi n_j$。\n因此，$2k_j L = 4\\pi n_j$，它是 $2\\pi$ 的整数倍。由于正弦函数是以 $2\\pi$ 为周期的周期函数，我们有 $\\sin(4\\pi n_j + \\theta) = \\sin(\\theta)$。第二个积分的表达式简化为：\n$$\n\\frac{1}{2k_{j}} \\left[ \\sin(2\\phi^{(c)}_{j} + \\delta) - \\sin(2\\phi^{(c)}_{j} + \\delta) \\right] = 0\n$$\n在 L 足够大的备选假设下，同样的结果也成立，因为一个振荡函数在多个周期上的积分平均值为零。\n因此，第二个积分为零，我们剩下：\n$$\nI_j(\\delta) = \\frac{1}{2L} [L \\cos(\\delta) + 0] = \\frac{1}{2} \\cos(\\delta)\n$$\n这个结果与模块索引 $j$ 和初始相位 $\\phi^{(c)}_j$ 无关。现在我们将此结果代回 $J(\\delta)$ 的表达式中：\n$$\nJ(\\delta) = \\frac{1}{M} \\sum_{j=1}^{M} \\left( \\frac{1}{2} \\cos(\\delta) \\right)^{2} = \\frac{1}{M} \\sum_{j=1}^{M} \\frac{1}{4} \\cos^2(\\delta)\n$$\n由于求和项是常数，所以和是该项的 M 倍：\n$$\nJ(\\delta) = \\frac{1}{M} \\cdot M \\cdot \\frac{1}{4} \\cos^2(\\delta) = \\frac{1}{4} \\cos^2(\\delta)\n$$\n这就是干扰泛函 $J(\\delta)$ 的闭式表达式。\n\n接下来，我们必须找到最小化 $J(\\delta)$ 的值 $\\delta^{\\star}$。这等价于在 $\\delta \\in [0, 2\\pi)$ 上最小化 $\\cos^2(\\delta)$。函数 $\\cos^2(\\delta)$ 是非负的，其最小值为 0。当 $\\cos(\\delta) = 0$ 时达到此最小值。在区间 $[0, 2\\pi)$ 内满足此条件的 $\\delta$ 的值是 $\\delta = \\frac{\\pi}{2}$ 和 $\\delta = \\frac{3\\pi}{2}$。\n\n最后，我们考虑映射 $s \\mapsto h(s;c)$ 必须几乎处处保持单射的约束。任何上下文 $c$ 的编码是 $h(s;c) = W g(s;\\phi^{(c)})$。由于 W 是满列秩的，h 关于 s 的单射性等价于网格编码 $g(s;\\phi^{(c)})$ 的单射性。从位置 s 到向量空间 $\\mathbb{R}^M$ 的网格编码映射的单射性（几乎处处）是由网格周期 $\\{\\lambda_j\\}$ 两两不可通约的基本条件所保证的。这确保了当 s 变化时，$g(s;\\phi^{(c)})$ 所描绘的轨迹不会自相交。\n施加一个全局相位偏移 $\\delta$ 只是同时改变所有模块这条轨迹的起始相位。它不改变频率 $\\{k_j\\}$ 或它们的不可通约性。因此，对于任何 $\\delta$ 值，保证单射性的轨迹的几何属性都得以保留。因此，所有可能的 $\\delta$ 值都满足该约束，包括那两个最小化 $J(\\delta)$ 的值。\n\n问题要求的是“一个值” $\\delta^{\\star}$，这表明答案是唯一的。按照惯例，在没有其他标准的情况下，选择最小的正角。$\\frac{\\pi}{2}$ 和 $\\frac{3\\pi}{2}$ 都能导致两个上下文的表示之间的最大去相关（平均意义上的正交），从而最小化干扰。我们选择主值。\n\n因此，最小化干扰的全局相位偏移值为 $\\delta^{\\star} = \\frac{\\pi}{2}$。",
            "answer": "$$\n\\boxed{\\frac{\\pi}{2}}\n$$"
        }
    ]
}