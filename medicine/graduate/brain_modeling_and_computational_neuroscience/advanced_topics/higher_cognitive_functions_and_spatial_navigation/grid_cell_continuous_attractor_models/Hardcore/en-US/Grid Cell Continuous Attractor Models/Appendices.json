{
    "hands_on_practices": [
        {
            "introduction": "The defining feature of a continuous attractor is its unique stability profile: the network state is stable against perturbations that change the pattern's form but neutrally stable against translations that shift its position. This exercise provides a hands-on look at this principle by analyzing the stability of a simplified 'normal form' model . By computing the Jacobian and its eigenvalues, you will directly observe how these dynamics give rise to a stable pattern amplitude alongside neutrally stable 'Goldstone modes' corresponding to the phase, which is the mathematical heart of path integration.",
            "id": "3985883",
            "problem": "Consider a two-dimensional, translation-invariant neural field model for medial entorhinal cortex grid cells that supports a stationary hexagonal firing-rate pattern. Let the firing-rate field be denoted by $u(\\mathbf{x}, t)$ with $\\mathbf{x} \\in \\mathbb{R}^{2}$. The coarse-grained dynamics near the onset of pattern formation can be reduced, under standard symmetry and weakly nonlinear assumptions, to a low-dimensional system describing the global pattern amplitude and phase (lattice shift). Specifically, assume that the slow dynamics of the pattern amplitude $A(t) \\in \\mathbb{R}$ and the global phase (lattice shift) $\\boldsymbol{\\phi}(t) = (\\phi_{x}(t), \\phi_{y}(t)) \\in \\mathbb{R}^{2}$ are governed by the truncated normal form\n$$\n\\frac{dA}{dt} = \\mu A - \\gamma A^{3}, \\qquad \\frac{d\\phi_{x}}{dt} = 0, \\qquad \\frac{d\\phi_{y}}{dt} = 0,\n$$\nwhere $\\mu  0$ is the linear growth parameter (set by spectral properties of the synaptic kernel and neural gain at criticality) and $\\gamma  0$ is the leading-order nonlinear saturation coefficient (set by higher-order terms in the neural transfer function and recurrent interactions). The stationary hexagonal pattern with nonzero amplitude corresponds to $A^{\\ast}  0$ and an arbitrary constant $\\boldsymbol{\\phi}^{\\ast} \\in \\mathbb{R}^{2}$, reflecting continuous translational symmetry.\n\nCompute the Jacobian of the vector field of this $(A, \\phi_{x}, \\phi_{y})$ system at the stationary point with $A^{\\ast}  0$ and arbitrary $\\boldsymbol{\\phi}^{\\ast}$, and determine its eigenvalues. Use these eigenvalues to assess the linear stability of the stationary pattern against perturbations in amplitude and phase. Provide the ordered triple $(\\lambda_{A}, \\lambda_{\\phi_{x}}, \\lambda_{\\phi_{y}})$ of eigenvalues evaluated at the nontrivial stationary amplitude. Express your final answer as a single row matrix in terms of $\\mu$ only. No numerical approximation is required, and no units are needed. The final answer must be a single analytic expression.",
            "solution": "The user wants me to analyze the stability of a stationary pattern in a simplified model of grid cell activity.\n\n### Step 1: Problem Validation\n\n**1.1. Extract Givens**\n- **State variables**: The system is described by the amplitude $A(t) \\in \\mathbb{R}$ and the phase $\\boldsymbol{\\phi}(t) = (\\phi_{x}(t), \\phi_{y}(t)) \\in \\mathbb{R}^{2}$. The state vector is effectively $(A, \\phi_x, \\phi_y)$.\n- **Dynamical equations**:\n$$\n\\frac{dA}{dt} = \\mu A - \\gamma A^{3}\n$$\n$$\n\\frac{d\\phi_{x}}{dt} = 0\n$$\n$$\n\\frac{d\\phi_{y}}{dt} = 0\n$$\n- **Parameters**: $\\mu  0$ and $\\gamma  0$.\n- **Objective**: Compute the Jacobian of the vector field for the $(A, \\phi_{x}, \\phi_{y})$ system at the stationary point where the amplitude $A^{\\ast}  0$.\n- **Objective**: Determine the eigenvalues of this Jacobian.\n- **Objective**: Use the eigenvalues to assess the linear stability of the stationary pattern.\n- **Output Requirement**: Provide the ordered triple of eigenvalues $(\\lambda_{A}, \\lambda_{\\phi_{x}}, \\lambda_{\\phi_{y}})$ as a single row matrix expressed in terms of $\\mu$.\n\n**1.2. Validate Using Extracted Givens**\n- **Scientific Grounding**: The problem uses a standard normal form reduction for a pattern-forming system near a Turing instability. This is a canonical model in theoretical physics and computational neuroscience used to study continuous attractors, which are hypothesized to underlie grid cell firing patterns. The model is scientifically sound and relevant.\n- **Well-Posedness**: The problem is well-posed. It provides a complete set of ordinary differential equations and asks for a standard linear stability analysis at a specific fixed point. The existence of this fixed point is guaranteed by the conditions $\\mu  0$ and $\\gamma  0$. The requested calculations are standard and lead to a unique result.\n- **Objectivity**: The language is precise, technical, and free of any subjective or ambiguous statements.\n\n**1.3. Verdict and Action**\nThe problem is valid. It is scientifically grounded, well-posed, and objective. There are no contradictions, missing information, or other flaws. I will proceed with the solution.\n\n### Step 2: Solution Derivation\n\nThe system of differential equations is given by:\n$$\n\\frac{dA}{dt} = f_A(A, \\phi_x, \\phi_y) = \\mu A - \\gamma A^3\n$$\n$$\n\\frac{d\\phi_x}{dt} = f_{\\phi_x}(A, \\phi_x, \\phi_y) = 0\n$$\n$$\n\\frac{d\\phi_y}{dt} = f_{\\phi_y}(A, \\phi_x, \\phi_y) = 0\n$$\n\nFirst, we find the stationary point (or fixed point) of the system, denoted by $(A^{\\ast}, \\phi_x^{\\ast}, \\phi_y^{\\ast})$. A stationary point satisfies $\\frac{dA}{dt} = 0$, $\\frac{d\\phi_x}{dt} = 0$, and $\\frac{d\\phi_y}{dt} = 0$.\n\nThe equations for the phase components, $\\frac{d\\phi_x}{dt} = 0$ and $\\frac{d\\phi_y}{dt} = 0$, are satisfied for any constant values of $\\phi_x$ and $\\phi_y$. This reflects the continuous translational symmetry of the system, where any phase shift $\\boldsymbol{\\phi}$ is equally valid.\n\nThe equation for the amplitude is:\n$$\n\\mu A - \\gamma A^3 = 0\n$$\n$$\nA(\\mu - \\gamma A^2) = 0\n$$\nThis equation has two solutions for $A$. One is the trivial solution $A = 0$. The other is found by setting the term in the parenthesis to zero:\n$$\n\\mu - \\gamma A^2 = 0 \\implies A^2 = \\frac{\\mu}{\\gamma}\n$$\nThe problem specifies that we are interested in the stationary pattern with a nonzero amplitude, $A^{\\ast}  0$. Since $\\mu  0$ and $\\gamma  0$, we can take the positive square root:\n$$\nA^{\\ast} = \\sqrt{\\frac{\\mu}{\\gamma}}\n$$\nThus, the stationary points of interest form a continuous family (a manifold) described by $(A^{\\ast}, \\phi_x^{\\ast}, \\phi_y^{\\ast}) = (\\sqrt{\\frac{\\mu}{\\gamma}}, c_x, c_y)$, where $c_x$ and $c_y$ are arbitrary real constants.\n\nNext, we compute the Jacobian matrix, $J$, of the vector field $\\mathbf{F} = (f_A, f_{\\phi_x}, f_{\\phi_y})$ with respect to the state variables $(A, \\phi_x, \\phi_y)$.\n$$\nJ = \\begin{pmatrix}\n\\frac{\\partial f_A}{\\partial A}  \\frac{\\partial f_A}{\\partial \\phi_x}  \\frac{\\partial f_A}{\\partial \\phi_y} \\\\\n\\frac{\\partial f_{\\phi_x}}{\\partial A}  \\frac{\\partial f_{\\phi_x}}{\\partial \\phi_x}  \\frac{\\partial f_{\\phi_x}}{\\partial \\phi_y} \\\\\n\\frac{\\partial f_{\\phi_y}}{\\partial A}  \\frac{\\partial f_{\\phi_y}}{\\partial \\phi_x}  \\frac{\\partial f_{\\phi_y}}{\\partial \\phi_y}\n\\end{pmatrix}\n$$\nWe calculate the partial derivatives:\n$$\n\\frac{\\partial f_A}{\\partial A} = \\mu - 3\\gamma A^2\n$$\nAll other partial derivatives are zero because $f_A$ does not depend on $\\phi_x$ or $\\phi_y$, and $f_{\\phi_x}$ and $f_{\\phi_y}$ are identically zero.\n$$\n\\frac{\\partial f_A}{\\partial \\phi_x} = 0, \\quad \\frac{\\partial f_A}{\\partial \\phi_y} = 0\n$$\n$$\n\\frac{\\partial f_{\\phi_x}}{\\partial A} = \\frac{\\partial f_{\\phi_x}}{\\partial \\phi_x} = \\frac{\\partial f_{\\phi_x}}{\\partial \\phi_y} = 0\n$$\n$$\n\\frac{\\partial f_{\\phi_y}}{\\partial A} = \\frac{\\partial f_{\\phi_y}}{\\partial \\phi_x} = \\frac{\\partial f_{\\phi_y}}{\\partial \\phi_y} = 0\n$$\nThe Jacobian matrix is therefore:\n$$\nJ = \\begin{pmatrix}\n\\mu - 3\\gamma A^2  0  0 \\\\\n0  0  0 \\\\\n0  0  0\n\\end{pmatrix}\n$$\nNow, we evaluate this Jacobian at the stationary point where $A = A^{\\ast} = \\sqrt{\\frac{\\mu}{\\gamma}}$. Let's call this $J^{\\ast}$.\nThe only non-trivial element is the top-left one:\n$$\n\\frac{\\partial f_A}{\\partial A}\\bigg|_{A=A^{\\ast}} = \\mu - 3\\gamma (A^{\\ast})^2 = \\mu - 3\\gamma \\left(\\frac{\\mu}{\\gamma}\\right) = \\mu - 3\\mu = -2\\mu\n$$\nSo, the Jacobian evaluated at the stationary point is:\n$$\nJ^{\\ast} = \\begin{pmatrix}\n-2\\mu  0  0 \\\\\n0  0  0 \\\\\n0  0  0\n\\end{pmatrix}\n$$\nThe eigenvalues $(\\lambda)$ of a diagonal matrix are its diagonal entries. The eigenvalues of $J^{\\ast}$ are therefore:\n$$\n\\lambda_1 = -2\\mu, \\quad \\lambda_2 = 0, \\quad \\lambda_3 = 0\n$$\nThe first eigenvalue, $\\lambda_A = -2\\mu$, corresponds to the dynamics of the amplitude $A$. Since $\\mu  0$, this eigenvalue is negative, which indicates that the stationary amplitude $A^{\\ast}$ is stable to small perturbations. Any small deviation in amplitude will decay exponentially back to the fixed point value.\n\nThe other two eigenvalues, $\\lambda_{\\phi_x} = 0$ and $\\lambda_{\\phi_y} = 0$, correspond to the dynamics of the phase components $\\phi_x$ and $\\phi_y$. These zero eigenvalues indicate neutral or marginal stability. Physically, this means that if the phase is perturbed, it does not return to its original value, nor does it grow unbounded. It simply settles at the new value. This is the hallmark of a continuous attractor, where the zero eigenvalues correspond to directions of motion along the continuous manifold of fixed points (the \"attractor state\"). These are the Goldstone modes associated with the spontaneous breaking of the system's continuous translational symmetry.\n\nThe ordered triple of eigenvalues is $(\\lambda_{A}, \\lambda_{\\phi_{x}}, \\lambda_{\\phi_{y}}) = (-2\\mu, 0, 0)$. The problem requires this to be expressed as a single row matrix.",
            "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n-2\\mu  0  0\n\\end{pmatrix}\n}\n$$"
        },
        {
            "introduction": "The neutral stability along phase dimensions allows the network to integrate velocity inputs, updating the encoded spatial location without resistance. This practice moves from the abstract stability analysis to a concrete simulation of path integration, the primary function of grid cell attractor models . You will derive the low-dimensional dynamics that map velocity to phase shifts on a torus and implement a simulation to track the model's performance against the true physical displacement, exploring how factors like gain or rotational mismatches lead to integration errors.",
            "id": "3985930",
            "problem": "You are given a velocity time series and a translationally symmetric neural field that implements a two-dimensional path integration mechanism typical of grid cell continuous attractor models. Your task is to derive a reduced dynamical description for the bump phase on the torus and implement a simulation that quantifies the discrepancy between the simulated phase trajectory and the phase predicted by direct integration of the physical displacement. Use the following foundational base: translation invariance in a two-dimensional neural field implies a continuous family of bump solutions, and the corresponding Goldstone modes yield low-dimensional neutral dynamics of the bump center driven by input. Start from the continuous attractor neural network (CANN) formulation and derive the low-dimensional phase dynamics driven by velocity input. The comparison must be made on the two-dimensional torus with angles expressed in radians.\n\nDefinitions and setup:\n- Consider a two-dimensional continuous attractor neural field for activity $u(\\mathbf{x}, t)$, where $\\mathbf{x} \\in \\mathbb{R}^2$, with spatially translation-invariant recurrent connectivity and an external input encoding velocity. Periodic boundary conditions identify the activity bump’s center as a phase point on a torus $\\mathbb{T}^2$.\n- The physical velocity is $\\mathbf{v}(t) = (v_x(t), v_y(t))$ with units $\\mathrm{m/s}$, and the physical displacement is $\\mathbf{s}(t) = \\int_0^t \\mathbf{v}(\\tau)\\, d\\tau$ with units $\\mathrm{m}$.\n- The torus coordinates are angles $\\boldsymbol{\\phi}(t) = (\\phi_x(t), \\phi_y(t))$ with units radians, each defined modulo $2\\pi$. The spatial periods along the two axes are $\\boldsymbol{\\lambda} = (\\lambda_x, \\lambda_y)$ with units $\\mathrm{m}$, so that a displacement by $\\lambda_i$ along axis $i$ corresponds to a $2\\pi$ phase advance in $\\phi_i$.\n- The reduced low-dimensional dynamics should be derived from the CANN by projecting onto the neutral shift modes and expressing the phase evolution $\\boldsymbol{\\phi}(t)$ in terms of $\\mathbf{v}(t)$ and a coupling matrix consistent with the spatial periods $\\boldsymbol{\\lambda}$. Angles must be wrapped to the interval $[0, 2\\pi)$.\n\nError metric:\n- Given a simulated phase trajectory $\\boldsymbol{\\phi}_{\\mathrm{model}}(t)$ and a “true” phase trajectory $\\boldsymbol{\\phi}_{\\mathrm{true}}(t)$ obtained by mapping physical displacement $\\mathbf{s}(t)$ to torus angles using the spatial periods $\\boldsymbol{\\lambda}$, define the component-wise wrapped phase difference $\\Delta_i(t) = \\mathrm{wrap}\\big(\\phi_{\\mathrm{model}, i}(t) - \\phi_{\\mathrm{true}, i}(t)\\big)$, where $\\mathrm{wrap}(\\cdot)$ maps angles to $(-\\pi, \\pi]$. The instantaneous geodesic error on $\\mathbb{T}^2$ is $e(t) = \\sqrt{\\Delta_x(t)^2 + \\Delta_y(t)^2}$. The required scalar metric is the root-mean-square error $E = \\sqrt{\\frac{1}{N} \\sum_{n=1}^{N} e(t_n)^2}$, where $t_n$ are the discrete time samples and $N$ is the total number of samples. Report $E$ as a float rounded to six decimal places.\n\nAngle unit is radians. Physical units for velocity and spatial period are meters and meters per second as specified; the final error $E$ is a dimensionless float (radians).\n\nSimulation requirements:\n- Use discrete-time integration with a fixed time step $dt$ to compute $\\mathbf{s}(t)$ by summing $\\mathbf{v}(t) dt$ and to advance the model’s phase $\\boldsymbol{\\phi}_{\\mathrm{model}}(t)$ using the reduced phase dynamics derived from the continuous attractor neural field. At each step, wrap $\\boldsymbol{\\phi}_{\\mathrm{model}}(t)$ to $[0, 2\\pi)$ component-wise.\n- Compute $\\boldsymbol{\\phi}_{\\mathrm{true}}(t)$ by mapping $\\mathbf{s}(t)$ to angles using the spatial periods $\\boldsymbol{\\lambda}$: each component $\\phi_{\\mathrm{true}, i}(t)$ is the physical displacement $s_i(t)$ scaled to radians according to the period $\\lambda_i$, then wrapped to $[0, 2\\pi)$.\n- Implement the wrapped difference and the root-mean-square error $E$ as defined above.\n\nTest suite:\nImplement your program to run the following five cases, each fully specified by a discrete-time duration $T$, time step $dt$, spatial periods $\\boldsymbol{\\lambda}$, a velocity time series specification, and a model coupling matrix to be used in the reduced phase dynamics obtained from the derivation. All angles are in radians; velocities are in $\\mathrm{m/s}$; spatial periods are in $\\mathrm{m}$.\n\n- Case $1$ (general “happy path”):\n  - $T = 10.0$, $dt = 0.01$, $\\boldsymbol{\\lambda} = (0.5, 0.5)$.\n  - Velocity: constant $\\mathbf{v}(t) = (0.1, 0.05)$ for all $t \\in [0, T]$.\n  - Model coupling matrix equals the true mapping from velocity to phase rate consistent with $\\boldsymbol{\\lambda}$.\n- Case $2$ (boundary wrapping with high velocity):\n  - $T = 2.0$, $dt = 0.005$, $\\boldsymbol{\\lambda} = (0.25, 0.30)$.\n  - Velocity: constant $\\mathbf{v}(t) = (1.2, -0.8)$ for all $t \\in [0, T]$.\n  - Model coupling matrix equals the true mapping from velocity to phase rate consistent with $\\boldsymbol{\\lambda}$.\n- Case $3$ (gain mismatch):\n  - $T = 10.0$, $dt = 0.01$, $\\boldsymbol{\\lambda} = (0.5, 0.5)$.\n  - Velocity: constant $\\mathbf{v}(t) = (0.09, 0.07)$ for all $t \\in [0, T]$.\n  - Model coupling matrix is a scaled version of the true mapping with component-wise scale factors $1.02$ on $x$ and $0.97$ on $y$.\n- Case $4$ (zero velocity edge case):\n  - $T = 3.0$, $dt = 0.01$, $\\boldsymbol{\\lambda} = (0.5, 0.5)$.\n  - Velocity: constant $\\mathbf{v}(t) = (0.0, 0.0)$ for all $t \\in [0, T]$.\n  - Model coupling matrix equals the true mapping from velocity to phase rate consistent with $\\boldsymbol{\\lambda}$.\n- Case $5$ (rotational mismatch and sinusoidal velocity):\n  - $T = 8.0$, $dt = 0.01$, $\\boldsymbol{\\lambda} = (0.45, 0.60)$.\n  - Velocity: $\\mathbf{v}(t) = \\big(0.4 \\sin(2\\pi \\cdot 0.5 \\, t),\\; 0.3 \\cos(2\\pi \\cdot 0.75 \\, t)\\big)$ for all $t \\in [0, T]$.\n  - Model coupling matrix is a rotated version of the true mapping by angle $\\theta = \\pi/12$ in the output (phase) space.\n\nYour program must:\n- For each case, generate the velocity time series, simulate the phase dynamics on $\\mathbb{T}^2$ using the derived reduced model, compute the “true” phase from displacement and spatial periods, and then compute the root-mean-square geodesic error $E$.\n- Produce a single line of output containing the results as a comma-separated list enclosed in square brackets, with each float rounded to six decimal places, and no spaces. For example, the output should look like $[\\text{case1},\\text{case2},\\text{case3},\\text{case4},\\text{case5}]$, where each entry is the scalar $E$ for the corresponding case.",
            "solution": "We begin from the continuous attractor neural network (CANN) neural field equation for activity $u(\\mathbf{x}, t)$ defined on $\\mathbb{R}^2$ with spatially translation-invariant recurrent connectivity, a static nonlinearity, and an external input:\n$$\n\\tau \\frac{\\partial u(\\mathbf{x}, t)}{\\partial t} = -u(\\mathbf{x}, t) + \\int_{\\mathbb{R}^2} w(\\mathbf{x} - \\mathbf{x}') \\, \\phi\\big(u(\\mathbf{x}', t)\\big)\\, d\\mathbf{x}' + I(\\mathbf{x}, t),\n$$\nwhere $\\tau$ is a time constant, $w(\\mathbf{x} - \\mathbf{x}')$ is a translation-invariant kernel, $\\phi(\\cdot)$ is a static gain function, and $I(\\mathbf{x}, t)$ is an external input. Under standard assumptions for a grid-cell-like continuous attractor, there exists a stationary bump solution $u_0(\\mathbf{x} - \\boldsymbol{\\theta})$ parameterized by a continuous shift $\\boldsymbol{\\theta} \\in \\mathbb{R}^2$ due to translational symmetry. The presence of a continuous family of solutions implies a pair of neutral (Goldstone) modes associated with infinitesimal translations, given by the spatial derivatives $\\partial u_0 / \\partial x$ and $\\partial u_0 / \\partial y$.\n\nTo obtain the low-dimensional dynamics of the bump center (phase on the torus), we project the full dynamics onto the subspace spanned by these neutral modes. Let the adjoint eigenfunctions associated with the zero eigenvalue be denoted by $\\psi_x(\\mathbf{x})$ and $\\psi_y(\\mathbf{x})$, and consider a perturbation that shifts the bump center. Multiplying the neural field equation by $\\psi_i(\\mathbf{x})$ and integrating over space isolates the contribution that moves the bump:\n$$\n\\frac{d\\theta_i}{dt} = \\kappa_i \\int_{\\mathbb{R}^2} I(\\mathbf{x}, t)\\, \\frac{\\partial u_0(\\mathbf{x} - \\boldsymbol{\\theta})}{\\partial x_i}\\, d\\mathbf{x}, \\quad i \\in \\{x, y\\},\n$$\nwhere $\\kappa_i$ are normalization constants determined by the inner products of the adjoint modes and the derivatives of $u_0$. If the external input encodes physical velocity by coupling to the spatial derivatives of the bump, a widely used formulation is\n$$\nI(\\mathbf{x}, t) = a_x v_x(t)\\, \\frac{\\partial u_0(\\mathbf{x} - \\boldsymbol{\\theta})}{\\partial x} + a_y v_y(t)\\, \\frac{\\partial u_0(\\mathbf{x} - \\boldsymbol{\\theta})}{\\partial y},\n$$\nwhere $a_x$ and $a_y$ are gains along each axis and $\\mathbf{v}(t) = (v_x(t), v_y(t))$ is the physical velocity. Substituting this input and using orthogonality of the modes yields a linear relation between the bump center velocity and the physical velocity:\n$$\n\\frac{d\\boldsymbol{\\theta}}{dt} = \\mathbf{B}\\, \\mathbf{v}(t),\n$$\nwhere $\\mathbf{B} \\in \\mathbb{R}^{2 \\times 2}$ is a coupling matrix determined by the neural field, the choice of gains, and the shape of the bump. Periodic boundary conditions identify the bump position modulo the spatial periods along each axis, yielding a torus $\\mathbb{T}^2$. Each component of displacement $\\theta_i$ is related to a phase $\\phi_i$ by scaling so that a physical displacement by the spatial period $\\lambda_i$ corresponds to a phase advance of $2\\pi$:\n$$\n\\phi_i = \\frac{2\\pi}{\\lambda_i} \\theta_i \\quad \\Rightarrow \\quad \\frac{d\\phi_i}{dt} = \\frac{2\\pi}{\\lambda_i} \\frac{d\\theta_i}{dt} = \\sum_{j \\in \\{x,y\\}} K_{ij}\\, v_j(t),\n$$\nwith\n$$\n\\mathbf{K} = \\operatorname{diag}\\left(\\frac{2\\pi}{\\lambda_x}, \\frac{2\\pi}{\\lambda_y}\\right)\\, \\mathbf{B}.\n$$\nFor an ideal integrator that faithfully converts velocity to phase rate consistent with the spatial periods, the “true” mapping between displacement and phase is\n$$\n\\boldsymbol{\\phi}_{\\mathrm{true}}(t) = \\operatorname{wrap}_{2\\pi}\\left(\\operatorname{diag}\\left(\\frac{2\\pi}{\\lambda_x}, \\frac{2\\pi}{\\lambda_y}\\right) \\, \\mathbf{s}(t)\\right),\n$$\nwhere $\\mathbf{s}(t) = \\int_0^t \\mathbf{v}(\\tau)\\, d\\tau$ is the physical displacement and $\\operatorname{wrap}_{2\\pi}(\\cdot)$ wraps each angular component to $[0, 2\\pi)$. The simulated model phase evolves according to\n$$\n\\boldsymbol{\\phi}_{\\mathrm{model}}(t+\\Delta t) = \\operatorname{wrap}_{2\\pi}\\left(\\boldsymbol{\\phi}_{\\mathrm{model}}(t) + \\Delta t \\, \\mathbf{K}_{\\mathrm{model}} \\, \\mathbf{v}(t)\\right),\n$$\nwhere $\\mathbf{K}_{\\mathrm{model}}$ is the coupling matrix obtained from the reduced dynamics (which may differ from the true mapping due to gain or orientation mismatch). Note that the derivation from the CANN establishes the existence of such a linear relation by symmetry and mode projection; the specific values used in the test suite instantiate different regimes (perfect mapping, gain mismatch, rotation mismatch).\n\nTo compare the simulated phase to the “true” phase, we compute the wrapped difference component-wise\n$$\n\\Delta_i(t) = \\operatorname{wrap}_{\\pi}\\left(\\phi_{\\mathrm{model}, i}(t) - \\phi_{\\mathrm{true}, i}(t)\\right),\n$$\nwhere $\\operatorname{wrap}_{\\pi}(\\alpha) = ((\\alpha + \\pi) \\bmod 2\\pi) - \\pi$ maps to $(-\\pi, \\pi]$. The instantaneous geodesic error is\n$$\ne(t) = \\sqrt{\\Delta_x(t)^2 + \\Delta_y(t)^2},\n$$\nand the root-mean-square error is\n$$\nE = \\sqrt{\\frac{1}{N} \\sum_{n=1}^{N} e(t_n)^2},\n$$\nwhich we report as a float rounded to six decimal places.\n\nAlgorithmic design:\n- Discretize time into $N = \\lfloor T / dt \\rfloor$ steps with samples $t_n = n \\cdot dt$ for $n = 0, 1, \\ldots, N-1$.\n- Generate the velocity time series $\\mathbf{v}(t_n)$ according to each case specification.\n- Initialize $\\boldsymbol{\\phi}_{\\mathrm{model}}(0) = (0, 0)$ and $\\mathbf{s}(0) = (0, 0)$.\n- At each time step, update displacement $\\mathbf{s}(t_{n+1}) = \\mathbf{s}(t_n) + dt \\cdot \\mathbf{v}(t_n)$.\n- Compute $\\boldsymbol{\\phi}_{\\mathrm{true}}(t_{n+1})$ by scaling $\\mathbf{s}(t_{n+1})$ to radians with $\\operatorname{diag}\\left(\\frac{2\\pi}{\\lambda_x}, \\frac{2\\pi}{\\lambda_y}\\right)$ and wrapping to $[0, 2\\pi)$.\n- Update $\\boldsymbol{\\phi}_{\\mathrm{model}}(t_{n+1})$ by adding $dt \\cdot \\mathbf{K}_{\\mathrm{model}}\\mathbf{v}(t_n)$ to $\\boldsymbol{\\phi}_{\\mathrm{model}}(t_n)$ and wrapping to $[0, 2\\pi)$.\n- Compute wrapped differences $\\Delta_i(t_n)$, instantaneous error $e(t_n)$, and finally $E$ as the root-mean-square over all samples.\n- Repeat for each case using the specified $\\boldsymbol{\\lambda}$ and $\\mathbf{K}_{\\mathrm{model}}$:\n  - For cases with ideal mapping, use $\\mathbf{K}_{\\mathrm{model}} = \\operatorname{diag}\\left(\\frac{2\\pi}{\\lambda_x}, \\frac{2\\pi}{\\lambda_y}\\right)$.\n  - For gain mismatch, scale components by the specified factors.\n  - For rotational mismatch, pre-multiply by a rotation matrix\n    $$\n    \\mathbf{R}(\\theta) = \\begin{bmatrix}\n    \\cos \\theta  -\\sin \\theta \\\\\n    \\sin \\theta  \\cos \\theta\n    \\end{bmatrix}\n    $$\n    to obtain $\\mathbf{K}_{\\mathrm{model}} = \\mathbf{R}(\\theta) \\operatorname{diag}\\left(\\frac{2\\pi}{\\lambda_x}, \\frac{2\\pi}{\\lambda_y}\\right)$.\n\nNumerical aspects:\n- Wrapping is performed component-wise using modular arithmetic for $[0, 2\\pi)$ and $(-\\pi, \\pi]$.\n- The discretization error is minimized by choosing sufficiently small $dt$ relative to the time scales of the velocity signals.\n- The output is a single line containing $E$ for each case as a comma-separated list enclosed in brackets, with each float rounded to six decimal places and no spaces.\n\nThis design integrates symmetry-based reduction from the CANN and implements a principled comparison between the simulated toroidal phase trajectory and the physically integrated displacement’s corresponding phase.",
            "answer": "```python\nimport numpy as np\n\ndef wrap_to_2pi(angle):\n    # Wrap angles to [0, 2*pi)\n    return (angle % (2.0 * np.pi))\n\ndef wrap_to_pi(angle):\n    # Wrap angles to (-pi, pi]\n    return ((angle + np.pi) % (2.0 * np.pi)) - np.pi\n\ndef simulate_case(T, dt, lam, velocity_fn, K_model):\n    \"\"\"\n    Simulate phase dynamics on T^2 for a given velocity time series and model coupling.\n    Compute RMS geodesic error against true displacement-derived phase.\n\n    Parameters:\n    - T: duration (seconds)\n    - dt: timestep (seconds)\n    - lam: spatial periods (lambda_x, lambda_y) in meters\n    - velocity_fn: function returning velocity array shape (N, 2)\n    - K_model: 2x2 matrix mapping velocity to phase rate (radians per second)\n    \"\"\"\n    N = int(np.round(T / dt))\n    t = np.arange(N) * dt\n    v = velocity_fn(t)  # shape (N,2)\n\n    # True mapping from displacement to phase\n    K_true = np.diag(2.0 * np.pi / np.array(lam))\n\n    # Initialize displacement and phases\n    s = np.zeros(2)              # physical displacement (m)\n    phi_model = np.zeros(2)      # model phase (rad)\n    phi_true = np.zeros(2)       # true phase (rad)\n\n    errors_sq = np.zeros(N)\n\n    for n in range(N):\n        vn = v[n]\n\n        # Update displacement\n        s = s + dt * vn  # integrate velocity\n\n        # True phase from displacement\n        phi_true = wrap_to_2pi(K_true @ s)\n\n        # Model phase update from velocity\n        phi_model = wrap_to_2pi(phi_model + dt * (K_model @ vn))\n\n        # Wrapped difference and instantaneous geodesic error\n        delta = wrap_to_pi(phi_model - phi_true)\n        errors_sq[n] = np.sum(delta**2)\n\n    rms_error = float(np.sqrt(np.mean(errors_sq)))\n    return rms_error\n\ndef velocity_constant_factory(vx, vy):\n    def vfn(t):\n        return np.column_stack((np.full_like(t, vx, dtype=float),\n                                np.full_like(t, vy, dtype=float)))\n    return vfn\n\ndef velocity_sinusoidal_factory(ax, fx, ay, fy):\n    def vfn(t):\n        vx = ax * np.sin(2.0 * np.pi * fx * t)\n        vy = ay * np.cos(2.0 * np.pi * fy * t)\n        return np.column_stack((vx, vy))\n    return vfn\n\ndef solve():\n    # Define test cases as tuples: (T, dt, lambda, velocity_fn, K_model)\n    test_cases = []\n\n    # Case 1: Happy path\n    T1, dt1 = 10.0, 0.01\n    lam1 = (0.5, 0.5)\n    vfn1 = velocity_constant_factory(0.1, 0.05)\n    K_true1 = np.diag(2.0 * np.pi / np.array(lam1))\n    K_model1 = K_true1.copy()\n    test_cases.append((T1, dt1, lam1, vfn1, K_model1))\n\n    # Case 2: High velocity wrapping\n    T2, dt2 = 2.0, 0.005\n    lam2 = (0.25, 0.30)\n    vfn2 = velocity_constant_factory(1.2, -0.8)\n    K_true2 = np.diag(2.0 * np.pi / np.array(lam2))\n    K_model2 = K_true2.copy()\n    test_cases.append((T2, dt2, lam2, vfn2, K_model2))\n\n    # Case 3: Gain mismatch\n    T3, dt3 = 10.0, 0.01\n    lam3 = (0.5, 0.5)\n    vfn3 = velocity_constant_factory(0.09, 0.07)\n    K_true3 = np.diag(2.0 * np.pi / np.array(lam3))\n    scale = np.diag([1.02, 0.97])\n    K_model3 = scale @ K_true3\n    test_cases.append((T3, dt3, lam3, vfn3, K_model3))\n\n    # Case 4: Zero velocity\n    T4, dt4 = 3.0, 0.01\n    lam4 = (0.5, 0.5)\n    vfn4 = velocity_constant_factory(0.0, 0.0)\n    K_true4 = np.diag(2.0 * np.pi / np.array(lam4))\n    K_model4 = K_true4.copy()\n    test_cases.append((T4, dt4, lam4, vfn4, K_model4))\n\n    # Case 5: Rotational mismatch + sinusoidal velocity\n    T5, dt5 = 8.0, 0.01\n    lam5 = (0.45, 0.60)\n    vfn5 = velocity_sinusoidal_factory(ax=0.4, fx=0.5, ay=0.3, fy=0.75)\n    K_true5 = np.diag(2.0 * np.pi / np.array(lam5))\n    theta = np.pi / 12.0\n    R = np.array([[np.cos(theta), -np.sin(theta)],\n                  [np.sin(theta),  np.cos(theta)]])\n    K_model5 = R @ K_true5\n    test_cases.append((T5, dt5, lam5, vfn5, K_model5))\n\n    results = []\n    for (T, dt, lam, vfn, K_model) in test_cases:\n        rms_err = simulate_case(T, dt, lam, vfn, K_model)\n        results.append(f\"{rms_err:.6f}\")\n\n    print(f\"[{','.join(results)}]\")\n\nif __name__ == \"__main__\":\n    solve()\n```"
        },
        {
            "introduction": "A successful continuous attractor model of grid cells must produce spatial firing patterns with the hexagonal symmetry observed in experimental recordings. To verify this, we need a quantitative metric to measure the 'gridness' of a firing rate map. This exercise introduces the standard procedure for calculating the gridness score, a crucial tool for analyzing both model output and real neural data . You will learn how the six-fold rotational symmetry of a hexagonal lattice is detected by correlating a pattern's spatial autocorrelogram with its rotated versions.",
            "id": "3985974",
            "problem": "In continuous attractor network models of medial entorhinal cortex grid cells, a stable bump lattice in population activity gives rise to approximately hexagonal spatial firing fields in two dimensions. Consider a single neuron’s spatial firing rate map $r(\\mathbf{x})$ over a bounded, two-dimensional arena, where $\\mathbf{x}\\in\\mathbb{R}^2$ denotes spatial position. The spatial autocorrelogram is defined from first principles as the two-dimensional autocovariance (normalized to a correlation coefficient) of $r(\\mathbf{x})$ with itself at spatial offset $\\boldsymbol{\\Delta}$, \n$$\nA(\\boldsymbol{\\Delta}) \\equiv \\frac{\\sum_{\\mathbf{x}\\in\\Omega} \\left(r(\\mathbf{x})-\\bar{r}\\right)\\left(r(\\mathbf{x}+\\boldsymbol{\\Delta})-\\bar{r}\\right)}{\\sqrt{\\sum_{\\mathbf{x}\\in\\Omega} \\left(r(\\mathbf{x})-\\bar{r}\\right)^2}\\sqrt{\\sum_{\\mathbf{x}\\in\\Omega} \\left(r(\\mathbf{x}+\\boldsymbol{\\Delta})-\\bar{r}\\right)^2}},\n$$\nwhere $\\Omega$ is the set of sampled locations and $\\bar{r}$ is the mean firing rate over $\\Omega$. To assess sixfold rotational symmetry expected from a hexagonal lattice, one compares $A(\\boldsymbol{\\Delta})$ to rotated versions $A_\\theta(\\boldsymbol{\\Delta}) \\equiv A(\\mathbf{R}_\\theta \\boldsymbol{\\Delta})$, where $\\mathbf{R}_\\theta$ is the planar rotation by angle $\\theta$. In practice, to avoid the trivial central peak and to focus on the first ring of lattice peaks, one restricts comparisons to an annular mask $\\mathcal{M}$ in $\\boldsymbol{\\Delta}$-space that excludes the origin and spans the first ring of peaks and troughs.\n\nStarting from these definitions and the geometric property that a hexagonal lattice is invariant under rotations by multiples of $60^\\circ$ but not by $90^\\circ$, determine which of the following procedures correctly defines the gridness score and yields the correct numerical value using the following empirically obtained, ring-masked Pearson correlations between $A(\\boldsymbol{\\Delta})$ and its rotated versions $A_\\theta(\\boldsymbol{\\Delta})$ at multiples of $30^\\circ$:\n$C(30^\\circ)=0.08$, $C(60^\\circ)=0.62$, $C(90^\\circ)=-0.12$, $C(120^\\circ)=0.58$, $C(150^\\circ)=0.03$.\n\nChoose the single best option.\n\nA. Compute the gridness score as the difference between the worst-case hexagonal-aligned correlation and the worst-case off-hexagonal correlation, using the annular mask $\\mathcal{M}$ on the spatial autocorrelogram. Formally,\n$$\n\\mathrm{Gridness}=\\min\\{C(60^\\circ),\\,C(120^\\circ)\\}-\\max\\{C(30^\\circ),\\,C(90^\\circ),\\,C(150^\\circ)\\},\n$$\nwhich evaluates numerically to $0.58-0.08=0.50$.\n\nB. Compute the gridness score as the difference of the averages of the “hexagonal” and “non-hexagonal” correlations on the spatial autocorrelogram,\n$$\n\\mathrm{Gridness}=\\frac{C(60^\\circ)+C(120^\\circ)}{2}-\\frac{C(30^\\circ)+C(90^\\circ)+C(150^\\circ)}{3},\n$$\nwhich evaluates numerically to $0.60-(-0.003\\overline{3})\\approx 0.603\\overline{3}$.\n\nC. Compute the gridness score directly on the raw firing rate map $r(\\mathbf{x})$ by rotating $r(\\mathbf{x})$ and correlating it with itself under the annular mask $\\mathcal{M}$, then taking\n$$\n\\mathrm{Gridness}=\\min\\{C(60^\\circ),\\,C(120^\\circ)\\}-\\max\\{C(30^\\circ),\\,C(90^\\circ),\\,C(150^\\circ)\\},\n$$\nwhich evaluates numerically to $0.50$.\n\nD. Compute the gridness score as the ratio of the best hexagonal alignment to the worst non-hexagonal alignment on the spatial autocorrelogram,\n$$\n\\mathrm{Gridness}=\\frac{\\min\\{C(60^\\circ),\\,C(120^\\circ)\\}}{\\max\\{C(30^\\circ),\\,C(90^\\circ),\\,C(150^\\circ)\\}},\n$$\nwhich evaluates numerically to $\\frac{0.58}{0.08}=7.25$.",
            "solution": "### Problem Validation\n\n**Step 1: Extract Givens**\n\nThe problem statement provides the following definitions, conditions, and data:\n1.  **Subject**: Continuous attractor network models of medial entorhinal cortex grid cells.\n2.  **Firing Rate Map**: A single neuron’s spatial firing rate map is denoted as $r(\\mathbf{x})$ over a two-dimensional arena, with $\\mathbf{x} \\in \\mathbb{R}^2$.\n3.  **Spatial Autocorrelogram Definition**: The spatial autocorrelogram, $A(\\boldsymbol{\\Delta})$, is defined as the normalized two-dimensional autocovariance of $r(\\mathbf{x})$:\n    $$\n    A(\\boldsymbol{\\Delta}) \\equiv \\frac{\\sum_{\\mathbf{x}\\in\\Omega} \\left(r(\\mathbf{x})-\\bar{r}\\right)\\left(r(\\mathbf{x}+\\boldsymbol{\\Delta})-\\bar{r}\\right)}{\\sqrt{\\sum_{\\mathbf{x}\\in\\Omega} \\left(r(\\mathbf{x})-\\bar{r}\\right)^2}\\sqrt{\\sum_{\\mathbf{x}\\in\\Omega} \\left(r(\\mathbf{x}+\\boldsymbol{\\Delta})-\\bar{r}\\right)^2}}\n    $$\n    where $\\Omega$ is the set of sampled locations and $\\bar{r}$ is the mean firing rate.\n4.  **Rotated Autocorrelogram**: Rotated versions of the autocorrelogram are defined as $A_\\theta(\\boldsymbol{\\Delta}) \\equiv A(\\mathbf{R}_\\theta \\boldsymbol{\\Delta})$, where $\\mathbf{R}_\\theta$ is the planar rotation by angle $\\theta$.\n5.  **Annular Mask**: Comparisons are restricted to an annular mask $\\mathcal{M}$ in $\\boldsymbol{\\Delta}$-space, which excludes the origin and covers the first ring of peaks and troughs.\n6.  **Symmetry Property**: A hexagonal lattice is invariant under rotations by multiples of $60^\\circ$ but not by $90^\\circ$.\n7.  **Empirical Data**: The Pearson correlations between $A(\\boldsymbol{\\Delta})$ and its rotated versions $A_\\theta(\\boldsymbol{\\Delta})$ over the mask $\\mathcal{M}$ are given as $C(\\theta)$:\n    *   $C(30^\\circ) = 0.08$\n    *   $C(60^\\circ) = 0.62$\n    *   $C(90^\\circ) = -0.12$\n    *   $C(120^\\circ) = 0.58$\n    *   $C(150^\\circ) = 0.03$\n\n**Step 2: Validate Using Extracted Givens**\n\nThe problem statement is critically evaluated against established criteria:\n*   **Scientifically Grounded**: The problem is firmly rooted in the field of computational neuroscience, specifically the analysis of grid cell activity. The definitions of the spatial firing rate map, the spatial autocorrelogram (as a normalized autocovariance), the use of an annular mask, and the assessment of rotational symmetry are all standard, well-established methods in this research area, originally detailed in foundational papers (e.g., Hafting et al., 2005; Sargolini et al., 2006). The stated properties of hexagonal lattices are geometrically correct.\n*   **Well-Posed**: The problem is well-posed. It clearly defines all necessary terms and provides all the data required to evaluate the proposed formulas for the \"gridness score\". The question is unambiguous: determine which of the provided procedures is correct and yields the correct numerical result.\n*   **Objective**: The language is precise, technical, and free of any subjective or opinion-based claims.\n*   **Completeness and Consistency**: The problem is self-contained. There are no missing definitions or contradictory pieces of information.\n*   **Realism**: The provided correlation values are realistic for empirical data obtained from neuronal recordings or simulations.\n\n**Step 3: Verdict and Action**\n\nThe problem statement is **valid**. It is scientifically sound, well-posed, objective, and complete. Therefore, I will proceed with a full derivation and analysis.\n\n### Solution Derivation\n\nThe goal is to identify the correct definition and calculation of the \"gridness score,\" a metric designed to quantify the degree to which a neuron's spatial firing pattern resembles a hexagonal lattice.\n\n1.  **First Principles of Gridness Measurement**: A perfect hexagonal lattice possesses six-fold rotational symmetry. This means that the pattern is invariant under rotations by integer multiples of $360^\\circ/6 = 60^\\circ$. The spatial autocorrelogram, $A(\\boldsymbol{\\Delta})$, inherits this symmetry. Consequently, for a perfect grid cell, the autocorrelogram $A(\\boldsymbol{\\Delta})$ should be highly correlated with its versions rotated by $60^\\circ$ and $120^\\circ$. Conversely, rotations by angles that do not align with this symmetry (such as $30^\\circ$, $90^\\circ$, or $150^\\circ$) should result in a poor alignment and thus low correlation. A robust gridness score must capture this contrast: high correlation for symmetry-preserving rotations and low correlation for symmetry-breaking rotations.\n\n2.  **Formulation of the Gridness Score**: The standard and most widely accepted definition of the gridness score in neuroscience literature addresses this contrast by comparing the correlations at hexagonal-symmetry angles ($60^\\circ$ and $120^\\circ$) with those at non-hexagonal angles ($30^\\circ$, $90^\\circ$, and $150^\\circ$). The specific formulation is designed to be conservative and robust to noise. It is defined as the difference between the *minimum* correlation found at the hexagonal symmetry angles and the *maximum* correlation found at the non-hexagonal angles.\n    $$\n    \\mathrm{Gridness} = \\min\\{C(60^\\circ), C(120^\\circ)\\} - \\max\\{C(30^\\circ), C(90^\\circ), C(150^\\circ)\\}\n    $$\n    The use of $\\min$ ensures that the score is high only if the autocorrelogram exhibits strong alignment at *all* tested hexagonal symmetry angles. The use of $\\max$ ensures that the score is penalized if there is any significant correlation at angles that are *inconsistent* with hexagonal symmetry (e.g., a high $C(90^\\circ)$ might indicate square-like, not hexagonal, symmetry). This min-max formulation is more robust than using averages, which could mask a single poor alignment. The calculation must be performed on the spatial autocorrelogram $A(\\boldsymbol{\\Delta})$, not the raw firing rate map $r(\\mathbf{x})$, because the score is intended to measure the symmetry of the underlying periodic lattice structure, which is revealed by the autocorrelogram.\n\n3.  **Numerical Calculation**: Using the provided data, we can compute the gridness score.\n    *   Data: $C(30^\\circ)=0.08$, $C(60^\\circ)=0.62$, $C(90^\\circ)=-0.12$, $C(120^\\circ)=0.58$, $C(150^\\circ)=0.03$.\n    *   First term (minimum hexagonal-aligned correlation):\n        $$\n        \\min\\{C(60^\\circ), C(120^\\circ)\\} = \\min\\{0.62, 0.58\\} = 0.58\n        $$\n    *   Second term (maximum off-hexagonal correlation):\n        $$\n        \\max\\{C(30^\\circ), C(90^\\circ), C(150^\\circ)\\} = \\max\\{0.08, -0.12, 0.03\\} = 0.08\n        $$\n    *   Gridness score:\n        $$\n        \\mathrm{Gridness} = 0.58 - 0.08 = 0.50\n        $$\n\n### Option-by-Option Analysis\n\n**A. Compute the gridness score as the difference between the worst-case hexagonal-aligned correlation and the worst-case off-hexagonal correlation, using the annular mask $\\mathcal{M}$ on the spatial autocorrelogram. Formally, $\\mathrm{Gridness}=\\min\\{C(60^\\circ),\\,C(120^\\circ)\\}-\\max\\{C(30^\\circ),\\,C(90^\\circ),\\,C(150^\\circ)\\}$, which evaluates numerically to $0.58-0.08=0.50$.**\n\n*   **Analysis**: This option presents the correct, standard definition of the gridness score. The procedure described—operating on the spatial autocorrelogram and using the min-max formulation—is the canonical method. The numerical evaluation is also performed correctly based on the provided data and the formula.\n*   **Verdict**: **Correct**.\n\n**B. Compute the gridness score as the difference of the averages of the “hexagonal” and “non-hexagonal” correlations on the spatial autocorrelogram, $\\mathrm{Gridness}=\\frac{C(60^\\circ)+C(120^\\circ)}{2}-\\frac{C(30^\\circ)+C(90^\\circ)+C(150^\\circ)}{3}$, which evaluates numerically to $0.60-(-0.003\\overline{3})\\approx 0.603\\overline{3}$.**\n\n*   **Analysis**: This an alternative, but non-standard, formulation. Using averages is less robust than the min-max approach because a single aberrant correlation value (e.g., a low $C(60^\\circ)$ with a high $C(120^\\circ)$) would be masked, yielding a moderate score for a pattern that lacks consistent six-fold symmetry. The established scientific convention is the formula in option A.\n*   **Verdict**: **Incorrect**.\n\n**C. Compute the gridness score directly on the raw firing rate map $r(\\mathbf{x})$ by rotating $r(\\mathbf{x})$ and correlating it with itself under the annular mask $\\mathcal{M}$, then taking $\\mathrm{Gridness}=\\min\\{C(60^\\circ),\\,C(120^\\circ)\\}-\\max\\{C(30^\\circ),\\,C(90^\\circ),\\,C(150^\\circ)\\}$, which evaluates numerically to $0.50$.**\n\n*   **Analysis**: This option makes a fundamental conceptual error. The gridness score measures the periodicity and symmetry of the *lattice* of firing fields, not the rotational symmetry of the entire rate map within its environment. The correct object for this analysis is the spatial autocorrelogram $A(\\boldsymbol{\\Delta})$, which makes the periodic structure explicit. Applying this procedure to the raw rate map $r(\\mathbf{x})$ would measure something entirely different and would fail to correctly identify grid cells. For instance, a single, perfectly circular firing field at the center of the arena would yield a perfect score by this flawed method.\n*   **Verdict**: **Incorrect**.\n\n**D. Compute the gridness score as the ratio of the best hexagonal alignment to the worst non-hexagonal alignment on the spatial autocorrelogram, $\\mathrm{Gridness}=\\frac{\\min\\{C(60^\\circ),\\,C(120^\\circ)\\}}{\\max\\{C(30^\\circ),\\,C(90^\\circ),\\,C(150^\\circ)\\}}$, which evaluates numerically to $\\frac{0.58}{0.08}=7.25$.**\n\n*   **Analysis**: This option proposes a ratio-based metric. While it captures the idea of comparing on-axis to off-axis correlations, it is not the standard definition. A ratio can be numerically unstable, especially if the denominator (the max off-axis correlation) is close to zero, which can happen in practice. The subtractive method of option A is more stable and is the accepted standard in the field.\n*   **Verdict**: **Incorrect**.",
            "answer": "$$\\boxed{A}$$"
        }
    ]
}