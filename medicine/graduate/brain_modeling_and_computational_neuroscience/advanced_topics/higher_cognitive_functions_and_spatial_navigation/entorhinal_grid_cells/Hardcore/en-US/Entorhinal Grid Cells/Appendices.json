{
    "hands_on_practices": [
        {
            "introduction": "A foundational model for grid cell function is the continuous attractor network (CAN), which performs path integration by integrating velocity signals over time. However, biological velocity signals are inherently noisy, leading to an accumulation of error in the represented position. This exercise  guides you through a first-principles derivation to quantify how this error grows, revealing a fundamental challenge that the spatial navigation system must overcome.",
            "id": "3978900",
            "problem": "Consider a minimal path-integration model of Entorhinal cortex grid cells implemented by a Continuous Attractor Network (CAN). The CAN encodes a two-dimensional position estimate $\\hat{\\mathbf{r}}(t) \\in \\mathbb{R}^{2}$ by integrating velocity-coded inputs according to the kinematic identity $\\frac{d\\hat{\\mathbf{r}}}{dt}=\\mathbf{v}_{\\text{obs}}(t)$, where $\\mathbf{v}_{\\text{obs}}(t)$ is the observed velocity signal delivered by upstream neurons. Assume the true velocity is constant, $\\mathbf{v}_{0} \\in \\mathbb{R}^{2}$, and the observation noise is additive Gaussian white noise, so that $\\mathbf{v}_{\\text{obs}}(t)=\\mathbf{v}_{0}+\\boldsymbol{\\eta}(t)$ with $\\mathbb{E}[\\boldsymbol{\\eta}(t)]=\\mathbf{0}$ and component-wise covariance $\\mathbb{E}[\\eta_{i}(t)\\eta_{j}(t^{\\prime})]=2D\\,\\delta_{ij}\\,\\delta(t-t^{\\prime})$, where $D>0$ is a diffusion constant, $\\delta_{ij}$ is the Kronecker delta, and $\\delta(\\cdot)$ is the Dirac delta. The true position obeys $\\frac{d\\mathbf{r}}{dt}=\\mathbf{v}_{0}$.\n\nDefine the position error $\\mathbf{e}(t)=\\hat{\\mathbf{r}}(t)-\\mathbf{r}(t)$. Starting from the above definitions and properties of Gaussian white noise, derive the closed-form expression for the root-mean-square error magnitude $\\sqrt{\\mathbb{E}[|\\mathbf{e}(t)|^{2}]}$ in the two-dimensional case ($d=2$), expressed in terms of $D$ and $t$. Your answer must be a single analytic expression. Express the final magnitude in meters. No intermediate or target formulas are provided; base your derivation on first principles of stochastic integration and the given noise statistics.",
            "solution": "The Continuous Attractor Network (CAN) implements path integration via the kinematic relation $\\frac{d\\hat{\\mathbf{r}}}{dt}=\\mathbf{v}_{\\text{obs}}(t)$. With $\\mathbf{v}_{\\text{obs}}(t)=\\mathbf{v}_{0}+\\boldsymbol{\\eta}(t)$ and the true position obeying $\\frac{d\\mathbf{r}}{dt}=\\mathbf{v}_{0}$, we integrate both to obtain the position estimate and true position:\n$$\n\\hat{\\mathbf{r}}(t)=\\hat{\\mathbf{r}}(0)+\\int_{0}^{t}\\mathbf{v}_{\\text{obs}}(s)\\,ds=\\hat{\\mathbf{r}}(0)+\\int_{0}^{t}\\mathbf{v}_{0}\\,ds+\\int_{0}^{t}\\boldsymbol{\\eta}(s)\\,ds,\n$$\n$$\n\\mathbf{r}(t)=\\mathbf{r}(0)+\\int_{0}^{t}\\mathbf{v}_{0}\\,ds.\n$$\nSubtracting, the error is\n$$\n\\mathbf{e}(t)=\\hat{\\mathbf{r}}(t)-\\mathbf{r}(t)=\\left[\\hat{\\mathbf{r}}(0)-\\mathbf{r}(0)\\right]+\\int_{0}^{t}\\boldsymbol{\\eta}(s)\\,ds.\n$$\nIf the initial alignment is exact, $\\hat{\\mathbf{r}}(0)=\\mathbf{r}(0)$, then\n$$\n\\mathbf{e}(t)=\\int_{0}^{t}\\boldsymbol{\\eta}(s)\\,ds.\n$$\nWe seek the root-mean-square error magnitude $\\sqrt{\\mathbb{E}[|\\mathbf{e}(t)|^{2}]}$. Since $\\boldsymbol{\\eta}(t)$ is zero-mean Gaussian white noise with covariance $\\mathbb{E}[\\eta_{i}(t)\\eta_{j}(t^{\\prime})]=2D\\,\\delta_{ij}\\,\\delta(t-t^{\\prime})$, the integral of white noise yields a Wiener process with variance growing linearly in time. Compute the second moment of $\\mathbf{e}(t)$ component-wise. Let $e_{i}(t)=\\int_{0}^{t}\\eta_{i}(s)\\,ds$. Then\n$$\n\\mathbb{E}\\left[e_{i}(t)e_{j}(t)\\right]=\\mathbb{E}\\left[\\int_{0}^{t}\\int_{0}^{t}\\eta_{i}(s)\\eta_{j}(s^{\\prime})\\,ds\\,ds^{\\prime}\\right].\n$$\nUsing the given covariance,\n$$\n\\mathbb{E}\\left[\\eta_{i}(s)\\eta_{j}(s^{\\prime})\\right]=2D\\,\\delta_{ij}\\,\\delta(s-s^{\\prime}),\n$$\nwe substitute:\n$$\n\\mathbb{E}\\left[e_{i}(t)e_{j}(t)\\right]=\\int_{0}^{t}\\int_{0}^{t}2D\\,\\delta_{ij}\\,\\delta(s-s^{\\prime})\\,ds\\,ds^{\\prime}.\n$$\nEvaluate the inner integral using the sifting property of the Dirac delta. For fixed $s$, $\\int_{0}^{t}\\delta(s-s^{\\prime})\\,ds^{\\prime}=1$ for $s\\in[0,t]$, hence\n$$\n\\mathbb{E}\\left[e_{i}(t)e_{j}(t)\\right]=\\delta_{ij}\\int_{0}^{t}2D\\,ds=2D\\,t\\,\\delta_{ij}.\n$$\nTherefore, each component has variance $\\mathbb{E}[e_{i}(t)^{2}]=2D\\,t$, and different components are uncorrelated. The squared magnitude of the error is $|\\mathbf{e}(t)|^{2}=e_{1}(t)^{2}+e_{2}(t)^{2}$ in two dimensions. Its expectation is the sum of the component variances:\n$$\n\\mathbb{E}\\left[|\\mathbf{e}(t)|^{2}\\right]=\\mathbb{E}\\left[e_{1}(t)^{2}\\right]+\\mathbb{E}\\left[e_{2}(t)^{2}\\right]=2D\\,t+2D\\,t=4D\\,t.\n$$\nThe root-mean-square (RMS) error magnitude is\n$$\n\\sqrt{\\mathbb{E}\\left[|\\mathbf{e}(t)|^{2}\\right]}=\\sqrt{4D\\,t}=2\\sqrt{D\\,t}.\n$$\nThis expression has units of meters because $D$ carries units of $\\text{m}^{2}\\,\\text{s}^{-1}$ and $t$ has units of $\\text{s}$, yielding $\\text{m}^{2}$ inside the square root and thus meters after taking the root. The time dependence is $\\propto \\sqrt{t}$ via the square-root factor, characteristic of diffusive growth arising from integrating white noise.",
            "answer": "$$\\boxed{2\\sqrt{D\\,t}}$$"
        },
        {
            "introduction": "The defining characteristic of a grid cell is its spatially periodic firing pattern, which forms a hexagonal lattice across an environment. While this pattern can be seen in a firing rate map, a more rigorous and quantitative method for its identification is Fourier analysis. This practice  challenges you to mathematically transform a model grid cell's rate map into the frequency domain, showing how the hexagonal structure in real space gives rise to a corresponding hexagonal pattern of 'Bragg peaks' in Fourier space.",
            "id": "3978907",
            "problem": "A neuron in the medial entorhinal cortex exhibits a hexagonal array of firing fields in the plane. Model the spatial firing rate as a sum of identical fields located on a triangular Bravais lattice plus a constant baseline. Specifically, let the triangular lattice be generated by the basis vectors $\\mathbf{a}_{1} = a(1,0)$ and $\\mathbf{a}_{2} = a\\left(\\frac{1}{2}, \\frac{\\sqrt{3}}{2}\\right)$, where $a > 0$ is the nearest-neighbor lattice spacing and the angle between $\\mathbf{a}_{1}$ and $\\mathbf{a}_{2}$ is $60^\\circ$. The firing rate is\n$$\nr(\\mathbf{x}) \\;=\\; r_{b} \\;+\\; \\sum_{\\mathbf{R}\\in\\Lambda} A \\,\\exp\\!\\left(-\\frac{|\\mathbf{x}-\\mathbf{R}|^{2}}{2\\sigma^{2}}\\right),\n$$\nwhere $\\Lambda = \\{n_{1}\\mathbf{a}_{1} + n_{2}\\mathbf{a}_{2} \\,:\\, n_{1},n_{2}\\in\\mathbb{Z}\\}$, $A>0$ is the peak height of each Gaussian field above baseline at its center, $\\sigma>0$ is the field width, and $r_{b}\\ge 0$ is the baseline rate.\n\nUsing only the definition of the two-dimensional Fourier transform\n$$\n\\hat{r}(\\mathbf{k}) \\;=\\; \\int_{\\mathbb{R}^{2}} r(\\mathbf{x}) \\,\\exp\\!\\big(-i\\,\\mathbf{k}\\cdot\\mathbf{x}\\big)\\,d^{2}\\mathbf{x},\n$$\nand well-tested results from the Poisson summation formula for Bravais lattices, derive the spectral representation of $\\hat{r}(\\mathbf{k})$ and identify the locations of its Bragg peaks. Then, focusing on the first reciprocal-lattice shell (the six shortest nonzero reciprocal vectors of the triangular lattice), determine the amplitude coefficient multiplying the Dirac delta at any one of these six wavevectors as a closed-form analytic expression in terms of $A$, $a$, and $\\sigma$ only. Your final answer must be a single closed-form expression. Do not approximate or round. No units are required. State angles, where needed, in degrees.",
            "solution": "The problem statement is evaluated to be scientifically grounded, well-posed, objective, and self-contained. The model provides a canonical representation of entorhinal grid cell firing fields, a cornerstone of computational neuroscience. The task is a standard application of Fourier analysis to periodic structures, a technique widely used in physics and engineering. All parameters and conditions are clearly defined, leading to a unique and meaningful solution. The problem is valid.\n\nThe spatial firing rate $r(\\mathbf{x})$ is given by:\n$$\nr(\\mathbf{x}) = r_{b} + \\sum_{\\mathbf{R}\\in\\Lambda} A \\,\\exp\\left(-\\frac{|\\mathbf{x}-\\mathbf{R}|^{2}}{2\\sigma^{2}}\\right)\n$$\nwhere $r_b$ is a constant baseline rate and the sum represents the periodic arrangement of firing fields. We can separate the function into two parts: $r(\\mathbf{x}) = r_b + f(\\mathbf{x})$, where\n$$\nf(\\mathbf{x}) = \\sum_{\\mathbf{R}\\in\\Lambda} A g(\\mathbf{x}-\\mathbf{R})\n$$\nwith $g(\\mathbf{x}) = \\exp\\left(-\\frac{|\\mathbf{x}|^{2}}{2\\sigma^{2}}\\right)$.\n\nThe Fourier transform is a linear operator, so the Fourier transform of $r(\\mathbf{x})$, denoted $\\hat{r}(\\mathbf{k})$, is the sum of the transforms of its parts:\n$$\n\\hat{r}(\\mathbf{k}) = \\mathcal{F}\\{r_b\\} + \\mathcal{F}\\{f(\\mathbf{x})\\}\n$$\nThe Fourier transform of the constant baseline rate $r_b$ is a Dirac delta function at the origin of the frequency domain:\n$$\n\\mathcal{F}\\{r_b\\} = \\int_{\\mathbb{R}^2} r_b e^{-i\\mathbf{k}\\cdot\\mathbf{x}} d^2\\mathbf{x} = r_b (2\\pi)^2 \\delta(\\mathbf{k})\n$$\nwhere $\\delta(\\mathbf{k})$ is the two-dimensional Dirac delta function. This term contributes only to the DC component ($\\mathbf{k}=\\mathbf{0}$) of the spectrum.\n\nThe second term, $f(\\mathbf{x})$, can be expressed as a convolution of the single field shape $A g(\\mathbf{x})$ with a Dirac comb $S(\\mathbf{x})$ representing the lattice points:\n$$\nf(\\mathbf{x}) = A \\cdot (g * S)(\\mathbf{x})\n$$\nwhere $S(\\mathbf{x}) = \\sum_{\\mathbf{R}\\in\\Lambda} \\delta(\\mathbf{x}-\\mathbf{R})$.\n\nBy the convolution theorem, the Fourier transform of a convolution is the product of the individual Fourier transforms:\n$$\n\\hat{f}(\\mathbf{k}) = A \\cdot \\hat{g}(\\mathbf{k}) \\cdot \\hat{S}(\\mathbf{k})\n$$\nFirst, we find the Fourier transform of the Gaussian function $g(\\mathbf{x})$. This is a standard result: the Fourier transform of a Gaussian is also a Gaussian. For a 2D Gaussian $g(\\mathbf{x}) = \\exp(-\\alpha|\\mathbf{x}|^2)$, the Fourier transform is $\\hat{g}(\\mathbf{k}) = \\frac{\\pi}{\\alpha}\\exp(-|\\mathbf{k}|^2/(4\\alpha))$. In our case, $\\alpha = 1/(2\\sigma^2)$, so:\n$$\n\\hat{g}(\\mathbf{k}) = \\frac{\\pi}{1/(2\\sigma^2)} \\exp\\left( -\\frac{|\\mathbf{k}|^2}{4/(2\\sigma^2)} \\right) = 2\\pi\\sigma^2 \\exp\\left( -\\frac{\\sigma^2|\\mathbf{k}|^2}{2} \\right)\n$$\nNext, we find the Fourier transform of the Dirac comb $S(\\mathbf{x})$. The Poisson summation formula for a Bravais lattice states that the Fourier transform of a lattice of delta functions in real space is a lattice of delta functions in reciprocal space. The result is:\n$$\n\\hat{S}(\\mathbf{k}) = \\frac{(2\\pi)^2}{V_{\\text{cell}}} \\sum_{\\mathbf{K}\\in\\Lambda^*} \\delta(\\mathbf{k}-\\mathbf{K})\n$$\nwhere $\\Lambda^*$ is the reciprocal lattice and $V_{\\text{cell}}$ is the area of the real-space unit cell.\n\nThe real-space unit cell is the parallelogram spanned by the basis vectors $\\mathbf{a}_{1} = a(1,0)$ and $\\mathbf{a}_{2} = a(1/2, \\sqrt{3}/2)$. Its area is given by the magnitude of their cross product, or in 2D, the determinant of the matrix formed by them:\n$$\nV_{\\text{cell}} = \\left| \\det \\begin{pmatrix} a & a/2 \\\\ 0 & a\\sqrt{3}/2 \\end{pmatrix} \\right| = \\left| a \\cdot \\frac{a\\sqrt{3}}{2} - 0 \\cdot \\frac{a}{2} \\right| = \\frac{\\sqrt{3}}{2}a^2\n$$\nThe reciprocal lattice $\\Lambda^*$ is spanned by basis vectors $\\mathbf{b}_1, \\mathbf{b}_2$ satisfying $\\mathbf{a}_i \\cdot \\mathbf{b}_j = 2\\pi \\delta_{ij}$. Solving this system yields a set of reciprocal basis vectors. For the triangular lattice, the reciprocal lattice is also a triangular (hexagonal) lattice. The first shell of the reciprocal lattice consists of the six shortest non-zero wavevectors $\\mathbf{K}$. All vectors in this shell have the same magnitude, which we denote as $K_1$. For a triangular lattice with nearest-neighbor spacing $a$, this magnitude is known to be:\n$$\nK_1 = |\\mathbf{K}| = \\frac{4\\pi}{a\\sqrt{3}}\n$$\nTherefore, the magnitude squared is:\n$$\n|\\mathbf{K}|^2 = K_1^2 = \\frac{16\\pi^2}{3a^2}\n$$\nNow, we combine the expressions for $\\hat{g}(\\mathbf{k})$ and $\\hat{S}(\\mathbf{k})$ to find $\\hat{f}(\\mathbf{k})$:\n$$\n\\hat{f}(\\mathbf{k}) = A \\left( 2\\pi\\sigma^2 \\exp\\left(-\\frac{\\sigma^2|\\mathbf{k}|^2}{2}\\right) \\right) \\left( \\frac{(2\\pi)^2}{V_{\\text{cell}}} \\sum_{\\mathbf{K}\\in\\Lambda^*} \\delta(\\mathbf{k}-\\mathbf{K}) \\right)\n$$\nUsing the sifting property of the delta function, $h(\\mathbf{k})\\delta(\\mathbf{k}-\\mathbf{K}) = h(\\mathbf{K})\\delta(\\mathbf{k}-\\mathbf{K})$, we get:\n$$\n\\hat{f}(\\mathbf{k}) = \\frac{A(2\\pi)^3\\sigma^2}{V_{\\text{cell}}} \\sum_{\\mathbf{K}\\in\\Lambda^*} \\exp\\left(-\\frac{\\sigma^2|\\mathbf{K}|^2}{2}\\right) \\delta(\\mathbf{k}-\\mathbf{K})\n$$\nThe full spectrum $\\hat{r}(\\mathbf{k})$ is:\n$$\n\\hat{r}(\\mathbf{k}) = (2\\pi)^2 r_b \\delta(\\mathbf{k}) + \\frac{A(2\\pi)^3\\sigma^2}{V_{\\text{cell}}} \\sum_{\\mathbf{K}\\in\\Lambda^*} \\exp\\left(-\\frac{\\sigma^2|\\mathbf{K}|^2}{2}\\right) \\delta(\\mathbf{k}-\\mathbf{K})\n$$\nThis expression shows that the spectrum consists of discrete Bragg peaks at the locations of the reciprocal lattice vectors $\\mathbf{K}$.\n\nThe problem asks for the amplitude coefficient of the Dirac delta at any one of the six wavevectors in the first reciprocal-lattice shell. These correspond to the six nonzero vectors $\\mathbf{K}$ with the smallest magnitude, $|\\mathbf{K}| = K_1$. Let $C_{K_1}$ be this coefficient. From the expression for $\\hat{f}(\\mathbf{k})$, this coefficient is:\n$$\nC_{K_1} = \\frac{A(2\\pi)^3\\sigma^2}{V_{\\text{cell}}} \\exp\\left(-\\frac{\\sigma^2 K_1^2}{2}\\right)\n$$\nSubstituting $V_{\\text{cell}} = \\frac{\\sqrt{3}}{2}a^2$ and $K_1^2 = \\frac{16\\pi^2}{3a^2}$:\n$$\nC_{K_1} = \\frac{A(8\\pi^3)\\sigma^2}{\\frac{\\sqrt{3}}{2}a^2} \\exp\\left(-\\frac{\\sigma^2}{2} \\cdot \\frac{16\\pi^2}{3a^2}\\right)\n$$\nSimplifying the pre-factor and the exponent gives the final expression:\n$$\nC_{K_1} = \\frac{16\\pi^3 A \\sigma^2}{\\sqrt{3} a^2} \\exp\\left(-\\frac{8\\pi^2\\sigma^2}{3a^2}\\right)\n$$\nThis is the closed-form analytic expression for the amplitude coefficient of any of the six primary Bragg peaks in the spatial frequency domain, in terms of the given parameters $A$, $a$, and $\\sigma$.",
            "answer": "$$\n\\boxed{\\frac{16 \\pi^3 A \\sigma^2}{\\sqrt{3} a^2} \\exp\\left(-\\frac{8\\pi^2\\sigma^2}{3a^2}\\right)}\n$$"
        },
        {
            "introduction": "Moving from theoretical rate maps to practical neuroscience involves decoding information from discrete, noisy spike trains. In this computational exercise , you will implement a decoder that estimates an animal's spatial phase within a grid-cell lattice based on a simulated firing map. You will use Maximum Likelihood Estimation to find the best-fit phase and apply Fisher information theory to calculate a confidence interval for your estimate, a core skill in analyzing neural data.",
            "id": "3978961",
            "problem": "You are given a discretized two-dimensional spatial environment with positions in meters and an observed firing map as spike counts per spatial bin generated by a single entorhinal grid cell. The grid cell is modeled by a hexagonal lattice template. The goal is to estimate the spatial phase $\\phi$ by fitting a shifted lattice template to the observed firing map under Poisson spiking noise, and to derive a confidence interval for $\\phi$ using Fisher information.\n\nFundamental base:\n- Spiking is modeled as a Poisson process: for each bin $i$, the spike count $y_i$ is drawn independently as $y_i \\sim \\mathrm{Poisson}(\\mu_i)$, where $\\mu_i = \\Delta_i \\lambda(x_i; \\phi)$, $\\Delta_i$ is the occupancy duration (in seconds) of bin $i$, and $\\lambda(x_i; \\phi)$ is the firing rate (in spikes per second) at position $x_i$.\n- The Maximum Likelihood Estimator (MLE) for $\\phi$ maximizes the Poisson log-likelihood $\\ell(\\phi) = \\sum_i \\left[y_i \\log \\mu_i - \\mu_i - \\log(y_i!)\\right]$.\n- Asymptotic normal theory for MLE under regularity conditions states that $\\phi$ is approximately distributed as a multivariate normal around the true phase with covariance given by the inverse of the Fisher information matrix evaluated at the MLE. The Fisher information for independent Poisson observations is $I(\\phi) = \\sum_i \\mathbb{E}\\left[\\left(\\partial_\\phi \\log \\mu_i\\right)\\left(\\partial_\\phi \\log \\mu_i\\right)^\\top\\right] = \\sum_i \\mu_i \\left(\\partial_\\phi \\log \\mu_i\\right)\\left(\\partial_\\phi \\log \\mu_i\\right)^\\top$.\n\nModel specification:\n- Positions are two-dimensional vectors $x = (x_x, x_y)$ in meters.\n- The spatial phase $\\phi \\in \\mathbb{R}^2$ (in meters) is a shift vector of the lattice template within the fundamental domain.\n- Define the hexagonal lattice template using three cosine gratings:\n$$\nT(z) = \\sum_{k=1}^3 \\cos\\left(\\kappa \\, n_k \\cdot z\\right),\n$$\nwhere $z \\in \\mathbb{R}^2$, $\\kappa = \\frac{2\\pi}{\\lambda}$ with grid spacing $\\lambda$ in meters, and unit vectors\n$$\nn_1 = \\begin{bmatrix} 1 \\\\ 0 \\end{bmatrix},\\quad\nn_2 = \\begin{bmatrix} \\cos\\left(\\frac{\\pi}{3}\\right) \\\\ \\sin\\left(\\frac{\\pi}{3}\\right) \\end{bmatrix},\\quad\nn_3 = \\begin{bmatrix} \\cos\\left(\\frac{2\\pi}{3}\\right) \\\\ \\sin\\left(\\frac{2\\pi}{3}\\right) \\end{bmatrix}.\n$$\n- The firing rate map is\n$$\n\\lambda(x; \\phi) = r_0 + r_1 \\, T(x + \\phi),\n$$\nwith $r_0 > 3 r_1$ ensuring positivity of $\\lambda(x; \\phi)$ for all $x$ (units: spikes per second).\n- Occupancy is uniform per bin, $\\Delta_i = \\tau$ seconds for all $i$.\n\nOptimization target:\n- Estimate $\\phi$ by maximizing the Poisson log-likelihood with respect to $\\phi$ in the bounded domain $[0,\\lambda) \\times [0,\\lambda)$.\n\nGradients needed for optimization and information:\n- The gradient of $T$ with respect to its argument is\n$$\n\\nabla T(z) = -\\kappa \\sum_{k=1}^3 \\sin\\left(\\kappa \\, n_k \\cdot z\\right) n_k.\n$$\n- Using the chain rule, \n$$\n\\partial_\\phi \\lambda(x; \\phi) = r_1 \\nabla T(x + \\phi),\n$$\nand therefore\n$$\n\\partial_\\phi \\mu_i = \\tau \\, \\partial_\\phi \\lambda(x_i; \\phi) = \\tau r_1 \\nabla T(x_i + \\phi), \\quad\n\\partial_\\phi \\log \\mu_i = \\frac{\\partial_\\phi \\mu_i}{\\mu_i}.\n$$\n- The Fisher information matrix is\n$$\nI(\\phi) = \\sum_{i} \\frac{\\left(\\partial_\\phi \\mu_i\\right)\\left(\\partial_\\phi \\mu_i\\right)^\\top}{\\mu_i}\n= \\sum_i \\frac{\\left(\\tau r_1 \\nabla T(x_i + \\phi)\\right)\\left(\\tau r_1 \\nabla T(x_i + \\phi)\\right)^\\top}{\\tau \\lambda(x_i; \\phi)}\n= \\sum_i \\frac{\\tau r_1^2}{\\lambda(x_i; \\phi)} \\left(\\nabla T(x_i + \\phi)\\right)\\left(\\nabla T(x_i + \\phi)\\right)^\\top.\n$$\n\nConfidence interval:\n- Approximate the covariance matrix by $I(\\hat{\\phi})^{-1}$, where $\\hat{\\phi}$ is the MLE. A marginal $95\\%$ confidence interval (expressed as decimals without a percentage sign) for each component $\\phi_j$ is\n$$\n\\left[\\hat{\\phi}_j - 1.96 \\sqrt{\\Sigma_{jj}},\\; \\hat{\\phi}_j + 1.96 \\sqrt{\\Sigma_{jj}}\\right],\n$$\nwhere $\\Sigma = I(\\hat{\\phi})^{-1}$.\n- All spatial quantities including $\\phi$ and its confidence intervals must be expressed in meters. Angles in cosine arguments are in radians.\n\nImplementation requirements:\n- Discretize the environment as a uniform grid of positions $x_i$ over $[0,1] \\times [0,1]$ meters.\n- Use the provided parameters to generate a simulated firing map $y_i$ from the model under the given ground-truth $\\phi$ and Poisson noise.\n- Estimate $\\hat{\\phi}$ by maximizing the Poisson log-likelihood using a gradient-based optimizer with bound constraints, starting from multiple initial points to mitigate local maxima.\n- Compute the Fisher information at $\\hat{\\phi}$ and return component-wise $95\\%$ confidence intervals.\n\nTest suite:\nFor each case, the program should simulate data with a fixed random seed for reproducibility, then estimate $\\hat{\\phi}$ and output the confidence intervals.\n\n- Case 1 (happy path): $\\lambda = 0.30$ meters, $r_0 = 4.5$ spikes per second, $r_1 = 1.0$ spikes per second, $\\tau = 1.0$ seconds, grid $25 \\times 25$, true phase $\\phi = (0.12, 0.07)$ meters.\n- Case 2 (boundary phase): $\\lambda = 0.30$ meters, $r_0 = 5.0$ spikes per second, $r_1 = 0.8$ spikes per second, $\\tau = 0.5$ seconds, grid $25 \\times 25$, true phase $\\phi = (0.29, 0.29)$ meters.\n- Case 3 (low counts, wider intervals): $\\lambda = 0.30$ meters, $r_0 = 4.5$ spikes per second, $r_1 = 0.5$ spikes per second, $\\tau = 0.1$ seconds, grid $25 \\times 25$, true phase $\\phi = (0.18, 0.02)$ meters.\n\nFinal output format:\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets. Each test case must produce a list of six floats: $[\\hat{\\phi}_x, \\hat{\\phi}_y, \\mathrm{CI}_{x,\\mathrm{lower}}, \\mathrm{CI}_{x,\\mathrm{upper}}, \\mathrm{CI}_{y,\\mathrm{lower}}, \\mathrm{CI}_{y,\\mathrm{upper}}]$. Aggregate the three test case results into one list, for example: $[[\\dots],[\\dots],[\\dots]]$.",
            "solution": "The problem of estimating the spatial phase of an entorhinal grid cell from spike data is a well-posed and scientifically grounded task in computational neuroscience. It leverages established principles of statistical inference, namely Maximum Likelihood Estimation (MLE) for models involving Poisson processes. The problem is self-contained, providing all necessary mathematical models, parameters, and computational requirements to proceed with a solution.\n\nA minor inconsistency is noted in the \"Fundamental base\" section, where the general definition of the Fisher information appears as $I(\\phi) = \\sum_i \\mathbb{E}\\left[\\left(\\partial_\\phi \\log \\mu_i\\right)\\left(\\partial_\\phi \\log \\mu_i\\right)^\\top\\right]$. As $\\mu_i$ is a parameter, not a random variable, the expectation operator is misplaced. The correct general form involves the score function, $\\mathbb{E}[(\\partial_\\phi \\log P(y_i|\\phi))(\\partial_\\phi \\log P(y_i|\\phi))^\\top]$, where the expectation is over the data $y_i$. However, the problem immediately provides the correct, derived forms for the Poisson case, such as $I(\\phi) = \\sum_i \\frac{1}{\\mu_i}(\\partial_\\phi \\mu_i)(\\partial_\\phi \\mu_i)^\\top$. Since these subsequent, specific formulas are correct and provide an unambiguous basis for implementation, the initial notational error does not invalidate the problem. The solution proceeds based on these correct, explicitly provided formulas.\n\nThe solution is implemented by following a sequence of steps: data simulation, parameter estimation via numerical optimization, and confidence interval derivation using the Fisher information matrix.\n\n**1. Model Specification and Simulation of Firing Data**\n\nThe core of the model is the firing rate map $\\lambda(x; \\phi)$, which describes the expected firing rate of the grid cell at a spatial position $x = (x_x, x_y)$ given a spatial phase $\\phi = (\\phi_x, \\phi_y)$. The firing rate is defined as:\n$$\n\\lambda(x; \\phi) = r_0 + r_1 \\, T(x + \\phi)\n$$\nwhere $r_0$ is the baseline firing rate, $r_1$ is the modulation depth, and $T(z)$ is the hexagonal lattice template. The template is a sum of three cosine gratings:\n$$\nT(z) = \\sum_{k=1}^3 \\cos\\left(\\kappa \\, n_k \\cdot z\\right)\n$$\nHere, $\\kappa = \\frac{2\\pi}{\\lambda}$ is the spatial frequency determined by the grid spacing $\\lambda$, and $n_k$ are three unit vectors separated by $60^\\circ$ ($ \\pi/3 $ radians):\n$$\nn_1 = \\begin{bmatrix} 1 \\\\ 0 \\end{bmatrix},\\quad\nn_2 = \\begin{bmatrix} \\cos\\left(\\frac{\\pi}{3}\\right) \\\\ \\sin\\left(\\frac{\\pi}{3}\\right) \\end{bmatrix},\\quad\nn_3 = \\begin{bmatrix} \\cos\\left(\\frac{2\\pi}{3}\\right) \\\\ \\sin\\left(\\frac{2\\pi}{3}\\right) \\end{bmatrix}.\n$$\nThe environment is discretized into a uniform grid of $N$ spatial bins, indexed by $i$. For each test case, we first simulate the observed data. The mean spike count in each bin $i$ is $\\mu_i = \\tau \\lambda(x_i; \\phi_{true})$, where $\\tau$ is the uniform occupancy time per bin and $\\phi_{true}$ is the given ground-truth phase. Spike counts $y_i$ are then drawn from independent Poisson distributions:\n$$\ny_i \\sim \\mathrm{Poisson}(\\mu_i)\n$$\nTo ensure reproducibility, a fixed random seed is used for this data generation process.\n\n**2. Maximum Likelihood Estimation (MLE) of the Spatial Phase**\n\nThe goal is to estimate the phase $\\phi$ that best explains the observed spike counts $y_i$. We use the MLE method, which maximizes the log-likelihood of observing the data given the parameter $\\phi$. The log-likelihood for independent Poisson observations is:\n$$\n\\ell(\\phi) = \\sum_{i=1}^N \\left[ y_i \\log(\\mu_i(\\phi)) - \\mu_i(\\phi) - \\log(y_i!) \\right]\n$$\nMaximizing $\\ell(\\phi)$ is equivalent to minimizing its negative. Dropping terms that are constant with respect to $\\phi$, we obtain the objective function $J(\\phi)$ to be minimized:\n$$\nJ(\\phi) = \\sum_{i=1}^N \\left[ \\tau \\lambda(x_i; \\phi) - y_i \\log(\\lambda(x_i; \\phi)) \\right]\n$$\nThis is a non-linear optimization problem. We employ a gradient-based quasi-Newton method (`L-BFGS-B`) that can handle the bound constraints $\\phi \\in [0, \\lambda) \\times [0, \\lambda)$. The gradient (Jacobian) of the objective function with respect to $\\phi$ is required for this algorithm and is given by:\n$$\n\\nabla_\\phi J(\\phi) = \\sum_{i=1}^N \\left( \\tau - \\frac{y_i}{\\lambda(x_i; \\phi)} \\right) \\nabla_\\phi \\lambda(x_i; \\phi)\n$$\nUsing the chain rule, $\\nabla_\\phi \\lambda(x; \\phi) = r_1 \\nabla T(x + \\phi)$, where $\\nabla T(z)$ is the gradient of the template function:\n$$\n\\nabla T(z) = -\\kappa \\sum_{k=1}^3 \\sin\\left(\\kappa \\, n_k \\cdot z\\right) n_k\n$$\nThe likelihood landscape may contain multiple local minima. To find the global optimum, the optimization is performed multiple times from a grid of different starting points within the search domain $[0, \\lambda) \\times [0, \\lambda)$. The estimate $\\hat{\\phi}$ corresponding to the lowest value of $J(\\phi)$ across all starts is chosen as the final MLE.\n\n**3. Confidence Interval Calculation via Fisher Information**\n\nAccording to asymptotic theory for MLEs, the estimator $\\hat{\\phi}$ is approximately normally distributed around the true phase, with a covariance matrix given by the inverse of the Fisher Information matrix, $I(\\phi)^{-1}$. We evaluate the Fisher Information at the MLE, $I(\\hat{\\phi})$, to approximate this covariance. The Fisher Information matrix for this model is:\n$$\nI(\\phi) = \\sum_{i=1}^N \\frac{1}{\\mu_i(\\phi)} (\\nabla_\\phi \\mu_i(\\phi)) (\\nabla_\\phi \\mu_i(\\phi))^\\top = \\sum_{i=1}^N \\frac{\\tau r_1^2}{\\lambda(x_i; \\phi)} (\\nabla T(x_i + \\phi)) (\\nabla T(x_i + \\phi))^\\top\n$$\nThis expression is computed by summing the outer products of the template gradient vector over all spatial bins, weighted by a scalar factor. After computing the $2 \\times 2$ matrix $I(\\hat{\\phi})$, its inverse is calculated to obtain the covariance matrix $\\Sigma = I(\\hat{\\phi})^{-1}$.\n\nThe diagonal elements of $\\Sigma$, $\\Sigma_{xx}$ and $\\Sigma_{yy}$, represent the estimated variances of the phase components $\\hat{\\phi}_x$ and $\\hat{\\phi}_y$, respectively. A marginal $95\\%$ confidence interval for each component $\\phi_j$ is then constructed as:\n$$\n\\left[ \\hat{\\phi}_j - 1.96 \\sqrt{\\Sigma_{jj}}, \\; \\hat{\\phi}_j + 1.96 \\sqrt{\\Sigma_{jj}} \\right]\n$$\nThis provides a measure of uncertainty for the estimated phase components, with wider intervals indicating lower certainty, typically resulting from lower spike counts or weaker grid modulation. The final output for each test case consists of the estimated phase $\\hat{\\phi}$ and its associated confidence intervals.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.optimize import minimize\n\ndef solve():\n    \"\"\"\n    Solves the grid cell phase estimation problem for a suite of test cases.\n    For each case, it simulates firing data, estimates the spatial phase via MLE,\n    and computes 95% confidence intervals using the Fisher information matrix.\n    \"\"\"\n    # Set a fixed random seed for reproducibility of data simulation.\n    np.random.seed(42)\n\n    # Define the three unit vectors for the hexagonal lattice.\n    n_vectors = np.array([\n        [1.0, 0.0],\n        [np.cos(np.pi / 3), np.sin(np.pi / 3)],\n        [np.cos(2 * np.pi / 3), np.sin(2 * np.pi / 3)]\n    ])\n\n    test_cases = [\n        # Case 1: happy path\n        {'lambda_val': 0.30, 'r0': 4.5, 'r1': 1.0, 'tau': 1.0, 'grid_size': 25, 'true_phi': np.array([0.12, 0.07])},\n        # Case 2: boundary phase\n        {'lambda_val': 0.30, 'r0': 5.0, 'r1': 0.8, 'tau': 0.5, 'grid_size': 25, 'true_phi': np.array([0.29, 0.29])},\n        # Case 3: low counts, wider intervals\n        {'lambda_val': 0.30, 'r0': 4.5, 'r1': 0.5, 'tau': 0.1, 'grid_size': 25, 'true_phi': np.array([0.18, 0.02])},\n    ]\n\n    results = []\n\n    for case in test_cases:\n        # Unpack parameters for the current case\n        lambda_val = case['lambda_val']\n        r0 = case['r0']\n        r1 = case['r1']\n        tau = case['tau']\n        grid_size = case['grid_size']\n        true_phi = case['true_phi']\n        \n        kappa = 2 * np.pi / lambda_val\n\n        # 1. Setup environment and model functions\n        \n        # Create a grid of spatial positions\n        lin_space = np.linspace(0, 1.0, grid_size)\n        x_coords, y_coords = np.meshgrid(lin_space, lin_space)\n        positions = np.vstack([x_coords.ravel(), y_coords.ravel()]).T\n\n        # Define model functions\n        def T_template(z):\n            # z is an (N, 2) array of positions\n            cos_args = kappa * (z @ n_vectors.T) # N x 3\n            return np.sum(np.cos(cos_args), axis=1) # N x 1\n\n        def firing_rate(x, phi):\n            return r0 + r1 * T_template(x + phi)\n\n        def grad_T(z):\n            # z is an (N, 2) array of positions\n            sin_args = kappa * (z @ n_vectors.T) # N x 3\n            sines = -kappa * np.sin(sin_args) # N x 3\n            return sines @ n_vectors # (N x 3) @ (3 x 2) -> N x 2\n\n        # 2. Simulate observed firing map\n        \n        true_mean_rates = tau * firing_rate(positions, true_phi)\n        # Ensure rates are non-negative before passing to Poisson sampler\n        observed_spikes = np.random.poisson(np.maximum(0, true_mean_rates))\n\n        # 3. MLE Optimization\n        \n        # Define negative log-likelihood (objective function) and its gradient\n        def neg_log_likelihood(phi, x, y, r0_p, r1_p, tau_p, kappa_p):\n            rates = r0_p + r1_p * T_template(x + phi)\n            # Add a small epsilon to log to avoid log(0)\n            log_rates = np.log(rates + 1e-9)\n            return np.sum(tau_p * rates - y * log_rates)\n\n        def jacobian_neg_log_likelihood(phi, x, y, r0_p, r1_p, tau_p, kappa_p):\n            rates = r0_p + r1_p * T_template(x + phi)\n            rates_safe = rates + 1e-9\n            \n            grad_T_vals = grad_T(x + phi) # (N, 2)\n            \n            common_factor = tau_p - (y / rates_safe) # (N,)\n            \n            # Sum over all positions\n            grad = np.sum(common_factor[:, np.newaxis] * (r1_p * grad_T_vals), axis=0)\n            return grad\n\n        # Set up a multi-start optimization to find the global minimum\n        num_starts = 4  # Use a 4x4 grid of starting points\n        phi_starts = np.linspace(0, lambda_val, num_starts, endpoint=False)\n        initial_guesses = np.array(np.meshgrid(phi_starts, phi_starts)).T.reshape(-1, 2)\n\n        best_result = None\n        min_fun = np.inf\n        \n        bounds = [(0, lambda_val), (0, lambda_val)]\n        args_for_opt = (positions, observed_spikes, r0, r1, tau, kappa)\n\n        for phi0 in initial_guesses:\n            opt_result = minimize(\n                neg_log_likelihood,\n                phi0,\n                args=args_for_opt,\n                method='L-BFGS-B',\n                jac=jacobian_neg_log_likelihood,\n                bounds=bounds\n            )\n            if opt_result.success and opt_result.fun < min_fun:\n                min_fun = opt_result.fun\n                best_result = opt_result\n\n        phi_hat = best_result.x\n\n        # 4. Fisher Information and Confidence Intervals\n\n        # Calculate template gradients and firing rates at phi_hat\n        grads_T_at_phi_hat = grad_T(positions + phi_hat) # (N, 2)\n        lambda_at_phi_hat = firing_rate(positions, phi_hat) # (N,)\n        \n        # Calculate the Fisher Information matrix\n        fisher_matrix = np.zeros((2, 2))\n        scalar_weights = (tau * r1**2) / (lambda_at_phi_hat + 1e-9) # (N,)\n        \n        # Using einsum for efficient outer product summation\n        # 'ni,nj->nij' calculates the outer product for each of the N vectors\n        # Resulting array is (N, 2, 2)\n        outer_products = np.einsum('ni,nj->nij', grads_T_at_phi_hat, grads_T_at_phi_hat)\n        \n        # Weight each outer product and sum over N\n        fisher_matrix = np.sum(scalar_weights[:, np.newaxis, np.newaxis] * outer_products, axis=0)\n\n        # Invert Fisher matrix to get covariance matrix\n        try:\n            covariance_matrix = np.linalg.inv(fisher_matrix)\n            std_errors = np.sqrt(np.diag(covariance_matrix))\n            \n            # Calculate 95% CIs\n            z_score = 1.96\n            ci_lower = phi_hat - z_score * std_errors\n            ci_upper = phi_hat + z_score * std_errors\n            \n        except np.linalg.LinAlgError:\n            # Handle cases where the matrix is singular (e.g., no spikes)\n            ci_lower = np.array([np.nan, np.nan])\n            ci_upper = np.array([np.nan, np.nan])\n\n        # Store results for this case\n        case_result = [\n            phi_hat[0], phi_hat[1],\n            ci_lower[0], ci_upper[0],\n            ci_lower[1], ci_upper[1]\n        ]\n        results.append(case_result)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join([f'[{\",\".join(map(str, r))}]' for r in results])}]\")\n\nsolve()\n```"
        }
    ]
}