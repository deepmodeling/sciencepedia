{
    "hands_on_practices": [
        {
            "introduction": "The foundation of any successful Brain-Computer Interface is the faithful acquisition of minuscule neural signals. The very first challenge lies at the physical interface between the recording electrode and the amplifier, where improper electrical matching can lead to significant signal loss. This exercise  models this crucial junction as a simple voltage divider, allowing you to derive the signal attenuation and appreciate the critical importance of high input impedance in bioinstrumentation design.",
            "id": "3966620",
            "problem": "In a Brain-Computer Interface (BCI) system that records cortical potentials using Electroencephalography (EEG), the electrode-tissue interface can be modeled, under quasi-static conditions, as a Thevenin voltage source with open-circuit amplitude $V_{\\mathrm{s}}$ in series with an electrode contact impedance $Z_{\\mathrm{s}}$. The front-end amplifier presents an input impedance $Z_{\\mathrm{in}}$ across which the measured signal is taken. Assume linear time-invariant behavior and that the impedances can be treated as lumped elements. Using Kirchhoff’s laws and Ohm’s law, derive the general expression for the amplitude attenuation factor, defined as the ratio of the measured amplitude to the source amplitude, in terms of $Z_{\\mathrm{s}}$ and $Z_{\\mathrm{in}}$. Then, evaluate this attenuation for a purely resistive contact impedance of $1\\,\\mathrm{k}\\Omega$ and a purely resistive amplifier input impedance of $10\\,\\mathrm{M}\\Omega$. Express the final attenuation factor as an exact rational number in simplest form, as a pure dimensionless ratio with no units. No rounding is required.",
            "solution": "The problem statement is first subjected to validation.\n\n### Step 1: Extract Givens\n-   **System:** A Brain-Computer Interface (BCI) system recording cortical potentials using Electroencephalography (EEG).\n-   **Model:** The electrode-tissue interface is modeled as a Thevenin equivalent circuit.\n-   **Source:** A Thevenin voltage source with open-circuit amplitude $V_{\\mathrm{s}}$ in series with an electrode contact impedance $Z_{\\mathrm{s}}$.\n-   **Load:** A front-end amplifier with an input impedance $Z_{\\mathrm{in}}$.\n-   **Measurement Point:** The measured signal is the voltage across $Z_{\\mathrm{in}}$.\n-   **Assumptions:** Quasi-static conditions, linear time-invariant (LTI) behavior, and lumped element model for impedances.\n-   **Governing Principles:** Kirchhoff’s laws and Ohm’s law.\n-   **Definition:** The amplitude attenuation factor is the ratio of the measured amplitude to the source amplitude.\n-   **Task 1:** Derive the general expression for the amplitude attenuation factor in terms of $Z_{\\mathrm{s}}$ and $Z_{\\mathrm{in}}$.\n-   **Task 2:** Evaluate the attenuation factor for $Z_{\\mathrm{s}} = 1\\,\\mathrm{k}\\Omega$ (purely resistive) and $Z_{\\mathrm{in}} = 10\\,\\mathrm{M}\\Omega$ (purely resistive).\n-   **Required Output Format:** An exact rational number in simplest form, dimensionless.\n\n### Step 2: Validate Using Extracted Givens\n-   **Scientifically Grounded:** The problem is firmly grounded in fundamental electrical circuit theory. The use of a Thevenin equivalent circuit to model the electrode-amplifier interface is a standard and widely accepted practice in bioinstrumentation and electrophysiology, including EEG systems. The specified impedance values are realistic for such applications, where a low electrode contact impedance and a very high amplifier input impedance are desired to minimize signal loss.\n-   **Well-Posed:** The problem is clearly defined. It requests the derivation of a specific quantity (attenuation factor) based on a standard circuit model and then asks for a numerical evaluation using provided values. The setup guarantees a unique and meaningful solution.\n-   **Objective:** The language is technical and precise, with no subjective or ambiguous terms.\n\n### Step 3: Verdict and Action\nThe problem is scientifically sound, well-posed, and objective. It is a valid problem of circuit analysis as applied to bioinstrumentation. The solution process may proceed.\n\nThe system described constitutes a simple electrical circuit. The Thevenin source, consisting of the voltage $V_{\\mathrm{s}}$ in series with the impedance $Z_{\\mathrm{s}}$, is connected to the load, which is the amplifier input impedance $Z_{\\mathrm{in}}$. This forms a series circuit where $Z_{\\mathrm{s}}$ and $Z_{\\mathrm{in}}$ act as a voltage divider.\n\nLet $V_{\\mathrm{m}}$ be the measured voltage across the amplifier's input impedance $Z_{\\mathrm{in}}$. According to Kirchhoff's Voltage Law, the total voltage drop in the closed loop must equal the source voltage $V_{\\mathrm{s}}$. The total impedance of the series circuit is the sum of the individual impedances:\n$$Z_{\\mathrm{total}} = Z_{\\mathrm{s}} + Z_{\\mathrm{in}}$$\nUsing Ohm's law, the current $I$ flowing through the circuit is given by the source voltage divided by the total impedance:\n$$I = \\frac{V_{\\mathrm{s}}}{Z_{\\mathrm{total}}} = \\frac{V_{\\mathrm{s}}}{Z_{\\mathrm{s}} + Z_{\\mathrm{in}}}$$\nThe measured voltage $V_{\\mathrm{m}}$ across the input impedance $Z_{\\mathrm{in}}$ is found by applying Ohm's law to the load:\n$$V_{\\mathrm{m}} = I \\cdot Z_{\\mathrm{in}}$$\nSubstituting the expression for the current $I$ into this equation gives:\n$$V_{\\mathrm{m}} = \\left(\\frac{V_{\\mathrm{s}}}{Z_{\\mathrm{s}} + Z_{\\mathrm{in}}}\\right) Z_{\\mathrm{in}} = V_{\\mathrm{s}} \\frac{Z_{\\mathrm{in}}}{Z_{\\mathrm{s}} + Z_{\\mathrm{in}}}$$\nThe problem defines the amplitude attenuation factor, let us denote it by $A$, as the ratio of the measured amplitude to the source amplitude. In the context of LTI systems and impedances (which are complex quantities in the general case), \"amplitude\" refers to the magnitude of the complex voltage (phasor). Therefore, the attenuation factor $A$ is:\n$$A = \\frac{|V_{\\mathrm{m}}|}{|V_{\\mathrm{s}}|}$$\nSubstituting the relationship between $V_{\\mathrm{m}}$ and $V_{\\mathrm{s}}$:\n$$A = \\frac{\\left|V_{\\mathrm{s}} \\frac{Z_{\\mathrm{in}}}{Z_{\\mathrm{s}} + Z_{\\mathrm{in}}}\\right|}{|V_{\\mathrm{s}}|} = \\left|\\frac{Z_{\\mathrm{in}}}{Z_{\\mathrm{s}} + Z_{\\mathrm{in}}}\\right|$$\nThis is the general expression for the amplitude attenuation factor.\n\nThe second part of the problem requires evaluating this factor for specific values. The impedances are given as purely resistive. Thus, we can replace the complex impedances $Z_{\\mathrm{s}}$ and $Z_{\\mathrm{in}}$ with real-valued resistances $R_{\\mathrm{s}}$ and $R_{\\mathrm{in}}$, respectively.\nGiven:\n-   Source resistance, $R_{\\mathrm{s}} = 1\\,\\mathrm{k}\\Omega = 1 \\times 10^{3}\\,\\Omega$.\n-   Input resistance, $R_{\\mathrm{in}} = 10\\,\\mathrm{M}\\Omega = 10 \\times 10^{6}\\,\\Omega = 1 \\times 10^{7}\\,\\Omega$.\n\nSince resistances are positive real numbers, the absolute value in the expression for $A$ is redundant. The attenuation factor becomes:\n$$A = \\frac{R_{\\mathrm{in}}}{R_{\\mathrm{s}} + R_{\\mathrm{in}}}$$\nSubstituting the numerical values:\n$$A = \\frac{10 \\times 10^{6}\\,\\Omega}{1 \\times 10^{3}\\,\\Omega + 10 \\times 10^{6}\\,\\Omega} = \\frac{10,000,000}{1000 + 10,000,000} = \\frac{10,000,000}{10,001,000}$$\nThe problem requires this ratio to be expressed as an exact rational number in simplest form. We can simplify the fraction by dividing both the numerator and the denominator by their greatest common divisor. A common factor is $1000$:\n$$A = \\frac{10,000,000 \\div 1000}{10,001,000 \\div 1000} = \\frac{10000}{10001}$$\nTo confirm if this is the simplest form, we must check for common factors between the numerator, $10000 = 10^{4} = (2 \\cdot 5)^{4} = 2^{4} \\cdot 5^{4}$, and the denominator, $10001$. The prime factors of the numerator are $2$ and $5$. The number $10001$ is not divisible by $2$ (it is odd) or $5$ (it does not end in $0$ or $5$). Therefore, there are no common prime factors, and the fraction $\\frac{10000}{10001}$ is in its simplest form.",
            "answer": "$$\\boxed{\\frac{10000}{10001}}$$"
        },
        {
            "introduction": "Once a neural signal is acquired, the core task of a BCI is to decode the user's intent, often in the presence of noise and artifacts. This practice  explores how a BCI decoder based on a linear state-space model can optimally track a latent control variable over time. By deriving the behavior of the Kalman gain, you will see how the decoder intelligently adapts to increased measurement uncertainty, quantitatively revealing the fundamental trade-off between responsiveness to new information and stability against noise.",
            "id": "3966609",
            "problem": "Consider an Electroencephalography (EEG)-based Brain-Computer Interface (BCI) decoder modeled by a scalar linear Gaussian state-space process for a single latent control variable. Let the latent state be $x_k \\in \\mathbb{R}$ and the observation be $y_k \\in \\mathbb{R}$. The dynamics are given by the linear model $x_{k+1} = a x_k + w_k$, where $w_k$ is zero-mean Gaussian process noise with variance $q$, and the observation model is $y_k = h x_k + v_k$, where $v_k$ is zero-mean Gaussian measurement noise with variance $r$. Due to transient electromyographic artifact contamination, the observation becomes $y_k = h x_k + v_k + a_k$, where $a_k$ is zero-mean Gaussian artifact noise independent of $v_k$ and $w_k$, with variance $\\sigma_a^2$. Assume a standard recursive Bayesian estimator that minimizes mean-squared error under the linear Gaussian assumptions, and suppose at time $k$ the prior distribution of $x_k$ conditioned on past observations has mean $\\hat{x}_{k|k-1}$ and variance $p = \\operatorname{Var}(x_k \\mid y_{1:k-1})$.\n\nStarting from the definitions of the linear Gaussian model and Bayes’ rule, derive how the inflation of the measurement noise variance by $\\sigma_a^2$ alters the measurement update and, specifically, the gain factor that weights the innovation $y_k - h \\hat{x}_{k|k-1}$. Compute a closed-form analytic expression for the ratio between the artifact-inflated measurement gain and the baseline measurement gain, expressed purely in terms of $h$, $p$, $r$, and $\\sigma_a^2$. Express your final answer as a single simplified analytic expression. No numerical approximation or rounding is required.\n\nAdditionally, qualitatively discuss, based on your derivation, the implications of this variance inflation for decoder responsiveness (how quickly estimates track changes in $y_k$) and estimator stability (resistance to erratic fluctuations), but do not include any qualitative discussion in your final answer.",
            "solution": "The problem statement is evaluated as valid. It is scientifically grounded in the principles of Bayesian state estimation, specifically the Kalman filter, which is a standard method in signal processing and computational neuroscience for tasks like BCI decoding. The problem is well-posed, providing all necessary definitions, variables ($a$, $h$, $p$, $r$, $\\sigma_a^2$), and a clear objective. It is free from ambiguity, contradiction, and subjective content.\n\nThe core of the problem lies in the application of the measurement update step of a recursive Bayesian estimator for a linear Gaussian system. For such a system, the estimator that minimizes the mean-squared error is the Kalman filter. The problem is scalar, concerning a single latent state $x_k \\in \\mathbb{R}$ and a single observation $y_k \\in \\mathbb{R}$.\n\nThe filter operates in two steps: a prediction step and a measurement update step. The problem provides the prior distribution of the state at time $k$ conditioned on all past observations up to time $k-1$, denoted $y_{1:k-1}$. This prior is given as a Gaussian distribution with mean $\\hat{x}_{k|k-1}$ and variance $p$:\n$$p(x_k | y_{1:k-1}) = \\mathcal{N}(x_k; \\hat{x}_{k|k-1}, p)$$\n\nThe measurement update step incorporates the new observation $y_k$ to refine this prior into a posterior distribution $p(x_k | y_{1:k})$. According to Bayes' rule, the posterior is proportional to the product of the likelihood and the prior:\n$$p(x_k | y_{1:k}) \\propto p(y_k | x_k) p(x_k | y_{1:k-1})$$\n\nFor the given linear Gaussian model, the likelihood $p(y_k | x_k)$ is also Gaussian. The observation model is $y_k = h x_k + \\epsilon_k$, where $\\epsilon_k$ is the total measurement noise. Given $x_k$, $y_k$ is distributed as $\\mathcal{N}(y_k; h x_k, R_{\\text{total}})$, where $R_{\\text{total}}$ is the variance of the total measurement noise $\\epsilon_k$. Since the product of two Gaussian distributions is another (unnormalized) Gaussian, the posterior $p(x_k | y_{1:k})$ is also Gaussian.\n\nThe updated (posterior) state estimate $\\hat{x}_{k|k}$ and its variance $p_{k|k}$ are given by the standard Kalman filter measurement update equations. For the scalar case, the posterior mean is:\n$$\\hat{x}_{k|k} = \\hat{x}_{k|k-1} + K_k (y_k - h \\hat{x}_{k|k-1})$$\nThe term $(y_k - h \\hat{x}_{k|k-1})$ is the innovation or prediction error. The factor $K_k$ is the Kalman gain, which optimally weights this innovation. The gain is calculated to minimize the posterior variance $p_{k|k}$. The formula for the scalar Kalman gain is:\n$$K_k = \\frac{p h}{h^2 p + R_{\\text{total}}}$$\nwhere $p$ is the prior variance $\\operatorname{Var}(x_k \\mid y_{1:k-1})$, and $R_{\\text{total}}$ is the variance of the measurement noise process.\n\nWe will now compute the gain for two cases as specified by the problem.\n\nCase 1: Baseline (no artifact)\nIn the baseline scenario, the observation model is $y_k = h x_k + v_k$. The measurement noise is solely $v_k$, which is a zero-mean Gaussian process with variance $r$. Therefore, the total measurement noise variance is:\n$$R_{\\text{base}} = \\operatorname{Var}(v_k) = r$$\nThe baseline measurement gain, which we denote $K_{\\text{base}}$, is found by substituting $R_{\\text{base}}$ into the gain equation:\n$$K_{\\text{base}} = \\frac{p h}{h^2 p + r}$$\n\nCase 2: Artifact-Inflated\nIn the presence of artifact contamination, the observation model becomes $y_k = h x_k + v_k + a_k$. The total measurement noise is now the sum of the intrinsic measurement noise and the artifact noise: $\\epsilon_k = v_k + a_k$.\nThe problem states that $v_k$ and $a_k$ are independent, zero-mean Gaussian random variables with variances $r$ and $\\sigma_a^2$, respectively. The sum of two independent random variables has a variance equal to the sum of their individual variances. Thus, the variance of the total measurement noise is:\n$$R_{\\text{artifact}} = \\operatorname{Var}(v_k + a_k) = \\operatorname{Var}(v_k) + \\operatorname{Var}(a_k) = r + \\sigma_a^2$$\nThe artifact-inflated measurement gain, denoted $K_{\\text{artifact}}$, is found by substituting this new total variance into the gain equation:\n$$K_{\\text{artifact}} = \\frac{p h}{h^2 p + (r + \\sigma_a^2)}$$\n\nFinally, we compute the required ratio of the artifact-inflated gain to the baseline gain:\n$$\\frac{K_{\\text{artifact}}}{K_{\\text{base}}} = \\frac{\\frac{p h}{h^2 p + r + \\sigma_a^2}}{\\frac{p h}{h^2 p + r}}$$\nThe term $p h$ in the numerator of both expressions cancels out, yielding:\n$$\\frac{K_{\\text{artifact}}}{K_{\\text{base}}} = \\frac{h^2 p + r}{h^2 p + r + \\sigma_a^2}$$\nThis is the final closed-form analytic expression for the ratio, expressed purely in terms of the given variables $h$, $p$, $r$, and $\\sigma_a^2$.\n\nBased on this derivation, we can discuss the qualitative implications. Since the artifact variance $\\sigma_a^2$ is a non-negative quantity (a variance must be $\\ge 0$; for a non-trivial artifact, $\\sigma_a^2  0$), the denominator of the ratio, $h^2 p + r + \\sigma_a^2$, is strictly greater than the numerator, $h^2 p + r$. Consequently, the ratio is always less than $1$, meaning $K_{\\text{artifact}}  K_{\\text{base}}$. The presence of the artifact correctly forces the optimal estimator to reduce its gain.\n\nRegarding decoder responsiveness, the Kalman gain $K_k$ determines how much the state estimate is adjusted based on the new measurement. A smaller gain means the estimator places less weight on the incoming (and now less reliable) observation $y_k$ and more weight on its own prediction $\\hat{x}_{k|k-1}$. As a result, the state estimate becomes less sensitive to immediate changes in the measurement. This makes the BCI decoder less responsive, or more \"sluggish,\" in tracking the user's intent as reflected in the signal $y_k$.\n\nRegarding estimator stability, the reduced reliance on the noisy measurement has the benefit of making the estimate smoother and more robust against erratic fluctuations. The artifact noise $a_k$ introduces high-variance, spurious changes in $y_k$. By lowering the gain, the filter effectively filters out more of this noise, preventing it from corrupting the state estimate $x_k$. This increases the stability of the estimator. In essence, the Kalman filter automatically and optimally trades off responsiveness for stability when faced with increased measurement uncertainty. The inflation of the measurement noise variance by $\\sigma_a^2$ is the mechanism by which the filter is informed of this uncertainty.",
            "answer": "$$\\boxed{\\frac{h^2 p + r}{h^2 p + r + \\sigma_a^2}}$$"
        },
        {
            "introduction": "A BCI's performance must be validated with statistical rigor, a task complicated by the large number of features (e.g., channels, frequency bands) typically analyzed. This creates a multiple comparisons problem, where the likelihood of finding spurious effects by chance is high. This final exercise  introduces a powerful, non-parametric method to address this: a permutation test using the maximum statistic to control the family-wise error rate (FWER). By calculating an FWER-corrected $p$-value, you will practice a crucial skill for establishing the scientific credibility of BCI performance claims.",
            "id": "3966629",
            "problem": "A researcher is evaluating a motor-imagery Brain-Computer Interface (BCI) using multichannel electroencephalography (EEG) recordings. For each EEG channel-band pair, the classification pipeline applies feature extraction followed by a linear classifier and reports balanced accuracy. Let the balanced accuracy be denoted by $A_{\\text{bal}}$, and let the test statistic for a given channel $c$ and band $b$ be defined as $T_{c,b} = A_{\\text{bal}} - 0.5$, where $0.5$ corresponds to chance-level performance for a binary classification task. The null hypothesis is that labels are exchangeable, implying $T_{c,b}$ is centered at $0$ when the labels are permuted.\n\nTo control for multiple comparisons across channels and bands, the researcher uses a nonparametric permutation test with the maximum statistic across all tests: in each permutation $p$, labels are randomly permuted while preserving class counts, the pipeline is re-run identically, and the maximum test statistic across all channel-band pairs is computed, $\\max_{c,b} T_{c,b}^{(p)}$. The experiment includes $C = 32$ channels and $B = 5$ frequency bands, so there are $K = C \\times B$ simultaneous comparisons. The researcher performs $P = 10000$ independent label permutations and records the empirical distribution of the maximum statistic. The one-sided alternative hypothesis is that a specific pair $(c^{\\ast}, b^{\\ast})$ has $T_{c^{\\ast},b^{\\ast}} > 0$.\n\nFor the particular pair $(c^{\\ast}, b^{\\ast})$, the observed test statistic is $T_{c^{\\ast},b^{\\ast}}^{\\text{obs}} = 0.136$. Across the $P = 10000$ permutations, the number of permutation maxima satisfying $\\max_{c,b} T_{c,b}^{(p)} \\geq T_{c^{\\ast},b^{\\ast}}^{\\text{obs}}$ is $m = 214$. Assume exchangeability of labels under the null, and use a finite-sample conservative adjustment so that zero $p$-values do not occur.\n\nCompute the family-wise error rate (FWER) controlled $p$-value for the one-sided test using the empirical maximum-statistic permutation distribution. Round your answer to four significant figures. Express the final value as a decimal without a percentage sign.",
            "solution": "The problem statement is evaluated for validity and is found to be scientifically grounded, well-posed, and objective. It describes a standard and statistically sound procedure for multiple comparisons correction in neuroimaging data analysis, specifically the use of a maximum statistic permutation test to control the family-wise error rate (FWER). All necessary data for the calculation are provided.\n\nThe objective is to compute the FWER-controlled $p$-value for a specific observed test statistic using an empirical distribution derived from permutations. The family-wise error rate is the probability of making at least one Type I error (a false positive) among a family of simultaneous hypothesis tests, under the assumption that the global null hypothesis (i.e., all individual null hypotheses are true) is correct. The maximum statistic permutation testing procedure, as described, is designed to strongly control the FWER.\n\nThe test statistic for a given channel-band pair $(c, b)$ is defined as $T_{c,b} = A_{\\text{bal}} - 0.5$, where $A_{\\text{bal}}$ is the balanced accuracy and $0.5$ represents chance-level performance. The researcher is testing $K = C \\times B = 32 \\times 5 = 160$ hypotheses simultaneously. The specific observed statistic for the pair of interest, $(c^{\\ast}, b^{\\ast})$, is $T_{c^{\\ast},b^{\\ast}}^{\\text{obs}} = 0.136$.\n\nThe core of the method is to compare this observed statistic against the distribution of the *maximum* statistic obtained under the null hypothesis. The null hypothesis of exchangeability implies that permuting the class labels creates datasets consistent with the absence of a true effect. For each of $P = 10000$ permutations, the maximum test statistic across all $K$ pairs is calculated, yielding a set of values $\\{\\max_{c,b} T_{c,b}^{(p)}\\}_{p=1}^{P}$. This set forms the empirical null distribution for the maximum statistic.\n\nThe FWER-controlled $p$-value for the observed statistic $T_{c^{\\ast},b^{\\ast}}^{\\text{obs}}$ is the probability of observing a maximum permuted statistic at least as large as $T_{c^{\\ast},b^{\\ast}}^{\\text{obs}}$. This can be expressed as:\n$$\np_{\\text{FWER}} = \\text{Pr}(\\max_{c,b} T_{c,b}^{(p)} \\geq T_{c^{\\ast},b^{\\ast}}^{\\text{obs}} | H_0)\n$$\nwhere $H_0$ is the global null hypothesis.\n\nAn empirical estimate of this probability is the proportion of permutation maxima that meet this criterion. The problem states that $m = 214$ out of the $P = 10000$ permutations resulted in a maximum statistic greater than or equal to the observed statistic, i.e., instances where $\\max_{c,b} T_{c,b}^{(p)} \\geq T_{c^{\\ast},b^{\\ast}}^{\\text{obs}}$.\n\nThe problem specifies the use of a \"finite-sample conservative adjustment so that zero $p$-values do not occur.\" This refers to the standard practice of including the observed data's outcome as part of the permutation distribution. This adjustment prevents $p$-values of zero, which are nonsensical in a finite permutation sample, and provides a more accurate estimate of the true $p$-value. The formula for this adjusted $p$-value is:\n$$\np_{\\text{FWER}} = \\frac{m + 1}{P + 1}\n$$\nHere, $m$ is the count of permutations where the maximum statistic is greater than or equal to the observed statistic, and $P$ is the total number of permutations. The numerator is incremented to account for the observed statistic itself (which, under the null, is just another draw from the same distribution), and the denominator is incremented to reflect the total number of samples being considered ($P$ permutations plus the original data).\n\nSubstituting the given values:\n$m = 214$\n$P = 10000$\n\nWe compute the $p$-value:\n$$\np_{\\text{FWER}} = \\frac{214 + 1}{10000 + 1} = \\frac{215}{10001}\n$$\n\nNow, we perform the division to obtain the decimal value:\n$$\np_{\\text{FWER}} = \\frac{215}{10001} \\approx 0.02149785021...\n$$\n\nThe problem requires rounding the answer to four significant figures. The first four significant figures are $2$, $1$, $4$, and $9$. The fifth significant figure is $7$. Since $7 \\geq 5$, we round up the fourth significant figure, $9$. This results in a carry-over, changing the last part from $49$ to $50$.\n\nTherefore, the rounded $p$-value is $0.02150$. The trailing zero is significant and must be included.",
            "answer": "$$\\boxed{0.02150}$$"
        }
    ]
}