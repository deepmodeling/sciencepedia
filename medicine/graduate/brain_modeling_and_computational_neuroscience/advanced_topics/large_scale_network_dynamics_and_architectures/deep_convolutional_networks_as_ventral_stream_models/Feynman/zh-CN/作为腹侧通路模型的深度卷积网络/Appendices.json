{
    "hands_on_practices": [
        {
            "introduction": "深度卷积网络（DCNs）的层次结构是其成功模拟腹侧视觉通路的关键。这一结构使得模型能够建立起感受野（receptive fields）逐层增大的神经元，这与视觉皮层中的观察相符。本练习旨在通过推导和应用感受野尺寸的增长公式，加深对这一过程的定量理解，从而巩固您关于局部特征如何跨层整合成全局表征的直觉 。",
            "id": "3988311",
            "problem": "考虑一个灵长类动物腹侧视觉流的层次前馈模型，该模型实现为卷积神经网络（CNN）中的卷积层堆栈。在视觉神经科学中，神经元的感受野是感觉输入空间的一个子集，该空间中的刺激会调节神经元的活动。在具有离散输入的计算模型中，某一层中一个单元的感受野是指其值能够通过其下方的操作序列影响该单元激活的输入样本集合。假设沿着图像行进行一维空间索引；对于二维各向同性核和步幅，一维结果同样适用于两个轴。\n\n从以下基本基础出发：(i) 上述感受野的定义，即影响单元激活的输入子集；(ii) 一个经过充分验证的事实，即一个核大小为 $k_i$、步幅为 $s_i$ 的卷积层，对于当前层的每个单元，会从前一层采样 $k_i$ 个相邻单元，并且相对于前一层，当前层单元的位置间隔为 $s_i$ 个索引。令 $R_i$ 表示第 $i$ 层单元相对于原始输入样本的感受野大小，令 $S_i$ 表示第 $i$ 层单元相对于输入的有效采样步幅。\n\n根据第一性原理，推导出一个用 $\\{k_i\\}_{i=1}^{L}$ 和 $\\{s_i\\}_{i=1}^{L}$ 表示 $R_L$ 的闭式表达式。然后，将您的推导应用于以下受腹侧视觉流启发的具有 $L=4$ 层的架构：\n- 第1层：核大小 $k_1=7$，步幅 $s_1=2$（类V1的简单-复杂整合与子采样），\n- 第2层：核大小 $k_2=5$，步幅 $s_2=2$（类V2的整合与子采样），\n- 第3层：核大小 $k_3=9$，步幅 $s_3=2$（类V4的整合与子采样），\n- 第4层：核大小 $k_4=9$，步幅 $s_4=1$（类颞下皮层的整合，无子采样）。\n\n请以等于 $R_4$ 的单个整数形式提供您的最终答案，即以输入样本数量度量的顶层感受野大小。无需四舍五入。最终答案中不要包含任何单位。",
            "solution": "感受野定义为能够影响特定单元激活的输入值的集合。在层次前馈堆栈中，这个集合随着深度的增加而增长，因为每个单元都聚合了其下方多个单元的信息，而这些单元中的每一个本身又受到原始输入的不断扩大的子集的影响。\n\n我们在一维离散模型中将其形式化。令 $R_i$ 为第 $i$ 层相对于原始输入（第 $0$ 层）的感受野大小。基本情况是 $R_0 = 1$，因为一个输入样本影响其自身。定义 $S_i$ 为第 $i$ 层相对于输入的有效采样步幅。由于步幅是乘法复合的，我们有\n$$\nS_i \\;=\\; \\prod_{j=1}^{i} s_j, \\quad \\text{with} \\quad S_0 = 1.\n$$\n考虑从第 $i-1$ 层到第 $i$ 层的过渡。第 $i$ 层的一个单元从第 $i-1$ 层采样 $k_i$ 个相邻单元。最左边和最右边被采样的单元在第 $i-1$ 层上相隔 $k_i - 1$ 步，而第 $i-1$ 层的每一步对应于输入中的 $S_{i-1}$ 步。因此，由第 $i$ 层贡献的感受野增量扩展为 $(k_i - 1) \\, S_{i-1}$。第 $i$ 层的总感受野是第 $i-1$ 层的感受野加上这个增量：\n$$\nR_i \\;=\\; R_{i-1} \\;+\\; (k_i - 1) \\, S_{i-1}.\n$$\n从 $R_0 = 1$ 展开这个递归关系，得到一个闭式形式：\n$$\nR_L \\;=\\; 1 \\;+\\; \\sum_{i=1}^{L} (k_i - 1) \\, \\prod_{j=1}^{i-1} s_j.\n$$\n我们现在为指定的架构计算 $R_4$：\n- 给定 $k_1 = 7, s_1 = 2, k_2 = 5, s_2 = 2, k_3 = 9, s_3 = 2, k_4 = 9, s_4 = 1$。\n- 计算 $i = 1,2,3,4$ 时的乘积 $\\prod_{j=1}^{i-1} s_j$：\n  - 对于 $i=1$，空积为 $1$，所以 $\\prod_{j=1}^{0} s_j = 1$。\n  - 对于 $i=2$，$\\prod_{j=1}^{1} s_j = s_1 = 2$。\n  - 对于 $i=3$，$\\prod_{j=1}^{2} s_j = s_1 s_2 = 2 \\cdot 2 = 4$。\n  - 对于 $i=4$，$\\prod_{j=1}^{3} s_j = s_1 s_2 s_3 = 2 \\cdot 2 \\cdot 2 = 8$。\n- 计算每一项 $(k_i - 1) \\prod_{j=1}^{i-1} s_j$：\n  - 对于 $i=1$：$(k_1 - 1) \\cdot 1 = (7 - 1) \\cdot 1 = 6$。\n  - 对于 $i=2$：$(k_2 - 1) \\cdot 2 = (5 - 1) \\cdot 2 = 4 \\cdot 2 = 8$。\n  - 对于 $i=3$：$(k_3 - 1) \\cdot 4 = (9 - 1) \\cdot 4 = 8 \\cdot 4 = 32$。\n  - 对于 $i=4$：$(k_4 - 1) \\cdot 8 = (9 - 1) \\cdot 8 = 8 \\cdot 8 = 64$。\n- 求和并加上基数 $1$：\n$$\nR_4 \\;=\\; 1 + (6 + 8 + 32 + 64) \\;=\\; 1 + 110 \\;=\\; 111.\n$$\n\n因此，顶层感受野在一个维度上跨越 $111$ 个输入样本。对于各向同性的二维核和步幅，感受野范围在每个轴上是相同的，感受野区域将是 $111 \\times 111$，但所要求的量是一维跨度 $R_4$。",
            "answer": "$$\\boxed{111}$$"
        },
        {
            "introduction": "尽管 DCNs 在物体识别方面表现出色，但它们实现这一目标的方式常与人类不同，表现出对纹理的偏好超过形状，即所谓的“纹理偏见”。本练习将探讨一个简化的理论模型，以理解这种偏见如何直接源于训练数据的统计特性 。这项实践将超越模型架构本身，深入探讨学习环境的关键作用，您将通过数学推导来量化这种偏见，并通过数据重加权方法设计解决方案，为构建更接近人类视觉特性的模型提供深刻见解。",
            "id": "3974084",
            "problem": "考虑一个简化的理论分析，探讨一个通过经验风险最小化训练的深度卷积神经网络（DCNN）在作为灵长类动物腹侧视觉通路模型时，如何获得纹理偏差。假设一个二元分类任务，标签为 $y \\in \\{-1, +1\\}$，每张图像有两个潜在线索：形状线索 $s$ 和纹理线索 $t$。假设一个从固定特征表示 $(s,t)$ 中进行的线性读出，通过最小二乘法进行训练以预测 $y$，这是大样本极限下基于梯度的训练动态的一个标准分析代理。每个训练样本由三种增强机制之一生成，其混合比例 $f_A$、$f_B$ 和 $f_C$ 的总和为 $1$：\n- 机制 A（比例 $f_A$）：形状和纹理都与标签对齐，模型为 $s = y + \\eta_{s,A}$ 和 $t = y + \\eta_{t,A}$。\n- 机制 B（比例 $f_B$）：形状对齐但纹理被随机化（破坏），模型为 $s = y + \\eta_{s,B}$ 和 $t = \\eta_{t,B}$，与 $y$ 无关。\n- 机制 C（比例 $f_C$）：一种线索冲突操作，其中纹理与标签反对齐，模型为 $s = y + \\eta_{s,C}$ 和 $t = -y + \\eta_{t,C}$。\n\n假设在所有机制中：$y$ 取 $+1$ 或 $-1$ 的概率相等，所有噪声 $\\eta$ 均为零均值，与 $y$ 相互独立，并且在不同线索和机制之间也相互独立，并具有以下方差：$\\sigma_{s,A}^{2} = \\sigma_{s,B}^{2} = \\sigma_{s,C}^{2} = 2.25$，$\\sigma_{t,A}^{2} = \\sigma_{t,C}^{2} = 0.0025$ 以及 $\\sigma_{t,B}^{2} = 1.0$。假设数据集构成为 $f_A = 0.9$，$f_B = 0.05$ 以及 $f_C = 0.05$。\n\n定义最小二乘线性读出 $w = (w_s, w_t)^\\top$，该读出最小化期望平方误差 $E[(y - w_s s - w_t t)^2]$。在大样本极限下，$w$ 满足正规方程 $w = \\Sigma_{xx}^{-1} \\Sigma_{xy}$，其中 $\\Sigma_{xx} = \\mathrm{Cov}([s,t]^\\top)$ 和 $\\Sigma_{xy} = \\mathrm{Cov}([s,t]^\\top, y)$ 是在混合分布下的协方差。\n\n任务：\n1. 从上述生成性假设和正规方程出发，推导 $\\Sigma_{xx}$ 和 $\\Sigma_{xy}$ 作为 $f_A$、$f_B$、$f_C$ 和指定噪声方差的函数的解析表达式。然后计算 $w$，并对于给定的数值，证明 $|w_t| > |w_s|$（即存在纹理偏差）。\n2. 提出一种有原则的重要性重加权方法，通过非负因子 $\\alpha_A$、$\\alpha_B$、$\\alpha_C$（不一定总和为 $1$）对不同机制的训练样本进行重加权，旨在消除加权总体中纹理和标签之间的净相关性，即在大样本极限下强制实现 $\\mathrm{Cov}_{\\alpha}(t,y) = 0$。采用约定 $\\alpha_A = 1$ 和 $\\alpha_B = 1$，求解能实现 $\\mathrm{Cov}_{\\alpha}(t,y) = 0$ 的单个自由参数 $\\alpha_C$。\n\n对于指定的 $f_A$、$f_B$ 和 $f_C$，给出能达到此目标的 $\\alpha_C$ 的值作为最终答案。最终答案表示为一个精确的实数（不要四舍五入）。",
            "solution": "该问题被认为是有效的，因为它具有科学依据、问题设定良好、客观且内部一致。它是在统计学习理论应用于计算神经科学问题方面的一个标准理论练习。我们开始解题。\n\n根据问题陈述，解答分为两部分。首先，我们推导线性读出的权重 $w_s$ 和 $w_t$ 并证明纹理偏差的存在。其次，我们确定消除纹理-标签相关性所需的重要性权重 $\\alpha_C$。\n\n首先，我们计算必要的协方差矩阵 $\\Sigma_{xx}$ 和 $\\Sigma_{xy}$。总体是三种机制的混合，因此我们使用全期望定律。对于任何随机变量 $Z$，其期望为 $E[Z] = f_A E[Z|A] + f_B E[Z|B] + f_C E[Z|C]$，其中 $A$、$B$ 和 $C$ 表示三种数据生成机制。\n\n首先，我们确定变量的均值。标签 $y$ 是平衡的，所以 $E[y] = \\frac{1}{2}(+1) + \\frac{1}{2}(-1) = 0$。因此，$E[y^2] = \\frac{1}{2}(+1)^2 + \\frac{1}{2}(-1)^2 = 1$。噪声 $\\eta$ 是零均值的，$E[\\eta]=0$，并且与 $y$ 以及彼此之间相互独立。\n\n线索 $s$ 和 $t$ 的均值为：\n$E[s] = E[f_A(y+\\eta_{s,A}) + f_B(y+\\eta_{s,B}) + f_C(y+\\eta_{s,C})] = (f_A+f_B+f_C)E[y] = E[y] = 0$。\n$E[t] = E[f_A(y+\\eta_{t,A}) + f_B(\\eta_{t,B}) + f_C(-y+\\eta_{t,C})] = f_A E[y] + f_B E[\\eta_{t,B}] - f_C E[y] + f_C E[\\eta_{t,C}] = 0$。\n由于所有变量 $y, s, t$ 都是零均值的，协方差简化为乘积的期望，例如 $\\mathrm{Cov}(s,y) = E[sy]$。\n\n我们计算协方差矩阵所需的乘积的条件期望。\n对于机制 A ($s = y + \\eta_{s,A}$, $t = y + \\eta_{t,A}$)：\n$E[sy|A] = E[(y+\\eta_{s,A})y] = E[y^2] = 1$。\n$E[ty|A] = E[(y+\\eta_{t,A})y] = E[y^2] = 1$。\n$E[s^2|A] = E[(y+\\eta_{s,A})^2] = E[y^2] + E[\\eta_{s,A}^2] = 1 + \\sigma_{s,A}^2$。\n$E[t^2|A] = E[(y+\\eta_{t,A})^2] = E[y^2] + E[\\eta_{t,A}^2] = 1 + \\sigma_{t,A}^2$。\n$E[st|A] = E[(y+\\eta_{s,A})(y+\\eta_{t,A})] = E[y^2] = 1$。\n\n对于机制 B ($s = y + \\eta_{s,B}$, $t = \\eta_{t,B}$)：\n$E[sy|B] = E[(y+\\eta_{s,B})y] = E[y^2] = 1$。\n$E[ty|B] = E[\\eta_{t,B}y] = E[\\eta_{t,B}]E[y] = 0$。\n$E[s^2|B] = E[(y+\\eta_{s,B})^2] = 1 + \\sigma_{s,B}^2$。\n$E[t^2|B] = E[\\eta_{t,B}^2] = \\sigma_{t,B}^2$。\n$E[st|B] = E[(y+\\eta_{s,B})\\eta_{t,B}] = 0$。\n\n对于机制 C ($s = y + \\eta_{s,C}$, $t = -y + \\eta_{t,C}$)：\n$E[sy|C] = E[(y+\\eta_{s,C})y] = E[y^2] = 1$。\n$E[ty|C] = E[(-y+\\eta_{t,C})y] = -E[y^2] = -1$。\n$E[s^2|C] = E[(y+\\eta_{s,C})^2] = 1 + \\sigma_{s,C}^2$。\n$E[t^2|C] = E[(-y+\\eta_{t,C})^2] = E[y^2] + E[\\eta_{t,C}^2] = 1 + \\sigma_{t,C}^2$。\n$E[st|C] = E[(y+\\eta_{s,C})(-y+\\eta_{t,C})] = -E[y^2] = -1$。\n\n现在我们使用混合比例 $f_A, f_B, f_C$ 将这些结合起来。\n向量 $\\Sigma_{xy}$：\n$\\mathrm{Cov}(s,y) = E[sy] = f_A(1) + f_B(1) + f_C(1) = 1$。\n$\\mathrm{Cov}(t,y) = E[ty] = f_A(1) + f_B(0) + f_C(-1) = f_A - f_C$。\n所以，$\\Sigma_{xy} = \\begin{pmatrix} 1 \\\\ f_A - f_C \\end{pmatrix}$。\n\n矩阵 $\\Sigma_{xx}$：\n$\\mathrm{Var}(s) = E[s^2] = f_A(1+\\sigma_{s,A}^2) + f_B(1+\\sigma_{s,B}^2) + f_C(1+\\sigma_{s,C}^2)$。\n给定 $\\sigma_{s,A}^2 = \\sigma_{s,B}^2 = \\sigma_{s,C}^2 = \\sigma_s^2$，这等于 $(f_A+f_B+f_C)(1+\\sigma_s^2) = 1 + \\sigma_s^2$。\n$\\mathrm{Var}(t) = E[t^2] = f_A(1+\\sigma_{t,A}^2) + f_B\\sigma_{t,B}^2 + f_C(1+\\sigma_{t,C}^2)$。\n$\\mathrm{Cov}(s,t) = E[st] = f_A(1) + f_B(0) + f_C(-1) = f_A-f_C$。\n所以，$\\Sigma_{xx} = \\begin{pmatrix} 1+\\sigma_s^2  f_A-f_C \\\\ f_A-f_C  f_A(1+\\sigma_{t,A}^2) + f_B\\sigma_{t,B}^2 + f_C(1+\\sigma_{t,C}^2) \\end{pmatrix}$。\n\n第1部分：计算权重并证明纹理偏差。\n我们代入给定的数值：$f_A = 0.9$，$f_B = 0.05$，$f_C = 0.05$。\n$\\sigma_s^2 = 2.25$，$\\sigma_{t,A}^2 = 0.0025$，$\\sigma_{t,B}^2 = 1.0$，$\\sigma_{t,C}^2 = 0.0025$。\n\n$f_A - f_C = 0.9 - 0.05 = 0.85$。\n$\\Sigma_{xy} = \\begin{pmatrix} 1 \\\\ 0.85 \\end{pmatrix}$。\n\n$\\mathrm{Var}(s) = 1 + 2.25 = 3.25$。\n$\\mathrm{Var}(t) = 0.9(1+0.0025) + 0.05(1.0) + 0.05(1+0.0025) = 0.9(1.0025) + 0.05 + 0.05(1.0025) = 0.95(1.0025) + 0.05 = 0.952375 + 0.05 = 1.002375$。\n$\\mathrm{Cov}(s,t) = 0.85$。\n$\\Sigma_{xx} = \\begin{pmatrix} 3.25  0.85 \\\\ 0.85  1.002375 \\end{pmatrix}$。\n\n权重为 $w = \\Sigma_{xx}^{-1} \\Sigma_{xy}$。\n$\\Sigma_{xx}$ 的逆矩阵是 $\\frac{1}{\\det(\\Sigma_{xx})} \\begin{pmatrix} \\mathrm{Var}(t)  -\\mathrm{Cov}(s,t) \\\\ -\\mathrm{Cov}(s,t)  \\mathrm{Var}(s) \\end{pmatrix}$。\n$\\det(\\Sigma_{xx}) = \\mathrm{Var}(s)\\mathrm{Var}(t) - (\\mathrm{Cov}(s,t))^2 = (3.25)(1.002375) - (0.85)^2 = 3.25771875 - 0.7225 = 2.53521875$。\n$w = \\begin{pmatrix} w_s \\\\ w_t \\end{pmatrix} = \\frac{1}{2.53521875} \\begin{pmatrix} 1.002375  -0.85 \\\\ -0.85  3.25 \\end{pmatrix} \\begin{pmatrix} 1 \\\\ 0.85 \\end{pmatrix}$。\n\n$w_s = \\frac{1 \\times 1.002375 - 0.85 \\times 0.85}{2.53521875} = \\frac{1.002375 - 0.7225}{2.53521875} = \\frac{0.279875}{2.53521875}$。\n$w_t = \\frac{-0.85 \\times 1 + 3.25 \\times 0.85}{2.53521875} = \\frac{0.85(3.25 - 1)}{2.53521875} = \\frac{0.85 \\times 2.25}{2.53521875} = \\frac{1.9125}{2.53521875}$。\n\n为了证明纹理偏差（$|w_t| > |w_s|$），我们比较分子，因为分母为正且对两者是公共的。\n$w_s$ 的分子：$0.279875$。\n$w_t$ 的分子：$1.9125$。\n由于 $1.9125 > 0.279875$，且两者均为正，我们有 $|w_t| > |w_s|$。这证明了纹理偏差，意味着模型更依赖于纹理线索而非形状线索。\n\n第2部分：重要性重加权以消除纹理相关性。\n我们为每个机制引入非负的重要性权重 $\\alpha_A, \\alpha_B, \\alpha_C$。线性读出通过最小化加权期望平方误差 $E[\\alpha(y - w \\cdot x)^2]$ 来训练。大样本解满足加权正规方程 $w_\\alpha = (E[\\alpha x x^\\top])^{-1} E[\\alpha x y]$。\n问题要求消除纹理和标签之间的净相关性，我们将其解释为将交叉协方差项 $E[\\alpha x y]$ 的纹理-标签分量设置为零。该分量为 $E[\\alpha t y]$。\n$E[\\alpha t y] = \\sum_{R \\in \\{A,B,C\\}} f_R \\alpha_R E[ty|R]$。\n使用我们之前计算的条件期望：\n$E[\\alpha t y] = f_A \\alpha_A E[ty|A] + f_B \\alpha_B E[ty|B] + f_C \\alpha_C E[ty|C]$\n$E[\\alpha t y] = f_A \\alpha_A (1) + f_B \\alpha_B (0) + f_C \\alpha_C (-1) = f_A \\alpha_A - f_C \\alpha_C$。\n\n我们将其设为零以满足条件：\n$f_A \\alpha_A - f_C \\alpha_C = 0$。\n这得出 $\\alpha_C = \\frac{f_A \\alpha_A}{f_C}$。\n\n使用指定的约定 $\\alpha_A = 1$ 和 $\\alpha_B = 1$，以及数据集构成 $f_A = 0.9$ 和 $f_C = 0.05$，我们可以解出 $\\alpha_C$：\n$\\alpha_C = \\frac{0.9 \\times 1}{0.05} = \\frac{90}{5} = 18$。\n因子 $\\alpha_C = 18$ 是非负的，符合要求。这意味着相对于来自机制 A 和 B 的样本（其权重为 $1$），我们必须将来自线索冲突机制 C 的每个样本上调 18 倍的权重，以消除学习到的纹理与标签之间的关联偏差。",
            "answer": "$$\\boxed{18}$$"
        },
        {
            "introduction": "在计算神经科学中，将 DCNs 用作“计算实验（in-silico）”的对象是一种强大的研究范式。本练习将模拟神经科学中的经典技术——损伤研究（lesion studies）。我们将识别并“移除”被认为是关键的特征图（feature maps），以观察其对模型分类性能的影响 。通过这项实践，您将亲身体验一种用于探索和解释神经网络表征的核心方法，您将实现一个完整的流程，包括衡量特征显著性、执行靶向“损伤”以及量化由此产生的特定类别缺陷，从而将计算特征与模型行为联系起来。",
            "id": "3973984",
            "problem": "给定一个深度卷积网络 (DCN) 特征图的合成表示，该表示用于模拟大脑中的腹侧视觉流 (VVS)。考虑一个包含 $C=3$ 个类别的多分类场景。每个样本由一个特征向量表示，该向量对应于 DCN 单个层中 $D=30$ 个特征图（通道）的响应。目标是量化当移除一组被显著性度量识别为关键的特征图时，类别的线性可解码性如何变化，并将此变化与特定类别的功能缺陷相关联。\n\n从以下定义和原则开始：\n\n- 设有 $C$ 个类别，索引为 $c \\in \\{0,1,2\\}$。每个样本都有一个特征向量 $\\mathbf{x} \\in \\mathbb{R}^D$。\n- 线性解码器以一对多 (one-versus-rest) 的方式进行训练。对于类别 $c$，定义目标标签 $y_{i}^{(c)} \\in \\{+1,-1\\}$，如果样本 $i$ 属于类别 $c$，则 $y_{i}^{(c)} = +1$，否则 $y_{i}^{(c)} = -1$。\n- 为了包含一个截距（偏置项）而不对其进行惩罚，将特征向量增广为 $\\tilde{\\mathbf{x}} = [\\mathbf{x}^\\top, 1]^\\top \\in \\mathbb{R}^{D+1}$，并相应地定义一个对角惩罚矩阵 $\\mathbf{P} \\in \\mathbb{R}^{(D+1)\\times(D+1)}$，其中对于偏置项 $\\mathbf{P}_{00} = 0$，对于所有特征维度 $k \\in \\{1,\\dots,D\\}$，$\\mathbf{P}_{kk} = 1$。\n- 对于类别 $c$，通过求解以下问题来训练一个岭回归解码器\n$$\n\\mathbf{w}^{(c)} = \\arg\\min_{\\mathbf{w} \\in \\mathbb{R}^{D+1}} \\sum_{i} \\left( y_{i}^{(c)} - \\tilde{\\mathbf{x}}_{i}^\\top \\mathbf{w} \\right)^2 + \\lambda \\, \\mathbf{w}^\\top \\mathbf{P} \\mathbf{w},\n$$\n这会得到闭式解\n$$\n\\mathbf{w}^{(c)} = \\left( \\tilde{\\mathbf{X}}^\\top \\tilde{\\mathbf{X}} + \\lambda \\mathbf{P} \\right)^{-1} \\tilde{\\mathbf{X}}^\\top \\mathbf{y}^{(c)},\n$$\n其中 $\\tilde{\\mathbf{X}}$ 是增广训练特征的矩阵，$\\mathbf{y}^{(c)}$ 是类别 $c$ 的一对多标签向量。\n- 对于一个具有增广特征 $\\tilde{\\mathbf{x}}$ 的测试样本，类别 $c$ 的线性分数为 $s^{(c)}(\\tilde{\\mathbf{x}}) = \\tilde{\\mathbf{x}}^\\top \\mathbf{w}^{(c)}$。多分类预测通过赢者通吃规则执行，选择 $\\hat{c} = \\arg\\max_{c} s^{(c)}(\\tilde{\\mathbf{x}})$。\n- 类别 $c$ 的可解码性被度量为来自类别 $c$ 的测试样本中被多分类解码器正确预测的比例。将此准确率表示为 $A_c \\in [0,1]$。\n\n为了识别对类别 $c$ 关键的特征图，使用一种适用于线性解码器的基于梯度的显著性度量。$s^{(c)}(\\tilde{\\mathbf{x}})$ 相对于非偏置特征维度的梯度是权重向量 $\\mathbf{w}^{(c)}_{\\text{feat}} \\in \\mathbb{R}^D$（不包括偏置项）。将特征 $k$ 的特定类别显著性定义为\n$$\nS_c(k) = \\left| w^{(c)}_{\\text{feat},k} \\right| \\cdot \\mathbb{E}_{\\mathbf{x} \\sim \\text{test}, \\, y=c}\\left[ \\left| x_k \\right| \\right],\n$$\n这将绝对权重乘以该特征在类别 $c$ 内于留出测试数据上的平均绝对激活值。定义一个全局显著性为\n$$\nS_{\\text{global}}(k) = \\sum_{c=0}^{C-1} S_c(k).\n$$\n\n特征移除的定义是：通过选择 $S_c(k)$（对于指定的类别 $c$，即按类别选择）或 $S_{\\text{global}}(k)$（全局选择）中前 $K$ 个最显著的特征索引，构成一个大小为 $K$ 的集合 $\\mathcal{M} \\subset \\{1,\\dots,D\\}$，然后在训练和测试表示中将这些特征维度置零：\n$$\nx_k \\leftarrow 0 \\quad \\text{for all } k \\in \\mathcal{M}.\n$$\n\n对于给定的正则化参数 $\\lambda$ 和选择模式，计算：\n1. 基线可解码性 $A_c^{\\text{base}}$，通过在标准化的原始特征上训练解码器，并在标准化的测试特征上进行评估。\n2. 修改后的可解码性 $A_c^{\\text{mod}}$，通过在将选定特征维度置零后的标准化特征上训练解码器，并在经过相同置零操作的标准化测试特征上进行评估。\n3. 特定类别的功能缺陷\n$$\n\\Delta_c = A_c^{\\text{base}} - A_c^{\\text{mod}},\n$$\n表示为 $[ -1, 1 ]$ 内的一个小数。\n\n数据集生成协议（固定且可复现），用于 $C=3$ 个类别和 $D=30$ 个特征图：\n- 将特征索引划分为三个不相交的组 $G_0 = \\{1,\\dots,10\\}$、$G_1 = \\{11,\\dots,20\\}$ 和 $G_2 = \\{21,\\dots,30\\}$。\n- 对于每个类别 $c$，抽取训练样本：对于 $G_c$ 中的特征，从均值为 $\\mu_{\\text{high}} = 2.0$、标准差为 $\\sigma = 0.5$ 的高斯分布中采样；对于所有其他特征，从均值为 $0$、标准差为 $\\sigma = 0.5$ 的高斯分布中采样。对测试样本也执行相同操作。\n- 使用 $N_{\\text{train}} = 300$ 个训练样本（在各类别间平均分布）和 $N_{\\text{test}} = 180$ 个测试样本（平均分布），并使用一个固定的随机种子以保证可复现性。\n- 通过 z-score 标准化特征，使用仅在训练数据上计算的统计数据：对于每个特征 $k$，计算训练均值 $m_k$ 和标准差 $s_k$；然后通过 $x_k \\leftarrow (x_k - m_k) / s_k$ 转换所有输入，约定如果 $s_k = 0$，则设 $s_k = 1$。\n\n测试套件：\n- 每个测试用例是一个元组 $(K, \\lambda, \\text{mode}, c^\\star)$，描述如下：\n    - $K$：要移除的显著特征数量（一个整数）。\n    - $\\lambda$：岭正则化系数（一个正浮点数）。\n    - `mode`：为 \"per_class\" 或 \"global\"，指示显著性是为特定类别 $c^\\star$ 计算还是跨所有类别计算。\n    - $c^\\star$：用于按类别选择的类别索引（一个在 $\\{0,1,2\\}$ 中的整数）；如果 `mode` = \"global\"，则设置 $c^\\star = -1$ 并忽略它。\n- 使用以下测试用例：\n    1. $(5, 0.01, \\text{\"per_class\"}, 0)$: 正常路径，移除少量对类别 0 关键的特征。\n    2. $(0, 0.01, \\text{\"per_class\"}, 0)$: 边界条件，不移除任何特征。\n    3. $(10, 0.50, \\text{\"per_class\"}, 1)$: 边缘情况，在更强的正则化下移除一整个对类别 1 具有诊断性的特征块。\n    4. $(12, 0.01, \\text{\"global\"}, -1)$: 全局移除，移除跨类别显著的特征。\n\n您的程序应实现上述协议，为每个测试用例计算 $c \\in \\{0,1,2\\}$ 的功能缺陷 $\\Delta_c$，并生成一行输出，其中包含一个用方括号括起来的逗号分隔列表形式的结果。最终输出应为一个扁平化的功能缺陷列表，按测试用例排序，然后在每个测试用例内按类别索引排序，即 $[\\Delta^{(1)}_0, \\Delta^{(1)}_1, \\Delta^{(1)}_2, \\Delta^{(2)}_0, \\dots, \\Delta^{(4)}_2]$，其中上标表示上述列表中的测试用例索引。",
            "solution": "用户提供了一个在计算神经科学领域定义明确的问题。第一步是验证问题陈述。\n\n### 问题验证\n\n**第 1 步：提取已知条件**\n- **任务**：量化从一个 $D=30$ 维表示中移除 $K$ 个显著特征图后，$C=3$ 个类别的线性可解码性的变化。\n- **数据**：$N_{\\text{train}}=300$ 个训练样本，$N_{\\text{test}}=180$ 个测试样本，平均分布在 $C=3$ 个类别中。\n- **数据生成**：特征被划分为 $G_0=\\{1,\\dots,10\\}$、$G_1=\\{11,\\dots,20\\}$ 和 $G_2=\\{21,\\dots,29\\}$。对于类别 $c$ 的样本， $G_c$ 中的特征从 $\\mathcal{N}(\\mu=2.0, \\sigma=0.5)$ 中抽取，而其他特征从 $\\mathcal{N}(\\mu=0, \\sigma=0.5)$ 中抽取。使用固定的随机种子以确保可复现性。\n- **预处理**：使用训练数据的统计数据（均值和标准差）对特征进行标准化（z-score）。\n- **线性解码器**：为每个类别 $c$ 使用一个一对多（one-versus-rest）岭回归分类器。\n- **模型公式**：特征向量 $\\mathbf{x} \\in \\mathbb{R}^D$ 被增广以包含一个偏置项，$\\tilde{\\mathbf{x}} \\in \\mathbb{R}^{D+1}$。问题文本表明存在一个微小的表示不一致：$\\tilde{\\mathbf{x}} = [\\mathbf{x}^\\top, 1]^\\top$ 将偏置项放在最后，而惩罚矩阵 $\\mathbf{P}$ 的 $\\mathbf{P}_{00}=0$ 则暗示偏置项在最前。为了遵循 $\\mathbf{P}$ 的显式索引，一个更一致的表示是 $\\tilde{\\mathbf{x}} = [1, \\mathbf{x}^\\top]^\\top$。我们将采用此解释。\n- **训练**：每个类别 $c$ 的权重向量 $\\mathbf{w}^{(c)}$ 通过闭式解找到：$\\mathbf{w}^{(c)} = ( \\tilde{\\mathbf{X}}^\\top \\tilde{\\mathbf{X}} + \\lambda \\mathbf{P} )^{-1} \\tilde{\\mathbf{X}}^\\top \\mathbf{y}^{(c)}$。\n- **预测**：多分类通过对分数 $s^{(c)}(\\tilde{\\mathbf{x}}) = \\tilde{\\mathbf{x}}^\\top \\mathbf{w}^{(c)}$ 应用赢者通吃规则来完成。\n- **性能指标**：可解码性 $A_c$ 是对类别 $c$ 的测试样本的分类准确率。\n- **显著性**：特征 $k$ 的特定类别显著性为 $S_c(k) = | w^{(c)}_{\\text{feat},k} | \\cdot \\mathbb{E}_{\\mathbf{x} \\sim \\text{test}, y=c}[ |x_k| ]$。全局显著性为 $S_{\\text{global}}(k) = \\sum_{c} S_c(k)$。\n- **特征移除**：根据按类别或全局显著性识别出前 $K$ 个特征，并在标准化表示中将其对应的值设置为零。\n- **功能缺陷**：性能下降由 $\\Delta_c = A_c^{\\text{base}} - A_c^{\\text{mod}}$ 度量，其中 `base` 指的是在原始标准化特征上的性能，`mod` 指的是在特征移除后的性能。\n- **测试用例**：指定了四个用例，参数为 $(K, \\lambda, \\text{mode}, c^\\star)$。\n\n**第 2 步：使用提取的已知条件进行验证**\n- **科学依据**：该问题在计算神经科学和机器学习领域有很好的基础，使用了线性解码和岭回归等标准方法来探究神经网络表示。合成数据模型是进行科学研究的一种有效的、受控的方法。\n- **适定性**：岭回归目标函数是凸的，并且对于 $\\lambda > 0$，它有一个唯一的、稳定的解。需要求逆的矩阵 $(\\tilde{\\mathbf{X}}^\\top \\tilde{\\mathbf{X}} + \\lambda \\mathbf{P})$ 是正定的，因此是可逆的。\n- **客观性**：问题陈述使用了精确的数学和计算语言。\n- **完整性**：问题是自包含的。唯一缺失的信息是“固定随机种子”的值。为确保可复现性，必须假设一个标准值（例如，$42$）。这不会使问题的结构失效。\n- **一致性**：关于偏置项位置的微小符号不一致，通过采用 $\\tilde{\\mathbf{x}} = [1, \\mathbf{x}^\\top]^\\top$ 的约定得以解决，这与惩罚矩阵 $\\mathbf{P}$ 的显式索引保持一致。\n\n**第 3 步：结论与行动**\n该问题被判定为**有效**。它在科学上是合理的，适定的，客观的，并提供了一个清晰的计算过程。\n\n### 解决方案\n\n解决方案通过为每个测试用例实现指定的协议来推进。这涉及数据生成、标准化、训练基线和修改后的解码器，并最终计算由此产生的性能功能缺陷。为保证可复现性，使用随机种子 $42$。\n\n**第 1 步：数据生成与预处理**\n首先，我们生成原始的训练和测试数据集。对于 $C=3$ 个类别和 $D=30$ 个特征，我们有 $N_{\\text{train}}=300$ 和 $N_{\\text{test}}=180$ 个样本。特征索引被划分为三个组：$G_0$（索引 $0-9$）、$G_1$（索引 $10-19$）和 $G_2$（索引 $20-29$）。对于类别 $c$ 的每个样本，组 $G_c$ 中的特征从高斯分布 $\\mathcal{N}(\\mu=2.0, \\sigma=0.5)$ 中抽取，所有其他特征从 $\\mathcal{N}(\\mu=0, \\sigma=0.5)$ 中抽取。\n\n接下来，我们对数据进行标准化。我们从训练集 $\\mathbf{X}_{\\text{train}}$ 中为每个特征维度 $k$ 计算均值 $m_k$ 和标准差 $s_k$。如果 $s_k=0$，我们设置 $s_k=1$。然后我们使用 $x_k \\leftarrow (x_k - m_k)/s_k$ 来转换训练集和测试集。我们将这些表示为 $\\mathbf{X}_{\\text{train, std}}$ 和 $\\mathbf{X}_{\\text{test, std}}$。\n\n最后，我们通过在特征向量前添加一个常数 $1$ 来增广特征向量以包含偏置项。对于任何特征向量 $\\mathbf{x}_{\\text{std}}$，增广向量是 $\\tilde{\\mathbf{x}}_{\\text{std}} = [1, \\mathbf{x}_{\\text{std}}^\\top]^\\top \\in \\mathbb{R}^{31}$。这给我们提供了矩阵 $\\tilde{\\mathbf{X}}_{\\text{train, std}}$ 和 $\\tilde{\\mathbf{X}}_{\\text{test, std}}$。\n\n**第 2 步：基线性能评估 ($A_c^{\\text{base}}$)**\n对于四个测试用例中的每一个，我们首先计算基线性能。这包括为每个类别 $c \\in \\{0, 1, 2\\}$ 训练三个一对多解码器，使用测试用例中指定的正则化参数 $\\lambda$。每个解码器的权重向量使用闭式解计算：\n$$\n\\mathbf{w}^{(c)}_{\\text{base}} = \\left( \\tilde{\\mathbf{X}}_{\\text{train, std}}^\\top \\tilde{\\mathbf{X}}_{\\text{train, std}} + \\lambda \\mathbf{P} \\right)^{-1} \\tilde{\\mathbf{X}}_{\\text{train, std}}^\\top \\mathbf{y}^{(c)}_{\\text{train}}\n$$\n其中 $\\mathbf{y}^{(c)}_{\\text{train}}$ 是类别 $c$ 的一对多标签（$+1/-1$）向量，$\\mathbf{P}$ 是 $31 \\times 31$ 的对角惩罚矩阵，其中 $\\mathbf{P}_{00}=0$ 且对于 $k \\ge 1$ 有 $\\mathbf{P}_{kk}=1$。\n\n利用训练好的权重，我们预测每个测试样本的类别。对于一个测试样本 $\\tilde{\\mathbf{x}}_{\\text{test, std}, i}$，我们计算三个分数 $s^{(c)}_i = \\tilde{\\mathbf{x}}_{\\text{test, std}, i}^\\top \\mathbf{w}^{(c)}_{\\text{base}}$。预测的类别是 $\\hat{c}_i = \\arg\\max_{c} s^{(c)}_i$。类别 $c$ 的基线准确率 $A_c^{\\text{base}}$ 是真实标签为 $c$ 的测试样本被正确分类的比例。\n\n**第 3 步：显著性计算和特征选择**\n使用基线权重 $\\mathbf{w}^{(c)}_{\\text{base}}$，我们计算特征显著性。特定于特征的权重是 $\\mathbf{w}^{(c)}_{\\text{feat, base}}$，它们是 $\\mathbf{w}^{(c)}_{\\text{base}}$ 中从索引 $1$ 到 $30$ 的分量。对于每个特征 $k \\in \\{1, \\dots, 30\\}$ 和类别 $c$，显著性为：\n$$\nS_c(k) = \\left| w^{(c)}_{\\text{feat, base},k} \\right| \\cdot \\mathbb{E}_{\\mathbf{x} \\sim \\text{test, std}, \\, y=c}\\left[ \\left| x_k \\right| \\right]\n$$\n期望值被估计为属于类别 $c$ 的测试样本上绝对激活值的样本均值。\n\n根据测试用例的 `mode` 参数：\n- 如果 `mode` 是 `\"per_class\"`，我们识别出对于指定类别 $c^\\star$ 具有最高显著性分数 $S_{c^\\star}(k)$ 的 $K$ 个特征的集合 $\\mathcal{M}$。\n- 如果 `mode` 是 `\"global\"`，我们计算全局显著性 $S_{\\text{global}}(k) = \\sum_{c=0}^{2} S_c(k)$，并选择具有最高全局分数的 $K$ 个特征的集合 $\\mathcal{M}$。\n\n对于 $K=0$ 的特殊情况，集合 $\\mathcal{M}$ 为空。\n\n**第 4 步：修改后的性能评估 ($A_c^{\\text{mod}}$)**\n我们创建修改后的数据集 $\\tilde{\\mathbf{X}}_{\\text{train, mod}}$ 和 $\\tilde{\\mathbf{X}}_{\\text{test, mod}}$，方法是取标准化的增广数据集，并将与集合 $\\mathcal{M}$ 中特征索引相对应的列中的所有值设置为零。注意，偏置列（索引 $0$）永远不会被移除。\n\n然后，我们使用与第 2 步相同的过程，在修改后的训练数据 $\\tilde{\\mathbf{X}}_{\\text{train, mod}}$ 上训练一组新的解码器：\n$$\n\\mathbf{w}^{(c)}_{\\text{mod}} = \\left( \\tilde{\\mathbf{X}}_{\\text{train, mod}}^\\top \\tilde{\\mathbf{X}}_{\\text{train, mod}} + \\lambda \\mathbf{P} \\right)^{-1} \\tilde{\\mathbf{X}}_{\\text{train, mod}}^\\top \\mathbf{y}^{(c)}_{\\text{train}}\n$$\n这些新的解码器在修改后的测试数据 $\\tilde{\\mathbf{X}}_{\\text{test, mod}}$ 上进行评估，以计算修改后的准确率 $A_c^{\\text{mod}}$。\n\n**第 5 步：功能缺陷计算 ($\\Delta_c$)**\n最后，对于每个类别 $c$，功能缺陷计算为基线准确率和修改后准确率之间的差值：\n$$\n\\Delta_c = A_c^{\\text{base}} - A_c^{\\text{mod}}\n$$\n对所有四个提供的测试用例重复整个过程，并收集和格式化得到的十二个功能缺陷值。对于 $K=0$ 的情况，$A_c^{\\text{mod}} = A_c^{\\text{base}}$，因此对所有 $c$ 都有 $\\Delta_c = 0$。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to run the simulation and compute deficits.\n    \"\"\"\n    \n    # Define problem constants\n    C = 3  # Number of categories\n    D = 30  # Number of features\n    N_TRAIN_TOTAL = 300\n    N_TEST_TOTAL = 180\n    N_TRAIN_PER_CLASS = N_TRAIN_TOTAL // C\n    N_TEST_PER_CLASS = N_TEST_TOTAL // C\n    MU_HIGH = 2.0\n    SIGMA = 0.5\n    SEED = 42\n\n    def generate_data(rng):\n        \"\"\"Generates raw training and test data according to the protocol.\"\"\"\n        X_train_raw = np.zeros((N_TRAIN_TOTAL, D))\n        y_train = np.zeros(N_TRAIN_TOTAL, dtype=int)\n        X_test_raw = np.zeros((N_TEST_TOTAL, D))\n        y_test = np.zeros(N_TEST_TOTAL, dtype=int)\n        \n        feature_groups = [range(0, 10), range(10, 20), range(20, 30)]\n\n        # Generate training data\n        for c in range(C):\n            start_idx = c * N_TRAIN_PER_CLASS\n            end_idx = (c + 1) * N_TRAIN_PER_CLASS\n            y_train[start_idx:end_idx] = c\n            \n            # Draw from N(0, 0.5) for all features\n            X_train_raw[start_idx:end_idx, :] = rng.normal(loc=0.0, scale=SIGMA, size=(N_TRAIN_PER_CLASS, D))\n            # For diagnostic features, redraw from N(2.0, 0.5)\n            diagnostic_features = feature_groups[c]\n            X_train_raw[start_idx:end_idx, diagnostic_features] = rng.normal(loc=MU_HIGH, scale=SIGMA, size=(N_TRAIN_PER_CLASS, len(diagnostic_features)))\n\n        # Generate test data\n        for c in range(C):\n            start_idx = c * N_TEST_PER_CLASS\n            end_idx = (c + 1) * N_TEST_PER_CLASS\n            y_test[start_idx:end_idx] = c\n            \n            X_test_raw[start_idx:end_idx, :] = rng.normal(loc=0.0, scale=SIGMA, size=(N_TEST_PER_CLASS, D))\n            diagnostic_features = feature_groups[c]\n            X_test_raw[start_idx:end_idx, diagnostic_features] = rng.normal(loc=MU_HIGH, scale=SIGMA, size=(N_TEST_PER_CLASS, len(diagnostic_features)))\n            \n        return X_train_raw, y_train, X_test_raw, y_test\n\n    def run_single_case(case_params, data):\n        \"\"\"\n        Runs the full analysis for a single test case.\n        \"\"\"\n        K, lam, mode, c_star = case_params\n        X_train_raw, y_train, X_test_raw, y_test = data\n\n        # 1. Standardize data\n        train_mean = np.mean(X_train_raw, axis=0)\n        train_std = np.std(X_train_raw, axis=0)\n        train_std[train_std == 0] = 1.0  # Convention for zero std dev\n\n        X_train_std = (X_train_raw - train_mean) / train_std\n        X_test_std = (X_test_raw - train_mean) / train_std\n\n        # Augment features with bias term\n        X_train_aug = np.hstack([np.ones((N_TRAIN_TOTAL, 1)), X_train_std])\n        X_test_aug = np.hstack([np.ones((N_TEST_TOTAL, 1)), X_test_std])\n        \n        # Penalty matrix P\n        P = np.diag([0.] + [1.] * D)\n\n        def train_and_eval(X_train, X_test):\n            weights = np.zeros((D + 1, C))\n            for c in range(C):\n                y_ovr = np.where(y_train == c, 1, -1)\n                term1 = X_train.T @ X_train + lam * P\n                term2 = X_train.T @ y_ovr\n                weights[:, c] = np.linalg.solve(term1, term2)\n            \n            scores = X_test @ weights\n            predictions = np.argmax(scores, axis=1)\n            \n            accuracies = []\n            for c in range(C):\n                class_mask = (y_test == c)\n                correct_predictions = np.sum(predictions[class_mask] == y_test[class_mask])\n                accuracies.append(correct_predictions / np.sum(class_mask))\n            return np.array(accuracies), weights\n\n        # 2. Baseline performance\n        A_base, W_base = train_and_eval(X_train_aug, X_test_aug)\n\n        if K == 0:\n            return [0.0, 0.0, 0.0]\n\n        # 3. Saliency calculation\n        W_feat_base = W_base[1:, :] # Exclude bias weight\n        saliencies = np.zeros((D, C))\n        for c in range(C):\n            class_mask = (y_test == c)\n            # E[|x_k|] for class c\n            mean_abs_activation = np.mean(np.abs(X_test_std[class_mask, :]), axis=0)\n            saliencies[:, c] = np.abs(W_feat_base[:, c]) * mean_abs_activation\n        \n        if mode == 'per_class':\n            target_saliency = saliencies[:, c_star]\n        else: # 'global'\n            target_saliency = np.sum(saliencies, axis=1)\n\n        # Identify features to remove (indices are 0-based for features 0..D-1)\n        features_to_remove_indices = np.argsort(target_saliency)[-K:]\n\n        # 4. Modified performance\n        X_train_mod = X_train_aug.copy()\n        X_test_mod = X_test_aug.copy()\n        \n        # Zero out feature columns (+1 offset for bias column)\n        X_train_mod[:, features_to_remove_indices + 1] = 0.0\n        X_test_mod[:, features_to_remove_indices + 1] = 0.0\n        \n        A_mod, _ = train_and_eval(X_train_mod, X_test_mod)\n        \n        # 5. Deficit calculation\n        deficits = A_base - A_mod\n        return deficits.tolist()\n\n    # Define test cases\n    test_cases = [\n        (5, 0.01, \"per_class\", 0),\n        (0, 0.01, \"per_class\", 0),\n        (10, 0.50, \"per_class\", 1),\n        (12, 0.01, \"global\", -1),\n    ]\n\n    # Initialize RNG and generate data once\n    rng = np.random.default_rng(SEED)\n    data = generate_data(rng)\n\n    # Run all test cases and collect results\n    all_deficits = []\n    for case in test_cases:\n        deficits = run_single_case(case, data)\n        all_deficits.extend(deficits)\n\n    # Format and print the final output\n    formatted_results = [f\"{d:.8f}\" for d in all_deficits]\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n\n```"
        }
    ]
}