{
    "hands_on_practices": [
        {
            "introduction": "Building a multi-scale model of the brain starts with understanding its fundamental computational unit: the synapse. This exercise explores how the discrete, all-or-none events of presynaptic spikes are translated into continuous postsynaptic currents. By applying principles of linear systems theory, you will derive the total synaptic response to a train of incoming spikes, providing a foundational tool for modeling temporal integration in single neurons .",
            "id": "4000876",
            "problem": "A single-compartment neuron is voltage clamped at a constant membrane potential $V_{\\text{hold}}$. It receives a set of presynaptic spikes at times $\\{t_k\\}_{k=1}^{N}$ impinging on an excitatory conductance-based synapse with reversal potential $E_{\\text{syn}}$. At the microscopic level, an isolated presynaptic spike at time $t=0$ evokes a causal alpha-function conductance transient\n$$\ng_{\\alpha}(t) \\;=\\; g_0 \\,\\frac{t}{\\tau}\\,\\exp\\!\\big(1 - \\frac{t}{\\tau}\\big)\\,H(t),\n$$\nwhere $g_0$ is a peak conductance, $\\tau$ is a synaptic time constant, and $H(t)$ is the Heaviside step function. Assume linearity and time-invariance of the synaptic input-output relationship and negligible interaction between conductances beyond linear superposition. Represent the presynaptic spike train as a sum of Dirac delta impulses and use the definition of convolution to derive from first principles the effective synaptic filter produced by the entire spike train and, under the voltage clamp, the resulting postsynaptic current $I(t)$.\n\nIn particular:\n- Start from a representation of the spike train $s(t)$ in terms of Dirac delta distributions and the convolution integral for a linear time-invariant system.\n- Derive a closed-form expression for the total synaptic conductance $g(t)$ evoked by the spike train $\\{t_k\\}$.\n- Using Ohm’s law for synaptic current under voltage clamp, $I(t) = g(t)\\,(V_{\\text{hold}} - E_{\\text{syn}})$, compute a single closed-form analytic expression for $I(t)$ in terms of $t$, $\\{t_k\\}$, $g_0$, and $\\tau$ that enforces causality.\n\nProvide your final answer as a single closed-form analytic expression for $I(t)$ (no units inside the final expression). Do not round.",
            "solution": "The problem statement has been validated and is deemed scientifically grounded, well-posed, objective, and internally consistent. It represents a standard exercise in computational neuroscience. We may therefore proceed with the derivation.\n\nThe objective is to derive the postsynaptic current $I(t)$ in a voltage-clamped neuron that receives a train of presynaptic spikes. The derivation will proceed from first principles, utilizing the concepts of linear time-invariant (LTI) systems and convolution.\n\nFirst, we represent the presynaptic spike train, arriving at discrete times $\\{t_k\\}_{k=1}^{N}$, as a signal $s(t)$. As stipulated, we model this train as a sum of Dirac delta impulses:\n$$\ns(t) = \\sum_{k=1}^{N} \\delta(t - t_k)\n$$\nwhere $\\delta(t)$ is the Dirac delta function. Each term $\\delta(t - t_k)$ represents a single spike occurring precisely at time $t_k$.\n\nSecond, we identify the system's impulse response. The problem states that a single presynaptic spike at time $t=0$, which is represented by $\\delta(t)$, evokes a causal alpha-function conductance transient $g_{\\alpha}(t)$. Therefore, $g_{\\alpha}(t)$ is, by definition, the impulse response function (or kernel) of the synapse.\n$$\ng_{\\alpha}(t) = g_0 \\frac{t}{\\tau} \\exp\\left(1 - \\frac{t}{\\tau}\\right) H(t)\n$$\nHere, $g_0$ is the peak conductance, $\\tau$ is the time constant, and $H(t)$ is the Heaviside step function, which ensures causality (i.e., the response is zero for $t  0$).\n\nThird, we compute the total synaptic conductance $g(t)$ resulting from the entire spike train $s(t)$. The problem states we should assume linearity and time-invariance. For a linear time-invariant (LTI) system, the output signal is the convolution of the input signal with the system's impulse response. Thus, the total conductance $g(t)$ is given by the convolution of $s(t)$ and $g_{\\alpha}(t)$:\n$$\ng(t) = (s * g_{\\alpha})(t) = \\int_{-\\infty}^{\\infty} s(t') g_{\\alpha}(t - t') dt'\n$$\nSubstituting the expression for the spike train $s(t')$:\n$$\ng(t) = \\int_{-\\infty}^{\\infty} \\left( \\sum_{k=1}^{N} \\delta(t' - t_k) \\right) g_{\\alpha}(t - t') dt'\n$$\nSince the summation is over a finite number of terms $N$, we can interchange the order of summation and integration:\n$$\ng(t) = \\sum_{k=1}^{N} \\int_{-\\infty}^{\\infty} \\delta(t' - t_k) g_{\\alpha}(t - t') dt'\n$$\nWe now apply the sifting property of the Dirac delta function, which states that $\\int_{-\\infty}^{\\infty} \\delta(x - a) f(x) dx = f(a)$. In our case, the variable of integration is $t'$, the delta function is centered at $t_k$, and the function being sifted is $g_{\\alpha}(t - t')$. Evaluating the integral for each term in the sum gives:\n$$\ng(t) = \\sum_{k=1}^{N} g_{\\alpha}(t - t_k)\n$$\nThis result embodies the principle of linear superposition: the total conductance is the sum of the individual conductance transients generated by each spike. Now, we substitute the functional form of $g_{\\alpha}$ with its argument replaced by $(t-t_k)$:\n$$\ng(t) = \\sum_{k=1}^{N} g_0 \\frac{t - t_k}{\\tau} \\exp\\left(1 - \\frac{t - t_k}{\\tau}\\right) H(t - t_k)\n$$\nThe Heaviside function $H(t - t_k)$ correctly enforces causality for each spike-evoked transient, ensuring it only contributes to the total conductance for times $t \\ge t_k$.\n\nFinally, we compute the postsynaptic current $I(t)$ under voltage clamp. The problem provides the relevant form of Ohm's law:\n$$\nI(t) = g(t) (V_{\\text{hold}} - E_{\\text{syn}})\n$$\nThe term $(V_{\\text{hold}} - E_{\\text{syn}})$ is the driving force, which is constant because the membrane potential is clamped at $V_{\\text{hold}}$ and the synaptic reversal potential $E_{\\text{syn}}$ is a fixed parameter. Substituting our derived expression for the total conductance $g(t)$ yields the final expression for the postsynaptic current:\n$$\nI(t) = \\left( \\sum_{k=1}^{N} g_0 \\frac{t - t_k}{\\tau} \\exp\\left(1 - \\frac{t - t_k}{\\tau}\\right) H(t - t_k) \\right) (V_{\\text{hold}} - E_{\\text{syn}})\n$$\nThis can be written more compactly by factoring out the constant terms:\n$$\nI(t) = g_0 (V_{\\text{hold}} - E_{\\text{syn}}) \\sum_{k=1}^{N} \\frac{t - t_k}{\\tau} \\exp\\left(1 - \\frac{t - t_k}{\\tau}\\right) H(t - t_k)\n$$\nThis is the single closed-form analytic expression for the total postsynaptic current $I(t)$ that was requested.",
            "answer": "$$\\boxed{g_0 (V_{\\text{hold}} - E_{\\text{syn}}) \\sum_{k=1}^{N} \\frac{t - t_k}{\\tau} \\exp\\left(1 - \\frac{t - t_k}{\\tau}\\right) H(t - t_k)}$$"
        },
        {
            "introduction": "While synapses form the building blocks, the brain's complex functions emerge from the collective dynamics of large neural populations. This practice moves up in scale to a classic Wilson-Cowan model, which describes the coupled activity of excitatory and inhibitory ensembles . Through nonlinear dynamical systems analysis, you will investigate how network connectivity and external drive can give rise to emergent, brain-like states such as stable activity patterns, oscillations, and bistability.",
            "id": "4000907",
            "problem": "Consider a mesoscopic excitatory–inhibitory population model of cortical tissue given by the Wilson–Cowan system of ordinary differential equations (ODEs), obtained by coarse-graining spiking neuron dynamics into population activity fractions. Let $E(t)$ and $I(t)$ denote the fractions of active excitatory and inhibitory neurons, respectively, taking values in $[0,1]$. The dynamics are\n$$\n\\frac{dE}{dt} \\;=\\; -E \\;+\\; S_E\\!\\left(w_{EE} E \\;-\\; w_{EI} I \\;+\\; P_E\\right),\n\\qquad\n\\frac{dI}{dt} \\;=\\; -I \\;+\\; S_I\\!\\left(w_{IE} E \\;-\\; w_{II} I \\;+\\; P_I\\right),\n$$\nwhere $w_{EE}, w_{EI}, w_{IE}, w_{II}  0$ are effective coupling strengths between populations, $P_E$ and $P_I$ are constant external drives, and $S_E(\\cdot)$ and $S_I(\\cdot)$ are sigmoidal activation functions modeling the population response to net input. Assume the sigmoids are logistic functions\n$$\nS_E(x) \\;=\\; \\frac{1}{1 + \\exp\\!\\big(-a_E(x - \\theta_E)\\big)},\n\\qquad\nS_I(x) \\;=\\; \\frac{1}{1 + \\exp\\!\\big(-a_I(x - \\theta_I)\\big)},\n$$\nwith slopes $a_E0$, $a_I0$ and thresholds $\\theta_E$, $\\theta_I$. The time scale has been nondimensionalized so that coefficients in front of $E$ and $I$ are unity.\n\nTasks:\n- Starting from the definitions of fixed points and linearization for nonlinear ODEs, derive the fixed point conditions for $(E^{*}, I^{*})$ and the Jacobian matrix $J(E^{*}, I^{*})$ governing linear stability. Express the linear stability criteria in terms of the trace and determinant of $J$.\n- Using the general Hopf bifurcation conditions for a two-dimensional smooth dynamical system, express the condition for a Hopf bifurcation in terms of $(E^{*}, I^{*})$, the parameters $(w_{EE}, w_{EI}, w_{IE}, w_{II})$, and the slopes $a_E$ and $a_I$ evaluated at the fixed point via $S_E'(x)$ and $S_I'(x)$.\n- Explain, in terms of nullcline geometry and gain slope, how parameter regimes with sufficiently strong recurrent excitation and appropriately tuned inhibition can produce bistability (two distinct stable fixed points separated by an unstable one).\n- Now specialize to the parameter set\n$$\na_E \\;=\\; 1,\\quad a_I \\;=\\; 1,\\quad \\theta_E \\;=\\; 3,\\quad \\theta_I \\;=\\; 3,\\\\\nw_{EE} \\;=\\; 14,\\quad w_{EI} \\;=\\; 12,\\quad w_{IE} \\;=\\; 13,\\quad w_{II} \\;=\\; 6,\\\\\nP_I \\;=\\; -0.5,\n$$\nand consider $P_E$ as the bifurcation parameter. Determine the critical value $P_E^{H}$ at which a Hopf bifurcation occurs. Your derivation must proceed from the fixed point equations and the Jacobian-based conditions. Express $P_E^{H}$ as a single real number. Round your final numeric answer to four significant figures. No physical units are required since all quantities are nondimensional.",
            "solution": "The problem asks for an analysis of the Wilson-Cowan model, a system of two coupled ordinary differential equations (ODEs) describing the activity of excitatory ($E$) and inhibitory ($I$) neural populations.\n\nThe system is given by:\n$$\n\\frac{dE}{dt} = -E + S_E(w_{EE} E - w_{EI} I + P_E)\n$$\n$$\n\\frac{dI}{dt} = -I + S_I(w_{IE} E - w_{II} I + P_I)\n$$\nwhere $E, I \\in [0, 1]$. The activation functions $S_E$ and $S_I$ are sigmoidal logistic functions.\n\nFirst, the problem statement is validated.\n**Step 1: Extract Givens**\n- ODEs for $E(t)$ and $I(t)$:\n  $\\frac{dE}{dt} = -E + S_E(w_{EE} E - w_{EI} I + P_E)$\n  $\\frac{dI}{dt} = -I + S_I(w_{IE} E - w_{II} I + P_I)$\n- Activation functions:\n  $S_E(x) = \\frac{1}{1 + \\exp(-a_E(x - \\theta_E))}$\n  $S_I(x) = \\frac{1}{1 + \\exp(-a_I(x - \\theta_I))}$\n- Parameter constraints: $w_{EE}, w_{EI}, w_{IE}, w_{II}  0$; $a_E  0$, $a_I  0$.\n- Specific parameter values for the final task:\n  $a_E = 1$, $a_I = 1$, $\\theta_E = 3$, $\\theta_I = 3$\n  $w_{EE} = 14$, $w_{EI} = 12$, $w_{IE} = 13$, $w_{II} = 6$\n  $P_I = -0.5$\n- Bifurcation parameter: $P_E$.\n\n**Step 2: Validate Using Extracted Givens**\n- **Scientifically Grounded**: The Wilson-Cowan model is a foundational and widely studied model in theoretical and computational neuroscience for describing cortical population dynamics. The problem is scientifically sound.\n- **Well-Posed**: The problem asks for standard dynamical systems analysis: finding fixed points, linearization, stability criteria, bifurcation conditions, and calculating a specific bifurcation point for a given set of parameters. The tasks are clearly defined and lead to a unique answer.\n- **Objective**: The problem is stated in precise mathematical and scientific language, free of subjective claims.\n- The problem is self-contained and consistent, with no apparent flaws. It does not violate any of the invalidity criteria.\n\n**Step 3: Verdict and Action**\nThe problem is valid. A full solution will be provided.\n\n**Task 1: Fixed Points and Linear Stability**\n\nA fixed point, denoted by $(E^*, I^*)$, is a state of the system where the dynamics cease, i.e., $\\frac{dE}{dt} = 0$ and $\\frac{dI}{dt} = 0$. Setting the time derivatives to zero yields the fixed point conditions:\n$$\nE^* = S_E(w_{EE} E^* - w_{EI} I^* + P_E)\n$$\n$$\nI^* = S_I(w_{IE} E^* - w_{II} I^* + P_I)\n$$\nThese are a pair of coupled transcendental equations. The solutions $(E^*, I^*)$ correspond to the intersections of the system's nullclines.\n\nTo analyze the linear stability of a fixed point, we linearize the system around $(E^*, I^*)$. Let the right-hand sides of the ODEs be $F_E(E, I)$ and $F_I(E, I)$. The dynamics of small perturbations $(\\delta E, \\delta I)$ around the fixed point are governed by the Jacobian matrix $J$ evaluated at $(E^*, I^*)$:\n$$\nJ(E^*, I^*) = \\begin{pmatrix} \\frac{\\partial F_E}{\\partial E}  \\frac{\\partial F_E}{\\partial I} \\\\ \\frac{\\partial F_I}{\\partial E}  \\frac{\\partial F_I}{\\partial I} \\end{pmatrix}_{(E^*, I^*)}\n$$\nThe partial derivatives are:\n$\\frac{\\partial F_E}{\\partial E} = -1 + w_{EE} S_E'(x_E)$, where $x_E = w_{EE} E - w_{EI} I + P_E$.\n$\\frac{\\partial F_E}{\\partial I} = -w_{EI} S_E'(x_E)$.\n$\\frac{\\partial F_I}{\\partial E} = w_{IE} S_I'(x_I)$, where $x_I = w_{IE} E - w_{II} I + P_I$.\n$\\frac{\\partial F_I}{\\partial I} = -1 - w_{II} S_I'(x_I)$.\n\nLet $S_{E,*}' = S_E'(w_{EE} E^* - w_{EI} I^* + P_E)$ and $S_{I,*}' = S_I'(w_{IE} E^* - w_{II} I^* + P_I)$. The Jacobian at the fixed point is:\n$$\nJ = \\begin{pmatrix} -1 + w_{EE} S_{E,*}'  -w_{EI} S_{E,*}' \\\\ w_{IE} S_{I,*}'  -1 - w_{II} S_{I,*}' \\end{pmatrix}\n$$\nThe stability of the fixed point is determined by the eigenvalues of $J$. For a two-dimensional system, a fixed point is stable if and only if both eigenvalues have negative real parts. According to the Routh-Hurwitz stability criterion, this is equivalent to two conditions on the trace ($\\text{Tr}(J)$) and determinant ($\\text{Det}(J)$) of the Jacobian:\n$1.$ $\\text{Tr}(J) = \\lambda_1 + \\lambda_2  0$\n$2.$ $\\text{Det}(J) = \\lambda_1 \\lambda_2  0$\n\nThe trace and determinant for this system are:\n$$\n\\text{Tr}(J) = (-1 + w_{EE} S_{E,*}') + (-1 - w_{II} S_{I,*}') = w_{EE} S_{E,*}' - w_{II} S_{I,*}' - 2\n$$\n$$\n\\text{Det}(J) = (-1 + w_{EE} S_{E,*}')(-1 - w_{II} S_{I,*}') - (-w_{EI} S_{E,*}')(w_{IE} S_{I,*}') = 1 - (w_{EE} S_{E,*}' - w_{II} S_{I,*}') + (w_{EI} w_{IE} - w_{EE} w_{II}) S_{E,*}' S_{I,*}'\n$$\n\n**Task 2: Hopf Bifurcation Condition**\n\nA Hopf bifurcation occurs when a fixed point loses stability as a pair of complex conjugate eigenvalues crosses the imaginary axis. For a two-dimensional system, this happens when:\n$1.$ $\\text{Tr}(J) = 0$\n$2.$ $\\text{Det}(J)  0$\n\nThe condition $\\text{Tr}(J) = 0$ gives:\n$$\nw_{EE} S_{E,*}' - w_{II} S_{I,*}' - 2 = 0 \\quad \\implies \\quad w_{EE} S_{E,*}' - w_{II} S_{I,*}' = 2\n$$\nThe derivative of the logistic function $S(x) = (1 + \\exp(-a(x-\\theta)))^{-1}$ is $S'(x) = a S(x) (1 - S(x))$. At a fixed point, $S_E(\\dots) = E^*$ and $S_I(\\dots) = I^*$, so we can write $S_{E,*}' = a_E E^*(1-E^*)$ and $S_{I,*}' = a_I I^*(1-I^*)$.\nSubstituting these into the trace condition, the Hopf bifurcation condition becomes an algebraic relation between the fixed-point coordinates $(E^*, I^*)$:\n$$\nw_{EE} a_E E^*(1-E^*) - w_{II} a_I I^*(1-I^*) = 2\n$$\n\n**Task 3: Explanation of Bistability**\n\nBistability refers to the co-existence of two stable fixed points for the same set of parameters. In the Wilson-Cowan model, this arises from the interplay of recurrent excitation and inhibition, which shapes the geometry of the system's nullclines.\nThe nullclines are the curves where $\\frac{dE}{dt}=0$ (E-nullcline) and $\\frac{dI}{dt}=0$ (I-nullcline). Fixed points are their intersections.\nThe E-nullcline is defined by $E = S_E(w_{EE} E - w_{EI} I + P_E)$. Due to the recurrent excitatory coupling $w_{EE}E$, this nullcline can have a non-monotonic, 'N'-shape when plotted as $I$ versus $E$. This shape emerges when the self-excitation is sufficiently strong, specifically when the \"gain\" of the recurrent loop, $w_{EE} S_E'$, exceeds $1$ for some value of $E$. High $w_{EE}$ and a steep sigmoid slope $a_E$ promote this condition.\nThe I-nullcline is given by $I = S_I(w_{IE} E - w_{II} I + P_I)$. Due to self-inhibition ($-w_{II}I$), this nullcline is typically a monotonic, increasing function of $E$.\nBistability occurs when the monotonic I-nullcline intersects the N-shaped E-nullcline at three points. The stability of these fixed points alternates along the E-nullcline. The two intersections on the outer, positive-slope branches of the 'N' are stable, while the middle intersection on the negative-slope branch is unstable (a saddle point). Thus, \"appropriately tuned inhibition\" means that the position and slope of the I-nullcline are such that it cuts through all three branches of the E-nullcline's 'N' shape.\n\n**Task 4: Calculation of the Hopf Bifurcation Point $P_E^H$**\n\nWe must find the value of the bifurcation parameter $P_E$, denoted $P_E^H$, for which the system undergoes a Hopf bifurcation. This requires simultaneously solving the two fixed-point equations and the Hopf condition $\\text{Tr}(J)=0$.\nThe given parameters are:\n$a_E = 1, a_I = 1, \\theta_E = 3, \\theta_I = 3$\n$w_{EE} = 14, w_{EI} = 12, w_{IE} = 13, w_{II} = 6$\n$P_I = -0.5$\n\nThe system of equations for the bifurcation point $(E^*, I^*, P_E^H)$ is:\n$1.$ (E-nullcline) $E^* = \\frac{1}{1 + \\exp(-(14E^* - 12I^* + P_E^H - 3))}$\n$2.$ (I-nullcline) $I^* = \\frac{1}{1 + \\exp(-(13E^* - 6I^* - 0.5 - 3))} = \\frac{1}{1 + \\exp(-(13E^* - 6I^* - 3.5))}$\n$3.$ (Hopf Condition) $14 \\cdot 1 \\cdot E^*(1-E^*) - 6 \\cdot 1 \\cdot I^*(1-I^*) = 2$\n\nLet's work with the latter two equations first to find the fixed point $(E^*, I^*)$ at the bifurcation.\nThe Hopf condition simplifies to:\n$7E^*(1-E^*) - 3I^*(1-I^*) = 1$\n$7E^* - 7(E^*)^2 - 3I^* + 3(I^*)^2 = 1$\n\nThe I-nullcline equation can be rewritten by inverting the sigmoid:\n$\\ln\\left(\\frac{1}{I^*} - 1\\right) = -(13E^* - 6I^* - 3.5)$\n$\\ln\\left(\\frac{1-I^*}{I^*}\\right) = -13E^* + 6I^* + 3.5$\n\nDue to the symmetry of the parameters ($\\theta_E=\\theta_I, a_E=a_I$) and the structure of the equations, let's test the special point $(E^*, I^*) = (0.5, 0.5)$ as a potential solution.\nCheck the Hopf condition:\n$7(0.5)(1-0.5) - 3(0.5)(1-0.5) = 7(0.25) - 3(0.25) = 1.75 - 0.75 = 1$. The condition is satisfied.\nCheck the I-nullcline equation:\nLHS: $\\ln\\left(\\frac{1-0.5}{0.5}\\right) = \\ln(1) = 0$.\nRHS: $-13(0.5) + 6(0.5) + 3.5 = -6.5 + 3.0 + 3.5 = 0$. The equation is satisfied.\nThus, the fixed point at the Hopf bifurcation is indeed $(E^*, I^*) = (0.5, 0.5)$.\n\nWe must also verify that $\\text{Det}(J)  0$. At the bifurcation point, $\\text{Tr}(J)=0$, so $w_{EE}S'_{E,*} - w_{II}S'_{I,*} = 2$.\n$\\text{Det}(J) = 1 - (w_{EE} S_{E,*}' - w_{II} S_{I,*}') + (w_{EI} w_{IE} - w_{EE} w_{II}) S_{E,*}' S_{I,*}'$\n$\\text{Det}(J) = 1 - 2 + (w_{EI} w_{IE} - w_{EE} w_{II}) S_{E,*}' S_{I,*}' = -1 + (w_{EI} w_{IE} - w_{EE} w_{II}) S_{E,*}' S_{I,*}'$\nWith the given parameters: $w_{EI} w_{IE} - w_{EE} w_{II} = (12)(13) - (14)(6) = 156 - 84 = 72$.\nAt the fixed point $(0.5, 0.5)$:\n$S_{E,*}' = a_E E^*(1-E^*) = 1 \\cdot 0.5 \\cdot 0.5 = 0.25$.\n$S_{I,*}' = a_I I^*(1-I^*) = 1 \\cdot 0.5 \\cdot 0.5 = 0.25$.\n$\\text{Det}(J) = -1 + 72(0.25)(0.25) = -1 + 72(0.0625) = -1 + 4.5 = 3.5$.\nSince $\\text{Det}(J) = 3.5  0$, the condition for a Hopf bifurcation is fully met.\n\nFinally, we find the value of $P_E^H$ from the E-nullcline equation using the fixed point $(E^*,I^*) = (0.5, 0.5)$. We invert the sigmoid for the E-population:\n$\\ln\\left(\\frac{1-E^*}{E^*}\\right) = -a_E(w_{EE}E^* - w_{EI}I^* + P_E^H - \\theta_E)$\nWe solve for $P_E^H$:\n$P_E^H = \\theta_E - w_{EE}E^* + w_{EI}I^* - \\frac{1}{a_E}\\ln\\left(\\frac{1-E^*}{E^*}\\right)$\nSubstituting values:\n$P_E^H = 3 - 14(0.5) + 12(0.5) - \\frac{1}{1}\\ln\\left(\\frac{1-0.5}{0.5}\\right)$\n$P_E^H = 3 - 7 + 6 - \\ln(1)$\n$P_E^H = 3 - 7 + 6 - 0 = 2$.\nThe critical value is exactly 2. To four significant figures, this is 2.000.",
            "answer": "$$\n\\boxed{2.000}\n$$"
        },
        {
            "introduction": "To bridge from mesoscopic populations to brain-wide dynamics, we must employ statistical descriptions. A common simplification is to assume neurons act independently, yet real neural activity is highly correlated. This exercise delves into the statistical mechanics of a large neural network to precisely quantify the impact of these pairwise correlations on a key macroscopic observable: the variance of the total population activity . By solving the underlying Lyapunov equation, you will derive the exact error introduced by neglecting correlations, providing critical insight into the validity of mean-field approximations in brain modeling.",
            "id": "4000929",
            "problem": "Consider a homogeneous, fully connected network of $N$ identical neuronal units, modeled at the mesoscopic scale by a linearized rate dynamics around a stable fixed point. Let $\\mathbf{r}(t) \\in \\mathbb{R}^{N}$ denote the deviation of firing rates from the fixed point, governed by the linear stochastic differential equation\n$$\n\\frac{d\\mathbf{r}}{dt} = -\\left(I - W\\right)\\mathbf{r}(t) + \\boldsymbol{\\xi}(t),\n$$\nwhere $I$ is the $N \\times N$ identity matrix, the effective coupling matrix is $W = \\frac{g}{N}\\mathbf{1}\\mathbf{1}^{\\top}$ with scalar gain $g \\in \\mathbb{R}$, and $\\mathbf{1}$ is the $N$-dimensional vector of ones. Assume stability, that is, $g  1$. The input fluctuations $\\boldsymbol{\\xi}(t)$ are zero-mean Gaussian white noise with covariance\n$$\n\\mathbb{E}\\left[\\boldsymbol{\\xi}(t)\\boldsymbol{\\xi}(t')^{\\top}\\right] = q\\, I\\, \\delta(t-t'),\n$$\nfor some $q  0$, where $\\delta(\\cdot)$ denotes the Dirac delta function. This defines an Ornstein–Uhlenbeck (OU) process with stationary covariance matrix $\\Sigma \\in \\mathbb{R}^{N \\times N}$.\n\nIt is known (and you may use without proof) that for a stable linear OU process of the above form, the stationary covariance matrix $\\Sigma$ solves the continuous-time Lyapunov equation\n$$\n\\left(I - W\\right)\\Sigma + \\Sigma \\left(I - W\\right)^{\\top} = q\\, I.\n$$\n\nDefine the population activity as the scalar process $A(t) = \\mathbf{1}^{\\top} \\mathbf{r}(t)$. The true steady-state variance of $A(t)$ is $\\mathrm{Var}_{\\mathrm{true}}(A) = \\mathbf{1}^{\\top}\\Sigma\\,\\mathbf{1}$. An approximation that neglects all pairwise correlations between different units replaces $\\Sigma$ by its diagonal part, yielding the prediction $\\mathrm{Var}_{\\mathrm{ind}}(A) = \\sum_{i=1}^{N} \\Sigma_{ii}$. The error introduced by neglecting pairwise correlations is defined as\n$$\nE \\equiv \\mathrm{Var}_{\\mathrm{true}}(A) - \\mathrm{Var}_{\\mathrm{ind}}(A) = \\sum_{i \\neq j} \\Sigma_{ij}.\n$$\n\nUsing only the assumptions and facts stated above, derive a closed-form analytical expression for $E$ in terms of $N$, $g$, and $q$. Express your final answer as a single simplified expression. No numerical evaluation is required and no rounding is needed. The answer is dimensionless up to the scale set by $q$; report it as a pure symbolic expression in terms of $N$, $g$, and $q$.",
            "solution": "The problem asks for the derivation of a closed-form expression for the error term $E$, which quantifies the contribution of pairwise correlations to the variance of the population activity. The error is defined as $E \\equiv \\mathrm{Var}_{\\mathrm{true}}(A) - \\mathrm{Var}_{\\mathrm{ind}}(A)$, where $A(t) = \\mathbf{1}^{\\top} \\mathbf{r}(t)$.\n\nThe true variance of the population activity is given by\n$$ \\mathrm{Var}_{\\mathrm{true}}(A) = \\mathrm{Var}(\\mathbf{1}^{\\top}\\mathbf{r}) = \\mathbf{1}^{\\top}\\mathbb{E}[\\mathbf{r}\\mathbf{r}^{\\top}]\\mathbf{1} = \\mathbf{1}^{\\top}\\Sigma\\,\\mathbf{1} $$\nThis can be written as the sum of all elements of the covariance matrix $\\Sigma$:\n$$ \\mathbf{1}^{\\top}\\Sigma\\,\\mathbf{1} = \\sum_{i=1}^{N}\\sum_{j=1}^{N} \\Sigma_{ij} $$\nThe approximation that neglects pairwise correlations is given by\n$$ \\mathrm{Var}_{\\mathrm{ind}}(A) = \\sum_{i=1}^{N} \\Sigma_{ii} = \\mathrm{Tr}(\\Sigma) $$\nwhere $\\mathrm{Tr}(\\cdot)$ denotes the matrix trace.\nThe error term $E$ is therefore the sum of all off-diagonal elements of the covariance matrix $\\Sigma$:\n$$ E = \\mathbf{1}^{\\top}\\Sigma\\,\\mathbf{1} - \\mathrm{Tr}(\\Sigma) = \\sum_{i \\neq j} \\Sigma_{ij} $$\nOur goal is to find an expression for $E$ using the given continuous-time Lyapunov equation for the stationary covariance matrix $\\Sigma$:\n$$ \\left(I - W\\right)\\Sigma + \\Sigma \\left(I - W\\right)^{\\top} = q\\, I $$\nThe coupling matrix is $W = \\frac{g}{N}\\mathbf{1}\\mathbf{1}^{\\top}$. Since $W$ is symmetric, its transpose $W^{\\top}$ is equal to $W$. Let us define the matrix $M \\equiv I - W$. The matrix $M$ is also symmetric, $M=M^{\\top}$. The Lyapunov equation simplifies to:\n$$ M\\Sigma + \\Sigma M = q\\, I $$\n\nWe will now derive expressions for $\\mathbf{1}^{\\top}\\Sigma\\,\\mathbf{1}$ and $\\mathrm{Tr}(\\Sigma)$ separately.\n\nFirst, to find $\\mathbf{1}^{\\top}\\Sigma\\,\\mathbf{1}$, we can pre-multiply the Lyapunov equation by $\\mathbf{1}^{\\top}$ and post-multiply it by $\\mathbf{1}$:\n$$ \\mathbf{1}^{\\top} \\left( M\\Sigma + \\Sigma M \\right) \\mathbf{1} = \\mathbf{1}^{\\top} (qI) \\mathbf{1} $$\n$$ \\mathbf{1}^{\\top}M\\Sigma\\mathbf{1} + \\mathbf{1}^{\\top}\\Sigma M\\mathbf{1} = q (\\mathbf{1}^{\\top}\\mathbf{1}) = qN $$\nWe need to evaluate the action of $M$ on the vector $\\mathbf{1}$.\n$$ M\\mathbf{1} = (I - W)\\mathbf{1} = \\left(I - \\frac{g}{N}\\mathbf{1}\\mathbf{1}^{\\top}\\right)\\mathbf{1} = I\\mathbf{1} - \\frac{g}{N}\\mathbf{1}(\\mathbf{1}^{\\top}\\mathbf{1}) $$\nSince $\\mathbf{1}^{\\top}\\mathbf{1} = \\sum_{i=1}^{N} 1 = N$, we have:\n$$ M\\mathbf{1} = \\mathbf{1} - \\frac{g}{N}\\mathbf{1}(N) = \\mathbf{1} - g\\mathbf{1} = (1-g)\\mathbf{1} $$\nSince $M$ is symmetric, we also have $\\mathbf{1}^{\\top}M = (M\\mathbf{1})^{\\top} = ((1-g)\\mathbf{1})^{\\top} = (1-g)\\mathbf{1}^{\\top}$.\nSubstituting these into the equation for $qN$:\n$$ (1-g)\\mathbf{1}^{\\top}\\Sigma\\mathbf{1} + \\mathbf{1}^{\\top}\\Sigma (1-g)\\mathbf{1} = qN $$\n$$ (1-g)\\left(\\mathbf{1}^{\\top}\\Sigma\\mathbf{1}\\right) + (1-g)\\left(\\mathbf{1}^{\\top}\\Sigma\\mathbf{1}\\right) = qN $$\n$$ 2(1-g)\\left(\\mathbf{1}^{\\top}\\Sigma\\mathbf{1}\\right) = qN $$\nThe stability condition $g  1$ ensures that $1-g \\neq 0$. We can thus solve for $\\mathbf{1}^{\\top}\\Sigma\\mathbf{1}$:\n$$ \\mathrm{Var}_{\\mathrm{true}}(A) = \\mathbf{1}^{\\top}\\Sigma\\mathbf{1} = \\frac{qN}{2(1-g)} $$\n\nNext, to find $\\mathrm{Tr}(\\Sigma)$, we take the trace of the Lyapunov equation:\n$$ \\mathrm{Tr}(M\\Sigma + \\Sigma M) = \\mathrm{Tr}(qI) $$\nUsing the linearity of the trace operator, $\\mathrm{Tr}(A+B) = \\mathrm{Tr}(A)+\\mathrm{Tr}(B)$, and the cyclic property, $\\mathrm{Tr}(AB)=\\mathrm{Tr}(BA)$, we get:\n$$ \\mathrm{Tr}(M\\Sigma) + \\mathrm{Tr}(\\Sigma M) = q\\mathrm{Tr}(I) $$\n$$ 2\\mathrm{Tr}(M\\Sigma) = qN $$\nNow we expand $M\\Sigma$:\n$$ \\mathrm{Tr}(M\\Sigma) = \\mathrm{Tr}((I-W)\\Sigma) = \\mathrm{Tr}(I\\Sigma - W\\Sigma) = \\mathrm{Tr}(\\Sigma) - \\mathrm{Tr}(W\\Sigma) $$\nSubstituting this back gives:\n$$ 2(\\mathrm{Tr}(\\Sigma) - \\mathrm{Tr}(W\\Sigma)) = qN $$\nWe need to evaluate $\\mathrm{Tr}(W\\Sigma)$.\n$$ \\mathrm{Tr}(W\\Sigma) = \\mathrm{Tr}\\left(\\left(\\frac{g}{N}\\mathbf{1}\\mathbf{1}^{\\top}\\right)\\Sigma\\right) = \\frac{g}{N}\\mathrm{Tr}(\\mathbf{1}\\mathbf{1}^{\\top}\\Sigma) $$\nUsing the cyclic property again:\n$$ \\mathrm{Tr}(\\mathbf{1}\\mathbf{1}^{\\top}\\Sigma) = \\mathrm{Tr}(\\mathbf{1}^{\\top}\\Sigma\\mathbf{1}) $$\nThe term $\\mathbf{1}^{\\top}\\Sigma\\mathbf{1}$ is a $1 \\times 1$ matrix (a scalar), and the trace of a scalar is the scalar itself. So, $\\mathrm{Tr}(\\mathbf{1}^{\\top}\\Sigma\\mathbf{1}) = \\mathbf{1}^{\\top}\\Sigma\\mathbf{1}$.\nWe have already found that $\\mathbf{1}^{\\top}\\Sigma\\mathbf{1} = \\frac{qN}{2(1-g)}$. Therefore:\n$$ \\mathrm{Tr}(W\\Sigma) = \\frac{g}{N} \\left(\\frac{qN}{2(1-g)}\\right) = \\frac{qg}{2(1-g)} $$\nNow we substitute this expression for $\\mathrm{Tr}(W\\Sigma)$ into the traced Lyapunov equation:\n$$ 2\\left(\\mathrm{Tr}(\\Sigma) - \\frac{qg}{2(1-g)}\\right) = qN $$\n$$ \\mathrm{Tr}(\\Sigma) - \\frac{qg}{2(1-g)} = \\frac{qN}{2} $$\nSolving for $\\mathrm{Tr}(\\Sigma)$:\n$$ \\mathrm{Var}_{\\mathrm{ind}}(A) = \\mathrm{Tr}(\\Sigma) = \\frac{qN}{2} + \\frac{qg}{2(1-g)} $$\n\nFinally, we compute the error term $E$:\n$$ E = \\mathrm{Var}_{\\mathrm{true}}(A) - \\mathrm{Var}_{\\mathrm{ind}}(A) $$\n$$ E = \\frac{qN}{2(1-g)} - \\left(\\frac{qN}{2} + \\frac{qg}{2(1-g)}\\right) $$\n$$ E = \\frac{qN}{2(1-g)} - \\frac{qN(1-g)}{2(1-g)} - \\frac{qg}{2(1-g)} $$\n$$ E = \\frac{qN - qN(1-g) - qg}{2(1-g)} $$\n$$ E = \\frac{qN - qN + qNg - qg}{2(1-g)} $$\n$$ E = \\frac{qNg - qg}{2(1-g)} $$\nFactoring out the common terms in the numerator provides the final simplified expression:\n$$ E = \\frac{qg(N-1)}{2(1-g)} $$\nThis expression gives the total contribution of all pairwise correlations to the population activity variance in terms of the network size $N$, the coupling gain $g$, and the input noise variance $q$.",
            "answer": "$$\\boxed{\\frac{qg(N-1)}{2(1-g)}}$$"
        }
    ]
}