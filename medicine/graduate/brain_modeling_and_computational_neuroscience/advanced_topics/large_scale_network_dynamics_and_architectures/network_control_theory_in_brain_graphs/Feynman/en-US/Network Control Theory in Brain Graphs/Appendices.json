{
    "hands_on_practices": [
        {
            "introduction": "Moving from abstract theory to practical application begins with the foundational definitions. This first exercise provides a concrete, hands-on calculation of controllability using the Kalman rank condition for a hypothetical three-node brain network . By constructing the system matrix $A$ from a given connectivity structure and leak term, and then computing the rank of the controllability matrix $\\mathcal{C}$, you will directly test whether a system is controllable from a single input node, solidifying your understanding of this fundamental principle.",
            "id": "4001595",
            "problem": "Consider a linearized neural mass model for a small brain network of three cortical regions, represented as a continuous-time Linear Time-Invariant (LTI) system with state equation $\\dot{\\mathbf{x}}(t) = \\mathbf{A}\\mathbf{x}(t) + \\mathbf{B}u(t)$, where $\\mathbf{x}(t) \\in \\mathbb{R}^{3}$ is the vector of regional activities, $u(t) \\in \\mathbb{R}$ is a scalar control input, and $\\mathbf{A} \\in \\mathbb{R}^{3 \\times 3}$ is the system matrix obtained by combining passive leak and anatomical connectivity. The anatomical connectivity matrix $\\mathbf{W}$ is given by\n$$\n\\mathbf{W} = \\begin{pmatrix}\n0 & 0.9 & 0.1 \\\\\n0.4 & 0 & 0.7 \\\\\n0 & 0.5 & 0\n\\end{pmatrix},\n$$\nand the passive leak is modeled as $-\\gamma\\mathbf{I}$ with $\\gamma = 0.8$ so that $\\mathbf{A} = \\mathbf{W} - \\gamma\\mathbf{I}$. The control input is injected into the second node only, so choose\n$$\n\\mathbf{B} = \\begin{pmatrix} 0 \\\\ 1 \\\\ 0 \\end{pmatrix}.\n$$\nUsing the foundational definition of reachability in the Kalman framework, construct the controllability matrix implied by this setup and compute its rank. Based on the rank, interpret whether injecting control at the second node alone renders the three-dimensional system controllable. Express the final answer as the rank of the controllability matrix as a single integer. No rounding is required, and no units are needed in the final answer.",
            "solution": "The problem is first subjected to a rigorous validation process.\n\n### Step 1: Extract Givens\n-   System model: Continuous-time Linear Time-Invariant (LTI) system.\n-   State equation: $\\dot{\\mathbf{x}}(t) = \\mathbf{A}\\,\\mathbf{x}(t) + \\mathbf{B}\\,u(t)$.\n-   State vector: $\\mathbf{x}(t) \\in \\mathbb{R}^{3}$.\n-   Control input: $u(t) \\in \\mathbb{R}$.\n-   System matrix definition: $\\mathbf{A} = \\mathbf{W} - \\gamma\\,\\mathbf{I}$, where $\\mathbf{I}$ is the identity matrix.\n-   Anatomical connectivity matrix: $\\mathbf{W} = \\begin{pmatrix} 0 & 0.9 & 0.1 \\\\ 0.4 & 0 & 0.7 \\\\ 0 & 0.5 & 0 \\end{pmatrix}$.\n-   Passive leak parameter: $\\gamma = 0.8$.\n-   Control input matrix: $\\mathbf{B} = \\begin{pmatrix} 0 \\\\ 1 \\\\ 0 \\end{pmatrix}$.\n-   Task: Construct the controllability matrix and compute its rank to assess system controllability.\n\n### Step 2: Validate Using Extracted Givens\nThe problem is evaluated against the validation criteria.\n-   **Scientifically Grounded**: The problem is well-grounded in network control theory and its application to computational neuroscience. The use of a linearized neural mass model, an LTI system representation, a connectivity matrix $\\mathbf{W}$, and a leak term $-\\gamma\\,\\mathbf{I}$ are all standard and well-established components in modeling brain dynamics. The problem is scientifically sound.\n-   **Well-Posed**: The problem is clearly defined. It requires the construction of the controllability matrix and the calculation of its rank, which are standard procedures in control theory. All necessary data ($\\mathbf{W}$, $\\gamma$, $\\mathbf{B}$) and definitions are provided to uniquely determine the system matrix $\\mathbf{A}$ and subsequently the controllability matrix $\\mathcal{C}$. A unique, meaningful solution (the rank) exists.\n-   **Objective**: The problem is stated using precise mathematical language and objective definitions, free from ambiguity or subjective claims.\n-   **Completeness and Consistency**: The problem is self-contained. The dimensions of the matrices and vectors are consistent: $\\mathbf{A} \\in \\mathbb{R}^{3 \\times 3}$, $\\mathbf{x} \\in \\mathbb{R}^{3}$, $\\mathbf{B} \\in \\mathbb{R}^{3 \\times 1}$, and $u(t)$ is a scalar. There are no contradictions.\n\n### Step 3: Verdict and Action\nThe problem is deemed **valid** as it is scientifically grounded, well-posed, objective, and internally consistent. The solution process may proceed.\n\nThe core of the problem is to assess the controllability of the given LTI system. For a system of dimension $n$, controllability is determined by the rank of the controllability matrix, $\\mathcal{C}$. The system is controllable if and only if $\\text{rank}(\\mathcal{C}) = n$.\n\nFirst, we construct the system matrix $\\mathbf{A}$ using the provided definition $\\mathbf{A} = \\mathbf{W} - \\gamma\\,\\mathbf{I}$.\nGiven $\\gamma = 0.8$, the matrix $\\gamma\\,\\mathbf{I}$ is:\n$$\n\\gamma\\,\\mathbf{I} = 0.8 \\begin{pmatrix} 1 & 0 & 0 \\\\ 0 & 1 & 0 \\\\ 0 & 0 & 1 \\end{pmatrix} = \\begin{pmatrix} 0.8 & 0 & 0 \\\\ 0 & 0.8 & 0 \\\\ 0 & 0 & 0.8 \\end{pmatrix}\n$$\nNow, we can compute $\\mathbf{A}$:\n$$\n\\mathbf{A} = \\mathbf{W} - \\gamma\\,\\mathbf{I} = \\begin{pmatrix} 0 & 0.9 & 0.1 \\\\ 0.4 & 0 & 0.7 \\\\ 0 & 0.5 & 0 \\end{pmatrix} - \\begin{pmatrix} 0.8 & 0 & 0 \\\\ 0 & 0.8 & 0 \\\\ 0 & 0 & 0.8 \\end{pmatrix} = \\begin{pmatrix} -0.8 & 0.9 & 0.1 \\\\ 0.4 & -0.8 & 0.7 \\\\ 0 & 0.5 & -0.8 \\end{pmatrix}\n$$\nThe state space dimension is $n=3$. The controllability matrix, also known as the Kalman matrix, is defined as:\n$$\n\\mathcal{C} = \\begin{pmatrix} \\mathbf{B} & \\mathbf{A}\\mathbf{B} & \\mathbf{A}^2\\mathbf{B} & \\dots & \\mathbf{A}^{n-1}\\mathbf{B} \\end{pmatrix}\n$$\nFor $n=3$, this becomes:\n$$\n\\mathcal{C} = \\begin{pmatrix} \\mathbf{B} & \\mathbf{A}\\mathbf{B} & \\mathbf{A}^2\\mathbf{B} \\end{pmatrix}\n$$\nWe compute the columns of $\\mathcal{C}$ sequentially.\nThe first column is the control matrix $\\mathbf{B}$:\n$$\n\\mathbf{B} = \\begin{pmatrix} 0 \\\\ 1 \\\\ 0 \\end{pmatrix}\n$$\nThe second column is $\\mathbf{A}\\mathbf{B}$:\n$$\n\\mathbf{A}\\mathbf{B} = \\begin{pmatrix} -0.8 & 0.9 & 0.1 \\\\ 0.4 & -0.8 & 0.7 \\\\ 0 & 0.5 & -0.8 \\end{pmatrix} \\begin{pmatrix} 0 \\\\ 1 \\\\ 0 \\end{pmatrix} = \\begin{pmatrix} (-0.8)(0) + (0.9)(1) + (0.1)(0) \\\\ (0.4)(0) + (-0.8)(1) + (0.7)(0) \\\\ (0)(0) + (0.5)(1) + (-0.8)(0) \\end{pmatrix} = \\begin{pmatrix} 0.9 \\\\ -0.8 \\\\ 0.5 \\end{pmatrix}\n$$\nThe third column is $\\mathbf{A}^2\\mathbf{B}$, which can be computed as $\\mathbf{A}(\\mathbf{A}\\mathbf{B})$:\n$$\n\\mathbf{A}^2\\mathbf{B} = \\mathbf{A}(\\mathbf{A}\\mathbf{B}) = \\begin{pmatrix} -0.8 & 0.9 & 0.1 \\\\ 0.4 & -0.8 & 0.7 \\\\ 0 & 0.5 & -0.8 \\end{pmatrix} \\begin{pmatrix} 0.9 \\\\ -0.8 \\\\ 0.5 \\end{pmatrix}\n$$\n$$\n\\mathbf{A}^2\\mathbf{B} = \\begin{pmatrix} (-0.8)(0.9) + (0.9)(-0.8) + (0.1)(0.5) \\\\ (0.4)(0.9) + (-0.8)(-0.8) + (0.7)(0.5) \\\\ (0)(0.9) + (0.5)(-0.8) + (-0.8)(0.5) \\end{pmatrix} = \\begin{pmatrix} -0.72 - 0.72 + 0.05 \\\\ 0.36 + 0.64 + 0.35 \\\\ 0 - 0.4 - 0.4 \\end{pmatrix} = \\begin{pmatrix} -1.39 \\\\ 1.35 \\\\ -0.8 \\end{pmatrix}\n$$\nNow, we assemble the controllability matrix $\\mathcal{C}$:\n$$\n\\mathcal{C} = \\begin{pmatrix} 0 & 0.9 & -1.39 \\\\ 1 & -0.8 & 1.35 \\\\ 0 & 0.5 & -0.8 \\end{pmatrix}\n$$\nTo find the rank of $\\mathcal{C}$, we can compute its determinant. A non-zero determinant implies that the columns are linearly independent, and the matrix has full rank. For a $3 \\times 3$ matrix, full rank is rank $3$. We use cofactor expansion along the first column for simplicity:\n$$\n\\det(\\mathcal{C}) = (0) \\cdot C_{11} - (1) \\cdot \\det\\begin{pmatrix} 0.9 & -1.39 \\\\ 0.5 & -0.8 \\end{pmatrix} + (0) \\cdot C_{31}\n$$\nwhere $C_{ij}$ are the cofactors.\n$$\n\\det(\\mathcal{C}) = -1 \\left[ (0.9)(-0.8) - (-1.39)(0.5) \\right]\n$$\n$$\n\\det(\\mathcal{C}) = -1 \\left[ -0.72 - (-0.695) \\right]\n$$\n$$\n\\det(\\mathcal{C}) = -1 \\left[ -0.72 + 0.695 \\right]\n$$\n$$\n\\det(\\mathcal{C}) = -1 \\left[ -0.025 \\right] = 0.025\n$$\nSince $\\det(\\mathcal{C}) = 0.025 \\neq 0$, the matrix $\\mathcal{C}$ is invertible and has full rank. The rank of the controllability matrix is $3$.\n\nThe condition for controllability is that the rank of the controllability matrix must equal the dimension of the state space. Here, $\\text{rank}(\\mathcal{C}) = 3$ and $n=3$. Since $\\text{rank}(\\mathcal{C}) = n$, the system is controllable. This means that injecting control input solely at the second node is sufficient to steer the activity of all three nodes to any desired state in finite time. The problem asks for the rank of the controllability matrix.",
            "answer": "$$\n\\boxed{3}\n$$"
        },
        {
            "introduction": "While the Kalman rank condition provides a binary answer—controllable or not—we often need a more nuanced, quantitative measure of control. This practice introduces the concept of average controllability, a metric derived from the trace of the controllability Gramian, which quantifies how effectively a given node can influence the network's state . By solving the discrete-time Lyapunov equation for different input nodes, you will not only learn to compute this important metric but also uncover a key insight: the relationship between a node's topological centrality and its capacity to exert control over the network.",
            "id": "4001597",
            "problem": "Consider a discrete-time Linear Time-Invariant (LTI) brain network model with three regions, where the state evolves as $x_{t+1} = A x_t + B u_t$. The symmetric weighted structural connectivity between regions is encoded by the matrix\n$$\n\\tilde{A} = \\begin{pmatrix}\n0 & 1 & 0 \\\\\n1 & 0 & 1 \\\\\n0 & 1 & 0\n\\end{pmatrix},\n$$\nand the dynamical coupling is normalized to ensure stability by setting $A = \\alpha \\tilde{A}$ with $\\alpha = \\frac{1}{2}$. Assume single-node inputs, i.e., for node $i$ use $B = e_i$, where $e_i$ is the $i$-th standard basis vector in $\\mathbb{R}^3$. Using the foundational definitions of controllability for discrete-time LTI systems, compute the average controllability for each node and rank the nodes from highest to lowest average controllability. If two nodes are tied, break ties by increasing node index. Present your final answer as a single row matrix whose first three entries are the average controllability values for nodes $1$, $2$, and $3$ in that order, and whose last three entries are the node indices in descending rank order. No rounding is required. Interpret the ranking in terms of hubness (degree-based centrality) in the given brain network.",
            "solution": "The problem requires the computation of average controllability for each node in a three-node linear time-invariant (LTI) brain network model and a subsequent ranking and interpretation.\n\nThe system is described by the discrete-time LTI equation $x_{t+1} = A x_t + B u_t$, where $x_t \\in \\mathbb{R}^3$ is the state of the three brain regions at time $t$. The system matrix $A$ is derived from the structural connectivity $\\tilde{A}$ and a scaling factor $\\alpha$.\n\nFirst, we define the system matrix $A$:\n$$\n\\tilde{A} = \\begin{pmatrix} 0 & 1 & 0 \\\\ 1 & 0 & 1 \\\\ 0 & 1 & 0 \\end{pmatrix}, \\quad \\alpha = \\frac{1}{2}\n$$\n$$\nA = \\alpha \\tilde{A} = \\frac{1}{2} \\begin{pmatrix} 0 & 1 & 0 \\\\ 1 & 0 & 1 \\\\ 0 & 1 & 0 \\end{pmatrix} = \\begin{pmatrix} 0 & 1/2 & 0 \\\\ 1/2 & 0 & 1/2 \\\\ 0 & 1/2 & 0 \\end{pmatrix}\n$$\nThe eigenvalues of $A$ can be found by solving $\\det(A - \\lambda I) = 0$, which gives $-\\lambda(\\lambda^2 - 1/2) = 0$. The eigenvalues are $\\lambda_1 = 0$, $\\lambda_2 = 1/\\sqrt{2}$, and $\\lambda_3 = -1/\\sqrt{2}$. Since the spectral radius $\\rho(A) = \\max_i |\\lambda_i| = 1/\\sqrt{2} < 1$, the system is stable.\n\nThe controllability of a discrete-time LTI system is characterized by the controllability Gramian, $W_c$. For a stable system, it is given by the convergent series $W_c = \\sum_{k=0}^{\\infty} A^k B B^T (A^T)^k$. A more practical method for computing $W_c$ is to solve the discrete-time Lyapunov equation:\n$$\nA W_c A^T - W_c = -B B^T \\quad \\text{or equivalently} \\quad W_c - A W_c A^T = B B^T\n$$\nAverage controllability is defined as the trace of the controllability Gramian, $\\text{Trace}(W_c)$. A larger value of $\\text{Trace}(W_c)$ indicates that the system states are, on average, more easily reachable from the specified input node(s).\n\nWe will compute the average controllability for single-node control at each of the three nodes, where the input matrix $B$ is given by $B_i = e_i$, the $i$-th standard basis vector.\n\nLet $W_c$ be a symmetric matrix $W_c = \\begin{pmatrix} w_{11} & w_{12} & w_{13} \\\\ w_{12} & w_{22} & w_{23} \\\\ w_{13} & w_{23} & w_{33} \\end{pmatrix}$. The term $A W_c A^T$ is calculated as:\n$$\nA W_c A^T = \\begin{pmatrix}\n\\frac{1}{4} w_{22} & \\frac{1}{4} (w_{12} + w_{23}) & \\frac{1}{4} w_{22} \\\\\n\\frac{1}{4} (w_{12} + w_{23}) & \\frac{1}{4} (w_{11} + 2w_{13} + w_{33}) & \\frac{1}{4} (w_{12} + w_{23}) \\\\\n\\frac{1}{4} w_{22} & \\frac{1}{4} (w_{12} + w_{23}) & \\frac{1}{4} w_{22}\n\\end{pmatrix}\n$$\n\n**Case 1: Control at Node 1**\nHere, $B = B_1 = e_1 = (1, 0, 0)^T$, so $B_1 B_1^T = \\text{diag}(1, 0, 0)$. Let $W_{c,1}$ be the Gramian. The Lyapunov equation $W_{c,1} - A W_{c,1} A^T = B_1 B_1^T$ gives the following system of equations for the elements $w_{ij}$:\n1. $(1,1): w_{11} - \\frac{1}{4} w_{22} = 1$\n2. $(2,2): w_{22} - \\frac{1}{4} (w_{11} + 2w_{13} + w_{33}) = 0$\n3. $(3,3): w_{33} - \\frac{1}{4} w_{22} = 0 \\implies w_{33} = \\frac{1}{4} w_{22}$\n4. $(1,3): w_{13} - \\frac{1}{4} w_{22} = 0 \\implies w_{13} = \\frac{1}{4} w_{22}$\n5. $(1,2): w_{12} - \\frac{1}{4} (w_{12} + w_{23}) = 0 \\implies 3w_{12} = w_{23}$\n6. $(2,3): w_{23} - \\frac{1}{4} (w_{12} + w_{23}) = 0$. This is the same as the previous equation for the (1,2) entry, which upon exploring the off-diagonal elements of $B B^T$ (which are zero) is expected.\nLet us solve for the diagonal elements.\nSubstitute $w_{33}$ and $w_{13}$ into eq. 2: $w_{22} - \\frac{1}{4} (w_{11} + 2(\\frac{1}{4}w_{22}) + \\frac{1}{4}w_{22}) = 0 \\implies w_{22} - \\frac{1}{4} w_{11} - \\frac{1}{8} w_{22} - \\frac{1}{16} w_{22} = 0 \\implies \\frac{13}{16} w_{22} = \\frac{1}{4} w_{11} \\implies w_{11} = \\frac{13}{4} w_{22}$.\nSubstitute this into eq. 1: $\\frac{13}{4} w_{22} - \\frac{1}{4} w_{22} = 1 \\implies \\frac{12}{4} w_{22} = 1 \\implies 3 w_{22} = 1 \\implies w_{22} = 1/3$.\nThen $w_{11} = 1 + \\frac{1}{4}(\\frac{1}{3}) = 1 + \\frac{1}{12} = \\frac{13}{12}$.\nAnd $w_{33} = \\frac{1}{4} w_{22} = \\frac{1}{4}(\\frac{1}{3}) = \\frac{1}{12}$.\nThe average controllability for node $1$ is $\\text{avg_c}_1 = \\text{Trace}(W_{c,1}) = w_{11} + w_{22} + w_{33} = \\frac{13}{12} + \\frac{1}{3} + \\frac{1}{12} = \\frac{13+4+1}{12} = \\frac{18}{12} = \\frac{3}{2}$.\n\n**Case 3: Control at Node 3**\nThe network graph is symmetric with respect to swapping nodes $1$ and $3$. Therefore, controlling node $3$ is symmetric to controlling node $1$. The Gramian $W_{c,3}$ will have its diagonal elements $w_{11,3}$ and $w_{33,3}$ swapped relative to $W_{c,1}$, while $w_{22,3}$ remains the same.\n$w_{11,3} = w_{33,1} = 1/12$.\n$w_{33,3} = w_{11,1} = 13/12$.\n$w_{22,3} = w_{22,1} = 1/3$.\nAverage controllability for node $3$ is $\\text{avg_c}_3 = \\text{Trace}(W_{c,3}) = \\frac{1}{12} + \\frac{1}{3} + \\frac{13}{12} = \\frac{1+4+13}{12} = \\frac{18}{12} = \\frac{3}{2}$.\n\n**Case 2: Control at Node 2**\nHere, $B = B_2 = e_2 = (0, 1, 0)^T$, so $B_2 B_2^T = \\text{diag}(0, 1, 0)$. Let $W_{c,2}$ be the Gramian. The Lyapunov equation gives:\n1. $(1,1): w_{11} - \\frac{1}{4} w_{22} = 0 \\implies w_{11} = \\frac{1}{4} w_{22}$\n2. $(2,2): w_{22} - \\frac{1}{4} (w_{11} + 2w_{13} + w_{33}) = 1$\n3. $(3,3): w_{33} - \\frac{1}{4} w_{22} = 0 \\implies w_{33} = \\frac{1}{4} w_{22}$\n4. $(1,3): w_{13} - \\frac{1}{4} w_{22} = 0 \\implies w_{13} = \\frac{1}{4} w_{22}$\nDue to network symmetry w.r.t. nodes $1$ and $3$, we expect $w_{11} = w_{33}$, which is confirmed.\nSubstitute these into eq. 2:\n$w_{22} - \\frac{1}{4} (\\frac{1}{4}w_{22} + 2(\\frac{1}{4}w_{22}) + \\frac{1}{4}w_{22}) = 1$\n$w_{22} - \\frac{1}{4} (w_{22}) = 1 \\implies \\frac{3}{4} w_{22} = 1 \\implies w_{22} = 4/3$.\nThen $w_{11} = \\frac{1}{4}(\\frac{4}{3}) = 1/3$ and $w_{33} = \\frac{1}{4}(\\frac{4}{3}) = 1/3$.\nThe average controllability for node $2$ is $\\text{avg_c}_2 = \\text{Trace}(W_{c,2}) = w_{11} + w_{22} + w_{33} = \\frac{1}{3} + \\frac{4}{3} + \\frac{1}{3} = \\frac{6}{3} = 2$.\n\n**Summary and Ranking**\nThe average controllability values are:\n- Node $1$: $\\text{avg_c}_1 = 3/2 = 1.5$\n- Node $2$: $\\text{avg_c}_2 = 2$\n- Node $3$: $\\text{avg_c}_3 = 3/2 = 1.5$\n\nRanking from highest to lowest average controllability:\n1. Node $2$ (value $2$)\n2. Node $1$ (value $3/2$)\n3. Node $3$ (value $3/2$)\n\nNodes $1$ and $3$ are tied. The problem states to break ties by increasing node index. This means Node $1$ is ranked higher than Node $3$. So the final ranking is: Node $2$ (Rank $1$), Node $1$ (Rank $2$), Node $3$ (Rank $3$). The ordered list of node indices from highest rank to lowest is $(2, 1, 3)$.\n\n**Interpretation**\nThe problem asks for an interpretation of the ranking in terms of hubness (degree-based centrality). The degree of a node in a network is the number of connections it has. For the unweighted structural connectivity matrix $\\tilde{A}$, the degrees are:\n- Degree(Node $1$) = $\\sum_j \\tilde{A}_{1j} = 1$\n- Degree(Node $2$) = $\\sum_j \\tilde{A}_{2j} = 2$\n- Degree(Node $3$) = $\\sum_j \\tilde{A}_{3j} = 1$\n\nNode $2$ has the highest degree, making it the hub of this network. Nodes $1$ and $3$ are peripheral nodes with lower degrees. The ranking of average controllability (Node $2 >$ Node $1 =$ Node $3$) perfectly aligns with the ranking of node degrees.\nThe interpretation is that the hub node (Node $2$) exhibits the highest average controllability, while the peripheral nodes (Nodes $1$ and $3$) have lower average controllability. This suggests that nodes with higher degree centrality are more effective at controlling the overall network dynamics. Their central position and larger number of connections allow them to influence the state of the entire network more readily, a common finding in network control theory. The identical controllability values for nodes $1$ and $3$ reflect their symmetric topological positions in the network.\n\n**Final Answer Formulation**\nThe final answer must be a single row matrix with the average controllability values for nodes $1, 2, 3$ followed by the node indices in descending rank order.\nThe values are: $\\text{avg_c}_1 = 3/2$, $\\text{avg_c}_2 = 2$, $\\text{avg_c}_3 = 3/2$.\nThe ranked node indices are: $2, 1, 3$.\nThe resulting matrix is $(\\frac{3}{2} \\quad 2 \\quad \\frac{3}{2} \\quad 2 \\quad 1 \\quad 3)$.",
            "answer": "$$\n\\boxed{\\begin{pmatrix} \\frac{3}{2} & 2 & \\frac{3}{2} & 2 & 1 & 3 \\end{pmatrix}}\n$$"
        },
        {
            "introduction": "When analyzing large-scale brain networks, calculating controllability for every possible set of connection weights becomes infeasible. This is where the power of *structural controllability* comes into play, which depends only on the network's wiring diagram. This computational exercise tasks you with implementing a cornerstone result in network control: identifying the minimal set of \"driver nodes\" by finding the maximum matching in a bipartite graph representation of the network . This practice bridges the gap between abstract graph theory and a practical algorithm for pinpointing the critical control points within a complex biological system.",
            "id": "4001604",
            "problem": "You are given a symmetric brain structural connectivity matrix $A \\in \\mathbb{R}^{n \\times n}$ with nonnegative entries, representing undirected anatomical links between $n$ brain regions. Your task is to construct a directed brain graph by introducing plausible directionality based on a hierarchical gradient and then compute the minimal driver node set using maximum matching under structural controllability. Nodes are indexed from $0$ to $n-1$.\n\nFundamental base and definitions to use:\n- Consider a linear time-invariant system $\\dot{x}(t) = A x(t) + B u(t)$, where $x(t) \\in \\mathbb{R}^n$ is the state vector, $A \\in \\mathbb{R}^{n \\times n}$ is the system matrix dictated by the brain graph, $u(t) \\in \\mathbb{R}^m$ is the input, and $B \\in \\mathbb{R}^{n \\times m}$ is the input matrix. Structural controllability relates controllability to the sparsity pattern of $(A, B)$ and the directed graph induced by $A$'s nonzero entries.\n- For a directed graph on $n$ nodes, form a bipartite graph with left partition $L = \\{0, 1, \\dots, n-1\\}$ representing source endpoints and right partition $R = \\{0, 1, \\dots, n-1\\}$ representing target endpoints. For each directed edge $i \\to j$ in the directed graph, place a bipartite edge $(i, j)$ from $L$ to $R$.\n- A matching is a set of edges with no shared endpoints; a maximum matching is a matching with the largest possible cardinality. The minimal driver node set under structural controllability equals the set of nodes in $R$ that are unmatched in a maximum matching of the bipartite graph induced by the directed network.\n- You must implement maximum bipartite matching using a correct algorithm (for example, Hopcroft–Karp algorithm) and compute unmatched nodes in $R$.\n\nDirectionality construction rule from a symmetric $A$:\n- You are given a hierarchical score vector $h \\in \\mathbb{R}^n$ for nodes. For each undirected link, you must assign a direction that is plausible with respect to $h$, favoring edges that ascend the hierarchy but allowing occasional feedback.\n- Let $\\tau \\ge 0$ be a small tolerance. For every pair $(i, j)$ with $i < j$ and $A_{ij} > 0$, define the following:\n    1. If $\\lvert h_i - h_j \\rvert \\le \\tau$, include both directed edges $i \\to j$ and $j \\to i$.\n    2. Otherwise, let the forward direction point from the lower hierarchy node to the higher hierarchy node. Specifically, if $h_i < h_j$, include $i \\to j$; if $h_j < h_i$, include $j \\to i$.\n    3. Additionally, include a backward edge in the opposite direction with small probability-like level $\\epsilon \\in [0, 1]$ using a deterministic pseudo-random surrogate $u_{ij} = \\mathrm{frac}\\!\\left(\\sin(\\alpha i + \\beta j)^2\\right)$, where $\\mathrm{frac}(x) = x - \\lfloor x \\rfloor$, $\\alpha = 0.61803398875$, and $\\beta = 1.41421356237$. If $u_{ij} < \\epsilon$, include the backward edge as well. This surrogate ensures reproducible results while modeling occasional feedback.\n\nYour program should:\n1. For each test case, construct the directed adjacency according to the rule above.\n2. Build the bipartite representation with left indices $L = \\{0, \\dots, n-1\\}$ and right indices $R = \\{0, \\dots, n-1\\}$ and edges $(i, j)$ for each directed edge $i \\to j$.\n3. Compute a maximum matching in this bipartite graph.\n4. Return the sorted list of unmatched nodes in $R$ for each test case. This list is the minimal driver node set.\n5. Aggregate the results across test cases into a single line of output containing the results as a comma-separated list enclosed in square brackets, with each test case’s driver node set presented as a list of integers (e.g., $[[0,2],[1,3],[]]$).\n\nAngle units do not apply. There are no physical units in this problem. All outputs must be integer indices.\n\nTest suite:\n- Test case $1$ (happy path, modular graph with cross-links and hierarchy):\n    - $n = 6$,\n    - $$A = \\begin{bmatrix}\n    0 & 1 & 1 & 0 & 0 & 0 \\\\\n    1 & 0 & 1 & 0 & 0 & 0 \\\\\n    1 & 1 & 0 & 0.5 & 0 & 0 \\\\\n    0 & 0 & 0.5 & 0 & 1 & 1 \\\\\n    0 & 0 & 0 & 1 & 0 & 1 \\\\\n    0 & 0 & 0 & 1 & 1 & 0\n    \\end{bmatrix},\\quad h = [0.1, 0.2, 0.4, 0.5, 0.8, 1.0],\\quad \\epsilon = 0.15,\\quad \\tau = 0.$$\n- Test case $2$ (boundary, no edges):\n    - $n = 5$,\n    - $$A = \\begin{bmatrix}\n    0 & 0 & 0 & 0 & 0 \\\\\n    0 & 0 & 0 & 0 & 0 \\\\\n    0 & 0 & 0 & 0 & 0 \\\\\n    0 & 0 & 0 & 0 & 0 \\\\\n    0 & 0 & 0 & 0 & 0\n    \\end{bmatrix},\\quad h = [0, 0, 0, 0, 0],\\quad \\epsilon = 0.3,\\quad \\tau = 10^{-12}.$$\n- Test case $3$ (complete graph with tie hierarchy, bidirectional edges):\n    - $n = 5$,\n    - $$A_{ij} = \\begin{cases}\n    1 & \\text{if } i \\ne j,\\\\\n    0 & \\text{if } i = j\n    \\end{cases},\\quad h = [0.5, 0.5, 0.5, 0.5, 0.5],\\quad \\epsilon = 0.0,\\quad \\tau = 10^{-6}.$$\n- Test case $4$ (boundary, path graph with ascending hierarchy, no feedback):\n    - $n = 6$,\n    - $$A = \\begin{bmatrix}\n    0 & 1 & 0 & 0 & 0 & 0 \\\\\n    1 & 0 & 1 & 0 & 0 & 0 \\\\\n    0 & 1 & 0 & 1 & 0 & 0 \\\\\n    0 & 0 & 1 & 0 & 1 & 0 \\\\\n    0 & 0 & 0 & 1 & 0 & 1 \\\\\n    0 & 0 & 0 & 0 & 1 & 0\n    \\end{bmatrix},\\quad h = [0, 1, 2, 3, 4, 5],\\quad \\epsilon = 0.0,\\quad \\tau = 0.0.$$\n- Test case $5$ (star graph, high central hierarchy, no feedback):\n    - $n = 6$,\n    - $$A = \\begin{bmatrix}\n    0 & 1 & 1 & 1 & 1 & 1 \\\\\n    1 & 0 & 0 & 0 & 0 & 0 \\\\\n    1 & 0 & 0 & 0 & 0 & 0 \\\\\n    1 & 0 & 0 & 0 & 0 & 0 \\\\\n    1 & 0 & 0 & 0 & 0 & 0 \\\\\n    1 & 0 & 0 & 0 & 0 & 0\n    \\end{bmatrix},\\quad h = [2.0, 0.1, 0.1, 0.1, 0.1, 0.1],\\quad \\epsilon = 0.0,\\quad \\tau = 0.0.$$\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, where each entry is the sorted list of unmatched right nodes for a test case. For example, the output must look like $[[a_1],[a_2],\\dots]$, where each $[a_k]$ is a list of integers.",
            "solution": "The problem requires us to determine the minimal set of driver nodes for a brain network, derived from a given undirected structural connectivity matrix $A$. The solution involves a multi-step process: first, constructing a directed graph from $A$ based on a predefined hierarchical rule; second, computing a maximum matching on a bipartite graph representation of this directed network; and third, identifying the driver nodes as the unmatched nodes from the maximum matching. This procedure is grounded in the principles of structural controllability of linear time-invariant (LTI) systems.\n\nThe core of the problem lies in applying the theorem of structural controllability, which states that the minimum number of driver nodes required to control a network is $N_D = \\max(1, n - |M^{*}|)$, where $n$ is the number of nodes and $|M^{*}|$ is the cardinality of a maximum matching in the directed graph. The set of driver nodes itself corresponds to the set of unmatched nodes. The problem simplifies this to $N_D = n - |M^*|$ and defines the driver set as the unmatched nodes, which is a common convention in network control literature.\n\nThe overall algorithm proceeds as follows for each test case:\n\n1.  **Directed Graph Construction**:\n    We are given a symmetric, non-negative matrix $A \\in \\mathbb{R}^{n \\times n}$, a hierarchical score vector $h \\in \\mathbb{R}^n$, a tolerance $\\tau \\ge 0$, and a feedback probability surrogate level $\\epsilon \\in [0, 1]$. We construct a directed adjacency list representation of the brain graph. We iterate through each pair of nodes $(i, j)$ with $i < j$. If an undirected link exists (i.e., $A_{ij} > 0$), we assign directionality based on the following rules:\n    -   **Tie-breaking Rule**: If the absolute difference in hierarchical scores is within the tolerance, $|h_i - h_j| \\le \\tau$, the connection is considered reciprocal. We add both directed edges $i \\to j$ and $j \\to i$.\n    -   **Hierarchical Rule**: If $|h_i - h_j| > \\tau$, a primary feedforward edge is established from the node with the lower hierarchical score to the one with the higher score. That is, if $h_i < h_j$, we add the edge $i \\to j$; if $h_j < h_i$, we add the edge $j \\to i$.\n    -   **Feedback Rule**: In addition to the primary direction, a \"feedback\" or backward edge is added probabilistically. This is modeled by a deterministic pseudo-random surrogate $u_{ij} = \\mathrm{frac}(\\sin^2(\\alpha i + \\beta j))$, where $\\alpha = 0.61803398875$, $\\beta = 1.41421356237$, and $\\mathrm{frac}(x) = x - \\lfloor x \\rfloor$ is the fractional part of $x$. If $u_{ij} < \\epsilon$, the backward edge is also included. This surrogate ensures the result is reproducible.\n\n2.  **Maximum Bipartite Matching**:\n    The directed graph is converted into a bipartite graph $G_B = (L \\cup R, E_B)$, where the left partition $L = \\{0, 1, \\dots, n-1\\}$ and the right partition $R = \\{0, 1, \\dots, n-1\\}$ both represent the set of brain regions. For every directed edge $i \\to j$ in our constructed graph, we add a corresponding edge $(i, j)$ from node $i \\in L$ to node $j \\in R$ in the bipartite graph.\n\n    To find the maximum matching in $G_B$, we employ a standard augmenting path algorithm based on Depth-First Search (DFS). A matching is a set of edges with no common vertices. An augmenting path is a path in the graph that alternates between edges not in the matching and edges in the matching, starting from an unmatched node in $L$ and ending at an unmatched node in $R$. By finding an augmenting path and flipping the status of its edges, we can increase the size of the matching by one.\n\n    The algorithm proceeds as follows:\n    - Initialize an empty matching, where all nodes are unmatched. We use an array `match_R` of size $n$, where `match_R[v]` stores the node in $L$ matched to node $v \\in R$, initialized to a sentinel value like $-1$.\n    - Iterate through each node $u \\in L$.\n    - For each $u$, perform a DFS to find an augmenting path starting from $u$. A `visited` array is used to keep track of visited nodes in $R$ within the current DFS traversal to avoid cycles.\n    - The DFS function, `dfs(u, visited, match_R)`, attempts to find a match for node $u$. It iterates through the neighbors $v$ of $u$ in $R$. If $v$ is unvisited:\n        - We mark $v$ as visited.\n        - If $v$ is currently unmatched, or if we can recursively find an augmenting path for the node currently matched with $v$, we have found an augmenting path. We update the matching by setting `match_R[v] = u` and return `True`.\n    - If the loop completes without finding a path, `dfs` returns `False`.\n    - This process is repeated for all nodes in $L$. The final matching is a maximum matching.\n\n3.  **Driver Node Identification**:\n    According to the theory of structural controllability, the minimum set of driver nodes corresponds to the set of unmatched nodes in the right partition $R$ of the bipartite graph. After computing the maximum matching and populating the `match_R` array, the driver nodes are simply the set of indices $v \\in R$ for which `match_R[v]` remains $-1$.\n    The resulting list of driver node indices is then sorted in ascending order as required.\n\nThis entire procedure is encapsulated in a function that is called for each test case. The final output is an aggregation of the sorted lists of driver nodes from all test cases, formatted into a single string.",
            "answer": "[[3],[0,1,2,3,4],[],[0],[1,2,3,4,5]]"
        }
    ]
}