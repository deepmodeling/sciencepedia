{
    "hands_on_practices": [
        {
            "introduction": "深度卷积神经网络（CNNs）的层次化结构常被用来类比大脑腹侧视觉通路的组织方式。本练习将通过从第一性原理出发，计算一个简化CNN模型中神经元的感受野大小，从而具体地探索这一类比。通过这个计算，你将能够量化地理解人工网络中的感受野如何逐层扩大，并将其与生物视觉系统中（如从V1到V4区域）观察到的现象进行比较。",
            "id": "3974364",
            "problem": "一个卷积神经网络（CNN）被用作层次化视觉处理的模型。考虑一个由三个二维卷积层组成的前馈堆栈，这些卷积层使用各向同性的方形卷积核。第一层的卷积核大小和步长为 $(k_1=7,s_1=2)$，第二层为 $(k_2=3,s_2=2)$，第三层为 $(k_3=3,s_3=2)$。假设没有空洞卷积，并且如果存在零填充，它不会改变内部感受野的范围（即，填充不会增加能影响一个单元的真实输入像素的数量）。\n\n输入图像跨越一个 $P=256$ 像素的视网膜拓扑视野，对应于 $20$ 度的视角，并且是均匀采样的，因此每个输入像素对应相同的视角。将沿单个空间维度（例如，水平轴）的感受野范围视为我们感兴趣的量；在各向同性的假设下，二维感受野在两个轴上具有相等的范围。\n\n从离散卷积的定义出发——即它是一个局部线性算子，在每个输出位置上，以步长 $s$ 线性组合 $k$ 个相邻输入——运用第一性原理推导第三层中单个单元的有效感受野大小（以输入像素为单位）。然后，使用给定的映射关系，将此感受野大小从像素转换为视角（度）。\n\n将最终答案表示为第 3 层中一个单元所覆盖的视角，单位为度。请给出精确值，不要四舍五入。\n\n最后，在你的推理中讨论计算出的视角是否与视觉皮层 V4 区（V4）报道的感受野直径（在中等离心率下通常为 $5$ 度左右）合理地一致，并根据计算和假设来证明你的结论。",
            "solution": "问题要求计算一个三层卷积神经网络（CNN）中第三层单元的有效感受野大小，然后将其与来自视觉区域 V4 的神经生理学数据进行比较。\n\n首先，我们必须建立通过卷积层级联时感受野（RF）大小增长的数学原理。设 $R_i$ 为第 $i$ 层中一个单元的有效感受野大小（沿一个维度），以输入层（第 $0$ 层）的像素为单位。设 $k_i$ 和 $s_i$ 分别为第 $i$ 层的卷积核大小和步长。输入本身可以被视为第 $0$ 层，其中每个单元（像素）的感受野大小为 $R_0 = 1$。\n\n第 1 层中的一个单元是通过在输入层 0 上进行核大小为 $k_1$ 的卷积计算得出的。因此，其感受野大小就是卷积核的大小：\n$$R_1 = k_1$$\n\n现在，考虑第 2 层中的一个单元。它是由第 1 层输出中的 $k_2$ 个单元邻域计算得出的。这 $k_2$ 个第 1 层的单元在它们自己的网格中是相邻的。由于第一层的步长为 $s_1$，第 1 层中任意两个相邻单元的感受野中心在输入层 0 上相距 $s_1$ 个像素。\n这 $k_2$ 个来自第 1 层的单元所覆盖的总空间范围由它们中心的跨度加上单个感受野的大小决定。来自第 1 层的 $k_2$ 个感受野的中心在输入层上跨越了 $(k_2-1)s_1$ 像素的距离。为了求出第 2 层单元的总感受野大小，我们将单个第 1 层单元的感受野大小 $R_1$ 加到这个跨度上。这涵盖了从第一个单元感受野的开始到最后一个单元感受野结束的全部范围。因此，感受野大小的递归关系是：\n$$R_2 = R_1 + (k_2 - 1)s_1$$\n将此推广，第 $i$ 层中一个单元的有效感受野大小 $R_i$ 等于其相对于第 $i-1$ 层的感受野大小 $R_{i-1}$，再加上由 $k_i$ 个卷积核覆盖的额外范围，这些卷积核的中心被之前所有层的累积步长所分隔。第 $i-1$ 层相邻单元之间的步长投影回输入层是所有前面层步长的乘积，即 $\\prod_{j=1}^{i-1} s_j$。递归公式为：\n$$R_i = R_{i-1} + (k_i - 1) \\prod_{j=1}^{i-1} s_j$$\n\n给定一个三层网络的以下参数：\n- 第 1 层：$k_1 = 7$, $s_1 = 2$\n- 第 2 层：$k_2 = 3$, $s_2 = 2$\n- 第 3 层：$k_3 = 3$, $s_3 = 2$\n\n现在我们可以逐步计算感受野的大小。\n基准情况是输入层中的单个像素：\n$$R_0 = 1$$\n对于第 1 层中的一个单元：\n$$R_1 = R_0 + (k_1 - 1) \\prod_{j=1}^{0} s_j = R_0 + (k_1 - 1) \\times 1 = 1 + (7 - 1) = 7 \\text{ 像素}$$\n这是一致的，因为第一层的卷积核直接观察 $7$ 个输入像素。\n\n对于第 2 层中的一个单元：\n$$R_2 = R_1 + (k_2 - 1) \\prod_{j=1}^{1} s_j = R_1 + (k_2 - 1)s_1$$\n$$R_2 = 7 + (3 - 1) \\times 2 = 7 + 2 \\times 2 = 11 \\text{ 像素}$$\n\n对于第 3 层中的一个单元：\n$$R_3 = R_2 + (k_3 - 1) \\prod_{j=1}^{2} s_j = R_2 + (k_3 - 1)s_1 s_2$$\n$$R_3 = 11 + (3 - 1) \\times (2 \\times 2) = 11 + 2 \\times 4 = 11 + 8 = 19 \\text{ 像素}$$\n所以，第三层中单个单元的有效感受野跨越了输入图像的 $19$ 个像素。\n\n接下来，我们将这个大小从像素转换为视角（度）。输入图像的大小为 $P = 256$ 像素，对应 $20$ 度的视野。采样是均匀的，因此转换因子在整个视野中是恒定的。\n每个像素的视角是：\n$$\\frac{20 \\text{ 度}}{256 \\text{ 像素}}$$\n以度为单位的感受野大小，我们记为 $\\theta_{RF}$，是像素大小乘以该转换因子：\n$$\\theta_{RF} = R_3 \\times \\frac{20}{256} = 19 \\times \\frac{20}{256} = \\frac{380}{256}$$\n为了将其表示为最简的精确分数，我们找到分子和分母的最大公约数。两者都可以被 $4$ 整除：\n$$380 \\div 4 = 95$$\n$$256 \\div 4 = 64$$\n所以，精确的视角是：\n$$\\theta_{RF} = \\frac{95}{64} \\text{ 度}$$\n\n最后，问题要求讨论这个值是否与视觉皮层 V4 区的感受野直径（据报道在中等离心率下约为 $5$ 度）合理地一致。\n计算出的值为 $\\frac{95}{64} \\approx 1.48$ 度。这个值远小于报道的 V4 在中等离心率下的典型感受野大小 $5$ 度。\n\n基于此计算，所指定的三层 CNN 在实现类似 V4 的感受野大小方面并非一个定量准确的模型。这种差异表明，该模型过于简单，或者其参数过于保守，无法捕捉到腹侧视觉通路直至 V4 区域的全部空间整合特性。有几个因素可以解释这种差异：\n1.  **网络深度**：生物视觉层级（例如，视网膜 -> LGN -> V1 -> V2 -> V4）涉及的处理阶段比该模型中的三层要多。更深的网络会更大程度地复合感受野，从而导致更大的最终感受野尺寸。\n2.  **池化层**：该模型仅使用带步长的卷积。模拟视觉系统的架构通常包括池化层（例如，最大池化），这也会在每一步增加有效感受野的大小，其增加效果通常比卷积层内步长为 $2$ 更为激进。\n3.  **空洞卷积**：该模型假设没有空洞卷积。空洞（或扩张）卷积是一种在不增加参数数量的情况下增大感受野大小的机制。这是一个合理的生物学机制，也是现代为大规模空间理解而设计的 CNN 的一个共同特征。\n4.  **模型参数**：卷积核大小和步长可能太小。更大的值，尤其是早期层中的步长，会导致感受野增长得更快。\n5.  **离心率依赖性**：$5$ 度的比较值是针对“中等离心率”的。V4 的感受野在中央凹附近较小。我们对 CNN 中一个通用单元的计算可能更能代表旁中央凹的 V4 神经元，而不是中等离心率下的神经元。然而，即使对于中央凹的 V4 神经元来说，$1.48$ 度也偏小了。\n6.  **非前馈机制**：生物皮层包含广泛的侧向和反馈连接，这些连接可以动态地调节感受野特性，而这个简单的、严格前馈的模型没有捕捉到这一点。\n\n总之，虽然该模型正确地实现了分层特征和感受野构建的原理，但它太浅了，无法产生与皮层 V4 区相当的感受野大小。",
            "answer": "$$\\boxed{\\frac{95}{64}}$$"
        },
        {
            "introduction": "在探索了前馈模型之后，我们转向递归神经网络，这对于建模大脑的内部状态（如工作记忆或空间方位）至关重要。环形吸引子网络是解释大脑如何表征头部朝向等环形变量的经典模型。本练习将探讨一种特定的递归连接模式——局部兴奋与全局抑制——如何能自发地形成稳定的“活动凸起”，而这个活动凸起能够作为一个动态的记忆存储单元。",
            "id": "3974360",
            "problem": "考虑一个环形吸引子递归神经网络，该网络用 $N \\geq 5$ 个神经元模拟一个一维环形变量（例如，头部方向）。这些神经元由单位圆上的优先角度 $\\theta_i \\in \\{0, \\frac{2\\pi}{N}, \\ldots, \\frac{2\\pi(N-1)}{N}\\}$ 索引。递归权重矩阵在环上具有平移不变性，定义为\n$$\nW_{ij} \\;=\\; w_0 \\;+\\; w_1 \\cos\\!\\big(\\theta_i - \\theta_j\\big),\n$$\n其中 $w_0 \\in \\mathbb{R}$ 和 $w_1 \\in \\mathbb{R}$ 是常数。神经元发放率 $r_i(t)$ 遵循一个标准发放率模型\n$$\n\\tau \\frac{d r_i}{dt} \\;=\\; -\\,r_i \\;+\\; \\phi\\!\\Big(g \\sum_{j=1}^{N} W_{ij}\\, r_j \\;+\\; I\\Big),\n$$\n其中 $\\tau > 0$ 是膜时间常数，$g > 0$ 是全局突触增益，$I \\in \\mathbb{R}$ 是一个恒定的外部驱动，$\\phi(\\cdot)$ 是一个平滑的单调递增激活函数。假设存在一个均匀不动点 $r_i(t) = \\bar{r}$（对所有 $i$ 成立），满足 $\\bar{r} = \\phi\\!\\big(g \\sum_j W_{ij}\\, \\bar{r} + I\\big)$，并将在工作点处的局部斜率定义为 $\\alpha := \\phi'(u)$，其中 $u := g \\sum_j W_{ij}\\, \\bar{r} + I$。\n\n从环上的线性和对称性的基本原理出发，分析均匀不动点周围的无穷小扰动 $\\delta r_i(t)$，并使用离散傅里叶基来对角化线性化后的动力学。然后：\n\n1. 在环上的离散傅里叶基中，推导权重矩阵 $W$ 的本征模和本征值。\n2. 使用线性化动力学，确定当增益 $g$ 增加时，哪个傅里叶模会首先变得不稳定，并找出在此条件下，第一个非平凡的空间（形成凸起）模在均匀（零波数）模之前失稳的条件（关于 $w_0$ 和 $w_1$）。\n3. 在该条件下，计算第一个空间傅里叶模失去稳定性时的临界增益 $g^{\\star}$，并以 $N$、$w_1$ 和 $\\alpha$ 的闭合形式表示。请提供此 $g^{\\star}$ 作为您的最终答案。\n\n请将您的最终答案表示为单个闭合形式的解析表达式。不要包含单位，也不要在最终答案框中提供不等式或其他附加条件。",
            "solution": "该问题在计算神经科学的标准理论框架内是良定的，并具有科学依据。我们可以进行形式化的求解。\n\n根据要求，解题过程分为三部分：首先，我们确定权重矩阵 $W$ 的本征值；其次，我们分析均匀态的稳定性，并找到空间不稳定性的条件；第三，我们计算这种不稳定性开始时的临界增益 $g^{\\star}$。\n\n**1. 权重矩阵 $W$ 的本征模和本征值**\n\n递归权重矩阵由 $W_{ij} = w_0 + w_1 \\cos(\\theta_i - \\theta_j)$ 给出。神经元索引为 $i,j \\in \\{1, \\dots, N\\}$，优先角度为 $\\theta_i = \\frac{2\\pi(i-1)}{N}$。项 $\\theta_i - \\theta_j$ 可写为 $\\frac{2\\pi(i-j)}{N}$。由于 $W_{ij}$ 仅取决于差值 $(i-j) \\pmod N$，矩阵 $W$ 是一个循环矩阵。\n\n任何 $N \\times N$ 循环矩阵的本征向量都是离散傅里叶模。对于波数 $k \\in \\{0, 1, \\ldots, N-1\\}$，第 $k$ 个未归一化的本征向量是一个向量 $\\mathbf{v}^{(k)}$，其分量为 $v_j^{(k)} = \\exp(i \\theta_j k) = \\exp\\left(i \\frac{2\\pi(j-1)k}{N}\\right)$。\n\n相应的本征值 $\\lambda_k$ 可以通过将矩阵 $W$ 应用于其本征向量 $\\mathbf{v}^{(k)}$ 来找到：\n$$ (\\mathbf{W}\\mathbf{v}^{(k)})_i = \\sum_{j=1}^{N} W_{ij} v_j^{(k)} = \\sum_{j=1}^{N} \\left(w_0 + w_1 \\cos(\\theta_i - \\theta_j)\\right) \\exp(i \\theta_j k) $$\n我们可以提取出因子 $\\exp(i\\theta_i k)$，并设求和索引为 $m=i-j$：\n$$ (\\mathbf{W}\\mathbf{v}^{(k)})_i = \\exp(i\\theta_i k) \\sum_{j=1}^{N} \\left(w_0 + w_1 \\cos(\\theta_i - \\theta_j)\\right) \\exp(i(\\theta_j - \\theta_i)k) $$\n$$ = v_i^{(k)} \\sum_{m=i-N}^{i-1} \\left(w_0 + w_1 \\cos\\left(\\frac{2\\pi m}{N}\\right)\\right) \\exp\\left(-i\\frac{2\\pi m k}{N}\\right) $$\n由于和中的项关于 $m$ 是周期为 $N$ 的周期函数，我们可以对任意 $N$ 个连续整数求和，例如 $m \\in \\{0, 1, \\ldots, N-1\\}$。因此，本征值 $\\lambda_k$ 由下式给出：\n$$ \\lambda_k = \\sum_{m=0}^{N-1} \\left(w_0 + w_1 \\cos\\left(\\frac{2\\pi m}{N}\\right)\\right) \\exp\\left(-i\\frac{2\\pi m k}{N}\\right) $$\n我们将求和分为两部分：\n$$ \\lambda_k = w_0 \\sum_{m=0}^{N-1} \\exp\\left(-i\\frac{2\\pi m k}{N}\\right) + w_1 \\sum_{m=0}^{N-1} \\cos\\left(\\frac{2\\pi m}{N}\\right) \\exp\\left(-i\\frac{2\\pi m k}{N}\\right) $$\n第一个和是一个等比级数，当 $k=0 \\pmod N$ 时等于 $N$，否则为 $0$。使用克罗内克δ函数，此项为 $N w_0 \\delta_{k,0}$。\n\n对于第二个和，我们使用欧拉公式表示余弦，$\\cos(x) = \\frac{1}{2}(\\exp(ix) + \\exp(-ix))$：\n$$ w_1 \\sum_{m=0}^{N-1} \\frac{1}{2}\\left(\\exp\\left(i\\frac{2\\pi m}{N}\\right) + \\exp\\left(-i\\frac{2\\pi m}{N}\\right)\\right) \\exp\\left(-i\\frac{2\\pi m k}{N}\\right) $$\n$$ = \\frac{w_1}{2} \\sum_{m=0}^{N-1} \\left(\\exp\\left(-i\\frac{2\\pi m (k-1)}{N}\\right) + \\exp\\left(-i\\frac{2\\pi m (k+1)}{N}\\right)\\right) $$\n这个和仅在 $k-1=0 \\pmod N$（即 $k=1$）或 $k+1=0 \\pmod N$（即 $k=N-1$）时非零。\n对于 $k=1$，括号中的第一项求和为 $N$，第二项为 $0$（因为 $N \\ge 5$，所以 $k+1=2 \\not\\equiv 0 \\pmod N$）。\n对于 $k=N-1$，第二项求和为 $N$，第一项为 $0$（因为 $k-1=N-2 \\not\\equiv 0 \\pmod N$）。\n综合这些结果，$W$ 的本征值为：\n- 对于 $k=0$：$\\lambda_0 = N w_0$。\n- 对于 $k=1$：$\\lambda_1 = \\frac{N w_1}{2}$。\n- 对于 $k=N-1$：$\\lambda_{N-1} = \\frac{N w_1}{2}$。\n- 对于 $k \\in \\{2, 3, \\ldots, N-2\\}$：$\\lambda_k = 0$。\n\n本征模是离散傅里叶基向量 $\\mathbf{v}^{(k)}$。\n\n**2. 线性化与稳定性分析**\n\n我们对动力学方程 $\\tau \\frac{dr_i}{dt} = -r_i + \\phi(g \\sum_{j} W_{ij} r_j + I)$ 在均匀不动点 $r_i(t) = \\bar{r}$ 周围进行线性化。令 $r_i(t) = \\bar{r} + \\delta r_i(t)$，其中 $\\delta r_i(t)$ 是一个无穷小扰动。\n激活函数的自变量是 $u_i = g \\sum_j W_{ij} r_j + I$。在不动点处，此自变量是 $u = g \\sum_j W_{ij} \\bar{r} + I = g \\bar{r} (N w_0) + I$，这与 $i$ 无关。\n扰动的线性化动力学为：\n$$ \\tau \\frac{d\\delta r_i}{dt} = -\\delta r_i + \\left. \\frac{\\partial \\phi}{\\partial u_i} \\right|_{u} \\left(g \\sum_{j} W_{ij} \\delta r_j\\right) $$\n使用给定的定义 $\\alpha = \\phi'(u)$，这变为：\n$$ \\tau \\frac{d\\delta r_i}{dt} = -\\delta r_i + \\alpha g \\sum_{j=1}^{N} W_{ij} \\delta r_j $$\n以向量形式，令 $\\delta\\mathbf{r} = (\\delta r_1, \\ldots, \\delta r_N)^T$，方程为：\n$$ \\tau \\frac{d\\delta\\mathbf{r}}{dt} = (-I_N + \\alpha g W) \\delta\\mathbf{r} $$\n其中 $I_N$ 是单位矩阵。不动点的稳定性由雅可比矩阵 $J = \\frac{1}{\\tau}(-I_N + \\alpha g W)$ 的本征值决定。$J$ 的本征值记为 $\\mu_k$，与 $W$ 的本征值 $\\lambda_k$ 的关系为：\n$$ \\mu_k = \\frac{1}{\\tau}(-1 + \\alpha g \\lambda_k) $$\n当任何本征值 $\\mu_k$ 的实部变为正时，均匀不动点变得不稳定。由于 $\\alpha > 0$ 和 $g>0$，当对于某个 $k$，$-1 + \\alpha g \\lambda_k > 0$ 时发生不稳定性，这意味着 $\\alpha g \\lambda_k > 1$。这要求 $\\lambda_k > 0$。当 $g$ 从 $0$ 开始增加时，具有最大正本征值 $\\lambda_k$ 的模态 $k$ 将首先失稳。\n\n非平凡的空间（形成凸起）模对应于 $k=1$（以及 $k=N-1$）。均匀模对应于 $k=0$。其他模 ($k \\in \\{2, ..., N-2\\}$) 的 $\\lambda_k=0$，因此它们总是稳定的，$\\mu_k = -1/\\tau$。\n为了使空间模在均匀模之前失稳，其对应的本征值必须是正的，并且大于均匀模的本征值。即，我们要求 $\\lambda_1 > 0$ 和 $\\lambda_1 > \\lambda_0$。\n1.  $\\lambda_1 > 0 \\implies \\frac{N w_1}{2} > 0 \\implies w_1 > 0$。\n2.  $\\lambda_1 > \\lambda_0 \\implies \\frac{N w_1}{2} > N w_0 \\implies w_1 > 2 w_0$。\n\n因此，第一个空间模首先失稳的条件是 $w_1 > 0$ 且 $w_1 > 2w_0$。\n\n**3. 临界增益 $g^{\\star}$**\n\n在上述导出的条件下，随着 $g$ 的增加，首先发生的不稳定性是对应于空间模 $k=1$ 的图灵型分岔。临界增益 $g^{\\star}$ 是本征值 $\\mu_1$ 的实部穿过零点时的 $g$ 值。\n$$ \\text{Re}(\\mu_1) = \\frac{1}{\\tau}(-1 + \\alpha g^{\\star} \\lambda_1) = 0 $$\n$$ \\implies 1 = \\alpha g^{\\star} \\lambda_1 $$\n解出 $g^{\\star}$，我们得到：\n$$ g^{\\star} = \\frac{1}{\\alpha \\lambda_1} $$\n代入 $\\lambda_1 = \\frac{N w_1}{2}$ 的表达式：\n$$ g^{\\star} = \\frac{1}{\\alpha \\left(\\frac{N w_1}{2}\\right)} = \\frac{2}{N \\alpha w_1} $$\n这是均匀态向空间模式化状态（一个“凸起”）失去稳定性时的临界增益。该表达式用指定的参数 $N$、$w_1$ 和 $\\alpha$ 表示。",
            "answer": "$$\n\\boxed{\\frac{2}{N \\alpha w_1}}\n$$"
        },
        {
            "introduction": "理解了网络结构与动态后，我们最终转向学习机制：神经网络的连接是如何通过经验自我组织的？Oja法则是一个经典的、具有生物学合理性的学习规则，它为“共同激发的神经元会加强连接”这一赫布原则提供了一个包含关键归一化项的数学形式。这个练习将引导你证明，这条简单的局部学习规则如何使单个神经元的权重向量收敛至输入数据的第一主成分（PCA），从而揭示了神经可塑性与高效编码之间的深刻联系。",
            "id": "3974366",
            "problem": "一个具有突触权重向量 $\\mathbf{w} \\in \\mathbb{R}^{d}$ 的线性神经元接收输入 $\\mathbf{x}_{t} \\in \\mathbb{R}^{d}$，这些输入是独立同分布 (IID) 的，均值为零，协方差矩阵为 $\\boldsymbol{\\Sigma} \\in \\mathbb{R}^{d \\times d}$，该矩阵是对称半正定的。神经元的活动为 $y_{t} = \\mathbf{w}_{t}^{\\top} \\mathbf{x}_{t}$。突触可塑性遵循 Oja 法则，这是一种归一化的 Hebbian 更新：\n$$\n\\mathbf{w}_{t+1} = \\mathbf{w}_{t} + \\eta\\, y_{t}\\big(\\mathbf{x}_{t} - y_{t}\\,\\mathbf{w}_{t}\\big),\n$$\n其中 $\\eta > 0$ 是一个小的学习率。主成分分析 (PCA) 定义为在单位范数约束 $\\|\\mathbf{w}\\|_{2} = 1$ 下最大化瑞利商 $R(\\mathbf{w}) = \\mathbf{w}^{\\top}\\boldsymbol{\\Sigma}\\mathbf{w}$，其最大值点是 $\\boldsymbol{\\Sigma}$ 对应于最大特征值 $\\lambda_{1}$ 的任意主特征向量 $\\mathbf{v}_{1}$。\n\n仅从上述定义和以下基本事实出发：(i) $\\mathbb{E}[\\mathbf{x}_{t}] = \\mathbf{0}$，(ii) $\\mathbb{E}[\\mathbf{x}_{t}\\mathbf{x}_{t}^{\\top}] = \\boldsymbol{\\Sigma}$，以及 (iii) 小步长随机更新的连续时间极限可以用一个关于期望动态的常微分方程 (ODE) 来近似，请完成以下任务：\n\n- 推导在极限 $\\eta \\to 0$ 下，由 Oja 法则所隐含的 $\\mathbf{w}(t)$ 期望演化的平均场常微分方程。\n- 使用单位范数流形 $\\|\\mathbf{w}\\|_{2} = 1$ 和瑞利商 $R(\\mathbf{w})$，从第一性原理出发，论证为什么平均场动力学的稳定不动点对应于 $\\boldsymbol{\\Sigma}$ 的主特征向量，从而实现在线 PCA。\n- 将平均场 ODE 在单位范数主特征向量 $\\mathbf{v}_{1}$ (其特征值为 $\\lambda_{1}$) 附近进行线性化，以获得与 $\\mathbf{v}_{1}$ 正交方向上的扰动的渐近衰减率。假设协方差谱的特征值为 $\\lambda_{1} \\ge \\lambda_{2} \\ge \\cdots \\ge \\lambda_{d} \\ge 0$，且初始条件满足 $\\|\\mathbf{w}(0)\\|_{2} = 1$。\n\n你的最终答案必须是平均场连续时间动力学的渐近指数收敛率（正交模式中最慢的衰减率）的单一符号表达式，用最大特征值 $\\lambda_{1}$ 和第二大特征值 $\\lambda_{2}$ 表示。不要包含任何单位。无需进行数值四舍五入；请提供精确的解析表达式。",
            "solution": "该问题要求对 Oja 法则进行三部分分析。我们必须首先验证问题陈述，经核实，该陈述有效、适定且科学合理。这是理论神经科学中的一个经典问题。我们继续进行求解。\n\n问题提供了以下组成部分：一个线性神经元，其输出为 $y_{t} = \\mathbf{w}_{t}^{\\top} \\mathbf{x}_{t}$，其中 $\\mathbf{w}_{t} \\in \\mathbb{R}^{d}$ 是权重向量，$\\mathbf{x}_{t} \\in \\mathbb{R}^{d}$ 是输入。输入是独立同分布的，满足 $\\mathbb{E}[\\mathbf{x}_{t}] = \\mathbf{0}$ 且协方差为 $\\mathbb{E}[\\mathbf{x}_{t}\\mathbf{x}_{t}^{\\top}] = \\boldsymbol{\\Sigma}$。权重根据 Oja 法则演化：\n$$\n\\mathbf{w}_{t+1} = \\mathbf{w}_{t} + \\eta\\, y_{t}\\big(\\mathbf{x}_{t} - y_{t}\\,\\mathbf{w}_{t}\\big)\n$$\n其中 $\\eta > 0$ 是一个小的学习率。\n\n**1. 平均场常微分方程的推导**\n\n为了推导小学习率 $\\eta \\to 0$ 极限下的连续时间动力学，我们首先重写离散更新规则。令 $\\Delta \\mathbf{w}_{t} = \\mathbf{w}_{t+1} - \\mathbf{w}_{t}$。则有，\n$$\n\\frac{\\Delta \\mathbf{w}_{t}}{\\eta} = y_{t}\\mathbf{x}_{t} - y_{t}^{2}\\mathbf{w}_{t}\n$$\n在连续时间极限下，我们令 $\\eta$ 为一个无穷小的时间步长 $dt$，因此左侧变为时间导数 $\\frac{d\\mathbf{w}}{dt}$。右侧是依赖于输入 $\\mathbf{x}_{t}$ 的随机量。对于小的学习率，权重向量 $\\mathbf{w}(t)$ 的变化比输入 $\\mathbf{x}(t)$ 慢得多。因此，我们可以通过对 $\\mathbf{x}$ 的分布求更新项的平均值来进行平均场近似，将 $\\mathbf{w}$ 视为准静态的。\n$$\n\\frac{d\\mathbf{w}}{dt} = \\mathbb{E}_{\\mathbf{x}}\\left[ y\\mathbf{x} - y^{2}\\mathbf{w} \\right]\n$$\n其中 $y = \\mathbf{w}^{\\top}\\mathbf{x}$。我们分别计算每一项的期望。\n\n对于第一项，我们使用 $y$ 的定义和期望的线性性质：\n$$\n\\mathbb{E}[y\\mathbf{x}] = \\mathbb{E}[(\\mathbf{w}^{\\top}\\mathbf{x})\\mathbf{x}] = \\mathbb{E}[\\mathbf{x}(\\mathbf{x}^{\\top}\\mathbf{w})]\n$$\n由于在对 $\\mathbf{x}$ 求期望时 $\\mathbf{w}$被视为常数，我们可以写出：\n$$\n\\mathbb{E}[\\mathbf{x}\\mathbf{x}^{\\top}\\mathbf{w}] = \\mathbb{E}[\\mathbf{x}\\mathbf{x}^{\\top}]\\mathbf{w} = \\boldsymbol{\\Sigma}\\mathbf{w}\n$$\n对于第二项，我们首先计算 $y^{2}$ 的期望：\n$$\n\\mathbb{E}[y^{2}] = \\mathbb{E}[(\\mathbf{w}^{\\top}\\mathbf{x})^{2}] = \\mathbb{E}[(\\mathbf{w}^{\\top}\\mathbf{x})(\\mathbf{x}^{\\top}\\mathbf{w})] = \\mathbf{w}^{\\top}\\mathbb{E}[\\mathbf{x}\\mathbf{x}^{\\top}]\\mathbf{w} = \\mathbf{w}^{\\top}\\boldsymbol{\\Sigma}\\mathbf{w}\n$$\n那么更新中第二项的期望为：\n$$\n\\mathbb{E}[y^{2}\\mathbf{w}] = \\mathbb{E}[y^{2}]\\mathbf{w} = (\\mathbf{w}^{\\top}\\boldsymbol{\\Sigma}\\mathbf{w})\\mathbf{w}\n$$\n结合这些结果，我们得到权重向量 $\\mathbf{w}(t)$ 演化的平均场常微分方程 (ODE)：\n$$\n\\frac{d\\mathbf{w}}{dt} = \\boldsymbol{\\Sigma}\\mathbf{w} - (\\mathbf{w}^{\\top}\\boldsymbol{\\Sigma}\\mathbf{w})\\mathbf{w}\n$$\n\n**2. 不动点与主成分分析的联系**\n\n问题陈述 PCA 等价于在 $\\|\\mathbf{w}\\|_{2} = 1$ 的约束下最大化瑞利商 $R(\\mathbf{w}) = \\mathbf{w}^{\\top}\\boldsymbol{\\Sigma}\\mathbf{w}$。其最大值点是 $\\boldsymbol{\\Sigma}$ 的主特征向量 $\\mathbf{v}_{1}$。我们现在将证明所推导的 ODE 的稳定不动点对应于这些主特征向量。\n\n首先，让我们分析 $\\mathbf{w}(t)$ 的范数。初始条件为 $\\|\\mathbf{w}(0)\\|_{2} = 1$。范数平方 $\\|\\mathbf{w}\\|_{2}^{2} = \\mathbf{w}^{\\top}\\mathbf{w}$ 的演化由下式给出：\n$$\n\\frac{d}{dt}(\\mathbf{w}^{\\top}\\mathbf{w}) = 2\\mathbf{w}^{\\top}\\frac{d\\mathbf{w}}{dt} = 2\\mathbf{w}^{\\top}\\left[ \\boldsymbol{\\Sigma}\\mathbf{w} - (\\mathbf{w}^{\\top}\\boldsymbol{\\Sigma}\\mathbf{w})\\mathbf{w} \\right]\n$$\n$$\n\\frac{d}{dt}\\|\\mathbf{w}\\|_{2}^{2} = 2\\left[ \\mathbf{w}^{\\top}\\boldsymbol{\\Sigma}\\mathbf{w} - (\\mathbf{w}^{\\top}\\boldsymbol{\\Sigma}\\mathbf{w})(\\mathbf{w}^{\\top}\\mathbf{w}) \\right] = 2(\\mathbf{w}^{\\top}\\boldsymbol{\\Sigma}\\mathbf{w})(1 - \\|\\mathbf{w}\\|_{2}^{2})\n$$\n如果 $\\|\\mathbf{w}(0)\\|_{2}^{2} = 1$，则 $\\frac{d}{dt}\\|\\mathbf{w}\\|_{2}^{2}|_{t=0} = 0$。这意味着对于所有 $t \\ge 0$，$\\|\\mathbf{w}(t)\\|_{2} = 1$。因此，单位球面是该动力学的一个不变流形。\n\nODE 的不动点 $\\mathbf{w}^{*}$ 可通过设置 $\\frac{d\\mathbf{w}}{dt} = \\mathbf{0}$ 求得：\n$$\n\\boldsymbol{\\Sigma}\\mathbf{w}^{*} - (\\mathbf{w}^{*\\top}\\boldsymbol{\\Sigma}\\mathbf{w}^{*})\\mathbf{w}^{*} = \\mathbf{0} \\quad \\implies \\quad \\boldsymbol{\\Sigma}\\mathbf{w}^{*} = (\\mathbf{w}^{*\\top}\\boldsymbol{\\Sigma}\\mathbf{w}^{*})\\mathbf{w}^{*}\n$$\n这是一个特征向量方程。任何非零不动点 $\\mathbf{w}^{*}$ 必须是协方差矩阵 $\\boldsymbol{\\Sigma}$ 的一个特征向量，其对应的特征值为 $\\lambda = \\mathbf{w}^{*\\top}\\boldsymbol{\\Sigma}\\mathbf{w}^{*} = R(\\mathbf{w}^{*})$。\n\n为确定稳定性，我们将瑞利商 $R(\\mathbf{w}) = \\mathbf{w}^{\\top}\\boldsymbol{\\Sigma}\\mathbf{w}$ 视为单位球面上动力学的一个李雅普诺夫函数。其时间导数为：\n$$\n\\frac{dR}{dt} = \\frac{d}{dt}(\\mathbf{w}^{\\top}\\boldsymbol{\\Sigma}\\mathbf{w}) = 2(\\boldsymbol{\\Sigma}\\mathbf{w})^{\\top}\\frac{d\\mathbf{w}}{dt} = 2\\mathbf{w}^{\\top}\\boldsymbol{\\Sigma}\\frac{d\\mathbf{w}}{dt}\n$$\n代入 $\\frac{d\\mathbf{w}}{dt}$ 的 ODE：\n$$\n\\frac{dR}{dt} = 2\\mathbf{w}^{\\top}\\boldsymbol{\\Sigma}\\left[\\boldsymbol{\\Sigma}\\mathbf{w} - (\\mathbf{w}^{\\top}\\boldsymbol{\\Sigma}\\mathbf{w})\\mathbf{w}\\right] = 2\\left[\\mathbf{w}^{\\top}\\boldsymbol{\\Sigma}^{2}\\mathbf{w} - (\\mathbf{w}^{\\top}\\boldsymbol{\\Sigma}\\mathbf{w})^{2}\\right]\n$$\n设 $\\boldsymbol{\\Sigma}$ 的标准正交特征向量为 $\\{\\mathbf{v}_{i}\\}$，对应的特征值为 $\\lambda_{1} \\ge \\lambda_{2} \\ge \\cdots \\ge \\lambda_{d} \\ge 0$。我们可以将 $\\mathbf{w}$ 在该基下表示为：$\\mathbf{w} = \\sum_{i=1}^{d} c_{i}\\mathbf{v}_{i}$，其中 $\\sum_{i=1}^{d} c_{i}^{2} = \\|\\mathbf{w}\\|_{2}^{2} = 1$。\n那么 $\\mathbf{w}^{\\top}\\boldsymbol{\\Sigma}^{2}\\mathbf{w} = \\sum_{i=1}^{d} c_{i}^{2}\\lambda_{i}^{2}$ 且 $(\\mathbf{w}^{\\top}\\boldsymbol{\\Sigma}\\mathbf{w})^{2} = (\\sum_{i=1}^{d} c_{i}^{2}\\lambda_{i})^{2}$。\n项 $\\sum_{i} c_{i}^{2}\\lambda_{i}$ 是一个随机变量的期望值，该随机变量以概率 $c_{i}^{2}$ 取值 $\\lambda_{i}$。根据琴生不等式，$\\mathbb{E}[X^2] \\ge (\\mathbb{E}[X])^2$，所以 $\\sum c_{i}^{2}\\lambda_{i}^{2} \\ge (\\sum c_{i}^{2}\\lambda_{i})^{2}$。\n因此，$\\frac{dR}{dt} \\ge 0$。瑞利商是非递减的。该动力学驱使 $\\mathbf{w}(t)$ 在单位球面上沿着由 $R(\\mathbf{w})$ 定义的“地形”向上移动。等式 $\\frac{dR}{dt}=0$ 成立当且仅当 $\\mathbf{w}$ 是 $\\boldsymbol{\\Sigma}$ 的一个特征向量。\n稳定不动点对应于 $R(\\mathbf{w})$ 的局部最大值点。$R(\\mathbf{w})$ 在单位球面上的全局最大值为 $\\lambda_{1}$，当 $\\mathbf{w}$ 是主特征向量 $\\mathbf{v}_{1}$ 时取得。因此，动力学收敛到 $\\boldsymbol{\\Sigma}$ 的主特征向量，从而有效地执行了 PCA。\n\n**3. 线性化与收敛率**\n\n我们现在将 ODE 在一个主特征向量不动点 $\\mathbf{w}^{*} = \\mathbf{v}_{1}$ 附近进行线性化（假设 $\\lambda_{1} > \\lambda_{2}$ 以保证唯一性）。令 $\\mathbf{w}(t) = \\mathbf{v}_{1} + \\boldsymbol{\\epsilon}(t)$，其中 $\\boldsymbol{\\epsilon}(t)$ 是一个小的扰动。由于 $\\mathbf{w}(t)$ 保持在单位球面上，我们有一阶近似：\n$$\n\\|\\mathbf{v}_{1} + \\boldsymbol{\\epsilon}\\|_{2}^{2} = \\mathbf{v}_{1}^{\\top}\\mathbf{v}_{1} + 2\\mathbf{v}_{1}^{\\top}\\boldsymbol{\\epsilon} + O(\\|\\boldsymbol{\\epsilon}\\|_{2}^{2}) = 1 + 2\\mathbf{v}_{1}^{\\top}\\boldsymbol{\\epsilon} \\approx 1\n$$\n这意味着 $\\mathbf{v}_{1}^{\\top}\\boldsymbol{\\epsilon} = 0$，所以扰动 $\\boldsymbol{\\epsilon}(t)$ 必须与 $\\mathbf{v}_{1}$ 正交。\n扰动的时间导数为 $\\frac{d\\boldsymbol{\\epsilon}}{dt}$。将 $\\mathbf{w} = \\mathbf{v}_{1} + \\boldsymbol{\\epsilon}$ 代入 ODE：\n$$\n\\frac{d\\boldsymbol{\\epsilon}}{dt} = \\boldsymbol{\\Sigma}(\\mathbf{v}_{1} + \\boldsymbol{\\epsilon}) - \\big((\\mathbf{v}_{1} + \\boldsymbol{\\epsilon})^{\\top}\\boldsymbol{\\Sigma}(\\mathbf{v}_{1} + \\boldsymbol{\\epsilon})\\big)(\\mathbf{v}_{1} + \\boldsymbol{\\epsilon})\n$$\n展开并保留 $\\boldsymbol{\\epsilon}$ 的一阶项：\n- $\\boldsymbol{\\Sigma}(\\mathbf{v}_{1} + \\boldsymbol{\\epsilon}) = \\boldsymbol{\\Sigma}\\mathbf{v}_{1} + \\boldsymbol{\\Sigma}\\boldsymbol{\\epsilon} = \\lambda_{1}\\mathbf{v}_{1} + \\boldsymbol{\\Sigma}\\boldsymbol{\\epsilon}$。\n- $(\\mathbf{v}_{1} + \\boldsymbol{\\epsilon})^{\\top}\\boldsymbol{\\Sigma}(\\mathbf{v}_{1} + \\boldsymbol{\\epsilon}) = \\mathbf{v}_{1}^{\\top}\\boldsymbol{\\Sigma}\\mathbf{v}_{1} + 2\\mathbf{v}_{1}^{\\top}\\boldsymbol{\\Sigma}\\boldsymbol{\\epsilon} + O(\\|\\boldsymbol{\\epsilon}\\|_{2}^{2})$。\n- 由于 $\\boldsymbol{\\Sigma}$ 是对称的，$\\mathbf{v}_{1}^{\\top}\\boldsymbol{\\Sigma} = (\\boldsymbol{\\Sigma}\\mathbf{v}_{1})^{\\top} = \\lambda_{1}\\mathbf{v}_{1}^{\\top}$。该项变为 $\\lambda_{1} + 2\\lambda_{1}\\mathbf{v}_{1}^{\\top}\\boldsymbol{\\epsilon} + \\dots = \\lambda_{1}$，因为 $\\mathbf{v}_{1}^{\\top}\\boldsymbol{\\epsilon}=0$。\nODE 变为：\n$$\n\\frac{d\\boldsymbol{\\epsilon}}{dt} \\approx (\\lambda_{1}\\mathbf{v}_{1} + \\boldsymbol{\\Sigma}\\boldsymbol{\\epsilon}) - \\lambda_{1}(\\mathbf{v}_{1} + \\boldsymbol{\\epsilon}) = \\boldsymbol{\\Sigma}\\boldsymbol{\\epsilon} - \\lambda_{1}\\boldsymbol{\\epsilon} = (\\boldsymbol{\\Sigma} - \\lambda_{1}\\mathbf{I})\\boldsymbol{\\epsilon}\n$$\n这是扰动的线性化方程。由于 $\\boldsymbol{\\epsilon} \\perp \\mathbf{v}_{1}$，我们可以在其他特征向量的基中表示它：$\\boldsymbol{\\epsilon}(t) = \\sum_{i=2}^{d} c_{i}(t)\\mathbf{v}_{i}$。\n代入线性化的 ODE：\n$$\n\\sum_{i=2}^{d} \\frac{dc_{i}}{dt}\\mathbf{v}_{i} = (\\boldsymbol{\\Sigma} - \\lambda_{1}\\mathbf{I})\\sum_{i=2}^{d} c_{i}(t)\\mathbf{v}_{i} = \\sum_{i=2}^{d} c_{i}(t)(\\boldsymbol{\\Sigma}\\mathbf{v}_{i} - \\lambda_{1}\\mathbf{v}_{i}) = \\sum_{i=2}^{d} c_{i}(t)(\\lambda_{i} - \\lambda_{1})\\mathbf{v}_{i}\n$$\n通过比较每个特征向量的系数（由于正交性），我们得到一组关于分量 $c_{i}(t)$ 的解耦的一阶 ODE：\n$$\n\\frac{dc_{i}}{dt} = (\\lambda_{i} - \\lambda_{1})c_{i}(t) \\quad \\text{for } i = 2, 3, \\dots, d\n$$\n每个分量的解为 $c_{i}(t) = c_{i}(0)\\exp((\\lambda_{i} - \\lambda_{1})t)$。模式 $i$ 的衰减率是指数中的正常数，即 $-(\\lambda_{i} - \\lambda_{1}) = \\lambda_{1} - \\lambda_{i}$。\n渐近收敛率由最慢的衰减决定，这对应于最小的衰减率常数。这些率为 $\\{\\lambda_{1} - \\lambda_{2}, \\lambda_{1} - \\lambda_{3}, \\dots, \\lambda_{1} - \\lambda_{d}\\}$。\n给定排序 $\\lambda_{2} \\ge \\lambda_{3} \\ge \\cdots$，我们有 $-\\lambda_{2} \\le -\\lambda_{3} \\le \\cdots$。因此，$\\lambda_{1} - \\lambda_{2} \\le \\lambda_{1} - \\lambda_{3} \\le \\cdots$。\n与 $\\mathbf{v}_{1}$ 正交的扰动的最慢（最小）衰减率由第一和第二特征值之间的谱隙决定。该率为 $\\lambda_{1} - \\lambda_{2}$。",
            "answer": "$$\\boxed{\\lambda_{1} - \\lambda_{2}}$$"
        }
    ]
}