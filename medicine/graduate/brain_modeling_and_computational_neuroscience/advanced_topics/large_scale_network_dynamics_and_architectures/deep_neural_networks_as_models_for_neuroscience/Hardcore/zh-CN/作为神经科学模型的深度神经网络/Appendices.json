{
    "hands_on_practices": [
        {
            "introduction": "将深度神经网络（DNNs）作为神经科学的模型，一个最成功的例子是利用卷积神经网络（CNNs）来模拟大脑的腹侧视觉通路。这种类比的一个关键检验在于比较两者的量化属性，例如感受野的大小。本练习  将指导您从第一性原理出发，计算一个典型CNN中神经元的有效感受野，并将其与视觉皮层V4区域的神经生理学数据进行比较，从而让您亲手评估模型架构的生物学合理性。",
            "id": "3974364",
            "problem": "一个卷积神经网络（CNN）被用作层次化视觉处理的模型。考虑一个由三个二维卷积层组成的前馈堆栈，其卷积核为各向同性的方形核。第一层的核尺寸和步长为 $(k_1=7,s_1=2)$，第二层为 $(k_2=3,s_2=2)$，第三层为 $(k_3=3,s_3=2)$。假设没有扩张（dilation），并且如果存在零填充（zero-padding），它不会改变内部感受野的范围（即，填充不会增加能影响一个单元的真实输入像素的数量）。\n\n输入图像跨越一个视网膜拓扑的视野，大小为 $P=256$ 像素，对应 $20$ 度的视角，且为均匀采样，因此每个输入像素对应相同的视角。将沿单个空间维度（例如，水平轴）的感受野范围视为我们感兴趣的量；在各向同性的假设下，二维感受野在两个轴上具有相等的范围。\n\n从离散卷积的定义出发（即在每个输出位置，以步长 $s$ 线性组合 $k$ 个相邻输入的局部线性算子），使用第一性原理推导第三层中单个单元的有效感受野大小（以输入像素为单位）。然后，使用给定的映射关系，将此感受野大小从像素转换为视角（度）。\n\n将最终答案表示为第 $3$ 层单元所覆盖的视角，单位为度。请提供未经四舍五入的精确值。\n\n最后，在你的推理中讨论计算出的视角是否与视觉皮层V4区（V4）报告的感受野直径（在中等离心率下通常约为 $5$ 度）合理地一致，并根据计算和假设证明你的结论。",
            "solution": "该问题要求计算一个三层卷积神经网络（CNN）中第三层单元的有效感受野大小，并将其与来自视觉V4区的神经生理学数据进行比较。\n\n首先，我们必须建立感受野（RF）大小随卷积层层次结构增长的数学原理。设 $R_i$ 为第 $i$ 层中一个单元的有效感受野大小（沿一个维度），以输入层（第 $0$ 层）的像素为单位。设 $k_i$ 和 $s_i$ 分别为第 $i$ 层的核尺寸和步长。输入本身可被视为第 $0$ 层，其中每个单元（像素）的感受野大小为 $R_0 = 1$。\n\n第 $1$ 层中的一个单元是通过在输入层 $0$ 上进行核尺寸为 $k_1$ 的卷积计算得出的。因此，其感受野就是核的大小：\n$$R_1 = k_1$$\n\n现在，考虑第 $2$ 层中的一个单元。它是由第 $1$ 层输出中 $k_2$ 个单元的邻域计算得出的。这 $k_2$ 个第 $1$ 层的单元在它们自己的网格中是相邻的。由于第一层的步长为 $s_1$，第 $1$ 层中任意两个相邻单元的感受野中心在输入层 $0$ 中相距 $s_1$ 个像素。\n这 $k_2$ 个来自第 $1$ 层的单元所覆盖的总空间范围取决于它们中心的跨度加上单个感受野的大小。来自第 $1$ 层的 $k_2$ 个感受野的中心在输入层中跨越的距离为 $(k_2-1)s_1$ 像素。为了求得第 $2$ 层单元的总感受野大小，我们将单个第 $1$ 层单元的感受野大小 $R_1$ 加到这个跨度上。这覆盖了从第一个单元感受野的起点到最后一个单元感受野的终点的全部范围。因此，感受野大小的递归关系是：\n$$R_2 = R_1 + (k_2 - 1)s_1$$\n将其推广，第 $i$ 层中一个单元的有效感受野大小 $R_i$ 由其相对于第 $i-1$ 层的感受野大小 $R_{i-1}$，加上由 $k_i$ 个核覆盖的额外范围给出，这些核的中心被之前所有层的累积步长所分隔。投射回输入层的第 $i-1$ 层相邻单元之间的步长是所有先前步长的乘积，即 $\\prod_{j=1}^{i-1} s_j$。递归公式为：\n$$R_i = R_{i-1} + (k_i - 1) \\prod_{j=1}^{i-1} s_j$$\n\n给定一个三层网络的以下参数：\n- 第 1 层：$k_1 = 7$, $s_1 = 2$\n- 第 2 层：$k_2 = 3$, $s_2 = 2$\n- 第 3 层：$k_3 = 3$, $s_3 = 2$\n\n我们现在可以逐步计算感受野的大小。\n基础情况是输入层中的单个像素：\n$$R_0 = 1$$\n对于第 $1$ 层中的一个单元：\n$$R_1 = R_0 + (k_1 - 1) \\prod_{j=1}^{0} s_j = R_0 + (k_1 - 1) \\times 1 = 1 + (7 - 1) = 7 \\text{ 像素}$$\n这是符合的，因为第一层的核直接观察 $7$ 个输入像素。\n\n对于第 $2$ 层中的一个单元：\n$$R_2 = R_1 + (k_2 - 1) \\prod_{j=1}^{1} s_j = R_1 + (k_2 - 1)s_1$$\n$$R_2 = 7 + (3 - 1) \\times 2 = 7 + 2 \\times 2 = 11 \\text{ 像素}$$\n\n对于第 $3$ 层中的一个单元：\n$$R_3 = R_2 + (k_3 - 1) \\prod_{j=1}^{2} s_j = R_2 + (k_3 - 1)s_1 s_2$$\n$$R_3 = 11 + (3 - 1) \\times (2 \\times 2) = 11 + 2 \\times 4 = 11 + 8 = 19 \\text{ 像素}$$\n所以，第三层中单个单元的有效感受野跨越了输入图像的 $19$ 个像素。\n\n接下来，我们将这个大小从像素转换为视角（度）。输入图像的大小为 $P = 256$ 像素，对应 $20$ 度的视野。采样是均匀的，因此转换因子在整个视野中是恒定的。\n每个像素的视角是：\n$$\\frac{20 \\text{ 度}}{256 \\text{ 像素}}$$\n以度为单位的感受野大小，我们记为 $\\theta_{RF}$，是像素大小乘以这个转换因子：\n$$\\theta_{RF} = R_3 \\times \\frac{20}{256} = 19 \\times \\frac{20}{256} = \\frac{380}{256}$$\n为了将其表示为最简的精确分数，我们找到分子和分母的最大公约数。两者都可以被 $4$ 整除：\n$$380 \\div 4 = 95$$\n$$256 \\div 4 = 64$$\n所以，精确的视角是：\n$$\\theta_{RF} = \\frac{95}{64} \\text{ 度}$$\n\n最后，问题要求讨论这个值是否与视觉皮层V4区报告的感受野直径（通常约为 $5$ 度）合理地一致。\n计算出的值为 $\\frac{95}{64} \\approx 1.48$ 度。这个值远小于在中等离心率下为V4感受野报告的典型值 $5$ 度。\n\n基于此计算，指定的三层CNN在实现类似V4的感受野大小方面不是一个定量准确的模型。这种差异表明，该模型过于简单，或者其参数过于保守，无法捕捉到腹侧视觉通路直至V4区的完整空间整合特性。有几个因素可以解释这种差异：\n1.  **网络深度**：生物视觉层级（例如，视网膜 -> LGN -> V1 -> V2 -> V4）涉及的处理阶段比该模型中的三层要多。更深的网络会更大程度地复合感受野，从而导致最终的感受野尺寸更大。\n2.  **池化层**：该模型仅使用带步长的卷积。模拟视觉系统的架构通常包括池化层（例如，最大池化），这也会在每一步增加有效感受野的大小，其增加幅度通常比卷积层内步长为 $2$ 更为激进。\n3.  **扩张（Dilation）**：该模型假设没有扩张。扩张（或atrous）卷积是一种在不增加参数数量的情况下增大大感受野的机制。这是一个合理的生物学机制，也是现代为大规模空间理解而设计的CNN中的一个共同特征。\n4.  **模型参数**：核尺寸和步长可能太小。更大的值，特别是早期层中的步长，会导致感受野增长得更快。\n5.  **离心率依赖性**：$5$ 度的比较值是针对“中等离心率”的。V4感受野在中央凹附近较小。我们对CNN中通用单元的计算可能更能代表旁中央凹的V4神经元，而不是中等离心率下的神经元。然而，即使对于中央凹的V4，$1.48$ 度也偏小。\n6.  **非前馈机制**：生物皮层包含广泛的侧向和反馈连接，这些连接可以动态地调节感受野属性，而这个简单的、严格前馈的模型没有捕捉到这些机制。\n\n总之，虽然该模型正确地实现了分层特征和感受野构建的原理，但它太浅了，无法产生与皮层V4区相当的感受野大小。",
            "answer": "$$\\boxed{\\frac{95}{64}}$$"
        },
        {
            "introduction": "大脑的许多功能，如工作记忆和方向追踪，都依赖于神经活动的持续状态，这是由循环连接的神经回路实现的。环形吸引子网络是解释神经连接如何产生稳定活动“凸起”（activity bump）以表征连续变量（如头部朝向）的经典模型。本练习  将带您深入分析这种网络的设计与稳定性，揭示网络的动态特性是如何从突触权重结构中涌现的，这对于理解神经回路如何维持和处理信息至关重要。",
            "id": "3974360",
            "problem": "考虑一个环形吸引子循环神经网络，该网络用$N \\geq 5$个神经元来模拟一个一维环形变量（例如，头部方向）。这些神经元由单位圆上的偏好角度 $\\theta_i \\in \\{0, \\frac{2\\pi}{N}, \\ldots, \\frac{2\\pi(N-1)}{N}\\}$ 进行索引。循环权重矩阵在环上是平移不变的，定义为\n$$\nW_{ij} \\;=\\; w_0 \\;+\\; w_1 \\cos\\!\\big(\\theta_i - \\theta_j\\big),\n$$\n其中 $w_0 \\in \\mathbb{R}$ 和 $w_1 \\in \\mathbb{R}$ 是常数。神经元发放率 $r_i(t)$ 遵循一个标准发放率模型\n$$\n\\tau \\frac{d r_i}{dt} \\;=\\; -\\,r_i \\;+\\; \\phi\\!\\Big(g \\sum_{j=1}^{N} W_{ij}\\, r_j \\;+\\; I\\Big),\n$$\n其中 $\\tau > 0$ 是膜时间常数，$g > 0$ 是全局突触增益，$I \\in \\mathbb{R}$ 是一个恒定的外部驱动，$\\phi(\\cdot)$ 是一个光滑的单调递增激活函数。假设存在一个对所有 $i$ 都成立的均匀不动点 $r_i(t) = \\bar{r}$，满足 $\\bar{r} = \\phi\\!\\big(g \\sum_j W_{ij}\\, \\bar{r} + I\\big)$，并定义在工作点处的局部斜率为 $\\alpha := \\phi'(u)$，其中 $u := g \\sum_j W_{ij}\\, \\bar{r} + I$。\n\n从线性和环上对称性的第一性原理出发，分析围绕均匀不动点的无穷小扰动 $\\delta r_i(t)$，并使用离散傅里葉基对线性化动力学进行对角化。然后：\n\n1. 在环上的离散傅里叶基中，推导权重矩阵 $W$ 的本征模和本征值。\n2. 利用线性化动力学，确定当增益 $g$ 增加时，哪个傅里叶模态首先变得不稳定，并找出第一个非平凡空间（形成“凸起”的）模态在均匀（零波数）模态之前失稳的 $w_0$ 和 $w_1$ 所需满足的条件。\n3. 在该条件下，计算第一个空间傅里叶模态失稳时的临界增益 $g^{\\star}$，用 $N$、$w_1$ 和 $\\alpha$ 的闭合形式表达式表示。将此 $g^{\\star}$作为你的最终答案。\n\n将你的最终答案表示为单个闭合形式的解析表达式。不要在最终答案框中包含单位、不等式或附加条件。",
            "solution": "该问题在计算神经科学的标准理论框架内得到了很好的阐述，并具有科学依据。我们可以进行形式化的求解。\n\n按照要求，解答分为三个部分：首先，我们确定权重矩阵 $W$ 的本征值；其次，我们分析均匀状态的稳定性，并找出空间不稳定性出现的条件；第三，我们计算这种不稳定性发生时的临界增益 $g^{\\star}$。\n\n**1. 权重矩阵 $W$ 的本征模和本征值**\n\n循环权重矩阵由 $W_{ij} = w_0 + w_1 \\cos(\\theta_i - \\theta_j)$ 给出。神经元索引为 $i,j \\in \\{1, \\dots, N\\}$，偏好角度为 $\\theta_i = \\frac{2\\pi(i-1)}{N}$。项 $\\theta_i - \\theta_j$ 可以写成 $\\frac{2\\pi(i-j)}{N}$。由于 $W_{ij}$ 仅取决于差值 $(i-j) \\pmod N$，矩阵 $W$ 是一个循环矩阵。\n\n任何 $N \\times N$ 循环矩阵的本征向量都是离散傅里叶模。对于波数 $k \\in \\{0, 1, \\ldots, N-1\\}$，第 $k$ 个未归一化的本征向量是一个矢量 $\\mathbf{v}^{(k)}$，其分量为 $v_j^{(k)} = \\exp(i \\theta_j k) = \\exp\\left(i \\frac{2\\pi(j-1)k}{N}\\right)$。\n\n相应的本征值 $\\lambda_k$ 可以通过将矩阵 $W$ 应用于其本征向量 $\\mathbf{v}^{(k)}$ 来找到：\n$$ (\\mathbf{W}\\mathbf{v}^{(k)})_i = \\sum_{j=1}^{N} W_{ij} v_j^{(k)} = \\sum_{j=1}^{N} \\left(w_0 + w_1 \\cos(\\theta_i - \\theta_j)\\right) \\exp(i \\theta_j k) $$\n我们可以提出因子 $\\exp(i\\theta_i k)$，并令求和索引为 $m=i-j$：\n$$ (\\mathbf{W}\\mathbf{v}^{(k)})_i = \\exp(i\\theta_i k) \\sum_{j=1}^{N} \\left(w_0 + w_1 \\cos(\\theta_i - \\theta_j)\\right) \\exp(i(\\theta_j - \\theta_i)k) $$\n$$ = v_i^{(k)} \\sum_{m=i-N}^{i-1} \\left(w_0 + w_1 \\cos\\left(\\frac{2\\pi m}{N}\\right)\\right) \\exp\\left(-i\\frac{2\\pi m k}{N}\\right) $$\n由于和中的项关于 $m$ 是周期为 $N$ 的，我们可以在任何 $N$ 个连续整数上求和，例如 $m \\in \\{0, 1, \\ldots, N-1\\}$。因此，本征值 $\\lambda_k$ 由下式给出：\n$$ \\lambda_k = \\sum_{m=0}^{N-1} \\left(w_0 + w_1 \\cos\\left(\\frac{2\\pi m}{N}\\right)\\right) \\exp\\left(-i\\frac{2\\pi m k}{N}\\right) $$\n我们将这个和分成两部分：\n$$ \\lambda_k = w_0 \\sum_{m=0}^{N-1} \\exp\\left(-i\\frac{2\\pi m k}{N}\\right) + w_1 \\sum_{m=0}^{N-1} \\cos\\left(\\frac{2\\pi m}{N}\\right) \\exp\\left(-i\\frac{2\\pi m k}{N}\\right) $$\n第一个和是一个几何级数，当 $k=0 \\pmod N$ 时等于 $N$，否则等于 $0$。使用克罗内克δ函数，此项为 $N w_0 \\delta_{k,0}$。\n\n对于第二个和，我们使用欧拉公式表示余弦, $\\cos(x) = \\frac{1}{2}(\\exp(ix) + \\exp(-ix))$：\n$$ w_1 \\sum_{m=0}^{N-1} \\frac{1}{2}\\left(\\exp\\left(i\\frac{2\\pi m}{N}\\right) + \\exp\\left(-i\\frac{2\\pi m}{N}\\right)\\right) \\exp\\left(-i\\frac2\\pi m k}{N}\\right) $$\n$$ = \\frac{w_1}{2} \\sum_{m=0}^{N-1} \\left(\\exp\\left(-i\\frac{2\\pi m (k-1)}{N}\\right) + \\exp\\left(-i\\frac{2\\pi m (k+1)}{N}\\right)\\right) $$\n这个和仅在 $k-1=0 \\pmod N$（即 $k=1$）或 $k+1=0 \\pmod N$（即 $k=N-1$）时非零。\n对于 $k=1$，括号中的第一项和为 $N$，第二项和为 $0$（因为 $N \\ge 5$, $k+1=2 \\not\\equiv 0 \\pmod N$）。\n对于 $k=N-1$，第二项和为 $N$，第一项和为 $0$（因为 $k-1=N-2 \\not\\equiv 0 \\pmod N$）。\n综合这些结果，$W$ 的本征值为：\n- 对于 $k=0$：$\\lambda_0 = N w_0$。\n- 对于 $k=1$：$\\lambda_1 = \\frac{N w_1}{2}$。\n- 对于 $k=N-1$：$\\lambda_{N-1} = \\frac{N w_1}{2}$。\n- 对于 $k \\in \\{2, 3, \\ldots, N-2\\}$：$\\lambda_k = 0$。\n\n本征模是离散傅里叶基向量 $\\mathbf{v}^{(k)}$。\n\n**2. 线性化与稳定性分析**\n\n我们在均匀不动点 $r_i(t) = \\bar{r}$ 附近对动力学方程 $\\tau \\frac{dr_i}{dt} = -r_i + \\phi(g \\sum_{j} W_{ij} r_j + I)$ 进行线性化。令 $r_i(t) = \\bar{r} + \\delta r_i(t)$，其中 $\\delta r_i(t)$ 是一个无穷小扰动。\n激活函数的自变量为 $u_i = g \\sum_j W_{ij} r_j + I$。在不动点处，该自变量为 $u = g \\sum_j W_{ij} \\bar{r} + I = g \\bar{r} (N w_0) + I$，它与 $i$ 无关。\n扰动的线性化动力学方程为：\n$$ \\tau \\frac{d\\delta r_i}{dt} = -\\delta r_i + \\left. \\frac{\\partial \\phi}{\\partial u_i} \\right|_{u} \\left(g \\sum_{j} W_{ij} \\delta r_j\\right) $$\n使用给定的定义 $\\alpha = \\phi'(u)$，方程变为：\n$$ \\tau \\frac{d\\delta r_i}{dt} = -\\delta r_i + \\alpha g \\sum_{j=1}^{N} W_{ij} \\delta r_j $$\n以向量形式表示，令 $\\delta\\mathbf{r} = (\\delta r_1, \\ldots, \\delta r_N)^T$，方程为：\n$$ \\tau \\frac{d\\delta\\mathbf{r}}{dt} = (-I_N + \\alpha g W) \\delta\\mathbf{r} $$\n其中 $I_N$ 是单位矩阵。不动点的稳定性由雅可比矩阵 $J = \\frac{1}{\\tau}(-I_N + \\alpha g W)$ 的本征值决定。$J$ 的本征值，记为 $\\mu_k$，与 $W$ 的本征值 $\\lambda_k$ 的关系为：\n$$ \\mu_k = \\frac{1}{\\tau}(-1 + \\alpha g \\lambda_k) $$\n当任意本征值 $\\mu_k$ 的实部变为正时，均匀不动点变得不稳定。由于 $\\alpha > 0$ 且 $g > 0$，不稳定性在某个 $k$ 满足 $-1 + \\alpha g \\lambda_k > 0$ 时发生，这意味着 $\\alpha g \\lambda_k > 1$。这要求 $\\lambda_k > 0$。当 $g$ 从 $0$ 开始增加时，具有最大正本征值 $\\lambda_k$ 的模态 $k$ 将首先失稳。\n\n非平凡空间（形成“凸起”的）模态对应于 $k=1$（以及 $k=N-1$）。均匀模态对应于 $k=0$。其他模态（$k \\in \\{2, ..., N-2\\}$）的 $\\lambda_k=0$，因此它们总是稳定的，其 $\\mu_k = -1/\\tau$。\n为了使空间模态在均匀模态之前失稳，其对应的本征值必须为正，并且大于均匀模态的本征值。也就是说，我们需要 $\\lambda_1 > 0$ 且 $\\lambda_1 > \\lambda_0$。\n1.  $\\lambda_1 > 0 \\implies \\frac{N w_1}{2} > 0 \\implies w_1 > 0$。\n2.  $\\lambda_1 > \\lambda_0 \\implies \\frac{N w_1}{2} > N w_0 \\implies w_1 > 2 w_0$。\n\n因此，第一个空间模态首先失稳的条件是 $w_1 > 0$ 且 $w_1 > 2w_0$。\n\n**3. 临界增益 $g^{\\star}$**\n\n在上述条件下，随着 $g$ 的增加，首先发生的不稳定性是对应于空间模态 $k=1$ 的图灵型分岔。临界增益 $g^{\\star}$ 是指本征值 $\\mu_1$ 的实部穿过零时的 $g$ 值。\n$$ \\text{Re}(\\mu_1) = \\frac{1}{\\tau}(-1 + \\alpha g^{\\star} \\lambda_1) = 0 $$\n$$ \\implies 1 = \\alpha g^{\\star} \\lambda_1 $$\n解出 $g^{\\star}$，我们得到：\n$$ g^{\\star} = \\frac{1}{\\alpha \\lambda_1} $$\n代入 $\\lambda_1 = \\frac{N w_1}{2}$ 的表达式：\n$$ g^{\\star} = \\frac{1}{\\alpha \\left(\\frac{N w_1}{2}\\right)} = \\frac{2}{N \\alpha w_1} $$\n这是均匀状态失稳并转变为空间模式态（一个“凸起”）的临界增益。该表达式用指定的参数 $N$、$w_1$ 和 $\\alpha$ 表示。",
            "answer": "$$\n\\boxed{\\frac{2}{N \\alpha w_1}}\n$$"
        }
    ]
}