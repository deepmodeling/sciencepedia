## 引言
近年来，[深度神经网络](@entry_id:636170)（DNNs）在人工智能领域取得了革命性突破，其强大的模式识别和生成能力不禁让我们思考一个根本性问题：这些人工系统在多大程度上能够作为理解我们自身大脑的模型？将DNNs作为一种“理论透镜”来研究神经科学，已成为连接人工智能与大脑科学两个领域最有前景的交叉点之一。然而，这种类比的有效性取决于我们能否在浮于表面的相似性之下，建立起严谨的、可检验的机制性联系。本文旨在弥合这一知识鸿沟，系统性地梳理将DNNs作为[神经科学模型](@entry_id:1128668)的理论基础、核心机制及其广泛应用。

为了构建一个全面的理解框架，本文将分为三个核心部分。在“原理与机制”一章中，我们将深入探讨构成现代DNNs的核心计算原理——从单个神经元的抽象，到网络学习表征的理论，再到关键架构（如卷积、循环、归一化和注意力）的神经科学类比，并审视信用分配等学习难题。接下来，在“应用与跨学科连接”一章中，我们将展示这些原理如何被用于模拟从[感觉处理](@entry_id:906172)到[工作记忆](@entry_id:894267)的复杂认知功能，如何催生分析高维神经数据的新方法，以及如何为神经与精神疾病提供系统层面的解释。最后，在“动手实践”部分，读者将有机会通过具体的计算练习，亲手实现和分析这些模型，从而将理论知识转化为实践技能。通过这一系列的探索，我们旨在揭示DNNs不仅是模拟大脑的工具，更是一种能够激发新假设、指导实验并推动神经科学向前发展的[通用计算](@entry_id:275847)语言。

## 原理与机制

本章旨在深入探讨将深度神经网络（DNNs）作为大脑功能模型的背后核心原理与机制。我们将从单个神经元的计算抽象开始，逐步扩展到网络如何学习有意义的表征，再到构成现代深度学习模型的关键结构组件及其在神经科学中的对应概念。最后，我们将审视网络层面的学习、推理和适应性问题，从而为理解大脑计算与人工智能之间的深刻联系奠定坚实的基础。

### 从生物神经元到人工单元：速率编码的抽象

将深度网络与大脑联系起来的起点，是将生物神经元的复杂动态行为抽象为可计算的人工单元。一个经典的例子是**[漏积分放电](@entry_id:261896)（Leaky Integrate-and-Fire, LIF）模型**，这是一种广泛使用的尖峰神经元模型。

在[LIF模型](@entry_id:1127214)中，[神经元膜电位](@entry_id:191007) $v(t)$ 的动态由以下常微分方程描述：
$$ \tau \frac{dv(t)}{dt} = -v(t) + R I(t) $$
其中，$\tau$ 是膜时间常数，$R$ 是膜电阻，$I(t)$ 是总突触输入电流。当 $v(t)$ 达到一个阈值 $v_{\text{th}}$ 时，神经元会发放一个**[动作电位](@entry_id:138506)（尖峰）**，随后其膜电位被重置为 $v_{\text{r}}$，并经历一段[不应期](@entry_id:152190) $\tau_{\text{ref}}$。

为了将这种基于尖峰的动态模型与标准DNN中使用的静态[激活函数](@entry_id:141784)联系起来，我们可以推导其在[稳态](@entry_id:139253)下的**发放率（firing rate）**，即著名的**[f-I曲线](@entry_id:268989)**。假设输入电流 $I$ 恒定且足以使神经元发放尖峰（即 $RI > v_{\text{th}}$），我们可以求解上述[微分](@entry_id:158422)方程，计算出膜电位从 $v_{\text{r}}$ 上升到 $v_{\text{th}}$ 所需的时间。这个时间，加上[不应期](@entry_id:152190)，构成了**峰间期（inter-spike interval, ISI）**。发放率即为峰间期的倒数。经过推导，我们得到[LIF神经元](@entry_id:1127215)的[稳态](@entry_id:139253)发放率 $r(I)$ 为 ：
$$ r(I) = \begin{cases} \left( \tau_{\text{ref}} + \tau \ln\left(\frac{R I - v_{\text{r}}}{R I - v_{\text{th}}}\right) \right)^{-1}  \text{若 } R I > v_{\text{th}} \\ 0  \text{若 } R I \le v_{\text{th}} \end{cases} $$
这个 $r(I)$ 函数将一个连续的输入值 $I$ 映射到一个输出率，其形式类似于DNN中的**激活函数**，例如[ReLU函数](@entry_id:273016)（因为它有一个阈值）。这表明，一个由[LIF神经元](@entry_id:1127215)组成的尖峰网络，在输入变化缓慢（慢于膜时间常数 $\tau$）且噪声较低的“速率编码”机制下，其层级平均活动或许可以被一个使用相应[f-I曲线](@entry_id:268989)作为[激活函数](@entry_id:141784)的深度速率网络（即标准DNN）所近似 。

然而，这种近似有其局限性。当输入电流存在显著波动或噪声时，神经元的发放行为会变得随机。在这种“噪声驱动”或“波动驱动”的机制下，即使平均输入低于阈值，随机波动也可能暂时将膜电位推过阈值，产生尖峰。此时，发放率将不仅依赖于输入的均值，还依赖于其方差。一个仅使用确定性[f-I曲线](@entry_id:268989)的速率网络将无法捕捉到这种由噪声引发的活动，从而系统性地低估神经元的响应 。此外，在具有复杂时间动态（如 recurrent networks）的系统中，忽略突触和膜的滤波效应的纯静态速率模型，也常常无法准确预测系统的[瞬态响应](@entry_id:165150)和稳定性 。尽[管存](@entry_id:1127299)在这些局限，从[LIF模型](@entry_id:1127214)到速率模型的抽象，为使用DNNs作为大脑宏观计算原理的“隐喻”或“模型”提供了理论依据。

### 表征学习的原理

神经网络的核心功能之一是从感觉输入中学习有意义的内部表征。大脑是如何在没有明确监督信号的情况下发展出这些高效的[神经编码](@entry_id:263658)的？[计算神经科学](@entry_id:274500)和机器学习提供了几个关键的理论视角。

#### [无监督特征学习](@entry_id:922380)：从[赫布可塑性](@entry_id:276660)到[主成分分析](@entry_id:145395)

神经科学中最古老的[学习理论](@entry_id:634752)之一是**[赫布学习](@entry_id:156080)（Hebbian learning）**，其核心思想是“一起发放的神经元，连接会更紧密”。对于一个接收输入向量 $x$ 并产生输出 $y = w^\top x$ 的线性神经元，最简单的[赫布可塑性](@entry_id:276660)规则可以表示为权重更新与突触前后活动的乘积成正比：
$$ \Delta w \propto x y $$
在期望意义下，这个学习规则的动态可以由一个[常微分方程](@entry_id:147024)描述：$\frac{dw}{dt} = Cw$，其中 $C = \mathbb{E}[xx^\top]$ 是输入的[协方差矩阵](@entry_id:139155)。这个系统的解表明，权重向量 $w$ 的方向会逐渐对齐到输入[数据协方差](@entry_id:748192)矩阵的最大[特征向量](@entry_id:151813)上，也就是数据的**第一主成分（Principal Component, PC1）**。然而，这个简单的规则存在一个致命缺陷：权重的大小（即 $\|w\|$）会无限制地增长，这在生物学上是不现实的 。

为了解决这个问题，需要引入某种形式的归一化或稳定性机制。**Oja规则**就是一种优雅的解决方案，它在赫布项的基础上增加了一个与输出活动平方成比例的[权重衰减](@entry_id:635934)项：
$$ \Delta w \propto x y - y^2 w $$
其期望动态为 $\frac{dw}{dt} = Cw - (w^\top C w)w$。这个额外的项有效地对权重向量的长度进行归一化，使其收敛到单位长度（$\|w\| \to 1$）。与简单的赫布规则一样，Oja规则下的权重向量方向也会收敛到数据的第一主成分。因此，Oja规则提供了一个生物学上更合理的局部学习机制，该机制能够执行**[主成分分析](@entry_id:145395)（PCA）**——一种基础的[无监督学习](@entry_id:160566)算法，旨在找到数据中方差最大的方向 。这表明，简单的、局部的[突触可塑性](@entry_id:137631)规则可以实现强大的[统计计算](@entry_id:637594)。

#### [高效编码](@entry_id:1124203)、[稀疏性](@entry_id:136793)与自然图像统计

PCA关注的是数据的[二阶统计量](@entry_id:919429)（协方差）。然而，大脑处理的自然信号（如图像、声音）具有比高斯分布复杂得多的高阶统计结构。例如，自然图像的[功率谱](@entry_id:159996)通常服从 $S(\mathbf{k}) \propto \|\mathbf{k}\|^{-2}$ 的[幂律分布](@entry_id:262105)，但其最显著的特征是局部化的边缘和轮廓，这些特征是稀疏存在的。

如果一个线性模型只考虑[二阶统计量](@entry_id:919429)（如PCA），它学到的[最优基](@entry_id:752971)函数将是傅里叶模式（全局的正弦波），因为它们是[平稳过程](@entry_id:196130)中协方差算子的特征函数 。然而，这与在灵长类动物[初级视皮层](@entry_id:908756)（V1）中观察到的、对特定方向和空间频率敏感的局部化感受野（常被**[Gabor函数](@entry_id:1125442)**所模拟）不符。

为了解释Gabor[感受野](@entry_id:636171)的出现，我们需要超越二阶统计。**稀疏编码（Sparse Coding）**理论提出，一个好的表征应该使得对于任何给定的输入，只有少数神经元是活跃的。当将稀疏编码模型应用于自然图像块时，学到的基函数（或说滤波器）确实是局部化的、定向的、带通的，与V1神经元的[感受野](@entry_id:636171)和[Gabor函数](@entry_id:1125442)非常相似。这是因为能够匹配图像中稀疏边缘的滤波器，其响应分布会是高度峰化的（大部分时间为零）并带有重尾（偶尔有大的响应），即所谓的超高斯或稀疏分布 。**独立成分分析（Independent Component Analysis, ICA）**是另一种旨在发现数据中统计独立来源的[无监督学习](@entry_id:160566)算法，当应用于自然图像时，它也能得到类似Gabor的滤波器。

这一理论与[深度学习](@entry_id:142022)的观察结果惊人地一致：在大型自然图像数据集上训练的**[卷积神经网络](@entry_id:178973)（Convolutional Neural Networks, CNNs）**的第一层，其学到的滤波器也常常类似于[Gabor函数](@entry_id:1125442)。这并非巧合，而是CNN的架构（如小的、局部的[卷积核](@entry_id:1123051)）和学习目标共同作用的结果，推动网络去发现与自然图像高阶统计结构相匹配的有效特征 。

#### 效率编码的规范化理论：[信息瓶颈](@entry_id:263638)

我们可以用信息论的语言来更精确地定义“[高效编码](@entry_id:1124203)”的含义。经典的**[率失真理论](@entry_id:138593)（Rate-Distortion, RD）**旨在以最低的“[码率](@entry_id:176461)”（用互信息 $I(X;T)$ 衡量，其中 $X$ 是输入， $T$ 是表征）来表征一个信号，同时将“失真”（用期望失真 $\mathbb{E}[d(X,T)]$ 衡量）控制在一定水平之下。其[目标函数](@entry_id:267263)可以写作一个拉格朗日量：$\min I(X;T) + \beta \mathbb{E}[d(X,T)]$ 。RD理论为忠实地压缩感官输入提供了数学框架。

然而，大脑的表征可能不仅仅是为了忠实地重建输入，更是为了服务于特定的行为任务。**[信息瓶颈](@entry_id:263638)（Information Bottleneck, IB）**理论将这一思想形式化。它假设存在一个与任务相关的变量 $Y$，并寻求一个既能最大程度地压缩输入 $X$（即最小化 $I(X;T)$），又能最大程度地保留关于 $Y$ 的信息（即最大化 $I(T;Y)$）的中间表征 $T$。这是一个权衡问题，其[拉格朗日形式](@entry_id:145697)为：
$$ \min_{p(t|x)} I(X;T) - \beta I(T;Y) $$
这里的 $\beta$ 是一个[拉格朗日乘子](@entry_id:142696)，它控制着压缩与保留任务相关信息之间的权衡。当 $\beta$ 较小时，模型更注重压缩；当 $\beta$ 较大时，模型更注重保留与 $Y$ 相关的信息。

IB理论与RD理论有一个深刻的联系：IB可以被看作是一种特殊的RD，其[失真函数](@entry_id:271986) $d(x,t)$ 被定义为一种“语义失真”，即由于用 $T$ 替代 $X$ 而导致的关于 $Y$ 的信息损失。具体来说，如果失真被定义为[条件概率分布](@entry_id:163069) $p(y|x)$ 和 $p(y|t)$ 之间的KL散度，那么期望失真就等于 $I(X;Y) - I(T;Y)$。因此，IB理论为“学习与任务相关的有效特征”这一目标提供了规范化的信息论基础，超越了RD理论中简单的保真度压缩 。

### 核心架构机制及其神经科学类比

现代[深度神经网络](@entry_id:636170)的成功在很大程度上归功于其独特的架构设计。这些设计中的许多都与大脑皮层的组织原则有着惊人的相似之处。

#### 卷积、[等变性](@entry_id:636671)与[不变性](@entry_id:140168)

CNN的核心操作是**卷积**。一个关键特性是，当对输入信号应用平移操作时，卷积层的输出也会相应地平移，这一性质被称为**[平移等变性](@entry_id:636340)（translation equivariance）** 。形式上，如果 $r(x)$ 是卷积操作， $T_\delta$ 是平移算子，那么 $r(T_\delta x) = T'_\delta r(x)$，其中 $T'_\delta$ 是在[特征图](@entry_id:637719)上的相应平移操作。这种性质非常适合处理像图像这样的数据，因为物体无论出现在视野的哪个位置，其基本特征都应被同样地检测出来。在卷积之后应用的逐点[非线性](@entry_id:637147)操作（如ReLU）会保持这种[等变性](@entry_id:636671) 。

然而，一个鲁棒的识别系统通常需要**[平移不变性](@entry_id:195885)（translation invariance）**，即无论物体如何平移，最终的表征都保持不变。CNN通过在卷积层之后引入**池化（pooling）**操作来逐步建立这种[不变性](@entry_id:140168)。例如，[最大池化](@entry_id:636121)或[平均池化](@entry_id:635263)会对[特征图](@entry_id:637719)的一个局部区域进行聚合。虽然局部池化不能保证完全的[平移不变性](@entry_id:195885)，但它对小的、不越过池化窗口边界的平移提供了近似的不变性 。只有当池化操作作用于整个[特征图](@entry_id:637719)时（全局池化），才能实现严格的[平移不变性](@entry_id:195885) 。CNN中交替进行的[卷积和](@entry_id:263238)池化操作，构建了一个从简单的、位置敏感的特征到复杂的、位置不敏感的物体表征的层级结构，这与灵长类动物视觉[腹侧通路](@entry_id:912563)的功能组织非常相似。值得注意的是，在实际的有限尺寸网络中，由于边界填充（padding）效应，完美的[等变性](@entry_id:636671)通常只在远离边界的区域成立 。

#### 归一化即增益控制

神经元和神经网络都需要机制来控制其活动的动态范围，防止信号饱和或消失。这一过程被称为**增益控制（gain control）**。在[感觉系统](@entry_id:1131482)中，一个被广泛研究的规范计算是**[除法归一化](@entry_id:894527)（Divisive Normalization, DN）**。在该模型中，一个神经元的响应 $r_i$ 由其驱动输入 $z_i$ 除以一个包含[半饱和常数](@entry_id:1125887) $\sigma$ 和其邻近神经元活动加权和的项得到：
$$ r_i = \frac{z_i}{\sigma + \sum_j w_{ij} z_j} $$
这个机制能够实现**对比度增益控制**：在低对比度（小 $z$）时，响应近似[线性增长](@entry_id:157553)；在高对比度（大 $z$）时，分母中的 $z_j$ 项占主导，使得响应饱和，从而对输入的整体强度变化保持相对不敏感 。

在深度学习中，**[批量归一化](@entry_id:634986)（Batch Normalization, BN）**是一种广泛用于稳定和加速训练的技术。对于一个小批量（mini-batch）中的每个样本，BN通过减去该特征在整个批次中的均值 $\mu$ 并除以其标准差 $\sigma$ 来对每个特征的激活值进行归一化：
$$ r_i = \frac{z_i - \mu}{\sqrt{\sigma^2 + \epsilon}} $$
尽管DN和BN都实现了某种形式的增益控制，但它们的计算范畴截然不同。DN是在**单个样本内部**，跨越一个**神经元群体**进行归一化，这在生物学上可以通过侧向抑制等局部回路来实现。而BN是在**单个特征维度上**，跨越一个**样本批次**进行归一化。这种跨样本的计算使得BN的直接生物学对应性很低，它更多被视为一种有效的工程解决方案，而非大脑计算的模型 。理解这种差异对于区分DNN中的生物学启发性原理和纯粹的工程技巧至关重要 。

#### 循环与时间处理

大脑的功能本质上是动态的，处理的是随时间演变的信息。**[循环神经网络](@entry_id:634803)（Recurrent Neural Networks, RNNs）**通过在神经元之间引入循环连接来捕捉时间依赖性。其核心是一个更新[隐藏状态](@entry_id:634361) $h_t$ 的[递推公式](@entry_id:149465)：
$$ h_t = \phi(W_h h_{t-1} + W_x x_t + b) $$
与[前馈网络](@entry_id:1124893)不同，RNN的当前状态 $h_t$ 显式地依赖于其前一时刻的状态 $h_{t-1}$，这使得信息可以在网络中随时间流动，形成一种“记忆” 。隐藏状态的维度 $n_h$ 至关重要，它决定了网络可以表征的潜在动态模式的丰富程度。从动力学系统角度看，$n_h$ 越大，循环权重矩阵 $W_h$ 的特征谱就越丰富，从而能够学习和混合更多具有不同时间尺度的动态模式 。

然而，简单的RNN在学习[长期依赖](@entry_id:637847)关系时会遇到**梯度消失或爆炸**的问题。**[长短期记忆](@entry_id:637886)（Long Short-Term Memory, [LSTM](@entry_id:635790)）**和**[门控循环单元](@entry_id:1125510)（Gated Recurrent Unit, GRU）**等门控RNN架构通过引入乘法[门控机制](@entry_id:152433)来解决这一问题。这些门（如[遗忘门](@entry_id:637423)、输入门）可以学会动态地控制信息的流动，决定何时遗忘旧信息、何时写入新信息。这种设计使得梯度能够通过一个近似线性的“细胞状态”通路在许[多时间步](@entry_id:752313)长上传播而不衰减，从而使网络能够有效地学习和利用跨越很长时间间隔的信息，这对于建模具有复杂[长期依赖](@entry_id:637847)的神经生理信号至关重要 。

#### [注意力机制](@entry_id:917648)

大脑能够从海量感官信息中选择性地关注与当前任务相关的部分。**特征注意力（feature-based attention）**模型提出，注意力通过乘法性地调制神经元的增益来实现：当一个神经元偏好的特征被关注时，其对所有输入的响应都会被放大。

近年来，[深度学习](@entry_id:142022)领域的**[注意力机制](@entry_id:917648)**，特别是[Transformer架构](@entry_id:635198)中的**缩放点积[自注意力](@entry_id:635960)（scaled dot-product self-attention）**，为这一认知功能提供了强大的[计算模型](@entry_id:637456)。其核心公式为：
$$ \mathrm{Att}(Q,K,V) = \mathrm{softmax}\left(\frac{QK^\top}{\sqrt{d}}\right) V $$
这里，$Q$（查询）、$K$（键）、$V$（值）是从输入导出的矩阵。我们可以将查询 $q_i$ 想象为代表当前任务目标的[特征向量](@entry_id:151813)，将键 $k_j$ 想象为某个输入项的[特征向量](@entry_id:151813)。点积 $q_i^\top k_j$ 计算了任务目标与输入项之间的**相似度**。这些相似度分数（logits）通过一个**softmax函数**进行归一化。[Softmax函数](@entry_id:143376)的分母是所有指数化分数的总和，这是一种典型的除法归一化，它产生了一组总和为1的权重。这些权重然后被用于对值向量 $V$ 进行加权求和，从而得到最终的输出。这个过程可以被理解为：根据与当前“查询”的“相关性”，动态地为不同的输入“值”分配不同的“注意力权重” 。

这个机制与神经科学中的特征注意力模型有多个对应点：
1.  **相似度加权**：权重基于查询和键的相似度，类似于注意力增益取决于被关注特征与神经元偏好特征的相似度。
2.  **乘法增益和归一化**：[Softmax](@entry_id:636766)产生的权重对值向量进行乘法加权，这与乘法增益模型一致。其固有的归一化特性也与大脑中广泛存在的群体活动归一化现象相呼应。
3.  **[贝叶斯推断](@entry_id:146958)视角**：注意力权重可以被解释为在给定任务目标（查询）下，关于哪个输入项是相关的后验概率分布。从这个角度看，[注意力机制](@entry_id:917648)是在执行一种**贝叶斯加权平均**，根据推断出的相关性来整合信息，这与“[贝叶斯大脑](@entry_id:152777)”假说不谋而合 。
4.  **缩放因子**：公式中的缩放因子 $1/\sqrt{d}$ （$d$是特征维度）在数学上起着稳定方差的作用，防止点积的幅度随维度增长而变得过大，从而避免softmax函数进入饱和区，保证了梯度的有效传播 。

### 深度网络中的学习与推理

深度网络如何学习其复杂的内部参数？标准的[反向传播算法](@entry_id:198231)虽然高效，但其[生物学合理性](@entry_id:916293)备受质疑，这催生了对更符合生物学原理的学习算法的探索。

#### 信用分配问题与生物学上合理的学习

在[多层网络](@entry_id:261728)中，核心的学习挑战是**信用[分配问题](@entry_id:174209)（credit assignment problem）**：如何确定网络底层的参数对最终输出的误差负有多大责任 。**[反向传播](@entry_id:199535)（Backpropagation, BP）**算法通过链式法则精确地计算了[损失函数](@entry_id:634569)对每一层参数的梯度，从而解决了这个问题。然而，BP的典型实现需要一个[反向传播](@entry_id:199535)误差的通路，该通路使用了[前向通路](@entry_id:275478)权重的转置（$\mathbf{W}^{l+1\top}$）。这种精确的权重对称性要求被称为**权重传输问题（weight transport problem）**，在生物[神经回路](@entry_id:169301)中很难找到其直接对应物 。

为了解决这个问题，研究人员提出了多种生物学上更合理的替代算法：
*   **反馈对齐（Feedback Alignment, FA）**：该算法用一个固定的、随机的反馈矩阵 $\mathbf{B}^l$ 来替代 $\mathbf{W}^{l+1\top}$ 传播误差。令人惊讶的是，即使反馈通路与[前向通路](@entry_id:275478)不匹配，网络在学习过程中也能自发地调整前向权重，使其更新方向与真实[梯度对齐](@entry_id:172328)，从而实现有效的学习 。
*   **差分目标传播（Difference Target Propagation, DTP）**：这种方法通过学习一个近似的前向映射逆函数，将高层的目标（或修正）“传播”回低层，为低层[神经元活动](@entry_id:174309)创建一个局部目标。学习规则变为最小化当前活动与这个局部目标之间的差异 。

**预测编码（Predictive Coding, PC）**提供了一个更全面的理论框架，它将感知和学习统一在最小化**预测误差**的单一原则之下。PC将[大脑建模](@entry_id:1121850)为一个分层的生成模型，其中高层向低层发送预测，而低层则将这些预测与实际输入进行比较，并将[误差信号](@entry_id:271594)向上传递。学习和**推理（perception）**都是通过最小化一个称为**[变分自由能](@entry_id:1133721)（variational free-energy）**的[目标函数](@entry_id:267263)来实现的 。

与标准DNN的单次[前向传播](@entry_id:193086)不同，PC中的推理是一个**迭代的动态过程**：网络中的表征单元和误差单元不断相互作用，直到预测[误差最小化](@entry_id:163081)，活动达到一个[稳态](@entry_id:139253) 。权重更新（学习）则是一个更慢的过程，它根据局部神经元活动和误差信号，按照一种类赫布规则进行调整。一个深刻的理论结果是，在某些条件下（如线性网络），当PC的推理过程收敛后，其权重更新规则在代数上等价于BP算法计算的梯度 。这表明，大脑可能通过一种动态的、基于[误差最小化](@entry_id:163081)的推理过程，间接地实现了类似于反向传播的有效学习。

#### 稳定-可塑性困境：[持续学习](@entry_id:634283)

人类和动物可以在不忘记旧技能的情况下不断学习新技能。然而，使用标准BP算法训练的DNN在序贯地学习多个任务时，会遭受**[灾难性遗忘](@entry_id:636297)（catastrophic forgetting）**：在学习新任务后，网络在旧任务上的性能会急剧下降 。这是**稳定-可塑性困境**的体现：网络既需要保持稳定以记住旧知识，又需要具备可塑性以学习新知识。

解决这个问题的一个重要思路是**[突触巩固](@entry_id:173007)（synaptic consolidation）**，其灵感来自于记忆在大脑中从短期形式转变为长期形式的过程。**弹性权重巩固（Elastic Weight Consolidation, EWC）**是该思想的一个计算实现。EWC从贝叶斯序贯学习的视角出发，将旧任务的[后验概率](@entry_id:153467)分布作为新任务的先验。它通过[拉普拉斯近似](@entry_id:636859)，将旧任务的[后验近似](@entry_id:753628)为一个高斯分布，其[精度矩阵](@entry_id:264481)由**费雪信息矩阵（Fisher Information Matrix, FIM）**给出。FIM的对角线元素衡量了每个权重对于旧任务的重要性。在学习新任务时，EWC在损失函数中增加一个二次惩罚项，该惩罚项阻止那些对旧任务重要的权重发生大的改变，从而保护旧记忆 。

另一类有效的方法是**回放（replay）或排练（rehearsal）**。这类方法通过在学习新任务的同时，交叉地“回放”来自旧任务的样本来近似联合训练。这些旧样本可以是从一个存储库中提取的真实样本，也可以是由一个在旧任务上训练好的生成模型所合成的“伪样本”（**生成式回放**）。通过不断地重新接触旧任务的数据，网络能够维持其在这些任务上的性能。

### 涌现属性与脆弱性：[对抗性样本](@entry_id:636615)

将DNN作为大脑模型的一个重要价值在于，它们可能会展现出一些意想不到的、可以作为对生物系统进行检验的预测或现象。**[对抗性样本](@entry_id:636615)（adversarial examples）**就是这样一个例子。

[对抗性样本](@entry_id:636615)是指通过对一个被正确分类的输入 $x$ 添加一个微小的、人眼几乎无法察觉的扰动 $\eta$，从而得到一个被分类器误分类的新输入 $x+\eta$ 。这种现象的普遍存在揭示了高维空间中分类器的一个反直觉特性。

一种主流解释是“高维空间中的线性”假说。尽管DNN是高度[非线性](@entry_id:637147)的函数，但在局部区域内，它们的行为可以被一个一阶[泰勒展开](@entry_id:145057)近似：$z(x+\eta) \approx z(x) + \nabla_x z(x)^\top \eta$，其中 $z(x)$ 是分类器的决策分数。为了使[分类结果](@entry_id:924005)翻转（例如，从正变为负），我们需要使扰动引起的决策分数变化 $\nabla_x z(x)^\top \eta$ 足够大且为负。为了在保持扰动范数 $\|\eta\|_p$ 很小的情况下最大化这个变化，最优的扰动方向应该与梯度的[对偶范数](@entry_id:200340)方向对齐。

在 $d$ 维高维空间中，即使梯度的每个分量都很小，梯度的某个范数（例如，对于[无穷范数](@entry_id:637586)扰动的 $L_1$ 范数）也可能非常大（可能与维度 $d$ 成比例）。这意味着，只需要一个在 $L_p$ 范数下非常小的扰动 $\eta$（其大小可能与 $1/d^{1/q}$ 成反比，其中 $1/p+1/q=1$），就可以产生足以改变[分类结果](@entry_id:924005)的决策分数变化 。这种对精心设计的微小扰动的极端敏感性，提出了一个有趣的问题：生物视觉系统是否也同样脆弱？对这个问题的研究正在成为连接[人工智能安全](@entry_id:634060)和计算神经科学的一个活跃领域。