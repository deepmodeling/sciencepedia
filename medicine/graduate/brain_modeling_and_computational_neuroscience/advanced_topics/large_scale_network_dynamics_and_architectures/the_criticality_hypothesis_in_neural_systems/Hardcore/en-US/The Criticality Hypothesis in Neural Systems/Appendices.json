{
    "hands_on_practices": [
        {
            "introduction": "A hallmark of systems at a critical point is the absence of a characteristic timescale, leading to long-range temporal correlations. This exercise provides a foundational look into how this property is quantified, challenging you to derive the direct relationship between a power-law decay in the temporal autocorrelation function and the corresponding power-law scaling in the power spectral density . Mastering this connection is crucial for identifying and interpreting the famous \"$1/f$\" noise signature, a key piece of evidence for criticality in empirical neural data.",
            "id": "4027960",
            "problem": "Consider a stationary, zero-mean scalar neural activity signal $x(t)$ generated by a large, recurrent network poised near a continuous phase transition. Let the autocorrelation function be defined by $C(t) = \\langle x(0) x(t) \\rangle$, and let the power spectral density (PSD) be defined via the Wiener–Khinchin theorem as $S(f) = 2 \\int_{0}^{\\infty} C(t) \\cos(2 \\pi f t) \\, dt$, where $f$ is the temporal frequency.\n\nTwo dynamical regimes are relevant:\n1. In the off-critical regime, correlations decay with a finite correlation time, $C(t) \\approx A \\exp(-t/\\tau)$ with $\\tau  \\infty$ and amplitude $A  0$.\n2. At criticality, the correlation time diverges and correlations become scale-free over an extended inertial range (bounded by microscopic and macroscopic cutoffs), $C(t) \\approx A \\, t^{-\\alpha_{t}}$ for $t$ in an interval $[t_{0}, T]$ with $0  \\alpha_{t}  1$, $t_{0} \\ll T$, and $A  0$.\n\nStarting strictly from the definitions given above and standard asymptotic properties of Fourier cosine transforms, derive the low-frequency form of $S(f)$ in both regimes (you may introduce a vanishing exponential regulator to justify interchange of limits for the critical case). Then, deduce the spectral scaling exponent $\\beta$ defined by $S(f) \\sim f^{-\\beta}$ in the critical regime and express it in terms of $\\alpha_{t}$.\n\nYour final answer must be a single closed-form analytical expression for $\\beta$ in terms of $\\alpha_{t}$.",
            "solution": "The problem statement is first validated to ensure it is scientifically grounded, well-posed, and objective.\n\n### Step 1: Extract Givens\n-   **Signal**: A stationary, zero-mean scalar neural activity signal, $x(t)$.\n-   **Autocorrelation Function**: $C(t) = \\langle x(0) x(t) \\rangle$.\n-   **Power Spectral Density (PSD)**: $S(f) = 2 \\int_{0}^{\\infty} C(t) \\cos(2 \\pi f t) \\, dt$, where $f$ is the temporal frequency.\n-   **Off-critical Regime**: The autocorrelation function has the form $C(t) \\approx A \\exp(-t/\\tau)$ with a finite correlation time $\\tau  \\infty$ and amplitude $A  0$.\n-   **Critical Regime**: The autocorrelation function exhibits power-law decay, $C(t) \\approx A \\, t^{-\\alpha_{t}}$, for $t$ in an interval $[t_{0}, T]$ with $0  \\alpha_{t}  1$, $t_{0} \\ll T$, and $A  0$.\n-   **Definition**: The spectral scaling exponent $\\beta$ is defined by the relation $S(f) \\sim f^{-\\beta}$ in the critical regime.\n-   **Objective**: Derive the low-frequency form of $S(f)$ for both regimes and find an expression for $\\beta$ in terms of $\\alpha_{t}$.\n\n### Step 2: Validate Using Extracted Givens\n1.  **Scientifically Grounded**: The problem is based on the criticality hypothesis, a well-established framework in computational neuroscience and statistical physics. The definitions of the autocorrelation function, power spectral density via the Wiener-Khinchin theorem, exponential correlation decay (off-critical), and power-law correlation decay (critical) are standard and correct.\n2.  **Well-Posed**: The problem is well-posed. It provides all necessary definitions and constraints (e.g., $0  \\alpha_t  1$) to derive a unique and meaningful relationship between $\\alpha_t$ and $\\beta$.\n3.  **Objective**: The problem is stated using precise, formal language, free of ambiguity or subjective claims.\n\n### Step 3: Verdict and Action\nThe problem is valid. A complete solution will be provided.\n\n### Derivation\n\nThe analysis proceeds by calculating the power spectral density $S(f)$ for the two specified regimes.\n\n**1. Off-critical Regime**\n\nIn this regime, the autocorrelation function is given by $C(t) \\approx A \\exp(-t/\\tau)$. The power spectral density $S(f)$ is the Fourier cosine transform of $C(t)$:\n$$S(f) = 2 \\int_{0}^{\\infty} A \\exp(-t/\\tau) \\cos(2 \\pi f t) \\, dt$$\nThis is a standard integral form. Recognizing the formula for the Fourier cosine transform of an exponential function, $\\int_{0}^{\\infty} \\exp(-at) \\cos(bt) \\, dt = \\frac{a}{a^2 + b^2}$, we set $a = 1/\\tau$ and $b = 2\\pi f$.\n$$S(f) = 2A \\left( \\frac{1/\\tau}{(1/\\tau)^2 + (2\\pi f)^2} \\right)$$\n$$S(f) = 2A \\left( \\frac{1/\\tau}{1/\\tau^2 + 4\\pi^2 f^2} \\right) = 2A \\frac{\\tau}{1 + (2\\pi f \\tau)^2}$$\nThis functional form is a Lorentzian. In the low-frequency limit, as $f \\to 0$, the denominator approaches $1$.\n$$S(f \\to 0) \\approx 2A\\tau$$\nThe spectrum is flat (white noise) at low frequencies, which is characteristic of systems with a finite correlation time. In this case, the scaling exponent is $\\beta=0$.\n\n**2. Critical Regime**\n\nAt criticality, the autocorrelation function is approximated by a power law, $C(t) \\approx A t^{-\\alpha_{t}}$, over an extended range of time scales. The condition $0  \\alpha_{t}  1$ is crucial. The PSD is given by:\n$$S(f) \\approx 2 \\int_{0}^{\\infty} A t^{-\\alpha_{t}} \\cos(2 \\pi f t) \\, dt$$\nThe low-frequency behavior of $S(f)$ is determined by the long-time behavior of $C(t)$. The integral's convergence is delicate because for $0  \\alpha_t  1$, the function $t^{-\\alpha_t}$ is not in $L^1[0, \\infty)$, as $\\int_0^\\infty t^{-\\alpha_t} dt$ diverges at the upper limit. However, the Fourier cosine transform is well-defined.\n\nTo determine the scaling with frequency $f$, we perform a change of variables. Let $u = 2\\pi f t$. This gives $t = u / (2\\pi f)$ and $dt = du / (2\\pi f)$. Substituting these into the integral for $S(f)$:\n$$S(f) \\approx 2A \\int_{0}^{\\infty} \\left(\\frac{u}{2\\pi f}\\right)^{-\\alpha_{t}} \\cos(u) \\, \\frac{du}{2\\pi f}$$\nWe can factor out the terms involving $f$:\n$$S(f) \\approx 2A (2\\pi f)^{\\alpha_{t}} \\frac{1}{2\\pi f} \\int_{0}^{\\infty} u^{-\\alpha_{t}} \\cos(u) \\, du$$\n$$S(f) \\approx \\frac{A}{\\pi} (2\\pi f)^{\\alpha_{t}-1} \\int_{0}^{\\infty} u^{-\\alpha_{t}} \\cos(u) \\, du$$\nSimplifying the frequency-dependent term:\n$$S(f) \\approx \\frac{A (2\\pi)^{\\alpha_{t}-1}}{\\pi} f^{-(1-\\alpha_{t})} \\int_{0}^{\\infty} u^{-\\alpha_{t}} \\cos(u) \\, du$$\nThe integral $\\int_{0}^{\\infty} u^{-\\alpha_{t}} \\cos(u) \\, du$ is a definite integral whose value depends only on the parameter $\\alpha_{t}$. For the given range $0  \\alpha_{t}  1$, this integral converges to a finite, positive constant. The exact value of this constant is $\\Gamma(1-\\alpha_t) \\sin(\\pi \\alpha_t / 2)$, where $\\Gamma$ is the gamma function.\n\nLet $K(\\alpha_t) = \\frac{A (2\\pi)^{\\alpha_{t}-1}}{\\pi} \\int_{0}^{\\infty} u^{-\\alpha_{t}} \\cos(u) \\, du$. Since $K(\\alpha_t)$ is a constant with respect to frequency $f$, we have the scaling relationship:\n$$S(f) \\propto f^{-(1-\\alpha_{t})}$$\nThe problem defines the spectral scaling exponent $\\beta$ by the relation $S(f) \\sim f^{-\\beta}$. By comparing this definition with our derived result, we can directly identify the expression for $\\beta$.\n$$f^{-\\beta} \\sim f^{-(1-\\alpha_{t})}$$\nTherefore, the spectral scaling exponent $\\beta$ is related to the temporal correlation exponent $\\alpha_{t}$ by:\n$$\\beta = 1 - \\alpha_{t}$$\nThis result is a fundamental signature of critical dynamics, where a power-law decay in time with exponent $\\alpha_t$ translates to a power-law spectrum in frequency with exponent $\\beta = 1 - \\alpha_t$. The condition $0  \\alpha_t  1$ ensures that $0  \\beta  1$, which is characteristic of so-called \"$1/f$ noise\" or \"pink noise\" observed in many complex systems at or near criticality.",
            "answer": "$$\\boxed{1 - \\alpha_{t}}$$"
        },
        {
            "introduction": "The theoretical predictions of criticality, such as diverging correlation lengths and susceptibilities, are defined in the thermodynamic limit of an infinite system. This practice bridges the gap between theory and reality by exploring the consequences of finite system size, which is the case for any real-world experiment or computer simulation . By applying the principles of finite-size scaling, you will derive how the location and height of peak susceptibility depend on system size, providing an essential framework for analyzing and interpreting data from finite neural networks.",
            "id": "4027966",
            "problem": "Consider a spatially embedded, sparsely connected neural network poised near a continuous phase transition in its activity propagation parameter $p$, with $p_{c}$ denoting the critical value. Let the network have $N$ neurons arranged in an effectively $d$-dimensional geometry with linear extent $L$ satisfying $L \\sim N^{1/d}$, and assume short-range interactions. The order parameter $m$ is the steady-state fraction of active neurons. The susceptibility $\\chi$ is defined as the linear response of $m$ to a small homogeneous external drive $h$ as $\\chi = \\left.\\frac{\\partial m}{\\partial h}\\right|_{h \\to 0}$, and is empirically observed in such models to diverge in the thermodynamic limit according to $\\chi \\sim |p - p_{c}|^{-\\gamma}$, while the correlation length $\\xi$ for activity fluctuations diverges as $\\xi \\sim |p - p_{c}|^{-\\nu}$.\n\nUsing only these foundations and the cutoff of the divergence by finite size when $\\xi$ becomes comparable to $L$ (finite-size rounding), derive how the finite-size location $p_{\\max}$ of the susceptibility peak and its finite-size height $\\chi_{\\max}(N)$ scale with $N$ as $N \\to \\infty$ for fixed $d$. Then, for a network belonging to the two-dimensional Ising universality class (with exponents $\\gamma = \\frac{7}{4}$ and $\\nu = 1$) embedded in a cortical sheet modeled as $d = 2$, and for $N = 10^{8}$, compute the dimensionless quantity\n$$\nS(N) \\equiv \\frac{\\chi_{\\max}(N)}{|p_{\\max} - p_{c}|}\n$$\nin the leading power-law approximation that neglects non-universal multiplicative constants. Express the final answer as a single number with no units. No rounding is required if an exact value can be given; otherwise, round your answer to four significant figures.",
            "solution": "The scenario specifies a continuous phase transition with standard scaling behavior. By definition, the susceptibility scales as $\\chi \\sim |p - p_{c}|^{-\\gamma}$ and the correlation length scales as $\\xi \\sim |p - p_{c}|^{-\\nu}$ in the thermodynamic limit. In a finite system with $N$ neurons embedded in $d$ dimensions, the linear size is $L \\sim N^{1/d}$.\n\nFinite-size rounding occurs because the divergence of $\\xi$ cannot exceed the system size $L$. The peak of the susceptibility $\\chi_{\\max}(N)$ is reached when the control parameter $p$ is tuned close enough to $p_{c}$ that the correlation length $\\xi$ saturates at the system size $L$. The condition for the peak is\n$$\n\\xi \\sim L \\quad \\Rightarrow \\quad |p_{\\max} - p_{c}| \\sim L^{-1/\\nu}.\n$$\nThis gives the scaling of the peak position shift,\n$$\n|p_{\\max} - p_{c}| \\sim L^{-1/\\nu}.\n$$\nSubstituting the relation $L \\sim N^{1/d}$ yields\n$$\n|p_{\\max} - p_{c}| \\sim N^{-1/(d \\nu)}.\n$$\n\nNext, evaluate the susceptibility at this shifted position. Since $\\chi \\sim |p - p_{c}|^{-\\gamma}$, plugging in $|p_{\\max} - p_{c}| \\sim L^{-1/\\nu}$ gives\n$$\n\\chi_{\\max}(N) \\sim \\left(L^{-1/\\nu}\\right)^{-\\gamma} = L^{\\gamma/\\nu}.\n$$\nUsing $L \\sim N^{1/d}$,\n$$\n\\chi_{\\max}(N) \\sim N^{\\gamma/(d \\nu)}.\n$$\n\nWe are asked to compute the quantity\n$$\nS(N) \\equiv \\frac{\\chi_{\\max}(N)}{|p_{\\max} - p_{c}|}.\n$$\nUsing the derived scalings,\n$$\nS(N) \\sim \\frac{N^{\\gamma/(d \\nu)}}{N^{-1/(d \\nu)}} = N^{\\left(\\gamma + 1\\right)/(d \\nu)}.\n$$\n\nFor the specified universality class and geometry, use $\\gamma = \\frac{7}{4}$, $\\nu = 1$, and $d = 2$. Then\n$$\n\\frac{\\gamma + 1}{d \\nu} = \\frac{\\frac{7}{4} + 1}{2 \\cdot 1} = \\frac{\\frac{11}{4}}{2} = \\frac{11}{8}.\n$$\nTherefore,\n$$\nS(N) \\sim N^{11/8}.\n$$\nWith $N = 10^{8}$,\n$$\nS(10^{8}) \\sim \\left(10^{8}\\right)^{11/8} = 10^{11}.\n$$\nThis is an exact evaluation under the leading power-law approximation (non-universal multiplicative constants neglected). No rounding is required.",
            "answer": "$$\\boxed{1 \\times 10^{11}}$$"
        },
        {
            "introduction": "Observing scale-free statistics in the brain is one thing; explaining their origin is another. This advanced computational exercise puts you in the role of a researcher testing two competing hypotheses: is the brain finely tuned to a single critical point, or does its inherent structural diversity give rise to an extended critical-like \"Griffiths phase\"?  You will implement a simulation of neural avalanches under both scenarios and develop quantitative metrics to distinguish them, gaining hands-on experience in model comparison and hypothesis testing at the cutting edge of computational neuroscience.",
            "id": "4027904",
            "problem": "Consider the criticality hypothesis in neural systems, in which spontaneous neural activity exhibits scale-free avalanches when the system operates near a critical point. A minimal mathematical framework for avalanche generation is the Galton–Watson branching process, where each active unit (e.g., neuron or local population) produces a random number of offspring. Let the expected number of offspring per active unit be denoted by $m$. In a homogeneous system, tuning $m$ to $m=1$ yields criticality, while $m1$ is subcritical and $m1$ is supercritical. In spatially heterogeneous systems with quenched disorder, rare regions with $m1$ embedded in an overall subcritical medium can generate an extended regime of apparent critical-like behavior termed the Griffiths phase, characterized by non-universal power-law exponents and broad variability across subsystems (e.g., cortical areas or experimental conditions).\n\nYou are tasked with designing and implementing a computational experiment to distinguish a Griffiths phase from tuned criticality by analyzing variability across cortical areas. Model each cortical area as composed of $K$ micro-patches, each with a fixed (quenched) reproduction mean $m_k$. An avalanche begins in one micro-patch and proceeds as a Galton–Watson process in that patch with Poisson offspring distribution of mean $m_k$, truncated by a finite system size $N$ (i.e., the avalanche size cannot exceed $N$). For area $a$, simulate $A$ avalanches and collect the avalanche sizes $\\{s_i^{(a)}\\}_{i=1}^A$. For an area-level tail exponent estimate, use the continuous maximum likelihood estimator for a power-law tail: for a chosen lower cutoff $s_{\\min}$, the exponent $\\tau^{(a)}$ is estimated as\n$$\n\\hat{\\tau}^{(a)} \\;=\\; 1 \\;+\\; \\frac{n_a}{\\sum_{i=1}^{n_a} \\ln\\!\\left(\\frac{s_i^{(a)}}{s_{\\min}}\\right)},\n$$\nwhere the sum is over the $n_a$ avalanche sizes in area $a$ satisfying $s_i^{(a)} \\ge s_{\\min}$.\n\nDefine the following cross-area metrics for a given scenario:\n- The across-area mean tail exponent $\\overline{\\tau} = \\frac{1}{M}\\sum_{a=1}^{M} \\hat{\\tau}^{(a)}$, where $M$ is the number of areas.\n- The across-area variability $V_\\tau = \\sqrt{\\frac{1}{M}\\sum_{a=1}^{M} \\left(\\hat{\\tau}^{(a)} - \\overline{\\tau}\\right)^2}$.\n- The rare-region saturation indicator $R$, defined as the fraction of avalanches across all areas that reach the cap $N$ (i.e., $s_i^{(a)} = N$), aggregated over all areas.\n\nScientific bases to use:\n- In homogeneous branching, $m=1$ yields scale-free avalanches with characteristic exponents; $m1$ yields exponential cutoffs and few saturations at finite $N$.\n- In Griffiths phases due to quenched disorder, rare supercritical patches ($m_k1$) embedded in a subcritical bulk cause non-universal effective exponents and heightened variability across areas, as well as an increased frequency of avalanches saturating $N$ due to explosive growth in rare patches.\n\nYour program must:\n1. Implement the above simulation for each area, where an avalanche is a Galton–Watson process with Poisson($m_k$) offspring, starting from one active unit in a single micro-patch, and stopping when the process goes extinct or when cumulative size reaches $N$.\n2. Estimate $\\hat{\\tau}^{(a)}$ for each area using the formula above. Choose $s_{\\min}$ adaptively from the set $\\{5,2,1\\}$: start with $s_{\\min}=5$, and if the tail sample size $n_a100$, reduce to $s_{\\min}=2$, and if still $n_a100$, reduce to $s_{\\min}=1$.\n3. Compute $\\overline{\\tau}$, $V_\\tau$, and $R$ for the scenario.\n4. Classify the scenario using the following decision rule, which formalizes the empirical tests:\n   - Output the integer $2$ (Griffiths-like) if $V_\\tau  0.08$ and $R  0.02$.\n   - Else, output the integer $1$ (tuned critical) if $\\left|\\overline{\\tau} - 1.5\\right| \\le 0.15$, $V_\\tau \\le 0.05$, and $0.005 \\le R \\le 0.05$.\n   - Else, output the integer $0$ (non-critical/off-critical).\n\nUse the following test suite of scenarios, each providing $(M, N\\text{-list}, K, A, \\text{heterogeneity parameters})$:\n- Scenario 1 (Griffiths-like): $M=8$, $N\\text{-list} = [220,260,300,340,380,420,460,500]$, $K=50$, $A=3000$, with a fraction $p_{\\mathrm{rr}}=0.05$ of rare patches having $m_k \\sim \\mathcal{N}(\\mu_{\\mathrm{super}}, \\sigma_{\\mathrm{super}})$ with $\\mu_{\\mathrm{super}}=1.05$, $\\sigma_{\\mathrm{super}}=0.01$, and the remaining $1-p_{\\mathrm{rr}}$ bulk patches having $m_k \\sim \\mathcal{N}(\\mu_{\\mathrm{sub}}, \\sigma_{\\mathrm{sub}})$ with $\\mu_{\\mathrm{sub}}=0.95$, $\\sigma_{\\mathrm{sub}}=0.02$. Truncate $m_k$ to the interval $[0.2, 2.0]$.\n- Scenario 2 (tuned critical): $M=8$, $N\\text{-list} = [220,260,300,340,380,420,460,500]$, $K=50$, $A=3000$, with all patches sampled as $m_k \\sim \\mathcal{N}(\\mu_{\\mathrm{crit}}, \\sigma_{\\mathrm{crit}})$ with $\\mu_{\\mathrm{crit}}=1.0$, $\\sigma_{\\mathrm{crit}}=0.005$, truncated to $[0.2, 2.0]$.\n- Scenario 3 (subcritical/off-critical): $M=8$, $N\\text{-list} = [220,260,300,340,380,420,460,500]$, $K=50$, $A=3000$, with all patches sampled as $m_k \\sim \\mathcal{N}(\\mu_{\\mathrm{sub}}, \\sigma_{\\mathrm{sub}})$ with $\\mu_{\\mathrm{sub}}=0.90$, $\\sigma_{\\mathrm{sub}}=0.02$, truncated to $[0.2, 2.0]$.\n\nFor each scenario, assume avalanches begin by uniformly selecting one of the $K$ patches of the corresponding area and then evolve entirely within that patch (thus respecting quenched disorder at the patch level). All random sampling should be reproducible by fixing a single global pseudorandom seed.\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (e.g., \"[result1,result2,result3]\"), where each result is the integer classification for the corresponding scenario in the order listed above. No physical units or angles are involved; report only integer outputs as specified.",
            "solution": "The problem requires the design and implementation of a computational experiment to classify neural activity patterns into three categories: Griffiths-like, tuned critical, and non-critical/off-critical. The classification is based on simulating neural avalanches using a Galton-Watson branching process model across multiple distinct areas, each characterized by quenched disorder in its micro-patch structure.\n\nThe solution proceeds by first constructing the simulation framework, then defining the statistical metrics for analysis, and finally implementing the provided classification rule. Each step is grounded in the principles of computational neuroscience and statistical physics as described in the problem statement.\n\n### 1. Model and Simulation Framework\n\nThe core of the simulation is a Galton-Watson branching process, a standard model for avalanche dynamics. An avalanche begins with a single active unit and proceeds in discrete generations. In each generation, every active unit produces a number of \"offspring\" units, which become the active units of the next generation. The process terminates when a generation produces zero offspring (extinction).\n\n**Simulation of a Single Avalanche:**\nAn avalanche is simulated within a single micro-patch $k$ characterized by a reproduction mean $m_k$. The number of offspring for each active unit is drawn from a Poisson distribution with mean $m_k$. If there are $N_{\\text{active}}$ units in the current generation, the total number of offspring is the sum of $N_{\\text{active}}$ independent draws from a $\\text{Poisson}(m_k)$ distribution. By the properties of the Poisson distribution, this sum is equivalent to a single draw from a $\\text{Poisson}(N_{\\text{active}} \\cdot m_k)$. This mathematical equivalence is leveraged for computational efficiency.\n\nThe simulation is constrained by a finite system size $N$, specific to each cortical area. If the cumulative size of the avalanche (total units activated) plus the newly generated offspring exceeds or equals $N$, the avalanche is considered to have saturated the system. Its size is recorded as $N$, and the process terminates. Otherwise, the total size and the count of active units are updated, and the process continues. The final size $s$ of the avalanche is the total number of units activated throughout its lifetime.\n\n**Modeling Cortical Areas and Quenched Disorder:**\nThe system comprises $M$ cortical areas. Each area $a$ is composed of $K$ micro-patches, and a specific system size cap $N_a$ is assigned to it. The \"quenched disorder\" is represented by assigning a fixed, time-invariant reproduction mean $m_k$ to each of the $K$ patches. These $m_k$ values are generated once per area for each scenario and remain constant for all $A$ avalanches simulated in that area.\n\nFor each of the $A$ avalanches in an area, a patch $k$ is chosen uniformly at random from the $K$ available patches. The entire avalanche then unfolds according to the branching process dynamics governed by that patch's specific reproduction mean $m_k$.\n\nThe generation of the set of $\\{m_k\\}_{k=1}^K$ for an area depends on the scenario:\n- **Scenario 1 (Griffiths-like):** A small fraction $p_{\\mathrm{rr}}$ of patches are designated as \"rare regions\" with a supercritical reproduction mean, $m_k \\sim \\mathcal{N}(\\mu_{\\mathrm{super}}, \\sigma_{\\mathrm{super}})$ where $\\mu_{\\mathrm{super}}  1$. The majority of patches are subcritical, with $m_k \\sim \\mathcal{N}(\\mu_{\\mathrm{sub}}, \\sigma_{\\mathrm{sub}})$ where $\\mu_{\\mathrm{sub}}  1$. This heterogeneity is the defining feature of the Griffiths phase model. The number of rare patches is determined as $\\text{round}(p_{\\mathrm{rr}} \\cdot K)$.\n- **Scenarios 2  3 (Homogeneous):** All $K$ patches in an area have their $m_k$ values drawn from a single normal distribution: centered near $1$ for the tuned critical case ($\\mu_{\\mathrm{crit}}=1.0$) and significantly less than $1$ for the subcritical case ($\\mu_{\\mathrm{sub}}=0.90$). The small variance $\\sigma$ models slight, homogeneous disorder.\n\nIn all cases, the sampled $m_k$ values are truncated to a specified interval $[0.2, 2.0]$.\n\n### 2. Statistical Analysis and Metrics\n\nAfter simulating $A$ avalanches for each of the $M$ areas, we analyze the resulting distributions of avalanche sizes $\\{s_i^{(a)}\\}_{i=1}^A$ to compute three key metrics.\n\n**Tail Exponent Estimation ($\\hat{\\tau}^{(a)}$):**\nFor each area $a$, the tail exponent of the avalanche size distribution is estimated. Critical systems are expected to exhibit power-law distributions, $P(s) \\sim s^{-\\tau}$. The problem provides the continuous maximum likelihood estimator for $\\tau$, given a lower cutoff $s_{\\min}$:\n$$ \\hat{\\tau}^{(a)} \\;=\\; 1 \\;+\\; \\frac{n_a}{\\sum_{i=1}^{n_a} \\ln\\!\\left(\\frac{s_i^{(a)}}{s_{\\min}}\\right)} $$\nHere, $n_a$ is the number of avalanches in area $a$ with size $s_i^{(a)} \\ge s_{\\min}$. To ensure a robust estimate, $s_{\\min}$ is chosen adaptively. We first try $s_{\\min}=5$. If this yields fewer than $n_a=100$ data points for the fit, we relax the cutoff to $s_{\\min}=2$. If the count is still below $100$, we use $s_{\\min}=1$. This procedure balances the need to fit the tail of the distribution with the need for a sufficient sample size.\n\n**Cross-Area Metrics ($\\overline{\\tau}$, $V_\\tau$, $R$):**\nThe individual area-level estimates $\\hat{\\tau}^{(a)}$ are aggregated across the $M$ areas to compute two global metrics:\n1.  The mean tail exponent, $\\overline{\\tau} = \\frac{1}{M}\\sum_{a=1}^{M} \\hat{\\tau}^{(a)}$.\n2.  The variability (population standard deviation) of the tail exponents, $V_\\tau = \\sqrt{\\frac{1}{M}\\sum_{a=1}^{M} \\left(\\hat{\\tau}^{(a)} - \\overline{\\tau}\\right)^2}$.\n\nA third metric, the rare-region saturation indicator $R$, is calculated by pooling data from all avalanches across all areas. It is defined as the total fraction of avalanches that reached their respective area's size cap $N_a$:\n$$ R = \\frac{\\sum_{a=1}^{M} |\\{i \\mid s_i^{(a)} = N_a\\}|}{M \\cdot A} $$\n\n### 3. Classification Logic\n\nThe three metrics—$\\overline{\\tau}$, $V_\\tau$, and $R$—form a feature vector that captures the essential dynamics of the simulated system. A decision tree, based on thresholds provided in the problem, classifies each scenario:\n- **Griffiths-like (output $2$):** Characterized by high variability and frequent large events. This is identified if $V_\\tau  0.08$ AND $R  0.02$. The high variability arises from the diverse dynamics in different areas due to the random placement of rare supercritical patches, and the high saturation rate is a direct consequence of these patches driving explosive avalanches.\n- **Tuned Critical (output $1$):** Characterized by behavior consistent with theoretical predictions for criticality. This is identified if the mean exponent is close to the theoretical value of $1.5$ (specifically, $|\\overline{\\tau} - 1.5| \\le 0.15$), variability is low ($V_\\tau \\le 0.05$), and saturation is moderate ($0.005 \\le R \\le 0.05$).\n- **Non-critical/Off-critical (output $0$):** Any scenario not meeting the above criteria, which would include subcritical systems that produce few large avalanches and have statistics inconsistent with criticality.\n\n### 4. Implementation Strategy\n\nThe implementation is a direct translation of the above principles into a Python script using the `numpy` library. A single pseudorandom number generator is seeded at the start to ensure reproducibility. The main logic iterates through each predefined scenario, performing the following steps:\n1.  For each of the $M$ areas, generate and store the quenched set of $m_k$ values according to the scenario's parameters.\n2.  For each area, simulate $A$ avalanches, each starting in a randomly selected patch. Store the resulting avalanche sizes.\n3.  Calculate the saturation count for the area and estimate its tail exponent $\\hat{\\tau}^{(a)}$.\n4.  After processing all areas, compute the aggregate metrics $\\overline{\\tau}$, $V_\\tau$, and $R$.\n5.  Apply the classification rules to determine the integer output for the scenario.\n6.  Collect the results for all scenarios and print them in the specified format. The use of `np.nanmean` and `np.nanstd` provides robustness against potential failures in the $\\hat{\\tau}$ estimation for any single area.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\n# language: Python\n# version: 3.12\n# libraries:\n#   - name: numpy, version: 1.23.5\n#   - name: scipy, version: 1.11.4 (not used)\n\ndef generate_m_ks_for_area(params, K, rng):\n    \"\"\"\n    Generates the quenched list of m_k values for a single area based on scenario parameters.\n    \"\"\"\n    m_clip_min, m_clip_max = params[\"m_clip\"]\n    \n    if params[\"heterogeneous\"]:\n        p_rr = params[\"p_rr\"]\n        # Use int(x + 0.5) for standard rounding of positive numbers for reproducibility.\n        n_rare = int(p_rr * K + 0.5)\n        n_bulk = K - n_rare\n        \n        m_super_params = params[\"super\"]\n        m_sub_params = params[\"sub\"]\n        \n        m_rare = rng.normal(loc=m_super_params[\"mean\"], scale=m_super_params[\"std\"], size=n_rare)\n        m_bulk = rng.normal(loc=m_sub_params[\"mean\"], scale=m_sub_params[\"std\"], size=n_bulk)\n        \n        m_ks = np.concatenate((m_rare, m_bulk))\n    else:\n        m_dist_params = params[\"dist\"]\n        m_ks = rng.normal(loc=m_dist_params[\"mean\"], scale=m_dist_params[\"std\"], size=K)\n        \n    m_ks = np.clip(m_ks, m_clip_min, m_clip_max)\n    rng.shuffle(m_ks)\n    return m_ks\n\ndef run_avalanche(m_k, N, rng):\n    \"\"\"\n    Simulates a single Galton-Watson avalanche with a size cap N.\n    \"\"\"\n    active_units = 1\n    total_size = 1\n\n    if N = 1:\n        return 1\n\n    while active_units  0:\n        # Sum of 'k' Poisson(lambda) variables is a Poisson(k*lambda) variable.\n        # This is a correct and efficient way to calculate total offspring.\n        num_offspring = rng.poisson(m_k * active_units)\n        \n        if total_size + num_offspring = N:\n            return N\n        \n        total_size += num_offspring\n        active_units = num_offspring\n        \n    return total_size\n\ndef estimate_tau(avalanche_sizes):\n    \"\"\"\n    Estimates the tail exponent tau using the continuous MLE and adaptive s_min.\n    \"\"\"\n    sizes = np.asarray(avalanche_sizes)\n    s_min_choices = [5, 2, 1]\n    \n    s_min_final = -1\n    tail_sizes = np.array([])\n    \n    for s_min in s_min_choices:\n        tail = sizes[sizes = s_min]\n        if len(tail) = 100:\n            s_min_final = s_min\n            tail_sizes = tail\n            break\n            \n    if s_min_final == -1:\n        s_min_final = 1\n        tail_sizes = sizes[sizes = s_min_final]\n\n    n_a = len(tail_sizes)\n    \n    if n_a == 0:\n        return np.nan\n\n    log_sum = np.sum(np.log(tail_sizes / s_min_final))\n    \n    if log_sum = 1e-9: # Avoid division by zero or near-zero\n        return np.nan\n        \n    tau_hat = 1.0 + n_a / log_sum\n    return tau_hat\n\ndef classify_scenario(tau_bar, v_tau, R):\n    \"\"\"\n    Classifies the scenario based on the computed metrics.\n    \"\"\"\n    if v_tau  0.08 and R  0.02:\n        return 2\n    elif abs(tau_bar - 1.5) = 0.15 and v_tau = 0.05 and 0.005 = R = 0.05:\n        return 1\n    else:\n        return 0\n\ndef run_scenario(params, rng):\n    \"\"\"\n    Runs the full simulation for one scenario and returns its classification.\n    \"\"\"\n    M, N_list, K, A = params[\"M\"], params[\"N_list\"], params[\"K\"], params[\"A\"]\n    \n    all_area_taus = []\n    total_saturated_count = 0\n    \n    all_areas_m_ks = [generate_m_ks_for_area(params, K, rng) for _ in range(M)]\n    \n    for i in range(M):\n        N_area = N_list[i]\n        m_ks_area = all_areas_m_ks[i]\n        \n        area_avalanche_sizes = np.empty(A, dtype=int)\n        \n        patch_indices = rng.integers(0, K, size=A)\n        \n        for j in range(A):\n            m_k = m_ks_area[patch_indices[j]]\n            size = run_avalanche(m_k, N_area, rng)\n            area_avalanche_sizes[j] = size\n            \n        total_saturated_count += np.sum(area_avalanche_sizes == N_area)\n        \n        tau_a = estimate_tau(area_avalanche_sizes)\n        all_area_taus.append(tau_a)\n        \n    tau_bar = np.nanmean(all_area_taus)\n    v_tau = np.nanstd(all_area_taus) # Population standard deviation (ddof=0 default)\n    R = total_saturated_count / (M * A)\n    \n    if np.isnan(tau_bar) or np.isnan(v_tau):\n        return 0\n        \n    return classify_scenario(tau_bar, v_tau, R)\n\ndef solve():\n    \"\"\"\n    Main function to define scenarios, run simulations, and print results.\n    \"\"\"\n    RNG = np.random.default_rng(0)\n\n    test_cases = [\n        # Scenario 1 (Griffiths-like)\n        {\n            \"name\": \"Griffiths-like\",\n            \"M\": 8, \"N_list\": [220, 260, 300, 340, 380, 420, 460, 500],\n            \"K\": 50, \"A\": 3000,\n            \"heterogeneous\": True,\n            \"p_rr\": 0.05,\n            \"super\": {\"mean\": 1.05, \"std\": 0.01},\n            \"sub\": {\"mean\": 0.95, \"std\": 0.02},\n            \"m_clip\": [0.2, 2.0]\n        },\n        # Scenario 2 (Tuned critical)\n        {\n            \"name\": \"Tuned critical\",\n            \"M\": 8, \"N_list\": [220, 260, 300, 340, 380, 420, 460, 500],\n            \"K\": 50, \"A\": 3000,\n            \"heterogeneous\": False,\n            \"dist\": {\"mean\": 1.0, \"std\": 0.005},\n            \"m_clip\": [0.2, 2.0]\n        },\n        # Scenario 3 (Subcritical/off-critical)\n        {\n            \"name\": \"Subcritical/off-critical\",\n            \"M\": 8, \"N_list\": [220, 260, 300, 340, 380, 420, 460, 500],\n            \"K\": 50, \"A\": 3000,\n            \"heterogeneous\": False,\n            \"dist\": {\"mean\": 0.90, \"std\": 0.02},\n            \"m_clip\": [0.2, 2.0]\n        }\n    ]\n\n    results = []\n    for case in test_cases:\n        result = run_scenario(case, RNG)\n        results.append(result)\n\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        }
    ]
}