{
    "hands_on_practices": [
        {
            "introduction": "To study neural avalanches empirically, we first need a clear and quantitative language to describe them. This initial exercise provides a concrete scenario to practice calculating the three most fundamental metrics: avalanche size, duration, and rate. Mastering these definitions  is the essential first step before moving on to more complex modeling or data analysis.",
            "id": "4292846",
            "problem": "A spike raster from a recurrent neural network is observed over a window of $200\\,\\mathrm{ms}$ and discretized into time bins of width $2\\,\\mathrm{ms}$. In the standard neural avalanche framework, an avalanche is defined as a maximal sequence of consecutive time bins with nonzero activity (no silent bin), bounded before and after by silent bins (bins with zero activity). Avalanche size is the total number of active neuron events accumulated over all bins in the avalanche. Avalanche duration is the time spanned by the avalanche’s consecutive active bins. The average avalanche rate is the total number of active neuron events per unit time over the avalanche duration.\n\nSuppose that during one contiguous sequence of $8$ active bins there are exactly $50$ neurons active in each bin, with no silent bin between the first and last active bin in the sequence, and assume that there are silent bins immediately before and after this sequence so that it constitutes a single avalanche. Using these definitions, compute the avalanche size, the avalanche duration, and the average avalanche rate. Express the avalanche size as a dimensionless count, the avalanche duration in milliseconds, and the average rate in hertz (Hz). No rounding is required; report exact values.",
            "solution": "The problem asks for the calculation of three quantities related to a single neural avalanche: its size, duration, and average rate. We are given the necessary parameters to compute these values based on their definitions.\n\nLet $N_{bins}$ be the number of consecutive active time bins in the avalanche, and let $N_{events\\_per\\_bin}$ be the number of active neuron events in each bin. Let $\\Delta t$ be the width of a single time bin.\n\nFrom the problem statement, we have:\n-   Number of active bins, $N_{bins} = 8$.\n-   Number of events per bin, $N_{events\\_per\\_bin} = 50$.\n-   Time bin width, $\\Delta t = 2\\,\\mathrm{ms}$.\n\nFirst, we compute the **avalanche size**, denoted by $S$. The size is defined as the total number of active neuron events accumulated over all bins in the avalanche. Since each of the $N_{bins}$ bins has $N_{events\\_per\\_bin}$ events, the total size is their product.\n$$S = N_{bins} \\times N_{events\\_per\\_bin}$$\nSubstituting the given values:\n$$S = 8 \\times 50 = 400$$\nThe avalanche size is a dimensionless count of events. So, $S = 400$.\n\nSecond, we compute the **avalanche duration**, denoted by $T$. The duration is defined as the total time spanned by the avalanche's consecutive active bins. This is the product of the number of active bins and the width of each time bin.\n$$T = N_{bins} \\times \\Delta t$$\nSubstituting the given values:\n$$T = 8 \\times 2\\,\\mathrm{ms} = 16\\,\\mathrm{ms}$$\nThe problem asks for the duration in milliseconds, so $T = 16\\,\\mathrm{ms}$.\n\nThird, we compute the **average avalanche rate**, denoted by $R$. This is defined as the total number of active neuron events per unit time over the avalanche duration. This is the ratio of the avalanche size $S$ to the avalanche duration $T$.\n$$R = \\frac{S}{T}$$\nThe problem requires the rate to be expressed in hertz ($\\mathrm{Hz}$), which is equivalent to events per second ($\\mathrm{s}^{-1}$). We must first convert the duration $T$ from milliseconds to seconds.\n$$T = 16\\,\\mathrm{ms} = 16 \\times 10^{-3}\\,\\mathrm{s}$$\nNow we can calculate the rate:\n$$R = \\frac{400 \\text{ events}}{16 \\times 10^{-3}\\,\\mathrm{s}} = \\frac{400}{16} \\times 10^3\\,\\mathrm{Hz}$$\n$$R = 25 \\times 10^3\\,\\mathrm{Hz} = 25000\\,\\mathrm{Hz}$$\nExpressing this in standard scientific notation:\n$$R = 2.5 \\times 10^4\\,\\mathrm{Hz}$$\n\nThe three computed quantities are:\n-   Avalanche size: $400$\n-   Avalanche duration: $16\\,\\mathrm{ms}$\n-   Average avalanche rate: $25000\\,\\mathrm{Hz}$ or $2.5 \\times 10^4\\,\\mathrm{Hz}$\n\nThe final answer should present these three numerical values in the specified order.",
            "answer": "$$\\boxed{\\begin{pmatrix} 400  16  2.5 \\times 10^4 \\end{pmatrix}}$$"
        },
        {
            "introduction": "A key piece of evidence for the \"critical brain\" hypothesis is the repeated observation of power-law distributions in avalanche statistics. This exercise goes to the theoretical heart of this phenomenon, guiding you through the derivation of the iconic $s^{-3/2}$ size distribution from a critical branching process model . By working through this derivation, you will connect the abstract concept of criticality to a concrete, testable mathematical prediction.",
            "id": "4002313",
            "problem": "In a simplified model of neural avalanches, consider a discrete-time Galton–Watson branching process in which each active neuron at generation $t$ produces a random number $K$ of active descendants at generation $t+1$. Assume the process is initiated by a single active neuron at generation $t=0$, that offspring numbers are independent and identically distributed across neurons and generations, and that the process is critical with mean offspring $\\mathbb{E}[K]=m=1$ and finite, nonzero variance $\\mathrm{Var}(K)=\\sigma^{2}\\in(0,\\infty)$. Define the avalanche size $S$ as the total number of active neurons across all generations until extinction, including the initial neuron.\n\nLet $f(u)=\\sum_{k=0}^{\\infty} p_{k} u^{k}$ denote the probability generating function (PGF) of $K$, and let $T(z)=\\sum_{s=1}^{\\infty} \\mathbb{P}(S=s) z^{s}$ denote the PGF of the avalanche size $S$. Starting from first principles for branching processes and properties of probability generating functions (PGFs), do the following:\n\n- Construct the functional relation between $T(z)$ and $f(u)$ implied by the branching property and the definition of $S$.\n- Analyze the behavior of $T(z)$ in the neighborhood of $z=1$ under the criticality condition $\\mathbb{E}[K]=1$ and finite variance $\\sigma^{2}$.\n- Use a standard transfer theorem for coefficient asymptotics of generating functions with square-root singularities to deduce the asymptotic form of the avalanche size distribution $\\mathbb{P}(S=s)$ for large $s$.\n\nReport the coefficient $C$ (as a closed-form analytic expression in terms of $\\sigma$ only) in the asymptotic law\n$$\n\\mathbb{P}(S=s)\\sim C\\, s^{-3/2}\\quad \\text{as } s\\to\\infty.\n$$\nYour final answer must be the expression for $C$ only. No numerical approximation is required, and no units are involved.",
            "solution": "The problem asks for the derivation of the coefficient $C$ in the asymptotic law for the size distribution of avalanches in a critical Galton-Watson branching process, given by $\\mathbb{P}(S=s)\\sim C\\, s^{-3/2}$. The process starts with a single individual, has a mean offspring of $\\mathbb{E}[K]=m=1$ (criticality), and a finite, non-zero offspring variance $\\mathrm{Var}(K)=\\sigma^2$.\n\nFirst, we establish the functional relationship between the probability generating function (PGF) of the avalanche size, $T(z) = \\sum_{s=1}^{\\infty} \\mathbb{P}(S=s) z^{s}$, and the PGF of the offspring distribution, $f(u) = \\sum_{k=0}^{\\infty} \\mathbb{P}(K=k) u^{k}$. The total avalanche size $S$ is the sum of the initial ancestor (size $1$) and the sizes of the sub-avalanches initiated by its $K$ offspring. Let the number of offspring of the initial ancestor be $K$. Each of these $K$ offspring starts a new, independent branching process, and the size of each sub-avalanche, denoted $S_i$ for $i=1, \\ldots, K$, has the same distribution as $S$. Thus, the total size is $S=1+\\sum_{i=1}^{K} S_i$.\n\nWe can write the PGF for $S$ using the law of total expectation:\n$$T(z) = \\mathbb{E}[z^S] = \\mathbb{E}\\left[z^{1+\\sum_{i=1}^{K} S_i}\\right] = z \\cdot \\mathbb{E}\\left[\\mathbb{E}\\left[z^{\\sum_{i=1}^{K} S_i} \\Big| K\\right]\\right]$$\nSince the $S_i$ are independent and identically distributed, given $K=k$, the PGF of their sum is the product of their individual PGFs: $\\mathbb{E}\\left[z^{\\sum_{i=1}^{k} S_i}\\right] = \\left(\\mathbb{E}[z^S]\\right)^k = (T(z))^k$.\nTaking the expectation over $K$, we get $\\mathbb{E}[(T(z))^K] = \\sum_{k=0}^{\\infty} \\mathbb{P}(K=k) (T(z))^k$, which is by definition the PGF of $K$ evaluated at $u=T(z)$. Therefore, we have:\n$$T(z) = z \\cdot f(T(z))$$\nThis is the fundamental functional equation for the PGF of the total progeny.\n\nNext, we analyze this equation in the neighborhood of $z=1$. For a critical process, the probability of eventual extinction is $1$, meaning $\\mathbb{P}(S  \\infty)=1$. Thus, as $z \\to 1^{-}$, $T(z) = \\sum \\mathbb{P}(S=s)z^s \\to \\sum \\mathbb{P}(S=s) = 1$. Let $u=T(z)$. We perform a Taylor expansion of $f(u)$ around $u=1$. The derivatives of $f(u)$ at $u=1$ relate to the moments of $K$:\n$f(1) = \\sum \\mathbb{P}(K=k) = 1$.\n$f'(1) = \\sum k \\mathbb{P}(K=k) = \\mathbb{E}[K] = m = 1$ (by the criticality condition).\n$f''(1) = \\sum k(k-1) \\mathbb{P}(K=k) = \\mathbb{E}[K(K-1)] = \\mathbb{E}[K^2] - \\mathbb{E}[K]$.\nWe know $\\mathrm{Var}(K) = \\sigma^2 = \\mathbb{E}[K^2] - (\\mathbb{E}[K])^2$. Since $\\mathbb{E}[K]=1$, we have $\\mathbb{E}[K^2] = \\sigma^2 + 1$.\nSo, $f''(1) = (\\sigma^2+1) - 1 = \\sigma^2$.\n\nThe Taylor series for $f(u)$ around $u=1$ is:\n$$f(u) = f(1) + f'(1)(u-1) + \\frac{f''(1)}{2!}(u-1)^2 + O((u-1)^3)$$\n$$f(u) = 1 + 1 \\cdot (u-1) + \\frac{\\sigma^2}{2}(u-1)^2 + O((u-1)^3) = u + \\frac{\\sigma^2}{2}(u-1)^2 + O((u-1)^3)$$\nSubstituting this back into the functional equation $T(z) = z f(T(z))$, with $u=T(z)$:\n$$u = z \\left( u + \\frac{\\sigma^2}{2}(u-1)^2 + O((u-1)^3) \\right)$$\nRearranging the terms:\n$$u(1-z) = z \\frac{\\sigma^2}{2}(u-1)^2 + z O((u-1)^3)$$\nAs $z \\to 1^-$, we have $u=T(z) \\to 1^-$. We can analyze the leading order behavior by setting $z \\approx 1$ and $u \\approx 1$ in the less sensitive parts of the equation:\n$$1 \\cdot (1-z) \\approx 1 \\cdot \\frac{\\sigma^2}{2}(u-1)^2$$\n$$(u-1)^2 \\approx \\frac{2(1-z)}{\\sigma^2}$$\nSince $u=T(z)1$ for $z1$, we have $u-10$, so we must take the negative square root:\n$$u-1 \\approx -\\sqrt{\\frac{2(1-z)}{\\sigma^2}} = -\\frac{\\sqrt{2}}{\\sigma}\\sqrt{1-z}$$\nThus, the asymptotic behavior of $T(z)$ near its singularity at $z=1$ is:\n$$T(z) \\approx 1 - \\frac{\\sqrt{2}}{\\sigma}\\sqrt{1-z} = 1 - \\frac{\\sqrt{2}}{\\sigma}(1-z)^{1/2}$$\nThis square-root singularity governs the asymptotic behavior of the coefficients $\\mathbb{P}(S=s)$.\n\nTo find the asymptotic form of $\\mathbb{P}(S=s)$, we use a transfer theorem from analytic combinatorics. It is often more convenient to apply the theorem to a function with a singularity of the form $(1-z)^{-\\alpha}$ where $\\alpha  0$. We can achieve this by differentiating $T(z)$:\n$$T'(z) = \\sum_{s=1}^{\\infty} s \\, \\mathbb{P}(S=s) z^{s-1}$$\nDifferentiating the asymptotic expression for $T(z)$:\n$$T'(z) \\approx \\frac{d}{dz}\\left(1 - \\frac{\\sqrt{2}}{\\sigma}(1-z)^{1/2}\\right) = - \\frac{\\sqrt{2}}{\\sigma} \\cdot \\frac{1}{2}(1-z)^{-1/2} \\cdot (-1) = \\frac{\\sqrt{2}}{2\\sigma}(1-z)^{-1/2} = \\frac{1}{\\sigma\\sqrt{2}}(1-z)^{-1/2}$$\nThe standard transfer theorem states that if a generating function $A(z) = \\sum a_n z^n$ behaves as $A(z) \\sim K(1-z)^{-\\alpha}$ for $z \\to 1$ (with $\\alpha \\notin \\{0, -1, -2, \\ldots\\}$), then its coefficients have the asymptotic form $a_n \\sim K \\frac{n^{\\alpha-1}}{\\Gamma(\\alpha)}$.\n\nLet's apply this to $T'(z)$. Here we have $K = \\frac{1}{\\sigma\\sqrt{2}}$ and $\\alpha = 1/2$. The coefficients of $T'(z)$ are given by $[z^s]T'(z) = (s+1)\\mathbb{P}(S=s+1)$. Applying the theorem:\n$$[z^s]T'(z) \\sim \\frac{1}{\\sigma\\sqrt{2}} \\frac{s^{(1/2)-1}}{\\Gamma(1/2)} = \\frac{1}{\\sigma\\sqrt{2}} \\frac{s^{-1/2}}{\\sqrt{\\pi}} = \\frac{1}{\\sigma\\sqrt{2\\pi}} s^{-1/2}$$\nwhere we used the known value $\\Gamma(1/2)=\\sqrt{\\pi}$.\nEquating the two expressions for the coefficients of $T'(z)$:\n$$(s+1)\\mathbb{P}(S=s+1) \\sim \\frac{1}{\\sigma\\sqrt{2\\pi}} s^{-1/2}$$\nFor large $s$, we can replace $s+1$ with $s$ on the left-hand side, and $s$ with $s-1$ on the right-hand side. Let $n=s+1$. For large $n$:\n$$n \\mathbb{P}(S=n) \\sim \\frac{1}{\\sigma\\sqrt{2\\pi}} (n-1)^{-1/2} \\approx \\frac{1}{\\sigma\\sqrt{2\\pi}} n^{-1/2}$$\nDividing by $n$, we obtain the asymptotic distribution for the avalanche size $S$:\n$$\\mathbb{P}(S=n) \\sim \\frac{1}{\\sigma\\sqrt{2\\pi}} n^{-3/2}$$\nComparing this to the requested form $\\mathbb{P}(S=s)\\sim C\\, s^{-3/2}$, we can identify the coefficient $C$.\n\nThe coefficient $C$ is therefore:\n$$C = \\frac{1}{\\sigma\\sqrt{2\\pi}}$$\nThis is the celebrated result for the size distribution of critical branching processes.",
            "answer": "$$\\boxed{\\frac{1}{\\sigma\\sqrt{2\\pi}}}$$"
        },
        {
            "introduction": "Identifying a power law in empirical data requires more than just plotting a histogram on logarithmic axes. This practice introduces the gold standard for this task: Maximum Likelihood Estimation (MLE), a robust statistical method for fitting power-law distributions . Understanding this technique is crucial for rigorously testing the criticality hypothesis and avoiding the common biases that plague naive methods like linear regression.",
            "id": "4292887",
            "problem": "A cortical network at putative criticality produces a sequence of neuronal avalanches whose size $S$ is defined as the total count of neuronal activations within an avalanche event. Empirical work in complex systems and network science often models the tail of avalanche sizes by a power law for $S \\ge S_{\\min}$. You are given an independent and identically distributed (i.i.d.) sample $\\{S_i\\}_{i=1}^n$ of avalanche sizes, each satisfying $S_i \\ge S_{\\min}$, collected under stationary recording conditions with fixed measurement resolution. Using the fundamental definition of maximum likelihood estimation (maximum likelihood estimation (MLE)), start from the properly normalized tail model and derive the estimator for the tail exponent $\\hat{\\tau}$ under a continuous power-law assumption with a hard lower cutoff at $S_{\\min}$. Then, identify the assumptions required for the validity and consistency of the estimator, and explain how the situation changes if the data are inherently discrete counts or if there is a finite-size upper cutoff.\n\nWhich option correctly outlines how to compute $\\hat{\\tau}$ and accurately states the assumptions behind the estimator?\n\nA. Assume a continuous Pareto tail for $S \\ge S_{\\min}$ with probability density $p(S \\mid \\tau)$ normalized over $[S_{\\min}, \\infty)$, write down the likelihood $L(\\tau) = \\prod_{i=1}^n p(S_i \\mid \\tau)$, maximize the log-likelihood with respect to $\\tau$ to obtain a closed-form $\\hat{\\tau}$, and require $S_i$ to be i.i.d., the tail to follow a continuous power law above $S_{\\min}$, the process to be stationary, and $\\tau  1$ for normalizability. Acknowledge that if avalanche sizes are discrete counts, the MLE involves a Hurwitz zeta normalization and typically requires numerical optimization; and if there is an upper cutoff $S_{\\max}$ close to $S_{\\min}$, the continuous lower-cutoff-only formula is biased and a truncated model must be used.\n\nB. Compute $\\hat{\\tau}$ by linear regression on the slope of a log-log histogram of all observed sizes without imposing a lower cutoff, taking the negative slope as the exponent. Assume only that the sample is large; binning does not affect bias, and whether sizes are continuous or discrete is irrelevant.\n\nC. Assume a discrete power law with probability mass function $p(S \\mid \\tau) = S^{-\\tau} / \\zeta(\\tau, S_{\\min})$, where $\\zeta$ is the Hurwitz zeta function, and claim that the MLE reduces exactly to the same closed form as in the continuous case. The estimator does not depend on the choice of $S_{\\min}$, and the presence of an upper cutoff has no impact.\n\nD. Use the sample mean $\\bar{S}$ and the method-of-moments relation between $\\bar{S}$ and $\\tau$ to produce $\\hat{\\tau}$, which is consistent even for heavy tails and does not require that $S_i$ be i.i.d. or that $S_{\\min}$ be correctly chosen.\n\nE. If there is a finite upper cutoff $S_{\\max}$, the MLE remains unbiased when using the continuous lower-cutoff-only formula; the normalizing constant cancels out, so the presence of $S_{\\max}$ never affects the estimate. Therefore, $\\hat{\\tau}$ can be computed by the same closed form regardless of $S_{\\max}$, and assumptions about $S_{\\min}$ or discreteness are unnecessary.",
            "solution": "The problem requires deriving the MLE for the exponent $\\tau$ of a continuous power-law distribution.\n\n1.  **Define and Normalize the Probability Density Function (PDF)**\n    The model assumes that for avalanche sizes $S \\ge S_{\\min}$, the probability density follows a power law:\n    $$p(S) \\propto S^{-\\tau}$$\n    To be a valid PDF, this must be normalized. We introduce a normalization constant $C$ such that the integral of the PDF from $S_{\\min}$ to $\\infty$ is equal to $1$.\n    $$ \\int_{S_{\\min}}^{\\infty} C S^{-\\tau} dS = 1 $$\n    For this integral to converge, the exponent of $S$ at the upper limit must be less than $-1$. That is, $-\\tau  -1$, which implies $\\tau  1$. Given this condition, we can evaluate the integral:\n    $$ C \\left[ \\frac{S^{-\\tau+1}}{-\\tau+1} \\right]_{S_{\\min}}^{\\infty} = 1 $$\n    $$ C \\left( \\lim_{S \\to \\infty} \\frac{S^{1-\\tau}}{1-\\tau} - \\frac{S_{\\min}^{1-\\tau}}{1-\\tau} \\right) = 1 $$\n    Since $\\tau  1$, $1-\\tau  0$, so $\\lim_{S \\to \\infty} S^{1-\\tau} = 0$. The expression simplifies to:\n    $$ C \\left( 0 - \\frac{S_{\\min}^{1-\\tau}}{1-\\tau} \\right) = C \\frac{S_{\\min}^{1-\\tau}}{\\tau-1} = 1 $$\n    Solving for $C$ gives:\n    $$ C = (\\tau-1)S_{\\min}^{\\tau-1} $$\n    The normalized PDF for the continuous power-law model is therefore:\n    $$ p(S \\mid \\tau, S_{\\min}) = (\\tau-1)S_{\\min}^{\\tau-1} S^{-\\tau} \\quad \\text{for} \\quad S \\ge S_{\\min} $$\n\n2.  **Construct the Likelihood Function**\n    Given an i.i.d. sample of $n$ observations $\\{S_i\\}_{i=1}^n$, where each $S_i \\ge S_{\\min}$, the likelihood function $L(\\tau)$ is the product of the individual probabilities (densities):\n    $$ L(\\tau \\mid \\{S_i\\}) = \\prod_{i=1}^{n} p(S_i \\mid \\tau, S_{\\min}) = \\prod_{i=1}^{n} \\left( (\\tau-1)S_{\\min}^{\\tau-1} S_i^{-\\tau} \\right) $$\n\n3.  **Maximize the Log-Likelihood**\n    It is mathematically more convenient to maximize the log-likelihood, $\\mathcal{L}(\\tau) = \\ln L(\\tau)$.\n    $$ \\mathcal{L}(\\tau) = \\ln \\left( \\left( (\\tau-1)S_{\\min}^{\\tau-1} \\right)^n \\prod_{i=1}^{n} S_i^{-\\tau} \\right) $$\n    $$ \\mathcal{L}(\\tau) = n \\ln(\\tau-1) + n \\ln(S_{\\min}^{\\tau-1}) - \\sum_{i=1}^{n} \\ln(S_i^{\\tau}) $$\n    $$ \\mathcal{L}(\\tau) = n \\ln(\\tau-1) + n(\\tau-1)\\ln(S_{\\min}) - \\tau \\sum_{i=1}^{n} \\ln(S_i) $$\n    To find the value of $\\tau$ that maximizes this function, we take the derivative with respect to $\\tau$ and set it to zero:\n    $$ \\frac{d\\mathcal{L}}{d\\tau} = \\frac{n}{\\tau-1} + n\\ln(S_{\\min}) - \\sum_{i=1}^{n} \\ln(S_i) = 0 $$\n    Rearranging to solve for the estimator $\\hat{\\tau}$:\n    $$ \\frac{n}{\\hat{\\tau}-1} = \\sum_{i=1}^{n} \\ln(S_i) - n\\ln(S_{\\min}) $$\n    $$ \\frac{n}{\\hat{\\tau}-1} = \\sum_{i=1}^{n} (\\ln(S_i) - \\ln(S_{\\min})) = \\sum_{i=1}^{n} \\ln\\left(\\frac{S_i}{S_{\\min}}\\right) $$\n    Isolating $\\hat{\\tau}$:\n    $$ \\hat{\\tau} - 1 = \\frac{n}{\\sum_{i=1}^{n} \\ln\\left(\\frac{S_i}{S_{\\min}}\\right)} $$\n    $$ \\hat{\\tau} = 1 + n \\left[ \\sum_{i=1}^{n} \\ln\\left(\\frac{S_i}{S_{\\min}}\\right) \\right]^{-1} $$\n    This is the closed-form MLE for the exponent of a continuous power law.\n\n4.  **Assumptions and Caveats**\n    -   **Assumptions**: The validity and consistency of this estimator rest on several key assumptions:\n        1.  The data $\\{S_i\\}$ are indeed independent and identically distributed.\n        2.  The underlying data-generating process is stationary, so $\\tau$ is a constant parameter.\n        3.  The data above $S_{\\min}$ are accurately described by a continuous power-law distribution.\n        4.  The value of $S_{\\min}$ is known or has been correctly determined.\n        5.  $\\tau  1$ is required for the distribution to be normalizable.\n    -   **Discrete Data**: If the data are discrete counts (as avalanche sizes fundamentally are), the continuous PDF should be replaced by a discrete probability mass function (PMF). The normalized PMF is:\n        $$ P(S \\mid \\tau, S_{\\min}) = \\frac{S^{-\\tau}}{\\sum_{k=S_{\\min}}^{\\infty} k^{-\\tau}} = \\frac{S^{-\\tau}}{\\zeta(\\tau, S_{\\min})} $$\n        where $\\zeta(\\tau, S_{\\min})$ is the Hurwitz zeta function. The log-likelihood involves this function, and its maximization leads to a transcendental equation for $\\hat{\\tau}$ that must be solved numerically. The continuous formula is an approximation that is good for large $S_{\\min}$ but is formally incorrect for discrete data.\n    -   **Upper Cutoff**: If there is a finite-size upper cutoff $S_{\\max}$, the distribution is truncated. The normalization integral runs from $S_{\\min}$ to $S_{\\max}$, not to infinity. The normalization constant becomes dependent on both $\\tau$ and $S_{\\max}$. The resulting log-likelihood function is more complex, and its maximization also requires numerical methods. Using the lower-cutoff-only formula (derived above) on data that has an upper cutoff introduces a systematic bias, especially if $S_{\\max}$ is not much larger than $S_{\\min}$.\n\nA. Assume a continuous Pareto tail for $S \\ge S_{\\min}$ with probability density $p(S \\mid \\tau)$ normalized over $[S_{\\min}, \\infty)$, write down the likelihood $L(\\tau) = \\prod_{i=1}^n p(S_i \\mid \\tau)$, maximize the log-likelihood with respect to $\\tau$ to obtain a closed-form $\\hat{\\tau}$, and require $S_i$ to be i.i.d., the tail to follow a continuous power law above $S_{\\min}$, the process to be stationary, and $\\tau  1$ for normalizability. Acknowledge that if avalanche sizes are discrete counts, the MLE involves a Hurwitz zeta normalization and typically requires numerical optimization; and if there is an upper cutoff $S_{\\max}$ close to $S_{\\min}$, the continuous lower-cutoff-only formula is biased and a truncated model must be used.\n**Verdict: Correct.**\n\nB. Compute $\\hat{\\tau}$ by linear regression on the slope of a log-log histogram of all observed sizes without imposing a lower cutoff, taking the negative slope as the exponent. Assume only that the sample is large; binning does not affect bias, and whether sizes are continuous or discrete is irrelevant.\n**Verdict: Incorrect.**\n\nC. Assume a discrete power law with probability mass function $p(S \\mid \\tau) = S^{-\\tau} / \\zeta(\\tau, S_{\\min})$, where $\\zeta$ is the Hurwitz zeta function, and claim that the MLE reduces exactly to the same closed form as in the continuous case. The estimator does not depend on the choice of $S_{\\min}$, and the presence of an upper cutoff has no impact.\n**Verdict: Incorrect.**\n\nD. Use the sample mean $\\bar{S}$ and the method-of-moments relation between $\\bar{S}$ and $\\tau$ to produce $\\hat{\\tau}$, which is consistent even for heavy tails and does not require that $S_i$ be i.i.d. or that $S_{\\min}$ be correctly chosen.\n**Verdict: Incorrect.**\n\nE. If there is a finite upper cutoff $S_{\\max}$, the MLE remains unbiased when using the continuous lower-cutoff-only formula; the normalizing constant cancels out, so the presence of $S_{\\max}$ never affects the estimate. Therefore, $\\hat{\\tau}$ can be computed by the same closed form regardless of $S_{\\max}$, and assumptions about $S_{\\min}$ or discreteness are unnecessary.\n**Verdict: Incorrect.**",
            "answer": "$$\\boxed{A}$$"
        }
    ]
}