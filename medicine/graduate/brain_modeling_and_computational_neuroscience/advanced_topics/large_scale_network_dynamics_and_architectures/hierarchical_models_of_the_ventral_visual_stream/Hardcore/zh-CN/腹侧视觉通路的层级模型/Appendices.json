{
    "hands_on_practices": [
        {
            "introduction": "要理解腹侧视觉通路中的分层处理，一个核心概念是感受野（receptive field）的系统性扩展。随着信息在视觉层次中向上流动，神经元会整合来自越来越大的输入区域的信号。这个练习将通过一个简化的分层模型，让你亲手计算更高层级单元的感受野大小，从而量化这一过程。通过这个计算，你将能更深刻地体会模型是如何通过牺牲空间精度来聚合上下文信息，这是物体识别的一个基本权衡 。",
            "id": "3988326",
            "problem": "腹侧视觉通路的层级模型可以被理想化为一个由局部连接的阶段组成的前馈堆叠，类似于卷积神经网络（CNN），其中每一层都应用空间局部化的线性滤波器，然后进行由步幅指定的下采样。在这类模型中，感受野的概念形式化了有多少输入单元（像素）可以影响一个更深层中的单个单元。假设一个三层前馈模型，其各层是严格空间局部和平移等变的，第 $1$、$2$、$3$ 层的方形各向同性滤波器尺寸分别为 $7 \\times 7$、$5 \\times 5$ 和 $3 \\times 3$，第 $1$、$2$、$3$ 层的步幅分别为 $1$、$2$ 和 $2$。假设单位扩张，无跳跃连接，且填充（如果存在）不改变能影响更深层单元的不同输入像素的数量。将第 $l$ 层单元的感受野定义为最小连续输入区间的沿一个空间轴的不同输入像素的数量（即以像素为单位的线性范围），使得该区间内输入像素的变化能够影响该单元的输出，这与标准卷积支持几何一致。\n\n从第一性原理出发——即层级模型中局部连接和步幅的定义——推导控制感受野范围如何随层数增长的递归关系，并用它计算该模型第 $3$ 层单元的线性感受野大小（沿一个轴的像素数）。然后，简要解释这个感受野大小对于腹侧视觉通路层级结构中上下文信息整合的意义，重点关注空间分辨率和上下文聚合之间的权衡。将最终数值答案表示为沿一个轴的线性感受野大小，以像素为单位。无需四舍五入。",
            "solution": "问题陈述已经过分析，并被认为是有效的。它在科学上基于计算神经科学和深度学习的原理，特别是关于视觉皮层的层级模型。该问题是适定的，提供了所有必要的参数和明确的目标。语言精确客观，设置内部一致且完整。\n\n主要任务是确定一个简化层级模型中第三层单元的线性感受野大小。为此，我们必须首先推导控制感受野大小跨层增长的通用递归关系。\n\n令 $RF_l$ 表示第 $l$ 层单元的线性感受野大小（沿一个轴的范围），以输入层（第 $0$ 层）的像素来衡量。\n令 $k_l$ 为第 $l$ 层滤波器（核）的线性尺寸。\n令 $s_l$ 为第 $l$ 层卷积的步幅。\n\n给定层中一个单元的感受野是指输入空间中能够影响其激活的区域。我们可以为 $RF_l$ 建立一个递归公式。\n\n对于第一层（$l=1$），一个单元的输出是通过将一个大小为 $k_1$ 的滤波器直接与输入图像进行卷积来计算的。因此，沿一个轴能够影响该单元的输入像素数量就是滤波器的大小。\n$$RF_1 = k_1$$\n\n现在，考虑第 $l$ 层（$l > 1$）中的一个单元。其输出是通过将一个大小为 $k_l$ 的滤波器应用于第 $l-1$ 层的输出特征图来计算的。这意味着该单元的激活依赖于来自第 $l-1$ 层的沿一个轴的 $k_l$ 个单元的连续块。第 $l$ 层单元的总感受野是来自第 $l-1$ 层的这 $k_l$ 个单元的感受野的并集。\n\n为了找到这个并集的大小，我们需要知道第 $l-1$ 层特征图中相邻单元的感受野在原始输入空间中的间隔。这个间隔，我们称之为累积步幅或跳跃，$J_{l-1}$，是所有前面层的步幅的乘积。\n跳跃 $J_i$ 是第 $i$ 层输出中两个相邻单元感受野中心之间的距离（以输入像素为单位）。\n对于第 $1$ 层，步幅为 $s_1$ 意味着相邻单元的感受野在输入上相隔 $s_1$ 个像素。所以，$J_1 = s_1$。\n对于第 $2$ 层，步幅为 $s_2$ 作用于第 $1$ 层的特征图。在第 $2$ 层图中的一个步长对应于在第 $1$ 层图中的大小为 $s_1$ 的步长。因此，在第 $2$ 层输出中的一个步长对应于在输入上 $s_2 \\times J_1 = s_2 s_1$ 个像素的跳跃。\n一般来说，直到第 $l-1$ 层的累积步幅是：\n$$J_{l-1} = \\prod_{i=1}^{l-1} s_i$$\n\n第 $l$ 层的一个单元看到来自第 $l-1$ 层的 $k_l$ 个相邻单元。这 $k_l$ 个单元的感受野在输入上的大小各为 $RF_{l-1}$。这些感受野的中心相隔 $J_{l-1}$ 个像素。总范围是块中第一个单元的感受野大小，加上其余 $k_l-1$ 个单元所覆盖的额外距离。这个额外距离是 $(k_l-1) \\times J_{l-1}$。\n因此，递归关系是：\n$$RF_l = RF_{l-1} + (k_l - 1) \\times J_{l-1} = RF_{l-1} + (k_l - 1) \\prod_{i=1}^{l-1} s_i$$\n这就是控制感受野范围如何随层数增长的递归关系。\n\n现在，我们将此公式应用于具体问题。给定参数为：\n滤波器尺寸：$k_1 = 7$，$k_2 = 5$，$k_3 = 3$。\n步幅：$s_1 = 1$，$s_2 = 2$，$s_3 = 2$。注意，计算 $RF_3$ 不需要 $s_3$，但计算 $RF_4$ 时会需要。\n\n步骤 1：计算第 1 层单元的感受野大小。\n使用基本情况：\n$$RF_1 = k_1 = 7$$\n第 1 层单元的感受野大小为 $7$ 像素。\n\n步骤 2：计算第 2 层单元的感受野大小。\n使用 $l=2$ 的递归公式：\n$$RF_2 = RF_1 + (k_2 - 1) \\prod_{i=1}^{1} s_i = RF_1 + (k_2 - 1) s_1$$\n代入数值：\n$$RF_2 = 7 + (5 - 1) \\times 1 = 7 + 4 = 11$$\n第 2 层单元的感受野大小为 $11$ 像素。\n\n步骤 3：计算第 3 层单元的感受野大小。\n使用 $l=3$ 的递归公式：\n$$RF_3 = RF_2 + (k_3 - 1) \\prod_{i=1}^{2} s_i = RF_2 + (k_3 - 1) s_1 s_2$$\n代入数值：\n$$RF_3 = 11 + (3 - 1) \\times (1 \\times 2) = 11 + 2 \\times 2 = 11 + 4 = 15$$\n第 3 层单元的线性感受野大小为 $15$ 像素。\n\n解释：\n计算出的第 3 层单元 $15 \\times 15$ 像素的感受野大小，体现了腹侧视觉通路中层级处理的核心原则。在上下文信息的聚合与精细空间分辨率的保持之间存在着根本性的权衡。\n\n上下文聚合：感受野大小随层数增加而增大，从第 1 层的 $7 \\times 7$ 增加到第 2 层的 $11 \\times 11$，最终到第 3 层的 $15 \\times 15$。这种增长表明，更高层级的单元整合了来自输入中逐渐增大的区域的信息。这使得模型能够构建日益复杂和抽象的特征的表示。一个第 3 层的单元可以通过组合其 $15 \\times 15$ 输入窗口内由较低层级单元检测到的更简单特征（如边缘、纹理），来对大规模模式或物体部分作出响应。\n\n空间分辨率的损失：这种上下文的聚合是通过下采样实现的，这里由大于一的步幅（$s_2=2, s_3=2$）来实现。虽然一个第 3 层的单元对一个大的 $15 \\times 15$ 区域内的刺激敏感，但它对于该区域内特征的精确位置的敏锐度较差。一个特征可以在 $15 \\times 15$ 的视场内移动几个像素，而不会改变哪个第 3 层的单元被激活。这就产生了位置不变性。\n\n这种权衡对于主要负责物体识别的腹侧（“什么”）通路的功能至关重要。该系统系统性地牺牲空间精度（“哪里”）来构建对物体身份（“什么”）具有选择性，并对位置、尺度和姿态的变化具有容忍度的表示。感受野大小的层级递增是实现这种依赖于上下文但又具有空间不变性的表示的关键机制。",
            "answer": "$$\\boxed{15}$$"
        },
        {
            "introduction": "稳健的物体识别能力依赖于对物体位置、大小和姿态变化的“不变性”表征。Hubel 和 Wiesel 提出的从简单细胞到复杂细胞的经典模型，为我们理解这种不变性是如何建立的提供了第一个计算框架。这个练习将引导你模拟这一过程：首先通过卷积运算模拟简单细胞（S1）的特征检测功能，然后通过局部最大池化（local maximum pooling）模拟复杂细胞（C1）的整合功能。完成这个练习后，你将直观地看到一个简单的机制如何能够产生对刺激平移的局部不变性，这是所有现代视觉模型的基础 。",
            "id": "3988315",
            "problem": "考虑一个腹侧视觉通路的典型前馈分层模型，其中简单层 (S1) 实现类似于经典简单细胞的线性滤波，而复杂层 (C1) 实现类似于经典复杂细胞的局部池化。假设 S1 的基本操作为通过卷积进行线性滤波，C1 的基本操作为局部最大池化。\n\n给定一个灰度图像刺激 $I \\in \\mathbb{R}^{4 \\times 4}$，其包含一个清晰的垂直阶跃边缘，像素强度为\n$$\nI \\;=\\;\n\\begin{pmatrix}\n0  0  1  1 \\\\\n0  0  1  1 \\\\\n0  0  1  1 \\\\\n0  0  1  1\n\\end{pmatrix}.\n$$\nS1 阶段配备了一个单一的方向选择性滤波器，近似于一个垂直方向的边缘检测器，\n$$\nF^{(v)} \\;=\\;\n\\begin{pmatrix}\n-1  0  1 \\\\\n-1  0  1 \\\\\n-1  0  1\n\\end{pmatrix}.\n$$\n将有效位置 $(i,j)$ （即 $3 \\times 3$ 滤波器可完全置于图像内部的位置）处的 S1 响应定义为修正线性滤波\n$$\ns_{i,j} \\;=\\; \\max\\!\\left(0,\\;\\sum_{m=1}^{3}\\sum_{n=1}^{3} F^{(v)}_{m,n}\\,P_{i,j}(m,n)\\right),\n$$\n其中 $P_{i,j} \\in \\mathbb{R}^{3 \\times 3}$ 是以 $(i,j)$ 为中心的图像块（即，使用基于 1 的索引，$P_{i,j}(m,n) = I(i+m-2,\\, j+n-2)$）。设有效的 S1 中心点集合为 $\\{(2,2),(2,3),(3,2),(3,3)\\}$。\n\n定义一个 C1 单元，该单元通过在窗口上取最大值进行局部池化\n$$\nW \\;=\\; \\{(i,j) \\;\\big|\\; i \\in \\{2,3\\},\\; j \\in \\{2,3\\}\\}.\n$$\n因此，C1 响应为\n$$\nC1 \\;=\\; \\max_{(i,j)\\in W} s_{i,j}.\n$$\n\n任务：对于给定的刺激和滤波器，计算 $C1$ 的数值，然后在推导过程中解释窗口 $W$ 中的局部最大池化如何支持对相对于滤波器的小范围刺激平移的不变性。将最终答案表示为单个实数。无需四舍五入。无需单位。",
            "solution": "该问题要求在一个腹侧视觉通路的简单分层模型中计算复杂层 (C1) 的响应。这包括两个阶段：首先，通过修正线性滤波计算简单层 (S1) 单元的响应；其次，通过在指定的池化窗口上取 S1 响应的最大值来计算 C1 响应。\n\n输入是一个 $4 \\times 4$ 的灰度图像 $I$ 和一个 $3 \\times 3$ 的垂直方向滤波器 $F^{(v)}$：\n$$\nI \\;=\\;\n\\begin{pmatrix}\n0  0  1  1 \\\\\n0  0  1  1 \\\\\n0  0  1  1 \\\\\n0  0  1  1\n\\end{pmatrix}\n\\quad\\text{和}\\quad\nF^{(v)} \\;=\\;\n\\begin{pmatrix}\n-1  0  1 \\\\\n-1  0  1 \\\\\n-1  0  1\n\\end{pmatrix}.\n$$\n在位置 $(i,j)$ 处的 S1 响应由 $s_{i,j} = \\max(0, \\text{线性响应})$ 给出，其中线性响应是滤波器 $F^{(v)}$ 与以 $(i,j)$ 为中心的图像块 $P_{i,j}$ 的逐元素乘积之和。我们必须为所有有效中心点 $(i,j) \\in \\{(2,2), (2,3), (3,2), (3,3)\\}$ 计算 $s_{i,j}$。\n\n1.  **计算在 $(i,j) = (2,2)$ 处的 S1 响应：**\n    图像块 $P_{2,2}$ 是以 $(2,2)$ 为中心的 $I$ 的 $3 \\times 3$ 区域，它跨越第 1 到 3 行和第 1 到 3 列。\n    $$\n    P_{2,2} \\;=\\;\n    \\begin{pmatrix}\n    0  0  1 \\\\\n    0  0  1 \\\\\n    0  0  1\n    \\end{pmatrix}.\n    $$\n    线性响应是展开后的滤波器和图像块的点积，即 $\\sum_{m,n} F^{(v)}_{m,n} P_{2,2}(m,n)$。\n    $$\n    \\text{Linear Response}_{(2,2)} = (-1)(0) + (0)(0) + (1)(1) + (-1)(0) + (0)(0) + (1)(1) + (-1)(0) + (0)(0) + (1)(1) = 1+1+1 = 3.\n    $$\n    修正后的 S1 响应为：\n    $$\n    s_{2,2} = \\max(0, 3) = 3.\n    $$\n\n2.  **计算在 $(i,j) = (2,3)$ 处的 S1 响应：**\n    图像块 $P_{2,3}$ 以 $(2,3)$ 为中心，跨越第 1 到 3 行和第 2 到 4 列。\n    $$\n    P_{2,3} \\;=\\;\n    \\begin{pmatrix}\n    0  1  1 \\\\\n    0  1  1 \\\\\n    0  1  1\n    \\end{pmatrix}.\n    $$\n    线性响应为：\n    $$\n    \\text{Linear Response}_{(2,3)} = (-1)(0) + (0)(1) + (1)(1) + (-1)(0) + (0)(1) + (1)(1) + (-1)(0) + (0)(1) + (1)(1) = 1+1+1 = 3.\n    $$\n    修正后的 S1 响应为：\n    $$\n    s_{2,3} = \\max(0, 3) = 3.\n    $$\n\n3.  **计算在 $(i,j) = (3,2)$ 处的 S1 响应：**\n    图像块 $P_{3,2}$ 以 $(3,2)$ 为中心，跨越第 2 到 4 行和第 1 到 3 列。由于输入图像 $I$ 的垂直均匀性，这个图像块与 $P_{2,2}$ 相同。\n    $$\n    P_{3,2} \\;=\\; P_{2,2} \\;=\\;\n    \\begin{pmatrix}\n    0  0  1 \\\\\n    0  0  1 \\\\\n    0  0  1\n    \\end{pmatrix}.\n    $$\n    因此，其响应与 $(2,2)$ 处的响应相同。\n    $$\n    s_{3,2} = s_{2,2} = 3.\n    $$\n\n4.  **计算在 $(i,j) = (3,3)$ 处的 S1 响应：**\n    图像块 $P_{3,3}$ 以 $(3,3)$ 为中心，跨越第 2 到 4 行和第 2 到 4 列。由于输入图像 $I$ 的垂直均匀性，这个图像块与 $P_{2,3}$ 相同。\n    $$\n    P_{3,3} \\;=\\; P_{2,3} \\;=\\;\n    \\begin{pmatrix}\n    0  1  1 \\\\\n    0  1  1 \\\\\n    0  1  1\n    \\end{pmatrix}.\n    $$\n    因此，其响应与 $(2,3)$ 处的响应相同。\n    $$\n    s_{3,3} = s_{2,3} = 3.\n    $$\n\n池化窗口 $W = \\{(2,2), (2,3), (3,2), (3,3)\\}$ 内的 S1 响应集合为 $\\{s_{2,2}, s_{2,3}, s_{3,2}, s_{3,3}\\} = \\{3, 3, 3, 3\\}$。滤波器 $F^{(v)}$ 在 S1 单元的 $2 \\times 2$ 网格内的所有四个位置上都稳健地检测到了垂直边缘特征。\n\n现在，我们通过对这些 S1 响应取最大值来计算 C1 响应：\n$$\nC1 \\;=\\; \\max_{(i,j)\\in W} s_{i,j} \\;=\\; \\max(s_{2,2}, s_{2,3}, s_{3,2}, s_{3,3}) = \\max(3, 3, 3, 3) = 3.\n$$\n\nC1 单元响应的最终数值是 $3$。\n\n推导过程说明了局部最大池化如何支持平移不变性。S1 层充当特征检测器层；在本例中，一个高的 $s_{i,j}$ 值表示在位置 $(i,j)$ 处存在一个垂直边缘。C1 层对这些检测器的输出进行池化。通过计算最大值，C1 单元的响应由其池化区域内最强的特征信号决定，从而有效地忽略了是哪个特定的 S1 检测器产生了该信号。这使得 C1 响应对特征的精确位置具有稳健性。\n\n为了具体说明这一点，考虑如果刺激边缘向左平移一个像素，得到一个新图像 $I'$，会发生什么：\n$$\nI' \\;=\\;\n\\begin{pmatrix}\n0  1  1  0 \\\\\n0  1  1  0 \\\\\n0  1  1  0 \\\\\n0  1  1  0\n\\end{pmatrix}.\n$$\n对这个平移后的刺激 $I'$ 在相同的窗口 $W$ 上重复 S1 计算，会得到一组不同的 S1 响应：$\\{s'_{2,2}, s'_{2,3}, s'_{3,2}, s'_{3,3}\\} = \\{3, 0, 3, 0\\}$。S1 层中的活动模式发生了变化。然而，C1 响应将会是：\n$$\nC1' \\;=\\; \\max(3, 0, 3, 0) = 3.\n$$\n尽管刺激发生了平移，C1 单元的输出保持不变。这表明最大池化操作提供了对特征位置小范围变化的容忍度，这是稳健物体识别的一个称为平移不变性的基本属性。",
            "answer": "$$\\boxed{3}$$"
        },
        {
            "introduction": "现代的腹侧视觉通路计算模型，如卷积神经网络（CNNs），不仅仅是简单的滤波器堆叠，它们还包含了各种对于模型性能和生物学 plausibility 至关重要的复杂计算单元，例如归一化（normalization）。这个练习要求你深入分析和比较三种主流的归一化方案：批量归一化、层归一化和受生物学启发的除法归一化。通过评估它们对表征稳定性和与大脑活动对齐度的影响，你将学会如何从第一性原理出发，将模型组件的工程选择与神经科学的假设联系起来，这是连接机器学习和计算神经科学的关键技能 。",
            "id": "3988310",
            "problem": "一个卷积神经网络（CNN）被训练成腹侧视觉流的分层模型，其中连续的卷积阶段旨在近似初级视觉皮层、次级视觉皮层和下颞叶皮层（IT）的计算角色。考虑在每个阶段应用的三种归一化方案：批量归一化、层归一化和受生物学启发的除法归一化。令 $x \\in \\mathbb{R}^d$ 表示给定阶段单个样本的归一化前激活向量，由特征 $i \\in \\{1,\\dots,d\\}$ 索引。令小批量为 $\\mathcal{B} = \\{x^{(1)},\\dots,x^{(n)}\\}$，大小为 $n$。\n\n批量归一化通过以下方式转换每个特征：\n$$\ny_i = \\gamma_i \\frac{x_i - \\mu_{\\mathcal{B},i}}{\\sqrt{\\sigma^2_{\\mathcal{B},i} + \\epsilon}} + \\beta_i,\n$$\n其中 $\\mu_{\\mathcal{B},i}$ 和 $\\sigma^2_{\\mathcal{B},i}$ 是特征 $i$ 的小批量均值和方差，$\\epsilon > 0$ 是一个很小的常数，$(\\gamma_i,\\beta_i)$ 是学习到的仿射参数。在推理时，使用训练期间计算的移动估计值 $(\\hat{\\mu}_i,\\hat{\\sigma}^2_i)$。\n\n层归一化通过以下方式进行转换：\n$$\ny_i = \\gamma_i \\frac{x_i - \\mu_{\\text{L}}}{\\sqrt{\\sigma^2_{\\text{L}} + \\epsilon}} + \\beta_i,\n$$\n其中 $\\mu_{\\text{L}} = \\frac{1}{d}\\sum_{j=1}^d x_j$ 和 $\\sigma^2_{\\text{L}} = \\frac{1}{d}\\sum_{j=1}^d (x_j - \\mu_{\\text{L}})^2$ 是对特征计算的单个样本的统计量。\n\n受生物学启发的除法归一化通过以下方式对神经元增益控制进行建模：\n$$\ny_i = \\frac{x_i}{\\sigma + \\sum_{j=1}^d w_{ij} |x_j|^p},\n$$\n其中 $w_{ij} \\ge 0$ 编码了一个局部池化结构（例如，根据感受野或方向相似性进行调整），$\\sigma > 0$ 是一个半饱和常数，$p \\ge 1$ 控制非线性。\n\n将表征对批量构成的稳定性定义为当批量变化时，固定 $x$ 的预期平方差：\n$$\nS_{\\text{BN}}(x) = \\mathbb{E}_{\\mathcal{B}_1,\\mathcal{B}_2} \\left[ \\| y^{\\mathcal{B}_1}(x) - y^{\\mathcal{B}_2}(x) \\|_2^2 \\right],\n$$\n$S_{\\text{LN}}(x)$ 和 $S_{\\text{DN}}(x)$ 的定义类似，保持网络参数和 $x$ 不变，只改变 $\\mathcal{B}$。\n\n大脑对齐度通过表征相似性分析（RSA）进行评估：对于一组图像 $\\{I_k\\}$，根据模型层响应和神经记录计算表征非相似性矩阵，并测量模型和神经非相似性结构之间的相关性 $\\rho$。分层对齐的目标是模型早期阶段与初级或次级视觉皮层对齐，而后期阶段与下颞叶皮层（IT）对齐。\n\n以下哪个陈述最符合关于上述机制的第一性原理推理以及大脑建模中广泛报道的经验趋势？\n\nA. 因为批量归一化依赖于小批量统计量 $(\\mu_{\\mathcal{B},i},\\sigma^2_{\\mathcal{B},i})$，所以 $S_{\\text{BN}}(x)$ 随着 $n$ 的增加而减小，但对于有限的 $n$ 不为零；层归一化产生 $S_{\\text{LN}}(x) = 0$ 对任何 $n$ 都成立，因为它只使用单个样本的统计量；除法归一化不依赖于 $\\mathcal{B}$，并通过其局部池化实现增益控制，从而降低了对均匀对比度缩放的敏感性，并倾向于改善与早期腹侧阶段的对齐度。\n\nB. 在推理时，使用移动平均值 $(\\hat{\\mu}_i,\\hat{\\sigma}^2_i)$ 的批量归一化与层归一化相同，因此它们在所有层上具有相同的表征稳定性和大脑对齐度。\n\nC. 对于 $p = 2$ 和 $\\sigma > 0$，除法归一化在乘法输入缩放的作用下产生压缩性响应，$y_i(\\alpha x) \\approx \\frac{\\alpha x_i}{\\sigma + \\alpha^2 \\sum_j w_{ij} |x_j|^2}$，相对于批量归一化（其效果取决于 $\\mathcal{B}$ 的分布）降低了对 $\\alpha$ 的敏感性；这一特性与早期视觉区域中改善的 RSA 对齐度一致，这些区域表现出对比度增益控制。\n\nD. 层归一化近似于生物除法归一化，因为它使用层内所有特征的统计数据，从而实现交叉方向抑制，并且通常在这三种方法中与初级视觉皮层产生最强的对齐。\n\nE. 在为物体识别训练的分层 CNN 中，一种在早期阶段使用除法归一化，在更深阶段用层归一化替换批量归一化的配置，可以通过在早期阶段结合局部增益控制与在与下颞叶皮层（IT）选择性对齐的后期阶段使用与批量无关的单样本归一化，来提高表征稳定性和跨区域的大脑对齐度。\n\n选择所有适用项。",
            "solution": "问题陈述是有效的。它为三种常见的归一化方案（批量归一化、层归一化、除法归一化）和计算神经科学中使用的度量标准（表征稳定性、表征相似性分析）提供了标准的、数学上精确的定义。其背景，即用分层CNN对大脑的腹侧视觉流进行建模，是一个成熟且活跃的科学研究领域。这个问题是客观的，可以通过对所提供的定义和该领域的既定原则进行逻辑推导来回答。\n\n我们现在将根据所提供的定义来分析每种归一化方案的属性。\n\n令 $x \\in \\mathbb{R}^d$ 为单个样本的归一化前激活，$\\mathcal{B} = \\{x^{(1)},\\dots,x^{(n)}\\}$ 为大小为 $n$ 的小批量。网络参数被认为是固定的。\n\n**表征稳定性分析**\n\n稳定性度量是 $S(x) = \\mathbb{E}_{\\mathcal{B}_1,\\mathcal{B}_2} \\left[ \\| y^{\\mathcal{B}_1}(x) - y^{\\mathcal{B}_2}(x) \\|_2^2 \\right]$，其中 $x$ 被包含在两个不同的小批量 $\\mathcal{B}_1$ 和 $\\mathcal{B}_2$ 中。\n\n1.  **批量归一化 (BN)**：对于输入 $x_i$，输出 $y_i$ 由 $y_i = \\gamma_i \\frac{x_i - \\mu_{\\mathcal{B},i}}{\\sqrt{\\sigma^2_{\\mathcal{B},i} + \\epsilon}} + \\beta_i$ 给出。统计量 $\\mu_{\\mathcal{B},i}$ 和 $\\sigma^2_{\\mathcal{B},i}$ 是在小批量 $\\mathcal{B}$ 上计算的。如果我们将小批量从 $\\mathcal{B}_1$ 更改为 $\\mathcal{B}_2$，这些统计量通常会发生变化。因此，通常情况下 $y^{\\mathcal{B}_1}(x) \\neq y^{\\mathcal{B}_2}(x)$。这意味着对于任何有限的批量大小 $n$，$S_{\\text{BN}}(x) > 0$。当 $n \\to \\infty$ 时，小批量统计量收敛于真实的总体统计量，因此来自两个大批量的统计量之间的差异趋近于零。因此，$S_{\\text{BN}}(x)$ 是 $n$ 的递减函数。\n\n2.  **层归一化 (LN)**：输出 $y_i$ 依赖于 $\\mu_{\\text{L}} = \\frac{1}{d}\\sum_{j=1}^d x_j$ 和 $\\sigma^2_{\\text{L}} = \\frac{1}{d}\\sum_{j=1}^d (x_j - \\mu_{\\text{L}})^2$。这些统计量是在单个样本 $x$ 的特征上计算的。它们完全独立于小批量 $\\mathcal{B}$ 中的任何其他样本。因此，对于任何包含 $x$ 的 $\\mathcal{B}_1, \\mathcal{B}_2$，$y^{\\mathcal{B}_1}(x) = y^{\\mathcal{B}_2}(x)$。这意味着 $S_{\\text{LN}}(x) = 0$。\n\n3.  **除法归一化 (DN)**：输出为 $y_i = \\frac{x_i}{\\sigma + \\sum_{j=1}^d w_{ij} |x_j|^p}$。此计算仅涉及单个输入向量 $x$ 的分量。它不依赖于小批量 $\\mathcal{B}$。因此，与 LN 一样，$y^{\\mathcal{B}_1}(x) = y^{\\mathcal{B}_2}(x)$，这意味着 $S_{\\text{DN}}(x) = 0$。\n\n**增益控制分析**\n\n让我们分析对输入进行乘法缩放 $x \\to \\alpha x$（其中 $\\alpha > 0$）的响应。\n\n1.  **层归一化**：新的均值是 $\\mu'_{\\text{L}} = \\alpha \\mu_{\\text{L}}$，新的方差是 $\\sigma'^2_{\\text{L}} = \\alpha^2 \\sigma^2_{\\text{L}}$。新的输出是 $y_i(\\alpha x) = \\gamma_i \\frac{\\alpha x_i - \\alpha \\mu_{\\text{L}}}{\\sqrt{\\alpha^2 \\sigma^2_{\\text{L}} + \\epsilon}} + \\beta_i$。如果我们假设 $\\epsilon$ 很小，则 $y_i(\\alpha x) \\approx \\gamma_i \\frac{\\alpha (x_i - \\mu_{\\text{L}})}{\\alpha \\sqrt{\\sigma^2_{\\text{L}}}} + \\beta_i = y_i(x)$。LN 使表征对单个样本的缩放近似不变。\n\n2.  **除法归一化**：新的输出是 $y_i(\\alpha x) = \\frac{\\alpha x_i}{\\sigma + \\sum_{j=1}^d w_{ij} |\\alpha x_j|^p} = \\frac{\\alpha x_i}{\\sigma + \\alpha^p \\sum_{j=1}^d w_{ij} |x_j|^p}$。该函数表现出压缩性响应。对于小的 $\\alpha$，$y_i(\\alpha x) \\approx \\frac{\\alpha x_i}{\\sigma}$，因此响应是线性的。对于大的 $\\alpha$，$y_i(\\alpha x) \\approx \\frac{\\alpha x_i}{\\alpha^p \\sum_j w_{ij} |x_j|^p} = \\alpha^{1-p} \\frac{x_i}{\\sum_j w_{ij} |x_j|^p}$。由于 $p \\ge 1$，响应要么饱和（当 $p = 1$ 时），要么收缩（当 $p > 1$ 时）。这种行为是神经增益控制的一个标志，特别是在早期视觉系统中的对比度增益控制。\n\n**逐项分析**\n\nA. **因为批量归一化依赖于小批量统计量 $(\\mu_{\\mathcal{B},i},\\sigma^2_{\\mathcal{B},i})$，所以 $S_{\\text{BN}}(x)$ 随着 $n$ 的增加而减小，但对于有限的 $n$ 不为零；层归一化产生 $S_{\\text{LN}}(x) = 0$ 对任何 $n$ 都成立，因为它只使用单个样本的统计量；除法归一化不依赖于 $\\mathcal{B}$，并通过其局部池化实现增益控制，从而降低了对均匀对比度缩放的敏感性，并倾向于改善与早期腹侧阶段的对齐度。**\n这个陈述是一系列正确事实的集合。\n- 对 $S_{\\text{BN}}(x)$ 的分析是正确的，如上所述。\n- $S_{\\text{LN}}(x) = 0$ 的结论是正确的。\n- 除法归一化确实不依赖于 $\\mathcal{B}$，这意味着 $S_{\\text{DN}}(x) = 0$。其公式实现了增益控制，降低了对输入缩放（对比度）的敏感性。这种机制是像 V1 这样的早期视觉区域中计算的经典模型，并且已知可以改善模型与这些大脑区域的对齐度。\n结论：**正确**。\n\nB. **在推理时，使用移动平均值 $(\\hat{\\mu}_i,\\hat{\\sigma}^2_i)$ 的批量归一化与层归一化相同，因此它们在所有层上具有相同的表征稳定性和大脑对齐度。**\n这个陈述是错误的。在推理时，对于特征 $i$ 的 BN 变换变为 $y_i = a_i x_i + b_i$，其中 $a_i = \\gamma_i / \\sqrt{\\hat{\\sigma}^2_i + \\epsilon}$ 和 $b_i = \\beta_i - \\gamma_i \\hat{\\mu}_i / \\sqrt{\\hat{\\sigma}^2_i + \\epsilon}$ 是常数。这是一个固定的、按特征进行的仿射变换。相比之下，层归一化计算依赖于当前输入样本 $x$ 的统计量 ($\\mu_{\\text{L}}, \\sigma^2_{\\text{L}}$)，并在特征间进行归一化。这些是根本不同的操作。因为前提是错误的，所以结论是无效的。\n结论：**不正确**。\n\nC. **对于 $p = 2$ 和 $\\sigma > 0$，除法归一化在乘法输入缩放的作用下产生压缩性响应，$y_i(\\alpha x) \\approx \\frac{\\alpha x_i}{\\sigma + \\alpha^2 \\sum_j w_{ij} |x_j|^2}$，相对于批量归一化（其效果取决于 $\\mathcal{B}$ 的分布）降低了对 $\\alpha$ 的敏感性；这一特性与早期视觉区域中改善的 RSA 对齐度一致，这些区域表现出对比度增益控制。**\n这个陈述是完全正确的。给出的 $y_i(\\alpha x)$ 公式是直接代入 DN 定义的结果。对于 $\\alpha > 1$，分母呈二次方增长，而分子呈线性增长，从而产生压缩性响应。这一特性模拟了对比度增益控制，这是早期视觉皮层神经元中一个有充分记录的特征。因此，结合这种机制是期望与那些大脑区域的 RSA 对齐度得到改善的一个有原则的理由。与 BN 的比较也是恰当的；BN 对单一样本缩放的响应是复杂的且依赖于批量的，不像 DN 那样具有清晰的、内在的增益控制。\n结论：**正确**。\n\nD. **层归一化近似于生物除法归一化，因为它使用层内所有特征的统计数据，从而实现交叉方向抑制，并且通常在这三种方法中与初级视觉皮层产生最强的对齐。**\n这个陈述是有缺陷的。虽然 LN 可以被看作是一种归一化形式，但它是对生物 DN 的一个非常粗糙的近似。生物 DN 涉及加权池化（$w_{ij}$），这种池化通常是局部的和经过调整的（例如，对方向敏感）。LN 使用对所有特征进行非加权的全局池化。这无法实现经过调整的*交叉方向*抑制，后者需要基于特征相似性的差异化抑制。此外，经验研究通常表明，与通用的 LN 或 BN 相比，更忠实的 DN 模型（具有学习的、局部的/经过调整的权重）能与 V1 数据产生更好的对齐。\n结论：**不正确**。\n\nE. **在为物体识别训练的分层 CNN 中，一种在早期阶段使用除法归一化，在更深阶段用层归一化替换批量归一化的配置，可以通过在早期阶段结合局部增益控制与在与下颞叶皮层（IT）选择性对齐的后期阶段使用与批量无关的单样本归一化，来提高表征稳定性和跨区域的大脑对齐度。**\n这个陈述描述了一种合理且复杂的建模策略。\n-   **表征稳定性**：通过用 DN 和 LN（其 $S(x) = 0$）替换 BN（其 $S_{\\text{BN}}(x) > 0$），根据问题的定义，模型的表征相对于批量构成变得完全稳定。\n-   **跨区域大脑对齐度**：该策略在神经科学上是有原则的。在早期阶段使用 DN 的动机是其在 V1/V2 中作为经典计算（局部增益控制）的角色。在对应于 IT 皮层的更深阶段使用 LN，用一种稳定的、与批量无关的归一化取代了 BN 的训练时期的不稳定性。这可能更好地捕捉 IT 神经元的稳定物体选择性。该摘要正确地阐述了这一双重基本原理。这种方法与该领域的前沿研究方向一致。\n结论：**正确**。\n\n因此，陈述 A、C 和 E 都与第一性原理和广泛报道的经验趋势一致。",
            "answer": "$$\\boxed{ACE}$$"
        }
    ]
}