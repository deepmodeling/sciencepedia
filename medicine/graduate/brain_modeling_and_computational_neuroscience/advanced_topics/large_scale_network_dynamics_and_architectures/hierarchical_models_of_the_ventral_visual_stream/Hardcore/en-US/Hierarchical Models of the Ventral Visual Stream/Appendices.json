{
    "hands_on_practices": [
        {
            "introduction": "To build a deep understanding of hierarchical models, we begin with the fundamental computational motif inspired by the primary visual cortex. This practice will guide you through the core operations of a simple-cell (S1) layer, which performs feature detection via linear filtering, and a complex-cell (C1) layer, which builds tolerance to small shifts in position through local pooling. By manually computing the response to a simple edge stimulus , you will gain a concrete intuition for how these models begin to construct invariant feature representations.",
            "id": "3988315",
            "problem": "Consider a canonical feedforward hierarchical model of the ventral visual stream in which the Simple layer (S1) implements linear filtering akin to classical simple cells and the Complex layer (C1) implements local pooling akin to classical complex cells. Assume the following foundational operations: linear filtering by convolution for S1 and local maximum pooling for C1.\n\nYou are given a grayscale image stimulus $I \\in \\mathbb{R}^{4 \\times 4}$ containing a sharp vertical step edge, with pixel intensities\n$$\nI \\;=\\;\n\\begin{pmatrix}\n0 & 0 & 1 & 1 \\\\\n0 & 0 & 1 & 1 \\\\\n0 & 0 & 1 & 1 \\\\\n0 & 0 & 1 & 1\n\\end{pmatrix}.\n$$\nThe S1 stage is equipped with a single orientation-selective filter approximating a vertically oriented edge detector,\n$$\nF^{(v)} \\;=\\;\n\\begin{pmatrix}\n-1 & 0 & 1 \\\\\n-1 & 0 & 1 \\\\\n-1 & 0 & 1\n\\end{pmatrix}.\n$$\nDefine the S1 response at a valid location $(i,j)$ (where the $3 \\times 3$ filter fits inside the image) by rectified linear filtering\n$$\ns_{i,j} \\;=\\; \\max\\!\\left(0,\\;\\sum_{m=1}^{3}\\sum_{n=1}^{3} F^{(v)}_{m,n}\\,P_{i,j}(m,n)\\right),\n$$\nwhere $P_{i,j} \\in \\mathbb{R}^{3 \\times 3}$ is the image patch centered at $(i,j)$ (i.e., $P_{i,j}(m,n) = I(i+m-2,\\, j+n-2)$ using $1$-based indexing). Let the valid S1 centers be the set $\\{(2,2),(2,3),(3,2),(3,3)\\}$.\n\nDefine a single C1 unit that pools locally by the maximum over the window\n$$\nW \\;=\\; \\{(i,j) \\;\\big|\\; i \\in \\{2,3\\},\\; j \\in \\{2,3\\}\\}.\n$$\nThus, the C1 response is\n$$\nC1 \\;=\\; \\max_{(i,j)\\in W} s_{i,j}.\n$$\n\nTask: Compute the numerical value of $C1$ for the given stimulus and filter, and then interpret, in your derivation, how local maximum pooling in $W$ supports invariance to small stimulus translations relative to the filter. Express the final answer as a single real number. No rounding is required. No units are required.",
            "solution": "The problem requires the computation of a Complex layer (C1) response in a simple hierarchical model of the ventral visual stream. This involves two stages: first, computing the responses of Simple layer (S1) units via rectified linear filtering, and second, computing the C1 response by taking the maximum of the S1 responses over a specified pooling window.\n\nThe input is a $4 \\times 4$ grayscale image $I$ and a $3 \\times 3$ vertically oriented filter $F^{(v)}$:\n$$\nI \\;=\\;\n\\begin{pmatrix}\n0 & 0 & 1 & 1 \\\\\n0 & 0 & 1 & 1 \\\\\n0 & 0 & 1 & 1 \\\\\n0 & 0 & 1 & 1\n\\end{pmatrix}\n\\quad\\text{and}\\quad\nF^{(v)} \\;=\\;\n\\begin{pmatrix}\n-1 & 0 & 1 \\\\\n-1 & 0 & 1 \\\\\n-1 & 0 & 1\n\\end{pmatrix}.\n$$\nThe S1 response at a location $(i,j)$ is given by $s_{i,j} = \\max(0, \\text{linear response})$, where the linear response is the sum of element-wise products of the filter $F^{(v)}$ and the image patch $P_{i,j}$ centered at $(i,j)$. We must compute $s_{i,j}$ for all valid centers $(i,j) \\in \\{(2,2), (2,3), (3,2), (3,3)\\}$.\n\n1.  **Compute S1 response at $(i,j) = (2,2)$:**\n    The image patch $P_{2,2}$ is the $3 \\times 3$ region of $I$ centered at $(2,2)$, which spans rows $1$ to $3$ and columns $1$ to $3$.\n    $$\n    P_{2,2} \\;=\\;\n    \\begin{pmatrix}\n    0 & 0 & 1 \\\\\n    0 & 0 & 1 \\\\\n    0 & 0 & 1\n    \\end{pmatrix}.\n    $$\n    The linear response is the dot product of the flattened filter and patch, or $\\sum_{m,n} F^{(v)}_{m,n} P_{2,2}(m,n)$.\n    $$\n    \\text{Linear Response}_{(2,2)} = (-1)(0) + (0)(0) + (1)(1) + (-1)(0) + (0)(0) + (1)(1) + (-1)(0) + (0)(0) + (1)(1) = 1+1+1 = 3.\n    $$\n    The rectified S1 response is:\n    $$\n    s_{2,2} = \\max(0, 3) = 3.\n    $$\n\n2.  **Compute S1 response at $(i,j) = (2,3)$:**\n    The image patch $P_{2,3}$ is centered at $(2,3)$, spanning rows $1$ to $3$ and columns $2$ to $4$.\n    $$\n    P_{2,3} \\;=\\;\n    \\begin{pmatrix}\n    0 & 1 & 1 \\\\\n    0 & 1 & 1 \\\\\n    0 & 1 & 1\n    \\end{pmatrix}.\n    $$\n    The linear response is:\n    $$\n    \\text{Linear Response}_{(2,3)} = (-1)(0) + (0)(1) + (1)(1) + (-1)(0) + (0)(1) + (1)(1) + (-1)(0) + (0)(1) + (1)(1) = 1+1+1 = 3.\n    $$\n    The rectified S1 response is:\n    $$\n    s_{2,3} = \\max(0, 3) = 3.\n    $$\n\n3.  **Compute S1 response at $(i,j) = (3,2)$:**\n    The image patch $P_{3,2}$ is centered at $(3,2)$, spanning rows $2$ to $4$ and columns $1$ to $3$. Due to the vertical uniformity of the input image $I$, this patch is identical to $P_{2,2}$.\n    $$\n    P_{3,2} \\;=\\; P_{2,2} \\;=\\;\n    \\begin{pmatrix}\n    0 & 0 & 1 \\\\\n    0 & 0 & 1 \\\\\n    0 & 0 & 1\n    \\end{pmatrix}.\n    $$\n    Therefore, the response is the same as for $(2,2)$.\n    $$\n    s_{3,2} = s_{2,2} = 3.\n    $$\n\n4.  **Compute S1 response at $(i,j) = (3,3)$:**\n    The image patch $P_{3,3}$ is centered at $(3,3)$, spanning rows $2$ to $4$ and columns $2$ to $4$. Due to the vertical uniformity of the input image $I$, this patch is identical to $P_{2,3}$.\n    $$\n    P_{3,3} \\;=\\; P_{2,3} \\;=\\;\n    \\begin{pmatrix}\n    0 & 1 & 1 \\\\\n    0 & 1 & 1 \\\\\n    0 & 1 & 1\n    \\end{pmatrix}.\n    $$\n    Therefore, the response is the same as for $(2,3)$.\n    $$\n    s_{3,3} = s_{2,3} = 3.\n    $$\n\nThe set of S1 responses within the pooling window $W = \\{(2,2), (2,3), (3,2), (3,3)\\}$ is $\\{s_{2,2}, s_{2,3}, s_{3,2}, s_{3,3}\\} = \\{3, 3, 3, 3\\}$. The filter $F^{(v)}$ robustly detects the vertical edge feature at all four positions within the $2 \\times 2$ grid of S1 units.\n\nNow, we compute the C1 response by taking the maximum over these S1 responses:\n$$\nC1 \\;=\\; \\max_{(i,j)\\in W} s_{i,j} \\;=\\; \\max(s_{2,2}, s_{2,3}, s_{3,2}, s_{3,3}) = \\max(3, 3, 3, 3) = 3.\n$$\n\nThe final numerical value of the C1 unit's response is $3$.\n\nThe derivation illustrates how local maximum pooling supports translation invariance. The S1 layer acts as a layer of feature detectors; in this case, a high $s_{i,j}$ value signals the presence of a vertical edge at location $(i,j)$. The C1 layer pools the outputs of these detectors. By computing the maximum, the C1 unit's response is determined by the strongest feature signal within its pooling region, effectively ignoring which specific S1 detector produced that signal. This makes the C1 response robust to the precise location of the feature.\n\nTo make this concrete, consider what would happen if the stimulus edge shifted one pixel to the left, yielding a new image $I'$:\n$$\nI' \\;=\\;\n\\begin{pmatrix}\n0 & 1 & 1 & 0 \\\\\n0 & 1 & 1 & 0 \\\\\n0 & 1 & 1 & 0 \\\\\n0 & 1 & 1 & 0\n\\end{pmatrix}.\n$$\nRepeating the S1 calculation for this shifted stimulus $I'$ over the same window $W$ would yield a different set of S1 responses: $\\{s'_{2,2}, s'_{2,3}, s'_{3,2}, s'_{3,3}\\} = \\{3, 0, 3, 0\\}$. The pattern of activity in the S1 layer has shifted. However, the C1 response would be:\n$$\nC1' \\;=\\; \\max(3, 0, 3, 0) = 3.\n$$\nThe output of the C1 unit remains unchanged despite the translation of the stimulus. This demonstrates that the maximum pooling operation provides tolerance to small shifts in feature position, a foundational property for robust object recognition known as translation invariance.",
            "answer": "$$\\boxed{3}$$"
        },
        {
            "introduction": "The power of hierarchical models stems from stacking multiple processing stages, which allows for the progressive aggregation of information over larger spatial areas. A key property that quantifies this process is the receptive field (RF) size of a neuron. This exercise  asks you to derive and apply the recursive formula for calculating RF size in a multi-layer model, providing a quantitative understanding of the trade-off between building context-aware representations and losing fine-grained spatial precision.",
            "id": "3988326",
            "problem": "A hierarchical model of the ventral visual stream can be idealized as a feedforward stack of locally connected stages, analogous to a Convolutional Neural Network (CNN), where each layer applies spatially localized linear filters followed by a downsampling specified by a stride. In such models, the concept of a receptive field formalizes how many input units (pixels) can influence a single unit at a deeper layer. Assume a three-layer feedforward model whose layers are strictly spatially local and translation equivariant, with square, isotropic filters of sizes $7 \\times 7$, $5 \\times 5$, and $3 \\times 3$ at layers $1$, $2$, and $3$ respectively, and strides $1$, $2$, and $2$ for layers $1$, $2$, and $3$ respectively. Assume unit dilation, no skip connections, and that padding (if present) does not change the count of distinct input pixels that can influence a unit at a deeper layer. Define the receptive field for a unit in layer $l$ as the number of distinct input pixels along one spatial axis (i.e., the linear extent in pixels) of the smallest contiguous input interval such that changes in those input pixels can affect the unit’s output, consistent with the standard convolutional support geometry.\n\nStarting from first principles—namely, the definitions of local connectivity and stride in hierarchical models—derive the recursive relationship that governs how receptive field extent grows through layers and use it to compute the linear receptive field size (in pixels along one axis) for a unit in layer $3$ of this model. Then provide a brief interpretation of what this receptive field size implies for the integration of contextual information in the ventral stream hierarchy, focusing on the trade-off between spatial resolution and context aggregation. Express the final numerical answer as the linear receptive field size along one axis, in pixels. No rounding is required.",
            "solution": "The primary task is to determine the linear receptive field size for a unit in the third layer of a simplified hierarchical model. To do this, we must first derive the general recursive relationship governing the growth of the receptive field size across layers.\n\nLet $RF_l$ denote the linear receptive field size (the extent along one axis) of a unit in layer $l$, measured in terms of pixels in the input layer (layer $0$).\nLet $k_l$ be the linear size of the filter (kernel) at layer $l$.\nLet $s_l$ be the stride of the convolution at layer $l$.\n\nThe receptive field of a unit in a given layer is the region of the input space that can influence its activation. We can establish a recursive formula for $RF_l$.\n\nFor the first layer ($l=1$), a unit's output is computed by convolving a filter of size $k_1$ directly with the input image. Therefore, the number of input pixels along one axis that can affect this unit is simply the filter size.\n$$RF_1 = k_1$$\n\nNow, consider a unit in layer $l$ (for $l > 1$). Its output is computed by applying a filter of size $k_l$ to the output feature map of layer $l-1$. This means the unit's activation depends on a contiguous block of $k_l$ units along one axis from layer $l-1$. The total receptive field of the layer-$l$ unit is the union of the receptive fields of these $k_l$ units from layer $l-1$.\n\nTo find the size of this union, we need to know how the receptive fields of adjacent units in the layer $l-1$ feature map are spaced in the original input space. This spacing, which we call the cumulative stride or jump, $J_{l-1}$, is the product of the strides of all preceding layers.\nThe jump $J_i$ is the distance in input pixels between the centers of the receptive fields of two adjacent units in the output of layer $i$.\nFor layer $1$, a stride of $s_1$ means adjacent units' receptive fields are centered $s_1$ pixels apart on the input. So, $J_1 = s_1$.\nFor layer $2$, a stride of $s_2$ operates on the feature map of layer $1$. A single step in the layer $2$ map corresponds to a step of size $s_1$ in the layer $1$ map. Thus, a single step in the layer $2$ output corresponds to a jump of $s_2 \\times J_1 = s_2 s_1$ pixels on the input.\nIn general, the cumulative stride up to layer $l-1$ is:\n$$J_{l-1} = \\prod_{i=1}^{l-1} s_i$$\n\nA unit in layer $l$ sees $k_l$ adjacent units from layer $l-1$. The receptive fields of these $k_l$ units each have a size of $RF_{l-1}$ on the input. The centers of these receptive fields are separated by $J_{l-1}$ pixels. The total extent is the size of the receptive field of the first unit in the block, plus the additional distance covered by the remaining $k_l-1$ units. This additional distance is $(k_l-1) \\times J_{l-1}$.\nTherefore, the recursive relationship is:\n$$RF_l = RF_{l-1} + (k_l - 1) \\times J_{l-1} = RF_{l-1} + (k_l - 1) \\prod_{i=1}^{l-1} s_i$$\nThis is the recursive relationship that governs how receptive field extent grows through the layers.\n\nNow, we apply this formula to the specific problem. The given parameters are:\nFilter sizes: $k_1 = 7$, $k_2 = 5$, $k_3 = 3$.\nStrides: $s_1 = 1$, $s_2 = 2$, $s_3 = 2$. Note that $s_3$ is not needed for calculating $RF_3$ but would be needed for $RF_4$.\n\nStep 1: Compute the receptive field size for a unit in layer $1$.\nUsing the base case:\n$$RF_1 = k_1 = 7$$\nA unit in layer $1$ has a receptive field size of $7$ pixels.\n\nStep 2: Compute the receptive field size for a unit in layer $2$.\nUsing the recursive formula for $l=2$:\n$$RF_2 = RF_1 + (k_2 - 1) \\prod_{i=1}^{1} s_i = RF_1 + (k_2 - 1) s_1$$\nSubstituting the values:\n$$RF_2 = 7 + (5 - 1) \\times 1 = 7 + 4 = 11$$\nA unit in layer $2$ has a receptive field size of $11$ pixels.\n\nStep 3: Compute the receptive field size for a unit in layer $3$.\nUsing the recursive formula for $l=3$:\n$$RF_3 = RF_2 + (k_3 - 1) \\prod_{i=1}^{2} s_i = RF_2 + (k_3 - 1) s_1 s_2$$\nSubstituting the values:\n$$RF_3 = 11 + (3 - 1) \\times (1 \\times 2) = 11 + 2 \\times 2 = 11 + 4 = 15$$\nThe linear receptive field size for a unit in layer $3$ is $15$ pixels.\n\nInterpretation:\nThe calculated receptive field size of $15 \\times 15$ pixels for a unit in layer $3$ encapsulates a core principle of hierarchical processing in the ventral visual stream. There is a fundamental trade-off between the aggregation of contextual information and the preservation of fine-grained spatial resolution.\n\nContext Aggregation: The receptive field size increases with each layer, from $7 \\times 7$ at layer $1$ to $11 \\times 11$ at layer $2$, and finally to $15 \\times 15$ at layer $3$. This growth demonstrates that higher-level units integrate information over progressively larger areas of the input. This allows the model to build representations of increasingly complex and abstract features. A layer-$3$ unit can respond to a large-scale pattern or object part by combining simpler features (e.g., edges, textures) detected by lower-level units across its $15 \\times 15$ input window.\n\nLoss of Spatial Resolution: This aggregation of context is enabled by downsampling, implemented here by strides greater than one ($s_2=2, s_3=2$). While a layer-$3$ unit is sensitive to stimuli within a large $15 \\times 15$ area, it has poor acuity regarding the precise location of features within that area. A feature could shift several pixels within the $15 \\times 15$ field without changing the identity of which layer-$3$ unit is activated. This creates positional invariance.\n\nThis trade-off is central to the function of the ventral (\"what\") pathway, which is primarily concerned with object recognition. The system systematically sacrifices spatial precision (\"where\") to build representations that are selective for object identity (\"what\") and tolerant to variations in position, scale, and pose. The hierarchical increase in receptive field size is the key mechanism for achieving this context-dependent, yet spatially-invariant, representation.",
            "answer": "$$\\boxed{15}$$"
        },
        {
            "introduction": "Modern hierarchical models, particularly those implemented as Convolutional Neural Networks (CNNs), employ normalization techniques to stabilize training and improve performance. This practice  challenges you to compare three distinct normalization schemes: batch normalization, layer normalization, and the biologically-inspired divisive normalization. By analyzing their mechanisms and implications for representation stability and brain alignment, you will explore how architectural choices can be guided by both engineering principles and neuroscientific plausibility.",
            "id": "3988310",
            "problem": "A Convolutional Neural Network (CNN) is trained as a hierarchical model of the ventral visual stream, with successive convolutional stages intended to approximate the computational roles of primary visual cortex, secondary visual cortex, and inferior temporal cortex (IT). Consider three normalization schemes applied at every stage: batch normalization, layer normalization, and biologically motivated divisive normalization. Let $x \\in \\mathbb{R}^d$ denote the pre-normalization activation vector for a single sample at a given stage, indexed by feature $i \\in \\{1,\\dots,d\\}$. Let the mini-batch be $\\mathcal{B} = \\{x^{(1)},\\dots,x^{(n)}\\}$ of size $n$.\n\nBatch normalization transforms each feature by\n$$\ny_i = \\gamma_i \\frac{x_i - \\mu_{\\mathcal{B},i}}{\\sqrt{\\sigma^2_{\\mathcal{B},i} + \\epsilon}} + \\beta_i,\n$$\nwhere $\\mu_{\\mathcal{B},i}$ and $\\sigma^2_{\\mathcal{B},i}$ are the mini-batch mean and variance of feature $i$, $\\epsilon > 0$ is a small constant, and $(\\gamma_i,\\beta_i)$ are learned affine parameters. At inference, running estimates $(\\hat{\\mu}_i,\\hat{\\sigma}^2_i)$ computed during training are used.\n\nLayer normalization transforms by\n$$\ny_i = \\gamma_i \\frac{x_i - \\mu_{\\text{L}}}{\\sqrt{\\sigma^2_{\\text{L}} + \\epsilon}} + \\beta_i,\n$$\nwhere $\\mu_{\\text{L}} = \\frac{1}{d}\\sum_{j=1}^d x_j$ and $\\sigma^2_{\\text{L}} = \\frac{1}{d}\\sum_{j=1}^d (x_j - \\mu_{\\text{L}})^2$ are per-sample statistics over features.\n\nBiologically motivated divisive normalization models neuronal gain control by\n$$\ny_i = \\frac{x_i}{\\sigma + \\sum_{j=1}^d w_{ij} |x_j|^p},\n$$\nwhere $w_{ij} \\ge 0$ encodes a local pooling structure (e.g., tuned to receptive field or orientation similarity), $\\sigma > 0$ is a semi-saturation constant, and $p \\ge 1$ controls nonlinearity.\n\nDefine representation stability to batch composition as the expected squared difference for a fixed $x$ when the batch changes:\n$$\nS_{\\text{BN}}(x) = \\mathbb{E}_{\\mathcal{B}_1,\\mathcal{B}_2} \\left[ \\| y^{\\mathcal{B}_1}(x) - y^{\\mathcal{B}_2}(x) \\|_2^2 \\right],\n$$\nwith analogous definitions for $S_{\\text{LN}}(x)$ and $S_{\\text{DN}}(x)$, holding the network parameters fixed and the same $x$ while varying only $\\mathcal{B}$.\n\nBrain alignment is evaluated by representational similarity analysis (RSA): for a set of images $\\{I_k\\}$, compute representational dissimilarity matrices from model layer responses and from neural recordings, and measure the correlation $\\rho$ between model and neural dissimilarity structures. The hierarchical alignment goal is that earlier model stages align with primary or secondary visual cortex, and later stages align with inferior temporal cortex (IT).\n\nWhich of the following statements is most consistent with first-principles reasoning about the mechanisms above and with widely reported empirical trends in brain modeling?\n\nA. Because batch normalization depends on mini-batch statistics $(\\mu_{\\mathcal{B},i},\\sigma^2_{\\mathcal{B},i})$, $S_{\\text{BN}}(x)$ decreases as $n$ increases but is nonzero for finite $n$; layer normalization yields $S_{\\text{LN}}(x) = 0$ for any $n$ because it uses only per-sample statistics; divisive normalization does not depend on $\\mathcal{B}$ and, by its local pooling, implements gain control that reduces sensitivity to uniform contrast scaling and tends to improve alignment with early ventral stages.\n\nB. At inference, batch normalization using running averages $(\\hat{\\mu}_i,\\hat{\\sigma}^2_i)$ is identical to layer normalization, so both have identical representation stability and brain alignment across all layers.\n\nC. For $p = 2$ and $\\sigma > 0$, divisive normalization yields compressive responses under multiplicative input scaling, $y_i(\\alpha x) \\approx \\frac{\\alpha x_i}{\\sigma + \\alpha^2 \\sum_j w_{ij} |x_j|^2}$, reducing sensitivity to $\\alpha$ relative to batch normalization whose effect depends on the distribution of $\\mathcal{B}$; this property is consistent with improved RSA alignment in early visual areas, which exhibit contrast gain control.\n\nD. Layer normalization approximates biological divisive normalization because it uses statistics over all features within a layer, thereby implementing cross-orientation suppression and typically yielding the strongest alignment with primary visual cortex among the three methods.\n\nE. In hierarchical CNNs trained for object recognition, a configuration in which early stages use divisive normalization and deeper stages replace batch normalization with layer normalization can improve representation stability and cross-area brain alignment, by combining local gain control in early stages with batch-independent per-sample normalization in later stages that align with inferior temporal cortex (IT) selectivity.\n\nSelect all that apply.",
            "solution": "We will analyze the properties of each normalization scheme based on the provided definitions.\n\nLet $x \\in \\mathbb{R}^d$ be a pre-normalization activation for a single sample, and $\\mathcal{B} = \\{x^{(1)},\\dots,x^{(n)}\\}$ be a mini-batch of size $n$. The network parameters are considered fixed.\n\n**Representation Stability Analysis**\n\nThe stability metric is $S(x) = \\mathbb{E}_{\\mathcal{B}_1,\\mathcal{B}_2} \\left[ \\| y^{\\mathcal{B}_1}(x) - y^{\\mathcal{B}_2}(x) \\|_2^2 \\right]$, where $x$ is included in two different mini-batches $\\mathcal{B}_1$ and $\\mathcal{B}_2$.\n\n1.  **Batch Normalization (BN)**: The output $y_i$ for an input $x_i$ is given by $y_i = \\gamma_i \\frac{x_i - \\mu_{\\mathcal{B},i}}{\\sqrt{\\sigma^2_{\\mathcal{B},i} + \\epsilon}} + \\beta_i$. The statistics $\\mu_{\\mathcal{B},i}$ and $\\sigma^2_{\\mathcal{B},i}$ are computed over the mini-batch $\\mathcal{B}$. If we change the mini-batch from $\\mathcal{B}_1$ to $\\mathcal{B}_2$, these statistics will generally change. Thus, $y^{\\mathcal{B}_1}(x) \\neq y^{\\mathcal{B}_2}(x)$ in general. This means $S_{\\text{BN}}(x) > 0$ for any finite batch size $n$. As $n \\to \\infty$, the mini-batch statistics converge to the true population statistics, so the difference between statistics from two large batches approaches zero. Consequently, $S_{\\text{BN}}(x)$ is a decreasing function of $n$.\n\n2.  **Layer Normalization (LN)**: The output $y_i$ depends on $\\mu_{\\text{L}} = \\frac{1}{d}\\sum_{j=1}^d x_j$ and $\\sigma^2_{\\text{L}} = \\frac{1}{d}\\sum_{j=1}^d (x_j - \\mu_{\\text{L}})^2$. These statistics are computed over the features of the single sample $x$. They are completely independent of any other samples in the mini-batch $\\mathcal{B}$. Therefore, $y^{\\mathcal{B}_1}(x) = y^{\\mathcal{B}_2}(x)$ for any $\\mathcal{B}_1, \\mathcal{B}_2$ containing $x$. This implies $S_{\\text{LN}}(x) = 0$.\n\n3.  **Divisive Normalization (DN)**: The output is $y_i = \\frac{x_i}{\\sigma + \\sum_{j=1}^d w_{ij} |x_j|^p}$. This computation only involves the components of the single input vector $x$. It has no dependency on the mini-batch $\\mathcal{B}$. Thus, like LN, $y^{\\mathcal{B}_1}(x) = y^{\\mathcal{B}_2}(x)$, which implies $S_{\\text{DN}}(x) = 0$.\n\n**Gain Control Analysis**\n\nLet's analyze the response to a multiplicative scaling of the input, $x \\to \\alpha x$ for $\\alpha > 0$.\n\n1.  **Layer Normalization**: The new mean is $\\mu'_{\\text{L}} = \\alpha \\mu_{\\text{L}}$ and the new variance is $\\sigma'^2_{\\text{L}} = \\alpha^2 \\sigma^2_{\\text{L}}$. The new output is $y_i(\\alpha x) = \\gamma_i \\frac{\\alpha x_i - \\alpha \\mu_{\\text{L}}}{\\sqrt{\\alpha^2 \\sigma^2_{\\text{L}} + \\epsilon}} + \\beta_i$. If we assume $\\epsilon$ is small, $y_i(\\alpha x) \\approx \\gamma_i \\frac{\\alpha (x_i - \\mu_{\\text{L}})}{\\alpha \\sqrt{\\sigma^2_{\\text{L}}}} + \\beta_i = y_i(x)$. LN makes the representation approximately invariant to the scaling of an individual sample.\n\n2.  **Divisive Normalization**: The new output is $y_i(\\alpha x) = \\frac{\\alpha x_i}{\\sigma + \\sum_{j=1}^d w_{ij} |\\alpha x_j|^p} = \\frac{\\alpha x_i}{\\sigma + \\alpha^p \\sum_{j=1}^d w_{ij} |x_j|^p}$. This function exhibits a compressive response. For small $\\alpha$, $y_i(\\alpha x) \\approx \\frac{\\alpha x_i}{\\sigma}$, so the response is linear. For large $\\alpha$, $y_i(\\alpha x) \\approx \\frac{\\alpha x_i}{\\alpha^p \\sum_j w_{ij} |x_j|^p} = \\alpha^{1-p} \\frac{x_i}{\\sum_j w_{ij} |x_j|^p}$. Since $p \\ge 1$, the response either saturates (for $p = 1$) or contracts (for $p > 1$). This behavior is a hallmark of neural gain control, particularly contrast gain control in the early visual system.\n\n**Option-by-Option Analysis**\n\nA. **Because batch normalization depends on mini-batch statistics $(\\mu_{\\mathcal{B},i},\\sigma^2_{\\mathcal{B},i})$, $S_{\\text{BN}}(x)$ decreases as $n$ increases but is nonzero for finite $n$; layer normalization yields $S_{\\text{LN}}(x) = 0$ for any $n$ because it uses only per-sample statistics; divisive normalization does not depend on $\\mathcal{B}$ and, by its local pooling, implements gain control that reduces sensitivity to uniform contrast scaling and tends to improve alignment with early ventral stages.**\nThis statement is a collection of correct facts. \n- The analysis of $S_{\\text{BN}}(x)$ is correct, as derived above.\n- The conclusion that $S_{\\text{LN}}(x) = 0$ is correct.\n- Divisive normalization indeed does not depend on $\\mathcal{B}$, which implies $S_{\\text{DN}}(x) = 0$. Its formula implements gain control, reducing sensitivity to input scaling (contrast). This mechanism is a canonical model for computation in early visual areas like V1 and is known to improve model-to-brain alignment for these areas.\nVerdict: **Correct**.\n\nB. **At inference, batch normalization using running averages $(\\hat{\\mu}_i,\\hat{\\sigma}^2_i)$ is identical to layer normalization, so both have identical representation stability and brain alignment across all layers.**\nThis statement is incorrect. At inference, the BN transformation for feature $i$ becomes $y_i = a_i x_i + b_i$, where $a_i = \\gamma_i / \\sqrt{\\hat{\\sigma}^2_i + \\epsilon}$ and $b_i = \\beta_i - \\gamma_i \\hat{\\mu}_i / \\sqrt{\\hat{\\sigma}^2_i + \\epsilon}$ are constants. This is a fixed, per-feature affine transformation. Layer normalization, by contrast, computes statistics ($\\mu_{\\text{L}}, \\sigma^2_{\\text{L}}$) that depend on the current input sample $x$, normalizing across features. These are fundamentally different operations. Because the premise is false, the conclusion is invalid.\nVerdict: **Incorrect**.\n\nC. **For $p = 2$ and $\\sigma > 0$, divisive normalization yields compressive responses under multiplicative input scaling, $y_i(\\alpha x) \\approx \\frac{\\alpha x_i}{\\sigma + \\alpha^2 \\sum_j w_{ij} |x_j|^2}$, reducing sensitivity to $\\alpha$ relative to batch normalization whose effect depends on the distribution of $\\mathcal{B}$; this property is consistent with improved RSA alignment in early visual areas, which exhibit contrast gain control.**\nThis statement is precisely correct. The given formula for $y_i(\\alpha x)$ is a direct substitution into the DN definition. For $\\alpha > 1$, the denominator grows quadratically while the numerator grows linearly, resulting in a compressive response. This property models contrast gain control, a well-documented feature of neurons in early visual cortex. Therefore, incorporating this mechanism is a principled reason to expect improved RSA alignment with those brain areas. The comparison with BN is also apt; BN's response to single-sample scaling is complex and batch-dependent, unlike the clear, intrinsic gain control of DN.\nVerdict: **Correct**.\n\nD. **Layer normalization approximates biological divisive normalization because it uses statistics over all features within a layer, thereby implementing cross-orientation suppression and typically yielding the strongest alignment with primary visual cortex among the three methods.**\nThis statement is flawed. While LN can be viewed as a form of normalization, it is a very crude approximation of biological DN. Biological DN involves weighted pooling ($w_{ij}$) that is often local and tuned (e.g., to orientation). LN uses unweighted, global pooling across all features. This cannot implement tuned *cross-orientation* suppression, which requires differential suppression based on feature similarity. Furthermore, empirical studies generally show that more faithful models of DN (with learned, local/tuned weights) yield better alignment with V1 data than generic LN or BN.\nVerdict: **Incorrect**.\n\nE. **In hierarchical CNNs trained for object recognition, a configuration in which early stages use divisive normalization and deeper stages replace batch normalization with layer normalization can improve representation stability and cross-area brain alignment, by combining local gain control in early stages with batch-independent per-sample normalization in later stages that align with inferior temporal cortex (IT) selectivity.**\nThis statement describes a sound and sophisticated modeling strategy.\n-   **Representation Stability**: By replacing BN ($S_{\\text{BN}}(x) > 0$) with DN and LN (for which $S(x) = 0$), the model's representations become perfectly stable with respect to batch composition by the problem's definition.\n-   **Cross-Area Brain Alignment**: The strategy is neuroscientifically principled. Using DN in early stages is motivated by its role as a canonical computation in V1/V2 (local gain control). Using LN in deeper stages, which correspond to IT cortex, replaces the training-time instability of BN with a stable, batch-independent normalization. This may better capture the stable object selectivity of IT neurons. The summary correctly articulates this dual rationale. This approach is consistent with advanced research directions in the field.\nVerdict: **Correct**.\n\nTherefore, statements A, C, and E are all consistent with first principles and widely reported empirical trends.",
            "answer": "$$\\boxed{ACE}$$"
        }
    ]
}