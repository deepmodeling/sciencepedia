{
    "hands_on_practices": [
        {
            "introduction": "在神经科学中，一个基本的挑战是准确地描述神经元发放脉冲的统计特性。虽然泊松过程为描述脉冲计数提供了一个简单的基线模型，但真实神经元的发放活动通常表现出比泊松模型所预测的更大的变异性，即“超离散”现象。本练习将指导您通过构建一个泊松-伽马混合模型来解决这个问题，这是一种在统计学上更为严谨的方法，最终将引出负二项分布。通过亲手推导其方差，您将对超离散现象获得定量的理解，并学会如何利用离散度参数来控制模型的灵活性，这是精确建模神经活动数据的一项关键技能。",
            "id": "3993296",
            "problem": "考虑一个神经元群体活动的隐流形模型，其中低维隐状态$z$通过一个连接函数驱动单个神经元随时间变化的平均发放率，从而在固定的时间窗内产生脉冲计数的观测值$y \\in \\{0,1,2,\\dots\\}$。为了捕捉相对于泊松模型的过度离散现象，假设观测模型由以下分层结构定义：在给定瞬时率$\\lambda$的条件下，脉冲计数服从泊松随机变量$y \\mid \\lambda \\sim \\mathrm{Poisson}(\\lambda)$；而率本身由于未观测到的潜在变异性而波动，被建模为伽马随机变量$\\lambda \\sim \\mathrm{Gamma}(k,\\beta)$，其中形状参数$k0$，率参数$\\beta0$。假设隐状态$z$通过连接$\\mu = \\mathbb{E}[\\lambda]$决定$\\lambda$的均值，其中$\\mu$是$z$的任意正函数，例如广义线性模型 (GLM) 中常用的指数映射$\\mu = \\exp\\!\\big(C^{\\top} z + b\\big)$，其中$C$是载荷向量，$b$是偏置。\n\n仅使用泊松分布和伽马分布的定义以及全期望定律和全方差定律，首先根据$k$和$\\mu$选择伽马分布的率参数$\\beta$，使得$\\mathbb{E}[\\lambda] = \\mu$，从而为$y$定义一个均值为$\\mu$、离散度为$k$的负二项观测模型。然后，推导出无条件方差$\\mathrm{Var}[y]$关于$\\mu$和$k$的闭式表达式，该表达式量化了相对于泊松情况的过度离散程度。以$\\mathrm{Var}[y]$关于$\\mu$和$k$的闭式表达式形式给出你的最终答案。不需要数值近似，也没有单位。",
            "solution": "用户希望我解决以下问题：\n首先根据指定标准验证问题陈述。\n\n### 步骤1：提取已知条件\n- 观测值是脉冲计数 $y \\in \\{0, 1, 2, \\dots\\}$。\n- 脉冲计数的条件分布是泊松分布：$y \\mid \\lambda \\sim \\mathrm{Poisson}(\\lambda)$。\n- 瞬时率 $\\lambda$ 是一个随机变量。\n- 率的分布是伽马分布：$\\lambda \\sim \\mathrm{Gamma}(k, \\beta)$。\n- 形状参数为 $k  0$。\n- 率参数为 $\\beta  0$。\n- 率 $\\lambda$ 的均值记为 $\\mu$：$\\mathbb{E}[\\lambda] = \\mu$。\n- $\\mu$ 是隐状态 $z$ 的一个正函数。\n- 需要使用的工具是泊松分布和伽马分布的定义，以及全期望定律和全方差定律。\n- 第一个目标是根据 $k$ 和 $\\mu$ 确定伽马分布的率参数 $\\beta$。\n- 第二个目标是推导出无条件方差 $\\mathrm{Var}[y]$ 关于 $\\mu$ 和 $k$ 的表达式。\n\n### 步骤2：使用提取的已知条件进行验证\n- **科学依据**：该问题在统计学和计算神经科学中有充分的科学依据。泊松-伽马混合模型是建模过度离散计数数据（如神经元脉冲计数）的标准且成熟的方法。\n- **良态**：问题陈述清晰，并且基于所提供的信息和标准概率论，有一个唯一的、可推导的解。\n- **客观性**：语言正式、精确且客观，使用了标准的数学术语。\n- **完整性和一致性**：问题是自洽的。它提供了进行所需推导的所有必要定义和约束。它没有欠定或过约束。找出 $\\beta$ 的指令是问题任务的一部分，而不是一个缺失的信息。\n- **其他缺陷**：问题没有表现出任何其他缺陷，例如不切实际、病态、琐碎或无法验证。它代表了统计建模中的一个标准推导。\n\n### 步骤3：结论与行动\n问题有效。将提供完整的解答。\n\n### 解答推导\n\n该问题需要一个基于分层模型的两部分推导，其中脉冲计数 $y$ 条件性地服从泊松分布，其率参数 $\\lambda$ 服从伽马分布。\n\n首先，我们建立伽马分布参数与平均率 $\\mu$ 之间的关系。对于一个形状参数 $k  0$、率参数 $\\beta  0$ 的伽马分布随机变量 $\\lambda$，记为 $\\lambda \\sim \\mathrm{Gamma}(k, \\beta)$，其概率密度函数为 $f(\\lambda; k, \\beta) = \\frac{\\beta^k}{\\Gamma(k)} \\lambda^{k-1} \\exp(-\\beta \\lambda)$（对于 $\\lambda  0$）。该分布的均值为：\n$$\n\\mathbb{E}[\\lambda] = \\frac{k}{\\beta}\n$$\n问题指定 $\\lambda$ 的均值为 $\\mu$，即 $\\mathbb{E}[\\lambda] = \\mu$。通过令两个均值表达式相等，我们可以解出率参数 $\\beta$：\n$$\n\\mu = \\frac{k}{\\beta} \\implies \\beta = \\frac{k}{\\mu}\n$$\n这完成了问题的第一部分。这种重新参数化的方法根据均值 $\\mu$ 和形状/离散度参数 $k$ 来定义率 $\\lambda$ 的分布。\n\n接下来，我们推导脉冲计数的无条件方差 $\\mathrm{Var}[y]$。我们使用全方差定律，该定律指出对于任意两个随机变量 $y$ 和 $\\lambda$：\n$$\n\\mathrm{Var}[y] = \\mathbb{E}[\\mathrm{Var}[y \\mid \\lambda]] + \\mathrm{Var}[\\mathbb{E}[y \\mid \\lambda]]\n$$\n要应用这一定律，我们需要条件期望 $\\mathbb{E}[y \\mid \\lambda]$ 和条件方差 $\\mathrm{Var}[y \\mid \\lambda]$。问题陈述，给定 $\\lambda$ 时 $y$ 的条件分布是泊松分布，$y \\mid \\lambda \\sim \\mathrm{Poisson}(\\lambda)$。对于率参数为 $\\lambda$ 的泊松分布，其均值和方差都等于率参数：\n$$\n\\mathbb{E}[y \\mid \\lambda] = \\lambda\n$$\n$$\n\\mathrm{Var}[y \\mid \\lambda] = \\lambda\n$$\n将这些表达式代入全方差定律公式，我们得到：\n$$\n\\mathrm{Var}[y] = \\mathbb{E}[\\lambda] + \\mathrm{Var}[\\lambda]\n$$\n我们已知 $\\mathbb{E}[\\lambda] = \\mu$。剩下需要求解的项是 $\\mathrm{Var}[\\lambda]$。伽马分布 $\\lambda \\sim \\mathrm{Gamma}(k, \\beta)$ 的方差由下式给出：\n$$\n\\mathrm{Var}[\\lambda] = \\frac{k}{\\beta^2}\n$$\n现在，我们将先前推导出的 $\\beta$ 的表达式 $\\beta = \\frac{k}{\\mu}$ 代入 $\\lambda$ 的方差公式：\n$$\n\\mathrm{Var}[\\lambda] = \\frac{k}{\\left(\\frac{k}{\\mu}\\right)^2} = \\frac{k}{\\frac{k^2}{\\mu^2}} = \\frac{k \\mu^2}{k^2} = \\frac{\\mu^2}{k}\n$$\n最后，我们将 $\\mathbb{E}[\\lambda]$ 和 $\\mathrm{Var}[\\lambda]$ 的表达式代回 $\\mathrm{Var}[y]$ 的方程中：\n$$\n\\mathrm{Var}[y] = \\mu + \\frac{\\mu^2}{k}\n$$\n这就是脉冲计数 $y$ 的无条件方差的闭式表达式。这个结果是负二项分布的特征，负二项分布是泊松-伽马混合模型中 $y$ 的边际分布。方差由两部分组成：一部分等于均值 $\\mu$，这是简单泊松过程的方差；另一部分是一个额外的正项 $\\frac{\\mu^2}{k}$，它解释了由于潜在率 $\\lambda$ 的变异性而导致的过度离散。参数 $k$ 通常被称为离散度参数，其中较小的 $k$ 值对应于较大的过度离散。当 $k \\to \\infty$ 时，这个额外的方差项消失，$\\mathrm{Var}[y] \\to \\mu$，恢复到泊松情况。",
            "answer": "$$\n\\boxed{\\mu + \\frac{\\mu^2}{k}}\n$$"
        },
        {
            "introduction": "在构建了能够捕捉神经活动观测噪声的统计模型之后，下一步是为潜在的神经动力学过程本身建立一个合适的先验模型。本练习将引导您探索高斯过程因子分析（GPFA）中的一个核心概念：核函数（kernel）的选择，特别是比较平方指数核（Squared-Exponential kernel）和马特恩核（Matérn kernel）。通过分析它们的谱特性，您将学习到如何将核函数的抽象数学形式与推断出的神经轨迹的具体、可解释的平滑度联系起来，从而掌握如何为模型注入符合生物学直觉的先验假设。",
            "id": "3993294",
            "problem": "考虑在高斯过程因子分析（GPFA）中的一个潜在轨迹，其中每个潜在维度被建模为一个在连续时间内具有平稳协方差函数（核函数）的零均值高斯过程。考虑使用两种候选核函数来描述潜在动态：平方指数核函数和一个带有平滑度参数的 Matérn 核函数。设分箱观测区间为$\\Delta t = 20 \\, \\mathrm{ms}$，并考虑一个潜在长度尺度$\\ell = 50 \\, \\mathrm{ms}$，边际方差为$\\sigma^{2}$。\n\n平方指数核函数定义为$k_{\\mathrm{SE}}(\\tau) = \\sigma^{2} \\exp\\!\\big(-\\tau^{2}/(2 \\ell^{2})\\big)$。Matérn 核函数族由一个平滑度参数$\\nu > 0$和长度尺度$\\ell$参数化，其协方差$k_{\\mathrm{Mat}\\,\\nu}(\\tau)$产生的样本路径的平滑度由$\\nu$控制；请使用 Matérn 核函数的标准谱特征。假设潜在先验采用无混叠的连续时间建模，并通过在$\\Delta t$处进行分箱来引起离散采样。\n\n从平稳高斯过程的定义和维纳-辛钦定理（Wiener–Khinchin theorem，该定理通过傅里叶变换将协方差函数与双边功率谱密度联系起来）出发，推导每个核函数所蕴含的定性平滑度（样本路径的均方可微性）及其功率谱的渐近高频行为。然后，针对所选的箱体大小，计算在奈奎斯特角频率\n$$\n\\omega_{N} \\;=\\; \\frac{\\pi}{\\Delta t},\n$$\n处的归一化谱功率，即每个核函数的比率$R(\\omega_{N}) = S(\\omega_{N})/S(0)$，其中$S(\\omega)$表示双边功率谱密度。使用与连续时间的维纳-辛钦定理一致的约定，并用$\\ell$、$\\nu$和$\\Delta t$表示您的结果；然后对$\\Delta t = 20 \\, \\mathrm{ms}$、$\\ell = 50 \\, \\mathrm{ms}$以及$\\nu = 3/2$的 Matérn 情况进行数值评估。\n\n在指定参数下，哪个选项正确描述了这些核函数的样本路径平滑度和归一化的奈奎斯特谱功率？\n\nA. 平方指数潜在轨迹是所有阶均方可微的（实际上是解析的），而 $\\nu = 3/2$ 的 Matérn 产生一次均方可微的轨迹；平方指数的高频谱呈高斯衰减，形式为 $\\exp\\!\\big(-\\tfrac{1}{2}\\ell^{2}\\omega^{2}\\big)$，而 Matérn 的高频谱呈多项式衰减，形式为 $\\big(1 + \\ell^{2}\\omega^{2}/(2\\nu)\\big)^{-(\\nu + 1/2)}$。对于 $\\Delta t = 20 \\, \\mathrm{ms}$ 和 $\\ell = 50 \\, \\mathrm{ms}$，归一化的奈奎斯特比率为 $R_{\\mathrm{SE}}(\\omega_{N}) \\approx 4.0 \\times 10^{-14}$ 和 $R_{\\mathrm{Mat}\\,3/2}(\\omega_{N}) \\approx 2.15 \\times 10^{-3}$。\n\nB. 平方指数潜在轨迹比 $\\nu = 3/2$ 的 Matérn 更不平滑，且平方指数比 Matérn 具有更重的谱尾；对于 $\\Delta t = 20 \\, \\mathrm{ms}$ 和 $\\ell = 50 \\, \\mathrm{ms}$，$R_{\\mathrm{SE}}(\\omega_{N}) \\approx 2.15 \\times 10^{-3}$ 而 $R_{\\mathrm{Mat}\\,3/2}(\\omega_{N}) \\approx 4.0 \\times 10^{-14}$。\n\nC. 平方指数潜在轨迹是解析的，且 $\\nu = 3/2$ 的 Matérn 是一次均方可微的，但是使用以赫兹为单位的奈奎斯特频率 $f_{N} = 1/(2\\Delta t)$ 计算，而未转换为角频率时，得到的归一化奈奎斯特比率为 $R_{\\mathrm{SE}}(2\\pi f_{N}) \\approx 0.46$ 和 $R_{\\mathrm{Mat}\\,3/2}(2\\pi f_{N}) \\approx 0.09$（对于 $\\Delta t = 20 \\, \\mathrm{ms}$ 和 $\\ell = 50 \\, \\mathrm{ms}$）。\n\nD. 平方指数潜在轨迹是解析的，且 $\\nu = 3/2$ 的 Matérn 是一次均方可微的；平方指数的奈奎斯特比率如上所述为 $R_{\\mathrm{SE}}(\\omega_{N}) \\approx 4.0 \\times 10^{-14}$，但 Matérn 的奈奎斯特比率遵循 $\\big(1 + \\ell^{2}\\omega_{N}^{2}/(2\\nu)\\big)^{-\\nu}$，得出 $R_{\\mathrm{Mat}\\,3/2}(\\omega_{N}) \\approx 1.0 \\times 10^{-2}$（对于 $\\Delta t = 20 \\, \\mathrm{ms}$ 和 $\\ell = 50 \\, \\mathrm{ms}$）。",
            "solution": "用户提供了一个需要以严谨的 STEM 教授身份解决的问题。第一步是验证问题陈述。\n\n### 问题验证\n\n**步骤 1：提取已知条件**\n- **模型：** 高斯过程因子分析（GPFA）中的潜在轨迹。\n- **潜在过程：** 在连续时间内具有平稳协方差函数（核函数）的零均值高斯过程。\n- **观测区间：** $\\Delta t = 20 \\, \\mathrm{ms}$。\n- **潜在长度尺度：** $\\ell = 50 \\, \\mathrm{ms}$。\n- **边际方差：** $\\sigma^{2}$。\n- **核函数 1 (平方指数)：** $k_{\\mathrm{SE}}(\\tau) = \\sigma^{2} \\exp\\!\\big(-\\tau^{2}/(2 \\ell^{2})\\big)$。\n- **核函数 2 (Matérn)：** $k_{\\mathrm{Mat}\\,\\nu}(\\tau)$，平滑度参数 $\\nu  0$。要使用的具体情况是 $\\nu=3/2$。问题指定使用标准的谱特征。\n- **建模假设：** 潜在先验采用无混叠的连续时间建模，并通过在 $\\Delta t$ 处进行分箱来引起离散采样。\n- **奈奎斯特角频率：** $\\omega_{N} = \\frac{\\pi}{\\Delta t}$。\n- **待计算量：** 在奈奎斯特角频率处的归一化谱功率，$R(\\omega_{N}) = S(\\omega_{N})/S(0)$，其中 $S(\\omega)$ 是双边功率谱密度。\n\n**步骤 2：使用提取的已知条件进行验证**\n- **科学基础：** 该问题坚实地植根于随机过程理论，特别是高斯过程，这是现代统计学、机器学习和计算神经科学的基石。协方差核（平方指数、Matérn）、维纳-辛钦定理、功率谱密度和均方可微性等概念都是标准且定义明确的。\n- **适定性：** 该问题要求推导定性属性（平滑度）并计算一个具体的、定义明确的定量度量（$R(\\omega_N)$）。所有必要的参数和定义都已提供。存在唯一解，并且可以从已知条件推导出来。\n- **客观性：** 该问题以精确、客观的数学语言陈述。没有主观或含糊不清的术语。\n- **一致性与完整性：** 该问题是自洽的。所提供的参数（$\\Delta t, \\ell, \\nu$）足以进行所需的计算。对“Matérn 核函数的标准谱特征”的引用是对文献中标准公式的明确引用。\n\n**步骤 3：结论与行动**\n- **结论：** 问题陈述是有效的。它在科学上是合理的，是适定的、客观的和完整的。\n- **行动：** 继续进行推导和求解。\n\n### 推导与求解\n\n问题的核心在于将平稳高斯过程的协方差函数 $k(\\tau)$ 与其样本路径属性（平滑度）和其功率谱密度（PSD）$S(\\omega)$ 联系起来。\n\n**1. 理论框架：平滑度与功率谱密度（PSD）**\n\n维纳-辛钦定理指出，平稳过程的 PSD $S(\\omega)$ 和自协方差函数 $k(\\tau)$ 构成一个傅里叶变换对。我们使用以下约定：\n$$ S(\\omega) = \\int_{-\\infty}^{\\infty} k(\\tau) e^{-i\\omega\\tau} \\, d\\tau $$\n高斯过程样本路径的平滑度由其协方差函数在原点的可微性决定，而这又与其 PSD 的高频衰减有关。一个过程是 $m$ 次均方可微的，当且仅当 $\\int_{-\\infty}^{\\infty} \\omega^{2m} S(\\omega) \\, d\\omega  \\infty$。这要求 PSD 的衰减速度快于 $\\omega^{-(2m+1)}$。\n\n**2. 平方指数（SE）核的分析**\n\n- **协方差与平滑度：** SE 核由 $k_{\\mathrm{SE}}(\\tau) = \\sigma^{2} \\exp\\!\\big(-\\tau^{2}/(2 \\ell^{2})\\big)$ 给出。该函数是关于 $\\tau$ 的高斯函数，并且在 $\\tau=0$ 及其他任何地方都是无限可微的（$C^{\\infty}$）。因此，具有 SE 核的高斯过程的样本路径是所有阶均方可微的。这样的路径被称为均方解析的。\n\n- **功率谱密度：** 高斯函数的傅里叶变换是另一个高斯函数。使用标准变换对 $\\mathcal{F}\\{e^{-a\\tau^2}\\} = \\sqrt{\\pi/a} \\, e^{-\\omega^2/(4a)}$，其中 $a = 1/(2\\ell^2)$，我们得到 PSD：\n$$ S_{\\mathrm{SE}}(\\omega) = \\sigma^2 \\mathcal{F}\\left\\{e^{-\\tau^2/(2\\ell^2)}\\right\\}(\\omega) = \\sigma^2 \\sqrt{2\\pi\\ell^2} \\exp\\left(-\\frac{\\ell^2\\omega^2}{2}\\right) $$\nPSD 随 $\\omega$ 呈高斯函数衰减，这比 $\\omega$ 的任何多项式都快。这与样本路径的无限均方可微性是一致的。\n\n**3. Matérn 核的分析**\n\n- **功率谱密度与平滑度：** Matérn 核族通常通过其 PSD 来定义，其 PSD 具有多项式衰减特性。PSD 的标准形式为：\n$$ S_{\\mathrm{Mat}\\,\\nu}(\\omega) \\propto \\left(\\frac{2\\nu}{\\ell^2} + \\omega^2\\right)^{-(\\nu + 1/2)} $$\n这可以重写以显示对无量纲量 $\\ell\\omega$ 的依赖性：\n$$ S_{\\mathrm{Mat}\\,\\nu}(\\omega) \\propto \\left(1 + \\frac{\\ell^2\\omega^2}{2\\nu}\\right)^{-(\\nu + 1/2)} $$\nPSD 渐近衰减为 $\\omega^{-2(\\nu+1/2)} = \\omega^{-(2\\nu+1)}$。满足 $m$ 次均方可微性的条件是 $2m  (2\\nu+1)-1 = 2\\nu$，或 $m  \\nu$。满足此条件的最大整数 $m$ 是 $m = \\lfloor \\nu \\rfloor$。\n对于指定的 $\\nu = 3/2 = 1.5$ 情况，我们有 $m  1.5$。$m$ 的最大整数值为 $1$。因此，该过程是一次均方可微的，但不是二次。\n\n**4. 归一化奈奎斯特谱功率的计算**\n\n我们被要求计算 $R(\\omega_N) = S(\\omega_N)/S(0)$，参数为 $\\Delta t = 20 \\, \\mathrm{ms} = 0.02 \\, \\mathrm{s}$ 和 $\\ell = 50 \\, \\mathrm{ms} = 0.05 \\, \\mathrm{s}$。\n\n首先，我们计算奈奎斯特角频率：\n$$ \\omega_N = \\frac{\\pi}{\\Delta t} = \\frac{\\pi}{0.02 \\, \\mathrm{s}} = 50\\pi \\, \\mathrm{rad/s} $$\n\n接下来，我们计算表达式中出现的无量纲项：\n$$ \\ell \\omega_N = (0.05 \\, \\mathrm{s}) \\times (50\\pi \\, \\mathrm{rad/s}) = 2.5\\pi $$\n$$ (\\ell \\omega_N)^2 = (2.5\\pi)^2 = 6.25\\pi^2 \\approx 6.25 \\times 9.8696044 \\approx 61.685 $$\n\n- **对于 SE 核：**\n归一化 PSD 为：\n$$ R_{\\mathrm{SE}}(\\omega) = \\frac{S_{\\mathrm{SE}}(\\omega)}{S_{\\mathrm{SE}}(0)} = \\frac{\\exp(-\\ell^2\\omega^2/2)}{\\exp(0)} = \\exp\\left(-\\frac{\\ell^2\\omega^2}{2}\\right) $$\n在奈奎斯特频率处：\n$$ R_{\\mathrm{SE}}(\\omega_N) = \\exp\\left(-\\frac{(\\ell\\omega_N)^2}{2}\\right) = \\exp\\left(-\\frac{6.25\\pi^2}{2}\\right) = \\exp(-3.125\\pi^2) $$\n$$ R_{\\mathrm{SE}}(\\omega_N) \\approx \\exp(-30.8425) \\approx 4.02 \\times 10^{-14} $$\n\n- **对于 $\\nu=3/2$ 的 Matérn 核：**\n归一化 PSD 为：\n$$ R_{\\mathrm{Mat}\\,\\nu}(\\omega) = \\frac{S_{\\mathrm{Mat}\\,\\nu}(\\omega)}{S_{\\mathrm{Mat}\\,\\nu}(0)} = \\left(1 + \\frac{\\ell^2\\omega^2}{2\\nu}\\right)^{-(\\nu + 1/2)} $$\n代入 $\\nu = 3/2$：\n$$ R_{\\mathrm{Mat}\\,3/2}(\\omega) = \\left(1 + \\frac{\\ell^2\\omega^2}{2(3/2)}\\right)^{-(3/2 + 1/2)} = \\left(1 + \\frac{\\ell^2\\omega^2}{3}\\right)^{-2} $$\n在奈奎斯特频率处：\n$$ R_{\\mathrm{Mat}\\,3/2}(\\omega_N) = \\left(1 + \\frac{(\\ell\\omega_N)^2}{3}\\right)^{-2} = \\left(1 + \\frac{6.25\\pi^2}{3}\\right)^{-2} $$\n$$ R_{\\mathrm{Mat}\\,3/2}(\\omega_N) \\approx \\left(1 + \\frac{61.685}{3}\\right)^{-2} \\approx (1 + 20.5617)^{-2} = (21.5617)^{-2} $$\n$$ R_{\\mathrm{Mat}\\,3/2}(\\omega_N) \\approx \\frac{1}{464.90} \\approx 0.002151 = 2.151 \\times 10^{-3} $$\n\n### 逐项分析\n\n**A. 平方指数潜在轨迹是所有阶均方可微的（实际上是解析的），而 $\\nu = 3/2$ 的 Matérn 产生一次均方可微的轨迹；平方指数的高频谱呈高斯衰减，形式为 $\\exp\\!\\big(-\\tfrac{1}{2}\\ell^{2}\\omega^{2}\\big)$，而 Matérn 的高频谱呈多项式衰减，形式为 $\\big(1 + \\ell^{2}\\omega^{2}/(2\\nu)\\big)^{-(\\nu + 1/2)}$。对于 $\\Delta t = 20 \\, \\mathrm{ms}$ 和 $\\ell = 50 \\, \\mathrm{ms}$，归一化的奈奎斯特比率为 $R_{\\mathrm{SE}}(\\omega_{N}) \\approx 4.0 \\times 10^{-14}$ 和 $R_{\\mathrm{Mat}\\,3/2}(\\omega_{N}) \\approx 2.15 \\times 10^{-3}$。**\n\n- 关于平滑度的陈述（SE 是解析的，Matérn $\\nu=3/2$ 是一次可微的）是**正确的**。\n- 关于 SE 谱函数形式的陈述（与 $\\exp(-\\ell^2\\omega^2/2)$ 成比例）是**正确的**。\n- 关于 Matérn 谱函数形式的陈述是**正确的**。\n- 计算值 $R_{\\mathrm{SE}}(\\omega_{N}) \\approx 4.0 \\times 10^{-14}$ 是**正确的**（我的计算：$4.02 \\times 10^{-14}$）。\n- 计算值 $R_{\\mathrm{Mat}\\,3/2}(\\omega_{N}) \\approx 2.15 \\times 10^{-3}$ 是**正确的**（我的计算：$2.151 \\times 10^{-3}$）。\n**结论：正确。**\n\n**B. 平方指数潜在轨迹比 $\\nu = 3/2$ 的 Matérn 更不平滑，且平方指数比 Matérn 具有更重的谱尾；对于 $\\Delta t = 20 \\, \\mathrm{ms}$ 和 $\\ell = 50 \\, \\mathrm{ms}$，$R_{\\mathrm{SE}}(\\omega_{N}) \\approx 2.15 \\times 10^{-3}$ 而 $R_{\\mathrm{Mat}\\,3/2}(\\omega_{N}) \\approx 4.0 \\times 10^{-14}$。**\n\n- 关于平滑度的陈述是**不正确的**。SE 是无限可微的，因此平滑得多。\n- 关于谱尾的陈述是**不正确的**。更重的尾部意味着更慢的衰减。SE 核具有高斯衰减（轻尾），而 Matérn 核具有多项式衰减（重尾）。\n- 比率的数值被互换了。**不正确**。\n**结论：不正确。**\n\n**C. 平方指数潜在轨迹是解析的，且 $\\nu = 3/2$ 的 Matérn 是一次均方可微的，但是使用以赫兹为单位的奈奎斯特频率 $f_{N} = 1/(2\\Delta t)$ 计算，而未转换为角频率时，得到的归一化奈奎斯特比率为 $R_{\\mathrm{SE}}(2\\pi f_{N}) \\approx 0.46$ 和 $R_{\\mathrm{Mat}\\,3/2}(2\\pi f_{N}) \\approx 0.09$（对于 $\\Delta t = 20 \\, \\mathrm{ms}$ 和 $\\ell = 50 \\, \\mathrm{ms}$）。**\n\n- 关于平滑度的陈述是**正确的**。\n- 比率的数值结果是**不正确的**。符号 $R(2\\pi f_N)$ 与 $R(\\omega_N)$ 相同。我对 $R(\\omega_N)$ 的正确计算得出的值约为 $4.0 \\times 10^{-14}$ 和 $2.15 \\times 10^{-3}$。数值 $0.46$ 和 $0.09$ 是不正确的。前面的文本描述了一个常见的计算错误（在需要 $\\omega$ 的地方使用 $f_N$），但即使这个错误也没有被一致地应用来得出给定的数字，而且无论如何，最终的陈述对 $R(2\\pi f_N)$ 的值做出了一个错误的断言。\n**结论：不正确。**\n\n**D. 平方指数潜在轨迹是解析的，且 $\\nu = 3/2$ 的 Matérn 是一次均方可微的；平方指数的奈奎斯特比率如上所述为 $R_{\\mathrm{SE}}(\\omega_{N}) \\approx 4.0 \\times 10^{-14}$，但 Matérn 的奈奎斯特比率遵循 $\\big(1 + \\ell^{2}\\omega_{N}^{2}/(2\\nu)\\big)^{-\\nu}$，得出 $R_{\\mathrm{Mat}\\,3/2}(\\omega_{N}) \\approx 1.0 \\times 10^{-2}$（对于 $\\Delta t = 20 \\, \\mathrm{ms}$ 和 $\\ell = 50 \\, \\mathrm{ms}$）。**\n\n- 关于平滑度的陈述是**正确的**。\n- 关于 SE 比率的陈述是**正确的**。\n- 为 Matérn 比率提供的公式是**不正确的**。指数应该是 $-(\\nu+1/2)$，而不是 $-\\nu$。\n- 数值结果 $R_{\\mathrm{Mat}\\,3/2}(\\omega_{N}) \\approx 1.0 \\times 10^{-2}$ 是从这个不正确的公式推导出来的，但由于公式本身不正确，结果和主张都存在根本性缺陷。\n**结论：不正确。**",
            "answer": "$$\\boxed{A}$$"
        },
        {
            "introduction": "一个完整的建模工作流程不仅包括模型拟合，还要求我们能够系统地比较不同模型（例如，具有不同潜在维度的模型），以找出那个在解释数据和避免过拟合之间达到最佳平衡的模型。本练习将引导您从第一性原理出发，推导在统计建模中无处不在的两个模型选择准则：赤池信息准则（AIC）和贝叶斯信息准则（BIC）。通过这个过程，您将揭开这些准则的神秘面纱，理解它们如何分别从信息论和贝叶斯推断的视角出发，为我们提供了一个量化模型拟合优度与模型复杂度之间权衡的数学框架。",
            "id": "3993305",
            "problem": "您正在对 $n$ 次统计独立的试验中同步记录的 $N$ 个神经元的神经群体活动进行建模。在每次试验 $i \\in \\{1,\\dots,n\\}$ 中，您观察到一个由形式如下的隐性流形模型生成的向量 $\\mathbf{y}_{i} \\in \\mathbb{R}^{N}$\n$$\n\\mathbf{y}_{i} \\sim p(\\mathbf{y}\\,|\\,\\boldsymbol{\\theta}, \\mathcal{M}),\n$$\n其中 $\\mathcal{M}$ 表示一个由连续隐变量 $\\mathbf{x}_{i} \\in \\mathbb{R}^{d}$ 定义的模型族，这些隐变量被边际化（积分掉），\n$$\np(\\mathbf{y}_{i}\\,|\\,\\boldsymbol{\\theta}, \\mathcal{M}) \\;=\\; \\int p(\\mathbf{y}_{i}, \\mathbf{x}_{i}\\,|\\,\\boldsymbol{\\theta}, \\mathcal{M}) \\, d\\mathbf{x}_{i},\n$$\n而 $\\boldsymbol{\\theta} \\in \\mathbb{R}^{k}$ 包含了在施加任何必要约束以消除不可辨识性（例如，旋转对称性）之后的所有可辨识自由参数，从而使得模型在最大似然估计量的一个邻域内是正则的。假设各次试验在给定 $\\boldsymbol{\\theta}$ 的条件下是独立同分布的，并令观测数据对数似然为\n$$\n\\ell_{n}(\\boldsymbol{\\theta}) \\;=\\; \\sum_{i=1}^{n} \\ln p(\\mathbf{y}_{i}\\,|\\,\\boldsymbol{\\theta}, \\mathcal{M}).\n$$\n令 $\\widehat{\\boldsymbol{\\theta}}$ 表示使 $\\ell_{n}(\\boldsymbol{\\theta})$ 最大化的最大似然估计量。假设模型族 $\\mathcal{M}$ 配备了一个先验密度 $\\pi(\\boldsymbol{\\theta}\\,|\\,\\mathcal{M})$，该密度在 $\\widehat{\\boldsymbol{\\theta}}$ 的一个邻域内为正且二次连续可微，并定义边际似然（模型证据）为\n$$\np(\\mathcal{D}\\,|\\,\\mathcal{M}) \\;=\\; \\int \\bigg[\\prod_{i=1}^{n} p(\\mathbf{y}_{i}\\,|\\,\\boldsymbol{\\theta}, \\mathcal{M})\\bigg] \\, \\pi(\\boldsymbol{\\theta}\\,|\\,\\mathcal{M}) \\, d\\boldsymbol{\\theta}.\n$$\n从以下基本依据出发：\n- 用于围绕 $f$ 的一个非退化最大值点对形如 $\\int \\exp\\{n f(\\boldsymbol{\\theta})\\} g(\\boldsymbol{\\theta}) \\, d\\boldsymbol{\\theta}$ 的积分进行渐近近似的拉普拉斯方法。\n- 在独立观测的标准正则性条件下，最大似然估计量的渐近正态性和一致性。\n- Kullback-Leibler (KL) 散度的定义，以及将期望样本外对数似然解释为最小化与数据生成分布之间期望 KL 散度的代理。\n\n推导（到 $n$ 的主导阶）两个模型选择准则，用最大化的观测数据对数似然 $\\ell_{n}(\\widehat{\\boldsymbol{\\theta}})$ 和参数维度 $k$ 表示：\n1. 通过拉普拉斯方法渐近近似 $-2 \\ln p(\\mathcal{D}\\,|\\,\\mathcal{M})$ 得到的准则，忽略不依赖于模型 $\\mathcal{M}$ 的加性常数。\n2. 通过使用二阶泰勒展开和 $\\widehat{\\boldsymbol{\\theta}}$ 的渐近协方差，渐近近似在一个大小为 $n$ 的独立重复样本上的期望样本外对数似然的 $-2$ 倍所得到的准则。\n\n将这两个准则分别解释为贝叶斯信息准则 (BIC) 和赤池信息准则 (AIC)，它们是针对隐变量模型的特例，使用了将隐变量积分掉的观测数据似然。将两个准则都以 $\\ell_{n}(\\widehat{\\boldsymbol{\\theta}})$、$k$ 和 $n$ 的闭式形式表示为待最小化的值。以一个双元素行矩阵的形式提供您的最终答案，该矩阵按顺序包含 $\\mathrm{AIC}(\\mathcal{M})$ 和 $\\mathrm{BIC}(\\mathcal{M})$ 的解析表达式。不需要进行数值计算；给出精确的符号形式。不包含任何单位。如果出现任何在模型间共享且不影响模型比较的常数，请在最终表达式中省略它们。",
            "solution": "该问题要求为神经群体活动的隐变量模型推导两个模型选择准则，即贝叶斯信息准则 (BIC) 和赤池信息准则 (AIC)。推导将基于所提供的基本原理，并侧重于观测数据对数似然，该似然将隐变量边际化。\n\n### 1. 贝叶斯信息准则 (BIC) 的推导\n\n第一个准则是从边际似然或模型证据 $p(\\mathcal{D}\\,|\\,\\mathcal{M})$ 的渐近近似推导出来的。边际似然定义为：\n$$\np(\\mathcal{D}\\,|\\,\\mathcal{M}) = \\int p(\\mathcal{D}\\,|\\,\\boldsymbol{\\theta},\\mathcal{M}) \\pi(\\boldsymbol{\\theta}\\,|\\,\\mathcal{M}) \\, d\\boldsymbol{\\theta} = \\int \\exp\\{\\ell_{n}(\\boldsymbol{\\theta})\\} \\pi(\\boldsymbol{\\theta}\\,|\\,\\mathcal{M}) \\, d\\boldsymbol{\\theta}\n$$\n其中 $\\ell_{n}(\\boldsymbol{\\theta})$ 是观测数据对数似然，$\\pi(\\boldsymbol{\\theta}\\,|\\,\\mathcal{M})$ 是 $k$ 维参数向量 $\\boldsymbol{\\theta}$ 上的先验。\n\n我们将使用拉普拉斯方法来近似这个对于大 $n$ 的积分。该方法通过将概率质量集中在后验分布的众数周围来近似积分。对于大的 $n$，似然项 $\\ell_{n}(\\boldsymbol{\\theta})$ 主导先验项 $\\ln \\pi(\\boldsymbol{\\theta}\\,|\\,\\mathcal{M})$，因此后验众数渐近地接近最大似然估计量 (MLE) $\\widehat{\\boldsymbol{\\theta}}$，后者使 $\\ell_{n}(\\boldsymbol{\\theta})$ 最大化。\n\n我们定义 $h(\\boldsymbol{\\theta}) = \\ell_{n}(\\boldsymbol{\\theta}) + \\ln \\pi(\\boldsymbol{\\theta}\\,|\\,\\mathcal{M})$。我们在 MLE $\\widehat{\\boldsymbol{\\theta}}$ 周围对 $h(\\boldsymbol{\\theta})$ 进行二阶泰勒展开。更精确的展开是围绕后验众数 $\\tilde{\\boldsymbol{\\theta}} = \\arg\\max_{\\boldsymbol{\\theta}} h(\\boldsymbol{\\theta})$，但对于大的 $n$，$\\tilde{\\boldsymbol{\\theta}} \\approx \\widehat{\\boldsymbol{\\theta}}$ 且主导阶项是相同的。让我们在 $\\widehat{\\boldsymbol{\\theta}}$ 周围展开 $\\ell_n(\\boldsymbol{\\theta})$：\n$$\n\\ell_{n}(\\boldsymbol{\\theta}) \\approx \\ell_{n}(\\widehat{\\boldsymbol{\\theta}}) + (\\boldsymbol{\\theta} - \\widehat{\\boldsymbol{\\theta}})^{T} \\nabla\\ell_{n}(\\widehat{\\boldsymbol{\\theta}}) + \\frac{1}{2} (\\boldsymbol{\\theta} - \\widehat{\\boldsymbol{\\theta}})^{T} \\nabla^2\\ell_{n}(\\widehat{\\boldsymbol{\\theta}}) (\\boldsymbol{\\theta} - \\widehat{\\boldsymbol{\\theta}})\n$$\n根据 MLE 的定义，$\\nabla\\ell_{n}(\\widehat{\\boldsymbol{\\theta}}) = \\mathbf{0}$。因此，展开式简化为：\n$$\n\\ell_{n}(\\boldsymbol{\\theta}) \\approx \\ell_{n}(\\widehat{\\boldsymbol{\\theta}}) - \\frac{1}{2} (\\boldsymbol{\\theta} - \\widehat{\\boldsymbol{\\theta}})^{T} J_{n}(\\widehat{\\boldsymbol{\\theta}}) (\\boldsymbol{\\theta} - \\widehat{\\boldsymbol{\\theta}})\n$$\n其中 $J_n(\\widehat{\\boldsymbol{\\theta}}) = -\\nabla^2\\ell_{n}(\\widehat{\\boldsymbol{\\theta}})$ 是观测到的费雪信息矩阵，它在最大值点是正定的。\n\n将此代入 $p(\\mathcal{D}\\,|\\,\\mathcal{M})$ 的积分中，并用平滑的先验项 $\\pi(\\boldsymbol{\\theta}\\,|\\,\\mathcal{M})$ 在峰值处的值 $\\pi(\\widehat{\\boldsymbol{\\theta}}\\,|\\,\\mathcal{M})$ 来近似，我们得到：\n$$\np(\\mathcal{D}\\,|\\,\\mathcal{M}) \\approx \\int \\exp\\left\\{ \\ell_{n}(\\widehat{\\boldsymbol{\\theta}}) - \\frac{1}{2} (\\boldsymbol{\\theta} - \\widehat{\\boldsymbol{\\theta}})^{T} J_{n}(\\widehat{\\boldsymbol{\\theta}}) (\\boldsymbol{\\theta} - \\widehat{\\boldsymbol{\\theta}}) \\right\\} \\pi(\\widehat{\\boldsymbol{\\theta}}\\,|\\,\\mathcal{M}) \\, d\\boldsymbol{\\theta}\n$$\n$$\np(\\mathcal{D}\\,|\\,\\mathcal{M}) \\approx \\exp\\{\\ell_{n}(\\widehat{\\boldsymbol{\\theta}})\\} \\, \\pi(\\widehat{\\boldsymbol{\\theta}}\\,|\\,\\mathcal{M}) \\int \\exp\\left\\{ - \\frac{1}{2} (\\boldsymbol{\\theta} - \\widehat{\\boldsymbol{\\theta}})^{T} J_{n}(\\widehat{\\boldsymbol{\\theta}}) (\\boldsymbol{\\theta} - \\widehat{\\boldsymbol{\\theta}}) \\right\\} d\\boldsymbol{\\theta}\n$$\n该积分是一个均值为 $\\widehat{\\boldsymbol{\\theta}}$、协方差矩阵为 $J_{n}(\\widehat{\\boldsymbol{\\theta}})^{-1}$ 的多元高斯概率密度函数（未归一化）的形式。该积分的值为 $(2\\pi)^{k/2} \\det(J_{n}(\\widehat{\\boldsymbol{\\theta}}))^{-1/2}$。\n因此，\n$$\np(\\mathcal{D}\\,|\\,\\mathcal{M}) \\approx \\exp\\{\\ell_{n}(\\widehat{\\boldsymbol{\\theta}})\\} \\, \\pi(\\widehat{\\boldsymbol{\\theta}}\\,|\\,\\mathcal{M}) \\, (2\\pi)^{k/2} \\det(J_{n}(\\widehat{\\boldsymbol{\\theta}}))^{-1/2}\n$$\n根据大数定律，对于独立同分布的数据，观测信息 $J_n(\\widehat{\\boldsymbol{\\theta}})$ 与 $n$ 呈线性关系。也就是说，$J_n(\\widehat{\\boldsymbol{\\theta}}) = O(n)$。我们可以写成 $J_n(\\widehat{\\boldsymbol{\\theta}}) \\approx n I(\\boldsymbol{\\theta}_0)$，其中 $I(\\boldsymbol{\\theta}_0)$ 是在真实参数值 $\\boldsymbol{\\theta}_0$ 处评估的单个观测的费雪信息。\n因此，$\\det(J_n(\\widehat{\\boldsymbol{\\theta}})) \\approx \\det(nI(\\boldsymbol{\\theta}_0)) = n^k \\det(I(\\boldsymbol{\\theta}_0))$。将此代入近似式中：\n$$\np(\\mathcal{D}\\,|\\,\\mathcal{M}) \\approx \\exp\\{\\ell_{n}(\\widehat{\\boldsymbol{\\theta}})\\} \\, \\pi(\\widehat{\\boldsymbol{\\theta}}\\,|\\,\\mathcal{M}) \\, (2\\pi)^{k/2} (n^k \\det(I(\\boldsymbol{\\theta}_0)))^{-1/2}\n$$\n现在，我们计算 $-2 \\ln p(\\mathcal{D}\\,|\\,\\mathcal{M})$：\n$$\n-2 \\ln p(\\mathcal{D}\\,|\\,\\mathcal{M}) \\approx -2\\ell_{n}(\\widehat{\\boldsymbol{\\theta}}) - 2\\ln \\pi(\\widehat{\\boldsymbol{\\theta}}\\,|\\,\\mathcal{M}) - k\\ln(2\\pi) + k\\ln n + \\ln \\det(I(\\boldsymbol{\\theta}_0))\n$$\nBIC 是通过仅保留随样本量 $n$ 增长的项得到的。项 $\\ell_{n}(\\widehat{\\boldsymbol{\\theta}})$ 是 $O(n)$，而项 $k\\ln n$ 是 $O(\\ln n)$。所有其他项，例如涉及先验和费雪信息的项，都是 $O(1)$ 并且是渐近可忽略的。忽略这些 $O(1)$ 项即可得到 BIC：\n$$\n\\mathrm{BIC}(\\mathcal{M}) = -2\\ell_{n}(\\widehat{\\boldsymbol{\\theta}}) + k \\ln n\n$$\n该准则用于模型选择，需要被最小化。它代表了负二倍对数边际证据的渐近近似。它对模型的拟合不足（第一项）及其复杂性（第二项）进行惩罚。\n\n### 2. 赤池信息准则 (AIC) 的推导\n\n第二个准则是期望样本外对数似然的 $-2$ 倍的近似。目标是估计拟合好的模型在预测来自相同生成过程的新的、未见过的数据时的表现如何。令 $p_0(\\mathbf{y})$ 为真实但未知的数据生成分布。令 $\\mathcal{D}' = \\{\\mathbf{y}'_1, \\dots, \\mathbf{y}'_n\\}$ 为一个独立的重复数据集。在数据 $\\mathcal{D}$ 上拟合的模型的期望样本外对数似然为：\n$$\nC = E_{\\mathcal{D}'}[\\ell_{n}(\\widehat{\\boldsymbol{\\theta}}(\\mathcal{D}))] = E_{\\mathcal{D}'}\\left[ \\sum_{i=1}^{n} \\ln p(\\mathbf{y}'_i \\,|\\, \\widehat{\\boldsymbol{\\theta}}(\\mathcal{D}), \\mathcal{M}) \\right] = n \\int p_0(\\mathbf{y}) \\ln p(\\mathbf{y} \\,|\\, \\widehat{\\boldsymbol{\\theta}}(\\mathcal{D}), \\mathcal{M}) d\\mathbf{y}\n$$\n这个量通过 $\\widehat{\\boldsymbol{\\theta}}(\\mathcal{D})$ 依赖于特定的训练数据集 $\\mathcal{D}$。我们希望估计它在所有可能的训练集 $\\mathcal{D}$ 上的期望：\n$$\nE_{\\mathcal{D}}[C] = E_{\\mathcal{D}} \\left[ n \\int p_0(\\mathbf{y}) \\ln p(\\mathbf{y} \\,|\\, \\widehat{\\boldsymbol{\\theta}}(\\mathcal{D}), \\mathcal{M}) d\\mathbf{y} \\right]\n$$\n令 $\\boldsymbol{\\theta}_0$ 为最小化真实分布 $p_0(\\mathbf{y})$ 与模型族 $p(\\mathbf{y}\\,|\\,\\boldsymbol{\\theta},\\mathcal{M})$ 之间 KL 散度的参数值。在模型族被正确指定的假设下，$p_0(\\mathbf{y}) = p(\\mathbf{y}\\,|\\,\\boldsymbol{\\theta}_0, \\mathcal{M})$。\n我们定义 $L(\\boldsymbol{\\theta}) = E_{\\mathbf{y}\\sim p_0}[\\ln p(\\mathbf{y}\\,|\\,\\boldsymbol{\\theta},\\mathcal{M})]$。我们想要估计的量是 $E_{\\mathcal{D}}[n L(\\widehat{\\boldsymbol{\\theta}})]$。\n使用 $L(\\widehat{\\boldsymbol{\\theta}})$ 在 $\\boldsymbol{\\theta}_0$ 周围的二阶泰勒展开：\n$$\nL(\\widehat{\\boldsymbol{\\theta}}) \\approx L(\\boldsymbol{\\theta}_0) + (\\widehat{\\boldsymbol{\\theta}} - \\boldsymbol{\\theta}_0)^T \\nabla L(\\boldsymbol{\\theta}_0) + \\frac{1}{2}(\\widehat{\\boldsymbol{\\theta}} - \\boldsymbol{\\theta}_0)^T \\nabla^2 L(\\boldsymbol{\\theta}_0) (\\widehat{\\boldsymbol{\\theta}} - \\boldsymbol{\\theta}_0)\n$$\n根据定义，$\\boldsymbol{\\theta}_0$ 使 $L(\\boldsymbol{\\theta})$ 最大化，所以 $\\nabla L(\\boldsymbol{\\theta}_0) = \\mathbf{0}$。并且，$\\nabla^2 L(\\boldsymbol{\\theta}_0) = E_{\\mathbf{y}\\sim p_0} [\\nabla^2 \\ln p(\\mathbf{y} | \\boldsymbol{\\theta}_0)] = -I(\\boldsymbol{\\theta}_0)$，其中 $I(\\boldsymbol{\\theta}_0)$ 是单个观测的费雪信息矩阵。\n对 $\\mathcal{D}$ 取期望：\n$$\nE_{\\mathcal{D}}[L(\\widehat{\\boldsymbol{\\theta}})] \\approx L(\\boldsymbol{\\theta}_0) + \\frac{1}{2} E_{\\mathcal{D}}\\left[ (\\widehat{\\boldsymbol{\\theta}} - \\boldsymbol{\\theta}_0)^T (-I(\\boldsymbol{\\theta}_0)) (\\widehat{\\boldsymbol{\\theta}} - \\boldsymbol{\\theta}_0) \\right]\n$$\n使用迹恒等式和期望的线性性质，这变为：\n$$\nE_{\\mathcal{D}}[L(\\widehat{\\boldsymbol{\\theta}})] \\approx L(\\boldsymbol{\\theta}_0) - \\frac{1}{2} \\mathrm{Tr}\\left( I(\\boldsymbol{\\theta}_0) E_{\\mathcal{D}}\\left[ (\\widehat{\\boldsymbol{\\theta}} - \\boldsymbol{\\theta}_0)(\\widehat{\\boldsymbol{\\theta}} - \\boldsymbol{\\theta}_0)^T \\right] \\right)\n$$\n在所述的正则性条件下，MLE $\\widehat{\\boldsymbol{\\theta}}$ 是渐近正态的，其渐近协方差为 $E_{\\mathcal{D}}\\left[ (\\widehat{\\boldsymbol{\\theta}} - \\boldsymbol{\\theta}_0)(\\widehat{\\boldsymbol{\\theta}} - \\boldsymbol{\\theta}_0)^T \\right] \\approx \\frac{1}{n} I(\\boldsymbol{\\theta}_0)^{-1}$。\n$$\nE_{\\mathcal{D}}[L(\\widehat{\\boldsymbol{\\theta}})] \\approx L(\\boldsymbol{\\theta}_0) - \\frac{1}{2} \\mathrm{Tr}\\left( I(\\boldsymbol{\\theta}_0) \\frac{1}{n} I(\\boldsymbol{\\theta}_0)^{-1} \\right) = L(\\boldsymbol{\\theta}_0) - \\frac{1}{2n} \\mathrm{Tr}(I_k) = L(\\boldsymbol{\\theta}_0) - \\frac{k}{2n}\n$$\n因此，期望样本外对数似然为 $E_{\\mathcal{D}}[n L(\\widehat{\\boldsymbol{\\theta}})] \\approx n L(\\boldsymbol{\\theta}_0) - \\frac{k}{2}$。\n\n现在我们将其与样本内最大化对数似然 $\\ell_n(\\widehat{\\boldsymbol{\\theta}})$ 联系起来。让我们求其期望。对 $\\frac{1}{n}\\ell_n(\\widehat{\\boldsymbol{\\theta}})$ 的类似展开表明，$E_{\\mathcal{D}}[\\ell_n(\\widehat{\\boldsymbol{\\theta}})]$ 有一个向上的偏差：\n$$\nE_{\\mathcal{D}}[\\ell_n(\\widehat{\\boldsymbol{\\theta}})] \\approx n L(\\boldsymbol{\\theta}_0) + \\frac{k}{2}\n$$\n差值 $E_{\\mathcal{D}}[\\ell_n(\\widehat{\\boldsymbol{\\theta}})] - E_{\\mathcal{D}}[n L(\\widehat{\\boldsymbol{\\theta}})] \\approx k$ 是样本内对数似然的“乐观度”。这表明 $\\ell_n(\\widehat{\\boldsymbol{\\theta}}) - k$ 是期望样本外对数似然 $E_{\\mathcal{D}}[n L(\\widehat{\\boldsymbol{\\theta}})]$ 的一个近似无偏估计量。\n赤池信息准则被定义为这个校正后对数似然的 $-2$ 倍：\n$$\n\\mathrm{AIC}(\\mathcal{M}) = -2(\\ell_n(\\widehat{\\boldsymbol{\\theta}}) - k) = -2\\ell_n(\\widehat{\\boldsymbol{\\theta}}) + 2k\n$$\n该准则也用于模型选择，需要被最小化。它提供了对新数据上期望预测误差的估计，通过一个与参数数量成正比的项来惩罚样本内拟合。\n\n关键的洞见是，尽管两种推导源于不同的哲学立场（贝叶斯派 vs. 频率派），但它们都仅依赖于观测数据对数似然 $\\ell_n(\\boldsymbol{\\theta})$ 及其最大化子 $\\widehat{\\boldsymbol{\\theta}}$ 的渐近性质。$\\ell_n(\\boldsymbol{\\theta})$ 是通过边际化从一个隐变量模型推导出来这一事实，由问题的假设处理，即假设 $\\ell_n(\\boldsymbol{\\theta})$ 仍然满足 MLE 渐近性成立所必需的正则性条件，其中 $k$ 是可辨识参数的数量。\n\n总而言之，这两个准则是：\n1. $\\mathrm{BIC}(\\mathcal{M}) = -2\\ell_{n}(\\widehat{\\boldsymbol{\\theta}}) + k \\ln n$\n2. $\\mathrm{AIC}(\\mathcal{M}) = -2\\ell_{n}(\\widehat{\\boldsymbol{\\theta}}) + 2k$",
            "answer": "$$\n\\boxed{\\begin{pmatrix} -2\\ell_{n}(\\widehat{\\boldsymbol{\\theta}}) + 2k  -2\\ell_{n}(\\widehat{\\boldsymbol{\\theta}}) + k \\ln n \\end{pmatrix}}\n$$"
        }
    ]
}