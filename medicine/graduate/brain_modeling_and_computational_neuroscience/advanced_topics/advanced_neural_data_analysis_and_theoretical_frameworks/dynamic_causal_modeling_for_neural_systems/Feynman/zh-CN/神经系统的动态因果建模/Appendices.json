{
    "hands_on_practices": [
        {
            "introduction": "掌握动态因果模型（DCM）的第一步是建立关于其动态行为的直观理解。通过从一个具有已知参数的模型中生成数据，我们可以深入了解连接强度和外部输入的变化如何影响神经活动和最终的观测信号。本练习  将指导您将核心的双线性状态方程转化为一个可运行的计算机模拟，从而为理解模型动力学奠定坚实的基础。",
            "id": "3976292",
            "problem": "构建一个针对两个相互作用的神经区域的最小动态因果模型，该模型具有一个作用于第一个区域的单一外源输入，并使用双线性状态方程和线性观测模型。连续时间潜在神经状态是一个向量 $x(t) \\in \\mathbb{R}^2$，其动态由双线性常微分方程 $\\dot{x}(t) = A x(t) + B u(t) x(t) + C u(t)$ 控制，观测模型为 $y(t) = h(x(t)) + \\epsilon(t)$，其中 $y(t) \\in \\mathbb{R}^2$，$u(t) \\in \\mathbb{R}$ 是一个标量外源输入，$A \\in \\mathbb{R}^{2 \\times 2}$ 是内在有效连接矩阵，$B \\in \\mathbb{R}^{2 \\times 2}$ 是连接的输入依赖调制矩阵，$C \\in \\mathbb{R}^{2}$ 是直接输入增益向量，而 $h(x)$ 是一个线性映射 $h(x) = L x$，其中 $L \\in \\mathbb{R}^{2 \\times 2}$。假设在模拟中测量噪声 $\\epsilon(t)$ 恒为零，即 $\\epsilon(t) = 0$。\n\n所有模拟使用以下固定参数：\n- 内在连接 $A = \\begin{bmatrix} -1.0 & 0.3 \\\\ 0.2 & -0.8 \\end{bmatrix}$。\n- 调制连接 $B = \\begin{bmatrix} 0.0 & 0.0 \\\\ 0.5 & 0.0 \\end{bmatrix}$。\n- 直接输入增益 $C = \\begin{bmatrix} 1.0 \\\\ 0.0 \\end{bmatrix}$。\n- 观测矩阵 $L = I_2 = \\begin{bmatrix} 1.0 & 0.0 \\\\ 0.0 & 1.0 \\end{bmatrix}$。\n- 初始状态 $x(0) = \\begin{bmatrix} 0.0 \\\\ 0.0 \\end{bmatrix}$。\n\n输入 $u(t)$ 是一个由三个参数定义的矩形脉冲：振幅 $a$、起始时间 $t_{\\mathrm{on}}$ 和结束时间 $t_{\\mathrm{off}}$。具体而言，\n$$\nu(t) = \\begin{cases}\na, & t_{\\mathrm{on}} \\le t  t_{\\mathrm{off}},\\\\\n0,  \\text{otherwise}.\n\\end{cases}\n$$\n\n从时间导数的定义和用于常微分方程数值积分的前向欧拉法出发，推导出一个离散时间更新规则，该规则在步长为 $\\Delta t$ 的时间网格上近似双线性系统的解，并说明在给定上述假设的情况下，如何计算最终时间 $T$ 处的 $y(T)$。然后，实现一个程序，使用以下输入参数测试套件来模拟该系统，每个测试用例指定为一个元组 $(a, t_{\\mathrm{on}}, t_{\\mathrm{off}}, T, \\Delta t)$：\n- 案例 $1$：$(1.0, 0.5, 1.5, 3.0, 0.001)$。\n- 案例 $2$：$(0.0, 0.5, 1.5, 3.0, 0.001)$。\n- 案例 $3$：$(2.0, 0.0, 0.01, 3.0, 0.001)$。\n- 案例 $4$：$(1.0, 0.5, 1.5, 3.0, 0.01)$。\n\n对于每个案例，使用你推导出的欧拉方案模拟从 $t=0$ 到 $t=T$ 的轨迹，并返回最终的观测状态向量 $y(T) \\in \\mathbb{R}^2$。将 $y(T)$ 的每个分量表示为四舍五入到六位小数的浮点数。你的程序应生成单行输出，其中包含一个方括号内的逗号分隔列表形式的结果，列表中的每个元素是一个案例的双分量列表 $[y_1(T),y_2(T)]$，并且不含任何空格。例如，整体输出格式必须与 $[[y_{11},y_{12}],[y_{21},y_{22}],[y_{31},y_{32}],[y_{41},y_{42}]]$ 完全一样。",
            "solution": "用户希望构建一个最小动态因果模型并对其进行模拟。\n\n### 步骤 1：提取已知条件\n- **状态方程**：$\\dot{x}(t) = A x(t) + B u(t) x(t) + C u(t)$，其中 $x(t) \\in \\mathbb{R}^2$ 是潜在神经状态，$u(t) \\in \\mathbb{R}$ 是一个标量输入。\n- **观测方程**：$y(t) = L x(t) + \\epsilon(t)$，其中 $y(t) \\in \\mathbb{R}^2$ 是观测值，并假设测量噪声 $\\epsilon(t) = 0$。\n- **内在连接**：$A = \\begin{bmatrix} -1.0  0.3 \\\\ 0.2  -0.8 \\end{bmatrix}$。\n- **调制连接**：$B = \\begin{bmatrix} 0.0  0.0 \\\\ 0.5  0.0 \\end{bmatrix}$。\n- **直接输入增益**：$C = \\begin{bmatrix} 1.0 \\\\ 0.0 \\end{bmatrix}$。\n- **观测矩阵**：$L = I_2 = \\begin{bmatrix} 1.0  0.0 \\\\ 0.0  1.0 \\end{bmatrix}$。\n- **初始状态**：$x(0) = \\begin{bmatrix} 0.0 \\\\ 0.0 \\end{bmatrix}$。\n- **输入函数**：一个矩形脉冲，$u(t) = a$ 当 $t_{\\mathrm{on}} \\le t  t_{\\mathrm{off}}$ 时成立，否则 $u(t)=0$。\n- **数值方法**：前向欧拉法，时间步长为 $\\Delta t$。\n- **任务**：对于给定的一组参数 $(a, t_{\\mathrm{on}}, t_{\\mathrm{off}}, T, \\Delta t)$，模拟系统从 $t=0$ 到 $t=T$ 的行为，并报告最终的观测状态 $y(T)$。\n- **测试用例**：\n    - 案例 1：$(1.0, 0.5, 1.5, 3.0, 0.001)$\n    - 案例 2：$(0.0, 0.5, 1.5, 3.0, 0.001)$\n    - 案例 3：$(2.0, 0.0, 0.01, 3.0, 0.001)$\n    - 案例 4：$(1.0, 0.5, 1.5, 3.0, 0.01)$\n- **输出**：每个案例的最终状态向量 $y(T)$ 的分量，四舍五入到六位小数，格式化为单行字符串。\n\n### 步骤 2：使用提取的已知条件进行验证\n该问题具有科学依据，描述了在计算神经科学的一个成熟领域——动态因果模型（DCM）中使用的标准双线性状态空间模型。该常微分方程组（ODE）在给定的初始条件下是良定义的，确保了唯一解的存在。所有参数、变量和常数都以数学上的精确且无歧义的方式指定。该问题是自洽、一致且计算上可行的。所要求的数值方法（前向欧拉法）是求解 ODE 的标准技术。该任务是将数值方法直接应用于一个已定义的物理模型，因此是一个有效的科学问题。\n\n### 步骤 3：结论与行动\n该问题有效。将提供完整的解决方案。\n\n### 基于原理的设计\n该问题要求对定义神经状态动态的一阶非线性常微分方程组（ODE）进行数值积分。指定的模型是一个双线性系统，这是一种非线性系统，其非线性来源于状态和输入的乘积。\n\n潜在神经状态 $x(t)$ 的连续时间动态由以下公式给出：\n$$\n\\dot{x}(t) = \\frac{dx(t)}{dt} = A x(t) + u(t) B x(t) + C u(t)\n$$\n在此，项 $u(t) B x(t)$ 表示输入 $u(t)$ 对神经区域之间内在连接的调制效应。项 $C u(t)$ 表示输入对这些区域的直接驱动效应。\n\n为了在有限时间区间 $[0, T]$ 上模拟 $x(t)$ 的轨迹，我们必须对此连续时间方程进行离散化。问题指定使用前向欧拉法，这是一种用于求解具有给定初始值的 ODE 的一阶数值方法。\n\n前向欧拉法的推导始于时间导数的定义：\n$$\n\\frac{dx(t)}{dt} = \\lim_{\\Delta t \\to 0} \\frac{x(t + \\Delta t) - x(t)}{\\Delta t}\n$$\n对于一个小的、有限的时间步长 $\\Delta t > 0$，我们可以将导数近似为：\n$$\n\\frac{dx(t)}{dt} \\approx \\frac{x(t + \\Delta t) - x(t)}{\\Delta t}\n$$\n将系统的微分方程代入此近似式，得到：\n$$\n\\frac{x(t + \\Delta t) - x(t)}{\\Delta t} \\approx A x(t) + u(t) B x(t) + C u(t)\n$$\n重新整理此方程以求解下一时间步的状态 $x(t + \\Delta t)$，便得到前向欧拉更新法则：\n$$\nx(t + \\Delta t) \\approx x(t) + \\Delta t \\left( A x(t) + u(t) B x(t) + C u(t) \\right)\n$$\n为了在数值上实现这一点，我们定义一个离散时间网格 $t_k = k \\Delta t$，其中 $k = 0, 1, 2, \\dots, N$，且 $N = T / \\Delta t$。令 $x_k = x(t_k)$ 为时间 $t_k$ 时的状态，令 $u_k = u(t_k)$ 为该时间点的输入。离散时间更新方程为：\n$$\nx_{k+1} = x_k + \\Delta t \\left( A x_k + u_k B x_k + u_k C \\right)\n$$\n模拟算法如下：\n1.  在时间 $t_0 = 0$ 时，使用给定的初始条件初始化状态向量：$x_0 = \\begin{bmatrix} 0.0 \\\\ 0.0 \\end{bmatrix}$。\n2.  确定总积分步数，$N = \\text{integer}(T / \\Delta t)$。\n3.  从 $k=0$ 到 $N-1$ 进行迭代：\n    a. 计算当前时间 $t_k = k \\Delta t$。\n    b. 根据其定义评估输入函数 $u_k = u(t_k)$：如果 $t_{\\mathrm{on}} \\le t_k  t_{\\mathrm{off}}$，则 $u_k = a$，否则 $u_k = 0$。\n    c. 计算时间 $t_k$ 时的状态导数近似值（ODE 的右侧）：$\\dot{x}_k = A x_k + u_k B x_k + u_k C$。\n    d. 应用欧拉更新法则来找到下一时间步的状态：$x_{k+1} = x_k + \\Delta t \\cdot \\dot{x}_k$。\n4.  循环结束后，最终状态为 $x_N$，它近似于 $x(T)$。\n\n最后一步是计算在时间 $T$ 时的观测输出。观测模型由 $y(t) = L x(t) + \\epsilon(t)$ 给出。根据提供的参数 $\\epsilon(t) = 0$ 和 $L = I_2$（$2 \\times 2$ 单位矩阵），观测方程简化为：\n$$\ny(T) = I_2 x(T) = x(T)\n$$\n因此，最终的观测状态 $y(T)$ 与通过数值积分获得的最终潜在状态 $x(T)$ 相同。程序将为每个测试用例执行此模拟，将最终向量 $y(T)$ 的两个分量四舍五入到六位小数，并按规定格式化结果。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the dynamic causal modeling problem by simulating a bilinear system\n    using the forward Euler method for a given set of test cases.\n    \"\"\"\n\n    # Define the fixed model parameters as specified in the problem.\n    # Intrinsic connectivity matrix A\n    A = np.array([[-1.0, 0.3], [0.2, -0.8]])\n    # Modulatory connectivity matrix B\n    B = np.array([[0.0, 0.0], [0.5, 0.0]])\n    # Direct input gain vector C\n    C = np.array([1.0, 0.0])\n    # Initial state vector x(0)\n    x0 = np.array([0.0, 0.0])\n\n    # The observation matrix L is the identity matrix, and noise is zero,\n    # so y(t) = x(t). We don't need L in the code.\n\n    # Define the test cases from the problem statement.\n    # Each case is a tuple: (a, t_on, t_off, T, dt)\n    test_cases = [\n        (1.0, 0.5, 1.5, 3.0, 0.001),  # Case 1\n        (0.0, 0.5, 1.5, 3.0, 0.001),  # Case 2\n        (2.0, 0.0, 0.01, 3.0, 0.001),  # Case 3\n        (1.0, 0.5, 1.5, 3.0, 0.01),   # Case 4\n    ]\n\n    results = []\n    # Process each test case.\n    for case in test_cases:\n        a, t_on, t_off, T, dt = case\n\n        # Calculate the number of integration steps.\n        num_steps = int(round(T / dt))\n        \n        # Initialize the state vector.\n        x = x0.copy()\n\n        # Perform the numerical integration using the forward Euler method.\n        for k in range(num_steps):\n            current_t = k * dt\n            \n            # Determine the value of the input u(t) at the current time step.\n            u_val = 0.0\n            if t_on = current_t  t_off:\n                u_val = a\n            \n            # Calculate the derivative dx/dt using the bilinear state equation:\n            # dx/dt = A*x + u*(B*x) + u*C\n            dxdt = A @ x + u_val * (B @ x) + u_val * C\n            \n            # Update the state vector using the forward Euler step.\n            x = x + dt * dxdt\n\n        # The final observed state y(T) is equal to the final latent state x(T).\n        y_T = x\n        \n        # Round the components of the final state vector to six decimal places.\n        y_T_rounded = [round(y_T[0], 6), round(y_T[1], 6)]\n        results.append(y_T_rounded)\n\n    # Format the final list of results into the exact required single-line string,\n    # e.g., [[y11,y12],[y21,y22],...], with no spaces.\n    final_output_str = str(results).replace(' ', '')\n    \n    # Final print statement in the exact required format.\n    print(final_output_str)\n\nsolve()\n```"
        },
        {
            "introduction": "在我们能够模拟模型之后，下一个分析层次是理解其内在属性，例如稳定性。这个练习  探索了一个更复杂的非线性DCM变体，并引入了强大的线性化技术来分析系统在某个工作点周围的行为。这对于理解大脑网络如何维持或失去稳定的活动模式是一个至关重要的概念。",
            "id": "3976258",
            "problem": "考虑一个简化的非线性动态因果模型（DCM）公式，用于描述一对相互作用的神经元群体，其中生成模型的确定性部分由以下连续时间动力学系统给出：\n$$\n\\frac{d x}{d t} = f(x) = A x + \\sum_{k=1}^{2} x_{k} \\, D^{(k)} x,\n$$\n其中状态 $x \\in \\mathbb{R}^{2}$ 代表群体活动。此处，$A \\in \\mathbb{R}^{2 \\times 2}$ 编码基线有效连接性，而 $D^{(k)} \\in \\mathbb{R}^{2 \\times 2}$ 编码由活动 $x_{k}$ 引起的连接的非线性、状态依赖性门控。假设 $A$ 和 $D^{(k)}$ 的条目物理单位为 $\\mathrm{s}^{-1}$，状态 $x$ 是无量纲的。工作点被指定为 $x^{\\ast} = \\begin{pmatrix} 0.2 \\\\ 0.5 \\end{pmatrix}$。\n\n使用连续时间动力学系统的线性化第一性原理和雅可比矩阵 $J(x) = \\frac{\\partial f}{\\partial x}(x)$ 的定义，执行以下操作：\n\n1.  从上述 $f(x)$ 的定义出发，推导非线性项 $\\sum_{k=1}^{2} x_{k} \\, D^{(k)} x$ 如何对一个一般状态 $x$ 下的雅可比矩阵 $J(x)$ 做出贡献。您的推导必须在分量级别上对 $J_{im}(x)$ 明确，其中 $i$ 索引输出维度，$m$ 索引关于 $x_{m}$ 的偏导数。\n2.  使用您的一般表达式，计算在特定参数化下的雅可比矩阵 $J(x^{\\ast})$：\n    $$\n    A = \\begin{pmatrix} -2.0  1.2 \\\\ 0.7  -1.4 \\end{pmatrix}, \\quad\n    D^{(1)} = \\begin{pmatrix} 0  0.5 \\\\ -0.3  0 \\end{pmatrix}, \\quad\n    D^{(2)} = \\begin{pmatrix} 0  -0.4 \\\\ 0.2  0 \\end{pmatrix}.\n    $$\n3.  通过计算 $J(x^{\\ast})$ 特征值的最大实部来量化 $x^{\\ast}$ 处的局部稳定性。将您的最终稳定性度量以 $\\mathrm{s}^{-1}$ 为单位表示，并将您的答案四舍五入到四位有效数字。\n\n您的最终答案必须是一个实数。",
            "solution": "该问题要求对一个双群体系统的简化非线性动态因果模型（DCM）进行分析。这包括推导系统的雅可比矩阵，在指定的工作点上对其进行评估，并通过找到其特征值的最大实部来确定局部稳定性。\n\n状态空间模型由以下微分方程给出：\n$$\n\\frac{d x}{d t} = f(x) = A x + \\sum_{k=1}^{2} x_{k} \\, D^{(k)} x\n$$\n其中 $x = \\begin{pmatrix} x_1 \\\\ x_2 \\end{pmatrix}$ 是状态向量。雅可比矩阵 $J(x)$ 由其分量 $J_{im}(x) = \\frac{\\partial f_i(x)}{\\partial x_m}$ 定义，其中 $f_i(x)$ 是向量场 $f(x)$ 的第 $i$ 个分量。\n\n函数 $f(x)$ 是一个线性项 $A x$ 和一个非线性项之和，我们可以将非线性项表示为 $g(x) = \\sum_{k=1}^{2} x_k D^{(k)} x$。根据微分的线性性质，雅可比矩阵为 $J(x) = A + \\frac{\\partial g}{\\partial x}(x)$。\n\n**第1部分：推导非线性项的雅可比矩阵**\n\n我们首先明确写出非线性项 $g(x)$ 的第 $i$ 个分量。\n$$\ng_i(x) = \\left( \\sum_{k=1}^{2} x_k D^{(k)} x \\right)_i = \\sum_{k=1}^{2} x_k (D^{(k)} x)_i\n$$\n项 $(D^{(k)} x)_i$ 是矩阵-向量乘积 $D^{(k)} x$ 所得向量的第 $i$ 个分量，即 $\\sum_{j=1}^{2} D^{(k)}_{ij} x_j$。代入后得到：\n$$\ng_i(x) = \\sum_{k=1}^{2} x_k \\left( \\sum_{j=1}^{2} D^{(k)}_{ij} x_j \\right) = \\sum_{k=1}^{2} \\sum_{j=1}^{2} D^{(k)}_{ij} x_k x_j\n$$\n现在，我们通过对 $x_m$ 求偏导数来找到此项对雅可比矩阵的贡献，其中 $m \\in \\{1, 2\\}$。\n$$\n\\frac{\\partial g_i(x)}{\\partial x_m} = \\frac{\\partial}{\\partial x_m} \\left( \\sum_{k=1}^{2} \\sum_{j=1}^{2} D^{(k)}_{ij} x_k x_j \\right)\n$$\n由于 $D^{(k)}_{ij}$ 是常数，我们可以将导数移到求和符号内部：\n$$\n\\frac{\\partial g_i(x)}{\\partial x_m} = \\sum_{k=1}^{2} \\sum_{j=1}^{2} D^{(k)}_{ij} \\frac{\\partial (x_k x_j)}{\\partial x_m}\n$$\n使用微分的乘法法则以及 $\\frac{\\partial x_p}{\\partial x_q} = \\delta_{pq}$（克罗内克δ函数）这一事实，我们得到：\n$$\n\\frac{\\partial (x_k x_j)}{\\partial x_m} = \\frac{\\partial x_k}{\\partial x_m} x_j + x_k \\frac{\\partial x_j}{\\partial x_m} = \\delta_{km} x_j + x_k \\delta_{jm}\n$$\n将此代回 $g_i(x)$ 的偏导数表达式中：\n$$\n\\frac{\\partial g_i(x)}{\\partial x_m} = \\sum_{k=1}^{2} \\sum_{j=1}^{2} D^{(k)}_{ij} (\\delta_{km} x_j + x_k \\delta_{jm}) = \\sum_{k=1}^{2} \\sum_{j=1}^{2} D^{(k)}_{ij} \\delta_{km} x_j + \\sum_{k=1}^{2} \\sum_{j=1}^{2} D^{(k)}_{ij} x_k \\delta_{jm}\n$$\n在第一项中，关于 $k$ 的求和会简化，因为 $\\delta_{km}$ 仅在 $k=m$ 时非零。在第二项中，关于 $j$ 的求和会简化，因为 $\\delta_{jm}$ 仅在 $j=m$ 时非零。\n$$\n\\frac{\\partial g_i(x)}{\\partial x_m} = \\sum_{j=1}^{2} D^{(m)}_{ij} x_j + \\sum_{k=1}^{2} D^{(k)}_{im} x_k\n$$\n这是非线性项雅可比矩阵的 $(i, m)$ 分量的一般表达式。完整的雅可比矩阵是 $J_{im}(x) = A_{im} + \\frac{\\partial g_i(x)}{\\partial x_m}$。\n\n**第2部分：计算工作点 $x^{\\ast}$ 处的雅可比矩阵**\n\n给定工作点 $x^{\\ast} = \\begin{pmatrix} 0.2 \\\\ 0.5 \\end{pmatrix}$ 和矩阵：\n$$\nA = \\begin{pmatrix} -2.0  1.2 \\\\ 0.7  -1.4 \\end{pmatrix}, \\quad\nD^{(1)} = \\begin{pmatrix} 0  0.5 \\\\ -0.3  0 \\end{pmatrix}, \\quad\nD^{(2)} = \\begin{pmatrix} 0  -0.4 \\\\ 0.2  0 \\end{pmatrix}\n$$\n让我们首先计算非线性项的雅可比矩阵 $J_g(x^{\\ast})$，然后将其与 $A$ 相加，来计算雅可比矩阵 $J(x^{\\ast})$。设 $J_g(x^{\\ast})$ 的分量为 $J_{g,im}$。\n\n对于 $(i,m) = (1,1)$:\n$J_{g,11} = \\sum_{j=1}^{2} D^{(1)}_{1j} x_j^{\\ast} + \\sum_{k=1}^{2} D^{(k)}_{11} x_k^{\\ast} = (D^{(1)}_{11}x_1^{\\ast} + D^{(1)}_{12}x_2^{\\ast}) + (D^{(1)}_{11}x_1^{\\ast} + D^{(2)}_{11}x_2^{\\ast})$\n$J_{g,11} = (0 \\cdot 0.2 + 0.5 \\cdot 0.5) + (0 \\cdot 0.2 + 0 \\cdot 0.5) = 0.25 + 0 = 0.25$\n\n对于 $(i,m) = (1,2)$:\n$J_{g,12} = \\sum_{j=1}^{2} D^{(2)}_{1j} x_j^{\\ast} + \\sum_{k=1}^{2} D^{(k)}_{12} x_k^{\\ast} = (D^{(2)}_{11}x_1^{\\ast} + D^{(2)}_{12}x_2^{\\ast}) + (D^{(1)}_{12}x_1^{\\ast} + D^{(2)}_{12}x_2^{\\ast})$\n$J_{g,12} = (0 \\cdot 0.2 + (-0.4) \\cdot 0.5) + (0.5 \\cdot 0.2 + (-0.4) \\cdot 0.5) = -0.2 + (0.1 - 0.2) = -0.3$\n\n对于 $(i,m) = (2,1)$:\n$J_{g,21} = \\sum_{j=1}^{2} D^{(1)}_{2j} x_j^{\\ast} + \\sum_{k=1}^{2} D^{(k)}_{21} x_k^{\\ast} = (D^{(1)}_{21}x_1^{\\ast} + D^{(1)}_{22}x_2^{\\ast}) + (D^{(1)}_{21}x_1^{\\ast} + D^{(2)}_{21}x_2^{\\ast})$\n$J_{g,21} = (-0.3 \\cdot 0.2 + 0 \\cdot 0.5) + (-0.3 \\cdot 0.2 + 0.2 \\cdot 0.5) = -0.06 + (-0.06 + 0.1) = -0.02$\n\n对于 $(i,m) = (2,2)$:\n$J_{g,22} = \\sum_{j=1}^{2} D^{(2)}_{2j} x_j^{\\ast} + \\sum_{k=1}^{2} D^{(k)}_{22} x_k^{\\ast} = (D^{(2)}_{21}x_1^{\\ast} + D^{(2)}_{22}x_2^{\\ast}) + (D^{(1)}_{22}x_1^{\\ast} + D^{(2)}_{22}x_2^{\\ast})$\n$J_{g,22} = (0.2 \\cdot 0.2 + 0 \\cdot 0.5) + (0 \\cdot 0.2 + 0 \\cdot 0.5) = 0.04 + 0 = 0.04$\n\n所以，非线性项在 $x^{\\ast}$ 处的雅可比矩阵是 $J_g(x^{\\ast}) = \\begin{pmatrix} 0.25  -0.3 \\\\ -0.02  0.04 \\end{pmatrix}$。\n\n完整的雅可比矩阵是 $J(x^{\\ast}) = A + J_g(x^{\\ast})$。\n$$\nJ(x^{\\ast}) = \\begin{pmatrix} -2.0  1.2 \\\\ 0.7  -1.4 \\end{pmatrix} + \\begin{pmatrix} 0.25  -0.3 \\\\ -0.02  0.04 \\end{pmatrix} = \\begin{pmatrix} -1.75  0.9 \\\\ 0.68  -1.36 \\end{pmatrix}\n$$\n\n**第3部分：通过特征值进行稳定性分析**\n\n工作点 $x^{\\ast}$ 处的局部稳定性由雅可比矩阵 $J(x^{\\ast})$ 的特征值决定。如果所有特征值的实部都为负，则系统是稳定的。特征值 $\\lambda$ 是特征方程 $\\det(J(x^{\\ast}) - \\lambda I) = 0$ 的根。对于一个 $2 \\times 2$ 矩阵，该方程为 $\\lambda^2 - \\text{Tr}(J) \\lambda + \\det(J) = 0$。\n\n设 $J' = J(x^{\\ast})$。\n$J'$ 的迹是 $\\text{Tr}(J') = -1.75 + (-1.36) = -3.11$。\n$J'$ 的行列式是 $\\det(J') = (-1.75)(-1.36) - (0.9)(0.68) = 2.38 - 0.612 = 1.768$。\n\n特征方程是：\n$$\n\\lambda^2 - (-3.11)\\lambda + 1.768 = 0 \\implies \\lambda^2 + 3.11\\lambda + 1.768 = 0\n$$\n根由二次求根公式给出：\n$$\n\\lambda = \\frac{-b \\pm \\sqrt{b^2 - 4ac}}{2a} = \\frac{-3.11 \\pm \\sqrt{(3.11)^2 - 4(1)(1.768)}}{2}\n$$\n$$\n\\lambda = \\frac{-3.11 \\pm \\sqrt{9.6721 - 7.072}}{2} = \\frac{-3.11 \\pm \\sqrt{2.6001}}{2}\n$$\n由于判别式 $2.6001 > 0$，两个特征值都是实数。稳定性度量是特征值的最大实部，也就是两个实特征值中较大的那个。\n$$\n\\lambda_1 = \\frac{-3.11 + \\sqrt{2.6001}}{2} \\quad \\text{和} \\quad \\lambda_2 = \\frac{-3.11 - \\sqrt{2.6001}}{2}\n$$\n显然，$\\lambda_1$ 是最大的特征值。\n计算其值：\n$\\sqrt{2.6001} \\approx 1.6124825$\n$$\n\\lambda_1 \\approx \\frac{-3.11 + 1.6124825}{2} = \\frac{-1.4975175}{2} \\approx -0.74875875\n$$\n问题要求答案四舍五入到四位有效数字。\n$$\n\\lambda_1 \\approx -0.7488\n$$\n$A$ 和 $D^{(k)}$ 的条目单位是 $\\mathrm{s}^{-1}$，$x$ 是无量纲的。因此，雅可比矩阵条目及其特征值的单位是 $\\mathrm{s}^{-1}$。特征值的最大实部是 $-0.7488 \\, \\mathrm{s}^{-1}$。由于这个值是负数，工作点 $x^{\\ast}$ 是局部稳定的。\n稳定性度量就是这个值本身。",
            "answer": "$$\\boxed{-0.7488}$$"
        },
        {
            "introduction": "本章的顶石实践练习旨在连接从单被试建模到组水平科学推断的鸿沟。DCM的真正威力通常在比较不同组别或将大脑连接与个体差异（如临床症状）相关联时得以体现。这个练习  演示了如何使用参数化经验贝叶斯（PEB）方法，综合来自多个被试的结果，并检验关于整个群体的假设，这是现代计算神经科学中的一个核心工作流程。",
            "id": "3976280",
            "problem": "给定来自 Dynamic Causal Modeling (DCM) 的特定于被试的后验摘要，以及一个代表症状严重程度的单一组水平回归量。目标是在第二水平上执行 Parametric Empirical Bayes (PEB) 以估计组效应，并计算严重程度效应大于零的后验概率。使用以下基于高斯线性模型和 Bayes 定理的分层设置。模型假设如下：\n\n- Dynamic Causal Modeling (DCM) 为每个被试 $i$ 提供一个单一标量参数（例如，有效连接）的后验分布，该后验分布可以很好地用均值为 $\\mu_i$、方差为 $\\sigma_i^2$ 的高斯分布来近似。\n- 第二水平的 PEB 模型是一个线性回归，它将 $\\mu_i$ 与一个带截距的组回归量联系起来：$\\mu_i = x_{i0}\\,\\beta_0 + x_{i1}\\,\\beta_1 + \\epsilon_i$，其中对于所有 $i$，$x_{i0} = 1$，$x_{i1}$ 是被试 $i$ 的症状严重程度，而 $\\epsilon_i \\sim \\mathcal{N}(0,\\sigma_i^2)$ 反映了从第一水平传播而来的估计不确定性。\n- 组参数的先验是高斯分布：$\\beta \\sim \\mathcal{N}(0,\\Sigma_0)$，其中 $\\beta = [\\beta_0,\\beta_1]^\\top$ 并且 $\\Sigma_0$ 是一个已知的正定协方差矩阵。\n\n从 Bayes 定理和多元正态分布的性质出发，在上述假设下推导后验分布 $p(\\beta \\mid \\mu)$。用设计矩阵 $X$、逐被试的精度（方差的倒数）和先验协方差 $\\Sigma_0$ 来表示后验均值和协方差。然后，对于严重程度效应 $\\beta_1$，计算后验概率 $p(\\beta_1 > 0 \\mid \\text{data})$。\n\n实现一个程序，对于下面的每个测试用例，该程序构建分层模型，计算 $\\beta$ 的后验，边缘化到分量 $\\beta_1$，并以小数形式输出后验概率 $p(\\beta_1 > 0 \\mid \\text{data})$。不涉及物理单位；概率必须表示为小数。\n\n使用以下测试套件。在每个案例中，严重程度的回归向量是 $s$，观测到的被试均值是 $y$（代表 $\\mu_i$），观测到的被试方差是 $v$（代表 $\\sigma_i^2$），并且 $\\beta$ 的先验协方差是对角的，其截距和斜率的条目指定为 $(\\sigma_{\\beta_0}^2,\\sigma_{\\beta_1}^2)$：\n\n- 测试用例 1（典型的提供信息的案例）：\n  - $s = [0.2,-0.1,0.3,0.0,0.5,-0.4]$\n  - $y = [0.19,-0.10,0.25,-0.01,0.42,-0.35]$\n  - $v = [0.04,0.05,0.03,0.06,0.02,0.07]$\n  - 先验对角方差 $(\\sigma_{\\beta_0}^2,\\sigma_{\\beta_1}^2) = (1.0,1.0)$\n- 测试用例 2（一个具有大不确定性的被试，接近边界的信息量）：\n  - $s = [-0.5,-0.2,0.0,0.2,0.6]$\n  - $y = [-0.10,-0.04,-0.10,0.06,0.21]$\n  - $v = [0.02,0.02,2.0,0.02,0.02]$\n  - 先验对角方差 $(\\sigma_{\\beta_0}^2,\\sigma_{\\beta_1}^2) = (2.0,2.0)$\n- 测试用例 3（严重程度效应的证据较弱，斜率接近于零）：\n  - $s = [-0.3,-0.1,0.0,0.1,0.3,0.5]$\n  - $y = [-0.02,0.01,0.00,-0.01,0.02,0.00]$\n  - $v = [0.05,0.05,0.05,0.05,0.05,0.05]$\n  - 先验对角方差 $(\\sigma_{\\beta_0}^2,\\sigma_{\\beta_1}^2) = (1.0,1.0)$\n\n您的程序应产生单行输出，其中包含用方括号括起来的逗号分隔列表形式的结果（例如 $[r_1,r_2,r_3]$），其中 $r_k$ 是测试用例 $k$ 的后验概率 $p(\\beta_10 \\mid \\text{data})$。输出必须是小数。",
            "solution": "该问题要求在一个分层贝叶斯模型中推导和计算后验量，具体来说是 Dynamic Causal Modeling (DCM) 后验的第二水平 Parametric Empirical Bayes (PEB) 分析。我们将首先推导组水平参数的后验分布，然后详细说明计算感兴趣效应的后验概率的方法。\n\n### 1. 分层模型公式化\n\n问题描述了一个两水平的分层模型。在第一水平，对 $N$ 个被试的 DCM 分析得出了一个标量参数的后验分布。这些后验分布用高斯分布来近似。对于被试 $i$，后验参数估计是一个随机变量，其均值为 $\\mu_i$，方差为 $\\sigma_i^2$。这些后验均值成为第二水平分析的数据。\n\n第二水平模型是一个广义线性模型，旨在用一个组水平回归量来解释参数均值 $\\mu_i$ 在被试间的变异性。模型给出如下：\n$$\n\\mu_i = x_{i0}\\,\\beta_0 + x_{i1}\\,\\beta_1 + \\epsilon_i\n$$\n其中 $\\beta_0$ 是组水平截距，$\\beta_1$ 是症状严重程度的效应，对所有被试 $x_{i0}=1$，而 $x_{i1}$ 是被试 $i$ 的症状严重程度。项 $\\epsilon_i \\sim \\mathcal{N}(0, \\sigma_i^2)$ 表示从第一水平 DCM 传播而来的不确定性（估计误差），其中 $\\sigma_i^2$ 是来自被试 $i$ 分析的后验方差。\n\n我们可以将这个模型对所有 $N$ 个被试以矩阵形式表示。设 $y$ 是特定于被试的均值 $[\\mu_1, \\mu_2, \\dots, \\mu_N]^\\top$ 的 $N \\times 1$ 列向量。设 $X$ 是 $N \\times 2$ 的设计矩阵，其中第一列是全为 1 的向量，第二列是症状严重程度的向量 $[x_{11}, x_{21}, \\dots, x_{N1}]^\\top$。设 $\\beta$ 是组水平参数 $[\\beta_0, \\beta_1]^\\top$ 的 $2 \\times 1$ 向量。则模型为：\n$$\ny = X\\beta + \\epsilon\n$$\n其中 $\\epsilon$ 是噪声项向量 $[\\epsilon_1, \\epsilon_2, \\dots, \\epsilon_N]^\\top$。由于 $\\epsilon_i$ 是独立的，它们的协方差矩阵（表示为 $V$）是一个对角矩阵，对角线上的元素是第一水平的方差 $\\sigma_i^2$：$V = \\text{diag}(\\sigma_1^2, \\sigma_2^2, \\dots, \\sigma_N^2)$。因此，给定参数 $\\beta$ 的数据 $y$ 的分布（似然）是一个多元正态分布：\n$$\np(y \\mid \\beta) = \\mathcal{N}(y; X\\beta, V)\n$$\n\n问题指定了组参数 $\\beta$ 上的一个高斯先验：\n$$\np(\\beta) = \\mathcal{N}(\\beta; \\beta_p, \\Sigma_p)\n$$\n其中先验均值为零向量，$\\beta_p = [0, 0]^\\top$，先验协方差 $\\Sigma_0$ 是一个已知的正定矩阵。\n\n### 2. 后验分布的推导\n\n我们的目标是找到给定数据 $y$ 时 $\\beta$ 的后验分布，表示为 $p(\\beta \\mid y)$。根据 Bayes 定理，后验分布正比于似然和先验的乘积：\n$$\np(\\beta \\mid y) \\propto p(y \\mid \\beta) p(\\beta)\n$$\n由于似然和先验都是高斯分布，它们的乘积也将正比于一个高斯分布。我们可以通过检查对数后验，重点关注依赖于 $\\beta$ 的项，来找到这个后验高斯分布的参数。\n\n对数后验为：\n$$\n\\ln p(\\beta \\mid y) = \\ln p(y \\mid \\beta) + \\ln p(\\beta) + \\text{const}\n$$\n对数似然为：\n$$\n\\ln p(y \\mid \\beta) = -\\frac{1}{2}(y - X\\beta)^\\top V^{-1} (y - X\\beta) + \\text{const}\n$$\n对数先验为：\n$$\n\\ln p(\\beta) = -\\frac{1}{2}(\\beta - \\beta_p)^\\top \\Sigma_0^{-1} (\\beta - \\beta_p) + \\text{const}\n$$\n代入 $\\beta_p=0$ 并组合得到：\n$$\n\\ln p(\\beta \\mid y) = -\\frac{1}{2} \\left[ (y - X\\beta)^\\top V^{-1} (y - X\\beta) + \\beta^\\top \\Sigma_0^{-1} \\beta \\right] + \\text{const}\n$$\n展开二次型：\n$$\n\\ln p(\\beta \\mid y) = -\\frac{1}{2} \\left[ y^\\top V^{-1} y - 2y^\\top V^{-1} X\\beta + \\beta^\\top X^\\top V^{-1} X\\beta + \\beta^\\top \\Sigma_0^{-1} \\beta \\right] + \\text{const}\n$$\n我们将涉及 $\\beta$ 的项组合起来：\n$$\n\\ln p(\\beta \\mid y) = -\\frac{1}{2} \\left[ \\beta^\\top (X^\\top V^{-1} X + \\Sigma_0^{-1}) \\beta - 2(X^\\top V^{-1} y)^\\top \\beta \\right] + \\text{const}\n$$\n这个表达式是 $\\beta$ 的一个二次函数。我们可以通过将其与多元高斯分布的标准对数形式进行比较，来识别后验分布 $p(\\beta \\mid y) = \\mathcal{N}(\\beta; \\mu_\\beta, \\Sigma_\\beta)$ 的参数：\n$$\n\\ln \\mathcal{N}(\\beta; \\mu_\\beta, \\Sigma_\\beta) = -\\frac{1}{2} \\left[ \\beta^\\top \\Sigma_\\beta^{-1} \\beta - 2\\mu_\\beta^\\top \\Sigma_\\beta^{-1} \\beta + \\mu_\\beta^\\top \\Sigma_\\beta^{-1} \\mu_\\beta \\right] + \\text{const}\n$$\n通过匹配 $\\beta$ 的二次项，我们找到后验精度（协方差的逆）：\n$$\n\\Sigma_\\beta^{-1} = X^\\top V^{-1} X + \\Sigma_0^{-1}\n$$\n因此，后验协方差为：\n$$\n\\Sigma_\\beta = (X^\\top V^{-1} X + \\Sigma_0^{-1})^{-1}\n$$\n让我们用 $\\Pi_y = V^{-1}$ 表示逐被试的精度，它是一个对角矩阵，其条目为 $1/\\sigma_i^2$。表达式变为：\n$$\n\\Sigma_\\beta = (X^\\top \\Pi_y X + \\Sigma_0^{-1})^{-1}\n$$\n通过匹配 $\\beta$ 的线性项，我们得到：\n$$\n\\mu_\\beta^\\top \\Sigma_\\beta^{-1} = (X^\\top V^{-1} y)^\\top = y^\\top V^{-1} X\n$$\n求解后验均值 $\\mu_\\beta$：\n$$\n\\mu_\\beta = \\Sigma_\\beta (X^\\top V^{-1} y) = \\Sigma_\\beta (X^\\top \\Pi_y y)\n$$\n这些方程提供了完整的后验分布 $p(\\beta \\mid y) = \\mathcal{N}(\\mu_\\beta, \\Sigma_\\beta)$。\n\n### 3. 后验概率的计算\n\n问题要求计算严重程度效应大于零的后验概率，即 $p(\\beta_1 > 0 \\mid y)$。$\\beta=[\\beta_0, \\beta_1]^\\top$ 的后验是一个二元正态分布。多元正态分布的任何单个分量的边缘分布也是正态的。\n\n$\\beta_1$ 的边缘后验分布由下式给出：\n$$\np(\\beta_1 \\mid y) = \\mathcal{N}(\\beta_1; \\mu_{\\beta_1}, \\sigma_{\\beta_1}^2)\n$$\n其中均值 $\\mu_{\\beta_1}$ 是后验均值向量 $\\mu_\\beta$ 的第二个元素，方差 $\\sigma_{\\beta_1}^2$ 是后验协方差矩阵 $\\Sigma_\\beta$ 的第二个对角元素。\n$$\n\\mu_{\\beta_1} = (\\mu_\\beta)_1 \\quad (\\text{使用从0开始的索引})\n$$\n$$\n\\sigma_{\\beta_1}^2 = (\\Sigma_\\beta)_{1,1} \\quad (\\text{使用从0开始的索引})\n$$\n后验标准差是 $\\sigma_{\\beta_1} = \\sqrt{(\\Sigma_\\beta)_{1,1}}$。\n\n为了计算 $p(\\beta_1 > 0 \\mid y)$，我们将 $p(\\beta_1 \\mid y)$ 的概率密度函数从 $0$ 积分到 $\\infty$。这等价于求 $1 - \\text{CDF}(0)$，其中 CDF 是 $\\mathcal{N}(\\mu_{\\beta_1}, \\sigma_{\\beta_1}^2)$ 的累积分布函数。\n令 $Z = (\\beta_1 - \\mu_{\\beta_1}) / \\sigma_{\\beta_1}$，它服从标准正态分布 $\\mathcal{N}(0, 1)$。条件 $\\beta_1 > 0$ 等价于 $Z > -\\mu_{\\beta_1} / \\sigma_{\\beta_1}$。因此：\n$$\np(\\beta_1 > 0 \\mid y) = P\\left(Z > -\\frac{\\mu_{\\beta_1}}{\\sigma_{\\beta_1}}\\right) = 1 - \\Phi\\left(-\\frac{\\mu_{\\beta_1}}{\\sigma_{\\beta_1}}\\right)\n$$\n其中 $\\Phi$ 是标准正态分布的 CDF。由于标准正态分布的对称性，$\\Phi(-z) = 1 - \\Phi(z)$，所以我们有：\n$$\np(\\beta_1 > 0 \\mid y) = 1 - \\left(1 - \\Phi\\left(\\frac{\\mu_{\\beta_1}}{\\sigma_{\\beta_1}}\\right)\\right) = \\Phi\\left(\\frac{\\mu_{\\beta_1}}{\\sigma_{\\beta_1}}\\right)\n$$\n这个量可以使用科学计算库中可用的标准正态 CDF 进行数值计算。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.stats import norm\n\ndef solve():\n    \"\"\"\n    Main function to solve the Parametric Empirical Bayes (PEB) problem\n    for the given test cases.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        {\n            # Test case 1 (typical informative case)\n            's': np.array([0.2, -0.1, 0.3, 0.0, 0.5, -0.4]),\n            'y': np.array([0.19, -0.10, 0.25, -0.01, 0.42, -0.35]),\n            'v': np.array([0.04, 0.05, 0.03, 0.06, 0.02, 0.07]),\n            'prior_vars': np.array([1.0, 1.0])\n        },\n        {\n            # Test case 2 (one subject with large uncertainty)\n            's': np.array([-0.5, -0.2, 0.0, 0.2, 0.6]),\n            'y': np.array([-0.10, -0.04, -0.10, 0.06, 0.21]),\n            'v': np.array([0.02, 0.02, 2.0, 0.02, 0.02]),\n            'prior_vars': np.array([2.0, 2.0])\n        },\n        {\n            # Test case 3 (weak evidence for severity effect)\n            's': np.array([-0.3, -0.1, 0.0, 0.1, 0.3, 0.5]),\n            'y': np.array([-0.02, 0.01, 0.00, -0.01, 0.02, 0.00]),\n            'v': np.array([0.05, 0.05, 0.05, 0.05, 0.05, 0.05]),\n            'prior_vars': np.array([1.0, 1.0])\n        }\n    ]\n\n    results = []\n    for case in test_cases:\n        s = case['s']\n        y = case['y']\n        v = case['v']\n        prior_vars = case['prior_vars']\n\n        # Number of subjects\n        n_subjects = len(s)\n\n        # 1. Construct the model matrices\n        # Design matrix X (N x 2) with intercept and severity regressor\n        X = np.vstack([np.ones(n_subjects), s]).T\n\n        # Precision of first-level estimates (inverse of variance)\n        Pi_y = np.diag(1.0 / v)\n\n        # Prior precision matrix for beta\n        Pi_0 = np.diag(1.0 / prior_vars)\n\n        # 2. Compute posterior parameters for beta = [beta_0, beta_1]\n        # Posterior precision: Pi_beta = X' * Pi_y * X + Pi_0\n        Pi_beta = X.T @ Pi_y @ X + Pi_0\n\n        # Posterior covariance: Sigma_beta = inv(Pi_beta)\n        Sigma_beta = np.linalg.inv(Pi_beta)\n\n        # Posterior mean: mu_beta = Sigma_beta * X' * Pi_y * y\n        mu_beta = Sigma_beta @ X.T @ Pi_y @ y\n\n        # 3. Extract marginal posterior for the severity effect beta_1\n        # The mean of beta_1 is the second element of mu_beta\n        mu_beta1 = mu_beta[1]\n        \n        # The variance of beta_1 is the second diagonal element of Sigma_beta\n        var_beta1 = Sigma_beta[1, 1]\n        \n        # The standard deviation of beta_1\n        std_beta1 = np.sqrt(var_beta1)\n\n        # 4. Compute the posterior probability P(beta_1 > 0 | data)\n        # This is the CDF of the standard normal distribution evaluated at mu/std\n        # Z = (beta_1 - mu_beta1) / std_beta1 ~ N(0, 1)\n        # P(beta_1 > 0) = P(Z > -mu_beta1 / std_beta1) = 1 - Phi(-mu_beta1 / std_beta1)\n        # By symmetry, this is Phi(mu_beta1 / std_beta1).\n        prob_beta1_positive = norm.cdf(mu_beta1 / std_beta1)\n        \n        results.append(prob_beta1_positive)\n\n    # Format the output as a string and print\n    # Using f-string formatting to ensure decimal representation\n    formatted_results = [f\"{r:.10f}\".rstrip('0').rstrip('.') if r != 0 and r != 1 else str(int(r)) for r in results]\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```"
        }
    ]
}