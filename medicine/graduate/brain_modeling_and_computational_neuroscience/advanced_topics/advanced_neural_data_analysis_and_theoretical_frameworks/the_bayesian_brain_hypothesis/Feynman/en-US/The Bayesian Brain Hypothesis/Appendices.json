{
    "hands_on_practices": [
        {
            "introduction": "At the heart of the Bayesian brain lies the mathematical process of integrating prior knowledge with sensory data. This first exercise walks you through the fundamental computation of this process for the common case of Gaussian distributions. By deriving the posterior belief from scratch, you will uncover the principle of precision-weighted averaging, a cornerstone concept explaining how the brain should optimally balance its internal models against incoming evidence. ",
            "id": "4063569",
            "problem": "In the Bayesian brain hypothesis, cortical computation is often modeled as probabilistic inference that combines internally generated predictions (priors) with incoming sensory evidence (likelihoods), with the relative influence modulated by precision (inverse variance). Consider a neuromorphic sensory estimation module for a single latent cause $s$ with prior $p(s)=\\mathcal{N}(0,1)$, and a scalar observation $x$ generated conditionally by $p(x\\mid s)=\\mathcal{N}(s,0.25)$. Starting only from Bayes' rule $p(s\\mid x)\\propto p(x\\mid s)\\,p(s)$ and the definition of precision as the inverse of variance, derive the posterior distribution $p(s\\mid x)$ by explicitly completing the square in the exponent of the product of Gaussians. Then, compute the posterior mean and posterior variance of $s$ given $x$, and interpret the posterior mean as a precision-weighted average of the prior mean and the observed value. \n\nExpress your final answer as a single row matrix containing the posterior mean and posterior variance, in exact symbolic form as functions of $x$. No rounding is required. No physical units are involved.",
            "solution": "The problem requires the derivation of the posterior distribution $p(s \\mid x)$ for a latent variable $s$ given an observation $x$, based on a specified prior $p(s)$ and likelihood $p(x \\mid s)$. The derivation must proceed from Bayes' rule by completing the square in the exponent of the product of Gaussian densities. Subsequently, the posterior mean and variance are to be computed and interpreted.\n\nThe provided distributions are:\n1.  Prior distribution for $s$: $p(s) = \\mathcal{N}(\\mu_{prior}, \\sigma_{prior}^2)$, where the mean is $\\mu_{prior} = 0$ and the variance is $\\sigma_{prior}^2 = 1$.\n2.  Likelihood of observation $x$ given $s$: $p(x \\mid s) = \\mathcal{N}(s, \\sigma_{like}^2)$, where the variance is $\\sigma_{like}^2 = 0.25$. Note that the mean of this distribution is the latent variable $s$.\n\nThe probability density function (PDF) for a general Gaussian distribution $\\mathcal{N}(\\mu, \\sigma^2)$ is given by $f(y) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}} \\exp\\left(-\\frac{(y-\\mu)^2}{2\\sigma^2}\\right)$.\nThus, the specific PDFs for the prior and likelihood are:\n$p(s) = \\frac{1}{\\sqrt{2\\pi(1)}} \\exp\\left(-\\frac{(s-0)^2}{2(1)}\\right) = \\frac{1}{\\sqrt{2\\pi}} \\exp\\left(-\\frac{s^2}{2}\\right)$\n$p(x \\mid s) = \\frac{1}{\\sqrt{2\\pi(0.25)}} \\exp\\left(-\\frac{(x-s)^2}{2(0.25)}\\right) = \\frac{1}{\\sqrt{0.5\\pi}} \\exp\\left(-\\frac{(x-s)^2}{0.5}\\right)$\n\nAccording to Bayes' rule, the posterior distribution $p(s \\mid x)$ is proportional to the product of the likelihood and the prior:\n$p(s \\mid x) \\propto p(x \\mid s) p(s)$\n\nSubstituting the expressions for the PDFs, we get:\n$p(s \\mid x) \\propto \\left[ \\frac{1}{\\sqrt{0.5\\pi}} \\exp\\left(-\\frac{(x-s)^2}{0.5}\\right) \\right] \\left[ \\frac{1}{\\sqrt{2\\pi}} \\exp\\left(-\\frac{s^2}{2}\\right) \\right]$\n\nSince we are working with proportionality, the constant normalization factors can be ignored. The posterior is proportional to the exponential part:\n$p(s \\mid x) \\propto \\exp\\left(-\\frac{(x-s)^2}{0.5}\\right) \\exp\\left(-\\frac{s^2}{2}\\right) = \\exp\\left(-\\frac{(x-s)^2}{0.5} - \\frac{s^2}{2}\\right)$\n\nLet's analyze the exponent, which we denote as $\\Phi(s)$:\n$\\Phi(s) = -\\left(\\frac{(s-x)^2}{0.5} + \\frac{s^2}{2}\\right) = -\\left(2(s-x)^2 + \\frac{s^2}{2}\\right)$\n\nTo identify the form of the posterior distribution, we expand the terms in the exponent and collect powers of $s$. A posterior of Gaussian form $\\mathcal{N}(\\mu_{post}, \\sigma_{post}^2)$ will have an exponent of the form $-\\frac{(s-\\mu_{post})^2}{2\\sigma_{post}^2} + C$, where $C$ is a constant with respect to $s$.\n$\\Phi(s) = -\\left(2(s^2 - 2sx + x^2) + \\frac{s^2}{2}\\right)$\n$\\Phi(s) = -\\left(2s^2 - 4sx + 2x^2 + \\frac{s^2}{2}\\right)$\n$\\Phi(s) = -\\left(\\left(2 + \\frac{1}{2}\\right)s^2 - 4sx + 2x^2\\right)$\n$\\Phi(s) = -\\left(\\frac{5}{2}s^2 - 4sx + 2x^2\\right)$\n\nNow, we complete the square for the terms involving $s$. The general form is $As^2+Bs+C$. We factor out $A$ from the terms involving $s$: $A(s^2 + \\frac{B}{A}s) + C = A\\left(s+\\frac{B}{2A}\\right)^2 + C - \\frac{B^2}{4A}$.\nIn our expression, the term in the parenthesis is $\\frac{5}{2}s^2 - 4sx + 2x^2$. Here, $A = \\frac{5}{2}$ and $B = -4x$.\n$\\frac{5}{2}s^2 - 4sx + 2x^2 = \\frac{5}{2}\\left(s^2 - \\frac{2}{5}(4x)s\\right) + 2x^2$\n$= \\frac{5}{2}\\left(s^2 - \\frac{8x}{5}s\\right) + 2x^2$\n$= \\frac{5}{2}\\left[\\left(s - \\frac{4x}{5}\\right)^2 - \\left(\\frac{4x}{5}\\right)^2\\right] + 2x^2$\n$= \\frac{5}{2}\\left(s - \\frac{4x}{5}\\right)^2 - \\frac{5}{2}\\left(\\frac{16x^2}{25}\\right) + 2x^2$\n$= \\frac{5}{2}\\left(s - \\frac{4x}{5}\\right)^2 - \\frac{8x^2}{5} + 2x^2$\n$= \\frac{5}{2}\\left(s - \\frac{4x}{5}\\right)^2 - \\frac{8x^2}{5} + \\frac{10x^2}{5}$\n$= \\frac{5}{2}\\left(s - \\frac{4x}{5}\\right)^2 + \\frac{2x^2}{5}$\n\nSubstituting this back into the expression for $\\Phi(s)$:\n$\\Phi(s) = -\\left(\\frac{5}{2}\\left(s - \\frac{4x}{5}\\right)^2 + \\frac{2x^2}{5}\\right) = -\\frac{5}{2}\\left(s - \\frac{4x}{5}\\right)^2 - \\frac{2x^2}{5}$\n\nTherefore, the posterior distribution is:\n$p(s \\mid x) \\propto \\exp\\left(-\\frac{1}{2} \\cdot 5 \\left(s - \\frac{4x}{5}\\right)^2\\right) \\exp\\left(-\\frac{2x^2}{5}\\right)$\n\nThe term $\\exp(-2x^2/5)$ is constant with respect to $s$ and can be absorbed into the normalization constant. The remaining expression has the form of a Gaussian PDF for $s$:\n$p(s \\mid x) \\propto \\exp\\left(-\\frac{(s - \\mu_{post})^2}{2\\sigma_{post}^2}\\right)$\n\nBy comparing the derived exponent with the general form, we can identify the posterior mean $\\mu_{post}$ and posterior variance $\\sigma_{post}^2$:\n$\\mu_{post} = \\frac{4x}{5}$\n$\\frac{1}{2\\sigma_{post}^2} = \\frac{5}{2} \\implies \\sigma_{post}^2 = \\frac{1}{5}$\n\nSo, the posterior distribution is a Gaussian: $p(s \\mid x) = \\mathcal{N}\\left(\\frac{4x}{5}, \\frac{1}{5}\\right)$.\nThe posterior mean is $\\mu_{post} = \\frac{4x}{5}$.\nThe posterior variance is $\\sigma_{post}^2 = \\frac{1}{5}$.\n\nTo interpret the posterior mean as a precision-weighted average, we first define precisions. Precision $\\lambda$ is the inverse of variance, $\\lambda = 1/\\sigma^2$.\nPrior precision: $\\lambda_{prior} = 1/\\sigma_{prior}^2 = 1/1 = 1$.\nLikelihood precision: $\\lambda_{like} = 1/\\sigma_{like}^2 = 1/0.25 = 4$.\n\nThe general formula for the posterior mean $\\mu_{post}$ in the case of a Gaussian prior and Gaussian likelihood is a precision-weighted average of the prior mean $\\mu_{prior}$ and the data $x$ (which is the mean of the likelihood function evaluated at $s=x$):\n$\\mu_{post} = \\frac{\\lambda_{prior}\\mu_{prior} + \\lambda_{like}x}{\\lambda_{prior} + \\lambda_{like}}$\nThe posterior precision is the sum of the prior and likelihood precisions:\n$\\lambda_{post} = \\lambda_{prior} + \\lambda_{like}$\nAnd the posterior variance is the inverse of the posterior precision:\n$\\sigma_{post}^2 = \\frac{1}{\\lambda_{post}} = \\frac{1}{\\lambda_{prior} + \\lambda_{like}}$\n\nLet's verify our results using these general formulas with the given values:\n$\\mu_{prior} = 0$, $\\lambda_{prior} = 1$, $\\lambda_{like} = 4$.\n$\\mu_{post} = \\frac{(1)(0) + (4)x}{1 + 4} = \\frac{4x}{5}$\n$\\sigma_{post}^2 = \\frac{1}{1 + 4} = \\frac{1}{5}$\n\nThe results match perfectly. The interpretation is that the posterior mean $\\mu_{post}$ is a weighted average of the prior's belief about the mean ($\\mu_{prior}=0$) and the sensory evidence ($x$). The weights are the respective precisions. The data has a precision of $4$ while the prior has a precision of $1$, so the sensory data has four times the influence on the final estimate as the prior belief. This can be seen by writing the posterior mean as:\n$\\mu_{post} = \\left(\\frac{\\lambda_{prior}}{\\lambda_{prior}+\\lambda_{like}}\\right)\\mu_{prior} + \\left(\\frac{\\lambda_{like}}{\\lambda_{prior}+\\lambda_{like}}\\right)x = \\left(\\frac{1}{5}\\right)(0) + \\left(\\frac{4}{5}\\right)x = \\frac{4x}{5}$.\n\nThe final answer requires the posterior mean and posterior variance in a single row matrix.\nPosterior mean: $\\frac{4x}{5}$\nPosterior variance: $\\frac{1}{5}$",
            "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n\\frac{4x}{5} & \\frac{1}{5}\n\\end{pmatrix}\n}\n$$"
        },
        {
            "introduction": "The brain doesn't just form beliefs once; it continuously updates them as new information arrives. This practice extends the concept of Bayesian integration to a dynamic context by framing it as a one-step Kalman filter update. You will derive the update equations and see how the 'Kalman gain' mechanism elegantly implements precision-weighting to adjust beliefs based on prediction errors, a process thought to be implemented by cortical circuits. ",
            "id": "4063550",
            "problem": "A central tenet of the Bayesian brain hypothesis (BBH) is that cortical circuits implement probabilistic inference, approximating Bayes’ rule through precision-weighted prediction errors. Consider a scalar latent variable $z$ that a neural population encodes as a Gaussian prior $p(z)=\\mathcal{N}(m,P)$, and a noisy sensory observation $x$ generated by a linear Gaussian generative model $p(x \\mid z)=\\mathcal{N}(C z, R)$, where $C$ is a known scalar observation matrix and $R$ is the observation noise variance. Assume the brain performs a one-step Bayesian update of its belief about $z$ upon receiving $x$, and that the linear-Gaussian structure is exploited to obtain a Gaussian posterior $p(z \\mid x)=\\mathcal{N}(m^{+}, P^{+})$. Starting from Bayes’ rule and the algebra of Gaussian densities, derive the posterior mean $m^{+}$ and posterior variance $P^{+}$ in terms of the prior parameters $m$ and $P$, the observation $x$, the observation matrix $C$, and the observation variance $R$. Then, interpret the precision-weighting as a Kalman filter (KF) gain $K$ multiplying the prediction error $x - C m$, and compute the numerical values of $K$, $m^{+}$, and $P^{+}$ for the specific case with prior mean $m=0$, prior variance $P=1$, observation $x=1$, observation matrix $C=1$, and observation variance $R=0.5$. Provide exact values; do not round. Express your final answer as a single row matrix containing, in order, the Kalman gain $K$, the updated mean $m^{+}$, and the updated variance $P^{+}$.",
            "solution": "The core of the problem is to perform a one-step Bayesian update for a scalar latent variable $z$, given a prior belief and a new observation. The prior belief about $z$ is modeled as a Gaussian distribution:\n$$p(z) = \\mathcal{N}(z; m, P) = \\frac{1}{\\sqrt{2\\pi P}} \\exp\\left(-\\frac{(z-m)^2}{2P}\\right)$$\nHere, $m$ is the prior mean and $P$ is the prior variance.\n\nThe observation $x$ is related to $z$ through a linear Gaussian generative model, which serves as the likelihood function:\n$$p(x \\mid z) = \\mathcal{N}(x; Cz, R) = \\frac{1}{\\sqrt{2\\pi R}} \\exp\\left(-\\frac{(x-Cz)^2}{2R}\\right)$$\nHere, $C$ is a scalar mapping the latent variable to the observation space, and $R$ is the variance of the observation noise.\n\nAccording to Bayes' rule, the posterior distribution of the latent variable given the observation is proportional to the product of the likelihood and the prior:\n$$p(z \\mid x) = \\frac{p(x \\mid z) p(z)}{p(x)} \\propto p(x \\mid z) p(z)$$\nSince the product of two Gaussian functions is another (unnormalized) Gaussian function, the posterior $p(z \\mid x)$ will also be Gaussian, which we denote as $p(z \\mid x) = \\mathcal{N}(z; m^{+}, P^{+})$. Our goal is to find the posterior mean $m^{+}$ and posterior variance $P^{+}$.\n\nTo do this, it is most convenient to work with the logarithm of the posterior probability, as the exponents of the Gaussians will add linearly.\n$$\\ln p(z \\mid x) \\propto \\ln(p(x \\mid z) p(z)) = \\ln p(x \\mid z) + \\ln p(z)$$\nIgnoring the normalization constants, we have:\n$$\\ln p(z \\mid x) = -\\frac{(x-Cz)^2}{2R} - \\frac{(z-m)^2}{2P} + \\text{const.}$$\nWe expand the quadratic terms:\n$$\\ln p(z \\mid x) = -\\frac{1}{2}\\left(\\frac{x^2 - 2xCz + C^2z^2}{R} + \\frac{z^2 - 2zm + m^2}{P}\\right) + \\text{const.}$$\nTo find the parameters of the posterior Gaussian, we rearrange the expression as a quadratic form in $z$:\n$$\\ln p(z \\mid x) = -\\frac{1}{2}\\left[ \\left(\\frac{C^2}{R} + \\frac{1}{P}\\right)z^2 - 2\\left(\\frac{xC}{R} + \\frac{m}{P}\\right)z \\right] + \\text{const.'}$$\nwhere `const.'` absorbs all terms not dependent on $z$.\n\nThe log of the posterior density $\\mathcal{N}(z; m^{+}, P^{+})$ is, by definition:\n$$\\ln p(z \\mid x) = -\\frac{(z-m^{+})^2}{2P^{+}} + \\text{const.} = -\\frac{1}{2}\\left( \\frac{z^2}{P^{+}} - \\frac{2m^{+}z}{P^{+}} + \\frac{(m^{+})^2}{P^{+}} \\right) + \\text{const.}$$\nBy comparing the coefficients of $z^2$ and $z$ in both expressions for $\\ln p(z \\mid x)$, we can identify $P^{+}$ and $m^{+}$.\n\nComparing the coefficients of the $z^2$ term:\n$$\\frac{1}{P^{+}} = \\frac{C^2}{R} + \\frac{1}{P}$$\nThis equation shows that the posterior precision (inverse variance) is the sum of the prior precision and the precision of the information gained from the observation. Solving for the posterior variance $P^{+}$:\n$$P^{+} = \\left(\\frac{C^2}{R} + \\frac{1}{P}\\right)^{-1} = \\left(\\frac{PC^2 + R}{PR}\\right)^{-1} = \\frac{PR}{PC^2 + R}$$\n\nComparing the coefficients of the $z$ term:\n$$\\frac{m^{+}}{P^{+}} = \\frac{xC}{R} + \\frac{m}{P}$$\nSolving for the posterior mean $m^{+}$:\n$$m^{+} = P^{+}\\left(\\frac{xC}{R} + \\frac{m}{P}\\right)$$\nSubstituting the expression for $P^{+}$:\n$$m^{+} = \\frac{PR}{PC^2 + R} \\left(\\frac{xCP + mR}{PR}\\right) = \\frac{xCP + mR}{PC^2 + R}$$\n\nTo interpret this result in the context of a Kalman filter, we rearrange the expression for $m^{+}$ to show an update from the prior mean $m$ based on a prediction error. The prediction error is the difference between the actual observation $x$ and the predicted observation based on the prior mean, $Cm$.\n$$m^{+} = \\frac{mR + xCP}{PC^2 + R} = \\frac{m(PC^2 + R) - mPC^2 + xCP}{PC^2 + R}$$\n$$m^{+} = m + \\frac{xCP - mPC^2}{PC^2 + R} = m + \\left(\\frac{PC}{PC^2 + R}\\right)(x - Cm)$$\nThis is the classic Kalman filter update equation. The term $K = \\frac{PC}{PC^2 + R}$ is the Kalman gain, which optimally weights the prediction error $(x - Cm)$. The posterior mean is the prior mean adjusted by the precision-weighted prediction error.\n\nNow we compute the numerical values for the specific case provided:\nPrior mean $m=0$.\nPrior variance $P=1$.\nObservation $x=1$.\nObservation matrix $C=1$.\nObservation variance $R=0.5$.\n\nFirst, we calculate the Kalman gain $K$:\n$$K = \\frac{PC}{PC^2 + R} = \\frac{(1)(1)}{(1)(1^2) + 0.5} = \\frac{1}{1 + 0.5} = \\frac{1}{1.5} = \\frac{1}{3/2} = \\frac{2}{3}$$\n\nNext, we calculate the posterior mean $m^{+}$:\n$$m^{+} = m + K(x - Cm) = 0 + \\frac{2}{3}(1 - (1)(0)) = \\frac{2}{3}(1) = \\frac{2}{3}$$\n\nFinally, we calculate the posterior variance $P^{+}$:\n$$P^{+} = \\frac{PR}{PC^2 + R} = \\frac{(1)(0.5)}{(1)(1^2) + 0.5} = \\frac{0.5}{1.5} = \\frac{1/2}{3/2} = \\frac{1}{3}$$\nAlternatively, using the update rule $P^{+} = (1-KC)P$:\n$$P^{+} = \\left(1 - \\frac{2}{3}(1)\\right)(1) = \\left(1 - \\frac{2}{3}\\right) = \\frac{1}{3}$$\nThe results are consistent.\n\nThe final answer requires a row matrix containing $K$, $m^{+}$, and $P^{+}$ in order.\n$$K = \\frac{2}{3}, \\quad m^{+} = \\frac{2}{3}, \\quad P^{+} = \\frac{1}{3}$$",
            "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n\\frac{2}{3} & \\frac{2}{3} & \\frac{1}{3}\n\\end{pmatrix}\n}\n$$"
        },
        {
            "introduction": "A powerful application of the Bayesian brain hypothesis is building computational models that can explain behavioral data from perceptual experiments. This hands-on coding problem challenges you to become a computational modeler, fitting psychometric data to distinguish between two competing hypotheses for suboptimal decision-making. By implementing and comparing models, you will practice a core skill in modern neuroscience: using quantitative models to infer the hidden cognitive processes that give rise to observable behavior. ",
            "id": "4027148",
            "problem": "A Bayesian observer model in perception posits that an observer combines sensory evidence with prior expectations to make decisions. Consider a binary discrimination task in which, on each trial, a scalar stimulus $s \\in \\mathbb{R}$ must be classified as being on the \"right\" side ($s > 0$) versus the \"left\" side ($s < 0$). The Bayesian brain hypothesis models this observer as performing probabilistic inference according to Bayes' rule under Gaussian assumptions, with occasional lapses resulting in random choices independent of the stimulus. The psychometric data consist of counts of \"right\" choices across stimulus levels.\n\nFundamental base:\n- Bayes' rule: for a latent variable $s$ with prior $p(s)$ and observation $x$ with likelihood $p(x \\mid s)$, the posterior is $p(s \\mid x) \\propto p(x \\mid s)p(s)$.\n- Gaussian prior and likelihood: assume $p(s) = \\mathcal{N}(\\mu_p,\\tau_p^2)$ and $p(x \\mid s) = \\mathcal{N}(s,\\sigma^2)$.\n- Binary decision: under symmetric loss and a two-alternative forced choice (2AFC) with categories \"right\" versus \"left\", an optimal Bayesian observer classifies \"right\" when the posterior evidence favors the \"right\" hypothesis (equivalently, the posterior mean exceeds zero).\n- Lapse mechanism: with probability $\\lambda \\in [0,1)$, the observer ignores stimulus information and makes a random choice, yielding $0.5$ probability of \"right\" irrespective of $s$.\n\nGiven these bases, the program must:\n- Derive from first principles the psychometric function $p_{\\mathrm{right}}(s)$ for the Bayesian observer with lapse rate. It must formalize and implement the probabilistic choice rule implied by the Gaussian prior and likelihood, the binary thresholding decision, and the lapse component.\n- Fit psychometric data by maximum likelihood under two model classes to distinguish whether suboptimality arises primarily from incorrect priors or from increased internal noise:\n  1. Incorrect-prior model: assumes known sensory noise variance $\\sigma_0^2$, and fits prior mean $\\mu_p$, prior standard deviation $\\tau_p$, and lapse rate $\\lambda$.\n  2. Incorrect-noise model: assumes a flat prior (zero mean and effectively infinite variance so that it does not bias the decision boundary), and fits sensory noise standard deviation $\\sigma$ and lapse rate $\\lambda$.\n- Use the binomial likelihood for observed counts at each stimulus level. Apply model comparison via the Bayesian Information Criterion (BIC), where for a model with $k$ free parameters and $N$ total trials, $\\mathrm{BIC} = k \\ln N - 2 \\ln \\hat{L}$ with $\\hat{L}$ the maximum likelihood. Choose the model with the lower $\\mathrm{BIC}$ as the explanatory mechanism.\n\nData generation for the test suite:\n- For each test case, define stimulus levels $s_i$ and trial counts $n_i$. Generate synthetic counts $k_i$ deterministically by computing the expected number of \"right\" choices as $n_i p_{\\mathrm{right}}(s_i)$ under the specified generative parameters and rounding to the nearest integer.\n- The program must not use randomness; it must reproduce the counts deterministically from the generative parameters as specified.\n\nImplement and test on the following test suite that probes different regimes:\n- Test Case A (happy path, incorrect priors): baseline sensory noise standard deviation $\\sigma_0 = 1.0$, generative prior mean $\\mu_p^{\\mathrm{true}} = 0.8$, generative prior standard deviation $\\tau_p^{\\mathrm{true}} = 0.7$, generative sensory noise standard deviation $\\sigma^{\\mathrm{true}} = 1.0$, generative lapse rate $\\lambda^{\\mathrm{true}} = 0.05$. Use stimulus levels $s_i \\in \\{-3,-2,-1,0,1,2,3\\}$ with $n_i = 1000$ trials each. The ground-truth mechanism label for this case is \"prior\".\n- Test Case B (happy path, increased noise): baseline sensory noise standard deviation $\\sigma_0 = 1.0$, generative prior mean $\\mu_p^{\\mathrm{true}} = 0.0$, generative prior standard deviation $\\tau_p^{\\mathrm{true}}$ effectively infinite (flat), generative sensory noise standard deviation $\\sigma^{\\mathrm{true}} = 2.0$, generative lapse rate $\\lambda^{\\mathrm{true}} = 0.05$. Use stimulus levels $s_i \\in \\{-3,-2,-1,0,1,2,3\\}$ with $n_i = 1000$ trials each. The ground-truth mechanism label for this case is \"noise\".\n- Test Case C (boundary condition, high lapse with incorrect priors): baseline sensory noise standard deviation $\\sigma_0 = 1.5$, generative prior mean $\\mu_p^{\\mathrm{true}} = 0.6$, generative prior standard deviation $\\tau_p^{\\mathrm{true}} = 0.5$, generative sensory noise standard deviation $\\sigma^{\\mathrm{true}} = 1.5$, generative lapse rate $\\lambda^{\\mathrm{true}} = 0.3$. Use stimulus levels $s_i \\in \\{-3,-2,-1,0,1,2,3\\}$ with $n_i = 1000$ trials each. The ground-truth mechanism label for this case is \"prior\".\n\nSolution expectations:\n- Derive the decision boundary and the psychometric function $p_{\\mathrm{right}}(s)$ implied by the Gaussian prior and likelihood and the binary decision rule, then incorporate the lapse mechanism.\n- Implement maximum likelihood estimation for each model class with appropriate parameter constraints: $\\sigma > 0$, $\\tau_p > 0$, and $\\lambda \\in [0,1)$. Use robust numerical optimization.\n- Compute $\\mathrm{BIC}$ for each model and select the lower $\\mathrm{BIC}$. For each test case, output a boolean that is $True$ if the selected model matches the ground-truth label and $False$ otherwise.\n\nFinal output specification:\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (e.g., \"[resultA,resultB,resultC]\"), where each result is a boolean corresponding to Test Cases A, B, and C in order.",
            "solution": "The problem requires us to develop a computational model of a Bayesian observer for a binary perceptual decision task, fit it to synthetic psychometric data, and use model comparison to determine the likely source of suboptimality. The solution involves three main stages: first, the mathematical derivation of the observer's psychometric function; second, the formulation of the statistical fitting procedure using maximum likelihood and model comparison via the Bayesian Information Criterion (BIC); and third, the implementation and testing of this procedure on provided test cases.\n\n### Derivation of the Psychometric Function\n\nThe observer's goal is to classify a stimulus $s \\in \\mathbb{R}$ as \"right\" ($s > 0$) or \"left\" ($s < 0$). The observer receives a noisy sensory measurement $x$, which is related to the true stimulus $s$ through a likelihood distribution $p(x \\mid s)$. This measurement is then combined with a prior belief about the stimulus, $p(s)$, to form a posterior distribution $p(s \\mid x)$ via Bayes' rule:\n\n$$\np(s \\mid x) \\propto p(x \\mid s) p(s)\n$$\n\nThe problem specifies Gaussian forms for both the prior and the likelihood:\n- Prior: $p(s) = \\mathcal{N}(s; \\mu_p, \\tau_p^2)$, representing the observer's belief about the distribution of stimuli before seeing the current measurement.\n- Likelihood: $p(x \\mid s) = \\mathcal{N}(x; s, \\sigma^2)$, representing the sensory noise corrupting the true stimulus value.\n\nSince the prior and likelihood are conjugate Gaussian distributions, the posterior distribution $p(s \\mid x)$ is also a Gaussian, $p(s \\mid x) = \\mathcal{N}(s; \\mu_{\\text{post}}, \\sigma_{\\text{post}}^2)$. The posterior precision ($1/\\sigma_{\\text{post}}^2$) is the sum of the prior and likelihood precisions:\n\n$$\n\\frac{1}{\\sigma_{\\text{post}}^2} = \\frac{1}{\\tau_p^2} + \\frac{1}{\\sigma^2}\n$$\n\nThe posterior mean, $\\mu_{\\text{post}}$, is a precision-weighted average of the prior mean $\\mu_p$ and the sensory measurement $x$:\n\n$$\n\\mu_{\\text{post}} = \\sigma_{\\text{post}}^2 \\left( \\frac{\\mu_p}{\\tau_p^2} + \\frac{x}{\\sigma^2} \\right) = \\frac{\\sigma^2 \\mu_p + \\tau_p^2 x}{\\sigma^2 + \\tau_p^2}\n$$\n\nThe observer makes a \"right\" decision if the posterior evidence favors the \"right\" category. With a symmetric loss function, this corresponds to deciding \"right\" if the posterior mean of the stimulus is greater than $0$:\n\n$$\n\\mu_{\\text{post}} > 0\n$$\n\nSubstituting the expression for $\\mu_{\\text{post}}$ and solving for $x$:\n$$\n\\frac{\\sigma^2 \\mu_p + \\tau_p^2 x}{\\sigma^2 + \\tau_p^2} > 0 \\implies \\tau_p^2 x > -\\sigma^2 \\mu_p \\implies x > -\\frac{\\sigma^2 \\mu_p}{\\tau_p^2}\n$$\nThis defines a decision threshold, $T = -\\frac{\\sigma^2 \\mu_p}{\\tau_p^2}$, on the sensory measurement $x$. The observer chooses \"right\" if and only if $x > T$.\n\nThe probability of choosing \"right\" for a given stimulus $s$, denoted $p_{\\text{bayes\\_right}}(s)$, is the probability that the random measurement $x \\sim \\mathcal{N}(s, \\sigma^2)$ exceeds this threshold $T$:\n\n$$\np_{\\text{bayes\\_right}}(s) = P(x > T \\mid s)\n$$\n\nThis probability can be calculated using the cumulative distribution function (CDF) of the standard normal distribution, $\\Phi(z) = P(Z \\le z)$ where $Z \\sim \\mathcal{N}(0,1)$.\n\n$$\np_{\\text{bayes\\_right}}(s) = P\\left(\\frac{x-s}{\\sigma} > \\frac{T-s}{\\sigma}\\right) = 1 - \\Phi\\left(\\frac{T-s}{\\sigma}\\right) = \\Phi\\left(-\\frac{T-s}{\\sigma}\\right) = \\Phi\\left(\\frac{s-T}{\\sigma}\\right)\n$$\n\nSubstituting the expression for $T$:\n\n$$\np_{\\text{bayes\\_right}}(s) = \\Phi\\left(\\frac{s - (-\\frac{\\sigma^2 \\mu_p}{\\tau_p^2})}{\\sigma}\\right) = \\Phi\\left(\\frac{s + \\frac{\\sigma^2 \\mu_p}{\\tau_p^2}}{\\sigma}\\right)\n$$\n\nFinally, we incorporate the lapse rate $\\lambda$, which is the probability of making a random choice regardless of the stimulus. With probability $1-\\lambda$, the observer follows the Bayesian decision rule, and with probability $\\lambda$, the observer guesses, choosing \"right\" with probability $0.5$. The full psychometric function $p_{\\mathrm{right}}(s)$ is therefore a mixture model:\n\n$$\np_{\\mathrm{right}}(s) = (1 - \\lambda) p_{\\text{bayes\\_right}}(s) + 0.5 \\lambda\n$$\n\n### Model Definitions and Specialization\n\nWe consider two distinct models of suboptimality:\n\n1.  **Incorrect-Prior Model:** Suboptimality arises from a biased or incorrectly calibrated prior. Here, the sensory noise $\\sigma$ is assumed to be known and fixed at a baseline value $\\sigma_0$. The free parameters to be fitted are the prior mean $\\mu_p$, the prior standard deviation $\\tau_p$, and the lapse rate $\\lambda$. The psychometric function is:\n    $$\n    p_{\\mathrm{right}}(s; \\mu_p, \\tau_p, \\lambda | \\sigma_0) = (1-\\lambda) \\Phi\\left( \\frac{s + \\frac{\\sigma_0^2 \\mu_p}{\\tau_p^2}}{\\sigma_0} \\right) + 0.5 \\lambda\n    $$\n\n2.  **Incorrect-Noise Model:** Suboptimality arises from elevated sensory noise. Here, the prior is assumed to be \"flat\" or uninformative, which corresponds to setting $\\mu_p=0$ and letting $\\tau_p \\to \\infty$. In this limit, the decision threshold $T = -\\frac{\\sigma^2 \\mu_p}{\\tau_p^2}$ approaches $0$. The decision rule simplifies to $x > 0$. The free parameters are the sensory noise standard deviation $\\sigma$ and the lapse rate $\\lambda$. The psychometric function becomes:\n    $$\n    p_{\\mathrm{right}}(s; \\sigma, \\lambda) = (1-\\lambda) \\Phi\\left(\\frac{s}{\\sigma}\\right) + 0.5 \\lambda\n    $$\n\n### Model Fitting and Comparison\n\nTo fit these models to data, we use maximum likelihood estimation. The data consist of pairs $(k_i, n_i)$ for each stimulus level $s_i$, where $k_i$ is the number of \"right\" choices out of $n_i$ total trials. The likelihood of observing $k_i$ for a given $s_i$ follows a binomial distribution:\n\n$$\nL_i(\\theta) = P(k_i \\mid n_i, s_i; \\theta) = \\binom{n_i}{k_i} p_{\\mathrm{right}}(s_i; \\theta)^{k_i} (1 - p_{\\mathrm{right}}(s_i; \\theta))^{n_i - k_i}\n$$\nwhere $\\theta$ represents the set of free parameters for a given model. The total log-likelihood is the sum over all stimulus levels: $\\ln \\hat{L}(\\theta) = \\sum_i \\ln L_i(\\theta)$. We seek the parameters $\\hat{\\theta}$ that maximize this function, which is equivalent to minimizing the negative log-likelihood (NLL).\n\nFor model comparison, we use the Bayesian Information Criterion (BIC):\n$$\n\\mathrm{BIC} = k \\ln N - 2 \\ln \\hat{L}\n$$\nwhere $k$ is the number of free parameters in the model ($k=3$ for the prior model, $k=2$ for the noise model), $N = \\sum_i n_i$ is the total number of trials, and $\\hat{L}$ is the maximized likelihood value. The model with the lower BIC is preferred, as it provides a better trade-off between goodness of fit and model complexity.\n\nThe implementation will proceed by first generating the synthetic count data $k_i = \\text{round}(n_i p_{\\mathrm{right}}(s_i))$ using the true generative parameters for each test case. Then, for each dataset, we will minimize the NLL for both the incorrect-prior and incorrect-noise models using numerical optimization, subject to parameter constraints ($\\tau_p > 0$, $\\sigma > 0$, $0 \\le \\lambda < 1$). Finally, we will compute the BIC for each model, select the one with the lower BIC, and check if this matches the ground-truth generating mechanism.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.optimize import minimize\nfrom scipy.stats import norm\n\n# from scipy import ...\n\ndef solve():\n    \"\"\"\n    Main function to run the model comparison for the Bayesian observer.\n    \"\"\"\n\n    # Helper function to prevent log(0) issues\n    def _safe_log(x):\n        return np.log(np.maximum(x, 1e-9))\n\n    # --- Psychometric Function Definitions ---\n\n    def psychometric_function_prior(s, mu_p, tau_p, lam, sigma_0):\n        \"\"\"\n        Psychometric function for the 'incorrect-prior' model.\n        p_right(s) = (1-lambda) * Phi((s + (sigma_0^2 * mu_p / tau_p^2)) / sigma_0) + 0.5 * lambda\n        \"\"\"\n        # Ensure tau_p is positive\n        tau_p = np.maximum(tau_p, 1e-9)\n        \n        # Bayesian part: probability of making a 'right' choice based on evidence\n        p_bayes_right = norm.cdf((s + (sigma_0**2 * mu_p) / tau_p**2) / sigma_0)\n        \n        # Mixture with lapse rate\n        p_right = (1.0 - lam) * p_bayes_right + 0.5 * lam\n        return p_right\n\n    def psychometric_function_noise(s, sigma, lam):\n        \"\"\"\n        Psychometric function for the 'incorrect-noise' model.\n        p_right(s) = (1-lambda) * Phi(s / sigma) + 0.5 * lambda\n        \"\"\"\n        # Ensure sigma is positive\n        sigma = np.maximum(sigma, 1e-9)\n        \n        # Bayesian part (with flat prior)\n        p_bayes_right = norm.cdf(s / sigma)\n        \n        # Mixture with lapse rate\n        p_right = (1.0 - lam) * p_bayes_right + 0.5 * lam\n        return p_right\n\n    # --- Negative Log-Likelihood (NLL) Definitions ---\n\n    def nll_prior(params, s, k, n, sigma_0):\n        \"\"\"Negative log-likelihood for the incorrect-prior model.\"\"\"\n        mu_p, tau_p, lam = params\n        p_right = psychometric_function_prior(s, mu_p, tau_p, lam, sigma_0)\n        \n        log_likelihood = k * _safe_log(p_right) + (n - k) * _safe_log(1.0 - p_right)\n        return -np.sum(log_likelihood)\n\n    def nll_noise(params, s, k, n):\n        \"\"\"Negative log-likelihood for the incorrect-noise model.\"\"\"\n        sigma, lam = params\n        p_right = psychometric_function_noise(s, sigma, lam)\n        \n        log_likelihood = k * _safe_log(p_right) + (n - k) * _safe_log(1.0 - p_right)\n        return -np.sum(log_likelihood)\n\n    # --- Fitter and BIC Calculation ---\n\n    def fit_and_compare(s, k, n, sigma_0, ground_truth_label):\n        \"\"\"\n        Fits both models, computes BIC, and compares to ground truth.\n        \"\"\"\n        total_trials = np.sum(n)\n        \n        # 1. Fit Incorrect-Prior Model\n        params_prior_initial = [0.0, 1.0, 0.05]\n        bounds_prior = [(-np.inf, np.inf), (1e-6, np.inf), (0, 0.999)]\n        \n        res_prior = minimize(\n            nll_prior,\n            params_prior_initial,\n            args=(s, k, n, sigma_0),\n            method='L-BFGS-B',\n            bounds=bounds_prior\n        )\n        \n        nll_min_prior = res_prior.fun\n        num_params_prior = 3\n        bic_prior = num_params_prior * np.log(total_trials) + 2 * nll_min_prior\n\n        # 2. Fit Incorrect-Noise Model\n        params_noise_initial = [1.0, 0.05]\n        bounds_noise = [(1e-6, np.inf), (0, 0.999)]\n\n        res_noise = minimize(\n            nll_noise,\n            params_noise_initial,\n            args=(s, k, n),\n            method='L-BFGS-B',\n            bounds=bounds_noise\n        )\n        \n        nll_min_noise = res_noise.fun\n        num_params_noise = 2\n        bic_noise = num_params_noise * np.log(total_trials) + 2 * nll_min_noise\n\n        # 3. Compare models\n        if bic_prior  bic_noise:\n            selected_model = \"prior\"\n        else:\n            selected_model = \"noise\"\n            \n        return selected_model == ground_truth_label\n\n    # --- Test Cases ---\n\n    test_cases = [\n        # Test Case A (happy path, incorrect priors)\n        {\n            \"sigma_0\": 1.0,\n            \"gen_params\": {\"mu_p\": 0.8, \"tau_p\": 0.7, \"sigma\": 1.0, \"lambda\": 0.05},\n            \"gen_model\": \"prior\",\n            \"ground_truth\": \"prior\"\n        },\n        # Test Case B (happy path, increased noise)\n        {\n            \"sigma_0\": 1.0,\n            \"gen_params\": {\"mu_p\": 0.0, \"tau_p\": np.inf, \"sigma\": 2.0, \"lambda\": 0.05},\n            \"gen_model\": \"noise\",\n            \"ground_truth\": \"noise\"\n        },\n        # Test Case C (boundary condition, high lapse with incorrect priors)\n        {\n            \"sigma_0\": 1.5,\n            \"gen_params\": {\"mu_p\": 0.6, \"tau_p\": 0.5, \"sigma\": 1.5, \"lambda\": 0.3},\n            \"gen_model\": \"prior\",\n            \"ground_truth\": \"prior\"\n        }\n    ]\n    \n    stim_levels = np.array([-3.0, -2.0, -1.0, 0.0, 1.0, 2.0, 3.0])\n    num_trials_per_level = np.full_like(stim_levels, 1000)\n\n    results = []\n\n    for case in test_cases:\n        # Generate synthetic data deterministically\n        gp = case[\"gen_params\"]\n        if case[\"gen_model\"] == \"prior\":\n            p_gen = psychometric_function_prior(stim_levels, gp[\"mu_p\"], gp[\"tau_p\"], gp[\"lambda\"], gp[\"sigma\"])\n        else: # \"noise\" model\n            p_gen = psychometric_function_noise(stim_levels, gp[\"sigma\"], gp[\"lambda\"])\n        \n        k_counts = np.round(num_trials_per_level * p_gen).astype(int)\n        \n        # Run the fitting and comparison\n        is_correct = fit_and_compare(\n            stim_levels,\n            k_counts,\n            num_trials_per_level,\n            case[\"sigma_0\"],\n            case[\"ground_truth\"]\n        )\n        results.append(is_correct)\n    \n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        }
    ]
}