{
    "hands_on_practices": [
        {
            "introduction": "在主动推断和预测性加工的框架下，大脑的一个核心功能是根据新的感官证据不断更新其对世界的内部（生成）模型。本练习将深入探讨这一过程的数学机制，特别是智能体如何推断其感官信息的可靠性或“精度”($\\lambda_y$)。掌握这种共轭先验（Gamma-Gaussian）模型中精度参数的贝叶斯更新，是构建更复杂生成模型的基石，对于理解信念更新的动态至关重要。",
            "id": "3961700",
            "problem": "考虑一个预测性处理生成模型中的单个层级，其中观测噪声精度对预测误差进行加权。设 $\\{y_t\\}_{t=1}^{T}$ 是在给定潜状态 $\\{x_t\\}_{t=1}^{T}$ 和一个观测精度参数 $\\lambda_{y}$ 的情况下的条件独立标量观测值。似然函数为高斯分布，其精度为 $\\lambda_{y}$，均值为 $c^{\\top} x_t$，其中 $c \\in \\mathbb{R}^{n}$ 是一个固定的设计向量，因此对于每个 $t$，\n$$\np(y_t \\mid x_t, \\lambda_{y}) = \\mathcal{N}\\!\\big(y_t; c^{\\top} x_t, \\lambda_{y}^{-1}\\big).\n$$\n假设精度的先验是在形状-率参数化下的Gamma分布，\n$$\np(\\lambda_{y}) = \\mathrm{Gamma}(\\lambda_{y}; \\alpha_{0}, \\beta_{0}),\n$$\n其形状参数 $\\alpha_{0} > 0$，率参数 $\\beta_{0} > 0$。设潜状态的近似后验由一个平均场高斯因子给出，\n$$\nq(x_1, \\dots, x_T) = \\prod_{t=1}^{T} \\mathcal{N}\\!\\big(x_t; m_t, S_t\\big),\n$$\n其均值为 $m_t \\in \\mathbb{R}^{n}$，协方差为 $S_t \\in \\mathbb{R}^{n \\times n}$。在平均场假设下，$q(\\lambda_{y})$ 与 $q(x_1, \\dots, x_T)$ 相互独立，最优因子 $q^{\\ast}(\\lambda_{y})$ 最小化变分自由能 (VFE)，等价于最大化证据下界 (ELBO)，并满足\n$$\nq^{\\ast}(\\lambda_{y}) \\propto \\exp\\!\\left(\\mathbb{E}_{q(x_1,\\dots,x_T)}\\big[\\ln p(y_1,\\dots,y_T, x_1,\\dots,x_T, \\lambda_{y})\\big]\\right).\n$$\n从贝叶斯法则、带精度的高斯似然和Gamma先验的定义，以及上述平均场变分更新规则出发，推导后验期望 $\\mathbb{E}_{q^{\\ast}(\\lambda_{y})}[\\lambda_{y}]$ 的闭式解析表达式。该表达式应以超参数 $\\alpha_{0}$、$\\beta_{0}$、观测值 $\\{y_t\\}_{t=1}^{T}$、设计向量 $c$ 以及近似后验的充分统计量 $\\{m_t, S_t\\}_{t=1}^{T}$ 来表示。\n\n你的最终答案必须是关于 $\\mathbb{E}_{q^{\\ast}(\\lambda_{y})}[\\lambda_{y}]$ 的单个闭式解析表达式。不需要数值。不包括单位。不需要四舍五入。",
            "solution": "该问题定义明确且具有科学依据，是平均场变分推断在共轭指数族模型上的一个标准应用。我们接下来进行推导。\n\n我们的目标是找到后验期望 $\\mathbb{E}_{q^{\\ast}(\\lambda_{y})}[\\lambda_{y}]$ 的闭式表达式。推导从最优变分分布 $q^{\\ast}(\\lambda_{y})$ 的标准更新规则开始，该规则由下式给出：\n$$\nq^{\\ast}(\\lambda_{y}) \\propto \\exp\\!\\left(\\mathbb{E}_{q(x_1,\\dots,x_T)}\\big[\\ln p(y_1,\\dots,y_T, x_1,\\dots,x_T, \\lambda_{y})\\big]\\right)\n$$\n这意味着 $q^{\\ast}(\\lambda_{y})$ 的对数由下式给出：\n$$\n\\ln q^{\\ast}(\\lambda_{y}) = \\mathbb{E}_{q(x_{1:T})}\\big[\\ln p(y_{1:T}, x_{1:T}, \\lambda_{y})\\big] + \\text{constant}\n$$\n其中常数项包含所有不依赖于 $\\lambda_{y}$ 的项。联合概率分布可以使用概率的链式法则进行分解：\n$$\np(y_{1:T}, x_{1:T}, \\lambda_{y}) = p(y_{1:T} | x_{1:T}, \\lambda_{y}) p(x_{1:T} | \\lambda_{y}) p(\\lambda_{y})\n$$\n在这个层级模型中，通常假设潜状态的先验 $p(x_{1:T})$ 与观测精度 $\\lambda_{y}$ 独立，即 $p(x_{1:T} | \\lambda_{y}) = p(x_{1:T})$。在此假设下，$\\ln p(x_{1:T})$ 项相对于 $\\lambda_y$ 是一个常数，可以被吸收到归一化常数中。因此，$\\ln q^{\\ast}(\\lambda_{y})$ 的表达式简化为：\n$$\n\\ln q^{\\ast}(\\lambda_{y}) = \\mathbb{E}_{q(x_{1:T})}\\big[\\ln p(y_{1:T} | x_{1:T}, \\lambda_{y})\\big] + \\ln p(\\lambda_{y}) + \\text{constant}\n$$\n鉴于观测值 $\\{y_t\\}$ 是条件独立的，对数似然项展开为一个和式：\n$$\n\\ln p(y_{1:T} | x_{1:T}, \\lambda_{y}) = \\sum_{t=1}^{T} \\ln p(y_t | x_t, \\lambda_y)\n$$\n单个观测的似然是高斯分布，$p(y_t \\mid x_t, \\lambda_{y}) = \\mathcal{N}(y_t; c^{\\top} x_t, \\lambda_{y}^{-1})$。该高斯概率密度函数的对数为：\n$$\n\\ln p(y_t \\mid x_t, \\lambda_{y}) = \\frac{1}{2}\\ln \\lambda_y - \\frac{1}{2}\\ln(2\\pi) - \\frac{\\lambda_y}{2}(y_t - c^{\\top}x_t)^2\n$$\n接下来，我们计算该量关于近似后验 $q(x_{1:T})$ 的期望。由于平均场假设 $q(x_{1:T}) = \\prod_{t=1}^{T} q(x_t)$，和的期望等于期望的和：\n$$\n\\mathbb{E}_{q(x_{1:T})}\\left[ \\sum_{t=1}^{T} \\ln p(y_t | x_t, \\lambda_y) \\right] = \\sum_{t=1}^{T} \\mathbb{E}_{q(x_t)}\\left[ \\frac{1}{2}\\ln \\lambda_y - \\frac{1}{2}\\ln(2\\pi) - \\frac{\\lambda_y}{2}(y_t - c^{\\top}x_t)^2 \\right]\n$$\n项 $\\frac{1}{2}\\ln \\lambda_y$ 和 $-\\frac{1}{2}\\ln(2\\pi)$ 相对于 $x_t$ 是常数。期望计算集中在平方误差项上：\n$$\n\\mathbb{E}_{q(x_t)}\\left[(y_t - c^{\\top}x_t)^2\\right] = \\mathbb{E}_{q(x_t)}\\left[ y_t^2 - 2y_t c^{\\top}x_t + (c^{\\top}x_t)^2 \\right]\n$$\n利用期望的线性性质和给定的 $q(x_t) = \\mathcal{N}(x_t; m_t, S_t)$ 的统计量，其中 $\\mathbb{E}_{q(x_t)}[x_t] = m_t$：\n$$\n\\mathbb{E}_{q(x_t)}\\left[(y_t - c^{\\top}x_t)^2\\right] = y_t^2 - 2y_t c^{\\top}\\mathbb{E}_{q(x_t)}[x_t] + \\mathbb{E}_{q(x_t)}[(c^{\\top}x_t)^2] = y_t^2 - 2y_t c^{\\top}m_t + \\mathbb{E}_{q(x_t)}[(c^{\\top}x_t)^2]\n$$\n对于二次项，我们使用性质 $\\mathbb{E}[Z^2] = \\mathrm{Var}[Z] + (\\mathbb{E}[Z])^2$。令 $Z = c^{\\top}x_t$。那么 $\\mathbb{E}[Z] = c^{\\top}\\mathbb{E}[x_t] = c^{\\top}m_t$ 且 $\\mathrm{Var}[Z] = c^{\\top}\\mathrm{Cov}(x_t)c = c^{\\top}S_t c$。\n因此，$\\mathbb{E}_{q(x_t)}[(c^{\\top}x_t)^2] = c^{\\top}S_t c + (c^{\\top}m_t)^2$。\n将其代回，期望平方误差为：\n$$\n\\mathbb{E}_{q(x_t)}\\left[(y_t - c^{\\top}x_t)^2\\right] = y_t^2 - 2y_t c^{\\top}m_t + (c^{\\top}m_t)^2 + c^{\\top}S_t c = (y_t - c^{\\top}m_t)^2 + c^{\\top}S_t c\n$$\n现在，我们可以写出完整的期望对数似然：\n$$\n\\mathbb{E}_{q(x_{1:T})}\\left[ \\ln p(y_{1:T} | x_{1:T}, \\lambda_{y}) \\right] = \\sum_{t=1}^{T} \\left( \\frac{1}{2}\\ln\\lambda_y - \\frac{\\lambda_y}{2}\\left[ (y_t - c^{\\top}m_t)^2 + c^{\\top}S_t c \\right] \\right) + \\text{const.}\n$$\n$$\n= \\frac{T}{2}\\ln\\lambda_y - \\frac{\\lambda_y}{2} \\sum_{t=1}^{T} \\left[ (y_t - c^{\\top}m_t)^2 + c^{\\top}S_t c \\right] + \\text{const.}\n$$\n精度的先验是 Gamma 分布，$p(\\lambda_{y}) = \\mathrm{Gamma}(\\lambda_{y}; \\alpha_{0}, \\beta_{0})$。其对数为：\n$$\n\\ln p(\\lambda_{y}) = (\\alpha_0 - 1)\\ln\\lambda_y - \\beta_0\\lambda_y + \\text{const.}\n$$\n结合期望对数似然和对数先验来求 $\\ln q^{\\ast}(\\lambda_{y})$：\n$$\n\\ln q^{\\ast}(\\lambda_{y}) = \\left( \\frac{T}{2}\\ln\\lambda_y - \\frac{\\lambda_y}{2} \\sum_{t=1}^{T} \\left[ (y_t - c^{\\top}m_t)^2 + c^{\\top}S_t c \\right] \\right) + \\left( (\\alpha_0 - 1)\\ln\\lambda_y - \\beta_0\\lambda_y \\right) + \\text{const.}\n$$\n我们根据各项对 $\\lambda_y$ 的依赖关系进行分组：\n$$\n\\ln q^{\\ast}(\\lambda_{y}) = \\left(\\alpha_0 + \\frac{T}{2} - 1\\right)\\ln\\lambda_y - \\left(\\beta_0 + \\frac{1}{2} \\sum_{t=1}^{T} \\left[ (y_t - c^{\\top}m_t)^2 + c^{\\top}S_t c \\right]\\right)\\lambda_y + \\text{const.}\n$$\n这个表达式是一个Gamma分布核的对数。通过观察，我们可以确定 $q^{\\ast}(\\lambda_y)$ 是一个Gamma分布，$q^{\\ast}(\\lambda_{y}) = \\mathrm{Gamma}(\\lambda_{y}; \\alpha_N, \\beta_N)$，其更新后的形状参数为 $\\alpha_N$，率参数为 $\\beta_N$：\n$$\n\\alpha_N = \\alpha_0 + \\frac{T}{2}\n$$\n$$\n\\beta_N = \\beta_0 + \\frac{1}{2} \\sum_{t=1}^{T} \\left[ (y_t - c^{\\top}m_t)^2 + c^{\\top}S_t c \\right]\n$$\n服从形状参数为 $\\alpha$、率参数为 $\\beta$ 的Gamma分布的随机变量的期望由比率 $\\frac{\\alpha}{\\beta}$ 给出。因此，$\\lambda_y$ 的后验期望是：\n$$\n\\mathbb{E}_{q^{\\ast}(\\lambda_{y})}[\\lambda_{y}] = \\frac{\\alpha_N}{\\beta_N} = \\frac{\\alpha_0 + \\frac{T}{2}}{\\beta_0 + \\frac{1}{2} \\sum_{t=1}^{T} \\left[ (y_t - c^{\\top}m_t)^2 + c^{\\top}S_t c \\right]}\n$$\n这就是观测精度后验期望的最终闭式表达式。它正确地依赖于先验超参数、观测值以及潜状态近似后验的充分统计量。",
            "answer": "$$\n\\boxed{\\frac{\\alpha_{0} + \\frac{T}{2}}{\\beta_{0} + \\frac{1}{2} \\sum_{t=1}^{T} \\left[ (y_t - c^{\\top}m_t)^2 + c^{\\top}S_t c \\right]}}\n$$"
        },
        {
            "introduction": "在更新了对世界状态的信念之后，主动推断智能体必须决定下一步该做什么。本练习探讨了这一决策过程，其中策略的选择旨在最小化“期望自由能”($G(\\pi)$)。你将推导出标准的 softmax 策略选择规则，并观察一个“温度”参数 $\\tau$ 如何控制在利用已知最佳策略和探索其他可能性之间的平衡，这是对“有限理性”的一个关键建模方式。",
            "id": "4055588",
            "problem": "在预测编码框架 (PCF) 和主动推理 (AI) 中，智能体通过权衡预测结果与认知价值和实用价值来选择策略。一种常见的构造假设存在一个有限的候选策略集 $\\Pi = \\{\\pi_i\\}_{i=1}^{K}$，每个策略都被赋予一个期望自由能 $G(\\pi_i) \\in \\mathbb{R}$，该自由能概括了预测的不准确性和模糊性。策略的后验概率是通过最小化一个在低期望自由能和高熵之间进行权衡的正则化变分目标函数来获得的。考虑变分泛函\n$$\n\\mathcal{F}[q] \\equiv \\sum_{i=1}^{K} q(\\pi_i)\\, G(\\pi_i) + \\tau \\sum_{i=1}^{K} q(\\pi_i)\\,\\ln q(\\pi_i),\n$$\n其受归一化约束 $\\sum_{i=1}^{K} q(\\pi_i) = 1$ 的限制，其中 $\\tau > 0$ 是一个控制策略选择随机性的温度（逆精度）参数。该目标函数是一种经过充分检验的自由能正则化的期望自由能形式，用于在神经形态和类脑实现中对不确定性下的有限理性选择进行建模。\n\n任务：\n- 从上述泛函和归一化约束出发，推导使 $\\mathcal{F}[q]$ 最小化的策略后验概率 $q_{\\tau}(\\pi_i)$ 的表达式。\n- 将情况特化为 $K = 2$ 个策略，其中 $G(\\pi_1) = 1.2$，$G(\\pi_2) = 1.8$。将 $q_{\\tau}(\\pi_1)$ 表示为 $\\tau$ 的封闭形式函数。\n- 确定唯一的温度 $\\tau^{\\star} > 0$，使得 $q_{\\tau^{\\star}}(\\pi_1) = 0.9$。将 $\\tau^{\\star}$ 的最终数值答案四舍五入到4位有效数字。将 $\\tau^{\\star}$ 报告为无量纲量（无单位）。",
            "solution": "问题要求关于预测编码框架中用于策略选择的变分目标函数的三个相关结果。我们将依次解决每个任务。\n\n首先，我们必须推导在归一化约束下，使变分泛函 $\\mathcal{F}[q]$ 最小化的策略后验概率 $q_{\\tau}(\\pi_i)$ 的一般表达式。泛函由下式给出：\n$$\n\\mathcal{F}[q] \\equiv \\sum_{i=1}^{K} q(\\pi_i)\\, G(\\pi_i) + \\tau \\sum_{i=1}^{K} q(\\pi_i)\\,\\ln q(\\pi_i)\n$$\n其中 $q(\\pi_i)$ 是选择策略 $\\pi_i$ 的概率，$G(\\pi_i)$ 是其相关的期望自由能，$\\tau > 0$ 是一个温度参数。该最小化问题受限于 $q$ 是一个有效的概率分布这一约束：\n$$\n\\sum_{i=1}^{K} q(\\pi_i) = 1\n$$\n这是一个约束优化问题，可以使用拉格朗日乘数法来解决。为简单起见，我们记 $q_i \\equiv q(\\pi_i)$ 和 $G_i \\equiv G(\\pi_i)$。通过将目标泛函与约束（乘以一个拉格朗日乘子 $\\lambda$）相结合，构建拉格朗日量 $\\mathcal{L}$：\n$$\n\\mathcal{L}(q_1, \\dots, q_K, \\lambda) = \\left( \\sum_{i=1}^{K} q_i G_i + \\tau \\sum_{i=1}^{K} q_i \\ln q_i \\right) - \\lambda \\left( \\sum_{i=1}^{K} q_i - 1 \\right)\n$$\n为了找到使 $\\mathcal{F}[q]$ 最小化的分布 $\\{q_i\\}$，我们对 $\\mathcal{L}$ 关于每个 $q_j$ 求偏导数，并令其为零。\n$$\n\\frac{\\partial \\mathcal{L}}{\\partial q_j} = \\frac{\\partial}{\\partial q_j} \\left( q_j G_j + \\tau q_j \\ln q_j - \\lambda q_j \\right) = 0\n$$\n使用 $q_j \\ln q_j$ 的导数的乘法法则，即 $1 \\cdot \\ln q_j + q_j \\cdot \\frac{1}{q_j} = \\ln q_j + 1$，我们得到：\n$$\nG_j + \\tau (\\ln q_j + 1) - \\lambda = 0\n$$\n现在，我们求解 $q_j$：\n$$\n\\tau \\ln q_j = \\lambda - G_j - \\tau\n$$\n$$\n\\ln q_j = \\frac{\\lambda - \\tau}{\\tau} - \\frac{G_j}{\\tau}\n$$\n$$\nq_j = \\exp\\left(\\frac{\\lambda - \\tau}{\\tau}\\right) \\exp\\left(-\\frac{G_j}{\\tau}\\right)\n$$\n项 $\\exp\\left(\\frac{\\lambda - \\tau}{\\tau}\\right)$ 是一个与索引 $j$ 无关的常数。我们称之为 $C$。因此，$q_j = C \\exp\\left(-\\frac{G_j}{\\tau}\\right)$。我们通过应用归一化约束 $\\sum_{j=1}^{K} q_j = 1$ 来确定常数 $C$：\n$$\n\\sum_{j=1}^{K} C \\exp\\left(-\\frac{G_j}{\\tau}\\right) = 1\n$$\n$$\nC \\left( \\sum_{j=1}^{K} \\exp\\left(-\\frac{G_j}{\\tau}\\right) \\right) = 1\n$$\n$$\nC = \\frac{1}{\\sum_{k=1}^{K} \\exp\\left(-\\frac{G_k}{\\tau}\\right)}\n$$\n将此代回 $q_j$ 的表达式，我们得到策略后验概率，这是一个吉布斯-玻尔兹曼分布：\n$$\nq_{\\tau}(\\pi_i) = \\frac{\\exp\\left(-\\frac{G(\\pi_i)}{\\tau}\\right)}{\\sum_{j=1}^{K} \\exp\\left(-\\frac{G(\\pi_j)}{\\tau}\\right)}\n$$\n这是第一个任务的解。该分布也称为应用于负的缩放期望自由能 $-\\frac{G(\\pi_i)}{\\tau}$ 的 softmax 函数。\n\n第二，我们必须将此结果特化到 $K=2$ 个策略的情况，其期望自由能分别为 $G(\\pi_1) = 1.2$ 和 $G(\\pi_2) = 1.8$。我们需要找到 $q_{\\tau}(\\pi_1)$ 的封闭形式表达式。使用上面推导的通用公式：\n$$\nq_{\\tau}(\\pi_1) = \\frac{\\exp\\left(-\\frac{G(\\pi_1)}{\\tau}\\right)}{\\exp\\left(-\\frac{G(\\pi_1)}{\\tau}\\right) + \\exp\\left(-\\frac{G(\\pi_2)}{\\tau}\\right)}\n$$\n代入给定值 $G(\\pi_1) = 1.2$ 和 $G(\\pi_2) = 1.8$：\n$$\nq_{\\tau}(\\pi_1) = \\frac{\\exp\\left(-\\frac{1.2}{\\tau}\\right)}{\\exp\\left(-\\frac{1.2}{\\tau}\\right) + \\exp\\left(-\\frac{1.8}{\\tau}\\right)}\n$$\n为了简化此表达式，我们可以将分子和分母同时除以 $\\exp\\left(-\\frac{1.2}{\\tau}\\right)$：\n$$\nq_{\\tau}(\\pi_1) = \\frac{1}{1 + \\frac{\\exp\\left(-\\frac{1.8}{\\tau}\\right)}{\\exp\\left(-\\frac{1.2}{\\tau}\\right)}} = \\frac{1}{1 + \\exp\\left(-\\frac{1.8}{\\tau} - \\left(-\\frac{1.2}{\\tau}\\right)\\right)}\n$$\n$$\nq_{\\tau}(\\pi_1) = \\frac{1}{1 + \\exp\\left(\\frac{1.2 - 1.8}{\\tau}\\right)} = \\frac{1}{1 + \\exp\\left(-\\frac{0.6}{\\tau}\\right)}\n$$\n这是 $q_{\\tau}(\\pi_1)$ 作为 $\\tau$ 的函数的封闭形式表达式，它具有 logistic sigmoid 函数的形式。\n\n第三，我们需要找到特定的温度 $\\tau^{\\star} > 0$，使得选择第一个策略的概率为 $q_{\\tau^{\\star}}(\\pi_1) = 0.9$。我们将推导出的 $q_{\\tau}(\\pi_1)$ 表达式设为 $0.9$，并求解 $\\tau = \\tau^{\\star}$：\n$$\n\\frac{1}{1 + \\exp\\left(-\\frac{0.6}{\\tau^{\\star}}\\right)} = 0.9\n$$\n重新整理方程以求解 $\\tau^{\\star}$：\n$$\n1 = 0.9 \\left(1 + \\exp\\left(-\\frac{0.6}{\\tau^{\\star}}\\right)\\right)\n$$\n$$\n\\frac{1}{0.9} = 1 + \\exp\\left(-\\frac{0.6}{\\tau^{\\star}}\\right)\n$$\n$$\n\\frac{10}{9} - 1 = \\exp\\left(-\\frac{0.6}{\\tau^{\\star}}\\right)\n$$\n$$\n\\frac{1}{9} = \\exp\\left(-\\frac{0.6}{\\tau^{\\star}}\\right)\n$$\n为了分离出 $\\tau^{\\star}$，我们取等式两边的自然对数：\n$$\n\\ln\\left(\\frac{1}{9}\\right) = -\\frac{0.6}{\\tau^{\\star}}\n$$\n使用属性 $\\ln(1/x) = -\\ln(x)$：\n$$\n-\\ln(9) = -\\frac{0.6}{\\tau^{\\star}}\n$$\n$$\n\\ln(9) = \\frac{0.6}{\\tau^{\\star}}\n$$\n最后，求解 $\\tau^{\\star}$：\n$$\n\\tau^{\\star} = \\frac{0.6}{\\ln(9)}\n$$\n这是 $\\tau^{\\star}$ 的精确解析表达式。问题要求一个四舍五入到4位有效数字的数值答案。我们计算其值：\n$$\n\\tau^{\\star} = \\frac{0.6}{\\ln(9)} \\approx \\frac{0.6}{2.197224577...} \\approx 0.2730591...\n$$\n将此结果四舍五入到4位有效数字，得到 $0.2731$。",
            "answer": "$$\\boxed{0.2731}$$"
        },
        {
            "introduction": "最后的这个练习将知觉和行动结合在一起，以阐明主动推断的核心原则：我们的行动不仅是为了实现目标，也是为了减少关于世界的不确定性。你将通过编程实现一个模型，其中智能体通过计算行动的“认知价值”（epistemic value）——即关于世界状态不确定性的预期减少量——来决定是否执行一个信息收集的动作。这个练习将好奇心和信息寻求行为等抽象概念，以一种计算上具体的方式呈现出来。",
            "id": "4011073",
            "problem": "考虑一个遵循预测编码和主动推断 (AI) 传统的二元隐状态生成模型，其中智能体可以采取行动来影响后续感官数据的信息量。隐状态用 $s \\in \\{0,1\\}$ 表示，观测用 $o \\in \\{0,1\\}$ 表示，行动用 $a \\in \\{0,1\\}$ 表示，其中 $a=0$ 表示信息量较少（被动）的采样，$a=1$ 表示信息量较多（主动）的采样。智能体对隐状态的先验信念为 $p(s=1)=\\pi$ 和 $p(s=0)=1-\\pi$。\n\n在给定隐状态和行动的情况下，观测的似然模型由一个依赖于行动的准确度参数 $\\alpha_a \\in [0.5,1]$ 进行参数化，并具有以下对称性：\n- $p(o=1 \\mid s=1,a)=\\alpha_a$， $p(o=0 \\mid s=1,a)=1-\\alpha_a$，\n- $p(o=0 \\mid s=0,a)=\\alpha_a$， $p(o=1 \\mid s=0,a)=1-\\alpha_a$。\n\n任务是通过计算采取行动后后验熵的期望减少量，来展示主动推断如何通过消除状态模糊性的行动来解决模糊的感官输入。请使用以下基本原理：\n- 贝叶斯法则：$p(s \\mid o,a) = \\dfrac{p(o \\mid s,a)\\,p(s)}{p(o \\mid a)}$，其中 $p(o \\mid a)=\\sum_{s} p(o \\mid s,a)\\,p(s)$。\n- 香农熵（单位：奈特）：对于一个二元分布 $p(s)$，$H[p(s)] = -\\sum_{s \\in \\{0,1\\}} p(s)\\,\\ln p(s)$。\n\n将行动 $a$ 的后验熵期望减少量定义为先验熵与在行动 $a$ 下观测到 $o$ 之后的期望后验熵之差，即：\n- 先验熵：$H[p(s)]$，\n- 给定一个观测的后验熵：$H[p(s \\mid o,a)]$，\n- 期望后验熵：$\\mathbb{E}_{o \\sim p(o \\mid a)}[H[p(s \\mid o,a)]]$，\n- 期望减少量：$H[p(s)] - \\mathbb{E}_{o \\sim p(o \\mid a)}[H[p(s \\mid o,a)]]$。\n\n您必须：\n1. 仅使用贝叶斯法则和香农熵，从第一性原理推导出对于任意给定的 $(\\pi,\\alpha_0,\\alpha_1)$，后验熵期望减少量的计算过程。\n2. 实现一个程序，该程序为每个测试用例计算 $a=0$ 和 $a=1$ 时的后验熵期望减少量，选择使期望减少量最大化的行动（平局时选择较小的索引），并为每个测试用例输出结果列表 $[R_0,R_1,A^\\ast]$，其中 $R_0$ 和 $R_1$ 分别是 $a=0$ 和 $a=1$ 时的期望减少量（单位：奈特，四舍五入到六位小数），$A^\\ast \\in \\{0,1\\}$ 是所选的行动索引。\n\n使用以下测试套件：\n- 用例 1：$\\pi=0.5$, $\\alpha_0=0.6$, $\\alpha_1=0.9$。\n- 用例 2：$\\pi=0.99$, $\\alpha_0=0.8$, $\\alpha_1=0.95$。\n- 用例 3：$\\pi=0.5$, $\\alpha_0=0.5$, $\\alpha_1=0.5$。\n- 用例 4：$\\pi=0.7$, $\\alpha_0=0.55$, $\\alpha_1=0.75$。\n\n所有熵值必须以奈特为单位表示，并四舍五入到六位小数。您的程序应生成单行输出，其中包含上述用例的结果，格式为一个由方括号括起来的逗号分隔列表，其中每个元素本身是 $[R_0,R_1,A^\\ast]$ 形式的列表。例如：$[[0.123456,0.234567,1],[\\dots]]$。\n\n不允许外部输入；请将测试套件硬编码在程序中。该解决方案必须在纯数学意义上适用，并且可以使用任何现代编程语言解决。请确保数值稳定性和科学真实性，不要引入无效概率（例如，$[0,1]$ 范围之外的概率）。",
            "solution": "首先根据既定标准对用户提供的问题进行验证。\n\n### 步骤 1：提取已知条件\n- **隐状态：** $s \\in \\{0,1\\}$\n- **观测：** $o \\in \\{0,1\\}$\n- **行动：** $a \\in \\{0,1\\}$\n- **先验信念：** $p(s=1) = \\pi$， $p(s=0) = 1-\\pi$。\n- **似然模型：** 这是一个对称二元信道，其中正确观测的概率为 $\\alpha_a \\in [0.5, 1]$，依赖于行动 $a$。\n  - $p(o=1 \\mid s=1,a) = \\alpha_a$\n  - $p(o=0 \\mid s=1,a) = 1-\\alpha_a$\n  - $p(o=0 \\mid s=0,a) = \\alpha_a$\n  - $p(o=1 \\mid s=0,a) = 1-\\alpha_a$\n- **基本原理：**\n  - 贝叶斯法则：$p(s \\mid o,a) = \\frac{p(o \\mid s,a)\\,p(s)}{p(o \\mid a)}$，其中 $p(o \\mid a) = \\sum_{s} p(o \\mid s,a)\\,p(s)$。\n  - 香农熵（单位：奈特）：$H[p(x)] = -\\sum_i p(x_i)\\,\\ln p(x_i)$。\n- **目标函数：** 行动 $a$ 的后验熵期望减少量，记为 $R_a$，定义为：\n  $R_a = H[p(s)] - \\mathbb{E}_{o \\sim p(o \\mid a)}[H[p(s \\mid o,a)]]$，其中：\n  - $H[p(s)]$ 是状态先验分布的熵。\n  - $H[p(s \\mid o,a)]$ 是在采取行动 $a$ 并观测到 $o$ 后，状态后验分布的熵。\n  - $\\mathbb{E}_{o \\sim p(o \\mid a)}[\\cdot]$ 表示对从分布 $p(o \\mid a)$ 中抽取的观测 $o$ 的期望。\n- **行动选择：** 最优行动 $A^\\ast$ 是使熵的期望减少量最大化的行动，平局时选择较小的行动索引 ($a=0$)。$A^\\ast = \\arg\\max_a R_a$。\n- **测试用例：**\n    1. $\\pi=0.5$, $\\alpha_0=0.6$, $\\alpha_1=0.9$\n    2. $\\pi=0.99$, $\\alpha_0=0.8$, $\\alpha_1=0.95$\n    3. $\\pi=0.5$, $\\alpha_0=0.5$, $\\alpha_1=0.5$\n    4. $\\pi=0.7$, $\\alpha_0=0.55$, $\\alpha_1=0.75$\n\n### 步骤 2：使用提取的已知条件进行验证\n- **科学依据：** 该问题牢固地植根于贝叶斯概率和信息论，这是计算神经科学和机器学习的基础。该模型虽然简单，却是一个标准范式，用于阐释主动推断和预测编码的原理，即智能体通过行动来减少其对世界的不确定性。该问题在科学上是合理的。\n- **良态问题：** 所有必要的参数（$\\pi, \\alpha_0, \\alpha_1$）、定义（熵、贝叶斯法则）和目标都已明确给出。该问题是自洽的，并且对于每个测试用例都有唯一的、可计算的解。\n- **客观性：** 该问题使用精确的数学语言陈述，没有任何主观或模棱两可的术语。\n- **其他标准：** 该问题没有矛盾、不完整或基于不切实际的物理学。这是一个可形式化且非平凡的计算任务。\n\n### 步骤 3：结论与行动\n该问题是有效的。下面将提供解决方案的逐步推导。\n\n### 解决方案推导\n\n解决方案需要为每个行动 $a \\in \\{0,1\\}$ 计算后验熵的期望减少量 $R_a$。这个量也被称为期望信息增益或互信息 $I(S;O|a)$。\n\n**1. 先验熵**\n二元状态 $s$ 的先验分布是参数为 $\\pi$ 的伯努利分布。其香农熵 $H[p(s)]$ 为：\n$$ H[p(s)] = -\\left[ p(s=0)\\ln(p(s=0)) + p(s=1)\\ln(p(s=1)) \\right] = -\\left[ (1-\\pi)\\ln(1-\\pi) + \\pi\\ln(\\pi) \\right] $$\n为简洁起见，我们可以使用二元熵函数 $h(x) = -x\\ln(x) - (1-x)\\ln(1-x)$。因此，$H[p(s)] = h(\\pi)$。按照惯例，$0\\ln(0)=0$，所以如果 $\\pi=0$ 或 $\\pi=1$，熵为 $0$。\n\n**2. 观测的边际概率**\n对于给定的行动 $a$ 和准确度参数 $\\alpha_a$，我们通过对隐状态 $s$ 进行边缘化来计算每个观测 $o$ 的概率：\n$$ p(o \\mid a) = \\sum_{s \\in \\{0,1\\}} p(o \\mid s, a) p(s) $$\n对于 $o=1$：\n$$ p(o=1 \\mid a) = p(o=1 \\mid s=1, a)p(s=1) + p(o=1 \\mid s=0, a)p(s=0) = \\alpha_a \\pi + (1-\\alpha_a)(1-\\pi) $$\n对于 $o=0$：\n$$ p(o=0 \\mid a) = p(o=0 \\mid s=1, a)p(s=1) + p(o=0 \\mid s=0, a)p(s=0) = (1-\\alpha_a)\\pi + \\alpha_a(1-\\pi) $$\n可以验证 $p(o=1 \\mid a) + p(o=0 \\mid a) = 1$。\n\n**3. 隐状态的后验概率**\n使用贝叶斯法则，我们求得在给定观测 $o$ 和行动 $a$ 的情况下，状态 $s=1$ 的后验概率，我们将其记为 $\\pi'_{o,a}$：\n$$ \\pi'_{o,a} = p(s=1 \\mid o, a) = \\frac{p(o \\mid s=1, a)p(s=1)}{p(o \\mid a)} $$\n若 $o=1$：\n$$ \\pi'_{1,a} = \\frac{\\alpha_a \\pi}{p(o=1 \\mid a)} = \\frac{\\alpha_a \\pi}{\\alpha_a \\pi + (1-\\alpha_a)(1-\\pi)} $$\n若 $o=0$：\n$$ \\pi'_{0,a} = \\frac{(1-\\alpha_a) \\pi}{p(o=0 \\mid a)} = \\frac{(1-\\alpha_a) \\pi}{(1-\\alpha_a)\\pi + \\alpha_a(1-\\pi)} $$\n那么状态 $s=0$ 的后验概率为 $1 - \\pi'_{o,a}$。\n\n**4. 期望后验熵**\n后验分布 $p(s \\mid o, a)$ 的熵是 $H[p(s \\mid o, a)] = h(\\pi'_{o,a})$。期望后验熵是这些后验熵的平均值，由每个观测的概率加权：\n$$ \\mathbb{E}_{o \\sim p(o \\mid a)}[H[p(s \\mid o,a)]] = p(o=0 \\mid a)H[p(s \\mid o=0, a)] + p(o=1 \\mid a)H[p(s \\mid o=1, a)] $$\n$$ \\mathbb{E}_{o \\sim p(o \\mid a)}[H[p(s \\mid o,a)]] = p(o=0 \\mid a) \\cdot h(\\pi'_{0,a}) + p(o=1 \\mid a) \\cdot h(\\pi'_{1,a}) $$\n\n**5. 熵的期望减少量**\n最终值 $R_a$ 是先验熵和期望后验熵之间的差值：\n$$ R_a = H[p(s)] - \\mathbb{E}_{o \\sim p(o \\mid a)}[H[p(s \\mid o,a)]] $$\n对 $a=0$（使用 $\\alpha_0$）和 $a=1$（使用 $\\alpha_1$）都执行此计算，以获得 $R_0$ 和 $R_1$。\n\n**6. 行动选择**\n智能体选择使期望信息增益最大化的行动。\n$$ A^\\ast = \\begin{cases} 1  \\text{if } R_1 > R_0 \\\\ 0  \\text{if } R_1 \\le R_0 \\end{cases} $$\n这遵循了指定的平局处理规则。每个测试用例的结果是一个三元组 $[R_0, R_1, A^\\ast]$。该过程的实现将在下一节中提供。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the Active Inference problem by calculating expected entropy reduction for given test cases.\n    \"\"\"\n    \n    # Define the test cases from the problem statement.\n    test_cases = [\n        # (pi, alpha_0, alpha_1)\n        (0.5, 0.6, 0.9),\n        (0.99, 0.8, 0.95),\n        (0.5, 0.5, 0.5),\n        (0.7, 0.55, 0.75),\n    ]\n\n    def binary_entropy(p):\n        \"\"\"\n        Calculates the Shannon entropy for a binary probability distribution p(x=1)=p.\n        H(p) = -p*ln(p) - (1-p)*ln(1-p) in nats.\n        Handles edge cases where p=0 or p=1.\n        \"\"\"\n        if p == 0 or p == 1:\n            return 0.0\n        return -p * np.log(p) - (1 - p) * np.log(1 - p)\n\n    def calculate_expected_reduction(pi, alpha_a):\n        \"\"\"\n        Computes the expected reduction in posterior entropy for a given prior pi and action accuracy alpha_a.\n        \"\"\"\n        # 1. Prior Entropy\n        prior_entropy = binary_entropy(pi)\n        \n        # If prior is certain, no uncertainty to reduce.\n        if prior_entropy == 0.0:\n            return 0.0\n\n        # Special case: if action is uninformative, posterior equals prior, so no reduction.\n        if alpha_a == 0.5:\n            return 0.0\n\n        # 2. Marginal Probability of Observations\n        # p(o=1 | a)\n        p_o1_a = alpha_a * pi + (1 - alpha_a) * (1 - pi)\n        # p(o=0 | a)\n        p_o0_a = 1.0 - p_o1_a\n\n        # 3. Posterior Probabilities of Hidden States\n        # p(s=1 | o=1, a)\n        # Handle cases where p_o1_a might be zero if pi=0 or pi=1.\n        if p_o1_a > 0:\n            post_s1_o1 = (alpha_a * pi) / p_o1_a\n        else: # This happens if pi=0 and alpha_a=1, or pi=1 and alpha_a=0 (not in domain)\n            post_s1_o1 = 0\n            \n        # p(s=1 | o=0, a)\n        if p_o0_a > 0:\n            post_s1_o0 = ((1 - alpha_a) * pi) / p_o0_a\n        else: # This happens if pi=1 and alpha_a=1, or pi=0 and alpha_a=0 (not in domain)\n            post_s1_o0 = 0\n\n        # 4. Expected Posterior Entropy\n        # H[p(s|o=1,a)]\n        post_entropy_o1 = binary_entropy(post_s1_o1)\n        # H[p(s|o=0,a)]\n        post_entropy_o0 = binary_entropy(post_s1_o0)\n        \n        expected_posterior_entropy = p_o1_a * post_entropy_o1 + p_o0_a * post_entropy_o0\n\n        # 5. Expected Reduction in Entropy\n        reduction = prior_entropy - expected_posterior_entropy\n        \n        return reduction\n\n    \n    results_str_list = []\n    for case in test_cases:\n        pi, alpha_0, alpha_1 = case\n        \n        # Compute reduction for action a=0\n        R0 = calculate_expected_reduction(pi, alpha_0)\n        \n        # Compute reduction for action a=1\n        R1 = calculate_expected_reduction(pi, alpha_1)\n        \n        # Select action that maximizes reduction, tie-break to a=0\n        A_star = 1 if R1 > R0 else 0\n        \n        # Format results as specified\n        formatted_r0 = f\"{round(R0, 6):.6f}\"\n        formatted_r1 = f\"{round(R1, 6):.6f}\"\n        result_str = f\"[{formatted_r0},{formatted_r1},{A_star}]\"\n        results_str_list.append(result_str)\n\n    # Final print statement in the exact required format.\n    print(f\"[[{','.join(results_str_list)}]]\")\n\nsolve()\n```"
        }
    ]
}