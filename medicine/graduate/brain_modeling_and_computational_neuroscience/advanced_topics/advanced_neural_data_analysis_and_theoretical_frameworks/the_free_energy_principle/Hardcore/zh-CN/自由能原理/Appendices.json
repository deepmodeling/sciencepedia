{
    "hands_on_practices": [
        {
            "introduction": "自由能原理的核心在于一个精妙的权衡：我们的信念既要准确地解释感官输入，又要尽可能地保持简单。本练习将这一抽象概念具体化，通过一个基础的高斯模型，你将亲手推导并计算自由能的两个关键组成部分——“准确度”和“复杂度”。通过比较“学习”前后的变化，你将直观地理解系统是如何在解释证据和维持简约信念之间做出平衡，这正是奥卡姆剃刀原则在计算神经科学中的生动体现。",
            "id": "4028543",
            "problem": "考虑一个基于自由能原理的单一潜变量生成模型，该模型用于大脑建模和计算神经科学中的感知研究。设潜变量为 $s \\in \\mathbb{R}$，其高斯先验为 $p(s) = \\mathcal{N}(s; \\mu_{0}, \\sigma_{0}^{2})$，似然函数为 $p(o \\mid s) = \\mathcal{N}(o; s, \\sigma_{o}^{2})$，其中 $o \\in \\mathbb{R}$ 是一个观测数据点。假设平均场变分后验为 $q(s) = \\mathcal{N}(s; \\mu_{q}, \\sigma_{q}^{2})$。变分自由能由以下基本恒等式定义\n$$\nF[q] = \\mathbb{E}_{q}[\\ln q(s)] - \\mathbb{E}_{q}[\\ln p(o,s)],\n$$\n并且可以通过因子分解 $p(o,s) = p(o \\mid s)p(s)$ 分解为一个准确度项和一个复杂度项。复杂度是库尔贝克-莱布勒（Kullback–Leibler，KL）散度 $D_{\\mathrm{KL}}(q(s) \\| p(s))$，准确度是期望对数似然 $\\mathbb{E}_{q}[\\ln p(o \\mid s)]$。从上述定义出发，仅使用由这些定义得出的高斯恒等式，推导此共轭高斯模型中准确度和复杂度分量的闭式表达式。\n\n现在考虑一个具体的、科学上真实的设定，参数为 $\\mu_{0} = 0$, $\\sigma_{0}^{2} = 1$, $\\sigma_{o}^{2} = \\frac{1}{4}$，以及单个观测数据 $o = 1$。定义“学习前”为初始化 $q_{\\text{before}}(s) = p(s)$，“学习后”为通过在高斯族上最小化 $F[q]$ 得到的精确高斯后验 $q_{\\text{after}}(s) = p(s \\mid o)$。计算 $q_{\\text{before}}$ 和 $q_{\\text{after}}$ 的准确度和复杂度。\n\n以单行矩阵的形式给出你的最终答案，其中包含按以下顺序排列的四个量，并使用你推导出的精确解析形式：\n$$\n\\big[\\text{accuracy}_{\\text{before}}, \\ \\text{complexity}_{\\text{before}}, \\ \\text{accuracy}_{\\text{after}}, \\ \\text{complexity}_{\\text{after}}\\big].\n$$\n用精确的解析形式表示你的答案（不要近似或四舍五入）。最后，简要解释奥卡姆权衡，说明准确度和复杂度的变化如何解释“学习前”和“学习后”之间变分自由能 $F[q]$ 的变化。",
            "solution": "问题要求在一个简单高斯生成模型的变分自由能框架内推导准确度和复杂度项，然后计算这两个特定状态下的这些量：“学习前” ($q_{\\text{before}}(s) = p(s)$) 和 “学习后” ($q_{\\text{after}}(s) = p(s \\mid o)$)。\n\n生成模型由以下部分指定：\n- 潜变量 $s$ 的高斯先验：$p(s) = \\mathcal{N}(s; \\mu_{0}, \\sigma_{0}^{2})$\n- 观测值 $o$ 的高斯似然：$p(o \\mid s) = \\mathcal{N}(o; s, \\sigma_{o}^{2})$\n\n假设近似后验属于同一族分布：$q(s) = \\mathcal{N}(s; \\mu_{q}, \\sigma_{q}^{2})$。\n\n变分自由能 $F[q]$ 分解为 $F[q] = \\text{复杂度} - \\text{准确度}$，其中：\n- 复杂度 $= D_{\\mathrm{KL}}(q(s) \\| p(s))$\n- 准确度 $= \\mathbb{E}_{q}[\\ln p(o \\mid s)]$\n\n我们首先推导这两项的通用闭式表达式。\n\n**1. 复杂度项的推导**\n\n复杂度是从先验 $p(s)$ 到变分后验 $q(s)$ 的库尔贝克-莱布勒（KL）散度。\n$$\nD_{\\mathrm{KL}}(q(s) \\| p(s)) = \\int_{-\\infty}^{\\infty} q(s) \\ln \\frac{q(s)}{p(s)} ds = \\mathbb{E}_{q}[\\ln q(s) - \\ln p(s)]\n$$\n对数概率密度函数为：\n$$\n\\ln q(s) = -\\frac{1}{2} \\ln(2\\pi\\sigma_{q}^{2}) - \\frac{(s - \\mu_{q})^{2}}{2\\sigma_{q}^{2}}\n$$\n$$\n\\ln p(s) = -\\frac{1}{2} \\ln(2\\pi\\sigma_{0}^{2}) - \\frac{(s - \\mu_{0})^{2}}{2\\sigma_{0}^{2}}\n$$\n我们计算在 $q(s)$ 下每一项的期望：\n$\\ln q(s)$ 的期望与高斯分布的微分熵 $H[q]$ 相关。\n$$\n\\mathbb{E}_{q}[\\ln q(s)] = -\\frac{1}{2} \\ln(2\\pi\\sigma_{q}^{2}) - \\frac{1}{2\\sigma_{q}^{2}} \\mathbb{E}_{q}[(s - \\mu_{q})^{2}] = -\\frac{1}{2} \\ln(2\\pi\\sigma_{q}^{2}) - \\frac{\\sigma_{q}^{2}}{2\\sigma_{q}^{2}} = -\\frac{1}{2}(\\ln(2\\pi\\sigma_{q}^{2}) + 1)\n$$\n对于 $\\ln p(s)$ 的期望：\n$$\n\\mathbb{E}_{q}[\\ln p(s)] = -\\frac{1}{2} \\ln(2\\pi\\sigma_{0}^{2}) - \\frac{1}{2\\sigma_{0}^{2}} \\mathbb{E}_{q}[(s - \\mu_{0})^{2}]\n$$\n期望项 $\\mathbb{E}_{q}[(s - \\mu_{0})^{2}]$ 可以展开为：\n$$\n\\mathbb{E}_{q}[(s - \\mu_{0})^{2}] = \\mathbb{E}_{q}[((s - \\mu_{q}) + (\\mu_{q} - \\mu_{0}))^{2}] = \\mathbb{E}_{q}[(s - \\mu_{q})^{2} + 2(s - \\mu_{q})(\\mu_{q} - \\mu_{0}) + (\\mu_{q} - \\mu_{0})^{2}]\n$$\n利用期望的线性和 $\\mathbb{E}_{q}[s - \\mu_{q}] = 0$ 以及 $\\mathbb{E}_{q}[(s - \\mu_{q})^{2}] = \\sigma_{q}^{2}$：\n$$\n\\mathbb{E}_{q}[(s - \\mu_{0})^{2}] = \\sigma_{q}^{2} + 0 + (\\mu_{q} - \\mu_{0})^{2} = \\sigma_{q}^{2} + (\\mu_{q} - \\mu_{0})^{2}\n$$\n将其代回：\n$$\n\\mathbb{E}_{q}[\\ln p(s)] = -\\frac{1}{2} \\ln(2\\pi\\sigma_{0}^{2}) - \\frac{\\sigma_{q}^{2} + (\\mu_{q} - \\mu_{0})^{2}}{2\\sigma_{0}^{2}}\n$$\nKL散度是这些期望之间的差：\n$$\nD_{\\mathrm{KL}}(q(s) \\| p(s)) = \\left(-\\frac{1}{2}(\\ln(2\\pi\\sigma_{q}^{2}) + 1)\\right) - \\left(-\\frac{1}{2} \\ln(2\\pi\\sigma_{0}^{2}) - \\frac{\\sigma_{q}^{2} + (\\mu_{q} - \\mu_{0})^{2}}{2\\sigma_{0}^{2}}\\right)\n$$\n$$\n= \\frac{1}{2} \\left( \\ln(2\\pi\\sigma_{0}^{2}) - \\ln(2\\pi\\sigma_{q}^{2}) - 1 + \\frac{\\sigma_{q}^{2} + (\\mu_{q} - \\mu_{0})^{2}}{\\sigma_{0}^{2}} \\right)\n$$\n$$\n\\text{Complexity} = D_{\\mathrm{KL}}(q(s) \\| p(s)) = \\frac{1}{2} \\left( \\ln\\left(\\frac{\\sigma_{0}^{2}}{\\sigma_{q}^{2}}\\right) - 1 + \\frac{\\sigma_{q}^{2} + (\\mu_{q} - \\mu_{0})^{2}}{\\sigma_{0}^{2}} \\right)\n$$\n\n**2. 准确度项的推导**\n\n准确度是观测值在变分后验下的期望对数似然。\n$$\n\\text{Accuracy} = \\mathbb{E}_{q}[\\ln p(o \\mid s)]\n$$\n对数似然为：\n$$\n\\ln p(o \\mid s) = -\\frac{1}{2}\\ln(2\\pi\\sigma_{o}^{2}) - \\frac{(o - s)^{2}}{2\\sigma_{o}^{2}}\n$$\n关于 $q(s)$ 取期望：\n$$\n\\text{Accuracy} = \\mathbb{E}_{q}\\left[-\\frac{1}{2}\\ln(2\\pi\\sigma_{o}^{2}) - \\frac{(o - s)^{2}}{2\\sigma_{o}^{2}}\\right] = -\\frac{1}{2}\\ln(2\\pi\\sigma_{o}^{2}) - \\frac{1}{2\\sigma_{o}^{2}}\\mathbb{E}_{q}[(o - s)^{2}]\n$$\n期望 $\\mathbb{E}_{q}[(o - s)^{2}]$ 的计算与上面的项类似：\n$$\n\\mathbb{E}_{q}[(o - s)^{2}] = \\mathbb{E}_{q}[((o - \\mu_{q}) - (s - \\mu_{q}))^{2}] = \\mathbb{E}_{q}[(o - \\mu_{q})^{2} - 2(o - \\mu_{q})(s - \\mu_{q}) + (s - \\mu_{q})^{2}]\n$$\n$$\n= (o - \\mu_{q})^{2} - 0 + \\sigma_{q}^{2}\n$$\n将此结果代回准确度表达式中：\n$$\n\\text{Accuracy} = -\\frac{1}{2}\\ln(2\\pi\\sigma_{o}^{2}) - \\frac{(o - \\mu_{q})^{2} + \\sigma_{q}^{2}}{2\\sigma_{o}^{2}}\n$$\n\n**3. 在特定案例中的应用**\n\n问题给出的参数为：$\\mu_{0} = 0$，$\\sigma_{0}^{2} = 1$，$\\sigma_{o}^{2} = \\frac{1}{4}$，以及观测值 $o = 1$。\n\n**“学习前”状态：**\n在此，变分分布设为先验分布：$q_{\\text{before}}(s) = p(s)$。这意味着其参数为 $\\mu_{q} = \\mu_{0} = 0$ 和 $\\sigma_{q}^{2} = \\sigma_{0}^{2} = 1$。\n- **学习前的复杂度：**\n  由于 $q_{\\text{before}}(s) = p(s)$，根据定义，KL散度为零。\n  $$\n  \\text{complexity}_{\\text{before}} = D_{\\mathrm{KL}}(p(s) \\| p(s)) = 0\n  $$\n- **学习前的准确度：**\n  我们使用推导出的准确度公式，并代入 $\\mu_{q} = 0$, $\\sigma_{q}^{2} = 1$, $o = 1$, 和 $\\sigma_{o}^{2} = \\frac{1}{4}$。\n  $$\n  \\text{accuracy}_{\\text{before}} = -\\frac{1}{2}\\ln\\left(2\\pi\\left(\\frac{1}{4}\\right)\\right) - \\frac{(1 - 0)^{2} + 1}{2\\left(\\frac{1}{4}\\right)} = -\\frac{1}{2}\\ln\\left(\\frac{\\pi}{2}\\right) - \\frac{2}{1/2} = -\\frac{1}{2}\\ln\\left(\\frac{\\pi}{2}\\right) - 4\n  $$\n\n**“学习后”状态：**\n在此，变分分布是精确后验 $q_{\\text{after}}(s) = p(s \\mid o)$。对于此共轭模型，后验分布也是高斯分布。我们通过结合先验和似然来找到其参数。\n$p(s \\mid o) \\propto p(o \\mid s)p(s)$。后验参数，我们称之为 $\\mu_{q, \\text{after}}$ 和 $\\sigma_{q, \\text{after}}^{2}$，由高斯分布的标准贝叶斯更新规则给出：\n后验精度是先验精度和似然精度的和：\n$$\n\\frac{1}{\\sigma_{q, \\text{after}}^{2}} = \\frac{1}{\\sigma_{0}^{2}} + \\frac{1}{\\sigma_{o}^{2}} = \\frac{1}{1} + \\frac{1}{1/4} = 1 + 4 = 5 \\implies \\sigma_{q, \\text{after}}^{2} = \\frac{1}{5}\n$$\n后验均值是精度加权平均值：\n$$\n\\mu_{q, \\text{after}} = \\sigma_{q, \\text{after}}^{2} \\left(\\frac{\\mu_{0}}{\\sigma_{0}^{2}} + \\frac{o}{\\sigma_{o}^{2}}\\right) = \\frac{1}{5} \\left(\\frac{0}{1} + \\frac{1}{1/4}\\right) = \\frac{1}{5}(0 + 4) = \\frac{4}{5}\n$$\n所以，$q_{\\text{after}}(s) = \\mathcal{N}(s; \\mu_{q} = \\frac{4}{5}, \\sigma_{q}^{2} = \\frac{1}{5})$。\n- **学习后的复杂度：**\n  使用复杂度公式，并代入 $\\mu_{q} = \\frac{4}{5}$, $\\sigma_{q}^{2} = \\frac{1}{5}$, $\\mu_{0} = 0$, $\\sigma_{0}^{2} = 1$。\n  $$\n  \\text{complexity}_{\\text{after}} = \\frac{1}{2} \\left( \\ln\\left(\\frac{1}{1/5}\\right) - 1 + \\frac{1/5 + (4/5 - 0)^{2}}{1} \\right)\n  $$\n  $$\n  = \\frac{1}{2} \\left( \\ln(5) - 1 + \\frac{1}{5} + \\frac{16}{25} \\right) = \\frac{1}{2} \\left( \\ln(5) - \\frac{25}{25} + \\frac{5}{25} + \\frac{16}{25} \\right) = \\frac{1}{2} \\left( \\ln(5) - \\frac{4}{25} \\right) = \\frac{1}{2}\\ln(5) - \\frac{2}{25}\n  $$\n- **学习后的准确度：**\n  使用准确度公式，并代入 $\\mu_{q} = \\frac{4}{5}$, $\\sigma_{q}^{2} = \\frac{1}{5}$, $o = 1$, 和 $\\sigma_{o}^{2} = \\frac{1}{4}$。\n  $$\n  \\text{accuracy}_{\\text{after}} = -\\frac{1}{2}\\ln\\left(2\\pi\\left(\\frac{1}{4}\\right)\\right) - \\frac{(1 - 4/5)^{2} + 1/5}{2(1/4)}\n  $$\n  $$\n  = -\\frac{1}{2}\\ln\\left(\\frac{\\pi}{2}\\right) - \\frac{(1/5)^{2} + 1/5}{1/2} = -\\frac{1}{2}\\ln\\left(\\frac{\\pi}{2}\\right) - 2\\left(\\frac{1}{25} + \\frac{5}{25}\\right) = -\\frac{1}{2}\\ln\\left(\\frac{\\pi}{2}\\right) - 2\\left(\\frac{6}{25}\\right) = -\\frac{1}{2}\\ln\\left(\\frac{\\pi}{2}\\right) - \\frac{12}{25}\n  $$\n\n计算出的四个量是：\n$\\text{accuracy}_{\\text{before}} = -4 - \\frac{1}{2}\\ln\\left(\\frac{\\pi}{2}\\right)$\n$\\text{complexity}_{\\text{before}} = 0$\n$\\text{accuracy}_{\\text{after}} = -\\frac{12}{25} - \\frac{1}{2}\\ln\\left(\\frac{\\pi}{2}\\right)$\n$\\text{complexity}_{\\text{after}} = \\frac{1}{2}\\ln(5) - \\frac{2}{25}$\n\n**对奥卡姆权衡的解释**\n自由能原理假定，像大脑这样的系统旨在最小化变分自由能 $F[q] = \\text{复杂度} - \\text{准确度}$。这种最小化过程涉及一个类似奥卡姆剃刀的权衡。复杂度项 $D_{\\mathrm{KL}}(q(s) \\| p(s))$ 惩罚了偏离先验信念 $p(s)$ 的后验信念 $q(s)$，从而倾向于简单性。准确度项 $\\mathbb{E}_{q}[\\ln p(o \\mid s)]$ 是数据的期望对数似然，它奖励那些能为感官观测提供良好解释的信念。最小化 $F[q]$ 等同于在最小化复杂度的同时最大化准确度。\n\n比较“学习前”和“学习后”的状态揭示了这种权衡的实际作用：\n- 学习前，信念等于先验 ($q_{\\text{before}} = p(s)$)。这是最“简单”的可能状态，因为复杂度为零。然而，这个信念对于特定观测值 $o=1$ 的解释很差，导致准确度得分很低（一个大的负数，约 $\\approx -4.22$）。\n- 学习后，系统通过整合来自观测的证据，将其信念更新为后验 $q_{\\text{after}} = p(s|o)$。这次更新将复杂度从 $0$ 增加到 $\\frac{1}{2}\\ln(5) - \\frac{2}{25} \\approx 0.72$，因为后验信念现在不同于先验信念。这种复杂度的“成本”是为了获得准确度的显著提升而付出的。准确度得分从 $-4 - \\frac{1}{2}\\ln(\\frac{\\pi}{2})$ 增加到 $-\\frac{12}{25} - \\frac{1}{2}\\ln(\\frac{\\pi}{2})$，提升了 $4 - \\frac{12}{25} = \\frac{88}{25} = 3.52$。\n意外（surprise）的减少（即准确度的增加）远远超过了模型复杂度增加的成本。自由能的变化 $\\Delta F = \\Delta(\\text{复杂度}) - \\Delta(\\text{准确度})$ 因此为负，表明学习已成功地最小化了系统对其感觉的整体意外。最终的信念状态 $q_{\\text{after}}$ 比初始状态更复杂，但它代表了在给定感官证据的情况下，对世界潜变量状态的一个更准确的模型。",
            "answer": "$$\n\\boxed{\\begin{pmatrix} -4 - \\frac{1}{2}\\ln\\left(\\frac{\\pi}{2}\\right) & 0 & -\\frac{12}{25} - \\frac{1}{2}\\ln\\left(\\frac{\\pi}{2}\\right) & \\frac{1}{2}\\ln(5) - \\frac{2}{25} \\end{pmatrix}}\n$$"
        },
        {
            "introduction": "理解了自由能最小化的基本权衡后，我们进而探索大脑可能如何实现这一过程。预测编码理论提供了一个神经科学上可信的框架，它将自由能最小化诠释为大脑层级间预测误差的不断修正。在这个实践中，你将通过编程实现预测编码模型的核心更新步骤，亲身体验信念（后验均值）是如何在预测误差的驱动下动态演化，从而将抽象的数学原理转化为可执行的计算过程。",
            "id": "4028586",
            "problem": "考虑一个适用于自由能原理下预测编码的线性高斯生成模型。设潜状态向量为 $\\mathbf{s} \\in \\mathbb{R}^m$，其先验为零均值高斯分布 $\\mathbf{s} \\sim \\mathcal{N}(\\mathbf{0}, I)$，其中 $I$ 是 $m \\times m$ 的单位矩阵。设观测向量为 $\\mathbf{y} \\in \\mathbb{R}^n$，根据 $\\mathbf{y} \\mid \\mathbf{s} \\sim \\mathcal{N}(W \\mathbf{s}, \\Sigma)$ 生成，其中 $W \\in \\mathbb{R}^{n \\times m}$ 是一个已知的生成映射，$\\Sigma \\in \\mathbb{R}^{n \\times n}$ 是一个已知的正定观测噪声协方差。考虑一个高斯变分后验 $q(\\mathbf{s}) = \\mathcal{N}(\\mu_q, \\Sigma_q)$，其均值为 $\\mu_q \\in \\mathbb{R}^m$，协方差为正定矩阵 $\\Sigma_q \\in \\mathbb{R}^{m \\times m}$。\n\n从第一性原理出发，仅依赖于线性高斯模型的贝叶斯法则、作为模型对数证据下界的负变分自由能的定义以及拉普拉斯近似（围绕众数的的高斯近似），推导在自然梯度通过 $\\Sigma_q$ 进行预处理和单位先验协方差 $I$ 的条件下，均值参数 $\\mu_q$ 的连续时间预测编码动力学。使用这些动力学来定义一个对应于步长 $\\eta = 1$ 的单次显式欧拉步的离散更新，并计算应用于上述模型时，一次迭代中均值参数的变化，记为 $\\Delta \\mu_q$。您的程序必须实现给定 $(W, \\Sigma, \\mu_q, \\Sigma_q, \\mathbf{y})$ 时 $\\Delta \\mu_q$ 的计算，并且不得依赖任何非从所述基本定律和定义推导出的公式。\n\n为以下测试套件实现计算。每个案例提供维度为 $n = 2$ 和 $m = 2$ 的 $(W, \\Sigma, \\mu_q, \\Sigma_q, \\mathbf{y})$：\n\n- 案例 1（一般良态情况）：\n  - $W = \\begin{bmatrix} 1.0 & 0.2 \\\\ 0.0 & 1.0 \\end{bmatrix}$,\n  - $\\Sigma = \\begin{bmatrix} 0.5 & 0.0 \\\\ 0.0 & 0.5 \\end{bmatrix}$,\n  - $\\mu_q = \\begin{bmatrix} 0.1 \\\\ -0.2 \\end{bmatrix}$,\n  - $\\Sigma_q = \\begin{bmatrix} 0.8 & 0.0 \\\\ 0.0 & 0.6 \\end{bmatrix}$,\n  - $\\mathbf{y} = \\begin{bmatrix} 1.5 \\\\ -0.5 \\end{bmatrix}$。\n\n- 案例 2（高观测噪声）：\n  - $W = \\begin{bmatrix} 1.0 & -0.5 \\\\ 0.3 & 1.2 \\end{bmatrix}$,\n  - $\\Sigma = \\begin{bmatrix} 5.0 & 0.0 \\\\ 0.0 & 5.0 \\end{bmatrix}$,\n  - $\\mu_q = \\begin{bmatrix} -0.3 \\\\ 0.4 \\end{bmatrix}$,\n  - $\\Sigma_q = \\begin{bmatrix} 1.1 & 0.0 \\\\ 0.0 & 0.9 \\end{bmatrix}$,\n  - $\\mathbf{y} = \\begin{bmatrix} 0.2 \\\\ -1.0 \\end{bmatrix}$。\n\n- 案例 3（相关后验协方差）：\n  - $W = \\begin{bmatrix} 0.7 & 0.4 \\\\ -0.2 & 1.3 \\end{bmatrix}$,\n  - $\\Sigma = \\begin{bmatrix} 0.6 & 0.0 \\\\ 0.0 & 0.4 \\end{bmatrix}$,\n  - $\\mu_q = \\begin{bmatrix} 0.5 \\\\ 0.1 \\end{bmatrix}$,\n  - $\\Sigma_q = \\begin{bmatrix} 0.7 & 0.3 \\\\ 0.3 & 0.9 \\end{bmatrix}$,\n  - $\\mathbf{y} = \\begin{bmatrix} 1.0 \\\\ 0.0 \\end{bmatrix}$。\n\n- 案例 4（秩亏生成映射）：\n  - $W = \\begin{bmatrix} 1.0 & 0.0 \\\\ 0.0 & 0.0 \\end{bmatrix}$,\n  - $\\Sigma = \\begin{bmatrix} 0.1 & 0.0 \\\\ 0.0 & 0.1 \\end{bmatrix}$,\n  - $\\mu_q = \\begin{bmatrix} 2.0 \\\\ -1.0 \\end{bmatrix}$,\n  - $\\Sigma_q = \\begin{bmatrix} 1.0 & 0.0 \\\\ 0.0 & 1.0 \\end{bmatrix}$,\n  - $\\mathbf{y} = \\begin{bmatrix} 1.0 \\\\ 0.0 \\end{bmatrix}$。\n\n- 案例 5（强感知精度）：\n  - $W = \\begin{bmatrix} 0.9 & -0.1 \\\\ 0.2 & 0.8 \\end{bmatrix}$,\n  - $\\Sigma = \\begin{bmatrix} 0.01 & 0.0 \\\\ 0.0 & 0.02 \\end{bmatrix}$,\n  - $\\mu_q = \\begin{bmatrix} -0.1 \\\\ 0.2 \\end{bmatrix}$,\n  - $\\Sigma_q = \\begin{bmatrix} 0.5 & 0.0 \\\\ 0.0 & 0.5 \\end{bmatrix}$,\n  - $\\mathbf{y} = \\begin{bmatrix} 0.0 \\\\ 1.0 \\end{bmatrix}$。\n\n您的程序应生成单行输出，包含一个用方括号括起来的逗号分隔列表形式的结果，其中每个条目是对应一个测试案例的二维变化向量 $\\Delta \\mu_q$，四舍五入到六位小数，表示为 Python 风格的列表。例如，格式应为 $[\\,[\\delta\\mu_{1,1}, \\delta\\mu_{1,2}], [\\delta\\mu_{2,1}, \\delta\\mu_{2,2}], \\dots\\,]$。不涉及物理单位。不使用角度。所有数值输出必须是实值浮点数。算法必须根据给定的基础定义实现，不得调用任何预先指定的捷径公式。",
            "solution": "我们从一个线性高斯生成模型和一个高斯变分后验开始。潜状态为 $\\mathbf{s} \\in \\mathbb{R}^m$，其先验为 $p(\\mathbf{s}) = \\mathcal{N}(\\mathbf{0}, I)$，其中 $I$ 是 $m \\times m$ 的单位矩阵。似然函数为 $p(\\mathbf{y} \\mid \\mathbf{s}) = \\mathcal{N}(W \\mathbf{s}, \\Sigma)$，其中 $W \\in \\mathbb{R}^{n \\times m}$，$\\Sigma \\in \\mathbb{R}^{n \\times n}$ 是一个正定协方差。变分后验为 $q(\\mathbf{s}) = \\mathcal{N}(\\mu_q, \\Sigma_q)$，其中 $\\mu_q \\in \\mathbb{R}^m$，$\\Sigma_q \\in \\mathbb{R}^{m \\times m}$ 是正定的。\n\n自由能原理使用变分自由能来界定对数证据。负变分自由能（证据下界）由下式给出：\n$$\n\\mathcal{L}(\\mu_q, \\Sigma_q) = \\mathbb{E}_{q(\\mathbf{s})}[\\log p(\\mathbf{y}, \\mathbf{s})] - \\mathbb{E}_{q(\\mathbf{s})}[\\log q(\\mathbf{s})].\n$$\n在拉普拉斯近似和自然梯度动力学下，预测编码通过对 $\\mathcal{L}$ 关于变分参数执行梯度上升而出现，通常使用高斯族的费雪信息度量进行预处理，这里对于均值参数由 $\\Sigma_q$ 表示。为了推导更新，我们从基本的概率定义出发。\n\n首先，写出联合密度：\n$$\n\\log p(\\mathbf{y}, \\mathbf{s}) = \\log p(\\mathbf{y}\\mid \\mathbf{s}) + \\log p(\\mathbf{s}).\n$$\n对于高斯项，\n$$\n\\log p(\\mathbf{y}\\mid \\mathbf{s}) = -\\tfrac{1}{2}(\\mathbf{y} - W \\mathbf{s})^\\top \\Sigma^{-1}(\\mathbf{y} - W \\mathbf{s}) + \\text{const},\n$$\n$$\n\\log p(\\mathbf{s}) = -\\tfrac{1}{2}\\mathbf{s}^\\top I \\mathbf{s} + \\text{const} = -\\tfrac{1}{2}\\mathbf{s}^\\top \\mathbf{s} + \\text{const}.\n$$\n变分后验为\n$$\n\\log q(\\mathbf{s}) = -\\tfrac{1}{2}(\\mathbf{s} - \\mu_q)^\\top \\Sigma_q^{-1}(\\mathbf{s} - \\mu_q) + \\text{const}.\n$$\n我们关注均值的更新。在对均值使用拉普拉斯近似时，将负自由能（在常数项之外，等同于期望负对数后验）视为 $\\mu_q$ 的函数，通过在均值处求值来近似期望（这在拉普拉斯变分方案中是标准做法）。定义能量函数\n$$\nF(\\mu_q) = \\tfrac{1}{2}(\\mathbf{y} - W \\mu_q)^\\top \\Sigma^{-1}(\\mathbf{y} - W \\mu_q) + \\tfrac{1}{2}\\mu_q^\\top I \\mu_q,\n$$\n这是在 $\\mu_q$ 处求值的负对数后验（第一项对应于似然，第二项对应于先验，其中 $I$ 是先验精度）。最小化 $F(\\mu_q)$ 对应于最大化后验概率，并且在拉普拉斯近似下，等效于最大化关于 $\\mu_q$ 的证据下界。\n\n计算 $F(\\mu_q)$ 相对于 $\\mu_q$ 的梯度。使用标准矩阵微积分，\n$$\n\\nabla_{\\mu_q} F(\\mu_q) = - W^\\top \\Sigma^{-1}(\\mathbf{y} - W \\mu_q) + I \\mu_q.\n$$\n预测编码可以表示为对 $F(\\mu_q)$ 的梯度下降，或对 $\\mathcal{L}$ 进行梯度上升，并使用 $\\Sigma_q$ 进行自然梯度预处理。指数族高斯分布中均值参数的自然梯度步长可以通过将普通欧几里得梯度左乘 $\\Sigma_q$ 来近似，从而得到一个考虑了后验协方差所隐含的局部曲率的方向。因此，在对 $\\mathcal{L}$ 进行自然梯度上升（等效于对 $F$ 进行自然梯度下降）的情况下，$\\mu_q$ 的连续时间动力学变为\n$$\n\\frac{d\\mu_q}{dt} = \\Sigma_q\\left[ W^\\top \\Sigma^{-1}(\\mathbf{y} - W \\mu_q) - I \\mu_q \\right].\n$$\n使用步长 $\\eta = 1$ 进行单次显式欧拉步，得到离散变化\n$$\n\\Delta \\mu_q = \\Sigma_q\\left[ W^\\top \\Sigma^{-1}(\\mathbf{y} - W \\mu_q) - I \\mu_q \\right].\n$$\n这个 $\\Delta \\mu_q$ 就是在规定假设下（线性高斯模型、单位先验协方差、拉普拉斯近似以及通过 $\\Sigma_q$ 进行自然梯度预处理）一次预测编码迭代中后验均值的所求变化。\n\n算法设计：\n- 输入：矩阵 $W$, $\\Sigma$, $\\Sigma_q$ 和向量 $\\mu_q$, $\\mathbf{y}$。\n- 验证维度：$W$ 是 $n \\times m$，$\\Sigma$ 是 $n \\times n$，$\\Sigma_q$ 是 $m \\times m$，$\\mu_q \\in \\mathbb{R}^m$，$\\mathbf{y} \\in \\mathbb{R}^n$。\n- 计算感知预测误差 $\\mathbf{e}_y = \\mathbf{y} - W \\mu_q$。\n- 计算精度加权误差 $\\mathbf{r}_y = \\Sigma^{-1} \\mathbf{e}_y$。\n- 计算反向传播到潜层的精度加权误差 $\\mathbf{g} = W^\\top \\mathbf{r}_y$。\n- 计算先验贡献 $\\mathbf{p} = I \\mu_q = \\mu_q$。\n- 组合形成欧几里得梯度方向 $\\mathbf{d} = \\mathbf{g} - \\mathbf{p}$。\n- 通过 $\\Sigma_q$ 进行预处理，获得自然梯度步长 $\\Delta \\mu_q = \\Sigma_q \\mathbf{d}$。\n- 按规定对 $\\Delta \\mu_q$ 进行数值舍入并输出。\n\n测试套件中包含了边缘情况：\n- 案例 1 验证了一般、良态的场景。\n- 案例 2 使用大的观测噪声 $\\Sigma$，抑制了感知项相对于先验项的作用。\n- 案例 3 使用相关的 $\\Sigma_q$，检验了跨维度的自然梯度预处理。\n- 案例 4 使用秩亏的 $W$，将感知信息限制在一个子空间内。\n- 案例 5 使用非常小的观测噪声（高精度），强调了感知项并导致较大的校正。\n\n最终程序为每个测试案例实现上述步骤，并以要求的单行格式打印结果，即一个逗号分隔的列表的列表，每个分量四舍五入到六位小数。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef predictive_coding_delta_mu(W, Sigma, mu_q, Sigma_q, y):\n    \"\"\"\n    Compute one predictive coding iteration change in posterior mean (Delta mu_q)\n    under a linear-Gaussian generative model with identity prior covariance,\n    Laplace approximation, and natural gradient preconditioning by Sigma_q.\n\n    Delta mu_q = Sigma_q * [ W^T * Sigma^{-1} * (y - W * mu_q) - mu_q ]\n    \"\"\"\n    # Sensory prediction error\n    e_y = y - W @ mu_q\n    # Precision-weighted error\n    r_y = np.linalg.solve(Sigma, e_y)\n    # Backpropagated precision-weighted error to latent space\n    g = W.T @ r_y\n    # Prior term (identity prior precision)\n    p = mu_q\n    # Euclidean gradient direction\n    d = g - p\n    # Natural gradient step preconditioned by Sigma_q\n    delta_mu = Sigma_q @ d\n    return delta_mu\n\ndef format_vector(vec):\n    # Round to six decimals and format as Python-style list\n    return \"[\" + \",\".join(f\"{x:.6f}\" for x in vec.tolist()) + \"]\"\n\ndef solve():\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # Case 1\n        (\n            np.array([[1.0, 0.2],\n                      [0.0, 1.0]]),\n            np.array([[0.5, 0.0],\n                      [0.0, 0.5]]),\n            np.array([0.1, -0.2]),\n            np.array([[0.8, 0.0],\n                      [0.0, 0.6]]),\n            np.array([1.5, -0.5])\n        ),\n        # Case 2\n        (\n            np.array([[1.0, -0.5],\n                      [0.3,  1.2]]),\n            np.array([[5.0, 0.0],\n                      [0.0, 5.0]]),\n            np.array([-0.3, 0.4]),\n            np.array([[1.1, 0.0],\n                      [0.0, 0.9]]),\n            np.array([0.2, -1.0])\n        ),\n        # Case 3\n        (\n            np.array([[ 0.7, 0.4],\n                      [-0.2, 1.3]]),\n            np.array([[0.6, 0.0],\n                      [0.0, 0.4]]),\n            np.array([0.5, 0.1]),\n            np.array([[0.7, 0.3],\n                      [0.3, 0.9]]),\n            np.array([1.0, 0.0])\n        ),\n        # Case 4\n        (\n            np.array([[1.0, 0.0],\n                      [0.0, 0.0]]),\n            np.array([[0.1, 0.0],\n                      [0.0, 0.1]]),\n            np.array([2.0, -1.0]),\n            np.array([[1.0, 0.0],\n                      [0.0, 1.0]]),\n            np.array([1.0, 0.0])\n        ),\n        # Case 5\n        (\n            np.array([[0.9, -0.1],\n                      [0.2,  0.8]]),\n            np.array([[0.01, 0.0],\n                      [0.0,  0.02]]),\n            np.array([-0.1, 0.2]),\n            np.array([[0.5, 0.0],\n                      [0.0, 0.5]]),\n            np.array([0.0, 1.0])\n        ),\n    ]\n\n    results = []\n    for W, Sigma, mu_q, Sigma_q, y in test_cases:\n        delta_mu = predictive_coding_delta_mu(W, Sigma, mu_q, Sigma_q, y)\n        results.append(format_vector(delta_mu))\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(results)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "自由能原理不仅解释了感知，更统一了感知与行动。一个主动的智能体（agent）不仅要推断世界的当前状态，还要选择行动来塑造自己的未来。本练习将你带入主动推理（active inference）的核心，要求你计算并比较不同行动策略的期望自由能。通过这个过程，你将理解智能体是如何通过最小化期望自由能来做出决策，从而在实现偏好结果（实用价值）和减少未来不确定性（认知价值）之间进行权衡。",
            "id": "4028595",
            "problem": "考虑一个在脑建模和计算神经科学中根据自由能原理（FEP）构建的单步决策问题。隐藏状态是二元的，$s \\in \\{s_{0}, s_{1}\\}$，其当前信念（识别密度）$Q(s)$ 由 $Q(s_{0}) = 0.6$ 和 $Q(s_{1}) = 0.4$ 给出。观测是二元的，$o \\in \\{0,1\\}$，存在两个候选的单步策略 $\\pi_{1}$ 和 $\\pi_{2}$，分别对应两个行动 $a_{1}$ 和 $a_{2}$，它们如下调节似然映射 $P(o \\mid s, a)$：\n- 在行动 $a_{1}$ 下：$P(o=1 \\mid s_{0}, a_{1}) = 0.8$，$P(o=0 \\mid s_{0}, a_{1}) = 0.2$，$P(o=1 \\mid s_{1}, a_{1}) = 0.3$，$P(o=0 \\mid s_{1}, a_{1}) = 0.7$。\n- 在行动 $a_{2}$ 下：$P(o=1 \\mid s_{0}, a_{2}) = 0.6$，$P(o=0 \\mid s_{0}, a_{2}) = 0.4$，$P(o=1 \\mid s_{1}, a_{2}) = 0.1$，$P(o=0 \\mid s_{1}, a_{2}) = 0.9$。\n\n偏好结果由先验偏好分布 $P^{\\ast}(o)$ 编码，其中 $P^{\\ast}(1) = 0.9$ 和 $P^{\\ast}(0) = 0.1$。假设只有一个时间步，并且用于评分期望自由能的隐藏状态先验与当前信念相匹配，即 $P(s) = Q(s)$。使用自然对数 $\\ln$。\n\n从单个观测的变分自由能的定义出发（该定义基于识别分布 $Q(s \\mid o, \\pi)$ 和带有结果偏好的生成模型 $P^{\\ast}(o)$），并仅使用变分贝叶斯推断的核心定义（例如，Kullback–Leibler 散度（KLD）、互信息和全期望定律），推导出一个策略 $\\pi$ 的单步期望自由能 $\\mathcal{G}(\\pi)$ 的表达式，该表达式可分为 (i) 一个依赖于 $P^{\\ast}(o)$ 和预测分布 $Q(o \\mid \\pi)$ 的外在项，以及 (ii) 一个在策略 $\\pi$ 下隐藏状态和结果之间的互信息的认知项。然后，数值计算 $\\mathcal{G}(\\pi_{1})$ 和 $\\mathcal{G}(\\pi_{2})$，并确定哪个策略能最小化 $\\mathcal{G}(\\pi)$。\n\n作为你的最终答案，报告最小化策略 $\\pi_{i}$ 的索引 $i \\in \\{1,2\\}$。最终索引无需四舍五入。如果需要中间数值计算，请使用精确算术和 $\\ln$ 求值；任何近似都应在你的推导中明确指出。",
            "solution": "### 期望自由能表达式的推导\n\n一个策略 $\\pi$ 的期望自由能 $\\mathcal{G}(\\pi)$ 是在该策略下预期的自由能，按该策略预测的结果 $o$ 进行平均。这可以写成：\n$$ \\mathcal{G}(\\pi) = \\mathbb{E}_{Q(o|\\pi)}[F(o|\\pi)] $$\n其中 $F(o|\\pi)$ 是与特定未来结果 $o$ 相关的变分自由能。问题指出，我们应从一个涉及识别分布 $Q(s|o,\\pi)$ 和带有结果偏好 $P^\\ast(o)$ 的生成模型的自由能定义出发。自由能是识别密度 $Q$ 和生成模型 $P$ 的泛函，定义为 $F = \\mathbb{E}_{Q}[\\ln Q - \\ln P]$。对于主动推断，生成模型体现了智能体的目标。我们定义一个简单的生成模型，其中状态和结果是独立的，结果遵循偏好分布 $P^\\ast(o)$，状态遵循先验分布 $P(s)$。因此，联合概率为 $P(s,o) = P(s)P^\\ast(o)$。\n\n未来结果 $o$ 的自由能是关于状态的近似后验信念 $Q(s|o,\\pi)$ 与这个目标导向的生成模型 $P(s,o)$ 之间的 Kullback-Leibler (KL) 散度：\n$$ F(o|\\pi) = \\mathbb{E}_{Q(s|o,\\pi)}[\\ln Q(s|o,\\pi) - \\ln P(s,o)] $$\n代入 $P(s,o) = P(s)P^\\ast(o)$:\n$$ F(o|\\pi) = \\mathbb{E}_{Q(s|o,\\pi)}[\\ln Q(s|o,\\pi) - \\ln(P(s)P^\\ast(o))] $$\n$$ F(o|\\pi) = \\mathbb{E}_{Q(s|o,\\pi)}[\\ln \\frac{Q(s|o,\\pi)}{P(s)}] - \\ln P^\\ast(o) $$\n第一项是 KL 散度 $D_{KL}[Q(s|o,\\pi) || P(s)]$。所以：\n$$ F(o|\\pi) = D_{KL}[Q(s|o,\\pi) || P(s)] - \\ln P^\\ast(o) $$\n现在，我们通过对 $F(o|\\pi)$ 在结果的预测分布 $Q(o|\\pi) = \\sum_s P(o|s,\\pi)Q(s)$ 上取期望来计算期望自由能 $\\mathcal{G}(\\pi)$：\n$$ \\mathcal{G}(\\pi) = \\mathbb{E}_{Q(o|\\pi)}[D_{KL}[Q(s|o,\\pi) || P(s)] - \\ln P^\\ast(o)] $$\n$$ \\mathcal{G}(\\pi) = \\mathbb{E}_{Q(o|\\pi)}[D_{KL}[Q(s|o,\\pi) || P(s)]] + \\mathbb{E}_{Q(o|\\pi)}[-\\ln P^\\ast(o)] $$\n该表达式分为两项。\n\n第一项是**认知项**，它量化了关于隐藏状态的预期信息增益：\n$$ \\mathcal{G}_I(\\pi) = \\mathbb{E}_{Q(o|\\pi)}[D_{KL}[Q(s|o,\\pi) || P(s)]] $$\n使用问题中状态先验即为当前信念的条件，$P(s) = Q(s)$，该项变为：\n$$ \\mathcal{G}_I(\\pi) = \\mathbb{E}_{Q(o|\\pi)}[D_{KL}[Q(s|o,\\pi) || Q(s)]] = \\sum_o Q(o|\\pi) \\sum_s Q(s|o,\\pi) \\ln\\frac{Q(s|o,\\pi)}{Q(s)} $$\n根据定义，这是在策略 $\\pi$ 下隐藏状态 $s$ 和结果 $o$ 之间的互信息 $I(s;o|\\pi)$。\n\n第二项是**外在项**（或实用价值），它量化了预期结果与偏好结果的偏离程度：\n$$ \\mathcal{G}_E(\\pi) = \\mathbb{E}_{Q(o|\\pi)}[-\\ln P^\\ast(o)] = \\sum_o Q(o|\\pi) (-\\ln P^\\ast(o)) $$\n这是预测分布 $Q(o|\\pi)$ 和偏好分布 $P^\\ast(o)$ 之间的交叉熵。该项按要求依赖于 $P^{\\ast}(o)$ 和 $Q(o|\\pi)$。\n\n因此，要最小化的单步期望自由能是：\n$$ \\mathcal{G}(\\pi) = \\mathcal{G}_E(\\pi) + \\mathcal{G}_I(\\pi) $$\n\n### 策略 $\\pi_1$（行动 $a_1$）的计算\n\n当前信念为 $Q(s_0) = 0.6$ 和 $Q(s_1) = 0.4$。\n\n1.  **预测结果分布 $Q(o|\\pi_1)$**：\n    $Q(o=1|\\pi_1) = \\sum_s P(o=1|s, a_1)Q(s) = (0.8)(0.6) + (0.3)(0.4) = 0.48 + 0.12 = 0.6$。\n    $Q(o=0|\\pi_1) = \\sum_s P(o=0|s, a_1)Q(s) = (0.2)(0.6) + (0.7)(0.4) = 0.12 + 0.28 = 0.4$。\n\n2.  **外在项 $\\mathcal{G}_E(\\pi_1)$**：\n    $\\mathcal{G}_E(\\pi_1) = Q(o=0|\\pi_1)(-\\ln P^\\ast(0)) + Q(o=1|\\pi_1)(-\\ln P^\\ast(1))$\n    $\\mathcal{G}_E(\\pi_1) = 0.4(-\\ln 0.1) + 0.6(-\\ln 0.9) \\approx 0.4(2.3026) + 0.6(0.1054) \\approx 0.98428$。\n\n3.  **认知项 $\\mathcal{G}_I(\\pi_1)$**：\n    首先，我们计算后验信念 $Q(s|o, \\pi_1) = \\frac{P(o|s,a_1)Q(s)}{Q(o|\\pi_1)}$。\n    对于 $o=1$：\n    $Q(s_0|o=1, \\pi_1) = \\frac{0.8 \\times 0.6}{0.6} = 0.8$。\n    $Q(s_1|o=1, \\pi_1) = \\frac{0.3 \\times 0.4}{0.6} = 0.2$。\n    对于 $o=0$：\n    $Q(s_0|o=0, \\pi_1) = \\frac{0.2 \\times 0.6}{0.4} = 0.3$。\n    $Q(s_1|o=0, \\pi_1) = \\frac{0.7 \\times 0.4}{0.4} = 0.7$。\n\n    接下来，我们计算互信息，即期望的KL散度：\n    $D_{KL}[Q(s|o=1,\\pi_1) || Q(s)] = 0.8\\ln(\\frac{0.8}{0.6}) + 0.2\\ln(\\frac{0.2}{0.4})$。\n    $D_{KL}[Q(s|o=0,\\pi_1) || Q(s)] = 0.3\\ln(\\frac{0.3}{0.6}) + 0.7\\ln(\\frac{0.7}{0.4})$。\n\n    $\\mathcal{G}_I(\\pi_1) = Q(o=1|\\pi_1) D_{KL}[Q(s|o=1,\\pi_1) || Q(s)] + Q(o=0|\\pi_1) D_{KL}[Q(s|o=0,\\pi_1) || Q(s)] \\approx 0.12845$。\n\n4.  **总期望自由能 $\\mathcal{G}(\\pi_1)$**：\n    $\\mathcal{G}(\\pi_1) = \\mathcal{G}_E(\\pi_1) + \\mathcal{G}_I(\\pi_1) \\approx 0.98428 + 0.12845 = 1.11273$。\n\n### 策略 $\\pi_2$（行动 $a_2$）的计算\n\n1.  **预测结果分布 $Q(o|\\pi_2)$**：\n    $Q(o=1|\\pi_2) = \\sum_s P(o=1|s, a_2)Q(s) = (0.6)(0.6) + (0.1)(0.4) = 0.36 + 0.04 = 0.4$。\n    $Q(o=0|\\pi_2) = \\sum_s P(o=0|s, a_2)Q(s) = (0.4)(0.6) + (0.9)(0.4) = 0.24 + 0.36 = 0.6$。\n\n2.  **外在项 $\\mathcal{G}_E(\\pi_2)$**：\n    $\\mathcal{G}_E(\\pi_2) = Q(o=0|\\pi_2)(-\\ln P^\\ast(0)) + Q(o=1|\\pi_2)(-\\ln P^\\ast(1))$\n    $\\mathcal{G}_E(\\pi_2) = 0.6(-\\ln 0.1) + 0.4(-\\ln 0.9) \\approx 0.6(2.3026) + 0.4(0.1054) \\approx 1.42372$。\n\n3.  **认知项 $\\mathcal{G}_I(\\pi_2)$**：\n    首先，我们计算后验信念 $Q(s|o, \\pi_2) = \\frac{P(o|s,a_2)Q(s)}{Q(o|\\pi_2)}$。\n    对于 $o=1$：\n    $Q(s_0|o=1, \\pi_2) = \\frac{0.6 \\times 0.6}{0.4} = 0.9$。\n    $Q(s_1|o=1, \\pi_2) = \\frac{0.1 \\times 0.4}{0.4} = 0.1$。\n    对于 $o=0$：\n    $Q(s_0|o=0, \\pi_2) = \\frac{0.4 \\times 0.6}{0.6} = 0.4$。\n    $Q(s_1|o=0, \\pi_2) = \\frac{0.9 \\times 0.4}{0.6} = 0.6$。\n\n    $\\mathcal{G}_I(\\pi_2) = Q(o=1|\\pi_2) D_{KL}[Q(s|o=1,\\pi_2) || Q(s)] + Q(o=0|\\pi_2) D_{KL}[Q(s|o=0,\\pi_2) || Q(s)] \\approx 0.13919$。\n\n4.  **总期望自由能 $\\mathcal{G}(\\pi_2)$**：\n    $\\mathcal{G}(\\pi_2) = \\mathcal{G}_E(\\pi_2) + \\mathcal{G}_I(\\pi_2) \\approx 1.42372 + 0.13919 = 1.56291$。\n\n### 结论\n\n比较两个策略的总期望自由能：\n$$ \\mathcal{G}(\\pi_1) \\approx 1.11273 $$\n$$ \\mathcal{G}(\\pi_2) \\approx 1.56291 $$\n由于遵循自由能原理的智能体会选择最小化期望自由能的策略，我们比较这两个值。我们发现 $\\mathcal{G}(\\pi_1) < \\mathcal{G}(\\pi_2)$。\n因此，策略 $\\pi_1$ 是最优策略。最小化策略的索引是 $i=1$。",
            "answer": "$$\\boxed{1}$$"
        }
    ]
}