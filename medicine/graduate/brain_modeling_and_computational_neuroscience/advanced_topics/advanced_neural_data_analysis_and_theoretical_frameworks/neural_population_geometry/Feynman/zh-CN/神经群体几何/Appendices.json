{
    "hands_on_practices": [
        {
            "introduction": "研究神经几何的第一步是理解这些几何对象如何从潜在的神经过程中产生。本练习将通过一个生成模型，引导您从一个抽象的低维动态过程，一步步构建出高维且含有噪声的神经轨迹，这是神经群体几何研究中的核心对象。通过计算其弧长，您将开始学习如何量化这些复杂轨迹的几何特性。",
            "id": "4003652",
            "problem": "给定从一个神经元群体记录的试验平均脉冲计数，您的任务是构建一个神经元群体状态空间轨迹并计算其弧长。在每个时间窗，神经元群体由一个状态向量 $x(t) \\in \\mathbb{R}^N$ 表示，其分量是在时间窗 $t$ 的 $N$ 个神经元的试验平均脉冲计数，其中 $t \\in \\{1,2,\\dots,T\\}$。状态空间轨迹的弧长由欧几里得度量定义为\n$$\nL \\;=\\; \\sum_{t=1}^{T-1} \\left\\| x(t+1) - x(t) \\right\\|_2 \\, .\n$$\n从以下基础出发：\n\n- 欧几里得空间 $\\mathbb{R}^N$ 和对于 $y \\in \\mathbb{R}^N$ 的欧几里得范数 $\\|y\\|_2 = \\sqrt{\\sum_{i=1}^N y_i^2}$。\n- 一个标准的脉冲发放点过程模型，其中在试验 $k$ 和时间窗 $t$ 观测到的神经元 $i$ 的脉冲计数 $s_i^{(k)}(t)$ 是独立的泊松随机变量，其均值等于一个非负的发放率 $\\lambda_i(t)$ 乘以时间窗宽度 $\\Delta$（单位为秒），即 $s_i^{(k)}(t) \\sim \\mathrm{Poisson}(\\lambda_i(t)\\Delta)$。\n- 一个低维潜在动力学过程 $z(t) \\in \\mathbb{R}^d$，它通过一个线性映射加偏移，然后是一个指数非线性（以确保正值）来驱动发放率：$\\lambda(t) = \\exp\\!\\big(W z(t) + b\\big)$，其中 $W \\in \\mathbb{R}^{N \\times d}$ 且 $b \\in \\mathbb{R}^{N}$，指数函数是逐分量应用的。\n\n对于下方的每个测试用例，根据指定的动力学确定性地构建 $z(t)$，使用给定的随机种子生成 $W$ 和 $b$，计算 $\\lambda(t)$，对 $K$ 个独立试验进行采样以获得脉冲计数 $s_i^{(k)}(t)$，形成试验平均的脉冲计数状态向量\n$$\nx(t) \\;=\\; \\frac{1}{K} \\sum_{k=1}^K s^{(k)}(t) \\in \\mathbb{R}^N \\, ,\n$$\n并计算弧长 $L$。将每个弧长以脉冲数（计数）表示，并四舍五入到六位小数。\n\n您的程序必须实现上述步骤，并为以下测试套件生成输出。请使用指定的确切参数值，所有随机数生成都由提供的种子控制，以确保可复现性。在实现中，时间索引应使用整数 $t \\in \\{0,1,\\dots,T-1\\}$，对应于上述公式中的 $t \\in \\{1,2,\\dots,T\\}$。\n\n参数化用例的测试套件：\n\n- 用例 A（理想情况，旋转加斜坡潜在动力学）：\n  - $N = 100$, $T = 1000$, $K = 50$, $d = 3$, $\\Delta = 0.01$ s.\n  - 潜在动力学：$z_1(t) = A_1 \\cos(\\omega t)$，其中 $A_1 = 1.0$；$z_2(t) = A_2 \\sin(\\omega t)$，其中 $A_2 = 0.8$；$z_3(t) = \\alpha \\left(t - \\frac{T}{2}\\right)$，其中 $\\alpha = 0.001$；$\\omega = 0.02$ 弧度/时间窗。\n  - 权重和偏移：$W$ 和 $b$ 使用种子 $\\mathrm{seed}_W = 1$ 构建。$W$ 的条目为独立的 $\\mathcal{N}(0,\\sigma_W^2)$，其中 $\\sigma_W = 0.2$；$b$ 为 $b_i = \\log(5.0) + \\epsilon_i$，其中 $\\epsilon_i \\sim \\mathcal{N}(0,\\sigma_b^2)$，$\\sigma_b = 0.3$，对于 $i = 1,\\dots,N$ 独立。\n  - 脉冲采样种子：$\\mathrm{seed}_{\\mathrm{spk}} = 11$。\n\n- 用例 B（边界跳跃，最小 T）：\n  - $N = 100$, $T = 2$, $K = 50$, $d = 1$, $\\Delta = 0.01$ s.\n  - 潜在动力学：$z_1(0) = 0$, $z_1(1) = A_{\\mathrm{step}}$，其中 $A_{\\mathrm{step}} = 2.0$。\n  - 权重和偏移：$W$、$b$ 使用种子 $\\mathrm{seed}_W = 2$，分布与用例 A 相同。\n  - 脉冲采样种子：$\\mathrm{seed}_{\\mathrm{spk}} = 22$。\n\n- 用例 C（恒定潜在变量，测试纯噪声轨迹）：\n  - $N = 100$, $T = 1000$, $K = 100$, $d = 1$, $\\Delta = 0.01$ s.\n  - 潜在动力学：对于所有 $t$，$z_1(t) = 0$。\n  - 权重和偏移：$W$、$b$ 使用种子 $\\mathrm{seed}_W = 3$，分布与用例 A 相同。\n  - 脉冲采样种子：$\\mathrm{seed}_{\\mathrm{spk}} = 33$。\n\n- 用例 D（单神经元正弦波，小 T）：\n  - $N = 1$, $T = 10$, $K = 1000$, $d = 1$, $\\Delta = 0.02$ s.\n  - 潜在动力学：$z_1(t) = A \\sin(\\omega t)$，其中 $A = 3.0$，$\\omega = 0.5$ 弧度/时间窗。\n  - 权重和偏移：$W$、$b$ 使用种子 $\\mathrm{seed}_W = 4$，分布与用例 A 相同。\n  - 脉冲采样种子：$\\mathrm{seed}_{\\mathrm{spk}} = 44$。\n\n- 用例 E（边界情况，T=1 时弧长为零）：\n  - $N = 100$, $T = 1$, $K = 20$, $d = 1$, $\\Delta = 0.01$ s.\n  - 潜在动力学：$z_1(0) = 0$。\n  - 权重和偏移：$W$、$b$ 使用种子 $\\mathrm{seed}_W = 5$，分布与用例 A 相同。\n  - 脉冲采样种子：$\\mathrm{seed}_{\\mathrm{spk}} = 55$。\n\n实现细节：\n\n- 对构建 $W$、$b$ 和脉冲采样使用独立的随机数生成器，并按每个用例指定的方式播种。\n- 构建 $\\lambda(t) = \\exp(W z(t) + b)$，其中指数函数逐分量应用以确保正值。\n- 在神经元、时间窗和试验间独立地采样脉冲计数 $s_i^{(k)}(t) \\sim \\mathrm{Poisson}(\\lambda_i(t)\\Delta)$；然后通过在试验间平均来计算 $x(t)$。\n- 完全按照上面给出的欧几里得弧长公式计算 $L$。\n- 将每个 $L$ 以脉冲数表示为一个浮点数，四舍五入到六位小数。\n\n最终输出格式：\n\n您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表，按 A 到 E 的用例顺序列出结果，例如，“[result_A,result_B,result_C,result_D,result_E]”。每个条目必须四舍五入到六位小数。",
            "solution": "经过彻底验证，该问题被认定为有效。其科学基础是计算神经科学的原理，特别是关于神经元群体活动的建模。所有参数和步骤都有明确定义，使该问题定义明确且客观。它没有矛盾、歧义和事实错误。该问题要求实现一个标准的神经脉冲序列生成模型，并计算所得状态空间轨迹的几何属性——弧长。\n\n解决方案首先构建一个低维潜在轨迹，然后将其映射到高维神经元发放率，从一个随机过程中采样脉冲计数，最后计算试验平均活动的几何形状。每个步骤详述如下。\n\n神经元群体活动的状态空间表示提供了一个几何框架，用于理解信息是如何被处理的。在此模型中，一个由 $N$ 个神经元组成的群体在给定时间 $t$ 的状态是一个向量 $x(t) \\in \\mathbb{R}^N$。这些向量随时间变化的序列 $\\{x(0), x(1), \\dots, x(T-1)\\}$，在这个 $N$ 维状态空间中形成一条轨迹。该轨迹的几何属性（如其长度）可以揭示计算上的期望特性。\n\n目标是计算该轨迹的弧长 $L$，它被定义为连续状态向量之间欧几里得距离的总和：\n$$\nL = \\sum_{t=0}^{T-2} \\| x(t+1) - x(t) \\|_2\n$$\n其中 $\\| \\cdot \\|_2$ 表示 $\\mathbb{R}^N$ 中的标准欧几里得范数。请注意，求和已根据实现要求调整为基于零的时间索引 $t \\in \\{0, 1, \\dots, T-1\\}$。\n\n状态向量 $x(t)$ 的生成遵循一个在脑建模中典型的多步生成过程：\n\n1.  **潜在动力学**：首先定义一个低维时间序列 $z(t) \\in \\mathbb{R}^d$，其中 $d \\ll N$。此潜在变量被假定为捕捉神经回路的基本、底层计算。对于每个测试用例，$z(t)$ 的动力学是确定性给出的。例如，在用例 A 中，动力学是正弦函数和线性函数的组合，在 $d=3$ 维的潜在空间中创建了一个螺旋轨迹：\n    $$\n    z(t) = \\begin{pmatrix} A_1 \\cos(\\omega t) \\\\ A_2 \\sin(\\omega t) \\\\ \\alpha(t - T/2) \\end{pmatrix}\n    $$\n\n2.  **发放率生成**：潜在动力学 $z(t)$ 驱动 $N$ 个神经元的发放率 $\\lambda(t) \\in \\mathbb{R}^N$。此映射被建模为一个线性变换，后接一个非线性函数，以确保发放率为非负值。\n    $$\n    \\lambda(t) = \\exp(W z(t) + b)\n    $$\n    此处，$W \\in \\mathbb{R}^{N \\times d}$ 是一个权重矩阵，$b \\in \\mathbb{R}^N$ 是一个偏置向量。指数函数是逐分量应用的。$W$ 和 $b$ 从指定的正态分布中抽取，并使用一个由 $\\mathrm{seed}_W$ 播种的专用随机数生成器以保证可复现性。\n\n3.  **脉冲计数采样**：单个神经元的活动是随机的。我们将神经元 $i$ 在试验 $k$、时间 $t$ 的脉冲计数（表示为 $s_i^{(k)}(t)$）建模为从泊松分布中的一次独立抽样。该分布的均值是发放率 $\\lambda_i(t)$ 乘以时间窗宽度 $\\Delta$。\n    $$\n    s_i^{(k)}(t) \\sim \\mathrm{Poisson}(\\lambda_i(t) \\Delta)\n    $$\n    此步骤对每个神经元和每个时间窗执行 $K$ 次独立试验。一个由 $\\mathrm{seed}_{\\mathrm{spk}}$ 播种的、独立的第二个随机数生成器用于此随机采样。\n\n4.  **状态向量构建**：为了获得一个噪声较小的群体状态表示，脉冲计数在 $K$ 个试验中进行平均。这就得到了状态向量 $x(t)$：\n    $$\n    x(t) = \\frac{1}{K} \\sum_{k=1}^K s^{(k)}(t)\n    $$\n    其中 $s^{(k)}(t)$ 是试验 $k$、时间 $t$ 时所有 $N$ 个神经元的脉冲计数向量。得到的向量集 $\\{x(0), \\dots, x(T-1)\\}$ 构成了神经轨迹。\n\n5.  **弧长计算**：最后，根据初始公式的定义，通过对轨迹上连续点之间的欧几里得距离求和来计算弧长 $L$。对于 $T \\le 1$ 的边界情况，轨迹最多只包含一个点，对空段集合的求和定义为 $L=0$。\n\n实现将为每个测试用例系统地执行这些步骤。为了效率，将使用 `numpy` 库进行向量化操作。将为模型参数生成（$W, b$）和脉冲计数采样分别初始化独立的随机数生成器，以确保精确遵守指定的种子并得到可复现的结果。每个用例的最终弧长将四舍五入到六位小数。",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Computes the arc length of neural population state-space trajectories\n    for a suite of test cases based on a generative model.\n    \"\"\"\n    test_cases = [\n        {\n            \"name\": \"Case A\",\n            \"params\": {\n                \"N\": 100, \"T\": 1000, \"K\": 50, \"d\": 3, \"delta\": 0.01,\n                \"sigma_W\": 0.2, \"sigma_b\": 0.3, \"log_base_rate\": np.log(5.0)\n            },\n            \"latent_dynamics\": {\n                \"type\": \"rotational_ramp\",\n                \"A1\": 1.0, \"A2\": 0.8, \"omega\": 0.02, \"alpha\": 0.001\n            },\n            \"seeds\": {\"seed_W\": 1, \"seed_spk\": 11}\n        },\n        {\n            \"name\": \"Case B\",\n            \"params\": {\n                \"N\": 100, \"T\": 2, \"K\": 50, \"d\": 1, \"delta\": 0.01,\n                \"sigma_W\": 0.2, \"sigma_b\": 0.3, \"log_base_rate\": np.log(5.0)\n            },\n            \"latent_dynamics\": {\n                \"type\": \"step\",\n                \"A_step\": 2.0\n            },\n            \"seeds\": {\"seed_W\": 2, \"seed_spk\": 22}\n        },\n        {\n            \"name\": \"Case C\",\n            \"params\": {\n                \"N\": 100, \"T\": 1000, \"K\": 100, \"d\": 1, \"delta\": 0.01,\n                \"sigma_W\": 0.2, \"sigma_b\": 0.3, \"log_base_rate\": np.log(5.0)\n            },\n            \"latent_dynamics\": {\n                \"type\": \"constant_zero\"\n            },\n            \"seeds\": {\"seed_W\": 3, \"seed_spk\": 33}\n        },\n        {\n            \"name\": \"Case D\",\n            \"params\": {\n                \"N\": 1, \"T\": 10, \"K\": 1000, \"d\": 1, \"delta\": 0.02,\n                \"sigma_W\": 0.2, \"sigma_b\": 0.3, \"log_base_rate\": np.log(5.0)\n            },\n            \"latent_dynamics\": {\n                \"type\": \"sinusoid\",\n                \"A\": 3.0, \"omega\": 0.5\n            },\n            \"seeds\": {\"seed_W\": 4, \"seed_spk\": 44}\n        },\n        {\n            \"name\": \"Case E\",\n            \"params\": {\n                \"N\": 100, \"T\": 1, \"K\": 20, \"d\": 1, \"delta\": 0.01,\n                \"sigma_W\": 0.2, \"sigma_b\": 0.3, \"log_base_rate\": np.log(5.0)\n            },\n            \"latent_dynamics\": {\n                \"type\": \"constant_zero\"\n            },\n            \"seeds\": {\"seed_W\": 5, \"seed_spk\": 55}\n        }\n    ]\n\n    results = []\n    \n    for case in test_cases:\n        p = case[\"params\"]\n        ld = case[\"latent_dynamics\"]\n        s = case[\"seeds\"]\n\n        # Unpack parameters for clarity\n        N, T, K, d, delta = p[\"N\"], p[\"T\"], p[\"K\"], p[\"d\"], p[\"delta\"]\n        sigma_W, sigma_b, log_base_rate = p[\"sigma_W\"], p[\"sigma_b\"], p[\"log_base_rate\"]\n        seed_W, seed_spk = s[\"seed_W\"], s[\"seed_spk\"]\n        \n        # 1. Initialize random number generators with specified seeds\n        rng_W = np.random.default_rng(seed_W)\n        rng_spk = np.random.default_rng(seed_spk)\n\n        # 2. Generate weight matrix W and offset vector b\n        W = rng_W.normal(loc=0.0, scale=sigma_W, size=(N, d))\n        epsilon = rng_W.normal(loc=0.0, scale=sigma_b, size=N)\n        b = log_base_rate + epsilon\n\n        # 3. Generate the latent trajectory z(t)\n        t_steps = np.arange(T)\n        z = np.zeros((T, d))\n        \n        if ld[\"type\"] == \"rotational_ramp\":\n            z[:, 0] = ld[\"A1\"] * np.cos(ld[\"omega\"] * t_steps)\n            z[:, 1] = ld[\"A2\"] * np.sin(ld[\"omega\"] * t_steps)\n            z[:, 2] = ld[\"alpha\"] * (t_steps - T / 2.0)\n        elif ld[\"type\"] == \"step\":\n            if T > 1:\n                z[1, 0] = ld[\"A_step\"]\n        elif ld[\"type\"] == \"constant_zero\":\n            # z is already initialized to zeros\n            pass\n        elif ld[\"type\"] == \"sinusoid\":\n            z[:, 0] = ld[\"A\"] * np.sin(ld[\"omega\"] * t_steps)\n\n        # 4. Compute firing rates lambda(t)\n        # z is (T, d), W is (N, d). We need z @ W.T which is (T, N)\n        # b is (N,). Broadcasting adds b to each row.\n        lambda_t = np.exp(z @ W.T + b)\n\n        # 5. Compute Poisson means\n        poisson_means = lambda_t * delta\n\n        # 6. Generate spike counts s_i^(k)(t)\n        # `poisson_means` is (T, N). `size=(K, T, N)` broadcasts correctly.\n        s_counts = rng_spk.poisson(lam=poisson_means, size=(K, T, N))\n\n        # 7. Compute trial-averaged state vector x(t)\n        # Average over the trials axis (axis 0)\n        x = s_counts.mean(axis=0)\n\n        # 8. Compute the arc length L\n        if T = 1:\n            L = 0.0\n        else:\n            # x is (T, N). Differences between consecutive time points.\n            diffs = x[1:] - x[:-1]  # Shape (T-1, N)\n            # Calculate Euclidean norm for each time step difference along neuron axis\n            segment_lengths = np.linalg.norm(diffs, axis=1) # Shape (T-1,)\n            L = np.sum(segment_lengths)\n            \n        results.append(f\"{L:.6f}\")\n        \n    print(f\"[{','.join(results)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "神经表征的几何结构不仅仅是一种描述，它更具有深刻的功能意义。本练习将探讨其中一个核心关联：神经状态之间的几何间距如何决定大脑在噪声环境下进行稳健计算的能力。通过支持向量机（SVM）的边距概念，您将亲手建立几何特性与信息解码鲁棒性之间的桥梁。",
            "id": "4003672",
            "problem": "考虑一个神经元群体中的两种实验条件，每种条件由一个$n$维实数空间中的平均响应向量表示。设正性条件和负性条件的平均响应向量分别记为 $\\mathbf{m}_{+} \\in \\mathbb{R}^{n}$ 和 $\\mathbf{m}_{-} \\in \\mathbb{R}^{n}$。假设分类由线性支持向量机 (SVM) 执行，该分类器为线性可分的数据找到具有最大几何间隔的分离超平面。对于带有标签 $y_{i} \\in \\{+1, -1\\}$ 的线性可分数据 $\\{ (\\mathbf{x}_{i}, y_{i}) \\}_{i=1}^{N}$，支持向量机 (SVM) 的原始优化问题是最小化 $\\frac{1}{2} \\lVert \\mathbf{w} \\rVert_{2}^{2}$，其约束条件为 $y_{i} \\left( \\mathbf{w}^{\\top} \\mathbf{x}_{i} + b \\right) \\geq 1$，其中 $\\mathbf{w} \\in \\mathbb{R}^{n}$ 是分离超平面的法向量，$b \\in \\mathbb{R}$ 是偏置项。由 $(\\mathbf{w}, b)$ 定义的超平面的几何间隔是数据点到超平面沿法线方向的最小距离，在规范缩拿下等于 $\\frac{1}{\\lVert \\mathbf{w} \\rVert_{2}}$。\n\n模型对噪声的鲁棒性通过在神经元群体响应上添加加性各向同性高斯噪声来评估，即观测响应为 $\\mathbf{x}' = \\mathbf{x} + \\boldsymbol{\\eta}$，其中 $\\boldsymbol{\\eta} \\sim \\mathcal{N}(\\mathbf{0}, \\sigma^{2} \\mathbf{I}_{n})$，$\\sigma  0$ 是每个坐标的标准差，$\\mathbf{I}_{n}$ 是 $n \\times n$ 的单位矩阵。线性分类器的决策变量是 $d(\\mathbf{x}) = \\mathbf{w}^{\\top} \\mathbf{x} + b$。在加性噪声模型下，决策变量的波动由 $\\mathbf{w}^{\\top} \\boldsymbol{\\eta}$ 的分布和正态分布的标准性质决定。\n\n仅从上述定义以及关于正态分布和线性分类的经过充分检验的事实出发，推导一个算法以实现以下目标：\n1. 在线性可分的情况下，计算条件平均响应对 $\\mathbf{m}_{+}$ 和 $\\mathbf{m}_{-}$ 的 SVM 几何间隔 $m$。\n2. 通过确定最大的 $\\sigma$（记为 $\\sigma_{\\text{max}}$），将间隔 $m$ 与对加性各向同性高斯噪声的鲁棒性联系起来。该 $\\sigma$ 需满足：当分类器应用于条件平均响应时，在任一均值处的错分概率不超过以小数形式表示的指定误差容限 $\\tau \\in (0, 0.5)$。\n\n您的程序必须实现上述推导，并为下面的每个测试用例计算 $(m, \\sigma_{\\text{max}})$。如果在条件均值层面数据不是线性可分的（例如，如果 $\\mathbf{m}_{+} = \\mathbf{m}_{-}$），则将几何间隔定义为 $m = 0$，并对任何 $\\tau \\in (0, 0.5)$ 报告 $\\sigma_{\\text{max}} = 0$。\n\n测试套件（每个用例由 $(\\mathbf{m}_{+}, \\mathbf{m}_{-}, \\tau)$ 指定）：\n- 用例 1：$\\mathbf{m}_{+} = (1, 0, 0, 0, 0)$，$\\mathbf{m}_{-} = (-1, 0, 0, 0, 0)$，$\\tau = 0.1$。\n- 用例 2：$\\mathbf{m}_{+} = (0.1, 0, 0)$，$\\mathbf{m}_{-} = (0, 0, 0)$，$\\tau = 0.01$。\n- 用例 3：$\\mathbf{m}_{+} = (0.5, 0.5, \\dots, 0.5) \\in \\mathbb{R}^{50}$，$\\mathbf{m}_{-} = (-0.5, -0.5, \\dots, -0.5) \\in \\mathbb{R}^{50}$，$\\tau = 0.001$。\n- 用例 4：$\\mathbf{m}_{+} = (0, 0, 0)$，$\\mathbf{m}_{-} = (0, 0, 0)$，$\\tau = 0.1$。\n\n您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表。列表中的每个元素本身是一个对应于一个测试用例的双元素列表 $[m, \\sigma_{\\text{max}}]$。所有浮点数必须四舍五入到六位小数。例如，两个假设用例的输出应如下所示：$[[0.500000,0.300000],[1.250000,0.800000]]$。",
            "solution": "问题陈述已经过验证，并被认为是合理的。它科学地基于线性代数、统计决策理论和支持向量机几何学的原理。该问题是适定的、客观的，并包含了推导出唯一解所需的所有必要信息。\n\n推导过程按要求分为两部分：首先，计算两个条件平均响应的几何间隔 $m$；其次，将此间隔与最大可容忍噪声 $\\sigma_{\\text{max}}$ 联系起来。\n\n### 第 1 部分：SVM 几何间隔 ($m$) 的推导\n\n给定两个条件平均响应向量 $\\mathbf{m}_{+} \\in \\mathbb{R}^{n}$ 和 $\\mathbf{m}_{-} \\in \\mathbb{R}^{n}$。这可以被看作是一个由两个点 $(\\mathbf{m}_{+}, +1)$ 和 $(\\mathbf{m}_{-}, -1)$ 组成的数据集。线性支持向量机 (SVM) 的目标是找到一个由法向量 $\\mathbf{w} \\in \\mathbb{R}^{n}$ 和偏置项 $b \\in \\mathbb{R}$ 定义的超平面，以最大化几何间隔。间隔最大化问题可以表示为：\n$$\n\\min_{\\mathbf{w}, b} \\frac{1}{2} \\lVert \\mathbf{w} \\rVert_{2}^{2}\n$$\n约束条件为：\n$$\n\\begin{cases}\n(+1) (\\mathbf{w}^{\\top} \\mathbf{m}_{+} + b) \\geq 1 \\\\\n(-1) (\\mathbf{w}^{\\top} \\mathbf{m}_{-} + b) \\geq 1\n\\end{cases}\n$$\n对于两个线性可分的点，在最大间隔情况下，这两个点本身就成为支持向量，这意味着不等式约束变为激活的等式：\n$$\n\\mathbf{w}^{\\top} \\mathbf{m}_{+} + b = 1 \\\\\n\\mathbf{w}^{\\top} \\mathbf{m}_{-} + b = -1\n$$\n这是一个由两个线性方程组成的方程组。用第一个方程减去第二个方程，得到：\n$$\n(\\mathbf{w}^{\\top} \\mathbf{m}_{+} + b) - (\\mathbf{w}^{\\top} \\mathbf{m}_{-} + b) = 1 - (-1)\n$$\n$$\n\\mathbf{w}^{\\top} (\\mathbf{m}_{+} - \\mathbf{m}_{-}) = 2\n$$\n为了在关于 $\\mathbf{w}$ 的这个单一线性约束条件下最小化 $\\lVert \\mathbf{w} \\rVert_{2}^{2}$，向量 $\\mathbf{w}$ 必须与定义该约束的向量 $(\\mathbf{m}_{+} - \\mathbf{m}_{-})$ 平行。这是利用拉格朗日乘子法或应用柯西-施瓦茨不等式进行优化的一个标准结果。因此，我们可以写出 $\\mathbf{w} = k (\\mathbf{m}_{+} - \\mathbf{m}_{-})$，其中 $k \\in \\mathbb{R}$ 为某个标量。将此形式代入约束方程：\n$$\n(k (\\mathbf{m}_{+} - \\mathbf{m}_{-}))^{\\top} (\\mathbf{m}_{+} - \\mathbf{m}_{-}) = 2\n$$\n$$\nk \\lVert \\mathbf{m}_{+} - \\mathbf{m}_{-} \\rVert_{2}^{2} = 2\n$$\n如果 $\\mathbf{m}_{+} \\neq \\mathbf{m}_{-}$，我们可以解出 $k$：\n$$\nk = \\frac{2}{\\lVert \\mathbf{m}_{+} - \\mathbf{m}_{-} \\rVert_{2}^{2}}\n$$\n这就给出了最优权重向量：\n$$\n\\mathbf{w} = \\frac{2}{\\lVert \\mathbf{m}_{+} - \\mathbf{m}_{-} \\rVert_{2}^{2}} (\\mathbf{m}_{+} - \\mathbf{m}_{-})\n$$\n几何间隔 $m$ 定义为 $m = \\frac{1}{\\lVert \\mathbf{w} \\rVert_{2}}$。我们计算 $\\mathbf{w}$ 的范数：\n$$\n\\lVert \\mathbf{w} \\rVert_{2} = \\left\\lVert \\frac{2}{\\lVert \\mathbf{m}_{+} - \\mathbf{m}_{-} \\rVert_{2}^{2}} (\\mathbf{m}_{+} - \\mathbf{m}_{-}) \\right\\rVert_{2} = \\frac{2}{\\lVert \\mathbf{m}_{+} - \\mathbf{m}_{-} \\rVert_{2}^{2}} \\lVert \\mathbf{m}_{+} - \\mathbf{m}_{-} \\rVert_{2} = \\frac{2}{\\lVert \\mathbf{m}_{+} - \\mathbf{m}_{-} \\rVert_{2}}\n$$\n因此，几何间隔是：\n$$\nm = \\frac{1}{\\lVert \\mathbf{w} \\rVert_{2}} = \\frac{\\lVert \\mathbf{m}_{+} - \\mathbf{m}_{-} \\rVert_{2}}{2}\n$$\n这个结果很直观：两点之间的最大间隔是它们之间欧几里得距离的一半。如果两个点相同（$\\mathbf{m}_{+} = \\mathbf{m}_{-}$），那么它们在非平凡意义上是线性不可分的。在这种情况下，$\\lVert \\mathbf{m}_{+} - \\mathbf{m}_{-} \\rVert_{2} = 0$，导致 $m=0$，这与问题中对此边缘情况的指定处理方式一致。\n\n### 第 2 部分：最大噪声标准差 ($\\sigma_{\\text{max}}$) 的推导\n\n我们现在评估分类器对加性各向同性高斯噪声的鲁棒性。观测响应为 $\\mathbf{x}' = \\mathbf{x} + \\boldsymbol{\\eta}$，其中 $\\boldsymbol{\\eta} \\sim \\mathcal{N}(\\mathbf{0}, \\sigma^{2} \\mathbf{I}_{n})$。分类使用决策函数 $d(\\mathbf{x}') = \\mathbf{w}^{\\top}\\mathbf{x}' + b$ 执行。\n\n考虑正性均值附近的带噪声观测 $\\mathbf{x}'_{+} = \\mathbf{m}_{+} + \\boldsymbol{\\eta}$。决策变量为：\n$$\nd(\\mathbf{x}'_{+}) = \\mathbf{w}^{\\top} (\\mathbf{m}_{+} + \\boldsymbol{\\eta}) + b = (\\mathbf{w}^{\\top} \\mathbf{m}_{+} + b) + \\mathbf{w}^{\\top} \\boldsymbol{\\eta}\n$$\n从激活的 SVM 约束可知，$\\mathbf{w}^{\\top} \\mathbf{m}_{+} + b = 1$。因此，\n$$\nd(\\mathbf{x}'_{+}) = 1 + \\mathbf{w}^{\\top} \\boldsymbol{\\eta}\n$$\n如果 $d(\\mathbf{x}'_{+})  0$（因为真实标签是 $+1$），则发生错分。错分概率为 $P(1 + \\mathbf{w}^{\\top} \\boldsymbol{\\eta}  0) = P(\\mathbf{w}^{\\top} \\boldsymbol{\\eta}  -1)$。\n\n我们来刻画随机变量 $Z = \\mathbf{w}^{\\top} \\boldsymbol{\\eta}$ 的特性。由于它是独立高斯随机变量的线性组合，$Z$ 也服从高斯分布。其均值为 $\\mathbb{E}[Z] = \\mathbf{w}^{\\top} \\mathbb{E}[\\boldsymbol{\\eta}] = \\mathbf{w}^{\\top} \\mathbf{0} = 0$。其方差为 $\\text{Var}(Z) = \\mathbf{w}^{\\top} \\text{Cov}(\\boldsymbol{\\eta}) \\mathbf{w} = \\mathbf{w}^{\\top} (\\sigma^{2} \\mathbf{I}_{n}) \\mathbf{w} = \\sigma^{2} \\lVert \\mathbf{w} \\rVert_{2}^{2}$。\n所以，$Z \\sim \\mathcal{N}(0, \\sigma^{2} \\lVert \\mathbf{w} \\rVert_{2}^{2})$。\n\n错分概率 $P_{\\text{error}}$ 为：\n$$\nP_{\\text{error}} = P(Z  -1) = \\Phi\\left(\\frac{-1 - 0}{\\sqrt{\\sigma^{2} \\lVert \\mathbf{w} \\rVert_{2}^{2}}}\\right) = \\Phi\\left(\\frac{-1}{\\sigma \\lVert \\mathbf{w} \\rVert_{2}}\\right)\n$$\n其中 $\\Phi$ 是标准正态分布 $\\mathcal{N}(0, 1)$ 的累积分布函数 (CDF)。代入 $\\lVert \\mathbf{w} \\rVert_{2} = 1/m$，我们得到：\n$$\nP_{\\text{error}} = \\Phi\\left(\\frac{-m}{\\sigma}\\right)\n$$\n对负性均值 $\\mathbf{m}_{-}$ 进行对称分析，得到的错分概率为 $P(\\mathbf{w}^{\\top} \\boldsymbol{\\eta} > 1) = 1 - \\Phi(m/\\sigma) = \\Phi(-m/\\sigma)$，结果是相同的。\n\n我们要求这个概率不超过容限 $\\tau \\in (0, 0.5)$：\n$$\n\\Phi\\left(\\frac{-m}{\\sigma}\\right) \\leq \\tau\n$$\n由于 $\\Phi$ 是单调递增的，我们可以对其两边应用其反函数 $\\Phi^{-1}$（概率单位函数或分位数函数）：\n$$\n\\frac{-m}{\\sigma} \\leq \\Phi^{-1}(\\tau)\n$$\n我们要找到满足此条件的最大 $\\sigma$。令 $z_{\\tau} = \\Phi^{-1}(\\tau)$。由于 $\\tau \\in (0, 0.5)$，$z_{\\tau}$ 是负数。为求解 $\\sigma > 0$ 而整理不等式时需要翻转不等号：\n$$\n\\sigma \\leq \\frac{-m}{z_{\\tau}} \\implies \\sigma \\leq \\frac{-m}{\\Phi^{-1}(\\tau)}\n$$\n因此，$\\sigma$ 的最大允许值为：\n$$\n\\sigma_{\\text{max}} = \\frac{-m}{\\Phi^{-1}(\\tau)}\n$$\n如果 $m=0$，那么显然 $\\sigma_{\\text{max}}=0$，这与问题陈述一致。\n\n### 算法总结\n对于每个测试用例 $(\\mathbf{m}_{+}, \\mathbf{m}_{-}, \\tau)$：\n1.  计算欧几里得距离 $d = \\lVert \\mathbf{m}_{+} - \\mathbf{m}_{-} \\rVert_{2}$。\n2.  计算几何间隔 $m = d/2$。\n3.  如果 $m = 0$，则结果为 $(m, \\sigma_{\\text{max}}) = (0, 0)$。\n4.  如果 $m > 0$，计算标准正态分位数 $z_{\\tau} = \\Phi^{-1}(\\tau)$，然后计算 $\\sigma_{\\text{max}} = -m/z_{\\tau}$。\n5.  返回数对 $(m, \\sigma_{\\text{max}})$。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.stats import norm\n\ndef solve():\n    \"\"\"\n    Computes the SVM geometric margin and maximum noise robustness for a series of test cases.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        (np.array([1.0, 0.0, 0.0, 0.0, 0.0]), np.array([-1.0, 0.0, 0.0, 0.0, 0.0]), 0.1),\n        (np.array([0.1, 0.0, 0.0]), np.array([0.0, 0.0, 0.0]), 0.01),\n        (np.full(50, 0.5), np.full(50, -0.5), 0.001),\n        (np.array([0.0, 0.0, 0.0]), np.array([0.0, 0.0, 0.0]), 0.1),\n    ]\n\n    results_str = []\n    for m_plus, m_minus, tau in test_cases:\n        # Step 1  2: Calculate the geometric margin m.\n        # The margin is half the Euclidean distance between the two mean vectors.\n        distance = np.linalg.norm(m_plus - m_minus)\n        margin = distance / 2.0\n\n        sigma_max = 0.0\n        # Step 3  4: Calculate sigma_max based on the margin.\n        if margin > 0:\n            # For a margin > 0, calculate the maximum tolerable noise standard deviation.\n            # Find the z-score corresponding to the cumulative probability tau.\n            # This is the inverse of the standard normal CDF, also known as the percent point function (ppf).\n            z_tau = norm.ppf(tau)\n            \n            # The derivation yields sigma_max = -m / z_tau.\n            # Since tau is in (0, 0.5), z_tau is negative, making sigma_max positive.\n            sigma_max = -margin / z_tau\n        # If margin is 0, sigma_max remains 0 as per the problem statement.\n\n        # Append the formatted result string for the current case.\n        results_str.append(f\"[{margin:.6f},{sigma_max:.6f}]\")\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(results_str)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "我们如何判断两个不同的神经群体——例如来自不同个体或不同脑区——是否采用了相似的计算策略？这个问题的答案需要我们以一种与具体神经元选择无关的方式来比较它们的表征几何。本练习将指导您实践普氏分析（Procrustes analysis），这是一种强大的技术，能够最佳地对齐两个几何结构并量化它们之间的相似性，从而揭示普遍的神经编码原则。",
            "id": "4003561",
            "problem": "考虑由条件均值响应矩阵表示的两个神经群体几何结构。设 $C$ 表示条件数， $D$ 表示记录的单元数。对于每个会话，定义一个矩阵 $A \\in \\mathbb{R}^{C \\times D}$，其第 $i$ 行编码了条件 $i$ 在 $D$ 个单元上的均值响应向量。类似地，为第二个会话定义矩阵 $B \\in \\mathbb{R}^{C \\times D}$，该会话在相同的 $C$ 个条件下进行，但记录轴可能不同。任务是仅使用特殊正交群中的正交变换将 $A$ 对齐到 $B$，并量化最优对齐后的残余失配。\n\n从欧几里得几何和最小二乘法的基本定义出发，您必须为每个测试用例实现以下过程：\n- 通过跨条件中心化每个几何结构来移除平移：计算 $A$ 和 $B$ 的列均值，然后减去它们以获得 $A_{c}$ 和 $B_{c}$，使得对于所有 $j \\in \\{1,\\dots,D\\}$，都有 $\\sum_{i=1}^{C} A_{c}(i, j) = 0$ 和 $\\sum_{i=1}^{C} B_{c}(i, j) = 0$。\n- 计算最优正交矩阵 $Q^{\\star} \\in \\mathbb{R}^{D \\times D}$，满足 $Q^{\\star \\top} Q^{\\star} = I$ 和 $\\det(Q^{\\star}) = +1$，该矩阵在所有满足约束的 $Q$ 上最小化平方弗罗贝尼乌斯范数 $\\|A_{c} Q - B_{c}\\|_{F}^{2}$。这将 $Q$ 限制为无反射的真旋转。\n- 将残余对齐误差量化为以下比率\n$$\n\\mathrm{err} = \\frac{\\|A_{c} Q^{\\star} - B_{c}\\|_{F}^{2}}{\\|B_{c}\\|_{F}^{2}},\n$$\n该值无量纲，位于 $[0, +\\infty)$ 区间内，$\\mathrm{err} = 0$ 表示完美对齐。\n\n实现一个完整的程序，为以下每个测试用例计算 $\\mathrm{err}$。所有矩阵都已明确指定，每个案例中 $C = 4$，$D = 3$。\n\n测试用例 1 (精确旋转)：\n$$\nA_{1} =\n\\begin{bmatrix}\n0  1  2 \\\\\n1  0  1 \\\\\n2  1  0 \\\\\n1  2  1\n\\end{bmatrix},\n\\quad\nR_{z,90} =\n\\begin{bmatrix}\n0  -1  0 \\\\\n1  \\phantom{-}0  0 \\\\\n0  \\phantom{-}0  1\n\\end{bmatrix},\n\\quad\nB_{1} = A_{1} R_{z,90}.\n$$\n\n测试用例 2 (旋转加小噪声)：\n$$\nA_{2} = A_{1}, \\quad\nN_{2} =\n\\begin{bmatrix}\n0.05  -0.03  0.02 \\\\\n-0.01  0.04  -0.02 \\\\\n0.00  -0.02  0.03 \\\\\n0.02  0.01  -0.01\n\\end{bmatrix},\n\\quad\nB_{2} = A_{2} R_{z,90} + N_{2}.\n$$\n\n测试用例 3 (秩亏几何结构，旋转加小噪声)：\n$$\nA_{3} =\n\\begin{bmatrix}\n1  2  3 \\\\\n2  4  6 \\\\\n3  6  9 \\\\\n4  8  12\n\\end{bmatrix},\n\\quad\nN_{3} =\n\\begin{bmatrix}\n0.10  -0.10  0.00 \\\\\n0.00  \\phantom{-}0.00  0.10 \\\\\n-0.05  \\phantom{-}0.02  -0.02 \\\\\n0.03  -0.04  0.01\n\\end{bmatrix},\n\\quad\nB_{3} = A_{3} R_{z,90} + N_{3}.\n$$\n\n测试用例 4 (纯反射失配与保向约束)：\n$$\nA_{4} = A_{1}, \\quad\nF_{x} =\n\\begin{bmatrix}\n-1  0  0 \\\\\n\\phantom{-}0  1  0 \\\\\n\\phantom{-}0  0  1\n\\end{bmatrix},\n\\quad\nB_{4} = A_{4} F_{x}.\n$$\n\n您的程序必须使用上述步骤为每个测试用例计算 $\\mathrm{err}$，并生成单行输出，其中包含四个浮点数结果，格式为方括号括起来的逗号分隔列表，例如 $[\\mathrm{err}_{1},\\mathrm{err}_{2},\\mathrm{err}_{3},\\mathrm{err}_{4}]$。不涉及任何物理单位。答案必须是所描述的精确格式。\n\n您的解决方案必须从欧几里得几何、最小二乘法和正交变换的第一性原理推导得出，不得依赖问题陈述中直接给出的快捷公式。",
            "solution": "问题要求我们找到两种神经群体响应的几何构型之间的最优对齐，并量化残余误差。这些构型由矩阵 $A$ 和 $B$ 表示，它们属于 $\\mathbb{R}^{C \\times D}$，其中 $C$ 是实验条件的数量，$D$ 是神经元的数量。对齐被限制为真旋转，即特殊正交群 $SO(D)$ 中的一个元素。\n\n规定的流程如下：\n1.  通过中心化数据来移除任何平移偏移。对于数据矩阵 $X \\in \\mathbb{R}^{C \\times D}$，中心化矩阵 $X_c$ 是通过减去每个神经元在所有条件下的平均响应得到的。这等效于从每列中减去该列的均值。得到的中心化矩阵 $A_c$ 和 $B_c$ 具有每列之和为零的性质。\n2.  找到最优真旋转 $Q^{\\star} \\in SO(D)$，以最小化对齐成本，该成本定义为旋转后的几何构型 $A_c Q$ 与目标几何构型 $B_c$ 之差的平方弗罗贝尼乌斯范数。\n3.  计算归一化的残余误差。\n\n我们现在将从第一性原理推导解决方案。\n\n设中心化矩阵为 $A_c \\in \\mathbb{R}^{C \\times D}$ 和 $B_c \\in \\mathbb{R}^{C \\times D}$。优化问题是找到一个矩阵 $Q^{\\star}$ 来解决：\n$$\n\\min_{Q} \\|A_{c} Q - B_{c}\\|_{F}^{2} \\quad \\text{subject to} \\quad Q^{\\top}Q = I \\text{ and } \\det(Q) = 1\n$$\n这里，$I$ 是 $D \\times D$ 单位矩阵，$\\| \\cdot \\|_F$ 表示弗罗贝尼乌斯范数。\n\n首先，我们展开目标函数。矩阵 $M$ 的平方弗罗贝尼乌斯范数由 $\\mathrm{Tr}(M^{\\top}M)$ 给出，其中 $\\mathrm{Tr}(\\cdot)$ 是迹算子。\n$$\n\\|A_{c} Q - B_{c}\\|_{F}^{2} = \\mathrm{Tr}\\left( (A_{c} Q - B_{c})^{\\top} (A_{c} Q - B_{c}) \\right)\n$$\n展开乘积：\n$$\n= \\mathrm{Tr}\\left( (Q^{\\top} A_{c}^{\\top} - B_{c}^{\\top}) (A_{c} Q - B_{c}) \\right)\n$$\n$$\n= \\mathrm{Tr}\\left( Q^{\\top} A_{c}^{\\top} A_{c} Q - Q^{\\top} A_{c}^{\\top} B_{c} - B_{c}^{\\top} A_{c} Q + B_{c}^{\\top} B_{c} \\right)\n$$\n利用迹的线性性质，我们可以分离各项：\n$$\n= \\mathrm{Tr}(Q^{\\top} A_{c}^{\\top} A_{c} Q) - \\mathrm{Tr}(Q^{\\top} A_{c}^{\\top} B_{c}) - \\mathrm{Tr}(B_{c}^{\\top} A_{c} Q) + \\mathrm{Tr}(B_{c}^{\\top} B_{c})\n$$\n我们简化每一项。利用迹的循环性质 $\\mathrm{Tr}(XYZ) = \\mathrm{Tr}(ZXY)$ 和 $Q$ 的正交性 ($Q^{\\top}Q = I$)：\n$$\n\\mathrm{Tr}(Q^{\\top} A_{c}^{\\top} A_{c} Q) = \\mathrm{Tr}(A_{c}^{\\top} A_{c} Q Q^{\\top}) = \\mathrm{Tr}(A_{c}^{\\top} A_{c}) = \\|A_{c}\\|_{F}^{2}\n$$\n最后一项就是 $\\|B_{c}\\|_{F}^{2}$。对于中间两项，我们注意到矩阵的迹等于其转置的迹，所以 $\\mathrm{Tr}(B_{c}^{\\top} A_{c} Q) = \\mathrm{Tr}((B_{c}^{\\top} A_{c} Q)^{\\top}) = \\mathrm{Tr}(Q^{\\top} A_{c}^{\\top} B_{c})$。\n因此，目标函数简化为：\n$$\n\\|A_{c} Q - B_{c}\\|_{F}^{2} = \\|A_{c}\\|_{F}^{2} + \\|B_{c}\\|_{F}^{2} - 2 \\mathrm{Tr}(Q^{\\top} A_{c}^{\\top} B_{c})\n$$\n项 $\\|A_{c}\\|_{F}^{2}$ 和 $\\|B_{c}\\|_{F}^{2}$ 相对于 $Q$ 是常数。因此，最小化目标函数等价于最大化迹项：\n$$\n\\max_{Q \\in SO(D)} \\mathrm{Tr}(Q^{\\top} M), \\quad \\text{where} \\quad M = A_{c}^{\\top} B_{c} \\in \\mathbb{R}^{D \\times D}\n$$\n这是一个经典问题，称为正交普罗克汝斯忒斯问题，并附带了变换必须是真旋转的额外约束。\n\n为了解决这个最大化问题，我们使用矩阵 $M$ 的奇异值分解（SVD）。设 $M$ 的SVD为 $M = U \\Sigma V^{\\top}$，其中 $U, V \\in \\mathbb{R}^{D \\times D}$ 是正交矩阵（$U^{\\top}U = I$, $V^{\\top}V = I$），$\\Sigma$ 是一个对角矩阵，其对角线上有非负奇异值 $\\sigma_1 \\ge \\sigma_2 \\ge \\dots \\ge \\sigma_D \\ge 0$。\n将SVD代入迹中：\n$$\n\\mathrm{Tr}(Q^{\\top} M) = \\mathrm{Tr}(Q^{\\top} U \\Sigma V^{\\top})\n$$\n再次利用迹的循环性质：\n$$\n\\mathrm{Tr}(Q^{\\top} U \\Sigma V^{\\top}) = \\mathrm{Tr}(\\Sigma V^{\\top} Q^{\\top} U)\n$$\n我们定义一个新矩阵 $R = V^{\\top} Q^{\\top} U$。由于 $U$、$V$ 和 $Q$ 都是正交的，所以 $R$ 也是一个正交矩阵。问题转化为在所有满足行列式约束的正交矩阵 $R$ 上最大化 $\\mathrm{Tr}(\\Sigma R)$。\n$$\n\\mathrm{Tr}(\\Sigma R) = \\sum_{i=1}^{D} (\\Sigma R)_{ii} = \\sum_{i=1}^{D} \\sigma_i R_{ii}\n$$\n由于 $\\sigma_i \\ge 0$ 且 $R$ 是正交的（意味着 $|R_{ii}| \\le 1$），当 $R_{ii}$ 对每个 $i$ 都尽可能大时，即 $R_{ii}=1$ 时，此和达到最大值。如果 $R$ 是单位矩阵 $R=I$，就能实现这一点。\n如果 $R=I$，则 $V^{\\top}Q^{\\top}U = I$，这意味着 $Q^{\\top} = V U^{\\top}$，因此 $Q = U V^{\\top}$。这是无约束的正交普罗克汝斯忒斯问题的解。\n\n现在，我们必须强制执行约束 $\\det(Q) = +1$。\n我们提出的解的行列式是 $\\det(Q) = \\det(U V^{\\top}) = \\det(U) \\det(V^{\\top}) = \\det(U) \\det(V)$。来自SVD的 $U$ 和 $V$ 的行列式可以是 $+1$ 或 $-1$。\n情况 1: $\\det(U)\\det(V) = +1$。在这种情况下，$\\det(UV^{\\top}) = +1$，所以我们的解 $Q^{\\star} = UV^{\\top}$ 是一个真旋转，并且是最优解。\n情况 2: $\\det(U)\\det(V) = -1$。在这种情况下，$\\det(UV^{\\top}) = -1$，意味着最优正交变换是一个反射。我们被限制寻找最佳的*真旋转*。我们必须找到一个行列式为 $\\det(Q)=+1$ 的正交矩阵 $Q$ 来最大化 $\\mathrm{Tr}(Q^\\top M)$。这等价于找到一个行列式为 $\\det(R) = \\det(V)\\det(Q)\\det(U) = \\det(V)(+1)\\det(U) = \\det(U)\\det(V) = -1$ 的正交矩阵 $R=V^{\\top} Q^{\\top} U$ 来最大化 $\\mathrm{Tr}(\\Sigma R) = \\sum_{i} \\sigma_i R_{ii}$。\n在 $\\sigma_1 \\ge \\dots \\ge \\sigma_D \\ge 0$ 的条件下，通过设置 $R_{ii}=1$ 对 $i=1, \\dots, D-1$ 和 $R_{DD}=-1$ 来满足 $\\det(R) = -1$，可以达到最大值。这种选择最小化了由负号引起的惩罚，因为它被应用于最小的奇异值 $\\sigma_D$。\n所以，在这种情况下，最优的 $R$ 是 $R = \\mathrm{diag}(1, 1, \\dots, -1)$。\n然后，通过解方程 $V^{\\top} (Q^{\\star})^{\\top} U = \\mathrm{diag}(1, \\dots, -1)$ 来找到最优旋转 $Q^{\\star}$，得到 $Q^{\\star} = U \\mathrm{diag}(1, \\dots, -1) V^{\\top}$。\n\n我们可以用一个表达式统一这两种情况。令 $S = \\mathrm{diag}(1, \\dots, 1, \\det(UV^{\\top}))$。\n最优真旋转是 $Q^{\\star} = U S V^{\\top}$。\n如果 $\\det(UV^{\\top}) = 1$，$S=I$ 且 $Q^{\\star} = UV^{\\top}$。\n如果 $\\det(UV^{\\top}) = -1$，$S=\\mathrm{diag}(1, \\dots, -1)$ 且 $Q^{\\star} = U \\mathrm{diag}(1, \\dots, -1) V^{\\top}$。\n\n总体算法如下：\n1.  对于输入矩阵 $A$ 和 $B$，计算中心化矩阵 $A_c$ 和 $B_c$。\n2.  计算矩阵 $M = A_c^{\\top} B_c$。\n3.  对 $M = U \\Sigma V^{\\top}$ 进行奇异值分解 (SVD) 以找到 $U$ 和 $V$。\n4.  构造最优旋转 $Q^{\\star} = U S V^{\\top}$，其中 $S = \\mathrm{diag}(1, \\dots, 1, \\det(UV^{\\top}))$。\n5.  计算最终的误差度量：\n$$\n\\mathrm{err} = \\frac{\\|A_{c} Q^{\\star} - B_{c}\\|_{F}^{2}}{\\|B_{c}\\|_{F}^{2}}\n$$\n此过程为所有测试用例提供了唯一且稳定的解决方案，包括那些具有秩亏几何结构或反射失配的用例。",
            "answer": "```python\nimport numpy as np\n# from scipy import ... # Not used\n\ndef solve():\n    \"\"\"\n    Solves the neural population geometry alignment problem for all test cases.\n    \"\"\"\n\n    # Define the base matrix A1 and transformation matrices\n    A1 = np.array([\n        [0., 1., 2.],\n        [1., 0., 1.],\n        [2., 1., 0.],\n        [1., 2., 1.]\n    ])\n\n    Rz_90 = np.array([\n        [0., -1., 0.],\n        [1.,  0., 0.],\n        [0.,  0., 1.]\n    ])\n\n    # Test Case 1: Exact Rotation\n    A1_case = A1\n    B1_case = A1_case @ Rz_90\n\n    # Test Case 2: Rotation plus small noise\n    A2_case = A1\n    N2 = np.array([\n        [ 0.05, -0.03,  0.02],\n        [-0.01,  0.04, -0.02],\n        [ 0.00, -0.02,  0.03],\n        [ 0.02,  0.01, -0.01]\n    ])\n    B2_case = A2_case @ Rz_90 + N2\n\n    # Test Case 3: Rank-deficient geometry, rotation plus small noise\n    A3_case = np.array([\n        [1., 2., 3.],\n        [2., 4., 6.],\n        [3., 6., 9.],\n        [4., 8., 12.]\n    ])\n    N3 = np.array([\n        [ 0.10, -0.10,  0.00],\n        [ 0.00,  0.00,  0.10],\n        [-0.05,  0.02, -0.02],\n        [ 0.03, -0.04,  0.01]\n    ])\n    B3_case = A3_case @ Rz_90 + N3\n\n    # Test Case 4: Pure reflection mismatch\n    A4_case = A1\n    Fx = np.array([\n        [-1., 0., 0.],\n        [ 0., 1., 0.],\n        [ 0., 0., 1.]\n    ])\n    B4_case = A4_case @ Fx\n\n    test_cases = [\n        (A1_case, B1_case),\n        (A2_case, B2_case),\n        (A3_case, B3_case),\n        (A4_case, B4_case)\n    ]\n\n    results = []\n    for A, B in test_cases:\n        err = compute_alignment_error(A, B)\n        # Format the result to a reasonable precision for display\n        results.append(f\"{err:.8f}\")\n\n    print(f\"[{','.join(results)}]\")\n\ndef compute_alignment_error(A, B):\n    \"\"\"\n    Computes the alignment error between two neural population geometries A and B.\n    \n    Args:\n        A (np.ndarray): The first C x D condition-mean response matrix.\n        B (np.ndarray): The second C x D condition-mean response matrix.\n\n    Returns:\n        float: The normalized residual alignment error.\n    \"\"\"\n    # Step 1: Remove translation by centering each geometry\n    # A_c = A - A.mean(axis=0) creates a new array for the mean that is broadcasted.\n    A_c = A - A.mean(axis=0, keepdims=True)\n    B_c = B - B.mean(axis=0, keepdims=True)\n\n    # Step 2: Compute the optimal orthogonal matrix Q*\n    # This involves solving the Orthogonal Procrustes problem for a proper rotation.\n    \n    # Construct the matrix M = A_c^T * B_c\n    D = A.shape[1]\n    M = A_c.T @ B_c\n    \n    # Perform Singular Value Decomposition (SVD) on M\n    # M = U * Sigma * V^T\n    try:\n        U, s, Vt = np.linalg.svd(M)\n    except np.linalg.LinAlgError:\n        # If SVD fails, this indicates a serious numerical issue with the input.\n        # For the given test cases, this is not expected.\n        return np.nan\n\n    # The optimal orthogonal matrix (could be rotation or reflection) is Q_ortho = U @ Vt.\n    # We need to ensure Q is a proper rotation, i.e., det(Q) = +1.\n    \n    # Check the determinant of U @ Vt\n    det_check = np.linalg.det(U @ Vt)\n    \n    # Create the correction matrix S.\n    # S is the identity, but if det(U @ Vt) is -1, the last diagonal\n    # element of S is flipped to -1. This corrects the 'reflection' case.\n    S = np.identity(D)\n    if det_check  0:\n        S[-1, -1] = -1\n        \n    # The optimal proper rotation matrix Q_star\n    Q_star = U @ S @ Vt\n\n    # Step 3: Quantify the residual alignment error\n    \n    # Calculate the squared Frobenius norm of the residual\n    residual_norm_sq = np.linalg.norm(A_c @ Q_star - B_c, 'fro')**2\n    \n    # Calculate the squared Frobenius norm of the target geometry\n    target_norm_sq = np.linalg.norm(B_c, 'fro')**2\n    \n    # Avoid division by zero, though not expected for these test cases.\n    # If target_norm_sq is zero, it means all points in B_c are the origin.\n    # If A_c is also all-zero, they are perfectly aligned (error 0).\n    # If A_c is not, they are unalignable (error inf). We'll assume the former.\n    if target_norm_sq  1e-15:\n        return 0.0 if np.linalg.norm(A_c, 'fro')**2  1e-15 else np.inf\n\n    err = residual_norm_sq / target_norm_sq\n    \n    return err\n\nsolve()\n\n```"
        }
    ]
}