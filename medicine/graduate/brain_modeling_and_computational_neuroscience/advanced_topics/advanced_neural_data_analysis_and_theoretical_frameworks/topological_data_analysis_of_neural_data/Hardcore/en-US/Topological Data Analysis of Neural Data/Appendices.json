{
    "hands_on_practices": [
        {
            "introduction": "This first exercise provides a foundational, step-by-step walkthrough of computing homology. We will start with a hypothetical but common scenario in neuroscience: a simple coactivity graph between three neurons. By constructing a simplicial complex from this graph and applying the core definitions of simplicial homology, you will calculate the Betti numbers $\\beta_0$ and $\\beta_1$ from scratch, solidifying your understanding of how these topological invariants quantify connected components and cycles in a neural assembly .",
            "id": "4030995",
            "problem": "A common approach in Topological Data Analysis (TDA) of neural data is to build a simplicial complex from an instantaneous coactivity graph among neurons and then study its homology. Consider a spike-train dataset from $3$ hippocampal neurons $\\{n_1,n_2,n_3\\}$ recorded during exploration. At a fixed coactivity threshold $\\tau$, two neuron pairs exceed the threshold: $\\{n_1,n_2\\}$ and $\\{n_2,n_3\\}$, while $\\{n_1,n_3\\}$ does not. Assume there is no simultaneous triple coactivity above $\\tau$. Construct the flag (clique) complex $K(\\tau)$ from this graph: include a $0$-simplex for each neuron, a $1$-simplex for each observed coactive pair, and a $2$-simplex only if all three edges of a triangle are present. For this $K(\\tau)$, use simplicial homology with coefficients in a field (e.g., $\\mathbb{R}$).\n\nStarting from the core definitions of simplicial complexes, chain groups, and boundary operators, compute the Betti numbers $\\beta_0$ and $\\beta_1$ of $K(\\tau)$. Then, explain the topological meaning of these Betti numbers in the context of neural coactivity: interpret what $\\beta_0$ and $\\beta_1$ say about the number of connected neural assemblies and the presence or absence of one-dimensional coactivity loops at threshold $\\tau$.\n\nExpress your final answer as a row matrix using the $\\mathrm{pmatrix}$ environment with entries $\\beta_0$ and $\\beta_1$.",
            "solution": "The problem statement has been evaluated and is deemed valid. It is scientifically grounded in the principles of topological data analysis as applied to computational neuroscience, is well-posed with sufficient and consistent information, and is expressed in objective, formal language. We may proceed with the solution.\n\nThe solution involves three main steps: 1) constructing the simplicial complex based on the provided coactivity data, 2) computing the homology groups and their corresponding Betti numbers, and 3) interpreting these topological invariants in the context of the neural system.\n\n**1. Construction of the Simplicial Complex $K(\\tau)$**\n\nA simplicial complex is a collection of simplices (vertices, edges, triangles, etc.) that is closed under the operation of taking faces. The problem specifies the construction of a flag (or clique) complex, where a simplex is included if and only if all of its sub-simplices (faces) are present.\n\n*   **0-simplices (Vertices):** The vertices of the complex correspond to the individual neurons. We have $3$ neurons, which we denote as $n_1$, $n_2$, and $n_3$. The set of $0$-simplices is $K_0 = \\{[n_1], [n_2], [n_3]\\}$.\n\n*   **1-simplices (Edges):** The edges represent pairs of neurons whose coactivity exceeds the threshold $\\tau$. The problem states that the pairs $\\{n_1, n_2\\}$ and $\\{n_2, n_3\\}$ are coactive, while $\\{n_1, n_3\\}$ is not. Therefore, the set of $1$-simplices is $K_1 = \\{[n_1, n_2], [n_2, n_3]\\}$.\n\n*   **2-simplices (Triangles):** A $2$-simplex, $[n_1, n_2, n_3]$, would be included in the flag complex if and only if all three of its constituent edges ($1$-faces) are in $K_1$. These edges are $[n_1, n_2]$, $[n_2, n_3]$, and $[n_1, n_3]$. Since the edge $[n_1, n_3]$ is not in $K_1$, the $2$-simplex $[n_1, n_2, n_3]$ is not part of the complex. This is also consistent with the given condition of no simultaneous triple coactivity. Thus, the set of $2$-simplices is empty: $K_2 = \\emptyset$.\n\n*   **Higher-dimensional Simplices:** Since there are no $2$-simplices, there can be no simplices of dimension $p \\ge 2$.\n\nThe resulting simplicial complex $K(\\tau)$ consists of three vertices and two edges connecting them in a sequence: $n_1 - n_2 - n_3$. Topologically, this is a line segment.\n\n**2. Computation of Betti Numbers $\\beta_0$ and $\\beta_1$**\n\nWe will use simplicial homology with coefficients in a field $\\mathbb{F}$ (such as $\\mathbb{R}$). The $p$-th Betti number, $\\beta_p$, is the dimension of the $p$-th homology group $H_p(K) = \\ker(\\partial_p) / \\text{im}(\\partial_{p+1})$.\n\nFirst, we define the chain groups $C_p(K)$, which are vector spaces over $\\mathbb{F}$ with bases given by the oriented $p$-simplices.\n\n*   $C_0(K)$: A vector space with basis $\\{[n_1], [n_2], [n_3]\\}$. Its dimension is $\\dim(C_0) = 3$.\n*   $C_1(K)$: A vector space with basis $\\{[n_1, n_2], [n_2, n_3]\\}$. Its dimension is $\\dim(C_1) = 2$.\n*   $C_2(K)$: The trivial vector space $\\{0\\}$ since $K_2$ is empty. Its dimension is $\\dim(C_2) = 0$.\n\nNext, we define the boundary operators $\\partial_p: C_p(K) \\to C_{p-1}(K)$.\n\n*   $\\partial_2: C_2(K) \\to C_1(K)$ is the zero map since $C_2(K)=\\{0\\}$. Thus, $\\text{im}(\\partial_2) = \\{0\\}$.\n*   $\\partial_1: C_1(K) \\to C_0(K)$ is defined by its action on the basis elements:\n    $$ \\partial_1([v_0, v_1]) = [v_1] - [v_0] $$\n    So, for our basis:\n    $$ \\partial_1([n_1, n_2]) = [n_2] - [n_1] $$\n    $$ \\partial_1([n_2, n_3]) = [n_3] - [n_2] $$\n\n**Computation of $\\beta_0$:**\nThe $0$-th Betti number is the dimension of the $0$-th homology group, $H_0(K) = \\ker(\\partial_0) / \\text{im}(\\partial_1)$.\nBy definition, $\\partial_0$ is the zero map, so $\\ker(\\partial_0) = C_0(K)$.\nThus, $H_0(K) = C_0(K) / \\text{im}(\\partial_1)$. The dimension is given by:\n$$ \\beta_0 = \\dim(H_0(K)) = \\dim(C_0(K)) - \\dim(\\text{im}(\\partial_1)) $$\nThe image of $\\partial_1$, $\\text{im}(\\partial_1)$, is the subspace of $C_0(K)$ spanned by the vectors $[n_2] - [n_1]$ and $[n_3] - [n_2]$. These two vectors are linearly independent. For example, if $c_1([n_2] - [n_1]) + c_2([n_3] - [n_2]) = 0$, then $-c_1[n_1] + (c_1-c_2)[n_2] + c_2[n_3] = 0$. Since $\\{[n_1], [n_2], [n_3]\\}$ is a basis, this implies $-c_1=0$, $c_1-c_2=0$, and $c_2=0$, which gives $c_1=c_2=0$.\nThus, $\\dim(\\text{im}(\\partial_1)) = 2$.\nSubstituting the dimensions, we find:\n$$ \\beta_0 = 3 - 2 = 1 $$\n\n**Computation of $\\beta_1$:**\nThe $1$-st Betti number is the dimension of the $1$-st homology group, $H_1(K) = \\ker(\\partial_1) / \\text{im}(\\partial_2)$.\nAs established, $\\text{im}(\\partial_2) = \\{0\\}$. Therefore, $H_1(K) \\cong \\ker(\\partial_1)$. We need to find the dimension of the kernel of $\\partial_1$.\nAn arbitrary element of $C_1(K)$ is a linear combination $c = a_1[n_1, n_2] + a_2[n_2, n_3]$ for scalars $a_1, a_2 \\in \\mathbb{F}$.\nIts boundary is:\n$$ \\partial_1(c) = a_1 \\partial_1([n_1, n_2]) + a_2 \\partial_1([n_2, n_3]) $$\n$$ \\partial_1(c) = a_1([n_2] - [n_1]) + a_2([n_3] - [n_2]) $$\n$$ \\partial_1(c) = -a_1[n_1] + (a_1 - a_2)[n_2] + a_2[n_3] $$\nFor $c$ to be in the kernel of $\\partial_1$, we must have $\\partial_1(c) = 0$. Since $\\{[n_1], [n_2], [n_3]\\}$ forms a basis for $C_0(K)$, the coefficients of the basis vectors must all be zero:\n$$ -a_1 = 0 \\implies a_1 = 0 $$\n$$ a_1 - a_2 = 0 $$\n$$ a_2 = 0 $$\nSubstituting $a_1=0$ and $a_2=0$ into the middle equation confirms consistency. The only solution is $a_1 = 0$ and $a_2 = 0$. This means the only element in the kernel is the zero vector, $c=0$.\nTherefore, $\\ker(\\partial_1) = \\{0\\}$. The dimension of the kernel is $0$.\n$$ \\beta_1 = \\dim(H_1(K)) = \\dim(\\ker(\\partial_1)) = 0 $$\n\nThe Betti numbers for the complex $K(\\tau)$ are $\\beta_0=1$ and $\\beta_1=0$.\n\n**3. Topological Interpretation in the Neural Context**\n\nThe Betti numbers provide a concise, quantitative description of the topology of the coactivity graph.\n\n*   **Interpretation of $\\beta_0 = 1$:** The $0$-th Betti number, $\\beta_0$, counts the number of connected components in the topological space. In this context, the simplicial complex represents the functional connectivity structure of the neural population. A connected component is a maximal subgraph in which any two vertices are connected to each other by a path of edges. Such a component can be interpreted as a \"neural assembly\"—a group of neurons that are functionally integrated through pairwise coactivity, either directly or indirectly. The result $\\beta_0=1$ signifies that at the given threshold $\\tau$, all the neurons with significant coactivity form a single, unified functional network. There are no isolated, independent groups of coactive neurons.\n\n*   **Interpretation of $\\beta_1 = 0$:** The $1$-st Betti number, $\\beta_1$, counts the number of independent one-dimensional \"holes\" or loops in the space. In the coactivity complex, a $1$-cycle (a loop) would represent a pattern of circular coactivity, for example, where neuron A is coactive with B, B with C, and C back with A. Such a structure could be evidence of a recurrent or cyclic functional motif in the neural circuit. The result $\\beta_1=0$ indicates that no such one-dimensional loops exist in the coactivity structure at threshold $\\tau$. The functional relationships are acyclic, forming a chain-like (as in this specific case) or tree-like structure. The absence of the $\\{n_1, n_3\\}$ coactivity link is precisely what prevents the formation of a loop and leads to $\\beta_1=0$.",
            "answer": "$$ \\boxed{\\begin{pmatrix} 1 & 0 \\end{pmatrix}} $$"
        },
        {
            "introduction": "Real-world neural data is rarely represented by a single, fixed graph; instead, its structure depends on the scale at which we view it. This practice introduces the Vietoris-Rips (VR) complex, a fundamental tool in TDA for building a multi-scale topological representation from a distance matrix . By analyzing a small dataset at two different scales, you will see how topological features like connected components and cycles can appear and merge, providing direct intuition for the concept of a filtration, which underpins persistent homology.",
            "id": "4031010",
            "problem": "Consider four simultaneously recorded neurons represented by points in a feature space derived from spike train statistics, where pairwise dissimilarities are summarized by a symmetric distance matrix. In Topological Data Analysis (TDA), the Vietoris–Rips (VR) complex at scale $r$, denoted $\\mathrm{VR}_r$, is defined as the abstract simplicial complex on the vertex set with a $k$-simplex on a set of $k+1$ vertices if and only if all pairwise distances among those vertices are less than or equal to $r$. Betti numbers $\\beta_k$ are the ranks of the homology groups $H_k$ of the complex, quantifying $k$-dimensional topological features (connected components for $\\beta_0$, one-dimensional cycles for $\\beta_1$, and so on).\n\nYou are given the following dissimilarity matrix for neurons $N_1, N_2, N_3, N_4$:\n$$\nD =\n\\begin{pmatrix}\n0 & 0.9 & 1.8 & 1.4 \\\\\n0.9 & 0 & 1.5 & 1.9 \\\\\n1.8 & 1.5 & 0 & 0.8 \\\\\n1.4 & 1.9 & 0.8 & 0\n\\end{pmatrix}.\n$$\nAssume these distances arise from a valid metric on the neuronal feature space. Consider two scales $r_1$ and $r_2$ with $r_1=1.0$ and $r_2=1.6$, and use the closed condition “less than or equal to $r$”.\n\nTasks:\n1. Using only the definitions above, explicitly list all simplices in $\\mathrm{VR}_{r_1}$ and in $\\mathrm{VR}_{r_2}$, for $k=0,1,2$.\n2. Compute the Betti numbers $\\beta_0$, $\\beta_1$, and $\\beta_2$ for $\\mathrm{VR}_{r_1}$ and for $\\mathrm{VR}_{r_2}$.\n3. Compute the change in Betti numbers between the two scales, defined as the vector\n$$\n\\Delta \\boldsymbol{\\beta} = \\big(\\beta_0(r_2)-\\beta_0(r_1),\\; \\beta_1(r_2)-\\beta_1(r_1),\\; \\beta_2(r_2)-\\beta_2(r_1)\\big).\n$$\n\nProvide the final answer as a single row vector containing the three entries of $\\Delta \\boldsymbol{\\beta}$, in exact form with no rounding and no units.",
            "solution": "The problem statement is validated as scientifically grounded, well-posed, and objective. It provides a symmetric dissimilarity matrix $D$ with zero diagonal entries, two specific scales $r_1$ and $r_2$, and clear definitions for the Vietoris-Rips complex $\\mathrm{VR}_r$ and Betti numbers $\\beta_k$. The task is a standard application of topological data analysis. The distances in the matrix satisfy the triangle inequality, confirming they can arise from a valid metric space as assumed. All necessary information is present, and there are no contradictions or ambiguities. We may proceed with the solution.\n\nThe set of vertices for the simplicial complexes is the set of four neurons, $\\{N_1, N_2, N_3, N_4\\}$. A $k$-simplex exists on a subset of $k+1$ vertices if all pairwise distances within that subset are less than or equal to the scale parameter $r$.\n\n**Task 1: Explicitly list all simplices in $\\mathrm{VR}_{r_1}$ and $\\mathrm{VR}_{r_2}$**\n\nFirst, consider the scale $r_1 = 1.0$. We construct the Vietoris-Rips complex $\\mathrm{VR}_{1.0}$.\n\nThe $0$-simplices ($k=0$) are the individual vertices:\n$\\{N_1\\}, \\{N_2\\}, \\{N_3\\}, \\{N_4\\}$.\n\nThe $1$-simplices ($k=1$) are pairs of vertices $\\{N_i, N_j\\}$ such that their distance $D_{ij} \\le 1.0$. From the matrix $D$:\n$$\nD =\n\\begin{pmatrix}\n0 & 0.9 & 1.8 & 1.4 \\\\\n0.9 & 0 & 1.5 & 1.9 \\\\\n1.8 & 1.5 & 0 & 0.8 \\\\\n1.4 & 1.9 & 0.8 & 0\n\\end{pmatrix}\n$$\n- $D_{12} = 0.9 \\le 1.0$, so $\\{N_1, N_2\\}$ is a $1$-simplex.\n- $D_{13} = 1.8 > 1.0$.\n- $D_{14} = 1.4 > 1.0$.\n- $D_{23} = 1.5 > 1.0$.\n- $D_{24} = 1.9 > 1.0$.\n- $D_{34} = 0.8 \\le 1.0$, so $\\{N_3, N_4\\}$ is a $1$-simplex.\nThe set of $1$-simplices for $\\mathrm{VR}_{1.0}$ is $\\{\\{N_1, N_2\\}, \\{N_3, N_4\\}\\}$.\n\nThe $2$-simplices ($k=2$) are triplets of vertices $\\{N_i, N_j, N_l\\}$ such that all three pairwise distances are $\\le 1.0$. This requires a complete subgraph on three vertices ($K_3$) in the $1$-skeleton. The $1$-skeleton consists of two disjoint edges, so no such triplet of vertices exists. Therefore, there are no $2$-simplices in $\\mathrm{VR}_{1.0}$.\n\nNext, consider the scale $r_2 = 1.6$. We construct the Vietoris-Rips complex $\\mathrm{VR}_{1.6}$.\n\nThe $0$-simplices ($k=0$) are again the vertices:\n$\\{N_1\\}, \\{N_2\\}, \\{N_3\\}, \\{N_4\\}$.\n\nThe $1$-simplices ($k=1$) are pairs $\\{N_i, N_j\\}$ with $D_{ij} \\le 1.6$:\n- $D_{12} = 0.9 \\le 1.6$, so $\\{N_1, N_2\\}$ is a $1$-simplex.\n- $D_{13} = 1.8 > 1.6$.\n- $D_{14} = 1.4 \\le 1.6$, so $\\{N_1, N_4\\}$ is a $1$-simplex.\n- $D_{23} = 1.5 \\le 1.6$, so $\\{N_2, N_3\\}$ is a $1$-simplex.\n- $D_{24} = 1.9 > 1.6$.\n- $D_{34} = 0.8 \\le 1.6$, so $\\{N_3, N_4\\}$ is a $1$-simplex.\nThe set of $1$-simplices for $\\mathrm{VR}_{1.6}$ is $\\{\\{N_1, N_2\\}, \\{N_1, N_4\\}, \\{N_2, N_3\\}, \\{N_3, N_4\\}\\}$.\n\nThe $2$-simplices ($k=2$) are triplets $\\{N_i, N_j, N_l\\}$ with all pairwise distances $\\le 1.6$. We check all four possible triplets:\n- $\\{N_1, N_2, N_3\\}$: Distances are $D_{12}=0.9$, $D_{23}=1.5$, and $D_{13}=1.8$. Since $D_{13} > 1.6$, this is not a $2$-simplex.\n- $\\{N_1, N_2, N_4\\}$: Distances are $D_{12}=0.9$, $D_{14}=1.4$, and $D_{24}=1.9$. Since $D_{24} > 1.6$, this is not a $2$-simplex.\n- $\\{N_1, N_3, N_4\\}$: Distances are $D_{14}=1.4$, $D_{34}=0.8$, and $D_{13}=1.8$. Since $D_{13} > 1.6$, this is not a $2$-simplex.\n- $\\{N_2, N_3, N_4\\}$: Distances are $D_{23}=1.5$, $D_{34}=0.8$, and $D_{24}=1.9$. Since $D_{24} > 1.6$, this is not a $2$-simplex.\nTherefore, there are no $2$-simplices in $\\mathrm{VR}_{1.6}$.\n\n**Task 2: Compute the Betti numbers $\\beta_0$, $\\beta_1$, and $\\beta_2$**\n\nFor $\\mathrm{VR}_{r_1 = 1.0}$:\nThe complex consists of the vertices $\\{N_1, N_2, N_3, N_4\\}$ and the edges $\\{N_1, N_2\\}$ and $\\{N_3, N_4\\}$. Topologically, this is the disjoint union of two line segments.\n- $\\beta_0(r_1)$: This is the number of connected components. There are two components, one formed by $\\{N_1, N_2\\}$ and the other by $\\{N_3, N_4\\}$. Thus, $\\beta_0(r_1) = 2$.\n- $\\beta_1(r_1)$: This is the number of independent $1$-dimensional cycles (holes). The complex is a graph with no cycles (a forest). Thus, $\\beta_1(r_1) = 0$.\n- $\\beta_2(r_1)$: This is the number of independent $2$-dimensional voids. The complex is $1$-dimensional (it has no $2$-simplices), so it cannot enclose any $2$-dimensional voids. Thus, $\\beta_2(r_1) = 0$.\nThe Betti numbers for $\\mathrm{VR}_{1.0}$ are $(\\beta_0(r_1), \\beta_1(r_1), \\beta_2(r_1)) = (2, 0, 0)$.\n\nFor $\\mathrm{VR}_{r_2 = 1.6}$:\nThe complex's $1$-skeleton consists of the vertices $\\{N_1, N_2, N_3, N_4\\}$ and the edges $\\{N_1, N_2\\}$, $\\{N_2, N_3\\}$, $\\{N_3, N_4\\}$, and $\\{N_4, N_1\\}$. These form a cycle of length $4$: $N_1 - N_2 - N_3 - N_4 - N_1$.\n- $\\beta_0(r_2)$: The complex is path-connected; all vertices belong to a single component. Thus, $\\beta_0(r_2) = 1$.\n- $\\beta_1(r_2)$: The cycle $N_1 - N_2 - N_3 - N_4 - N_1$ constitutes a $1$-dimensional hole. Since there are no $2$-simplices to \"fill\" this hole, it represents a non-trivial element in the first homology group $H_1$. There is one such independent cycle. Thus, $\\beta_1(r_2) = 1$. For a graph, this can also be computed as $\\beta_1 = E - V + C$, where $E$ is the number of edges, $V$ is the number of vertices, and $C$ is the number of connected components. Here, $E=4$, $V=4$, and $C=1$, so $\\beta_1(r_2) = 4 - 4 + 1 = 1$.\n- $\\beta_2(r_2)$: The complex is $1$-dimensional, so there are no $2$-dimensional voids. Thus, $\\beta_2(r_2) = 0$.\nThe Betti numbers for $\\mathrm{VR}_{1.6}$ are $(\\beta_0(r_2), \\beta_1(r_2), \\beta_2(r_2)) = (1, 1, 0)$.\n\n**Task 3: Compute the change in Betti numbers $\\Delta \\boldsymbol{\\beta}$**\n\nThe change is defined as $\\Delta \\boldsymbol{\\beta} = \\big(\\beta_0(r_2)-\\beta_0(r_1),\\; \\beta_1(r_2)-\\beta_1(r_1),\\; \\beta_2(r_2)-\\beta_2(r_1)\\big)$.\nUsing the results from Task 2:\n- $\\beta_0$ changes from $2$ to $1$: $\\Delta \\beta_0 = 1 - 2 = -1$. This reflects the merging of two components into one.\n- $\\beta_1$ changes from $0$ to $1$: $\\Delta \\beta_1 = 1 - 0 = 1$. This reflects the creation of a new cycle.\n- $\\beta_2$ changes from $0$ to $0$: $\\Delta \\beta_2 = 0 - 0 = 0$.\n\nTherefore, the change vector is $\\Delta \\boldsymbol{\\beta} = (-1, 1, 0)$.",
            "answer": "$$ \\boxed{\n\\begin{pmatrix}\n-1 & 1 & 0\n\\end{pmatrix}\n} $$"
        },
        {
            "introduction": "Moving from manual calculation to computational implementation is key to applying TDA to real research problems. This final, comprehensive exercise guides you through building a complete software pipeline to analyze synthetic neural data and infer the topology of its underlying latent space . You will implement data generation for toroidal and non-toroidal manifolds, compute persistent homology using the Vietoris-Rips filtration, and apply a decision rule to classify the data's shape, mirroring a common workflow in studies of neural representation.",
            "id": "4031023",
            "problem": "You are given synthetic population neural activity generated from latent variables that may or may not have toroidal topology. Your task is to implement a complete procedure to estimate whether the underlying topology is toroidal using Persistent Homology (PH) computed on the Vietoris–Rips filtration. You must output a boolean decision for each provided test dataset, aggregated into a single line in the specified format.\n\nFundamental base and definitions:\n- The latent variables are angles $(\\theta_x,\\theta_y)\\in\\mathbb{T}^2$, where $\\mathbb{T}^2$ denotes the $2$-torus topological space. Angles must be measured in radians.\n- Population neural activity is modeled as a smooth embedding of the latent variables into a high-dimensional Euclidean space, with additive noise, which yields a point cloud $\\{x_i\\}_{i=1}^N\\subset\\mathbb{R}^M$.\n- Topological Data Analysis (TDA) studies the shape of data via algebraic topology. Vietoris–Rips (VR) filtration constructs simplicial complexes indexed by a scale parameter $\\epsilon\\geq 0$ by including a $k$-simplex if all pairwise distances between its vertices are at most $\\epsilon$.\n- Persistent Homology (PH) tracks the birth and death of topological features across the filtration. For $1$-dimensional homology ($H_1$), the birth of a class corresponds to the formation of a loop by edges, and its death corresponds to the addition of triangles that fill the loop. For $0$-dimensional homology ($H_0$), births occur at vertices and deaths occur when edges merge connected components.\n- Betti numbers $(\\beta_0,\\beta_1,\\beta_2,\\dots)$ count the number of independent $k$-dimensional holes. For the $2$-torus $\\mathbb{T}^2$, it is known that $\\beta_0=1$, $\\beta_1=2$, and $\\beta_2=1$.\n- A toroidal manifold embedded in $\\mathbb{R}^M$ should present two prominent $H_1$ features over a range of scales in the VR filtration under moderate noise.\n\nProblem requirements:\n1. Implement a generator of neural population activity $x\\in\\mathbb{R}^M$ from latent variables $(\\theta_x,\\theta_y)$ as follows. Define base features $u(\\theta_x,\\theta_y)\\in\\mathbb{R}^8$ by\n$$\nu(\\theta_x,\\theta_y) =\n\\begin{bmatrix}\n\\cos\\theta_x\\\\\n\\sin\\theta_x\\\\\n\\cos\\theta_y\\\\\n\\sin\\theta_y\\\\\n\\cos\\theta_x\\cos\\theta_y\\\\\n\\cos\\theta_x\\sin\\theta_y\\\\\n\\sin\\theta_x\\cos\\theta_y\\\\\n\\sin\\theta_x\\sin\\theta_y\n\\end{bmatrix},\n$$\nand set $x = W^\\top u + \\eta$, where $W\\in\\mathbb{R}^{8\\times M}$ has entries sampled from a zero-mean unit-variance Gaussian, and $\\eta\\sim\\mathcal{N}(0,\\sigma^2 I_M)$ is additive Gaussian noise. For non-toroidal datasets, modify $(\\theta_x,\\theta_y)$ generation appropriately as specified in the test suite. After generation, perform per-neuron standardization: subtract the mean and divide by the standard deviation across samples for each neuron.\n2. Compute the pairwise Euclidean distance matrix $D\\in\\mathbb{R}^{N\\times N}$ from the standardized activity.\n3. Construct the Vietoris–Rips filtration up to $2$-simplices (vertices, edges, triangles), where the filtration value of an edge $(i,j)$ is $d_{ij}$ and for a triangle $(i,j,k)$ is $\\max\\{d_{ij},d_{ik},d_{jk}\\}$. Vertices have filtration value $0$.\n4. Implement the standard matrix reduction algorithm for PH with coefficients in $\\mathbb{Z}_2$ to obtain persistence intervals for $H_0$ and $H_1$. For $H_0$, you may use the union–find algorithm equivalent to minimum spanning forest construction to compute finite intervals with births at $0$ and deaths at the edge filtration values. For $H_1$, perform column reduction on edge and triangle boundary matrices: edges create $H_1$ births when their reduced boundary is empty, and triangles kill $H_1$ classes by pairing with pivot edges; the interval length is the difference between the triangle and edge filtration values.\n5. Decision rule: classify a dataset as toroidal if there exist at least two $H_1$ persistence intervals whose lengths, normalized by the maximum edge filtration value, exceed a threshold $\\tau$, and the ratio of their lengths is within a factor of $2$ (to avoid classifying wedge-of-circles artifacts). Use a fixed $\\tau$ specified below.\n\nTest suite:\nImplement five datasets with parameters explicitly given:\n- Case A (toroidal manifold): $N=48$ samples, $M=64$ neurons, $\\sigma=0.10$, angles $(\\theta_x,\\theta_y)$ independently uniform on $[0,2\\pi)$ in radians.\n- Case B (single circle): $N=48$, $M=64$, $\\sigma=0.10$, set $\\theta_y\\equiv 0$ and $\\theta_x$ uniform on $[0,2\\pi)$ in radians.\n- Case C (random cloud): $N=48$, $M=64$, $\\sigma=0.10$, generate $x$ as independent $\\mathcal{N}(0,1)$ entries per sample and standardize per neuron.\n- Case D (cylinder-like manifold): $N=48$, $M=64$, $\\sigma=0.10$, set $\\theta_x$ uniform on $[0,2\\pi)$ in radians and $y\\in[0,1]$ uniform, and use features $u_{\\mathrm{cyl}}(\\theta_x,y)=[\\cos\\theta_x,\\sin\\theta_x,y,\\cos\\theta_x\\,y,\\sin\\theta_x\\,y, y^2, \\cos\\theta_x\\,y^2, \\sin\\theta_x\\,y^2]^\\top$ and $x = W^\\top u_{\\mathrm{cyl}} + \\eta$ with $W\\in\\mathbb{R}^{8\\times M}$ Gaussian as above.\n- Case E (toroidal with higher noise): $N=48$, $M=64$, $\\sigma=0.30$, angles $(\\theta_x,\\theta_y)$ independently uniform on $[0,2\\pi)$ in radians.\n\nClassification threshold:\n- Use $\\tau = 0.20$, where interval lengths are normalized by the maximum edge filtration value across the dataset.\n\nFinal output format:\n- Your program should produce a single line of output containing the boolean classification results for the five cases as a comma-separated list enclosed in square brackets (e.g., \"[True,False,False,False,True]\") with no spaces.",
            "solution": "The problem requires the development and implementation of a computational pipeline to determine if a given neural population activity dataset, represented as a point cloud, possesses an underlying toroidal topology. This decision is to be made using methods from Topological Data Analysis (TDA), specifically Persistent Homology (PH). The solution proceeds in a sequence of well-defined steps: data generation, construction of a simplicial complex filtration, computation of persistence intervals for 1-dimensional homology ($H_1$), and a final classification based on the characteristics of these intervals.\n\n### Step 1: Data Generation and Standardization\n\nThe foundation of the problem lies in a generative model of neural activity. A set of $N$ data points is sampled from a latent manifold, which may be a 2-torus $\\mathbb{T}^2$, a circle $S^1$, a cylinder $S^1 \\times [0,1]$, or a trivial point space (for the random cloud). This latent structure is then embedded into a high-dimensional Euclidean space $\\mathbb{R}^M$ (representing the activity of $M$ neurons) via a feature map $u$, a linear transformation $W$, and the addition of Gaussian noise $\\eta$. The model for a single data point $x_i \\in \\mathbb{R}^M$ is given by:\n$$ x_i = W^\\top u(\\lambda_i) + \\eta_i $$\nwhere $\\lambda_i$ represents the latent coordinates for the $i$-th sample (e.g., $\\lambda_i = (\\theta_{x,i}, \\theta_{y,i})$), $W \\in \\mathbb{R}^{8 \\times M}$ is a random projection matrix with entries drawn from $\\mathcal{N}(0,1)$, and $\\eta_i \\sim \\mathcal{N}(0, \\sigma^2 I_M)$ is isotropic Gaussian noise of variance $\\sigma^2$.\n\nThe specific feature map $u$ defines the geometry of the latent manifold. For the toroidal cases, the map is $u: \\mathbb{T}^2 \\to \\mathbb{R}^8$, defined as:\n$$\nu(\\theta_x,\\theta_y) =\n\\begin{bmatrix}\n\\cos\\theta_x, \\sin\\theta_x, \\cos\\theta_y, \\sin\\theta_y, \\cos\\theta_x\\cos\\theta_y, \\cos\\theta_x\\sin\\theta_y, \\sin\\theta_x\\cos\\theta_y, \\sin\\theta_x\\sin\\theta_y\n\\end{bmatrix}^\\top\n$$\nThis is a classic embedding of the 2-torus into $\\mathbb{R}^8$. The other manifold types (circle, cylinder) are generated using variations of this model as specified, altering the latent variables or the feature map $u$ itself. The random cloud case bypasses the latent model, generating points directly in $\\mathbb{R}^M$.\n\nAfter generating the $N \\times M$ data matrix $X$, a crucial preprocessing step is per-neuron standardization. For each column (neuron) of $X$, its mean is subtracted and the result is divided by its standard deviation. This ensures that each neuron contributes equally to the geometric structure of the point cloud, making the subsequent pairwise distance computations invariant to the idiosyncratic firing rates and dynamic ranges of individual neurons.\n\n### Step 2: Vietoris-Rips Filtration Construction\n\nWith the standardized point cloud $\\{x_i\\}_{i=1}^N \\subset \\mathbb{R}^M$, we study its shape by constructing a Vietoris-Rips (VR) filtration. The VR complex, $\\text{VR}(X, \\epsilon)$, at a scale $\\epsilon \\ge 0$ is a simplicial complex whose vertices are the points in $X$. A set of $k+1$ vertices forms a $k$-simplex if the Euclidean distance between any two vertices in the set is at most $\\epsilon$. As $\\epsilon$ increases from $0$ to infinity, we obtain a nested sequence of complexes, which is the filtration:\n$$ \\text{VR}(X, \\epsilon_1) \\subseteq \\text{VR}(X, \\epsilon_2) \\quad \\text{for} \\quad \\epsilon_1 \\le \\epsilon_2 $$\nFor our purpose, we only need to construct this filtration up to 2-simplices (triangles). The filtration value, or \"birth time,\" of each simplex is defined as:\n- A vertex $v_i$ (0-simplex) has a filtration value of $0$.\n- An edge $(v_i, v_j)$ (1-simplex) has a filtration value equal to the distance $d_{ij} = \\|x_i - x_j\\|_2$.\n- A triangle $(v_i, v_j, v_k)$ (2-simplex) has a filtration value of $\\max(d_{ij}, d_{ik}, d_{jk})$.\n\nTo implement the PH algorithm, all edges and triangles are generated and stored in a single list, sorted primarily by their filtration value and secondarily by their dimension.\n\n### Step 3: Persistent Homology ($H_1$) Calculation\n\nPersistent Homology tracks the \"lifetime\" of topological features, such as connected components ($H_0$), loops ($H_1$), and voids ($H_2$), across the filtration. A feature is \"born\" when it first appears and \"dies\" when it is filled in by higher-dimensional simplices. The persistence of a feature is the difference between its death and birth times. For this problem, we are interested in $H_1$, which captures loops. The expected Betti numbers for a 2-torus are $\\beta_0=1$, $\\beta_1=2$, and $\\beta_2=1$, so we anticipate finding two highly persistent 1-cycles.\n\nThe computation of persistence intervals for $H_1$ is performed using the standard matrix reduction algorithm over the field of two elements, $\\mathbb{Z}_2$. This algorithm operates on the boundary matrix of the simplicial complex. For $H_1$, we are concerned with the boundary map $\\partial_2: C_2 \\to C_1$, where $C_k$ is the vector space over $\\mathbb{Z}_2$ with a basis given by the $k$-simplices. An $H_1$ feature (a 1-cycle) is an element of $\\ker \\partial_1$ that is not in $\\text{im } \\partial_2$.\n\nThe algorithm proceeds as follows:\n1.  Let the sorted list of 1- and 2-simplices be $\\sigma_1, \\sigma_2, \\dots, \\sigma_K$.\n2.  Maintain a map of pivots, where a pivot is the simplex with the highest index in the boundary of another simplex.\n3.  Iterate through the sorted simplices $\\sigma_j$. We are primarily interested when $\\sigma_j$ is a 2-simplex (a triangle).\n4.  For each triangle $\\sigma_j$, compute its boundary $\\partial \\sigma_j$, which consists of three edges. This boundary is represented as a column vector in the boundary matrix.\n5.  This column is reduced by adding (XORing in $\\mathbb{Z}_2$) columns of other triangles that have already been processed and claim the same pivot. Let $\\text{low}(c)$ be the highest-indexed simplex in a boundary chain $c$. The reduction rule is: while the current column $c_j$ is not zero and $\\text{low}(c_j)$ is already the pivot of a previously processed column $c_i$, set $c_j \\leftarrow c_j + c_i$.\n6.  After reduction, if the column $c_j$ is non-zero, its pivot $\\text{low}(c_j) = \\sigma_p$ is an edge. This establishes a persistence pairing $(\\sigma_p, \\sigma_j)$. The 1-cycle born when the edge $\\sigma_p$ was added is now killed by the triangle $\\sigma_j$. The persistence interval is $[\\text{filtration}(\\sigma_p), \\text{filtration}(\\sigma_j)]$.\n7.  If an edge is never chosen as a pivot for any triangle column reduction, it contributes to a 1-cycle that persists indefinitely within the scope of the 2-skeleton (i.e., it is never filled by a triangle).\n\nThis procedure yields a set of persistence intervals for $H_1$, corresponding to the lifetimes of the loops in the data.\n\n### Step 4: Classification Logic\n\nThe final step is to classify the dataset as toroidal or not, based on the computed $H_1$ persistence intervals. A dataset is deemed toroidal if its topological signature is consistent with that of a 2-torus, which is characterized by two prominent, independent 1-cycles. The specific decision rule is:\n\n1.  Calculate the lengths of all finite $H_1$ persistence intervals: $L_k = \\text{death}_k - \\text{birth}_k$.\n2.  Normalize these lengths by the maximum filtration value of any edge in the complex, $L_{\\text{norm}, k} = L_k / \\max(d_{ij})$. This makes the criterion scale-invariant.\n3.  The dataset is classified as **True** (toroidal) if and only if:\n    a. There are at least two persistence intervals with normalized length greater than the threshold $\\tau=0.20$.\n    b. The ratio of the lengths of the two most persistent intervals (say $L_1 \\geq L_2$) is within a factor of 2, i.e., $L_1 / L_2 \\le 2$.\n\nThis rule ensures that we detect two significant loops of comparable scale, as expected from the two generator cycles of a well-formed torus, while rejecting structures like a single circle or cylinder ($\\beta_1=1$) or a wedge of two circles with vastly different radii.\n\nBased on topological first principles, we expect the following outcomes:\n-   **Case A (Torus)**: $\\beta_1=2$. Expected: **True**.\n-   **Case B (Circle)**: $\\beta_1=1$. Expected: **False**.\n-   **Case C (Random Cloud)**: $\\beta_1=0$. Expected: **False**.\n-   **Case D (Cylinder)**: Homotopy equivalent to a circle, $\\beta_1=1$. Expected: **False**.\n-   **Case E (Noisy Torus)**: $\\beta_1=2$, but features may be obscured by noise. The outcome will test the robustness of the method. Given the increased noise, it may fail to meet the persistence threshold, possibly resulting in **False**.\n\nThe implementation will now execute this entire pipeline for each of the five test cases.",
            "answer": "```python\nimport numpy as np\nfrom scipy.spatial.distance import pdist, squareform\nfrom itertools import combinations\n\ndef solve():\n    \"\"\"\n    Main function to run the full TDA pipeline on all test cases.\n    \"\"\"\n    RNG = np.random.default_rng(seed=42)\n\n    def generate_data(N, M, sigma, case_type, *, rng_instance):\n        \"\"\"Generates synthetic neural data for a given case.\"\"\"\n        W = rng_instance.normal(size=(8, M))\n        \n        if case_type == 'torus':\n            theta_x = rng_instance.uniform(0, 2 * np.pi, N)\n            theta_y = rng_instance.uniform(0, 2 * np.pi, N)\n            u = np.vstack([\n                np.cos(theta_x), np.sin(theta_x),\n                np.cos(theta_y), np.sin(theta_y),\n                np.cos(theta_x) * np.cos(theta_y), np.cos(theta_x) * np.sin(theta_y),\n                np.sin(theta_x) * np.cos(theta_y), np.sin(theta_x) * np.sin(theta_y)\n            ])\n            X = u.T @ W\n\n        elif case_type == 'circle':\n            theta_x = rng_instance.uniform(0, 2 * np.pi, N)\n            theta_y = np.zeros(N)\n            u = np.vstack([\n                np.cos(theta_x), np.sin(theta_x),\n                np.cos(theta_y), np.sin(theta_y),\n                np.cos(theta_x) * np.cos(theta_y), np.cos(theta_x) * np.sin(theta_y),\n                np.sin(theta_x) * np.cos(theta_y), np.sin(theta_x) * np.sin(theta_y)\n            ])\n            X = u.T @ W\n\n        elif case_type == 'cloud':\n            X = rng_instance.normal(size=(N, M))\n        \n        elif case_type == 'cylinder':\n            theta_x = rng_instance.uniform(0, 2 * np.pi, N)\n            y = rng_instance.uniform(0, 1, N)\n            u_cyl = np.vstack([\n                np.cos(theta_x), np.sin(theta_x), y,\n                np.cos(theta_x) * y, np.sin(theta_x) * y,\n                y**2, np.cos(theta_x) * y**2, np.sin(theta_x) * y**2\n            ])\n            X = u_cyl.T @ W\n        else:\n            raise ValueError(\"Unknown case type\")\n\n        if case_type != 'cloud':\n            eta = rng_instance.normal(0, sigma, size=(N, M))\n            X += eta\n\n        # Per-neuron standardization\n        mean = np.mean(X, axis=0)\n        std = np.std(X, axis=0)\n        # Avoid division by zero for constant neurons, though unlikely here.\n        std[std == 0] = 1.0 \n        X_std = (X - mean) / std\n        \n        return X_std\n\n    def compute_h1_persistence(X):\n        \"\"\"Computes H1 persistence intervals for a point cloud X.\"\"\"\n        N = X.shape[0]\n        dist_matrix = squareform(pdist(X, 'euclidean'))\n        \n        # Create sorted list of simplices (edges and triangles)\n        edges = []\n        for i, j in combinations(range(N), 2):\n            edges.append({'val': dist_matrix[i, j], 'dim': 1, 'v': frozenset({i, j})})\n\n        max_edge_dist = 0\n        if edges:\n            max_edge_dist = max(e['val'] for e in edges)\n\n        triangles = []\n        for i, j, k in combinations(range(N), 3):\n            val = max(dist_matrix[i, j], dist_matrix[i, k], dist_matrix[j, k])\n            triangles.append({'val': val, 'dim': 2, 'v': frozenset({i, j, k})})\n            \n        simplices = sorted(edges + triangles, key=lambda s: (s['val'], s['dim']))\n        \n        simplex_to_idx = {s['v']: i for i, s in enumerate(simplices)}\n        \n        # Precompute boundaries for triangles\n        boundaries = {}\n        for idx, s in enumerate(simplices):\n            if s['dim'] == 2:\n                i, j, k = tuple(s['v'])\n                b = [\n                    simplex_to_idx[frozenset({i, j})],\n                    simplex_to_idx[frozenset({i, k})],\n                    simplex_to_idx[frozenset({j, k})]\n                ]\n                boundaries[idx] = set(b)\n\n        # Standard persistence algorithm with column reduction\n        pivots = {} # pivot_idx -> col_idx that owns it\n        reduced_cols = {} # col_idx -> its reduced boundary set\n        \n        for j, simplex in enumerate(simplices):\n            if simplex['dim'] != 2:\n                continue\n\n            col = boundaries[j].copy()\n            \n            while col:\n                pivot = max(col)\n                if pivot not in pivots:\n                    pivots[pivot] = j\n                    reduced_cols[j] = col\n                    break\n                else:\n                    owner_col_idx = pivots[pivot]\n                    col.symmetric_difference_update(reduced_cols[owner_col_idx])\n        \n        # Extract H1 persistence intervals\n        h1_intervals = []\n        for edge_idx, tri_idx in pivots.items():\n            birth_simplex = simplices[edge_idx]\n            death_simplex = simplices[tri_idx]\n            \n            if birth_simplex['dim'] == 1 and death_simplex['dim'] == 2:\n                birth = birth_simplex['val']\n                death = death_simplex['val']\n                if death > birth:\n                    h1_intervals.append((birth, death))\n                    \n        return h1_intervals, max_edge_dist\n\n    def classify_toroidal(h1_intervals, max_edge_dist, tau):\n        \"\"\"Applies the decision rule to classify the dataset.\"\"\"\n        if not h1_intervals or max_edge_dist == 0:\n            return False\n\n        lengths = [death - birth for birth, death in h1_intervals]\n        norm_lengths = sorted([l / max_edge_dist for l in lengths], reverse=True)\n        \n        if len(norm_lengths)  2:\n            return False\n\n        l1, l2 = norm_lengths[0], norm_lengths[1]\n\n        if l1 > tau and l2 > tau and (l1 / l2) = 2.0:\n            return True\n        else:\n            return False\n\n    test_cases = [\n        {'N': 48, 'M': 64, 'sigma': 0.10, 'type': 'torus'},\n        {'N': 48, 'M': 64, 'sigma': 0.10, 'type': 'circle'},\n        {'N': 48, 'M': 64, 'sigma': 0.10, 'type': 'cloud'},\n        {'N': 48, 'M': 64, 'sigma': 0.10, 'type': 'cylinder'},\n        {'N': 48, 'M': 64, 'sigma': 0.30, 'type': 'torus'},\n    ]\n    \n    tau = 0.20\n    results = []\n\n    for case in test_cases:\n        data = generate_data(case['N'], case['M'], case['sigma'], case['type'], rng_instance=RNG)\n        intervals, max_dist = compute_h1_persistence(data)\n        is_toroidal = classify_toroidal(intervals, max_dist, tau)\n        results.append(is_toroidal)\n    \n    # Format output as required\n    result_str = \",\".join(map(str, results))\n    print(f\"[{result_str}]\")\n\nsolve()\n```"
        }
    ]
}