{
    "hands_on_practices": [
        {
            "introduction": "A simple Poisson process assumes a neuron can fire at any moment, which is biologically unrealistic due to the refractory period that follows a spike. This exercise  provides hands-on practice in building a more plausible model by constructing the interspike interval distribution from a hazard function that explicitly includes an absolute refractory period. Mastering this derivation is a key step in translating biophysical constraints into mathematically tractable renewal process models.",
            "id": "4014967",
            "problem": "A neuron is modeled as a renewal process in which the conditional intensity (hazard) function for the interspike interval is piecewise-constant with an absolute refractory period. Specifically, the hazard is given by $h(t)=0$ for $td$ and $h(t)=\\alpha$ for $t \\ge d$, where $d0$ represents a refractory duration and $\\alpha0$ is a constant rate parameter. Starting from the definition of the hazard for a renewal process and the standard relationships among the hazard, survival function, and probability density function, derive the interspike interval probability density function $f_{T}(t)$ for all $t \\ge 0$ and compute the mean interspike interval $\\mathbb{E}[T]$. Express the mean interspike interval in seconds. Provide your final answer as two expressions: first the closed-form $f_{T}(t)$, and second the scalar $\\mathbb{E}[T]$. Do not provide intermediate steps in the final answer.",
            "solution": "The solution proceeds by first deriving the interspike interval (ISI) probability density function $f_{T}(t)$ from the given hazard function $h(t)$, and then calculating the mean ISI, $\\mathbb{E}[T]$.\n\nThe fundamental relationship between the hazard function $h(t)$, the survival function $S(t) = P(T > t)$, and the probability density function $f_T(t)$ for a continuous random variable $T \\ge 0$ is given by:\n$$S(t) = \\exp\\left(-\\int_0^t h(\\tau) \\, d\\tau\\right)$$\nand\n$$f_T(t) = h(t) S(t)$$\n\nThe hazard function is given as a piecewise function:\n$$h(t) = \\begin{cases} 0  \\text{for } t  d \\\\ \\alpha  \\text{for } t \\ge d \\end{cases}$$\nwhere $d  0$ and $\\alpha  0$.\n\nFirst, we calculate the cumulative hazard, $H(t) = \\int_0^t h(\\tau) \\, d\\tau$. We must evaluate this integral piecewise.\n\nCase 1: $0 \\le t  d$\nIn this interval, $h(\\tau) = 0$ for all $\\tau \\in [0, t)$.\n$$H(t) = \\int_0^t h(\\tau) \\, d\\tau = \\int_0^t 0 \\, d\\tau = 0$$\n\nCase 2: $t \\ge d$\nThe integral must be split at the point of discontinuity, $d$.\n$$H(t) = \\int_0^t h(\\tau) \\, d\\tau = \\int_0^d h(\\tau) \\, d\\tau + \\int_d^t h(\\tau) \\, d\\tau$$\n$$H(t) = \\int_0^d 0 \\, d\\tau + \\int_d^t \\alpha \\, d\\tau = 0 + \\alpha[\\tau]_d^t = \\alpha(t-d)$$\n\nNow, we can find the survival function $S(t) = \\exp(-H(t))$.\n\nFor $0 \\le t  d$:\n$$S(t) = \\exp(-0) = 1$$\nThis result is logical: the probability of the neuron not spiking before the end of the absolute refractory period $d$ is $1$.\n\nFor $t \\ge d$:\n$$S(t) = \\exp(-\\alpha(t-d))$$\n\nCombining these, the survival function is:\n$$S(t) = \\begin{cases} 1  \\text{for } 0 \\le t  d \\\\ \\exp(-\\alpha(t-d))  \\text{for } t \\ge d \\end{cases}$$\n\nNext, we derive the probability density function $f_T(t)$ using the relation $f_T(t) = h(t)S(t)$.\n\nFor $0 \\le t  d$:\n$$f_T(t) = h(t)S(t) = 0 \\cdot 1 = 0$$\nThis is also logical, as the probability density of a spike occurring during the absolute refractory period is zero.\n\nFor $t \\ge d$:\n$$f_T(t) = h(t)S(t) = \\alpha \\exp(-\\alpha(t-d))$$\n\nTherefore, the complete ISI probability density function is:\n$$f_T(t) = \\begin{cases} 0  \\text{for } t  d \\\\ \\alpha \\exp(-\\alpha(t-d))  \\text{for } t \\ge d \\end{cases}$$\nThis is the probability density function of a shifted exponential distribution.\n\nFinally, we compute the mean interspike interval, $\\mathbb{E}[T]$. The mean can be calculated by integrating the survival function over its domain:\n$$\\mathbb{E}[T] = \\int_0^\\infty S(t) \\, dt$$\nWe split the integral at $t=d$:\n$$\\mathbb{E}[T] = \\int_0^d S(t) \\, dt + \\int_d^\\infty S(t) \\, dt$$\nSubstituting the expressions for $S(t)$:\n$$\\mathbb{E}[T] = \\int_0^d 1 \\, dt + \\int_d^\\infty \\exp(-\\alpha(t-d)) \\, dt$$\nThe first integral is straightforward:\n$$\\int_0^d 1 \\, dt = [t]_0^d = d$$\nFor the second integral, we can use the substitution $u = t-d$, which implies $du = dt$. The limits of integration change from $t=d \\rightarrow u=0$ and $t \\to \\infty \\rightarrow u \\to \\infty$.\n$$\\int_d^\\infty \\exp(-\\alpha(t-d)) \\, dt = \\int_0^\\infty \\exp(-\\alpha u) \\, du$$\nThis is the integral of the kernel of an exponential distribution.\n$$\\int_0^\\infty \\exp(-\\alpha u) \\, du = \\left[-\\frac{1}{\\alpha}\\exp(-\\alpha u)\\right]_0^\\infty = \\left( \\lim_{u\\to\\infty} -\\frac{1}{\\alpha}\\exp(-\\alpha u) \\right) - \\left(-\\frac{1}{\\alpha}\\exp(0)\\right) = 0 - \\left(-\\frac{1}{\\alpha}\\right) = \\frac{1}{\\alpha}$$\nCombining the results of the two integrals gives the mean ISI:\n$$\\mathbb{E}[T] = d + \\frac{1}{\\alpha}$$\nThis result is intuitive: the mean ISI is the sum of the fixed refractory duration $d$ and the mean interval of the subsequent Poisson process, which is $1/\\alpha$. To express the mean ISI in units of seconds, as requested, the parameter $d$ must be given in seconds and the rate parameter $\\alpha$ must be given in inverse seconds (s$^{-1}$ or Hz).",
            "answer": "$$\\boxed{\\begin{pmatrix} \\begin{cases} 0  t  d \\\\ \\alpha \\exp(-\\alpha (t-d))  t \\ge d \\end{cases}  d + \\frac{1}{\\alpha} \\end{pmatrix}}$$"
        },
        {
            "introduction": "While the model with a simple refractory period is an improvement, real spike trains often exhibit more complex variability than a shifted exponential distribution can capture. This practice  introduces the versatile Gamma distribution as a model for inter-spike intervals and guides you through deriving the equations for fitting its parameters using Maximum Likelihood Estimation. This exercise demonstrates how to handle more flexible models and introduces the common scenario where parameter estimation requires numerical methods.",
            "id": "4014931",
            "problem": "Consider a renewal process model for a single neuron's spike train in which the inter-spike intervals (ISIs) are independent and identically distributed according to a Gamma distribution with shape parameter $k0$ and scale parameter $\\theta0$. You observe $n$ complete inter-spike intervals $\\{x_{i}\\}_{i=1}^{n}$ from a long recording during which stationarity holds. Assume no censoring and ignore edge effects. Let $\\Gamma(\\cdot)$ denote the Gamma function, and let $\\psi(\\cdot)$ denote the digamma function, defined as $\\psi(k) = \\frac{d}{dk}\\ln\\Gamma(k)$.\n\nTasks:\n- Starting from the independence of inter-spike intervals and the Gamma probability density function $f(x \\mid k,\\theta)$, derive the log-likelihood $\\ell(k,\\theta;\\mathbf{x})$ for the observed inter-spike intervals $\\mathbf{x}=(x_{1},\\dots,x_{n})$.\n- Compute the components of the score vector, $\\frac{\\partial \\ell}{\\partial k}$ and $\\frac{\\partial \\ell}{\\partial \\theta}$, and set them equal to zero to obtain the maximum likelihood estimation (MLE) equations for $k$ and $\\theta$. Express $\\theta$ explicitly as a function of $k$ and the data, and reduce the $k$-equation to an implicit scalar equation in $k$ that highlights the role of the digamma function.\n- Define the sample mean $\\bar{x}=\\frac{1}{n}\\sum_{i=1}^{n}x_{i}$ and the sample mean of logarithms $m_{\\ln}=\\frac{1}{n}\\sum_{i=1}^{n}\\ln x_{i}$, and show that the $k$-equation can be written in terms of $\\psi(k)$, $\\ln k$, $\\bar{x}$, and $m_{\\ln}$.\n\nAnswer specification:\n- Your final boxed answer must be a single row matrix with three entries, in this order: the log-likelihood $\\ell(k,\\theta;\\mathbf{x})$ as a single analytic expression; the score component with respect to $k$ written as a single analytic expression (do not include an equality); and the score component with respect to $\\theta$ written as a single analytic expression (do not include an equality).\n- Do not include any equations or inequalities in the final boxed answer; write only the expressions. No numerical approximation or units are required.",
            "solution": "The probability density function (PDF) of a Gamma distribution with shape parameter $k$ and scale parameter $\\theta$ is given by:\n$$f(x \\mid k, \\theta) = \\frac{x^{k-1} \\exp(-x/\\theta)}{\\Gamma(k) \\theta^k}$$\nfor $x  0$, $k  0$, and $\\theta  0$.\n\n**Task 1: Derive the log-likelihood $\\ell(k, \\theta; \\mathbf{x})$**\n\nSince the inter-spike intervals $\\{x_i\\}_{i=1}^n$ are independent and identically distributed, the likelihood function $L(k, \\theta; \\mathbf{x})$ is the product of the individual PDFs:\n$$L(k, \\theta; \\mathbf{x}) = \\prod_{i=1}^{n} f(x_i \\mid k, \\theta) = \\prod_{i=1}^{n} \\left( \\frac{x_i^{k-1} \\exp(-x_i/\\theta)}{\\Gamma(k) \\theta^k} \\right)$$\nThe log-likelihood, $\\ell(k, \\theta; \\mathbf{x})$, is the natural logarithm of the likelihood function:\n$$\\ell(k, \\theta; \\mathbf{x}) = \\ln(L(k, \\theta; \\mathbf{x})) = \\ln \\left( \\prod_{i=1}^{n} \\frac{x_i^{k-1} \\exp(-x_i/\\theta)}{\\Gamma(k) \\theta^k} \\right)$$\nUsing the properties of logarithms, we can write this as a sum:\n$$\\ell(k, \\theta; \\mathbf{x}) = \\sum_{i=1}^{n} \\ln \\left( \\frac{x_i^{k-1} \\exp(-x_i/\\theta)}{\\Gamma(k) \\theta^k} \\right)$$\n$$\\ell(k, \\theta; \\mathbf{x}) = \\sum_{i=1}^{n} \\left[ \\ln(x_i^{k-1}) + \\ln(\\exp(-x_i/\\theta)) - \\ln(\\Gamma(k) \\theta^k) \\right]$$\n$$\\ell(k, \\theta; \\mathbf{x}) = \\sum_{i=1}^{n} \\left[ (k-1)\\ln x_i - \\frac{x_i}{\\theta} - \\ln\\Gamma(k) - k\\ln\\theta \\right]$$\nWe can separate the summation over the terms:\n$$\\ell(k, \\theta; \\mathbf{x}) = (k-1)\\sum_{i=1}^{n}\\ln x_i - \\frac{1}{\\theta}\\sum_{i=1}^{n}x_i - n\\ln\\Gamma(k) - nk\\ln\\theta$$\nThis is the log-likelihood function.\n\n**Task 2: Compute the score components and derive the MLE equations**\n\nThe score vector consists of the partial derivatives of the log-likelihood with respect to the parameters $k$ and $\\theta$.\n\n- **Component with respect to $k$**:\n$$\\frac{\\partial \\ell}{\\partial k} = \\frac{\\partial}{\\partial k} \\left( (k-1)\\sum_{i=1}^{n}\\ln x_i - \\frac{1}{\\theta}\\sum_{i=1}^{n}x_i - n\\ln\\Gamma(k) - nk\\ln\\theta \\right)$$\n$$\\frac{\\partial \\ell}{\\partial k} = \\sum_{i=1}^{n}\\ln x_i - 0 - n\\frac{d}{dk}\\ln\\Gamma(k) - n\\ln\\theta$$\nUsing the definition of the digamma function, $\\psi(k) = \\frac{d}{dk}\\ln\\Gamma(k)$:\n$$\\frac{\\partial \\ell}{\\partial k} = \\sum_{i=1}^{n}\\ln x_i - n\\psi(k) - n\\ln\\theta$$\n\n- **Component with respect to $\\theta$**:\n$$\\frac{\\partial \\ell}{\\partial \\theta} = \\frac{\\partial}{\\partial \\theta} \\left( (k-1)\\sum_{i=1}^{n}\\ln x_i - \\frac{1}{\\theta}\\sum_{i=1}^{n}x_i - n\\ln\\Gamma(k) - nk\\ln\\theta \\right)$$\n$$\\frac{\\partial \\ell}{\\partial \\theta} = 0 - \\left(\\sum_{i=1}^{n}x_i\\right)\\left(-\\frac{1}{\\theta^2}\\right) - 0 - nk\\left(\\frac{1}{\\theta}\\right)$$\n$$\\frac{\\partial \\ell}{\\partial \\theta} = \\frac{1}{\\theta^2}\\sum_{i=1}^{n}x_i - \\frac{nk}{\\theta}$$\n\nTo find the MLE estimates, we set these partial derivatives to zero. Let $\\hat{k}$ and $\\hat{\\theta}$ be the MLEs.\n1.  $\\frac{\\partial \\ell}{\\partial \\theta} = 0 \\implies \\frac{1}{\\hat{\\theta}^2}\\sum_{i=1}^{n}x_i - \\frac{n\\hat{k}}{\\hat{\\theta}} = 0$\n2.  $\\frac{\\partial \\ell}{\\partial k} = 0 \\implies \\sum_{i=1}^{n}\\ln x_i - n\\psi(\\hat{k}) - n\\ln\\hat{\\theta} = 0$\n\nFrom equation (1), we can solve for $\\hat{\\theta}$:\n$$\\frac{1}{\\hat{\\theta}^2}\\sum_{i=1}^{n}x_i = \\frac{n\\hat{k}}{\\hat{\\theta}}$$\n$$\\sum_{i=1}^{n}x_i = n\\hat{k}\\hat{\\theta}$$\n$$\\hat{\\theta} = \\frac{\\sum_{i=1}^{n}x_i}{n\\hat{k}} = \\frac{\\bar{x}}{\\hat{k}}$$\nwhere $\\bar{x} = \\frac{1}{n}\\sum_{i=1}^{n}x_i$ is the sample mean.\n\nNext, we substitute this expression for $\\hat{\\theta}$ into equation (2):\n$$\\sum_{i=1}^{n}\\ln x_i - n\\psi(\\hat{k}) - n\\ln\\left(\\frac{\\bar{x}}{\\hat{k}}\\right) = 0$$\nDividing by $n$:\n$$\\frac{1}{n}\\sum_{i=1}^{n}\\ln x_i - \\psi(\\hat{k}) - \\ln\\left(\\frac{\\bar{x}}{\\hat{k}}\\right) = 0$$\n$$\\frac{1}{n}\\sum_{i=1}^{n}\\ln x_i - \\psi(\\hat{k}) - (\\ln\\bar{x} - \\ln\\hat{k}) = 0$$\nRearranging the terms gives the implicit equation for $\\hat{k}$:\n$$\\ln\\hat{k} - \\psi(\\hat{k}) = \\ln\\bar{x} - \\frac{1}{n}\\sum_{i=1}^{n}\\ln x_i$$\n\n**Task 3: Rewrite the k-equation**\n\nUsing the definitions for the sample mean $\\bar{x}$ and the sample mean of logarithms $m_{\\ln}$:\n$$\\bar{x} = \\frac{1}{n}\\sum_{i=1}^{n}x_i$$\n$$m_{\\ln} = \\frac{1}{n}\\sum_{i=1}^{n}\\ln x_i$$\nThe implicit equation for $\\hat{k}$ becomes:\n$$\\ln\\hat{k} - \\psi(\\hat{k}) = \\ln(\\bar{x}) - m_{\\ln}$$\nThis successfully expresses the equation for $\\hat{k}$ in the required terms.\n\nThe final answer requires the three expressions: $\\ell(k, \\theta; \\mathbf{x})$, $\\frac{\\partial \\ell}{\\partial k}$, and $\\frac{\\partial \\ell}{\\partial \\theta}$. Based on the derivations above, these are:\n1.  $\\ell(k, \\theta; \\mathbf{x}) = (k-1)\\sum_{i=1}^{n}\\ln x_i - \\frac{1}{\\theta}\\sum_{i=1}^{n}x_i - n\\ln\\Gamma(k) - nk\\ln\\theta$\n2.  $\\frac{\\partial \\ell}{\\partial k} = \\sum_{i=1}^{n}\\ln x_i - n\\psi(k) - n\\ln\\theta$\n3.  $\\frac{\\partial \\ell}{\\partial \\theta} = \\frac{1}{\\theta^2}\\sum_{i=1}^{n}x_i - \\frac{nk}{\\theta}$\nThese expressions will be formatted into a single row matrix as requested.",
            "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n(k-1) \\sum_{i=1}^{n} \\ln x_{i} - \\frac{1}{\\theta} \\sum_{i=1}^{n} x_{i} - n \\ln \\Gamma(k) - n k \\ln \\theta  \\sum_{i=1}^{n} \\ln x_{i} - n \\psi(k) - n \\ln \\theta  \\frac{1}{\\theta^{2}} \\sum_{i=1}^{n} x_{i} - \\frac{nk}{\\theta}\n\\end{pmatrix}\n}\n$$"
        },
        {
            "introduction": "Having formulated different models, how do we decide which one best describes our data? This advanced practice  tackles this crucial question of model selection by guiding you through the implementation of a statistical test to distinguish a general modulated renewal process from a simpler inhomogeneous Poisson process. You will apply the powerful time-rescaling theorem and a likelihood ratio test, integrating simulation and statistical theory to perform a rigorous model comparisonâ€”a core skill for any computational neuroscientist.",
            "id": "4014995",
            "problem": "Consider a doubly-stochastic spiking model in continuous time where the instantaneous rate (intensity) is a known, strictly positive function $\\lambda(t)$ on an interval $[0,T]$. A renewal process is defined by independent, identically distributed inter-spike intervals drawn from a base distribution in a rescaled time. An inhomogeneous Poisson process is the special case of a renewal process in rescaled time where the base inter-spike intervals are exponentially distributed with unit mean.\n\nThe fundamental base for this problem is the time-rescaling theorem and the renewal definition. The time-rescaling theorem states that, for any simple point process with conditional intensity $\\lambda(t)$, the transformed inter-spike intervals $Z_i = \\int_{t_i}^{t_{i+1}} \\lambda(s) \\, ds$ are independent and identically distributed as exponential random variables with unit mean if and only if the process is an inhomogeneous Poisson process. For a modulated renewal process in continuous time with base distribution $F$ in rescaled time, the $Z_i$ generated by this integral transformation are independent and identically distributed according to $F$.\n\nYour task is to propose and implement a statistical test to distinguish a modulated renewal process from an inhomogeneous Poisson process by using the distribution of rescaled inter-spike intervals conditioned on the instantaneous rate. Assume that $\\lambda(t)$ is known and equals $\\lambda(t) = \\lambda_0 \\left(1 + \\alpha \\sin(2 \\pi f t + \\phi)\\right)$ for constants $\\lambda_0  0$, $0 \\le \\alpha  1$, frequency $f  0$, and phase $\\phi \\in \\mathbb{R}$. The cumulative intensity between times $t_a$ and $t_b$ is given by\n$$\n\\int_{t_a}^{t_b} \\lambda(s) \\, ds = \\lambda_0 (t_b - t_a) - \\frac{\\lambda_0 \\alpha}{2 \\pi f} \\left[ \\cos(2 \\pi f t_b + \\phi) - \\cos(2 \\pi f t_a + \\phi) \\right].\n$$\nYou must use this relationship to simulate spike trains and to compute the rescaled inter-spike intervals.\n\nDesign a likelihood ratio test based on the following modeling assumptions:\n- Under the null hypothesis $H_0$, the process is an inhomogeneous Poisson process, and the rescaled intervals $Z_i$ are independent and identically distributed as $\\operatorname{Exp}(1)$, which is a Gamma distribution with shape parameter $k = 1$ and scale parameter $\\theta = 1$.\n- Under the alternative hypothesis $H_1$, the process is a modulated renewal process with a Gamma base distribution in rescaled time, $Z_i \\sim \\operatorname{Gamma}(k, \\theta)$ with $\\theta = 1$ fixed and unknown shape parameter $k  0$. The inhomogeneous Poisson case is the special case $k = 1$.\n\nFrom first principles, derive the likelihood ratio test statistic for $H_0: k = 1$ versus $H_1: k \\neq 1$ under $\\theta = 1$. Use the log-likelihood for the Gamma distribution with shape $k$ and scale $\\theta = 1$ applied to the rescaled intervals $\\{Z_i\\}$, and determine the maximum likelihood estimate $\\hat{k}$ by solving the score equation involving the digamma function. Use a standard large-sample approximation for the null distribution of the likelihood ratio test statistic to obtain a decision rule at significance level $\\alpha_{\\text{test}} = 0.05$.\n\nImplement a program that:\n1. Simulates spike trains by drawing independent rescaled inter-spike intervals $U_i$ from the base distribution in rescaled time (Gamma with shape $k$ and scale $1$), and then maps them to calendar time using the cumulative intensity inversion $\\int_{t_i}^{t_{i+1}} \\lambda(s) \\, ds = U_i$. Only include intervals that end before or at $T$.\n2. Computes the observed rescaled intervals $Z_i$ for the simulated spike trains using the same cumulative intensity formula; note that in this construction, $Z_i = U_i$ exactly.\n3. Computes the likelihood ratio test statistic comparing $H_0: k = 1$ versus $H_1: k \\neq 1$ using the Gamma log-likelihood with scale $1$ and the maximum likelihood estimate $\\hat{k}$ obtained by solving the score equation involving the digamma function.\n4. Outputs a boolean per test case indicating whether $H_0$ is rejected at level $0.05$.\n\nUnits and numerical conventions:\n- Time $t$ and window length $T$ are in seconds.\n- The rate $\\lambda(t)$ is in events per second.\n- The frequency $f$ is in inverse seconds.\n- The phase $\\phi$ is in radians.\n- The final boolean outputs are unitless.\n\nTest suite:\nUse the following three test cases to validate your implementation. Each test case is specified by $(\\lambda_0, \\alpha, f, \\phi, T, k)$:\n1. $(40, 0.6, 2.0, 0.0, 10.0, 1.0)$: inhomogeneous Poisson baseline (happy path).\n2. $(40, 0.6, 2.0, 0.3, 10.0, 2.5)$: modulated renewal with clear deviation from Poisson (strong alternative).\n3. $(20, 0.9, 3.0, 1.0, 8.0, 1.05)$: modulated renewal close to Poisson (near-boundary alternative).\n\nFinal output format:\nYour program should produce a single line of output containing the test decisions for the three cases as a comma-separated list enclosed in square brackets (e.g., \"[False,True,False]\"), where each boolean indicates whether the null hypothesis \"inhomogeneous Poisson\" is rejected for that test case.",
            "solution": "The problem requires the design and implementation of a statistical test to distinguish between an inhomogeneous Poisson process (IPP) and a more general modulated renewal process. The distinction is made based on a sequence of spike times observed over a duration $[0, T]$. The core of the problem lies in the time-rescaling theorem, which provides a powerful tool for analyzing such point processes.\n\n### 1. Problem Formulation and Theoretical Background\n\nA point process in continuous time can be characterized by its conditional intensity, or instantaneous rate, $\\lambda(t)$. The time-rescaling theorem states that if we define a new \"rescaled\" time $\\tau(t) = \\int_0^t \\lambda(s) ds$, the transformed spike times $\\tau_i = \\tau(t_i)$ form a stationary Poisson process with unit rate if and only if the original process $\\{t_i\\}$ is an inhomogeneous Poisson process. A direct consequence is that the rescaled inter-spike intervals (ISIs), $Z_i = \\tau(t_{i+1}) - \\tau(t_i) = \\int_{t_i}^{t_{i+1}} \\lambda(s) ds$, are independent and identically distributed (i.i.d.) random variables from an exponential distribution with unit mean, $Z_i \\sim \\operatorname{Exp}(1)$.\n\nFor a general modulated renewal process, the rescaled ISIs $Z_i$ are i.i.d. draws from some base distribution $F$. The IPP is the special case where $F$ is the $\\operatorname{Exp}(1)$ distribution. The problem specifies that for the alternative hypothesis, this base distribution is a Gamma distribution.\n\nThe instantaneous rate is given by the function:\n$$\n\\lambda(t) = \\lambda_0 \\left(1 + \\alpha \\sin(2 \\pi f t + \\phi)\\right)\n$$\nwhere $\\lambda_0  0$ and $0 \\le \\alpha  1$ ensures that $\\lambda(t)  0$ for all $t$. The cumulative intensity from $t_a$ to $t_b$ is given by:\n$$\n\\int_{t_a}^{t_b} \\lambda(s) \\, ds = \\lambda_0 (t_b - t_a) - \\frac{\\lambda_0 \\alpha}{2 \\pi f} \\left[ \\cos(2 \\pi f t_b + \\phi) - \\cos(2 \\pi f t_a + \\phi) \\right]\n$$\n\n### 2. Hypothesis Testing Framework\n\nWe aim to test whether the observed spike train originates from an IPP or a more structured renewal process. This translates to a test on the distribution of the rescaled ISIs, $\\{Z_i\\}_{i=1}^N$. We formalize the hypotheses as follows:\n\n- **Null Hypothesis ($H_0$):** The process is an inhomogeneous Poisson process. The rescaled ISIs $Z_i$ are i.i.d. from an exponential distribution with unit mean, $Z_i \\sim \\operatorname{Exp}(1)$. This is equivalent to a Gamma distribution with shape parameter $k=1$ and scale parameter $\\theta=1$, i.e., $Z_i \\sim \\operatorname{Gamma}(1, 1)$.\n\n- **Alternative Hypothesis ($H_1$):** The process is a modulated renewal process with a Gamma base distribution. The rescaled ISIs $Z_i$ are i.i.d. from a Gamma distribution with an unknown shape parameter $k  0$ and fixed scale $\\theta=1$, i.e., $Z_i \\sim \\operatorname{Gamma}(k, 1)$ where $k \\neq 1$.\n\n### 3. Derivation of the Likelihood Ratio Test\n\nWe will use a generalized likelihood ratio test (LRT) to decide between $H_0$ and $H_1$.\n\n**Log-Likelihood Function:**\nThe probability density function (PDF) of a $\\operatorname{Gamma}(k, \\theta)$ distribution is:\n$$\np(z | k, \\theta) = \\frac{z^{k-1} e^{-z/\\theta}}{\\Gamma(k) \\theta^k}\n$$\nWith the scale parameter fixed at $\\theta=1$, the PDF simplifies to:\n$$\np(z | k) = \\frac{z^{k-1} e^{-z}}{\\Gamma(k)}\n$$\nFor a set of $N$ observed rescaled ISIs $\\{Z_1, \\dots, Z_N\\}$, the log-likelihood function for the shape parameter $k$ is:\n$$\n\\ell(k | \\{Z_i\\}) = \\log \\prod_{i=1}^N p(Z_i | k) = \\sum_{i=1}^N \\log p(Z_i | k)\n$$\n$$\n\\ell(k | \\{Z_i\\}) = \\sum_{i=1}^N \\left( (k-1) \\log Z_i - Z_i - \\log \\Gamma(k) \\right) = (k-1) \\sum_{i=1}^N \\log Z_i - \\sum_{i=1}^N Z_i - N \\log \\Gamma(k)\n$$\n\n**Maximum Likelihood Estimation of $k$:**\nUnder the alternative hypothesis $H_1$, the parameter $k$ is unknown. We estimate it using the maximum likelihood estimate (MLE), $\\hat{k}$, found by setting the derivative of the log-likelihood (the score) to zero:\n$$\n\\frac{\\partial \\ell}{\\partial k} = \\sum_{i=1}^N \\log Z_i - N \\frac{d}{dk} \\log \\Gamma(k) = \\sum_{i=1}^N \\log Z_i - N \\psi(k) = 0\n$$\nwhere $\\psi(k)$ is the digamma function. The score equation for $\\hat{k}$ is thus:\n$$\n\\psi(\\hat{k}) = \\frac{1}{N} \\sum_{i=1}^N \\log Z_i\n$$\nThis equation has no closed-form solution for $\\hat{k}$ and must be solved numerically.\n\n**Likelihood Ratio Test Statistic:**\nThe LRT statistic, $\\Lambda$, is defined as twice the difference between the maximum log-likelihood under $H_1$ and the log-likelihood under $H_0$:\n$$\n\\Lambda = 2 \\left( \\ell(\\hat{k}) - \\ell(1) \\right)\n$$\nLet's compute the two terms:\nThe log-likelihood under $H_1$ is evaluated at $\\hat{k}$:\n$$\n\\ell(\\hat{k}) = (\\hat{k}-1) \\sum_{i=1}^N \\log Z_i - \\sum_{i=1}^N Z_i - N \\log \\Gamma(\\hat{k})\n$$\nThe log-likelihood under $H_0$ is evaluated at $k=1$. Since $\\log \\Gamma(1) = \\log(1) = 0$:\n$$\n\\ell(1) = (1-1) \\sum_{i=1}^N \\log Z_i - \\sum_{i=1}^N Z_i - N \\log \\Gamma(1) = - \\sum_{i=1}^N Z_i\n$$\nSubstituting these into the expression for $\\Lambda$:\n$$\n\\Lambda = 2 \\left( \\left( (\\hat{k}-1) \\sum_{i=1}^N \\log Z_i - \\sum_{i=1}^N Z_i - N \\log \\Gamma(\\hat{k}) \\right) - \\left( - \\sum_{i=1}^N Z_i \\right) \\right)\n$$\n$$\n\\Lambda = 2 \\left( (\\hat{k}-1) \\sum_{i=1}^N \\log Z_i - N \\log \\Gamma(\\hat{k}) \\right)\n$$\nThis expression is used for computation.\n\n**Null Distribution and Decision Rule:**\nAccording to Wilks' theorem, for a large sample size $N$, the test statistic $\\Lambda$ under the null hypothesis $H_0$ follows a chi-squared distribution, $\\Lambda \\sim \\chi^2_\\nu$. The degrees of freedom, $\\nu$, is the difference in the number of free parameters between $H_1$ and $H_0$. Here, $H_1$ has one free parameter ($k$) and $H_0$ has zero free parameters (since $k=1$ is fixed). Thus, $\\nu=1$.\n\nThe decision rule at a significance level $\\alpha_{\\text{test}} = 0.05$ is to reject the null hypothesis $H_0$ if the observed statistic $\\Lambda_{\\text{obs}}$ exceeds the critical value $c$, where $c$ is the $1 - \\alpha_{\\text{test}} = 0.95$ quantile of the $\\chi^2_1$ distribution. Numerically, this critical value is approximately $3.841$.\n\n### 4. Implementation Strategy\n\nThe implementation proceeds in four steps for each test case:\n\n1.  **Simulate Spike Trains:**\n    Spike trains are generated by first drawing a sequence of i.i.d. rescaled ISIs, $U_i \\sim \\operatorname{Gamma}(k_{\\text{true}}, 1)$, where $k_{\\text{true}}$ is the true shape parameter for the test case. Starting with an initial time $t_0=0$, each subsequent spike time $t_{i+1}$ is found by solving the following equation for $t_{i+1}$:\n    $$\n    \\int_{t_i}^{t_{i+1}} \\lambda(s) \\, ds = U_i\n    $$\n    This is equivalent to finding the root of $C(t_{i+1}) - (C(t_i) + U_i) = 0$, where $C(t) = \\int_0^t \\lambda(s) ds$ is the cumulative intensity from time $0$. This non-linear equation is solved using a numerical root-finding algorithm. The simulation collects all intervals that end before or at the final time $T$. The set of generated variates $\\{U_i\\}$ corresponding to these intervals forms our observed data $\\{Z_i\\}$.\n\n2.  **Collect Rescaled Intervals:**\n    As noted in the problem statement, the observed rescaled intervals $Z_i$ are identical to the generated random variates $U_i$ from the simulation step. Let $N$ be the number of such intervals.\n\n3.  **Compute the LRT Statistic:**\n    a. First, the MLE $\\hat{k}$ is computed by numerically solving the score equation $\\psi(\\hat{k}) = \\frac{1}{N} \\sum_{i=1}^N \\log Z_i$ using a root-finding algorithm. The `digamma` function ($\\psi$) is available in standard scientific libraries.\n    b. The test statistic $\\Lambda = 2 ( (\\hat{k}-1) \\sum \\log Z_i - N \\log \\Gamma(\\hat{k}) )$ is then calculated using the computed $\\hat{k}$ and the observed data $\\{Z_i\\}$.\n\n4.  **Make a Decision:**\n    The calculated $\\Lambda$ is compared against the critical value from the $\\chi^2_1$ distribution for $\\alpha_{\\text{test}} = 0.05$. If $\\Lambda  3.841$, $H_0$ is rejected (output `True`); otherwise, it is not rejected (output `False`). This procedure is repeated for each test case.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.optimize import root_scalar\nfrom scipy.special import digamma, gamma\nfrom scipy.stats import chi2\n\ndef solve():\n    \"\"\"\n    Implements a likelihood ratio test to distinguish a modulated renewal process\n    from an inhomogeneous Poisson process based on simulated spike trains.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    # Each case is (lambda0, alpha, f, phi, T, k_true)\n    test_cases = [\n        (40.0, 0.6, 2.0, 0.0, 10.0, 1.0),\n        (40.0, 0.6, 2.0, 0.3, 10.0, 2.5),\n        (20.0, 0.9, 3.0, 1.0, 8.0, 1.05),\n    ]\n\n    # Set parameters for the statistical test\n    alpha_test = 0.05\n    \n    # We set a random seed to ensure the stochastic simulation is reproducible,\n    # leading to a deterministic outcome for the test cases.\n    np.random.seed(42)\n\n    results = []\n    \n    for case in test_cases:\n        lambda0, alpha_param, f, phi, T, k_true = case\n\n        # Define the cumulative intensity function C(t) = integral from 0 to t of lambda(s)ds\n        # cos_phi = cos(phi) which is constant for a given case\n        cos_phi = np.cos(phi)\n        def cum_intensity(t):\n            return lambda0 * t - (lambda0 * alpha_param / (2 * np.pi * f)) * (np.cos(2 * np.pi * f * t + phi) - cos_phi)\n\n        # 1. Simulate spike trains\n        t_current = 0.0\n        rescaled_ISIs = []\n        \n        # Pre-generate a sufficiently large number of potential ISIs\n        # Expected number of events is approx. lambda0 * T. \n        # Generate twice that to be safe.\n        num_potential_isis = int(2 * lambda0 * T)\n        if num_potential_isis  100:\n             num_potential_isis = 100 # Ensure a minimum number for low-rate cases\n        \n        U_samples = np.random.gamma(k_true, 1, size=num_potential_isis)\n        \n        for U in U_samples:\n            current_cum_intensity = cum_intensity(t_current)\n            target_cum_intensity = current_cum_intensity + U\n\n            # Function whose root gives the next spike time\n            def root_func(t_next):\n                return cum_intensity(t_next) - target_cum_intensity\n            \n            # The cumulative intensity function is monotonic, so a root finder like brentq is robust.\n            # We use a safe bracket for the root finding.\n            try:\n                # The upper bracket is set generously; the actual interval will be much smaller.\n                sol = root_scalar(root_func, bracket=[t_current, t_current + T * 2], method='brentq')\n                t_next = sol.root\n            except ValueError:\n                # Bracket might be invalid if the function is too flat, though unlikely with these params.\n                # Stop simulation if root finding fails.\n                break\n\n            if t_next = T:\n                rescaled_ISIs.append(U)\n                t_current = t_next\n            else:\n                break\n        \n        # 2. Compute observed rescaled intervals (Z_i = U_i)\n        Z = np.array(rescaled_ISIs)\n        N = len(Z)\n\n        if N  2:\n            # If fewer than 2 intervals are generated, the test is not meaningful.\n            # We do not reject the null hypothesis in this edge case.\n            results.append(False)\n            continue\n            \n        # 3. Compute the likelihood ratio test statistic\n        \n        # 3a. Find the Maximum Likelihood Estimate (MLE) for k\n        log_Z = np.log(Z)\n        log_Z_mean = np.mean(log_Z)\n\n        def score_eq(k):\n            # This is the score equation: digamma(k) - mean(log(Z)) = 0\n            return digamma(k) - log_Z_mean\n        \n        # Solve for k_hat in a reasonable range (0, infinity)\n        try:\n            sol_k = root_scalar(score_eq, bracket=[1e-6, 200], method='brentq')\n            k_hat = sol_k.root\n        except ValueError:\n            # If root finding fails (e.g., log_Z_mean is outside digamma's range for bracket)\n            results.append(False) \n            continue\n\n        # 3b. Calculate the LRT statistic Lambda\n        # Lambda = 2 * ( (k_hat - 1) * sum(log(Z_i)) - N * log(gamma(k_hat)) )\n        sum_log_Z = np.sum(log_Z)\n        log_gamma_k_hat = np.log(gamma(k_hat))\n        \n        Lambda = 2 * ((k_hat - 1) * sum_log_Z - N * log_gamma_k_hat)\n        \n        # 4. Make a decision\n        # The test statistic Lambda follows a chi-squared distribution with 1 degree of freedom under H0.\n        critical_value = chi2.ppf(1 - alpha_test, 1)\n        reject_H0 = Lambda > critical_value\n        results.append(reject_H0)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        }
    ]
}