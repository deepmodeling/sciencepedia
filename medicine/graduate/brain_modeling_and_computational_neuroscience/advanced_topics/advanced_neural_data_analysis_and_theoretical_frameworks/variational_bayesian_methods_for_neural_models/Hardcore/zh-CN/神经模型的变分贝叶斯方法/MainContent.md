## 引言
在神经科学研究中，对复杂系统的不确定性进行量化至关重要。贝叶斯方法为此提供了一个严谨的数学框架，使我们能够不仅估计模型参数，还能评估这些估计的可信度。然而，对于描述神经活动的复杂高维模型而言，精确执行[贝叶斯推断](@entry_id:146958)——即计算后验分布——往往在计算上是不可行的。这一挑战催生了对高效[近似推断](@entry_id:746496)方法的需求，而[变分贝叶斯方法](@entry_id:1133718)正是其中最强大和最流行的解决方案之一。

本文旨在系统性地介绍神经模型中的[变分贝叶斯方法](@entry_id:1133718)。您将学习到如何将一个棘手的积分问题巧妙地转化为一个优化问题。我们将分三章深入探讨：
第一章，“原理与机制”，将从[贝叶斯推断](@entry_id:146958)的根本挑战出发，详细推导[证据下界](@entry_id:634110)（ELBO）的构成，并剖析平均场近似、[重参数化技巧](@entry_id:636986)以及[摊销推断](@entry_id:1120981)等核心算法思想。
第二章，“应用与跨学科联系”，将展示这些原理如何应用于解决实际的神经科学问题，例如利用[变分自编码器](@entry_id:177996)揭示神经群体动力学，以及它如何与预测编码等理论框架产生深刻共鸣。
第三章，“动手实践”，将通过一系列编程练习，引导您亲手实现和分析[变分推断](@entry_id:634275)算法，从而将理论知识转化为实践技能。

让我们首先从[变分推断](@entry_id:634275)的基本原理与机制开始，揭示其如何为复杂的神经模型提供可行的[贝叶斯分析](@entry_id:271788)途径。

## 原理与机制

在上一章中，我们介绍了在神经模型中进行贝叶斯推断的动机：即量化参数和潜在变量的不确定性，并利用贝叶斯定律的规范性力量进行模型选择。然而，我们也指出了一个核心的实践障碍：对于大多数有趣的神经模型，精确计算后验分布 $p(\theta, z \mid D)$ 在计算上是不可行的。本章将深入探讨[变分贝叶斯方法](@entry_id:1133718)（Variational Bayesian methods），这是一种将推断问题重新表述为优化问题的强大近似框架。我们将从基本原理出发，构建[证据下界](@entry_id:634110)（ELBO）的[目标函数](@entry_id:267263)，剖析其内在机制，并探讨在计算神经科学中实现可扩展和高效推断的现代算法策略。

### [贝叶斯推断](@entry_id:146958)的理想与现实

贝叶斯推断的核心目标是利用[贝叶斯定理](@entry_id:897366)计算在给定数据 $\mathcal{D}$ 的情况下，模型参数 $\theta$（以及任何潜在变量 $z$）的 **[后验分布](@entry_id:145605)** (posterior distribution)：

$$
p(\theta \mid \mathcal{D}) = \frac{p(\mathcal{D} \mid \theta) p(\theta)}{p(\mathcal{D})}
$$

这个公式的每个组成部分都有其独特的意义。**似然** (likelihood) $p(\mathcal{D} \mid \theta)$ 描述了在给定一组特定参数 $\theta$ 的情况下，观测到我们实际数据 $\mathcal{D}$ 的概率。**先验** (prior) $p(\theta)$ 则编码了我们在看到任何数据之前关于参数可能取值的信念。它们的乘积，即分子 $p(\mathcal{D} \mid \theta) p(\theta)$，与[联合分布](@entry_id:263960) $p(\mathcal{D}, \theta)$ 成正比，代表了数据和参数的契合程度。

分母 $p(\mathcal{D})$ 被称为 **边缘[似然](@entry_id:167119)** (marginal likelihood) 或 **模型证据** (model evidence)。它通过对所有可能的参数值进行积分（或求和）来计算：

$$
p(\mathcal{D}) = \int p(\mathcal{D} \mid \theta) p(\theta) \, \mathrm{d}\theta
$$

为了使[后验分布](@entry_id:145605)成为一个合法的概率分布（即，其总积分为1），贝叶斯定理的公式必须是“良态的”（well-posed）。这意味着边缘[似然](@entry_id:167119) $p(\mathcal{D})$ 必须是一个有限且大于零的常数。以一个用于分析神经脉冲数据的[泊松模型](@entry_id:1129884)为例，假设我们将[脉冲序列](@entry_id:1132157)离散化为时间窗，其中每个时间窗的脉冲计数 $y_t$ 服从期望为 $\lambda_t(\theta)\Delta$ 的[泊松分布](@entry_id:147769)。[似然函数](@entry_id:921601)是所有时间窗概率的乘积。要使后验分布 $p(\theta \mid \mathcal{D})$ 有意义，我们必须满足一些基本的[正则性条件](@entry_id:166962)：[似然函数](@entry_id:921601)作为 $\theta$ 的函数必须是可测的，并且先验 $p(\theta)$ 必须被选择，以确保边缘似然的[积分收敛](@entry_id:139742)到一个正常数 。值得注意的是，先验不一定需要是[正常返](@entry_id:195139)的（即积分为1）；即使使用一个非[正常返](@entry_id:195139)的先验（例如，在参数空间上均匀分布），只要它与[似然函数](@entry_id:921601)的乘积是可积的，我们仍然可以得到一个正常的[后验分布](@entry_id:145605)。

模型证据 $p(\mathcal{D})$ 的作用远不止是一个[归一化常数](@entry_id:752675)。它本身就是一个极具价值的量。从定义可以看出，它是先验分布下似然的[期望值](@entry_id:150961)。这意味着它衡量了一个模型（由其先验和似然结构定义）在平均意义上生成观测数据的能力 。一个非常复杂的模型，其[先验分布](@entry_id:141376)在广阔的[参数空间](@entry_id:178581)上很弥散，可能只能将少量概率[质量分配](@entry_id:751704)给能很好解释当前数据的参数区域，从而导致较小的证据值。相反，一个更简单的模型将其先验集中在较小的区域，如果这个区域恰好能很好地拟合数据，其证据值就会更高。因此，[模型证据](@entry_id:636856)自然地体现了 **奥卡姆剃刀** (Occam's razor) 原则，它在数据拟合优度和[模型复杂度](@entry_id:145563)之间进行权衡。这使得模型证据成为[贝叶斯模型比较](@entry_id:637692)的黄金标准，通过计算两个竞争模型 $M_1$ 和 $M_2$ 的 **[贝叶斯因子](@entry_id:143567)** (Bayes factor)，即它们的证据之比 $p(\mathcal{D} \mid M_1) / p(\mathcal{D} \mid M_2)$。

然而，[模型证据](@entry_id:636856)的巨大价值也伴随着巨大的计算挑战。这个定义中的积分涉及对所有参数（可能还有高维潜在变量）的整个空间进行积分。除非在非常特殊的情况下，例如当先验和似然构成 **共轭** (conjugate) 对时（如泊松观测配上Gamma先验），这个积分才能解析地计算出来。在[计算神经科学](@entry_id:274500)中遇到的大多数模型，如具有非共轭稀疏性先验（如拉普拉斯先验）的广义线性模型（GLM），或具有[非线性](@entry_id:637147)动态的潜在[状态空间模型](@entry_id:137993)，其证据积分都是 **难解的** (intractable) 。正是这种难解性，促使我们寻找[近似推断](@entry_id:746496)的方法，而[变分推断](@entry_id:634275)正是其中最主要的方法之一。

### [变分推断](@entry_id:634275)：将推断转化为优化

[变分推断](@entry_id:634275)（Variational Inference, VI）通过一个巧妙的转变得以绕开直接计算难解的后验 $p(\theta \mid \mathcal{D})$。其核心思想是，我们不再试图直接计算 $p$，而是选择一个我们能够处理的、更简单的概率分布族（称为 **变分族** (variational family)），然后在这个族中寻找一个成员 $q(\theta)$，使其与真实的后验 $p(\theta \mid \mathcal{D})$ “最接近”。

“最接近”的度量标准是 **[KL散度](@entry_id:140001)** (Kullback-Leibler divergence)，它衡量了从一个分布 $q$ 到另一个分布 $p$ 的[信息增益](@entry_id:262008)：

$$
\mathrm{KL}(q \parallel p) = \int q(\theta) \log\frac{q(\theta)}{p(\theta \mid \mathcal{D})} \, \mathrm{d}\theta
$$

我们的目标是找到变分族中使 $\mathrm{KL}(q \parallel p)$ 最小化的分布 $q^*(\theta)$。然而，这个[目标函数](@entry_id:267263)本身就包含了我们试图避免的难解后验 $p(\theta \mid \mathcal{D})$。[变分法](@entry_id:166033)的精髓在于以下恒等式，它将模型证据的对数 $\log p(\mathcal{D})$ 分解为两项：

$$
\log p(\mathcal{D}) = \mathcal{L}(q) + \mathrm{KL}(q \parallel p(\theta \mid \mathcal{D}))
$$

其中，$\mathcal{L}(q)$ 被称为 **[证据下界](@entry_id:634110)** (Evidence Lower Bound, ELBO)：

$$
\mathcal{L}(q) = \int q(\theta) \log\frac{p(\mathcal{D}, \theta)}{q(\theta)} \, \mathrm{d}\theta = \mathbb{E}_{q(\theta)}[\log p(\mathcal{D}, \theta) - \log q(\theta)]
$$

由于KL散度总是非负的（$\mathrm{KL}(q \parallel p) \ge 0$），所以 $\mathcal{L}(q)$ 总是小于或等于对数[模型证据](@entry_id:636856) $\log p(\mathcal{D})$，这正是其“下界”名称的由来。当且仅当 $q(\theta) = p(\theta \mid \mathcal{D})$ 时，KL散度为零，此时下界等于对数证据。因此，最小化[KL散度](@entry_id:140001)等价于最大化ELBO。这个转化至关重要，因为ELBO的表达式 $\mathbb{E}_{q(\theta)}[\log p(\mathcal{D}, \theta) - \log q(\theta)]$ 只依赖于[联合分布](@entry_id:263960) $p(\mathcal{D}, \theta)$ 和变分分布 $q(\theta)$，两者通常都是可计算的。这样，我们就成功地将一个棘手的积分问题（计算 $p(\mathcal{D})$）转化为了一个（可能仍然具有挑战性，但通常更易于处理的）优化问题：在变分族中寻找最大化 $\mathcal{L}(q)$ 的 $q$。

#### KL散度的不对称性及其后果

选择最小化 $\mathrm{KL}(q \parallel p)$ 作为目标并非没有后果。KL散度的一个关键特性是其 **不对称性**，即 $\mathrm{KL}(q \parallel p) \neq \mathrm{KL}(p \parallel q)$。这种不对称性对变分近似的行为有着深刻的影响。

$\mathrm{KL}(q \parallel p)$ 的形式 $\int q \log(q/p)$ 意味着，如果存在某个区域，其中 $q(\theta)$ 具有一定的概率质量，而 $p(\theta)$ 的概率质量趋近于零，那么 $\log(q/p)$ 项会变得非常大，从而导致巨大的惩罚。为了使[KL散度](@entry_id:140001)保持较小，优化过程会强制 $q(\theta)$ 在 $p(\theta)$ 接近零的区域也必须接近零。这种行为被称为 **“零力”（zero-forcing）** 或 **“模式寻求”（mode-seeking）**。

相比之下，反向的[KL散度](@entry_id:140001) $\mathrm{KL}(p \parallel q) = \int p \log(p/q)$ 会在 $p(\theta)$ 有概率质量而 $q(\theta)$ 趋近于零的区域产生巨大惩罚。最小化这个目标会迫使 $q(\theta)$ “覆盖”所有 $p(\theta)$ 具有显著概率质量的区域，这种行为被称为 **“质量覆盖”（mass-covering）**。

在标准的[变分推断](@entry_id:634275)中，我们最小化的是“正向”的 $\mathrm{KL}(q \parallel p)$。这导致了一个系统性的偏差：变分近似倾向于找到真实后验的一个模式并紧密地拟合它，但往往会低估后验的方差，并且可能会完全忽略掉后验分布的次要模式或[重尾](@entry_id:274276)。

我们可以通过一个具体的例子来理解这一点 。假设一个神经模型中权重的真实后验 $p(w)$ 由于某种鲁棒的[似然函数](@entry_id:921601)而呈现出 **[重尾](@entry_id:274276)** (heavy-tailed) 特性，例如[柯西分布](@entry_id:266469) $p(w) \propto 1/(1+w^2)$。而我们的变分族被限制为 **轻尾** (light-tailed) 的高斯分布 $q(w) = \mathcal{N}(w; 0, \sigma^2)$。在这种情况下：
- $\mathrm{KL}(q \parallel p)$ 是 **有限的**。这意味着优化过程可以成功地找到一个高斯分布来近似[柯西分布](@entry_id:266469)的中心部分，尽管它完全无法捕捉到[柯西分布](@entry_id:266469)的重尾。优化过程会“乐于”忽略那些尾部，因为 $q(w)$ 在尾部的[概率密度](@entry_id:175496)为零，从而避免了在这些区域产生惩罚。
- $\mathrm{KL}(p \parallel q)$ 则是 **无限的**。这是因为[柯西分布](@entry_id:266469) $p(w)$ 在尾部有不可忽略的概率质量，而高斯分布 $q(w)$ 在那里的概率密度以指数级速度衰减到零。$p(w) > 0$ 而 $q(w) \to 0$ 的区域对积分的贡献会发散。

这个例子清晰地表明，[变分推断](@entry_id:634275)的“零力”特性使其在面对比变分族更复杂的真实后验（例如，多模态或[重尾](@entry_id:274276)）时，会产生一种偏向于“保守”和集中的近似。

### ELBO的剖析：重建与正则化

为了更深入地理解[变分推断](@entry_id:634275)在做什么，我们可以将ELBO进行另一种形式的分解。从 $\mathcal{L}(q) = \mathbb{E}_{q}[\log p(\mathcal{D}, z)]$（为简洁起见，我们将参数和[潜变量](@entry_id:143771)统一记为 $z$）和熵 $H(q) = -\mathbb{E}_q[\log q(z)]$ 出发，我们有：

$$
\mathcal{L}(q) = \mathbb{E}_{q}[\log p(\mathcal{D}, z)] + H(q)
$$

利用联合概率 $p(\mathcal{D}, z) = p(\mathcal{D} \mid z) p(z)$，我们可以进一步分解：

$$
\mathcal{L}(q) = \mathbb{E}_{q}[\log p(\mathcal{D} \mid z)] - \mathbb{E}_{q}[\log \frac{q(z)}{p(z)}] = \mathbb{E}_{q}[\log p(\mathcal{D} \mid z)] - \mathrm{KL}(q(z) \parallel p(z))
$$

这个分解揭示了最大化ELBO所涉及的两个核心组成部分之间的权衡：

1.  **重建项 (Reconstruction Term)**: $\mathbb{E}_{q}[\log p(\mathcal{D} \mid z)]$。这一项是数据在变分[后验分布](@entry_id:145605)下的期望[对数似然](@entry_id:273783)。它衡量了从我们关于潜变量的信念 $q(z)$ 中采样的 $z$，能够多好地“重建”或解释观测数据 $\mathcal{D}$。最大化ELBO就是要找到一个 $q(z)$，使得从它采样的[潜变量](@entry_id:143771)能让数据出现的可能性最大。

2.  **正则化项 (Regularization Term)**: $-\mathrm{KL}(q(z) \parallel p(z))$。这一项是负的KL散度，它衡量了变分后验 $q(z)$ 与先验 $p(z)$ 之间的距离。最大化ELBO等价于最小化[KL散度](@entry_id:140001) $\mathrm{KL}(q(z) \parallel p(z))$，这会惩罚那些偏离[先验信念](@entry_id:264565)太远的变分后验。因此，它起到了正则化的作用，防止模型为了拟[合数](@entry_id:263553)据而形成过于复杂或偏离先验预期的潜在表征。

这个分解在与 **预测编码** (predictive coding) 等神经理论的联系中尤为深刻 。考虑一个生成模型，其中潜在原因 $z$（例如，高级皮层的神经活动）通过一个生成函数 $f_\theta(z)$ 产生一个预测，该预测与感觉输入 $y$（例如，低级皮层的活动）进行比较。如果我们将似然建模为高斯分布 $p_\theta(y \mid z) = \mathcal{N}(y; f_\theta(z), \Sigma_y)$，那么对数似然项 $\log p_\theta(y \mid z)$ 就正比于负的、由[精度矩阵](@entry_id:264481) $\Sigma_y^{-1}$ 加权的 **预测误差** (prediction error) 的平方，即 $-(y - f_\theta(z))^\top \Sigma_y^{-1} (y - f_\theta(z))$。在这种情况下，最大化重建项就相当于最小化期望的精度加权预测误差。

同时，正则化项 $-\mathrm{KL}(q \parallel p)$ 驱使后验信念 $q(z)$ 保持接近先验 $p(z)$。如果先验 $p(z)$ 是一个简单的分布（例如，[标准正态分布](@entry_id:184509) $\mathcal{N}(0, I)$），那么这一项就体现了一个偏好简单解释的奥卡姆剃刀。它惩罚那些为了解释数据而变得过于复杂（例如，均值远离原点或方差过小）的潜在表征。

因此，最大化ELBO的过程可以被看作是大脑在解决一个推断问题：在最小化[感觉预测误差](@entry_id:1131481)（最大化重建项）和维持对世界简单、符合先验的信念（最小化与先验的[KL散度](@entry_id:140001)）这两个目标之间寻找一个平衡。

### 因子化近似：[平均场方法](@entry_id:141668)

到目前为止，我们还没有具体说明变分族 $q(z)$ 的形式。选择一个足够灵活以很好地近似真实后验，同时又足够简单以便于计算的变分族是VI的核心艺术。最常见和最简单的选择是 **平均场 (mean-field)** 近似。

平均场假设将高维[潜变量](@entry_id:143771) $z$ 的联合变分分布 $q(z)$ 因子化为一组相互独立的分布的乘积：

$$
q(z) = \prod_{i=1}^d q_i(z_i)
$$

其中 $z_i$ 是潜变量向量 $z$ 的第 $i$ 个分量（或一组分量）。这个因子化假设极大地简化了优化问题，但它也付出了巨大的代价：**它强行假设了潜变量在后验中是相互独立的** 。无论真实后验 $p(z \mid \mathcal{D})$ 中的变量之间存在多么强的相关性，[平均场近似](@entry_id:144121)都无法在其表征中捕捉到这些相关性。其[协方差矩阵](@entry_id:139155)被强制为对角阵。

我们可以精确地量化这种近似所带来的误差 。考虑一个简单的二维情况，其中真实后验是一个零均值的高斯分布，其[协方差矩阵](@entry_id:139155)为 $\Sigma = \begin{pmatrix} 1  \rho \\ \rho  1 \end{pmatrix}$，表示两个变量之间存在相关性 $\rho$。可以证明，最优的平均场近似 $q^\star(z) = q_1^\star(z_1)q_2^\star(z_2)$ 是一个协方差为零的高斯分布，其每个分量的均值为0，方差为1。换句话说，它只匹配了真实后验的边缘分布，但完全忽略了它们之间的相关性。

在这种情况下，近似 $q^\star$ 与真实后验 $p$ 之间的[KL散度](@entry_id:140001)可以被解析地计算出来，结果为：

$$
\mathrm{KL}(q^\star \parallel p) = -\frac{1}{2} \ln(1 - \rho^2)
$$

这个简洁的公式优美地展示了[平均场近似](@entry_id:144121)的局限性。当真实相关性 $\rho = 0$ 时，[KL散度](@entry_id:140001)为0，因为此时平均场假设是准确的。随着相关性 $|\rho|$ 趋近于1，$\ln(1-\rho^2)$ 趋近于负无穷，[KL散度](@entry_id:140001)（即近似误差）则趋向于无穷大。这为我们的直觉提供了定量的支持：平均场近似的质量随着真实后验中变量依赖性的增强而急剧下降。

为了缓解这个问题，可以采用 **结构化平均场 (structured mean-field)** 的方法 。该方法不是将所有变量都因子化，而是将相关的变量分组成块，并在块内保留它们的[联合分布](@entry_id:263960)，同时在块之间维持独立性假设。例如，对于一个时间序列模型中的潜变量 $z_{1:T}$，我们可以使用如下的因子化：

$$
q_{\mathrm{STR}}(z_{1:T}) = q_{12}(z_1, z_2) \prod_{t=3}^T q_t(z_t)
$$

这种方法允许我们捕捉相邻潜变量 $z_1$ 和 $z_2$ 之间的后验相关性，因为它们在真实模型中通过动力学 $p(z_2 \mid z_1)$ 直接耦合。与完全因子化的平均场相比，结构化平均场提供了一个更灵活的变分族，因此能够达到一个更高（或相等）的ELBO值，从而获得更准确的近似。这种保真度的提升通常伴随着适度的计算成本增加，因为它只是将两个独立的小规模更新替换为一个稍大规模的联合更新，但总体计算复杂度通常保持在同一数量级。这是一个在近似保真度和计算可行性之间进行权衡的典型例子。

### [变分推断](@entry_id:634275)的[优化算法](@entry_id:147840)

确定了ELBO目标和变分族之后，下一个问题就是如何执行优化。对于[平均场方法](@entry_id:141668)，经典算法是 **坐标上升[变分推断](@entry_id:634275) (Coordinate Ascent Variational Inference, CAVI)**，它循环地对每个因子 $q_i(z_i)$ 进行更新，同时固定其他因子。

然而，对于大型数据集和复杂模型，一种更现代、更具可扩展性的方法是基于梯度优化的，即 **随机梯度[变分贝叶斯](@entry_id:756437) (Stochastic Gradient Variational Bayes, SGVB)**。其思想是直接使用梯度上升法来优化变分参数。主要挑战在于计算ELBO的梯度，因为它本身是一个期望的形式 $\mathcal{L}(q) = \mathbb{E}_{q(z)}[\dots]$。

计算这种期望的梯度主要有两种方法：

1.  **[得分函数](@entry_id:164520)估计器 (Score-Function Estimator)**，也称为REINFORCE。它利用了恒等式 $\nabla_\phi q_\phi(z) = q_\phi(z) \nabla_\phi \log q_\phi(z)$。这种方法非常通用，不要求[目标函数](@entry_id:267263)可微，但其[梯度估计](@entry_id:164549)的方差通常非常高，导致优化过程缓慢且不稳定。

2.  **[重参数化技巧](@entry_id:636986) (Reparameterization Trick)**，也称为路径[导数估计](@entry_id:1123569)器 (pathwise estimator)。这种方法适用于能够被重[参数化](@entry_id:265163)的分布（如高斯分布）。其核心思想是将[随机变量](@entry_id:195330) $z \sim q_\phi(z)$ 表示为一个确定性函数，该函数作用于分布参数 $\phi$ 和一个独立的、与参数无关的基础噪声变量 $\epsilon$。例如，对于高斯分布 $z \sim \mathcal{N}(\mu, \sigma^2)$，我们可以写成 $z = \mu + \sigma \epsilon$，其中 $\epsilon \sim \mathcal{N}(0, 1)$。通过这种方式，期望中的随机性被从分布 $q$ 转移到了基础噪声 $\epsilon$ 上，使得梯度可以直接被推进到期望内部：

    $$
    \nabla_\phi \mathbb{E}_{q_\phi(z)}[f(z)] = \nabla_\phi \mathbb{E}_{\epsilon}[f(g(\phi, \epsilon))] = \mathbb{E}_{\epsilon}[\nabla_\phi f(g(\phi, \epsilon))]
    $$

    这样得到的[梯度估计](@entry_id:164549)通常方差要低得多。我们可以通过一个简单的例子定量地看到这一点 。对于目标函数 $f(z)=z^2$ 和变分分布 $z \sim \mathcal{N}(\mu, \sigma^2)$，真实梯度为 $\partial/\partial\mu \, \mathbb{E}[z^2] = 2\mu$。可以推导出，得分函数估计器的方差为 $14\mu^2 + 15\sigma^2 + \mu^4/\sigma^2$，而重[参数化](@entry_id:265163)估计器的方差仅为 $4\sigma^2$。两者之差 $14\mu^2 + 11\sigma^2 + \mu^4/\sigma^2$ 总是非负的，清晰地表明了[重参数化技巧](@entry_id:636986)在降低梯度方差方面的巨大优势。

作为一个具体的实践例子，让我们推导在一个由潜变量驱动的[泊松GLM](@entry_id:1129879)中ELBO的重[参数化](@entry_id:265163)梯度 。假设变分分布为 $q(z \mid \mu, \sigma) = \mathcal{N}(z; \mu, \mathrm{diag}(\sigma^2))$，先验为[标准正态分布](@entry_id:184509) $p(z) = \mathcal{N}(0, I)$。我们使用重[参数化](@entry_id:265163) $z = \mu + \sigma \odot \epsilon$（其中 $\odot$ 表示逐元素乘积，$\epsilon \sim \mathcal{N}(0, I)$），并基于单个噪声样本 $\epsilon$ 构造ELBO $\mathcal{L} = \mathbb{E}_{q}[\log p(y \mid z)] - \mathrm{KL}(q \parallel p)$ 的[蒙特卡洛](@entry_id:144354)[梯度估计](@entry_id:164549)。

通过[链式法则](@entry_id:190743)和对KL散度求导，我们可以得到ELBO关于变分均值 $\mu$ 和标准差 $\sigma$ 的梯度：
$$
\nabla_{\mu} \mathcal{L} \approx (y - \lambda(z))w - \mu
$$
$$
\nabla_{\sigma} \mathcal{L} \approx ((y - \lambda(z))w) \odot \epsilon + \sigma^{\odot -1} - \sigma
$$
其中 $z = \mu + \sigma \odot \epsilon$，$\lambda(z) = \exp(w^\top z + b)$ 是泊松模型的速率，而 $\sigma^{\odot -1}$ 是 $\sigma$ 的逐元素倒数。这些[解析梯度](@entry_id:1120999)可以直接用于任何[基于梯度的优化](@entry_id:169228)器（如Adam）中，以有效地学习变分参数 $\mu$ 和 $\sigma$。

### 规模化推断：摊销[变分推断](@entry_id:634275)

传统的[变分推断](@entry_id:634275)（无论是CAVI还是SGVB）为数据集中的每一个数据点 $x_n$ 学习一套独立的变分参数 $\lambda_n$。这意味着对于一个包含 $N$ 个数据点的数据集，我们需要优化 $N$ 组独立的参数。当 $N$ 很大时，这种方法的计算成本变得令人望而却步。更糟糕的是，当遇到一个新的、未见过的数据点时，我们必须重新运行整个优化过程来推断其[潜变量](@entry_id:143771)，这在测试阶段非常耗时。

**摊销[变分推断](@entry_id:634275) (Amortized Variational Inference)** 提供了一个优雅的解决方案 。其核心思想是，我们不再为每个数据点单独学习变分参数，而是学习一个能够将任何观测值 $x$ 直接映射到其对应[后验分布](@entry_id:145605)参数的函数。这个函数，通常被称为 **推断网络 (inference network)** 或 **识别模型 (recognition model)**，本身由一组共享的全局参数 $\phi$（例如，一个神经网络的权重）来[参数化](@entry_id:265163)。因此，变分后验被写成[条件分布](@entry_id:138367)的形式 $q_\phi(z \mid x)$。

通过这种方式，对 $N$ 个独立优化问题的求解被替换为了对单个全局参数 $\phi$ 的优化。[目标函数](@entry_id:267263)变成了在整个数据集上对ELBO求和（或求平均）：

$$
\phi^\star = \arg\max_\phi \sum_{n=1}^N \mathcal{L}(q_\phi, \theta; x_n)
$$

这个[全局优化](@entry_id:634460)通常使用[小批量随机梯度下降](@entry_id:635020)来完成。其“摊销”的含义在于，推断的计算成本在训练阶段被“预先支付”了。一旦推断网络训练完成，对任何数据点（无论是训练集内的还是全新的）进行推断的成本就变得极其低廉：只需通过网络进行一次[前向传播](@entry_id:193086)，即可立即获得其[后验分布](@entry_id:145605)的参数。这种方法极大地提高了推断效率，使得在大型数据集上应用复杂的贝叶斯模型（如[变分自编码器](@entry_id:177996)）成为可能，也为在线实时处理神经数据流的[贝叶斯建模](@entry_id:178666)铺平了道路。