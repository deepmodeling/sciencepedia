{
    "hands_on_practices": [
        {
            "introduction": "将感知建模为概率推断的第一步，是为潜在成因如何产生感官数据建立一个生成模型。这项练习将带你为一个经典的视觉检测任务构建这样一个模型，这个任务是理解贝叶斯感知的基础。通过精确定义潜在成因（例如刺激是否存在）和感官观测值之间的数学关系，你将为所有后续的推断和决策分析奠定基础 。",
            "id": "4008976",
            "problem": "考虑一个单次视觉检测任务，其中一个潜伏二元变量 $z \\in \\{0,1\\}$ 编码了目标不存在 ($z=0$) 或存在 ($z=1$) 的情况。测量值 $x \\in \\mathbb{R}$ 是一个标量感知观测值。假设测量噪声是高斯加性噪声，当目标不存在时，基线测量的均值为 $0$，而当目标存在时，测量的均值为 $\\mu_1 \\in \\mathbb{R}$。设目标存在的先验概率为 $\\pi \\in (0,1)$，噪声方差为 $\\sigma^2 \\in (0,\\infty)$。将参数向量定义为 $\\theta = (\\pi, \\mu_1, \\sigma^2)$。哪个选项正确地指定了一个科学上合理的联合生成模型 $p(x,z \\mid \\theta)$，使得潜伏原因 $z$ 通过高斯噪声影响观测值 $x$，并对规范中的每一项给出清晰的解释？\n\nA. $p(x,z \\mid \\theta) = \\big[\\pi^{z}(1-\\pi)^{1-z}\\big] \\,\\frac{1}{\\sqrt{2\\pi\\sigma^2}} \\exp\\!\\left(-\\frac{(x - z\\,\\mu_1)^2}{2\\sigma^2}\\right)$，其中 $\\pi$ 是 $z=1$ 的先验概率，条件分布 $x \\mid z$ 是均值为 $z\\,\\mu_1$、方差为 $\\sigma^2$ 的高斯分布，并且 $\\theta=(\\pi,\\mu_1,\\sigma^2)$ 参数化了先验和似然。\n\nB. $p(x,z \\mid \\theta) = \\big[\\pi^{z}(1-\\pi)^{1-z}\\big] \\,\\frac{1}{\\sqrt{2\\pi\\sigma^2}} \\exp\\!\\left(-\\frac{x^2}{2\\sigma^2}\\right)$，其中 $\\pi$ 是 $z=1$ 的先验概率，对于 $z \\in \\{0,1\\}$，条件分布 $x \\mid z$ 都是均值为 $0$、方差为 $\\sigma^2$ 的高斯分布，并且 $\\theta=(\\pi,\\sigma^2)$ 参数化了先验和似然。\n\nC. $p(x,z \\mid \\theta) = \\big[\\pi^{z}(1-\\pi)^{1-z}\\big] \\,\\frac{1}{2b} \\exp\\!\\left(-\\frac{|x - z\\,\\mu_1|}{b}\\right)$，其中 $\\pi$ 是 $z=1$ 的先验概率，条件分布 $x \\mid z$ 是均值为 $z\\,\\mu_1$、尺度为 $b>0$ 的 Laplace 分布，并且 $\\theta=(\\pi,\\mu_1,b)$ 参数化了先验和似然。\n\nD. $p(x,z \\mid \\theta) = \\big[\\pi^{z}(1-\\pi)^{1-z}\\big] \\,\\exp\\!\\left(-\\frac{(x - z\\,\\mu_1)^2}{2\\sigma^2}\\right)$，其中 $\\pi$ 是 $z=1$ 的先验概率，条件分布 $x \\mid z$ 在比例常数范围内是高斯分布，并且 $\\theta=(\\pi,\\mu_1,\\sigma^2)$ 参数化了先验和似然。\n\nE. $p(x,z \\mid \\theta) = p(x \\mid \\theta)\\,p(z \\mid x,\\theta)$，其中 $p(x \\mid \\theta) = \\pi\\,\\mathcal{N}(x; \\mu_1, \\sigma^2) + (1-\\pi)\\,\\mathcal{N}(x; 0, \\sigma^2)$ 且 $p(z=1 \\mid x,\\theta) = \\frac{1}{1+\\exp(-\\alpha x)}$，其中 $\\alpha \\in \\mathbb{R}$ 控制斜率，并且 $\\theta=(\\pi,\\mu_1,\\sigma^2,\\alpha)$ 参数化了混合模型和后验分类器。\n\n选择正确的选项。",
            "solution": "用户要求对问题陈述进行批判性验证，然后对一个关于计算神经科学中生成模型的问题所提供的选项进行全面推导和评估。\n\n### 问题验证\n\n**步骤1：提取已知信息**\n问题陈述提供了以下信息：\n- 一个潜伏二元变量 $z \\in \\{0,1\\}$。\n- $z=0$ 表示目标不存在。\n- $z=1$ 表示目标存在。\n- 一个标量感知观测值 $x \\in \\mathbb{R}$。\n- 测量噪声是高斯加性噪声。\n- 当目标不存在时（$z=0$），测量的均值为 $0$。\n- 当目标存在时（$z=1$），测量的均值为 $\\mu_1 \\in \\mathbb{R}$。\n- 目标存在的先验概率为 $P(z=1) = \\pi$，其中 $\\pi \\in (0,1)$。\n- 噪声方差为 $\\sigma^2$，其中 $\\sigma^2 \\in (0,\\infty)$。\n- 参数向量定义为 $\\theta = (\\pi, \\mu_1, \\sigma^2)$。\n- 任务是识别正确指定联合生成模型 $p(x,z \\mid \\theta)$ 及其解释的选项，其中潜伏原因 $z$ 通过高斯噪声影响观测值 $x$。\n\n**步骤2：使用提取的已知信息进行验证**\n- **科学依据：** 该问题描述了信号检测论（SDT）中的一个典型模型，这是心理物理学、知觉和计算神经科学中用于建模不确定性下决策的一个基本框架。它是将感知视为概率推断的一个经典例子。该模型在科学上是合理的，并被广泛使用。\n- **良态性：** 该问题是良态的。它为变量（$z, x$）、参数（$\\pi, \\mu_1, \\sigma^2$）以及概率关系结构（二元变量的先验、高斯条件分布）提供了清晰的定义。其目标——构建联合概率分布 $p(x,z \\mid \\theta)$——是概率论中一个标准且可解的任务。\n- **客观性：** 语言是形式化的、数学的且无歧义的。没有主观或基于观点的断言。\n\n问题陈述没有违反任何无效标准。它是科学上合理的、良态的、客观的、完整的且可形式化的。\n\n**步骤3：结论和行动**\n问题陈述是**有效的**。现在开始解题过程。\n\n### 联合生成模型的推导\n\n目标是构建联合概率分布 $p(x,z \\mid \\theta)$。生成模型指定了如何从潜伏原因生成数据。这可以很自然地使用概率的链式法则表示为：\n$$p(x,z \\mid \\theta) = p(x \\mid z, \\theta) \\, p(z \\mid \\theta)$$\n这种分解表示了生成序列：首先，从其先验分布 $p(z \\mid \\theta)$ 中抽取一个潜伏原因 $z$，然后从似然（或条件分布）$p(x \\mid z, \\theta)$ 中生成一个观测值 $x$。\n\n1.  **先验分布 $p(z \\mid \\theta)$：**\n    潜伏变量 $z$ 是二元的，$z \\in \\{0, 1\\}$。我们已知目标存在的先验概率为 $P(z=1) = \\pi$。由于只有两种结果，目标不存在的概率为 $P(z=0) = 1-\\pi$。这描述了一个伯努利分布。伯努利变量的概率质量函数的一个紧凑数学表达式是：\n    $$p(z \\mid \\theta) = \\pi^z (1-\\pi)^{1-z}$$\n    对于 $z=1$，该表达式正确地得到 $\\pi$；对于 $z=0$，则得到 $1-\\pi$。与先验相关的参数 $\\theta$ 是 $\\pi$。\n\n2.  **似然函数 $p(x \\mid z, \\theta)$：**\n    问题陈述指出，观测值 $x$ 是由一个涉及加性高斯噪声的过程生成的。这个过程的均值取决于潜伏变量 $z$ 的状态。\n    -   当 $z=0$ (目标不存在) 时，$x$ 的均值为 $0$。$x$ 的分布是均值为 $0$、方差为 $\\sigma^2$ 的高斯分布。其概率密度函数 (PDF) 是：\n        $$p(x \\mid z=0, \\theta) = \\mathcal{N}(x; 0, \\sigma^2) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}} \\exp\\left(-\\frac{(x - 0)^2}{2\\sigma^2}\\right)$$\n    -   当 $z=1$ (目标存在) 时，$x$ 的均值为 $\\mu_1$。$x$ 的分布是均值为 $\\mu_1$、方差为 $\\sigma^2$ 的高斯分布。其概率密度函数是：\n        $$p(x \\mid z=1, \\theta) = \\mathcal{N}(x; \\mu_1, \\sigma^2) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}} \\exp\\left(-\\frac{(x - \\mu_1)^2}{2\\sigma^2}\\right)$$\n    我们可以写一个单一的似然表达式来涵盖这两种情况。当 $z=0$ 时高斯分布的均值为 $0$，当 $z=1$ 时为 $\\mu_1$。这可以紧凑地写为 $z\\,\\mu_1$。因此，似然的一般形式是：\n    $$p(x \\mid z, \\theta) = \\mathcal{N}(x; z\\,\\mu_1, \\sigma^2) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}} \\exp\\left(-\\frac{(x - z\\,\\mu_1)^2}{2\\sigma^2}\\right)$$\n    与似然相关的参数 $\\theta$ 是 $\\mu_1$ 和 $\\sigma^2$。\n\n3.  **联合分布 $p(x,z \\mid \\theta)$：**\n    结合先验和似然，我们得到联合分布：\n    $$p(x,z \\mid \\theta) = p(z \\mid \\theta) \\, p(x \\mid z, \\theta) = \\left[ \\pi^z (1-\\pi)^{1-z} \\right] \\left[ \\frac{1}{\\sqrt{2\\pi\\sigma^2}} \\exp\\left(-\\frac{(x - z\\,\\mu_1)^2}{2\\sigma^2}\\right) \\right]$$\n\n### 选项评估\n\n**A. $p(x,z \\mid \\theta) = \\big[\\pi^{z}(1-\\pi)^{1-z}\\big] \\,\\frac{1}{\\sqrt{2\\pi\\sigma^2}} \\exp\\!\\left(-\\frac{(x - z\\,\\mu_1)^2}{2\\sigma^2}\\right)$，其中 $\\pi$ 是 $z=1$ 的先验概率，条件分布 $x \\mid z$ 是均值为 $z\\,\\mu_1$、方差为 $\\sigma^2$ 的高斯分布，并且 $\\theta=(\\pi,\\mu_1,\\sigma^2)$ 参数化了先验和似然。**\n-   **数学表达式：** 该表达式与从第一性原理推导出的表达式完全匹配。项 $\\pi^z(1-\\pi)^{1-z}$ 正确地表示了伯努利先验 $p(z \\mid \\theta)$。项 $\\frac{1}{\\sqrt{2\\pi\\sigma^2}} \\exp\\!\\left(-\\frac{(x - z\\,\\mu_1)^2}{2\\sigma^2}\\right)$ 正确地表示了均值为 $z\\,\\mu_1$（当 $z=0$ 时为 $0$，当 $z=1$ 时为 $\\mu_1$）、方差为 $\\sigma^2$ 的高斯似然 $p(x \\mid z, \\theta)$。\n-   **解释：** 所提供的解释与问题陈述和数学推导完全一致。$\\pi$ 是 $z=1$ 的先验，给定 $z$ 时 $x$ 的条件分布确实是均值为 $z\\mu_1$、方差为 $\\sigma^2$ 的高斯分布，并且参数 $\\theta$ 在先验和似然之间被正确划分。\n-   **结论：** **正确**。\n\n**B. $p(x,z \\mid \\theta) = \\big[\\pi^{z}(1-\\pi)^{1-z}\\big] \\,\\frac{1}{\\sqrt{2\\pi\\sigma^2}} \\exp\\!\\left(-\\frac{x^2}{2\\sigma^2}\\right)$，其中 $\\pi$ 是 $z=1$ 的先验概率，对于 $z \\in \\{0,1\\}$，条件分布 $x \\mid z$ 都是均值为 $0$、方差为 $\\sigma^2$ 的高斯分布，并且 $\\theta=(\\pi,\\sigma^2)$ 参数化了先验和似然。**\n-   **数学表达式：** 该表达式的似然部分 $\\frac{1}{\\sqrt{2\\pi\\sigma^2}} \\exp\\!\\left(-\\frac{x^2}{2\\sigma^2}\\right)$ 对应于对所有 $z$ 值均值为 $0$ 的高斯分布。这意味着观测值 $x$ 独立于潜伏原因 $z$，即 $p(x \\mid z, \\theta) = p(x \\mid \\theta)$。\n-   **解释：** 这与问题陈述中“当目标存在时，测量的均值为 $\\mu_1$”相矛盾。该选项中指定的模型意味着潜伏原因 $z$ 对观测值 $x$ 的均值没有影响。\n-   **结论：** **不正确**。\n\n**C. $p(x,z \\mid \\theta) = \\big[\\pi^{z}(1-\\pi)^{1-z}\\big] \\,\\frac{1}{2b} \\exp\\!\\left(-\\frac{|x - z\\,\\mu_1|}{b}\\right)$，其中 $\\pi$ 是 $z=1$ 的先验概率，条件分布 $x \\mid z$ 是均值为 $z\\,\\mu_1$、尺度为 $b>0$ 的 Laplace 分布，并且 $\\theta=(\\pi,\\mu_1,b)$ 参数化了先验和似然。**\n-   **数学表达式：** 该表达式的似然部分 $\\frac{1}{2b} \\exp\\!\\left(-\\frac{|x - z\\,\\mu_1|}{b}\\right)$ 是 Laplace 分布的概率密度函数，而不是高斯分布。\n-   **解释：** 这与问题明确要求的“测量噪声是高斯加性噪声”相矛盾。\n-   **结论：** **不正确**。\n\n**D. $p(x,z \\mid \\theta) = \\big[\\pi^{z}(1-\\pi)^{1-z}\\big] \\,\\exp\\!\\left(-\\frac{(x - z\\,\\mu_1)^2}{2\\sigma^2}\\right)$，其中 $\\pi$ 是 $z=1$ 的先验概率，条件分布 $x \\mid z$ 在比例常数范围内是高斯分布，并且 $\\theta=(\\pi,\\mu_1,\\sigma^2)$ 参数化了先验和似然。**\n-   **数学表达式：** 似然的表达式 $\\exp\\!\\left(-\\frac{(x - z\\,\\mu_1)^2}{2\\sigma^2}\\right)$ 缺少归一化常数 $\\frac{1}{\\sqrt{2\\pi\\sigma^2}}$。对于包含连续变量（如 $x$）的联合概率密度函数，其在连续变量上的积分和在离散变量上的求和必须等于 $1$。没有这个常数，该函数不是一个有效的联合概率密度函数。问题要求正确指定生成模型，这意味着需要一个被正确定义的概率分布。\n-   **解释：** 虽然“在比例常数范围内是高斯分布”的陈述承认了缺失的项，但它描述了一个不完整并因此不正确的概率密度函数规范。\n-   **结论：** **不正确**。\n\n**E. $p(x,z \\mid \\theta) = p(x \\mid \\theta)\\,p(z \\mid x,\\theta)$，其中 $p(x \\mid \\theta) = \\pi\\,\\mathcal{N}(x; \\mu_1, \\sigma^2) + (1-\\pi)\\,\\mathcal{N}(x; 0, \\sigma^2)$ 且 $p(z=1 \\mid x,\\theta) = \\frac{1}{1+\\exp(-\\alpha x)}$，其中 $\\alpha \\in \\mathbb{R}$ 控制斜率，并且 $\\theta=(\\pi,\\mu_1,\\sigma^2,\\alpha)$ 参数化了混合模型和后验分类器。**\n-   **数学表达式：** 该选项使用了分解 $p(x,z) = p(x)p(z|x)$。这在数学上是有效的，但它代表了“诊断”或“判别”方向 ($x \\to z$)，而不是潜伏原因影响观测值的“生成”方向 ($z \\to x$) 。问题明确要求的是生成模型。此外，后验概率 $p(z=1 \\mid x,\\theta)$ 被指定为 $x$ 的一个简单逻辑斯谛函数，这是一种近似。从选项A的生成模型中推导出的真实后验概率是 $x$ 的线性函数的逻辑斯谛函数，特别地，它包含一个偏移项。引入一个独立的参数 $\\alpha$ 也与原始参数集 $\\theta$ 不一致。\n-   **解释：** 这种表述描述了一种在概念上与所要求的生成过程不同的模型结构。它将一个边际分布（证据）与一个单独参数化的后验（分类器）混合在一起。这不是联合生成模型本身的标准规范。\n-   **结论：** **不正确**。",
            "answer": "$$\\boxed{A}$$"
        },
        {
            "introduction": "在计算出后验概率分布 $p(z|x)$ 之后，感知系统必须做出决策或形成一个估计。这项练习探讨了贝叶斯决策理论如何为此提供一个原则性框架，它表明最优估计不仅取决于后验概率，还取决于与不同类型错误相关的具体“损失”或“代价”。通过对比不同的估计量（如后验众数和后验均值）并引入非对称损失函数，这项练习揭示了任务目标在塑造最终感知判断中的关键作用 。",
            "id": "4008950",
            "problem": "考虑一个潜在刺激变量 $z \\in \\mathbb{R}$（例如，视觉方向）和一个感觉观察值 $x \\in \\mathbb{R}$。知觉系统通过贝叶斯法则将似然 $p(x \\mid z)$ 与先验 $p(z)$ 相结合，形成后验 $p(z \\mid x)$。在贝叶斯决策理论中，最优估计量 $\\hat{z}(x)$ 最小化后验期望损失，该损失由风险泛函 $\\mathcal{R}(\\hat{z};x) = \\int L(\\hat{z},z) \\, p(z \\mid x) \\, dz$ 定义，其中 $L(\\hat{z},z)$ 是一个与任务相关的损失。两个典型的估计量是最大后验 (MAP) 估计量 $\\hat{z}_{\\mathrm{MAP}}(x) = \\arg\\max_{z} p(z \\mid x)$ 和最小均方误差 (MMSE) 估计量 $\\hat{z}_{\\mathrm{MMSE}}(x) = \\mathbb{E}[z \\mid x]$，它们在不同的损失设定下产生。在高级知觉情境中，损失可能是不对称的：例如，由于运动或安全约束，对 $z$ 的低估可能比高估的代价更大。考虑不对称线性损失\n$$\nL(\\hat{z},z) = c_{+} \\, (z - \\hat{z})_{+} + c_{-} \\, (\\hat{z} - z)_{+},\n$$\n其中 $(a)_{+} = \\max\\{a,0\\}$，$c_{+} > 0$ 是真实值 $z$ 超过估计值 $\\hat{z}$（低估）时的成本权重，$c_{-} > 0$ 是 $\\hat{z}$ 超过 $z$（高估）时的成本权重。假设 $p(z \\mid x)$ 是连续的，其累积分布函数为 $F_{Z \\mid X}(z \\mid x)$。选择所有关于 $\\hat{z}_{\\mathrm{MAP}}$ 和 $\\hat{z}_{\\mathrm{MMSE}}$ 如何对比以及它们在不对称损失下何时不同的正确陈述。\n\nA. 最小化后验期望损失的贝叶斯估计量是 $\\hat{z}(x) = \\arg\\min_{\\hat{z}} \\int L(\\hat{z},z) \\, p(z \\mid x) \\, dz$；在平方误差损失 $L(\\hat{z},z) = (z - \\hat{z})^{2}$ 下，它是 $\\hat{z}_{\\mathrm{MMSE}}(x) = \\mathbb{E}[z \\mid x]$；在连续情况下 $0$-$1$ 损失的极限邻域版本下，它是后验众数 $\\hat{z}_{\\mathrm{MAP}}(x)$；在不对称线性损失 $L(\\hat{z},z) = c_{+} (z - \\hat{z})_{+} + c_{-} (\\hat{z} - z)_{+}$ 下，它是求解 $F_{Z \\mid X}(\\hat{z} \\mid x) = \\frac{c_{+}}{c_{+} + c_{-}}$ 的后验分位数，该分位数仅当 $p(z \\mid x)$ 是对称单峰且 $c_{+} = c_{-}$ 时才与 $\\hat{z}_{\\mathrm{MMSE}}$ 和 $\\hat{z}_{\\mathrm{MAP}}$ 一致。\n\nB. MAP 估计量 $\\hat{z}_{\\mathrm{MAP}}(x)$ 对任何损失函数 $L(\\hat{z},z)$ 都能最小化期望损失，因为它最大化了 $p(z \\mid x)$。\n\nC. 对于任何凸损失函数 $L(\\hat{z},z)$，贝叶斯最优估计量总是 $\\hat{z}_{\\mathrm{MMSE}}(x) = \\mathbb{E}[z \\mid x]$，因此损失的不对称性不会改变最优估计量。\n\nD. 对于不对称线性损失 $L(\\hat{z},z) = c_{+} (z - \\hat{z})_{+} + c_{-} (\\hat{z} - z)_{+}$ 且 $c_{+} > c_{-}$，贝叶斯最优估计量满足 $F_{Z \\mid X}(\\hat{z} \\mid x) = \\frac{c_{-}}{c_{+} + c_{-}}$，这意味着估计量相对于 $\\mathbb{E}[z \\mid x]$ 向下偏移。\n\nE. 如果 $p(z \\mid x)$ 是高斯分布且损失是平方误差，则 $\\hat{z}_{\\mathrm{MAP}}(x) = \\hat{z}_{\\mathrm{MMSE}}(x)$；在不对称线性损失且 $c_{+} \\neq c_{-}$ 的情况下，贝叶斯最优估计量是一个后验分位数而不是后验均值，因此 $\\hat{z}_{\\mathrm{MMSE}}(x)$ 对于该损失不是最优的。",
            "solution": "问题陈述是贝叶斯决策理论中一个有效且定义明确的问题，该理论是计算神经科学和统计学中的一个标准框架。所提供的定义和概念具有科学依据、内部一致，并且足以进行严谨的分析。我们将继续推导指定损失函数的最优估计量，然后评估每个陈述。\n\n### 贝叶斯估计量的推导\n\n贝叶斯最优估计量 $\\hat{z}(x)$ 是使后验期望损失（或风险）$\\mathcal{R}(\\hat{z};x)$ 最小化的值：\n$$\n\\hat{z}(x) = \\arg\\min_{\\hat{z}} \\mathcal{R}(\\hat{z};x) = \\arg\\min_{\\hat{z}} \\int_{-\\infty}^{\\infty} L(\\hat{z},z) \\, p(z \\mid x) \\, dz\n$$\n我们分析由损失函数 $L(\\hat{z},z)$ 的不同选择产生的具体估计量。\n\n**1. 平方误差损失：** $L(\\hat{z},z) = (z - \\hat{z})^{2}$\n风险为 $\\mathcal{R}(\\hat{z};x) = \\int (z - \\hat{z})^{2} p(z \\mid x) \\, dz$。为了找到最小值，我们将关于 $\\hat{z}$ 的导数设为零：\n$$\n\\frac{\\partial \\mathcal{R}}{\\partial \\hat{z}} = \\frac{\\partial}{\\partial \\hat{z}} \\int (z^2 - 2z\\hat{z} + \\hat{z}^2) p(z \\mid x) \\, dz = \\int (-2z + 2\\hat{z}) p(z \\mid x) \\, dz\n$$\n$$\n\\frac{\\partial \\mathcal{R}}{\\partial \\hat{z}} = 2\\hat{z} \\int p(z \\mid x) \\, dz - 2 \\int z p(z \\mid x) \\, dz = 2\\hat{z} - 2\\mathbb{E}[z \\mid x]\n$$\n将导数设为零得到 $\\hat{z} = \\mathbb{E}[z \\mid x]$。二阶导数为 $\\frac{\\partial^2 \\mathcal{R}}{\\partial \\hat{z}^2} = 2 > 0$，确认了这是一个最小值。因此，平方误差损失的最优估计量是后验均值，$\\hat{z}_{\\mathrm{MMSE}}(x)$。\n\n**2. 0-1 损失（极限情况）：** $L(\\hat{z},z) = \\begin{cases} 0  \\text{若 } |z - \\hat{z}| \\le \\epsilon \\\\ 1  \\text{若 } |z - \\hat{z}| > \\epsilon \\end{cases}$，对于一个小的 $\\epsilon > 0$。\n风险为 $\\mathcal{R}(\\hat{z};x) = \\int_{|z - \\hat{z}| > \\epsilon} 1 \\cdot p(z \\mid x) \\, dz = 1 - \\int_{\\hat{z}-\\epsilon}^{\\hat{z}+\\epsilon} p(z \\mid x) \\, dz$。\n最小化风险等价于最大化项 $\\int_{\\hat{z}-\\epsilon}^{\\hat{z}+\\epsilon} p(z \\mid x) \\, dz$。当 $\\epsilon \\to 0$ 时，通过选择 $\\hat{z}$ 为密度 $p(z \\mid x)$ 最高处的值，可以最大化该积分。根据定义，这就是后验众数。因此，该损失的最优估计量是最大后验 (MAP) 估计量，$\\hat{z}_{\\mathrm{MAP}}(x) = \\arg\\max_z p(z \\mid x)$。\n\n**3. 不对称线性损失：** $L(\\hat{z},z) = c_{+} \\, (z - \\hat{z})_{+} + c_{-} \\, (\\hat{z} - z)_{+}$\n风险可以写成：\n$$\n\\mathcal{R}(\\hat{z};x) = \\int_{-\\infty}^{\\hat{z}} c_{-} (\\hat{z} - z) p(z \\mid x) \\, dz + \\int_{\\hat{z}}^{\\infty} c_{+} (z - \\hat{z}) p(z \\mid x) \\, dz\n$$\n我们使用莱布尼茨积分法则对 $\\hat{z}$ 求导：\n$$\n\\frac{\\partial \\mathcal{R}}{\\partial \\hat{z}} = \\int_{-\\infty}^{\\hat{z}} c_{-} p(z \\mid x) \\, dz - \\int_{\\hat{z}}^{\\infty} c_{+} p(z \\mid x) \\, dz\n$$\n设 $F_{Z \\mid X}(z \\mid x)$ 是后验 $p(z \\mid x)$ 的累积分布函数 (CDF)。导数是：\n$$\n\\frac{\\partial \\mathcal{R}}{\\partial \\hat{z}} = c_{-} F_{Z \\mid X}(\\hat{z} \\mid x) - c_{+} [1 - F_{Z \\mid X}(\\hat{z} \\mid x)]\n$$\n将其设为零以找到最优的 $\\hat{z}$：\n$$\nc_{-} F_{Z \\mid X}(\\hat{z} \\mid x) = c_{+} - c_{+} F_{Z \\mid X}(\\hat{z} \\mid x)\n$$\n$$\n(c_{+} + c_{-}) F_{Z \\mid X}(\\hat{z} \\mid x) = c_{+}\n$$\n$$\nF_{Z \\mid X}(\\hat{z} \\mid x) = \\frac{c_{+}}{c_{+} + c_{-}}\n$$\n二阶导数为 $(c_{+} + c_{-})p(\\hat{z} \\mid x) > 0$，确认了这是一个最小值。最优估计量是与累积概率 $\\frac{c_{+}}{c_{+} + c_{-}}$ 对应的后验分布的分位数。\n\n### 选项评估\n\n**A. 最小化后验期望损失的贝叶斯估计量是 $\\hat{z}(x) = \\arg\\min_{\\hat{z}} \\int L(\\hat{z},z) \\, p(z \\mid x) \\, dz$；在平方误差损失 $L(\\hat{z},z) = (z - \\hat{z})^{2}$ 下，它是 $\\hat{z}_{\\mathrm{MMSE}}(x) = \\mathbb{E}[z \\mid x]$；在连续情况下 $0$-$1$ 损失的极限邻域版本下，它是后验众数 $\\hat{z}_{\\mathrm{MAP}}(x)$；在不对称线性损失 $L(\\hat{z},z) = c_{+} (z - \\hat{z})_{+} + c_{-} (\\hat{z} - z)_{+}$ 下，它是求解 $F_{Z \\mid X}(\\hat{z} \\mid x) = \\frac{c_{+}}{c_{+} + c_{-}}$ 的后验分位数，该分位数仅当 $p(z \\mid x)$ 是对称单峰且 $c_{+} = c_{-}$ 时才与 $\\hat{z}_{\\mathrm{MMSE}}$ 和 $\\hat{z}_{\\mathrm{MAP}}$ 一致。**\n这个陈述是一个全面的总结。\n- 贝叶斯估计量的初始定义是正确的。\n- 如我们的推导所示，对于平方误差损失的 MMSE 估计量的确定是正确的。\n- 如我们的推导所示，对于 0-1 损失的 MAP 估计量的确定是正确的。\n- 如我们的推导所示，对于不对称线性损失的分位数估计量的确定，以及其正确公式 $F_{Z \\mid X}(\\hat{z} \\mid x) = \\frac{c_{+}}{c_{+} + c_{-}}$，是正确的。\n- 关于一致性的最终条件：如果 $p(z \\mid x)$ 是对称且单峰的，其均值 ($\\hat{z}_{\\mathrm{MMSE}}$)、中位数和众数 ($\\hat{z}_{\\mathrm{MAP}}$) 都相等。如果 $c_{+} = c_{-}$，则最优分位数位于概率 $\\frac{c_{+}}{c_{+} + c_{-}} = \\frac{1}{2}$ 处，即中位数。因此，在这些条件下，所有三个估计量都一致。“仅当”部分对于此类模型中通常使用的广泛的良态单峰分布成立。为使估计量一致，我们需要均值 = 众数 = $q$-分位数。对于单峰分布，均值=众数意味着对称性。对称性意味着均值=中位数。所以 $q$-分位数必须是中位数，这要求 $q=1/2$，因此 $c_+=c_-$。该陈述在标准上下文中是准确的。\n结论：**正确**。\n\n**B. MAP 估计量 $\\hat{z}_{\\mathrm{MAP}}(x)$ 对任何损失函数 $L(\\hat{z},z)$ 都能最小化期望损失，因为它最大化了 $p(z \\mid x)$。**\n这个陈述是错误的。最优贝叶斯估计量取决于具体的损失函数。如上所述，平方误差损失导致后验均值 ($\\hat{z}_{\\mathrm{MMSE}}$)，而不是后验众数 ($\\hat{z}_{\\mathrm{MAP}}$)，除非后验是对称且单峰的。对于一般损失函数，最大化后验密度与最小化后验期望损失是不同的优化准则。\n结论：**不正确**。\n\n**C. 对于任何凸损失函数 $L(\\hat{z},z)$，贝叶斯最优估计量总是 $\\hat{z}_{\\mathrm{MMSE}}(x) = \\mathbb{E}[z \\mid x]$，因此损失的不对称性不会改变最优估计量。**\n这个陈述是错误的。不对称线性损失函数在 $\\hat{z}$ 上是凸的，但正如我们推导的，其最优估计量是后验分位数，而不是后验均值（除非分位数恰好等于均值）。另一个反例是绝对误差损失 $L(\\hat{z},z) = |z-\\hat{z}|$，它也是凸的，并以后验中位数作为最优估计量。关于不对称性不改变估计量的断言也是错误的；如果 $c_{+} \\neq c_{-}$，分位数就不是中位数，这证明了不对称性的影响。\n结论：**不正确**。\n\n**D. 对于不对称线性损失 $L(\\hat{z},z) = c_{+} (z - \\hat{z})_{+} + c_{-} (\\hat{z} - z)_{+}$ 且 $c_{+} > c_{-}$，贝叶斯最优估计量满足 $F_{Z \\mid X}(\\hat{z} \\mid x) = \\frac{c_{-}}{c_{+} + c_{-}}$，这意味着估计量相对于 $\\mathbb{E}[z \\mid x]$ 向下偏移。**\n这个陈述包含两个错误。首先，我们的推导表明正确的公式是 $F_{Z \\mid X}(\\hat{z} \\mid x) = \\frac{c_{+}}{c_{+} + c_{-}}$。该陈述错误地将 $c_{-}$ 放在了分子上。其次，直观上，低估的高成本 ($c_{+} > c_{-}$) 应导致估计向上偏置，以避免代价高昂的低估。正确的公式证实了这一点：如果 $c_{+} > c_{-}$，那么 $\\frac{c_{+}}{c_{+} + c_{-}} > \\frac{1}{2}$，所以最优估计是高于中位数的分位数，对于对称后验分布代表向上偏移。陈述中的错误公式将意味着一个低于中位数的分位数，从而导致向下偏移的错误结论。\n结论：**不正确**。\n\n**E. 如果 $p(z \\mid x)$ 是高斯分布且损失是平方误差，则 $\\hat{z}_{\\mathrm{MAP}}(x) = \\hat{z}_{\\mathrm{MMSE}}(x)$；在不对称线性损失且 $c_{+} \\neq c_{-}$ 的情况下，贝叶斯最优估计量是一个后验分位数而不是后验均值，因此 $\\hat{z}_{\\mathrm{MMSE}}(x)$ 对于该损失不是最优的。**\n- 第一部分：高斯后验分布是一种对称且单峰的分布。其均值、中位数和众数都位于分布的中心。因此，对于高斯后验，$\\hat{z}_{\\mathrm{MAP}}(x)$（众数）等于 $\\hat{z}_{\\mathrm{MMSE}}(x)$（均值）。这是正确的。\n- 第二部分：对于不对称线性损失且 $c_{+} \\neq c_{-}$，最优估计量是位于 $q = \\frac{c_{+}}{c_{+} + c_{-}} \\neq \\frac{1}{2}$ 的分位数。对于高斯分布（或任何对称分布），均值就是中位数（$1/2$-分位数）。由于最优估计量是不同于中位数的分位数，所以它不是后验均值。这是正确的。\n- 结论：因此，MMSE 估计量对于这种不对称损失不是最优的。这是一个正确的逻辑结论。整个陈述在事实上是正确的。\n结论：**正确**。",
            "answer": "$$\\boxed{AE}$$"
        },
        {
            "introduction": "感知系统面临的一个核心挑战是，其对世界的内部模型（尤其是先验信念）可能与环境的真实统计特性不完全匹配。这项练习深入探讨了这个问题，它要求你量化使用“失配”先验所带来的后果，即计算均方误差。通过这个推导，你将具体分析由不准确先验引起的偏差-方差权衡，并理解贝叶斯估计量在模型失配情况下的稳健性 。",
            "id": "4008934",
            "problem": "考虑一个单一的潜标量刺激 $z$ 和一个由真实环境根据以下线性高斯模型产生的带噪声测量值 $x$：潜变量 $z$ 从高斯先验 $p_{\\text{true}}(z) = \\mathcal{N}(z; \\mu, \\sigma_{z}^{2})$ 中抽取，测量值由 $x = z + \\varepsilon$ 给出，其中测量噪声 $\\varepsilon$ 独立于 $z$ 并服从分布 $\\varepsilon \\sim \\mathcal{N}(0, \\sigma^{2})$。一个感知估计器（例如，一个执行概率推断的大脑）形成一个可能与真实环境不匹配的内部先验 $p_{\\text{int}}(z) = \\mathcal{N}(z; \\mu_{0}, \\tau^{2})$，并使用该内部先验下的贝叶斯最小二乘法（后验均值）从观测值 $x$ 中产生一个估计值 $\\hat{z}(x)$。\n\n从 Bayes 法则以及高斯似然和先验的定义出发，推导出在内部先验 $p_{\\text{int}}(z)$ 和测量模型所隐含的似然下的后验均值作为估计器 $\\hat{z}(x)$。然后，在上述指定的真实生成过程下，计算均方误差 (MSE)，定义为 $\\mathbb{E}\\!\\left[\\left(\\hat{z}(x) - z\\right)^{2}\\right]$，其中期望是关于由 $p_{\\text{true}}(z)$ 和 $p(x \\mid z)$ 导出的 $(z, x)$ 的真实联合分布。将您的最终答案表示为关于参数 $\\mu$、$\\mu_{0}$、$\\sigma_{z}^{2}$、$\\sigma^{2}$ 和 $\\tau^{2}$ 的单个、完全简化的解析表达式。不需要数值近似，并且不应留下任何未计算的积分。最终答案必须是解析表达式；除了所要求的表达式外，不要报告任何不等式或方程。",
            "solution": "该问题陈述具有科学依据，是适定且客观的。它形式化了计算神经科学和贝叶斯统计中一个关于先验不匹配的标准情景。所有参数和分布都已明确定义，任务是在这些条件下推导出一个特定的解析量——均方误差 (MSE)。该问题是有效的，并且有唯一解。\n\n解决过程包括两个主要部分：首先，在智能体的内部模型下推导贝叶斯估计器 $\\hat{z}(x)$；其次，在环境的真实生成模型下计算该估计器的 MSE。\n\n第一部分：估计器 $\\hat{z}(x)$ 的推导\n\n估计器 $\\hat{z}(x)$ 是内部模型下的后验均值。内部模型由内部先验 $p_{\\text{int}}(z)$ 和似然 $p(x|z)$ 组成。\n\n内部先验是高斯分布：\n$$p_{\\text{int}}(z) = \\mathcal{N}(z; \\mu_{0}, \\tau^{2}) = \\frac{1}{\\sqrt{2\\pi\\tau^2}} \\exp\\left(-\\frac{(z-\\mu_0)^2}{2\\tau^2}\\right)$$\n\n测量模型为 $x = z + \\varepsilon$，其中 $\\varepsilon \\sim \\mathcal{N}(0, \\sigma^{2})$。这意味着在给定潜变量 $z$ 的情况下，测量值 $x$ 的条件分布，即似然函数为：\n$$p(x|z) = \\mathcal{N}(x; z, \\sigma^{2}) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}} \\exp\\left(-\\frac{(x-z)^2}{2\\sigma^2}\\right)$$\n\n根据 Bayes 法则，在内部模型下给定 $x$ 时 $z$ 的后验分布与似然和内部先验的乘积成正比：\n$$p_{\\text{int}}(z|x) \\propto p(x|z) p_{\\text{int}}(z)$$\n$$p_{\\text{int}}(z|x) \\propto \\exp\\left(-\\frac{(x-z)^2}{2\\sigma^2}\\right) \\exp\\left(-\\frac{(z-\\mu_0)^2}{2\\tau^2}\\right)$$\n$$p_{\\text{int}}(z|x) \\propto \\exp\\left(-\\frac{1}{2} \\left[ \\frac{(z-x)^2}{\\sigma^2} + \\frac{(z-\\mu_0)^2}{\\tau^2} \\right] \\right)$$\n\n为了找到后验分布的参数，我们在指数中对 $z$ 进行配方。方括号内的项是：\n$$ \\frac{z^2 - 2zx + x^2}{\\sigma^2} + \\frac{z^2 - 2z\\mu_0 + \\mu_0^2}{\\tau^2} = z^2 \\left(\\frac{1}{\\sigma^2} + \\frac{1}{\\tau^2}\\right) - 2z \\left(\\frac{x}{\\sigma^2} + \\frac{\\mu_0}{\\tau^2}\\right) + \\text{不依赖于 } z \\text{ 的项} $$\n后验分布 $p_{\\text{int}}(z|x)$ 是一个高斯分布，我们称之为 $\\mathcal{N}(z; \\mu_{\\text{post}}, \\sigma_{\\text{post}}^2)$，其指数形式为 $-\\frac{(z-\\mu_{\\text{post}})^2}{2\\sigma_{\\text{post}}^2}$。展开此式可得 $-\\frac{1}{2\\sigma_{\\text{post}}^2} (z^2 - 2z\\mu_{\\text{post}} + \\mu_{\\text{post}}^2)$。\n\n通过比较 $z^2$ 和 $z$ 的系数，我们可以确定后验方差 $\\sigma_{\\text{post}}^2$ 和后验均值 $\\mu_{\\text{post}}$。\n后验分布的精度（方差的倒数）是似然和先验的精度之和：\n$$\\frac{1}{\\sigma_{\\text{post}}^2} = \\frac{1}{\\sigma^2} + \\frac{1}{\\tau^2} = \\frac{\\tau^2 + \\sigma^2}{\\sigma^2 \\tau^2} \\implies \\sigma_{\\text{post}}^2 = \\frac{\\sigma^2 \\tau^2}{\\sigma^2 + \\tau^2}$$\n后验分布的均值由下式给出：\n$$\\frac{\\mu_{\\text{post}}}{\\sigma_{\\text{post}}^2} = \\frac{x}{\\sigma^2} + \\frac{\\mu_0}{\\tau^2}$$\n$$\\mu_{\\text{post}} = \\sigma_{\\text{post}}^2 \\left(\\frac{x}{\\sigma^2} + \\frac{\\mu_0}{\\tau^2}\\right) = \\frac{\\sigma^2 \\tau^2}{\\sigma^2 + \\tau^2} \\left(\\frac{x\\tau^2 + \\mu_0\\sigma^2}{\\sigma^2\\tau^2}\\right) = \\frac{\\tau^2 x + \\sigma^2 \\mu_0}{\\sigma^2 + \\tau^2}$$\n估计器 $\\hat{z}(x)$ 是后验均值 $\\mu_{\\text{post}}$。\n$$\\hat{z}(x) = \\frac{\\tau^2}{\\sigma^2 + \\tau^2}x + \\frac{\\sigma^2}{\\sigma^2 + \\tau^2}\\mu_0$$\n\n第二部分：均方误差 (MSE) 的计算\n\nMSE 定义为误差平方的期望值，即 $\\mathbb{E}[(\\hat{z}(x) - z)^2]$，其中期望是关于真实生成过程计算的。在真实过程中，$z \\sim p_{\\text{true}}(z) = \\mathcal{N}(z; \\mu, \\sigma_z^2)$ 且 $x = z + \\varepsilon$，其中 $\\varepsilon \\sim \\mathcal{N}(0, \\sigma^2)$。变量 $z$ 和 $\\varepsilon$ 是独立的。\n\n首先，我们将误差项 $\\hat{z}(x) - z$ 表示为 $z$ 和 $\\varepsilon$ 的函数：\n$$\\hat{z}(x) - z = \\left(\\frac{\\tau^2 x + \\sigma^2 \\mu_0}{\\sigma^2 + \\tau^2}\\right) - z$$\n代入 $x = z + \\varepsilon$：\n$$\\hat{z}(x) - z = \\frac{\\tau^2(z+\\varepsilon) + \\sigma^2 \\mu_0}{\\sigma^2 + \\tau^2} - z = \\frac{\\tau^2 z + \\tau^2 \\varepsilon + \\sigma^2 \\mu_0 - z(\\sigma^2 + \\tau^2)}{\\sigma^2 + \\tau^2}$$\n$$= \\frac{(\\tau^2 - \\sigma^2 - \\tau^2)z + \\tau^2 \\varepsilon + \\sigma^2 \\mu_0}{\\sigma^2 + \\tau^2} = \\frac{-\\sigma^2 z + \\tau^2 \\varepsilon + \\sigma^2 \\mu_0}{\\sigma^2 + \\tau^2}$$\n$$= \\frac{\\tau^2 \\varepsilon - \\sigma^2 (z - \\mu_0)}{\\sigma^2 + \\tau^2}$$\n现在，我们计算该表达式平方的期望值：\n$$\\text{MSE} = \\mathbb{E}\\left[\\left(\\frac{\\tau^2 \\varepsilon - \\sigma^2 (z - \\mu_0)}{\\sigma^2 + \\tau^2}\\right)^2\\right] = \\frac{1}{(\\sigma^2 + \\tau^2)^2} \\mathbb{E}\\left[(\\tau^2 \\varepsilon - \\sigma^2 (z - \\mu_0))^2\\right]$$\n展开期望内的平方项：\n$$(\\tau^2 \\varepsilon - \\sigma^2 (z - \\mu_0))^2 = (\\tau^2)^2 \\varepsilon^2 - 2\\tau^2\\sigma^2\\varepsilon(z-\\mu_0) + (\\sigma^2)^2 (z-\\mu_0)^2$$\n我们逐项计算此和的期望。期望是关于 $z$ 和 $\\varepsilon$ 的真实分布计算的。\n1.  $\\mathbb{E}[(\\tau^2)^2 \\varepsilon^2] = \\tau^4 \\mathbb{E}[\\varepsilon^2]$。由于 $\\varepsilon \\sim \\mathcal{N}(0, \\sigma^2)$，其均值为 $\\mathbb{E}[\\varepsilon]=0$，方差为 $\\text{Var}(\\varepsilon)=\\sigma^2$。我们知道 $\\text{Var}(\\varepsilon) = \\mathbb{E}[\\varepsilon^2] - (\\mathbb{E}[\\varepsilon])^2$，因此 $\\mathbb{E}[\\varepsilon^2] = \\sigma^2$。所以，该项为 $\\tau^4 \\sigma^2$。\n2.  $\\mathbb{E}[-2\\tau^2\\sigma^2\\varepsilon(z-\\mu_0)] = -2\\tau^2\\sigma^2 \\mathbb{E}[\\varepsilon(z-\\mu_0)]$。由于 $z$ 和 $\\varepsilon$ 是独立的，所以 $\\mathbb{E}[\\varepsilon(z-\\mu_0)] = \\mathbb{E}[\\varepsilon]\\mathbb{E}[z-\\mu_0]$。因为 $\\mathbb{E}[\\varepsilon]=0$，所以该项为 $0$。\n3.  $\\mathbb{E}[(\\sigma^2)^2 (z-\\mu_0)^2] = \\sigma^4 \\mathbb{E}[(z-\\mu_0)^2]$。对于随机变量 $Y$ 和常数 $c$，有 $\\mathbb{E}[(Y-c)^2] = \\text{Var}(Y) + (\\mathbb{E}[Y]-c)^2$。这里，$Y=z$，$c=\\mu_0$。在真实分布下，$\\mathbb{E}[z]=\\mu$，$\\text{Var}(z)=\\sigma_z^2$。因此，$\\mathbb{E}[(z-\\mu_0)^2] = \\text{Var}(z) + (\\mathbb{E}[z]-\\mu_0)^2 = \\sigma_z^2 + (\\mu - \\mu_0)^2$。该项变为 $\\sigma^4 (\\sigma_z^2 + (\\mu - \\mu_0)^2)$。\n\n结合这些结果，期望为：\n$$\\mathbb{E}\\left[(\\tau^2 \\varepsilon - \\sigma^2 (z - \\mu_0))^2\\right] = \\tau^4 \\sigma^2 + 0 + \\sigma^4 (\\sigma_z^2 + (\\mu - \\mu_0)^2)$$\n最后，将此结果代入 MSE 表达式中：\n$$\\text{MSE} = \\frac{\\tau^4 \\sigma^2 + \\sigma^4 (\\sigma_z^2 + (\\mu - \\mu_0)^2)}{(\\sigma^2 + \\tau^2)^2}$$\n为得到最终表达式，展开分子中的第二项：\n$$\\text{MSE} = \\frac{\\tau^4 \\sigma^2 + \\sigma^4 \\sigma_z^2 + \\sigma^4 (\\mu - \\mu_0)^2}{(\\sigma^2 + \\tau^2)^2}$$\n这个表达式表示总均方误差，它由三部分组成：与测量噪声相关的项 $(\\tau^4 \\sigma^2)$，与方差不匹配相关的项 $(\\sigma^4 \\sigma_z^2)$，以及与先验均值不匹配造成的偏差相关的项 $(\\sigma^4 (\\mu - \\mu_0)^2)$，所有这些项都除以内部模型分量方差之和的平方。",
            "answer": "$$\\boxed{\\frac{\\tau^4 \\sigma^2 + \\sigma^4 \\sigma_z^2 + \\sigma^4 (\\mu - \\mu_0)^2}{(\\sigma^2 + \\tau^2)^2}}$$"
        }
    ]
}