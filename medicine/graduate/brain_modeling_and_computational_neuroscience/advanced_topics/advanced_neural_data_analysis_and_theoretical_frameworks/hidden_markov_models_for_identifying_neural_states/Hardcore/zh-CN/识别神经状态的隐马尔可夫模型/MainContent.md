## 引言
在神经科学中，理解大脑如何在不同认知任务中动态切换其功能状态是一个核心挑战。这些“神经状态”是无法直接观测的，但它们会系统性地影响我们记录到的神经活动模式。[隐马尔可夫模型](@entry_id:275059)（Hidden Markov Model, HMM）为从复杂且充满噪声的神经数据中推断这些[隐藏状态](@entry_id:634361)提供了一个强大而富有原则的概率框架。本文旨在解决如何应用HMM来解码大脑动态结构这一问题。

为了实现这一目标，我们将分三部分展开：首先，在“原理与机制”一章中，我们将深入剖析HMM的数学定义、核心假设以及用于参数估计和状态推断的关键算法。接着，在“应用与跨学科联系”一章中，我们将展示HMM如何在神经科学的多个场景中被用于分析不同类型的神经数据，并探讨其与行为的联系以及在遗传学、[气候学](@entry_id:1122484)等其他领域的广泛应用。最后，在“动手实践”部分，我们将通过具体的编程练习来巩固理论知识，帮助读者将HMM付诸实践。

## 原理与机制

本章旨在深入探讨[隐马尔可夫模型](@entry_id:275059)（Hidden Markov Model, HMM）的基本原理与核心机制。我们将从模型的形式化定义出发，阐述其关键的概率假设，进而介绍用于揭示神经状态和估计模型参数的核心算法。最后，我们将讨论HMM的一些根本性质与内在局限性，为后续章节中介绍更高级的模型奠定基础。

### 定义隐马尔可夫模型

隐马尔可夫模型是一个强大的概率时序模型，它假设我们观测到的数据是由一个不可见的、满足[马尔可夫性质](@entry_id:139474)的离散状态[序列生成](@entry_id:635570)的。在[计算神经科学](@entry_id:274500)中，这些隐藏状态可以被诠释为大脑在不同计算任务或认知过程中所处的离散的、功能性的“神经状态”。

一个HMM由以下几个核心要素构成：

1.  **[隐藏状态](@entry_id:634361) (Latent States)**：一个不可观测的状态序列 $\mathbf{z}_{1:T} = \{z_1, z_2, \dots, z_T\}$，其中每个状态 $z_t$ 从一个包含 $K$ 个离散状态的集合 $\{1, 2, \dots, K\}$ 中取值。

2.  **观测变量 (Observations)**：一个可观测的数据序列 $\mathbf{x}_{1:T} = \{x_1, x_2, \dots, x_T\}$。在神经科学应用中，$x_t$ 可以是单个时间窗内记录到的神经元发放的脉冲数量，也可以是多通道记录的群体发放率向量，或者是[局部场电位](@entry_id:1127395)（LFP）的某个特征。

3.  **模型参数 ($\theta$)**：描述模型行为的一组参数，包括：
    *   **初始状态分布 (Initial State Distribution) $\pi$**：一个长度为 $K$ 的向量，其中元素 $\pi_k = p(z_1 = k)$ 表示系统在第一个时刻处于状态 $k$ 的概率。显然，$\sum_{k=1}^K \pi_k = 1$。
    *   **状态转移[概率矩阵](@entry_id:274812) (State Transition Probability Matrix) $A$**：一个 $K \times K$ 的矩阵，其中元素 $A_{ij} = p(z_t = j | z_{t-1} = i)$ 表示系统从状态 $i$ 转移到状态 $j$ 的概率。由于系统必须转移到某个状态，因此该矩阵的每一行之和必须为1，即 $\sum_{j=1}^K A_{ij} = 1$。
    *   **发射概率分布 (Emission Probability Distributions)**：一组概率分布 $\{ p(x_t | z_t = k, \phi_k) \}_{k=1}^K$，其中 $\phi_k$ 是状态 $k$ 对应的发射分布的参数。该分布描述了当系统处于某个隐藏状态 $k$ 时，生成特定观测值 $x_t$ 的概率。

#### 基本假设与概率结构

HMM的强大之处在于其简洁的概率结构，该结构建立在两个核心的[条件独立性](@entry_id:262650)假设之上：

1.  **[马尔可夫性质](@entry_id:139474) (Markov Property)**：隐藏状态序列是一个一阶[马尔可夫链](@entry_id:150828)。这意味着，给定当前时刻 $t-1$ 的状态，未来时刻 $t$ 的状态仅依赖于当前状态，而与所有过去的状态无关。数学上表示为：
    $p(z_t | z_{1:t-1}) = p(z_t | z_{t-1})$
    这个性质极大地简化了状态之间的时序依赖关系，而这种关系完全由[状态转移矩阵](@entry_id:269075) $A$ 所捕捉。

2.  **观测的[条件独立性](@entry_id:262650) (Conditional Independence of Observations)**：在给定当前时刻 $t$ 的[隐藏状态](@entry_id:634361) $z_t$ 的条件下，当前时刻的观测值 $x_t$ 与其他任何时刻的状态或观测值都无关。数学上表示为：
    $p(x_t | \mathbf{z}_{1:T}, \mathbf{x}_{1:t-1}) = p(x_t | z_t)$
    这一假设意味着，观测到的神经活动仅仅是当前潜在神经状态的一种（可能有噪声的）反映。

在这两个假设下，整个数据序列（包括[隐藏状态](@entry_id:634361)和观测值）的联合概率分布可以被分解为一系列更简单的项的乘积。这个分解是所有后续推断和学习算法的基石：
$p(\mathbf{x}_{1:T}, \mathbf{z}_{1:T}) = p(z_1) \left( \prod_{t=2}^T p(z_t | z_{t-1}) \right) \left( \prod_{t=1}^T p(x_t | z_t) \right)$
代入模型参数，我们得到：
$p(\mathbf{x}_{1:T}, \mathbf{z}_{1:T} | \theta) = \pi_{z_1} p(x_1 | \phi_{z_1}) \prod_{t=2}^T A_{z_{t-1}, z_t} p(x_t | \phi_{z_t})$
这个[因子分解](@entry_id:150389)结构清晰地展示了模型的生成过程：首先根据 $\pi$ 采样初始状态 $z_1$，然后生成观测 $x_1$；接着根据 $A$ 从 $z_1$ 转移到 $z_2$，再生成观测 $x_2$，如此循环往复，直至生成整个序列。

与完全可观测的马尔可夫链相比，HMM的关键区别在于其状态是“隐藏”的。在完全可观测的[马尔可夫链](@entry_id:150828)中，状态就是观测值本身（$z_t = x_t$），其[似然函数](@entry_id:921601)为 $p(\mathbf{x}_{1:T}) = p(x_1) \prod_{t=2}^{T} p(x_t | x_{t-1})$。而在HMM中，我们需要通过复杂的推断过程，从观测序列 $\mathbf{x}_{1:T}$ 中恢复出[隐藏状态](@entry_id:634361)序列 $\mathbf{z}_{1:T}$ 的信息。

#### 适用于神经数据的发射模型

发射分布的选择对于模型的成功至关重要，它必须与所分析的神经数据的统计特性相匹配。

*   **泊松HMM (Poisson HMM)**：当观测数据 $x_t$ 是在时间窗 $\Delta t$ 内记录到的神经元脉冲计数时（一个非负整数），泊松分布是一个自然的选择。假设在状态 $k$ 下，神经元的平均发放率为 $\lambda_k$ (单位：spikes/second)，则在一个宽度为 $\Delta t$ 的时间窗内，观测到的脉冲数 $x_t$ 服从均值为 $\lambda_k \Delta t$ 的泊松分布：
    $p(x_t | z_t=k, \lambda_k, \Delta t) = \frac{\exp(-\lambda_k \Delta t) (\lambda_k \Delta t)^{x_t}}{x_t!}$
    对于一个包含 $D$ 个神经元的群体，如果假设给定[隐藏状态](@entry_id:634361)后神经元之间条件独立，则联合发射概率为各自泊松概率的乘积：
    $p(\mathbf{x}_t | z_t=k, \boldsymbol{\lambda}_k, \Delta t) = \prod_{d=1}^D \frac{\exp(-\lambda_{k,d} \Delta t) (\lambda_{k,d} \Delta t)^{x_{t,d}}}{x_{t,d}!}$
    其中 $\mathbf{x}_t \in \mathbb{N}^D$ 是 $D$ 个神经元的脉冲计数向量，$\boldsymbol{\lambda}_k \in \mathbb{R}_{>0}^D$ 是状态 $k$ 对应的发放率向量。

*   **高斯HMM (Gaussian HMM)**：当观测数据是连续的，例如多神经元发放率向量 $x_t \in \mathbb{R}^d$ 或LFP信号的特征时，多元高斯分布是常用的发射模型。每个状态 $k$ 都与一个特定的[均值向量](@entry_id:266544) $\mu_k$ 和协方差矩阵 $\Sigma_k$ 相关联：
    $p(x_t | z_t=k, \mu_k, \Sigma_k) = \mathcal{N}(x_t | \mu_k, \Sigma_k)$
    其中 $\mu_k$ 捕捉了状态 $k$ 下神经活动的平均模式，而 $\Sigma_k$ 则描述了该状态下群体活动的变异性及神经元之间的协同变化模式。

### 核心计算问题：推断与学习

在定义了HMM之后，我们需要解决两个核心的计算问题：
1.  **推断 (Inference)**：给定模型参数 $\theta$ 和观测序列 $\mathbf{x}_{1:T}$，如何推断出[隐藏状态](@entry_id:634361)序列 $\mathbf{z}_{1:T}$ 的性质？
2.  **学习 (Learning)**：给定观测序列 $\mathbf{x}_{1:T}$，如何估计出最优的模型参数 $\theta$？

#### 推断：揭示[隐藏状态](@entry_id:634361)

推断的核心目标是计算关于[隐藏状态](@entry_id:634361)的后验概率分布。主要有两种推断任务：

*   **滤波 (Filtering)**：计算在时刻 $t$ 的**滤波[后验概率](@entry_id:153467)** $p(z_t | \mathbf{x}_{1:t})$。这表示利用截至当前时刻的所有观测信息，来估计当前最可能处于哪个状态。该任务在需要实时解码神经状态的在线应用（如脑机接口）中至关重要。

*   **平滑 (Smoothing)**：计算在时刻 $t$ 的**平滑后验概率** $p(z_t | \mathbf{x}_{1:T})$。这表示利用整个实验记录的全部观测信息（包括过去、现在和未来）来估计在任一时刻 $t$ 的状态。由于利用了更全面的信息，平滑估计通常比滤波估计更准确，因此是神经数据离线分析的标准方法。

这两种推断任务都可以通过一种名为**[前向-后向算法](@entry_id:194772) (Forward-Backward algorithm)** 的高效动态规划方法来精确求解。该算法的核心是计算两个中间变量：

*   **前向变量 (Forward variable)** $\alpha_t(k)$：定义为在给定模型参数的条件下，观测到序列 $\mathbf{x}_{1:t}$ 并且在时刻 $t$ 处于状态 $k$ 的联合概率：
    $\alpha_t(k) = p(\mathbf{x}_{1:t}, z_t=k)$
    $\alpha_t(k)$ 可以通过一个高效的递归过程从 $\alpha_{t-1}(j)$ 计算得到，它有效地“吸收”了从开始到时刻 $t$ 的所有观测信息。

*   **后向变量 (Backward variable)** $\beta_t(k)$：定义为在给定时刻 $t$ 处于状态 $k$ 的条件下，观测到未来序列 $\mathbf{x}_{t+1:T}$ 的条件概率：
    $\beta_t(k) = p(\mathbf{x}_{t+1:T} | z_t=k)$
    $\beta_t(k)$ 同样可以通过一个从后向前的递归过程计算得到，它有效地“汇集”了从结尾到时刻 $t$ 的所有未来证据。

一旦我们计算出所有时刻和状态的前向与后向变量，平滑后验概率（也常用 $\gamma_t(k)$ 表示）就可以通过它们的乘积简单地得到。根据[条件概率](@entry_id:151013)的定义和HMM的独立性假设，我们可以推导出：
$p(z_t=k | \mathbf{x}_{1:T}) = \frac{p(z_t=k, \mathbf{x}_{1:T})}{p(\mathbf{x}_{1:T})} = \frac{p(\mathbf{x}_{1:t}, z_t=k) p(\mathbf{x}_{t+1:T} | z_t=k, \mathbf{x}_{1:t})}{p(\mathbf{x}_{1:T})}$
利用HMM的[条件独立性](@entry_id:262650)，$p(\mathbf{x}_{t+1:T} | z_t=k, \mathbf{x}_{1:t}) = p(\mathbf{x}_{t+1:T} | z_t=k)$。因此，分子就是 $\alpha_t(k) \beta_t(k)$。分母是整个观测序列的边缘概率，可以通过对所有状态求和来获得归一化：
$\gamma_t(k) = p(z_t=k | \mathbf{x}_{1:T}) = \frac{\alpha_t(k) \beta_t(k)}{\sum_{j=1}^K \alpha_t(j) \beta_t(j)}$
这个公式优雅地结合了来自过去的信息（由 $\alpha_t(k)$ 编码）和来自未来的信息（由 $\beta_t(k)$ 编码），从而给出对时刻 $t$ 状态的最优估计。相比之下，滤波后验只使用了前向变量：$p(z_t=k | \mathbf{x}_{1:t}) = \frac{\alpha_t(k)}{\sum_{j=1}^K \alpha_t(j)}$。[前向-后向算法](@entry_id:194772)的计算复杂度为 $\mathcal{O}(TK^2)$，这对于典型的神经科学数据集来说是完全可行的。 

#### 学习：估计模型参数

在大多数实际应用中，我们并不知道模型的真实参数 $\theta$。**期望-最大化 (Expectation-Maximization, EM)** 算法是用于从数据中学习HMM参数的标准方法。[EM算法](@entry_id:274778)是一个迭代过程，它在两个步骤之间交替进行，直到参数收敛：

*   **E-步 (Expectation Step)**：在给定当前[参数估计](@entry_id:139349) $\theta^{\text{old}}$ 和观测数据 $\mathbf{x}_{1:T}$ 的情况下，计算隐藏变量的后验分布。对于HMM，这主要意味着运行[前向-后向算法](@entry_id:194772)来计算所有需要的期望统计量，尤其是平滑后验状态占据率 $\gamma_t(k) = p(z_t=k | \mathbf{x}_{1:T}, \theta^{\text{old}})$ 和状态转移[后验概率](@entry_id:153467) $\xi_t(i,j) = p(z_{t-1}=i, z_t=j | \mathbf{x}_{1:T}, \theta^{\text{old}})$。

*   **M-步 (Maximization Step)**：利用E-步计算出的期望统计量，更新模型参数 $\theta$，以最大化**期望[完全数](@entry_id:636981)据对数似然** (expected complete-data log-likelihood)。这个[目标函数](@entry_id:267263) $Q(\theta | \theta^{\text{old}})$ 的形式为：
    $Q(\theta | \theta^{\text{old}}) = \mathbb{E}_{\mathbf{z}_{1:T} | \mathbf{x}_{1:T}, \theta^{\text{old}}}[\ln p(\mathbf{x}_{1:T}, \mathbf{z}_{1:T} | \theta)]$
    幸运的是，对于HMM中的标准参数（初始分布、转移矩阵和发射分布参数），M-步的更新通常有解析解。这些解往往具有非常直观的加权平均形式。

让我们以两种常见的发射模型为例，推导其M-步更新规则：

**泊松HMM的M-步更新**
对于泊松发射模型，我们希望找到最大化 $Q$ 函数的发射率 $\lambda_k$。只考虑与 $\lambda_k$ 相关的项，目标函数简化为：
$Q_k(\lambda_k) = \sum_{t=1}^T \gamma_t(k) \ln p(x_t | z_t=k, \lambda_k) = \sum_{t=1}^T \gamma_t(k) (-\lambda_k \Delta t + x_t \ln(\lambda_k \Delta t) - \ln(x_t!))$
对 $\lambda_k$ 求导并令其为零，可以解出更新后的 $\lambda_k^{\text{new}}$：
$\lambda_k^{\text{new}} = \frac{\sum_{t=1}^T \gamma_t(k) x_t}{(\sum_{t=1}^T \gamma_t(k)) \Delta t}$
这个结果非常直观：新的发放率是“期望总脉冲数”（分子）除以“期望总[停留时间](@entry_id:263953)”（分母）。分子是将每个时间窗的脉冲数 $x_t$ 用其属于状态 $k$ 的概率 $\gamma_t(k)$ 进行加权求和。分母则是将状态 $k$ 的期望占据时长（以时间窗数为单位）乘以每个时间窗的宽度 $\Delta t$。$\Delta t$ 的存在确保了我们估计的是一个具有物理意义的、与时间窗选择无关的“率”（spikes/second）。

**高斯HMM的M-步更新**
对于高斯发射模型，我们需要更新均值 $\mu_k$ 和协方差 $\Sigma_k$。同样，我们最大化 $Q$ 函数中与这些参数相关的部分。对 $\mu_k$ 和 $\Sigma_k$ 分别求导并设为零，可以得到如下更新规则：
$\mu_k^{\text{new}} = \frac{\sum_{t=1}^T \gamma_t(k) x_t}{\sum_{t=1}^T \gamma_t(k)}$
$\Sigma_k^{\text{new}} = \frac{\sum_{t=1}^T \gamma_t(k) (x_t - \mu_k^{\text{new}})(x_t - \mu_k^{\text{new}})^\top}{\sum_{t=1}^T \gamma_t(k)}$
同样，这些更新规则也具有直观的解释。新的均值 $\mu_k^{\text{new}}$ 是对所有数据点 $x_t$ 的加权平均，权重为该数据点由状态 $k$ 生成的后验概率 $\gamma_t(k)$。类似地，新的协方差 $\Sigma_k^{\text{new}}$ 是对每个状态的加权样本协方差。这与为[高斯混合模型](@entry_id:634640)（GMM）推导出的EM更新规则完全类似。

### 基本性质与局限性

虽然HMM是一个非常强大的工具，但理解其内在的性质和固有的局限性对于正确应用和[解释模型](@entry_id:925527)至关重要。

#### 可辨识性与[标签切换](@entry_id:751100)

HMM的一个根本性质是**[标签切换](@entry_id:751100) (label switching)** 的非[可辨识性](@entry_id:194150)。这意味着，我们可以任意地置换（或重新标记）模型的 $K$ 个[隐藏状态](@entry_id:634361)，并相应地调整模型参数，而不会改变模型所产生的观测数据的任何统计特性。

具体来说，给定一个参数集 $\theta = (\pi, A, \{\phi_k\}_{k=1}^K)$ 和一个对状态标签 $\{1, \dots, K\}$ 的任意置换 $\sigma$，我们可以定义一个新的参数集 $\theta'$，其中状态 $k$ 的角色由原先的状态 $\sigma(k)$ 扮演。通过矩阵运算，这个变换可以表示为 $\pi' = P\pi$, $A' = PAP^\top$, 以及 $\phi'_k = \phi_{\sigma^{-1}(k)}$，其中 $P$ 是对应于置换 $\sigma$ 的[置换矩阵](@entry_id:136841)。可以严格证明，对于任何观测序列 $\mathbf{x}_{1:T}$，其边缘[似然函数](@entry_id:921601)在这种变换下保持不变：
$p(\mathbf{x}_{1:T} | \theta) = p(\mathbf{x}_{1:T} | \theta')$
这是因为将联合概率 $p(\mathbf{x}_{1:T}, \mathbf{z}_{1:T} | \theta)$ 对所有可能的[隐藏状态](@entry_id:634361)路径 $\mathbf{z}_{1:T}$ 求和时，求和的操作对于路径中状态标签的任意一致性重命名是不变的。

[标签切换](@entry_id:751100)带来了几个重要的实际后果：
1.  **参数非唯一性**：[最大似然估计](@entry_id:142509)（如[EM算法](@entry_id:274778)）的解不是唯一的。算法收敛到的参数解取决于其初始化，但所有这些解都对应于同一个似然值，并且只是彼此的置换版本。
2.  **[贝叶斯推断](@entry_id:146958)的挑战**：在贝叶斯框架下，如果[先验分布](@entry_id:141376)对于状态标签是可交换的，那么后验分布 $p(\theta | \mathbf{x}_{1:T})$ 将会有 $K!$ 个对称的模式（modes）。这会导致[MCMC采样](@entry_id:751801)器难以在这些模式之间有效移动（混合不良），从而使得对单个参数（如状态1的平均发放率 $\lambda_1$）的后验估计变得无意义。
3.  **解决方案**：为了获得唯一的[参数估计](@entry_id:139349)并促进解释，通常需要施加**[可辨识性](@entry_id:194150)约束 (identifiability constraint)**。例如，我们可以对发射分布的某个参数进行排序，如要求高斯模型的均值满足 $\mu_1  \mu_2  \dots  \mu_K$。这样的约束从每个[等价类](@entry_id:156032)中选择一个唯一的代表，从而“打破”了[标签切换](@entry_id:751100)的对称性，而不会改变模型能够表达的[似然函数](@entry_id:921601)集合。

虽然[标签切换](@entry_id:751100)使得单个状态的参数无法唯一确定，但模型的**预测**（如[后验预测分布](@entry_id:167931) $p(x_{T+1} | \mathbf{x}_{1:T})$）以及对状态参数的**[可交换性](@entry_id:909050)总结**（如所有状态的平均发放率的均值）在[贝叶斯推断](@entry_id:146958)中是良定义且不受影响的，因为这些量在求积分或求和时会自动消除标签的模糊性。

更深层次的**[参数可辨识性](@entry_id:197485)**（在标签置换的意义下）问题，即我们是否能够从无限多的数据中唯一地恢复出参数集合，也至关重要。理论研究表明，HMM参数的可辨识性通常需要满足以下条件：
*   所有状态的发射分布 $p(x|\phi_k)$ 必须是两两不同的，并且作为函数是[线性无关](@entry_id:148207)的。
*   [状态转移矩阵](@entry_id:269075) $A$ 必须是“非简并”的（例如，具有满秩）。
如果这些条件不满足，例如两个状态具有完全相同的发射分布，那么即使它们有不同的[转移特性](@entry_id:1133302)，也无法从观测数据中将它们区分开来。在实践中，即使发射分布不完全相同但高度重叠，也会导致模型的Fisher[信息矩阵](@entry_id:750640)接近奇异，使得参数估计变得非常困难（即所谓的“实践上的[不可辨识性](@entry_id:1128800)”）。

#### 隐含的驻留时间分布

标准HMM的一个重要但常被忽视的特性是其对状态**驻留时间 (dwell time)** 的隐含假设。驻留时间 $D_k$ 指的是系统进入状态 $k$ 后，连续停留在该状态的时步数。

由于HMM的[马尔可夫性质](@entry_id:139474)，每次在状态 $k$ 时，系统在下一时刻离开该状态的概率是一个常数，即 $1 - A_{kk}$，这个概率与系统已经停留在该状态多久无关。这种“无记忆”的特性导致状态 $k$ 的驻留时间 $D$ 必然服从**[几何分布](@entry_id:154371) (geometric distribution)**：
$p(D = d | \text{进入状态 } k) = (A_{kk})^{d-1}(1 - A_{kk}), \quad d = 1, 2, \dots$
该分布的期望驻留时间为 $\mathbb{E}[D] = \frac{1}{1 - A_{kk}}$。

[几何分布](@entry_id:154371)的尾部呈指数衰减，这意味着非常长的驻留时间出现的概率极低。然而，许多生物和物理系统，包括大脑网络，都表现出比指数衰减慢得多的“[重尾](@entry_id:274276)” (heavy-tailed) 驻留时间分布。神经状态可能表现出“[亚稳态](@entry_id:167515)” (metastability)，即在某个状态停留的时间长度具有很大的变异性，有时很短，有时则异常地长。标准HMM的几何驻留时间假设无法捕捉这种复杂的动力学。

为了克服这一局限性，研究者们提出了多种HMM的扩展，其中最著名的是**隐半[马尔可夫模型](@entry_id:899700) (Hidden Semi-Markov Model, HSMM)**。在HSMM中，几何驻留时间分布被一个显式的、更灵活的概率分布（如负二项分布、对数正态分布或非参数分布）所取代，从而能够更好地模拟神经状态的持续性。

#### 离散状态的合理性：与连续状态模型的对比

在对神经活动进行建模时，一个基本问题是：潜在的动力学过程应该用离散状态、连续状态，还是两者结合来描述？HMM正是离散状态模型的代表。与之相对的是**[线性动力系统](@entry_id:1127277) (Linear Dynamical System, LDS)**，它使用连续的潜在变量来捕捉神经活动的平滑演化。

一个关键的区别在于它们所能产生的[预测分布](@entry_id:165741)的形状。在一个标准的LDS中，由于所有变换都是线性的，所有噪声都是高斯的，因此其一步预测分布 $p(x_t | x_{1:t-1})$ 必然是**单峰的 (unimodal)** 高斯分布。

然而，如果神经系统确实在不同的、功能上分离的“模式”或“状态”之间切换，我们期望观测到的活动数据会呈现出多峰结构。例如，在对一个LDS进行[模型诊断](@entry_id:136895)时，如果发现其预测残差（观测值与预测值之差）呈现出强烈的双峰或多峰分布，这就强烈暗示了单个[线性高斯模型](@entry_id:268963)不足以描述数据，数据的生成过程很可能涉及离散的切换机制。

在这种情况下，一个包含离散切换状态的模型，如HMM或更一般的**切换[线性动力系统](@entry_id:1127277) (Switching Linear Dynamical System, SLDS)**，是更合适的选择。在这些模型中，通过对离散的[隐藏状态](@entry_id:634361)进行[边缘化](@entry_id:264637)，可以得到一个**[高斯混合模型](@entry_id:634640) (mixture of Gaussians)** 形式的[预测分布](@entry_id:165741)：
$p(x_t | x_{1:t-1}) = \sum_{k=1}^K w_{t,k} \mathcal{N}(x_t | \mu_{t,k}, \Sigma_{t,k})$
这种[混合分布](@entry_id:276506)能够灵活地捕捉和生成多峰数据。因此，观测到多峰的预测残差不仅是诊断简单模型失效的有力证据，也为采用HMM这类具有离散潜在结构的模型的合理性提供了有力支持。