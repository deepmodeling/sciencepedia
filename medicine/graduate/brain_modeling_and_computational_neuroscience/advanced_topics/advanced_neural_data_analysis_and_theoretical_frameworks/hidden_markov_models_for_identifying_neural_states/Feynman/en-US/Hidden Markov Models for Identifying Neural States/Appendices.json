{
    "hands_on_practices": [
        {
            "introduction": "Before we build complex inference machinery, it is crucial to develop an intuition for what the parameters of a Hidden Markov Model signify. This first practice  explores the direct and powerful link between the self-transition probabilities $A_{kk}$ in the transition matrix and the expected 'dwell time' of a latent neural state. Understanding this relationship is a key first step toward interpreting a trained model's behavior and assessing its scientific plausibility.",
            "id": "3987987",
            "problem": "Consider a discrete-time Hidden Markov Model (HMM) for latent neural states in a cortical population recorded in fixed-width time bins. Let the latent process be a time-homogeneous Markov chain with three states $k \\in \\{1,2,3\\}$ and transition matrix $A$, where $A_{kk}$ denotes the self-transition probability of remaining in state $k$ at the next time bin. Assume that $0  A_{kk}  1$ for all $k$, and that all non-self transition probabilities are strictly positive and sum with $A_{kk}$ to $1$. You observe contiguous runs of the same latent state and define the dwell time $d_{k}$ for state $k$ as the number of consecutive time bins spent in state $k$ starting from the time of entry until the first exit to a different state.\n\nUsing only the Markov property and time-homogeneity of the chain, derive the probability mass function of $d_{k}$ in terms of $A_{kk}$. Then, for a model with self-transition probabilities $A_{11}=0.95$, $A_{22}=0.90$, and $A_{33}=0.85$, compute the expected dwell time $E[d_{k}]$ for each state $k \\in \\{1,2,3\\}$. Express the expected durations in time bins. Provide your final numerical answers as exact values without rounding and present them in a single row vector. No additional assumptions about emissions or observation noise are needed. The final answer must be a single calculation result and must not include units inside the final boxed expression.",
            "solution": "The problem statement is validated as scientifically grounded, well-posed, and objective. It provides a clear, self-contained, and formalizable task based on standard principles of Markov chain theory as applied in computational neuroscience. All necessary data and definitions are provided, and there are no contradictions, ambiguities, or factual errors.\n\nThe problem asks for two results: first, the derivation of the probability mass function (PMF) of the dwell time $d_k$ in a latent neural state $k$, and second, the calculation of the expected dwell time $E[d_k]$ for three specific states.\n\nLet the latent process be a time-homogeneous Markov chain with states $S_t \\in \\{1, 2, 3\\}$ at time $t$. The transition probability from state $i$ to state $j$ is $A_{ij} = P(S_{t+1}=j|S_t=i)$. The self-transition probability for state $k$ is $A_{kk}$.\n\nThe dwell time $d_k$ for a state $k$ is defined as the number of consecutive time bins spent in that state, starting from the time of entry. Let us assume the system enters state $k$ at time $t_0$. The event $\\{d_k = m\\}$, for $m \\in \\{1, 2, 3, \\dots\\}$, corresponds to the sequence of states where the system is in state $k$ for $m$ time bins and then transitions to a different state. This means $S_{t_0} = k, S_{t_0+1} = k, \\dots, S_{t_0+m-1} = k$, and $S_{t_0+m} \\neq k$.\n\nDue to the time-homogeneous Markov property, the probability of this sequence of events is the product of the probabilities of the individual transitions:\n$$ P(d_k = m) = P(S_{t_0+1}=k|S_{t_0}=k) \\times \\dots \\times P(S_{t_0+m-1}=k|S_{t_0+m-2}=k) \\times P(S_{t_0+m} \\neq k|S_{t_0+m-1}=k) $$\nThe probability of remaining in state $k$ is $A_{kk}$. The probability of exiting state $k$ is $1 - A_{kk}$, since the outgoing probabilities from any state must sum to $1$. The event $\\{d_k = m\\}$ consists of $m-1$ successful self-transitions followed by one transition to a different state.\nThus, the probability is:\n$$ P(d_k = m) = (A_{kk})^{m-1} (1 - A_{kk}) $$\nThis is the probability mass function for $d_k$. This is a geometric distribution on the set $\\{1, 2, 3, \\dots\\}$ with a success parameter $p = 1 - A_{kk}$, where \"success\" is defined as exiting the state.\n\nNext, we derive the expected dwell time, $E[d_k]$. By definition, the expected value of a discrete random variable is the sum of each value multiplied by its probability:\n$$ E[d_k] = \\sum_{m=1}^{\\infty} m \\cdot P(d_k = m) = \\sum_{m=1}^{\\infty} m (A_{kk})^{m-1} (1 - A_{kk}) $$\nWe can factor out the constant term $(1 - A_{kk})$:\n$$ E[d_k] = (1 - A_{kk}) \\sum_{m=1}^{\\infty} m (A_{kk})^{m-1} $$\nThe summation is a standard result from the analysis of geometric series. For any variable $x$ such that $|x|  1$, the geometric series formula is $\\sum_{m=0}^{\\infty} x^m = \\frac{1}{1-x}$. Differentiating both sides with respect to $x$ yields:\n$$ \\frac{d}{dx} \\sum_{m=0}^{\\infty} x^m = \\sum_{m=1}^{\\infty} m x^{m-1} = \\frac{d}{dx} \\left( \\frac{1}{1-x} \\right) = \\frac{1}{(1-x)^2} $$\nSince the problem specifies $0  A_{kk}  1$, we can substitute $x = A_{kk}$ into this result:\n$$ \\sum_{m=1}^{\\infty} m (A_{kk})^{m-1} = \\frac{1}{(1 - A_{kk})^2} $$\nSubstituting this back into the expression for $E[d_k]$:\n$$ E[d_k] = (1 - A_{kk}) \\left( \\frac{1}{(1 - A_{kk})^2} \\right) = \\frac{1}{1 - A_{kk}} $$\nThis is the general expression for the expected dwell time in state $k$.\n\nFinally, we apply this formula to compute the expected dwell times for each state, given the self-transition probabilities $A_{11}=0.95$, $A_{22}=0.90$, and $A_{33}=0.85$.\n\nFor state $k=1$:\n$$ E[d_1] = \\frac{1}{1 - A_{11}} = \\frac{1}{1 - 0.95} = \\frac{1}{0.05} = 20 $$\n\nFor state $k=2$:\n$$ E[d_2] = \\frac{1}{1 - A_{22}} = \\frac{1}{1 - 0.90} = \\frac{1}{0.10} = 10 $$\n\nFor state $k=3$:\n$$ E[d_3] = \\frac{1}{1 - A_{33}} = \\frac{1}{1 - 0.85} = \\frac{1}{0.15} = \\frac{1}{\\frac{15}{100}} = \\frac{100}{15} = \\frac{20}{3} $$\n\nThe expected dwell times are $20$, $10$, and $\\frac{20}{3}$ time bins for states $1$, $2$, and $3$, respectively. These are to be presented in a single row vector.",
            "answer": "$$\n\\boxed{\\begin{pmatrix} 20  10  \\frac{20}{3} \\end{pmatrix}}\n$$"
        },
        {
            "introduction": "A central application of HMMs in neuroscience is to infer the sequence of hidden states that likely gave rise to an observed pattern of neural activity. This exercise  guides you through the implementation of the forward-backward algorithm, the canonical method for solving this 'smoothing' problem. By computing the posterior probability of each latent state at every time point given the entire observation sequence, you will be implementing a fundamental tool for neural decoding and analysis.",
            "id": "3987985",
            "problem": "You are given several small Hidden Markov Models (HMMs) tailored to discrete-time latent neural state identification. Each HMM has a finite set of latent states $\\{1,\\dots,K\\}$, an initial state distribution $\\pi$, a state transition matrix $A$, and a categorical emission model with probabilities arranged as a matrix $B$, where $B_{k,m} = p(x_t = m \\mid z_t = k)$. You will implement the forward-backward algorithm to compute the posterior distribution over the latent state at time index $t=2$ (i.e., $z_2$) given the entire observation sequence $x_{1:4}$. Your program should output the posterior distribution $p(z_2 = k \\mid x_{1:4})$ for each state index $k$ in the ordering $k=1,\\dots,K$ for each test case.\n\nUse only the following fundamental base:\n- The joint distribution of an HMM factorizes as $p(z_{1:T}, x_{1:T}) = p(z_1)\\prod_{t=2}^{T} p(z_t\\mid z_{t-1}) \\prod_{t=1}^{T} p(x_t\\mid z_t)$.\n- The Markov property: $p(z_t \\mid z_{1:t-1}) = p(z_t \\mid z_{t-1})$ and conditional independence of observations: $p(x_t \\mid z_{1:T}, x_{1:t-1}) = p(x_t \\mid z_t)$.\n- Bayes’ rule and the sum-product principle for exact inference on chains.\n\nYou must design your computation to be numerically stable for long sequences and small probabilities by employing explicit scaling of messages or a log-domain equivalent. For this problem, you must implement scaled forward-backward with per-time scaling constants to prevent numerical underflow. Do not rely on external black-box HMM toolkits.\n\nDefinitions and conventions:\n- Time indices are $t=1,2,3,4$.\n- The state space size is $K$ and the observation alphabet size is $M$ for each test case (both given below).\n- The initial distribution $\\pi$ is a length-$K$ vector with entries $\\pi_k = p(z_1 = k)$ in the order $k=1,\\dots,K$.\n- The transition matrix $A$ is $K \\times K$ with entries $A_{i,j} = p(z_t=j \\mid z_{t-1}=i)$.\n- The emission matrix $B$ is $K \\times M$ with entries $B_{k,m} = p(x_t = m \\mid z_t = k)$, where observation symbols are integers in $\\{0,1,\\dots,M-1\\}$.\n- The observed sequence is $x_{1:4} = (x_1,x_2,x_3,x_4)$, given explicitly per test case.\n\nYour task for each test case:\n- Compute the posterior vector $\\gamma_2$ with components $\\gamma_2(k) = p(z_2 = k \\mid x_{1:4})$ for $k=1,\\dots,K$ using scaled forward-backward messages derived from the HMM factorization and sum-product principle. Ensure the final vector is normalized so that $\\sum_{k=1}^{K} \\gamma_2(k) = 1$ up to numerical precision.\n\nTest suite:\n- All numbers below are probabilities and must be used exactly as given. Each test is independent and must be run as specified.\n\nTest case $1$:\n- $K=2$, $M=3$.\n- $\\pi = [\\,0.6,\\,0.4\\,]$.\n- $A = \\begin{pmatrix} 0.7  0.3 \\\\ 0.2  0.8 \\end{pmatrix}$.\n- $B = \\begin{pmatrix} 0.5  0.4  0.1 \\\\ 0.1  0.3  0.6 \\end{pmatrix}$.\n- $x_{1:4} = (2,\\,1,\\,0,\\,1)$.\n\nTest case $2$:\n- $K=3$, $M=3$.\n- $\\pi = [\\,0.2,\\,0.5,\\,0.3\\,]$.\n- $A = \\begin{pmatrix} 0.90  0.09  0.01 \\\\ 0.05  0.90  0.05 \\\\ 0.02  0.08  0.90 \\end{pmatrix}$.\n- $B = \\begin{pmatrix} 0.6  0.3  0.1 \\\\ 0.2  0.5  0.3 \\\\ 0.1  0.2  0.7 \\end{pmatrix}$.\n- $x_{1:4} = (0,\\,2,\\,1,\\,2)$.\n\nTest case $3$ (tests underflow handling by using very small probabilities):\n- $K=2$, $M=2$.\n- $\\pi = [\\,0.001,\\,0.999\\,]$.\n- $A = \\begin{pmatrix} 0.0001  0.9999 \\\\ 0.00001  0.99999 \\end{pmatrix}$.\n- $B = \\begin{pmatrix} 0.001  0.999 \\\\ 0.999999  0.000001 \\end{pmatrix}$.\n- $x_{1:4} = (1,\\,1,\\,0,\\,1)$.\n\nTest case $4$:\n- $K=3$, $M=4$.\n- $\\pi = [\\,\\tfrac{1}{3},\\,\\tfrac{1}{3},\\,\\tfrac{1}{3}\\,]$.\n- $A = \\begin{pmatrix} 0.6  0.3  0.1 \\\\ 0.2  0.5  0.3 \\\\ 0.25  0.25  0.5 \\end{pmatrix}$.\n- $B = \\begin{pmatrix} 0.25  0.25  0.25  0.25 \\\\ 0.1  0.2  0.3  0.4 \\\\ 0.4  0.3  0.2  0.1 \\end{pmatrix}$.\n- $x_{1:4} = (3,\\,2,\\,1,\\,0)$.\n\nOutput specification:\n- For each test case, output the posterior vector $\\left[\\,\\gamma_2(1),\\,\\gamma_2(2),\\,\\dots,\\,\\gamma_2(K)\\,\\right]$ in the state order $k=1,\\dots,K$.\n- Round each component to exactly $6$ decimal places.\n- Aggregate all test case outputs into a single line as a list of lists with no extra whitespace, for example: $\\texttt{[[a\\_1,\\dots,a\\_K],[b\\_1,\\dots,b\\_K],\\dots]}$.\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, exactly in the format above.\n\nNo physical units or angles are involved. All answers must be pure numbers rounded as specified. Ensure scientific realism by respecting probability constraints, correct normalization, and numerical stability via scaling. The final program must be entirely self-contained and require no input.",
            "solution": "The user wants to compute the posterior distribution over a latent state in a Hidden Markov Model (HMM) at a specific time step, given a sequence of observations. The problem is well-defined and requires the implementation of the forward-backward algorithm, specifically with scaling to ensure numerical stability.\n\n### Step 1: Extract Givens\nThe problem provides the following data for several test cases:\n- A set of latent states $\\{1, \\dots, K\\}$.\n- An initial state distribution vector $\\pi$ of length $K$, where $\\pi_k = p(z_1 = k)$.\n- A $K \\times K$ state transition matrix $A$, where $A_{i,j} = p(z_t=j \\mid z_{t-1}=i)$.\n- A $K \\times M$ emission matrix $B$, where $B_{k,m} = p(x_t = m \\mid z_t = k)$.\n- An observation sequence $x_{1:4} = (x_1, x_2, x_3, x_4)$ of length $T=4$.\n- The specific task is to compute the posterior distribution $\\gamma_2(k) = p(z_2=k \\mid x_{1:4})$ for each state $k=1,\\dots,K$.\n- Time indices are specified as $t=1,2,3,4$. Observation symbols are integers $\\{0, \\dots, M-1\\}$.\n- Four test cases with specific parameters for $K, M, \\pi, A, B,$ and $x_{1:4}$ are provided.\n\n### Step 2: Validate Using Extracted Givens\n- **Scientifically Grounded**: The problem is based on the theory of Hidden Markov Models, a cornerstone of statistical modeling in various STEM fields. The factorization $p(z_{1:T}, x_{1:T}) = p(z_1)\\prod_{t=2}^{T} p(z_t\\mid z_{t-1}) \\prod_{t=1}^{T} p(x_t\\mid z_t)$ is the standard definition of an HMM's joint distribution. The task, computing a smoothed posterior $p(z_t \\mid x_{1:T})$, is a fundamental inference problem solvable by the forward-backward algorithm. The provided probability parameters in $\\pi, A,$ and $B$ for all test cases are valid (non-negative and rows sum to $1$). The problem is scientifically sound.\n- **Well-Posed**: The problem is well-posed. Given a fully specified HMM and an observation sequence, the forward-backward algorithm provides a unique and stable method for computing the required posterior probabilities.\n- **Objective**: The problem is stated with mathematical precision, using standard notation and providing exact numerical values. There are no subjective or ambiguous elements.\n- **Completeness**: All necessary information ($\\pi, A, B, x_{1:4}$) is provided for each test case.\n- **Numerical Stability**: The problem correctly identifies the potential for numerical underflow with long sequences or small probabilities and explicitly requests a scaled implementation of the forward-backward algorithm, which is the standard and correct approach to this challenge.\n\n### Step 3: Verdict and Action\nThe problem is valid. It is a well-defined, scientifically grounded task in computational statistics. I will now proceed with deriving and implementing the solution.\n\n### Algorithmic Solution: The Scaled Forward-Backward Algorithm\n\nThe goal is to compute the posterior state distribution (smoothing distribution) $\\gamma_t(k) = p(z_t=k \\mid x_{1:T})$. This can be expressed using forward and backward messages:\n$$\n\\gamma_t(k) = \\frac{p(z_t=k, x_{1:T})}{p(x_{1:T})} = \\frac{\\alpha_t(k) \\beta_t(k)}{\\sum_{j=1}^K \\alpha_t(j) \\beta_t(j)}\n$$\nwhere $\\alpha_t(k) = p(z_t=k, x_{1:t})$ is the forward message and $\\beta_t(k) = p(x_{t+1:T} \\mid z_t=k)$ is the backward message. Direct computation of these messages can lead to numerical underflow. We will use a scaled version of the algorithm.\n\n**1. Scaled Forward Pass**\n\nWe define scaled forward messages $\\hat{\\alpha}_t(k) = p(z_t=k \\mid x_{1:t})$ and scaling constants $c_t = p(x_t \\mid x_{1:t-1})$.\n\n- **Initialization ($t=1$):**\n  The unscaled message is $\\alpha_1(k) = p(z_1=k, x_1) = \\pi_k B_{k, x_1}$.\n  The first scaling constant is $c_1 = p(x_1) = \\sum_{j=1}^K \\alpha_1(j)$.\n  The scaled message is $\\hat{\\alpha}_1(k) = \\frac{\\alpha_1(k)}{c_1}$.\n\n- **Recursion ($t=2, \\dots, T$):**\n  The unscaled message for step $t$ is computed from the scaled message of step $t-1$:\n  $$\n  \\alpha'_t(j) = \\left( \\sum_{i=1}^K \\hat{\\alpha}_{t-1}(i) A_{i,j} \\right) B_{j, x_t}\n  $$\n  The scaling constant for step $t$ is $c_t = \\sum_{j=1}^K \\alpha'_t(j)$.\n  The scaled message is $\\hat{\\alpha}_t(j) = \\frac{\\alpha'_t(j)}{c_t}$.\n\nWe will compute and store the vectors $\\hat{\\alpha}_t$ and scalars $c_t$ for all $t=1, \\dots, 4$. For this problem, we only need $\\hat{\\alpha}_2$.\n\n**2. Scaled Backward Pass**\n\nWe define scaled backward messages $\\hat{\\beta}_t(k)$ that are scaled using the same constants $c_t$ from the forward pass.\n\n- **Initialization ($t=T=4$):**\n  The unscaled message $\\beta_T(k) = 1$ for all $k$. We define the scaled message $\\hat{\\beta}_T(k) = 1$.\n\n- **Recursion ($t=T-1, \\dots, 1$):**\n  The recursion for the scaled backward message is derived as:\n  $$\n  \\hat{\\beta}_t(i) = \\frac{1}{c_{t+1}} \\sum_{j=1}^K A_{i,j} B_{j, x_{t+1}} \\hat{\\beta}_{t+1}(j)\n  $$\n  We need to compute this for $t=3, 2, 1$ to obtain $\\hat{\\beta}_2$.\n\n**3. Posterior Calculation**\n\nThe unnormalized posterior is given by the product of the corresponding scaled forward and backward messages:\n$$\n\\gamma_t(k) \\propto \\hat{\\alpha}_t(k) \\hat{\\beta}_t(k)\n$$\nThe product is then normalized to ensure it sums to $1$. For this problem, we need to compute $\\gamma_2(k)$ for $k=1, \\dots, K$:\n$$\n\\gamma_2(k) = \\frac{\\hat{\\alpha}_2(k) \\hat{\\beta}_2(k)}{\\sum_{j=1}^K \\hat{\\alpha}_2(j) \\hat{\\beta}_2(j)}\n$$\n\nThis procedure is followed for each test case to obtain the required posterior distributions for $z_2$.",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to solve the HMM problem for all test cases.\n    It computes the posterior distribution p(z_2 | x_{1:4}) using the\n    scaled forward-backward algorithm and formats the output as specified.\n    \"\"\"\n\n    def calculate_posterior_z2(pi, A, B, x):\n        \"\"\"\n        Implements the scaled forward-backward algorithm to compute gamma_2.\n        \n        Args:\n            pi (np.array): Initial state distribution (K,).\n            A (np.array): State transition matrix (K, K).\n            B (np.array): Emission matrix (K, M).\n            x (list): Observation sequence of length T.\n\n        Returns:\n            np.array: The posterior distribution p(z_2 | x_{1:T}) of shape (K,).\n        \"\"\"\n        T = len(x)\n        K = A.shape[0]\n\n        # --- Scaled Forward Pass ---\n        # We only need alpha_hat_2 for the final result, so we only need to go up to t=2.\n        # But the backward pass needs all scaling constants c, so we do the full forward pass.\n        alpha_hats = np.zeros((T, K))\n        c = np.zeros(T)\n\n        # Time t=1 (index 0)\n        # pi has shape (K,), B[:, x[0]] has shape (K,)\n        alpha_1_prime = pi * B[:, x[0]]\n        c[0] = np.sum(alpha_1_prime)\n        alpha_hats[0, :] = alpha_1_prime / c[0]\n\n        # Time t=2...T\n        for t in range(1, T):\n            # alpha_hats[t-1,:] is (K,), A is (K, K). Result of @ is (K,)\n            # B[:, x[t]] is (K,).\n            alpha_t_prime = (alpha_hats[t-1, :] @ A) * B[:, x[t]]\n            c[t] = np.sum(alpha_t_prime)\n            alpha_hats[t, :] = alpha_t_prime / c[t]\n\n        # --- Scaled Backward Pass ---\n        # We need to compute up to beta_hat_2.\n        beta_hats = np.zeros((T, K))\n\n        # Time t=T (index T-1)\n        beta_hats[T - 1, :] = 1.0\n\n        # Time t=T-1...1\n        # Loop from t=T-2 down to 0, which corresponds to time T-1 down to 1\n        for t in range(T - 2, -1, -1):\n            # A is (K,K), B[:, x[t+1]] is (K,), beta_hats[t+1,:] is (K,)\n            # The term to be left-multiplied by A is a vector of shape (K,)\n            term_to_sum = B[:, x[t+1]] * beta_hats[t+1, :]\n            # The result of A @ term_to_sum is a vector of shape (K,)\n            beta_hats[t, :] = (A @ term_to_sum) / c[t + 1]\n\n        # --- Posterior for t=2 (index 1) ---\n        # gamma_2 is proportional to the element-wise product of alpha_hat_2 and beta_hat_2.\n        gamma_2_unnormalized = alpha_hats[1, :] * beta_hats[1, :]\n        \n        # Normalize to get the final posterior distribution.\n        gamma_2 = gamma_2_unnormalized / np.sum(gamma_2_unnormalized)\n\n        return gamma_2\n\n    test_cases = [\n        (\n            np.array([0.6, 0.4]),\n            np.array([[0.7, 0.3], [0.2, 0.8]]),\n            np.array([[0.5, 0.4, 0.1], [0.1, 0.3, 0.6]]),\n            [2, 1, 0, 1]\n        ),\n        (\n            np.array([0.2, 0.5, 0.3]),\n            np.array([[0.90, 0.09, 0.01], [0.05, 0.90, 0.05], [0.02, 0.08, 0.90]]),\n            np.array([[0.6, 0.3, 0.1], [0.2, 0.5, 0.3], [0.1, 0.2, 0.7]]),\n            [0, 2, 1, 2]\n        ),\n        (\n            np.array([0.001, 0.999]),\n            np.array([[0.0001, 0.9999], [0.00001, 0.99999]]),\n            np.array([[0.001, 0.999], [0.999999, 0.000001]]),\n            [1, 1, 0, 1]\n        ),\n        (\n            np.array([1/3, 1/3, 1/3]),\n            np.array([[0.6, 0.3, 0.1], [0.2, 0.5, 0.3], [0.25, 0.25, 0.5]]),\n            np.array([[0.25, 0.25, 0.25, 0.25], [0.1, 0.2, 0.3, 0.4], [0.4, 0.3, 0.2, 0.1]]),\n            [3, 2, 1, 0]\n        )\n    ]\n\n    all_results_str = []\n    for pi, A, B, x in test_cases:\n        gamma_2 = calculate_posterior_z2(pi, A, B, x)\n        # Format each list of results to 6 decimal places without extra spaces\n        inner_list_str = ','.join(f'{v:.6f}' for v in gamma_2)\n        all_results_str.append(f'[{inner_list_str}]')\n    \n    # Combine all formatted results into a single string representing a list of lists\n    final_output = f\"[{','.join(all_results_str)}]\"\n    print(final_output)\n\nsolve()\n```"
        },
        {
            "introduction": "In most scientific applications, the parameters of the HMM are unknown and must be learned from the data itself. This capstone practice  walks you through a complete iteration of the Expectation-Maximization (EM) algorithm, the standard procedure for training HMMs. You will see how the inference machinery from the E-step (using the forward-backward algorithm) provides the necessary information for the M-step to update and improve the model parameters, illustrating the powerful feedback loop between inference and learning.",
            "id": "3987936",
            "problem": "You are tasked with implementing a single Expectation–Maximization (EM) iteration for a two-state Hidden Markov Model (HMM) with Poisson emissions, in order to identify latent neural states from spike count data. The core objective is to compute the posterior state marginals $\\gamma_t(k)$ and pairwise posteriors $\\xi_t(i,j)$ via the forward–backward algorithm, update the transition matrix $A$ and Poisson rates $\\lambda_k$, and verify that the observed-data log-likelihood $\\log p(x_{1:T} \\mid \\theta)$ strictly increases after the EM update.\n\nBegin from fundamental probabilistic definitions. A Hidden Markov Model (HMM) comprises:\n- An initial state distribution $\\pi$ over $K$ discrete states.\n- A state transition matrix $A$ with entries $A_{ij} = p(z_{t+1}=j \\mid z_t=i)$, where rows sum to $1$.\n- An emission model $p(x_t \\mid z_t)$ for observed data $x_t$ conditioned on latent state $z_t$.\n\nFor this problem, the emission model is Poisson: for spike counts $x_t \\in \\{0,1,2,\\dots\\}$ and state $k \\in \\{1,2\\}$, the likelihood is\n$$\np(x_t \\mid z_t = k, \\lambda_k) = \\frac{\\lambda_k^{x_t} e^{-\\lambda_k}}{x_t!}.\n$$\nLet $x_{1:T} \\equiv (x_1, x_2, \\dots, x_T)$ and $z_{1:T} \\equiv (z_1, z_2, \\dots, z_T)$ denote the observed counts and latent states, respectively. The joint distribution under parameters $\\theta \\equiv (\\pi, A, \\lambda)$ is\n$$\np(x_{1:T}, z_{1:T} \\mid \\theta) = \\pi_{z_1} \\left( \\prod_{t=1}^{T-1} A_{z_t, z_{t+1}} \\right) \\left( \\prod_{t=1}^{T} p(x_t \\mid z_t, \\lambda_{z_t}) \\right).\n$$\n\nTasks to implement and verify:\n1. For each test case, generate a synthetic sequence of spike counts $x_{1:T}$ from a two-state HMM specified by the given true parameters $(\\pi^{\\text{true}}, A^{\\text{true}}, \\lambda^{\\text{true}})$, using the stated random seed to ensure reproducibility. Use the generative process implied by the joint distribution above (sample $z_1 \\sim \\pi^{\\text{true}}$, then recursively sample $z_{t+1} \\sim A^{\\text{true}}_{z_t, \\cdot}$, and sample $x_t \\sim \\text{Poisson}(\\lambda^{\\text{true}}_{z_t})$ for each $t$).\n2. Given initial parameters $\\theta^{(0)} \\equiv (\\pi^{(0)}, A^{(0)}, \\lambda^{(0)})$, derive from first principles the forward–backward algorithm to compute the posterior state marginals $\\gamma_t(k) \\equiv p(z_t=k \\mid x_{1:T}, \\theta^{(0)})$ and pairwise posteriors $\\xi_t(i,j) \\equiv p(z_t=i, z_{t+1}=j \\mid x_{1:T}, \\theta^{(0)})$ for $t \\in \\{1,\\dots,T-1\\}$.\n3. From the expected complete-data log-likelihood under $\\theta^{(0)}$, derive the maximization (M-step) updates for the transition matrix $A$ and Poisson rates $\\lambda_k$, using the sufficient statistics obtained from $\\gamma_t(k)$ and $\\xi_t(i,j)$, while keeping the initial distribution $\\pi$ fixed at $\\pi^{(0)}$.\n4. Compute the observed-data log-likelihood $\\log p(x_{1:T} \\mid \\theta)$ before and after the EM update, using a numerically stable scaled forward algorithm. Use natural logarithms (base $e$).\n5. For each test case, verify whether the log-likelihood strictly increases after the EM update, i.e., check whether $\\log p(x_{1:T} \\mid \\theta^{(1)})  \\log p(x_{1:T} \\mid \\theta^{(0)})$, where $\\theta^{(1)}$ are the updated parameters.\n\nTest suite specification:\n- All test cases use $K = 2$ states. The following four parameter sets cover diverse regimes:\n  - Case $1$ (general mixing, moderate rates, length $T=50$): \n    - True parameters: $\\pi^{\\text{true}} = [\\,0.6,\\,0.4\\,]$, \n      $A^{\\text{true}} = \\begin{bmatrix} 0.95  0.05 \\\\ 0.05  0.95 \\end{bmatrix}$, \n      $\\lambda^{\\text{true}} = [\\,3.0,\\,10.0\\,]$, \n      random seed $1234$.\n    - Initial parameters: $\\pi^{(0)} = [\\,0.5,\\,0.5\\,]$, \n      $A^{(0)} = \\begin{bmatrix} 0.8  0.2 \\\\ 0.2  0.8 \\end{bmatrix}$, \n      $\\lambda^{(0)} = [\\,5.0,\\,5.0\\,]$.\n  - Case $2$ (strong rate contrast, length $T=60$):\n    - True parameters: $\\pi^{\\text{true}} = [\\,0.5,\\,0.5\\,]$, \n      $A^{\\text{true}} = \\begin{bmatrix} 0.9  0.1 \\\\ 0.1  0.9 \\end{bmatrix}$, \n      $\\lambda^{\\text{true}} = [\\,0.5,\\,20.0\\,]$, \n      random seed $5678$.\n    - Initial parameters: $\\pi^{(0)} = [\\,0.5,\\,0.5\\,]$, \n      $A^{(0)} = \\begin{bmatrix} 0.7  0.3 \\\\ 0.3  0.7 \\end{bmatrix}$, \n      $\\lambda^{(0)} = [\\,1.0,\\,15.0\\,]$.\n  - Case $3$ (near-deterministic transitions, length $T=40$):\n    - True parameters: $\\pi^{\\text{true}} = [\\,0.7,\\,0.3\\,]$, \n      $A^{\\text{true}} = \\begin{bmatrix} 0.99  0.01 \\\\ 0.01  0.99 \\end{bmatrix}$, \n      $\\lambda^{\\text{true}} = [\\,2.0,\\,12.0\\,]$, \n      random seed $1357$.\n    - Initial parameters: $\\pi^{(0)} = [\\,0.5,\\,0.5\\,]$, \n      $A^{(0)} = \\begin{bmatrix} 0.85  0.15 \\\\ 0.15  0.85 \\end{bmatrix}$, \n      $\\lambda^{(0)} = [\\,4.0,\\,9.0\\,]$.\n  - Case $4$ (short sequence edge case, length $T=5$):\n    - True parameters: $\\pi^{\\text{true}} = [\\,0.5,\\,0.5\\,]$, \n      $A^{\\text{true}} = \\begin{bmatrix} 0.9  0.1 \\\\ 0.1  0.9 \\end{bmatrix}$, \n      $\\lambda^{\\text{true}} = [\\,1.0,\\,8.0\\,]$, \n      random seed $2468$.\n    - Initial parameters: $\\pi^{(0)} = [\\,0.5,\\,0.5\\,]$, \n      $A^{(0)} = \\begin{bmatrix} 0.6  0.4 \\\\ 0.4  0.6 \\end{bmatrix}$, \n      $\\lambda^{(0)} = [\\,2.0,\\,6.0\\,]$.\n\nAnswer specification:\n- For each test case, compute a boolean value indicating whether the log-likelihood strictly increased after the EM update.\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (e.g., $\\texttt{[result1,result2,result3,result4]}$). Each entry must be a boolean value $\\texttt{True}$ or $\\texttt{False}$, in the order of the test cases ($1$ through $4$).\n- No physical units or angle units apply to this problem. If any fractional values are desired in implementation, use floating-point numbers. All logarithms must be natural logarithms.",
            "solution": "The problem requires the implementation and validation of a single Expectation-Maximization (EM) iteration for a two-state Hidden Markov Model (HMM) with Poisson emissions. The process involves generating synthetic data, performing the E-step via the forward-backward algorithm, executing the M-step to update parameters, and verifying the monotonic increase of the observed-data log-likelihood.\n\nLet the HMM be defined by the parameters $\\theta = (\\pi, A, \\lambda)$, where $\\pi$ is the initial state distribution, $A$ is the state transition matrix, and $\\lambda$ is the vector of Poisson emission rates. The model has $K=2$ latent states $z_t \\in \\{1, 2\\}$ and produces observed spike counts $x_t \\in \\{0, 1, 2, \\dots\\}$.\n\nFirst, for each test case, a sequence of observations $x_{1:T} = (x_1, \\dots, x_T)$ of length $T$ is generated according to the true parameters $(\\pi^{\\text{true}}, A^{\\text{true}}, \\lambda^{\\text{true}})$ and a specified random seed. This involves sampling an initial state $z_1 \\sim \\text{Categorical}(\\pi^{\\text{true}})$, followed by recursively sampling states $z_{t+1} \\sim \\text{Categorical}(A_{z_t, \\cdot}^{\\text{true}})$ and observations $x_t \\sim \\text{Poisson}(\\lambda_{z_t}^{\\text{true}})$.\n\nThe core of the task is to update a set of initial parameters $\\theta^{(0)} = (\\pi^{(0)}, A^{(0)}, \\lambda^{(0)})$ to new parameters $\\theta^{(1)}$ using one EM iteration. The EM algorithm maximizes the log-likelihood of the observed data, $\\log p(x_{1:T} \\mid \\theta)$, by iteratively maximizing the expected complete-data log-likelihood. The complete-data log-likelihood is given by:\n$$\n\\log p(x_{1:T}, z_{1:T} \\mid \\theta) = \\log \\pi_{z_1} + \\sum_{t=1}^{T-1} \\log A_{z_t, z_{t+1}} + \\sum_{t=1}^{T} \\log p(x_t \\mid z_t, \\lambda_{z_t})\n$$\nThe EM algorithm alternates between two steps:\n\n**1. Expectation (E) Step**\nIn the E-step, we compute the expected complete-data log-likelihood with respect to the posterior distribution of the latent states given the observed data and current parameters $\\theta^{(0)}$. This is the $Q$-function:\n$$\nQ(\\theta \\mid \\theta^{(0)}) = E_{z_{1:T} \\mid x_{1:T}, \\theta^{(0)}}[\\log p(x_{1:T}, z_{1:T} \\mid \\theta)]\n$$\nEvaluating this expectation requires computing the posterior state marginals $\\gamma_t(k) = p(z_t=k \\mid x_{1:T}, \\theta^{(0)})$ and the posterior pairwise marginals $\\xi_t(i,j) = p(z_t=i, z_{t+1}=j \\mid x_{1:T}, \\theta^{(0)})$. These are found using the forward-backward algorithm. To prevent numerical underflow, a scaled version of the algorithm is used.\n\n**Forward Algorithm (Scaled)**\nThe forward messages, $\\alpha_t(k) = p(x_{1:t}, z_t=k \\mid \\theta^{(0)})$, are computed recursively. To maintain numerical stability, we define scaled messages $\\hat{\\alpha}_t(k) = p(z_t=k \\mid x_{1:t}, \\theta^{(0)})$.\nThe initialization at $t=1$ is:\n$$\n\\alpha_1(k) = \\pi^{(0)}_k p(x_1 \\mid z_1=k, \\lambda^{(0)}_k)\n$$\nThe scaling factor is $c_1 = \\sum_{k=1}^K \\alpha_1(k)$, and the scaled message is $\\hat{\\alpha}_1(k) = \\alpha_1(k) / c_1$.\nFor $t=2, \\dots, T$, the recursion is:\n$$\n\\alpha_t(k) = p(x_t \\mid z_t=k, \\lambda^{(0)}_k) \\sum_{j=1}^K \\hat{\\alpha}_{t-1}(j) A^{(0)}_{jk}\n$$\nThe scaling factor is $c_t = \\sum_{k=1}^K \\alpha_t(k)$, and the scaled message is $\\hat{\\alpha}_t(k) = \\alpha_t(k) / c_t$.\nThe observed-data log-likelihood is a direct product of this scaling:\n$$\n\\log p(x_{1:T} \\mid \\theta^{(0)}) = \\sum_{t=1}^T \\log c_t\n$$\n\n**Backward Algorithm (Scaled)**\nThe backward messages, $\\beta_t(k) = p(x_{t+1:T} \\mid z_t=k, \\theta^{(0)})$, are also computed recursively. We define scaled messages $\\hat{\\beta}_t(k)$ that are compatible with the forward scaling.\nThe initialization at $t=T$ is $\\hat{\\beta}_T(k) = 1$ for all $k \\in \\{1, \\dots, K\\}$.\nThe recursion for $t=T-1, \\dots, 1$ is:\n$$\n\\hat{\\beta}_t(i) = \\frac{1}{c_{t+1}} \\sum_{j=1}^K A^{(0)}_{ij} p(x_{t+1} \\mid z_{t+1}=j, \\lambda^{(0)}_j) \\hat{\\beta}_{t+1}(j)\n$$\n\n**Posterior Probabilities**\nWith the scaled forward and backward messages, the required posteriors are computed as:\nThe state marginal posterior, $\\gamma_t(k)$:\n$$\n\\gamma_t(k) = p(z_t=k \\mid x_{1:T}, \\theta^{(0)}) = \\frac{\\alpha_t(k)\\beta_t(k)}{p(x_{1:T}|\\theta^{(0)})} = \\hat{\\alpha}_t(k) \\hat{\\beta}_t(k)\n$$\nThe pairwise marginal posterior, $\\xi_t(i,j)$:\n$$\n\\xi_t(i,j) = p(z_t=i, z_{t+1}=j \\mid x_{1:T}, \\theta^{(0)}) = \\frac{\\alpha_t(i) A^{(0)}_{ij} p(x_{t+1} \\mid z_{t+1}=j, \\lambda_j^{(0)}) \\beta_{t+1}(j)}{p(x_{1:T}|\\theta^{(0)})}\n$$\n$$\n= \\frac{\\hat{\\alpha}_t(i) A^{(0)}_{ij} p(x_{t+1} \\mid z_{t+1}=j, \\lambda_j^{(0)}) \\hat{\\beta}_{t+1}(j)}{c_{t+1}}\n$$\n\n**2. Maximization (M) Step**\nIn the M-step, we find the parameters $\\theta^{(1)}$ that maximize the $Q$-function, $Q(\\theta \\mid \\theta^{(0)})$. The initial distribution $\\pi$ is held fixed at $\\pi^{(0)}$.\n\n**Transition Matrix Update**\nThe part of $Q(\\theta \\mid \\theta^{(0)})$ depending on $A$ is $\\sum_{t=1}^{T-1} \\sum_{i=1}^K \\sum_{j=1}^K \\xi_t(i,j) \\log A_{ij}$. Maximizing this subject to the constraint $\\sum_j A_{ij} = 1$ for each row $i$ yields the update:\n$$\nA^{(1)}_{ij} = \\frac{\\text{Expected number of transitions from } i \\text{ to } j}{\\text{Expected number of transitions from } i} = \\frac{\\sum_{t=1}^{T-1} \\xi_t(i,j)}{\\sum_{t=1}^{T-1} \\gamma_t(i)}\n$$\n\n**Emission Rates Update**\nThe part of $Q(\\theta \\mid \\theta^{(0)})$ depending on $\\lambda$ is $\\sum_{t=1}^T \\sum_{k=1}^K \\gamma_t(k) \\log p(x_t \\mid z_t=k, \\lambda_k)$. For the Poisson emission model, $\\log p(x_t \\mid z_t=k, \\lambda_k) = x_t \\log \\lambda_k - \\lambda_k - \\log(x_t!)$. Maximizing with respect to $\\lambda_k$ yields:\n$$\n\\lambda^{(1)}_k = \\frac{\\text{Expected total count in state } k}{\\text{Expected duration in state } k} = \\frac{\\sum_{t=1}^T \\gamma_t(k) x_t}{\\sum_{t=1}^T \\gamma_t(k)}\n$$\nThe initial distribution is fixed, so $\\pi^{(1)} = \\pi^{(0)}$. This defines the new parameter set $\\theta^{(1)} = (\\pi^{(0)}, A^{(1)}, \\lambda^{(1)})$.\n\n**3. Verification**\nFinally, we compute the log-likelihood using the updated parameters, $\\log p(x_{1:T} \\mid \\theta^{(1)})$, by running the scaled forward algorithm with $\\theta^{(1)}$. The fundamental property of the EM algorithm guarantees that $\\log p(x_{1:T} \\mid \\theta^{(1)}) \\ge \\log p(x_{1:T} \\mid \\theta^{(0)})$. The problem requires verifying a strict increase, which is expected since the initial parameters $\\theta^{(0)}$ are not at a local maximum of the likelihood function.\n\nThe implementation will perform these steps for each test case and report whether the strict inequality $\\log p(x_{1:T} \\mid \\theta^{(1)})  \\log p(x_{1:T} \\mid \\theta^{(0)})$ holds. All logarithms are natural (base $e$).",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.special import logsumexp, gammaln\n\ndef solve():\n    \"\"\"\n    Main function to run the EM HMM validation for all test cases.\n    \"\"\"\n\n    test_cases = [\n        {\n            \"T\": 50,\n            \"pi_true\": np.array([0.6, 0.4]),\n            \"A_true\": np.array([[0.95, 0.05], [0.05, 0.95]]),\n            \"lambda_true\": np.array([3.0, 10.0]),\n            \"seed\": 1234,\n            \"pi0\": np.array([0.5, 0.5]),\n            \"A0\": np.array([[0.8, 0.2], [0.2, 0.8]]),\n            \"lambda0\": np.array([5.0, 5.0])\n        },\n        {\n            \"T\": 60,\n            \"pi_true\": np.array([0.5, 0.5]),\n            \"A_true\": np.array([[0.9, 0.1], [0.1, 0.9]]),\n            \"lambda_true\": np.array([0.5, 20.0]),\n            \"seed\": 5678,\n            \"pi0\": np.array([0.5, 0.5]),\n            \"A0\": np.array([[0.7, 0.3], [0.3, 0.7]]),\n            \"lambda0\": np.array([1.0, 15.0])\n        },\n        {\n            \"T\": 40,\n            \"pi_true\": np.array([0.7, 0.3]),\n            \"A_true\": np.array([[0.99, 0.01], [0.01, 0.99]]),\n            \"lambda_true\": np.array([2.0, 12.0]),\n            \"seed\": 1357,\n            \"pi0\": np.array([0.5, 0.5]),\n            \"A0\": np.array([[0.85, 0.15], [0.15, 0.85]]),\n            \"lambda0\": np.array([4.0, 9.0])\n        },\n        {\n            \"T\": 5,\n            \"pi_true\": np.array([0.5, 0.5]),\n            \"A_true\": np.array([[0.9, 0.1], [0.1, 0.9]]),\n            \"lambda_true\": np.array([1.0, 8.0]),\n            \"seed\": 2468,\n            \"pi0\": np.array([0.5, 0.5]),\n            \"A0\": np.array([[0.6, 0.4], [0.4, 0.6]]),\n            \"lambda0\": np.array([2.0, 6.0])\n        }\n    ]\n\n    results = []\n    for case in test_cases:\n        x_obs = generate_data(\n            case[\"T\"], case[\"pi_true\"], case[\"A_true\"], case[\"lambda_true\"], case[\"seed\"]\n        )\n\n        pi0, A0, lambda0 = case[\"pi0\"], case[\"A0\"], case[\"lambda0\"]\n\n        # E-step with initial parameters theta_0\n        gamma, xi, log_L0 = forward_backward(x_obs, pi0, A0, lambda0)\n        \n        # M-step to get updated parameters theta_1\n        pi1, A1, lambda1 = m_step(x_obs, gamma, xi, pi0)\n\n        # Calculate log-likelihood with updated parameters theta_1\n        _, _, log_L1 = forward_backward(x_obs, pi1, A1, lambda1)\n\n        # Verify strict increase in log-likelihood\n        results.append(log_L1 > log_L0)\n\n    # Format the boolean results to match the required output (True/False)\n    output_str = f\"[{','.join('True' if r else 'False' for r in results)}]\"\n    print(output_str)\n\n\ndef generate_data(T, pi_true, A_true, lambda_true, seed):\n    \"\"\"\n    Generates a sequence of spike counts from an HMM with Poisson emissions.\n    \"\"\"\n    rng = np.random.default_rng(seed)\n    K = len(pi_true)\n    states = np.arange(K)\n    \n    z_obs = np.zeros(T, dtype=int)\n    x_obs = np.zeros(T, dtype=int)\n\n    # Sample initial state z_1\n    z_obs[0] = rng.choice(states, p=pi_true)\n    x_obs[0] = rng.poisson(lambda_true[z_obs[0]])\n\n    # Sample remaining states and observations\n    for t in range(T - 1):\n        z_obs[t+1] = rng.choice(states, p=A_true[z_obs[t], :])\n        x_obs[t+1] = rng.poisson(lambda_true[z_obs[t+1]])\n    \n    return x_obs\n\n\ndef poisson_log_pmf(x, rate):\n    \"\"\"\n    Computes the log of the Poisson probability mass function.\n    Handles rate > 0.\n    \"\"\"\n    # Add a small epsilon to rate to avoid log(0) if rate is 0.\n    rate = np.maximum(rate, 1e-12)\n    return x * np.log(rate) - rate - gammaln(x + 1)\n\n\ndef forward_backward(x_obs, pi, A, lmbda):\n    \"\"\"\n    Performs the forward-backward algorithm to compute posteriors and log-likelihood.\n    Uses log-space calculations for numerical stability.\n    \"\"\"\n    T = len(x_obs)\n    K = len(pi)\n\n    # Compute emission log-probabilities\n    log_em_probs = np.zeros((T, K))\n    for k in range(K):\n        log_em_probs[:, k] = poisson_log_pmf(x_obs, lmbda[k])\n    \n    # --- Forward pass (log-space scaled alphas) ---\n    log_alpha_hat = np.zeros((T, K))\n    log_c = np.zeros(T)\n\n    # Initialization t=0\n    log_alpha_0_unscaled = np.log(pi) + log_em_probs[0, :]\n    log_c[0] = logsumexp(log_alpha_0_unscaled)\n    log_alpha_hat[0, :] = log_alpha_0_unscaled - log_c[0]\n\n    # Recursion t=1 to T-1\n    for t in range(1, T):\n        log_alpha_t_unscaled = log_em_probs[t, :] + logsumexp(log_alpha_hat[t-1, :] + np.log(A).T, axis=1)\n        log_c[t] = logsumexp(log_alpha_t_unscaled)\n        log_alpha_hat[t, :] = log_alpha_t_unscaled - log_c[t]\n\n    log_likelihood = np.sum(log_c)\n\n    # --- Backward pass (log-space scaled betas) ---\n    log_beta_hat = np.zeros((T, K))\n    # Initialization t=T-1 is log(1) = 0\n    \n    # Recursion t=T-2 down to 0\n    for t in range(T - 2, -1, -1):\n        log_beta_hat[t, :] = logsumexp(np.log(A) + log_em_probs[t+1, :] + log_beta_hat[t+1, :], axis=1) - log_c[t+1]\n\n    # --- Compute posteriors ---\n    # Gamma: p(z_t=k | x_{1:T})\n    log_gamma = log_alpha_hat + log_beta_hat\n    gamma = np.exp(log_gamma)\n    \n    # Xi: p(z_t=i, z_{t+1}=j | x_{1:T})\n    log_xi = np.zeros((T - 1, K, K))\n    for t in range(T - 1):\n        log_xi[t, :, :] = log_alpha_hat[t, :, np.newaxis] + np.log(A) + \\\n                          log_em_probs[t+1, :] + log_beta_hat[t+1, :] - \\\n                          log_c[t+1]\n    xi = np.exp(log_xi)\n\n    return gamma, xi, log_likelihood\n\n\ndef m_step(x_obs, gamma, xi, pi0):\n    \"\"\"\n    Performs the M-step to update the HMM parameters.\n    \"\"\"\n    # Update transition matrix A\n    sum_gamma_T_minus_1 = np.sum(gamma[:-1, :], axis=0)\n    sum_xi = np.sum(xi, axis=0)\n    A1 = sum_xi / sum_gamma_T_minus_1[:, np.newaxis]\n    \n    # Update Poisson rates lambda\n    sum_gamma_T = np.sum(gamma, axis=0)\n    weighted_x = np.sum(gamma * x_obs[:, np.newaxis], axis=0)\n    lambda1 = weighted_x / sum_gamma_T\n\n    # Initial distribution pi is fixed\n    pi1 = pi0\n\n    return pi1, A1, lambda1\n\nif __name__ == \"__main__\":\n    solve()\n```"
        }
    ]
}