{
    "hands_on_practices": [
        {
            "introduction": "预测编码的核心是贝叶斯推断的一种形式，即大脑不断地利用新的感官证据来更新其对世界的内部模型。本练习将通过一个基础但至关重要的案例，推导这一更新过程的数学法则。通过这个练习，你将亲手揭示“精度加权”（precision-weighting）这一优美的原则：大脑如何平衡先验信念和感官证据，并赋予更可靠的信息来源更大的权重，这是理解贝叶斯大脑假说的基石。",
            "id": "5052192",
            "problem": "考虑一个单潜变量生成模型，该模型通常用于形式化神经生物学中的预测编码（Predictive Coding）和贝叶斯大脑（Bayesian brain）框架。一个潜变量成因 $x$ 代表大脑对感官输入的预测，而测量值 $y$ 是观测到的感官信号。假设潜变量成因服从高斯先验分布 $x \\sim \\mathcal{N}(\\mu_{0}, \\sigma_{0}^{2})$，给定该成因的观测值的似然也服从高斯分布 $y \\mid x \\sim \\mathcal{N}(x, \\sigma_{y}^{2})$，其中 $\\sigma_{0}^{2} > 0$ 和 $\\sigma_{y}^{2} > 0$ 是已知常数。使用贝叶斯法则以及“高斯密度函数的乘积会产生关于目标变量的另一个高斯密度函数”这一经过充分验证的事实，推导出后验密度 $p(x \\mid y)$ 的闭合形式，并证明其为高斯分布。然后，使用先验均值和观测值的精度加权组合来表示后验均值和后验方差。定义精度为方差的倒数，即 $\\tau_{0} = 1 / \\sigma_{0}^{2}$ 和 $\\tau_{y} = 1 / \\sigma_{y}^{2}$。提供以后验均值和后验方差的最终表达式，用 $\\mu_{0}$、$y$、$\\tau_{0}$ 和 $\\tau_{y}$ 表示。不需要数值近似；请给出精确的符号表达式。最终答案必须是一个计算结果，并应表示为包含后验均值和后验方差的单行矩阵。",
            "solution": "问题陈述经评估有效。这是一个贝叶斯统计中的适定问题，它基于已建立的数学原理，并直接适用于指定的预测编码神经生物学框架。所有必要信息均已提供，术语清晰无歧义。\n\n任务是推导给定观测值 $y$ 的潜变量成因 $x$ 的后验概率密度函数 (PDF) $p(x \\mid y)$。我们已知 $x$ 的先验分布和给定 $x$ 的 $y$ 的似然函数。\n\n先验分布是高斯分布：\n$$p(x) = \\mathcal{N}(x \\mid \\mu_{0}, \\sigma_{0}^{2}) = \\frac{1}{\\sqrt{2\\pi\\sigma_{0}^{2}}} \\exp\\left(-\\frac{(x - \\mu_{0})^2}{2\\sigma_{0}^{2}}\\right)$$\n似然函数也是高斯分布：\n$$p(y \\mid x) = \\mathcal{N}(y \\mid x, \\sigma_{y}^{2}) = \\frac{1}{\\sqrt{2\\pi\\sigma_{y}^{2}}} \\exp\\left(-\\frac{(y - x)^2}{2\\sigma_{y}^{2}}\\right)$$\n根据贝叶斯法则，后验分布与似然函数和先验分布的乘积成正比：\n$$p(x \\mid y) \\propto p(y \\mid x) p(x)$$\n代入给定的分布，我们得到：\n$$p(x \\mid y) \\propto \\exp\\left(-\\frac{(y - x)^2}{2\\sigma_{y}^{2}}\\right) \\exp\\left(-\\frac{(x - \\mu_{0})^2}{2\\sigma_{0}^{2}}\\right)$$\n我们可以合并指数函数的指数部分：\n$$p(x \\mid y) \\propto \\exp\\left( -\\frac{(y - x)^2}{2\\sigma_{y}^{2}} - \\frac{(x - \\mu_{0})^2}{2\\sigma_{0}^{2}} \\right)$$\n为求后验分布的形式，我们分析指数部分，重点关注依赖于 $x$ 的项。设 $E(x)$ 为指数函数的指数部分：\n$$E(x) = -\\frac{1}{2} \\left( \\frac{(y - x)^2}{\\sigma_{y}^{2}} + \\frac{(x - \\mu_{0})^2}{\\sigma_{0}^{2}} \\right)$$\n展开平方项：\n$$E(x) = -\\frac{1}{2} \\left( \\frac{y^2 - 2yx + x^2}{\\sigma_{y}^{2}} + \\frac{x^2 - 2x\\mu_{0} + \\mu_{0}^2}{\\sigma_{0}^{2}} \\right)$$\n现在我们按 $x$ 的幂次对各项进行分组：\n$$E(x) = -\\frac{1}{2} \\left[ x^2 \\left(\\frac{1}{\\sigma_{0}^{2}} + \\frac{1}{\\sigma_{y}^{2}}\\right) - 2x \\left(\\frac{\\mu_{0}}{\\sigma_{0}^{2}} + \\frac{y}{\\sigma_{y}^{2}}\\right) + \\left(\\frac{\\mu_{0}^2}{\\sigma_{0}^{2}} + \\frac{y^2}{\\sigma_{y}^{2}}\\right) \\right]$$\n问题将精度定义为方差的倒数：$\\tau_{0} = 1/\\sigma_{0}^{2}$ 和 $\\tau_{y} = 1/\\sigma_{y}^{2}$。将它们代入表达式中：\n$$E(x) = -\\frac{1}{2} \\left[ x^2 (\\tau_{0} + \\tau_{y}) - 2x (\\tau_{0}\\mu_{0} + \\tau_{y}y) + (\\tau_{0}\\mu_{0}^2 + \\tau_{y}y^2) \\right]$$\n这个表达式是关于 $x$ 的二次函数。这意味着后验分布 $p(x \\mid y)$ 是一个高斯分布，正如问题中所述。一个均值为 $\\mu_{\\text{post}}$、方差为 $\\sigma_{\\text{post}}^2$ 的变量 $x$ 的一般高斯 PDF，其指数部分具有以下形式：\n$$-\\frac{(x - \\mu_{\\text{post}})^2}{2\\sigma_{\\text{post}}^2} = -\\frac{1}{2\\sigma_{\\text{post}}^2} (x^2 - 2x\\mu_{\\text{post}} + \\mu_{\\text{post}}^2) = -\\frac{1}{2} (\\tau_{\\text{post}}x^2 - 2\\tau_{\\text{post}}\\mu_{\\text{post}}x + \\text{const})$$\n其中 $\\tau_{\\text{post}} = 1/\\sigma_{\\text{post}}^2$ 是后验精度。\n\n通过将我们推导出的指数 $E(x)$ 中 $x$ 各次幂的系数与一般形式进行比较，我们可以确定后验分布的参数。\n比较 $x^2$ 项的系数：\n$$\\tau_{\\text{post}} = \\tau_{0} + \\tau_{y}$$\n这表明后验精度是先验精度和似然精度的和。后验方差 $\\sigma_{\\text{post}}^2$ 是后验精度的倒数：\n$$\\sigma_{\\text{post}}^2 = \\frac{1}{\\tau_{\\text{post}}} = \\frac{1}{\\tau_{0} + \\tau_{y}}$$\n现在，比较 $x$ 项的系数：\n$$2\\tau_{\\text{post}}\\mu_{\\text{post}} = 2(\\tau_{0}\\mu_{0} + \\tau_{y}y)$$\n$$\\mu_{\\text{post}} = \\frac{\\tau_{0}\\mu_{0} + \\tau_{y}y}{\\tau_{\\text{post}}}$$\n代入 $\\tau_{\\text{post}}$ 的表达式：\n$$\\mu_{\\text{post}} = \\frac{\\tau_{0}\\mu_{0} + \\tau_{y}y}{\\tau_{0} + \\tau_{y}}$$\n后验均值是先验均值 $\\mu_{0}$ 和观测数据 $y$ 的精度加权平均值。$E(x)$ 中不依赖于 $x$ 的项被吸收到后验高斯 PDF 的归一化常数中。\n\n因此，后验分布 $p(x \\mid y)$ 是一个高斯分布 $\\mathcal{N}(\\mu_{\\text{post}}, \\sigma_{\\text{post}}^2)$，其均值和方差如上推导。\n\n后验均值为：\n$$\\mu_{\\text{post}} = \\frac{\\tau_{0}\\mu_{0} + \\tau_{y}y}{\\tau_{0} + \\tau_{y}}$$\n后验方差为：\n$$\\sigma_{\\text{post}}^2 = \\frac{1}{\\tau_{0} + \\tau_{y}}$$\n这些就是所要求的最终符号表达式。",
            "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n\\frac{\\tau_{0} \\mu_{0} + \\tau_{y} y}{\\tau_{0} + \\tau_{y}}  \\frac{1}{\\tau_{0} + \\tau_{y}}\n\\end{pmatrix}\n}\n$$"
        },
        {
            "introduction": "在现实世界中，感官输入往往是模糊不清的，可能对应多种解释。预测编码框架如何处理这种模糊性？本练习通过构建一个具有“双阱势”（double-well potential）的变分自由能（Variational Free Energy, VFE）函数来模拟这种情况，其中每个“阱”代表一个稳定的感知假设。通过在这个非凸的能量景观上实施梯度下降，你将观察到推断过程如何根据初始状态和感官数据“落入”其中一个可能的解释，这类似于我们感知内克尔立方体等双稳态错觉的体验。这项实践将展示预测编码不仅能用于简单估计，还能解释复杂感知现象的动态过程。",
            "id": "4011074",
            "problem": "考虑一个一维预测编码系统，该系统通过最小化变分自由能 (Variational Free Energy, VFE) 来执行近似贝叶斯推断。潜变量表示为 $x \\in \\mathbb{R}$，观测数据表示为 $y \\in \\mathbb{R}$。该生成模型包含一个精度为 $\\lambda  0$ 的高斯似然和一个其负对数密度会产生双阱势的非高斯先验。该系统通过使用梯度下降法对 $x$ 最小化 VFE 来寻求最大后验 (Maximum A Posteriori, MAP) 估计。\n\n基本原理：\n- 根据贝叶斯法则，给定 $y$ 的 $x$ 的后验概率正比于似然与先验的乘积。\n- 在精度为 $\\lambda$ 的高斯观测噪声下，负对数似然为 VFE 贡献了一个精度加权的预测误差平方项。\n- 预测编码将推断实现为在 VFE 上的梯度下降，其中下降方向是目标函数相对于潜变量 $x$ 的负梯度。\n\n使用以下组件构建一个双阱自由能函数：\n- 一个先验能量项，它在 $\\pm m$ 处创建两个稳定模态，其中 $m  0$，由一个四次双阱势 $U(x) = \\dfrac{\\alpha}{4} \\left( x^2 - m^2 \\right)^2$ 给出，其中 $\\alpha  0$。\n- 一个来自精度为 $\\lambda$ 的高斯似然的数据拟合项：$\\dfrac{\\lambda}{2} \\left( y - x \\right)^2$。\n\n因此，需要最小化的变分自由能为\n$$\nF(x; \\alpha, m, \\lambda, y) = \\dfrac{\\alpha}{4} \\left( x^2 - m^2 \\right)^2 + \\dfrac{\\lambda}{2} \\left( y - x \\right)^2.\n$$\n\n任务：\n1. 从以上定义出发，推导最小化 $F(x; \\alpha, m, \\lambda, y)$ 的 $x$ 的梯度下降更新规则。\n2. 实现一个确定性算法，给定 $(\\alpha, m, \\lambda, y)$ 和一个初始化值 $x_0$，对 $F$ 执行梯度下降直至收敛。当梯度绝对值大小小于 $10^{-10}$ 或迭代次数超过指定的最大值时，必须声明收敛。使用回溯法确保每次接受的更新不会增加自由能。每当提议的更新增加了 $F$ 时，回溯过程应将当前步长减半，每次迭代最多进行 $20$ 次减半。\n3. 收敛后，按如下方式为解 $x^\\star$ 分配一个模态索引。令 $d_+ = |x^\\star - m|$ 和 $d_- = |x^\\star + m|$。如果 $d_+  d_-$（更接近右边的阱 $+m$），则输出 $+1$；如果 $d_-  d_+$（更接近左边的阱 $-m$），则输出 $-1$；如果 $d_+ = d_-$（等距，这在 $x^\\star = 0$ 时发生），则输出 $0$。\n4. 通过下面的测试套件，展示初始化如何决定吸引盆和最终模态，从而分析非凸性如何影响收敛。\n\n测试套件：\n对于每种情况，使用元组 $(\\alpha, m, \\lambda, y, x_0, \\eta, \\text{max\\_iter})$，其中 $\\eta$ 是梯度下降的初始步长，$\\text{max\\_iter}$ 是最大迭代次数。请使用以下确切值：\n- 情况 1：$(4.0, 1.0, 2.0, 0.2, 0.9, 0.02, 20000)$，一个一般情况，其中观测数据略微偏向右阱。\n- 情况 2：$(4.0, 1.0, 2.0, -0.2, -0.9, 0.02, 20000)$，一个对称的对应情况，偏向左阱。\n- 情况 3：$(4.0, 1.0, 2.0, 0.0, 0.0, 0.02, 20000)$，一个恰好在鞍点处的不稳定临界点。\n- 情况 4：$(10.0, 1.0, 0.5, 0.0, -0.1, 0.02, 20000)$，一个强先验，弱数据将初始化值拉入左吸引盆。\n- 情况 5：$(1.0, 1.0, 50.0, 0.3, -0.7, 0.02, 20000)$，数据主导的区域，将解拉向右阱。\n- 情况 6：$(4.0, 1.5, 2.0, -0.1, -0.4, 0.02, 20000)$，改变了阱的位置，$m = 1.5$。\n\n最终输出格式：\n您的程序应生成单行输出，其中包含六个测试用例的模态索引，形式为一个用方括号括起来的、逗号分隔的列表（例如，$[+1,-1,0,-1,+1,-1]$）。每个条目必须是来自 $\\{-1, 0, +1\\}$ 的整数，代表从指定初始化开始的梯度下降收敛后确定的最终模态索引。",
            "solution": "该问题被评估为有效。它在科学上基于计算神经科学和贝叶斯推断的原理，特别是预测编码框架。该问题定义良好，提供了一个明确的目标函数、一个标准的数值优化任务以及所有必要的参数。定义和目标是客观且数学上精确的。所有给定条件都是自洽和一致的。\n\n给定的条件是：\n- 潜变量：$x \\in \\mathbb{R}$\n- 观测数据：$y \\in \\mathbb{R}$\n- 先验能量（四次双阱势）：$U(x) = \\dfrac{\\alpha}{4} \\left( x^2 - m^2 \\right)^2$，参数为 $\\alpha  0$ 和 $m  0$。\n- 数据拟合能量（高斯分布的负对数似然）：$\\dfrac{\\lambda}{2} \\left( y - x \\right)^2$，精度为 $\\lambda  0$。\n- 变分自由能 (VFE)：$F(x; \\alpha, m, \\lambda, y) = \\dfrac{\\alpha}{4} \\left( x^2 - m^2 \\right)^2 + \\dfrac{\\lambda}{2} \\left( y - x \\right)^2$。\n- 优化方法：使用带回溯法的梯度下降来找到 $x^\\star = \\arg\\min_x F(x)$。\n- 收敛标准：梯度绝对值 $|\\nabla_x F|  10^{-10}$ 或迭代次数超过 `max_iter`。\n- 回溯法规则：如果一次更新导致 $F$ 增加，则步长减半。每次迭代最多重复此操作 20 次。\n- 模态分类：收敛状态 $x^\\star$ 根据其与先验势阱 $+m$ 和 $-m$ 的接近程度被分配一个模态索引。\n- 测试用例：一套六个参数集 $(\\alpha, m, \\lambda, y, x_0, \\eta, \\text{max\\_iter})$ 用于测试实现。\n\n**1. 梯度下降更新规则的推导**\n\n这里描述的预测编码过程的核心是通过梯度下降最小化变分自由能 $F(x)$。潜变量 $x$ 的更新规则是通过将 $x$ 沿 $F(x)$ 梯度的反方向移动来给出的。首先，我们必须计算梯度 $\\dfrac{dF}{dx}$。\n\nVFE 是两项之和：\n$$\nF(x) = F_{prior}(x) + F_{data}(x) = \\dfrac{\\alpha}{4} \\left( x^2 - m^2 \\right)^2 + \\dfrac{\\lambda}{2} \\left( y - x \\right)^2\n$$\n\n我们使用链式法则对每一项关于 $x$ 进行微分：\n\n对于先验能量项 $F_{prior}(x)$:\n$$\n\\dfrac{dF_{prior}}{dx} = \\dfrac{d}{dx} \\left[ \\dfrac{\\alpha}{4} \\left( x^2 - m^2 \\right)^2 \\right] = \\dfrac{\\alpha}{4} \\cdot 2 \\left( x^2 - m^2 \\right) \\cdot \\dfrac{d}{dx}(x^2 - m^2) = \\dfrac{\\alpha}{2} \\left( x^2 - m^2 \\right) (2x) = \\alpha x (x^2 - m^2)\n$$\n这可以简化为 $\\alpha (x^3 - m^2 x)$。\n\n对于数据拟合能量项 $F_{data}(x)$:\n$$\n\\dfrac{dF_{data}}{dx} = \\dfrac{d}{dx} \\left[ \\dfrac{\\lambda}{2} \\left( y - x \\right)^2 \\right] = \\dfrac{\\lambda}{2} \\cdot 2 \\left( y - x \\right) \\cdot \\dfrac{d}{dx}(y - x) = \\lambda (y - x) (-1) = \\lambda (x - y)\n$$\n\nVFE 的总梯度是这两个分量的和：\n$$\n\\dfrac{dF}{dx} = \\alpha (x^3 - m^2 x) + \\lambda(x - y)\n$$\n\n在迭代 $k$ 次时，对于步长（学习率）$\\eta_k$，$x$ 的梯度下降更新规则是：\n$$\nx_{k+1} = x_k - \\eta_k \\left. \\dfrac{dF}{dx} \\right|_{x=x_k}\n$$\n代入推导出的梯度，我们得到显式的更新规则：\n$$\nx_{k+1} = x_k - \\eta_k \\left( \\alpha (x_k^3 - m^2 x_k) + \\lambda(x_k - y) \\right)\n$$\n\n**2. 算法设计与实现**\n\n该问题要求一个确定性算法来执行此梯度下降直至收敛。像 $F(x)$ 这样的非凸函数可以有多个局部最小值，而标准的梯度下降算法仅保证收敛到其中一个，具体取决于初始化 $x_0$。为确保稳定收敛，采用回溯线搜索来确定每次迭代的步长 $\\eta_k$。\n\n算法流程如下：\n1.  使用给定的起始值 $x_0$ 初始化 $x$。\n2.  开始一个迭代循环，最多进行 `max_iter` 次迭代。\n3.  在每次迭代 $k$ 中，计算梯度 $g_k = \\dfrac{dF}{dx}|_{x=x_k}$。\n4.  检查收敛性：如果梯度的绝对值大小 $|g_k|$ 小于容差 $10^{-10}$，则过程已收敛到一个驻点。循环终止。\n5.  如果未收敛，则执行回溯线搜索以找到合适的步长 $\\eta_k$。\n    a. 以初始步长 $\\eta_k = \\eta$ 开始。设当前能量为 $F_k = F(x_k)$。\n    b. 提出一个新状态 $x_{prop} = x_k - \\eta_k g_k$。\n    c. 如果 $F(x_{prop})  F_k$，则接受该步长。\n    d. 如果 $F(x_{prop}) \\geq F_k$，则步长过大。将其减半 ($\\eta_k \\leftarrow \\eta_k / 2$)，并重复步骤 5b。此减半操作最多进行 20 次。\n    e. 如果在所有允许的减半后仍未找到合适的步长，则意味着无法从 $x_k$ 取得任何进展。算法被认为在 $x_k$ 处收敛。\n6.  使用接受的步长更新状态：$x_{k+1} = x_k - \\eta_k g_k$。\n7.  循环继续，直到满足终止条件（梯度容差、最大迭代次数或回溯失败）。$x$ 的最终值是解 $x^\\star$。\n\n**3. 模态分类**\n\n收敛到一个稳定点 $x^\\star$ 后，必须根据解落入先验的两个势阱中的哪一个来进行分类。这两个阱以 $+m$ 和 $-m$ 为中心。分类基于 $x^\\star$ 到这两点的欧几里得距离：\n-   令 $d_+ = |x^\\star - m|$ 为到右阱的距离。\n-   令 $d_- = |x^\\star + m|$ 为到左阱的距离。\n\n模态索引分配如下：\n-   若 $d_+  d_-$，则为 $+1$，表示 $x^\\star$ 更接近右阱。对于任何 $x^\\star > 0$ 都成立。\n-   若 $d_-  d_+$，则为 $-1$，表示 $x^\\star$ 更接近左阱。对于任何 $x^\\star  0$ 都成立。\n-   若 $d_+ = d_-$，则为 $0$，表示 $x^\\star$ 与两个阱等距。这只在 $x^\\star = 0$ 时发生，当 $y=0$ 时，这是 VFE 的一个鞍点（局部最大值）。\n\n此过程正确地将实线划分为三个区域，对应于两个最小值的吸引盆以及它们之间的不稳定不动点。测试套件演示了先验（$\\alpha, m$）、数据（$\\lambda, y$）和初始化（$x_0$）之间的相互作用如何决定系统收敛到哪个区域。例如，一个强数据项（大的 $\\lambda$）可以将系统从其初始化所暗示的吸引盆中拉出，而一个强先验（大的 $\\alpha$）会使系统对冲突的数据更具弹性。",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the predictive coding problem for a suite of test cases.\n    \"\"\"\n\n    class PredictiveCodingSystem:\n        \"\"\"\n        Implements the minimization of a double-well Variational Free Energy function.\n        \"\"\"\n        def __init__(self, alpha, m, lamb, y, x0, eta, max_iter):\n            self.alpha = float(alpha)\n            self.m = float(m)\n            self.lamb = float(lamb)\n            self.y = float(y)\n            self.x = float(x0)\n            self.eta = float(eta)\n            self.max_iter = int(max_iter)\n            self.grad_tol = 1e-10\n            self.max_backtrack = 20\n\n        def free_energy(self, x):\n            \"\"\"Calculates the Variational Free Energy F(x).\"\"\"\n            prior_energy = (self.alpha / 4.0) * ((x**2 - self.m**2)**2)\n            data_term = (self.lamb / 2.0) * ((self.y - x)**2)\n            return prior_energy + data_term\n\n        def gradient(self, x):\n            \"\"\"Calculates the gradient of F(x) with respect to x.\"\"\"\n            prior_grad = self.alpha * x * (x**2 - self.m**2)\n            data_grad = self.lamb * (x - self.y)\n            return prior_grad + data_grad\n\n        def minimize(self):\n            \"\"\"\n            Performs gradient descent with backtracking to find the minimum of F(x).\n            \"\"\"\n            for _ in range(self.max_iter):\n                grad = self.gradient(self.x)\n\n                if abs(grad)  self.grad_tol:\n                    # Convergence based on small gradient\n                    break\n\n                current_energy = self.free_energy(self.x)\n                step_eta = self.eta\n                found_descent_step = False\n                \n                # Backtracking line search to find a step that decreases energy\n                for i in range(self.max_backtrack + 1):\n                    x_proposed = self.x - step_eta * grad\n                    \n                    if self.free_energy(x_proposed)  current_energy:\n                        self.x = x_proposed\n                        found_descent_step = True\n                        break # Step accepted, exit backtracking\n                    \n                    step_eta /= 2.0\n                \n                if not found_descent_step:\n                    # Could not find a descent step even after max halvings.\n                    # This implies we are at a minimum (to machine precision).\n                    break\n            \n            return self.x\n\n        def get_mode_index(self, x_star):\n            \"\"\"\n            Classifies the converged state x_star into a mode index {-1, 0, +1}.\n            \"\"\"\n            d_plus = abs(x_star - self.m)\n            d_minus = abs(x_star + self.m)\n\n            if d_plus  d_minus:\n                return 1\n            elif d_minus  d_plus:\n                return -1\n            else:\n                return 0\n\n    def solve_case(params):\n        \"\"\"\n        Initializes and runs the minimization for a single test case.\n        \"\"\"\n        alpha, m, lamb, y, x0, eta, max_iter = params\n        system = PredictiveCodingSystem(alpha, m, lamb, y, x0, eta, max_iter)\n        x_star = system.minimize()\n        return system.get_mode_index(x_star)\n\n    # Test suite as defined in the problem statement\n    test_cases = [\n        # (alpha, m, lambda, y, x0, eta, max_iter)\n        (4.0, 1.0, 2.0, 0.2, 0.9, 0.02, 20000),   # Case 1\n        (4.0, 1.0, 2.0, -0.2, -0.9, 0.02, 20000),  # Case 2\n        (4.0, 1.0, 2.0, 0.0, 0.0, 0.02, 20000),   # Case 3\n        (10.0, 1.0, 0.5, 0.0, -0.1, 0.02, 20000),  # Case 4\n        (1.0, 1.0, 50.0, 0.3, -0.7, 0.02, 20000),  # Case 5\n        (4.0, 1.5, 2.0, -0.1, -0.4, 0.02, 20000),  # Case 6\n    ]\n\n    results = []\n    for case in test_cases:\n        mode_index = solve_case(case)\n        results.append(mode_index)\n\n    # Format the final output string exactly as specified\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "面对感知上的模糊性，大脑并非一个被动的观察者，而是一个能够主动探索环境的代理。行动如何帮助解决感知上的不确定性？这就引出了主动推断（Active Inference）的核心思想：选择行动的目的不仅是实现目标，更是为了收集信息以减少未来的不确定性。本练习要求你量化一个行动在“信息增益”（即预期的后验熵减少量）方面的价值。你将实现一个模型，其中代理人决策是否执行一个信息量更大的行动，以更好地分辨世界的真实状态，从而将感知与行动联系起来，展示了预测编码框架最强大的扩展之一。",
            "id": "4011073",
            "problem": "考虑一个遵循预测编码和主动推断（AI）传统的二元隐状态生成模型，其中智能体可以采取行动来影响后续感官数据的信息量。隐状态用 $s \\in \\{0,1\\}$ 表示，观测用 $o \\in \\{0,1\\}$ 表示，行动用 $a \\in \\{0,1\\}$ 表示，其中 $a=0$ 表示信息量较少（被动）的采样，$a=1$ 表示信息量较多（主动）的采样。智能体对隐状态的先验信念为 $p(s=1)=\\pi$ 和 $p(s=0)=1-\\pi$。\n\n给定隐状态和行动的观测似然模型由一个依赖于行动的准确度参数 $\\alpha_a \\in [0.5,1]$ 参数化，并具有以下对称性：\n- $p(o=1 \\mid s=1,a)=\\alpha_a$, $p(o=0 \\mid s=1,a)=1-\\alpha_a$,\n- $p(o=0 \\mid s=0,a)=\\alpha_a$, $p(o=1 \\mid s=0,a)=1-\\alpha_a$.\n\n任务是通过计算采取行动后后验熵的期望减少量，来演示主动推断如何通过消除状态歧义的行动来解决模糊的感官输入。请使用以下基本原理：\n- 贝叶斯法则：$p(s \\mid o,a) = \\dfrac{p(o \\mid s,a)\\,p(s)}{p(o \\mid a)}$，其中 $p(o \\mid a)=\\sum_{s} p(o \\mid s,a)\\,p(s)$。\n- 香农熵（以奈特为单位）：对于一个二元分布 $p(s)$，$H[p(s)] = -\\sum_{s \\in \\{0,1\\}} p(s)\\,\\ln p(s)$。\n\n将行动 $a$ 的后验熵的期望减少量定义为先验熵与观察到在行动 $a$ 下生成的 $o$ 之后的期望后验熵之差，即：\n- 先验熵：$H[p(s)]$，\n- 给定一个观测的后验熵：$H[p(s \\mid o,a)]$，\n- 期望后验熵：$\\mathbb{E}_{o \\sim p(o \\mid a)}[H[p(s \\mid o,a)]]$，\n- 期望减少量：$H[p(s)] - \\mathbb{E}_{o \\sim p(o \\mid a)}[H[p(s \\mid o,a)]]$。\n\n您必须：\n1. 仅使用贝叶斯法则和香农熵，从第一性原理推导对于任意给定的 $(\\pi,\\alpha_0,\\alpha_1)$，后验熵期望减少量的计算方法。\n2. 实现一个程序，该程序为每个测试用例计算 $a=0$ 和 $a=1$ 时的后验熵期望减少量，选择使期望减少量最大化的行动（平局时选择较小的索引），并为每个测试用例输出结果列表 $[R_0,R_1,A^\\ast]$，其中 $R_0$ 和 $R_1$ 分别是 $a=0$ 和 $a=1$ 时的期望减少量（以奈特为单位，四舍五入到六位小数），$A^\\ast \\in \\{0,1\\}$ 是所选行动的索引。\n\n使用以下测试套件：\n- 案例 1：$\\pi=0.5$, $\\alpha_0=0.6$, $\\alpha_1=0.9$。\n- 案例 2：$\\pi=0.99$, $\\alpha_0=0.8$, $\\alpha_1=0.95$。\n- 案例 3：$\\pi=0.5$, $\\alpha_0=0.5$, $\\alpha_1=0.5$。\n- 案例 4：$\\pi=0.7$, $\\alpha_0=0.55$, $\\alpha_1=0.75$。\n\n所有熵值必须以奈特表示并四舍五入到六位小数。您的程序应生成单行输出，其中包含上述案例的结果，形式为包含在方括号内的逗号分隔列表，其中每个元素本身都是 $[R_0,R_1,A^\\ast]$ 形式的列表。例如：$[[0.123456,0.234567,1],[\\dots]]$。\n\n不允许外部输入；请将测试套件硬编码在程序中。解决方案必须在纯数学意义上适用，并且可用任何现代编程语言解决。请通过不引入无效概率（例如，$[0,1]$ 范围之外的概率）来确保数值稳定性和科学真实性。",
            "solution": "首先根据既定标准对用户提供的问题进行验证。\n\n### 步骤1：提取已知条件\n- **隐状态：** $s \\in \\{0,1\\}$\n- **观测：** $o \\in \\{0,1\\}$\n- **行动：** $a \\in \\{0,1\\}$\n- **先验信念：** $p(s=1) = \\pi$, $p(s=0) = 1-\\pi$.\n- **似然模型：** 这是一个对称二元信道，其中正确观测的概率为 $\\alpha_a \\in [0.5, 1]$，依赖于行动 $a$。\n  - $p(o=1 \\mid s=1,a) = \\alpha_a$\n  - $p(o=0 \\mid s=1,a) = 1-\\alpha_a$\n  - $p(o=0 \\mid s=0,a) = \\alpha_a$\n  - $p(o=1 \\mid s=0,a) = 1-\\alpha_a$\n- **基本原理：**\n  - 贝叶斯法则：$p(s \\mid o,a) = \\frac{p(o \\mid s,a)\\,p(s)}{p(o \\mid a)}$，其中 $p(o \\mid a) = \\sum_{s} p(o \\mid s,a)\\,p(s)$。\n  - 香农熵（以奈特为单位）：$H[p(x)] = -\\sum_i p(x_i)\\,\\ln p(x_i)$。\n- **目标函数：** 行动 $a$ 的后验熵期望减少量，记为 $R_a$，定义为：\n  $R_a = H[p(s)] - \\mathbb{E}_{o \\sim p(o \\mid a)}[H[p(s \\mid o,a)]]$，其中：\n  - $H[p(s)]$ 是状态先验分布的熵。\n  - $H[p(s \\mid o,a)]$ 是在采取行动 $a$ 并观测到 $o$ 后状态后验分布的熵。\n  - $\\mathbb{E}_{o \\sim p(o \\mid a)}[\\cdot]$ 表示对从分布 $p(o \\mid a)$ 中抽取的观测 $o$ 的期望。\n- **行动选择：** 最优行动 $A^\\ast$ 是使熵的期望减少量最大化的行动，平局时选择较小的行动索引（$a=0$）。$A^\\ast = \\arg\\max_a R_a$。\n- **测试用例：**\n    1. $\\pi=0.5$, $\\alpha_0=0.6$, $\\alpha_1=0.9$\n    2. $\\pi=0.99$, $\\alpha_0=0.8$, $\\alpha_1=0.95$\n    3. $\\pi=0.5$, $\\alpha_0=0.5$, $\\alpha_1=0.5$\n    4. $\\pi=0.7$, $\\alpha_0=0.55$, $\\alpha_1=0.75$\n\n### 步骤2：使用提取的已知条件进行验证\n- **科学依据：** 该问题坚实地植根于贝叶斯概率和信息论，这是计算神经科学和机器学习的基础。该模型虽然简单，却是一个标准范式，用于阐释主动推断和预测编码的原理，即智能体通过行动来减少其对世界的不确定性。该问题在科学上是合理的。\n- **适定性：** 所有必要的参数（$\\pi, \\alpha_0, \\alpha_1$）、定义（熵、贝叶斯法则）和目标都已明确给出。问题是自洽的，并且对每个测试用例都有唯一的、可计算的解。\n- **客观性：** 问题使用精确的数学语言陈述，没有任何主观或模糊的术语。\n- **其他标准：** 问题不存在矛盾、不完整或基于不切实际的物理学。它是一个可形式化且非平凡的计算任务。\n\n### 步骤3：结论与行动\n问题有效。下面将提供解决方案的逐步推导。\n\n### 解决方案推导\n\n解决方案需要为每个行动 $a \\in \\{0,1\\}$ 计算后验熵的期望减少量 $R_a$。这个量也被称为期望信息增益或互信息 $I(S;O|a)$。\n\n**1. 先验熵**\n二元状态 $s$ 的先验分布是参数为 $\\pi$ 的伯努利分布。其香农熵 $H[p(s)]$ 为：\n$$ H[p(s)] = -\\left[ p(s=0)\\ln(p(s=0)) + p(s=1)\\ln(p(s=1)) \\right] = -\\left[ (1-\\pi)\\ln(1-\\pi) + \\pi\\ln(\\pi) \\right] $$\n为简洁起见，我们可以使用二元熵函数 $h(x) = -x\\ln(x) - (1-x)\\ln(1-x)$。因此，$H[p(s)] = h(\\pi)$。按照惯例，$0\\ln(0)=0$，所以如果 $\\pi=0$ 或 $\\pi=1$，熵为 $0$。\n\n**2. 观测的边际概率**\n对于给定的行动 $a$ 和准确度参数 $\\alpha_a$，我们通过对隐状态 $s$ 进行边际化来计算每个观测 $o$ 的概率：\n$$ p(o \\mid a) = \\sum_{s \\in \\{0,1\\}} p(o \\mid s, a) p(s) $$\n对于 $o=1$:\n$$ p(o=1 \\mid a) = p(o=1 \\mid s=1, a)p(s=1) + p(o=1 \\mid s=0, a)p(s=0) = \\alpha_a \\pi + (1-\\alpha_a)(1-\\pi) $$\n对于 $o=0$:\n$$ p(o=0 \\mid a) = p(o=0 \\mid s=1, a)p(s=1) + p(o=0 \\mid s=0, a)p(s=0) = (1-\\alpha_a)\\pi + \\alpha_a(1-\\pi) $$\n可以验证 $p(o=1 \\mid a) + p(o=0 \\mid a) = 1$。\n\n**3. 隐状态的后验概率**\n使用贝叶斯法则，我们求得在给定观测 $o$ 和行动 $a$ 的情况下状态 $s=1$ 的后验概率，我们将其记为 $\\pi'_{o,a}$：\n$$ \\pi'_{o,a} = p(s=1 \\mid o, a) = \\frac{p(o \\mid s=1, a)p(s=1)}{p(o \\mid a)} $$\n如果 $o=1$：\n$$ \\pi'_{1,a} = \\frac{\\alpha_a \\pi}{p(o=1 \\mid a)} = \\frac{\\alpha_a \\pi}{\\alpha_a \\pi + (1-\\alpha_a)(1-\\pi)} $$\n如果 $o=0$：\n$$ \\pi'_{0,a} = \\frac{(1-\\alpha_a) \\pi}{p(o=0 \\mid a)} = \\frac{(1-\\alpha_a) \\pi}{(1-\\alpha_a)\\pi + \\alpha_a(1-\\pi)} $$\n状态 $s=0$ 的后验概率则为 $1 - \\pi'_{o,a}$。\n\n**4. 期望后验熵**\n后验分布 $p(s \\mid o, a)$ 的熵为 $H[p(s \\mid o, a)] = h(\\pi'_{o,a})$。期望后验熵是这些后验熵的加权平均，权重为每个观测的概率：\n$$ \\mathbb{E}_{o \\sim p(o \\mid a)}[H[p(s \\mid o,a)]] = p(o=0 \\mid a)H[p(s \\mid o=0, a)] + p(o=1 \\mid a)H[p(s \\mid o=1, a)] $$\n$$ \\mathbb{E}_{o \\sim p(o \\mid a)}[H[p(s \\mid o,a)]] = p(o=0 \\mid a) \\cdot h(\\pi'_{0,a}) + p(o=1 \\mid a) \\cdot h(\\pi'_{1,a}) $$\n\n**5. 熵的期望减少量**\n最终值 $R_a$ 是先验熵与期望后验熵之差：\n$$ R_a = H[p(s)] - \\mathbb{E}_{o \\sim p(o \\mid a)}[H[p(s \\mid o,a)]] $$\n对 $a=0$（使用 $\\alpha_0$）和 $a=1$（使用 $\\alpha_1$）分别执行此计算，以获得 $R_0$ 和 $R_1$。\n\n**6. 行动选择**\n智能体选择使期望信息增益最大化的行动。\n$$ A^\\ast = \\begin{cases} 1  \\text{if } R_1 > R_0 \\\\ 0  \\text{if } R_1 \\le R_0 \\end{cases} $$\n这遵循了指定的平局决胜规则。每个测试用例的结果是一个三元组 $[R_0, R_1, A^\\ast]$。此过程的实现将在下一节中提供。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the Active Inference problem by calculating expected entropy reduction for given test cases.\n    \"\"\"\n    \n    # Define the test cases from the problem statement.\n    test_cases = [\n        # (pi, alpha_0, alpha_1)\n        (0.5, 0.6, 0.9),\n        (0.99, 0.8, 0.95),\n        (0.5, 0.5, 0.5),\n        (0.7, 0.55, 0.75),\n    ]\n\n    def binary_entropy(p):\n        \"\"\"\n        Calculates the Shannon entropy for a binary probability distribution p(x=1)=p.\n        H(p) = -p*ln(p) - (1-p)*ln(1-p) in nats.\n        Handles edge cases where p=0 or p=1.\n        \"\"\"\n        if p == 0 or p == 1:\n            return 0.0\n        return -p * np.log(p) - (1 - p) * np.log(1 - p)\n\n    def calculate_expected_reduction(pi, alpha_a):\n        \"\"\"\n        Computes the expected reduction in posterior entropy for a given prior pi and action accuracy alpha_a.\n        \"\"\"\n        # 1. Prior Entropy\n        prior_entropy = binary_entropy(pi)\n        \n        # If prior is certain, no uncertainty to reduce.\n        if prior_entropy == 0.0:\n            return 0.0\n\n        # Special case: if action is uninformative, posterior equals prior, so no reduction.\n        if alpha_a == 0.5:\n            return 0.0\n\n        # 2. Marginal Probability of Observations\n        # p(o=1 | a)\n        p_o1_a = alpha_a * pi + (1 - alpha_a) * (1 - pi)\n        # p(o=0 | a)\n        p_o0_a = 1.0 - p_o1_a\n\n        # 3. Posterior Probabilities of Hidden States\n        # p(s=1 | o=1, a)\n        # Handle cases where p_o1_a might be zero if pi=0 or pi=1.\n        if p_o1_a > 0:\n            post_s1_o1 = (alpha_a * pi) / p_o1_a\n        else: # This happens if pi=0 and alpha_a=1, or pi=1 and alpha_a=0 (not in domain)\n            post_s1_o1 = 0\n            \n        # p(s=1 | o=0, a)\n        if p_o0_a > 0:\n            post_s1_o0 = ((1 - alpha_a) * pi) / p_o0_a\n        else: # This happens if pi=1 and alpha_a=1, or pi=0 and alpha_a=0 (not in domain)\n            post_s1_o0 = 0\n\n        # 4. Expected Posterior Entropy\n        # H[p(s|o=1,a)]\n        post_entropy_o1 = binary_entropy(post_s1_o1)\n        # H[p(s|o=0,a)]\n        post_entropy_o0 = binary_entropy(post_s1_o0)\n        \n        expected_posterior_entropy = p_o1_a * post_entropy_o1 + p_o0_a * post_entropy_o0\n\n        # 5. Expected Reduction in Entropy\n        reduction = prior_entropy - expected_posterior_entropy\n        \n        return reduction\n\n    \n    results_str_list = []\n    for case in test_cases:\n        pi, alpha_0, alpha_1 = case\n        \n        # Compute reduction for action a=0\n        R0 = calculate_expected_reduction(pi, alpha_0)\n        \n        # Compute reduction for action a=1\n        R1 = calculate_expected_reduction(pi, alpha_1)\n        \n        # Select action that maximizes reduction, tie-break to a=0\n        A_star = 1 if R1 > R0 else 0\n        \n        # Format results as specified\n        formatted_r0 = f\"{round(R0, 6):.6f}\"\n        formatted_r1 = f\"{round(R1, 6):.6f}\"\n        result_str = f\"[{formatted_r0},{formatted_r1},{A_star}]\"\n        results_str_list.append(result_str)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(results_str_list)}]\")\n\nsolve()\n```"
        }
    ]
}