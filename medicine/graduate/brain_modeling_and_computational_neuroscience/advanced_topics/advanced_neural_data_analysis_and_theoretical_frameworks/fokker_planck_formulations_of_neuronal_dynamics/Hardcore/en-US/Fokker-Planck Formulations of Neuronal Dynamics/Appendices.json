{
    "hands_on_practices": [
        {
            "introduction": "Before diving into complex numerical simulations, it is invaluable to solve a simplified problem analytically to build physical intuition. This first exercise explores the classic Kramers' escape problem, a cornerstone of statistical physics, applied to a canonical neuron model . By using asymptotic methods in the low-noise limit, you will derive an explicit formula for the firing rate, revealing the fundamental exponential relationship between noise intensity, the potential barrier height, and the rate of rare, noise-driven events like neuronal spiking.",
            "id": "3982076",
            "problem": "Consider the stochastic dynamics of a canonical one-dimensional excitable neuron model in nondimensionalized time, driven by additive Gaussian white noise, given by the ItÃ´ stochastic differential equation\n$$\n\\mathrm{d}V_{t} \\;=\\; f(V_{t})\\,\\mathrm{d}t \\;+\\; \\sqrt{2D}\\,\\mathrm{d}W_{t},\n$$\nwhere $V_{t}$ is the membrane potential, $W_{t}$ is a standard Wiener process, $D$ is a small positive diffusion coefficient, and the deterministic drift is the saddle-node normal form\n$$\nf(V) \\;=\\; -a \\;+\\; V^{2},\n$$\nwith parameter $a>0$. The system has a stable rest point at $V_{s}=-\\sqrt{a}$ and an unstable threshold (saddle) at $V_{b}=+\\sqrt{a}$. Define firing as absorption at a threshold $V_{\\mathrm{th}}>V_{b}$, and assume the probability distribution is confined within the basin of attraction of $V_{s}$ so that a quasi-stationary state exists with a small probability current through the threshold.\n\nLet $p(V,t)$ denote the probability density of $V_{t}$, and $\\mathcal{J}(V,t)$ the associated probability flux defined from the Fokker-Planck equation (FPE). In the small-noise regime $D\\to 0^{+}$, use matched asymptotic expansions for the outer solution in the basin of attraction and the inner boundary layer near the unstable threshold to compute the leading-order asymptotic firing rate $r$ as the stationary threshold flux in the quasi-stationary state. As a physically meaningful base, work from the Fokker-Planck equation,\n$$\n\\frac{\\partial p}{\\partial t} \\;=\\; -\\frac{\\partial}{\\partial V}\\big(f(V)p\\big) \\;+\\; D\\,\\frac{\\partial^{2}p}{\\partial V^{2}},\n$$\nand the conservative representation $f(V)=-U'(V)$ for a smooth potential $U(V)$.\n\nExpress the final answer as a single closed-form analytic expression for $r$ in terms of $a$ and $D$, and relate it explicitly to the classical Kramers barrier-crossing rate by identifying the barrier height and local curvatures. No numerical approximation or rounding is required; provide the exact leading-order asymptotic expression. The time units are nondimensional.",
            "solution": "The user wants to compute the leading-order asymptotic firing rate for a one-dimensional excitable neuron model described by a stochastic differential equation.\n\n### Step 1: Extract Givens\n- **Stochastic Differential Equation (SDE)**: $\\mathrm{d}V_{t} = f(V_{t})\\,\\mathrm{d}t + \\sqrt{2D}\\,\\mathrm{d}W_{t}$\n- **Drift Term**: $f(V) = -a + V^{2}$, with $a>0$\n- **Diffusion Coefficient**: $D$, a small positive constant ($D\\to 0^{+}$)\n- **Wiener Process**: $W_{t}$ is a standard Wiener process.\n- **Stable Rest Point**: $V_{s}=-\\sqrt{a}$\n- **Unstable Threshold**: $V_{b}=+\\sqrt{a}$\n- **Firing Condition**: Absorption at a threshold $V_{\\mathrm{th}} > V_{b}$.\n- **Fokker-Planck Equation (FPE)**: $\\frac{\\partial p}{\\partial t} = -\\frac{\\partial}{\\partial V}\\left(f(V)p\\right) + D\\,\\frac{\\partial^{2}p}{\\partial V^{2}}$\n- **Potential Definition**: $f(V) = -U'(V)$ for a potential $U(V)$.\n\n### Step 2: Validate Using Extracted Givens\nThe problem is scientifically grounded. It describes a canonical problem in statistical physics and computational neuroscience known as Kramers' escape rate problem, applied to a simplified neuron model (the saddle-node or normal form for a Type I excitable membrane). The SDE, FPE, and the concept of a quasi-stationary state are standard, well-established theoretical tools. The problem is well-posed: it is self-contained, provides all necessary information (the drift and diffusion terms, the boundary conditions implicitly defined by the dynamics), and asks for a well-defined physical quantity (the leading-order escape rate). The language is objective and precise. The problem is a non-trivial but solvable exercise in asymptotic analysis of stochastic processes, a core topic in the specified field. No flaws are identified.\n\n### Step 3: Verdict and Action\nThe problem is valid. A complete, reasoned solution will be provided.\n\n### Solution Derivation\nThe problem asks for the firing rate $r$, which is the rate of escape of the system from the basin of attraction of the stable fixed point $V_{s}$. In the context of the Fokker-Planck equation (FPE), this rate corresponds to the constant probability flux in the quasi-stationary state.\n\nThe FPE is given as:\n$$\n\\frac{\\partial p(V,t)}{\\partial t} = -\\frac{\\partial \\mathcal{J}(V,t)}{\\partial V}\n$$\nwhere $\\mathcal{J}(V,t)$ is the probability flux:\n$$\n\\mathcal{J}(V,t) = f(V)p(V,t) - D\\frac{\\partial p(V,t)}{\\partial V}\n$$\nIn the quasi-stationary state, the probability density within the potential well decays slowly with a single exponential rate $r$, i.e., $p(V,t) = p_{qs}(V) e^{-rt}$. The flux, however, is assumed to be stationary, $\\mathcal{J}(V,t) = \\mathcal{J}(V)$. Within the quasi-stationary approximation, the flux between the potential minimum and the absorbing boundary is taken to be constant, $\\mathcal{J}(V) = r$, where $r$ is the firing rate. This leads to the ordinary differential equation for the quasi-stationary probability density $p(V)$:\n$$\nr = f(V)p(V) - D\\frac{\\mathrm{d}p(V)}{\\mathrm{d}V}\n$$\nThe problem states that the drift term $f(V)$ can be derived from a potential $U(V)$ as $f(V) = -U'(V)$. Given $f(V) = -a + V^{2}$, we find $U'(V) = -f(V) = a - V^{2}$. Integrating with respect to $V$ yields the potential:\n$$\nU(V) = \\int(a-V^{2})\\mathrm{d}V = aV - \\frac{1}{3}V^{3}\n$$\nwhere we have set the integration constant to zero without loss of generality.\n\nThe ODE for $p(V)$ can be rewritten as:\n$$\n\\frac{\\mathrm{d}p}{\\mathrm{d}V} + \\frac{1}{D}U'(V)p(V) = -\\frac{r}{D}\n$$\nThis is a first-order linear ODE. We solve it using an integrating factor $I(V) = \\exp\\left(\\int \\frac{U'(V)}{D} \\mathrm{d}V\\right) = \\exp\\left(\\frac{U(V)}{D}\\right)$. Multiplying the ODE by $I(V)$ gives:\n$$\n\\frac{\\mathrm{d}}{\\mathrm{d}V}\\left(p(V) \\exp\\left(\\frac{U(V)}{D}\\right)\\right) = -\\frac{r}{D}\\exp\\left(\\frac{U(V)}{D}\\right)\n$$\nIntegrating this equation from a point $V$ to the absorbing boundary $V_{\\mathrm{th}}$ yields:\n$$\n\\left[ p(s)\\exp\\left(\\frac{U(s)}{D}\\right) \\right]_{V}^{V_{\\mathrm{th}}} = -\\frac{r}{D}\\int_{V}^{V_{\\mathrm{th}}} \\exp\\left(\\frac{U(s)}{D}\\right) \\mathrm{d}s\n$$\nThe firing condition is defined as absorption at $V_{\\mathrm{th}}$, which implies the boundary condition $p(V_{\\mathrm{th}})=0$. Applying this, we get:\n$$\n-p(V)\\exp\\left(\\frac{U(V)}{D}\\right) = -\\frac{r}{D}\\int_{V}^{V_{\\mathrm{th}}} \\exp\\left(\\frac{U(s)}{D}\\right) \\mathrm{d}s\n$$\nSolving for $p(V)$:\n$$\np(V) = \\frac{r}{D} \\exp\\left(-\\frac{U(V)}{D}\\right) \\int_{V}^{V_{\\mathrm{th}}} \\exp\\left(\\frac{U(s)}{D}\\right) \\mathrm{d}s\n$$\nThe rate $r$ is determined by the quasi-stationary normalization condition, $\\int_{-\\infty}^{V_{\\mathrm{th}}} p(V) \\mathrm{d}V = 1$. This leads to an expression for the inverse rate, $r^{-1}$:\n$$\nr^{-1} = \\frac{1}{D} \\int_{-\\infty}^{V_{\\mathrm{th}}} \\exp\\left(-\\frac{U(V)}{D}\\right) \\left( \\int_{V}^{V_{\\mathrm{th}}} \\exp\\left(\\frac{U(s)}{D}\\right) \\mathrm{d}s \\right) \\mathrm{d}V\n$$\nFor small $D$, this double integral can be evaluated using the saddle-point method (Laplace's method). We can change the order of integration:\n$$\nr^{-1} = \\frac{1}{D} \\int_{-\\infty}^{V_{\\mathrm{th}}} \\mathrm{d}s \\exp\\left(\\frac{U(s)}{D}\\right) \\int_{-\\infty}^{s} \\mathrm{d}V \\exp\\left(-\\frac{U(V)}{D}\\right)\n$$\nThe value of this integral is dominated by the regions where the exponents are maximal. The term $\\exp(U(s)/D)$ is maximal at the maximum of the potential $U(s)$, and the term $\\exp(-U(V)/D)$ is maximal at the minimum of the potential $U(V)$.\n\nThe extrema of $U(V)$ are found by setting $U'(V)=0$, which gives $a-V^{2}=0$, so $V=\\pm\\sqrt{a}$.\nThe stable point (potential minimum) is $V_{s} = -\\sqrt{a}$.\nThe unstable point (potential maximum, i.e., the barrier) is $V_{b} = +\\sqrt{a}$.\nThe second derivative is $U''(V)=-2V$.\nAt the minimum: $U''(V_s) = U''(-\\sqrt{a}) = 2\\sqrt{a} > 0$.\nAt the maximum: $U''(V_b) = U''(\\sqrt{a}) = -2\\sqrt{a} < 0$.\n\nThe inner integral, $\\int_{-\\infty}^{s} \\exp(-U(V)/D) \\mathrm{d}V$, is dominated by the contribution around the minimum $V_{s}$. We approximate $U(V)$ near $V_s$ with a Taylor expansion: $U(V) \\approx U(V_s) + \\frac{1}{2}U''(V_s)(V-V_s)^2$. The integral becomes a Gaussian:\n$$\n\\int_{-\\infty}^{s} \\exp\\left(-\\frac{U(V)}{D}\\right) \\mathrm{d}V \\approx \\exp\\left(-\\frac{U(V_s)}{D}\\right) \\int_{-\\infty}^{\\infty} \\exp\\left(-\\frac{U''(V_s)}{2D}(V-V_s)^2\\right) \\mathrm{d}V = \\exp\\left(-\\frac{U(V_s)}{D}\\right) \\sqrt{\\frac{2\\pi D}{U''(V_s)}}\n$$\nThe outer integral, $\\int_{-\\infty}^{V_{\\mathrm{th}}} \\exp(U(s)/D) \\mathrm{d}s$, is dominated by the barrier at $s=V_b$. We approximate $U(s)$ near $V_b$: $U(s) \\approx U(V_b) + \\frac{1}{2}U''(V_b)(s-V_b)^2$. The integral is:\n$$\n\\int_{-\\infty}^{V_{\\mathrm{th}}} \\exp\\left(\\frac{U(s)}{D}\\right) \\mathrm{d}s \\approx \\exp\\left(\\frac{U(V_b)}{D}\\right) \\int_{-\\infty}^{\\infty} \\exp\\left(\\frac{U''(V_b)}{2D}(s-V_b)^2\\right) \\mathrm{d}s = \\exp\\left(\\frac{U(V_b)}{D}\\right) \\sqrt{\\frac{2\\pi D}{-U''(V_b)}}\n$$\nSubstituting these approximations back into the formula for $r^{-1}$:\n$$\nr^{-1} \\approx \\frac{1}{D} \\left(\\exp\\left(\\frac{U(V_b)}{D}\\right) \\sqrt{\\frac{2\\pi D}{-U''(V_b)}}\\right) \\left(\\exp\\left(-\\frac{U(V_s)}{D}\\right) \\sqrt{\\frac{2\\pi D}{U''(V_s)}}\\right)\n$$\n$$\nr^{-1} \\approx \\frac{2\\pi}{\\sqrt{U''(V_s)}\\sqrt{-U''(V_b)}} \\exp\\left(\\frac{U(V_b)-U(V_s)}{D}\\right)\n$$\nInverting gives the firing rate $r$:\n$$\nr \\approx \\frac{\\sqrt{U''(V_s)}\\sqrt{-U''(V_b)}}{2\\pi} \\exp\\left(-\\frac{U(V_b)-U(V_s)}{D}\\right)\n$$\nThis is the classical Kramers' rate formula. We now evaluate the components for the given potential.\n\nThe barrier height is $\\Delta U = U(V_b) - U(V_s)$:\n$U(V_b) = U(\\sqrt{a}) = a\\sqrt{a} - \\frac{1}{3}(\\sqrt{a})^3 = \\frac{2}{3}a^{3/2}$\n$U(V_s) = U(-\\sqrt{a}) = a(-\\sqrt{a}) - \\frac{1}{3}(-\\sqrt{a})^3 = -\\frac{2}{3}a^{3/2}$\n$$\n\\Delta U = \\frac{2}{3}a^{3/2} - \\left(-\\frac{2}{3}a^{3/2}\\right) = \\frac{4}{3}a^{3/2}\n$$\nThe curvatures at the well bottom and barrier top are:\n$$\nU''(V_s) = 2\\sqrt{a}\n$$\n$$\n-U''(V_b) = -(-2\\sqrt{a}) = 2\\sqrt{a}\n$$\nSubstituting these into the Kramers' rate formula:\n$$\nr \\approx \\frac{\\sqrt{2\\sqrt{a}}\\sqrt{2\\sqrt{a}}}{2\\pi} \\exp\\left(-\\frac{4a^{3/2}}{3D}\\right)\n$$\n$$\nr \\approx \\frac{2\\sqrt{a}}{2\\pi} \\exp\\left(-\\frac{4a^{3/2}}{3D}\\right)\n$$\nFinally, simplifying the prefactor gives the leading-order asymptotic expression for the firing rate:\n$$\nr \\approx \\frac{\\sqrt{a}}{\\pi} \\exp\\left(-\\frac{4a^{3/2}}{3D}\\right)\n$$\nThis expression gives the firing rate in terms of the system parameters $a$ and $D$, and explicitly relates to the Kramers' formula through the identified barrier height $\\Delta U = \\frac{4}{3}a^{3/2}$ and curvatures $U''(V_s) = -U''(V_b) = 2\\sqrt{a}$.",
            "answer": "$$ \\boxed{ \\frac{\\sqrt{a}}{\\pi} \\exp\\left(-\\frac{4a^{3/2}}{3D}\\right) } $$"
        },
        {
            "introduction": "While analytical solutions provide deep insight, they are often restricted to simplified models. This practice guides you through a more general and powerful approach: numerically solving the stationary Fokker-Planck equation for a leaky integrate-and-fire (LIF) neuron population . You will implement the \"population density method,\" a workhorse of computational neuroscience, by discretizing the equation and its boundary conditions to find the steady-state voltage distribution and firing rate, bridging the gap between abstract theory and quantitative prediction.",
            "id": "4051216",
            "problem": "Consider a homogeneous population of uncoupled leaky integrate-and-fire (LIF) neurons under a diffusion approximation. Let the membrane voltage be denoted by $V$, and suppose each neuron obeys the stochastic differential equation (SDE) $dV = A(V)\\,dt + \\sigma\\,dW_t$, where $A(V) = -\\dfrac{V - V_{\\mathrm{L}}}{\\tau} + \\mu$. Here, $\\tau$ is the membrane time constant in seconds, $V_{\\mathrm{L}}$ is the leak reversal potential in volts, $\\mu$ is a constant drift term in volts per second, $\\sigma$ is the noise amplitude in volts per square root second, and $W_t$ is a standard Wiener process. The corresponding Fokker-Planck equation (FPE) for the probability density $p(V,t)$ is $\\dfrac{\\partial p}{\\partial t} = -\\dfrac{\\partial J}{\\partial V}$ with probability flux $J(V,t) = A(V)\\,p(V,t) - D\\,\\dfrac{\\partial p}{\\partial V}$, where $D = \\dfrac{\\sigma^2}{2}$.\n\nIn the steady state, let $p(V)$ be time-independent and let the flux be piecewise constant except at the reset voltage due to reinjection of mass. Impose the following boundary conditions in voltage space:\n- Absorbing boundary at the threshold voltage $V_{\\mathrm{th}}$, i.e., $p(V_{\\mathrm{th}}) = 0$, and the outgoing flux at threshold equals the steady firing rate $r$ in per second.\n- Reinjection at the reset voltage $V_{\\mathrm{r}}$, modeled as a point source of probability current of strength $r$, yielding a jump in flux across $V_{\\mathrm{r}}$ equal to $r$.\n- Zero-flux boundary at a lower bound $V_{\\min}$, i.e., $J(V_{\\min}) = 0$.\n- Normalization condition $\\int_{V_{\\min}}^{V_{\\mathrm{th}}} p(V)\\,dV = 1$.\n\nYour task is to formulate and implement the population density method by discretizing the stationary Fokker-Planck equation with appropriate flux boundary conditions to compute the steady-state firing rate $r$ and the stationary density $p(V)$ numerically. Use a uniform grid of $N+1$ points on the interval $[V_{\\min}, V_{\\mathrm{th}}]$ with grid spacing $\\Delta V = \\dfrac{V_{\\mathrm{th}} - V_{\\min}}{N}$. Denote the grid points by $V_i = V_{\\min} + i\\,\\Delta V$ for $i \\in \\{0,1,\\dots,N\\}$ and the discrete density by $p_i \\approx p(V_i)$. Approximate the steady-state flux at grid point $V_i$ by the first-order finite-volume expression $J_i = A(V_i)\\,p_i - D\\,\\dfrac{p_i - p_{i-1}}{\\Delta V}$ for $i \\in \\{1,2,\\dots,N\\}$. Let the reset index $k$ be the index closest to $V_{\\mathrm{r}}$ on this grid.\n\nEnforce the following discrete conditions:\n- For $i \\in \\{1,2,\\dots,k\\}$, set $J_i = 0$ to reflect zero flux below reset.\n- For $i \\in \\{k+1,k+2,\\dots,N-1\\}$, set $J_i = r$ to reflect constant outgoing flux above reset.\n- At threshold, enforce $J_N = r$ with $p_N = 0$ via $r - D\\,\\dfrac{p_{N-1}}{\\Delta V} = 0$.\n- Enforce normalization $\\sum_{i=0}^{N-1} p_i\\,\\Delta V = 1$.\n\nThis yields a linear system in the unknowns $\\{p_0,p_1,\\dots,p_{N-1},r\\}$, which you must solve to obtain $r$ and $p_i$. You must ensure scientific realism by using parameter values that produce physically plausible densities and rates. Express firing rates in per second ($\\mathrm{s}^{-1}$).\n\nImplement a complete program that:\n- Builds and solves the described linear system for each test case.\n- Returns the steady-state firing rate $r$ for each test case as a floating-point number in $\\mathrm{s}^{-1}$.\n- Internally also computes the stationary density $p_i$ on the grid, although only the rates are required to be output.\n\nTest Suite:\nUse the following parameter sets as the test suite. For all cases, use $A(V) = -\\dfrac{V - V_{\\mathrm{L}}}{\\tau} + \\mu$ and $D = \\dfrac{\\sigma^2}{2}$.\n\n- Case $1$ (general case): $\\tau = 0.02$ $\\mathrm{s}$, $V_{\\mathrm{L}} = -0.065$ $\\mathrm{V}$, $\\mu = 0.001$ $\\mathrm{V/s}$, $\\sigma = 0.003$ $\\mathrm{V/\\sqrt{s}}$, $V_{\\mathrm{th}} = -0.050$ $\\mathrm{V}$, $V_{\\mathrm{r}} = -0.065$ $\\mathrm{V}$, $V_{\\min} = -0.085$ $\\mathrm{V}$, $N = 200$.\n- Case $2$ (low diffusion edge): $\\tau = 0.02$ $\\mathrm{s}$, $V_{\\mathrm{L}} = -0.065$ $\\mathrm{V}$, $\\mu = 0.001$ $\\mathrm{V/s}$, $\\sigma = 0.0001$ $\\mathrm{V/\\sqrt{s}}$, $V_{\\mathrm{th}} = -0.050$ $\\mathrm{V}$, $V_{\\mathrm{r}} = -0.065$ $\\mathrm{V}$, $V_{\\min} = -0.085$ $\\mathrm{V}$, $N = 200$.\n- Case $3$ (high drift): $\\tau = 0.02$ $\\mathrm{s}$, $V_{\\mathrm{L}} = -0.065$ $\\mathrm{V}$, $\\mu = 0.010$ $\\mathrm{V/s}$, $\\sigma = 0.002$ $\\mathrm{V/\\sqrt{s}}$, $V_{\\mathrm{th}} = -0.050$ $\\mathrm{V}$, $V_{\\mathrm{r}} = -0.065$ $\\mathrm{V}$, $V_{\\min} = -0.085$ $\\mathrm{V}$, $N = 200$.\n- Case $4$ (reset at lower bound): $\\tau = 0.02$ $\\mathrm{s}$, $V_{\\mathrm{L}} = -0.065$ $\\mathrm{V}$, $\\mu = 0.002$ $\\mathrm{V/s}$, $\\sigma = 0.004$ $\\mathrm{V/\\sqrt{s}}$, $V_{\\mathrm{th}} = -0.050$ $\\mathrm{V}$, $V_{\\mathrm{r}} = -0.075$ $\\mathrm{V}$, $V_{\\min} = -0.075$ $\\mathrm{V}$, $N = 150$.\n\nFinal Output Format:\nYour program should produce a single line of output containing the firing rates for the four test cases as a comma-separated list enclosed in square brackets, for example, $[r_1,r_2,r_3,r_4]$, where each $r_i$ is a floating-point number in $\\mathrm{s}^{-1}$ with default Python formatting. No other text should be printed.",
            "solution": "The user wants to solve a problem in computational neuroscience, specifically calculating the steady-state firing rate of a population of leaky integrate-and-fire (LIF) neurons using the Fokker-Planck formalism.\n\n### Problem Validation\n\nFirst, I will validate the problem statement according to the specified protocol.\n\n#### Step 1: Extract Givens\n\n- **Stochastic Differential Equation (SDE)**: $dV = A(V)\\,dt + \\sigma\\,dW_t$\n- **Drift Term**: $A(V) = -\\dfrac{V - V_{\\mathrm{L}}}{\\tau} + \\mu$\n- **Parameters**:\n    - $\\tau$: membrane time constant (s)\n    - $V_{\\mathrm{L}}$: leak reversal potential (V)\n    - $\\mu$: constant drift term (V/s)\n    - $\\sigma$: noise amplitude (V/$\\sqrt{\\mathrm{s}}$)\n- **Fokker-Planck Equation (FPE)**: $\\dfrac{\\partial p}{\\partial t} = -\\dfrac{\\partial J}{\\partial V}$\n- **Probability Flux**: $J(V,t) = A(V)\\,p(V,t) - D\\,\\dfrac{\\partial p}{\\partial V}$, where $D = \\dfrac{\\sigma^2}{2}$.\n- **Steady-State Conditions**:\n    - $\\dfrac{\\partial p}{\\partial t} = 0$, so $J(V)$ is piecewise constant.\n    - $r$: steady firing rate ($\\mathrm{s}^{-1}$).\n- **Boundary Conditions**:\n    - Absorbing boundary at threshold: $p(V_{\\mathrm{th}}) = 0$.\n    - Outgoing flux at threshold: $J(V_{\\mathrm{th}}) = r$.\n    - Reinjection at reset: Flux jump of $r$ across $V_{\\mathrm{r}}$.\n    - Zero-flux at lower bound: $J(V_{\\min}) = 0$.\n    - Normalization: $\\int_{V_{\\min}}^{V_{\\mathrm{th}}} p(V)\\,dV = 1$.\n- **Numerical Discretization**:\n    - Grid: Uniform with $N+1$ points on $[V_{\\min}, V_{\\mathrm{th}}]$.\n    - Grid spacing: $\\Delta V = \\dfrac{V_{\\mathrm{th}} - V_{\\min}}{N}$.\n    - Grid points: $V_i = V_{\\min} + i\\,\\Delta V$ for $i \\in \\{0, 1, \\dots, N\\}$.\n    - Discrete density: $p_i \\approx p(V_i)$.\n    - Reset index: $k$ is the index closest to $V_{\\mathrm{r}}$.\n    - Discrete flux: $J_i = A(V_i)\\,p_i - D\\,\\dfrac{p_i - p_{i-1}}{\\Delta V}$ for $i \\in \\{1, 2, \\dots, N\\}$.\n- **Discrete System Conditions**:\n    - For $i \\in \\{1, 2, \\dots, k\\}$: $J_i = 0$.\n    - For $i \\in \\{k+1, k+2, \\dots, N-1\\}$: $J_i = r$.\n    - At threshold ($i=N$): $J_N = r$ with $p_N = 0$, imposed via $r - D\\,\\dfrac{p_{N-1}}{\\Delta V} = 0$.\n    - Normalization: $\\sum_{i=0}^{N-1} p_i\\,\\Delta V = 1$.\n- **Test Suite**:\n    - Case 1: $\\tau = 0.02$ $\\mathrm{s}$, $V_{\\mathrm{L}} = -0.065$ $\\mathrm{V}$, $\\mu = 0.001$ $\\mathrm{V/s}$, $\\sigma = 0.003$ $\\mathrm{V/\\sqrt{s}}$, $V_{\\mathrm{th}} = -0.050$ $\\mathrm{V}$, $V_{\\mathrm{r}} = -0.065$ $\\mathrm{V}$, $V_{\\min} = -0.085$ $\\mathrm{V}$, $N = 200$.\n    - Case 2: $\\tau = 0.02$ $\\mathrm{s}$, $V_{\\mathrm{L}} = -0.065$ $\\mathrm{V}$, $\\mu = 0.001$ $\\mathrm{V/s}$, $\\sigma = 0.0001$ $\\mathrm{V/\\sqrt{s}}$, $V_{\\mathrm{th}} = -0.050$ $\\mathrm{V}$, $V_{\\mathrm{r}} = -0.065$ $\\mathrm{V}$, $V_{\\min} = -0.085$ $\\mathrm{V}$, $N = 200$.\n    - Case 3: $\\tau = 0.02$ $\\mathrm{s}$, $V_{\\mathrm{L}} = -0.065$ $\\mathrm{V}$, $\\mu = 0.010$ $\\mathrm{V/s}$, $\\sigma = 0.002$ $\\mathrm{V/\\sqrt{s}}$, $V_{\\mathrm{th}} = -0.050$ $\\mathrm{V}$, $V_{\\mathrm{r}} = -0.065$ $\\mathrm{V}$, $V_{\\min} = -0.085$ $\\mathrm{V}$, $N = 200$.\n    - Case 4: $\\tau = 0.02$ $\\mathrm{s}$, $V_{\\mathrm{L}} = -0.065$ $\\mathrm{V}$, $\\mu = 0.002$ $\\mathrm{V/s}$, $\\sigma = 0.004$ $\\mathrm{V/\\sqrt{s}}$, $V_{\\mathrm{th}} = -0.050$ $\\mathrm{V}$, $V_{\\mathrm{r}} = -0.075$ $\\mathrm{V}$, $V_{\\min} = -0.075$ $\\mathrm{V}$, $N = 150$.\n\n#### Step 2: Validate Using Extracted Givens\n\n- **Scientifically Grounded**: The problem describes the diffusion approximation for a population of LIF neurons, leading to a Fokker-Planck equation. This is a canonical and scientifically established method in theoretical and computational neuroscience. The parameters are provided in consistent SI units (V, s) and their magnitudes are physically plausible for biological neurons.\n- **Well-Posed**: The problem requires solving for $N+1$ unknowns: the $N$ probability density values $\\{p_0, p_1, \\dots, p_{N-1}\\}$ and the firing rate $r$. The problem provides $N+1$ linear equations: $k$ equations from $J_i=0$, $N-1-k$ equations from $J_i=r$, one equation for the boundary condition at threshold $J_N=r$, and one normalization equation. The total number of linear equations ($k + (N-1-k) + 1 + 1 = N+1$) matches the number of unknowns. This forms a linear system of the form $M \\mathbf{x} = \\mathbf{b}$, which is expected to have a unique solution for the given physical parameters.\n- **Objective**: The problem is stated using precise mathematical definitions and objective language, free from ambiguity or subjective claims.\n- **Other Flaws**: The problem is self-contained, with all necessary data and conditions provided. It does not contain contradictions; even in Case 4 where $V_{\\mathrm{r}} = V_{\\min}$, the discrete formulation handles this as a specific boundary case where reinjection occurs at the lower reflective barrier. The problem is not trivial, requiring a careful implementation of a numerical method.\n\n#### Step 3: Verdict and Action\n\nThe problem is **valid**. I will proceed with the solution.\n\n### Solution Derivation and Implementation\n\nThe task is to compute the steady-state firing rate $r$ by solving a system of linear equations derived from the discretized stationary Fokker-Planck equation. The unknowns are the probability densities $p_i$ at each grid point $V_i$ for $i \\in \\{0, \\dots, N-1\\}$ and the firing rate $r$. This gives a total of $N+1$ unknowns. We must construct a linear system $M \\mathbf{x} = \\mathbf{b}$ of size $(N+1) \\times (N+1)$, where $\\mathbf{x} = [p_0, p_1, \\dots, p_{N-1}, r]^T$.\n\n1.  **Define Grid and Parameters**:\n    The voltage domain $[V_{\\min}, V_{\\mathrm{th}}]$ is discretized into $N$ intervals of width $\\Delta V = (V_{\\mathrm{th}} - V_{\\min}) / N$. The grid points are $V_i = V_{\\min} + i\\Delta V$. The diffusion coefficient is $D = \\sigma^2/2$. The drift is $A_i = A(V_i) = -(V_i - V_{\\mathrm{L}})/\\tau + \\mu$. The reset index $k$ is the grid index closest to $V_{\\mathrm{r}}$.\n\n2.  **Formulate the Linear System**:\n    We assemble the $(N+1) \\times (N+1)$ matrix $M$ and the $(N+1) \\times 1$ vector $\\mathbf{b}$ based on the $N+1$ discrete conditions. The columns of $M$ correspond to the coefficients of $p_0, \\dots, p_{N-1}, r$.\n\n    - **Flux equations for $i \\in \\{1, \\dots, k\\}$ ($k$ equations)**:\n      The condition is $J_i = 0$. Substituting the discrete flux expression:\n      $A_i p_i - D \\dfrac{p_i - p_{i-1}}{\\Delta V} = 0 \\implies \\left(\\dfrac{D}{\\Delta V}\\right) p_{i-1} + \\left(A_i - \\dfrac{D}{\\Delta V}\\right) p_i = 0$.\n      For each $i$ in this range, we fill row $i-1$ of matrix $M$:\n      $M[i-1, i-1] = \\dfrac{D}{\\Delta V}$\n      $M[i-1, i] = A_i - \\dfrac{D}{\\Delta V}$\n\n    - **Flux equations for $i \\in \\{k+1, \\dots, N-1\\}$ ($N-1-k$ equations)**:\n      The condition is $J_i = r$.\n      $A_i p_i - D \\dfrac{p_i - p_{i-1}}{\\Delta V} = r \\implies \\left(\\dfrac{D}{\\Delta V}\\right) p_{i-1} + \\left(A_i - \\dfrac{D}{\\Delta V}\\right) p_i - r = 0$.\n      For each $i$ in this range, we fill row $i-1$ of matrix $M$. Note that the last column, index $N$, corresponds to the unknown $r$.\n      $M[i-1, i-1] = \\dfrac{D}{\\Delta V}$\n      $M[i-1, i] = A_i - \\dfrac{D}{\\Delta V}$\n      $M[i-1, N] = -1$\n\n    - **Threshold flux equation ($1$ equation)**:\n      The condition at $i=N$ is $r - D \\dfrac{p_{N-1}}{\\Delta V} = 0$. This comes from $J_N = r$ with the approximation $J_N \\approx -D\\frac{p_N - p_{N-1}}{\\Delta V}$ and the boundary condition $p_N=p(V_{th})=0$.\n      This gives $-\\left(\\dfrac{D}{\\Delta V}\\right) p_{N-1} + r = 0$.\n      This corresponds to row $N-1$ of matrix $M$:\n      $M[N-1, N-1] = -\\dfrac{D}{\\Delta V}$\n      $M[N-1, N] = 1$\n\n    - **Normalization equation ($1$ equation)**:\n      The condition is $\\sum_{i=0}^{N-1} p_i \\Delta V = 1$. The trapezoidal rule is used here, but the problem statement specifies a simpler sum which we follow.\n      This corresponds to the last row, $N$, of matrix $M$:\n      $M[N, j] = \\Delta V$ for $j \\in \\{0, \\dots, N-1\\}$\n      $M[N, N] = 0$\n      The corresponding entry in the vector $\\mathbf{b}$ is $b_N = 1$. All other entries of $\\mathbf{b}$ are $0$.\n\n3.  **Solve the System**:\n    With the matrix $M$ and vector $\\mathbf{b}$ fully constructed, the system $M \\mathbf{x} = \\mathbf{b}$ is solved for the vector of unknowns $\\mathbf{x}$. The last element of the solution vector, $x_N$, is the steady-state firing rate $r$. The implementation will use `numpy.linalg.solve` for this purpose. This procedure is repeated for each parameter set in the test suite.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to solve the problem for the given test cases.\n    \"\"\"\n    # Test cases defined in the problem statement.\n    test_cases = [\n        {\n            \"tau\": 0.02, \"V_L\": -0.065, \"mu\": 0.001, \"sigma\": 0.003,\n            \"V_th\": -0.050, \"V_r\": -0.065, \"V_min\": -0.085, \"N\": 200\n        },\n        {\n            \"tau\": 0.02, \"V_L\": -0.065, \"mu\": 0.001, \"sigma\": 0.0001,\n            \"V_th\": -0.050, \"V_r\": -0.065, \"V_min\": -0.085, \"N\": 200\n        },\n        {\n            \"tau\": 0.02, \"V_L\": -0.065, \"mu\": 0.010, \"sigma\": 0.002,\n            \"V_th\": -0.050, \"V_r\": -0.065, \"V_min\": -0.085, \"N\": 200\n        },\n        {\n            \"tau\": 0.02, \"V_L\": -0.065, \"mu\": 0.002, \"sigma\": 0.004,\n            \"V_th\": -0.050, \"V_r\": -0.075, \"V_min\": -0.075, \"N\": 150\n        }\n    ]\n\n    results = []\n    for params in test_cases:\n        r = calculate_firing_rate(**params)\n        results.append(r)\n\n    # Print the final result in the specified format.\n    print(f\"[{','.join(map(str, results))}]\")\n\ndef calculate_firing_rate(tau, V_L, mu, sigma, V_th, V_r, V_min, N):\n    \"\"\"\n    Calculates the steady-state firing rate for a single set of parameters.\n    \"\"\"\n    # System parameters\n    D = sigma**2 / 2.0\n    def A(V):\n        return -(V - V_L) / tau + mu\n\n    # Discretization\n    V_grid = np.linspace(V_min, V_th, N + 1)\n    dV = (V_th - V_min) / N\n    k = np.argmin(np.abs(V_grid - V_r))\n\n    # Initialize the linear system M*x = b\n    # The unknowns x are [p_0, p_1, ..., p_{N-1}, r]\n    M = np.zeros((N + 1, N + 1))\n    b = np.zeros(N + 1)\n\n    A_vals = A(V_grid)\n\n    # Row indices of M correspond to equation numbers (0 to N)\n    # Column indices of M correspond to unknowns (p_0 to p_{N-1}, then r)\n\n    # Flux equations for i in {1, ..., k}: J_i = 0\n    # These equations correspond to rows 0 to k-1 of the matrix M\n    for i in range(1, k + 1):\n        row = i - 1\n        # Coefficient for p_{i-1}\n        M[row, i - 1] = D / dV\n        # Coefficient for p_i\n        M[row, i] = A_vals[i] - D / dV\n    \n    # Flux equations for i in {k+1, ..., N-1}: J_i = r\n    # These equations correspond to rows k to N-2 of M\n    for i in range(k + 1, N):\n        row = i - 1\n        # Coefficient for p_{i-1}\n        M[row, i - 1] = D / dV\n        # Coefficient for p_i\n        M[row, i] = A_vals[i] - D / dV\n        # Coefficient for r (unknown at index N)\n        M[row, N] = -1.0\n\n    # Threshold equation for i = N: J_N = r with p_N = 0\n    # This equation corresponds to row N-1 of M\n    row = N - 1\n    # Coefficient for p_{N-1}\n    M[row, N - 1] = -D / dV\n    # Coefficient for r\n    M[row, N] = 1.0\n\n    # Normalization equation: sum(p_i * dV) = 1\n    # This equation corresponds to row N of M\n    row = N\n    M[row, 0:N] = dV\n    M[row, N] = 0.0\n    b[row] = 1.0\n\n    # Solve the linear system\n    try:\n        solution = np.linalg.solve(M, b)\n    except np.linalg.LinAlgError:\n        # Return a value indicating failure, e.g., NaN, if the matrix is singular\n        return np.nan\n        \n    # The firing rate r is the last element of the solution vector\n    r = solution[-1]\n\n    return r\n\nsolve()\n```"
        },
        {
            "introduction": "Theoretical models are only as powerful as their connection to real-world data. This final practice tackles the crucial task of parameter inference, linking the Fokker-Planck framework to observable measurements . You will derive and implement a maximum likelihood estimator to infer the biophysical parameters of a neuron model directly from a recorded subthreshold voltage trajectory. This exercise demonstrates how the generator of the stochastic process provides a rigorous foundation for constructing likelihood functions, a central task in building data-driven models of neural systems.",
            "id": "3982115",
            "problem": "You are asked to design and implement a maximum likelihood estimator for parameters of a Leaky Integrate-and-Fire (LIF) neuron model using the Fokker-Planck generator. The LIF neuron in the subthreshold regime is modeled as an Ornstein-Uhlenbeck process with membrane voltage $V_t$ obeying the stochastic differential equation $dV_t = a(V_t)\\,dt + b\\,dW_t$ where $W_t$ is standard Brownian motion, drift $a(V) = (\\mu - V)/\\tau_m$, and diffusion amplitude $b = \\sqrt{2\\,\\sigma^2/\\tau_m}$. The physical units are: $V_t$ and $\\mu$ in volts, $\\sigma$ in volts, and $\\tau_m$ in seconds. You must assume subthreshold operation (no threshold or reset), and focus purely on the continuous stochastic dynamics.\n\nYour task is to derive, from first principles appropriate for the context of brain modeling and computational neuroscience, a generator-based approximate likelihood for discrete-time sampled trajectories $V_0, V_1, \\dots, V_{N}$ observed at uniform sampling interval $\\Delta t$. Start from the following foundational base:\n\n- Stochastic differential equation and the associated Fokker-Planck equation: For $dV_t = a(V_t)\\,dt + b\\,dW_t$ with smooth $a(\\cdot)$ and constant $b$, the probability density $p(v,t)$ evolves according to the Fokker-Planck equation $\\partial_t p(v,t) = -\\partial_v\\left(a(v)\\,p(v,t)\\right) + \\tfrac{1}{2}\\,\\partial_v^2\\left(b^2\\,p(v,t)\\right)$.\n- The infinitesimal generator acting on twice-differentiable test functions $f$ is $\\mathcal{L}f(v) = a(v)\\,f'(v) + \\tfrac{1}{2}\\,b^2\\,f''(v)$.\n- For small sampling interval $\\Delta t$, the Markov property and the generator imply a Gaussian approximation to the transition over $\\Delta t$.\n\nUsing only these fundamental definitions and laws, derive the generator-induced approximate Gaussian transition model over $\\Delta t$, construct the corresponding log-likelihood for a discrete trajectory, and propose a numerically stable algorithm to maximize it under the constraints $\\sigma \\ge 0$ and $\\tau_m > 0$. Provide an algorithmic strategy for initialization that does not rely on providing the final formulas in the problem statement and explain how your estimator is grounded in the generator structure.\n\nYou must then implement a complete, runnable program that:\n- Simulates synthetic subthreshold membrane voltage trajectories using the described stochastic neuron model via Euler-Maruyama integration for given $(\\mu,\\sigma,\\tau_m)$, sampling interval $\\Delta t$, and trajectory length $N$, from a specified initial voltage $V_0$.\n- Computes the maximum likelihood estimates $\\widehat{\\mu},\\widehat{\\sigma},\\widehat{\\tau}_m$ from each simulated trajectory using the generator-based approximate likelihood.\n- Produces a single line of output containing the results as a comma-separated list enclosed in square brackets, where each per-test result is itself a list of three floats $[\\widehat{\\mu},\\widehat{\\sigma},\\widehat{\\tau}_m]$, in the units volts for $\\widehat{\\mu}$, volts for $\\widehat{\\sigma}$, and seconds for $\\widehat{\\tau}_m$, each rounded to six decimal places. For example: $[[\\widehat{\\mu}_1,\\widehat{\\sigma}_1,\\widehat{\\tau}_{m,1}],[\\widehat{\\mu}_2,\\widehat{\\sigma}_2,\\widehat{\\tau}_{m,2}],\\dots]$.\n\nPhysical units:\n- Report $\\mu$ in volts, $\\sigma$ in volts, and $\\tau_m$ in seconds. Each number must be rounded to six decimal places.\n\nAngle units:\n- Not applicable.\n\nPercentages:\n- Not applicable.\n\nTest suite:\nUse the following three parameter sets and simulation specifications to generate trajectories and then estimate parameters. All voltages are in volts, times in seconds.\n\n- Case $1$ (general case): $(\\mu,\\sigma,\\tau_m) = (-0.062, 0.0045, 0.018)$, $\\Delta t = 0.0001$, $N = 15000$, $V_0 = -0.070$, random seed $123$.\n- Case $2$ (low-noise edge case): $(\\mu,\\sigma,\\tau_m) = (-0.070, 0.0012, 0.010)$, $\\Delta t = 0.0005$, $N = 12000$, $V_0 = -0.072$, random seed $456$.\n- Case $3$ (coarser sampling edge case): $(\\mu,\\sigma,\\tau_m) = (-0.055, 0.0060, 0.030)$, $\\Delta t = 0.0010$, $N = 6000$, $V_0 = -0.060$, random seed $789$.\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, with each result formatted as described above. No other output is permitted. The output type for each test case is a list of three floats.",
            "solution": "The problem requires the derivation and implementation of a maximum likelihood estimator for the parameters $(\\mu, \\sigma, \\tau_m)$ of a subthreshold Leaky Integrate-and-Fire (LIF) neuron model. The model's voltage dynamics are described by the Ornstein-Uhlenbeck (OU) process given by the stochastic differential equation (SDE) $dV_t = a(V_t)\\,dt + b\\,dW_t$, with drift $a(V) = (\\mu - V)/\\tau_m$ and diffusion $b = \\sqrt{2\\sigma^2/\\tau_m}$. The estimation is to be based on a discrete-time trajectory $V_0, V_1, \\dots, V_N$ sampled at a uniform interval $\\Delta t$. The derivation must be founded on the provided Fokker-Planck generator.\n\n### Problem Validation\nThe problem statement is validated as follows:\n\n**1. Extracted Givens:**\n- **SDE:** $dV_t = a(V_t)\\,dt + b\\,dW_t$.\n- **Drift:** $a(V) = (\\mu - V)/\\tau_m$.\n- **Diffusion:** $b = \\sqrt{2\\sigma^2/\\tau_m}$.\n- **Fokker-Planck Equation:** $\\partial_t p(v,t) = -\\partial_v\\left(a(v)\\,p(v,t)\\right) + \\tfrac{1}{2}\\,\\partial_v^2\\left(b^2\\,p(v,t)\\right)$.\n- **Infinitesimal Generator:** $\\mathcal{L}f(v) = a(v)\\,f'(v) + \\tfrac{1}{2}\\,b^2\\,f''(v)$.\n- **Data:** Discrete trajectory $V_0, V_1, \\dots, V_N$ with sampling interval $\\Delta t$.\n- **Task:** Derive a generator-based approximate likelihood, design an MLE algorithm, and implement it for specified test cases.\n- **Constraints:** $\\sigma \\ge 0$, $\\tau_m > 0$.\n\n**2. Validation Analysis:**\n- **Scientific Grounding:** The problem is firmly located within computational neuroscience and statistical physics. The LIF model, OU process, Fokker-Planck equation, and its generator are standard, well-established theoretical tools in this domain. All premises are scientifically sound.\n- **Well-Posedness:** The problem of parameter estimation for an OU process is well-posed. The objective is to find the parameters $(\\mu, \\sigma, \\tau_m)$ that maximize the likelihood of an observed trajectory, which is a standard inference task. The provision of an approximate likelihood based on a small $\\Delta t$ makes the problem tractable and well-defined.\n- **Objectivity and Completeness:** The problem is specified with mathematical precision. All necessary equations, simulation parameters, and output formats are provided, leaving no room for ambiguity or subjectivity. The problem is self-contained.\n\n**3. Verdict:**\nThe problem is deemed **valid**. It is scientifically sound, well-posed, objective, and contains all necessary information for a unique solution.\n\n### Derivation of the Estimator\n\nThe derivation proceeds in three stages: first, we derive the approximate transition probability using the generator; second, we construct the log-likelihood for the observed trajectory; and third, we formulate an algorithm to maximize this likelihood.\n\n**1. Generator-Based Approximate Transition Probability**\n\nThe infinitesimal generator $\\mathcal{L}$ of a stochastic process describes the expected instantaneous rate of change of any smooth function $f(V_t)$ of the process state. For a small time interval $\\Delta t$, the expected value of $f(V_{t+\\Delta t})$ conditioned on $V_t=v$ can be approximated by a first-order Taylor expansion in time:\n$$\n\\mathbb{E}[f(V_{t+\\Delta t}) | V_t=v] \\approx f(v) + \\Delta t \\cdot \\mathcal{L}f(v)\n$$\nWe use this relation to find the first two moments of the transition probability distribution $p(V_{i+1} | V_i)$.\n\n- **Conditional Mean:** Let $f(v) = v$. Then $f'(v) = 1$ and $f''(v) = 0$. The generator acts as:\n$$\n\\mathcal{L}v = a(v) \\cdot 1 + \\frac{1}{2}b^2 \\cdot 0 = a(v)\n$$\nThe conditional mean of $V_{i+1}$ given $V_i$ is therefore:\n$$\n\\mathbb{E}[V_{i+1} | V_i] \\approx V_i + \\Delta t \\cdot a(V_i) = V_i + \\frac{\\mu - V_i}{\\tau_m}\\Delta t\n$$\n\n- **Conditional Variance:** To find the variance, we first compute the second moment using $f(v) = v^2$. Then $f'(v) = 2v$ and $f''(v) = 2$.\n$$\n\\mathcal{L}v^2 = a(v) \\cdot (2v) + \\frac{1}{2}b^2 \\cdot 2 = 2v\\,a(v) + b^2\n$$\nThe conditional second moment is:\n$$\n\\mathbb{E}[V_{i+1}^2 | V_i] \\approx V_i^2 + \\Delta t \\cdot (2V_i\\,a(V_i) + b^2)\n$$\nThe conditional variance is $\\text{Var}[V_{i+1} | V_i] = \\mathbb{E}[V_{i+1}^2 | V_i] - (\\mathbb{E}[V_{i+1} | V_i])^2$. Substituting our approximations:\n$$\n\\text{Var}[V_{i+1} | V_i] \\approx \\left( V_i^2 + 2V_i\\,a(V_i)\\Delta t + b^2\\Delta t \\right) - \\left( V_i + a(V_i)\\Delta t \\right)^2\n$$\n$$\n\\approx \\left( V_i^2 + 2V_i\\,a(V_i)\\Delta t + b^2\\Delta t \\right) - \\left( V_i^2 + 2V_i\\,a(V_i)\\Delta t + (a(V_i)\\Delta t)^2 \\right)\n$$\n$$\n= b^2\\Delta t - (a(V_i)\\Delta t)^2\n$$\nFor a small sampling interval $\\Delta t$, the term of order a $(\\Delta t)^2$ is negligible compared to the term of order $\\Delta t$. Thus, we have:\n$$\n\\text{Var}[V_{i+1} | V_i] \\approx b^2\\Delta t = \\frac{2\\sigma^2}{\\tau_m}\\Delta t\n$$\nThe problem states to assume a Gaussian approximation for the transition, which is justified by the connection to the Euler-Maruyama discretization of the SDE. Therefore, the generator-induced approximate transition probability is:\n$$\np(V_{i+1} | V_i; \\theta) \\approx \\mathcal{N}\\left( V_{i+1};\\, V_i + \\frac{\\mu - V_i}{\\tau_m}\\Delta t, \\, \\frac{2\\sigma^2\\Delta t}{\\tau_m} \\right)\n$$\nwhere $\\theta = (\\mu, \\sigma, \\tau_m)$ represents the model parameters.\n\n**2. Log-Likelihood Construction**\n\nGiven the Markov property of the process, the likelihood of the entire trajectory $V_1, \\dots, V_N$ conditional on the starting point $V_0$ is the product of individual transition probabilities:\n$$\nL(\\theta) = p(V_1, \\dots, V_N | V_0; \\theta) = \\prod_{i=0}^{N-1} p(V_{i+1} | V_i; \\theta)\n$$\nThe log-likelihood, $\\mathcal{LL}(\\theta) = \\log L(\\theta)$, is the sum of the log-probabilities:\n$$\n\\mathcal{LL}(\\theta) = \\sum_{i=0}^{N-1} \\log p(V_{i+1} | V_i; \\theta)\n$$\nUsing the Gaussian transition probability, the log-likelihood is:\n$$\n\\mathcal{LL}(\\theta) = \\sum_{i=0}^{N-1} \\left[ -\\frac{1}{2}\\log(2\\pi\\sigma_{\\epsilon}^2) - \\frac{(V_{i+1} - \\mu_{\\epsilon,i})^2}{2\\sigma_{\\epsilon}^2} \\right]\n$$\nwhere $\\mu_{\\epsilon,i} = V_i + \\frac{\\mu - V_i}{\\tau_m}\\Delta t$ and $\\sigma_{\\epsilon}^2 = \\frac{2\\sigma^2\\Delta t}{\\tau_m}$.\n\n**3. Maximum Likelihood Estimation Algorithm**\n\nTo maximize $\\mathcal{LL}(\\theta)$, we can re-parameterize the model. Let us rearrange the expression for the conditional mean:\n$$\nV_{i+1} \\approx V_i + \\frac{\\mu\\Delta t}{\\tau_m} - \\frac{V_i\\Delta t}{\\tau_m} + \\epsilon_i = \\left(1 - \\frac{\\Delta t}{\\tau_m}\\right)V_i + \\frac{\\mu\\Delta t}{\\tau_m} + \\epsilon_i\n$$\nwhere $\\epsilon_i$ are independent and identically distributed Gaussian random variables with mean $0$ and variance $\\sigma_{\\epsilon}^2$. This is an autoregressive model of order $1$ (AR($1$)):\n$$\nV_{i+1} = \\alpha V_i + \\beta + \\epsilon_i\n$$\nwith parameters:\n$$\n\\alpha = 1 - \\frac{\\Delta t}{\\tau_m}, \\quad \\beta = \\frac{\\mu\\Delta t}{\\tau_m}, \\quad \\text{Var}(\\epsilon_i) = \\sigma_{\\epsilon}^2 = \\frac{2\\sigma^2\\Delta t}{\\tau_m}\n$$\nFor a linear-Gaussian model, maximum likelihood estimation is equivalent to ordinary least squares (OLS). We can thus find the MLEs for $\\alpha$ and $\\beta$ by regressing $V_{i+1}$ on $V_i$ for the observed data points $(V_0, V_1), \\dots, (V_{N-1}, V_N)$. The MLE for the noise variance $\\sigma_\\epsilon^2$ is the mean squared error of this regression.\n\nThis procedure does not require an iterative numerical optimizer or an initial parameter guess; it has an analytical solution. The algorithm is as follows:\n1.  Construct two vectors from the data: $\\mathbf{y} = [V_1, V_2, \\dots, V_N]^T$ and $\\mathbf{x} = [V_0, V_1, \\dots, V_{N-1}]^T$.\n2.  Perform a linear regression of $\\mathbf{y}$ on $\\mathbf{x}$ and a constant term to find the estimates $\\hat{\\alpha}$ and $\\hat{\\beta}$. This can be done efficiently using standard linear algebra libraries (e.g., `numpy.linalg.lstsq`).\n3.  Calculate the residuals of the fit: $e_i = V_{i+1} - (\\hat{\\alpha}V_i + \\hat{\\beta})$.\n4.  Estimate the variance of the residuals: $\\hat{\\sigma}_{\\epsilon}^2 = \\frac{1}{N} \\sum_{i=0}^{N-1} e_i^2$.\n5.  Invert the parameter mapping to obtain the estimates for the original physical parameters:\n    -   From $\\hat{\\alpha} = 1 - \\frac{\\Delta t}{\\hat{\\tau}_m}$, we get $\\hat{\\tau}_m = \\frac{\\Delta t}{1 - \\hat{\\alpha}}$. The constraint $\\tau_m > 0$ implies $1 - \\hat{\\alpha} > 0$, or $\\hat{\\alpha} < 1$, which is expected for a stable mean-reverting process.\n    -   From $\\hat{\\beta} = \\frac{\\hat{\\mu}\\Delta t}{\\hat{\\tau}_m}$, we get $\\hat{\\mu} = \\frac{\\hat{\\beta}\\hat{\\tau}_m}{\\Delta t} = \\frac{\\hat{\\beta}}{1 - \\hat{\\alpha}}$.\n    -   From $\\hat{\\sigma}_{\\epsilon}^2 = \\frac{2\\hat{\\sigma}^2\\Delta t}{\\hat{\\tau}_m}$, we obtain $\\hat{\\sigma}^2 = \\frac{\\hat{\\sigma}_\\epsilon^2 \\hat{\\tau}_m}{2\\Delta t} = \\frac{\\hat{\\sigma}_\\epsilon^2}{2(1 - \\hat{\\alpha})}$. The constraint $\\sigma \\ge 0$ requires taking the positive square root: $\\hat{\\sigma} = \\sqrt{\\frac{\\hat{\\sigma}_{\\epsilon}^2}{2(1 - \\hat{\\alpha})}}$.\n\nThis algorithm is numerically stable, computationally efficient, and directly maximizes the derived approximate likelihood. Its foundation lies in recognizing that the generator-based approximation for a linear drift SDE leads to a linear-Gaussian transition model, for which MLE is equivalent to OLS.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to run the simulation and estimation for all test cases.\n    \"\"\"\n\n    # Test suite from the problem statement\n    test_cases = [\n        # ( (mu, sigma, tau_m), dt, N, V0, seed )\n        ((-0.062, 0.0045, 0.018), 0.0001, 15000, -0.070, 123),\n        ((-0.070, 0.0012, 0.010), 0.0005, 12000, -0.072, 456),\n        ((-0.055, 0.0060, 0.030), 0.0010, 6000, -0.060, 789),\n    ]\n\n    results = []\n    for params, dt, N, V0, seed in test_cases:\n        mu, sigma, tau_m = params\n        \n        # 1. Simulate the voltage trajectory\n        v_trajectory = simulate_lif_trajectory(mu, sigma, tau_m, dt, N, V0, seed)\n        \n        # 2. Estimate parameters from the trajectory\n        mu_hat, sigma_hat, tau_m_hat = estimate_lif_parameters(v_trajectory, dt)\n        \n        # 3. Format and store the results\n        results.append([\n            round(mu_hat, 6),\n            round(sigma_hat, 6),\n            round(tau_m_hat, 6)\n        ])\n\n    # Final print statement in the exact required format\n    # Using repr to ensure correct list of lists formatting without spaces\n    print(repr(results).replace(\" \", \"\"))\n\ndef simulate_lif_trajectory(mu, sigma, tau_m, dt, N, V0, seed):\n    \"\"\"\n    Simulates a subthreshold LIF trajectory using Euler-Maruyama integration.\n    \n    Args:\n        mu (float): Mean potential (V).\n        sigma (float): Noise standard deviation (V).\n        tau_m (float): Membrane time constant (s).\n        dt (float): Simulation time step (s).\n        N (int): Number of simulation steps.\n        V0 (float): Initial membrane voltage (V).\n        seed (int): Random seed for reproducibility.\n        \n    Returns:\n        np.ndarray: Array of membrane voltage values of length N+1.\n    \"\"\"\n    rng = np.random.default_rng(seed)\n    \n    v = np.zeros(N + 1)\n    v[0] = V0\n    \n    # Pre-calculate constants for the simulation loop\n    drift_term_factor = dt / tau_m\n    diffusion_term_factor = np.sqrt(2 * sigma**2 * dt / tau_m)\n    \n    for i in range(N):\n        # Euler-Maruyama step for the Ornstein-Uhlenbeck process\n        drift = (mu - v[i]) * drift_term_factor\n        diffusion = diffusion_term_factor * rng.normal()\n        v[i+1] = v[i] + drift + diffusion\n        \n    return v\n\ndef estimate_lif_parameters(v_trajectory, dt):\n    \"\"\"\n    Estimates LIF parameters (mu, sigma, tau_m) from a voltage trajectory\n    using the maximum likelihood method based on the AR(1) approximation.\n    \n    Args:\n        v_trajectory (np.ndarray): The observed voltage trajectory.\n        dt (float): The sampling interval of the trajectory.\n        \n    Returns:\n        tuple[float, float, float]: The estimated parameters (mu_hat, sigma_hat, tau_m_hat).\n    \"\"\"\n    # Number of transitions\n    N = len(v_trajectory) - 1\n    \n    # Set up the linear regression problem: V_{i+1} = alpha * V_i + beta\n    # y = A * x, where y is V_t_plus_1 and A is [V_t, 1] and x is [alpha, beta]\n    y = v_trajectory[1:]\n    A = np.vstack([v_trajectory[:-1], np.ones(N)]).T\n    \n    # Solve for [alpha, beta] using ordinary least squares\n    # This provides the MLE for alpha and beta in a linear-Gaussian model.\n    # np.linalg.lstsq is a numerically stable way to do this.\n    coeffs, residuals, _, _ = np.linalg.lstsq(A, y, rcond=None)\n    alpha_hat, beta_hat = coeffs\n    \n    # The MLE for the residual variance\n    # residuals[0] from lstsq is the sum of squared errors\n    sigma_epsilon_sq_hat = residuals[0] / N\n    \n    # Invert the parameter mapping to find the physical parameters\n    # from the estimated AR(1) parameters.\n    \n    # Check for stability condition alpha_hat < 1, which implies tau_m > 0\n    if not (alpha_hat < 1):\n        # This case is unlikely for data generated from a stable OU process\n        # but is a necessary numerical safeguard. A large positive value or NaN\n        # signals a problem.\n        # We can return NaN or raise an error. For this problem, we assume\n        # the estimator will behave well on the given test data.\n        tau_m_hat = np.nan\n        mu_hat = np.nan\n        sigma_hat = np.nan\n    else:\n        one_minus_alpha = 1 - alpha_hat\n        \n        # Estimate tau_m\n        tau_m_hat = dt / one_minus_alpha\n        \n        # Estimate mu\n        mu_hat = beta_hat / one_minus_alpha\n        \n        # Estimate sigma\n        sigma_sq_hat = sigma_epsilon_sq_hat / (2 * one_minus_alpha)\n        # sigma is non-negative\n        sigma_hat = np.sqrt(sigma_sq_hat)\n        \n    return mu_hat, sigma_hat, tau_m_hat\n\n# Execute the solution\nsolve()\n\n```"
        }
    ]
}