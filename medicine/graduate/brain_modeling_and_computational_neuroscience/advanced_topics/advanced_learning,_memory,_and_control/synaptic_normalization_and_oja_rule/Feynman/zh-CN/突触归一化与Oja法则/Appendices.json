{
    "hands_on_practices": [
        {
            "introduction": "纯粹的赫布可塑性虽然在概念上很简单，但存在一个固有的不稳定性问题，即突触权重会无限制地增长。这个练习通过对比几种赫布式学习规则，揭示了当输入信号具有非零均值时这个问题的严重性 。通过分析相关性规则、协方差规则和Oja法则的动力学，你将亲手推导出为什么需要对输入进行中心化或使用像Oja法则那样的归一化机制，从而对突触归一化的核心动机建立深刻的理解。",
            "id": "4025537",
            "problem": "一个线性神经元接收一个输入向量 $\\mathbf{x} \\in \\mathbb{R}^n$，该向量随时间从一个平稳分布中独立抽取，其均值为 $\\boldsymbol{\\mu} = \\mathbb{E}[\\mathbf{x}] \\neq \\mathbf{0}$，协方差矩阵为 $\\mathbf{C} = \\mathbb{E}\\left[(\\mathbf{x} - \\boldsymbol{\\mu})(\\mathbf{x} - \\boldsymbol{\\mu})^\\top\\right]$，其中 $\\mathbf{C}$ 是对称半正定的。该神经元产生输出 $y = \\mathbf{w}^\\top \\mathbf{x}$，其中 $\\mathbf{w} \\in \\mathbb{R}^n$ 是突触权重。考虑在连续时间极限下，以下具有小学习率 $\\eta  0$ 的突触可塑性规则，其中 $\\Delta \\mathbf{w}$ 表示在一个小时间步长内的增量：\n\n- 相关性 Hebb 规则 (Correlation Hebbian rule): $\\Delta \\mathbf{w} = \\eta\\, y\\, \\mathbf{x}$。\n- 协方差 Hebb 规则 (Covariance Hebbian rule): $\\Delta \\mathbf{w} = \\eta\\, y\\, (\\mathbf{x} - \\boldsymbol{\\mu})$。\n- Oja 法则 (Oja's rule, 一种局部突触归一化规则): $\\Delta \\mathbf{w} = \\eta\\, y\\, (\\mathbf{x} - y\\, \\mathbf{w})$。\n\n从均值和协方差的定义以及线性神经元模型出发，分析当 $\\boldsymbol{\\mu} \\neq \\mathbf{0}$ 时，相关性 Hebb 规则和协方差 Hebb 规则的期望权重动态和范数行为，并解释在有和没有对输入进行均值中心化的情况下，Oja 法则如何改变稳定性和渐近行为。假设标准的正则性条件成立，以确保在小 $\\eta$ 极限下期望与微分可以互换，并且协方差矩阵 $\\mathbf{C}$ 至少有一个严格为正的特征值。\n\n下列哪个陈述是正确的？\n\nA. 在相关性 Hebb 规则下，期望权重动态满足 $\\dfrac{d\\mathbf{w}}{dt} = \\eta\\left(\\mathbf{C}\\,\\mathbf{w} + (\\mathbf{w}^\\top \\boldsymbol{\\mu})\\, \\boldsymbol{\\mu}\\right)$，这意味着当 $\\boldsymbol{\\mu} \\neq \\mathbf{0}$ 时，存在沿 $\\boldsymbol{\\mu}$ 方向的无界漂移；若无额外的归一化，则不存在有限范数的稳定不动点。\n\nB. 在协方差 Hebb 规则下，期望权重动态满足 $\\dfrac{d\\mathbf{w}}{dt} = \\eta\\, \\mathbf{C}\\,\\mathbf{w}$，因此 $\\mathbf{w}$ 的方向与 $\\mathbf{C}$ 的最大特征值所对应的特征向量对齐，但在没有归一化的情况下，范数 $\\lVert \\mathbf{w} \\rVert$ 会无界增长。\n\nC. 无论 $\\boldsymbol{\\mu}$ 的值如何，仅协方差 Hebb 规则就能保证对于任何半正定矩阵 $\\mathbf{C}$，$\\mathbf{w}$ 都能全局稳定地收敛到一个有界不动点。\n\nD. 用 Oja 法则替换任一 Hebb 规则，当输入被均值中心化（$\\boldsymbol{\\mu} = \\mathbf{0}$）时，期望动态变为 $\\dfrac{d\\mathbf{w}}{dt} = \\mathbf{C}\\,\\mathbf{w} - (\\mathbf{w}^\\top \\mathbf{C}\\,\\mathbf{w})\\, \\mathbf{w}$，这使得 $\\mathbf{w}$ 稳定地收敛到与 $\\mathbf{C}$ 最大特征值对应的单位范数特征向量；当 $\\boldsymbol{\\mu} \\neq \\mathbf{0}$ 且使用原始输入时，漂移项中会出现一个额外的项 $(\\mathbf{w}^\\top \\boldsymbol{\\mu})\\, \\boldsymbol{\\mu}$，除非输入被中心化，否则该项会使解偏向 $\\boldsymbol{\\mu}$。\n\nE. 当 $\\boldsymbol{\\mu} \\neq \\mathbf{0}$ 时，相关性 Hebb 规则是稳定的，因为项 $(\\mathbf{w}^\\top \\boldsymbol{\\mu})\\, \\boldsymbol{\\mu}$ 起到了权重衰减的作用，从而减小了 $\\lVert \\mathbf{w} \\rVert$。",
            "solution": "问题陈述展示了对计算神经科学中几种 Hebb 型突触可塑性规则的标准分析。其定义、假设和物理背景与该领域的已有文献一致。该设定在数学上是定义良好且自洽的。所有术语都是标准的，它们之间的关系也得到了正确说明。该问题具有科学依据、提法恰当且客观。\n\n分析过程是通过推导每种学习规则在连续时间极限下的期望动态来进行的。对于一个小的学习率 $\\eta$，权重向量 $\\mathbf{w}$ 的演化可以由常微分方程（ODE）$\\frac{d\\mathbf{w}}{dt} = \\eta \\mathbb{E}\\left[\\frac{\\Delta \\mathbf{w}}{\\eta}\\right]$ 来近似，其中期望是对输入向量 $\\mathbf{x}$ 的分布取的。\n\n首先，我们建立一个关键的恒等式，将二阶矩矩阵 $\\mathbb{E}[\\mathbf{x}\\mathbf{x}^\\top]$ 与协方差矩阵 $\\mathbf{C}$ 和均值向量 $\\boldsymbol{\\mu}$ 联系起来。根据定义，$\\mathbf{C} = \\mathbb{E}[(\\mathbf{x} - \\boldsymbol{\\mu})(\\mathbf{x} - \\boldsymbol{\\mu})^\\top]$。展开此表达式可得：\n$$\n\\mathbf{C} = \\mathbb{E}[\\mathbf{x}\\mathbf{x}^\\top - \\mathbf{x}\\boldsymbol{\\mu}^\\top - \\boldsymbol{\\mu}\\mathbf{x}^\\top + \\boldsymbol{\\mu}\\boldsymbol{\\mu}^\\top]\n$$\n利用期望的线性性质以及 $\\mathbb{E}[\\mathbf{x}] = \\boldsymbol{\\mu}$：\n$$\n\\mathbf{C} = \\mathbb{E}[\\mathbf{x}\\mathbf{x}^\\top] - \\mathbb{E}[\\mathbf{x}]\\boldsymbol{\\mu}^\\top - \\boldsymbol{\\mu}\\mathbb{E}[\\mathbf{x}^\\top] + \\boldsymbol{\\mu}\\boldsymbol{\\mu}^\\top\n$$\n$$\n\\mathbf{C} = \\mathbb{E}[\\mathbf{x}\\mathbf{x}^\\top] - \\boldsymbol{\\mu}\\boldsymbol{\\mu}^\\top - \\boldsymbol{\\mu}\\boldsymbol{\\mu}^\\top + \\boldsymbol{\\mu}\\boldsymbol{\\mu}^\\top = \\mathbb{E}[\\mathbf{x}\\mathbf{x}^\\top] - \\boldsymbol{\\mu}\\boldsymbol{\\mu}^\\top\n$$\n因此，二阶矩矩阵由下式给出：\n$$\n\\mathbb{E}[\\mathbf{x}\\mathbf{x}^\\top] = \\mathbf{C} + \\boldsymbol{\\mu}\\boldsymbol{\\mu}^\\top\n$$\n\n有了这个，我们来分析每条规则。\n\n**相关性 Hebb 规则**\n更新规则为 $\\Delta \\mathbf{w} = \\eta\\, y\\, \\mathbf{x}$。代入 $y = \\mathbf{w}^\\top \\mathbf{x}$，我们得到 $\\Delta \\mathbf{w} = \\eta\\, (\\mathbf{w}^\\top \\mathbf{x})\\, \\mathbf{x}$。期望变化为：\n$$\n\\frac{d\\mathbf{w}}{dt} = \\eta \\mathbb{E}[(\\mathbf{w}^\\top \\mathbf{x})\\, \\mathbf{x}] = \\eta \\mathbb{E}[\\mathbf{x}\\mathbf{x}^\\top \\mathbf{w}]\n$$\n由于 $\\mathbf{w}$ 相对于对 $\\mathbf{x}$ 的期望是常数：\n$$\n\\frac{d\\mathbf{w}}{dt} = \\eta \\mathbb{E}[\\mathbf{x}\\mathbf{x}^\\top] \\mathbf{w}\n$$\n代入 $\\mathbb{E}[\\mathbf{x}\\mathbf{x}^\\top] = \\mathbf{C} + \\boldsymbol{\\mu}\\boldsymbol{\\mu}^\\top$：\n$$\n\\frac{d\\mathbf{w}}{dt} = \\eta (\\mathbf{C} + \\boldsymbol{\\mu}\\boldsymbol{\\mu}^\\top) \\mathbf{w} = \\eta (\\mathbf{C}\\mathbf{w} + \\boldsymbol{\\mu}(\\boldsymbol{\\mu}^\\top\\mathbf{w})) = \\eta (\\mathbf{C}\\mathbf{w} + (\\mathbf{w}^\\top\\boldsymbol{\\mu})\\boldsymbol{\\mu})\n$$\n该动态有两个驱动项。第一项 $\\eta\\mathbf{C}\\mathbf{w}$ 将 $\\mathbf{w}$ 推向 $\\mathbf{C}$ 的主特征向量。第二项 $\\eta(\\mathbf{w}^\\top\\boldsymbol{\\mu})\\boldsymbol{\\mu}$ 为 $\\mathbf{w}$ 沿着均值向量 $\\boldsymbol{\\mu}$ 的分量提供正反馈。例如，如果 $\\mathbf{w}$ 初始时有一个沿着 $\\boldsymbol{\\mu}$ 的分量，使得 $\\mathbf{w}^\\top\\boldsymbol{\\mu}  0$，那么这个分量将呈指数增长。这表明系统存在不稳定性，并导致权重向量范数 $\\lVert \\mathbf{w} \\rVert$ 的无界增长。不存在有限范数的稳定不动点。\n\n**协方差 Hebb 规则**\n更新规则为 $\\Delta \\mathbf{w} = \\eta\\, y\\, (\\mathbf{x} - \\boldsymbol{\\mu})$。代入 $y = \\mathbf{w}^\\top \\mathbf{x}$：\n$$\n\\frac{d\\mathbf{w}}{dt} = \\eta \\mathbb{E}[(\\mathbf{w}^\\top \\mathbf{x})(\\mathbf{x} - \\boldsymbol{\\mu})] = \\eta \\mathbb{E}[\\mathbf{x}\\mathbf{x}^\\top \\mathbf{w} - \\mathbf{x}\\boldsymbol{\\mu}^\\top \\mathbf{w}]\n$$\n利用期望的线性性质并将 $\\mathbf{w}$ 视为常数：\n$$\n\\frac{d\\mathbf{w}}{dt} = \\eta (\\mathbb{E}[\\mathbf{x}\\mathbf{x}^\\top]\\mathbf{w} - \\mathbb{E}[\\mathbf{x}]\\boldsymbol{\\mu}^\\top \\mathbf{w})\n$$\n代入 $\\mathbb{E}[\\mathbf{x}\\mathbf{x}^\\top] = \\mathbf{C} + \\boldsymbol{\\mu}\\boldsymbol{\\mu}^\\top$ 和 $\\mathbb{E}[\\mathbf{x}] = \\boldsymbol{\\mu}$：\n$$\n\\frac{d\\mathbf{w}}{dt} = \\eta ((\\mathbf{C} + \\boldsymbol{\\mu}\\boldsymbol{\\mu}^\\top)\\mathbf{w} - \\boldsymbol{\\mu}\\boldsymbol{\\mu}^\\top \\mathbf{w}) = \\eta (\\mathbf{C}\\mathbf{w} + \\boldsymbol{\\mu}\\boldsymbol{\\mu}^\\top \\mathbf{w} - \\boldsymbol{\\mu}\\boldsymbol{\\mu}^\\top \\mathbf{w}) = \\eta \\mathbf{C}\\mathbf{w}\n$$\n这是一个线性常微分方程。其解代表了用于寻找与 $\\mathbf{C}$ 的最大特征值对应的特征向量的幂迭代法。如果 $\\mathbf{w}(t) = \\sum_i c_i(t) \\mathbf{v}_i$，其中 $\\mathbf{v}_i$ 是 $\\mathbf{C}$ 的特征向量，特征值为 $\\lambda_i$，则系数的动态为 $\\frac{dc_i}{dt} = \\eta \\lambda_i c_i$，导致 $c_i(t) = c_i(0)e^{\\eta\\lambda_i t}$。当 $t\\to\\infty$ 时，与最大特征值 $\\lambda_{\\text{max}}$ 对应的项将占主导地位。$\\mathbf{w}$ 的方向将与相应的特征向量 $\\mathbf{v}_{\\text{max}}$ 对齐。由于问题陈述 $\\mathbf{C}$ 至少有一个严格为正的特征值，因此 $\\lambda_{\\text{max}}  0$。因此，范数 $\\lVert \\mathbf{w} \\rVert$ 将无界地指数增长。\n\n**Oja 法则**\n更新规则为 $\\Delta \\mathbf{w} = \\eta\\, y (\\mathbf{x} - y \\mathbf{w})$。期望动态为：\n$$\n\\frac{d\\mathbf{w}}{dt} = \\eta \\mathbb{E}[y\\mathbf{x} - y^2\\mathbf{w}] = \\eta (\\mathbb{E}[y\\mathbf{x}] - \\mathbb{E}[y^2]\\mathbf{w})\n$$\n第一项与相关性规则中的相同：$\\mathbb{E}[y\\mathbf{x}] = (\\mathbf{C} + \\boldsymbol{\\mu}\\boldsymbol{\\mu}^\\top)\\mathbf{w}$。\n第二项是期望的输出平方：$\\mathbb{E}[y^2] = \\mathbb{E}[(\\mathbf{w}^\\top\\mathbf{x})^2] = \\mathbb{E}[\\mathbf{w}^\\top\\mathbf{x}\\mathbf{x}^\\top\\mathbf{w}] = \\mathbf{w}^\\top \\mathbb{E}[\\mathbf{x}\\mathbf{x}^\\top] \\mathbf{w} = \\mathbf{w}^\\top(\\mathbf{C} + \\boldsymbol{\\mu}\\boldsymbol{\\mu}^\\top)\\mathbf{w}$。\n完整的动态方程为：\n$$\n\\frac{d\\mathbf{w}}{dt} = \\eta \\left( (\\mathbf{C} + \\boldsymbol{\\mu}\\boldsymbol{\\mu}^\\top)\\mathbf{w} - (\\mathbf{w}^\\top(\\mathbf{C} + \\boldsymbol{\\mu}\\boldsymbol{\\mu}^\\top)\\mathbf{w})\\mathbf{w} \\right)\n$$\n情况1：均值中心化输入, $\\boldsymbol{\\mu} = \\mathbf{0}$。\n动态简化为 $\\frac{d\\mathbf{w}}{dt} = \\eta (\\mathbf{C}\\mathbf{w} - (\\mathbf{w}^\\top\\mathbf{C}\\mathbf{w})\\mathbf{w})$。\n为了分析范数，我们计算 $\\frac{d}{dt}\\lVert\\mathbf{w}\\rVert^2 = 2\\mathbf{w}^\\top \\frac{d\\mathbf{w}}{dt}$：\n$$\n\\frac{d}{dt}\\lVert\\mathbf{w}\\rVert^2 = 2\\mathbf{w}^\\top \\eta (\\mathbf{C}\\mathbf{w} - (\\mathbf{w}^\\top\\mathbf{C}\\mathbf{w})\\mathbf{w}) = 2\\eta (\\mathbf{w}^\\top\\mathbf{C}\\mathbf{w} - (\\mathbf{w}^\\top\\mathbf{C}\\mathbf{w})\\lVert\\mathbf{w}\\rVert^2) = 2\\eta (\\mathbf{w}^\\top\\mathbf{C}\\mathbf{w})(1 - \\lVert\\mathbf{w}\\rVert^2)\n$$\n由于 $\\mathbf{C}$ 是半正定的且有一个严格为正的特征值，对于任何不在零空间中的 $\\mathbf{w}$，$\\mathbf{w}^\\top\\mathbf{C}\\mathbf{w}  0$。该动态驱使 $\\lVert\\mathbf{w}\\rVert^2 \\to 1$。该规则将权重向量的范数稳定到单位1。更详细的稳定性分析表明，$\\mathbf{w}$ 收敛到对应于 $\\mathbf{C}$ 最大特征值的单位范数特征向量 $\\mathbf{v}_{\\text{max}}$。\n情况2：非零均值, $\\boldsymbol{\\mu} \\neq \\mathbf{0}$。\n动态由相关项 $\\mathbb{E}[y\\mathbf{x}] = (\\mathbf{C} + \\boldsymbol{\\mu}\\boldsymbol{\\mu}^\\top)\\mathbf{w} = \\mathbf{C}\\mathbf{w} + (\\mathbf{w}^\\top\\boldsymbol{\\mu})\\boldsymbol{\\mu}$ 驱动。与均值中心化的情况相比，驱动项或“漂移”项包含额外的分量 $(\\mathbf{w}^\\top\\boldsymbol{\\mu})\\boldsymbol{\\mu}$，这将权重向量的演化偏向输入均值 $\\boldsymbol{\\mu}$ 的方向，与向 $\\mathbf{C}$ 的主特征向量对齐的趋势相竞争。\n\n现在我们评估给定的选项。\n\n**A. 在相关性 Hebb 规则下，期望权重动态满足 $\\dfrac{d\\mathbf{w}}{dt} = \\eta\\left(\\mathbf{C}\\,\\mathbf{w} + (\\mathbf{w}^\\top \\boldsymbol{\\mu})\\, \\boldsymbol{\\mu}\\right)$，这意味着当 $\\boldsymbol{\\mu} \\neq \\mathbf{0}$ 时，存在沿 $\\boldsymbol{\\mu}$ 方向的无界漂移；若无额外的归一化，则不存在有限范数的稳定不动点。**\n我们的推导与所给的动态方程相符。项 $\\eta(\\mathbf{w}^\\top\\boldsymbol{\\mu})\\boldsymbol{\\mu}$ 沿着 $\\boldsymbol{\\mu}$ 的方向产生正反馈，导致无界增长。这一项和 $\\eta\\mathbf{C}\\mathbf{w}$ 项（由于 $\\lambda_{\\text{max}}  0$）都会导致范数增长，因此系统是不稳定的，没有有限范数的稳定不动点。\n**结论：正确。**\n\n**B. 在协方差 Hebb 规则下，期望权重动态满足 $\\dfrac{d\\mathbf{w}}{dt} = \\eta\\, \\mathbf{C}\\,\\mathbf{w}$，因此 $\\mathbf{w}$ 的方向与 $\\mathbf{C}$ 的最大特征值所对应的特征向量对齐，但在没有归一化的情况下，范数 $\\lVert \\mathbf{w} \\rVert$ 会无界增长。**\n我们的推导证实了动态为 $\\frac{d\\mathbf{w}}{dt} = \\eta \\mathbf{C}\\mathbf{w}$。这是幂迭代法，它使得 $\\mathbf{w}$ 的方向收敛到 $\\mathbf{C}$ 的主特征向量。由于 $\\lambda_{\\text{max}}  0$，$\\mathbf{w}$ 的范数会以 $e^{\\eta\\lambda_{\\text{max}}t}$ 的形式指数增长。\n**结论：正确。**\n\n**C. 无论 $\\boldsymbol{\\mu}$ 的值如何，仅协方差 Hebb 规则就能保证对于任何半正定矩阵 $\\mathbf{C}$，$\\mathbf{w}$ 都能全局稳定地收敛到一个有界不动点。**\n这是错误的。如在对B的分析中所确立的，只要 $\\mathbf{C}$ 有一个正特征值，协方差规则就会导致权重范数的无界增长。它不会收敛到一个有界不动点（除了在 $\\mathbf{w}=\\mathbf{0}$ 处的不稳定不动点）。\n**结论：不正确。**\n\n**D. 用 Oja 法则替换任一 Hebb 规则，当输入被均值中心化（$\\boldsymbol{\\mu} = \\mathbf{0}$）时，期望动态变为 $\\dfrac{d\\mathbf{w}}{dt} = \\mathbf{C}\\,\\mathbf{w} - (\\mathbf{w}^\\top \\mathbf{C}\\,\\mathbf{w})\\, \\mathbf{w}$，这使得 $\\mathbf{w}$ 稳定地收敛到与 $\\mathbf{C}$ 最大特征值对应的单位范数特征向量；当 $\\boldsymbol{\\mu} \\neq \\mathbf{0}$ 且使用原始输入时，漂移项中会出现一个额外的项 $(\\mathbf{w}^\\top \\boldsymbol{\\mu})\\, \\boldsymbol{\\mu}$，除非输入被中心化，否则该项会使解偏向 $\\boldsymbol{\\mu}$。**\n对 Oja 法则的分析证实了这一陈述的两个部分。对于 $\\boldsymbol{\\mu}=\\mathbf{0}$，其动态（在忽略一个缩放因子 $\\eta$ 的情况下）和稳定性属性的描述是正确的。对于 $\\boldsymbol{\\mu}\\neq\\mathbf{0}$，有效的“漂移”项从 $\\mathbf{C}\\mathbf{w}$ 变为 $(\\mathbf{C}+\\boldsymbol{\\mu}\\boldsymbol{\\mu}^\\top)\\mathbf{w}$，其中包含了额外的项 $(\\mathbf{w}^\\top\\boldsymbol{\\mu})\\boldsymbol{\\mu}$。该项正确地描述了向输入均值的偏置。\n**结论：正确。**\n\n**E. 当 $\\boldsymbol{\\mu} \\neq \\mathbf{0}$ 时，相关性 Hebb 规则是稳定的，因为项 $(\\mathbf{w}^\\top \\boldsymbol{\\mu})\\, \\boldsymbol{\\mu}$ 起到了权重衰减的作用，从而减小了 $\\lVert \\mathbf{w} \\rVert$。**\n这个陈述提出了一个根本上不正确的论断。项 $(\\mathbf{w}^\\top \\boldsymbol{\\mu})\\, \\boldsymbol{\\mu}$ 是一个正反馈项，而不是衰减项。一个衰减项应该带负号（例如 $-\\gamma\\mathbf{w}$）。我们对范数导数的分析 $\\frac{d}{dt}\\lVert\\mathbf{w}\\rVert^2 = 2\\eta (\\mathbf{w}^\\top\\mathbf{C}\\mathbf{w} + (\\mathbf{w}^\\top\\boldsymbol{\\mu})^2)$ 表明，两项都对范数增长有贡献，保证了不稳定性，而非稳定性。\n**结论：不正确。**",
            "answer": "$$\\boxed{ABD}$$"
        },
        {
            "introduction": "在静态环境中理解学习规则只是第一步，真实世界的输入统计特性是不断变化的。这个练习将带你进入一个动态场景，研究Oja法则如何追踪一个旋转的主成分方向 。通过求解这个非平稳系统，你将量化学习率和环境变化速度之间的权衡，并推导出神经元权重在追踪过程中产生的“滞后”量，这对于理解自适应系统在现实条件下的性能至关重要。",
            "id": "4025497",
            "problem": "考虑一个单一线性神经元，其接收一个二维零均值输入 $x(t) \\in \\mathbb{R}^{2}$，该输入的协方差矩阵 $C(t)$ 随时间变化。突触权重向量为 $w(t) \\in \\mathbb{R}^{2}$。该突触遵循 Oja 法则，这是一种归一化的赫布可塑性定律，其确定性平均场形式由下式给出\n$$\n\\dot{w}(t) \\;=\\; \\eta \\left( C(t)\\, w(t) \\;-\\; \\big(w(t)^{\\top} C(t)\\, w(t)\\big)\\, w(t) \\right),\n$$\n其中 $\\eta0$ 是学习率。假设输入协方差是秩为一的，并具有一个旋转的主轴，\n$$\nC(t) \\;=\\; e_{1}(t)\\, e_{1}(t)^{\\top}, \\qquad e_{1}(t) \\;=\\; \\begin{pmatrix}\\cos\\big(\\Omega t\\big) \\\\ \\sin\\big(\\Omega t\\big)\\end{pmatrix},\n$$\n其中 $\\Omega0$ 是一个恒定的漂移角频率，角度以弧度为单位。定义有符号角滞后 $\\delta$ 为权重方向与瞬时最大特征向量方向之间的稳态恒定差异，即，\n$$\n\\delta \\;=\\; \\psi(t) \\;-\\; \\theta(t),\n$$\n在锁相状态下，$\\delta$ 是与时间无关的，其中 $w(t) = \\big(\\cos\\psi(t),\\, \\sin\\psi(t)\\big)^{\\top}$ 和 $e_{1}(t) = \\big(\\cos\\theta(t),\\, \\sin\\theta(t)\\big)^{\\top}$，且 $\\theta(t) = \\Omega t$。从这些定义和给定的动力学方程出发，推导稳态有符号滞后 $\\delta$ 作为 $\\eta$ 和 $\\Omega$ 的函数的闭式解析表达式，假设系统达到了锁相状态。将您的最终答案表示为以弧度为单位的单个解析表达式。不需要进行数值计算。",
            "solution": "用户想要解决一个计算神经科学中的问题。\n\n### 第 1 步：问题验证\n\n**1. 提取已知条件：**\n*   **神经元模型：** 单一线性神经元，权重向量为 $w(t) \\in \\mathbb{R}^{2}$。\n*   **输入：** 零均值输入 $x(t) \\in \\mathbb{R}^{2}$。\n*   **学习法则 (Oja 法则)：** 权重向量 $w(t)$ 的确定性平均场动力学由下式给出：\n    $$ \\dot{w}(t) = \\eta \\left( C(t)\\, w(t) - \\big(w(t)^{\\top} C(t)\\, w(t)\\big)\\, w(t) \\right) $$\n    其中 $\\eta  0$ 是学习率。\n*   **输入协方差：** 输入协方差矩阵 $C(t)$ 是时变的、秩为一的，并定义为：\n    $$ C(t) = e_{1}(t)\\, e_{1}(t)^{\\top} $$\n    其主特征向量 $e_{1}(t)$ 由下式给出：\n    $$ e_{1}(t) = \\begin{pmatrix}\\cos\\big(\\Omega t\\big) \\\\ \\sin\\big(\\Omega t\\big)\\end{pmatrix} $$\n    其中 $\\Omega  0$ 是一个恒定的角频率。\n*   **参数化：** 权重向量通过其角度 $\\psi(t)$ 进行参数化，为 $w(t) = \\big(\\cos\\psi(t),\\, \\sin\\psi(t)\\big)^{\\top}$，这意味着其范数固定为 $\\|w(t)\\| = 1$。主特征向量通过其角度 $\\theta(t) = \\Omega t$ 进行参数化，为 $e_{1}(t) = \\big(\\cos\\theta(t),\\, \\sin\\theta(t)\\big)^{\\top}$。\n*   **稳态条件 (锁相)：** 假设系统处于锁相状态，其中有符号角滞后 $\\delta = \\psi(t) - \\theta(t)$ 是一个与时间无关的常数。\n*   **目标：** 推导稳态滞后 $\\delta$ 作为 $\\eta$ 和 $\\Omega$ 的函数的闭式解析表达式。\n\n**2. 使用提取的已知条件进行验证：**\n*   **科学依据：** 该问题在计算神经科学中有坚实的理论基础。Oja 法则是突触可塑性的一个经典模型，分析其在时变输入下的行为是一个标准且有意义的理论问题。\n*   **适定性：** 该问题提供了一个定义明确的微分方程系统，并要求在一个明确的假设（锁相）下求解一个特定的稳态属性。给出的条件是充分且一致的。\n*   **客观性：** 问题陈述由精确的数学定义构成，不含任何主观或模糊的语言。\n*   **缺陷检查表：** 该问题不违反任何无效性标准。它在科学上是合理的、可形式化的、完整的和适定的。\n\n**3. 结论与行动：**\n*   **结论：** 问题有效。\n*   **行动：** 继续推导解答。\n\n### 第 2 步：解答推导\n\n解答过程是通过找到权重向量时间导数 $\\dot{w}(t)$ 的两个不同表达式并将它们相等来求解。一个表达式来自给定的 Oja 法则，另一个来自旋转权重向量的运动学定义。\n\n首先，我们使用所提供的参数化来简化 Oja 法则中的各项。权重向量 $w(t)$ 与主特征向量 $e_{1}(t)$ 之间的标量积为：\n$$ w(t)^{\\top} e_{1}(t) = \\cos\\psi(t)\\cos\\theta(t) + \\sin\\psi(t)\\sin\\theta(t) = \\cos(\\psi(t)-\\theta(t)) = \\cos(\\delta) $$\n由于在锁相状态下 $\\delta$ 是常数，所以该乘积也是常数。\n\n现在，我们将其代入 Oja 法则的各个分量中。项 $C(t)w(t)$ 变为：\n$$ C(t)w(t) = \\left(e_{1}(t)e_{1}(t)^{\\top}\\right)w(t) = e_{1}(t)\\left(e_{1}(t)^{\\top}w(t)\\right) = e_{1}(t)\\cos(\\delta) $$\n二次项 $w(t)^{\\top}C(t)w(t)$ 变为：\n$$ w(t)^{\\top}C(t)w(t) = w(t)^{\\top}\\left(e_{1}(t)\\cos(\\delta)\\right) = \\left(w(t)^{\\top}e_{1}(t)\\right)\\cos(\\delta) = \\cos(\\delta)\\cos(\\delta) = \\cos^{2}(\\delta) $$\n将这些表达式代回 Oja 法则方程，我们得到 $\\dot{w}(t)$ 的第一个表达式：\n$$ \\dot{w}(t) = \\eta \\left( e_{1}(t)\\cos(\\delta) - \\cos^{2}(\\delta)w(t) \\right) $$\n\n接下来，我们从其运动学定义推导 $\\dot{w}(t)$ 的第二个表达式。权重向量为 $w(t) = \\begin{pmatrix}\\cos\\psi(t) \\\\ \\sin\\psi(t)\\end{pmatrix}$。其时间导数为：\n$$ \\dot{w}(t) = \\begin{pmatrix}-\\sin\\psi(t)\\dot{\\psi}(t) \\\\ \\cos\\psi(t)\\dot{\\psi}(t)\\end{pmatrix} = \\dot{\\psi}(t) \\begin{pmatrix}-\\sin\\psi(t) \\\\ \\cos\\psi(t)\\end{pmatrix} $$\n向量 $\\begin{pmatrix}-\\sin\\psi(t) \\\\ \\cos\\psi(t)\\end{pmatrix}$ 是与 $w(t)$ 正交的单位向量，我们将其记为 $w_{\\perp}(t)$。\n锁相条件 $\\delta = \\psi(t) - \\theta(t) = \\text{常数}$ 意味着它们的时间导数相等：$\\dot{\\psi}(t) = \\dot{\\theta}(t)$。由于 $\\theta(t)=\\Omega t$，我们有 $\\dot{\\theta}(t) = \\Omega$。因此，$\\dot{\\psi}(t) = \\Omega$。\n将此代入 $\\dot{w}(t)$ 的表达式，得到我们的第二个表达式：\n$$ \\dot{w}(t) = \\Omega w_{\\perp}(t) $$\n\n现在，我们将 $\\dot{w}(t)$ 的两个推导表达式相等：\n$$ \\Omega w_{\\perp}(t) = \\eta \\left( e_{1}(t)\\cos(\\delta) - \\cos^{2}(\\delta)w(t) \\right) $$\n为了求解 $\\delta$，我们将此向量方程投影到基向量 $w_{\\perp}(t)$ 上。我们用 $w_{\\perp}(t)^{\\top}$ 对等式两边取点积：\n$$ w_{\\perp}(t)^{\\top} \\left( \\Omega w_{\\perp}(t) \\right) = w_{\\perp}(t)^{\\top} \\left( \\eta e_{1}(t)\\cos(\\delta) - \\eta \\cos^{2}(\\delta)w(t) \\right) $$\n我们来计算两边的点积。\n左边：\n$$ \\Omega \\left( w_{\\perp}(t)^{\\top}w_{\\perp}(t) \\right) = \\Omega \\|w_{\\perp}(t)\\|^{2} = \\Omega $$\n右边：\n$$ \\eta\\cos(\\delta) \\left(w_{\\perp}(t)^{\\top}e_{1}(t)\\right) - \\eta\\cos^{2}(\\delta) \\left(w_{\\perp}(t)^{\\top}w(t)\\right) $$\n第二项为零，因为 $w_{\\perp}(t)$ 和 $w(t)$ 是正交的。我们需要计算标量积 $w_{\\perp}(t)^{\\top}e_{1}(t)$：\n$$ w_{\\perp}(t)^{\\top}e_{1}(t) = \\begin{pmatrix}-\\sin\\psi(t)  \\cos\\psi(t)\\end{pmatrix} \\begin{pmatrix}\\cos\\theta(t) \\\\ \\sin\\theta(t)\\end{pmatrix} $$\n$$ = \\cos\\psi(t)\\sin\\theta(t) - \\sin\\psi(t)\\cos\\theta(t) = \\sin(\\theta(t)-\\psi(t)) $$\n由于 $\\delta = \\psi(t)-\\theta(t)$，我们有 $\\theta(t)-\\psi(t) = -\\delta$。因此：\n$$ w_{\\perp}(t)^{\\top}e_{1}(t) = \\sin(-\\delta) = -\\sin(\\delta) $$\n将这些结果代回投影后的方程：\n$$ \\Omega = \\eta\\cos(\\delta) \\left(-\\sin(\\delta)\\right) $$\n$$ \\Omega = -\\eta\\sin(\\delta)\\cos(\\delta) $$\n使用三角恒等式 $\\sin(2x)=2\\sin(x)\\cos(x)$，我们可以将方程重写为：\n$$ \\Omega = -\\frac{\\eta}{2}\\sin(2\\delta) $$\n求解 $\\sin(2\\delta)$：\n$$ \\sin(2\\delta) = -\\frac{2\\Omega}{\\eta} $$\n为了求出 $\\delta$，我们对两边取反正弦。为了存在一个稳定的锁相解，权重向量必须滞后于特征向量，这意味着 $\\delta$ 是一个小的负角度。反正弦函数的主值提供了稳定解。\n$$ 2\\delta = \\arcsin\\left(-\\frac{2\\Omega}{\\eta}\\right) $$\n使用性质 $\\arcsin(-x) = -\\arcsin(x)$，我们得到：\n$$ 2\\delta = -\\arcsin\\left(\\frac{2\\Omega}{\\eta}\\right) $$\n最后，求解 $\\delta$：\n$$ \\delta = -\\frac{1}{2}\\arcsin\\left(\\frac{2\\Omega}{\\eta}\\right) $$\n该表达式要求 $|\\frac{2\\Omega}{\\eta}| \\le 1$，或 $\\eta \\ge 2\\Omega$，以使实数解存在。这个条件表明，学习率必须相对于旋转频率足够大，神经元才能跟踪输入的主成分。问题假设已经达到了这样的锁相状态。负号表示权重向量滞后于旋转的特征向量，这在物理上是符合预期的。",
            "answer": "$$\n\\boxed{-\\frac{1}{2}\\arcsin\\left(\\frac{2\\Omega}{\\eta}\\right)}\n$$"
        },
        {
            "introduction": "Oja法则通过其独特的更新形式，有效地对突触权重施加了$L_2$范数（欧几里得长度）的软约束，从而实现了主成分分析。然而，不同的归一化约束可以导致神经元学习出完全不同的特征 。这个练习要求你对比$L_2$范数和$L_1$范数约束下的学习结果，探索后者如何促进“稀疏”权重向量的形成，即只有少数几个突触权重保持显著，这在特征选择和高效编码中具有重要意义。",
            "id": "4025498",
            "problem": "一个线性神经元接收零均值输入 $x \\in \\mathbb{R}^d$，其协方差矩阵为 $C \\in \\mathbb{R}^{d \\times d}$，该矩阵是对称半正定的。其输出为 $y = w^\\top x$，其中 $w \\in \\mathbb{R}^d$ 是突触权重向量。考虑在固定范数突触归一化约束下提升期望输出功率的突触可塑性规则，因此在连续时间极限下，该动力学系统实现了对目标函数 $J(w) = \\mathbb{E}[y^2] = w^\\top C w$ 的约束上升，其约束条件为 $L_2$ 约束 $\\|w\\|_2 = 1$ 或 $L_1$ 约束 $\\|w\\|_1 = 1$。该设定是带有突触归一化的 Hebb 学习的标准抽象，其中 Oja 法则是经典的 $L_2$ 归一化实例。假设存在一个具有一小组 $k$ 个主导特征的数据体系：存在一个索引集 $S \\subset \\{1,\\dots,d\\}$，其大小 $|S| = k$ 且 $k \\ll d$，使得主子矩阵 $C_{SS}$ 的特征值远大于 $C$ 限制在 $S^c$ 上的特征值，并且在 $S$ 内部，$C$ 的非对角线元素不全为零，因此 $C$ 的顶层特征向量在 $S$ 中的所有坐标上都有非零（且同号）的载荷。在此体系下，通过选择所有关于不动点、其稳定性以及在两种不同范数约束下收敛后 $w$ 的稀疏性的正确陈述来回答以下问题。\n\nA. 在 $L_2$ 约束下，渐近稳定不动点与 $C$ 的顶层特征值相关的单位范数特征向量重合（相差一个全局符号）。在所述的具有相互关联的主导特征的体系中，收敛后的 $w$ 通常在 $S$ 中的所有坐标上都有非零分量（且在环境基中不一定是稀疏的）。\n\nB. 在 $L_1$ 约束下，如果 $C$ 是对角矩阵，且具有唯一的严格最大对角元素 $C_{ii}$，那么约束上升的每个渐近稳定不动点在坐标 $i$ 处恰好有一个非零项（符号可正可负），即 $w = \\pm e_i$，而所有其他坐标完全为零。\n\nC. 在 $L_2$ 约束下，且 $C$ 的顶层两个特征值之间存在简单的谱隙，则存在一个由顶层两个特征向量的张成空间内所有单位向量组成的连续单参数渐近稳定不动点族（一个圆）。\n\nD. 在 $L_1$ 约束下，当存在两个相等的主导方差而其他方差可忽略不计时，存在一个渐近稳定不动点的连续体，在 $L_1$ 球面上形成一个非平凡线段，其在两个主导坐标上都有非零权重。\n\nE. 在 $L_2$ 约束下，非主特征向量是不稳定的，且稳定性由谱隙决定；在 $L_1$ 约束下，当多个主导特征完全相等时（例如，在对角矩阵 $C$ 中具有相等的对角元素），存在多个与这些相等特征对应的离散稀疏吸引子（符号对称），但不存在一个稳定的不动点连续体。",
            "solution": "用户需要对一个线性神经元的不动点及其稳定性进行分析，该神经元的权重会进行调整以在 $L_2$ 或 $L_1$ 范数约束下最大化输出方差。\n\n### 问题验证\n\n**步骤 1：提取已知条件**\n- 神经元输入：$x \\in \\mathbb{R}^d$，且 $\\mathbb{E}[x]=0$。\n- 输入协方差：$C = \\mathbb{E}[xx^\\top] \\in \\mathbb{R}^{d \\times d}$，对称半正定。\n- 神经元输出：$y = w^\\top x$，权重向量为 $w \\in \\mathbb{R}^d$。\n- 目标函数：最大化 $J(w) = \\mathbb{E}[y^2] = \\mathbb{E}[(w^\\top x)(x^\\top w)] = w^\\top \\mathbb{E}[xx^\\top] w = w^\\top C w$。\n- 约束条件：动力学系统受限于 $\\|w\\|_2 = 1$ 或 $\\|w\\|_1 = 1$。\n- 特殊数据体系：存在一个索引集 $S \\subset \\{1,\\dots,d\\}$，其大小 $|S| = k \\ll d$。与 $S$ 中坐标所张成的子空间相关的特征值远大于其他特征值。子矩阵 $C_{SS}$ 具有非零的非对角线元素，且 $C$ 的顶层特征向量对于 $S$ 中的所有索引都具有非零且同号的分量。\n\n**步骤 2：使用提取的已知条件进行验证**\n- **科学依据：** 该问题是计算神经科学和机器学习中的一个标准表述。在 $\\|w\\|_2=1$ 约束下最大化 $w^\\top C w$ 是主成分分析（PCA）的定义。所描述的动力学对应于 PCA 的神经实现，如 Oja 法则。使用 $L_1$ 约束与稀疏 PCA 相关。这些都是公认的基本概念。\n- **适定性：** 该问题是适定的。它要求在一个紧集上求解一个约束优化问题的不动点性质。目标函数是连续的，约束集（$L_1$ 和 $L_2$ 单位球面）是紧的，这保证了最大值的存在。在梯度上升动力学下分析这些最大值的稳定性是一个标准程序。\n- **客观性：** 语言是技术性的、精确的，并且没有主观因素。\n\n**步骤 3：结论与行动**\n问题陈述在科学上是合理的、适定的和客观的。它是有效的。我将继续对每个选项进行详细分析。\n\n### 解答推导\n\n该问题涉及在范数约束下，寻找目标函数 $J(w) = w^\\top C w$ 的连续时间梯度上升动力学系统的稳定不动点。目标函数的梯度为 $\\nabla_w J(w) = 2Cw$。\n\n**$L_2$ 约束分析：$\\|w\\|_2 = 1$**\n这是经典的 PCA 问题。约束优化的不动点是方程 $Cw = \\lambda w$ 的解，其中 $\\lambda$ 是一个拉格朗日乘子。因此，不动点是协方差矩阵 $C$ 的单位范数特征向量。在不动点 $w=v_i$（其中 $v_i$ 是特征值为 $\\lambda_i$ 的特征向量）处的目标值为 $J(v_i) = v_i^\\top C v_i = v_i^\\top (\\lambda_i v_i) = \\lambda_i \\|v_i\\|_2^2 = \\lambda_i$。为了最大化 $J(w)$，必须选择对应于最大特征值 $\\lambda_{\\max}$ 的特征向量。\n\n关于稳定性，我们考虑一个投影到球面上的梯度流，其一般形式为 $\\dot{w} \\propto (I - ww^\\top)Cw$。Oja 法则导出连续时间动力学 $\\dot{w} = Cw - (w^\\top Cw)w$。对这些动力学的稳定性分析表明，一个特征向量 $v_i$ 是渐近稳定不动点的充要条件是其对应的特征值 $\\lambda_i$ 是 $C$ 的唯一最大特征值。如果 $\\lambda_i  \\lambda_{\\max}$，任何朝向顶层特征向量 $v_{\\max}$ 方向的微小扰动都会增长，使得 $v_i$ 成为一个不稳定不动点（具体来说，是一个鞍点）。如果顶层特征值是退化的（例如 $\\lambda_1 = \\lambda_2  \\lambda_3$），则由相应特征向量张成的整个子空间是一个稳定不动点流形。\n\n**$L_1$ 约束分析：$\\|w\\|_1 = 1$**\n这种表述被称为稀疏 PCA。约束流形是一个交叉多胞体，它在 $\\pm e_i$（标准基向量）处有“角点”和扁平的“面”。这种几何形状，结合二次目标函数，倾向于产生稀疏解，即最优 $w$ 的许多分量完全为零。\n最大值的 Karush-Kuhn-Tucker (KKT) 条件涉及 $L_1$ 范数的次梯度。这通常导致解的支撑集（其非零元素的集合）很小。\n不动点的稳定性取决于目标函数在约束曲面上的局部几何性质。梯度上升动力学将驱动权重向量 $w$ 朝向 $J(w)$ 在 $L_1$ 球面上的局部最大值。\n\n### 逐项分析\n\n**A. 在 $L_2$ 约束下，渐近稳定不动点与 $C$ 的顶层特征值相关的单位范数特征向量重合（相差一个全局符号）。在所述的具有相互关联的主导特征的体系中，收敛后的 $w$ 通常在 $S$ 中的所有坐标上都有非零分量（且在环境基中不一定是稀疏的）。**\n- 陈述的第一部分是 PCA 和 Hebb 学习理论中的一个标准结果，如上所述。假设顶层特征值是简单的（非退化的），唯一的渐近稳定不动点是 $\\pm v_{\\max}$，即对应于 $\\lambda_{\\max}$ 的特征向量。\n- 第二部分涉及问题中描述的特定数据体系。问题明确假设“$C$ 的顶层特征向量在 $S$ 中的所有坐标上都有非零载荷...”。由于动力学系统会收敛到这个顶层特征向量，收敛后的权重向量 $w$ 确实会在 $S$ 中的所有坐标上都有非零分量。主成分通常不是稀疏的，因此收敛后的 $w$ 在 $S$ 之外也可能具有非零（尽管可能很小）的分量。\n- **结论：正确。**\n\n**B. 在 $L_1$ 约束下，如果 $C$ 是对角矩阵，且具有唯一的严格最大对角元素 $C_{ii}$，那么约束上升的每个渐近稳定不动点在坐标 $i$ 处恰好有一个非零项（符号可正可负），即 $w = \\pm e_i$，而所有其他坐标完全为零。**\n- 在这种情况下，$C$ 是对角的，所以当 $j \\neq k$ 时 $C_{jk} = 0$。目标函数变为 $J(w) = w^\\top C w = \\sum_{j=1}^d C_{jj}w_j^2$。我们需要在 $\\sum_{j=1}^d |w_j| = 1$ 的约束下最大化它。\n- 设 $C_{ii}$ 是唯一的最大对角元素。对于任何向量 $w$，如果其权重分布在其他分量上（即 $w_j \\neq 0$，$j \\neq i$），我们可以通过将该权重移至第 $i$ 个分量来增加目标函数值。具体来说，如果我们将 $|w_j|$ 减小一个微小的量 $\\delta  0$ 并将 $|w_i|$ 增加 $\\delta$（保持 $L_1$ 范数不变），$J(w)$ 的变化量大约与 $2|w_i|\\delta C_{ii} - 2|w_j|\\delta C_{jj}$ 成正比，外加 $\\delta^2$ 阶的项。由于 $C_{ii}  C_{jj}$，我们总能构造一个能增加 $J(w)$ 的变化，除非所有权重都在第 $i$ 个分量上。\n- 因此，全局最大值点在 $w = \\pm e_i$ 处，此时 $J(w)=C_{ii}$。这些是 $L_1$ 球面的“角点”。梯度上升动力学将收敛到这两个点之一，使它们成为唯一的渐近稳定不动点。\n- **结论：正确。**\n\n**C. 在 $L_2$ 约束下，且 $C$ 的顶层两个特征值之间存在简单的谱隙，则存在一个由顶层两个特征向量的张成空间内所有单位向量组成的连续单参数渐近稳定不动点族（一个圆）。**\n- “顶层两个特征值之间存在简单的谱隙”意味着 $\\lambda_1  \\lambda_2 \\ge \\dots$。这表示最大特征值 $\\lambda_1$ 是唯一的（非退化的）。\n- 根据我们对 $L_2$ 情况的一般分析，如果顶层特征值是唯一的，唯一的渐近稳定不动点是其对应的特征向量 $\\pm v_1$。只有两个这样的点。\n- 只有当顶层特征值退化（即 $\\lambda_1 = \\lambda_2$）时，才会出现一个连续的稳定不动点族（一个圆）。但前提明确说明存在谱隙。因此，在 $\\{v_1, v_2\\}$ 的张成空间中，任何不是 $\\pm v_1$ 的向量都不是稳定不动点。实际上，这样的向量甚至根本不是不动点（除非它们是 $\\pm v_2$，而 $\\pm v_2$ 是不稳定的）。\n- **结论：不正确。**\n\n**D. 在 $L_1$ 约束下，当存在两个相等的主导方差而其他方差可忽略不计时，存在一个渐近稳定不动点的连续体，在 $L_1$ 球面上形成一个非平凡线段，其在两个主导坐标上都有非零权重。**\n- 这个场景假设一个对角矩阵 $C$，其中 $C_{11} = C_{22}  C_{jj}$ 对于 $j  2$。目标函数是 $J(w) = C_{11} w_1^2 + C_{11} w_2^2 + \\sum_{j2} C_{jj} w_j^2$。\n- 当 $w_j=0$ 对于所有 $j2$ 并且 $|w_1|+|w_2|=1$ 时，$J(w)$ 达到最大值。这组点在 $(w_1, w_2)$ 平面中形成一个正方形，这是一个全局最大值点的连续体。\n- 然而，该陈述是关于*渐近稳定*不动点。让我们分析这个集合内的稳定性。令 $|w_1|=\\alpha$ 和 $|w_2|=1-\\alpha$，其中 $\\alpha \\in [0,1]$。目标值为 $J(\\alpha) = C_{11}(\\alpha^2 + (1-\\alpha)^2)$。这个关于 $\\alpha$ 的函数是一个开口向上的抛物线（$J''(\\alpha) = 4C_{11}  0$），其最小值在 $\\alpha=1/2$ 处。最大值出现在区间的边界上，即 $\\alpha=0$ 和 $\\alpha=1$。\n- 这意味着线段内部的任何点（其中 $|w_1|,|w_2|  0$）在梯度上升动力学下都是不稳定的。动力学将把解推向其中一个权重为零的角点（即推向 $w=\\pm e_1$ 或 $w=\\pm e_2$）。因此，不存在一个*稳定*不动点的连续体。\n- **结论：不正确。**\n\n**E. 在 $L_2$ 约束下，非主特征向量是不稳定的，且稳定性由谱隙决定；在 $L_1$ 约束下，当多个主导特征完全相等时（例如，在对角矩阵 $C$ 中具有相等的对角元素），存在多个与这些相等特征对应的离散稀疏吸引子（符号对称），但不存在一个稳定的不动点连续体。**\n- 第一部分，关于 $L_2$ 约束，是对稳定性分析的正确总结。对于特征向量 $v_i$，如果其特征值 $\\lambda_i  \\lambda_{\\max}$，它们是不稳定的，因为沿具有更大特征值的特征向量方向的扰动将会增长。这种变化的速率 $(\\lambda_j - \\lambda_i)$ 取决于谱隙。\n- 第二部分，关于 $L_1$ 约束，描述了为选项 D 分析的情况。当主导特征相等（$C_{11} = C_{22}$）时，分析表明稳定不动点是离散的、稀疏的解 $w=\\pm e_1$ 和 $w=\\pm e_2$。这些是“与这些相等特征对应的多个离散稀疏吸引子”。分析还表明“不存在一个稳定的不动点连续体”。这是一个正确的描述。\n- **结论：正确。**",
            "answer": "$$\\boxed{ABE}$$"
        }
    ]
}