## 引言
在[计算神经科学](@entry_id:274500)领域，理解大脑如何处理信息的核心挑战在于如何精确地描述和建模神经元的随机发放活动。神经[脉冲序列](@entry_id:1132157)，即神经元在时间上的“语言”，本质上是随机的，需要强大的概率和统计工具来进行解码。本文旨在为研究生和研究人员提供一个关于分析神经数据的两个基石性概率模型——[泊松分布](@entry_id:147769)与高斯分布的全面指南。

文章旨在填补理论知识与实际应用之间的鸿沟。我们不仅要理解这些分布的数学形式，更要掌握何时以及如何应用它们，并认识到它们的局限性。通过本文的学习，读者将能够为神经数据选择合适的[统计模型](@entry_id:165873)，从而更准确地揭示[神经编码](@entry_id:263658)的奥秘。

为实现这一目标，本文分为三个核心章节。在“原理与机制”中，我们将深入探讨泊松过程与高斯分布的数学基础，分析其关键假设、统计特性以及两者之间的关系。接着，在“应用与跨学科连接”中，我们将展示这些理论如何在[广义线性模型](@entry_id:900434)（GLM）、模型评估、动态系统追踪以及[网络分析](@entry_id:139553)等前沿研究中发挥作用。最后，“动手实践”部分将通过具体的编程练习，帮助读者将理论知识转化为解决实际问题的能力。

## 原理与机制

本章深入探讨了用于分析神经脉冲数据的核心概率模型——泊松过程与高斯分布。我们将从泊松过程的基本原理出发，将其作为描述神经元发放活动的一个基准模型。随后，我们将讨论如何对这些模型进行统计推断，并研究真实数据中常见的对[泊松模型](@entry_id:1129884)的偏离现象，如超离散。我们还将评估在何种条件下高斯分布可以作为脉冲计数的有效近似，并阐明其局限性。最后，我们将介绍超越标[准泊松](@entry_id:920823)框架的更高级[点过程模型](@entry_id:1129863)，如双重[随机过程](@entry_id:268487)和[自激励过程](@entry_id:1131410)，它们能够更真实地捕捉神经活动的复杂动态。

### 泊松过程：神经[脉冲序列](@entry_id:1132157)的基准模型

泊松过程是描述一系列离散事件在时间上随机发生的数学模型，是计算神经科学中对神经[脉冲序列](@entry_id:1132157)进行建模的基石。其核心在于“[无记忆性](@entry_id:201790)”，即事件在任何时刻发生的概率不依赖于过去的历史。

#### 泊松过程的基本假设

一个[点过程](@entry_id:1129862)可以用其在微小时间间隔 $[t, t+dt)$ 内产生一个事件的条件概率来定义，即[条件强度函数](@entry_id:1122850) $\lambda(t)$。对于一个泊松过程，其关键假设是过程的增量是独立的，这意味着在任何不重叠的时间区间内，事件发生的次数是相互独立的。这进一步意味着[条件强度函数](@entry_id:1122850) $\lambda(t)$ 是一个确定性函数，不依赖于过程在 $t$ 时刻之前的历史。

根据[强度函数](@entry_id:755508) $\lambda(t)$ 是否随时间变化，泊松过程可分为两类：
- **[齐次泊松过程](@entry_id:263782) (Homogeneous Poisson Process, HPP)**：[强度函数](@entry_id:755508)为常数 $\lambda(t) = \lambda$。这意味着事件发生的概率在任何时间点都是相同的。
- **[非齐次泊松过程](@entry_id:1128851) (Inhomogeneous Poisson Process, IPP)**：[强度函数](@entry_id:755508)是时间的函数 $\lambda(t)$。这允许我们对神经元发放率随时间动态变化的情况进行建模，例如响应于外部刺激或受内部状态调制。

#### [齐次泊松过程](@entry_id:263782)

[齐次泊松过程](@entry_id:263782)是最简单的[点过程模型](@entry_id:1129863)。我们可以从两个等价的视角来理解它。一个视角是基于计数的，另一个是基于事件间隔的。

从事件间隔的视角来看，[齐次泊松过程](@entry_id:263782)可以被定义为一个更新过程，其中事件间的间隔时间（Interspike Intervals, ISIs）是[独立同分布](@entry_id:169067)（i.i.d.）的指数[随机变量](@entry_id:195330)，其概率密度函数为 $f(t) = \lambda \exp(-\lambda t)$。基于这一“无记忆”的假设，我们可以推导出在任意长度为 $t$ 的时间窗口内观察到 $k$ 个脉冲的概率。第 $k$ 个脉冲的到达时间 $S_k$ 是前 $k$ 个独立[指数分布](@entry_id:273894)的总和，它遵循[形状参数](@entry_id:270600)为 $k$、速[率参数](@entry_id:265473)为 $\lambda$ 的伽马分布，即 $S_k \sim \text{Gamma}(k, \lambda)$。事件 $\{N(t)=k\}$ 等价于第 $k$ 个脉冲在时间 $t$ 或之前到达，而第 $k+1$ 个脉冲在时间 $t$ 之后到达，即 $\{S_k \le t \lt S_{k+1}\}$。通过对伽马分布的[累积分布函数](@entry_id:143135)进行分析，可以证明在一个持续时间为 $t$ 的观测窗口内，脉冲计数 $N(t)$ 的[概率质量函数](@entry_id:265484)为：

$$
P(N(t)=k) = \frac{(\lambda t)^k \exp(-\lambda t)}{k!}, \quad k \in \{0, 1, 2, \dots\}
$$

这正是[泊松分布](@entry_id:147769)的[概率质量函数](@entry_id:265484)，其参数为 $\mu = \lambda t$ 。

基于泊松过程的微小时间间隔定义，即在足够小的间隔 $\Delta t$ 内，发生一次脉冲的概率为 $\lambda \Delta t + o(\Delta t)$，发生零次脉冲的概率为 $1 - \lambda \Delta t + o(\Delta t)$，而发生两次或以上脉冲的概率为 $o(\Delta t)$，我们也可以推导出该过程的基本统计特性。通过构建脉冲数 $N(T)$ 的[概率生成函数](@entry_id:190573) $G(s,T) = \mathbb{E}[s^{N(T)}] = \exp(\lambda T (s-1))$，可以方便地计算出其均值和方差 。对 $G(s,T)$ 求导并取 $s=1$ 即可得到：

$$
\mathbb{E}[N(T)] = \lambda T
$$
$$
\mathrm{Var}[N(T)] = \lambda T
$$

这一结果表明，对于[齐次泊松过程](@entry_id:263782)，计数的方差等于其均值。这个特性引出了一个重要的度量——**法诺因子 (Fano factor)**，定义为方差与均值的比率：$F = \mathrm{Var}(N)/\mathbb{E}[N]$。对于任何[齐次泊松过程](@entry_id:263782)，[法诺因子](@entry_id:136562)恒等于 $1$。

#### [非齐次泊松过程](@entry_id:1128851)

当神经元的发放率随时间变化时，例如在响应动态刺激时，使用[非齐次泊松过程](@entry_id:1128851)（IPP）进行建模更为合适。IPP 由一个随时间变化的[条件强度函数](@entry_id:1122850) $\lambda(t)$ 定义。

对于一个IPP，在任意区间 $[t, t+\Delta]$ 内的脉冲计数 $N([t, t+\Delta])$ 依然遵循[泊松分布](@entry_id:147769)，但其参数不再是 $\lambda \Delta$，而是[强度函数](@entry_id:755508)在该区间上的积分 ：

$$
\Lambda(t, t+\Delta) = \int_t^{t+\Delta} \lambda(s) \, ds
$$

因此，计数的[概率质量函数](@entry_id:265484)为：

$$
P(N([t, t+\Delta])=k) = \frac{\Lambda(t, t+\Delta)^k \exp(-\Lambda(t, t+\Delta))}{k!}
$$

同样地，对于在给定区间上的脉冲计数，其均值和方差都等于 $\Lambda(t, t+\Delta)$，这意味着即使发放率随时间变化，只要该变化是确定性的（非随机的），在试验间重复测量的脉冲计数的法诺因子仍然为 $1$ 。然而，与[齐次泊松过程](@entry_id:263782)不同，IPP 的脉冲间隔（ISIs）不再服从单一的[指数分布](@entry_id:273894)。一个脉冲在 $t_i$ 时刻发生后，到下一个脉冲的等待时间 $\tau$ 的概率密度函数依赖于未来的[强度函数](@entry_id:755508)，形式为 $f(\tau | t_i) = \lambda(t_i+\tau) \exp(-\int_{t_i}^{t_i+\tau} \lambda(s) ds)$，这通常不是指数形式 。

### 泊松模型的统计推断

为了将[泊松模型](@entry_id:1129884)应用于真实的神经数据，我们需要从观测到的[脉冲序列](@entry_id:1132157)中估计模型的参数。[最大似然估计](@entry_id:142509)（MLE）是一种核心的统计推断方法。

#### [似然函数](@entry_id:921601)

[似然函数](@entry_id:921601)是在给定模型参数下，观测到特定数据集的概率（或概率密度）。对于一个由[强度函数](@entry_id:755508) $\lambda(t; \boldsymbol{\theta})$ [参数化](@entry_id:265163)的[非齐次泊松过程](@entry_id:1128851)，在区间 $[0, T]$ 内观测到一组脉冲时间 $\{t_i\}_{i=1}^{N(T)}$ 的[似然函数](@entry_id:921601)可以从其基本定义推导得出。该[似然函数](@entry_id:921601)必须同时捕捉到两方面的信息：一是在精确的 $t_i$ 时刻发生了脉冲，二是在所有这些脉冲之间的空隙时间里没有发生脉冲。其表达式为 ：

$$
\mathcal{L}(\boldsymbol{\theta}) = \left( \prod_{i=1}^{N(T)} \lambda(t_i; \boldsymbol{\theta}) \right) \exp\left( -\int_0^T \lambda(t; \boldsymbol{\theta}) \, dt \right)
$$

这个表达式中的第一项是所有脉冲时刻的强度乘积，反映了在这些时刻“应该”有脉冲。第二项是一个指数衰减项，它惩罚了那些在整个观测窗口内产生过高平均强度的参数，这个积分项确保了模型对“沉默”时段的正确描述。

在实践中，我们通常最大化对数似然函数 $\ell(\boldsymbol{\theta}) = \ln \mathcal{L}(\boldsymbol{\theta})$，因为它将乘积转换为求和，更易于数学处理：

$$
\ell(\boldsymbol{\theta}) = \sum_{i=1}^{N(T)} \ln \lambda(t_i; \boldsymbol{\theta}) - \int_0^T \lambda(t; \boldsymbol{\theta}) \, dt
$$

#### 广义线性模型（GLM）的应用

[广义线性模型](@entry_id:900434)（GLM）为[参数化](@entry_id:265163)[强度函数](@entry_id:755508) $\lambda(t; \boldsymbol{\theta})$ 提供了一个强大而灵活的框架。一个常见的选择是使用指数链接函数，以确保[强度函数](@entry_id:755508)始终为正：

$$
\lambda(t; \boldsymbol{\theta}) = \exp(\mathbf{x}(t)^\top \boldsymbol{\theta})
$$

其中 $\mathbf{x}(t)$ 是一个已知的[协变](@entry_id:634097)量向量，可以代表外部刺激、神经元自身的发放历史或来自其他神经元群体的输入。$\boldsymbol{\theta}$ 是需要估计的参数权重向量。

将此GLM形式代入[对数似然函数](@entry_id:168593)，我们得到：

$$
\ell(\boldsymbol{\theta}) = \sum_{i=1}^{N(T)} \mathbf{x}(t_i)^\top \boldsymbol{\theta} - \int_0^T \exp(\mathbf{x}(t)^\top \boldsymbol{\theta}) \, dt
$$

这个对数似然函数对于参数 $\boldsymbol{\theta}$ 是[凹函数](@entry_id:274100)。这意味着它只有一个[全局最大值](@entry_id:174153)，没有[局部极值](@entry_id:144991)，这极大地简化了参数估计过程，因为标准的梯度上升等优化算法可以保证收敛到唯一的[最大似然](@entry_id:146147)解 。

### 对[泊松模型](@entry_id:1129884)的偏离：超离散与[负二项模型](@entry_id:918790)

尽管泊松过程是一个非常有用的理论工具，但真实神经元的发放活动常常偏离其严格的统计假设。最常见的偏离之一是**超离散 (overdispersion)**，即在重复试验中，脉冲计数的方差显著大于其均值，导致法诺因子大于 $1$。

#### 识别超离散：法诺因子

超离散现象可能源于多种生物学机制，例如神经元内在的爆发式发放模式，或是在不同试验间存在缓慢的、未被观测到的兴奋性波动。这些波动违反了[泊松模型](@entry_id:1129884)关于试验间发放率恒定的假设。

[法诺因子](@entry_id:136562)是诊断超离散的有力工具。一个严谨的诊断程序应在控制了潜在混淆因素（如发放率的[非平稳性](@entry_id:180513)）的情况下进行。具体而言，我们应该针对一个假定发放率平稳的短时间窗（或时间仓, bin），计算在多次试验（trials）间的样本均值 $\hat{\mu}$ 和样本方差 $\hat{v}$，然后得到该时间仓的经验法诺因子 $\hat{F} = \hat{v}/\hat{\mu}$。如果在一个刺激响应周期内的多个时间仓中，$\hat{F}$ 系统性地大于 $1$，则表明存在超离散。需要注意的是，将不同时间仓的计数混合在一起计算总的[法诺因子](@entry_id:136562)是错误的做法，因为发放率的[非平稳性](@entry_id:180513)本身就会人为地造成[方差膨胀](@entry_id:756433)，从而与真实的超离散相混淆 。

通过分析不同模型如何影响法诺因子，我们可以获得更深的洞察。例如，一个**[零膨胀](@entry_id:920070)泊松 (Zero-Inflated Poisson, ZIP)** 模型，其中发放过程以概率 $\pi$ 处于完全不发放的“结构性零”状态，以概率 $1-\pi$ 遵循一个泊松过程，其[法诺因子](@entry_id:136562)约为 $F \approx 1 + \pi\mu$，其中 $\mu$ 是潜在泊松过程的均值。另一个例子是**混合泊松 (Mixed-Poisson)** 模型，其中每次试验的发放率 $\Lambda_t$ 本身是一个[随机变量](@entry_id:195330)。根据全变异数律，这种试验间发放率的变异会导致[法诺因子](@entry_id:136562) $F = 1 + w \frac{\mathrm{Var}(\Lambda)}{\mathbb{E}[\Lambda]}$，其中 $w$ 是时间仓宽度。在这两种情况下，法诺因子都大于 $1$ 且随平均计数的增加而[线性增长](@entry_id:157553)，这为识别超离散的来源提供了线索 。

#### 伽马-泊松混合模型：[负二项分布](@entry_id:894191)

为了对超离散数据进行建模，我们可以使用比[泊松分布](@entry_id:147769)更灵活的模型。负二项分布（Negative Binomial, NB）是一个自然的选择，它可以被看作一个**伽马-泊松[混合模型](@entry_id:266571)**。这个模型假设在单次试验中，脉冲计数 $Y$ 遵循[泊松分布](@entry_id:147769) $Y | \Lambda \sim \mathrm{Poisson}(\Lambda)$，但其速[率参数](@entry_id:265473) $\Lambda$ 本身在不同试验间是随机变化的，遵循伽马分布 $\Lambda \sim \mathrm{Gamma}(k, \beta)$。

通过对潜变量 $\Lambda$ 进行积分，可以得到 $Y$ 的边缘分布，即负二项分布。我们可以利用全期望律和全变异数律来推导其均值和方差，而无需写出其复杂的[概率质量函数](@entry_id:265484)。设 $Y$ 的无条件均值为 $\mu$，我们可以推导出 ：

- **均值**: $\mathbb{E}[Y] = \mathbb{E}[\mathbb{E}[Y | \Lambda]] = \mathbb{E}[\Lambda] = \mu$
- **方差**: $\mathrm{Var}(Y) = \mathbb{E}[\mathrm{Var}(Y | \Lambda)] + \mathrm{Var}(\mathbb{E}[Y | \Lambda]) = \mathbb{E}[\Lambda] + \mathrm{Var}(\Lambda)$

对于伽马分布 $\mathrm{Gamma}(k, \beta)$，其均值为 $k/\beta$，方差为 $k/\beta^2$。将 $\mu = k/\beta$ 代入，可得 $\mathrm{Var}(\Lambda) = \mu^2/k$。因此，[负二项分布](@entry_id:894191)的方差为：

$$
\mathrm{Var}(Y) = \mu + \frac{\mu^2}{k}
$$

这个方差-均值关系式明确地体现了超离散。方差总是大于均值，其法诺因子为 $F = 1 + \mu/k$。参数 $k$ 被称为**离散参数**，它控制着超离散的程度。当 $k \to \infty$ 时，$\mu^2/k \to 0$，[负二项分布](@entry_id:894191)收敛于泊松分布，其[法诺因子](@entry_id:136562)趋近于 $1$。

### [高斯近似](@entry_id:636047)及其局限性

在处理大量数据时，使用[连续分布](@entry_id:264735)（如高斯分布）来近似离散的脉冲计数，在计算上可能更方便。这种近似的合理性根植于中心极限定理（CLT）。

#### 单个神经元计数的[高斯近似](@entry_id:636047)

[中心极限定理](@entry_id:143108)表明，大量[独立同分布](@entry_id:169067)的[随机变量](@entry_id:195330)的均值，其分布近似于高斯分布。对于 $n$ 次独立重复试验中的脉冲计数 $N_i \sim \text{Poisson}(\lambda)$，其样本均值 $\bar{N} = \frac{1}{n}\sum_{i=1}^n N_i$ 在 $n$ 很大时，其分布可以近似为 $\mathcal{N}(\lambda, \lambda/n)$。

然而，这种近似在某些条件下会失效，尤其是在神经科学的常见场景中 ：

1.  **平均计数过小**：当平均脉冲计数 $\lambda$ 很小时（例如，$\lambda \ll 1$），[泊松分布](@entry_id:147769)高度偏斜且集中在少数几个整数上。此时，对称的高斯分布是一个糟糕的近似。基于[高斯近似](@entry_id:636047)构建的置信区间（如[Wald区间](@entry_id:173132)）可能会产生无意义的结果，例如负的置信下限，因为高斯分布的支撑集是整个[实数轴](@entry_id:147286)，而计数不能为负。

2.  **分布的[偏度](@entry_id:178163)**：泊松分布的偏度为 $1/\sqrt{\lambda}$。当 $\lambda$ 很小时，分布呈明显的[右偏](@entry_id:180351)。对于样本均值 $\bar{N}$，其分布 $S_n = \sum N_i \sim \text{Poisson}(n\lambda)$ 的[偏度](@entry_id:178163)为 $1/\sqrt{n\lambda}$。如果总[期望计数](@entry_id:162854) $n\lambda$ 不够大，$\bar{N}$ 的[抽样分布](@entry_id:269683)将保持明显的非对称性。此时，基于对称性假设的推断方法（如对称[置信区间](@entry_id:142297)和双边[Wald检验](@entry_id:164095)）会错误地分配尾部概率，导致推断不准确 。

3.  **数据的离散性**：脉冲计数是整数。这导致基于计数的检验统计量的[p值](@entry_id:136498)只能取一些离散的值。因此，对于任意给定的[显著性水平](@entry_id:902699) $\alpha$（如 $0.05$），通常无法构建一个[拒绝域](@entry_id:897982)，使其大小恰好等于 $\alpha$。这使得基于离散数据的[精确检验](@entry_id:178040)本质上是保守的，即实际的I类错误率低于名义水平 。

#### 群体计数的多变量[高斯近似](@entry_id:636047)

尽管对单个神经元的低计数进行[高斯近似](@entry_id:636047)存在问题，但当考虑一个大的神经元群体时，[高斯近似](@entry_id:636047)可以成为一个非常强大的工具。我们可以将一个时间窗内的群体脉冲计数向量 $\mathbf{N}$ 表示为在许多个极小时间子区间内脉冲增量向量 $\mathbf{X}_k$ 的总和，即 $\mathbf{N} = \sum_{k=1}^K \mathbf{X}_k$。

根据**多变量中心极限定理**，如果这些增量向量 $\mathbf{X}_k$ 是独立的，并且其总和的均值足够大，那么总计数向量 $\mathbf{N}$ 的分布可以很好地用一个多变量高斯分布 $\mathcal{N}(\boldsymbol{\mu}, \boldsymbol{\Sigma})$ 来近似 。其中：

- [均值向量](@entry_id:266544) $\boldsymbol{\mu} = \mathbb{E}[\mathbf{N}] = \sum_k \mathbb{E}[\mathbf{X}_k]$。
- 协方差矩阵 $\boldsymbol{\Sigma} = \mathrm{Cov}(\mathbf{N}) = \sum_k \mathrm{Cov}(\mathbf{X}_k)$。

这个近似的有效性取决于两个条件：
1.  **大的平均计数**：每个神经元的平均计数 $\mu_i$ 都必须足够大（$\mu_i \gg 1$），以确保边缘分布不严重偏斜。
2.  **弱离散性**：计数的单位步长 $1$ 相对于分布的标准差 $\sqrt{\Sigma_{ii}}$ 必须很小。

这个框架的一个重要优点是，它能自然地将神经元之间的相关性（源于共同输入或网络内部相互作用）捕捉到协方差矩阵 $\boldsymbol{\Sigma}$ 的非对角[线元](@entry_id:196833)素中，从而提供对群体编码的丰富描述。

### 超越泊松过程：更真实的神经脉冲模型

为了更精确地捕捉神经[脉冲序列](@entry_id:1132157)的复杂动态，研究者们发展了超越标[准泊松](@entry_id:920823)过程假设的模型。这些模型通常通过引入随机[强度函数](@entry_id:755508)或历史依赖性来实现。

#### 双重[随机过程](@entry_id:268487)：对数-高斯[Cox过程](@entry_id:747993)

**[Cox过程](@entry_id:747993)**，或称**[双重随机泊松过程](@entry_id:274191) (doubly stochastic Poisson process)**，是一个[非齐次泊松过程](@entry_id:1128851)，其[强度函数](@entry_id:755508) $\lambda(t)$ 本身就是一个[随机过程](@entry_id:268487)。这为建模无法直接观测的、随时间随机波动的神经元状态（如兴奋性水平）提供了一个优雅的框架。

一个特别强大和灵活的[Cox过程](@entry_id:747993)是**对数-高斯[Cox过程](@entry_id:747993) (Log-Gaussian Cox Process, LGCP)**。在该模型中，[强度函数](@entry_id:755508)被建模为 $\lambda(t) = \exp(g(t))$，其中对数强度 $g(t)$ 是一个高斯过程 (Gaussian Process, GP)。[高斯过程](@entry_id:182192)先验为函数 $g(t)$ 赋予了平滑性等属性，使其成为一个强大的非参数[贝叶斯建模](@entry_id:178666)工具。

在一个LGCP模型中，我们感兴趣的是从观测到的[脉冲时间](@entry_id:1132155) $\{t_i\}$ 中推断出潜在的对数[强度函数](@entry_id:755508) $g(t)$。根据[贝叶斯定理](@entry_id:897366)，[后验概率](@entry_id:153467) $p(g | \{t_i\})$ 正比于[似然](@entry_id:167119)和先验的乘积。这个模型的联合概率密度（未归一化）可以表示为 ：

$$
p(\{t_i\}, g) \propto p(\{t_i\} | g) \cdot p(g) \propto \exp\left( \sum_{i=1}^N g(t_i) - \int_0^T \exp(g(t)) \, dt \right) \cdot p_{\mathcal{GP}}(g)
$$

其中第一项是给定 $g(t)$ 下的泊松[似然](@entry_id:167119)，第二项 $p_{\mathcal{GP}}(g)$ 是由高斯过程定义的[函数空间](@entry_id:143478)上的先验概率。

#### [自激励过程](@entry_id:1131410)：[霍克斯过程](@entry_id:203666)

真实神经元的一个关键特征是其发放历史会影响其未来的发放概率，例如，一个脉冲之后通常会有一个不应期，或者一个脉冲可能增加（或减少）短期内再次发放的可能性（即爆发或适应）。**[霍克斯过程](@entry_id:203666) (Hawkes process)** 是一类能够直接对这种历史依赖性或“自激励”特性进行建模的[点过程](@entry_id:1129862)。

一个线性的 $p$ 维霍克斯过程，用于描述一个神经元群体，其第 $i$ 个神经元的[条件强度函数](@entry_id:1122850) $\lambda_i(t)$ 定义为 ：

$$
\lambda_i(t) = \mu_i + \sum_{j=1}^p \int_0^\infty \phi_{ij}(\tau) \, dN_j(t-\tau)
$$

这里，$\mu_i$ 是一个恒定的背景发放率。$\phi_{ij}(\tau)$ 是**激励[核函数](@entry_id:145324)**，它描述了神经元 $j$ 在 $\tau$ 时间前的一个脉冲对神经元 $i$ 当前发放率的贡献。如果 $i=j$，则 $\phi_{ii}$ 描述了神经元自身的历史依赖性；如果 $i \neq j$，则 $\phi_{ij}$ 描述了神经元间的有效连接。

[霍克斯过程](@entry_id:203666)可以被看作一个分支过程：背景事件（由 $\mu_i$ 产生）是一代，它们可以触发二代事件（由 $\phi_{ij}$ 介导），二代又可以触发三代，依此类推。这个过程能否达到一个平稳状态，取决于这个“分支”过程是否是亚临界的。定义一个矩阵 $\mathbf{G}$，其元素 $g_{ij} = \int_0^\infty \phi_{ij}(\tau) d\tau$ 代表神经元 $j$ 的一个脉冲平均能触发神经元 $i$ 产生多少个后代脉冲。该过程存在一个唯一的、具有有限发放率的平稳解的充要条件是 $\mathbf{G}$ 的谱半径 $\rho(\mathbf{G})$ 小于 $1$ 。

在平稳状态下，平均发放率向量 $\mathbf{r}$ 满足[线性方程](@entry_id:151487) $\mathbf{r} = \boldsymbol{\mu} + \mathbf{G}\mathbf{r}$，其解为：

$$
\mathbf{r} = (\mathbf{I} - \mathbf{G})^{-1} \boldsymbol{\mu}
$$

此外，对于一个平稳的霍克斯过程，在长为 $T$ 的时间窗口内的脉冲计数向量 $\mathbf{N}(T)$ 满足一个多变量中心极限定理，其渐近协方差矩阵为 ：

$$
\mathbf{\Sigma} = (\mathbf{I}-\mathbf{G})^{-1}\,\mathrm{diag}(\mathbf{r})\,(\mathbf{I}-\mathbf{G})^{-\top}
$$

这个结果表明，[霍克斯过程](@entry_id:203666)不仅能捕捉到神经元的平均发放率，还能通过其参数 $(\boldsymbol{\mu}, \mathbf{G})$ 完整地刻画群体活动中的协方差结构，使其成为分析[神经回路功能](@entry_id:183982)连接的强大工具。