## 引言
神经元发放的[脉冲序列](@entry_id:1132157)，即“[脉冲序列](@entry_id:1132157)”，是大脑中信息传递、处理和存储的基本货币。这些看似随机的时间事件序列蕴含着关于外部世界、内部状态和认知过程的丰富信息。然而，要从这些复杂的时序模式中提取意义，我们面临一个核心挑战：如何建立一个严谨的数学框架来描述、分析并最终理解这些[脉冲序列](@entry_id:1132157)的统计结构及其背后的生物物理机制？本文旨在系统性地解决这一知识鸿沟。

本文将引导读者深入[脉冲序列](@entry_id:1132157)统计的世界，从基础原理到高级应用。在第一部分 **“原理与机制”** 中，我们将学习如何将[脉冲序列](@entry_id:1132157)形式化为点过程，掌握衡量其变异性的核心统计量，并通过一系列生成模型（如泊松过程、[更新过程](@entry_id:275714)、[霍克斯过程](@entry_id:203666)等）来理解不同的生物机制如何塑造我们观察到的发放模式。接着，在第二部分 **“应用与跨学科联系”** 中，我们将探讨这些统计工具如何被应用于破译神经密码、评估神经元间的相互作用，以及将微观的脉冲活动与宏观的网络状态联系起来。最后，在 **“实践练习”** 部分，你将有机会通过具体的编程和推导任务，亲手实现和应用前文所学的核心概念，从而将理论知识转化为实践技能。通过这一结构化的学习路径，你将能够掌握分析神经数据、构建[神经计算模型](@entry_id:1128632)所需的关键统计学基础。

## 原理与机制

在神经科学中，神经元发放的[脉冲序列](@entry_id:1132157)是信息传递和处理的基本单位。为了从这些看似随机的事件序列中提取有意义的[神经编码](@entry_id:263658)原理，我们需要一个严谨的数学框架来描述和分析它们的统计特性。本章将深入探讨描述单个及多个神经元[脉冲序列](@entry_id:1132157)的关键统计原理和生成机制。我们将从[脉冲序列](@entry_id:1132157)的点过程形式化定义开始，介绍衡量其变异性的核心统计量，然后通过一系列典型的[随机过程模型](@entry_id:272197)，揭示不同生物物理机制如何塑造我们观测到的脉冲统计特性。

### 将[脉冲序列](@entry_id:1132157)形式化为点过程

从数学角度看，一个神经元的[脉冲序列](@entry_id:1132157)可以被理想化为时间轴上的一系列离散事件。点过程理论为描述这[类数](@entry_id:156164)据提供了强大的形式化工具。

#### [点过程](@entry_id:1129862)和[计数过程](@entry_id:896402)

一个[脉冲序列](@entry_id:1132157)最自然的表示是一系列严格递增的脉冲时间$\{T_k\}_{k \ge 1}$，其中$T_k$是第$k$个脉冲的发生时刻。在[点过程](@entry_id:1129862)理论中，这组随机的时间点可以被等价地视为一个 **简单[点过程](@entry_id:1129862)（simple point process）**。形式上，一个简单点过程$\Pi$是一个从[概率空间](@entry_id:201477)$(\Omega, \mathcal{F}, \mathbb{P})$到某个[测度空间](@entry_id:191702)的映射。对于每一个outcome $\omega \in \Omega$，$\Pi(\omega)$都是$\mathbb{R}_+$上的一个整数值[拉东测度](@entry_id:188027)（Radon measure），它满足两个关键条件：对于任何有界区间$B$，$\Pi(B)$的值（即区间$B$内的脉冲数）[几乎必然](@entry_id:262518)是有限的；且对于任何单一时间点$t$，$\Pi(\{t\})$的值[几乎必然](@entry_id:262518)为0或1。后一个条件即为“简单性”，它意味着在同一个瞬间发生多个脉冲的概率为零 。

与点过程的测度视角密切相关的是 **[计数过程](@entry_id:896402)（counting process）** 的视角。给定一个点过程$\Pi$，我们可以定义一个与之相关的[计数过程](@entry_id:896402)$N(t)$，它表示在时间区间$(0, t]$内发生的脉冲总数，即$N(t) \triangleq \Pi((0, t])$。这个过程$N(t)$是一个右连续[左极限](@entry_id:139055)（càdlàg）、非递减、取整数值的[随机过程](@entry_id:268487)。对于一个简单点过程，$N(t)$的跳跃幅度最大为1。反之，任何具有这些性质的[计数过程](@entry_id:896402)也唯一地定义了一个简单[点过程](@entry_id:1129862)。这两种视角——事件时间的集合和随时间累积的计数——是等价的，为我们分析[脉冲序列](@entry_id:1132157)提供了灵活的工具 。

#### 历史和条件强度

为了捕捉脉冲发放的动态和依赖性，我们需要一个能够描述在任意时刻$t$，神经元发放脉冲的瞬时可能性的量。这个量就是 **[条件强度函数](@entry_id:1122850)（conditional intensity function）**，通常记为$\lambda(t | \mathcal{H}_t)$。这里的$\mathcal{H}_t$代表在时间$t$之前所有可观测事件的 **历史（history）**，它在数学上由一个 **filtration** $\{\mathcal{F}_t\}_{t \ge 0}$来形式化，$\mathcal{F}_t$是包含了截至时间$t$所有信息的$\sigma$-代数。

条件强度$\lambda(t | \mathcal{H}_t)$被精确地定义为在给定历史$\mathcal{H}_t$的条件下，在时间$t$附近一个无穷小区间$[t, t+dt)$内发生一个脉冲的瞬时概率率 ：
$$
\mathbb{P}(\text{在 } [t, t+dt) \text{ 内有一个脉冲} | \mathcal{H}_t) = \lambda(t | \mathcal{H}_t) dt + o(dt)
$$
这个定义等价于$\mathbb{E}[dN(t) | \mathcal{H}_t] = \lambda(t | \mathcal{H}_t) dt$，其中$dN(t)$是在$[t, t+dt)$内的脉冲计数增量。[条件强度函数](@entry_id:1122850)是点过程理论的核心，因为它完全刻画了一个[点过程](@entry_id:1129862)的统计动力学。一个模型一旦指定了$\lambda(t | \mathcal{H}_t)$的形式，也就完全确定了该[脉冲序列](@entry_id:1132157)的所有统计性质。更深层次地，现代点过程理论通过[鞅](@entry_id:267779)论（martingale theory）提供了最严谨的框架。在该框架下，$\lambda(t | \mathcal{H}_t)$是一个[可预测过程](@entry_id:262945)（predictable process），它使得 **补偿过程（compensated process）** $M(t) = N(t) - \int_0^t \lambda(s | \mathcal{H}_s) ds$成为一个[鞅](@entry_id:267779) 。

### [脉冲序列](@entry_id:1132157)的基本统计量

有了形式化的框架，我们便可以定义一系列统计量来量化[脉冲序列](@entry_id:1132157)的不同方面。这些统计量通常分为两类：基于脉冲间隔（ISI）的和基于脉冲计数的。

#### 发放率的[点估计](@entry_id:174544)

最基本的统计量是神经元的 **平均发放率（mean firing rate）** $\lambda$。在持续时间为$T$的观测窗口内，如果记录到的总脉冲数为$N(T)$，那么发放率的一个自然估计量是经验发放率$\hat{\lambda}$：
$$
\hat{\lambda} = \frac{N(T)}{T}
$$
如果其背后的脉冲过程是 **平稳的（stationary）**，即其统计特性不随时间改变，那么这个估计量是 **无偏的（unbiased）**。这是因为根据[平稳过程](@entry_id:196130)的定义，期望脉冲数$\mathbb{E}[N(T)] = \lambda T$。因此，估计量的期望为$\mathbb{E}[\hat{\lambda}] = \mathbb{E}[N(T)/T] = (\lambda T) / T = \lambda$ 。

然而，这个估计量的精度取决于观测时长$T$和过程本身的变异性。对于一个平穩的泊松过程（Poisson process），其脉冲计数服从泊松分布，方差等于均值，即$\mathrm{Var}(N(T)) = \lambda T$。因此，[估计量的方差](@entry_id:167223)为：
$$
\mathrm{Var}(\hat{\lambda}) = \mathrm{Var}\left(\frac{N(T)}{T}\right) = \frac{1}{T^2}\mathrm{Var}(N(T)) = \frac{\lambda T}{T^2} = \frac{\lambda}{T}
$$
这个结果表明，随着观测时长$T$的增加，发放率的估计会变得越来越精确，其方差以$1/T$的速率衰减。对于更一般的、满足一定混合条件的平稳[点过程](@entry_id:1129862)，这个$1/T$的衰减规律通常仍然成立 。

#### 脉冲间隔的变异性：变异系数

发放率描述了脉冲的快慢，但没有告诉我们脉冲发放的规律性。为了量化这一点，我们转而分析 **脉冲间隔（Inter-Spike Interval, ISI）** 的分布。令$\mu = \mathbb{E}[\text{ISI}]$和$\sigma^2 = \mathrm{Var}(\text{ISI})$分别为ISI的均值和方差。一个重要的无量纲度量是 **变異系数（Coefficient of Variation, CV）**：
$$
\mathrm{CV} = \frac{\sigma}{\mu}
$$
CV衡量了[ISI分布](@entry_id:1126754)的离散程度相对于其均值的比例。
-   如果$\mathrm{CV} = 1$，表明脉冲发放的变异性与泊松过程相似（其ISI服从[指数分布](@entry_id:273894)）。
-   如果$\mathrm{CV}  1$，表明脉冲发放比泊松过程更规律、更接近周期性。这种情况称为 **亚泊松（sub-Poisson）** 或规则发放（regular spiking）。
-   如果$\mathrm{CV} > 1$，表明脉冲发放比泊松过程更不规律，通常表现为脉冲的集群或“猝发”（bursting）。这种情况称为 **超泊松（super-Poisson）** 或猝发发放（bursty spiking）。

因此，CV是区分不同发放模式（如规则发放、随机发和猝发放）的第一个关键指标。

#### 脉冲计数的变异性：[法诺因子](@entry_id:136562)

另一个衡量变异性的重要指标是 **法诺因子（Fano Factor, FF）**，它衡量在固定时间窗口$T$内脉冲计数的变异性：
$$
F(T) = \frac{\mathrm{Var}(N_T)}{\mathbb{E}[N_T]}
$$
法诺因子同样是一个无量纲量，其解释与CV类似：
-   $F(T) = 1$对应于泊松过程的计数统计。
-   $F(T)  1$(亚泊松) 表明计数比泊松过程更稳定，意味着[脉冲序列](@entry_id:1132157)更具规律性。
-   $F(T) > 1$(超泊松) 表明计数比泊松过程有更大的波动，反映了脉冲发放的集群或慢速调制。

法诺因子通常依赖于观测窗口的长度$T$。分析$F(T)$如何随$T$变化可以揭示[脉冲序列](@entry_id:1132157)在不同时间尺度上的相关性结构。

### 生成模型与变异性的机制

CV和FF为我们提供了量化[脉冲序列变异性](@entry_id:1132164)的“什么”（what），而不同的[点过程模型](@entry_id:1129863)则为我们提供了关于“为什么”（why）的mechanistic 解释。下面我们将探讨几种核心模型，看它们如何与特定的生物物理机制联系起来，并产生不同的统计特性。

#### 基准模型：泊松过程

最简单的[点过程模型](@entry_id:1129863)是 **[齐次泊松过程](@entry_id:263782)（homogeneous Poisson process）**。其条件强度是一个与历史无关的常数：$\lambda(t | \mathcal{H}_t) = \lambda$。这意味着脉冲的发生是完全随机的，不受过去脉冲的影响。它的ISI服从均值为$1/\lambda$的[指数分布](@entry_id:273894)，因此$\mathrm{CV} = 1$。其在任何长度为$T$的区间内的脉冲计数$N_T$服从均值为$\lambda T$的[泊松分布](@entry_id:147769)，因此$\mathrm{Var}(N_T) = \mathbb{E}[N_T] = \lambda T$，从而$F(T) = 1$对所有$T$成立  。

一个常见的误解是，如果发放率随时间变化，那么过程的变异性就一定会偏离[泊松分布](@entry_id:147769)。然而，**[非齐次泊松过程](@entry_id:1128851)（inhomogeneous Poisson process）** 的[条件强度](@entry_id:1122849)是一个确定的时间函数$\lambda(t)$，同样与脉冲历史无关。尽管发放率在变，但计数的方差仍然等于其均值（$\mathrm{Var}(N_T) = \mathbb{E}[N_T] = \int_0^T \lambda(t) dt$），因此[法诺因子](@entry_id:136562)$F(T)$仍然恒等于1  。这说明，要使CV或FF偏离1，脉冲强度必须依赖于 **过去脉冲的历史** 或 **随机的外部因素**。

#### 更新过程：近期历史的作用

**更新过程（renewal process）** 是对泊松过程的第一个重要推广。在更新过程中，ISI是[独立同分布](@entry_id:169067)的（i.i.d.），但不再局限于指数分布。这意味着，一个脉冲发生后，下一个脉冲的发生概率只取决于自上一个脉冲以来经过的时间，而与更早的脉冲历史无关。其条件强度$\lambda(t | \mathcal{H}_t)$退化为一个只依赖于$t - T_{N(t)}$（即当前时间与上一个脉冲时间的差）的函数，这个函数被称为 **风险函数（hazard function）** $h(\tau)$ 。风险函数$h(\tau)$与ISI的[概率密度函数](@entry_id:140610)$p(\tau)$和[生存函数](@entry_id:267383)$S(\tau)$密切相关，关系为$h(\tau) = p(\tau) / S(\tau)$。

##### 绝对不應期的影响

神经元的一个基本生物物理特性是 **[绝对不应期](@entry_id:151661)（absolute refractory period）**，即在发放一个脉冲后的一小段时间$\tau_{\mathrm{ref}}$内，神经元无法再次发放。我们可以通过一个简单的[风险函数](@entry_id:166593)来建模这一现象：在$t  \tau_{\mathrm{ref}}$时$h(t)=0$，而在$t \ge \tau_{\mathrm{ref}}$时$h(t)=\lambda$。

通过这个[风险函数](@entry_id:166593)，我们可以推导出ISI的概率密度函数$p(t)$，它是一个向右平移了$\tau_{\mathrm{ref}}$的指数分布。由此可以计算出ISI的均值$\mu = \tau_{\mathrm{ref}} + 1/\lambda$和方差$\sigma^2 = 1/\lambda^2$ 。因此，变异系数为：
$$
\mathrm{CV} = \frac{\sigma}{\mu} = \frac{1/\lambda}{\tau_{\mathrm{ref}} + 1/\lambda} = \frac{1}{1 + \lambda \tau_{\mathrm{ref}}}
$$
由于$\lambda > 0$和$\tau_{\mathrm{ref}} > 0$，我们必然得到$\mathrm{CV}  1$。这直观地反映了不应期通过消除极短的ISI，使得[脉冲序列](@entry_id:1132157)变得比泊松过程更加规律。值得注意的是，引入不应期后，ISI不再服从[指数分布](@entry_id:273894)，因此该过程不再是泊松过程 。

##### 伽马更新过程和发放规律性

伽马分布为ISI提供了一个更灵活的模型。一个 **伽马更新过程** 的ISI服从[形状参数](@entry_id:270600)为$k$、尺度参数为$\theta$的伽马分布。其ISI的均值为$\mu=k\theta$，方差为$\sigma^2=k\theta^2$。因此，其变异系数的平方为：
$$
\mathrm{CV}^2 = \frac{\sigma^2}{\mu^2} = \frac{k\theta^2}{(k\theta)^2} = \frac{1}{k}
$$
这个结果非常重要：伽马更新过程的CV仅由[形状参数](@entry_id:270600)$k$决定。当$k=1$时，伽马分布退化为[指数分布](@entry_id:273894)，我们回到了泊松过程，$\mathrm{CV}=1$。当$k > 1$时，[ISI分布](@entry_id:1126754)比指数分布更窄，$\mathrm{CV}  1$，发放更规律。当$k \to \infty$时，$\mathrm{CV} \to 0$，过程趋近于完全规则的周期性发放。当$0  k  1$时，$\mathrm{CV} > 1$，发放比泊松过程更不规则。

##### 法诺因子和[变异系数](@entry_id:192183)的渐近关系

CV和FF虽然都衡量变异性，但它们之间存在深刻的联系。对于任何[平稳更新过程](@entry_id:273771)，当观测窗口$T$足够大时，[法诺因子](@entry_id:136562)会收敛到ISI的[变异系数](@entry_id:192183)的平方 ：
$$
\lim_{T \to \infty} F(T) = \mathrm{CV}^2
$$
这个基本定理连接了短时间尺度的间隔统计量（CV）和长时间尺度的计数统计量（FF）。例如，对于上述具有绝对不应期的模型，其渐近法諾因子为$\mathcal{F}_{\infty} = \mathrm{CV}^2 = 1 / (1 + \lambda \tau_{\mathrm{ref}})^2  1$ 。对于伽马[更新过程](@entry_id:275714)，其渐近[法诺因子](@entry_id:136562)为$\mathcal{F}_{\infty} = 1/k$  。这都说明，由内在“记忆”（如不应期）引起的ISI规律性（$\mathrm{CV}1$）会导致长时间尺度上计数的规律性（$F1$）。

#### 双重[随机过程](@entry_id:268487)：慢速外部波动的作用

与更新过程的内在记忆不同，另一类导致非泊松统计特性的重要机制是 **外部驱动的慢速波动**。如果一个神经元接收的兴奋性输入在缓慢地波动（例如，由于网络状态、动物的觉醒水平或注意力的变化），那么其发放率也会随之波动。**双重[随机过程](@entry_id:268487)（doubly stochastic process）** 或 **[Cox过程](@entry_id:747993)** 正是用于建模这种情况的。其条件强度$\lambda(t)$本身就是一个[随机过程](@entry_id:268487)。

##### 由发放率变异性引起的计数过分散

让我们考虑一个简单但富有启发性的[Cox过程](@entry_id:747993)模型：在每次观测中，发放率$\Lambda$是一个常数，但它在不同次观测之间是随机变化的，其均值为$\mathbb{E}[\Lambda] = r$，方差为$\mathrm{Var}(\Lambda) = v$。我们可以使用 **[全方差公式](@entry_id:177482)** 来计算脉冲计数$N_T$的无[条件方差](@entry_id:183803)：
$$
\mathrm{Var}(N_T) = \mathbb{E}[\mathrm{Var}(N_T|\Lambda)] + \mathrm{Var}(\mathbb{E}[N_T|\Lambda])
$$
-   $\mathbb{E}[N_T|\Lambda] = \Lambda T$且$\mathrm{Var}(N_T|\Lambda) = \Lambda T$（因为条件于$\Lambda$是泊松过程）。
-   第一项是$\mathbb{E}[\Lambda T] = rT$。
-   第二项是$\mathrm{Var}(\Lambda T) = T^2 \mathrm{Var}(\Lambda) = vT^2$。

因此，总方差为$\mathrm{Var}(N_T) = rT + vT^2$。计数的均值为$\mathbb{E}[N_T] = \mathbb{E}[\Lambda T] = rT$。于是，[法诺因子](@entry_id:136562)为：
$$
F(T) = \frac{rT + vT^2}{rT} = 1 + \frac{v}{r}T
$$
这个结果表明，当发放率存在随机波动时（$v>0$），[法诺因子](@entry_id:136562)总是大于1，并且随观测窗口$T$[线性增长](@entry_id:157553)  。这种$F(T) > 1$的现象被称为 **过分散（over-dispersion）**，它是慢速发放率波动的标志性特征。更一般地，对于具有stationary 强度过程$\lambda(t)$和[自协方差函数](@entry_id:262114)$C(\tau)$的[Cox过程](@entry_id:747993)，Fano因子可以表示为$F(T) = 1 + \frac{2}{\mu T} \int_0^T (T-\tau)C(\tau)d\tau$，这显示了方差的增加是如何由强度的[自相关](@entry_id:138991)性决定的 。

##### 发放率混合对脉冲间隔变异性的影响

发放率的波动不仅影响计数，也影响ISI的统计。如果我们考虑一个由不同速率的泊松过程混合而成的过程（例如，每次选择一个速率$\lambda_i$的概率为$p_i$），那么得到的混合[ISI分布](@entry_id:1126754)通常会导致$\mathrm{CV} > 1$。例如，在一个由两个具有不同[不应期](@entry_id:152190)和发放率的[更新过程](@entry_id:275714)混合而成的模型中，总ISI方差不仅包含每个过程的方差的加权平均，还包含一个由两个过程均值之差的平方贡献的项$\propto (\mu_A - \mu_B)^2$。这个额外的方差来源通常会使$\mathrm{CV}$增大 。在更简单的情况下，如果发放率$\lambda$是从一个伽马分布中抽取的，那么得到的[ISI分布](@entry_id:1126754)的$\mathrm{CV}_{\mathrm{ISI}}$会大于1，反映了“猝发”特性：在高速率状态下产生密集的脉冲串，在低速率状态下则是长时间的静息 。

#### 历史依赖过程：脉冲历史的整合

[更新过程](@entry_id:275714)的“记忆”是有限的，它只记得上一次脉冲的时间。然而，神经元的动力学可能更复杂，受到多个过去脉冲的累积影响。

##### [广义线性模型](@entry_id:900434)和脉冲历史核

**[广义线性模型](@entry_id:900434)（Generalized Linear Model, GLM）** 提供了一个强大的框架来描述这种更长的历史依赖性。在GLM中，条件强度被建模为：
$$
\lambda(t | \mathcal{H}_t) = f\left(\mu + \sum_{t_k  t} h(t - t_k)\right)
$$
其中$f$是一个非负link function（如指数函数$\exp(\cdot)$），$\mu$是基线输入，而$h(\tau)$是 **脉冲历史核（spike-history kernel）**。这个核函数描述了在$\tau$时间前的一个脉冲如何影响当前的瞬时发放率。通过精心设计$h(\tau)$的形状，我们可以捕捉复杂的动力学 ：
-   **[绝对不应期](@entry_id:151661)**：可以通过使$h(\tau)$在$\tau$很小时趋于$-\infty$来实现，这将通过link function $f$把$\lambda(t)$压制到0。
-   **[相对不应期](@entry_id:169059)**：可以通过使$h(\tau)$在[不应期](@entry_id:152190)后的一段时间内为负值来实现，这会抑制发放率。
-   **发放后易化** 或 **反弹**：可以通过使$h(\tau)$在某个时间尺度上为正值来实现，这会增加发放率，可能导致猝发。

##### 霍克斯过程：自兴奋和集群发放

一个特别重要的历史依赖模型是 **[霍克斯过程](@entry_id:203666)（Hawkes process）**，其[条件强度](@entry_id:1122849)是线性的：
$$
\lambda(t | \mathcal{H}_t) = \mu + \sum_{t_k  t} \phi(t-t_k)
$$
其中$\mu > 0$是基线强度，$\phi(t)$是一个非负的 **触发核（triggering kernel）**。这里的$\phi(t) > 0$意味着每个脉冲都会“自我兴奋”，增加未来发放脉冲的可能性。这种自[反馈机制](@entry_id:269921)是产生脉冲集群或“雪崩”的典型方式。该过程的稳定性由 **分支比（branching ratio）** $n = \int_0^\infty \phi(t) dt$控制，当$n  1$时过程是平稳的。对于[霍克斯过程](@entry_id:203666)，其渐近[法诺因子](@entry_id:136562)为 ：
$$
\lim_{T \to \infty} F(T) = \frac{1}{(1-n)^2}
$$
由于$0 \le n  1$，我们有$F(\infty) \ge 1$。当$n > 0$时，$F(\infty) > 1$，反映了自兴奋导致的超泊松计数统计。这与[Cox过程](@entry_id:747993)形成了有趣的对比：两者都能产生[超泊松统计](@entry_id:1132632)，但[Cox过程](@entry_id:747993)的机制是外部慢速波动，而霍克斯过程的机制是内在的、快速的自兴奋。

### 扩展到多元过程：神经元间的相互作用

以上讨论主要集中在单个神经元的[脉冲序列](@entry_id:1132157)上。然而，神经计算源于神经元群体的相互作用。GLM/Hawkes框架可以自然地扩展到 **多元点过程（multivariate point process）**，以描述一个神经元群体$(N_1(t), \dots, N_p(t))$的活动。对于群体中的第$i$个神经元，其条件强度现在依赖于整个群体的历史$\mathcal{H}_t = \{N_1, \dots, N_p\}$：
$$
\lambda_i(t | \mathcal{H}_t) = f\left(\mu_i + \sum_{j=1}^p \int_0^{t^-} h_{ij}(t-s) dN_j(s)\right)
$$
这里的核函数$h_{ij}(\tau)$现在有了更丰富的含义 ：
-   当$i=j$时，$h_{ii}(\tau)$是 **自身历史核（self-history kernel）**，描述了神经元自身的发放历史如何影响其当前发放率（例如，不应期）。
-   当$i \neq j$时，$h_{ij}(\tau)$是 **交叉历史核（cross-history kernel）**，它描述了神经元$j$的脉冲如何因果地影响神经元$i$的发放率。

交叉历史核$h_{ij}$的符号和形状揭示了神经元间的 **有效连接（effective connectivity）**。如果$h_{ij}(\tau)$在某个延迟$\tau > 0$后为正，表明$j$对$i$有兴奋性作用；如果为负，则为抑制性作用。重要的是，这种影响是 **有向的** 和 **因果的**，通常$h_{ij} \neq h_{ji}$，反映了[神经回路](@entry_id:169301)中连接的非对称性。通过从同时记录的[脉冲序列](@entry_id:1132157)数据中拟合这些核函数，我们可以推断出[神经回路](@entry_id:169301)的功能连接图谱。