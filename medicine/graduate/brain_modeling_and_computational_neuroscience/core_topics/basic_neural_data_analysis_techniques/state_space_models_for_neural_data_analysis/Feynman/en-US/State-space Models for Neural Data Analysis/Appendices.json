{
    "hands_on_practices": [
        {
            "introduction": "Before fitting a state-space model to data, it is crucial to understand its fundamental structural properties. This exercise provides hands-on practice with two core concepts from systems theory: controllability and observability. By analyzing a simple, hypothetical linear time-invariant system, you will learn how to determine if a model's latent states can be influenced by inputs (controllability) and inferred from outputs (observability), which is essential for ensuring a model is well-posed and identifiable from data. ",
            "id": "4022537",
            "problem": "Consider a linear time-invariant (LTI) latent state model of a neural population near a fixed point, where latent dynamics arise from a first-order linearization of the underlying biophysical processes and observations represent linearly mixed firing rates. The discrete-time state-space model is\n$$\nx_{t+1} = A x_t + B u_t,\\quad y_t = C x_t,\n$$\nwhere $x_t \\in \\mathbb{R}^{n}$ is the latent state, $u_t \\in \\mathbb{R}^{m}$ is the exogenous input, and $y_t \\in \\mathbb{R}^{p}$ is the observed activity. The matrices $A \\in \\mathbb{R}^{n \\times n}$, $B \\in \\mathbb{R}^{n \\times m}$, and $C \\in \\mathbb{R}^{p \\times n}$ are given by\n$$\nA = \\begin{pmatrix}\n0  1  0 \\\\\n0  0  0 \\\\\n0  0  0\n\\end{pmatrix},\\quad\nB = \\begin{pmatrix}\n0 \\\\\n1 \\\\\n0\n\\end{pmatrix},\\quad\nC = \\begin{pmatrix}\n1  0  0\n\\end{pmatrix}.\n$$\nUse the foundational definitions of controllability and observability for linear time-invariant systems: the reachable (controllable) subspace generated by $B$ under $A$ is the span of $\\{A^{k} B\\}_{k=0}^{n-1}$, and the unobservable subspace under $C$ and $A$ is the intersection of kernels of $\\{C A^{k}\\}_{k=0}^{n-1}$. From these bases, compute:\n1. The rank of the controllability matrix for the pair $(A,B)$.\n2. The rank of the observability matrix for the pair $(A,C)$.\n3. The minimal latent dimensionality consistent with the input-output behavior generable by $(A,B,C)$, understood as the dimension of the controllable-and-observable part of the system (the minimal realization of the transfer behavior $u_t \\mapsto y_t$).\n\nExpress your final answer as a row matrix containing, in order, the controllability rank, the observability rank, and the minimal latent dimension. No rounding is required. Do not include units.",
            "solution": "The problem asks for an analysis of a given discrete-time linear time-invariant (LTI) state-space model to determine its controllability, observability, and the minimal dimensionality required to represent its input-output behavior.\n\nThe state-space model is defined by the equations:\n$$\nx_{t+1} = A x_t + B u_t\n$$\n$$\ny_t = C x_t\n$$\nwhere the state dimension is $n=3$, the input dimension is $m=1$, and the output dimension is $p=1$. The matrices are given as:\n$$\nA = \\begin{pmatrix}\n0  1  0 \\\\\n0  0  0 \\\\\n0  0  0\n\\end{pmatrix},\\quad\nB = \\begin{pmatrix}\n0 \\\\\n1 \\\\\n0\n\\end{pmatrix},\\quad\nC = \\begin{pmatrix}\n1  0  0\n\\end{pmatrix}\n$$\n\nWe will compute the three requested quantities in order.\n\n1. The rank of the controllability matrix for the pair $(A, B)$.\n\nAccording to the problem definition, the controllable subspace is the span of the columns of the controllability matrix $\\mathcal{C}$. For a system with state dimension $n=3$, this matrix is constructed as:\n$$\n\\mathcal{C} = \\begin{pmatrix} B  AB  A^2B \\end{pmatrix}\n$$\nFirst, we compute the matrix products $AB$ and $A^2B$.\n$$\nAB = \\begin{pmatrix}\n0  1  0 \\\\\n0  0  0 \\\\\n0  0  0\n\\end{pmatrix}\n\\begin{pmatrix}\n0 \\\\\n1 \\\\\n0\n\\end{pmatrix}\n= \\begin{pmatrix}\n1 \\\\\n0 \\\\\n0\n\\end{pmatrix}\n$$\nTo compute $A^2B$, we first find $A^2$:\n$$\nA^2 = A \\cdot A = \\begin{pmatrix}\n0  1  0 \\\\\n0  0  0 \\\\\n0  0  0\n\\end{pmatrix}\n\\begin{pmatrix}\n0  1  0 \\\\\n0  0  0 \\\\\n0  0  0\n\\end{pmatrix}\n= \\begin{pmatrix}\n0  0  0 \\\\\n0  0  0 \\\\\n0  0  0\n\\end{pmatrix} = \\mathbf{0}\n$$\nSince $A^2$ is the zero matrix, it follows that $A^2B = \\mathbf{0} \\cdot B = \\begin{pmatrix} 0 \\\\ 0 \\\\ 0 \\end{pmatrix}$.\nNow, we construct the controllability matrix $\\mathcal{C}$:\n$$\n\\mathcal{C} = \\begin{pmatrix}\n0  1  0 \\\\\n1  0  0 \\\\\n0  0  0\n\\end{pmatrix}\n$$\nThe rank of a matrix is the number of linearly independent columns (or rows). The first two columns, $\\begin{pmatrix} 0  1  0 \\end{pmatrix}^T$ and $\\begin{pmatrix} 1  0  0 \\end{pmatrix}^T$, are orthogonal and thus linearly independent. The third column is the zero vector, which is linearly dependent on the others. Therefore, the rank of the controllability matrix is $2$.\n$$\n\\text{rank}(\\mathcal{C}) = 2\n$$\n\n2. The rank of the observability matrix for the pair $(A, C)$.\n\nThe unobservable subspace is defined as the intersection of the kernels of $CA^k$ for $k=0, \\dots, n-1$. This is equivalent to the null space of the observability matrix $\\mathcal{O}$, which for $n=3$ is:\n$$\n\\mathcal{O} = \\begin{pmatrix} C \\\\ CA \\\\ CA^2 \\end{pmatrix}\n$$\nWe compute the matrix products $CA$ and $CA^2$.\n$$\nCA = \\begin{pmatrix}\n1  0  0\n\\end{pmatrix}\n\\begin{pmatrix}\n0  1  0 \\\\\n0  0  0 \\\\\n0  0  0\n\\end{pmatrix}\n= \\begin{pmatrix}\n0  1  0\n\\end{pmatrix}\n$$\nSince $A^2 = \\mathbf{0}$, we have:\n$$\nCA^2 = C \\cdot \\mathbf{0} = \\begin{pmatrix} 0  0  0 \\end{pmatrix}\n$$\nNow, we construct the observability matrix $\\mathcal{O}$:\n$$\n\\mathcal{O} = \\begin{pmatrix}\n1  0  0 \\\\\n0  1  0 \\\\\n0  0  0\n\\end{pmatrix}\n$$\nThe rank of this matrix is the number of linearly independent rows. The first two rows, $\\begin{pmatrix} 1  0  0 \\end{pmatrix}$ and $\\begin{pmatrix} 0  1  0 \\end{pmatrix}$, are orthogonal and thus linearly independent. The third row is the zero vector. The matrix is already in row echelon form with two pivots. Therefore, the rank of the observability matrix is $2$.\n$$\n\\text{rank}(\\mathcal{O}) = 2\n$$\n\n3. The minimal latent dimensionality consistent with the input-output behavior.\n\nThis dimension is defined as the dimension of the controllable-and-observable part of the system. This can be found using the Kalman decomposition of the state space. The state space $\\mathbb{R}^n$ can be decomposed into a direct sum of four subspaces: controllable and observable ($S_{co}$), controllable and unobservable ($S_{c\\bar{o}}$), uncontrollable and observable ($S_{\\bar{c}o}$), and uncontrollable and unobservable ($S_{\\bar{c}\\bar{o}}$). The minimal dimension corresponds to $\\dim(S_{co})$.\n\nThe controllable subspace is the image of the controllability matrix, $\\mathcal{R} = \\text{Im}(\\mathcal{C})$. From our calculation in part 1:\n$$\n\\mathcal{R} = \\text{span}\\left\\{\\begin{pmatrix} 0 \\\\ 1 \\\\ 0 \\end{pmatrix}, \\begin{pmatrix} 1 \\\\ 0 \\\\ 0 \\end{pmatrix}\\right\\} = \\text{span}\\{e_1, e_2\\}\n$$\nwhere $e_1, e_2, e_3$ are the standard basis vectors in $\\mathbb{R}^3$. The dimension of the controllable subspace is $\\dim(\\mathcal{R}) = \\text{rank}(\\mathcal{C}) = 2$.\n\nThe unobservable subspace is the null space of the observability matrix, $\\mathcal{N} = \\text{Ker}(\\mathcal{O})$. We solve $\\mathcal{O}x = 0$:\n$$\n\\begin{pmatrix}\n1  0  0 \\\\\n0  1  0 \\\\\n0  0  0\n\\end{pmatrix}\n\\begin{pmatrix} x_1 \\\\ x_2 \\\\ x_3 \\end{pmatrix} = \\begin{pmatrix} 0 \\\\ 0 \\\\ 0 \\end{pmatrix}\n$$\nThis yields $x_1=0$ and $x_2=0$, with $x_3$ being a free variable. Thus, the unobservable subspace is:\n$$\n\\mathcal{N} = \\text{span}\\left\\{\\begin{pmatrix} 0 \\\\ 0 \\\\ 1 \\end{pmatrix}\\right\\} = \\text{span}\\{e_3\\}\n$$\nThe observable subspace, denoted $\\mathcal{O}_s$, is the orthogonal complement of the unobservable subspace $\\mathcal{N}$, or equivalently, the image of $\\mathcal{O}^T$.\n$$\n\\mathcal{O}_s = \\mathcal{N}^{\\perp} = (\\text{span}\\{e_3\\})^{\\perp} = \\text{span}\\{e_1, e_2\\}\n$$\n The dimension of the observable subspace is $\\dim(\\mathcal{O}_s) = \\text{rank}(\\mathcal{O}) = 2$.\n\nThe controllable-and-observable subspace $S_{co}$ is the intersection of the controllable subspace $\\mathcal{R}$ and the observable subspace $\\mathcal{O}_s$:\n$$\nS_{co} = \\mathcal{R} \\cap \\mathcal{O}_s = \\text{span}\\{e_1, e_2\\} \\cap \\text{span}\\{e_1, e_2\\} = \\text{span}\\{e_1, e_2\\}\n$$\nThe dimension of this subspace is the number of basis vectors, which is $2$.\n\nAlternatively, the minimal dimension is the order of the system's transfer function $H(z) = C(zI - A)^{-1}B$. We compute $(zI - A)^{-1}$:\n$$\nzI - A = \\begin{pmatrix} z  -1  0 \\\\ 0  z  0 \\\\ 0  0  z \\end{pmatrix}\n$$\n$$\n(zI - A)^{-1} = \\frac{1}{\\det(zI-A)} \\text{adj}(zI-A) = \\frac{1}{z^3} \\begin{pmatrix} z^2  z  0 \\\\ 0  z^2  0 \\\\ 0  0  z^2 \\end{pmatrix} = \\begin{pmatrix} \\frac{1}{z}  \\frac{1}{z^2}  0 \\\\ 0  \\frac{1}{z}  0 \\\\ 0  0  \\frac{1}{z} \\end{pmatrix}\n$$\nNow we compute the transfer function:\n$$\nH(z) = C (zI - A)^{-1} B = \\begin{pmatrix} 1  0  0 \\end{pmatrix} \\begin{pmatrix} \\frac{1}{z}  \\frac{1}{z^2}  0 \\\\ 0  \\frac{1}{z}  0 \\\\ 0  0  \\frac{1}{z} \\end{pmatrix} \\begin{pmatrix} 0 \\\\ 1 \\\\ 0 \\end{pmatrix}\n$$\n$$\nH(z) = \\begin{pmatrix} \\frac{1}{z}  \\frac{1}{z^2}  0 \\end{pmatrix} \\begin{pmatrix} 0 \\\\ 1 \\\\ 0 \\end{pmatrix} = \\frac{1}{z^2}\n$$\nThe transfer function is $H(z) = z^{-2}$. This is a second-order system. The minimal realization of this system has dimension $2$. This confirms the result from the state-space decomposition.\n\nThe three requested values are:\n1. Controllability rank: $2$\n2. Observability rank: $2$\n3. Minimal latent dimension: $2$",
            "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n2  2  2\n\\end{pmatrix}\n}\n$$"
        },
        {
            "introduction": "The relationship between latent neural states and observed activity is often nonlinear. This practice moves from linear theory to the practical implementation of nonlinear filters, a critical step for modeling real neural data. You will implement and compare two workhorse algorithms: the Extended Kalman Filter (EKF), which uses linearization, and the Unscented Kalman Filter (UKF), which uses a deterministic sampling method. By coding the update steps and testing them on a model with a saturating nonlinearity, you will gain concrete intuition for their mechanisms and performance differences. ",
            "id": "4022569",
            "problem": "Consider a single-step measurement update in a nonlinear state-observation setting suitable for neural data analysis. Let the latent neural state be scalar $x \\in \\mathbb{R}$ with a Gaussian prior $x \\sim \\mathcal{N}(m, P)$ and an observation $y \\in \\mathbb{R}$ generated by a saturating nonlinearity plus noise, $y = h(x) + \\varepsilon$, where $h(x) = \\tanh(x)$ and $\\varepsilon \\sim \\mathcal{N}(0, R)$. The goal is to implement a single posterior update step using both the Extended Kalman Filter (EKF) and the Unscented Kalman Filter (UKF), and to compare the posterior variance reductions achieved by each method.\n\nStarting from fundamental Bayesian principles, the EKF constructs a local linear approximation to the observation model and applies the Gaussian update. The UKF constructs sigma points for the prior and propagates them through the nonlinear observation function to approximate the measurement mean and covariance. Use Unscented Transform parameters $\\alpha = 0.3$, $\\beta = 2$, and $\\kappa = 0$.\n\nYour program must compute, for each test case, the posterior variances produced by the EKF and UKF updates and then report the variance reduction ratios defined by $(P - P_{\\text{post}})/P$ for each method, where $P$ is the prior variance and $P_{\\text{post}}$ is the posterior variance from the corresponding filter.\n\nImplement the update for the EKF and UKF without any randomness, using the following test suite of parameter sets, where each test case is specified as $(m, P, R, y)$:\n\n- Happy-path case near moderate nonlinearity: $(0.2, 0.5, 0.1, \\tanh(0.2) + 0.05)$.\n- Saturation boundary case with large prior mean: $(3.0, 0.5, 0.1, \\tanh(3.0) - 0.02)$.\n- Very low measurement noise edge case: $(-1.0, 0.3, 10^{-6}, \\tanh(-1.0) + 0.0)$.\n- Very high measurement noise edge case: $(0.0, 1.0, 10.0, \\tanh(0.0) + 0.5)$.\n- Small prior variance boundary case: $(0.5, 10^{-4}, 0.1, \\tanh(0.5) + 0.02)$.\n\nNo physical units are involved; treat all quantities as dimensionless real numbers. Angles, if any, must be interpreted in radians, but this problem requires only real-valued scalars.\n\nFor each test case, compute two decimal numbers: the EKF variance reduction ratio and the UKF variance reduction ratio. Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, where each element is a two-element list corresponding to $[\\text{EKF reduction}, \\text{UKF reduction}]$ for that test case. For example, the output format must be like $[[r_{1,\\text{EKF}}, r_{1,\\text{UKF}}],[r_{2,\\text{EKF}}, r_{2,\\text{UKF}}],\\dots]$ where each $r$ is a decimal number.",
            "solution": "We begin from Bayesian filtering principles for state-space models. The latent scalar state $x \\in \\mathbb{R}$ has a Gaussian prior $x \\sim \\mathcal{N}(m, P)$ with prior mean $m$ and prior variance $P$. The measurement model is $y = h(x) + \\varepsilon$, where $h(x) = \\tanh(x)$ represents a saturating nonlinearity often used as a proxy for neural firing rate nonlinearities, and $\\varepsilon \\sim \\mathcal{N}(0, R)$ is Gaussian observation noise with variance $R$. The objective of a single measurement update is to produce an approximate posterior $p(x \\mid y)$ that remains Gaussian via either the Extended Kalman Filter (EKF) or the Unscented Kalman Filter (UKF), and then to compare the posterior variance reductions $(P - P_{\\text{post}})/P$ achieved by each method.\n\nThe fundamental base is Bayes’ rule:\n$$\np(x \\mid y) \\propto p(y \\mid x) p(x).\n$$\nIn linear-Gaussian models, the exact posterior remains Gaussian and can be found via the Kalman filter. For nonlinear observation functions $h(x)$, the EKF and UKF provide Gaussian approximations to the posterior.\n\nExtended Kalman Filter (EKF) measurement update derives from local linearization of the nonlinear observation function. At the prior mean $m$, we linearize $h(x)$ as\n$$\nh(x) \\approx h(m) + H (x - m),\n$$\nwhere $H$ is the Jacobian (for scalar $x$, the derivative) evaluated at $m$,\n$$\nH = \\frac{d}{dx} \\tanh(x) \\bigg|_{x=m} = 1 - \\tanh^2(m).\n$$\nUnder this local linear model and Gaussian noise, the measurement prediction is $h(m)$ with innovation $v = y - h(m)$. The scalar innovation covariance is\n$$\nS = H P H + R,\n$$\nand the scalar Kalman gain is\n$$\nK = \\frac{P H}{S}.\n$$\nThe posterior mean and variance are then\n$$\nm_{\\text{post,EKF}} = m + K v,\n\\quad\nP_{\\text{post,EKF}} = P - K H P.\n$$\nThe variance reduction ratio for the EKF is\n$$\nr_{\\text{EKF}} = \\frac{P - P_{\\text{post,EKF}}}{P}.\n$$\n\nUnscented Kalman Filter (UKF) uses the Unscented Transform to approximate the mean and covariance of the measurement by propagating deterministically chosen sigma points through the nonlinearity. For a scalar state ($n = 1$), choose parameters $\\alpha = 0.3$, $\\beta = 2$, and $\\kappa = 0$. Define\n$$\n\\lambda = \\alpha^2 (n + \\kappa) - n,\n\\quad\nc = n + \\lambda.\n$$\nConstruct sigma points:\n$$\nX_0 = m, \\quad X_1 = m + \\sqrt{c P}, \\quad X_2 = m - \\sqrt{c P}.\n$$\nDefine weights for mean and covariance:\n$$\nW^{(m)}_0 = \\frac{\\lambda}{c}, \\quad W^{(c)}_0 = \\frac{\\lambda}{c} + (1 - \\alpha^2 + \\beta),\n\\quad\nW^{(m)}_i = W^{(c)}_i = \\frac{1}{2c} \\ \\text{for} \\ i \\in \\{1,2\\}.\n$$\nPropagate sigma points through the measurement function:\n$$\nY_i = h(X_i) = \\tanh(X_i).\n$$\nCompute the predicted measurement mean and covariance:\n$$\n\\hat{y} = \\sum_{i=0}^{2} W^{(m)}_i Y_i,\n\\quad\nS = \\sum_{i=0}^{2} W^{(c)}_i \\left(Y_i - \\hat{y}\\right)^2 + R.\n$$\nCompute the cross-covariance between state and measurement:\n$$\nC = \\sum_{i=0}^{2} W^{(c)}_i \\left(X_i - m\\right)\\left(Y_i - \\hat{y}\\right).\n$$\nThe scalar Kalman gain, posterior mean, and posterior variance are\n$$\nK = \\frac{C}{S},\n\\quad\nm_{\\text{post,UKF}} = m + K \\left(y - \\hat{y}\\right),\n\\quad\nP_{\\text{post,UKF}} = P - K S K.\n$$\nThe variance reduction ratio for the UKF is\n$$\nr_{\\text{UKF}} = \\frac{P - P_{\\text{post,UKF}}}{P}.\n$$\n\nWe evaluate both methods on a deterministic test suite covering typical and edge conditions relevant to nonlinear neural observation models:\n- A happy-path case with moderate nonlinearity near $m = 0.2$,\n- A saturation boundary case at $m = 3.0$ where $h'(m)$ is small,\n- An edge case with extremely low measurement noise $R = 10^{-6}$,\n- An edge case with very high measurement noise $R = 10.0$,\n- A boundary case with very small prior variance $P = 10^{-4}$.\n\nFor each test case, the measurement $y$ is set deterministically as $y = h(m) + \\delta$ with $\\delta$ specified to avoid randomness:\n- Case $1$: $(m, P, R, y) = (0.2, 0.5, 0.1, \\tanh(0.2) + 0.05)$,\n- Case $2$: $(m, P, R, y) = (3.0, 0.5, 0.1, \\tanh(3.0) - 0.02)$,\n- Case $3$: $(m, P, R, y) = (-1.0, 0.3, 10^{-6}, \\tanh(-1.0) + 0.0)$,\n- Case $4$: $(m, P, R, y) = (0.0, 1.0, 10.0, \\tanh(0.0) + 0.5)$,\n- Case $5$: $(m, P, R, y) = (0.5, 10^{-4}, 0.1, \\tanh(0.5) + 0.02)$.\n\nAlgorithmic steps to implement for each case:\n$1.$ Compute $r_{\\text{EKF}}$ using the EKF linearization and scalar Kalman update.\n$2.$ Compute $r_{\\text{UKF}}$ using the Unscented Transform with the specified parameters and the scalar Kalman update.\n$3.$ Report the pair $[r_{\\text{EKF}}, r_{\\text{UKF}}]$.\n\nFinally, aggregate all results into a single list of lists and print them as a single line in the exact required format $[[r_{1,\\text{EKF}}, r_{1,\\text{UKF}}],[r_{2,\\text{EKF}}, r_{2,\\text{UKF}}],\\dots]$, where each $r$ is a decimal number.",
            "answer": "```python\nimport numpy as np\n\ndef h(x):\n    # Nonlinear observation function: tanh\n    return np.tanh(x)\n\ndef dh_dx_at(m):\n    # Derivative of tanh is 1 - tanh(m)^2\n    t = np.tanh(m)\n    return 1.0 - t * t\n\ndef ekf_variance_reduction(m, P, R, y):\n    # EKF single measurement update in 1D\n    H = dh_dx_at(m)\n    y_hat = h(m)\n    v = y - y_hat  # innovation\n    S = H * P * H + R\n    K = (P * H) / S\n    P_post = P - K * H * P\n    # Variance reduction ratio\n    reduction = (P - P_post) / P\n    return float(reduction)\n\ndef ukf_variance_reduction(m, P, R, y, alpha=0.3, beta=2.0, kappa=0.0):\n    # UKF single measurement update in 1D\n    n = 1\n    lam = alpha**2 * (n + kappa) - n\n    c = n + lam\n    # Sigma points\n    gamma = np.sqrt(c) * np.sqrt(P)\n    X = np.array([m, m + gamma, m - gamma])\n    # Weights\n    Wm = np.array([lam / c, 1.0 / (2.0 * c), 1.0 / (2.0 * c)])\n    Wc = np.array([lam / c + (1.0 - alpha**2 + beta), 1.0 / (2.0 * c), 1.0 / (2.0 * c)])\n    # Propagate through measurement\n    Y = h(X)\n    y_hat = np.sum(Wm * Y)\n    # Measurement covariance\n    S = np.sum(Wc * (Y - y_hat)**2) + R\n    # Cross covariance\n    C = np.sum(Wc * (X - m) * (Y - y_hat))\n    # Kalman gain and posterior variance\n    K = C / S\n    P_post = P - K * S * K  # scalar case\n    reduction = (P - P_post) / P\n    return float(reduction)\n\ndef solve():\n    # Define deterministic test cases: (m, P, R, y)\n    test_cases = [\n        # Happy-path case near moderate nonlinearity\n        (0.2, 0.5, 0.1, np.tanh(0.2) + 0.05),\n        # Saturation boundary case with large prior mean\n        (3.0, 0.5, 0.1, np.tanh(3.0) - 0.02),\n        # Very low measurement noise edge case\n        (-1.0, 0.3, 1e-6, np.tanh(-1.0) + 0.0),\n        # Very high measurement noise edge case\n        (0.0, 1.0, 10.0, np.tanh(0.0) + 0.5),\n        # Small prior variance boundary case\n        (0.5, 1e-4, 0.1, np.tanh(0.5) + 0.02),\n    ]\n\n    results = []\n    for m, P, R, y in test_cases:\n        r_ekf = ekf_variance_reduction(m, P, R, y)\n        r_ukf = ukf_variance_reduction(m, P, R, y, alpha=0.3, beta=2.0, kappa=0.0)\n        results.append([r_ekf, r_ukf])\n\n    # Final print statement in the exact required format.\n    # Produce a single line with list of lists of decimal numbers.\n    print(str(results))\n\nsolve()\n```"
        },
        {
            "introduction": "A central challenge in building scientific models is selecting the appropriate level of complexity—for instance, how many latent dimensions should a neural state-space model have? This exercise tackles this question by focusing on cross-validation, a powerful technique for assessing how well a model will generalize to new data. The challenge lies in correctly applying this technique to time-series data, where temporal dependencies must be handled carefully to avoid misleading results. This practice will guide you through designing a methodologically sound procedure to compare models and select the one with the best predictive power. ",
            "id": "4022517",
            "problem": "Consider multi-neuron spike count data aggregated in time bins of width $\\Delta$ seconds. Let $y_{t} \\in \\mathbb{N}^{N}$ denote the vector of counts from $N$ neurons at time index $t \\in \\{1,\\dots,T\\}$, and let $x_{t} \\in \\mathbb{R}^{k}$ be a latent state of dimension $k$ evolving according to linear Gaussian dynamics\n$$\nx_{t} = A x_{t-1} + w_{t}, \\quad w_{t} \\sim \\mathcal{N}(0, Q),\n$$\nwith prior $x_{1} \\sim \\mathcal{N}(m_{1}, P_{1})$. The observation model is conditionally independent across neurons given the latent state and is defined by a Generalized Linear Model (GLM) with Poisson observations,\n$$\ny_{t,n} \\mid x_{t} \\sim \\mathrm{Poisson}\\big(\\lambda_{t,n}\\big), \\quad \\lambda_{t,n} = \\exp\\big(c_{n}^{\\top} x_{t} + d_{n}\\big),\n$$\nwhere $C = [c_{1}^{\\top};\\dots;c_{N}^{\\top}] \\in \\mathbb{R}^{N \\times k}$ and $d \\in \\mathbb{R}^{N}$ are observation parameters, and $(A, Q)$ are dynamics parameters. Suppose we will fit such a state-space model for a range of candidate latent dimensions $k \\in \\{1,2,\\dots,k_{\\max}\\}$ using Expectation-Maximization (EM), yielding parameter estimates $\\hat{\\theta}_{k} = (\\hat{A}_{k}, \\hat{Q}_{k}, \\hat{C}_{k}, \\hat{d}_{k})$ for each $k$.\n\nYou are asked to propose and justify a cross-validated predictive log-likelihood criterion to choose the latent dimension $k$ that most accurately predicts held-out spikes, and to specify how to handle temporal dependence when constructing cross-validation folds. Your proposal must start from the definition of predictive distributions in state-space models, must not leak information from held-out data into training or evaluation, and must be scientifically plausible for neural spike trains.\n\nWhich of the following is the most appropriate criterion and fold construction?\n\nA. Use blocked and buffered rolling cross-validation. Partition the time axis into $K$ contiguous test blocks $\\{T_{f}\\}_{f=1}^{K}$ of equal length $B$; for each test block $T_{f}$, exclude a buffer of $L$ bins on each side from training to mitigate temporal leakage and allow the latent dynamics to mix. For each candidate $k$, fit $\\hat{\\theta}_{k}$ on the training indices $\\mathcal{I}_{\\text{train}}^{(f)} = \\{1,\\dots,T\\} \\setminus \\big(T_{f} \\cup \\text{buffer}(T_{f}, L)\\big)$. Evaluate the block’s predictive log-likelihood by the one-step-ahead predictive distribution,\n$$\n\\mathrm{PLL}_{f}(k) = \\sum_{t \\in T_{f}} \\log p\\big(y_{t} \\mid y_{1:(t-1)}^{\\text{train}}, \\hat{\\theta}_{k}\\big), \\quad p\\big(y_{t} \\mid y_{1:(t-1)}^{\\text{train}}, \\hat{\\theta}_{k}\\big) = \\int p\\big(y_{t} \\mid x_{t}, \\hat{\\theta}_{k}\\big)\\, p\\big(x_{t} \\mid y_{1:(t-1)}^{\\text{train}}, \\hat{\\theta}_{k}\\big)\\, dx_{t}.\n$$\nAggregate across folds via $\\mathrm{PLL}(k) = \\sum_{f=1}^{K} \\mathrm{PLL}_{f}(k)$ or average per bin and per neuron. Choose $k$ maximizing $\\mathrm{PLL}(k)$. For Poisson observations, approximate the integral with the Laplace approximation around the filtering mean; for Gaussian observations, the integral is closed form due to conjugacy. Set $L$ based on the latent mixing time, e.g., the smallest $L$ such that $\\lVert \\hat{A}_{k}^{L} \\rVert \\approx \\varepsilon$ for a small $\\varepsilon$.\n\nB. Randomly shuffle time bins into $K$ folds to break time dependence. For each candidate $k$, fit $\\hat{\\theta}_{k}$ on the training folds and compute the held-out log-likelihood by plugging in the smoothed posterior mean $\\hat{x}_{t}$ computed using all data (train and test) to evaluate $\\log p\\big(y_{t} \\mid \\hat{x}_{t}, \\hat{\\theta}_{k}\\big)$ at test points, then choose the $k$ with the largest average held-out log-likelihood.\n\nC. Avoid cross-validation and select $k$ by maximizing the training marginal log-likelihood $\\log p\\big(y_{1:T} \\mid \\hat{\\theta}_{k}\\big)$ penalized only by a static model-selection term such as the Akaike Information Criterion (AIC), ignoring the state evolution and temporal dependence.\n\nD. Use blocked $K$-fold without buffers. For each candidate $k$, fit $\\hat{\\theta}_{k}$ on all data except the contiguous test block, then compute the held-out log-likelihood using the two-sided smoothed posterior $p\\big(x_{t} \\mid y_{\\text{train}} \\cup y_{\\text{test}}, \\hat{\\theta}_{k}\\big)$ to evaluate $\\log p\\big(y_{t} \\mid x_{t}, \\hat{\\theta}_{k}\\big)$ at $t$ in the test block, and choose $k$ maximizing the sum over test bins.\n\nSelect the single best option and be prepared to justify your choice from first principles of state-space modeling, the definition of predictive distributions, and appropriate handling of temporal dependence in cross-validation.",
            "solution": "The problem statement poses a valid and well-defined question in computational neuroscience and time-series analysis. It describes a standard state-space model for neural spike counts (a Poisson-observation Generalized Linear Model with latent linear-Gaussian dynamics) and asks for the most appropriate cross-validation strategy to select the latent state dimension, $k$. All components of the model are clearly defined, and the objective is scientifically meaningful.\n\nThe givens are:\n-   Spike count data: $y_{t} \\in \\mathbb{N}^{N}$ for $t \\in \\{1,\\dots,T\\}$ from $N$ neurons.\n-   Latent state: $x_{t} \\in \\mathbb{R}^{k}$.\n-   State dynamics: $x_{t} = A x_{t-1} + w_{t}$, where $w_{t} \\sim \\mathcal{N}(0, Q)$.\n-   State prior: $x_{1} \\sim \\mathcal{N}(m_{1}, P_{1})$.\n-   Observation model: $y_{t,n} \\mid x_{t} \\sim \\mathrm{Poisson}\\big(\\lambda_{t,n}\\big)$, with $\\lambda_{t,n} = \\exp\\big(c_{n}^{\\top} x_{t} + d_{n}\\big)$.\n-   Parameters: $\\theta_k = (A_k, Q_k, C_k, d_k)$ for a given dimension $k$, estimated via EM to get $\\hat{\\theta}_k$.\n-   Goal: Propose a cross-validated predictive log-likelihood criterion to select $k$.\n\nThe core of the problem is to select a model parameter ($k$) based on its ability to predict unseen data. For time-series data, this requires careful handling of temporal dependencies to avoid information leakage and obtain an unbiased estimate of generalization performance.\n\nA valid procedure must satisfy three key principles:\n1.  **Preservation of Temporal Order**: The cross-validation structure must not shuffle data randomly. Test sets should, in some sense, be \"future\" to the training sets. This necessitates blocked or rolling-fold structures.\n2.  **No Information Leakage**: The model evaluation on a test point $y_t$ must only use information available up to time $t-1$. Conditioning on data $y_{t'}$ for $t' \\geq t$ (i.e., using smoothed posteriors) turns a predictive task into an interpolation task, which inflates performance metrics and leads to selecting overly complex models. The parameters $\\hat{\\theta}_k$ themselves must be trained only on the designated training data for each fold.\n3.  **Correct Predictive Distribution**: The predictive log-likelihood for an observation $y_t$ given past observations $y_{1:t-1}$ and parameters $\\theta$ is $\\log p(y_t | y_{1:t-1}, \\theta)$. For a latent variable model, this is computed by marginalizing out the latent state:\n    $$\n    p(y_t | y_{1:t-1}, \\theta) = \\int p(y_t | x_t, \\theta) p(x_t | y_{1:t-1}, \\theta) dx_t\n    $$\n    Here, $p(x_t | y_{1:t-1}, \\theta)$ is the one-step-ahead predictive posterior of the latent state, derived from the filtering distributions.\n\nWith these principles, I will evaluate each option.\n\n**Option A Evaluation**\n-   **Cross-validation scheme**: \"blocked and buffered rolling cross-validation\" is an advanced and appropriate method for time series. Blocking preserves temporal order. Using buffers of size $L$ between training and test sets is crucial for state-space models, as it mitigates the direct dependence of the state at the beginning of the test block on the state at the end of the training block. This prevents artificially high performance scores due to short-term state memory. The justification for setting $L$ based on the latent mixing time ($\\lVert \\hat{A}_{k}^{L} \\rVert \\approx \\varepsilon$) is principled.\n-   **Parameter fitting**: The parameters $\\hat{\\theta}_k$ are correctly fitted only on the training indices for each fold $\\mathcal{I}_{\\text{train}}^{(f)}$.\n-   **Evaluation metric**: The proposed metric is the one-step-ahead predictive log-likelihood, $\\mathrm{PLL}_{f}(k) = \\sum_{t \\in T_{f}} \\log p\\big(y_{t} \\mid y_{1:(t-1)}^{\\text{train}}, \\hat{\\theta}_{k}\\big)$. This correctly defines the predictive goal. The integral form provided, $\\int p\\big(y_{t} \\mid x_{t}, \\hat{\\theta}_{k}\\big)\\, p\\big(x_{t} \\mid y_{1:(t-1)}^{\\text{train}}, \\hat{\\theta}_{k}\\big)\\, dx_{t}$, is the rigorous mathematical definition of this predictive probability. It correctly uses the state's one-step-ahead predictive distribution, which is derived by filtering through the training data. There is no information leakage. The note about using the Laplace approximation for the intractable integral is a correct and practical detail for this model class.\n-   **Verdict**: This option correctly specifies a state-of-the-art, scientifically rigorous procedure for cross-validated predictive model selection in this context. **Correct**.\n\n**Option B Evaluation**\n-   **Cross-validation scheme**: \"Randomly shuffle time bins into $K$ folds to break time dependence.\" This is fundamentally incorrect. The model's purpose is to capture temporal dynamics $x_t = A x_{t-1} + w_t$. Shuffling the data makes the observations approximately independent and identically distributed (i.i.d.), destroying the very structure the model is meant to learn and predict.\n-   **Evaluation metric**: The proposal is to use the smoothed posterior mean $\\hat{x}_t$ computed using \"all data (train and test)\". This constitutes severe information leakage. The smoothed posterior $p(x_t | y_{1:T})$ is conditioned on future observations relative to $t$. Using it to \"predict\" $y_t$ is invalid. Furthermore, using a point estimate $\\hat{x}_t$ instead of marginalizing over the posterior distribution ignores uncertainty and provides a poor approximation of the log-likelihood.\n-   **Verdict**: This option is flawed in its cross-validation structure and its evaluation metric, which leaks information. **Incorrect**.\n\n**Option C Evaluation**\n-   **Cross-validation scheme**: This option explicitly \"avoid[s] cross-validation\". This contradicts the problem's request to propose a cross-validated criterion and is generally a less robust approach for model selection than out-of-sample validation.\n-   **Evaluation metric**: It proposes using an in-sample information criterion like AIC. While AIC is a valid method for model selection, it relies on asymptotic approximations and may not perform as well as direct cross-validation, especially for complex models or finite datasets. The statement about \"ignoring the state evolution and temporal dependence\" is slightly misleading, as a proper calculation of the marginal log-likelihood for AIC *would* involve the state dynamics (e.g., via the Kalman filter). However, the primary flaw is its rejection of the more robust cross-validation paradigm for a purely in-sample metric.\n-   **Verdict**: This option proposes a non-cross-validation method, failing to meet the core requirement of the problem, and is generally considered less reliable than a well-executed cross-validation. **Incorrect**.\n\n**Option D Evaluation**\n-   **Cross-validation scheme**: \"blocked $K$-fold without buffers\". This is an improvement over random shuffling (Option B) as it preserves temporal blocks. However, the lack of buffers can lead to optimistic bias in performance evaluation, as the initial states of the test block are heavily constrained by the final states of the adjacent training block.\n-   **Evaluation metric**: The critical flaw is the use of the \"two-sided smoothed posterior $p\\big(x_{t} \\mid y_{\\text{train}} \\cup y_{\\text{test}}, \\hat{\\theta}_{k}\\big)$\". This is identical in principle to the flaw in Option B. It uses data from the test set (and other future data) to infer the latent state $x_t$ which is then used to evaluate the likelihood of $y_t$. This is not a predictive measure but a measure of how well the model can explain data it has already been conditioned upon. This constitutes a direct and significant leakage of information from the test set into its own evaluation.\n-   **Verdict**: The use of a smoothed posterior for evaluation invalidates this method for assessing predictive performance. **Incorrect**.\n\nIn summary, Option A is the only one that presents a methodologically sound and rigorous approach, respecting the principles of time-series analysis, forbidding information leakage, and correctly defining the predictive likelihood. It represents the best practice for this problem.",
            "answer": "$$\\boxed{A}$$"
        }
    ]
}