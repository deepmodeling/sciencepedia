{
    "hands_on_practices": [
        {
            "introduction": "在将状态空间模型拟合到数据之前，理解模型的基本结构特性至关重要。可控性和可观测性是核心概念，它们分别决定了系统的潜在状态是否能被输入影响，以及是否能从输出中推断出来。这个练习  提供了通过系统矩阵计算这些属性的实践机会，这对于诊断模型辨识性问题和理解潜在动态与观测数据之间的关系至关重要。",
            "id": "4022537",
            "problem": "考虑一个神经元群体在不动点附近的线性时不变 (LTI) 潜状态模型，其中潜动力学源于底层生物物理过程的一阶线性化，而观测表示线性混合的发放率。离散时间状态空间模型为\n$$\nx_{t+1} = A x_t + B u_t,\\quad y_t = C x_t,\n$$\n其中 $x_t \\in \\mathbb{R}^{n}$ 是潜状态，$u_t \\in \\mathbb{R}^{m}$ 是外源输入，$y_t \\in \\mathbb{R}^{p}$ 是观测活动。矩阵 $A \\in \\mathbb{R}^{n \\times n}$、$B \\in \\mathbb{R}^{n \\times m}$ 和 $C \\in \\mathbb{R}^{p \\times n}$ 由下式给出：\n$$\nA = \\begin{pmatrix}\n0  1  0 \\\\\n0  0  0 \\\\\n0  0  0\n\\end{pmatrix},\\quad\nB = \\begin{pmatrix}\n0 \\\\\n1 \\\\\n0\n\\end{pmatrix},\\quad\nC = \\begin{pmatrix}\n1  0  0\n\\end{pmatrix}.\n$$\n使用线性时不变系统的能控性和能观性的基本定义：由 $B$ 在 $A$ 下生成的可达（能控）子空间是 $\\{A^{k} B\\}_{k=0}^{n-1}$ 的张成空间，而在 $C$ 和 $A$ 下的不能观子空间是 $\\{C A^{k}\\}_{k=0}^{n-1}$ 的核的交集。根据这些基础，计算：\n1. 矩阵对 $(A,B)$ 的能控性矩阵的秩。\n2. 矩阵对 $(A,C)$ 的能观性矩阵的秩。\n3. 与 $(A,B,C)$ 可生成的输入-输出行为一致的最小潜维度，该维度被理解为系统能控且能观部分的维度（即传递行为 $u_t \\mapsto y_t$ 的最小实现）。\n\n将您的最终答案表示为一个行矩阵，其中按顺序包含能控性秩、能观性秩和最小潜维度。无需四舍五入。不要包含单位。",
            "solution": "问题要求分析一个给定的离散时间线性时不变 (LTI) 状态空间模型，以确定其能控性、能观性以及表示其输入-输出行为所需的最小维度。\n\n状态空间模型由以下方程定义：\n$$\nx_{t+1} = A x_t + B u_t\n$$\n$$\ny_t = C x_t\n$$\n其中状态维度为 $n=3$，输入维度为 $m=1$，输出维度为 $p=1$。矩阵如下所示：\n$$\nA = \\begin{pmatrix}\n0  1  0 \\\\\n0  0  0 \\\\\n0  0  0\n\\end{pmatrix},\\quad\nB = \\begin{pmatrix}\n0 \\\\\n1 \\\\\n0\n\\end{pmatrix},\\quad\nC = \\begin{pmatrix}\n1  0  0\n\\end{pmatrix}\n$$\n\n我们将按顺序计算这三个所求的量。\n\n1. 矩阵对 $(A, B)$ 的能控性矩阵的秩。\n\n根据问题定义，能控子空间是能控性矩阵 $\\mathcal{C}$ 的列向量的张成空间。对于状态维度为 $n=3$ 的系统，该矩阵构造如下：\n$$\n\\mathcal{C} = \\begin{pmatrix} B  AB  A^2B \\end{pmatrix}\n$$\n首先，我们计算矩阵乘积 $AB$ 和 $A^2B$。\n$$\nAB = \\begin{pmatrix}\n0  1  0 \\\\\n0  0  0 \\\\\n0  0  0\n\\end{pmatrix}\n\\begin{pmatrix}\n0 \\\\\n1 \\\\\n0\n\\end{pmatrix}\n= \\begin{pmatrix}\n1 \\\\\n0 \\\\\n0\n\\end{pmatrix}\n$$\n为了计算 $A^2B$，我们首先求出 $A^2$：\n$$\nA^2 = A \\cdot A = \\begin{pmatrix}\n0  1  0 \\\\\n0  0  0 \\\\\n0  0  0\n\\end{pmatrix}\n\\begin{pmatrix}\n0  1  0 \\\\\n0  0  0 \\\\\n0  0  0\n\\end{pmatrix}\n= \\begin{pmatrix}\n0  0  0 \\\\\n0  0  0 \\\\\n0  0  0\n\\end{pmatrix} = \\mathbf{0}\n$$\n由于 $A^2$ 是零矩阵，因此 $A^2B = \\mathbf{0} \\cdot B = \\begin{pmatrix} 0 \\\\ 0 \\\\ 0 \\end{pmatrix}$。\n现在，我们构造能控性矩阵 $\\mathcal{C}$：\n$$\n\\mathcal{C} = \\begin{pmatrix}\n0  1  0 \\\\\n1  0  0 \\\\\n0  0  0\n\\end{pmatrix}\n$$\n矩阵的秩是线性无关的列（或行）的数量。前两列 $\\begin{pmatrix} 0  1  0 \\end{pmatrix}^T$ 和 $\\begin{pmatrix} 1  0  0 \\end{pmatrix}^T$ 是正交的，因此线性无关。第三列是零向量，与其他向量线性相关。因此，能控性矩阵的秩为 $2$。\n$$\n\\text{rank}(\\mathcal{C}) = 2\n$$\n\n2. 矩阵对 $(A, C)$ 的能观性矩阵的秩。\n\n不能观子空间被定义为 $k=0, \\dots, n-1$ 时 $CA^k$ 的核的交集。这等价于能观性矩阵 $\\mathcal{O}$ 的零空间，对于 $n=3$，该矩阵为：\n$$\n\\mathcal{O} = \\begin{pmatrix} C \\\\ CA \\\\ CA^2 \\end{pmatrix}\n$$\n我们计算矩阵乘积 $CA$ 和 $CA^2$。\n$$\nCA = \\begin{pmatrix}\n1  0  0\n\\end{pmatrix}\n\\begin{pmatrix}\n0  1  0 \\\\\n0  0  0 \\\\\n0  0  0\n\\end{pmatrix}\n= \\begin{pmatrix}\n0  1  0\n\\end{pmatrix}\n$$\n由于 $A^2 = \\mathbf{0}$，我们有：\n$$\nCA^2 = C \\cdot \\mathbf{0} = \\begin{pmatrix} 0  0  0 \\end{pmatrix}\n$$\n现在，我们构造能观性矩阵 $\\mathcal{O}$：\n$$\n\\mathcal{O} = \\begin{pmatrix}\n1  0  0 \\\\\n0  1  0 \\\\\n0  0  0\n\\end{pmatrix}\n$$\n该矩阵的秩是线性无关的行的数量。前两行 $\\begin{pmatrix} 1  0  0 \\end{pmatrix}$ 和 $\\begin{pmatrix} 0  1  0 \\end{pmatrix}$ 是正交的，因此线性无关。第三行是零向量。该矩阵已经处于行阶梯形，有两个主元。因此，能观性矩阵的秩为 $2$。\n$$\n\\text{rank}(\\mathcal{O}) = 2\n$$\n\n3. 与输入-输出行为一致的最小潜维度。\n\n这个维度被定义为系统能控且能观部分的维度。这可以通过对状态空间进行 Kalman 分解来找到。状态空间 $\\mathbb{R}^n$ 可以分解为四个子空间的直和：能控且能观 ($S_{co}$)、能控但不能观 ($S_{c\\bar{o}}$)、不能控但能观 ($S_{\\bar{c}o}$) 以及不能控且不能观 ($S_{\\bar{c}\\bar{o}}$)。最小维度对应于 $\\dim(S_{co})$。\n\n能控子空间是能控性矩阵的像，即 $\\mathcal{R} = \\text{Im}(\\mathcal{C})$。根据我们在第 1 部分的计算：\n$$\n\\mathcal{R} = \\text{span}\\left\\{\\begin{pmatrix} 0 \\\\ 1 \\\\ 0 \\end{pmatrix}, \\begin{pmatrix} 1 \\\\ 0 \\\\ 0 \\end{pmatrix}\\right\\} = \\text{span}\\{e_1, e_2\\}\n$$\n其中 $e_1, e_2, e_3$ 是 $\\mathbb{R}^3$ 中的标准基向量。能控子空间的维度是 $\\dim(\\mathcal{R}) = \\text{rank}(\\mathcal{C}) = 2$。\n\n不能观子空间是能观性矩阵的零空间，即 $\\mathcal{N} = \\text{Ker}(\\mathcal{O})$。我们求解 $\\mathcal{O}x = 0$：\n$$\n\\begin{pmatrix}\n1  0  0 \\\\\n0  1  0 \\\\\n0  0  0\n\\end{pmatrix}\n\\begin{pmatrix} x_1 \\\\ x_2 \\\\ x_3 \\end{pmatrix} = \\begin{pmatrix} 0 \\\\ 0 \\\\ 0 \\end{pmatrix}\n$$\n这得到 $x_1=0$ 和 $x_2=0$，而 $x_3$ 是一个自由变量。因此，不能观子空间为：\n$$\n\\mathcal{N} = \\text{span}\\left\\{\\begin{pmatrix} 0 \\\\ 0 \\\\ 1 \\end{pmatrix}\\right\\} = \\text{span}\\{e_3\\}\n$$\n能观子空间，记为 $\\mathcal{O}_s$，是不能观子空间 $\\mathcal{N}$ 的正交补，或者等价地，是 $\\mathcal{O}^T$ 的像。\n$$\n\\mathcal{O}_s = \\mathcal{N}^{\\perp} = (\\text{span}\\{e_3\\})^{\\perp} = \\text{span}\\{e_1, e_2\\}\n$$\n 能观子空间的维度是 $\\dim(\\mathcal{O}_s) = \\text{rank}(\\mathcal{O}) = 2$。\n\n能控且能观子空间 $S_{co}$ 是能控子空间 $\\mathcal{R}$ 和能观子空间 $\\mathcal{O}_s$ 的交集：\n$$\nS_{co} = \\mathcal{R} \\cap \\mathcal{O}_s = \\text{span}\\{e_1, e_2\\} \\cap \\text{span}\\{e_1, e_2\\} = \\text{span}\\{e_1, e_2\\}\n$$\n这个子空间的维度是基向量的数量，即 $2$。\n\n另外，最小维度是系统传递函数 $H(z) = C(zI - A)^{-1}B$ 的阶数。我们计算 $(zI - A)^{-1}$：\n$$\nzI - A = \\begin{pmatrix} z  -1  0 \\\\ 0  z  0 \\\\ 0  0  z \\end{pmatrix}\n$$\n$$\n(zI - A)^{-1} = \\frac{1}{\\det(zI-A)} \\text{adj}(zI-A) = \\frac{1}{z^3} \\begin{pmatrix} z^2  z  0 \\\\ 0  z^2  0 \\\\ 0  0  z^2 \\end{pmatrix} = \\begin{pmatrix} \\frac{1}{z}  \\frac{1}{z^2}  0 \\\\ 0  \\frac{1}{z}  0 \\\\ 0  0  \\frac{1}{z} \\end{pmatrix}\n$$\n现在我们计算传递函数：\n$$\nH(z) = C (zI - A)^{-1} B = \\begin{pmatrix} 1  0  0 \\end{pmatrix} \\begin{pmatrix} \\frac{1}{z}  \\frac{1}{z^2}  0 \\\\ 0  \\frac{1}{z}  0 \\\\ 0  0  \\frac{1}{z} \\end{pmatrix} \\begin{pmatrix} 0 \\\\ 1 \\\\ 0 \\end{pmatrix}\n$$\n$$\nH(z) = \\begin{pmatrix} \\frac{1}{z}  \\frac{1}{z^2}  0 \\end{pmatrix} \\begin{pmatrix} 0 \\\\ 1 \\\\ 0 \\end{pmatrix} = \\frac{1}{z^2}\n$$\n传递函数是 $H(z) = z^{-2}$。这是一个二阶系统。该系统的最小实现维度为 $2$。这证实了从状态空间分解得到的结果。\n\n所求的三个值是：\n1. 能控性秩：$2$\n2. 能观性秩：$2$\n3. 最小潜维度：$2$",
            "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n2  2  2\n\\end{pmatrix}\n}\n$$"
        },
        {
            "introduction": "神经活动通常通过非线性函数与潜在状态相关联，这需要使用近似推断方法。扩展卡尔曼滤波器（EKF）和无迹卡尔曼滤波器（UKF）是两种常用的算法，但它们处理非线性的方式不同——EKF进行线性化，而UKF使用确定性采样方法。这个编程练习  通过让你为一个常见的神经观测模型实现这两种滤波器，提供了一个直接的实践比较，有助于建立对它们性能差异的直观理解，尤其是在强非线性情况下。",
            "id": "4022569",
            "problem": "考虑一个适用于神经数据分析的非线性状态观测设定中的单步测量更新。设潜在神经状态为标量 $x \\in \\mathbb{R}$，其高斯先验为 $x \\sim \\mathcal{N}(m, P)$。观测值 $y \\in \\mathbb{R}$ 由一个饱和非线性加上噪声生成，$y = h(x) + \\varepsilon$，其中 $h(x) = \\tanh(x)$ 且 $\\varepsilon \\sim \\mathcal{N}(0, R)$。目标是使用扩展卡尔曼滤波器 (EKF) 和无迹卡尔曼滤波器 (UKF) 实现单步后验更新，并比较两种方法实现的后验方差减小量。\n\nEKF 从基本贝叶斯原理出发，构建观测模型的局部线性近似并应用高斯更新。UKF 为先验构建 sigma 点，并将这些点通过非线性观测函数进行传播，以近似测量的均值和协方差。使用无迹变换参数 $\\alpha = 0.3$，$\\beta = 2$ 和 $\\kappa = 0$。\n\n你的程序必须为每个测试用例计算 EKF 和 UKF 更新产生的后验方差，然后报告每种方法的方差减小率，其定义为 $(P - P_{\\text{post}})/P$，其中 $P$ 是先验方差，$P_{\\text{post}}$ 是相应滤波器得出的后验方差。\n\n使用以下参数集测试套件，为 EKF 和 UKF 实现无任何随机性的更新，其中每个测试用例指定为 $(m, P, R, y)$：\n\n- 中等非线性附近的正常路径用例：$(0.2, 0.5, 0.1, \\tanh(0.2) + 0.05)$。\n- 大先验均值的饱和边界用例：$(3.0, 0.5, 0.1, \\tanh(3.0) - 0.02)$。\n- 极低测量噪声的边缘用例：$(-1.0, 0.3, 10^{-6}, \\tanh(-1.0) + 0.0)$。\n- 极高测量噪声的边缘用例：$(0.0, 1.0, 10.0, \\tanh(0.0) + 0.5)$。\n- 小先验方差的边界用例：$(0.5, 10^{-4}, 0.1, \\tanh(0.5) + 0.02)$。\n\n不涉及物理单位；将所有量视为无量纲实数。如果存在角度，必须以弧度为单位进行解释，但本问题仅需要实值标量。\n\n对于每个测试用例，计算两个十进制数：EKF 方差减小率和 UKF 方差减小率。你的程序应生成单行输出，包含一个用方括号括起来的逗号分隔列表形式的结果，其中每个元素是对应于该测试用例的 $[\\text{EKF 减小率}, \\text{UKF 减小率}]$ 的双元素列表。例如，输出格式必须类似于 $[[r_{1,\\text{EKF}}, r_{1,\\text{UKF}}],[r_{2,\\text{EKF}}, r_{2,\\text{UKF}}],\\dots]$，其中每个 $r$ 是一个十进制数。",
            "solution": "我们从状态空间模型的贝叶斯滤波原理开始。潜在标量状态 $x \\in \\mathbb{R}$ 具有高斯先验 $x \\sim \\mathcal{N}(m, P)$，其先验均值为 $m$，先验方差为 $P$。测量模型为 $y = h(x) + \\varepsilon$，其中 $h(x) = \\tanh(x)$ 表示一个饱和非线性，通常用作神经元发放率非线性的代理，而 $\\varepsilon \\sim \\mathcal{N}(0, R)$ 是方差为 $R$ 的高斯观测噪声。单次测量更新的目标是通过扩展卡尔曼滤波器 (EKF) 或无迹卡尔曼滤波器 (UKF) 生成一个保持高斯分布的近似后验 $p(x \\mid y)$，然后比较每种方法实现的后验方差减小率 $(P - P_{\\text{post}})/P$。\n\n基本依据是贝叶斯法则：\n$$\np(x \\mid y) \\propto p(y \\mid x) p(x).\n$$\n在线性高斯模型中，精确后验分布保持为高斯分布，并可通过卡尔曼滤波器求得。对于非线性观测函数 $h(x)$，EKF 和 UKF 提供了对后验分布的高斯近似。\n\n扩展卡尔曼滤波器 (EKF) 的测量更新源于对非线性观测函数的局部线性化。在先验均值 $m$ 处，我们将 $h(x)$ 线性化为\n$$\nh(x) \\approx h(m) + H (x - m),\n$$\n其中 $H$ 是在 $m$ 处求值的雅可比矩阵（对于标量 $x$，即为导数），\n$$\nH = \\frac{d}{dx} \\tanh(x) \\bigg|_{x=m} = 1 - \\tanh^2(m).\n$$\n在此局部线性模型和高斯噪声下，测量预测值为 $h(m)$，新息为 $v = y - h(m)$。标量新息协方差为\n$$\nS = H P H + R,\n$$\n标量卡尔曼增益为\n$$\nK = \\frac{P H}{S}.\n$$\n后验均值和方差则为\n$$\nm_{\\text{post,EKF}} = m + K v,\n\\quad\nP_{\\text{post,EKF}} = P - K H P.\n$$\nEKF 的方差减小率为\n$$\nr_{\\text{EKF}} = \\frac{P - P_{\\text{post,EKF}}}{P}.\n$$\n\n无迹卡尔曼滤波器 (UKF) 使用无迹变换，通过将确定性选择的 sigma 点在非线性函数中传播，来近似测量的均值和协方差。对于标量状态（$n=1$），选择参数 $\\alpha = 0.3$，$\\beta = 2$ 和 $\\kappa = 0$。定义\n$$\n\\lambda = \\alpha^2 (n + \\kappa) - n,\n\\quad\nc = n + \\lambda.\n$$\n构建 sigma 点：\n$$\nX_0 = m, \\quad X_1 = m + \\sqrt{c P}, \\quad X_2 = m - \\sqrt{c P}.\n$$\n定义均值和协方差的权重：\n$$\nW^{(m)}_0 = \\frac{\\lambda}{c}, \\quad W^{(c)}_0 = \\frac{\\lambda}{c} + (1 - \\alpha^2 + \\beta),\n\\quad\nW^{(m)}_i = W^{(c)}_i = \\frac{1}{2c} \\ \\text{for} \\ i \\in \\{1,2\\}.\n$$\n将 sigma 点通过测量函数传播：\n$$\nY_i = h(X_i) = \\tanh(X_i).\n$$\n计算预测的测量均值和协方差：\n$$\n\\hat{y} = \\sum_{i=0}^{2} W^{(m)}_i Y_i,\n\\quad\nS = \\sum_{i=0}^{2} W^{(c)}_i \\left(Y_i - \\hat{y}\\right)^2 + R.\n$$\n计算状态与测量之间的互协方差：\n$$\nC = \\sum_{i=0}^{2} W^{(c)}_i \\left(X_i - m\\right)\\left(Y_i - \\hat{y}\\right).\n$$\n标量卡尔曼增益、后验均值和后验方差为\n$$\nK = \\frac{C}{S},\n\\quad\nm_{\\text{post,UKF}} = m + K \\left(y - \\hat{y}\\right),\n\\quad\nP_{\\text{post,UKF}} = P - K S K.\n$$\nUKF 的方差减小率为\n$$\nr_{\\text{UKF}} = \\frac{P - P_{\\text{post,UKF}}}{P}.\n$$\n\n我们在一个确定性测试套件上评估这两种方法，该套件涵盖了与非线性神经观测模型相关的典型和边缘条件：\n- 靠近 $m=0.2$ 的中等非线性度的正常路径用例，\n- 在 $m=3.0$ 处的饱和边界用例，此时 $h'(m)$ 很小，\n- 测量噪声极低 $R = 10^{-6}$ 的边缘用例，\n- 测量噪声极高 $R = 10.0$ 的边缘用例，\n- 先验方差极小 $P = 10^{-4}$ 的边界用例。\n\n对于每个测试用例，测量值 $y$ 被确定性地设置为 $y = h(m) + \\delta$，其中 $\\delta$ 是为避免随机性而指定的：\n- 用例 1: $(m, P, R, y) = (0.2, 0.5, 0.1, \\tanh(0.2) + 0.05)$，\n- 用例 2: $(m, P, R, y) = (3.0, 0.5, 0.1, \\tanh(3.0) - 0.02)$，\n- 用例 3: $(m, P, R, y) = (-1.0, 0.3, 10^{-6}, \\tanh(-1.0) + 0.0)$，\n- 用例 4: $(m, P, R, y) = (0.0, 1.0, 10.0, \\tanh(0.0) + 0.5)$，\n- 用例 5: $(m, P, R, y) = (0.5, 10^{-4}, 0.1, \\tanh(0.5) + 0.02)$。\n\n每个用例的算法实现步骤：\n1. 使用 EKF 线性化和标量卡尔曼更新计算 $r_{\\text{EKF}}$。\n2. 使用具有指定参数的无迹变换和标量卡尔曼更新计算 $r_{\\text{UKF}}$。\n3. 报告配对 $[r_{\\text{EKF}}, r_{\\text{UKF}}]$。\n\n最后，将所有结果聚合成一个列表的列表，并以确切的所需格式 $[[r_{1,\\text{EKF}}, r_{1,\\text{UKF}}],[r_{2,\\text{EKF}}, r_{2,\\text{UKF}}],\\dots]$ 单行打印，其中每个 $r$ 是一个十进制数。",
            "answer": "```python\nimport numpy as np\n\ndef h(x):\n    # Nonlinear observation function: tanh\n    return np.tanh(x)\n\ndef dh_dx_at(m):\n    # Derivative of tanh is 1 - tanh(m)^2\n    t = np.tanh(m)\n    return 1.0 - t * t\n\ndef ekf_variance_reduction(m, P, R, y):\n    # EKF single measurement update in 1D\n    H = dh_dx_at(m)\n    y_hat = h(m)\n    v = y - y_hat  # innovation\n    S = H * P * H + R\n    K = (P * H) / S\n    P_post = P - K * H * P\n    # Variance reduction ratio\n    reduction = (P - P_post) / P\n    return float(reduction)\n\ndef ukf_variance_reduction(m, P, R, y, alpha=0.3, beta=2.0, kappa=0.0):\n    # UKF single measurement update in 1D\n    n = 1\n    lam = alpha**2 * (n + kappa) - n\n    c = n + lam\n    # Sigma points\n    gamma = np.sqrt(c) * np.sqrt(P)\n    X = np.array([m, m + gamma, m - gamma])\n    # Weights\n    Wm = np.array([lam / c, 1.0 / (2.0 * c), 1.0 / (2.0 * c)])\n    Wc = np.array([lam / c + (1.0 - alpha**2 + beta), 1.0 / (2.0 * c), 1.0 / (2.0 * c)])\n    # Propagate through measurement\n    Y = h(X)\n    y_hat = np.sum(Wm * Y)\n    # Measurement covariance\n    S = np.sum(Wc * (Y - y_hat)**2) + R\n    # Cross covariance\n    C = np.sum(Wc * (X - m) * (Y - y_hat))\n    # Kalman gain and posterior variance\n    K = C / S\n    P_post = P - K * S * K  # scalar case\n    reduction = (P - P_post) / P\n    return float(reduction)\n\ndef solve():\n    # Define deterministic test cases: (m, P, R, y)\n    test_cases = [\n        # Happy-path case near moderate nonlinearity\n        (0.2, 0.5, 0.1, np.tanh(0.2) + 0.05),\n        # Saturation boundary case with large prior mean\n        (3.0, 0.5, 0.1, np.tanh(3.0) - 0.02),\n        # Very low measurement noise edge case\n        (-1.0, 0.3, 1e-6, np.tanh(-1.0) + 0.0),\n        # Very high measurement noise edge case\n        (0.0, 1.0, 10.0, np.tanh(0.0) + 0.5),\n        # Small prior variance boundary case\n        (0.5, 1e-4, 0.1, np.tanh(0.5) + 0.02),\n    ]\n\n    results = []\n    for m, P, R, y in test_cases:\n        r_ekf = ekf_variance_reduction(m, P, R, y)\n        r_ukf = ukf_variance_reduction(m, P, R, y, alpha=0.3, beta=2.0, kappa=0.0)\n        results.append([r_ekf, r_ukf])\n\n    # Final print statement in the exact required format.\n    # Produce a single line with list of lists of decimal numbers.\n    print(str(results))\n\nsolve()\n```"
        },
        {
            "introduction": "应用状态空间模型的一个关键挑战是选择合适的模型复杂度，例如潜在状态的维度。模型泛化到新的、未见过数据的能力是评估的黄金标准，而交叉验证是评估这一能力的主要工具。这个实践问题  指导你为时间序列神经数据设计一个方法论上合理的交叉验证程序，迫使你考虑时间依赖性和信息泄露等关键问题，以确保对预测性能进行无偏评估。",
            "id": "4022517",
            "problem": "考虑在宽度为 $\\Delta$ 秒的时间窗内聚合的多神经元脉冲计数数据。令 $y_{t} \\in \\mathbb{N}^{N}$ 表示在时间索引 $t \\in \\{1,\\dots,T\\}$ 时来自 $N$ 个神经元的计数向量，令 $x_{t} \\in \\mathbb{R}^{k}$ 是一个维度为 $k$ 的潜在状态，其根据线性高斯动态演化\n$$\nx_{t} = A x_{t-1} + w_{t}, \\quad w_{t} \\sim \\mathcal{N}(0, Q),\n$$\n先验为 $x_{1} \\sim \\mathcal{N}(m_{1}, P_{1})$。观测模型在给定潜在状态的条件下，在神经元之间是条件独立的，并由一个具有泊松观测的广义线性模型 (GLM) 定义，\n$$\ny_{t,n} \\mid x_{t} \\sim \\mathrm{Poisson}\\big(\\lambda_{t,n}\\big), \\quad \\lambda_{t,n} = \\exp\\big(c_{n}^{\\top} x_{t} + d_{n}\\big),\n$$\n其中 $C = [c_{1}^{\\top};\\dots;c_{N}^{\\top}] \\in \\mathbb{R}^{N \\times k}$ 和 $d \\in \\mathbb{R}^{N}$ 是观测参数，而 $(A, Q)$ 是动态参数。假设我们将使用期望最大化 (EM) 算法，对一系列候选的潜在维度 $k \\in \\{1,2,\\dots,k_{\\max}\\}$ 拟合这样一个状态空间模型，从而对每个 $k$ 得到参数估计 $\\hat{\\theta}_{k} = (\\hat{A}_{k}, \\hat{Q}_{k}, \\hat{C}_{k}, \\hat{d}_{k})$。\n\n要求您提出并论证一个交叉验证的预测对数似然准则，用以选择能够最准确预测留出脉冲的潜在维度 $k$，并具体说明在构建交叉验证折时如何处理时间依赖性。您的提议必须从状态空间模型中预测分布的定义出发，不得将留出数据中的信息泄露到训练或评估中，并且对于神经脉冲序列必须是科学上合理的。\n\n以下哪项是最合适的准则和折的构建方法？\n\nA. 使用分块和带缓冲区的滚动交叉验证。将时间轴划分为 $K$ 个长度相等的连续测试块 $\\{T_{f}\\}_{f=1}^{K}$；对于每个测试块 $T_{f}$，从训练中排除其两侧大小为 $L$ 个时间窗的缓冲区，以减轻时间泄露并允许潜在动态混合。对于每个候选的 $k$，在训练索引 $\\mathcal{I}_{\\text{train}}^{(f)} = \\{1,\\dots,T\\} \\setminus \\big(T_{f} \\cup \\text{buffer}(T_{f}, L)\\big)$ 上拟合 $\\hat{\\theta}_{k}$。通过单步预测分布评估该块的预测对数似然，\n$$\n\\mathrm{PLL}_{f}(k) = \\sum_{t \\in T_{f}} \\log p\\big(y_{t} \\mid y_{1:(t-1)}^{\\text{train}}, \\hat{\\theta}_{k}\\big), \\quad p\\big(y_{t} \\mid y_{1:(t-1)}^{\\text{train}}, \\hat{\\theta}_{k}\\big) = \\int p\\big(y_{t} \\mid x_{t}, \\hat{\\theta}_{k}\\big)\\, p\\big(x_{t} \\mid y_{1:(t-1)}^{\\text{train}}, \\hat{\\theta}_{k}\\big)\\, dx_{t}.\n$$\n通过 $\\mathrm{PLL}(k) = \\sum_{f=1}^{K} \\mathrm{PLL}_{f}(k)$ 或按每个时间窗和每个神经元取平均值，对所有折进行聚合。选择使 $\\mathrm{PLL}(k)$ 最大化的 $k$。对于泊松观测，使用滤波均值周围的拉普拉斯近似来近似积分；对于高斯观测，由于共轭性，积分为闭式解。根据潜在混合时间设置 $L$，例如，对于一个小的 $\\varepsilon$，使得 $\\lVert \\hat{A}_{k}^{L} \\rVert \\approx \\varepsilon$ 的最小 $L$。\n\nB. 将时间窗随机打乱成 $K$ 折以打破时间依赖性。对于每个候选的 $k$，在训练折上拟合 $\\hat{\\theta}_{k}$，并通过代入使用所有数据（训练和测试）计算出的平滑后验均值 $\\hat{x}_{t}$ 来计算留出对数似然，以评估测试点上的 $\\log p\\big(y_{t} \\mid \\hat{x}_{t}, \\hat{\\theta}_{k}\\big)$，然后选择具有最大平均留出对数似然的 $k$。\n\nC. 避免交叉验证，并通过最大化仅由静态模型选择项（如赤池信息准则 (Akaike Information Criterion, AIC)）惩罚的训练边际对数似然 $\\log p\\big(y_{1:T} \\mid \\hat{\\theta}_{k}\\big)$ 来选择 $k$，忽略状态演化和时间依赖性。\n\nD. 使用无缓冲区的分块 $K$ 折交叉验证。对于每个候选的 $k$，在除连续测试块外的所有数据上拟合 $\\hat{\\theta}_{k}$，然后使用双边平滑后验 $p\\big(x_{t} \\mid y_{\\text{train}} \\cup y_{\\text{test}}, \\hat{\\theta}_{k}\\big)$ 来评估测试块中 $t$ 处的 $\\log p\\big(y_{t} \\mid x_{t}, \\hat{\\theta}_{k}\\big)$，并选择使测试时间窗总和最大化的 $k$。\n\n选择唯一的最佳选项，并准备好从状态空间建模的第一性原理、预测分布的定义以及交叉验证中对时间依赖性的适当处理来证明您的选择。",
            "solution": "问题陈述提出了一个在计算神经科学和时间序列分析领域中有效且定义明确的问题。它描述了一个用于神经脉冲计数的标准状态空间模型（一个具有潜在线性高斯动态的泊松观测广义线性模型），并要求选择最合适的交叉验证策略来选择潜在状态维度 $k$。模型的所有组成部分都得到了清晰的定义，且目标具有科学意义。\n\n已知条件如下：\n-   脉冲计数数据：来自 $N$ 个神经元的 $y_{t} \\in \\mathbb{N}^{N}$，其中 $t \\in \\{1,\\dots,T\\}$。\n-   潜在状态：$x_{t} \\in \\mathbb{R}^{k}$。\n-   状态动态：$x_{t} = A x_{t-1} + w_{t}$，其中 $w_{t} \\sim \\mathcal{N}(0, Q)$。\n-   状态先验：$x_{1} \\sim \\mathcal{N}(m_{1}, P_{1})$。\n-   观测模型：$y_{t,n} \\mid x_{t} \\sim \\mathrm{Poisson}\\big(\\lambda_{t,n}\\big)$，其中 $\\lambda_{t,n} = \\exp\\big(c_{n}^{\\top} x_{t} + d_{n}\\big)$。\n-   参数：对于给定的维度 $k$，$\\theta_k = (A_k, Q_k, C_k, d_k)$，通过 EM 算法估计得到 $\\hat{\\theta}_k$。\n-   目标：提出一个交叉验证的预测对数似然准则来选择 $k$。\n\n该问题具有科学依据，提法得当且客观。它不包含任何不一致或模糊之处。因此，我将进行全面分析。\n\n问题的核心是根据模型预测未见数据的能力来选择模型参数 ($k$)。对于时间序列数据，这需要仔细处理时间依赖性，以避免信息泄露并获得对泛化性能的无偏估计。\n\n一个有效的程序必须满足三个关键原则：\n1.  **保持时间顺序**：交叉验证结构不能随机打乱数据。测试集在某种意义上应该是训练集的“未来”。这需要采用分块或滚动的折结构。\n2.  **无信息泄露**：对测试点 $y_t$ 的模型评估必须只使用截至时间 $t-1$ 可用的信息。以 $t' \\geq t$ 的数据 $y_{t'}$ 为条件（即使用平滑后验）会将预测任务变成插值任务，这会夸大性能指标，并导致选择过于复杂的模型。参数 $\\hat{\\theta}_k$ 本身必须只在每个折指定的训练数据上进行训练。\n3.  **正确的预测分布**：在给定过去观测值 $y_{1:t-1}$ 和参数 $\\theta$ 的条件下，观测值 $y_t$ 的预测对数似然为 $\\log p(y_t | y_{1:t-1}, \\theta)$。对于潜变量模型，这通过对潜在状态进行边缘化来计算：\n    $$\n    p(y_t | y_{1:t-1}, \\theta) = \\int p(y_t | x_t, \\theta) p(x_t | y_{1:t-1}, \\theta) dx_t\n    $$\n    此处，$p(x_t | y_{1:t-1}, \\theta)$ 是潜在状态的单步预测后验，由滤波分布导出。\n\n基于这些原则，我将评估每个选项。\n\n**选项 A 评估**\n-   **交叉验证方案**：“分块和带缓冲区的滚动交叉验证”是一种适用于时间序列的先进且恰当的方法。分块保留了时间顺序。在训练集和测试集之间使用大小为 $L$ 的缓冲区对于状态空间模型至关重要，因为它减轻了测试块开始时的状态对训练块结束时状态的直接依赖。这可以防止因短期状态记忆而导致人为的高性能分数。根据潜在混合时间设置 $L$（$\\lVert \\hat{A}_{k}^{L} \\rVert \\approx \\varepsilon$）的理由是符合原则的。\n-   **参数拟合**：参数 $\\hat{\\theta}_k$ 被正确地仅在每个折的训练索引 $\\mathcal{I}_{\\text{train}}^{(f)}$ 上进行拟合。\n-   **评估指标**：所提出的指标是单步预测对数似然，$\\mathrm{PLL}_{f}(k) = \\sum_{t \\in T_{f}} \\log p\\big(y_{t} \\mid y_{1:(t-1)}^{\\text{train}}, \\hat{\\theta}_{k}\\big)$。这正确定义了预测目标。所提供的积分形式，$\\int p\\big(y_{t} \\mid x_{t}, \\hat{\\theta}_{k}\\big)\\, p\\big(x_{t} \\mid y_{1:(t-1)}^{\\text{train}}, \\hat{\\theta}_{k}\\big)\\, dx_{t}$，是该预测概率的严格数学定义。它正确地使用了通过对训练数据进行滤波而得到的状态的单步预测分布。没有信息泄露。关于对难解积分使用拉普拉斯近似的说明是此类模型的一个正确且实用的细节。\n-   **结论**：此选项正确地指定了在此背景下进行交叉验证预测模型选择的最新、科学严谨的程序。**正确**。\n\n**选项 B 评估**\n-   **交叉验证方案**：“将时间窗随机打乱成 $K$ 折以打破时间依赖性。”这在根本上是错误的。模型的目的是捕捉时间动态 $x_t = A x_{t-1} + w_t$。打乱数据会使观测值近似独立同分布 (i.i.d.)，从而破坏了模型旨在学习和预测的结构。\n-   **评估指标**：该提议是使用通过“所有数据（训练和测试）”计算出的平滑后验均值 $\\hat{x}_t$。这构成了严重的信息泄露。平滑后验 $p(x_t | y_{1:T})$ 是以相对于 $t$ 的未来观测为条件的。用它来“预测”$y_t$ 是无效的。此外，使用点估计 $\\hat{x}_t$ 而不是对后验分布进行边缘化，会忽略不确定性，并提供对数似然的一个糟糕近似。\n-   **结论**：此选项的交叉验证结构及其评估指标存在缺陷，会泄露信息。**不正确**。\n\n**选项 C 评估**\n-   **交叉验证方案**：此选项明确“避免交叉验证”。这与问题要求提出交叉验证准则相矛盾，并且与样本外验证相比，通常是一种不够稳健的模型选择方法。\n-   **评估指标**：它建议使用像 AIC 这样的样本内信息准则。虽然 AIC 是一种有效的模型选择方法，但它依赖于渐近近似，并且可能不如直接交叉验证表现得好，特别是对于复杂模型或有限数据集。关于“忽略状态演化和时间依赖性”的说法有点误导，因为对 AIC 的边际对数似然的正确计算*会*涉及状态动态（例如，通过卡尔曼滤波器）。然而，主要缺陷在于它拒绝了更稳健的交叉验证范式，而选择了纯粹的样本内指标。\n-   **结论**：此选项提出了一种非交叉验证方法，未能满足问题的核心要求，并且通常被认为不如执行良好的交叉验证可靠。**不正确**。\n\n**选项 D 评估**\n-   **交叉验证方案**：“无缓冲区的分块 $K$ 折交叉验证”。这相对于随机打乱（选项 B）是一个改进，因为它保留了时间块。然而，缺少缓冲区可能导致性能评估出现乐观偏差，因为测试块的初始状态受到相邻训练块最终状态的严重约束。\n-   **评估指标**：关键缺陷是使用了“双边平滑后验 $p\\big(x_{t} \\mid y_{\\text{train}} \\cup y_{\\text{test}}, \\hat{\\theta}_{k}\\big)$”。这在原则上与选项 B 的缺陷相同。它使用来自测试集（以及其他未来数据）的数据来推断潜在状态 $x_t$，然后用 $x_t$ 来评估 $y_t$ 的似然。这不是一个预测性度量，而是衡量模型解释其已被条件化的数据的能力的度量。这构成了从测试集到其自身评估的直接且显著的信息泄露。\n-   **结论**：使用平滑后验进行评估使此方法无法用于评估预测性能。**不正确**。\n\n总之，选项 A 是唯一一个提出方法上健全且严谨的方案，尊重时间序列分析的原则，禁止信息泄露，并正确定义了预测似然。它代表了解决此问题的最佳实践。",
            "answer": "$$\\boxed{A}$$"
        }
    ]
}