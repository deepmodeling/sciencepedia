{
    "hands_on_practices": [
        {
            "introduction": "A cornerstone of cognitive modeling is connecting the theoretical constructs of a model to measurable behavior. This first practice focuses on deriving one of the most fundamental predictions of the Drift-Diffusion Model: the mean decision time. By solving the boundary value problem derived from the process's infinitesimal generator, you will gain hands-on experience in translating the abstract stochastic differential equation into a concrete and testable prediction about reaction times, a skill essential for any modeler .",
            "id": "4028304",
            "problem": "Consider the Drift-Diffusion Model (DDM) for two-choice decisions, in which a scalar decision variable $X_{t}$ evolves according to the Itô stochastic differential equation (SDE)\n$$\n\\mathrm{d}X_{t} \\;=\\; v\\,\\mathrm{d}t \\;+\\; \\sigma\\,\\mathrm{d}W_{t},\n$$\nwhere $v$ is a constant drift, $\\sigma > 0$ is a constant diffusion coefficient, and $W_{t}$ is a standard Wiener process (Brownian motion). Decisions are registered when $X_{t}$ first exits the open interval $(-a,a)$, where $a>0$ is a fixed absorbing threshold. Define the stopping time\n$$\nT \\;=\\; \\inf\\{\\, t \\geq 0 \\;:\\; X_{t} \\notin (-a,a) \\,\\},\n$$\nand the expected decision time\n$$\nm(x) \\;=\\; \\mathbb{E}_{x}[\\,T\\,],\n$$\nwith $X_{0} = x \\in (-a,a)$.\n\nStarting from the generator of the Itô diffusion and Dynkin’s formula (without invoking any pre-derived hitting-time formulas), derive the boundary value problem that $m(x)$ must satisfy on $(-a,a)$ together with appropriate boundary conditions at $\\pm a$. Solve this boundary value problem exactly and evaluate $m(0)$ to obtain the unconditional mean decision time starting at the unbiased initial condition $X_{0}=0$. Express your final answer as a single closed-form analytic expression in terms of $a$, $v$, and $\\sigma$. No numerical evaluation is required, and no rounding is needed. Do not report any intermediate equations as the final answer; only report the single closed-form expression for $m(0)$ as requested.",
            "solution": "The user wants to derive and solve the boundary value problem for the mean decision time in a Drift-Diffusion Model and evaluate it at the starting point $x=0$.\n\n### Step 1: Extract Givens\n- Stochastic Differential Equation (SDE): $\\mathrm{d}X_{t} = v\\,\\mathrm{d}t + \\sigma\\,\\mathrm{d}W_{t}$\n- Drift coefficient: $v$ (constant)\n- Diffusion coefficient: $\\sigma > 0$ (constant)\n- Wiener process: $W_{t}$\n- Decision boundaries: $X_{t}$ exits the interval $(-a,a)$, where $a>0$\n- Stopping time: $T = \\inf\\{\\, t \\geq 0 \\,:\\, X_{t} \\notin (-a,a) \\,\\}$\n- Expected decision time (Mean First Passage Time): $m(x) = \\mathbb{E}_{x}[\\,T\\,]$\n- Initial condition: $X_{0} = x \\in (-a,a)$\n\n### Step 2: Validate Using Extracted Givens\n- **Scientifically Grounded**: The problem describes the standard Drift-Diffusion Model, a canonical model in computational neuroscience for decision-making. The formulation as an Itô process and the task of finding the mean first-passage time are fundamental and well-established concepts in the theory of stochastic processes. The use of the process generator and Dynkin's formula is the standard mathematical technique for this derivation.\n- **Well-Posed**: The problem of finding the mean exit time from an interval for a one-dimensional diffusion process is a classic, well-posed boundary value problem. It is known to have a unique and stable solution.\n- **Objective**: The problem is stated using precise mathematical language and definitions, with no ambiguity or subjective elements.\n- **Flaws**: The problem is self-contained, scientifically sound, and well-posed. It does not violate any of the invalidity criteria.\n\n### Step 3: Verdict and Action\nThe problem is valid. A complete solution will be provided.\n\nThe Itô diffusion process is given by\n$$\n\\mathrm{d}X_{t} \\;=\\; v\\,\\mathrm{d}t \\;+\\; \\sigma\\,\\mathrm{d}W_{t}\n$$\nThe generator $\\mathcal{L}$ of this diffusion process, when applied to a twice continuously differentiable function $f(x)$, is\n$$\n\\mathcal{L}f(x) \\;=\\; v \\frac{\\mathrm{d}f}{\\mathrm{d}x} \\;+\\; \\frac{1}{2}\\sigma^2 \\frac{\\mathrm{d}^2f}{\\mathrm{d}x^2}\n$$\nWe are asked to find the expected decision time $m(x) = \\mathbb{E}_{x}[T]$, where $T$ is the first time the process $X_t$ starting from $X_0=x$ exits the interval $(-a,a)$. The function $m(x)$ satisfies the ordinary differential equation (ODE) $\\mathcal{L}m(x) = -1$. This can be derived from Dynkin's formula, which states that for a suitable function $f$ and a stopping time $T$:\n$$\n\\mathbb{E}_{x}[f(X_T)] \\;=\\; f(x) \\;+\\; \\mathbb{E}_{x}\\left[\\int_0^T (\\mathcal{L}f)(X_s)\\,\\mathrm{d}s\\right]\n$$\nIf we could find a function $m(x)$ such that $\\mathcal{L}m(x) = -1$, and which satisfies the boundary conditions $m(\\pm a) = 0$, then substituting $f(x)=m(x)$ into Dynkin's formula would yield:\n$$\n\\mathbb{E}_{x}[m(X_T)] \\;=\\; m(x) \\;+\\; \\mathbb{E}_{x}\\left[\\int_0^T (-1)\\,\\mathrm{d}s\\right]\n$$\nAt the stopping time $T$, the process is at one of the boundaries, $X_T \\in \\{-a, a\\}$. The boundary conditions $m(a)=0$ and $m(-a)=0$ imply that $m(X_T)=0$. Therefore, the left-hand side is $\\mathbb{E}_{x}[0] = 0$. The right-hand side becomes:\n$$\n0 \\;=\\; m(x) \\;-\\; \\mathbb{E}_{x}\\left[\\int_0^T \\mathrm{d}s\\right] \\;=\\; m(x) \\;-\\; \\mathbb{E}_{x}[T]\n$$\nThis confirms that if we solve the boundary value problem (BVP) defined by $\\mathcal{L}m(x)=-1$ and the appropriate boundary conditions, the solution $m(x)$ is indeed the desired expected stopping time $\\mathbb{E}_{x}[T]$.\n\nThe BVP for $m(x)$ on the interval $x \\in (-a,a)$ is therefore:\n$$\n\\frac{1}{2}\\sigma^2 m''(x) \\;+\\; v m'(x) \\;=\\; -1\n$$\nwith boundary conditions reflecting that the decision time is zero if we start at the boundary:\n$$\nm(a) \\;=\\; 0 \\quad \\text{and} \\quad m(-a) \\;=\\; 0\n$$\nThis is a second-order, linear, non-homogeneous ODE with constant coefficients. The general solution is the sum of a homogeneous solution $m_h(x)$ and a particular solution $m_p(x)$.\n\nFirst, consider the case where the drift $v \\neq 0$.\n\nThe homogeneous equation is $\\frac{1}{2}\\sigma^2 m_h''(x) + v m_h'(x) = 0$. The characteristic equation is $\\frac{1}{2}\\sigma^2 r^2 + v r = 0$, which gives $r(\\frac{1}{2}\\sigma^2 r + v) = 0$. The roots are $r_1=0$ and $r_2 = -2v/\\sigma^2$. The homogeneous solution is:\n$$\nm_h(x) \\;=\\; C_1 \\exp(0 \\cdot x) \\;+\\; C_2 \\exp\\left(-\\frac{2v}{\\sigma^2}x\\right) \\;=\\; C_1 \\;+\\; C_2 \\exp\\left(-\\frac{2vx}{\\sigma^2}\\right)\n$$\nFor the particular solution $m_p(x)$, since the right-hand side is a constant and one of the homogeneous roots is zero, we try a solution of the form $m_p(x) = Ax$. Substituting this into the ODE: $\\frac{1}{2}\\sigma^2(0) + v(A) = -1$, which gives $A = -1/v$. So, $m_p(x) = -x/v$.\n\nThe general solution is:\n$$\nm(x) \\;=\\; C_1 \\;+\\; C_2 \\exp\\left(-\\frac{2vx}{\\sigma^2}\\right) \\;-\\; \\frac{x}{v}\n$$\nNow, we apply the boundary conditions to find the constants $C_1$ and $C_2$:\n$1$. $m(a) = 0 \\implies C_1 + C_2 \\exp\\left(-\\frac{2va}{\\sigma^2}\\right) - \\frac{a}{v} = 0$\n$2$. $m(-a) = 0 \\implies C_1 + C_2 \\exp\\left(\\frac{2va}{\\sigma^2}\\right) + \\frac{a}{v} = 0$\n\nSubtracting the first equation from the second:\n$$\nC_2 \\left[\\exp\\left(\\frac{2va}{\\sigma^2}\\right) - \\exp\\left(-\\frac{2va}{\\sigma^2}\\right)\\right] + \\frac{2a}{v} \\;=\\; 0\n$$\n$$\nC_2 \\left[2\\sinh\\left(\\frac{2va}{\\sigma^2}\\right)\\right] \\;=\\; -\\frac{2a}{v} \\implies C_2 \\;=\\; -\\frac{a}{v \\sinh\\left(\\frac{2va}{\\sigma^2}\\right)}\n$$\nAdding the two equations:\n$$\n2C_1 + C_2 \\left[\\exp\\left(-\\frac{2va}{\\sigma^2}\\right) + \\exp\\left(\\frac{2va}{\\sigma^2}\\right)\\right] \\;=\\; 0\n$$\n$$\n2C_1 + C_2 \\left[2\\cosh\\left(\\frac{2va}{\\sigma^2}\\right)\\right] \\;=\\; 0 \\implies C_1 \\;=\\; -C_2 \\cosh\\left(\\frac{2va}{\\sigma^2}\\right)\n$$\nSubstituting the expression for $C_2$:\n$$\nC_1 \\;=\\; \\frac{a}{v \\sinh\\left(\\frac{2va}{\\sigma^2}\\right)} \\cosh\\left(\\frac{2va}{\\sigma^2}\\right) \\;=\\; \\frac{a}{v} \\coth\\left(\\frac{2va}{\\sigma^2}\\right)\n$$\nThe full solution for $m(x)$ is therefore:\n$$\nm(x) \\;=\\; \\frac{a}{v} \\coth\\left(\\frac{2va}{\\sigma^2}\\right) \\;-\\; \\frac{a}{v \\sinh\\left(\\frac{2va}{\\sigma^2}\\right)}\\exp\\left(-\\frac{2vx}{\\sigma^2}\\right) \\;-\\; \\frac{x}{v}\n$$\nWe are asked to find $m(0)$, the expected decision time starting from $x=0$. Substituting $x=0$:\n$$\nm(0) \\;=\\; \\frac{a}{v} \\coth\\left(\\frac{2va}{\\sigma^2}\\right) \\;-\\; \\frac{a}{v \\sinh\\left(\\frac{2va}{\\sigma^2}\\right)}\\exp(0) \\;-\\; 0\n$$\n$$\nm(0) \\;=\\; \\frac{a}{v} \\left[ \\coth\\left(\\frac{2va}{\\sigma^2}\\right) - \\frac{1}{\\sinh\\left(\\frac{2va}{\\sigma^2}\\right)} \\right]\n$$\n$$\nm(0) \\;=\\; \\frac{a}{v} \\left[ \\frac{\\cosh\\left(\\frac{2va}{\\sigma^2}\\right)}{\\sinh\\left(\\frac{2va}{\\sigma^2}\\right)} - \\frac{1}{\\sinh\\left(\\frac{2va}{\\sigma^2}\\right)} \\right] \\;=\\; \\frac{a}{v} \\frac{\\cosh\\left(\\frac{2va}{\\sigma^2}\\right)-1}{\\sinh\\left(\\frac{2va}{\\sigma^2}\\right)}\n$$\nUsing the hyperbolic half-angle identities $\\cosh(2\\theta)-1 = 2\\sinh^2(\\theta)$ and $\\sinh(2\\theta) = 2\\sinh(\\theta)\\cosh(\\theta)$, with $\\theta = va/\\sigma^2$:\n$$\nm(0) \\;=\\; \\frac{a}{v} \\frac{2\\sinh^2\\left(\\frac{va}{\\sigma^2}\\right)}{2\\sinh\\left(\\frac{va}{\\sigma^2}\\right)\\cosh\\left(\\frac{va}{\\sigma^2}\\right)} \\;=\\; \\frac{a}{v} \\frac{\\sinh\\left(\\frac{va}{\\sigma^2}\\right)}{\\cosh\\left(\\frac{va}{\\sigma^2}\\right)}\n$$\n$$\nm(0) \\;=\\; \\frac{a}{v} \\tanh\\left(\\frac{va}{\\sigma^2}\\right)\n$$\nThis expression is for $v \\neq 0$. For the case $v=0$, the ODE simplifies to $\\frac{1}{2}\\sigma^2 m''(x) = -1$, so $m''(x) = -2/\\sigma^2$. Integrating twice gives $m(x) = -x^2/\\sigma^2 + C_1 x + C_2$. The boundary conditions $m(a)=m(-a)=0$ yield $C_1=0$ and $C_2=a^2/\\sigma^2$. Thus, for $v=0$, $m(x) = (a^2-x^2)/\\sigma^2$, and $m(0) = a^2/\\sigma^2$.\nWe can verify that our general expression for $m(0)$ correctly limits to this result as $v \\to 0$. Let $y = va/\\sigma^2$. Then $m(0) = \\frac{a^2}{\\sigma^2} \\frac{\\tanh(y)}{y}$. Since $\\lim_{y \\to 0} \\frac{\\tanh(y)}{y} = 1$, we have $\\lim_{v \\to 0} m(0) = a^2/\\sigma^2$. Thus, the expression is robust.",
            "answer": "$$\n\\boxed{\\frac{a}{v} \\tanh\\left(\\frac{va}{\\sigma^2}\\right)}\n$$"
        },
        {
            "introduction": "While the mean provides a crucial summary, the full shape of the reaction time distribution contains far richer information about the underlying cognitive process. This exercise moves beyond the first moment to characterize the entire distribution using the powerful method of Laplace transforms. You will also incorporate the non-decision time parameter $T_{\\text{er}}$, learning how this essential component for fitting real-world data is mathematically integrated into the model's predictions without altering the choice outcome .",
            "id": "4028292",
            "problem": "A single-accumulator Drift–Diffusion Model (DDM) for two-alternative forced choice is defined as the one-dimensional stochastic process satisfying the stochastic differential equation $\\,\\mathrm{d}X_t = v\\,\\mathrm{d}t + s\\,\\mathrm{d}W_t\\,$ with constant drift $v \\in \\mathbb{R}$, diffusion amplitude $s>0$, and standard Wiener process $W_t$. The process starts at $X_0 = z$ with $z \\in (0,a)$ and is absorbed upon first hitting either the lower boundary at $0$ or the upper boundary at $a>0$. Let $\\tau$ denote the first-passage (decision) time to either boundary and let $C \\in \\{-,+\\}$ denote the boundary hit (lower or upper). The observed reaction time is modeled as $T = T_{\\text{er}} + \\tau$, where $T_{\\text{er}} \\ge 0$ is a non-decision time that is independent of the diffusion process and accounts for sensory and motor delays.\n\nStarting from the definition of the DDM as a continuous-time Markov process and the corresponding backward Kolmogorov boundary value problems for first-passage functionals, derive the psychometric and chronometric relations in the following precise sense. For $v \\neq 0$:\n\n1. Compute the upper-choice probability $p_{+}(v,a,z,s)$, defined as $p_{+} = \\mathbb{P}(C=+)$.\n\n2. For $\\lambda \\ge 0$, compute the conditional Laplace transform of the observed reaction time given an upper choice, $L_{T\\mid +}(\\lambda) = \\mathbb{E}[\\exp(-\\lambda T)\\mid C=+]$, and express it in closed form in terms of $v$, $a$, $z$, $s$, $\\lambda$, and $T_{\\text{er}}$.\n\n3. Use your expressions to explain why $T_{\\text{er}}$ changes the reaction time distribution by a pure shift without altering choice probabilities, and justify this decomposition by writing down the joint likelihood for independent trials $\\{(C_i,T_i)\\}_{i=1}^N$ in which $T_{\\text{er}}$ is independent of the diffusion process and additive.\n\nYour final answer must be a single analytic expression containing both $p_{+}(v,a,z,s)$ and $L_{T\\mid +}(\\lambda)$, written as a row matrix, with no units. No numerical approximation is required.",
            "solution": "This problem is scientifically grounded, well-posed, and objective. It is a standard derivation in the field of mathematical psychology and computational neuroscience concerning the Drift-Diffusion Model (DDM). All necessary information is provided, and the problem is mathematically solvable. Therefore, I will proceed with the solution.\n\nThe DDM is described by the stochastic differential equation $\\mathrm{d}X_t = v\\,\\mathrm{d}t + s\\,\\mathrm{d}W_t$, with initial state $X_0 = z \\in (0,a)$. The generator of this diffusion process is the operator $\\mathcal{L} = v \\frac{\\mathrm{d}}{\\mathrm{d}z} + \\frac{s^2}{2} \\frac{\\mathrm{d}^2}{\\mathrm{d}z^2}$. We will use the backward Kolmogorov equation to solve for the requested quantities.\n\n**1. Computation of the Upper-Choice Probability $p_{+}(v,a,z,s)$**\n\nThe probability of hitting the upper boundary $a$ before the lower boundary $0$, starting from $z$, is denoted by $p_{+}(z) = \\mathbb{P}(X_\\tau = a \\mid X_0 = z)$. This is a first-passage probability, which is a harmonic function with respect to the process generator. Thus, it satisfies the backward Kolmogorov equation $\\mathcal{L}p_{+}(z) = 0$.\n$$\n\\frac{s^2}{2} \\frac{\\mathrm{d}^2 p_{+}}{\\mathrm{d}z^2} + v \\frac{\\mathrm{d} p_{+}}{\\mathrm{d}z} = 0\n$$\nThe boundary conditions are determined by the outcome when starting at a boundary. If the process starts at $z=0$, it is absorbed at the lower boundary, so $p_{+}(0) = 0$. If it starts at $z=a$, it is absorbed at the upper boundary, so $p_{+}(a) = 1$.\n\nThis is a second-order linear homogeneous ordinary differential equation with constant coefficients. We can solve it by letting $q(z) = \\frac{\\mathrm{d} p_{+}}{\\mathrm{d}z}$. The equation becomes $\\frac{s^2}{2} \\frac{\\mathrm{d}q}{\\mathrm{d}z} + v q = 0$, which is a separable first-order ODE.\n$$\n\\frac{\\mathrm{d}q}{q} = -\\frac{2v}{s^2} \\mathrm{d}z\n$$\nIntegrating both sides yields $\\ln(q) = -\\frac{2vz}{s^2} + C_1$, so $q(z) = A \\exp(-\\frac{2vz}{s^2})$ for some constant $A$. Integrating $q(z)$ to find $p_{+}(z)$:\n$$\np_{+}(z) = \\int A \\exp\\left(-\\frac{2vz}{s^2}\\right) \\mathrm{d}z = A \\left(-\\frac{s^2}{2v}\\right) \\exp\\left(-\\frac{2vz}{s^2}\\right) + B\n$$\nwhere the case $v \\ne 0$ is assumed as per the problem statement. Let's rewrite the general solution with new constants $C_1'$ and $C_2'$ as $p_{+}(z) = C_1' \\exp(-\\frac{2vz}{s^2}) + C_2'$.\n\nNow, we apply the boundary conditions:\n$p_{+}(0) = 0 \\implies C_1' + C_2' = 0 \\implies C_2' = -C_1'$.\n$p_{+}(a) = 1 \\implies C_1' \\exp(-\\frac{2va}{s^2}) + C_2' = 1$.\n\nSubstituting $C_2' = -C_1'$ into the second equation gives $C_1' \\left(\\exp(-\\frac{2va}{s^2}) - 1\\right) = 1$, which implies $C_1' = \\frac{1}{\\exp(-\\frac{2va}{s^2}) - 1}$.\nThe solution for $p_{+}(z)$ is then:\n$$\np_{+}(z) = \\frac{1}{\\exp(-\\frac{2va}{s^2}) - 1} \\left( \\exp\\left(-\\frac{2vz}{s^2}\\right) - 1 \\right) = \\frac{\\exp(-\\frac{2vz}{s^2}) - 1}{\\exp(-\\frac{2va}{s^2}) - 1}\n$$\nMultiplying the numerator and denominator by $-1$ gives the more common form:\n$$\np_{+}(v,a,z,s) = \\frac{1 - \\exp\\left(-\\frac{2vz}{s^2}\\right)}{1 - \\exp\\left(-\\frac{2va}{s^2}\\right)}\n$$\n\n**2. Computation of the Conditional Laplace Transform $L_{T\\mid +}(\\lambda)$**\n\nThe conditional Laplace transform of the observed reaction time $T$ given an upper choice is $L_{T\\mid +}(\\lambda) = \\mathbb{E}[\\exp(-\\lambda T)\\mid C=+]$.\nSince $T = T_{\\text{er}} + \\tau$ and $T_{\\text{er}}$ is a constant independent of the diffusion process (which determines both $\\tau$ and $C$), we have:\n$$\n\\mathbb{E}[\\exp(-\\lambda T)\\mid C=+] = \\mathbb{E}[\\exp(-\\lambda (T_{\\text{er}} + \\tau))\\mid C=+] = \\exp(-\\lambda T_{\\text{er}}) \\mathbb{E}[\\exp(-\\lambda \\tau)\\mid C=+]\n$$\nLet's define $L_{\\tau\\mid+}(\\lambda) = \\mathbb{E}[\\exp(-\\lambda \\tau)\\mid C=+]$. By the definition of conditional expectation, this is $L_{\\tau\\mid+}(\\lambda) = \\frac{\\mathbb{E}[\\exp(-\\lambda \\tau) \\mathbb{I}(C=+)]}{\\mathbb{P}(C=+)}$, where $\\mathbb{I}(\\cdot)$ is the indicator function. The denominator is $p_{+}(z)$ which we found in Part 1.\n\nThe numerator is the unnormalized defective Laplace transform, let's call it $U(z; \\lambda) = \\mathbb{E}[\\exp(-\\lambda \\tau) \\mathbb{I}(C=+) \\mid X_0=z]$. This functional satisfies the Feynman-Kac formula, which leads to the following boundary value problem based on the backward Kolmogorov equation:\n$$\n\\mathcal{L}U(z; \\lambda) - \\lambda U(z; \\lambda) = 0 \\implies \\frac{s^2}{2} \\frac{\\mathrm{d}^2 U}{\\mathrm{d}z^2} + v \\frac{\\mathrm{d} U}{\\mathrm{d}z} - \\lambda U = 0\n$$\nThe boundary conditions are:\nFor $z=a$, the process is absorbed immediately ($\\tau=0$) at the upper boundary ($C=+$), so $U(a; \\lambda) = \\exp(-\\lambda \\cdot 0) \\cdot 1 = 1$.\nFor $z=0$, the process is absorbed immediately ($\\tau=0$) at the lower boundary ($C=-$), so $U(0; \\lambda) = \\exp(-\\lambda \\cdot 0) \\cdot 0 = 0$.\n\nThe characteristic equation for this ODE is $\\frac{s^2}{2} r^2 + vr - \\lambda = 0$, with roots:\n$$\nr = \\frac{-v \\pm \\sqrt{v^2 - 4(\\frac{s^2}{2})(-\\lambda)}}{s^2} = \\frac{-v \\pm \\sqrt{v^2 + 2\\lambda s^2}}{s^2}\n$$\nLet $\\theta = \\sqrt{v^2 + 2\\lambda s^2}$. The roots are $r_1 = \\frac{-v+\\theta}{s^2}$ and $r_2 = \\frac{-v-\\theta}{s^2}$.\nThe general solution is $U(z) = C_1 \\exp(r_1 z) + C_2 \\exp(r_2 z)$. Applying the boundary conditions:\n$U(0) = 0 \\implies C_1 + C_2 = 0 \\implies C_2 = -C_1$.\n$U(a) = 1 \\implies C_1 \\exp(r_1 a) + C_2 \\exp(r_2 a) = 1 \\implies C_1(\\exp(r_1 a) - \\exp(r_2 a)) = 1$.\nThus, $C_1 = \\frac{1}{\\exp(r_1 a) - \\exp(r_2 a)}$ and the solution is $U(z) = \\frac{\\exp(r_1 z) - \\exp(r_2 z)}{\\exp(r_1 a) - \\exp(r_2 a)}$.\n\nSubstituting the roots and using the identity $\\sinh(x) = (\\exp(x)-\\exp(-x))/2$:\n$$\nU(z) = \\frac{\\exp(\\frac{-vz}{s^2})\\left(\\exp(\\frac{\\theta z}{s^2})-\\exp(-\\frac{\\theta z}{s^2})\\right)}{\\exp(\\frac{-va}{s^2})\\left(\\exp(\\frac{\\theta a}{s^2})-\\exp(-\\frac{\\theta a}{s^2})\\right)} = \\exp\\left(\\frac{v(a-z)}{s^2}\\right) \\frac{\\sinh(\\frac{\\theta z}{s^2})}{\\sinh(\\frac{\\theta a}{s^2})}\n$$\nTo find $L_{\\tau\\mid+}(\\lambda)$, we divide by $p_{+}(z)$. We can express $p_{+}(z)$ in a similar hyperbolic sine form by setting $\\lambda=0$ in the derivation for $U(z)$, which yields the joint probability of hitting the upper boundary at any time. This corresponds to setting $\\theta = \\sqrt{v^2} = |v|$. For generality, we just use $v$, as $\\sinh(x)$ is an odd function. So, $p_+(z) = \\exp(\\frac{v(a-z)}{s^2}) \\frac{\\sinh(vz/s^2)}{\\sinh(va/s^2)}$.\n$$\nL_{\\tau\\mid+}(\\lambda) = \\frac{U(z)}{p_{+}(z)} = \\frac{\\exp(\\frac{v(a-z)}{s^2}) \\frac{\\sinh(\\theta z/s^2)}{\\sinh(\\theta a/s^2)}}{\\exp(\\frac{v(a-z)}{s^2}) \\frac{\\sinh(vz/s^2)}{\\sinh(va/s^2)}} = \\frac{\\sinh(\\frac{vz}{s^2})^{-1} \\sinh(\\frac{\\theta z}{s^2})}{\\sinh(\\frac{va}{s^2})^{-1} \\sinh(\\frac{\\theta a}{s^2})} = \\frac{\\sinh(\\frac{va}{s^2})}{\\sinh(\\frac{vz}{s^2})} \\frac{\\sinh(\\frac{z\\theta}{s^2})}{\\sinh(\\frac{a\\theta}{s^2})}\n$$\nFinally, we obtain the Laplace transform for the total observed reaction time $T$:\n$$\nL_{T\\mid +}(\\lambda) = \\exp(-\\lambda T_{\\text{er}}) L_{\\tau\\mid +}(\\lambda) = \\exp(-\\lambda T_{\\text{er}}) \\frac{\\sinh(\\frac{va}{s^2})}{\\sinh(\\frac{vz}{s^2})} \\frac{\\sinh(\\frac{z}{s^2}\\sqrt{v^2 + 2\\lambda s^2})}{\\sinh(\\frac{a}{s^2}\\sqrt{v^2 + 2\\lambda s^2})}\n$$\n\n**3. Role of Non-Decision Time $T_{\\text{er}}$ and Likelihood Function**\n\nThe derivations above demonstrate the separate roles of the diffusion process and the non-decision time.\nThe choice probability $p_{+}(v,a,z,s)$ depends only on the parameters of the diffusion process ($v, a, z, s$). It is completely independent of $T_{\\text{er}}$. This is because the choice is determined by which boundary is reached first, an event that is an outcome of the diffusion process itself. $T_{\\text{er}}$ is an independent, additive component that occurs after the decision is made at time $\\tau$.\n\nThe reaction time distribution is altered by $T_{\\text{er}}$. Our result for the Laplace transform is $L_{T\\mid +}(\\lambda) = \\exp(-\\lambda T_{\\text{er}}) L_{\\tau\\mid +}(\\lambda)$. In the time domain, the multiplication by $\\exp(-\\lambda T_{\\text{er}})$ in the Laplace domain corresponds to a time shift. If $f_{\\tau\\mid+}(t)$ is the probability density function (PDF) of the first-passage time $\\tau$ given an upper choice, and $f_{T\\mid+}(t)$ is the PDF for the observed time $T$, then $f_{T\\mid+}(t) = f_{\\tau\\mid+}(t-T_{\\text{er}})$ for $t \\ge T_{\\text{er}}$ and $0$ otherwise. This is a pure shift of the distribution of decision times.\n\nThis decomposition is justified by the structure of the likelihood function for a set of $N$ independent trials $\\{(C_i, T_i)\\}_{i=1}^N$. The likelihood of a single observation $(C_i, T_i)$ is given by the joint density $f(T_i, C_i; \\Theta)$, where $\\Theta = \\{v, a, z, s, T_{\\text{er}}\\}$ is the set of model parameters. We can write this as $f(T_i \\mid C_i; \\Theta) \\mathbb{P}(C_i; \\Theta)$.\n\nLet $\\delta_i=1$ if $C_i=+$ (upper choice) and $\\delta_i=0$ if $C_i=-$ (lower choice). The likelihood for trial $i$ is:\n$$\n\\mathcal{L}_i = [f_{T\\mid+}(T_i) p_{+}]^{\\delta_i} [f_{T\\mid-}(T_i) p_{-}]^{1-\\delta_i}\n$$\nwhere $p_- = 1 - p_+$, and $f_{T\\mid\\pm}(t)$ are the conditional PDFs of the observed time. Substituting $f_{T\\mid\\pm}(t) = f_{\\tau\\mid\\pm}(t-T_{\\text{er}})$:\n$$\n\\mathcal{L}_i = [f_{\\tau\\mid+}(T_i - T_{\\text{er}}; v,a,z,s) p_{+}(v,a,z,s)]^{\\delta_i} [f_{\\tau\\mid-}(T_i - T_{\\text{er}}; v,a,z,s) p_{-}(v,a,z,s)]^{1-\\delta_i}\n$$\nThe total log-likelihood for $N$ independent trials is $\\mathcal{L}(\\Theta) = \\prod_{i=1}^N \\mathcal{L}_i$. This expression shows that the choice probabilities $\\{p_+, p_-\\}$ are functions of $\\{v,a,z,s\\}$ only, while the reaction time PDFs $f_{\\tau\\mid\\pm}$ depend on $\\{v,a,z,s\\}$ and are evaluated at the shifted time $T_i - T_{\\text{er}}$. The parameter $T_{\\text{er}}$ enters the likelihood only as a shift parameter for the time data, separate from the parameters governing the choice probabilities and the shape of the decision time distribution, thus justifying the decomposition.",
            "answer": "$$\n\\boxed{\\begin{pmatrix} \\frac{1 - \\exp(-\\frac{2vz}{s^2})}{1 - \\exp(-\\frac{2va}{s^2})} & \\exp(-\\lambda T_{\\text{er}}) \\frac{\\sinh(\\frac{va}{s^2})}{\\sinh(\\frac{vz}{s^2})} \\frac{\\sinh(\\frac{z}{s^2}\\sqrt{v^2 + 2\\lambda s^2})}{\\sinh(\\frac{a}{s^2}\\sqrt{v^2 + 2\\lambda s^2})} \\end{pmatrix}}\n$$"
        },
        {
            "introduction": "Bridging the gap from an idealized model to messy, real-world data requires confronting the practical challenges of parameter estimation. This exercise tackles the critical and subtle issue of parameter identifiability, specifically when multiple sources of across-trial variability are present. Rather than a straightforward derivation, this practice challenges you to think like an experimental scientist, analyzing why certain parameters are difficult to disentangle and how clever experimental design can break their statistical mimicry .",
            "id": "4028267",
            "problem": "Consider a two-alternative forced-choice task modeled by the Drift-Diffusion Model (DDM), in which the decision variable $x(t)$ evolves according to the stochastic differential equation $dx(t) = v\\,dt + \\sigma\\,dW_t$ with absorbing boundaries at $x(t)=0$ (lower) and $x(t)=a$ (upper). Trials begin at time $t=0$ from a starting point $z \\in (0,a)$, and the observed reaction time $T$ includes a non-decision component $t_0$ so that $RT = T + t_0$.\n\nAssume the following sources of across-trial heterogeneity are present simultaneously:\n- The drift rate $v$ varies across trials according to $v \\sim \\mathcal{N}(\\bar v, \\eta^2)$, independently of other variables.\n- The starting point $z$ varies across trials according to $z \\sim \\text{Uniform}(z_0 - s_z/2, z_0 + s_z/2)$, truncated to $(0,a)$, independently of $v$.\n\nLet the diffusion coefficient $\\sigma > 0$, the boundary separation $a > 0$, and the non-decision time $t_0 \\ge 0$ be constant across trials. Data collected consist of many trials with observed choices and reaction times under a fixed stimulus condition with a single coherence level, yielding a fixed mean drift parameter $\\bar v$.\n\nFrom first principles of bounded evidence accumulation and mixture distributions over latent parameters, analyze the identifiability of the parameters $\\eta$ and $s_z$ using only choice probabilities and the full reaction time distributions (both correct and error) under the single-coherence, no-prior-manipulation condition. Then, consider experimental designs that introduce additional, scientifically controlled manipulations. You are asked to select all correct statements about identifiability and propose one design that enables disentangling the contributions of drift variability ($\\eta$) and starting point variability ($s_z$), along with the characteristic signatures in the data that make this disentanglement possible.\n\nSelect all options that are correct.\n\nA. In the single-coherence, no-prior-manipulation setting, there exists a continuum of $(\\eta, s_z)$ combinations that, together with small compensatory changes in $a$ and $z_0$, produce nearly indistinguishable joint choice–reaction time distributions, resulting in weak identifiability of $\\eta$ and $s_z$ from behavioral data alone.\n\nB. $\\eta$ and $s_z$ are exactly orthogonal in their effects on the reaction time distribution; therefore, the skewness of error reaction times uniquely determines $\\eta$ without any need to constrain $s_z$.\n\nC. Holding $a$, $\\sigma$, and $t_0$ fixed, the first two moments (mean and variance) of the observed reaction time distribution for correct and error trials, computed under a single-coherence stimulus condition, suffice to uniquely determine both $\\eta$ and $s_z$.\n\nD. Non-identifiability of $(\\eta, s_z)$ arises only when $\\bar v = 0$; if $\\bar v \\ne 0$ then the mapping from $(\\eta, s_z)$ to the joint choice–reaction time distribution is injective and the parameters are identifiable.\n\nE. A design that combines blockwise prior probability manipulations to shift $z_0$ and multiple coherence levels to modulate $\\bar v$, with a joint fit that shares $\\eta$ and $s_z$ across blocks and coherences, can disentangle $\\eta$ from $s_z$. In this design, changes in very-fast conditional accuracy $P(\\text{correct}\\mid RT=t)$ at small $t$ track $s_z$ under prior shifts, while the dependence of $P(\\text{correct})$ and the slope of $P(\\text{correct}\\mid RT=t)$ at larger $t$ across coherence levels primarily track $\\eta$.",
            "solution": "The problem statement has been critically validated and found to be scientifically grounded, well-posed, and objective. It describes a standard formulation of the Drift-Diffusion Model (DDM) with across-trial variability and poses a well-defined question about parameter identifiability, which is a central topic in computational modeling. The problem is valid.\n\nThe core of the problem lies in understanding how two different sources of across-trial variability—variability in the drift rate, $v$, and variability in the starting point, $z$—manifest in observable behavioral data, namely choice probabilities and reaction time (RT) distributions.\n\nThe decision process for a single trial is governed by the stochastic differential equation:\n$$dx(t) = v\\,dt + \\sigma\\,dW_t$$\nwhere $x(t)$ is the decision variable, $t$ is time, $v$ is the drift rate, $\\sigma$ is the diffusion coefficient (representing noise), and $dW_t$ is a Wiener process increment. The process starts at $x(0) = z$ and terminates when $x(t)$ first reaches one of two absorbing boundaries, at $0$ or $a$. A trial's decision time, $T$, is the time of this first passage. The observed reaction time is $RT = T + t_0$, where $t_0$ is a non-decision time component.\n\nThe problem introduces two sources of heterogeneity across trials:\n1.  **Drift Rate Variability**: The drift rate $v$ for each trial is drawn from a Normal distribution, $v \\sim \\mathcal{N}(\\bar v, \\eta^2)$. The parameter $\\eta$ quantifies the standard deviation of the drift rate across trials.\n2.  **Starting Point Variability**: The starting point $z$ for each trial is drawn from a Uniform distribution, $z \\sim \\text{Uniform}(z_0 - s_z/2, z_0 + s_z/2)$, truncated to the interval $(0,a)$. The parameter $s_z$ quantifies the range of this variability.\n\nThe observed data (choices and RTs) are a mixture over the distributions of $v$ and $z$. The probability density of an observed outcome is given by the integral over these latent variables:\n$$ p(\\text{RT, choice} | \\bar{v}, \\eta, z_0, s_z, \\dots) = \\int \\int p(\\text{RT, choice} | v, z, \\dots) p(v | \\bar{v}, \\eta) p(z | z_0, s_z) \\,dv \\,dz $$\nParameter identifiability concerns whether a unique set of parameters $(\\eta, s_z)$ maps to a given joint choice-RT distribution. Non-identifiability arises when different parameter combinations produce identical or nearly indistinguishable distributions.\n\nLet's analyze the distinct effects of $\\eta$ and $s_z$:\n- **Effect of Drift Rate Variability ($\\eta > 0$)**: This parameter introduces trial-to-trial fluctuation in the quality of evidence processing. When $\\bar v > 0$, most trials will have $v > 0$. However, a non-zero $\\eta$ means some trials will have a small positive $v$ (leading to slow correct responses) and some may even have a negative $v$ (leading to errors). These errors, driven by a drift rate opposing the mean trend, are typically slow. Thus, a key signature of $\\eta$ is the presence of slow errors and an increased skew in the overall RT distributions.\n- **Effect of Starting Point Variability ($s_z > 0$)**: This parameter introduces trial-to-trial fluctuation in the initial bias. A trial that happens to start with $z$ close to the correct boundary (e.g., $a$, for $\\bar v > 0$) will result in a fast correct response. Conversely, a trial that starts with $z$ close to the incorrect boundary (e.g., $0$) is more likely to produce an error, and this error will be fast because the diffusion path to that boundary is short. Thus, a key signature of $s_z$ is the presence of fast errors.\n\n**The Identifiability Problem in a Single Condition:**\nIn an experiment with a single stimulus coherence ($\\bar v$ is fixed) and no manipulation of response bias ($z_0$ is fixed), both $\\eta$ and $s_z$ contribute to the overall variance of RTs. Increasing $\\eta$ adds slow trials, while increasing $s_z$ adds very fast trials (both correct and error). The resulting mixture can be ambiguous. For instance, a wider RT distribution could be due to high $\\eta$ (more 'difficult' trials with low $|v|$) or high $s_z$ (more trials starting far from the center, leading to both very fast and somewhat slow responses). This \"mimicry\" creates a situation where an increase in $\\eta$ can be partially compensated by a decrease in $s_z$ (and vice-versa), along with small adjustments to other parameters like the boundary separation $a$, to produce nearly identical model predictions. This is the essence of the weak identifiability of these parameters from single-condition data.\n\nNow, we evaluate each option:\n\n**A. In the single-coherence, no-prior-manipulation setting, there exists a continuum of $(\\eta, s_z)$ combinations that, together with small compensatory changes in $a$ and $z_0$, produce nearly indistinguishable joint choice–reaction time distributions, resulting in weak identifiability of $\\eta$ and $s_z$ from behavioral data alone.**\nThis statement accurately describes the identifiability problem. The confounding effects of drift variability and starting point variability, especially when only a single condition is observed, are well-documented. Different combinations of $(\\eta, s_z)$ and other DDM parameters can indeed produce nearly identical likelihood surfaces for the data, making it difficult to pinpoint a unique parameter set. This is a classic result in DDM parameter estimation literature.\n**Verdict: Correct.**\n\n**B. $\\eta$ and $s_z$ are exactly orthogonal in their effects on the reaction time distribution; therefore, the skewness of error reaction times uniquely determines $\\eta$ without any need to constrain $s_z$.**\nThis statement is false. The effects of $\\eta$ and $s_z$ are confounded, not orthogonal. As explained above, they both influence the shape of the RT distributions in overlapping ways. While $\\eta$ is a strong determinant of slow errors and $s_z$ of fast errors, their influence is not exclusive. High $\\eta$ can lead to a trial with a large, opposite-sign $v$, causing a fast error. High $s_z$ can lead to a trial starting near the wrong boundary but taking a long, meandering path to it, causing a slow error. Therefore, a single summary statistic like the skewness of error RTs cannot uniquely determine one parameter in isolation from the other.\n**Verdict: Incorrect.**\n\n**C. Holding $a$, $\\sigma$, and $t_0$ fixed, the first two moments (mean and variance) of the observed reaction time distribution for correct and error trials, computed under a single-coherence stimulus condition, suffice to uniquely determine both $\\eta$ and $s_z$.**\nThis statement is incorrect. The mapping from the parameters $(\\eta, s_z)$ to the moments of the RT distribution is highly complex and not injective. The full shape of the distributions contains crucial information that is lost when considering only the mean and variance. The mimicry described for option A applies to the full distribution, and therefore also to its moments. It is easy to construct examples where different $(\\eta, s_z)$ pairs produce very similar first and second moments. Thus, moments are insufficient statistics for identifying these parameters.\n**Verdict: Incorrect.**\n\n**D. Non-identifiability of $(\\eta, s_z)$ arises only when $\\bar v = 0$; if $\\bar v \\ne 0$ then the mapping from $(\\eta, s_z)$ to the joint choice–reaction time distribution is injective and the parameters are identifiable.**\nThis statement is incorrect. The case of $\\bar v = 0$ is a particularly challenging one, but the identifiability problem is general and persists for $\\bar v \\ne 0$. The entire discussion of the trade-off between $\\eta$ creating slow errors and $s_z$ creating fast errors is most relevant precisely when $\\bar v \\ne 0$, as there is a clear \"correct\" and \"error\" response. The confounding of variability sources is a fundamental property of the mixture model, not a special feature of the zero-drift case.\n**Verdict: Incorrect.**\n\n**E. A design that combines blockwise prior probability manipulations to shift $z_0$ and multiple coherence levels to modulate $\\bar v$, with a joint fit that shares $\\eta$ and $s_z$ across blocks and coherences, can disentangle $\\eta$ from $s_z$. In this design, changes in very-fast conditional accuracy $P(\\text{correct}\\mid RT=t)$ at small $t$ track $s_z$ under prior shifts, while the dependence of $P(\\text{correct})$ and the slope of $P(\\text{correct}\\mid RT=t)$ at larger $t$ across coherence levels primarily track $\\eta$.**\nThis statement describes the state-of-the-art experimental and analytical approach to solving the identifiability problem.\n- **Manipulating $\\bar v$ (via coherence):** The effect of $\\eta$ is to produce a distribution of actual drift rates around the mean $\\bar v$. How accuracy changes as a function of $\\bar v$ is highly sensitive to the value of $\\eta$. For example, a large $\\eta$ will limit the maximum accuracy achievable even at high $\\bar v$.\n- **Manipulating $z_0$ (via priors):** The effect of $s_z$ is to create a distribution of starting points around $z_0$. The behavior of the fastest responses is a direct reflection of the part of the starting point distribution $p(z)$ that is closest to one of the boundaries. Shifting the mean of this distribution, $z_0$, and observing how the accuracy of the fastest RTs changes, provides a strong constraint on its width, $s_z$.\n- **Joint Fitting:** By fitting all conditions simultaneously while holding $\\eta$ and $s_z$ constant (as they are assumed to be stable subject traits), we leverage these differential effects to constrain the parameters.\nThe description of the characteristic signatures is also precise. The effect of starting point variability $s_z$ is most pronounced at the very beginning of the RT distribution, affecting the accuracy of the fastest responses. The effect of drift rate variability $\\eta$ is distributed throughout the process and is best isolated by observing how performance scales with changes in mean drift rate $\\bar v$. This approach provides orthogonalizing constraints that break the parameter trade-off.\n**Verdict: Correct.**",
            "answer": "$$\\boxed{AE}$$"
        }
    ]
}