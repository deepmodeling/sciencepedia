{
    "hands_on_practices": [
        {
            "introduction": "Understanding orientation selectivity begins with the structure of a neuron's receptive field. This exercise explores this fundamental principle using a canonical linear-quadratic 'energy' model of a V1 neuron . By analytically deriving the cell's response to moving gratings, you will uncover how the spatiotemporal symmetry of its linear filter dictates its tuning properties, providing a clear, mechanistic explanation for how high orientation selectivity can coexist with zero direction selectivity.",
            "id": "3999525",
            "problem": "Consider a linear–quadratic neural model for motion processing in primary visual cortex in which the stimulus is a scalar spatiotemporal luminance pattern $s(\\mathbf{x}, t)$ and the neuron’s linear stage is characterized by a spatiotemporal kernel $k(\\mathbf{x}, t)$. The instantaneous linear drive is defined as $z(t) = \\int_{\\mathbb{R}^{2}} \\int_{\\mathbb{R}} k(\\mathbf{x}, \\tau)\\, s(\\mathbf{x}, t - \\tau)\\, d\\tau\\, d^{2}\\mathbf{x}$, and the observable response is the time average of the squared drive $R[s] = \\lim_{T \\to \\infty} \\frac{1}{T} \\int_{0}^{T} z(t)^{2}\\, dt$. This $R[s]$ defines the response functional $R[\\mathbf{s}(x,t)]$ precisely for this model. All angles are in radians.\n\nYou are given a separable, even-symmetric kernel\n$$\nk(\\mathbf{x}, t) = k_{x}(x)\\, k_{y}(y)\\, k_{t}(t), \\quad k_{x}(x) = \\cos(k_{0} x)\\, \\exp\\!\\left(-\\frac{x^{2}}{2\\sigma_{x}^{2}}\\right), \\quad k_{y}(y) = \\exp\\!\\left(-\\frac{y^{2}}{2\\sigma_{y}^{2}}\\right), \\quad k_{t}(t) = \\exp\\!\\left(-\\frac{t^{2}}{2\\Delta^{2}}\\right),\n$$\nwith $k_{0}  0$, $\\sigma_{x}  0$, $\\sigma_{y}  0$, and $\\Delta  0$. Consider two drifting sinusoidal gratings of identical spatial frequency $k_{0}$ and temporal frequency $\\omega  0$:\n$$\ns_{\\mathrm{pref}}(\\mathbf{x}, t) = A\\, \\cos(k_{0} x - \\omega t), \\qquad s_{\\mathrm{null}}(\\mathbf{x}, t) = A\\, \\cos(k_{0} x + \\omega t),\n$$\nwhere $A  0$ is the contrast amplitude. Let $R_{\\mathrm{pref}} = R[s_{\\mathrm{pref}}]$ and $R_{\\mathrm{null}} = R[s_{\\mathrm{null}}]$, and define the Direction Selectivity Index (DSI) by\n$$\n\\mathrm{DSI} = \\frac{R_{\\mathrm{pref}} - R_{\\mathrm{null}}}{R_{\\mathrm{pref}} + R_{\\mathrm{null}}}.\n$$\n\nTasks:\n- Starting from the above model definitions, derive closed-form expressions for $R_{\\mathrm{pref}}$ and $R_{\\mathrm{null}}$ for the given kernel and stimuli. Your derivation must begin from the stated response functional and use only standard properties of convolution, even symmetry, and time averaging of sinusoids. Do not assume any special “shortcut” motion formulas.\n- Compute the resulting Direction Selectivity Index. Express your final DSI value as an exact number; no rounding is required. The DSI is dimensionless.\n- In addition, provide a principled derivation, based on the same model, explaining how orientation selectivity can be high while direction selectivity is zero. Concretely, analyze the responses $R_{\\parallel}$ and $R_{\\perp}$ to two gratings of identical $k_{0}$ and $\\omega$: one whose orientation is aligned with the kernel’s $x$-axis, $s_{\\parallel}(\\mathbf{x}, t) = A\\, \\cos(k_{0} x - \\omega t)$, and one orthogonal to it, $s_{\\perp}(\\mathbf{x}, t) = A\\, \\cos(k_{0} y - \\omega t)$. Show algebraically how the Orientation Selectivity Index (OSI), defined by $\\mathrm{OSI} = \\frac{R_{\\parallel} - R_{\\perp}}{R_{\\parallel} + R_{\\perp}}$, can approach $1$ (i.e., high orientation selectivity) for appropriate parameter regimes even when $\\mathrm{DSI} = 0$.\n\nGive the DSI as your final answer. No units are required for the final answer.",
            "solution": "The problem will be validated and, if valid, solved in three parts as requested: first, the derivation of the responses $R_{\\mathrm{pref}}$ and $R_{\\mathrm{null}}$ to compute the Direction Selectivity Index (DSI); second, the final calculation of the DSI; third, a principled derivation explaining how high orientation selectivity (OSI $\\approx 1$) can coexist with zero direction selectivity (DSI $= 0$) within this model framework.\n\n### Problem Validation\n\n**Step 1: Extract Givens**\n- **Model:** Linear-quadratic neural model.\n- **Stimulus:** $s(\\mathbf{x}, t)$, a scalar spatiotemporal luminance pattern.\n- **Kernel:** $k(\\mathbf{x}, t)$, a spatiotemporal kernel.\n- **Linear Drive:** $z(t) = \\int_{\\mathbb{R}^{2}} \\int_{\\mathbb{R}} k(\\mathbf{x}, \\tau)\\, s(\\mathbf{x}, t - \\tau)\\, d\\tau\\, d^{2}\\mathbf{x}$.\n- **Response Functional:** $R[s] = \\lim_{T \\to \\infty} \\frac{1}{T} \\int_{0}^{T} z(t)^{2}\\, dt$.\n- **Specific Kernel:** A separable, even-symmetric kernel $k(\\mathbf{x}, t) = k_{x}(x)\\, k_{y}(y)\\, k_{t}(t)$, where:\n  - $k_{x}(x) = \\cos(k_{0} x)\\, \\exp(-\\frac{x^{2}}{2\\sigma_{x}^{2}})$\n  - $k_{y}(y) = \\exp(-\\frac{y^{2}}{2\\sigma_{y}^{2}})$\n  - $k_{t}(t) = \\exp(-\\frac{t^{2}}{2\\Delta^{2}})$\n- **Kernel Parameters:** $k_{0}  0$, $\\sigma_{x}  0$, $\\sigma_{y}  0$, $\\Delta  0$.\n- **Stimuli for DSI:** Drifting sinusoidal gratings with spatial frequency $k_{0}$ and temporal frequency $\\omega  0$.\n  - $s_{\\mathrm{pref}}(\\mathbf{x}, t) = A\\, \\cos(k_{0} x - \\omega t)$, with amplitude $A  0$.\n  - $s_{\\mathrm{null}}(\\mathbf{x}, t) = A\\, \\cos(k_{0} x + \\omega t)$.\n- **Responses for DSI:** $R_{\\mathrm{pref}} = R[s_{\\mathrm{pref}}]$ and $R_{\\mathrm{null}} = R[s_{\\mathrm{null}}]$.\n- **DSI Definition:** $\\mathrm{DSI} = \\frac{R_{\\mathrm{pref}} - R_{\\mathrm{null}}}{R_{\\mathrm{pref}} + R_{\\mathrm{null}}}$.\n- **Stimuli for OSI:**\n  - $s_{\\parallel}(\\mathbf{x}, t) = A\\, \\cos(k_{0} x - \\omega t)$ (aligned).\n  - $s_{\\perp}(\\mathbf{x}, t) = A\\, \\cos(k_{0} y - \\omega t)$ (orthogonal).\n- **Responses for OSI:** $R_{\\parallel} = R[s_{\\parallel}]$ and $R_{\\perp} = R[s_{\\perp}]$.\n- **OSI Definition:** $\\mathrm{OSI} = \\frac{R_{\\parallel} - R_{\\perp}}{R_{\\parallel} + R_{\\perp}}$.\n\n**Step 2: Validate Using Extracted Givens**\n- **Scientifically Grounded:** The problem describes a simplified energy model (a linear-quadratic model), which is a canonical model in computational neuroscience for explaining response properties of V1 complex cells, such as direction and orientation selectivity. The use of Gabor-like filters and sinusoidal grating stimuli is standard methodology in the field. The model is scientifically sound.\n- **Well-Posed:** The problem is mathematically well-defined. All required functions, parameters, and definitions are provided. The calculations are standard applications of linear systems theory and Fourier analysis, which will lead to a unique and meaningful result.\n- **Objective:** The language is formal, mathematical, and free of any subjective or ambiguous statements.\n- **Flaw Checklist:** The problem does not violate any of the specified criteria for invalidity. It is scientifically sound, formal, complete, realistic within the modeling context, and well-posed.\n\n**Step 3: Verdict and Action**\nThe problem is **valid**. A full solution will be provided.\n\n### Derivation of Responses and DSI\n\nThe linear drive $z(t)$ is the result of a spatiotemporal convolution of the kernel $k(\\mathbf{x}, t)$ and the stimulus $s(\\mathbf{x}, t)$, with the spatial dimensions subsequently integrated out. We will analyze the response to a general complex exponential stimulus and then use superposition.\n\nLet the stimulus be of the form $s(\\mathbf{x}, t) = \\exp(i(k_x x + k_y y - \\Omega t))$. The corresponding complex linear drive $\\tilde{z}(t)$ is:\n$$\n\\tilde{z}(t) = \\int_{\\mathbb{R}^2}\\int_{\\mathbb{R}} k(\\mathbf{x}', \\tau) \\exp(i(k_x x' + k_y y' - \\Omega (t-\\tau))) \\, d\\tau \\, d^2\\mathbf{x}'\n$$\n$$\n\\tilde{z}(t) = \\exp(-i\\Omega t) \\int_{\\mathbb{R}^2}\\int_{\\mathbb{R}} k(\\mathbf{x}', \\tau) \\exp(i(k_x x' + k_y y' + \\Omega \\tau)) \\, d\\tau \\, d^2\\mathbf{x}'\n$$\nThe integral term is the spatiotemporal Fourier transform of the kernel, $\\hat{k}(k_x, k_y, \\Omega) = \\int k(\\mathbf{x},t) \\exp(-i(k_x x + k_y y + \\Omega t)) d^2\\mathbf{x} dt$. The integral in the expression for $\\tilde{z}(t)$ is thus $\\hat{k}(-k_x, -k_y, -\\Omega)$.\n$$\n\\tilde{z}(t) = \\hat{k}(-k_x, -k_y, -\\Omega) \\exp(-i\\Omega t)\n$$\nSince the kernel $k(\\mathbf{x}, t) = k_x(x)k_y(y)k_t(t)$ is a product of real, even functions, its Fourier transform $\\hat{k}(k_x, k_y, \\Omega) = \\hat{k}_x(k_x)\\hat{k}_y(k_y)\\hat{k}_t(\\Omega)$ is also real and even. Therefore, $\\hat{k}(-k_x, -k_y, -\\Omega) = \\hat{k}(k_x, k_y, \\Omega)$. The response to a complex exponential is $\\tilde{z}(t) = \\hat{k}(k_x, k_y, \\Omega) \\exp(-i\\Omega t)$.\n\n**1. Response to Preferred Direction Stimulus, $s_{\\mathrm{pref}}$**\nThe stimulus is $s_{\\mathrm{pref}}(\\mathbf{x}, t) = A \\cos(k_{0} x - \\omega t) = \\frac{A}{2} \\left( e^{i(k_0 x - \\omega t)} + e^{-i(k_0 x - \\omega t)} \\right)$.\nUsing linearity, the drive $z_{\\mathrm{pref}}(t)$ is the sum of responses to the two complex exponential components.\n- For the component $e^{i(k_0 x - \\omega t)}$, we have $k_x = k_0$, $k_y = 0$, $\\Omega = \\omega$. The complex drive is $\\hat{k}(k_0, 0, \\omega) e^{-i\\omega t}$.\n- For the component $e^{-i(k_0 x - \\omega t)} = e^{i(-k_0 x + \\omega t)}$, we have $k_x = -k_0$, $k_y = 0$, $\\Omega = -\\omega$. The complex drive is $\\hat{k}(-k_0, 0, -\\omega) e^{i\\omega t}$.\n\nThe total drive is:\n$$\nz_{\\mathrm{pref}}(t) = \\frac{A}{2} \\left( \\hat{k}(k_0, 0, \\omega) e^{-i\\omega t} + \\hat{k}(-k_0, 0, -\\omega) e^{i\\omega t} \\right)\n$$\nAs established, since $k(\\mathbf{x},t)$ is real and even, its Fourier transform $\\hat{k}(k_x,k_y,\\Omega)$ is also real and even. Thus, $\\hat{k}(-k_0, 0, -\\omega) = \\hat{k}(k_0, 0, \\omega)$. Let this real-valued transfer function magnitude be denoted by $H_{\\mathrm{pref}} = \\hat{k}(k_0, 0, \\omega) = \\hat{k}_x(k_0)\\hat{k}_y(0)\\hat{k}_t(\\omega)$.\n$$\nz_{\\mathrm{pref}}(t) = \\frac{A}{2} H_{\\mathrm{pref}} (e^{-i\\omega t} + e^{i\\omega t}) = A H_{\\mathrm{pref}} \\cos(\\omega t)\n$$\nThe response $R_{\\mathrm{pref}}$ is the time-average of $z_{\\mathrm{pref}}(t)^2$:\n$$\nR_{\\mathrm{pref}} = \\lim_{T \\to \\infty} \\frac{1}{T} \\int_{0}^{T} (A H_{\\mathrm{pref}} \\cos(\\omega t))^2 dt = A^2 H_{\\mathrm{pref}}^2 \\langle \\cos^2(\\omega t) \\rangle\n$$\nThe time-average of $\\cos^2(\\omega t)$ over an infinite interval is $\\frac{1}{2}$.\n$$\nR_{\\mathrm{pref}} = \\frac{1}{2} A^2 H_{\\mathrm{pref}}^2 = \\frac{1}{2} A^2 (\\hat{k}_x(k_0) \\hat{k}_y(0) \\hat{k}_t(\\omega))^2\n$$\n\n**2. Response to Null Direction Stimulus, $s_{\\mathrm{null}}$**\nThe stimulus is $s_{\\mathrm{null}}(\\mathbf{x}, t) = A \\cos(k_0 x + \\omega t) = \\frac{A}{2} \\left( e^{i(k_0 x + \\omega t)} + e^{-i(k_0 x + \\omega t)} \\right)$.\n- For the component $e^{i(k_0 x + \\omega t)}$, we have $k_x = k_0$, $k_y = 0$, $\\Omega = -\\omega$. The complex drive is $\\hat{k}(k_0, 0, -\\omega) e^{i\\omega t}$.\n- For the component $e^{-i(k_0 x + \\omega t)}$, we have $k_x = -k_0$, $k_y = 0$, $\\Omega = \\omega$. The complex drive is $\\hat{k}(-k_0, 0, \\omega) e^{-i\\omega t}$.\n\nThe total drive is:\n$$\nz_{\\mathrm{null}}(t) = \\frac{A}{2} \\left( \\hat{k}(k_0, 0, -\\omega) e^{i\\omega t} + \\hat{k}(-k_0, 0, \\omega) e^{-i\\omega t} \\right)\n$$\nAgain, using the even symmetry of the real kernel, $\\hat{k}(k_0, 0, -\\omega) = \\hat{k}(k_0, 0, \\omega)$ and $\\hat{k}(-k_0, 0, \\omega) = \\hat{k}(k_0, 0, \\omega)$. Both equal $H_{\\mathrm{pref}}$.\n$$\nz_{\\mathrm{null}}(t) = \\frac{A}{2} H_{\\mathrm{pref}} (e^{i\\omega t} + e^{-i\\omega t}) = A H_{\\mathrm{pref}} \\cos(\\omega t)\n$$\nThis is identical to $z_{\\mathrm{pref}}(t)$. Therefore, the response $R_{\\mathrm{null}}$ is also identical:\n$$\nR_{\\mathrm{null}} = \\frac{1}{2} A^2 H_{\\mathrm{pref}}^2 = \\frac{1}{2} A^2 (\\hat{k}_x(k_0) \\hat{k}_y(0) \\hat{k}_t(\\omega))^2\n$$\n\n**3. Calculation of DSI**\nSince $R_{\\mathrm{pref}} = R_{\\mathrm{null}}$, their difference is zero.\n$$\n\\mathrm{DSI} = \\frac{R_{\\mathrm{pref}} - R_{\\mathrm{null}}}{R_{\\mathrm{pref}} + R_{\\mathrm{null}}} = \\frac{0}{R_{\\mathrm{pref}} + R_{\\mathrm{null}}}\n$$\nThe response $R_{\\mathrm{pref}}$ is non-zero as long as $A  0$ and the kernel is not identically zero. Therefore, the denominator is non-zero.\n$$\n\\mathrm{DSI} = 0\n$$\nThe inability of the model to exhibit direction selectivity is a direct and necessary consequence of the spatiotemporal kernel $k(\\mathbf{x},t)$ being separable into a product of purely even functions, particularly the temporal kernel $k_t(t)$. A system with a time-symmetric impulse response cannot distinguish between a signal and its time-reversal, which is the relationship between the preferred and null stimuli.\n\n### Derivation of OSI and relation to DSI\n\nWe now analyze the responses to gratings with parallel and orthogonal orientations relative to the kernel's $x$-axis.\n\n**1. Response to Parallel Stimulus, $R_{\\parallel}$**\nThe parallel stimulus is $s_{\\parallel}(\\mathbf{x}, t) = A \\cos(k_0 x - \\omega t)$, which is identical to $s_{\\mathrm{pref}}$. Thus, its response is:\n$$\nR_{\\parallel} = R_{\\mathrm{pref}} = \\frac{1}{2} A^2 (\\hat{k}_x(k_0) \\hat{k}_y(0) \\hat{k}_t(\\omega))^2\n$$\n\n**2. Response to Orthogonal Stimulus, $R_{\\perp}$**\nThe orthogonal stimulus is $s_{\\perp}(\\mathbf{x}, t) = A \\cos(k_0 y - \\omega t)$. The same analysis method applies. The drive now depends on the kernel's Fourier transform at spatial frequency $(0, k_0)$ and temporal frequency $\\omega$.\n$$\nz_{\\perp}(t) = A H_{\\perp} \\cos(\\omega t)\n$$\nwhere $H_{\\perp} = \\hat{k}(0, k_0, \\omega) = \\hat{k}_x(0)\\hat{k}_y(k_0)\\hat{k}_t(\\omega)$.\nThe response is:\n$$\nR_{\\perp} = \\frac{1}{2} A^2 H_{\\perp}^2 = \\frac{1}{2} A^2 (\\hat{k}_x(0) \\hat{k}_y(k_0) \\hat{k}_t(\\omega))^2\n$$\n\n**3. Calculation of OSI**\nThe Orientation Selectivity Index is:\n$$\n\\mathrm{OSI} = \\frac{R_{\\parallel} - R_{\\perp}}{R_{\\parallel} + R_{\\perp}} = \\frac{(\\hat{k}_x(k_0) \\hat{k}_y(0) \\hat{k}_t(\\omega))^2 - (\\hat{k}_x(0) \\hat{k}_y(k_0) \\hat{k}_t(\\omega))^2}{(\\hat{k}_x(k_0) \\hat{k}_y(0) \\hat{k}_t(\\omega))^2 + (\\hat{k}_x(0) \\hat{k}_y(k_0) \\hat{k}_t(\\omega))^2}\n$$\nThe common factor $(\\frac{1}{2}A^2)^2 (\\hat{k}_t(\\omega))^4$ cancels. Let's define a ratio $\\rho = \\frac{R_{\\perp}}{R_{\\parallel}} = \\frac{(\\hat{k}_x(0) \\hat{k}_y(k_0))^2}{(\\hat{k}_x(k_0) \\hat{k}_y(0))^2}$. Then $\\mathrm{OSI} = \\frac{1-\\rho}{1+\\rho}$. High orientation selectivity (OSI $\\to 1$) occurs when $\\rho \\to 0$, which means $R_{\\perp} \\ll R_{\\parallel}$.\n\nTo show this is possible, we examine the ratio $\\rho$. This requires evaluating the specific Fourier transforms. The Fourier transform of a Gaussian $g(x) = \\exp(-x^2/(2\\sigma^2))$ is $\\hat{g}(k) = \\sigma\\sqrt{2\\pi}\\exp(-k^2\\sigma^2/2)$.\n- $\\hat{k}_y(k_0) = \\sigma_y\\sqrt{2\\pi}\\exp(-k_0^2\\sigma_y^2/2)$.\n- $\\hat{k}_y(0) = \\sigma_y\\sqrt{2\\pi}$.\n\nSo, $\\frac{\\hat{k}_y(k_0)}{\\hat{k}_y(0)} = \\exp(-k_0^2\\sigma_y^2/2)$.\n\n- $\\hat{k}_x(0) = \\mathcal{F}[\\cos(k_0 x)\\exp(-\\frac{x^2}{2\\sigma_x^2})]|_{k=0} = \\int \\cos(k_0 x)\\exp(-\\frac{x^2}{2\\sigma_x^2}) dx$. This evaluates to $\\sigma_x\\sqrt{2\\pi}\\exp(-k_0^2\\sigma_x^2/2)$.\n- $\\hat{k}_x(k_0)$. A more involved calculation gives $\\hat{k}_x(k_0) = \\frac{\\sigma_x\\sqrt{2\\pi}}{2}(1+\\exp(-2k_0^2\\sigma_x^2))$.\n\nThe ratio of responses is:\n$$\n\\rho = \\frac{R_{\\perp}}{R_{\\parallel}} = \\left( \\frac{\\hat{k}_x(0)}{\\hat{k}_x(k_0)} \\frac{\\hat{k}_y(k_0)}{\\hat{k}_y(0)} \\right)^2 = \\left( \\frac{\\sigma_x\\sqrt{2\\pi}\\exp(-k_0^2\\sigma_x^2/2)}{\\frac{\\sigma_x\\sqrt{2\\pi}}{2}(1+\\exp(-2k_0^2\\sigma_x^2))} \\cdot \\exp(-k_0^2\\sigma_y^2/2) \\right)^2\n$$\n$$\n\\rho = \\left( \\frac{2\\exp(-k_0^2\\sigma_x^2/2)}{1+\\exp(-2k_0^2\\sigma_x^2)} \\cdot \\exp(-k_0^2\\sigma_y^2/2) \\right)^2\n$$\nHigh orientation selectivity (OSI $\\to 1$) can be achieved if $\\rho \\to 0$. We can achieve this by choosing parameters such that the ratio of responses becomes very small. For instance, consider the limit as $\\sigma_y \\to \\infty$. In this limit, the term $\\exp(-k_0^2\\sigma_y^2/2) \\to 0$. Consequently, $\\rho \\to 0$ and OSI $\\to 1$.\n\nPhysically, $\\sigma_y \\to \\infty$ means the kernel becomes infinitely elongated along the $y$-axis, i.e., $k_y(y) = \\exp(-y^2/(2\\sigma_y^2)) \\to 1$. Such a neuron is selective for stimuli with variations along the $x$-axis (e.g., vertical contours) but is completely insensitive to variations along the $y$-axis (e.g., horizontal contours). Thus, it responds strongly to $s_{\\parallel}$ but gives virtually no response to $s_{\\perp}$. This leads to OSI approaching $1$.\n\nCrucially, this condition for high orientation selectivity (large $\\sigma_y$) is independent of the temporal properties of the kernel. Therefore, it can coexist with the condition $\\mathrm{DSI}=0$ which arose from the temporal even symmetry of $k_t(t)$. This demonstrates how a neuron model can be highly orientation-selective while being completely non-direction-selective.",
            "answer": "$$\\boxed{0}$$"
        },
        {
            "introduction": "While feedforward connections establish a neuron's basic tuning, recurrent interactions within cortical circuits play a crucial role in refining it. This hands-on coding exercise guides you through building a network of V1 simple cells with Gabor receptive fields to investigate how lateral inhibition sharpens orientation selectivity . By simulating the network dynamics, you will not only quantify the gain in selectivity but also analyze the network's stability, a critical consideration in any recurrent model.",
            "id": "3983190",
            "problem": "You are to implement a simulation-based analysis of orientation selectivity in a simplified network model of primary visual cortex (V1) simple cells with lateral inhibition. The core modeling components must be built from first principles of linear filtering with Gabor functions, half-wave rectification, and threshold-linear inhibitory interactions, in order to quantify the sharpening of orientation selectivity and analyze local map stability.\n\nFundamental base and definitions to be used:\n- A two-dimensional Gabor filter is defined as a Gaussian envelope modulating a sinusoidal carrier. Let the spatial coordinates be $(x,y)$ and the preferred orientation be $\\theta_i$. Define rotated coordinates $(x',y')$ by a rotation matrix of angle $\\theta_i$ applied to $(x,y)$. The Gabor filter is given by\n$$\ng_i(x,y) \\;=\\; \\exp\\!\\left(-\\frac{{x'}^2}{2\\sigma_x^2} - \\frac{{y'}^2}{2\\sigma_y^2}\\right)\\,\\cos\\!\\big(2\\pi f_0\\,x'\\big),\n$$\nwhere $\\sigma_x$, $\\sigma_y$ are the standard deviations of the Gaussian envelope along the filter’s axes and $f_0$ is the carrier spatial frequency in cycles per unit length.\n- A sinusoidal grating stimulus with orientation $\\theta$ is given by\n$$\ns_\\theta(x,y) \\;=\\; \\cos\\!\\left(2\\pi f_s\\,(x\\cos\\theta + y\\sin\\theta)\\right).\n$$\nTo ensure finite-energy inner products on a finite grid, window the stimulus with a Gaussian $w(x,y) = \\exp\\!\\left(-\\frac{x^2+y^2}{2\\sigma_w^2}\\right)$ before computing integrals.\n- A simple cell’s linear drive to stimulus $s_\\theta$ is the spatial inner product\n$$\nb_i(\\theta) \\;=\\; \\iint g_i(x,y)\\,\\big(s_\\theta(x,y)\\,w(x,y)\\big)\\,dx\\,dy,\n$$\napproximated numerically by a Riemann sum over a finite grid.\n- The half-wave rectified output (a standard linear–nonlinear cascade) is $r_i^{\\mathrm{ff}}(\\theta) = \\max\\big(0,\\,b_i(\\theta)\\big)$.\n- Lateral inhibition is modeled by a threshold-linear recurrent network. For a fixed stimulus orientation $\\theta$, let $\\mathbf{b}(\\theta) \\in \\mathbb{R}^K$ be the vector of drives across $K$ cells, and let $W \\in \\mathbb{R}^{K\\times K}$ be a symmetric nonnegative lateral interaction matrix parameterized by angular proximity in orientation space. The steady-state responses $\\mathbf{r}(\\theta)\\in\\mathbb{R}^K_{\\ge 0}$ satisfy the fixed-point condition\n$$\n\\mathbf{r}(\\theta) \\;=\\; \\big[\\mathbf{b}(\\theta) \\;-\\; \\gamma\\,W\\,\\mathbf{r}(\\theta)\\big]_+,\n$$\nwhere $[\\cdot]_+$ denotes elementwise rectification and $\\gamma \\ge 0$ is the inhibitory gain.\n- Orientation Selectivity Index (OSI) for cell $i$ over a set of stimulus orientations $\\{\\theta_m\\}_{m=1}^M$ is computed using the circular-moment definition with $\\pi$-periodicity:\n$$\n\\mathrm{OSI}_i \\;=\\; \\frac{\\left|\\sum_{m=1}^M r_i(\\theta_m)\\,e^{\\mathrm{i}\\,2\\theta_m}\\right|}{\\sum_{m=1}^M r_i(\\theta_m)},\n$$\nwith the convention $\\mathrm{OSI}_i = 0$ when the denominator is zero. Angles $\\theta$ must be in radians.\n- Map stability is analyzed by the spectral radius of the Jacobian of the threshold-linear map at a fixed point. For the discrete-time map $\\mathbf{F}(\\mathbf{r}) = [\\mathbf{b} - \\gamma W \\mathbf{r}]_+$, a fixed point $\\mathbf{r}^\\star$ has a local Jacobian\n$$\nJ(\\mathbf{r}^\\star) \\;=\\; -\\gamma\\,D(\\mathbf{r}^\\star)\\,W,\n$$\nwhere $D(\\mathbf{r}^\\star)$ is a diagonal indicator matrix with entries $D_{ii}=1$ if $r_i^\\star0$ and $D_{ii}=0$ otherwise. Local contraction, and hence local stability of the discrete iteration $\\mathbf{r}_{t+1}=\\mathbf{F}(\\mathbf{r}_t)$, is ensured if the spectral radius $\\rho\\!\\left(J(\\mathbf{r}^\\star)\\right)  1$.\n\nTask requirements:\n1) Implement a program that constructs $K$ oriented Gabor filters $g_i$ with preferred orientations $\\theta_i$ evenly spaced in $[0,\\pi)$, and computes their linear drives $b_i(\\theta_m)$ to a set of $M$ sinusoidal gratings $s_{\\theta_m}$ with orientations $\\theta_m$ evenly spaced in $[0,\\pi)$, using a finite grid discretization and the Gaussian window $w$ for the stimuli. Use half-wave rectification to obtain $r_i^{\\mathrm{ff}}(\\theta_m)=\\max(0,b_i(\\theta_m))$.\n2) Construct a lateral interaction matrix $W$ using a circular-Gaussian kernel of width $\\sigma_\\theta$ on orientation space with wrap-around distance on $[0,\\pi)$:\n$$\nW_{ij} \\;=\\; \\exp\\!\\left(-\\frac{d_\\pi(\\theta_i,\\theta_j)^2}{2\\sigma_\\theta^2}\\right), \\quad W_{ii}=0,\n$$\nwhere $d_\\pi(\\alpha,\\beta)=\\min\\big(|\\alpha-\\beta|,\\,\\pi-|\\alpha-\\beta|\\big)$. Normalize $W$ so that its spectral radius is exactly $1$ by dividing by its largest eigenvalue magnitude.\n3) For each test case and for each stimulus orientation $\\theta_m$, compute the recurrent steady state $\\mathbf{r}^\\star(\\theta_m)$ by iterating the threshold-linear dynamics $\\mathbf{r}_{t+1} = [\\mathbf{b}(\\theta_m) - \\gamma W \\mathbf{r}_t]_+$ until convergence to a fixed point within a small tolerance. You may use under-relaxation (constant convex combination with the previous iterate) to aid convergence; fixed points are invariant under such damping. Then compute the local Jacobian $J(\\mathbf{r}^\\star(\\theta_m))$ and its spectral radius $\\rho_m$ at the fixed point for each $\\theta_m$.\n4) For each test case, compute:\n   - The mean OSI gain across cells, defined as the average over $i$ of $\\mathrm{OSI}_i^{\\mathrm{post}} - \\mathrm{OSI}_i^{\\mathrm{pre}}$, where “pre” uses $r_i^{\\mathrm{ff}}(\\theta_m)$ and “post” uses $r_i^\\star(\\theta_m)$.\n   - The maximum Jacobian spectral radius across stimuli, $\\max_m \\rho_m$.\n   - A stability boolean that is true if and only if $\\rho_m  1$ for all $m$.\n\nNumerical specification to ensure reproducibility:\n- Use a square grid of size $N\\times N$ with $N = 64$ spanning $[-L,L]\\times[-L,L]$ with $L=1.0$. Use Riemann sum weights $\\Delta x=\\Delta y=2L/N$.\n- Use $K=16$ cells with preferred orientations $\\theta_i = i\\pi/K$ for $i\\in\\{0,1,\\dots,K-1\\}$.\n- Use $M=18$ stimulus orientations $\\theta_m = m\\pi/M$ for $m\\in\\{0,1,\\dots,M-1\\}$.\n- Use Gabor parameters $\\sigma_x=0.40$, $\\sigma_y=0.20$, $f_0=2.0$, carrier phase $0$, and stimulus parameters $f_s=2.0$, $\\sigma_w=0.80$.\n- Use $\\sigma_\\theta=0.35$ for the lateral kernel. Construct $W$ with $W_{ii}=0$ and then normalize it to have spectral radius exactly $1$.\n- For the fixed-point iteration, initialize $\\mathbf{r}_0=\\max(0,\\mathbf{b}(\\theta_m))$, use an under-relaxation factor $\\alpha=0.5$, a convergence tolerance of $10^{-8}$ in Euclidean norm difference between successive iterates, and a maximum of $1000$ iterations.\n\nTest suite:\nProvide results for the following four parameter sets, differing only in the inhibitory gain $\\gamma$:\n- Case A: $\\gamma = 0.00$.\n- Case B: $\\gamma = 0.40$.\n- Case C: $\\gamma = 0.90$.\n- Case D: $\\gamma = 1.10$.\n\nAngle unit requirement:\n- All angles, including $\\theta$, $\\theta_i$, and $\\theta_m$, must be treated in radians.\n\nFinal output format:\n- Your program should produce a single line of output containing the results as a comma-separated Python-style list of lists, one per test case, in the order [Case A, Case B, Case C, Case D]. Each inner list must be of the form [mean_osi_gain, max_spectral_radius, is_stable], where mean_osi_gain and max_spectral_radius are floating-point numbers and is_stable is a boolean. For example, the printed line must look like\n\"[[x1,y1,True],[x2,y2,False],[x3,y3,True],[x4,y4,True]]\"\nwith no spaces and no additional text. No physical units are required other than the specification that angles are in radians.",
            "solution": "The user's request is a valid and well-posed problem in computational neuroscience. I will proceed with a full solution.\n\n### Principle-Based Design\n\nThe problem requires the implementation and analysis of a simplified model of orientation processing in the primary visual cortex (V1). The model consists of several canonical components: Gabor filters as receptive fields of simple cells, half-wave rectification for firing rate conversion, and a recurrent network with lateral inhibition to sharpen tuning curves. The analysis involves quantifying this sharpening via the Orientation Selectivity Index (OSI) and assessing network stability through the spectral radius of the local Jacobian.\n\nThe solution is structured in a series of logical steps, from defining the model's components to simulating its dynamics and performing the required analyses.\n\n**1. Model Environment and Stimuli Definition**\n\nFirst, we establish the spatial domain and the set of stimuli. The model operates on a discrete grid representing a patch of the visual field.\n\n- **Spatial Grid**: A square grid of size $N \\times N$ represents the spatial coordinates $(x,y)$. The problem specifies $N=64$ points spanning the domain $[-L, L] \\times [-L, L]$ with $L=1.0$. The discretization step is uniform, $\\Delta x = \\Delta y = 2L/N$.\n- **Orientations**: We define two sets of orientations. One set for the preferred orientations of the $K=16$ model neurons, $\\theta_i = i\\pi/K$ for $i \\in \\{0, \\dots, K-1\\}$. The other for the $M=18$ orientations of the input stimuli, $\\theta_m = m\\pi/M$ for $m \\in \\{0, \\dots, M-1\\}$. All angles are in radians.\n- **Stimulus Creation**: The stimuli are sinusoidal gratings, a standard choice for probing orientation-selective cells. Each grating $s_{\\theta_m}(x,y)$ must be windowed by a Gaussian function $w(x,y)$ to ensure it is spatially localized and has finite energy. For each of the $M$ orientations, we generate a stimulus image on the $N \\times N$ grid:\n$$\nS_m(x,y) = s_{\\theta_m}(x,y)\\,w(x,y) = \\cos\\!\\left(2\\pi f_s\\,(x\\cos\\theta_m + y\\sin\\theta_m)\\right) \\exp\\!\\left(-\\frac{x^2+y^2}{2\\sigma_w^2}\\right)\n$$\nThe parameters are given as $f_s=2.0$ and $\\sigma_w=0.80$.\n\n**2. Simple Cell Receptive Fields and Feedforward Drive**\n\nThe receptive fields of V1 simple cells are modeled by Gabor filters. The response of a neuron to a stimulus is first calculated as a linear filtering operation.\n\n- **Gabor Filters**: For each of the $K$ neurons, a 2D Gabor filter $g_i(x,y)$ is generated. This function is a product of a Gaussian envelope and a sinusoidal carrier. Its orientation is determined by the cell's preferred orientation $\\theta_i$. The formula is:\n$$\ng_i(x,y) \\;=\\; \\exp\\!\\left(-\\frac{{x'}^2}{2\\sigma_x^2} - \\frac{{y'}^2}{2\\sigma_y^2}\\right)\\,\\cos\\!\\big(2\\pi f_0\\,x'\\big)\n$$\nwhere $(x', y')$ are rotated coordinates: $x' = x\\cos\\theta_i + y\\sin\\theta_i$ and $y' = -x\\sin\\theta_i + y\\cos\\theta_i$. The parameters are specified as $\\sigma_x=0.40$, $\\sigma_y=0.20$, and $f_0=2.0$.\n- **Linear Drive**: The linear drive $b_i(\\theta_m)$ of cell $i$ to stimulus $m$ is the inner product of the cell's Gabor filter and the windowed stimulus. On our discrete grid, this integral is approximated by a Riemann sum:\n$$\nb_i(\\theta_m) = \\iint g_i(x,y) S_m(x,y) \\,dx\\,dy \\approx \\sum_{j,k} g_i(x_j, y_k) S_m(x_j, y_k) (\\Delta x \\Delta y)\n$$\nThis computation is performed for all $K$ cells and all $M$ stimuli, resulting in a $K \\times M$ matrix of linear drives, $B = [b_{im}]$.\n- **Feedforward Response (Half-Wave Rectification)**: Neurons cannot have negative firing rates. This is modeled by a half-wave rectification nonlinearity. The feedforward response $r_i^{\\mathrm{ff}}(\\theta_m)$ is:\n$$\nr_i^{\\mathrm{ff}}(\\theta_m) = \\max\\big(0,\\,b_i(\\theta_m)\\big) = [b_i(\\theta_m)]_+\n$$\n\n**3. Lateral Interaction Network**\n\nThe model includes lateral connections between neurons, mediating inhibition. This is a key mechanism for sharpening orientation tuning.\n\n- **Weight Matrix Construction**: The connection strength $W_{ij}$ between cell $i$ and cell $j$ depends on the difference between their preferred orientations, $\\theta_i$ and $\\theta_j$. The problem specifies a circular-Gaussian kernel on the orientation space $[0, \\pi)$:\n$$\nW_{ij} \\;=\\; \\exp\\!\\left(-\\frac{d_\\pi(\\theta_i,\\theta_j)^2}{2\\sigma_\\theta^2}\\right) \\quad \\text{with} \\quad W_{ii}=0\n$$\nwhere $d_\\pi(\\alpha,\\beta)=\\min\\big(|\\alpha-\\beta|,\\,\\pi-|\\alpha-\\beta|\\big)$ is the wrap-around distance on the circle of orientations. The parameter $\\sigma_\\theta=0.35$ controls the width of inhibition in orientation space.\n- **Normalization**: To control the overall strength of interactions and ensure comparability, the weight matrix $W$ is normalized such that its spectral radius, $\\rho(W) = \\max_k |\\lambda_k(W)|$, is exactly $1$. This is achieved by calculating the matrix's eigenvalues, finding the one with the largest magnitude, and dividing all elements of $W$ by this value.\n\n**4. Recurrent Network Dynamics and Steady-State**\n\nThe final responses of neurons are not just the feedforward drive but are shaped by the recurrent inhibitory signals. The steady-state responses are the fixed point of the network dynamics.\n\n- **Fixed-Point Equation**: For a given stimulus orientation $\\theta$, the vector of steady-state responses $\\mathbf{r}(\\theta)$ must satisfy:\n$$\n\\mathbf{r}(\\theta) \\;=\\; \\big[\\mathbf{b}(\\theta) \\;-\\; \\gamma\\,W\\,\\mathbf{r}(\\theta)\\big]_+\n$$\nwhere $\\mathbf{b}(\\theta)$ is the vector of linear drives, $\\gamma$ is the inhibitory gain, and $[\\cdot]_+$ is element-wise rectification.\n- **Iterative Solution**: This fixed-point equation is solved numerically for each stimulus orientation $\\theta_m$. We use an iterative scheme with under-relaxation to enhance stability and convergence:\n$$\n\\mathbf{r}_{t+1} = (1 - \\alpha) \\mathbf{r}_t + \\alpha \\left[\\mathbf{b}(\\theta_m) - \\gamma W \\mathbf{r}_t\\right]_+\n$$\nThe iteration starts with the feedforward response, $\\mathbf{r}_0 = \\mathbf{r}^{\\mathrm{ff}}(\\theta_m) = [\\mathbf{b}(\\theta_m)]_+$, and continues until the change between successive iterates, $\\|\\mathbf{r}_{t+1} - \\mathbf{r}_t\\|_2$, falls below a tolerance of $10^{-8}$. The specified under-relaxation factor is $\\alpha=0.5$. The final converged vector is the steady-state response $\\mathbf{r}^\\star(\\theta_m)$.\n\n**5. Analysis of Tuning and Stability**\n\nThe final step is to analyze the results of the simulation for each value of the inhibitory gain $\\gamma$.\n\n- **Orientation Selectivity Index (OSI)**: The OSI quantifies how sharply tuned a neuron is to orientation. We use the circular-moment definition, which is robust and widely used:\n$$\n\\mathrm{OSI}_i \\;=\\; \\frac{\\left|\\sum_{m=1}^M r_i(\\theta_m)\\,e^{\\mathrm{i}\\,2\\theta_m}\\right|}{\\sum_{m=1}^M r_i(\\theta_m)}\n$$\nThe numerator represents the length of a resultant vector in the complex plane, where each response $r_i(\\theta_m)$ contributes a vector of that magnitude at an angle of $2\\theta_m$. The factor of $2$ accounts for the $\\pi$-periodicity of orientation. We compute this for each cell $i$ using both the pre-inhibition (feedforward) responses $r_i^{\\mathrm{ff}}$ and the post-inhibition (steady-state) responses $r_i^\\star$. The mean OSI gain is the average difference: $\\langle \\mathrm{OSI}^{\\mathrm{post}} - \\mathrm{OSI}^{\\mathrm{pre}} \\rangle_i$.\n- **Local Stability Analysis**: The stability of the network's steady-state responses is critical. An unstable network would exhibit oscillations or chaotic activity. Local stability of a fixed point $\\mathbf{r}^\\star$ is determined by the spectral radius of the Jacobian of the iteration map evaluated at $\\mathbf{r}^\\star$. The Jacobian is given by:\n$$\nJ(\\mathbf{r}^\\star) \\;=\\; -\\gamma\\,D(\\mathbf{r}^\\star)\\,W\n$$\nwhere $D(\\mathbf{r}^\\star)$ is a diagonal matrix with $D_{ii}=1$ if the corresponding neuron is active ($r_i^\\star  0$) and $D_{ii}=0$ otherwise. The fixed point is locally stable if the spectral radius $\\rho(J)  1$. We compute this spectral radius $\\rho_m = \\rho(J(\\mathbf{r}^\\star(\\theta_m)))$ for each stimulus orientation $\\theta_m$. The overall stability metric for a given $\\gamma$ is the maximum spectral radius found across all stimuli, $\\max_m \\rho_m$. The system is deemed stable if and only if this maximum value is less than $1$.\n\nThese steps will be implemented for each of the four specified values of $\\gamma$, and the resulting metrics (mean OSI gain, max spectral radius, stability) will be collected and formatted as required.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Implements a simulation-based analysis of orientation selectivity\n    in a simplified V1 simple cell network model.\n    \"\"\"\n\n    # 1. Numerical Specifications and Setup\n    N = 64  # Grid size\n    L = 1.0  # Spatial extent [-L, L]\n    K = 16  # Number of cells\n    M = 18  # Number of stimulus orientations\n    \n    # Gabor parameters\n    SIGMA_X = 0.40\n    SIGMA_Y = 0.20\n    F0 = 2.0\n    \n    # Stimulus parameters\n    F_S = 2.0\n    SIGMA_W = 0.80\n    \n    # Network parameters\n    SIGMA_THETA = 0.35\n    ALPHA = 0.5  # Under-relaxation factor\n    TOLERANCE = 1e-8\n    MAX_ITER = 1000\n\n    # Test suite for inhibitory gain gamma\n    gammas = [0.00, 0.40, 0.90, 1.10]\n\n    # Create spatial grid\n    grid_pts = np.linspace(-L, L, N)\n    x, y = np.meshgrid(grid_pts, grid_pts)\n    dx = dy = 2.0 * L / N\n\n    # Create orientation sets\n    thetas_i = np.arange(K) * np.pi / K  # Cell preferred orientations\n    thetas_m = np.arange(M) * np.pi / M  # Stimulus orientations\n\n    # 2. Pre-compute Stimuli and Gabor Filters\n    \n    # Window function\n    window = np.exp(-(x**2 + y**2) / (2 * SIGMA_W**2))\n\n    # Stimuli (M of them, each N x N)\n    stimuli = np.zeros((M, N, N))\n    for m, theta_m in enumerate(thetas_m):\n        stimulus_grating = np.cos(2 * np.pi * F_S * (x * np.cos(theta_m) + y * np.sin(theta_m)))\n        stimuli[m, :, :] = stimulus_grating * window\n\n    # Gabor filters (K of them, each N x N)\n    gabor_filters = np.zeros((K, N, N))\n    for i, theta_i in enumerate(thetas_i):\n        x_prime = x * np.cos(theta_i) + y * np.sin(theta_i)\n        y_prime = -x * np.sin(theta_i) + y * np.cos(theta_i)\n        envelope = np.exp(-(x_prime**2 / (2 * SIGMA_X**2) + y_prime**2 / (2 * SIGMA_Y**2)))\n        carrier = np.cos(2 * np.pi * F0 * x_prime)\n        gabor_filters[i, :, :] = envelope * carrier\n\n    # 3. Compute Linear Drives and Feedforward Responses\n    B = np.zeros((K, M))  # Linear drives matrix\n    for i in range(K):\n        for m in range(M):\n            # Riemann sum for inner product\n            B[i, m] = np.sum(gabor_filters[i] * stimuli[m]) * dx * dy\n    \n    R_ff = np.maximum(0, B) # Feedforward responses\n\n    # 4. Construct and Normalize Lateral Interaction Matrix W\n    def circular_dist(a, b, period=np.pi):\n        diff = np.abs(a - b)\n        return np.minimum(diff, period - diff)\n\n    W = np.zeros((K, K))\n    for i in range(K):\n        for j in range(K):\n            if i == j:\n                W[i, j] = 0\n            else:\n                dist_sq = circular_dist(thetas_i[i], thetas_i[j])**2\n                W[i, j] = np.exp(-dist_sq / (2 * SIGMA_THETA**2))\n\n    # Normalize W to have spectral radius of 1\n    eigenvalues_w = np.linalg.eigvals(W)\n    spectral_radius_w = np.max(np.abs(eigenvalues_w))\n    W /= spectral_radius_w\n\n    # 5. Define analysis functions\n    def compute_osi(responses, thetas):\n        \"\"\"Computes OSI for all cells.\"\"\"\n        # responses is K x M, thetas is M\n        numerator = np.abs(np.dot(responses, np.exp(2j * thetas)))\n        denominator = np.sum(responses, axis=1)\n        \n        # Handle case where a cell is silent\n        # np.divide handles division by zero, resulting in zero\n        osi = np.divide(numerator, denominator, out=np.zeros_like(numerator, dtype=float), where=denominator!=0)\n        return osi\n\n    # Compute pre-inhibition OSIs\n    osi_pre = compute_osi(R_ff, thetas_m)\n\n    # 6. Main loop over test cases\n    final_results = []\n    for gamma in gammas:\n        R_star = np.zeros((K, M))  # Steady-state responses\n        rhos = []  # Spectral radii for each stimulus\n\n        for m in range(M):\n            b_m = B[:, m]\n            \n            # Find fixed point by iteration\n            r_t = np.maximum(0, b_m)\n            for _ in range(MAX_ITER):\n                r_prime_t1 = np.maximum(0, b_m - gamma * np.dot(W, r_t))\n                r_t1 = (1 - ALPHA) * r_t + ALPHA * r_prime_t1\n                if np.linalg.norm(r_t1 - r_t)  TOLERANCE:\n                    break\n                r_t = r_t1\n            r_star_m = r_t\n            R_star[:, m] = r_star_m\n\n            # Compute Jacobian and its spectral radius\n            if gamma == 0:\n                rho_m = 0.0\n            else:\n                D = np.diag(r_star_m  0)\n                J = -gamma * np.dot(D, W)\n                eigenvalues_j = np.linalg.eigvals(J)\n                rho_m = np.max(np.abs(eigenvalues_j))\n            rhos.append(rho_m)\n\n        # Compute post-inhibition OSIs\n        osi_post = compute_osi(R_star, thetas_m)\n        \n        # Calculate final metrics for this case\n        mean_osi_gain = np.mean(osi_post - osi_pre)\n        max_spectral_radius = np.max(rhos)\n        is_stable = max_spectral_radius  1.0\n\n        final_results.append([mean_osi_gain, max_spectral_radius, is_stable])\n\n    # 7. Format and print the final output\n    # Use repr and string replacement for exact, space-free formatting\n    output_str = repr(final_results).replace(\" \", \"\")\n    print(output_str)\n\nsolve()\n```"
        },
        {
            "introduction": "A successful computational model must not only be internally consistent but also reproduce key experimental observations. This practice focuses on model validation, challenging you to implement a model incorporating divisive normalization—a canonical mechanism for gain control in the cortex . You will compute several well-known experimental signatures, such as contrast-invariant tuning and cross-orientation suppression, to systematically evaluate whether your model behaves like a real V1 neuron.",
            "id": "4000032",
            "problem": "You are given a family of simplified neuronal models for orientation tuning in the primary visual cortex, constructed from a feedforward drive and a divisive normalization stage. The stimulus is a drifting sinusoidal grating characterized by an orientation in degrees and a contrast in arbitrary units. The objective is to evaluate experimental signatures of orientation selectivity and validate models against criteria derived from widely observed phenomena.\n\nFundamental base. Use the following facts as the starting point for modeling and derivation:\n- The feedforward drive of an orientation-tuned filter responding to sinusoidal gratings is proportional to the contrast and a periodic function of orientation, with period $180^{\\circ}$, reflecting that orientation is a direction without sign. For even-symmetric energy models, the orientation dependence can be represented by a cosine of double the orientation difference.\n- Neuronal input-output transformations can be approximated by half-wave rectification and a power-law exponent capturing spike generation nonlinearities.\n- Divisive normalization captures the effect of network-level inhibitory stabilization and gain control, widely reported in visual cortex, and is modeled by scaling the output by a factor that grows with total contrast.\n\nModel definition. Let the preferred orientation be $\\theta_0$ in degrees. For a stimulus orientation $\\theta$ in degrees and contrast $c \\ge 0$, define the feedforward drive as\n$$\nD(\\theta;c) = k\\,c\\,[\\,b + m\\,\\cos(2(\\theta - \\theta_0))\\,],\n$$\nwhere $k \\gt 0$ is a gain, $b \\ge 0$ is a baseline drive, and $m \\ge 0$ controls orientation modulation amplitude. The neural nonlinearity applies half-wave rectification followed by a power-law with exponent $p \\ge 1$:\n$$\nN(D) = \\max(D,0)^p.\n$$\nDivisive normalization scales this by a factor depending on contrast with strength $\\gamma \\ge 0$:\n$$\nR(\\theta;c) = \\frac{N(D(\\theta;c))}{1 + \\gamma\\,c}.\n$$\nFor cross-orientation suppression, consider adding an orthogonal mask grating with contrast $c_m \\ge 0$. The combined drive assumes linear summation with efficiency $\\alpha \\ge 0$ for the mask, and the normalization depends on the total contrast:\n$$\nD_{\\text{mask}}(\\theta;c,c_m) = D(\\theta;c) + \\alpha\\,k\\,c_m\\,[\\,m\\,\\cos(2(\\theta - \\theta_0 - 90^{\\circ}))\\,],\n$$\n$$\nR_{\\text{mask}}(\\theta;c,c_m) = \\frac{\\max(D_{\\text{mask}}(\\theta;c,c_m),0)^p}{1 + \\gamma\\,(c + c_m)}.\n$$\n\nExperimental signatures and validation metrics. For all computations, angles must be in degrees.\n1. Preferred orientation stability: Let $\\theta_{\\text{pref}}(c)$ be the orientation in $[0,180)$ that maximizes $R(\\theta;c)$. Define the preferred orientation stability metric\n$$\n\\Delta\\theta_{\\text{pref}} = \\min\\left(\\left|\\theta_{\\text{pref}}(c_h) - \\theta_{\\text{pref}}(c_\\ell)\\right|, 180^{\\circ} - \\left|\\theta_{\\text{pref}}(c_h) - \\theta_{\\text{pref}}(c_\\ell)\\right|\\right),\n$$\nwith $c_\\ell$ and $c_h$ the low and high contrasts.\n2. Full width at half maximum (FWHM) bandwidth: For a given contrast $c$, define $W(c)$ as the width in degrees around $\\theta_{\\text{pref}}(c)$ of the contiguous region on $[0,180)$ where $R(\\theta;c)$ is at least half of its peak value at that $c$. If $R(\\theta;c)$ is identically zero for all $\\theta$, set $W(c)=180$.\n3. Contrast invariance metric (CIM):\n$$\n\\mathrm{CIM} = \\frac{\\left|W(c_h) - W(c_\\ell)\\right|}{W(c_h)}.\n$$\n4. Cross-orientation suppression index (XSI): At high contrast $c_h$, compare the peak response to the masked response at the same orientation:\n$$\n\\mathrm{XSI} = \\begin{cases}\n\\dfrac{R(\\theta_{\\text{pref}}(c_h);c_h) - R_{\\text{mask}}(\\theta_{\\text{pref}}(c_h);c_h,c_m)}{R(\\theta_{\\text{pref}}(c_h);c_h)},  R(\\theta_{\\text{pref}}(c_h);c_h) \\gt 0,\\\\[6pt]\n0,  \\text{otherwise.}\n\\end{cases}\n$$\n5. Orientation selectivity index (OSI) at high contrast:\n$$\n\\mathrm{OSI} = \\begin{cases}\n1 - \\dfrac{R((\\theta_{\\text{pref}}(c_h)+90^{\\circ}) \\pmod{180^{\\circ}};c_h)}{R(\\theta_{\\text{pref}}(c_h);c_h)},  R(\\theta_{\\text{pref}}(c_h);c_h) \\gt 0,\\\\[6pt]\n0,  \\text{otherwise.}\n\\end{cases}\n$$\n\nValidation criteria. A model instance is declared to pass if all of the following hold:\n- $\\Delta\\theta_{\\text{pref}} \\le 5^{\\circ}$,\n- $\\mathrm{CIM} \\le 0.1$,\n- $\\mathrm{XSI} \\ge 0.2$,\n- $\\mathrm{OSI} \\ge 0.5$.\n\nComputational requirements. Your program must:\n- Implement the above model and metrics, sampling $\\theta$ over $[0,180)$ with sufficient resolution to estimate $\\theta_{\\text{pref}}(c)$ and $W(c)$ accurately. Use degrees for all angle computations.\n- For FWHM, determine the contiguous segment around the peak where $R(\\theta;c)$ is at least half-maximum, with periodic boundary conditions on $[0,180)$, and report its width in degrees.\n\nTest suite. Evaluate the following model parameter sets, where each test case is a tuple:\n($k, b, m, p, \\gamma, \\alpha, \\theta_0, c_\\ell, c_h, c_m$).\nUse these four cases:\n- Case 1 (happy path): $(1.0, 0.3, 0.7, 2.0, 0.8, 1.0, 40.0, 0.1, 1.0, 1.0)$.\n- Case 2 (no normalization): $(1.0, 0.3, 0.7, 1.0, 0.0, 0.5, 40.0, 0.1, 1.0, 1.0)$.\n- Case 3 (boundary high nonlinearity): $(1.0, 0.05, 1.0, 3.0, 1.5, 0.5, 10.0, 0.05, 0.8, 0.8)$.\n- Case 4 (edge case no modulation): $(1.0, 0.3, 0.0, 2.0, 0.5, 1.0, 75.0, 0.1, 1.0, 1.0)$.\n\nFinal output format. Your program should produce a single line of output containing the boolean validation results for the four test cases as a comma-separated list enclosed in square brackets (e.g., \"[True,False,True,False]\").",
            "solution": "The problem requires the implementation and validation of a simplified computational model of orientation selectivity in primary visual cortex neurons. The model's response to oriented sinusoidal gratings is defined by a feedforward drive, a nonlinear transformation, and divisive normalization. We are tasked with computing several established experimental signatures of orientation tuning for four distinct sets of model parameters. These signatures are: preferred orientation stability ($\\Delta\\theta_{\\text{pref}}$), a contrast invariance metric for tuning bandwidth (CIM), a cross-orientation suppression index (XSI), and an orientation selectivity index (OSI). Finally, each parameter set, or model instance, is validated against a set of criteria based on these metrics.\n\nFirst, we will construct the core functions representing the neuronal response, followed by the implementation of functions to compute each of the specified metrics. We will then assemble these components into a cohesive validation procedure to evaluate each test case. All angular computations will be performed in degrees as specified.\n\nThe model is defined by a series of transformations. The feedforward drive $D$ for a stimulus of orientation $\\theta$ and contrast $c$ is given by:\n$$\nD(\\theta;c) = k\\,c\\,[\\,b + m\\,\\cos(2(\\theta - \\theta_0))\\,]\n$$\nwhere $k$, $b$, $m$, and $\\theta_0$ are model parameters. The input angles $\\theta$ and $\\theta_0$ are in degrees, so the argument of the cosine function must be converted to radians for computation. This drive $D$ is then passed through a half-wave rectification and power-law nonlinearity $N(D) = \\max(D,0)^p$. The final response $R$ is obtained by divisive normalization:\n$$\nR(\\theta;c) = \\frac{N(D(\\theta;c))}{1 + \\gamma\\,c}\n$$\n\nFor the cross-orientation suppression experiment, a masking grating is introduced. The combined drive $D_{\\text{mask}}$ is defined as:\n$$\nD_{\\text{mask}}(\\theta;c,c_m) = D(\\theta;c) + \\alpha\\,k\\,c_m\\,[\\,m\\,\\cos(2(\\theta - \\theta_0 - 90^{\\circ}))\\,]\n$$\nUsing the trigonometric identity $\\cos(x - 180^{\\circ}) = -\\cos(x)$, the term for the mask can be simplified: $\\cos(2(\\theta - \\theta_0) - 180^{\\circ}) = -\\cos(2(\\theta - \\theta_0))$. This simplifies the combined drive to:\n$$\nD_{\\text{mask}}(\\theta;c,c_m) = k\\,c\\,b + k\\,m\\,(c - \\alpha\\,c_m)\\,\\cos(2(\\theta - \\theta_0))\n$$\nThe response to the masked stimulus, $R_{\\text{mask}}$, applies the same nonlinearity but with a normalization term that depends on the sum of contrasts $c$ and $c_m$:\n$$\nR_{\\text{mask}}(\\theta;c,c_m) = \\frac{\\max(D_{\\text{mask}}(\\theta;c,c_m),0)^p}{1 + \\gamma\\,(c + c_m)}\n$$\n\nTo numerically compute the metrics, we must sample the orientation $\\theta$ over its range $[0, 180)$. A sufficiently high resolution is needed for accurate estimation of the peak orientation and tuning width. We will use a discrete set of angles from $0^{\\circ}$ to $180^{\\circ}$ with a fine step, for example, $0.1^{\\circ}$.\n\nThe metrics are calculated as follows:\n\n1.  **Preferred Orientation $\\theta_{\\text{pref}}(c)$**: For a given contrast $c$, we compute $R(\\theta;c)$ for all sampled orientations $\\theta$ and find the orientation that yields the maximum response. Numerically, this is achieved by finding the index of the maximum value in the response array and retrieving the corresponding angle.\n    The stability metric $\\Delta\\theta_{\\text{pref}}$ is then calculated using the preferred orientations at low ($c_\\ell$) and high ($c_h$) contrasts, accounting for the circular nature of orientation space with a period of $180^{\\circ}$.\n\n2.  **Full Width at Half Maximum (FWHM) $W(c)$**: For a given contrast $c$, we first find the peak response $R_{\\text{peak}} = R(\\theta_{\\text{pref}}(c);c)$. The half-maximum value is $0.5 \\times R_{\\text{peak}}$. The FWHM is the total width in degrees of the contiguous region around the peak where the response is at or above this half-maximum value. Given the unimodal nature of the tuning curves produced by this model (due to the single cosine term), this region is guaranteed to be contiguous. Therefore, we can find all orientations where $R(\\theta;c) \\ge 0.5 \\times R_{\\text{peak}}$ and sum their collective width. The special case where $R(\\theta;c)$ is identically zero for all $\\theta$ results in $W(c) = 180^{\\circ}$ by definition.\n\n3.  **Contrast Invariance Metric (CIM)**: This metric quantifies the change in tuning width with contrast. It is computed from the FWHM values at low ($c_\\ell$) and high ($c_h$) contrasts: $\\mathrm{CIM} = |W(c_h) - W(c_\\ell)| / W(c_h)$. If $W(c_h)=0$, this implies a potential division by zero, but given the FWHM definition, $W(c_h)$ will be positive if the peak response is positive.\n\n4.  **Cross-Orientation Suppression Index (XSI)**: This measures the reduction in response at the preferred orientation due to a superimposed orthogonal mask. It is calculated at high contrast $c_h$ with a mask of contrast $c_m$:\n    $$\n    \\mathrm{XSI} = \\frac{R(\\theta_{\\text{pref}}(c_h);c_h) - R_{\\text{mask}}(\\theta_{\\text{pref}}(c_h);c_h,c_m)}{R(\\theta_{\\text{pref}}(c_h);c_h)}\n    $$\n    If the peak response is not positive, XSI is defined as $0$.\n\n5.  **Orientation Selectivity Index (OSI)**: This index compares the response at the preferred orientation to the response at the orthogonal orientation ($90^{\\circ}$ away). It is calculated at high contrast $c_h$:\n    $$\n    \\mathrm{OSI} = 1 - \\frac{R(\\theta_{\\text{pref}}(c_h)+90^{\\circ};c_h)}{R(\\theta_{\\text{pref}}(c_h);c_h)}\n    $$\n    The orthogonal orientation is taken modulo $180^{\\circ}$. Again, if the peak response is not positive, OSI is defined as $0$.\n\nFinally, for each parameter set, the model is declared to \"pass\" validation if all four conditions are met:\n-   $\\Delta\\theta_{\\text{pref}} \\le 5^{\\circ}$\n-   $\\mathrm{CIM} \\le 0.1$\n-   $\\mathrm{XSI} \\ge 0.2$\n-   $\\mathrm{OSI} \\ge 0.5$\n\nThe implementation will process each of the four test cases, calculate the four metrics, check against the validation criteria, and produce a boolean result.",
            "answer": "```python\nimport numpy as np\n\nclass OrientationModelValidator:\n    \"\"\"\n    Implements and validates a model of neuronal orientation selectivity.\n    \"\"\"\n    def __init__(self, k, b, m, p, gamma, alpha, theta_0):\n        self.k = k\n        self.b = b\n        self.m = m\n        self.p = p\n        self.gamma = gamma\n        self.alpha = alpha\n        self.theta_0 = theta_0\n        \n        # High-resolution sampling of orientation space in degrees\n        self.num_thetas = 3600\n        self.theta_range = np.linspace(0.0, 180.0, self.num_thetas, endpoint=False)\n        self.theta_step = 180.0 / self.num_thetas\n\n    def _drive(self, theta, c):\n        \"\"\"Calculates the feedforward drive D(theta; c).\"\"\"\n        cos_term = np.cos(np.deg2rad(2 * (theta - self.theta_0)))\n        return self.k * c * (self.b + self.m * cos_term)\n\n    def _drive_mask(self, theta, c, c_m):\n        \"\"\"Calculates the feedforward drive with an orthogonal mask.\"\"\"\n        # Using the simplified form D_mask = k*c*b + k*m*(c - alpha*c_m)*cos(...)\n        cos_term = np.cos(np.deg2rad(2 * (theta - self.theta_0)))\n        return self.k * c * self.b + self.k * self.m * (c - self.alpha * c_m) * cos_term\n\n    def _nonlinearity(self, drive):\n        \"\"\"Applies half-wave rectification and power-law nonlinearity.\"\"\"\n        return np.maximum(drive, 0)**self.p\n\n    def get_response(self, theta, c):\n        \"\"\"Calculates the final response R(theta; c).\"\"\"\n        drive = self._drive(theta, c)\n        n_drive = self._nonlinearity(drive)\n        return n_drive / (1.0 + self.gamma * c)\n\n    def get_masked_response(self, theta, c, c_m):\n        \"\"\"Calculates the response R_mask with an orthogonal mask.\"\"\"\n        drive_mask = self._drive_mask(theta, c, c_m)\n        n_drive_mask = self._nonlinearity(drive_mask)\n        return n_drive_mask / (1.0 + self.gamma * (c + c_m))\n\n    def _get_theta_pref(self, c):\n        \"\"\"Finds the preferred orientation for a given contrast.\"\"\"\n        if c == 0:\n            return 0.0 # Response is zero, convention to return 0\n        responses = self.get_response(self.theta_range, c)\n        peak_idx = np.argmax(responses)\n        return self.theta_range[peak_idx]\n\n    def _get_fwhm(self, c):\n        \"\"\"Calculates the Full Width at Half Maximum (FWHM).\"\"\"\n        responses = self.get_response(self.theta_range, c)\n        \n        if np.all(responses == 0):\n            return 180.0\n\n        peak_response = np.max(responses)\n        \n        if peak_response = 0:\n            return 0.0\n            \n        half_max = 0.5 * peak_response\n        above_half_max = responses = half_max\n        \n        # For this model class, the suprathreshold region is contiguous.\n        # So we can just count the number of points above half-max.\n        width_in_points = np.sum(above_half_max)\n        return width_in_points * self.theta_step\n\n    def run_validation(self, c_l, c_h, c_m):\n        \"\"\"Runs all validation checks and returns a boolean result.\"\"\"\n        \n        # 1. Preferred orientation stability\n        theta_pref_low = self._get_theta_pref(c_l)\n        theta_pref_high = self._get_theta_pref(c_h)\n        diff = np.abs(theta_pref_high - theta_pref_low)\n        delta_theta_pref = np.min([diff, 180.0 - diff])\n        \n        # 2. Contrast invariance metric (CIM)\n        w_low = self._get_fwhm(c_l)\n        w_high = self._get_fwhm(c_h)\n        if w_high == 0.0:\n            cim = np.inf if w_low  0 else 0.0\n        else:\n            cim = np.abs(w_high - w_low) / w_high\n\n        # Response at high contrast for XSI and OSI\n        responses_high = self.get_response(self.theta_range, c_h)\n        peak_response_high = np.max(responses_high)\n\n        # 3. Cross-orientation suppression index (XSI)\n        if peak_response_high = 0:\n            xsi = 0.0\n        else:\n            masked_response_at_pref = self.get_masked_response(theta_pref_high, c_h, c_m)\n            unmasked_response_at_pref = self.get_response(theta_pref_high, c_h)\n            xsi = (unmasked_response_at_pref - masked_response_at_pref) / unmasked_response_at_pref\n        \n        # 4. Orientation selectivity index (OSI)\n        if peak_response_high = 0:\n            osi = 0.0\n        else:\n            theta_ortho = (theta_pref_high + 90.0) % 180.0\n            # Find the closest sample to theta_ortho\n            ortho_idx = np.argmin(np.abs(self.theta_range - theta_ortho))\n            ortho_response = responses_high[ortho_idx]\n            unmasked_response_at_pref = self.get_response(theta_pref_high, c_h)\n            osi = 1.0 - (ortho_response / unmasked_response_at_pref)\n\n        # Final validation\n        valid_delta_theta = delta_theta_pref = 5.0\n        valid_cim = cim = 0.1\n        valid_xsi = xsi = 0.2\n        valid_osi = osi = 0.5\n        \n        is_valid = all([valid_delta_theta, valid_cim, valid_xsi, valid_osi])\n        return is_valid\n\ndef solve():\n    \"\"\"\n    Evaluates the validation criteria for the four specified test cases.\n    \"\"\"\n    test_cases = [\n        # (k,    b,   m,   p, gamma, alpha, theta_0, c_l,  c_h,  c_m)\n        (1.0, 0.3, 0.7, 2.0,   0.8,   1.0,    40.0, 0.1,  1.0,  1.0),\n        (1.0, 0.3, 0.7, 1.0,   0.0,   0.5,    40.0, 0.1,  1.0,  1.0),\n        (1.0, 0.05, 1.0, 3.0,  1.5,   0.5,    10.0, 0.05, 0.8,  0.8),\n        (1.0, 0.3, 0.0, 2.0,   0.5,   1.0,    75.0, 0.1,  1.0,  1.0),\n    ]\n\n    results = []\n    for params in test_cases:\n        k, b, m, p, gamma, alpha, theta_0, c_l, c_h, c_m = params\n        model = OrientationModelValidator(k, b, m, p, gamma, alpha, theta_0)\n        is_valid = model.run_validation(c_l, c_h, c_m)\n        results.append(str(is_valid))\n\n    # Correcting the output format to match exactly: [True,False,True,False]\n    print(f\"[{','.join(r.capitalize() for r in results)}]\")\n\n# The original problem asked for a string like \"[True,False,True,False]\".\n# The provided solution produces \"[True,False,True,False]\". I've updated the \n# python script to produce the exact requested format, but the original code \n# was also functionally correct. I will edit the provided answer to exactly\n# match the requirements.\n\ndef solve_final():\n    test_cases = [\n        (1.0, 0.3, 0.7, 2.0,   0.8,   1.0,    40.0, 0.1,  1.0,  1.0),\n        (1.0, 0.3, 0.7, 1.0,   0.0,   0.5,    40.0, 0.1,  1.0,  1.0),\n        (1.0, 0.05, 1.0, 3.0,  1.5,   0.5,    10.0, 0.05, 0.8,  0.8),\n        (1.0, 0.3, 0.0, 2.0,   0.5,   1.0,    75.0, 0.1,  1.0,  1.0),\n    ]\n    results = []\n    for params in test_cases:\n        k, b, m, p, gamma, alpha, theta_0, c_l, c_h, c_m = params\n        model = OrientationModelValidator(k, b, m, p, gamma, alpha, theta_0)\n        is_valid = model.run_validation(c_l, c_h, c_m)\n        results.append(is_valid)\n    print(str(results).replace(\" \", \"\"))\n\nsolve_final()\n```"
        }
    ]
}