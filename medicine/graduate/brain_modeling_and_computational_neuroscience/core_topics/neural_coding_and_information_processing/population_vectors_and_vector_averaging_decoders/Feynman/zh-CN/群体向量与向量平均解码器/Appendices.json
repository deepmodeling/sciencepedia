{
    "hands_on_practices": [
        {
            "introduction": "在将解码模型应用于真实的神经数据时，第一步通常是估计神经元本身的属性。本练习将引导您完成一个完整的实践流程：首先，模拟神经数据；其次，使用线性回归从数据中估计调谐曲线参数；最后，利用这些估计值构建并测试一个向量平均解码器。这个练习构成了许多计算神经科学分析的基础工作流程。",
            "id": "4010760",
            "problem": "您有一项关于平面方向刺激的神经群体编码的计算神经科学任务。假设一个神经元群体，其中每个神经元都表现出相对于刺激方向的余弦调谐特性，并且其放电过程被建模为泊松点过程。任务目标是根据训练数据估计每个神经元的调谐参数和偏好方向，然后使用向量平均解码器对新刺激进行解码。整个任务必须实现为单个可运行的程序。\n\n基本原理和假设：\n- 每个神经元 $i$ 都有一个未知的偏好方向 $\\theta_i$，并根据带有基线的余弦调谐定律产生放电。期望放电率是刺激方向的函数。在试验 $t$ 中的神经响应被建模为一个泊松随机变量，其均值等于在该试验中呈现的刺激下的放电率。\n- 刺激方向在圆上表示，角度必须以弧度处理。一个基于群体向量和向量平均的解码器为每次试验生成单个方向估计值。\n\n您的程序必须对测试套件中的每个测试用例执行以下步骤：\n1. 生成训练数据：\n   - 构建一个包含 $N$ 个神经元的群体，具有指定的偏好方向 $\\{\\theta_i\\}_{i=1}^N$、基线 $\\{b_i\\}_{i=1}^N$（单位：放电次数/秒）和增益 $\\{g_i\\}_{i=1}^N$（单位：放电次数/秒），其中神经元 $i$ 在刺激角度 $\\phi$ 下的期望放电率为 $b_i + g_i \\cos(\\phi - \\theta_i)$。\n   - 模拟 $T$ 次训练试验。在每次试验 $t$ 中，从区间 $[-\\pi, \\pi)$ 中均匀抽取一个刺激角度 $\\phi_t$，并对每个神经元 $i$，根据均值为 $b_i + g_i \\cos(\\phi_t - \\theta_i)$ 的泊松分布抽取一个放电计数 $k_{i,t}$。\n2. 估计调谐参数：\n   - 使用训练数据 $\\{(\\phi_t, k_{i,t})\\}$，为每个神经元 $i$ 估计其基线 $\\hat{b}_i$、增益 $\\hat{g}_i$ 和偏好方向 $\\hat{\\theta}_i$。此过程仅依赖于余弦调谐结构和线性回归原理，其基础是将相移余弦转换为 $\\cos(\\phi)$ 和 $\\sin(\\phi)$ 项的线性组合的三角恒等式。\n   - 为了数值稳定性，忽略任何估计增益低于一个小的阈值 $\\varepsilon$ 的神经元；使用 $\\varepsilon = 10^{-3}$ 放电次数/秒。\n3. 生成测试数据并解码：\n   - 模拟 $K$ 次测试试验，其中新的刺激角度 $\\phi'_u$ 从 $[-\\pi, \\pi)$ 中均匀抽取，泊松放电计数 $k'_{i,u}$ 根据真实参数 $(b_i, g_i, \\theta_i)$ 生成。\n   - 使用源自群体向量概念的向量平均解码器对每个测试刺激角度进行解码：将每个神经元的贡献视为一个单位向量，其方向为该神经元的估计偏好方向，权重为一个非负活动量，该活动量与其减去基线后的放电计数成正比。具体来说，对于神经元 $i$，使用权重 $\\max(0, k'_{i,u} - \\hat{b}_i)$，并且只组合满足 $\\hat{g}_i \\ge \\varepsilon$ 的神经元。\n   - 解码器必须为每次测试试验 $u$ 生成一个以弧度为单位的角度估计值 $\\hat{\\phi}'_u$。\n4. 评估性能：\n   - 计算测试试验的平均绝对环形误差，其中解码角度 $\\hat{\\phi}$ 与真实角度 $\\phi$ 之间的绝对环形误差为 $d(\\hat{\\phi}, \\phi) = \\min_{k \\in \\mathbb{Z}} |\\hat{\\phi} - \\phi + 2\\pi k|$。结果以弧度表示。\n\n角度单位要求：所有角度必须以弧度处理和报告。\n\n物理单位要求：所有放电率必须以“放电次数/秒”为单位处理。\n\n最终输出格式：您的程序应生成单行输出，其中包含每个测试用例的平均绝对环形误差，格式为方括号内以逗号分隔的列表（例如，$[result_1,result_2,result_3]$），其中每个 $result_j$ 是一个以弧度为单位的浮点数。\n\n测试套件：\n- 用例 1（理想路径，多样化增益，充足训练）：\n  - $N = 8$, $T = 200$, $K = 50$。\n  - 偏好方向：$\\theta_i$ 在 $[-\\pi, \\pi)$ 上均匀分布，即 $\\theta_i = -\\pi + \\frac{2\\pi (i-1)}{N}$，对于 $i = 1, \\dots, N$。\n  - 基线：对于所有 $i$，$b_i = 20$（放电次数/秒）。\n  - 增益：$(g_1, g_2, \\dots, g_8) = (14, 12, 16, 10, 18, 11, 15, 13)$（放电次数/秒）。\n  - 伪随机数生成器种子：训练种子 $= 101$，测试种子 $= 202$。\n- 用例 2（零增益神经元的边界条件）：\n  - $N = 8$, $T = 60$, $K = 40$。\n  - 偏好方向：$\\theta_i$ 在 $[-\\pi, \\pi)$ 上均匀分布。\n  - 基线：对于所有 $i$，$b_i = 20$（放电次数/秒）。\n  - 增益：$(g_1, g_2, \\dots, g_8) = (0, 0, 12, 10, 8, 0, 6, 0)$（放电次数/秒）。\n  - 伪随机数生成器种子：训练种子 $= 303$，测试种子 $= 404$。\n- 用例 3（小样本，低增益，更高噪声设置）：\n  - $N = 6$, $T = 30$, $K = 30$。\n  - 偏好方向：$\\theta_i$ 在 $[-\\pi, \\pi)$ 上均匀分布。\n  - 基线：对于所有 $i$，$b_i = 15$（放电次数/秒）。\n  - 增益：$(g_1, g_2, \\dots, g_6) = (5, 4, 3, 2, 5, 4)$（放电次数/秒）。\n  - 伪随机数生成器种子：训练种子 $= 505$，测试种子 $= 606$。\n\n科学真实性约束：\n- 使用泊松分布生成放电计数，并指定均值率，以确保计数为非负整数。\n- 确保所有计算和解码都在弧度单位下执行。\n- 避免使用任何外部数据或用户输入；使用指定的种子以实现可复现的随机性。\n\n您的程序必须生成单行输出，总结三个以弧度为单位的平均绝对环形误差，格式为 $[e_1,e_2,e_3]$。",
            "solution": "该问题经评估具有科学依据、定义明确、客观且自成体系，因此被认为是有效的。以下解决方案概述了按规定进行的建模、估计和解码的分步过程。\n\n### 步骤 1：神经响应模型\n群体中每个神经元的活动都由一个余弦调谐模型控制。神经元 $i$ 对刺激方向 $\\phi$（以弧度为单位）的响应的期望放电率 $r_i$（单位：放电次数/秒，可解释为每次试验的放电次数）由下式给出：\n$$\nr_i(\\phi) = b_i + g_i \\cos(\\phi - \\theta_i)\n$$\n其中 $b_i$ 是神经元的基线放电率，$g_i$ 是其增益（调制深度），而 $\\theta_i$ 是其偏好方向。在给定试验 $t$ 中，神经元 $i$ 在刺激 $\\phi_t$ 下发出的放电次数 $k_{i,t}$ 被建模为一个随机变量，该变量从一个泊松分布中抽取，其均值等于期望放电率：\n$$\nk_{i,t} \\sim \\text{Poisson}(r_i(\\phi_t))\n$$\n所有测试用例的问题参数都确保 $b_i \\ge g_i$，从而保证了非负的放电率 $r_i(\\phi) \\ge 0$。\n\n### 步骤 2：训练数据生成\n对于每个测试用例，我们首先合成一个训练数据集。这包括模拟 $T$ 次试验。在每次试验 $t \\in \\{1, \\dots, T\\}$ 中，从 $[-\\pi, \\pi)$ 上的均匀分布中抽取一个刺激角度 $\\phi_t$。随后，对于 $N$ 个神经元中的每一个，使用真实的、预先指定的参数，从泊松分布 $\\text{Poisson}(b_i + g_i \\cos(\\phi_t - \\theta_i))$ 中生成一个放电计数 $k_{i,t}$。\n\n### 步骤 3：调谐参数估计\n此步骤的核心任务是从生成的训练数据 $\\{(\\phi_t, k_{i,t})\\}_{t=1}^T$ 中为每个神经元估计调谐参数 $(\\hat{b}_i, \\hat{g}_i, \\hat{\\theta}_i)$。这是通过基于调谐曲线的三角展开式进行线性回归来完成的。\n\n余弦项展开为 $\\cos(\\phi - \\theta_i) = \\cos\\phi \\cos\\theta_i + \\sin\\phi \\sin\\theta_i$。将其代入放电率方程得到：\n$$\nr_i(\\phi) = b_i + (g_i \\cos\\theta_i) \\cos\\phi + (g_i \\sin\\theta_i) \\sin\\phi\n$$\n该方程具有线性模型的形式，$r_i(\\phi) = \\beta_{i,0} \\cdot 1 + \\beta_{i,1} \\cos\\phi + \\beta_{i,2} \\sin\\phi$，其系数定义如下：\n- $\\beta_{i,0} = b_i$\n- $\\beta_{i,1} = g_i \\cos\\theta_i$\n- $\\beta_{i,2} = g_i \\sin\\theta_i$\n\n我们通过最小化观测到的放电计数 $k_{i,t}$ 与模型预测值之间的平方误差总和来估计这些系数。对于每个神经元，这是一个多元线性回归问题，可以对所有试验表示为矩阵形式：\n$$\n\\mathbf{k}_i \\approx \\mathbf{X} \\boldsymbol{\\beta}_i\n$$\n这里，$\\mathbf{k}_i = [k_{i,1}, \\dots, k_{i,T}]^T$ 是神经元 $i$ 的观测放电计数向量，$\\boldsymbol{\\beta}_i = [\\beta_{i,0}, \\beta_{i,1}, \\beta_{i,2}]^T$ 是待估计的系数向量，$\\mathbf{X}$ 是包含所有试验的预测变量的 $T \\times 3$ 设计矩阵：\n$$\n\\mathbf{X} = \\begin{pmatrix}\n1  & \\cos(\\phi_1)  & \\sin(\\phi_1) \\\\\n1  & \\cos(\\phi_2)  & \\sin(\\phi_2) \\\\\n\\vdots & \\vdots & \\vdots \\\\\n1  & \\cos(\\phi_T)  & \\sin(\\phi_T)\n\\end{pmatrix}\n$$\n系数向量的标准最小二乘解是 $\\hat{\\boldsymbol{\\beta}}_i = (\\mathbf{X}^T \\mathbf{X})^{-1} \\mathbf{X}^T \\mathbf{k}_i$。我们对所有 $N$ 个神经元求解此系统，以获得每个神经元 $i$ 的估计系数 $(\\hat{\\beta}_{i,0}, \\hat{\\beta}_{i,1}, \\hat{\\beta}_{i,2})$。\n\n从这些估计的系数中，我们恢复原始调谐参数的估计值：\n- 估计基线：$\\hat{b}_i = \\hat{\\beta}_{i,0}$\n- 估计增益：$\\hat{g}_i = \\sqrt{\\hat{\\beta}_{i,1}^2 + \\hat{\\beta}_{i,2}^2}$\n- 估计偏好方向：$\\hat{\\theta}_i = \\text{atan2}(\\hat{\\beta}_{i,2}, \\hat{\\beta}_{i,1})$\n\n### 步骤 4：解码测试刺激\n在参数估计之后，我们生成一组新的 $K$ 次测试试验。对于每次试验 $u \\in \\{1, \\dots, K\\}$，从 $[-\\pi, \\pi)$ 中均匀抽取一个刺激角度 $\\phi'_u$，并使用真实参数生成放电计数 $k'_{i,u}$。\n\n然后使用向量平均解码器对每次测试试验的刺激角度进行解码。该方法通过对所有被认为已充分调谐的神经元的向量贡献求和，来计算每次试验 $u$ 的群体向量 $\\vec{V}_u$：\n$$\n\\vec{V}_u = \\sum_{i=1}^N w_{i,u} \\cdot \\vec{d}_i\n$$\n- 一个神经元 $i$ 仅在其估计增益 $\\hat{g}_i$ 高于阈值时才对总和有贡献，即 $\\hat{g}_i \\ge \\varepsilon$，其中 $\\varepsilon=10^{-3}$。\n- 每个有效神经元的贡献是一个向量 $\\vec{d}_i = [\\cos(\\hat{\\theta}_i), \\sin(\\hat{\\theta}_i)]^T$，它指向其估计的偏好角度 $\\hat{\\theta}_i$ 的方向。\n- 该向量由神经元的整流后、减去基线的活动进行加权：$w_{i,u} = \\max(0, k'_{i,u} - \\hat{b}_i)$。\n\n试验的解码角度 $\\hat{\\phi}'_u$ 是合群体向量 $\\vec{V}_u = [V_{u,x}, V_{u,y}]^T$ 的角度：\n$$\n\\hat{\\phi}'_u = \\text{atan2}(V_{u,y}, V_{u,x})\n$$\n\n### 步骤 5：性能评估\n解码器的准确性通过计算所有 $K$ 次测试试验的平均绝对环形误差来评估。单次试验的绝对环形误差是真实刺激角度 $\\phi'_u$ 和解码角度 $\\hat{\\phi}'_u$ 之间的最短角距离：\n$$\nd(\\hat{\\phi}'_u, \\phi'_u) = \\min_{k \\in \\mathbb{Z}} |\\hat{\\phi}'_u - \\phi'_u + 2\\pi k|\n$$\n这等效于将角度差 $\\hat{\\phi}'_u - \\phi'_u$ 包装到区间 $[-\\pi, \\pi]$ 内并取其绝对值。每个测试用例最终报告的值是这些误差在 $K$ 次测试试验中的平均值。整个过程被封装在一个程序中，该程序执行所有三个测试用例，并根据指定格式报告结果。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve_case(N, T, K, thetas, bs, gs, train_seed, test_seed, epsilon):\n    \"\"\"\n    Solves a single test case for the neural decoding problem.\n\n    This function performs training data generation, parameter estimation,\n    test data generation, decoding, and performance evaluation.\n    \"\"\"\n    # === Step 1: Generate training data ===\n    rng_train = np.random.default_rng(train_seed)\n    train_stimuli = rng_train.uniform(-np.pi, np.pi, size=T)\n    \n    # train_spikes will have shape (N, T)\n    train_spikes = np.zeros((N, T))\n    for i in range(N):\n        # The problem statement's parameters ensure b_i >= g_i, so rates are non-negative.\n        rates = bs[i] + gs[i] * np.cos(train_stimuli - thetas[i])\n        train_spikes[i, :] = rng_train.poisson(rates)\n\n    # === Step 2: Estimate tuning parameters ===\n    # Design matrix X, shape (T, 3) for linear regression\n    X = np.vstack([np.ones(T), np.cos(train_stimuli), np.sin(train_stimuli)]).T\n    \n    # Solve the least squares problem for all neurons simultaneously.\n    # The model is k_counts.T (shape T,N) = X (shape T,3) @ beta_matrix.T (shape 3,N)\n    # np.linalg.lstsq solves ax=b for x. Here a=X, b=train_spikes.T, x=beta_matrix.\n    beta_matrix, _, _, _ = np.linalg.lstsq(X, train_spikes.T, rcond=None)\n    \n    # beta_matrix has shape (3, N). Rows correspond to b_hat, c_hat, s_hat.\n    b_hat = beta_matrix[0, :]\n    c_hat = beta_matrix[1, :]\n    s_hat = beta_matrix[2, :]\n    \n    g_hat = np.sqrt(c_hat**2 + s_hat**2)\n    theta_hat = np.arctan2(s_hat, c_hat)\n\n    # === Step 3: Generate test data and decode ===\n    rng_test = np.random.default_rng(test_seed)\n    test_stimuli = rng_test.uniform(-np.pi, np.pi, size=K)\n    \n    # test_spikes will have shape (N, K)\n    test_spikes = np.zeros((N, K))\n    for i in range(N):\n        rates = bs[i] + gs[i] * np.cos(test_stimuli - thetas[i])\n        test_spikes[i, :] = rng_test.poisson(rates)\n        \n    # Decoding using vector averaging\n    valid_neurons_mask = g_hat >= epsilon\n    \n    # Weights for population vector, shape (N, K)\n    weights = test_spikes - b_hat[:, np.newaxis]\n    weights[weights  0] = 0.0\n    weights[~valid_neurons_mask, :] = 0.0  # Zero out weights for invalid neurons\n    \n    # Preferred direction vectors, one x and one y component per neuron\n    pref_dir_vectors_x = np.cos(theta_hat)\n    pref_dir_vectors_y = np.sin(theta_hat)\n    \n    # Population vector components, summed over neurons for each trial, shape (K,)\n    pop_vector_x = pref_dir_vectors_x @ weights\n    pop_vector_y = pref_dir_vectors_y @ weights\n    \n    decoded_stimuli = np.arctan2(pop_vector_y, pop_vector_x)\n\n    # === Step 4: Evaluate performance ===\n    # Calculate absolute circular error\n    error_diff = decoded_stimuli - test_stimuli\n    circular_errors = np.abs((error_diff + np.pi) % (2 * np.pi) - np.pi)\n    \n    mean_abs_error = np.mean(circular_errors)\n    \n    return mean_abs_error\n\n\ndef solve():\n    \"\"\"\n    Main function to run the specified test suite and print results.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # Case 1: happy path, diverse gains, ample training\n        {\n            \"N\": 8, \"T\": 200, \"K\": 50,\n            \"b_val\": 20.0, \"gs\": [14.0, 12.0, 16.0, 10.0, 18.0, 11.0, 15.0, 13.0],\n            \"train_seed\": 101, \"test_seed\": 202\n        },\n        # Case 2: boundary condition with zero-gain neurons\n        {\n            \"N\": 8, \"T\": 60, \"K\": 40,\n            \"b_val\": 20.0, \"gs\": [0.0, 0.0, 12.0, 10.0, 8.0, 0.0, 6.0, 0.0],\n            \"train_seed\": 303, \"test_seed\": 404\n        },\n        # Case 3: small-sample, low-gain, noisier setting\n        {\n            \"N\": 6, \"T\": 30, \"K\": 30,\n            \"b_val\": 15.0, \"gs\": [5.0, 4.0, 3.0, 2.0, 5.0, 4.0],\n            \"train_seed\": 505, \"test_seed\": 606\n        }\n    ]\n\n    results = []\n    epsilon = 1e-3\n\n    for case in test_cases:\n        N = case[\"N\"]\n        # True preferred directions are evenly spaced on [-pi, pi)\n        thetas = -np.pi + (2 * np.pi * np.arange(N)) / N\n        bs = np.full(N, case[\"b_val\"])\n        gs = np.array(case[\"gs\"])\n        \n        result = solve_case(\n            N=N, T=case[\"T\"], K=case[\"K\"],\n            thetas=thetas, bs=bs, gs=gs,\n            train_seed=case[\"train_seed\"], test_seed=case[\"test_seed\"],\n            epsilon=epsilon\n        )\n        results.append(result)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "一个简单的解码器只考虑感官输入，但智能系统通常会将这些证据与先验知识或期望相结合。本练习将探讨如何利用贝叶斯推断来形式化这一过程，展示如何将先验信念（由冯·米塞斯分布表示）与来自群体向量的证据进行数学上的结合，从而得到一个更稳健的后验估计。这揭示了大脑作为贝叶斯推断引擎这一强大概念。",
            "id": "4010755",
            "problem": "初级视皮层中一个由 $N=8$ 个方向调谐神经元组成的群体编码一个环形变量（方向）$\\theta \\in [0,2\\pi)$。这些神经元的偏好方向均匀间隔，为 $\\phi_{k} \\in \\{0,\\frac{\\pi}{4},\\frac{\\pi}{2},\\frac{3\\pi}{4},\\pi,\\frac{5\\pi}{4},\\frac{3\\pi}{2},\\frac{7\\pi}{4}\\}$（其中 $k=1,\\dots,8$）。假设神经元是独立的泊松尖峰发放，具有相同的基线发放率和形状增益皆相同的余弦状调谐，并且偏好方向的分布是密集的、近似均匀的。在这些条件下，对数似然中依赖于 $\\theta$ 的部分可以由其环形傅里叶级数的一阶谐波很好地近似，并且与一种使用尖峰计数作为偏好方向权重的向量平均解码器兼容。在单个观测窗口中记录的尖峰计数为\n$$\nn_{1}=14,\\quad n_{2}=23,\\quad n_{3}=21,\\quad n_{4}=10,\\quad n_{5}=7,\\quad n_{6}=5,\\quad n_{7}=8,\\quad n_{8}=12.\n$$\n此外，观察者对 $\\theta$ 有一个非均匀先验，该先验是冯·米塞斯分布，其平均方向为 $\\theta_{0}=\\frac{\\pi}{6}$，集中参数为 $\\kappa_{0}=10$，即 $\\pi(\\theta)\\propto \\exp\\!\\big(\\kappa_{0}\\cos(\\theta-\\theta_{0})\\big)$。使用贝叶斯定理和所述的建模假设，确定由一个包含此先验的向量平均解码器产生的 $\\theta$ 的最大后验（MAP）估计。以弧度表示你的最终答案，并四舍五入到四位有效数字。",
            "solution": "该问题要求在给定一组来自神经元群体的尖峰计数和关于 $\\theta$ 的先验分布的情况下，求刺激方向 $\\theta$ 的最大后验（MAP）估计。这是一个贝叶斯推断中的典型问题。\n\n根据贝叶斯定理，给定观测到的尖峰计数 $\\mathbf{n} = (n_1, \\dots, n_N)$，刺激 $\\theta$ 的后验概率为：\n$$\nP(\\theta|\\mathbf{n}) = \\frac{P(\\mathbf{n}|\\theta)\\pi(\\theta)}{P(\\mathbf{n})}\n$$\n其中 $P(\\mathbf{n}|\\theta)$ 是在给定刺激下观测到尖峰计数的似然，$\\pi(\\theta)$ 是刺激的先验概率，$P(\\mathbf{n})$ 是数据的边缘概率，它作为一个归一化常数。\n\nMAP 估计 $\\hat{\\theta}_{MAP}$ 是使后验概率 $P(\\theta|\\mathbf{n})$ 最大化的 $\\theta$ 值。由于分母 $P(\\mathbf{n})$ 与 $\\theta$ 无关，这等价于最大化似然和先验的乘积：\n$$\n\\hat{\\theta}_{MAP} = \\underset{\\theta}{\\arg\\max} \\, [P(\\mathbf{n}|\\theta)\\pi(\\theta)]\n$$\n这也等同于最大化对数后验 $\\ln P(\\theta|\\mathbf{n}) = \\ln P(\\mathbf{n}|\\theta) + \\ln \\pi(\\theta) - \\ln P(\\mathbf{n})$。\n\n问题陈述解码过程与向量平均解码器兼容，并且对数似然中依赖于 $\\theta$ 的部分可以由其一阶谐波很好地近似。对于具有余弦调谐的独立泊松神经元，可以证明对数似然近似正比于 $\\sum_{k=1}^{N} n_k \\cos(\\theta - \\phi_k)$，其中 $n_k$ 是尖峰计数，$\\phi_k$ 是偏好方向。这个表达式可以重写为：\n$$\n\\sum_{k=1}^{N} n_k \\cos(\\theta - \\phi_k) = \\cos\\theta \\left(\\sum_{k=1}^{N} n_k \\cos\\phi_k\\right) + \\sin\\theta \\left(\\sum_{k=1}^{N} n_k \\sin\\phi_k\\right)\n$$\n括号中的项是群体向量 $V_{pop} = (V_{pop,x}, V_{pop,y})$ 的分量，其中 $V_{pop,x} = \\sum_k n_k \\cos\\phi_k$，$V_{pop,y} = \\sum_k n_k \\sin\\phi_k$。因此，该表达式等价于 $|V_{pop}|\\cos(\\theta - \\hat{\\theta}_{ML})$，其中 $|V_{pop}|$ 是群体向量的大小，$\\hat{\\theta}_{ML} = \\text{atan2}(V_{pop,y}, V_{pop,x})$ 是其角度，它对应于 $\\theta$ 的最大似然（ML）估计。\n\n因此，似然函数可以被建模为一个冯·米塞斯分布，其中心位于 $\\hat{\\theta}_{ML}$，集中参数与 $|V_{pop}|$ 成正比：\n$$\nP(\\mathbf{n}|\\theta) \\propto \\exp(|V_{pop}|\\cos(\\theta - \\hat{\\theta}_{ML}))\n$$\n这是使用向量平均解码器的一种数学形式化。来自神经数据的“证据”被封装在群体向量 $V_{pop}$ 中。\n\n先验分布被给定为一个冯·米塞斯分布，其平均方向为 $\\theta_0 = \\frac{\\pi}{6}$，集中参数为 $\\kappa_0=10$：\n$$\n\\pi(\\theta) \\propto \\exp(\\kappa_0 \\cos(\\theta - \\theta_0))\n$$\n\n因此，对数后验为：\n$$\n\\ln P(\\theta|\\mathbf{n}) \\propto |V_{pop}|\\cos(\\theta - \\hat{\\theta}_{ML}) + \\kappa_0\\cos(\\theta - \\theta_0)\n$$\n最大化此表达式等价于求两个向量之和的角度。第一个向量是群体向量 $V_{pop}$（代表似然），第二个向量 $V_{prior}$ 的大小等于先验的集中参数 $\\kappa_0$，方向等于先验的平均方向 $\\theta_0$。\n\n令 $V_{MAP} = V_{pop} + V_{prior}$。MAP 估计 $\\hat{\\theta}_{MAP}$ 是这个合向量的角度。\n\n首先，我们使用给定的尖峰计数 $n_k$ 和偏好方向 $\\phi_k$ 来计算群体向量 $V_{pop} = (V_{pop,x}, V_{pop,y})$。\n偏好方向为 $\\phi_k = (k-1)\\frac{\\pi}{4}$（其中 $k=1, \\dots, 8$）：\n$\\{0, \\frac{\\pi}{4}, \\frac{\\pi}{2}, \\frac{3\\pi}{4}, \\pi, \\frac{5\\pi}{4}, \\frac{3\\pi}{2}, \\frac{7\\pi}{4}\\}$。\n尖峰计数为 $n = \\{14, 23, 21, 10, 7, 5, 8, 12\\}$。\n\n群体向量的 x 分量是：\n$$\nV_{pop,x} = \\sum_{k=1}^{8} n_k \\cos(\\phi_k) = 14\\cos(0) + 23\\cos(\\frac{\\pi}{4}) + 21\\cos(\\frac{\\pi}{2}) + 10\\cos(\\frac{3\\pi}{4}) + 7\\cos(\\pi) + 5\\cos(\\frac{5\\pi}{4}) + 8\\cos(\\frac{3\\pi}{2}) + 12\\cos(\\frac{7\\pi}{4})\n$$\n$$\nV_{pop,x} = 14(1) + 23(\\frac{\\sqrt{2}}{2}) + 21(0) + 10(-\\frac{\\sqrt{2}}{2}) + 7(-1) + 5(-\\frac{\\sqrt{2}}{2}) + 8(0) + 12(\\frac{\\sqrt{2}}{2})\n$$\n$$\nV_{pop,x} = (14-7) + (23-10-5+12)\\frac{\\sqrt{2}}{2} = 7 + 20\\frac{\\sqrt{2}}{2} = 7 + 10\\sqrt{2}\n$$\n\n群体向量的 y 分量是：\n$$\nV_{pop,y} = \\sum_{k=1}^{8} n_k \\sin(\\phi_k) = 14\\sin(0) + 23\\sin(\\frac{\\pi}{4}) + 21\\sin(\\frac{\\pi}{2}) + 10\\sin(\\frac{3\\pi}{4}) + 7\\sin(\\pi) + 5\\sin(\\frac{5\\pi}{4}) + 8\\sin(\\frac{3\\pi}{2}) + 12\\sin(\\frac{7\\pi}{4})\n$$\n$$\nV_{pop,y} = 14(0) + 23(\\frac{\\sqrt{2}}{2}) + 21(1) + 10(\\frac{\\sqrt{2}}{2}) + 7(0) + 5(-\\frac{\\sqrt{2}}{2}) + 8(-1) + 12(-\\frac{\\sqrt{2}}{2})\n$$\n$$\nV_{pop,y} = (21-8) + (23+10-5-12)\\frac{\\sqrt{2}}{2} = 13 + 16\\frac{\\sqrt{2}}{2} = 13 + 8\\sqrt{2}\n$$\n\n接下来，我们定义先验向量 $V_{prior} = (V_{prior,x}, V_{prior,y})$，其大小为 $\\kappa_0=10$，角度为 $\\theta_0=\\frac{\\pi}{6}$。\n$$\nV_{prior,x} = \\kappa_0 \\cos(\\theta_0) = 10\\cos(\\frac{\\pi}{6}) = 10(\\frac{\\sqrt{3}}{2}) = 5\\sqrt{3}\n$$\n$$\nV_{prior,y} = \\kappa_0 \\sin(\\theta_0) = 10\\sin(\\frac{\\pi}{6}) = 10(\\frac{1}{2}) = 5\n$$\n\n用于 MAP 估计的合向量是 $V_{MAP} = V_{pop} + V_{prior}$。\n其分量为：\n$$\nV_{MAP,x} = V_{pop,x} + V_{prior,x} = (7 + 10\\sqrt{2}) + 5\\sqrt{3} = 7 + 10\\sqrt{2} + 5\\sqrt{3}\n$$\n$$\nV_{MAP,y} = V_{pop,y} + V_{prior,y} = (13 + 8\\sqrt{2}) + 5 = 18 + 8\\sqrt{2}\n$$\n\n现在，我们计算这些分量的数值：\n$$\nV_{MAP,x} \\approx 7 + 10(1.41421) + 5(1.73205) = 7 + 14.1421 + 8.66025 = 29.80235\n$$\n$$\nV_{MAP,y} \\approx 18 + 8(1.41421) = 18 + 11.31368 = 29.31368\n$$\n\nMAP 估计是这个合向量的角度：\n$$\n\\hat{\\theta}_{MAP} = \\text{atan2}(V_{MAP,y}, V_{MAP,x}) = \\text{atan2}(29.31368, 29.80235)\n$$\n由于两个分量都为正，所以角度在第一象限。\n$$\n\\hat{\\theta}_{MAP} = \\arctan\\left(\\frac{29.31368}{29.80235}\\right) \\approx \\arctan(0.983603) \\approx 0.777095 \\text{ radians}\n$$\n\n将结果四舍五入到四位有效数字，我们得到 $0.7771$。",
            "answer": "$$\\boxed{0.7771}$$"
        },
        {
            "introduction": "构建解码器是一回事，而严格评估其性能则是另一回事。本练习将介绍K折交叉验证这一黄金标准，以防止模型过拟合，并获得解码器在未见过数据上性能的可靠度量。您将实现这一评估流程，并学习不仅通过平均误差，还通过偏差和可靠性来描述解码器性能，从而更全面地了解其能力。",
            "id": "4010791",
            "problem": "您的任务是使用一个真实的余弦调谐神经元群体，实现并评估一个用于方向性刺激的向量平均解码器 (VAD)。评估必须使用 K-折交叉验证 (CV)，并产生明确定义的性能指标。所有角度必须以弧度表示。每个数值结果必须四舍五入到六位小数。\n\n建模的基础：\n- 神经元方向调谐通过余弦调谐进行建模。对于偏好方向为 $\\phi_i$ 的神经元 $i$，其对刺激方向 $\\theta$ 的平均发放率是一个形式为 $b + k \\cos(\\theta - \\phi_i)$ 的整流余弦函数，其中 $b \\ge 0$ 是基线率， $k \\ge 0$ 是调制幅度。为确保发放率为非负，通过 $\\max(0, b + k \\cos(\\theta - \\phi_i))$ 进行整流。\n- 脉冲发放的可变性遵循以平均发放率为条件的泊松过程。对于试验 $t$ 和神经元 $i$，观测到的脉冲计数 $r_{i,t}$ 是一个泊松随机变量，其均值等于整流后的调谐率。\n- 向量平均解码器 (VAD) 通过减去基线的神经活动和神经元特定的偏好方向单位向量来构建一个群体向量，并通过所得向量的角度来解码刺激方向，该角度通过双参数反正切函数计算。\n- K-折交叉验证 (CV) 将 $T$ 次试验划分为 $K$ 个连续且大小相等的折。对于每一折，训练集通过对训练试验中的神经元脉冲计数取平均来估计每个神经元的基线，然后将解码器应用于留出的测试集。聚合所有折的留出试验以计算指标。\n\n要求的解码和评估协议：\n1. 为每个测试案例生成一个合成数据集，如下所示：\n   - 从 $[0, 2\\pi)$ 中独立且均匀地抽取 $N$ 个偏好方向 $\\phi_i$。\n   - 从 $[0, 2\\pi)$ 中独立且均匀地抽取 $T$ 个刺激方向 $\\theta_t$。\n   - 计算平均发放率 $\\lambda_{i,t} = \\max(0, b + k \\cos(\\theta_t - \\phi_i))$。\n   - 采样脉冲计数 $r_{i,t} \\sim \\mathrm{Poisson}(\\lambda_{i,t})$。\n2. 使用连续的折执行 $K$-折交叉验证。设 $L = T/K$ 为折的长度（假设 $K$ 能整除 $T$）。对于折 $f \\in \\{0, 1, \\ldots, K-1\\}$，定义测试索引为 $t \\in \\{fL, fL+1, \\ldots, (f+1)L - 1\\}$，训练索引为所有其他索引。对于每一折：\n   - 将每个神经元的基线 $\\hat{b}_i$ 估计为 $r_{i,t}$ 在训练试验中的均值。\n   - 对于每个测试试验 $t$，通过使用减去基线的脉冲计数和与 $\\phi_i$ 对应的单位向量形成群体向量，并使用双参数反正切函数取其角度，来计算解码角度 $\\hat{\\theta}_t$。如果所得向量的模为零，则按惯例设置 $\\hat{\\theta}_t = 0$。\n3. 对于所有留出的试验（跨折聚合），计算：\n   - 平均绝对环形误差 (MACE): $\\frac{1}{T} \\sum_{t=1}^{T} \\left| \\mathrm{wrap}(\\hat{\\theta}_t - \\theta_t) \\right|$，其中 $\\mathrm{wrap}(\\alpha)$ 使用恒等式 $\\mathrm{wrap}(\\alpha) = \\arctan2(\\sin(\\alpha), \\cos(\\alpha))$ 将 $\\alpha$ 映射到 $(-\\pi, \\pi]$。\n   - 环形偏差 (BIAS): $\\frac{1}{T} \\sum_{t=1}^{T} \\mathrm{wrap}(\\hat{\\theta}_t - \\theta_t)$。\n   - 容差 $\\tau$ 内的比例 (FRAC): 留出试验中满足 $\\left| \\mathrm{wrap}(\\hat{\\theta}_t - \\theta_t) \\right| \\le \\tau$ 的比例。\n4. 输入和输出的角度单位均为弧度。基线估计、VAD 解码和误差计算必须严格遵循上述定义。\n\n您的程序必须实现上述协议，并为以下测试套件生成结果。在每种情况下，使用一个独立的随机数生成器，其固定种子等于 $42 + s$，其中 $s$ 是从 $0$ 开始的测试案例索引。\n\n测试套件（每个元组为 $(N, T, K, b, k, \\tau)$）：\n- 案例 $0$: $(50, 200, 5, 15, 10, 0.5)$\n- 案例 $1$: $(8, 120, 6, 10, 12, 0.5)$\n- 案例 $2$: $(4, 100, 4, 10, 10, 0.4)$\n- 案例 $3$: $(60, 240, 8, 20, 0, 0.5)$\n\n最终输出格式：\n- 您的程序应生成单行输出，包含一个外层列表，其中是每个测试案例的结果。每个测试案例的结果是一个列表 $[\\mathrm{MACE}, \\mathrm{BIAS}, \\mathrm{FRAC}]$，所有条目都四舍五入到六位小数。该行必须是一个用方括号括起来的逗号分隔列表，不含空格。例如：$[[0.123456,-0.000001,0.987654],[\\ldots],[\\ldots],[\\ldots]]$。",
            "solution": "问题陈述经评估有效。它在科学上是合理的，数学上是适定的，并为计算神经科学模拟提供了完整且明确的规范。因此，我们可以着手解决。\n\n目标是实现并评估一个用于编码方向性刺激的神经元群体的向量平均解码器 (VAD)。评估将对一个合成生成的数据集使用 $K$-折交叉验证协议。\n\n**1. 基础模型**\n\n首先，我们定义神经编码模型的组成部分。\n\n**神经元调谐模型：**\n每个神经元的发放率都针对特定方向进行调谐。对于给定偏好方向为 $\\phi_i$ 的神经元 $i$，其对呈现在方向 $\\theta_t$ 的刺激的平均发放率 $\\lambda_{i,t}$ 由一个整流余弦调谐曲线描述。这是方向选择性神经元（例如运动皮层中的神经元）的标准模型。公式为：\n$$\n\\lambda_{i,t} = \\max(0, b + k \\cos(\\theta_t - \\phi_i))\n$$\n这里，$b \\ge 0$ 代表基线发放率（在没有方向调制时神经元的活动），$k \\ge 0$ 是调制幅度，它决定了神经元的发放率受刺激方向影响的强度。$\\max(0, \\cdot)$ 函数确保作为物理量的发放率不能为负。\n\n**脉冲发放可变性模型：**\n神经脉冲序列表现出固有的随机性。这种可变性使用泊松过程建模。在试验 $t$ 期间从神经元 $i$ 记录到的脉冲数（计数）$r_{i,t}$ 是一个从泊松分布中抽取的随机变量，其均值由调谐曲线 $\\lambda_{i,t}$ 给出：\n$$\nr_{i,t} \\sim \\mathrm{Poisson}(\\lambda_{i,t})\n$$\n\n**2. 数据生成协议**\n\n对于每个测试案例，我们根据以下规范生成一个合成数据集：\n- 创建一个包含 $N$ 个神经元的群体。每个神经元 $i$ 被分配一个偏好方向 $\\phi_i$，该方向从区间 $[0, 2\\pi)$ 中独立且均匀地抽取。\n- 模拟一个包含 $T$ 次试验的序列。对于每次试验 $t$，从 $[0, 2\\pi)$ 中独立且均匀地抽取一个刺激方向 $\\theta_t$。\n- 对于每个神经元 $i$ 和试验 $t$，使用整流余弦调谐模型计算平均发放率 $\\lambda_{i,t}$。\n- 然后从均值为 $\\lambda_{i,t}$ 的泊松分布中采样相应的脉冲计数 $r_{i,t}$。\n这个过程生成了脉冲计数矩阵 $r_{i,t}$，以及真实的刺激方向 $\\theta_t$ 和神经元偏好方向 $\\phi_i$。\n\n**3. 解码与交叉验证**\n\n为了稳健地评估解码器的性能，采用了 $K$-折交叉验证程序。这种方法通过确保用于训练解码器（即估计其参数）的数据与用于测试它的数据是分开的，从而防止过拟合。\n\n**分区：** $T$ 次试验被划分为 $K$ 个不重叠、连续且大小相等的块（折），每块大小为 $L = T/K$。\n\n**迭代：** 该过程迭代 $K$ 次。在每次迭代 $f \\in \\{0, 1, \\ldots, K-1\\}$ 中，一折被指定为测试集，其余 $K-1$ 折构成训练集。\n\n**基线估计：** VAD 的一个关键参数是每个神经元的基线发放率。问题指定了一种经验估计方法。对于每个神经元 $i$，其基线率 $\\hat{b}_i$ 通过计算其在当前训练集中所有试验 $t$ 的观测脉冲计数 $r_{i,t}$ 的平均值来估计：\n$$\n\\hat{b}_i = \\frac{1}{T_{\\text{train}}} \\sum_{t \\in \\text{train}} r_{i,t}\n$$\n其中 $T_{\\text{train}}$ 是训练集中的试验次数。\n\n**向量平均解码器 (VAD)：** 对于测试集中的每个试验 $t$，解码刺激方向。VAD 算法工作如下：\n- 对于每个神经元 $i$，其对群体活动的贡献是其减去基线后的发放率，即 $(r_{i,t} - \\hat{b}_i)$。该值表示神经元的活动偏离其平均水平的程度。\n- 通过对指向每个神经元偏好方向的单位向量进行加权求和，形成一个群体向量 $\\vec{P}_t$。每个神经元的权重是其减去基线后的发放率。\n$$\n\\vec{P}_t = \\sum_{i=1}^{N} (r_{i,t} - \\hat{b}_i) \\vec{c}_i = \\sum_{i=1}^{N} (r_{i,t} - \\hat{b}_i) \\begin{bmatrix} \\cos(\\phi_i) \\\\ \\sin(\\phi_i) \\end{bmatrix} = \\begin{bmatrix} P_{t,x} \\\\ P_{t,y} \\end{bmatrix}\n$$\n- 解码角度 $\\hat{\\theta}_t$ 是所得群体向量 $\\vec{P}_t$ 的方向。这使用双参数反正切函数 $\\mathrm{atan2}$ 计算，该函数能在所有四个象限中正确解析角度。\n$$\n\\hat{\\theta}_t = \\mathrm{atan2}(P_{t,y}, P_{t,x})\n$$\n- 按照惯例，如果群体向量的模为零，即 $\\|\\vec{P}_t\\| = 0$，则解码角度设为 $\\hat{\\theta}_t = 0$。\n\n对所有 $K$ 折重复此过程，为每个试验 $t=1, \\ldots, T$ 产生一个解码角度 $\\hat{\\theta}_t$。\n\n**4. 性能评估指标**\n\n交叉验证后，通过比较所有 $T$ 次试验的解码角度 $\\hat{\\theta}_t$ 和真实刺激角度 $\\theta_t$ 来量化解码器的性能。由于我们处理的是环形数据（角度），需要使用特定的误差度量。\n\n**环形误差：** 对于每个试验 $t$，环形误差 $\\Delta\\theta_t$ 是 $\\hat{\\theta}_t$ 和 $\\theta_t$ 之间的最短夹角。它通过将它们的差值包裹到区间 $(-\\pi, \\pi]$ 来计算：\n$$\n\\Delta\\theta_t = \\mathrm{wrap}(\\hat{\\theta}_t - \\theta_t) = \\mathrm{atan2}(\\sin(\\hat{\\theta}_t - \\theta_t), \\cos(\\hat{\\theta}_t - \\theta_t))\n$$\n使用这些误差，我们计算三个聚合指标：\n\n- **平均绝对环形误差 (MACE):** 解码误差的平均绝对大小。它衡量解码器的精度。\n$$\n\\mathrm{MACE} = \\frac{1}{T} \\sum_{t=1}^{T} |\\Delta\\theta_t|\n$$\n\n- **环形偏差 (BIAS):** 平均有符号解码误差。它衡量解码器是否存在系统性高估或低估角度的趋势。\n$$\n\\mathrm{BIAS} = \\frac{1}{T} \\sum_{t=1}^{T} \\Delta\\theta_t\n$$\n\n- **容差内的比例 (FRAC):** 绝对环形误差在指定容差 $\\tau$ 内的试验比例。\n$$\n\\mathrm{FRAC} = \\frac{1}{T} \\sum_{t=1}^{T} \\mathbb{I}(|\\Delta\\theta_t| \\le \\tau)\n$$\n其中 $\\mathbb{I}(\\cdot)$ 是指示函数，如果其参数为真则为 $1$，否则为 $0$。\n\n实现将为问题中定义的每个测试案例执行这整个协议，并为每个案例使用不同的随机种子以确保可复现性。所有数值结果将按要求四舍五入到六位小数。",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Implements and evaluates a Vector Averaging Decoder (VAD) for\n    directional stimuli using a population of cosine-tuned neurons.\n    The evaluation uses K-fold cross-validation and computes MACE, BIAS, and FRAC metrics.\n    \"\"\"\n\n    test_cases = [\n        # (N, T, K, b, k, tau)\n        (50, 200, 5, 15, 10, 0.5), # Case 0\n        (8, 120, 6, 10, 12, 0.5), # Case 1\n        (4, 100, 4, 10, 10, 0.4), # Case 2\n        (60, 240, 8, 20, 0, 0.5),  # Case 3\n    ]\n\n    all_results_formatted = []\n\n    for s, case in enumerate(test_cases):\n        N, T, K, b, k, tau = case\n        seed = 42 + s\n        rng = np.random.default_rng(seed)\n\n        # Step 1: Generate synthetic dataset\n        # Preferred directions for N neurons, phi_i ~ U[0, 2*pi)\n        phi = rng.uniform(0, 2 * np.pi, size=N)  # Shape: (N,)\n        \n        # Stimulus directions for T trials, theta_t ~ U[0, 2*pi)\n        theta = rng.uniform(0, 2 * np.pi, size=T)  # Shape: (T,)\n\n        # Compute mean firing rates lambda_it = max(0, b + k*cos(theta_t - phi_i))\n        # Use broadcasting to compute difference for all (i, t) pairs\n        # theta[np.newaxis, :] -> shape (1, T)\n        # phi[:, np.newaxis]   -> shape (N, 1)\n        # Difference results in shape (N, T)\n        angle_diff = theta[np.newaxis, :] - phi[:, np.newaxis]\n        mean_rates = b + k * np.cos(angle_diff)\n        mean_rates[mean_rates  0] = 0  # Rectification\n        \n        # Sample spike counts r_it ~ Poisson(lambda_it)\n        r = rng.poisson(mean_rates)  # Shape: (N, T)\n\n        # Arrays to store aggregated results from all test folds\n        all_theta_true = np.zeros(T)\n        all_theta_decoded = np.zeros(T)\n        \n        # Step 2: Perform K-fold cross-validation\n        fold_length = T // K\n        indices = np.arange(T)\n        \n        for f in range(K):\n            test_indices = indices[f * fold_length : (f + 1) * fold_length]\n            train_indices = np.setdiff1d(indices, test_indices, assume_unique=True)\n            \n            # Estimate per-neuron baselines b_hat_i from training data\n            # Average spike counts for each neuron over training trials\n            r_train = r[:, train_indices]\n            b_hat = np.mean(r_train, axis=1)  # Shape: (N,)\n            \n            # Decode each trial in the current test fold\n            r_test = r[:, test_indices]      # Shape: (N, fold_length)\n            theta_test = theta[test_indices] # Shape: (fold_length,)\n            \n            # Subtract estimated baselines from test counts\n            r_subtracted = r_test - b_hat[:, np.newaxis] # Broadcasting b_hat\n            \n            # Create unit vectors for preferred directions [c_x, c_y]\n            c_vectors = np.vstack([np.cos(phi), np.sin(phi)]) # Shape: (2, N)\n            \n            # Compute population vector P_t by summing weighted unit vectors\n            # P = c_vectors @ r_subtracted\n            # (2, N) @ (N, fold_length) results in (2, fold_length)\n            P = c_vectors @ r_subtracted\n            \n            # Decode angle as the angle of the population vector\n            theta_decoded_fold = np.arctan2(P[1, :], P[0, :])\n            \n            # Convention for zero-magnitude vectors\n            magnitudes = np.linalg.norm(P, axis=0)\n            theta_decoded_fold[magnitudes == 0] = 0.0\n\n            # Store true and decoded angles for this fold\n            all_theta_true[test_indices] = theta_test\n            all_theta_decoded[test_indices] = theta_decoded_fold\n\n        # Step 3: Compute performance metrics over all T trials\n        # Calculate circular error: wrap(decoded - true)\n        error = all_theta_decoded - all_theta_true\n        wrapped_error = np.arctan2(np.sin(error), np.cos(error))\n\n        # MACE: Mean Absolute Circular Error\n        mace = np.mean(np.abs(wrapped_error))\n        \n        # BIAS: Circular Bias\n        bias = np.mean(wrapped_error)\n        \n        # FRAC: Fraction of trials with absolute error = tau\n        frac = np.mean(np.abs(wrapped_error) = tau)\n        \n        # Format results for this test case\n        case_results_str = f\"[{mace:.6f},{bias:.6f},{frac:.6f}]\"\n        all_results_formatted.append(case_results_str)\n\n    # Final print statement in the exact required format\n    print(f\"[{','.join(all_results_formatted)}]\")\n\nsolve()\n```"
        }
    ]
}