{
    "hands_on_practices": [
        {
            "introduction": "我们如何定量地衡量一个神经元的放电是否“锁定”于某个背景脑节律的特定相位？这个练习为解决这个问题提供了一个动手实践的方法，这是分析时间编码的基石。你将从一组假设的放电相位中计算锁相值（Phase-Locking Value, PLV），这是一个衡量神经同步性的基本指标。这项练习将巩固你关于如何将脉冲时间数据转化为时间编码精度的定量度量的理解。",
            "id": "4003069",
            "problem": "一个神经元接收角频率为 $2\\pi f$ 的弱正弦输入，并产生脉冲。这些脉冲的相位 $\\phi_j \\in (-\\pi,\\pi]$ 是相对于输入周期测量的。锁相值 (PLV) 定义为 $PLV = \\left|\\left\\langle e^{i \\phi}\\right\\rangle\\right| = \\left|\\frac{1}{N}\\sum_{j=1}^{N} e^{i \\phi_j}\\right|$，其中 $N$ 是脉冲数量，$\\langle \\cdot \\rangle$ 表示对脉冲的经验平均。脉冲相位被建模为来自 von Mises (VM) 分布 $p(\\phi \\mid \\mu,\\kappa) \\propto \\exp\\!\\big(\\kappa \\cos(\\phi - \\mu)\\big)$ 的独立同分布样本，其平均相位为 $\\mu$，集中度为 $\\kappa$。考虑 $N = 10$ 个观测到的相位（以弧度为单位）：\n$\\{0.5, 0.4, -0.3, 0.2, -0.1, 0.6, -0.5, 0.3, -0.4, 0.1\\}$。\n使用相位的复数表示和参数 $\\theta$ 的费雪信息 (FI) $J = \\mathbb{E}\\big[(\\partial/\\partial \\theta)\\ln p(X\\mid \\theta)\\big]^2$ 的基本定义，根据数据计算 $PLV$，并解释 $PLV$ 如何与环形集中度以及相位编码脉冲序列中的信息相关。选择给出正确的 $PLV$ 数值以及 $PLV$、$\\kappa$ 和关于平均相位 $\\mu$ 的费雪信息之间正确的定性关系的选项。\n\nA. $PLV \\approx 0.93$。$PLV$ 等于平均合向量长度，并随环形集中度的增加而单调增加；在 VM 模型下，较大的 $PLV$ 意味着较大的 $\\kappa$，并且对于足够集中的相位，关于 $\\mu$ 的费雪信息与 $\\kappa$ 和脉冲数量 $N$ 近似呈线性关系 (即 $J \\propto N \\kappa$)。\n\nB. $PLV \\approx 0.50$。$PLV$ 随环形集中度的增加而减小；关于 $\\mu$ 的费雪信息与 $\\kappa$ 成反比，且与 $N$ 无关 (即 $J \\propto \\kappa^{-1}$)。\n\nC. $PLV \\approx 0.93$。$PLV$ 在数值上等于集中度参数 $\\kappa$；关于 $\\mu$ 的费雪信息与 $\\kappa$ 呈二次关系，与 $N$ 呈线性关系 (即 $J \\propto N \\kappa^2$)。\n\nD. $PLV \\approx 0.80$。$PLV$ 随环形集中度的增加而增加，但关于 $\\mu$ 的费雪信息与 $\\kappa$ 无关，仅与 $\\sqrt{N}$ 成比例 (即 $J \\propto \\sqrt{N}$)。",
            "solution": "用户要求对问题陈述进行细致的验证，然后详细推导解决方案并评估所有选项。\n\n### 问题验证\n\n**步骤 1：提取已知条件**\n\n-   输入：角频率为 $2\\pi f$ 的弱正弦信号。\n-   脉冲相位：$\\phi_j \\in (-\\pi,\\pi]$，相对于输入周期测量。\n-   锁相值 (PLV) 定义：$PLV = \\left|\\left\\langle e^{i \\phi}\\right\\rangle\\right| = \\left|\\frac{1}{N}\\sum_{j=1}^{N} e^{i \\phi_j}\\right|$。\n-   $N$：脉冲数量。\n-   $\\langle \\cdot \\rangle$：对脉冲的经验平均。\n-   脉冲相位模型：来自 von Mises (VM) 分布的独立同分布 (i.i.d.) 样本。\n-   VM 分布概率密度函数 (PDF)：$p(\\phi \\mid \\mu,\\kappa) \\propto \\exp\\!\\big(\\kappa \\cos(\\phi - \\mu)\\big)$。\n-   $\\mu$：平均相位参数。\n-   $\\kappa$：集中度参数。\n-   观测到的脉冲数量：$N = 10$。\n-   观测到的相位数据（以弧度为单位）：$\\{\\phi_j\\}_{j=1}^{10} = \\{0.5, 0.4, -0.3, 0.2, -0.1, 0.6, -0.5, 0.3, -0.4, 0.1\\}$。\n-   费雪信息 (FI) 定义：$J = \\mathbb{E}\\big[(\\partial/\\partial \\theta)\\ln p(X\\mid \\theta)\\big]^2$。\n-   问题：计算 $PLV$，解释其与 $\\kappa$ 的关系，并解释关于 $\\mu$ 的费雪信息与参数 $\\kappa$ 和 $N$ 之间的关系。\n\n**步骤 2：使用提取的已知条件进行验证**\n\n-   **科学基础：** 该问题牢固地植根于计算神经科学和统计学。锁相值 ($PLV$) 是衡量神经同步性的标准指标。von Mises 分布是环形数据的经典概率分布，类似于线性数据的正态分布，并广泛用于建模神经锁相。费雪信息是信息论和统计估计中的一个基本概念。所有概念及其应用背景都是科学合理的。\n-   **适定性：** 该问题提供了执行所需计算和解释的所有必要数据和定义。问题具体，并允许一个唯一、稳定且有意义的解。\n-   **客观性：** 问题以精确、定量和客观的术语陈述，没有主观或模糊的语言。\n\n**步骤 3：结论与行动**\n\n-   **结论：** 该问题是有效的。它科学合理、适定且客观。没有明显缺陷。\n-   **行动：** 继续推导解决方案。\n\n### 解答推导\n\n该问题需要三个主要部分：$PLV$ 的数值计算，$PLV$ 与集中度参数 $\\kappa$ 之间关系的解释，以及关于平均相位 $\\mu$ 的费雪信息 ($J$) 的分析。\n\n**1. 锁相值 ($PLV$) 的计算**\n\n$PLV$ 被定义为表示在单位圆上的相位复数的平均合向量的模。\n$$PLV = \\left|\\frac{1}{N}\\sum_{j=1}^{N} e^{i \\phi_j}\\right|$$\n给定 $N=10$ 和相位数据 $\\{\\phi_j\\} = \\{0.5, 0.4, -0.3, 0.2, -0.1, 0.6, -0.5, 0.3, -0.4, 0.1\\}$，我们首先计算复相量之和 $\\sum_{j=1}^{N} e^{i \\phi_j}$。使用欧拉公式 $e^{i\\phi} = \\cos(\\phi) + i\\sin(\\phi)$，这个和可以展开为：\n$$\\sum_{j=1}^{N} e^{i \\phi_j} = \\sum_{j=1}^{N} \\cos(\\phi_j) + i \\sum_{j=1}^{N} \\sin(\\phi_j)$$\n让我们计算这个和的实部和虚部。\n\n对于实部（余弦之和）：\n数据包含大小相等符号相反的相位对：$\\{0.5, -0.5\\}$, $\\{0.4, -0.4\\}$, $\\{0.3, -0.3\\}$ 和 $\\{0.1, -0.1\\}$。由于 $\\cos(-\\phi) = \\cos(\\phi)$，余弦之和为：\n$$\\sum_{j=1}^{10} \\cos(\\phi_j) = 2\\cos(0.5) + 2\\cos(0.4) + 2\\cos(0.3) + 2\\cos(0.1) + \\cos(0.2) + \\cos(0.6)$$\n使用以下值（以弧度为单位）：\n$\\cos(0.1) \\approx 0.99500$, $\\cos(0.2) \\approx 0.98007$, $\\cos(0.3) \\approx 0.95534$, $\\cos(0.4) \\approx 0.92106$, $\\cos(0.5) \\approx 0.87758$, $\\cos(0.6) \\approx 0.82534$。\n$$ \\sum_{j=1}^{10} \\cos(\\phi_j) \\approx 2(0.87758) + 2(0.92106) + 2(0.95534) + 2(0.99500) + 0.98007 + 0.82534 $$\n$$ \\approx 1.75516 + 1.84212 + 1.91068 + 1.99000 + 0.98007 + 0.82534 = 9.30337 $$\n\n对于虚部（正弦之和）：\n由于 $\\sin(-\\phi) = -\\sin(\\phi)$，对于每一对相位 $\\{\\phi, -\\phi\\}$，它们的正弦之和为 $\\sin(\\phi) + \\sin(-\\phi) = 0$。数据由四对这样的相位以及相位 $0.2$ 和 $0.6$ 组成。\n$$\\sum_{j=1}^{10} \\sin(\\phi_j) = (\\sin(0.5)+\\sin(-0.5)) + (\\sin(0.4)+\\sin(-0.4)) + (\\sin(0.3)+\\sin(-0.3)) + (\\sin(0.1)+\\sin(-0.1)) + \\sin(0.2) + \\sin(0.6)$$\n$$ = 0 + 0 + 0 + 0 + \\sin(0.2) + \\sin(0.6) $$\n使用以下值（以弧度为单位）：\n$\\sin(0.2) \\approx 0.19867$, $\\sin(0.6) \\approx 0.56464$。\n$$ \\sum_{j=1}^{10} \\sin(\\phi_j) \\approx 0.19867 + 0.56464 = 0.76331 $$\n\n现在，我们求平均合向量：\n$$ \\frac{1}{N}\\sum_{j=1}^{N} e^{i \\phi_j} = \\frac{1}{10}(9.30337 + i \\cdot 0.76331) = 0.930337 + i \\cdot 0.076331 $$\n最后，$PLV$ 是这个向量的模：\n$$ PLV = |0.930337 + i \\cdot 0.076331| = \\sqrt{(0.930337)^2 + (0.076331)^2} $$\n$$ PLV \\approx \\sqrt{0.86552 + 0.00583} = \\sqrt{0.87135} \\approx 0.93346 $$\n因此，计算出的值为 $PLV \\approx 0.93$。\n\n**2. $PLV$、平均合向量长度和集中度 $\\kappa$ 之间的关系**\n\n量 $PLV$ 是经验或样本的“平均合向量长度”，通常表示为 $\\bar{R}$。它是一个统计量，用于估计潜在概率分布的理论平均合向量长度 $R$。对于 von Mises 分布 $p(\\phi \\mid \\mu,\\kappa)$，理论平均合向量长度由第一类修正贝塞尔函数的比值给出：\n$$R = \\mathbb{E}[\\cos(\\phi-\\mu)] = \\frac{I_1(\\kappa)}{I_0(\\kappa)} \\equiv A(\\kappa)$$\n函数 $A(\\kappa)$ 是集中度参数 $\\kappa$ 的严格单调递增函数，其中 $A(0)=0$ 且 $\\lim_{\\kappa\\to\\infty} A(\\kappa)=1$。因此，平均合向量长度（由 $PLV$ 估计）的值越大，对应于相位聚集程度越高，这意味着生成 von Mises 分布的集中度参数 $\\kappa$ 的值越大。“$PLV$ 随环形集中度单调增加”这一说法是正确的。\n\n**3. 费雪信息 ($J$)、$\\kappa$ 和 $N$ 之间的关系**\n\n对于来自独立同分布 (i.i.d.) 的大小为 $N$ 的样本，参数 $\\theta$ 的费雪信息 ($J$) 是单个观测值的费雪信息的 $N$ 倍。我们需要平均相位参数 $\\mu$ 的费雪信息。对于来自 von Mises 分布的单个观测值 $\\phi$，其对数概率为：\n$$\\ln p(\\phi \\mid \\mu, \\kappa) = \\kappa \\cos(\\phi - \\mu) - \\ln(2\\pi I_0(\\kappa))$$\n得分函数，即关于 $\\mu$ 的导数，是：\n$$\\frac{\\partial}{\\partial \\mu} \\ln p(\\phi \\mid \\mu, \\kappa) = \\kappa \\sin(\\phi - \\mu)$$\n单个观测值的费雪信息 $J_1(\\mu)$ 是得分函数平方的期望值：\n$$J_1(\\mu) = \\mathbb{E}\\left[\\left(\\kappa \\sin(\\phi - \\mu)\\right)^2\\right] = \\kappa^2 \\mathbb{E}\\left[\\sin^2(\\phi - \\mu)\\right]$$\nvon Mises 分布的一个已知性质是 $\\mathbb{E}\\left[\\sin^2(\\phi - \\mu)\\right] = \\frac{1}{\\kappa}\\frac{I_1(\\kappa)}{I_0(\\kappa)} = \\frac{A(\\kappa)}{\\kappa}$。代入可得：\n$$J_1(\\mu) = \\kappa^2 \\left(\\frac{A(\\kappa)}{\\kappa}\\right) = \\kappa A(\\kappa)$$\n对于 $N$ 个独立同分布的观测值，总费雪信息为：\n$$J = N \\cdot J_1(\\mu) = N \\kappa A(\\kappa)$$\n问题要求的是“相位足够集中”时的关系，这对应于大 $\\kappa$ 极限。在此极限下，$A(\\kappa) = I_1(\\kappa)/I_0(\\kappa)$ 的渐近展开为 $A(\\kappa) \\approx 1 - \\frac{1}{2\\kappa}$。当 $\\kappa \\to \\infty$ 时，$A(\\kappa) \\to 1$。\n因此，对于大 $\\kappa$，费雪信息近似为：\n$$J \\approx N \\kappa (1) = N\\kappa$$\n这表明，对于高度集中的相位，关于平均相位 $\\mu$ 的费雪信息与脉冲数量 $N$ 呈线性关系，并与集中度参数 $\\kappa$ 近似呈线性关系。\n\n### 选项评估\n\n*   **A. $PLV \\approx 0.93$。$PLV$ 等于平均合向量长度，并随环形集中度的增加而单调增加；在 VM 模型下，较大的 $PLV$ 意味着较大的 $\\kappa$，并且对于足够集中的相位，关于 $\\mu$ 的费雪信息与 $\\kappa$ 和脉冲数量 $N$ 近似呈线性关系 (即 $J \\propto N \\kappa$)。**\n    -   $PLV \\approx 0.93$：**正确**，如计算所示。\n    -   $PLV$ 等于平均合向量长度：**正确**，根据定义（更准确地说，是样本平均合向量长度）。\n    -   $PLV$ 随环形集中度单調增加：**正确**。\n    -   更大的 $PLV$ 意味着更大的 $\\kappa$：**正确**。\n    -   对于足够集中的相位，$J \\propto N \\kappa$：**正确**，从大 $\\kappa$ 近似推导得出。\n    -   结论: **正确**。\n\n*   **B. $PLV \\approx 0.50$。$PLV$ 随环形集中度的增加而减小；关于 $\\mu$ 的费雪信息与 $\\kappa$ 成反比，且与 $N$ 无关 (即 $J \\propto \\kappa^{-1}$)。**\n    -   $PLV \\approx 0.50$：**不正确**。值为 $\\approx 0.93$。\n    -   $PLV$ 随集中度增加而减小：**不正确**。它会增加。\n    -   $J \\propto \\kappa^{-1}$ 且与 $N$ 无关：**不正确**。$J$ 随 $\\kappa$ 和 $N$ 的增加而增加。\n    -   结论: **不正确**。\n\n*   **C. $PLV \\approx 0.93$。$PLV$ 在数值上等于集中度参数 $\\kappa$；关于 $\\mu$ 的费雪信息与 $\\kappa$ 呈二次关系，与 $N$ 呈线性关系 (即 $J \\propto N \\kappa^2$)。**\n    -   $PLV \\approx 0.93$：**正确**。\n    -   $PLV$ 在数值上等于 $\\kappa$：**不正确**。$PLV$ 是 $A(\\kappa) = I_1(\\kappa)/I_0(\\kappa)$ 的样本估计，对于有限的 $\\kappa$，该值始终小于 $1$，而 $\\kappa$ 可以是任何非负值。\n    -   $J \\propto N \\kappa^2$：**不正确**。这种缩放关系适用于小 $\\kappa$ (其中 $A(\\kappa)\\approx\\kappa/2$)，而不适用于“足够集中的相位” (大 $\\kappa$)，此时的缩放关系是 $J \\propto N\\kappa$。\n    -   结论: **不正确**。\n\n*   **D. $PLV \\approx 0.80$。$PLV$ 随环形集中度的增加而增加，但关于 $\\mu$ 的费雪信息与 $\\kappa$ 无关，仅与 $\\sqrt{N}$ 成比例 (即 $J \\propto \\sqrt{N}$)。**\n    -   $PLV \\approx 0.80$：**不正确**。值为 $\\approx 0.93$。\n    -   $J$ 与 $\\kappa$ 无关：**不正确**。费雪信息强烈依赖于 $\\kappa$。\n    -   $J \\propto \\sqrt{N}$：**不正确**。对于独立同分布样本，费雪信息与 $N$ 成比例，而不是 $\\sqrt{N}$。有效估计量的*标准误*与 $1/\\sqrt{J} \\propto 1/\\sqrt{N}$ 成比例。\n    -   结论: **不正确**。\n\n根据详细分析，只有选项 A 的所有陈述都是正确的。",
            "answer": "$$\\boxed{A}$$"
        },
        {
            "introduction": "除了简单地检测时间编码的存在，一个关键的挑战是“解读神经邮件”——也就是解码脉冲所携带的信息。这项练习将带你走过为神经脉冲相位编码的刺激构建一个基于统计学原理的解码器的过程。通过推导和计算解码器的期望误差，你将深入了解解码精度的基本限制，以及它如何依赖于脉冲数量和神经元的时间精度。",
            "id": "4003068",
            "problem": "某个刺激特征由相对于一个已知的持续振荡的脉冲相位进行编码，这是一个时间编码的例子。考虑单次试验，其中一个解码器观测到 $N$ 个脉冲相位 $\\{\\phi_{k}\\}_{k=1}^{N}$，每个相位都在圆周 $[0,2\\pi)$ 上定义，表示脉冲相对于该振荡的相位。假设在给定未知刺激相位 $\\theta$ 的条件下，每个相位的条件分布是独立同分布的，并且服从冯·米塞斯分布（von Mises distribution），其集中参数为 $\\kappa$，平均方向为 $\\theta$。也就是说，对于每个脉冲，\n$$\np(\\phi \\mid \\theta) = \\frac{1}{2\\pi I_{0}(\\kappa)} \\exp\\!\\big(\\kappa \\cos(\\phi - \\theta)\\big),\n$$\n其中 $I_{0}(\\kappa)$ 表示第一类零阶修正贝塞尔函数。该相位分布的群体级环形方差（circular variance）定义为 $\\mathcal{V} = 1 - \\rho$，其中平均合成向量长度 $\\rho$ 为 $\\rho = I_{1}(\\kappa)/I_{0}(\\kappa)$，而 $I_{1}(\\kappa)$ 是第一类一阶修正贝塞尔函数。\n\n从这些定义和独立性假设出发，基于观测到的相位 $\\{\\phi_{k}\\}_{k=1}^{N}$ 构建一个符合统计学原理的 $\\theta$ 解码器。在高集中度情况下（即冯·米塞斯分布可以近似为圆上的小噪声模型），推导相位估计的期望均方误差的近似表达式，该表达式应是环形方差 $\\mathcal{V}$ 和脉冲数 $N$ 的函数。\n\n对 $N = 50$ 个脉冲和环形方差 $\\mathcal{V} = 0.15$ 的情况，数值计算这个近似值。最终误差以弧度的平方为单位表示，并将答案四舍五入到四位有效数字。",
            "solution": "该问题提出了一个计算神经科学领域中关于从时间脉冲编码中解码刺激特征的有效且定义明确的问题。所提供的基于冯·米塞斯分布的模型，是分析相位编码的标准且有科学依据的框架。假设被清晰地陈述，任务是推导并评估一个符合统计学原理的解码器的性能。没有科学或逻辑上的缺陷，并且提供了所有必要的信息。\n\n我们首先从观测到的脉冲相位 $\\{\\phi_k\\}_{k=1}^{N}$ 开始，为未知的刺激相位 $\\theta$ 构建一个符合统计学原理的解码器。最大似然估计（Maximum Likelihood Estimator, MLE）是此类任务的典型选择。对于 $N$ 个独立同分布的脉冲相位集合，其似然函数 $L(\\theta)$ 是它们各自概率密度函数的乘积：\n$$\nL(\\theta \\mid \\{\\phi_k\\}) = \\prod_{k=1}^{N} p(\\phi_k \\mid \\theta) = \\prod_{k=1}^{N} \\frac{1}{2\\pi I_0(\\kappa)} \\exp\\big(\\kappa \\cos(\\phi_k - \\theta)\\big)\n$$\n为简化最大化过程，我们使用对数似然函数 $\\ln L(\\theta)$：\n$$\n\\ln L(\\theta) = \\sum_{k=1}^{N} \\left[ -\\ln(2\\pi) - \\ln(I_0(\\kappa)) + \\kappa \\cos(\\phi_k - \\theta) \\right]\n$$\n$\\theta$ 的最大似然估计（记为 $\\hat{\\theta}$）是使 $\\ln L(\\theta)$ 最大化的 $\\theta$ 值。这等价于最大化依赖于 $\\theta$ 的项：\n$$\n\\hat{\\theta} = \\arg\\max_{\\theta} \\sum_{k=1}^{N} \\kappa \\cos(\\phi_k - \\theta) = \\arg\\max_{\\theta} \\sum_{k=1}^{N} \\cos(\\phi_k - \\theta)\n$$\n使用三角恒等式 $\\cos(a - b) = \\cos a \\cos b + \\sin a \\sin b$，求和项变为：\n$$\n\\sum_{k=1}^{N} \\cos(\\phi_k - \\theta) = \\left(\\sum_{k=1}^{N} \\cos\\phi_k\\right)\\cos\\theta + \\left(\\sum_{k=1}^{N} \\sin\\phi_k\\right)\\sin\\theta\n$$\n该表达式的形式为 $C \\cos\\theta + S \\sin\\theta$，其中 $C = \\sum_{k=1}^{N} \\cos\\phi_k$ 且 $S = \\sum_{k=1}^{N} \\sin\\phi_k$。这可以重写为 $R \\cos(\\theta - \\bar{\\phi})$ 的形式，其中振幅 $R = \\sqrt{C^2 + S^2}$，相位角 $\\bar{\\phi} = \\operatorname{atan2}(S, C)$，即四象限反正切。当其余弦项等于 $1$ 时，该表达式取得最大值，这发生在 $\\theta = \\bar{\\phi}$ 时。因此，最大似然估计解码器是观测相位的环形均值：\n$$\n\\hat{\\theta} = \\operatorname{atan2}\\left(\\sum_{k=1}^{N} \\sin\\phi_k, \\sum_{k=1}^{N} \\cos\\phi_k\\right)\n$$\n接下来，我们在高集中度假设（$\\kappa \\gg 1$）下，推导期望均方误差（MSE）的近似值，其定义为 $E[(\\hat{\\theta} - \\theta)^2]$。在这种情况下，冯·米塞斯分布在其均值 $\\theta$ 附近呈尖锐峰值，对于小的偏差 $(\\phi - \\theta)$，我们可以近似为 $\\cos(\\phi - \\theta) \\approx 1 - \\frac{(\\phi - \\theta)^2}{2}$。冯·米塞斯概率密度函数（PDF）变为：\n$$\np(\\phi \\mid \\theta) \\approx \\frac{1}{2\\pi I_0(\\kappa)} \\exp\\left(\\kappa \\left[1 - \\frac{(\\phi - \\theta)^2}{2}\\right]\\right) = \\frac{e^{\\kappa}}{2\\pi I_0(\\kappa)} \\exp\\left(-\\frac{(\\phi - \\theta)^2}{2(1/\\kappa)}\\right)\n$$\n使用大 $\\kappa$ 值下修正贝塞尔函数的渐近展开式 $I_0(\\kappa) \\approx \\frac{\\exp(\\kappa)}{\\sqrt{2\\pi\\kappa}}$，归一化常数简化为 $\\frac{1}{\\sqrt{2\\pi(1/\\kappa)}}$。因此，冯·米塞斯分布可以很好地近似为直线上的正态分布：\n$$\np(\\phi \\mid \\theta) \\approx \\mathcal{N}(\\theta, \\sigma^2 = 1/\\kappa)\n$$\n在这个高斯近似下，相位集合 $\\{\\phi_k\\}$ 可以被视为来自均值为 $\\theta$、方差为 $1/\\kappa$ 的正态分布的独立同分布样本。对于正态分布，最大似然估计 $\\hat{\\theta}$ 就是样本的算术平均值，这对于紧密聚集的数据与环形均值是一致的：\n$$\n\\hat{\\theta} \\approx \\frac{1}{N} \\sum_{k=1}^{N} \\phi_k\n$$\n该估计量是无偏的，因为 $E[\\hat{\\theta}] = \\frac{1}{N} \\sum_{k=1}^{N} E[\\phi_k] = \\frac{1}{N} (N\\theta) = \\theta$。该估计量的方差为：\n$$\n\\text{Var}(\\hat{\\theta}) = \\text{Var}\\left(\\frac{1}{N} \\sum_{k=1}^{N} \\phi_k\\right) = \\frac{1}{N^2} \\sum_{k=1}^{N} \\text{Var}(\\phi_k) = \\frac{1}{N^2} \\sum_{k=1}^{N} \\frac{1}{\\kappa} = \\frac{N}{N^2 \\kappa} = \\frac{1}{N\\kappa}\n$$\n由于该估计量是无偏的，其均方误差等于其方差，因此 $\\text{MSE}(\\hat{\\theta}) = E[(\\hat{\\theta} - \\theta)^2] \\approx \\frac{1}{N\\kappa}$。\n\n为了用环形方差 $\\mathcal{V}$ 表示均方误差，我们使用给定的定义 $\\mathcal{V} = 1 - \\rho$ 和 $\\rho = I_1(\\kappa)/I_0(\\kappa)$。我们需要 $\\rho$ 在大 $\\kappa$ 值下的渐近行为。使用展开式 $I_1(\\kappa) \\approx \\frac{\\exp(\\kappa)}{\\sqrt{2\\pi\\kappa}}\\left(1 - \\frac{3}{8\\kappa}\\right)$ 和 $I_0(\\kappa) \\approx \\frac{\\exp(\\kappa)}{\\sqrt{2\\pi\\kappa}}\\left(1 + \\frac{1}{8\\kappa}\\right)$，它们的比值为：\n$$\n\\rho \\approx \\frac{1 - 3/(8\\kappa)}{1 + 1/(8\\kappa)} \\approx \\left(1 - \\frac{3}{8\\kappa}\\right)\\left(1 - \\frac{1}{8\\kappa}\\right) \\approx 1 - \\frac{4}{8\\kappa} = 1 - \\frac{1}{2\\kappa}\n$$\n现在，我们找出 $\\mathcal{V}$ 和 $\\kappa$ 之间的关系：\n$$\n\\mathcal{V} = 1 - \\rho \\approx 1 - \\left(1 - \\frac{1}{2\\kappa}\\right) = \\frac{1}{2\\kappa}\n$$\n这意味着对于大 $\\kappa$ 值，$\\kappa \\approx \\frac{1}{2\\mathcal{V}}$。将此代入我们的均方误差表达式中，得到最终的近似值：\n$$\n\\text{MSE}(\\hat{\\theta}) \\approx \\frac{1}{N\\kappa} \\approx \\frac{1}{N (1/(2\\mathcal{V}))} = \\frac{2\\mathcal{V}}{N}\n$$\n最后，我们对给定的值 $N = 50$ 和 $\\mathcal{V} = 0.15$ 对此表达式进行数值计算。使用这个近似是合理的，因为 $\\mathcal{V} = 0.15$ 意味着 $\\kappa \\approx \\frac{1}{2(0.15)} = \\frac{1}{0.3} \\approx 3.33$，这是一个中等大小的值。\n$$\n\\text{MSE}(\\hat{\\theta}) \\approx \\frac{2 \\times 0.15}{50} = \\frac{0.30}{50} = \\frac{3}{500} = 0.006\n$$\n问题要求将答案四舍五入到四位有效数字。因此，期望均方误差约为 $0.006000$ 弧度平方。",
            "answer": "$$\n\\boxed{0.006000}\n$$"
        },
        {
            "introduction": "神经元面临一个选择：是用脉冲的数量（速率编码）还是用其精确的时间（时间编码）来编码信息。哪种策略更有效？这个练习将引导你使用强大的信息论框架进行一次正式的比较。通过推导基于潜伏期的时间编码和基于计数的速率编码的互信息，你将揭示两者间的解析权衡，并精确地看到像时间抖动和脉冲计数变异性这样的因素是如何决定一种编码方案相对于另一种的优越性的。",
            "id": "4003129",
            "problem": "考虑一个感觉神经元，它通过基于延迟的时间编码或基于计数的速率编码来编码一个标量刺激 $s \\in \\mathbb{R}$。该刺激是随机的，服从高斯先验分布 $s \\sim \\mathcal{N}(0, v_{s})$。在延迟编码中，该神经元在每次试验中可靠地发出第一个尖峰，其延迟 $t$ 建模为 $t = t_{0} + a s + \\varepsilon$，其中 $t_{0}$ 是一个恒定的基线延迟，$a \\neq 0$ 是一个固定的灵敏度参数，而 $\\varepsilon \\sim \\mathcal{N}(0, \\sigma^{2})$ 表示方差为 $\\sigma^{2}$ 的加性时间抖动。在速率编码中，神经元在一个持续时间为 $T > 0$ 的固定观测窗口内，根据一个齐次泊松过程发出尖峰，该过程的速率 $\\lambda(s) = \\bar{\\lambda} + k s$ 依赖于刺激，其中 $k$ 是一个固定的灵敏度参数，$\\bar{\\lambda} > 0$ 的选择使得每次试验的匹配平均尖峰计数为 $M = \\bar{\\lambda} T$（假设 $M \\geq 10$ 以支持对泊松分布进行正态近似）。设观测到的计数为 $N$，经验速率为 $Y_{R} = N/T$。\n\n使用信息论的基本原理（随机变量的香农互信息）和在指定条件下对速率编码观测值 $Y_{R}$ 的高斯近似，推导每种编码范式的互信息（以奈特为单位），并通过相减得到互信息之差的解析表达式\n$$\\Delta I(\\sigma^{2}) = I_{\\text{latency}} - I_{\\text{rate}}$$\n该表达式是抖动方差 $\\sigma^{2}$、先验方差 $v_{s}$、灵敏度参数 $a$ 和 $k$、观测窗口 $T$ 以及匹配的平均尖峰计数 $M$ 的函数。将您的最终答案以奈特为单位，表示为单个闭式符号表达式。无需进行数值舍入。",
            "solution": "我们从连续随机变量的香农互信息的定义开始，以奈特表示：\n$$\nI(X;Y) = h(Y) - h(Y \\mid X),\n$$\n其中 $h(\\cdot)$ 表示微分熵。对于延迟编码，观测值为 $t = t_{0} + a s + \\varepsilon$，其中 $s \\sim \\mathcal{N}(0, v_{s})$ 且 $\\varepsilon \\sim \\mathcal{N}(0, \\sigma^{2})$，且与 $s$ 无关。对于速率编码，观测值为经验速率 $Y_{R} = N/T$，其中 $N$ 是均值为 $\\lambda(s) T = (\\bar{\\lambda} + k s) T$ 的泊松变量。在匹配平均尖峰计数 $M = \\bar{\\lambda} T$ 和假设 $M \\geq 10$ 的条件下，我们用正态分布近似泊松分布，并通过用其在刺激上的平均值替换方差，来线性化方差对 $s$ 的依赖性，从而得到一个高斯观测模型。\n\n延迟编码。由于 $t = t_{0} + a s + \\varepsilon$，加性常数 $t_{0}$ 不影响微分熵或互信息。有效观测值为 $Y_{L} = a s + \\varepsilon$，其中 $s \\sim \\mathcal{N}(0, v_{s})$ 且 $\\varepsilon \\sim \\mathcal{N}(0, \\sigma^{2})$；$s$ 和 $\\varepsilon$ 是独立的。那么 $Y_{L}$ 是方差为 $a^{2} v_{s} + \\sigma^{2}$ 的高斯变量。使用高斯分布 $X \\sim \\mathcal{N}(0, \\nu)$ 的熵公式 $h(X) = \\frac{1}{2} \\ln(2 \\pi \\exp(1) \\nu)$，我们有\n$$\nh(Y_{L}) = \\frac{1}{2} \\ln\\!\\big( 2 \\pi \\exp(1) (a^{2} v_{s} + \\sigma^{2}) \\big),\n\\qquad\nh(Y_{L} \\mid s) = h(\\varepsilon) = \\frac{1}{2} \\ln\\!\\big( 2 \\pi \\exp(1) \\sigma^{2} \\big).\n$$\n因此，\n$$\nI_{\\text{latency}} = h(Y_{L}) - h(Y_{L} \\mid s)\n= \\frac{1}{2} \\ln\\!\\left( \\frac{a^{2} v_{s} + \\sigma^{2}}{\\sigma^{2}} \\right)\n= \\frac{1}{2} \\ln\\!\\left( 1 + \\frac{a^{2} v_{s}}{\\sigma^{2}} \\right).\n$$\n\n速率编码。尖峰计数 $N \\mid s \\sim \\text{Poisson}((\\bar{\\lambda} + k s) T)$。对于 $M = \\bar{\\lambda} T \\geq 10$，我们将 $N \\mid s$ 近似为均值为 $(\\bar{\\lambda} + k s) T$、方差为 $(\\bar{\\lambda} + k s) T$ 的高斯分布。经验速率 $Y_{R} = N/T$ 于是满足\n$$\nY_{R} \\mid s \\approx \\mathcal{N}\\!\\left( \\bar{\\lambda} + k s, \\frac{\\bar{\\lambda} + k s}{T} \\right).\n$$\n因为噪声方差依赖于 $s$，精确的互信息表达式难以求得；然而，对于 $s$ 在其均值附近的小幅波动，并且为了获得一个易于处理的近似，我们用方差在所有刺激上的平均值来代替它，得到\n$$\nY_{R} \\mid s \\approx \\mathcal{N}\\!\\left( \\bar{\\lambda} + k s, \\frac{\\bar{\\lambda}}{T} \\right).\n$$\n定义减去均值的观测值 $Z_{R} = Y_{R} - \\bar{\\lambda}$，于是\n$$\nZ_{R} = k s + \\eta,\n\\quad \\text{其中} \\quad \\eta \\sim \\mathcal{N}\\!\\left( 0, \\frac{\\bar{\\lambda}}{T} \\right),\n\\quad s \\sim \\mathcal{N}(0, v_{s}),\n\\quad \\eta \\perp s.\n$$\n因此 $Z_{R}$ 是方差为 $k^{2} v_{s} + \\frac{\\bar{\\lambda}}{T}$ 的高斯变量。使用高斯熵公式，\n$$\nh(Z_{R}) = \\frac{1}{2} \\ln\\!\\left( 2 \\pi \\exp(1) \\left( k^{2} v_{s} + \\frac{\\bar{\\lambda}}{T} \\right) \\right),\n\\qquad\nh(Z_{R} \\mid s) = h(\\eta) = \\frac{1}{2} \\ln\\!\\left( 2 \\pi \\exp(1) \\frac{\\bar{\\lambda}}{T} \\right).\n$$\n因此，\n$$\nI_{\\text{rate}} = h(Z_{R}) - h(Z_{R} \\mid s)\n= \\frac{1}{2} \\ln\\!\\left( \\frac{k^{2} v_{s} + \\frac{\\bar{\\lambda}}{T}}{\\frac{\\bar{\\lambda}}{T}} \\right)\n= \\frac{1}{2} \\ln\\!\\left( 1 + \\frac{k^{2} v_{s} T}{\\bar{\\lambda}} \\right).\n$$\n在匹配平均尖峰计数条件 $M = \\bar{\\lambda} T$ 下，我们有 $\\bar{\\lambda} = \\frac{M}{T}$，这得到\n$$\nI_{\\text{rate}} = \\frac{1}{2} \\ln\\!\\left( 1 + \\frac{k^{2} v_{s} T}{M/T} \\right)\n= \\frac{1}{2} \\ln\\!\\left( 1 + \\frac{k^{2} v_{s} T^{2}}{M} \\right).\n$$\n\n互信息之差。从延迟编码的互信息中减去速率编码的互信息，\n$$\n\\Delta I(\\sigma^{2}) = I_{\\text{latency}} - I_{\\text{rate}}\n= \\frac{1}{2} \\ln\\!\\left( 1 + \\frac{a^{2} v_{s}}{\\sigma^{2}} \\right)\n- \\frac{1}{2} \\ln\\!\\left( 1 + \\frac{k^{2} v_{s} T^{2}}{M} \\right).\n$$\n合并对数项，\n$$\n\\Delta I(\\sigma^{2}) = \\frac{1}{2} \\ln\\!\\left( \\frac{1 + \\frac{a^{2} v_{s}}{\\sigma^{2}}}{1 + \\frac{k^{2} v_{s} T^{2}}{M}} \\right).\n$$\n这个表达式以奈特为单位，并明确显示了在匹配平均尖峰 $M = \\bar{\\lambda} T$ 和对基于计数的观测值进行高斯近似的条件下，时间抖动方差 $\\sigma^{2}$ 如何相对于速率编码互信息降低延迟编码的互信息。",
            "answer": "$$\\boxed{\\frac{1}{2}\\,\\ln\\!\\left(\\frac{1+\\frac{a^{2}v_{s}}{\\sigma^{2}}}{1+\\frac{k^{2}v_{s}T^{2}}{M}}\\right)}$$"
        }
    ]
}