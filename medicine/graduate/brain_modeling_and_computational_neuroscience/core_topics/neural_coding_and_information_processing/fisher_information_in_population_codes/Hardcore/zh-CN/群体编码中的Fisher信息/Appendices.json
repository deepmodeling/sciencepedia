{
    "hands_on_practices": [
        {
            "introduction": "我们的第一个练习将从基础入手。我们将为一个由独立神经元组成的群体推导费雪信息，其中每个神经元都由一个简单的广义线性模型（GLM）描述 。这个练习至关重要，它能帮助我们理解费雪信息的抽象定义如何转化为基于神经元调谐曲线特性的具体公式，并揭示信息是如何源于模型参数对刺激的敏感性。",
            "id": "3981091",
            "problem": "考虑一个在小时间窗内记录的、由 $N$ 个条件独立的二元神经元组成的群体。令 $r_i \\in \\{0,1\\}$ 表示神经元 $i$ 在该时间窗内的脉冲，令 $s \\in \\mathbb{R}$ 为一维刺激参数。假设在给定 $s$ 的条件下，每个神经元都遵循一个带有逻辑斯蒂链接的广义线性模型 (GLM)：对每个 $i \\in \\{1,\\dots,N\\}$，\n$$\n\\Pr(r_i=1 \\mid s) \\equiv p_i(s) = \\sigma\\!\\big(a_i(s)\\big), \\quad \\text{其中} \\quad \\sigma(z) = \\frac{1}{1+\\exp(-z)},\n$$\n其中 $a_i(s)$ 是关于 $s$ 的二次连续可微函数，且在给定 $s$ 的条件下 $\\{r_i\\}_{i=1}^N$ 是独立的。假设所有关于响应分布 $\\Pr(\\mathbf{r}\\mid s)$ 的期望都存在且有限。\n\n从参数族的 Fisher 信息的标准定义出发，推导关于标量参数 $s$ 的群体响应 $\\mathbf{r} = (r_1,\\dots,r_N)$ 的 Fisher 信息 $I(s)$ 的闭式解析表达式，该表达式仅用 $\\{a_i(s)\\}$、它们对 $s$ 的导数以及 $\\sigma$ 来表示。请以最简形式给出 $I(s)$ 的最终表达式。请以单个闭式解析表达式的形式提供您的答案，无需单位。",
            "solution": "该问题陈述经证实具有科学依据、问题适定、客观且完整。严格推导所需的所有条件均已提供。\n\n给定观测值 $\\mathbf{r}$，参数 $s$ 的 Fisher 信息 $I(s)$ 定义为得分函数平方的期望值，其中得分函数是数据对数似然函数关于参数的导数。\n$$\nI(s) = \\mathbb{E}_{\\mathbf{r}|s} \\left[ \\left( \\frac{\\partial}{\\partial s} \\ln \\Pr(\\mathbf{r} \\mid s) \\right)^2 \\right]\n$$\n神经响应向量为 $\\mathbf{r} = (r_1, \\dots, r_N)$，其中每个 $r_i$ 是一个二元随机变量，$r_i \\in \\{0, 1\\}$。在给定刺激 $s$ 的条件下，神经元是条件独立的。因此，联合概率质量函数（似然函数）是各个概率的乘积：\n$$\n\\Pr(\\mathbf{r} \\mid s) = \\prod_{i=1}^N \\Pr(r_i \\mid s)\n$$\n对于每个神经元 $i$，由于 $r_i$ 是二元的，其响应遵循伯努利分布。发生脉冲（$r_i=1$）的概率由 $p_i(s) = \\Pr(r_i=1 \\mid s)$ 给出。因此，单个神经元的概率质量函数可以写为：\n$$\n\\Pr(r_i \\mid s) = p_i(s)^{r_i} \\big(1 - p_i(s)\\big)^{1-r_i}\n$$\n该群体的完整似然函数为：\n$$\n\\Pr(\\mathbf{r} \\mid s) = \\prod_{i=1}^N p_i(s)^{r_i} \\big(1 - p_i(s)\\big)^{1-r_i}\n$$\n下一步是计算似然函数的自然对数：\n$$\n\\ln \\Pr(\\mathbf{r} \\mid s) = \\ln \\left( \\prod_{i=1}^N p_i(s)^{r_i} \\big(1 - p_i(s)\\big)^{1-r_i} \\right) = \\sum_{i=1}^N \\ln \\left( p_i(s)^{r_i} \\big(1 - p_i(s)\\big)^{1-r_i} \\right)\n$$\n$$\n\\ln \\Pr(\\mathbf{r} \\mid s) = \\sum_{i=1}^N \\left[ r_i \\ln p_i(s) + (1-r_i) \\ln\\big(1 - p_i(s)\\big) \\right]\n$$\n现在，我们将对数似然函数对 $s$ 求导，以获得得分函数。令 $a_i'(s) = \\frac{da_i}{ds}$。\n$$\n\\frac{\\partial}{\\partial s} \\ln \\Pr(\\mathbf{r} \\mid s) = \\sum_{i=1}^N \\left[ r_i \\frac{1}{p_i(s)}\\frac{dp_i}{ds} + (1-r_i) \\frac{1}{1-p_i(s)} \\left(-\\frac{dp_i}{ds}\\right) \\right]\n$$\n$$\n= \\sum_{i=1}^N \\frac{dp_i}{ds} \\left[ \\frac{r_i}{p_i(s)} - \\frac{1-r_i}{1-p_i(s)} \\right] = \\sum_{i=1}^N \\frac{dp_i}{ds} \\left[ \\frac{r_i\\big(1-p_i(s)\\big) - \\big(1-r_i\\big)p_i(s)}{p_i(s)\\big(1-p_i(s)\\big)} \\right]\n$$\n$$\n= \\sum_{i=1}^N \\frac{dp_i}{ds} \\left[ \\frac{r_i - r_i p_i(s) - p_i(s) + r_i p_i(s)}{p_i(s)\\big(1-p_i(s)\\big)} \\right] = \\sum_{i=1}^N \\frac{dp_i}{ds} \\frac{r_i - p_i(s)}{p_i(s)\\big(1-p_i(s)\\big)}\n$$\n我们需要计算导数 $\\frac{dp_i}{ds}$。已知 $p_i(s) = \\sigma(a_i(s))$，其中 $\\sigma(z) = (1+\\exp(-z))^{-1}$。sigmoid 函数 $\\sigma(z)$ 的导数是一个标准结果：\n$$\n\\sigma'(z) = \\frac{d}{dz}(1+\\exp(-z))^{-1} = -1(1+\\exp(-z))^{-2}(-\\exp(-z)) = \\frac{\\exp(-z)}{(1+\\exp(-z))^2}\n$$\n这可以写成 $\\sigma'(z) = \\frac{1}{1+\\exp(-z)} \\frac{\\exp(-z)}{1+\\exp(-z)} = \\sigma(z)(1-\\sigma(z))$。\n对 $\\frac{dp_i}{ds}$ 使用链式法则：\n$$\n\\frac{dp_i}{ds} = \\frac{d}{ds}\\sigma(a_i(s)) = \\sigma'(a_i(s)) \\cdot a_i'(s) = \\sigma(a_i(s))\\big(1-\\sigma(a_i(s))\\big) a_i'(s) = p_i(s)\\big(1-p_i(s)\\big) a_i'(s)\n$$\n将此结果代回得分函数的表达式中：\n$$\n\\frac{\\partial}{\\partial s} \\ln \\Pr(\\mathbf{r} \\mid s) = \\sum_{i=1}^N a_i'(s) p_i(s)\\big(1-p_i(s)\\big) \\frac{r_i - p_i(s)}{p_i(s)\\big(1-p_i(s)\\big)} = \\sum_{i=1}^N a_i'(s) \\big(r_i - p_i(s)\\big)\n$$\n这就是得分函数。为了求得 Fisher 信息，我们计算其平方的期望值：\n$$\nI(s) = \\mathbb{E} \\left[ \\left( \\sum_{i=1}^N a_i'(s) \\big(r_i - p_i(s)\\big) \\right)^2 \\right] = \\mathbb{E} \\left[ \\sum_{i=1}^N \\sum_{j=1}^N a_i'(s)a_j'(s)\\big(r_i - p_i(s)\\big)\\big(r_j - p_j(s)\\big) \\right]\n$$\n根据期望的线性性质，我们可以将期望移到求和符号内：\n$$\nI(s) = \\sum_{i=1}^N \\sum_{j=1}^N a_i'(s)a_j'(s) \\mathbb{E} \\left[ \\big(r_i - p_i(s)\\big)\\big(r_j - p_j(s)\\big) \\right]\n$$\n期望项是 $r_i$ 和 $r_j$ 之间的协方差。由于在给定 $s$ 的条件下神经元是条件独立的，因此对于 $i \\neq j$，它们的响应 $r_i$ 和 $r_j$ 是独立的。对于 $i \\neq j$：\n$$\n\\mathbb{E} \\left[ \\big(r_i - p_i(s)\\big)\\big(r_j - p_j(s)\\big) \\right] = \\mathbb{E} \\left[r_i - p_i(s)\\right] \\mathbb{E} \\left[r_j - p_j(s)\\right]\n$$\n根据定义，$\\mathbb{E}[r_k] = 1 \\cdot \\Pr(r_k=1) + 0 \\cdot \\Pr(r_k=0) = p_k(s)$。因此，$\\mathbb{E}[r_k - p_k(s)] = p_k(s) - p_k(s) = 0$。\n所以，所有 $i \\neq j$ 的交叉项都为零。求和简化为 $i=j$ 的项：\n$$\nI(s) = \\sum_{i=1}^N \\big(a_i'(s)\\big)^2 \\mathbb{E} \\left[ \\big(r_i - p_i(s)\\big)^2 \\right]\n$$\n期望项是伯努利变量 $r_i$ 的方差：\n$$\n\\mathbb{E} \\left[ \\big(r_i - p_i(s)\\big)^2 \\right] = \\text{Var}(r_i)\n$$\n成功概率为 $p$ 的伯努利变量的方差是 $p(1-p)$。因此：\n$$\n\\text{Var}(r_i) = p_i(s)\\big(1 - p_i(s)\\big)\n$$\n将此代入 $I(s)$ 的表达式中：\n$$\nI(s) = \\sum_{i=1}^N \\big(a_i'(s)\\big)^2 p_i(s)\\big(1 - p_i(s)\\big)\n$$\n最后，我们用指定的函数来表示它。我们代入 $p_i(s) = \\sigma(a_i(s))$：\n$$\nI(s) = \\sum_{i=1}^N \\big(a_i'(s)\\big)^2 \\sigma(a_i(s))\\big(1 - \\sigma(a_i(s))\\big)\n$$\n该表达式给出了总 Fisher 信息，即为每个神经元 Fisher 信息的总和，这是条件独立性假设的直接结果。来自每个神经元的信息量与其调谐曲线输入 $a_i(s)$ 的导数的平方成正比，也与其输出的方差成正比，当其放电概率 $\\sigma(a_i(s))$ 为 $1/2$ 时，方差最大。为了完全清晰，我们将导数表示为 $\\frac{da_i}{ds}$。\n$$\nI(s) = \\sum_{i=1}^N \\left(\\frac{da_i(s)}{ds}\\right)^2 \\sigma(a_i(s))\\big(1 - \\sigma(a_i(s))\\big)\n$$\n这就是最终的闭式表达式。",
            "answer": "$$\n\\boxed{\\sum_{i=1}^N \\left(\\frac{da_i(s)}{ds}\\right)^2 \\sigma(a_i(s))\\big(1 - \\sigma(a_i(s))\\big)}\n$$"
        },
        {
            "introduction": "感觉刺激很少是一维的。这个练习将我们的分析扩展到多维刺激空间，此时费雪信息（Fisher Information）变成一个矩阵 。你将探索这个矩阵与沿着特定方向辨别刺激时可用信息之间的关系，这是理解神经元群体如何编码复杂特征的关键概念。",
            "id": "3981050",
            "problem": "考虑一个神经群体编码，其中给定一个刺激 $s \\in \\mathbb{R}^{d}$，条件响应 $r \\in \\mathbb{R}^{N}$ 被建模为一个多元正态分布，其均值为 $A(s) \\in \\mathbb{R}^{N}$，协方差矩阵为与刺激无关的对称正定矩阵 $C \\in \\mathbb{R}^{N \\times N}$。令 $\\mu(s) \\equiv A(s)$ 表示平均响应。关于 $s$ 的费雪信息矩阵 $J(s) \\in \\mathbb{R}^{d \\times d}$ 通过得分函数定义如下：\n$$\nJ(s) \\equiv \\mathbb{E}\\!\\left[ \\left(\\nabla_{s} \\ln p(r \\mid s)\\right)\\left(\\nabla_{s} \\ln p(r \\mid s)\\right)^{\\top} \\right],\n$$\n其中期望是关于 $p(r \\mid s)$ 计算的。\n\n你将分两部分进行计算：\n\n- (a)部分：对于任意单位向量 $u \\in \\mathbb{R}^{d}$ (即 $|u| = 1$)，考虑标量化参数表示 $s(t) = s + t\\,u$ 以及在 $t = 0$ 时关于参数 $t$ 的相应标量费雪信息，其定义为：\n$$\nI(t)\\big|_{t=0} \\equiv \\mathbb{E}\\!\\left[ \\left( \\frac{\\partial}{\\partial t} \\ln p\\!\\left(r \\mid s(t)\\right) \\Big|_{t=0} \\right)^{2} \\right].\n$$\n从给定的费雪信息矩阵定义和上述指定的高斯似然模型出发，推导出用 $u$ 和 $J(s)$ 表示的 $I(t)\\big|_{t=0}$ 的显式表达式。\n\n- (b)部分：特别地，考虑 $d = 2$ 和 $N = 3$ 的情况。令平均响应为线性，$A(s) = M s$，其中\n$$\nM \\equiv \\begin{pmatrix}\n1  0 \\\\\n1  1 \\\\\n0  2\n\\end{pmatrix},\n$$\n令协方差为对角矩阵，\n$$\nC \\equiv \\operatorname{diag}(1, 2, 4).\n$$\n取单位方向\n$$\nu \\equiv \\begin{pmatrix} 3/5 \\\\ 4/5 \\end{pmatrix}.\n$$\n计算在任意 $s$ 处沿 $u$ 方向的标量费雪信息，将你的最终结果表示为一个无近似的精确实数。最终答案必须是单个实数值。无需四舍五入。",
            "solution": "该问题是有效的，因为它在科学上基于神经编码中的信息论，问题提法恰当，所有必要信息均已提供，并且以客观、正式的语言陈述。我们分两部分进行解答。\n\n(a)部分：标量费雪信息的推导。\n\n给定一个神经群体编码，其中对刺激 $s \\in \\mathbb{R}^{d}$ 的响应 $r \\in \\mathbb{R}^{N}$ 服从一个多元正态分布，$p(r \\mid s) \\sim \\mathcal{N}(\\mu(s), C)$，其中 $\\mu(s) = A(s)$ 是平均响应，$C$ 是一个与刺激无关的对称正定协方差矩阵。\n\n概率密度函数为\n$$\np(r \\mid s) = \\frac{1}{\\sqrt{(2\\pi)^{N} \\det(C)}} \\exp\\left(-\\frac{1}{2} (r - \\mu(s))^{\\top} C^{-1} (r - \\mu(s))\\right).\n$$\n对数似然 $\\ln p(r \\mid s)$ 为\n$$\n\\ln p(r \\mid s) = -\\frac{N}{2} \\ln(2\\pi) - \\frac{1}{2} \\ln(\\det(C)) - \\frac{1}{2} (r - \\mu(s))^{\\top} C^{-1} (r - \\mu(s)).\n$$\n为了求费雪信息矩阵 $J(s)$，我们首先计算得分函数，即对数似然关于刺激 $s$ 的梯度。不依赖于 $s$ 的项的梯度为零。\n$$\n\\nabla_{s} \\ln p(r \\mid s) = \\nabla_{s} \\left(-\\frac{1}{2} (r - \\mu(s))^{\\top} C^{-1} (r - \\mu(s))\\right).\n$$\n使用矩阵微积分恒等式，特别是二次型的导数，我们得到\n$$\n\\nabla_{s} \\ln p(r \\mid s) = (\\nabla_{s} \\mu(s))^{\\top} C^{-1} (r - \\mu(s)).\n$$\n这里，$\\nabla_{s} \\mu(s)$ 是平均响应函数的雅可比矩阵，维度为 $N \\times d$，我们记作 $\\mu'(s)$。其转置 $(\\mu'(s))^{\\top}$ 的维度为 $d \\times N$。得分函数是一个 $d \\times 1$ 的列向量。\n\n费雪信息矩阵定义为得分函数的协方差：\n$$\nJ(s) = \\mathbb{E}\\left[ (\\nabla_{s} \\ln p(r \\mid s)) (\\nabla_{s} \\ln p(r \\mid s))^{\\top} \\right].\n$$\n代入得分函数的表达式：\n$$\nJ(s) = \\mathbb{E}\\left[ \\left((\\mu'(s))^{\\top} C^{-1} (r - \\mu(s))\\right) \\left((\\mu'(s))^{\\top} C^{-1} (r - \\mu(s))\\right)^{\\top} \\right].\n$$\n$$\nJ(s) = \\mathbb{E}\\left[ (\\mu'(s))^{\\top} C^{-1} (r - \\mu(s)) (r - \\mu(s))^{\\top} (C^{-1})^{\\top} \\mu'(s) \\right].\n$$\n由于 $C$ 是对称的，$C^{-1}$ 也是对称的，所以 $(C^{-1})^{\\top} = C^{-1}$。我们可以将不含随机变量 $r$ 的项从期望中提出来：\n$$\nJ(s) = (\\mu'(s))^{\\top} C^{-1} \\mathbb{E}\\left[ (r - \\mu(s)) (r - \\mu(s))^{\\top} \\right] C^{-1} \\mu'(s).\n$$\n期望 $\\mathbb{E}\\left[ (r - \\mu(s)) (r - \\mu(s))^{\\top} \\right]$ 是 $r$ 的协方差矩阵的定义，即 $C$。\n$$\nJ(s) = (\\mu'(s))^{\\top} C^{-1} C C^{-1} \\mu'(s) = (\\mu'(s))^{\\top} C^{-1} \\mu'(s).\n$$\n这是具有与刺激无关的协方差的高斯群体编码的费雪信息矩阵的通用表达式。\n\n现在，我们考虑单位向量 $u \\in \\mathbb{R}^{d}$ 的标量化参数表示 $s(t) = s + t u$。我们想计算在 $t=0$ 时的标量费雪信息 $I(t)$。参数 $t$ 的得分是 $\\frac{\\partial}{\\partial t} \\ln p(r \\mid s(t))$。根据链式法则：\n$$\n\\frac{\\partial}{\\partial t} \\ln p(r \\mid s(t)) = (\\nabla_{s} \\ln p(r \\mid s(t)))^{\\top} \\frac{d s(t)}{dt}.\n$$\n由于 $\\frac{d s(t)}{dt} = u$，并且在 $t=0$ 时，$s(t) = s$，我们有：\n$$\n\\left. \\frac{\\partial}{\\partial t} \\ln p(r \\mid s(t)) \\right|_{t=0} = (\\nabla_{s} \\ln p(r \\mid s))^{\\top} u.\n$$\n在 $t=0$ 时关于 $t$ 的标量费雪信息是该得分的方差：\n$$\nI(t)\\big|_{t=0} = \\mathbb{E}\\left[ \\left( (\\nabla_{s} \\ln p(r \\mid s))^{\\top} u \\right)^{2} \\right].\n$$\n令得分向量为 $g_s = \\nabla_{s} \\ln p(r \\mid s)$。期望内的表达式是一个标量，所以我们可以将其平方写为 $(g_s^{\\top} u)^{2} = (u^{\\top} g_s)(g_s^{\\top} u) = u^{\\top} (g_s g_s^{\\top}) u$。\n$$\nI(t)\\big|_{t=0} = \\mathbb{E}\\left[ u^{\\top} (g_s g_s^{\\top}) u \\right].\n$$\n由于 $u$ 是一个常数向量，我们可以将其移到期望外面：\n$$\nI(t)\\big|_{t=0} = u^{\\top} \\mathbb{E}\\left[ g_s g_s^{\\top} \\right] u.\n$$\n项 $\\mathbb{E}\\left[ g_s g_s^{\\top} \\right]$ 正是费雪信息矩阵 $J(s)$ 的定义。\n因此，沿方向 $u$ 的标量费雪信息是：\n$$\nI(t)\\big|_{t=0} = u^{\\top} J(s) u.\n$$\n\n(b)部分：特定情况的计算。\n\n给定 $d=2, N=3$，平均响应 $\\mu(s) = M s$，其中 $M = \\begin{pmatrix} 1  0 \\\\ 1  1 \\\\ 0  2 \\end{pmatrix}$，协方差 $C = \\operatorname{diag}(1, 2, 4)$，以及方向 $u = \\begin{pmatrix} 3/5 \\\\ 4/5 \\end{pmatrix}$。\n\n我们使用推导出的公式 $u^{\\top} J(s) u$，其中 $J(s) = (\\mu'(s))^{\\top} C^{-1} \\mu'(s)$。\n\n首先，我们求平均响应的雅可比矩阵 $\\mu'(s)$。由于 $\\mu(s) = M s$ 是 $s$ 的一个线性函数，其雅可比矩阵就是矩阵 $M$：\n$$\n\\mu'(s) = \\frac{\\partial(Ms)}{\\partial s} = M = \\begin{pmatrix} 1  0 \\\\ 1  1 \\\\ 0  2 \\end{pmatrix}.\n$$\n由于雅可比矩阵是常数，费雪信息矩阵 $J(s)$ 将与 $s$ 无关，我们将其记为 $J$。\n\n接下来，我们求协方差矩阵 $C$ 的逆矩阵：\n$$\nC = \\begin{pmatrix} 1  0  0 \\\\ 0  2  0 \\\\ 0  0  4 \\end{pmatrix} \\implies C^{-1} = \\begin{pmatrix} 1^{-1}  0  0 \\\\ 0  2^{-1}  0 \\\\ 0  0  4^{-1} \\end{pmatrix} = \\begin{pmatrix} 1  0  0 \\\\ 0  1/2  0 \\\\ 0  0  1/4 \\end{pmatrix}.\n$$\n现在我们计算费雪信息矩阵 $J = M^{\\top} C^{-1} M$：\n$$\nM^{\\top} = \\begin{pmatrix} 1  1  0 \\\\ 0  1  2 \\end{pmatrix}.\n$$\n$$\nJ = \\begin{pmatrix} 1  1  0 \\\\ 0  1  2 \\end{pmatrix} \\begin{pmatrix} 1  0  0 \\\\ 0  1/2  0 \\\\ 0  0  1/4 \\end{pmatrix} \\begin{pmatrix} 1  0 \\\\ 1  1 \\\\ 0  2 \\end{pmatrix}\n$$\n$$\nJ = \\begin{pmatrix} 1  1/2  0 \\\\ 0  1/2  1/2 \\end{pmatrix} \\begin{pmatrix} 1  0 \\\\ 1  1 \\\\ 0  2 \\end{pmatrix}\n$$\n$$\nJ = \\begin{pmatrix} 1(1) + (1/2)(1) + 0(0)  1(0) + (1/2)(1) + 0(2) \\\\ 0(1) + (1/2)(1) + (1/2)(0)  0(0) + (1/2)(1) + (1/2)(2) \\end{pmatrix}\n$$\n$$\nJ = \\begin{pmatrix} 1 + 1/2  1/2 \\\\ 1/2  1/2 + 1 \\end{pmatrix} = \\begin{pmatrix} 3/2  1/2 \\\\ 1/2  3/2 \\end{pmatrix}.\n$$\n最后，我们计算标量费雪信息 $I = u^{\\top} J u$：\n$$\nu = \\begin{pmatrix} 3/5 \\\\ 4/5 \\end{pmatrix}.\n$$\n$$\nI = \\begin{pmatrix} 3/5  4/5 \\end{pmatrix} \\begin{pmatrix} 3/2  1/2 \\\\ 1/2  3/2 \\end{pmatrix} \\begin{pmatrix} 3/5 \\\\ 4/5 \\end{pmatrix}\n$$\n$$\nI = (3/5) \\left( (3/2)(3/5) + (1/2)(4/5) \\right) + (4/5) \\left( (1/2)(3/5) + (3/2)(4/5) \\right)\n$$\n$$\nI = (3/5) \\left( 9/10 + 4/10 \\right) + (4/5) \\left( 3/10 + 12/10 \\right)\n$$\n$$\nI = (3/5) (13/10) + (4/5) (15/10)\n$$\n$$\nI = \\frac{39}{50} + \\frac{60}{50} = \\frac{99}{50}.\n$$\n结果是一个精确的实数。",
            "answer": "$$\\boxed{\\frac{99}{50}}$$"
        },
        {
            "introduction": "在掌握了如何计算费雪信息之后，我们现在转向一个关键的概念性问题：噪声相关性的作用。这个问题通过一个涉及“试次重排”（trial shuffling）的思想实验，来剖析神经元之间的相关性如何限制或在其他情况下增强群体编码中的信息 。理解这一点是解读真实神经数据和评估群体编码效率的核心。",
            "id": "4163132",
            "problem": "一个实验室记录了一个包含 $N$ 个感觉神经元的群体对一维刺激参数 $\\theta$ 的响应。在每次试验中，群体响应由一个随机向量 $\\mathbf{r} \\in \\mathbb{R}^N$ 表示，并且在给定 $\\theta$ 的条件下 $\\mathbf{r}$ 的条件分布被建模为均值为 $\\boldsymbol{\\mu}(\\theta)$、协方差为与 $\\theta$ 无关的 $\\boldsymbol{\\Sigma}$ 的多元高斯分布，即 $p(\\mathbf{r} \\mid \\theta) = \\mathcal{N}(\\boldsymbol{\\mu}(\\theta), \\boldsymbol{\\Sigma})$。目标是使用费雪信息（FI）来量化该群体编码的灵敏度，其定义为 $J(\\theta) = \\mathbb{E}\\big[\\big(\\partial_{\\theta} \\log p(\\mathbf{r} \\mid \\theta)\\big)^2\\big]$，并特别分析在这种设定下常用的线性费雪信息 $I_{\\text{lin}}(\\theta)$。\n\n为了探究噪声相关性在编码中的作用，该实验室应用了试验重排（trial shuffling）：在相同 $\\theta$ 的重复呈现中，对每个神经元的试验进行独立置换，以构建一个伪群体，该伪群体保留了每个神经元的单次试验统计特性，但破坏了神经元间的相关性。假设原始协方差具有秩为1的相关形式\n$$\n\\boldsymbol{\\Sigma} \\;=\\; \\sigma^2 \\mathbf{I} \\;+\\; \\lambda \\,\\mathbf{v}\\mathbf{v}^\\top,\n$$\n其中 $\\sigma^2 > 0$，$\\lambda > 0$，$\\|\\mathbf{v}\\|_2 = 1$，$\\mathbf{I}$ 是单位矩阵。试验重排产生一个等效协方差\n$$\n\\boldsymbol{\\Sigma}_{\\text{shuf}} \\;=\\; \\sigma^2 \\mathbf{I},\n$$\n同时保持 $\\boldsymbol{\\mu}(\\theta)$ 不变。令 $\\mathbf{g}(\\theta) = \\partial_{\\theta} \\boldsymbol{\\mu}(\\theta)$ 表示群体调谐斜率（“信号方向”）。\n\n使用费雪信息 $J(\\theta)$ 的基本定义和所述的生成模型，分析试验重排如何影响 $I_{\\text{lin}}(\\theta)$ 的估计，以及这对相关性在神经编码中的作用意味着什么。以下哪个陈述是正确的？\n\nA. 在所述的 $\\boldsymbol{\\Sigma}$ 下，每当 $\\mathbf{v}$ 在 $\\mathbf{g}(\\theta)$ 上有非零投影时，试验重排会增加 $I_{\\text{lin}}(\\theta)$。\n\nB. 如果 $\\mathbf{v} \\perp \\mathbf{g}(\\theta)$，试验重排使 $I_{\\text{lin}}(\\theta)$ 保持不变。\n\nC. 观察到试验重排后 $I_{\\text{lin}}(\\theta)$ 的增加，是相关性对该编码起信息限制作用的证据。\n\nD. 对于任何群体和任何相关结构，试验重排总是会增加 $I_{\\text{lin}}(\\theta)$。",
            "solution": "首先对问题陈述进行验证。\n\n### 步骤 1：提取已知条件\n- 一个包含 $N$ 个感觉神经元的群体对刺激 $\\theta$ 作出响应。\n- 群体响应是一个随机向量 $\\mathbf{r} \\in \\mathbb{R}^N$。\n- 响应的条件概率分布是多元高斯分布：$p(\\mathbf{r} \\mid \\theta) = \\mathcal{N}(\\boldsymbol{\\mu}(\\theta), \\boldsymbol{\\Sigma})$。\n- 协方差矩阵 $\\boldsymbol{\\Sigma}$ 与刺激 $\\theta$ 无关。\n- 费雪信息的定义为 $J(\\theta) = \\mathbb{E}\\big[\\big(\\partial_{\\theta} \\log p(\\mathbf{r} \\mid \\theta)\\big)^2\\big]$。分析涉及线性费雪信息 $I_{\\text{lin}}(\\theta)$。\n- 原始协方差矩阵被指定为 $\\boldsymbol{\\Sigma} = \\sigma^2 \\mathbf{I} + \\lambda \\,\\mathbf{v}\\mathbf{v}^\\top$，其中 $\\sigma^2 > 0$，$\\lambda > 0$，$\\|\\mathbf{v}\\|_2 = 1$，$\\mathbf{I}$ 是 $N \\times N$ 单位矩阵。\n- 定义了一个“试验重排”过程，其产生一个等效的重排后协方差矩阵 $\\boldsymbol{\\Sigma}_{\\text{shuf}} = \\sigma^2 \\mathbf{I}$。\n- 均值响应向量 $\\boldsymbol{\\mu}(\\theta)$ 不受此过程影响。\n- 群体调谐斜率定义为 $\\mathbf{g}(\\theta) = \\partial_{\\theta} \\boldsymbol{\\mu}(\\theta)$。\n\n### 步骤 2：使用提取的已知条件进行验证\n- **科学依据：** 该问题在理论神经科学中有充分的依据。使用多元高斯模型、费雪信息和试验重排来研究群体编码和噪声相关性是该领域的标准方法。\n- **良定性：** 该问题是良定的。对于具有刺激无关协方差的高斯模型，广义费雪信息 $J(\\theta)$ 等价于线性费雪信息 $I_{\\text{lin}}(\\theta) = (\\partial_{\\theta} \\boldsymbol{\\mu}(\\theta))^\\top \\boldsymbol{\\Sigma}^{-1} (\\partial_{\\theta} \\boldsymbol{\\mu}(\\theta))$。参数的定义使得协方差矩阵 $\\boldsymbol{\\Sigma}$ 是正定的：其特征值为 $\\sigma^2 + \\lambda$ 和 $\\sigma^2$（重数为 $N-1$），在 $\\sigma^2 > 0$ 和 $\\lambda > 0$ 的条件下，这两个特征值都是严格为正的。因此，$\\boldsymbol{\\Sigma}$ 是可逆的。\n- **客观性和一致性：** 该问题以客观的数学术语陈述。对“试验重排”结果 $\\boldsymbol{\\Sigma}_{\\text{shuf}} = \\sigma^2 \\mathbf{I}$ 的定义是一个公理化的简化。一个在物理上更准确的试验重排模型会保留原始协方差矩阵的对角元素，得到 $\\boldsymbol{\\Sigma}_{\\text{shuf}}' = \\text{diag}(\\sigma^2+\\lambda v_1^2, \\ldots, \\sigma^2+\\lambda v_N^2)$。然而，问题明确地*定义*了重排的结果为 $\\sigma^2 \\mathbf{I}$。这不是一个矛盾，而是该数学练习的一个特定但简化的前提。该问题是在由 $\\boldsymbol{\\Sigma}$ 和 $\\boldsymbol{\\Sigma}_{\\text{shuf}}$ 描述的两个系统之间进行有效比较。\n\n### 步骤 3：结论与行动\n问题陈述在理论建模的背景下是内部一致且有科学依据的。它被认为是**有效的**。我们可以继续进行求解。\n\n### 推导\n\n对于响应服从多元高斯分布 $p(\\mathbf{r} \\mid \\theta) = \\mathcal{N}(\\boldsymbol{\\mu}(\\theta), \\boldsymbol{\\Sigma})$（其中 $\\boldsymbol{\\Sigma}$ 与 $\\theta$ 无关）的神经元群体，其线性费雪信息（FI）由以下公式给出：\n$$\nI_{\\text{lin}}(\\theta) = \\mathbf{g}(\\theta)^\\top \\boldsymbol{\\Sigma}^{-1} \\mathbf{g}(\\theta)\n$$\n其中 $\\mathbf{g}(\\theta) = \\partial_{\\theta} \\boldsymbol{\\mu}(\\theta)$ 是均值响应相对于刺激参数的导数。为简洁起见，我们将省略对 $\\theta$ 的显式依赖，写作 $\\mathbf{g}$ 和 $I_{\\text{lin}}$。\n\n首先，我们计算重排情况下的费雪信息 $I_{\\text{lin, shuf}}$。协方差矩阵为 $\\boldsymbol{\\Sigma}_{\\text{shuf}} = \\sigma^2 \\mathbf{I}$。其逆矩阵很简单：\n$$\n\\boldsymbol{\\Sigma}_{\\text{shuf}}^{-1} = (\\sigma^2 \\mathbf{I})^{-1} = \\frac{1}{\\sigma^2} \\mathbf{I}\n$$\n将此代入 FI 公式：\n$$\nI_{\\text{lin, shuf}} = \\mathbf{g}^\\top \\left(\\frac{1}{\\sigma^2} \\mathbf{I}\\right) \\mathbf{g} = \\frac{1}{\\sigma^2} (\\mathbf{g}^\\top \\mathbf{g}) = \\frac{\\|\\mathbf{g}\\|_2^2}{\\sigma^2}\n$$\n这表示在每个神经元只有方差为 $\\sigma^2$ 的独立噪声的情况下，编码中的信息量。\n\n接下来，我们计算原始相关情况下的费雪信息 $I_{\\text{lin}}$。协方差矩阵为 $\\boldsymbol{\\Sigma} = \\sigma^2 \\mathbf{I} + \\lambda \\mathbf{v}\\mathbf{v}^\\top$。为了求其逆矩阵，我们使用 Sherman-Morrison 公式来计算秩1更新的逆：$(\\mathbf{A} + \\mathbf{u}\\mathbf{w}^\\top)^{-1} = \\mathbf{A}^{-1} - \\frac{\\mathbf{A}^{-1}\\mathbf{u}\\mathbf{w}^\\top\\mathbf{A}^{-1}}{1 + \\mathbf{w}^\\top\\mathbf{A}^{-1}\\mathbf{u}}$。\n在这里，我们认定 $\\mathbf{A} = \\sigma^2 \\mathbf{I}$，$\\mathbf{u} = \\lambda\\mathbf{v}$，$\\mathbf{w} = \\mathbf{v}$。\n$\\mathbf{A}$ 的逆是 $\\mathbf{A}^{-1} = \\frac{1}{\\sigma^2} \\mathbf{I}$。\n分母项是 $1 + \\mathbf{v}^\\top (\\frac{1}{\\sigma^2}\\mathbf{I})(\\lambda\\mathbf{v}) = 1 + \\frac{\\lambda}{\\sigma^2} \\mathbf{v}^\\top\\mathbf{v}$。由于 $\\|\\mathbf{v}\\|_2=1$，我们有 $\\mathbf{v}^\\top\\mathbf{v} = 1$，所以分母是 $1 + \\frac{\\lambda}{\\sigma^2} = \\frac{\\sigma^2+\\lambda}{\\sigma^2}$。\n分子矩阵是 $\\mathbf{A}^{-1}\\mathbf{u}\\mathbf{w}^\\top\\mathbf{A}^{-1} = (\\frac{1}{\\sigma^2}\\mathbf{I})(\\lambda\\mathbf{v})\\mathbf{v}^\\top(\\frac{1}{\\sigma^2}\\mathbf{I}) = \\frac{\\lambda}{\\sigma^4}\\mathbf{v}\\mathbf{v}^\\top$。\n结合这些部分，逆协方差矩阵是：\n$$\n\\boldsymbol{\\Sigma}^{-1} = \\frac{1}{\\sigma^2}\\mathbf{I} - \\frac{\\frac{\\lambda}{\\sigma^4}\\mathbf{v}\\mathbf{v}^\\top}{\\frac{\\sigma^2+\\lambda}{\\sigma^2}} = \\frac{1}{\\sigma^2}\\mathbf{I} - \\frac{\\lambda}{\\sigma^2(\\sigma^2+\\lambda)}\\mathbf{v}\\mathbf{v}^\\top\n$$\n现在，我们计算 $I_{\\text{lin}}$：\n$$\nI_{\\text{lin}} = \\mathbf{g}^\\top \\boldsymbol{\\Sigma}^{-1} \\mathbf{g} = \\mathbf{g}^\\top \\left( \\frac{1}{\\sigma^2}\\mathbf{I} - \\frac{\\lambda}{\\sigma^2(\\sigma^2+\\lambda)}\\mathbf{v}\\mathbf{v}^\\top \\right) \\mathbf{g}\n$$\n$$\nI_{\\text{lin}} = \\frac{1}{\\sigma^2}\\mathbf{g}^\\top\\mathbf{g} - \\frac{\\lambda}{\\sigma^2(\\sigma^2+\\lambda)}\\mathbf{g}^\\top\\mathbf{v}\\mathbf{v}^\\top\\mathbf{g}\n$$\n认识到 $\\mathbf{g}^\\top\\mathbf{g} = \\|\\mathbf{g}\\|_2^2$ 且 $\\mathbf{g}^\\top\\mathbf{v}\\mathbf{v}^\\top\\mathbf{g} = (\\mathbf{g}^\\top\\mathbf{v})^2$，我们有：\n$$\nI_{\\text{lin}} = \\frac{\\|\\mathbf{g}\\|_2^2}{\\sigma^2} - \\frac{\\lambda}{\\sigma^2(\\sigma^2+\\lambda)}(\\mathbf{g}^\\top\\mathbf{v})^2\n$$\n第一项恰好是 $I_{\\text{lin, shuf}}$。因此，原始和重排后的 FI 之间的关系是：\n$$\nI_{\\text{lin}} = I_{\\text{lin, shuf}} - \\frac{\\lambda}{\\sigma^2(\\sigma^2+\\lambda)}(\\mathbf{g}^\\top\\mathbf{v})^2\n$$\n重排后费雪信息的变化量是 $\\Delta I = I_{\\text{lin, shuf}} - I_{\\text{lin}}$：\n$$\n\\Delta I = \\frac{\\lambda}{\\sigma^2(\\sigma^2+\\lambda)}(\\mathbf{g}^\\top\\mathbf{v})^2\n$$\n由于 $\\lambda > 0$ 和 $\\sigma^2 > 0$，系数 $\\frac{\\lambda}{\\sigma^2(\\sigma^2+\\lambda)}$ 是严格为正的。项 $(\\mathbf{g}^\\top\\mathbf{v})^2$ 是非负的。\n因此，$\\Delta I \\ge 0$，这意味着 $I_{\\text{lin, shuf}} \\ge I_{\\text{lin}}$。在这个模型下，试验重排永远不会减少费雪信息。\n\n### 逐项分析\n\nA. **在所述的 $\\boldsymbol{\\Sigma}$ 下，每当 $\\mathbf{v}$ 在 $\\mathbf{g}(\\theta)$ 上有非零投影时，试验重排会增加 $I_{\\text{lin}}(\\theta)$。**\n条件“$\\mathbf{v}$ 在 $\\mathbf{g}(\\theta)$ 上有非零投影”等价于点积 $\\mathbf{g}^\\top\\mathbf{v}$ 不为零。如果 $\\mathbf{g}^\\top\\mathbf{v} \\neq 0$，那么 $(\\mathbf{g}^\\top\\mathbf{v})^2 > 0$。从我们推导出的 FI 变化量表达式 $\\Delta I = \\frac{\\lambda}{\\sigma^2(\\sigma^2+\\lambda)}(\\mathbf{g}^\\top\\mathbf{v})^2$ 来看，非零投影意味着 $\\Delta I > 0$。这意味着 $I_{\\text{lin, shuf}} - I_{\\text{lin}} > 0$，即 $I_{\\text{lin, shuf}} > I_{\\text{lin}}$。因此，试验重排严格增加了费雪信息。\n**结论：正确。**\n\nB. **如果 $\\mathbf{v} \\perp \\mathbf{g}(\\theta)$，试验重排使 $I_{\\text{lin}}(\\theta)$ 保持不变。**\n条件 $\\mathbf{v} \\perp \\mathbf{g}(\\theta)$ 意味着向量是正交的，所以它们的点积为零：$\\mathbf{g}^\\top\\mathbf{v} = 0$。将此代入我们 FI 变化量的表达式，得到 $\\Delta I = \\frac{\\lambda}{\\sigma^2(\\sigma^2+\\lambda)}(0)^2 = 0$。这意味着 $I_{\\text{lin, shuf}} - I_{\\text{lin}} = 0$，即 $I_{\\text{lin, shuf}} = I_{\\text{lin}}$。费雪信息保持不变。\n**结论：正确。**\n\nC. **观察到试验重排后 $I_{\\text{lin}}(\\theta)$ 的增加，是相关性对该编码起信息限制作用的证据。**\n如果相关性的存在与基线情况（在此情境下，即移除了相关性的重排情况）相比减少了费雪信息，那么这些相关性就被认为是“信息限制性的”。观察到的增加意味着 $I_{\\text{lin, shuf}} > I_{\\text{lin}}$。我们的推导表明，当噪声相关性（由 $\\lambda \\mathbf{v}\\mathbf{v}^\\top$ 表示）存在于与信号方向 $\\mathbf{g}$ 不正交的方向 $\\mathbf{v}$ 上时，就会发生这种情况。$I_{\\text{lin}}$ 的值小于 $I_{\\text{lin, shuf}}$，这正是因为 $I_{\\text{lin}}$ 表达式中存在由相关性引起的负项。因此，观察到这种增加是相关性限制了该编码信息含量的直接证据。\n**结论：正确。**\n\nD. **对于任何群体和任何相关结构，试验重排总是会增加 $I_{\\text{lin}}(\\theta)$。**\n这个陈述对“任何相关结构”做出了一个普遍性论断。问题中的特定结构 $\\boldsymbol{\\Sigma} = \\sigma^2 \\mathbf{I} + \\lambda \\mathbf{v}\\mathbf{v}^\\top$ (其中 $\\lambda>0$) 代表了沿方向 $\\mathbf{v}$ 的正相关。这种类型的相关性确实是信息限制性的或中性的。然而，还存在其他相关结构。考虑一个简单的双神经元系统，信号为 $\\mathbf{g} = [1, 1]^\\top$，协方差矩阵具有负相关性：$\\boldsymbol{\\Sigma} = \\begin{pmatrix} 1  -0.8 \\\\ -0.8  1 \\end{pmatrix}$。其逆矩阵为 $\\boldsymbol{\\Sigma}^{-1} = \\frac{1}{1-0.64}\\begin{pmatrix} 1  0.8 \\\\ 0.8  1 \\end{pmatrix} = \\frac{1}{0.36}\\begin{pmatrix} 1  0.8 \\\\ 0.8  1 \\end{pmatrix}$。费雪信息为 $I_{\\text{lin}} = [1, 1] \\frac{1}{0.36}\\begin{pmatrix} 1  0.8 \\\\ 0.8  1 \\end{pmatrix} [1, 1]^\\top = \\frac{1}{0.36}(1+0.8+0.8+1) = \\frac{3.6}{0.36} = 10$。重排后，协方差变为 $\\boldsymbol{\\Sigma}_{\\text{shuf}}=\\begin{pmatrix} 1  0 \\\\ 0  1 \\end{pmatrix}$，且 $I_{\\text{lin, shuf}} = [1, 1] \\begin{pmatrix} 1  0 \\\\ 0  1 \\end{pmatrix} [1, 1]^\\top = 1+1=2$。在这种情况下，$I_{\\text{lin}} > I_{\\text{lin, shuf}}$，意味着重排*减少*了信息。这种相关性被称为“信息增强的”。因此，该陈述是错误的。\n**结论：不正确。**",
            "answer": "$$\\boxed{ABC}$$"
        }
    ]
}