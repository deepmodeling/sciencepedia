{
    "hands_on_practices": [
        {
            "introduction": "本练习是理解霍普菲尔德网络（Hopfield network）记忆容量限制的基础。通过从第一性原理出发，您将推导出有限尺寸网络中串扰噪声的精确方差 ()。理解这个方差的来源和形式，是掌握决定网络存储上限的信噪比论证的关键，它也揭示了从理想化的无限大网络到更现实的有限尺寸系统时，性能会如何修正。",
            "id": "4023731",
            "problem": "考虑一个大小为 $N$ 的全连接 Hopfield 网络，它存储了 $P$ 个二元模式 $\\{\\boldsymbol{\\xi}^{\\mu}\\}_{\\mu=1}^{P}$。这些模式的分量 $\\xi_{i}^{\\mu} \\in \\{-1,+1\\}$ 是独立同分布的，并且对于神经元索引 $i$ 和模式索引 $\\mu$ 都是均匀且独立采样的。突触矩阵通过赫布规则构建，且不包含自耦合，即：\n$$\nJ_{ij} \\equiv \\frac{1}{N}\\sum_{\\mu=1}^{P}\\xi_{i}^{\\mu}\\xi_{j}^{\\mu}, \\quad J_{ii}=0.\n$$\n假设网络在一个参考模式 $\\nu \\in \\{1,\\dots,P\\}$ 的吸引盆中初始化，并在零温下进行确定性更新，因此神经元 $i$ 上的局部场为\n$$\nh_{i}=\\sum_{j\\neq i}J_{ij}s_{j},\n$$\n在近乎完美检索的情况下，可以取 $s_{j}=\\xi_{j}^{\\nu}$。将 $h_{i}$ 分解为一个与 $\\xi_{i}^{\\nu}$ 对齐的信号项和一个由所有其他模式 $\\mu\\neq \\nu$ 产生的串扰项 $\\eta_{i}$。根据中心极限定理 (CLT)，串扰项 $\\eta_{i}$ 可近似为均值为零、方差为 $\\sigma^{2}(N,P)$ 的高斯分布，其中方差依赖于 $N$ 和 $P$。\n\n从以上定义出发，仅使用随机模式的独立性以及中心极限定理作为高斯性的定性依据（而非用于计算矩），完成以下任务：\n\n1) 在检索模式 $\\nu$ 期间，推导在神经元 $i$ 处串扰方差 $\\sigma^{2}(N,P)$ 的精确有限-$N$ 表达式，用 $N$ 和 $P$ 表示，然后将其改写为负载 $\\alpha\\equiv P/N$ 的函数。\n\n2) 在无限大尺寸极限下，临界存储负载记为 $\\alpha_{c}^{\\infty}$（一个正常数）。一種估算有限 $N$ 下临界负载的朴素经验性方法是，令测得的串扰方差等于无限大尺寸下的临界方差，即求解方程中的 $\\widehat{\\alpha}_{c}(N)$：\n$$\n\\sigma^{2}\\bigl(N,\\widehat{\\alpha}_{c}(N)\\,N\\bigr)=\\alpha_{c}^{\\infty}.\n$$\n精确求解该方程，得到 $\\widehat{\\alpha}_{c}(N)$ 的闭式解，并尽可能地简化结果。\n\n你的最终答案必须是关于 $N$ 和 $\\alpha_{c}^{\\infty}$ 的 $\\widehat{\\alpha}_{c}(N)$ 的单一简化符号表达式。不需要数值近似。",
            "solution": "该问题被评估为有效，因为它科学地基于标准的 Hopfield 模型，问题设定良好、客观，并包含一套完整且一致的定义和约束。这些任务是计算神经科学领域的标准推导。\n\n根据问题陈述的要求，解答分为两部分呈现。\n\n第 1 部分：串扰方差 $\\sigma^{2}(N,P)$ 的推导。\n\n神经元 $i$ 处的局部场 $h_{i}$ 由下式给出：\n$$\nh_{i}=\\sum_{j\\neq i}J_{ij}s_{j}\n$$\n当 $i \\neq j$ 时，突触权重 $J_{ij}$ 由赫布规则定义：\n$$\nJ_{ij} = \\frac{1}{N}\\sum_{\\mu=1}^{P}\\xi_{i}^{\\mu}\\xi_{j}^{\\mu}\n$$\n我们假设网络状态 $s_j$ 与参考模式 $\\boldsymbol{\\xi}^{\\nu}$ 完全对齐，因此 $s_{j}=\\xi_{j}^{\\nu}$。将这些代入局部场的表达式中，得到：\n$$\nh_{i} = \\sum_{j\\neq i} \\left( \\frac{1}{N}\\sum_{\\mu=1}^{P}\\xi_{i}^{\\mu}\\xi_{j}^{\\mu} \\right) \\xi_{j}^{\\nu}\n$$\n通过重新排列求和顺序：\n$$\nh_{i} = \\frac{1}{N} \\sum_{\\mu=1}^{P} \\xi_{i}^{\\mu} \\sum_{j\\neq i} \\xi_{j}^{\\mu} \\xi_{j}^{\\nu}\n$$\n我们可以将这个和分解为两部分：对应于参考模式 $\\mu=\\nu$ 的项和对应于所有其他模式 $\\mu \\neq \\nu$ 的项。\n$$\nh_{i} = \\frac{1}{N} \\left( \\xi_{i}^{\\nu} \\sum_{j\\neq i} \\xi_{j}^{\\nu} \\xi_{j}^{\\nu} + \\sum_{\\mu \\neq \\nu} \\xi_{i}^{\\mu} \\sum_{j\\neq i} \\xi_{j}^{\\mu} \\xi_{j}^{\\nu} \\right)\n$$\n模式的分量为 $\\xi_{j}^{\\nu} \\in \\{-1, +1\\}$，所以 $(\\xi_{j}^{\\nu})^{2} = 1$。第一项是信号项：\n$$\n\\text{Signal} = \\frac{1}{N} \\xi_{i}^{\\nu} \\sum_{j\\neq i} 1 = \\frac{1}{N} \\xi_{i}^{\\nu} (N-1) = \\left(1-\\frac{1}{N}\\right)\\xi_{i}^{\\nu}\n$$\n该项与期望状态 $\\xi_{i}^{\\nu}$ 成正比。第二项是串扰噪声 $\\eta_{i}$：\n$$\n\\eta_{i} = \\frac{1}{N} \\sum_{\\mu \\neq \\nu} \\xi_{i}^{\\mu} \\left( \\sum_{j\\neq i} \\xi_{j}^{\\mu}\\xi_{j}^{\\nu} \\right)\n$$\n我们接下来计算 $\\eta_{i}$ 的方差，记为 $\\sigma^{2}$。方差为 $\\sigma^{2} = E[\\eta_{i}^{2}] - (E[\\eta_{i}])^{2}$。首先，我们计算均值 $E[\\eta_{i}]$。期望是针对随机模式的分布计算的。对于所有的 $k, \\mu$，分量 $\\xi_{k}^{\\mu}$ 都是独立的并且均值为零，即 $E[\\xi_{k}^{\\mu}]=0$。\n$$\nE[\\eta_i] = \\frac{1}{N} \\sum_{\\mu \\neq \\nu} E\\left[\\xi_{i}^{\\mu} \\left( \\sum_{j\\neq i} \\xi_{j}^{\\mu}\\xi_{j}^{\\nu} \\right)\\right] = \\frac{1}{N} \\sum_{\\mu \\neq \\nu} E[\\xi_{i}^{\\mu}] E\\left[\\sum_{j\\neq i} \\xi_{j}^{\\mu}\\xi_{j}^{\\nu}\\right] = 0\n$$\n由于均值为零，方差为 $\\sigma^{2} = E[\\eta_{i}^{2}]$。\n$$\n\\sigma^{2} = E\\left[ \\left( \\frac{1}{N} \\sum_{\\mu \\neq \\nu} \\xi_{i}^{\\mu} \\sum_{j\\neq i} \\xi_{j}^{\\mu}\\xi_{j}^{\\nu} \\right)^{2} \\right] = \\frac{1}{N^{2}} E\\left[ \\left( \\sum_{\\mu \\neq \\nu} \\xi_{i}^{\\mu} \\sum_{j\\neq i} \\xi_{j}^{\\mu}\\xi_{j}^{\\nu} \\right) \\left( \\sum_{\\lambda \\neq \\nu} \\xi_{i}^{\\lambda} \\sum_{k\\neq i} \\xi_{k}^{\\lambda}\\xi_{k}^{\\nu} \\right) \\right]\n$$\n$$\n\\sigma^{2} = \\frac{1}{N^{2}} \\sum_{\\mu \\neq \\nu} \\sum_{\\lambda \\neq \\nu} E\\left[ \\xi_{i}^{\\mu}\\xi_{i}^{\\lambda} \\left(\\sum_{j\\neq i} \\xi_{j}^{\\mu}\\xi_{j}^{\\nu}\\right) \\left(\\sum_{k\\neq i} \\xi_{k}^{\\lambda}\\xi_{k}^{\\nu}\\right) \\right]\n$$\n由于模式的独立性，如果 $\\mu \\neq \\lambda$，则来自模式 $\\mu$ 和模式 $\\lambda$ 的任何变量乘积的期望可以分解。对于 $\\mu \\neq \\lambda$，$E[\\xi_{i}^{\\mu}\\xi_{i}^{\\lambda}] = E[\\xi_{i}^{\\mu}]E[\\xi_{i}^{\\lambda}] = 0 \\times 0 = 0$。因此，所有 $\\mu \\neq \\lambda$ 的交叉项都为零。我们只需要考虑 $\\mu = \\lambda$ 的项：\n$$\n\\sigma^{2} = \\frac{1}{N^{2}} \\sum_{\\mu \\neq \\nu} E\\left[ (\\xi_{i}^{\\mu})^{2} \\left(\\sum_{j\\neq i} \\xi_{j}^{\\mu}\\xi_{j}^{\\nu}\\right)^{2} \\right]\n$$\n由于 $(\\xi_{i}^{\\mu})^{2}=1$，上式可简化为：\n$$\n\\sigma^{2} = \\frac{1}{N^{2}} \\sum_{\\mu \\neq \\nu} E\\left[ \\left(\\sum_{j\\neq i} \\xi_{j}^{\\mu}\\xi_{j}^{\\nu}\\right)^{2} \\right]\n$$\n我们来分析这个期望。对于一个固定的 $\\mu \\neq \\nu$，令 $X_{j} = \\xi_{j}^{\\mu}\\xi_{j}^{\\nu}$。由于对于不同的 $j$，$\\xi_{j}^{\\mu}$ 和 $\\xi_{j}^{\\nu}$ 是独立的，所以变量 $X_{j}$ 是独立同分布的。它们的均值为 $E[X_{j}] = E[\\xi_{j}^{\\mu}]E[\\xi_{j}^{\\nu}]=0$。它们的二阶矩为 $E[X_{j}^{2}] = E[(\\xi_{j}^{\\mu})^{2}(\\xi_{j}^{\\nu})^{2}] = E[1 \\cdot 1] = 1$。\n该期望项是这些变量之和的方差：\n$$\nE\\left[ \\left(\\sum_{j\\neq i} X_{j}\\right)^{2} \\right] = E\\left[ \\sum_{j\\neq i} \\sum_{k\\neq i} X_{j}X_{k} \\right] = \\sum_{j\\neq i}\\sum_{k\\neq i} E[X_{j}X_{k}]\n$$\n由于 $E[X_j]=0$ 并且当 $j \\neq k$ 时 $X_j, X_k$ 独立，所以对于 $j \\neq k$，$E[X_{j}X_{k}] = E[X_{j}]E[X_{k}] = 0$。只有当 $j=k$ 时，和才非零：\n$$\nE\\left[ \\left(\\sum_{j\\neq i} X_{j}\\right)^{2} \\right] = \\sum_{j\\neq i} E[X_{j}^{2}] = \\sum_{j\\neq i} 1 = N-1\n$$\n对于每一个模式 $\\mu \\neq \\nu$，这个值都是相同的。和 $\\sum_{\\mu \\neq \\nu}$ 含有 $P-1$ 项。将此结果代回 $\\sigma^{2}$ 的表达式中：\n$$\n\\sigma^{2} = \\frac{1}{N^{2}} \\sum_{\\mu \\neq \\nu} (N-1) = \\frac{1}{N^{2}} (P-1)(N-1)\n$$\n这就是串扰方差 $\\sigma^{2}(N,P)$ 的精确有限-$N$ 表达式。\n\n为了用负载 $\\alpha \\equiv P/N$ 来表示它，我们代入 $P = \\alpha N$：\n$$\n\\sigma^{2}(N,\\alpha) = \\frac{(\\alpha N - 1)(N-1)}{N^{2}}\n$$\n\n第 2 部分：求解有限尺寸临界负载 $\\widehat{\\alpha}_{c}(N)$。\n\n题目要求我们求解方程 $\\sigma^{2}\\bigl(N,\\widehat{\\alpha}_{c}(N)\\,N\\bigr)=\\alpha_{c}^{\\infty}$ 以得到 $\\widehat{\\alpha}_{c}(N)$。为简化推导过程中的符号，令 $\\hat{\\alpha}_{c} \\equiv \\widehat{\\alpha}_{c}(N)$。我们代入推導出的方差表达式：\n$$\n\\frac{(\\hat{\\alpha}_{c} N - 1)(N-1)}{N^{2}} = \\alpha_{c}^{\\infty}\n$$\n我们求解这个关于 $\\hat{\\alpha}_{c}$ 的代数方程：\n$$\n(\\hat{\\alpha}_{c} N - 1)(N-1) = N^{2} \\alpha_{c}^{\\infty}\n$$\n$$\n\\hat{\\alpha}_{c} N - 1 = \\frac{N^{2} \\alpha_{c}^{\\infty}}{N-1}\n$$\n$$\n\\hat{\\alpha}_{c} N = 1 + \\frac{N^{2} \\alpha_{c}^{\\infty}}{N-1}\n$$\n$$\n\\hat{\\alpha}_{c} = \\frac{1}{N} \\left( 1 + \\frac{N^{2} \\alpha_{c}^{\\infty}}{N-1} \\right)\n$$\n简化此表达式得到 $\\widehat{\\alpha}_{c}(N)$ 的最终结果：\n$$\n\\widehat{\\alpha}_{c}(N) = \\frac{1}{N} + \\frac{N \\alpha_{c}^{\\infty}}{N-1}\n$$\n该表达式可以展开以显示主导项和有限尺寸修正项：\n$$\n\\widehat{\\alpha}_{c}(N) = \\frac{1}{N} + \\alpha_{c}^{\\infty} \\frac{N-1+1}{N-1} = \\frac{1}{N} + \\alpha_{c}^{\\infty} \\left(1 + \\frac{1}{N-1}\\right) = \\alpha_{c}^{\\infty} + \\frac{1}{N} + \\frac{\\alpha_{c}^{\\infty}}{N-1}\n$$\n形式 $\\frac{1}{N} + \\frac{N \\alpha_{c}^{\\infty}}{N-1}$ 已按要求足够简化。",
            "answer": "$$\n\\boxed{\\frac{1}{N} + \\frac{N \\alpha_{c}^{\\infty}}{N-1}}\n$$"
        },
        {
            "introduction": "伪吸引子为何会存在，甚至在某些情况下比真实的记忆模式更稳定？本练习 () 从能量景观的视角探讨了这个问题。通过计算并比较一个期望的记忆模式和一个伪混合模式的能量，您将能够确定网络错误地“回忆”起一个虚假记忆的条件，从而加深对吸引盆地概念以及外部场如何调控网络状态的理解。",
            "id": "4023654",
            "problem": "考虑一个由 $N$ 个二元神经元 $s_{i} \\in \\{-1, +1\\}$ 组成的全连接 Hopfield 网络，该网络存储了 $P$ 个独立同分布的随机模式 $\\{\\xi_{i}^{\\mu}\\}_{\\mu=1}^{P}$，其中 $\\xi_{i}^{\\mu} \\in \\{-1, +1\\}$ 且 $\\mathbb{P}(\\xi_{i}^{\\mu} = +1) = \\mathbb{P}(\\xi_{i}^{\\mu} = -1) = \\tfrac{1}{2}$。突触耦合由 Hebbian 规则构建\n$$\nJ_{ij} \\;=\\; \\frac{1}{N} \\sum_{\\mu=1}^{P} \\xi_{i}^{\\mu} \\xi_{j}^{\\mu}, \\quad J_{ii} \\;=\\; 0,\n$$\n且零温动力学最小化了带有加性外场的标准 Hopfield 能量，\n$$\nE(\\boldsymbol{s}; \\boldsymbol{h}^{\\text{ext}}) \\;=\\; -\\frac{1}{2} \\sum_{i,j=1}^{N} J_{ij} s_{i} s_{j} \\;-\\; \\sum_{i=1}^{N} h_{i}^{\\text{ext}} s_{i}.\n$$\n假设在固定负载 $\\alpha = P/N$ 的热力学极限 $N \\to \\infty$ 下，并设外场与模式 $\\mu = 3$ 对齐，即，\n$$\nh_{i}^{\\text{ext}} \\;=\\; h \\, \\xi_{i}^{3},\n$$\n其中振幅 $h \\ge 0$ 为常数。\n\n关注两个候选吸引子：\n- 纯模式态 $s_{i} = \\xi_{i}^{1}$，\n- 奇数伪混合态 $s_{i} = \\operatorname{sign}\\!\\big(\\xi_{i}^{1} + \\xi_{i}^{2} + \\xi_{i}^{3}\\big)$，该状态是良定义的，因为 $\\xi_{i}^{1} + \\xi_{i}^{2} + \\xi_{i}^{3} \\in \\{-3, -1, +1, +3\\}$ 永远不为零。\n\n使用上述基本定义、大数定律和中心极限定理 (CLT) 来评估大 $N$ 极限下的模式重叠以及来自非凝聚模式的串扰贡献，推导出这两种状态各自的每自旋能量，并确定阈值外偏置振幅 $h_{c}$。当 $h$ 从零开始增加时，在该阈值处，伪混合态的能量首次低于纯模式态。请用精确分数表示最终答案。无需四舍五入。答案是无量纲的。",
            "solution": "我们从带有加性外场的 Hopfield 能量开始\n$$\nE(\\boldsymbol{s}; \\boldsymbol{h}^{\\text{ext}}) \\;=\\; -\\frac{1}{2} \\sum_{i,j=1}^{N} J_{ij} s_{i} s_{j} \\;-\\; \\sum_{i=1}^{N} h_{i}^{\\text{ext}} s_{i}.\n$$\n使用 Hebbian $J_{ij}$ 和 $J_{ii}=0$，耦合项可以重写为模式重叠的形式。定义重叠\n$$\nM_{\\mu} \\;=\\; \\sum_{i=1}^{N} \\xi_{i}^{\\mu} s_{i}, \\qquad m_{\\mu} \\;=\\; \\frac{M_{\\mu}}{N}.\n$$\n使用 $J_{ij} = \\frac{1}{N} \\sum_{\\mu} \\xi_{i}^{\\mu} \\xi_{j}^{\\mu}$，并通过 $J_{ii}=0$ 分离对角项，我们得到恒等式\n$$\n\\sum_{i,j=1}^{N} J_{ij} s_{i} s_{j}\n= \\frac{1}{N} \\sum_{\\mu=1}^{P} \\left( \\sum_{i=1}^{N} \\xi_{i}^{\\mu} s_{i} \\right)^{\\!2} - P\n= N \\sum_{\\mu=1}^{P} m_{\\mu}^{2} - P.\n$$\n因此，每自旋能量 $e = E/N$ 为\n$$\ne(\\boldsymbol{s}; h) \\;=\\; -\\frac{1}{2} \\sum_{\\mu=1}^{P} m_{\\mu}^{2} \\;+\\; \\frac{1}{2}\\alpha \\;-\\; \\frac{1}{N} \\sum_{i=1}^{N} h_{i}^{\\text{ext}} s_{i}.\n$$\n最后一项的计算结果为 $-\\frac{1}{N} \\sum_{i} h \\xi_{i}^{3} s_{i} = - h m_{3}$。\n\n我们将计算这两种候选状态的 $e$。\n\n纯模式态 $s_{i} = \\xi_{i}^{1}$。在热力学极限下，重叠为\n$$\nm_{1} \\;=\\; \\frac{1}{N} \\sum_{i} \\xi_{i}^{1} \\xi_{i}^{1} \\;=\\; 1, \\qquad\nm_{\\mu} \\;=\\; \\frac{1}{N} \\sum_{i} \\xi_{i}^{\\mu} \\xi_{i}^{1} \\;\\to\\; 0 \\;\\text{for}\\; \\mu \\neq 1,\n$$\n根据独立性及大数定律。因此，\n$$\n\\sum_{\\mu=1}^{P} m_{\\mu}^{2} \\;\\to\\; 1, \\qquad m_{3} \\;\\to\\; 0.\n$$\n因此每自旋能量为\n$$\ne_{\\text{pure}}(h) \\;=\\; -\\frac{1}{2} \\cdot 1 \\;+\\; \\frac{1}{2} \\alpha \\;-\\; h \\cdot 0\n\\;=\\; -\\frac{1}{2} + \\frac{1}{2} \\alpha.\n$$\n\n伪混合态 $s_{i} = \\operatorname{sign}\\!\\big(\\xi_{i}^{1} + \\xi_{i}^{2} + \\xi_{i}^{3}\\big)$。根据对称性，与三个参与模式的重叠是相等的，$m_{1} = m_{2} = m_{3}$。我们通过枚举 $\\big(\\xi^{1},\\xi^{2},\\xi^{3}\\big) \\in \\{-1,+1\\}^{3}$ 的 $2^{3}$ 种可能性来精确计算 $m_{1}$。定义 $x_{1} = \\xi^{1}$，$x_{2} = \\xi^{2}$，$x_{3} = \\xi^{3}$，它们是均匀独立的。那么\n$$\nm_{1} \\;=\\; \\mathbb{E}\\left[ \\operatorname{sign}(x_{1}+x_{2}+x_{3}) \\, x_{1} \\right].\n$$\n和 $x_{1}+x_{2}+x_{3}$ 的取值范围是 $\\{-3,-1,+1,+3\\}$。枚举所有八种情况：\n\n$$\n\\begin{array}{c|c|c}\n(x_{1},x_{2},x_{3})  \\operatorname{sign}(x_{1}+x_{2}+x_{3})  \\operatorname{sign}(x_{1}+x_{2}+x_{3}) \\, x_{1} \\\\\n\\hline\n(+,+,+)  +  + \\\\\n(+,+,-)  +  + \\\\\n(+,-,+)  +  + \\\\\n(+,-,-)  -  - \\\\\n(-,+,+)  +  - \\\\\n(-,+,-)  -  + \\\\\n(-,-,+)  -  + \\\\\n(-,-,-)  -  + \\\\\n\\end{array}\n$$\n\n乘积在六种情况下为 $+1$，在两种情况下为 $-1$，所以\n$$\nm_{1} \\;=\\; \\frac{6 - 2}{8} \\;=\\; \\frac{1}{2}.\n$$\n根据对称性，$m_{2} = m_{3} = \\tfrac{1}{2}$ 也成立，且对于 $\\mu \\ge 4$（非凝聚模式），$m_{\\mu} \\to 0$。因此\n$$\n\\sum_{\\mu=1}^{P} m_{\\mu}^{2} \\;=\\; 3 \\left(\\frac{1}{2}\\right)^{\\!2} \\;=\\; \\frac{3}{4}, \\qquad m_{3} \\;=\\; \\frac{1}{2}.\n$$\n每自旋能量为\n$$\ne_{\\text{mix3}}(h) \\;=\\; -\\frac{1}{2} \\cdot \\frac{3}{4} \\;+\\; \\frac{1}{2} \\alpha \\;-\\; h \\cdot \\frac{1}{2}\n\\;=\\; -\\frac{3}{8} + \\frac{1}{2} \\alpha - \\frac{h}{2}.\n$$\n\n当 $e_{\\text{mix3}}(h) \\le e_{\\text{pure}}(h)$ 时，伪混合态在能量上比纯模式态更有利。阈值 $h_{c}$ 由等式定义：\n$$\n-\\frac{3}{8} + \\frac{1}{2} \\alpha - \\frac{h_{c}}{2} \\;=\\; -\\frac{1}{2} + \\frac{1}{2} \\alpha.\n$$\n负载项 $\\frac{1}{2}\\alpha$ 在两边被抵消，这反映了在此平均场极限下，非凝聚模式的串扰对两种状态的贡献是相等的。求解 $h_{c}$ 可得\n$$\n-\\frac{3}{8} - \\frac{h_{c}}{2} \\;=\\; -\\frac{1}{2}\n\\;\\;\\Longrightarrow\\;\\;\n\\frac{1}{8} \\;=\\; \\frac{h_{c}}{2}\n\\;\\;\\Longrightarrow\\;\\;\nh_{c} \\;=\\; \\frac{1}{4}.\n$$\n\n因此，在零温和外场与伪混合态的一个组分对齐的热力学极限下，当外部偏置振幅恰好达到 $h_{c} = \\tfrac{1}{4}$ 时，吸引盆从纯模式态翻转到三模式伪混合态。",
            "answer": "$$\\boxed{\\frac{1}{4}}$$"
        },
        {
            "introduction": "真实的生物突觸其強度并非无限精确。这个计算实践 () 旨在探索一个更具生物学合理性的场景，即突觸权重被“裁剪”或量化为有限的几个值。您将通过编写代码来模拟一个具有三元突觸的霍普菲尔德网络，并数值化地评估真实记忆和伪吸引子的稳定性。这项练习提供了计算神经科学的实践经验，并展示了当理想化假设被放宽时，网络的理论特性会如何改变。",
            "id": "4023655",
            "problem": "考虑一个具有 $N$ 个神经元的全连接二元联想记忆网络，该网络以 Hopfield 网络的形式建模。每个神经元的状态为 $s_i \\in \\{-1,+1\\}$，其中 $i \\in \\{1,\\dots,N\\}$。网络存储了一组 $P$ 个独立同分布的随机模式 $\\{\\boldsymbol{\\xi}^\\mu\\}_{\\mu=1}^P$，其中 $\\xi_i^\\mu \\in \\{-1,+1\\}$ 是独立且等概率的。突触耦合通过标准的 Hebbian 法则构建，然后被量化（裁剪）为三元值。你的任务是分析在三元裁剪条件下，伪混合态的存在性与稳定性。\n\n基本根据和定义：\n\n- Hebbian 耦合：\n$$\nJ_{ij} \\;=\\; \\begin{cases}\n\\dfrac{1}{N}\\sum_{\\mu=1}^{P} \\xi_i^\\mu \\,\\xi_j^\\mu,  i \\neq j,\\\\\n0,  i=j,\n\\end{cases}\n$$\n因此 $\\boldsymbol{J}$ 是对称的，且对角线元素为零。\n\n- 对突觸矩阵 $\\boldsymbol{W}$ 进行三元裁剪：\n$$\nw_{ij} \\;=\\; \\begin{cases}\nw_0 \\,\\mathrm{sign}(J_{ij}),  \\text{如果 } |J_{ij}| \\ge \\lambda \\text{ 且 } i \\neq j,\\\\\n0,  \\text{否则},\n\\end{cases}\n$$\n且 $w_{ii}=0$。此处 $w_0 > 0$ 是一个固定的突触强度，$\\lambda \\ge 0$ 是一个裁剪阈值。\n\n- 零温确定性动力学由局部场定义：\n$$\nh_i(\\boldsymbol{s}) \\;=\\; \\sum_{j\\neq i} w_{ij} \\, s_j,\n$$\n一个不动点 $\\boldsymbol{s}$ 的稳定性条件是每个神经元都严格地与其局部场对齐：\n$$\ns_i \\, h_i(\\boldsymbol{s}) \\;>\\; 0 \\quad \\text{对所有 } i \\in \\{1,\\dots,N\\}。\n$$\n将 $\\boldsymbol{s}$ 的稳定裕度定义为\n$$\n\\gamma(\\boldsymbol{s}) \\;=\\; \\min_{1\\le i \\le N} \\left[ s_i \\, h_i(\\boldsymbol{s}) \\right].\n$$\n\n- 在对称矩阵 $\\boldsymbol{W}$ 条件下，Lyapunov 能量函数为\n$$\nE(\\boldsymbol{s}) \\;=\\; -\\dfrac{1}{2} \\sum_{i\\neq j} w_{ij} \\, s_i \\, s_j,\n$$\n能量密度为 $e(\\boldsymbol{s}) \\;=\\; E(\\boldsymbol{s})/N^2$。\n\n- 使用等权重将 $k$-模式伪混合态定义为\n$$\ns_i^{(\\mathrm{mix},k)} \\;=\\; \\mathrm{sign}\\!\\left( \\sum_{\\mu=1}^k \\xi_i^\\mu \\right),\n$$\n遵循平局打破约定 $\\mathrm{sign}(0) = +1$。模式 $\\mu=1$ 的纯粹检索态是\n$$\ns_i^{(\\mathrm{pure})} \\;=\\; \\xi_i^1.\n$$\n\n对于每个指定的测试用例，你的程序必须执行以下操作：\n\n1. 使用提供的随机种子生成 $P$ 个独立模式 $\\{\\boldsymbol{\\xi}^\\mu\\}_{\\mu=1}^P$，其条目在 $\\{-1,+1\\}$ 中，以确保可复现性。\n2. 根据 Hebb 法则构建 $\\boldsymbol{J}$，然后使用上面定义的 $w_0$ 和 $\\lambda$ 将其裁剪为三元矩阵 $\\boldsymbol{W}$。\n3. 从前 $k$ 个存储的模式构建 $k$-混合伪态 $\\boldsymbol{s}^{(\\mathrm{mix},k)}$。\n4. 对 $\\boldsymbol{s}^{(\\mathrm{mix},k)}$ 和 $\\boldsymbol{s}^{(\\mathrm{pure})}$ 两者计算：\n   - 违反稳定性不等式的比例，\n     $$\n     \\phi(\\boldsymbol{s}) \\;=\\; \\dfrac{1}{N} \\sum_{i=1}^N \\mathbf{1}\\left\\{ s_i \\, h_i(\\boldsymbol{s}) \\le 0 \\right\\}。\n     $$\n   - 最小稳定裕度 $\\gamma(\\boldsymbol{s})$。\n   - 能量密度 $e(\\boldsymbol{s})$。\n   - 严格稳定性的布尔指示符，定义为 $\\mathrm{Stable}(\\boldsymbol{s}) = \\mathbf{1}\\{\\gamma(\\boldsymbol{s})>0\\}$。\n\n输出规格：\n\n- 对于每个测试用例，你的程序必须按以下顺序输出一个包含八个条目的列表：\n  1. $\\mathrm{Stable}(\\boldsymbol{s}^{(\\mathrm{mix},k)})$ (布尔值),\n  2. $\\phi(\\boldsymbol{s}^{(\\mathrm{mix},k)})$ (浮点数),\n  3. $\\gamma(\\boldsymbol{s}^{(\\mathrm{mix},k)})$ (浮点数),\n  4. $e(\\boldsymbol{s}^{(\\mathrm{mix},k)})$ (浮点数),\n  5. $\\mathrm{Stable}(\\boldsymbol{s}^{(\\mathrm{pure})})$ (布尔值),\n  6. $\\phi(\\boldsymbol{s}^{(\\mathrm{pure})})$ (浮点数),\n  7. $\\gamma(\\boldsymbol{s}^{(\\mathrm{pure})})$ (浮点数),\n  8. $e(\\boldsymbol{s}^{(\\mathrm{pure})})$ (浮点数).\n- 所有浮点数输出必须四舍五入到六位小数。\n- 将所有测试用例的结果汇总到单行打印输出，格式为由方括号括起来的、以逗号分隔的各测试用例列表，例如 $[\\,[\\dots],\\,[\\dots],\\dots\\,]$。\n- 此问题不涉及物理单位。也不使用角度。\n\n测试套件（每个元组为 $(N,P,k,w_0,\\lambda,\\mathrm{seed})$）：\n\n- Case $1$: $(200,\\,20,\\,3,\\,1.0,\\,0.0,\\,1)$\n- Case $2$: $(200,\\,20,\\,3,\\,1.0,\\,0.01,\\,1)$\n- Case $3$: $(200,\\,40,\\,3,\\,1.0,\\,0.0,\\,2)$\n- Case $4$: $(200,\\,5,\\,3,\\,1.0,\\,0.0,\\,3)$\n- Case $5$: $(200,\\,20,\\,5,\\,1.0,\\,0.0,\\,4)$\n- Case $6$: $(200,\\,20,\\,2,\\,1.0,\\,0.0,\\,5)$\n- Case $7$: $(200,\\,20,\\,3,\\,1.0,\\,0.05,\\,6)$\n\n科学要求：\n\n- 你的推理应基于上述定义、大数定律和中心极限定理（CLT）（如果需要近似计算），但你的实现必须计算指定有限 $N$ 的精确值。\n- 确保你的实现在构建混合态时遵守对所有 $i$ 的严格稳定性标准 $s_i h_i(\\boldsymbol{s}) > 0$ 以及平局打破约定 $\\mathrm{sign}(0)=+1$。\n\n你的程序应生成单行输出，其中包含按上述测试用例的确切顺序列出的、用方括号括起来的逗号分隔列表形式的结果。",
            "solution": "该问题定义明确且具有科学依据，属于计算神经科学和神经网络 statistical mechanics 的标准框架范畴。它要求对一个 Hopfield 型联想记忆网络进行数值模拟，该网络的突触结构有特定修改，即三元裁剪。任务是评估一个记忆模式和一个伪混合态的稳定性。\n\n解决方案的流程是，首先为每个测试用例生成网络模型的必要组件，然后评估指定的量。\n\n1.  **模式和状态的生成：**\n    对于由参数 $(N, P, k, w_0, \\lambda, \\mathrm{seed})$ 定义的每个测试用例，模拟首先使用给定的种子初始化一个伪随机数生成器，以确保可复现性。\n    生成一组 $P$ 个记忆模式 $\\{\\boldsymbol{\\xi}^\\mu\\}_{\\mu=1}^P$。每个模式 $\\boldsymbol{\\xi}^\\mu$ 是一个大小为 $N$ 的向量，其分量 $\\xi_i^\\mu$ 是独立同分布的随机变量，以相等的概率取值 $\\{-1, +1\\}$，即 $P(\\xi_i^\\mu = +1) = P(\\xi_i^\\mu = -1) = 1/2$。\n    根据这些模式，构建两个特定的网络状态用于分析：\n    -   纯粹检索态 $\\boldsymbol{s}^{(\\mathrm{pure})}$，设置为第一个存储的模式：$\\boldsymbol{s}^{(\\mathrm{pure})} = \\boldsymbol{\\xi}^1$。\n    -   $k$-模式伪混合态 $\\boldsymbol{s}^{(\\mathrm{mix},k)}$，由前 $k$ 个模式构建。其分量由规则 $s_i^{(\\mathrm{mix},k)} = \\mathrm{sign}(\\sum_{\\mu=1}^k \\xi_i^\\mu)$ 确定。求和 $\\sum_{\\mu=1}^k \\xi_i^\\mu$ 的结果是一个整数。如果此和为零（这只可能在 $k$ 为偶数时发生），则应用平局打破约定 $\\mathrm{sign}(0) = +1$。\n\n2.  **突觸矩阵的构建：**\n    突触权重通过一个两步过程确定。首先，计算一个中间的 Hebbian 耦合矩阵 $\\boldsymbol{J}$。遵循 Hebbian 学习原理，神经元 $i$ 和神经元 $j$ 之间的连接强度与它们在所有存储模式中的活动相关性成正比。元素 $J_{ij}$ 由以下公式给出：\n    $$\n    J_{ij} = \\frac{1}{N} \\sum_{\\mu=1}^{P} \\xi_i^\\mu \\xi_j^\\mu\n    $$\n    对于 $i \\neq j$，且 $J_{ii} = 0$ 以防止自相互作用。\n    其次，通过一个裁剪过程将此矩阵 $\\boldsymbol{J}$ 转换为一个三元权重矩阵 $\\boldsymbol{W}$。这是一个突触简化或量化的模型。对于给定的裁剪阈值 $\\lambda \\ge 0$ 和突触强度 $w_0 > 0$，元素 $w_{ij}$ 定义如下：\n    $$\n    w_{ij} = \\begin{cases}\n    w_0 \\, \\mathrm{sign}(J_{ij}),  \\text{如果 } |J_{ij}| \\ge \\lambda \\text{ 且 } i \\neq j,\\\\\n    0,  \\text{否则}.\n    \\end{cases}\n    $$\n    对角线元素保持为零，$w_{ii}=0$。这种裁剪将弱突触设置为零，并为所有剩余的突触分配一个统一的强度 $\\pm w_0$，仅保留原始 Hebbian 耦合的符号。\n\n3.  **稳定性和能量分析：**\n    对于一个给定的网络状态 $\\boldsymbol{s} \\in \\{-1, +1\\}^N$，评估其稳定性和能量。该分析对 $\\boldsymbol{s}^{(\\mathrm{pure})}$ 和 $\\boldsymbol{s}^{(\\mathrm{mix},k)}$ 都进行。\n    -   **局部场和稳定性：** 神经元 $i$ 的局部场（或输入）是所有其他神经元状态的加权和：$h_i(\\boldsymbol{s}) = \\sum_{j \\neq i} w_{ij} s_j$。这可以高效地计算为矩阵-向量乘积，$\\boldsymbol{h}(\\boldsymbol{s}) = \\boldsymbol{W}\\boldsymbol{s}$。\n        如果每个神经元的状态都与其局部场对齐，那么状态 $\\boldsymbol{s}$ 就是零温动力学的一个稳定不动点。严格稳定性条件是对于所有 $i=1,\\dots,N$，都有 $s_i h_i(\\boldsymbol{s}) > 0$。\n        由此，我们计算：\n        a. 最小稳定裕度，$\\gamma(\\boldsymbol{s}) = \\min_{i} [s_i h_i(\\boldsymbol{s})]$。\n        b. 稳定性的布尔指示符，$\\mathrm{Stable}(\\boldsymbol{s}) = \\mathbf{1}\\{\\gamma(\\boldsymbol{s}) > 0\\}$，当且仅当所有神经元都满足严格稳定性条件时，该值为真。\n        c. 违反稳定性条件的神经元比例，$\\phi(\\boldsymbol{s}) = \\frac{1}{N} \\sum_{i=1}^N \\mathbf{1}\\{s_i h_i(\\boldsymbol{s}) \\le 0\\}$，其中 $\\mathbf{1}\\{\\cdot\\}$ 是指示函数。请注意，满足 $s_i h_i(\\boldsymbol{s}) = 0$ 的神经元被认为是不稳定的。\n    -   **能量函数：** 对于对称权重矩阵 $\\boldsymbol{W}$，网络的 Lyapunov 能量函数为 $E(\\boldsymbol{s}) = -\\frac{1}{2} \\sum_{i \\neq j} w_{ij} s_i s_j$。使用局部场可以更高效地计算：$E(\\boldsymbol{s}) = -\\frac{1}{2} \\sum_{i=1}^N s_i h_i(\\boldsymbol{s})$。\n        然后能量密度计算为 $e(\\boldsymbol{s}) = E(\\boldsymbol{s})/N^2$。\n\n该实现将遍历每个测试用例，执行这些步骤以计算所需的八个数值（混合态四个，纯粹态四个），将浮点结果四舍五入到六位小数，并将其格式化为指定的列表-of-lists 结构作为最终输出。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to run the simulation for all test cases and print the results.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # (N, P, k, w_0, lambda, seed)\n        (200, 20, 3, 1.0, 0.0, 1),\n        (200, 20, 3, 1.0, 0.01, 1),\n        (200, 40, 3, 1.0, 0.0, 2),\n        (200, 5, 3, 1.0, 0.0, 3),\n        (200, 20, 5, 1.0, 0.0, 4),\n        (200, 20, 2, 1.0, 0.0, 5),\n        (200, 20, 3, 1.0, 0.05, 6),\n    ]\n\n    all_results = []\n    \n    for case in test_cases:\n        N, P, k, w0, lambda_val, seed = case\n        \n        # 1. Generate patterns and states\n        rng = np.random.default_rng(seed)\n        patterns = rng.choice([-1, 1], size=(P, N))\n        \n        # Pure retrieval state\n        s_pure = patterns[0, :].astype(np.float64)\n        \n        # K-mixture spurious state\n        mix_sum = np.sum(patterns[:k, :], axis=0)\n        s_mix = np.sign(mix_sum).astype(np.float64)\n        s_mix[s_mix == 0] = 1.0 # Tie-breaking rule sign(0) = +1\n        \n        # 2. Construct synaptic matrix\n        # Hebbian couplings J\n        J = (1.0 / N) * (patterns.T @ patterns)\n        np.fill_diagonal(J, 0)\n        \n        # Ternary clipped couplings W\n        W = np.zeros_like(J)\n        mask = np.abs(J) >= lambda_val\n        W[mask] = w0 * np.sign(J[mask])\n        np.fill_diagonal(W, 0) # Ensure no self-connections\n\n        # 3. Analyze states\n        mix_analysis = analyze_state(s_mix, W, N)\n        pure_analysis = analyze_state(s_pure, W, N)\n        \n        # 4. Collate results for the current case\n        case_results = list(mix_analysis) + list(pure_analysis)\n        all_results.append(case_results)\n\n    # Final print statement in the exact required format.\n    # We manually construct the string to match the required format: [[...],[...],...]\n    # without any spaces and with floating point numbers formatted to 6 decimal places.\n    outer_parts = []\n    for inner_list in all_results:\n        inner_parts = []\n        for item in inner_list:\n            if isinstance(item, (bool, np.bool_)):\n                inner_parts.append(str(item).lower())\n            elif isinstance(item, (float, np.floating)):\n                inner_parts.append(f\"{item:.6f}\")\n            else:\n                inner_parts.append(str(item))\n        outer_parts.append(f\"[{','.join(inner_parts)}]\")\n    \n    final_string = f\"[{','.join(outer_parts)}]\"\n    print(final_string)\n\ndef analyze_state(s, W, N):\n    \"\"\"\n    Computes stability metrics and energy for a given state s.\n    \n    Args:\n        s (np.ndarray): The state vector of size N.\n        W (np.ndarray): The synaptic weight matrix of size (N, N).\n        N (int): The number of neurons.\n    \n    Returns:\n        tuple: A tuple containing (Stable, phi, gamma, energy_density).\n    \"\"\"\n    # Local fields h_i(s)\n    h = W @ s\n    \n    # Alignments s_i * h_i(s)\n    alignments = s * h\n    \n    # Minimum stability margin gamma(s)\n    gamma = np.min(alignments)\n    \n    # Boolean indicator of strict stability\n    is_stable = gamma > 0\n    \n    # Fraction of violated stability inequalities phi(s)\n    violated_count = np.sum(alignments = 0)\n    phi = violated_count / N\n    \n    # Energy E(s) and energy density e(s)\n    energy = -0.5 * np.sum(alignments)\n    energy_density = energy / (N**2)\n\n    return is_stable, phi, gamma, energy_density\n\nsolve()\n```"
        }
    ]
}