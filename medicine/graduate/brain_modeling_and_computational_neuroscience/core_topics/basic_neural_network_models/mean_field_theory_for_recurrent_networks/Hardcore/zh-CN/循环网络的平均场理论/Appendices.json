{
    "hands_on_practices": [
        {
            "introduction": "理论的美妙之处在于其能够从看似复杂的现象中提炼出简洁的核心原则。此练习将引导我们探索一个循环网络在没有外部输入的情况下，如何自发产生复杂的混沌活动。我们将通过对零活动状态的线性稳定性分析，揭示一个关键的临界条件，即当网络内部的放大（增益）足够强时，静止状态便会失稳，为我们理解自持动态的起源提供一个基本的数学框架 。",
            "id": "3996232",
            "problem": "考虑一个大小为 $N$ 的大型循环速率网络，其连续时间动态为\n$$\n\\tau \\frac{d x_i(t)}{d t} \\;=\\; -x_i(t) \\;+\\; \\sum_{j=1}^{N} J_{ij} \\,\\phi\\!\\left(x_j(t)\\right),\n\\qquad i \\in \\{1,\\dots,N\\},\n$$\n其中 $\\tau0$ 是一个恒定的膜时间尺度，$J_{ij}$ 是独立同分布的高斯随机变量，均值为 $0$，方差为 $g^{2}/N$，而 $\\phi$ 是一个奇、平滑、饱和的非线性函数，满足 $\\phi(0)=0$ 和 $\\phi'(0)0$。没有外部输入。假设在大 $N$ 极限下，随机连接矩阵 $J$ 的经验谱分布收敛于复平面上以原点为中心、半径为 $g$ 的圆盘内的均匀分布，这与独立同分布高斯矩阵的经过充分检验的结果一致。\n\n从线性稳定性分析和随机矩阵性质的第一性原理出发，确定临界增益 $g_c$，在该增益下，平凡不动点 $x_i(t)\\equiv 0$ 失去线性稳定性。在动态平均场理论 (Dynamic Mean-Field Theory, DMFT) 中，对于奇、饱和的 $\\phi$，这与自持非周期性活动（混沌）的产生相关联。用 $\\phi'(0)$ 表示你的最终答案，形式为一个闭式解析表达式。不要提供不等式或需要数值求解的方程；给出 $g_c$ 的单个显式表达式。无需单位。",
            "solution": "问题要求解大型循环神经网络的平凡不动点失去稳定性时的临界增益 $g_c$。网络的动态由以下耦合常微分方程组描述：\n$$\n\\tau \\frac{d x_i(t)}{d t} = -x_i(t) + \\sum_{j=1}^{N} J_{ij} \\phi(x_j(t)), \\qquad i \\in \\{1, \\dots, N\\}\n$$\n其中 $\\tau  0$ 是膜时间常数，$J_{ij}$ 是随机突触权重，$\\phi$ 是激活函数。\n\n首先，我们必须验证对于所有 $i$，$x_i(t) \\equiv 0$ 确实是一个不动点。不动点 $\\mathbf{x}^* = (x_1^*, \\dots, x_N^*)^T$ 满足对于所有 $i$ 都有 $\\frac{d x_i}{d t} = 0$。将 $x_i(t)=0$（对于所有 $i$）代入动力学方程，我们得到：\n$$\n\\tau \\cdot 0 = -0 + \\sum_{j=1}^{N} J_{ij} \\phi(0)\n$$\n鉴于激活函数满足 $\\phi(0) = 0$，方程变为 $0 = 0$，这证实了 $\\mathbf{x}^* = \\mathbf{0}$ 是系统的一个不动点。\n\n接下来，我们围绕这个平凡不动点进行线性稳定性分析。我们考虑一个小的扰动 $\\delta\\mathbf{x}(t)$，使得 $\\mathbf{x}(t) = \\mathbf{x}^* + \\delta\\mathbf{x}(t) = \\delta\\mathbf{x}(t)$。对于其自变量的微小值，函数 $\\phi$ 可以用其在 $0$ 附近的的一阶泰勒展开来近似：\n$$\n\\phi(x_j) \\approx \\phi(0) + \\phi'(0) x_j\n$$\n因为 $x_j = \\delta x_j$ 且 $\\phi(0)=0$，我们有 $\\phi(\\delta x_j) \\approx \\phi'(0) \\delta x_j$。将这个线性化代入关于扰动 $\\delta x_i(t)$ 的原始动力学方程：\n$$\n\\tau \\frac{d \\delta x_i(t)}{d t} = -\\delta x_i(t) + \\sum_{j=1}^{N} J_{ij} \\left( \\phi'(0) \\delta x_j(t) \\right)\n$$\n这个线性微分方程组可以用向量形式表示。设 $\\delta\\mathbf{x}$ 为扰动列向量，$\\mathbf{J}$ 为 $N \\times N$ 的连接矩阵，其元素为 $J_{ij}$。方程变为：\n$$\n\\tau \\frac{d \\delta\\mathbf{x}}{d t} = -\\mathbf{I} \\delta\\mathbf{x} + \\phi'(0) \\mathbf{J} \\delta\\mathbf{x}\n$$\n其中 $\\mathbf{I}$ 是单位矩阵。这可以重写为：\n$$\n\\frac{d \\delta\\mathbf{x}}{d t} = \\frac{1}{\\tau} \\left( -\\mathbf{I} + \\phi'(0) \\mathbf{J} \\right) \\delta\\mathbf{x}\n$$\n不动点 $\\mathbf{x}^* = \\mathbf{0}$ 的稳定性由系统在不动点处评估的雅可比矩阵的特征值决定。雅可比矩阵是 $\\mathbf{M} = \\frac{1}{\\tau} \\left( -\\mathbf{I} + \\phi'(0) \\mathbf{J} \\right)$。当且仅当 $\\mathbf{M}$ 的所有特征值的实部均为负时，该不动点是线性稳定的。\n\n设 $\\lambda_M$ 是 $\\mathbf{M}$ 的一个特征值，$\\lambda_J$ 是 $\\mathbf{J}$ 的一个特征值。这些特征值通过关联这些矩阵的相同线性变换相关联：\n$$\n\\lambda_M = \\frac{1}{\\tau} \\left( -1 + \\phi'(0) \\lambda_J \\right)\n$$\n线性稳定的条件是对于所有特征值都有 $\\text{Re}(\\lambda_M)  0$。代入 $\\lambda_M$ 的表达式：\n$$\n\\text{Re}\\left( \\frac{1}{\\tau} \\left( -1 + \\phi'(0) \\lambda_J \\right) \\right)  0\n$$\n因为 $\\tau  0$ 和 $\\phi'(0)  0$ 是给定的正常数，这可以简化为：\n$$\n-1 + \\phi'(0) \\text{Re}(\\lambda_J)  0\n$$\n$$\n\\phi'(0) \\text{Re}(\\lambda_J)  1\n$$\n$$\n\\text{Re}(\\lambda_J)  \\frac{1}{\\phi'(0)}\n$$\n这个不等式必须对矩阵 $\\mathbf{J}$ 的所有特征值 $\\lambda_J$ 都成立。因此，系统的稳定性由 $\\mathbf{J}$ 的具有最大实部的特征值决定。记为 $\\max_{\\lambda_J \\in \\text{spec}(\\mathbf{J})} \\text{Re}(\\lambda_J)$。稳定性条件是：\n$$\n\\max_{\\lambda_J \\in \\text{spec}(\\mathbf{J})} \\text{Re}(\\lambda_J)  \\frac{1}{\\phi'(0)}\n$$\n当这个不等式变为等式时，不稳定性开始出现。临界增益 $g_c$ 是发生此转变时的 $g$ 值：\n$$\n\\max_{\\lambda_J \\in \\text{spec}(\\mathbf{J})} \\text{Re}(\\lambda_J) = \\frac{1}{\\phi'(0)}\n$$\n为了找到这个最大实部，我们使用提供的关于 $\\mathbf{J}$ 谱的信息。问题陈述，在大 $N$ 极限下，$\\mathbf{J}$ 的特征值均匀分布在复平面上以原点为中心、半径为 $g$ 的圆盘内。这个圆盘是集合 $\\{ z \\in \\mathbb{C} : |z| \\le g \\}$。这个圆盘中具有最大实部的点位于其边界上，特别是在点 $g + 0i$处。因此，$\\mathbf{J}$ 的任意特征值的最大实部是 $g$。\n$$\n\\max_{\\lambda_J \\in \\text{spec}(\\mathbf{J})} \\text{Re}(\\lambda_J) = g\n$$\n将此代入临界条件方程，我们可以解出临界增益 $g_c$：\n$$\ng_c = \\frac{1}{\\phi'(0)}\n$$\n这是增益参数的值，在该值下，平凡不动点失去其稳定性，标志着网络向自持混沌活动的转变。",
            "answer": "$$\n\\boxed{\\frac{1}{\\phi'(0)}}\n$$"
        },
        {
            "introduction": "在掌握了网络自发产生混沌的基础之上，我们现在将探讨外部输入如何调控这些动态。这个练习引入了一个恒定的外部驱动 $I$，并要求我们分析它如何改变混沌的起始点。其核心思想是，外部输入会移动神经元的工作点，从而改变其非线性激活函数的有效增益，最终影响整个网络的稳定性边界。通过这个计算，你将亲身体会到外部控制如何塑造网络内部的动态行为 。",
            "id": "3996308",
            "problem": "考虑一个由 $N$ 个单元组成的连续时间、大规模循环速率网络，其动力学方程为\n$$\n\\tau \\frac{d x_{i}(t)}{dt} \\;=\\; -\\,x_{i}(t) \\;+\\; \\sum_{j=1}^{N} J_{ij}\\,\\phi\\!\\left(x_{j}(t)\\right) \\;+\\; I,\n$$\n其中 $i=1,\\dots,N$，$\\tau0$ 是单个神经元的时间常数，$I$ 是一个施加于所有单元的恒定外部输入，$\\phi(x)$ 是一个二阶连续可微的S型传递函数，$J_{ij}$ 是独立同分布的随机突触权重，其均值为零，方差为 $\\mathrm{Var}(J_{ij}) = g^{2}/N$，并对于所有 $i$ 满足精确的行平衡条件 $\\sum_{j=1}^{N} J_{ij} = 0$。假设 $N$ 足够大，使得 $J$ 的谱满足圆定律，因此其特征值渐近均匀分布在复平面上一个半径为 $g$ 的圆盘内。设非线性函数为双曲正切 $\\phi(x)=\\tanh(x)$。\n\n使用不动点、雅可比线性化和谱稳定性（特征值最大实部决定稳定性）的定义，推导唯一同质不动点失去线性稳定性时的临界耦合强度 $g_{c}(I)$。你的推导必须明确追溯恒定输入 $I$ 如何设定工作点，并从而通过不动点处的平均斜率 $\\langle \\phi'(x)\\rangle$ 来改变网络的有效增益。将你的最终答案表示为关于 $I$ 的单个闭式解析表达式。不需要数值近似；不要包含物理单位。最终答案必须是单个表达式。",
            "solution": "网络的动力学由以下微分方程组给出：\n$$\n\\tau \\frac{d x_{i}(t)}{dt} = -x_{i}(t) + \\sum_{j=1}^{N} J_{ij}\\,\\phi(x_{j}(t)) + I\n$$\n对于 $i=1, \\dots, N$。传递函数为 $\\phi(x) = \\tanh(x)$。\n\n首先，我们确定系统的同质不动点。同质不动点是指对于所有 $i$ 和所有时间 $t$，$x_i(t) = x_0$ 的状态。在不动点处，时间导数为零，即 $\\frac{d x_i}{dt} = 0$。将这些条件代入动力学方程，得到：\n$$\n0 = -x_0 + \\sum_{j=1}^{N} J_{ij}\\,\\phi(x_0) + I\n$$\n我们可以从求和项中提出常数项 $\\phi(x_0)$：\n$$\n0 = -x_0 + \\phi(x_0) \\sum_{j=1}^{N} J_{ij} + I\n$$\n问题陈述指明，连接矩阵 $J$ 满足精确的行平衡约束，即对于所有 $i$，$\\sum_{j=1}^{N} J_{ij} = 0$。应用此约束，求和项消失：\n$$\n0 = -x_0 + \\phi(x_0) \\cdot 0 + I\n$$\n这简化为：\n$$\nx_0 = I\n$$\n因此，存在一个唯一的同质不动点，其中每个单元都处于一个等于外部输入 $I$ 的恒定值。这个值 $x_0 = I$ 是网络的工作点。\n\n接下来，我们分析这个不动点的线性稳定性。我们考虑不动点附近的小扰动 $\\delta x_i(t)$：$x_i(t) = x_0 + \\delta x_i(t) = I + \\delta x_i(t)$。将此代入动力学方程：\n$$\n\\tau \\frac{d}{dt} (I + \\delta x_i(t)) = -(I + \\delta x_i(t)) + \\sum_{j=1}^{N} J_{ij}\\,\\phi(I + \\delta x_j(t)) + I\n$$\n由于 $I$ 是常数，其时间导数为零。扰动方程变为：\n$$\n\\tau \\frac{d \\delta x_i(t)}{dt} = -\\delta x_i(t) + \\sum_{j=1}^{N} J_{ij}\\,\\phi(I + \\delta x_j(t))\n$$\n对于小扰动，我们可以使用一阶泰勒展开将传递函数 $\\phi$ 在工作点 $I$ 附近线性化：$\\phi(I + \\delta x_j) \\approx \\phi(I) + \\phi'(I)\\delta x_j$。\n将此近似代入扰动方程：\n$$\n\\tau \\frac{d \\delta x_i(t)}{dt} \\approx -\\delta x_i(t) + \\sum_{j=1}^{N} J_{ij} \\left( \\phi(I) + \\phi'(I)\\delta x_j(t) \\right)\n$$\n展开求和项：\n$$\n\\tau \\frac{d \\delta x_i(t)}{dt} \\approx -\\delta x_i(t) + \\phi(I) \\sum_{j=1}^{N} J_{ij} + \\phi'(I) \\sum_{j=1}^{N} J_{ij} \\delta x_j(t)\n$$\n再次使用行平衡约束 $\\sum_{j=1}^{N} J_{ij} = 0$。方程简化为：\n$$\n\\tau \\frac{d \\delta x_i(t)}{dt} = -\\delta x_i(t) + \\phi'(I) \\sum_{j=1}^{N} J_{ij} \\delta x_j(t)\n$$\n这是一个线性常微分方程组。写成向量形式，设 $\\delta \\mathbf{x}(t) = (\\delta x_1(t), \\dots, \\delta x_N(t))^T$，该系统为：\n$$\n\\tau \\frac{d \\delta \\mathbf{x}}{dt} = (-I_N + \\phi'(I)J) \\delta \\mathbf{x}\n$$\n其中 $I_N$ 是 $N \\times N$ 单位矩阵，$J$ 是连接矩阵。不动点的稳定性由线性化系统的雅可比矩阵 $M = \\frac{1}{\\tau}(-I_N + \\phi'(I)J)$ 的特征值决定。当且仅当 $M$ 的所有特征值的实部为负时，不动点是稳定的。\n\n设 $\\lambda_J$ 是矩阵 $J$ 的一个特征值。雅可比矩阵 $M$ 的相应特征值 $\\lambda_M$ 由下式给出：\n$$\n\\lambda_M = \\frac{1}{\\tau}(-1 + \\phi'(I)\\lambda_J)\n$$\n稳定性条件是对于所有特征值，$\\mathrm{Re}(\\lambda_M)  0$。由于 $\\tau  0$，这等价于：\n$$\n\\mathrm{Re}(-1 + \\phi'(I)\\lambda_J)  0\n$$\n传递函数的导数是 $\\phi'(x) = \\frac{d}{dx}\\tanh(x) = \\mathrm{sech}^2(x) = 1 - \\tanh^2(x)$。由于对于所有实数 $x$，$\\tanh^2(x)  1$，所以 $\\phi'(x)$ 是一个正实数。因此，$\\phi'(I)$ 是一个正常数。稳定性条件变为：\n$$\n-1 + \\phi'(I)\\mathrm{Re}(\\lambda_J)  0 \\quad \\implies \\quad \\phi'(I)\\mathrm{Re}(\\lambda_J)  1\n$$\n这个不等式必须对 $J$ 的所有特征值 $\\lambda_J$ 成立。当具有最大实部的特征值违反此条件时，系统失去稳定性。\n\n问题陈述，矩阵 $J$ 的特征值渐近均匀分布在复平面上一个以原点为中心、半径为 $g$ 的圆盘内。具有最大可能实部的特征值位于该圆盘的最右边缘，其值为 $\\mathrm{Re}(\\lambda_J) = g$。\n因此，整个系统的稳定性由以下条件决定：\n$$\n\\phi'(I) \\cdot g  1\n$$\n临界耦合强度 $g_c(I)$ 是指稳定性丧失时的 $g$ 值，即不等式变为等式：\n$$\n\\phi'(I) \\cdot g_c(I) = 1\n$$\n解出 $g_c(I)$：\n$$\ng_c(I) = \\frac{1}{\\phi'(I)}\n$$\n项 $\\phi'(I)$ 是由外部输入 $I$ 调节的神经元群体的有效增益。现在我们代入 $\\phi'(I)$ 的具体表达式：\n$$\n\\phi'(x) = 1 - \\tanh^2(x) \\quad \\text{或等价地} \\quad \\phi'(x) = \\mathrm{sech}^2(x) = \\frac{1}{\\cosh^2(x)}\n$$\n在不动点 $x_0 = I$ 处求值，我们有 $\\phi'(I) = 1 - \\tanh^2(I)$。\n因此，临界耦合强度为：\n$$\ng_c(I) = \\frac{1}{1 - \\tanh^2(I)}\n$$\n使用恒等式 $1 - \\tanh^2(x) = \\mathrm{sech}^2(x) = 1/\\cosh^2(x)$，我们以更紧凑的形式得到最终表达式：\n$$\ng_c(I) = \\cosh^2(I)\n$$\n这个表达式给出了 $(I, g)$ 参数空间中同质不动点变得不稳定、导致复杂动力学出现的边界。",
            "answer": "$$\\boxed{\\cosh^{2}(I)}$$"
        },
        {
            "introduction": "前面的练习侧重于确定稳定性的边界，而现在我们将挑战一个更核心的问题：直接求解网络的稳态。这需要我们推导并求解描述输入均值 $\\mu$ 和方差 $\\sigma^2$ 的完整自洽方程。这个实践不仅是理论推导，更是一个编程挑战，要求你实现一个数值求解器来寻找这些方程的解。通过这个过程，你将能够发现并理解多稳态等复杂的网络现象，即网络如何根据初始条件在多个不同的稳定活动状态之间进行选择 。",
            "id": "3996218",
            "problem": "考虑一个包含 $N \\to \\infty$ 个神经元的大型循环速率网络，其中神经元 $i$ 在稳态下的输入被建模为所有神经元输出的随机总和加上一个外部驱动。设输出非线性为整流线性函数 $\\phi(x) = \\max(0,x)$。突触权重是独立同分布的，其均值为 $m/N$，方差为 $g^2/N$，并且每个神经元的外部输入是一个恒定的偏置 $I$。在平均场极限下，神经元群体间的稳态输入分布可由一个均值为 $\\mu$、方差为 $\\sigma^2$ 的高斯分布近似。\n\n从中心极限定理 (CLT) 和大数定律出发，推导 $\\mu$ 和 $\\sigma^2$ 必须满足的自洽条件，该条件用 $\\phi(X)$ 的矩来表示，其中 $X \\sim \\mathcal{N}(\\mu,\\sigma^2)$，并且不假设任何用于计算这些矩的简化公式。明确定义 $m$、$g$ 和 $I$ 在这些自洽条件中的作用。然后，实现一个数值求解器，对于给定的 $(m,g,I)$，找到这些自洽方程的所有不同解 $(\\mu,\\sigma)$。\n\n您的程序必须：\n- 将 $\\mu$ 和 $\\sigma$ 作为未知数，并数值求解耦合的自洽方程。\n- 在 $(\\mu,\\sigma)$ 平面的一个有界区域内搜索多个初始条件，以发现所有不同的解，并报告那些残差低于一个很小容差的解。\n- 解析地处理边界情况 $g=0$。\n- 对于每个测试用例，返回找到的不同解的数量以及 $(\\mu,\\sigma)$ 对的列表。\n\n基于推导出的平均场方程，从循环反馈和整流非线性引起的可能多稳态的角度，解释多重解的存在性。\n\n测试套件由以下参数集组成，每个参数集由 $(m,g,I)$ 指定：\n1. $(0.5,\\,1.2,\\,0.2)$\n2. $(0.8,\\,0.0,\\,0.1)$\n3. $(0.98,\\,2.0,\\,-0.05)$\n4. $(-0.5,\\,1.5,\\,0.6)$\n\n您的程序应生成单行输出，其中包含一个方括号括起来的逗号分隔列表形式的结果，每个测试用例产生一个形如 $[n,\\mu_1,\\sigma_1,\\mu_2,\\sigma_2,\\ldots]$ 的列表，其中 $n$ 等于该案例找到的解的数量。所有的 $\\mu$ 和 $\\sigma$ 值都必须报告为浮点数。不涉及物理单位，也不需要角度或百分比。最终打印的输出必须是所描述的确切格式的单行。",
            "solution": "问题的核心是为一个大型、随机的循环速率神经元网络，推导并求解其突触输入分布的均值 $\\mu$ 和方差 $\\sigma^2$ 的自洽方程。\n\n### 1. 自洽方程的推导\n\n我们对一个包含 $N$ 个神经元的网络进行建模，其中 $N \\to \\infty$。神经元 $i$ 在稳态下的突触输入 $h_i$ 由下式给出：\n$$\nh_i = \\sum_{j=1}^{N} J_{ij} r_j + I\n$$\n其中 $r_j = \\phi(h_j)$ 是神经元 $j$ 的发放率，$\\phi(x) = \\max(0, x)$ 是整流线性（ReLU）激活函数，$I$ 是一个恒定的外部输入。突触权重 $J_{ij}$ 是独立同分布（i.i.d.）的随机变量，其均值为 $E[J_{ij}] = m/N$，方差为 $\\text{Var}(J_{ij}) = g^2/N$。\n\n在平均场极限（$N \\to \\infty$）下，我们假设群体中的输入集合 $\\{h_i\\}$ 可以由一个高斯分布 $h_i \\sim \\mathcal{N}(\\mu, \\sigma^2)$ 来描述。自洽性要求是，该分布的均值和方差必须与生成它的输入的统计特性相一致。\n\n**平均输入 ($\\mu$)**\n\n平均输入 $\\mu$ 是 $h_i$ 在群体上的期望，由于权重的随机性，我们通过对 $J_{ij}$ 的分布取期望来计算它。\n$$\n\\mu = E[h_i] = E\\left[\\sum_{j=1}^{N} J_{ij} r_j + I\\right]\n$$\n根据期望的线性性质以及 $J_{ij}$ 和 $r_j$ 的独立性（这是在此背景下平均场理论的基石），我们有：\n$$\n\\mu = \\sum_{j=1}^{N} E[J_{ij}] E[r_j] + E[I]\n$$\n由于所有神经元在统计上是相同的，因此对所有 $j$ 来说，发放率的期望 $E[r_j]$ 都是相同的。我们将其记为群体平均发放率 $\\langle r \\rangle$。我们有 $E[J_{ij}] = m/N$ 和 $E[I] = I$。\n$$\n\\mu = \\sum_{j=1}^{N} \\frac{m}{N} \\langle r \\rangle + I = N \\cdot \\frac{m}{N} \\langle r \\rangle + I = m \\langle r \\rangle + I\n$$\n平均发放率 $\\langle r \\rangle$ 是激活函数 $\\phi(X)$ 的期望，其中 $X$ 是从输入分布中抽样的一个随机变量，即 $X \\sim \\mathcal{N}(\\mu, \\sigma^2)$。\n$$\n\\langle r \\rangle = E[\\phi(X)]_{X \\sim \\mathcal{N}(\\mu, \\sigma^2)}\n$$\n因此，第一个自洽方程是：\n$$\n\\mu = m E[\\phi(X)] + I\n$$\n\n**输入方差 ($\\sigma^2$)**\n\n输入的方差 $\\sigma^2$ 是 $h_i$ 在群体中的方差。\n$$\n\\sigma^2 = \\text{Var}(h_i) = \\text{Var}\\left(\\sum_{j=1}^{N} J_{ij} r_j + I\\right) = \\text{Var}\\left(\\sum_{j=1}^{N} J_{ij} r_j\\right)\n$$\n求和项 $\\sum_j J_{ij} r_j$ 是大量弱相关随机变量的和。根据中心极限定理（CLT），这个和近似为高斯分布，这为我们的初始假设提供了依据。由于对于不同的 $j$，$J_{ij}r_j$ 项是近似独立的，因此和的方差是方差的和：\n$$\n\\sigma^2 = \\sum_{j=1}^{N} \\text{Var}(J_{ij} r_j)\n$$\n使用全方差公式 $\\text{Var}(Y) = E[\\text{Var}(Y|Z)] + \\text{Var}(E[Y|Z])$，但一个更直接的方法是：$\\text{Var}(J_{ij}r_j) = E[(J_{ij}r_j)^2] - (E[J_{ij}r_j])^2$。在独立性条件下，这变为 $E[J_{ij}^2]E[r_j^2] - (E[J_{ij}])^2(E[r_j])^2$。\n我们知道 $E[J_{ij}^2] = \\text{Var}(J_{ij}) + (E[J_{ij}])^2 = g^2/N + (m/N)^2$。\n$$\n\\text{Var}(J_{ij} r_j) = \\left(\\frac{g^2}{N} + \\frac{m^2}{N^2}\\right)E[r_j^2] - \\left(\\frac{m^2}{N^2}\\right)(E[r_j])^2 = \\frac{g^2}{N} E[r_j^2] + \\frac{m^2}{N^2} \\text{Var}(r_j)\n$$\n对 $j=1, \\dots, N$ 求和，并利用 $E[r_j^2]=\\langle r^2 \\rangle$ 和 $\\text{Var}(r_j) = \\text{Var}(r)$ 在群体中是恒定的这一事实：\n$$\n\\sigma^2 = N \\left(\\frac{g^2}{N} \\langle r^2 \\rangle + \\frac{m^2}{N^2} \\text{Var}(r)\\right) = g^2 \\langle r^2 \\rangle + \\frac{m^2}{N} \\text{Var}(r)\n$$\n在 $N \\to \\infty$ 的极限下，第二项消失。均方发放率 $\\langle r^2 \\rangle$ 是当 $X \\sim \\mathcal{N}(\\mu, \\sigma^2)$ 时 $\\phi(X)^2$ 的期望。\n$$\n\\langle r^2 \\rangle = E[\\phi(X)^2]_{X \\sim \\mathcal{N}(\\mu, \\sigma^2)}\n$$\n因此，第二个自洽方程是：\n$$\n\\sigma^2 = g^2 E[\\phi(X)^2]\n$$\n\n### 2. 整流高斯矩的计算\n\n问题要求对 $X \\sim \\mathcal{N}(\\mu, \\sigma^2)$ 的矩 $E[\\phi(X)]$ 和 $E[\\phi(X)^2]$ 进行显式推导，其概率密度函数为 $p(x) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}}e^{-(x-\\mu)^2/(2\\sigma^2)}$。\n\n**一阶矩 $E[\\phi(X)]$:**\n$$\nE[\\phi(X)] = \\int_{-\\infty}^{\\infty} \\max(0, x) p(x) dx = \\int_{0}^{\\infty} x \\frac{1}{\\sqrt{2\\pi\\sigma^2}}e^{-\\frac{(x-\\mu)^2}{2\\sigma^2}} dx\n$$\n令 $z=(x-\\mu)/\\sigma$，则 $x=\\sigma z+\\mu$ 且 $dx=\\sigma dz$。积分下限变为 $-\\mu/\\sigma$。\n$$\nE[\\phi(X)] = \\int_{-\\mu/\\sigma}^{\\infty} (\\sigma z + \\mu) \\frac{e^{-z^2/2}}{\\sqrt{2\\pi}} dz = \\sigma \\int_{-\\mu/\\sigma}^{\\infty} z \\frac{e^{-z^2/2}}{\\sqrt{2\\pi}} dz + \\mu \\int_{-\\mu/\\sigma}^{\\infty} \\frac{e^{-z^2/2}}{\\sqrt{2\\pi}} dz\n$$\n第一个积分的计算结果为 $\\frac{1}{\\sqrt{2\\pi}}[-e^{-z^2/2}]_{-\\mu/\\sigma}^{\\infty} = \\frac{1}{\\sqrt{2\\pi}} e^{-(\\mu/\\sigma)^2/2}$。\n第二个积分是标准正态分布的生存函数，即 $1 - \\Phi(-\\mu/\\sigma) = \\Phi(\\mu/\\sigma)$，其中 $\\Phi$ 是标准正态累积分布函数。\n$$\nE[\\phi(X)] = \\sigma \\frac{e^{-\\mu^2/(2\\sigma^2)}}{\\sqrt{2\\pi}} + \\mu \\Phi\\left(\\frac{\\mu}{\\sigma}\\right)\n$$\n\n**二阶矩 $E[\\phi(X)^2]$:**\n$$\nE[\\phi(X)^2] = \\int_{0}^{\\infty} x^2 \\frac{1}{\\sqrt{2\\pi\\sigma^2}}e^{-\\frac{(x-\\mu)^2}{2\\sigma^2}} dx\n$$\n使用相同的换元 $z=(x-\\mu)/\\sigma$：\n$$\nE[\\phi(X)^2] = \\int_{-\\mu/\\sigma}^{\\infty} (\\sigma z + \\mu)^2 \\frac{e^{-z^2/2}}{\\sqrt{2\\pi}} dz = \\int_{-\\mu/\\sigma}^{\\infty} (\\sigma^2 z^2 + 2\\mu\\sigma z + \\mu^2) \\frac{e^{-z^2/2}}{\\sqrt{2\\pi}} dz\n$$\n我们计算这三个部分：\n1.  $\\mu^2 \\int_{-\\mu/\\sigma}^{\\infty} \\frac{e^{-z^2/2}}{\\sqrt{2\\pi}} dz = \\mu^2 \\Phi(\\mu/\\sigma)$\n2.  $2\\mu\\sigma \\int_{-\\mu/\\sigma}^{\\infty} z \\frac{e^{-z^2/2}}{\\sqrt{2\\pi}} dz = 2\\mu\\sigma \\frac{e^{-\\mu^2/(2\\sigma^2)}}{\\sqrt{2\\pi}}$\n3.  $\\sigma^2 \\int_{-\\mu/\\sigma}^{\\infty} z^2 \\frac{e^{-z^2/2}}{\\sqrt{2\\pi}} dz$。使用分部积分（$\\int z^2 e^{-z^2/2} dz = -z e^{-z^2/2} + \\int e^{-z^2/2} dz$），此项变为 $\\sigma^2 \\left( \\frac{-\\mu}{\\sigma} \\frac{e^{-\\mu^2/(2\\sigma^2)}}{\\sqrt{2\\pi}} + \\Phi(\\mu/\\sigma) \\right) = -\\mu\\sigma \\frac{e^{-\\mu^2/(2\\sigma^2)}}{\\sqrt{2\\pi}} + \\sigma^2 \\Phi(\\mu/\\sigma)$。\n\n合并所有部分：\n$$\nE[\\phi(X)^2] = \\left(-\\mu\\sigma \\frac{e^{-\\mu^2/(2\\sigma^2)}}{\\sqrt{2\\pi}} + \\sigma^2 \\Phi(\\mu/\\sigma)\\right) + \\left(2\\mu\\sigma \\frac{e^{-\\mu^2/(2\\sigma^2)}}{\\sqrt{2\\pi}}\\right) + \\left(\\mu^2 \\Phi(\\mu/\\sigma)\\right)\n$$\n$$\nE[\\phi(X)^2] = (\\mu^2+\\sigma^2)\\Phi\\left(\\frac{\\mu}{\\sigma}\\right) + \\mu\\sigma\\frac{e^{-\\mu^2/(2\\sigma^2)}}{\\sqrt{2\\pi}}\n$$\n\n### 3. 最终系统与解释\n\n网络平均场统计的动力学由关于 $(\\mu, \\sigma)$ 的耦合非线性方程组的不动点描述：\n1.  $\\mu = m\\left[\\sigma \\frac{e^{-\\mu^2/(2\\sigma^2)}}{\\sqrt{2\\pi}} + \\mu \\Phi\\left(\\frac{\\mu}{\\sigma}\\right)\\right] + I$\n2.  $\\sigma^2 = g^2\\left[(\\mu^2+\\sigma^2)\\Phi\\left(\\frac{\\mu}{\\sigma}\\right) + \\mu\\sigma\\frac{e^{-\\mu^2/(2\\sigma^2)}}{\\sqrt{2\\pi}}\\right]$\n\n参数的作用很明确：\n-   $I$：一个恒定的外部驱动，它会平移平均输入 $\\mu$。\n-   $m$：平均突触强度，它控制从平均网络活动到平均输入的反馈强度。如果 $m  0$（兴奋性），更高的网络活动会增加 $\\mu$，从而产生正反馈。\n-   $g$：突触权重的标准差，它是网络中异质性和“混沌”的来源。它将输入的方差 $\\sigma^2$ 与均方网络活动耦合起来。对于相同水平的活动，更大的 $g$ 会产生更大的输入方差。\n\n对于单一一组参数 $(m, g, I)$，存在多个不同的解 $(\\mu_k, \\sigma_k)$ 意味着多稳态。这意味着网络可以支持多种不同的群体活动稳态。这种现象源于循环反馈与神经元非线性之间的相互作用。例如，一个强的正反馈（大的 $m$）可以造成这样一种情况：一个低活动状态（其中循环输入太弱而无法自我维持）和一个高活动状态（其中强的循环输入维持高的发放率）可以同时存在。系统将根据其初始条件稳定到这些状态之一。\n\n### 4. 数值求解策略\n\n该方程组对未知数 $(\\mu, \\sigma)$（其中 $\\sigma \\ge 0$）进行数值求解。\n-   **情况 $g=0$**：关于 $\\sigma^2$ 的方程变为 $\\sigma^2 = 0$，意味着 $\\sigma=0$。输入不再是随机的，对所有 $i$ 都有 $h_i = \\mu$。第一个方程简化为 $\\mu = m \\cdot \\max(0, \\mu) + I$。通过考虑 $\\mu  0$ 和 $\\mu \\le 0$ 两种情况，可以解析地求解该方程。\n-   **情况 $g0$**：使用数值求根算法（`scipy.optimize.root`）求解耦合的非线性方程。为了找到所有不同的解，在初始条件上执行网格搜索。求解器从 $(\\mu, \\sigma)$ 平面上的许多点启动。如果求解器成功收敛且最终残差低于一个很小的容差（$10^{-7}$），则认为解是有效的。$\\sigma  0$ 的非物理解将被丢弃。通过滤除距离小于指定容差（$10^{-4}$）的重复解，获得最终的唯一解集。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.optimize import root\nfrom scipy.special import erf\n\ndef solve():\n    \"\"\"\n    Derives and numerically solves the mean-field equations for a recurrent rate network.\n    \"\"\"\n    \n    # Test cases defined in the problem statement\n    test_cases = [\n        (0.5, 1.2, 0.2),\n        (0.8, 0.0, 0.1),\n        (0.98, 2.0, -0.05),\n        (-0.5, 1.5, 0.6)\n    ]\n\n    all_results = []\n    for params in test_cases:\n        m, g, I = params\n        \n        # Handle the g=0 case analytically\n        if np.abs(g)  1e-9:\n            solutions = []\n            # Case 1: mu = 0 => max(0, mu) = 0 => mu = I\n            if I = 0:\n                solutions.append((I, 0.0))\n            \n            # Case 2: mu > 0 => max(0, mu) = mu => mu = m*mu + I\n            if np.abs(1 - m) > 1e-9:  # m is not 1\n                mu_sol = I / (1 - m)\n                if mu_sol > 0:\n                    # Check for duplicates before adding\n                    is_new = True\n                    for sol in solutions:\n                        if np.isclose(sol[0], mu_sol):\n                            is_new = False\n                            break\n                    if is_new:\n                        solutions.append((mu_sol, 0.0))\n            elif np.abs(I)  1e-9: # m=1 and I=0\n                # Any mu > 0 is a solution. Problem is ill-posed for this specific point.\n                # Not in test cases. We report no solutions for simplicity.\n                pass\n            \n            unique_solutions = solutions\n        else: # Handle g > 0 case numerically\n            unique_solutions = solve_g_positive(m, g, I)\n\n        # Format the output for this test case\n        flat_list = [len(unique_solutions)]\n        for sol_mu, sol_sigma in unique_solutions:\n            flat_list.extend([sol_mu, sol_sigma])\n        all_results.append(str(flat_list))\n\n    # Print the final output in the required format\n    print(f\"[{','.join(all_results)}]\")\n\ndef get_moments(mu, sigma):\n    \"\"\"\n    Computes the first two moments of a rectified Gaussian distribution.\n    X ~ N(mu, sigma^2), calculates E[max(0,X)] and E[max(0,X)^2].\n    \"\"\"\n    # Handle sigma -> 0 limit for numerical stability\n    if sigma  1e-9:\n        F1 = np.maximum(0., mu)\n        F2 = np.maximum(0., mu)**2\n        return F1, F2\n    \n    z = mu / sigma\n    \n    # Precompute standard normal PDF and CDF values\n    # pdf_val = N(z|0,1), cdf_val = Phi(z)\n    pdf_val = np.exp(-0.5 * z**2) / np.sqrt(2. * np.pi)\n    cdf_val = 0.5 * (1. + erf(z / np.sqrt(2.)))\n    \n    # First moment E[phi(X)]\n    F1 = mu * cdf_val + sigma * pdf_val\n    # Second moment E[phi(X)^2]\n    F2 = (mu**2 + sigma**2) * cdf_val + mu * sigma * pdf_val\n    \n    return F1, F2\n\ndef solve_g_positive(m, g, I):\n    \"\"\"\n    Numerically solves the self-consistency equations for g > 0 using a grid search.\n    \"\"\"\n    \n    def residuals(variables, m_p, g_p, I_p):\n        \"\"\"Residuals of the self-consistency equations.\"\"\"\n        mu, sigma = variables\n        \n        # Penalize unphysical regions (sigma  0) to guide the solver\n        if sigma  0.:\n            return [1e6, 1e6]\n            \n        F1, F2 = get_moments(mu, sigma)\n        \n        res1 = mu - (m_p * F1 + I_p)\n        res2 = sigma**2 - g_p**2 * F2\n        \n        return [res1, res2]\n\n    # Grid search over initial conditions to find multiple solutions\n    mu_guesses = np.linspace(-5.0, 5.0, 21)\n    sigma_guesses = np.linspace(1e-3, 5.0, 21) # Start sigma slightly > 0\n    \n    found_solutions = []\n    \n    for mu0 in mu_guesses:\n        for sigma0 in sigma_guesses:\n            # Use a numerical root finder\n            sol = root(residuals, [mu0, sigma0], args=(m, g, I), method='hybr', tol=1e-9)\n            \n            # Check for convergence and small residual\n            if sol.success and np.linalg.norm(sol.fun)  1e-7:\n                mu_sol, sigma_sol = sol.x\n                # Accept only physical solutions\n                if sigma_sol >= -1e-9: # Allow for small numerical error around 0\n                    found_solutions.append((mu_sol, np.maximum(0, sigma_sol)))\n\n    # Filter for unique solutions\n    unique_solutions = []\n    uniqueness_tol = 1e-4\n    for sol in found_solutions:\n        is_unique = True\n        for unique_sol in unique_solutions:\n            dist = np.linalg.norm(np.array(sol) - np.array(unique_sol))\n            if dist  uniqueness_tol:\n                is_unique = False\n                break\n        if is_unique:\n            unique_solutions.append(sol)\n            \n    # Sort solutions by mu for consistent ordering\n    unique_solutions.sort(key=lambda x: x[0])\n            \n    return unique_solutions\n\nsolve()\n```"
        }
    ]
}