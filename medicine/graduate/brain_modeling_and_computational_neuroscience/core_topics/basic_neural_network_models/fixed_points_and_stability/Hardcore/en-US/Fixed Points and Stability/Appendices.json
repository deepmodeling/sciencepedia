{
    "hands_on_practices": [
        {
            "introduction": "The first step in analyzing any dynamical system, from a single neuron to a large network, is to identify its equilibrium states, or fixed points. This exercise provides foundational practice in this two-step process: first, by solving for the points where the system's dynamics cease, and second, by using linearization to classify the stability of that equilibrium. By calculating the eigenvalues of the Jacobian matrix, you will determine whether small perturbations decay, leading to a stable state, or grow, indicating instability, for a system that exhibits oscillatory behavior .",
            "id": "440703",
            "problem": "Consider the dynamical system defined by the differential equations:\n\n$$\n\\frac{dx}{dt} = -x + y, \\quad \\frac{dy}{dt} = -x - y^3.\n$$\n\nA fixed point occurs where both time derivatives vanish simultaneously. Find the fixed points of the system. Then, for each fixed point, compute the real part of the eigenvalues of the Jacobian matrix evaluated at that point. The real part of the eigenvalues determines linear stability: if negative, the fixed point is linearly stable; if positive, linearly unstable. Report the real part for each fixed point. Since the eigenvalues may be complex, the real part is a real number. The final answer is the real part of the eigenvalues at the fixed point(s), expressed as a single real number if there is only one fixed point.",
            "solution": "We seek fixed points by setting $\\dot x=-x+y=0$ and $\\dot y=-x-y^3=0$. \n1. From $-x+y=0$ we get $y=x$. \n2. Substituting into $-x-y^3=0$ gives $-y-y^3=0\\implies y(1+y^2)=0$, so the only real solution is $y=0$, hence $x=0$. \nThus the unique real fixed point is $(0,0)$.\n\nThe Jacobian matrix is\n$$\nJ(x,y)=\\begin{pmatrix}\n\\partial_x(-x+y)\\partial_y(-x+y)\\\\\n\\partial_x(-x-y^3)\\partial_y(-x-y^3)\n\\end{pmatrix}\n=\\begin{pmatrix}-11\\\\-1-3y^2\\end{pmatrix}.\n$$\nAt $(0,0)$ this becomes\n$$\nJ(0,0)=\\begin{pmatrix}-11\\\\-10\\end{pmatrix}.\n$$\nThe characteristic equation is\n$$\n\\det(J-\\lambda I)\n=\\det\\begin{pmatrix}-1-\\lambda1\\\\-1-\\lambda\\end{pmatrix}\n=(-1-\\lambda)(-\\lambda)-(-1)\n=\\lambda^2+\\lambda+1=0,\n$$\nso the eigenvalues are \n$$\n\\lambda=\\frac{-1\\pm i\\sqrt{3}}{2}.\n$$\nHence the real part of each eigenvalue is \n$$\n\\Re(\\lambda)=-\\frac12.\n$$",
            "answer": "$$\\boxed{-\\frac{1}{2}}$$"
        },
        {
            "introduction": "Linearization is a powerful tool, but it fails when the linear approximation of a system at a fixed point is inconclusiveâ€”specifically, when the Jacobian matrix has eigenvalues with a real part of zero. This problem introduces a more robust method from stability theory: the use of a Lyapunov function. By constructing a scalar function analogous to an \"energy\" landscape and showing that it always decreases along the system's trajectories, you can prove asymptotic stability even in these challenging non-hyperbolic cases .",
            "id": "440581",
            "problem": "Consider the dynamical system defined by the differential equations:\n\n$$\n\\dot{x} = -x^3 + y^4, \\quad \\dot{y} = -2x^2 y - y^3.\n$$\n\nThe origin $(0,0)$ is a fixed point. Using the Lyapunov function $V(x,y) = x^2 + \\frac{1}{2} y^2$, which is positive definite, compute the time derivative $\\dot{V}(x,y)$ along trajectories. Show that $\\dot{V}$ is negative definite in a neighborhood of the origin, and conclude that the origin is asymptotically stable. \n\nWhat is the expression for $\\dot{V}(x,y)$?",
            "solution": "Step 1: Define the Lyapunov function\n$$\nV(x,y)=x^2+\\frac12y^2.\n$$\nStep 2: Compute its partial derivatives\n$$\n\\frac{\\partial V}{\\partial x}=2x,\\quad \\frac{\\partial V}{\\partial y}=y.\n$$\nStep 3: Use the system equations $\\dot x=-x^3+y^4$, $\\dot y=-2x^2y-y^3$ to get\n$$\n\\dot V=\\frac{\\partial V}{\\partial x}\\dot x+\\frac{\\partial V}{\\partial y}\\dot y\n=2x(-x^3+y^4)+y(-2x^2y-y^3).\n$$\nStep 4: Expand and collect terms\n$$\n\\dot V=-2x^4+2x y^4-2x^2y^2-y^4\n=-2x^4-2x^2y^2-y^4+2x y^4.\n$$",
            "answer": "$$\\boxed{-2x^4-2x^2y^2-y^4+2x y^4}$$"
        },
        {
            "introduction": "Moving from abstract systems to practical models, this exercise applies stability concepts to a continuous-time Recurrent Neural Network (RNN), a cornerstone of modern computational neuroscience. This computational task pushes beyond simple stability checks to explore the critical role of non-normal connectivity, where a network can be asymptotically stable yet exhibit large transient amplification of inputs or noise. You will write code to quantify this transient growth and measure the network's robustness, providing direct, hands-on insight into how network architecture shapes its computational dynamics .",
            "id": "3981751",
            "problem": "Consider a continuous-time linear Recurrent Neural Network (RNN) with state vector $\\mathbf{x}(t) \\in \\mathbb{R}^{n}$ governed by the linear time-invariant (LTI) dynamics\n$$\n\\frac{d\\mathbf{x}}{dt} = -\\mathbf{x}(t) + W \\mathbf{x}(t) + \\mathbf{u}(t),\n$$\nwhere $W \\in \\mathbb{R}^{n \\times n}$ is the recurrent connectivity matrix and $\\mathbf{u}(t)$ is an external input. Under zero input, $\\mathbf{u}(t) \\equiv \\mathbf{0}$, the unique fixed point is $\\mathbf{x}^{\\star} = \\mathbf{0}$. Define the system matrix $A := W - I$, where $I$ is the identity matrix. For the homogeneous dynamics $\\frac{d\\mathbf{x}}{dt} = A \\mathbf{x}(t)$, the solution is $\\mathbf{x}(t) = e^{A t} \\mathbf{x}(0)$.\n\nA fixed point is asymptotically stable if and only if for every $\\mathbf{x}(0)$ the solution satisfies $\\lim_{t \\to \\infty} \\mathbf{x}(t) = \\mathbf{0}$. In the linear setting, this occurs if and only if the spectral abscissa $\\alpha(A) := \\max \\{ \\mathrm{Re}(\\lambda) : \\lambda \\in \\sigma(A) \\}$ is strictly negative. Although asymptotically stable, a system with a non-normal $W$ (that is, $W W^{\\top} \\neq W^{\\top} W$) can exhibit transient growth in the norm of the state due to the behavior of $\\lVert e^{A t} \\rVert_{2}$, where $\\lVert \\cdot \\rVert_{2}$ denotes the operator norm induced by the Euclidean vector norm. Such transient growth has implications for robustness of the fixed point because it relates to the size of perturbations that can drive the system away from the fixed point before asymptotic decay takes over. One quantitative robustness measure for unstructured complex perturbations is the complex stability radius $r_{c}(A)$, which can be approximated via the frequency response bound $r_{c}(A) \\approx \\left( \\sup_{\\omega \\in \\mathbb{R}} \\lVert (i \\omega I - A)^{-1} \\rVert_{2} \\right)^{-1}$ when $A$ is asymptotically stable.\n\nYour task is to write a program that, for a given set of small matrices $W$, determines:\n- Asymptotic stability of the fixed point $\\mathbf{x}^{\\star} = \\mathbf{0}$ under $\\mathbf{u}(t) \\equiv \\mathbf{0}$ by checking whether $\\alpha(A)  0$.\n- The peak transient amplification\n$$\nG := \\sup_{t \\in [0, T_{\\max}]} \\lVert e^{A t} \\rVert_{2},\n$$\nestimated on a uniform time grid $t_{k} = k \\Delta t$ for $k = 0, 1, \\dots, \\lfloor T_{\\max} / \\Delta t \\rfloor$.\n- The time $t_{\\mathrm{peak}} \\in [0, T_{\\max}]$ at which the sampled amplification achieves its maximum.\n- The approximate complex stability radius\n$$\nr_{c}(A) \\approx \\left( \\sup_{\\omega \\in [-\\Omega_{\\max}, \\Omega_{\\max}]} \\lVert (i \\omega I - A)^{-1} \\rVert_{2} \\right)^{-1},\n$$\nestimated on the uniform frequency grid $\\omega_{j} = -\\Omega_{\\max} + j \\Delta \\omega$ for $j = 0, 1, \\dots, \\left\\lfloor \\frac{2 \\Omega_{\\max}}{\\Delta \\omega} \\right\\rfloor$. If the system is not asymptotically stable (that is, if $\\alpha(A) \\ge 0$), then define $r_{c}(A) := 0$ without performing the frequency-domain computation.\n\nNumerical requirements:\n- Use the operator $2$-norm for all matrix norms.\n- Use $T_{\\max} = 20.0$ seconds and $\\Delta t = 0.005$ seconds for the time grid.\n- Use $\\Omega_{\\max} = 5.0$ radians per second and $\\Delta \\omega = 0.005$ radians per second for the frequency grid.\n- Express the reported time $t_{\\mathrm{peak}}$ in seconds. Gains $G$ and radii $r_{c}(A)$ are unitless.\n- For numerical stability, when checking asymptotic stability, treat $\\alpha(A)  -10^{-9}$ as stable and otherwise as not stable.\n\nTest suite:\n- Case $1$ (normal, asymptotically stable): $W_{1} = \\begin{bmatrix} 0.8  0.0 \\\\ 0.0  0.6 \\end{bmatrix}$.\n- Case $2$ (non-normal, asymptotically stable with transient growth): $W_{2} = \\begin{bmatrix} 0.9  5.0 \\\\ 0.0  0.9 \\end{bmatrix}$.\n- Case $3$ (non-normal, marginally stable boundary): $W_{3} = \\begin{bmatrix} 1.0  1.0 \\\\ 0.0  1.0 \\end{bmatrix}$.\n- Case $4$ (normal, unstable): $W_{4} = \\begin{bmatrix} 1.05  0.0 \\\\ 0.0  0.8 \\end{bmatrix}$.\n\nFinal output format:\n- For each case $i \\in \\{1,2,3,4\\}$, your program must produce a list $[s_{i}, G_{i}, t_{\\mathrm{peak}, i}, r_{c,i}]$, where $s_{i}$ is a boolean indicating asymptotic stability, $G_{i}$ is the peak transient amplification (float), $t_{\\mathrm{peak}, i}$ is the time of the peak (float, in seconds), and $r_{c,i}$ is the approximate complex stability radius (float).\n- Aggregate the results for the four cases into a single list in the same order as the cases appear above.\n- Round all floating-point outputs $G_{i}$, $t_{\\mathrm{peak}, i}$, and $r_{c,i}$ to exactly six decimal places.\n- Your program should produce a single line of output containing the results as a comma-separated Python-style list of lists, enclosed in square brackets (for example, $\\big[ [\\text{True}, 1.000000, 0.000000, 0.200000], \\dots \\big]$). No other text should be printed.",
            "solution": "The problem requires an analysis of a continuous-time linear Recurrent Neural Network (RNN) described by the state-space equation:\n$$\n\\frac{d\\mathbf{x}}{dt} = -\\mathbf{x}(t) + W \\mathbf{x}(t) + \\mathbf{u}(t)\n$$\nwhere $\\mathbf{x}(t) \\in \\mathbb{R}^{n}$ is the state vector, $W \\in \\mathbb{R}^{n \\times n}$ is the recurrent connectivity matrix, and $\\mathbf{u}(t)$ is an external input. We analyze the system under zero input, $\\mathbf{u}(t) \\equiv \\mathbf{0}$, for which the unique fixed point is $\\mathbf{x}^{\\star} = \\mathbf{0}$. The dynamics can be rewritten in the standard linear time-invariant (LTI) form $\\frac{d\\mathbf{x}}{dt} = A \\mathbf{x}(t)$ by defining the system matrix $A := W - I$, where $I$ is the $n \\times n$ identity matrix.\n\nThe analysis involves four main computational tasks for each given matrix $W$:\n1.  Determining the asymptotic stability of the fixed point.\n2.  Estimating the peak transient amplification, $G$, and the time at which it occurs, $t_{\\mathrm{peak}}$.\n3.  Approximating the complex stability radius, $r_c(A)$.\n\nThe solution proceeds by implementing a step-by-step procedure for each given $W$ matrix.\n\n**Step 1: Construct the System Matrix $A$**\nFor each provided weight matrix $W$, the corresponding system matrix $A$ is calculated as $A = W - I$.\n\n**Step 2: Determine Asymptotic Stability**\nThe asymptotic stability of the fixed point $\\mathbf{x}^{\\star} = \\mathbf{0}$ of the LTI system $\\frac{d\\mathbf{x}}{dt} = A \\mathbf{x}(t)$ is determined by the eigenvalues of the matrix $A$. The system is asymptotically stable if and only if all eigenvalues of $A$ have strictly negative real parts. This condition is equivalent to requiring the spectral abscissa of $A$, defined as $\\alpha(A) := \\max \\{ \\mathrm{Re}(\\lambda) : \\lambda \\in \\sigma(A) \\}$, to be strictly negative. Here, $\\sigma(A)$ denotes the set of eigenvalues of $A$.\nThe procedure is as follows:\n- Compute the eigenvalues of the matrix $A$.\n- Find the maximum of the real parts of these eigenvalues to get $\\alpha(A)$.\n- According to the problem's numerical requirement, the system is considered asymptotically stable if $\\alpha(A)  -10^{-9}$. We will assign a boolean value, $s$, which is `True` for stability and `False` otherwise.\n\n**Step 3: Estimate Peak Transient Amplification ($G$) and Time ($t_{\\mathrm{peak}}$)**\nEven for an asymptotically stable system, the state norm $\\lVert \\mathbf{x}(t) \\rVert_{2}$ can exhibit transient growth before decaying to zero. This phenomenon is particularly prominent in systems with non-normal matrices $A$ (i.e., $A A^{\\top} \\neq A^{\\top} A$). The amplification of initial conditions is described by the operator $2$-norm of the matrix exponential, $\\lVert e^{At} \\rVert_{2}$. The peak transient amplification, $G$, is the maximum value of this norm over a given time interval.\nThe procedure to estimate $G$ and the time of its occurrence, $t_{\\mathrm{peak}}$, is as follows:\n- Define a uniform time grid $t_k = k \\Delta t$ for $k = 0, 1, \\dots, \\lfloor T_{\\max} / \\Delta t \\rfloor$, with the given parameters $T_{\\max} = 20.0$ and $\\Delta t = 0.005$.\n- For each time point $t_k$ in the grid:\n    - Compute the matrix exponential, $E_k = e^{A t_k}$.\n    - Calculate the operator $2$-norm of this matrix, $g_k = \\lVert E_k \\rVert_{2}$.\n- The peak amplification $G$ is the maximum value found: $G = \\max_{k} \\{g_k\\}$.\n- The time of the peak, $t_{\\mathrm{peak}}$, is the time $t_k$ corresponding to the maximum gain $G$.\n\n**Step 4: Approximate the Complex Stability Radius ($r_c(A)$)**\nThe complex stability radius, $r_c(A)$, is a measure of the system's robustness to unstructured complex perturbations. For an asymptotically stable matrix $A$, it can be approximated by the inverse of the peak magnitude of the frequency response of the system's resolvent, $(i\\omega I - A)^{-1}$. The expression is:\n$$\nr_{c}(A) \\approx \\left( \\sup_{\\omega \\in \\mathbb{R}} \\lVert (i \\omega I - A)^{-1} \\rVert_{2} \\right)^{-1}\n$$\nThe problem specifies that if the system is not asymptotically stable (as determined in Step 2), then $r_c(A)$ is defined to be $0$.\nThe procedure to estimate $r_c(A)$ is as follows:\n- If the system is not asymptotically stable ($s$ is `False`), set $r_c(A) = 0.0$.\n- If the system is stable, proceed with the numerical estimation:\n    - Define a uniform frequency grid $\\omega_j = -\\Omega_{\\max} + j \\Delta \\omega$ for $j = 0, 1, \\dots, \\lfloor (2 \\Omega_{\\max}) / \\Delta \\omega \\rfloor$, with parameters $\\Omega_{\\max} = 5.0$ and $\\Delta \\omega = 0.005$.\n    - For each frequency $\\omega_j$ in the grid:\n        - Construct the resolvent matrix form $M_j = (i \\omega_j I - A)$.\n        - Compute its inverse, $M_j^{-1}$.\n        - Calculate the operator $2$-norm of the inverse, $h_j = \\lVert M_j^{-1} \\rVert_2$.\n    - Find the supremum (maximum) of these norms over the grid: $H_{\\max} = \\max_{j} \\{ h_j \\}$.\n    - The approximate complex stability radius is then calculated as $r_c(A) \\approx 1 / H_{\\max}$.\n\nThis complete procedure will be applied to each of the four test cases provided, and the final floating-point values for $G$, $t_{\\mathrm{peak}}$, and $r_c(A)$ will be rounded to six decimal places as required.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.linalg import expm\n\ndef solve():\n    \"\"\"\n    Analyzes the stability and transient behavior of four linear RNN models.\n\n    For each model defined by a matrix W, the function calculates:\n    1. Asymptotic stability based on the spectral abscissa of A = W - I.\n    2. Peak transient amplification G and the time t_peak at which it occurs.\n    3. The approximate complex stability radius r_c.\n    The results are formatted and printed as a single line.\n    \"\"\"\n    \n    # Define the test cases from the problem statement.\n    test_cases = [\n        np.array([[0.8, 0.0], [0.0, 0.6]]),  # Case 1\n        np.array([[0.9, 5.0], [0.0, 0.9]]),  # Case 2\n        np.array([[1.0, 1.0], [0.0, 1.0]]),  # Case 3\n        np.array([[1.05, 0.0], [0.0, 0.8]])  # Case 4\n    ]\n\n    # Numerical parameters\n    stability_threshold = -1e-9\n    T_max = 20.0\n    dt = 0.005\n    Omega_max = 5.0\n    d_omega = 0.005\n    \n    results = []\n    \n    for W in test_cases:\n        # Step 1: Construct the system matrix A\n        I = np.identity(W.shape[0])\n        A = W - I\n\n        # Step 2: Determine Asymptotic Stability\n        eigenvalues = np.linalg.eigvals(A)\n        spectral_abscissa = np.max(np.real(eigenvalues))\n        is_stable = spectral_abscissa  stability_threshold\n\n        # Step 3: Estimate Peak Transient Amplification (G) and Time (t_peak)\n        time_grid = np.arange(0, T_max + dt, dt)\n        gains = []\n        for t in time_grid:\n            exp_At = expm(A * t)\n            norm = np.linalg.norm(exp_At, ord=2)\n            gains.append(norm)\n        \n        gains_arr = np.array(gains)\n        peak_gain = np.max(gains_arr)\n        peak_time_index = np.argmax(gains_arr)\n        peak_time = time_grid[peak_time_index]\n\n        # Step 4: Approximate the Complex Stability Radius (r_c)\n        r_c = 0.0\n        if is_stable:\n            omega_grid = np.arange(-Omega_max, Omega_max + d_omega, d_omega)\n            resolvent_norms = []\n            for omega in omega_grid:\n                # Use complex numbers for the identity matrix\n                resolvent_matrix = (1j * omega * I - A)\n                try:\n                    # The resolvent matrix is guaranteed to be invertible if A is stable and omega is real\n                    inv_resolvent = np.linalg.inv(resolvent_matrix)\n                    norm = np.linalg.norm(inv_resolvent, ord=2)\n                    resolvent_norms.append(norm)\n                except np.linalg.LinAlgError:\n                    # Should not happen for stable A, but as a safeguard\n                    resolvent_norms.append(np.inf)\n\n            if resolvent_norms:\n                H_max = np.max(resolvent_norms)\n                if H_max  0 and np.isfinite(H_max):\n                    r_c = 1.0 / H_max\n                else: # To handle cases of H_max being 0 or infinity\n                    r_c = 0.0\n        \n        # Store results for the current case\n        results.append([is_stable, peak_gain, peak_time, r_c])\n\n    # Final print statement in the exact required format.\n    output_parts = []\n    for res in results:\n        s_i, G_i, t_peak_i, r_c_i = res\n        # Format floating-point numbers to 6 decimal places\n        part_str = f\"[{s_i}, {G_i:.6f}, {t_peak_i:.6f}, {r_c_i:.6f}]\"\n        output_parts.append(part_str)\n        \n    print(f\"[{','.join(output_parts)}]\")\n\nsolve()\n```"
        }
    ]
}