{
    "hands_on_practices": [
        {
            "introduction": "为了将循环神经网络（RNNs）有效地应用于皮层序列建模，理解其基本计算单元的内部工作原理至关重要。本练习将引导您完成门控循环单元（GRU）的单个前向计算步骤，通过具体数值揭示更新门如何将先前的隐藏状态与候选更新进行凸组合，从而形成新的隐藏状态。这项实践有助于加深对 GRU 如何通过门控机制来控制信息流的理解。",
            "id": "4013919",
            "problem": "一个用于皮层序列生成的局部回路模型被实现为一个三维门控循环单元 (GRU)。在时间步 $t$，前一个隐藏状态是 $h_{t-1} \\in \\mathbb{R}^{3}$，更新门输出是 $z_{t} \\in (0,1)^{3}$，重置门输出是 $r_{t} \\in (0,1)^{3}$，预计算的候选更新（有时称为候选隐藏状态）是 $\\tilde{h}_{t} \\in (-1,1)^{3}$。您可以假定文献中标准的 GRU 前向方程以及 logistic sigmoid 和双曲正切函数的常规性质。\n\n考虑以下数值指定的信号：\n- 前一个隐藏状态 $h_{t-1} = \\begin{pmatrix}0.35 \\\\ -0.70 \\\\ 0.20\\end{pmatrix}$。\n- 更新门 $z_{t} = \\begin{pmatrix}0.25 \\\\ 0.60 \\\\ 0.05\\end{pmatrix}$。\n- 重置门 $r_{t} = \\begin{pmatrix}0.40 \\\\ 0.90 \\\\ 0.30\\end{pmatrix}$。\n- 候选更新 $\\tilde{h}_{t} = \\begin{pmatrix}0.80 \\\\ -0.10 \\\\ -0.50\\end{pmatrix}$。\n\n任务：\n1. 使用 GRU 前向定义，根据给定的 $h_{t-1}$、$z_{t}$ 和 $\\tilde{h}_{t}$ 计算下一个隐藏状态 $h_{t}$。\n2. 使用 GRU 更新规则的基本原理以及 logistic sigmoid 和双曲正切函数的范围性质，验证 $h_{t}$ 的每个坐标都是 $h_{t-1}$ 和 $\\tilde{h}_{t}$ 相应坐标的凸组合。提供一个简短的论证，该论证不假设超出这些函数的标准定义和 GRU 方程的任何性质。\n3. 令 $\\|h_{t}\\|_{2}$ 表示新隐藏状态的欧几里得范数。计算 $\\|h_{t}\\|_{2}$ 并将最终答案表示为一个四舍五入到四位有效数字的实数。不需要单位。",
            "solution": "该问题要求完成与门控循环单元 (GRU) 模型相关的三项任务：计算下一个隐藏状态，验证更新规则的一个性质，以及计算新隐藏状态的欧几里得范数。我将按顺序解决这些任务。\n\n首先，提取给定的数据：\n前一个隐藏状态: $h_{t-1} = \\begin{pmatrix}0.35 \\\\ -0.70 \\\\ 0.20\\end{pmatrix}$。\n更新门输出: $z_{t} = \\begin{pmatrix}0.25 \\\\ 0.60 \\\\ 0.05\\end{pmatrix}$。\n重置门输出: $r_{t} = \\begin{pmatrix}0.40 \\\\ 0.90 \\\\ 0.30\\end{pmatrix}$。\n候选更新: $\\tilde{h}_{t} = \\begin{pmatrix}0.80 \\\\ -0.10 \\\\ -0.50\\end{pmatrix}$。\n\n该问题经检验具有科学依据、问题明确且客观。它基于 GRU 的标准数学公式，GRU 是机器学习和计算建模中广泛使用的组件。所提供的数据一致且足以进行所需计算。重置门输出 $r_t$ 的值对于指定的任务不是必需的，因为候选更新 $\\tilde{h}_t$ 已经提供。因此，该问题是有效的。\n\n**任务 1：计算下一个隐藏状态 $h_{t}$。**\n\n在 GRU 中更新隐藏状态的标准前向方程是：\n$$h_{t} = (1 - z_{t}) \\odot h_{t-1} + z_{t} \\odot \\tilde{h}_{t}$$\n其中 $\\odot$ 表示逐元素（哈达玛）积。项 $(1 - z_t)$ 是通过将 $z_t$ 的每个元素从 1 中减去来计算的。\n\n首先，我们计算向量 $(1 - z_t)$：\n$$1 - z_{t} = \\begin{pmatrix}1 \\\\ 1 \\\\ 1\\end{pmatrix} - \\begin{pmatrix}0.25 \\\\ 0.60 \\\\ 0.05\\end{pmatrix} = \\begin{pmatrix}1 - 0.25 \\\\ 1 - 0.60 \\\\ 1 - 0.05\\end{pmatrix} = \\begin{pmatrix}0.75 \\\\ 0.40 \\\\ 0.95\\end{pmatrix}$$\n\n接下来，我们计算更新方程的两项。\n第一项是 $(1 - z_{t}) \\odot h_{t-1}$：\n$$(1 - z_{t}) \\odot h_{t-1} = \\begin{pmatrix}0.75 \\\\ 0.40 \\\\ 0.95\\end{pmatrix} \\odot \\begin{pmatrix}0.35 \\\\ -0.70 \\\\ 0.20\\end{pmatrix} = \\begin{pmatrix}0.75 \\times 0.35 \\\\ 0.40 \\times (-0.70) \\\\ 0.95 \\times 0.20\\end{pmatrix} = \\begin{pmatrix}0.2625 \\\\ -0.28 \\\\ 0.19\\end{pmatrix}$$\n\n第二项是 $z_{t} \\odot \\tilde{h}_{t}$：\n$$z_{t} \\odot \\tilde{h}_{t} = \\begin{pmatrix}0.25 \\\\ 0.60 \\\\ 0.05\\end{pmatrix} \\odot \\begin{pmatrix}0.80 \\\\ -0.10 \\\\ -0.50\\end{pmatrix} = \\begin{pmatrix}0.25 \\times 0.80 \\\\ 0.60 \\times (-0.10) \\\\ 0.05 \\times (-0.50)\\end{pmatrix} = \\begin{pmatrix}0.20 \\\\ -0.06 \\\\ -0.025\\end{pmatrix}$$\n\n最后，我们将这两个结果向量相加得到 $h_{t}$：\n$$h_{t} = \\begin{pmatrix}0.2625 \\\\ -0.28 \\\\ 0.19\\end{pmatrix} + \\begin{pmatrix}0.20 \\\\ -0.06 \\\\ -0.025\\end{pmatrix} = \\begin{pmatrix}0.2625 + 0.20 \\\\ -0.28 - 0.06 \\\\ 0.19 - 0.025\\end{pmatrix} = \\begin{pmatrix}0.4625 \\\\ -0.34 \\\\ 0.165\\end{pmatrix}$$\n\n**任务 2：验证 $h_{t}$ 的每个坐标都是 $h_{t-1}$ 和 $\\tilde{h}_{t}$ 相应坐标的凸组合。**\n\n如果一个标量 $v$ 可以写成 $v = (1-\\alpha)u + \\alpha w$ 的形式，其中系数 $\\alpha \\in [0, 1]$，那么 $v$ 就是两个标量 $u$ 和 $w$ 的凸组合。\n\nGRU 更新方程是逐元素操作的。对于任意坐标 $i \\in \\{1, 2, 3\\}$，更新规则是：\n$$(h_{t})_i = (1 - (z_{t})_i)(h_{t-1})_i + (z_{t})_i(\\tilde{h}_{t})_i$$\n我们定义系数 $\\alpha_i = (z_{t})_i$。第 $i$ 个坐标的方程变为：\n$$(h_{t})_i = (1 - \\alpha_i)(h_{t-1})_i + \\alpha_i(\\tilde{h}_{t})_i$$\n这正是标量 $(h_{t-1})_i$ 和 $(\\tilde{h}_{t})_i$ 的凸组合形式。\n\n必须满足的条件是 $\\alpha_i \\in [0, 1]$。在问题陈述中，更新门输出 $z_t$ 被给定在 $(0,1)^3$ 范围内。这意味着对于每个坐标 $i$，分量 $(z_t)_i$ 严格介于 $0$ 和 $1$ 之间。区间 $(0,1)$ 是区间 $[0,1]$ 的一个子集。\n因此，系数 $\\alpha_i = (z_t)_i$ 满足凸组合的要求。这证实了新隐藏状态 $h_t$ 的每个坐标都是前一个隐藏状态 $h_{t-1}$ 和候选更新 $\\tilde{h}_t$ 相应坐标的凸组合。这个性质对于 GRU 的稳定性至关重要，因为它确保了新隐藏状态是前一个状态和候选更新之间的插值，从而防止了数值失控。\n\n**任务 3：计算欧几里得范数 $\\|h_{t}\\|_{2}$。**\n\n向量 $v = \\begin{pmatrix}v_1  v_2  v_3\\end{pmatrix}^T$ 的欧几里得范数由公式 $\\|v\\|_2 = \\sqrt{v_1^2 + v_2^2 + v_3^2}$ 给出。\n使用任务 1 中计算的向量 $h_t$：\n$$h_{t} = \\begin{pmatrix}0.4625 \\\\ -0.34 \\\\ 0.165\\end{pmatrix}$$\n我们计算其欧几里得范数：\n$$\\|h_{t}\\|_{2} = \\sqrt{(0.4625)^2 + (-0.34)^2 + (0.165)^2}$$\n首先，计算各分量的平方：\n$$(0.4625)^2 = 0.21390625$$\n$$(-0.34)^2 = 0.1156$$\n$$(0.165)^2 = 0.027225$$\n接下来，将这些平方值相加：\n$$\\|h_{t}\\|_{2}^2 = 0.21390625 + 0.1156 + 0.027225 = 0.35673125$$\n最后，取和的平方根：\n$$\\|h_{t}\\|_{2} = \\sqrt{0.35673125} \\approx 0.59726983$$\n问题要求答案四舍五入到四位有效数字。前四位有效数字是 $5$、$9$、$7$、$2$。第五位有效数字是 $6$，因此我们将第四位数字向上取整。\n$$\\|h_{t}\\|_{2} \\approx 0.5973$$\n这是最终的数值答案。",
            "answer": "$$\n\\boxed{0.5973}\n$$"
        },
        {
            "introduction": "超越单个时间步的计算，我们必须考虑 RNN 的长期动态行为，这决定了其作为序列处理器的能力。本练习将介绍回声状态属性（Echo State Property, ESP），这是一个确保网络状态最终只依赖于输入历史而非初始条件的关键概念。您将通过计算权重矩阵的谱半径，并将其与激活函数的 Lipschitz 常数联系起来，来判断一个回声状态网络（ESN）是否满足 ESP 的一个充分条件，从而将线性代数理论与网络稳定性直接挂钩。",
            "id": "4013925",
            "problem": "考虑一个离散时间回声状态网络 (ESN)，其储备池动力学由 $x_{t+1} = \\phi(W x_t + U u_t + b)$ 给出，其中 $x_t \\in \\mathbb{R}^{n}$ 是储备池状态，$u_t \\in \\mathbb{R}^{m}$ 是一个有界输入 ($\\sup_t \\|u_t\\|  \\infty$)，$W \\in \\mathbb{R}^{n \\times n}$ 是回归权重矩阵，$U \\in \\mathbb{R}^{n \\times m}$ 是输入权重矩阵，$b \\in \\mathbb{R}^{n}$ 是一个偏置。激活函数 $\\phi$ 逐元素作用，且为 $\\phi(z) = \\tanh(\\beta z)$，其中 $\\beta  0$。回声状态属性 (ESP) 指出，对于任何有界输入序列，储备池状态 $x_t$ 会渐进地独立于初始条件。\n\n已知矩阵 $W$ 的特征值为\n$$\n\\lambda_1 = 0.82, \\quad \\lambda_2 = -0.60 + 0.75 i, \\quad \\lambda_3 = 1.04 \\exp\\!\\left(i \\frac{\\pi}{6}\\right), \\quad \\lambda_4 = -0.95,\n$$\n且 $\\beta = 0.96$。谱半径 $\\rho(W)$ 定义为 $W$ 的特征值的最大模。激活函数 $\\phi$ 是全局利普希茨的，其利普希茨常数 $L_{\\phi}$ 定义为满足对所有 $a,b \\in \\mathbb{R}$ 都有 $|\\phi(a) - \\phi(b)| \\le L_{\\phi} |a - b|$ 的最小非负数 $L_{\\phi}$。\n\n从利普希茨收缩、线性算子谱半径的基本定义，以及诸如诱导矩阵范数的次可乘性和 Gelfand 公式 $\\lim_{k \\to \\infty} \\|W^{k}\\|^{1/k} = \\rho(W)$（对于任何相容矩阵范数）等经过充分检验的事实出发，推导一个在逐元素激活函数 $\\phi$ 下，对 ESN 储备池的充分且范数无关的收缩判据。然后，计算给定 $W$ 和 $\\beta$ 的相关收缩系数 $c$。\n\n只需提供 $c$ 的数值，四舍五入到四位有效数字。无需单位。你的推导必须在科学上是自洽的，并且除了已陈述的基本原理外，不得假定任何简便公式。",
            "solution": "当对于任何有界输入序列 $\\{u_t\\}$，从不同初始条件开始的轨迹在 $t \\to \\infty$ 时相互收敛，回声状态属性 (ESP) 就得以实现。获得 ESP 充分条件的一条标准途径是，证明对于固定的输入序列，驱动状态更新映射是关于储备池状态的一个收缩。我们使用利普希茨连续性、矩阵范数的次可乘性和谱半径来将此论证形式化。\n\n设储备池更新为 $x_{t+1} = \\phi(W x_t + U u_t + b)$，逐元素作用。考虑由相同输入序列和偏置驱动，但从不同初始条件 $x_0$ 和 $y_0$ 开始的两条轨迹 $x_t$ 和 $y_t$。定义 $\\delta_t = x_t - y_t$。则\n\n$$\n\\delta_{t+1} = \\phi(W x_t + U u_t + b) - \\phi(W y_t + U u_t + b).\n$$\n\n因为 $\\phi$ 逐元素作用并且是全局利普希茨的，常数为 $L_{\\phi}$，所以对于每个坐标 $j$，\n\n$$\n|\\delta_{t+1}^{(j)}| \\le L_{\\phi} \\left| \\left(W x_t + U u_t + b\\right)^{(j)} - \\left(W y_t + U u_t + b\\right)^{(j)} \\right| = L_{\\phi} \\left| \\left(W \\delta_t\\right)^{(j)} \\right|.\n$$\n\n在 $\\mathbb{R}^n$ 上取一个相容的诱导范数 $\\|\\cdot\\|$，并利用逐元素利普希茨连续性以相同常数提升到向量范数的性质，我们得到\n\n$$\n\\|\\delta_{t+1}\\| \\le L_{\\phi} \\|W \\delta_t\\| \\le L_{\\phi} \\|W\\| \\, \\|\\delta_t\\|.\n$$\n\n这个不等式表明，（关于状态差异的）单步利普希茨常数的上界是 $L_{\\phi} \\|W\\|$。如果对于某个诱导矩阵范数 $\\|\\cdot\\|$ 有 $L_{\\phi} \\|W\\|  1$，则该映射是一个收缩，确保了 $\\|\\delta_t\\|$ 指数衰减，从而意味着 ESP。\n\n为了消除对特定矩阵范数选择的依赖，并获得一个范数无关的充分判据，我们考虑 k 步映射。迭代该不等式得到\n\n$$\n\\|\\delta_{t+k}\\| \\le L_{\\phi}^{k} \\|W^{k}\\| \\, \\|\\delta_t\\|.\n$$\n\n根据 Gelfand 公式，对于任何相容矩阵范数，都有 $\\lim_{k \\to \\infty} \\|W^{k}\\|^{1/k} = \\rho(W)$，其中 $\\rho(W)$ 是谱半径。因此，\n\n$$\n\\limsup_{k \\to \\infty} \\left(L_{\\phi}^{k} \\|W^{k}\\|\\right)^{1/k} = L_{\\phi} \\, \\rho(W).\n$$\n\n如果 $L_{\\phi} \\rho(W)  1$，则渐进 k 步利普希茨因子会指数衰减，从而保证轨迹的收缩，因此对于有界输入，ESP 成立。因此，一个充分的、范数无关的收缩判据是\n\n$$\nL_{\\phi} \\, \\rho(W)  1.\n$$\n\n现在我们为给定的系统计算 $L_{\\phi}$ 和 $\\rho(W)$。激活函数是逐元素作用的 $\\phi(z) = \\tanh(\\beta z)$。对于标量 $z$，其导数是\n\n$$\n\\frac{d}{dz} \\tanh(\\beta z) = \\beta \\, \\operatorname{sech}^{2}(\\beta z),\n$$\n\n其在 $z \\in \\mathbb{R}$ 上的最大值是 $\\beta$（在 $z=0$ 时取得，因为 $\\operatorname{sech}^{2}(0) = 1$）。因此，全局利普希茨常数是\n\n$$\nL_{\\phi} = \\beta = 0.96.\n$$\n\n接下来，根据特征值计算谱半径 $\\rho(W)$。每个特征值的模是\n\n$$\n|\\lambda_1| = |0.82| = 0.82,\n$$\n\n\n$$\n|\\lambda_2| = \\sqrt{(-0.60)^{2} + (0.75)^{2}} = \\sqrt{0.36 + 0.5625} = \\sqrt{0.9225} = 0.96,\n$$\n\n\n$$\n|\\lambda_3| = \\left|1.04 \\exp\\!\\left(i \\frac{\\pi}{6}\\right)\\right| = 1.04,\n$$\n\n\n$$\n|\\lambda_4| = |-0.95| = 0.95.\n$$\n\n因此，\n\n$$\n\\rho(W) = \\max\\{0.82, 0.96, 1.04, 0.95\\} = 1.04.\n$$\n\n根据范数无关的充分判据计算出的相关收缩系数是\n\n$$\nc = L_{\\phi} \\, \\rho(W) = 0.96 \\times 1.04 = 0.9984.\n$$\n\n四舍五入到四位有效数字，该值仍为 $0.9984$。由于 $c  1$，该充分判据表明在给定条件下 ESP 成立。要求的最终输出是 $c$ 的数值。",
            "answer": "$$\\boxed{0.9984}$$"
        },
        {
            "introduction": "在将 RNN 模型应用于序列生成任务时，训练与部署之间的差异会带来重大的挑战。本练习探讨了“教师强制”（teacher forcing）训练方法的一个核心问题：当模型在没有真实数据引导的情况下“自由运行”时，由于模型失配导致的误差会如何随时间累积。通过从第一性原理出发，您将推导出一个闭式解，量化预测与真实状态之间的期望平方偏差，从而深刻理解自回归模型中误差传播的动态过程。",
            "id": "4013892",
            "problem": "考虑一个皮层微电路潜活动序列的简化线性模型，该模型表示为一个一阶自回归（$AR(1)$）过程。设真实潜状态为 $\\{x_t\\}_{t \\geq 0}$，其动态为\n$$\nx_t = a\\,x_{t-1} + \\epsilon_t,\n$$\n其中 $a \\in \\mathbb{R}$ 是真实的自回归系数，$\\epsilon_t$ 是独立同分布的高斯新息，满足 $\\epsilon_t \\sim \\mathcal{N}(0,\\sigma^2)$，并且 $x_0 \\sim \\mathcal{N}(0,s_0)$ 与 $\\{\\epsilon_t\\}_{t \\geq 1}$ 独立。一个使用教师强制训练的循环神经网络（RNN）学习一个单步线性预测器，在训练时，它将真实的前一状态 $x_{t-1}$ 作为输入，并预测 $\\hat{x}_t = \\hat{a}\\,x_{t-1}$，其中 $\\hat{a} \\in \\mathbb{R}$ 是学习到的系数。由于模型失配，假设 $\\hat{a} \\neq a$。在部署用于自主序列生成时，RNN在没有教师强制的自由运行模式下迭代运行\n$$\n\\hat{x}_t = \\hat{a}\\,\\hat{x}_{t-1}, \\quad \\text{with } \\hat{x}_0 = x_0.\n$$\n仅使用概率论和线性系统的核心定义以及上述独立性性质，推导在固定时间范围 $T \\in \\mathbb{N}$ 内，自由运行的RNN预测与真实潜状态之间的期望平方偏差\n$$\n\\mathbb{E}\\big[(\\hat{x}_T - x_T)^2\\big],\n$$\n的闭式解析表达式，该表达式是 $a$、$\\hat{a}$、$\\sigma^2$、$s_0$ 和 $T$ 的函数。将您的最终答案表示为单个解析表达式。不需要四舍五入。如果出现角度，应以弧度为单位；此量无需物理单位。",
            "solution": "用户要求我解决这个问题。\n\n### 第一步：提取已知条件\n- 真实潜状态动态：$x_t = a\\,x_{t-1} + \\epsilon_t$，对于 $t \\geq 1$。\n- 真实自回归系数：$a \\in \\mathbb{R}$。\n- 学习到的自回归系数：$\\hat{a} \\in \\mathbb{R}$，且 $\\hat{a} \\neq a$。\n- 新息：$\\epsilon_t$ 是独立同分布 (i.i.d.) 的，满足 $\\epsilon_t \\sim \\mathcal{N}(0,\\sigma^2)$。\n- 初始状态分布：$x_0 \\sim \\mathcal{N}(0,s_0)$。\n- 独立性：$x_0$ 与新息集合 $\\{\\epsilon_t\\}_{t \\geq 1}$ 独立。\n- 自由运行RNN动态：$\\hat{x}_t = \\hat{a}\\,\\hat{x}_{t-1}$，对于 $t \\geq 1$。\n- RNN的初始条件：$\\hat{x}_0 = x_0$。\n- 固定时间范围：$T \\in \\mathbb{N}$。\n- 目标：推导 $\\mathbb{E}\\big[(\\hat{x}_T - x_T)^2\\big]$ 的闭式表达式。\n\n### 第二步：使用提取的已知条件进行验证\n这个问题具有科学依据。它构建了一个真实随机过程（一阶自回归模型，或 $AR(1)$）与一个确定性线性模型之间的比较，这是时间序列分析、控制理论和机器学习中的一个常见基本问题。教师强制和自由运行模式的概念在循环神经网络的研究中是标准概念。\n\n问题是适定的。给出的条件充分且一致，可以得出一个唯一解。参数（$a, \\hat{a}, \\sigma^2, s_0, T$）被明确定义，目标是一个标准的统计量度（均方误差）。所有必要的分布和独立性假设都已提供。\n\n问题是客观的。语言精确且数学化，没有任何主观或推测性的陈述。\n\n问题要求基于概率论和线性系统的第一性原理进行推导，这是一项有效的科学任务。它并非微不足道或同义反复，因为它需要展开递归并应用期望和方差的性质。\n\n### 第三步：结论与行动\n问题是有效的。我将开始推导。\n\n要推导期望平方偏差 $\\mathbb{E}\\big[(\\hat{x}_T - x_T)^2\\big]$ 的表达式，我们首先需要找到在时间范围T时，真实状态 $x_T$ 和预测状态 $\\hat{x}_T$ 的闭式表达式。\n\n首先，考虑自由运行的RNN预测 $\\hat{x}_t$。其动态由递推关系 $\\hat{x}_t = \\hat{a}\\,\\hat{x}_{t-1}$ 和初始条件 $\\hat{x}_0 = x_0$ 给出。我们可以展开这个递推关系：\n$$\n\\hat{x}_1 = \\hat{a}\\,\\hat{x}_0\n$$\n$$\n\\hat{x}_2 = \\hat{a}\\,\\hat{x}_1 = \\hat{a}(\\hat{a}\\,\\hat{x}_0) = \\hat{a}^2\\,\\hat{x}_0\n$$\n通过归纳法，在时间 $T$ 的状态由以下公式给出：\n$$\n\\hat{x}_T = \\hat{a}^T\\,\\hat{x}_0 = \\hat{a}^T\\,x_0\n$$\n\n接下来，考虑真实潜状态 $x_t$。其动态由随机递推关系 $x_t = a\\,x_{t-1} + \\epsilon_t$ 给出。我们从初始状态 $x_0$ 开始展开这个关系：\n$$\nx_1 = a\\,x_0 + \\epsilon_1\n$$\n$$\nx_2 = a\\,x_1 + \\epsilon_2 = a(a\\,x_0 + \\epsilon_1) + \\epsilon_2 = a^2\\,x_0 + a\\,\\epsilon_1 + \\epsilon_2\n$$\n通过归纳法，我们可以将时间 $T$ 的状态表示为初始状态 $x_0$ 和新息序列 $\\{\\epsilon_t\\}_{t=1}^T$ 的函数：\n$$\nx_T = a^T\\,x_0 + \\sum_{k=1}^{T} a^{T-k} \\epsilon_k\n$$\n\n现在我们可以写出偏差项 $D_T = \\hat{x}_T - x_T$：\n$$\nD_T = \\hat{a}^T\\,x_0 - \\left( a^T\\,x_0 + \\sum_{k=1}^{T} a^{T-k} \\epsilon_k \\right)\n$$\n$$\nD_T = (\\hat{a}^T - a^T)\\,x_0 - \\sum_{k=1}^{T} a^{T-k} \\epsilon_k\n$$\n目标是计算这个偏差的平方的期望 $\\mathbb{E}[D_T^2]$。我们展开平方：\n$$\nD_T^2 = \\left( (\\hat{a}^T - a^T)\\,x_0 - \\sum_{k=1}^{T} a^{T-k} \\epsilon_k \\right)^2\n$$\n$$\nD_T^2 = ((\\hat{a}^T - a^T)\\,x_0)^2 - 2 (\\hat{a}^T - a^T)\\,x_0 \\left(\\sum_{k=1}^{T} a^{T-k} \\epsilon_k\\right) + \\left(\\sum_{k=1}^{T} a^{T-k} \\epsilon_k\\right)^2\n$$\n$$\nD_T^2 = (\\hat{a}^T - a^T)^2\\,x_0^2 - 2(\\hat{a}^T - a^T) \\sum_{k=1}^{T} a^{T-k} x_0 \\epsilon_k + \\left(\\sum_{k=1}^{T} a^{T-k} \\epsilon_k\\right)^2\n$$\n根据期望的线性性质，我们可以分别计算每一项的期望：\n$$\n\\mathbb{E}[D_T^2] = \\mathbb{E}\\left[(\\hat{a}^T - a^T)^2\\,x_0^2\\right] - \\mathbb{E}\\left[2(\\hat{a}^T - a^T) \\sum_{k=1}^{T} a^{T-k} x_0 \\epsilon_k\\right] + \\mathbb{E}\\left[\\left(\\sum_{k=1}^{T} a^{T-k} \\epsilon_k\\right)^2\\right]\n$$\n\n我们来逐一分析这三项。\n\n第一项：$\\mathbb{E}\\left[(\\hat{a}^T - a^T)^2\\,x_0^2\\right]$\n因子 $(\\hat{a}^T - a^T)^2$ 是一个常数。我们可以将其从期望中提出：\n$$\n\\mathbb{E}\\left[(\\hat{a}^T - a^T)^2\\,x_0^2\\right] = (\\hat{a}^T - a^T)^2\\,\\mathbb{E}[x_0^2]\n$$\n已知 $x_0 \\sim \\mathcal{N}(0, s_0)$，这意味着 $\\mathbb{E}[x_0] = 0$ 且方差为 $\\text{Var}(x_0) = s_0$。方差定义为 $\\text{Var}(x_0) = \\mathbb{E}[x_0^2] - (\\mathbb{E}[x_0])^2$。由于均值为0，我们有 $\\mathbb{E}[x_0^2] = \\text{Var}(x_0) = s_0$。因此，第一项是：\n$$\n(\\hat{a}^T - a^T)^2\\,s_0\n$$\n\n第二项：$-\\mathbb{E}\\left[2(\\hat{a}^T - a^T) \\sum_{k=1}^{T} a^{T-k} x_0 \\epsilon_k\\right]$\n我们提出常数并使用期望的线性性质：\n$$\n-2(\\hat{a}^T - a^T) \\sum_{k=1}^{T} a^{T-k} \\mathbb{E}[x_0 \\epsilon_k]\n$$\n问题陈述 $x_0$ 与 $\\{\\epsilon_t\\}_{t \\geq 1}$ 独立。对于任何 $k \\in \\{1, \\dots, T\\}$，$x_0$ 和 $\\epsilon_k$ 是独立的。对于独立的随机变量，其乘积的期望等于其期望的乘积：$\\mathbb{E}[x_0 \\epsilon_k] = \\mathbb{E}[x_0]\\mathbb{E}[\\epsilon_k]$。\n我们知道对于所有k，$\\mathbb{E}[x_0] = 0$ 和 $\\mathbb{E}[\\epsilon_k] = 0$。因此，$\\mathbb{E}[x_0 \\epsilon_k] = 0 \\times 0 = 0$。\n所以，整个交叉项的和为零。\n\n第三项：$\\mathbb{E}\\left[\\left(\\sum_{k=1}^{T} a^{T-k} \\epsilon_k\\right)^2\\right]$\n设 $S_T = \\sum_{k=1}^{T} a^{T-k} \\epsilon_k$。由于对于所有k，$\\mathbb{E}[\\epsilon_k]=0$，所以 $S_T$ 的均值为 $\\mathbb{E}[S_T] = \\sum_{k=1}^{T} a^{T-k} \\mathbb{E}[\\epsilon_k] = 0$。因此我们想计算的表达式就是 $S_T$ 的方差，$\\text{Var}(S_T) = \\mathbb{E}[S_T^2] - (\\mathbb{E}[S_T])^2 = \\mathbb{E}[S_T^2]$。\n新息 $\\{\\epsilon_t\\}$ 是独立同分布的，这意味着它们是不相关的。对于不相关随机变量的和，其方差等于方差的和：\n$$\n\\text{Var}(S_T) = \\text{Var}\\left(\\sum_{k=1}^{T} a^{T-k} \\epsilon_k\\right) = \\sum_{k=1}^{T} \\text{Var}(a^{T-k} \\epsilon_k)\n$$\n使用性质 $\\text{Var}(cZ) = c^2 \\text{Var}(Z)$，我们得到：\n$$\n\\sum_{k=1}^{T} (a^{T-k})^2 \\text{Var}(\\epsilon_k) = \\sum_{k=1}^{T} a^{2(T-k)} \\sigma^2 = \\sigma^2 \\sum_{k=1}^{T} a^{2(T-k)}\n$$\n我们来分析这个和。我们可以通过令 $j = T-k$ 来改变求和的索引。当 $k=1$ 时，$j=T-1$。当 $k=T$ 时，$j=0$。和变为：\n$$\n\\sum_{j=0}^{T-1} a^{2j} = \\sum_{j=0}^{T-1} (a^2)^j\n$$\n这是一个有 $T$ 项的有限几何级数，首项为1，公比为 $r = a^2$。其和由公式 $\\frac{1-r^n}{1-r}$ 给出，其中 $n=T$。这个公式在 $r \\neq 1$，即 $a^2 \\neq 1$ 时有效。\n$$\n\\sum_{j=0}^{T-1} (a^2)^j = \\frac{1 - (a^2)^T}{1 - a^2} = \\frac{1 - a^{2T}}{1 - a^2}\n$$\n如果 $a^2 = 1$，和就是项数 $T$。然而，单一解析表达式的形式通常由分数给出，它在极限 $a^2 \\to 1$ 下是连续的。因此，第三项是：\n$$\n\\sigma^2 \\frac{1 - a^{2T}}{1 - a^2}\n$$\n\n最后，我们将这三项相加，得到期望平方偏差的最终表达式：\n$$\n\\mathbb{E}\\big[(\\hat{x}_T - x_T)^2\\big] = (\\hat{a}^T - a^T)^2\\,s_0 + 0 + \\sigma^2 \\frac{1 - a^{2T}}{1 - a^2}\n$$\n$$\n\\mathbb{E}\\big[(\\hat{x}_T - x_T)^2\\big] = (\\hat{a}^T - a^T)^2\\,s_0 + \\sigma^2 \\frac{1 - a^{2T}}{1 - a^2}\n$$\n这个表达式由两部分组成。第一项 $(\\hat{a}^T - a^T)^2\\,s_0$ 表示由于模型（$\\hat{a}$）和真实过程（$a$）之间的动态不匹配而导致的初始状态误差的传播。第二项 $\\sigma^2 \\frac{1 - a^{2T}}{1 - a^2}$ 表示由于真实过程中未建模的随机新息 $\\{\\epsilon_t\\}$ 而累积的误差。",
            "answer": "$$\n\\boxed{(\\hat{a}^{T} - a^{T})^{2} s_{0} + \\sigma^{2} \\frac{1 - a^{2T}}{1 - a^{2}}}\n$$"
        }
    ]
}