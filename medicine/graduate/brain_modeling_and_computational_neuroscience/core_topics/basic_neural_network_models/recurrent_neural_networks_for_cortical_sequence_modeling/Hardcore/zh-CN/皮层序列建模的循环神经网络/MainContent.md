## 引言
大脑皮层的一个基本功能是处理和生成序列信息，这体现在语言、[运动控制](@entry_id:148305)和记忆等多种认知活动中。理解这些动态过程背后的神经计算原理是现代神经科学的核心挑战之一。[循环神经网络](@entry_id:634803)（RNNs）因其固有的处理[时序数据](@entry_id:636380)的能力，已成为模拟皮层序列活动的主要计算框架。然而，从抽象的[机器学习模型](@entry_id:262335)到生物学上合理的皮层环路模型之间存在着巨大的鸿沟。我们如何理解RNN的内部动力学，如何应对训练这些模型时的挑战，以及如何将它们与真实的神经数据和生物学约束联系起来？

本文旨在系统性地回答这些问题。在第一章“原理与机制”中，我们将深入剖析RNN的核心工作方式、训练挑战及其动态特性。随后，在第二章“应用与交叉学科联系”中，我们将展示这些模型如何被用于分析神经数据、启发认知理论，并拓展到神经科学以外的多个领域。最后，通过“动手实践”部分，读者将有机会通过具体的计算练习来巩固所学知识。让我们首先从RNN的基本原理与机制开始，揭示其作为[皮层序列建模](@entry_id:1135696)工具的强大潜力。

## 原理与机制

本章深入探讨将循环神经网络（RNNs）作为[皮层序列建模](@entry_id:1135696)工具的核心原理与机制。我们将从RNN的基本动态特性出发，逐步解析其作为皮层环路模型的[生物学合理性](@entry_id:916293)，探讨训练这些模型时遇到的挑战及解决方案，并审视它们在不同动态机制下的行为。

### RNN的基本动态特性与序列建模

[循环神经网络](@entry_id:634803)的核心在于其随时间演化的内部状态，这一机制使其能够捕捉并生成具有时间依赖性的序列。

#### 作为[生成模型](@entry_id:177561)的循环神经网络

一个循环神经网络通过其[隐藏状态](@entry_id:634361) $h_t$ 的递归更新来处理序列信息。在每一个时间步 $t$，隐藏状态根据前一时刻的状态 $h_{t-1}$ 和当前输入 $x_t$ 进行更新：
$$
h_t = F_{\theta}(h_{t-1}, x_t)
$$
其中 $F_{\theta}$ 是一个由参数 $\theta$ 决定的[非线性](@entry_id:637147)函数。这个隐藏状态可以被视为网络在任意时刻对过去信息的“记忆”或摘要。基于这个[隐藏状态](@entry_id:634361)，网络可以生成一个输出 $y_t$，或者在生成模型的情境下，一个关于下一状态的概率分布。

#### 记忆与上下文：RNN与[马尔可夫模型](@entry_id:899700)的对比

RNN在序列建模中的一个核心优势在于它能够以一种紧凑且连续的方式整合历史信息。这与更简单的模型（如一阶[马尔可夫链](@entry_id:150828)）形成了鲜明对比。一阶[马尔可夫链](@entry_id:150828)（MC）遵循**[马尔可夫性质](@entry_id:139474)**，即下一状态的概率仅依赖于当前状态，而与到达当前状态的历史路径无关。形式上，记离散化后的状态为 $X_t$，则有：
$$
\mathbb{P}(X_{t+1} \mid X_{0:t}) = \mathbb{P}(X_{t+1} \mid X_t)
$$
这种“无记忆”的特性限制了马尔可夫链捕捉[长程依赖](@entry_id:181727)关系的能力。虽然可以通过显式地扩展[状态空间](@entry_id:160914)（例如，将历史状态 $(X_t, X_{t-1}, \dots)$ 作为新状态）来引入更长的记忆，但这会导致[状态空间](@entry_id:160914)大小的指数级增长，从而引发计算和统计上的困难。

相比之下，RNN的隐藏状态 $h_t \in \mathbb{R}^m$ 在一个连续的向量空间中演化，它通过递归更新自然地集成了整个输入历史。RNN的输出（或下一状态的预测）依赖于隐藏状态，因此间接地依赖于全部历史信息。这意味着，对于RNN的输出序列 $\{x_t\}$，通常不满足一阶[马尔可夫性质](@entry_id:139474)，即 $\mathbb{P}(x_{t+1} \mid x_{0:t}) \neq \mathbb{P}(x_{t+1} \mid x_t)$。

此外，RNN状态演化的连续性可以通过其数学形式来保证。例如，一个典型的RNN更新规则可以写为 $h_{t+1} = \sigma(W h_t + U x_t + b)$，其中 $\sigma$ 是一个[非线性激活函数](@entry_id:635291)。如果 $\sigma$ 是**利普希茨连续**（Lipschitz continuous）的，即存在一个常数 $L_{\sigma}$ 使得对于所有 $z, z'$，都有 $\|\sigma(z)-\sigma(z')\| \le L_{\sigma} \|z-z'\|$，那么隐藏状态的变化幅度是有界的。我们可以推导出相邻隐藏状态之差的界限 ：
$$
\|h_{t+1} - h_t\| \le L_{\sigma} \big( \|W\| \, \|h_t - h_{t-1}\| + \|U\| \, \|x_t - x_{t-1}\| \big)
$$
这个不等式精确地表明，隐藏状态的改变受到前一时刻状态改变和输入改变的共同约束。这与马尔可夫链形成对比，后者即使在[状态空间](@entry_id:160914)被精细离散化后，仍可能在不相邻的状态间发生概率性的“跳跃”，缺乏这种内在的连续性保证 。

#### 从连续时间速率模型到离散时间RNN

在[计算神经科学](@entry_id:274500)中，皮层群体的活动通常由连续时间的**速率模型**（rate models）来描述。一个常见的形式是：
$$
\tau \frac{dh(t)}{dt} = -h(t) + \phi(W h(t) + U x(t) + b)
$$
这里，$h(t)$ 代表神经元群体的平均发放率，$\tau$ 是与[细胞膜](@entry_id:146704)或突触相关的内在时间常数，它引入了一种低通滤波效应。这个方程描述了活动 $h(t)$ 如何向一个由网络内部（$Wh(t)$）和外部（$Ux(t)$）输入驱动的目标值 $\phi(\cdot)$ 弛豫。

为了在[数字计算](@entry_id:186530)机上模拟或应用机器学习中的训练算法，我们通常需要将这个[连续时间系统](@entry_id:276553)离散化。使用最简单的[数值积分方法](@entry_id:141406)——**显式[前向欧拉法](@entry_id:141238)**（explicit forward Euler method），我们可以得到一个离散时间的更新规则。将导数 $\frac{dh(t)}{dt}$ 近似为 $\frac{h_{t+1} - h_t}{\Delta t}$，其中 $\Delta t$ 是离散的时间步长，我们得到 ：
$$
\frac{h_{t+1} - h_t}{\Delta t} = \frac{1}{\tau} \big(-h_t + \phi(W h_t + U x_t + b)\big)
$$
整理后可得：
$$
h_{t+1} = \left(1 - \frac{\Delta t}{\tau}\right)h_t + \frac{\Delta t}{\tau} \phi(W h_t + U x_t + b)
$$
这个离散化的方程本身就是一个RNN，其中下一时刻的状态是当前状态与一个[非线性](@entry_id:637147)输入驱动项的加权平均。这个形式揭示了时间常数 $\tau$ 和时间步长 $\Delta t$ 的比值 $\alpha = \Delta t / \tau$ 的重要性。

一个有趣且重要的特殊情况是，当我们设置离散化步长恰好等于网络的内在时间常数，即 $\Delta t = \tau$（或 $\alpha = 1$）时，上式简化为：
$$
h_{t+1} = \phi(W h_t + U x_t + b)
$$
这正是机器学习文献中所谓的“香草RNN”（vanilla RNN）的[更新方程](@entry_id:264802)。因此，标准的离散时间RNN可以被理解为一个内在时间常数等于其更新步长的连续时间速率模型的特例。这个联系为在生物学启发的模型和抽象的工程模型之间架起了一座桥梁 。

### 训练RNN的挑战与高级架构

尽管RNN在理论上功能强大，但在实践中训练它们，尤其是学习长序列中的依赖关系，面临着显著的挑战。

#### [长程依赖](@entry_id:181727)的挑战：[梯度消失与爆炸](@entry_id:634312)

训练RNN的标准算法是**[随时间反向传播](@entry_id:633900)**（Backpropagation Through Time, BPTT）。该算法首先将RNN在时间上“展开”成一个[深度前馈网络](@entry_id:635356)，然后应用标准的[反向传播算法](@entry_id:198231)计算损失函数对参数的梯度。

考虑一个在时间步 $j$ 的[隐藏状态](@entry_id:634361) $h_j$ 对后续某个时间步 $t$ ($t>j$) 的[隐藏状态](@entry_id:634361) $h_t$ 的影响。根据链式法则，这个影响的[雅可比矩阵](@entry_id:178326)为：
$$
\frac{\partial h_t}{\partial h_j} = \prod_{k=j+1}^{t} \frac{\partial h_k}{\partial h_{k-1}} = \prod_{k=j+1}^{t} \text{diag}(\phi'(a_k)) W
$$
其中 $a_k = W h_{k-1} + \dots$ 是时间步 $k$ 的预激活值。在[反向传播](@entry_id:199535)过程中，[误差信号](@entry_id:271594)会乘以这个[雅可比矩阵](@entry_id:178326)的转置。这个连乘积的范数会随着时间跨度 $t-j$ 的增长而指数级地增长或衰减。如果 recurrent weight matrix $W$ 的主要[奇异值](@entry_id:152907)（或在某些情况下，谱半径）与激活函数导数 $\phi'$ 的乘积大于1，梯度将指数级增长，导致**[梯度爆炸](@entry_id:635825)**（exploding gradients）。反之，如果该值小于1（对于饱和的激活函数如 `[tanh](@entry_id:636446)`，其导数在大部分区域都小于1），梯度将指数级衰减，导致**梯度消失**（vanishing gradients）。[梯度消失问题](@entry_id:144098)尤为严重，因为它使得网络无法学习到序列中相距很远的事件之间的关联 。

#### [长短期记忆](@entry_id:637886)（LSTM）网络

为了解决[梯度消失问题](@entry_id:144098)，**[长短期记忆](@entry_id:637886)**（Long Short-Term Memory, [LSTM](@entry_id:635790)）网络被提了出来。[LSTM](@entry_id:635790)的核心创新在于引入了一个独立的**细胞状态**（cell state）$c_t$，它充当信息传递的高速公路。信息流入和流出细胞状态由三个精密的“门”结构来控制：

1.  **[遗忘门](@entry_id:637423) (Forget Gate, $f_t$)**: 决定从前一时刻的细胞状态 $c_{t-1}$ 中丢弃哪些信息。
2.  **输入门 (Input Gate, $i_t$)**: 决定将哪些新的候选信息 $g_t$ 添加到细胞状态中。
3.  **[输出门](@entry_id:634048) (Output Gate, $o_t$)**: 决定细胞状态 $c_t$ 的哪些部分将被输出到隐藏状态 $h_t$。

这些门控单元使用 sigmoid [激活函数](@entry_id:141784) $\sigma$，其输出值在 $(0, 1)$ 之间，可以被解释为允许信息通过的比例。LSTM的完整[更新方程](@entry_id:264802)如下 ：
$$
\begin{align*}
f_t = \sigma(W_f x_t + U_f h_{t-1} + b_f) \\
i_t = \sigma(W_i x_t + U_i h_{t-1} + b_i) \\
o_t = \sigma(W_o x_t + U_o h_{t-1} + b_o) \\
g_t = \tanh(W_g x_t + U_g h_{t-1} + b_g) \\
c_t = f_t \odot c_{t-1} + i_t \odot g_t \\
h_t = o_t \odot \tanh(c_t)
\end{align*}
$$
其中 $\odot$ 表示逐元素乘积。

LSTM缓解梯度消失的关键在于细胞状态的更新方式。$c_t$ 的计算主要是加法操作，而不是像香草RNN中那样的[矩阵乘法](@entry_id:156035)。当我们沿时间反向传播计算梯度时，从 $c_t$ 到 $c_{t-1}$ 的直接路径上的雅可比是 $\text{diag}(f_t)$。这意味着梯度在时间上传播时，主要经历的是与[遗忘门](@entry_id:637423)的值的逐元素乘法，而不是与权重矩阵 $W$ 的反复相乘。如果网络学会在需要时将[遗忘门](@entry_id:637423) $f_t$ 的值设置得接近1，梯度就可以几乎无衰减地沿细胞状态路径向后流动。这个机制被称为**恒定误差流转**（Constant Error Carousel），它极大地改善了网络捕捉[长程依赖](@entry_id:181727)的能力 。

#### [BPTT](@entry_id:633900)的计算成本

理解[BPTT](@entry_id:633900)的计算成本对于实际应用至关重要。考虑一个隐藏层维度为 $n$、序列长度为 $T$ 的RNN。在前向传播的每个时间步，主要的计算开销来自矩阵-向量乘法 $W h_{t-1}$，其复杂度为 $O(n^2)$。因此，长度为 $T$ 的序列的[前向传播](@entry_id:193086)总[时间复杂度](@entry_id:145062)为 $O(T n^2)$。

在[反向传播](@entry_id:199535)中，每个时间步也涉及类似的矩阵-向量乘法（例如，计算 $W^T \delta_h^{(t+1)}$）以及用于累积梯度的[外积](@entry_id:147029)操作（例如，$\delta_a^{(t)} h_{t-1}^T$），这些操作的复杂度也是 $O(n^2)$。因此，[反向传播](@entry_id:199535)的[时间复杂度](@entry_id:145062)同样是 $O(T n^2)$。

如果我们定义网络的总参数数量为 $P$，且网络主要由循环权重构成（即 $P = \Theta(n^2)$），那么一次完整的前向和后向传播的总**[时间复杂度](@entry_id:145062)**为 $O(TP)$。

标准的[BPTT](@entry_id:633900)算法需要存储[前向传播](@entry_id:193086)过程中的所有中间激活值（如 $h_t$ 和预激活值 $a_t$），以便在后向传播时计算梯度。这意味着**内存复杂度**与序列长度 $T$ 成线性关系。总内存需求包括存储参数和梯度的 $O(P)$，以及存储激活值的 $O(Tn)$ 或 $O(T\sqrt{P})$。因此，总内存复杂度为 $O(P + T\sqrt{P})$ 。这种对内存的线性依赖限制了BPTT在极长序列上的应用，并催生了如截断BPTT（Truncated BPTT）等[近似算法](@entry_id:139835)。

### 动态机制与生物学约束

除了学习算法，RNN本身的动态特性以及如何将生物学原理融入其中，对于构建有效的皮层序列模型至关重要。

#### 从有序到混沌：随机循环网络的动态

一个引人入胜的发现是，即使是结构随机的RNN，也能表现出丰富的动态行为。考虑一个大型网络，其连接权重 $J_{ij}$ 从均值为0、方差为 $g^2/N$ 的高斯分布中随机抽取。这里的 $g$ 是一个控制连接强度的**增益**（gain）参数。这样的网络在没有外部输入时，其动态行为由 $g$ 的值决定。

根据Haim Sompolinsky及其同事开创性的均场理论，这类网络存在一个从有序到混沌的相变 。
*   当增益 $g  1$ 时，网络活动会收敛到一个稳定的不动点（通常是静息状态 $x_i = 0$）。任何微小的扰动都会随时间衰减。
*   当增益 $g > 1$ 时，不动点变得不稳定。网络不再收敛，而是进入一种**混沌**（chaotic）状态，其活动随时间不规则地、非周期性地持续变化。

这个相变的[临界点](@entry_id:144653) $g=1$ 可以通过对不动点进行[线性稳定性分析](@entry_id:154985)来确定。稳定性取决于[雅可比矩阵](@entry_id:178326) $gJ - I$ 的特征值。根据[随机矩阵理论](@entry_id:142253)，大型[随机矩阵](@entry_id:269622) $J$ 的[特征值分布](@entry_id:194746)在一个半径为 $\sqrt{N} \cdot \sqrt{g^2/N} = g$ 的圆盘内。当 $g1$ 时，该圆盘的某些部分会进入右半复平面（实部大于1），导致[雅可比矩阵](@entry_id:178326)的某些特征值实部为正，从而使不动点失稳。

在混沌状态（$g1$）下，网络活动（例如其方差 $q$）的统计特性可以通过一个自洽的均[场方程](@entry_id:1124935)来描述。这个理论不仅为理解大脑皮层中观察到的看似随机的自发活动提供了一个理论框架，也启发了后续的神经[网络动力学](@entry_id:268320)研究。

#### 水塘计算范式：[回声状态网络](@entry_id:1124113)

与通过BPTT费力地训练所有网络参数（包括循环权重）不同，**水塘计算**（Reservoir Computing）或**[回声状态网络](@entry_id:1124113)**（Echo State Network, ESN）提供了一种截然不同的范式 。

ESN的核心思想是，一个大型、固定且随机的循环网络（称为“水塘”或“reservoir”）可以作为一个丰富的非[线性动力系统](@entry_id:1127277)，将输入序列映射到高维的状态轨迹上。训练过程仅限于学习一个简单的线性“读出”层，该层将水塘的状态映射到期望的输出。
其主要步骤如下：
1.  **构建水塘**: 创建一个大型RNN，其输入权重 $W_{\text{in}}$ 和循环权重 $W$ 被随机初始化并在此后保持**固定**。
2.  **驱动水塘**: 将训练输入序列馈入水塘，并记录下其内部状态 $x(n)$ 的时间序列。
3.  **训练读出层**: 训练一个线性读出层 $W_{\text{out}}$，使得 $y(n) = W_{\text{out}} x(n)$ 尽可能地接近目标输出序列。由于这只是一个[线性回归](@entry_id:142318)问题，它可以被高效地、解析地求解（例如，使用[岭回归](@entry_id:140984)）。

这种方法的关键在于水塘必须具备**[回声状态属性](@entry_id:1124114)**（Echo State Property, ESP）。该属性要求水塘的当前状态最终应仅由输入历史决定，而与网络的初始状态无关。换句话说，初始条件的影响必须随时间“消逝”或“褪色” 。对于一个线性的动力系统 $x_{t+1} = W x_t + B u_t$，ESP成立的充分必要条件是 $W^t \to 0$ 当 $t \to \infty$。这等价于 $W$ 的**谱半径**（spectral radius）$\rho(W)$ 小于1。[谱半径](@entry_id:138984)定义为其特征值的最大绝对值，即 $\rho(W) = \max_i |\lambda_i(W)|$。因此，为了保证ESP，水塘的循环权重矩阵通常被缩放以使其[谱半径](@entry_id:138984)小于1。这使得水塘工作在稳定、非混沌的机制下，作为一个可靠的输入历史的[非线性滤波器](@entry_id:271726)  。

#### [生物学合理性](@entry_id:916293)：戴尔定律、[兴奋-抑制平衡](@entry_id:1124083)与[短期突触可塑性](@entry_id:171178)

为了使RNN成为更逼真的皮层模型，必须考虑一些基本的生物学约束。

**戴尔定律（Dale's Law）** 指出，一个神经元只释放一种类型的[神经递质](@entry_id:140919)，因此它对其所有突触后神经元的作用要么是兴奋性的，要么是抑制性的。在权重矩阵 $W$ 中，$W_{ij}$ 代表从神经元 $j$ 到 $i$ 的连接。戴尔定律意味着矩阵 $W$ 的每一**列**（代表一个突触前神经元的所有输出连接）的元素必须是同号的：要么全为非负（兴奋性神经元），要么全为非正（抑制性神经元）。

**[兴奋-抑制平衡](@entry_id:1124083)（E-I Balance）** 是皮层环路的一个关键工作机制，其中每个神经元接收到的大量兴奋性输入和抑制性输入在很大程度上相互抵消。这种平衡状态使得网络能够对输入变化做出快速响应，并产生在皮层中观察到的不规则发放模式。在线性化分析中，网络的稳定性取决于权重矩阵 $W$ 的谱特性。具体而言，如果神经元的增益为 $g$，则稳定性要求 $W$ 的谱横坐标（最大特征值实部）$\alpha(W)  1/g$。在包含随机连接和结构化连接（例如，一个增强特定模式的低秩成分）的E-I[平衡网络](@entry_id:1121318)中，结构化部分可以产生**离群特征值**（outlier eigenvalues），这些特征值可能脱离随机部分形成的“主体谱”，并主导网络的动力学。如果这样一个离群特征值的实部超过了稳定性边界 $1/g$，网络就会变得不稳定 。

除了连接的静态结构，突触本身也具有动态性。**[短期突触可塑性](@entry_id:171178)（Short-Term Plasticity, STP）** 是指突触效能在几毫秒到几秒的时间尺度上依赖于近期突触前活动历史的现象。**Tsodyks-Markram (TM)模型** 是描述STP的一个经典现象学模型，它包含两个关键变量 ：
*   $x(t)$: 可用[神经递质](@entry_id:140919)资源的比例，它的消耗导致**短期抑制**（short-term depression）。
*   $u(t)$: 突触利用率，它的增加导致**短期易化**（short-term facilitation）。

这两个变量的动力学由它们各自的时间常数（恢复时间 $\tau_{\text{rec}}$ 和易化时间 $\tau_{\text{fac}}$）以及突触前脉冲的驱动所决定。有效的突触权重在任意时刻是基准权重与 $u(t)$ 和 $x(t)$ 的乘积。通过在RNN中引入这种[动态突触](@entry_id:1124071)，我们在模型中增加了新的、位于突触层面的[隐藏状态](@entry_id:634361)。这极大地丰富了网络的计算能力，使其能够利用不同于[神经元膜电位](@entry_id:191007)时间常数的其他时间尺度来处理和记忆信息，甚至在没有持续神经元发放的情况下维持“沉默”的记忆痕迹 。

### 序列与生成式学习中的挑战

将RNN应用于生成任务和[持续学习](@entry_id:634283)场景时，会出现一些独特的挑战。

#### 生成式学习：[教师强制](@entry_id:636705)与[暴露偏差](@entry_id:637009)

在训练生成式RNN模型（例如，用于预测文本序列的下一个单词）时，一个常见的有效策略是**[教师强制](@entry_id:636705)**（Teacher Forcing）。在该策略下，为了预测时间步 $t$ 的输出，模型接收的输入是来自训练数据的真实（ground-truth）前一时刻的输出 $x_{t-1}$，而不是模型自己在前一步生成的输出。这种方法允许对所有时间步的训练进行高效的[并行化](@entry_id:753104)，并且它与标准的最大似然估计（MLE）目标——最小化 $\text{KL}(p_{\text{data}} \| p_{\text{model}})$ ——完全一致。

然而，这种训练方式在训练和推断之间造成了一个根本性的不匹配。在推断（或生成）阶段，模型必须在“闭环”模式下运行，即使用它自己生成的输出作为下一步的输入。这种分布上的差异被称为**[暴露偏差](@entry_id:637009)**（Exposure Bias）：模型在训练期间从未暴露于自己可能犯的错误之下。一旦在推断时产生一个错误，模型就会进入一个它在训练时很少见过的[状态空间](@entry_id:160914)区域，这可能导致错误[累积和](@entry_id:748124)雪崩 。

#### 缓解[暴露偏差](@entry_id:637009)与持续学习的挑战

为了缓解[暴露偏差](@entry_id:637009)，研究者提出了**预定采样**（Scheduled Sampling）等策略。在训练过程中，该方法以一定的概率（该概率可以随训练进程变化）随机选择使用真实数据或模型自身的输出来作为下一步的输入，从而迫使模型学习如何从自己的错误中恢复。然而，这种方法破坏了与最大似然估计的严格联系，可能导致训练不稳定 。

一个更广泛的挑战出现在**[持续学习](@entry_id:634283)**（Continual Learning）的背景下，即模型需要顺序地学习一系列任务。一个臭名昭著的问题是**灾难性干扰**（Catastrophic Interference）或**[灾难性遗忘](@entry_id:636297)**（Catastrophic Forgetting）。当一个已在任务1上训练好的网络接着在任务2上进行训练时，其在任务1上的性能会急剧下降。

这种遗忘现象的根源在于参数的共享。对任务2的损失函数 $L_2$ 进行[梯度下降](@entry_id:145942)，会更新参数 $\theta$，使其偏离任务1[损失函数](@entry_id:634569) $L_1$ 的[最小值点](@entry_id:634980) $\theta_1$。我们可以对这一过程进行[数学分析](@entry_id:139664)。由于 $\theta_1$ 是 $L_1$ 的一个极小值点，$\nabla_{\theta} L_1(\theta_1) \approx 0$。因此，在任务2上进行一步小的梯度更新 $\Delta\theta = -\eta \nabla_{\theta} L_2(\theta_1)$ 后，$L_1$ 的变化主要由二阶[泰勒展开](@entry_id:145057)项决定 ：
$$
\Delta L_1 = L_1(\theta_1 + \Delta\theta) - L_1(\theta_1) \approx \frac{1}{2} (\Delta\theta)^T H_1(\theta_1) \Delta\theta = \frac{1}{2} \eta^2 (\nabla_{\theta} L_2)^T H_1 (\nabla_{\theta} L_2)
$$
其中 $H_1$ 是 $L_1$ 在 $\theta_1$ 处的Hessian矩阵。使用[高斯-牛顿近似](@entry_id:749740) $H_1 \approx J_1^T J_1$（其中 $J_1$ 是任务1输出对参数的[雅可比矩阵](@entry_id:178326)），我们得到：
$$
\Delta L_1 \approx \frac{1}{2} \eta^2 \|J_1 \nabla_{\theta} L_2\|^2
$$
这个表达式精确地量化了干扰的程度。遗忘（即 $\Delta L_1  0$）的发生，是因为任务2的梯度更新方向 $\nabla_{\theta} L_2$ 没有落在任务1[雅可比矩阵](@entry_id:178326) $J_1$ 的[零空间](@entry_id:171336)（null space）中。换句话说，对任务2重要的参数改变方向，同样也对任务1的输出有影响。这种“[参数敏感性](@entry_id:274265)”的重叠是灾难性干扰的根本原因，也对任何试图模拟大脑终身学习能力的模型提出了深刻的挑战 。