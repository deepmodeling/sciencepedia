{
    "hands_on_practices": [
        {
            "introduction": "理想的联想记忆网络应仅将期望的模式存储为吸引子。然而，赫布学习规则的结构不可避免地会产生非预期的“伪”吸引子，它们通常是多个存储模式的混合态。本练习提供了一种分析工具，用于量化这些伪状态的能量，帮助我们理解它们在网络能量景观中的位置以及它们对记忆提取的潜在干扰。这项练习 () 是表征由简单学习规则所产生的复杂能量景观的基础。",
            "id": "3978367",
            "problem": "考虑一个具有 $N$ 个神经元、状态向量 $s \\in \\{-1,+1\\}^{N}$ 的 Hopfield 型全连接二元联想记忆。其对称突触是通过 Hebb 学习规则从 $P$ 个存储的二元模式 $\\{\\xi^{\\mu}\\}_{\\mu=1}^{P}$ 中学习得到的，其中每个分量 $\\xi_{i}^{\\mu} \\in \\{-1,+1\\}$ 是独立同分布的（i.i.d.），取 $-1$ 和 $+1$ 的概率相等。对于一个状态 $s$，其网络能量为\n$$\nE(s) \\equiv -\\frac{1}{2}\\sum_{i \\neq j} J_{ij}\\, s_{i}\\, s_{j},\n$$\n其中突触矩阵为\n$$\nJ_{ij} \\equiv \\frac{1}{N}\\sum_{\\mu=1}^{P} \\xi_{i}^{\\mu}\\, \\xi_{j}^{\\mu}, \\quad J_{ii} \\equiv 0.\n$$\n假设在低负载标度 $P/N \\to 0$ 下，取热力学极限 $N \\to \\infty$。对于以 $\\mu$、$\\nu$ 和 $\\rho$ 为索引的三个不同存储模式，将三模式伪混合态定义为每个神经元上的多数票决结果，即\n$$\ns_{i}^{\\mathrm{mix}} \\equiv \\mathrm{sgn}\\!\\big(\\xi_{i}^{\\mu} + \\xi_{i}^{\\nu} + \\xi_{i}^{\\rho}\\big),\n$$\n其中 $\\mathrm{sgn}(x) \\in \\{-1,+1\\}$ 表示符号函数，注意三个独立的 $\\{-1,+1\\}$ 变量之和不会出现平局。\n\n仅使用上述模型定义和标准概率极限定理，在热力学极限下推导每个神经元的能量差\n$$\n\\Delta e \\equiv \\lim_{N\\to\\infty}\\frac{1}{N}\\Big(E\\!\\big(s^{\\mathrm{mix}}\\big) - E\\!\\big(\\xi^{\\mu}\\big)\\Big),\n$$\n其中 $E\\!\\big(\\xi^{\\mu}\\big)$ 表示网络状态等于存储模式 $\\xi^{\\mu}$ 时的能量。\n\n将你的最终答案表示为一个精确的无量纲数。无需四舍五入。",
            "solution": "用户希望在 Hopfield 网络中，找出一个三模式伪混合态与单个存储模式之间的每个神经元的能量差 $\\Delta e$。该计算需要在热力学极限（$N \\to \\infty$）和低负载条件（$P/N \\to 0$）下进行。\n\n首先，我们为任意状态 $s \\in \\{-1,+1\\}^{N}$ 建立每个神经元能量的一般表达式 $e(s) = \\frac{E(s)}{N}$。从给定的能量函数开始：\n$$\nE(s) = -\\frac{1}{2}\\sum_{i \\neq j} J_{ij}\\, s_{i}\\, s_{j}\n$$\n代入突触矩阵 $J_{ij}$ 的表达式：\n$$\nE(s) = -\\frac{1}{2}\\sum_{i \\neq j} \\left(\\frac{1}{N}\\sum_{\\mu=1}^{P} \\xi_{i}^{\\mu}\\, \\xi_{j}^{\\mu}\\right) s_{i}\\, s_{j}\n$$\n每个神经元的能量为：\n$$\ne(s) = \\frac{E(s)}{N} = -\\frac{1}{2N^2}\\sum_{\\mu=1}^{P} \\sum_{i \\neq j} (\\xi_{i}^{\\mu} s_{i}) (\\xi_{j}^{\\mu} s_{j})\n$$\n关于 $i \\neq j$ 的求和可以使用恒等式 $\\sum_{i \\neq j} a_i a_j = (\\sum_i a_i)^2 - \\sum_i a_i^2$ 来重写。令 $a_i = \\xi_{i}^{\\mu} s_{i}$。由于 $\\xi_{i}^{\\mu}$ 和 $s_i$ 都在 $\\{-1, +1\\}$ 中，它们的乘积也在 $\\{-1, +1\\}$ 中。因此，$a_i^2 = (\\xi_{i}^{\\mu} s_{i})^2 = 1$，且 $\\sum_{i=1}^{N} a_i^2 = N$。\n$$\ne(s) = -\\frac{1}{2N^2}\\sum_{\\mu=1}^{P} \\left[ \\left(\\sum_{i=1}^{N} \\xi_{i}^{\\mu} s_{i}\\right)^2 - N \\right]\n$$\n我们将状态 $s$ 与存储模式 $\\xi^{\\mu}$ 之间的重叠（或相关性）定义为：\n$$\nm_{\\mu,s} \\equiv \\frac{1}{N}\\sum_{i=1}^{N} \\xi_{i}^{\\mu} s_{i}\n$$\n将此定义代入 $e(s)$ 的表达式中：\n$$\ne(s) = -\\frac{1}{2N^2}\\sum_{\\mu=1}^{P} \\left[ (N m_{\\mu,s})^2 - N \\right] = -\\frac{1}{2}\\sum_{\\mu=1}^{P} \\left[ m_{\\mu,s}^2 - \\frac{1}{N} \\right] = -\\frac{1}{2}\\sum_{\\mu=1}^{P} m_{\\mu,s}^2 + \\frac{P}{2N}\n$$\n在热力学极限 $N\\to\\infty$ 和低负载条件 $P/N \\to 0$ 下，项 $\\frac{P}{2N}$ 消失。此外，根据大数定律，经验平均值 $m_{\\mu,s}$ 在概率上收敛于其统计期望，我们将其表示为 $M_{\\mu,s}$：\n$$\n\\lim_{N \\to \\infty} m_{\\mu,s} = \\mathbb{E}[\\xi_{i}^{\\mu} s_{i}] \\equiv M_{\\mu,s}\n$$\n期望的随机性来自于模式 $\\xi_i^\\sigma$ 的独立同分布分量。因此，极限情况下的每个神经元能量变为：\n$$\n\\lim_{N\\to\\infty, P/N\\to 0} e(s) = -\\frac{1}{2}\\sum_{\\mu=1}^{P} M_{\\mu,s}^2\n$$\n\n现在，我们将此通用公式应用于我们感兴趣的两个状态。\n\n1.  **存储模式的能量，$E(\\xi^{\\nu})$**\n\n设网络状态为某个存储模式 $s = \\xi^{\\nu}$，其中 $\\nu \\in \\{1, \\dots, P\\}$ 是一个固定索引。我们计算期望重叠 $M_{\\mu,\\xi^{\\nu}}$：\n$$\nM_{\\mu,\\xi^{\\nu}} = \\mathbb{E}[\\xi_{i}^{\\mu} \\xi_{i}^{\\nu}]\n$$\n-   如果 $\\mu = \\nu$：$M_{\\nu,\\xi^{\\nu}} = \\mathbb{E}[(\\xi_{i}^{\\nu})^2] = \\mathbb{E}[1] = 1$。\n-   如果 $\\mu \\neq \\nu$：模式 $\\xi^{\\mu}$ 和 $\\xi^{\\nu}$ 是独立的。因此，$M_{\\mu,\\xi^{\\nu}} = \\mathbb{E}[\\xi_{i}^{\\mu}] \\mathbb{E}[\\xi_{i}^{\\nu}]$。由于 $\\xi_i^\\sigma$ 是独立同分布的，且 $P(\\xi_i^\\sigma=+1)=P(\\xi_i^\\sigma=-1)=1/2$，其期望为 $\\mathbb{E}[\\xi_i^\\sigma] = \\frac{1}{2}(+1) + \\frac{1}{2}(-1) = 0$。所以，$M_{\\mu,\\xi^{\\nu}} = 0 \\cdot 0 = 0$。\n\n和 $\\sum_{\\mu=1}^{P} M_{\\mu,\\xi^{\\nu}}^2$ 只有一个非零项，即在 $\\mu = \\nu$ 时。\n$$\n\\sum_{\\mu=1}^{P} M_{\\mu,\\xi^{\\nu}}^2 = M_{\\nu,\\xi^{\\nu}}^2 + \\sum_{\\mu \\neq \\nu} M_{\\mu,\\xi^{\\nu}}^2 = 1^2 + 0 = 1\n$$\n因此，任何存储模式的每个神经元能量为：\n$$\n\\lim_{N\\to\\infty}\\frac{1}{N}E(\\xi^{\\nu}) = -\\frac{1}{2}(1) = -\\frac{1}{2}\n$$\n\n2.  **伪混合态的能量，$E(s^{\\mathrm{mix}})$**\n\n设混合态由三个不同的模式形成，不失一般性地，我们将其标记为 $\\xi^1, \\xi^2, \\xi^3$。该状态由 $s_{i}^{\\mathrm{mix}} = \\mathrm{sgn}(\\xi_{i}^{1} + \\xi_{i}^{2} + \\xi_{i}^{3})$ 给出。我们计算期望重叠 $M_{\\mu,s^{\\mathrm{mix}}}$：\n$$\nM_{\\mu,s^{\\mathrm{mix}}} = \\mathbb{E}[\\xi_{i}^{\\mu} s_{i}^{\\mathrm{mix}}] = \\mathbb{E}[\\xi_{i}^{\\mu} \\, \\mathrm{sgn}(\\xi_{i}^{1} + \\xi_{i}^{2} + \\xi_{i}^{3})]\n$$\n-   如果 $\\mu \\in \\{1, 2, 3\\}$：根据对称性，这三个模式的重叠是相等的。我们来计算 $\\mu=1$ 的情况：\n    $M_{1,s^{\\mathrm{mix}}} = \\mathbb{E}[\\xi_{i}^{1} \\, \\mathrm{sgn}(\\xi_{i}^{1} + \\xi_{i}^{2} + \\xi_{i}^{3})]$。我们对 $(\\xi_i^1, \\xi_i^2, \\xi_i^3) \\in \\{-1,+1\\}^3$ 的 $2^3=8$ 种等可能组合进行平均。\n    -   $(+1,+1,+1)$: 项为 $(+1)\\mathrm{sgn}(3)=+1$\n    -   $(+1,+1,-1)$: 项为 $(+1)\\mathrm{sgn}(1)=+1$\n    -   $(+1,-1,+1)$: 项为 $(+1)\\mathrm{sgn}(1)=+1$\n    -   $(+1,-1,-1)$: 项为 $(+1)\\mathrm{sgn}(-1)=-1$\n    -   $(-1,+1,+1)$: 项为 $(-1)\\mathrm{sgn}(1)=-1$\n    -   $(-1,+1,-1)$: 项为 $(-1)\\mathrm{sgn}(-1)=+1$\n    -   $(-1,-1,+1)$: 项为 $(-1)\\mathrm{sgn}(-1)=+1$\n    -   $(-1,-1,-1)$: 项为 $(-1)\\mathrm{sgn}(-3)=+1$\n    期望是这些值的总和除以 $8$：\n    $M_{1,s^{\\mathrm{mix}}} = \\frac{1}{8}(1+1+1-1-1+1+1+1) = \\frac{4}{8} = \\frac{1}{2}$。\n    根据对称性，$M_{1,s^{\\mathrm{mix}}} = M_{2,s^{\\mathrm{mix}}} = M_{3,s^{\\mathrm{mix}}} = \\frac{1}{2}$。\n\n-   如果 $\\mu \\notin \\{1, 2, 3\\}$：模式 $\\xi^{\\mu}$ 与 $\\xi^1, \\xi^2, \\xi^3$ 独立。\n    $M_{\\mu,s^{\\mathrm{mix}}} = \\mathbb{E}[\\xi_{i}^{\\mu}] \\mathbb{E}[\\mathrm{sgn}(\\xi_{i}^{1} + \\xi_{i}^{2} + \\xi_{i}^{3})]$。\n    由于 $\\mathbb{E}[\\xi_{i}^{\\mu}] = 0$，我们有 $M_{\\mu,s^{\\mathrm{mix}}} = 0$。\n\n现在我们计算重叠的平方和：\n$$\n\\sum_{\\mu=1}^{P} M_{\\mu,s^{\\mathrm{mix}}}^2 = \\sum_{\\mu=1}^{3} M_{\\mu,s^{\\mathrm{mix}}}^2 + \\sum_{\\mu=4}^{P} M_{\\mu,s^{\\mathrm{mix}}}^2 = \\left(\\frac{1}{2}\\right)^2 + \\left(\\frac{1}{2}\\right)^2 + \\left(\\frac{1}{2}\\right)^2 + 0 = 3 \\times \\frac{1}{4} = \\frac{3}{4}\n$$\n混合态的每个神经元能量为：\n$$\n\\lim_{N\\to\\infty}\\frac{1}{N}E(s^{\\mathrm{mix}}) = -\\frac{1}{2}\\left(\\frac{3}{4}\\right) = -\\frac{3}{8}\n$$\n\n3.  **每个神经元的能量差，$\\Delta e$**\n\n最后，我们计算所求的差值：\n$$\n\\Delta e = \\lim_{N\\to\\infty}\\frac{1}{N}\\Big(E(s^{\\mathrm{mix}}) - E(\\xi^{\\mu})\\Big) = \\left(-\\frac{3}{8}\\right) - \\left(-\\frac{1}{2}\\right) = -\\frac{3}{8} + \\frac{4}{8} = \\frac{1}{8}\n$$",
            "answer": "$$\\boxed{\\frac{1}{8}}$$"
        },
        {
            "introduction": "了解静态的能量景观只是故事的一半。要真正理解模式补全，我们必须分析网络状态如何在该景观上演化的“动力学”过程。本练习 () 邀请您从一个被破坏的线索开始，推导模式提取随时间演化的轨迹。通过对网络状态与目标模式之间重叠度的演化进行建模，您将对吸引子网络如何执行其错误校正和记忆补全功能获得定量的理解。",
            "id": "3978314",
            "problem": "考虑一个由 $N$ 个二元神经元（状态为 $s_{i} \\in \\{-1,+1\\}$）组成的全连接 Hopfield 网络，该网络使用标准 Hebb 规则 $w_{ij} = \\frac{1}{N} \\xi_{i} \\xi_{j}$（$i \\neq j$ 且 $w_{ii} = 0$）存储一个单一的二元记忆模式 $\\xi \\in \\{-1,+1\\}^{N}$。网络在异步、零温动力学下演化：在每次基本更新中，均匀随机地选择一个神经元索引 $i$，并根据 $s_{i} \\leftarrow \\operatorname{sgn}\\!\\left(h_{i}\\right)$ 更新其状态，其中 $h_{i} = \\sum_{j=1}^{N} w_{ij} s_{j}$ 是局域场。系统的能量函数由 $E(s) = -\\frac{1}{2} \\sum_{i \\neq j} w_{ij} s_{i} s_{j}$ 给出，并且在这种异步更新下是单调递减的，从而确保收敛到动力学的一个吸引子。\n\n将当前状态 $s$ 与存储模式 $\\xi$ 之间的重叠度 $m$ 定义为 $m = \\frac{1}{N} \\sum_{i=1}^{N} \\xi_{i} s_{i}$。网络的初始状态 $s(0)$ 是通过独立地翻转 $\\xi$ 中恰好 $dN$ 个坐标而构建的，这些坐标是均匀随机选择的，其中 $d \\in [0, \\frac{1}{2})$，因此初始重叠度满足 $m(0) = 1 - 2d$。\n\n假设在大 $N$ 极限下，自耦合效应可以忽略不计，并且局域场满足平均场行为。令 $k$ 表示已应用的异步单神经元更新的总次数，并引入重标度的更新时间 $\\tau = \\frac{k}{N}$（因此 $\\tau$ 是每个神经元的更新次数）。在这些假设下，推导出期望重叠度轨迹 $m(\\tau)$，其形式为关于 $d$ 和 $\\tau$ 的闭式解析表达式。\n\n你的最终答案必须是 $m(\\tau)$ 的单个闭式解析表达式，并且不得包含任何单位。如果你进行了任何近似，请证明其合理性，并明确说明其有效的范围。无需四舍五入。",
            "solution": "该问题是有效的，因为它代表了吸引子神经网络理论中的一个标准的、适定的问题，具体来说是存储单个模式的 Hopfield 网络中模式检索的动力学。该问题具有科学依据、是客观的，并包含了在给定假设下获得唯一解所需的所有信息。我们开始推导。\n\n目标是找到期望重叠度轨迹 $m(\\tau)$，其中 $m$ 是网络状态 $s$ 与存储模式 $\\xi$ 之间的重叠度，$\\tau$ 是重标度的时间。重叠度定义为 $m = \\frac{1}{N} \\sum_{i=1}^{N} \\xi_{i} s_{i}$。\n\n首先，我们分析作用在神经元 $i$ 上的局域场 $h_{i}$。它由 $h_{i} = \\sum_{j=1}^{N} w_{ij} s_{j}$ 给出。使用 Hebb 学习规则 $w_{ij} = \\frac{1}{N} \\xi_{i} \\xi_{j}$（对于 $i \\neq j$）和条件 $w_{ii}=0$，我们有：\n$$h_{i} = \\sum_{j \\neq i} \\left(\\frac{1}{N} \\xi_{i} \\xi_{j}\\right) s_{j} = \\frac{\\xi_{i}}{N} \\sum_{j \\neq i} \\xi_{j} s_{j}$$\n这个和式可以通过包含并减去 $j=i$ 的项来改写：\n$$\\sum_{j \\neq i} \\xi_{j} s_{j} = \\left(\\sum_{j=1}^{N} \\xi_{j} s_{j}\\right) - \\xi_{i} s_{i}$$\n根据定义，$\\sum_{j=1}^{N} \\xi_{j} s_{j} = N m$。因此，\n$$\\sum_{j \\neq i} \\xi_{j} s_{j} = N m - \\xi_{i} s_{i}$$\n将此代回 $h_{i}$ 的表达式：\n$$h_{i} = \\frac{\\xi_{i}}{N} (N m - \\xi_{i} s_{i}) = \\xi_{i} m - \\frac{\\xi_{i}^{2} s_{i}}{N}$$\n由于状态是二元的，$\\xi_{i} \\in \\{-1, +1\\}$，我们有 $\\xi_{i}^{2} = 1$。因此局域场为：\n$$h_{i} = \\xi_{i} m - \\frac{s_{i}}{N}$$\n问题陈述我们应假设大 $N$ 极限，此时自耦合效应可以忽略不计，且平均场行为成立。项 $-\\frac{s_{i}}{N}$ 源于自耦合的缺失（$w_{ii}=0$），并且在 $N \\rightarrow \\infty$ 时变得无穷小。平均场近似意味着局域场主要由序参量 $m$ 所代表的平均活动主导。因此，我们可以将局域场近似为：\n$$h_{i} \\approx \\xi_{i} m$$\n在零温下，神经元 $i$ 的更新规则是 $s_{i} \\leftarrow \\operatorname{sgn}(h_{i})$。使用近似的场，新状态 $s'_{i}$ 为：\n$$s'_{i} = \\operatorname{sgn}(\\xi_{i} m) = \\xi_{i} \\operatorname{sgn}(m)$$\n初始状态是通过翻转 $\\xi$ 的 $dN$ 个位来准备的，其中 $d \\in [0, \\frac{1}{2})$。初始重叠度为 $m(0) = 1 - 2d$，这是一个严格的正数。由 $s'_{i}$ 的方程描述的动力学将导致未对齐的神经元与模式 $\\xi$ 对齐，从而增加重叠度 $m$。因此，我们可以预期对于所有 $\\tau \\geq 0$，$m(\\tau)$ 都保持为正，这意味着 $\\operatorname{sgn}(m) = +1$。更新规则简化为：\n$$s'_{i} = \\xi_{i}$$\n这意味着如果选择一个神经元 $i$ 进行更新，它的状态将被设置为 $\\xi_{i}$，而不管其先前的状态如何。如果神经元已经对齐（$s_i = \\xi_i$），其状态不变。如果它未对齐（$s_i = -\\xi_i$），它会翻转以变得对齐。\n\n现在我们可以推导重叠度 $m(\\tau)$ 演化的微分方程。重标度时间 $\\tau = k/N$ 意味着在微小时间间隔 $d\\tau$ 内，会发生 $dk = N d\\tau$ 次单神经元更新。\n令 $N_{-}$ 为未对齐神经元的数量，其中 $s_{i} = -\\xi_{i}$。重叠度 $m$ 可以用 $N_{-}$ 表示：\n$$m = \\frac{1}{N} \\sum_{i} \\xi_{i} s_{i} = \\frac{1}{N} \\left( (N - N_{-})(+1) + N_{-}(-1) \\right) = \\frac{N - 2N_{-}}{N} = 1 - \\frac{2N_{-}}{N}$$\n为了找到 $m$ 的变化量 $dm$，我们可以找到 $N_{-}$ 的变化量 $dN_{-}$。在每一步更新中，从 $N$ 个神经元中均匀随机地选择一个神经元。\n未对齐的神经元数量为 $N_{-}$，已对齐的神经元数量为 $N_{+} = N - N_{-}$。\n只有当一个未对齐的神经元被选中并更新时，$N_{-}$ 才会减少。发生这种情况的概率是 $p(\\text{选择未对齐}) = \\frac{N_{-}}{N}$。\n当一个未对齐的神经元被更新时，它变得对齐，所以 $N_{-}$ 减少 1。\n每单次更新步骤中 $N_{-}$ 的期望变化是：\n$$E[\\Delta N_{-}] = \\frac{N_{-}}{N} \\times (-1) + \\frac{N - N_{-}}{N} \\times (0) = -\\frac{N_{-}}{N}$$\n$N_{-}$ 相对于更新次数 $k$ 的变化率是 $\\frac{dN_{-}}{dk} = -\\frac{N_{-}}{N}$。\n我们将自变量从 $k$ 更改为重标度时间 $\\tau = k/N$，因此 $\\frac{dk}{d\\tau} = N$。使用链式法则：\n$$\\frac{dN_{-}}{d\\tau} = \\frac{dN_{-}}{dk} \\frac{dk}{d\\tau} = \\left(-\\frac{N_{-}}{N}\\right) N = -N_{-}$$\n我们得到了一个关于未对齐神经元数量的微分方程：$\\frac{dN_{-}}{d\\tau} = -N_{-}$。\n我们可以将其转换为一个关于 $m(\\tau)$ 的方程。从 $m = 1 - \\frac{2N_{-}}{N}$，我们得到 $N_{-} = \\frac{N(1-m)}{2}$。对 $\\tau$ 求导：\n$$\\frac{dN_{-}}{d\\tau} = \\frac{d}{d\\tau}\\left(\\frac{N(1-m)}{2}\\right) = -\\frac{N}{2} \\frac{dm}{d\\tau}$$\n将此代入 $N_{-}$ 的微分方程中：\n$$-\\frac{N}{2} \\frac{dm}{d\\tau} = -N_{-} = -\\frac{N(1-m)}{2}$$\n简化后，我们得到重叠度 $m(\\tau)$ 的微分方程：\n$$\\frac{dm}{d\\tau} = 1-m$$\n这是一个一阶线性常微分方程。我们通过分离变量法来求解它：\n$$\\frac{dm}{1-m} = d\\tau$$\n对两边从时间 $0$ 到 $\\tau$ 积分：\n$$\\int_{m(0)}^{m(\\tau)} \\frac{dm'}{1-m'} = \\int_{0}^{\\tau} d\\tau'$$\n$$[-\\ln(1-m')]_{m(0)}^{m(\\tau)} = [\\tau']_{0}^{\\tau}$$\n$$-\\ln(1-m(\\tau)) + \\ln(1-m(0)) = \\tau$$\n$$\\ln\\left(\\frac{1-m(0)}{1-m(\\tau)}\\right) = \\tau$$\n对两边取指数：\n$$\\frac{1-m(0)}{1-m(\\tau)} = \\exp(\\tau)$$\n$$1-m(\\tau) = (1-m(0))\\exp(-\\tau)$$\n$$m(\\tau) = 1 - (1-m(0))\\exp(-\\tau)$$\n问题给出了初始重叠度 $m(0) = 1 - 2d$。将其代入解中：\n$$m(\\tau) = 1 - (1 - (1-2d))\\exp(-\\tau) = 1 - (2d)\\exp(-\\tau)$$\n这就是期望重叠度轨迹的闭式解析表达式。它表明，重叠度从 $m(0) = 1-2d$ 开始，并随着 $\\tau \\to \\infty$ 指数增长到完全检索的模式状态 $m=1$。",
            "answer": "$$\n\\boxed{1 - 2d \\exp(-\\tau)}\n$$"
        },
        {
            "introduction": "我们许多的分析性见解，例如前面练习中得出的结论，都依赖于平均场理论和热力学极限 ($N \\to \\infty$) 的假设。但是，这些近似对于真实的、有限大小的网络究竟有多准确？这项计算实践 () 让您能够直接回答这个问题，它将平均场理论的预测与一个小型网络的确切统计行为进行比较。通过亲手实现这两种方法并量化它们之间的误差，您将为这些计算神经科学的基础理论工具的有效性和局限性建立起至关重要的直觉。",
            "id": "3978320",
            "problem": "您将研究一个具有对称突触权重的全连接二元霍普菲尔德网络，并检验在一个小型网络中，朴素平均场近似与基于吉布斯平稳分布的精确期望值相比表现如何。您的目标是量化在估计模式重叠度和期望能量方面的近似误差。\n\n基本原理：\n- 一个具有二元自旋的霍普菲尔德网络，其状态为 $s \\in \\{-1,+1\\}^N$，拥有对称权重矩阵 $W \\in \\mathbb{R}^{N \\times N}$ 且 $W_{ii} = 0$，以及外部场（偏置）$h \\in \\mathbb{R}^N$。\n- 网络在状态 $s$ 下的能量为 $E(s) = -\\frac{1}{2} s^\\top W s - h^\\top s$。\n- 在逆温度 $\\beta  0$ 下的玻尔兹曼分布为 $p(s) = Z^{-1} \\exp\\{-\\beta E(s)\\}$，其中 $Z$ 是配分函数。\n- 吉布斯采样是一种马尔可夫链蒙特卡洛 (MCMC) 方法，对于上述伊辛能量，其唯一的平稳分布是玻尔兹曼分布。在吉布斯平稳分布下的精确期望值是相对于 $p(s)$ 计算的。\n\n本任务所需的定义：\n- 存储的模式 $\\{\\xi^\\mu\\}_{\\mu=1}^P$（其中 $\\xi^\\mu \\in \\{-1,+1\\}^N$）通过赫布权重进行编码：当 $i \\neq j$ 时，$W_{ij} = \\frac{1}{N} \\sum_{\\mu=1}^P \\xi_i^\\mu \\xi_j^\\mu$，且 $W_{ii} = 0$。\n- 在分布 $p$ 下，模式 $\\mu$ 的模式重叠度为 $m^\\mu = \\frac{1}{N} \\sum_{i=1}^N \\xi_i^\\mu \\langle s_i \\rangle_p$，其中 $\\langle \\cdot \\rangle_p$ 表示在 $p$ 分布下的期望值。\n- 朴素平均场近似假设一个可分解的分布 $q(s) = \\prod_{i=1}^N q_i(s_i)$，其均值为 $m_i = \\mathbb{E}_q[s_i]$，并导出不动点方程 $m_i = \\tanh\\left(\\beta \\left(\\sum_{j=1}^N W_{ij} m_j + h_i\\right)\\right)$。\n- 期望能量的平均场近似为 $\\langle E \\rangle_{\\text{MF}} = -\\frac{1}{2} m^\\top W m - h^\\top m$，其中 $m = (m_1,\\dots,m_N)^\\top$。\n\n您需要：\n1. 对每个测试用例，使用指定的随机种子构建 $P$ 个随机模式 $\\{\\xi^\\mu\\}$，其中 $\\xi_i^\\mu \\in \\{-1,+1\\}$。构建赫布权重矩阵 $W$。使用外部场 $h = \\gamma \\, \\xi^1$ 为第一个模式提供一个弱检索提示，这将引发非零重叠度并测试模式补全能力。\n2. 通过枚举所有 $2^N$ 个状态来计算吉布斯平稳分布下的精确期望值，以获得：\n   - 精确的平均自旋 $\\langle s \\rangle_p \\in \\mathbb{R}^N$，从而得到精确的重叠度 $m^\\mu_{\\text{exact}} = \\frac{1}{N} \\sum_{i=1}^N \\xi_i^\\mu \\langle s_i \\rangle_p$，对于 $\\mu = 1,\\dots,P$。\n   - 精确的期望能量 $\\langle E \\rangle_{\\text{exact}} = \\sum_{s} p(s) E(s)$。\n3. 通过迭代平均场方程直到收敛，计算朴素平均场不动点 $m$。然后评估：\n   - 平均场重叠度 $m^\\mu_{\\text{MF}} = \\frac{1}{N} \\sum_{i=1}^N \\xi_i^\\mu m_i$，对于 $\\mu = 1,\\dots,P$。\n   - 平均场期望能量近似 $\\langle E \\rangle_{\\text{MF}} = -\\frac{1}{2} m^\\top W m - h^\\top m$。\n4. 每个测试用例报告两个误差：\n   - 跨模式的均方根重叠误差，$\\mathrm{RMSE}_m = \\sqrt{\\frac{1}{P} \\sum_{\\mu=1}^P \\left(m^\\mu_{\\text{MF}} - m^\\mu_{\\text{exact}}\\right)^2}$。\n   - 绝对能量误差，$\\mathrm{AE}_E = \\left|\\langle E \\rangle_{\\text{MF}} - \\langle E \\rangle_{\\text{exact}}\\right|$。\n5. 将所有测试用例的所有结果打印在单行中，形式为方括号括起来的逗号分隔列表。对于每个测试用例，依次附加 $\\mathrm{RMSE}_m$ 和 $\\mathrm{AE}_E$。每个值必须四舍五入到 $6$ 位小数。\n\n角度单位不适用。没有物理单位。\n\n测试套件：\n- 案例 A（正常路径，中等负载和温度）：$N = 10$，$P = 2$，$\\beta = 1.2$，$\\gamma = 0.2$，种子 $= 123$。\n- 案例 B（边界，近顺磁区）：$N = 8$，$P = 2$，$\\beta = 0.5$，$\\gamma = 0.05$，种子 $= 456$。\n- 案例 C（边缘，低温下有多个吸引子）：$N = 12$，$P = 3$，$\\beta = 2.0$，$\\gamma = 0.1$，种子 $= 789$。\n\n您的程序应产生单行输出，其中包含一个方括号括起来的逗号分隔列表形式的结果（例如，“[x1,x2,x3,x4,x5,x6]”），条目顺序为 $[\\mathrm{RMSE}_m^{\\text{A}}, \\mathrm{AE}_E^{\\text{A}}, \\mathrm{RMSE}_m^{\\text{B}}, \\mathrm{AE}_E^{\\text{B}}, \\mathrm{RMSE}_m^{\\text{C}}, \\mathrm{AE}_E^{\\text{C}}]$。将每个数值四舍五入到 $6$ 位小数。",
            "solution": "该问题是有效的，因为它科学地基于统计力学和计算神经科学的既定原理，特别是关于联想记忆的霍普菲尔德模型。问题阐述清晰，为获得唯一可计算的解提供了所有必要的参数和定义。对于一个小型网络，比较精确的吉布斯分布和朴素平均场近似是一个标准且有启发性的练习。所涉及的计算任务，包括枚举多达 $2^{12}$ 个状态，是完全可行的。\n\n我们首先正式定义系统和待计算的量。网络的状态是一个自旋向量 $s \\in \\{-1, +1\\}^N$，其中 $N$ 是神经元的数量。一个状态 $s$ 的能量由哈密顿量给出：\n$$\nE(s) = -\\frac{1}{2} \\sum_{i=1}^N \\sum_{j=1}^N W_{ij} s_i s_j - \\sum_{i=1}^N h_i s_i = -\\frac{1}{2} s^\\top W s - h^\\top s\n$$\n这里，$W$ 是一个对角线为零的对称突触权重矩阵（$W_{ij} = W_{ji}$ 且 $W_{ii} = 0$），$h$ 是一个外部场向量。权重由一组 $P$ 个存储的模式 $\\{\\xi^\\mu\\}_{\\mu=1}^P$（其中 $\\xi^\\mu \\in \\{-1, +1\\}^N$）通过赫布学习规则构建：\n$$\nW_{ij} = \\frac{1}{N} \\sum_{\\mu=1}^P \\xi_i^\\mu \\xi_j^\\mu \\quad \\text{for } i \\neq j\n$$\n外部场被设置为 $h = \\gamma \\xi^1$，为第一个模式提供一个强度为 $\\gamma$ 的检索提示。\n\n这个问题的核心是比较网络在逆温度 $\\beta$ 下统计行为的两种不同表征。\n\n首先，我们考虑通过吉布斯-玻尔兹曼分布进行的精确表征。在热平衡状态下，网络处于状态 $s$ 的概率由以下公式给出：\n$$\np(s) = \\frac{1}{Z} \\exp(-\\beta E(s))\n$$\n其中 $Z = \\sum_s \\exp(-\\beta E(s))$ 是配分函数，求和遍及所有 $2^N$ 个可能的状态。由于给定测试用例中的 $N$ 很小（最大为 $N=12$），我们可以通过直接枚举来计算所有状态的 $Z$ 和 $p(s)$。\n\n任何可观测量 $O(s)$ 的精确期望值则为 $\\langle O \\rangle_p = \\sum_s O(s) p(s)$。我们对两个特定的期望值感兴趣：\n1.  精确的平均自旋向量 $\\langle s \\rangle_p$，其分量为 $\\langle s_i \\rangle_p = \\sum_s s_i p(s)$。\n2.  精确的期望能量 $\\langle E \\rangle_{\\text{exact}} = \\sum_s E(s) p(s)$。\n\n从平均自旋向量，我们可以计算网络平均状态与每个存储模式 $\\xi^\\mu$ 的精确重叠度：\n$$\nm^\\mu_{\\text{exact}} = \\frac{1}{N} \\sum_{i=1}^N \\xi_i^\\mu \\langle s_i \\rangle_p\n$$\n\n其次，我们考虑朴素平均场近似。这种近似通过假设状态的概率分布在各个自旋上是可分解的来简化问题：$q(s) = \\prod_{i=1}^N q_i(s_i)$。这个关键假设忽略了自旋之间的相关性（对于 $i \\neq j$ 有 $\\langle s_i s_j \\rangle_q = \\langle s_i \\rangle_q \\langle s_j \\rangle_q$）。这导致了一组关于平均磁化强度 $m_i = \\mathbb{E}_q[s_i]$ 的自洽方程：\n$$\nm_i = \\tanh\\left(\\beta \\left(\\sum_{j=1}^N W_{ij} m_j + h_i\\right)\\right) \\quad \\text{for } i = 1, \\dots, N\n$$\n这个方程组可以通过为向量 $m = (m_1, \\dots, m_N)^\\top$ 设置一个初始猜测值，并迭代更新规则直到向量 $m$ 收敛到一个不动点来数值求解。\n\n一旦找到不动点磁化向量 $m$，我们就可以计算相应的平均场近似值：\n1.  平均场重叠度：\n$$\nm^\\mu_{\\text{MF}} = \\frac{1}{N} \\sum_{i=1}^N \\xi_i^\\mu m_i\n$$\n2.  期望能量的平均场近似。这是能量函数 $E(s)$ 在可分解分布 $q(s)$ 下的期望值，在 $W_{ii}=0$ 的条件下，其值为：\n$$\n\\langle E \\rangle_{\\text{MF}} = -\\frac{1}{2} m^\\top W m - h^\\top m\n$$\n\n最后，我们通过计算每个测试用例的两个指标来量化平均场近似的误差：\n1.  所有 $P$ 个模式的重叠度的均方根误差 (RMSE)：\n$$\n\\mathrm{RMSE}_m = \\sqrt{\\frac{1}{P} \\sum_{\\mu=1}^P \\left(m^\\mu_{\\text{MF}} - m^\\mu_{\\text{exact}}\\right)^2}\n$$\n2.  期望能量的绝对误差 (AE)：\n$$\n\\mathrm{AE}_E = \\left|\\langle E \\rangle_{\\text{MF}} - \\langle E \\rangle_{\\text{exact}}\\right|\n$$\n\n每个测试用例的计算步骤如下：\n1.  使用指定的种子初始化随机数生成器，并生成 $P$ 个随机模式 $\\{\\xi^\\mu\\}$。\n2.  构建权重矩阵 $W$ 和外部场向量 $h$。\n3.  执行精确计算：\n    a. 生成所有 $2^N$ 个自旋状态。\n    b. 对每个状态 $s$，计算其能量 $E(s)$。\n    c. 使用这些能量计算概率 $p(s)$，注意在指数化之前减去最小能量以保持数值稳定性。\n    d. 通过对所有状态按其概率加权求和，计算精确期望值 $\\langle s \\rangle_p$ 和 $\\langle E \\rangle_{\\text{exact}}$。\n    e. 计算精确重叠度 $m^\\mu_{\\text{exact}}$。\n4.  执行平均场计算：\n    a. 初始化磁化向量 $m$，例如，初始化为零向量。\n    b. 迭代应用平均场更新方程 $m \\leftarrow \\tanh(\\beta(Wm + h))$，直到两次迭代之间 $m$ 的变化可以忽略不计。\n    c. 使用收敛的 $m$ 计算平均场重叠度 $m^\\mu_{\\text{MF}}$ 和能量 $\\langle E \\rangle_{\\text{MF}}$。\n5.  计算并存储误差指标 $\\mathrm{RMSE}_m$ 和 $\\mathrm{AE}_E$。\n对所有三个测试用例重复此过程，并按规定报告结果。",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the problem for all test cases, comparing naive mean-field theory\n    to exact solutions for a Hopfield network.\n    \"\"\"\n    test_cases = [\n        # (N, P, beta, gamma, seed)\n        (10, 2, 1.2, 0.2, 123),  # Case A\n        (8, 2, 0.5, 0.05, 456),   # Case B\n        (12, 3, 2.0, 0.1, 789),  # Case C\n    ]\n\n    results = []\n    for N, P, beta, gamma, seed in test_cases:\n        rmse_m, ae_e = process_case(N, P, beta, gamma, seed)\n        results.extend([rmse_m, ae_e])\n\n    print(\"[\" + \",\".join(f\"{val:.6f}\" for val in results) + \"]\")\n\ndef process_case(N, P, beta, gamma, seed):\n    \"\"\"\n    Processes a single test case to compute and return the required error metrics.\n    \"\"\"\n    # 1. System Setup\n    rng = np.random.default_rng(seed)\n    patterns = rng.choice([-1, 1], size=(P, N))\n    \n    W = (patterns.T @ patterns) / N\n    np.fill_diagonal(W, 0)\n    \n    h = gamma * patterns[0]\n\n    # 2. Exact Calculation via State Enumeration\n    num_states = 1  N\n    states = (((np.arange(num_states)[:, None] >> np.arange(N))  1) * 2 - 1).astype(np.int8)\n\n    s_T_W_s = np.sum((states @ W) * states, axis=1)\n    h_T_s = states @ h\n    energies = -0.5 * s_T_W_s - h_T_s\n    \n    # Numerically stable calculation of probabilities\n    min_energy = np.min(energies)\n    log_probs = -beta * (energies - min_energy)\n    unnormalized_probs = np.exp(log_probs - np.max(log_probs))\n    probs = unnormalized_probs / np.sum(unnormalized_probs)\n\n    exact_mean_s = np.sum(states * probs[:, None], axis=0)\n    exact_expected_E = np.sum(probs * energies)\n    exact_overlaps = (patterns @ exact_mean_s) / N\n\n    # 3. Naive Mean-Field Calculation\n    m = np.zeros(N)\n    for _ in range(1000):\n        m_old = m.copy()\n        field_at_m = W @ m + h\n        m = np.tanh(beta * field_at_m)\n        if np.linalg.norm(m - m_old)  1e-9:\n            break\n            \n    mf_overlaps = (patterns @ m) / N\n    mf_expected_E = -0.5 * m.T @ W @ m - h.T @ m\n\n    # 4. Report Errors\n    rmse_m = np.sqrt(np.mean((mf_overlaps - exact_overlaps)**2))\n    ae_e = np.abs(mf_expected_E - exact_expected_E)\n\n    return rmse_m, ae_e\n\nif __name__ == '__main__':\n    solve()\n```"
        }
    ]
}