## 引言
“共同发放的神经元连接在一起”，这一由 [Donald Hebb](@entry_id:1123912) 在1949年提出的深刻见解，构成了我们理解大脑学习与记忆的基石。赫布学习（Hebbian Learning）为经验如何塑造神经连接强度提供了一个优雅的原则性框架。然而，将这一直观概念转化为数学模型时，我们很快会遇到一个核心挑战：其最简单的形式存在固有的不稳定性，会导致突触权重失控增长，这在生物学上是不现实的，也无法形成稳定的功能。本文旨在系统性地梳理赫布学习在基于发放率的[计算模型](@entry_id:637456)中的理论发展，并展示其在现代神经科学和人工智能中的广泛应用。

在接下来的内容中，我们将踏上一段从基本原理到复杂应用的探索之旅。首先，在**“原理与机制”**一章中，我们将深入剖析赫布学习的数学形式，揭示其不稳定性根源，并详细介绍多种关键的稳定化机制，如奥哈法则、[BCM理论](@entry_id:177448)和三因子规则，它们赋予了赫布学习强大的计算能力。接着，在**“应用与跨学科联系”**一章，我们将探讨这些理论如何具体应用于无监督[特征提取](@entry_id:164394)、记忆的吸引子网络模型以及大脑系统（如[空间导航](@entry_id:173666)）的自组织过程，并揭示其与人工智能、物理学等领域的深刻联系。最后，通过**“动手实践”**部分，你将有机会通过具体的数学推导，加深对这些核心概念的理解。

## 原理与机制

本章深入探讨赫布学习（Hebbian Learning）的核心原理及其在基于发放率的神经元模型中的各种数学表述。我们将从其最基础的形式出发，揭示其内在的不稳定性，并逐步介绍为解决此问题而发展的多种稳定化机制。这些机制不仅确保了学习过程的稳定，还赋予了神经元和神经网络提取输入数据中有效特征的强大计算能力。我们还将探讨赫布原理如何扩展到多神经元网络，以及如何通过引入第三因子信号来整合上下文与学习过程。

### 赫布突触的基本形式

现代[计算神经科学](@entry_id:274500)的基石之一是加拿大心理学家 [Donald Hebb](@entry_id:1123912) 在 1949 年提出的著名假设。其核心思想常被精炼地概括为“共同发放的神经元连接在一起”（Neurons that fire together, wire together）。这一假设为大脑中基于经验的突触连接强度变化（即突触可塑性）提供了一个简洁而深刻的原理。

在基于发放率（rate-based）的神经元模型中，我们可以将这一直观的原理转化为一个精确的数学表达式。考虑一个突触，其突触前神经元的瞬时发放率为 $x_j(t)$，突触后神经元的发放率为 $y(t)$。赫布假设表明，该突触权重 $w_j(t)$ 的变化率应与突触前后的活动同时性成正比。最直接的数学表述就是将这两种活动率相乘。因此，我们可以定义基本的**[赫布学习](@entry_id:156080)规则** ：

$$
\frac{dw_j}{dt} = \dot{w}_j(t) = \eta \, y(t) \, x_j(t)
$$

其中，$\eta$ 是一个小的正常数，称为**学习率**（learning rate），它决定了突触权重变化的整体速度。这个公式体现了几个关键的计算原则：

1.  **关联性（Associativity）**：权重的变化依赖于突触前和突触后活动的乘积。只有当两者都显著大于零时，才会发生强烈的权重增强（即[长时程增强](@entry_id:139004)，Long-Term Potentiation, LTP）。如果任意一方不活动（发放率为零），则权重不发生变化。
2.  **局部性（Locality）**：突触 $j$ 的权重变化仅依赖于局部可用的信息：突触前信号 $x_j(t)$、突触后信号 $y(t)$ 和权重自身 $w_j(t)$（尽管在此基本形式中未显式依赖）。它不需要关于网络中其他神经元活动或[全局误差](@entry_id:147874)信号的信息。
3.  **[输入特异性](@entry_id:166531)（Input Specificity）**：权重 $w_j$ 的变化仅与输入 $x_j$ 相关，而与其他输入 $x_k$（其中 $k \neq j$）无关。

这个简洁的乘积形式构成了后续更复杂学习规则的基础，并为我们理解神经系统如何从经验中学习提供了第一个数学切入点。

### 纯赫布学习的内在不稳定性

尽管赫布规则在概念上极具吸[引力](@entry_id:189550)，但其最简单的形式存在一个致命的缺陷：内在的**不稳定性**。当一个神经元持续暴露在具有统计规律的输入下时，纯[赫布学习](@entry_id:156080)会导致其突触权重无限制地增长，最终达到饱和或超出生物学上的合理范围。

为了清晰地揭示这一问题，我们考虑一个简单的线性神经元，其输出是其输入的加权和：$y(t) = \mathbf{w}(t)^{\top}\mathbf{x}(t)$。这里，$\mathbf{w}(t)$ 是权重向量，$\mathbf{x}(t)$ 是输入向量。我们将赫布规则应用于整个权重向量：

$$
\frac{d\mathbf{w}}{dt} = \eta \, y(t) \, \mathbf{x}(t)
$$

由于权重 $\mathbf{w}(t)$ 的变化通常比神经元发放率 $y(t)$ 和 $x(t)$ 的波动慢得多（[时间尺度分离](@entry_id:149780)假设），我们可以通过对快时间尺度上的活动进行平均来分析权重的慢速演化。权重的平均变化方向由 $\langle y(t) \mathbf{x}(t) \rangle$ 决定，其中 $\langle \cdot \rangle$ 表示时间平均。

$$
\frac{d\mathbf{w}}{dt} = \eta \langle y(t) \mathbf{x}(t) \rangle = \eta \langle (\mathbf{w}^{\top}\mathbf{x}(t)) \mathbf{x}(t) \rangle
$$

由于 $\mathbf{w}$ 在快时间尺度上可被视为常数，我们可以将其提出平均运算：

$$
\frac{d\mathbf{w}}{dt} = \eta \langle \mathbf{x}(t)\mathbf{x}(t)^{\top} \rangle \mathbf{w} = \eta \, \mathbf{C} \, \mathbf{w}
$$

这里，$\mathbf{C} = \langle \mathbf{x}(t)\mathbf{x}(t)^{\top} \rangle$ 是输入信号的**[协方差矩阵](@entry_id:139155)**（对于零均值输入而言）。这个[线性微分方程](@entry_id:150365)系统描述了权重向量的演化。其解的性质由矩阵 $\mathbf{C}$ 的特征值和[特征向量](@entry_id:151813)决定。

分析表明，权重向量 $\mathbf{w}(t)$ 会沿着 $\mathbf{C}$ 的[特征向量](@entry_id:151813)方向呈指数增长 。具体来说，如果 $\mathbf{w}(0)$ 在 $\mathbf{C}$ 的某个[特征向量](@entry_id:151813) $\mathbf{v}_k$上有投影，那么该分量的增长速度为 $\exp(\eta \lambda_k t)$，其中 $\lambda_k$ 是对应的特征值。由于[协方差矩阵](@entry_id:139155)的特征值代表了输入数据在相应[特征向量](@entry_id:151813)方向上的方差，这意味着权重会沿着输入方差最大的方向（即主成分方向）发生爆炸式增长。

这种无限制的增长形成了一个**正反馈循环**：一个强大的突触使得神经元更容易发放，而这种发放反过来又通过赫布规则进一步增强了这个突触。这个失控的过程不仅在生物学上不现实，也使得神经元无法稳定地学习和表征输入特征。因此，任何实用的赫布学习系统都必须引入额外的机制来约束权重的增长。

### 稳定与选择性：赫布规则的修正

为了克服纯[赫布学习](@entry_id:156080)的不稳定性并使其具备有用的计算功能，研究者们提出了一系列修正和扩展。这些修正的核心思想是引入某种形式的负反馈或约束，以防止权重无限制增长。

#### 相关性与协方差：中心化的作用

赫布规则的基本形式 $\dot{w}_j = \eta y x_j$ 是基于活动之间的**相关性**（correlation）的。然而，神经元的平均发放率可能不为零。在这种情况下，即使两个神经元的活动波动完全不相关，它们仅因为各自具有较高的基线发放率，就会导致突触权重持续增长。

一个重要的改进是使学习规则对活动的**协方差**（covariance）敏感，即关注信号的波动部分之间的关联，而非其绝对值。这可以通过从信号中减去其时间平均值来实现，这个过程称为**中心化**（centering）。

如果我们用中心化的信号 $\tilde{x}_j(t) = x_j(t) - \mathbb{E}[x_j]$ 和 $\tilde{y}(t) = y(t) - \mathbb{E}[y]$ 来代替原始信号，学习规则变为：

$$
\dot{w}_j = \eta \, \tilde{y}(t) \, \tilde{x}_j(t) = \eta (y(t) - \mathbb{E}[y])(x_j(t) - \mathbb{E}[x_j])
$$

对该规则取期望，我们发现平均权重变化正比于 $y$ 和 $x_j$ 之间的协方差，$\mathbb{E}[\dot{w}_j] = \eta \, \text{Cov}(y, x_j)$。相比之下，原始的相关性规则的期望变化包含一个偏置项：$\mathbb{E}[\dot{w}_j] = \eta (\text{Cov}(y, x_j) + \mathbb{E}[y]\mathbb{E}[x_j])$ 。当平均发放率不为零时，这个偏置项会导致不希望的权重漂移。因此，基于协方差的规则通常能更精确地捕捉输入信号中富有信息的结构。

#### 局部衰减与归一化：奥哈规则

芬兰科学家 Erkki Oja 提出了一个优雅的局部解决方案来解决权重增长问题。**奥哈规则**（Oja's Rule）在标准的赫布项之外，增加了一个与权重自身成比例的[非线性](@entry_id:637147)“遗忘”或衰减项 ：

$$
\dot{\mathbf{w}} = \eta (y \mathbf{x} - y^2 \mathbf{w})
$$

这里的 $y^2$ 项是关键。当突触后活动 $y$ 增加时，衰减项的强度会以更快的速度（平方）增长。这个衰减项可以被解释为对权重向量 $\mathbf{w}$ 施加的一个约束，使其[L2范数](@entry_id:172687)（即[向量长度](@entry_id:156432) $\| \mathbf{w} \|$）趋向于一个稳定值。通过分析权重范数的平方 $\| \mathbf{w} \|^2$ 的动态，可以证明其会稳定在 1 附近。

奥哈规则不仅解决了稳定性的问题，还赋予了神经元一个重要的计算功能：它能使权重向量 $\mathbf{w}$ 收敛到输入[数据协方差](@entry_id:748192)矩阵的**第一主成分**（Principal Component）方向。这意味着，经过学习，神经元会对输入中方差最大的特征方向产生最强的响应。因此，奥哈规则是实现[主成分分析](@entry_id:145395)（PCA）的一种在线、神经元式的算法。

#### 全局[稳态](@entry_id:139253)缩放

另一种稳定化机制源于生物学观察到的**[突触缩放](@entry_id:174471)**（synaptic scaling）。这是一种[稳态可塑性](@entry_id:151193)（homeostatic plasticity），它通过乘法调节一个神经元上的所有突触，以保持其平均发放率在一个预设的目标范围内。

在模型中，我们可以将赫布学习与[突触缩放](@entry_id:174471)结合起来 。赫布项负责学习输入特征的“方向”（例如，将权重向量对齐到主成分方向），而[突触缩放](@entry_id:174471)则负责调节权重的整体“幅度”，以确保突触后发放率的统计特性（如二阶矩 $\mathbb{E}[y^2]$）维持在一个目标值 $\rho_0^2$。例如，如果一个神经元的权重向量在奥哈规则的作用下对齐到了主成分方向 $\mathbf{u}_1$（对应特征值为 $\lambda_1$），那么其权重可以表示为 $\mathbf{w} = a \mathbf{u}_1$。[突触缩放](@entry_id:174471)机制会[调节幅度](@entry_id:923420) $a$，使得 $\mathbb{E}[y^2] = a^2 \lambda_1 = \rho_0^2$，从而得到稳定的权重幅度 $a = \rho_0 / \sqrt{\lambda_1}$。这种机制将[特征学习](@entry_id:749268)和活动稳定这两个过程[解耦](@entry_id:160890)开来。

#### 双向可塑性与元可塑性：BCM 规则

经典的赫布规则只描述了[突触增强](@entry_id:171314)（LTP）。然而，生物突触同样表现出[长时程抑制](@entry_id:154883)（Long-Term Depression, LTD）。**BCM 规则**（以其提出者 Bienenstock, Cooper 和 Munro 命名）是一个里程碑式的模型，它通过引入一个动态的修改阈值，优雅地统一了 LTP 和 LTD 。

BCM 规则的形式如下：

$$
\dot{w}_j = \eta \, y (y - \theta_M) \, x_j
$$

这里的关键是**修改阈值** $\theta_M$。当突触后活动 $y$ 高于阈值 $\theta_M$ 时，$(y - \theta_M)$ 项为正，[突触发生](@entry_id:168859) LTP。当 $y$ 低于 $\theta_M$（但大于零）时，该项为负，[突触发生](@entry_id:168859) LTD。

BCM 规则最精妙之处在于 $\theta_M$ 本身不是一个固定的常数，而是一个**滑动阈值**。它会根据突触后活动的近期历史进行缓慢的调整，通常与 $y$ 的超线性函数（如 $\mathbb{E}[y^2]$）成正比。这种阈值的动态变化被称为**元可塑性**（metaplasticity），即可塑性自身的可塑性。

这种机制引入了一个[稳态](@entry_id:139253)的负反馈：如果神经元由于权重增强而变得过度活跃，其平均活动会增加，从而推高阈值 $\theta_M$。更高的阈值使得 LTP 更难发生，而 LTD 更容易发生，这会反过来降低神经元的活动，使其恢复到正常水平。BCM 规则不仅确保了稳定性，还促进了神经元选择性的发展，使其能够对特定的输入模式产生稀疏而高效的响应。

### 网络功能与上下文调制

上述规则主要关注单个神经元的学习。然而，大脑的计算是在庞大的神经网络中完成的。赫布原理可以被扩展和应用到网络层面，以实现更复杂的计算功能，如同将学习过程与外部的上下文信息相结合。

#### 学习多个特征：桑格规则

单个奥哈神经元只能学习输入数据的第一个主成分。如何让一个网络学习多个（理想情况下是正交的）特征呢？**桑格规则**（Sanger's Rule），也称为广义赫布算法（Generalized Hebbian Algorithm, GHA），提供了一个解决方案 。

对于一个有多层输出神经元的网络，桑格规则对第 $i$ 个神经元的权重 $\mathbf{w}_i$ 的更新规则如下：

$$
\dot{\mathbf{w}}_i = \eta \, y_i \left( \mathbf{x} - \sum_{j \le i} y_j \mathbf{w}_j \right)
$$

这个规则可以被分解理解：
*   **赫布项**：$\eta y_i \mathbf{x}$，驱动权重学习输入-输出相关性。
*   **奥哈式[自归一化](@entry_id:636594)项**：当 $j=i$ 时，产生 $-\eta y_i^2 \mathbf{w}_i$，稳定了 $\mathbf{w}_i$ 的范数。
*   **[正交化](@entry_id:149208)项**：对于 $j  i$ 的项，$-\eta y_i \sum_{j  i} y_j \mathbf{w}_j$，起到了一个“减法”的作用。它从当前输入信号 $\mathbf{x}$ 中“剔除”已经被前面 $i-1$ 个神经元所编码的特征。这个过程类似于 Gram-Schmidt [正交化](@entry_id:149208)。

其结果是，网络中的神经元会按顺序学习输入数据的前 $k$ 个主成分。$\mathbf{w}_1$ 收敛到第一主成分，$\mathbf{w}_2$ 收敛到与 $\mathbf{w}_1$ 正交的第二主成分，以此类推。这使得网络能够构建一个输入数据的低维、正交表示。

#### 竞争与去相关：反赫布学习

与赫布学习“合作”原则相对的是**反赫布学习**（Anti-Hebbian Learning）的“竞争”原则 。其基本形式是简单地在赫布规则前加一个负号：

$$
\dot{\mathbf{w}} = -\eta \, y \, \mathbf{x}
$$

当应用于单个前馈神经元时，这个规则会最小化输出的方差，使权重向量对齐到输入协方差矩阵的**最小主成分**方向。然而，它更常见的应用是在网络的侧向或反馈连接中。

考虑一个网络中的两个神经元 $i$ 和 $j$，它们之间有抑制性连接 $v_{ij}$。如果这个连接根据反赫布规则进行更新，即 $\dot{v}_{ij} = -\eta y_i y_j$ (对于 $v_{ij} \le 0$），那么当两个神经元同时发放时，它们之间的[相互抑制](@entry_id:272361)会增强。这种机制鼓励神经元们“各司其职”，避免对相同的输入特征产生冗余的响应。它在网络中实现了**竞争**，并有效地**去相关**（decorrelates）了神经元的输出，促进了高效的编码。

#### 上下文与奖励门控：三因子规则

经典的赫布规则（及多数变体）是一个“两因子”规则，因为它只涉及突触前活动和突触后活动。然而，越来越多的证据表明，学习过程常常受到第三个因子的调制，例如全局的神经调节物质（如[多巴胺](@entry_id:149480)、乙酰胆碱）的释放，这些物质编码了行为的上下文、注意力状态或奖励预测误差等信息。

这引出了**三因子赫布规则**  的概念，其通用形式为：

$$
\dot{w}_j = \eta \, M(t) \, y(t) \, x_j(t)
$$

这里的 $M(t)$ 就是第三个**调制因子**。这个因子的性质决定了学习的模式：
*   **门控（Gating）**：如果 $M(t)$ 是一个二元信号（例如，在特定任务中为 1，否则为 0），那么它就起到了一个“开关”的作用，只允许在特定上下文中发生[突触可塑性](@entry_id:137631)。
*   **符号翻转（Sign Inversion）**：如果 $M(t)$ 可以取正值或负值（例如，编码奖励预测误差，正为“好于预期”，负为“差于预期”），那么它可以决定一个给定的赫布关联事件（$y x_j  0$）最终导致 LTP（当 $M0$）还是 LTD（当 $M0$）。这为在无监督的赫布框架内实现[强化学习](@entry_id:141144)提供了桥梁。
*   **速率调节（Rate Modulation）**：如果 $M(t)$ 是一个恒定的正常数，它仅仅是重新缩放了学习率 $\eta$。

三因子规则极大地扩展了赫布学习的计算能力，使其能够将底层的关联学习与高层的认知和行为目标联系起来，为我们理解大脑中更复杂的学习现象提供了强大的理论框架。