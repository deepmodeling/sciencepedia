{
    "hands_on_practices": [
        {
            "introduction": "术前评估最初也是最关键的一步是确保为这一侵入性、高风险的治疗路径选择了正确的患者群体。本练习  演示了如何使用决策分析方法来正式量化诊断测试的临床效用。通过计算避免因排除心因性非癫痫性发作 (PNES) 患者而造成的预期伤害（以质量调整生命年 $QALYs$ 衡量），您可以为优化诊断流程建立一个量化论证。",
            "id": "4516272",
            "problem": "一个三级癫痫中心评估了一组 $N = 1{,}000$ 名患有耐药性癫痫发作的转诊成年人，以确定他们是否适合接受切除性手术。在这类队列中，心因性非癫痫性发作 (PNES) 的基础率为 $p = 0.15$。在手术前，该中心可以选择是否采用视频脑电图 (vEEG; video-electroencephalography) 进行专门的PNES排除步骤。考虑两种手术分诊策略：\n- 策略 $\\mathcal{A}$ (无专门的PNES排除)：PNES患者被误分类为手术候选人的概率为 $r_{\\mathcal{A}} = 0.25$。\n- 策略 $\\mathcal{B}$ (使用vEEG进行专门的PNES排除)：PNES患者被误分类为手术候选人的概率为 $r_{\\mathcal{B}} = 0.02$。\n\n对于任何接受不适当手术的PNES患者，其预期伤害是根据以下经过充分检验的手术结果率和效用权重，以质量调整生命年 (QALYs; Quality-Adjusted Life Years) 来建模的：\n- 主要并发症概率 $c_{\\text{major}} = 0.04$，效用减量 $u_{\\text{major}} = 0.35$，持续时间 $d_{\\text{major}} = 1.5$ 年。\n- 次要并发症概率 $c_{\\text{minor}} = 0.18$，效用减量 $u_{\\text{minor}} = 0.08$，持续时间 $d_{\\text{minor}} = 0.5$ 年。\n- 由于不适当的手术和延迟的PNES特异性治疗而导致的诊断和心理社会伤害，模型化为在 $d_{\\text{psych}} = 1$ 年内固定的效用减量 $u_{\\text{psych}} = 0.10$。\n\n从概率的基础率定义和QALYs的期望值定义出发，推导在每种策略下，每 $N = 1{,}000$ 名候选人预期的总QALY损失，并计算通过实施策略 $\\mathcal{B}$ 而非策略 $\\mathcal{A}$ 所避免的预期QALY伤害。将您的最终答案四舍五入到四位有效数字。以QALYs为单位表示您的最终答案。",
            "solution": "在尝试求解之前，对问题的有效性进行评估。\n\n从问题陈述中提取的已知条件：\n- 总队列规模：$N = 1{,}000$\n- 心因性非癫痫性发作 (PNES) 的基础率：$p = 0.15$\n- 策略 $\\mathcal{A}$ 对PNES患者的误分类概率：$r_{\\mathcal{A}} = 0.25$\n- 策略 $\\mathcal{B}$ 对PNES患者的误分类概率：$r_{\\mathcal{B}} = 0.02$\n- 主要并发症概率：$c_{\\text{major}} = 0.04$\n- 主要并发症效用减量：$u_{\\text{major}} = 0.35$\n- 主要并发症持续时间：$d_{\\text{major}} = 1.5$ 年\n- 次要并发症概率：$c_{\\text{minor}} = 0.18$\n- 次要并发症效用减量：$u_{\\text{minor}} = 0.08$\n- 次要并发症持续时间：$d_{\\text{minor}} = 0.5$ 年\n- 心理社会伤害效用减量：$u_{\\text{psych}} = 0.10$\n- 心理社会伤害持续时间：$d_{\\text{psych}} = 1$ 年\n\n该问题是有效的。它在科学上基于医学决策分析、流行病学和神经病学的既定原则。质量调整生命年 (QALYs)、期望值和基础率等概念是标准的，并且应用正确。该问题提法明确，提供了计算唯一且有意义的解所需的所有数据。语言客观精确，给定的参数在临床背景下是合理的。该问题内部一致，没有违反任何科学或逻辑原则。\n\n求解过程将首先计算每次不适当手术的预期伤害，然后使用该值计算在整个队列中每种策略的总预期伤害，最后确定两种策略之间的伤害差异。\n\n首先，我们确定队列中患有PNES的患者数量，记为 $N_{\\text{PNES}}$。根据给定的总队列规模 $N = 1,000$ 和PNES的基础率 $p = 0.15$，这个数字是：\n$$N_{\\text{PNES}} = N \\times p = 1,000 \\times 0.15 = 150$$\n\n接下来，我们计算单个接受不适当手术的PNES患者损失的预期伤害（以QALYs计）。这个总预期伤害 $H_{\\text{patient}}$ 是主要并发症、次要并发症和固定心理社会伤害的预期QALY损失之和。一个事件的QALY损失是其效用减量和持续时间的乘积。预期的QALY损失是这个乘积再乘以事件的概率。\n\n主要并发症的预期QALY损失为：\n$$H_{\\text{major}} = c_{\\text{major}} \\times u_{\\text{major}} \\times d_{\\text{major}} = 0.04 \\times 0.35 \\times 1.5 = 0.021 \\text{ QALYs}$$\n\n次要并发症的预期QALY损失为：\n$$H_{\\text{minor}} = c_{\\text{minor}} \\times u_{\\text{minor}} \\times d_{\\text{minor}} = 0.18 \\times 0.08 \\times 0.5 = 0.0072 \\text{ QALYs}$$\n\n对于任何接受不适当手术的PNES患者，心理社会伤害的QALY损失是确定发生的，因此其概率为 $1$。该损失为：\n$$H_{\\text{psych}} = 1 \\times u_{\\text{psych}} \\times d_{\\text{psych}} = 0.10 \\times 1 = 0.10 \\text{ QALYs}$$\n\n每位被不当手术的PNES患者损失的总预期QALY是这些组成部分的总和：\n$$H_{\\text{patient}} = H_{\\text{major}} + H_{\\text{minor}} + H_{\\text{psych}} = 0.021 + 0.0072 + 0.10 = 0.1282 \\text{ QALYs}$$\n\n现在，我们可以计算在每种策略下，整个 $N=1,000$ 名候选人队列损失的总预期QALY。这是PNES患者数量、给定策略下的误分类概率以及每位被误分类患者的预期伤害的乘积。\n\n对于策略 $\\mathcal{A}$，总预期伤害 $H_{\\mathcal{A}}$ 为：\n$$H_{\\mathcal{A}} = N_{\\text{PNES}} \\times r_{\\mathcal{A}} \\times H_{\\text{patient}}$$\n$$H_{\\mathcal{A}} = 150 \\times 0.25 \\times 0.1282 = 37.5 \\times 0.1282 = 4.8075 \\text{ QALYs}$$\n\n对于策略 $\\mathcal{B}$，总预期伤害 $H_{\\mathcal{B}}$ 为：\n$$H_{\\mathcal{B}} = N_{\\text{PNES}} \\times r_{\\mathcal{B}} \\times H_{\\text{patient}}$$\n$$H_{\\mathcal{B}} = 150 \\times 0.02 \\times 0.1282 = 3 \\times 0.1282 = 0.3846 \\text{ QALYs}$$\n\n通过实施策略 $\\mathcal{B}$ 而非策略 $\\mathcal{A}$ 所避免的预期QALY伤害是它们各自总伤害的差值：\n$$\\Delta H = H_{\\mathcal{A}} - H_{\\mathcal{B}}$$\n这个差值的更一般形式是：\n$$\\Delta H = (N \\cdot p \\cdot r_{\\mathcal{A}} \\cdot H_{\\text{patient}}) - (N \\cdot p \\cdot r_{\\mathcal{B}} \\cdot H_{\\text{patient}})$$\n$$\\Delta H = N \\cdot p \\cdot (r_{\\mathcal{A}} - r_{\\mathcal{B}}) \\cdot H_{\\text{patient}}$$\n代入数值：\n$$\\Delta H = H_{\\mathcal{A}} - H_{\\mathcal{B}} = 4.8075 - 0.3846 = 4.4229 \\text{ QALYs}$$\n\n问题要求将最终答案四舍五入到四位有效数字。\n$$4.4229 \\approx 4.423$$\n\n因此，通过实施策略 $\\mathcal{B}$ 避免的预期QALY伤害约为 $4.423$ QALYs。",
            "answer": "$$\\boxed{4.423}$$"
        },
        {
            "introduction": "无创术前评估的一个核心挑战是从传感器层面数据（脑电图/脑磁图）中精确定位癫痫活动的起源，这需要解决一个不适定的电磁逆问题。本实践  将指导您从基本原理出发，通过计算步骤构建一个稳健的源定位算法——最小范数估计 (MNE)。您将实现一些关键功能，例如深度加权（以校正对浅层源的物理偏倚）和噪声归一化（以创建具有统计意义的大脑图谱）。",
            "id": "4516299",
            "problem": "您的任务是构建一种计算方法，在耐药性癫痫的术前评估中，使用最小范数估计 (MNE) 框架来定位癫痫发作间期棘波。定位必须整合深度加权和噪声归一化，以减轻表层偏倚和异方差传感器噪声。其推导和实现必须从神经生理学和电磁场理论中的基础线性系统和随机建模原理开始。\n\n假设以下基础：\n- 麦克斯韦方程组的准静态近似导出了皮层源振幅和传感器测量值之间的线性正向模型。设 $m$ 是传感器数量，$n$ 是源数量。测量值建模为 $y \\in \\mathbb{R}^m$，源建模为 $s \\in \\mathbb{R}^n$，增益（导联场）矩阵建模为 $G \\in \\mathbb{R}^{m \\times n}$，使得 $y = G s + \\varepsilon$，其中 $\\varepsilon$ 是加性传感器噪声。\n- 传感器噪声被建模为协方差为 $C_n \\in \\mathbb{R}^{m \\times m}$ 的零均值高斯随机向量，源振幅由协方差为 $R \\in \\mathbb{R}^{n \\times n}$ 的零均值高斯先验建模。深度加权通过修改 $R$ 来抵消深度偏倚；它通过 $R = \\mathrm{diag}(d_1, \\dots, d_n)$ 实现，其中 $d_i$ 取决于 $G$ 的列范数。\n- 噪声归一化利用由传感器噪声引起的估计量方差来产生标准化估计，这类似于动态统计参数图 (dSPM)，并根据逆算子和 $C_n$ 进行定义。\n\n您的目标：\n- 从线性正向模型 $y = G s + \\varepsilon$ 和高斯建模假设出发，推导具有Tikhonov型正则化强度 $\\lambda$ 的MNE估计量。必须使用噪声协方差进行归一化，以产生在不同源之间可比较的标准化估计。\n- 通过定义 $d_i = \\left(\\|g_i\\|_2 + \\delta\\right)^{-2\\alpha}$ 来实现深度加权，其中 $g_i$ 是 $G$ 的第 $i$ 列，$\\alpha \\in [0, 1]$ 是深度加权指数，$\\delta$ 是一个小的正常数以避免除以零。\n- 通过将估计的源向量除以估计量由噪声驱动的方差对角线元素的平方根来实现噪声归一化，从而使归一化后的估计无量纲。\n- 从归一化估计中，识别最大振幅的索引 $k^\\star$ 以表示定位的棘波发生器。该索引必须是从零开始的（$0$ 到 $n - 1$）。\n\n系统数据：\n- 使用 $m = 3$ 和 $n = 4$。\n- 设导联场矩阵 $G$ 为\n$G = \\begin{bmatrix}\n0.8  0.5  0.2  0.1 \\\\\n0.1  0.7  0.1  0.2 \\\\\n0.0  0.2  0.6  0.1\n\\end{bmatrix}$。\n- 定义小常数 $\\delta = 10^{-9}$。\n- 定义四个测试案例。对于每个案例，提供一个元组 $(\\alpha, \\lambda, C_n, y)$。对于每个案例，计算深度加权的协方差 $R$，构建MNE逆解，估计 $s$，通过估计的噪声方差对其进行归一化以产生标准化估计，并输出归一化估计中最大条目的索引。\n\n测试套件：\n- 案例1（通用“理想路径”）：\n  - $\\alpha = 0.5$，\n  - $\\lambda = 0.2$，\n  - $C_n = \\mathrm{diag}(0.02, 0.02, 0.02)$，\n  - $y = [0.2, 0.1, 0.6]^\\top + [0.01, -0.005, 0.0]^\\top$。\n- 案例2（无深度加权，边界情况）：\n  - $\\alpha = 0.0$，\n  - $\\lambda = 0.2$，\n  - $C_n = \\mathrm{diag}(0.02, 0.02, 0.02)$，\n  - $y = [0.2, 0.1, 0.6]^\\top$。\n- 案例3（强深度加权，边缘情况，对应一个低范数列）：\n  - $\\alpha = 1.0$，\n  - $\\lambda = 0.2$，\n  - $C_n = \\mathrm{diag}(0.02, 0.02, 0.02)$，\n  - $y = [0.1, 0.2, 0.1]^\\top + [0.0, 0.005, -0.005]^\\top$。\n- 案例4（病态噪声，鲁棒性检查）：\n  - $\\alpha = 0.5$，\n  - $\\lambda = 0.5$，\n  - $C_n = \\mathrm{diag}(0.5, 0.5, 10^{-4})$，\n  - $y = [0.2, 0.1, 0.6]^\\top + [0.0, 0.0, 0.01]^\\top$。\n\n算法要求：\n- 使用 $d_i = \\left(\\|g_i\\|_2 + \\delta\\right)^{-2\\alpha}$ 构建深度加权的源协方差 $R = \\mathrm{diag}(d_1, \\dots, d_n)$。\n- 构建与高斯线性模型和正则化强度 $\\lambda$ 一致的MNE逆算子 $W$。\n- 计算估计源 $\\hat{s} = W y$。\n- 通过将每个 $\\hat{s}_i$ 除以由噪声协方差 $C_n$ 和逆算子 $W$ 所隐含的 $\\hat{s}_i$ 方差的平方根，来计算噪声归一化的估计 $\\tilde{s}$。\n- 为每个测试案例识别 $k^\\star = \\mathrm{argmax}_i \\tilde{s}_i$。\n\n最终输出格式：\n- 您的程序应生成一行输出，其中包含一个用方括号括起来的逗号分隔列表，例如 $[r_1,r_2,r_3,r_4]$，其中 $r_j$ 是测试案例 $j$ 的从零开始的索引 $k^\\star$。",
            "solution": "我们从皮层电磁源在麦克斯韦方程组准静态近似下的线性正向模型开始，这些源通过脑电图 (EEG) 或脑磁图 (MEG) 进行测量。测量值建模为 $y \\in \\mathbb{R}^m$，源建模为 $s \\in \\mathbb{R}^n$，导联场矩阵建模为 $G \\in \\mathbb{R}^{m \\times n}$，使得\n$$\ny = G s + \\varepsilon,\n$$\n其中 $\\varepsilon$ 是加性的零均值高斯噪声，其协方差为 $C_n \\in \\mathbb{R}^{m \\times m}$。\n\n我们对源施加一个协方差为 $R \\in \\mathbb{R}^{n \\times n}$ 的高斯先验。最小范数估计 (MNE) 源于贝叶斯解释，等价于最小化一个Tikhonov型泛函：\n$$\n\\hat{s} = \\underset{s \\in \\mathbb{R}^n}{\\arg\\min}\\ \\left\\| y - G s \\right\\|_{C_n^{-1}}^2 + \\lambda^2 \\left\\| s \\right\\|_{R^{-1}}^2,\n$$\n其中 $\\|x\\|_{A}^2 := x^\\top A x$，$\\lambda > 0$ 是正则化参数，控制数据拟合与先验依从性之间的权衡。第一项根据噪声精度 $C_n^{-1}$ 对残差进行加权，第二项根据 $R^{-1}$ 强制执行源的正则性。\n\n求解此优化问题可得到众所周知的线性估计量（通过配方法或使用正规方程）：\n$$\n\\hat{s} = R G^\\top \\left( G R G^\\top + \\lambda^2 C_n \\right)^{-1} y,\n$$\n它定义了逆算子\n$$\nW := R G^\\top \\left( G R G^\\top + \\lambda^2 C_n \\right)^{-1}.\n$$\n此表达式通过将目标函数的导数设为零得出：\n$$\n-2 G^\\top C_n^{-1} (y - G s) + 2 \\lambda^2 R^{-1} s = 0\n\\ \\Rightarrow\\\n\\left( G^\\top C_n^{-1} G + \\lambda^2 R^{-1} \\right) s = G^\\top C_n^{-1} y,\n$$\n然后应用矩阵求逆引理得到上述包含 $W$ 的形式。等价地，对于联合高斯变量，贝叶斯后验均值会产生相同的 $W$。\n\n深度加权修改先验协方差，以减少由 $G$ 较大的列范数引起的表层偏倚。令 $g_i \\in \\mathbb{R}^m$ 表示 $G$ 的第 $i$ 列。我们定义\n$$\nd_i = \\left( \\| g_i \\|_2 + \\delta \\right)^{-2 \\alpha}, \\quad \\alpha \\in [0, 1],\\ \\delta > 0,\n$$\n并设置\n$$\nR = \\mathrm{diag}(d_1, \\dots, d_n).\n$$\n当 $\\alpha = 0$ 时，没有深度加权 ($R = I$)。当 $\\alpha = 1$ 时，应用强深度补偿，对具有大范数的列进行重罚。无穷小量 $\\delta$ 避免了在 $\\|g_i\\|_2 = 0$ 时出现除以零的情况。\n\n噪声归一化将估计量的分量标准化到一个无量纲尺度，同时考虑了传感器噪声和 $W$ 的几何结构。对于噪声协方差 $C_n$，估计量由噪声驱动的协方差为\n$$\n\\mathrm{Cov}(\\hat{s}) = W C_n W^\\top.\n$$\n动态统计参数图 (dSPM) 归一化将每个分量 $\\hat{s}_i$ 除以其方差的平方根：\n$$\n\\tilde{s}_i = \\frac{\\hat{s}_i}{\\sqrt{\\left[ W C_n W^\\top \\right]_{ii} + \\epsilon}},\n$$\n其中 $\\epsilon > 0$ 是一个小的稳定器，用于避免除以零。归一化后的估计 $\\tilde{s}$ 是无量纲的，提高了可解释性和在不同源之间的可比性。\n\n然后我们通过选择最大条目的索引来识别定位的癫痫发作间期棘波发生器：\n$$\nk^\\star = \\underset{i \\in \\{0, \\dots, n-1\\}}{\\arg\\max}\\ \\tilde{s}_i.\n$$\n\n每个测试案例的算法步骤：\n- 使用 $d_i = (\\|g_i\\|_2 + \\delta)^{-2\\alpha}$ 从 $G$ 计算 $R$，然后计算 $R = \\mathrm{diag}(d_1, \\dots, d_n)$。\n- 构造 $S = G R G^\\top + \\lambda^2 C_n$ 并计算一个数值稳定的逆（例如，伪逆）以获得 $W = R G^\\top S^{-1}$。\n- 计算 $\\hat{s} = W y$。\n- 计算对角线噪声方差 $\\sigma_i^2 = \\left[ W C_n W^\\top \\right]_{ii}$ 和归一化估计 $\\tilde{s}_i = \\hat{s}_i / \\sqrt{\\sigma_i^2 + \\epsilon}$。\n- 输出 $k^\\star = \\arg\\max_i \\tilde{s}_i$。\n\n逆解中的假设：\n- 线性：映射 $y = G s + \\varepsilon$ 是线性的，源自准静态近似、固定的电导率和已知的头部模型。这假定在相关频率上没有显著的容性或感性效应。\n- 高斯性：传感器噪声 $\\varepsilon$ 是协方差为 $C_n$ 的零均值高斯噪声，源 $s$ 被建模为协方差为 $R$ 的零均值高斯分布。这确保了后验均值的闭式表达式，并为二次惩罚项提供了依据。\n- 平稳性：在分析窗口内，噪声协方差 $C_n$ 是时不变的。\n- 独立性结构：源协方差 $R$ 是对角矩阵，意味着先验上源是不相关的；深度加权仅通过边缘方差引入。\n- 已知的 $G$：导联场矩阵 $G$ 是准确且固定的；$G$ 中的错误会降低定位的准确性。\n- 正则化：参数 $\\lambda$ 平衡了数据保真度和先验依从性；较大的 $\\lambda$ 会增加平滑度和稳定性，尤其是在 $C_n$ 病态的情况下。\n- 归一化有效性：dSPM归一化假设 $W C_n W^\\top$ 捕捉了噪声向估计中的传播；它在高斯线性模型下是合适的，并产生无量纲的标准化振幅。\n\n通过遵循这些步骤，程序将为每个测试案例计算 $k^\\star$，并以要求的单行格式打印结果。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef compute_depth_weighted_R(G, alpha, delta=1e-9):\n    \"\"\"\n    Compute diagonal source covariance R via depth weighting:\n    d_i = (||g_i||_2 + delta)^(-2 * alpha)\n    R = diag(d_i)\n    \"\"\"\n    col_norms = np.linalg.norm(G, axis=0)\n    d = (col_norms + delta) ** (-2.0 * alpha)\n    return np.diag(d)\n\ndef mne_inverse_operator(G, R, Cn, lam):\n    \"\"\"\n    Compute the MNE inverse operator:\n    W = R G^T (G R G^T + lam^2 Cn)^(-1)\n    Use pseudoinverse for numerical stability.\n    \"\"\"\n    S = G @ R @ G.T + (lam ** 2) * Cn\n    S_inv = np.linalg.pinv(S)\n    W = R @ G.T @ S_inv\n    return W\n\ndef dspm_normalize(W, Cn, s_hat, eps=1e-12):\n    \"\"\"\n    dSPM normalization:\n    s_tilde_i = s_hat_i / sqrt( (W Cn W^T)_{ii} + eps )\n    \"\"\"\n    cov_s = W @ Cn @ W.T\n    variances = np.clip(np.diag(cov_s), a_min=0.0, a_max=None)\n    denom = np.sqrt(variances + eps)\n    # Avoid division by zero by using eps in denom\n    s_tilde = s_hat / denom\n    return s_tilde\n\ndef localize_spike(G, Cn, y, alpha, lam):\n    \"\"\"\n    Full pipeline:\n    - Compute R via depth weighting\n    - Compute MNE inverse operator W\n    - Estimate sources s_hat\n    - dSPM normalization to s_tilde\n    - Return index of maximum amplitude\n    \"\"\"\n    R = compute_depth_weighted_R(G, alpha)\n    W = mne_inverse_operator(G, R, Cn, lam)\n    s_hat = W @ y\n    s_tilde = dspm_normalize(W, Cn, s_hat)\n    k_star = int(np.argmax(s_tilde))\n    return k_star\n\ndef solve():\n    # Define lead-field matrix G (3 sensors x 4 sources)\n    G = np.array([\n        [0.8, 0.5, 0.2, 0.1],\n        [0.1, 0.7, 0.1, 0.2],\n        [0.0, 0.2, 0.6, 0.1]\n    ], dtype=float)\n\n    # Construct test cases as tuples: (alpha, lambda, Cn, y)\n    # Case 1: happy path\n    Cn1 = np.diag([0.02, 0.02, 0.02])\n    y1 = np.array([0.2, 0.1, 0.6]) + np.array([0.01, -0.005, 0.0])\n    case1 = (0.5, 0.2, Cn1, y1)\n\n    # Case 2: no depth weighting\n    Cn2 = np.diag([0.02, 0.02, 0.02])\n    y2 = np.array([0.2, 0.1, 0.6])\n    case2 = (0.0, 0.2, Cn2, y2)\n\n    # Case 3: strong depth weighting; target matches column 3 with slight noise\n    Cn3 = np.diag([0.02, 0.02, 0.02])\n    y3 = np.array([0.1, 0.2, 0.1]) + np.array([0.0, 0.005, -0.005])\n    case3 = (1.0, 0.2, Cn3, y3)\n\n    # Case 4: ill-conditioned noise covariance with higher lambda\n    Cn4 = np.diag([0.5, 0.5, 1e-4])\n    y4 = np.array([0.2, 0.1, 0.6]) + np.array([0.0, 0.0, 0.01])\n    case4 = (0.5, 0.5, Cn4, y4)\n\n    test_cases = [case1, case2, case3, case4]\n\n    results = []\n    for alpha, lam, Cn, y in test_cases:\n        idx = localize_spike(G, Cn, y, alpha, lam)\n        results.append(idx)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "在完成全面评估并制定手术计划后，关键的最后一步是综合所有收集到的信息，以预测成功结果的可能性，这一预后估计对于与患者进行共同决策至关重要。在本练习  中，您将构建一个多变量预后模型，该模型整合了不同的临床、影像学和电生理数据，以估计术后无发作的概率。这项任务体现了如何利用统计学习将复杂的患者数据转化为可操作的个性化预测。",
            "id": "4516266",
            "problem": "构建一个多变量预后模型，通过整合症状学、影像学、脑电图（EEG; electroencephalography）和认知功能数据，来估计癫痫手术后$2$年内无癫痫发作的概率。在耐药性癫痫的术前评估框架内进行工作，并按如下方式形式化该预测问题。\n\n从基本定义开始：\n- 设二元手术结局为一个随机变量 $Y \\in \\{0,1\\}$，其中 $Y=1$ 表示$2$年内无癫痫发作，$Y=0$ 表示其他情况。假设 $Y$ 服从一个由 $p$ 参数化的伯努利定律，其中 $p$ 是给定协变量 $\\mathbf{x} \\in \\mathbb{R}^p$ 的条件概率 $p = \\mathbb{P}(Y=1 \\mid \\mathbf{x})$。\n- 设协变量向量 $\\mathbf{x}$ 编码了来自症状学、影像学、脑电图和认知功能的术前信息。假设一个线性预测器 $z = \\mathbf{w}^\\top \\tilde{\\mathbf{x}}$，其中 $\\tilde{\\mathbf{x}}$ 是通过为 $\\mathbf{x}$ 增加一个截距项而得到的增广向量，并要求一个严格单调可微的链接函数 $g$，使得 $p = g(z)$ 将 $\\mathbb{R}$ 映射到开区间 $(0,1)$。使用最大似然原理，通过最小化伯努利模型的期望负对数似然来估计 $\\mathbf{w}$，并对非截距项系数施加一个强度为 $\\lambda$ 的 $\\ell_2$ (岭) 惩罚项，以反映先验的正则性并避免过拟合。\n- 在模型拟合前，将训练数据中的每个特征维度标准化为零均值和单位方差，且不对截距项进行惩罚。\n\n每位患者的临床特征定义：\n- $x_1$：症状学与计划切除侧的一致性（$0$ 表示不一致，$1$ 表示一致）。\n- $x_2$：症状学局灶性评分（序数，取值于 $\\{0,1,2,3\\}$；值越高表示症状学局灶性越强）。\n- $x_3$：磁共振成像（MRI; magnetic resonance imaging）病灶存在性（$0$ 表示无病灶，$1$ 表示有病灶）。\n- $x_4$：病灶-切除一致性（$0$ 表示不一致或无病灶，$1$ 表示一致）。\n- $x_5$：头皮脑电图发作期起始与计划切除侧的一致性（$0$ 表示不一致，$1$ 表示一致）。\n- $x_6$：发作间期棘波负荷（每分钟棘波数，归一化为 $[0,3]$ 范围内的无单位标度）。\n- $x_7$：基线言语记忆 $z$ 分数（无单位；典型范围 $[-2,2]$）。\n\n包含 $N=18$ 名患者的训练数据集。每个项目列出 $(x_1,x_2,x_3,x_4,x_5,x_6,x_7; y)$，其中 $y \\in \\{0,1\\}$：\n- 患者 $1$：$(1,3,1,1,1,0.8,0.5; 1)$。\n- 患者 $2$：$(1,2,1,1,1,0.6,0.2; 1)$。\n- 患者 $3$：$(0,1,0,0,0,2.1,-0.8; 0)$。\n- 患者 $4$：$(1,3,0,0,1,1.5,0.4; 1)$。\n- 患者 $5$：$(0,0,1,0,0,2.8,-1.5; 0)$。\n- 患者 $6$：$(1,2,1,1,0,1.2,0.0; 1)$。\n- 患者 $7$：$(1,1,0,0,1,0.9,-0.2; 1)$。\n- 患者 $8$：$(0,1,0,0,0,1.8,-0.7; 0)$。\n- 患者 $9$：$(1,3,1,1,1,0.3,1.2; 1)$。\n- 患者 $10$：$(0,0,0,0,0,2.5,-1.8; 0)$。\n- 患者 $11$：$(1,2,1,1,1,0.5,0.8; 1)$。\n- 患者 $12$：$(0,1,1,0,0,1.7,-0.9; 0)$。\n- 患者 $13$：$(1,3,1,1,0,0.4,0.6; 1)$。\n- 患者 $14$：$(0,0,1,0,1,2.0,-1.0; 0)$。\n- 患者 $15$：$(1,2,0,0,1,1.1,0.3; 1)$。\n- 患者 $16$：$(0,1,0,0,1,2.3,-0.6; 0)$。\n- 患者 $17$：$(1,3,1,1,1,0.7,1.5; 1)$。\n- 患者 $18$：$(0,0,0,0,0,2.2,-1.2; 0)$。\n\n建模和算法要求：\n- 从伯努利模型和一个将 $\\mathbb{R}$ 映射到 $(0,1)$ 的严格单调链接函数 $g$ 开始，通过最小化带 $\\ell_2$ 惩罚项（强度 $\\lambda$）的负对数似然，推导出一个 $\\mathbf{w}$ 的估计量。使用 $\\lambda = 1.0$。惩罚项仅作用于非截距项系数。\n- 在标准化的特征空间上，通过 Newton–Raphson 方法实现最小化，并使用一个不被惩罚的截距项。在计算对数似然时，将概率限制在远离 $0$ 和 $1$ 的范围内，以确保数值稳定性。\n- 拟合后，为新的患者计算预测概率 $p$。\n\n包含 $5$ 个术前病例的测试套件（每个病例表示为 $(x_1,x_2,x_3,x_4,x_5,x_6,x_7)$）：\n- 病例 A（典型的一致性病灶候选者）：$(1,3,1,1,1,0.4,1.0)$。\n- 病例 B（不一致、弥漫性症状学、高棘波负荷）：$(0,0,0,0,0,2.4,-1.3)$。\n- 病例 C（症状学和脑电图一致、无病灶、中等棘波）：$(1,2,0,0,1,1.6,0.0)$。\n- 病例 D（病灶存在但不一致、脑电图不一致）：$(0,1,1,0,0,1.9,-0.5)$。\n- 病例 E（弱症状学证据、无病灶、低棘波）：$(1,1,0,0,0,0.5,-0.1)$。\n\n您的程序必须：\n- 使用训练集的统计数据（每个特征的均值和标准差）对特征进行标准化，任何为零的标准差都应替换为 $1$，以避免除以零。\n- 按规定拟合带惩罚项的模型。\n- 对每个测试病例，计算其$2$年无癫痫发作的预测概率，结果为 $(0,1)$ 内的小数，四舍五入到三位小数。\n\n最终输出格式：\n- 生成单行输出，包含 $5$ 个四舍五入后的概率，形式为逗号分隔的列表并用方括号括起，例如 $[0.842,0.137,0.511,0.203,0.436]$。",
            "solution": "所提出的问题是构建一个多变量预后模型，用于预测癫痫手术后$2$年的无癫痫发作情况。该模型将在广义线性模型 (GLM) 的框架内进行形式化，具体为带有 $\\ell_2$ (岭) 惩罚的逻辑回归，并且其参数使用 Newton-Raphson 方法进行估计。这个问题具有科学依据、提法明确且客观。它提供了一套完整的数据、模型规格和算法要求，足以得出一个唯一的解。\n\n首先，我将陈述完整的模型规格，然后推导参数估计算法。\n\n**1. 模型规格**\n\n对于每个患者 $i$，其结局是一个二元随机变量 $Y_i \\in \\{0, 1\\}$，其中 $Y_i=1$ 表示无癫痫发作。这由一个伯努利分布建模：\n$$ Y_i \\sim \\text{Bernoulli}(p_i) $$\n其中 $p_i = \\mathbb{P}(Y_i=1 \\mid \\mathbf{x}_i)$ 是在给定术前协变量向量 $\\mathbf{x}_i \\in \\mathbb{R}^7$ 的情况下，无癫痫发作的概率。\n\n该模型通过一个线性预测器 $z_i$ 和一个链接函数 $g$ 将概率 $p_i$ 与协变量联系起来。设 $\\tilde{\\mathbf{x}}_i$ 为协变量向量 $\\mathbf{x}_i$ 在前面增加一个 $1$ 以容纳截距项后的增广向量，即 $\\tilde{\\mathbf{x}}_i = [1, x_{i1}, \\dots, x_{i7}]^\\top$。线性预测器则为：\n$$ z_i = \\mathbf{w}^\\top \\tilde{\\mathbf{x}}_i = w_0 + \\sum_{j=1}^7 w_j x_{ij} $$\n其中 $\\mathbf{w} = [w_0, w_1, \\dots, w_7]^\\top$ 是模型权重的向量。\n\n问题指定了一个严格单调可微的链接函数 $g$，它将 $\\mathbb{R}$ 映射到 $(0,1)$。对于伯努利分布的响应变量，标准且规范的选择是逻辑函数（或称 sigmoid 函数），我将在此推导中使用它：\n$$ p_i = g(z_i) = \\frac{1}{1 + e^{-z_i}} $$\n这个模型被称为逻辑回归。\n\n**2. 目标函数：带惩罚的负对数似然**\n\n参数 $\\mathbf{w}$ 通过最大化观测数据的对数似然来估计，并附加一个 $\\ell_2$ 惩罚项以对模型进行正则化。对于单个观测 $(y_i, \\mathbf{x}_i)$，其似然函数为：\n$$ L(\\mathbf{w}; y_i, \\mathbf{x}_i) = p_i^{y_i} (1-p_i)^{1-y_i} $$\n对于包含 $N=18$ 名患者的整个数据集，其对数似然是每个样本对数似然之和：\n$$ \\mathcal{L}(\\mathbf{w}) = \\sum_{i=1}^N \\left[ y_i \\log(p_i) + (1-y_i) \\log(1-p_i) \\right] $$\n利用逻辑函数的性质 $p_i = \\frac{e^{z_i}}{1+e^{z_i}}$ 和 $1-p_i = \\frac{1}{1+e^{z_i}}$，我们可以将对数似然重写为：\n$$ \\mathcal{L}(\\mathbf{w}) = \\sum_{i=1}^N \\left[ y_i z_i - \\log(1+e^{z_i}) \\right] $$\n我们的任务是最小化带有 $\\ell_2$ 惩罚的负对数似然，该惩罚作用于非截距项系数（$w_1, \\dots, w_7$）。正则化参数给定为 $\\lambda = 1.0$。因此，需要最小化的目标函数 $J(\\mathbf{w})$ 为：\n$$ J(\\mathbf{w}) = -\\mathcal{L}(\\mathbf{w}) + \\frac{\\lambda}{2} \\sum_{j=1}^7 w_j^2 = \\sum_{i=1}^N \\left[ \\log(1+e^{z_i}) - y_i z_i \\right] + \\frac{\\lambda}{2} \\sum_{j=1}^7 w_j^2 $$\n\n**3. 通过 Newton-Raphson 方法进行优化**\n\nNewton-Raphson 方法是一种迭代优化算法，它使用目标函数的一阶和二阶导数。在第 $k+1$ 步的更新规则是：\n$$ \\mathbf{w}^{(k+1)} = \\mathbf{w}^{(k)} - \\left[H\\left(\\mathbf{w}^{(k)}\\right)\\right]^{-1} \\nabla J\\left(\\mathbf{w}^{(k)}\\right) $$\n其中 $\\nabla J$ 是 $J(\\mathbf{w})$ 的梯度，而 $H$ 是其 Hessian 矩阵。\n\n首先，我们需要 $J(\\mathbf{w})$ 的梯度。关于权重 $w_j$ 的偏导数是：\n$$ \\frac{\\partial J}{\\partial w_j} = \\sum_{i=1}^N \\left( \\frac{\\partial}{\\partial z_i} (\\log(1+e^{z_i}) - y_i z_i) \\cdot \\frac{\\partial z_i}{\\partial w_j} \\right) + \\frac{\\partial}{\\partial w_j} \\left( \\frac{\\lambda}{2} \\sum_{l=1}^7 w_l^2 \\right) $$\n注意到 $\\frac{\\partial z_i}{\\partial w_j} = \\tilde{x}_{ij}$ 和 $\\frac{d}{dz_i} \\log(1+e^{z_i}) = \\frac{e^{z_i}}{1+e^{z_i}} = p_i$，我们得到：\n$$ \\frac{\\partial J}{\\partial w_j} = \\sum_{i=1}^N (p_i - y_i) \\tilde{x}_{ij} + \\lambda w_j \\cdot \\mathbb{I}(j>0) $$\n其中 $\\mathbb{I}(j>0)$ 是一个指示函数，当 $j > 0$ 时为 $1$，当 $j=0$ 时为 $0$，确保截距项 $w_0$ 不被惩罚。\n\n在矩阵表示法中，设 $\\tilde{X}$ 为 $N \\times (7+1)$ 的设计矩阵（行为 $\\tilde{\\mathbf{x}}_i^\\top$），$\\mathbf{y}$ 为结局向量，$\\mathbf{p}$ 为预测概率向量，$\\mathbf{w}^* = [0, w_1, \\dots, w_7]^\\top$。梯度为：\n$$ \\nabla J(\\mathbf{w}) = \\tilde{X}^\\top (\\mathbf{p} - \\mathbf{y}) + \\lambda \\mathbf{w}^* $$\n\n接下来，我们需要 Hessian 矩阵 $H$，其元素为 $H_{jk} = \\frac{\\partial^2 J}{\\partial w_j \\partial w_k}$：\n$$ H_{jk} = \\frac{\\partial}{\\partial w_k} \\left( \\sum_{i=1}^N (p_i - y_i) \\tilde{x}_{ij} \\right) + \\lambda \\delta_{jk} \\cdot \\mathbb{I}(j>0) $$\n其中 $\\delta_{jk}$ 是克罗内克 delta。第一项的导数是：\n$$ \\sum_{i=1}^N \\frac{\\partial p_i}{\\partial w_k} \\tilde{x}_{ij} = \\sum_{i=1}^N \\left( \\frac{dp_i}{dz_i} \\frac{\\partial z_i}{\\partial w_k} \\right) \\tilde{x}_{ij} $$\n逻辑函数的导数是 $\\frac{dp_i}{dz_i} = p_i(1-p_i)$。这得出：\n$$ H_{jk} = \\sum_{i=1}^N p_i(1-p_i) \\tilde{x}_{ik} \\tilde{x}_{ij} + \\lambda \\delta_{jk} \\cdot \\mathbb{I}(j>0) $$\n在矩阵表示法中，设 $S$ 为一个 $N \\times N$ 的对角矩阵，其对角元素为 $S_{ii} = p_i(1-p_i)$，并设 $I^*$ 为一个 $(7+1) \\times (7+1)$ 的单位矩阵，其左上角元素 $I^*_{00}$ 设置为 $0$。Hessian 矩阵为：\n$$ H(\\mathbf{w}) = \\tilde{X}^\\top S \\tilde{X} + \\lambda I^* $$\n\n因此，在第 $k$ 次迭代中，Newton-Raphson 更新规则为：\n$$ \\mathbf{w}^{(k+1)} = \\mathbf{w}^{(k)} - \\left(\\tilde{X}^\\top S^{(k)} \\tilde{X} + \\lambda I^*\\right)^{-1} \\left(\\tilde{X}^\\top (\\mathbf{p}^{(k)} - \\mathbf{y}) + \\lambda \\mathbf{w}^{*(k)}\\right) $$\n这是迭代重加权最小二乘法 (IRLS) 算法的一个实例。\n\n**4. 算法实现步骤**\n\n1.  **数据准备**：将 $N=18$ 位患者的记录加载到一个特征矩阵 $X_{train}$ ($18 \\times 7$) 和一个结局向量 $\\mathbf{y}$ ($18 \\times 1$) 中。\n2.  **标准化**：计算训练数据中 $7$ 个特征各自的均值向量 $\\boldsymbol{\\mu}$ 和标准差向量 $\\boldsymbol{\\sigma}$。对于任何 $\\sigma_j = 0$ 的特征，将其替换为 $\\sigma_j=1.0$。对训练数据进行标准化：$X_{std} = (X_{train} - \\boldsymbol{\\mu}) / \\boldsymbol{\\sigma}$。\n3.  **设计矩阵**：在 $X_{std}$ 前面增加一列全为 $1$ 的列，以构成设计矩阵 $\\tilde{X}$。这是一个 $18 \\times 8$ 的矩阵。\n4.  **初始化**：将权重向量 $\\mathbf{w} = [w_0, w_1, \\dots, w_7]^\\top$ 初始化为全零。设置 $\\lambda=1.0$。\n5.  **迭代拟合**：\n    a. 进行固定次数的迭代（例如，$20$次）或直到收敛。\n    b. 在每次迭代中，计算当前的预测：$z_i = \\mathbf{w}^\\top \\tilde{\\mathbf{x}}_i$，然后 $p_i = 1 / (1 + e^{-z_i})$。将概率限制在一个小区间 $[\\epsilon, 1-\\epsilon]$ 内（例如，$\\epsilon=10^{-10}$），以确保数值稳定性。\n    c. 构建对角权重矩阵 $S$，其中 $S_{ii} = p_i(1-p_i)$。\n    d. 构建带惩罚的 Hessian 矩阵 $H = \\tilde{X}^\\top S \\tilde{X} + \\lambda I^*$。\n    e. 构建带惩罚的梯度 $\\nabla J = \\tilde{X}^\\top (\\mathbf{p} - \\mathbf{y}) + \\lambda \\mathbf{w}^*$。\n    f. 计算更新步长 $\\Delta \\mathbf{w} = -H^{-1} \\nabla J$。\n    g. 更新权重：$\\mathbf{w} \\leftarrow \\mathbf{w} + \\Delta \\mathbf{w}$。\n6.  **对测试病例进行预测**：在最后一次迭代之后，得到收敛的向量 $\\mathbf{w}$。对于 $5$ 个测试病例中的每一个：\n    a. 设 $\\mathbf{x}_{test}$ 为一个测试特征向量。\n    b. 使用*训练集*的统计数据对其进行标准化：$\\mathbf{x}_{test,std} = (\\mathbf{x}_{test} - \\boldsymbol{\\mu}) / \\boldsymbol{\\sigma}$。\n    c. 在前面增加一个 $1$，构成 $\\tilde{\\mathbf{x}}_{test,std}$。\n    d. 计算线性预测器 $z_{test} = \\mathbf{w}^\\top \\tilde{\\mathbf{x}}_{test,std}$。\n    e. 计算最终概率 $p_{test} = 1 / (1 + e^{-z_{test}})$。\n    f. 将结果四舍五入到三位小数。\n\n此过程将为给定的测试病例得出所需的概率。",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Constructs and fits a penalized logistic regression model to predict epilepsy surgery outcomes.\n    The model is fitted using the Newton-Raphson method (IRLS) on a standardized feature space.\n    \"\"\"\n\n    # Step 1: Define training and test data\n    train_data = [\n        (1, 3, 1, 1, 1, 0.8, 0.5, 1),\n        (1, 2, 1, 1, 1, 0.6, 0.2, 1),\n        (0, 1, 0, 0, 0, 2.1, -0.8, 0),\n        (1, 3, 0, 0, 1, 1.5, 0.4, 1),\n        (0, 0, 1, 0, 0, 2.8, -1.5, 0),\n        (1, 2, 1, 1, 0, 1.2, 0.0, 1),\n        (1, 1, 0, 0, 1, 0.9, -0.2, 1),\n        (0, 1, 0, 0, 0, 1.8, -0.7, 0),\n        (1, 3, 1, 1, 1, 0.3, 1.2, 1),\n        (0, 0, 0, 0, 0, 2.5, -1.8, 0),\n        (1, 2, 1, 1, 1, 0.5, 0.8, 1),\n        (0, 1, 1, 0, 0, 1.7, -0.9, 0),\n        (1, 3, 1, 1, 0, 0.4, 0.6, 1),\n        (0, 0, 1, 0, 1, 2.0, -1.0, 0),\n        (1, 2, 0, 0, 1, 1.1, 0.3, 1),\n        (0, 1, 0, 0, 1, 2.3, -0.6, 0),\n        (1, 3, 1, 1, 1, 0.7, 1.5, 1),\n        (0, 0, 0, 0, 0, 2.2, -1.2, 0),\n    ]\n\n    test_cases = {\n        'A': (1, 3, 1, 1, 1, 0.4, 1.0),\n        'B': (0, 0, 0, 0, 0, 2.4, -1.3),\n        'C': (1, 2, 0, 0, 1, 1.6, 0.0),\n        'D': (0, 1, 1, 0, 0, 1.9, -0.5),\n        'E': (1, 1, 0, 0, 0, 0.5, -0.1),\n    }\n\n    # Separate features (X) and outcomes (y)\n    train_X = np.array([row[:-1] for row in train_data])\n    train_y = np.array([row[-1] for row in train_data])\n\n    # Step 2: Standardize features using training data stats\n    mean = np.mean(train_X, axis=0)\n    std = np.std(train_X, axis=0)\n    # As per problem, replace std=0 with 1, though not necessary for this dataset\n    std[std == 0] = 1.0\n\n    X_std = (train_X - mean) / std\n\n    # Step 3: Augment design matrix with intercept term\n    intercept = np.ones((X_std.shape[0], 1))\n    X_tilde = np.hstack((intercept, X_std))\n    \n    # Model parameters\n    lambda_val = 1.0\n    num_features = X_tilde.shape[1]\n    w = np.zeros(num_features)\n    num_iterations = 20\n    epsilon = 1e-10\n\n    # Create penalty matrix I* (identity with I*[0,0]=0)\n    I_star = np.identity(num_features)\n    I_star[0, 0] = 0.0\n    \n    # Step 4: Fit the model using Newton-Raphson (IRLS)\n    for i in range(num_iterations):\n        # Linear predictor\n        z = X_tilde @ w\n        \n        # Predicted probabilities (clamped for stability)\n        p = 1.0 / (1.0 + np.exp(-z))\n        p = np.clip(p, epsilon, 1 - epsilon)\n\n        # Diagonal matrix S for Hessian\n        s_diag = p * (1 - p)\n        S = np.diag(s_diag)\n\n        # Gradient of penalized negative log-likelihood\n        w_star = w.copy()\n        w_star[0] = 0.0\n        gradient = X_tilde.T @ (p - train_y) + lambda_val * w_star\n\n        # Hessian of penalized negative log-likelihood\n        hessian = X_tilde.T @ S @ X_tilde + lambda_val * I_star\n\n        # Newton-Raphson update step\n        update_step = -np.linalg.inv(hessian) @ gradient\n        w += update_step\n\n        # Convergence check (optional but good practice)\n        if np.linalg.norm(update_step)  1e-6:\n            break\n\n    # Step 5: Predict probabilities for test cases\n    results = []\n    case_order = ['A', 'B', 'C', 'D', 'E']\n    for case_id in case_order:\n        x_test = np.array(test_cases[case_id])\n        \n        # Standardize using training set statistics\n        x_test_std = (x_test - mean) / std\n        \n        # Augment with intercept\n        x_test_tilde = np.hstack(([1.0], x_test_std))\n        \n        # Calculate prediction\n        z_test = x_test_tilde @ w\n        p_test = 1.0 / (1.0 + np.exp(-z_test))\n        \n        # Round and store\n        results.append(round(p_test, 3))\n\n    # Format and print the final output\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        }
    ]
}