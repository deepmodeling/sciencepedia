## 引言
从被动观测的数据中辨别因果关系，而非仅仅是相关性，是现代数据科学，尤其是在神经科学、生物信息学和健康科学等复杂领域中的核心挑战。我们收集到的数据往往并非来自精心设计的[随机对照试验](@entry_id:909406)，而是充满了[混淆变量](@entry_id:199777)、[选择偏倚](@entry_id:172119)和复杂的动态关系，这使得“关联不等于因果”成为一个必须时刻警惕的原则。直接从这些数据中得出的结论很可能具有误导性，甚至完全错误。本文旨在系统性地解决这一知识鸿沟，为读者提供一套从观测数据中进行可靠因果推断的理论框架与实用工具。

本文将引导您完成一次从理论到实践的深度探索。在“**原理与机制**”一章中，我们将首先深入探讨两大核心理论——[潜在结果框架](@entry_id:636884)和[结构因果模型](@entry_id:911144)，阐明定义和识别因果效应所需的关键假设与机制，并揭示诸如[辛普森悖论](@entry_id:136589)等常见陷阱的本质。接着，在“**应用与跨学科连接**”一章中，我们将展示这些原理如何在真实世界的复杂场景中被应用，通过[逆概率加权](@entry_id:1126661)、[工具变量](@entry_id:142324)、回归断点等方法应对[混杂偏倚](@entry_id:635723)和[准实验设计](@entry_id:915254)，并探讨与机器学习前沿技术的融合。最后，在“**动手实践**”部分，读者将有机会通过具体的练习，巩固对关键概念（如[后门准则](@entry_id:926460)、[对撞偏倚](@entry_id:163186)和[正定性](@entry_id:149643)假设）的理解，将理论知识转化为分析技能。通过本次学习，您将能够更自信地从数据中探寻因果真相。

## 原理与机制

在[神经科学数据分析](@entry_id:1128665)中，我们面临的核心挑战之一是从被动观测的数据中推断出因果关系。与通过实验干预主动操控系统不同，观测数据中的相关性可能源于真正的因果效应、[共同原因](@entry_id:266381)引起的混淆，或由数据选择过程引入的偏倚。本章旨在系统性地介绍从观测数据中进行因果推断的两个核心理论框架——[潜在结果框架](@entry_id:636884)（Potential Outcomes Framework）和[结构因果模型](@entry_id:911144)（Structural Causal Models），并阐述识别（identify）和估计因果效应的关键原理与机制。

### 混淆：关联并非因果

理解因果推断的必要性，始于深刻认识“关联不等于因果”这一基本原则。观测到的变量之间的[统计关联](@entry_id:172897)可能具有误导性。一个经典的例子是**[辛普森悖论](@entry_id:136589)（Simpson's Paradox）**，它揭示了一个在数据子集中表现出的关联趋势，在将数据合并后可能完全逆转。

让我们通过一个神经科学的假想场景来具体说明。假设我们正在分析一项视觉辨别任务中，刺激对比度（$X$）对前额叶皮层单个[神经元放电](@entry_id:184180)（$Y$）的影响。我们记录了两种刺激条件：高对比度（$X=1$）和低对比度（$X=0$）。神经元的反应被二元化为“发放了至少一个脉冲”（$Y=1$）或“未发放脉冲”（$Y=0$）。同时，我们通过瞳孔大小等指标推断出一个潜在的认知状态——警觉性（$Z$），分为高警觉性（$Z=1$）和低警觉性（$Z=0$）。实验并非随机设计，研究人员倾向于在动物处于高警觉性状态时呈现高对比度刺激。

我们收集到的数据如下 ：
- 在**高警觉性**（$Z=1$）状态下：
    - 300次高对比度刺激（$X=1$）试验中，有180次神经元发放了脉冲。
    - 100次低对比度刺激（$X=0$）试验中，有70次神经元发放了脉冲。
- 在**低警觉性**（$Z=0$）状态下：
    - 100次高对比度刺激（$X=1$）试验中，有30次神经元发放了脉冲。
    - 300次低对比度刺激（$X=0$）试验中，有120次神经元发放了脉冲。

首先，我们在每个警觉性状态（$Z$的每个层级）内部分析刺激与反应的关联。
- 在高警觉性状态下，$P(Y=1|X=1, Z=1) = 180/300 = 0.6$，$P(Y=1|X=0, Z=1) = 70/100 = 0.7$。关联差异为 $0.6 - 0.7 = -0.1$。
- 在低警觉性状态下，$P(Y=1|X=1, Z=0) = 30/100 = 0.3$，$P(Y=1|X=0, Z=0) = 120/300 = 0.4$。关联差异为 $0.3 - 0.4 = -0.1$。

在两个子集中，高对比度刺激都与较低的神经元放电概率相关。然而，如果我们忽略警觉性状态，将所有数据合并分析（即“边际化”$Z$）：
- 接受高对比度刺激的总试验次数为 $300+100=400$，其中神经元放电次数为 $180+30=210$。因此，$P(Y=1|X=1) = 210/400 = 0.525$。
- 接受低对比度刺激的总试验次数为 $100+300=400$，其中神经元放电次数为 $70+120=190$。因此，$P(Y=1|X=0) = 190/400 = 0.475$。

在合并数据中，边际关联差异为 $0.525 - 0.475 = +0.05$。关联的方向发生了逆转！这种现象就是[辛普森悖论](@entry_id:136589)。其根本原因在于**混淆（confounding）**。警觉性（$Z$）既影响了刺激的分配（$Z \to X$），又影响了神经元的反应（$Z \to Y$）。$Z$ 是 $X$ 和 $Y$ 的一个**[共同原因](@entry_id:266381)（common cause）**。由于高警觉性状态下神经元本身就更容易放电，并且高对比度刺激更常在该状态下出现，导致高对比度刺激与高放电率在总体上产生了虚假的正相关。

这个例子清晰地表明，为了揭示刺激对神经元反应的真实因果效应，我们必须处理[混淆变量](@entry_id:199777)的影响。这正是因果推断理论框架旨在解决的问题。

### [潜在结果框架](@entry_id:636884)

由 Donald Rubin 发展的**[潜在结果](@entry_id:753644)（Potential Outcomes）**框架，也称为Neyman-Rubin[因果模型](@entry_id:1122150)，为定义和识别因果效应提供了一种严谨的数学语言。

#### 核心概念

核心思想是为每个分析单元（unit）定义一组与其可能受到的所有处理（treatment）相对应的“潜在”结果。在一个简单的二元处理场景中，例如有或无视觉刺激，我们为每个单元（如一次[神经冲动](@entry_id:163940)发放计数试验）定义两个[潜在结果](@entry_id:753644) ：
- $Y_i(1)$：如果第 $i$ 次试验**接受**了刺激（$A_i=1$），该试验的[神经冲动](@entry_id:163940)发放计数将会是多少。
- $Y_i(0)$：如果第 $i$ 次试验**未接受**刺激（$A_i=0$），该试验的[神经冲动](@entry_id:163940)发放计数将会是多少。

对于任何一次试验，我们只能观测到这两个[潜在结果](@entry_id:753644)中的一个，即与实际接受的处理相对应的那一个。另一个则永远无法观测到，是**反事实（counterfactual）**的。

基于此，我们可以明确定义因果效应：
- **个体因果效应（Individual Causal Effect, ICE）**：对于单元 $i$，因果效应是 $Y_i(1) - Y_i(0)$。这个量在实践中无法直接计算，因为我们无法同时观测到同一个单元的两个[潜在结果](@entry_id:753644)。
- **平均[处理效应](@entry_id:636010)（Average Treatment Effect, ATE）**：在群体水平上，我们通常关心的是[平均因果效应](@entry_id:920217)，定义为 $ATE = E[Y(1) - Y(0)]$，其中期望 $E[\cdot]$ 是在目标群体中对所有单元取平均。ATE 回答了这样一个问题：“平均而言，施加处理相对于不施加处理，会对结果产生多大的影响？”

#### [因果识别](@entry_id:901515)的关键假设

为了从观测数据中估计 ATE，我们需要一系列假设来连接可观测的世界（由 $A$ 和 $Y$ 组成）与[反事实](@entry_id:923324)的[潜在结果](@entry_id:753644)世界。

1.  **一致性（Consistency）**：该假设断言，一个单元实际观测到的结果，等于其接受相应处理时的[潜在结果](@entry_id:753644)。形式化地，如果一个单元 $i$ 接受了处理 $A_i=a$，那么其观测结果 $Y_i$ 等于 $Y_i(a)$。即 $Y_i = Y_i(A_i)$。这个假设看似平凡，但它要求处理的定义必须明确无[歧义](@entry_id:276744) 。

2.  **稳定单元处理价值假设（Stable Unit Treatment Value Assumption, SUTVA）**：这是一个[复合假设](@entry_id:164787)，包含两个子假设：
    - **无干扰（No Interference）**：一个单元的[潜在结果](@entry_id:753644)不受其他单元所接受处理的影响。例如，在神经元记录中，这意味着一次试验的神经反应只取决于该次试验是否受到刺激，而不受其他试验刺激模式的影响 。在网络化的[神经回路](@entry_id:169301)中，这个假设尤其值得关注。如果一个神经元的活动会影响其邻近神经元，那么对一个神经元的刺激可能会影响邻近神经元的[潜在结果](@entry_id:753644)，从而违反SUTVA 。
    - **处理版本唯一性（No Multiple Versions of Treatment）**：这要求处理的定义是统一的。例如，“施加刺激”必须对所有接受处理的单元意味着完全相同的物理干预（如标准化的闪光强度和时长）。如果“刺激”在不同试验中有不同版本，那么 $Y(1)$ 的定义就变得模糊不清。

3.  **可交换性（Exchangeability）**：这是克服混淆问题的核心假设。
    - **边际可交换性**：在理想的**[随机对照试验](@entry_id:909406)（RCT）**中，处理组和[控制组](@entry_id:747837)的个体在所有（无论观测到与否）预处理特征上都是统计等价的。这意味着处理分配 $A$ 与[潜在结果](@entry_id:753644) $(Y(0), Y(1))$ 是统计独立的，即 $(Y(0), Y(1)) \perp A$。此时，观测到的处理组平均结果 $E[Y|A=1]$ 就是 $E[Y(1)]$ 的无偏估计，[控制组](@entry_id:747837)亦然。ATE可以直接通过 $E[Y|A=1] - E[Y|A=0]$ 计算。
    - **[条件可交换性](@entry_id:896124)（Conditional Exchangeability）**：在观测研究中，处理组和控制组通常在某些特征上存在系统性差异（即存在混淆）。[条件可交换性](@entry_id:896124)假设，一旦我们**控制**或**调整**了所有这些共同原因（[混淆变量](@entry_id:199777)，记为向量 $X$），在 $X$ 的每个特定层级内，处理分配就变得“仿佛是随机的”。形式化地，$(Y(0), Y(1)) \perp A \mid X$。这意味着在具有相同[协变](@entry_id:634097)量 $X$ 值的个体中，那些实际接受处理的个体和那些未接受处理的个体，他们的[潜在结果](@entry_id:753644)分布是相同的 。

4.  **正定性（Positivity）**或**重叠性（Overlap）**：该假设要求，对于协变量 $X$ 的每个可能取值 $x$，接受每种处理水平的概率都必须大于零。形式化地，对于所有 $x$ 和所有处理水平 $a$，必须有 $P(A=a|X=x) > 0$。如果在一个子群体中（例如，所有处于极低警觉性状态的个体），没有任何人接受过高对比度刺激，那么我们就无法从数据中直接得知在该状态下高对比度刺激的效果，任何推断都将依赖于不可靠的模型外推 。

如果以上四个假设（一致性、SUTVA、[条件可交换性](@entry_id:896124)和正定性）均成立，那么平均[处理效应](@entry_id:636010) ATE 就是**可识别的（identifiable）**。我们可以通过**调整公式（adjustment formula）**或**标准化（standardization）**来计算它，这个过程也称为**g-formula** ：
$$ATE = E[Y(1) - Y(0)] = \int \left( E[Y | A=1, X=x] - E[Y | A=0, X=x] \right) dP(x)$$
这个公式的直观含义是：我们在每个由协变量 $X=x$ 定义的同质子群体中，计算处理组和[控制组](@entry_id:747837)的平均结果差异，然后根据 $X$ 在总群体中的分布 $dP(x)$ 进行加权平均。这有效地移除了因 $X$ 分布在处理组和[控制组](@entry_id:747837)之间不均衡而导致的混淆。

### [结构因果模型](@entry_id:911144)与有向无环图

由 Judea Pearl 发展的**[结构因果模型](@entry_id:911144)（Structural Causal Model, SCM）**和**[有向无环图](@entry_id:164045)（Directed Acyclic Graph, DAG）**为因果推理提供了另一种强大的语言，它特别擅长于可视化和分析变量间的因果依赖关系。

#### 核心概念

一个SCM由一组**[结构方程](@entry_id:274644)（structural equations）**构成，每个方程描述一个变量如何由其直接原因（“父节点”）和一些未被模型化的外源随机噪声共同决定。例如，一个简单的[神经科学模型](@entry_id:1128668)可以写作 ：
- 刺激强度 $X = f_X(U_X)$
- 神经活动 $Y = f_Y(X, U_Y)$

这里，$X$ 和 $Y$ 是**内生变量（endogenous variables）**，它们的值在模型内部被决定。$U_X$ 和 $U_Y$ 是**外生变量（exogenous variables）**，它们代表了模型外部的、未解释的随机影响（如测量噪声、内在的随机波动等）。通常我们假设外生变量是[相互独立](@entry_id:273670)的。

每个SCM都唯一对应一个DAG。在图中，每个变量是一个节点，每个[结构方程](@entry_id:274644)中的因果关系被表示为一个有向箭头，从原因（父节点）指向结果（子节点）。对于上述SCM，如果假设 $U_X$ 和 $U_Y$ [相互独立](@entry_id:273670)（即 $U_X \perp U_Y$），则对应的DAG是简单的 $X \to Y$。这个箭头不仅表示了统计上的依赖，更重要的是，它编码了一个关于世界如何运作的**因果假设**。

#### `do`-算子与干预

SCM框架最强大的地方在于它对**干预（intervention）**的数学定义。一个干预，记为 **`do`-算子**，被模型化为对SCM进行的一次“手术”。执行干预 $do(X=x)$ 意味着我们从外部强行将变量 $X$ 的值固定为 $x$，并移除原先决定 $X$ 的机制。在[结构方程](@entry_id:274644)的层面上，这意味着我们将 $X$ 的方程（如 $X=f_X(U_X)$）替换为 $X=x$。在DAG的层面上，这等同于“切断”所有指向 $X$ 的箭头。

例如，考虑一个更复杂的线性SCM，其中神经调节剂水平 $X$ 和神经元放电率 $Y$ 都受到一个未观测的潜在唤醒状态 $Z$ 的影响 ：
- $X := U_X$
- $Z := U_Z$
- $Y := \theta_0 + \theta_X X + \theta_Z Z + U_Y$

假设外生噪声 $(U_X, U_Z)$ 之间存在相关性 $\text{Cov}(U_X, U_Z) = \rho \sigma_X \sigma_Z \neq 0$，而 $U_Y$ 与它们独立。这里的相关性意味着 $Z$ 是 $X$ 和 $Y$ 之间的一个混淆因子。如果我们执行干预 $do(X=x)$，SCM会变为：
- $X := x$
- $Z := U_Z$
- $Y := \theta_0 + \theta_X x + \theta_Z Z + U_Y$

在干预后的模型中，$Y$ 的分布 $p(Y|do(X=x))$ 完全由 $Z$ 和 $U_Y$ 的随机性决定。由于 $Z$ 和 $U_Y$ 都是高斯分布的，我们可以推导出 $Y$ 在干预下的分布也是一个高斯分布，其均值为 $E[Y|do(X=x)] = \theta_0 + \theta_X x + \theta_Z E[U_Z]$，方差为 $\text{Var}(Y|do(X=x)) = \theta_Z^2 \text{Var}(U_Z) + \text{Var}(U_Y)$。这个推导过程清晰地展示了干预如何通过改变系统的结构来消除混淆（$U_X$ 与 $U_Z$ 的相关性不再影响 $Y$）。

#### [d-分离](@entry_id:748152)：从图结构到[统计独立性](@entry_id:150300)

DAG的一个关键性质是，它通过一个名为**[d-分离](@entry_id:748152)（d-separation）**的图形准则，将图的结构与数据的统计性质（[条件独立性](@entry_id:262650)）联系起来。如果图中节点集合 $A$ 和 $B$ 被节点集合 $C$ [d-分离](@entry_id:748152)，那么在由该图生成的任何概率分布中，$A$ 和 $B$ 在给定 $C$ 的条件下都是条件独立的（$A \perp B \mid C$）。

[d-分离](@entry_id:748152)的规则依赖于路径上的三种基本结构：

1.  **链（Chain）**: $A \to M \to B$。如果 conditioning set（条件集）包含中间节点 $M$，则路径被**阻断**。
2.  **[分叉](@entry_id:270606)（Fork）**: $A \leftarrow M \to B$。如果条件集包含中间节点 $M$，则路径被**阻断**。
3.  **对撞（Collider）**: $A \to M \leftarrow B$。如果条件集**不**包含对撞点 $M$ 及其任何后代，则路径被**阻断**。反之，如果条件集包含 $M$ 或其任何后代，路径将变得**通畅**。

对撞点的行为是反直觉但至关重要的：两个独立的原因在给定它们的共同效应时会变得相关。这被称为“解释得通”效应（explaining away）。例如，在DAG $S \to N \leftarrow C$ 中，刺激 $S$ 和背景 $C$ 可能[相互独立](@entry_id:273670)，但如果我们知道了神经反应 $N$，那么观察到强的刺激 $S$ 可能会“解释掉”部分反应，从而降低了我们对背景 $C$ 也强的信念，反之亦然。因此，对 $N$ 进行条件化（conditioning on $N$）会打开 $S$ 和 $C$ 之间的信息通路 。

### 因果效应的识别策略

有了DAGs和[d-分离](@entry_id:748152)的工具，我们就可以系统地回答：为了估计 $X$ 对 $Y$ 的因果效应，我们需要调整哪些变量？

#### [后门准则](@entry_id:926460)

**[后门准则](@entry_id:926460)（Backdoor Criterion）**提供了一个基于DAG的、用于选择充分调整集（sufficient adjustment set）的图形化方法 。一个变量集合 $Z$ 满足相对于 $(X, Y)$ 的[后门准则](@entry_id:926460)，如果：
1.  $Z$ 中不包含 $X$ 的任何后代。
2.  $Z$ 阻断了所有从 $X$ 到 $Y$ 的**后门路径（backdoor paths）**。

后门路径是连接 $X$ 和 $Y$ 的、且起始箭头指向 $X$ 的任何路径（例如 $X \leftarrow \dots \to Y$）。这些路径代表了可能产生混淆的非因果关联。

一旦我们找到了满足[后门准则](@entry_id:926460)的集合 $Z$，我们就可以使用调整公式来识别因果效应：
$$P(Y=y | do(X=x)) = \sum_z P(Y=y | X=x, Z=z) P(Z=z)$$
这与[潜在结果框架](@entry_id:636884)下的调整公式是等价的。

让我们看一个经典的混淆例子 ，其中睡眠状态 $Z$ 影响刺激呈现 $X$ 和神经反应 $Y$，且 $X$ 也影响 $Y$。对应的DAG为 $Z \to X$, $Z \to Y$, $X \to Y$。这里存在一条后门路径 $X \leftarrow Z \to Y$。为了识别 $X$ 对 $Y$ 的因果效应，我们需要阻断这条路径。根据[d-分离](@entry_id:748152)的[分叉](@entry_id:270606)规则，对 $Z$ 进行条件化可以阻断该路径。由于 $Z$ 不是 $X$ 的后代，集合 $\{Z\}$ 满足[后门准则](@entry_id:926460)。因此，调整 $Z$ 是识别因果效应的正确策略。

#### 错误调整的危害

[后门准则](@entry_id:926460)不仅告诉我们应该调整什么，也暗示了不应该调整什么。错误地调整变量会导致偏倚，而非消除偏倚。

1.  **调整中介变量（Mediators）**：中介变量位于从原因到结果的因果路径上。例如，在模型 $X \to G \to Y$ 中，$G$（如突触增益）是 $X$ 对 $Y$ 效应的一个中介 。如果我们想估计 $X$ 对 $Y$ 的**总因果效应（total causal effect）**，就绝对不能调整 $G$。调整 $G$会阻断通过 $G$ 传递的因果路径，导致我们估计的只是 $X$ 对 $Y$ 的**直接效应（direct effect）**，这会低估总效应。只有当目标本身就是估计直接效应时，调整中介变量才是恰当的。

2.  **调整对撞点（Colliders）或其后代**：这是最危险且最违反直觉的错误之一。考虑一个场景 ，其中未测量的唤醒状态 $U$ 同时影响刺激前的alpha波功率 $X$ 和[数据质量](@entry_id:185007)指标 $C$（$X \leftarrow U \to C$）。同时，任务难度 $V$ 也影响 $C$ 和最终的检测结果 $Y$（$V \to C, V \to Y$）。$X$ 本身也影响 $Y$ ($X \to Y$)。在这个模型中，唯一的后门路径是 $X \leftarrow U \to C \leftarrow V \to Y$。注意，$C$ 是这条路径上的一个对撞点 ($U \to C \leftarrow V$)。根据[d-分离](@entry_id:748152)规则，这条路径默认是阻断的，因为我们没有对对撞点 $C$ 或其后代进行条件化。这意味着 $X$ 和 $Y$ 之间没有混淆，我们不需要调整任何变量就可以直接通过 $P(Y|X)$ 估计因果效应。
   然而，如果一个研究者认为[数据质量](@entry_id:185007) $C$ 是一个需要“控制”的变量而对其进行调整（例如，只分析高[质量数](@entry_id:142580)据，或在回归模型中加入 $C$），他就会打开这条后门路径。对 $C$ 进行条件化，会使得 $U$ 和 $V$ 变得相关，从而在 $X$ 和 $Y$ 之间创造出一条虚假的关联路径 $X \leftarrow U \leftrightarrow V \to Y$。这种偏倚被称为**[对撞偏倚](@entry_id:163186)（collider bias）**或[选择偏倚](@entry_id:172119)。这是一个强有力的警示：在因果图上，并非所有与处理和结果相关的变量都是混淆因子。有些变量（对撞点）最好保持原样。

### 神经科学中的高级主题

#### 时间序列：格兰杰因果 vs. 结构因果

在分析EEG、fMRI或神经冲动等时间序列数据时，**格兰杰因果（Granger Causality）**是一个常用概念。它是一个**预测性（predictive）**而非**干预性（interventional）**的概念。我们说时间序列 $X_t$ 格兰杰“导致”$Y_t$，如果 $X_t$ 的过去值能够帮助预测 $Y_t$ 的未来值，且这种预测能力超出了仅使用 $Y_t$ 自身过去值所能达到的水平。

然而，格兰杰因果与结构因果（即 $P(Y_{t+\ell}|do(X_t=x))$）在许多现实场景下并不等价 。两者之间存在鸿沟的主要原因有两个：
1.  **未观测的共同驱动（Unobserved Common Drivers）**：如果存在一个未测量的过程 $Z_t$ 同时驱动 $X_t$ 和 $Y_t$（可能存在不同的延迟），那么 $X_t$ 的历史可能包含关于 $Z_t$ 的信息，从而帮助预测 $Y_t$ 的未来。这会表现为从 $X$ 到 $Y$ 的格兰杰因果，即使 $X$ 对 $Y$ 没有直接的结构性因果影响。
2.  **瞬时混合（Instantaneous Mixing）**：在EEG或MEG数据中，由于**[容积传导](@entry_id:921795)（volume conduction）**，每个传感器记录到的信号实际上是多个底层神经源信号的瞬时线性混合。即使两个独立的神经源 $S_1(t)$ 和 $S_2(t)$ 之间没有因果关系，它们的混合信号 $X(t) = m_{11}S_1(t) + m_{12}S_2(t)$ 和 $Y(t) = m_{21}S_1(t) + m_{22}S_2(t)$ 也会表现出瞬时相关性，甚至可能导致虚假的格兰杰因果关系。因此，观测到的零延迟相关性并不足以断定存在瞬时因果影响。

只有在非常严格的假设下（例如，系统是线性高斯的、所有相关的变量都被测量、没有瞬时混合），格兰杰因果才能等同于结构因果。在大多数神经科学应用中，将格兰杰因果解释为真正的干预性因果关系需要极其谨慎。

#### 干扰与网络因果

SUTVA的“无干扰”假设在许多神经科学情境中可能不成立。神经元通过突触连接形成复杂的网络。对一个神经元的刺激（例如通过[光遗传学](@entry_id:175696)）几乎肯定会影响其下游神经元的活动。这意味着，神经元 $i$ 的结果 $Y_i$ 不仅取决于其自身的处理状态 $Z_i$，还取决于其邻居的处理状态 $\mathbf{Z}_{\mathcal{N}(i)}$ 。

当干扰存在时，传统的个体水平因果效应 $E[Y(1) - Y(0)]$ 变得定义不清。解决方案通常是重新定义分析的层次。
1.  **重新定义分析单元**：如果干扰主要局限于特定的神经集群（例如一个皮层柱或微回路）内部，而集群之间的干扰可以忽略（这被称为**部分干扰假设, partial interference**），那么我们可以将**整个集群**作为新的分析单元。
2.  **定义集群水平的因果效应**：我们可以定义集群水平的处理，例如“饱和刺激”（集群内所有神经元都被刺激）vs.“零刺激”（所有神经元都不被刺激）。相应的，结果可以是集群的平均活动。这样，我们就可以估计一个定义明确的集群水平因果效应，例如，饱和刺激对集群平均活动的影响。
3.  **调整[实验设计](@entry_id:142447)与分析策略**：在这种情况下，最理想的[实验设计](@entry_id:142447)是**集群[随机化](@entry_id:198186)试验（cluster-randomized trial）**，即随机地将整个集群分配到不同的处理条件下。对于观测数据，分析也应在集群水平进行，例如使用集群水平的[协变](@entry_id:634097)量来建立集群水平的倾[向性](@entry_id:144651)得分模型。

总之，从观测数据中推断因果关系是一项充满挑战但至关重要的任务。通过熟练运用[潜在结果](@entry_id:753644)和[结构因果模型](@entry_id:911144)这两个互补的框架，研究者可以更清晰地思考因果问题，明确所需的假设，识别并避免常见的分析陷阱，从而得出更可靠、更具科学意义的结论。