{
    "hands_on_practices": [
        {
            "introduction": "The cornerstone of identifying causal effects from observational data is the careful selection of covariates for statistical adjustment. This practice centers on applying the backdoor criterion, a fundamental principle that uses a Directed Acyclic Graph (DAG) to distinguish \"good\" adjustment sets from \"bad\" ones. This exercise will challenge you to identify all valid sets for estimating a total causal effect in a plausible neuroscience scenario, forcing you to consider not just confounders, but also mediators, colliders, and instruments to build a robust understanding of d-separation in practice .",
            "id": "4145163",
            "problem": "A behavioral neuroscience lab analyzes the observational effect of a non-invasive hippocampal stimulation intensity on memory performance. Let $A$ denote stimulation intensity, $Y$ denote a delayed-recall memory score, $M$ denote hippocampal theta-band power during encoding (a physiological mediator on the causal path from $A$ to $Y$), $Z_1$ denote baseline hippocampal firing rate, and $Z_2$ denote a neuroinflammation index. In addition, the dataset contains the following measured covariates: $I$ (clinic scheduling instrument that affects $A$ but not $Y$), $C$ (a case-selection indicator affected by $Z_1$ and $Z_2$ but with no direct effect on $A$ or $Y$), and $B$ (a baseline questionnaire score statistically independent of all other variables and with no causal effect on $A$ or $Y$). Assume the following Directed Acyclic Graph (DAG): there are directed edges $Z_1 \\to A$, $Z_1 \\to Y$, $Z_2 \\to A$, $Z_2 \\to Y$, $A \\to M$, $M \\to Y$, and $I \\to A$, as well as $Z_1 \\to C$ and $Z_2 \\to C$. There are no other arrows, and there is no unmeasured confounding beyond what is shown. All variables are measured without error. The target is the total causal effect of $A$ on $Y$ under the standard identifiability conditions of consistency, positivity, and the Stable Unit Treatment Value Assumption (SUTVA).\n\nUsing the backdoor criterion from causal graphical models, identify which of the following candidate covariate sets are valid adjustment sets for identifying the total effect of $A$ on $Y$ from observational data. Then, explain based on the graph why $\\{Z_1, Z_2\\}$ is a minimal valid adjustment set.\n\nSelect all that apply.\n\nA. $\\{Z_1, Z_2\\}$\n\nB. $\\{Z_1\\}$\n\nC. $\\{Z_2\\}$\n\nD. $\\{Z_1, Z_2, M\\}$\n\nE. $\\{Z_1, Z_2, C\\}$\n\nF. $\\{Z_1, Z_2, I\\}$\n\nG. $\\{Z_1, Z_2, B\\}$\n\nH. $\\{Z_1, Z_2, I, B\\}$\n\nProvide your reasoning starting from the definitions of d-separation and the backdoor criterion, and argue why $\\{Z_1, Z_2\\}$ is minimal for the total effect in this graph without introducing bias or blocking any part of the causal effect of $A$ on $Y$.",
            "solution": "We begin from first principles. In a Directed Acyclic Graph (DAG), a path is blocked by a set of nodes if either (i) the path contains a non-collider that is conditioned on, or (ii) the path contains a collider that is not conditioned on and none of its descendants are conditioned on. Two sets of variables are said to be d-separated given a conditioning set if every path between them is blocked by that conditioning set. The backdoor criterion states: a set $\\mathcal{S}$ is a valid adjustment set for the total effect of $A$ on $Y$ if (i) no element of $\\mathcal{S}$ is a descendant of $A$, and (ii) $\\mathcal{S}$ blocks every backdoor path from $A$ to $Y$ (that is, every path between $A$ and $Y$ that starts with an arrow into $A$). Under consistency, positivity, and the Stable Unit Treatment Value Assumption (SUTVA), if the backdoor criterion holds, then the total effect is identified by adjustment on $\\mathcal{S}$.\n\nWe now analyze the given DAG. The causal (front-door) paths from $A$ to $Y$ are $A \\to M \\to Y$. We must not block any causal path when the target is the total effect; in particular, we must not adjust for the mediator $M$ or any descendant of $A$.\n\nThe backdoor paths from $A$ to $Y$ are those that begin with an arrow into $A$. From the graph:\n- There is a backdoor path $A \\leftarrow Z_1 \\to Y$.\n- There is a backdoor path $A \\leftarrow Z_2 \\to Y$.\n- There is a backdoor structure involving the collider $C$: $A \\leftarrow Z_1 \\to C \\leftarrow Z_2 \\to Y$. This path is blocked by default at the collider $C$, but if we condition on $C$ (or its descendants, none of which are present), we would open this path and thereby induce bias.\n- The variable $I$ is an instrument with $I \\to A$ only and no path from $I$ to $Y$ other than through $A$. There is no backdoor path through $I$ because $I$ has no parents and no arrows to $Y$.\n\nThus, to block all backdoor paths, it suffices to adjust for $Z_1$ and $Z_2$, provided we do not condition on colliders like $C$ or descendants of $A$ like $M$.\n\nWe evaluate each candidate set with respect to the backdoor criterion.\n\nOption A: $\\{Z_1, Z_2\\}$. This set contains no descendants of $A$. Conditioning on $Z_1$ blocks $A \\leftarrow Z_1 \\to Y$, and conditioning on $Z_2$ blocks $A \\leftarrow Z_2 \\to Y$. The collider path through $C$ remains blocked because we are not conditioning on $C$ or any descendant of $C$. Therefore, all backdoor paths are blocked, and no causal paths are blocked. Verdict: Correct.\n\nOption B: $\\{Z_1\\}$. This conditions on $Z_1$ but not $Z_2$, leaving the backdoor path $A \\leftarrow Z_2 \\to Y$ unblocked. Therefore, bias remains. Verdict: Incorrect.\n\nOption C: $\\{Z_2\\}$. Symmetric to Option B, this leaves the backdoor path $A \\leftarrow Z_1 \\to Y$ unblocked. Verdict: Incorrect.\n\nOption D: $\\{Z_1, Z_2, M\\}$. Although $\\{Z_1, Z_2\\}$ blocks all backdoor paths, adding $M$ conditions on a mediator on the causal path $A \\to M \\to Y$. For the total effect, this would block part of the causal effect and identify only the controlled direct effect under this adjustment, not the total effect. Moreover, the backdoor criterion requires the set contain no descendants of $A$. Since $M$ is a descendant of $A$, this violates the criterion. Verdict: Incorrect.\n\nOption E: $\\{Z_1, Z_2, C\\}$. Conditioning on $C$ opens the collider path $A \\leftarrow Z_1 \\to C \\leftarrow Z_2 \\to Y$, creating a new backdoor path from $A$ to $Y$ that induces spurious association. Therefore, even though $Z_1$ and $Z_2$ are included, adding $C$ introduces bias. Verdict: Incorrect.\n\nOption F: $\\{Z_1, Z_2, I\\}$. Adding $I$ to $\\{Z_1, Z_2\\}$ does not introduce any new open backdoor paths because $I$ is not a descendant of $A$, is not a collider, and has no path to $Y$ except through $A$. The set blocks all backdoor paths and does not block any causal path. While superfluous for identification, it remains a valid adjustment set. Verdict: Correct.\n\nOption G: $\\{Z_1, Z_2, B\\}$. The variable $B$ is independent of all variables and has no causal relations; conditioning on $B$ does not open or close any paths. Therefore, this set still blocks the necessary backdoor paths via $Z_1$ and $Z_2$ and does not block any causal path. Verdict: Correct.\n\nOption H: $\\{Z_1, Z_2, I, B\\}$. By the same reasoning as for Options F and G, adding $I$ and $B$ to $\\{Z_1, Z_2\\}$ does not create bias or block causal paths. The backdoor paths remain blocked, and no descendants of $A$ nor colliders are conditioned on. Verdict: Correct.\n\nWhy $\\{Z_1, Z_2\\}$ is minimal: A valid adjustment set is minimal if no proper subset of it is also a valid adjustment set. Consider the two proper subsets $\\{Z_1\\}$ and $\\{Z_2\\}$. The set $\\{Z_1\\}$ fails to block the backdoor path $A \\leftarrow Z_2 \\to Y$, leaving confounding by $Z_2$ unaddressed. The set $\\{Z_2\\}$ fails to block the backdoor path $A \\leftarrow Z_1 \\to Y$, leaving confounding by $Z_1$ unaddressed. The empty set and any other proper subset (e.g., $\\varnothing$) trivially fail as well. Therefore, $\\{Z_1, Z_2\\}$ is the smallest set that blocks all backdoor paths and contains no descendants of $A$ or colliders, making it minimal for identifying the total effect. Any strict superset of $\\{Z_1, Z_2\\}$ that does not include forbidden variables like $M$ or $C$ is also valid but not minimal; such supersets (e.g., $\\{Z_1, Z_2, I\\}$, $\\{Z_1, Z_2, B\\}$) do not change the d-separation between $A$ and $Y$ but can affect statistical efficiency without affecting identifiability.",
            "answer": "$$\\boxed{AFGH}$$"
        },
        {
            "introduction": "Building on the principles of covariate adjustment, this next practice explores a common and perilous pitfall: adjusting for a variable that lies on the causal pathway. In this hypothetical study, we examine why conditioning on a mediator can be disastrous, not only because it blocks the causal effect of interest, but because it can actively introduce bias by opening a spurious statistical path through an unmeasured confounder. This phenomenon, known as endogenous selection bias or collider-stratification bias, is a crucial concept for any researcher conducting mediation analysis or estimating total effects from complex observational data .",
            "id": "4145232",
            "problem": "An observational neuroscience study aims to estimate the total effect of a neurochemical exposure $X$ (for example, baseline tonic dopaminergic tone measured indirectly from positron emission tomography) on a behavioral outcome $Y$ (for example, reaction time variability on a sustained attention task). A biomarker $M$ (for example, striatal functional connectivity measured via resting-state functional magnetic resonance imaging) is known to be affected by $X$ and, in turn, to affect $Y$. There exists an unmeasured latent factor $U$ (for example, arousal or sleep quality) that influences both $M$ and $Y$. The assumed causal structure is represented by a Directed Acyclic Graph (DAG): $X \\to M \\to Y$, $U \\to M$, $U \\to Y$, and there are no arrows into $X$ from $U$ or elsewhere. The investigator considers adjusting for $M$ when estimating the total effect of $X$ on $Y$ from the observational data.\n\nStarting from the fundamental definitions of the total effect $\\mathbb{E}[Y \\mid do(X=x)]$, $d$-separation, and the backdoor criterion, and without invoking shortcut formulas, reason through the causal pathways in the DAG to determine whether adjusting for $M$ when estimating the total effect of $X$ on $Y$ induces bias. Your reasoning should include the role of colliders and conditional dependence. Optionally, for concreteness, you may consider a linear Structural Equation Model (SEM) consistent with the DAG: $M = \\alpha X + \\gamma U + \\varepsilon_M$, $Y = \\beta M + \\delta U + \\varepsilon_Y$, with $X \\perp\\!\\!\\!\\perp U$, and $\\varepsilon_M$, $\\varepsilon_Y$ independent mean-zero errors.\n\nWhich of the following statements best explains why adjusting for $M$ when estimating the total effect of $X$ on $Y$ induces bias in the presence of unmeasured confounding $U$ of $M$ and $Y$ under the given DAG?\n\nA. Conditioning on $M$ opens the blocked collider path $X \\to M \\leftarrow U \\to Y$, creating conditional dependence between $X$ and $U$; because $U$ affects $Y$, this induces a backdoor path from $X$ to $Y$ and biases the estimate, while also blocking the causal path $X \\to M \\to Y$ that is part of the total effect.\n\nB. Adjusting for $M$ breaks the association between $U$ and $Y$, thereby removing confounding and yielding an unbiased estimate of the total effect of $X$ on $Y$.\n\nC. Adjusting for $M$ cannot bias the estimate because $U$ does not affect $X$; therefore, there is no backdoor path from $X$ to $Y$ to worry about.\n\nD. Bias arises only if $U$ also causes $X$; with $U \\to M$ and $U \\to Y$ alone, adjustment for $M$ is safe and does not induce bias.",
            "solution": "The total effect of $X$ on $Y$ is defined by the intervention $do(X=x)$, and our goal is to identify $\\mathbb{E}[Y \\mid do(X=x)]$ from observational data. We analyze the causal pathways in the given Directed Acyclic Graph (DAG) using the rules of d-separation.\n\nIn the graph, there are two paths from the exposure $X$ to the outcome $Y$:\n1.  **The causal path:** $X \\to M \\to Y$. This path transmits the entire total effect of $X$ on $Y$.\n2.  **The non-causal path:** $X \\to M \\leftarrow U \\to Y$. On this path, the mediator $M$ is a collider, as two arrows point into it ($X \\to M$ and $U \\to M$).\n\n**Analysis without adjusting for $M$:** When we do not condition on any variables, the causal path $X \\to M \\to Y$ is open, allowing the causal association to be observed. The non-causal path $X \\to M \\leftarrow U \\to Y$ is blocked by the collider $M$. Since there are no other confounding paths (i.e., no backdoor paths from $X$ to $Y$), the observed association between $X$ and $Y$ is equal to the causal effect. Thus, no adjustment is necessary.\n\n**Analysis when adjusting for $M$:** When we condition on the mediator $M$, two things happen:\n1.  Conditioning on the intermediate node $M$ on the causal path $X \\to M \\to Y$ **blocks this path**. This is a critical error, as it prevents the estimation of the very effect we want to measure—the total effect transmitted through $M$.\n2.  Conditioning on the collider $M$ on the path $X \\to M \\leftarrow U \\to Y$ **opens this path**. This creates a spurious statistical association between $X$ and the unmeasured confounder $U$. Because $U$ is a cause of $Y$, this open path induces a non-causal association between $X$ and $Y$, introducing bias. This phenomenon is known as collider-stratification bias.\n\nTherefore, adjusting for $M$ is incorrect for two reasons: it blocks the causal effect of interest and simultaneously induces confounding bias.\n\n**Evaluating the options:**\n*   **A:** This statement correctly identifies both critical issues: conditioning on the mediator $M$ opens the collider path $X \\to M \\leftarrow U \\to Y$, creating bias, and it also blocks the causal path $X \\to M \\to Y$. This is a complete and accurate explanation.\n*   **B:** This is incorrect. Adjusting for $M$ does not break the association between $U$ and $Y$; it induces an association between $X$ and $U$, creating confounding.\n*   **C:** This is incorrect. The absence of a pre-existing backdoor path from $X$ to $Y$ does not mean adjustment is safe. The act of conditioning on a collider *creates* a confounding pathway.\n*   **D:** This is incorrect. It wrongly assumes that confounding can only occur through a common cause of $X$ and $Y$. It fails to account for collider bias, which is the precise issue here.",
            "answer": "$$\\boxed{A}$$"
        },
        {
            "introduction": "Even with a correctly specified causal graph and a valid adjustment strategy, causal inference can be undermined by the characteristics of the data itself. This final practice moves from graphical theory to the practical challenge of the positivity assumption, which requires that for any given set of characteristics, there is a non-zero probability of receiving any level of the treatment. Through a realistic electroencephalography (EEG) study scenario, you will learn to diagnose violations of positivity by inspecting propensity scores and to apply standard remedies like weight truncation or sample trimming, ensuring your causal estimates are both statistically sound and well-defined .",
            "id": "4145210",
            "problem": "An observational electroencephalography (EEG) study aims to estimate the average causal effect of sedative exposure on subsequent alpha-band power. Let the binary exposure be denoted by $A \\in \\{0,1\\}$, the outcome by $Y$, and baseline covariates by the vector $X$. The vigilance state at baseline is categorized into three strata $V \\in \\{v_1, v_2, v_3\\}$ derived from EEG features and clinical observations prior to exposure. Investigators fit a propensity score model for the probability of exposure, $e(X) = \\mathbb{P}(A=1 \\mid X)$, and obtain estimated scores $\\hat{e}(X)$ for all units. In preliminary diagnostics, they find that in stratum $V=v_3$, the treated group’s $\\hat{e}(X)$ values are concentrated near $1$, whereas the control group’s $\\hat{e}(X)$ values are concentrated near $0$, while in $V=v_1$ there appears to be good overlap.\n\nFrom first principles of causal inference in observational studies, the positivity assumption requires that for all covariate values $x$ with positive probability in the target population, both exposure levels have nonzero probability: $0  \\mathbb{P}(A=a \\mid X=x)  1$ for $a \\in \\{0,1\\}$. Violations typically manifest as extreme estimated propensity scores near $0$ or $1$ and lack of common support between exposed and unexposed groups conditional on $X$ (or within meaningful strata such as $V$). Investigators wish to diagnose potential positivity violations by inspecting the estimated propensity scores and overlap plots across vigilance strata, and propose scientifically justifiable remedies.\n\nWhich of the following procedures are appropriate for diagnosing and addressing positivity violations in this EEG study? Select all that apply.\n\nA. Within each vigilance stratum $V=v$, overlay histograms or kernel density plots of $\\hat{e}(X)$ separately for $A=1$ and $A=0$, and flag strata where the supports are disjoint or concentrated near $0$ or $1$. As a remedy, truncate extreme inverse probability weights at the tails (for example at the $1\\%$ and $99\\%$ quantiles) and report sensitivity of estimates to this truncation.\n\nB. In strata with poor overlap, restrict the analysis to the region of common support by design-based subsampling or matching so that the empirical distribution of $X$ among $A=1$ and $A=0$ is more similar within $V=v$. Explicitly redefine and document the target estimand for the trimmed population.\n\nC. Quantify extremity by computing, for each stratum $V=v$, the proportions of units with $\\hat{e}(X)  \\epsilon$ or $\\hat{e}(X)  1-\\epsilon$ for a small $\\epsilon  0$, and examine the distribution of inverse probability weights. If a heavy tail is present and the effective sample size is small, consider weight truncation and overlap-based trimming.\n\nD. To improve overlap, add EEG features measured after exposure (for example, immediate post-sedation spectral changes) to the propensity score model so that $\\hat{e}(X)$ for treated and control units are more intermixed across $V$.\n\nE. Fit increasingly flexible propensity score models (for example, higher-order polynomials and interactions) until the $\\hat{e}(X)$ values lie strictly between $0.1$ and $0.9$ for all units, and proceed without any design changes, under the rationale that model flexibility resolves positivity.",
            "solution": "The problem concerns the positivity assumption, a fundamental prerequisite for unbiased estimation of causal effects from observational data. Positivity requires that for any given set of covariates $X=x$, there is a non-zero probability of being both treated and untreated; formally, $0  \\mathbb{P}(A=1 \\mid X=x)  1$. A violation of this assumption means that for some subjects, treatment assignment is nearly deterministic, making it impossible to find comparable subjects in the opposing treatment group. In methods like Inverse Probability of Treatment Weighting (IPTW), this leads to extremely large weights, which inflate the variance of the effect estimator and make it unstable. The diagnostic in stratum $V=v_3$ suggests a practical violation of positivity.\n\nWe evaluate the proposed procedures for diagnosing and addressing this issue:\n\n*   **A:** This is a standard and appropriate procedure. Overlaying propensity score distributions for treated and control groups is the canonical visual diagnostic for overlap. Weight truncation is a widely accepted remedy to reduce variance from extreme weights, at the cost of introducing some bias. Performing a sensitivity analysis to the truncation level is best practice to assess the robustness of the findings.\n*   **B:** This is also a standard and appropriate procedure. Restricting the analysis to the \"region of common support\" (i.e., trimming the sample) is another valid way to handle positivity violations. It strengthens the positivity assumption within the analyzed sample. Crucially, this changes the target of inference from the Average Treatment Effect (ATE) in the full population to the ATE in the trimmed, \"overlap\" subpopulation. The procedure correctly states that this change in the estimand must be explicitly documented.\n*   **C:** This procedure describes excellent quantitative diagnostics that complement the visual approach in A. Calculating the proportion of subjects with extreme scores and examining the weight distribution (including calculating the effective sample size) are key steps in assessing the severity of the positivity violation. Proposing to consider truncation or trimming based on these quantitative findings represents a rigorous and systematic workflow.\n*   **D:** This procedure is fundamentally incorrect. The propensity score model must only include pre-exposure covariates. Including a post-exposure variable, which may be on the causal pathway from the treatment to the outcome (a mediator) or affected by both the treatment and other factors (a collider), introduces severe bias. The goal is to balance pre-treatment confounders, not to artificially force overlap using post-treatment data.\n*   **E:** This procedure is based on a misunderstanding of the problem. Positivity is a property of the data-generating process, not the statistical model. A better, more flexible model should more accurately reflect reality. If the true propensity scores are near 0 or 1 for some subjects, a good model will estimate them as such, correctly revealing the positivity problem, not solving it. Intentionally misspecifying the model to force scores away from the boundaries is unprincipled and will likely fail to adequately control for confounding, leading to bias.",
            "answer": "$$\\boxed{ABC}$$"
        }
    ]
}