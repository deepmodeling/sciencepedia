## 引言
在神经科学、心理学及临床研究中，数据常常呈现出固有的层级结构，例如在多名被试中进行多次[重复测量](@entry_id:896842)。对这类分层（或称嵌套）数据进行分析是现代科学研究中的一个核心挑战。传统的统计方法，如普通[线性回归](@entry_id:142318)，由于其对观测独立性的严格假设，在处理此[类数](@entry_id:156164)据时往往会得出错误甚至误导性的结论。

[线性混合效应模型](@entry_id:917842)（Linear Mixed-effects Models, LMMs）应运而生，为这一难题提供了强大而灵活的解决方案。它通过显式地对数据中不同层级的变异来源进行建模，不仅克服了传统方法的局限性，还为探索个体差异提供了前所未有的深度。

本文旨在为研究生及研究人员提供一份关于LMM的综合指南。在**“原理与机制”**一章中，我们将解构LMM的数学基础，阐明固定效应与随机效应的关键区别，并探讨其核心优势——“[部分池化](@entry_id:165928)”。随后，在**“应用与跨学科连接”**一章中，我们将通过神经科学、心理测量学和临床科学中的丰富实例，展示如何应用LMM分析嵌套与[交叉设计](@entry_id:898765)、纵向数据，以及检验跨层次的[交互作用](@entry_id:164533)。最后，**“动手实践”**一章将通过具体问题，帮助读者巩固模型设定、参数解释和[模型比较](@entry_id:266577)等关键技能。

通过学习本章，您将能够理解为何以及如何使用LMM来分析复杂的[分层数据](@entry_id:894735)，从而提升您研究的统计严谨性和科学洞察力。让我们首先深入LMM的内部，探究其基本原理与运作机制。

## 原理与机制

在理解了[分层数据](@entry_id:894735)在神经科学中的普遍性之后，我们现在深入探讨用于分析此[类数](@entry_id:156164)据的核心统计框架——[线性混合效应模型](@entry_id:917842)（Linear Mixed-effects Models, LMMs）的原理与机制。本章将系统地解构这些模型，阐明它们如何克服传统方法的局限性，并提供对复杂生物数据更深刻、更准确的见解。

### 分层结构：传统[线性模型](@entry_id:178302)的失效

在许多神经科学实验中，数据天然地呈现出嵌套或分层的结构。例如，在一个多被试[电生理学](@entry_id:156731)研究中，我们可能记录了每个被试（subject）体内多个神经元（neuron）在多次刺激呈现（trial）下的反应。这构成了一个三层结构：**试次嵌套在神经元内，神经元嵌套在被试内** 。其他常见的例子包括在功能[磁共振成像](@entry_id:153995)（fMRI）研究中，多次试次或扫描时间点嵌套在被试内；或是在[动物研究](@entry_id:168816)中，试次嵌套在动物个体中。

这种[数据结构](@entry_id:262134)对传统的统计方法，如[普通最小二乘法](@entry_id:137121)（Ordinary Least Squares, OLS）回归，构成了根本性的挑战。OLS的一个核心假设，即[高斯-马尔可夫定理](@entry_id:138437)（Gauss-Markov theorem）中的一项，是观测的误差项是相互独立的。然而，在[分层数据](@entry_id:894735)中，来自同一聚类（cluster，例如同一个被试或同一个神经元）的观测值几乎总是相关的。来自同一个被试的多次测量的反应可能共同受到该被试独特的生理特征、注意力水平或遗传背景的影响。同样，来自同一个神经元的多次放电计数会共享该神经元固有的发放率和调谐特性。

这种内部相关性意味着，如果我们简单地将所有试次汇集起来进行OLS回归，我们就违反了独立性假设。让我们用一个更具体的模型来阐明这一点。考虑一个[三层模型](@entry_id:1133441)，其中试次 $i$ 的响应 $y_{sni}$ 来自被试 $s$ 的神经元 $n$：

$$y_{sni} = (\text{固定效应}) + b_{0s} + b_{0sn} + \dots + \epsilon_{sni}$$

这里，$b_{0s}$ 是一个被试特有的[随机效应](@entry_id:915431)（例如，该被试的平均反应水平与总体平均水平的偏差），$b_{0sn}$ 是一个神经元特有的[随机效应](@entry_id:915431)（例如，该神经元的基础发放率与该被试其他神经元的平均水平的偏差），而 $\epsilon_{sni}$ 是试次层面的独立噪声。对于来自同一个神经元的两次不同试次 $i$ 和 $j$，它们的响应 $y_{sni}$ 和 $y_{snj}$ 共享了相同的随机效应 $b_{0s}$ 和 $b_{0sn}$。因此，它们的协方差不为零：

$$\mathrm{Cov}(y_{sni}, y_{snj}) = \mathrm{Var}(b_{0s}) + \mathrm{Var}(b_{0sn}) + \dots \neq 0$$

这种非零协方差意味着观测值之间存在依赖，违反了OLS的假设。其直接后果是，虽然OLS估计的系数可能仍然是无偏的（在某些条件下），但其[标准误](@entry_id:635378)几乎肯定是错误的（通常是过分乐观地偏小），从而导致无效的假设检验和[置信区间](@entry_id:142297)  。

#### [组内相关系数](@entry_id:915664)（ICC）

量化这种聚类效应强度的一个有用指标是**[组内相关系数](@entry_id:915664)**（**Intraclass Correlation Coefficient, ICC**）。在一个简单的两层[随机截距模型](@entry_id:903767)中，响应 $y_{ij}$（例如，被试 $i$ 在试次 $j$ 的事件相关电位 ERP 峰值振幅）可以被建模为：

$$y_{ij} = \beta_0 + b_i + \varepsilon_{ij}$$

其中，$b_i \sim \mathcal{N}(0, \sigma_b^2)$ 是被试的随机截距，代表了被试间的变异；$\varepsilon_{ij} \sim \mathcal{N}(0, \sigma^2)$ 是试次间的残差变异。一个观测的总方差是 $\mathrm{Var}(y_{ij}) = \sigma_b^2 + \sigma^2$。来自同一被试的两次不同试次的协方差是 $\mathrm{Cov}(y_{ij}, y_{ik}) = \sigma_b^2$。

因此，ICC被定义为来自同一组的两个随机选择的观测值之间的相关性：

$$\mathrm{ICC} = \frac{\mathrm{Cov}(y_{ij}, y_{ik})}{\sqrt{\mathrm{Var}(y_{ij})\mathrm{Var}(y_{ik})}} = \frac{\sigma_b^2}{\sigma_b^2 + \sigma^2}$$

ICC的取值范围为0到1，它有两个直观的解释 ：
1.  它代表了由组间（例如，被试间）差异所能解释的总方差的比例。
2.  它是来自同一组的任意两个观测值之间的预期相关性。

例如，如果一项EEG研究的[方差分量](@entry_id:267561)估计为被试间方差 $\widehat{\sigma}_b^2 = 4$ 和试次间方差 $\widehat{\sigma}^2 = 6$，那么 $\mathrm{ICC} = 4 / (4+6) = 0.40$。这意味着总变异的 $40\%$ 来自于被试之间的系统性差异，并且我们预期来自同一被试的任意两次ERP振幅测量值的相关性约为 $0.40$。一个显著不为零的ICC证实了数据中存在聚类效应，必须在模型中加以说明。

### [线性混合效应模型](@entry_id:917842)的通用结构

[线性混合效应模型](@entry_id:917842)（LMM）通过显式地对数据中的这种多层变异来源进行建模，从而优雅地解决了这个问题。其通用矩阵形式为：

$$\mathbf{y} = X\boldsymbol{\beta} + Z\mathbf{b} + \boldsymbol{\varepsilon}$$

让我们仔细剖析这个方程的每个组成部分  。

-   $\mathbf{y}$ 是一个包含了所有观测值的向量（例如，所有被试在所有试次中的[fMRI BOLD信号](@entry_id:193498)变化百分比）。
-   $X\boldsymbol{\beta}$ 是模型的**固定效应**（**fixed effects**）部分。
    -   $\boldsymbol{\beta}$ 是一个包含 $p$ 个固定效应系数的向量。这些系数代表了**群体平均**（**population-average**）的关系。例如，在一个任务中，$\beta_1$ 可能代表刺激强度对神经反应的平均影响，这个影响是在整个目标群体中平均而言的。
    -   $X$ 是一个 $n \times p$ 的**固定效应[设计矩阵](@entry_id:165826)**，它将相应的固定效应系数与每个观测值联系起来。
-   $Z\mathbf{b}$ 是模型的**随机效应**（**random effects**）部分。
    -   $\mathbf{b}$ 是一个包含 $q$ 个[随机效应](@entry_id:915431)的向量。与代表固定常数的 $\boldsymbol{\beta}$ 不同，这些随机效应被视为**从一个概率分布中抽取的[随机变量](@entry_id:195330)**，通常是均值为零的正态分布，即 $\mathbf{b} \sim \mathcal{N}(0, G)$。它们捕捉了各个聚类（例如，每个被试）与群体平均之间的**特定偏差**。
    -   $Z$ 是一个 $n \times q$ 的**[随机效应](@entry_id:915431)[设计矩阵](@entry_id:165826)**。它的结构至关重要，因为它指定了哪些[随机效应](@entry_id:915431)影响哪些观测值。例如，为了给每个被试 $i$ 分配一个随机截距 $b_{0i}$，矩阵 $Z$ 中会有一列，该列中凡是属于被试 $i$ 的观测行都为1，其余为0。为了给被试 $i$ 分配一个关于预测变量 $x$ 的[随机斜率](@entry_id:1130554) $b_{1i}$，矩阵 $Z$ 中会有另一列，该列中属于被试 $i$ 的观测行的值为对应的 $x_{ij}$ 值，其余为0 。
-   $\boldsymbol{\varepsilon}$ 是[残差向量](@entry_id:165091)，通常假设 $\boldsymbol{\varepsilon} \sim \mathcal{N}(0, R)$。在最简单的情况下，$R = \sigma^2I$，表示观测在考虑了固定和[随机效应](@entry_id:915431)后是独立的且方差恒定。

#### 固定效应 vs. [随机效应](@entry_id:915431)：一个关键的区别

决定将一个因素（如“被试”）建模为固定效应还是随机效应，是LMM应用中的一个核心决策，它取决于研究目标和抽样设计 。

-   当一个因素的水平被视为从一个更大的潜在群体中**随机抽样**的代表，并且研究的**目标是推广**到该群体的未见过的成员时，该因素应被建模为**随机效应**。例如，在临床研究中招募的被试通常被看作是更广泛患者群体的一个样本。我们关心的不是这几个特定被试的效果，而是整个群体的变异性有多大，以及对未来的新被试做出推断。
-   当一个因素的水平是固定的、穷尽了所有感兴趣的水平，或者研究的**目标仅限于推断**实验中包含的这些特定水平时，该因素应被建模为**固定效应**。例如，实验中使用的两种刺激条件（如“低对比度”和“高对比度”）通常是固定的，因为研究者对这两种特定条件之间的差异感兴趣，而不是要推广到所有可能的对比度水平。

### 池化谱系：从完全池化到[部分池化](@entry_id:165928)

为了更深入地理解LMM的威力，我们可以将其置于一个“池化”（pooling）的光谱上进行考察。“池化”指的是我们如何利用或忽略数据的分组结构来估计模型参数 。

-   **完全池化（Complete Pooling）**：这种方法完全忽略数据的分组结构，将所有数据汇集在一起拟合一个模型（例如，一个简单的OLS回归）。这种方法假设所有组（例如，所有动物）都是相同的。如果组间确实存在差异，这种方法会因忽略了观测间的依赖性而导致[标准误](@entry_id:635378)被低估，从而增加[假阳性](@entry_id:197064)错误率 。

-   **无池化（No Pooling）**：这种方法与完全池化相反，它为每个组拟合一个完全独立的模型（等同于将组别作为固定效应处理）。例如，为每个动物单独进行一次回归。这种方法承认了组间的差异，但它存在严重问题：
    1.  它无法实现对群体的泛化推断。
    2.  对于数据点较少的组，其[参数估计](@entry_id:139349)会非常不稳定且不可靠。
    3.  它“花费”了大量的自由度来为每个组估计单独的参数。

-   **[部分池化](@entry_id:165928)（Partial Pooling）**：LMM采用的正是这种折衷策略。对于每个组的效应（例如，动物 $j$ 的截距 $\alpha_j$），其估计值并不是完全由该组的数据决定（如“无池化”），也不是完全由所有数据决定（如“完全池化”），而是这两者的**加权平均**。这个估计值会从该组自身的均值向着所有组的[总体均值](@entry_id:175446)“收缩”（shrinkage）。

这种收缩的程度是自适应的：
-   对于拥有大量数据点的组，其估计值会更接近其自身的均值（收缩较少）。
-   对于数据点很少的组，其估计值会更多地“借用”来自总体的信息，从而更接近[总体均值](@entry_id:175446)（收缩较多）。

数学上，一个组 $j$ 的随机效应的估计值（称为**最佳线性无偏预测**，**Best Linear Unbiased Predictor, BLUP**）可以表示为：

$$\hat{\alpha}_j^{\text{LMM}} = w_j \hat{\alpha}_j^{\text{No-pooling}} + (1 - w_j) \hat{\mu}_{\alpha}$$

其中，$\hat{\alpha}_j^{\text{No-pooling}}$ 是仅使用组 $j$ 数据得到的估计，$\hat{\mu}_{\alpha}$ 是[总体均值](@entry_id:175446)的估计。权重 $w_j$ 依赖于组内样本量 $n_j$ 和[组间方差](@entry_id:900909)与[组内方差](@entry_id:177112)的比值。当 $n_j \to \infty$ 时，权重 $w_j \to 1$，LMM的估计收敛于无池化估计 。这种在偏差（向[总体均值](@entry_id:175446)收缩）和方差（通过借用信息来稳定估计）之间的优化权衡，使得BLUP在最小化均方预测误差方面优于两个极端，是LMM的核心优势之一 。

### 对变异性的精细建模

LMMs不仅能处理简单的分组，还能对变异的复杂模式进行精细建模。

#### [随机斜率](@entry_id:1130554)与截距-斜率协方差

除了允许每个被试有自己的基线（**随机截距**），我们还可以允许每个被试对某个预测变量的敏感度不同（**[随机斜率](@entry_id:1130554)**）。例如，在研究反应时与任务难度 $x_{it}$ 的关系时，模型可以写成：

$$y_{it} = (\beta_0 + b_{0i}) + (\beta_1 + b_{1i})x_{it} + \varepsilon_{it}$$

这里，$b_{0i}$ 是被试 $i$ 的随机截距偏差，而 $b_{1i}$ 是其[随机斜率](@entry_id:1130554)偏差。$\beta_1$ 代表群体平均的难度效应，而 $\beta_1+b_{1i}$ 则是被试 $i$ 特有的难度效应 。

更进一步，模型可以估计随机截距和[随机斜率](@entry_id:1130554)之间的**协方差** $\tau_{01} = \mathrm{Cov}(b_{0i}, b_{1i})$。这个参数本身就具有重要的科学意义 ：
-   **在被试间的解释**：$\tau_{01}$ 量化了基线水平和任务敏感度之间的关系。例如，一个正的 $\tau_{01}$ 可能意味着那些基线反应时较慢的被试（$b_{0i}$ 大），其反应时也更容易受到任务难度增加的影响（$b_{1i}$ 大）。
-   **在被试内的影响**：这个协方差还会影响数据内部的方差-协方差结构。对于同一个被试内的两次试次 $t$ 和 $t'$，其响应的协方差变为：

    $$\mathrm{Cov}(y_{it}, y_{it'}) = \tau_0^2 + \tau_1^2 x_{it} x_{it'} + \tau_{01}(x_{it}+x_{it'})$$

    其中 $\tau_0^2$ 和 $\tau_1^2$ 分别是随机截距和斜率的方差。这表明，被试内观测值的相关性现在不仅是恒定的，还依赖于预测变量 $x$ 的具体值。

### 避免常见的分析陷阱

采用LMMs的一个主要动机是避免使用更简单但有缺陷的方法所导致的严重统计谬误。

#### [聚合谬误](@entry_id:271620)（Aggregation Fallacy）

一个常见的错误是，为了处理[分层数据](@entry_id:894735)，研究者首先计算每个被试的平均响应 $\bar{y}_i$ 和平均预测值 $\bar{x}_i$，然后对这些平均值进行回归。这种方法极其危险，因为它可能导致**[聚合谬误](@entry_id:271620)**或**[生态谬误](@entry_id:923927)**（**ecological fallacy**）。

问题在于，对聚[合数](@entry_id:263553)据（被试平均值）的回归所估计的是**被试间效应**（between-subject effect），而研究者真正关心的往往是**被试内效应**（within-subject effect），即对于一个给定的个体，当 $x$ 变化时 $y$ 如何变化。这两个效应可能完全不同，甚至符号相反。

LMM通过直接对试次级数据进行建模来避免这个问题。通过在模型中同时包含被试均值中心化的预测变量 $(x_{ij} - \bar{x}_i)$ 和被试均值 $\bar{x}_i$ 作为固定效应，LMM甚至可以同时、无偏地估计出被试内效应和被试间效应，从而清晰地分离这两种信息来源 。此外，聚合数据还会丢失大量信息，从而降低[统计功效](@entry_id:197129)，并且在每位被试的试次数量不同时会引入难以处理的[异方差性](@entry_id:895761)。

### 模型的假设及其影响

最后，理解LMM的统计假设对于正确解释其结果至关重要。标准的LMM假设[随机效应](@entry_id:915431)和残差都服从正态分布 ：

$$ \mathbf{b} \sim \mathcal{N}(0, G) \quad \text{and} \quad \boldsymbol{\varepsilon} \sim \mathcal{N}(0, R) $$

重要的是要区分哪些推断结果强烈依赖于此[正态性假设](@entry_id:170614)，哪些则不那么依赖：

-   **对[正态性假设](@entry_id:170614)不敏感的方面**：
    -   固定效应系数 $\boldsymbol{\beta}$ 的估计（通过[广义最小二乘法](@entry_id:272590) GLS）是**最佳线性[无偏估计](@entry_id:756289)**（BLUE），这仅要求均值和方差结构被正确指定。
    -   随机效应 $\mathbf{b}$ 的预测（BLUPs）是**最佳线性无偏预测**，这也仅依赖于二阶矩（均值和方差）。
    -   在大样本情况下，使用稳健（“三明治”）[标准误](@entry_id:635378)，可以对固定效应进行有效的推断，即使[正态性假设](@entry_id:170614)不成立。

-   **依赖于[正态性假设](@entry_id:170614)的方面**：
    -   对于小样本，关于固定效应的 $t$ 检验和 $F$ 检验的精确性依赖于正态性。
    -   基于[似然比检验](@entry_id:1127231)（LRT）的[方差分量](@entry_id:267561)（$G$ 和 $R$ 中的参数）推断。
    -   为[随机效应](@entry_id:915431)（如被试特定效应）构建的具有精确覆盖率的[预测区间](@entry_id:635786)。

总之，[线性混合效应模型](@entry_id:917842)为分析神经科学中的[分层数据](@entry_id:894735)提供了一个强大而灵活的框架。通过将变异分解为固定和随机部分，它们不仅解决了传统方法的统计缺陷，还能够对个体差异的复杂模式进行建模，从而提供更丰富、更可靠的科学洞见。在接下来的章节中，我们将探讨如何在实践中指定、拟合和诊断这些模型。