{
    "hands_on_practices": [
        {
            "introduction": "The primary challenge in simultaneous EEG-fMRI recording is the contamination of the EEG signal by large artifacts generated by the MRI's switching magnetic gradients. A foundational technique for removing this highly structured noise is Average Artifact Subtraction (AAS). This exercise  delves into the statistical principles of AAS, asking you to derive how the residual artifact power changes based on the number of fMRI volumes used for averaging. By exploring two different averaging schemes, you will gain a crucial understanding of the effectiveness and inherent trade-offs of this essential preprocessing step.",
            "id": "4179392",
            "problem": "You are given a mathematical model of electroencephalography (EEG) recorded during functional magnetic resonance imaging (fMRI) where the magnetic resonance (MR) gradient artifact appears repetitively across volumes. For each volume index $k$ and discrete time index $t \\in \\{0,1,\\dots,T-1\\}$, the artifact segment is modeled as $A_k(t) = \\mu(t) + \\epsilon_k(t)$, where $\\mu(t)$ is a deterministic artifact template (identical across volumes) and $\\epsilon_k(t)$ is a zero-mean random deviation across volumes. Assume that for each fixed $t$, the set $\\{\\epsilon_k(t)\\}_{k}$ is independent and identically distributed with variance $\\sigma_a^2$ (not necessarily independent across $t$), and that $\\epsilon_k(t)$ is independent of $\\mu(t)$. The artifact power per segment is defined as $P_{\\text{pre}} = \\sum_{t=0}^{T-1} \\mathbb{E}\\big[A_k(t)^2\\big]$, and the residual artifact power after average artifact subtraction is defined as $P_{\\text{res}} = \\sum_{t=0}^{T-1} \\mathbb{E}\\big[R_k(t)^2\\big]$, where $R_k(t)$ is the residual artifact after subtracting an average template computed from $N$ volumes.\n\nAverage Artifact Subtraction (AAS) uses an empirical average of observed artifact segments to estimate the template. Consider two estimator designs for the template used to subtract from a target volume $k^\\star$:\n\n- Inclusive average: $\\hat{\\mu}_N^{\\text{inc}}(t) = \\frac{1}{N}\\sum_{i=1}^{N} A_i(t)$ where the target volume $k^\\star$ is one of the $N$ volumes used to compute the average. The residual is $R_{k^\\star}^{\\text{inc}}(t) = A_{k^\\star}(t) - \\hat{\\mu}_N^{\\text{inc}}(t)$.\n\n- Leave-one-out (exclusive) average: $\\hat{\\mu}_N^{\\text{exc}}(t) = \\frac{1}{N}\\sum_{i \\in \\mathcal{I}} A_i(t)$ where $\\mathcal{I}$ is a set of $N$ volumes that excludes the target $k^\\star$. The residual is $R_{k^\\star}^{\\text{exc}}(t) = A_{k^\\star}(t) - \\hat{\\mu}_N^{\\text{exc}}(t)$.\n\nStarting from the above definitions and the properties of expectation and variance for independent random variables, derive expressions for the residual artifact power $P_{\\text{res}}$ under both designs and analyze their convergence as $N$ increases. Specifically, compute the residual artifact power ratio $R = P_{\\text{res}} / P_{\\text{pre}}$, which is dimensionless. All angles used in any sinusoidal construction of $\\mu(t)$ must be in radians. All powers must be expressed in microvolt squared ($\\mu\\text{V}^2$).\n\nFor numerical evaluation, use the following deterministic template construction for $\\mu(t)$ at sample count $T$:\n- $\\mu(t) = A_1 \\sin\\left(2\\pi f_1 \\frac{t}{T}\\right) + A_2 \\cos\\left(2\\pi f_2 \\frac{t}{T}\\right)$, with angles in radians.\n- Use $T = 256$, $A_1 = 50$ $\\mu\\text{V}$, $A_2 = 30$ $\\mu\\text{V}$, $f_1 = 5$, and $f_2 = 13$.\n- Use $\\sigma_a = 10$ $\\mu\\text{V}$ for the random deviation standard deviation across volumes at each $t$, so the variance is $\\sigma_a^2$.\n\nDefine the following test suite of parameter sets, each specifying the averaging design (inclusive or exclusive), the number of volumes $N$ used to compute the average, and the template $\\mu(t)$ condition. In all cases, report the residual artifact power ratio $R$ as a decimal number (dimensionless). For the final output, list the results in the exact order provided here:\n\n1. Inclusive design with $N=1$, $T=256$, $\\sigma_a=10$ $\\mu\\text{V}$, $\\mu(t)$ as above.\n2. Inclusive design with $N=5$, $T=256$, $\\sigma_a=10$ $\\mu\\text{V}$, $\\mu(t)$ as above.\n3. Inclusive design with $N=20$, $T=256$, $\\sigma_a=10$ $\\mu\\text{V}$, $\\mu(t)$ as above.\n4. Inclusive design with $N=100$, $T=256$, $\\sigma_a=10$ $\\mu\\text{V}$, $\\mu(t)$ as above.\n5. Exclusive design with $N=1$, $T=256$, $\\sigma_a=10$ $\\mu\\text{V}$, $\\mu(t)$ as above.\n6. Exclusive design with $N=5$, $T=256$, $\\sigma_a=10$ $\\mu\\text{V}$, $\\mu(t)$ as above.\n7. Exclusive design with $N=20$, $T=256$, $\\sigma_a=10$ $\\mu\\text{V}$, $\\mu(t)$ as above.\n8. Exclusive design with $N=100$, $T=256$, $\\sigma_a=10$ $\\mu\\text{V}$, $\\mu(t)$ as above.\n9. Exclusive design with $N=5$, $T=256$, $\\sigma_a=10$ $\\mu\\text{V}$, and $\\mu(t) = 0$ for all $t$ (boundary case).\n\nYour program should produce a single line of output containing the residual artifact power ratios for the nine test cases as a comma-separated list enclosed in square brackets (for example, $[r_1,r_2,\\dots,r_9]$), where each $r_i$ is a decimal number.",
            "solution": "The problem is assessed as valid as it is scientifically grounded in signal processing principles, internally consistent, and well-posed with all necessary information provided for a unique solution.\n\nThe objective is to derive the residual artifact power ratio $R = P_{\\text{res}} / P_{\\text{pre}}$ for two averaging designs, inclusive and exclusive, and then evaluate this ratio for a given set of parameters.\n\nThe model for an artifact segment for volume $k$ is given by:\n$$A_k(t) = \\mu(t) + \\epsilon_k(t)$$\nwhere $t \\in \\{0, 1, \\dots, T-1\\}$, $\\mu(t)$ is a deterministic template, and $\\epsilon_k(t)$ is a random deviation with $\\mathbb{E}[\\epsilon_k(t)] = 0$ and $\\text{Var}(\\epsilon_k(t)) = \\sigma_a^2$. The deviations $\\{\\epsilon_k(t)\\}_{k}$ for a fixed time $t$ are independent and identically distributed (i.i.d.).\n\n**Step 1: Derivation of the Pre-correction Power, $P_{\\text{pre}}$**\nThe pre-correction power per segment is defined as $P_{\\text{pre}} = \\sum_{t=0}^{T-1} \\mathbb{E}[A_k(t)^2]$.\nTo find $\\mathbb{E}[A_k(t)^2]$, we use the relation $\\mathbb{E}[X^2] = \\text{Var}(X) + (\\mathbb{E}[X])^2$.\nThe expectation of $A_k(t)$ is:\n$$\\mathbb{E}[A_k(t)] = \\mathbb{E}[\\mu(t) + \\epsilon_k(t)] = \\mu(t) + \\mathbb{E}[\\epsilon_k(t)] = \\mu(t)$$\nThe variance of $A_k(t)$ is:\n$$\\text{Var}(A_k(t)) = \\text{Var}(\\mu(t) + \\epsilon_k(t)) = \\text{Var}(\\epsilon_k(t)) = \\sigma_a^2$$\nsince $\\mu(t)$ is deterministic.\nTherefore, the expected squared amplitude at time $t$ is:\n$$\\mathbb{E}[A_k(t)^2] = \\text{Var}(A_k(t)) + (\\mathbb{E}[A_k(t)])^2 = \\sigma_a^2 + \\mu(t)^2$$\nSumming over all time points $t$ from $0$ to $T-1$:\n$$P_{\\text{pre}} = \\sum_{t=0}^{T-1} (\\mu(t)^2 + \\sigma_a^2) = \\left(\\sum_{t=0}^{T-1} \\mu(t)^2\\right) + T\\sigma_a^2$$\nLet $P_\\mu = \\sum_{t=0}^{T-1} \\mu(t)^2$ be the power of the deterministic template.\n$$P_{\\text{pre}} = P_\\mu + T\\sigma_a^2$$\n\n**Step 2: Derivation of Residual Power for Inclusive Design, $P_{\\text{res}}^{\\text{inc}}$**\nThe template is estimated using $N$ volumes, including the target volume $k^\\star$. Let $k^\\star$ be one of $\\{1, \\dots, N\\}$.\n$$\\hat{\\mu}_N^{\\text{inc}}(t) = \\frac{1}{N}\\sum_{i=1}^{N} A_i(t)$$\nThe residual for the target volume $k^\\star$ is $R_{k^\\star}^{\\text{inc}}(t) = A_{k^\\star}(t) - \\hat{\\mu}_N^{\\text{inc}}(t)$.\n$$R_{k^\\star}^{\\text{inc}}(t) = A_{k^\\star}(t) - \\frac{1}{N}\\sum_{i=1}^{N} A_i(t) = \\left(1 - \\frac{1}{N}\\right)A_{k^\\star}(t) - \\frac{1}{N}\\sum_{i \\neq k^\\star} A_i(t)$$\nSubstituting $A_i(t) = \\mu(t) + \\epsilon_i(t)$:\n$$R_{k^\\star}^{\\text{inc}}(t) = \\left(1 - \\frac{1}{N}\\right)(\\mu(t) + \\epsilon_{k^\\star}(t)) - \\frac{1}{N}\\sum_{i \\neq k^\\star} (\\mu(t) + \\epsilon_i(t))$$\nThe terms involving $\\mu(t)$ cancel out: $\\left(1 - \\frac{1}{N}\\right)\\mu(t) - \\frac{N-1}{N}\\mu(t) = 0$.\n$$R_{k^\\star}^{\\text{inc}}(t) = \\left(1 - \\frac{1}{N}\\right)\\epsilon_{k^\\star}(t) - \\frac{1}{N}\\sum_{i \\neq k^\\star} \\epsilon_i(t)$$\nSince $\\mathbb{E}[\\epsilon_i(t)] = 0$ for all $i$, we have $\\mathbb{E}[R_{k^\\star}^{\\text{inc}}(t)] = 0$.\nThe expected squared residual at time $t$ is its variance:\n$$\\mathbb{E}[(R_{k^\\star}^{\\text{inc}}(t))^2] = \\text{Var}(R_{k^\\star}^{\\text{inc}}(t))$$\nGiven that all $\\epsilon_i(t)$ are independent for a fixed $t$, we have:\n$$\\text{Var}(R_{k^\\star}^{\\text{inc}}(t)) = \\left(1 - \\frac{1}{N}\\right)^2 \\text{Var}(\\epsilon_{k^\\star}(t)) + \\sum_{i \\neq k^\\star} \\left(-\\frac{1}{N}\\right)^2 \\text{Var}(\\epsilon_i(t))$$\n$$= \\left(\\frac{N-1}{N}\\right)^2 \\sigma_a^2 + (N-1) \\frac{1}{N^2} \\sigma_a^2 = \\frac{(N-1)^2 + (N-1)}{N^2} \\sigma_a^2 = \\frac{(N-1)N}{N^2} \\sigma_a^2 = \\frac{N-1}{N} \\sigma_a^2$$\nThe total residual power is the sum over all time points:\n$$P_{\\text{res}}^{\\text{inc}} = \\sum_{t=0}^{T-1} \\frac{N-1}{N} \\sigma_a^2 = T\\sigma_a^2\\left(1 - \\frac{1}{N}\\right)$$\n\n**Step 3: Derivation of Residual Power for Exclusive Design, $P_{\\text{res}}^{\\text{exc}}$**\nThe template is estimated using $N$ volumes that do not include the target volume $k^\\star$.\n$$\\hat{\\mu}_N^{\\text{exc}}(t) = \\frac{1}{N}\\sum_{i \\in \\mathcal{I}} A_i(t), \\quad k^\\star \\notin \\mathcal{I}$$\nThe residual is $R_{k^\\star}^{\\text{exc}}(t) = A_{k^\\star}(t) - \\hat{\\mu}_N^{\\text{exc}}(t)$.\n$$R_{k^\\star}^{\\text{exc}}(t) = (\\mu(t) + \\epsilon_{k^\\star}(t)) - \\frac{1}{N}\\sum_{i \\in \\mathcal{I}} (\\mu(t) + \\epsilon_i(t))$$\nThe terms involving $\\mu(t)$ again cancel: $\\mu(t) - \\frac{N}{N}\\mu(t) = 0$.\n$$R_{k^\\star}^{\\text{exc}}(t) = \\epsilon_{k^\\star}(t) - \\frac{1}{N}\\sum_{i \\in \\mathcal{I}} \\epsilon_i(t)$$\nAs before, $\\mathbb{E}[R_{k^\\star}^{\\text{exc}}(t)] = 0$, so $\\mathbb{E}[(R_{k^\\star}^{\\text{exc}}(t))^2] = \\text{Var}(R_{k^\\star}^{\\text{exc}}(t))$.\nSince $k^\\star \\notin \\mathcal{I}$, $\\epsilon_{k^\\star}(t)$ is independent of all $\\epsilon_i(t)$ for $i \\in \\mathcal{I}$.\n$$\\text{Var}(R_{k^\\star}^{\\text{exc}}(t)) = \\text{Var}(\\epsilon_{k^\\star}(t)) + \\text{Var}\\left(-\\frac{1}{N}\\sum_{i \\in \\mathcal{I}} \\epsilon_i(t)\\right) = \\sigma_a^2 + \\frac{1}{N^2} \\sum_{i \\in \\mathcal{I}} \\text{Var}(\\epsilon_i(t))$$\n$$= \\sigma_a^2 + \\frac{1}{N^2} (N \\sigma_a^2) = \\sigma_a^2\\left(1 + \\frac{1}{N}\\right)$$\nThe total residual power is:\n$$P_{\\text{res}}^{\\text{exc}} = \\sum_{t=0}^{T-1} \\sigma_a^2\\left(1 + \\frac{1}{N}\\right) = T\\sigma_a^2\\left(1 + \\frac{1}{N}\\right)$$\n\n**Step 4: The Residual Power Ratio $R$ and Convergence**\nAs $N \\to \\infty$, both $P_{\\text{res}}^{\\text{inc}}$ and $P_{\\text{res}}^{\\text{exc}}$ converge to $T\\sigma_a^2$, which is the total power of the noise component. The inclusive design slightly underestimates this residual noise power for finite $N$, while the exclusive design overestimates it.\n\nThe ratios $R = P_{\\text{res}} / P_{\\text{pre}}$ are:\n$$R^{\\text{inc}} = \\frac{T\\sigma_a^2(1 - 1/N)}{P_\\mu + T\\sigma_a^2}$$\n$$R^{\\text{exc}} = \\frac{T\\sigma_a^2(1 + 1/N)}{P_\\mu + T\\sigma_a^2}$$\n\n**Step 5: Numerical Evaluation**\nThe parameters are: $T=256$, $A_1=50$, $A_2=30$, $f_1=5$, $f_2=13$, $\\sigma_a=10$. This gives $\\sigma_a^2=100$.\nThe template power $P_\\mu$ is calculated first:\n$$P_\\mu = \\sum_{t=0}^{T-1} \\left( A_1 \\sin\\left(\\frac{2\\pi f_1 t}{T}\\right) + A_2 \\cos\\left(\\frac{2\\pi f_2 t}{T}\\right) \\right)^2$$\nDue to the orthogonality of the sinusoidal functions over the interval $[0, T-1]$ for the given integer frequencies $f_1, f_2$ (where $f_1 \\neq f_2$ and neither is $0$ or $T/2$), the cross-term in the expansion sums to zero, and we have:\n$$\\sum_{t=0}^{T-1} \\sin^2\\left(\\frac{2\\pi f t}{T}\\right) = \\sum_{t=0}^{T-1} \\cos^2\\left(\\frac{2\\pi f t}{T}\\right) = \\frac{T}{2}$$\nThus, $P_\\mu = A_1^2 \\frac{T}{2} + A_2^2 \\frac{T}{2} = \\frac{T}{2}(A_1^2 + A_2^2)$.\n$$P_\\mu = \\frac{256}{2}(50^2 + 30^2) = 128(2500 + 900) = 128(3400) = 435200 \\, \\mu\\text{V}^2$$\nThe noise power term is $T\\sigma_a^2 = 256 \\times 100 = 25600 \\, \\mu\\text{V}^2$.\nThe total pre-correction power is $P_{\\text{pre}} = 435200 + 25600 = 460800 \\, \\mu\\text{V}^2$.\n\nThe ratio formulas can be simplified by dividing the numerator and denominator by $T$:\n$$R = \\frac{\\sigma_a^2(1 \\pm 1/N)}{P_\\mu/T + \\sigma_a^2} = \\frac{\\sigma_a^2(1 \\pm 1/N)}{\\frac{1}{2}(A_1^2 + A_2^2) + \\sigma_a^2}$$\nThe denominator term is $\\frac{1}{2}(50^2 + 30^2) + 10^2 = 1700 + 100 = 1800$.\nThe general formulas become:\n$$R^{\\text{inc}}(N) = \\frac{100(1 - 1/N)}{1800} = \\frac{1}{18}\\left(1 - \\frac{1}{N}\\right)$$\n$$R^{\\text{exc}}(N) = \\frac{100(1 + 1/N)}{1800} = \\frac{1}{18}\\left(1 + \\frac{1}{N}\\right)$$\n\nFor the special case $\\mu(t)=0$, $P_\\mu=0$. The ratio becomes $R^{\\text{exc}} = \\frac{T\\sigma_a^2(1+1/N)}{T\\sigma_a^2} = 1 + 1/N$.\n\nCalculations for the test cases:\n1. Inclusive, $N=1$: $R = \\frac{1}{18}(1 - 1/1) = 0$\n2. Inclusive, $N=5$: $R = \\frac{1}{18}(1 - 1/5) = \\frac{1}{18}(\\frac{4}{5}) = \\frac{4}{90} = \\frac{2}{45} \\approx 0.0444...$\n3. Inclusive, $N=20$: $R = \\frac{1}{18}(1 - 1/20) = \\frac{1}{18}(\\frac{19}{20}) = \\frac{19}{360} \\approx 0.0527...$\n4. Inclusive, $N=100$: $R = \\frac{1}{18}(1 - 1/100) = \\frac{1}{18}(\\frac{99}{100}) = \\frac{11}{200} = 0.055$\n5. Exclusive, $N=1$: $R = \\frac{1}{18}(1 + 1/1) = \\frac{2}{18} = \\frac{1}{9} \\approx 0.1111...$\n6. Exclusive, $N=5$: $R = \\frac{1}{18}(1 + 1/5) = \\frac{1}{18}(\\frac{6}{5}) = \\frac{6}{90} = \\frac{1}{15} \\approx 0.0666...$\n7. Exclusive, $N=20$: $R = \\frac{1}{18}(1 + 1/20) = \\frac{1}{18}(\\frac{21}{20}) = \\frac{7}{120} \\approx 0.0583...$\n8. Exclusive, $N=100$: $R = \\frac{1}{18}(1 + 1/100) = \\frac{101}{1800} \\approx 0.0561...$\n9. Exclusive, $N=5$, $\\mu=0$: $R = 1 + 1/5 = 1.2",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Calculates the residual artifact power ratio for nine test cases based on\n    a model of EEG-fMRI artifacts.\n    \"\"\"\n    # Define the constants from the problem statement\n    A1 = 50.0  # microV\n    A2 = 30.0  # microV\n    sigma_a = 10.0 # microV\n\n    # Define the test cases from the problem statement\n    test_cases = [\n        # (design, N, mu_is_zero)\n        ('inclusive', 1, False),\n        ('inclusive', 5, False),\n        ('inclusive', 20, False),\n        ('inclusive', 100, False),\n        ('exclusive', 1, False),\n        ('exclusive', 5, False),\n        ('exclusive', 20, False),\n        ('exclusive', 100, False),\n        ('exclusive', 5, True),\n    ]\n\n    results = []\n\n    # Pre-calculate squared terms for efficiency and clarity\n    sigma_a_sq = sigma_a**2\n    A1_sq = A1**2\n    A2_sq = A2**2\n\n    # The denominator of the ratio R can be simplified from the full power expressions.\n    # The full ratio is R = (T*sigma_a^2 * F(N)) / (P_mu + T*sigma_a^2), where\n    # P_mu = T/2 * (A1^2 + A2^2).\n    # Dividing by T simplifies the ratio to R = (sigma_a^2 * F(N)) / (1/2*(A1^2+A2^2) + sigma_a^2).\n    # This avoids large numbers and dependence on T.\n    denominator_term_mu_present = 0.5 * (A1_sq + A2_sq) + sigma_a_sq\n\n    for design, N, mu_is_zero in test_cases:\n        if mu_is_zero:\n            # Special case 9: mu(t) = 0 for all t.\n            # R = (T*sigma_a^2 * (1 + 1/N)) / (0 + T*sigma_a^2) = 1 + 1/N\n            # This applies to the exclusive design as specified in the test case.\n            if design == 'exclusive':\n                R = 1.0 + 1.0 / N\n            else: # For completeness, if the design were inclusive\n                R = 1.0 - 1.0 / N\n        else:\n            # Cases 1-8 where mu(t) is defined by the sinusoidal formula\n            if design == 'inclusive':\n                # R_inc = (sigma_a^2 * (1 - 1/N)) / (1/2*(A1^2+A2^2) + sigma_a^2)\n                numerator = sigma_a_sq * (1.0 - 1.0 / N)\n                R = numerator / denominator_term_mu_present\n            elif design == 'exclusive':\n                # R_exc = (sigma_a^2 * (1 + 1/N)) / (1/2*(A1^2+A2^2) + sigma_a^2)\n                numerator = sigma_a_sq * (1.0 + 1.0 / N)\n                R = numerator / denominator_term_mu_present\n        \n        results.append(R)\n\n    # Format the output as a comma-separated list enclosed in square brackets.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "One of the most powerful applications of EEG-fMRI fusion is using the millisecond-scale timing of EEG to explain the spatially precise, but sluggish, fMRI BOLD signal. This practice  demonstrates a sophisticated method for this, starting with EEG microstate analysis to capture global, quasi-stable patterns of brain electrical activity. You will learn to construct event-related fMRI regressors based on the occurrences of these microstates, convolve them with the canonical hemodynamic response function, and prepare them for inclusion in a General Linear Model (GLM) analysis.",
            "id": "4179375",
            "problem": "You are given a formal task to construct event-related regressors for a functional Magnetic Resonance Imaging (fMRI) General Linear Model (GLM) using Electroencephalography (EEG) microstate information. Assume the following foundational base in signal processing and multimodal integration: discrete spatial correlation between vectors, indicator functions, discrete-time impulse trains for event encoding, double-gamma Hemodynamic Response Function (HRF), and linear time-invariant convolution. You must compute microstate-specific event functions by assigning each EEG time sample to a single microstate based on maximum spatial correlation with template maps, then convolve those event functions with a canonical HRF, and finally sample the convolved signals at the fMRI repetition time to produce regressors. The final output must be a single line containing the regressors for multiple test cases in the exact format specified below.\n\nDefinitions and required steps:\n- Let $X \\in \\mathbb{R}^{T \\times M}$ be the EEG scalp potential matrix for $T$ discrete time samples and $M$ channels, sampled at frequency $f_{\\mathrm{EEG}}$ in $\\mathrm{Hz}$, with sampling period $dt = 1 / f_{\\mathrm{EEG}}$ in $\\mathrm{s}$. Let $G \\in \\mathbb{R}^{K \\times M}$ be $K$ microstate template maps.\n- For each time sample $t \\in \\{0,1,\\dots,T-1\\}$, define the mean-centered EEG map $\\tilde{x}_t \\in \\mathbb{R}^M$ by subtracting its mean. For each template $k \\in \\{1,\\dots,K\\}$, define the mean-centered template $\\tilde{g}_k \\in \\mathbb{R}^M$ by subtracting its mean. Compute the spatial correlation\n$$\nr_k(t) \\;=\\; \\frac{\\langle \\tilde{x}_t, \\tilde{g}_k \\rangle}{\\|\\tilde{x}_t\\|_2 \\, \\|\\tilde{g}_k\\|_2} \\, ,\n$$\nand assign the microstate label by\n$$\n\\hat{z}(t) \\;=\\; \\underset{k \\in \\{1,\\dots,K\\}}{\\arg\\max}\\; r_k(t) \\, .\n$$\nDefine the indicator time series for each microstate $k$ as\n$$\ns_k(t) \\;=\\; \\mathbb{I}\\big[\\hat{z}(t) = k\\big] \\, .\n$$\n- Let an event-related paradigm be encoded by an impulse train $e(t)$ at the EEG sampling grid, defined by $e(t_j) = 1$ at event indices $t_j = \\lfloor \\tau_j / dt \\rfloor$ where $\\tau_j$ are event times in $\\mathrm{s}$ and $e(t) = 0$ otherwise. If an event time maps beyond the last EEG sample, clamp to $t = T-1$. Construct microstate-specific event functions\n$$\nu_k(t) \\;=\\; s_k(t) \\cdot e(t) \\, .\n$$\n- Use a canonical double-gamma Hemodynamic Response Function sampled at the EEG grid, with parameters $\\alpha_1 = 6$, $\\beta_1 = 1$, $\\alpha_2 = 16$, $\\beta_2 = 1$, and $c = 1/6$. Define, for $t \\ge 0$,\n$$\n\\mathrm{GammaPDF}(t;\\alpha,\\beta) \\;=\\; \\frac{t^{\\alpha-1}\\, e^{-t/\\beta}}{\\beta^{\\alpha}\\, \\Gamma(\\alpha)} \\, ,\n$$\nand\n$$\nh(t) \\;=\\; \\mathrm{GammaPDF}(t;\\alpha_1,\\beta_1) \\;-\\; c \\cdot \\mathrm{GammaPDF}(t;\\alpha_2,\\beta_2) \\, .\n$$\nSample $h(t)$ on $t = 0, dt, 2dt, \\dots, L_{\\mathrm{HRF}}$ with $L_{\\mathrm{HRF}} = 32$ in $\\mathrm{s}$. Normalize $h$ to unit area by enforcing $\\sum_{m} h[m] \\cdot dt = 1$.\n- Convolve each $u_k$ with $h$ in discrete time to obtain $c_k = u_k * h$ using full convolution. Let the fMRI repetition time be $TR$ in $\\mathrm{s}$, and the number of volumes be $N_{\\mathrm{vol}}$. Sample the convolved signal at $t_n = n \\cdot TR$ for $n \\in \\{0,1,\\dots,N_{\\mathrm{vol}}-1\\}$ by nearest-lower indexing $y_k[n] = c_k[\\lfloor t_n / dt \\rfloor]$, provided the index lies within the bounds of the full convolution; if an index exceeds the length, clamp to the last available index.\n- Normalize each regressor $y_k$ to unit $\\ell_2$ norm if its norm is nonzero; otherwise leave it as a zero vector.\n\nUnits: All time quantities must be in $\\mathrm{s}$ (seconds). Angles are not used. Percentages are not used.\n\nYour program must implement the above definitions exactly for the following test suite. Each test case specifies $(M,K,f_{\\mathrm{EEG}},TR,N_{\\mathrm{vol}},T,\\text{events},G,\\text{EEG generation})$. For EEG generation, construct $X$ by selecting the microstate template indicated and adding independent Gaussian noise with the given standard deviation, using the provided random seed; that is, for each time $t$ in a segment associated to microstate $k$, set $x_{t} = g_k + \\epsilon_t$ with $\\epsilon_t \\sim \\mathcal{N}(0,\\sigma^2 I_M)$, and then proceed with mean-centering before correlation. All template maps must be mean-centered and $\\ell_2$-normalized before use.\n\nTest case 1 (happy path):\n- $M = 4$, $K = 4$, $f_{\\mathrm{EEG}} = 250$, $TR = 1$, $N_{\\mathrm{vol}} = 4$, $T = 1000$.\n- Events at times $\\tau = [0.5, 1.5, 2.5, 3.5]$.\n- Templates $G$ (before mean-centering and normalization):\n  $g_1 = [1, -1, 1, -1]$, $g_2 = [1, 1, -1, -1]$, $g_3 = [1, -1, -1, 1]$, $g_4 = [-1, 1, -1, 1]$.\n- EEG generation: segments $[0,249] \\rightarrow k=1$, $[250,499] \\rightarrow k=2$, $[500,749] \\rightarrow k=3$, $[750,999] \\rightarrow k=4$; Gaussian noise standard deviation $\\sigma = 0.05$, random seed $42$.\n\nTest case 2 (boundary length):\n- $M = 3$, $K = 3$, $f_{\\mathrm{EEG}} = 100$, $TR = 0.6$, $N_{\\mathrm{vol}} = 3$, $T = 120$.\n- Events at times $\\tau = [0.2, 0.8, 1.1]$.\n- Templates $G$ (before mean-centering and normalization):\n  $g_1 = [1, -1, 0]$, $g_2 = [-1, 1, 0]$, $g_3 = [0, 1, -1]$.\n- EEG generation: segments $[0,39] \\rightarrow k=1$, $[40,79] \\rightarrow k=2$, $[80,119] \\rightarrow k=3$; Gaussian noise standard deviation $\\sigma = 0.05$, random seed $7$.\n\nTest case 3 (edge events at bounds):\n- $M = 2$, $K = 2$, $f_{\\mathrm{EEG}} = 200$, $TR = 0.75$, $N_{\\mathrm{vol}} = 4$, $T = 600$.\n- Events at times $\\tau = [0.0, 1.5, 3.0]$.\n- Templates $G$ (before mean-centering and normalization):\n  $g_1 = [1, -1]$, $g_2 = [-1, 1]$.\n- EEG generation: segments $[0,299] \\rightarrow k=1$, $[300,599] \\rightarrow k=2$; Gaussian noise standard deviation $\\sigma = 0.02$, random seed $123$.\n\nRequired final output format:\n- Your program should produce a single line of output containing the regressors for all test cases, structured as a list of test cases, where each test case is a list of $K$ lists of length $N_{\\mathrm{vol}}$ (microstate regressors sampled at $TR$), with no spaces. For example, the outer structure should look like\n$[[$reg\\_case1$],[ $reg\\_case2$],[ $reg\\_case3$]]$, where each $reg\\_case$ is itself $[y_1,y_2,\\dots,y_K]$ and each $y_k$ is a list of floats of length $N_{\\mathrm{vol}}$. The printed string must contain no spaces anywhere.",
            "solution": "The problem statement has been critically validated and is deemed valid. It is scientifically grounded in established principles of EEG-fMRI integration, well-posed with a complete and consistent set of definitions and parameters, and expressed in objective, formal language. The task is to construct fMRI General Linear Model (GLM) regressors modulated by EEG microstate dynamics, a recognized a-priori approach in neuroimaging data analysis. The problem is a non-trivial, multi-step computational task that is fully specified and computationally feasible. We will proceed with a detailed solution.\n\nThe solution is implemented by following the sequence of steps specified in the problem statement.\n\n**1. Hemodynamic Response Function (HRF) Generation**\nThe canonical double-gamma Hemodynamic Response Function, $h(t)$, is defined for $t \\ge 0$ as the difference of two Gamma probability density functions. The Gamma PDF is given by:\n$$\n\\mathrm{GammaPDF}(t;\\alpha,\\beta) = \\frac{t^{\\alpha-1}\\, e^{-t/\\beta}}{\\beta^{\\alpha}\\, \\Gamma(\\alpha)}\n$$\nwhere $\\Gamma(\\alpha)$ is the Gamma function. The HRF is then:\n$$\nh(t) = \\mathrm{GammaPDF}(t;\\alpha_1,\\beta_1) - c \\cdot \\mathrm{GammaPDF}(t;\\alpha_2,\\beta_2)\n$$\nThe parameters are provided as $\\alpha_1 = 6$, $\\beta_1 = 1$, $\\alpha_2 = 16$, $\\beta_2 = 1$, and $c = 1/6$.\n\nThis continuous function is sampled at the EEG sampling period, $dt = 1/f_{\\mathrm{EEG}}$, over a duration of $L_{\\mathrm{HRF}} = 32$ s. The resulting discrete time series, let's call it $h_{samp}$, is then normalized to have a unit area, which in the discrete domain corresponds to ensuring its Riemann sum approximates an integral of $1$:\n$$\n\\sum_{i} h_{samp}[i] \\cdot dt = 1\n$$\nThis is achieved by dividing the sampled vector $h_{samp}$ by the sum of its elements multiplied by $dt$. The resulting vector $h$ is used as the convolution kernel.\n\n**2. Template Pre-processing and EEG Data Generation**\nThe provided microstate template maps $G \\in \\mathbb{R}^{K \\times M}$ are first pre-processed. For each raw template vector $g_{k,raw}$, we compute its mean-centered version $g'_k$ and then normalize it to have a unit $\\ell_2$ norm.\n$$\ng'_k = g_{k,raw} - \\text{mean}(g_{k,raw})\n$$\n$$\ng_k = \\frac{g'_k}{\\|g'_k\\|_2}\n$$\nThese processed templates $g_k$ are used for two purposes: generating the synthetic EEG data and for the subsequent correlation analysis.\n\nThe EEG data matrix $X \\in \\mathbb{R}^{T \\times M}$ is synthesized based on a piecewise-constant microstate sequence. For each time sample $t$, if it falls within a segment assigned to microstate $k$, the corresponding EEG scalp map $x_t$ is generated by taking the processed template $g_k$ and adding independent Gaussian noise:\n$$\nx_t = g_k + \\epsilon_t \\quad \\text{where} \\quad \\epsilon_t \\sim \\mathcal{N}(0, \\sigma^2 I_M)\n$$\nA specified random seed ensures reproducibility.\n\n**3. Microstate Assignment**\nThe generated EEG time series is labeled by assigning each time point $t$ to one of the $K$ microstates. This is achieved by finding the template map $g_k$ that has the highest spatial correlation with the EEG map $x_t$. The spatial correlation $r_k(t)$ is calculated as the cosine similarity between the mean-centered EEG map $\\tilde{x}_t$ and the mean-centered template map $\\tilde{g}_k$.\n$$\n\\tilde{x}_t = x_t - \\text{mean}(x_t) \\quad , \\quad \\tilde{g}_k = g_k - \\text{mean}(g_k)\n$$\nAs the templates $g_k$ were already mean-centered during pre-processing, $\\tilde{g}_k = g_k$. The correlation is:\n$$\nr_k(t) = \\frac{\\langle \\tilde{x}_t, \\tilde{g}_k \\rangle}{\\|\\tilde{x}_t\\|_2 \\, \\|\\tilde{g}_k\\|_2}\n$$\nThe microstate label for time $t$, denoted $\\hat{z}(t)$, is the index of the template with the maximum correlation:\n$$\n\\hat{z}(t) = \\underset{k \\in \\{1,\\dots,K\\}}{\\arg\\max}\\; r_k(t)\n$$\n\n**4. Microstate-Specific Event Function Construction**\nFirst, an impulse train $e(t)$ is created on the EEG time grid to represent the timing of experimental events. For each event time $\\tau_j$ (in seconds), an impulse is placed at the corresponding discrete time index $t_j = \\lfloor \\tau_j / dt \\rfloor$. If an index falls outside the valid range $[0, T-1]$, it is clamped to the nearest boundary.\n$$\ne(t) = \\begin{cases} 1 & \\text{if } t = \\min(\\lfloor \\tau_j / dt \\rfloor, T-1) \\text{ for some } j \\\\ 0 & \\text{otherwise} \\end{cases}\n$$\nNext, for each microstate $k$, an indicator time series $s_k(t)$ is defined, which is $1$ if the assigned label at time $t$ is $k$, and $0$ otherwise:\n$$\ns_k(t) = \\mathbb{I}\\big[\\hat{z}(t) = k\\big]\n$$\nThe microstate-specific event function $u_k(t)$ is then the element-wise product of the indicator series and the event impulse train. This function marks only those events that occurred while microstate $k$ was active.\n$$\nu_k(t) = s_k(t) \\cdot e(t)\n$$\n\n**5. Convolution and Downsampling**\nEach microstate-specific event function $u_k(t)$ is convolved with the normalized HRF kernel $h$ to model the expected BOLD signal. A 'full' convolution is used:\n$$\nc_k = u_k * h\n$$\nThe resulting continuous-time signal proxies, $c_k(t)$, are sampled at the fMRI acquisition times. These times are given by $t_n = n \\cdot TR$ for each fMRI volume $n \\in \\{0, 1, \\dots, N_{\\mathrm{vol}}-1\\}$. The sampling is performed by taking the value of the convolved signal at the nearest-lower index on the EEG time grid:\n$$\ny'_k[n] = c_k[\\lfloor n \\cdot TR / dt \\rfloor]\n$$\nAn index clamping rule is applied: if $\\lfloor n \\cdot TR / dt \\rfloor$ exceeds the length of the convolved signal $c_k$, the last value of $c_k$ is used.\n\n**6. Final Regressor Normalization**\nAs a final step, each sampled regressor vector $y'_k$ is normalized to have a unit $\\ell_2$ norm. This is a common practice in GLM analysis to ensure that the scale of the regressor does not bias the estimation of its corresponding beta coefficient. If a regressor vector is all zeros (i.e., its norm is zero), it remains unchanged.\n$$\ny_k = \\begin{cases} \\frac{y'_k}{\\|y'_k\\|_2} & \\text{if } \\|y'_k\\|_2 > 0 \\\\ y'_k & \\text{if } \\|y'_k\\|_2 = 0 \\end{cases}\n$$\nThese vectors $y_k$ are the final fMRI regressors. The process is repeated for each test case, and the results are aggregated.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.special import gamma as gamma_func\n\ndef solve():\n    \"\"\"\n    Main function to solve the problem for all test cases.\n    \"\"\"\n    \n    test_cases = [\n        {\n            \"M\": 4, \"K\": 4, \"f_EEG\": 250, \"TR\": 1, \"N_vol\": 4, \"T\": 1000,\n            \"events\": [0.5, 1.5, 2.5, 3.5],\n            \"templates_raw\": np.array([\n                [1, -1, 1, -1], [1, 1, -1, -1],\n                [1, -1, -1, 1], [-1, 1, -1, 1]\n            ], dtype=float),\n            \"eeg_gen\": {\n                \"segments\": [\n                    (0, 249, 0), (250, 499, 1),\n                    (500, 749, 2), (750, 999, 3)\n                ],\n                \"sigma\": 0.05,\n                \"seed\": 42\n            }\n        },\n        {\n            \"M\": 3, \"K\": 3, \"f_EEG\": 100, \"TR\": 0.6, \"N_vol\": 3, \"T\": 120,\n            \"events\": [0.2, 0.8, 1.1],\n            \"templates_raw\": np.array([\n                [1, -1, 0], [-1, 1, 0], [0, 1, -1]\n            ], dtype=float),\n            \"eeg_gen\": {\n                \"segments\": [\n                    (0, 39, 0), (40, 79, 1), (80, 119, 2)\n                ],\n                \"sigma\": 0.05,\n                \"seed\": 7\n            }\n        },\n        {\n            \"M\": 2, \"K\": 2, \"f_EEG\": 200, \"TR\": 0.75, \"N_vol\": 4, \"T\": 600,\n            \"events\": [0.0, 1.5, 3.0],\n            \"templates_raw\": np.array([\n                [1, -1], [-1, 1]\n            ], dtype=float),\n            \"eeg_gen\": {\n                \"segments\": [\n                    (0, 299, 0), (300, 599, 1)\n                ],\n                \"sigma\": 0.02,\n                \"seed\": 123\n            }\n        }\n    ]\n\n    all_results = []\n    \n    for case in test_cases:\n        case_results = run_case(case)\n        all_results.append(case_results)\n    \n    # Custom formatter to produce a JSON-like string with no spaces\n    def format_no_space(obj):\n        if isinstance(obj, list) or isinstance(obj, tuple):\n            return '[' + ','.join(format_no_space(item) for item in obj) + ']'\n        elif isinstance(obj, np.ndarray):\n            return format_no_space(obj.tolist())\n        else:\n            return str(obj)\n\n    print(format_no_space(all_results))\n\ndef run_case(params):\n    \"\"\"\n    Processes a single test case.\n    \"\"\"\n    M, K, f_EEG, TR, N_vol, T = params[\"M\"], params[\"K\"], params[\"f_EEG\"], params[\"TR\"], params[\"N_vol\"], params[\"T\"]\n    event_times = params[\"events\"]\n    templates_raw = params[\"templates_raw\"]\n    eeg_gen = params[\"eeg_gen\"]\n    \n    dt = 1.0 / f_EEG\n\n    # 1. HRF Generation\n    def gamma_pdf(t, alpha, beta):\n        return (t**(alpha - 1) * np.exp(-t / beta)) / (beta**alpha * gamma_func(alpha))\n\n    L_HRF = 32\n    hrf_t = np.arange(0, L_HRF + dt, dt)\n    h_sampled = gamma_pdf(hrf_t, 6, 1) - (1/6) * gamma_pdf(hrf_t, 16, 1)\n    \n    h_norm_factor = np.sum(h_sampled) * dt\n    h = h_sampled / h_norm_factor if h_norm_factor != 0 else h_sampled\n\n    # 2. Template Pre-processing\n    templates = np.zeros_like(templates_raw)\n    for i in range(K):\n        g_raw = templates_raw[i]\n        g_mean_centered = g_raw - np.mean(g_raw)\n        norm = np.linalg.norm(g_mean_centered)\n        templates[i] = g_mean_centered / norm if norm > 0 else g_mean_centered\n\n    # 3. EEG Data Generation\n    np.random.seed(eeg_gen[\"seed\"])\n    X = np.zeros((T, M))\n    for start, end, k_idx in eeg_gen[\"segments\"]:\n        num_samples = end - start + 1\n        noise = np.random.normal(0, eeg_gen[\"sigma\"], size=(num_samples, M))\n        X[start:end+1, :] = templates[k_idx] + noise\n\n    # 4. Microstate Assignment\n    z_hat = np.zeros(T, dtype=int)\n    g_tilde = templates # templates are already mean-centered and norm=1\n    g_tilde_norms = np.linalg.norm(g_tilde, axis=1)\n\n    for t in range(T):\n        x_t = X[t, :]\n        x_t_tilde = x_t - np.mean(x_t)\n        x_t_tilde_norm = np.linalg.norm(x_t_tilde)\n        \n        if x_t_tilde_norm == 0:\n            z_hat[t] = 0 # Default assignment if signal is flat\n            continue\n\n        corrs = np.dot(g_tilde, x_t_tilde) / (g_tilde_norms * x_t_tilde_norm)\n        z_hat[t] = np.argmax(corrs)\n\n    # 5. Microstate-Specific Event Functions\n    e = np.zeros(T)\n    for tau in event_times:\n        t_j = int(np.floor(tau / dt))\n        t_j = min(t_j, T - 1)\n        e[t_j] = 1\n\n    u = np.zeros((K, T))\n    for k in range(K):\n        s_k = (z_hat == k)\n        u[k, :] = s_k * e\n\n    # 6. Convolution and Downsampling\n    final_regressors = []\n    for k in range(K):\n        u_k = u[k, :]\n        \n        if np.sum(u_k) == 0:\n            final_regressors.append(np.zeros(N_vol).tolist())\n            continue\n\n        c_k = np.convolve(u_k, h, mode='full')\n        \n        y_k = np.zeros(N_vol)\n        for n in range(N_vol):\n            t_n = n * TR\n            idx = int(np.floor(t_n / dt))\n            # Clamp index to valid range for convolved signal\n            idx = min(idx, len(c_k) - 1)\n            y_k[n] = c_k[idx]\n\n        # 7. Final Normalization\n        norm_y_k = np.linalg.norm(y_k)\n        if norm_y_k > 0:\n            y_k /= norm_y_k\n        \n        final_regressors.append(y_k.tolist())\n        \n    return final_regressors\n\nif __name__ == '__main__':\n    solve()\n```"
        },
        {
            "introduction": "While EEG offers superb temporal resolution, localizing the underlying neural sources from scalp recordings—the 'inverse problem'—is notoriously difficult due to its ill-posed nature. Fusing EEG with fMRI provides a powerful solution by using fMRI's high spatial resolution to constrain the possible source locations. This hands-on exercise  simulates this exact scenario, allowing you to quantify the improvement in source localization accuracy when an fMRI-derived spatial prior is used compared to a whole-brain solution. This practice illuminates the synergistic benefit of multimodal data in overcoming the limitations of each individual modality.",
            "id": "4179358",
            "problem": "You are given a simplified linear forward model for Electroencephalography (EEG) and functional Magnetic Resonance Imaging (fMRI) integration in source localization. Under the quasi-static approximation of volume conduction, assume that EEG scalp potentials are generated by fixed-location point current sources (dipoles) and are linearly related to the source amplitudes. The forward model is specified as follows. Let there be $M$ sensors at positions $\\{\\mathbf{r}_i\\}_{i=1}^M$ (in millimeters) and $N$ candidate source locations at positions $\\{\\mathbf{s}_j\\}_{j=1}^N$ (in millimeters). The lead-field matrix $G \\in \\mathbb{R}^{M \\times N}$ is defined element-wise by\n$$\nG_{ij} = \\frac{1}{\\lVert \\mathbf{r}_i - \\mathbf{s}_j \\rVert_2^2},\n$$\nwhich is a simplified, physically motivated proxy for a scalar dipole-to-sensor coupling that decays with the square of the distance. Let the noiseless EEG measurement for a single active source at index $j_0$ with amplitude $a$ be $\\mathbf{y}_0 = G \\mathbf{x}_0$, where $\\mathbf{x}_0 \\in \\mathbb{R}^N$ has entries $(\\mathbf{x}_0)_j = a$ if $j=j_0$ and $(\\mathbf{x}_0)_j = 0$ otherwise. The measured data are corrupted by additive zero-mean Gaussian noise $\\mathbf{e} \\sim \\mathcal{N}(\\mathbf{0}, \\sigma^2 I_M)$, giving the observed data $\\mathbf{y} = \\mathbf{y}_0 + \\mathbf{e}$.\n\nThe inverse problem is to estimate the source vector $\\mathbf{x}$ from $\\mathbf{y}$. Use Tikhonov-regularized least squares to estimate $\\widehat{\\mathbf{x}}$ as the minimizer of the convex quadratic criterion\n$$\n\\widehat{\\mathbf{x}} \\in \\arg\\min_{\\mathbf{x} \\in \\mathbb{R}^N} \\left\\{ \\lVert \\mathbf{y} - G \\mathbf{x} \\rVert_2^2 + \\lambda \\lVert \\mathbf{x} \\rVert_2^2 \\right\\},\n$$\nwhere $\\lambda > 0$ is a regularization parameter. For fMRI-informed restriction, let $\\mathcal{C} \\subset \\{1,\\dots,N\\}$ denote a cluster of indices corresponding to an fMRI-identified region, and estimate $\\widehat{\\mathbf{x}}_{\\mathcal{C}}$ as the minimizer of the same criterion but with $\\mathbf{x}$ constrained to have support only on $\\mathcal{C}$ (equivalently, by restricting $G$ to its columns in $\\mathcal{C}$).\n\nDefine the estimated source location for a given estimate $\\widehat{\\mathbf{x}}$ as the candidate position $\\mathbf{s}_{\\widehat{j}}$ where $\\widehat{j} = \\arg\\max_{1 \\le j \\le N} | \\widehat{x}_j |$. Define the localization error (in millimeters) as\n$$\n\\varepsilon = \\lVert \\mathbf{s}_{j_0} - \\mathbf{s}_{\\widehat{j}} \\rVert_2.\n$$\nLet $\\varepsilon_{\\mathrm{WB}}$ denote the localization error for the whole-brain inversion (no restriction on $\\mathbf{x}$), and let $\\varepsilon_{\\mathrm{CL}}$ denote the localization error for the fMRI cluster-restricted inversion (restriction to $\\mathcal{C}$). Define the improvement (in millimeters) as\n$$\n\\Delta = \\varepsilon_{\\mathrm{WB}} - \\varepsilon_{\\mathrm{CL}}.\n$$\nA positive value of $\\Delta$ indicates a reduction in localization error due to fMRI restriction.\n\nImplement a program that performs the following steps using the given fixed geometry and test suite:\n\n1. Geometry and lead field.\n   - Use $M=6$ EEG sensors at positions (in millimeters)\n     - $\\mathbf{r}_1 = (90, 0, 0)$, $\\mathbf{r}_2 = (-90, 0, 0)$,\n     - $\\mathbf{r}_3 = (0, 90, 0)$, $\\mathbf{r}_4 = (0, -90, 0)$,\n     - $\\mathbf{r}_5 = (0, 0, 90)$, $\\mathbf{r}_6 = (0, 0, -90)$.\n   - Use $N=8$ candidate source locations (in millimeters)\n     - $\\mathbf{s}_1 = (40, 0, 0)$, $\\mathbf{s}_2 = (-40, 0, 0)$,\n     - $\\mathbf{s}_3 = (0, 40, 0)$, $\\mathbf{s}_4 = (0, -40, 0)$,\n     - $\\mathbf{s}_5 = (0, 0, 40)$, $\\mathbf{s}_6 = (0, 0, -40)$,\n     - $\\mathbf{s}_7 = (30, 30, 30)$, $\\mathbf{s}_8 = (-30, -30, 30)$.\n   - Construct $G$ via $G_{ij} = 1 / \\lVert \\mathbf{r}_i - \\mathbf{s}_j \\rVert_2^2$.\n\n2. Data generation for each test case.\n   - Use source amplitude $a = 1$ (dimensionless).\n   - For a given true index $j_0$, form $\\mathbf{y}_0 = G \\mathbf{x}_0$.\n   - Generate noise $\\mathbf{e}$ with standard deviation $\\sigma = \\alpha \\cdot \\mathrm{std}(\\mathbf{y}_0)$, where $\\alpha$ is the specified relative noise level and $\\mathrm{std}$ is the population standard deviation. Use a fixed pseudo-random seed $0$ to initialize the Gaussian noise generator.\n   - Form $\\mathbf{y} = \\mathbf{y}_0 + \\mathbf{e}$.\n\n3. Inference per test case.\n   - Whole-brain inversion: estimate $\\widehat{\\mathbf{x}}$ by minimizing $\\lVert \\mathbf{y} - G \\mathbf{x} \\rVert_2^2 + \\lambda \\lVert \\mathbf{x} \\rVert_2^2$ with the given $\\lambda$.\n   - Cluster-restricted inversion: let $\\mathcal{C}$ be the specified index set for that test, restrict the columns of $G$ to $\\mathcal{C}$, perform the same minimization to estimate $\\widehat{\\mathbf{x}}_{\\mathcal{C}}$, and map the chosen index back to the global index set.\n   - Compute $\\varepsilon_{\\mathrm{WB}}$ and $\\varepsilon_{\\mathrm{CL}}$ and report $\\Delta = \\varepsilon_{\\mathrm{WB}} - \\varepsilon_{\\mathrm{CL}}$ in millimeters.\n\nTest suite. For each case, the tuple is $(j_0, \\mathcal{C}, \\alpha, \\lambda)$:\n\n- Case $1$: $(7, \\{1,3,5,7\\}, 0.05, 10^{-3})$.\n- Case $2$: $(2, \\{1,3,5,7\\}, 0.01, 10^{-3})$.\n- Case $3$: $(5, \\{1,3,5,7\\}, 0.30, 10^{-2})$.\n- Case $4$: $(1, \\{1\\}, 0.20, 10^{-6})$.\n\nNotes on indexing: Indices $j_0$ and elements of $\\mathcal{C}$ are $1$-based in this description, corresponding to the ordering of $\\{\\mathbf{s}_j\\}_{j=1}^8$ above.\n\nYour program should produce a single line of output containing the four improvements $\\Delta$ for the test cases, as a comma-separated list enclosed in square brackets, with each value expressed in millimeters and rounded to three decimal places (for example, $[12.345,-4.210,0.000,5.678]$). No other text should be printed.",
            "solution": "The user has provided a computational problem in the domain of neuroscience data analysis, specifically concerning the fusion of Electroencephalography (EEG) and functional Magnetic Resonance Imaging (fMRI) data for brain source localization. This entry first validates the problem statement and then presents a detailed, principle-based solution.\n\n### Problem Validation\n\nThe problem is rigorously analyzed against the specified validation criteria.\n\n1.  **Givens Extraction**: All data, models, and parameters are explicitly provided. These include:\n    *   The forward model for EEG: $\\mathbf{y} = G\\mathbf{x} + \\mathbf{e}$.\n    *   The definition of the lead-field matrix $G$: $G_{ij} = 1 / \\lVert \\mathbf{r}_i - \\mathbf{s}_j \\rVert_2^2$.\n    *   The noise model: $\\mathbf{e} \\sim \\mathcal{N}(\\mathbf{0}, \\sigma^2 I_M)$ with $\\sigma = \\alpha \\cdot \\mathrm{std}(\\mathbf{y}_0)$.\n    *   The inverse problem solution method: Tikhonov-regularized least squares, minimizing $\\lVert \\mathbf{y} - G \\mathbf{x} \\rVert_2^2 + \\lambda \\lVert \\mathbf{x} \\rVert_2^2$.\n    *   fMRI-informed restriction via column selection on $G$.\n    *   Definitions for localization error ($\\varepsilon$) and improvement ($\\Delta$).\n    *   Fixed geometry for $M=6$ sensors and $N=8$ sources.\n    *   A test suite with four distinct cases specifying $(j_0, \\mathcal{C}, \\alpha, \\lambda)$.\n    *   A fixed seed for the pseudo-random number generator.\n    *   Clear instructions on indexing (1-based) and output format.\n\n2.  **Validation Check**:\n    *   **Scientifically Grounded**: The problem uses a simplified but standard and physically motivated model of EEG source localization. The linear forward model, inverse-square law for the lead field, additive Gaussian noise, and Tikhonov regularization are all foundational concepts in the field. Using fMRI to constrain the solution space is a well-established multimodal integration technique. The problem is scientifically sound.\n    *   **Well-Posed**: The Tikhonov regularization with $\\lambda > 0$ ensures that the inverse problem is well-posed computationally, yielding a unique and stable solution. All parameters are specified, so a deterministic result can be computed.\n    *   **Objective**: The problem is stated using precise mathematical language, free of ambiguity or subjective claims.\n    *   **Completeness**: The problem is self-contained and provides all necessary information to proceed to a solution. There are no contradictions.\n\n3.  **Verdict**: The problem is **valid**. It is a well-defined computational task based on established scientific principles.\n\n### Principle-Based Solution Design\n\nThe solution involves simulating EEG data based on a known source and then solving the inverse problem with and without fMRI-based spatial constraints to quantify the improvement in source localization accuracy.\n\n#### 1. Mathematical Framework\n\n**Forward Model**: The relationship between the $N$-dimensional source activity vector $\\mathbf{x}$ and the $M$-dimensional EEG sensor measurements $\\mathbf{y}$ is given by the linear system:\n$$\n\\mathbf{y} = G \\mathbf{x} + \\mathbf{e}\n$$\nHere, $G \\in \\mathbb{R}^{M \\times N}$ is the lead-field matrix, which maps source activities to sensor potentials. The problem provides a simplified model for its elements, $G_{ij} = 1/\\lVert \\mathbf{r}_i - \\mathbf{s}_j \\rVert_2^2$, where $\\mathbf{r}_i$ and $\\mathbf{s}_j$ are the positions of the $i$-th sensor and $j$-th source, respectively. This model captures the physical intuition that a source's influence on a sensor decays with distance. The term $\\mathbf{e}$ represents additive measurement noise, modeled as a zero-mean Gaussian random variable.\n\n**Inverse Problem**: Estimating the source activity $\\mathbf{x}$ from the measurement $\\mathbf{y}$ is an ill-posed inverse problem, primarily because $M \\ll N$ typically, and the columns of $G$ are often highly correlated. To find a stable and unique solution, we employ Tikhonov regularization (also known as ridge regression or L2-norm regularization). The estimated source vector, $\\widehat{\\mathbf{x}}$, is found by minimizing a cost function that balances data fidelity and solution norm:\n$$\n\\widehat{\\mathbf{x}} = \\arg\\min_{\\mathbf{x} \\in \\mathbb{R}^N} \\left\\{ \\lVert \\mathbf{y} - G \\mathbf{x} \\rVert_2^2 + \\lambda \\lVert \\mathbf{x} \\rVert_2^2 \\right\\}\n$$\nwhere $\\lambda > 0$ is the regularization parameter. This is a convex optimization problem with a unique, closed-form solution derived by setting the gradient of the cost function to zero:\n$$\n\\nabla_{\\mathbf{x}} \\left( (\\mathbf{y} - G\\mathbf{x})^T(\\mathbf{y} - G\\mathbf{x}) + \\lambda \\mathbf{x}^T\\mathbf{x} \\right) = -2G^T(\\mathbf{y} - G\\mathbf{x}) + 2\\lambda\\mathbf{x} = \\mathbf{0}\n$$\n$$\n(G^T G + \\lambda I_N) \\mathbf{x} = G^T \\mathbf{y}\n$$\nThe solution is thus:\n$$\n\\widehat{\\mathbf{x}} = (G^T G + \\lambda I_N)^{-1} G^T \\mathbf{y}\n$$\nwhere $I_N$ is the $N \\times N$ identity matrix.\n\n**fMRI-Informed Restriction**: fMRI can identify brain regions that are metabolically active. This information can be used to constrain the EEG inverse problem by assuming that the electrical sources are located within these fMRI-identified regions. Let $\\mathcal{C}$ be the set of indices of candidate sources within such a region. We enforce this constraint by restricting the search for $\\mathbf{x}$ to the subspace spanned by these sources. This is equivalent to solving the inverse problem using a restricted lead-field matrix, $G_{\\mathcal{C}}$, which consists only of the columns of $G$ corresponding to the indices in $\\mathcal{C}$. The resulting estimate, $\\widehat{\\mathbf{x}}_{\\mathcal{C}}$, is specific to this subset of sources.\n\n**Localization and Performance Evaluation**: The estimated source location is identified as the one with the maximum absolute amplitude in the estimated source vector: $\\widehat{j} = \\arg\\max_j |\\widehat{x}_j|$. The localization error, $\\varepsilon$, is the Euclidean distance between the true source position $\\mathbf{s}_{j_0}$ and the estimated source position $\\mathbf{s}_{\\widehat{j}}$: $\\varepsilon = \\lVert \\mathbf{s}_{j_0} - \\mathbf{s}_{\\widehat{j}} \\rVert_2$. We computethis error for both the whole-brain inversion ($\\varepsilon_{\\mathrm{WB}}$) and the cluster-restricted inversion ($\\varepsilon_{\\mathrm{CL}}$). The performance improvement due to the fMRI constraint is quantified as $\\Delta = \\varepsilon_{\\mathrm{WB}} - \\varepsilon_{\\mathrm{CL}}$.\n\n#### 2. Algorithmic Steps\n\nThe implementation will proceed as follows for each test case:\n\n1.  **Initialization**: Define the sensor and source position vectors. Construct the $M \\times N$ lead-field matrix $G$ using the specified distance-decay formula. Initialize a pseudo-random number generator with a fixed seed of $0$ for reproducibility.\n2.  **Data Simulation**:\n    a. For a given true source index $j_0$ (1-based), create the true source vector $\\mathbf{x}_0$ of length $N$, with a value of $a=1$ at the corresponding 0-based index and zeros elsewhere.\n    b. Compute the noiseless EEG signal: $\\mathbf{y}_0 = G \\mathbf{x}_0$.\n    c. Calculate the noise standard deviation $\\sigma = \\alpha \\cdot \\mathrm{std}(\\mathbf{y}_0)$, where $\\mathrm{std}$ is the population standard deviation.\n    d. Generate an $M$-dimensional noise vector $\\mathbf{e}$ from $\\mathcal{N}(0, \\sigma^2)$.\n    e. Create the final noisy measurement: $\\mathbf{y} = \\mathbf{y}_0 + \\mathbf{e}$.\n3.  **Whole-Brain Inversion**:\n    a. Solve the Tikhonov-regularized system $(G^T G + \\lambda I_N) \\widehat{\\mathbf{x}}_{\\mathrm{WB}} = G^T \\mathbf{y}$ to find the whole-brain estimate $\\widehat{\\mathbf{x}}_{\\mathrm{WB}}$.\n    b. Identify the estimated source index $\\widehat{j}_{\\mathrm{WB}} = \\arg\\max_j |\\widehat{x}_{\\mathrm{WB},j}|$.\n    c. Calculate the localization error $\\varepsilon_{\\mathrm{WB}} = \\lVert \\mathbf{s}_{j_0} - \\mathbf{s}_{\\widehat{j}_{\\mathrm{WB}}} \\rVert_2$.\n4.  **Cluster-Restricted Inversion**:\n    a. From the full lead-field matrix $G$, form the restricted matrix $G_{\\mathcal{C}}$ using the columns specified by the fMRI cluster $\\mathcal{C}$.\n    b. Solve the corresponding Tikhonov system $(G_{\\mathcal{C}}^T G_{\\mathcal{C}} + \\lambda I_{|\\mathcal{C}|}) \\widehat{\\mathbf{x}}_{\\mathcal{C}} = G_{\\mathcal{C}}^T \\mathbf{y}$ for the restricted source vector $\\widehat{\\mathbf{x}}_{\\mathcal{C}}$.\n    c. Identify the index of the maximum amplitude source within the cluster, and map it back to its global index $\\widehat{j}_{\\mathrm{CL}}$.\n    d. Calculate the localization error $\\varepsilon_{\\mathrm{CL}} = \\lVert \\mathbf{s}_{j_0} - \\mathbf{s}_{\\widehat{j}_{\\mathrm{CL}}} \\rVert_2$.\n5.  **Calculate Improvement**: Compute the final metric $\\Delta = \\varepsilon_{\\mathrm{WB}} - \\varepsilon_{\\mathrm{CL}}$.\n\nThis procedure will be repeated for all four test cases provided, and the resulting $\\Delta$ values will be collected and formatted as specified.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the EEG-fMRI source localization problem as specified.\n    \"\"\"\n    \n    # 1. Geometry and lead field construction.\n    # EEG sensors (M=6)\n    sensors = np.array([\n        [90.0, 0.0, 0.0], [-90.0, 0.0, 0.0],\n        [0.0, 90.0, 0.0], [0.0, -90.0, 0.0],\n        [0.0, 0.0, 90.0], [0.0, 0.0, -90.0]\n    ])\n    \n    # Candidate source locations (N=8)\n    sources = np.array([\n        [40.0, 0.0, 0.0], [-40.0, 0.0, 0.0],\n        [0.0, 40.0, 0.0], [0.0, -40.0, 0.0],\n        [0.0, 0.0, 40.0], [0.0, 0.0, -40.0],\n        [30.0, 30.0, 30.0], [-30.0, -30.0, 30.0]\n    ])\n    \n    M, N = sensors.shape[0], sources.shape[0]\n\n    # Construct the lead-field matrix G\n    # G_ij = 1 / ||r_i - s_j||^2\n    # Vectorized computation for efficiency\n    diffs = sensors[:, np.newaxis, :] - sources[np.newaxis, :, :]  # Shape (M, N, 3)\n    dist_sq = np.sum(diffs**2, axis=2) # Shape (M, N)\n    G = 1.0 / dist_sq\n\n    # Define test suite\n    # Each tuple is (j_0, C, alpha, lambda) with 1-based indexing for j_0 and C\n    test_cases = [\n        (7, {1, 3, 5, 7}, 0.05, 1e-3),\n        (2, {1, 3, 5, 7}, 0.01, 1e-3),\n        (5, {1, 3, 5, 7}, 0.30, 1e-2),\n        (1, {1}, 0.20, 1e-6)\n    ]\n    \n    # Initialize a single random number generator with a fixed seed for reproducibility\n    rng = np.random.default_rng(0)\n    \n    results = []\n\n    def solve_tikhonov(g_matrix, y_vec, lam):\n        \"\"\"\n        Solves the Tikhonov-regularized least squares problem:\n        min ||y - Gx||^2 + lambda * ||x||^2\n        The solution is x_hat = (G'G + lambda*I)^-1 * G'y\n        \"\"\"\n        # Get dimensions for identity matrix\n        n_sources = g_matrix.shape[1]\n        \n        # Form the matrices for the normal equation: Ax = b\n        # A = (G'G + lambda*I)\n        # b = G'y\n        GT = g_matrix.T\n        GTG = GT @ g_matrix\n        A = GTG + lam * np.eye(n_sources)\n        b = GT @ y_vec\n        \n        # Solve the linear system Ax = b for x\n        x_hat = np.linalg.solve(A, b)\n        return x_hat\n\n    # Process each test case\n    for case in test_cases:\n        j0_1based, C_1based, alpha, lambda_reg = case\n        \n        # Convert from 1-based to 0-based index\n        j0_idx = j0_1based - 1\n        C_idx = sorted([c - 1 for c in C_1based])\n        \n        # 2. Data generation\n        a = 1.0\n        x0 = np.zeros(N)\n        x0[j0_idx] = a\n        y0 = G @ x0\n        \n        # Add noise\n        sigma = alpha * np.std(y0)  # Population standard deviation\n        e = rng.normal(loc=0.0, scale=sigma, size=M)\n        y = y0 + e\n        \n        # 3. Whole-brain (WB) inversion\n        x_hat_wb = solve_tikhonov(G, y, lambda_reg)\n        j_hat_wb_idx = np.argmax(np.abs(x_hat_wb))\n        s_hat_wb = sources[j_hat_wb_idx]\n        s_true = sources[j0_idx]\n        error_wb = np.linalg.norm(s_true - s_hat_wb)\n        \n        # 4. Cluster-restricted (CL) inversion\n        G_c = G[:, C_idx]\n        x_hat_c = solve_tikhonov(G_c, y, lambda_reg)\n        \n        # Find the source with max amplitude within the cluster\n        local_max_idx = np.argmax(np.abs(x_hat_c))\n        # Map back to the global source index\n        j_hat_cl_idx = C_idx[local_max_idx]\n        \n        s_hat_cl = sources[j_hat_cl_idx]\n        error_cl = np.linalg.norm(s_true - s_hat_cl)\n        \n        # 5. Compute improvement\n        delta = error_wb - error_cl\n        results.append(delta)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join([f'{d:.3f}' for d in results])}]\")\n\nsolve()\n```"
        }
    ]
}