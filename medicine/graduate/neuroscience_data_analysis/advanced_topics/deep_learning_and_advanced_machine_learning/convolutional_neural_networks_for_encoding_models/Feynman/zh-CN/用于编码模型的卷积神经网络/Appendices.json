{
    "hands_on_practices": [
        {
            "introduction": "在构建复杂的编码模型之前，我们必须掌握其核心组件——卷积层的基本原理。本练习将重点放在一项基本技能上：根据输入尺寸、卷积核大小、步长和填充来计算输出特征图的维度。这不仅仅是一个技术练习，它对于设计与有意义的神经科学结构（如视网膜拓扑图）相对应的特征图，以及管理模型的计算复杂度都至关重要。",
            "id": "4149684",
            "problem": "神经科学中的一个视觉编码模型使用卷积神经网络 (CNN) 将二维刺激转换为排列在视网膜拓扑网格上的预测响应。考虑一个应用于输入张量的二维卷积层，该张量的空间高度为 $H$，空间宽度为 $W$，通道数为 $C$，其形状记为 $(H, W, C)$。该层使用空间大小为 $k \\times k$ 的方形卷积核，在两个空间维度上的步幅为 $s$，并对空间边界对称地应用宽度为 $p$ 的零填充。该层有 $F$ 个滤波器，每个滤波器产生一个输出特征图。假设卷积以带有步幅和零填充的标准离散形式实现，并且卷积核不会延伸到填充后的输入之外。\n\n从零填充输入上的离散卷积的定义以及将步幅解释为连续卷积核放置位置之间的步长出发，推导出当卷积核仅放置在完全覆盖填充后输入的位置时，输出空间维度的一般表达式。然后，对于一个具体的编码场景，其中刺激是单通道的视网膜拓扑图，其参数为 $H=95$、$W=127$、$C=1$，卷积层的参数为 $k=11$、$s=4$、$p=3$ 和 $F=32$，计算得到的输出张量形状 $(H_{\\text{out}}, W_{\\text{out}}, F)$。将您的最终答案表示为有序三元组 $(H_{\\text{out}}, W_{\\text{out}}, F)$。不需要四舍五入。",
            "solution": "该问题要求推导二维卷积层输出维度的一般公式，并针对一组特定参数计算这些维度。\n\n首先，我们推导一般表达式。让我们考虑一个单一的空间维度，例如高度。输入的高度为 $H$。应用宽度为 $p$ 的对称零填充，意味着在顶部和底部各添加 $p$ 行零。因此，这个填充后输入张量的有效高度为 $H' = H + 2p$。\n\n卷积核的空间高度为 $k$。我们需要确定该卷积核在填充后的输入上可以放置的可能位置数量。卷积核以步幅 $s$ 分隔的位置上应用。这些位置由卷积核的左上角确定。\n\n让填充后高度维度的索引从 $0$ 到 $H' - 1$。卷积核的第一次放置，其顶部边缘将在索引 $0$ 处。第二次放置将在索引 $s$ 处，第三次在 $2s$ 处，以此类推。设第 $j$ 次放置的顶部边缘在索引 $i_j = j \\cdot s$ 处，其中 $j$ 是一个从零开始的索引 ($j = 0, 1, 2, \\dots$)。\n\n问题陈述，卷积核必须完全位于填充后的输入之内。这意味着整个高度为 $k$ 的卷积核必须完全位于高度为 $H'$ 的填充后输入的边界内。如果卷积核的顶部边缘在索引 $i_j$ 处，则卷积核跨越的索引范围为从 $i_j$ 到 $i_j + k - 1$。为了使卷积核完全被包含，我们必须有：\n$$i_j + k - 1 \\leq H' - 1$$\n$$i_j \\leq H' - k$$\n代入 $i_j = j \\cdot s$ 和 $H' = H + 2p$，我们得到：\n$$j \\cdot s \\leq (H + 2p) - k$$\n为了找到有效放置的最大数量，我们需要找到满足此不等式的 $j$ 的最大整数值，我们称之为 $j_{\\max}$。\n$$j_{\\max} = \\left\\lfloor \\frac{H + 2p - k}{s} \\right\\rfloor$$\n$j$ 的可能值为 $0, 1, 2, \\dots, j_{\\max}$。这些值的总数是 $j_{\\max} + 1$。每个 $j$ 的值对应于输出特征图中的一个位置。因此，输出特征图的高度 $H_{\\text{out}}$ 是：\n$$H_{\\text{out}} = j_{\\max} + 1 = \\left\\lfloor \\frac{H + 2p - k}{s} \\right\\rfloor + 1$$\n同样的逻辑独立地适用于宽度维度。宽度为 $W$ 的输入经过对称填充 $p$ 后，变为宽度为 $W' = W + 2p$ 的填充后输入。输出宽度 $W_{\\text{out}}$ 由类似的公式给出：\n$$W_{\\text{out}} = \\left\\lfloor \\frac{W + 2p - k}{s} \\right\\rfloor + 1$$\n输出张量的通道数（或深度）由滤波器的数量 $F$ 决定。每个滤波器与输入体（跨越所有 $C$ 个输入通道）进行卷积，以产生一个二维特征图。因此，使用 $F$ 个滤波器，输出张量的深度将为 $F$。因此，输出张量的形状为 $(H_{\\text{out}}, W_{\\text{out}}, F)$。\n\n现在，我们将这些推导出的公式应用于所提供的具体场景。给定的参数是：\n- 输入高度 $H = 95$\n- 输入宽度 $W = 127$\n- 输入通道数 $C = 1$\n- 卷积核大小 $k = 11$\n- 步幅 $s = 4$\n- 填充宽度 $p = 3$\n- 滤波器数量 $F = 32$\n\n我们计算输出高度 $H_{\\text{out}}$：\n$$H_{\\text{out}} = \\left\\lfloor \\frac{H + 2p - k}{s} \\right\\rfloor + 1$$\n$$H_{\\text{out}} = \\left\\lfloor \\frac{95 + 2(3) - 11}{4} \\right\\rfloor + 1$$\n$$H_{\\text{out}} = \\left\\lfloor \\frac{95 + 6 - 11}{4} \\right\\rfloor + 1$$\n$$H_{\\text{out}} = \\left\\lfloor \\frac{90}{4} \\right\\rfloor + 1$$\n$$H_{\\text{out}} = \\lfloor 22.5 \\rfloor + 1$$\n$$H_{\\text{out}} = 22 + 1 = 23$$\n接下来，我们计算输出宽度 $W_{\\text{out}}$：\n$$W_{\\text{out}} = \\left\\lfloor \\frac{W + 2p - k}{s} \\right\\rfloor + 1$$\n$$W_{\\text{out}} = \\left\\lfloor \\frac{127 + 2(3) - 11}{4} \\right\\rfloor + 1$$\n$$W_{\\text{out}} = \\left\\lfloor \\frac{127 + 6 - 11}{4} \\right\\rfloor + 1$$\n$$W_{\\text{out}} = \\left\\lfloor \\frac{122}{4} \\right\\rfloor + 1$$\n$$W_{\\text{out}} = \\lfloor 30.5 \\rfloor + 1$$\n$$W_{\\text{out}} = 30 + 1 = 31$$\n输出通道的数量等于滤波器的数量，即 $F = 32$。\n\n因此，最终的输出张量形状 $(H_{\\text{out}}, W_{\\text{out}}, F)$ 为 $(23, 31, 32)$。最终答案要求以有序三元组的形式表示。",
            "answer": "$$ \\boxed{ \\begin{pmatrix} 23 & 31 & 32 \\end{pmatrix} } $$"
        },
        {
            "introduction": "如果模型的性能评估方法不当，那么即使是功能强大的模型也毫无用处。本练习旨在解决神经科学数据分析中最关键也最常见的陷阱之一：交叉验证策略的选择。通过一个精心设计的涉及“刺激记忆器”的思想实验，您将发现为什么在试验层面划分数据会严重高估模型的泛化能力，以及为什么在刺激层面进行划分对于真实评估模型在新刺激上的表现至关重要。",
            "id": "4149631",
            "problem": "在一个视觉神经科学的编码模型中，一个卷积神经网络（CNN）将每个静态图像刺激 $s$ 转换为一个特征向量 $\\phi(s)$，然后一个线性读出层预测单个神经元的响应为 $\\hat{y}(s) = w^{\\top}\\phi(s)$。神经元对刺激 $s$ 在第 $r$ 次试验中的真实单次试验响应被建模为 $y_{s,r} = \\mu_s + \\epsilon_{s,r}$，其中 $\\mu_s$ 是刺激诱发的均值，$\\epsilon_{s,r}$ 是零均值的试验噪声，该噪声在各次试验间独立，方差为 $\\sigma_{\\epsilon}^2$。在所有刺激上，$\\mu_s$ 的方差为 $\\sigma_{\\mu}^2$。\n\n考虑两种交叉验证方案：\n\n- 试验级划分：对于每个刺激 $s$，将 $n_{\\text{tr}}$ 次试验放入训练集，$n_{\\text{te}}$ 次试验放入测试集，因此每个刺激都同时出现在训练集和测试集中。\n- 刺激级划分：将刺激划分为不相交的训练集和测试集，因此测试集中的任何刺激都未在训练集中出现过。\n\n假设存在一个能够表示 $\\phi(s)$ 的任意函数的高容量编码器，并考虑一个基线“刺激记忆器”，该记忆器忽略 $\\phi(s)$，并在刺激 $s$ 存在于训练集中时，将 $\\hat{y}(s)$ 预测为每个刺激的训练均值 $\\bar{y}^{\\text{train}}_s = \\frac{1}{n_{\\text{tr}}}\\sum_{r=1}^{n_{\\text{tr}}} y_{s,r}$。当刺激不存在于训练集中时（刺激级划分），假设该基线模型默认使用全局训练均值 $\\bar{y}^{\\text{global}} = \\frac{1}{M_{\\text{tr}} n_{\\text{tr}}}\\sum_{s \\in \\text{train}}\\sum_{r=1}^{n_{\\text{tr}}} y_{s,r}$，该值不携带任何与刺激相关的信息。评估使用预测值与测试样本的测量响应之间的 Pearson 相关系数。\n\n选择所有正确的选项：\n\nA. 在试验级划分下，刺激记忆器的预测值 $\\bar{y}^{\\text{train}}_s$ 与所有测试样本的单次试验测试响应 $y_{s,r}$ 之间的期望 Pearson 相关系数为\n$$\n\\rho_{\\text{trial}} \\;=\\; \\frac{\\sigma_{\\mu}^2}{\\sqrt{\\left(\\sigma_{\\mu}^2 + \\frac{\\sigma_{\\epsilon}^2}{n_{\\text{tr}}}\\right)\\left(\\sigma_{\\mu}^2 + \\sigma_{\\epsilon}^2\\right)}} \\, .\n$$\n\nB. 在刺激级划分下，同样的记忆器（对于未见过的刺激，默认使用全局均值 $\\bar{y}^{\\text{global}}$）与单次试验的测试响应的期望 Pearson 相关系数为 $0$，即 $\\mathbb{E}[\\rho_{\\text{stim}}] = 0$。\n\nC. 当 $n_{\\text{tr}} \\to \\infty$ 时，试验级划分下记忆器的期望相关性收敛于\n$$\n\\lim_{n_{\\text{tr}}\\to\\infty} \\rho_{\\text{trial}} \\;=\\; \\sqrt{\\frac{\\sigma_{\\mu}^2}{\\sigma_{\\mu}^2 + \\sigma_{\\epsilon}^2}} \\, ,\n$$\n该值等于单次试验的分半信度，因此会显著高估对未见过刺激的泛化能力。\n\nD. 对每个刺激的 $n_{\\text{te}}$ 次重复试验的测试响应求平均，可以消除试验级划分下的高估；在使用训练均值和测试均值时，对于任何有限的 $n_{\\text{tr}}$ 和 $n_{\\text{te}}$，期望相关系数都恰好为 $1$。\n\nE. 如果来自 CNN 特征的读出是线性的且经过正则化，则试验级划分是对未见过刺激的泛化性能的无偏估计量，因此重复的刺激不能夸大性能。\n\n你可以假设 $M_{\\text{tr}}$ 和 $M_{\\text{te}}$ 是有限的，$\\epsilon_{s,r}$ 独立于 $\\mu_s$，并且评估会根据每种划分方式适当地汇集跨刺激和试验的测试样本。你的答案必须是所提供选项的一个子集。",
            "solution": "首先验证问题陈述，以确保其在科学上是合理的、良定的和客观的。\n\n### 第 1 步：提取已知条件\n-   来自 CNN 特征的模型预测：$\\hat{y}(s) = w^{\\top}\\phi(s)$。\n-   真实神经响应模型：$y_{s,r} = \\mu_s + \\epsilon_{s,r}$。\n-   $\\mu_s$：刺激诱发的均值响应，方差为 $\\text{Var}(\\mu_s) = \\sigma_{\\mu}^2$。\n-   $\\epsilon_{s,r}$：零均值的试验噪声，方差为 $\\sigma_{\\epsilon}^2$，在各次试验间独立且独立于 $\\mu_s$。\n-   **试验级划分**：对于每个刺激 $s$，$n_{\\text{tr}}$ 次试验用于训练，$n_{\\text{te}}$ 次试验用于测试。\n-   **刺激级划分**：训练和测试的刺激集不相交。\n-   **刺激记忆器基线模型**：\n    -   如果刺激 $s$ 在训练集中：预测 $\\hat{y}(s) = \\bar{y}^{\\text{train}}_s = \\frac{1}{n_{\\text{tr}}}\\sum_{r=1}^{n_{\\text{tr}}} y_{s,r}$。\n    -   如果刺激 $s$ 不在训练集中：预测 $\\hat{y}(s) = \\bar{y}^{\\text{global}} = \\frac{1}{M_{\\text{tr}} n_{\\text{tr}}}\\sum_{s \\in \\text{train}}\\sum_{r=1}^{n_{\\text{tr}}} y_{s,r}$。\n-   **评估指标**：预测值与单次试验测试响应之间的 Pearson 相关系数。\n-   **假设**：高容量编码器环境，有限数量的训练/测试刺激（$M_{\\text{tr}}$, $M_{\\text{te}}$），噪声和刺激均值的独立性。\n\n### 第 2 步：使用提取的已知条件进行验证\n该问题描述了计算神经科学中用于分析编码模型和交叉验证程序的标准理论框架。\n-   **科学依据**：响应模型 $y_{s,r} = \\mu_s + \\epsilon_{s,r}$ 是对神经元发放率的一个常用且有用的近似。试验级和刺激级交叉验证之间的区别是该领域一个关键且已确立的方法学主题。该设定在科学上是合理的。\n-   **良定性**：问题提供了一个清晰的概率模型，并要求推导期望的统计量（Pearson 相关系数）。定义是精确的，允许存在唯一的数学解。\n-   **客观性**：语言是技术性的，没有歧义。\n\n该问题不存在所列出的缺陷。这是一个在神经科学数据分析中有效、可形式化的问题。\n\n### 第 3 步：结论与行动\n问题陈述是**有效**的。将推导解答。\n\n### 推导与选项分析\n两个随机变量 $X$ 和 $Y$ 之间的 Pearson 相关系数由 $\\rho(X,Y) = \\frac{\\text{Cov}(X,Y)}{\\sqrt{\\text{Var}(X)\\text{Var}(Y)}}$ 给出。我们为测试集上的模型预测和测量响应计算该值。期望是针对刺激和试验噪声的分布计算的。我们可以不失一般性地假设 $\\mathbb{E}[\\mu_s] = 0$。\n\n首先，让我们确定单次试验测试响应 $y_{s,r} = \\mu_s + \\epsilon_{s,r}$ 的方差。\n由于 $\\mu_s$ 和 $\\epsilon_{s,r}$ 是独立的：\n$$\n\\text{Var}(y_{s,r}) = \\text{Var}(\\mu_s) + \\text{Var}(\\epsilon_{s,r}) = \\sigma_{\\mu}^2 + \\sigma_{\\epsilon}^2\n$$\n这将是与单次试验响应相关性计算公式中分母的一项。\n\n**A. 试验级划分分析**\n在此方案下，测试刺激 $s$ 在训练期间已经见过。预测是该刺激的训练响应的均值：\n$$\n\\hat{y}_s = \\bar{y}^{\\text{train}}_s = \\frac{1}{n_{\\text{tr}}}\\sum_{i=1}^{n_{\\text{tr}}} y_{s,i}^{\\text{train}} = \\frac{1}{n_{\\text{tr}}}\\sum_{i=1}^{n_{\\text{tr}}} (\\mu_s + \\epsilon_{s,i}^{\\text{train}}) = \\mu_s + \\bar{\\epsilon}_s^{\\text{train}}\n$$\n其中 $\\bar{\\epsilon}_s^{\\text{train}} = \\frac{1}{n_{\\text{tr}}}\\sum_{i=1}^{n_{\\text{tr}}} \\epsilon_{s,i}^{\\text{train}}$。\n测试响应为 $y_{s,r}^{\\text{test}} = \\mu_s + \\epsilon_{s,r}^{\\text{test}}$。\n\n我们需要计算 $\\rho(\\hat{y}_s, y_{s,r}^{\\text{test}})$。\n1.  预测的方差是：\n    $$\n    \\text{Var}(\\hat{y}_s) = \\text{Var}(\\mu_s + \\bar{\\epsilon}_s^{\\text{train}}) = \\text{Var}(\\mu_s) + \\text{Var}(\\bar{\\epsilon}_s^{\\text{train}})\n    $$\n    $n_{\\text{tr}}$ 个独立同分布噪声项的均值的方差是 $\\frac{\\sigma_{\\epsilon}^2}{n_{\\text{tr}}}$。因此，\n    $$\n    \\text{Var}(\\hat{y}_s) = \\sigma_{\\mu}^2 + \\frac{\\sigma_{\\epsilon}^2}{n_{\\text{tr}}}\n    $$\n2.  预测与单次试验测试响应之间的协方差是：\n    $$\n    \\text{Cov}(\\hat{y}_s, y_{s,r}^{\\text{test}}) = \\text{Cov}(\\mu_s + \\bar{\\epsilon}_s^{\\text{train}}, \\mu_s + \\epsilon_{s,r}^{\\text{test}})\n    $$\n    由于刺激均值 $\\mu_s$、训练噪声 $\\bar{\\epsilon}_s^{\\text{train}}$ 和测试噪声 $\\epsilon_{s,r}^{\\text{test}}$ 是相互独立的（噪声在各次试验间独立），协方差简化为：\n    $$\n    \\text{Cov}(\\hat{y}_s, y_{s,r}^{\\text{test}}) = \\text{Cov}(\\mu_s, \\mu_s) = \\text{Var}(\\mu_s) = \\sigma_{\\mu}^2\n    $$\n3.  Pearson 相关系数是：\n    $$\n    \\rho_{\\text{trial}} = \\frac{\\text{Cov}(\\hat{y}_s, y_{s,r}^{\\text{test}})}{\\sqrt{\\text{Var}(\\hat{y}_s) \\text{Var}(y_{s,r}^{\\text{test}})}} = \\frac{\\sigma_{\\mu}^2}{\\sqrt{\\left(\\sigma_{\\mu}^2 + \\frac{\\sigma_{\\epsilon}^2}{n_{\\text{tr}}}\\right)\\left(\\sigma_{\\mu}^2 + \\sigma_{\\epsilon}^2\\right)}}\n    $$\n这个表达式与选项 A 中提供的表达式相匹配。\n**结论：正确**\n\n**B. 刺激级划分分析**\n在此方案下，一个测试刺激 $s$ 在训练期间未曾见过。记忆器模型的预测是所有训练响应的全局均值：\n$$\n\\hat{y}(s) = \\bar{y}^{\\text{global}}\n$$\n这个预测对所有测试刺激都是一个常数值。设这个常数为 $C$。$C$ 的值是一个依赖于训练集的随机变量，但它独立于任何测试刺激 $s$ 及其对应的响应 $y_{s,r}$。\n我们正在计算预测值 $\\{\\hat{y}(s_i)\\}$ 和测试数据 $\\{y_{s_i, r_j}\\}$ 之间的相关性。由于对所有测试刺激的预测 $\\hat{y}(s)$ 都是相同的，因此在测试集的背景下，测试预测的方差为零。样本 Pearson 相关系数将是未定义的（$0/0$）。然而，问题要求的是期望相关系数，这意味着我们应该将预测器和响应视为随机变量，并考虑它们之间的理论相关性。\n预测器 $\\hat{y}_{\\text{test}} = \\bar{y}^{\\text{global}}$ 是一个随机变量，其值由训练集（刺激和噪声）决定。测试响应 $y_{\\text{test}} = \\mu_{s_{\\text{test}}} + \\epsilon_{s_{\\text{test}}, r}$ 由测试集决定。由于训练和测试的刺激集不相交，决定 $\\hat{y}_{\\text{test}}$ 的随机变量独立于决定 $y_{\\text{test}}$ 的随机变量。\n当两个随机变量独立时，它们的协方差为零。\n$$\n\\text{Cov}(\\hat{y}_{\\text{test}}, y_{\\text{test}}) = 0\n$$\n由于方差 $\\text{Var}(\\hat{y}_{\\text{test}})$ 和 $\\text{Var}(y_{\\text{test}})$ 不为零（对于 $\\sigma_\\mu, \\sigma_\\epsilon > 0$ 和有限的 $M_{tr}, n_{tr}$），理论相关性为：\n$$\n\\rho_{\\text{stim}} = \\frac{0}{\\sqrt{\\text{Var}(\\hat{y}_{\\text{test}}) \\text{Var}(y_{\\text{test}})}} = 0\n$$\n因此，该相关性的期望值为 $0$。\n**结论：正确**\n\n**C. 试验级划分相关性极限分析**\n我们取选项 A 中表达式在训练试验次数 $n_{\\text{tr}}$ 趋于无穷大时的极限：\n$$\n\\lim_{n_{\\text{tr}}\\to\\infty} \\rho_{\\text{trial}} = \\lim_{n_{\\text{tr}}\\to\\infty} \\frac{\\sigma_{\\mu}^2}{\\sqrt{\\left(\\sigma_{\\mu}^2 + \\frac{\\sigma_{\\epsilon}^2}{n_{\\text{tr}}}\\right)\\left(\\sigma_{\\mu}^2 + \\sigma_{\\epsilon}^2\\right)}}\n$$\n当 $n_{\\text{tr}}\\to\\infty$ 时，项 $\\frac{\\sigma_{\\epsilon}^2}{n_{\\text{tr}}} \\to 0$。表达式变为：\n$$\n\\frac{\\sigma_{\\mu}^2}{\\sqrt{(\\sigma_{\\mu}^2 + 0)(\\sigma_{\\mu}^2 + \\sigma_{\\epsilon}^2)}} = \\frac{\\sigma_{\\mu}^2}{\\sqrt{\\sigma_{\\mu}^4 + \\sigma_{\\mu}^2 \\sigma_{\\epsilon}^2}} = \\frac{\\sigma_{\\mu}^2}{\\sigma_{\\mu}\\sqrt{\\sigma_{\\mu}^2 + \\sigma_{\\epsilon}^2}} = \\frac{\\sigma_{\\mu}}{\\sqrt{\\sigma_{\\mu}^2 + \\sigma_{\\epsilon}^2}}\n$$\n这可以重写为 $\\sqrt{\\frac{\\sigma_{\\mu}^2}{\\sigma_{\\mu}^2 + \\sigma_{\\epsilon}^2}}$，与选项 C 中的公式相匹配。\n该选项将其等同于“单次试验的分半信度”。这个量也被称为噪声天花板，表示任何为每个刺激预测单一值的模型与含噪声的单次试验数据之间可能的最大相关性。它可以被推导为真实均值响应 $\\mu_s$ 和单次试验响应 $y_{s,r} = \\mu_s + \\epsilon_{s,r}$ 之间的相关性，这恰好是我们计算出的极限。将此极限解释为对泛化能力的高估是正确的，因为该模型在未见过刺激上的性能为 $0$（根据 B 部分），而这个极限可能远大于 $0$。\n**结论：正确**\n\n**D. 测试响应平均化分析**\n该选项表明，通过将训练均值 $\\bar{y}^{\\text{train}}_s$ 与测试均值 $\\bar{y}^{\\text{test}}_s = \\mu_s + \\bar{\\epsilon}_s^{\\text{test}}$（其中 $\\text{Var}(\\bar{\\epsilon}_s^{\\text{test}}) = \\sigma_\\epsilon^2/n_{\\text{te}}$）相关联，相关系数将变为 $1$。\n让我们使用我们已经推导出的分量来计算这个相关性：\n-   $\\text{Cov}(\\bar{y}_s^{\\text{train}}, \\bar{y}_s^{\\text{test}}) = \\text{Cov}(\\mu_s + \\bar{\\epsilon}_{s}^{\\text{train}}, \\mu_s + \\bar{\\epsilon}_{s}^{\\text{test}}) = \\text{Var}(\\mu_s) = \\sigma_{\\mu}^2$。\n-   $\\text{Var}(\\bar{y}_s^{\\text{train}}) = \\sigma_{\\mu}^2 + \\sigma_{\\epsilon}^2/n_{\\text{tr}}$。\n-   $\\text{Var}(\\bar{y}_s^{\\text{test}}) = \\sigma_{\\mu}^2 + \\sigma_{\\epsilon}^2/n_{\\text{te}}$。\n相关系数是：\n$$\n\\rho = \\frac{\\sigma_{\\mu}^2}{\\sqrt{\\left(\\sigma_{\\mu}^2 + \\frac{\\sigma_{\\epsilon}^2}{n_{\\text{tr}}}\\right)\\left(\\sigma_{\\mu}^2 + \\frac{\\sigma_{\\epsilon}^2}{n_{\\text{te}}}\\right)}}\n$$\n为了使该值等于 $1$，分子的平方必须等于平方根内的项：$(\\sigma_{\\mu}^2)^2 = (\\sigma_{\\mu}^2 + \\frac{\\sigma_{\\epsilon}^2}{n_{\\text{tr}}})(\\sigma_{\\mu}^2 + \\frac{\\sigma_{\\epsilon}^2}{n_{\\text{te}}})$。这仅在 $\\sigma_{\\epsilon}^2 = 0$ 或 $n_{\\text{tr}} \\to \\infty$ 和 $n_{\\text{te}} \\to \\infty$ 同时成立时才为真。对于任何有限的试验次数和非零噪声，此相关性严格小于 $1$。该说法是错误的。此外，对测试响应求平均并不能消除由刺激共享引起高估的根本问题。\n**结论：不正确**\n\n**E. 正则化线性模型分析**\n该选项声称，对于一个正则化的线性模型 $\\hat{y}(s) = w^{\\top}\\phi(s)$，试验级划分提供了对泛化性能的*无偏*估计。泛化性能指的是在未见过刺激上的性能，这需要通过刺激级划分来衡量。因此，该选项声称 $\\mathbb{E}[\\rho_{\\text{trial}}] = \\mathbb{E}[\\rho_{\\text{stim}}]$。\n这是一个众所周知的谬误。试验级划分允许模型通过部分“记忆”训练集中每个刺激的平均响应来获得高性能，因为这些相同的刺激也出现在测试集中。而刺激级划分则迫使模型学习从刺激特征 $\\phi(s)$ 到响应 $\\mu_s$ 的*通用*映射。即使有正则化，在试验级划分上训练的模型也可以利用训练集和测试集之间共享的刺激身份，导致一个过于乐观的（虚高的）性能分数，这个分数并不能反映对新刺激的真实泛化能力。正则化可能会减少对训练集噪声的过拟合程度，但它不能消除因在训练期间看到测试刺激而获得的信息优势。因此，性能估计是有偏的，而不是无偏的。\n**结论：不正确**\n\n基于以上分析，选项 A、B 和 C 是正确的。",
            "answer": "$$\\boxed{ABC}$$"
        },
        {
            "introduction": "在掌握了预测和评估之后，我们可以提出一个更深层次的问题：我们的模型表示信息的方式与大脑相似吗？本练习将指导您完成一个完整的研究级工作流程，使用表征相似性分析（Representational Similarity Analysis, RSA）这一强大的技术来比较表征几何。您将实现从计算表征非相似性矩阵（Representational Dissimilarity Matrix, RDM）到使用置换检验进行严格的统计假设检验，并应用错误发现率（False Discovery Rate, FDR）校正来处理跨模型层和大脑区域的多重比较的整个流程。",
            "id": "4149629",
            "problem": "您的任务是设计并实现一个完整的、基于置换的假设检验，用以评估在神经科学编码模型背景下，卷积神经网络 (CNN) 层与大脑感兴趣区域 (ROIs) 之间的表征相似性分析 (RSA) 对齐的显著性，然后使用错误发现率 (FDR) 进行多重比较校正。解决方案必须是一个可运行的程序，并且必须产生确定性的输出。\n\n从适用于此领域的以下基本基础开始：\n- RSA 通过量化两个空间（例如，CNN 层特征空间和神经 ROI 响应空间）的表征非相似性矩阵 (RDM) 的上三角项之间的统计关联，来比较它们。\n- 对于 $n$ 个刺激，一个 RDM 是一个对角线为零的对称矩阵，其位于 $(i,j)$ 的项是在给定特征空间中刺激 $i$ 和刺激 $j$ 之间的非相似性。一个广泛使用的非相似性度量是欧几里得距离：对于特征向量 $\\mathbf{x}_i \\in \\mathbb{R}^d$ 和 $\\mathbf{x}_j \\in \\mathbb{R}^d$，欧几里得距离为 $d_{ij} = \\left\\|\\mathbf{x}_i - \\mathbf{x}_j\\right\\|_2$。\n- 斯皮尔曼等级相关通过首先用值的等级替换值，然后计算等级之间的皮尔逊相关来衡量两个变量之间的统计关联。向量 $\\mathbf{u}$ 和 $\\mathbf{v}$ 之间的皮尔逊相关定义为\n$$\n\\rho(\\mathbf{u},\\mathbf{v}) = \\frac{\\sum_{k=1}^{m} (u_k - \\bar{u})(v_k - \\bar{v})}{\\sqrt{\\sum_{k=1}^{m}(u_k - \\bar{u})^2}\\sqrt{\\sum_{k=1}^{m}(v_k - \\bar{v})^2}},\n$$\n其中 $\\bar{u}$ 和 $\\bar{v}$ 分别表示 $\\mathbf{u}$ 和 $\\mathbf{v}$ 的均值。\n- 置换检验通过打破跨空间的刺激之间的映射来构建一个零分布。对于 RDM，这是通过在一个 RDM 中联合置换刺激索引（保持其对称性），并重新计算对齐度量来实现的。正向对齐的单边检验的经验 $p$ 值计算如下\n$$\np = \\frac{1 + \\sum_{b=1}^{K} \\mathbb{I}\\big(r_b \\ge r_{\\text{obs}}\\big)}{1 + K},\n$$\n其中 $r_{\\text{obs}}$ 是两个 RDM 之间观察到的斯皮尔曼相关性，$r_b$ 是在 $K$ 次随机置换下的相关性，$\\mathbb{I}$ 是指示函数。分子和分母中的加 1 确保即使没有零样本超过 $r_{\\text{obs}}$，也能得到一个有效的估计。\n- 用于在 $m$ 个假设上将错误发现率 (FDR) 控制在目标水平 $q$（表示为小数，而非百分比）的 Benjamini–Hochberg 程序操作如下：对 $p$ 值进行排序 $p_{(1)} \\le p_{(2)} \\le \\cdots \\le p_{(m)}$，找到最大索引 $i^\\star$ 使得 $p_{(i^\\star)} \\le \\frac{i^\\star}{m}q$，并宣布所有 $p \\le p_{(i^\\star)}$ 的假设为显著。如果不存在这样的索引，则没有假设被宣布为显著。\n\n请精确实现以下要求：\n1. 根据下文描述，从合成的刺激特征响应构建 CNN 层和神经 ROI 的 RDM。对于每个层-区域对，计算 RSA 对齐，即它们 RDM 的向量化上三角项之间的斯皮尔曼等级相关。\n2. 对于每个层-区域对，根据无对齐的零假设（通过对每对中的一个 RDM 的刺激索引进行随机置换来实现）执行一个包含 $K$ 次置换的置换检验。使用上面给出的公式计算正向对齐的单边经验 $p$ 值。\n3. 对每个测试用例中所有层-区域对，使用目标水平 $q$ 单独应用 Benjamini–Hochberg FDR 校正。\n4. 对于每个测试用例，输出一个等于经过 FDR 校正后显著的层-区域对数量的整数。\n\n合成数据生成协议：\n- 对每个测试用例使用独立的、固定的随机种子以确保确定性。\n- 对于每个区域，通过从标准正态分布中采样条目，为 $n$ 个刺激生成一个特征响应矩阵 $\\mathbf{X}^{(r)} \\in \\mathbb{R}^{n \\times d_r}$。\n- 对于每个层，根据下面每个测试用例指定的设计生成一个特征响应矩阵 $\\mathbf{Y}^{(l)} \\in \\mathbb{R}^{n \\times d_l}$，旨在产生对齐和未对齐场景的混合。\n\n表征非相似性计算：\n- 对于任何特征矩阵 $\\mathbf{Z} \\in \\mathbb{R}^{n \\times d}$，构建 RDM $\\mathbf{D} \\in \\mathbb{R}^{n \\times n}$，其中对于 $i \\neq j$，$\\mathbf{D}_{ij} = \\left\\|\\mathbf{z}_i - \\mathbf{z}_j\\right\\|_2$，且 $\\mathbf{D}_{ii} = 0$。\n\nRSA 对齐度量：\n- 对于两个 RDM $\\mathbf{D}^{(1)}$ 和 $\\mathbf{D}^{(2)}$，将严格上三角项向量化为 $\\mathbf{v}^{(1)}$ 和 $\\mathbf{v}^{(2)}$，计算 $\\mathbf{v}^{(1)}$ 和 $\\mathbf{v}^{(2)}$ 之间的斯皮尔曼等级相关，并将结果表示为 $r_{\\text{obs}}$。\n\n置换检验：\n- 对于每个置换 $b \\in \\{1,\\dots,K\\}$，采样一个 $\\{1,\\dots,n\\}$ 的随机置换 $\\pi_b$，并通过将 $\\pi_b$ 同时应用于 $\\mathbf{D}^{(2)}$ 的行和列来构建置换后的 RDM $\\tilde{\\mathbf{D}}^{(2)}$，即 $\\tilde{\\mathbf{D}}^{(2)}_{ij} = \\mathbf{D}^{(2)}_{\\pi_b(i),\\pi_b(j)}$。计算 $r_b$ 作为 $\\mathbf{D}^{(1)}$ 和 $\\tilde{\\mathbf{D}}^{(2)}$ 的上三角向量之间的斯皮尔曼相关。使用上面的经验 $p$ 值公式。\n\n多重比较校正：\n- 在每个测试用例中，汇集所有层-区域对的所有 $p$ 值（共 $m$ 个），并应用如上所述的 Benjamini–Hochberg 程序（在水平 $q$ 下），为每对产生一个布尔决策。\n\n测试套件和数据设计：\n精确实现以下三个测试用例。\n- 测试用例 1（理想路径）：$n=12$ 个刺激，$L=3$ 个 CNN 层，$R=2$ 个 ROI，$K=300$ 次置换，$q=0.1$（小数）。随机种子 $0$。数据设计：生成 $\\mathbf{X}^{(1)}$ 和 $\\mathbf{X}^{(2)}$，其中 $d_1=5$ 和 $d_2=5$。按如下方式生成 CNN 层特征：层 1 通过 $\\mathbf{Y}^{(1)} = \\mathbf{X}^{(1)} + \\boldsymbol{\\epsilon}$ 与 ROI 1 对齐，其中 $\\boldsymbol{\\epsilon}$ 是标准差为 $0.01$ 的独立同分布正态噪声；层 2 未对齐（具有 $d_2'=6$ 的独立标准正态特征）；层 3 通过 $\\mathbf{Y}^{(3)} = \\mathbf{X}^{(2)} + \\boldsymbol{\\epsilon}'$ 与 ROI 2 对齐，其中 $\\boldsymbol{\\epsilon}'$ 是标准差为 $0.01$ 的独立同分布正态噪声。在所有 $L \\times R = 6$ 对上计算 FDR。\n- 测试用例 2（边界条件）：$n=5$ 个刺激，$L=1$ 个 CNN 层，$R=1$ 个 ROI，$K=100$ 次置换，$q=0.05$（小数）。随机种子 $1$。数据设计：生成 $\\mathbf{X}^{(1)}$，其中 $d_1=4$；精确设置 $\\mathbf{Y}^{(1)} = \\mathbf{X}^{(1)}$。在 1 对上计算 FDR。\n- 测试用例 3（无对齐的边缘情况）：$n=10$ 个刺激，$L=2$ 个 CNN 层，$R=2$ 个 ROI，$K=200$ 次置换，$q=0.1$（小数）。随机种子 $2$。数据设计：生成 $\\mathbf{X}^{(1)}$ 和 $\\mathbf{X}^{(2)}$，其中 $d_1=6$ 和 $d_2=6$；将两个层都设置为具有 $d'_1=7$ 和 $d'_2=8$ 的独立标准正态特征（未对齐）。在所有 $L \\times R = 4$ 对上计算 FDR。\n\n最终输出格式：\n- 您的程序应产生单行输出，其中包含形如方括号内逗号分隔列表的结果（例如，$[r_1,r_2,r_3]$），其中 $r_t$ 是测试用例 $t \\in \\{1,2,3\\}$ 经过 FDR 校正后显著的层-区域对数量的整数。",
            "solution": "问题陈述是一项有效、定义明确且具有科学依据的计算神经科学数据分析练习。它要求实现一个标准的、尽管复杂的统计流程：表征相似性分析 (RSA)、基于置换的假设检验，以及使用 Benjamini-Hochberg 错误发现率 (FDR) 程序进行多重比较校正。所有组件都用数学和算法的精度进行了定义，并且测试用例的指定足够详细（包括随机种子），以确保一个唯一的、确定性的和可验证的结果。\n\n该过程将遵循以下科学和数学原则来实现。\n\n**步骤 1：问题验证**\n\n*   **提取已知条件**：\n    *   **核心方法**：表征相似性分析 (RSA)，用于比较卷积神经网络 (CNN) 层和大脑感兴趣区域 (ROI)。\n    *   **表征非相似性矩阵 (RDM)**：对于 $n$ 个刺激，一个 $n \\times n$ 的对称矩阵 $\\mathbf{D}$，其中 $\\mathbf{D}_{ii}=0$。对于特征向量 $\\mathbf{x}_i, \\mathbf{x}_j \\in \\mathbb{R}^d$，非相似性是欧几里得距离 $\\mathbf{D}_{ij} = \\left\\|\\mathbf{x}_i - \\mathbf{x}_j\\right\\|_2$。\n    *   **对齐度量**：两个 RDM 的向量化上三角项之间的斯皮尔曼等级相关 $\\rho$。\n    *   **置换检验**：通过为一个 RDM 置换刺激标签来创建零分布。对于 $K$ 次置换，正向对齐的单边经验 $p$ 值为 $p = \\frac{1 + \\sum_{b=1}^{K} \\mathbb{I}(r_b \\ge r_{\\text{obs}})}{1 + K}$，其中 $r_{\\text{obs}}$ 是观察到的相关性，$r_b$ 是来自零分布的相关性，$\\mathbb{I}$ 是指示函数。置换 $\\pi_b$ 应用于一个 RDM $\\mathbf{D}^{(2)}$，形式为 $\\tilde{\\mathbf{D}}^{(2)}_{ij} = \\mathbf{D}^{(2)}_{\\pi_b(i),\\pi_b(j)}$。\n    *   **多重比较校正**：在目标 FDR 水平 $q$ 下的 Benjamini–Hochberg 程序。对于 $m$ 个排序的 $p$ 值 $p_{(1)} \\le \\cdots \\le p_{(m)}$，找到最大索引 $i^\\star$ 使得 $p_{(i^\\star)} \\le \\frac{i^\\star}{m}q$。$p \\le p_{(i^\\star)}$ 的假设被认为是显著的。\n    *   **合成数据**：使用固定的随机种子生成。ROI 特征 $\\mathbf{X}^{(r)} \\in \\mathbb{R}^{n \\times d_r}$ 来自标准正态分布。CNN 特征 $\\mathbf{Y}^{(l)} \\in \\mathbb{R}^{n \\times d_l}$ 按每个案例指定生成。\n    *   **测试用例 1**：$n=12$，$L=3$ 层，$R=2$ 个 ROI，$K=300$ 次置换，$q=0.1$，种子=$0$。ROI 特征 $\\mathbf{X}^{(1)}, \\mathbf{X}^{(2)} \\in \\mathbb{R}^{12 \\times 5}$。CNN 特征：$\\mathbf{Y}^{(1)} = \\mathbf{X}^{(1)} + \\boldsymbol{\\epsilon}$ (噪声标准差 $0.01$)，$\\mathbf{Y}^{(2)} \\in \\mathbb{R}^{12 \\times 6}$ (独立标准正态)，$\\mathbf{Y}^{(3)} = \\mathbf{X}^{(2)} + \\boldsymbol{\\epsilon}'$ (噪声标准差 $0.01$)。\n    *   **测试用例 2**：$n=5$，$L=1$ 层，$R=1$ 个 ROI，$K=100$ 次置换，$q=0.05$，种子=$1$。ROI 特征 $\\mathbf{X}^{(1)} \\in \\mathbb{R}^{5 \\times 4}$。CNN 特征：$\\mathbf{Y}^{(1)} = \\mathbf{X}^{(1)}$。\n    *   **测试用例 3**：$n=10$，$L=2$ 层，$R=2$ 个 ROI，$K=200$ 次置换，$q=0.1$，种子=$2$。ROI 特征 $\\mathbf{X}^{(1)}, \\mathbf{X}^{(2)} \\in \\mathbb{R}^{10 \\times 6}$。CNN 特征：$\\mathbf{Y}^{(1)} \\in \\mathbb{R}^{10 \\times 7}$，$\\mathbf{Y}^{(2)} \\in \\mathbb{R}^{10 \\times 8}$ (均为独立标准正态)。\n    *   **输出**：对于每个测试用例，经过 FDR 校正后显著的层-区域对的整数计数。\n\n*   **验证结论**：该问题是**有效的**。它在计算神经科学中已建立的统计方法上具有科学依据，定义明确，有清晰且确定性的解决方案路径，并且其定义客观、无歧义。它没有违反任何无效性标准。\n\n**基于原则的解决方案设计**\n\n该任务需要一个由多个计算和统计模块组成的流程，我们将逐步构建。\n\n**1. RDM 构建**\n对于给定的 $n$ 个特征向量（刺激响应）集合 $\\{\\mathbf{z}_1, \\dots, \\mathbf{z}_n\\}$，其中每个 $\\mathbf{z}_i \\in \\mathbb{R}^d$，表征非相似性矩阵 (RDM)，记为 $\\mathbf{D}$，是一个 $n \\times n$ 的矩阵。每个条目 $\\mathbf{D}_{ij}$ 量化了刺激 $i$ 和刺激 $j$ 的表征之间的非相似性。按照规定，我们使用欧几里得距离：\n$$\n\\mathbf{D}_{ij} = \\left\\| \\mathbf{z}_i - \\mathbf{z}_j \\right\\|_2\n$$\n对角线元素 $\\mathbf{D}_{ii}$ 必然为 $0$，因为一个向量到其自身的距离为零。该矩阵是对称的，因为 $\\mathbf{D}_{ij} = \\mathbf{D}_{ji}$。\n\n**2. 使用斯皮尔曼相关进行 RSA 对齐**\n为了比较两种表征几何（一种来自 CNN 层，一种来自神经 ROI），我们计算它们各自的 RDM，$\\mathbf{D}^{(\\text{CNN})}$ 和 $\\mathbf{D}^{(\\text{ROI})}$ 的相似性。由于 RDM 是对称且对角线为零的，所有信息都包含在上（或下）三角部分。我们将每个 RDM 的严格上三角元素提取成向量，称之为 $\\mathbf{v}^{(\\text{CNN})}$ 和 $\\mathbf{v}^{(\\text{ROI})}$。此类元素的数量为 $m_{\\text{RDM}} = n(n-1)/2$。\n\n然后，对齐由这两个向量之间的斯皮尔曼等级相关来量化。斯皮尔曼的 $\\rho$ 等价于在等级变换后的变量上计算的皮尔逊相关系数。这个选择是基于原则的，因为它对两个空间非相似性之间非线性但单调的关系具有鲁棒性，这在神经数据分析中是一种常见情况。\n\n**3. 通过置换进行假设检验**\n为了评估观察到的相关性 $r_{\\text{obs}}$ 是否具有统计显著性，我们必须将其与一个零分布进行比较。零假设 $H_0$ 是 CNN 层和大脑 ROI 中的刺激表征之间没有系统性的关系。置换检验是一种非参数方法，用于在此零假设下生成数据。\n\n过程如下：我们取其中一个 RDM，比如 $\\mathbf{D}^{(\\text{CNN})}$，并根据相同的刺激标签置换随机地置换其行和列。如果 $\\pi$ 是索引 $\\{0, 1, \\dots, n-1\\}$ 的一个置换，则置换后的 RDM $\\tilde{\\mathbf{D}}^{(\\text{CNN})}$ 的条目为 $\\tilde{\\mathbf{D}}_{ij}^{(\\text{CNN})} = \\mathbf{D}_{\\pi(i), \\pi(j)}^{(\\text{CNN})}$。此操作打破了两个 RDM 中刺激之间的对应关系，同时保留了被置换 RDM 的内部几何结构。\n\n我们重复此过程 $K$ 次，每次生成一个新的随机置换 $\\pi_b$，并计算 $\\mathbf{D}^{(\\text{ROI})}$ 的向量化上三角与置换后的 $\\tilde{\\mathbf{D}}^{(\\text{CNN})}$ 之间的零相关系数 $r_b$。这产生一个零分布 $\\{r_1, r_2, \\dots, r_K\\}$。\n\n检验正相关的单边经验 $p$ 值是大于或等于观察相关性的零相关性的比例。所提供的公式，\n$$\np = \\frac{1 + \\sum_{b=1}^{K} \\mathbb{I}(r_b \\ge r_{\\text{obs}})}{1 + K}\n$$\n是计算这个值的标准方法。在分子和分母上加 1 作为伪计数，确保如果 $r_{\\text{obs}}$ 大于所有 $r_b$，则 $p$ 值为 $1/(K+1)$ 而不是 $0$，从而提供一个更保守和稳定的估计。\n\n**4. 使用 FDR 进行多重比较校正**\n当同时进行多个假设检验时（在我们的案例中，每个 CNN 层-ROI 对一个），做出至少一个错误发现（I 型错误）的概率会膨胀。Benjamini-Hochberg (BH) 程序控制错误发现率 (FDR)，即所有被拒绝的零假设中假阳性的预期比例。\n\n对于每个测试用例，我们有 $m = L \\times R$ 个比较，产生 $m$ 个 p 值 $\\{p_1, \\dots, p_m\\}$。BH 程序是：\n1.  对 $p$ 值进行排序：$p_{(1)} \\le p_{(2)} \\le \\dots \\le p_{(m)}$。让与这些排序后的 $p$ 值对应的原始假设为 $H_{(1)}, \\dots, H_{(m)}$。\n2.  对于给定的 FDR 水平 $q$，找到最大的整数 $i^\\star$，使得第 $i^\\star$ 个最小的 $p$ 值满足：\n    $$\n    p_{(i^\\star)} \\le \\frac{i^\\star}{m} q\n    $$\n3.  如果存在这样的 $i^\\star$，我们拒绝所有 $p_j \\le p_{(i^\\star)}$ 的检验的零假设。这意味着所有假设 $H_{(1)}, \\dots, H_{(i^\\star)}$ 都被宣布为显著。\n4.  如果不存在这样的 $i^\\star$，我们不拒绝任何零假设。\n\n每个测试用例的最终输出是满足此标准的对的总数。实现将仔细处理 BH 公式的 1-based 索引与编程数组中 0-based 索引之间的转换。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.stats import spearmanr\nfrom scipy.spatial.distance import pdist, squareform\n\ndef solve():\n    \"\"\"\n    Main solver function that orchestrates the execution of all test cases.\n    \"\"\"\n    test_cases = [\n        # Test case 1 (happy path)\n        {\n            \"n\": 12, \"L\": 3, \"R\": 2, \"K\": 300, \"q\": 0.1, \"seed\": 0,\n            \"data_dims\": {\n                \"rois\": [5, 5],\n                \"layers\": [None, 6, None] # Dim depends on aligned ROI\n            },\n            \"alignments\": {\n                0: 0, # Layer 0 aligns with ROI 0\n                2: 1  # Layer 2 aligns with ROI 1\n            },\n            \"noise_std\": 0.01\n        },\n        # Test case 2 (boundary condition)\n        {\n            \"n\": 5, \"L\": 1, \"R\": 1, \"K\": 100, \"q\": 0.05, \"seed\": 1,\n            \"data_dims\": {\n                \"rois\": [4],\n                \"layers\": [None]\n            },\n            \"alignments\": {\n                0: 0 # Layer 0 aligns with ROI 0\n            },\n            \"noise_std\": 0.0 # Perfect alignment\n        },\n        # Test case 3 (edge case with no alignment)\n        {\n            \"n\": 10, \"L\": 2, \"R\": 2, \"K\": 200, \"q\": 0.1, \"seed\": 2,\n            \"data_dims\": {\n                \"rois\": [6, 6],\n                \"layers\": [7, 8]\n            },\n            \"alignments\": {}, # No alignments\n            \"noise_std\": 0.0\n        },\n    ]\n\n    results = []\n    for case in test_cases:\n        result = run_test_case(**case)\n        results.append(result)\n\n    print(f\"[{','.join(map(str, results))}]\")\n\ndef run_test_case(n, L, R, K, q, seed, data_dims, alignments, noise_std):\n    \"\"\"\n    Executes a single test case for RSA significance testing.\n    \"\"\"\n    rng = np.random.default_rng(seed)\n\n    # 1. Generate synthetic data\n    roi_features = [rng.standard_normal(size=(n, d)) for d in data_dims[\"rois\"]]\n    \n    cnn_features = []\n    for l in range(L):\n        aligned_roi_idx = alignments.get(l)\n        if aligned_roi_idx is not None:\n            # Aligned layer\n            base_features = roi_features[aligned_roi_idx]\n            noise = rng.normal(scale=noise_std, size=base_features.shape)\n            cnn_features.append(base_features + noise)\n        else:\n            # Unaligned layer\n            d_l = data_dims[\"layers\"][l]\n            cnn_features.append(rng.standard_normal(size=(n, d_l)))\n\n    # 2. Compute RDMs\n    roi_rdms = [compute_rdm(features) for features in roi_features]\n    cnn_rdms = [compute_rdm(features) for features in cnn_features]\n\n    # Get upper triangle indices, which are constant for a given n\n    triu_indices = np.triu_indices(n, k=1)\n\n    p_values = []\n    # 3. Perform permutation test for each layer-region pair\n    for l in range(L):\n        rdm_cnn_vec = cnn_rdms[l][triu_indices]\n        for r in range(R):\n            rdm_roi_vec = roi_rdms[r][triu_indices]\n\n            # Observed correlation\n            r_obs, _ = spearmanr(rdm_cnn_vec, rdm_roi_vec)\n            \n            # Null distribution\n            null_correlations = np.zeros(K)\n            for b in range(K):\n                perm = rng.permutation(n)\n                # Permute one RDM (e.g., the CNN rdm)\n                rdm_cnn_permuted = cnn_rdms[l][perm, :][:, perm]\n                rdm_cnn_permuted_vec = rdm_cnn_permuted[triu_indices]\n                r_b, _ = spearmanr(rdm_cnn_permuted_vec, rdm_roi_vec)\n                null_correlations[b] = r_b\n            \n            # Empirical p-value\n            p_val = (1.0 + np.sum(null_correlations >= r_obs)) / (1.0 + K)\n            p_values.append(p_val)\n\n    # 4. Apply Benjamini-Hochberg FDR correction\n    p_values = np.array(p_values)\n    m = len(p_values)\n    \n    if m == 0:\n        return 0\n\n    # Sort p-values while keeping original indices\n    sorted_indices = np.argsort(p_values)\n    sorted_p_values = p_values[sorted_indices]\n    \n    # Find the largest i* such that p_(i*) = (i*/m)*q\n    i = np.arange(1, m + 1)\n    thresholds = (i / m) * q\n    \n    significant_mask = sorted_p_values = thresholds\n    \n    if not np.any(significant_mask):\n        return 0\n    else:\n        # Find the rank of the last p-value that was below its threshold\n        max_significant_index_in_sorted_array = np.where(significant_mask)[0].max()\n        # The p-value at this index is our significance threshold\n        p_threshold = sorted_p_values[max_significant_index_in_sorted_array]\n        \n        # Count how many of the original p-values are = this threshold\n        num_significant = np.sum(p_values = p_threshold)\n        return int(num_significant)\n\ndef compute_rdm(feature_matrix):\n    \"\"\"\n    Computes the Representational Dissimilarity Matrix (RDM)\n    from a feature matrix using Euclidean distance.\n    \"\"\"\n    # pdist computes the condensed distance matrix (upper triangle)\n    distances = pdist(feature_matrix, 'euclidean')\n    # squareform converts it to a full, symmetric matrix with zero diagonal\n    rdm = squareform(distances)\n    return rdm\n\nif __name__ == \"__main__\":\n    solve()\n\n```"
        }
    ]
}