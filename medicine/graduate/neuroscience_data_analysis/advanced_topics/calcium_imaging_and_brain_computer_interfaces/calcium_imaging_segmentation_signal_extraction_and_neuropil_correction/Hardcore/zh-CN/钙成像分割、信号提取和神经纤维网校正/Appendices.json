{
    "hands_on_practices": [
        {
            "introduction": "在分析钙成像数据时，首要任务是从像素场中识别出单个神经元。我们可以将像素建模为图中的节点，其中节点间的连接强度（边权重）基于其荧光信号的时间相关性。这样，神经元就表现为此图中紧密连接的社群。本练习将指导您使用谱聚类实现一个完整的分割流程，通过从头开始构建该算法，您将对如何将神经元社群的概念模型转化为有效的感兴趣区域（ROI）检测算法获得深入的实践理解。",
            "id": "4143860",
            "problem": "您将获得一个小型网格上排列的像素的合成钙成像时间序列数据。请将每个像素视为图中的一个节点，其边权重由像素荧光轨迹之间的统计依赖性定义。您必须从第一性原理出发，构建一个分割目标函数，该目标函数在奖励感兴趣区域（ROIs）内时间序列同质的像素分组的同时，惩罚跨越不同 ROI 的连接。然后，设计一个与此目标一致的算法流程，以计算分割、提取 ROI 信号并执行神经毡校正。计算并报告分割质量和神经毡校正效果的定量度量。\n\n基本假设和定义：\n- 每个像素 $i$ 都有一个在离散时间 $t \\in \\{1,\\dots,T\\}$ 上的荧光时间序列 $F_i(t)$。\n- 两个时间序列 $F_i(t)$ 和 $F_j(t)$ 之间的 Pearson 相关性是归一化协方差，\n$$\n\\rho_{ij} = \\frac{\\sum_{t=1}^T (F_i(t)-\\bar{F}_i) (F_j(t)-\\bar{F}_j)}{\\sqrt{\\sum_{t=1}^T (F_i(t)-\\bar{F}_i)^2}\\sqrt{\\sum_{t=1}^T (F_j(t)-\\bar{F}_j)^2}},\n$$\n其中 $\\bar{F}_i$ 和 $\\bar{F}_j$ 表示在时间 $t$ 上的样本均值。\n- 构建一个加权无向图，其邻接矩阵为 $W \\in \\mathbb{R}^{N \\times N}$，其中 $N$ 是像素数量，$W_{ij}$ 表示像素 $i$ 和 $j$ 之间的亲和度；使用从 $\\rho_{ij}$ 导出的相关性权重 $W_{ij}$，该权重非负且对称，并设置 $W_{ii} = 0$。\n- 对于任何节点集 $A \\subseteq V$，定义度 $d_i = \\sum_{j=1}^N W_{ij}$，体积 $\\mathrm{vol}(A) = \\sum_{i \\in A} d_i$，关联 $\\mathrm{assoc}(A,B) = \\sum_{i \\in A}\\sum_{j \\in B} W_{ij}$，以及切割 $\\mathrm{cut}(A,B) = \\sum_{i \\in A}\\sum_{j \\in B} W_{ij}$。\n\n任务要求：\n1. 从上述定义出发，推导一个显式的切割目标函数，用于平衡将节点集划分为 $K$ 个不相交 ROI 的划分 $\\mathcal{P} = \\{C_1,\\dots,C_K\\}$ 的 ROI 内部同质性和 ROI 之间分离度。该目标函数必须仅用 $W$、$d_i$、$\\mathrm{vol}(\\cdot)$、$\\mathrm{assoc}(\\cdot,\\cdot)$ 和 $\\mathrm{cut}(\\cdot,\\cdot)$ 表示，并且必须包含一个可调参数 $\\lambda \\in (0,1)$，用于权衡这两个期望特性。\n2. 使用一个基于原理的松弛方法，将推导出的目标函数与图的谱特性联系起来，实现一个将图划分为 $K$ 个 ROI 的分割算法。\n3. 对于每个 ROI，通过对属于 $C_k$ 的像素 $i$ 的 $F_i(t)$ 进行平均，提取平均信号 $F_{\\mathrm{ROI}_k}(t)$。将每个 ROI 的局部神经毡环定义为与 $C_k$ 中任何像素相邻（网格上的切比雪夫距离为 $1$）的所有像素的并集，但不包括 $C_k$ 本身。计算此环上的神经毡平均信号 $F_{\\mathrm{NP}_k}(t)$。使用固定系数 $\\alpha$ 进行神经毡校正，\n$$\nF_{\\mathrm{corr},k}(t) = F_{\\mathrm{ROI}_k}(t) - \\alpha \\left(F_{\\mathrm{NP}_k}(t) - \\mathrm{median}\\{F_{\\mathrm{NP}_k}(t)\\}_{t=1}^T \\right).\n$$\n4. 对于每个测试用例，计算：\n   - 您最终分割所得到的切割目标函数值，表示为 $J_\\lambda(\\mathcal{P})$，为一个实数。\n   - 平均相关性改善值，定义为校正前 $F_{\\mathrm{ROI}_k}(t)$ 与潜在真实信号 $s_k(t)$ 的 Pearson 相关性，与校正后 $F_{\\mathrm{corr},k}(t)$ 与 $s_k(t)$ 的 Pearson 相关性之差，在所有 ROI 上的平均值。将此改善值表示为十进制数。\n\n算法约束：\n- 使用非负的相关性派生权重构建 $W$，将任何负或未定义的相关性设置为 $0$。\n- 使用与最小化适当的归一化切割或等效地最大化归一化关联一致的谱松弛方法，以获得近似的 $K$-路划分。松弛后，通过对所选特征向量矩阵的行进行聚类（例如，使用 $K$-means）来进行离散化。\n- 计算相关性时，如果任何方差项为零，则将相关性视为 $0$。\n\n测试套件：\n您必须在以下参数集上实现并运行您的程序。在所有情况下，设置 $\\alpha = 0.7$，$\\lambda = 0.5$，并对任何随机组件使用指定的随机种子。\n\n- 测试用例 1（理想路径）：\n  - 网格大小：$4 \\times 4$（$N=16$），$T=60$，$K=2$，随机种子 $42$。\n  - 真实 ROI：$C_1$ 是前两行（$y \\in \\{1,2\\}$），$C_2$ 是后两行（$y \\in \\{3,4\\}$）。\n  - 潜在信号：\n    $$\n    s_1(t) = \\sin\\!\\left(2\\pi \\cdot 3 \\frac{t}{T}\\right) + 0.5 \\cdot \\mathbf{1}_{t \\in \\{10,11,12\\}}, \\quad s_2(t) = \\sin\\!\\left(2\\pi \\cdot 5 \\frac{t}{T}\\right),\n    $$\n    $$\n    n(t) = 0.3 \\cdot \\sin\\!\\left(2\\pi \\cdot 1 \\frac{t}{T}\\right).\n    $$\n  - 每个像素 $i$（其中 $c(i) \\in \\{1,2\\}$）的观测模型：\n    $$\n    F_i(t) = 1.0 \\cdot s_{c(i)}(t) + 0.5 \\cdot n(t) + \\epsilon_i(t),\n    $$\n    其中 $\\epsilon_i(t)$ 是独立同分布的高斯噪声，方差为 $\\sigma^2 = 0.2^2$。\n\n- 测试用例 2（边界条件：弱结构）：\n  - 网格大小：$4 \\times 4$（$N=16$），$T=60$，$K=2$，随机种子 $7$。\n  - 真实 ROI：与测试用例 1 相同的空间划分。\n  - 潜在信号：\n    $$\n    s_1(t) = 0, \\quad s_2(t) = 0, \\quad n(t) = \\sin\\!\\left(2\\pi \\cdot 2 \\frac{t}{T}\\right).\n    $$\n  - 每个像素 $i$ 的观测模型：\n    $$\n    F_i(t) = 0.0 \\cdot s_{c(i)}(t) + 1.0 \\cdot n(t) + \\epsilon_i(t), \\quad \\sigma^2 = 0.5^2.\n    $$\n\n- 测试用例 3（边缘案例：较大背景中的小 ROI）：\n  - 网格大小：$5 \\times 5$（$N=25$），$T=60$，$K=2$，随机种子 $123$。\n  - 真实 $C_1$ 是位于坐标 $\\{(3,3),(3,2),(3,4),(2,3),(4,3)\\}$ 的 $5$ 个像素（使用 1-based 索引，$(x,y)$ 表示列和行），$C_2$ 是所有剩余像素。\n  - 潜在信号：\n    $$\n    s_1(t) = 1 \\cdot \\mathbf{1}_{t \\in \\{20,21,22,23,24,25\\}} + 0.2 \\cdot \\sin\\!\\left(2\\pi \\cdot 4 \\frac{t}{T}\\right), \\quad s_2(t) \\approx 0,\n    $$\n    $$\n    n(t) = 0.2 \\cdot \\sin\\!\\left(2\\pi \\cdot 1 \\frac{t}{T}\\right).\n    $$\n  - 每个像素 $i$ 的观测模型：\n    $$\n    F_i(t) = 1.0 \\cdot s_{c(i)}(t) + 0.5 \\cdot n(t) + \\epsilon_i(t), \\quad \\sigma^2 = 0.3^2.\n    $$\n\n程序输出规范：\n- 您的程序必须为每个测试用例计算最终分割的推导目标值 $J_\\lambda(\\mathcal{P})$ 和神经毡校正后的平均相关性改善值。将所有测试用例的结果按顺序聚合到单行中，格式如下：\n$$\n[\\text{J}_1,\\Delta_1,\\text{J}_2,\\Delta_2,\\text{J}_3,\\Delta_3],\n$$\n其中每个条目都是一个十进制数。输出必须打印为仅含一个括号括起来的、逗号分隔列表的单行。不涉及角度。没有物理单位需要报告。将相关性改善值表示为十进制数。",
            "solution": "用户提供了一个关于分析钙成像数据的计算神经科学问题。我将首先验证问题陈述的正确性、完整性和科学依据。验证后，我将着手推导所需的目标函数，概述算法流程，然后构建最终的实现。\n\n### 第 1 步：提取给定信息\n- **数据**：每个像素 $i \\in \\{1, \\dots, N\\}$ 在时间 $t \\in \\{1, \\dots, T\\}$ 的荧光时间序列 $F_i(t)$。\n- **图构建**：一个加权无向图 $G=(V, E, W)$，其中 $V$ 是 $N$ 个像素的集合。邻接矩阵 $W \\in \\mathbb{R}^{N \\times N}$ 的权重 $W_{ij}$ 由 $F_i(t)$ 和 $F_j(t)$ 之间的 Pearson 相关性 $\\rho_{ij}$ 导出。$W_{ij}$ 必须为非负对称矩阵，且 $W_{ii}=0$。\n- **图论定义**：\n  - Pearson 相关性: $\\rho_{ij} = \\frac{\\mathrm{cov}(F_i, F_j)}{\\sigma_{F_i}\\sigma_{F_j}}$。\n  - 度：$d_i = \\sum_{j=1}^N W_{ij}$。\n  - 集合 $A \\subseteq V$ 的体积：$\\mathrm{vol}(A) = \\sum_{i \\in A} d_i$。\n  - 集合 $A, B \\subseteq V$ 之间的关联：$\\mathrm{assoc}(A,B) = \\sum_{i \\in A}\\sum_{j \\in B} W_{ij}$。\n  - 集合 $A, B \\subseteq V$ 之间的切割：$\\mathrm{cut}(A,B) = \\sum_{i \\in A}\\sum_{j \\in B} W_{ij}$。\n- **任务 1 (目标推导)**：为划分 $\\mathcal{P} = \\{C_1,\\dots,C_K\\}$ 推导一个切割目标 $J_\\lambda(\\mathcal{P})$，该目标使用参数 $\\lambda \\in (0,1)$ 来平衡 ROI 内部的同质性和 ROI 之间的分离度。表达式必须仅使用 $W, d_i, \\mathrm{vol}(\\cdot), \\mathrm{assoc}(\\cdot,\\cdot), \\mathrm{cut}(\\cdot,\\cdot)$。\n- **任务 2 (分割)**：基于推导目标的谱松弛，实现一个谱聚类算法，使用 K-means 对特征向量矩阵进行离散化。\n- **任务 3 (信号处理)**：对每个找到的 ROI $C_k$，提取平均信号 $F_{\\mathrm{ROI}_k}(t)$，根据切比雪夫距离为 1 定义其局部神经毡环，计算神经毡信号 $F_{\\mathrm{NP}_k}(t)$，并执行校正：$F_{\\mathrm{corr},k}(t) = F_{\\mathrm{ROI}_k}(t) - \\alpha (F_{\\mathrm{NP}_k}(t) - \\mathrm{median}\\{F_{\\mathrm{NP}_k}(t)\\})$。\n- **任务 4 (度量)**：对于每个测试用例，计算目标值 $J_\\lambda(\\mathcal{P})$ 和神经毡校正后的平均相关性改善值。\n- **算法约束**：\n  - $W_{ij} = \\max(0, \\rho_{ij})$ 对于 $i \\neq j$。如果方差为零，则相关性为 0。\n  - 使用谱聚类进行 K-路划分。\n- **参数**：$\\alpha = 0.7$, $\\lambda = 0.5$。\n- **测试用例**：指定了三个不同的测试用例，包括网格大小 ($4 \\times 4$, $4 \\times 4$, $5 \\times 5$)、时间点数 ($T=60$)、ROI 数量 ($K=2$)、用于随机性的随机种子、基准真相 ROI 定义、潜在信号模型和观测模型。\n\n### 第 2 步：使用提取的给定信息进行验证\n- **科学依据**：该问题在钙成像分析的标准实践中具有良好的基础。像素间相关性图、通过谱聚类进行 ROI 分割、通过平均提取信号以及线性神经毡校正等概念都是该领域的既定方法。所提供的数据生成模型是一种常见且适当的线性混合模型。\n- **适定性**：该问题是适定的。它提供了所有必要的数据、参数（如 $\\alpha, \\lambda, K$）和初始条件（通过数据生成模型和随机种子），以确保可以计算出唯一的、确定性的解。任务的规定足够详细。\n- **客观性**：问题陈述是形式化、精确的，没有主观或模糊的语言。所有术语都有数学定义。\n\n### 第 3 步：结论与行动\n该问题是**有效的**。它在科学上是合理的、适定的、客观的和完整的。我现在将着手解决。\n\n### 解决方案\n\n#### 1. 分割目标的推导\n目标是找到一个像素划分 $\\mathcal{P} = \\{C_1,\\dots,C_K\\}$，以最大化“ROI 内部同质性”和“ROI 之间分离度”。\n\n- **ROI 内部同质性**：簇 $C_k$ 内部的高度同质性对应于其组成像素之间的高平均连接性。内部边的总权重是簇内关联 $\\mathrm{assoc}(C_k, C_k)$。为了创建一个尺度不变的度量，防止偏爱单个大簇，通常用簇的体积 $\\mathrm{vol}(C_k)$ 对其进行归一化。对所有簇求和得到总的归一化簇内关联，这是一个待最大化的划分同质性度量：\n  $$ \\mathcal{H}(\\mathcal{P}) = \\sum_{k=1}^K \\frac{\\mathrm{assoc}(C_k, C_k)}{\\mathrm{vol}(C_k)} $$\n\n- **ROI 之间分离度**：ROI 之间良好的分离意味着它们之间的连接很弱。簇 $C_k$ 与图的其余部分 $V \\setminus C_k$ 之间的连接由切割 $\\mathrm{cut}(C_k, V \\setminus C_k)$ 来量化。通过除以 $\\mathrm{vol}(C_k)$ 进行归一化，得到标准的归一化切割（NCut）准则，为获得良好的分离度，应最小化该准则：\n  $$ \\mathcal{S}(\\mathcal{P}) = \\sum_{k=1}^K \\frac{\\mathrm{cut}(C_k, V \\setminus C_k)}{\\mathrm{vol}(C_k)} $$\n\n- **关系与组合目标**：簇的体积 $\\mathrm{vol}(C_k)$ 是其节点度的总和，代表连接到 $C_k$ 中节点的所有边的总权重。这可以分解为内部和外部连接：$\\mathrm{vol}(C_k) = \\mathrm{assoc}(C_k, C_k) + \\mathrm{cut}(C_k, V \\setminus C_k)$。\n两边同除以 $\\mathrm{vol}(C_k)$（假设 $\\mathrm{vol}(C_k)  0$），我们得到：\n  $$ 1 = \\frac{\\mathrm{assoc}(C_k, C_k)}{\\mathrm{vol}(C_k)} + \\frac{\\mathrm{cut}(C_k, V \\setminus C_k)}{\\mathrm{vol}(C_k)} $$\n对所有簇求和，我们发现 $\\mathcal{H}(\\mathcal{P}) + \\mathcal{S}(\\mathcal{P}) = \\sum_{k=1}^K 1 = K$。这表明最大化归一化关联与最小化归一化切割是完全等价的。\n\n问题要求一个目标函数 $J_\\lambda(\\mathcal{P})$，它使用参数 $\\lambda \\in (0,1)$ 来组合这两个准则。一个能够体现奖励同质性并惩罚不良分离（即奖励良好分离）意图的合适公式是加权和。我们将待最大化的目标定义为：\n$$ J_\\lambda(\\mathcal{P}) = \\lambda \\mathcal{H}(\\mathcal{P}) - (1-\\lambda) \\mathcal{S}(\\mathcal{P}) $$\n代入 $\\mathcal{S}(\\mathcal{P}) = K - \\mathcal{H}(\\mathcal{P})$，我们得到：\n$$ J_\\lambda(\\mathcal{P}) = \\lambda \\mathcal{H}(\\mathcal{P}) - (1-\\lambda)(K - \\mathcal{H}(\\mathcal{P})) = \\lambda\\mathcal{H}(\\mathcal{P}) - (1-\\lambda)K + (1-\\lambda)\\mathcal{H}(\\mathcal{P}) = \\mathcal{H}(\\mathcal{P}) - (1-\\lambda)K $$\n$$ J_\\lambda(\\mathcal{P}) = \\left(\\sum_{k=1}^K \\frac{\\mathrm{assoc}(C_k, C_k)}{\\mathrm{vol}(C_k)}\\right) - (1-\\lambda)K $$\n这个目标函数 $J_\\lambda(\\mathcal{P})$ 满足所有要求。它用允许的项表示，包含参数 $\\lambda$，并平衡了同质性和分离度。值得注意的是，无论 $\\lambda \\in (0,1)$ 的值如何，相对于划分 $\\mathcal{P}$ 优化此目标等同于最大化归一化关联 $\\mathcal{H}(\\mathcal{P})$。参数 $\\lambda$ 仅影响目标函数的最终值，而不影响最优划分本身。对于指定的 $\\lambda=0.5$，目标是 $J_{0.5}(\\mathcal{P}) = \\mathcal{H}(\\mathcal{P}) - 0.5K$。\n\n#### 2. 算法流程：谱聚类\n最大化 $\\mathcal{H}(\\mathcal{P})$ 的目标是一个 NP-难的离散优化问题。标准方法是使用谱松弛。这涉及图拉普拉斯算子的特征向量。最大化 $\\mathcal{H}(\\mathcal{P})$ 等价于找到随机游走归一化拉普拉斯算子 $L_{rw} = D^{-1}W$ 的顶层特征向量。\n\n算法如下：\n1.  **构建邻接矩阵 $W$**：给定 $N \\times T$ 的荧光矩阵 $\\mathbf{F}$，计算 $N \\times N$ 的 Pearson 相关性矩阵 $\\rho$。通过设置 $W_{ij} = \\max(0, \\rho_{ij})$（$i \\neq j$）和 $W_{ii} = 0$ 来构建 $W$。\n2.  **计算归一化拉普拉斯算子**：计算度矩阵 $D$，它是一个对角矩阵，其中 $D_{ii} = d_i = \\sum_{j} W_{ij}$。计算随机游走归一化拉普拉斯算子 $L_{rw} = D^{-1}W$。如果某个像素 $i$ 的 $d_i=0$，则 $D^{-1}$ 的相应行取为零。\n3.  **特征分解**：计算 $L_{rw}$ 的特征值和特征向量。选择与 $K$ 个最大特征值对应的 $K$ 个特征向量。\n4.  **形成嵌入**：构建一个矩阵 $U \\in \\mathbb{R}^{N \\times K}$，其列是所选的 $K$ 个特征向量。$U$ 的每一行现在都是一个特征向量，表示一个在 $K$ 维空间中的像素。\n5.  **使用 K-means 离散化**：对 $U$ 的 $N$ 行应用 K-means 算法，将它们划分为 $K$ 个簇。指定的随机种子确保结果的确定性。每个像素的簇分配构成了最终的划分 $\\mathcal{P}$。\n\n#### 3. 信号提取与神经毡校正\n1.  **提取 ROI 信号**：对于每个簇 $C_k \\in \\mathcal{P}$，计算平均荧光轨迹：$F_{\\mathrm{ROI}_k}(t) = \\frac{1}{|C_k|} \\sum_{i \\in C_k} F_i(t)$。\n2.  **识别神经毡环**：对于每个 ROI $C_k$，其神经毡环 $NP_k$ 是所有不属于 $C_k$ 但与 $C_k$ 中至少一个像素的切比雪夫距离为 1 的像素 $j$ 的集合。\n3.  **提取神经毡信号**：计算神经毡环上的平均荧光轨迹：$F_{\\mathrm{NP}_k}(t) = \\frac{1}{|NP_k|} \\sum_{j \\in NP_k} F_j(t)$。如果 $NP_k$ 为空，则 $F_{\\mathrm{NP}_k}(t) = 0$。\n4.  **执行校正**：使用给定公式和 $\\alpha=0.7$ 计算校正后的 ROI 信号：\n    $$ F_{\\mathrm{corr},k}(t) = F_{\\mathrm{ROI}_k}(t) - \\alpha \\left(F_{\\mathrm{NP}_k}(t) - \\mathrm{median}\\{F_{\\mathrm{NP}_k}(t)\\}_{t=1}^T \\right) $$\n\n#### 4. 定量评估\n1.  **目标值 $J_\\lambda(\\mathcal{P})$**：使用最终划分 $\\mathcal{P}$ 和邻接矩阵 $W$，计算 $J_{0.5}(\\mathcal{P}) = \\left(\\sum_{k=1}^K \\frac{\\mathrm{assoc}(C_k, C_k)}{\\mathrm{vol}(C_k)}\\right) - 0.5K$。如果 $\\mathrm{vol}(C_k)=0$，则和中的相应项被视为 0。\n2.  **平均相关性改善值 $\\Delta$**：\n    a.  **匹配簇**：对于每个找到的 ROI $C_k$，通过找到与 $C_k$ 有最大重叠（以像素数量计）的基准真相 ROI $C_{gt, j}$，来确定相应的基准真相信号 $s_{j(k)}(t)$。\n    b.  **计算相关性**：对于每个 $k \\in \\{1, \\dots, K\\}$，计算未校正信号与其匹配的基准真相信号的相关性 $\\rho_{\\text{before},k} = \\mathrm{corr}(F_{\\mathrm{ROI}_k}, s_{j(k)})$，以及校正后信号的相关性 $\\rho_{\\text{after},k} = \\mathrm{corr}(F_{\\mathrm{corr},k}, s_{j(k)})$。\n    c.  **计算平均改善值**：总的平均改善值是 $\\Delta = \\frac{1}{K}\\sum_{k=1}^K (\\rho_{\\text{after},k} - \\rho_{\\text{before},k})$。\n\n这个全面的流程满足了问题陈述的所有要求。实现将精确地遵循这个逻辑。",
            "answer": "```python\nimport numpy as np\nfrom scipy.cluster.vq import kmeans2\n\ndef pearson_corr(x, y):\n    \"\"\"Computes the Pearson correlation between two 1D arrays.\"\"\"\n    if x.ndim != 1 or y.ndim != 1:\n        raise ValueError(\"Inputs must be 1D arrays.\")\n    \n    x_mean, y_mean = np.mean(x), np.mean(y)\n    x_std, y_std = np.std(x), np.std(y)\n    \n    if x_std == 0 or y_std == 0:\n        return 0.0\n        \n    cov = np.mean((x - x_mean) * (y - y_mean))\n    return cov / (x_std * y_std)\n\ndef generate_data(case):\n    \"\"\"Generates synthetic data for a given test case.\"\"\"\n    \n    grid_shape = case['grid_size']\n    N = grid_shape[0] * grid_shape[1]\n    T = case['T']\n    K = case['K']\n    seed = case['seed']\n    \n    # Generate pixel coordinates and ground-truth ROI assignments\n    coords = np.array([(i % grid_shape[1], i // grid_shape[1]) for i in range(N)]) # (x, y) 0-indexed\n    gt_roi_map = np.zeros(N, dtype=int)\n    for i, (x, y) in enumerate(coords):\n        if 'C1_func' in case and case['C1_func'](x + 1, y + 1): # 1-based indexing for func\n            gt_roi_map[i] = 0 # C1 maps to index 0\n        else:\n            gt_roi_map[i] = 1 # C2 maps to index 1\n\n    # Generate latent signals\n    t_axis = np.arange(1, T + 1)\n    s1, s2, n = case['latent_signals_func'](t_axis, T)\n    s_true = [s1, s2]\n\n    # Generate observed fluorescence\n    rng = np.random.default_rng(seed)\n    F = np.zeros((N, T))\n    sigma = np.sqrt(case['obs_model']['sigma2'])\n    \n    s_coeffs = case['obs_model']['s_coeffs']\n    n_coeff = case['obs_model']['n_coeff']\n\n    for i in range(N):\n        c_i = gt_roi_map[i]\n        s_i_t = s_true[c_i]\n        \n        # In case 2, s_coeffs are 0.0, this handles it.\n        s_term = s_coeffs[c_i] * s_i_t if s_coeffs else 0.0\n        \n        noise = rng.normal(0, sigma, T)\n        F[i, :] = s_term + n_coeff * n + noise\n\n    return F, s_true, gt_roi_map, grid_shape\n\ndef compute_adjacency_matrix(F):\n    \"\"\"Computes the correlation-based adjacency matrix W.\"\"\"\n    N, T = F.shape\n    # np.corrcoef is faster than manual computation\n    # It handles zero-variance case by returning nan which we convert to 0\n    rho = np.corrcoef(F)\n    np.nan_to_num(rho, copy=False, nan=0.0)\n    W = np.maximum(0, rho)\n    np.fill_diagonal(W, 0)\n    return W\n\ndef spectral_clustering(W, K, seed):\n    \"\"\"Performs spectral clustering on the graph W.\"\"\"\n    N = W.shape[0]\n    \n    # Degree matrix\n    d = W.sum(axis=1)\n    D_inv = np.diag(np.where(d > 0, 1.0 / d, 0))\n    \n    # Random-walk normalized Laplacian\n    L_rw = D_inv @ W\n    \n    # Eigendecomposition\n    # We need eigenvectors for largest eigenvalues.\n    # For a general matrix, use np.linalg.eig\n    eigenvalues, eigenvectors = np.linalg.eig(L_rw)\n    eigenvalues = np.real(eigenvalues)\n    eigenvectors = np.real(eigenvectors)\n    \n    # Get indices of K largest eigenvalues\n    top_k_indices = np.argsort(eigenvalues)[-K:]\n    U = eigenvectors[:, top_k_indices]\n    \n    # K-means clustering on the rows of U\n    # Scipy kmeans2 requires a seed in a specific way. We'll set the global numpy seed.\n    np.random.seed(seed)\n    _, labels = kmeans2(U, K, minit='points', iter=20)\n    \n    return labels\n\ndef calculate_metrics(partition_labels, W, F, s_true, gt_roi_map, grid_shape, K, alpha, lambda_):\n    \"\"\"Calculates the objective value and correlation improvement.\"\"\"\n    N, T = F.shape\n    coords = np.array([(i % grid_shape[1], i // grid_shape[1]) for i in range(N)])\n\n    # 1. Calculate objective value J_lambda\n    d = W.sum(axis=1)\n    assoc_terms = []\n    unique_labels = np.unique(partition_labels)\n    K_found = len(unique_labels)\n\n    for k in unique_labels:\n        cluster_indices = np.where(partition_labels == k)[0]\n        if len(cluster_indices) == 0:\n            continue\n        \n        vol_k = d[cluster_indices].sum()\n        \n        # Slicing is an efficient way to get submatrix sum\n        sub_w = W[np.ix_(cluster_indices, cluster_indices)]\n        assoc_kk = sub_w.sum()\n        \n        if vol_k > 0:\n            assoc_terms.append(assoc_kk / vol_k)\n        else:\n            assoc_terms.append(0.0)\n            \n    H_p = np.sum(assoc_terms)\n    \n    # Use K from the spec, not K_found, as per objective formula\n    J_lambda_val = H_p - (1 - lambda_) * K\n\n    # 2. Calculate average correlation improvement\n    corr_improvements = []\n    \n    # Match found clusters to ground truth clusters\n    cluster_map = {}\n    for k in unique_labels:\n        cluster_indices = np.where(partition_labels == k)[0]\n        gt_labels_in_cluster = gt_roi_map[cluster_indices]\n        # Find which ground truth cluster has max overlap\n        # since K=2, this is simple\n        if len(gt_labels_in_cluster) > 0:\n            matched_gt_label = np.bincount(gt_labels_in_cluster).argmax()\n            cluster_map[k] = matched_gt_label\n    \n    # If a found cluster is empty or matching fails, it won't be processed.\n    # This loop runs over successfully matched clusters.\n    for k, matched_gt_label in cluster_map.items():\n        cluster_indices = np.where(partition_labels == k)[0]\n        \n        # ROI Signal\n        F_roi_k = F[cluster_indices, :].mean(axis=0)\n        \n        # Neuropil Ring and Signal\n        roi_coords = set(map(tuple, coords[cluster_indices]))\n        neuropil_pixels = set()\n        for x_i, y_i in roi_coords:\n            for dx in [-1, 0, 1]:\n                for dy in [-1, 0, 1]:\n                    if dx == 0 and dy == 0:\n                        continue\n                    neighbor = (x_i + dx, y_i + dy)\n                    if 0 = neighbor[0]  grid_shape[1] and 0 = neighbor[1]  grid_shape[0]:\n                        if neighbor not in roi_coords:\n                            neuropil_pixels.add(neighbor)\n        \n        neuropil_indices = [y * grid_shape[1] + x for x, y in neuropil_pixels]\n        \n        if len(neuropil_indices) > 0:\n            F_np_k = F[neuropil_indices, :].mean(axis=0)\n        else:\n            F_np_k = np.zeros(T)\n            \n        # Corrected Signal\n        F_corr_k = F_roi_k - alpha * (F_np_k - np.median(F_np_k))\n        \n        # Ground-truth signal for comparison\n        s_k_true = s_true[matched_gt_label]\n        \n        # Correlations\n        rho_before = pearson_corr(F_roi_k, s_k_true)\n        rho_after = pearson_corr(F_corr_k, s_k_true)\n        \n        corr_improvements.append(rho_after - rho_before)\n\n    if len(corr_improvements) > 0:\n        avg_corr_improvement = np.mean(corr_improvements)\n    else: # Handle case of empty clusters or failed matching\n        avg_corr_improvement = 0.0\n\n    return J_lambda_val, avg_corr_improvement\n\n\ndef solve():\n    test_cases = [\n        {\n            'name': 'happy path',\n            'grid_size': (4, 4), 'T': 60, 'K': 2, 'seed': 42, 'alpha': 0.7, 'lambda': 0.5,\n            'C1_func': lambda x, y: y = 2,\n            'latent_signals_func': lambda t, T: (\n                np.sin(2 * np.pi * 3 * t / T) + 0.5 * np.isin(t, [10, 11, 12]),\n                np.sin(2 * np.pi * 5 * t / T),\n                0.3 * np.sin(2 * np.pi * 1 * t / T)\n            ),\n            'obs_model': {'s_coeffs': [1.0, 1.0], 'n_coeff': 0.5, 'sigma2': 0.2**2}\n        },\n        {\n            'name': 'weak structure',\n            'grid_size': (4, 4), 'T': 60, 'K': 2, 'seed': 7, 'alpha': 0.7, 'lambda': 0.5,\n            'C1_func': lambda x, y: y = 2,\n            'latent_signals_func': lambda t, T: (\n                np.zeros_like(t, dtype=float),\n                np.zeros_like(t, dtype=float),\n                np.sin(2 * np.pi * 2 * t / T)\n            ),\n            'obs_model': {'s_coeffs': [0.0, 0.0], 'n_coeff': 1.0, 'sigma2': 0.5**2}\n        },\n        {\n            'name': 'small ROI',\n            'grid_size': (5, 5), 'T': 60, 'K': 2, 'seed': 123, 'alpha': 0.7, 'lambda': 0.5,\n            'C1_func': lambda x, y: (x, y) in [(3,3),(3,2),(3,4),(2,3),(4,3)],\n            'latent_signals_func': lambda t, T: (\n                1.0 * np.isin(t, np.arange(20, 26)) + 0.2 * np.sin(2 * np.pi * 4 * t / T),\n                np.zeros_like(t, dtype=float), # s2 is approx 0\n                0.2 * np.sin(2 * np.pi * 1 * t / T)\n            ),\n            'obs_model': {'s_coeffs': [1.0, 1.0], 'n_coeff': 0.5, 'sigma2': 0.3**2}\n        }\n    ]\n\n    results = []\n    for case in test_cases:\n        F, s_true, gt_roi_map, grid_shape = generate_data(case)\n        W = compute_adjacency_matrix(F)\n        partition_labels = spectral_clustering(W, case['K'], case['seed'])\n        \n        obj_val, avg_corr_improvement = calculate_metrics(\n            partition_labels, W, F, s_true, gt_roi_map, grid_shape,\n            case['K'], case['alpha'], case['lambda']\n        )\n        \n        results.append(f\"{obj_val:.6f}\")\n        results.append(f\"{avg_corr_improvement:.6f}\")\n        \n    print(f\"[{','.join(results)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "在识别出一个神经元的空间足迹（即ROI）后，我们需要从荧光视频中提取其潜在的时间活动，而观测到的荧光通常是真实神经信号、神经毡污染和噪声的混合体。约束非负矩阵分解（Constrained Nonnegative Matrix Factorization, CNMF）是一个强大的框架，它将观测到的荧光建模为一个空间足迹和一个时间分量的乘积。本练习要求您为一个简化的CNMF模型推导出核心的交替优化更新规则，通过推导数学原理并将其应用于一个具体例子，您将揭开这一基石算法的神秘面纱，并理解它如何将神经信号从污染物中分离出来。",
            "id": "4143876",
            "problem": "考虑一部经过运动校正的二维荧光视频，其已被分割以提取单个神经元的固定感兴趣区域 (ROI)。该区域由一个矩阵 $Y \\in \\mathbb{R}^{p \\times T}$ 表示，涵盖了 $p$ 个像素和 $T$ 个时间点。设空间足迹为 $A \\in \\mathbb{R}^{p \\times 1}$，时间活动轨迹为 $C \\in \\mathbb{R}^{1 \\times T}$，因此秩一分解 $A C$ 建模了该神经元的贡献。假设视频被神经毡荧光 $S \\in \\mathbb{R}^{p \\times T}$ 污染，其污染系数为 $\\rho \\in \\mathbb{R}_{+}$，并定义校正后的数据 $Y' = Y - \\rho S$。目标是在概率观测模型下，通过交替优化来估计 $A$ 和 $C$，同时施加与约束非负矩阵分解 (CNMF) 相关的约束。\n\n从经过充分检验的观测模型和核心定义出发：\n- 在高斯噪声模型下，假设 $Y'$ 由 $Y' = A C + E$ 生成，其中 $E$ 由独立的、均值为零、方差为 $\\sigma^{2}$ 的高斯随机变量组成。\n- 在泊松计数模型下，假设 $Y'$ 表示光子计数，其率为 $\\Lambda = A C$，因此 $Y'_{i,t} \\sim \\mathrm{Poisson}(\\Lambda_{i,t})$。\n\n你将从两个模型的负对数似然函数（通过与 CNMF 实践一致的正则化和约束进行增广）出发，推导 $A$ 和 $C$ 的交替优化更新规则，然后在高斯模型下计算一个特定的标量更新。\n\n任务：\n1. 在高斯模型下，通过最小化惩罚负对数似然函数\n$$\n\\mathcal{L}_{\\mathrm{G}}(A,C) = \\frac{1}{2 \\sigma^{2}} \\| Y' - A C \\|_{F}^{2} + \\frac{\\lambda_{C}}{2} \\| C \\|_{F}^{2}\n$$\n并在约束条件 $C \\geq 0$ 下，推导给定 $A$ 时 $C$ 的更新规则。展示无约束情况下的最小化解，并描述如何施加非负性约束。\n\n2. 在高斯模型下，通过最小化\n$$\n\\mathcal{L}_{\\mathrm{G}}(A,C) = \\frac{1}{2 \\sigma^{2}} \\| Y' - A C \\|_{F}^{2} + \\frac{\\lambda_{A}}{2} \\| A \\|_{2}^{2}\n$$\n并在约束条件 $A \\geq 0$ 下，推导给定 $C$ 时 $A$ 的更新规则。展示无约束情况下的最小化解，并描述如何施加非负性约束。在你的推导中，清晰地指出在秩一情况下交替优化是如何解耦的。\n\n3. 从泊松负对数似然\n$$\n\\mathcal{L}_{\\mathrm{P}}(A,C) = \\sum_{i=1}^{p} \\sum_{t=1}^{T} \\left[ (A C)_{i,t} - Y'_{i,t} \\ln\\left( (A C)_{i,t} \\right) \\right],\n$$\n出发，推导满足 $A \\geq 0$ 和 $C \\geq 0$ 的 $A$ 和 $C$ 的乘性更新规则。提供通过施加 Karush–Kuhn–Tucker 最优性条件或在广义 Kullback–Leibler 散度下使用适用于非负矩阵分解的辅助函数法得到的表达式。\n\n4. 利用推导出的目标函数和约束的结构，解释为什么非负性、空间正则化（例如，对 $A$ 的二次惩罚或离散拉普拉斯惩罚）以及显式支持集约束等约束条件能够防止退化解，例如坍缩的足迹（例如，$A$ 将所有权重集中在单个像素上）。\n\n5. 在高斯模型下计算单次数值更新。考虑\n$$\nY = \\begin{pmatrix}\n10  12 \\\\\n22  20 \\\\\n11  15\n\\end{pmatrix}, \\quad\nS = \\begin{pmatrix}\n4  3 \\\\\n5  4 \\\\\n3  2\n\\end{pmatrix}, \\quad\n\\rho = 0.2,\n$$\n以及一个初始空间足迹\n$$\nA = \\begin{pmatrix}\n1 \\\\\n2 \\\\\n1\n\\end{pmatrix}.\n$$\n使用任务1中推导的 $C$ 更新规则，并设 $\\lambda_{C} = 1$，计算经过神经毡校正后，在时间点 $t=2$ 的更新活动（记为 $c_2$）。用任意荧光单位表示数值结果。将你的答案四舍五入到四位有效数字。",
            "solution": "问题陈述经评估是有效的。它在计算神经科学和优化的既定原则上具有科学依据，特别是关于使用约束矩阵分解分析钙成像数据。该问题是适定的，提供了执行所需推导和计算的所有必要定义、模型和数据。其语言客观且数学上精确。该问题是神经科学数据分析中一个核心任务的标准（尽管简化了的）表述，适合进行严谨的解答。\n\n我们将按顺序解决这五个任务。\n\n### 任务1：高斯模型下 C 的更新\n\n对于固定的空间分量 $A \\in \\mathbb{R}^{p \\times 1}$，需要针对时间分量 $C \\in \\mathbb{R}^{1 \\times T}$ 最小化的目标函数是惩罚负对数似然：\n$$\n\\mathcal{L}_{\\mathrm{G}}(C) = \\frac{1}{2 \\sigma^{2}} \\| Y' - A C \\|_{F}^{2} + \\frac{\\lambda_{C}}{2} \\| C \\|_{F}^{2}\n$$\n约束条件为 $C \\geq 0$（逐元素）。\n\n为找到无约束最小化解，我们计算 $\\mathcal{L}_{\\mathrm{G}}$ 关于 $C$ 的梯度并将其设为零。弗罗贝尼乌斯范数的平方是元素平方和，即 $\\|X\\|_F^2 = \\mathrm{Tr}(X^T X)$。让我们用迹表示法来表达目标函数：\n$$\n\\mathcal{L}_{\\mathrm{G}}(C) = \\frac{1}{2 \\sigma^{2}} \\mathrm{Tr}((Y' - AC)^T(Y' - AC)) + \\frac{\\lambda_{C}}{2} \\mathrm{Tr}(C^T C)\n$$\n由于 $C$ 是一个 $1 \\times T$ 的行向量，更方便的做法是计算关于每个分量 $c_t$ ($t=1, \\dots, T$) 的导数。\n$$\n\\| Y' - A C \\|_{F}^{2} = \\sum_{i=1}^{p} \\sum_{t=1}^{T} (Y'_{i,t} - a_i c_t)^2\n$$\n第一项关于特定分量 $c_t$ 的导数是：\n$$\n\\frac{\\partial}{\\partial c_t} \\left( \\sum_{i, \\tau} (Y'_{i,\\tau} - a_i c_\\tau)^2 \\right) = \\sum_{i=1}^{p} 2(Y'_{i,t} - a_i c_t)(-a_i) = -2 \\sum_{i=1}^{p} a_i(Y'_{i,t} - a_i c_t) = -2 (A^T Y'_t - (A^T A) c_t)\n$$\n其中 $Y'_t$ 是 $Y'$ 的第 $t$ 列。正则化项的导数是：\n$$\n\\frac{\\partial}{\\partial c_t} \\left( \\frac{\\lambda_C}{2} \\|C\\|_F^2 \\right) = \\frac{\\partial}{\\partial c_t} \\left( \\frac{\\lambda_C}{2} \\sum_{\\tau=1}^T c_{\\tau}^2 \\right) = \\lambda_C c_t\n$$\n结合这些，完整目标函数关于 $c_t$ 的导数是：\n$$\n\\frac{\\partial \\mathcal{L}_{\\mathrm{G}}}{\\partial c_t} = \\frac{1}{2 \\sigma^{2}} [-2 (A^T Y'_t - (A^T A) c_t)] + \\lambda_C c_t = \\frac{1}{\\sigma^2} ( (A^T A) c_t - A^T Y'_t) + \\lambda_C c_t\n$$\n将导数设为零以找到无约束最小值：\n$$\n\\left( \\frac{A^T A}{\\sigma^2} + \\lambda_C \\right) c_t = \\frac{A^T Y'_t}{\\sigma^2} \\implies c_t = \\frac{A^T Y'_t}{A^T A + \\sigma^2 \\lambda_C}\n$$\n这可以为整个向量 $C$ 写成：\n$$\nC_{\\mathrm{unconstrained}} = \\frac{A^T Y'}{A^T A + \\sigma^2 \\lambda_C}\n$$\n注意 $A^T A = \\|A\\|_2^2$ 是一个标量，因此除法是良定义的。\n\n该优化问题是一个带有简单非负性约束的二次规划问题。其解可以通过将无约束最小化解投影到可行集（非负象限）上得到。这个投影就是简单地取与零的逐元素最大值。因此，施加 $C \\geq 0$ 约束的 $C$ 的更新规则是：\n$$\nC \\leftarrow \\left( \\frac{A^T Y'}{A^T A + \\sigma^2 \\lambda_C} \\right)_+\n$$\n其中 $(\\cdot)_+$ 表示逐元素应用的修正函数 $\\max(0, \\cdot)$。\n\n### 任务2：高斯模型下 A 的更新\n\n对于固定的时间分量 $C \\in \\mathbb{R}^{1 \\times T}$，需要针对空间分量 $A \\in \\mathbb{R}^{p \\times 1}$ 最小化的目标函数是：\n$$\n\\mathcal{L}_{\\mathrm{G}}(A) = \\frac{1}{2 \\sigma^{2}} \\| Y' - A C \\|_{F}^{2} + \\frac{\\lambda_{A}}{2} \\| A \\|_{2}^{2}\n$$\n约束条件为 $A \\geq 0$。这与 $C$ 的更新类似。我们对 $A$ 的每个分量 $a_i$ 求导：\n$$\n\\frac{\\partial}{\\partial a_i} \\left( \\sum_{j=1}^{p} \\sum_{t=1}^{T} (Y'_{j,t} - a_j c_t)^2 \\right) = \\sum_{t=1}^{T} 2(Y'_{i,t} - a_i c_t)(-c_t) = -2 ( (Y'C^T)_i - a_i(CC^T) )\n$$\n其中 $(Y'C^T)_i$ 是向量 $Y'C^T$ 的第 $i$ 个元素。正则化项的导数是 $\\frac{\\partial}{\\partial a_i} (\\frac{\\lambda_A}{2} \\sum_j a_j^2) = \\lambda_A a_i$。\n\n完整目标函数关于 $a_i$ 的导数是：\n$$\n\\frac{\\partial \\mathcal{L}_{\\mathrm{G}}}{\\partial a_i} = \\frac{1}{\\sigma^2}( a_i(CC^T) - (Y'C^T)_i) + \\lambda_A a_i\n$$\n设为零：\n$$\n\\left( \\frac{CC^T}{\\sigma^2} + \\lambda_A \\right) a_i = \\frac{(Y'C^T)_i}{\\sigma^2} \\implies a_i = \\frac{(Y'C^T)_i}{CC^T + \\sigma^2 \\lambda_A}\n$$\n对于整个向量 $A$：\n$$\nA_{\\mathrm{unconstrained}} = \\frac{Y'C^T}{CC^T + \\sigma^2 \\lambda_A}\n$$\n注意 $CC^T = \\|C\\|_F^2$ 是一个标量。\n\n这个更新方程展示了 $A$ 的优化的解耦特性。每个像素权重 $a_i$ 的更新只依赖于数据矩阵的相应行 $Y'_{i,:}$，而与所有其他像素 $j \\neq i$ 无关。这是秩一模型结构的直接结果，其中每个像素的时间序列被建模为对公共时间分量 $C$ 的独立缩放。\n\n如前所述，通过投影来施加非负性约束 $A \\geq 0$：\n$$\nA \\leftarrow \\left( \\frac{Y'C^T}{CC^T + \\sigma^2 \\lambda_A} \\right)_+\n$$\n\n### 任务3：泊松模型下的乘性更新\n\n目标函数是泊松模型的负对数似然，这等价于最小化广义 Kullback–Leibler (KL) 散度 $D_{KL}(Y' || AC)$：\n$$\n\\mathcal{L}_{\\mathrm{P}}(A,C) = \\sum_{i=1}^{p} \\sum_{t=1}^{T} \\left[ (A C)_{i,t} - Y'_{i,t} \\ln\\left( (A C)_{i,t} \\right) \\right]\n$$\n我们寻求 $A \\geq 0$ 和 $C \\geq 0$ 的乘性更新规则。这些规则可以使用辅助函数法或从 Karush–Kuhn–Tucker (KKT) 条件推导得出。对于分解 $V \\approx WH$，使用 KL 散度的非负矩阵分解 (NMF) 的标准乘性更新规则是：\n$$\nH \\leftarrow H \\odot \\frac{W^T (V ./ (WH))}{W^T \\mathbf{1}} \\quad \\text{and} \\quad W \\leftarrow W \\odot \\frac{(V ./ (WH)) H^T}{\\mathbf{1} H^T}\n$$\n其中 $\\odot$ 和 $./$ 分别表示逐元素乘法和除法，$\\mathbf{1}$ 是一个大小适当的全一矩阵。\n\n在我们的例子中，$V=Y'$, $W=A$（一个 $p \\times 1$ 矩阵），$H=C$（一个 $1 \\times T$ 矩阵）。\n\n对于 $C$ 的更新：\n项 $W^T \\mathbf{1}$ 变成一个 $1 \\times T$ 的行向量，其中每个元素是 $\\sum_{i=1}^p a_i$。\n项 $(Y' ./ (AC))_{i,t} = Y'_{i,t} / (a_i c_t)$。\n项 $W^T (V ./ (WH))$ 变成一个 $1 \\times T$ 向量。其第 $t$ 个分量是：\n$$\n\\sum_{i=1}^p a_i \\frac{Y'_{i,t}}{a_i c_t} = \\frac{1}{c_t} \\sum_{i=1}^p Y'_{i,t}\n$$\n元素 $c_t$ 的乘性更新是：\n$$\nc_t \\leftarrow c_t \\odot \\frac{\\frac{1}{c_t} \\sum_{i=1}^p Y'_{i,t}}{\\sum_{i=1}^p a_i} = \\frac{\\sum_{i=1}^p Y'_{i,t}}{\\sum_{i=1}^p a_i}\n$$\n\n对于 $A$ 的更新：\n项 $\\mathbf{1} H^T$ 变成一个 $p \\times 1$ 的列向量，其中每个元素是 $\\sum_{t=1}^T c_t$。\n项 $(V ./ (WH)) H^T$ 变成一个 $p \\times 1$ 向量。其第 $i$ 个分量是：\n$$\n\\sum_{t=1}^T \\frac{Y'_{i,t}}{a_i c_t} c_t = \\frac{1}{a_i} \\sum_{t=1}^T Y'_{i,t}\n$$\n元素 $a_i$ 的乘性更新是：\n$$\na_i \\leftarrow a_i \\odot \\frac{\\frac{1}{a_i} \\sum_{t=1}^T Y'_{i,t}}{\\sum_{t=1}^T c_t} = \\frac{\\sum_{t=1}^T Y'_{i,t}}{\\sum_{t=1}^T c_t}\n$$\n因此，为秩一情况简化后，推导出的乘性更新规则是：\n$$\n\\text{对于 } t=1, \\dots, T: \\quad c_t \\leftarrow \\frac{\\sum_{i=1}^p Y'_{i,t}}{\\sum_{i=1}^p a_i}\n$$\n$$\n\\text{对于 } i=1, \\dots, p: \\quad a_i \\leftarrow \\frac{\\sum_{t=1}^T Y'_{i,t}}{\\sum_{t=1}^T c_t}\n$$\n只要 $Y'$ 和初始的 $A, C$ 是非负的，这些更新规则就能内在地保持非负性。\n\n### 任务4：约束在防止退化解中的作用\n\n无约束的分解问题 $Y' \\approx AC$ 是不适定的。若无约束，它会容许无限多个退化解。例如，尺度模糊性允许对于任何标量 $k \\neq 0$ 都有 $(kA)(k^{-1}C) = AC$。这意味着 $A$ 和 $C$ 的大小不是唯一确定的。更严重的退化包括那些不具有物理意义的解。\n\n1.  **非负性 ($A \\geq 0, C \\geq 0$):** 这是最基本的约束，其动机源于荧光的物理特性。它将解限制在解空间的一个锥体内，并将尺度模糊性限制在 $k  0$。然而，仅靠它本身不足以防止过拟合或非生理性的空间足迹。\n\n2.  **对 $A$ 的空间正则化:** 这编码了关于神经元空间足迹形状的先验信念。\n    *   **二次 ($L_2$) 惩罚 ($\\lambda_A \\|A\\|_2^2$):** 此惩罚不鼓励 $A$ 中出现大幅值的项。一个坍缩的足迹，即所有能量集中在一个像素 $a_k=M$ 而其他像素为零，其惩罚为 $\\frac{\\lambda_A}{2}M^2$。而一个将相同能量分布在 $N$ 个像素上的足迹（例如，$a_i=M/N$），其惩罚将与 $N(M/N)^2 = M^2/N$ 成正比，这个值更小。因此，$L_2$ 惩罚偏好空间上分布的足迹，而非高度集中的足迹，从而减轻了坍缩的风险。\n    *   **拉普拉斯惩罚 ($A^T L A$):** 这种形式的正则化明确地促进了空间平滑性。拉普拉斯算子 $L$ 惩罚相邻像素之间的巨大差异。单个像素上的坍缩足迹代表了一个急剧的空间不连续性（一个大值旁边是零），这将导致非常高的惩罚。这种约束在强制足迹连续且平滑方面非常有效，这与细胞体的微观视图一致。\n\n3.  **显式支持集约束:** 这涉及强制所有在预定义感兴趣区域之外的像素 $i$ 满足 $a_i = 0$。这是防止坍缩足迹最直接的方法，因为可以定义一个具有合理大小和形状的支持区域，使得解不可能只存在于该区域内的单个像素上（除非该区域本身就是一个像素）。\n\n总而言之，这些约束并非随意设置，而是对不适定分解问题进行正则化的关键。它们融入了关于信号源物理和生物学性质的关键先验知识，引导优化朝向不仅在数学上有效，而且在科学上有意义且对噪声鲁棒的解。\n\n### 任务5：数值更新计算\n\n我们被要求使用任务1中高斯模型的 C 更新规则，根据给定的初始状态，计算 $c_2$ 的更新值。\n更新公式为：\n$$\nc_t = \\left( \\frac{A^T Y'_t}{A^T A + \\sigma^2 \\lambda_C} \\right)_+\n$$\n问题没有指定噪声方差 $\\sigma^2$。在从概率模型推导出的优化背景下，这个参数通常在不失一般性的情况下设为1，因为它实际上是对正则化参数 $\\lambda_C$ 进行重新缩放。我们将基于 $\\sigma^2=1$ 这个标准假设继续进行。\n\n给定的数据是：\n$$\nY = \\begin{pmatrix} 10  12 \\\\ 22  20 \\\\ 11  15 \\end{pmatrix}, \\quad S = \\begin{pmatrix} 4  3 \\\\ 5  4 \\\\ 3  2 \\end{pmatrix}, \\quad \\rho = 0.2\n$$\n$$\nA = \\begin{pmatrix} 1 \\\\ 2 \\\\ 1 \\end{pmatrix}, \\quad \\lambda_C = 1\n$$\n首先，我们计算经神经毡校正的数据 $Y' = Y - \\rho S$：\n$$\n\\rho S = 0.2 \\begin{pmatrix} 4  3 \\\\ 5  4 \\\\ 3  2 \\end{pmatrix} = \\begin{pmatrix} 0.8  0.6 \\\\ 1.0  0.8 \\\\ 0.6  0.4 \\end{pmatrix}\n$$\n$$\nY' = \\begin{pmatrix} 10  12 \\\\ 22  20 \\\\ 11  15 \\end{pmatrix} - \\begin{pmatrix} 0.8  0.6 \\\\ 1.0  0.8 \\\\ 0.6  0.4 \\end{pmatrix} = \\begin{pmatrix} 9.2  11.4 \\\\ 21.0  19.2 \\\\ 10.4  14.6 \\end{pmatrix}\n$$\n我们需要计算 $c_2$，因此我们使用 $Y'$ 的第二列，记为 $Y'_2$：\n$$\nY'_2 = \\begin{pmatrix} 11.4 \\\\ 19.2 \\\\ 14.6 \\end{pmatrix}\n$$\n接下来，我们计算更新公式中的各项：\n分子是 $A^T Y'_2$：\n$$\nA^T Y'_2 = \\begin{pmatrix} 1  2  1 \\end{pmatrix} \\begin{pmatrix} 11.4 \\\\ 19.2 \\\\ 14.6 \\end{pmatrix} = (1)(11.4) + (2)(19.2) + (1)(14.6) = 11.4 + 38.4 + 14.6 = 64.4\n$$\n分母包含 $A^T A$ 和 $\\sigma^2 \\lambda_C$：\n$$\nA^T A = \\begin{pmatrix} 1  2  1 \\end{pmatrix} \\begin{pmatrix} 1 \\\\ 2 \\\\ 1 \\end{pmatrix} = 1^2 + 2^2 + 1^2 = 1 + 4 + 1 = 6\n$$\n$$\n\\sigma^2 \\lambda_C = (1)(1) = 1\n$$\n现在，将这些值代入 $c_2$ 的公式中：\n$$\nc_2 = \\left( \\frac{64.4}{6 + 1} \\right)_+ = \\left( \\frac{64.4}{7} \\right)_+ = (9.2)_+\n$$\n由于 $9.2  0$，修正函数不起作用。\n$$\nc_2 = 9.2\n$$\n问题要求答案四舍五入到四位有效数字。\n$$\nc_2 = 9.200\n$$",
            "answer": "$$\n\\boxed{9.200}\n$$"
        },
        {
            "introduction": "即使在信号提取和神经毡校正之后，荧光轨迹仍可能受到由光漂白或其他实验因素引起的缓慢基线漂移的干扰。在不扭曲快速神经瞬变的情况下移除这种漂移是一项关键挑战。虽然简单的多项式去趋势易于应用，但它可能会引入伪影；而更精细的方法，如约束平滑样条，可以被设计成选择性地移除低频噪声，同时保留神经事件的形状。通过对一个样本轨迹进行直接计算，本练习将让您量化朴素去趋势方法的缺陷（如边缘效应），然后您将构建并应用一个约束样条基线估计器，从而对如何构建尊重底层生物学的稳健信号处理工具有一个第一性原理的理解。",
            "id": "4143917",
            "problem": "从单个感兴趣区域（ROI）中提取通过钙成像获得的荧光时间序列，并使用标量系数校正神经纤维网污染，得到在采集时间 $t_i$ 处经神经纤维网校正后的信号 $y_i$。考虑 $n=5$ 个等间距样本，其时间点为 $t_1=-1, t_2=-\\frac{1}{2}, t_3=0, t_4=\\frac{1}{2}, t_5=1$（单位：秒），神经纤维网校正后的值为 $y_1=1.0, y_2=1.1, y_3=2.1, y_4=1.2, y_5=1.3$（任意单位）。\n\n已知该信号在 $t_3=0$ 秒处包含一个局部瞬时事件。数据分析的目标是刻画多项式去趋势的边缘行为，并构建一个基于样条的基线估计器，该估计器在抑制缓慢漂移的同时，能保留 $t_3$ 附近的局部事件结构。\n\n任务：\n\n1. 使用线性模型 $y = X\\beta + \\varepsilon$，其中 $X$ 是由列 $1$、$t$ 和 $t^2$（2次多项式）组成的设计矩阵。从最小二乘投影（帽子）矩阵 $H = X\\left(X^{\\top}X\\right)^{-1}X^{\\top}$ 的定义出发，针对特定网格 $t_i \\in \\{-1,-\\frac{1}{2},0,\\frac{1}{2},1\\}$，计算 $H_{11}$ 和 $H_{33}$。利用这些结果，从第一性原理出发，解释为什么多项式去趋势会在 $t=-1$ 处（相对于内部点 $t=0$）引入边缘伪影。\n\n2. 为了估计一个能够抑制缓慢漂移同时保留 $t_3=0$ 附近局部事件结构的基线 $b$，通过对离散曲率施加平滑惩罚来在样本网格上对 $b$ 进行建模。从三次平滑样条的粗糙度泛函的经典离散近似\n$$\n\\sum_{i=2}^{n-1}\\left(b_{i-1}-2b_i+b_{i+1}\\right)^2,\n$$\n出发，将基线估计问题表述为在平滑参数 $\\lambda = 1$ 和满足事件保留及边缘稳定的线性约束\n$$\nb_2 - b_1 = 0,\\quad b_5 - b_4 = 0,\\quad b_2 - 2 b_3 + b_4 = 0.\n$$\n的条件下，最小化\n$$\nJ(b) = \\sum_{i=1}^{n}\\left(y_i - b_i\\right)^2 + \\lambda \\sum_{i=2}^{n-1}\\left(b_{i-1}-2b_i+b_{i+1}\\right)^2\n$$\n的问题。从第一性原理出发，推导在 $n=5$ 网格上的约束最优解 $b^{\\star}$。\n\n3. 使用你推导出的约束样条基线 $b^{\\star}$，计算第一个时间点 $t_1=-1$ 秒处经神经纤维网校正和基线扣除后的值，即 $r_1 = y_1 - b^{\\star}_1$。用任意单位表示你的最终数值答案，并将结果四舍五入到四位有效数字。",
            "solution": "我们首先回顾适用于钙成像数据分析的线性回归和平滑样条的核心定义。\n\n对于任务1，我们使用2次多项式回归，其设计矩阵 $X$ 的第 $i$ 行为 $\\left[1, t_i, t_i^2\\right]$。最小二乘估计量通过帽子矩阵\n$$\nH = X\\left(X^{\\top}X\\right)^{-1}X^{\\top}.\n$$\n将数据 $y$ 投影到 $X$ 的列空间上。对角元素 $H_{ii} = x_i^{\\top}\\left(X^{\\top}X\\right)^{-1}x_i$（其中 $x_i = \\left[1, t_i, t_i^2\\right]^{\\top}$）量化了杠杆率，并表明每个点的拟合值对其观测值的敏感度。\n\n我们为网格 $t_i \\in \\left\\{-1, -\\frac{1}{2}, 0, \\frac{1}{2}, 1\\right\\}$ 计算 $X^{\\top}X$。令 $S_k = \\sum_{i=1}^{5} t_i^k$。由对称性可知 $S_1=0$ 和 $S_3=0$。我们计算\n$$\nS_0 = 5,\\quad S_2 = 1 + \\frac{1}{4} + 0 + \\frac{1}{4} + 1 = \\frac{5}{2},\\quad S_4 = 1 + \\frac{1}{16} + 0 + \\frac{1}{16} + 1 = \\frac{17}{8}.\n$$\n因此\n$$\nX^{\\top}X = \\begin{pmatrix}\n5  0  \\frac{5}{2} \\\\\n0  \\frac{5}{2}  0 \\\\\n\\frac{5}{2}  0  \\frac{17}{8}\n\\end{pmatrix}.\n$$\n对该块状结构求逆，中间项的逆是 $\\left(X^{\\top}X\\right)^{-1}_{22} = \\frac{2}{5}$。对于索引 $\\{1,3\\}$ 的 $2\\times 2$ 子块，其行列式为\n$$\n\\det = 5\\cdot \\frac{17}{8} - \\left(\\frac{5}{2}\\right)^2 = \\frac{85}{8} - \\frac{25}{4} = \\frac{35}{8},\n$$\n得到\n$$\n\\left(X^{\\top}X\\right)^{-1}_{\\{1,3\\}} = \\frac{8}{35} \\begin{pmatrix}\n\\frac{17}{8}  -\\frac{5}{2} \\\\\n-\\frac{5}{2}  5\n\\end{pmatrix} = \\begin{pmatrix}\n\\frac{17}{35}  -\\frac{4}{7} \\\\\n-\\frac{4}{7}  \\frac{8}{7}\n\\end{pmatrix}.\n$$\n所以，\n$$\n\\left(X^{\\top}X\\right)^{-1} = \\begin{pmatrix}\n\\frac{17}{35}  0  -\\frac{4}{7} \\\\\n0  \\frac{2}{5}  0 \\\\\n-\\frac{4}{7}  0  \\frac{8}{7}\n\\end{pmatrix}.\n$$\n然后，对于任意 $t$，当 $x = \\left[1, t, t^2\\right]^{\\top}$ 时，杠杆率为\n$$\nH_{ii} = x^{\\top}\\left(X^{\\top}X\\right)^{-1}x = \\frac{17}{35} + \\frac{2}{5} t^2 + \\frac{8}{7} t^4 + 2\\left(-\\frac{4}{7}\\right) t^2 = \\frac{17}{35} + \\left(\\frac{2}{5} - \\frac{8}{7}\\right) t^2 + \\frac{8}{7} t^4.\n$$\n在 $t=-1$（左边缘）处，$t^2=1$ 且 $t^4=1$，得到\n$$\nH_{11} = \\frac{17}{35} + \\frac{2}{5} + \\frac{8}{7} - \\frac{8}{7} = \\frac{17}{35} + \\frac{2}{5} = \\frac{31}{35}.\n$$\n在 $t=0$（内部）处，$t^2=t^4=0$，得到\n$$\nH_{33} = \\frac{17}{35}.\n$$\n由于 $\\frac{31}{35}  \\frac{17}{35}$，端点的杠杆率更高。边缘处的高杠杆率意味着多项式去趋势将更紧密地追踪端点值，在存在漂移或噪声的情况下，这相对于内部点会表现为边缘伪影（拟合基线在边界附近的过冲或下冲）。\n\n对于任务2，我们使用离散曲率惩罚构建一个约束的类样条基线。目标函数是\n$$\nJ(b) = \\sum_{i=1}^{5}\\left(y_i - b_i\\right)^2 + \\sum_{i=2}^{4}\\left(b_{i-1}-2b_i+b_{i+1}\\right)^2,\n$$\n其中 $\\lambda = 1$。约束条件为\n$$\nb_2 - b_1 = 0,\\quad b_5 - b_4 = 0,\\quad b_2 - 2 b_3 + b_4 = 0,\n$$\n这些约束在两端强制斜率为零以抑制端点不稳定性，并在以事件为中心的索引 $i=3$ 处强制曲率为零，以防止基线吸收瞬变事件的形状。我们通过使用约束条件消除变量来参数化可行集：\n$$\nb_2 = b_1,\\quad b_5 = b_4,\\quad b_4 = 2 b_3 - b_2 = 2 b_3 - b_1.\n$$\n因此，令 $\\alpha = b_1$ 和 $\\beta = b_3$，我们有\n$$\nb = \\begin{pmatrix} b_1 \\\\ b_2 \\\\ b_3 \\\\ b_4 \\\\ b_5 \\end{pmatrix} = \\begin{pmatrix} \\alpha \\\\ \\alpha \\\\ \\beta \\\\ 2\\beta - \\alpha \\\\ 2\\beta - \\alpha \\end{pmatrix}.\n$$\n计算曲率项：\n\\begin{align*}\n\\Delta^2 b_2 = b_1 - 2 b_2 + b_3 = \\alpha - 2\\alpha + \\beta = \\beta - \\alpha,\\\\\n\\Delta^2 b_3 = b_2 - 2 b_3 + b_4 = \\alpha - 2\\beta + (2\\beta - \\alpha) = 0,\\\\\n\\Delta^2 b_4 = b_3 - 2 b_4 + b_5 = \\beta - 2(2\\beta - \\alpha) + (2\\beta - \\alpha) = \\alpha - \\beta.\n\\end{align*}\n因此，\n$$\n\\sum_{i=2}^{4}(\\Delta^2 b_i)^2 = (\\beta - \\alpha)^2 + 0^2 + (\\alpha - \\beta)^2 = 2(\\alpha - \\beta)^2.\n$$\n数据保真项，使用 $y_1=1.0, y_2=1.1, y_3=2.1, y_4=1.2, y_5=1.3$，为\n\\begin{align*}\n\\sum_{i=1}^{5}(y_i - b_i)^2 = (1.0 - \\alpha)^2 + (1.1 - \\alpha)^2 + (2.1 - \\beta)^2 \\\\\n\\quad + \\left(1.2 - (2\\beta - \\alpha)\\right)^2 + \\left(1.3 - (2\\beta - \\alpha)\\right)^2 \\\\\n= (\\alpha - 1.0)^2 + (\\alpha - 1.1)^2 + (\\beta - 2.1)^2 \\\\\n\\quad + (\\alpha - 2\\beta + 1.2)^2 + (\\alpha - 2\\beta + 1.3)^2.\n\\end{align*}\n因此\n\\begin{align*}\nJ(\\alpha,\\beta) = (\\alpha - 1.0)^2 + (\\alpha - 1.1)^2 + (\\beta - 2.1)^2 \\\\\n\\quad + (\\alpha - 2\\beta + 1.2)^2 + (\\alpha - 2\\beta + 1.3)^2 + 2(\\alpha - \\beta)^2.\n\\end{align*}\n为最小化 $J$ 对 $(\\alpha,\\beta)$ 的值，我们将梯度设为零：\n\\begin{align*}\n\\frac{\\partial J}{\\partial \\alpha} = 2(\\alpha - 1.0) + 2(\\alpha - 1.1) + 2(\\alpha - 2\\beta + 1.2) + 2(\\alpha - 2\\beta + 1.3) + 4(\\alpha - \\beta) = 0,\\\\\n\\frac{\\partial J}{\\partial \\beta} = 2(\\beta - 2.1) - 4(\\alpha - 2\\beta + 1.2) - 4(\\alpha - 2\\beta + 1.3) - 4(\\alpha - \\beta) = 0.\n\\end{align*}\n简化第一个方程，\n\\begin{align*}\n2\\left[4\\alpha - 4\\beta + \\left(-1.0 - 1.1 + 1.2 + 1.3\\right)\\right] + 4(\\alpha - \\beta) = 0,\\\\\n2(4\\alpha - 4\\beta + 0.4) + 4(\\alpha - \\beta) = 0,\\\\\n8\\alpha - 8\\beta + 0.8 + 4\\alpha - 4\\beta = 0,\\\\\n12\\alpha - 12\\beta + 0.8 = 0,\n\\end{align*}\n所以\n$$\n\\alpha - \\beta = -\\frac{0.8}{12} = -\\frac{1}{15}.\n$$\n简化第二个方程，\n\\begin{align*}\n2\\beta - 4.2 - 4(\\alpha - 2\\beta + 1.2) - 4(\\alpha - 2\\beta + 1.3) - 4(\\alpha - \\beta) = 0,\\\\\n2\\beta - 4.2 - 4\\alpha + 8\\beta - 4.8 - 4\\alpha + 8\\beta - 5.2 - 4\\alpha + 4\\beta = 0,\\\\\n(-12\\alpha) + (22\\beta) - 14.2 = 0,\\\\\n22\\beta - 12\\alpha = 14.2.\n\\end{align*}\n代入 $\\alpha = \\beta - \\frac{1}{15}$：\n\\begin{align*}\n22\\beta - 12\\left(\\beta - \\frac{1}{15}\\right) = 14.2,\\\\\n22\\beta - 12\\beta + \\frac{12}{15} = 14.2,\\\\\n10\\beta + \\frac{4}{5} = 14.2,\\\\\n10\\beta = 13.4,\\\\\n\\beta = 1.34 = \\frac{67}{50}.\n\\end{align*}\n因此\n$$\n\\alpha = \\beta - \\frac{1}{15} = \\frac{67}{50} - \\frac{1}{15} = \\frac{191}{150} \\approx 1.273\\overline{3}.\n$$\n恢复 $b^{\\star}$：\n\\begin{align*}\nb^{\\star}_1 = \\alpha = \\frac{191}{150},\\\\\nb^{\\star}_2 = \\alpha = \\frac{191}{150},\\\\\nb^{\\star}_3 = \\beta = \\frac{67}{50},\\\\\nb^{\\star}_4 = 2\\beta - \\alpha = 2\\cdot \\frac{67}{50} - \\frac{191}{150} = \\frac{211}{150},\\\\\nb^{\\star}_5 = 2\\beta - \\alpha = \\frac{211}{150}.\n\\end{align*}\n这个约束解通过在 $i=3$ 处强制离散曲率为零来保持事件中心索引处的局域线性，并通过在边界处强制离散斜率为零来抑制端点不稳定性。\n\n对于任务3，计算扣除基线后的第一个样本：\n$$\nr_1 = y_1 - b^{\\star}_1 = 1.0 - \\frac{191}{150} = -\\frac{41}{150} \\approx -0.273\\overline{3}.\n$$\n四舍五入到四位有效数字，$r_1 \\approx -0.2733$（任意单位）。",
            "answer": "$$\\boxed{-0.2733}$$"
        }
    ]
}