{
    "hands_on_practices": [
        {
            "introduction": "The core of spike deconvolution can often be framed as a linear inverse problem. This exercise guides you through one of the most common and powerful approaches: formulating spike inference as a convex optimization problem with a sparsity-promoting penalty. You will implement the Fast Iterative Shrinkage-Thresholding Algorithm (FISTA) from first principles, a fundamental skill for any computational neuroscientist working with inverse problems. This practice deepens your understanding of how optimization machinery is applied to extract sparse neural signals from dense fluorescence data.",
            "id": "4154479",
            "problem": "You are given a discrete-time model of intracellular calcium dynamics for a single neuron recorded via fluorescence imaging. The calcium concentration is modeled as a stable linear time-invariant process driven by a nonnegative spike train. Let $t \\in \\{0,1,2,\\dots,T-1\\}$. The latent calcium concentration $c_t$ obeys $c_t = \\alpha \\, c_{t-1} + s_t$ with $c_{-1} = 0$, where $0  \\alpha  1$ is the per-time-step decay factor and $s_t \\ge 0$ is the nonnegative spike rate in arbitrary units. The observed fluorescence $y_t$ is $y_t = c_t + \\varepsilon_t$, where $\\varepsilon_t$ is an additive disturbance.\n\nWrite a complete program that, for each test case below, estimates the spike train by solving a convex optimization problem and then reports a quantitative error metric. Your program must accept no input and must print a single line containing the aggregated results.\n\nFundamental base and definitions:\n- The discrete-time convolutional forward model implied by $c_t = \\alpha \\, c_{t-1} + s_t$ and $c_{-1}=0$ yields $c_t = \\sum_{k=0}^{t} \\alpha^{t-k} s_k$. Define the lower-triangular Toeplitz matrix $G \\in \\mathbb{R}^{T \\times T}$ whose first column is $[1,\\alpha,\\alpha^2,\\dots,\\alpha^{T-1}]^\\top$ and whose first row is $[1,0,0,\\dots,0]$. Then the fluorescence time series is $y = G s + \\varepsilon$, where $s \\in \\mathbb{R}_{\\ge 0}^{T}$ is the nonnegative spike vector and $y \\in \\mathbb{R}^{T}$ is observed.\n- Spike inference is posed as a penalized least-squares estimation: minimize $f(s) = \\frac{1}{2} \\lVert G s - y \\rVert_2^2 + \\lambda \\lVert s \\rVert_1$ subject to $s \\ge 0$, where $\\lambda > 0$ controls the level of sparsity via the nonnegative Least Absolute Shrinkage and Selection Operator (LASSO) penalty.\n\nYour tasks:\n1. Starting strictly from the base definitions above, derive the gradient of the smooth term with respect to $s$, the Lipschitz constant of that gradient, and the proximal operator corresponding to the nonnegativity-constrained $\\ell_1$ penalty. Use these derivations to design a first-order method with Nesterov acceleration, namely the Fast Iterative Shrinkage-Thresholding Algorithm (FISTA), to minimize the objective over $s \\ge 0$.\n2. Implement the derived algorithm in code with the following numerical prescriptions:\n   - Use a fixed step size equal to the reciprocal of the Lipschitz constant of the gradient of the smooth term.\n   - Initialize at $s^{(0)} = 0$ and use standard Nesterov acceleration for iterates.\n   - Use a termination criterion based on the relative $\\ell_2$-change between successive iterates: stop when $\\lVert s^{(k)} - s^{(k-1)} \\rVert_2 / \\max\\{1,\\lVert s^{(k-1)} \\rVert_2\\} \\le \\tau$, where $\\tau$ is a tolerance.\n   - Impose nonnegativity and $\\ell_1$ regularization via the appropriate proximal operator at each iteration.\n3. For each test case below, construct $G$ from $\\alpha$ and $T$, construct the ground-truth $s_{\\mathrm{true}}$, construct $y = G s_{\\mathrm{true}} + \\varepsilon$, run your solver to obtain $\\hat{s}$, and report the mean absolute error $\\mathrm{MAE} = \\frac{1}{T} \\sum_{t=0}^{T-1} | \\hat{s}_t - s_{\\mathrm{true},t} |$ as a floating-point number rounded to six decimals.\n\nUse the following deterministic test suite (all angles mentioned below are in radians):\n- Test A (happy path, exact model match):\n  - Length $T = 60$, decay factor $\\alpha = 0.95$, regularization $\\lambda = 0.001$, tolerance $\\tau = 10^{-9}$.\n  - Ground-truth spikes $s_{\\mathrm{true}}$ are zero everywhere except $s_{\\mathrm{true},5} = 1.0$, $s_{\\mathrm{true},20} = 0.5$, $s_{\\mathrm{true},40} = 1.5$.\n  - Disturbance $\\varepsilon_t = 0$ for all $t$.\n- Test B (burst with structured disturbance):\n  - Length $T = 80$, decay factor $\\alpha = 0.9$, regularization $\\lambda = 0.1$, tolerance $\\tau = 10^{-9}$.\n  - Ground-truth spikes $s_{\\mathrm{true}}$ are zero everywhere except $s_{\\mathrm{true},10} = 0.3$, $s_{\\mathrm{true},11} = 0.3$, $s_{\\mathrm{true},12} = 0.3$.\n  - Disturbance $\\varepsilon_t = 0.02 \\cos\\!\\big(2\\pi t / 11\\big)$ for $t \\in \\{0,\\dots,79\\}$.\n- Test C (no spikes, strong regularization, tiny disturbance):\n  - Length $T = 50$, decay factor $\\alpha = 0.98$, regularization $\\lambda = 0.2$, tolerance $\\tau = 10^{-9}$.\n  - Ground-truth spikes $s_{\\mathrm{true}}$ are all zero.\n  - Disturbance $\\varepsilon_t = 0.001 \\left[\\sin\\!\\big(2\\pi t / 7\\big) + 0.5 \\sin\\!\\big(2\\pi t / 3\\big)\\right]$ for $t \\in \\{0,\\dots,49\\}$.\n\nYour program must:\n- Implement the solver once and reuse it across the three test cases.\n- For each test case compute the mean absolute error defined above and round it to six decimals.\n- Produce a single line of output containing the three results as a comma-separated list enclosed in square brackets, in the order A, B, C. For example, your program should output on one line a value like $[0.000123,0.045678,0.000000]$ (this is an example only; compute the actual values).",
            "solution": "The problem is valid as it presents a well-posed, scientifically grounded, and self-contained task in computational neuroscience and signal processing. It requires the application of standard convex optimization techniques to a linear inverse problem. All models, parameters, and test cases are defined with mathematical precision and without ambiguity.\n\nThe objective is to estimate a non-negative spike train $s \\in \\mathbb{R}_{\\ge 0}^{T}$ from an observed fluorescence time series $y \\in \\mathbb{R}^{T}$. The problem is formulated as the following convex optimization problem:\n$$\n\\underset{s \\ge 0}{\\text{minimize}} \\quad f(s) = \\frac{1}{2} \\lVert G s - y \\rVert_2^2 + \\lambda \\lVert s \\rVert_1\n$$\nwhere $G$ is the convolution matrix representing the calcium dynamics, and $\\lambda > 0$ is a regularization parameter that promotes sparsity in the estimated spike train $s$.\n\nThis problem is solved using the Fast Iterative Shrinkage-Thresholding Algorithm (FISTA), a first-order proximal gradient method well-suited for composite objective functions of the form $f(s) = L(s) + R(s)$, where $L(s)$ is a smooth convex function and $R(s)$ is a convex (possibly non-smooth) function.\n\nFor our problem, we define:\n- The smooth component (data fidelity term): $L(s) = \\frac{1}{2} \\lVert G s - y \\rVert_2^2$.\n- The non-smooth component (regularizer and constraint): $R(s) = \\lambda \\lVert s \\rVert_1 + I_+(s)$, where $I_+(s)$ is the indicator function for the non-negative orthant, which is $0$ if $s \\ge 0$ (component-wise) and $\\infty$ otherwise. This term enforces both sparsity through the $\\ell_1$-norm and non-negativity of the spike train.\n\nThe FISTA algorithm requires three key components derived from this formulation: the gradient of the smooth term, the Lipschitz constant of this gradient, and the proximal operator of the non-smooth term.\n\n1.  **Gradient of the Smooth Term, $\\nabla L(s)$**\n    The smooth term is a standard least-squares objective. Its gradient with respect to $s$ is derived as follows:\n    $$\n    L(s) = \\frac{1}{2} (Gs - y)^\\top (Gs - y) = \\frac{1}{2} (s^\\top G^\\top G s - 2 y^\\top G s + y^\\top y)\n    $$\n    Taking the derivative with respect to the vector $s$ yields:\n    $$\n    \\nabla L(s) = G^\\top G s - G^\\top y = G^\\top(Gs - y)\n    $$\n\n2.  **Lipschitz Constant of the Gradient, $K$**\n    The FISTA algorithm's convergence is guaranteed if the step size is chosen appropriately. A common choice is the reciprocal of the Lipschitz constant of $\\nabla L(s)$. For a function with a continuous second derivative, the Lipschitz constant is the maximum norm of its Hessian. The Hessian of $L(s)$ is:\n    $$\n    \\nabla^2 L(s) = G^\\top G\n    $$\n    The Lipschitz constant $K$ is the largest eigenvalue, $\\lambda_{\\max}$, of this positive semidefinite matrix $G^\\top G$. This is equivalent to the squared largest singular value, $\\sigma_{\\max}$, of the matrix $G$.\n    $$\n    K = \\lambda_{\\max}(G^\\top G) = \\sigma_{\\max}(G)^2\n    $$\n    The step size for the gradient descent updates will be fixed at $\\gamma = 1/K$.\n\n3.  **Proximal Operator of the Non-Smooth Term, $\\text{prox}_{\\gamma R}(v)$**\n    The proximal operator of $\\gamma R(s)$ is defined as:\n    $$\n    \\text{prox}_{\\gamma R}(v) = \\underset{s}{\\text{argmin}} \\left( \\frac{1}{2} \\lVert s - v \\rVert_2^2 + \\gamma R(s) \\right)\n    $$\n    Substituting $R(s) = \\lambda \\lVert s \\rVert_1 + I_+(s)$, we get:\n    $$\n    \\text{prox}_{\\gamma R}(v) = \\underset{s \\ge 0}{\\text{argmin}} \\left( \\frac{1}{2} \\lVert s - v \\rVert_2^2 + \\gamma \\lambda \\lVert s \\rVert_1 \\right)\n    $$\n    This problem is separable and can be solved for each component $s_i$ independently:\n    $$\n    \\underset{s_i \\ge 0}{\\text{argmin}} \\left( \\frac{1}{2} (s_i - v_i)^2 + \\gamma \\lambda s_i \\right)\n    $$\n    The objective is a parabola in $s_i$ with its minimum at $s_i = v_i - \\gamma \\lambda$. Since we have the constraint $s_i \\ge 0$, the solution is found by projecting this minimum onto the non-negative half-line. If $v_i - \\gamma \\lambda > 0$, the minimum is at $s_i = v_i - \\gamma \\lambda$. If $v_i - \\gamma \\lambda \\le 0$, the objective is increasing for all $s_i \\ge 0$, so the minimum occurs at the boundary, $s_i = 0$. This can be written compactly as:\n    $$\n    s_i = \\max(0, v_i - \\gamma \\lambda)\n    $$\n    This operation is equivalent to a soft-thresholding followed by a projection onto the non-negative orthant.\n\nWith these components, the FISTA algorithm is implemented as follows:\n\n**Algorithm: Fast Iterative Shrinkage-Thresholding Algorithm (FISTA)**\n\n1.  **Initialization**:\n    - Iteration counter $k=1$.\n    - Spike estimates $s^{(0)} = \\mathbf{0}$, $s^{(-1)} = \\mathbf{0}$.\n    - Auxiliary sequence $z^{(1)} = s^{(0)}$.\n    - Momentum sequence $t_1 = 1$.\n    - Step size $\\gamma = 1/K = 1/\\sigma_{\\max}(G)^2$.\n\n2.  **Iteration Loop (for $k=1, 2, \\dots$)**:\n    a. Compute the gradient at the auxiliary point $z^{(k)}$: $\\nabla_k = G^\\top(G z^{(k)} - y)$.\n    b. Perform a gradient step: $v^{(k)} = z^{(k)} - \\gamma \\nabla_k$.\n    c. Apply the proximal operator to find the next spike estimate $s^{(k)}$: $s^{(k)}_i = \\max(0, v^{(k)}_i - \\gamma \\lambda)$ for each component $i$.\n    d. Check for convergence: Stop if $\\lVert s^{(k)} - s^{(k-1)} \\rVert_2 / \\max(1, \\lVert s^{(k-1)} \\rVert_2) \\le \\tau$.\n    e. Update the momentum term: $t_{k+1} = \\frac{1 + \\sqrt{1 + 4 t_k^2}}{2}$.\n    f. Update the auxiliary sequence for the next iteration: $z^{(k+1)} = s^{(k)} + \\frac{t_k - 1}{t_{k+1}}(s^{(k)} - s^{(k-1)})$.\n    g. Set $s^{(k-1)} \\leftarrow s^{(k)}$, $t_k \\leftarrow t_{k+1}$, and increment $k$.\n\n3.  **Output**: The final estimate $\\hat{s} = s^{(k)}$.\n\nThis algorithm is implemented for each test case. The convolution matrix $G$ is constructed using its definition as a lower-triangular Toeplitz matrix. The Lipschitz constant $K$ is computed by finding the largest singular value of $G$. The solver then runs until the specified tolerance $\\tau$ is met. Finally, the Mean Absolute Error (MAE) between the estimated spike train $\\hat{s}$ and the ground-truth $s_{\\mathrm{true}}$ is calculated.",
            "answer": "```python\nimport numpy as np\nfrom scipy.linalg import toeplitz, svd\n\ndef fista_solver(G, y, lam, tau, K):\n    \"\"\"\n    Solves the non-negative LASSO problem using FISTA.\n\n    min_s 0.5 * ||Gs - y||_2^2 + lam * ||s||_1  subject to s = 0.\n\n    Args:\n        G (np.ndarray): The forward model matrix.\n        y (np.ndarray): The observed data vector.\n        lam (float): The regularization parameter.\n        tau (float): The convergence tolerance.\n        K (float): The Lipschitz constant of the gradient of the smooth term.\n\n    Returns:\n        np.ndarray: The estimated spike train s_hat.\n    \"\"\"\n    T = G.shape[0]\n    \n    # Initialization\n    s_prev = np.zeros(T)\n    z = np.zeros(T)\n    t_prev = 1.0\n\n    # Pre-compute G transpose for efficiency\n    GT = G.T\n    \n    # Fixed step size\n    step_size = 1.0 / K\n    \n    # Set a maximum number of iterations as a safeguard\n    max_iter = 200000 \n    \n    for _ in range(max_iter):\n        # Compute gradient at the auxiliary point z\n        grad_z = GT @ (G @ z - y)\n        \n        # Perform gradient descent step from z\n        v = z - step_size * grad_z\n        \n        # Apply proximal operator to get the current estimate s_curr\n        s_curr = np.maximum(0, v - step_size * lam)\n        \n        # Check for convergence using the specified criterion\n        norm_s_prev = np.linalg.norm(s_prev)\n        rel_diff = np.linalg.norm(s_curr - s_prev) / max(1.0, norm_s_prev)\n        \n        if rel_diff  tau:\n            break\n            \n        # Nesterov acceleration update\n        t_curr = (1.0 + np.sqrt(1.0 + 4.0 * t_prev**2)) / 2.0\n        z = s_curr + ((t_prev - 1.0) / t_curr) * (s_curr - s_prev)\n        \n        # Update variables for the next iteration\n        s_prev = s_curr\n        t_prev = t_curr\n        \n    return s_curr\n\ndef solve():\n    \"\"\"\n    Main function to run the test cases and print the results.\n    \"\"\"\n    \n    # --- Test Case A: Happy path, exact model match ---\n    T_A = 60\n    alpha_A = 0.95\n    lambda_A = 0.001\n    tau_A = 1e-9\n    s_true_A = np.zeros(T_A)\n    s_true_A[5] = 1.0\n    s_true_A[20] = 0.5\n    s_true_A[40] = 1.5\n    epsilon_A = np.zeros(T_A)\n    \n    # --- Test Case B: Burst with structured disturbance ---\n    T_B = 80\n    alpha_B = 0.9\n    lambda_B = 0.1\n    tau_B = 1e-9\n    s_true_B = np.zeros(T_B)\n    s_true_B[10:13] = 0.3\n    t_vals_B = np.arange(T_B)\n    epsilon_B = 0.02 * np.cos(2 * np.pi * t_vals_B / 11)\n    \n    # --- Test Case C: No spikes, strong regularization, tiny disturbance ---\n    T_C = 50\n    alpha_C = 0.98\n    lambda_C = 0.2\n    tau_C = 1e-9\n    s_true_C = np.zeros(T_C)\n    t_vals_C = np.arange(T_C)\n    epsilon_C = 0.001 * (np.sin(2 * np.pi * t_vals_C / 7) + 0.5 * np.sin(2 * np.pi * t_vals_C / 3))\n    \n    test_cases = [\n        (T_A, alpha_A, lambda_A, tau_A, s_true_A, epsilon_A),\n        (T_B, alpha_B, lambda_B, tau_B, s_true_B, epsilon_B),\n        (T_C, alpha_C, lambda_C, tau_C, s_true_C, epsilon_C)\n    ]\n    \n    results = []\n    \n    for T, alpha, lam, tau, s_true, epsilon in test_cases:\n        # 1. Construct the convolution matrix G\n        g_first_col = alpha**np.arange(T)\n        g_first_row = np.zeros(T)\n        g_first_row[0] = 1.0\n        G = toeplitz(g_first_col, g_first_row)\n        \n        # 2. Compute the Lipschitz constant K\n        singular_values = svd(G, compute_uv=False)\n        K = singular_values[0]**2\n        \n        # 3. Construct the observed fluorescence y\n        y = G @ s_true + epsilon\n        \n        # 4. Run the solver to obtain the spike estimate s_hat\n        s_hat = fista_solver(G, y, lam, tau, K)\n        \n        # 5. Compute the Mean Absolute Error (MAE)\n        mae = np.mean(np.abs(s_hat - s_true))\n        results.append(f\"{mae:.6f}\")\n        \n    # Print the final results in the specified format\n    print(f\"[{','.join(results)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "While standard deconvolution models are powerful, their performance can be enhanced by incorporating prior knowledge about neural firing patterns. This practice moves beyond simple sparsity priors to model more complex, biophysically plausible structures like bursting and refractory periods within a Maximum A Posteriori (MAP) framework. You will implement an exact solution using dynamic programming, which is made possible by the model's specific structure, providing a contrast to the iterative methods used for less constrained problems. This exercise demonstrates how to translate biological constraints into a mathematical prior to improve inference.",
            "id": "4154477",
            "problem": "You are given a one-dimensional time series representing a fluorescent calcium signal modeled by a linear dynamical system arising from spike-evoked calcium transients. The generative model is defined on discrete time samples with fixed sampling interval in seconds and known parameters. The task is to compute a Maximum A Posteriori (MAP) estimate of a constrained spike train under a refractory constraint and a bursting prior, and to output the set of spike sample indices for multiple specified test cases.\n\nFundamental base and data model:\n- Let $t \\in \\{0,1,\\dots,T-1\\}$ denote discrete time samples separated by a sampling interval $\\Delta t$ (in seconds).\n- Let $s_t$ denote a spike train at sample $t$. In this problem, $s_t$ is constrained to be either $0$ or a fixed amplitude $a > 0$.\n- Calcium dynamics are modeled as a linear system with impulse response kernel $h_k = \\alpha \\gamma^k$ for $k \\in \\{0,1,\\dots,K-1\\}$, where $\\alpha > 0$ is the instantaneous calcium increment per spike and $\\gamma \\in (0,1)$ is the discrete-time decay factor derived from the calcium decay time constant $\\tau_c$ via $\\gamma = \\exp(-\\Delta t / \\tau_c)$.\n- The predicted fluorescence is the discrete convolution $(h * s)_t = \\sum_{k=0}^{K-1} h_k s_{t-k}$ where indices below $0$ are treated as zero.\n- The observed fluorescence $y_t$ is modeled as $y_t = (h * s)_t + \\varepsilon_t$, where $\\varepsilon_t$ are independent Gaussian noise samples with zero mean and variance $\\sigma^2$.\n\nStructured prior with refractory constraint and bursting preference:\n- A refractory period of $r$ samples is enforced between the starts of any two bursts, with $r \\ge K$, ensuring that the support of the impulse responses from distinct bursts do not overlap in time.\n- The spike train $s_t$ is restricted to be a union of bursts, where a burst is defined as a contiguous block of spike samples at amplitude $a$ of length $L \\in \\{L_{\\min}, \\dots, L_{\\max}\\}$. Within a burst, $s_t = a$ on the burst interval and $s_t = 0$ outside.\n- The negative log-prior cost is defined as $\\lambda \\sum_t \\mathbf{1}[s_t = a] - \\rho \\sum_t \\mathbf{1}[s_t = a, s_{t+1} = a]$, where $\\lambda \\ge 0$ penalizes the total number of spike samples and $\\rho \\ge 0$ provides a discount for adjacent spike pairs to prefer longer contiguous bursts.\n\nMAP objective:\n- Given $y_t$, the MAP estimate minimizes the objective\n$$\nJ(s) = \\frac{1}{2 \\sigma^2} \\sum_{t=0}^{T-1} \\left( y_t - (h * s)_t \\right)^2 \\;+\\; \\lambda \\sum_{t=0}^{T-1} \\mathbf{1}[s_t=a] \\;-\\; \\rho \\sum_{t=0}^{T-2} \\mathbf{1}[s_t=a, s_{t+1}=a],\n$$\nsubject to the refractory constraint and burst structure described above, and $s_t \\in \\{0,a\\}$.\n\nAlgorithmic requirement:\n- Because $r \\ge K$, the contributions of distinct bursts to the likelihood do not overlap in time. You must implement an exact dynamic program over the timeline that, at each position $t$, either selects a burst starting at $t$ of some length $L \\in [L_{\\min}, L_{\\max}]$ or selects a single-sample gap (no spike at $t$), accruing the appropriate likelihood cost and prior cost, and advancing the time index accordingly. When a burst is selected, the next possible burst start index is $t + L + r$. When a gap is selected, the next index is $t + 1$. The likelihood cost for a burst of length $L$ starting at $t$ is computed over its coverage window of length $W = \\min(L + K - 1, T - t)$ as the residual sum of squares between $y_t$ and the predicted convolution of that burst. You must also add the noise-only cost for any gap samples between the end of the coverage window and the next allowed start time imposed by the refractory period. Use Gaussian negative log-likelihood scaling by $\\frac{1}{2 \\sigma^2}$.\n\nOutput specification:\n- For each test case, output the estimated spike sample indices as a list of integers in ascending order, where each integer is a sample index $t$ such that $s_t = a$ in the MAP solution. Combine the results from all test cases into a single line of output containing the results as a comma-separated list enclosed in square brackets. For example, a valid output format is \"[[i_1,i_2,...],[j_1,j_2,...],...]\". All indices are sample indices (dimensionless integers). No physical unit conversion is required in the final answer.\n\nTest suite:\nYou must implement your program to solve the following four test cases. In each case, you must:\n1. Construct the kernel $h_k = \\alpha \\gamma^k$ with the provided $K$.\n2. Simulate $y_t$ by generating $s_t$ from the specified ground-truth bursts and convolving with $h_k$, then add independent Gaussian noise with standard deviation $\\sigma$.\n3. Run the dynamic program with the given parameters to compute the MAP estimate and report the spike sample indices.\n\nTest Case 1 (happy path):\n- $T = 80$, $\\Delta t = 0.1$ seconds, $\\tau_c = 0.7$ seconds, $\\alpha = 1.0$, $K = 12$, $a = 0.8$, $\\sigma = 0.05$, refractory $r = 12$, $\\lambda = 0.2$, $\\rho = 0.1$, $L_{\\min} = 2$, $L_{\\max} = 6$.\n- Ground-truth bursts: starts and lengths $(10,3)$, $(35,4)$, $(60,2)$.\n\nTest Case 2 (no prior influence):\n- $T = 80$, $\\Delta t = 0.1$ seconds, $\\tau_c = 0.7$ seconds, $\\alpha = 1.0$, $K = 12$, $a = 0.8$, $\\sigma = 0.08$, refractory $r = 12$, $\\lambda = 0.0$, $\\rho = 0.0$, $L_{\\min} = 1$, $L_{\\max} = 5$.\n- Ground-truth bursts: $(20,2)$, $(50,3)$.\n\nTest Case 3 (bursting prior dominates):\n- $T = 100$, $\\Delta t = 0.1$ seconds, $\\tau_c = 1.0$ seconds, $\\alpha = 1.0$, $K = 10$, $a = 0.7$, $\\sigma = 0.06$, refractory $r = 10$, $\\lambda = 0.5$, $\\rho = 0.45$, $L_{\\min} = 1$, $L_{\\max} = 8$.\n- Ground-truth bursts: $(15,6)$, $(40,1)$, $(70,5)$.\n\nTest Case 4 (boundary and higher noise):\n- $T = 30$, $\\Delta t = 0.1$ seconds, $\\tau_c = 0.5$ seconds, $\\alpha = 1.0$, $K = 8$, $a = 0.9$, $\\sigma = 0.15$, refractory $r = 8$, $\\lambda = 0.15$, $\\rho = 0.05$, $L_{\\min} = 1$, $L_{\\max} = 4$.\n- Ground-truth burst: $(5,3)$.\n\nAngle units are not applicable. Express all time-related quantities internally in samples; the final outputs are sample indices as integers. Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, in the exact format described above.",
            "solution": "The problem requires the computation of a Maximum A Posteriori (MAP) estimate of a spike train from a noisy fluorescent calcium signal. The underlying model is a linear dynamical system where the signal is a convolution of the spike train with an exponential decay kernel, corrupted by additive Gaussian noise. The spike train is structured into bursts of specific lengths, with a refractory period enforced between bursts. The MAP objective function combines a Gaussian likelihood term with a structured prior that penalizes the total number of spikes but rewards contiguous spikes forming bursts.\n\nFirst, we validate the problem statement. All parameters for the model and the optimization are explicitly provided for each of four test cases. The model itself, based on linear systems theory and Bayesian estimation (MAP), is standard in computational neuroscience. The algorithmic requirement to use dynamic programming is well-defined and feasible due to the key constraint that the refractory period $r$ is no shorter than the kernel length $K$ ($r \\ge K$). This constraint ensures that the calcium transients from different inferred bursts do not overlap in time, making the likelihood term separable over disjoint time intervals corresponding to each burst and the gaps between them. The problem is scientifically grounded, self-contained, and well-posed. Thus, the problem is deemed valid.\n\nThe solution proceeds by implementing an exact dynamic programming (DP) algorithm. Let $V(t)$ be the minimum cost (negative log-posterior) for the observed signal $y$ on the time interval $[t, T-1]$, where $T$ is the total number of samples. Our goal is to find the spike train that corresponds to $V(0)$. We can compute $V(t)$ recursively by working backwards in time from $t = T-1$ down to $0$. The base case is $V(t) = 0$ for all $t \\ge T$.\n\nFor any time $t  T$, we have two choices:\n1.  **There is no spike burst starting at $t$**. This corresponds to a single-sample gap. In this case, we assume the spike value $s_t=0$. The predicted signal at $t$ is $0$. The cost incurred is the negative log-likelihood of observing $y_t$ given a signal of $0$, which is $\\frac{1}{2\\sigma^2} y_t^2$. The total cost for this choice is this one-sample cost plus the minimum cost for the rest of the signal, $V(t+1)$.\n    $$V_{\\text{gap}}(t) = \\frac{1}{2\\sigma^2} y_t^2 + V(t+1)$$\n\n2.  **A burst of length $L$ starts at $t$**, where $L \\in [L_{\\min}, L_{\\max}]$. For this choice to be valid, the burst must end within the time series, i.e., $t+L \\le T$. The total cost for this choice is the sum of three components:\n    a.  **Prior Cost**: The prior term for a burst of length $L$ with amplitude $a$ is $\\lambda \\sum \\mathbf{1}[s_t=a] - \\rho \\sum \\mathbf{1}[s_t=a, s_{t+1}=a]$. This evaluates to $\\lambda L - \\rho(L-1)$.\n    b.  **Likelihood Cost**: Due to the $r \\ge K$ condition, the cost separates.\n        i.   *Burst-related cost*: We calculate the residual sum of squares between the observed signal $y_t$ and the predicted signal from this single burst over its full \"coverage window\". A burst starting at $t$ of length $L$ has an effect lasting until time $t+L+K-2$. Let $W = \\min(L+K-1, T-t)$ be the effective length of this window. The cost is $\\frac{1}{2\\sigma^2} \\sum_{k=0}^{W-1} (y_{t+k} - c_{t+k}^{\\text{burst}})^2$, where $c^{\\text{burst}}$ is the convolution of the single burst with the kernel $h$.\n        ii.  *Refractory gap cost*: The refractory period $r$ forces a gap of zeros after the burst. The next possible burst can only start at $t' = t+L+r$. The time interval between the end of the current burst's coverage window and the start of the next decision point comprises samples that are constrained to have no spikes. The cost for this enforced gap is the noise-only likelihood: $\\frac{1}{2\\sigma^2} \\sum_{k=t+W}^{t'-1} y_k^2$.\n    c.  **Future Cost**: The cost of the optimal solution for the remainder of the signal starting from the next decision point, which is $V(t' = t+L+r)$.\n\nThe recurrence relation for the DP is:\n$$V(t) = \\min \\left( V_{\\text{gap}}(t), \\min_{L \\in [L_{\\min}, L_{\\max}], t+L \\le T} V_{\\text{burst}}(t, L) \\right)$$\nwhere $V_{\\text{burst}}(t, L)$ encapsulates the three cost components described for a burst of length $L$ starting at $t$.\n\nTo implement this efficiently, we first simulate the noisy signal $y_t$ for each test case as described. Then, for the DP, we pre-compute helper quantities: the kernel $h_k=\\alpha\\gamma^k$, the scaled squared signal $\\frac{1}{2\\sigma^2} y_t^2$, its cumulative sum for rapid gap cost calculation, and the predicted fluorescence signals for bursts of each possible length $L$. We then fill a DP table storing the costs $V(t)$ and another table storing the optimal choice (gap or burst length $L$) for each $t$.\n\nAfter filling the tables from $t=T-1$ down to $0$, we perform a backtracking pass starting from $t=0$. We follow the stored optimal choices to reconstruct the sequence of bursts. If the choice at time $t$ was a burst of length $L$, we add the indices $[t, t+1, \\dots, t+L-1]$ to our solution set and jump to the next decision point $t' = t+L+r$. If the choice was a gap, we simply advance to $t+1$. This process yields the final set of decoded spike indices.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to run all test cases and print the final results.\n    \"\"\"\n    # Use a fixed seed for the random number generator to ensure that the\n    # simulated noisy calcium traces are reproducible.\n    np.random.seed(0)\n\n    # Define test cases as a list of dictionaries.\n    test_cases = [\n        {\n            \"T\": 80, \"dt\": 0.1, \"tau_c\": 0.7, \"alpha\": 1.0, \"K\": 12, \"a\": 0.8,\n            \"sigma\": 0.05, \"r\": 12, \"lam\": 0.2, \"rho\": 0.1, \"L_min\": 2, \"L_max\": 6,\n            \"ground_truth_bursts\": [(10, 3), (35, 4), (60, 2)]\n        },\n        {\n            \"T\": 80, \"dt\": 0.1, \"tau_c\": 0.7, \"alpha\": 1.0, \"K\": 12, \"a\": 0.8,\n            \"sigma\": 0.08, \"r\": 12, \"lam\": 0.0, \"rho\": 0.0, \"L_min\": 1, \"L_max\": 5,\n            \"ground_truth_bursts\": [(20, 2), (50, 3)]\n        },\n        {\n            \"T\": 100, \"dt\": 0.1, \"tau_c\": 1.0, \"alpha\": 1.0, \"K\": 10, \"a\": 0.7,\n            \"sigma\": 0.06, \"r\": 10, \"lam\": 0.5, \"rho\": 0.45, \"L_min\": 1, \"L_max\": 8,\n            \"ground_truth_bursts\": [(15, 6), (40, 1), (70, 5)]\n        },\n        {\n            \"T\": 30, \"dt\": 0.1, \"tau_c\": 0.5, \"alpha\": 1.0, \"K\": 8, \"a\": 0.9,\n            \"sigma\": 0.15, \"r\": 8, \"lam\": 0.15, \"rho\": 0.05, \"L_min\": 1, \"L_max\": 4,\n            \"ground_truth_bursts\": [(5, 3)]\n        }\n    ]\n\n    all_results = []\n    for params in test_cases:\n        spikes = run_deconvolution_case(params)\n        all_results.append(spikes)\n\n    # Format the final output string as specified: [[i_1,i_2,...],[j_1,j_2,...],...]\n    output_str = f\"[{','.join([f'[{\",\".join(map(str, res))}]' for res in all_results])}]\"\n    print(output_str)\n\ndef simulate_signal(T, dt, tau_c, alpha, K, a, sigma, ground_truth_bursts):\n    \"\"\"\n    Generates a noisy calcium signal based on the generative model.\n    \"\"\"\n    # Construct spike train s_t from ground-truth bursts\n    s = np.zeros(T)\n    for start, length in ground_truth_bursts:\n        if start + length = T:\n            s[start:start + length] = a\n\n    # Construct impulse response kernel h_k\n    gamma = np.exp(-dt / tau_c)\n    k = np.arange(K)\n    h = alpha * (gamma ** k)\n\n    # Compute clean fluorescence signal by convolution\n    c = np.convolve(h, s)[:T]\n\n    # Generate and add Gaussian noise\n    noise = np.random.normal(0, sigma, T)\n    y = c + noise\n    return y\n\ndef run_deconvolution_case(params):\n    \"\"\"\n    Solves the MAP estimation problem for a single test case.\n    \"\"\"\n    # Unpack parameters\n    T = params[\"T\"]; dt = params[\"dt\"]; tau_c = params[\"tau_c\"]; alpha = params[\"alpha\"]\n    K = params[\"K\"]; a = params[\"a\"]; sigma = params[\"sigma\"]; r = params[\"r\"]\n    lam = params[\"lam\"]; rho = params[\"rho\"]; L_min = params[\"L_min\"]; L_max = params[\"L_max\"]\n    ground_truth_bursts = params[\"ground_truth_bursts\"]\n\n    # 1. Simulate the observed fluorescence signal y_t\n    y = simulate_signal(T, dt, tau_c, alpha, K, a, sigma, ground_truth_bursts)\n\n    # 2. Pre-computation for the dynamic programming algorithm\n    gamma = np.exp(-dt / tau_c)\n    k = np.arange(K)\n    h = alpha * (gamma ** k)\n    cost_scale = 1.0 / (2.0 * sigma**2)\n    y_sq_cumsum = np.zeros(T + 1)\n    y_sq_cumsum[1:] = np.cumsum(y**2)\n\n    burst_responses = {}\n    for L in range(L_min, L_max + 1):\n        s_burst = np.zeros(L + K - 1)\n        s_burst[:L] = a\n        burst_responses[L] = np.convolve(h, s_burst)[:L + K - 1]\n\n    # 3. Dynamic Programming to find the MAP estimate\n    dp_cost = np.full(T + 1, np.inf)\n    dp_choices = np.zeros(T, dtype=int)\n    dp_cost[T] = 0.0\n\n    for t in range(T - 1, -1, -1):\n        # Option 1: Place a gap (no spike) at time t\n        cost_gap = cost_scale * y[t]**2 + dp_cost[t + 1]\n        min_cost = cost_gap\n        best_choice = 0\n\n        # Option 2: Place a burst of length L starting at time t\n        for L in range(L_min, L_max + 1):\n            if t + L > T:\n                continue\n\n            prior_cost = lam * L - (rho * (L - 1) if L > 1 else 0)\n\n            c_burst = burst_responses[L]\n            W = min(L + K - 1, T - t)\n            y_window = y[t : t + W]\n            c_window = c_burst[:W]\n            ll_burst = cost_scale * np.sum((y_window - c_window)**2)\n\n            t_next = t + L + r\n            \n            gap_start_idx = t + W\n            gap_end_idx = min(t_next, T)\n            ll_refractory_gap = 0.0\n            if gap_start_idx  gap_end_idx:\n                ll_refractory_gap = cost_scale * (y_sq_cumsum[gap_end_idx] - y_sq_cumsum[gap_start_idx])\n            \n            future_cost = dp_cost[min(t_next, T)]\n            cost_burst = prior_cost + ll_burst + ll_refractory_gap + future_cost\n\n            if cost_burst  min_cost:\n                min_cost = cost_burst\n                best_choice = L\n        \n        dp_cost[t] = min_cost\n        dp_choices[t] = best_choice\n\n    # 4. Backtracking to reconstruct the optimal spike train\n    spike_indices = []\n    current_t = 0\n    while current_t  T:\n        choice = dp_choices[current_t]\n        if choice == 0:  # Gap\n            current_t += 1\n        else:  # Burst of length L = choice\n            L = choice\n            spike_indices.extend(range(current_t, current_t + L))\n            current_t += L + r\n    \n    return spike_indices\n\nsolve()\n```"
        },
        {
            "introduction": "A critical challenge in calcium imaging is its limited temporal resolution, as the measurement process integrates fluorescence over time, obscuring the precise moment of a spike. This advanced exercise tackles the problem of achieving \"super-resolution\" timingâ€”estimating spike times with a precision greater than the imaging frame rate. You will derive an exact forward model by analytically integrating the continuous-time calcium dynamics, and then use it to infer spike times with sub-frame accuracy. This practice illustrates how a meticulous physical model of the measurement process can help overcome the apparent limitations of the hardware.",
            "id": "4154469",
            "problem": "You are given a continuous-time generative model for calcium fluorescence driven by neuronal spikes and a frame-averaged measurement process. The latent intracellular calcium concentration is modeled by the linear time-invariant ordinary differential equation\n$$\n\\frac{d c(t)}{d t} = -\\frac{1}{\\tau} c(t) + \\alpha\\, s(t),\n$$\nwhere $c(t)$ is calcium concentration, $s(t)$ is the spike train modeled as a sum of Dirac impulses at unknown spike times, $\\tau$ is the calcium decay time constant, and $\\alpha$ is the instantaneous jump in $c(t)$ per spike. The imaging system integrates $c(t)$ over frames of duration $\\Delta$ seconds and returns the frame-averaged fluorescence\n$$\ny_k = \\frac{1}{\\Delta} \\int_{k\\Delta}^{(k+1)\\Delta} c(t) \\, dt + \\eta_k,\n$$\nfor frame index $k \\in \\{0,1,\\dots, K-1\\}$, with additive zero-mean Gaussian noise $\\eta_k$ having known standard deviation $\\sigma$.\n\nYour task is to achieve timing super-resolution within frames by assuming a uniform sub-frame grid with $R$ sub-bins per frame, giving a sub-bin duration $\\delta = \\Delta / R$. Let the total number of frames be $K$, so the total number of sub-bins is $N = K R$, and define sub-bin times $t_n = n \\delta$ for $n \\in \\{0,1,\\dots,N-1\\}$. Assume spikes occur on this sub-bin grid. Starting from the calcium dynamics differential equation and the frame-averaged measurement definition above, derive the exact linear forward operator that maps a nonnegative sub-bin spike vector of length $N$ to the $K$ frame-averaged fluorescence samples by analytically integrating the impulse response over each frame.\n\nImplement a program that:\n- Constructs the forward operator exactly from the analytical integral implied by the model, without making any discrete-time Euler approximations.\n- Simulates $y_k$ for each test case by multiplying the forward operator with the ground-truth sub-bin spike vector and adding independent Gaussian noise with the specified $\\sigma$.\n- Estimates the nonnegative sub-bin spike amplitudes by solving a Non-Negative Least Squares (NNLS) problem, i.e., minimize the squared error subject to nonnegativity.\n- Detects spike times by thresholding the estimated sub-bin amplitudes with a fixed threshold equal to $\\max(\\alpha/2, 3\\sigma)$ and selecting only local maxima on the sub-bin lattice to avoid multiple detections per spike. Refine each detected spike time by fitting a local parabola to the three-point neighborhood around the local maximum and using the vertex location to estimate a sub-bin offset within $[-\\delta/2, \\delta/2]$ whenever both neighbors exist; otherwise, use the sub-bin center. Express all reported spike times in seconds.\n- Outputs, for each test case, the list of estimated spike times in seconds, sorted in ascending order and rounded to $4$ decimal places.\n\nPhysical units and output specification:\n- Time must be expressed in seconds and rounded to $4$ decimal places.\n- Fluorescence amplitude is in arbitrary units (a.u.), but only spike times are to be output.\n\nTest suite:\nUse the following four scientifically plausible test cases, each describing $(\\Delta, \\tau, \\alpha, R, K, \\sigma)$ and the ground-truth spike times in seconds. All given spike times lie on the corresponding sub-bin grid.\n\n- Case $1$ (happy path): $\\Delta = 0.1$ seconds, $\\tau = 0.8$ seconds, $\\alpha = 1.0$ a.u., $R = 5$, $K = 25$, $\\sigma = 0.02$ a.u., ground truth spikes at $[1.22]$ seconds.\n- Case $2$ (boundary condition at frame edge): $\\Delta = 0.1$ seconds, $\\tau = 1.0$ seconds, $\\alpha = 1.0$ a.u., $R = 8$, $K = 20$, $\\sigma = 0.05$ a.u., ground truth spikes at $[1.0]$ seconds.\n- Case $3$ (two spikes within one frame): $\\Delta = 0.1$ seconds, $\\tau = 0.5$ seconds, $\\alpha = 1.0$ a.u., $R = 10$, $K = 15$, $\\sigma = 0.01$ a.u., ground truth spikes at $[0.62, 0.66]$ seconds.\n- Case $4$ (no spikes, noise-only edge case): $\\Delta = 0.1$ seconds, $\\tau = 1.2$ seconds, $\\alpha = 1.0$ a.u., $R = 5$, $K = 10$, $\\sigma = 0.03$ a.u., ground truth spikes at $[]$ seconds (empty list).\n\nFinal output format:\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, where each element is a list of spike times in seconds for the corresponding test case, rounded to $4$ decimal places, for example, $[[0.6200,0.6600],[1.0000],[1.2200],[]]$. The order of test cases in the output must match the order listed above.",
            "solution": "The problem requires the derivation and implementation of a deconvolution algorithm to estimate neuronal spike times from frame-averaged calcium fluorescence data. The process begins with a formal validation of the problem statement, followed by a detailed derivation of the forward model and a description of the inversion and spike detection algorithm.\n\n### Problem Validation\n\n**Step 1: Extracted Givens**\n-   **Calcium Dynamics Model:** The intracellular calcium concentration, $c(t)$, is governed by the linear ordinary differential equation (ODE):\n    $$ \\frac{d c(t)}{d t} = -\\frac{1}{\\tau} c(t) + \\alpha\\, s(t) $$\n    where $\\tau$ is the calcium decay time constant, $\\alpha$ is the concentration jump per spike, and $s(t)$ is the spike train, modeled as a sum of Dirac delta functions.\n-   **Measurement Model:** The measured fluorescence for frame $k$, $y_k$, is the time-average of $c(t)$ over the frame duration $\\Delta$, with additive Gaussian noise $\\eta_k$:\n    $$ y_k = \\frac{1}{\\Delta} \\int_{k\\Delta}^{(k+1)\\Delta} c(t) \\, dt + \\eta_k $$\n    where $k \\in \\{0, 1, \\dots, K-1\\}$ and $\\eta_k \\sim \\mathcal{N}(0, \\sigma^2)$.\n-   **Discretization Scheme:** Spikes are assumed to occur on a uniform sub-frame grid with $R$ bins per frame. The sub-bin duration is $\\delta = \\Delta / R$, and the total number of sub-bins is $N = K R$. The spike train is represented by a non-negative vector of amplitudes on this grid.\n-   **Task:** The objective is to derive the exact linear operator mapping the sub-bin spike vector to the fluorescence samples, simulate data, and then invert the model to estimate spike times using Non-Negative Least Squares (NNLS), followed by thresholding, local-maxima finding, and parabolic time refinement.\n-   **Spike Detection Criteria:**\n    -   Threshold: $\\max(\\alpha/2, 3\\sigma)$ on the estimated spike amplitudes.\n    -   Peak finding: Select only local maxima.\n    -   Refinement: Fit a parabola to the 3-point neighborhood of a peak to find a sub-bin time offset.\n-   **Test Cases:** Four specific parameter sets $(\\Delta, \\tau, \\alpha, R, K, \\sigma)$ and corresponding ground-truth spike times are provided.\n\n**Step 2: Validation Using Extracted Givens**\nThe problem statement is evaluated against the validation criteria:\n1.  **Scientifically Grounded:** The model is a standard and widely accepted representation of calcium dynamics and fluorescence imaging in computational neuroscience. All principles are scientifically sound.\n2.  **Well-Posed:** The problem is structured to have a unique and stable solution. The forward model derivation is a direct analytical task. The inverse problem is framed as a convex optimization problem (NNLS), which has a unique solution. Subsequent processing steps are deterministic.\n3.  **Objective:** The problem is specified with precise mathematical formalism and objective, quantifiable tasks.\n4.  **Incomplete or Contradictory Setup:** All necessary parameters and model definitions are provided. The test case data (e.g., spike times on the grid) are consistent with the model's assumptions.\n5.  **Unrealistic or Infeasible:** The specified parameters and required computations are realistic and computationally feasible.\n6.  **Ill-Posed or Poorly Structured:** The problem is well-structured, guiding from theory to implementation.\n7.  **Pseudo-Profound, Trivial, or Tautological:** The problem involves a non-trivial analytical derivation and the implementation of a standard, substantive data analysis pipeline. It is not trivial or contrived.\n8.  **Relevance and Verifiability:** The problem is directly relevant to the specified topic and its solution is mathematically and computationally verifiable.\n\n**Step 3: Verdict and Action**\nThe problem is deemed **valid** across all criteria. I will proceed with the derivation and solution.\n\n### Derivation of the Forward Operator\n\nThe goal is to construct a linear operator (a matrix) $A$ that maps a discrete vector of spike amplitudes, $\\mathbf{s}$, to a vector of frame-averaged fluorescence measurements, $\\mathbf{y}$, according to the model $\\mathbf{y} = A\\mathbf{s} + \\boldsymbol{\\eta}$.\n\n**1. Impulse Response Function**\nFirst, we solve the ODE for a single spike occurring at time $t_j = j\\delta$, represented by the input $\\alpha \\delta(t-t_j)$. The equation is:\n$$ \\frac{d c(t)}{d t} + \\frac{1}{\\tau} c(t) = \\alpha \\, \\delta(t-t_j) $$\nAssuming the system is at rest for $t  t_j$ (i.e., $c(t)=0$), the solution for $t \\ge t_j$ is a causal exponential decay. The Dirac delta input causes an instantaneous jump in $c(t)$ at $t=t_j$ from $0$ to $\\alpha$. For $t>t_j$, the equation is homogeneous, $\\frac{dc}{dt} = -\\frac{c}{\\tau}$, with initial condition $c(t_j^+) = \\alpha$. The solution is:\n$$ c(t) = \\alpha \\exp\\left(-\\frac{t-t_j}{\\tau}\\right) \\quad \\text{for } t \\ge t_j $$\nWe can write the complete response to a spike at $t_j$, also known as the impulse response, as:\n$$ h(t; t_j) = \\alpha \\exp\\left(-\\frac{t-t_j}{\\tau}\\right) U(t-t_j) $$\nwhere $U(\\cdot)$ is the Heaviside step function.\n\n**2. Calcium Concentration for a Spike Train**\nBy the principle of linear superposition, the calcium concentration $c(t)$ resulting from a train of spikes with amplitudes $s_j$ at discrete times $t_j = j\\delta$ is the sum of individual responses:\n$$ c(t) = \\sum_{j=0}^{N-1} s_j h(t; t_j) = \\sum_{j=0}^{N-1} s_j \\alpha \\exp\\left(-\\frac{t-t_j}{\\tau}\\right) U(t-t_j) $$\n\n**3. Frame-Averaged Fluorescence Measurement**\nThe measurement $y_k$ is the integral of $c(t)$ over the $k$-th frame, from $T_k^{\\text{start}} = k\\Delta$ to $T_k^{\\text{end}} = (k+1)\\Delta$, normalized by the frame duration $\\Delta$. Substituting the expression for $c(t)$ and ignoring the noise term for now:\n$$ y_k = \\frac{1}{\\Delta} \\int_{k\\Delta}^{(k+1)\\Delta} \\left( \\sum_{j=0}^{N-1} s_j \\alpha \\exp\\left(-\\frac{t-t_j}{\\tau}\\right) U(t-t_j) \\right) dt $$\nWe can exchange the summation and integration:\n$$ y_k = \\sum_{j=0}^{N-1} s_j \\left[ \\frac{\\alpha}{\\Delta} \\int_{k\\Delta}^{(k+1)\\Delta} \\exp\\left(-\\frac{t-t_j}{\\tau}\\right) U(t-t_j) dt \\right] $$\nThis equation is in the form $y_k = \\sum_{j=0}^{N-1} A_{kj} s_j$, where $A_{kj}$ is the element in the $k$-th row and $j$-th column of the forward operator matrix $A$.\n\n**4. Analytical Calculation of Matrix Elements $A_{kj}$**\nThe matrix element $A_{kj}$ represents the contribution of a unit-amplitude spike in sub-bin $j$ to the average fluorescence in frame $k$.\n$$ A_{kj} = \\frac{\\alpha}{\\Delta} \\int_{k\\Delta}^{(k+1)\\Delta} \\exp\\left(-\\frac{t-t_j}{\\tau}\\right) U(t-t_j) dt $$\nThe Heaviside function $U(t-t_j)$ makes the integrand non-zero only for $t \\ge t_j$. Thus, the effective lower limit of integration is $\\max(k\\Delta, t_j)$. The integral is non-zero only if $\\max(k\\Delta, t_j)  (k+1)\\Delta$. This means $t_j  (k+1)\\Delta$.\n\nLet's evaluate the indefinite integral:\n$$ \\int \\exp\\left(-\\frac{t-t_j}{\\tau}\\right) dt = -\\tau \\exp\\left(-\\frac{t-t_j}{\\tau}\\right) + C $$\nWe now consider three cases based on the relative timing of the spike ($t_j$) and the frame interval $[k\\Delta, (k+1)\\Delta]$:\n\nCase 1: Spike occurs before the frame begins ($t_j  k\\Delta$).\nThe integration interval is $[k\\Delta, (k+1)\\Delta]$.\n\\begin{align*} A_{kj} = \\frac{\\alpha}{\\Delta} \\left[ -\\tau \\exp\\left(-\\frac{t-t_j}{\\tau}\\right) \\right]_{k\\Delta}^{(k+1)\\Delta} \\\\ = \\frac{\\alpha\\tau}{\\Delta} \\left[ \\exp\\left(-\\frac{k\\Delta-t_j}{\\tau}\\right) - \\exp\\left(-\\frac{(k+1)\\Delta-t_j}{\\tau}\\right) \\right] \\\\ = \\frac{\\alpha\\tau}{\\Delta} \\exp\\left(-\\frac{k\\Delta-t_j}{\\tau}\\right) \\left(1 - \\exp\\left(-\\frac{\\Delta}{\\tau}\\right)\\right)\\end{align*}\n\nCase 2: Spike occurs within the frame ($k\\Delta \\le t_j  (k+1)\\Delta$).\nThe integration interval is $[t_j, (k+1)\\Delta]$.\n\\begin{align*} A_{kj} = \\frac{\\alpha}{\\Delta} \\left[ -\\tau \\exp\\left(-\\frac{t-t_j}{\\tau}\\right) \\right]_{t_j}^{(k+1)\\Delta} \\\\ = \\frac{\\alpha\\tau}{\\Delta} \\left[ \\exp\\left(-\\frac{t_j-t_j}{\\tau}\\right) - \\exp\\left(-\\frac{(k+1)\\Delta-t_j}{\\tau}\\right) \\right] \\\\ = \\frac{\\alpha\\tau}{\\Delta} \\left( 1 - \\exp\\left(-\\frac{(k+1)\\Delta-t_j}{\\tau}\\right) \\right) \\end{align*}\n\nCase 3: Spike occurs after the frame ends ($t_j \\ge (k+1)\\Delta$).\nThe integration interval is empty.\n$$ A_{kj} = 0 $$\n\nThese three cases completely define the forward operator matrix $A$.\n\n### Inversion and Spike Estimation Algorithm\nWith the forward operator $A$ constructed, the problem of estimating the spike amplitudes $\\mathbf{s}$ from noisy measurements $\\mathbf{y}$ is an inverse problem.\n\n1.  **Non-Negative Least Squares (NNLS):** Given that spike amplitudes must be non-negative, we solve the constrained optimization problem:\n    $$ \\hat{\\mathbf{s}} = \\arg\\min_{\\mathbf{s} \\ge 0} || A\\mathbf{s} - \\mathbf{y} ||_2^2 $$\n    This is a standard NNLS problem, which can be solved efficiently with numerical libraries.\n\n2.  **Spike Detection:** The resulting vector $\\hat{\\mathbf{s}}$ contains estimated amplitudes for each sub-bin. Spikes are identified by:\n    a. **Thresholding:** Select all sub-bins $n$ where the estimated amplitude $\\hat{s}_n$ exceeds a threshold $T = \\max(\\alpha/2, 3\\sigma)$.\n    b. **Local Maxima (Non-Maximum Suppression):** From the thresholded bins, retain only those that are local maxima, i.e., $\\hat{s}_n  \\hat{s}_{n-1}$ and $\\hat{s}_n  \\hat{s}_{n+1}$ (handling boundary conditions appropriately). This ensures that a single broader peak in the estimate, corresponding to one true spike, is not detected multiple times.\n\n3.  **Spike Time Refinement:** To achieve super-resolution timing within a sub-bin, we refine the time of each detected spike. For a peak at sub-bin $n$, we fit a parabola $f(t) = at^2+bt+c$ to the three points $(\\hat{t}_{n-1}, \\hat{s}_{n-1})$, $(\\hat{t}_{n}, \\hat{s}_{n})$, and $(\\hat{t}_{n+1}, \\hat{s}_{n+1})$, where $\\hat{t}_n = n\\delta$. The refined spike time is the horizontal coordinate of the parabola's vertex. The offset $\\Delta t$ from the center of the bin $n$ is given by:\n    $$ \\Delta t = \\frac{\\hat{s}_{n-1} - \\hat{s}_{n+1}}{2(\\hat{s}_{n-1} + \\hat{s}_{n+1} - 2\\hat{s}_n)} \\delta $$\n    The refined spike time is $t_{\\text{refined}} = \\hat{t}_n + \\Delta t$. This refinement is performed only for peaks with both neighbors available; otherwise, the sub-bin center time $\\hat{t}_n$ is used. This concludes the algorithmic design.",
            "answer": "```python\nimport numpy as np\nfrom scipy.optimize import nnls\n\ndef solve():\n    \"\"\"\n    Main function to run all test cases and print results.\n    \"\"\"\n    # Test suite from the problem statement\n    test_cases = [\n        # Case 1: (Delta, tau, alpha, R, K, sigma, true_spike_times)\n        (0.1, 0.8, 1.0, 5, 25, 0.02, [1.22]),\n        # Case 2\n        (0.1, 1.0, 1.0, 8, 20, 0.05, [1.0]),\n        # Case 3\n        (0.1, 0.5, 1.0, 10, 15, 0.01, [0.62, 0.66]),\n        # Case 4\n        (0.1, 1.2, 1.0, 5, 10, 0.03, []),\n    ]\n\n    all_results = []\n    for i, case in enumerate(test_cases):\n        # Use a fixed seed for each case for reproducibility, although not strictly required\n        np.random.seed(i)\n        \n        Delta, tau, alpha, R, K, sigma, true_spike_times = case\n\n        # Derived parameters\n        delta = Delta / R\n        N = K * R  # Total number of sub-bins\n\n        # 1. Construct the forward operator A\n        A = build_forward_operator(Delta, tau, alpha, R, K, N, delta)\n\n        # 2. Build ground-truth spike vector s_true\n        s_true = np.zeros(N)\n        if true_spike_times:\n            # Note: problem statement guarantees spikes are on the grid\n            spike_indices = np.round(np.array(true_spike_times) / delta).astype(int)\n            s_true[spike_indices] = 1.0\n\n        # 3. Simulate fluorescence data y\n        y_clean = A @ s_true\n        noise = np.random.normal(0, sigma, K)\n        y = y_clean + noise\n\n        # 4. Estimate spike amplitudes s_est via NNLS\n        s_est, _ = nnls(A, y)\n\n        # 5. Detect and refine spike times\n        estimated_times = detect_and_refine_spikes(s_est, delta, N, alpha, sigma)\n        \n        # Format results to 4 decimal places\n        formatted_times = [f\"{t:.4f}\" for t in estimated_times]\n        all_results.append(f\"[{','.join(formatted_times)}]\")\n\n    # Print final output in the required format\n    print(f\"[{','.join(all_results)}]\")\n\ndef build_forward_operator(Delta, tau, alpha, R, K, N, delta):\n    \"\"\"\n    Constructs the exact K x N forward operator matrix A.\n    \"\"\"\n    A = np.zeros((K, N))\n    \n    # Grid of time points and frame indices\n    k_grid, j_grid = np.meshgrid(np.arange(K), np.arange(N), indexing='ij')\n\n    t_j = j_grid * delta\n    T_k_start = k_grid * Delta\n    T_k_end = (k_grid + 1) * Delta\n\n    # Case 1: Spike before frame (t_j  T_k_start)\n    idx1 = t_j  T_k_start\n    term1 = (alpha * tau / Delta)\n    # The exponential term can be large, but the product is well-behaved\n    # exp((t_j - T_k_start)/tau) = exp((j*delta - k*Delta)/tau)\n    # = exp((j/R - k)*Delta/tau)\n    exp_decay_across_frame = np.exp(-Delta / tau)\n    A[idx1] = term1 * np.exp((t_j[idx1] - T_k_start[idx1]) / tau) * (1 - exp_decay_across_frame)\n\n    # Case 2: Spike within frame (T_k_start = t_j  T_k_end)\n    idx2 = (t_j >= T_k_start)  (t_j  T_k_end)\n    A[idx2] = term1 * (1 - np.exp(-(T_k_end[idx2] - t_j[idx2]) / tau))\n\n    # Case 3 (spike after frame) is implicitly handled as A is initialized to zeros.\n    \n    return A\n\ndef detect_and_refine_spikes(s_est, delta, N, alpha, sigma):\n    \"\"\"\n    Detects spikes from estimated amplitudes via thresholding, non-maximum\n    suppression, and refines their timing using parabolic interpolation.\n    \"\"\"\n    if N == 0:\n        return []\n\n    threshold = max(alpha / 2.0, 3.0 * sigma)\n    \n    # Find indices of potential peaks (above threshold)\n    potential_peak_indices = np.where(s_est > threshold)[0]\n    \n    peak_indices = []\n    for n in potential_peak_indices:\n        # Check for local maximum property (non-maximum suppression)\n        is_local_max = True\n        # Check left neighbor\n        if n > 0 and s_est[n] = s_est[n-1]:\n            is_local_max = False\n        # Check right neighbor\n        if n  N - 1 and s_est[n] = s_est[n+1]:\n            is_local_max = False\n        \n        if is_local_max:\n            peak_indices.append(n)\n\n    estimated_times = []\n    for n in peak_indices:\n        t_n = n * delta\n        \n        # Perform parabolic refinement if neighbors exist\n        if 0  n  N - 1:\n            s_left, s_peak, s_right = s_est[n-1], s_est[n], s_est[n+1]\n            \n            # The denominator is 2 * (s_left + s_right - 2*s_peak)\n            # which is proportional to the second derivative (curvature)\n            denominator = 2 * (s_left + s_right - 2 * s_peak)\n            \n            if np.abs(denominator)  1e-9: # Avoid division by zero (collinear points)\n                offset = 0.0\n            else:\n                offset = delta * (s_left - s_right) / denominator\n                \n            # As per problem, offset is expected within [-delta/2, delta/2].\n            # Clip for robustness.\n            offset = np.clip(offset, -delta / 2.0, delta / 2.0)\n\n            refined_time = t_n + offset\n        else:\n            # Use sub-bin center for boundary peaks\n            refined_time = t_n\n        \n        estimated_times.append(refined_time)\n\n    estimated_times.sort()\n    return estimated_times\n\nsolve()\n```"
        }
    ]
}