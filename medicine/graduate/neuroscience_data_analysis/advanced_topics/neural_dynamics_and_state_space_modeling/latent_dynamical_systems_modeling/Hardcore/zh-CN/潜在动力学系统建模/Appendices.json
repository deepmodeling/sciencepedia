{
    "hands_on_practices": [
        {
            "introduction": "本练习将深入探讨拟合潜动力系统模型的理论核心。通过推导线性高斯状态空间模型（LGSSM）的边际似然，您将理解如何量化模型与观测数据的匹配程度。这个过程揭示了卡尔曼滤波器如何通过其“创新”序列高效地计算这一关键量，为参数估计和模型选择提供了理论基础 。",
            "id": "4173383",
            "problem": "考虑一个用于介观双光子钙成像实验中潜在群体活动的线性高斯状态空间模型 (LGSSM)。潜在状态 $\\mathbf{x}_t \\in \\mathbb{R}^n$ 捕捉了低维神经动力学，观测值 $\\mathbf{y}_t \\in \\mathbb{R}^m$ 代表了 $m$ 个感兴趣区域的荧光强度。该模型由以下生成性假设指定：\n$$\n\\mathbf{x}_1 \\sim \\mathcal{N}(\\mathbf{m}_0, \\mathbf{P}_0), \\quad \\mathbf{x}_{t+1} = \\mathbf{A}\\,\\mathbf{x}_t + \\mathbf{w}_t, \\quad \\mathbf{w}_t \\sim \\mathcal{N}(\\mathbf{0}, \\mathbf{Q}),\n$$\n$$\n\\mathbf{y}_t = \\mathbf{C}\\,\\mathbf{x}_t + \\mathbf{v}_t, \\quad \\mathbf{v}_t \\sim \\mathcal{N}(\\mathbf{0}, \\mathbf{R}),\n$$\n其中 $\\mathbf{A} \\in \\mathbb{R}^{n \\times n}$、$\\mathbf{C} \\in \\mathbb{R}^{m \\times n}$、$\\mathbf{Q} \\in \\mathbb{R}^{n \\times n}$、$\\mathbf{R} \\in \\mathbb{R}^{m \\times m}$、$\\mathbf{m}_0 \\in \\mathbb{R}^n$ 和 $\\mathbf{P}_0 \\in \\mathbb{R}^{n \\times n}$ 是已知的。随机变量 $\\mathbf{x}_1$、$\\{\\mathbf{w}_t\\}_{t=1}^{T-1}$ 和 $\\{\\mathbf{v}_t\\}_{t=1}^{T}$ 是相互独立的，该过程在 $\\mathbf{x}_t$ 上是一阶马尔可夫过程，并且在给定 $\\mathbf{x}_t$ 的条件下观测值是条件独立的。假设 $\\mathbf{y}_{1:T}$ 是在 $T$ 个时间步长内观测到的荧光测量值，其中 $T \\in \\mathbb{N}$。\n\n从这些假设所隐含的联合分布因子分解出发，仅使用多变量高斯分布的性质和条件期望的塔性质，对潜在状态进行递归高斯积分，以获得边际似然 $p(\\mathbf{y}_{1:T})$。你的推导必须通过将 $p(\\mathbf{y}_{1:T})$ 表示为由 Kalman 滤波器的创新序列构建的一步预测观测密度的乘积来进行。根据 Kalman 预测均值和协方差定义创新及其协方差，但不要假设任何稳态或渐近公式。\n\n以作用于 $\\mathbf{y}_{1:T}$ 的 Kalman 滤波器生成的创新向量 $\\{\\mathbf{e}_t\\}_{t=1}^{T}$ 和创新协方差 $\\{\\mathbf{S}_t\\}_{t=1}^{T}$ 的形式，为 $p(\\mathbf{y}_{1:T})$ 提供一个单一的闭式解析表达式。此外，说明模型参数和由此产生的预测协方差需满足的最小条件，以使该计算是可行的（即，积分以及所需的矩阵逆和行列式存在且有限）。不需要进行数值评估。以符号形式表示最终答案；不要包含任何单位。",
            "solution": "### 步骤 1：提取已知条件\n问题定义了一个线性高斯状态空间模型 (LGSSM)，包含以下组成部分：\n- 潜在状态：$\\mathbf{x}_t \\in \\mathbb{R}^n$\n- 观测值：$\\mathbf{y}_t \\in \\mathbb{R}^m$\n- 生成性假设：\n  - 初始状态分布：$\\mathbf{x}_1 \\sim \\mathcal{N}(\\mathbf{m}_0, \\mathbf{P}_0)$\n  - 状态转移方程：$\\mathbf{x}_{t+1} = \\mathbf{A}\\,\\mathbf{x}_t + \\mathbf{w}_t$，其中过程噪声 $\\mathbf{w}_t \\sim \\mathcal{N}(\\mathbf{0}, \\mathbf{Q})$\n  - 观测方程：$\\mathbf{y}_t = \\mathbf{C}\\,\\mathbf{x}_t + \\mathbf{v}_t$，其中测量噪声 $\\mathbf{v}_t \\sim \\mathcal{N}(\\mathbf{0}, \\mathbf{R})$\n- 模型参数是已知的：$\\mathbf{A} \\in \\mathbb{R}^{n \\times n}$、$\\mathbf{C} \\in \\mathbb{R}^{m \\times n}$、$\\mathbf{Q} \\in \\mathbb{R}^{n \\times n}$（对称半正定）、$\\mathbf{R} \\in \\mathbb{R}^{m \\times m}$（对称半正定）、$\\mathbf{m}_0 \\in \\mathbb{R}^n$ 和 $\\mathbf{P}_0 \\in \\mathbb{R}^{n \\times n}$（对称半正定）。\n- 独立性假设：随机变量 $\\mathbf{x}_1$、$\\{\\mathbf{w}_t\\}_{t=1}^{T-1}$ 和 $\\{\\mathbf{v}_t\\}_{t=1}^{T}$ 是相互独立的。\n- 马尔可夫性质：该过程在 $\\mathbf{x}_t$ 上是一阶马尔可夫过程，并且在给定 $\\mathbf{x}_t$ 的条件下观测值 $\\mathbf{y}_t$ 是条件独立的。\n- 数据：一个在 $T \\in \\mathbb{N}$ 个时间步长上的观测序列 $\\mathbf{y}_{1:T} = \\{\\mathbf{y}_1, \\dots, \\mathbf{y}_T\\}$。\n\n### 步骤 2：使用提取的已知条件进行验证\n- **科学上合理**：该问题描述了一个标准的线性高斯状态空间模型，也称为 Kalman 滤波器模型。这是现代信号处理、控制理论和时间序列分析的基石，应用广泛，包括神经科学数据分析。其前提在科学上是合理的，并且在数理统计学中得到了牢固的确立。\n- **适定性**：该问题要求推导边际似然 $p(\\mathbf{y}_{1:T})$，这是统计推断中一个明确定义的量。模型已用所有必要的参数和分布完全指定。任务是提供一个特定的解析表达式，这是该模型的标准结果。\n- **客观性**：该问题以精确的数学语言陈述，没有任何主观或有偏见的术语。\n\n该问题没有表现出验证标准中列出的任何缺陷。它在科学上是合理的、适定的、客观的、完整的，并要求在潜在动力系统建模这一特定主题内进行非平凡的推导。\n\n### 步骤 3：结论与行动\n该问题是有效的。将提供一个完整的、有理有据的解决方案。\n\n### 边际似然的推导\n\n目标是计算观测值的边际似然 $p(\\mathbf{y}_{1:T})$。这个量是通过对所有潜在状态 $\\mathbf{x}_{1:T}$ 的联合概率分布进行积分得到的：\n$$\np(\\mathbf{y}_{1:T}) = \\int p(\\mathbf{y}_{1:T}, \\mathbf{x}_{1:T}) d\\mathbf{x}_{1:T}\n$$\n问题指定推导应通过将 $p(\\mathbf{y}_{1:T})$ 表示为一步预测观测密度的乘积来进行。这可以通过对观测序列应用概率的链式法则来实现：\n$$\np(\\mathbf{y}_{1:T}) = p(\\mathbf{y}_T | \\mathbf{y}_{1:T-1}) p(\\mathbf{y}_{T-1} | \\mathbf{y}_{1:T-2}) \\dots p(\\mathbf{y}_2 | \\mathbf{y}_1) p(\\mathbf{y}_1)\n$$\n这可以紧凑地写成：\n$$\np(\\mathbf{y}_{1:T}) = \\prod_{t=1}^{T} p(\\mathbf{y}_t | \\mathbf{y}_{1:t-1})\n$$\n其中当 $t=1$ 时，条件集为空，因此第一项就是边际密度 $p(\\mathbf{y}_1)$。\n\n推导的核心是为该乘积中的每一项 $p(\\mathbf{y}_t | \\mathbf{y}_{1:t-1})$ 找到一个表达式。由于整个模型是线性高斯状态空间模型，因此整个联合分布 $p(\\mathbf{x}_{1:T}, \\mathbf{y}_{1:T})$ 是高斯的。因此，所有由它导出的边际分布和条件分布也都是高斯的。所以，一步预测观测密度 $p(\\mathbf{y}_t | \\mathbf{y}_{1:t-1})$ 是高斯的，我们的任务就简化为求其均值和协方差。\n\n这正是 Kalman 滤波器算法所计算的。Kalman 滤波器提供了一种递归方法来获得状态的后验分布。让我们将以截至时间 $t-1$ 的观测值为条件的状态分布的均值和协方差表示为：\n$$\np(\\mathbf{x}_t | \\mathbf{y}_{1:t-1}) = \\mathcal{N}(\\mathbf{x}_t; \\mathbf{m}_{t|t-1}, \\mathbf{P}_{t|t-1})\n$$\n这是状态的一步向前预测分布。密度 $p(\\mathbf{y}_t | \\mathbf{y}_{1:t-1})$ 可以通过对 $\\mathbf{x}_t$ 进行边际化来找到：\n$$\np(\\mathbf{y}_t | \\mathbf{y}_{1:t-1}) = \\int p(\\mathbf{y}_t | \\mathbf{x}_t, \\mathbf{y}_{1:t-1}) p(\\mathbf{x}_t | \\mathbf{y}_{1:t-1}) d\\mathbf{x}_t\n$$\n由于模型中的条件独立性假设，$p(\\mathbf{y}_t | \\mathbf{x}_t, \\mathbf{y}_{1:t-1}) = p(\\mathbf{y}_t | \\mathbf{x}_t) = \\mathcal{N}(\\mathbf{y}_t; \\mathbf{C}\\mathbf{x}_t, \\mathbf{R})$。因此，我们是在对两个高斯分布的乘积进行积分，其结果也是一个高斯分布。\n\n我们可以使用条件期望和协方差的法则来找到 $p(\\mathbf{y}_t | \\mathbf{y}_{1:t-1})$ 的均值和协方差。均值是通过期望的塔性质找到的：\n$$\nE[\\mathbf{y}_t | \\mathbf{y}_{1:t-1}] = E[E[\\mathbf{y}_t | \\mathbf{x}_t, \\mathbf{y}_{1:t-1}] | \\mathbf{y}_{1:t-1}] = E[E[\\mathbf{C}\\mathbf{x}_t + \\mathbf{v}_t | \\mathbf{x}_t] | \\mathbf{y}_{1:t-1}]\n$$\n$$\nE[\\mathbf{y}_t | \\mathbf{y}_{1:t-1}] = E[\\mathbf{C}\\mathbf{x}_t | \\mathbf{y}_{1:t-1}] = \\mathbf{C} E[\\mathbf{x}_t | \\mathbf{y}_{1:t-1}] = \\mathbf{C} \\mathbf{m}_{t|t-1}\n$$\n协方差是：\n$$\n\\text{Cov}(\\mathbf{y}_t | \\mathbf{y}_{1:t-1}) = \\text{Cov}(\\mathbf{C}\\mathbf{x}_t + \\mathbf{v}_t | \\mathbf{y}_{1:t-1})\n$$\n由于 $\\mathbf{v}_t$ 独立于 $\\mathbf{x}_t$ 和所有先前的观测值 $\\mathbf{y}_{1:t-1}$，它的协方差与条件无关：\n$$\n\\text{Cov}(\\mathbf{y}_t | \\mathbf{y}_{1:t-1}) = \\text{Cov}(\\mathbf{C}\\mathbf{x}_t | \\mathbf{y}_{1:t-1}) + \\text{Cov}(\\mathbf{v}_t) = \\mathbf{C} \\text{Cov}(\\mathbf{x}_t | \\mathbf{y}_{1:t-1}) \\mathbf{C}^T + \\mathbf{R}\n$$\n$$\n\\text{Cov}(\\mathbf{y}_t | \\mathbf{y}_{1:t-1}) = \\mathbf{C} \\mathbf{P}_{t|t-1} \\mathbf{C}^T + \\mathbf{R}\n$$\n这个量被定义为创新协方差，$\\mathbf{S}_t$。\n$$\n\\mathbf{S}_t \\equiv \\mathbf{C} \\mathbf{P}_{t|t-1} \\mathbf{C}^T + \\mathbf{R}\n$$\n因此，一步预测观测分布为：\n$$\np(\\mathbf{y}_t | \\mathbf{y}_{1:t-1}) = \\mathcal{N}(\\mathbf{y}_t; \\mathbf{C} \\mathbf{m}_{t|t-1}, \\mathbf{S}_t)\n$$\n创新向量 $\\mathbf{e}_t$ 被定义为实际观测值 $\\mathbf{y}_t$ 与其一步预测值之间的差：\n$$\n\\mathbf{e}_t \\equiv \\mathbf{y}_t - E[\\mathbf{y}_t | \\mathbf{y}_{1:t-1}] = \\mathbf{y}_t - \\mathbf{C} \\mathbf{m}_{t|t-1}\n$$\n因此，创新（以过去观测值为条件）的分布是 $\\mathbf{e}_t | \\mathbf{y}_{1:t-1} \\sim \\mathcal{N}(\\mathbf{0}, \\mathbf{S}_t)$。因此，密度 $p(\\mathbf{y}_t | \\mathbf{y}_{1:t-1})$ 可以优雅地表示为创新向量的概率密度：\n$$\np(\\mathbf{y}_t | \\mathbf{y}_{1:t-1}) = \\frac{1}{\\sqrt{(2\\pi)^m \\det(\\mathbf{S}_t)}} \\exp\\left(-\\frac{1}{2} (\\mathbf{y}_t - \\mathbf{C}\\mathbf{m}_{t|t-1})^T \\mathbf{S}_t^{-1} (\\mathbf{y}_t - \\mathbf{C}\\mathbf{m}_{t|t-1})\\right)\n$$\n$$\np(\\mathbf{y}_t | \\mathbf{y}_{1:t-1}) = \\frac{1}{\\sqrt{(2\\pi)^m \\det(\\mathbf{S}_t)}} \\exp\\left(-\\frac{1}{2} \\mathbf{e}_t^T \\mathbf{S}_t^{-1} \\mathbf{e}_t\\right)\n$$\n这里，$m$ 是观测向量 $\\mathbf{y}_t$ 的维度。量 $\\mathbf{m}_{t|t-1}$ 和 $\\mathbf{P}_{t|t-1}$ 由 Kalman 滤波器的预测步骤产生，该步骤更新了前一步的滤波估计值 $\\mathbf{m}_{t-1|t-1}$ 和 $\\mathbf{P}_{t-1|t-1}$。递归从 $t=1$ 开始，使用先验信息 $p(\\mathbf{x}_1) = \\mathcal{N}(\\mathbf{x}_1; \\mathbf{m}_0, \\mathbf{P}_0)$，这意味着我们设置 $\\mathbf{m}_{1|0} = \\mathbf{m}_0$ 和 $\\mathbf{P}_{1|0} = \\mathbf{P}_0$。\n\n将此表达式代入边际似然的乘积形式，我们得到：\n$$\np(\\mathbf{y}_{1:T}) = \\prod_{t=1}^{T} \\left[ \\frac{1}{\\sqrt{(2\\pi)^m \\det(\\mathbf{S}_t)}} \\exp\\left(-\\frac{1}{2} \\mathbf{e}_t^T \\mathbf{S}_t^{-1} \\mathbf{e}_t\\right) \\right]\n$$\n这个表达式可以重写，将乘积分离成一个归一化常数项和一个指数项：\n$$\np(\\mathbf{y}_{1:T}) = \\left(\\prod_{t=1}^{T} (2\\pi)^{-m/2} (\\det(\\mathbf{S}_t))^{-1/2} \\right) \\exp\\left(-\\frac{1}{2} \\sum_{t=1}^{T} \\mathbf{e}_t^T \\mathbf{S}_t^{-1} \\mathbf{e}_t\\right)\n$$\n这就是用创新及其协方差表示的边际似然的最终解析表达式。\n\n### 可计算性条件\n\n为了使边际似然 $p(\\mathbf{y}_{1:T})$ 的计算是可行的 (tractable)，乘积中的每一项都必须是明确定义且有限的。在每个步骤 $t$ 的高斯密度公式涉及两个关键操作：行列式 $\\det(\\mathbf{S}_t)$ 和逆矩阵 $\\mathbf{S}_t^{-1}$。\n1.  行列式 $\\det(\\mathbf{S}_t)$ 出现在分母中，所以它必须非零。\n2.  矩阵的逆 $\\mathbf{S}_t^{-1}$ 必须存在。\n当且仅当矩阵 $\\mathbf{S}_t$ 对所有 $t=1, \\dots, T$ 都是可逆的，这两个条件才能满足。\n\n矩阵 $\\mathbf{S}_t = \\mathbf{C} \\mathbf{P}_{t|t-1} \\mathbf{C}^T + \\mathbf{R}$ 是两个对称半正定矩阵（因为 $\\mathbf{P}_{t|t-1}$ 和 $\\mathbf{R}$ 是协方差矩阵）的和，因此 $\\mathbf{S}_t$ 本身是对称且半正定的。对于一个对称半正定矩阵，可逆等价于正定。\n\n因此，计算可行的最小充要条件是创新协方差矩阵 $\\mathbf{S}_t$ 对所有 $t \\in \\{1, \\dots, T\\}$ 都必须是正定的。\n\n一个能确保这一点的常见且实用的模型参数充分条件是，观测噪声协方差矩阵 $\\mathbf{R}$ 是正定的。如果 $\\mathbf{R}$ 是正定的，那么对于任何非零向量 $\\mathbf{z} \\in \\mathbb{R}^m$，有 $\\mathbf{z}^T \\mathbf{R} \\mathbf{z} > 0$。由于 $\\mathbf{C} \\mathbf{P}_{t|t-1} \\mathbf{C}^T$ 是半正定的，所以 $\\mathbf{z}^T (\\mathbf{C} \\mathbf{P}_{t|t-1} \\mathbf{C}^T) \\mathbf{z} \\ge 0$。因此，和 $\\mathbf{z}^T \\mathbf{S}_t \\mathbf{z} = \\mathbf{z}^T (\\mathbf{C} \\mathbf{P}_{t|t-1} \\mathbf{C}^T) \\mathbf{z} + \\mathbf{z}^T \\mathbf{R} \\mathbf{z}$ 将是严格为正的，从而证明 $\\mathbf{S}_t$ 是正定的。",
            "answer": "$$\n\\boxed{\\left(\\prod_{t=1}^{T} (2\\pi)^{-m/2} (\\det(\\mathbf{S}_t))^{-1/2} \\right) \\exp\\left(-\\frac{1}{2} \\sum_{t=1}^{T} \\mathbf{e}_t^T \\mathbf{S}_t^{-1} \\mathbf{e}_t\\right)}\n$$"
        },
        {
            "introduction": "从理论走向实践，本练习将处理在神经科学中更常见的泊松（Poisson）脉冲计数数据。您将通过编程实现一个关键的评估任务：使用已拟合的模型预测未见神经元的活动，并将其与一个更简单的静态模型进行量化比较 。此练习不仅能锻炼您的编程和模型评估技能，还能直观地展示捕捉时间动态和不确定性的重要性。",
            "id": "4173354",
            "problem": "给定一个已拟合的泊松线性动态系统 (PLDS) 和一个已拟合的静态泊松分解 (SPF) 模型，用于处理多神经元、多时间窗记录中的神经元脉冲计数。任务是计算在 PLDS 模型下，被保留神经元 (held-out neurons) 的期望脉冲计数和预测对数似然，并将这些指标与在 SPF 模型下获得的指标进行比较。必须在多个测试用例上进行比较，以评估在不同后验协方差结构和数据情况下的性能。\n\n从以下基本定义开始：\n- 线性动态系统的定义：在每个时间窗 $t$，潜在状态 $\\mathbf{x}_t \\in \\mathbb{R}^K$ 根据 $\\mathbf{x}_t = \\mathbf{A}\\mathbf{x}_{t-1} + \\mathbf{b} + \\mathbf{w}_t$ 演化，其中 $\\mathbf{w}_t \\sim \\mathcal{N}(\\mathbf{0}, \\mathbf{Q})$ 是高斯过程噪声。\n- 脉冲计数的条件泊松观测模型定义：对于神经元 $n$，在给定 $\\mathbf{x}_t$ 的条件下，脉冲计数 $y_{t,n}$ 服从泊松随机变量分布，其速率为 $\\lambda_{t,n} = \\exp(\\mathbf{c}_n^\\top \\mathbf{x}_t + d_n)$，其中 $\\mathbf{c}_n \\in \\mathbb{R}^K$ 是神经元 $n$ 的负载向量 (loading vector)，$d_n \\in \\mathbb{R}$ 是其对数速率偏移量。\n- 静态泊松分解模型的定义：给定 $\\mathbf{u}_t$，$y_{t,n}$ 服从泊松分布，其速率为 $\\tilde{\\lambda}_{t,n} = \\exp(\\mathbf{v}_n^\\top \\mathbf{u}_t + b_n)$，其中 $\\mathbf{u}_t \\in \\mathbb{R}^K$ 是（静态的）时间因子向量，$\\mathbf{v}_n \\in \\mathbb{R}^K$ 是神经元因子向量，$b_n \\in \\mathbb{R}$ 是其对数速率偏移量。\n- 预测对数似然的定义：对于脉冲计数 $y_{t,n}$ 和由参数指定的模型，预测对数似然是在潜在变量的相关后验分布下的对数似然的期望值。对于 PLDS，假设一个高斯变分后验 $\\mathbf{x}_t \\sim \\mathcal{N}(\\mathbf{m}_t, \\mathbf{S}_t)$ 是可用的。对于 SPF，将 $\\mathbf{u}_t$ 作为确定性点估计。\n\n仅使用这些定义和经过充分检验的概率论事实，推导计算以下内容所需的公式：\n- 在 PLDS 和 SPF 模型下，被保留神经元的期望脉冲计数。\n- 在 PLDS 模型下（作为高斯后验分布下的期望）和在 SPF 模型下（作为确定性评估），被保留神经元的预测对数似然。\n\n然后实现一个程序，对下面描述的每个测试用例，计算两个摘要指标：\n1. 在所有时间窗内，被保留神经元的总预测对数似然之差，定义为 $L_{\\mathrm{PLDS}} - L_{\\mathrm{SPF}}$。\n2. 在所有时间窗内，被保留神经元的模型期望脉冲计数之间的平均绝对差。\n\n你的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表的结果。结果必须按测试用例排序，每个测试用例有两个数字：首先是预测对数似然差，然后是期望计数的平均绝对差。因此，对于三个测试用例，输出必须总共包含六个数字，顺序为 $[L_{\\mathrm{PLDS}} - L_{\\mathrm{SPF}} \\text{（用例 1）}, \\text{ MAD}_{\\text{counts}} \\text{（用例 1）}, L_{\\mathrm{PLDS}} - L_{\\mathrm{SPF}} \\text{（用例 2）}, \\text{ MAD}_{\\text{counts}} \\text{（用例 2）}, L_{\\mathrm{PLDS}} - L_{\\mathrm{SPF}} \\text{（用例 3）}, \\text{ MAD}_{\\text{counts}} \\text{（用例 3）}]$。\n\n不涉及物理单位或角度单位。输出中的所有数值答案必须是浮点数。\n\n每个测试用例的已拟合模型参数和数据如下。潜在维度为 $K = 2$，神经元数量为 $N = 4$，时间窗数量为 $T = 5$，被保留神经元的索引集为 $\\{2, 3\\}$（从零开始的索引）。\n\n所有测试用例的共享参数：\n- PLDS 观测参数：\n  - $\\mathbf{C} = \\begin{bmatrix} 0.7  -0.3 \\\\ -0.5  0.6 \\\\ 0.2  0.8 \\\\ 1.0  -0.4 \\end{bmatrix}$，其中第 $n$ 行为 $\\mathbf{c}_n^\\top$。\n  - $\\mathbf{d} = \\begin{bmatrix} -1.0 \\\\ -0.7 \\\\ -1.2 \\\\ -0.5 \\end{bmatrix}$。\n- SPF 观测参数：\n  - $\\mathbf{V} = \\begin{bmatrix} 0.6  -0.2 \\\\ -0.4  0.5 \\\\ 0.15  0.7 \\\\ 0.9  -0.1 \\end{bmatrix}$，其中第 $n$ 行为 $\\mathbf{v}_n^\\top$。\n  - $\\mathbf{b} = \\begin{bmatrix} -1.0 \\\\ -0.7 \\\\ -1.1 \\\\ -0.6 \\end{bmatrix}$。\n\n测试用例 1（PLDS 的非零后验协方差）：\n- 形状为 $T \\times N$ 的观测脉冲计数矩阵 $\\mathbf{Y}^{(1)}$：\n  - 第 1 行：$\\begin{bmatrix} 5  2  3  0 \\end{bmatrix}$，\n  - 第 2 行：$\\begin{bmatrix} 6  3  4  1 \\end{bmatrix}$，\n  - 第 3 行：$\\begin{bmatrix} 4  1  2  0 \\end{bmatrix}$，\n  - 第 4 行：$\\begin{bmatrix} 7  2  5  1 \\end{bmatrix}$，\n  - 第 5 行：$\\begin{bmatrix} 3  2  1  0 \\end{bmatrix}$。\n- PLDS 变分后验均值 $\\mathbf{m}_t^{(1)}$ (对于 $t = 1, \\dots, 5$)：\n  - $\\mathbf{m}_1^{(1)} = \\begin{bmatrix} 0.2 \\\\ -0.1 \\end{bmatrix}$，\n  - $\\mathbf{m}_2^{(1)} = \\begin{bmatrix} 0.4 \\\\ -0.05 \\end{bmatrix}$，\n  - $\\mathbf{m}_3^{(1)} = \\begin{bmatrix} 0.35 \\\\ 0.0 \\end{bmatrix}$，\n  - $\\mathbf{m}_4^{(1)} = \\begin{bmatrix} 0.3 \\\\ 0.1 \\end{bmatrix}$，\n  - $\\mathbf{m}_5^{(1)} = \\begin{bmatrix} 0.1 \\\\ 0.2 \\end{bmatrix}$。\n- PLDS 变分后验协方差 $\\mathbf{S}_t^{(1)}$ (对于 $t = 1, \\dots, 5$)：\n  - $\\mathbf{S}_t^{(1)} = \\begin{bmatrix} 0.2  0.0 \\\\ 0.0  0.1 \\end{bmatrix}$ 对于所有 $t$。\n- SPF 时间因子 $\\mathbf{u}_t^{(1)}$ (对于 $t = 1, \\dots, 5$)：\n  - $\\mathbf{u}_1^{(1)} = \\begin{bmatrix} 0.25 \\\\ -0.15 \\end{bmatrix}$，\n  - $\\mathbf{u}_2^{(1)} = \\begin{bmatrix} 0.45 \\\\ -0.10 \\end{bmatrix}$，\n  - $\\mathbf{u}_3^{(1)} = \\begin{bmatrix} 0.40 \\\\ -0.05 \\end{bmatrix}$，\n  - $\\mathbf{u}_4^{(1)} = \\begin{bmatrix} 0.35 \\\\ 0.05 \\end{bmatrix}$，\n  - $\\mathbf{u}_5^{(1)} = \\begin{bmatrix} 0.15 \\\\ 0.15 \\end{bmatrix}$。\n\n测试用例 2（PLDS 的零后验协方差）：\n- 观测脉冲计数矩阵 $\\mathbf{Y}^{(2)} = \\mathbf{Y}^{(1)}$（与测试用例 1 相同）。\n- PLDS 变分后验均值 $\\mathbf{m}_t^{(2)} = \\mathbf{m}_t^{(1)}$（与测试用例 1 相同）。\n- PLDS 变分后验协方差 $\\mathbf{S}_t^{(2)}$ (对于 $t = 1, \\dots, 5$)：\n  - $\\mathbf{S}_t^{(2)} = \\begin{bmatrix} 0.0  0.0 \\\\ 0.0  0.0 \\end{bmatrix}$ 对于所有 $t$。\n- SPF 时间因子 $\\mathbf{u}_t^{(2)} = \\mathbf{m}_t^{(2)}$ 对于所有 $t$。\n\n测试用例 3（被保留神经元计数为零，PLDS 的非零后验协方差）：\n- 形状为 $T \\times N$ 的观测脉冲计数矩阵 $\\mathbf{Y}^{(3)}$：\n  - 第 1 行：$\\begin{bmatrix} 3  1  2  0 \\end{bmatrix}$，\n  - 第 2 行：$\\begin{bmatrix} 4  2  3  0 \\end{bmatrix}$，\n  - 第 3 行：$\\begin{bmatrix} 2  1  1  0 \\end{bmatrix}$，\n  - 第 4 行：$\\begin{bmatrix} 5  2  4  0 \\end{bmatrix}$，\n  - 第 5 行：$\\begin{bmatrix} 3  1  2  0 \\end{bmatrix}$。\n- PLDS 变分后验均值 $\\mathbf{m}_t^{(3)}$ (对于 $t = 1, \\dots, 5$)：\n  - $\\mathbf{m}_t^{(3)} = \\begin{bmatrix} 0.0 \\\\ 0.0 \\end{bmatrix}$ 对于所有 $t$。\n- PLDS 变分后验协方差 $\\mathbf{S}_t^{(3)}$ (对于 $t = 1, \\dots, 5$)：\n  - $\\mathbf{S}_t^{(3)} = \\begin{bmatrix} 0.3  0.0 \\\\ 0.0  0.3 \\end{bmatrix}$ 对于所有 $t$。\n- SPF 时间因子 $\\mathbf{u}_t^{(3)}$ (对于 $t = 1, \\dots, 5$)：\n  - $\\mathbf{u}_t^{(3)} = \\begin{bmatrix} 0.0 \\\\ 0.0 \\end{bmatrix}$ 对于所有 $t$。\n\n实现要求：\n- 对于 PLDS，将 $\\mathbf{m}_t$ 和 $\\mathbf{S}_t$ 视为从训练神经元（索引为 0 和 1 的神经元）获得的 $\\mathbf{x}_t$ 的拟合高斯变分后验。使用这些来计算被保留神经元（索引为 2 和 3）的期望。\n- 对于 SPF，使用 $\\mathbf{u}_t$ 作为确定性的拟合时间因子；相应地计算被保留神经元的期望。\n- 对于预测对数似然，仅使用被保留神经元的观测计数。\n- 你的程序应生成单行输出，其中包含按上述顺序排列的六个浮点数结果，格式为方括号括起来的逗号分隔列表（例如，$[\\text{结果}_1,\\text{结果}_2,\\dots]$）。不应打印任何其他文本。",
            "solution": "问题陈述已被解析和验证。所有定义在数学和科学上都是合理的，所有数据和参数都已提供，并且维度一致。该问题定义明确、客观，并且处于神经科学统计建模的既定框架内。它要求应用概率论的标准原理来推导和计算特定量，以比较两种常见的神经活动模型：泊松线性动态系统 (PLDS) 和静态泊松分解 (SPF)。该问题被认为是有效的。\n\n我们首先推导这两种模型的必要公式。评估是在一组被保留神经元（索引为 $n \\in \\mathcal{H}$）上，跨越多个时间窗（索引为 $t=1, \\dots, T$）进行的。\n\n**静态泊松分解 (SPF) 模型**\n\n在 SPF 模型中，潜在时间因子 $\\mathbf{u}_t \\in \\mathbb{R}^K$ 被视为确定性点估计。假设神经元 $n$ 在时间 $t$ 的脉冲计数 $y_{t,n}$ 服从泊松分布，其速率为 $\\tilde{\\lambda}_{t,n} = \\exp(\\mathbf{v}_n^\\top \\mathbf{u}_t + b_n)$，其中 $\\mathbf{v}_n$ 是神经元因子向量，$b_n$ 是对数速率偏移量。\n\n期望脉冲计数 (SPF)：\n泊松随机变量的期望值是其速率参数。由于右侧的所有变量都是确定性的，因此期望脉冲计数就是速率：\n$$\n\\mathbb{E}[y_{t,n}]_{\\mathrm{SPF}} = \\tilde{\\lambda}_{t,n} = \\exp(\\mathbf{v}_n^\\top \\mathbf{u}_t + b_n)\n$$\n\n预测对数似然 (SPF)：\n观测到脉冲计数 $y_{t,n}$ 的对数似然由泊松对数概率质量函数给出：\n$$\n\\log P(y_{t,n} | \\tilde{\\lambda}_{t,n}) = y_{t,n} \\log(\\tilde{\\lambda}_{t,n}) - \\tilde{\\lambda}_{t,n} - \\log(y_{t,n}!)\n$$\n代入 $\\log(\\tilde{\\lambda}_{t,n}) = \\mathbf{v}_n^\\top \\mathbf{u}_t + b_n$ 和 $\\tilde{\\lambda}_{t,n} = \\exp(\\mathbf{v}_n^\\top \\mathbf{u}_t + b_n)$，我们得到：\n$$\nL_{t,n}^{\\mathrm{SPF}} = y_{t,n}(\\mathbf{v}_n^\\top \\mathbf{u}_t + b_n) - \\exp(\\mathbf{v}_n^\\top \\mathbf{u}_t + b_n) - \\log(y_{t,n}!)\n$$\n由于 $\\mathbf{u}_t$ 是确定性的，这就是单个观测的预测对数似然。SPF 模型的总预测对数似然 $L_{\\mathrm{SPF}}$ 是 $L_{t,n}^{\\mathrm{SPF}}$ 在所有 $t \\in \\{1, \\dots, T\\}$ 和 $n \\in \\mathcal{H}$ 上的总和。\n\n**泊松线性动态系统 (PLDS) 模型**\n\n在 PLDS 模型中，潜在状态 $\\mathbf{x}_t \\in \\mathbb{R}^K$ 是一个随机变量。我们已知其变分后验分布是高斯分布，即 $\\mathbf{x}_t \\sim \\mathcal{N}(\\mathbf{m}_t, \\mathbf{S}_t)$。脉冲计数 $y_{t,n}$ 服从泊松分布，其速率为 $\\lambda_{t,n} = \\exp(\\mathbf{c}_n^\\top \\mathbf{x}_t + d_n)$。为了计算所需的量，我们必须对 $\\mathbf{x}_t$ 的后验分布求期望。\n\n我们定义指数的参数为 $\\alpha_{t,n} = \\mathbf{c}_n^\\top \\mathbf{x}_t + d_n$。由于 $\\alpha_{t,n}$ 是高斯随机变量 $\\mathbf{x}_t$ 的线性变换，因此 $\\alpha_{t,n}$ 也是一个高斯随机变量。其均值和方差为：\n$$\n\\mu_{\\alpha_{t,n}} = \\mathbb{E}[\\alpha_{t,n}] = \\mathbb{E}[\\mathbf{c}_n^\\top \\mathbf{x}_t + d_n] = \\mathbf{c}_n^\\top \\mathbb{E}[\\mathbf{x}_t] + d_n = \\mathbf{c}_n^\\top \\mathbf{m}_t + d_n\n$$\n$$\n\\sigma^2_{\\alpha_{t,n}} = \\mathrm{Var}[\\alpha_{t,n}] = \\mathrm{Var}[\\mathbf{c}_n^\\top \\mathbf{x}_t + d_n] = \\mathbf{c}_n^\\top \\mathrm{Var}[\\mathbf{x}_t] \\mathbf{c}_n = \\mathbf{c}_n^\\top \\mathbf{S}_t \\mathbf{c}_n\n$$\n因此，$\\alpha_{t,n} \\sim \\mathcal{N}(\\mu_{\\alpha_{t,n}}, \\sigma^2_{\\alpha_{t,n}})$。\n\n期望脉冲计数 (PLDS)：\n期望脉冲计数是速率参数 $\\lambda_{t,n}$ 在 $\\mathbf{x}_t$ 的后验分布上的期望。速率为 $\\lambda_{t,n} = e^{\\alpha_{t,n}}$。\n$$\n\\mathbb{E}[y_{t,n}]_{\\mathrm{PLDS}} = \\mathbb{E}_{\\mathbf{x}_t \\sim \\mathcal{N}(\\mathbf{m}_t, \\mathbf{S}_t)}[\\lambda_{t,n}] = \\mathbb{E}_{\\alpha_{t,n}}[e^{\\alpha_{t,n}}]\n$$\n这是高斯变量 $\\alpha_{t,n}$ 在 $s=1$ 处的矩生成函数。对于一个高斯变量 $Z \\sim \\mathcal{N}(\\mu, \\sigma^2)$，其矩生成函数为 $M_Z(s) = \\exp(s\\mu + \\frac{1}{2}s^2\\sigma^2)$。令 $s=1$，我们得到：\n$$\n\\mathbb{E}[y_{t,n}]_{\\mathrm{PLDS}} = \\exp(\\mu_{\\alpha_{t,n}} + \\frac{1}{2}\\sigma^2_{\\alpha_{t,n}}) = \\exp\\left( (\\mathbf{c}_n^\\top \\mathbf{m}_t + d_n) + \\frac{1}{2}\\mathbf{c}_n^\\top \\mathbf{S}_t \\mathbf{c}_n \\right)\n$$\n\n预测对数似然 (PLDS)：\n预测对数似然是对数似然函数关于 $\\mathbf{x}_t$ 的后验分布的期望。\n$$\nL_{t,n}^{\\mathrm{PLDS}} = \\mathbb{E}_{\\mathbf{x}_t \\sim \\mathcal{N}(\\mathbf{m}_t, \\mathbf{S}_t)}[\\log P(y_{t,n} | \\mathbf{x}_t)] = \\mathbb{E}_{\\mathbf{x}_t}[y_{t,n}(\\mathbf{c}_n^\\top \\mathbf{x}_t + d_n) - \\exp(\\mathbf{c}_n^\\top \\mathbf{x}_t + d_n) - \\log(y_{t,n}!)]\n$$\n根据期望的线性性质：\n$$\nL_{t,n}^{\\mathrm{PLDS}} = y_{t,n}\\mathbb{E}[\\mathbf{c}_n^\\top \\mathbf{x}_t + d_n] - \\mathbb{E}[\\exp(\\mathbf{c}_n^\\top \\mathbf{x}_t + d_n)] - \\log(y_{t,n}!)\n$$\n第一项的期望是 $\\mu_{\\alpha_{t,n}}$。第二项的期望是期望脉冲计数 $\\mathbb{E}[y_{t,n}]_{\\mathrm{PLDS}}$。\n$$\nL_{t,n}^{\\mathrm{PLDS}} = y_{t,n}(\\mathbf{c}_n^\\top \\mathbf{m}_t + d_n) - \\exp\\left( \\mathbf{c}_n^\\top \\mathbf{m}_t + d_n + \\frac{1}{2}\\mathbf{c}_n^\\top \\mathbf{S}_t \\mathbf{c}_n \\right) - \\log(y_{t,n}!)\n$$\nPLDS 模型的总预测对数似然 $L_{\\mathrm{PLDS}}$ 是 $L_{t,n}^{\\mathrm{PLDS}}$ 在所有 $t \\in \\{1, \\dots, T\\}$ 和 $n \\in \\mathcal{H}$ 上的总和。\n\n**摘要指标**\n\n我们需要为每个测试用例计算两个指标。\n\n1. 总预测对数似然之差，$L_{\\mathrm{PLDS}} - L_{\\mathrm{SPF}}$：\n$$\nL_{\\mathrm{PLDS}} - L_{\\mathrm{SPF}} = \\sum_{t=1}^T \\sum_{n \\in \\mathcal{H}} (L_{t,n}^{\\mathrm{PLDS}} - L_{t,n}^{\\mathrm{SPF}})\n$$\n注意，项 $\\log(y_{t,n}!)$ 在 $L_{t,n}^{\\mathrm{PLDS}}$ 和 $L_{t,n}^{\\mathrm{SPF}}$ 中是共有的，因此在差值中会抵消。因此，我们只需要计算：\n$$\nL_{t,n}^{\\mathrm{PLDS}} - L_{t,n}^{\\mathrm{SPF}} = \\left(y_{t,n}(\\mathbf{c}_n^\\top \\mathbf{m}_t + d_n) - \\mathbb{E}[y_{t,n}]_{\\mathrm{PLDS}}\\right) - \\left(y_{t,n}(\\mathbf{v}_n^\\top \\mathbf{u}_t + b_n) - \\mathbb{E}[y_{t,n}]_{\\mathrm{SPF}}\\right)\n$$\n\n2. 期望脉冲计数之间的平均绝对差：\n这是两个模型对期望脉冲数的预测之间的平均绝对差异，在所有被保留神经元和时间窗上取平均。\n$$\n\\mathrm{MAD}_{\\mathrm{counts}} = \\frac{1}{T \\cdot |\\mathcal{H}|} \\sum_{t=1}^T \\sum_{n \\in \\mathcal{H}} \\left| \\mathbb{E}[y_{t,n}]_{\\mathrm{PLDS}} - \\mathbb{E}[y_{t,n}]_{\\mathrm{SPF}} \\right|\n$$\n其中 $|\\mathcal{H}|$ 是被保留神经元的数量，即 $2$。用于求平均的总点数为 $T \\times |\\mathcal{H}| = 5 \\times 2 = 10$。\n\n有了这些公式，我们就可以继续进行实现和对每个测试用例的计算。",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    计算 PLDS 和 SPF 在被保留神经元数据上的模型比较指标。\n    \"\"\"\n\n    # --- 共享参数 ---\n    C = np.array([\n        [0.7, -0.3],\n        [-0.5, 0.6],\n        [0.2, 0.8],\n        [1.0, -0.4]\n    ])\n    d = np.array([-1.0, -0.7, -1.2, -0.5])\n    V = np.array([\n        [0.6, -0.2],\n        [-0.4, 0.5],\n        [0.15, 0.7],\n        [0.9, -0.1]\n    ])\n    b = np.array([-1.0, -0.7, -1.1, -0.6])\n    held_out_neurons = [2, 3]\n\n    # --- 测试用例数据 ---\n    \n    # 测试用例 1\n    Y1 = np.array([\n        [5, 2, 3, 0],\n        [6, 3, 4, 1],\n        [4, 1, 2, 0],\n        [7, 2, 5, 1],\n        [3, 2, 1, 0]\n    ])\n    m1 = np.array([\n        [0.2, -0.1],\n        [0.4, -0.05],\n        [0.35, 0.0],\n        [0.3, 0.1],\n        [0.1, 0.2]\n    ])\n    S1 = np.array([\n        [0.2, 0.0],\n        [0.0, 0.1]\n    ])\n    u1 = np.array([\n        [0.25, -0.15],\n        [0.45, -0.10],\n        [0.40, -0.05],\n        [0.35, 0.05],\n        [0.15, 0.15]\n    ])\n\n    # 测试用例 2\n    Y2 = Y1\n    m2 = m1\n    S2 = np.zeros((2, 2))\n    u2 = m2\n\n    # 测试用例 3\n    Y3 = np.array([\n        [3, 1, 2, 0],\n        [4, 2, 3, 0],\n        [2, 1, 1, 0],\n        [5, 2, 4, 0],\n        [3, 1, 2, 0]\n    ])\n    m3 = np.zeros((5, 2))\n    S3 = np.array([\n        [0.3, 0.0],\n        [0.0, 0.3]\n    ])\n    u3 = np.zeros((5, 2))\n\n    test_cases = [\n        (Y1, m1, S1, u1),\n        (Y2, m2, S2, u2),\n        (Y3, m3, S3, u3)\n    ]\n\n    all_results = []\n\n    for Y, M, S, U in test_cases:\n        total_ll_plds_part = 0.0\n        total_ll_spf_part = 0.0\n        exp_count_diffs = []\n        T = Y.shape[0]\n\n        for t in range(T):\n            m_t = M[t]\n            u_t = U[t]\n            S_t = S  # 在所有给定的测试用例中，S 不随时间变化\n\n            for n_idx in held_out_neurons:\n                y_tn = Y[t, n_idx]\n                c_n = C[n_idx]\n                d_n = d[n_idx]\n                v_n = V[n_idx]\n                b_n = b[n_idx]\n\n                # --- PLDS 计算 ---\n                mu_alpha = c_n @ m_t + d_n\n                var_alpha = c_n @ S_t @ c_n\n                \n                exp_count_plds = np.exp(mu_alpha + 0.5 * var_alpha)\n                ll_plds_part = y_tn * mu_alpha - exp_count_plds\n                total_ll_plds_part += ll_plds_part\n\n                # --- SPF 计算 ---\n                log_rate_spf = v_n @ u_t + b_n\n                exp_count_spf = np.exp(log_rate_spf)\n                \n                ll_spf_part = y_tn * log_rate_spf - exp_count_spf\n                total_ll_spf_part += ll_spf_part\n\n                # --- 指标计算 ---\n                exp_count_diffs.append(np.abs(exp_count_plds - exp_count_spf))\n\n        # 计算当前测试用例的摘要指标\n        ll_diff = total_ll_plds_part - total_ll_spf_part\n        mad_counts = np.mean(exp_count_diffs)\n        \n        all_results.append(ll_diff)\n        all_results.append(mad_counts)\n\n    # 格式化并打印最终输出\n    print(f\"[{','.join(map(str, all_results))}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "拟合模型后的最后一步是解释其揭示的科学内涵。本练习将指导您分析一个已学习到的非线性动力系统的行为，这是理解神经回路计算原理的关键一步。通过定位系统的不动点并分析它们的稳定性，您将学会如何从抽象的模型参数中提取出关于系统稳定活动模式的宝贵见解 。",
            "id": "4173330",
            "problem": "考虑一个用于神经群体活动的潜在自主连续时间动力学系统，该系统被建模为常微分方程（ODE）：$$\\frac{d\\mathbf{x}}{dt} = f_{\\theta}(\\mathbf{x}),$$ 其中，估计的向量场通过逐元素的双曲正切函数按分量定义为 $$f_{\\theta}(\\mathbf{x}) = \\mathbf{W}\\,\\tanh\\!\\big(\\mathbf{V}\\,\\mathbf{x} + \\mathbf{b}\\big) + \\mathbf{C}\\,\\mathbf{x} + \\mathbf{d},$$ 其参数元组为 $\\theta = (\\mathbf{W}, \\mathbf{V}, \\mathbf{C}, \\mathbf{b}, \\mathbf{d})$。一个候选不动点 $\\mathbf{x}^{\\star}$ 满足 $f_{\\theta}(\\mathbf{x}^{\\star}) = \\mathbf{0}$。在 $\\mathbf{x}^{\\star}$ 附近的局部线性化使用雅可比矩阵 $\\mathbf{J}_{f_{\\theta}}(\\mathbf{x}^{\\star})$，该矩阵根据多元微积分的核心原理（链式法则和线性化定义）定义。对于连续时间系统，局部稳定性由 $\\mathbf{J}_{f_{\\theta}}(\\mathbf{x}^{\\star})$ 的特征值决定：当且仅当所有特征值的实部都严格为负时，该不动点是渐近稳定的。本问题不涉及物理单位。\n\n您的任务是编写一个完整的程序，对每个提供的测试用例，完全从第一性原理出发执行以下步骤：\n- 使用雅可比矩阵的定义以及针对线性映射和逐元素 $\\tanh(\\cdot)$ 函数复合的链式法则，计算给定候选不动点处的雅可比矩阵 $\\mathbf{J}_{f_{\\theta}}(\\mathbf{x}^{\\star})$。\n- 计算 $\\mathbf{J}_{f_{\\theta}}(\\mathbf{x}^{\\star})$ 的特征值。\n- 通过检查所有特征值的实部是否严格为负来判断候选不动点的稳定性。\n- 为每个测试用例返回一个布尔结果：如果候选不动点是渐近稳定的，则返回 $\\,\\texttt{True}\\,$，否则返回 $\\,\\texttt{False}\\,$。\n\n双曲正切函数的逐元素导数是一个经过充分检验的数学事实：$$\\frac{d}{dz}\\tanh(z) = 1 - \\tanh^{2}(z)。$$ 利用此事实和链式法则来构建复合向量场的雅可比矩阵。\n\n测试套件。使用以下科学上一致的参数集。矩阵和向量已明确指定：\n\n- 测试用例 1（2 维，存在非线性，稳定）：\n  $$\\mathbf{W} = \\begin{bmatrix} -0.3  0 \\\\ 0  -0.3 \\end{bmatrix},\\quad \\mathbf{V} = \\begin{bmatrix} 1  0 \\\\ 0  1 \\end{bmatrix},\\quad \\mathbf{C} = \\begin{bmatrix} -0.4  0 \\\\ 0  -0.4 \\end{bmatrix},$$\n  $$\\mathbf{b} = \\begin{bmatrix} 0 \\\\ 0 \\end{bmatrix},\\quad \\mathbf{d} = \\begin{bmatrix} 0 \\\\ 0 \\end{bmatrix},\\quad \\mathbf{x}^{\\star} = \\begin{bmatrix} 0 \\\\ 0 \\end{bmatrix}。$$\n\n- 测试用例 2（2 维，鞍点型行为）：\n  $$\\mathbf{W} = \\begin{bmatrix} 0.2  0 \\\\ 0  0.2 \\end{bmatrix},\\quad \\mathbf{V} = \\begin{bmatrix} 3.0  0 \\\\ 0  0.2 \\end{bmatrix},\\quad \\mathbf{C} = \\begin{bmatrix} -0.1  0 \\\\ 0  -0.05 \\end{bmatrix},$$\n  $$\\mathbf{b} = \\begin{bmatrix} 0 \\\\ 0 \\end{bmatrix},\\quad \\mathbf{d} = \\begin{bmatrix} 0 \\\\ 0 \\end{bmatrix},\\quad \\mathbf{x}^{\\star} = \\begin{bmatrix} 0 \\\\ 0 \\end{bmatrix}。$$\n\n- 测试用例 3（3 维，纯线性不稳定）：\n  $$\\mathbf{W} = \\begin{bmatrix} 0  0  0 \\\\ 0  0  0 \\\\ 0  0  0 \\end{bmatrix},\\quad \\mathbf{V} = \\begin{bmatrix} 1  0  0 \\\\ 0  1  0 \\\\ 0  0  1 \\end{bmatrix},\\quad \\mathbf{C} = \\begin{bmatrix} 0.1  0  0 \\\\ 0  0.2  0 \\\\ 0  0  0.3 \\end{bmatrix},$$\n  $$\\mathbf{b} = \\begin{bmatrix} 0 \\\\ 0 \\\\ 0 \\end{bmatrix},\\quad \\mathbf{d} = \\begin{bmatrix} 0 \\\\ 0 \\\\ 0 \\end{bmatrix},\\quad \\mathbf{x}^{\\star} = \\begin{bmatrix} 0 \\\\ 0 \\\\ 0 \\end{bmatrix}。$$\n\n- 测试用例 4（2 维，边缘情况，有一个零特征值）：\n  $$\\mathbf{W} = \\begin{bmatrix} 0  0 \\\\ 0  0 \\end{bmatrix},\\quad \\mathbf{V} = \\begin{bmatrix} 1  0 \\\\ 0  1 \\end{bmatrix},\\quad \\mathbf{C} = \\begin{bmatrix} -0.1  0 \\\\ 0  0.0 \\end{bmatrix},$$\n  $$\\mathbf{b} = \\begin{bmatrix} 0 \\\\ 0 \\end{bmatrix},\\quad \\mathbf{d} = \\begin{bmatrix} 0 \\\\ 0 \\end{bmatrix},\\quad \\mathbf{x}^{\\star} = \\begin{bmatrix} 0 \\\\ 0 \\end{bmatrix}。$$\n\n- 测试用例 5（1 维，在非零参数处存在非平凡非线性，稳定）：\n  $$\\mathbf{W} = \\begin{bmatrix} -0.8 \\end{bmatrix},\\quad \\mathbf{V} = \\begin{bmatrix} 2.5 \\end{bmatrix},\\quad \\mathbf{C} = \\begin{bmatrix} -0.05 \\end{bmatrix},$$\n  $$\\mathbf{x}^{\\star} = \\begin{bmatrix} 0.5 \\end{bmatrix},\\quad \\mathbf{b} = \\begin{bmatrix} -0.05 \\end{bmatrix},\\quad \\mathbf{d} = \\begin{bmatrix} 0.6919232 \\end{bmatrix}。$$\n\n对于每个测试用例，按上述要求计算布尔稳定性结果。您的程序应生成单行输出，其中包含一个用方括号括起来的、以逗号分隔的结果列表，例如 $$[\\texttt{result1},\\texttt{result2},\\texttt{result3},\\texttt{result4},\\texttt{result5}].$$",
            "solution": "该问题要求对给定连续时间自主系统的候选不动点的局部渐近稳定性进行分析。系统的演化由常微分方程（ODE）$\\frac{d\\mathbf{x}}{dt} = f_{\\theta}(\\mathbf{x})$ 描述，其中状态向量 $\\mathbf{x}$ 代表神经群体活动，向量场 $f_{\\theta}(\\mathbf{x})$ 由参数 $\\theta = (\\mathbf{W}, \\mathbf{V}, \\mathbf{C}, \\mathbf{b}, \\mathbf{d})$ 参数化。如果点 $\\mathbf{x}^{\\star}$ 满足条件 $f_{\\theta}(\\mathbf{x}^{\\star}) = \\mathbf{0}$，则它是一个不动点。\n\n根据 Hartman-Grobman 定理和连续时间系统的线性化原理，不动点 $\\mathbf{x}^{\\star}$ 的局部稳定性由向量场的雅可比矩阵 $\\mathbf{J}_{f_{\\theta}}(\\mathbf{x})$ 在该不动点处的值的特征值决定。当且仅当雅可比矩阵 $\\mathbf{J}_{f_{\\theta}}(\\mathbf{x}^{\\star})$ 的所有特征值都具有严格为负的实部时，不动点 $\\mathbf{x}^{\\star}$ 是局部渐近稳定的。\n\n此任务的核心是推导雅可比矩阵 $\\mathbf{J}_{f_{\\theta}}(\\mathbf{x})$ 的解析形式，然后用它来评估每个提供的测试用例的稳定性。向量场由下式给出：\n$$f_{\\theta}(\\mathbf{x}) = \\mathbf{W}\\,\\tanh\\!\\big(\\mathbf{V}\\,\\mathbf{x} + \\mathbf{b}\\big) + \\mathbf{C}\\,\\mathbf{x} + \\mathbf{d}$$\n雅可比矩阵 $\\mathbf{J}_{f_{\\theta}}(\\mathbf{x})$ 是一个偏导数矩阵，其中元素 $(i, j)$ 由 $J_{ij} = \\frac{\\partial f_i}{\\partial x_j}$ 给出。由于微分算子的线性特性，向量函数之和的雅可比矩阵是它们各自雅可比矩阵之和。因此，我们可以分别分析每一项。\n\n1. 项 $\\mathbf{C}\\mathbf{x}$ 是 $\\mathbf{x}$ 的一个线性变换。它的雅可比矩阵就是矩阵 $\\mathbf{C}$。\n2. 项 $\\mathbf{d}$ 是一个常数向量。它关于 $\\mathbf{x}$ 的导数是零矩阵 $\\mathbf{0}$。\n3. 第一项 $\\mathbf{g}(\\mathbf{x}) = \\mathbf{W}\\,\\tanh(\\mathbf{V}\\,\\mathbf{x} + \\mathbf{b})$ 是一个复合函数。我们必须应用多元链式法则。让我们如下定义这个复合过程：\n- 令 $\\mathbf{u}(\\mathbf{x}) = \\mathbf{V}\\mathbf{x} + \\mathbf{b}$。这是一个仿射变换。它关于 $\\mathbf{x}$ 的雅可比矩阵是 $\\mathbf{J}_{\\mathbf{u}} = \\mathbf{V}$。\n- 令 $\\mathbf{h}(\\mathbf{u}) = \\tanh(\\mathbf{u})$，其中 $\\tanh$ 函数是逐元素应用的。第 $k$ 个分量是 $h_k(\\mathbf{u}) = \\tanh(u_k)$。偏导数 $\\frac{\\partial h_k}{\\partial u_l}$ 仅在 $k=l$ 时非零。因此，$\\mathbf{h}$ 关于 $\\mathbf{u}$ 的雅可比矩阵是一个对角矩阵。使用所给的恒等式 $\\frac{d}{dz}\\tanh(z) = 1 - \\tanh^2(z)$，该雅可比矩阵的对角线元素为 $\\frac{d h_k}{d u_k} = 1 - \\tanh^2(u_k)$。我们可以将此雅可比矩阵表示为：\n$$ \\mathbf{J}_{\\mathbf{h}}(\\mathbf{u}) = \\text{diag}\\left(1 - \\tanh^2(\\mathbf{u})\\right) $$\n其中 $\\text{diag}(\\cdot)$ 算子内的表达式是一个向量，其分量为 $1 - \\tanh^2(u_k)$。\n- 完整项是对 $\\mathbf{h}(\\mathbf{u}(\\mathbf{x}))$ 应用的线性变换 $\\mathbf{W}$。这个最终线性变换的雅可比矩阵就是 $\\mathbf{W}$。\n\n根据链式法则，复合函数 $\\mathbf{g}(\\mathbf{x}) = \\mathbf{W}(\\mathbf{h}(\\mathbf{u}(\\mathbf{x})))$ 的雅可比矩阵是其各组成部分在相应点求值的雅可比矩阵的乘积：\n$$ \\mathbf{J}_{\\mathbf{g}}(\\mathbf{x}) = \\mathbf{W} \\cdot \\mathbf{J}_{\\mathbf{h}}(\\mathbf{u}(\\mathbf{x})) \\cdot \\mathbf{J}_{\\mathbf{u}}(\\mathbf{x}) $$\n代入各部分雅可比矩阵的表达式，我们得到：\n$$ \\mathbf{J}_{\\mathbf{g}}(\\mathbf{x}) = \\mathbf{W} \\, \\text{diag}\\left(1 - \\tanh^2(\\mathbf{V}\\mathbf{x} + \\mathbf{b})\\right) \\, \\mathbf{V} $$\n\n结合所有项的雅可比矩阵，向量场 $f_{\\theta}(\\mathbf{x})$ 的完整雅可比矩阵为：\n$$ \\mathbf{J}_{f_{\\theta}}(\\mathbf{x}) = \\mathbf{W} \\, \\text{diag}\\left(1 - \\tanh^2(\\mathbf{V}\\mathbf{x} + \\mathbf{b})\\right) \\, \\mathbf{V} + \\mathbf{C} $$\n\n解决每个测试用例的算法步骤如下：\n1. 对于给定的参数集 $(\\mathbf{W}, \\mathbf{V}, \\mathbf{C}, \\mathbf{b}, \\mathbf{d})$ 和候选不动点 $\\mathbf{x}^{\\star}$，首先计算双曲正切函数的参数：$\\mathbf{u}^{\\star} = \\mathbf{V}\\mathbf{x}^{\\star} + \\mathbf{b}$。\n2. 构建对角矩阵 $\\mathbf{D}^{\\star} = \\text{diag}(1 - \\tanh^2(\\mathbf{u}^{\\star}))$，其中运算是逐元素执行的。\n3. 计算不动点处的数值雅可比矩阵：$\\mathbf{J}_{f_{\\theta}}(\\mathbf{x}^{\\star}) = \\mathbf{W}\\mathbf{D}^{\\star}\\mathbf{V} + \\mathbf{C}$。\n4. 计算 $\\mathbf{J}_{f_{\\theta}}(\\mathbf{x}^{\\star})$ 的特征值。\n5. 通过检查每个特征值的实部是否严格小于零来确定稳定性。如果此条件成立，则该不动点是渐近稳定的（$\\texttt{True}$）；否则，它不是（$\\texttt{False}$）。\n将对每个测试用例执行这一系列操作，以生成最终的结果列表。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the problem by analyzing the stability of fixed points for several\n    dynamical systems.\n    \"\"\"\n\n    test_cases = [\n        # Test case 1 (dimension 2, nonlinearity present, stable)\n        {\n            \"W\": np.array([[-0.3, 0], [0, -0.3]]),\n            \"V\": np.array([[1, 0], [0, 1]]),\n            \"C\": np.array([[-0.4, 0], [0, -0.4]]),\n            \"b\": np.array([[0], [0]]),\n            \"d\": np.array([[0], [0]]),\n            \"x_star\": np.array([[0], [0]]),\n        },\n        # Test case 2 (dimension 2, saddle-type behavior)\n        {\n            \"W\": np.array([[0.2, 0], [0, 0.2]]),\n            \"V\": np.array([[3.0, 0], [0, 0.2]]),\n            \"C\": np.array([[-0.1, 0], [0, -0.05]]),\n            \"b\": np.array([[0], [0]]),\n            \"d\": np.array([[0], [0]]),\n            \"x_star\": np.array([[0], [0]]),\n        },\n        # Test case 3 (dimension 3, purely linear unstable)\n        {\n            \"W\": np.array([[0, 0, 0], [0, 0, 0], [0, 0, 0]]),\n            \"V\": np.array([[1, 0, 0], [0, 1, 0], [0, 0, 1]]),\n            \"C\": np.array([[0.1, 0, 0], [0, 0.2, 0], [0, 0, 0.3]]),\n            \"b\": np.array([[0], [0], [0]]),\n            \"d\": np.array([[0], [0], [0]]),\n            \"x_star\": np.array([[0], [0], [0]]),\n        },\n        # Test case 4 (dimension 2, marginal with a zero eigenvalue)\n        {\n            \"W\": np.array([[0, 0], [0, 0]]),\n            \"V\": np.array([[1, 0], [0, 1]]),\n            \"C\": np.array([[-0.1, 0], [0, 0.0]]),\n            \"b\": np.array([[0], [0]]),\n            \"d\": np.array([[0], [0]]),\n            \"x_star\": np.array([[0], [0]]),\n        },\n        # Test case 5 (dimension 1, nontrivial nonlinearity at nonzero argument, stable)\n        {\n            \"W\": np.array([[-0.8]]),\n            \"V\": np.array([[2.5]]),\n            \"C\": np.array([[-0.05]]),\n            \"b\": np.array([[-0.05]]),\n            \"d\": np.array([[0.6919232]]),\n            \"x_star\": np.array([[0.5]]),\n        },\n    ]\n\n    def check_stability(params):\n        \"\"\"\n        Computes the Jacobian and checks the stability of the given fixed point.\n\n        Args:\n            params (dict): A dictionary containing the parameters W, V, C, b, and x_star.\n\n        Returns:\n            bool: True if the fixed point is asymptotically stable, False otherwise.\n        \"\"\"\n        W = params[\"W\"]\n        V = params[\"V\"]\n        C = params[\"C\"]\n        b = params[\"b\"]\n        x_star = params[\"x_star\"]\n\n        # 1. Compute the argument of the tanh function\n        u_star = V @ x_star + b\n\n        # 2. Compute the diagonal elements of the Jacobian of the nonlinearity\n        # The derivative of tanh(z) is 1 - tanh^2(z).\n        # We need to flatten the result for np.diag as it expects a 1D array.\n        tanh_deriv_vec = 1 - np.tanh(u_star)**2\n        D_star = np.diag(tanh_deriv_vec.flatten())\n\n        # 3. Compute the full Jacobian matrix at the fixed point\n        # J = W * D * V + C\n        J = W @ D_star @ V + C\n\n        # 4. Calculate the eigenvalues of the Jacobian\n        eigenvalues = np.linalg.eigvals(J)\n        \n        # 5. Check if all eigenvalues have strictly negative real parts\n        is_stable = np.all(np.real(eigenvalues)  0)\n\n        return is_stable\n\n    results = []\n    for case in test_cases:\n        result = check_stability(case)\n        results.append(result)\n\n    # Format the final output as a comma-separated list of lowercase strings.\n    print(f\"[{','.join(str(r).lower() for r in results)}]\")\n\nsolve()\n```"
        }
    ]
}