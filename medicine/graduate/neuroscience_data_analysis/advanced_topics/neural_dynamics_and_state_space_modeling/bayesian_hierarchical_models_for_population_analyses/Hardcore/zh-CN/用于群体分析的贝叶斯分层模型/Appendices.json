{
    "hands_on_practices": [
        {
            "introduction": "在神经科学中，对神经元发放的脉冲计数进行建模至关重要。本练习将指导您在一个经典的层次模型中推导后验分布，该模型使用泊松分布对脉冲计数进行建模，并使用伽马分布作为其共轭先验。掌握这种推导是贝叶斯分析的一项基本技能，它清晰地展示了共轭性如何简化计算，并为理解更复杂的模型奠定了基础 。",
            "id": "4141070",
            "problem": "在一个跨多个记录区间的单神经元脉冲序列的群体分析中，假设神经元 $i$ 在已知暴露时长 $\\{T_{it}\\}_{t=1}^{n_i}$（单位为秒）的观测窗口内产生脉冲计数 $\\{y_{it}\\}_{t=1}^{n_i}$。假设以下生成模型基于脉冲计数的标准点过程近似：以神经元特异性发放率参数 $\\lambda_i$ 为条件，跨区间的脉冲计数是条件独立的，并服从泊松随机变量分布，其均值与暴露时长成正比，即 $y_{it} \\mid \\lambda_i, T_{it} \\sim \\text{Poisson}(\\lambda_i T_{it})$。在群体水平上，为 $\\lambda_i$ 设置一个伽马先验，其形状参数为 $\\alpha$，速率参数为 $\\beta$，记为 $\\lambda_i \\mid \\alpha,\\beta \\sim \\text{Gamma}(\\alpha,\\beta)$，其中概率密度函数为 $p(\\lambda_i \\mid \\alpha,\\beta) = \\frac{\\beta^{\\alpha}}{\\Gamma(\\alpha)} \\lambda_i^{\\alpha-1} \\exp(-\\beta \\lambda_i)$，对于 $\\lambda_i > 0$。将 $\\alpha$ 和 $\\beta$ 视为所有神经元共享的已知超参数。使用贝叶斯法则以及泊松概率质量函数和伽马概率密度函数的标准形式，推导后验分布 $p(\\lambda_i \\mid \\{y_{it}\\}_{t=1}^{n_i}, \\{T_{it}\\}_{t=1}^{n_i}, \\alpha, \\beta)$，并将其识别为一个已命名的参数族成员。用一个单独的解析表达式给出最终答案，该表达式给出分布族名称及其参数，参数用 $\\alpha$、$\\beta$、$\\sum_{t=1}^{n_i} y_{it}$ 和 $\\sum_{t=1}^{n_i} T_{it}$ 表示。不要进行数值简化。你的最终答案必须是一个单一的闭式解析表达式。",
            "solution": "首先验证问题，以确保其具有科学依据、良定且客观。\n\n**步骤 1：提取已知条件**\n-   神经元 $i$ 的数据：脉冲计数 $\\{y_{it}\\}_{t=1}^{n_i}$ 和暴露时长 $\\{T_{it}\\}_{t=1}^{n_i}$。\n-   单个观测的似然模型：$y_{it} \\mid \\lambda_i, T_{it} \\sim \\text{Poisson}(\\lambda_i T_{it})$。\n-   条件独立性：在给定神经元特异性发放率参数 $\\lambda_i$ 的情况下，脉冲计数 $y_{it}$ 是条件独立的。\n-   发放率的先验模型：$\\lambda_i \\mid \\alpha,\\beta \\sim \\text{Gamma}(\\alpha,\\beta)$。\n-   先验的概率密度函数(PDF)：$p(\\lambda_i \\mid \\alpha,\\beta) = \\frac{\\beta^{\\alpha}}{\\Gamma(\\alpha)} \\lambda_i^{\\alpha-1} \\exp(-\\beta \\lambda_i)$，对于 $\\lambda_i > 0$。\n-   超参数：$\\alpha$ 和 $\\beta$ 是已知的常数。\n-   目标：推导后验分布 $p(\\lambda_i \\mid \\{y_{it}\\}_{t=1}^{n_i}, \\{T_{it}\\}_{t=1}^{n_i}, \\alpha, \\beta)$ 并确定其所属族和参数。\n\n**步骤 2：使用提取的已知条件进行验证**\n该问题具有科学依据，采用了标准的泊松模型来描述神经脉冲计数，并使用伽马先验，这是泊松速率参数的共轭先验。这是贝叶斯统计和计算神经科学中的一个典型问题。该问题是良定的，因为所有必要的组成部分（似然、先验、数据）都已指定，从而可以得到唯一的后验分布。语言客观且数学上精确。未发现任何缺陷。\n\n**步骤 3：结论与行动**\n问题有效。将提供完整解答。\n\n目标是为单个神经元 $i$ 推导其发放率参数 $\\lambda_i$ 的后验分布。设神经元 $i$ 的完整数据集表示为 $D_i = (\\{y_{it}\\}_{t=1}^{n_i}, \\{T_{it}\\}_{t=1}^{n_i})$。我们应用贝叶斯定理，该定理指出后验分布与似然和先验分布的乘积成正比。\n\n$$\np(\\lambda_i \\mid D_i, \\alpha, \\beta) \\propto p(D_i \\mid \\lambda_i) \\times p(\\lambda_i \\mid \\alpha, \\beta)\n$$\n\n首先，我们构建似然函数 $p(D_i \\mid \\lambda_i)$。问题陈述，在给定 $\\lambda_i$ 的情况下，脉冲计数 $y_{it}$ 是条件独立的泊松随机变量。单个观测 $y_{it}$ 的概率质量函数 (PMF) 为：\n$$\np(y_{it} \\mid \\lambda_i, T_{it}) = \\frac{(\\lambda_i T_{it})^{y_{it}} \\exp(-\\lambda_i T_{it})}{y_{it}!}\n$$\n由于条件独立性，神经元 $i$ 的所有 $n_i$ 个观测的总似然是各个 PMF 的乘积：\n$$\nL(\\lambda_i; D_i) = p(D_i \\mid \\lambda_i) = \\prod_{t=1}^{n_i} p(y_{it} \\mid \\lambda_i, T_{it}) = \\prod_{t=1}^{n_i} \\frac{(\\lambda_i T_{it})^{y_{it}} \\exp(-\\lambda_i T_{it})}{y_{it}!}\n$$\n在贝叶斯推断中，我们关心的是似然函数相对于参数 $\\lambda_i$ 的函数形式。因此，我们可以丢弃任何不依赖于 $\\lambda_i$ 的项，因为它们将被吸收到归一化常数中。\n$$\nL(\\lambda_i; D_i) \\propto \\prod_{t=1}^{n_i} (\\lambda_i T_{it})^{y_{it}} \\exp(-\\lambda_i T_{it})\n$$\n我们可以分离包含 $\\lambda_i$ 的项并简化乘积：\n$$\nL(\\lambda_i; D_i) \\propto \\prod_{t=1}^{n_i} \\lambda_i^{y_{it}} \\cdot \\prod_{t=1}^{n_i} T_{it}^{y_{it}} \\cdot \\prod_{t=1}^{n_i} \\exp(-\\lambda_i T_{it})\n$$\n再次，丢弃不是 $\\lambda_i$ 函数的项（具体来说是 $\\prod T_{it}^{y_{it}}$）：\n$$\nL(\\lambda_i; D_i) \\propto \\left( \\prod_{t=1}^{n_i} \\lambda_i^{y_{it}} \\right) \\left( \\prod_{t=1}^{n_i} \\exp(-\\lambda_i T_{it}) \\right)\n$$\n利用指数的性质，这可以简化为：\n$$\nL(\\lambda_i; D_i) \\propto \\lambda_i^{\\sum_{t=1}^{n_i} y_{it}} \\exp\\left(-\\lambda_i \\sum_{t=1}^{n_i} T_{it}\\right)\n$$\n接下来，我们考虑 $\\lambda_i$ 的先验分布，它被给定为一个形状为 $\\alpha$、速率为 $\\beta$ 的伽马分布：\n$$\np(\\lambda_i \\mid \\alpha, \\beta) = \\frac{\\beta^{\\alpha}}{\\Gamma(\\alpha)} \\lambda_i^{\\alpha-1} \\exp(-\\beta \\lambda_i)\n$$\n该先验分布的核，包含了所有对 $\\lambda_i$ 的依赖关系，是：\n$$\np(\\lambda_i \\mid \\alpha, \\beta) \\propto \\lambda_i^{\\alpha-1} \\exp(-\\beta \\lambda_i)\n$$\n现在，我们将似然的核与先验的核相乘以求得后验分布的核：\n$$\np(\\lambda_i \\mid D_i, \\alpha, \\beta) \\propto \\left( \\lambda_i^{\\sum_{t=1}^{n_i} y_{it}} \\exp\\left(-\\lambda_i \\sum_{t=1}^{n_i} T_{it}\\right) \\right) \\times \\left( \\lambda_i^{\\alpha-1} \\exp(-\\beta \\lambda_i) \\right)\n$$\n合并同底项：\n$$\np(\\lambda_i \\mid D_i, \\alpha, \\beta) \\propto \\lambda_i^{\\left(\\sum_{t=1}^{n_i} y_{it}\\right) + (\\alpha-1)} \\exp\\left(-\\lambda_i \\sum_{t=1}^{n_i} T_{it} - \\beta \\lambda_i\\right)\n$$\n$$\np(\\lambda_i \\mid D_i, \\alpha, \\beta) \\propto \\lambda_i^{\\left(\\alpha + \\sum_{t=1}^{n_i} y_{it}\\right) - 1} \\exp\\left(-\\left(\\beta + \\sum_{t=1}^{n_i} T_{it}\\right) \\lambda_i\\right)\n$$\n这个得到的函数形式是伽马分布的核。一个服从形状参数为 $\\alpha'$、速率参数为 $\\beta'$ 的伽马分布的随机变量 $X$，记为 $X \\sim \\text{Gamma}(\\alpha', \\beta')$，其概率密度函数正比于 $x^{\\alpha'-1}\\exp(-\\beta'x)$。\n\n通过将此形式与我们的后验核进行比较，我们可以确定后验分布的参数。\n后验形状参数 $\\alpha'$ 是：\n$$\n\\alpha' = \\alpha + \\sum_{t=1}^{n_i} y_{it}\n$$\n后验速率参数 $\\beta'$ 是：\n$$\n\\beta' = \\beta + \\sum_{t=1}^{n_i} T_{it}\n$$\n因此，$\\lambda_i$ 的后验分布是具有这些更新后参数的伽马分布。这个结果展示了伽马先验和泊松似然之间的共轭性。后验分布是：\n$$\n\\lambda_i \\mid D_i, \\alpha, \\beta \\sim \\text{Gamma}\\left(\\alpha + \\sum_{t=1}^{n_i} y_{it}, \\beta + \\sum_{t=1}^{n_i} T_{it}\\right)\n$$\n参数的更新是直观的：后验形状是先验形状加上观测到的总脉冲数，后验速率是先验速率加上总暴露时长。",
            "answer": "$$\n\\boxed{\\text{Gamma}\\left(\\alpha + \\sum_{t=1}^{n_i} y_{it}, \\beta + \\sum_{t=1}^{n_i} T_{it}\\right)}\n$$"
        },
        {
            "introduction": "在计算出后验分布之后，我们来探索其最强大的一个推论：收缩（shrinkage）。本练习通过一个假设但极具启发性的场景，展示了贝叶斯估计如何系统地将个体估计“拉向”群体平均值。您将通过计算发现，这种收缩效应甚至可以逆转从原始数据中观察到的效应排序，这凸显了层次模型通过在群体成员之间“借用统计力量”来提供更稳健估计的能力 。",
            "id": "4141091",
            "problem": "考虑在一个系统神经科学实验中，在单一刺激条件下记录的神经元群体的诱发发放率测量值。对于每个单元 $i \\in \\{A,B,C\\}$，用 $\\theta_i$（单位：$\\mathrm{spikes/s}$）表示其潜在诱发发放率，用 $y_i$（单位：$\\mathrm{spikes/s}$）表示其在多次试验中观测到的样本均值。假设一个高斯层级模型，其中潜在诱发率围绕一个已知的群体均值 $ \\mu $ 是可交换的，其先验方差为 $ \\tau^2 $，并且观测值受到具有已知方差的独立高斯测量噪声的干扰：\n- 先验分布：$ \\theta_i \\mid \\mu \\sim \\mathcal{N}(\\mu, \\tau^2) $。\n- 似然函数：$ y_i \\mid \\theta_i \\sim \\mathcal{N}(\\theta_i, \\sigma_i^2) $。\n假设根据一个大型历史数据集，已知群体均值为 $ \\mu = 20 $（单位：$\\mathrm{spikes/s}$），并且当前实验得到了以下观测均值和测量方差：\n- 单元 $A$：$ y_A = 12 $，$ \\sigma_A^2 = 9 $。\n- 单元 $B$：$ y_B = 15 $，$ \\sigma_B^2 = 1 $。\n- 单元 $C$：$ y_C = 40 $，$ \\sigma_C^2 = 4 $。\n所有量 $ y_i $ 和 $ \\sigma_i^2 $ 的单位均如上所述。朴素差异 $ y_B - y_A $ 是正的。从贝叶斯定理以及高斯似然和高斯先验的共轭性出发，推导每个单元 $ i $ 的后验均值 $ \\mathbb{E}[\\theta_i \\mid y_i, \\mu, \\tau^2] $，用 $ \\tau^2 $ 表示后验差异 $ \\mathbb{E}[\\theta_B \\mid y_B, \\mu, \\tau^2] - \\mathbb{E}[\\theta_A \\mid y_A, \\mu, \\tau^2] $，并解析地证明存在一个临界先验方差 $ \\tau_{\\star}^2 $，使得单元 $A$ 和 $B$ 的后验均值相等。计算上述给定数值的临界值 $ \\tau_{\\star}^2 $，并解释对于 $ \\tau^2  \\tau_{\\star}^2 $ 的情况，收缩效应如何反转了朴素差异的方向。将 $ \\tau_{\\star}^2 $ 的最终数值答案以 $(\\mathrm{spikes/s})^2$ 为单位表示，并四舍五入到四位有效数字。",
            "solution": "问题陈述提出了贝叶斯统计分析中一个标准的、定义明确的问题，特别是在神经科学数据的层级模型背景下。所有参数和分布都已明确指定，该模型在科学上是合理的且被普遍使用，问题在数学上是可解的。所提供的数据是内部一致的。因此，该问题被认为是有效的，可以推导出完整的解。\n\n该问题描述了一个高斯-高斯层级模型。对于每个单元 $i$，潜在发放率 $\\theta_i$ 的先验分布由下式给出\n$$ p(\\theta_i \\mid \\mu, \\tau^2) = \\frac{1}{\\sqrt{2\\pi\\tau^2}} \\exp\\left(-\\frac{(\\theta_i - \\mu)^2}{2\\tau^2}\\right) $$\n这是一个正态分布 $\\mathcal{N}(\\mu, \\tau^2)$。在给定潜在发放率 $\\theta_i$ 的情况下，观测到样本均值发放率 $y_i$ 的似然函数为\n$$ p(y_i \\mid \\theta_i, \\sigma_i^2) = \\frac{1}{\\sqrt{2\\pi\\sigma_i^2}} \\exp\\left(-\\frac{(y_i - \\theta_i)^2}{2\\sigma_i^2}\\right) $$\n这是一个正态分布 $\\mathcal{N}(\\theta_i, \\sigma_i^2)$。\n\n我们的首要任务是推导在给定观测值 $y_i$ 和超参数 $\\mu$、$\\tau^2$ 的情况下 $\\theta_i$ 的后验分布。根据贝叶斯定理，后验概率密度与似然和先验的乘积成正比：\n$$ p(\\theta_i \\mid y_i, \\mu, \\tau^2) \\propto p(y_i \\mid \\theta_i, \\sigma_i^2) p(\\theta_i \\mid \\mu, \\tau^2) $$\n由于两个高斯分布的乘积与另一个高斯分布成正比（这一性质称为共轭性），后验分布 $p(\\theta_i \\mid y_i, \\mu, \\tau^2)$ 也将是一个高斯分布。我们可以通过检查乘积的指数部分来找到其参数。\n$$ p(\\theta_i \\mid y_i, \\mu, \\tau^2) \\propto \\exp\\left(-\\frac{(y_i - \\theta_i)^2}{2\\sigma_i^2}\\right) \\exp\\left(-\\frac{(\\theta_i - \\mu)^2}{2\\tau^2}\\right) $$\n$$ \\propto \\exp\\left( -\\frac{1}{2} \\left[ \\frac{(\\theta_i - y_i)^2}{\\sigma_i^2} + \\frac{(\\theta_i - \\mu)^2}{\\tau^2} \\right] \\right) $$\n为了找到后验均值，我们对指数中的 $\\theta_i$ 进行配方。设后验分布为 $\\mathcal{N}(\\hat{\\theta}_i, \\sigma_{\\text{post},i}^2)$。指数部分将具有 $-\\frac{(\\theta_i - \\hat{\\theta}_i)^2}{2\\sigma_{\\text{post},i}^2}$ 的形式。展开括号中的项：\n$$ \\frac{\\theta_i^2 - 2\\theta_i y_i + y_i^2}{\\sigma_i^2} + \\frac{\\theta_i^2 - 2\\theta_i \\mu + \\mu^2}{\\tau^2} $$\n合并关于 $\\theta_i^2$ 和 $\\theta_i$ 的项：\n$$ \\theta_i^2 \\left(\\frac{1}{\\sigma_i^2} + \\frac{1}{\\tau^2}\\right) - 2\\theta_i \\left(\\frac{y_i}{\\sigma_i^2} + \\frac{\\mu}{\\tau^2}\\right) + \\dots $$\n后验精度（方差的倒数）是各个精度的和：\n$$ \\frac{1}{\\sigma_{\\text{post},i}^2} = \\frac{1}{\\sigma_i^2} + \\frac{1}{\\tau^2} $$\n后验均值 $\\hat{\\theta}_i = \\mathbb{E}[\\theta_i \\mid y_i, \\mu, \\tau^2]$ 由 $-2\\theta_i$ 的系数与 $\\theta_i^2$ 的系数之比给出：\n$$ \\hat{\\theta}_i = \\frac{\\frac{y_i}{\\sigma_i^2} + \\frac{\\mu}{\\tau^2}}{\\frac{1}{\\sigma_i^2} + \\frac{1}{\\tau^2}} $$\n这表明后验均值是观测数据 $y_i$ 和先验均值 $\\mu$ 的精度加权平均。通过将分子和分母同乘以 $\\sigma_i^2 \\tau^2$，我们得到一个更方便的形式：\n$$ \\hat{\\theta}_i = \\frac{y_i \\tau^2 + \\mu \\sigma_i^2}{\\tau^2 + \\sigma_i^2} $$\n这个表达式可以解释为一个加权平均：\n$$ \\hat{\\theta}_i = \\left(\\frac{\\tau^2}{\\sigma_i^2 + \\tau^2}\\right) y_i + \\left(\\frac{\\sigma_i^2}{\\sigma_i^2 + \\tau^2}\\right) \\mu = (1 - B_i) y_i + B_i \\mu $$\n其中 $B_i = \\frac{\\sigma_i^2}{\\sigma_i^2 + \\tau^2}$ 是“收缩因子”，它量化了估计值从观测值 $y_i$ 向先验均值 $\\mu$ 收缩的程度。\n\n问题要求的是单元 $A$ 和 $B$ 的后验均值相等的条件。令 $\\hat{\\theta}_A = \\mathbb{E}[\\theta_A \\mid y_A, \\mu, \\tau^2]$ 且 $\\hat{\\theta}_B = \\mathbb{E}[\\theta_B \\mid y_B, \\mu, \\tau^2]$。我们设 $\\hat{\\theta}_A = \\hat{\\theta}_B$：\n$$ \\frac{y_A \\tau^2 + \\mu \\sigma_A^2}{\\tau^2 + \\sigma_A^2} = \\frac{y_B \\tau^2 + \\mu \\sigma_B^2}{\\tau^2 + \\sigma_B^2} $$\n为了找到使该等式成立的临界方差 $\\tau_{\\star}^2$，我们求解 $\\tau^2$。\n$$ (y_A \\tau^2 + \\mu \\sigma_A^2)(\\tau^2 + \\sigma_B^2) = (y_B \\tau^2 + \\mu \\sigma_B^2)(\\tau^2 + \\sigma_A^2) $$\n$$ y_A (\\tau^2)^2 + y_A \\tau^2 \\sigma_B^2 + \\mu \\sigma_A^2 \\tau^2 + \\mu \\sigma_A^2 \\sigma_B^2 = y_B (\\tau^2)^2 + y_B \\tau^2 \\sigma_A^2 + \\mu \\sigma_B^2 \\tau^2 + \\mu \\sigma_B^2 \\sigma_A^2 $$\n项 $\\mu \\sigma_A^2 \\sigma_B^2$ 在两边被消掉。我们重新整理，合并关于 $(\\tau^2)^2$ 和 $\\tau^2$ 的项：\n$$ (\\tau^2)^2 (y_A - y_B) + \\tau^2 (y_A \\sigma_B^2 + \\mu \\sigma_A^2 - y_B \\sigma_A^2 - \\mu \\sigma_B^2) = 0 $$\n$$ \\tau^2 \\left[ \\tau^2 (y_A - y_B) + (y_A \\sigma_B^2 - y_B \\sigma_A^2 + \\mu \\sigma_A^2 - \\mu \\sigma_B^2) \\right] = 0 $$\n一个解是平凡情况 $\\tau^2 = 0$。非平凡解 $\\tau_{\\star}^2$ 可通过将括号中的项设为零来求得：\n$$ \\tau_{\\star}^2 (y_A - y_B) = - (y_A \\sigma_B^2 - y_B \\sigma_A^2 + \\mu \\sigma_A^2 - \\mu \\sigma_B^2) $$\n$$ \\tau_{\\star}^2 (y_A - y_B) = y_B \\sigma_A^2 - y_A \\sigma_B^2 - \\mu \\sigma_A^2 + \\mu \\sigma_B^2 $$\n$$ \\tau_{\\star}^2 (y_A - y_B) = \\sigma_A^2 (y_B - \\mu) - \\sigma_B^2 (y_A - \\mu) $$\n解出 $\\tau_{\\star}^2$：\n$$ \\tau_{\\star}^2 = \\frac{\\sigma_A^2 (y_B - \\mu) - \\sigma_B^2 (y_A - \\mu)}{y_A - y_B} $$\n这解析地表明，只要该临界方差为正，它就存在。我们现在代入给定的数值： $\\mu = 20$，$ y_A = 12 $，$ \\sigma_A^2 = 9 $，$ y_B = 15 $，$ \\sigma_B^2 = 1 $。\n$$ \\tau_{\\star}^2 = \\frac{9(15 - 20) - 1(12 - 20)}{12 - 15} $$\n$$ \\tau_{\\star}^2 = \\frac{9(-5) - 1(-8)}{-3} = \\frac{-45 + 8}{-3} = \\frac{-37}{-3} = \\frac{37}{3} $$\n由于 $\\tau_{\\star}^2 = 37/3  0$，一个物理上有意义的临界方差是存在的。其数值约为 $12.3333...$ $(\\mathrm{spikes/s})^2$。四舍五入到四位有效数字，即为 $12.33$ $(\\mathrm{spikes/s})^2$。\n\n最后，我们必须解释在 $\\tau^2  \\tau_{\\star}^2$ 时朴素差异的反转。朴素差异为 $y_B - y_A = 15 - 12 = 3  0$。我们想要分析后验差异 $\\hat{\\theta}_B - \\hat{\\theta}_A$ 的符号。\n$$ \\hat{\\theta}_B - \\hat{\\theta}_A = \\frac{y_B \\tau^2 + \\mu \\sigma_B^2}{\\tau^2 + \\sigma_B^2} - \\frac{y_A \\tau^2 + \\mu \\sigma_A^2}{\\tau^2 + \\sigma_A^2} $$\n公分母 $(\\tau^2 + \\sigma_B^2)(\\tau^2 + \\sigma_A^2)$ 是正的。差异的符号由分子决定：\n$$ N(\\tau^2) = (y_B \\tau^2 + \\mu \\sigma_B^2)(\\tau^2 + \\sigma_A^2) - (y_A \\tau^2 + \\mu \\sigma_A^2)(\\tau^2 + \\sigma_B^2) $$\n这正是我们之前设为零的表达式的负值。根据前面的推导：\n$$ N(\\tau^2) = \\tau^2 (\\tau^2(y_B - y_A) - [\\sigma_A^2(y_A - \\mu) - \\sigma_B^2(y_B - \\mu)]) $$\n使用 $\\tau_{\\star}^2$ 的定义：$\\tau_{\\star}^2 (y_A - y_B) = \\sigma_A^2(y_B - \\mu) - \\sigma_B^2(y_A - \\mu)$，这等价于 $\\tau_{\\star}^2 (y_B - y_A) = -[\\sigma_A^2(y_A - \\mu) - \\sigma_B^2(y_B - \\mu)]$。\n将此代入 $N(\\tau^2)$ 的表达式中：\n$$ N(\\tau^2) = \\tau^2 (\\tau^2(y_B - y_A) - [-\\tau_{\\star}^2(y_B - y_A)]) $$\n$$ N(\\tau^2) = \\tau^2 (y_B - y_A) (\\tau^2 - \\tau_{\\star}^2) $$\n$\\hat{\\theta}_B - \\hat{\\theta}_A$ 的符号与 $N(\\tau^2)$ 的符号相同。我们已知 $y_B - y_A = 3  0$。并且 $\\tau^2 \\ge 0$。因此，符号由项 $(\\tau^2 - \\tau_{\\star}^2)$ 决定。\n对于 $\\tau^2  \\tau_{\\star}^2$，项 $(\\tau^2 - \\tau_{\\star}^2)$ 为负。\n因此，$N(\\tau^2)$ 的符号是 $(+)(+)(-) = (-)$。\n这意味着对于 $\\tau^2  \\tau_{\\star}^2$，我们有 $\\hat{\\theta}_B - \\hat{\\theta}_A  0$，即 $\\hat{\\theta}_B  \\hat{\\theta}_A$。\n朴素差异 $y_B > y_A$ 被反转为 $\\hat{\\theta}_B  \\hat{\\theta}_A$。这种现象是差异性收缩的结果。两个观测均值 $y_A = 12$ 和 $y_B = 15$ 都低于群体均值 $\\mu=20$。贝叶斯模型将两个估计值都向 $\\mu$ 收缩，从而增加了它们的值。这种收缩的强度由收缩因子 $B_i = \\sigma_i^2/(\\sigma_i^2 + \\tau^2)$ 决定。我们比较单元 $A$ 和 $B$ 的收缩因子：\n$$ B_A = \\frac{9}{9+\\tau^2} \\quad \\text{和} \\quad B_B = \\frac{1}{1+\\tau^2} $$\n由于 $9(1+\\tau^2) = 9+9\\tau^2  9+\\tau^2 = 1(9+\\tau^2)$，因此可得 $\\frac{9}{9+\\tau^2}  \\frac{1}{1+\\tau^2}$，所以 $B_A  B_B$。\n单元 $A$ 的测量方差（$\\sigma_A^2=9$）远大于单元 $B$ 的测量方差（$\\sigma_B^2=1$），表明其测量结果不太可靠。因此，其后验均值 $\\hat{\\theta}_A$ 更强烈地向群体均值 $\\mu$ 收缩。由于 $y_A$ 和 $y_B$ 都低于 $\\mu$，$\\hat{\\theta}_A$ 从 $12$ 被“拉高”的幅度比 $\\hat{\\theta}_B$ 从 $15$ 被拉高的幅度更大。当先验分布提供足够的信息时（即 $\\tau^2$ 很小，具体来说是 $\\tau^2  \\tau_{\\star}^2$），这种差异性的拉动足够强，导致 $\\hat{\\theta}_A$ 超过 $\\hat{\\theta}_B$，从而反转了在原始数据中观察到的差异方向。\n后验差异由下式给出\n$$ \\hat{\\theta}_B - \\hat{\\theta}_A = \\frac{\\tau^2 (y_B - y_A) (\\tau^2 - \\tau_{\\star}^2)}{(\\tau^2 + \\sigma_A^2)(\\tau^2 + \\sigma_B^2)} $$",
            "answer": "$$\\boxed{12.33}$$"
        },
        {
            "introduction": "现实世界中的神经科学模型，例如广义线性模型（GLMs），往往因为不具备共轭性而无法精确求解其后验分布。本高级练习将介绍拉普拉斯近似法，这是一种在实践中处理复杂贝叶斯模型的关键近似推断技术。通过完成这一推导，您将深入了解如何处理非共轭模型，并理解使复杂的贝叶斯群体分析在计算上变得可行的核心方法之一 。",
            "id": "4141059",
            "problem": "考虑来自 $N$ 个同时记录的、响应时变刺激的神经元的尖峰计数数据。对于神经元 $i \\in \\{1,\\dots,N\\}$ 和时间窗 $t \\in \\{1,\\dots,T_i\\}$，令 $y_{it} \\in \\{0,1,2,\\dots\\}$ 表示观测到的尖峰计数，并令 $x_{it} \\in \\mathbb{R}^{p}$ 表示一个根据实验设计（例如，近期刺激历史和协变量）构建的 $p$ 维刺激特征向量。假设每个神经元都有一个分层广义线性模型 (GLM; Generalized Linear Model)，该模型具有泊松观测模型和规范对数连接：\n$$\ny_{it} \\mid w_i \\sim \\text{Poisson}\\!\\left(\\lambda_{it}\\right), \\quad \\lambda_{it} = \\exp\\!\\left(x_{it}^{\\top} w_i\\right),\n$$\n其中 $w_i \\in \\mathbb{R}^{p}$ 是神经元 $i$ 的单元级参数（权重）。在单元级参数上放置一个多元正态总体先验，\n$$\nw_i \\mid \\mu, \\Sigma \\sim \\mathcal{N}\\!\\left(\\mu, \\Sigma\\right),\n$$\n其超参数为 $\\mu \\in \\mathbb{R}^{p}$ 和一个正定协方差矩阵 $\\Sigma \\in \\mathbb{R}^{p \\times p}$。假设一个正常超先验密度 $p(\\mu,\\Sigma)$，其支持域为 $\\mathbb{R}^{p} \\times \\{\\text{正定矩阵}\\}$。\n\n从 Bayes' 法则以及上面定义的泊松似然和高斯先验出发，通过在每个神经元的众数周围使用二阶泰勒展开来积分掉单元级参数 $\\{w_i\\}_{i=1}^{N}$，从而推导给定所有神经元数据的超参数的边缘后验密度的一个解析上易于处理的近似。你的推导必须从第一性原理（Bayes' 法则、独立性假设和 Taylor's 定理）出发，并且必须将每个神经元的众数 $w_i^{\\star}$ 识别为 $w_i$ 的联合对数密度的最大化者，以及相应的负海森矩阵。你可以省略任何不依赖于 $\\mu$ 或 $\\Sigma$ 的常数。\n\n提供最终结果，作为一个关于 Laplace 近似的边缘后验密度 $p(\\mu,\\Sigma \\mid \\{y_{it}\\}, \\{x_{it}\\})$ 的单一闭式解析表达式，该表达式在相差一个比例常数的意义下，用 $\\mu$, $\\Sigma$, 数据 $\\{y_{it}\\}$, $\\{x_{it}\\}$, 每个神经元的众数 $w_i^{\\star}$ 以及在 $w_i^{\\star}$ 处求值的负海森矩阵来表示。不需要进行数值计算，也不需要四舍五入。所有对数都表示为自然对数，所有指数都使用 $\\exp(\\cdot)$ 符号表示。",
            "solution": "目标是通过积分掉单元级参数 $\\{w_i\\}_{i=1}^N$ 来推导超参数的边缘后验密度 $p(\\mu, \\Sigma \\mid \\{y_{it}\\}, \\{x_{it}\\})$ 的一个近似。这通过使用 Laplace 近似方法来实现。\n\n我们从所有参数的联合后验的 Bayes' 法则开始：\n$$\np(\\{w_i\\}_{i=1}^N, \\mu, \\Sigma \\mid \\{y_{it}\\}, \\{x_{it}\\}) \\propto p(\\{y_{it}\\}, \\{x_{it}\\} \\mid \\{w_i\\}_{i=1}^N, \\mu, \\Sigma) \\times p(\\{w_i\\}_{i=1}^N, \\mu, \\Sigma)\n$$\n使用问题陈述中指定的条件独立性假设，我们可以分解这些项。似然仅依赖于 $\\{w_i\\}$，而先验可以分解为超先验和给定超参数下 $\\{w_i\\}$ 的先验：\n$$\np(\\{y_{it}\\}, \\{x_{it}\\} \\mid \\{w_i\\}_{i=1}^N, \\mu, \\Sigma) = p(\\{y_{it}\\} \\mid \\{w_i\\}_{i=1}^N, \\{x_{it}\\}) = \\prod_{i=1}^N p(\\{y_{it}\\}_{t=1}^{T_i} \\mid w_i, \\{x_{it}\\}_{t=1}^{T_i})\n$$\n$$\np(\\{w_i\\}_{i=1}^N, \\mu, \\Sigma) = p(\\{w_i\\}_{i=1}^N \\mid \\mu, \\Sigma) p(\\mu, \\Sigma) = \\left( \\prod_{i=1}^N p(w_i \\mid \\mu, \\Sigma) \\right) p(\\mu, \\Sigma)\n$$\n为了符号简化，我们将完整数据集 $(\\{y_{it}\\}, \\{x_{it}\\})$ 表示为 $\\mathcal{D}$。超参数的边缘后验是通过积分掉权重 $\\{w_i\\}$ 获得的：\n$$\np(\\mu, \\Sigma \\mid \\mathcal{D}) = \\int \\dots \\int p(\\{w_i\\}_{i=1}^N, \\mu, \\Sigma \\mid \\mathcal{D}) \\, dw_1 \\dots dw_N\n$$\n代入联合后验的分解形式，我们得到：\n$$\np(\\mu, \\Sigma \\mid \\mathcal{D}) \\propto \\int \\dots \\int \\left( \\prod_{i=1}^N p(\\{y_{it}\\}_{t=1}^{T_i} \\mid w_i) p(w_i \\mid \\mu, \\Sigma) \\right) p(\\mu, \\Sigma) \\, dw_1 \\dots dw_N\n$$\n由于 $p(\\mu, \\Sigma)$ 不依赖于任何 $w_i$，我们可以将其移到积分之外。由于在 $(\\mu, \\Sigma)$ 条件下，$(w_i, \\text{data}_i)$ 对是独立的，因此乘积的积分等于积分的乘积：\n$$\np(\\mu, \\Sigma \\mid \\mathcal{D}) \\propto p(\\mu, \\Sigma) \\prod_{i=1}^N \\int p(\\{y_{it}\\}_{t=1}^{T_i} \\mid w_i) p(w_i \\mid \\mu, \\Sigma) \\, dw_i\n$$\n我们对乘积中的每个积分应用 Laplace 近似。对于单个神经元 $i$，积分为：\n$$\nI_i(\\mu, \\Sigma) = \\int p(\\{y_{it}\\}_{t=1}^{T_i} \\mid w_i) p(w_i \\mid \\mu, \\Sigma) \\, dw_i = \\int \\exp\\left( \\ln\\left( p(\\{y_{it}\\}_{t=1}^{T_i} \\mid w_i) p(w_i \\mid \\mu, \\Sigma) \\right) \\right) \\, dw_i\n$$\n令 $L_i(w_i; \\mu, \\Sigma)$ 为被积函数的对数，即 $w_i$ 的对数后验（在相差一个不依赖于 $w_i$ 的常数的意义下）：\n$$\nL_i(w_i; \\mu, \\Sigma) = \\ln p(\\{y_{it}\\}_{t=1}^{T_i} \\mid w_i) + \\ln p(w_i \\mid \\mu, \\Sigma)\n$$\n问题将每个神经元的众数 $w_i^{\\star}$ 定义为该联合对数密度的最大化者：\n$$\nw_i^{\\star} = \\arg\\max_{w_i} L_i(w_i; \\mu, \\Sigma)\n$$\nLaplace 近似依赖于 $L_i$ 在 $w_i^{\\star}$ 周围的二阶泰勒展开：\n$$\nL_i(w_i; \\mu, \\Sigma) \\approx L_i(w_i^{\\star}; \\mu, \\Sigma) + (w_i - w_i^{\\star})^{\\top} \\nabla_{w_i} L_i(w_i^{\\star}) + \\frac{1}{2} (w_i - w_i^{\\star})^{\\top} \\nabla_{w_i}^2 L_i(w_i^{\\star}) (w_i - w_i^{\\star})\n$$\n根据众数的定义，$\\nabla_{w_i} L_i(w_i^{\\star}) = 0$。令 $A_i^{\\star}$ 为在众数处求值的负海森矩阵：\n$$\nA_i^{\\star} = -\\nabla_{w_i}^2 L_i(w_i^{\\star}; \\mu, \\Sigma)\n$$\n$L_i$ 的近似变为：\n$$\nL_i(w_i; \\mu, \\Sigma) \\approx L_i(w_i^{\\star}; \\mu, \\Sigma) - \\frac{1}{2} (w_i - w_i^{\\star})^{\\top} A_i^{\\star} (w_i - w_i^{\\star})\n$$\n将此代回积分 $I_i$，我们得到：\n$$\nI_i(\\mu, \\Sigma) \\approx \\int \\exp\\left( L_i(w_i^{\\star}; \\mu, \\Sigma) - \\frac{1}{2} (w_i - w_i^{\\star})^{\\top} A_i^{\\star} (w_i - w_i^{\\star}) \\right) \\, dw_i\n$$\n$$\nI_i(\\mu, \\Sigma) \\approx \\exp(L_i(w_i^{\\star}; \\mu, \\Sigma)) \\int \\exp\\left(-\\frac{1}{2} (w_i - w_i^{\\star})^{\\top} A_i^{\\star} (w_i - w_i^{\\star})\\right) \\, dw_i\n$$\n剩余的积分是一个均值为 $w_i^{\\star}$、协方差矩阵为 $(A_i^{\\star})^{-1}$ 的多元正态分布的未归一化密度。其值为 $(2\\pi)^{p/2} |(A_i^{\\star})^{-1}|^{1/2} = (2\\pi)^{p/2} |A_i^{\\star}|^{-1/2}$。\n因此，该积分的 Laplace 近似为：\n$$\nI_i(\\mu, \\Sigma) \\approx (2\\pi)^{p/2} |A_i^{\\star}|^{-1/2} \\exp(L_i(w_i^{\\star}; \\mu, \\Sigma))\n$$\n现在我们必须找到 $L_i(w_i^{\\star}; \\mu, \\Sigma)$ 和 $A_i^{\\star}$ 的显式形式。\n神经元 $i$ 的对数似然为（在相差常数的意义下）：\n$$\n\\ln p(\\{y_{it}\\} \\mid w_i) \\propto \\sum_{t=1}^{T_i} \\left( y_{it} \\ln(\\lambda_{it}) - \\lambda_{it} \\right) = \\sum_{t=1}^{T_i} \\left( y_{it} (x_{it}^{\\top} w_i) - \\exp(x_{it}^{\\top} w_i) \\right)\n$$\n$w_i$ 的对数先验为（在相差常数的意义下）：\n$$\n\\ln p(w_i \\mid \\mu, \\Sigma) \\propto -\\frac{1}{2} \\ln|\\Sigma| - \\frac{1}{2} (w_i - \\mu)^{\\top} \\Sigma^{-1} (w_i - \\mu)\n$$\n$w_i$ 的完整对数密度为：\n$$\nL_i(w_i; \\mu, \\Sigma) \\propto \\sum_{t=1}^{T_i} \\left( y_{it} x_{it}^{\\top} w_i - \\exp(x_{it}^{\\top} w_i) \\right) - \\frac{1}{2} (w_i - \\mu)^{\\top} \\Sigma^{-1} (w_i - \\mu) - \\frac{1}{2}\\ln|\\Sigma|\n$$\n负海森矩阵 $A_i^{\\star}$ 是通过求导两次并取负得到的。一阶导数（梯度）是：\n$$\n\\nabla_{w_i} L_i = \\sum_{t=1}^{T_i} x_{it} \\left( y_{it} - \\exp(x_{it}^{\\top} w_i) \\right) - \\Sigma^{-1} (w_i - \\mu)\n$$\n二阶导数（海森矩阵）是：\n$$\n\\nabla_{w_i}^2 L_i = \\sum_{t=1}^{T_i} -x_{it} \\exp(x_{it}^{\\top} w_i) x_{it}^{\\top} - \\Sigma^{-1} = -\\left( \\sum_{t=1}^{T_i} \\exp(x_{it}^{\\top} w_i) x_{it} x_{it}^{\\top} + \\Sigma^{-1} \\right)\n$$\n因此，在众数 $w_i^{\\star}$ 处求值的负海森矩阵是：\n$$\nA_i^{\\star} = \\sum_{t=1}^{T_i} \\exp(x_{it}^{\\top} w_i^{\\star}) x_{it} x_{it}^{\\top} + \\Sigma^{-1}\n$$\n现在，组合超参数的边缘后验，省略不依赖于 $\\mu$ 和 $\\Sigma$ 的常数，例如 $(2\\pi)^{p/2}$：\n$$\np(\\mu, \\Sigma \\mid \\mathcal{D}) \\propto p(\\mu, \\Sigma) \\prod_{i=1}^N \\left( |A_i^{\\star}|^{-1/2} \\exp(L_i(w_i^{\\star}; \\mu, \\Sigma)) \\right)\n$$\n代入 $L_i(w_i^{\\star}; \\mu, \\Sigma)$ 的表达式，并去掉指数内的加性常数项：\n$$\np(\\mu, \\Sigma \\mid \\mathcal{D}) \\propto p(\\mu, \\Sigma) \\prod_{i=1}^N \\left( |A_i^{\\star}|^{-1/2} \\exp\\left( \\sum_{t=1}^{T_i} \\left[ y_{it} x_{it}^{\\top} w_i^{\\star} - \\exp(x_{it}^{\\top} w_i^{\\star}) \\right] - \\frac{1}{2} (w_i^{\\star} - \\mu)^{\\top} \\Sigma^{-1} (w_i^{\\star} - \\mu) - \\frac{1}{2}\\ln|\\Sigma| \\right) \\right)\n$$\n我们可以合并乘积中的各项。项 $\\exp(-\\frac{1}{2}\\ln|\\Sigma|) = |\\Sigma|^{-1/2}$ 对 $N$ 个神经元中的每一个都出现。\n$$\np(\\mu, \\Sigma \\mid \\mathcal{D}) \\propto p(\\mu, \\Sigma) \\left( \\prod_{i=1}^N |A_i^{\\star}|^{-1/2} \\right) \\left( \\prod_{i=1}^N |\\Sigma|^{-1/2} \\right) \\exp\\left( \\sum_{i=1}^N \\left( \\sum_{t=1}^{T_i} \\left[ y_{it} x_{it}^{\\top} w_i^{\\star} - \\exp(x_{it}^{\\top} w_i^{\\star}) \\right] - \\frac{1}{2} (w_i^{\\star} - \\mu)^{\\top} \\Sigma^{-1} (w_i^{\\star} - \\mu) \\right) \\right)\n$$\n简化行列式的乘积，得到 Laplace 近似的边缘后验密度的最终表达式：\n$$\np(\\mu, \\Sigma \\mid \\{y_{it}\\}, \\{x_{it}\\}) \\propto p(\\mu,\\Sigma) |\\Sigma|^{-N/2} \\left( \\prod_{i=1}^N |A_i^{\\star}|^{-1/2} \\right) \\exp\\left( -\\frac{1}{2} \\sum_{i=1}^N (w_i^{\\star} - \\mu)^{\\top} \\Sigma^{-1} (w_i^{\\star} - \\mu) + \\sum_{i=1}^N \\sum_{t=1}^{T_i} \\left( y_{it} x_{it}^{\\top} w_i^{\\star} - \\exp(x_{it}^{\\top} w_i^{\\star}) \\right) \\right)\n$$\n这里，$w_i^{\\star}$ 是神经元 $i$ 的众数，而 $A_i^{\\star} = \\sum_{t=1}^{T_i} \\exp(x_{it}^{\\top} w_i^{\\star}) x_{it} x_{it}^{\\top} + \\Sigma^{-1}$ 是相应的负海森矩阵。",
            "answer": "$$\n\\boxed{p(\\mu,\\Sigma) |\\Sigma|^{-N/2} \\left( \\prod_{i=1}^N |A_i^{\\star}|^{-1/2} \\right) \\exp\\left( -\\frac{1}{2} \\sum_{i=1}^N (w_i^{\\star} - \\mu)^{\\top} \\Sigma^{-1} (w_i^{\\star} - \\mu) + \\sum_{i=1}^N \\sum_{t=1}^{T_i} \\left( y_{it} x_{it}^{\\top} w_i^{\\star} - \\exp(x_{it}^{\\top} w_i^{\\star}) \\right) \\right)}\n$$"
        }
    ]
}