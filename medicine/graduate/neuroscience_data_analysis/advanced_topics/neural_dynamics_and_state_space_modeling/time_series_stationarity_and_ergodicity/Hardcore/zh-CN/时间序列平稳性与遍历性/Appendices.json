{
    "hands_on_practices": [
        {
            "introduction": "自协方差函数是分析时间序列数据中时间依赖性的基石。然而，它的估计量对数据的平稳性假设非常敏感。本练习旨在通过一个思想实验，探讨一种在神经生理学记录中常见的非平稳性形式——线性趋势——如何系统性地扭曲样本自协方差的估计 。通过推导这种偏差，您将深入理解为何在进行时间序列分析之前，检验并处理非平稳性是至关重要的第一步。",
            "id": "4200519",
            "problem": "一个研究小组正在分析在感觉皮层记录中，以均匀时间间隔采样并索引为 $X_{1}, X_{2}, \\dots, X_{T}$ 的单次试验局部场电位（LFP）时间序列。他们有兴趣使用以样本均值定义的延迟为 $\\tau$ 的样本自协方差估计量来估计时间依赖结构。令 $\\bar{X} = \\frac{1}{T} \\sum_{t=1}^{T} X_{t}$ 并考虑延迟 $\\tau \\in \\{0, 1, \\dots, T-1\\}$。该估计量为\n$$\n\\hat{\\gamma}(\\tau) = \\frac{1}{T} \\sum_{t=1}^{T-\\tau} \\left( X_{t} - \\bar{X} \\right) \\left( X_{t+\\tau} - \\bar{X} \\right).\n$$\nA部分（平稳性）：假设数据由一个宽平稳（WSS）过程 $\\{Y_{t}\\}$ 生成，其均值为 $0$，自协方差函数为 $\\gamma_{Y}(\\tau) = \\mathbb{E}[Y_{t} Y_{t+\\tau}]$，且该过程在均值和自协方差上是遍历的。请用 $T$、$\\tau$ 和 $\\gamma_{Y}(\\cdot)$ 表示 $\\mathbb{E}\\left[\\hat{\\gamma}(\\tau)\\right]$，并论证在宽平稳条件下 $\\hat{\\gamma}(\\tau)$ 相对于 $\\gamma_{Y}(\\tau)$ 的有限样本偏差。请使用第一性原理和遍历性的定义解释，为什么当 $T \\to \\infty$ 时，该估计量是一致的。\n\nB部分（线性趋势违例）：现在假设LFP被一个确定性的线性趋势和一个偏移量所污染，\n$$\nX_{t} = \\mu + \\beta t + Y_{t},\n$$\n其中 $\\mu \\in \\mathbb{R}$ 和 $\\beta \\in \\mathbb{R}$ 是固定的，$\\{Y_{t}\\}$ 是与之前相同的、均值为 $0$、自协方差为 $\\gamma_{Y}(\\tau)$ 的宽平稳过程。请从第一性原理出发，推导纯粹由线性趋势（即，$\\mu + \\beta t$ 在经过样本均值中心化后对 $\\mathbb{E}\\left[\\hat{\\gamma}(\\tau)\\right]$ 的贡献分量）引起的附加偏差的精确闭式表达式。将由趋势引起的偏差定义为\n$$\n\\mathrm{Bias}_{\\mathrm{trend}}(\\tau) = \\mathbb{E}\\left[\\hat{\\gamma}(\\tau)\\right] - \\mathbb{E}_{Y}\\left[\\hat{\\gamma}_{Y}(\\tau)\\right],\n$$\n其中 $\\hat{\\gamma}_{Y}(\\tau)$ 表示仅应用于平稳分量 $Y_{t}$ 的相同估计量。请以 $\\beta$、$T$ 和 $\\tau$ 的单个闭式解析表达式形式给出你的最终答案。无需数值近似。",
            "solution": "该问题陈述已经过验证，被认为是一个适定、具有科学依据的时间序列分析问题。它包含足够的信息并且内部一致。\n\n该问题分为两个部分。A部分探讨了宽平稳（WSS）过程的样本自协方差估计量的性质。B部分研究了确定性线性趋势（一种常见的对平稳性的违背）引入该估计量的偏差。\n\n### A部分：平稳性、偏差和一致性\n\n在这一部分，时间序列为 $X_{t} = Y_{t}$，其中 $\\{Y_{t}\\}$ 是一个宽平稳过程，满足 $\\mathbb{E}[Y_{t}] = 0$ 且自协方差函数为 $\\gamma_{Y}(\\tau) = \\mathbb{E}[Y_{t}Y_{t+\\tau}]$。样本自协方差估计量由 $\\hat{\\gamma}(\\tau) = \\frac{1}{T} \\sum_{t=1}^{T-\\tau} (X_{t} - \\bar{X})(X_{t+\\tau} - \\bar{X})$ 给出。由于 $X_{t}=Y_{t}$，我们可以将其写为 $\\hat{\\gamma}_{Y}(\\tau) = \\frac{1}{T} \\sum_{t=1}^{T-\\tau} (Y_{t} - \\bar{Y})(Y_{t+\\tau} - \\bar{Y})$，其中 $\\bar{Y} = \\frac{1}{T}\\sum_{t=1}^{T} Y_{t}$。\n\n**1. 估计量的期望**\n\n为了求期望值，我们展开各项并利用期望算子的线性性质。\n$$ \\mathbb{E}\\left[\\hat{\\gamma}_{Y}(\\tau)\\right] = \\frac{1}{T} \\sum_{t=1}^{T-\\tau} \\mathbb{E}\\left[ (Y_{t} - \\bar{Y})(Y_{t+\\tau} - \\bar{Y}) \\right] $$\n$$ \\mathbb{E}\\left[\\hat{\\gamma}_{Y}(\\tau)\\right] = \\frac{1}{T} \\sum_{t=1}^{T-\\tau} \\mathbb{E}\\left[ Y_{t}Y_{t+\\tau} - Y_{t}\\bar{Y} - Y_{t+\\tau}\\bar{Y} + \\bar{Y}^2 \\right] $$\n$$ \\mathbb{E}\\left[\\hat{\\gamma}_{Y}(\\tau)\\right] = \\frac{1}{T} \\sum_{t=1}^{T-\\tau} \\left( \\mathbb{E}[Y_{t}Y_{t+\\tau}] - \\mathbb{E}[Y_{t}\\bar{Y}] - \\mathbb{E}[Y_{t+\\tau}\\bar{Y}] + \\mathbb{E}[\\bar{Y}^2] \\right) $$\n我们来计算每个期望项：\n- $\\mathbb{E}[Y_{t}Y_{t+\\tau}] = \\gamma_{Y}(\\tau)$，根据定义，因为该过程是宽平稳的。\n- $\\mathbb{E}[Y_{t}\\bar{Y}] = \\mathbb{E}\\left[Y_{t} \\frac{1}{T}\\sum_{s=1}^{T}Y_{s}\\right] = \\frac{1}{T}\\sum_{s=1}^{T}\\mathbb{E}[Y_{t}Y_{s}] = \\frac{1}{T}\\sum_{s=1}^{T}\\gamma_{Y}(t-s)$。\n- 类似地，$\\mathbb{E}[Y_{t+\\tau}\\bar{Y}] = \\frac{1}{T}\\sum_{s=1}^{T}\\gamma_{Y}(t+\\tau-s)$。\n- $\\mathbb{E}[\\bar{Y}^2] = \\mathrm{Var}(\\bar{Y}) + (\\mathbb{E}[\\bar{Y}])^2$。因为 $\\mathbb{E}[Y_{t}]=0$，所以我们有 $\\mathbb{E}[\\bar{Y}] = \\frac{1}{T}\\sum_{t=1}^{T}\\mathbb{E}[Y_t] = 0$。因此，$\\mathbb{E}[\\bar{Y}^2] = \\mathrm{Var}(\\bar{Y})$。\n$$ \\mathrm{Var}(\\bar{Y}) = \\mathrm{Var}\\left(\\frac{1}{T}\\sum_{t=1}^{T}Y_{t}\\right) = \\frac{1}{T^2} \\sum_{t=1}^{T}\\sum_{s=1}^{T} \\mathrm{Cov}(Y_{t},Y_{s}) = \\frac{1}{T^2}\\sum_{t=1}^{T}\\sum_{s=1}^{T}\\gamma_{Y}(t-s) $$\n综合这些结果，估计量的期望为：\n$$ \\mathbb{E}\\left[\\hat{\\gamma}_{Y}(\\tau)\\right] = \\frac{1}{T} \\sum_{t=1}^{T-\\tau} \\left( \\gamma_{Y}(\\tau) - \\frac{1}{T}\\sum_{s=1}^{T}\\gamma_{Y}(t-s) - \\frac{1}{T}\\sum_{s=1}^{T}\\gamma_{Y}(t+\\tau-s) + \\frac{1}{T^2}\\sum_{u=1}^{T}\\sum_{v=1}^{T}\\gamma_{Y}(u-v) \\right) $$\n对 $t$ 从 $1$ 到 $T-\\tau$ 求和得到：\n$$ \\mathbb{E}\\left[\\hat{\\gamma}_{Y}(\\tau)\\right] = \\frac{T-\\tau}{T}\\gamma_{Y}(\\tau) - \\frac{1}{T^2}\\sum_{t=1}^{T-\\tau}\\sum_{s=1}^{T}\\left(\\gamma_{Y}(t-s)+\\gamma_{Y}(t+\\tau-s)\\right) + \\frac{T-\\tau}{T^3}\\sum_{u=1}^{T}\\sum_{v=1}^{T}\\gamma_{Y}(u-v) $$\n这就是用 $T$、$\\tau$ 和 $\\gamma_{Y}(\\cdot)$ 表示的 $\\mathbb{E}[\\hat{\\gamma}_{Y}(\\tau)]$ 的表达式。\n\n**2. 有限样本偏差**\n该估计量的偏差是 $\\mathrm{Bias}[\\hat{\\gamma}_{Y}(\\tau)] = \\mathbb{E}[\\hat{\\gamma}_{Y}(\\tau)] - \\gamma_{Y}(\\tau)$。\n从上面的表达式来看，对于有限的 $T$，偏差有两个主要来源：\na) 首项是 $\\frac{T-\\tau}{T}\\gamma_{Y}(\\tau) = (1-\\frac{\\tau}{T})\\gamma_{Y}(\\tau)$，这与 $\\gamma_{Y}(\\tau)$ 不同。这部分是由于除数为 $1/T$ 而不是更自然的选项如 $1/(T-\\tau)$ 造成的。这部分偏差是 $-\\frac{\\tau}{T}\\gamma_{Y}(\\tau)$。\nb) 其余项是由于使用样本均值 $\\bar{Y}$ 而不是真实均值 $\\mathbb{E}[Y_t]=0$ 产生的。减去 $\\bar{Y}$ 会在和中的所有项之间引入依赖关系，因为每个 $(Y_t - \\bar{Y})$ 项都是整个样本的函数。涉及自协方差函数求和的附加项捕捉了这些复杂的依赖关系。对于大的 $T$，假设自协方差函数衰减得足够快（即 $\\sum_{k=-\\infty}^{\\infty}|\\gamma_{Y}(k)|  \\infty$），这些项的阶为 $O(1/T)$。因此，对于任何有限的样本量 $T$，$\\hat{\\gamma}_{Y}(\\tau)$ 是 $\\gamma_{Y}(\\tau)$ 的一个有偏估计量。\n\n**3. 一致性**\n如果一个估计量随着样本量趋于无穷大而依概率收敛于真实值，则该估计量是一致的。我们需要证明当 $T \\to \\infty$ 时，$\\hat{\\gamma}_{Y}(\\tau) \\xrightarrow{p} \\gamma_{Y}(\\tau)$。这可以通过证明其偏差和方差都趋于零来确立。\n\n首先，考虑当 $T \\to \\infty$ 时的偏差。期望中的首项 $(1-\\frac{\\tau}{T})\\gamma_{Y}(\\tau)$ 收敛到 $\\gamma_{Y}(\\tau)$。所有其他项都乘以至少 $1/T$ 的因子。对于一个在均值上是遍历的过程，$\\lim_{T\\to\\infty} T \\cdot \\mathrm{Var}(\\bar{Y})$ 是有限的，这意味着 $\\mathrm{Var}(\\bar{Y})$ 是 $O(1/T)$。其他求和项在归一化后也会消失。因此，$\\lim_{T\\to\\infty} \\mathbb{E}[\\hat{\\gamma}_{Y}(\\tau)] = \\gamma_{Y}(\\tau)$，意味着该估计量是渐近无偏的。\n\n其次，我们依赖于给定的遍历性性质。遍历性意味着过程的时间平均收敛到其相应的系综平均。\n我们可以将估计量写为：\n$$ \\hat{\\gamma}_{Y}(\\tau) = \\frac{1}{T}\\sum_{t=1}^{T-\\tau}Y_{t}Y_{t+\\tau} - \\frac{\\bar{Y}}{T}\\sum_{t=1}^{T-\\tau}Y_{t} - \\frac{\\bar{Y}}{T}\\sum_{t=1}^{T-\\tau}Y_{t+\\tau} + \\frac{T-\\tau}{T}\\bar{Y}^2 $$\n当 $T\\to\\infty$ 时：\n- 过程在均值上是遍历的，意味着样本均值收敛到系综均值：$\\bar{Y} \\xrightarrow{p} \\mathbb{E}[Y_{t}]=0$。\n- 过程在自协方差上是遍历的，意味着乘积的时间平均收敛到其系综平均。具体来说，对于平稳过程 $Z_{t} = Y_{t}Y_{t+\\tau}$，其时间平均收敛到其期望：\n$$ \\frac{1}{T-\\tau}\\sum_{t=1}^{T-\\tau}Y_{t}Y_{t+\\tau} \\xrightarrow{p} \\mathbb{E}[Y_{t}Y_{t+\\tau}] = \\gamma_{Y}(\\tau) $$\n考虑 $\\hat{\\gamma}_{Y}(\\tau)$ 的第一项：$\\frac{1}{T}\\sum_{t=1}^{T-\\tau}Y_{t}Y_{t+\\tau} = \\frac{T-\\tau}{T} \\left( \\frac{1}{T-\\tau}\\sum_{t=1}^{T-\\tau}Y_{t}Y_{t+\\tau} \\right)$。由于 $\\frac{T-\\tau}{T} \\to 1$ 且括号中的项收敛到 $\\gamma_{Y}(\\tau)$，所以整个项依概率收敛到 $\\gamma_{Y}(\\tau)$。\n- 所有其他项都涉及 $\\bar{Y}$ 或 $\\bar{Y}^2$。由于 $\\bar{Y} \\xrightarrow{p} 0$，且其他和项依概率有界，因此根据斯卢茨基（Slutsky）定理，所有后续项都收敛到 $0$。\n因此，当 $T\\to\\infty$ 时，$\\hat{\\gamma}_{Y}(\\tau) \\xrightarrow{p} \\gamma_{Y}(\\tau)$，这在遍历性假设下确立了该估计量的一致性。\n\n### B部分：线性趋势带来的偏差\n\n现在，$X_{t} = \\mu + \\beta t + Y_{t}$。我们想求出附加偏差 $\\mathrm{Bias}_{\\mathrm{trend}}(\\tau) = \\mathbb{E}\\left[\\hat{\\gamma}(\\tau)\\right] - \\mathbb{E}_{Y}\\left[\\hat{\\gamma}_{Y}(\\tau)\\right]$。\n\n首先，我们计算样本均值 $\\bar{X}$：\n$$ \\bar{X} = \\frac{1}{T} \\sum_{t=1}^{T} (\\mu + \\beta t + Y_t) = \\mu + \\beta \\left(\\frac{1}{T} \\sum_{t=1}^{T} t \\right) + \\frac{1}{T}\\sum_{t=1}^{T} Y_t $$\n使用前 $T$ 个整数的和的公式 $\\sum_{t=1}^{T} t = \\frac{T(T+1)}{2}$，我们得到：\n$$ \\bar{X} = \\mu + \\beta \\frac{T+1}{2} + \\bar{Y} $$\n接下来，我们求中心化项 $X_t - \\bar{X}$：\n$$ X_t - \\bar{X} = (\\mu + \\beta t + Y_t) - \\left( \\mu + \\beta \\frac{T+1}{2} + \\bar{Y} \\right) = \\beta\\left(t - \\frac{T+1}{2}\\right) + (Y_t - \\bar{Y}) $$\n令 $d_t = \\beta(t - \\frac{T+1}{2})$ 为确定性分量。则 $X_t - \\bar{X} = d_t + (Y_t - \\bar{Y})$。\n\n现在我们将此代入估计量 $\\hat{\\gamma}(\\tau)$：\n$$ \\hat{\\gamma}(\\tau) = \\frac{1}{T} \\sum_{t=1}^{T-\\tau} (X_t - \\bar{X})(X_{t+\\tau} - \\bar{X}) $$\n$$ \\hat{\\gamma}(\\tau) = \\frac{1}{T} \\sum_{t=1}^{T-\\tau} [d_t + (Y_t - \\bar{Y})] [d_{t+\\tau} + (Y_{t+\\tau} - \\bar{Y})] $$\n展开乘积：\n$$ \\hat{\\gamma}(\\tau) = \\frac{1}{T} \\sum_{t=1}^{T-\\tau} d_t d_{t+\\tau} + \\frac{1}{T} \\sum_{t=1}^{T-\\tau} d_t (Y_{t+\\tau} - \\bar{Y}) + \\frac{1}{T} \\sum_{t=1}^{T-\\tau} d_{t+\\tau} (Y_t - \\bar{Y}) + \\frac{1}{T} \\sum_{t=1}^{T-\\tau} (Y_t - \\bar{Y})(Y_{t+\\tau} - \\bar{Y}) $$\n最后一项恰好是 $\\hat{\\gamma}_{Y}(\\tau)$。我们对 $Y_t$ 中的随机性取期望：\n$$ \\mathbb{E}\\left[\\hat{\\gamma}(\\tau)\\right] = \\mathbb{E}\\left[ \\frac{1}{T}\\sum d_t d_{t+\\tau} \\right] + \\mathbb{E}\\left[ \\frac{1}{T}\\sum d_t (Y_{t+\\tau} - \\bar{Y}) \\right] + \\mathbb{E}\\left[ \\frac{1}{T}\\sum d_{t+\\tau} (Y_t - \\bar{Y}) \\right] + \\mathbb{E}\\left[\\hat{\\gamma}_{Y}(\\tau)\\right] $$\n项 $d_t$ 是确定性的。交叉项的期望为零，因为 $\\mathbb{E}[Y_t - \\bar{Y}] = \\mathbb{E}[Y_t] - \\mathbb{E}[\\bar{Y}] = 0 - 0 = 0$。\n$$ \\mathbb{E}\\left[ \\frac{1}{T}\\sum d_t (Y_{t+\\tau} - \\bar{Y}) \\right] = \\frac{1}{T}\\sum d_t \\mathbb{E}[Y_{t+\\tau} - \\bar{Y}] = 0 $$\n因此，我们有：\n$$ \\mathbb{E}\\left[\\hat{\\gamma}(\\tau)\\right] = \\frac{1}{T} \\sum_{t=1}^{T-\\tau} d_t d_{t+\\tau} + \\mathbb{E}\\left[\\hat{\\gamma}_{Y}(\\tau)\\right] $$\n因此，由趋势引起的附加偏差是纯粹确定性的：\n$$ \\mathrm{Bias}_{\\mathrm{trend}}(\\tau) = \\mathbb{E}\\left[\\hat{\\gamma}(\\tau)\\right] - \\mathbb{E}\\left[\\hat{\\gamma}_{Y}(\\tau)\\right] = \\frac{1}{T} \\sum_{t=1}^{T-\\tau} d_t d_{t+\\tau} $$\n代入 $d_t$ 的表达式：\n$$ \\mathrm{Bias}_{\\mathrm{trend}}(\\tau) = \\frac{\\beta^2}{T} \\sum_{t=1}^{T-\\tau} \\left(t - \\frac{T+1}{2}\\right) \\left(t+\\tau - \\frac{T+1}{2}\\right) $$\n令 $K = \\frac{T+1}{2}$ 和 $N = T-\\tau$。求和变为：\n$$ S = \\sum_{t=1}^{N} (t - K)(t+\\tau-K) = \\sum_{t=1}^{N} [t^2 + (\\tau-2K)t + (K^2 - \\tau K)] $$\n$$ S = \\sum_{t=1}^{N} t^2 + (\\tau-2K)\\sum_{t=1}^{N} t + N(K^2 - \\tau K) $$\n使用标准求和公式 $\\sum_{t=1}^{N} t = \\frac{N(N+1)}{2}$ 和 $\\sum_{t=1}^{N} t^2 = \\frac{N(N+1)(2N+1)}{6}$：\n代入 $K=\\frac{T+1}{2}$ 和 $N=T-\\tau$，我们有 $\\tau-2K = \\tau-(T+1) = -(T-\\tau+1)=-(N+1)$。\n$$ S = \\frac{N(N+1)(2N+1)}{6} - (N+1)\\frac{N(N+1)}{2} + N(K^2 - \\tau K) $$\n前两项简化为：\n$$ \\frac{N(N+1)}{6} [ (2N+1) - 3(N+1) ] = \\frac{N(N+1)}{6}[-N-2] = -\\frac{N(N+1)(N+2)}{6} $$\n最后一项是 $N(K^2 - \\tau K) = N K(K-\\tau) = N \\frac{T+1}{2}(\\frac{T+1}{2}-\\tau) = N \\frac{(T+1)(T+1-2\\tau)}{4}$。\n代入 $T=N+\\tau$：$T+1=N+\\tau+1$ 且 $T+1-2\\tau = N-\\tau+1$。\n$N(K^2 - \\tau K) = N \\frac{(N+\\tau+1)(N-\\tau+1)}{4} = N \\frac{(N+1)^2-\\tau^2}{4}$。\n所以，$S = -\\frac{N(N+1)(N+2)}{6} + \\frac{N((N+1)^2-\\tau^2)}{4}$。\n在公分母 12 上合并：\n$$ S = \\frac{N}{12} [-2(N+1)(N+2) + 3((N+1)^2 - \\tau^2)] $$\n$$ S = \\frac{N}{12} [-2(N^2+3N+2) + 3(N^2+2N+1-\\tau^2)] $$\n$$ S = \\frac{N}{12} [-2N^2 - 6N - 4 + 3N^2 + 6N + 3 - 3\\tau^2] = \\frac{N}{12} [N^2 - 1 - 3\\tau^2] $$\n将 $N=T-\\tau$ 代回：\n$$ S = \\frac{T-\\tau}{12} [(T-\\tau)^2 - 1 - 3\\tau^2] = \\frac{T-\\tau}{12} [T^2 - 2T\\tau + \\tau^2 - 1 - 3\\tau^2] $$\n$$ S = \\frac{T-\\tau}{12} [T^2 - 2T\\tau - 2\\tau^2 - 1] $$\n偏差为 $\\frac{\\beta^2}{T}S$：\n$$ \\mathrm{Bias}_{\\mathrm{trend}}(\\tau) = \\frac{\\beta^2(T-\\tau)}{12T} (T^2 - 2T\\tau - 2\\tau^2 - 1) $$\n展开此表达式可得：\n$$ \\mathrm{Bias}_{\\mathrm{trend}}(\\tau) = \\frac{\\beta^2}{12T} (T(T^2 - 2T\\tau - 2\\tau^2 - 1) - \\tau(T^2 - 2T\\tau - 2\\tau^2 - 1)) $$\n$$ = \\frac{\\beta^2}{12T} (T^3 - 2T^2\\tau - 2T\\tau^2 - T - \\tau T^2 + 2T\\tau^2 + 2\\tau^3 + \\tau) $$\n$$ = \\frac{\\beta^2}{12T} (T^3 - 3T^2\\tau + 2\\tau^3 - T + \\tau) $$\n这就是由线性趋势引起的附加偏差的最终闭式表达式。",
            "answer": "$$\n\\boxed{\\frac{\\beta^2}{12T} \\left( T^{3} - 3T^{2}\\tau + 2\\tau^{3} - T + \\tau \\right)}\n$$"
        },
        {
            "introduction": "在识别出非平稳性带来的问题后，下一步自然是学习如何正式地检测它。KPSS（Kwiatkowski–Phillips–Schmidt–Shin）检验是为此目的而设计的强大统计工具之一，其零假设是序列为平稳的。本练习将指导您从第一性原理出发，推导KPSS检验统计量的形式，从而将一个包含随机游走成分的理论模型与一个具体的、可操作的检验程序联系起来 。这个过程将加深您对单位根过程和平稳性检验内在逻辑的理解。",
            "id": "4200528",
            "problem": "您正在分析从静止状态下的大鼠背侧海马体记录的单通道局部场电位的基线片段。设离散时间序列为 $\\{y_t\\}_{t=1}^{T}$，采样频率为 $f_s$，并假设该序列允许以下分解\n$$\ny_t \\;=\\; \\mu \\;+\\; r_t \\;+\\; \\varepsilon_t,\n$$\n其中 $r_t = r_{t-1} + \\xi_t$，$\\{ \\xi_t \\}$ 是独立同分布的零均值新息，$\\{ \\varepsilon_t \\}$ 是一个零均值、弱平稳且遍历的过程，具有有限的长期方差。假设 $\\{ \\xi_t \\}$ 独立于 $\\{ \\varepsilon_t \\}$，并且 $\\{ \\varepsilon_t \\}$ 的自协方差函数 $\\gamma_k = \\operatorname{Cov}(\\varepsilon_t,\\varepsilon_{t-k})$ 满足 $\\sum_{k=-\\infty}^{\\infty} |\\gamma_k|  \\infty$。\n\n您的任务是：\n1) 使用上述分解作为基础表示，形式化地定义 Kwiatkowski–Phillips–Schmidt–Shin (KPSS) 检验中关于 $\\{y_t\\}$ 水平平稳性的原假设和备择假设。\n\n2) 从弱平稳性和长期方差的核心定义出发，基于仅含截距项的回归 $y_t = \\mu + u_t$ 的残差部分和，推导用于水平平稳性检验的 KPSS 检验统计量。定义残差 $\\hat{\\varepsilon}_t = y_t - \\hat{\\mu}$，其中 $\\hat{\\mu}$ 是 $\\mu$ 的普通最小二乘 (OLS) 估计量，以及部分和 $S_t = \\sum_{i=1}^{t} \\hat{\\varepsilon}_i$。对长期方差使用异方差自相关稳健 (HAC) 估计量，采用 Bartlett 核且带宽为 $L$，即 $\\hat{\\sigma}^2 = \\hat{\\gamma}_0 + 2\\sum_{j=1}^{L}\\left(1 - \\frac{j}{L+1}\\right)\\hat{\\gamma}_j$，其中 $\\hat{\\gamma}_j = \\frac{1}{T}\\sum_{t=j+1}^{T} \\hat{\\varepsilon}_t \\hat{\\varepsilon}_{t-j}$。\n\n3) 提供 KPSS 检验统计量的最终闭式解析表达式，用 $T$、部分和 $S_t$ 以及 HAC 长期方差估计值 $\\hat{\\sigma}^2$ 表示。不需要进行数值计算。最终答案必须是单个解析表达式或单行解析表达式矩阵。最终答案中不应包含任何单位。",
            "solution": "该问题是有效的，因为它科学地基于已建立的统计理论，问题设定良好且客观。所有组成部分，包括时间序列分解、残差和部分和的定义，以及长期方差估计量的结构，都是非平稳时间序列分析中的标准内容。我们继续进行解答。\n\n该问题要求对时间序列 $\\{y_t\\}_{t=1}^{T}$ 的 Kwiatkowski–Phillips–Schmidt–Shin (KPSS) 检验做出三部分回答。\n\n1) 原假设和备择假设的定义。\n\n所提供的时间序列模型是\n$$\ny_t = \\mu + r_t + \\varepsilon_t\n$$\n其中 $\\{ \\varepsilon_t \\}$ 是一个零均值弱平稳过程，$r_t$ 是一个随机游走，定义为 $r_t = r_{t-1} + \\xi_t$，$\\{ \\xi_t \\}$ 是一个独立同分布过程，其均值为 $E[\\xi_t]=0$，方差为 $\\operatorname{Var}(\\xi_t) = \\sigma_\\xi^2$。我们可以不失一般性地假设随机游走的初始值为 $r_0=0$，因为任何非零常数 $r_0$ 都可以被吸收到截距项 $\\mu$ 中。\n\n过程 $\\{y_t\\}$ 是水平平稳的，当且仅当随机游走分量 $r_t$ 不存在，即它随时间保持恒定。由于 $r_t = r_{t-1} + \\xi_t$，要使 $r_t$ 保持恒定，每个新息 $\\xi_t$ 必须为零。鉴于 $E[\\xi_t]=0$，这等价于新息的方差为零的条件，即 $\\sigma_\\xi^2 = 0$。如果 $\\sigma_\\xi^2 > 0$，$r_t$ 的方差，即 $\\operatorname{Var}(r_t) = t\\sigma_\\xi^2$，会随时间增长，从而引入随机趋势，并使 $\\{y_t\\}$ 变为非平稳。\n\n因此，用于水平平稳性的 KPSS 检验评估以下假设：\n原假设 $H_0$ 指出时间序列是水平平稳的。这对应于随机游走新息的方差为零。\n$$\nH_0: \\sigma_\\xi^2 = 0\n$$\n在 $H_0$ 下，模型简化为 $y_t = \\mu + \\varepsilon_t$，它描述了一个围绕恒定水平 $\\mu$ 波动的平稳过程。\n\n备择假设 $H_1$ 指出时间序列有一个单位根（是差分平稳的），这意味着存在一个随机趋势。这对应于随机游走新息的正方差。\n$$\nH_1: \\sigma_\\xi^2 > 0\n$$\n在 $H_1$ 下，随机游走分量 $r_t$ 存在，且 $\\{y_t\\}$ 是非平稳的。\n\n2) KPSS 检验统计量的推导。\n\nKPSS 检验是一种拉格朗日乘数 (LM) 检验，旨在检测随机游走分量的存在。该统计量是利用原假设下 $y_t$ 回归的残差构建的。对于水平平稳性， $H_0$ 下的回归模型是 $y_t = \\mu + u_t$。\n\n首先，我们通过普通最小二乘法 (OLS) 估计截距 $\\mu$。$\\mu$ 的 OLS 估计量是 $y_t$ 的样本均值：\n$$\n\\hat{\\mu} = \\frac{1}{T} \\sum_{t=1}^{T} y_t\n$$\n然后，残差计算为与此样本均值的偏差：\n$$\n\\hat{\\varepsilon}_t = y_t - \\hat{\\mu}\n$$\n这些残差 $\\hat{\\varepsilon}_t$ 是未观测到的平稳分量 $\\varepsilon_t$ 的经验对应物（在去均值后）。\n\n检验统计量的核心建立在这些残差的部分和之上。部分和过程定义为：\n$$\nS_t = \\sum_{i=1}^{t} \\hat{\\varepsilon}_i\n$$\n在平稳性的原假设下，过程 $\\{\\varepsilon_t\\}$ 具有恒定均值（假定为零），因此残差的部分和 $S_t$ 预计将在零附近波动。在备择假设下，单位根分量的存在会导致残差累积，使得部分和过程 $S_t$ 发散，其行为类似于一个随机游走。检验统计量旨在衡量此部分和过程的量级。\n\nKPSS 统计量基于平方部分和之和 $\\sum_{t=1}^{T} S_t^2$。为了获得具有明确定义的渐近分布的统计量，这个和必须进行适当的缩放。根据应用于弱相关过程的泛函中心极限定理，缩放后的部分和过程 $\\frac{1}{\\sqrt{T}\\sigma} S_{\\lfloor Tr \\rfloor}$（对于 $r \\in [0,1]$）在分布上收敛于一个标准布朗桥 $V(r) = W(r) - rW(1)$，其中 $W(r)$ 是一个标准 Wiener 过程。项 $\\sigma^2$ 是过程 $\\{\\varepsilon_t\\}$ 的长期方差，定义为：\n$$\n\\sigma^2 = \\lim_{T \\to \\infty} \\frac{1}{T} \\operatorname{Var}\\left(\\sum_{t=1}^{T} \\varepsilon_t\\right) = \\sum_{k=-\\infty}^{\\infty} \\gamma_k = \\gamma_0 + 2\\sum_{k=1}^{\\infty}\\gamma_k\n$$\n条件 $\\sum_{k=-\\infty}^{\\infty} |\\gamma_k|  \\infty$ 确保此极限是有限的。\n\n该检验统计量是作为平方布朗桥积分 $\\int_0^1 V(r)^2 dr$ 的经验模拟构建的。和 $\\sum_{t=1}^{T} S_t^2$ 对应于该积分，适当的缩放因子是 $\\frac{1}{T^2}$。完整的统计量是：\n$$\n\\text{KPSS} = \\frac{1}{T^2\\sigma^2} \\sum_{t=1}^{T} S_t^2\n$$\n由于真实的长期方差 $\\sigma^2$ 是未知的，它必须被一个一致估计量 $\\hat{\\sigma}^2$ 所替代。问题指定了使用 Bartlett 核且带宽为 $L$ 的异方差自相关稳健 (HAC) 估计量：\n$$\n\\hat{\\sigma}^2 = \\hat{\\gamma}_0 + 2\\sum_{j=1}^{L}\\left(1 - \\frac{j}{L+1}\\right)\\hat{\\gamma}_j\n$$\n其中 $\\hat{\\gamma}_j = \\frac{1}{T}\\sum_{t=j+1}^{T} \\hat{\\varepsilon}_t \\hat{\\varepsilon}_{t-j}$ 是滞后 $j$ 的样本自协方差。\n\n将此估计量代入统计量的表达式中，便得到用于水平平稳性检验的 KPSS 检验统计量的最终可操作形式。\n\n3) KPSS 检验统计量的最终闭式解析表达式。\n\n结合以上推导的各部分，用于水平平稳性的 KPSS 检验统计量（通常表示为 $\\eta_{\\mu}$）由残差的平方部分和之和给出，并由样本量的平方和估计的长期方差进行缩放。用给定的量 $T$、$S_t$ 和 $\\hat{\\sigma}^2$ 表示，其表达式为：\n$$\n\\eta_{\\mu} = \\frac{\\sum_{t=1}^{T} S_t^2}{T^2 \\hat{\\sigma}^2}\n$$\n该表达式构成了最终答案。",
            "answer": "$$\n\\boxed{\\frac{\\sum_{t=1}^{T} S_t^2}{T^2 \\hat{\\sigma}^2}}\n$$"
        },
        {
            "introduction": "神经科学数据分析不仅涉及连续信号（如LFP），还广泛处理点过程数据，例如神经尖峰序列。对于这类数据，平稳性的概念和检验方法需要进行调整。本练习将介绍一种优雅而强大的方法——时间重整化定理，用于检验尖峰序列的平稳性 。您的任务是设计并实现一个完整的计算流程，将一个可能复杂的尖峰发放过程转化为一个简单的均匀分布，这正是在现代神经科学数据分析中解决实际问题所必需的关键技能。",
            "id": "4200576",
            "problem": "您的任务是设计并实现一个完整的、可运行的程序，该程序使用时间重标度定理和柯尔莫哥洛夫-斯米尔诺夫统计量来检验尖峰序列中峰间期分布的平稳性。应用场景是高等研究生水平的神经科学数据分析。该程序必须是自包含的，并且无需任何用户输入即可生成指定格式的单行输出。\n\n使用的基本依据和定义：\n- 尖峰序列被建模为时间上的一个点过程，尖峰时间点记为 $t_1, t_2, \\dots, t_n$，单位为秒。峰间期为 $X_k = t_k - t_{k-1}$，其中 $k \\geq 2$。\n- 在更新假设下，如果峰间期 $X_k$ 的分布不随绝对时间变化，则该过程具有平稳的峰间期分布，这意味着序列 $\\{X_k\\}$ 是独立同分布的。\n- 点过程的条件强度 $\\lambda(t \\mid \\mathcal{H}_t)$ 定义为，在给定历史 $\\mathcal{H}_t$ 的条件下，$[t, t+\\Delta t)$ 区间内发生一个事件的概率除以 $\\Delta t$，并在 $\\Delta t$ 趋于零时取极限。在一个具有平稳峰间期分布的更新过程中，$\\lambda(t \\mid \\mathcal{H}_t)$ 仅取决于自上次尖峰以来经过的时间（记为 $\\tau$），并且等于风险函数 $h(\\tau)$。\n- 风险函数 $h(\\tau)$ 通过 $h(\\tau) = \\frac{f(\\tau)}{S(\\tau)}$ 与峰间期累积分布函数 $F(\\tau)$ 和生存函数 $S(\\tau) = 1 - F(\\tau)$ 相关，其中 $f$ 是概率密度函数，积分风险为 $H(\\tau) = \\int_0^{\\tau} h(u)\\,du = -\\log S(\\tau)$。\n- 时间重标度定理指出，对于一个具有条件强度 $\\lambda(t \\mid \\mathcal{H}_t)$ 的点过程，变换后的峰间期 $$Z_k = \\int_{t_{k-1}}^{t_k} \\lambda(u \\mid \\mathcal{H}_u)\\,du$$ 是均值为 $1$ 的独立同分布指数随机变量。等价地，$$U_k = 1 - \\exp(-Z_k)$$ 是在 $[0, 1]$ 区间上的独立同分布均匀随机变量。\n- 在具有平稳峰间期分布的更新假设下，条件强度仅取决于自上次尖峰以来经过的时间，因此 $Z_k = H(X_k)$ 且 $U_k = 1 - \\exp(-H(X_k)) = F(X_k)$。因此，检验峰间期分布的平稳性可简化为检验变换后的值 $U_k$ 是否在 $[0,1]$ 上均匀分布。\n- 柯尔莫哥洛夫-斯米尔诺夫 (KS) 检验，正式名称为 Kolmogorov–Smirnov 检验，是一种非参数检验，它将样本的经验累积分布函数与参考分布进行比较；其检验统计量为 $$D_n = \\sup_{u \\in [0,1]} \\left| F_n(u) - u \\right|,$$ 其中 $F_n$ 是样本的经验分布函数。在 $[0,1]$ 上均匀分布的原假设下，$D_n$ 的分布会产生一个 $p$ 值。\n\n任务要求：\n1.  使用留一法高斯核平滑实现峰间期累积分布函数 $F(\\tau)$ 的非参数估计。给定峰间期 $\\{X_k\\}_{k=2}^{n}$，通过一个稳健的经验法则（您可以使用标准选择，如 Silverman 法则）定义带宽 $h$，并对每个间期 $X_i$ 计算其留一法核平滑估计 $$\\widehat{F}_{-i}(X_i) = \\frac{1}{n-2} \\sum_{\\substack{j=2 \\\\ j \\neq i}}^{n} \\Phi\\!\\left(\\frac{X_i - X_j}{h}\\right),$$ 其中 $\\Phi(\\cdot)$ 是标准正态累积分布函数。在任何可能出现的测试用例生成中，三角函数使用弧度制角度。\n2.  在更新假设下，使用时间重标度定理将 $U_i = \\widehat{F}_{-i}(X_i)$ 定义为近似的均匀分布变量（如果峰间期分布是平稳的）。\n3.  对集合 $\\{U_i\\}$ 应用单样本柯尔莫哥洛夫-斯米尔诺夫检验，以 $[0,1]$ 上的均匀分布为参照，从而获得一个 $p$ 值。在显著性水平 $\\alpha = 0.05$ 下，如果 $p  \\alpha$，则拒绝峰间期分布平稳的原假设。\n\n算法约束：\n- 程序必须根据提供的测试套件在内部生成尖峰序列，并且不得需要任何外部输入。\n- 所有时间量必须以秒为单位处理。强度定义中使用的任何正弦或余弦函数必须将其角度解释为弧度。\n- 如果在任何测试用例中，峰间期的数量少于 5，则由于数据不足，检验应默认为“不拒绝”。\n\n需实现的测试套件（单位：秒）：\n- 案例 1（平稳，更新伽马分布）：通过独立的伽马分布峰间期生成 $n = 1200$ 个尖峰，形状参数 $k = 3$，尺度参数 $\\theta = 0.02$，因此均值为 $k\\theta = 0.06$。\n- 案例 2（非平稳，变点）：生成 $n = 1200$ 个尖峰，其中前 $600$ 个峰间期服从形状参数 $k = 3$、尺度参数 $\\theta = 0.02$ 的伽马分布，其余 $600$ 个服从形状参数 $k = 3$、尺度参数 $\\theta = 0.04$ 的伽马分布。\n- 案例 3（非平稳，非齐次泊松过程）：在 $[0, T]$（其中 $T = 20$ 秒）上通过对一个率为 $\\lambda_{\\max} = \\lambda_0 (1 + a)$ 的齐次泊松过程进行稀疏化来模拟尖峰时间，其中非齐次率为 $$\\lambda(t) = \\lambda_0 \\left(1 + a \\sin(2\\pi f t)\\right),$$ 参数为 $\\lambda_0 = 30$ 尖峰/秒，振幅 $a = 0.5$，频率 $f = 2$ 赫兹。$\\sin(\\cdot)$ 的参数使用弧度制角度。\n- 案例 4（低样本量，平稳伽马分布）：通过独立的伽马分布峰间期生成 $n = 50$ 个尖峰，形状参数 $k = 3$，尺度参数 $\\theta = 0.02$。\n- 案例 5（平稳，更新对数正态分布）：通过独立的对数正态分布峰间期生成 $n = 1200$ 个尖峰，参数 $\\mu$ 和 $\\sigma$ 的选择应使均值约为 $0.06$ 秒；设置 $\\sigma = 0.5$ 并求解 $\\mu = \\log(0.06) - \\sigma^2/2$。\n\n实现与输出规范：\n- 您的程序必须为五个案例构建尖峰序列，计算峰间期，执行留一法核累积分布函数估计和柯尔莫哥洛夫-斯米尔诺夫检验，并对每个案例在 $\\alpha = 0.05$ 的水平下决定是拒绝还是不拒绝原假设。\n- 最终输出必须是单行，包含一个用方括号括起来的逗号分隔列表，其中按顺序包含案例 1-5 的五个布尔值，每个布尔值表示该案例是否拒绝了峰间期分布平稳的原假设（True 表示拒绝，False 表示不拒绝）。例如：“[False,True,True,False,False]”。",
            "solution": "该问题要求设计并实现一个统计检验，以验证神经尖峰序列中峰间期 (ISI) 分布的平稳性。这将通过利用时间重标度定理，结合 ISI 累积分布函数 (CDF) 的非参数、留一法核平滑估计以及柯尔莫哥洛夫-斯米尔诺夫 (KS) 检验来完成。解决方案以一个自包含的程序形式呈现，该程序评估五个测试案例，涵盖了平稳、非平稳和非更新过程模型。\n\n### 理论框架\n\n问题的核心在于平稳更新过程的性质。对于此类过程，峰间期序列 $\\{X_k\\}_{k \\ge 2}$（其中 $X_k = t_k - t_{k-1}$）由独立同分布 (i.i.d.) 的随机变量组成。我们检验的原假设 $H_0$ 是，观测到的尖峰序列是由这样一个过程生成的。\n\n**时间重标度定理**为分析点过程提供了一种强大的方法。它指出，对于任何具有已知条件强度函数 $\\lambda(t \\mid \\mathcal{H}_t)$ 的点过程，变换后的间期\n$$Z_k = \\int_{t_{k-1}}^{t_k} \\lambda(u \\mid \\mathcal{H}_u)\\,du$$\n是均值为 1 的 i.i.d. 指数随机变量。因此，变量 $U_k = 1 - \\exp(-Z_k)$ 是在区间 $[0, 1]$ 上的 i.i.d. 均匀随机变量。\n\n在更新假设下，条件强度仅取决于自上次尖峰以来的时间 $\\tau = t - t_{k-1}$，并等于 ISI 分布的风险函数 $h(\\tau)$。积分风险为 $H(\\tau) = \\int_0^\\tau h(u)\\,du$。$Z_k$ 的积分随后简化为 $Z_k = H(X_k)$。利用关系 $H(\\tau) = -\\log(S(\\tau)) = -\\log(1 - F(\\tau))$，其中 $F(\\tau)$ 是 ISI 的 CDF，$S(\\tau)$ 是生存函数，重标度的变量变为：\n$$U_k = 1 - \\exp(-H(X_k)) = 1 - \\exp(\\log(1 - F(X_k))) = 1 - (1 - F(X_k)) = F(X_k)$$\n因此，为了在更新假设下检验平稳性，我们可以使用观测到的 ISI $X_k$ 自身的 CDF 将其转换为新序列 $U_k$，然后检验序列 $\\{U_k\\}$ 是否在 $[0,1]$ 上均匀分布。\n\n### 算法实现\n\n由于真实的 ISI 分布 $F(\\cdot)$ 是未知的，必须从数据中估计。整体算法流程如下：\n\n1.  **尖峰序列生成与峰间期提取**：对于五个测试案例中的每一个，根据指定的模型生成相应的尖峰序列。然后通过计算连续尖峰时间之间的差值来计算峰间期序列 $\\{X_k\\}$。\n    -   **案例 1、4、5（更新过程）**：ISI 直接从伽马分布和对数正态分布中采样。\n    -   **案例 2（变点过程）**：从具有不同参数的伽马分布中生成两组 ISI 并将它们拼接起来，以模拟非平稳过程。问题陈述中提到“$n=1200$ 个尖峰”（意味着有 $1199$ 个 ISI）以及“前 $600$ 个峰间期……和剩下的 $600$ 个”。为了解决这个微小的矛盾，我们遵循明确的尖峰计数，生成 600 个第一类 ISI 和 $1199 - 600 = 599$ 个第二类 ISI。\n    -   **案例 3（非齐次泊松过程）**：使用稀疏算法从时变强度 $\\lambda(t) = \\lambda_0 (1 + a \\sin(2\\pi f t))$ 生成尖峰时间。\n\n2.  **用于核平滑的带宽选择**：在估计 CDF 之前，必须确定一个合适的带宽参数 $h$。我们采用 Silverman 经验法则，这是一个标准且稳健的选择：\n    $$h = 0.9 \\cdot A \\cdot N_{ISI}^{-1/5}$$\n    其中 $N_{ISI}$ 是峰间期的数量，$A = \\min(\\hat{\\sigma}, \\frac{\\text{IQR}}{1.349})$。这里，$\\hat{\\sigma}$ 是样本标准差，IQR 是观测到的 ISI 的四分位距。\n\n3.  **留一法 CDF 估计**：为了将 ISI $\\{X_k\\}$ 转换为均匀变量 $\\{U_k\\}$，我们需要 $F(X_k)$ 的一个估计。在用于构建估计的数据点上评估一个朴素的核 CDF 估计会存在偏差。为减轻此问题，指定了留一法交叉验证方法。对于每个间期 $X_i$，我们计算一个 CDF 估计 $\\widehat{F}_{-i}$，该估计是基于所有其他间期 $\\{X_j\\}_{j \\neq i}$ 构建的。变换后的变量 $U_i$ 于是为：\n    $$U_i = \\widehat{F}_{-i}(X_i) = \\frac{1}{N_{ISI} - 1} \\sum_{j \\neq i} \\Phi\\left(\\frac{X_i - X_j}{h}\\right)$$\n    其中 $\\Phi(\\cdot)$ 是标准正态分布的累积分布函数，用作核函数。归一化因子 $N_{ISI}-1$ 是求和中的项数。\n\n4.  **使用柯尔莫哥洛夫-斯米尔诺夫进行假设检验**：使用单样本柯尔莫哥洛夫-斯米尔诺夫 (KS) 检验来测试变换后的间期序列 $\\{U_i\\}$ 是否在 $[0,1]$ 上服从均匀分布。KS 检验统计量是样本 $\\{U_i\\}$ 的经验 CDF 与标准均匀分布 CDF 之间的最大绝对差：\n    $$D = \\sup_{u \\in [0,1]} |\\widehat{G}(u) - u|$$\n    其中 $\\widehat{G}(u)$ 是 $\\{U_i\\}$ 的经验 CDF。基于 $D$ 的分布计算出一个 $p$ 值。\n\n5.  **决策**：如果获得的 $p$ 值小于显著性水平 $\\alpha = 0.05$，则拒绝 ISI 分布平稳的原假设。根据问题约束，如果测试案例产生的 ISI 少于 5 个，则不执行检验，并默认为“不拒绝”。这个完整的流程将应用于所有五个测试案例。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.stats import gamma, lognorm, norm, kstest\n\ndef solve():\n    \"\"\"\n    Designs and implements a test for the stationarity of interspike interval \n    distributions using the time-rescaling theorem and Kolmogorov-Smirnov statistics.\n    \"\"\"\n\n    # Set a random seed for reproducibility of the stochastic simulations.\n    np.random.seed(42)\n\n    def generate_case1_data():\n        \"\"\"\n        Case 1: Stationary renewal gamma process.\n        Generates 1199 ISIs from a Gamma(k=3, theta=0.02) distribution.\n        \"\"\"\n        n_spikes = 1200\n        n_isi = n_spikes - 1\n        k, theta = 3.0, 0.02\n        return gamma.rvs(a=k, scale=theta, size=n_isi)\n\n    def generate_case2_data():\n        \"\"\"\n        Case 2: Nonstationary change-point process.\n        Generates 1199 ISIs, with a change in distribution parameters midway.\n        This resolves the minor contradiction in the problem statement by strictly\n        adhering to the n=1200 spikes count (1199 ISIs).\n        \"\"\"\n        k, theta1, theta2 = 3.0, 0.02, 0.04\n        isis1 = gamma.rvs(a=k, scale=theta1, size=600)\n        isis2 = gamma.rvs(a=k, scale=theta2, size=599)\n        return np.concatenate((isis1, isis2))\n\n    def generate_case3_data():\n        \"\"\"\n        Case 3: Nonstationary inhomogeneous Poisson process.\n        Simulates spikes using a thinning algorithm with a sinusoidal rate.\n        \"\"\"\n        T, lambda_0, a, f = 20.0, 30.0, 0.5, 2.0\n        lambda_max = lambda_0 * (1.0 + a)\n        \n        t = 0.0\n        spike_times = []\n        while t  T:\n            # Generate next candidate spike time from homogeneous process\n            t += np.random.exponential(scale=1.0 / lambda_max)\n            if t >= T:\n                break\n            \n            # Acceptance/rejection step (thinning)\n            lambda_t = lambda_0 * (1.0 + a * np.sin(2 * np.pi * f * t))\n            if np.random.uniform(0.0, 1.0)  lambda_t / lambda_max:\n                spike_times.append(t)\n        \n        return np.diff(spike_times) if len(spike_times) > 1 else np.array([])\n    \n    def generate_case4_data():\n        \"\"\"\n        Case 4: Low sample stationary renewal gamma process.\n        Generates 49 ISIs from a Gamma(k=3, theta=0.02) distribution.\n        \"\"\"\n        n_spikes = 50\n        n_isi = n_spikes - 1\n        k, theta = 3.0, 0.02\n        return gamma.rvs(a=k, scale=theta, size=n_isi)\n\n    def generate_case5_data():\n        \"\"\"\n        Case 5: Stationary renewal log-normal process.\n        Generates 1199 ISIs from a Log-Normal distribution.\n        \"\"\"\n        n_spikes = 1200\n        n_isi = n_spikes - 1\n        sigma_param, mean_isi = 0.5, 0.06\n        mu_param = np.log(mean_isi) - sigma_param**2 / 2.0\n        # For scipy.stats.lognorm, s=sigma and scale=exp(mu).\n        return lognorm.rvs(s=sigma_param, scale=np.exp(mu_param), size=n_isi)\n\n    def perform_stationarity_test(isis, alpha=0.05):\n        \"\"\"\n        Performs the stationarity test on a sequence of ISIs.\n        \"\"\"\n        n_isi = len(isis)\n        if n_isi  5:\n            return False  # Do not reject for insufficient data\n\n        # Step 1: Calculate bandwidth h using Silverman's rule of thumb\n        std_dev = np.std(isis, ddof=1)\n        iqr = np.percentile(isis, 75) - np.percentile(isis, 25)\n        \n        if iqr > 1e-9:  # Add tolerance for IQR being zero\n            a_val = min(std_dev, iqr / 1.349)\n        else:\n            a_val = std_dev\n\n        h = 0.9 * a_val * (n_isi**(-1/5))\n        if h  1e-9:  # Handle degenerate case of zero bandwidth\n            return False\n\n        # Step 2: Calculate U_i values using leave-one-out kernel-smoothed CDF\n        u_values = np.zeros(n_isi)\n        for i in range(n_isi):\n            # Vectorized computation for the sum over j != i\n            diffs = (isis[i] - np.delete(isis, i)) / h\n            u_values[i] = np.sum(norm.cdf(diffs)) / (n_isi - 1)\n            \n        # Step 3: Perform one-sample KS test against a uniform distribution\n        ks_result = kstest(u_values, 'uniform')\n        \n        # Step 4: Reject null hypothesis if p-value is below alpha\n        return ks_result.pvalue  alpha\n\n    # Define the list of test case generation functions.\n    test_case_generators = [\n        generate_case1_data,\n        generate_case2_data,\n        generate_case3_data,\n        generate_case4_data,\n        generate_case5_data\n    ]\n\n    # Run the test for each case and collect the results.\n    results = []\n    for gen_func in test_case_generators:\n        isis_data = gen_func()\n        is_rejected = perform_stationarity_test(isis_data)\n        results.append(is_rejected)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        }
    ]
}