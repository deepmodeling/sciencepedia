{
    "hands_on_practices": [
        {
            "introduction": "在检测有意义的神经同步性时，第一步是精确定义“偶然”的同步是什么样的。本练习将指导您基于单个神经元的放电率来计算期望的重合事件数，这构成了我们统计检验的零假设。这是单元事件分析的基石，它为我们提供了一个比较的基准，以判断观测到的同步性是否超出了偶然的范畴。",
            "id": "4202846",
            "problem": "考虑一个使用单元事件（UE）分析法分析的数据集，其中脉冲序列被离散化为宽度为 $\\Delta = 5 \\times 10^{-3}$ 秒的不重叠时间窗，当一个指定子集中的每个神经元在同一个时间窗内至少发放一次脉冲时，定义为一次符合事件。假设在单个时间窗 $t$ 内，不同神经元的脉冲发放被建模为独立的伯努利试验，其成功概率为 $p_i(t)$，由于非平稳的发放率，该概率会随时间窗变化。对于子集 $S = \\{1, 2\\}$，在时间窗 $t = 1, \\dots, 12$ 内，估计的每个时间窗的脉冲概率由以下序列给出：\n$p_1(1), \\dots, p_1(12) = (0.11, 0.12, 0.10, 0.09, 0.13, 0.15, 0.18, 0.16, 0.14, 0.12, 0.11, 0.10)$\n和\n$p_2(1), \\dots, p_2(12) = (0.08, 0.09, 0.07, 0.06, 0.10, 0.12, 0.15, 0.13, 0.11, 0.09, 0.08, 0.07)$。\n从概率论的核心原理（指示随机变量和期望的线性性）以及在类泊松小时间窗假设下对每个时间窗脉冲发放的伯努利近似出发，推导在时间窗口 $\\mathcal{W} = \\{1, \\dots, 12\\}$ 内子集 $S$ 的符合事件的期望数量，并计算其数值。此外，解释用于证明通过对各时间窗的符合事件概率求和来获得期望计数的建模和数学假设。将最终数值答案表示为四舍五入到四位有效数字的无量纲计数值。",
            "solution": "本问题要求在使用单元事件（UE）分析法分析的数据集中，推导并计算符合事件的期望数量。我将首先验证问题陈述，然后基于概率论的基本原理进行严格推导，解释其基本假设，最后计算出数值结果。\n\n### 问题验证\n\n**步骤1：提取已知条件**\n- **分析方法：** 单元事件（UE）分析。\n- **时间窗宽度：** $\\Delta = 5 \\times 10^{-3}$ 秒。\n- **符合事件定义：** 对于一个神经元子集，每个神经元在同一个时间窗内至少发放一次脉冲。\n- **神经元脉冲模型：** 在单个时间窗 $t$ 内，不同神经元的脉冲发放被建模为独立的伯努利试验，其成功概率为非平稳的 $p_i(t)$。\n- **神经元子集：** $S = \\{1, 2\\}$。\n- **时间窗口：** $\\mathcal{W} = \\{1, \\dots, 12\\}$ 个时间窗。\n- **神经元1的脉冲概率：** $t=1, \\dots, 12$ 时 $p_1(t)$ 的序列为 $(0.11, 0.12, 0.10, 0.09, 0.13, 0.15, 0.18, 0.16, 0.14, 0.12, 0.11, 0.10)$。\n- **神经元2的脉冲概率：** $t=1, \\dots, 12$ 时 $p_2(t)$ 的序列为 $(0.08, 0.09, 0.07, 0.06, 0.10, 0.12, 0.15, 0.13, 0.11, 0.09, 0.08, 0.07)$。\n- **目标：** 推导在 $\\mathcal{W}$ 内符合事件的期望数量，计算其四舍五入到四位有效数字的数值，并解释该方法的合理性。\n\n**步骤2：使用提取的已知条件进行验证**\n该问题具有科学依据，采用了计算神经科学中的一个标准模型（对分箱后的脉冲序列进行伯努利近似）。其数学表述一致且自洽，提供了所有必要的数据——概率序列 $p_1(t)$ 和 $p_2(t)$ 的长度与指定的时间窗口一致。术语精确客观。该问题是适定的，会导出一个唯一且有意义的解。它没有违反任何无效标准。\n\n**步骤3：结论与行动**\n问题被判定为**有效**。将提供完整解答。\n\n### 推导与求解\n\n让我们按照要求从概率论的核心原理开始。该分析考虑了两个神经元（索引为 $i \\in \\{1, 2\\}$）在 $T=12$ 个离散时间窗内发放的脉冲序列。\n\n设 $X_{i,t}$ 为指示随机变量，表示神经元 $i$ 在时间窗 $t$ 内的发放情况，其中 $t \\in \\{1, \\dots, 12\\}$。由于脉冲发放被建模为成功概率为 $p_i(t)$ 的伯努利试验，我们有：\n$$\nX_{i,t} =\n\\begin{cases}\n1  \\text{如果神经元 } i \\text{ 在时间窗 } t \\text{ 内发放脉冲} \\\\\n0  \\text{其他情况}\n\\end{cases}\n$$\n发放一次脉冲的概率为 $P(X_{i,t} = 1) = p_i(t)$，不发放脉冲的概率为 $P(X_{i,t} = 0) = 1 - p_i(t)$。该指示随机变量的期望为 $E[X_{i,t}] = 1 \\cdot P(X_{i,t}=1) + 0 \\cdot P(X_{i,t}=0) = p_i(t)$。\n\n时间窗 $t$ 内的一个符合事件定义为神经元1和神经元2在该时间窗内都发放脉冲的事件。设 $C_t$ 为时间窗 $t$ 内发生符合事件的指示随机变量。要发生符合事件（$C_t = 1$），必须同时有 $X_{1,t} = 1$ 和 $X_{2,t} = 1$。这意味着联合事件的指示随机变量可以表示为各个指示随机变量的乘积：\n$$C_t = X_{1,t} X_{2,t}$$\n在单个时间窗 $t$ 内，符合事件的期望数量是 $C_t$ 的期望，即 $E[C_t]$。由于 $C_t$ 是一个指示随机变量，其期望等于它所指示事件的概率：\n$$E[C_t] = P(C_t = 1) = P(X_{1,t}=1 \\text{ 且 } X_{2,t}=1)$$\n问题陈述中提到，在单个时间窗内，不同神经元的脉冲发放被建模为独立的。这是一个关键假设。在此独立性假设下，联合概率是边缘概率的乘积：\n$$P(X_{1,t}=1 \\text{ 且 } X_{2,t}=1) = P(X_{1,t}=1) \\times P(X_{2,t}=1) = p_1(t) p_2(t)$$\n因此，在时间窗 $t$ 内，符合事件的期望数量为：\n$$E[C_t] = p_1(t) p_2(t)$$\n在整个时间窗口 $\\mathcal{W}$ 内，符合事件的总数 $N_C$ 是每个时间窗内符合事件数量的总和：\n$$N_C = \\sum_{t=1}^{12} C_t$$\n为了求这个总和的期望值 $E[N_C]$，我们应用期望的线性性原理。该原理指出，随机变量之和的期望等于它们各自期望之和，即 $E[\\sum_k Y_k] = \\sum_k E[Y_k]$。这是一个基本性质，无论随机变量 $Y_k$ 是否独立，该性质都成立。在我们的情况中，这意味着我们不需要假设不同时间窗内的符合事件是独立的。\n将期望的线性性应用于 $N_C$：\n$$E[N_C] = E\\left[\\sum_{t=1}^{12} C_t\\right] = \\sum_{t=1}^{12} E[C_t]$$\n代入我们得到的 $E[C_t]$ 的表达式，我们得到符合事件总期望数量的最终公式：\n$$E[N_C] = \\sum_{t=1}^{12} p_1(t) p_2(t)$$\n\n### 假设的合理性说明\n\n问题明确要求对各时间窗求和的合理性以及建模假设进行说明。\n\n1.  **对时间窗求和：** 将每个时间窗的期望值 $\\sum_{t} E[C_t]$ 相加得到总期望计数 $E[N_C]$，其合理性由**期望的线性性**严格保证。如上所述，该性质允许将总期望分解为每个时间窗的期望之和，而无需假设*跨*时间窗的脉冲活动是独立的。\n\n2.  **建模假设：**\n    -   **伯努利脉冲模型：** 将一个时间窗内的脉冲发放表示为伯努利试验是一种近似。如果时间窗宽度 $\\Delta$ 足够小，这种近似是合理的。这被称为“类泊松小时间窗假设”。如果脉冲发放是一个瞬时率为 $\\lambda(t)$ 的泊松过程，则在一个小区间 $\\Delta$ 内发生一次或多次脉冲的概率是 $1 - \\exp(-\\lambda(t)\\Delta)$。对于小的 $\\lambda(t)\\Delta$，泰勒展开给出 $1 - (1 - \\lambda(t)\\Delta + O((\\lambda(t)\\Delta)^2)) \\approx \\lambda(t)\\Delta$。这就得到了伯努利概率 $p(t) = \\lambda(t)\\Delta$。在此假设下，时间窗内发生一次以上脉冲的概率可以忽略不计。\n    -   **神经元的独立性（在时间窗内）：** 计算 $E[C_t] = p_1(t) p_2(t)$ 关键依赖于神经元1和神经元2的脉冲发放是*在同一个时间窗内*的统计独立事件这一假设。在单元事件分析的背景下，这个假设构成了原假设（$H_0$）的基础，即符合事件以偶然预测的速率发生。然后将观察到的符合事件数量与这个期望数量进行比较，以检验是否存在超出机会水平的相关性（即“单元事件”）。\n\n### 数值计算\n\n现在我们使用所提供的数据计算 $E[N_C]$ 的值。\n序列为：\n$P_1 = (0.11, 0.12, 0.10, 0.09, 0.13, 0.15, 0.18, 0.16, 0.14, 0.12, 0.11, 0.10)$\n$P_2 = (0.08, 0.09, 0.07, 0.06, 0.10, 0.12, 0.15, 0.13, 0.11, 0.09, 0.08, 0.07)$\n\n我们计算每个时间窗 $t=1, \\dots, 12$ 的乘积 $p_1(t) p_2(t)$：\n- $t=1$: $0.11 \\times 0.08 = 0.0088$\n- $t=2$: $0.12 \\times 0.09 = 0.0108$\n- $t=3$: $0.10 \\times 0.07 = 0.0070$\n- $t=4$: $0.09 \\times 0.06 = 0.0054$\n- $t=5$: $0.13 \\times 0.10 = 0.0130$\n- $t=6$: $0.15 \\times 0.12 = 0.0180$\n- $t=7$: $0.18 \\times 0.15 = 0.0270$\n- $t=8$: $0.16 \\times 0.13 = 0.0208$\n- $t=9$: $0.14 \\times 0.11 = 0.0154$\n- $t=10$: $0.12 \\times 0.09 = 0.0108$\n- $t=11$: $0.11 \\times 0.08 = 0.0088$\n- $t=12$: $0.10 \\times 0.07 = 0.0070$\n\n将这些值相加：\n$$E[N_C] = 0.0088 + 0.0108 + 0.0070 + 0.0054 + 0.0130 + 0.0180 + 0.0270 + 0.0208 + 0.0154 + 0.0108 + 0.0088 + 0.0070$$\n$$E[N_C] = 0.1528$$\n问题要求答案四舍五入到四位有效数字。计算出的值 $0.1528$ 已经有四位有效数字。",
            "answer": "$$\\boxed{0.1528}$$"
        },
        {
            "introduction": "在计算出偶然重合的期望数量后，下一步是确定我们*观测到*的重合数量是否在统计上是令人意外的。本练习深入探讨了核心的统计检验过程，要求您使用精确的（但计算上更密集的）泊松二项分布和一种常见且高效的泊松近似来计算p值。理解这两种方法之间的差异对于正确解释结果和权衡统计建模中的利弊至关重要。",
            "id": "4202842",
            "problem": "考虑一个基于窗口的单元事件分析 (UEA)，其检验在跨时间窗格条件独立的原假设下，同步脉冲巧合是否超出偶然水平。在原模型下，每个窗格的同步巧合指示变量被建模为具有异质成功概率的独立伯努利随机变量。设窗口包含 $T$ 个离散窗格，索引为 $t \\in \\{1, 2, \\dots, T\\}$，并令 $q(t) \\in [0,1]$ 表示在独立性假设下窗格 $t$ 中发生巧合的偶然概率。定义随机变量 $X = \\sum_{t=1}^{T} B_t$，其中 $B_t \\sim \\text{Bernoulli}(q(t))$ 且对于不同的 $t$ 是独立的。$X$ 的分布是泊松二项分布。假设在窗口中测量到观测巧合计数 $k_{\\text{obs}}$。统计问题是计算在原假设下观测到至少 $k_{\\text{obs}}$ 次巧合的尾部概率（一个单边 p 值）：\n$$\np_{\\text{PB}} = \\mathbb{P}\\big(X \\ge k_{\\text{obs}}\\big).\n$$\n神经科学数据分析中常用的一种近似方法是用一个率参数为 $\\lambda = \\sum_{t=1}^{T} q(t)$ 的泊松分布来替代泊松二项分布，从而得到近似的尾部概率\n$$\np_{\\text{Pois}} = \\mathbb{P}\\big(Y \\ge k_{\\text{obs}}\\big), \\quad Y \\sim \\text{Poisson}(\\lambda).\n$$\n仅从独立伯努利试验的基本概率定律和泊松分布的定义出发，推导一种算法，该算法通过基于对每个窗格的两点分布进行逐次卷积的动态规划方法，精确计算 $p_{\\text{PB}}$。然后，对于给定的集合 $\\{q(t)\\}$ 和 $k_{\\text{obs}}$，实现精确尾部概率 $p_{\\text{PB}}$ 和泊松近似 $p_{\\text{Pois}}$ 的计算，并对它们进行定量比较。\n\n您的程序必须：\n- 使用动态规划（对每个窗格的分布进行逐次卷积）计算精确的泊松二项尾部概率 $p_{\\text{PB}}$。\n- 使用率参数 $\\lambda = \\sum_{t=1}^{T} q(t)$ 计算泊松近似尾部概率 $p_{\\text{Pois}}$。\n- 对于每个测试用例，输出一个包含三个浮点数的列表 $[p_{\\text{PB}}, p_{\\text{Pois}}, \\lvert p_{\\text{PB}} - p_{\\text{Pois}} \\rvert]$，每个浮点数都精确到小数点后 $12$ 位。\n\n您的程序应生成单行输出，其中包含所有测试用例的结果，格式为一个由方括号括起来的逗号分隔列表（例如，$ [ [\\cdot,\\cdot,\\cdot], [\\cdot,\\cdot,\\cdot], \\dots ]$）。\n\n使用以下测试套件，其中包含一般情况、边界条件和偏斜概率场景。在每个用例中，样本窗口是指定列表 $\\{q(t)\\}$ 的长度，观测计数是 $k_{\\text{obs}}$。\n\n- 测试用例 $1$（一般情况，异质小概率）：\n  - $\\{q(t)\\} = [\\, 0.02, 0.03, 0.025, 0.015, 0.04, 0.03, 0.02, 0.05, 0.01, 0.035, 0.025, 0.02, 0.03, 0.015, 0.04, 0.025, 0.02, 0.03, 0.02, 0.05, 0.015, 0.02, 0.03, 0.025, 0.02, 0.035, 0.025, 0.02, 0.015, 0.04, 0.03, 0.02, 0.015, 0.05, 0.02, 0.025, 0.03, 0.02, 0.035, 0.015 \\,]$\n  - $k_{\\text{obs}} = 4$\n- 测试用例 $2$（均匀小概率，长窗口）：\n  - $\\{q(t)\\} = [\\, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02 \\,]$\n  - $k_{\\text{obs}} = 3$\n- 测试用例 $3$（偏斜分布，含少数大概率）：\n  - $\\{q(t)\\} = [\\, 0.30, 0.25, 0.20, 0.05, 0.01, 0.02, 0.01, 0.05, 0.02, 0.01, 0.03, 0.01, 0.02, 0.01, 0.01 \\,]$\n  - $k_{\\text{obs}} = 5$\n- 测试用例 $4$（边界情况：零阈值）：\n  - $\\{q(t)\\} = [\\, 0.05, 0.02, 0.03, 0.04, 0.01, 0.02, 0.05, 0.03, 0.02, 0.01 \\,]$\n  - $k_{\\text{obs}} = 0$\n- 测试用例 $5$（边界情况：全成功阈值）：\n  - $\\{q(t)\\} = [\\, 0.10, 0.10, 0.10, 0.10, 0.10, 0.10, 0.10, 0.10, 0.10, 0.10 \\,]$\n  - $k_{\\text{obs}} = 10$\n\n角度单位不适用。不需要物理单位。您的程序必须将其单行输出格式化为一个逗号分隔的列表，该列表包含每个测试用例的列表，每个内部列表包含三个浮点数，小数点后精确到 $12$ 位。",
            "solution": "这个问题是有效的，因为它具有科学依据、问题明确、客观，并且包含了推导和实现解决方案所需的所有必要信息。\n\n问题的核心是计算一个随机变量 $X$ 的尾部概率，该变量是 $T$ 个独立但不同分布的伯努利随机变量之和。\n设 $X = \\sum_{t=1}^{T} B_t$，其中 $B_t \\sim \\text{Bernoulli}(q(t))$ 且对于 $t \\in \\{1, 2, \\dots, T\\}$ 是独立的。$X$ 的分布被称为泊松二项分布。我们的任务是计算精确的尾部概率 $p_{\\text{PB}} = \\mathbb{P}(X \\ge k_{\\text{obs}})$，并将其与泊松近似 $p_{\\text{Pois}}$ 进行比较。\n\n首先，我们推导一个算法来计算 $X$ 的精确概率质量函数 (PMF)，从中可以得到 $p_{\\text{PB}}$。该算法基于动态规划，利用了逐次卷积的原理。\n设 $X_n = \\sum_{t=1}^{n} B_t$ 是前 $n$ 个伯努利变量的和。$X_n$ 的 PMF 可以递归计算。基本情况是 $n=1$，此时 $X_1 = B_1$。$X_1$ 的 PMF 由下式给出：\n$$ \\mathbb{P}(X_1=0) = 1 - q(1) $$\n$$ \\mathbb{P}(X_1=1) = q(1) $$\n对于递归步骤，我们将 $X_n$ 表示为 $X_{n-1}$ 和 $B_n$ 的形式：\n$$ X_n = X_{n-1} + B_n $$\n由于 $B_n$ 独立于 $X_{n-1}$（它是 $B_1, \\dots, B_{n-1}$ 的和），$X_n$ 的 PMF 是 $X_{n-1}$ 和 $B_n$ 的 PMF 的卷积。设 $P_n(k) = \\mathbb{P}(X_n=k)$。卷积公式为：\n$$ P_n(k) = \\sum_{j=0}^{k} \\mathbb{P}(X_{n-1}=j) \\cdot \\mathbb{P}(B_n=k-j) $$\n由于 $B_n$ 只能取值 $0$ 或 $1$，该和式简化为两项：\n$$ P_n(k) = \\mathbb{P}(X_{n-1}=k) \\cdot \\mathbb{P}(B_n=0) + \\mathbb{P}(X_{n-1}=k-1) \\cdot \\mathbb{P}(B_n=1) $$\n代入伯努利试验 $B_n$ 的概率，我们得到递推关系：\n$$ P_n(k) = P_{n-1}(k) \\cdot (1 - q(n)) + P_{n-1}(k-1) \\cdot q(n) $$\n其中约定，如果 $k  0$ 或 $k > n-1$，则 $P_{n-1}(k)=0$。\n\n这个递推关系构成了动态规划算法的基础。我们可以将 $X_n$ 的 PMF 表示为一个概率数组，例如 `pmf_n`。我们从 $X_0$ 的 PMF 开始，这是一个以概率 $1$ 等于 $0$ 的退化随机变量。这表示为一个数组 `[1.0]`。然后我们从 $n=1$ 迭代到 $T$，在每个步骤 $n$ 中，使用 `pmf_{n-1}` 和 $q(n)$ 根据递推关系计算 `pmf_n`。\n算法流程如下：\n1. 初始化一个大小为 $T+1$ 的概率向量 `pmf` 来表示和的 PMF。对于 $X_0$，这是 `[1.0, 0.0, ..., 0.0]`。\n2. 对于从 $1$ 到 $T$ 的每次试验 $t$，其概率为 $q(t)$：\n   更新 `pmf` 向量。设此步骤前的向量为 $P_{t-1}$。新的向量 $P_t$ 通过从 $k=t$ 向下迭代到 $1$ 来计算：\n   $P_t(k) \\leftarrow P_{t-1}(k) \\cdot (1 - q(t)) + P_{t-1}(k-1) \\cdot q(t)$。$k=0$ 的情况是特殊的：$P_t(0) \\leftarrow P_{t-1}(0) \\cdot (1 - q(t))$。\n   反向迭代对于 `pmf` 数组的就地更新至关重要。\n3. 在遍历所有 $T$ 次试验后，`pmf` 向量持有 $X = X_T$ 的 PMF。\n然后，所需的尾部概率是所有大于或等于 $k_{\\text{obs}}$ 的结果的概率之和：\n$$ p_{\\text{PB}} = \\mathbb{P}(X \\ge k_{\\text{obs}}) = \\sum_{k=k_{\\text{obs}}}^{T} P_T(k) $$\n\n接下来，我们讨论泊松近似。泊松二项分布由一个泊松分布近似，其率参数 $\\lambda$ 等于各个伯努利概率之和：\n$$ \\lambda = \\sum_{t=1}^{T} q(t) $$\n设 $Y \\sim \\text{Poisson}(\\lambda)$。$Y$ 的 PMF 是：\n$$ \\mathbb{P}(Y=k) = \\frac{\\lambda^k e^{-\\lambda}}{k!} \\quad \\text{for } k=0, 1, 2, \\dots $$\n近似的尾部概率 $p_{\\text{Pois}}$ 是 $\\mathbb{P}(Y \\ge k_{\\text{obs}})$。通过累积分布函数 (CDF) 的补来计算这个值在数值上更稳定：\n$$ p_{\\text{Pois}} = \\mathbb{P}(Y \\ge k_{\\text{obs}}) = 1 - \\mathbb{P}(Y  k_{\\text{obs}}) = 1 - \\sum_{k=0}^{k_{\\text{obs}}-1} \\mathbb{P}(Y=k) $$\n对于 $k_{\\text{obs}}=0$，这个和是空的，其值为 $0$，所以 $p_{\\text{Pois}}=1$。对于 $k_{\\text{obs}}>0$，我们可以迭代计算这个和。设 $S_{j} = \\sum_{k=0}^{j} \\mathbb{P}(Y=k)$。和的各项可以递归计算：\n$$ \\mathbb{P}(Y=k) = \\mathbb{P}(Y=k-1) \\cdot \\frac{\\lambda}{k} $$\n从 $\\mathbb{P}(Y=0)=e^{-\\lambda}$ 开始。我们将这些项从 $k=0$ 到 $k_{\\text{obs}}-1$ 求和以找到 CDF 值，然后用 $1$ 减去它得到尾部概率 $p_{\\text{Pois}}$。\n\n最后，定量比较是绝对差 $|p_{\\text{PB}} - p_{\\text{Pois}}|$。该实现将为每个测试用例计算这三个值。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef compute_poisson_binomial_tail(q_list, k_obs):\n    \"\"\"\n    Computes the exact tail probability P(X >= k_obs) for a Poisson Binomial distribution.\n    The distribution is the sum of independent Bernoulli trials with probabilities q_list.\n    This is achieved using a dynamic programming approach based on successive convolutions.\n    \"\"\"\n    T = len(q_list)\n\n    if k_obs > T:\n        return 0.0\n    if k_obs  0:\n        k_obs = 0\n    \n    # pmf array stores P(X_n = k) at index k.\n    # Initialize for a sum of 0 trials, where P(sum=0) = 1.\n    pmf = np.zeros(T + 1, dtype=np.float64)\n    pmf[0] = 1.0\n    \n    # Iterate through each Bernoulli trial\n    # num_trials tracks the number of trials processed so far (from 1 to T)\n    num_trials = 0\n    for q_t in q_list:\n        num_trials += 1\n        # Update the pmf from a sum of num_trials-1 Bernoullis to num_trials.\n        # The recurrence is: P_n(k) = P_{n-1}(k)*(1-q_t) + P_{n-1}(k-1)*q_t\n        # We iterate backwards to use the values from the previous step (pmf_{n-1})\n        # before they are overwritten.\n        # The loop range covers a max possible sum of num_trials.\n        for k in range(num_trials, 0, -1):\n            pmf[k] = pmf[k] * (1.0 - q_t) + pmf[k - 1] * q_t\n        \n        # Update the k=0 case separately\n        pmf[0] = pmf[0] * (1.0 - q_t)\n\n    # The tail probability is the sum of probabilities from k_obs to T.\n    p_pb_tail = np.sum(pmf[k_obs:])\n    return p_pb_tail\n\ndef compute_poisson_tail(q_list, k_obs):\n    \"\"\"\n    Computes the tail probability P(Y >= k_obs) for a Poisson distribution\n    approximating the Poisson Binomial distribution.\n    The rate lambda is the sum of the Bernoulli probabilities.\n    \"\"\"\n    if k_obs = 0:\n        return 1.0\n\n    lam = np.sum(q_list)\n\n    # If lambda is 0, the only possible outcome is 0.\n    # P(Y=0) = 1, P(Y>0) = 0.\n    # The tail P(Y >= k_obs) is 0 for k_obs > 0.\n    if lam == 0.0:\n        return 0.0\n\n    # Compute CDF P(Y  k_obs) = sum_{k=0}^{k_obs-1} P(Y=k)\n    # P(Y=k) = exp(-lam) * lam^k / k!\n    # We compute terms iteratively: term_k = term_{k-1} * lam / k\n    # Start with k=0 term\n    term = np.exp(-lam)\n    cdf_sum = term\n    \n    for k in range(1, k_obs):\n        term = term * lam / k\n        cdf_sum += term\n        \n    p_pois_tail = 1.0 - cdf_sum\n    # Due to floating point errors, result can be slightly negative. Clip at 0.\n    return max(0.0, p_pois_tail)\n\ndef solve():\n    \"\"\"\n    Main function to run test cases and produce the final output.\n    \"\"\"\n    test_cases = [\n        # Test case 1 (general, heterogeneous small probabilities)\n        ([0.02, 0.03, 0.025, 0.015, 0.04, 0.03, 0.02, 0.05, 0.01, 0.035, 0.025, 0.02, 0.03, 0.015, 0.04, 0.025, 0.02, 0.03, 0.02, 0.05, 0.015, 0.02, 0.03, 0.025, 0.02, 0.035, 0.025, 0.02, 0.015, 0.04, 0.03, 0.02, 0.015, 0.05, 0.02, 0.025, 0.03, 0.02, 0.035, 0.015], 4),\n        # Test case 2 (uniform small probabilities, longer window)\n        ([0.02] * 50, 3),\n        # Test case 3 (skewed with a few large probabilities)\n        ([0.30, 0.25, 0.20, 0.05, 0.01, 0.02, 0.01, 0.05, 0.02, 0.01, 0.03, 0.01, 0.02, 0.01, 0.01], 5),\n        # Test case 4 (boundary: zero threshold)\n        ([0.05, 0.02, 0.03, 0.04, 0.01, 0.02, 0.05, 0.03, 0.02, 0.01], 0),\n        # Test case 5 (boundary: full successes threshold)\n        ([0.10] * 10, 10),\n    ]\n\n    all_results_formatted = []\n    for q_list, k_obs in test_cases:\n        \n        p_pb = compute_poisson_binomial_tail(q_list, k_obs)\n        p_pois = compute_poisson_tail(q_list, k_obs)\n        diff = abs(p_pb - p_pois)\n        \n        case_results = [p_pb, p_pois, diff]\n        formatted_case_results = [f\"{val:.12f}\" for val in case_results]\n        all_results_formatted.append(f\"[{','.join(formatted_case_results)}]\")\n\n    print(f\"[{','.join(all_results_formatted)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "真实的神经科学实验通常涉及同时分析成百上千个神经元对的同步性。如此大量的检验会增加纯粹由偶然性导致“显著”结果的风险。本练习介绍了Benjamini-Hochberg程序，这是一种控制错误发现率（FDR）的强大方法，可确保我们发现的“单元事件”列表在统计上是稳健的，而不仅仅是虚假警报的集合。",
            "id": "4202845",
            "problem": "考虑神经科学数据分析中的一组单元事件 (UE) 显著性检验，其中每个检验在独立发放的零假设下都会产生一个p值。根据基本原理，p值是在零假设下的尾部概率，而错误发现率 (FDR) 定义为所有拒绝中错误拒绝的期望比例。您需要实现用于FDR控制的 Benjamini–Hochberg (BH) 程序。Benjamini–Hochberg (BH) 程序是一种升阶多重比较方法，在检验统计量独立或满足子集正回归依赖 (PRDS) 的条件下，它保证FDR以目标水平为界。在此任务中，您将把BH程序应用于合成的UE p值矩阵，并确定在指定的FDR水平下哪些UE检验是显著的。\n\n使用的基本依据：零假设下p值的定义、错误发现率的定义，以及Benjamini–Hochberg程序在独立性或正回归依赖条件下将错误发现率控制在目标水平这一经过充分检验的事实。请勿在问题陈述中使用任何快捷公式；相反，应依赖于对p值进行排序并选择一个数据驱动的拒绝阈值的概念性步骤，以确保在独立或PRDS情境下控制FDR。\n\n您的程序必须为每个提供的合成测试用例执行以下步骤：\n- 将UE检验的二维p值矩阵展平为单个p值列表。\n- 在指定的FDR水平 $q$（以小数形式表示，而非百分比）下应用Benjamini–Hochberg升阶程序以确定拒绝阈值，包括精确处于阈值上的并列值。\n- 将被拒绝的p值映射回其原始矩阵坐标。\n- 以从零开始的行主序索引对 $[r,c]$ 的形式报告显著UE检验的坐标，并按 $(r,c)$ 进行字典序排序。\n\n假设p值为 $[0,1]$ 范围内的有效概率，并为控制FDR的目的假设检验之间相互独立。本问题不涉及角度。没有物理单位。\n\n测试套件和要求输出：\n您必须处理以下五个测试用例。对于每个测试用例，输出一个 $[r,c]$ 对的列表，用以指示显著的UE坐标，使用从零开始的索引并按行主序排列。最终输出必须是单行，内容为用方括号括起来的、由各测试用例结果组成的逗号分隔列表。\n\n- 测试用例A（一般情况，混合了较小和中等的p值）：\n  设p值矩阵为\n  $$M_A=\\begin{bmatrix}\n  0.001  0.20  0.04  0.15 \\\\\n  0.005  0.02  0.50  0.07 \\\\\n  0.10  0.003  0.80  0.25\n  \\end{bmatrix},$$\n  目标FDR水平 $q=0.10$。\n\n- 测试用例B（包含零、一和重复中等p值的边界情况）：\n  设p值矩阵为\n  $$M_B=\\begin{bmatrix}\n  0.0  0.99  0.05  1.0  0.0005 \\\\\n  0.001  0.07  0.5  0.05  0.05\n  \\end{bmatrix},$$\n  目标FDR水平 $q=0.05$。\n\n- 测试用例C（在自适应阈值处处理并列值；与升阶边界完全相等）：\n  设p值矩阵为\n  $$M_C=\\begin{bmatrix}\n  0.01  0.02  0.03  0.04 \\\\\n  0.05  0.06  0.07  0.08 \\\\\n  0.09  0.10  0.11  0.12\n  \\end{bmatrix},$$\n  目标FDR水平 $q=0.12$。\n\n- 测试用例D（单行矩阵；若干较小和中等的p值）：\n  设p值矩阵为\n  $$M_D=\\begin{bmatrix}\n  0.3  0.2  0.25  0.01  0.6  0.05  0.07  0.04\n  \\end{bmatrix},$$\n  目标FDR水平 $q=0.25$。\n\n- 测试用例E（在非常严格的水平下预计无拒绝的边界情况）：\n  设p值矩阵为\n  $$M_E=\\begin{bmatrix}\n  0.2  0.2 \\\\\n  0.2  0.2\n  \\end{bmatrix},$$\n  目标FDR水平 $q=0.001$。\n\n最终输出格式规范：\n您的程序应生成单行输出，其中包含五个测试用例的结果，形式为一个用方括号括起来的逗号分隔列表，其中每个元素是按行主序排序的显著坐标 $[r,c]$ 的每个测试用例列表。例如，格式应为\n$$[\\text{caseA\\_result},\\text{caseB\\_result},\\text{caseC\\_result},\\text{caseD\\_result},\\text{caseE\\_result}],$$\n其中每个 $\\text{caseX\\_result}$ 是一个整数列表的列表，例如\n$$[[0,0],[0,2],[1,1]],$$\n且整体输出必须是单行，不含任何额外文本。",
            "solution": "所提出的问题是标准统计程序 Benjamini-Hochberg (BH) 方法在神经科学数据分析中一个常见场景的有效且定义明确的应用，即对单元事件 (UE) 显著性检验中的多重比较进行校正。该问题具有科学依据、客观，并提供了为每个测试用例推导出唯一解所需的所有必要信息。\n\n问题的核心是在同时进行大量统计检验时，如何管理在发现真实效应和避免错误警报之间的权衡。如果对 $m$ 个检验中的每一个都在显著性水平 $\\alpha$ 下进行评估，那么即使所有零假设都为真，也预计会产生 $m \\times \\alpha$ 次错误拒绝。错误发现率 (FDR) 是一个比控制族错误率 (FWER) 更强大且通常更合适的多重检验控制标准。FDR是“发现”（被拒绝的零假设）中实际上是错误的发现所占的期望比例。Benjamini-Hochberg程序提供了一种将FDR控制在指定水平 $q$ 的方法。\n\n让我们将此场景形式化。我们执行 $m$ 次假设检验，得到一组p值 $\\{p_1, p_2, \\dots, p_m\\}$。检验总数 $m$ 是输入p值矩阵维度的乘积。我们可以将这 $m$ 次检验的结果分类到一个列联表中：\n\n| | 宣告为不显著 | 宣告为显著 | 总计 |\n|---|---|---|---|\n| 零假设为真 | $U$ (真阴性) | $V$ (假阳性/第一类错误) | $m_0$ |\n| 零假设为假 | $T$ (假阴性/第二类错误) | $S$ (真阳性) | $m_1$ |\n| 总计 | $m-R$ | $R$ (总拒绝数) | $m$ |\n\n错误发现比例 (FDP) 是假阳性数与总拒绝数的比率，即 $Q = V/R$，如果 $R=0$ 则定义 $Q$ 为 $0$。错误发现率 (FDR) 是该值的期望，即 $FDR = E[Q] = E[V/R]$。BH程序保证，在 $m$ 个检验是独立的（或满足一个称为子集正回归依赖(PRDS)的较弱条件）的假设下，$FDR \\le \\frac{m_0}{m} q \\le q$。\n\nBenjamini-Hochberg升阶程序如下：\n\n$1$. 将 $m$ 个p值从小到大排序：$p_{(1)} \\le p_{(2)} \\le \\dots \\le p_{(m)}$。这些排序后的p值与其原始假设 $H_{(1)}, H_{(2)}, \\dots, H_{(m)}$ 相关联。\n\n$2$. 对于给定的FDR目标水平 $q$，找到最大的秩 $k$，使得该秩上的p值 $p_{(k)}$ 满足条件：\n$$p_{(k)} \\le \\frac{k}{m}q$$\n\n$3$. 如果存在这样的 $k$，则拒绝所有 $i = 1, 2, \\dots, k$ 的零假设 $H_{(i)}$。也就是说，所有对应于 $k$ 个最小p值的假设都被宣告为显著。如果不存在这样的 $k$，则不拒绝任何假设。\n\n为了针对给定问题实现此程序，我们必须对每个由p值矩阵 $M$ 和目标FDR水平 $q$ 定义的测试用例执行以下算法步骤：\n\n$1$. 将大小为 $R \\times C$ 的二维矩阵 $M$ 展平为一维p值列表。检验总数为 $m = R \\times C$。为了将结果映射回原始矩阵，我们必须为每个p值保留其原始的从零开始的坐标 $(r, c)$。一个实用的方法是创建一个元组列表，其中每个元组的形式为 $(p_{\\text{值}}, r, c)$。\n\n$2$. 将这个包含 $m$ 个元组的列表根据p值按升序排序。这将产生排序后的p值 $p_{(1)}, p_{(2)}, \\dots, p_{(m)}$ 及其对应的原始坐标。\n\n$3$. 然后我们找到满足BH条件的最大秩 $k$。这可以通过从 $k=m$ 向下迭代到 $k=1$ 来高效完成。我们找到的第一个满足 $p_{(k)} \\le \\frac{k}{m}q$ 的 $k$ 就是最大的此类 $k$。设此值为 $k_{\\text{max}}$。如果循环完成仍未找到这样的 $k$，则 $k_{\\text{max}} = 0$，没有p值是显著的。\n\n$4$. 如果 $k_{\\text{max}}  0$，我们将秩从 $1$ 到 $k_{\\text{max}}$ 的所有p值识别为显著。这些对应于我们排序列表中的前 $k_{\\text{max}}$ 个元素。\n\n$5$. 提取这 $k_{\\text{max}}$ 个显著检验的原始坐标 $(r, c)$。\n\n$6$. 最后，将此显著坐标列表按字典序（先按行索引 $r$，再按列索引 $c$）排序，以生成该测试用例的最终结果，格式化为 $[r,c]$ 对的列表。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef apply_bh(p_matrix: np.ndarray, q: float) -> list[list[int]]:\n    \"\"\"\n    Applies the Benjamini-Hochberg procedure to a matrix of p-values.\n\n    Args:\n        p_matrix: A numpy array of p-values.\n        q: The target False Discovery Rate (FDR) level.\n\n    Returns:\n        A list of [row, col] coordinates of significant tests, sorted lexicographically.\n    \"\"\"\n    if p_matrix.size == 0:\n        return []\n\n    m = p_matrix.size\n    \n    # Step 1: Flatten the p-value matrix while keeping original indices.\n    p_values_with_indices = []\n    for (r, c), p_val in np.ndenumerate(p_matrix):\n        p_values_with_indices.append({'p_val': p_val, 'coords': [r, c]})\n\n    # Step 2: Sort the list by p-value in ascending order.\n    # Python's sort is stable, which is good practice but not strictly required here.\n    p_values_with_indices.sort(key=lambda x: x['p_val'])\n    \n    # Step 3: Find the largest k such that p_(k) = (k/m) * q.\n    k_max = 0\n    # Iterate from k=m down to 1 to find the largest k that satisfies the condition.\n    for k in range(m, 0, -1):\n        p_k = p_values_with_indices[k - 1]['p_val']\n        bh_threshold = (k / m) * q\n        if p_k = bh_threshold:\n            k_max = k\n            break\n            \n    # Step 4: If no such k is found, no rejections. Otherwise, collect significant results.\n    if k_max == 0:\n        return []\n    \n    significant_tests = p_values_with_indices[:k_max]\n    \n    # Step 5  6: Extract coordinates and sort them lexicographically.\n    significant_coords = [item['coords'] for item in significant_tests]\n    significant_coords.sort()\n    \n    return significant_coords\n\ndef format_result_list(results: list) -> str:\n    \"\"\"Formats a list of lists of coordinates into the required string format.\"\"\"\n    if not results:\n        return '[]'\n    \n    inner_parts = [f'[{r},{c}]' for r, c in results]\n    return f\"[{','.join(inner_parts)}]\"\n\ndef solve():\n    \"\"\"\n    Defines and runs the test cases, printing the final formatted output.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # Test case A\n        (np.array([\n            [0.001, 0.20, 0.04, 0.15],\n            [0.005, 0.02, 0.50, 0.07],\n            [0.10, 0.003, 0.80, 0.25]\n        ]), 0.10),\n        # Test case B\n        (np.array([\n            [0.0, 0.99, 0.05, 1.0, 0.0005],\n            [0.001, 0.07, 0.5, 0.05, 0.05]\n        ]), 0.05),\n        # Test case C\n        (np.array([\n            [0.01, 0.02, 0.03, 0.04],\n            [0.05, 0.06, 0.07, 0.08],\n            [0.09, 0.10, 0.11, 0.12]\n        ]), 0.12),\n        # Test case D\n        (np.array(\n           [[0.3, 0.2, 0.25, 0.01, 0.6, 0.05, 0.07, 0.04]]\n        ), 0.25),\n        # Test case E\n        (np.array([\n            [0.2, 0.2],\n            [0.2, 0.2]\n        ]), 0.001)\n    ]\n\n    results = []\n    for p_matrix, q in test_cases:\n        result = apply_bh(p_matrix, q)\n        results.append(result)\n\n    # Format the final output string as per the specification.\n    str_results = [format_result_list(res) for res in results]\n    final_output_string = f\"[{','.join(str_results)}]\"\n    \n    print(final_output_string)\n\nsolve()\n```"
        }
    ]
}