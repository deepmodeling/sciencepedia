{
    "hands_on_practices": [
        {
            "introduction": "The cornerstone of Unitary Event Analysis is comparing an observed number of synchronous spikes to the number expected purely by chance. This first practice challenges you to derive this expected count from fundamental principles, assuming neurons fire independently but allowing for their rates to change over time . Mastering this calculation is essential for understanding the null hypothesis that Unitary Event Analysis is designed to test.",
            "id": "4202846",
            "problem": "Consider a dataset analyzed with Unitary Event (UE) analysis, where spike trains are discretized into non-overlapping bins of width $\\Delta = 5 \\times 10^{-3}$ seconds, and a coincidence is defined when each neuron in a specified subset spikes at least once within the same bin. Assume that within a single bin $t$, the spiking of different neurons is modeled as independent Bernoulli trials with success probabilities $p_i(t)$ that can vary across bins due to nonstationary firing rates. For the subset $S = \\{1, 2\\}$, the estimated per-bin spike probabilities for bins $t = 1, \\dots, 12$ are given by the sequences\n$p_1(1), \\dots, p_1(12) = (0.11, 0.12, 0.10, 0.09, 0.13, 0.15, 0.18, 0.16, 0.14, 0.12, 0.11, 0.10)$\nand\n$p_2(1), \\dots, p_2(12) = (0.08, 0.09, 0.07, 0.06, 0.10, 0.12, 0.15, 0.13, 0.11, 0.09, 0.08, 0.07)$.\nStarting from core principles of probability (indicator random variables and linearity of expectation) and the Bernoulli approximation of per-bin spiking under the Poisson-like small-bin assumption, derive the expected number of coincidences in the window $\\mathcal{W} = \\{1, \\dots, 12\\}$ for the subset $S$ and compute its numerical value. In addition, explain the modeling and mathematical assumptions that justify summation over bins to obtain the expected count from per-bin coincidence probabilities. Express your final numerical answer as a dimensionless count rounded to four significant figures.",
            "solution": "The problem asks for the derivation and computation of the expected number of coincidences in a dataset analyzed with Unitary Event (UE) analysis. I will first validate the problem statement, then proceed with a rigorous derivation based on first principles of probability, explain the underlying assumptions, and finally compute the numerical value.\n\n### Problem Validation\n\n**Step 1: Extract Givens**\n- **Analysis Method:** Unitary Event (UE) analysis.\n- **Bin Width:** $\\Delta = 5 \\times 10^{-3}$ seconds.\n- **Coincidence Definition:** For a subset of neurons, each neuron spikes at least once within the same bin.\n- **Neuron Spiking Model:** Within a single bin $t$, the spiking of different neurons is modeled as independent Bernoulli trials with non-stationary success probabilities $p_i(t)$.\n- **Neuron Subset:** $S = \\{1, 2\\}$.\n- **Time Window:** $\\mathcal{W} = \\{1, \\dots, 12\\}$ bins.\n- **Spike Probabilities for Neuron 1:** The sequence of $p_1(t)$ for $t=1, \\dots, 12$ is $(0.11, 0.12, 0.10, 0.09, 0.13, 0.15, 0.18, 0.16, 0.14, 0.12, 0.11, 0.10)$.\n- **Spike Probabilities for Neuron 2:** The sequence of $p_2(t)$ for $t=1, \\dots, 12$ is $(0.08, 0.09, 0.07, 0.06, 0.10, 0.12, 0.15, 0.13, 0.11, 0.09, 0.08, 0.07)$.\n- **Objective:** Derive the expected number of coincidences in $\\mathcal{W}$, compute its numerical value rounded to four significant figures, and explain the justifications for the method.\n\n**Step 2: Validate Using Extracted Givens**\nThe problem is scientifically grounded, employing a standard model in computational neuroscience (Bernoulli approximation for binned spike trains). The mathematical formulation is consistent and self-contained, providing all necessary data—the sequences of probabilities $p_1(t)$ and $p_2(t)$ have lengths consistent with the specified time window. The terminology is precise and objective. The problem is well-posed, leading to a unique and meaningful solution. It does not violate any of the invalidity criteria.\n\n**Step 3: Verdict and Action**\nThe problem is deemed **valid**. A full solution will be provided.\n\n### Derivation and Solution\n\nLet us begin from the core principles of probability as requested. The analysis considers spike trains from two neurons, indexed $i \\in \\{1, 2\\}$, over a time window of $T=12$ discrete bins.\n\nLet $X_{i,t}$ be the indicator random variable representing the spiking of neuron $i$ in bin $t$, where $t \\in \\{1, \\dots, 12\\}$. Since the spiking is modeled as a Bernoulli trial with success probability $p_i(t)$, we have:\n$$\nX_{i,t} =\n\\begin{cases}\n1 & \\text{if neuron } i \\text{ spikes in bin } t \\\\\n0 & \\text{otherwise}\n\\end{cases}\n$$\nThe probability of a spike is $P(X_{i,t} = 1) = p_i(t)$, and the probability of no spike is $P(X_{i,t} = 0) = 1 - p_i(t)$. The expectation of this indicator variable is $E[X_{i,t}] = 1 \\cdot P(X_{i,t}=1) + 0 \\cdot P(X_{i,t}=0) = p_i(t)$.\n\nA coincidence in bin $t$ is defined as the event where both neuron $1$ and neuron $2$ spike in that bin. Let $C_t$ be the indicator random variable for a coincidence in bin $t$. For a coincidence to occur ($C_t = 1$), we must have both $X_{1,t} = 1$ and $X_{2,t} = 1$. This means the indicator variable for the joint event can be expressed as the product of the individual indicator variables:\n$$C_t = X_{1,t} X_{2,t}$$\nThe expected number of coincidences in a single bin $t$ is the expectation of $C_t$, which is $E[C_t]$. Since $C_t$ is an indicator variable, its expectation is equal to the probability of the event it indicates:\n$$E[C_t] = P(C_t = 1) = P(X_{1,t}=1 \\text{ and } X_{2,t}=1)$$\nThe problem states that the spiking of different neurons within a single bin is modeled as independent. This is a critical assumption. Under this assumption of independence, the joint probability is the product of the marginal probabilities:\n$$P(X_{1,t}=1 \\text{ and } X_{2,t}=1) = P(X_{1,t}=1) \\times P(X_{2,t}=1) = p_1(t) p_2(t)$$\nTherefore, the expected number of coincidences in bin $t$ is:\n$$E[C_t] = p_1(t) p_2(t)$$\nThe total number of coincidences, $N_C$, across the entire window $\\mathcal{W}$ is the sum of the coincidences in each bin:\n$$N_C = \\sum_{t=1}^{12} C_t$$\nTo find the expected value of this sum, $E[N_C]$, we apply the principle of linearity of expectation. This principle states that the expectation of a sum of random variables is equal to the sum of their individual expectations, $E[\\sum_k Y_k] = \\sum_k E[Y_k]$. It is a fundamental property that holds regardless of whether the random variables $Y_k$ are independent. In our case, this means we do not need to assume that coincidences in different bins are independent events.\nApplying linearity of expectation to $N_C$:\n$$E[N_C] = E\\left[\\sum_{t=1}^{12} C_t\\right] = \\sum_{t=1}^{12} E[C_t]$$\nSubstituting our expression for $E[C_t]$, we arrive at the final formula for the expected total number of coincidences:\n$$E[N_C] = \\sum_{t=1}^{12} p_1(t) p_2(t)$$\n\n### Justification of Assumptions\n\nThe problem explicitly asks for the justification for summing per-bin quantities and for a statement of the modeling assumptions.\n\n1.  **Summation over Bins:** The summation of the per-bin expected values, $\\sum_{t} E[C_t]$, to obtain the total expected count $E[N_C]$ is rigorously justified by the **linearity of expectation**. As derived above, this property allows the decomposition of the total expectation into a sum of expectations for each bin, without requiring the assumption of independence of spiking activity *across* bins.\n\n2.  **Modeling Assumptions:**\n    -   **Bernoulli Spike Model:** The representation of spiking in a bin as a Bernoulli trial is an approximation. It is justified if the bin width $\\Delta$ is sufficiently small. This is referred to as the \"Poisson-like small-bin assumption\". If spiking is a Poisson process with an instantaneous rate $\\lambda(t)$, the probability of one or more spikes in a small interval $\\Delta$ is $1 - \\exp(-\\lambda(t)\\Delta)$. For small $\\lambda(t)\\Delta$, a Taylor expansion gives $1 - (1 - \\lambda(t)\\Delta + O((\\lambda(t)\\Delta)^2)) \\approx \\lambda(t)\\Delta$. This gives the Bernoulli probability $p(t) = \\lambda(t)\\Delta$. The probability of more than one spike in the bin is negligible under this assumption.\n    -   **Independence of Neurons (within a bin):** The calculation $E[C_t] = p_1(t) p_2(t)$ relies critically on the assumption that the spiking of neuron 1 and neuron 2 are statistically independent events *within the same bin*. In the context of UE analysis, this assumption forms the basis of the null hypothesis ($H_0$) that coincidences occur at a rate predicted by chance. The observed number of coincidences is then compared to this expected number to test for excess correlation (a \"unitary event\").\n\n### Numerical Computation\n\nWe now compute the value of $E[N_C]$ using the provided data.\nThe sequences are:\n$P_1 = (0.11, 0.12, 0.10, 0.09, 0.13, 0.15, 0.18, 0.16, 0.14, 0.12, 0.11, 0.10)$\n$P_2 = (0.08, 0.09, 0.07, 0.06, 0.10, 0.12, 0.15, 0.13, 0.11, 0.09, 0.08, 0.07)$\n\nWe calculate the product $p_1(t) p_2(t)$ for each bin $t=1, \\dots, 12$:\n- $t=1$: $0.11 \\times 0.08 = 0.0088$\n- $t=2$: $0.12 \\times 0.09 = 0.0108$\n- $t=3$: $0.10 \\times 0.07 = 0.0070$\n- $t=4$: $0.09 \\times 0.06 = 0.0054$\n- $t=5$: $0.13 \\times 0.10 = 0.0130$\n- $t=6$: $0.15 \\times 0.12 = 0.0180$\n- $t=7$: $0.18 \\times 0.15 = 0.0270$\n- $t=8$: $0.16 \\times 0.13 = 0.0208$\n- $t=9$: $0.14 \\times 0.11 = 0.0154$\n- $t=10$: $0.12 \\times 0.09 = 0.0108$\n- $t=11$: $0.11 \\times 0.08 = 0.0088$\n- $t=12$: $0.10 \\times 0.07 = 0.0070$\n\nSumming these values:\n$$E[N_C] = 0.0088 + 0.0108 + 0.0070 + 0.0054 + 0.0130 + 0.0180 + 0.0270 + 0.0208 + 0.0154 + 0.0108 + 0.0088 + 0.0070$$\n$$E[N_C] = 0.1528$$\nThe problem requires the answer to be rounded to four significant figures. The calculated value $0.1528$ already has four significant figures.",
            "answer": "$$\\boxed{0.1528}$$"
        },
        {
            "introduction": "Once you have an observed coincidence count, you must determine how surprising it is under the null hypothesis. This exercise guides you through implementing a dynamic programming algorithm to compute the *exact* p-value using the Poisson Binomial distribution . By comparing this exact result to the widely used Poisson approximation, you will gain critical insight into the accuracy and limitations of different statistical models in neuroscience.",
            "id": "4202842",
            "problem": "Consider a window-based Unitary Event Analysis (UEA), where one tests for excess synchronous spike coincidences beyond chance under a null hypothesis of conditional independence across time bins. Under the null model, per-bin synchronous coincidence indicators are modeled as independent Bernoulli random variables with heterogeneous success probabilities. Let the window contain $T$ discrete bins indexed by $t \\in \\{1, 2, \\dots, T\\}$, and let $q(t) \\in [0,1]$ denote the chance probability of a coincidence in bin $t$ under independence. Define the random variable $X = \\sum_{t=1}^{T} B_t$, where $B_t \\sim \\text{Bernoulli}(q(t))$ are independent across $t$. The distribution of $X$ is the Poisson binomial distribution. Suppose an observed coincidence count $k_{\\text{obs}}$ is measured in the window. The statistical question is to compute the tail probability (a one-sided p-value) of observing at least $k_{\\text{obs}}$ coincidences under the null:\n$$\np_{\\text{PB}} = \\mathbb{P}\\big(X \\ge k_{\\text{obs}}\\big).\n$$\nA common approximation used in neuroscience data analysis is to replace the Poisson binomial distribution by a Poisson distribution with rate parameter $\\lambda = \\sum_{t=1}^{T} q(t)$, yielding the approximate tail\n$$\np_{\\text{Pois}} = \\mathbb{P}\\big(Y \\ge k_{\\text{obs}}\\big), \\quad Y \\sim \\text{Poisson}(\\lambda).\n$$\nStarting only from the fundamental probability laws for independent Bernoulli trials and the definition of the Poisson distribution, derive an algorithm that computes $p_{\\text{PB}}$ exactly via a dynamic programming method based on successive convolution of per-bin two-point distributions. Then implement both the exact tail $p_{\\text{PB}}$ and the Poisson approximation $p_{\\text{Pois}}$ for a given set $\\{q(t)\\}$ and $k_{\\text{obs}}$, and compare them quantitatively.\n\nYour program must:\n- Compute the exact Poisson binomial tail $p_{\\text{PB}}$ using dynamic programming (successive convolution with per-bin distributions).\n- Compute the Poisson approximation tail $p_{\\text{Pois}}$ using the rate $\\lambda = \\sum_{t=1}^{T} q(t)$.\n- For each test case, output a list of three decimal floats $[p_{\\text{PB}}, p_{\\text{Pois}}, \\lvert p_{\\text{PB}} - p_{\\text{Pois}} \\rvert]$, each rounded to exactly $12$ decimal places.\n\nYour program should produce a single line of output containing the results for all test cases as a comma-separated list enclosed in square brackets (for example, $[ [\\cdot,\\cdot,\\cdot], [\\cdot,\\cdot,\\cdot], \\dots ]$).\n\nUse the following test suite, which includes a general case, boundary conditions, and skewed-probability scenarios. In each case, the sample window is the length of the specified list $\\{q(t)\\}$, and the observed count is $k_{\\text{obs}}$.\n\n- Test case $1$ (general, heterogeneous small probabilities):\n  - $\\{q(t)\\} = [\\, 0.02, 0.03, 0.025, 0.015, 0.04, 0.03, 0.02, 0.05, 0.01, 0.035, 0.025, 0.02, 0.03, 0.015, 0.04, 0.025, 0.02, 0.03, 0.02, 0.05, 0.015, 0.02, 0.03, 0.025, 0.02, 0.035, 0.025, 0.02, 0.015, 0.04, 0.03, 0.02, 0.015, 0.05, 0.02, 0.025, 0.03, 0.02, 0.035, 0.015 \\,]$\n  - $k_{\\text{obs}} = 4$\n- Test case $2$ (uniform small probabilities, longer window):\n  - $\\{q(t)\\} = [\\, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02 \\,]$\n  - $k_{\\text{obs}} = 3$\n- Test case $3$ (skewed with a few large probabilities):\n  - $\\{q(t)\\} = [\\, 0.30, 0.25, 0.20, 0.05, 0.01, 0.02, 0.01, 0.05, 0.02, 0.01, 0.03, 0.01, 0.02, 0.01, 0.01 \\,]$\n  - $k_{\\text{obs}} = 5$\n- Test case $4$ (boundary: zero threshold):\n  - $\\{q(t)\\} = [\\, 0.05, 0.02, 0.03, 0.04, 0.01, 0.02, 0.05, 0.03, 0.02, 0.01 \\,]$\n  - $k_{\\text{obs}} = 0$\n- Test case $5$ (boundary: full successes threshold):\n  - $\\{q(t)\\} = [\\, 0.10, 0.10, 0.10, 0.10, 0.10, 0.10, 0.10, 0.10, 0.10, 0.10 \\,]$\n  - $k_{\\text{obs}} = 10$\n\nAngle units are not applicable. No physical units are required. Your program must format its single-line output as a comma-separated list of per-test-case lists, each inner list containing three decimal floats with exactly $12$ digits after the decimal point.",
            "solution": "The problem is valid as it is scientifically grounded, well-posed, objective, and contains all necessary information to derive and implement a solution.\n\nThe core of the problem is to compute the tail probability of a random variable $X$, which is the sum of $T$ independent but not identically distributed Bernoulli random variables.\nLet $X = \\sum_{t=1}^{T} B_t$, where $B_t \\sim \\text{Bernoulli}(q(t))$ are independent for $t \\in \\{1, 2, \\dots, T\\}$. The distribution of $X$ is known as the Poisson binomial distribution. We are tasked with computing the exact tail probability $p_{\\text{PB}} = \\mathbb{P}(X \\ge k_{\\text{obs}})$ and comparing it to a Poisson approximation, $p_{\\text{Pois}}$.\n\nFirst, we derive an algorithm to compute the exact probability mass function (PMF) of $X$, from which $p_{\\text{PB}}$ can be obtained. The algorithm is based on dynamic programming, leveraging the principle of successive convolution.\nLet $X_n = \\sum_{t=1}^{n} B_t$ be the sum of the first $n$ Bernoulli variables. The PMF of $X_n$ can be computed recursively. The base case is for $n=1$, where $X_1 = B_1$. The PMF of $X_1$ is given by:\n$$ \\mathbb{P}(X_1=0) = 1 - q(1) $$\n$$ \\mathbb{P}(X_1=1) = q(1) $$\nFor the recursive step, we express $X_n$ in terms of $X_{n-1}$ and $B_n$:\n$$ X_n = X_{n-1} + B_n $$\nSince $B_n$ is independent of $X_{n-1}$ (which is a sum of $B_1, \\dots, B_{n-1}$), the PMF of $X_n$ is the convolution of the PMFs of $X_{n-1}$ and $B_n$. Let $P_n(k) = \\mathbb{P}(X_n=k)$. The convolution formula is:\n$$ P_n(k) = \\sum_{j=0}^{k} \\mathbb{P}(X_{n-1}=j) \\cdot \\mathbb{P}(B_n=k-j) $$\nSince $B_n$ can only take values $0$ or $1$, the sum simplifies to two terms:\n$$ P_n(k) = \\mathbb{P}(X_{n-1}=k) \\cdot \\mathbb{P}(B_n=0) + \\mathbb{P}(X_{n-1}=k-1) \\cdot \\mathbb{P}(B_n=1) $$\nSubstituting the probabilities for the Bernoulli trial $B_n$, we get the recurrence relation:\n$$ P_n(k) = P_{n-1}(k) \\cdot (1 - q(n)) + P_{n-1}(k-1) \\cdot q(n) $$\nwith the understanding that $P_{n-1}(k)=0$ if $k < 0$ or $k > n-1$.\n\nThis recurrence forms the basis of a dynamic programming algorithm. We can represent the PMF of $X_n$ as an array of probabilities, say `pmf_n`. We start with the PMF of $X_0$, a degenerate random variable equal to $0$ with probability $1$. This is represented by an array `[1.0]`. We then iterate from $n=1$ to $T$, at each step $n$ using `pmf_{n-1}` and $q(n)$ to compute `pmf_n` according to the recurrence.\nThe algorithm proceeds as follows:\n1. Initialize a probability vector `pmf` of size $T+1$ to represent the PMF of the sum. For $X_0$, this is `[1.0, 0.0, ..., 0.0]`.\n2. For each trial $t$ from $1$ to $T$, with probability $q(t)$:\n   Update the `pmf` vector. Let the vector before this step be $P_{t-1}$. The new vector $P_t$ is computed by iterating backwards from $k=t$ down to $1$:\n   $P_t(k) \\leftarrow P_{t-1}(k) \\cdot (1 - q(t)) + P_{t-1}(k-1) \\cdot q(t)$. The $k=0$ case is special: $P_t(0) \\leftarrow P_{t-1}(0) \\cdot (1 - q(t))$.\n   The backward iteration is crucial for an in-place update of the `pmf` array.\n3. After iterating through all $T$ trials, the `pmf` vector holds the PMF of $X = X_T$.\nThe desired tail probability is then the sum of the probabilities for all outcomes greater than or equal to $k_{\\text{obs}}$:\n$$ p_{\\text{PB}} = \\mathbb{P}(X \\ge k_{\\text{obs}}) = \\sum_{k=k_{\\text{obs}}}^{T} P_T(k) $$\n\nNext, we address the Poisson approximation. The Poisson binomial distribution is approximated by a Poisson distribution with a rate parameter $\\lambda$ equal to the sum of the individual Bernoulli probabilities:\n$$ \\lambda = \\sum_{t=1}^{T} q(t) $$\nLet $Y \\sim \\text{Poisson}(\\lambda)$. The PMF of $Y$ is:\n$$ \\mathbb{P}(Y=k) = \\frac{\\lambda^k e^{-\\lambda}}{k!} \\quad \\text{for } k=0, 1, 2, \\dots $$\nThe approximate tail probability, $p_{\\text{Pois}}$, is $\\mathbb{P}(Y \\ge k_{\\text{obs}})$. It is more numerically stable to compute this via the complement of the cumulative distribution function (CDF):\n$$ p_{\\text{Pois}} = \\mathbb{P}(Y \\ge k_{\\text{obs}}) = 1 - \\mathbb{P}(Y < k_{\\text{obs}}) = 1 - \\sum_{k=0}^{k_{\\text{obs}}-1} \\mathbb{P}(Y=k) $$\nFor $k_{\\text{obs}}=0$, this sum is empty and has value $0$, so $p_{\\text{Pois}}=1$. For $k_{\\text{obs}}>0$, we can compute the sum iteratively. Let $S_{j} = \\sum_{k=0}^{j} \\mathbb{P}(Y=k)$. The terms of the sum can be computed recursively:\n$$ \\mathbb{P}(Y=k) = \\mathbb{P}(Y=k-1) \\cdot \\frac{\\lambda}{k} $$\nstarting with $\\mathbb{P}(Y=0)=e^{-\\lambda}$. We sum these terms from $k=0$ to $k_{\\text{obs}}-1$ to find the CDF value, and subtract from $1$ to get the tail probability $p_{\\text{Pois}}$.\n\nFinally, the quantitative comparison is the absolute difference $|p_{\\text{PB}} - p_{\\text{Pois}}|$. The implementation will compute these three values for each test case.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef compute_poisson_binomial_tail(q_list, k_obs):\n    \"\"\"\n    Computes the exact tail probability P(X >= k_obs) for a Poisson Binomial distribution.\n    The distribution is the sum of independent Bernoulli trials with probabilities q_list.\n    This is achieved using a dynamic programming approach based on successive convolutions.\n    \"\"\"\n    T = len(q_list)\n\n    if k_obs > T:\n        return 0.0\n    if k_obs < 0:\n        k_obs = 0\n    \n    # pmf array stores P(X_n = k) at index k.\n    # Initialize for a sum of 0 trials, where P(sum=0) = 1.\n    pmf = np.zeros(T + 1, dtype=np.float64)\n    pmf[0] = 1.0\n    \n    # Iterate through each Bernoulli trial\n    # num_trials tracks the number of trials processed so far (from 1 to T)\n    num_trials = 0\n    for q_t in q_list:\n        num_trials += 1\n        # Update the pmf from a sum of num_trials-1 Bernoullis to num_trials.\n        # The recurrence is: P_n(k) = P_{n-1}(k)*(1-q_t) + P_{n-1}(k-1)*q_t\n        # We iterate backwards to use the values from the previous step (pmf_{n-1})\n        # before they are overwritten.\n        # The loop range covers a max possible sum of num_trials.\n        for k in range(num_trials, 0, -1):\n            pmf[k] = pmf[k] * (1.0 - q_t) + pmf[k - 1] * q_t\n        \n        # Update the k=0 case separately\n        pmf[0] = pmf[0] * (1.0 - q_t)\n\n    # The tail probability is the sum of probabilities from k_obs to T.\n    p_pb_tail = np.sum(pmf[k_obs:])\n    return p_pb_tail\n\ndef compute_poisson_tail(q_list, k_obs):\n    \"\"\"\n    Computes the tail probability P(Y >= k_obs) for a Poisson distribution\n    approximating the Poisson Binomial distribution.\n    The rate lambda is the sum of the Bernoulli probabilities.\n    \"\"\"\n    if k_obs <= 0:\n        return 1.0\n\n    lam = np.sum(q_list)\n\n    # If lambda is 0, the only possible outcome is 0.\n    # P(Y=0) = 1, P(Y>0) = 0.\n    # The tail P(Y >= k_obs) is 0 for k_obs > 0.\n    if lam == 0.0:\n        return 0.0\n\n    # Compute CDF P(Y < k_obs) = sum_{k=0}^{k_obs-1} P(Y=k)\n    # P(Y=k) = exp(-lam) * lam^k / k!\n    # We compute terms iteratively: term_k = term_{k-1} * lam / k\n    # Start with k=0 term\n    term = np.exp(-lam)\n    cdf_sum = term\n    \n    for k in range(1, k_obs):\n        term = term * lam / k\n        cdf_sum += term\n        \n    p_pois_tail = 1.0 - cdf_sum\n    # Due to floating point errors, result can be slightly negative. Clip at 0.\n    return max(0.0, p_pois_tail)\n\ndef solve():\n    \"\"\"\n    Main function to run test cases and produce the final output.\n    \"\"\"\n    test_cases = [\n        # Test case 1 (general, heterogeneous small probabilities)\n        ([0.02, 0.03, 0.025, 0.015, 0.04, 0.03, 0.02, 0.05, 0.01, 0.035, 0.025, 0.02, 0.03, 0.015, 0.04, 0.025, 0.02, 0.03, 0.02, 0.05, 0.015, 0.02, 0.03, 0.025, 0.02, 0.035, 0.025, 0.02, 0.015, 0.04, 0.03, 0.02, 0.015, 0.05, 0.02, 0.025, 0.03, 0.02, 0.035, 0.015], 4),\n        # Test case 2 (uniform small probabilities, longer window)\n        ([0.02] * 50, 3),\n        # Test case 3 (skewed with a few large probabilities)\n        ([0.30, 0.25, 0.20, 0.05, 0.01, 0.02, 0.01, 0.05, 0.02, 0.01, 0.03, 0.01, 0.02, 0.01, 0.01], 5),\n        # Test case 4 (boundary: zero threshold)\n        ([0.05, 0.02, 0.03, 0.04, 0.01, 0.02, 0.05, 0.03, 0.02, 0.01], 0),\n        # Test case 5 (boundary: full successes threshold)\n        ([0.10] * 10, 10),\n    ]\n\n    all_results_formatted = []\n    for q_list, k_obs in test_cases:\n        \n        p_pb = compute_poisson_binomial_tail(q_list, k_obs)\n        p_pois = compute_poisson_tail(q_list, k_obs)\n        diff = abs(p_pb - p_pois)\n        \n        case_results = [p_pb, p_pois, diff]\n        formatted_case_results = [f\"{val:.12f}\" for val in case_results]\n        all_results_formatted.append(f\"[{','.join(formatted_case_results)}]\")\n\n    print(f\"[{','.join(all_results_formatted)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "This final practice addresses a crucial step in real-world data analysis: correcting for multiple comparisons when testing many neuron pairs simultaneously. You will implement the Benjamini-Hochberg procedure to control the False Discovery Rate (FDR), learning how to confidently identify significant results from a large set of tests . This skill is indispensable for producing robust and reproducible scientific findings from large-scale neural recordings.",
            "id": "4202845",
            "problem": "Consider a set of Unitary Event (UE) significance tests in neuroscience data analysis, where each test produces a p-value under a null hypothesis of independent firing. From first principles, a p-value is the tail probability under the null hypothesis, and the false discovery rate (FDR) is defined as the expected proportion of false rejections among all rejections. You are to implement the Benjamini–Hochberg (BH) procedure for FDR control. The Benjamini–Hochberg (BH) procedure is a step-up multiple-comparison method that, under independence or positive regression dependence on a subset (PRDS) of the test statistics, guarantees that the FDR is bounded by a target level. In this task, you will apply BH to synthetic UE p-value matrices and determine which UE tests are significant at a specified FDR level.\n\nFundamental base to be used: the definition of p-values under the null hypothesis, the definition of the false discovery rate, and the well-tested fact that the Benjamini–Hochberg procedure controls the false discovery rate at the target level under independence or positive regression dependence. Do not use any shortcut formulas in the problem statement; instead, rely on the conceptual steps of ordering p-values and selecting a data-driven rejection threshold that ensures FDR control in the independent or PRDS setting.\n\nYour program must, for each provided synthetic test case, perform the following steps:\n- Flatten the two-dimensional p-value matrix of UE tests into a single list of p-values.\n- Apply the Benjamini–Hochberg step-up procedure at the specified FDR level $q$ (expressed as a decimal fraction, not a percentage) to determine the rejection threshold, including ties exactly at the threshold.\n- Map the rejected p-values back to their original matrix coordinates.\n- Report the coordinates of significant UE tests as zero-based row-major index pairs $[r,c]$, ordered lexicographically by $(r,c)$.\n\nAssume the p-values are valid probabilities in $[0,1]$, and assume independence among tests for the purpose of FDR control. Angles are not involved in this problem. There are no physical units.\n\nTest suite and required outputs:\nYou must process the following five test cases. For each test case, output a list of $[r,c]$ pairs indicating the significant UE coordinates, using zero-based indexing and ordered by row-major order. The final output must be a single line that is a comma-separated list of these per-test-case results enclosed in square brackets.\n\n- Test case A (general case, mixed small and moderate p-values):\n  Let the p-value matrix be\n  $$M_A=\\begin{bmatrix}\n  0.001 & 0.20 & 0.04 & 0.15 \\\\\n  0.005 & 0.02 & 0.50 & 0.07 \\\\\n  0.10 & 0.003 & 0.80 & 0.25\n  \\end{bmatrix},$$\n  with target FDR level $q=0.10$.\n\n- Test case B (edge case with zeros, ones, and repeated moderate p-values):\n  Let the p-value matrix be\n  $$M_B=\\begin{bmatrix}\n  0.0 & 0.99 & 0.05 & 1.0 & 0.0005 \\\\\n  0.001 & 0.07 & 0.5 & 0.05 & 0.05\n  \\end{bmatrix},$$\n  with target FDR level $q=0.05$.\n\n- Test case C (tie-handling at the adaptive threshold; exact equality to step-up boundaries):\n  Let the p-value matrix be\n  $$M_C=\\begin{bmatrix}\n  0.01 & 0.02 & 0.03 & 0.04 \\\\\n  0.05 & 0.06 & 0.07 & 0.08 \\\\\n  0.09 & 0.10 & 0.11 & 0.12\n  \\end{bmatrix},$$\n  with target FDR level $q=0.12$.\n\n- Test case D (single-row matrix; several small and moderate p-values):\n  Let the p-value matrix be\n  $$M_D=\\begin{bmatrix}\n  0.3 & 0.2 & 0.25 & 0.01 & 0.6 & 0.05 & 0.07 & 0.04\n  \\end{bmatrix},$$\n  with target FDR level $q=0.25$.\n\n- Test case E (boundary case with no expected rejections at a very stringent level):\n  Let the p-value matrix be\n  $$M_E=\\begin{bmatrix}\n  0.2 & 0.2 \\\\\n  0.2 & 0.2\n  \\end{bmatrix},$$\n  with target FDR level $q=0.001$.\n\nFinal output format specification:\nYour program should produce a single line of output containing the results for the five test cases as a comma-separated list enclosed in square brackets, where each element is the per-test-case list of significant coordinates $[r,c]$ sorted by row-major order. For example, the format should be\n$$[\\text{caseA\\_result},\\text{caseB\\_result},\\text{caseC\\_result},\\text{caseD\\_result},\\text{caseE\\_result}],$$\nwhere each $\\text{caseX\\_result}$ is a list of lists of integers, such as\n$$[[0,0],[0,2],[1,1]],$$\nand the overall output must be exactly one line with no additional text.",
            "solution": "The problem posed is a valid and well-defined application of a standard statistical procedure, the Benjamini-Hochberg (BH) method, to a common scenario in neuroscience data analysis, namely the correction for multiple comparisons in Unitary Event (UE) significance testing. The problem is scientifically grounded, objective, and provides all necessary information to derive a unique solution for each test case.\n\nThe core of the problem is to manage the trade-off between discovering true effects and avoiding false alarms when conducting numerous statistical tests simultaneously. If each of $m$ tests is evaluated at a significance level $\\alpha$, one would expect to make $m \\times \\alpha$ false rejections even if all null hypotheses are true. The False Discovery Rate (FDR) is a more powerful and often more appropriate criterion for controlling for multiple testing than controlling the family-wise error rate (FWER). The FDR is the expected proportion of \"discoveries\" (rejected null hypotheses) that are actually false. The Benjamini-Hochberg procedure provides a way to control the FDR at a specified level $q$.\n\nLet us formalize the scenario. We perform $m$ hypothesis tests, obtaining a set of p-values $\\{p_1, p_2, \\dots, p_m\\}$. The total number of tests $m$ is the product of the dimensions of the input p-value matrix. We can classify the outcomes of these $m$ tests into a contingency table:\n\n| | Declared non-significant | Declared significant | Total |\n|---|---|---|---|\n| True null hypothesis | $U$ (True Negatives) | $V$ (False Positives/Type I Errors) | $m_0$ |\n| False null hypothesis | $T$ (False Negatives/Type II Errors) | $S$ (True Positives) | $m_1$ |\n| Total | $m-R$ | $R$ (Total Rejections) | $m$ |\n\nThe False Discovery Proportion (FDP) is the ratio of false positives to the total number of rejections, $Q = V/R$, with $Q$ defined as $0$ if $R=0$. The False Discovery Rate (FDR) is the expectation of this value, $FDR = E[Q] = E[V/R]$. The BH procedure guarantees that $FDR \\le \\frac{m_0}{m} q \\le q$ under the assumption that the $m$ tests are independent (or satisfy a weaker condition known as positive regression dependence on a subset, PRDS).\n\nThe Benjamini-Hochberg step-up procedure is as follows:\n\n$1$. Order the $m$ p-values from smallest to largest: $p_{(1)} \\le p_{(2)} \\le \\dots \\le p_{(m)}$. These ordered p-values are associated with their original hypotheses $H_{(1)}, H_{(2)}, \\dots, H_{(m)}$.\n\n$2$. For a given FDR target level $q$, find the largest rank $k$ such that the p-value at that rank, $p_{(k)}$, satisfies the condition:\n$$p_{(k)} \\le \\frac{k}{m}q$$\n\n$3$. If such a $k$ exists, reject all null hypotheses $H_{(i)}$ for $i = 1, 2, \\dots, k$. That is, all hypotheses corresponding to the $k$ smallest p-values are declared significant. If no such $k$ exists, no hypotheses are rejected.\n\nTo implement this procedure for the given problem, we must perform the following algorithmic steps for each test case, which is defined by a p-value matrix $M$ and a target FDR level $q$:\n\n$1$. The $2D$ matrix $M$ of size $R \\times C$ is flattened into a one-dimensional list of p-values. The total number of tests is $m = R \\times C$. To map the results back to the original matrix, we must preserve the original zero-based coordinates $(r, c)$ for each p-value. A practical way to do this is to create a list of tuples, where each tuple is of the form $(p_{\\text{value}}, r, c)$.\n\n$2$. This list of $m$ tuples is sorted in ascending order based on the p-value. This yields the ordered p-values $p_{(1)}, p_{(2)}, \\dots, p_{(m)}$ and their corresponding original coordinates.\n\n$3$. We then find the largest rank $k$ that satisfies the BH condition. This can be done efficiently by iterating downwards from $k=m$ to $k=1$. The first $k$ for which we find $p_{(k)} \\le \\frac{k}{m}q$ is the largest such $k$. Let this value be $k_{\\text{max}}$. If the loop completes without finding such a $k$, then $k_{\\text{max}} = 0$ and no p-values are significant.\n\n$4$. If $k_{\\text{max}} > 0$, we identify all p-values with ranks from $1$ to $k_{\\text{max}}$ as significant. These correspond to the first $k_{\\text{max}}$ elements in our sorted list.\n\n$5$. The original coordinates $(r, c)$ are extracted for these $k_{\\text{max}}$ significant tests.\n\n$6$. Finally, this list of significant coordinates is sorted lexicographically (first by row index $r$, then by column index $c$) to produce the final result for the test case, formatted as a list of $[r,c]$ pairs.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef apply_bh(p_matrix: np.ndarray, q: float) -> list[list[int]]:\n    \"\"\"\n    Applies the Benjamini-Hochberg procedure to a matrix of p-values.\n\n    Args:\n        p_matrix: A numpy array of p-values.\n        q: The target False Discovery Rate (FDR) level.\n\n    Returns:\n        A list of [row, col] coordinates of significant tests, sorted lexicographically.\n    \"\"\"\n    if p_matrix.size == 0:\n        return []\n\n    m = p_matrix.size\n    \n    # Step 1: Flatten the p-value matrix while keeping original indices.\n    p_values_with_indices = []\n    for (r, c), p_val in np.ndenumerate(p_matrix):\n        p_values_with_indices.append({'p_val': p_val, 'coords': [r, c]})\n\n    # Step 2: Sort the list by p-value in ascending order.\n    # Python's sort is stable, which is good practice but not strictly required here.\n    p_values_with_indices.sort(key=lambda x: x['p_val'])\n    \n    # Step 3: Find the largest k such that p_(k) <= (k/m) * q.\n    k_max = 0\n    # Iterate from k=m down to 1 to find the largest k that satisfies the condition.\n    for k in range(m, 0, -1):\n        p_k = p_values_with_indices[k - 1]['p_val']\n        bh_threshold = (k / m) * q\n        if p_k <= bh_threshold:\n            k_max = k\n            break\n            \n    # Step 4: If no such k is found, no rejections. Otherwise, collect significant results.\n    if k_max == 0:\n        return []\n    \n    significant_tests = p_values_with_indices[:k_max]\n    \n    # Step 5 & 6: Extract coordinates and sort them lexicographically.\n    significant_coords = [item['coords'] for item in significant_tests]\n    significant_coords.sort()\n    \n    return significant_coords\n\ndef format_result_list(results: list) -> str:\n    \"\"\"Formats a list of lists of coordinates into the required string format.\"\"\"\n    if not results:\n        return '[]'\n    \n    inner_parts = [f'[{r},{c}]' for r, c in results]\n    return f\"[{','.join(inner_parts)}]\"\n\ndef solve():\n    \"\"\"\n    Defines and runs the test cases, printing the final formatted output.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # Test case A\n        (np.array([\n            [0.001, 0.20, 0.04, 0.15],\n            [0.005, 0.02, 0.50, 0.07],\n            [0.10, 0.003, 0.80, 0.25]\n        ]), 0.10),\n        # Test case B\n        (np.array([\n            [0.0, 0.99, 0.05, 1.0, 0.0005],\n            [0.001, 0.07, 0.5, 0.05, 0.05]\n        ]), 0.05),\n        # Test case C\n        (np.array([\n            [0.01, 0.02, 0.03, 0.04],\n            [0.05, 0.06, 0.07, 0.08],\n            [0.09, 0.10, 0.11, 0.12]\n        ]), 0.12),\n        # Test case D\n        (np.array(\n           [[0.3, 0.2, 0.25, 0.01, 0.6, 0.05, 0.07, 0.04]]\n        ), 0.25),\n        # Test case E\n        (np.array([\n            [0.2, 0.2],\n            [0.2, 0.2]\n        ]), 0.001)\n    ]\n\n    results = []\n    for p_matrix, q in test_cases:\n        result = apply_bh(p_matrix, q)\n        results.append(result)\n\n    # Format the final output string as per the specification.\n    str_results = [format_result_list(res) for res in results]\n    final_output_string = f\"[{','.join(str_results)}]\"\n    \n    print(final_output_string)\n\nsolve()\n```"
        }
    ]
}