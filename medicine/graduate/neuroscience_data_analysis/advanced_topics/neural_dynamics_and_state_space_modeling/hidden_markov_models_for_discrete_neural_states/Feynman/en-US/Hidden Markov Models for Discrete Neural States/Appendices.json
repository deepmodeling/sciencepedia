{
    "hands_on_practices": [
        {
            "introduction": "The first step in applying a Hidden Markov Model is to infer the most probable sequence of latent states from an observed data stream. This exercise provides foundational practice in implementing the Viterbi algorithm, the cornerstone dynamic programming method for this task. By subsequently analyzing the durations of the decoded states and comparing them to their theoretical expectation, you will gain a concrete understanding of the implicit geometric duration assumption inherent in the standard HMM framework, a crucial insight for model building and critique .",
            "id": "4168489",
            "problem": "You are given a set of parameters defining a Hidden Markov Model (HMM) for discrete neural states and sequences of binned spike counts. A Hidden Markov Model (HMM) consists of a discrete latent state process that is a first-order Markov chain with an initial distribution and a transition matrix, coupled to an observation process whose distribution depends on the current latent state. In neuroscience data analysis, spike counts aggregated in fixed-width bins are commonly modeled using a Poisson distribution conditioned on the latent neural state. The objective is to compute the most probable latent sequence given the observed spike counts using the Viterbi algorithm, and then assess the empirical state durations against the durations implied by the Markov property.\n\nStarting from core definitions:\n- The latent sequence has states from the finite set $\\{0,1,\\dots,S-1\\}$, where $S$ denotes the number of states.\n- The initial state distribution is denoted by the vector $\\boldsymbol{\\pi}$ with entries $\\pi_i$ for $i \\in \\{0,1,\\dots,S-1\\}$, where $\\pi_i$ represents the probability of starting in state $i$.\n- The state transition probabilities are represented by a matrix $\\mathbf{A}$ with entries $a_{ij}$, defined as the probability of transitioning from state $i$ to state $j$ in one time step, with $i,j \\in \\{0,1,\\dots,S-1\\}$.\n- Observations at time $t$, denoted $o_t$, are spike counts modeled as a Poisson random variable conditioned on the state $s_t$: $o_t \\sim \\mathrm{Poisson}(\\lambda_{s_t})$, where $\\lambda_i$ is the Poisson rate parameter associated with state $i$. All spike counts $o_t$ are nonnegative integers.\n\nUnder the Markov property and conditional independence assumptions inherent to the HMM, the most probable latent sequence $s_{0:T-1}$ given observations $o_{0:T-1}$ can be obtained using dynamic programming (Viterbi algorithm), which maximizes the joint log-probability over paths. State durations in discrete-time Markov chains are geometrically distributed due to the memoryless property: the number of consecutive time steps $D_i$ spent in state $i$ before transitioning to a different state has a geometric distribution on the support $\\{1,2,3,\\dots\\}$ with success parameter $q_i = 1 - a_{ii}$, implying that the expected duration is $\\mathbb{E}[D_i] = \\frac{1}{q_i} = \\frac{1}{1 - a_{ii}}$.\n\nYour task is to implement a program that:\n1. For each provided test case, computes the Viterbi path $s_{0:T-1}$ using the given $\\boldsymbol{\\pi}$, $\\mathbf{A}$, and $\\boldsymbol{\\lambda}$ and the provided observation sequence $o_{0:T-1}$. Use log-probabilities to avoid numerical underflow. In the case of ties between candidate predecessors or states, break ties deterministically by choosing the smallest state index.\n2. Parses the Viterbi path to obtain empirical run-lengths for each state: contiguous segments of identical states yield durations measured in time steps. For each state $i$, compute the empirical mean of its run-lengths. If a state $i$ does not appear in the Viterbi path, define its empirical mean duration to be $0$ by convention.\n3. For each state $i$, compute the expected mean duration using $\\mathbb{E}[D_i] = \\frac{1}{1 - a_{ii}}$. Then compute the absolute difference between the empirical mean and the expected mean for each state.\n4. Round each absolute difference to six decimal places.\n5. Aggregate results across all test cases into a single output as specified.\n\nAll quantities are dimensionless counts and probabilities, so no physical units are required. Angles are not used. The final output must be a single line representing a list of lists of floats, consistent across test cases. The line must be exactly formatted as described below.\n\nTest Suite:\n- Test Case $1$:\n  - Number of states $S = 3$.\n  - Initial distribution $\\boldsymbol{\\pi} = [\\,0.6,\\,0.3,\\,0.1\\,]$.\n  - Transition matrix $\\mathbf{A} = \\begin{bmatrix} 0.90 & 0.08 & 0.02 \\\\ 0.05 & 0.92 & 0.03 \\\\ 0.04 & 0.06 & 0.90 \\end{bmatrix}$.\n  - Poisson rates $\\boldsymbol{\\lambda} = [\\,2.0,\\,8.0,\\,15.0\\,]$.\n  - Observation sequence $o_{0:25} = [\\,2,\\,1,\\,3,\\,2,\\,2,\\,9,\\,8,\\,7,\\,10,\\,15,\\,14,\\,16,\\,17,\\,13,\\,12,\\,1,\\,2,\\,3,\\,8,\\,9,\\,8,\\,12,\\,18,\\,15,\\,14,\\,16\\,]$.\n- Test Case $2$:\n  - Number of states $S = 3$.\n  - Initial distribution $\\boldsymbol{\\pi} = [\\,0.33,\\,0.33,\\,0.34\\,]$.\n  - Transition matrix $\\mathbf{A} = \\begin{bmatrix} 0.97 & 0.02 & 0.01 \\\\ 0.01 & 0.97 & 0.02 \\\\ 0.02 & 0.01 & 0.97 \\end{bmatrix}$.\n  - Poisson rates $\\boldsymbol{\\lambda} = [\\,3.0,\\,9.0,\\,14.0\\,]$.\n  - Observation sequence $o_{0:44} = [\\,14,\\,15,\\,13,\\,16,\\,14,\\,14,\\,15,\\,13,\\,17,\\,12,\\,14,\\,16,\\,15,\\,13,\\,14,\\,15,\\,16,\\,13,\\,15,\\,14,\\,9,\\,10,\\,8,\\,9,\\,10,\\,7,\\,9,\\,8,\\,9,\\,11,\\,9,\\,8,\\,10,\\,9,\\,9,\\,3,\\,2,\\,4,\\,3,\\,3,\\,2,\\,4,\\,3,\\,2,\\,3\\,]$.\n- Test Case $3$:\n  - Number of states $S = 2$.\n  - Initial distribution $\\boldsymbol{\\pi} = [\\,0.5,\\,0.5\\,]$.\n  - Transition matrix $\\mathbf{A} = \\begin{bmatrix} 0.60 & 0.40 \\\\ 0.40 & 0.60 \\end{bmatrix}$.\n  - Poisson rates $\\boldsymbol{\\lambda} = [\\,5.0,\\,5.0\\,]$.\n  - Observation sequence $o_{0:11} = [\\,4,\\,6,\\,5,\\,7,\\,5,\\,5,\\,4,\\,6,\\,5,\\,5,\\,5,\\,6\\,]$.\n\nProgram Requirements:\n- Implement the Viterbi algorithm in the log domain for numerical stability.\n- Compute empirical mean durations from the decoded path and absolute differences to $\\frac{1}{1-a_{ii}}$ for each state $i$.\n- Round differences to six decimal places.\n- Deterministic tie-breaking: when two or more predecessor states yield equal scores (within floating-point equality) for the same current state and time, select the smallest index predecessor; similarly, if two states tie at initialization or final backtracking comparison, select the smallest index.\n- Final Output Format: Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, where each element is a sublist of comma-separated rounded floats per test case. For example, the output must look exactly like `[[0.123456,0.000001,2.500000],[0.100000,0.200000,0.300000],[3.141593,2.718282]]`.\n\nYour program must be self-contained and must not read input from the user. It must use the specified runtime environment and produce deterministic output. The observations are provided as exact integer counts per bin; do not infer any physical units beyond dimensionless counts.",
            "solution": "The solution involves three main components: decoding the latent states, calculating empirical statistics from the decoded path, and comparing these with theoretical expectations derived from the model parameters.\n\n**1. Viterbi Algorithm for Path Decoding:**\nThe objective is to find the state sequence $s^*_{0:T-1} = (s^*_0, s^*_1, \\dots, s^*_{T-1})$ that maximizes the joint probability $P(s_{0:T-1}, o_{0:T-1})$. To prevent numerical underflow with long sequences, we work with log-probabilities. The Viterbi algorithm efficiently solves this maximization problem using dynamic programming.\n\nLet $\\delta_t(i)$ be the maximum log-probability of any state sequence ending in state $i$ at time $t$, given the observations up to time $t$.\n$$\n\\delta_t(i) = \\max_{s_{0:t-1}} \\log P(s_{0:t-1}, s_t=i, o_{0:t})\n$$\nThe algorithm proceeds as follows:\n\n- **Initialization ($t=0$):**\nFor each state $i \\in \\{0, \\dots, S-1\\}$, the initial log-probability is the sum of the log-initial-probability and the log-emission-probability for the first observation $o_0$.\n$$\n\\delta_0(i) = \\log \\pi_i + \\log p(o_0 | s_0=i)\n$$\nThe log-probability for a Poisson emission is $\\log p(o_t | s_t=i) = o_t \\log \\lambda_i - \\lambda_i - \\log(o_t!)$. The term $\\log(o_t!)$ is constant for all states $i$ at a given time $t$ and can be omitted from the maximization steps, as it does not affect the outcome of any comparison.\n\n- **Recursion ($t=1, \\dots, T-1$):**\nFor each state $j \\in \\{0, \\dots, S-1\\}$, we find the most probable path leading to it by considering all possible predecessor states $i$ at time $t-1$.\n$$\n\\delta_t(j) = \\left( \\max_{i \\in \\{0, \\dots, S-1\\}} (\\delta_{t-1}(i) + \\log a_{ij}) \\right) + \\log p(o_t | s_t=j)\n$$\nA backpointer table, $\\psi_t(j)$, stores the predecessor state $i$ that achieved this maximum for each $j$.\n$$\n\\psi_t(j) = \\arg\\max_{i \\in \\{0, \\dots, S-1\\}} (\\delta_{t-1}(i) + \\log a_{ij})\n$$\nThe specified tie-breaking rule (smallest index) is applied here.\n\n- **Termination and Path Backtracking:**\nThe most probable final state is found by maximizing $\\delta_{T-1}(i)$ over all states $i$.\n$$\ns^*_{T-1} = \\arg\\max_{i \\in \\{0, \\dots, S-1\\}} \\delta_{T-1}(i)\n$$\nThe rest of the path is recovered by backtracking from $t=T-2$ down to $0$ using the stored pointers:\n$$\ns^*_t = \\psi_{t+1}(s^*_{t+1})\n$$\n\n**2. Empirical and Theoretical State Durations:**\n- **Empirical Duration:** After obtaining the Viterbi path $s^*_{0:T-1}$, we parse it to identify contiguous segments of identical states. For each state $i$, we collect the lengths of all such segments (run-lengths). The empirical mean duration for state $i$ is the arithmetic average of these run-lengths. If a state does not appear in the path, its empirical mean duration is defined as $0$.\n\n- **Theoretical Duration:** The latent state process is a discrete-time Markov chain. The memoryless property of the Markov chain implies that the duration of a stay in any state $i$ (i.e., the number of consecutive time steps spent in $i$ before transitioning out) follows a geometric distribution. The probability of self-transition is $a_{ii}$, so the probability of leaving the state is $q_i = 1 - a_{ii}$. The expected number of steps until this \"leave\" event occurs, including the first step, is given by:\n$$\n\\mathbb{E}[D_i] = \\frac{1}{q_i} = \\frac{1}{1 - a_{ii}}\n$$\n\n**3. Final Calculation:**\nFor each state $i \\in \\{0, \\dots, S-1\\}$, we compute the absolute difference between the empirical mean duration and the theoretical expected duration. This difference is then rounded to six decimal places as required. The results for all states within a test case form a list, and the lists for all test cases are aggregated into a final list of lists.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef viterbi(obs, S, pi, A, lmbdas):\n    \"\"\"\n    Computes the most probable latent state sequence using the Viterbi algorithm.\n    This implementation operates in the log domain for numerical stability and adheres\n    to the problem's tie-breaking rule (smallest index).\n\n    Args:\n        obs (np.array): Sequence of observations.\n        S (int): Number of states.\n        pi (np.array): Initial state distribution.\n        A (np.array): State transition matrix.\n        lmbdas (np.array): Poisson rate parameters for each state.\n\n    Returns:\n        np.array: The most probable sequence of latent states (Viterbi path).\n    \"\"\"\n    T = len(obs)\n    delta = np.zeros((T, S))\n    psi = np.zeros((T, S), dtype=int)\n\n    with np.errstate(divide='ignore'):\n        log_pi = np.log(pi)\n        log_A = np.log(A)\n        log_lmbdas = np.log(lmbdas)\n\n    # Initialization (t=0)\n    for i in range(S):\n        # Poisson log-probability without the constant log(o_t!) term\n        log_p_emission = obs[0] * log_lmbdas[i] - lmbdas[i]\n        delta[0, i] = log_pi[i] + log_p_emission\n\n    # Recursion (t=1 to T-1)\n    for t in range(1, T):\n        for j in range(S):\n            # Log-probabilities of paths ending in state j at time t\n            trans_log_probs = delta[t-1, :] + log_A[:, j]\n            \n            # The smallest-index tie-breaking rule is naturally handled by np.argmax\n            argmax_state = np.argmax(trans_log_probs)\n            max_log_prob = trans_log_probs[argmax_state]\n            \n            log_p_emission = obs[t] * log_lmbdas[j] - lmbdas[j]\n            \n            delta[t, j] = max_log_prob + log_p_emission\n            psi[t, j] = argmax_state\n\n    # Path backtracking\n    path = np.zeros(T, dtype=int)\n    # Tie-breaking for the final state is also handled by np.argmax\n    path[T-1] = np.argmax(delta[T-1, :])\n    \n    for t in range(T-2, -1, -1):\n        path[t] = psi[t+1, path[t+1]]\n        \n    return path\n\ndef get_run_lengths(path, S):\n    \"\"\"\n    Parses a sequence to find contiguous runs of each state and groups them.\n\n    Args:\n        path (np.array): A sequence of states.\n        S (int): The total number of possible states.\n\n    Returns:\n        dict: A dictionary mapping each state index to a list of its run-lengths.\n    \"\"\"\n    run_lengths = {i: [] for i in range(S)}\n    if len(path) == 0:\n        return run_lengths\n\n    current_state = path[0]\n    current_length = 1\n    for i in range(1, len(path)):\n        if path[i] == current_state:\n            current_length += 1\n        else:\n            run_lengths[current_state].append(current_length)\n            current_state = path[i]\n            current_length = 1\n    \n    # Append the last run\n    run_lengths[current_state].append(current_length)\n    return run_lengths\n\ndef solve():\n    \"\"\"\n    Main function to run all test cases and produce the final output.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        {\n            \"S\": 3,\n            \"pi\": [0.6, 0.3, 0.1],\n            \"A\": [[0.90, 0.08, 0.02], [0.05, 0.92, 0.03], [0.04, 0.06, 0.90]],\n            \"lmbdas\": [2.0, 8.0, 15.0],\n            \"obs\": [2, 1, 3, 2, 2, 9, 8, 7, 10, 15, 14, 16, 17, 13, 12, 1, 2, 3, 8, 9, 8, 12, 18, 15, 14, 16],\n        },\n        {\n            \"S\": 3,\n            \"pi\": [0.33, 0.33, 0.34],\n            \"A\": [[0.97, 0.02, 0.01], [0.01, 0.97, 0.02], [0.02, 0.01, 0.97]],\n            \"lmbdas\": [3.0, 9.0, 14.0],\n            \"obs\": [14, 15, 13, 16, 14, 14, 15, 13, 17, 12, 14, 16, 15, 13, 14, 15, 16, 13, 15, 14, 9, 10, 8, 9, 10, 7, 9, 8, 9, 11, 9, 8, 10, 9, 9, 3, 2, 4, 3, 3, 2, 4, 3, 2, 3],\n        },\n        {\n            \"S\": 2,\n            \"pi\": [0.5, 0.5],\n            \"A\": [[0.60, 0.40], [0.40, 0.60]],\n            \"lmbdas\": [5.0, 5.0],\n            \"obs\": [4, 6, 5, 7, 5, 5, 4, 6, 5, 5, 5, 6],\n        },\n    ]\n\n    all_case_results = []\n    for case in test_cases:\n        S = case[\"S\"]\n        pi = np.array(case[\"pi\"])\n        A = np.array(case[\"A\"])\n        lmbdas = np.array(case[\"lmbdas\"])\n        obs = np.array(case[\"obs\"])\n\n        viterbi_path = viterbi(obs, S, pi, A, lmbdas)\n        \n        # Calculate empirical mean durations\n        run_lengths = get_run_lengths(viterbi_path, S)\n        empirical_means = np.zeros(S)\n        for i in range(S):\n            if run_lengths[i]:\n                empirical_means[i] = np.mean(run_lengths[i])\n            else:\n                # Per problem spec, mean duration is 0 if state does not appear\n                empirical_means[i] = 0.0\n\n        # Calculate expected mean durations from the Markov property\n        expected_means = 1.0 / (1.0 - np.diag(A))\n\n        # Compute absolute differences and round to six decimal places\n        abs_diffs = np.abs(empirical_means - expected_means)\n        rounded_diffs = [round(d, 6) for d in abs_diffs]\n        \n        all_case_results.append(rounded_diffs)\n    \n    # Format the final output string as a list of lists with no spaces\n    sublist_strings = [f\"[{','.join(map(str, res))}]\" for res in all_case_results]\n    final_output = f\"[{','.join(sublist_strings)}]\"\n    print(final_output)\n\nsolve()\n```"
        },
        {
            "introduction": "While the Viterbi algorithm finds the single most probable state sequence, this is not the only way to perform decoding. This exercise explores the critical conceptual and practical differences between finding the most likely *sequence* (global decoding) and finding the most likely state at each *individual time point* (marginal decoding). Through a carefully constructed scenario relevant to neural data, you will dissect why these two statistically valid approaches can yield different results, thereby deepening your understanding of the loss functions and assumptions underlying different inference goals .",
            "id": "4168530",
            "problem": "Consider a Hidden Markov Model (HMM) for discrete neural states describing a single neuron's spike counts in sequential time bins. There are two latent states, $S_t \\in \\{1,2\\}$, representing a low-rate state ($1$) and a high-rate state ($2$). The initial state distribution is uniform, $\\pi_1(1)=\\pi_1(2)=0.5$. The state transition matrix is\n$$\nA = \\begin{pmatrix}\n0.8 & 0.2 \\\\\n0.2 & 0.8\n\\end{pmatrix},\n$$\nso self-transitions have probability $0.8$ and switches have probability $0.2$. Observations are spike counts $y_t \\in \\mathbb{N}_0$, modeled as conditionally independent across time given the states, with Poisson emissions:\n$$\np(y_t \\mid S_t=i) = \\frac{\\lambda_i^{y_t} e^{-\\lambda_i}}{y_t!}, \\quad \\lambda_1 = 1, \\ \\lambda_2 = 4.\n$$\nAssume three consecutive bins are observed with counts $y_{1:3}=(1,4,1)$.\n\nDefine the marginal posterior $\\gamma_t(i) = \\mathbb{P}(S_t=i \\mid y_{1:3})$ obtained by the forward-backward (sum-product) algorithm, and the Viterbi path as the maximum a posteriori (MAP) state sequence $\\hat{s}_{1:3} = \\arg\\max_{s_{1:3}} \\mathbb{P}(s_{1:3} \\mid y_{1:3})$, computed by dynamic programming (max-product). In neuroscience data analysis, one often compares per-bin marginal decoding, $\\hat{s}^{\\mathrm{marg}}_t = \\arg\\max_i \\gamma_t(i)$, against the Viterbi sequence $\\hat{s}_{1:3}$.\n\nUsing only fundamental definitions of HMMs (Markov property, Bayes rule, Poisson emission model, and dynamic programming as an implementation of maximizing or summing over hidden-state trajectories), reason through the contrast between the Viterbi path and marginal decoding. In particular, determine whether the two decodings agree for the given observation $y_{1:3}$ and parameters, and explain the statistical conditions under which they disagree in neural data characterized by transient bursts flanked by quiescent bins.\n\nSelect all correct statements below.\n\nA. For the given HMM and data $y_{1:3}=(1,4,1)$, marginal decoding at $t=2$ yields $\\arg\\max_i \\gamma_2(i)=2$, while the Viterbi path is $\\hat{s}_{1:3}=(1,1,1)$; thus they disagree at $t=2$.\n\nB. Under sequence-level $0$–$1$ loss (counting an error if any time step is wrong), the Viterbi path is Bayes optimal; under per-bin $0$–$1$ loss (Hamming loss on states), marginal decoding via $\\arg\\max_i \\gamma_t(i)$ is Bayes optimal.\n\nC. In this setting, the disagreement arises because the posterior probability mass summed over all state sequences with $S_2=2$ exceeds that with $S_2=1$, even though the single most probable path is $(1,1,1)$.\n\nD. Marginal decoding $\\hat{s}^{\\mathrm{marg}}_t = \\arg\\max_i \\gamma_t(i)$ necessarily outputs a state sequence that satisfies all HMM transition constraints (i.e., it always has nonzero probability under the modeled transition matrix).\n\nE. In neural data with a transient high-rate burst at a single bin flanked by low-rate bins and strong self-transition probabilities, disagreement between Viterbi and marginal decoding is more likely at the burst bin because two switches are penalized at the sequence level, whereas the per-bin posterior can still favor the burst state at that time.",
            "solution": "The problem statement is scientifically sound, well-posed, and objective. It provides a complete definition of a Hidden Markov Model (HMM) with all necessary parameters: the state space $S_t \\in \\{1,2\\}$, the initial state distribution $\\pi$, the transition matrix $A$, and the Poisson emission distributions $p(y_t|S_t)$. The observed data sequence $y_{1:3}$ is also provided. The questions posed are standard inquiries in the analysis of HMMs and can be answered through direct calculation and reasoning based on the fundamental principles of HMM theory. Therefore, a full analysis is warranted.\n\nThe core of the problem is to compare the Viterbi path $\\hat{s}_{1:3}$ (the single most likely state sequence) with the sequence of per-bin maximum marginal posterior states $\\hat{s}^{\\mathrm{marg}}_{1:3}$.\n\nThe joint probability of a state sequence $s_{1:T}$ and an observation sequence $y_{1:T}$ is given by:\n$$\n\\mathbb{P}(s_{1:T}, y_{1:T}) = \\pi(s_1) p(y_1|s_1) \\prod_{t=2}^{T} a_{s_{t-1}s_t} p(y_t|s_t)\n$$\nwhere $a_{ij} = \\mathbb{P}(S_t=j \\mid S_{t-1}=i)$.\n\nThe Viterbi path is the sequence $\\hat{s}_{1:T}$ that maximizes this joint probability (and thus also the conditional probability $\\mathbb{P}(s_{1:T} \\mid y_{1:T})$):\n$$\n\\hat{s}_{1:T} = \\arg\\max_{s_{1:T}} \\mathbb{P}(s_{1:T}, y_{1:T})\n$$\nThis is computed using the Viterbi algorithm (max-product).\n\nThe marginal posterior probability of being in state $i$ at time $t$ is:\n$$\n\\gamma_t(i) = \\mathbb{P}(S_t=i \\mid y_{1:T}) = \\frac{\\mathbb{P}(S_t=i, y_{1:T})}{\\mathbb{P}(y_{1:T})} = \\frac{\\sum_{s_{1:t-1}, s_{t+1:T}} \\mathbb{P}(s_1, \\dots, S_t=i, \\dots, s_T, y_{1:T})}{\\mathbb{P}(y_{1:T})}\n$$\nThis is computed efficiently using the forward-backward algorithm (sum-product), where $\\mathbb{P}(S_t=i, y_{1:T}) = \\alpha_t(i)\\beta_t(i)$. The marginal decoding is then $\\hat{s}^{\\mathrm{marg}}_t = \\arg\\max_i \\gamma_t(i)$.\n\nLet's compute the necessary quantities for the given data $y_{1:3}=(1,4,1)$. The emission probabilities are:\n$p(y=1|S=1, \\lambda_1=1) = \\frac{1^1 e^{-1}}{1!} = e^{-1}$\n$p(y=1|S=2, \\lambda_2=4) = \\frac{4^1 e^{-4}}{1!} = 4e^{-4}$\n$p(y=4|S=1, \\lambda_1=1) = \\frac{1^4 e^{-1}}{4!} = \\frac{e^{-1}}{24}$\n$p(y=4|S=2, \\lambda_2=4) = \\frac{4^4 e^{-4}}{4!} = \\frac{256}{24}e^{-4} = \\frac{32}{3}e^{-4}$\n\n**1. Viterbi Path Calculation**\n\nWe use the Viterbi recursion $\\delta_t(j) = \\max_i (\\delta_{t-1}(i) a_{ij}) p(y_t|S_t=j)$. We also keep track of the most likely predecessor state in $\\psi_t(j)$.\n\n**Time $t=1$:**\n$\\delta_1(1) = \\pi(1) p(y_1=1|S_1=1) = 0.5 \\cdot e^{-1}$\n$\\delta_1(2) = \\pi(2) p(y_1=1|S_1=2) = 0.5 \\cdot 4e^{-4} = 2e^{-4}$\nSince $0.5e^{-1} \\approx 0.184$ and $2e^{-4} \\approx 0.037$, $\\delta_1(1) > \\delta_1(2)$.\n\n**Time $t=2$:**\n$\\delta_2(1) = \\max(\\delta_1(1)a_{11}, \\delta_1(2)a_{21}) \\cdot p(y_2=4|S_2=1)$\n$= \\max(0.5e^{-1} \\cdot 0.8, 2e^{-4} \\cdot 0.2) \\cdot \\frac{e^{-1}}{24} = \\max(0.4e^{-1}, 0.4e^{-4}) \\cdot \\frac{e^{-1}}{24}$\nSince $0.4e^{-1} > 0.4e^{-4}$, the max is the first term. Predecessor is state $1$.\n$\\delta_2(1) = 0.4e^{-1} \\cdot \\frac{e^{-1}}{24} = \\frac{0.4}{24}e^{-2} \\approx 0.00226$. $\\psi_2(1)=1$.\n\n$\\delta_2(2) = \\max(\\delta_1(1)a_{12}, \\delta_1(2)a_{22}) \\cdot p(y_2=4|S_2=2)$\n$= \\max(0.5e^{-1} \\cdot 0.2, 2e^{-4} \\cdot 0.8) \\cdot \\frac{32}{3}e^{-4} = \\max(0.1e^{-1}, 1.6e^{-4}) \\cdot \\frac{32}{3}e^{-4}$\nSince $0.1e^{-1} \\approx 0.0368 > 1.6e^{-4} \\approx 0.00029$, the max is the first term. Predecessor is state $1$.\n$\\delta_2(2) = 0.1e^{-1} \\cdot \\frac{32}{3}e^{-4} = \\frac{3.2}{3}e^{-5} \\approx 0.00719$. $\\psi_2(2)=1$.\n\n**Time $t=3$:**\n$\\delta_3(1) = \\max(\\delta_2(1)a_{11}, \\delta_2(2)a_{21}) \\cdot p(y_3=1|S_3=1)$\n$= \\max(\\frac{0.4}{24}e^{-2} \\cdot 0.8, \\frac{3.2}{3}e^{-5} \\cdot 0.2) \\cdot e^{-1} = \\max(\\frac{0.32}{24}e^{-2}, \\frac{0.64}{3}e^{-5}) \\cdot e^{-1}$\nThe terms are $\\approx 0.00180$ and $\\approx 0.00144$. The max is the first term. Predecessor is state $1$.\n$\\delta_3(1) = \\frac{0.32}{24}e^{-3} \\approx 0.00066$. $\\psi_3(1)=1$.\n\n$\\delta_3(2) = \\max(\\delta_2(1)a_{12}, \\delta_2(2)a_{22}) \\cdot p(y_3=1|S_3=2)$\n$= \\max(\\frac{0.4}{24}e^{-2} \\cdot 0.2, \\frac{3.2}{3}e^{-5} \\cdot 0.8) \\cdot 4e^{-4} = \\max(\\frac{0.08}{24}e^{-2}, \\frac{2.56}{3}e^{-5}) \\cdot 4e^{-4}$\nThe terms are $\\approx 0.00045$ and $\\approx 0.00575$. The max is the second term. Predecessor is state $2$.\n$\\delta_3(2) = \\frac{2.56}{3}e^{-5} \\cdot 4e^{-4} = \\frac{10.24}{3}e^{-9} \\approx 0.00042$. $\\psi_3(2)=2$.\n\n**Termination and Backtracking:**\nThe maximum probability is $\\max(\\delta_3(1), \\delta_3(2)) = \\delta_3(1)$.\nSo, the most probable state at $t=3$ is $\\hat{s}_3=1$.\nBacktracking:\n$\\hat{s}_3=1 \\implies \\hat{s}_2 = \\psi_3(1) = 1$.\n$\\hat{s}_2=1 \\implies \\hat{s}_1 = \\psi_2(1) = 1$.\nThe Viterbi path is $\\hat{s}_{1:3} = (1,1,1)$.\n\n**2. Marginal Posterior Calculation at $t=2$**\n\nWe need to compare $\\gamma_2(1)$ and $\\gamma_2(2)$. This is equivalent to comparing $\\alpha_2(1)\\beta_2(1)$ and $\\alpha_2(2)\\beta_2(2)$.\n\n**Forward pass ($\\alpha_t(i)$):**\n$\\alpha_1(1) = 0.5e^{-1}$, $\\alpha_1(2) = 2e^{-4}$.\n$\\alpha_2(1) = (\\alpha_1(1)a_{11} + \\alpha_1(2)a_{21}) p(y_2=4|S_2=1)$\n$= (0.5e^{-1} \\cdot 0.8 + 2e^{-4} \\cdot 0.2) \\frac{e^{-1}}{24} = (0.4e^{-1} + 0.4e^{-4})\\frac{e^{-1}}{24} \\approx 0.00236$.\n$\\alpha_2(2) = (\\alpha_1(1)a_{12} + \\alpha_1(2)a_{22}) p(y_2=4|S_2=2)$\n$= (0.5e^{-1} \\cdot 0.2 + 2e^{-4} \\cdot 0.8) \\frac{32}{3}e^{-4} = (0.1e^{-1} + 1.6e^{-4})\\frac{32}{3}e^{-4} \\approx 0.00776$.\n\n**Backward pass ($\\beta_t(i)$):**\n$\\beta_3(1)=1$, $\\beta_3(2)=1$.\n$\\beta_2(1) = a_{11} p(y_3=1|S_3=1) \\beta_3(1) + a_{12} p(y_3=1|S_3=2) \\beta_3(2)$\n$= 0.8 \\cdot e^{-1} + 0.2 \\cdot 4e^{-4} = 0.8e^{-1} + 0.8e^{-4} \\approx 0.3089$.\n$\\beta_2(2) = a_{21} p(y_3=1|S_3=1) \\beta_3(1) + a_{22} p(y_3=1|S_3=2) \\beta_3(2)$\n$= 0.2 \\cdot e^{-1} + 0.8 \\cdot 4e^{-4} = 0.2e^{-1} + 3.2e^{-4} \\approx 0.1322$.\n\n**Marginal Posterior at $t=2$:**\nWe compare the joint probabilities $\\mathbb{P}(S_2=i, y_{1:3}) = \\alpha_2(i)\\beta_2(i)$:\n$\\mathbb{P}(S_2=1, y_{1:3}) = \\alpha_2(1)\\beta_2(1) \\approx 0.00236 \\cdot 0.3089 \\approx 0.000729$.\n$\\mathbb{P}(S_2=2, y_{1:3}) = \\alpha_2(2)\\beta_2(2) \\approx 0.00776 \\cdot 0.1322 \\approx 0.001026$.\nSince $\\mathbb{P}(S_2=2, y_{1:3}) > \\mathbb{P}(S_2=1, y_{1:3})$, it follows that $\\gamma_2(2) > \\gamma_2(1)$.\nThus, the marginal decoding at $t=2$ is $\\hat{s}^{\\mathrm{marg}}_2 = \\arg\\max_i \\gamma_2(i) = 2$.\n\n**Option-by-Option Analysis**\n\n**A. For the given HMM and data $y_{1:3}=(1,4,1)$, marginal decoding at $t=2$ yields $\\arg\\max_i \\gamma_2(i)=2$, while the Viterbi path is $\\hat{s}_{1:3}=(1,1,1)$; thus they disagree at $t=2$.**\nOur calculations show the Viterbi path is $\\hat{s}_{1:3}=(1,1,1)$, so $\\hat{s}_2=1$. Our calculations also show the marginal decoding is $\\hat{s}^{\\mathrm{marg}}_2=2$. The two methods yield different state estimates for time $t=2$.\n**Verdict: Correct.**\n\n**B. Under sequence-level $0$–$1$ loss (counting an error if any time step is wrong), the Viterbi path is Bayes optimal; under per-bin $0$–$1$ loss (Hamming loss on states), marginal decoding via $\\arg\\max_i \\gamma_t(i)$ is Bayes optimal.**\nThis is a fundamental theorem of decision theory as applied to HMMs.\n- The Viterbi path finds $\\hat{s}_{1:T} = \\arg\\max_{s_{1:T}} \\mathbb{P}(s_{1:T} | y_{1:T})$. By finding the single most probable overall sequence, it minimizes the probability of being entirely wrong about the sequence, which is the definition of a Bayes optimal decision rule for a sequence-level $0-1$ loss function.\n- Marginal decoding finds $\\hat{s}^{\\mathrm{marg}}_t = \\arg\\max_i \\mathbb{P}(S_t=i | y_{1:T})$. For each time bin $t$, this rule maximizes the probability of being correct about the state in that specific bin, thus minimizing the expected loss under a per-bin $0-1$ loss. Summing these losses over all bins yields the Hamming loss. Thus, marginal decoding is the Bayes optimal procedure for minimizing the expected Hamming loss.\n**Verdict: Correct.**\n\n**C. In this setting, the disagreement arises because the posterior probability mass summed over all state sequences with $S_2=2$ exceeds that with $S_2=1$, even though the single most probable path is $(1,1,1)$.**\nThe \"posterior probability mass summed over all state sequences with $S_2=i$\" is precisely the definition of the marginal posterior $\\mathbb{P}(S_2=i \\mid y_{1:3})$, which is $\\gamma_2(i)$. The statement is thus equivalent to: \"$\\gamma_2(2) > \\gamma_2(1)$ even though the Viterbi path is $(1,1,1)$\". Our calculations in (1) and (2) confirm both of these facts. The statement accurately describes the statistical source of the disagreement: the Viterbi algorithm identifies the single path with the highest probability, while the marginal posterior at a point $t$ sums the probabilities of all paths that pass through a given state at $t$. A large number of individually less-likely paths can collectively have more probability mass than a smaller number of paths that includes the single most-likely one.\n**Verdict: Correct.**\n\n**D. Marginal decoding $\\hat{s}^{\\mathrm{marg}}_t = \\arg\\max_i \\gamma_t(i)$ necessarily outputs a state sequence that satisfies all HMM transition constraints (i.e., it always has nonzero probability under the modeled transition matrix).**\nThis statement is false. The marginal decoding procedure $\\hat{s}^{\\mathrm{marg}}_t = \\arg\\max_i \\gamma_t(i)$ is performed independently for each time step $t$. It considers the entire observation sequence $y_{1:T}$ to compute each $\\gamma_t(i)$, but the choice of $\\hat{s}^{\\mathrm{marg}}_t$ does not constrain the choice of $\\hat{s}^{\\mathrm{marg}}_{t+1}$. If the transition matrix $A$ contains zero entries (i.e., forbidden transitions, $a_{ij}=0$), it is possible for marginal decoding to produce a sequence $(\\dots, \\hat{s}^{\\mathrm{marg}}_t=i, \\hat{s}^{\\mathrm{marg}}_{t+1}=j, \\dots)$ where $a_{ij}=0$. Such a sequence is \"impossible\" under the model's dynamics. The Viterbi algorithm, in contrast, explicitly constructs a path by following valid transitions, so its output is always a valid sequence. In the specific HMM for this problem, all transitions are non-zero, but the statement makes a general claim about marginal decoding which is not true in general.\n**Verdict: Incorrect.**\n\n**E. In neural data with a transient high-rate burst at a single bin flanked by low-rate bins and strong self-transition probabilities, disagreement between Viterbi and marginal decoding is more likely at the burst bin because two switches are penalized at the sequence level, whereas the per-bin posterior can still favor the burst state at that time.**\nThis provides a qualitative explanation for the phenomenon observed. The data $y_{1:3}=(1,4,1)$ represents exactly such a transient burst. The model has strong self-transitions ($a_{11}=a_{22}=0.8$).\n- To explain the data with a state sequence like $(1,2,1)$, the Viterbi algorithm must account for the probability of the entire path. This involves a factor of $a_{12}a_{21} = 0.2 \\cdot 0.2 = 0.04$ for the two state switches. Viterbi decoding penalizes these switches. It may prefer a path like $(1,1,1)$ which has a higher transition probability factor ($a_{11}a_{11} = 0.8 \\cdot 0.8 = 0.64$) but pays a penalty on the emission term at the burst bin ($p(y_2=4|S_2=1)$ is low).\n- The marginal posterior $\\gamma_2(2)$ at the burst bin, however, sums over all paths through state $2$. The strong evidence from the emission $p(y_2=4|S_2=2)$ boosts the probability of all such paths, and their sum can easily dominate the sum of probabilities for paths through state $1$, where the emission term is small. This statement correctly identifies the tension between path-level optimization (Viterbi) and state-level optimization (marginal decoding).\n**Verdict: Correct.**",
            "answer": "$$\\boxed{ABCE}$$"
        },
        {
            "introduction": "Our first exercise revealed that standard HMMs impose a restrictive, memoryless geometric distribution on state durations, which may not align with biological reality. To build more flexible and realistic models, we can extend the HMM framework to directly model the time spent in each state. This advanced practice introduces the Hidden Semi-Markov Model (HSMM), which accomplishes this by incorporating explicit duration distributions, and guides you through the complete workflow of fitting these distributions from data, selecting the best model, and implementing the corresponding dynamic programming algorithm for decoding .",
            "id": "4168478",
            "problem": "You are given empirical dwell-time histograms for discrete neural states and spike count observations from a neural population recorded at regular time steps. The modeling task is to construct a Hidden Semi-Markov Model (HSMM), which is an extension of the Hidden Markov Model (HMM) that explicitly models state durations, and decode the most likely sequence of discrete neural states over time. The goal is to ground the design in the fundamental definitions of probabilistic modeling, likelihood-based parameter estimation, and dynamic programming for state inference.\n\nStarting from foundational principles, you must proceed as follows:\n- Define a Hidden Markov Model (HMM) with discrete states that emits observations according to a state-specific distribution, and extend it to a Hidden Semi-Markov Model (HSMM) by specifying an explicit duration distribution for each state. The Hidden Semi-Markov Model (HSMM) separates the duration distribution from the transition mechanism and does not rely on self-transitions to encode persistence.\n- Fit parametric duration distributions to the empirical dwell-time histograms for each state by maximizing the likelihood of the histogram counts under each candidate family and then select a family using an information criterion. You must perform Maximum Likelihood Estimation (MLE) using only the empirical histogram counts and the parametric forms, without relying on any pre-derived shortcut formulas presented to you.\n- Implement exact-duration decoding using a dynamic programming algorithm that computes the most likely segmentation and state sequence that exactly covers the observation sequence, respecting the explicit duration distributions. The inference must be performed over a finite duration support and must ensure probabilities are properly normalized over this support.\n\nYou must implement the following computational elements:\n- Fit two candidate explicit duration distributions per state: a geometric distribution on $\\{1,2,\\dots\\}$ parameterized by $p$, and a shifted Poisson distribution on $\\{1,2,\\dots\\}$ parameterized by $\\lambda$ via a shift of one time step. For model selection between these two one-parameter families, use the Akaike Information Criterion (AIC), and in the event of an exact tie you must choose the geometric distribution. You must use likelihoods computed from the empirical histogram counts and parametric probabilities evaluated at the observed durations. You must truncate the duration probability mass function to a maximum duration $D_{\\max}$ and renormalize it to sum to $1$ on $\\{1,\\dots,D_{\\max}\\}$ for HSMM inference.\n- Use a Poisson observation model for spike counts with state-specific rate parameters $\\lambda^{(\\mathrm{em})}_i$ for state $i$, and compute the most likely state sequence consistent with the HSMM using an explicit-duration Viterbi-style dynamic program that sums over possible segment durations. You must assume transitions only occur at segment boundaries and are governed by a boundary transition matrix with no self-transitions.\n\nYour program must take no input and must operate on the following fixed test suite embedded in the code. For each test case, you will compute the single most likely decoded state sequence (as a list of integers) of length $T$, where each element is the inferred state index at that time step.\n\nTest suite specification:\n- Let the number of states be $K = 2$ and the maximum duration support be $D_{\\max} = 8$ for all cases.\n- Case $1$:\n    - Empirical dwell-time histogram counts for state $0$: $\\{40,30,20,10,5,3,2,1\\}$ over durations $\\{1,2,3,4,5,6,7,8\\}$.\n    - Empirical dwell-time histogram counts for state $1$: $\\{5,10,15,20,15,10,5,4\\}$ over durations $\\{1,2,3,4,5,6,7,8\\}$.\n    - Observation sequence length $T = 25$ with spike counts $y_{1:T} = \\{2,1,3,0,1,4,2,1,10,8,9,7,11,12,8,9,7,10,9,1,3,2,0,2,1\\}$.\n    - Initial state distribution $\\boldsymbol{\\pi} = [0.5, 0.5]$.\n    - Boundary transition matrix $A = \\begin{bmatrix}0 & 1 \\\\ 1 & 0\\end{bmatrix}$.\n    - Poisson emission rates $\\boldsymbol{\\lambda}^{(\\mathrm{em})} = [2.0, 9.0]$.\n- Case $2$:\n    - Empirical dwell-time histogram counts for state $0$: $\\{80,10,5,3,1,1,0,0\\}$ over durations $\\{1,2,3,4,5,6,7,8\\}$.\n    - Empirical dwell-time histogram counts for state $1$: $\\{5,10,15,10,8,6,5,3\\}$ over durations $\\{1,2,3,4,5,6,7,8\\}$.\n    - Observation sequence length $T = 12$ with spike counts $y_{1:T} = \\{5,6,0,1,2,1,0,7,6,5,1,0\\}$.\n    - Initial state distribution $\\boldsymbol{\\pi} = [0.5, 0.5]$.\n    - Boundary transition matrix $A = \\begin{bmatrix}0 & 1 \\\\ 1 & 0\\end{bmatrix}$.\n    - Poisson emission rates $\\boldsymbol{\\lambda}^{(\\mathrm{em})} = [5.0, 1.0]$.\n- Case $3$:\n    - Empirical dwell-time histogram counts for state $0$: $\\{10,9,8,7,6,5,4,3\\}$ over durations $\\{1,2,3,4,5,6,7,8\\}$.\n    - Empirical dwell-time histogram counts for state $1$: $\\{1,2,3,4,5,6,7,8\\}$ over durations $\\{1,2,3,4,5,6,7,8\\}$.\n    - Observation sequence length $T = 20$ with spike counts $y_{1:T} = \\{3,2,4,3,5,2,3,4,8,7,9,6,8,7,9,2,1,3,2,2\\}$.\n    - Initial state distribution $\\boldsymbol{\\pi} = [0.5, 0.5]$.\n    - Boundary transition matrix $A = \\begin{bmatrix}0 & 1 \\\\ 1 & 0\\end{bmatrix}$.\n    - Poisson emission rates $\\boldsymbol{\\lambda}^{(\\mathrm{em})} = [3.0, 7.0]$.\n\nAlgorithmic requirements:\n- For duration fitting per state, compute the Maximum Likelihood Estimates for each candidate family from the histogram counts and durations $\\{1,\\dots,D_{\\max}\\}$, evaluate the log-likelihood at those durations, compute the Akaike Information Criterion, and select the family with the lower AIC (choose geometric in case of tie). Then construct a truncated and renormalized duration probability mass function over $\\{1,\\dots,D_{\\max}\\}$ for HSMM inference.\n- For decoding, compute the Poisson log-likelihood of each observation under each state, and implement an explicit-duration Viterbi dynamic program over time $\\{1,\\dots,T\\}$ that considers all durations $d \\in \\{1,\\dots,\\min(D_{\\max}, t)\\}$ for segments ending at time $t$, correctly handling the initial segment with the initial state distribution and transitions only at boundaries.\n\nYour program should produce a single line of output containing the decoded state sequences for the three test cases as a comma-separated list enclosed in square brackets, where each element is itself a list of integers of length $T$ representing the inferred state at each time step, for example: `[[s_1^{(1)},...,s_{T_1}^{(1)}], [s_1^{(2)},...,s_{T_2}^{(2)}], [s_1^{(3)},...,s_{T_3}^{(3)}]]`.",
            "solution": "The problem requires the construction and application of a Hidden Semi-Markov Model (HSMM) to decode a sequence of discrete neural states from spike count data. This involves two primary stages: first, estimating the parameters of the model, specifically the state duration distributions, from empirical data; and second, using these parameters to find the most likely sequence of hidden states corresponding to an observed sequence of spike counts. The solution will be developed from fundamental principles of probabilistic modeling, maximum likelihood estimation, and dynamic programming.\n\n**1. Model Specification: From HMM to HSMM**\n\nA standard discrete-time Hidden Markov Model (HMM) is defined by a set of hidden states $S = \\{s_1, \\dots, s_K\\}$, an alphabet of observations, and three probability distributions:\n1.  An initial state distribution $\\boldsymbol{\\pi} = [\\pi_i]$, where $\\pi_i = P(q_1 = s_i)$.\n2.  A state transition probability matrix $A = [a_{ij}]$, where $a_{ij} = P(q_t = s_j | q_{t-1} = s_i)$.\n3.  An emission probability distribution $B = [b_j(y)]$, where $b_j(y) = P(y_t = y | q_t = s_j)$.\n\nIn a standard HMM, the duration $d$ a state $s_i$ is occupied follows a geometric distribution with parameter $p = 1 - a_{ii}$. This implicit modeling of duration is often restrictive. The Hidden Semi-Markov Model (HSMM) generalizes the HMM by introducing an explicit probability distribution for the dwell time in each state, $P_i(d) = P(\\text{duration} = d | \\text{state} = s_i)$. In an HSMM, transitions between states occur only at the end of a state segment. The transition probability $A_{ij}$ is now the probability of transitioning to state $s_j$ given that a segment of state $s_i$ has just ended. Consequently, the diagonal elements of this boundary transition matrix are zero, i.e., $A_{ii}=0$.\n\n**2. Parameter Estimation for State Duration Distributions**\n\nThe problem provides empirical dwell-time histograms for each state $i$, given as counts $N_i(d)$ for durations $d \\in \\{1, 2, \\dots, D_{\\max}\\}$. We must fit two candidate parametric distributions, Geometric and Shifted Poisson, to these counts via Maximum Likelihood Estimation (MLE).\n\nThe likelihood of observing the histogram counts $\\{N_i(d)\\}_{d=1}^{D_{\\max}}$ for a state $i$ under a parametric duration distribution $p(d; \\theta)$ is given by the multinomial probability distribution. The log-likelihood, ignoring constant terms, is:\n$$ \\mathcal{L}(\\theta) = \\sum_{d=1}^{D_{\\max}} N_i(d) \\log p(d; \\theta) $$\nWe find the MLE parameter $\\hat{\\theta}$ by maximizing this log-likelihood.\n\n**2.1. Geometric Distribution**\nThe PMF for a geometric distribution on $d \\in \\{1, 2, \\dots\\}$ is $p(d; p) = (1-p)^{d-1} p$.\nThe log-likelihood is:\n$$ \\mathcal{L}(p) = \\sum_{d=1}^{D_{\\max}} N_i(d) \\log\\left((1-p)^{d-1} p\\right) = \\sum_{d=1}^{D_{\\max}} N_i(d) \\left((d-1)\\log(1-p) + \\log p\\right) $$\nTo find the MLE for $p$, we set the derivative with respect to $p$ to zero:\n$$ \\frac{\\partial \\mathcal{L}}{\\partial p} = \\sum_{d=1}^{D_{\\max}} N_i(d) \\left( \\frac{-(d-1)}{1-p} + \\frac{1}{p} \\right) = 0 $$\n$$ \\frac{1}{p} \\sum_{d=1}^{D_{\\max}} N_i(d) = \\frac{1}{1-p} \\sum_{d=1}^{D_{\\max}} (d-1)N_i(d) $$\nLet $N_{total} = \\sum_{d} N_i(d)$ be the total number of observed segments and $\\bar{d} = \\frac{\\sum_{d} d N_i(d)}{N_{total}}$ be the empirical mean duration. The equation becomes:\n$$ \\frac{N_{total}}{p} = \\frac{1}{1-p} (\\sum_d d N_i(d) - \\sum_d N_i(d)) = \\frac{N_{total}(\\bar{d}-1)}{1-p} $$\n$$ \\frac{1}{p} = \\frac{\\bar{d}-1}{1-p} \\implies 1-p = p(\\bar{d}-1) \\implies 1 = p\\bar{d} $$\nThus, the MLE for the geometric parameter is $\\hat{p} = 1/\\bar{d} = \\frac{\\sum_{d=1}^{D_{\\max}} N_i(d)}{\\sum_{d=1}^{D_{\\max}} d \\cdot N_i(d)}$.\n\n**2.2. Shifted Poisson Distribution**\nThe PMF for a Poisson distribution is $P(k; \\lambda) = e^{-\\lambda} \\lambda^k / k!$ for $k \\in \\{0, 1, \\dots\\}$. A shifted Poisson distribution for durations $d=k+1 \\in \\{1, 2, \\dots\\}$ has the PMF $p(d; \\lambda) = \\frac{e^{-\\lambda} \\lambda^{d-1}}{(d-1)!}$.\nThe log-likelihood is:\n$$ \\mathcal{L}(\\lambda) = \\sum_{d=1}^{D_{\\max}} N_i(d) \\log\\left(\\frac{e^{-\\lambda} \\lambda^{d-1}}{(d-1)!}\\right) = \\sum_{d=1}^{D_{\\max}} N_i(d) \\left(-\\lambda + (d-1)\\log \\lambda - \\log((d-1)!)\\right) $$\nSetting the derivative with respect to $\\lambda$ to zero:\n$$ \\frac{\\partial \\mathcal{L}}{\\partial \\lambda} = \\sum_{d=1}^{D_{\\max}} N_i(d) \\left(-1 + \\frac{d-1}{\\lambda}\\right) = 0 $$\n$$ \\frac{1}{\\lambda} \\sum_{d=1}^{D_{\\max}} (d-1)N_i(d) = \\sum_{d=1}^{D_{\\max}} N_i(d) $$\n$$ \\lambda \\sum_{d} N_i(d) = \\sum_{d} (d-1)N_i(d) = \\sum_{d} d N_i(d) - \\sum_{d} N_i(d) $$\nSolving for $\\lambda$ gives the MLE: $\\hat{\\lambda} = \\frac{\\sum_d d N_i(d)}{\\sum_d N_i(d)} - 1 = \\bar{d} - 1$.\n\n**2.3. Model Selection and Renormalization**\nAfter computing the MLE parameters $\\hat{p}$ and $\\hat{\\lambda}$, we evaluate the maximized log-likelihood $\\mathcal{L}_{max}$ for each model. The Akaike Information Criterion (AIC) is used for model selection:\n$$ \\text{AIC} = 2k - 2\\mathcal{L}_{max} $$\nwhere $k$ is the number of estimated parameters. For both the geometric and shifted Poisson models, $k=1$. We select the model with the lower AIC value, choosing the geometric model in case of a tie.\nOnce the best-fitting distribution $p(d;\\hat{\\theta})$ is selected for each state $i$, its PMF is calculated for durations $d \\in \\{1, \\dots, D_{\\max}\\}$. This distribution must be truncated and renormalized to ensure it sums to $1$ over this finite support:\n$$ P_i(d) = \\frac{p(d; \\hat{\\theta})}{\\sum_{d'=1}^{D_{\\max}} p(d'; \\hat{\\theta})} \\quad \\text{for } d=1, \\dots, D_{\\max} $$\n\n**3. Decoding with Explicit-Duration Viterbi Algorithm**\n\nThe goal of decoding is to find the most likely sequence of hidden states $q^*_{1:T} = (q^*_1, \\dots, q^*_T)$ that generated the observation sequence $y_{1:T} = (y_1, \\dots, y_T)$. This is solved using a dynamic programming approach, analogous to the Viterbi algorithm for HMMs.\n\nWe define $\\delta_t(j)$ as the maximum log-probability of any valid segmentation of the observation sequence $y_{1:t}$ ending with a segment of state $j$. We also use backpointer arrays, $\\psi_d(t, j)$ and $\\psi_s(t, j)$, to store the duration of the final segment and the identity of the previous state, respectively, for the path that yields $\\delta_t(j)$.\n\nThe observation model is a Poisson distribution with state-specific rate $\\lambda^{(\\mathrm{em})}_j$. The log-likelihood of observing a spike count $y$ in state $j$ is:\n$$ \\log P(y | \\text{state } j) = y \\log(\\lambda^{(\\mathrm{em})}_j) - \\lambda^{(\\mathrm{em})}_j - \\log(y!) $$\nWe precompute a table of these log-likelihoods for all observed counts and states. Let this be $\\log B_{t,j} = \\log P(y_t | \\text{state } j)$. The log-likelihood of an observation subsequence $y_{t-d+1:t}$ being generated by state $j$ is $L_{t-d+1:t}(j) = \\sum_{k=t-d+1}^{t} \\log B_{k,j}$.\n\nThe dynamic programming recursion proceeds as follows:\nFor $t = 1, \\dots, T$:\n  For each state $j \\in \\{0, \\dots, K-1\\}$:\n    $$ \\delta_t(j) = \\max_{d \\in \\{1,\\dots,\\min(t, D_{\\max})\\}} \\left( \\mathcal{V}_{t-d}(j) + \\log P_j(d) + L_{t-d+1:t}(j) \\right) $$\n    where $\\mathcal{V}_{\\tau}(j)$ is the maximum log-probability of a path ending at time $\\tau$ and transitioning to state $j$.\n    $$ \\mathcal{V}_{\\tau}(j) = \\begin{cases} \\log \\pi_j & \\text{if } \\tau = 0 \\\\ \\max_{i \\neq j} \\{\\delta_{\\tau}(i) + \\log A_{ij}\\} & \\text{if } \\tau > 0 \\end{cases} $$\n    For the specific case of $K=2$ and $A = \\begin{bmatrix}0&1\\\\1&0\\end{bmatrix}$, this simplifies to $\\mathcal{V}_{\\tau}(j) = \\delta_{\\tau}(1-j)$ for $\\tau>0$, since $\\log A_{ij} = \\log(1) = 0$.\n\nThe values of $d$ (duration) and $i$ (previous state) that achieve the maximum for $\\delta_t(j)$ are stored in the backpointer tables $\\psi_d(t,j)$ and $\\psi_s(t,j)$.\n\n**Initialization**: The recursion is naturally initialized by the $\\tau=0$ case in the definition of $\\mathcal{V}_{\\tau}(j)$. For a segment starting at time $1$ with duration $d=t$, the path probability comes from the initial distribution $\\pi_j$.\n\n**Termination**: After computing $\\delta_t(j)$ for all $t$ and $j$, the log-probability of the most likely full path is $\\log P^* = \\max_{j} \\delta_T(j)$, and the final state of this path is $q^*_T = \\arg\\max_{j} \\delta_T(j)$.\n\n**Backtracking**: The most likely state sequence is reconstructed by starting from $q^*_T$ at time $T$ and tracing backwards using the stored pointers.\nLet $t_{curr} = T$ and $j_{curr} = q^*_T$.\nWhile $t_{curr} > 0$:\n  1. Get the duration of the last segment: $d = \\psi_d(t_{curr}, j_{curr})$.\n  2. Get the previous state: $j_{prev} = \\psi_s(t_{curr}, j_{curr})$.\n  3. Assign state $j_{curr}$ to the time steps from $t_{curr}-d+1$ to $t_{curr}$.\n  4. Update for the next iteration: $t_{curr} \\leftarrow t_{curr} - d$, $j_{curr} \\leftarrow j_{prev}$.\nThis process continues until the entire sequence $q^*_{1:T}$ is reconstructed.\n\nThis comprehensive procedure, combining MLE-based parameter estimation with an explicit-duration dynamic programming algorithm, allows for the principled decoding of hidden neural states from observed activity.",
            "answer": "```python\nimport numpy as np\nfrom scipy.special import gammaln\n\ndef solve():\n    \"\"\"\n    Main function to run the HSMM decoding for all test cases.\n    \"\"\"\n    test_cases = [\n        {\n            \"hist_0\": np.array([40, 30, 20, 10, 5, 3, 2, 1]),\n            \"hist_1\": np.array([5, 10, 15, 20, 15, 10, 5, 4]),\n            \"obs\": np.array([2, 1, 3, 0, 1, 4, 2, 1, 10, 8, 9, 7, 11, 12, 8, 9, 7, 10, 9, 1, 3, 2, 0, 2, 1]),\n            \"pi\": np.array([0.5, 0.5]),\n            \"A\": np.array([[0.0, 1.0], [1.0, 0.0]]),\n            \"lambda_em\": np.array([2.0, 9.0]),\n        },\n        {\n            \"hist_0\": np.array([80, 10, 5, 3, 1, 1, 0, 0]),\n            \"hist_1\": np.array([5, 10, 15, 10, 8, 6, 5, 3]),\n            \"obs\": np.array([5, 6, 0, 1, 2, 1, 0, 7, 6, 5, 1, 0]),\n            \"pi\": np.array([0.5, 0.5]),\n            \"A\": np.array([[0.0, 1.0], [1.0, 0.0]]),\n            \"lambda_em\": np.array([5.0, 1.0]),\n        },\n        {\n            \"hist_0\": np.array([10, 9, 8, 7, 6, 5, 4, 3]),\n            \"hist_1\": np.array([1, 2, 3, 4, 5, 6, 7, 8]),\n            \"obs\": np.array([3, 2, 4, 3, 5, 2, 3, 4, 8, 7, 9, 6, 8, 7, 9, 2, 1, 3, 2, 2]),\n            \"pi\": np.array([0.5, 0.5]),\n            \"A\": np.array([[0.0, 1.0], [1.0, 0.0]]),\n            \"lambda_em\": np.array([3.0, 7.0]),\n        },\n    ]\n\n    D_max = 8\n    K = 2\n    results = []\n\n    for case in test_cases:\n        decoded_sequence = _solve_one_case(case, K, D_max)\n        results.append(decoded_sequence)\n\n    # Format output as specified\n    result_str = \",\".join(map(str, results))\n    print(f\"[{result_str}]\")\n\n\ndef _poisson_logpmf(k, lam):\n    \"\"\"\n    Computes the log of the Poisson PMF, handling lam=0.\n    \"\"\"\n    # handle lam=0 case to avoid log(0)\n    lam = np.maximum(lam, 1e-9)\n    return k * np.log(lam) - lam - gammaln(k + 1)\n\n\ndef _fit_and_select_duration_model(hist_counts, D_max):\n    \"\"\"\n    Fits Geometric and Shifted Poisson distributions to histogram data,\n    selects the best model using AIC, and returns the renormalized PMF.\n    \"\"\"\n    durations = np.arange(1, D_max + 1)\n    \n    # Ensure sums are not zero to avoid division by zero\n    total_counts = np.sum(hist_counts)\n    if total_counts == 0:\n        return np.ones(D_max) / D_max # Uniform if no data\n\n    weighted_sum_d = np.sum(durations * hist_counts)\n    \n    # --- Geometric Model ---\n    # MLE: p = 1 / E[d] = sum(N_d) / sum(d * N_d)\n    p_mle_geom = total_counts / weighted_sum_d if weighted_sum_d > 0 else 0\n    \n    log_likelihood_geom = 0\n    log_pmf_geom = np.full(D_max, -np.inf)\n    if 0  p_mle_geom  1: # p cannot be 1, would mean all durations are 1\n        # PMF: p(d) = (1-p)^(d-1) * p\n        log_pmf_geom = (durations - 1) * np.log(1 - p_mle_geom) + np.log(p_mle_geom)\n        log_likelihood_geom = np.sum(hist_counts * log_pmf_geom)\n    aic_geom = 2 * 1 - 2 * log_likelihood_geom\n\n    # --- Shifted Poisson Model ---\n    # MLE: lambda = E[d] - 1 = (sum(d*N_d)/sum(N_d)) - 1\n    lambda_mle_poisson = (weighted_sum_d / total_counts) - 1.0\n    \n    log_likelihood_poisson = 0\n    log_pmf_poisson = np.full(D_max, -np.inf)\n    if lambda_mle_poisson > 0:\n        # PMF: p(d) = exp(-lambda) * lambda^(d-1) / (d-1)!\n        log_pmf_poisson = -lambda_mle_poisson + (durations - 1) * np.log(lambda_mle_poisson) - gammaln(durations)\n        log_likelihood_poisson = np.sum(hist_counts * log_pmf_poisson)\n    aic_poisson = 2 * 1 - 2 * log_likelihood_poisson\n\n    # --- Model Selection and PMF generation ---\n    # Tie-break rule: choose geometric\n    if aic_poisson  aic_geom:\n        chosen_log_pmf = log_pmf_poisson\n    else:\n        chosen_log_pmf = log_pmf_geom\n\n    # Truncate and renormalize\n    pmf_unnormalized = np.exp(chosen_log_pmf)\n    norm_factor = np.sum(pmf_unnormalized)\n    \n    if norm_factor > 0:\n        final_pmf = pmf_unnormalized / norm_factor\n    else: # If all probabilities are numerically zero\n        final_pmf = np.ones(D_max) / D_max\n        \n    return final_pmf\n\ndef _solve_one_case(params, K, D_max):\n    \"\"\"\n    Solves a single test case for HSMM decoding.\n    \"\"\"\n    obs = params[\"obs\"]\n    T = len(obs)\n    pi = params[\"pi\"]\n    A = params[\"A\"]\n    lambda_em = params[\"lambda_em\"]\n    histograms = [params[\"hist_0\"], params[\"hist_1\"]]\n\n    # 1. Fit duration models for each state\n    log_P_duration = np.zeros((K, D_max))\n    for i in range(K):\n        pmf = _fit_and_select_duration_model(histograms[i], D_max)\n        with np.errstate(divide='ignore'):\n            log_P_duration[i, :] = np.log(pmf)\n\n    # 2. Precompute observation log-likelihoods\n    log_B = np.zeros((T, K))\n    for j in range(K):\n        log_B[:, j] = _poisson_logpmf(obs, lambda_em[j])\n    \n    log_B_cumsum = np.cumsum(log_B, axis=0)\n\n    def get_log_obs_likelihood(t_start, t_end, state):\n        # 0-based indexing for arrays\n        # sum from t_start to t_end inclusive\n        if t_start == 0:\n            return log_B_cumsum[t_end, state]\n        else:\n            return log_B_cumsum[t_end, state] - log_B_cumsum[t_start - 1, state]\n\n    # 3. HSMM Viterbi DP\n    # Using T+1 to align with time indices 1..T\n    log_delta = np.full((T + 1, K), -np.inf)\n    psi_duration = np.zeros((T + 1, K), dtype=int)\n    \n    # DP loop\n    for t in range(1, T + 1):\n        for j in range(K):\n            max_log_prob = -np.inf\n            best_d = -1\n\n            for d in range(1, min(t, D_max) + 1):\n                t_prev = t - d\n                \n                log_P_obs = get_log_obs_likelihood(t_prev, t-1, j)\n                log_prob_segment = log_P_duration[j, d-1] + log_P_obs\n                \n                log_prob_path = -np.inf\n                if t_prev == 0:\n                    with np.errstate(divide='ignore'):\n                        log_prob_path = np.log(pi[j]) + log_prob_segment\n                else:\n                    # Simplified for K=2 and A_ij=1 for i!=j\n                    i_prev = 1 - j\n                    with np.errstate(divide='ignore'):\n                        prev_path_prob = log_delta[t_prev, i_prev] + np.log(A[i_prev, j])\n                    log_prob_path = prev_path_prob + log_prob_segment\n                \n                if log_prob_path > max_log_prob:\n                    max_log_prob = log_prob_path\n                    best_d = d\n            \n            log_delta[t, j] = max_log_prob\n            psi_duration[t, j] = best_d\n\n    # 4. Backtracking\n    state_sequence = np.zeros(T, dtype=int)\n    \n    # Find best final state\n    current_t = T\n    current_j = np.argmax(log_delta[T, :])\n    \n    while current_t > 0:\n        d = psi_duration[current_t, current_j]\n        # Assign state for the segment\n        for i in range(current_t - d, current_t):\n            state_sequence[i] = current_j\n        \n        # Move to previous segment\n        current_t -= d\n        if current_t > 0:\n            current_j = 1 - current_j # Simplified for K=2\n\n    return state_sequence.tolist()\n\nif __name__ == '__main__':\n    solve()\n```"
        }
    ]
}