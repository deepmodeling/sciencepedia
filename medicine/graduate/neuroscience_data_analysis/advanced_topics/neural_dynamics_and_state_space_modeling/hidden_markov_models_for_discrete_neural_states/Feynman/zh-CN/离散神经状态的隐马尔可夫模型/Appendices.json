{
    "hands_on_practices": [
        {
            "introduction": "Viterbi 算法是隐马尔可夫模型 (HMM) 分析的基石，它使我们能够从观测数据中推断出最可能的隐藏神经状态序列。本初级练习将指导你以数值稳定的方式实现这一基本算法，并通过将推断出的状态持续时间与理论期望值进行比较，介绍一种基本的模型验证形式。",
            "id": "4168489",
            "problem": "您会获得一组定义隐马尔可夫模型（HMM）的参数，该模型用于描述离散的神经元状态和分箱后的脉冲计数序列。隐马尔可夫模型（HMM）包含一个离散的隐状态过程，该过程是一个具有初始分布和转移矩阵的一阶马尔可夫链，并与一个观测过程相耦合，观测过程的分布取决于当前的隐状态。在神经科学数据分析中，固定宽度分箱中聚合的脉冲计数通常使用以隐神经元状态为条件的泊松分布进行建模。目标是使用维特比算法，根据观测到的脉冲计数计算最可能的隐状态序列，然后将经验状态持续时间与马尔可夫性质所蕴含的持续时间进行评估。\n\n从核心定义开始：\n- 隐状态序列的状态来自有限集合 $\\{0,1,\\dots,S-1\\}$，其中 $S$ 表示状态的数量。\n- 初始状态分布由向量 $\\boldsymbol{\\pi}$ 表示，其条目为 $\\pi_i$，其中 $i \\in \\{0,1,\\dots,S-1\\}$，$\\pi_i$ 代表从状态 $i$ 开始的概率。\n- 状态转移概率由矩阵 $\\mathbf{A}$ 表示，其条目为 $a_{ij}$，定义为在一个时间步内从状态 $i$ 转换到状态 $j$ 的概率，其中 $i,j \\in \\{0,1,\\dots,S-1\\}$。\n- 时刻 $t$ 的观测值，记为 $o_t$，是脉冲计数，被建模为以状态 $z_t$ 为条件的泊松随机变量：$o_t \\sim \\mathrm{Poisson}(\\lambda_{z_t})$，其中 $\\lambda_i$ 是与状态 $i$ 相关联的泊松率参数。所有脉冲计数 $o_t$ 均为非负整数。\n\n根据HMM固有的马尔可夫性质和条件独立性假设，给定观测序列 $o_{0:T-1}$，最可能的隐状态序列 $z_{0:T-1}$ 可以通过动态规划（维特比算法）获得，该算法最大化了路径的联合对数概率。在离散时间马尔可夫链中，由于无记忆性，状态持续时间呈几何分布：在转换到不同状态之前，在状态 $i$ 中连续花费的时间步数 $D_i$ 服从支撑集为 $\\{1,2,3,\\dots\\}$ 的几何分布，其成功参数为 $q_i = 1 - a_{ii}$，这意味着期望持续时间为 $\\mathbb{E}[D_i] = \\frac{1}{q_i} = \\frac{1}{1 - a_{ii}}$。\n\n您的任务是实现一个程序，该程序：\n1. 对于每个给定的测试用例，使用给定的 $\\boldsymbol{\\pi}$、$\\mathbf{A}$ 和 $\\boldsymbol{\\lambda}$ 以及提供的观测序列 $o_{0:T-1}$ 计算维特比路径 $z_{0:T-1}$。使用对数概率以避免数值下溢。在候选前驱或状态出现平局的情况下，通过选择最小的状态索引来确定性地打破平局。\n2. 解析维特比路径以获得每个状态的经验游程长度：连续的相同状态段产生以时间步为单位测量的持续时间。对于每个状态 $i$，计算其游程长度的经验均值。如果某个状态 $i$ 未出现在维特比路径中，按照惯例将其经验平均持续时间定义为 $0$。\n3. 对于每个状态 $i$，使用 $\\mathbb{E}[D_i] = \\frac{1}{1 - a_{ii}}$ 计算期望平均持续时间。然后计算每个状态的经验均值与期望均值之间的绝对差。\n4. 将每个绝对差四舍五入到六位小数。\n5. 按规定将所有测试用例的结果汇总到单个输出中。\n\n所有量均为无量纲的计数和概率，因此不需要物理单位。未使用角度。最终输出必须是单行文本，表示一个由浮点数列表组成的列表，并在所有测试用例中保持一致。该行必须严格按照下文所述的格式。\n\n测试套件：\n- 测试用例 1：\n  - 状态数 $S = 3$。\n  - 初始分布 $\\boldsymbol{\\pi} = [\\,0.6,\\,0.3,\\,0.1\\,]$。\n  - 转移矩阵 $\\mathbf{A} = \\begin{bmatrix} 0.90  0.08  0.02 \\\\ 0.05  0.92  0.03 \\\\ 0.04  0.06  0.90 \\end{bmatrix}$。\n  - 泊松率 $\\boldsymbol{\\lambda} = [\\,2.0,\\,8.0,\\,15.0\\,]$。\n  - 观测序列 $o_{0:25} = [\\,2,\\,1,\\,3,\\,2,\\,2,\\,9,\\,8,\\,7,\\,10,\\,15,\\,14,\\,16,\\,17,\\,13,\\,12,\\,1,\\,2,\\,3,\\,8,\\,9,\\,8,\\,12,\\,18,\\,15,\\,14,\\,16\\,]$。\n- 测试用例 2：\n  - 状态数 $S = 3$。\n  - 初始分布 $\\boldsymbol{\\pi} = [\\,0.33,\\,0.33,\\,0.34\\,]$。\n  - 转移矩阵 $\\mathbf{A} = \\begin{bmatrix} 0.97  0.02  0.01 \\\\ 0.01  0.97  0.02 \\\\ 0.02  0.01  0.97 \\end{bmatrix}$。\n  - 泊松率 $\\boldsymbol{\\lambda} = [\\,3.0,\\,9.0,\\,14.0\\,]$。\n  - 观测序列 $o_{0:44} = [\\,14,\\,15,\\,13,\\,16,\\,14,\\,14,\\,15,\\,13,\\,17,\\,12,\\,14,\\,16,\\,15,\\,13,\\,14,\\,15,\\,16,\\,13,\\,15,\\,14,\\,9,\\,10,\\,8,\\,9,\\,10,\\,7,\\,9,\\,8,\\,9,\\,11,\\,9,\\,8,\\,10,\\,9,\\,9,\\,3,\\,2,\\,4,\\,3,\\,3,\\,2,\\,4,\\,3,\\,2,\\,3\\,]$。\n- 测试用例 3：\n  - 状态数 $S = 2$。\n  - 初始分布 $\\boldsymbol{\\pi} = [\\,0.5,\\,0.5\\,]$。\n  - 转移矩阵 $\\mathbf{A} = \\begin{bmatrix} 0.60  0.40 \\\\ 0.40  0.60 \\end{bmatrix}$。\n  - 泊松率 $\\boldsymbol{\\lambda} = [\\,5.0,\\,5.0\\,]$。\n  - 观测序列 $o_{0:11} = [\\,4,\\,6,\\,5,\\,7,\\,5,\\,5,\\,4,\\,6,\\,5,\\,5,\\,5,\\,6\\,]$。\n\n程序要求：\n- 在对数域中实现维特比算法以保证数值稳定性。\n- 从解码路径计算经验平均持续时间，并计算每个状态 $i$ 与 $\\frac{1}{1-a_{ii}}$ 的绝对差。\n- 将差异四舍五入到六位小数。\n- 确定性平局打破规则：当两个或多个前驱状态为同一当前状态和时间产生相等的分数时（在浮点数相等范围内），选择索引最小的前驱；类似地，如果两个状态在初始化或最终回溯比较中平局，则选择最小的索引。\n- 最终输出格式：您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表，每个元素是每个测试用例的逗号分隔的四舍五入浮点数的子列表。例如，输出必须看起来完全像 $\\texttt{[[0.123456,0.000001,2.500000],[0.100000,0.200000,0.300000],[3.141593,2.718282]]}$。\n\n您的程序必须是自包含的，并且不得从用户读取输入。它必须使用指定的运行时环境并产生确定性的输出。观测值是每个分箱的精确整数计数；不要推断除无量纲计数之外的任何物理单位。",
            "solution": "用户提供了一个需要应用隐马尔可夫模型（HMM）来分析模拟神经脉冲计数数据的问题。核心任务是使用维特比算法，根据观测序列确定最可能的隐神经元状态序列，然后将从此序列中得出的经验状态持续时间与其理论期望值进行比较。\n\n### 第1步：问题验证\n\n根据所需标准对问题陈述进行严格评估。\n\n**1. 提取已知条件：**\n问题为三个不同的测试用例提供了以下量和模型：\n- 一个有限的隐状态集合 $\\{0, 1, \\dots, S-1\\}$，其中 $S$ 是状态数。\n- 一个初始状态分布向量 $\\boldsymbol{\\pi}$，其中 $\\pi_i = P(z_0=i)$。\n- 一个状态转移概率矩阵 $\\mathbf{A}$，其中 $a_{ij} = P(z_t=j | z_{t-1}=i)$。\n- 一个观测模型，其中脉冲计数 $o_t$ 服从以隐状态 $z_t$ 为条件的泊松分布：$p(o_t | z_t=i) = \\mathrm{Poisson}(o_t; \\lambda_i)$。泊松率参数以向量 $\\boldsymbol{\\lambda}$ 的形式给出。\n- 一个观测序列 $o_{0:T-1}$，代表分箱后的脉冲计数。\n- 一个状态期望持续时间的公式：$\\mathbb{E}[D_i] = \\frac{1}{1-a_{ii}}$。\n- 一个确定性的平局打破规则：在概率相等的情况下选择最小的状态索引。\n- 为三个测试用例提供的具体参数集（$\\boldsymbol{\\pi}$、$\\mathbf{A}$、$\\boldsymbol{\\lambda}$）和观测序列。\n\n**2. 使用提取的已知条件进行验证：**\n- **科学基础：** 该问题牢固地植根于计算神经科学和统计建模的标准实践。使用带泊松观测的HMM是分析脉冲序列数据的公认方法。维特比算法是寻找最可能状态序列（维特比路径）的正确且标准的动态规划方法。离散时间马尔可夫链中状态期望持续时间的公式是概率论的基本结果。所有前提在科学上和数学上都是合理的。\n- **良构性：** 问题是良构的。为每个测试用例提供了所有必要的参数（$S, \\boldsymbol{\\pi}, \\mathbf{A}, \\boldsymbol{\\lambda}$）和数据（$o_{0:T-1}$）。目标明确定义：计算经验状态持续时间与期望状态持续时间之间的绝对差。明确的平局打破规则确保维特比算法产生唯一的输出路径，使得整个计算过程具有确定性和可复现性。\n- **客观性：** 问题以精确、客观的语言陈述。没有主观性陈述或含糊之处。任务纯粹是计算和分析性的。\n- **完整性和一致性：** 每个测试用例的输入是完整的。提供的概率分布（$\\boldsymbol{\\pi}$）和转移矩阵（$\\mathbf{A}$）是有效的（即，条目非负且行/元素之和为1）。泊松率（$\\boldsymbol{\\lambda}$）为正，观测值为非负整数，符合要求。内部没有矛盾。\n- **结论：** 问题陈述是有效的。它在科学上合理、良构、客观且自包含。\n\n### 第2步：算法和科学原理\n\n解决方案包括三个主要部分：解码隐状态，从解码路径计算经验统计数据，以及将这些数据与从模型参数派生的理论期望进行比较。\n\n**1. 用于路径解码的维特比算法：**\n目标是找到状态序列 $z^*_{0:T-1} = (z^*_0, z^*_1, \\dots, z^*_{T-1})$，以最大化联合概率 $P(z_{0:T-1}, o_{0:T-1})$。为防止长序列的数值下溢，我们使用对数概率。维特比算法使用动态规划高效地解决这个最大化问题。\n\n令 $\\delta_t(i)$ 为在给定截至时刻 $t$ 的观测值的情况下，任何以状态 $i$ 结尾的状态序列的最大对数概率。\n$$\n\\delta_t(i) = \\max_{z_{0:t-1}} \\log P(z_{0:t-1}, z_t=i, o_{0:t})\n$$\n算法按以下步骤进行：\n\n- **初始化 ($t=0$):**\n对于每个状态 $i \\in \\{0, \\dots, S-1\\}$，初始对数概率是初始对数概率与第一个观测值 $o_0$ 的对数发射概率之和。\n$$\n\\delta_0(i) = \\log \\pi_i + \\log p(o_0 | z_0=i)\n$$\n泊松发射的对数概率为 $\\log p(o_t | z_t=i) = o_t \\log \\lambda_i - \\lambda_i - \\log(o_t!)$。在给定的时间 $t$，项 $\\log(o_t!)$ 对所有状态 $i$ 都是常数，可以在最大化步骤中省略，因为它不影响任何比较的结果。\n\n- **递归 ($t=1, \\dots, T-1$):**\n对于每个状态 $j \\in \\{0, \\dots, S-1\\}$，我们通过考虑时刻 $t-1$ 的所有可能的前驱状态 $i$ 来找到通向它的最可能路径。\n$$\n\\delta_t(j) = \\left( \\max_{i \\in \\{0, \\dots, S-1\\}} (\\delta_{t-1}(i) + \\log a_{ij}) \\right) + \\log p(o_t | z_t=j)\n$$\n一个回溯指针表 $\\psi_t(j)$ 存储为每个 $j$ 实现此最大值的前驱状态 $i$。\n$$\n\\psi_t(j) = \\arg\\max_{i \\in \\{0, \\dots, S-1\\}} (\\delta_{t-1}(i) + \\log a_{ij})\n$$\n此处应用指定的平局打破规则（最小索引）。\n\n- **终止和路径回溯：**\n通过在所有状态 $i$ 上最大化 $\\delta_{T-1}(i)$ 来找到最可能的最终状态。\n$$\nz^*_{T-1} = \\arg\\max_{i \\in \\{0, \\dots, S-1\\}} \\delta_{T-1}(i)\n$$\n路径的其余部分通过使用存储的指针从 $t=T-2$ 回溯到 $0$ 来恢复：\n$$\nz^*_t = \\psi_{t+1}(z^*_{t+1})\n$$\n\n**2. 经验与理论状态持续时间：**\n- **经验持续时间：** 获得维特比路径 $z^*_{0:T-1}$ 后，我们对其进行解析，以识别连续的相同状态段。对于每个状态 $i$，我们收集所有此类段的长度（游程长度）。状态 $i$ 的经验平均持续时间是这些游程长度的算术平均值。如果一个状态未出现在路径中，其经验平均持续时间定义为 $0$。\n\n- **理论持续时间：** 隐状态过程是一个离散时间马尔可夫链。马尔可夫链的无记忆性质意味着在任何状态 $i$ 的停留持续时间（即，在转换出去之前在 $i$ 中连续花费的时间步数）服从几何分布。自转换概率为 $a_{ii}$，因此离开该状态的概率为 $q_i = 1 - a_{ii}$。直到这个“离开”事件发生的期望步数，包括第一步，由以下公式给出：\n$$\n\\mathbb{E}[D_i] = \\frac{1}{q_i} = \\frac{1}{1 - a_{ii}}\n$$\n\n**3. 最终计算：**\n对于每个状态 $i \\in \\{0, \\dots, S-1\\}$，我们计算经验平均持续时间与理论期望持续时间之间的绝对差。然后按要求将此差值四舍五入到六位小数。一个测试用例中所有状态的结果形成一个列表，所有测试用例的列表被聚合成一个最终的列表的列表。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef viterbi(obs, S, pi, A, lmbdas):\n    \"\"\"\n    Computes the most probable latent state sequence using the Viterbi algorithm.\n    This implementation operates in the log domain for numerical stability and adheres\n    to the problem's tie-breaking rule (smallest index).\n\n    Args:\n        obs (np.array): Sequence of observations.\n        S (int): Number of states.\n        pi (np.array): Initial state distribution.\n        A (np.array): State transition matrix.\n        lmbdas (np.array): Poisson rate parameters for each state.\n\n    Returns:\n        np.array: The most probable sequence of latent states (Viterbi path).\n    \"\"\"\n    T = len(obs)\n    delta = np.zeros((T, S))\n    psi = np.zeros((T, S), dtype=int)\n\n    with np.errstate(divide='ignore'):\n        log_pi = np.log(pi)\n        log_A = np.log(A)\n        log_lmbdas = np.log(lmbdas)\n\n    # Initialization (t=0)\n    for i in range(S):\n        # Poisson log-probability without the constant log(o_t!) term\n        log_p_emission = obs[0] * log_lmbdas[i] - lmbdas[i]\n        delta[0, i] = log_pi[i] + log_p_emission\n\n    # Recursion (t=1 to T-1)\n    for t in range(1, T):\n        for j in range(S):\n            # Log-probabilities of paths ending in state j at time t\n            trans_log_probs = delta[t-1, :] + log_A[:, j]\n            \n            # The smallest-index tie-breaking rule is naturally handled by np.argmax\n            argmax_state = np.argmax(trans_log_probs)\n            max_log_prob = trans_log_probs[argmax_state]\n            \n            log_p_emission = obs[t] * log_lmbdas[j] - lmbdas[j]\n            \n            delta[t, j] = max_log_prob + log_p_emission\n            psi[t, j] = argmax_state\n\n    # Path backtracking\n    path = np.zeros(T, dtype=int)\n    # Tie-breaking for the final state is also handled by np.argmax\n    path[T-1] = np.argmax(delta[T-1, :])\n    \n    for t in range(T-2, -1, -1):\n        path[t] = psi[t+1, path[t+1]]\n        \n    return path\n\ndef get_run_lengths(path, S):\n    \"\"\"\n    Parses a sequence to find contiguous runs of each state and groups them.\n\n    Args:\n        path (np.array): A sequence of states.\n        S (int): The total number of possible states.\n\n    Returns:\n        dict: A dictionary mapping each state index to a list of its run-lengths.\n    \"\"\"\n    run_lengths = {i: [] for i in range(S)}\n    if len(path) == 0:\n        return run_lengths\n\n    current_state = path[0]\n    current_length = 1\n    for i in range(1, len(path)):\n        if path[i] == current_state:\n            current_length += 1\n        else:\n            run_lengths[current_state].append(current_length)\n            current_state = path[i]\n            current_length = 1\n    \n    # Append the last run\n    run_lengths[current_state].append(current_length)\n    return run_lengths\n\ndef solve():\n    \"\"\"\n    Main function to run all test cases and produce the final output.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        {\n            \"S\": 3,\n            \"pi\": [0.6, 0.3, 0.1],\n            \"A\": [[0.90, 0.08, 0.02], [0.05, 0.92, 0.03], [0.04, 0.06, 0.90]],\n            \"lmbdas\": [2.0, 8.0, 15.0],\n            \"obs\": [2, 1, 3, 2, 2, 9, 8, 7, 10, 15, 14, 16, 17, 13, 12, 1, 2, 3, 8, 9, 8, 12, 18, 15, 14, 16],\n        },\n        {\n            \"S\": 3,\n            \"pi\": [0.33, 0.33, 0.34],\n            \"A\": [[0.97, 0.02, 0.01], [0.01, 0.97, 0.02], [0.02, 0.01, 0.97]],\n            \"lmbdas\": [3.0, 9.0, 14.0],\n            \"obs\": [14, 15, 13, 16, 14, 14, 15, 13, 17, 12, 14, 16, 15, 13, 14, 15, 16, 13, 15, 14, 9, 10, 8, 9, 10, 7, 9, 8, 9, 11, 9, 8, 10, 9, 9, 3, 2, 4, 3, 3, 2, 4, 3, 2, 3],\n        },\n        {\n            \"S\": 2,\n            \"pi\": [0.5, 0.5],\n            \"A\": [[0.60, 0.40], [0.40, 0.60]],\n            \"lmbdas\": [5.0, 5.0],\n            \"obs\": [4, 6, 5, 7, 5, 5, 4, 6, 5, 5, 5, 6],\n        },\n    ]\n\n    all_case_results = []\n    for case in test_cases:\n        S = case[\"S\"]\n        pi = np.array(case[\"pi\"])\n        A = np.array(case[\"A\"])\n        lmbdas = np.array(case[\"lmbdas\"])\n        obs = np.array(case[\"obs\"])\n\n        viterbi_path = viterbi(obs, S, pi, A, lmbdas)\n        \n        # Calculate empirical mean durations\n        run_lengths = get_run_lengths(viterbi_path, S)\n        empirical_means = np.zeros(S)\n        for i in range(S):\n            if run_lengths[i]:\n                empirical_means[i] = np.mean(run_lengths[i])\n            else:\n                # Per problem spec, mean duration is 0 if state does not appear\n                empirical_means[i] = 0.0\n\n        # Calculate expected mean durations from the Markov property\n        expected_means = 1.0 / (1.0 - np.diag(A))\n\n        # Compute absolute differences and round to six decimal places\n        abs_diffs = np.abs(empirical_means - expected_means)\n        rounded_diffs = [round(d, 6) for d in abs_diffs]\n        \n        all_case_results.append(rounded_diffs)\n    \n    # Format the final output string as a list of lists with no spaces\n    sublist_strings = [f\"[{','.join(map(str, res))}]\" for res in all_case_results]\n    final_output = f\"[{','.join(sublist_strings)}]\"\n    print(final_output)\n\nsolve()\n```"
        },
        {
            "introduction": "标准的 HMM 假设所有状态之间的转换都是可能的，但现实世界中的神经过程通常遵循结构化规则，例如学习任务中的顺序阶段。本练习将演示如何通过实现“从左到右”的 HMM 来融合此类先验知识，其中状态按有序方式进行。你将学习如何修改 Viterbi 算法以强制执行这些约束，这是构建更具生物学合理性的模型的关键技能。",
            "id": "4168504",
            "problem": "给定一个应用于任务结构化神经数据的离散隐马尔可夫模型 (HMM)，其中隐藏的神经状态代表潜在的任务阶段，观测值为离散化的神经特征（例如，分箱的脉冲计数类别）。一个隐马尔可夫模型 (HMM) 由一个隐藏状态过程 $\\{z_t\\}_{t=0}^{T-1}$（其中 $z_t \\in \\{0,1,\\dots,N-1\\}$）和一个观测过程 $\\{O_t\\}_{t=0}^{T-1}$（其中 $O_t \\in \\{0,1,\\dots,M-1\\}$）组成。该 HMM 由一个初始状态分布 $\\boldsymbol{\\pi}$、一个状态转移矩阵 $\\mathbf{A}$ 和一个发射概率矩阵 $\\mathbf{B}$ 指定。其基本基础是马尔可夫性质（条件独立的转移）、在给定当前状态下发射的独立性，以及概率的乘法法则。你必须引入一个适用于任务结构化神经序列的从左到右的拓扑约束：在每个时间步，只允许从状态 $i$ 转移到状态 $j$（如果 $j \\in \\{i, i+1\\}$），而最后一个状态 $N-1$ 只允许自转移。目标是在此约束下，在对数域中推导并实现维特比动态规划算法，以计算最可能的状态路径。\n\n定义：\n- 初始分布为 $\\boldsymbol{\\pi} = (\\pi_0, \\pi_1, \\dots, \\pi_{N-1})$，其中 $\\pi_i = \\mathbb{P}(z_0 = i)$。\n- 转移矩阵为 $\\mathbf{A}$，其元素为 $A_{ij} = \\mathbb{P}(z_t = j \\mid z_{t-1} = i)$。\n- 发射矩阵为 $\\mathbf{B}$，其元素为 $B_{j,k} = \\mathbb{P}(O_t = k \\mid z_t = j)$。\n- 观测序列为 $(O_0, O_1, \\dots, O_{T-1})$。\n- 在数学和代码中，对状态和观测符号都使用从0开始的索引。\n\n要求：\n1. 使用概率乘法法则和马尔可夫性质，从基本原理推导出受约束的维特比递归，并在对数域中实现它。使用 $-\\infty$ 表示 $\\log(0)$。\n2. 通过将在时间 $t$ 状态 $j$ 的前驱状态限制在集合 $\\{j-1, j\\}$（对于 $j=0$，则为 $\\{0\\}$）来强制执行从左到右的约束。所有不允许的转移都必须从最大化过程中排除。\n3. 实现一个确定性的平局打破规则：每当 $\\arg\\max$ 不唯一时，选择最大化器中最小的状态索引（这将产生字典序最小的最可能路径）。\n4. 对于每个测试用例，返回最可能的状态路径，形式为使用从0开始的状态索引的整数列表。\n\n测试套件：\n实现你的程序来处理以下四个参数集。所有概率都是实数、有效的，并根据定义进行了归一化。\n\n- 测试用例 1 (理想情况，三个状态，四个符号)：\n    - $N = 3$, $M = 4$, $T = 6$。\n    - $\\boldsymbol{\\pi} = [\\, $0.9$, $0.1$, $0.0$ \\,]$。\n    - $\\mathbf{A} =$ \n      $\\begin{bmatrix}\n      $0.7$  $0.3$  $0.0$ \\\\\n      $0.0$  $0.6$  $0.4$ \\\\\n      $0.0$  $0.0$  $1.0$\n      \\end{bmatrix}$。\n    - $\\mathbf{B} =$ \n      $\\begin{bmatrix}\n      $0.6$  $0.3$  $0.05$  $0.05$ \\\\\n      $0.1$  $0.6$  $0.2$  $0.1$ \\\\\n      $0.05$  $0.15$  $0.7$  $0.1$\n      \\end{bmatrix}$。\n    - 观测值: $(\\, $0$, $1$, $1$, $2$, $2$, $3$ \\,)$。\n\n- 测试用例 2 (边界处理，包含近零发射概率和吸收性的最终状态)：\n    - $N = 4$, $M = 3$, $T = 5$。\n    - $\\boldsymbol{\\pi} = [\\, $1.0$, $0.0$, $0.0$, $0.0$ \\,]$。\n    - $\\mathbf{A} =$ \n      $\\begin{bmatrix}\n      $0.5$  $0.5$  $0.0$  $0.0$ \\\\\n      $0.0$  $0.5$  $0.5$  $0.0$ \\\\\n      $0.0$  $0.0$  $0.5$  $0.5$ \\\\\n      $0.0$  $0.0$  $0.0$  $1.0$\n      \\end{bmatrix}$。\n    - $\\mathbf{B} =$ \n      $\\begin{bmatrix}\n      $0.9$  $0.1$  $1\\times 10^{-12}$ \\\\\n      $0.1$  $0.8$  $0.1$ \\\\\n      $1\\times 10^{-12}$  $0.2$  $0.8$ \\\\\n      $0.05$  $0.05$  $0.9$\n      \\end{bmatrix}$。\n    - 观测值: $(\\, $0$, $1$, $2$, $2$, $2$ \\,)$。\n\n- 测试用例 3 (边界情况，存在平局；两个状态，两个符号；强制执行字典序平局打破规则)：\n    - $N = 2$, $M = 2$, $T = 3$。\n    - $\\boldsymbol{\\pi} = [\\, $0.5$, $0.5$ \\,]$。\n    - $\\mathbf{A} =$ \n      $\\begin{bmatrix}\n      $0.5$  $0.5$ \\\\\n      $0.0$  $1.0$\n      \\end{bmatrix}$。\n    - $\\mathbf{B} =$ \n      $\\begin{bmatrix}\n      $0.6$  $0.4$ \\\\\n      $0.6$  $0.4$\n      \\end{bmatrix}$。\n    - 观测值: $(\\, $0$, $0$, $1$ \\,)$。\n\n- 测试用例 4 (与任务阶段一致的不可逆进展；最终状态为吸收态)：\n    - $N = 3$, $M = 3$, $T = 8$。\n    - $\\boldsymbol{\\pi} = [\\, $0.2$, $0.8$, $0.0$ \\,]$。\n    - $\\mathbf{A} =$ \n      $\\begin{bmatrix}\n      $0.4$  $0.6$  $0.0$ \\\\\n      $0.0$  $0.7$  $0.3$ \\\\\n      $0.0$  $0.0$  $1.0$\n      \\end{bmatrix}$。\n    - $\\mathbf{B} =$ \n      $\\begin{bmatrix}\n      $0.7$  $0.2$  $0.1$ \\\\\n      $0.1$  $0.7$  $0.2$ \\\\\n      $0.05$  $0.25$  $0.7$\n      \\end{bmatrix}$。\n    - 观测值: $(\\, $1$, $1$, $2$, $2$, $2$, $2$, $0$, $0$ \\,)$。\n\n你的程序必须生成单行输出，其中包含一个用方括号括起来的逗号分隔列表。每个元素对应一个测试用例，本身是一个给出最可能状态路径的整数列表，例如，$[\\,[0,1,2],[1,1,2]\\,]$，最终输出中没有空格。四个测试用例的输出必须遵循这种确切格式：单行形式如 $[\\,[\\dots],[\\dots],[\\dots],[\\dots]\\,]$，全程使用从0开始的索引。不涉及物理单位、角度或百分比。程序必须是完全自包含的，并且不得读取任何输入。",
            "solution": "该问题要求推导并实现一个受约束的维特比算法，为一个具有特定从左到右拓扑结构的隐马尔可夫模型 (HMM) 寻找最可能的隐藏状态序列。该算法必须在对数域中实现，以保持数值稳定性。\n\n### 第 1 步：问题验证\n\n**1.1. 提取已知条件**\n\n- **模型：** 离散隐马尔可夫模型 (HMM)。\n- **隐藏状态：** $z_t \\in \\{0, 1, \\dots, N-1\\}$，其中 $t \\in \\{0, \\dots, T-1\\}$。\n- **观测值：** $O_t \\in \\{0, 1, \\dots, M-1\\}$，其中 $t \\in \\{0, \\dots, T-1\\}$。\n- **参数：**\n    - 初始状态分布：$\\boldsymbol{\\pi} = (\\pi_i)$，其中 $\\pi_i = \\mathbb{P}(z_0 = i)$。\n    - 状态转移矩阵：$\\mathbf{A} = (A_{ij})$，其中 $A_{ij} = \\mathbb{P}(z_t = j \\mid z_{t-1} = i)$。\n    - 发射概率矩阵：$\\mathbf{B} = (B_{j,k})$，其中 $B_{j,k} = \\mathbb{P}(O_t = k \\mid z_t = j)$。\n- **观测序列：** 给定序列 $(O_0, O_1, \\dots, O_{T-1})$。\n- **拓扑约束：** 从状态 $i$ 到状态 $j$ 的转移仅在 $j \\in \\{i, i+1\\}$ 时被允许。最后一个状态 $N-1$ 只能转移到自身。这意味着对于状态 $j$，唯一可能的前驱状态是 $\\{j-1, j\\}$ (对于状态 $j=0$ 则仅为 $\\{0\\}$)。\n- **实现要求：**\n    - 所有计算使用对数域。$\\log(0)$ 由 $-\\infty$ 表示。\n    - 实现一个确定性的平局打破规则：当 $\\arg\\max$ 不唯一时，选择最小的状态索引。\n- **输出：** 最可能的状态路径 $(z_0^*, z_1^*, \\dots, z_{T-1}^*)$，形式为使用从0开始索引的整数列表。\n- **测试用例：** 提供了四组特定的参数 ($\\boldsymbol{\\pi}$, $\\mathbf{A}$, $\\mathbf{B}$) 和观测序列。\n\n**1.2. 使用提取的已知条件进行验证**\n\n- **科学性：** 该问题是 HMM 的一个标准应用，HMM 是许多 STEM 领域统计建模的基石，包括用于分析神经状态动力学的神经科学。维特比算法是解码最可能隐藏状态序列的经典方法。从左到右的拓扑结构是为模拟按序进行的过程（如任务结构化的神经活动）而设置的一个常见且有意義的约束。所有定义和原理都基于标准概率论，并且在数学上是合理的。\n- **适定性：** 该问题是适定的。给定一套完整的 HMM 参数和一个观测序列，维特比算法保证了最可能路径的存在。指定的平局打破规则确保了该路径的唯一性。问题是自包含的，并为每个测试用例提供了所有必要的数据。\n- **客观性：** 该问题以精确、客观的数学语言陈述。定义是形式化的。要求是明确的。\n\n**1.3. 结论与行动**\n\n问题陈述是有效的。它具有科学性、适定性、客观性和完整性。我将继续推导并实现解决方案。\n\n### 第 2 步：受约束维特بي算法的推导\n\n目标是找到状态序列 $z = (z_0, z_1, \\dots, z_{T-1})$，使得条件概率 $\\mathbb{P}(z \\mid O)$ 最大化，其中 $O = (O_0, O_1, \\dots, O_{T-1})$ 是观测序列。根据贝叶斯定理，$\\mathbb{P}(z \\mid O) = \\frac{\\mathbb{P}(z, O)}{\\mathbb{P}(O)}$。由于对于给定的观测序列，$\\mathbb{P}(O)$ 是一个常数，因此最大化 $\\mathbb{P}(z \\mid O)$ 等价于最大化联合概率 $\\mathbb{P}(z, O)$。\n\nHMM 的基本假设（转移的马尔可夫性质和发射的状态条件独立性）使我们能够将联合概率表示为：\n$$\n\\mathbb{P}(z, O) = \\mathbb{P}(z_0) \\mathbb{P}(O_0 \\mid z_0) \\prod_{t=1}^{T-1} \\mathbb{P}(z_t \\mid z_{t-1}) \\mathbb{P}(O_t \\mid z_t)\n$$\n使用提供的 HMM 参数，这变为：\n$$\n\\mathbb{P}(z, O) = \\pi_{z_0} B_{z_0, O_0} \\prod_{t=1}^{T-1} A_{z_{t-1}, z_t} B_{z_t, O_t}\n$$\n维特比算法使用动态规划来找到最大化序列 $z^*$。令 $\\delta_t(j)$ 为在时间 $t$ 结束于状态 $j$，并已生成前 $t+1$ 个观测值 $O_0, \\dots, O_t$ 的所有长度为 $t+1$ 的状态序列的最大概率：\n$$\n\\delta_t(j) = \\max_{z_0, \\dots, z_{t-1}} \\mathbb{P}(z_0, \\dots, z_{t-1}, z_t=j, O_0, \\dots, O_t)\n$$\n为了重构路径，我们还定义一个回溯指针变量 $\\psi_t(j)$，它存储了在时间 $t$ 结束于状态 $j$ 的路径的最可能的前驱状态。\n\n**初始化 ($t=0$)：**\n开始于状态 $j$ 并观测到 $O_0$ 的概率是：\n$$\n\\delta_0(j) = \\pi_j B_{j, O_0}\n$$\n**递归 ($1 \\le t  T$)：**\n我们可以根据时间 $t-1$ 的值来定义 $\\delta_t(j)$：\n$$\n\\delta_t(j) = \\max_{i=0,\\dots,N-1} \\left[ \\delta_{t-1}(i) \\cdot A_{ij} \\right] \\cdot B_{j, O_t}\n$$\n回溯指针是实现这个最大值的状态 $i$：\n$$\n\\psi_t(j) = \\arg\\max_{i=0,\\dots,N-1} \\left[ \\delta_{t-1}(i) \\cdot A_{ij} \\right]\n$$\n**对数域公式：**\n为了防止长序列的数值下溢，我们在对数概率上进行计算。令 $v_t(j) = \\log \\delta_t(j)$。乘积最大化问题变为求和最大化问题：\n$$\nv_t(j) = \\max_{i} \\left[ v_{t-1}(i) + \\log A_{ij} \\right] + \\log B_{j, O_t}\n$$\n在对数域中的回溯指针是：\n$$\n\\psi_t(j) = \\arg\\max_{i} \\left[ v_{t-1}(i) + \\log A_{ij} \\right]\n$$\n初始化变为：\n$$\nv_0(j) = \\log \\pi_j + \\log B_{j, O_0}\n$$\n其中概率为 $0$ 的情况变为 $\\log(0) = -\\infty$。\n\n**应用从左到右的约束：**\n问题指定从状态 $i$ 的转移只允许到状态 $j \\in \\{i, i+1\\}$。这意味着在时间 $t$ 状态 $j$ 的唯一可能的前驱状态是在时间 $t-1$ 的状态 $j$ 和 $j-1$。这极大地简化了最大化过程。\n\n- 对于状态 $j=0$，唯一的前驱状态是状态 0。\n  $$\n  v_t(0) = \\left( v_{t-1}(0) + \\log A_{00} \\right) + \\log B_{0, O_t}\n  $$\n  $$\n  \\psi_t(0) = 0\n  $$\n- 对于状态 $j \\in \\{1, \\dots, N-1\\}$，前驱状态可以是 $j-1$ 或 $j$。\n  $$\n  v_t(j) = \\max \\left( v_{t-1}(j-1) + \\log A_{j-1, j}, v_{t-1}(j) + \\log A_{jj} \\right) + \\log B_{j, O_t}\n  $$\n  回溯指针 $\\psi_t(j)$ 是产生最大值的状态索引（$j-1$ 或 $j$）。指定的平局打破规则要求在出现平局时选择较小的索引。\n  $$\n  \\psi_t(j) = \\begin{cases} j-1  \\text{if } v_{t-1}(j-1) + \\log A_{j-1, j} \\ge v_{t-1}(j) + \\log A_{jj} \\\\ j  \\text{otherwise} \\end{cases}\n  $$\n\n**终止和路径回溯：**\n在填充动态规划表直到时间 $T-1$ 后：\n1.  找到最可能的最终状态 $z_{T-1}^*$：\n    $$\n    z_{T-1}^* = \\arg\\max_{j=0,\\dots,N-1} v_{T-1,j}\n    $$\n    同样，平局打破规则意味着在出现平局时选择最小的索引 $j$。\n2.  回溯以找到路径的其余部分：\n    $$\n    z_{t-1}^* = \\psi_t(z_t^*) \\quad \\text{for } t = T-1, T-2, \\dots, 1\n    $$\n序列 $(z_0^*, z_1^*, \\dots, z_{T-1}^*)$ 是最可能的状态路径。\n\n### 算法总结\n\n1.  **预处理：** 将参数 $\\boldsymbol{\\pi}$、$\\mathbf{A}$、$\\mathbf{B}$ 转换为对数域，正确处理零（例如，使用 `numpy.log`）。\n2.  **初始化 ($t=0$)：**\n    - 创建一个 $T \\times N$ 的对数概率表 $v$ 和一个 $T \\times N$ 的回溯指针表 $\\psi$。\n    - 对于每个状态 $j=0, \\dots, N-1$，计算 $v_{0,j} = \\log\\pi_j + \\log B_{j, O_0}$。\n3.  **递归 ($t=1, \\dots, T-1$)：**\n    - 对于 $j=0$：设置 $v_{t,0} = v_{t-1,0} + \\log A_{00} + \\log B_{0, O_t}$ 和 $\\psi_{t,0} = 0$。\n    - 对于 $j=1, \\dots, N-1$：\n        - 计算来自前驱状态的路径概率：\n          - $p_{j-1} = v_{t-1, j-1} + \\log A_{j-1, j}$\n          - $p_j = v_{t-1, j} + \\log A_{jj}$\n        - 如果 $p_{j-1} \\ge p_j$，则将最大概率设为 $p_{j-1}$ 并设置 $\\psi_{t,j} = j-1$。\n        - 否则，将最大概率设为 $p_j$ 并设置 $\\psi_{t,j} = j$。\n        - 设置 $v_{t,j} = (\\text{最大概率}) + \\log B_{j, O_t}$。\n4.  **终止：** 找到最终状态 $z_{T-1}^* = \\arg\\max_j v_{T-1,j}$。\n5.  **回溯：**\n    - 初始化长度为 $T$ 的路径 `path`。设置 `path[T-1] = z_{T-1}^*`。\n    - 对于 $t=T-2, \\dots, 0$：`path[t] = \\psi_{t+1, path[t+1]}`。\n6.  **返回：** 计算出的路径。\n\n将实施此结构化过程以解决给定的测试用例。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the Viterbi decoding problem for four different HMM test cases.\n    \"\"\"\n    \n    test_cases = [\n        # Test Case 1\n        {\n            \"N\": 3, \"M\": 4, \"T\": 6,\n            \"pi\": np.array([0.9, 0.1, 0.0]),\n            \"A\": np.array([\n                [0.7, 0.3, 0.0],\n                [0.0, 0.6, 0.4],\n                [0.0, 0.0, 1.0]\n            ]),\n            \"B\": np.array([\n                [0.6, 0.3, 0.05, 0.05],\n                [0.1, 0.6, 0.2, 0.1],\n                [0.05, 0.15, 0.7, 0.1]\n            ]),\n            \"O\": np.array([0, 1, 1, 2, 2, 3])\n        },\n        # Test Case 2\n        {\n            \"N\": 4, \"M\": 3, \"T\": 5,\n            \"pi\": np.array([1.0, 0.0, 0.0, 0.0]),\n            \"A\": np.array([\n                [0.5, 0.5, 0.0, 0.0],\n                [0.0, 0.5, 0.5, 0.0],\n                [0.0, 0.0, 0.5, 0.5],\n                [0.0, 0.0, 0.0, 1.0]\n            ]),\n            \"B\": np.array([\n                [0.9, 0.1, 1e-12],\n                [0.1, 0.8, 0.1],\n                [1e-12, 0.2, 0.8],\n                [0.05, 0.05, 0.9]\n            ]),\n            \"O\": np.array([0, 1, 2, 2, 2])\n        },\n        # Test Case 3\n        {\n            \"N\": 2, \"M\": 2, \"T\": 3,\n            \"pi\": np.array([0.5, 0.5]),\n            \"A\": np.array([\n                [0.5, 0.5],\n                [0.0, 1.0]\n            ]),\n            \"B\": np.array([\n                [0.6, 0.4],\n                [0.6, 0.4]\n            ]),\n            \"O\": np.array([0, 0, 1])\n        },\n        # Test Case 4\n        {\n            \"N\": 3, \"M\": 3, \"T\": 8,\n            \"pi\": np.array([0.2, 0.8, 0.0]),\n            \"A\": np.array([\n                [0.4, 0.6, 0.0],\n                [0.0, 0.7, 0.3],\n                [0.0, 0.0, 1.0]\n            ]),\n            \"B\": np.array([\n                [0.7, 0.2, 0.1],\n                [0.1, 0.7, 0.2],\n                [0.05, 0.25, 0.7]\n            ]),\n            \"O\": np.array([1, 1, 2, 2, 2, 2, 0, 0])\n        }\n    ]\n\n    results = []\n    for params in test_cases:\n        path = constrained_viterbi(params)\n        results.append(path)\n\n    # Format the final output string exactly as required.\n    # e.g., [[0,1,2],[1,1,2]]\n    formatted_results = [f\"[{','.join(map(str, p))}]\" for p in results]\n    print(f\"[{','.join(formatted_results)}]\")\n\ndef constrained_viterbi(params):\n    \"\"\"\n    Implements the constrained Viterbi algorithm in the log domain.\n    \"\"\"\n    N = params[\"N\"]  # Number of states\n    T = params[\"T\"]  # Length of observation sequence\n    \n    # Use np.log which correctly handles log(0) = -inf\n    with np.errstate(divide='ignore'):\n        log_pi = np.log(params[\"pi\"])\n        log_A = np.log(params[\"A\"])\n        log_B = np.log(params[\"B\"])\n\n    O = params[\"O\"]\n\n    # Dynamic programming tables\n    # v_table stores the log probabilities (delta in standard literature)\n    v_table = np.full((T, N), -np.inf)\n    # psi_table stores backpointers to reconstruct the path\n    psi_table = np.zeros((T, N), dtype=int)\n\n    # Initialization step (t=0)\n    obs_0 = O[0]\n    for j in range(N):\n        v_table[0, j] = log_pi[j] + log_B[j, obs_0]\n\n    # Recursion step (t=1 to T-1)\n    for t in range(1, T):\n        obs_t = O[t]\n        \n        # State j=0 can only be reached from state 0\n        v_table[t, 0] = v_table[t-1, 0] + log_A[0, 0] + log_B[0, obs_t]\n        psi_table[t, 0] = 0\n\n        # States j=1 to N-1\n        for j in range(1, N):\n            # Probability of path from predecessor j-1\n            prob_from_j_minus_1 = v_table[t-1, j-1] + log_A[j-1, j]\n            # Probability of path from predecessor j\n            prob_from_j = v_table[t-1, j] + log_A[j, j]\n\n            # Tie-breaking rule: choose smallest state index (j-1)\n            if prob_from_j_minus_1 = prob_from_j:\n                max_prob = prob_from_j_minus_1\n                psi_table[t, j] = j-1\n            else:\n                max_prob = prob_from_j\n                psi_table[t, j] = j\n            \n            v_table[t, j] = max_prob + log_B[j, obs_t]\n\n    # Termination and Path Backtracking\n    path = np.zeros(T, dtype=int)\n    \n    # Find the most likely final state\n    # np.argmax breaks ties by choosing the first occurrence (smallest index)\n    path[T-1] = np.argmax(v_table[T-1, :])\n\n    # Backtrack to find the full path\n    for t in range(T-2, -1, -1):\n        path[t] = psi_table[t+1, path[t+1]]\n\n    return path.tolist()\n\nsolve()\n```"
        },
        {
            "introduction": "标准 HMM 的一个关键限制是其隐含的假设，即状态持续时间服从几何分布，而真实神经状态的持续时间通常并非如此。本高级练习将介绍隐半马尔可夫模型 (HSMM)，它通过显式地为状态持续时间建模来克服这一限制。你将学习如何将持续时间分布与经验数据进行拟合，并实现一种更复杂的动态规划算法进行解码，这代表了向更真实的神经状态建模迈出的重要一步。",
            "id": "4168478",
            "problem": "给定离散神经状态的经验驻留时间直方图，以及从某个神经元群体以固定时间步长记录的尖峰计数观测值。建模任务是构建一个隐半马尔可夫模型（HSMM），它是隐马尔可夫模型（HMM）的一种扩展，显式地对状态持续时间进行建模，并解码随时间变化的最可能的离散神经状态序列。目标是使设计基于概率建模、基于似然的参数估计以及用于状态推断的动态规划等基本定义。\n\n您必须从基本原则出发，按以下步骤进行：\n- 定义一个隐马尔可夫模型（HMM），其具有离散状态，并根据特定于状态的分布发射观测值，然后通过为每个状态指定一个显式的持续时间分布，将其扩展为隐半马尔可夫模型（HSMM）。隐半马尔可夫模型（HSMM）将持续时间分布与转移机制分离，并且不依赖自转换来编码持续性。\n- 通过最大化每个候选族下直方图计数的似然，将参数化持续时间分布拟合到每个状态的经验驻留时间直方图，然后使用信息准则选择一个分布族。您必须仅使用经验直方图计数和参数形式执行最大似然估计（MLE），而不能依赖任何提供给您的预先推导的快捷公式。\n- 使用动态规划算法实现精确持续时间解码，该算法计算能够精确覆盖观测序列、并遵循显式持续时间分布的最可能的分割和状态序列。推断必须在有限的持续时间支撑集上执行，并必须确保概率在该支撑集上被正确归一化。\n\n您必须实现以下计算元素：\n- 为每个状态拟合两种候选的显式持续时间分布：一个在 $\\{1,2,\\dots\\}$ 上由 $p$ 参数化的几何分布，以及一个通过一个时间步平移、在 $\\{1,2,\\dots\\}$ 上由 $\\lambda$ 参数化的平移泊松分布。对于这两种单参数族之间的模型选择，请使用赤池信息准则（AIC），如果出现完全平局，则必须选择几何分布。您必须使用根据经验直方图计数和在观测到的持续时间点上评估的参数概率计算出的似然。为了 HSMM 推断，您必须将持续时间概率质量函数截断到最大持续时间 $D_{\\max}$，并将其重新归一化，使其在 $\\{1,\\dots,D_{\\max}\\}$ 上的和为 1。\n- 对尖峰计数使用泊松观测模型，其具有特定于状态的率参数 $\\lambda^{(\\mathrm{em})}_i$（对于状态 $i$），并使用一个显式持续时间的 Viterbi 式动态规划程序计算与 HSMM 一致的最可能状态序列，该程序对可能的分段持续时间进行求和。您必须假设转移仅在分段边界发生，并由一个没有自转换的边界转移矩阵控制。\n\n您的程序不得接受任何输入，并且必须对嵌入在代码中的以下固定测试套件进行操作。对于每个测试用例，您将计算长度为 $T$ 的单个最可能解码状态序列（作为整数列表），其中每个元素是该时间步推断出的状态索引。\n\n测试套件规范：\n- 设所有情况下状态数为 $K = 2$，最大持续时间支撑集为 $D_{\\max} = 8$。\n- 情况 1：\n    - 状态 0 的经验驻留时间直方图计数：在持续时间 $\\{1,2,3,4,5,6,7,8\\}$ 上为 $\\{40,30,20,10,5,3,2,1\\}$。\n    - 状态 1 的经验驻留时间直方图计数：在持续时间 $\\{1,2,3,4,5,6,7,8\\}$ 上为 $\\{5,10,15,20,15,10,5,4\\}$。\n    - 观测序列长度 $T = 25$，尖峰计数为 $y_{0:24} = \\{2,1,3,0,1,4,2,1,10,8,9,7,11,12,8,9,7,10,9,1,3,2,0,2,1\\}$。\n    - 初始状态分布 $\\boldsymbol{\\pi} = [0.5, 0.5]$。\n    - 边界转移矩阵 $A = \\begin{bmatrix}0  1 \\\\ 1  0\\end{bmatrix}$。\n    - 泊松发射率 $\\boldsymbol{\\lambda}^{(\\mathrm{em})} = [2.0, 9.0]$。\n- 情况 2：\n    - 状态 0 的经验驻留时间直方图计数：在持续时间 $\\{1,2,3,4,5,6,7,8\\}$ 上为 $\\{80,10,5,3,1,1,0,0\\}$。\n    - 状态 1 的经验驻留时间直方图计数：在持续时间 $\\{1,2,3,4,5,6,7,8\\}$ 上为 $\\{5,10,15,10,8,6,5,3\\}$。\n    - 观测序列长度 $T = 12$，尖峰计数为 $y_{0:11} = \\{5,6,0,1,2,1,0,7,6,5,1,0\\}$。\n    - 初始状态分布 $\\boldsymbol{\\pi} = [0.5, 0.5]$。\n    - 边界转移矩阵 $A = \\begin{bmatrix}0  1 \\\\ 1  0\\end{bmatrix}$。\n    - 泊松发射率 $\\boldsymbol{\\lambda}^{(\\mathrm{em})} = [5.0, 1.0]$。\n- 情况 3：\n    - 状态 0 的经验驻留时间直方图计数：在持续时间 $\\{1,2,3,4,5,6,7,8\\}$ 上为 $\\{10,9,8,7,6,5,4,3\\}$。\n    - 状态 1 的经验驻留时间直方图计数：在持续时间 $\\{1,2,3,4,5,6,7,8\\}$ 上为 $\\{1,2,3,4,5,6,7,8\\}$。\n    - 观测序列长度 $T = 20$，尖峰计数为 $y_{0:19} = \\{3,2,4,3,5,2,3,4,8,7,9,6,8,7,9,2,1,3,2,2\\}$。\n    - 初始状态分布 $\\boldsymbol{\\pi} = [0.5, 0.5]$。\n    - 边界转移矩阵 $A = \\begin{bmatrix}0  1 \\\\ 1  0\\end{bmatrix}$。\n    - 泊松发射率 $\\boldsymbol{\\lambda}^{(\\mathrm{em})} = [3.0, 7.0]$。\n\n算法要求：\n- 对于每个状态的持续时间拟合，根据直方图计数和持续时间 $\\{1,\\dots,D_{\\max}\\}$ 计算每个候选族的最大似然估计，在这些持续时间点上评估对数似然，计算赤池信息准则，并选择 AIC 较低的族（如果平局则选择几何分布）。然后为 HSMM 推断构建一个在 $\\{1,\\dots,D_{\\max}\\}$ 上截断并重新归一化的持续时间概率质量函数。\n- 对于解码，计算每个观测在每个状态下的泊松对数似然，并实现一个在时间 $\\{1,\\dots,T\\}$ 上的显式持续时间 Viterbi 动态规划，该规划考虑在时间 $t$ 结束的分段的所有可能持续时间 $d \\in \\{1,\\dots,\\min(D_{\\max}, t)\\}$，正确处理具有初始状态分布的初始分段以及仅在边界发生的转移。\n\n您的程序应生成单行输出，其中包含三个测试用例的解码状态序列，格式为用方括号括起来的逗号分隔列表，其中每个元素本身是一个长度为 $T$ 的整数列表，表示每个时间步推断出的状态，例如：$\\big[\\,[z^{(1)}_0,\\dots,z^{(1)}_{T_1-1}],\\,[z^{(2)}_0,\\dots,z^{(2)}_{T_2-1}],\\,[z^{(3)}_0,\\dots,z^{(3)}_{T_3-1}]\\,\\big]$。唯一有效的输出是整数列表；此问题中没有物理单位，也没有角度。",
            "solution": "该问题要求构建并应用隐半马尔可夫模型（HSMM）从尖峰计数数据中解码离san神经状态序列。这涉及两个主要阶段：首先，从经验数据中估计模型参数，特别是状态持续时间分布；其次，使用这些参数找到与观测到的尖峰计数序列相对应的最可能隐状态序列。该解决方案将从概率建模、最大似然估计和动态规划的基本原则出发进行开发。\n\n**1. 模型规范：从 HMM 到 HSMM**\n\n一个标准的离散时间隐马尔可夫模型（HMM）由一组隐状态集合 $S = \\{0, 1, \\dots, K-1\\}$、一个观测字母表和三个概率分布定义：\n1.  初始状态分布 $\\boldsymbol{\\pi} = [\\pi_i]$，其中 $\\pi_i = P(z_0 = i)$。\n2.  状态转移概率矩阵 $A = [a_{ij}]$，其中 $a_{ij} = P(z_t = j | z_{t-1} = i)$。\n3.  发射概率分布 $B = [b_j(y)]$，其中 $b_j(y) = P(y_t = y | z_t = j)$。\n\n在标准 HMM 中，状态 $s_i$ 被占用的持续时间 $d$ 服从参数为 $p = 1 - a_{ii}$ 的几何分布。这种对持续时间的隐式建模通常具有限制性。隐半马尔可夫模型（HSMM）通过为每个状态引入一个显式的驻留时间概率分布 $P_i(d) = P(\\text{duration} = d | \\text{state} = i)$ 来推广 HMM。在 HSMM 中，状态之间的转移仅在状态分段结束时发生。此时，转移概率 $A_{ij}$ 是在状态 $i$ 的分段刚刚结束后转移到状态 $j$ 的概率。因此，该边界转移矩阵的对角元素为零，即 $A_{ii}=0$。\n\n**2. 状态持续时间分布的参数估计**\n\n该问题为每个状态 $i$ 提供了经验驻留时间直方图，以持续时间 $d \\in \\{1, 2, \\dots, D_{\\max}\\}$ 的计数 $N_i(d)$ 的形式给出。我们必须通过最大似然估计（MLE）将两个候选的参数分布（几何分布和平移泊松分布）拟合到这些计数。\n\n在参数化持续时间分布 $p(d; \\theta)$ 下，观测到状态 $i$ 的直方图计数 $\\{N_i(d)\\}_{d=1}^{D_{\\max}}$ 的似然由多项式概率分布给出。忽略常数项，对数似然为：\n$$ \\mathcal{L}(\\theta) = \\sum_{d=1}^{D_{\\max}} N_i(d) \\log p(d; \\theta) $$\n我们通过最大化此对数似然来找到 MLE 参数 $\\hat{\\theta}$。\n\n**2.1. 几何分布**\n在 $d \\in \\{1, 2, \\dots\\}$ 上的几何分布的概率质量函数（PMF）为 $p(d; p) = (1-p)^{d-1} p$。\n对数似然为：\n$$ \\mathcal{L}(p) = \\sum_{d=1}^{D_{\\max}} N_i(d) \\log\\left((1-p)^{d-1} p\\right) = \\sum_{d=1}^{D_{\\max}} N_i(d) \\left((d-1)\\log(1-p) + \\log p\\right) $$\n为求 $p$ 的 MLE，我们将其关于 $p$ 的导数设为零：\n$$ \\frac{\\partial \\mathcal{L}}{\\partial p} = \\sum_{d=1}^{D_{\\max}} N_i(d) \\left( \\frac{-(d-1)}{1-p} + \\frac{1}{p} \\right) = 0 $$\n$$ \\frac{1}{p} \\sum_{d=1}^{D_{\\max}} N_i(d) = \\frac{1}{1-p} \\sum_{d=1}^{D_{\\max}} (d-1)N_i(d) $$\n令 $N_{total} = \\sum_{d} N_i(d)$ 为观测到的分段总数，$\\bar{d} = \\frac{\\sum_{d} d N_i(d)}{N_{total}}$ 为经验平均持续时间。方程变为：\n$$ \\frac{N_{total}}{p} = \\frac{1}{1-p} (\\sum_d d N_i(d) - \\sum_d N_i(d)) = \\frac{N_{total}(\\bar{d}-1)}{1-p} $$\n$$ \\frac{1}{p} = \\frac{\\bar{d}-1}{1-p} \\implies 1-p = p(\\bar{d}-1) \\implies 1 = p\\bar{d} $$\n因此，几何参数的 MLE 为 $\\hat{p} = 1/\\bar{d} = \\frac{\\sum_{d=1}^{D_{\\max}} N_i(d)}{\\sum_{d=1}^{D_{\\max}} d \\cdot N_i(d)}$。\n\n**2.2. 平移泊松分布**\n泊松分布的 PMF 为 $P(k; \\lambda) = e^{-\\lambda} \\lambda^k / k!$（对于 $k \\in \\{0, 1, \\dots\\}$）。用于持续时间 $d=k+1 \\in \\{1, 2, \\dots\\}$ 的平移泊松分布的 PMF 为 $p(d; \\lambda) = \\frac{e^{-\\lambda} \\lambda^{d-1}}{(d-1)!}$。\n对数似然为：\n$$ \\mathcal{L}(\\lambda) = \\sum_{d=1}^{D_{\\max}} N_i(d) \\log\\left(\\frac{e^{-\\lambda} \\lambda^{d-1}}{(d-1)!}\\right) = \\sum_{d=1}^{D_{\\max}} N_i(d) \\left(-\\lambda + (d-1)\\log \\lambda - \\log((d-1)!)\\right) $$\n将其关于 $\\lambda$ 的导数设为零：\n$$ \\frac{\\partial \\mathcal{L}}{\\partial \\lambda} = \\sum_{d=1}^{D_{\\max}} N_i(d) \\left(-1 + \\frac{d-1}{\\lambda}\\right) = 0 $$\n$$ \\frac{1}{\\lambda} \\sum_{d=1}^{D_{\\max}} (d-1)N_i(d) = \\sum_{d=1}^{D_{\\max}} N_i(d) $$\n$$ \\lambda \\sum_{d} N_i(d) = \\sum_{d} (d-1)N_i(d) = \\sum_{d} d N_i(d) - \\sum_{d} N_i(d) $$\n解出 $\\lambda$ 得到 MLE：$\\hat{\\lambda} = \\frac{\\sum_d d N_i(d)}{\\sum_d N_i(d)} - 1 = \\bar{d} - 1$。\n\n**2.3. 模型选择和重新归一化**\n计算出 MLE 参数 $\\hat{p}$ 和 $\\hat{\\lambda}$ 后，我们为每个模型评估最大化对数似然 $\\mathcal{L}_{max}$。使用赤池信息准则（AIC）进行模型选择：\n$$ \\text{AIC} = 2k - 2\\mathcal{L}_{max} $$\n其中 $k$ 是估计参数的数量。对于几何分布和平移泊松分布模型，$k=1$。我们选择 AIC 值较低的模型，若出现平局则选择几何模型。\n一旦为每个状态 $i$ 选定了最拟合的分布 $p(d;\\hat{\\theta})$，就为其计算在持续时间 $d \\in \\{1, \\dots, D_{\\max}\\}$ 上的 PMF。必须对该分布进行截断和重新归一化，以确保其在该有限支撑集上的和为 1：\n$$ P_i(d) = \\frac{p(d; \\hat{\\theta})}{\\sum_{d'=1}^{D_{\\max}} p(d'; \\hat{\\theta})} \\quad \\text{对于 } d=1, \\dots, D_{\\max} $$\n\n**3. 使用显式持续时间 Viterbi 算法解码**\n\n解码的目标是找到生成观测序列 $y_{0:T-1} = (y_0, \\dots, y_{T-1})$ 的最可能隐状态序列 $z^*_{0:T-1} = (z^*_0, \\dots, z^*_{T-1})$。这通过一种动态规划方法解决，类似于 HMM 的 Viterbi 算法。\n\n我们定义 $\\delta_t(j)$ 为观测序列 $y_{0:t-1}$ 的任何有效分割，且以状态 $j$ 的分段结束的最大对数概率。我们还使用回溯指针数组 $\\psi_d(t, j)$ 和 $\\psi_s(t, j)$ 分别存储得到 $\\delta_t(j)$ 的路径的最后一个分段的持续时间和前一个状态的标识。\n\n观测模型是具有状态特定率 $\\lambda^{(\\mathrm{em})}_j$ 的泊松分布。在状态 $j$ 中观测到尖峰计数 $y$ 的对数似然为：\n$$ \\log P(y | \\text{state } j) = y \\log(\\lambda^{(\\mathrm{em})}_j) - \\lambda^{(\\mathrm{em})}_j - \\log(y!) $$\n我们预先计算一个包含所有观测到的计数和状态的这些对数似然的表格。令其为 $\\log B_{t,j} = \\log P(y_t | \\text{state } j)$。观测子序列 $y_{t-d:t-1}$ 由状态 $j$ 生成的对数似然为 $L_{t-d:t-1}(j) = \\sum_{k=t-d}^{t-1} \\log B_{k,j}$。\n\n动态规划递推过程如下：\n对于 $t = 1, \\dots, T$:\n  对于每个状态 $j \\in \\{0, \\dots, K-1\\}$:\n    $$ \\delta_t(j) = \\max_{d \\in \\{1,\\dots,\\min(t, D_{\\max})\\}} \\left( \\mathcal{V}_{t-d}(j) + \\log P_j(d) + L_{t-d:t-1}(j) \\right) $$\n    其中 $\\mathcal{V}_{\\tau}(j)$ 是在时间 $\\tau$ 结束并转移到状态 $j$ 的路径的最大对数概率。\n    $$ \\mathcal{V}_{\\tau}(j) = \\begin{cases} \\log \\pi_j  \\text{如果 } \\tau = 0 \\\\ \\max_{i \\neq j} \\{\\delta_{\\tau}(i) + \\log A_{ij}\\}  \\text{如果 } \\tau > 0 \\end{cases} $$\n    对于 $K=2$ 且 $A = \\begin{bmatrix}01\\\\10\\end{bmatrix}$ 的特定情况，这简化为 $\\mathcal{V}_{\\tau}(j) = \\delta_{\\tau}(1-j)$（对于 $\\tau>0$），因为 $\\log A_{ij} = \\log(1) = 0$。\n\n达到 $\\delta_t(j)$ 最大值的 $d$（持续时间）和 $i$（前一个状态）的值存储在回溯指针表 $\\psi_d(t,j)$ 和 $\\psi_s(t,j)$ 中。\n\n**初始化**：递推由 $\\mathcal{V}_{\\tau}(j)$ 定义中的 $\\tau=0$ 情况自然初始化。对于从时间 0 开始、持续时间为 $d=t$ 的分段，路径概率来自初始分布 $\\pi_j$。\n\n**终止**：在计算完所有 $t$ 和 $j$ 的 $\\delta_t(j)$ 后，最可能完整路径的对数概率为 $\\log P^* = \\max_{j} \\delta_T(j)$，该路径最后一个分段的状态为 $z^*_{final} = \\arg\\max_{j} \\delta_T(j)$。\n\n**回溯**：最可能的状态序列通过从时间 $T$ 的 $z^*_{final}$ 开始，并使用存储的指针向后追溯来重构。\n令 $t_{curr} = T$ 和 $j_{curr} = z^*_{final}$。\n当 $t_{curr} > 0$ 时：\n  1. 获取最后一个分段的持续时间：$d = \\psi_d(t_{curr}, j_{curr})$。\n  2. 获取前一个状态：$j_{prev} = \\psi_s(t_{curr}, j_{curr})$。\n  3. 将状态 $j_{curr}$ 分配给从 $t_{curr}-d$ 到 $t_{curr}-1$ 的时间步。\n  4. 为下一次迭代更新：$t_{curr} \\leftarrow t_{curr} - d$，$j_{curr} \\leftarrow j_{prev}$。\n此过程持续进行，直到整个序列 $z^*_{0:T-1}$ 被重构。\n\n这个综合过程，将基于 MLE 的参数估计与显式持续时间的动态规划算法相结合，实现了对观测活动中隐藏神经状态的原则性解码。",
            "answer": "```python\nimport numpy as np\nfrom scipy.special import gammaln\n\ndef solve():\n    \"\"\"\n    Main function to run the HSMM decoding for all test cases.\n    \"\"\"\n    test_cases = [\n        {\n            \"hist_0\": np.array([40, 30, 20, 10, 5, 3, 2, 1]),\n            \"hist_1\": np.array([5, 10, 15, 20, 15, 10, 5, 4]),\n            \"obs\": np.array([2, 1, 3, 0, 1, 4, 2, 1, 10, 8, 9, 7, 11, 12, 8, 9, 7, 10, 9, 1, 3, 2, 0, 2, 1]),\n            \"pi\": np.array([0.5, 0.5]),\n            \"A\": np.array([[0.0, 1.0], [1.0, 0.0]]),\n            \"lambda_em\": np.array([2.0, 9.0]),\n        },\n        {\n            \"hist_0\": np.array([80, 10, 5, 3, 1, 1, 0, 0]),\n            \"hist_1\": np.array([5, 10, 15, 10, 8, 6, 5, 3]),\n            \"obs\": np.array([5, 6, 0, 1, 2, 1, 0, 7, 6, 5, 1, 0]),\n            \"pi\": np.array([0.5, 0.5]),\n            \"A\": np.array([[0.0, 1.0], [1.0, 0.0]]),\n            \"lambda_em\": np.array([5.0, 1.0]),\n        },\n        {\n            \"hist_0\": np.array([10, 9, 8, 7, 6, 5, 4, 3]),\n            \"hist_1\": np.array([1, 2, 3, 4, 5, 6, 7, 8]),\n            \"obs\": np.array([3, 2, 4, 3, 5, 2, 3, 4, 8, 7, 9, 6, 8, 7, 9, 2, 1, 3, 2, 2]),\n            \"pi\": np.array([0.5, 0.5]),\n            \"A\": np.array([[0.0, 1.0], [1.0, 0.0]]),\n            \"lambda_em\": np.array([3.0, 7.0]),\n        },\n    ]\n\n    D_max = 8\n    K = 2\n    results = []\n\n    for case in test_cases:\n        decoded_sequence = _solve_one_case(case, K, D_max)\n        results.append(decoded_sequence)\n\n    # Format output as specified\n    result_str = \",\".join(f\"[{','.join(map(str, res))}]\" for res in results)\n    print(f\"[{result_str}]\")\n\n\ndef _poisson_logpmf(k, lam):\n    \"\"\"\n    Computes the log of the Poisson PMF, handling lam=0.\n    \"\"\"\n    # handle lam=0 case to avoid log(0)\n    lam = np.maximum(lam, 1e-9)\n    with np.errstate(invalid='ignore', divide='ignore'):\n        return k * np.log(lam) - lam - gammaln(k + 1)\n\n\ndef _fit_and_select_duration_model(hist_counts, D_max):\n    \"\"\"\n    Fits Geometric and Shifted Poisson distributions to histogram data,\n    selects the best model using AIC, and returns the renormalized PMF.\n    \"\"\"\n    durations = np.arange(1, D_max + 1)\n    \n    total_counts = np.sum(hist_counts)\n    if total_counts == 0:\n        return np.ones(D_max) / D_max\n\n    weighted_sum_d = np.sum(durations * hist_counts)\n    \n    # --- Geometric Model ---\n    p_mle_geom = total_counts / weighted_sum_d if weighted_sum_d > 0 else 0\n    log_likelihood_geom = -np.inf\n    log_pmf_geom = np.full(D_max, -np.inf)\n    if 0  p_mle_geom  1:\n        log_pmf_geom = (durations - 1) * np.log1p(-p_mle_geom) + np.log(p_mle_geom)\n        log_likelihood_geom = np.sum(hist_counts * log_pmf_geom)\n    aic_geom = 2 * 1 - 2 * log_likelihood_geom\n\n    # --- Shifted Poisson Model ---\n    mean_duration = weighted_sum_d / total_counts\n    lambda_mle_poisson = mean_duration - 1.0\n    log_likelihood_poisson = -np.inf\n    log_pmf_poisson = np.full(D_max, -np.inf)\n    if lambda_mle_poisson > 0:\n        log_pmf_poisson = _poisson_logpmf(durations - 1, lambda_mle_poisson)\n        log_likelihood_poisson = np.sum(hist_counts * log_pmf_poisson)\n    aic_poisson = 2 * 1 - 2 * log_likelihood_poisson\n\n    # --- Model Selection and PMF generation ---\n    chosen_log_pmf = log_pmf_geom\n    if aic_poisson  aic_geom:\n        chosen_log_pmf = log_pmf_poisson\n\n    pmf_unnormalized = np.exp(chosen_log_pmf)\n    norm_factor = np.sum(pmf_unnormalized)\n    \n    if norm_factor > 0:\n        final_pmf = pmf_unnormalized / norm_factor\n    else: \n        final_pmf = np.ones(D_max) / D_max\n        \n    return final_pmf\n\ndef _solve_one_case(params, K, D_max):\n    \"\"\"\n    Solves a single test case for HSMM decoding.\n    \"\"\"\n    obs = params[\"obs\"]\n    T = len(obs)\n    pi = params[\"pi\"]\n    A = params[\"A\"]\n    lambda_em = params[\"lambda_em\"]\n    histograms = [params[\"hist_0\"], params[\"hist_1\"]]\n\n    # 1. Fit duration models for each state\n    log_P_duration = np.zeros((K, D_max))\n    for i in range(K):\n        pmf = _fit_and_select_duration_model(histograms[i], D_max)\n        with np.errstate(divide='ignore'):\n            log_P_duration[i, :] = np.log(pmf)\n\n    # 2. Precompute observation log-likelihoods\n    log_B = np.zeros((T, K))\n    for j in range(K):\n        log_B[:, j] = _poisson_logpmf(obs, lambda_em[j])\n    \n    log_B_cumsum = np.cumsum(log_B, axis=0)\n\n    def get_log_obs_likelihood(t_start, t_end, state):\n        if t_start == 0:\n            return log_B_cumsum[t_end, state]\n        else:\n            return log_B_cumsum[t_end, state] - log_B_cumsum[t_start - 1, state]\n\n    # 3. HSMM Viterbi DP\n    log_delta = np.full((T + 1, K), -np.inf)\n    psi_duration = np.zeros((T + 1, K), dtype=int)\n    psi_prev_state = np.zeros((T + 1, K), dtype=int)\n\n    with np.errstate(divide='ignore'):\n      log_pi = np.log(pi)\n      log_A = np.log(A)\n    \n    for t in range(1, T + 1):\n        for j in range(K):\n            max_log_prob = -np.inf\n            best_d = -1\n            best_i = -1\n\n            for d in range(1, min(t, D_max) + 1):\n                t_prev = t - d\n                log_P_obs = get_log_obs_likelihood(t_prev, t-1, j)\n                log_prob_segment = log_P_duration[j, d-1] + log_P_obs\n                \n                if t_prev == 0:\n                    log_prob_path = log_pi[j] + log_prob_segment\n                    prev_state = -1 # Sentinel for initial state\n                else:\n                    i_prev = 1 - j # Simplified for K=2\n                    prev_path_prob = log_delta[t_prev, i_prev] + log_A[i_prev, j]\n                    log_prob_path = prev_path_prob + log_prob_segment\n                    prev_state = i_prev\n                \n                if log_prob_path > max_log_prob:\n                    max_log_prob = log_prob_path\n                    best_d = d\n                    best_i = prev_state\n            \n            log_delta[t, j] = max_log_prob\n            psi_duration[t, j] = best_d\n            psi_prev_state[t, j] = best_i\n\n    # 4. Backtracking\n    state_sequence = np.zeros(T, dtype=int)\n    \n    current_t = T\n    current_j = np.argmax(log_delta[T, :])\n    \n    while current_t > 0:\n        d = psi_duration[current_t, current_j]\n        prev_j = psi_prev_state[current_t, current_j]\n        \n        for i in range(current_t - d, current_t):\n            state_sequence[i] = current_j\n        \n        current_t -= d\n        current_j = prev_j\n\n    return state_sequence.tolist()\n\nif __name__ == '__main__':\n    solve()\n```"
        }
    ]
}