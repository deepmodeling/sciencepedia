{
    "hands_on_practices": [
        {
            "introduction": "本练习是理解潜变量模型如何解释神经群体活动的基础。通过推导一个简单线性高斯模型下观测活动的协方差矩阵，你将亲手揭示一个低维潜在空间（$k \\ll n$）如何在一个高维神经群体中产生相关性结构。这个练习 () 让你能够探索噪声如何影响这种结构，这是理解因子分析和主成分分析等降维方法数学核心的关键一步。",
            "id": "4173653",
            "problem": "考虑一个用于神经元群体的线性高斯潜变量模型。设时间 $t$ 观测到的群体活动为 $y_t \\in \\mathbb{R}^{n}$，由潜变量 $x_t \\in \\mathbb{R}^{k}$ 生成：\n$$\ny_t \\;=\\; C x_t \\;+\\; \\epsilon_t,\n$$\n其中 $C \\in \\mathbb{R}^{n \\times k}$ 是一个固定的载荷矩阵，潜状态满足 $x_t \\sim \\mathcal{N}(0,Q)$，其中 $Q \\in \\mathbb{R}^{k \\times k}$ 是对称半正定矩阵，观测噪声为 $\\epsilon_t \\sim \\mathcal{N}(0,R)$，其中 $R \\in \\mathbb{R}^{n \\times n}$ 是对称半正定矩阵。假设 $x_t$ 和 $\\epsilon_t$ 相互独立，并且所有过程都是广义平稳的，因此在讨论二阶矩时可以省略时间索引。\n\n从概率论和统计学的核心定义出发，包括协方差、独立性和全协方差定律的定义，推导群体协方差 $\\Sigma_y = \\operatorname{Cov}(y_t)$ 关于 $C$、$Q$ 和 $R$ 的闭式表达式。然后，在以下假设下分析 $\\Sigma_y$ 的秩如何依赖于潜变量维度 $k$ 和观测噪声协方差 $R$：$Q$ 是正定的，且 $C$ 具有满列秩 $k$。为以下两种情况提供严格的论证：\n(i) $R = 0$，\n(ii) $R = \\sigma^{2} I_{n}$ 且 $\\sigma^{2} > 0$。\n\n将你的最终答案表示为一个行矩阵，其第一个元素是 $\\Sigma_y$ 的闭式表达式，第二个元素是在情况 (i) 和 (ii) 下给出 $\\operatorname{rank}(\\Sigma_y)$ 的单个分段解析表达式。不需要进行数值取整。",
            "solution": "我们首先推导协方差矩阵 $\\Sigma_y = \\operatorname{Cov}(y)$。模型为 $y = Cx + \\epsilon$。根据全协方差定律：\n$$\n\\operatorname{Cov}(y) = \\mathbb{E}[\\operatorname{Cov}(y|x)] + \\operatorname{Cov}(\\mathbb{E}[y|x])\n$$\n我们分别计算右侧的两项：\n1.  **条件期望的协方差**:\n    $\\mathbb{E}[y|x] = \\mathbb{E}[Cx + \\epsilon | x] = Cx + \\mathbb{E}[\\epsilon|x]$。由于 $x$ 和 $\\epsilon$ 独立，$\\mathbb{E}[\\epsilon|x] = \\mathbb{E}[\\epsilon] = 0$。因此 $\\mathbb{E}[y|x] = Cx$。\n    那么，$\\operatorname{Cov}(\\mathbb{E}[y|x]) = \\operatorname{Cov}(Cx) = C\\operatorname{Cov}(x)C^T = CQC^T$。\n2.  **条件协方差的期望**:\n    $\\operatorname{Cov}(y|x) = \\operatorname{Cov}(Cx + \\epsilon | x) = \\operatorname{Cov}(\\epsilon|x)$，因为给定 $x$ 时 $Cx$ 是常数。由于 $x$ 和 $\\epsilon$ 独立，$\\operatorname{Cov}(\\epsilon|x) = \\operatorname{Cov}(\\epsilon) = R$。\n    因此，$\\mathbb{E}[\\operatorname{Cov}(y|x)] = \\mathbb{E}[R] = R$。\n\n将两项相加，得到：\n$$\n\\Sigma_y = CQC^T + R\n$$\n接下来分析秩。假设 $Q$ 是正定的（秩为 $k$），$C$ 是满列秩（秩为 $k$）。\n\n(i) **情况 $R=0$**:\n$\\Sigma_y = CQC^T$。由于 $Q$ 是正定矩阵，$C$ 是满列秩矩阵，乘积 $CQC^T$ 的秩等于 $C$ 的秩。这可以通过考虑 $CQC^T$ 的零空间来证明，或更直接地，注意到 $Q$ 有一个可逆的平方根 $Q^{1/2}$。那么 $\\operatorname{rank}(\\Sigma_y) = \\operatorname{rank}((CQ^{1/2})(CQ^{1/2})^T) = \\operatorname{rank}(CQ^{1/2})$。因为 $Q^{1/2}$ 是可逆方阵，$C$ 乘以它不会改变秩，所以 $\\operatorname{rank}(CQ^{1/2}) = \\operatorname{rank}(C) = k$。\n因此，$\\operatorname{rank}(\\Sigma_y) = k$。\n\n(ii) **情况 $R = \\sigma^2 I_n$ 且 $\\sigma^2 > 0$**:\n$\\Sigma_y = CQC^T + \\sigma^2 I_n$。矩阵 $CQC^T$ 是半正定的（因为 $v^T(CQC^T)v = (C^Tv)^TQ(C^Tv) \\ge 0$）。矩阵 $\\sigma^2 I_n$ 是正定的（因为 $\\sigma^2 > 0$）。一个半正定矩阵和一个正定矩阵的和是正定矩阵。一个 $n \\times n$ 的正定矩阵是可逆的，因此具有满秩。\n因此，$\\operatorname{rank}(\\Sigma_y) = n$。",
            "answer": "$$\n\\boxed{\n\\begin{pmatrix}\nC Q C^T + R  \n\\begin{cases}\nk  \\text{若 } R = 0 \\\\\nn  \\text{若 } R = \\sigma^2 I_n \\text{ 且 } \\sigma^2 > 0\n\\end{cases}\n\\end{pmatrix}\n}\n$$"
        },
        {
            "introduction": "真实的神经数据通常是尖峰计数，使用泊松分布比高斯分布更为合适。本练习 () 将指导你为一个更实际的泊松潜变量模型推导其目标函数——证据下界（ELBO）。这是运用一种强大的现代技术，即变分推断（variational inference），来拟合这类模型的关键。掌握ELBO的推导是实践中应用复杂潜变量模型的必备技能。",
            "id": "4173638",
            "problem": "考虑一个由 $N$ 个神经元组成的群体，在 $T$ 个离散时间区间内进行观测。令 $y_{t,i} \\in \\{0,1,2,\\dots\\}$ 表示神经元 $i$ 在时间 $t$ 的脉冲计数。假设一个潜在线性率模型，其中在给定潜在状态 $x_t \\in \\mathbb{R}^{K}$、神经元特定的载荷 $C_i \\in \\mathbb{R}^{K}$ 和偏移量 $d_i \\in \\mathbb{R}$ 的条件下，$y_{t,i}$ 的条件分布是强度为\n$$\n\\lambda_{t,i} \\;=\\; \\exp\\!\\big(C_i^{\\top} x_t + d_i\\big).\n$$\n的泊松分布。假设独立的先验分布 $p(x_{1:T})$、$p(C_i)$ 和 $p(d_i)$，其中 $x_{1:T} := (x_1,\\dots,x_T)$。您将使用一个均值场族进行变分推断，该均值场族可分解为\n$$\nq(x_{1:T}) \\;\\prod_{i=1}^{N} q(C_i)\\,q(d_i).\n$$\n仅从以下原则出发：\n- 对于 $y \\sim \\mathrm{Poisson}(\\lambda)$，泊松分布的概率质量函数的对数为 $\\ln p(y \\mid \\lambda) = y \\ln \\lambda - \\lambda - \\ln(y!)$。\n- 变分推断中的证据下界 (ELBO) 定义为 $\\mathcal{L}(q) = \\mathbb{E}_{q}\\!\\left[\\ln p(y, x_{1:T}, C_{1:N}, d_{1:N})\\right] - \\mathbb{E}_{q}\\!\\left[\\ln q(x_{1:T}, C_{1:N}, d_{1:N})\\right]$，其中 $C_{1:N} := (C_1,\\dots,C_N)$ 且 $d_{1:N} := (d_1,\\dots,d_N)$。\n- Kullback–Leibler (KL) 散度定义为 $\\mathrm{KL}(q \\,\\|\\, p) = \\mathbb{E}_{q}\\!\\left[\\ln\\frac{q}{p}\\right]$。\n\n在所述的均值场分解下，推导该模型的 ELBO。您的推导必须明确地将期望对数似然项 $\\mathbb{E}_{q}\\!\\left[\\ln p\\!\\left(y_{1:T,1:N} \\mid x_{1:T}, C_{1:N}, d_{1:N}\\right)\\right]$ 写成基于变分因子的期望形式，并在有效时利用分解所隐含的独立性。将您最终的 ELBO 表示为单个封闭形式的解析表达式，该表达式仅包含观测到的计数 $y_{t,i}$、在 $q$ 下的期望以及变分因子与其相应先验之间的 KL 散度。不需要进行数值计算。最终答案必须是单个解析表达式。不包含任何单位。不需要四舍五入。",
            "solution": "该问题要求针对神经脉冲计数的泊松潜在变量模型，使用指定的均值场变分近似，推导其证据下界 (ELBO)。\n\nELBO 定义为：\n$$\n\\mathcal{L}(q) = \\mathbb{E}_{q}\\!\\left[\\ln p(y, x_{1:T}, C_{1:N}, d_{1:N})\\right] - \\mathbb{E}_{q}\\!\\left[\\ln q(x_{1:T}, C_{1:N}, d_{1:N})\\right]\n$$\n其中 $y$ 表示观测到的脉冲计数的完整集合 $\\{y_{t,i}\\}$。项 $p(y, x_{1:T}, C_{1:N}, d_{1:N})$ 是模型的完整联合概率，而 $q(x_{1:T}, C_{1:N}, d_{1:N})$ 是变分近似。\n\n首先，我们使用概率的链式法则和指定的模型依赖关系来展开联合概率。该模型假设潜在变量具有独立的先验分布，并且在给定潜在变量的情况下，观测值是条件独立的。\n$$\np(y, x_{1:T}, C_{1:N}, d_{1:N}) = p(y \\mid x_{1:T}, C_{1:N}, d_{1:N}) \\, p(x_{1:T}) \\, p(C_{1:N}) \\, p(d_{1:N})\n$$\n根据每个神经元参数具有独立先验的假设，我们有 $p(C_{1:N}) = \\prod_{i=1}^N p(C_i)$ 和 $p(d_{1:N}) = \\prod_{i=1}^N p(d_i)$。此外，对于每个时间区间和神经元，在给定潜在变量的情况下，观测值是条件独立的，因此 $p(y \\mid x_{1:T}, C_{1:N}, d_{1:N}) = \\prod_{t=1}^T \\prod_{i=1}^N p(y_{t,i} \\mid x_t, C_i, d_i)$。\n\n因此，联合概率的对数为：\n$$\n\\ln p(y, x, C, d) = \\sum_{t=1}^{T}\\sum_{i=1}^{N} \\ln p(y_{t,i} \\mid x_t, C_i, d_i) + \\ln p(x_{1:T}) + \\sum_{i=1}^{N} \\ln p(C_i) + \\sum_{i=1}^{N} \\ln p(d_i)\n$$\n\n接下来，我们对变分分布 $q$ 使用指定的均值场分解：\n$$\nq(x_{1:T}, C_{1:N}, d_{1:N}) = q(x_{1:T}) \\prod_{i=1}^{N} q(C_i) q(d_i)\n$$\n变分分布的对数为：\n$$\n\\ln q(x, C, d) = \\ln q(x_{1:T}) + \\sum_{i=1}^{N} \\ln q(C_i) + \\sum_{i=1}^{N} \\ln q(d_i)\n$$\n\n现在，我们将这些展开的对数概率代入 ELBO 的定义中。我们可以将与每个潜在变量块相关的项分组：\n$$\n\\begin{aligned}\n\\mathcal{L}(q) ={} \\mathbb{E}_{q}\\!\\left[\\sum_{t=1}^{T}\\sum_{i=1}^{N} \\ln p(y_{t,i} \\mid x_t, C_i, d_i)\\right] \\\\\n + \\mathbb{E}_{q}\\!\\left[\\ln p(x_{1:T})\\right] - \\mathbb{E}_{q}\\!\\left[\\ln q(x_{1:T})\\right] \\\\\n + \\sum_{i=1}^{N} \\left( \\mathbb{E}_{q}\\!\\left[\\ln p(C_i)\\right] - \\mathbb{E}_{q}\\!\\left[\\ln q(C_i)\\right] \\right) \\\\\n + \\sum_{i=1}^{N} \\left( \\mathbb{E}_{q}\\!\\left[\\ln p(d_i)\\right] - \\mathbb{E}_{q}\\!\\left[\\ln q(d_i)\\right] \\right)\n\\end{aligned}\n$$\n由于均值场分解，只依赖于 $q$ 的单个因子的函数的期望，简化为仅对该因子求期望。例如，$\\mathbb{E}_{q}[\\ln p(x_{1:T})] = \\mathbb{E}_{q(x_{1:T})}[\\ln p(x_{1:T})]$。使用 Kullback-Leibler (KL) 散度的定义 $\\mathrm{KL}(q \\,\\|\\, p) = \\mathbb{E}_{q}[\\ln q] - \\mathbb{E}_{q}[\\ln p]$，我们可以将表达式重写为：\n$$\n\\begin{aligned}\n\\mathcal{L}(q) = \\mathbb{E}_{q}\\!\\left[\\ln p(y \\mid x_{1:T}, C_{1:N}, d_{1:N})\\right]  - \\mathrm{KL}(q(x_{1:T}) \\| p(x_{1:T})) \\\\\n - \\sum_{i=1}^{N} \\mathrm{KL}(q(C_i) \\| p(C_i)) \\\\\n - \\sum_{i=1}^{N} \\mathrm{KL}(q(d_i) \\| p(d_i))\n\\end{aligned}\n$$\n第一项是期望对数似然。其余各项是变分分布与其相应先验之间的负 KL 散度。\n\n任务的核心是展开期望对数似然项。我们从单个观测值 $y_{t,i}$ 的对数概率表达式开始，该观测值来自速率为 $\\lambda_{t,i} = \\exp(C_i^{\\top} x_t + d_i)$ 的泊松分布：\n$$\n\\ln p(y_{t,i} \\mid x_t, C_i, d_i) = y_{t,i} \\ln(\\lambda_{t,i}) - \\lambda_{t,i} - \\ln(y_{t,i}!)\n$$\n代入 $\\lambda_{t,i}$：\n$$\n\\ln p(y_{t,i} \\mid x_t, C_i, d_i) = y_{t,i} \\left(C_i^{\\top} x_t + d_i\\right) - \\exp(C_i^{\\top} x_t + d_i) - \\ln(y_{t,i}!)\n$$\n期望对数似然是这些项在所有 $t$ 和 $i$ 上的总和的期望：\n$$\n\\mathbb{E}_{q}\\!\\left[\\ln p(y \\mid \\dots)\\right] = \\mathbb{E}_{q}\\!\\left[\\sum_{t=1}^{T}\\sum_{i=1}^{N} \\left( y_{t,i}(C_i^{\\top} x_t + d_i) - \\exp(C_i^{\\top} x_t + d_i) - \\ln(y_{t,i}!) \\right) \\right]\n$$\n根据期望的线性性质，我们可以将期望移到求和符号内部：\n$$\n= \\sum_{t=1}^{T}\\sum_{i=1}^{N} \\mathbb{E}_{q}\\!\\left[ y_{t,i}(C_i^{\\top} x_t + d_i) - \\exp(C_i^{\\top} x_t + d_i) - \\ln(y_{t,i}!) \\right]\n$$\n由于 $y_{t,i}$ 和 $\\ln(y_{t,i}!)$ 相对于对潜在变量的期望是常数：\n$$\n= \\sum_{t=1}^{T}\\sum_{i=1}^{N} \\left( y_{t,i} \\mathbb{E}_{q}\\!\\left[C_i^{\\top} x_t + d_i\\right] - \\mathbb{E}_{q}\\!\\left[\\exp(C_i^{\\top} x_t + d_i)\\right] - \\ln(y_{t,i}!) \\right)\n$$\n现在我们应用均值场分解 $q(x_t, C_i, d_i) = q(x_t)q(C_i)q(d_i)$ 的独立性。对于线性项：\n$$\n\\mathbb{E}_{q}\\!\\left[C_i^{\\top} x_t + d_i\\right] = \\mathbb{E}_{q}\\!\\left[C_i^{\\top} x_t\\right] + \\mathbb{E}_{q}\\!\\left[d_i\\right] = \\mathbb{E}_{q}[C_i]^{\\top} \\mathbb{E}_{q}[x_t] + \\mathbb{E}_{q}[d_i]\n$$\n分离 $\\mathbb{E}_{q}[C_i^{\\top} x_t] = \\mathbb{E}_{q}[C_i]^{\\top} \\mathbb{E}_{q}[x_t]$ 是有效的，因为在变分分布 $q$ 下，随机变量 $C_i$ 和 $x_t$ 是独立的。对于指数项，变量 $(C_i, x_t)$ 独立于 $d_i$：\n$$\n\\mathbb{E}_{q}\\!\\left[\\exp(C_i^{\\top} x_t + d_i)\\right] = \\mathbb{E}_{q}\\!\\left[\\exp(C_i^{\\top} x_t) \\exp(d_i)\\right] = \\mathbb{E}_{q}\\!\\left[\\exp(C_i^{\\top} x_t)\\right] \\mathbb{E}_{q}\\!\\left[\\exp(d_i)\\right]\n$$\n请注意，在没有 $q(C_i)$ 和 $q(x_t)$ 的具体函数形式的情况下，项 $\\mathbb{E}_{q}[\\exp(C_i^{\\top} x_t)]$ 无法进一步简化，因为期望算子不能分配到指数内的乘积 $C_i^\\top x_t$ 上。\n\n将这些结果代回到期望对数似然的表达式中，然后再代入完整的 ELBO 中，我们便得到了最终的表达式。\n\n完整的证据下界是：\n$$\n\\begin{aligned}\n\\mathcal{L}(q) ={} \\sum_{t=1}^{T}\\sum_{i=1}^{N} \\left( y_{t,i} \\left(\\mathbb{E}_{q}[C_i]^{\\top} \\mathbb{E}_{q}[x_t] + \\mathbb{E}_{q}[d_i]\\right) - \\mathbb{E}_{q}\\!\\left[\\exp(C_i^{\\top} x_t)\\right] \\mathbb{E}_{q}\\!\\left[\\exp(d_i)\\right] - \\ln(y_{t,i}!) \\right) \\\\\n - \\mathrm{KL}(q(x_{1:T}) \\| p(x_{1:T})) - \\sum_{i=1}^{N} \\mathrm{KL}(q(C_i) \\| p(C_i)) - \\sum_{i=1}^{N} \\mathrm{KL}(q(d_i) \\| p(d_i))\n\\end{aligned}\n$$\n该表达式依赖于观测数据 $y_{t,i}$、在变分分布 $q$ 下的期望以及变分因子与其先验之间的 KL 散度，符合要求。",
            "answer": "$$\n\\boxed{\n\\begin{aligned}\n \\sum_{t=1}^{T}\\sum_{i=1}^{N} \\left( y_{t,i} \\left(\\mathbb{E}_{q}[C_i]^{\\top} \\mathbb{E}_{q}[x_t] + \\mathbb{E}_{q}[d_i]\\right) - \\mathbb{E}_{q}\\!\\left[\\exp(C_i^{\\top} x_t)\\right] \\mathbb{E}_{q}\\!\\left[\\exp(d_i)\\right] - \\ln(y_{t,i}!) \\right) \\\\\n \\quad - \\mathrm{KL}(q(x_{1:T}) \\| p(x_{1:T})) - \\sum_{i=1}^{N} \\mathrm{KL}(q(C_i) \\| p(C_i)) - \\sum_{i=1}^{N} \\mathrm{KL}(q(d_i) \\| p(d_i))\n\\end{aligned}\n}\n$$"
        },
        {
            "introduction": "拟合模型后，一个至关重要的问题是：这个模型真的捕捉到了真实数据的重要特征吗？本练习 () 介绍了后验预测检验（posterior predictive checking），这是现代贝叶斯工作流程的基石。你将学习如何设计一个流程，从你拟合的模型中模拟出“复制”数据集，并将其与观测数据进行系统性比较，以诊断模型与数据之间的潜在不匹配之处。",
            "id": "4173683",
            "problem": "一个神经科学实验室使用带有泊松观测的潜变量模型，具体来说是泊松线性动力系统 (PLDS)，来为 $N$ 个神经元在 $T$ 个时间窗内的联合脉冲发放活动建模。潜状态 $x_t \\in \\mathbb{R}^K$ 根据线性高斯动力学演化，并且在给定潜状态的条件下，脉冲发放服从条件泊松分布：\n$$\nx_{t+1} = A x_t + \\varepsilon_t,\\quad \\varepsilon_t \\sim \\mathcal{N}(0, Q),\\quad x_1 \\sim \\mathcal{N}(m_0, V_0),\n$$\n$$\ny_{i t} \\mid x_t, \\theta \\sim \\text{Poisson}\\!\\left(\\lambda_{i t}\\right),\\quad \\lambda_{i t} = \\exp\\!\\left(b_i + w_i^\\top x_t + c_i^\\top s_t\\right)\\,\\Delta t,\n$$\n其中 $i \\in \\{1,\\dots,N\\}$ 索引神经元，$t \\in \\{1,\\dots,T\\}$ 索引时间窗，$s_t$ 表示已知的刺激协变量，$\\Delta t$ 表示时间窗宽度，$\\theta = \\{A, Q, m_0, V_0, b_{1:N}, w_{1:N}, c_{1:N}\\}$ 表示模型参数。将模型拟合到观测到的脉冲计数 $y = \\{y_{i t}\\}$ 后，该实验室希望使用后验预测检验来评估模型的绝对拟合优度。\n\n此任务的基础是后验预测分布和经典时间序列自相关的定义。后验预测分布是\n$$\np(\\tilde{y} \\mid y) = \\int p(\\tilde{y} \\mid x, \\theta)\\,p(x, \\theta \\mid y)\\,dx\\,d\\theta,\n$$\n它将生成似然 $p(\\tilde{y} \\mid x, \\theta)$ 在贝叶斯后验 $p(x, \\theta \\mid y)$ 上进行平均。对于每个神经元 $i$，跨时间的经验脉冲计数分布是由下式定义的非负整数上的概率质量函数\n$$\n\\hat{P}_i(k; y) = \\frac{1}{T}\\sum_{t=1}^{T} \\mathbf{1}\\{y_{i t} = k\\},\\quad k \\in \\mathbb{N}_0,\n$$\n滞后为 $\\ell$ 的样本自相关函数是\n$$\n\\hat{\\rho}_i(\\ell; y) = \\frac{\\sum_{t=1}^{T-\\ell} \\left(y_{i t} - \\hat{\\mu}_i\\right)\\left(y_{i, t+\\ell} - \\hat{\\mu}_i\\right)}{\\sum_{t=1}^{T} \\left(y_{i t} - \\hat{\\mu}_i\\right)^2},\\quad \\hat{\\mu}_i = \\frac{1}{T}\\sum_{t=1}^{T} y_{i t},\\quad \\ell \\in \\{1,\\dots,L\\},\n$$\n其中 $L$ 是一个选定的最大滞后。\n\n该实验室寻求一种程序，该程序 (i) 使用后验预测分布从拟合的模型中模拟重复数据集 $\\tilde{y}$，(ii) 比较观测数据和重复数据之间的脉冲计数分布和自相关，(iii) 通过明确定义的统计量和后验预测 p 值来量化差异。\n\n下列哪个选项描述了一种科学上有效且完整的、满足标准 (i)-(iii) 的针对此 PLDS 的后验预测检验？\n\nA. 使用例如马尔可夫链蒙特卡罗 (MCMC) 从贝叶斯后验 $p(x, \\theta \\mid y)$ 中抽取 $M$ 个样本 $\\{(x^{(m)}_{1:T}, \\theta^{(m)})\\}_{m=1}^{M}$。对于每个 $m$，通过在以 $(x^{(m)}, \\theta^{(m)})$ 为条件下，在神经元 $i$ 和时间窗 $t$ 上独立地抽取 $\\tilde{y}^{(m)}_{i t} \\sim \\text{Poisson}\\!\\left(\\exp\\!\\left(b_i^{(m)} + {w_i^{(m)}}^\\top x_t^{(m)} + {c_i^{(m)}}^\\top s_t\\right)\\,\\Delta t\\right)$ 来模拟一个完整的重复数据集 $\\tilde{y}^{(m)}$。对于每个神经元 $i$，计算观测的脉冲计数质量函数 $\\hat{P}_i(k; y)$ 和重复数据集的质量函数 $\\hat{P}_i(k; \\tilde{y}^{(m)})$，其中 $k \\in \\mathbb{N}_0$。为每个后验抽样定义一个直方图差异，\n$$\nT^{\\text{hist}}_i\\!\\left(y, \\theta^{(m)}\\right) = \\sum_{k=0}^{K_{\\max}} \\left[\\hat{P}_i(k; y) - \\hat{P}_i\\!\\left(k; \\tilde{y}^{(m)}\\right)\\right]^2,\n$$\n其中 $K_{\\max}$ 是一个截断值，其选择使得 $\\sum_{k=0}^{K_{\\max}}\\hat{P}_i(k;y) \\approx 1$。同样地，计算观测的自相关 $\\hat{\\rho}_i(\\ell; y)$ 和重复数据集的自相关 $\\hat{\\rho}_i\\!\\left(\\ell; \\tilde{y}^{(m)}\\right)$，其中 $\\ell = 1,\\dots,L$，并为每个抽样定义一个自相关差异，\n$$\nT^{\\text{acf}}_i\\!\\left(y, \\theta^{(m)}\\right) = \\sqrt{\\frac{1}{L}\\sum_{\\ell=1}^{L} \\left[\\hat{\\rho}_i(\\ell; y) - \\hat{\\rho}_i\\!\\left(\\ell; \\tilde{y}^{(m)}\\right)\\right]^2 }.\n$$\n通过后验预测 p 值来量化绝对拟合优度，\n$$\np^{\\text{hist}}_i = \\frac{1}{M}\\sum_{m=1}^{M} \\mathbf{1}\\!\\left\\{T^{\\text{hist}}_i\\!\\left(\\tilde{y}^{(m)}, \\theta^{(m)}\\right) \\ge T^{\\text{hist}}_i\\!\\left(y, \\theta^{(m)}\\right)\\right\\},\\quad\np^{\\text{acf}}_i = \\frac{1}{M}\\sum_{m=1}^{M} \\mathbf{1}\\!\\left\\{T^{\\text{acf}}_i\\!\\left(\\tilde{y}^{(m)}, \\theta^{(m)}\\right) \\ge T^{\\text{acf}}_i\\!\\left(y, \\theta^{(m)}\\right)\\right\\},\n$$\n并在神经元间进行总结（例如，通过报告 $p^{\\text{hist}}_i$ 和 $p^{\\text{acf}}_i$ 在 $i$ 上的分布）。接近 0.5 的值表示拟合充分；接近 0 或 1 的极端值表示在脉冲计数分布或自相关方面存在模型-数据差异。\n\nB. 计算一个单一的“即插即用”点估计 $\\hat{\\theta}$ 和 $\\hat{x}_{1:T}$（例如，最大后验概率估计）并从 $p(\\tilde{y} \\mid \\hat{x}, \\hat{\\theta})$ 中模拟一个数据集 $\\tilde{y}$。比较每个神经元的 $y$ 和 $\\tilde{y}$ 的样本平均发放率 $\\hat{\\mu}_i$ 和滞后为1的自相关 $\\hat{\\rho}_i(1)$，并报告差异 $\\hat{\\mu}_i(y) - \\hat{\\mu}_i(\\tilde{y})$ 和 $\\hat{\\rho}_i(1; y) - \\hat{\\rho}_i(1; \\tilde{y})$，而不对后验不确定性进行积分，也不计算任何后验预测 p 值。\n\nC. 从先验分布 $p(\\theta)\\,p(x)$ 中抽取参数和潜状态，从 $p(\\tilde{y} \\mid x, \\theta)$ 中模拟 $\\tilde{y}$，并通过在计算柯尔莫哥洛夫-斯米尔诺夫差异之前用高斯核对 $y$ 和 $\\tilde{y}$ 进行卷积来比较平滑后的脉冲直方图。对于自相关，仅计算 $\\ell=1$ 时的 $\\hat{\\rho}_i(\\ell)$，并通过绘图进行定性评估拟合，而不计算定量的后验预测 p 值。\n\nD. 使用后验平均率 $\\hat{\\lambda}_{i t} = \\mathbb{E}[\\lambda_{i t} \\mid y]$，并在时间 $t$ 上独立地模拟 $\\tilde{y}_{i t} \\sim \\text{Poisson}\\!\\left(\\hat{\\lambda}_{i t}\\right)$，忽略潜在动力学。计算零滞后下的神经元间相关性 $\\text{Corr}(y_{i t}, y_{j t})$ (对于 $i \\neq j$)，而不是每个神经元跨时间的自相关，并将观测和模拟的神经元间相关性的平均差异报告为差异度量，而不计算后验预测 p 值。\n\n选择正确阐明了后验预测检验的选项，该检验从拟合模型中模拟 $\\tilde{y}_{i t}$，并将脉冲计数分布和自相关与观测数据进行比较，定量评估差异。",
            "solution": "后验预测检验的核心在于，通过将在观测数据 $y$ 上拟合好的模型参数和潜变量的后验不确定性考虑在内，比较观测数据与模型模拟出的重复数据之间的差异。正确的流程如下：\n\n1.  **从后验分布中抽样：** 从参数 $\\theta$ 和潜状态 $x$ 的联合后验分布 $p(x, \\theta \\mid y)$ 中抽取样本。这体现了在观测到数据后，我们对模型参数和潜变量的不确定性。\n2.  **模拟重复数据集：** 对于每一个后验样本 $(x^{(m)}, \\theta^{(m)})$，从生成模型（即似然）$p(\\tilde{y} \\mid x^{(m)}, \\theta^{(m)})$ 中模拟一个完整的重复数据集 $\\tilde{y}^{(m)}$。\n3.  **计算检验统计量：** 选择一个或多个检验统计量 $T(\\cdot)$（或差异度量），这些统计量应能捕捉模型可能无法正确描述的数据特征（例如脉冲计数分布或自相关性）。对观测数据 $y$ 和每个重复数据集 $\\tilde{y}^{(m)}$ 计算这些统计量的值。\n4.  **计算p值：** 后验预测p值定义为，在所有模拟中，重复数据集的检验统计量值等于或超过观测数据检验统计量值的比例。接近0或1的p值表明，模型在所选的特征方面与数据存在系统性差异。\n\n基于此框架评估各个选项：\n\n*   **选项A** 完美地遵循了以上所有步骤。它从完整的后验分布中抽样，为每个样本模拟重复数据，定义了针对脉冲计数分布和自相关的差异统计量，并正确地构建了后验预测p值来量化模型-数据的失配程度。这是一个完整且有效的程序。\n*   **选项B** 是错误的，因为它使用了参数和状态的点估计（“即插即用”），完全忽略了后验不确定性，这是一个根本性的缺陷。它也没有计算p值进行定量评估。\n*   **选项C** 是错误的，因为它从*先验*分布而非*后验*分布中抽样。这构成的是先验预测检验，它回答的是“模型通常会产生什么样的数据”，而不是评估模型对当前观测数据的拟合优度。\n*   **选项D** 错在多个方面。它从后验平均发放率进行模拟，这不等于对后验模拟结果进行平均。更严重的是，它独立地模拟每个时间点的数据，完全破坏了PLDS模型旨在捕捉的时间动态结构，使得对自相关性的任何检验都变得无效。\n\n因此，只有选项A描述了符合要求的、科学上严谨且完整的后验预测检验程序。",
            "answer": "$$\\boxed{A}$$"
        }
    ]
}