{
    "hands_on_practices": [
        {
            "introduction": "The heart of a particle filter lies in its weight update step, where each particle is scored based on how well it explains the latest observation. This exercise focuses on deriving this crucial update for a scenario common in neuroscience—calcium imaging—where measurement noise may not follow a simple Gaussian distribution. By working through the derivation for a Laplace noise model (), you will gain first-hand insight into how the choice of likelihood function directly impacts the filter's robustness to outliers, a critical feature for analyzing real-world experimental data.",
            "id": "4184449",
            "problem": "A neuroscience laboratory employs calcium imaging to observe neuronal activity. Let the latent intracellular calcium concentration be denoted by the state variable $c_t$ at time $t$. The imaging measurement is modeled as $y_t \\approx c_t + \\epsilon_t$, where the observation noise $\\epsilon_t$ is distributed according to a Laplace distribution with zero mean and scale parameter $b0$. The calcium dynamics are nonlinear, driven by spike-dependent effects and biophysical decay, and are approximated for inference with a discrete set of $N$ particles. Specifically, suppose a bootstrap Particle Filter (PF), in which the proposal density equals the state transition density, is used to track $c_t$. At time $t-1$, a particle approximation $\\{c_{t-1}^{(i)}, w_{t-1}^{(i)}\\}_{i=1}^{N}$ to the filtering distribution is available, and after propagation through the nonlinear dynamics, one obtains predicted particles $\\{c_t^{(i)}\\}_{i=1}^{N}$ for time $t$.\n\nStarting from the principles of Bayesian filtering, the definition of a bootstrap Particle Filter (PF), and the known probability density function of the Laplace distribution, derive the normalized importance weight update at time $t$ for each particle $i$ in terms of $y_t$, $c_t^{(i)}$, $w_{t-1}^{(i)}$, and $b$. Then, explain from first principles why this update confers robustness to outliers in the measurements compared to a Gaussian observation noise model. Your final answer must be a single closed-form analytic expression for the normalized weight $w_t^{(i)}$ as a function of $y_t$, $c_t^{(i)}$, $w_{t-1}^{(i)}$, and $b$. No numerical rounding is required, and no physical units need to be reported in the answer.",
            "solution": "The problem is valid as it is scientifically grounded in computational neuroscience and statistics, well-posed, objective, and contains all necessary information for a rigorous derivation.\n\nThe objective of a Bayesian filter is to recursively estimate the posterior probability density function (PDF) of the state, $c_t$, given all measurements up to time $t$, denoted $y_{1:t}$. This posterior is $p(c_t | y_{1:t})$. The recursive estimation consists of two steps: prediction and update.\n\n1.  **Prediction**: The predicted density at time $t$ is computed based on the posterior at time $t-1$:\n    $$p(c_t | y_{1:t-1}) = \\int p(c_t | c_{t-1}) p(c_{t-1} | y_{1:t-1}) dc_{t-1}$$\n    where $p(c_t | c_{t-1})$ is the state transition model.\n\n2.  **Update**: The predicted density is updated using the new measurement $y_t$ via Bayes' rule:\n    $$p(c_t | y_{1:t}) = \\frac{p(y_t | c_t) p(c_t | y_{1:t-1})}{p(y_t | y_{1:t-1})} \\propto p(y_t | c_t) p(c_t | y_{1:t-1})$$\n    where $p(y_t | c_t)$ is the likelihood function derived from the observation model.\n\nA Particle Filter (PF) approximates these distributions using a set of $N$ weighted samples or \"particles\". The posterior at time $t-1$ is represented as:\n$$p(c_{t-1} | y_{1:t-1}) \\approx \\sum_{i=1}^{N} w_{t-1}^{(i)} \\delta(c_{t-1} - c_{t-1}^{(i)})$$\nwhere $\\delta(\\cdot)$ is the Dirac delta function, and $\\{c_{t-1}^{(i)}, w_{t-1}^{(i)}\\}_{i=1}^{N}$ is the set of particles and their associated weights, with $\\sum_{i=1}^{N} w_{t-1}^{(i)} = 1$.\n\nThe problem states that we are given the predicted particles $\\{c_t^{(i)}\\}_{i=1}^{N}$, which are obtained by propagating each particle $c_{t-1}^{(i)}$ through the (potentially stochastic) state dynamics. For a bootstrap Particle Filter, the proposal distribution for generating new particles is simply the state transition model, $q(c_t | c_{t-1}, y_t) = p(c_t | c_{t-1})$. In this simple case, the particle weights from the previous step are carried over to the predicted particles. The predicted distribution is thus approximated as:\n$$p(c_t | y_{1:t-1}) \\approx \\sum_{i=1}^{N} w_{t-1}^{(i)} \\delta(c_t - c_t^{(i)})$$\n\nThe update step involves calculating new weights, $\\tilde{w}_t^{(i)}$, for each particle based on how well it explains the new measurement $y_t$. According to the principle of importance sampling, the unnormalized weight for particle $i$ is given by the product of its prior weight and the likelihood of the measurement given the particle's state:\n$$\\tilde{w}_t^{(i)} = w_{t-1}^{(i)} p(y_t | c_t^{(i)})$$\nThe term $p(y_t | c_t^{(i)})$ is the importance weight. We must derive this from the problem statement.\n\nThe measurement model is given as $y_t \\approx c_t + \\epsilon_t$, or more formally $y_t = c_t + \\epsilon_t$. The measurement noise $\\epsilon_t$ is distributed according to a Laplace distribution with zero mean and scale parameter $b  0$. The PDF of a Laplace-distributed random variable $x$ with mean $\\mu$ and scale $b$ is:\n$$f(x | \\mu, b) = \\frac{1}{2b} \\exp\\left(-\\frac{|x-\\mu|}{b}\\right)$$\nIn our case, the random variable is the noise, $\\epsilon_t = y_t - c_t$, with mean $\\mu=0$. Therefore, the likelihood function $p(y_t | c_t)$ is the PDF of the noise evaluated at $y_t - c_t$:\n$$p(y_t | c_t) = \\frac{1}{2b} \\exp\\left(-\\frac{|y_t - c_t|}{b}\\right)$$\nFor each particle $c_t^{(i)}$, the likelihood is:\n$$p(y_t | c_t^{(i)}) = \\frac{1}{2b} \\exp\\left(-\\frac{|y_t - c_t^{(i)}|}{b}\\right)$$\nSubstituting this into the unnormalized weight update equation, we get:\n$$\\tilde{w}_t^{(i)} = w_{t-1}^{(i)} \\frac{1}{2b} \\exp\\left(-\\frac{|y_t - c_t^{(i)}|}{b}\\right)$$\nTo obtain the normalized weights $w_t^{(i)}$, we divide each unnormalized weight by the sum of all unnormalized weights:\n$$w_t^{(i)} = \\frac{\\tilde{w}_t^{(i)}}{\\sum_{j=1}^{N} \\tilde{w}_t^{(j)}} = \\frac{w_{t-1}^{(i)} \\frac{1}{2b} \\exp\\left(-\\frac{|y_t - c_t^{(i)}|}{b}\\right)}{\\sum_{j=1}^{N} w_{t-1}^{(j)} \\frac{1}{2b} \\exp\\left(-\\frac{|y_t - c_t^{(j)}|}{b}\\right)}$$\nThe constant factor $\\frac{1}{2b}$ appears in the numerator and in every term of the sum in the denominator, and thus cancels out. This leaves the final expression for the normalized weight update:\n$$w_t^{(i)} = \\frac{w_{t-1}^{(i)} \\exp\\left(-\\frac{|y_t - c_t^{(i)}|}{b}\\right)}{\\sum_{j=1}^{N} w_{t-1}^{(j)} \\exp\\left(-\\frac{|y_t - c_t^{(j)}|}{b}\\right)}$$\n\nNext, we explain from first principles why this model is more robust to outliers than a Gaussian observation model. Robustness to outliers is determined by the properties of the likelihood function $p(y_t | c_t)$. Let us compare the Laplace likelihood to a Gaussian likelihood. A Gaussian noise model with mean $0$ and variance $\\sigma^2$ would yield a likelihood:\n$$p_G(y_t | c_t) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}} \\exp\\left(-\\frac{(y_t - c_t)^2}{2\\sigma^2}\\right)$$\nThe weight assigned to a particle is proportional to this likelihood. Let the prediction error for particle $i$ be $d^{(i)} = y_t - c_t^{(i)}$.\nFor the Laplace model, the likelihood is proportional to $\\exp(-|d^{(i)}|/b)$.\nFor the Gaussian model, the likelihood is proportional to $\\exp(-(d^{(i)})^2/(2\\sigma^2))$.\n\nAn outlier is a measurement $y_t$ that is far from the true state, and thus far from the cloud of predicted particles $\\{c_t^{(i)}\\}$. This means the magnitude of the error, $|d^{(i)}|$, is large for the majority of particles.\n\nIn the Gaussian case, the likelihood penalty term in the exponent is quadratic in the error, $(d^{(i)})^2$. As $|d^{(i)}|$ increases, this penalty term grows very rapidly. Consequently, the likelihood value plummets towards zero exceptionally fast. If an outlier measurement occurs, all particles that are consistent with the prior dynamics (and thus far from the outlier) will be assigned near-zero weights. The filter will be forced to assign significant weight only to the few (or single) stray particles that happen to be near the outlier, potentially causing the filter to lose track of the true state entirely. This phenomenon is a consequence of the very thin tails of the Gaussian distribution, which implicitly assumes that large errors are virtually impossible.\n\nIn the Laplace case, the likelihood penalty term is linear in the error's magnitude, $|d^{(i)}|$. As $|d^{(i)}|$ increases, this penalty grows only linearly, which is much slower than the quadratic growth in the Gaussian model. Consequently, the likelihood decays exponentially, but much more slowly. When an outlier occurs, particles consistent with the prior dynamics will see their weights reduced, but not to the catastrophic near-zero values seen in the Gaussian model. They retain non-trivial weights, allowing the filter to \"distrust\" the outlier measurement and maintain its track on the true state. This robustness stems from the heavier tails of the Laplace distribution, which assigns a higher probability to large-error events (outliers) than the Gaussian distribution does. From a first-principles standpoint, choosing a Laplace observation model is equivalent to stating a prior belief that measurements can be corrupted by outliers, whereas a Gaussian model reflects a belief that such events are exceedingly rare.",
            "answer": "$$\\boxed{\\frac{w_{t-1}^{(i)} \\exp\\left(-\\frac{|y_t - c_t^{(i)}|}{b}\\right)}{\\sum_{j=1}^{N} w_{t-1}^{(j)} \\exp\\left(-\\frac{|y_t - c_t^{(j)}|}{b}\\right)}}$$"
        },
        {
            "introduction": "After weighting, the resampling step is essential for combating particle degeneracy, but it also introduces sampling variability that can degrade filter performance. This practice delves into the statistical properties of this crucial step, comparing two common methods: multinomial and stratified resampling. By deriving the variance of the particle offspring count (), you will develop a rigorous understanding of why stratified resampling is generally preferred and how it contributes to a more stable and efficient filter.",
            "id": "4184410",
            "problem": "A neuroscientist is using a Sequential Importance Resampling (SIR) particle filter to infer a latent synaptic drive that modulates a neuron's spiking intensity in a nonlinear, non-Gaussian state-space model. After the weighting step at a given time, there are $N$ particles with normalized weights $\\tilde{w}_{1},\\ldots,\\tilde{w}_{N}$, where $\\tilde{w}_{i} \\ge 0$ and $\\sum_{i=1}^{N} \\tilde{w}_{i} = 1$. The resampling step allocates an integer offspring count $N_{i}$ to each particle $i \\in \\{1,\\ldots,N\\}$, with $\\sum_{i=1}^{N} N_{i} = N$, to form the next generation.\n\nYou will analyze the variability of $N_{i}$ under two standard resampling schemes using only core probability tools.\n\n1) Under multinomial resampling, the algorithm performs $N$ independent draws with replacement from the categorical distribution on $\\{1,\\ldots,N\\}$ with probabilities $\\tilde{w}_{1},\\ldots,\\tilde{w}_{N}$. Starting from the indicator-variable decomposition of $N_{i}$ and the variance properties of sums of independent Bernoulli random variables, derive a closed-form expression for $\\mathrm{Var}(N_{i})$ in terms of $N$ and $\\tilde{w}_{i}$. Your final answer must be a single analytic expression.\n\n2) Under stratified resampling, the algorithm draws $U_{j} = \\frac{j-1+V_{j}}{N}$ with $V_{j} \\stackrel{\\mathrm{iid}}{\\sim} \\mathrm{Uniform}(0,1)$ for $j \\in \\{1,\\ldots,N\\}$, and assigns each $U_{j}$ to index $i$ such that $U_{j} \\in (C_{i-1}, C_{i}]$, where $C_{k} = \\sum_{m=1}^{k} \\tilde{w}_{m}$ and $C_{0}=0$. Using only the independence of the $U_{j}$ and the fact that $U_{j}$ is uniform on the interval $\\left(\\frac{j-1}{N}, \\frac{j}{N}\\right]$, express $\\mathrm{Var}(N_{i})$ in terms of overlap lengths between $(C_{i-1}, C_{i}]$ and the strata $\\left(\\frac{j-1}{N}, \\frac{j}{N}\\right]$. Then, using basic inequalities for sums of squares, argue rigorously that the stratified variance is no larger than your answer from part $1)$, and identify when strict inequality holds.\n\nAnswer specification: Provide only the expression you derived for $\\mathrm{Var}(N_{i})$ under multinomial resampling in part $1)$ as your final answer. Do not include units. No rounding is required.",
            "solution": "The problem asks for an analysis of the variance of the offspring count $N_i$ for a particle $i$ under two different resampling schemes: multinomial and stratified.\n\nPart 1: Multinomial Resampling\n\nUnder multinomial resampling, the new set of $N$ particles is formed by drawing $N$ times independently and with replacement from the old set of particles $\\{1, \\ldots, N\\}$. The probability of drawing particle $i$ in any single draw is given by its normalized weight, $\\tilde{w}_i$. The random variable $N_i$ represents the total number of times particle $i$ is chosen in these $N$ draws.\n\nTo find the variance of $N_i$, denoted $\\mathrm{Var}(N_i)$, we follow the problem's suggestion to use an indicator-variable decomposition. Let $I_j$ be an indicator random variable for the $j$-th draw, where $j \\in \\{1, \\ldots, N\\}$. We define $I_j=1$ if particle $i$ is selected on the $j$-th draw, and $I_j=0$ otherwise.\n\nThe total count for particle $i$ is the sum of these indicators over all $N$ draws:\n$$\nN_i = \\sum_{j=1}^{N} I_j\n$$\nEach draw is a Bernoulli trial with a \"success\" probability of $p = P(I_j=1) = \\tilde{w}_i$. The outcome of each draw is independent of the others. Therefore, the random variables $I_1, I_2, \\ldots, I_N$ are independent and identically distributed (i.i.d.) Bernoulli random variables, with $I_j \\sim \\mathrm{Bernoulli}(\\tilde{w}_i)$.\n\nThe variance of a single Bernoulli random variable $I_j$ is given by:\n$$\n\\mathrm{Var}(I_j) = p(1-p) = \\tilde{w}_i(1-\\tilde{w}_i)\n$$\nA fundamental property of variance is that for a sum of independent random variables, the variance of the sum is the sum of the variances. Thus,\n$$\n\\mathrm{Var}(N_i) = \\mathrm{Var}\\left(\\sum_{j=1}^{N} I_j\\right) = \\sum_{j=1}^{N} \\mathrm{Var}(I_j)\n$$\nSince the variables $I_j$ are identically distributed, their variances are all equal. Therefore, the sum simplifies to:\n$$\n\\mathrm{Var}(N_i) = N \\cdot \\mathrm{Var}(I_1) = N \\tilde{w}_i(1-\\tilde{w}_i)\n$$\nThis is the closed-form expression for the variance of the offspring count $N_i$ under multinomial resampling. This derivation also confirms that $N_i$ follows a binomial distribution, $N_i \\sim \\mathrm{Binomial}(N, \\tilde{w}_i)$, for which this variance formula is a standard result.\n\nPart 2: Stratified Resampling and Comparison\n\nUnder stratified resampling, the interval $(0, 1]$ is partitioned into $N$ disjoint strata $S_j = \\left(\\frac{j-1}{N}, \\frac{j}{N}\\right]$ for $j \\in \\{1, \\ldots, N\\}$. One uniform random sample $U_j$ is drawn from each stratum. The offspring count $N_i$ for particle $i$ is the number of samples $U_j$ that fall into the cumulative weight interval for particle $i$, which is $I_i = (C_{i-1}, C_i]$ where $C_k = \\sum_{m=1}^{k} \\tilde{w}_m$. The length of this interval is $\\text{length}(I_i) = C_i - C_{i-1} = \\tilde{w}_i$.\n\nThe offspring count can be written as a sum of indicator variables:\n$$\nN_i = \\sum_{j=1}^{N} J_j, \\quad \\text{where } J_j = \\mathbf{1}_{I_i}(U_j) = \\begin{cases} 1  \\text{if } U_j \\in I_i \\\\ 0  \\text{otherwise} \\end{cases}\n$$\nThe draws $U_j$ are independent, which means the indicator variables $J_j$ are also independent. The variance of $N_i$ is again the sum of the variances:\n$$\n\\mathrm{Var}(N_i)_{\\text{strat}} = \\sum_{j=1}^{N} \\mathrm{Var}(J_j)\n$$\nEach $J_j$ is a Bernoulli random variable. Let $p_{ij} = P(J_j=1) = P(U_j \\in I_i)$. Since $U_j$ is uniform on $S_j$, a stratum of length $1/N$, this probability is the ratio of the length of the intersection of the two intervals to the length of the stratum:\n$$\np_{ij} = \\frac{\\text{length}(I_i \\cap S_j)}{\\text{length}(S_j)} = \\frac{\\text{length}(I_i \\cap S_j)}{1/N} = N \\cdot \\text{length}(I_i \\cap S_j)\n$$\nThe variance of each $J_j$ is $\\mathrm{Var}(J_j) = p_{ij}(1-p_{ij})$. Thus, the total variance is:\n$$\n\\mathrm{Var}(N_i)_{\\text{strat}} = \\sum_{j=1}^{N} p_{ij}(1-p_{ij})\n$$\nThis is the expression for the stratified variance in terms of overlap lengths. Now we compare this to the multinomial variance. The expected value of $N_i$ under this scheme is $E[N_i]_{\\text{strat}} = \\sum_{j=1}^{N} E[J_j] = \\sum_{j=1}^{N} p_{ij}$. Since the strata $\\{S_j\\}$ form a partition of $(0, 1]$, the sum of the lengths of the intersections is the length of $I_i$ itself: $\\sum_{j=1}^{N} \\text{length}(I_i \\cap S_j) = \\text{length}(I_i) = \\tilde{w}_i$. Therefore, $E[N_i]_{\\text{strat}} = \\sum_{j=1}^{N} N \\cdot \\text{length}(I_i \\cap S_j) = N \\tilde{w}_i$, confirming the scheme is unbiased, same as the multinomial scheme.\n\nWe can rewrite the variances as:\n$$\n\\mathrm{Var}(N_i)_{\\text{multi}} = N\\tilde{w}_i - N\\tilde{w}_i^2\n$$\n$$\n\\mathrm{Var}(N_i)_{\\text{strat}} = \\sum_{j=1}^{N} p_{ij} - \\sum_{j=1}^{N} p_{ij}^2 = N\\tilde{w}_i - \\sum_{j=1}^{N} p_{ij}^2\n$$\nTo show that $\\mathrm{Var}(N_i)_{\\text{strat}} \\le \\mathrm{Var}(N_i)_{\\text{multi}}$, we must show that $N\\tilde{w}_i - \\sum_{j=1}^{N} p_{ij}^2 \\le N\\tilde{w}_i - N\\tilde{w}_i^2$, which is equivalent to proving:\n$$\n\\sum_{j=1}^{N} p_{ij}^2 \\ge N\\tilde{w}_i^2\n$$\nWe know that $\\sum_{j=1}^{N} p_{ij} = N\\tilde{w}_i$. Let $\\mathbf{p}_i = (p_{i1}, p_{i2}, \\ldots, p_{iN})$ and $\\mathbf{1} = (1, 1, \\ldots, 1)$ be vectors in $\\mathbb{R}^N$. The Cauchy-Schwarz inequality states that $(\\mathbf{p}_i \\cdot \\mathbf{1})^2 \\le \\|\\mathbf{p}_i\\|^2 \\|\\mathbf{1}\\|^2$. Applying this:\n$$\n\\left(\\sum_{j=1}^{N} p_{ij}\\right)^2 \\le \\left(\\sum_{j=1}^{N} p_{ij}^2\\right) \\left(\\sum_{j=1}^{N} 1^2\\right)\n$$\nSubstituting the known quantities:\n$$\n(N\\tilde{w}_i)^2 \\le \\left(\\sum_{j=1}^{N} p_{ij}^2\\right) (N)\n$$\n$$\nN^2\\tilde{w}_i^2 \\le N \\sum_{j=1}^{N} p_{ij}^2\n$$\nDividing by $N$ (since $N \\ge 1$) yields the desired inequality:\n$$\nN\\tilde{w}_i^2 \\le \\sum_{j=1}^{N} p_{ij}^2\n$$\nThis rigorously proves that $\\mathrm{Var}(N_i)_{\\text{strat}} \\le \\mathrm{Var}(N_i)_{\\text{multi}}$.\n\nStrict inequality holds if the equality condition for the Cauchy-Schwarz inequality is not met. Equality holds if and only if one vector is a scalar multiple of the other, i.e., $\\mathbf{p}_i = c \\mathbf{1}$ for some scalar $c$. This means $p_{i1} = p_{i2} = \\ldots = p_{iN}$. This condition implies that the overlap of the interval $I_i$ with each stratum $S_j$ is identical. This can only happen in the trivial cases where $\\tilde{w}_i=0$ (all $p_{ij}=0$) or $\\tilde{w}_i=1$ (all $p_{ij}=1$). In all non-trivial cases, where $0  \\tilde{w}_i  1$, the interval $I_i$ will not overlap with all strata equally (it will fully contain some, partially overlap others, and not overlap some at all). Thus, the values of $p_{ij}$ will not all be equal, and the inequality will be strict. Therefore, $\\mathrm{Var}(N_i)_{\\text{strat}}  \\mathrm{Var}(N_i)_{\\text{multi}}$ for any particle $i$ with weight $0  \\tilde{w}_i  1$.",
            "answer": "$$\\boxed{N \\tilde{w}_{i} (1 - \\tilde{w}_{i})}$$"
        },
        {
            "introduction": "A key strength of the state-space framework is its ability to model complex, realistic data-generating processes, including imperfections in the measurement itself. This problem addresses a frequent challenge in electrophysiology: spike sorting errors or detection failures, where the observed spike count is only a fraction of the true underlying activity. You will practice the essential technique of marginalization to derive the correct observation likelihood (), demonstrating how to properly account for latent variables within the observation model.",
            "id": "4184375",
            "problem": "A neural population latent state $\\{x_t\\}_{t=1}^T$ evolves according to a nonlinear Markov process with transition density $p(x_t \\mid x_{t-1})$, where $x_t \\in \\mathbb{R}^d$ represents a low-dimensional latent firing rate trajectory. The observation process at time $t$ proceeds as follows:\n\n1. Conditional on $x_t$, the true spike count $y_t \\in \\mathbb{N}_0$ is generated according to a point process with intensity $\\lambda_t = \\lambda(x_t)$, and for this problem you may assume a canonical spike count model $y_t \\mid x_t \\sim \\mathrm{Poisson}(\\lambda_t)$, with $\\lambda_t  0$.\n\n2. Due to spike sorting failures, each true spike is independently detected with probability $q_t \\in (0,1)$, yielding an observed count $z_t \\in \\mathbb{N}_0$. Formally, $z_t \\mid y_t \\sim \\mathrm{Binomial}(y_t, q_t)$.\n\nYou implement a bootstrap Sequential Monte Carlo (SMC) particle filter, in which the proposal distribution equals the transition density $p(x_t \\mid x_{t-1})$. Let $\\{x_t^{(i)}, w_{t-1}^{(i)}\\}_{i=1}^N$ denote the particles propagated to time $t$ with previous weights $w_{t-1}^{(i)}$. The bootstrap weight update is defined by Bayes’ rule and the SMC construction as $w_t^{(i)} \\propto w_{t-1}^{(i)} \\, p(z_t \\mid x_t^{(i)})$, where the observation likelihood $p(z_t \\mid x_t^{(i)})$ must marginalize over the unobserved $y_t$.\n\nStarting from the definitions of the Poisson and Binomial models and Bayes’ rule, and without invoking any shortcut formulas, determine the correct expression for the marginalized observation likelihood $p(z_t \\mid x_t^{(i)})$ that should be used in the particle weight update. Assume $\\lambda_t^{(i)} = \\lambda(x_t^{(i)})$ is known once $x_t^{(i)}$ is given, and $q_t$ is known from spike sorting quality metrics.\n\nWhich option correctly gives $p(z_t \\mid x_t^{(i)})$?\n\nA. $p(z_t \\mid x_t^{(i)}) = \\dfrac{\\exp\\!\\big(- q_t \\lambda_t^{(i)}\\big) \\, \\big(q_t \\lambda_t^{(i)}\\big)^{z_t}}{z_t!}$\n\nB. $p(z_t \\mid x_t^{(i)}) = \\binom{\\lambda_t^{(i)}}{z_t} \\, q_t^{z_t} \\, (1 - q_t)^{\\lambda_t^{(i)} - z_t}$\n\nC. $p(z_t \\mid x_t^{(i)}) = \\dfrac{\\exp\\!\\big(- \\lambda_t^{(i)}\\big) \\, \\big(\\lambda_t^{(i)}\\big)^{z_t}}{z_t!}$\n\nD. $p(z_t \\mid x_t^{(i)}) = (1 - q_t) \\, \\delta_{z_t, 0} + q_t \\, \\dfrac{\\exp\\!\\big(- \\lambda_t^{(i)}\\big) \\, \\big(\\lambda_t^{(i)}\\big)^{z_t}}{z_t!}$\n\nHere, $\\delta_{z_t, 0}$ denotes the Kronecker delta, equal to $1$ if $z_t = 0$ and $0$ otherwise.",
            "solution": "The problem statement is critically validated as scientifically grounded, well-posed, and objective. It describes a standard hierarchical Bayesian state-space model used in computational neuroscience, where a latent state (firing rate) is estimated from observed spike counts that are subject to a detection failure process. The probabilistic models (Poisson and Binomial) are canonical choices for this scenario. The problem is self-contained and provides all necessary information to perform the requested derivation. No flaws are identified.\n\nThe objective is to derive the marginalized observation likelihood, $p(z_t \\mid x_t^{(i)})$, which is required for the weight update step in a bootstrap particle filter. This requires marginalizing out the unobserved true spike count, $y_t$.\n\nFor clarity and without loss of generality, we will drop the time subscript $t$ and the particle index $i$ during the derivation. We are given the following conditional distributions:\n$1$. The true spike count $y$, conditional on the latent state $x$, follows a Poisson distribution with rate $\\lambda = \\lambda(x)$. The probability mass function (PMF) is:\n$$p(y \\mid x) = \\frac{\\exp(-\\lambda) \\lambda^y}{y!}, \\quad \\text{for } y \\in \\{0, 1, 2, \\dots\\}$$\n$2$. The observed spike count $z$, conditional on the true count $y$, follows a Binomial distribution. This models a \"thinning\" process where each of the $y$ true spikes is detected independently with probability $q$. The PMF is:\n$$p(z \\mid y) = \\binom{y}{z} q^z (1-q)^{y-z}, \\quad \\text{for } z \\in \\{0, 1, \\dots, y\\}$$\nNote that $p(z \\mid y) = 0$ if $z  y$. The problem statement also implies that given $y$, the observed count $z$ is conditionally independent of the latent state $x$, i.e., $p(z \\mid y, x) = p(z \\mid y)$.\n\nTo find the desired likelihood $p(z \\mid x)$, we must integrate (or, for discrete variables, sum) over all possible values of the latent variable $y$:\n$$p(z \\mid x) = \\sum_{y=0}^{\\infty} p(z, y \\mid x)$$\nUsing the chain rule of probability, $p(z, y \\mid x) = p(z \\mid y, x) p(y \\mid x)$. As established, this simplifies to $p(z \\mid y)p(y \\mid x)$.\n$$p(z \\mid x) = \\sum_{y=0}^{\\infty} p(z \\mid y) p(y \\mid x)$$\nWe now substitute the PMFs of the Binomial and Poisson distributions into this summation:\n$$p(z \\mid x) = \\sum_{y=0}^{\\infty} \\left[ \\binom{y}{z} q^z (1-q)^{y-z} \\right] \\left[ \\frac{\\exp(-\\lambda) \\lambda^y}{y!} \\right]$$\nThe binomial coefficient $\\binom{y}{z}$ is zero for $y  z$. Therefore, the summation can start from $y = z$:\n$$p(z \\mid x) = \\sum_{y=z}^{\\infty} \\left[ \\frac{y!}{z!(y-z)!} q^z (1-q)^{y-z} \\right] \\left[ \\frac{\\exp(-\\lambda) \\lambda^y}{y!} \\right]$$\nThe term $y!$ in the numerator of the binomial coefficient and the denominator of the Poisson PMF cancel out:\n$$p(z \\mid x) = \\sum_{y=z}^{\\infty} \\frac{1}{z!(y-z)!} q^z (1-q)^{y-z} \\exp(-\\lambda) \\lambda^y$$\nWe can pull terms that do not depend on the summation index $y$ out of the sum:\n$$p(z \\mid x) = \\frac{\\exp(-\\lambda) q^z}{z!} \\sum_{y=z}^{\\infty} \\frac{1}{(y-z)!} (1-q)^{y-z} \\lambda^y$$\nTo simplify the term $\\lambda^y$ inside the sum, we can rewrite it as $\\lambda^y = \\lambda^z \\lambda^{y-z}$ and move the $\\lambda^z$ factor outside the summation:\n$$p(z \\mid x) = \\frac{\\exp(-\\lambda) q^z \\lambda^z}{z!} \\sum_{y=z}^{\\infty} \\frac{(1-q)^{y-z} \\lambda^{y-z}}{(y-z)!}$$\nCombining the terms outside the sum, we get:\n$$p(z \\mid x) = \\frac{\\exp(-\\lambda) (q\\lambda)^z}{z!} \\sum_{y=z}^{\\infty} \\frac{((1-q)\\lambda)^{y-z}}{(y-z)!}$$\nLet us perform a change of variables for the summation index, with $k = y - z$. When $y = z$, $k = 0$. As $y \\to \\infty$, $k \\to \\infty$. The summation becomes:\n$$\\sum_{k=0}^{\\infty} \\frac{((1-q)\\lambda)^k}{k!}$$\nThis is the Taylor series expansion of the exponential function, $\\exp(\\alpha) = \\sum_{k=0}^{\\infty} \\frac{\\alpha^k}{k!}$, with $\\alpha = (1-q)\\lambda$. Therefore, the sum is equal to $\\exp((1-q)\\lambda)$.\n\nSubstituting this result back into our expression for $p(z \\mid x)$:\n$$p(z \\mid x) = \\frac{\\exp(-\\lambda) (q\\lambda)^z}{z!} \\exp((1-q)\\lambda)$$\nNow, we simplify the exponential terms:\n$$p(z \\mid x) = \\frac{(q\\lambda)^z}{z!} \\exp(-\\lambda + (1-q)\\lambda) = \\frac{(q\\lambda)^z}{z!} \\exp(-\\lambda + \\lambda - q\\lambda) = \\frac{(q\\lambda)^z}{z!} \\exp(-q\\lambda)$$\nThis is the PMF of a Poisson distribution with a new rate parameter equal to $q\\lambda$. This is a well-known result known as the thinning property of Poisson processes. Reintroducing the particle and time indices, we have $\\lambda_t^{(i)} = \\lambda(x_t^{(i)})$ and $q_t$. The final expression for the marginalized likelihood is:\n$$p(z_t \\mid x_t^{(i)}) = \\frac{\\exp(-q_t \\lambda_t^{(i)}) (q_t \\lambda_t^{(i)})^{z_t}}{z_t!}$$\n\nNow we evaluate the given options.\n\nA. $p(z_t \\mid x_t^{(i)}) = \\dfrac{\\exp\\!\\big(- q_t \\lambda_t^{(i)}\\big) \\, \\big(q_t \\lambda_t^{(i)}\\big)^{z_t}}{z_t!}$\nThis expression exactly matches our derived result. It is the PMF of a Poisson distribution with rate $q_t \\lambda_t^{(i)}$.\n**Verdict: Correct**\n\nB. $p(z_t \\mid x_t^{(i)}) = \\binom{\\lambda_t^{(i)}}{z_t} \\, q_t^{z_t} \\, (1 - q_t)^{\\lambda_t^{(i)} - z_t}$\nThis is the PMF for a Binomial distribution $\\mathrm{Binomial}(\\lambda_t^{(i)}, q_t)$. This is incorrect for two primary reasons. First, the number of trials in the binomial model must be an integer, but $\\lambda_t^{(i)}$ is a rate parameter and a real number. Second, the true number of spikes, $y_t$, is a random variable, not a fixed parameter $\\lambda_t^{(i)}$.\n**Verdict: Incorrect**\n\nC. $p(z_t \\mid x_t^{(i)}) = \\dfrac{\\exp\\!\\big(- \\lambda_t^{(i)}\\big) \\, \\big(\\lambda_t^{(i)}\\big)^{z_t}}{z_t!}$\nThis is the PMF of a Poisson distribution with rate $\\lambda_t^{(i)}$. This expression represents $p(y_t = z_t \\mid x_t^{(i)})$, the probability that the true number of spikes equals the observed number. It completely ignores the observation process where spikes can be missed (i.e., it assumes $q_t=1$).\n**Verdict: Incorrect**\n\nD. $p(z_t \\mid x_t^{(i)}) = (1 - q_t) \\, \\delta_{z_t, 0} + q_t \\, \\dfrac{\\exp\\!\\big(- \\lambda_t^{(i)}\\big) \\, \\big(\\lambda_t^{(i)}\\big)^{z_t}}{z_t!}$\nThis describes a mixture model, suggesting that with probability $1-q_t$ the observation is zero, and with probability $q_t$ it follows the original Poisson process. This is a different model from the one described, which involves thinning each individual spike, not switching between two outcomes for the entire observation. The derived Poisson($q_t\\lambda_t^{(i)}$) distribution has a different functional form. For $z_t=0$, this option gives $p(z_t=0 \\mid x_t^{(i)}) = (1 - q_t) + q_t \\exp(-\\lambda_t^{(i)})$, whereas the correct probability is $\\exp(-q_t \\lambda_t^{(i)})$. These are not equal in general.\n**Verdict: Incorrect**\n\nTherefore, only option A provides the correct mathematical form for the marginalized observation likelihood.",
            "answer": "$$\\boxed{A}$$"
        }
    ]
}