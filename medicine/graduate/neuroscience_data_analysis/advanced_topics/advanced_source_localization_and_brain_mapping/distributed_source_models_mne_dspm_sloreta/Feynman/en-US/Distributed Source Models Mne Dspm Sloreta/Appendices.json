{
    "hands_on_practices": [
        {
            "introduction": "A central challenge in all distributed source models is managing the trade-off between fitting the measured data and maintaining a plausible, simple source estimate. This balance is governed by the regularization parameter, $\\lambda$, which directly influences the spatial resolution and amplitude accuracy of the resulting source map. This exercise provides a concrete, quantitative look at this fundamental trade-off by analyzing how $\\lambda$ affects the point-spread function in a simple two-source system, revealing the direct relationship between regularization, spatial leakage, and amplitude bias .",
            "id": "4157012",
            "problem": "Consider the linear forward model of magnetoencephalography/electroencephalography (MEG/EEG) distributed source imaging, where the sensor measurements $y \\in \\mathbb{R}^{m}$ are related to the cortical sources $x \\in \\mathbb{R}^{n}$ by $y = L x + n$, with $L \\in \\mathbb{R}^{m \\times n}$ the lead-field matrix and $n$ zero-mean Gaussian sensor noise that has been whitened so that its covariance is the identity. The Minimum Norm Estimate (MNE) solves $\\hat{x} = \\arg\\min_{x} \\|y - L x\\|_{2}^{2} + \\lambda \\|x\\|_{2}^{2}$ and yields the linear estimator $\\hat{x} = G(\\lambda) y$ with $G(\\lambda) = (L^{\\top} L + \\lambda I)^{-1} L^{\\top}$. The point-spread function (PSF) is characterized by the resolution matrix $R(\\lambda) = G(\\lambda) L = (L^{\\top} L + \\lambda I)^{-1} L^{\\top} L$. Dynamic Statistical Parametric Mapping (dSPM) and standardized Low Resolution Electromagnetic Tomography (sLORETA) are diagonal normalizations of the MNE that rescale the amplitudes of $\\hat{x}$, but the spatial spread embodied in $R(\\lambda)$ originates from the same Tikhonov regularization trade-off.\n\nTo analyze how the regularization parameter $\\lambda$ trades off PSF width versus amplitude bias, consider an idealized two-source system ($n=2$) whose lead-field columns are unit-norm and have mutual correlation $\\rho \\in [0,1)$, so that the Gram matrix is $L^{\\top} L = \\begin{pmatrix} 1 & \\rho \\\\ \\rho & 1 \\end{pmatrix}$. Assume a unit-amplitude focal source at index $1$, so the PSF is the first column of $R(\\lambda)$. Define the amplitude bias at the true location by $R_{11}(\\lambda)$ and a two-point width proxy by the leakage-to-peak ratio $w(\\lambda) = R_{21}(\\lambda) / R_{11}(\\lambda)$.\n\nStarting from these definitions and the stated model, derive a closed-form analytic expression for $w(\\lambda)$ in terms of $\\lambda$ and $\\rho$, and use it to obtain the limiting behaviors as $\\lambda \\to 0$ and as $\\lambda \\to \\infty$. Express your final answer as the single closed-form formula $w(\\lambda)$ in terms of $\\lambda$ and $\\rho$. No rounding is required.",
            "solution": "The problem is well-defined, scientifically grounded, and possesses a unique, derivable solution. All necessary information is provided.\n\nThe starting point is the definition of the resolution matrix, $R(\\lambda)$, which characterizes the point-spread function (PSF) of the Minimum Norm Estimate (MNE) inverse operator. It is given by $R(\\lambda) = (L^{\\top} L + \\lambda I)^{-1} L^{\\top} L$, where $L$ is the lead-field matrix, $\\lambda > 0$ is the Tikhonov regularization parameter, and $I$ is the identity matrix. The problem considers an idealized system with $n=2$ sources, where the Gram matrix $L^{\\top} L$ is given as:\n$$\nL^{\\top} L = \\begin{pmatrix} 1 & \\rho \\\\ \\rho & 1 \\end{pmatrix}\n$$\nwhere $\\rho \\in [0,1)$ is the correlation between the two lead-field columns.\n\nOur first step is to compute the matrix $(L^{\\top} L + \\lambda I)^{-1}$. Let $A = L^{\\top} L$. We need to compute $(A + \\lambda I)^{-1}$.\n$$\nA + \\lambda I = \\begin{pmatrix} 1 & \\rho \\\\ \\rho & 1 \\end{pmatrix} + \\lambda \\begin{pmatrix} 1 & 0 \\\\ 0 & 1 \\end{pmatrix} = \\begin{pmatrix} 1+\\lambda & \\rho \\\\ \\rho & 1+\\lambda \\end{pmatrix}\n$$\nTo find the inverse of this $2 \\times 2$ matrix, we first compute its determinant:\n$$\n\\det(A + \\lambda I) = (1+\\lambda)(1+\\lambda) - \\rho \\cdot \\rho = (1+\\lambda)^2 - \\rho^2\n$$\nThe inverse is then given by:\n$$\n(A + \\lambda I)^{-1} = (L^{\\top} L + \\lambda I)^{-1} = \\frac{1}{(1+\\lambda)^2 - \\rho^2} \\begin{pmatrix} 1+\\lambda & -\\rho \\\\ -\\rho & 1+\\lambda \\end{pmatrix}\n$$\nNote that since $\\rho \\in [0,1)$, we have $\\rho^2 < 1$. For any $\\lambda > 0$, we have $1+\\lambda > 1 > \\rho$, so $(1+\\lambda)^2 - \\rho^2 > 0$, and the inverse is always well-defined.\n\nNext, we compute the resolution matrix $R(\\lambda)$:\n$$\nR(\\lambda) = (L^{\\top} L + \\lambda I)^{-1} (L^{\\top} L) = \\frac{1}{(1+\\lambda)^2 - \\rho^2} \\begin{pmatrix} 1+\\lambda & -\\rho \\\\ -\\rho & 1+\\lambda \\end{pmatrix} \\begin{pmatrix} 1 & \\rho \\\\ \\rho & 1 \\end{pmatrix}\n$$\nPerforming the matrix multiplication:\n$$\n\\begin{pmatrix} 1+\\lambda & -\\rho \\\\ -\\rho & 1+\\lambda \\end{pmatrix} \\begin{pmatrix} 1 & \\rho \\\\ \\rho & 1 \\end{pmatrix} = \\begin{pmatrix} (1+\\lambda)(1) + (-\\rho)(\\rho) & (1+\\lambda)(\\rho) + (-\\rho)(1) \\\\ (-\\rho)(1) + (1+\\lambda)(\\rho) & (-\\rho)(\\rho) + (1+\\lambda)(1) \\end{pmatrix}\n$$\n$$\n= \\begin{pmatrix} 1+\\lambda - \\rho^2 & \\lambda\\rho \\\\ \\lambda\\rho & 1+\\lambda - \\rho^2 \\end{pmatrix}\n$$\nSubstituting this back into the expression for $R(\\lambda)$:\n$$\nR(\\lambda) = \\frac{1}{(1+\\lambda)^2 - \\rho^2} \\begin{pmatrix} 1+\\lambda - \\rho^2 & \\lambda\\rho \\\\ \\lambda\\rho & 1+\\lambda - \\rho^2 \\end{pmatrix}\n$$\nThe problem states that the PSF for a unit-amplitude source at index $1$ is the first column of $R(\\lambda)$. The amplitude bias at the true location is $R_{11}(\\lambda)$ and the leakage to the second source is $R_{21}(\\lambda)$. From the matrix $R(\\lambda)$, we can identify these elements:\n$$\nR_{11}(\\lambda) = \\frac{1+\\lambda - \\rho^2}{(1+\\lambda)^2 - \\rho^2}\n$$\n$$\nR_{21}(\\lambda) = \\frac{\\lambda\\rho}{(1+\\lambda)^2 - \\rho^2}\n$$\nThe width proxy $w(\\lambda)$ is defined as the leakage-to-peak ratio, $w(\\lambda) = R_{21}(\\lambda) / R_{11}(\\lambda)$. We can now compute this ratio:\n$$\nw(\\lambda) = \\frac{\\frac{\\lambda\\rho}{(1+\\lambda)^2 - \\rho^2}}{\\frac{1+\\lambda - \\rho^2}{(1+\\lambda)^2 - \\rho^2}}\n$$\nThe denominator term $(1+\\lambda)^2 - \\rho^2$ cancels out, provided that the numerator term $1+\\lambda - \\rho^2$ is non-zero. Since $\\lambda > 0$ and $\\rho^2 < 1$, we have $1 - \\rho^2 > 0$, so $1+\\lambda-\\rho^2 > 0$. Therefore, we arrive at the closed-form analytic expression:\n$$\nw(\\lambda) = \\frac{\\lambda\\rho}{1+\\lambda - \\rho^2}\n$$\nThis is the required expression for the width proxy.\n\nThe problem also asks for the limiting behaviors.\nFirst, consider the limit as $\\lambda \\to 0$:\n$$\n\\lim_{\\lambda \\to 0} w(\\lambda) = \\lim_{\\lambda \\to 0} \\frac{\\lambda\\rho}{1+\\lambda - \\rho^2} = \\frac{0 \\cdot \\rho}{1+0 - \\rho^2} = \\frac{0}{1 - \\rho^2} = 0\n$$\nThis result indicates that for very small regularization, the PSF becomes perfectly localized, with no leakage to the neighboring source.\n\nNext, consider the limit as $\\lambda \\to \\infty$:\n$$\n\\lim_{\\lambda \\to \\infty} w(\\lambda) = \\lim_{\\lambda \\to \\infty} \\frac{\\lambda\\rho}{1+\\lambda - \\rho^2}\n$$\nThis is a limit of a ratio of polynomials in $\\lambda$. We can divide the numerator and the denominator by the highest power of $\\lambda$, which is $\\lambda^1$:\n$$\n\\lim_{\\lambda \\to \\infty} \\frac{\\frac{\\lambda\\rho}{\\lambda}}{\\frac{1+\\lambda - \\rho^2}{\\lambda}} = \\lim_{\\lambda \\to \\infty} \\frac{\\rho}{\\frac{1}{\\lambda} + 1 - \\frac{\\rho^2}{\\lambda}}\n$$\nAs $\\lambda \\to \\infty$, the terms $\\frac{1}{\\lambda}$ and $\\frac{\\rho^2}{\\lambda}$ both approach $0$. Therefore, the limit is:\n$$\n\\lim_{\\lambda \\to \\infty} w(\\lambda) = \\frac{\\rho}{0 + 1 - 0} = \\rho\n$$\nThis result indicates that for very strong regularization, the spatial smearing (width) of the PSF becomes maximal, and the leakage to the second source is directly proportional to the correlation $\\rho$ between the source topographies. The solution spatial profile mimics the source correlation structure.\nThe final answer required is the closed-form expression for $w(\\lambda)$.",
            "answer": "$$\n\\boxed{\\frac{\\lambda\\rho}{1+\\lambda - \\rho^2}}\n$$"
        },
        {
            "introduction": "Building on the concept of spatial resolution, we now critically examine a specific advanced method, sLORETA, which is often noted for its property of having zero localization error. This hypothetical scenario explores the practical limits of that claim by investigating what happens when multiple sources are active simultaneously. This practice demonstrates how linear superposition can cause the individual source responses to merge, reintroducing localization error and highlighting the importance of understanding an algorithm's performance in complex, multi-source environments .",
            "id": "4157039",
            "problem": "Consider a linear electroencephalography/magnetoencephalography forward model with measurements $y$ and distributed cortical current $j$ satisfying $y = L j + n$, where $L$ is the leadfield operator and $n$ is additive sensor noise. Distributed source reconstructions such as Minimum Norm Estimate (MNE), Dynamic Statistical Parametric Mapping (dSPM), and Standardized Low-Resolution Brain Electromagnetic Tomography (sLORETA) produce linear estimates of $j$ from $y$ that can be analyzed via their resolution properties. Assume a one-dimensional cortical manifold parameterized by position $x \\in \\mathbb{R}$ along which sources are indexed, and suppose the head model and noise are homogeneous enough that the point-spread function of any linear estimator is translation invariant and even in displacement.\n\nUnder Standardized Low-Resolution Brain Electromagnetic Tomography (sLORETA), single-source unbiasedness is asserted in the sense that, for a noise-free single active source at $x_0$, the standardized map achieves its maximum at $x_0$. In this problem, analyze the limitation of this property when multiple sources are simultaneously active. Assume:\n- White sensor noise covariance with $C_n = \\sigma^{2} I$ and identity source covariance,\n- Fixed and identical source orientations,\n- A translation-invariant, even, strictly unimodal point-spread function $r(u)$ for the underlying linear estimator before standardization,\n- A diagonal variance standardization for sLORETA that is constant across position under the stated homogeneity.\n\nConsider two simultaneously active dipolar sources of equal amplitude located at $x_1 = 0$ and $x_2 = d$, with $d = 28$ mm. Starting from the linear forward model, the definition of the resolution matrix, and the variance standardization underlying sLORETA, derive from first principles how cross-talk between sources causes the sLORETA standardized map to form a single peak between $x_1$ and $x_2$, thereby reintroducing localization error relative to either true source. Then, compute the magnitude of this localization error with respect to $x_1$.\n\nExpress your final answer in mm and round your answer to four significant figures.",
            "solution": "The problem asks for a derivation of the localization error for sLORETA when two sources are simultaneously active, under a set of simplifying assumptions.\n\n1.  **Model Formulation**: The true cortical current distribution consists of two equally strong point sources (dipoles) at positions $x_1 = 0$ and $x_2 = d$. We can write this as $j_{true}(x) = A\\delta(x - 0) + A\\delta(x - d)$, where $A$ is the amplitude and $\\delta(\\cdot)$ is the Dirac delta function.\n\n2.  **Linear Estimator and Point-Spread Function (PSF)**: We are given a linear estimator whose noise-free response to a single point source at $x_0$ is given by a translation-invariant and even point-spread function, $r(x-x_0)$. This means the shape of the estimated activity is the same regardless of the source location, and it is symmetric around the true location (since $r(u) = r(-u)$).\n\n3.  **Superposition Principle**: Due to the linearity of the forward model and the estimator, the estimated activity for multiple sources is the sum of the estimated activities for each source individually. For our two sources, the unstandardized estimated current distribution, $\\hat{j}_{unstd}(x)$, is:\n    $$ \\hat{j}_{unstd}(x) = A \\cdot r(x - 0) + A \\cdot r(x - d) = A [r(x) + r(x - d)] $$\n\n4.  **sLORETA Standardization**: The problem states that the variance standardization for sLORETA is constant across all positions. This means the sLORETA map, $\\hat{j}_{sLORETA}(x)$, is simply the unstandardized map divided by a constant value.\n    $$ \\hat{j}_{sLORETA}(x) \\propto \\hat{j}_{unstd}(x) $$\n    Therefore, the location of the peak(s) in the sLORETA map is the same as the location of the peak(s) in the unstandardized map. We can find the peak by analyzing the function $f(x) = r(x) + r(x - d)$.\n\n5.  **Finding the Peak Location**: The problem states that the combined activity forms a single peak. We can demonstrate that this peak must occur at the midpoint between the two sources, $x = d/2$, by showing that the function $f(x)$ is symmetric around this point. Let's check the value of $f(x)$ at a point $d/2 + \\epsilon$ and a point $d/2 - \\epsilon$:\n    $$ f(d/2 + \\epsilon) = r(d/2 + \\epsilon) + r(d/2 + \\epsilon - d) = r(d/2 + \\epsilon) + r(-d/2 + \\epsilon) $$\n    $$ f(d/2 - \\epsilon) = r(d/2 - \\epsilon) + r(d/2 - \\epsilon - d) = r(d/2 - \\epsilon) + r(-d/2 - \\epsilon) $$\n    Since the PSF $r(u)$ is an even function, $r(u) = r(-u)$. Therefore, $r(d/2 + \\epsilon) = r(-(d/2 + \\epsilon)) = r(-d/2 - \\epsilon)$ and $r(-d/2 + \\epsilon) = r(-(-d/2 + \\epsilon)) = r(d/2 - \\epsilon)$. Substituting these into the second equation:\n    $$ f(d/2 - \\epsilon) = r(-d/2 + \\epsilon) + r(d/2 + \\epsilon) = f(d/2 + \\epsilon) $$\n    The function $f(x)$ is symmetric about the line $x = d/2$. Since it is also unimodal (as stated in the problem), its single peak must lie on this axis of symmetry. Thus, the estimated source location is $x_{peak} = d/2$.\n\n6.  **Calculating Localization Error**: The localization error is the distance between the estimated peak location and a true source location. We can calculate it with respect to the source at $x_1 = 0$:\n    $$ \\text{Error} = |x_{peak} - x_1| = |d/2 - 0| = d/2 $$\n    Given the distance between the sources is $d = 28$ mm, the localization error is:\n    $$ \\text{Error} = \\frac{28 \\text{ mm}}{2} = 14 \\text{ mm} $$\n\n7.  **Conclusion**: Although sLORETA has zero localization error for a single source under these ideal conditions, the linear superposition (cross-talk) of activity from multiple nearby sources causes the peaks to merge. The resulting single peak is located at the center of mass of the activity, leading to a localization error for both original sources. In this symmetric case, the error is exactly half the distance between them. The final answer, rounded to four significant figures, is 14.00 mm.",
            "answer": "$$\n\\boxed{14.00}\n$$"
        },
        {
            "introduction": "This final practice moves from the spatial characteristics of estimators to a fundamental statistical question regarding the underlying generative model. Using the Expectation-Maximization (EM) algorithm framework, this problem explores the estimation of model hyperparameters, specifically the signal and noise variances. The derivation uncovers a crucial property of the MNE inverse problem: the solution is only sensitive to the *ratio* of these variances, not their absolute values, a concept known as non-identifiability, which has profound consequences for interpreting noise-normalized maps like dSPM and sLORETA .",
            "id": "4157091",
            "problem": "Consider a distributed source model for magnetoencephalography/electroencephalography (M/EEG) inverse imaging used by Minimum Norm Estimate (MNE), Dynamic Statistical Parametric Mapping (dSPM), and Standardized Low Resolution Electromagnetic Tomography (sLORETA). Let there be $T$ independent time samples indexed by $t \\in \\{1,\\dots,T\\}$, with sensor data $y_t \\in \\mathbb{R}^{M}$, forward (leadfield) matrix $L \\in \\mathbb{R}^{M \\times N}$, and latent source vector $x_t \\in \\mathbb{R}^{N}$. The generative model is the linear Gaussian model\n$$\ny_t = L x_t + \\varepsilon_t,\n$$\nwith independent Gaussian priors and noise\n$$\nx_t \\sim \\mathcal{N}\\!\\left(0,\\ \\lambda C\\right), \\qquad \\varepsilon_t \\sim \\mathcal{N}\\!\\left(0,\\ \\rho I_M\\right),\n$$\nwhere $C \\in \\mathbb{R}^{N \\times N}$ is a known symmetric positive definite source covariance template, $I_M$ is the $M \\times M$ identity, and $\\lambda > 0$ and $\\rho > 0$ are unknown hyperparameters. Assume that $\\lambda$ is held fixed and that an empirical Bayes estimate of $\\rho$ is desired by maximizing the marginal likelihood $\\log p\\!\\left(\\{y_t\\}_{t=1}^T \\mid \\rho,\\lambda\\right)$ via the Expectation-Maximization (EM) algorithm, treating $\\{x_t\\}_{t=1}^T$ as latent variables. Let the E-step compute the posterior moments\n$$\n\\mu_t \\equiv \\mathbb{E}[x_t \\mid y_t,\\rho,\\lambda] \\in \\mathbb{R}^{N}, \n\\qquad \n\\Sigma \\equiv \\operatorname{Cov}[x_t \\mid y_t,\\rho,\\lambda] \\in \\mathbb{R}^{N \\times N},\n$$\nwith the understanding that, for this linear Gaussian model with $\\rho I_M$ noise and $\\lambda C$ prior, $\\Sigma$ does not depend on $t$. Starting from fundamental properties of multivariate normal densities and the definition of the EM algorithm for latent-variable models, derive the maximizer for the M-step update of $\\rho$ in closed form in terms of $\\{y_t\\}_{t=1}^T$, $L$, $\\{\\mu_t\\}_{t=1}^T$, and $\\Sigma$. Express your final answer as a single symbolic expression for the updated $\\rho$. Then, using only these fundamentals, discuss whether $\\lambda$ and $\\rho$ are jointly identifiable from the posterior mean estimator used in Minimum Norm Estimate (MNE), and explain the consequence of your conclusion for noise-normalized methods such as Dynamic Statistical Parametric Mapping (dSPM) and Standardized Low Resolution Electromagnetic Tomography (sLORETA). \n\nYour final answer must be the single closed-form analytic expression for the updated $\\rho$. Do not include any units. No numerical rounding is required.",
            "solution": "This problem requires deriving the M-step update for the noise variance parameter $\\rho$ in an EM algorithm and discussing hyperparameter identifiability.\n\n**1. M-Step Update for $\\rho$**\n\nThe EM algorithm maximizes the log-likelihood of the observed data by iteratively maximizing the expectation of the complete-data log-likelihood. The M-step for $\\rho$ involves maximizing the $Q$-function with respect to $\\rho$. The complete-data log-likelihood is $p(\\{y_t, x_t\\}) = \\prod_t p(y_t|x_t, \\rho) p(x_t|\\lambda)$. We only need the terms that depend on $\\rho$.\n\nThe relevant part of the $Q$-function is:\n$$ Q(\\rho) = \\mathbb{E} \\left[ \\sum_{t=1}^T \\log p(y_t | x_t, \\rho) \\right] $$\nwhere the expectation is taken over the posterior distribution of the latent variables $x_t$ given the data $y_t$ and the current parameter estimates.\n\nThe conditional likelihood $p(y_t | x_t, \\rho)$ is from the noise model $\\varepsilon_t = y_t - L x_t \\sim \\mathcal{N}(0, \\rho I_M)$. Its log-density is:\n$$ \\log p(y_t | x_t, \\rho) = -\\frac{M}{2} \\log(2\\pi\\rho) - \\frac{1}{2\\rho} \\|y_t - L x_t\\|_2^2 $$\nTaking the expectation, the $Q$-function becomes:\n$$ Q(\\rho) = \\sum_{t=1}^T \\left( -\\frac{M}{2} \\log\\rho - \\frac{1}{2\\rho} \\mathbb{E}\\left[\\|y_t - L x_t\\|_2^2\\right] \\right) + \\text{const} $$\nThe expected value of the squared norm is:\n\\begin{align*} \\mathbb{E}\\left[\\|y_t - L x_t\\|_2^2\\right] &= \\mathbb{E}\\left[ (y_t - L x_t)^T(y_t - L x_t) \\right] \\\\ &= \\mathbb{E}\\left[ y_t^T y_t - 2y_t^T L x_t + x_t^T L^T L x_t \\right] \\\\ &= y_t^T y_t - 2y_t^T L \\mathbb{E}[x_t] + \\mathbb{E}[x_t^T L^T L x_t] \\end{align*}\nUsing the posterior moments from the E-step, $\\mu_t = \\mathbb{E}[x_t]$ and $\\Sigma = \\operatorname{Cov}[x_t]$, and the identity $\\mathbb{E}[z^T A z] = \\operatorname{Tr}(A\\Sigma_z) + \\mu_z^T A \\mu_z$:\n$$ \\mathbb{E}[x_t^T L^T L x_t] = \\operatorname{Tr}(L^T L \\Sigma) + \\mu_t^T L^T L \\mu_t = \\operatorname{Tr}(L \\Sigma L^T) + \\|L\\mu_t\\|_2^2 $$\nSubstituting back:\n$$ \\mathbb{E}\\left[\\|y_t - L x_t\\|_2^2\\right] = \\|y_t\\|_2^2 - 2y_t^T L\\mu_t + \\|L\\mu_t\\|_2^2 + \\operatorname{Tr}(L \\Sigma L^T) = \\|y_t - L\\mu_t\\|_2^2 + \\operatorname{Tr}(L\\Sigma L^T) $$\nThe full $Q$-function summed over $T$ samples is:\n$$ Q(\\rho) = -\\frac{TM}{2} \\log\\rho - \\frac{1}{2\\rho} \\left( \\sum_{t=1}^T \\|y_t - L\\mu_t\\|_2^2 + T \\operatorname{Tr}(L\\Sigma L^T) \\right) $$\nTo maximize $Q(\\rho)$, we set its derivative with respect to $\\rho$ to zero:\n$$ \\frac{\\partial Q}{\\partial \\rho} = -\\frac{TM}{2\\rho} + \\frac{1}{2\\rho^2} \\left( \\sum_{t=1}^T \\|y_t - L\\mu_t\\|_2^2 + T \\operatorname{Tr}(L\\Sigma L^T) \\right) = 0 $$\nSolving for $\\rho$ gives the M-step update rule:\n$$ \\rho_{\\text{new}} = \\frac{1}{TM} \\left( \\sum_{t=1}^T \\|y_t - L\\mu_t\\|_2^2 + T \\operatorname{Tr}(L\\Sigma L^T) \\right) $$\n\n**2. Joint Identifiability of $\\lambda$ and $\\rho$**\n\nThe MNE solution is the posterior mean $\\mu_t = \\mathbb{E}[x_t | y_t]$. For this linear Gaussian model, the well-known formula is:\n$$ \\mu_t = (\\lambda C L^T) (\\lambda L C L^T + \\rho I_M)^{-1} y_t $$\nWe can factor out $\\lambda$ from the inverse term:\n$$ \\mu_t = (\\lambda C L^T) [\\lambda(L C L^T + (\\rho/\\lambda) I_M)]^{-1} y_t = \\lambda C L^T \\frac{1}{\\lambda} (L C L^T + (\\rho/\\lambda) I_M)^{-1} y_t $$\n$$ \\mu_t = C L^T (L C L^T + (\\rho/\\lambda) I_M)^{-1} y_t $$\nThis final expression demonstrates that the MNE solution $\\mu_t$ depends only on the ratio of the hyperparameters, $\\gamma = \\rho/\\lambda$, not on their absolute values. Any pair $(\\lambda, \\rho)$ that shares the same ratio (e.g., $(\\lambda_1, \\rho_1)$ and $(k\\lambda_1, k\\rho_1)$ for $k>0$) will produce an identical MNE source estimate. Therefore, $\\lambda$ and $\\rho$ are not jointly identifiable from the MNE estimator alone.\n\n**3. Consequence for dSPM and sLORETA**\n\ndSPM and sLORETA normalize the MNE solution by an estimate of the noise standard deviation to create statistical maps. The dSPM value for source $j$ is $Z_j = [\\mu_t]_j / \\sqrt{\\operatorname{Var}([\\mu_t]_j)_{\\text{noise}}}}$.\nThe variance of the MNE estimate under the null hypothesis (noise only) is:\n$$ \\operatorname{Var}([\\mu_t])_{\\text{noise}} = \\operatorname{Cov}(W \\varepsilon_t) = W \\operatorname{Cov}(\\varepsilon_t) W^T = W (\\rho I_M) W^T = \\rho W W^T $$\nwhere $W$ is the MNE inverse operator, which depends only on the ratio $\\gamma=\\rho/\\lambda$. The dSPM statistic is:\n$$ Z_j = \\frac{[W y_t]_j}{\\sqrt{\\rho [W W^T]_{jj}}} \\propto \\frac{1}{\\sqrt{\\rho}} $$\nSince the MNE solution in the numerator is invariant to a joint scaling of $(\\lambda, \\rho)$ but the noise standard deviation in the denominator scales with $\\sqrt{\\rho}$, the entire statistic scales with $1/\\sqrt{\\rho}$. Because $\\rho$ is not identifiable from the MNE solution itself, the absolute scale of dSPM and sLORETA maps is arbitrary. This non-identifiability must be resolved by fixing the scale, typically by using an independent measurement of the noise variance $\\rho$ from a baseline period in the data. This anchors the model and makes the resulting statistical values meaningful.",
            "answer": "$$\\boxed{\\frac{1}{TM} \\left( \\sum_{t=1}^T \\|y_t - L\\mu_t\\|_2^2 + T\\operatorname{Tr}(L \\Sigma L^T) \\right)}$$"
        }
    ]
}