{
    "hands_on_practices": [
        {
            "introduction": "比较不同的大脑分区方案是一项基本任务，无论是评估一种新的分割算法，还是衡量评估者之间的一致性。$\\text{Dice}$系数和$\\text{Jaccard}$指数是用于此目的的标准度量，它们为空间重叠度提供了量化指标。本练习将指导您从集合论的基本原理推导这些度量，并将其应用于一个实际场景，从而巩固您对如何评估分割准确性的理解。",
            "id": "4143491",
            "problem": "给定两个结构磁共振成像 (MRI) 脑图谱，每个图谱都为同一个皮质标签提供了一个二值掩模。这些掩模定义在一个共享的体素网格上，其各向同性体素大小为 $1 \\, \\mathrm{mm}^{3}$。设由图谱 $\\mathcal{A}$ 标记的体素集合表示为 $S_{\\mathcal{A}} \\subset \\Omega$，由图谱 $\\mathcal{B}$ 标记的体素集合表示为 $S_{\\mathcal{B}} \\subset \\Omega$，其中 $\\Omega$ 是脑容量中所有体素的有限集合。二值掩模通过将标签内的体素赋值为 1，其余赋值为 0，来编码集合的隶属关系。根据经验计算得出以下计数：\n- 图谱 $\\mathcal{A}$ 标签的基数 $|S_{\\mathcal{A}}|$ 为 $12{,}800$ 个体素。\n- 图谱 $\\mathcal{B}$ 标签的基数 $|S_{\\mathcal{B}}|$ 为 $13{,}600$ 个体素。\n- 交集 $|S_{\\mathcal{A}} \\cap S_{\\mathcal{B}}|$ 的基数为 $12{,}000$ 个体素。\n\n从核心集合论定义和性质（例如集合交集、集合并集的定义，以及容斥恒等式 $|S_{\\mathcal{A}} \\cup S_{\\mathcal{B}}| = |S_{\\mathcal{A}}| + |S_{\\mathcal{B}}| - |S_{\\mathcal{A}} \\cap S_{\\mathcal{B}}|$）出发，完成以下任务：\n\n1. 从第一性原理出发，将相似性解释为集合层面精确率和召回率的调和平均数，推导出用 $|S_{\\mathcal{A}}|$、 $|S_{\\mathcal{B}}|$ 和 $|S_{\\mathcal{A}} \\cap S_{\\mathcal{B}}|$ 表示的 Dice 相似系数表达式。\n2. 从第一性原理出发，将相似性解释为交并比，推导出用 $|S_{\\mathcal{A}}|$、 $|S_{\\mathcal{B}}|$ 和 $|S_{\\mathcal{A}} \\cap S_{\\mathcal{B}}|$ 表示的 Jaccard 指数表达式。\n3. 使用您推导出的表达式，计算给定掩模的 Dice 相似系数和 Jaccard 指数。\n\n将这两个度量表示为无量纲小数，并四舍五入到四位有效数字。最终答案必须以两个值的形式给出，分别对应 $\\text{Dice}$ 和 $\\text{Jaccard}$。",
            "solution": "我们使用体素域 $\\Omega$ 上的基本集合论定义来将问题形式化。对于任意两个标签集 $S_{\\mathcal{A}}, S_{\\mathcal{B}} \\subset \\Omega$，交集 $S_{\\mathcal{A}} \\cap S_{\\mathcal{B}}$ 精确地包含被两个图谱同时标记的体素，而并集 $S_{\\mathcal{A}} \\cup S_{\\mathcal{B}}$ 包含被至少一个图谱标记的体素。容斥原理确保了\n$$\n|S_{\\mathcal{A}} \\cup S_{\\mathcal{B}}| = |S_{\\mathcal{A}}| + |S_{\\mathcal{B}}| - |S_{\\mathcal{A}} \\cap S_{\\mathcal{B}}|.\n$$\n\n我们将 $S_{\\mathcal{A}}$（作为参考）和 $S_{\\mathcal{B}}$（作为候选）的集合层面精确率和召回率定义如下：\n- 精确率是被 $\\mathcal{B}$ 标记的体素中，也同时被 $\\mathcal{A}$ 标记的体素所占的比例，由下式给出：\n$$\nP = \\frac{|S_{\\mathcal{A}} \\cap S_{\\mathcal{B}}|}{|S_{\\mathcal{B}}|}.\n$$\n- 召回率是被 $\\mathcal{A}$ 标记的体素中，也同时被 $\\mathcal{B}$ 标记的体素所占的比例，由下式给出：\n$$\nR = \\frac{|S_{\\mathcal{A}} \\cap S_{\\mathcal{B}}|}{|S_{\\mathcal{A}}|}.\n$$\n\nDice 相似系数可以推导为精确率和召回率的调和平均数：\n$$\n\\text{Dice} = \\frac{2 \\, P \\, R}{P + R}.\n$$\n代入 $P$ 和 $R$ 可得\n$$\n\\text{Dice} = \\frac{2 \\left( \\frac{|S_{\\mathcal{A}} \\cap S_{\\mathcal{B}}|}{|S_{\\mathcal{B}}|} \\right) \\left( \\frac{|S_{\\mathcal{A}} \\cap S_{\\mathcal{B}}|}{|S_{\\mathcal{A}}|} \\right)}{\\frac{|S_{\\mathcal{A}} \\cap S_{\\mathcal{B}}|}{|S_{\\mathcal{B}}|} + \\frac{|S_{\\mathcal{A}} \\cap S_{\\mathcal{B}}|}{|S_{\\mathcal{A}}|}} = \\frac{2 \\, |S_{\\mathcal{A}} \\cap S_{\\mathcal{B}}|}{|S_{\\mathcal{A}}| + |S_{\\mathcal{B}}|}.\n$$\n\nJaccard 指数定义为交集与并集的比率：\n$$\n\\text{Jaccard} = \\frac{|S_{\\mathcal{A}} \\cap S_{\\mathcal{B}}|}{|S_{\\mathcal{A}} \\cup S_{\\mathcal{B}}|} = \\frac{|S_{\\mathcal{A}} \\cap S_{\\mathcal{B}}|}{|S_{\\mathcal{A}}| + |S_{\\mathcal{B}}| - |S_{\\mathcal{A}} \\cap S_{\\mathcal{B}}|}.\n$$\n\n这些定义得出了两个度量之间的函数关系。设 $I = |S_{\\mathcal{A}} \\cap S_{\\mathcal{B}}|$ 且 $T = |S_{\\mathcal{A}}| + |S_{\\mathcal{B}}|$。那么\n$$\n\\text{Dice} = \\frac{2 I}{T}, \\quad \\text{Jaccard} = \\frac{I}{T - I}.\n$$\n从 Dice 表达式中解出 $I$ 可得 $I = \\frac{\\text{Dice} \\cdot T}{2}$。将其代入 Jaccard 表达式中：\n$$\n\\text{Jaccard} = \\frac{\\frac{\\text{Dice} \\cdot T}{2}}{T - \\frac{\\text{Dice} \\cdot T}{2}} = \\frac{\\text{Dice}}{2 - \\text{Dice}},\n$$\n以及其反向关系\n$$\n\\text{Dice} = \\frac{2 \\, \\text{Jaccard}}{1 + \\text{Jaccard}}.\n$$\n\n现在我们使用给定的计数来计算这些度量：\n$$\n|S_{\\mathcal{A}}| = 12{,}800, \\quad |S_{\\mathcal{B}}| = 13{,}600, \\quad |S_{\\mathcal{A}} \\cap S_{\\mathcal{B}}| = 12{,}000.\n$$\n首先，使用容斥原理计算并集的基数：\n$$\n|S_{\\mathcal{A}} \\cup S_{\\mathcal{B}}| = 12{,}800 + 13{,}600 - 12{,}000 = 14{,}400.\n$$\n计算 Dice 相似系数：\n$$\n\\text{Dice} = \\frac{2 \\times 12{,}000}{12{,}800 + 13{,}600} = \\frac{24{,}000}{26{,}400} = \\frac{240}{264} = \\frac{60}{66} = \\frac{10}{11}.\n$$\n因此，\n$$\n\\text{Dice} = \\frac{10}{11} \\approx 0.909090\\ldots\n$$\n计算 Jaccard 指数：\n$$\n\\text{Jaccard} = \\frac{12{,}000}{14{,}400} = \\frac{120}{144} = \\frac{5}{6} \\approx 0.833333\\ldots\n$$\n\n最后，按要求将两个小数值四舍五入到四位有效数字：\n$$\n\\text{Dice} \\approx 0.9091, \\quad \\text{Jaccard} \\approx 0.8333.\n$$\n这些是无量纲量。",
            "answer": "$$\\boxed{\\begin{pmatrix}0.9091 & 0.8333\\end{pmatrix}}$$"
        },
        {
            "introduction": "在神经影像处理流程中，经常需要对脑图谱进行重采样，以匹配功能或结构数据的分辨率。由于脑图谱是类别数据，标准的插值方法并不适用。这个动手练习要求您实现并比较两种常用的标签保持策略——最近邻法和多数投票法，并量化每种方法产生的“错标率”，从而揭示它们对图谱保真度的不同影响。",
            "id": "4143470",
            "problem": "您将分析使用两种插值策略将带标签的脑分区图谱从 $1$ 毫米各向同性网格重采样到 $2$ 毫米各向同性网格对标签保真度的影响，并计算由此产生的错标率。将该图谱视为一个由整数区域标签（分区）组成的三维数组，其中每个元素对应一个体素。基本原则是：脑分区图谱是体素网格上的分段常数标签场，重采样标签场时不得创建新标签，而应根据规则重新分配标签。您必须遵循以下精确定义，以使问题纯数学化且完全可复现。\n\n定义和算子：\n- 设 $A \\in \\mathbb{N}^{X \\times Y \\times Z}$ 表示分辨率为 $1$ 毫米的原始标签图谱，其中 $X=Y=Z=8$。设标签集为正整数。定义降采样因子 $s=2$。\n- $2$ 毫米网格将 $1$ 毫米网格划分为大小为 $2 \\times 2 \\times 2$ 的不重叠块。用 $(I,J,K)$ 索引粗网格体素，其中 $I \\in \\{0,\\dots,\\frac{X}{2}-1\\}$, $J \\in \\{0,\\dots,\\frac{Y}{2}-1\\}$, $K \\in \\{0,\\dots,\\frac{Z}{2}-1\\}$。块中对应的细网格索引为 $i \\in \\{2I,2I+1\\}$, $j \\in \\{2J,2J+1\\}$, $k \\in \\{2K,2K+1\\}$。\n- 定义两种降采样算子：\n  1. 最近邻抽取 $D^{(\\mathrm{nn})}$：对于每个粗体素 $(I,J,K)$，\n     $$B^{(\\mathrm{nn})}_{I,J,K} \\equiv D^{(\\mathrm{nn})}(A)_{I,J,K} := A_{2I,\\,2J,\\,2K}.$$\n     这对应于选取每个 $2 \\times 2 \\times 2$ 块的左上角前方顶点的标签。\n  2. 多数投票块众数 $D^{(\\mathrm{mv})}$：对于每个粗体素 $(I,J,K)$，\n     $$B^{(\\mathrm{mv})}_{I,J,K} \\equiv D^{(\\mathrm{mv})}(A)_{I,J,K} := \\arg\\max_{\\ell \\in \\mathcal{L}} c_{\\ell}(I,J,K),$$\n     其中 $\\mathcal{L}$ 是块中存在的标签集合，而 $c_{\\ell}(I,J,K)$ 计算块中 $8$ 个细体素中标签为 $\\ell$ 的数量。如果最大计数出现平局，则选择平局标签中值最小的标签。\n- 定义一个复制上采样算子 $U$，它通过用粗标签填充每个 $2 \\times 2 \\times 2$ 的块，将粗网格映射回细网格：\n  $$C_{i,j,k} \\equiv U(B)_{i,j,k} := B_{\\left\\lfloor \\frac{i}{2} \\right\\rfloor,\\, \\left\\lfloor \\frac{j}{2} \\right\\rfloor,\\, \\left\\lfloor \\frac{k}{2} \\right\\rfloor}.$$\n- 定义重采样流程 $A \\mapsto B \\mapsto C$ 的错标率 $r$ 为上采样后的标签与原始标签不同的细网格体素所占的比例：\n  $$r := \\frac{1}{XYZ} \\sum_{i=0}^{X-1} \\sum_{j=0}^{Y-1} \\sum_{k=0}^{Z-1} \\mathbf{1}\\big[ C_{i,j,k} \\neq A_{i,j,k} \\big],$$\n  其中 $\\mathbf{1}[\\cdot]$ 是指示函数。\n\n任务：\n- 对于下面定义的每个测试图谱，使用先 $D^{(\\mathrm{nn})}$ 后 $U$ 的方法计算错标率 $r^{(\\mathrm{nn})}$，并使用先 $D^{(\\mathrm{mv})}$ 后 $U$ 的方法计算错标率 $r^{(\\mathrm{mv})}$。报告每个测试的 $r^{(\\mathrm{nn})}$ 和 $r^{(\\mathrm{mv})}$。\n\n测试套件（每个图谱都根据索引 $i \\in \\{0,\\dots,7\\}$, $j \\in \\{0,\\dots,7\\}$, $k \\in \\{0,\\dots,7\\}$ 确定性地定义）：\n- 测试 $1$（均匀图谱）：对于所有 $(i,j,k)$，$A_{i,j,k} = 1$。\n- 测试 $2$（每块稀疏角点杂质）：对于所有 $(i,j,k)$，$A_{i,j,k} = 1$，但对于每个块的起始点 $(i,j,k)$，其中 $i \\in \\{0,2,4,6\\}$, $j \\in \\{0,2,4,6\\}$, $k \\in \\{0,2,4,6\\}$，设置 $A_{i,j,k} = 2$。\n- 测试 $3$（对齐的平面边界）：如果 $i  4$，则 $A_{i,j,k} = 1$，否则 $A_{i,j,k} = 2$。\n- 测试 $4$（未对齐的平面边界）：如果 $i  5$，则 $A_{i,j,k} = 1$，否则 $A_{i,j,k} = 2$。\n- 测试 $5$（三维棋盘格）：如果 $(i + j + k) \\bmod 2 = 0$，则 $A_{i,j,k} = 1$，否则 $A_{i,j,k} = 2$。\n- 测试 $6$（确定性多标签异质性）：$A_{i,j,k} = \\big( (7 i + 11 j + 13 k) \\bmod 3 \\big) + 1$。\n\n输出规范：\n- 您的程序必须生成单行输出，其中包含按顺序排列的 $6$ 个测试的结果列表。每个结果都是一个双元素列表 $[r^{(\\mathrm{nn})}, r^{(\\mathrm{mv})}]$，每个浮点数四舍五入到六位小数。最终输出必须是以下形式\n  $$\\big[ [r^{(\\mathrm{nn})}_1, r^{(\\mathrm{mv})}_1], [r^{(\\mathrm{nn})}_2, r^{(\\mathrm{mv})}_2], \\dots, [r^{(\\mathrm{nn})}_6, r^{(\\mathrm{mv})}_6] \\big],$$\n  精确地打印为单行字符串，不带任何附加文本。\n\n科学真实性说明：\n- 脑分区图谱是代表感兴趣区域（Regions of Interest）的标签场，标准做法是使用最近邻或多数投票操作进行重采样，以在不进行平均的情况下保留标签。上述定义在一个离散网格上实例化了这些原则，以便结果是可复现和可测试的。\n\n交付成果：\n- 实现一个完整、可运行的程序，该程序构建测试图谱，应用两种重采样流程，计算所定义的错标率，并以要求的格式打印结果（四舍五入到六位小数）。",
            "solution": "这个问题要求实现并比较两种不同的重采样流程，这两种流程应用于一个被称为标签图谱的 $3$ 维分类数据场。目标是量化将图谱从细网格降采样到粗网格，然后再上采样回原始分辨率时所造成的信息损失，即“错标率”。\n\n解决方案的基本组成部分是：\n1.  生成六个不同的初始图谱，表示为 $A \\in \\mathbb{N}^{8 \\times 8 \\times 8}$。\n2.  实现两种降采样算子 $D^{(\\mathrm{nn})}$ 和 $D^{(\\mathrm{mv})}$，它们将 $8 \\times 8 \\times 8$ 的图谱 $A$ 映射到一个 $4 \\times 4 \\times 4$ 的粗略图谱 $B$。\n3.  实现一种上采样算子 $U$，它将粗略图谱 $B$ 映射回一个 $8 \\times 8 \\times 8$ 的图谱 $C$。\n4.  为每个流程和每个测试图谱计算错标率 $r$。\n\n首先，我们构建六个测试图谱中的每一个，即 $A$，它表示为一个大小为 $8 \\times 8 \\times 8$ 的三维整数数组。每个图谱都根据其精确的数学定义生成，为每个体素 $(i,j,k)$ 提供一个“基准真相”标签。\n\n接下来，我们定义两种重采样流程。每个流程都包含一个降采样步骤和一个上采样步骤。\n大小为 $4 \\times 4 \\times 4$ 的粗网格将原始的细网格划分为 $64$ 个大小为 $2 \\times 2 \\times 2$ 的不重叠块。\n\n第一个流程使用**最近邻抽取**算子 $D^{(\\mathrm{nn})}$。对于每个粗体素 $(I,J,K)$，其标签通过简单地从原始图谱 $A$ 中取其对应块的最小索引角点的标签来确定。具体来说，$B^{(\\mathrm{nn})}_{I,J,K} = A_{2I, 2J, 2K}$。这种方法计算上很简单，但可能对特征相对于采样网格的对齐方式很敏感。\n\n第二个流程使用**多数投票块众数**算子 $D^{(\\mathrm{mv})}$。对于每个块，该算子会识别出该块内 $8$ 个细体素中出现最频繁的标签。粗体素 $(I,J,K)$ 的标签被设置为这个众数：$B^{(\\mathrm{mv})}_{I,J,K} = \\arg\\max_{\\ell} c_{\\ell}(I,J,K)$。这种方法提供了对块内容更鲁棒的表示，因为它考虑了块内的所有体素。问题指定了一个确定性的平局打破规则：如果多个标签共享相同的最大频率，则选择整数值最小的那个。这确保了结果的唯一性。\n\n两个降采样后的图谱 $B^{(\\mathrm{nn})}$ 和 $B^{(\\mathrm{mv})}$，随后使用相同的上采样算子 $U$ 被上采样回原始的 $8 \\times 8 \\times 8$ 分辨率。这个算子定义为 $C_{i,j,k} = B_{\\left\\lfloor i/s \\right\\rfloor, \\left\\lfloor j/s \\right\\rfloor, \\left\\lfloor k/s \\right\\rfloor}$（其中 $s=2$），执行零阶保持或复制操作。它用来自相应粗体素的单个标签值填充细网格中的每个 $2 \\times 2 \\times 2$ 块。得到的上采样图谱表示为 $C^{(\\mathrm{nn})}$ 和 $C^{(\\mathrm{mv})}$。\n\n最后，我们量化每个流程引入的误差。错标率 $r$ 定义为上采样图谱 $C$ 中与原始图谱 $A$ 不匹配的体素所占的比例。这使用指示函数 $\\mathbf{1}[\\cdot]$ 计算：\n$$ r = \\frac{1}{XYZ} \\sum_{i=0}^{X-1} \\sum_{j=0}^{Y-1} \\sum_{k=0}^{Z-1} \\mathbf{1}\\big[ C_{i,j,k} \\neq A_{i,j,k} \\big] $$\n我们为两种流程计算这个比率，得到 $r^{(\\mathrm{nn})}$ 和 $r^{(\\mathrm{mv})}$。\n\n整体算法通过遍历六个测试用例中的每一个来进行。对于每个用例，生成图谱 $A$。然后，计算并存储 $r^{(\\mathrm{nn})}$ 和 $r^{(\\mathrm{mv})}$。最终输出是这些成对结果的聚合。这个系统化的过程允许直接比较最近邻重采样与多数投票重采样在各种空间模式下保留标签保真度的表现。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.stats import mode\n\ndef solve():\n    \"\"\"\n    Solves the brain atlas resampling problem for all specified test cases.\n    \"\"\"\n    X, Y, Z = 8, 8, 8\n    S = 2\n    TOTAL_VOXELS = X * Y * Z\n    \n    # List of functions to generate each test atlas\n    test_generators = [\n        generate_test_1,\n        generate_test_2,\n        generate_test_3,\n        generate_test_4,\n        generate_test_5,\n        generate_test_6,\n    ]\n\n    results = []\n    for gen_func in test_generators:\n        atlas_a = gen_func(X, Y, Z)\n        \n        # Pipeline 1: Nearest-Neighbor\n        atlas_b_nn = downsample_nn(atlas_a, S)\n        atlas_c_nn = upsample_replicate(atlas_b_nn, S)\n        r_nn = np.sum(atlas_c_nn != atlas_a) / TOTAL_VOXELS\n        \n        # Pipeline 2: Majority-Vote\n        atlas_b_mv = downsample_mv(atlas_a, S)\n        atlas_c_mv = upsample_replicate(atlas_b_mv, S)\n        r_mv = np.sum(atlas_c_mv != atlas_a) / TOTAL_VOXELS\n        \n        # Format the result for the current test case as specified\n        results.append(f\"[{r_nn:.6f},{r_mv:.6f}]\")\n\n    # Final print statement in the exact required format\n    print(f\"[{','.join(results)}]\")\n\ndef generate_test_1(X, Y, Z):\n    \"\"\"Test 1 (Uniform atlas): A_ijk = 1 for all (i,j,k).\"\"\"\n    return np.ones((X, Y, Z), dtype=int)\n\ndef generate_test_2(X, Y, Z):\n    \"\"\"Test 2 (Sparse corner impurity per block): A_ijk = 1, except A_ijk = 2 at block corners.\"\"\"\n    A = np.ones((X, Y, Z), dtype=int)\n    for i in range(0, X, 2):\n        for j in range(0, Y, 2):\n            for k in range(0, Z, 2):\n                A[i, j, k] = 2\n    return A\n\ndef generate_test_3(X, Y, Z):\n    \"\"\"Test 3 (Aligned planar boundary): A_ijk = 1 if i  4, else A_ijk = 2.\"\"\"\n    A = np.ones((X, Y, Z), dtype=int)\n    A[4:, :, :] = 2\n    return A\n\ndef generate_test_4(X, Y, Z):\n    \"\"\"Test 4 (Misaligned planar boundary): A_ijk = 1 if i  5, else A_ijk = 2.\"\"\"\n    A = np.ones((X, Y, Z), dtype=int)\n    A[5:, :, :] = 2\n    return A\n\ndef generate_test_5(X, Y, Z):\n    \"\"\"Test 5 (Three-dimensional checkerboard): A_ijk = 1 if (i+j+k) mod 2 = 0, else 2.\"\"\"\n    i, j, k = np.mgrid[0:X, 0:Y, 0:Z]\n    A = ((i + j + k) % 2) + 1\n    return A.astype(int)\n\ndef generate_test_6(X, Y, Z):\n    \"\"\"Test 6 (Deterministic multi-label heterogeneity): A_ijk = ((7i+11j+13k) mod 3) + 1.\"\"\"\n    i, j, k = np.mgrid[0:X, 0:Y, 0:Z]\n    A = ((7 * i + 11 * j + 13 * k) % 3) + 1\n    return A.astype(int)\n\ndef downsample_nn(A, s):\n    \"\"\"Downsamples a 3D atlas using nearest-neighbor decimation.\"\"\"\n    return A[::s, ::s, ::s]\n\ndef downsample_mv(A, s):\n    \"\"\"Downsamples a 3D atlas using majority-vote block mode.\"\"\"\n    X, Y, Z = A.shape\n    Xc, Yc, Zc = X // s, Y // s, Z // s\n    B = np.zeros((Xc, Yc, Zc), dtype=A.dtype)\n    \n    for I in range(Xc):\n        for J in range(Yc):\n            for K in range(Zc):\n                block = A[I*s:(I+1)*s, J*s:(J+1)*s, K*s:(K+1)*s]\n                # scipy.stats.mode with default parameters breaks ties by choosing the smallest value,\n                # which matches the problem specification.\n                B[I, J, K] = mode(block, axis=None, keepdims=False).mode\n    return B\n\ndef upsample_replicate(B, s):\n    \"\"\"Upsamples a 3D atlas by replicating coarse voxels into blocks.\"\"\"\n    # np.kron is a convenient way to perform block replication\n    return np.kron(B, np.ones((s, s, s), dtype=B.dtype))\n\nsolve()\n```"
        },
        {
            "introduction": "在公共空间中分析多被试数据时，理解解剖对准的一致性至关重要。不完美的配准和真实的解剖差异会导致不同被试在标签分配上存在变异。本练习将引入香农熵来量化皮层表面每个点上的这种局部不确定性，提供一种强大的方法来识别高变异区域和潜在的配准错误。",
            "id": "4143439",
            "problem": "给定一个表示离散化皮层表面的有限顶点集、一个编码表面拓扑的邻接结构、一组个体受试者的皮层分区标记以及一个组别图谱标记。您的目标是通过计算每个顶点上标记的香农熵来评估跨受试者对齐情况，量化与组别图谱的一致性，并使用基于邻接的边界敏感性指数将高熵与解剖变异性或配准错误联系起来。本问题中的所有量都是无单位的。\n\n基本和核心定义：\n- 设存在 $V$ 个顶点，索引为 $v \\in \\{0,1,\\dots,V-1\\}$，以及 $S$ 个受试者，索引为 $s \\in \\{0,1,\\dots,S-1\\}$。\n- 设标记集为一个有限集 $L = \\{0,1,\\dots,K-1\\}$。\n- 设 $l_{s,v} \\in L$ 表示受试者 $s$ 在顶点 $v$ 处的标记。\n- 设 $g_v \\in L$ 表示组别图谱在顶点 $v$ 处的标记。\n- 设 $N(v)$ 表示顶点 $v$ 在邻接关系下的邻居集合。\n\n您必须基于经过充分检验的公式和定义执行以下计算：\n\n1. 每个顶点上的经验标记分布：\n   对于每个顶点 $v$，计算经验概率\n   $$p_{v,l} = \\frac{1}{S} \\sum_{s=0}^{S-1} \\mathbf{1}\\{l_{s,v} = l\\}, \\quad \\text{对于所有 } l \\in L,$$\n   其中 $\\mathbf{1}\\{\\cdot\\}$ 是指示函数。\n\n2. 每个顶点上的香non熵：\n   使用经验分布 $\\{p_{v,l}\\}_{l \\in L}$，计算熵\n   $$H_v = -\\sum_{l \\in L} p_{v,l} \\log p_{v,l},$$\n   约定 $0 \\log 0 = 0$，对数底为 $e$（自然对数）。熵的单位是奈特（nats）。\n\n3. 与组别图谱的一致性率：\n   对于每个顶点 $v$，计算\n   $$A_v = \\frac{1}{S} \\sum_{s=0}^{S-1} \\mathbf{1}\\{l_{s,v} = g_v\\}.$$\n\n4. 边界邻近指数：\n   仅基于组别图谱标记和邻接关系定义边界敏感性：\n   $$B_v = \\frac{1}{|N(v)|} \\sum_{u \\in N(v)} \\mathbf{1}\\{g_u \\neq g_v\\},$$\n   其中 $|N(v)|$ 是顶点 $v$ 的度。该指数在图谱边界附近较高，在远离边界处为零。\n\n5. 熵与边界邻近性之间的相关性：\n   计算 $\\{H_v\\}_{v=0}^{V-1}$ 和 $\\{B_v\\}_{v=0}^{V-1}$ 之间的皮尔逊相关系数：\n   $$\\rho = \\frac{\\sum_{v=0}^{V-1} (H_v - \\bar{H})(B_v - \\bar{B})}{\\sqrt{\\sum_{v=0}^{V-1} (H_v - \\bar{H})^2}\\sqrt{\\sum_{v=0}^{V-1} (B_v - \\bar{B})^2}},$$\n   其中 $\\bar{H}$ 和 $\\bar{B}$ 是所有顶点的均值。如果任一分母项为零（$\\{H_v\\}$ 或 $\\{B_v\\}$ 的方差为零），则按惯例定义 $\\rho = 0$。\n\n6. 配准敏感顶点分类：\n   使用阈值 $\\tau_B$ 和 $\\tau_A$，如果满足以下条件，则将顶点 $v$ 分类为配准敏感型\n   $$R_v = \\mathbf{1}\\{B_v \\ge \\tau_B \\land A_v  \\tau_A\\}.$$\n   然后计算配准敏感顶点的比例\n   $$F = \\frac{1}{V}\\sum_{v=0}^{V-1} R_v.$$\n\n您的程序必须实现上述计算，并为每个测试用例返回三元组 $[\\bar{H}, \\rho, F]$，其中\n$$\\bar{H} = \\frac{1}{V}\\sum_{v=0}^{V-1} H_v.$$\n\n测试套件：\n您必须使用以下三个具有指定参数的测试用例。所有标记值均为整数且无单位。\n\n- 测试用例 1（边界相关配准错误的理想路径）：\n  - $V = 12$, $S = 10$, $L = \\{0,1\\}$。\n  - 邻接关系：一个包含 $12$ 个顶点的路径图，$N(v) = \\{v-1, v+1\\}$（在有定义的情况下）；端点只有一个邻居。\n  - 组别图谱标记：对于 $v \\in \\{0,1,2,3,4,5\\}$，$g_v = 0$；对于 $v \\in \\{6,7,8,9,10,11\\}$，$g_v = 1$。\n  - 个体标记：从所有 $s,v$ 的 $l_{s,v} = g_v$ 开始，然后引入边界配准错误：\n    - 在 $v = 5$ 处，对于 $s \\in \\{0,3,7\\}$，设置 $l_{s,5} = 1$。\n    - 在 $v = 6$ 处，对于 $s \\in \\{2,4\\}$，设置 $l_{s,6} = 0$。\n  - 阈值：$\\tau_B = 0.5$, $\\tau_A = 0.85$。\n\n- 测试用例 2（完美对齐）：\n  - $V = 12$, $S = 10$, $L = \\{0,1\\}$。\n  - 邻接关系：与测试用例 1 相同的路径图。\n  - 组别图谱标记：与测试用例 1 相同。\n  - 个体标记：对于所有 $s,v$，$l_{s,v} = g_v$。\n  - 阈值：$\\tau_B = 0.5$, $\\tau_A = 0.85$。\n\n- 测试用例 3（远离边界的解剖变异性）：\n  - $V = 12$, $S = 10$, $L = \\{0,1\\}$。\n  - 邻接关系：与测试用例 1 相同的路径图。\n  - 组别图谱标记：与测试用例 1 相同。\n  - 个体标记：从 $l_{s,v} = g_v$ 开始，然后引入内部变异：\n    - 在 $v = 2$ 处，对于 $s \\in \\{0,1,2,3,4\\}$，设置 $l_{s,2} = 1$。\n    - 在 $v = 9$ 处，对于 $s \\in \\{5,6,7,8,9\\}$，设置 $l_{s,9} = 0$。\n  - 阈值：$\\tau_B = 0.5$, $\\tau_A = 0.85$。\n\n最终输出格式：\n您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表。每个测试用例的结果都按顺序作为一个三元素列表包含在内。所需格式为\n$$[[\\bar{H}_1,\\rho_1,F_1],[\\bar{H}_2,\\rho_2,F_2],[\\bar{H}_3,\\rho_3,F_3]],$$\n不打印任何额外文本。",
            "solution": "该问题要求实现一系列标准的神经信息学指标，以评估皮层表面分区中的受试者间变异性和配准质量。验证过程确认了问题陈述在科学上是合理的、适定的、客观的和完整的。所有定义和公式在信息论和统计学等领域都是标准的，并可直接应用于神经影像数据的分析。所提供的测试用例定义明确，用于说明数据变异性的不同场景。因此，我们可以继续进行有原则的求解。\n\n总体方法是创建一个计算流程，为每个测试用例处理给定的数据——顶点数 $V$、受试者数 $S$、标记集 $L$、邻接结构、组别图谱标记 $g_v$ 以及个体受试者标记 $l_{s,v}$——以生成所需的三元组输出 $[\\bar{H}, \\rho, F]$。\n\n单个测试用例的逐步过程如下：\n\n1.  **数据表示**：为实现高效计算，输入数据使用数值数组表示。个体受试者标记 $l_{s,v}$ 构成一个大小为 $S \\times V$ 的矩阵，组别图谱标记 $g_v$ 构成一个大小为 $V$ 的向量，邻接结构表示为列表的列表，其中每个内部列表包含相邻顶点的索引。\n\n2.  **经验标记分布 ($p_{v,l}$)**：对于每个顶点 $v$，我们计算所有 $S$ 个受试者中每个可能标记 $l \\in L$ 的出现次数。然后将这些计数除以 $S$ 进行归一化，以得出该顶点的经验概率分布 $\\{p_{v,l}\\}_{l \\in L}$。这将产生一个大小为 $V \\times K$ 的概率矩阵，其中 $K = |L|$。\n\n3.  **香Shannon熵 ($H_v$)**：使用计算出的概率 $p_{v,l}$，计算每个顶点 $v$ 的香Shannon熵为 $H_v = -\\sum_{l \\in L} p_{v,l} \\log_e p_{v,l}$。使用自然对数，并通过确保仅对非零概率计算对数来处理 $0 \\log_e 0 = 0$ 的约定。这将生成一个熵值向量 $\\{H_v\\}_{v=0}^{V-1}$。然后通过对此向量求平均值来计算平均熵 $\\bar{H}$。\n\n4.  **组别图谱一致性 ($A_v$)**：对于每个顶点 $v$，一致性率是其标记 $l_{s,v}$ 与组别图谱标记 $g_v$ 相匹配的受试者比例。计算公式为 $A_v = \\frac{1}{S} \\sum_{s=0}^{S-1} \\mathbf{1}\\{l_{s,v} = g_v\\}$，得出一个一致性率向量 $\\{A_v\\}_{v=0}^{V-1}$。\n\n5.  **边界邻近指数 ($B_v$)**：该指数用于量化顶点 $v$ 与组别图谱 $g$ 中边界的接近程度。对于每个顶点 $v$，我们检查其邻居 $u \\in N(v)$。指数 $B_v$ 是其图谱标记 $g_u$ 与 $g_v$ 不同的邻居比例：$B_v = \\frac{1}{|N(v)|} \\sum_{u \\in N(v)} \\mathbf{1}\\{g_u \\neq g_v\\}$。此计算生成一个向量 $\\{B_v\\}_{v=0}^{V-1}$。\n\n6.  **相关性 ($\\rho$)**：计算熵向量 $\\{H_v\\}$ 和边界邻近向量 $\\{B_v\\}$ 之间的皮尔逊相关系数 $\\rho$。计算遵循标准公式：\n    $$\\rho = \\frac{\\sum_{v=0}^{V-1} (H_v - \\bar{H})(B_v - \\bar{B})}{\\sqrt{\\sum_{v=0}^{V-1} (H_v - \\bar{H})^2}\\sqrt{\\sum_{v=0}^{V-1} (B_v - \\bar{B})^2}}$$\n    实现了一个特殊条件：如果 $\\{H_v\\}$ 或 $\\{B_v\\}$ 的方差为零（即相应的分母项为零），则定义 $\\rho$ 为 $0$。\n\n7.  **配准敏感比例 ($F$)**：如果一个顶点 $v$ 位于图谱边界附近 ($B_v \\ge \\tau_B$) 同时与组别图谱的一致性较低 ($A_v  \\tau_A$)，则将其分类为“配准敏感型”。通过对所有顶点求和指示函数 $R_v = \\mathbf{1}\\{B_v \\ge \\tau_B \\land A_v  \\tau_A\\}$ 并除以 $V$，计算出此类顶点的总比例 $F$。\n\n将此完整的计算序列应用于问题中指定的三个测试用例，并将最终结果汇总为所需的输出格式。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef compute_metrics(V, S, L, adj, g_v, l_sv, tau_A, tau_B):\n    \"\"\"\n    Computes all required metrics for a single test case.\n    \"\"\"\n    K = len(L)\n\n    # 1. Empirical label distribution p_{v,l}\n    p_vl = np.zeros((V, K))\n    for v in range(V):\n        labels_at_v = l_sv[:, v]\n        counts = np.bincount(labels_at_v, minlength=K)\n        p_vl[v, :] = counts / S\n\n    # 2. Shannon entropy H_v and its mean H_bar\n    log_p = np.log(p_vl, where=(p_vl > 0), out=np.zeros_like(p_vl, dtype=float))\n    H_v = -np.sum(p_vl * log_p, axis=1)\n    H_bar = np.mean(H_v)\n\n    # 3. Agreement rate A_v\n    agreement_matrix = (l_sv == g_v[None, :])\n    A_v = np.mean(agreement_matrix, axis=0)\n\n    # 4. Boundary proximity index B_v\n    B_v = np.zeros(V, dtype=float)\n    for v in range(V):\n        neighbors = adj[v]\n        if not neighbors:\n            continue\n        num_neighbors = len(neighbors)\n        neighbor_labels = g_v[neighbors]\n        num_mismatches = np.sum(neighbor_labels != g_v[v])\n        B_v[v] = num_mismatches / num_neighbors\n\n    # 5. Correlation rho\n    var_H = np.var(H_v)\n    var_B = np.var(B_v)\n\n    if var_H  1e-9 or var_B  1e-9:\n        rho = 0.0\n    else:\n        mean_H = np.mean(H_v)\n        mean_B = np.mean(B_v)\n        numerator = np.sum((H_v - mean_H) * (B_v - mean_B))\n        denominator_H = np.sqrt(np.sum((H_v - mean_H)**2))\n        denominator_B = np.sqrt(np.sum((B_v - mean_B)**2))\n        rho = numerator / (denominator_H * denominator_B) if (denominator_H * denominator_B) > 0 else 0.0\n\n    # 6. Registration-sensitive fraction F\n    R_v_mask = (B_v >= tau_B)  (A_v  tau_A)\n    F = np.mean(R_v_mask.astype(float))\n\n    return [H_bar, rho, F]\n\n\ndef solve():\n    # Define the test cases from the problem statement.\n    V = 12\n    S = 10\n    L = {0, 1}\n    adj = []\n    for v in range(V):\n        if v == 0:\n            adj.append([1])\n        elif v == V - 1:\n            adj.append([V - 2])\n        else:\n            adj.append([v - 1, v + 1])\n    g_v = np.array([0] * 6 + [1] * 6, dtype=int)\n    tau_A = 0.85\n    tau_B = 0.5\n\n    test_cases_data = []\n\n    # Test Case 1\n    l_sv_1 = np.tile(g_v, (S, 1))\n    l_sv_1[[0, 3, 7], 5] = 1\n    l_sv_1[[2, 4], 6] = 0\n    test_cases_data.append(l_sv_1)\n\n    # Test Case 2\n    l_sv_2 = np.tile(g_v, (S, 1))\n    test_cases_data.append(l_sv_2)\n\n    # Test Case 3\n    l_sv_3 = np.tile(g_v, (S, 1))\n    l_sv_3[list(range(5)), 2] = 1\n    l_sv_3[list(range(5, 10)), 9] = 0\n    test_cases_data.append(l_sv_3)\n\n    results = []\n    for l_sv in test_cases_data:\n        case_result = compute_metrics(V, S, L, adj, g_v, l_sv, tau_A, tau_B)\n        results.append(case_result)\n\n    # Final print statement in the exact required format.\n    print(str(results).replace(\" \", \"\"))\n\nsolve()\n```"
        }
    ]
}