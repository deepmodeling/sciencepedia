{
    "hands_on_practices": [
        {
            "introduction": "在分析动态功能连接之前，我们必须首先定义我们用来观察时间序列的“透镜”。第一个练习将重点讨论滑动窗口分析的基本参数——窗口长度 ($L$) 和步长 ($S$)，以及它们如何决定我们最终 dFC 估计的观测数量和时间特性。理解这些基础知识是进行可靠分析的第一步。",
            "id": "4193710",
            "problem": "一项静息态功能磁共振成像 (fMRI) 分析旨在通过在连续重叠的固定长度时间窗内计算连接性估计，来估算两个脑区之间的动态功能连接 (dFC)。考虑一个长度为 $T$ 个样本的单变量时间序列。对于滑动窗口 dFC，将窗口定义为 $L$ 个样本的连续段，第一个窗口从样本索引 $1$ 开始，后续窗口每隔 $S$ 个样本开始。只保留完全包含在 $T$ 个样本内的窗口。\n\n从这些定义出发，推导出一个关于 $T$、$L$ 和 $S$ 的函数，用以表示可以形成的窗口数量 $W$ 的表达式。然后，在 $T=600$、$L=60$ 和 $S=30$ 的条件下计算 $W$ 的值。接下来，讨论在保持 $T$ 和 $L$ 不变的情况下，将步长减小到 $S=10$ 会如何影响 dFC 估计的计算负担以及连续窗口化连接性估计之间的时间相关性（序列依赖性），并使用关于重叠和采样的基本原理解释。\n\n报告在 $T=600$、$L=60$ 和 $S=30$ 条件下的窗口数量作为最终数值答案。最终答案无需四舍五入，也无需单位。",
            "solution": "该问题陈述经评估具有科学依据、适定、客观且完整。它描述了时间序列分析中的一个标准程序，特别是神经科学中的动态功能连接 (dFC) 估计，并要求基于清晰、可形式化的定义进行推导和计算。所提供的参数对于 fMRI 数据分析是符合实际的。该问题有效。\n\n我们首先推导窗口数量 $W$ 的通用表达式，它是一个关于总时间序列长度 $T$、窗口长度 $L$ 和步长 $S$ 的函数。\n\n设时间序列的样本索引范围为 $1$ 到 $T$。一个窗口被定义为一个包含 $L$ 个样本的连续块。第一个窗口从样本索引 $1$ 开始。后续窗口以 $S$ 个样本的步长移动。\n\n让我们从 $k=0$ 开始为窗口编制索引，代表第一个窗口。第 $k$ 个窗口的起始样本索引 $s_k$ 可以表示为：\n$$s_k = 1 + kS$$\n其中 $k$ 是一个整数且 $k \\ge 0$。\n\n从索引 $s_k$ 开始的窗口包含从 $s_k$ 到 $s_k + L - 1$ 的样本。问题陈述中说明，只保留完全包含在 $T$ 个样本内的窗口。这对任何有效窗口的结束索引施加了以下约束：\n$$s_k + L - 1 \\le T$$\n\n将 $s_k$ 的表达式代入这个不等式，我们得到：\n$$(1 + kS) + L - 1 \\le T$$\n简化这个表达式得到：\n$$kS + L \\le T$$\n\n为了找到索引 $k$ 的最大可能值（我们将其表示为 $k_{max}$），我们解出 $k$：\n$$kS \\le T - L$$\n$$k \\le \\frac{T - L}{S}$$\n\n由于 $k$ 必须是整数，所以 $k$ 的最大有效值是该表达式的向下取整：\n$$k_{max} = \\left\\lfloor \\frac{T - L}{S} \\right\\rfloor$$\n\n窗口的有效索引是 $k = 0, 1, 2, \\dots, k_{max}$。窗口的总数 $W$ 是这些可能的整数值的数量，即 $k_{max} + 1$。\n因此，窗口数量的通用表达式是：\n$$W = \\left\\lfloor \\frac{T - L}{S} \\right\\rfloor + 1$$\n\n现在，我们使用给定的特定参数计算 $W$：$T = 600$，$L = 60$，$S = 30$。\n将这些值代入推导出的表达式中：\n$$W = \\left\\lfloor \\frac{600 - 60}{30} \\right\\rfloor + 1$$\n$$W = \\left\\lfloor \\frac{540}{30} \\right\\rfloor + 1$$\n$$W = \\lfloor 18 \\rfloor + 1$$\n$$W = 18 + 1$$\n$$W = 19$$\n因此，对于给定的参数，可以形成 $19$ 个窗口。\n\n最后，我们讨论在保持 $T = 600$ 和 $L = 60$ 不变的情况下，将步长减小到 $S = 10$ 的影响。\n\n首先，我们计算新的窗口数量，记为 $W'$。\n$$W' = \\left\\lfloor \\frac{600 - 60}{10} \\right\\rfloor + 1$$\n$$W' = \\left\\lfloor \\frac{540}{10} \\right\\rfloor + 1$$\n$$W' = \\lfloor 54 \\rfloor + 1$$\n$$W' = 54 + 1 = 55$$\n窗口数量从 $19$ 增加到 $55$。\n\n对计算负担的影响：\ndFC 的估计涉及为 $W$ 个窗口中的每一个计算连接性度量（例如皮尔逊相关）。因此，总计算成本与窗口数量近似成正比。通过将 $S$ 从 $30$ 减小到 $10$，窗口数量 $W$ 从 $19$ 增加到 $55$。这导致计算负担大幅增加，增加了约 $\\frac{55}{19} \\approx 2.89$ 倍。从推导出的公式可以看出，当 $T \\gg L$ 时，$W$ 与 $S$ 近似成反比，因此较小的步长会导致更多的窗口和更高的计算负荷。\n\n对连续估计值之间时间相关性的影响：\n连续窗口的连接性估计之间的时间相关性或序列依赖性，主要由这些窗口之间的数据重叠程度驱动。让我们量化这种重叠。考虑两个连续的窗口，索引为 $k$ 和 $k+1$。\n窗口 $k$ 跨越样本 $[s_k, s_k + L - 1]$。\n窗口 $k+1$ 跨越样本 $[s_{k+1}, s_{k+1} + L - 1] = [s_k + S, s_k + S + L - 1]$。\n\n这两个窗口之间重叠样本的数量由其样本索引集交集的长度给出。假设 $S \\le L$（在这两种情况下都成立），重叠量由以下公式给出：\n$$N_{overlap} = (s_k + L - 1) - (s_k + S) + 1 = L - S$$\n相对于窗口长度 $L$ 的重叠分数是：\n$$f_{overlap} = \\frac{L - S}{L} = 1 - \\frac{S}{L}$$\n\n对于初始情况，$S=30$ 且 $L=60$：\n$$f_{overlap} = 1 - \\frac{30}{60} = 1 - 0.5 = 0.5$$\n因此，连续窗口重叠 $50\\%$。\n\n对于第二种情况，$S=10$ 且 $L=60$：\n$$f_{overlap} = 1 - \\frac{10}{60} = 1 - \\frac{1}{6} \\approx 0.833$$\n现在连续窗口的重叠率约为 $83.3\\%$。\n\n减小步长 $S$ 会显著增加连续窗口之间的重叠。当从共享大量数据点的两个数据集中估计连接性时，所得的估计值预计将高度相关。因此，根据基本原理，将步长从 $S=30$ 减小到 $S=10$ 会增加所得 dFC 时间序列的时间相关性（序列依赖性）。这会产生一个更平滑、采样更精细的连接动态估计，但代价是引入了统计冗余，这可能会使后续的分析（例如识别连接性的显著变化）变得复杂。",
            "answer": "$$\\boxed{19}$$"
        },
        {
            "introduction": "现实世界中的 fMRI 数据很少是完美的，常常会受到头部运动等伪影的污染。一种常见的策略是“审查”或移除受污染的时间点，但这直接影响了我们进行滑动窗口分析的能力。本练习将演示如何量化由于运动审查造成的数据损失，这是评估 dFC 研究可行性和统计功效的关键一步。",
            "id": "4193717",
            "problem": "一位研究人员正在进行滑动窗口分析，以从一个预处理过的静息态功能磁共振成像时间序列中估计动态功能连接。窗口由连续的体积（volumes）序列定义，运动污染通过审查（censoring）超过指定帧间位移（Framewise Displacement, FD）阈值的体积来处理。在此实验方案中，任何包含至少一个被审查体积的窗口都被视为受污染，并从后续的连接性估计中排除。\n\n给定以下采集和分析参数以及质量控制结果：\n- 总体积数为 $T = 240$。\n- 滑动窗口长度为 $L = 30$ 个体积。\n- 连续窗口起始索引之间的步长为 $S = 5$ 个体积。\n- 窗口的起始索引为 $s \\in \\{1, 1+S, 1+2S, \\dots, T-L+1\\}$，每个窗口跨越的体积为 $\\{s, s+1, \\dots, s+L-1\\}$。\n- 被审查的体积集合（由于瞬时运动过大，FD超过阈值）为\n$$\\mathcal{C} = \\{14, 15, 16, 45, 90, 91, 92, 93, 94, 95, 120, 121, 150, 151, 152, 153, 154, 155, 200, 201, 202, 203, 204, 205, 230\\}.$$\n\n仅使用这些定义和参数，计算：\n1. 受运动污染的窗口所占的比例，定义为受污染窗口数与总窗口数之比。将此比例表示为一个精确分数，无需四舍五入。\n2. 可用于后续动态分析的干净窗口的有效数量，定义为不与 $\\mathcal{C}$ 相交的窗口数量。\n\n请使用 LaTeX 的 $\\texttt{pmatrix}$ 环境，将您的最终答案表示为一个包含两个量的单行矩阵，其中第一个条目是受污染比例的精确分数，第二个条目是干净窗口的整数数量。无需四舍五入，最终答案中不应包含任何单位。",
            "solution": "通过滑动窗口实现的动态功能连接依赖于在时间序列的短连续片段内估计时变的统计依赖关系。此计算的基本要素是：\n- 滑动窗口的定义：一个从索引 $s$ 开始的窗口覆盖集合 $\\{s, s+1, \\dots, s+L-1\\}$。\n- 窗口网格：起始索引 $s$ 以步长 $S$ 分隔，从 $1$ 开始，到 $T-L+1$ 结束。\n- 污染规则：如果一个窗口包含任何被审查的体积 $v \\in \\mathcal{C}$，则该窗口被视为受污染。\n\n首先，计算总窗口数。有效的起始索引为\n$$s \\in \\{1, 1+S, 1+2S, \\dots, T-L+1\\}.$$\n当 $T=240$，$L=30$ 且 $S=5$ 时，最大的起始索引是\n$$T - L + 1 = 240 - 30 + 1 = 211.$$\n因此，起始索引构成等差数列 $s_k = 1 + 5k$，其中 $k = 0, 1, 2, \\dots, K$，且 $s_K \\le 211$。解方程 $1 + 5K = 211$ 可得\n$$5K = 210 \\Rightarrow K = 42,$$\n所以总窗口数为\n$$N_{\\text{total}} = K + 1 = 43.$$\n\n接下来，确定哪些窗口是受污染的。一个从 $s$ 开始的窗口是受污染的，如果存在 $v \\in \\mathcal{C}$ 使得 $v \\in \\{s, s+1, \\dots, s+L-1\\}$，这等价于\n$$s \\leq v \\leq s + L - 1.$$\n对于给定的 $v$，这个条件可以反转为对 $s$ 的约束：\n$$v - L + 1 \\leq s \\leq v.$$\n对于一个被审查的体积块 $\\{a, a+1, \\dots, b\\}$，所有 $v \\in [a,b]$ 的约束的并集简化为\n$$a - L + 1 \\leq s \\leq b.$$\n我们现在将 $\\mathcal{C}$ 分割成连续的块，并推导出相应的起始索引污染区间，将它们裁剪到有效的起始范围 $[1, T-L+1] = [1, 211]$ 内：\n- 体积块 $\\{14, 15, 16\\}$ 产生 $[14 - L + 1, 16] = [14 - 29, 16] = [-15, 16]$，裁剪为 $[1, 16]$。\n- 体积块 $\\{45\\}$ 产生 $[45 - 29, 45] = [16, 45]$。\n- 体积块 $\\{90, 91, 92, 93, 94, 95\\}$ 产生 $[90 - 29, 95] = [61, 95]$。\n- 体积块 $\\{120, 121\\}$ 产生 $[120 - 29, 121] = [91, 121]$。\n- 体积块 $\\{150, 151, 152, 153, 154, 155\\}$ 产生 $[150 - 29, 155] = [121, 155]$。\n- 体积块 $\\{200, 201, 202, 203, 204, 205\\}$ 产生 $[200 - 29, 205] = [171, 205]$。\n- 体积块 $\\{230\\}$ 产生 $[230 - 29, 230] = [201, 230]$，裁剪为 $[201, 211]$。\n\n求这些区间的并集，合并重叠部分：\n- 区间 $[1, 16]$ 和 $[16, 45]$ 合并为 $[1, 45]$。\n- 区间 $[61, 95]$、$[91, 121]$ 和 $[121, 155]$ 合并为 $[61, 155]$。\n- 区间 $[171, 205]$ 和 $[201, 211]$ 合并为 $[171, 211]$。\n\n因此，受污染的起始索引集合是三个不相交区间的并集：\n$$[1, 45] \\cup [61, 155] \\cup [171, 211].$$\n\n我们现在计算网格 $s \\in \\{1, 6, 11, \\dots, 211\\}$ 中有多少个起始索引落入每个区间。因为起始索引满足 $s \\equiv 1 \\pmod{5}$，可以通过列举或使用 $s = 1 + 5k$ 中 $k$ 的界限来进行计数。\n\n- 对于 $[1, 45]$：允许的 $s$ 值为 $1, 6, 11, 16, 21, 26, 31, 36, 41$，得到\n$$N_{[1,45]} = 9.$$\n\n- 对于 $[61, 155]$：允许的 $s$ 值从 $61$ 开始，以 $5$ 为步长递增至 $151$，即 $61, 66, 71, 76, 81, 86, 91, 96, 101, 106, 111, 116, 121, 126, 131, 136, 141, 146, 151$，得到\n$$N_{[61,155]} = 19.$$\n\n- 对于 $[171, 211]$：允许的 $s$ 值从 $171$ 开始，以 $5$ 为步长递增至 $211$，即 $171, 176, 181, 186, 191, 196, 201, 206, 211$，得到\n$$N_{[171,211]} = 9.$$\n\n将这些相加，\n$$N_{\\text{contaminated}} = N_{[1,45]} + N_{[61,155]} + N_{[171,211]} = 9 + 19 + 9 = 37.$$\n\n因此，受污染窗口的比例是\n$$p_{\\text{contaminated}} = \\frac{N_{\\text{contaminated}}}{N_{\\text{total}}} = \\frac{37}{43}.$$\n\n可用于后续分析的干净窗口的有效数量是\n$$N_{\\text{clean}} = N_{\\text{total}} - N_{\\text{contaminated}} = 43 - 37 = 6.$$\n\n无需四舍五入。最终答案应报告为一个行矩阵，包含精确分数和其后的整数：\n$$\\begin{pmatrix} \\frac{37}{43}  6 \\end{pmatrix}.$$",
            "answer": "$$\\boxed{\\begin{pmatrix}\\frac{37}{43}  6\\end{pmatrix}}$$"
        },
        {
            "introduction": "观察连接性随时间波动是一回事，而确定这些波动是否具有统计学意义则是另一回事。这最后一个练习将从计算转向推断，指导您完成一个相位随机化代理检验的实现。通过创建一个保留原始信号频谱特性但破坏其时序相关性的零模型，您可以严格检验观察到的连接动态是否显著大于偶然预期的水平。",
            "id": "4193720",
            "problem": "给定两个离散的实值时间序列 $x_t$ 和 $y_t$，它们代表以均匀间隔采样的神经信号，每个序列的长度为 $T$。目标是评估 $x_t$ 和 $y_t$ 之间滑动窗口动态功能连接（dFC）的波动是否超出了谱约束零假设下的预期。在该零假设中，每个序列保留其功率谱，但缺乏真实的时变交叉依赖性。动态功能连接（dFC）在操作上定义为在连续、重叠的窗口内计算的皮尔逊相关性。该检验必须使用相位随机化代理程序来实现。\n\n使用的基本原理：\n- 实值时间序列 $x_t$ 的离散傅里叶变换（DFT）定义为 $$X_k = \\sum_{t=0}^{T-1} x_t e^{-i 2\\pi kt/T}, \\quad k \\in \\{0,1,\\dots,T-1\\}.$$ 幅度 $|X_k|$ 决定了频率索引 $k$ 处的功率。对于实信号，频谱满足厄米对称性。\n- 从索引 $s$ 开始，长度为 $L$ 的窗口内的皮尔逊相关性为 $$r_s = \\frac{\\sum_{t=s}^{s+L-1} \\left(x_t - \\bar{x}_s\\right)\\left(y_t - \\bar{y}_s\\right)}{\\sqrt{\\sum_{t=s}^{s+L-1} \\left(x_t - \\bar{x}_s\\right)^2}\\sqrt{\\sum_{t=s}^{s+L-1} \\left(y_t - \\bar{y}_s\\right)^2}},$$ 其中 $\\bar{x}_s$ 和 $\\bar{y}_s$ 是窗口内的样本均值。在平稳性假设下，Fisher $z$ 变换 $z_s = \\operatorname{arctanh}(r_s)$ 可以稳定不同窗口间的相关性方差。\n- 时间序列 $x_t$ 的相位随机化代理是一个新的序列 $\\tilde{x}_t$，其 DFT 满足对所有 $k$ 都有 $|\\tilde{X}_k| = |X_k|$，并且其正频率索引的相位在 $[0,2\\pi)$ 上独立同分布地均匀分布，负频率索引的相位通过厄米对称性设置以确保 $\\tilde{x}_t$ 是实数。直流（DC）分量和奈奎斯特分量（如果 $T$ 是偶数）保持为实值。\n\n你的程序必须：\n1. 实现一个滑动窗口分析，对于所有有效的起始索引 $s \\in \\{0, S, 2S, \\dots\\}$ 且 $s+L \\le T$，计算长度为 $L$、步长（step）为 $S$ 的连续窗口的 $r_s$。将每个 $r_s$ 转换为 $z_s = \\operatorname{arctanh}(r_s)$，并通过所有窗口的 $\\{z_s\\}$ 的标准差 $\\sigma_z$ 来概括波动幅度。\n2. 实现一个相位随机化代理生成器，给定 $x_t$ 返回 $\\tilde{x}_t$，给定 $y_t$ 返回 $\\tilde{y}_t$，每个代理序列都保留其各自的幅度谱 $|X_k|$ 和 $|Y_k|$，同时独立地随机化相位（并强制执行厄米对称性）。\n3. 通过使用独立相位随机化的代理 $(\\tilde{x}_t^{(b)}, \\tilde{y}_t^{(b)})$ 计算 $b \\in \\{1,\\dots,B\\}$ 的 $\\sigma_z^{(b)}$，生成 $\\sigma_z$ 的零分布，并获得 $\\{\\sigma_z^{(b)}\\}_{b=1}^B$ 的 $0.95$ 分位数 $q_{0.95}$。\n4. 返回一个布尔值，指示来自观测数据的 $\\sigma_z$ 是否超过 $q_{0.95}$。\n\n用合成的、科学上合理的、能产生清晰可解释的 dFC 行为的场景来设计测试套件。为了可复现性，在生成数据和代理之前为每种情况设置指定的随机种子。\n\n测试套件：\n- 情况 1（理想情况，清晰的时变耦合）：\n  - $T = 1024$, $L = 128$, $S = 64$, $B = 200$。\n  - 生成 $x_t$ 作为 1 阶自回归（AR(1)）过程 $x_t = \\phi_x x_{t-1} + \\epsilon_t$，其中 $\\phi_x = 0.9$，新息 $\\epsilon_t \\sim \\mathcal{N}(0,\\sigma_x^2)$ 被选择以产生单位方差。类似地生成 $y_t$，其中 $\\phi_y = 0.9$。通过对 $t \\in [256,768)$ 设置 $y_t \\leftarrow y_t + c x_t$（其中 $c = 0.8$）来引入一个耦合段 $[256,768)$。使用随机种子 $42$。\n  - 预期结果：观测到的 $\\sigma_z$ 应超过 $q_{0.95}$，返回布尔值 $True$。\n- 情况 2（边界情况，平稳独立）：\n  - $T = 1024$, $L = 128$, $S = 64$, $B = 200$。\n  - 如情况 1 中生成独立的 AR(1) 过程，其中 $\\phi_x = 0.9$, $\\phi_y = 0.9$，但没有耦合。使用随机种子 $123$。\n  - 预期结果：观测到的 $\\sigma_z$ 不应超过 $q_{0.95}$，返回布尔值 $False$。\n- 情况 3（边缘情况，较短长度、窄带内容和短暂事件）：\n  - $T = 400$, $L = 100$, $S = 50$, $B = 200$。\n  - 生成 $x_t$ 为 $x_t = \\sin(2\\pi f t + \\varphi_x) + \\eta_t$，其中 $f = 0.08$，$\\varphi_x$ 在 $[0,2\\pi)$ 上均匀抽取，且 $\\eta_t \\sim \\mathcal{N}(0,\\sigma^2)$，$\\sigma = 0.5$。类似地生成 $y_t$，具有独立的相位 $\\varphi_y$ 和独立的噪声。通过对 $t \\in [150,250)$ 设置 $y_t \\leftarrow y_t + c x_t$（其中 $c = 1.0$）来引入一个耦合段 $[150,250)$。使用随机种子 $7$。\n  - 预期结果：观测到的 $\\sigma_z$ 可能会超过 $q_{0.95}$，具体取决于谱内容和事件强度；此情况测试在窄带主导下的灵敏度。\n\n最终输出格式：\n- 你的程序应产生单行输出，其中包含三个测试用例的结果，格式为方括号内用逗号分隔的布尔值列表（例如，`\"[True,False,True]\"`）。不应打印任何其他文本。\n\n所有答案都是无单位的实数或布尔值；不需要物理单位或角度单位。所有数值答案和参数都必须视为无量纲。",
            "solution": "该问题要求实现一个统计检验，以确定两个时间序列 $x_t$ 和 $y_t$ 之间的动态功能连接（dFC）波动是否具有统计显著性。所指定的方法是基于相位随机化代理数据的非参数检验，这是神经科学中建立零假设的标准技术，该零假设保留了单个信号的谱特性（从而保留了自相关结构），同时破坏了它们特定的时间交叉相关。\n\n该解决方案基于三个核心原则设计：（1）量化 dFC 波动，（2）构建谱约束的零分布，以及（3）通过蒙特卡洛模拟进行统计推断。\n\n首先，我们将 dFC 及其波动操作化。两个时间序列 $x_t$ 和 $y_t$（每个长度为 $T$）之间的动态连接性是通过计算在以步幅 $S$ 移动的指定长度 $L$ 的滑动窗口内的皮尔逊相关系数 $r_s$ 来测量的。对于每个从时间索引 $s$ 开始的窗口，相关性计算如下：\n$$r_s = \\frac{\\sum_{t=s}^{s+L-1} (x_t - \\bar{x}_s)(y_t - \\bar{y}_s)}{\\sqrt{\\sum_{t=s}^{s+L-1} (x_t - \\bar{x}_s)^2}\\sqrt{\\sum_{t=s}^{s+L-1} (y_t - \\bar{y}_s)^2}}$$\n其中 $\\bar{x}_s$ 和 $\\bar{y}_s$ 是各自序列在该窗口内的均值。皮尔逊相关系数 $r$ 的范围在 $-1$ 和 $1$ 之间。其采样分布是偏斜的，特别是当 $r$ 的值接近边界时。为了减轻这种情况并稳定方差，我们对每个相关值应用 Fisher $z$ 变换：\n$$z_s = \\operatorname{arctanh}(r_s) = \\frac{1}{2}\\ln\\left(\\frac{1+r_s}{1-r_s}\\right)$$\n得到的 $z$ 分数时间序列 $\\{z_s\\}$ 代表了连接强度随时间变化的轨迹。dFC 波动的整体幅度随后通过该序列的标准差来量化，记为 $\\sigma_z$。这个值 $\\sigma_z^{\\text{obs}}$ 就是我们寻求检验的统计量。\n\n其次，我们必须建立一个零假设。零假设 $H_0$ 假定，观测到的 dFC 波动不大于两个独立的平稳过程所预期的波动，这两个过程恰好与原始信号 $x_t$ 和 $y_t$ 具有相同的功率谱。为了在该零假设下生成数据，我们使用相位随机化代理方法。对于给定的时间序列 $x_t$，其代理 $\\tilde{x}_t$ 被构造成具有相同的功率谱但随机化的时间结构。这在频域中实现。我们计算信号的离散傅里叶变换（DFT），即 $X_k$。傅里叶系数的幅度 $|X_k|$（定义了功率谱）被保留下来。然而，相位 $\\arg(X_k)$ 被替换为从 $[0, 2\\pi)$ 的均匀分布中独立抽取的新相位。为确保生成的代理时间序列 $\\tilde{x}_t$ 是实值的，必须对复数谱强制执行厄米对称性。具体来说，频率 $-k$ 的相位必须是频率 $k$ 相位的负数。此外，直流分量（$k=0$）以及（如果序列长度 $T$ 是偶数）奈奎斯特分量（$k=T/2$）必须保持实值；它们的原始值被保留。然后，新的复数谱 $\\tilde{X}_k$ 通过逆 DFT 转换回时域，得到代理信号 $\\tilde{x}_t$。此过程独立地应用于 $x_t$ 和 $y_t$。\n\n第三，我们进行统计推断。我们生成大量的（$B$ 个）代理对 $(\\tilde{x}_t^{(b)}, \\tilde{y}_t^{(b)})$，其中 $b=1, \\dots, B$。对于每一对，我们重复整个 dFC 分析流程，以计算一个代理 dFC 波动统计量 $\\sigma_z^{(b)}$。这 $B$ 个值的集合 $\\{\\sigma_z^{(b)}\\}$ 构成了一个经验零分布。通过将我们的观测统计量 $\\sigma_z^{\\text{obs}}$ 与此分布进行比较，我们可以评估其显著性。具体来说，我们找到零分布的 $0.95$ 分位数 $q_{0.95}$。如果 $\\sigma_z^{\\text{obs}} > q_{0.95}$，我们得出结论，观测到的 dFC 波动在平稳零模型下显著大于偶然预期的水平，我们拒绝 $H_0$。这对应于显著性水平为 $\\alpha=0.05$ 的单尾检验。\n\n该实现涉及几个函数。每个测试用例的数据生成函数创建具有已知属性的合成信号（例如，有或没有真实时变耦合的时期）。函数 `generate_surrogate` 使用 `numpy.fft.rfft` 来实现相位随机化，以高效处理实信号。函数 `calculate_dfc_fluctuation` 执行滑动窗口相关性分析，包括 Fisher $z$ 变换和最终的标准差计算，并仔细处理数值边缘情况，例如完全相关（会导致 $\\operatorname{arctanh}$ 返回 `inf`）或零方差窗口。一个主函数 `run_dfc_test` 协调整个过程：计算观测到的 $\\sigma_z$，从 $B$ 个代理生成零分布，并返回最终的布尔决策。指定的随机种子确保了合成数据和代理生成过程的可复现性。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.signal import lfilter\n\ndef generate_surrogate(signal: np.ndarray, rng: np.random.Generator) -> np.ndarray:\n    \"\"\"\n    Generates a phase-randomized surrogate of a real-valued time series.\n\n    The surrogate has the same power spectrum (and autocorrelation) as the\n    original signal but is otherwise temporally decorrelated.\n    \"\"\"\n    T = len(signal)\n    \n    # Compute the Fourier transform of the real signal\n    X = np.fft.rfft(signal)\n    \n    # Preserve the magnitudes\n    magnitudes = np.abs(X)\n    \n    # Generate random phases uniformly from [0, 2*pi)\n    # The number of phases corresponds to the output of rfft\n    random_phases = rng.uniform(0, 2 * np.pi, len(X))\n    \n    # Create the new complex spectrum by combining original magnitudes with random phases\n    surrogate_X = magnitudes * np.exp(1j * random_phases)\n    \n    # Enforce constraints for a real-valued time series:\n    # 1. DC component (k=0) must be real. We preserve its original value.\n    surrogate_X[0] = X[0]\n    \n    # 2. Nyquist component (k=T/2), if T is even, must be real. Preserve original.\n    if T % 2 == 0:\n        surrogate_X[-1] = X[-1]\n        \n    # Perform the inverse Fourier transform to get the surrogate time series\n    surrogate_signal = np.fft.irfft(surrogate_X, n=T)\n    \n    return surrogate_signal\n\ndef calculate_dfc_fluctuation(x: np.ndarray, y: np.ndarray, L: int, S: int) -> float:\n    \"\"\"\n    Calculates the fluctuation of Dynamic Functional Connectivity (dFC).\n\n    dFC is computed using sliding window Pearson correlation, followed by Fisher's\n    z-transform. Fluctuation is the standard deviation of the z-scores.\n    \"\"\"\n    T = len(x)\n    z_scores = []\n    \n    for s in range(0, T - L + 1, S):\n        x_win = x[s : s + L]\n        y_win = y[s : s + L]\n\n        # Handle windows with zero variance\n        if np.std(x_win) == 0 or np.std(y_win) == 0:\n            z_scores.append(0.0)\n            continue\n            \n        r = np.corrcoef(x_win, y_win)[0, 1]\n        \n        # Clip r to avoid inf from arctanh at r = +/- 1\n        r_clipped = np.clip(r, -1.0 + 1e-12, 1.0 - 1e-12)\n        \n        z = np.arctanh(r_clipped)\n        z_scores.append(z)\n        \n    if not z_scores:\n        return 0.0\n\n    sigma_z = np.std(z_scores)\n    return sigma_z\n\ndef run_dfc_test(x: np.ndarray, y: np.ndarray, L: int, S: int, B: int, rng: np.random.Generator) -> bool:\n    \"\"\"\n    Runs the full statistical test for dFC significance.\n    \"\"\"\n    # 1. Compute the observed dFC fluctuation\n    sigma_z_obs = calculate_dfc_fluctuation(x, y, L, S)\n    \n    # 2. Generate the null distribution\n    surrogate_sigma_z = []\n    for _ in range(B):\n        x_surr = generate_surrogate(x, rng)\n        y_surr = generate_surrogate(y, rng)\n        sigma_z_surr = calculate_dfc_fluctuation(x_surr, y_surr, L, S)\n        surrogate_sigma_z.append(sigma_z_surr)\n        \n    # 3. Find the 0.95 quantile of the null distribution\n    q_095 = np.quantile(surrogate_sigma_z, 0.95)\n    \n    # 4. Compare observed statistic to the null distribution threshold\n    return sigma_z_obs > q_095\n\ndef generate_ar1_data(T: int, phi: float, rng: np.random.Generator) -> np.ndarray:\n    \"\"\"\n    Generates a mean-zero, unit-variance AR(1) process.\n    \"\"\"\n    # Variance of innovation to yield unit variance for the process\n    sigma_eps = np.sqrt(1 - phi**2)\n    \n    # Generate innovations\n    eps = rng.normal(0, sigma_eps, T)\n    \n    # AR(1) filter parameters: a_1*y[n] = b_0*x[n] - a_1*y[n-1]\n    # y[n] - phi*y[n-1] = eps[n], so a=[1, -phi], b=[1]\n    ar_process = lfilter([1], [1, -phi], eps)\n    \n    # Burn-in might be needed for perfect stationarity, but for long T, this is fine.\n    # Normalize to enforce mean-zero, unit-variance\n    ar_process = (ar_process - np.mean(ar_process)) / np.std(ar_process)\n    return ar_process\n\ndef solve():\n    \"\"\"\n    Main solver function to run all test cases and print results.\n    \"\"\"\n    test_cases = [\n        # Case 1 (happy path, clear time-varying coupling)\n        {'case_id': 1, 'T': 1024, 'L': 128, 'S': 64, 'B': 200, 'seed': 42,\n         'phi': 0.9, 'c': 0.8, 'coupling_interval': (256, 768)},\n        \n        # Case 2 (boundary, stationary independence)\n        {'case_id': 2, 'T': 1024, 'L': 128, 'S': 64, 'B': 200, 'seed': 123,\n         'phi': 0.9, 'c': 0.0, 'coupling_interval': (0, 0)},\n        \n        # Case 3 (edge, shorter length with narrowband content)\n        {'case_id': 3, 'T': 400, 'L': 100, 'S': 50, 'B': 200, 'seed': 7,\n         'f': 0.08, 'noise_sigma': 0.5, 'c': 1.0, 'coupling_interval': (150, 250)}\n    ]\n    \n    results = []\n    \n    for case in test_cases:\n        rng = np.random.default_rng(case['seed'])\n        \n        if case['case_id'] in [1, 2]:\n            x = generate_ar1_data(case['T'], case['phi'], rng)\n            y = generate_ar1_data(case['T'], case['phi'], rng)\n            start, end = case['coupling_interval']\n            if end > start:\n                y[start:end] += case['c'] * x[start:end]\n                # Renormalize to not bias variance-based metrics\n                y = (y - np.mean(y)) / np.std(y)\n\n        elif case['case_id'] == 3:\n            t_ax = np.arange(case['T'])\n            \n            phi_x = rng.uniform(0, 2 * np.pi)\n            eta_x = rng.normal(0, case['noise_sigma'], case['T'])\n            x = np.sin(2 * np.pi * case['f'] * t_ax + phi_x) + eta_x\n            \n            phi_y = rng.uniform(0, 2 * np.pi)\n            eta_y = rng.normal(0, case['noise_sigma'], case['T'])\n            y = np.sin(2 * np.pi * case['f'] * t_ax + phi_y) + eta_y\n            \n            start, end = case['coupling_interval']\n            y[start:end] += case['c'] * x[start:end]\n\n            # Normalize after adding coupling\n            x = (x - np.mean(x)) / np.std(x)\n            y = (y - np.mean(y)) / np.std(y)\n\n        # Run the dFC significance test with a new RNG for surrogate generation\n        # as per \"set a specified random seed for each case before ... surrogates\"\n        test_rng = np.random.default_rng(case['seed'])\n        result = run_dfc_test(x, y, case['L'], case['S'], case['B'], test_rng)\n        results.append(result)\n        \n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n\n```"
        }
    ]
}