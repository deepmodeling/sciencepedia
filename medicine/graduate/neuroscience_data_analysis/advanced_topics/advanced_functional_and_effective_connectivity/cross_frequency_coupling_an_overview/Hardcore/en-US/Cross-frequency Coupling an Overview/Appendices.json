{
    "hands_on_practices": [
        {
            "introduction": "Before we can analyze cross-frequency coupling, we must first correctly capture the raw neural signal. This exercise  walks through the critical first step of determining the minimum sampling rate required, grounding the abstract Nyquist-Shannon theorem in a concrete CFC scenario. Understanding this principle is crucial to prevent the irreversible loss of high-frequency information before analysis even begins.",
            "id": "4151446",
            "problem": "You are designing a data acquisition system for analyzing cross-frequency coupling (CFC) between a low-frequency phase and a high-frequency amplitude in intracranial local field potential (LFP) recordings. The high-frequency component is narrowband with energy confined to the interval $[80\\,\\mathrm{Hz}, 150\\,\\mathrm{Hz}]$, and its amplitude envelope is band-limited by physiology and preprocessing choices such that the envelope has no frequency components above $20\\,\\mathrm{Hz}$. The low-frequency phase is extracted from a band-limited signal with energy confined to the interval $[4\\,\\mathrm{Hz}, 12\\,\\mathrm{Hz}]$. You will compute the minimum sampling rate required to accurately capture both the high-frequency amplitude envelope and the low-frequency phase.\n\nUse only the following fundamental bases:\n\n- The Nyquist–Shannon Sampling Theorem (NSST): any signal band-limited to a maximum frequency $f_{\\max}$ requires a sampling rate strictly greater than $2 f_{\\max}$ to avoid aliasing.\n- In amplitude modulation of a band-limited carrier $x(t)$ with center frequencies in a band $[f_{\\mathrm{H,low}}, f_{\\mathrm{H,high}}]$ by a band-limited envelope $a(t)$ confined to $[0, B_{\\mathrm{env}}]$, the spectrum of the modulated signal is confined within sidebands whose highest frequency does not exceed $f_{\\mathrm{H,high}} + B_{\\mathrm{env}}$.\n\nAssume no other spectral content is present outside the stated bands, and that you will compute instantaneous phase and amplitude via analytic signal methods (e.g., Hilbert transform) after digital band-pass filtering, which cannot recover energy lost to aliasing in acquisition. Determine the minimum sampling rate that simultaneously satisfies the constraints implied by the low-frequency phase band and the high-frequency amplitude modulation sidebands. Express your final sampling rate in $\\mathrm{Hz}$. If you decide to round, round to four significant figures; otherwise, provide the exact value.",
            "solution": "The problem requires the determination of the minimum sampling rate, denoted as $f_s$, for a data acquisition system designed to analyze cross-frequency coupling in local field potential (LFP) recordings. The preservation of information for this analysis depends on acquiring the raw signal without aliasing, as subsequent digital filtering cannot recover information lost during sampling. The total signal contains multiple components, and the sampling rate must be sufficient to capture the highest frequency present across all of them.\n\nThe LFP signal is composed of two primary components of interest: a low-frequency component and a high-frequency component. To satisfy the Nyquist-Shannon Sampling Theorem (NSST) for the composite signal, we must first identify its maximum frequency, $f_{\\max}$. The NSST, as stated in the problem, requires that the sampling rate $f_s$ must be strictly greater than $2 f_{\\max}$.\n\nFirst, let's analyze the low-frequency component. Its energy is confined to the interval $[4\\,\\mathrm{Hz}, 12\\,\\mathrm{Hz}]$. The maximum frequency for this part of the signal is therefore $f_{\\mathrm{L,max}} = 12\\,\\mathrm{Hz}$. To capture this component without aliasing, the sampling rate would need to satisfy $f_s > 2 \\times 12\\,\\mathrm{Hz} = 24\\,\\mathrm{Hz}$.\n\nNext, we analyze the high-frequency component. This component is described as a narrowband signal with carrier energy in the interval $[f_{\\mathrm{H,low}}, f_{\\mathrm{H,high}}] = [80\\,\\mathrm{Hz}, 150\\,\\mathrm{Hz}]$. This carrier is amplitude-modulated by an envelope whose own spectral content is band-limited to a maximum frequency of $B_{\\mathrm{env}} = 20\\,\\mathrm{Hz}$. The problem provides the fundamental basis for the spectrum of such a modulated signal: the highest frequency of the resulting signal does not exceed $f_{\\mathrm{H,high}} + B_{\\mathrm{env}}$. This phenomenon is due to the process of modulation, which in the frequency domain corresponds to a convolution of the carrier spectrum with the envelope spectrum, creating upper and lower sidebands. The upper sideband extends the spectral content of the signal upwards.\n\nUsing the provided values, we can calculate the maximum frequency of this modulated high-frequency component, $f_{\\mathrm{H,max}}$:\n$$\nf_{\\mathrm{H,max}} = f_{\\mathrm{H,high}} + B_{\\mathrm{env}}\n$$\nSubstituting the given values:\n$$\nf_{\\mathrm{H,max}} = 150\\,\\mathrm{Hz} + 20\\,\\mathrm{Hz} = 170\\,\\mathrm{Hz}\n$$\nTo capture this high-frequency modulated component without aliasing, the sampling rate must satisfy $f_s > 2 \\times 170\\,\\mathrm{Hz} = 340\\,\\mathrm{Hz}$.\n\nThe data acquisition system samples the entire raw LFP signal, which is a superposition of all its components. Therefore, to prevent aliasing for the *entire* signal, the sampling rate must be chosen based on the absolute maximum frequency present in the signal. This maximum frequency, $f_{\\max}$, is the greater of the maximum frequencies of its constituent parts.\n$$\nf_{\\max} = \\max(f_{\\mathrm{L,max}}, f_{\\mathrm{H,max}})\n$$\n$$\nf_{\\max} = \\max(12\\,\\mathrm{Hz}, 170\\,\\mathrm{Hz}) = 170\\,\\mathrm{Hz}\n$$\nApplying the NSST to the entire signal, we have the condition:\n$$\nf_s > 2 f_{\\max}\n$$\n$$\nf_s > 2 \\times 170\\,\\mathrm{Hz}\n$$\n$$\nf_s > 340\\,\\mathrm{Hz}\n$$\nThe problem asks for the minimum sampling rate. This corresponds to the theoretical lower bound, or infimum, of the set of valid sampling rates, which is known as the Nyquist rate. Any sampling rate strictly greater than this value will prevent aliasing. The minimum required rate is therefore the boundary value of this inequality.\n$$\nf_{s,\\mathrm{min}} = 2 f_{\\max} = 340\\,\\mathrm{Hz}\n$$\nThis value is exact, so no rounding is necessary. This sampling rate ensures that both the low-frequency phase information (contained in the $[4\\,\\mathrm{Hz}, 12\\,\\mathrm{Hz}]$ band) and the high-frequency amplitude information (encoded in the sidebands of the $[80\\,\\mathrm{Hz}, 150\\,\\mathrm{Hz}]$ signal, extending up to $170\\,\\mathrm{Hz}$) can be recovered without distortion from aliasing during the initial acquisition.",
            "answer": "$$\\boxed{340}$$"
        },
        {
            "introduction": "After acquiring data, we use digital filters to isolate the low- and high-frequency components of interest. However, no filter is perfect, and their imperfections can introduce serious artifacts. This practice  provides a theoretical demonstration of how \"spectral leakage\" from filter transition bands can create the illusion of coupling even in a signal that has none, a critical confound to understand and mitigate in any CFC analysis.",
            "id": "4151495",
            "problem": "Consider a zero-mean, wide-sense stationary neural field signal $x(t)$ with flat two-sided power spectral density (PSD) $S_{x}(f) = \\sigma^{2}$ for all real frequencies $f \\in \\mathbb{R}$. You analyze cross-frequency coupling (CFC) by extracting a low-frequency component and a high-frequency component using two real, zero-phase, linear time-invariant (LTI) bandpass filters. Let their magnitude responses be denoted by $H_{L}(f)$ (low-frequency) and $H_{H}(f)$ (high-frequency). Each filter has an ideal unity-gain passband of width $B$ and symmetric, linear transition bands of width $\\Delta$ on both sides of the passband, reaching zero gain outside the transition. Specifically, for the low-frequency filter,\n- $|H_{L}(f)| = 1$ for $f \\in [f_{L-}, f_{L+}]$ where $f_{L+} - f_{L-} = B_{L}$;\n- $|H_{L}(f)|$ decreases linearly from $1$ to $0$ as $f$ increases from $f_{L+}$ to $f_{L+} + \\Delta$;\n- $|H_{L}(f)|$ decreases linearly from $1$ to $0$ as $f$ decreases from $f_{L-}$ to $f_{L-} - \\Delta$;\nand analogously for the high-frequency filter with passband $[f_{H-}, f_{H+}]$ of width $B_{H}$ and transition width $\\Delta$.\n\nAssume the passbands do not overlap and that the only overlap between the two magnitude responses occurs between the upper transition band of the low-frequency filter and the lower transition band of the high-frequency filter. Let this overlap interval be $[f_{L+}, f_{H-}]$ of length $\\ell = f_{H-} - f_{L+}$, with $0 < \\ell \\leq \\Delta$. The outputs are $y_{L}(t)$ and $y_{H}(t)$, obtained by filtering $x(t)$ with $H_{L}$ and $H_{H}$, respectively.\n\nStarting from the spectral representation of second-order moments for LTI-filtered stationary processes, derive the dependence of the variance and cross-covariance of $y_{L}(t)$ and $y_{H}(t)$ on the passband widths $B_{L}$ and $B_{H}$ and the transition width $\\Delta$, and then derive the Pearson correlation coefficient\n$$\\rho = \\frac{\\operatorname{Cov}(y_{L}, y_{H})}{\\sqrt{\\operatorname{Var}(y_{L}) \\operatorname{Var}(y_{H})}}$$\nas a function of $B_{L}$, $B_{H}$, $\\Delta$, and $\\ell$. Use your derivation to explain how nonzero overlap $\\ell$ embodies spectral leakage that can create spurious cross-band dependencies even when $x(t)$ has a flat PSD.\n\nFinally, evaluate your derived expression for $\\rho$ for the parameter values $B_{L} = 6\\,\\text{Hz}$, $B_{H} = 10\\,\\text{Hz}$, $\\Delta = 8\\,\\text{Hz}$, and $\\ell = 4\\,\\text{Hz}$. Express the final answer as a single exact analytical expression with no units and do not round.",
            "solution": "The problem asks for the Pearson correlation coefficient $\\rho$ between two filtered signals, $y_L(t)$ and $y_H(t)$, derived from a common white noise input $x(t)$. The filters are non-ideal, with overlapping transition bands.\n\nFirst, we recall the relationship between the power spectral density (PSD) of an input to a linear time-invariant (LTI) system and the statistics of its output. For a zero-mean, wide-sense stationary (WSS) input $x(t)$ with PSD $S_x(f)$, the variance of the output $y(t)$ from a filter with frequency response $H(f)$ is:\n$$ \\operatorname{Var}(y) = \\int_{-\\infty}^{\\infty} |H(f)|^2 S_x(f) \\, df $$\nThe cross-covariance between two outputs, $y_L(t)$ and $y_H(t)$, from filters $H_L(f)$ and $H_H(f)$ is:\n$$ \\operatorname{Cov}(y_L, y_H) = \\int_{-\\infty}^{\\infty} H_L(f) H_H^*(f) S_x(f) \\, df $$\nGiven that the input is white noise ($S_x(f) = \\sigma^2$) and the filters are real and zero-phase ($H(f) = H^*(f) = |H(f)|$), and that the filter responses are even functions of frequency, we can integrate over positive frequencies and multiply by 2.\n$$ \\operatorname{Var}(y) = 2\\sigma^2 \\int_{0}^{\\infty} |H(f)|^2 \\, df $$\n$$ \\operatorname{Cov}(y_L, y_H) = 2\\sigma^2 \\int_{0}^{\\infty} |H_L(f)| |H_H(f)| \\, df $$\n\n**Calculating the Variances:**\nThe variance of $y_L(t)$ is determined by the integral of its squared magnitude response over positive frequencies. The response is non-zero in the passband $[f_{L-}, f_{L+}]$, the lower transition band $[f_{L-}-\\Delta, f_{L-}]$, and the upper transition band $[f_{L+}, f_{L+}+\\Delta]$.\n1.  **Passband:** The integral of $|H_L(f)|^2 = 1^2$ over a width of $B_L$ is $B_L$.\n2.  **Transition Bands:** Each linear transition band (from gain 1 to 0 over width $\\Delta$) contributes to the integral. The integral of the squared response over one such band is $\\int_0^\\Delta (1 - x/\\Delta)^2 dx = \\Delta/3$.\nThe integral over positive frequencies covers the passband and two transition bands:\n$$ \\int_0^{\\infty} |H_L(f)|^2 df = B_L + \\frac{\\Delta}{3} + \\frac{\\Delta}{3} = B_L + \\frac{2\\Delta}{3} $$\nThe total variance is:\n$$ \\operatorname{Var}(y_L) = 2\\sigma^2 \\left(B_L + \\frac{2\\Delta}{3}\\right) $$\nBy analogy, for the high-frequency filter:\n$$ \\operatorname{Var}(y_H) = 2\\sigma^2 \\left(B_H + \\frac{2\\Delta}{3}\\right) $$\n\n**Calculating the Cross-Covariance:**\nThe cross-covariance depends on the product of the filter responses. The problem states that the only overlap for $f>0$ is in the interval $[f_{L+}, f_{H-}]$ of length $\\ell$.\nIn this interval, $|H_L(f)| = 1 - (f - f_{L+})/\\Delta$ and $|H_H(f)| = 1 - (f_{H-} - f)/\\Delta$.\nThe integral for the cross-covariance (for $f>0$) is:\n$$ \\int_0^\\infty |H_L(f)||H_H(f)| df = \\int_{f_{L+}}^{f_{H-}} \\left(1 - \\frac{f - f_{L+}}{\\Delta}\\right) \\left(1 - \\frac{f_{H-} - f}{\\Delta}\\right) df $$\nLet's make a substitution $u = f - f_{L+}$. The integral becomes:\n$$ \\int_0^\\ell \\left(1 - \\frac{u}{\\Delta}\\right) \\left(1 - \\frac{\\ell-u}{\\Delta}\\right) du = \\int_0^\\ell \\left(1 - \\frac{\\ell}{\\Delta} + \\frac{\\ell u - u^2}{\\Delta^2}\\right) du $$\n$$ = \\left[ u - \\frac{\\ell u}{\\Delta} + \\frac{\\ell u^2}{2\\Delta^2} - \\frac{u^3}{3\\Delta^2} \\right]_0^\\ell = \\ell - \\frac{\\ell^2}{\\Delta} + \\frac{\\ell^3}{2\\Delta^2} - \\frac{\\ell^3}{3\\Delta^2} = \\ell - \\frac{\\ell^2}{\\Delta} + \\frac{\\ell^3}{6\\Delta^2} $$\nThe total cross-covariance is:\n$$ \\operatorname{Cov}(y_L, y_H) = 2\\sigma^2 \\left(\\ell - \\frac{\\ell^2}{\\Delta} + \\frac{\\ell^3}{6\\Delta^2}\\right) $$\n\n**Deriving the Correlation Coefficient $\\rho$:**\nThe Pearson correlation coefficient is $\\rho = \\frac{\\operatorname{Cov}(y_L, y_H)}{\\sqrt{\\operatorname{Var}(y_L)\\operatorname{Var}(y_H)}}$.\n$$ \\rho = \\frac{2\\sigma^2 \\left(\\ell - \\frac{\\ell^2}{\\Delta} + \\frac{\\ell^3}{6\\Delta^2}\\right)}{\\sqrt{2\\sigma^2(B_L + \\frac{2\\Delta}{3}) \\cdot 2\\sigma^2(B_H + \\frac{2\\Delta}{3})}} = \\frac{\\ell - \\frac{\\ell^2}{\\Delta} + \\frac{\\ell^3}{6\\Delta^2}}{\\sqrt{\\left(B_L + \\frac{2\\Delta}{3}\\right)\\left(B_H + \\frac{2\\Delta}{3}\\right)}} $$\nThis expression shows that even for a white noise input with no inherent cross-frequency structure, a non-zero correlation ($\\rho > 0$) will arise if the filter transition bands overlap ($\\ell > 0$). This is a direct result of spectral leakage, where both filters pass common frequency components, creating spurious covariance.\n\n**Final Evaluation:**\nFor $B_L=6$, $B_H=10$, $\\Delta=8$, and $\\ell=4$:\nNumerator: $4 - \\frac{4^2}{8} + \\frac{4^3}{6(8^2)} = 4 - 2 + \\frac{64}{384} = 2 + \\frac{1}{6} = \\frac{13}{6}$.\nDenominator:\n$$ \\sqrt{\\left(6 + \\frac{2(8)}{3}\\right)\\left(10 + \\frac{2(8)}{3}\\right)} = \\sqrt{\\left(\\frac{18+16}{3}\\right)\\left(\\frac{30+16}{3}\\right)} = \\sqrt{\\frac{34}{3} \\cdot \\frac{46}{3}} = \\frac{\\sqrt{1564}}{3} $$\n$1564 = 4 \\times 391$, so $\\sqrt{1564} = 2\\sqrt{391}$.\nThe denominator is $\\frac{2\\sqrt{391}}{3}$.\n$$ \\rho = \\frac{13/6}{2\\sqrt{391}/3} = \\frac{13}{6} \\cdot \\frac{3}{2\\sqrt{391}} = \\frac{13}{4\\sqrt{391}} $$",
            "answer": "$$\\boxed{\\frac{13}{4\\sqrt{391}}}$$"
        },
        {
            "introduction": "Observing a non-zero coupling value is not enough; we must determine if this result is statistically significant or merely a product of chance. This exercise  delves into the heart of hypothesis testing for PAC by deriving the theoretical null distribution for a common coupling estimator. This practice provides the formal basis for using surrogate data methods, such as time-shifting, to assess the statistical significance of observed coupling.",
            "id": "4151462",
            "problem": "Consider a single-channel neural time series that has been bandpass filtered into a low-frequency component and a high-frequency component. Let the analytic phase of the low-frequency component be denoted by $\\phi_{L}(t)$ and the analytic amplitude envelope of the high-frequency component be denoted by $A_{H}(t)$, both sampled at $t = 1, 2, \\dots, N$. Phase–Amplitude Coupling (PAC) refers to statistical dependence between $A_{H}(t)$ and $\\phi_{L}(t)$. A common class of PAC estimators forms a complex mean vector whose magnitude quantifies coupling.\n\nConstruct a time-shift surrogate by drawing an integer $s$ uniformly from $\\{0, 1, \\dots, N-1\\}$ and circularly shifting $A_{H}(t)$ relative to $\\phi_{L}(t)$ to obtain $\\tilde{A}_{H}(t) = A_{H}((t + s) \\bmod N)$. Define the coupling estimator as the magnitude of the complex mean vector\n$$\nR_{N} = \\left|\\frac{1}{N} \\sum_{t=1}^{N} \\tilde{A}_{H}(t) \\exp\\!\\left(i \\,\\phi_{L}(t)\\right)\\right|.\n$$\nAssume the following stationarity conditions hold over the analysis window: both $\\{A_{H}(t)\\}$ and $\\{\\phi_{L}(t)\\}$ are wide-sense stationary and ergodic; under the null hypothesis of no coupling, $A_{H}(t)$ and $\\phi_{L}(t)$ are statistically independent; and the marginal distribution of $\\phi_{L}(t)$ is uniform on $[0, 2\\pi)$. Let $m_{2} = \\mathbb{E}[A_{H}(t)^{2}]$ denote the second moment of the high-frequency amplitude envelope, which is preserved by the circular shift.\n\nUsing these assumptions and first principles from random process theory, derive the expected null probability density function of $R_{N}$ induced by the time-shift surrogate. Express your final answer as a single closed-form analytic expression for the density $f_{R_{N}}(r)$ in terms of $r$, $N$, and $m_{2}$. Do not provide an inequality or an equation as your final answer; provide only the density function expression. No numerical approximation is required.",
            "solution": "The problem asks for the probability density function (PDF) of a Phase-Amplitude Coupling (PAC) estimator, $R_N$, under the null hypothesis of no coupling. The estimator is the magnitude of a complex mean vector formed from the high-frequency amplitude $\\tilde{A}_H(t)$ and the low-frequency phase $\\phi_L(t)$.\n\nLet the complex random variable whose magnitude is the estimator be $Z_N$:\n$$ Z_N = \\frac{1}{N} \\sum_{t=1}^{N} \\tilde{A}_{H}(t) \\exp(i \\phi_{L}(t)) $$\nWe can decompose $Z_N$ into its real and imaginary parts, $Z_N = X_N + i Y_N$. The problem asks for the PDF of $R_N = |Z_N| = \\sqrt{X_N^2 + Y_N^2}$.\n\nFor a large number of samples $N$, the Central Limit Theorem (CLT) states that the distribution of the sum (and thus the mean) of random variables will approach a Gaussian distribution. We apply this to $X_N$ and $Y_N$. To define this Gaussian distribution, we need to find their means, variances, and covariance under the null hypothesis.\n\n**1. Calculate the Mean:**\nUnder the null hypothesis, the amplitude process $\\{\\tilde{A}_H(t)\\}$ is statistically independent of the phase process $\\{\\phi_L(t)\\}$. The phase $\\phi_L(t)$ is uniformly distributed on $[0, 2\\pi)$. The expectation of the complex exponential of the phase is:\n$$ \\mathbb{E}[\\exp(i \\phi_L(t))] = \\int_0^{2\\pi} e^{i\\phi} \\frac{1}{2\\pi} d\\phi = 0 $$\nTherefore, the expectation of $Z_N$ is:\n$$ \\mathbb{E}[Z_N] = \\frac{1}{N} \\sum_{t=1}^{N} \\mathbb{E}[\\tilde{A}_{H}(t)] \\mathbb{E}[\\exp(i \\phi_L(t))] = 0 $$\nThis implies that $\\mathbb{E}[X_N] = 0$ and $\\mathbb{E}[Y_N] = 0$.\n\n**2. Calculate the Variances:**\nSince the mean is zero, the variance of $X_N$ is $\\operatorname{Var}(X_N) = \\mathbb{E}[X_N^2]$.\n$$ \\operatorname{Var}(X_N) = \\mathbb{E}\\left[\\left(\\frac{1}{N} \\sum_{t=1}^{N} \\tilde{A}_{H}(t) \\cos(\\phi_{L}(t))\\right)^2\\right] $$\nExpanding the square and using the independence of amplitude and phase:\n$$ \\operatorname{Var}(X_N) = \\frac{1}{N^2} \\sum_{t=1}^{N} \\sum_{t'=1}^{N} \\mathbb{E}[\\tilde{A}_{H}(t)\\tilde{A}_{H}(t')] \\mathbb{E}[\\cos(\\phi_{L}(t))\\cos(\\phi_{L}(t'))] $$\nAssuming the phase samples $\\phi_L(t)$ are uncorrelated, the expectation of the cosine product is non-zero only for $t=t'$.\nFor $t \\neq t'$, $\\mathbb{E}[\\cos(\\phi_{L}(t))\\cos(\\phi_{L}(t'))] = \\mathbb{E}[\\cos(\\phi_{L}(t))] \\mathbb{E}[\\cos(\\phi_{L}(t'))] = 0$.\nFor $t=t'$, $\\mathbb{E}[\\cos^2(\\phi_{L}(t))] = \\int_0^{2\\pi} \\cos^2(\\phi) \\frac{1}{2\\pi} d\\phi = 1/2$.\nThe double sum collapses, and using the stationarity of the amplitude process ($\\mathbb{E}[\\tilde{A}_H(t)^2] = m_2$):\n$$ \\operatorname{Var}(X_N) = \\frac{1}{N^2} \\sum_{t=1}^{N} \\mathbb{E}[\\tilde{A}_{H}(t)^2] \\cdot \\frac{1}{2} = \\frac{1}{N^2} \\sum_{t=1}^{N} \\frac{m_2}{2} = \\frac{N m_2}{2N^2} = \\frac{m_2}{2N} $$\nA similar calculation for $Y_N$, using $\\mathbb{E}[\\sin^2(\\phi_L)] = 1/2$, yields the same variance: $\\operatorname{Var}(Y_N) = \\frac{m_2}{2N}$.\n\n**3. Calculate the Covariance:**\nThe covariance is $\\operatorname{Cov}(X_N, Y_N) = \\mathbb{E}[X_N Y_N]$.\n$$ \\operatorname{Cov}(X_N, Y_N) = \\frac{1}{N^2} \\sum_{t=1}^{N} \\sum_{t'=1}^{N} \\mathbb{E}[\\tilde{A}_{H}(t)\\tilde{A}_{H}(t')] \\mathbb{E}[\\cos(\\phi_{L}(t))\\sin(\\phi_{L}(t'))] $$\nThe expectation of the phase product is always zero. For $t \\neq t'$, it is zero due to independence. For $t=t'$, $\\mathbb{E}[\\cos(\\phi_L)\\sin(\\phi_L)] = \\mathbb{E}[\\frac{1}{2}\\sin(2\\phi_L)] = 0$. Thus, $\\operatorname{Cov}(X_N, Y_N) = 0$.\n\n**4. Determine the PDF of $R_N$:**\nWe have shown that for large $N$, $X_N$ and $Y_N$ are approximately independent, identically distributed (i.i.d.) Gaussian random variables with mean 0 and variance $\\sigma^2 = m_2 / (2N)$.\nThe magnitude $R_N = \\sqrt{X_N^2 + Y_N^2}$ of a 2D vector whose components are i.i.d. zero-mean Gaussians with variance $\\sigma^2$ follows a Rayleigh distribution.\nThe PDF for a Rayleigh distribution is given by $f(r; \\sigma^2) = \\frac{r}{\\sigma^2} \\exp\\left(-\\frac{r^2}{2\\sigma^2}\\right)$ for $r \\geq 0$.\nSubstituting our variance $\\sigma^2 = m_2 / (2N)$:\n$$ f_{R_N}(r) = \\frac{r}{m_2 / (2N)} \\exp\\left(-\\frac{r^2}{2(m_2 / (2N))}\\right) $$\nSimplifying this expression gives the final PDF for the PAC estimator under the null hypothesis:\n$$ f_{R_N}(r) = \\frac{2Nr}{m_2} \\exp\\left(-\\frac{Nr^2}{m_2}\\right) $$",
            "answer": "$$\n\\boxed{\\frac{2Nr}{m_{2}} \\exp\\left(-\\frac{Nr^{2}}{m_{2}}\\right)}\n$$"
        }
    ]
}