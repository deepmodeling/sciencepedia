{
    "hands_on_practices": [
        {
            "introduction": "在进行任何基于网络的统计分析之前，首要任务是精确地构建我们的统计模型。本练习将指导您如何在通用线性模型（GLM）的框架下，将一个科学假设（例如，在控制年龄和性别等混杂变量的情况下比较两组）转化为精确的数学形式。正确构建设计矩阵和对比向量是确保我们准确检验预期假设的分析基石 。",
            "id": "4181134",
            "problem": "您正在分析一个功能连接组，其中包含 $n$ 名被试，这些被试被分为三个互斥的组：A组、B组和C组。对于每位被试 $i \\in \\{1,\\dots,n\\}$ 和连接组中的每条边 $e$，您观察到一个边权重 $y_{i}^{(e)}$。您计划使用基于网络的统计（NBS）方法，以逐边通用线性模型（GLM）为基础模型，在每条边上构建检验统计量，从而在连接边组件的层面上检验组间差异。\n\n从标准的通用线性模型基础出发，对于每条边 $e$，响应向量 $y^{(e)} \\in \\mathbb{R}^{n}$ 满足以下模型：\n$$\ny^{(e)} \\;=\\; X \\beta^{(e)} + \\varepsilon^{(e)},\n$$\n其中 $X \\in \\mathbb{R}^{n \\times p}$ 是设计矩阵，$\\beta^{(e)} \\in \\mathbb{R}^{p}$ 是特定于边的参数向量，$\\varepsilon^{(e)} \\in \\mathbb{R}^{n}$ 是均值为零且方差有限的误差项。您将纳入被试水平的年龄和性别协变量以控制混淆因素。\n\n构建一个科学有效、满秩的设计矩阵 $X$，用于三组比较，该矩阵包括：\n- 一个截距项，\n- 使用二元指示变量对A组和B组成员身份进行编码，以C组为参照类别，\n- 一个均值中心化的年龄协变量，\n- 一个性别协变量，编码为女性为 $0$，男性为 $1$。\n\n确保您的构建避免了完全多重共线性，并且适用于NBS背景下的逐边GLM估计。然后，基于此矩阵 $X$，指定一个单一的对比向量，用于在每条边上检验“在控制年龄和性别的情况下，A组的平均边权重等于B组的平均边权重”这一零假设。\n\n您最终报告的答案必须是表示为单一闭式解析表达式的对比向量。如果您在构建中引入任何数值常数，它们必须以符号形式定义，而不是以数值实例化。无需四舍五入。请提供对比向量作为您的最终答案。",
            "solution": "该问题是有效的。它在科学上基于通用线性模型（GLM）应用于神经科学中统计假设检验的既定原则。该问题提法恰当、客观，并包含了构建所需设计矩阵和对比向量的所有必要信息，没有歧义或矛盾。\n\n目标是在GLM框架内构建一个对比向量，以检验一个特定的假设。对于给定边 $e$，观测到的边权重 $y^{(e)} \\in \\mathbb{R}^n$ 的模型是：\n$$\ny^{(e)} = X \\beta^{(e)} + \\varepsilon^{(e)}\n$$\n其中 $X \\in \\mathbb{R}^{n \\times p}$ 是设计矩阵，$\\beta^{(e)} \\in \\mathbb{R}^p$ 是参数向量，$\\varepsilon^{(e)}$ 是误差项。\n\n首先，我们根据指定的要求构建设计矩阵 $X$。问题陈述了有三个组（A、B、C），我们需要包含一个截距项、以C组为参照的A组和B组的指示变量、一个均值中心化的年龄协变量以及一个性别协变量。这定义了一个包含 $p=5$ 个参数的模型。让我们来定义设计矩阵 $X$ 的列。对于每位被试 $i \\in \\{1, \\dots, n\\}$，$X$ 的第 $i$ 行（表示为 $x_i^T$）构建如下：\n\n令 $G_{iA}$ 为一个指示变量，如果被试 $i$ 属于A组，则 $G_{iA} = 1$，否则 $G_{iA} = 0$。\n令 $G_{iB}$ 为一个指示变量，如果被试 $i$ 属于B组，则 $G_{iB} = 1$，否则 $G_{iB} = 0$。\n如果被试 $i$ 属于C组，则 $G_{iA} = 0$ 且 $G_{iB} = 0$，这样C组就成为所要求的参照类别。\n\n令 $Age_i$ 为被试 $i$ 的年龄。问题指定了一个均值中心化的年龄协变量。令 $\\bar{A} = \\frac{1}{n} \\sum_{j=1}^n Age_j$ 为所有被试的平均年龄。被试 $i$ 的均值中心化年龄为 $A_i = Age_i - \\bar{A}$。\n\n令 $S_i$ 为被试 $i$ 的性别协变量，编码为女性 $S_i = 0$，男性 $S_i = 1$。\n\n设计矩阵 $X$ 是一个 $n \\times 5$ 的矩阵。$X$ 的第 $i$ 行由向量 $x_i^T$ 给出：\n$$\nx_i^T = \\begin{pmatrix} 1 & G_{iA} & G_{iB} & A_i & S_i \\end{pmatrix}\n$$\n对应的边 $e$ 的参数向量 $\\beta^{(e)}$ 是 $\\mathbb{R}^5$ 中的一个列向量：\n$$\n\\beta^{(e)} = \\begin{pmatrix} \\beta_0^{(e)} \\\\ \\beta_1^{(e)} \\\\ \\beta_2^{(e)} \\\\ \\beta_3^{(e)} \\\\ \\beta_4^{(e)} \\end{pmatrix}\n$$\n被试 $i$ 在边 $e$ 上的期望边权重 $E[y_i^{(e)}]$ 由以下模型给出：\n$$\nE[y_i^{(e)}] = \\beta_0^{(e)} \\cdot 1 + \\beta_1^{(e)} G_{iA} + \\beta_2^{(e)} G_{iB} + \\beta_3^{(e)} A_i + \\beta_4^{(e)} S_i\n$$\n参数的解释（为清晰起见，省略上标 $(e)$）如下：\n- $\\beta_0$：参照组（C组）中，年龄为平均年龄（$A_i=0$）、性别为参照性别（女性，$S_i=0$）的被试的平均边权重。\n- $\\beta_1$：在控制年龄和性别后，A组与C组之间的平均边权重差异。\n- $\\beta_2$：在控制年龄和性别后，B组与C组之间的平均边权重差异。\n- $\\beta_3$：年龄对边权重的影响（斜率）。\n- $\\beta_4$：在控制组别和年龄后，男性与女性之间的平均边权重差异。\n\n接下来，我们构建零假设：在控制年龄和性别的情况下，A组的平均边权重等于B组的平均边权重。为了用模型参数来表示这一点，我们写出每组的调整后均值。一个组的调整后均值是指该组中被试在协变量设置为某个共同参考值（例如，平均年龄 $A_i=0$ 和特定性别 $s$）时的期望边权重。\n\nA组的调整后均值 $\\mu_A$ 为：\n$$\n\\mu_A = E[y^{(e)} | \\text{Group A, avg age, sex } s] = \\beta_0 + \\beta_1(1) + \\beta_2(0) + \\beta_3(0) + \\beta_4 s = \\beta_0 + \\beta_1 + \\beta_4 s\n$$\nB组的调整后均值 $\\mu_B$ 为：\n$$\n\\mu_B = E[y^{(e)} | \\text{Group B, avg age, sex } s] = \\beta_0 + \\beta_1(0) + \\beta_2(1) + \\beta_3(0) + \\beta_4 s = \\beta_0 + \\beta_2 + \\beta_4 s\n$$\n零假设 $H_0: \\mu_A = \\mu_B$ 现在可以用参数表示为：\n$$\nH_0: \\beta_0 + \\beta_1 + \\beta_4 s = \\beta_0 + \\beta_2 + \\beta_4 s\n$$\n这可以简化为：\n$$\nH_0: \\beta_1 = \\beta_2\n$$\n或等价地，\n$$\nH_0: \\beta_1 - \\beta_2 = 0\n$$\n一个线性假设表示为 $c^T \\beta^{(e)} = 0$ 的形式，其中 $c$ 是对比向量。将我们的假设与此形式进行比较：\n$$\nc^T \\beta^{(e)} = c_0 \\beta_0 + c_1 \\beta_1 + c_2 \\beta_2 + c_3 \\beta_3 + c_4 \\beta_4 = 0\n$$\n我们要求这等价于 $1 \\cdot \\beta_1 + (-1) \\cdot \\beta_2 = 0$。通过匹配每个 $\\beta_j$ 的系数，我们找到对比向量 $c$ 的分量：\n$c_0 = 0$\n$c_1 = 1$\n$c_2 = -1$\n$c_3 = 0$\n$c_4 = 0$\n\n因此，写成行向量的对比向量是 $[0, 1, -1, 0, 0]$。该向量指定了参数估计值的线性组合，在零假设下，该组合的和将被检验是否为零。对比向量中元素的顺序必须与 $\\beta^{(e)}$ 中参数的顺序相匹配，而后者由设计矩阵 $X$ 的列顺序决定：截距项、A组指示变量、B组指示变量、均值中心化年龄和性别。",
            "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n0 & 1 & -1 & 0 & 0\n\\end{pmatrix}\n}\n$$"
        },
        {
            "introduction": "在基于网络的统计（NBS）方法中，我们首先对所有边的逐边检验统计量设置一个初始阈值，然后识别出由超阈值边构成的连通子网络。这个过程的核心计算挑战是如何高效地识别这些“网络”或连通分量。本练习聚焦于NBS流程中这一关键的算法步骤，并探讨了并查集（union-find）数据结构在解决此问题时的高效性 。",
            "id": "4181097",
            "problem": "您正在使用基于网络的统计（NBS）分析功能连接组数据，该方法通过对边级检验统计量设置一个主阈值，在由此产生的图中识别超阈值边的连接组件。假设有 $V$ 个感兴趣区域（ROI），以及一个无向、无自环的图 $G=(\\mathcal{V}, \\mathcal{E}_{\\tau})$，其中 $\\lvert \\mathcal{V} \\rvert = V$ 且 $\\mathcal{E}_{\\tau} = \\{ (i,j) : i \\neq j,\\, T_{ij} \\ge \\tau \\}$ 表示在阈值水平 $\\tau$ 下对检验统计量矩阵进行阈值处理后得到的超阈值边集。令 $E = \\lvert \\mathcal{E}_{\\tau} \\rvert$。在NBS的每次置换中，目标是提取图 $G$ 的所有连接组件，以便计算组件级统计量（例如，最大组件大小）。假设采用标准的随机存取机计算模型，并且 $\\mathcal{E}_{\\tau}$ 以无序顶点对列表的形式给出。\n\n请选择一个选项，该选项既概述了在NBS步骤中提取连接组件的正确且高效的不相交集并（union–find）方法，又陈述了关于 $E$ 和 $V$ 的正确的紧凑摊销时间复杂度界限。\n\nA. 为 $V$ 个顶点中的每一个初始化一个不相交集数据结构，每个顶点自成一个单例集。对于每个超阈值边 $(i,j) \\in \\mathcal{E}_{\\tau}$，使用按秩合并和路径压缩对包含 $i$ 和 $j$ 的集合执行合并操作。处理完所有边后，遍历所有顶点一次，应用 find 操作获取每个顶点的代表元，并按代表元将顶点分组以生成组件。所有操作的总摊销运行时间为 $O\\big((E+V)\\,\\alpha(V)\\big)$，其中 $\\alpha(\\cdot)$ 是反阿克曼函数，当 $E \\ge V$ 时，可简化为 $O\\big(E\\,\\alpha(V)\\big)$。\n\nB. 为超阈值图构建一个邻接表，并从每个未访问过的顶点开始运行深度优先搜索（DFS）来标记组件，其运行时间为 $O(E+V)$。这严格快于任何不相交集并方法，因此是NBS中的首选方法。\n\nC. 使用一个没有按秩合并和路径压缩的不相交集结构。对于每个超阈值边，对其端点执行合并操作。最后，遍历所有顶点并应用 find 操作来标记组件。摊销运行时间为 $O\\big(E \\log V\\big)$。\n\nD. 按检验统计量值对超阈值边进行排序，然后运行一个类似 Kruskal 算法的扫描，在扫描过程中合并端点；排序步骤导致总体复杂度为 $O\\big(E \\log E\\big)$，这在该场景下是提取连接组件的最优方法，并且在NBS中使用时对于保证正确性是必需的。",
            "solution": "问题要求选择一个选项，该选项能正确描述一种高效的不相交集并（DSU）或并查集（union–find）算法，用于查找图的连接组件，并为该任务提供正确的时间复杂度。其背景是神经科学中基于网络的统计（NBS）方法的一个特定步骤，在该步骤中，通过对检验统计量矩阵进行阈值处理来形成一个图 $G=(\\mathcal{V}, \\mathcal{E}_{\\tau})$。该图有 $V = \\lvert \\mathcal{V} \\rvert$ 个顶点和 $E = \\lvert \\mathcal{E}_{\\tau} \\rvert$ 条边，输入以这 $E$ 条边的列表形式给出。\n\n首先，让我们确定使用不相交集并数据结构查找连接组件的最有效方法。\n\nDSU数据结构维护一个不相交集的集合。三个主要操作是：\n1.  `MAKESET(x)`: 创建一个只包含元素 $x$ 的新集合。\n2.  `FIND(x)`: 返回包含 $x$ 的集合的代表（或根）。\n3.  `UNION(x, y)`: 合并包含 $x$ 和 $y$ 的两个集合。\n\n查找具有 $V$ 个顶点和 $E$ 条边的边列表的图的连接组件的算法如下：\n1.  初始化DSU数据结构，为 $V$ 个顶点中的每一个创建一个单例集。这需要调用 $V$ 次 `MAKESET`。\n2.  遍历 $E$ 条边。对于每条边 $(u, v)$：\n    a. 通过比较它们的代表来检查 $u$ 和 $v$ 是否已在同一个组件中：`FIND(u) == FIND(v)`。\n    b. 如果不在，则合并它们的集合：`UNION(u, v)`。\n3.  处理完所有 $E$ 条边后，属于同一个连接组件的所有顶点都将在DSU结构中的同一个集合内。为了明确地检索这些组件，可以遍历所有 $V$ 个顶点，并根据使用 `FIND` 操作找到的集合代表对它们进行分组。\n\n该算法的时间复杂度取决于 `UNION` 和 `FIND` 操作的实现。最有效的实现使用了两种启发式方法：\n- **按大小或按秩合并：** 当合并两个集合时，将代表较小集合的树的根附加到代表较大集合的树的根上。这可以防止树变得不必要地深。\n- **路径压缩：** 在 `FIND(x)` 操作期间，从 $x$ 到根路径上的每个节点都成为根的直接子节点。这会随着时间的推移使树结构变得扁平。\n\n当同时使用按秩/大小合并和路径压缩时，对 $n$ 个元素执行 $m$ 次操作序列的摊销时间复杂度为 $O(m \\, \\alpha(n))$，其中 $\\alpha(n)$ 是反阿克曼函数。函数 $\\alpha(n)$ 增长极其缓慢；对于任何实际的 $n$ 值，$\\alpha(n) \\le 5$。\n\n在我们特定的问题中：\n- 元素数量为 $n = V$。\n- 我们为初始化执行 $V$ 次 `MAKESET` 操作。\n- 我们处理 $E$ 条边，这涉及 $E$ 对 `FIND` 操作和最多 $E-1$ 次 `UNION` 操作。这大约相当于 $3E$ 次操作。\n- 最后，为了明确列出组件，我们执行 $V$ 次 `FIND` 操作。\n- 因此，总操作数 $m$ 的数量级为 $V + 3E + V$，即 $O(E+V)$。\n\n将这些代入通用复杂度公式，总摊销时间为 $O\\big((E+V)\\,\\alpha(V)\\big)$。在许多连接组学应用中，图并不是极其稀疏的，因此通常有 $E \\ge V$。在这种情况下，$E$ 项占主导地位，复杂度可以简化为 $O\\big(E\\,\\alpha(V)\\big)$。\n\n现在我们评估每个选项。\n\n**A. 为 $V$ 个顶点中的每一个初始化一个不相交集数据结构，每个顶点自成一个单例集。对于每个超阈值边 $(i,j) \\in \\mathcal{E}_{\\tau}$，使用按秩合并和路径压缩对包含 $i$ 和 $j$ 的集合执行合并操作。处理完所有边后，遍历所有顶点一次，应用 find 操作获取每个顶点的代表元，并按代表元将顶点分组以生成组件。所有操作的总摊销运行时间为 $O\\big((E+V)\\,\\alpha(V)\\big)$，其中 $\\alpha(\\cdot)$ 是反阿克曼函数，当 $E \\ge V$ 时，可简化为 $O\\big(E\\,\\alpha(V)\\big)$。**\n\n该选项精确地描述了最优的不相交集并算法。\n- 程序描述是正确的：初始化 $V$ 个集合，使用 `UNION`（依赖于 `FIND`）处理 $E$ 条边，然后通过遍历顶点并使用 `FIND` 来最终确定组件结构。\n- 它正确地指出了使用“按秩合并和路径压缩”是关键的优化。\n- 所陈述的摊销时间复杂度 $O\\big((E+V)\\,\\alpha(V)\\big)$ 是此过程的正确紧凑界限。\n- 在 $E \\ge V$ 的合理条件下，简化为 $O\\big(E\\,\\alpha(V)\\big)$ 也是正确的。\n**结论：正确。**\n\n**B. 为超阈值图构建一个邻接表，并从每个未访问过的顶点开始运行深度优先搜索（DFS）来标记组件，其运行时间为 $O(E+V)$。这严格快于任何不相交集并方法，因此是NBS中的首选方法。**\n\n该选项描述了一种替代算法（DFS/BFS）来查找连接组件。对DFS算法及其时间复杂度 $O(E+V)$ 的描述是正确的。然而，问题陈述明确要求选择一个概述**不相交集并（union-find）方法**的选项。此选项描述了一种完全不同的方法。此外，声称DFS“严格更快”在渐近意义上是技术性正确的，因为对于 $V>2$，$\\alpha(V) > 1$，但出于实际目的，性能是可比的，而声称它“因此是首选方法”是一种主观判断，而非正式的事实陈述。因为它没有描述并查集方法，所以它没有回答问题。\n**结论：不正确。**\n\n**C. 使用一个没有按秩合并和路径压缩的不相交集结构。对于每个超阈值边，对其端点执行合并操作。最后，遍历所有顶点并应用 find 操作来标记组件。摊销运行时间为 $O\\big(E \\log V\\big)$。**\n\n该选项描述了DSU算法的一种朴素实现，明确指出“没有按秩合并和路径压缩”。在这种情况下，数据结构可能退化为链表，其中 `FIND` 操作在最坏情况下可能需要 $O(V)$ 时间。因此，一系列 $E$ 个边处理步骤最多可能需要 $O(EV)$ 时间。对于这种朴素实现，所陈述的 $O(E \\log V)$ 复杂度是不正确的；它对应于使用按秩合并*或*路径压缩，但不是两者都用，也不是两者都不用的实现。\n**结论：不正确。**\n\n**D. 按检验统计量值对超阈值边进行排序，然后运行一个类似 Kruskal 算法的扫描，在扫描过程中合并端点；排序步骤导致总体复杂度为 $O\\big(E \\log E\\big)$，这在该场景下是提取连接组件的最优方法，并且在NBS中使用时对于保证正确性是必需的。**\n\n该选项引入了一个不必要且计算成本高昂的步骤：对边进行排序。问题是在由*单一固定阈值* $\\tau$ 定义的图 $G$ 上找到连接组件。对于此任务，$\\mathcal{E}_{\\tau}$ 中的所有边都是等效的；它们原始的检验统计量值与图的拓扑结构无关。排序步骤需要 $O(E \\log E)$ 时间，是不必要的。声称这是“最优的”是错误的，因为选项A中的DSU方法（$O((E+V)\\alpha(V))$）和选项B中的DFS方法（$O(E+V)$）都比 $O(E \\log E)$ 快。声称其“对于保证正确性是必需的”也是错误的。这个过程模仿了用于寻找最小生成树的 Kruskal 算法，但这并不是要解决的问题。\n**结论：不正确。**\n\n根据分析，只有选项A为指定问题提供了对高效DSU算法及其相应紧凑时间复杂度的正确描述。",
            "answer": "$$\\boxed{A}$$"
        },
        {
            "introduction": "这项综合性练习是检验您对NBS方法全面理解的终极挑战，它将引导您完成一个完整的端到端分析流程。您将从零开始，首先模拟包含已知“植入”效应的连接组数据，然后构建一个完整的NBS分析管道来检测这一效应。这个过程涵盖了从生成时间序列、计算边连接、执行假设检验到通过置换检验获得最终$p$值的每一个步骤 。",
            "id": "4181079",
            "problem": "您需要为合成连接组数据上的基于网络的统计 (NBS) 实现一个完整的模拟和假设检验流程。该模拟必须构建一个植入的子网络效应，并生成时间序列，使其边相关性接近预设的目标值。该流程必须通过置换检验产生组件水平的显著性估计，并在一个测试套件中汇总结果。\n\n请使用以下定义作为基本基础：\n- 对于长度为 $T$ 的两个节点时间序列 $x$ 和 $y$，其皮尔逊相关系数为 $r = \\frac{\\sum_{t=1}^{T} (x_t - \\bar{x})(y_t - \\bar{y})}{\\sqrt{\\sum_{t=1}^{T} (x_t - \\bar{x})^2} \\sqrt{\\sum_{t=1}^{T} (y_t - \\bar{y})^2}}$。\n- Fisher $z$ 变换为 $z = \\operatorname{atanh}(r)$，在独立同分布的高斯抽样下，对于足够大的 $T$，其抽样分布近似为正态分布，方差为 $1/(T-3)$。\n- 用于组间边水平差异的 Welch 双样本 $t$ 统计量为 $t = \\frac{\\bar{z}_A - \\bar{z}_B}{\\sqrt{s_A^2 / n_A + s_B^2 / n_B}}$，其中 $\\bar{z}_A$ 和 $\\bar{z}_B$ 是 A 组和 B 组经过 Fisher $z$ 变换的边相关性的样本均值，$s_A^2$ 和 $s_B^2$ 是相应的样本方差，$n_A$ 和 $n_B$ 是被试数量。\n- 基于网络的统计 (NBS) 通过在一个主阈值上对边级别的统计量进行阈值处理来构建一个包含 $p$ 个节点的图，然后识别连通组件；对于每个组件，其“质量”是其所有边上超阈值统计量的总和。对组标签进行置换检验可以得出最大组件质量的零分布，从中可以获得组件水平的 $p$ 值，计算公式为 $\\frac{1 + \\#\\{\\text{permutations with max mass} \\ge \\text{observed max mass}\\}}{1 + P}$，其中 $P$ 是置换次数。\n\n您的程序必须为每个测试用例执行以下步骤：\n1. 为 $p$ 个节点构建两个目标相关矩阵，每组一个。B 组（对照组）的所有边的非对角线相关性具有统一的基线值 $\\rho$。A 组（效应组）具有相同的基线 $\\rho$，但在一个大小为 $s$ 的植入子网络 $S \\subset \\{1,\\dots,p\\}$ 内，非对角线相关性增加 $\\delta$ 到 $\\rho + \\delta$。确保构建的矩阵是有效的相关矩阵（对称正定且对角线为 1）。\n2. 通过强制执行 Fisher $z$ 标准差界限来选择时间序列长度 $T$，以达到边相关性的目标精度。具体来说，对于给定的容差 $\\epsilon$，选择满足 $1/\\sqrt{T-3} \\le \\epsilon$ 的 $T$。使用 $T = \\lceil 3 + 1/\\epsilon^2 \\rceil$。\n3. 为每个组中的每个被试模拟 $p$ 维的 $T$ 个独立高斯时间点，其均值为零，协方差等于该组的目标相关矩阵。使用一种能确保每个时间点的跨节点协方差等于目标相关矩阵的方法（例如，Cholesky 分解）。\n4. 对每个被试，计算其 $p \\times p$ 的样本皮尔逊相关矩阵（跨时间）。提取上三角的边相关性，并应用 Fisher $z$ 变换，以获得每个被试的边级别值。\n5. 对 Fisher $z$ 值比较 A 组与 B 组，为每条边计算 Welch 双样本 $t$ 统计量。应用一个单侧主阈值 $\\tau$，保留 $t > \\tau$ 的边。在由超阈值边所引出的 $p$ 节点图上识别连通组件，并计算每个组件的质量，即其超阈值边上 $t$ 值的总和。记录观测到的最大组件质量 $M_{\\text{obs}}$。如果没有超阈值的边，则设置 $M_{\\text{obs}} = 0$。\n6. 执行 $P$ 次组标签置换。对于每次置换，重新计算边级别的 $t$ 统计量、进行阈值处理、计算最大组件质量 $M_{\\text{perm}}$，并形成 $M_{\\text{perm}}$ 的经验零分布。计算 NBS 组件水平的 $p$ 值 $p_{\\text{NBS}} = \\frac{1 + \\#\\{M_{\\text{perm}} \\ge M_{\\text{obs}}\\}}{1 + P}$。如果 $M_{\\text{obs}} = 0$，则定义 $p_{\\text{NBS}} = 1$。\n\n请使用固定的随机种子实现上述过程，以使输出是确定性的。\n\n测试套件：\n请提供恰好三个测试用例，参数如下，覆盖一般情况、较低效应情况和边界阈值情况：\n- 用例 1：$p = 12$，$s = 5$，子网络索引 $S = \\{0,1,2,3,4\\}$，基线 $\\rho = 0.2$，增量 $\\delta = 0.25$，组大小 $n_A = 22, n_B = 22$，容差 $\\epsilon = 0.07$，主阈值 $\\tau = 3.0$，置换次数 $P = 200$。\n- 用例 2：$p = 10$，$s = 3$，子网络索引 $S = \\{0,1,2\\}$，基线 $\\rho = 0.1$，增量 $\\delta = 0.1$，组大小 $n_A = 20, n_B = 20$，容差 $\\epsilon = 0.08$，主阈值 $\\tau = 3.5$，置换次数 $P = 200$。\n- 用例 3：$p = 12$，$s = 5$，子网络索引 $S = \\{0,1,2,3,4\\}$，基线 $\\rho = 0.2$，增量 $\\delta = 0.25$，组大小 $n_A = 22, n_B = 22$，容差 $\\epsilon = 0.07$，主阈值 $\\tau = 9.0$，置换次数 $P = 200$。\n\n最终输出格式：\n您的程序应生成单行输出，其中包含一个逗号分隔的列表形式的结果，并用方括号括起来（例如 $[result1,result2,result3]$）。每个 $result$ 必须是对应测试用例的 NBS 组件水平 $p$ 值，表示为浮点数。不应打印任何其他文本。",
            "solution": "用户要求实现一个用于连接组假设检验的基于网络的统计 (NBS) 流程。这涉及到为两个组模拟合成的大脑连接数据，其中一个组带有“植入”的子网络效应，然后应用 NBS 程序来检测此效应并计算其统计显著性。该过程必须针对一组特定的测试用例进行实现，并且结果必须是确定性的。\n\n在提供解决方案之前，对问题陈述进行了验证。发现该问题在科学上是合理的、定义明确的、客观且完整的。它描述了计算神经科学中一种标准的、广泛使用的方法（Zalesky et al., 2010），并提供了所有必要的数学定义、算法步骤和参数。测试套件中参数的选择是合理的，并探究了该方法性能的不同方面。因此，该问题被认为是有效的，并且有必要提供完整的解决方案。\n\n该解决方案通过实现问题陈述中指定的六个步骤来展开。\n\n### 步骤 1：目标相关矩阵的构建\n\n对于每个组（A：效应组，B：对照组），我们构建一个目标 $p \\times p$ 相关矩阵 $\\boldsymbol{\\Sigma}$。这些矩阵模拟了期望的群体水平连接结构。\n- 对于对照组（B 组），矩阵 $\\boldsymbol{\\Sigma}_B$ 的所有对角线元素等于 $1$，所有非对角线元素等于基线相关性 $\\rho$。该矩阵是正定的当且仅当 $-\\frac{1}{p-1} < \\rho < 1$。\n- 对于效应组（A 组），矩阵 $\\boldsymbol{\\Sigma}_A$ 以相同的基线结构开始，但在指定子网络 $S$ 内的所有节点对的相关性增加了 $\\delta$。因此，非对角线元素 $(i, j)$ 为：\n$$\n(\\boldsymbol{\\Sigma}_A)_{ij} = \\begin{cases}\n1 & \\text{if } i=j \\\\\n\\rho + \\delta & \\text{if } i \\neq j \\text{ and } i, j \\in S \\\\\n\\rho & \\text{if } i \\neq j \\text{ and } i \\notin S \\text{ or } j \\notin S\n\\end{cases}\n$$\n测试套件中提供的参数确保所有构建的矩阵都是有效的相关矩阵（即对称正定且对角线为单位值）。\n\n### 步骤 2：时间序列长度的确定\n\n选择模拟时间序列的长度 $T$ 是为了控制样本相关性估计的精度。皮尔逊相关系数 $r$ 的 Fisher $z$ 变换（由 $z = \\operatorname{atanh}(r)$ 给出）具有一个近似正态的抽样分布，其标准差为 $1/\\sqrt{T-3}$。为确保该标准差不大于指定的容差 $\\epsilon$，我们为 $T$ 设置一个下界：\n$$\n\\frac{1}{\\sqrt{T-3}} \\le \\epsilon \\implies T-3 \\ge \\frac{1}{\\epsilon^2} \\implies T \\ge 3 + \\frac{1}{\\epsilon^2}\n$$\n为了用最小的整数 $T$ 满足此条件，我们使用 $T = \\lceil 3 + 1/\\epsilon^2 \\rceil$。\n\n### 步骤 3：合成数据生成\n\n对于 A 组和 B 组中各自的 $n_A$ 和 $n_B$ 个被试，我们为 $p$ 个节点模拟长度为 $T$ 的多变量时间序列。数据从一个 $p$ 元正态分布中抽取，其均值为零，协方差矩阵等于该组的目标相关矩阵（$\\boldsymbol{\\Sigma}_A$ 或 $\\boldsymbol{\\Sigma}_B$）。这是通过 Cholesky 分解实现的。如果 $\\boldsymbol{\\Sigma} = \\boldsymbol{L}\\boldsymbol{L}^T$，其中 $\\boldsymbol{L}$ 是一个下三角矩阵，我们可以生成一个大小为 $T \\times p$ 的矩阵 $\\boldsymbol{Z}$，其条目从标准正态分布 $\\mathcal{N}(0, 1)$ 中抽取。期望的时间序列数据 $\\boldsymbol{X}$ 则由 $\\boldsymbol{X} = \\boldsymbol{Z}\\boldsymbol{L}^T$ 给出。$\\boldsymbol{X}$ 的每一行都是来自 $\\mathcal{N}(\\boldsymbol{0}, \\boldsymbol{\\Sigma})$ 的一个样本。\n\n### 步骤 4：被试水平边值的计算\n\n对于每个模拟的被试，我们从其 $T \\times p$ 的时间序列数据中计算 $p \\times p$ 的样本皮尔逊相关矩阵。提取该矩阵上三角的相关性。为了稳定方差并使这些相关性值的分布正态化，每个值都使用 Fisher $z$ 变换（$z = \\operatorname{atanh}(r)$）进行转换。这样就为每个被试得到一个边级别的 $z$ 值向量。\n\n### 步骤 5：观测检验统计量的计算\n\n为了检验每条边上的组间差异，对 Fisher $z$ 值计算 Welch 双样本 $t$ 统计量。对于每条边，比较 A 组和 B 组：\n$$\nt = \\frac{\\bar{z}_A - \\bar{z}_B}{\\sqrt{s_A^2 / n_A + s_B^2 / n_B}}\n$$\n其中 $\\bar{z}$ 和 $s^2$ 分别是组内某条边的 $z$ 值的样本均值和方差。将一个单侧主阈值 $\\tau$ 应用于这些 $t$ 统计量，仅保留 $t > \\tau$ 的边。这些超阈值边定义了一个包含 $p$ 个节点的图。\n\n下一步是识别该图中的连通组件。对于每个组件，其“质量”计算为构成该组件的所有边的 $t$ 统计量之和。这些组件质量的最大值即为观测到的 NBS 检验统计量 $M_{\\text{obs}}$。如果没有边通过主阈值筛选，则将 $M_{\\text{obs}}$ 设置为 $0$。\n\n### 步骤 6：置换检验和显著性评估\n\n为评估 $M_{\\text{obs}}$ 的显著性，通过置换检验经验性地生成一个零分布。将所有被试的组标签随机置换 $P$ 次。对于每次置换，重复计算边级别 $t$ 统计量和寻找最大组件质量的全过程，得到一个最大质量值 $M_{\\text{perm}}$。这 $P$ 个值的集合构成了最大组件质量的经验零分布。\n\n然后，通过将观测统计量 $M_{\\text{obs}}$ 与此零分布进行比较来计算最终的 NBS 组件水平 $p$ 值：\n$$\np_{\\text{NBS}} = \\frac{1 + \\text{number of permutations where } M_{\\text{perm}} \\ge M_{\\text{obs}}}{1 + P}\n$$\n在分子和分母中都加上“1”是为了考虑观测数据本身，并防止出现 $p$ 值为 $0$ 的情况。如果 $M_{\\text{obs}} = 0$，则将 $p$ 值定义为 $1$，因为没有检测到效应。对每个测试用例执行这整个过程以产生最终结果。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.sparse.csgraph import connected_components\nimport math\n\ndef _calculate_max_mass(z_A, z_B, p, tau):\n    \"\"\"\n    Computes t-statistics, thresholds, finds components, and returns max component mass.\n    \"\"\"\n    n_A = z_A.shape[0]\n    n_B = z_B.shape[0]\n\n    # Handle cases with zero variance for robustness\n    with np.errstate(divide='ignore', invalid='ignore'):\n        mean_A = np.mean(z_A, axis=0)\n        mean_B = np.mean(z_B, axis=0)\n        var_A = np.var(z_A, axis=0, ddof=1)\n        var_B = np.var(z_B, axis=0, ddof=1)\n        \n        # Welch's t-statistic\n        denominator = np.sqrt(var_A / n_A + var_B / n_B)\n        t_stats = np.divide(mean_A - mean_B, denominator, out=np.zeros_like(mean_A), where=denominator!=0)\n\n    # Apply primary threshold\n    suprathreshold_idx = np.where(t_stats > tau)[0]\n\n    if suprathreshold_idx.size == 0:\n        return 0.0\n\n    # Build adjacency matrix from suprathreshold edges\n    adj_matrix = np.zeros((p, p))\n    rows, cols = np.triu_indices(p, k=1)\n    \n    suprathreshold_rows = rows[suprathreshold_idx]\n    suprathreshold_cols = cols[suprathreshold_idx]\n    \n    adj_matrix[suprathreshold_rows, suprathreshold_cols] = 1\n    adj_matrix = adj_matrix + adj_matrix.T\n\n    # Find connected components\n    n_components, labels = connected_components(csgraph=adj_matrix, directed=False)\n    \n    if n_components == p: # No connections formed\n        return 0.0\n\n    # Calculate component masses\n    suprathreshold_t_stats = t_stats[suprathreshold_idx]\n    # The component label for an edge (u,v) is labels[u] (or labels[v])\n    edge_component_labels = labels[suprathreshold_rows]\n    \n    component_masses = np.bincount(edge_component_labels, weights=suprathreshold_t_stats, minlength=n_components)\n    \n    return np.max(component_masses) if component_masses.size > 0 else 0.0\n\n\ndef run_nbs_test(p, S, rho, delta, n_A, n_B, epsilon, tau, P, rng):\n    \"\"\"\n    Runs one full NBS simulation and hypothesis test.\n    \"\"\"\n    # 1. Construct target correlation matrices\n    corr_B = np.full((p, p), rho)\n    np.fill_diagonal(corr_B, 1)\n\n    corr_A = corr_B.copy()\n    subnetwork_indices = np.ix_(S, S)\n    corr_A[subnetwork_indices] = rho + delta\n    np.fill_diagonal(corr_A, 1)\n\n    # 2. Choose time series length T\n    T = math.ceil(3 + 1 / epsilon**2)\n\n    # 3. Simulate time series data and 4. Compute subject-level edge values\n    n_edges = p * (p - 1) // 2\n    z_vals_A = np.zeros((n_A, n_edges))\n    z_vals_B = np.zeros((n_B, n_edges))\n    \n    # Cholesky factors\n    L_A = np.linalg.cholesky(corr_A)\n    L_B = np.linalg.cholesky(corr_B)\n    \n    triu_indices = np.triu_indices(p, k=1)\n\n    # Group A\n    for i in range(n_A):\n        Z = rng.standard_normal(size=(T, p))\n        X = Z @ L_A.T\n        sample_corr = np.corrcoef(X, rowvar=False)\n        r_vals = sample_corr[triu_indices]\n        # Clipping to avoid inf in atanh, a practical necessity\n        r_vals = np.clip(r_vals, -1.0 + 1e-12, 1.0 - 1e-12)\n        z_vals_A[i, :] = np.arctanh(r_vals)\n\n    # Group B\n    for i in range(n_B):\n        Z = rng.standard_normal(size=(T, p))\n        X = Z @ L_B.T\n        sample_corr = np.corrcoef(X, rowvar=False)\n        r_vals = sample_corr[triu_indices]\n        r_vals = np.clip(r_vals, -1.0 + 1e-12, 1.0 - 1e-12)\n        z_vals_B[i, :] = np.arctanh(r_vals)\n\n    # 5. Compute observed maximum component mass\n    M_obs = _calculate_max_mass(z_vals_A, z_vals_B, p, tau)\n\n    if M_obs == 0:\n        return 1.0\n\n    # 6. Perform permutation testing\n    all_z_vals = np.vstack((z_vals_A, z_vals_B))\n    n_total = n_A + n_B\n    max_mass_perms = np.zeros(P)\n\n    for i in range(P):\n        perm_indices = rng.permutation(n_total)\n        perm_z_vals = all_z_vals[perm_indices]\n        \n        perm_z_A = perm_z_vals[:n_A, :]\n        perm_z_B = perm_z_vals[n_A:, :]\n        \n        max_mass_perms[i] = _calculate_max_mass(perm_z_A, perm_z_B, p, tau)\n\n    # Compute p-value\n    p_nbs = (1 + np.sum(max_mass_perms >= M_obs)) / (1 + P)\n    \n    return p_nbs\n\ndef solve():\n    \"\"\"\n    Main function to run the test suite and print results.\n    \"\"\"\n    # A fixed seed ensures the entire simulation is deterministic.\n    # We use a Random Number Generator for modern, encapsulated randomness.\n    rng = np.random.default_rng(42)\n\n    test_cases = [\n        {'p': 12, 's': 5, 'S': [0, 1, 2, 3, 4], 'rho': 0.2, 'delta': 0.25, 'n_A': 22, 'n_B': 22, 'epsilon': 0.07, 'tau': 3.0, 'P': 200},\n        {'p': 10, 's': 3, 'S': [0, 1, 2], 'rho': 0.1, 'delta': 0.1, 'n_A': 20, 'n_B': 20, 'epsilon': 0.08, 'tau': 3.5, 'P': 200},\n        {'p': 12, 's': 5, 'S': [0, 1, 2, 3, 4], 'rho': 0.2, 'delta': 0.25, 'n_A': 22, 'n_B': 22, 'epsilon': 0.07, 'tau': 9.0, 'P': 200}\n    ]\n\n    results = []\n    for case in test_cases:\n        p_val = run_nbs_test(\n            p=case['p'], S=case['S'], rho=case['rho'], delta=case['delta'],\n            n_A=case['n_A'], n_B=case['n_B'], epsilon=case['epsilon'],\n            tau=case['tau'], P=case['P'], rng=rng\n        )\n        results.append(p_val)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        }
    ]
}