{
    "hands_on_practices": [
        {
            "introduction": "在功能连接分析中，原始的功能磁共振成像 (fMRI) 信号混合了来自头部运动、生理搏动等来源的多种噪声。在计算区域间相关性之前，一个至关重要的预处理步骤是“伪迹回归”，用以移除这些不相关的信号。本练习将引导您从普通最小二乘法的基本原理出发，推导并应用正交投影算子来分离和剔除这些伪迹信号，从而为构建准确的功能连接矩阵奠定坚实的基础。",
            "id": "4147895",
            "problem": "在静息态功能连接分析中，原始的血氧水平依赖 (BOLD) 时间序列通常在计算区域间相关性之前，通过回归去除头部运动、脑脊液 (CSF) 和白质 (WM) 等干扰信号进行预处理。考虑一个具有 $T$ 个时间点的单次会话数据集。设 $X \\in \\mathbb{R}^{T \\times p}$ 表示一个干扰设计矩阵，其列张成干扰子空间，并设 $y \\in \\mathbb{R}^{T}$ 表示一个原始的区域 BOLD 时间序列。残差化是通过拟合一个普通最小二乘模型，并从 $y$ 中减去拟合的干扰分量来执行的。从普通最小二乘法作为残差平方和最小化器的定义以及子空间上的正交投影的定义出发，推导将 $y$ 映射到其关于 $X$ 的列空间的回归残差的线性算子，然后将其应用于以下构建功能连接的具体示例。\n\n给定两个区域的 $T=5$ 个时间点的原始 BOLD 时间序列 $y^{(1)}$ 和 $y^{(2)}$：\n$$\ny^{(1)} = \\begin{pmatrix} 1 \\\\ 3 \\\\ 2 \\\\ 5 \\\\ 7 \\end{pmatrix}, \n\\quad\ny^{(2)} = \\begin{pmatrix} 2 \\\\ 1 \\\\ 4 \\\\ 3 \\\\ 6 \\end{pmatrix}.\n$$\n对于干扰回归，使用一个双回归量设计矩阵 $X = [x_{0}, x_{1}] \\in \\mathbb{R}^{5 \\times 2}$，其列为\n$$\nx_{0} = \\begin{pmatrix} 1 \\\\ 1 \\\\ 1 \\\\ 1 \\\\ 1 \\end{pmatrix} \\quad \\text{(截距项)}, \n\\qquad\nx_{1} = \\begin{pmatrix} -2 \\\\ -1 \\\\ 0 \\\\ 1 \\\\ 2 \\end{pmatrix} \\quad \\text{(一个复合干扰，捕捉了脑脊液和白质生理学以及头部运动，已标准化为零均值)}。\n$$\n仅使用普通最小二乘法和正交投影的基本原理，计算通过将 $y^{(1)}$ 和 $y^{(2)}$ 对 $X$ 的列进行回归所得到的两个区域的残差化时间序列之间的皮尔逊相关系数。将您的最终答案表示为单个精确的简化表达式，不带单位。不要四舍五入。",
            "solution": "这个问题是有效的，因为它在科学上基于神经科学数据分析中使用的标准统计方法（普通最小二乘法，功能连接），问题设定良好且有唯一解，并且客观地表达，提供了所有必要的数据。\n\n第一步是推导将原始时间序列向量 $y \\in \\mathbb{R}^{T}$ 映射到其关于设计矩阵 $X \\in \\mathbb{R}^{T \\times p}$ 的列空间的回归残差的线性算子。普通最小二乘 (OLS) 模型是 $y = X\\beta + e$，其中 $\\beta \\in \\mathbb{R}^{p}$ 是系数向量， $e \\in \\mathbb{R}^{T}$ 是残差向量。OLS 旨在找到最小化残差平方和的估计值 $\\hat{\\beta}$，即残差向量 $e$ 的欧几里得范数的平方：\n$$S(\\beta) = \\|e\\|^2 = \\|y - X\\beta\\|^2 = (y - X\\beta)^T(y - X\\beta)$$\n展开此表达式可得：\n$$S(\\beta) = y^T y - y^T X\\beta - \\beta^T X^T y + \\beta^T X^T X \\beta$$\n由于 $\\beta^T X^T y$ 是一个标量，它等于其转置 $(y^T X\\beta)^T$，即 $y^T X\\beta$。所以，我们可以写成：\n$$S(\\beta) = y^T y - 2y^T X\\beta + \\beta^T X^T X \\beta$$\n为了找到最小值，我们计算 $S(\\beta)$ 关于 $\\beta$ 的梯度并将其设为零：\n$$\\frac{\\partial S}{\\partial \\beta} = -2X^T y + 2X^T X \\beta = 0$$\n这就得到了正规方程组：\n$$X^T X \\hat{\\beta} = X^T y$$\n假设 $X$ 的列是线性无关的，则矩阵 $X^T X$ 是可逆的。那么系数的 OLS 估计值为：\n$$\\hat{\\beta} = (X^T X)^{-1} X^T y$$\n拟合值向量 $\\hat{y}$ 是 $y$ 在 $X$ 的列空间上的投影。它由以下公式给出：\n$$\\hat{y} = X\\hat{\\beta} = X(X^T X)^{-1} X^T y$$\n矩阵 $P = X(X^T X)^{-1} X^T$ 是到 $X$ 的列空间上的正交投影矩阵。回归残差是原始数据与拟合值之间的差：\n$$e = y - \\hat{y} = y - Py = (I - P)y$$\n因此，将 $y$ 映射到其残差的线性算子是矩阵 $M = I - P = I - X(X^T X)^{-1} X^T$。该算子本身是一个到与 $X$ 的列空间正交的子空间上的正交投影矩阵。\n\n现在，我们将此应用于给定的数据。给定 $T=5$ 和设计矩阵 $X = [x_0, x_1]$：\n$$X = \\begin{pmatrix} 1 & -2 \\\\ 1 & -1 \\\\ 1 & 0 \\\\ 1 & 1 \\\\ 1 & 2 \\end{pmatrix}$$\n首先，我们计算 $X^T X$：\n$$X^T X = \\begin{pmatrix} 1 & 1 & 1 & 1 & 1 \\\\ -2 & -1 & 0 & 1 & 2 \\end{pmatrix} \\begin{pmatrix} 1 & -2 \\\\ 1 & -1 \\\\ 1 & 0 \\\\ 1 & 1 \\\\ 1 & 2 \\end{pmatrix} = \\begin{pmatrix} 5 & 0 \\\\ 0 & 10 \\end{pmatrix}$$\n非对角元素为零，这证实了列 $x_0$ 和 $x_1$ 是正交的。这简化了计算。其逆矩阵为：\n$$(X^T X)^{-1} = \\begin{pmatrix} \\frac{1}{5} & 0 \\\\ 0 & \\frac{1}{10} \\end{pmatrix}$$\n我们需要找到 $y^{(1)}$ 和 $y^{(2)}$ 的残差。我们将其表示为 $e^{(1)}$ 和 $e^{(2)}$。\n\n对于 $y^{(1)} = \\begin{pmatrix} 1 \\\\ 3 \\\\ 2 \\\\ 5 \\\\ 7 \\end{pmatrix}$：\n我们首先计算 $X^T y^{(1)}$：\n$$X^T y^{(1)} = \\begin{pmatrix} 1 & 1 & 1 & 1 & 1 \\\\ -2 & -1 & 0 & 1 & 2 \\end{pmatrix} \\begin{pmatrix} 1 \\\\ 3 \\\\ 2 \\\\ 5 \\\\ 7 \\end{pmatrix} = \\begin{pmatrix} 1+3+2+5+7 \\\\ -2-3+0+5+14 \\end{pmatrix} = \\begin{pmatrix} 18 \\\\ 14 \\end{pmatrix}$$\n现在我们求系数 $\\hat{\\beta}^{(1)}$：\n$$\\hat{\\beta}^{(1)} = (X^T X)^{-1} X^T y^{(1)} = \\begin{pmatrix} \\frac{1}{5} & 0 \\\\ 0 & \\frac{1}{10} \\end{pmatrix} \\begin{pmatrix} 18 \\\\ 14 \\end{pmatrix} = \\begin{pmatrix} \\frac{18}{5} \\\\ \\frac{14}{10} \\end{pmatrix} = \\begin{pmatrix} \\frac{18}{5} \\\\ \\frac{7}{5} \\end{pmatrix}$$\n拟合值为 $\\hat{y}^{(1)} = X\\hat{\\beta}^{(1)}$：\n$$\\hat{y}^{(1)} = \\begin{pmatrix} 1 & -2 \\\\ 1 & -1 \\\\ 1 & 0 \\\\ 1 & 1 \\\\ 1 & 2 \\end{pmatrix} \\begin{pmatrix} \\frac{18}{5} \\\\ \\frac{7}{5} \\end{pmatrix} = \\frac{1}{5} \\begin{pmatrix} 18 - 14 \\\\ 18 - 7 \\\\ 18 - 0 \\\\ 18 + 7 \\\\ 18 + 14 \\end{pmatrix} = \\frac{1}{5} \\begin{pmatrix} 4 \\\\ 11 \\\\ 18 \\\\ 25 \\\\ 32 \\end{pmatrix}$$\n残差 $e^{(1)}$ 为 $y^{(1)} - \\hat{y}^{(1)}$：\n$$e^{(1)} = \\frac{1}{5} \\begin{pmatrix} 5 \\\\ 15 \\\\ 10 \\\\ 25 \\\\ 35 \\end{pmatrix} - \\frac{1}{5} \\begin{pmatrix} 4 \\\\ 11 \\\\ 18 \\\\ 25 \\\\ 32 \\end{pmatrix} = \\frac{1}{5} \\begin{pmatrix} 1 \\\\ 4 \\\\ -8 \\\\ 0 \\\\ 3 \\end{pmatrix}$$\n\n对于 $y^{(2)} = \\begin{pmatrix} 2 \\\\ 1 \\\\ 4 \\\\ 3 \\\\ 6 \\end{pmatrix}$：\n我们计算 $X^T y^{(2)}$：\n$$X^T y^{(2)} = \\begin{pmatrix} 1 & 1 & 1 & 1 & 1 \\\\ -2 & -1 & 0 & 1 & 2 \\end{pmatrix} \\begin{pmatrix} 2 \\\\ 1 \\\\ 4 \\\\ 3 \\\\ 6 \\end{pmatrix} = \\begin{pmatrix} 2+1+4+3+6 \\\\ -4-1+0+3+12 \\end{pmatrix} = \\begin{pmatrix} 16 \\\\ 10 \\end{pmatrix}$$\n系数 $\\hat{\\beta}^{(2)}$ 为：\n$$\\hat{\\beta}^{(2)} = (X^T X)^{-1} X^T y^{(2)} = \\begin{pmatrix} \\frac{1}{5} & 0 \\\\ 0 & \\frac{1}{10} \\end{pmatrix} \\begin{pmatrix} 16 \\\\ 10 \\end{pmatrix} = \\begin{pmatrix} \\frac{16}{5} \\\\ \\frac{10}{10} \\end{pmatrix} = \\begin{pmatrix} \\frac{16}{5} \\\\ 1 \\end{pmatrix}$$\n拟合值为 $\\hat{y}^{(2)} = X\\hat{\\beta}^{(2)}$：\n$$\\hat{y}^{(2)} = \\begin{pmatrix} 1 & -2 \\\\ 1 & -1 \\\\ 1 & 0 \\\\ 1 & 1 \\\\ 1 & 2 \\end{pmatrix} \\begin{pmatrix} \\frac{16}{5} \\\\ 1 \\end{pmatrix} = \\frac{1}{5} \\begin{pmatrix} 16 - 10 \\\\ 16 - 5 \\\\ 16 - 0 \\\\ 16 + 5 \\\\ 16 + 10 \\end{pmatrix} = \\frac{1}{5} \\begin{pmatrix} 6 \\\\ 11 \\\\ 16 \\\\ 21 \\\\ 26 \\end{pmatrix}$$\n残差 $e^{(2)}$ 为 $y^{(2)} - \\hat{y}^{(2)}$：\n$$e^{(2)} = \\frac{1}{5} \\begin{pmatrix} 10 \\\\ 5 \\\\ 20 \\\\ 15 \\\\ 30 \\end{pmatrix} - \\frac{1}{5} \\begin{pmatrix} 6 \\\\ 11 \\\\ 16 \\\\ 21 \\\\ 26 \\end{pmatrix} = \\frac{1}{5} \\begin{pmatrix} 4 \\\\ -6 \\\\ 4 \\\\ -6 \\\\ 4 \\end{pmatrix}$$\n\n最后，我们计算 $e^{(1)}$ 和 $e^{(2)}$ 之间的皮尔逊相关系数 $r$。由于回归包含截距项 ($x_0$)，两个时间序列的残差均值为零。这将皮尔逊相关公式简化为两个向量之间夹角的余弦：\n$$r = \\frac{ \\sum_{i=1}^T e_i^{(1)} e_i^{(2)} }{ \\sqrt{\\sum_{i=1}^T (e_i^{(1)})^2} \\sqrt{\\sum_{i=1}^T (e_i^{(2)})^2} } = \\frac{e^{(1) T} e^{(2)}}{\\|e^{(1)}\\| \\|e^{(2)}\\|}$$\n我们计算点积 $e^{(1) T} e^{(2)}$：\n$$e^{(1) T} e^{(2)} = \\left(\\frac{1}{5}\\right)^2 \\begin{pmatrix} 1 & 4 & -8 & 0 & 3 \\end{pmatrix} \\begin{pmatrix} 4 \\\\ -6 \\\\ 4 \\\\ -6 \\\\ 4 \\end{pmatrix} = \\frac{1}{25}(1(4) + 4(-6) + (-8)(4) + 0(-6) + 3(4))$$\n$$e^{(1) T} e^{(2)} = \\frac{1}{25}(4 - 24 - 32 + 0 + 12) = \\frac{1}{25}(16 - 56) = \\frac{-40}{25} = -\\frac{8}{5}$$\n接下来，我们计算残差向量的范数平方：\n$$\\|e^{(1)}\\|^2 = \\left(\\frac{1}{5}\\right)^2 (1^2 + 4^2 + (-8)^2 + 0^2 + 3^2) = \\frac{1}{25}(1+16+64+0+9) = \\frac{90}{25} = \\frac{18}{5}$$\n$$\\|e^{(2)}\\|^2 = \\left(\\frac{1}{5}\\right)^2 (4^2 + (-6)^2 + 4^2 + (-6)^2 + 4^2) = \\frac{1}{25}(16+36+16+36+16) = \\frac{1}{25}(48+72) = \\frac{120}{25} = \\frac{24}{5}$$\n现在我们组合相关系数：\n$$r = \\frac{-\\frac{8}{5}}{\\sqrt{\\frac{18}{5}} \\sqrt{\\frac{24}{5}}} = \\frac{-\\frac{8}{5}}{\\sqrt{\\frac{18 \\times 24}{25}}} = \\frac{-\\frac{8}{5}}{\\frac{\\sqrt{432}}{5}} = \\frac{-8}{\\sqrt{432}}$$\n为了简化平方根，我们分解 432：$432 = 144 \\times 3 = 12^2 \\times 3$。所以，$\\sqrt{432} = 12\\sqrt{3}$。\n$$r = \\frac{-8}{12\\sqrt{3}} = \\frac{-2}{3\\sqrt{3}}$$\n对分母进行有理化，得到最终答案：\n$$r = \\frac{-2\\sqrt{3}}{3\\sqrt{3}\\sqrt{3}} = \\frac{-2\\sqrt{3}}{9}$$\n残差化时间序列之间的皮尔逊相关系数为 $-\\frac{2\\sqrt{3}}{9}$。",
            "answer": "$$\\boxed{-\\frac{2\\sqrt{3}}{9}}$$"
        },
        {
            "introduction": "从时间序列计算出的相关系数值仅仅是一个点估计，它会受到样本噪声的影响。为了进行可靠的科学推断，我们必须量化其不确定性。本练习将介绍 Fisher z 变换，这是一种将相关系数的采样分布近似正态化的经典统计方法，通过它我们可以为真实的连接强度构建置信区间，从而评估我们观察到的连接的统计可靠性。",
            "id": "4147949",
            "problem": "您正在根据静息态功能磁共振成像 (fMRI) 数据构建一个功能连接矩阵。对于每对感兴趣区域 (ROI)，您计算样本皮尔逊相关系数以填充该矩阵。考虑由 $i$ 和 $j$ 索引的单个 ROI 对。在进行运动审查、时间去趋势和自回归 (AR) 预白化后，时间序列被视为独立的，并近似服从二元正态分布，有效样本量为 $n=150$。从这些预处理信号计算得出的连接矩阵中的条目 $\\hat{R}_{ij}$ 为 $\\hat{R}_{ij}=0.4$。\n\n从皮尔逊相关的定义和 ROI 信号近似二元正态性的假设出发，推导出一个适当的变换，该变换能为相关性得出一个近似正态的统计量，并论证为何使用该变换来为总体相关性 $R_{ij}$ 构建一个覆盖率近似为 $0.95$ 的双侧置信区间。然后，应用此框架，根据给定的 $\\hat{R}_{ij}$ 和 $n$ 计算 $R_{ij}$ 的近似双侧 $0.95$ 置信区间的下限。\n\n将您的最终数值答案四舍五入到四位有效数字。将最终答案表示为无单位的小数。",
            "solution": "功能连接矩阵通常是利用 ROI 时间序列对之间的皮尔逊积矩相关系数来构建的。对于两个标量的、零均值的、平稳的随机过程 $X_{i}(t)$ 和 $X_{j}(t)$，在预白化后被视为独立的，并采样 $n$ 次，其样本皮尔逊相关性为\n$$\n\\hat{R}_{ij} \\;=\\; \\frac{\\sum_{t=1}^{n} X_{i}(t) X_{j}(t)}{\\sqrt{\\sum_{t=1}^{n} X_{i}(t)^{2}} \\,\\sqrt{\\sum_{t=1}^{n} X_{j}(t)^{2}}}.\n$$\n在 $(X_{i}(t), X_{j}(t))$ 近似服从二元正态分布（真实相关性为 $R_{ij}$）且 $n$ 较大的假设下，Fisher 证明了变换\n$$\nz \\;=\\; \\operatorname{atanh}(r) \\;=\\; \\frac{1}{2}\\,\\ln\\!\\left(\\frac{1+r}{1-r}\\right)\n$$\n应用于相关性 $r$ 会产生一个其抽样分布接近正态分布的统计量。更具体地说，对于样本相关性 $\\hat{R}_{ij}$，变换后的统计量\n$$\n\\hat{z}_{ij} \\;=\\; \\operatorname{atanh}(\\hat{R}_{ij})\n$$\n近似服从均值为 $\\operatorname{atanh}(R_{ij})$、方差为 $\\frac{1}{n-3}$ 的正态分布：\n$$\n\\hat{z}_{ij} \\;\\dot{\\sim}\\; \\mathcal{N}\\!\\left(\\operatorname{atanh}(R_{ij}), \\;\\frac{1}{n-3}\\right),\n$$\n其中，点号表示一个由大样本理论支持的近似（对于二元正态数据，这是一个经典的、经过充分检验的结果）。这一性质源于相关估计量的渐近正态性，并结合了应用于平滑单调函数 $\\operatorname{atanh}(\\cdot)$ 的德尔塔方法。\n\n鉴于这种近似正态性，对于变换后的参数 $\\operatorname{atanh}(R_{ij})$，一个覆盖率近似为 $0.95$ 的双侧置信区间是\n$$\n\\operatorname{atanh}(R_{ij}) \\in \\left[\\,\\hat{z}_{ij} - z_{0.975}\\,\\sqrt{\\frac{1}{n-3}},\\; \\hat{z}_{ij} + z_{0.975}\\,\\sqrt{\\frac{1}{n-3}}\\,\\right],\n$$\n其中 $z_{0.975}$ 是标准正态分布的 $0.975$ 分位数，因此 $z_{0.975} = 1.96$。使用逆变换 $r = \\tanh(z)$ 将此区间映射回相关尺度，可以得到 $R_{ij}$ 的一个近似置信区间：\n$$\nR_{ij} \\in \\left[\\,\\tanh\\!\\left(\\hat{z}_{ij} - 1.96\\,\\sqrt{\\frac{1}{n-3}}\\right),\\; \\tanh\\!\\left(\\hat{z}_{ij} + 1.96\\,\\sqrt{\\frac{1}{n-3}}\\right)\\,\\right].\n$$\n\n我们需要计算给定数据的下限。首先计算观测到的相关性的 Fisher z 变换：\n$$\n\\hat{z}_{ij} \\;=\\; \\operatorname{atanh}(0.4) \\;=\\; \\frac{1}{2}\\,\\ln\\!\\left(\\frac{1+0.4}{1-0.4}\\right) \\;=\\; \\frac{1}{2}\\,\\ln\\!\\left(\\frac{1.4}{0.6}\\right) \\;=\\; \\frac{1}{2}\\,\\ln\\!\\left(2.\\overline{3}\\right).\n$$\n数值上，\n$$\n\\hat{z}_{ij} \\approx 0.423648930193.\n$$\n接下来计算 z 尺度上的标准误：\n$$\n\\mathrm{SE}_{z} \\;=\\; \\sqrt{\\frac{1}{n-3}} \\;=\\; \\sqrt{\\frac{1}{150-3}} \\;=\\; \\sqrt{\\frac{1}{147}} \\;=\\; \\frac{1}{\\sqrt{147}} \\;=\\; \\frac{1}{7\\sqrt{3}} \\approx 0.082478609898.\n$$\n在 z 尺度上构建下限：\n$$\nz_{\\text{lower}} \\;=\\; \\hat{z}_{ij} - 1.96\\,\\mathrm{SE}_{z} \\;\\approx\\; 0.423648930193 \\;-\\; 1.96 \\times 0.082478609898 \\;\\approx\\; 0.261990854792.\n$$\n使用 $r = \\tanh(z)$ 变换回相关尺度：\n$$\nR_{\\text{lower}} \\;=\\; \\tanh\\!\\left(z_{\\text{lower}}\\right) \\;=\\; \\frac{\\exp\\!\\left(2\\,z_{\\text{lower}}\\right) - 1}{\\exp\\!\\left(2\\,z_{\\text{lower}}\\right) + 1},\n$$\n其中\n$$\n2\\,z_{\\text{lower}} \\;\\approx\\; 0.523981709584, \\quad \\exp\\!\\left(2\\,z_{\\text{lower}}\\right) \\;\\approx\\; 1.68873831,\n$$\n所以\n$$\nR_{\\text{lower}} \\;\\approx\\; \\frac{1.68873831 - 1}{1.68873831 + 1} \\;=\\; \\frac{0.68873831}{2.68873831} \\;\\approx\\; 0.2561567.\n$$\n四舍五入到四位有效数字，下限为\n$$\n0.2562.\n$$\n这个值就是所求的、ROI $i$ 和 $j$ 之间真实功能连接（相关性）$R_{ij}$ 的近似双侧 $0.95$ 置信区间的下限。",
            "answer": "$$\\boxed{0.2562}$$"
        },
        {
            "introduction": "功能连接矩阵为我们将大脑作为一个复杂网络来研究提供了基础。然而，如何表示这个网络——是保留连接的权重信息，还是通过阈值处理将其简化为二元网络——是一个关键的分析决策。本练习将通过一个编程实践，让您亲手计算并比较加权网络与二值化网络在聚类系数和特征路径长度等核心图论指标上的差异，从而深刻理解不同分析选择对网络拓扑属性解释的影响。",
            "id": "4147918",
            "problem": "您的任务是根据合成的多元时间序列构建功能连接矩阵，并评估加权连接的二值化对两个典型图指标（聚类系数和特征路径长度）的影响。您必须生成一个单一的可运行程序，为指定的测试套件计算所需的量，并以文末描述的精确格式打印最终结果。所有计算必须源自图论和统计学中的核心定义和经过充分检验的公式。\n\n此问题的基本基础如下。您将从一个零均值多元正态分布 $\\mathcal{N}(0, \\Sigma)$ 生成合成的多元时间序列 $X \\in \\mathbb{R}^{T \\times N}$，其协方差矩阵 $\\Sigma \\in \\mathbb{R}^{N \\times N}$ 在每个测试用例中都已指定。根据 $X$，您将计算每对节点时间序列之间的皮尔逊相关系数 (PCC)，以获得一个相关矩阵 $R \\in \\mathbb{R}^{N \\times N}$，其中每个条目 $r_{ij}$ 是节点 $i$ 和节点 $j$ 之间的 PCC。您必须使用 $w_{ij} = |r_{ij}|$ (对于 $i \\neq j$) 和 $w_{ii} = 0$ (对于所有 $i$) 构建一个加权无向功能连接邻接矩阵 $W \\in \\mathbb{R}^{N \\times N}$。\n\n为了评估二值化的影响，使用阈值 $\\tau > 0$ 定义一个二值邻接矩阵 $B \\in \\{0,1\\}^{N \\times N}$，使得如果 $w_{ij} \\ge \\tau$，则 $b_{ij} = 1$，否则 $b_{ij} = 0$，并设 $b_{ii} = 0$。对于 $B$，所有图均假定为无向无权图；对于 $W$，则为具有正权重的无向图。\n\n您将计算以下图指标：\n- 二值图的逐节点聚类系数。节点 $i$ 的聚类系数是与节点 $i$ 关联的三角形数量与可能关联的三角形数量之比，全局聚类系数是所有节点的平均值。对于度小于 $2$ 的节点，聚类系数定义为 $0$。\n- 使用 Onnela 公式的加权图的逐节点加权聚类系数：设 $\\hat{W}$ 是权重归一化的邻接矩阵，其中 $\\hat{w}_{ij} = \\frac{w_{ij}}{\\max_{p,q} w_{pq}}$。节点 $i$ 的加权聚类系数是与节点 $i$ 相邻的三角形边权重的几何平均值的平均值，再除以潜在邻居对的数量，全局系数是所有节点的平均值。对于度小于 $2$ 的节点，此系数定义为 $0$。\n- 二值图的特征路径长度，定义为所有相连的不同节点对之间的平均最短路径长度，其中每条边的长度为单位长度。\n- 加权图的特征路径长度，定义为所有不同节点对之间的平均最短路径长度，其中穿过一条边的成本为 $c_{ij} = \\frac{1}{w_{ij}}$ (对于 $w_{ij} > 0$)。如果在二值图下没有成对的节点是相连的，则将特征路径长度定义为 $\\mathrm{NaN}$。\n\n您将为每个测试用例计算二值化对这些指标的影响，即差值：\n$$\n\\Delta C = \\bar{C}_B - \\bar{C}_W, \\quad \\Delta L = L_B - L_W,\n$$\n其中 $\\bar{C}_B$ 是二值图的全局聚类系数，$\\bar{C}_W$ 是加权图的全局加权聚类系数，$L_B$ 是二值特征路径长度，$L_W$ 是加权特征路径长度。\n\n所有量必须使用以下核心定义进行计算：\n- 两个实值序列 $x, y \\in \\mathbb{R}^{T}$ 之间的皮尔逊相关系数 (PCC) 为\n$$\nr(x,y) = \\frac{\\sum_{t=1}^{T} \\left(x_t - \\bar{x}\\right)\\left(y_t - \\bar{y}\\right)}{\\sqrt{\\sum_{t=1}^{T} \\left(x_t - \\bar{x}\\right)^2} \\sqrt{\\sum_{t=1}^{T} \\left(y_t - \\bar{y}\\right)^2}},\n$$\n其中 $\\bar{x}$ 和 $\\bar{y}$ 是样本均值。\n- 节点 $i$ 的二值聚类系数为\n$$\nC_i = \\frac{\\text{与节点 } i \\text{ 关联的三角形数量}}{\\binom{k_i}{2}},\n$$\n对于度 $k_i \\ge 2$，否则 $C_i = 0$。全局二值聚类系数为\n$$\n\\bar{C}_B = \\frac{1}{N} \\sum_{i=1}^{N} C_i.\n$$\n- 节点 $i$ 的加权聚类系数 (Onnela) 为\n$$\nC_i^w = \\frac{1}{\\binom{k_i}{2}} \\sum_{\\{j,k\\} \\subset \\mathcal{N}(i)} \\left(\\hat{w}_{ij} \\hat{w}_{ik} \\hat{w}_{jk}\\right)^{1/3},\n$$\n对于度 $k_i \\ge 2$，否则 $C_i^w = 0$，其中 $\\mathcal{N}(i)$ 是加权图中节点 $i$ 的邻居集合，$\\hat{w}_{ij}$ 是归一化权重。全局加权聚类系数为\n$$\n\\bar{C}_W = \\frac{1}{N} \\sum_{i=1}^{N} C_i^w.\n$$\n- 对于具有距离矩阵 $D$ 的图，其特征路径长度为\n$$\nL = \\frac{1}{|\\{(i,j): i<j, D_{ij} < \\infty\\}|} \\sum_{i<j, D_{ij} < \\infty} D_{ij}.\n$$\n如果在二值图下没有成对的节点是相连的，则将特征路径长度定义为 $\\mathrm{NaN}$。\n\n您将为以下四个测试用例计算这些量：\n```python\n[\n    {\n        \"N\": 6, \"T\": 3000, \"tau\": 0.4, \"seed\": 123,\n        \"Sigma\": np.array([\n            [1, 0.8, 0.8, 0.2, 0.2, 0.2],\n            [0.8, 1, 0.8, 0.2, 0.2, 0.2],\n            [0.8, 0.8, 1, 0.2, 0.2, 0.2],\n            [0.2, 0.2, 0.2, 1, 0.5, 0.5],\n            [0.2, 0.2, 0.2, 0.5, 1, 0.5],\n            [0.2, 0.2, 0.2, 0.5, 0.5, 1]\n        ])\n    },\n    {\n        \"N\": 6, \"T\": 3000, \"tau\": 0.5, \"seed\": 456,\n        \"Sigma\": np.array([\n            [1, 0.6, 0.6, 0.6, 0.6, 0.6],\n            [0.6, 1, 0.6, 0.6, 0.6, 0.6],\n            [0.6, 0.6, 1, 0.6, 0.6, 0.6],\n            [0.6, 0.6, 0.6, 1, 0.6, 0.6],\n            [0.6, 0.6, 0.6, 0.6, 1, 0.6],\n            [0.6, 0.6, 0.6, 0.6, 0.6, 1]\n        ])\n    },\n    {\n        \"N\": 6, \"T\": 3000, \"tau\": 0.2, \"seed\": 789,\n        \"Sigma\": np.array([\n            [1, 0.7, 0.7, 0.7, 0.7, 0.7],\n            [0.7, 1, 0.05, 0.05, 0.05, 0.05],\n            [0.7, 0.05, 1, 0.05, 0.05, 0.05],\n            [0.7, 0.05, 0.05, 1, 0.05, 0.05],\n            [0.7, 0.05, 0.05, 0.05, 1, 0.05],\n            [0.7, 0.05, 0.05, 0.05, 0.05, 1]\n        ])\n    },\n    {\n        \"N\": 5, \"T\": 5000, \"tau\": 0.25, \"seed\": 101112,\n        \"Sigma\": np.array([\n            [1, 0.3, 0.05, 0.05, 0.3],\n            [0.3, 1, 0.3, 0.05, 0.05],\n            [0.05, 0.3, 1, 0.3, 0.05],\n            [0.05, 0.05, 0.3, 1, 0.3],\n            [0.3, 0.05, 0.05, 0.3, 1]\n        ])\n    }\n]\n```\n最终输出必须是一个包含所有测试用例结果的单一列表。每个结果都是一个包含两个浮点数的列表，`[ΔC, ΔL]`，四舍五入到六位小数。如果 $L_B$ 为 NaN，则应将 `ΔL` 表示为字符串 \"nan\"。最终输出格式应为：`[[dC1, dL1], [dC2, dL2], ...]`。",
            "solution": "该问题已经过分析，被认为是有效的。它具有科学依据、问题明确、客观，并包含了进行求解所需的所有必要信息和定义。所提供的协方差矩阵是正定的，确保可以定义有效的多元正态分布。计算任务有明确的数学公式和算法要求。\n\n解决方案通过为每个测试用例实施指定步骤来进行。\n\n**1. 合成时间序列的生成**\n对于每个测试用例，我们都给定了节点数 $N$、时间点数 $T$、一个协方差矩阵 $\\Sigma \\in \\mathbb{R}^{N \\times N}$ 以及一个随机数生成器种子 $s$。我们通过从零均值多元正态分布 $X \\sim \\mathcal{N}(0, \\Sigma)$ 中抽取 $T$ 个样本来生成一个多元时间序列矩阵 $X \\in \\mathbb{R}^{T \\times N}$。使用特定的种子可确保结果的可复现性。\n\n**2. 连接矩阵的构建**\n根据时间序列数据 $X$，我们推导出两个功能连接矩阵：一个加权邻接矩阵 $W$ 和一个二值邻接矩阵 $B$。\n\n*   **皮尔逊相关矩阵 ($R$)**：首先，我们计算 $X$ 中每对时间序列（列）之间的皮尔逊相关系数 (PCC)。两个序列 $x, y \\in \\mathbb{R}^T$ 之间的 PCC 由下式给出：\n    $$\n    r(x,y) = \\frac{\\sum_{t=1}^{T} (x_t - \\bar{x})(y_t - \\bar{y})}{\\sqrt{\\sum_{t=1}^{T} (x_t - \\bar{x})^2} \\sqrt{\\sum_{t=1}^{T} (y_t - \\bar{y})^2}}\n    $$\n    这将得到一个 $N \\times N$ 的相关矩阵 $R$，其中 $R_{ij} = r(X_i, X_j)$，$X_i$ 是节点 $i$ 的时间序列。\n\n*   **加权邻接矩阵 ($W$)**：通过取相关系数的绝对值来构建加权无向邻接矩阵 $W$：\n    $$\n    w_{ij} = |r_{ij}| \\quad \\text{for } i \\neq j, \\quad \\text{and} \\quad w_{ii} = 0.\n    $$\n\n*   **二值邻接矩阵 ($B$)**：通过对加权矩阵 $W$ 应用阈值 $\\tau$ 来获得二值邻接矩阵 $B$：\n    $$\n    b_{ij} = \\begin{cases} 1 & \\text{if } w_{ij} \\ge \\tau \\\\ 0 & \\text{otherwise} \\end{cases}, \\quad \\text{with } b_{ii} = 0.\n    $$\n\n**3. 图论指标的计算**\n\n**3.1. 聚类系数**\n聚类系数衡量图中节点聚集在一起的趋势。我们为二值图和加权图计算全局聚类系数。\n\n*   **二值全局聚类系数 ($\\bar{C}_B$)**：对于二值图 $B$ 中的每个节点 $i$，局部聚类系数 $C_i$ 是其邻居之间也相互连接的比例。\n    $$\n    C_i = \\frac{\\text{节点 } i \\text{ 周围的三角形数量}}{\\text{节点 } i \\text{ 周围可能的三角形数量}} = \\frac{|\\{(j,k) \\mid b_{ij}=1, b_{ik}=1, b_{jk}=1\\}|}{\\binom{k_i}{2}}\n    $$\n    其中 $k_i$ 是节点 $i$ 的度 ($k_i = \\sum_j b_{ij}$)。如果 $k_i < 2$，$C_i$ 定义为 $0$。全局系数是所有节点的平均值：$\\bar{C}_B = \\frac{1}{N} \\sum_{i=1}^{N} C_i$。\n\n*   **加权全局聚类系数 ($\\bar{C}_W$)**：我们使用 Onnela 公式。首先，权重矩阵 $W$ 通过其最大项进行归一化：$\\hat{w}_{ij} = w_{ij} / \\max_{p,q} w_{pq}$。节点 $i$ 的加权聚类系数为：\n    $$\n    C_i^w = \\frac{1}{\\binom{k_i}{2}} \\sum_{\\{j,k\\} \\subset \\mathcal{N}(i)} \\left(\\hat{w}_{ij} \\hat{w}_{ik} \\hat{w}_{jk}\\right)^{1/3}\n    $$\n    这里，$\\mathcal{N}(i)$ 是节点 $i$ 的邻居集合（即 $w_{ij}>0$ 的节点 $j$），且 $k_i = |\\mathcal{N}(i)|$。如果 $k_i < 2$，$C_i^w=0$。全局系数是平均值：$\\bar{C}_W = \\frac{1}{N} \\sum_{i=1}^{N} C_i^w$。\n\n**3.2. 特征路径长度**\n特征路径长度是衡量网络中节点之间平均分离程度的指标。我们需要使用 Floyd-Warshall 算法计算所有节点对之间的最短路径。\n\n*   **Floyd-Warshall 算法**：给定一个初始距离矩阵 `Dist`，其中 `Dist`$[i][j]$ 是节点 $i$ 和 $j$ 之间的直接距离（或成本）（如果不相连则为 `infinity`），该算法通过迭代地将每个节点 $k$ 视为任意两个节点 $i$ 和 $j$ 之间路径上的中间点来找到所有节点对之间的最短路径：\n    `for k from 1 to N: for i from 1 to N: for j from 1 to N: Dist[i][j] = min(Dist[i][j], Dist[i][k] + Dist[k][j])`\n\n*   **二值特征路径长度 ($L_B$)**：我们首先构建一个距离矩阵，其中 $B$ 中每条边的长度为 $1$。对于任意一对 $(i,j)$，如果 $b_{ij}=1$，则 $d_{ij}=1$，否则 $d_{ij}=\\infty$，并设 $d_{ii}=0$。运行 Floyd-Warshall 算法后，我们得到最短路径长度矩阵。$L_B$ 是不同节点对之间所有有限最短路径长度的平均值。如果任意一对节点之间不存在路径，则 $L_B$ 定义为 `NaN`。\n\n*   **加权特征路径长度 ($L_W$)**：在加权图 $W$ 中穿过一条边 $(i, j)$ 的成本定义为其权重的倒数，$c_{ij} = 1/w_{ij}$（对于 $w_{ij} > 0$）。初始距离矩阵用这些成本填充（如果 $w_{ij}>0$，则 $d_{ij} = c_{ij}$，否则为 $\\infty$，并设 $d_{ii}=0$）。运行 Floyd-Warshall 算法后，$L_W$ 是不同节点对之间所有最短路径长度的平均值。由于抽样的相关矩阵几乎肯定会产生一个全连接的加权图，所有节点对都将有有限的路径长度。\n\n**4. 最终差异计算**\n最后，对于每个测试用例，我们计算二值化图和加权图指标之间的差异，并将结果四舍五入到 $6$ 位小数：\n$$\n\\Delta C = \\bar{C}_B - \\bar{C}_W\n$$\n$$\n\\Delta L = L_B - L_W\n$$\n这些值根据指定的输出结构进行格式化和打印。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef _floyd_warshall(dist_matrix):\n    \"\"\"Computes all-pairs shortest paths using the Floyd-Warshall algorithm.\"\"\"\n    n = dist_matrix.shape[0]\n    sp_matrix = dist_matrix.copy()\n    for k in range(n):\n        for i in range(n):\n            for j in range(n):\n                if sp_matrix[i, k] + sp_matrix[k, j]  sp_matrix[i, j]:\n                    sp_matrix[i, j] = sp_matrix[i, k] + sp_matrix[k, j]\n    return sp_matrix\n\ndef calculate_global_clustering(adj_matrix, is_weighted):\n    \"\"\"\n    Computes the global clustering coefficient for a given adjacency matrix.\n    Handles both binary and weighted (Onnela) cases.\n    \"\"\"\n    n = adj_matrix.shape[0]\n    node_coeffs = []\n    \n    if is_weighted:\n        max_w = np.max(adj_matrix)\n        if max_w == 0:\n            return 0.0\n        w_hat = adj_matrix / max_w\n    \n    for i in range(n):\n        if is_weighted:\n            neighbors = np.where(adj_matrix[i] > 0)[0]\n        else:\n            neighbors = np.where(adj_matrix[i] == 1)[0]\n        \n        k_i = len(neighbors)\n        \n        if k_i  2:\n            node_coeffs.append(0.0)\n            continue\n            \n        num_possible_triangles = k_i * (k_i - 1) / 2.0\n        \n        if is_weighted:\n            triangle_sum = 0.0\n            for j_idx in range(k_i):\n                for k_idx in range(j_idx + 1, k_i):\n                    j, k = neighbors[j_idx], neighbors[k_idx]\n                    triangle_sum += (w_hat[i, j] * w_hat[i, k] * w_hat[j, k])**(1.0/3.0)\n            c_i = triangle_sum / num_possible_triangles if num_possible_triangles > 0 else 0.0\n        else:\n            num_actual_triangles = 0\n            for j_idx in range(k_i):\n                for k_idx in range(j_idx + 1, k_i):\n                    j, k = neighbors[j_idx], neighbors[k_idx]\n                    if adj_matrix[j, k] == 1:\n                        num_actual_triangles += 1\n            c_i = num_actual_triangles / num_possible_triangles if num_possible_triangles > 0 else 0.0\n        \n        node_coeffs.append(c_i)\n        \n    return np.mean(node_coeffs)\n\ndef calculate_char_path_length(adj_matrix, is_weighted):\n    \"\"\"\n    Computes the characteristic path length for a given adjacency matrix.\n    Handles both binary and weighted cases.\n    \"\"\"\n    n = adj_matrix.shape[0]\n    dist_matrix = np.full((n, n), np.inf)\n    \n    if is_weighted:\n        non_zero_edges = adj_matrix > 0\n        dist_matrix[non_zero_edges] = 1.0 / adj_matrix[non_zero_edges]\n    else:\n        edges = adj_matrix == 1\n        dist_matrix[edges] = 1.0\n        \n    np.fill_diagonal(dist_matrix, 0)\n    \n    sp_matrix = _floyd_warshall(dist_matrix)\n    \n    # Extract unique paths from the upper triangle\n    paths = sp_matrix[np.triu_indices(n, k=1)]\n    \n    if is_weighted:\n        # Weighted graph from correlation is almost always fully connected\n        return np.mean(paths)\n    else:\n        # For binary graph, only consider connected pairs\n        connected_paths = paths[np.isfinite(paths)]\n        if len(connected_paths) == 0:\n            return np.nan\n        else:\n            return np.mean(connected_paths)\n\ndef solve():\n    \"\"\"\n    Main function to run the test suite and compute results.\n    \"\"\"\n    test_cases = [\n        {\n            \"N\": 6, \"T\": 3000, \"tau\": 0.4, \"seed\": 123,\n            \"Sigma\": np.array([\n                [1, 0.8, 0.8, 0.2, 0.2, 0.2],\n                [0.8, 1, 0.8, 0.2, 0.2, 0.2],\n                [0.8, 0.8, 1, 0.2, 0.2, 0.2],\n                [0.2, 0.2, 0.2, 1, 0.5, 0.5],\n                [0.2, 0.2, 0.2, 0.5, 1, 0.5],\n                [0.2, 0.2, 0.2, 0.5, 0.5, 1]\n            ])\n        },\n        {\n            \"N\": 6, \"T\": 3000, \"tau\": 0.5, \"seed\": 456,\n            \"Sigma\": np.array([\n                [1, 0.6, 0.6, 0.6, 0.6, 0.6],\n                [0.6, 1, 0.6, 0.6, 0.6, 0.6],\n                [0.6, 0.6, 1, 0.6, 0.6, 0.6],\n                [0.6, 0.6, 0.6, 1, 0.6, 0.6],\n                [0.6, 0.6, 0.6, 0.6, 1, 0.6],\n                [0.6, 0.6, 0.6, 0.6, 0.6, 1]\n            ])\n        },\n        {\n            \"N\": 6, \"T\": 3000, \"tau\": 0.2, \"seed\": 789,\n            \"Sigma\": np.array([\n                [1, 0.7, 0.7, 0.7, 0.7, 0.7],\n                [0.7, 1, 0.05, 0.05, 0.05, 0.05],\n                [0.7, 0.05, 1, 0.05, 0.05, 0.05],\n                [0.7, 0.05, 0.05, 1, 0.05, 0.05],\n                [0.7, 0.05, 0.05, 0.05, 1, 0.05],\n                [0.7, 0.05, 0.05, 0.05, 0.05, 1]\n            ])\n        },\n        {\n            \"N\": 5, \"T\": 5000, \"tau\": 0.25, \"seed\": 101112,\n            \"Sigma\": np.array([\n                [1, 0.3, 0.05, 0.05, 0.3],\n                [0.3, 1, 0.3, 0.05, 0.05],\n                [0.05, 0.3, 1, 0.3, 0.05],\n                [0.05, 0.05, 0.3, 1, 0.3],\n                [0.3, 0.05, 0.05, 0.3, 1]\n            ])\n        }\n    ]\n\n    all_results = []\n    for case in test_cases:\n        N, T, Sigma, tau, seed = case[\"N\"], case[\"T\"], case[\"Sigma\"], case[\"tau\"], case[\"seed\"]\n\n        rng = np.random.default_rng(seed)\n        mean = np.zeros(N)\n        X = rng.multivariate_normal(mean, Sigma, size=T, check_valid='warn')\n\n        R = np.corrcoef(X, rowvar=False)\n        W = np.abs(R)\n        np.fill_diagonal(W, 0)\n        B = (W >= tau).astype(int)\n\n        C_B = calculate_global_clustering(B, is_weighted=False)\n        C_W = calculate_global_clustering(W, is_weighted=True)\n        L_B = calculate_char_path_length(B, is_weighted=False)\n        L_W = calculate_char_path_length(W, is_weighted=True)\n        \n        delta_C = C_B - C_W\n        delta_L = L_B - L_W\n        \n        all_results.append([delta_C, delta_L])\n\n    formatted_results = []\n    for dc, dl in all_results:\n        dc_str = f\"{dc:.6f}\"\n        dl_str = \"nan\" if np.isnan(dl) else f\"{dl:.6f}\"\n        formatted_results.append(f\"[{dc_str},{dl_str}]\")\n    \n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```"
        }
    ]
}