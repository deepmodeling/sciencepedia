## Introduction
How does the brain transform sensory input into meaningful thoughts and actions? Answering this question requires moving beyond simply identifying which brain regions are active, to understanding the informational content of that activity. Representational Similarity Analysis (RSA) provides a powerful framework for this deeper inquiry. Instead of focusing on activation levels, RSA characterizes a neural population by the geometric structure of its response patterns, offering a rich signature of how information is encoded and organized.

This article addresses the challenge of comparing these [complex representations](@entry_id:144331), not only within the brain but also across different individuals, species, and even between biological brains and artificial intelligence. It bridges the gap between raw neural data and abstract theoretical models by providing a common language: the language of geometry.

Across the following chapters, you will gain a comprehensive understanding of this versatile method. The "Principles and Mechanisms" chapter lays the foundation, explaining how to construct and compare Representational Dissimilarity Matrices (RDMs). The "Applications and Interdisciplinary Connections" chapter showcases how RSA is used to map the brain, test computational theories, and tackle fundamental questions in cognitive science and evolution. Finally, the "Hands-On Practices" section provides practical experience with the core computational steps of an RSA-based analysis.

## Principles and Mechanisms

Representational Similarity Analysis (RSA) offers a powerful framework for understanding how information is represented in the brain and in computational models. Moving beyond [simple activation](@entry_id:1131661)-based analyses, RSA characterizes the informational content of a neural population by the geometry of its responses to a set of experimental conditions. This chapter delves into the core principles and mechanisms of RSA, from the construction of its central [data structure](@entry_id:634264)—the Representational Dissimilarity Matrix (RDM)—to the statistical methods for comparing these structures and interpreting the results.

### The Representational Dissimilarity Matrix: A Geometric Fingerprint

The fundamental object of study in RSA is the **Representational Dissimilarity Matrix (RDM)**. For a set of $n$ experimental conditions, each eliciting a multivariate activity pattern $\mathbf{r}_i \in \mathbb{R}^p$ across $p$ measurement channels (e.g., voxels, neurons, or model units), the RDM is a symmetric $n \times n$ matrix, denoted by $D$. Each off-diagonal entry $D_{ij}$ quantifies the dissimilarity between the activity patterns for conditions $i$ and $j$.

Formally, the entries are defined as $D_{ij} = d(\mathbf{r}_i, \mathbf{r}_j)$, where $d$ is a chosen **[dissimilarity metric](@entry_id:913782)**. By definition, any valid [dissimilarity metric](@entry_id:913782) must be symmetric, so $d(\mathbf{r}_i, \mathbf{r}_j) = d(\mathbf{r}_j, \mathbf{r}_i)$, and the dissimilarity of a pattern with itself is zero, $d(\mathbf{r}_i, \mathbf{r}_i) = 0$. These properties dictate that the RDM $D$ is always symmetric ($D_{ij} = D_{ji}$) with a diagonal of zeros ($D_{ii} = 0$) . Consequently, all unique pairwise dissimilarities are contained in the upper (or lower) triangular part of the matrix, which comprises $\frac{n(n-1)}{2}$ unique values. This vector of unique dissimilarities is the core [data structure](@entry_id:634264) used for subsequent analysis .

The RDM encapsulates the **[representational geometry](@entry_id:1130876)**: the complete set of pairwise relationships between the neural representations of the experimental conditions. This geometry serves as a signature of the information processing in a given neural population, abstracting away from the high-dimensional measurement space itself. For example, if conditions A and B are represented more similarly to each other than to condition C, this will be reflected as a smaller dissimilarity value $D_{AB}$ compared to $D_{AC}$ and $D_{BC}$. This relational structure is the "what" of the representation, which can be compared across different brain regions, individuals, species, or between brains and computational models.

### Choosing a Dissimilarity Metric: Invariances and Hypotheses

The choice of the [dissimilarity metric](@entry_id:913782) $d(\mathbf{r}_i, \mathbf{r}_j)$ is a critical step that defines which properties of the activity patterns contribute to the [representational geometry](@entry_id:1130876). The choice is not merely technical; it is deeply intertwined with the scientific hypothesis about what aspects of the neural response are information-bearing . Different metrics have different **invariance properties**, meaning they are insensitive to certain transformations of the pattern vectors. A well-chosen metric should be sensitive to the features of the neural code that are thought to encode information, while being invariant to nuisance variability.

Let us consider the most common metrics and their invariance properties :

*   **Euclidean Distance**: $d_{\mathrm{E}}(\mathbf{r}_i, \mathbf{r}_j) = \lVert \mathbf{r}_i - \mathbf{r}_j \rVert_2$. This is the straight-line distance between two points in the $p$-dimensional space of activity patterns. It is invariant to translation (adding a constant vector to all patterns) and rotation of the entire pattern space. However, it is sensitive to the magnitude of the patterns; if all pattern vectors are uniformly scaled by a factor $a > 0$, the distances scale by $a$. Euclidean distance is appropriate when the absolute position of patterns in the state space is considered meaningful.

*   **Cosine Distance**: $d_{\mathrm{COS}}(\mathbf{r}_i, \mathbf{r}_j) = 1 - \frac{\mathbf{r}_i^\top \mathbf{r}_j}{\lVert \mathbf{r}_i \rVert_2 \lVert \mathbf{r}_j \rVert_2}$. This metric is derived from the cosine of the angle between two pattern vectors. It is invariant to rotation and, crucially, to any uniform positive scaling of the patterns ($ \mathbf{r} \mapsto a \mathbf{r}$ for $a > 0$). This makes it suitable for hypotheses where the information is contained in the "shape" or profile of the activity pattern across channels, rather than its overall magnitude or activation level.

*   **Correlation Distance**: $d_{\mathrm{COR}}(\mathbf{r}_i, \mathbf{r}_j) = 1 - \rho(\mathbf{r}_i, \mathbf{r}_j)$, where $\rho$ is the Pearson [correlation coefficient](@entry_id:147037). The Pearson correlation is equivalent to the [cosine similarity](@entry_id:634957) between mean-centered vectors. Correlation distance is therefore invariant to uniform scaling and to adding a constant offset to all channels within a pattern. This makes it a popular choice for fMRI data, where the arbitrary units of the BOLD signal and global fluctuations in activity can be treated as nuisances. It is ideal for testing **pattern-based coding** schemes, where the relative activity across channels is what matters . It's important to note that neither cosine nor [correlation distance](@entry_id:634939) is invariant to arbitrary rotations after mean-centering, as the centering operation itself is not rotation-invariant.

*   **Mahalanobis Distance**: $d_{\mathrm{M}}(\mathbf{r}_i, \mathbf{r}_j) = \sqrt{(\mathbf{r}_i - \mathbf{r}_j)^\top \Sigma^{-1} (\mathbf{r}_i - \mathbf{r}_j)}$. Here, $\Sigma$ is an estimate of the covariance of the noise across the $p$ measurement channels. This metric accounts for the fact that noise in neural data is often not isotropic (i.e., equal in all directions). By weighting dimensions according to their noise level and accounting for correlations between channels, the Mahalanobis distance effectively measures distance in a "whitened" space where the noise is isotropic and has unit variance. This provides a statistically optimal way to measure dissimilarity when the noise structure is known or can be estimated, rendering the geometry independent of the (potentially heterogeneous) units and noise levels of the original measurement channels .

The choice of metric defines the [equivalence class](@entry_id:140585) of representations being tested. For example, using Euclidean distance and comparing RDMs implies testing for equivalence of representations up to [rigid motion](@entry_id:155339) (rotation and translation). Using [correlation distance](@entry_id:634939) tests for a weaker equivalence, abstracting away from pattern magnitude. This principled abstraction is a hallmark of RSA .

### Constructing RDMs from Noisy Data: The Necessity of Cross-Validation

Neural data are invariably noisy. A fundamental challenge in constructing a neural RDM is to ensure that the estimated dissimilarities are not systematically biased by this noise. Consider the model for an observed activity pattern for condition $c$ in run $r$ as $\hat{\boldsymbol{\beta}}_{c,r} = \boldsymbol{\mu}_c + \boldsymbol{\epsilon}_{c,r}$, where $\boldsymbol{\mu}_c$ is the true underlying pattern and $\boldsymbol{\epsilon}_{c,r}$ is a zero-mean noise term.

If we compute a dissimilarity using estimates from the same data partition (e.g., within the same run), the noise contributes a positive bias. For squared Euclidean distance, the expected value of the measured dissimilarity is not the true dissimilarity, but is inflated by the variance of the noise :

$E[\|\hat{\boldsymbol{\beta}}_{i,r} - \hat{\boldsymbol{\beta}}_{j,r}\|^2] = \|\boldsymbol{\mu}_i - \boldsymbol{\mu}_j\|^2 + E[\|\boldsymbol{\epsilon}_{i,r} - \boldsymbol{\epsilon}_{j,r}\|^2]$

The second term, $E[\|\boldsymbol{\epsilon}_{i,r} - \boldsymbol{\epsilon}_{j,r}\|^2]$, is a positive bias term that artificially inflates dissimilarities, potentially distorting the representational geometry.

The solution is **[cross-validation](@entry_id:164650)**. To obtain an unbiased estimate of the dissimilarity between conditions $i$ and $j$, we must use pattern estimates derived from statistically independent data partitions. A standard approach is to partition the experimental runs into at least two [independent sets](@entry_id:270749) (or "folds"), for instance, odd-numbered runs versus even-numbered runs. Let's call the pattern estimates from these folds $\hat{\boldsymbol{\beta}}_{c,a}$ and $\hat{\boldsymbol{\beta}}_{c,b}$. An [unbiased estimator](@entry_id:166722) of the squared Euclidean distance is the dot product of the difference vectors from the independent folds:

$d^2_{CV}(i,j) = (\hat{\boldsymbol{\beta}}_{i,a} - \hat{\boldsymbol{\beta}}_{j,a})^\top (\hat{\boldsymbol{\beta}}_{i,b} - \hat{\boldsymbol{\beta}}_{j,b})$

Because the noise terms in fold $a$ and fold $b$ are independent, the expectation of their cross-product is zero. This removes the bias term, and the expected value of this cross-validated estimator is exactly the true squared distance, $E[d^2_{CV}(i,j)] = \|\boldsymbol{\mu}_i - \boldsymbol{\mu}_j\|^2$ . A similar cross-validated approach is used for [correlation distance](@entry_id:634939) and Mahalanobis distance (where it is often called the "crossnobis" estimator) .

It is imperative that the data folds remain truly independent. Any preprocessing step that pools information across folds before the dissimilarity calculation, such as using data from all runs to compute a normalization factor that is then applied to each run, can introduce **[data leakage](@entry_id:260649)**. This leakage can break the independence assumption and reintroduce bias, undermining the purpose of cross-validation .

### Comparing Geometries and Testing Hypotheses

The central act of RSA is the comparison of two or more RDMs. For example, a neural RDM from a brain region can be compared to a model RDM derived from a computational theory, a behavioral RDM from human judgments, or another neural RDM from a different brain area. The comparison quantifies the extent to which the representational geometries are similar.

#### Justifying Rank Correlation for Abstract Comparisons

The standard procedure for comparing two RDMs, $D^{(A)}$ and $D^{(B)}$, is to correlate their vectorized upper-triangular entries. A key insight is that we often lack a "ground truth" scale for dissimilarity. The transformation from a latent representational space to our measured dissimilarities might involve an unknown, nonlinear function. For example, the measured dissimilarity $D_X$ in a modality $X$ might be related to a "true" latent dissimilarity $d_X$ by an unknown, strictly increasing function $h_X$, such that $D_X = h_X(d_X)$ plus noise .

If we were to use a standard Pearson correlation, our result would be sensitive to the specific shapes of these unknown functions. The solution is to use a **rank-based correlation**, such as **Spearman's [rank correlation](@entry_id:175511) ($\rho$)** or Kendall's tau ($\tau$). A strictly increasing function, by definition, preserves the rank ordering of its inputs. Therefore, the rank ordering of the measured dissimilarities is the same as the rank ordering of the underlying latent dissimilarities (ignoring noise). By correlating the ranks of the RDMs, we test for a shared ordinal structure, making our comparison robust to any (unknown) monotonic nonlinearities in our measurement processes. This allows RSA to support claims about shared **abstract representational content**, independent of the particular measurement scale .

#### Statistical Inference with Non-Independent Data

After computing the correlation between two RDMs, we must assess its [statistical significance](@entry_id:147554). A major pitfall is to treat the $\frac{n(n-1)}{2}$ dissimilarity values as independent observations. They are not. Any dissimilarity $D_{ij}$ involving condition $i$ is statistically dependent on any other dissimilarity $D_{ik}$ also involving condition $i$, because they share a common source of [signal and noise](@entry_id:635372) ($\mathbf{r}_i$). This violation of independence invalidates standard parametric tests for the significance of a correlation .

The correct approach is a **non-parametric permutation test** that respects the dependency structure of the RDM. The null hypothesis is that there is no correspondence between the condition labels of the two RDMs. We can simulate this null hypothesis by repeatedly shuffling the labels of one RDM, recomputing the correlation, and building a null distribution of correlations. Specifically, we randomly permute the rows and columns of one RDM (e.g., $D^{(A)}$) while keeping the other ($D^{(B)}$) fixed. This breaks the link between the conditions while preserving the internal covariance structure within $D^{(A)}$ that arises from shared conditions. The [p-value](@entry_id:136498) is then the proportion of correlations from the null distribution that are as large as or larger than the empirically observed correlation .

### Interpreting Model Performance: The Noise Ceiling

Suppose we find that a model RDM has a Spearman correlation of $\rho=0.4$ with a neural RDM. Is this good? To contextualize this performance, we use the **[noise ceiling](@entry_id:1128751)**. The noise ceiling estimates the highest possible correlation any model can be expected to achieve, given the level of noise in the data. It is a property of the data, not of the model being tested .

The noise ceiling is estimated from the consistency of the data across multiple measurements (e.g., across human participants). It is typically presented as a range defined by a lower and an upper bound.

*   The **lower bound** is estimated using a leave-one-subject-out procedure. For each subject, their RDM is correlated with the average RDM of all *other* subjects. Because the noise in the left-out subject is independent of the noise in the average of the others, this correlation is slightly attenuated, yielding a conservative, lower-bound estimate.

*   The **upper bound** is estimated by correlating each subject's RDM with the average RDM of *all* subjects (including the subject themselves). Because the subject's own noise is present in both sides of the correlation, this estimate is slightly inflated by shared noise, yielding a liberal, upper-bound estimate.

The resulting range $[r^{\mathrm{lower}}, r^{\mathrm{upper}}]$ defines the zone of performance expected from a "perfect" model that could capture the true underlying [representational geometry](@entry_id:1130876). If a model's performance falls within or near this [noise ceiling](@entry_id:1128751), it is considered to be a good model, as it explains the reliable (i.e., consistent across subjects) variance in the data. Conversely, a low [noise ceiling](@entry_id:1128751) indicates that the data themselves are very noisy, setting a low bar for all possible models .

### RSA in Context: Contrasting with Other Frameworks

RSA offers a unique perspective on neural representations that complements other [multivariate analysis](@entry_id:168581) techniques. Understanding what information each framework preserves and discards clarifies their distinct scientific goals .

*   **Univariate Analysis**: This approach typically summarizes the activity for each condition into a single number, such as the average activation across a region of interest. In doing so, it discards the rich multivariate pattern of activity, preserving only information along a single, predefined dimension.

*   **Multivariate Decoding (MVPA)**: This framework trains a classifier to predict the experimental condition from the multivariate activity pattern. Its primary output is classification accuracy, a summary measure of whether the conditions are linearly (or non-linearly) separable. While powerful for demonstrating the presence of information, decoding discards the continuous geometric relationships between conditions. Two very different geometries could yield the same decoding accuracy.

*   **Representational Similarity Analysis (RSA)**: In contrast, RSA's primary focus is the [representational geometry](@entry_id:1130876) itself. It preserves the full set of pairwise relationships among condition patterns. Unlike decoding, it provides a rich, continuous characterization of how conditions relate to one another. Unlike a voxel-wise encoding model, which attempts to predict the activity of each individual channel, RSA abstracts away from the specific axes of the measurement space. This abstraction is powerful: by focusing on the invariant geometric structure, RSA allows for comparisons of representations across modalities where the measurement channels are fundamentally different (e.g., fMRI voxels and artificial neural network units) .

In summary, the principles and mechanisms of RSA provide a comprehensive framework for characterizing, comparing, and testing hypotheses about neural representations at an abstract, geometric level. By carefully selecting dissimilarity metrics, using cross-validation to combat noise, and applying appropriate rank-based statistical tests, researchers can gain deep insights into the structure of information processing in the brain.