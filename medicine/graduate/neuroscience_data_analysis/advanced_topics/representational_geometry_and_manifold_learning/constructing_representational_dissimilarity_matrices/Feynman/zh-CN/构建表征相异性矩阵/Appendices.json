{
    "hands_on_practices": [
        {
            "introduction": "构建表征相似性矩阵 (Representational Dissimilarity Matrix, RDM) 是表征相似性分析 (Representational Similarity Analysis, RSA) 的核心步骤。本练习将指导您从第一性原理出发，基于一组给定的刺激特征来构建一个模型 RDM，并探索特征加权如何改变所预测的表征几何 。这对于理解计算模型如何将理论假设转化为可检验的表征预测至关重要。",
            "id": "4148250",
            "problem": "给定有限维实向量空间中的一组刺激特征向量，以及一个逐特征缩放的规范。目标是构建一个模型表征非相似性矩阵 (RDM)，并量化特征缩放如何改变预测的表征几何。请基于向量空间和度量的基本定义进行操作，不要依赖任何预先推导的捷径。\n\n使用的基础理论：\n- 一个维度为 $p$ 的实向量空间配备了标准内积和诱导范数。对于任何向量 $v \\in \\mathbb{R}^p$，欧几里得范数满足范数公理，并定义为一个向量与其自身内积的平方根。集合上的度量 $d$ 是一个满足非负性、不可辨识者同一性、对称性和三角不等式的函数。在具有欧几里得范数的 $\\mathbb{R}^p$ 中，两点之间的度量定义为其差向量的范数。\n- 表征非相似性矩阵 (RDM) 是一个以刺激为索引的对称矩阵，其中每个非对角线元素是对应刺激对之间的非相似性，而当非相似性由基于范数的度量诱导时，根据不可辨识者同一性，对角线元素为零。\n\n任务：\n1. 给定 $n$ 个刺激及其特征向量 $x_i \\in \\mathbb{R}^p$（其中 $i \\in \\{1,\\dots,n\\}$），以及一个所有元素严格为正的特征缩放向量 $w \\in \\mathbb{R}^p$，通过以下步骤构建一个模型 RDM：\n   - 对每个刺激特征向量与 $w$ 进行逐分量相乘，以获得每个刺激的缩放后表征。\n   - 在缩放后的特征空间中，计算刺激之间的成对非相似性作为欧几里得度量，将每个非相似性放入一个 $n \\times n$ 矩阵的相应非对角线位置，并将对角线元素设置为 $0$。\n   - 以固定、一致的顺序（例如，对上三角部分采用行主序）将 RDM 的上三角部分（不包括对角线）向量化为一维数组。\n2. 对于每个测试用例，计算两个量来量化由缩放引起的、相对于未缩放基线 $w = \\mathbf{1}_p$ 的几何变化：\n   - 基线 RDM 和缩放后 RDM 的上三角向量化之间的皮尔逊相关系数。如果因为任一向量的方差为零（例如，所有元素相同）导致此相关系数未定义，则返回相关系数值 $0.0$。\n   - 相对弗罗贝尼乌斯变化，定义为缩放后 RDM 与基线 RDM 之差的弗罗贝尼乌斯范数除以基线 RDM 的弗罗贝尼乌斯范数。如果基线弗罗贝尼乌斯范数为 $0$，则返回相对变化值 $0.0$。\n3. 仅使用欧几里得范数和度量的定义来实现以上内容，确保 RDM 是对称、非负、对角线为零的，并且距离是根据第一性原理（向量相减后求欧几里得范数）计算的。\n\n测试套件：\n使用以下矩阵和缩放向量集。\n- 用例 $1$（理想路径，各向异性缩放）：$n = 5$, $p = 3$，刺激矩阵\n$$\nX^{(1)} = \\begin{bmatrix}\n0  1  2 \\\\\n1  0  3 \\\\\n2  2  1 \\\\\n3  1.5  0.5 \\\\\n0.5  3  2.5\n\\end{bmatrix},\n$$\n和缩放向量\n$$\nw^{(1)} = \\begin{bmatrix} 1 \\\\ 2 \\\\ 0.5 \\end{bmatrix}.\n$$\n- 用例 $2$（边界情况，均匀缩放）：重用 $X^{(1)}$ 并使用\n$$\nw^{(2)} = \\begin{bmatrix} 3 \\\\ 3 \\\\ 3 \\end{bmatrix}.\n$$\n- 用例 $3$（边缘情况，极端各向异性）：重用 $X^{(1)}$ 并使用\n$$\nw^{(3)} = \\begin{bmatrix} 0.1 \\\\ 10 \\\\ 0.1 \\end{bmatrix}.\n$$\n- 用例 $4$（退化基线，相同刺激）：$n = 3$, $p = 2$,\n$$\nX^{(4)} = \\begin{bmatrix}\n1  2 \\\\\n1  2 \\\\\n1  2\n\\end{bmatrix},\n\\quad\nw^{(4)} = \\begin{bmatrix} 5 \\\\ 7 \\end{bmatrix}.\n$$\n\n输出规范：\n- 对于每个用例 $k \\in \\{1,2,3,4\\}$，计算基线 RDM（$w = \\mathbf{1}_p$）和缩放后 RDM（$w = w^{(k)}$）之间的皮尔逊相关系数，以及如上定义的相对弗罗贝尼乌斯变化。返回有序对 $\\left[\\text{corr}^{(k)}, \\text{rel\\_change}^{(k)}\\right]$，形式为一个包含两个浮点数的列表。\n- 你的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表。列表中的每个元素对应一个测试用例，并且本身是一个包含两个元素的列表。例如，输出应如下所示\n$$\n[\\,[c_1,r_1],[c_2,r_2],[c_3,r_3],[c_4,r_4]\\,],\n$$\n其中每个 $c_k$ 和 $r_k$ 都是一个浮点数。",
            "solution": "该问题要求根据一组给定的刺激特征向量和一个逐特征缩放向量来构建表征非相似性矩阵 (RDM)。此外，问题还要求量化这种缩放相对于未缩放的基线表征所引起的几何变化。整个过程必须基于向量空间、范数和度量的基本定义。\n\n该解决方案分三个阶段展开：首先，定义特征向量的缩放；其次，使用欧几里得度量从这些缩放后的向量构建 RDM；第三，使用皮尔逊相关系数和相对弗罗贝尼乌斯范数将缩放后的 RDM 与基线 RDM进行比较。\n\n一个刺激被表示为 $p$ 维实向量空间 $\\mathbb{R}^p$ 中的一个向量 $x_i$。$n$ 个刺激的集合构成一个大小为 $n \\times p$ 的矩阵 $X$。特征缩放通过一个所有元素严格为正（$w_j > 0$）的向量 $w \\in \\mathbb{R}^p$ 来应用。缩放操作通过逐分量相乘，将每个刺激向量 $x_i = [x_{i,1}, x_{i,2}, \\dots, x_{i,p}]$ 转换为一个新的向量 $x'_i$：\n$$\nx'_i = [x_{i,1} w_1, x_{i,2} w_2, \\dots, x_{i,p} w_p]\n$$\n该操作等效于哈达玛（逐元素）积，$x'_i = x_i \\circ w$。此变换通过沿每个特征轴拉伸或压缩特征空间来改变其几何形状。\n\nRDM 是一个 $n \\times n$ 的对称矩阵，其元素量化了刺激对之间的非相似性。问题指定非相似性为缩放后特征空间中的欧几里得距离。根据基础定义，两个向量 $u, v \\in \\mathbb{R}^p$ 之间的欧几里得距离 $d(u,v)$ 是由欧几里得范数 $\\| \\cdot \\|$ 诱导的，使得 $d(u,v) = \\|u-v\\|$。范数本身由标准内积 $\\langle \\cdot, \\cdot \\rangle$ 定义为 $\\|z\\| = \\sqrt{\\langle z, z \\rangle}$。对于向量 $z = [z_1, \\dots, z_p]$，这变成：\n$$\n\\|z\\| = \\sqrt{\\sum_{k=1}^{p} z_k^2}\n$$\n因此，缩放后的刺激向量 $x'_i$ 和 $x'_j$ 之间的非相似性 $d_{ij}$ 为：\n$$\nd_{ij} = \\|x'_i - x'_j\\| = \\sqrt{\\sum_{k=1}^{p} (x'_{i,k} - x'_{j,k})^2}\n$$\nRDM，表示为 $R$，其构造方式是使其非对角线元素为这些成对非相似性，$R_{ij} = d_{ij}$（当 $i \\neq j$ 时）。根据度量的一个性质——不可辨识者同一性，一个点到其自身的距离为零，$d(x'_i, x'_i) = 0$。因此，RDM 的对角线元素全为零，$R_{ii} = 0$。对称性属性 $d(u,v) = d(v,u)$ 确保了 RDM 是对称的，$R_{ij} = R_{ji}$。\n\n为了比较，RDM 的上三角元素（不包括对角线）被向量化为一个一维数组。该向量以固定的行主序包含了所有 $\\frac{n(n-1)}{2}$ 个唯一的成对非相似性。\n\n为了量化缩放的效果，将使用给定缩放向量 $w$ 计算的 RDM ($RDM_{scaled}$) 与不进行显式缩放计算的基线 RDM ($RDM_{baseline}$) 进行比较。该基线对应于使用全为 1 的缩放向量，$w_{base} = \\mathbf{1}_p = [1, 1, \\dots, 1]^T$。此比较采用两种度量：\n\n1.  **皮尔逊相关系数**：这衡量了 $RDM_{scaled}$ 和 $RDM_{baseline}$ 的向量化上三角部分之间的线性关系。设向量化的非相似性为 $v_{scaled}$ 和 $v_{baseline}$。相关系数为：\n    $$\n    \\rho = \\frac{\\sum_{k=1}^{N} (v_{scaled,k} - \\bar{v}_{scaled})(v_{baseline,k} - \\bar{v}_{baseline})}{\\sqrt{\\sum_{k=1}^{N} (v_{scaled,k} - \\bar{v}_{scaled})^2} \\sqrt{\\sum_{k=1}^{N} (v_{baseline,k} - \\bar{v}_{baseline})^2}}\n    $$\n    其中 $N = \\frac{n(n-1)}{2}$。相关系数为 $1$ 意味着缩放对所有非相似性是均匀的（即，对于常数 $a>0, b$，$v_{scaled} = a \\cdot v_{baseline} + b$）。在距离的背景下，由于距离是非负的，这可以简化为 $v_{scaled} = a \\cdot v_{baseline}$。偏离 $1$ 表明表征几何发生了非线性重构。如果任一向量的方差为零（所有非相似性都相同），则相关系数未定义，并按规定报告为 $0.0$。\n\n2.  **相对弗罗贝尼乌斯变化**：这衡量了两个 RDM 矩阵之间差异的大小，并由基线 RDM 的大小进行归一化。一个 $n \\times n$ 矩阵 $A$ 的弗罗贝尼乌斯范数为 $\\|A\\|_F = \\sqrt{\\sum_{i=1}^n \\sum_{j=1}^n A_{ij}^2}$。相对变化为：\n    $$\n    \\text{rel\\_change} = \\frac{\\|RDM_{scaled} - RDM_{baseline}\\|_F}{\\|RDM_{baseline}\\|_F}\n    $$\n    该度量提供了非相似性值总体变化的归一化度量。如果基线 RDM 是一个零矩阵（即 $\\|RDM_{baseline}\\|_F = 0$），则相对变化报告为 $0.0$。\n\n实现过程首先是定义一个函数，用于从刺激矩阵和缩放向量计算 RDM 及其向量化，并严格遵守欧几里得距离的第一性原理计算。然后，对于每个测试用例，为指定的缩放向量和基线缩放向量分别调用此函数。最后，使用得到的两个 RDM 及其向量化来计算如上定义的相关系数和相对弗罗贝尼乌斯变化，包括处理指定的边缘情况。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef _compute_rdm_and_vectorization(X, w):\n    \"\"\"\n    Constructs an RDM and its upper-triangular vectorization from first principles.\n\n    Args:\n        X (np.ndarray): An n x p stimulus matrix.\n        w (np.ndarray): A p-dimensional feature scaling vector.\n\n    Returns:\n        tuple[np.ndarray, np.ndarray]: A tuple containing:\n            - The n x n RDM.\n            - The vectorized upper-triangular dissimilarities.\n    \"\"\"\n    n, p = X.shape\n    \n    # Scale the stimulus feature vectors component-wise\n    X_scaled = X * w  # Broadcasting w across rows of X\n    \n    rdm = np.zeros((n, n), dtype=np.float64)\n    \n    # Get indices for the upper triangle (excluding the diagonal)\n    # This provides a fixed, consistent row-major order for vectorization.\n    rows, cols = np.triu_indices(n, k=1)\n    \n    num_dissimilarities = len(rows)\n    vec = np.zeros(num_dissimilarities, dtype=np.float64)\n    \n    for k in range(num_dissimilarities):\n        i, j = rows[k], cols[k]\n        \n        # 1. Compute the difference vector\n        diff_vec = X_scaled[i, :] - X_scaled[j, :]\n        \n        # 2. Compute the Euclidean norm from first principles: sqrt(sum of squares)\n        dist = np.sqrt(np.sum(diff_vec**2))\n        \n        # Populate the RDM and the vector\n        rdm[i, j] = dist\n        rdm[j, i] = dist  # Ensure symmetry\n        vec[k] = dist\n        \n    return rdm, vec\n\ndef solve():\n    \"\"\"\n    Solves the problem for all test cases as specified.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    X1 = np.array([\n        [0, 1, 2],\n        [1, 0, 3],\n        [2, 2, 1],\n        [3, 1.5, 0.5],\n        [0.5, 3, 2.5]\n    ], dtype=np.float64)\n    w1 = np.array([1, 2, 0.5], dtype=np.float64)\n    w2 = np.array([3, 3, 3], dtype=np.float64)\n    w3 = np.array([0.1, 10, 0.1], dtype=np.float64)\n    \n    X4 = np.array([\n        [1, 2],\n        [1, 2],\n        [1, 2]\n    ], dtype=np.float64)\n    w4 = np.array([5, 7], dtype=np.float64)\n    \n    test_cases = [\n        (X1, w1),\n        (X1, w2),\n        (X1, w3),\n        (X4, w4),\n    ]\n\n    results = []\n    # Machine epsilon for floating point comparisons\n    epsilon = np.finfo(float).eps\n\n    for X, w in test_cases:\n        n, p = X.shape\n        w_base = np.ones(p, dtype=np.float64)\n        \n        # Compute baseline RDM and its vectorization (w = 1)\n        rdm_base, vec_base = _compute_rdm_and_vectorization(X, w_base)\n        \n        # Compute scaled RDM and its vectorization\n        rdm_scaled, vec_scaled = _compute_rdm_and_vectorization(X, w)\n        \n        # Task 2.1: Pearson Correlation\n        # Check for zero variance, as correlation is undefined in this case.\n        if np.std(vec_base)  epsilon or np.std(vec_scaled)  epsilon:\n            corr = 0.0\n        else:\n            # np.corrcoef returns a 2x2 matrix, we need the off-diagonal element\n            corr = np.corrcoef(vec_base, vec_scaled)[0, 1]\n            \n        # Task 2.2: Relative Frobenius Change\n        norm_base = np.linalg.norm(rdm_base, 'fro')\n        \n        if norm_base  epsilon:\n            rel_change = 0.0\n        else:\n            norm_diff = np.linalg.norm(rdm_scaled - rdm_base, 'fro')\n            rel_change = norm_diff / norm_base\n            \n        results.append([corr, rel_change])\n\n    # Final print statement in the exact required format.\n    # The format [,[c,r],[c,r],] is achieved by this construction.\n    result_strings = [f\"[{c},{r}]\" for c, r in results]\n    print(f\"[{','.join(result_strings)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "在构建 RDM 时，选择合适的相异性度量是一个关键决策，因为不同的选择似乎为数据提供了不同的视角。本练习通过理论推导，揭示了两种最常用的度量——标准化数据上的平方欧几里得距离和相关性距离——在特定条件下实则为线性等价。理解这种等价性  不仅能帮助我们解读和比较使用不同方法学的研究结果，也阐明了数据预处理对表征几何的深远影响。",
            "id": "4148140",
            "problem": "一个实验室正在根据功能性磁共振成像 (fMRI) 的响应模式构建表征非相似性矩阵 (RDM)。对于两个刺激，设其响应模式为向量 $\\mathbf{x}, \\mathbf{y} \\in \\mathbb{R}^{n}$，其中 $n$ 是测量特征（例如，体素）的数量。每个模式都通过减去其样本均值并除以其样本标准差（以 $n-1$ 为分母计算）在特征上进行独立标准化，从而得到 $\\mathbf{z}_{\\mathbf{x}}$ 和 $\\mathbf{z}_{\\mathbf{y}}$。研究团队考虑了两种非相似性度量：\n- 标准化模式之间的平方欧几里得距离，定义为 $d_{\\mathrm{E}}^{2}(\\mathbf{z}_{\\mathbf{x}}, \\mathbf{z}_{\\mathbf{y}}) = \\|\\mathbf{z}_{\\mathbf{x}} - \\mathbf{z}_{\\mathbf{y}}\\|_{2}^{2}$；\n- 原始模式之间的相关距离，定义为 $d_{\\mathrm{corr}}(\\mathbf{x}, \\mathbf{y}) = 1 - r(\\mathbf{x}, \\mathbf{y})$，其中 $r(\\mathbf{x}, \\mathbf{y})$ 是跨特征的皮尔逊相关系数。\n\n从欧几里得距离、样本均值和样本方差以及皮尔逊相关的基本定义出发，推导出精确的恒定缩放因子 $c(n)$，使得在适当的预处理和定义条件下，有 $d_{\\mathrm{E}}^{2}(\\mathbf{z}_{\\mathbf{x}}, \\mathbf{z}_{\\mathbf{y}}) = c(n)\\, d_{\\mathrm{corr}}(\\mathbf{x}, \\mathbf{y})$。清晰地陈述为使此等式有效，$\\mathbf{z}_{\\mathbf{x}}$、$\\mathbf{z}_{\\mathbf{y}}$ 和 $r(\\mathbf{x}, \\mathbf{y})$ 必须满足的充分必要条件。然后，解释这种线性等价关系对于“在标准化模式上使用平方欧几里得距离”与“在原始模式上使用相关距离”所构建的 RDM 之间的可比性有何影响，包括基于秩的 RDM 比较和线性 RDM 比较会受到怎样的影响。\n\n将常数 $c(n)$ 以仅依赖于 $n$ 的封闭形式解析表达式报告。不需要数值近似。",
            "solution": "该问题要求推导一个恒定的缩放因子，该因子关联了在构建表征非相似性矩阵 (RDM) 中使用的两种常用非相似性度量：标准化响应模式之间的平方欧几里得距离和原始模式之间的相关距离。\n\n设 $\\mathbf{x} = (x_1, x_2, \\ldots, x_n)^T$ 和 $\\mathbf{y} = (y_1, y_2, \\ldots, y_n)^T$ 是 $\\mathbb{R}^{n}$ 中的两个响应模式向量。\n\n首先，我们定义标准化过程。对于向量 $\\mathbf{x}$，样本均值为 $\\bar{x} = \\frac{1}{n} \\sum_{i=1}^{n} x_i$。使用指定分母 $n-1$ 的样本方差为 $s_x^2 = \\frac{1}{n-1} \\sum_{i=1}^{n} (x_i - \\bar{x})^2$。相应的样本标准差为 $s_x = \\sqrt{s_x^2}$。标准化向量 $\\mathbf{z}_{\\mathbf{x}}$ 的一个分量 $z_{x,i}$ 由 $z_{x,i} = \\frac{x_i - \\bar{x}}{s_x}$ 给出。此过程要求样本方差为非零，即 $s_x^2  0$。\n\n标准化向量 $\\mathbf{z}_{\\mathbf{x}}$ 和 $\\mathbf{z}_{\\mathbf{y}}$ 具有对推导至关重要的特定属性。标准化向量各分量的均值为零：\n$$\n\\bar{z}_x = \\frac{1}{n} \\sum_{i=1}^{n} z_{x,i} = \\frac{1}{n} \\sum_{i=1}^{n} \\frac{x_i - \\bar{x}}{s_x} = \\frac{1}{n s_x} \\left( \\sum_{i=1}^{n} x_i - \\sum_{i=1}^{n} \\bar{x} \\right) = \\frac{1}{n s_x} (n\\bar{x} - n\\bar{x}) = 0\n$$\n标准化向量各分量的平方和为：\n$$\n\\sum_{i=1}^{n} z_{x,i}^2 = \\sum_{i=1}^{n} \\left( \\frac{x_i - \\bar{x}}{s_x} \\right)^2 = \\frac{1}{s_x^2} \\sum_{i=1}^{n} (x_i - \\bar{x})^2\n$$\n根据定义，$s_x^2 = \\frac{1}{n-1} \\sum_{i=1}^{n} (x_i - \\bar{x})^2$，这意味着 $\\sum_{i=1}^{n} (x_i - \\bar{x})^2 = (n-1)s_x^2$。将此代入前面的表达式中得到：\n$$\n\\sum_{i=1}^{n} z_{x,i}^2 = \\frac{1}{s_x^2} ((n-1)s_x^2) = n-1\n$$\n这个和也是标准化向量的平方欧几里得范数，即 $\\|\\mathbf{z}_{\\mathbf{x}}\\|_{2}^{2} = n-1$。\n\n现在，我们分析第一种非相似性度量，即标准化模式之间的平方欧几里得距离 $d_{\\mathrm{E}}^{2}(\\mathbf{z}_{\\mathbf{x}}, \\mathbf{z}_{\\mathbf{y}})$：\n$$\nd_{\\mathrm{E}}^{2}(\\mathbf{z}_{\\mathbf{x}}, \\mathbf{z}_{\\mathbf{y}}) = \\|\\mathbf{z}_{\\mathbf{x}} - \\mathbf{z}_{\\mathbf{y}}\\|_{2}^{2} = \\sum_{i=1}^{n} (z_{x,i} - z_{y,i})^2\n$$\n展开平方，我们得到：\n$$\nd_{\\mathrm{E}}^{2}(\\mathbf{z}_{\\mathbf{x}}, \\mathbf{z}_{\\mathbf{y}}) = \\sum_{i=1}^{n} (z_{x,i}^2 - 2z_{x,i}z_{y,i} + z_{y,i}^2) = \\sum_{i=1}^{n} z_{x,i}^2 + \\sum_{i=1}^{n} z_{y,i}^2 - 2 \\sum_{i=1}^{n} z_{x,i}z_{y,i}\n$$\n使用属性 $\\|\\mathbf{z}_{\\mathbf{x}}\\|_{2}^{2} = \\sum z_{x,i}^2 = n-1$ 以及同样地 $\\|\\mathbf{z}_{\\mathbf{y}}\\|_{2}^{2} = \\sum z_{y,i}^2 = n-1$，该表达式变为：\n$$\nd_{\\mathrm{E}}^{2}(\\mathbf{z}_{\\mathbf{x}}, \\mathbf{z}_{\\mathbf{y}}) = (n-1) + (n-1) - 2 \\sum_{i=1}^{n} z_{x,i}z_{y,i} = 2(n-1) - 2 \\mathbf{z}_{\\mathbf{x}} \\cdot \\mathbf{z}_{\\mathbf{y}}\n$$\n接下来，我们将标准化向量的点积 $\\mathbf{z}_{\\mathbf{x}} \\cdot \\mathbf{z}_{\\mathbf{y}}$ 与原始向量之间的皮尔逊相关系数 $r(\\mathbf{x}, \\mathbf{y})$ 联系起来。皮尔逊相关定义为两个向量的协方差除以它们标准差的乘积：\n$$\nr(\\mathbf{x}, \\mathbf{y}) = \\frac{\\text{cov}(\\mathbf{x}, \\mathbf{y})}{s_x s_y} = \\frac{\\frac{1}{n-1}\\sum_{i=1}^{n} (x_i - \\bar{x})(y_i - \\bar{y})}{s_x s_y}\n$$\n标准化向量的点积为：\n$$\n\\mathbf{z}_{\\mathbf{x}} \\cdot \\mathbf{z}_{\\mathbf{y}} = \\sum_{i=1}^{n} z_{x,i}z_{y,i} = \\sum_{i=1}^{n} \\left(\\frac{x_i - \\bar{x}}{s_x}\\right) \\left(\\frac{y_i - \\bar{y}}{s_y}\\right) = \\frac{1}{s_x s_y} \\sum_{i=1}^{n} (x_i - \\bar{x})(y_i - \\bar{y})\n$$\n将其与 $r(\\mathbf{x}, \\mathbf{y})$ 的定义进行比较，我们发现以下关系：\n$$\n\\mathbf{z}_{\\mathbf{x}} \\cdot \\mathbf{z}_{\\mathbf{y}} = (n-1) r(\\mathbf{x}, \\mathbf{y})\n$$\n现在，我们将此结果代回平方欧几里得距离的表达式中：\n$$\nd_{\\mathrm{E}}^{2}(\\mathbf{z}_{\\mathbf{x}}, \\mathbf{z}_{\\mathbf{y}}) = 2(n-1) - 2 ((n-1) r(\\mathbf{x}, \\mathbf{y})) = 2(n-1) (1 - r(\\mathbf{x}, \\mathbf{y}))\n$$\n第二种非相似性度量是相关距离，定义为 $d_{\\mathrm{corr}}(\\mathbf{x}, \\mathbf{y}) = 1 - r(\\mathbf{x}, \\mathbf{y})$。通过代入，我们得到最终的等式：\n$$\nd_{\\mathrm{E}}^{2}(\\mathbf{z}_{\\mathbf{x}}, \\mathbf{z}_{\\mathbf{y}}) = 2(n-1) d_{\\mathrm{corr}}(\\mathbf{x}, \\mathbf{y})\n$$\n从这个方程中，我们可以确定恒定的缩放因子 $c(n)$ 为：\n$$\nc(n) = 2(n-1)\n$$\n此等式有效的充分必要条件已在推导中隐含：\n1. 向量 $\\mathbf{x}$ 和 $\\mathbf{y}$ 必须具有非零的样本方差。如果任一向量的方差为零，其标准差也为零，这将导致标准化过程和皮尔逊相关系数因除以零而未定义。\n2. 产生 $\\mathbf{z}_{\\mathbf{x}}$ 和 $\\mathbf{z}_{\\mathbf{y}}$ 的标准化过程必须通过减去样本均值并除以以 $n-1$ 为分母计算的样本标准差来执行。这确保了 $\\|\\mathbf{z}_{\\mathbf{x}}\\|_{2}^{2} = \\|\\mathbf{z}_{\\mathbf{y}}\\|_{2}^{2} = n-1$。使用不同的分母（例如 $n$）会改变缩放因子。\n\n这种线性等价关系对于表征相似性分析领域具有重要意义：\n关系式 $d_{\\mathrm{E}}^{2} = c(n) d_{\\mathrm{corr}}$ 是一个完美的线性变换，其缩放因子为正值 $c(n) = 2(n-1)$ 且截距为零。这意味着在标准化数据上使用平方欧几里得距离计算的 RDM 是在原始数据上使用相关距离计算的 RDM 的一个缩放版本。\n对于任意两对刺激 $(i, j)$ 和 $(k, l)$，它们非相似性的顺序得以保留。也就是说，$d_{\\mathrm{corr}}(\\mathbf{x}_i, \\mathbf{x}_j)  d_{\\mathrm{corr}}(\\mathbf{x}_k, \\mathbf{x}_l)$ 当且仅当 $d_{\\mathrm{E}}^{2}(\\mathbf{z}_{\\mathbf{x}_i}, \\mathbf{z}_{\\mathbf{x}_j})  d_{\\mathrm{E}}^{2}(\\mathbf{z}_{\\mathbf{x}_k}, \\mathbf{z}_{\\mathbf{x}_l})$。\n因此，这两种 RDM 之间的基于秩的比较，例如对其向量化的上三角部分使用斯皮尔曼等级相关 (Spearman's rank correlation)，将产生 $\\rho = 1$ 的完美相关性。这两个矩阵是秩等价的。\n此外，由于该变换是截距为零的完美线性变换，线性比较（例如使用皮尔逊相关）也将产生 $r = 1$ 的完美相关性。\n这种数学上的等价性表明，只要使用了指定的预处理和定义，在这两种非相似性度量流程之间进行选择在形式上是无关紧要的。所产生的 RDM 包含相同的表征几何结构，仅相差一个全局缩放因子。这使得可以直接比较和整合那些可能使用了这两种看似不同方法构建 RDM 的研究结果。它将两种常见的实践统一在了一个单一的数学框架之下。",
            "answer": "$$\n\\boxed{2(n-1)}\n$$"
        },
        {
            "introduction": "将模型 RDM 与从神经数据中得到的 RDM 相关联，可以量化模型对神经活动的解释程度，但我们如何确定这种相关性在统计上是显著的，而非偶然产生的？本练习将介绍置换检验 (permutation test)，这是一种在 RSA 中进行统计推断的强大非参数方法。您将学习通过置换条件标签来生成一个零分布，从而评估观测到的模型与大脑 RDM 相关性的显著性 ，这是进行严谨假设检验和得出可靠科学结论的关键一步。",
            "id": "4148208",
            "problem": "您的任务是使用表征相异性矩阵（Representational Dissimilarity Matrices, RDM）来评估计算模型的刺激关系假设是否与神经表征几何相符。表征相异性矩阵（RDM）定义为特定条件下表征之间成对相异性的矩阵。形式上，对于具有表征 $\\{\\mathbf{x}_1,\\dots,\\mathbf{x}_n\\}$ 的 $n$ 个条件，RDM $D \\in \\mathbb{R}^{n \\times n}$ 的元素为 $D_{ij} = \\delta(\\mathbf{x}_i,\\mathbf{x}_j)$，其中 $\\delta$ 是一个相异性函数。在本问题中，使用欧几里得距离，即 $\\delta(\\mathbf{x}_i,\\mathbf{x}_j) = \\|\\mathbf{x}_i - \\mathbf{x}_j\\|_2$。\n\n为量化模型RDM与大脑RDM之间的关联，请使用斯皮尔曼等级相关（Spearman’s rank correlation）：计算模型和大脑RDM的秩变换后的上三角元素（不包括对角线）之间的相关性。令 $v^{\\text{model}} \\in \\mathbb{R}^{m}$ 和 $v^{\\text{brain}} \\in \\mathbb{R}^{m}$ 分别表示通过读取模型和大脑RDM的 $m = \\frac{n(n-1)}{2}$ 个上三角元素得到的向量。检验统计量是 $v^{\\text{model}}$ 和 $v^{\\text{brain}}$ 之间的斯皮尔曼相关性。\n\n通过基于重排条件标签的置换检验来评估统计显著性。零假设应明确阐述为：$H_0$：条件标签到大脑测量的分配相对于模型是可交换的，这意味着模型RDM和大脑RDM之间的任何对齐都源于偶然，并且检验统计量的分布在条件标签的置换下是不变的。在 $H_0$ 下，置换标签会为斯皮尔曼相关性导出一个零分布。使用双边检验，比较 $|r_{\\text{perm}}|$ 与 $|r_{\\text{obs}}|$，其中 $r_{\\text{obs}}$ 是观测到的相关性，$r_{\\text{perm}}$ 是在置换下计算出的相关性。\n\n您的程序必须：\n- 为每个测试用例（见测试套件）使用欧几里得距离构建模型和大脑RDM。\n- 计算 $v^{\\text{model}}$ 和 $v^{\\text{brain}}$ 之间的观测斯皮尔曼相关性 $r_{\\text{obs}}$。\n- 通过同时置换大脑RDM的行和列，对 $n$ 个条件标签执行 $B$ 次随机置换（等效地，应用置换 $\\pi$ 对索引重新排序，并取置换后的大脑RDM的上三角元素）。对于每次置换，计算 $r_{\\text{perm}}$。\n- 按如下方式计算双边置换 $p$ 值：$\\displaystyle p = \\frac{1 + \\sum_{b=1}^B \\mathbf{1}\\left(|r_{\\text{perm},b}| \\ge |r_{\\text{obs}}|\\right)}{B+1}$，其中 $\\mathbf{1}(\\cdot)$ 是指示函数。这种连续性校正确保了即使在没有置换统计量超过观测统计量的情况下，也能得到一个有效的 $p$ 值。\n- 生成一行输出，其中包含所有测试用例的 $p$ 值，格式为方括号内以逗号分隔的列表，例如 $[p_1,p_2,p_3,p_4]$。\n\n测试套件（每个用例指定模型特征、如何生成大脑模式以及置换次数 $B$；所有随机元素都使用指定的种子以确保可复现性）：\n\n- 用例1（对齐的模型和大脑；聚类结构）：\n  - 条件：$n = 8$，体素：$v = 50$，模型特征维度：$d = 2$。\n  - 模型特征 $M \\in \\mathbb{R}^{8 \\times 2}$（行为条件）：\n    - 聚类 $\\mathcal{A}$：$(0.0, 0.0)$, $(0.0, 0.5)$, $(0.5, 0.0)$, $(0.5, 0.5)$。\n    - 聚类 $\\mathcal{B}$：$(3.0, 3.0)$, $(3.0, 3.5)$, $(3.5, 3.0)$, $(3.5, 3.5)$。\n  - 大脑模式 $X \\in \\mathbb{R}^{8 \\times 50}$ 通过线性映射加噪声生成：\n    - 权重矩阵 $W \\in \\mathbb{R}^{2 \\times 50}$ 从标准正态分布中采样，种子为 $42$。\n    - 使用种子 $24$ 添加标准差为 $\\sigma = 0.3$ 的独立高斯噪声。\n    - 构建方式：$X = M W + \\text{noise}$。\n  - 置换次数：$B = 2000$，置换种子 $1001$。\n\n- 用例2（零假设用例；独立的大脑模式）：\n  - 条件：$n = 8$，体素：$v = 50$，模型与用例1相同（相同的 $M$）。\n  - 大脑模式 $X \\in \\mathbb{R}^{8 \\times 50}$ 从标准正态分布中独立采样，种子为 $99$（即与 $M$ 无关）。\n  - 置换次数：$B = 2000$，置换种子 $2002$。\n\n- 用例3（边界用例；最小条件数）：\n  - 条件：$n = 3$，体素：$v = 30$，模型特征维度：$d = 1$。\n  - 模型特征 $M = \\begin{bmatrix}0\\\\1\\\\2\\end{bmatrix}$。\n  - 大脑模式 $X \\in \\mathbb{R}^{3 \\times 30}$：\n    - 权重向量 $W \\in \\mathbb{R}^{1 \\times 30}$ 从标准正态分布中采样，种子为 $7$。\n    - 使用种子 $31$ 添加标准差为 $\\sigma = 0.05$ 的独立高斯噪声。\n    - 构建方式：$X = M W + \\text{noise}$。\n  - 置换次数：$B = 1000$，置换种子 $3003$。\n\n- 用例4（模型RDM中的相等距离；类别结构）：\n  - 条件：$n = 6$，体素：$v = 40$，模型特征维度：$d = 1$。\n  - 模型特征 $M = \\begin{bmatrix}0\\\\0\\\\0\\\\1\\\\1\\\\1\\end{bmatrix}$（两个类别）。\n  - 大脑模式 $X \\in \\mathbb{R}^{6 \\times 40}$：\n    - 权重向量 $W \\in \\mathbb{R}^{1 \\times 40}$ 从标准正态分布中采样，种子为 $123$。\n    - 使用种子 $321$ 添加标准差为 $\\sigma = 0.1$ 的独立高斯噪声。\n    - 构建方式：$X = M W + \\text{noise}$。\n  - 置换次数：$B = 2000$，置换种子 $4004$。\n\n您的程序必须实现上述内容，并以 $[p_1,p_2,p_3,p_4]$ 的格式生成单行最终输出，其中 $p_i$ 分别是针对用例1、2、3和4的双边置换 $p$ 值（浮点数）。不应打印任何额外文本。",
            "solution": "该问题是有效的。它在计算神经科学领域，特别是表征相似性分析（RSA）的框架内，提出了一个清晰、有科学依据且定义明确的任务。所有给定的信息，包括数学定义、算法步骤以及测试用例的数值参数，都是完整且无矛盾的。任务是实现一个标准的统计分析流程，这是一个可形式化且可验证的问题。\n\n解决方案将基于RSA、假设检验和计算统计学的原理来开发。\n\n**1. 表征相似性分析（RSA）的基本原理**\n\nRSA的核心目标是通过对单个神经元或体素的具体活动模式进行抽象，来刻画神经反应群体中所表征的信息。这是通过计算表征相异性矩阵（RDM）来实现的，这是一个方形对称矩阵，总结了大脑对一组实验条件的反应之间的成对相异性。\n\n对于 $n$ 个条件，一个RDM表示为 $D \\in \\mathbb{R}^{n \\times n}$，其元素 $D_{ij} = \\delta(\\mathbf{x}_i, \\mathbf{x}_j)$，其中 $\\mathbf{x}_i$ 和 $\\mathbf{x}_j$ 分别是条件 $i$ 和 $j$ 的神经反应模式，$\\delta$ 是一个选定的相异性度量。本问题指定使用欧几里得距离 $\\delta(\\mathbf{x}_i, \\mathbf{x}_j) = \\|\\mathbf{x}_i - \\mathbf{x}_j\\|_2$，这是一个常见且直观的选择，它测量了高维神经激活空间中反应向量之间的距离。对角线元素 $D_{ii}$ 恒为 $0$，因为一个模式与自身的相异性为零。\n\n**2. 比较表征几何**\n\nRSA通过比较不同表征空间（例如，计算模型和大脑数据）各自的RDM来评估它们之间的一致性。为了进行这种比较，我们首先将每个RDM的上三角部分线性化为一个向量。对于一个 $n \\times n$ 的RDM，该向量包含 $m = \\frac{n(n-1)}{2}$ 个唯一的成对相异性值。设这些向量为 $v^{\\text{model}}$ 和 $v^{\\text{brain}}$。\n\n本问题要求使用斯皮尔曼等级相关 $\\rho(v^{\\text{model}}, v^{\\text{brain}})$。这个非参数统计量测量了秩变换后的相异性值之间单调关系的强度和方向。使用它的优点在于它对异常值具有稳健性，并且不假设模型和大脑的相异性之间存在线性关系，这使其成为比较可能在尺度上不同但具有相似相异性等级排序的表征几何的灵活工具。\n\n**3. 通过置换检验进行统计推断**\n\n为了确定观测到的相关性 $r_{\\text{obs}}$ 是否具有统计显著性，我们必须将其与一个零分布进行比较。本问题指定了置换检验，这是一种用于假设检验的强大的非参数方法。\n\n零假设 $H_0$ 假定模型的表征结构与大脑的表征结构之间没有系统性关系。在 $H_0$ 下，大脑数据上的条件标签是可交换的；任何观测到的相关性都纯粹是由于偶然。\n\n置换检验通过重复重排大脑数据的条件标签来模拟这一零假设。在算法上，这是通过对大脑RDM $D_{\\text{brain}}$ 的索引 $\\{0, 1, \\dots, n-1\\}$ 应用一个随机置换 $\\pi$ 来实现的。置换后的RDM $D'_{\\text{brain}}$ 的元素为 $(D'_{\\text{brain}})_{ij} = (D_{\\text{brain}})_{\\pi(i)\\pi(j)}$。对于 $B$ 次这样的置换中的每一次，我们从置换后的RDM中提取上三角向量，并计算一个“零”斯皮尔曼相关性 $r_{\\text{perm},b}$（其中 $b \\in \\{1, \\dots, B\\}$）。\n\n**4. 双边p值的计算**\n\n零相关性的集合 $\\{r_{\\text{perm},b}\\}_{b=1}^B$ 构成了一个经验零分布。本问题要求进行双边检验，该检验评估观测到的相关性是否显著不为零，而不论其符号（正或负）。这是通过将观测相关性的绝对值 $|r_{\\text{obs}}|$ 与零相关性的绝对值 $|r_{\\text{perm},b}|$ 进行比较来完成的。\n\n$p$ 值计算为产生至少与观测值一样极端的相关性的置换比例。指定的公式为：\n$$p = \\frac{1 + \\sum_{b=1}^B \\mathbf{1}\\left(|r_{\\text{perm},b}| \\ge |r_{\\text{obs}}|\\right)}{B+1}$$\n这里，$\\mathbf{1}(\\cdot)$ 是指示函数，如果其参数为真则为 $1$，否则为 $0$。分子中的“$+1$”和分母中的“$B+1$”代表了连续性校正。这将观测到的统计量本身视为来自零分布的一个样本，确保 $p$ 值界于 $\\frac{1}{B+1}$ 和 $1$ 之间，并且即使在没有置换统计量比观测统计量更极端的情况下也是有效的。\n\n**5. 算法实现**\n\n实现将通过系统地处理每个测试用例来进行，如下所示：\n\n1.  **数据生成**：对于每个用例，我们生成模型特征矩阵 $M$ 和大脑数据矩阵 $X$。对于用例1、3和4，大脑数据 $X$ 构建为 $X = M W + \\text{noise}$，其中权重矩阵 $W$ 和噪声项均使用指定的随机种子从正态分布生成，以保证可复现性。对于用例2， $X$ 独立于 $M$ 生成，同样使用指定的种子。\n\n2.  **RDM构建**：一个函数将使用欧几里得距离从输入的 $n \\times d$ 数据矩阵计算出 $n \\times n$ 的RDM。然后该函数将提取 $m = \\frac{n(n-1)}{2}$ 个上三角元素到一个向量中。\n\n3.  **观测相关性**：计算模型RDM向量 $v^{\\text{model}}$ 和大脑RDM向量 $v^{\\text{brain}}$。然后根据这两个向量计算观测到的斯皮尔曼相关性 $r_{\\text{obs}}$。\n\n4.  **置换循环**：\n    a. 使用用例指定的置换种子来初始化一个随机数生成器。\n    b. 一个循环运行 $B$ 次迭代。在每次迭代中，生成一个 $n$ 个条件索引的随机置换。\n    c. 将此置换应用于大脑RDM $D_{\\text{brain}}$ 的行和列，以创建一个置换后的RDM $D'_{\\text{brain}}$。\n    d. 提取 $D'_{\\text{brain}}$ 的上三角向量，并计算其与原始（固定的）$v^{\\text{model}}$ 的斯皮尔曼相关性，从而得到一个 $r_{\\text{perm}}$。\n\n5.  **p值计算**：循环结束后，计算 $|r_{\\text{perm}}| \\ge |r_{\\text{obs}}|$ 的置换次数。此计数加 $1$ 后除以 $B+1$，得到该测试用例的最终双边 $p$ 值。\n\n此过程将对所有4个指定的测试用例重复进行，并将得到的 $p$ 值收集并格式化为所需的输出。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.spatial.distance import pdist, squareform\nfrom scipy.stats import spearmanr\n\ndef solve():\n    \"\"\"\n    Main function to run all test cases for Representational Similarity Analysis.\n    \"\"\"\n\n    def compute_rdm_and_vector(data_matrix):\n        \"\"\"\n        Computes the RDM using Euclidean distance and returns the upper-triangular vector.\n        \n        Args:\n            data_matrix (np.ndarray): An (n_conditions x n_features) matrix.\n        \n        Returns:\n            tuple: A tuple containing:\n                - rdm (np.ndarray): The n_conditions x n_conditions RDM.\n                - rdm_vec (np.ndarray): The flattened upper-triangular vector of the RDM.\n        \"\"\"\n        if data_matrix.shape[0]  2:\n            return np.array([[]]), np.array([])\n            \n        distances = pdist(data_matrix, metric='euclidean')\n        rdm = squareform(distances)\n        \n        n_conditions = data_matrix.shape[0]\n        # Get indices for the upper triangle, excluding the diagonal (k=1)\n        triu_indices = np.triu_indices(n_conditions, k=1)\n        rdm_vec = rdm[triu_indices]\n        \n        return rdm, rdm_vec\n\n    def run_rsa_permutation_test(model_features, brain_patterns, n_permutations, perm_seed):\n        \"\"\"\n        Performs the full RSA permutation test for a given model and brain data.\n\n        Args:\n            model_features (np.ndarray): The model's feature matrix (n_conditions x d_model).\n            brain_patterns (np.ndarray): The brain data matrix (n_conditions x n_voxels).\n            n_permutations (int): The number of permutations (B).\n            perm_seed (int): The seed for the permutation random number generator.\n\n        Returns:\n            float: The two-sided permutation p-value.\n        \"\"\"\n        n_conditions = model_features.shape[0]\n        \n        # 1. Compute RDMs and upper-triangular vectors\n        model_rdm, v_model = compute_rdm_and_vector(model_features)\n        brain_rdm, v_brain = compute_rdm_and_vector(brain_patterns)\n        \n        # 2. Compute observed Spearman correlation\n        if v_model.size == 0 or v_brain.size == 0:\n            return 1.0 # Cannot compute correlation\n        r_obs, _ = spearmanr(v_model, v_brain)\n        \n        # 3. Perform permutation test\n        rng_perm = np.random.default_rng(perm_seed)\n        n_exceeding = 0\n        \n        for _ in range(n_permutations):\n            # Generate a permutation of condition labels\n            perm_indices = rng_perm.permutation(n_conditions)\n            \n            # Permute the brain RDM by reordering rows and columns\n            permuted_brain_rdm = brain_rdm[perm_indices][:, perm_indices]\n            \n            # Get the upper-triangular vector of the permuted RDM\n            triu_indices = np.triu_indices(n_conditions, k=1)\n            v_brain_perm = permuted_brain_rdm[triu_indices]\n            \n            # Compute the null correlation\n            r_perm, _ = spearmanr(v_model, v_brain_perm)\n            \n            # Compare absolute values for a two-sided test\n            if abs(r_perm) >= abs(r_obs):\n                n_exceeding += 1\n        \n        # 4. Compute the p-value with continuity correction\n        p_value = (1 + n_exceeding) / (1 + n_permutations)\n        \n        return p_value\n\n    test_cases = [\n        # Case 1 (aligned model and brain; cluster structure)\n        {\n            \"n\": 8, \"v\": 50, \"d\": 2, \"B\": 2000,\n            \"model_features_coords\": [\n                (0.0, 0.0), (0.0, 0.5), (0.5, 0.0), (0.5, 0.5),\n                (3.0, 3.0), (3.0, 3.5), (3.5, 3.0), (3.5, 3.5)\n            ],\n            \"gen_brain\": {\n                \"method\": \"linear_map\",\n                \"W_seed\": 42, \"noise_sigma\": 0.3, \"noise_seed\": 24\n            },\n            \"perm_seed\": 1001\n        },\n        # Case 2 (null case; independent brain patterns)\n        {\n            \"n\": 8, \"v\": 50, \"d\": 2, \"B\": 2000,\n            \"model_features_coords\": [\n                (0.0, 0.0), (0.0, 0.5), (0.5, 0.0), (0.5, 0.5),\n                (3.0, 3.0), (3.0, 3.5), (3.5, 3.0), (3.5, 3.5)\n            ],\n            \"gen_brain\": {\n                \"method\": \"independent_normal\",\n                \"X_seed\": 99\n            },\n            \"perm_seed\": 2002\n        },\n        # Case 3 (boundary case; minimal number of conditions)\n        {\n            \"n\": 3, \"v\": 30, \"d\": 1, \"B\": 1000,\n            \"model_features_coords\": [[0], [1], [2]],\n            \"gen_brain\": {\n                \"method\": \"linear_map\",\n                \"W_seed\": 7, \"noise_sigma\": 0.05, \"noise_seed\": 31\n            },\n            \"perm_seed\": 3003\n        },\n        # Case 4 (tied distances in the model RDM; categorical structure)\n        {\n            \"n\": 6, \"v\": 40, \"d\": 1, \"B\": 2000,\n            \"model_features_coords\": [[0], [0], [0], [1], [1], [1]],\n            \"gen_brain\": {\n                \"method\": \"linear_map\",\n                \"W_seed\": 123, \"noise_sigma\": 0.1, \"noise_seed\": 321\n            },\n            \"perm_seed\": 4004\n        }\n    ]\n\n    p_values = []\n    \n    for case in test_cases:\n        # Generate Model Features\n        M = np.array(case[\"model_features_coords\"])\n        \n        # Generate Brain Patterns\n        n, v, d = case[\"n\"], case[\"v\"], case[\"d\"]\n        gen_params = case[\"gen_brain\"]\n        \n        if gen_params[\"method\"] == \"linear_map\":\n            rng_w = np.random.default_rng(gen_params[\"W_seed\"])\n            W = rng_w.standard_normal(size=(d, v))\n            \n            rng_noise = np.random.default_rng(gen_params[\"noise_seed\"])\n            noise = rng_noise.normal(loc=0, scale=gen_params[\"noise_sigma\"], size=(n, v))\n            \n            X = M @ W + noise\n        elif gen_params[\"method\"] == \"independent_normal\":\n            rng_x = np.random.default_rng(gen_params[\"X_seed\"])\n            X = rng_x.standard_normal(size=(n, v))\n\n        # Run the permutation test\n        p_val = run_rsa_permutation_test(M, X, case[\"B\"], case[\"perm_seed\"])\n        p_values.append(p_val)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, p_values))}]\")\n\nsolve()\n\n```"
        }
    ]
}