{
    "hands_on_practices": [
        {
            "introduction": "本练习是构建表征相似性分析（RSA）计算模型的第一步。您将学习如何将一组抽象的刺激特征转化为关于神经表征几何的具体预测，即模型表征相异性矩阵（RDM）。这项练习强调了建模中的选择（例如对不同特征进行加权）如何直接塑造预测的相似性模式，为假设驱动的神经科学研究提供了基础技能。",
            "id": "4148250",
            "problem": "给定一组有限维实向量空间中的刺激特征向量，以及特征尺度缩放的规范。目标是构建一个模型表征非相似性矩阵（RDM），并量化特征缩放如何改变预测的表征几何。请基于向量空间和度量的基本定义进行操作，不要依赖于预先推导出的捷径。\n\n使用的基础知识：\n- 一个维度为 $p$ 的实向量空间配备了标准内积和诱导范数。对于任何向量 $v \\in \\mathbb{R}^p$，欧几里得范数满足范数公理，并由向量与其自身的内积的平方根定义。集合上的度量 $d$ 是一个满足非负性、不可辨识者同一性、对称性和三角不等式的函数。在具有欧几里得范数的 $\\mathbb{R}^p$ 中，两点之间的度量定义为它们差的范数。\n- 表征非相似性矩阵（RDM）是一个以刺激为索引的对称矩阵，其中每个非对角线元素是对应刺激对之间的非相似性，而当非相似性是由基于范数的度量诱导时，根据不可辨识者同一性，对角线元素为零。\n\n任务：\n1. 给定 $n$ 个刺激，其特征向量为 $x_i \\in \\mathbb{R}^p$（其中 $i \\in \\{1,\\dots,n\\}$），以及一个具有严格正值的特征缩放向量 $w \\in \\mathbb{R}^p$，通过以下步骤构建一个模型 RDM：\n   - 通过 $w$ 对每个刺激特征向量进行逐分量缩放，以获得每个刺激的缩放表示。\n   - 将刺激之间的成对非相似性计算为缩放特征空间中的欧几里得度量，将每个非相似性放置在 $n \\times n$ 矩阵的相应非对角线位置，并将对角线元素设置为 $0$。\n   - 以固定的、一致的顺序（例如，按上三角的行主序）将 RDM 的上三角部分（不包括对角线）向量化为一个一维数组。\n2. 对于每个测试用例，计算两个量来量化由于缩放相对于未缩放基线 $w = \\mathbf{1}_p$ 引起的几何变化：\n   - 基线 RDM 和缩放后 RDM 的上三角向量化之间的皮尔逊相关系数。如果由于任一向量的方差为零（例如，所有条目都相同）导致此相关性未定义，则返回相关值为 $0.0$。\n   - 相对弗罗贝尼乌斯变化，定义为缩放后 RDM 与基线 RDM 之差的弗罗贝尼乌斯范数除以基线 RDM 的弗罗贝尼乌斯范数。如果基线弗罗贝尼乌斯范数为 $0$，则返回相对变化为 $0.0$。\n3. 仅使用欧几里得范数和度量的定义来实现以上内容，确保 RDM 是对称的、非负的、对角线为零，并且距离是根据第一性原理（向量之差后跟欧几里得范数）计算的。\n\n测试套件：\n使用以下矩阵和缩放向量集。\n- 案例 $1$（正常情况，各向异性缩放）：$n = 5$, $p = 3$，刺激矩阵\n$$\nX^{(1)} = \\begin{bmatrix}\n0  1  2 \\\\\n1  0  3 \\\\\n2  2  1 \\\\\n3  1.5  0.5 \\\\\n0.5  3  2.5\n\\end{bmatrix},\n$$\n和缩放向量\n$$\nw^{(1)} = \\begin{bmatrix} 1 \\\\ 2 \\\\ 0.5 \\end{bmatrix}.\n$$\n- 案例 $2$（边界情况，均匀缩放）：重用 $X^{(1)}$ 并使用\n$$\nw^{(2)} = \\begin{bmatrix} 3 \\\\ 3 \\\\ 3 \\end{bmatrix}.\n$$\n- 案例 $3$（边缘情况，极端各向异性）：重用 $X^{(1)}$ 并使用\n$$\nw^{(3)} = \\begin{bmatrix} 0.1 \\\\ 10 \\\\ 0.1 \\end{bmatrix}.\n$$\n- 案例 $4$（退化基线，相同的刺激）：$n = 3$, $p = 2$，\n$$\nX^{(4)} = \\begin{bmatrix}\n1  2 \\\\\n1  2 \\\\\n1  2\n\\end{bmatrix},\n\\quad\nw^{(4)} = \\begin{bmatrix} 5 \\\\ 7 \\end{bmatrix}.\n$$\n\n输出规范：\n- 对于每个案例 $k \\in \\{1,2,3,4\\}$，计算基线 RDM（$w = \\mathbf{1}_p$）和缩放后 RDM（$w = w^{(k)}$）之间的皮尔逊相关系数，以及如上定义的相对弗罗贝尼乌斯变化。返回有序对 $\\left[\\text{corr}^{(k)}, \\text{rel\\_change}^{(k)}\\right]$ 作为两个浮点数的列表。\n- 你的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表形式的结果，每个元素对应一个测试用例，并且本身是一个包含两个元素的列表。例如，输出应如下所示：\n```\n[[c_1,r_1],[c_2,r_2],[c_3,r_3],[c_4,r_4]]\n```\n其中每个 $c_k$ 和 $r_k$ 是一个浮点数。",
            "solution": "该问题要求根据一组给定的刺激特征向量和一个逐特征的缩放向量来构建表征非相似性矩阵（RDM）。此外，它要求量化这种缩放引起的几何变化，该变化是相对于一个基准的未缩放表征而言的。整个过程必须基于向量空间、范数和度量的基本定义。\n\n解决方案分三个阶段展开：首先，定义特征向量的缩放；其次，使用欧几里得度量从这些缩放后的向量构建 RDM；第三，使用皮尔逊相关和相对弗罗贝尼乌斯范数将缩放后的 RDM 与基准 RDM 进行比较。\n\n一个刺激被表示为一个在 $p$ 维实向量空间 $\\mathbb{R}^p$ 中的向量 $x_i$。$n$ 个刺激的集合构成一个大小为 $n \\times p$ 的矩阵 $X$。特征缩放使用一个具有严格正值条目（$w_j > 0$）的向量 $w \\in \\mathbb{R}^p$ 来应用。缩放操作通过逐分量乘法将每个刺激向量 $x_i = [x_{i,1}, x_{i,2}, \\dots, x_{i,p}]$ 转换为一个新向量 $x'_i$：\n$$\nx'_i = [x_{i,1} w_1, x_{i,2} w_2, \\dots, x_{i,p} w_p]\n$$\n该操作等同于 Hadamard（逐元素）积，$x'_i = x_i \\circ w$。此变换通过沿每个特征轴拉伸或压缩特征空间来改变其几何结构。\n\nRDM 是一个 $n \\times n$ 的对称矩阵，其条目量化了刺激对之间的非相似性。问题指定非相似性为缩放后特征空间中的欧几里得距离。根据基础定义，两个向量 $u, v \\in \\mathbb{R}^p$ 之间的欧几里得距离 $d(u,v)$ 由欧几里得范数 $\\| \\cdot \\|$ 诱导，使得 $d(u,v) = \\|u-v\\|$。范数本身由标准内积 $\\langle \\cdot, \\cdot \\rangle$ 定义为 $\\|z\\| = \\sqrt{\\langle z, z \\rangle}$。对于向量 $z = [z_1, \\dots, z_p]$，这变为：\n$$\n\\|z\\| = \\sqrt{\\sum_{k=1}^{p} z_k^2}\n$$\n因此，缩放后的刺激向量 $x'_i$ 和 $x'_j$ 之间的非相似性 $d_{ij}$ 是：\n$$\nd_{ij} = \\|x'_i - x'_j\\| = \\sqrt{\\sum_{k=1}^{p} (x'_{i,k} - x'_{j,k})^2}\n$$\nRDM（表示为 $R$）的构建方式是，其非对角线元素为这些成对的非相似性，即当 $i \\neq j$ 时，$R_{ij} = d_{ij}$。根据度量的一个属性——不可辨识者同一性，一个点到其自身的距离为零，$d(x'_i, x'_i) = 0$。因此，RDM 的对角线元素全为零，$R_{ii} = 0$。对称性属性 $d(u,v) = d(v,u)$ 确保了 RDM 是对称的，$R_{ij} = R_{ji}$。\n\n为了比较，RDM 的上三角元素（不包括对角线）被向量化成一个一维数组。该向量以固定的行主序包含了所有 $\\frac{n(n-1)}{2}$ 个独特的成对非相似性。\n\n为了量化缩放的效果，将使用给定缩放向量 $w$ 计算的 RDM（$RDM_{scaled}$）与不进行显式缩放计算的基准 RDM（$RDM_{baseline}$）进行比较。该基准对应于使用一个全为一的缩放向量，$w_{base} = \\mathbf{1}_p = [1, 1, \\dots, 1]^T$。此比较使用两个度量：\n\n1.  **皮尔逊相关系数**：这衡量了 $RDM_{scaled}$ 和 $RDM_{baseline}$ 的向量化上三角之间的线性关系。设向量化的非相似性为 $v_{scaled}$ 和 $v_{baseline}$。相关性为：\n    $$\n    \\rho = \\frac{\\sum_{k=1}^{N} (v_{scaled,k} - \\bar{v}_{scaled})(v_{baseline,k} - \\bar{v}_{baseline})}{\\sqrt{\\sum_{k=1}^{N} (v_{scaled,k} - \\bar{v}_{scaled})^2} \\sqrt{\\sum_{k=1}^{N} (v_{baseline,k} - \\bar{v}_{baseline})^2}}\n    $$\n    其中 $N = \\frac{n(n-1)}{2}$。相关性为 $1$ 意味着缩放对所有非相似性是均匀的（即对于常数 $a>0, b$，有 $v_{scaled} = a \\cdot v_{baseline} + b$）。在距离的上下文中，由于距离是非负的，这简化为 $v_{scaled} = a \\cdot v_{baseline}$。与 $1$ 的偏差表明表征几何发生了非线性重构。如果任一向量的方差为零（所有非相似性都相同），则相关性未定义，并按规定报告为 $0.0$。\n\n2.  **相对弗罗贝尼乌斯变化**：这衡量了两个 RDM 矩阵之间差异的大小，并由基准 RDM 的大小进行归一化。一个 $n \\times n$ 矩阵 $A$ 的弗罗贝尼乌斯范数是 $\\|A\\|_F = \\sqrt{\\sum_{i=1}^n \\sum_{j=1}^n A_{ij}^2}$。相对变化是：\n    $$\n    \\text{rel\\_change} = \\frac{\\|RDM_{scaled} - RDM_{baseline}\\|_F}{\\|RDM_{baseline}\\|_F}\n    $$\n    该度量提供了一个对非相似性值总体变化的归一化度量。如果基准 RDM 是一个零矩阵（即 $\\|RDM_{baseline}\\|_F = 0$），则相对变化报告为 $0.0$。\n\n实现过程首先定义一个函数，该函数根据刺激矩阵和缩放向量计算 RDM 及其向量化，严格遵守欧几里得距离的第一性原理计算。然后，对于每个测试用例，使用指定的缩放向量和基准缩放向量调用此函数。最后，使用得到的两个 RDM 及其向量化来计算如上定义的相关性和相对弗罗贝尼乌斯变化，包括处理指定的边缘情况。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef _compute_rdm_and_vectorization(X, w):\n    \"\"\"\n    Constructs an RDM and its upper-triangular vectorization from first principles.\n\n    Args:\n        X (np.ndarray): An n x p stimulus matrix.\n        w (np.ndarray): A p-dimensional feature scaling vector.\n\n    Returns:\n        tuple[np.ndarray, np.ndarray]: A tuple containing:\n            - The n x n RDM.\n            - The vectorized upper-triangular dissimilarities.\n    \"\"\"\n    n, p = X.shape\n    \n    # Scale the stimulus feature vectors component-wise\n    X_scaled = X * w  # Broadcasting w across rows of X\n    \n    rdm = np.zeros((n, n), dtype=np.float64)\n    \n    # Get indices for the upper triangle (excluding the diagonal)\n    # This provides a fixed, consistent row-major order for vectorization.\n    rows, cols = np.triu_indices(n, k=1)\n    \n    num_dissimilarities = len(rows)\n    vec = np.zeros(num_dissimilarities, dtype=np.float64)\n    \n    for k in range(num_dissimilarities):\n        i, j = rows[k], cols[k]\n        \n        # 1. Compute the difference vector\n        diff_vec = X_scaled[i, :] - X_scaled[j, :]\n        \n        # 2. Compute the Euclidean norm from first principles: sqrt(sum of squares)\n        dist = np.sqrt(np.sum(diff_vec**2))\n        \n        # Populate the RDM and the vector\n        rdm[i, j] = dist\n        rdm[j, i] = dist  # Ensure symmetry\n        vec[k] = dist\n        \n    return rdm, vec\n\ndef solve():\n    \"\"\"\n    Solves the problem for all test cases as specified.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    X1 = np.array([\n        [0, 1, 2],\n        [1, 0, 3],\n        [2, 2, 1],\n        [3, 1.5, 0.5],\n        [0.5, 3, 2.5]\n    ], dtype=np.float64)\n    w1 = np.array([1, 2, 0.5], dtype=np.float64)\n    w2 = np.array([3, 3, 3], dtype=np.float64)\n    w3 = np.array([0.1, 10, 0.1], dtype=np.float64)\n    \n    X4 = np.array([\n        [1, 2],\n        [1, 2],\n        [1, 2]\n    ], dtype=np.float64)\n    w4 = np.array([5, 7], dtype=np.float64)\n    \n    test_cases = [\n        (X1, w1),\n        (X1, w2),\n        (X1, w3),\n        (X4, w4),\n    ]\n\n    results = []\n    # Machine epsilon for floating point comparisons\n    epsilon = np.finfo(float).eps\n\n    for X, w in test_cases:\n        n, p = X.shape\n        w_base = np.ones(p, dtype=np.float64)\n        \n        # Compute baseline RDM and its vectorization (w = 1)\n        rdm_base, vec_base = _compute_rdm_and_vectorization(X, w_base)\n        \n        # Compute scaled RDM and its vectorization\n        rdm_scaled, vec_scaled = _compute_rdm_and_vectorization(X, w)\n        \n        # Task 2.1: Pearson Correlation\n        # Check for zero variance, as correlation is undefined in this case.\n        if np.std(vec_base)  epsilon or np.std(vec_scaled)  epsilon:\n            corr = 0.0\n        else:\n            # np.corrcoef returns a 2x2 matrix, we need the off-diagonal element\n            corr = np.corrcoef(vec_base, vec_scaled)[0, 1]\n            \n        # Task 2.2: Relative Frobenius Change\n        norm_base = np.linalg.norm(rdm_base, 'fro')\n        \n        if norm_base  epsilon:\n            rel_change = 0.0\n        else:\n            norm_diff = np.linalg.norm(rdm_scaled - rdm_base, 'fro')\n            rel_change = norm_diff / norm_base\n            \n        results.append([corr, rel_change])\n\n    # Final print statement in the exact required format.\n    # The format [[c,r],[c,r],...] is achieved by this construction.\n    result_strings = [f\"[{c},{r}]\" for c, r in results]\n    print(f\"[{','.join(result_strings)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "在将模型与神经数据进行检验之前，理解数据本身的结构和可靠性至关重要。本练习介绍了“噪声上限”这一概念，它是RSA中的一个重要基准，用于估计在数据固有噪声和变异性的情况下，任何模型所能达到的最佳性能。通过实施“留一被试交叉验证”程序，您将学会如何量化一组被试间表征几何的一致性，从而为模型评估提供一个切合实际的性能上限。",
            "id": "4148180",
            "problem": "给定一组来自多个被试的多条件神经响应数据，您的任务是为每个被试构建表征非相似性矩阵 (Representational Dissimilarity Matrix, RDM)，并使用留一被试法 (leave-one-subject-out) 聚合来估计噪声天花板下界 (lower noise ceiling)。表征非相似性矩阵 (RDM) 由表征相似性分析 (Representational Similarity Analysis, RSA) 框架定义，它编码了特定条件响应向量之间的成对非相似性。请完全以纯数学和算法术语进行操作。\n\n基础定义：\n- 单个被试的数据表示为一个矩阵 $X^{(s)} \\in \\mathbb{R}^{K \\times V}$，其中有 $K$ 个条件和 $V$ 个特征（例如，体素强度），每一行 $x_{i}^{(s)} \\in \\mathbb{R}^{V}$ 对应于被试 $s$ 的条件 $i$ 的响应向量。\n- 两个向量 $x \\in \\mathbb{R}^{V}$ 和 $y \\in \\mathbb{R}^{V}$ 之间的 Pearson 相关系数 $\\rho(x, y)$ 是一种经过充分检验的统计关联性度量。\n- 两个等长数值向量之间的 Spearman 等级相关系数 (Spearman Rank Correlation Coefficient, SRCC) 是一种经过充分检验的度量，用于评估单调关联，对线性重缩放具有鲁棒性。\n\n根据这些定义，为每个被试 $s$ 构建 RDM，它是一个对角线元素为零的对称矩阵 $D^{(s)} \\in \\mathbb{R}^{K \\times K}$，其中当 $i \\neq j$ 时，第 $(i,j)$ 个元素是通过相关距离从条件向量 $x_{i}^{(s)}$ 和 $x_{j}^{(s)}$ 计算出的非相似性 $d_{ij}^{(s)}$：\n$$\nd_{ij}^{(s)} = 1 - \\rho\\big(x_{i}^{(s)}, \\, x_{j}^{(s)}\\big)\n$$\n为了比较 RDM，我们使用其向量化形式 $u^{(s)} \\in \\mathbb{R}^{K(K-1)/2}$，该向量是通过将 $D^{(s)}$ 的严格上三角元素（即索引为 $(i,j)$ 且 $1 \\le i  j \\le K$ 的元素）堆叠成一个向量得到的。\n\n将被试 $s$ 的留一被试法 (Leave-One-Subject-Out, LOSO) 组平均 RDM 定义为除被试 $s$ 之外所有被试的 RDM 的算术平均值：\n$$\n\\overline{D}^{(-s)} = \\frac{1}{S-1}\\sum_{\\substack{t=1 \\\\ t\\neq s}}^{S} D^{(t)}\n$$\n及其在严格上三角上的向量化形式 $\\overline{u}^{(-s)}$。使用 Spearman 等级相关系数 (SRCC)，为每个被试 $s$ 计算 $u^{(s)}$ 和 $\\overline{u}^{(-s)}$ 之间的相关性 $r_s$。然后，噪声天花板下界估计值是这些相关性在所有被试间的算术平均值：\n$$\n\\widehat{c}_{\\text{lower}} = \\frac{1}{S}\\sum_{s=1}^{S} r_s\n$$\n解释要求：计算出 $\\widehat{c}_{\\text{lower}}$ 后，在解决方案中解释为什么对于任何针对单个被试 RDM 进行评估的固定模型，这个值是可实现模型与数据相关性的一个下界，以及为什么留一被试法程序可以避免循环论证。\n\n算法任务：\n- 实现上述步骤，通过对被试 RDM 及其 LOSO 组平均 RDM 的向量化上三角部分使用 Spearman 等级相关来计算 $\\widehat{c}_{\\text{lower}}$。\n- 根据以下测试套件构建被试级别的数据矩阵，方法是按照指定方式使用带种子的伪随机数或显式确定性矩阵生成条件响应矩阵 $X^{(s)}$。对于每个测试用例，报告一个等于 $\\widehat{c}_{\\text{lower}}$ 的单精度浮点数。\n\n测试套件：\n- 测试用例 1 (具有异构噪声的理想路径)：$S=5$, $K=6$, $V=30$。设 $B \\in \\mathbb{R}^{K \\times V}$ 是一个基础矩阵，其元素使用种子 $42$ 从标准正态分布中抽取。对于每个被试 $s \\in \\{1,2,3,4,5\\}$，设独立噪声 $N^{(s)} \\in \\mathbb{R}^{K \\times V}$ 为使用种子 $1,2,3,4,5$ 分别生成的标准正态分布，并设置 $X^{(s)} = B + \\sigma_s N^{(s)}$，其中 $\\sigma = [0.2,\\,0.25,\\,0.3,\\,0.35,\\,0.4]$。\n- 测试用例 2 ($S=2$ 的边界情况)：$S=2$, $K=5$, $V=20$。使用种子 $123$ 生成 $X^{(1)}$ 的元素作为标准正态分布。设 $N^{(2)}$ 为使用种子 $456$ 生成的标准正态分布，并设置 $X^{(2)} = X^{(1)} + 0.1\\,N^{(2)}$。\n- 测试用例 3 (被试完全相同的边缘情况)：$S=3$, $K=4$, $V=15$。使用种子 $789$ 从标准正态分布生成一个基础矩阵 $B$，并设置 $X^{(1)}=X^{(2)}=X^{(3)}=B$。\n- 测试用例 4 (通过结构化设计在非相似性中产生平局)：$S=4$, $K=4$, $V=8$。按行定义一个确定性基础矩阵 $B$：\n  - 第 1 行: $[0,\\,1,\\,2,\\,3,\\,0,\\,1,\\,2,\\,3]$，\n  - 第 2 行: $[3,\\,2,\\,1,\\,0,\\,3,\\,2,\\,1,\\,0]$，\n  - 第 3 行: $[1,\\,1,\\,1,\\,1,\\,2,\\,2,\\,2,\\,2]$，\n  - 第 4 行: $[2,\\,2,\\,2,\\,2,\\,1,\\,1,\\,1,\\,1]$。\n  设置 $X^{(1)}=X^{(2)}=X^{(3)}=X^{(4)}=B$。\n\n输出规格：\n- 您的程序应产生单行输出，其中包含一个用方括号括起来的逗号分隔列表（例如 $[r_1,r_2,r_3,r_4]$）的结果，其中每个元素是按上述顺序为相应测试用例计算出的 $\\widehat{c}_{\\text{lower}}$。\n- 所有数字都是无单位的标量。不涉及角度。\n\n请忠实遵循上述定义和生成过程，以确保科学真实性。避免任何快捷方式或硬编码公式；从给定的基础定义推导并实现每一步。程序必须是完整的，并且无需外部输入即可运行。",
            "solution": "该问题提出了一个来自计算神经科学领域，特别是表征相似性分析 (RSA) 领域的有效且适定的任务。其目标是为一组多被试神经响应数据集计算噪声天花板下界 $\\widehat{c}_{\\text{lower}}$。该度量通过估计一个模型与含噪声的实验数据所能达到的最高可能相关性，为评估计算模型提供了一个基准。该程序基于成熟的统计方法，并遵循标准的交叉验证范式。\n\n算法流程如下：\n\n首先，我们为每个被试构建一个表征非相似性矩阵 (RDM)。对于总共 $S$ 个被试中的一个给定被试 $s$，其数据以矩阵 $X^{(s)} \\in \\mathbb{R}^{K \\times V}$ 的形式提供，其中 $K$ 是实验条件的数量，$V$ 是特征的数量（例如，fMRI 中的体素，电生理学中的神经元）。$X^{(s)}$ 的每一行 $x_i^{(s)}$ 是条件 $i$ 的响应模式向量。两个不同条件 $i$ 和 $j$ 的神经响应之间的非相似性使用相关距离来定义。我们计算相应响应向量之间的 Pearson 相关系数 $\\rho(x_i^{(s)}, x_j^{(s)})$。那么，非相似性由下式给出：\n$$\nd_{ij}^{(s)} = 1 - \\rho(x_i^{(s)}, x_j^{(s)})\n$$\n对于所有 $i, j \\in \\{1, \\dots, K\\}$，这些成对的非相似性构成了 $K \\times K$ 对称矩阵 $D^{(s)}$ 的元素，该矩阵即为被试 $s$ 的 RDM。根据定义，对角线元素为 $d_{ii}^{(s)} = 1 - \\rho(x_i^{(s)}, x_i^{(s)}) = 1 - 1 = 0$。\n\n其次，为了便于 RDM 之间的比较，我们将其线性化。提取每个 RDM $D^{(s)}$ 的严格上三角部分（即 $i  j$ 时的元素 $d_{ij}^{(s)}$），并将其重塑为一个向量 $u^{(s)} \\in \\mathbb{R}^{M}$，其中 $M = K(K-1)/2$ 是唯一成对非相似性的数量。\n\n第三，我们实施留一被试法 (LOSO) 交叉验证程序来估计组级表征，同时避免循环论证。对于每个被试 $s$，我们使用所有其他被试的数据计算一个平均 RDM。这个 LOSO 组平均 RDM 定义为：\n$$\n\\overline{D}^{(-s)} = \\frac{1}{S-1} \\sum_{\\substack{t=1 \\\\ t \\neq s}}^{S} D^{(t)}\n$$\n这个平均矩阵 $\\overline{D}^{(-s)}$ 也通过提取其上三角元素被向量化为 $\\overline{u}^{(-s)}$。\n\n第四，我们量化单个被试的 RDM 与相应的 LOSO 组平均 RDM 之间的相似性。这通过计算它们向量化形式之间的 Spearman 等级相关系数 (SRCC) 来完成：\n$$\nr_s = \\text{SRCC}(u^{(s)}, \\overline{u}^{(-s)})\n$$\n使用 Spearman 相关而非 Pearson 相关，是因为它评估的是两组非相似性之间的单调关系，这使其对非相似性度量的非线性但单调的变换具有鲁棒性。这是一个理想的特性，因为组平均 RDM $\\overline{D}^{(-s)}$ 的非相似性尺度将与单个被试的 RDM $D^{(s)}$ 不同。\n\n最后，噪声天花板下界 $\\widehat{c}_{\\text{lower}}$ 通过计算所有被试的这些单个相关值的算术平均值来估计：\n$$\n\\widehat{c}_{\\text{lower}} = \\frac{1}{S} \\sum_{s=1}^{S} r_s\n$$\n\n噪声天花板下界与 LOSO 程序的解释：\n\n“噪声天花板”一词指的是任何模型在解释数据方面性能的理论上限。数据本身是含噪声的；因此，即使一个“完美”的潜在神经表征模型也不会与测量到的数据完全相关。噪声天花板估算了这一上限。\n\n下界 $\\widehat{c}_{\\text{lower}}$ 源于这样一个原理：任何单个被试的 RDM, $D^{(s)}$，都是一个假设的“真实”共同表征结构的含噪声样本。经过 LOSO 平均的 RDM, $\\overline{D}^{(-s)}$，是这个真实结构的另一个独立样本。通过对多个被试（除 $s$ 外的所有被试）进行平均，每个被试的特异性噪声被降低，使得 $\\overline{D}^{(-s)}$ 成为一个比任何单个被试的 RDM 更可靠（尽管仍不完美）的真实 RDM 估计。因此，这两个含噪声估计值 $u^{(s)}$ 和 $\\overline{u}^{(-s)}$ 之间的相关性 $r_s$ 预计会低于单个被试的 RDM $u^{(s)}$ 与假设的无噪声真实 RDM 之间的相关性。对这些值进行平均得到 $\\widehat{c}_{\\text{lower}}$，它代表了单个被试的 RDM 与一个可比较的独立群体的 RDM 之间的预期相关性。它作为一个“下界”，因为任何旨在解释神经数据的可信模型，其预测单个个体表征几何的能力至少应该与预测其他个体的平均水平的能力相当。\n\n留一被试法 (LOSO) 程序对于确保此估计的统计有效性至关重要。如果我们将一个被试的 RDM $D^{(s)}$ 与一个包含 $D^{(s)}$ 本身的组平均值相关联，就会发生循环分析或“二次蘸取 (double-dipping)”。这会人为地夸大相关性，因为 $D^{(s)}$ 将与一个包含其自身成分的基准相关。LOSO 方法通过从一个与被评估数据 $X^{(s)}$ 完全独立的数据集中构建基准 $\\overline{D}^{(-s)}$ 来严格避免这种情况。这种交叉验证方法得出了对被试池中表征几何一致性的无偏估计，为模型评估提供了坚实的基础。\n\n完整的算法通过将这些步骤应用于测试套件中指定的数据集来执行。每个案例都涉及生成被试数据矩阵，计算所有被试的 RDM，然后执行 LOSO 循环以找到每个 $r_s$ 及其最终平均值 $\\widehat{c}_{\\text{lower}}$。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy import stats\nfrom scipy.spatial.distance import squareform\n\ndef solve():\n    \"\"\"\n    Main function to run all test cases and print the results.\n    \"\"\"\n\n    def compute_lower_noise_ceiling(S, K, V, data_matrices):\n        \"\"\"\n        Computes the lower noise ceiling for a list of subject data matrices.\n\n        Args:\n            S (int): Number of subjects.\n            K (int): Number of conditions.\n            V (int): Number of features.\n            data_matrices (list of np.ndarray): A list of S data matrices,\n                                                 each of shape (K, V).\n\n        Returns:\n            float: The computed lower noise ceiling, c_lower_hat.\n        \"\"\"\n        if S  2:\n            # LOSO procedure is not well-defined for S  2.\n            # Per the problem constraints, all test cases have S >= 2.\n            # Returning NaN for robustness in a general function.\n            return np.nan\n\n        # Step 1  2: Compute RDM and vectorize for each subject.\n        rdm_vectors = []\n        for s in range(S):\n            X_s = data_matrices[s]\n            # Compute Pearson correlation matrix between conditions (rows).\n            corr_matrix = np.corrcoef(X_s)\n            # Define RDM D_s as 1 - correlation matrix.\n            D_s = 1 - corr_matrix\n            # Vectorize the strict upper-triangular part of D_s.\n            u_s = squareform(D_s, checks=False)\n            rdm_vectors.append(u_s)\n        \n        rdm_vectors = np.array(rdm_vectors)\n\n        # Step 3  4: LOSO procedure and Spearman correlation.\n        r_s_values = []\n        for s in range(S):\n            # The RDM vector for the left-out subject.\n            u_s = rdm_vectors[s]\n            \n            # The RDM vectors for all other subjects.\n            u_others_indices = [i for i in range(S) if i != s]\n            u_others = rdm_vectors[u_others_indices]\n            \n            # Compute the LOSO group-average RDM vector.\n            u_bar_minus_s = np.mean(u_others, axis=0)\n            \n            # Compute Spearman correlation between u_s and u_bar_minus_s.\n            # We only need the correlation coefficient, not the p-value.\n            r_s, _ = stats.spearmanr(u_s, u_bar_minus_s)\n            \n            # Handle potential NaN if an input vector is constant.\n            if np.isnan(r_s):\n                # If a vector is constant, its correlation with any other\n                # vector is undefined (NaN). If both are constant, also NaN.\n                # If one vector is constant and the other is not, it should be 0,\n                # but scipy may return NaN. A single constant vector has 0 variance.\n                # A more robust check might be needed for pathological cases,\n                # but problem test cases avoid this. If they are identical vectors\n                # (and not constant), correlation is 1. If both are constant,\n                # they are perfectly related, so we can treat this as 1.\n                if np.all(u_s == u_s[0]) and np.all(u_bar_minus_s == u_bar_minus_s[0]):\n                    r_s = 1.0\n                else: # Should not happen in this problem's cases.\n                    r_s = 0.0\n\n            r_s_values.append(r_s)\n            \n        # Step 5: Compute the final lower noise ceiling estimate.\n        c_lower_hat = np.mean(r_s_values)\n        \n        return c_lower_hat\n\n    test_case_results = []\n\n    # --- Test Case 1 ---\n    S1, K1, V1 = 5, 6, 30\n    rng_base = np.random.default_rng(42)\n    B1 = rng_base.standard_normal((K1, V1))\n    noise_seeds = [1, 2, 3, 4, 5]\n    sigmas = [0.2, 0.25, 0.3, 0.35, 0.4]\n    data_matrices1 = []\n    for s in range(S1):\n        rng_noise = np.random.default_rng(noise_seeds[s])\n        N_s = rng_noise.standard_normal((K1, V1))\n        X_s = B1 + sigmas[s] * N_s\n        data_matrices1.append(X_s)\n    result1 = compute_lower_noise_ceiling(S1, K1, V1, data_matrices1)\n    test_case_results.append(result1)\n\n    # --- Test Case 2 ---\n    S2, K2, V2 = 2, 5, 20\n    rng1 = np.random.default_rng(123)\n    X1 = rng1.standard_normal((K2, V2))\n    rng2 = np.random.default_rng(456)\n    N2 = rng2.standard_normal((K2, V2))\n    X2 = X1 + 0.1 * N2\n    data_matrices2 = [X1, X2]\n    result2 = compute_lower_noise_ceiling(S2, K2, V2, data_matrices2)\n    test_case_results.append(result2)\n\n    # --- Test Case 3 ---\n    S3, K3, V3 = 3, 4, 15\n    rng_base3 = np.random.default_rng(789)\n    B3 = rng_base3.standard_normal((K3, V3))\n    data_matrices3 = [B3, B3, B3]\n    result3 = compute_lower_noise_ceiling(S3, K3, V3, data_matrices3)\n    test_case_results.append(result3)\n\n    # --- Test Case 4 ---\n    S4, K4, V4 = 4, 4, 8\n    B4 = np.array([\n        [0, 1, 2, 3, 0, 1, 2, 3],\n        [3, 2, 1, 0, 3, 2, 1, 0],\n        [1, 1, 1, 1, 2, 2, 2, 2],\n        [2, 2, 2, 2, 1, 1, 1, 1]\n    ], dtype=float)\n    data_matrices4 = [B4, B4, B4, B4]\n    result4 = compute_lower_noise_ceiling(S4, K4, V4, data_matrices4)\n    test_case_results.append(result4)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(f'{r:.10f}' for r in test_case_results)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "许多RSA研究的最后一步是正式检验一个假设的模型RDM是否与从神经测量中派生出的大脑RDM显著相关。本练习将指导您完成置换检验，这是一种功能强大且广泛应用的非参数方法，用于评估统计显著性。通过学习如何通过重排条件标签来生成零分布，您将亲身体验如何确定观测到的模型-大脑对应关系是稳健的，还是仅仅由偶然因素造成的。",
            "id": "4148208",
            "problem": "您的任务是使用表征非相似性矩阵（RDM）来评估计算模型的刺激关系假设是否与神经表征几何相符。表征非相似性矩阵（RDM）定义为特定条件下表征之间两两非相似性的矩阵。形式上，对于具有表征 $\\{\\mathbf{x}_1,\\dots,\\mathbf{x}_n\\}$ 的 $n$ 个条件，RDM $D \\in \\mathbb{R}^{n \\times n}$ 的元素为 $D_{ij} = \\delta(\\mathbf{x}_i,\\mathbf{x}_j)$，其中 $\\delta$ 是一个非相似性函数。在本问题中，请使用欧几里得距离，即 $\\delta(\\mathbf{x}_i,\\mathbf{x}_j) = \\|\\mathbf{x}_i - \\mathbf{x}_j\\|_2$。\n\n为量化模型 RDM 和大脑 RDM 之间的关联，请使用斯皮尔曼等级相关：计算模型和大脑 RDM 经过秩转换后的上三角元素（不包括对角线）之间的相关性。令 $v^{\\text{model}} \\in \\mathbb{R}^{m}$ 和 $v^{\\text{brain}} \\in \\mathbb{R}^{m}$ 分别表示通过读取模型和大脑 RDM 的 $m = \\frac{n(n-1)}{2}$ 个上三角元素得到的向量。检验统计量是 $v^{\\text{model}}$ 和 $v^{\\text{brain}}$ 之间的斯皮尔曼相关系数。\n\n通过基于条件标签重排的置换检验来评估统计显著性。零假设应清晰阐明：$H_0$：条件标签与大脑测量值的分配相对于模型是可交换的，这意味着模型 RDM 与大脑 RDM 之间的任何对齐都是偶然产生的，并且检验统计量的分布在条件标签的置换下保持不变。在 $H_0$ 下，对标签进行置换会导出斯皮尔曼相关系数的零分布。使用双侧检验，比较 $|r_{\\text{perm}}|$ 和 $|r_{\\text{obs}}|$，其中 $r_{\\text{obs}}$ 是观测到的相关系数，$r_{\\text{perm}}$ 是在置换下计算出的相关系数。\n\n您的程序必须：\n- 对每个测试用例（见测试套件），使用欧几里得距离构建模型和大脑 RDM。\n- 计算 $v^{\\text{model}}$ 和 $v^{\\text{brain}}$ 之间的观测斯皮尔曼相关系数 $r_{\\text{obs}}$。\n- 对大脑 RDM 执行 $B$ 次 $n$ 个条件标签的随机置换，方法是同时置换其行和列（等效于应用一个置换 $\\pi$ 来重排索引，并取置换后大脑 RDM 的上三角元素）。对每次置换，计算 $r_{\\text{perm}}$。\n- 计算双侧置换 $p$ 值，公式为 \n$$p = \\frac{1 + \\sum_{b=1}^B \\mathbf{1}\\left(|r_{\\text{perm},b}| \\ge |r_{\\text{obs}}|\\right)}{B+1}$$\n其中 $\\mathbf{1}(\\cdot)$ 是指示函数。这种连续性校正确保了即使在没有置换统计量超过观测统计量的情况下，也能得到一个有效的 $p$ 值。\n- 生成一行输出，其中包含所有测试用例的 $p$ 值，格式为方括号内以逗号分隔的列表，例如 $[p_1,p_2,p_3,p_4]$。\n\n测试套件（每个用例指定了模型特征、如何生成大脑模式以及置换次数 $B$；所有随机元素使用指定的种子以确保可复现性）：\n\n- 用例 1（对齐的模型和大脑；聚类结构）：\n  - 条件：$n = 8$，体素：$v = 50$，模型特征维度：$d = 2$。\n  - 模型特征 $M \\in \\mathbb{R}^{8 \\times 2}$（行为条件）：\n    - 簇 $\\mathcal{A}$：$(0.0, 0.0)$, $(0.0, 0.5)$, $(0.5, 0.0)$, $(0.5, 0.5)$。\n    - 簇 $\\mathcal{B}$：$(3.0, 3.0)$, $(3.0, 3.5)$, $(3.5, 3.0)$, $(3.5, 3.5)$。\n  - 大脑模式 $X \\in \\mathbb{R}^{8 \\times 50}$ 通过线性映射加噪声生成：\n    - 权重矩阵 $W \\in \\mathbb{R}^{2 \\times 50}$ 从种子为 $42$ 的标准正态分布中采样。\n    - 使用种子 $24$ 添加标准差为 $\\sigma = 0.3$ 的独立高斯噪声。\n    - 构建方式：$X = M W + \\text{noise}$。\n  - 置换：$B = 2000$，置换种子 $1001$。\n\n- 用例 2（零假设用例；独立的大脑模式）：\n  - 条件：$n = 8$，体素：$v = 50$，模型与用例 1 相同（即相同的 $M$）。\n  - 大脑模式 $X \\in \\mathbb{R}^{8 \\times 50}$ 从种子为 $99$ 的标准正态分布中独立采样（即与 $M$ 无关）。\n  - 置换：$B = 2000$，置换种子 $2002$。\n\n- 用例 3（边界用例；最小条件数）：\n  - 条件：$n = 3$，体素：$v = 30$，模型特征维度：$d = 1$。\n  - 模型特征 $M = \\begin{bmatrix}0\\\\1\\\\2\\end{bmatrix}$。\n  - 大脑模式 $X \\in \\mathbb{R}^{3 \\times 30}$：\n    - 权重向量 $W \\in \\mathbb{R}^{1 \\times 30}$ 从种子为 $7$ 的标准正态分布中采样。\n    - 使用种子 $31$ 添加标准差为 $\\sigma = 0.05$ 的独立高斯噪声。\n    - 构建方式：$X = M W + \\text{noise}$。\n  - 置换：$B = 1000$，置换种子 $3003$。\n\n- 用例 4（模型 RDM 中存在相等距离；分类结构）：\n  - 条件：$n = 6$，体素：$v = 40$，模型特征维度：$d = 1$。\n  - 模型特征 $M = \\begin{bmatrix}0\\\\0\\\\0\\\\1\\\\1\\\\1\\end{bmatrix}$（两个类别）。\n  - 大脑模式 $X \\in \\mathbb{R}^{6 \\times 40}$：\n    - 权重向量 $W \\in \\mathbb{R}^{1 \\times 40}$ 从种子为 $123$ 的标准正态分布中采样。\n    - 使用种子 $321$ 添加标准差为 $\\sigma = 0.1$ 的独立高斯噪声。\n    - 构建方式：$X = M W + \\text{noise}$。\n  - 置换：$B = 2000$，置换种子 $4004$。\n\n您的程序必须实现上述要求，并以 $[p_1,p_2,p_3,p_4]$ 的格式生成单行最终输出，其中 $p_i$ 分别是用例 $1$、$2$、$3$ 和 $4$ 的双侧置换 $p$ 值（浮点数）。不应打印任何其他文本。",
            "solution": "该问题是有效的。它在计算神经科学领域，特别是表征相似性分析（RSA）方面，提出了一个清晰、有科学依据且定义明确的任务。所有给定的条件，包括数学定义、算法流程和测试用例的数值参数，都已完整提供且无矛盾。任务是实现一个标准的统计分析流程，这是一个可形式化和可验证的问题。\n\n解决方案将基于 RSA、假设检验和计算统计的原理来开发。\n\n**1. 表征相似性分析（RSA）的基本原理**\n\nRSA 的核心目标是通过对单个神经元或体素的特定活动模式进行抽象，来刻画神经反应群体中所表征的信息。这是通过计算表征非相似性矩阵（RDM）来实现的。RDM 是一个方形对称矩阵，总结了一组实验条件下大脑反应之间的两两非相似性。\n\n对于 $n$ 个条件，RDM 表示为 $D \\in \\mathbb{R}^{n \\times n}$，其元素为 $D_{ij} = \\delta(\\mathbf{x}_i, \\mathbf{x}_j)$，其中 $\\mathbf{x}_i$ 和 $\\mathbf{x}_j$ 分别是条件 $i$ 和 $j$ 的神经反应模式，$\\delta$ 是选定的非相似性度量。本问题指定使用欧几里得距离 $\\delta(\\mathbf{x}_i, \\mathbf{x}_j) = \\|\\mathbf{x}_i - \\mathbf{x}_j\\|_2$，这是一种常见且直观的选择，用于测量高维神经激活空间中响应向量之间的距离。对角线元素 $D_{ii}$ 恒为 $0$，因为一个模式与自身的非相似性为零。\n\n**2. 比较表征几何**\n\nRSA 通过比较不同表征空间（例如，计算模型和大脑数据）各自的 RDM 来评估它们之间的一致性。为了进行这种比较，我们首先将每个 RDM 的上三角部分线性化为一个向量。对于一个 $n \\times n$ 的 RDM，这个向量包含 $m = \\frac{n(n-1)}{2}$ 个唯一的两两非相似性值。设这些向量为 $v^{\\text{model}}$ 和 $v^{\\text{brain}}$。\n\n本问题要求使用斯皮尔曼等级相关 $\\rho(v^{\\text{model}}, v^{\\text{brain}})$。这种非参数统计量衡量了秩转换后非相似性值之间单调关系的强度和方向。使用它的优点在于它对异常值具有鲁棒性，并且不假设模型和大脑的非相似性之间存在线性关系，这使其成为一个灵活的工具，可用于比较可能在尺度上不同但共享相似非相似性等级排序的表征几何。\n\n**3. 通过置换检验进行统计推断**\n\n为了确定观测到的相关性 $r_{\\text{obs}}$ 是否具有统计显著性，我们必须将其与一个零分布进行比较。本问题指定使用置换检验，这是一种用于假设检验的强大的非参数方法。\n\n零假设 $H_0$ 假定模型的表征结构与大脑的表征结构之间没有系统性关系。在 $H_0$ 下，大脑数据上的条件标签是可交换的；任何观测到的相关性都纯粹是偶然产生的。\n\n置换检验通过重复重排大脑数据的条件标签来模拟这一零假设。在算法上，这是通过对大脑 RDM $D_{\\text{brain}}$ 的索引 $\\{0, 1, \\dots, n-1\\}$ 应用一个随机置换 $\\pi$ 来实现的。置换后的 RDM $D'_{\\text{brain}}$ 的元素为 $(D'_{\\text{brain}})_{ij} = (D_{\\text{brain}})_{\\pi(i)\\pi(j)}$。对于 $B$ 次这样的置换中的每一次，我们从置换后的 RDM 中提取上三角向量，并计算一个“零”斯皮尔曼相关系数 $r_{\\text{perm},b}$，其中 $b \\in \\{1, \\dots, B\\}$。\n\n**4. 双侧 p 值的计算**\n\n零相关系数的集合 $\\{r_{\\text{perm},b}\\}_{b=1}^B$ 构成了一个经验零分布。本问题要求进行双侧检验，该检验评估观测到的相关性是否显著不为零，而不论其符号（正或负）。这是通过将观测相关性的绝对值 $|r_{\\text{obs}}|$ 与零相关性的绝对值 $|r_{\\text{perm},b}|$ 进行比较来完成的。\n\n$p$ 值计算为产生至少与观测值一样极端的相关的置换比例。指定的公式是：\n$$\np = \\frac{1 + \\sum_{b=1}^B \\mathbf{1}\\left(|r_{\\text{perm},b}| \\ge |r_{\\text{obs}}|\\right)}{B+1}\n$$\n这里，$\\mathbf{1}(\\cdot)$ 是指示函数，如果其参数为真则为 $1$，否则为 $0$。分子中的“$1+$”和分母中的“$B+1$”代表了连续性校正。这将观测到的统计量本身视为来自零分布的一个样本，确保了 $p$ 值界于 $\\frac{1}{B+1}$ 和 $1$ 之间，并且即使在没有置换统计量比观测统计量更极端的情况下也是有效的。\n\n**5. 算法实现**\n\n实现将通过系统地处理每个测试用例来进行，步骤如下：\n\n1.  **数据生成**：对于每个用例，我们生成模型特征矩阵 $M$ 和大脑数据矩阵 $X$。对于用例 1、3 和 4，大脑数据 $X$ 构建为 $X = M W + \\text{noise}$，其中权重矩阵 $W$ 和噪声项是使用指定的随机种子从正态分布生成的，以确保可复现性。对于用例 2，$X$ 是独立于 $M$ 生成的，也使用指定的种子。\n\n2.  **RDM 构建**：一个函数将使用欧几里得距离从输入的 $n \\times d$ 数据矩阵计算 $n \\times n$ 的 RDM。然后，该函数将提取 $m = \\frac{n(n-1)}{2}$ 个上三角元素到一个向量中。\n\n3.  **观测相关性**：计算模型 RDM 向量 $v^{\\text{model}}$ 和大脑 RDM 向量 $v^{\\text{brain}}$。然后根据这两个向量计算观测到的斯皮尔曼相关系数 $r_{\\text{obs}}$。\n\n4.  **置换循环**：\n    a. 使用用例指定的置换种子来初始化一个随机数生成器。\n    b. 循环运行 $B$ 次。在每次迭代中，生成一个 $n$ 个条件索引的随机置换。\n    c. 将此置换应用于大脑 RDM $D_{\\text{brain}}$ 的行和列，以创建一个置换后的 RDM $D'_{\\text{brain}}$。\n    d. 提取 $D'_{\\text{brain}}$ 的上三角向量，并计算其与原始（固定）$v^{\\text{model}}$ 的斯皮尔曼相关性，从而得到一个 $r_{\\text{perm}}$。\n\n5.  **p 值计算**：循环结束后，计算 $|r_{\\text{perm}}| \\ge |r_{\\text{obs}}|$ 的置换次数。该计数加 $1$ 后，除以 $B+1$，得到该测试用例的最终双侧 $p$ 值。\n\n此过程将对所有 4 个指定的测试用例重复进行，并将得到的 $p$ 值收集并格式化为所需的输出。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.spatial.distance import pdist, squareform\nfrom scipy.stats import spearmanr\n\ndef solve():\n    \"\"\"\n    Main function to run all test cases for Representational Similarity Analysis.\n    \"\"\"\n\n    def compute_rdm_and_vector(data_matrix):\n        \"\"\"\n        Computes the RDM using Euclidean distance and returns the upper-triangular vector.\n        \n        Args:\n            data_matrix (np.ndarray): An (n_conditions x n_features) matrix.\n        \n        Returns:\n            tuple: A tuple containing:\n                - rdm (np.ndarray): The n_conditions x n_conditions RDM.\n                - rdm_vec (np.ndarray): The flattened upper-triangular vector of the RDM.\n        \"\"\"\n        if data_matrix.shape[0]  2:\n            return np.array([[]]), np.array([])\n            \n        distances = pdist(data_matrix, metric='euclidean')\n        rdm = squareform(distances)\n        \n        n_conditions = data_matrix.shape[0]\n        # Get indices for the upper triangle, excluding the diagonal (k=1)\n        triu_indices = np.triu_indices(n_conditions, k=1)\n        rdm_vec = rdm[triu_indices]\n        \n        return rdm, rdm_vec\n\n    def run_rsa_permutation_test(model_features, brain_patterns, n_permutations, perm_seed):\n        \"\"\"\n        Performs the full RSA permutation test for a given model and brain data.\n\n        Args:\n            model_features (np.ndarray): The model's feature matrix (n_conditions x d_model).\n            brain_patterns (np.ndarray): The brain data matrix (n_conditions x n_voxels).\n            n_permutations (int): The number of permutations (B).\n            perm_seed (int): The seed for the permutation random number generator.\n\n        Returns:\n            float: The two-sided permutation p-value.\n        \"\"\"\n        n_conditions = model_features.shape[0]\n        \n        # 1. Compute RDMs and upper-triangular vectors\n        model_rdm, v_model = compute_rdm_and_vector(model_features)\n        brain_rdm, v_brain = compute_rdm_and_vector(brain_patterns)\n        \n        # 2. Compute observed Spearman correlation\n        if v_model.size == 0 or v_brain.size == 0:\n            return 1.0 # Cannot compute correlation\n        r_obs, _ = spearmanr(v_model, v_brain)\n        \n        # 3. Perform permutation test\n        rng_perm = np.random.default_rng(perm_seed)\n        n_exceeding = 0\n        \n        for _ in range(n_permutations):\n            # Generate a permutation of condition labels\n            perm_indices = rng_perm.permutation(n_conditions)\n            \n            # Permute the brain RDM by reordering rows and columns\n            permuted_brain_rdm = brain_rdm[perm_indices][:, perm_indices]\n            \n            # Get the upper-triangular vector of the permuted RDM\n            triu_indices = np.triu_indices(n_conditions, k=1)\n            v_brain_perm = permuted_brain_rdm[triu_indices]\n            \n            # Compute the null correlation\n            r_perm, _ = spearmanr(v_model, v_brain_perm)\n            \n            # Compare absolute values for a two-sided test\n            if abs(r_perm) = abs(r_obs):\n                n_exceeding += 1\n        \n        # 4. Compute the p-value with continuity correction\n        p_value = (1 + n_exceeding) / (1 + n_permutations)\n        \n        return p_value\n\n    test_cases = [\n        # Case 1 (aligned model and brain; cluster structure)\n        {\n            \"n\": 8, \"v\": 50, \"d\": 2, \"B\": 2000,\n            \"model_features_coords\": [\n                (0.0, 0.0), (0.0, 0.5), (0.5, 0.0), (0.5, 0.5),\n                (3.0, 3.0), (3.0, 3.5), (3.5, 3.0), (3.5, 3.5)\n            ],\n            \"gen_brain\": {\n                \"method\": \"linear_map\",\n                \"W_seed\": 42, \"noise_sigma\": 0.3, \"noise_seed\": 24\n            },\n            \"perm_seed\": 1001\n        },\n        # Case 2 (null case; independent brain patterns)\n        {\n            \"n\": 8, \"v\": 50, \"d\": 2, \"B\": 2000,\n            \"model_features_coords\": [\n                (0.0, 0.0), (0.0, 0.5), (0.5, 0.0), (0.5, 0.5),\n                (3.0, 3.0), (3.0, 3.5), (3.5, 3.0), (3.5, 3.5)\n            ],\n            \"gen_brain\": {\n                \"method\": \"independent_normal\",\n                \"X_seed\": 99\n            },\n            \"perm_seed\": 2002\n        },\n        # Case 3 (boundary case; minimal number of conditions)\n        {\n            \"n\": 3, \"v\": 30, \"d\": 1, \"B\": 1000,\n            \"model_features_coords\": [[0], [1], [2]],\n            \"gen_brain\": {\n                \"method\": \"linear_map\",\n                \"W_seed\": 7, \"noise_sigma\": 0.05, \"noise_seed\": 31\n            },\n            \"perm_seed\": 3003\n        },\n        # Case 4 (tied distances in the model RDM; categorical structure)\n        {\n            \"n\": 6, \"v\": 40, \"d\": 1, \"B\": 2000,\n            \"model_features_coords\": [[0], [0], [0], [1], [1], [1]],\n            \"gen_brain\": {\n                \"method\": \"linear_map\",\n                \"W_seed\": 123, \"noise_sigma\": 0.1, \"noise_seed\": 321\n            },\n            \"perm_seed\": 4004\n        }\n    ]\n\n    p_values = []\n    \n    for case in test_cases:\n        # Generate Model Features\n        M = np.array(case[\"model_features_coords\"])\n        \n        # Generate Brain Patterns\n        n, v, d = case[\"n\"], case[\"v\"], case[\"d\"]\n        gen_params = case[\"gen_brain\"]\n        \n        if gen_params[\"method\"] == \"linear_map\":\n            rng_w = np.random.default_rng(gen_params[\"W_seed\"])\n            W = rng_w.standard_normal(size=(d, v))\n            \n            rng_noise = np.random.default_rng(gen_params[\"noise_seed\"])\n            noise = rng_noise.normal(loc=0, scale=gen_params[\"noise_sigma\"], size=(n, v))\n            \n            X = M @ W + noise\n        elif gen_params[\"method\"] == \"independent_normal\":\n            rng_x = np.random.default_rng(gen_params[\"X_seed\"])\n            X = rng_x.standard_normal(size=(n, v))\n\n        # Run the permutation test\n        p_val = run_rsa_permutation_test(M, X, case[\"B\"], case[\"perm_seed\"])\n        p_values.append(p_val)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, p_values))}]\")\n\nsolve()\n\n```"
        }
    ]
}