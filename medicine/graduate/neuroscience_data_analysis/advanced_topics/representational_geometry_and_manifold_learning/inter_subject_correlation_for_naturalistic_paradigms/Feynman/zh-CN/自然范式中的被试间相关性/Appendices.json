{
    "hands_on_practices": [
        {
            "introduction": "掌握被试间相关性 (Inter-Subject Correlation, ISC) 分析的第一步是理解其基本计算方法和统计评估的逻辑。本练习提供了一个具体的场景——两名被试观看同一部电影——让你能从基本的汇总统计数据开始，亲手计算 ISC 值 。更重要的是，你将学习如何参照一个通过置换检验生成的零分布来评估其统计显著性，为后续更复杂的应用打下坚实的基础。",
            "id": "4170720",
            "problem": "两名参与者在接受功能性磁共振成像扫描的同时，观看了同一部自然主义电影。在对自然主义刺激进行标准预处理（包括运动回归、高通滤波和移除低阶趋势）后，从单个皮层区域提取了每位参与者在 $T=120$ 个时间点上的局部血氧水平依赖（BOLD）时间序列。设预处理后的时间序列为 $\\{x_t\\}_{t=1}^{T}$ 和 $\\{y_t\\}_{t=1}^{T}$。被试间相关性（Inter-Subject Correlation, ISC）定义为两名参与者时间序列之间随时间计算的皮尔逊相关系数。\n\n给定从预处理时间序列中计算出的充分统计量：\n- $\\sum_{t=1}^{T} x_t = 0$ 且 $\\sum_{t=1}^{T} y_t = 0$，\n- $\\sum_{t=1}^{T} x_t^2 = 120$ 且 $\\sum_{t=1}^{T} y_t^2 = 120$，\n- $\\sum_{t=1}^{T} x_t y_t = 41.4$。\n\n使用循环时间平移零假设程序来近似ISC的机遇分布，同时保留每个序列的自相关性：将一个序列进行循环平移，平移的延迟跨越整个时长（不包括零延迟对齐），从而产生 $K=1000$ 个代理对齐。得到的代理ISC值的经验均值为 $\\mu_0 = 0$，经验标准差为 $\\sigma_0 = 0.08$。为了进行推断，假设代理分布服从高斯近似。\n\n任务：\n1) 仅使用样本协方差和皮尔逊相关的定义，根据提供的充分统计量计算两名被试之间的ISC。报告保留四位有效数字的ISC值。\n2) 使用零分布参数 $\\mu_0$ 和 $\\sigma_0$，计算观测到的ISC的单尾 $z$-分数，并判断在显著性水平 $\\alpha = 0.05$（单尾）下，观测到的同步性是否反映了超出机遇水平的共享处理。请证明你的解释；这部分的最终答案无需报告数值。\n\n最终答案仅需写出ISC的数值（无单位）。",
            "solution": "对于在相同自然主义刺激下记录的两个时间序列 $\\{x_t\\}$ 和 $\\{y_t\\}$，其被试间相关性（ISC）是随时间计算的皮尔逊相关系数。从基本定义出发，$x$ 和 $y$ 之间的样本协方差为\n$$\n\\operatorname{cov}(x,y) \\;=\\; \\frac{1}{T-1} \\sum_{t=1}^{T} \\big(x_t - \\bar{x}\\big)\\big(y_t - \\bar{y}\\big),\n$$\n其中 $\\bar{x} = \\frac{1}{T}\\sum_{t=1}^{T} x_t$ 和 $\\bar{y} = \\frac{1}{T}\\sum_{t=1}^{T} y_t$ 是样本均值。样本方差为\n$$\ns_x^2 \\;=\\; \\frac{1}{T-1} \\sum_{t=1}^{T} \\big(x_t - \\bar{x}\\big)^2, \n\\qquad\ns_y^2 \\;=\\; \\frac{1}{T-1} \\sum_{t=1}^{T} \\big(y_t - \\bar{y}\\big)^2.\n$$\n因此，皮尔逊相关系数为\n$$\nr \\;=\\; \\frac{\\operatorname{cov}(x,y)}{s_x s_y}\n\\;=\\;\n\\frac{\\sum_{t=1}^{T} \\big(x_t - \\bar{x}\\big)\\big(y_t - \\bar{y}\\big)}{\\sqrt{\\left[\\sum_{t=1}^{T} \\big(x_t - \\bar{x}\\big)^2\\right]\\left[\\sum_{t=1}^{T} \\big(y_t - \\bar{y}\\big)^2\\right]}}.\n$$\n\n给定 $\\sum_{t=1}^{T} x_t = 0$ 且 $\\sum_{t=1}^{T} y_t = 0$，可得 $\\bar{x} = 0$ 和 $\\bar{y} = 0$。因此，\n$$\n\\sum_{t=1}^{T} \\big(x_t - \\bar{x}\\big)^2 \\;=\\; \\sum_{t=1}^{T} x_t^2 \\;=\\; 120,\n\\qquad\n\\sum_{t=1}^{T} \\big(y_t - \\bar{y}\\big)^2 \\;=\\; \\sum_{t=1}^{T} y_t^2 \\;=\\; 120,\n$$\n和\n$$\n\\sum_{t=1}^{T} \\big(x_t - \\bar{x}\\big)\\big(y_t - \\bar{y}\\big) \\;=\\; \\sum_{t=1}^{T} x_t y_t \\;=\\; 41.4.\n$$\n因此ISC为\n$$\nr \\;=\\; \\frac{41.4}{\\sqrt{120 \\times 120}} \\;=\\; \\frac{41.4}{120} \\;=\\; 0.345.\n$$\n保留四位有效数字，ISC为 $0.3450$。\n\n为了解释在自然主义刺激下，该ISC是否反映了超出机遇水平的共享处理，我们使用循环时间平移零分布。该零分布通过将一个序列相对于另一个进行循环平移来保留每个序列的自相关结构，这对于在连续刺激期间记录的时间序列非常重要，并且它近似了由机遇性时间对齐所预期的ISC分布。\n\n在零均值 $\\mu_0 = 0$ 和零标准差 $\\sigma_0 = 0.08$ 的高斯近似下，观测到的ISC的单尾 $z$-分数为\n$$\nz \\;=\\; \\frac{r - \\mu_0}{\\sigma_0} \\;=\\; \\frac{0.345 - 0}{0.08} \\;=\\; 4.3125.\n$$\n在标准正态分布下单尾 $p$-值为\n$$\np \\;=\\; 1 - \\Phi(z),\n$$\n其中 $\\Phi(\\cdot)$ 是标准正态分布的累积分布函数。对于 $z = 4.3125$，$p$ 的数量级为 $10^{-5}$，具体约为 $8 \\times 10^{-6}$。在 $\\alpha = 0.05$（单尾）的显著性水平下，这个值远低于阈值，表明观测到的ISC远高于机遇水平，并且与两名参与者对自然主义电影的共享处理相一致。\n\n从概念上讲，这与自然主义范式中被试间相关性分析的范围相符：一个正向且统计显著的ISC表明，与时间锁定的、由刺激诱发的神经动力学在个体间是共享的，其程度超出了自相关或由循环平移零模型捕获的其他特异性波动所能预期的水平。",
            "answer": "$$\\boxed{0.3450}$$"
        },
        {
            "introduction": "在真实的神经影像数据中，我们测量的信号往往混合了与研究无关的“混淆”信号，例如由眼球运动或头部微动引起的信号，这些信号可能人为地抬高或压低被试间的同步性。本练习引入了部分被试间相关性 (Partial ISC) 的概念，通过线性回归的方法在计算相关性之前剔除这些混淆变量的影响 。通过这个练习，你将学会如何获得对刺激驱动的神经同步性更精确的估计。",
            "id": "4170718",
            "problem": "您将执行一项神经科学数据分析领域的计算任务，该任务专注于自然范式下的主体间相关（Inter-Subject Correlation, ISC）。目标是在一个模拟的视觉皮层环境中计算原始ISC和偏ISC，其中偏ISC通过线性回归控制眼动协变量。计算必须从第一性原理出发，并以纯粹的数学和算法术语来表达。主体间相关（ISC）定义为所有唯一被试对之间相关性的平均值。\n\n请使用以下基本原理进行推导和实现：\n- 皮尔逊相关性计算于零均值信号之间，用于量化线性关联。\n- 普通最小二乘回归通过将响应正交投影到协变量子空间的补集上来产生残差。\n- 控制了协变量后，两个变量之间的偏相关可以通过对其回归残差进行相关性计算来得出。\n\n所有三角函数的角度单位均为弧度。不涉及任何物理单位。所有最终数值输出必须报告为四舍五入到 $6$ 位小数的小数。\n\n任务：\n1. 对于下方的每个测试用例，根据所提供的参数构建各被试的视觉皮层时间序列和眼动协变量。\n2. 计算原始ISC，即被试视觉皮层时间序列之间所有成对皮尔逊相关性的平均值。\n3. 计算偏ISC，即在每个被试减去眼动协变量和截距的回归效应后，其残差时间序列之间所有成对皮尔逊相关性的平均值。\n4. 如果任何被试的残差时间序列方差为零，为保持结果的适定性，按惯例将涉及该被试的任何配对的相关性定义为 $0$。\n\n测试套件定义（每个测试用例均由数学参数完全指定，并且必须确定性地生成；所有三角函数输入角度均为弧度）：\n\n设 $t \\in \\{0,1,\\ldots,T-1\\}$ 为离散时间指数。\n\n- 在指定情况下使用的共同刺激分量：\n  $s(t) = \\sin\\left(\\frac{2\\pi t}{12}\\right) + 0.5 \\sin\\left(\\frac{2\\pi t}{6}\\right)$。\n\n- 被试 $i$ 的协变量：\n  $c^{(1)}_i(t)$ 和 $c^{(2)}_i(t)$ 按各用例指定。\n  被试 $i$ 的响应构建如下：\n  $y_i(t) = \\alpha_i \\, s(t) + \\gamma_i \\, c^{(1)}_i(t) + \\delta_i \\, c^{(2)}_i(t) + \\varepsilon_i(t)$,\n  其中 $\\varepsilon_i(t)$ 是按规定方式确定的噪声。\n\n测试套件：\n- 用例 A（典型情况；眼动是显著的、被试特异性的混杂因素）：\n  - 被试数量 $n = 4$，时间点 $T = 60$。\n  - 对所有被试，使用共同刺激 $s(t)$。\n  - 协变量：\n    $c^{(1)}_i(t) = \\sin\\left(\\frac{2\\pi t}{10} + \\phi_i\\right)$, \n    $c^{(2)}_i(t) = \\cos\\left(\\frac{2\\pi t}{15} + \\psi_i\\right)$.\n  - 相位：\n    $\\phi = [0.0, 0.3, -0.2, 0.5]$, \n    $\\psi = [0.1, -0.1, 0.2, -0.3]$.\n  - 系数：\n    $\\alpha = [1.00, 0.90, 1.10, 1.05]$, \n    $\\gamma = [0.80, 0.70, 0.75, 0.85]$, \n    $\\delta = [0.60, 0.65, 0.55, 0.60]$.\n  - 噪声：\n    $\\varepsilon_i(t) = 0.1 \\sin\\left(\\frac{2\\pi t}{7} + \\theta_i\\right)$ with \n    $\\theta = [0.0, 0.4, -0.5, 0.2]$.\n\n- 用例 B（协变量与响应正交；偏ISC约等于原始ISC）：\n  - 被试数量 $n = 3$，时间点 $T = 60$。\n  - 对所有被试，使用共同刺激 $s(t)$。\n  - 协变量：\n    $c^{(1)}_i(t) = \\sin\\left(\\frac{2\\pi t}{9} + \\phi_i\\right)$, \n    $c^{(2)}_i(t) = \\cos\\left(\\frac{2\\pi t}{11} + \\psi_i\\right)$.\n  - 相位：\n    $\\phi = [0.2, -0.3, 0.4]$, \n    $\\psi = [-0.2, 0.1, -0.4]$.\n  - 系数：\n    $\\alpha = [1.00, 0.80, 1.20]$, \n    $\\gamma = [0.00, 0.00, 0.00]$, \n    $\\delta = [0.00, 0.00, 0.00]$.\n  - 噪声：\n    $\\varepsilon_i(t) = 0.05 \\sin\\left(\\frac{2\\pi t}{13} + \\theta_i\\right)$ with \n    $\\theta = [0.1, -0.2, 0.3]$.\n\n- 用例 C（边界情况；协变量存在完全共线性；响应完全由协变量解释；所有被试的协变量相同）：\n  - 被试数量 $n = 3$，时间点 $T = 60$。\n  - 无刺激：对所有 $t$ 设置 $s(t) = 0$。\n  - 所有被试的协变量相同：\n    $c^{(1)}(t) = \\sin\\left(\\frac{2\\pi t}{8}\\right)$, \n    $c^{(2)}(t) = 2\\, c^{(1)}(t)$.\n    对所有被试 $i$，设置 $c^{(1)}_i(t) = c^{(1)}(t)$ 且 $c^{(2)}_i(t) = c^{(2)}(t)$。\n  - 系数：\n    $\\gamma = [0.50, 0.90, 0.70]$, \n    $\\delta = [1.00, 1.80, 1.40]$.\n  - 噪声：\n    $\\varepsilon_i(t) = 0$ for all $i,t$.\n\n算法要求：\n- 在每个用例中，对每个被试，将 $y_i(t)$ 对一个截距和该被试的两个协变量进行最小二乘回归，以获得残差 $r_i(t)$。\n- 计算原始ISC，即在所有时间点 $t$ 上，$\\{y_i(t)\\}$（$i=1,\\ldots,n$）之间所有成对相关性的平均值。\n- 计算偏ISC，即 $\\{r_i(t)\\}$ 之间所有成对相关性的平均值。\n- 如果一对中任何被试的序列方差为零，则将该对的相关性定义为 $0$。\n\n您的程序应生成单行输出，其中包含按以下格式汇总的三个用例的结果：\n- 一个用方括号括起来的逗号分隔列表，其值按 $[\\text{raw\\_A}, \\text{partial\\_A}, \\text{raw\\_B}, \\text{partial\\_B}, \\text{raw\\_C}, \\text{partial\\_C}]$ 的顺序排列。\n- 每个值都必须是四舍五入到 $6$ 位小数的小数。\n\n不允许用户输入；所有值必须使用指定的参数在内部生成。",
            "solution": "该问题是有效的，因为它在科学上基于统计方法，所有必要参数均已定义，问题是适定的，且其表述是客观的。任务是针对三个不同的测试用例，计算模拟神经科学数据的原始和偏主体间相关（ISC）。\n\n解决方案是根据第一性原理开发的，遵循皮尔逊相关、普通最小二乘（OLS）回归和偏相关的数学定义。\n\n**1. 数学基础**\n\n**1.1. 皮尔逊相关系数**\n皮尔逊相关系数 $\\rho$ 用于量化两个长度为 $T$ 的时间序列向量 $\\mathbf{u}$ 和 $\\mathbf{v}$ 之间的线性关系。其计算方法是用两个变量的协方差除以它们标准差的乘积。对于两个离散时间序列 $u(t)$ 和 $v(t)$，其中 $t \\in \\{0, 1, \\ldots, T-1\\}$，公式为：\n$$ \\rho_{\\mathbf{u},\\mathbf{v}} = \\frac{\\sum_{t=0}^{T-1} (u(t) - \\bar{u})(v(t) - \\bar{v})}{\\sqrt{\\sum_{t=0}^{T-1} (u(t) - \\bar{u})^2} \\sqrt{\\sum_{t=0}^{T-1} (v(t) - \\bar{v})^2}} $$\n其中 $\\bar{u}$ 和 $\\bar{v}$ 分别是时间序列的均值。如果任一时间序列的方差为零（即其标准差为 $0$），则相关性未定义。根据问题规范，在这种情况下我们将相关性定义为 $0$。\n\n**1.2. 普通最小二乘（OLS）回归与残差**\n为了控制协变量的影响，我们使用OLS回归。对于给定的被试 $i$，我们将其响应时间序列 $\\mathbf{y}_i$ 建模为协变量和截距的线性组合。模型为：\n$$ y_i(t) = \\beta_0 + \\beta_1 c^{(1)}_i(t) + \\beta_2 c^{(2)}_i(t) + r_i(t) $$\n用矩阵形式表示为 $\\mathbf{y}_i = X_i \\boldsymbol{\\beta}_i + \\mathbf{r}_i$，其中：\n- $\\mathbf{y}_i$ 是 $(T \\times 1)$ 的响应向量。\n- $X_i$ 是 $(T \\times 3)$ 的设计矩阵。其列分别为一个全为1的向量（用于截距 $\\beta_0$）、第一个协变量向量 $\\mathbf{c}^{(1)}_i$ 和第二个协变量向量 $\\mathbf{c}^{(2)}_i$。\n- $\\boldsymbol{\\beta}_i$ 是 $(3 \\times 1)$ 的回归系数向量。\n- $\\mathbf{r}_i$ 是 $(T \\times 1)$ 的残差向量，代表 $\\mathbf{y}_i$ 中未被线性模型解释的部分。\n\n系数的OLS估计值 $\\hat{\\boldsymbol{\\beta}}_i$ 是通过最小化残差平方和求得的。解由以下公式给出：\n$$ \\hat{\\boldsymbol{\\beta}}_i = (X_i^T X_i)^{+} X_i^T \\mathbf{y}_i $$\n其中 $(X_i^T X_i)^{+}$ 是 $X_i^T X_i$ 的 Moore-Penrose 伪逆。使用伪逆可以确保即使在 $X_i$ 的列是共线的情况下（如用例 C），也能得到唯一解。\n\n然后，残差向量通过计算实际响应与预测响应之间的差值得到：\n$$ \\mathbf{r}_i = \\mathbf{y}_i - X_i \\hat{\\boldsymbol{\\beta}}_i $$\n\n**1.3. 偏相关与主体间相关（ISC）**\n两个变量之间的偏相关是在回归掉一个或多个控制变量后，它们残差之间的相关性。在此问题中，偏ISC是基于OLS回归得到的残差 $\\mathbf{r}_i$ 计算的。\n\nISC 定义为所有唯一被试对之间相关性的平均值。对于 $n$ 个被试，存在 $\\binom{n}{2} = \\frac{n(n-1)}{2}$ 个唯一的对。\n- **原始ISC**：原始响应时间序列 $\\{\\mathbf{y}_i\\}$ 之间的成对皮尔逊相关性的平均值。\n$$ \\text{ISC}_{\\text{raw}} = \\frac{1}{\\binom{n}{2}} \\sum_{1 \\le i  j \\le n} \\rho(\\mathbf{y}_i, \\mathbf{y}_j) $$\n- **偏ISC**：残差时间序列 $\\{\\mathbf{r}_i\\}$ 之间的成对皮尔逊相关性的平均值。\n$$ \\text{ISC}_{\\text{partial}} = \\frac{1}{\\binom{n}{2}} \\sum_{1 \\le i  j \\le n} \\rho(\\mathbf{r}_i, \\mathbf{r}_j) $$\n\n**2. 算法步骤**\n\n对于每个测试用例（A、B 和 C），将通过执行以下步骤来计算解：\n\n1.  **数据生成**：对于测试用例中的每个被试 $i=1, \\ldots, n$：\n    a. 生成离散时间向量 $t = [0, 1, \\ldots, T-1]$。\n    b. 根据特定用例的公式和参数，生成共同刺激 $s(t)$、被试特异性协变量 $c^{(1)}_i(t)$ 和 $c^{(2)}_i(t)$，以及噪声 $\\varepsilon_i(t)$。\n    c. 构建被试的完整响应时间序列 $y_i(t) = \\alpha_i s(t) + \\gamma_i c^{(1)}_i(t) + \\delta_i c^{(2)}_i(t) + \\varepsilon_i(t)$。\n\n2.  **原始ISC计算**：\n    a. 收集所有响应时间序列向量的集合 $\\{\\mathbf{y}_1, \\ldots, \\mathbf{y}_n\\}$。\n    b. 遍历所有唯一的被试对 $(i, j)$，其中 $i  j$。\n    c. 对于每对，计算皮尔逊相关性 $\\rho(\\mathbf{y}_i, \\mathbf{y}_j)$。\n    d. 计算原始ISC，作为这些成对相关性的算术平均值。\n\n3.  **偏ISC计算**：\n    a. 对于每个被试 $i=1, \\ldots, n$：\n        i. 构建设计矩阵 $X_i = [\\mathbf{1}, \\mathbf{c}^{(1)}_i, \\mathbf{c}^{(2)}_i]$。\n        ii. 对 $\\mathbf{y}_i$ 和 $X_i$ 执行OLS回归，以找到系数估计值 $\\hat{\\boldsymbol{\\beta}}_i$。\n        iii. 计算残差向量 $\\mathbf{r}_i = \\mathbf{y}_i - X_i \\hat{\\boldsymbol{\\beta}}_i$。\n    b. 收集所有残差时间序列向量的集合 $\\{\\mathbf{r}_1, \\ldots, \\mathbf{r}_n\\}$。\n    c. 遍历所有唯一的被试对 $(i, j)$，其中 $i  j$。\n    d. 对于每对，计算皮尔逊相关性 $\\rho(\\mathbf{r}_i, \\mathbf{r}_j)$，并应用规则：如果任何残差向量的方差为零，则相关性为 $0$。\n    e. 计算偏ISC，作为这些成对残差相关性的算术平均值。\n\n**测试用例分析：**\n\n-   **用例 A**：一个标准场景，其中被试的响应是共同刺激和被试特异性混杂因素（眼动）的混合。我们预期原始ISC会因协变量的共享结构而被夸大。偏ISC通过移除这些协变量的影响，应该能得出一个更能代表由共同刺激 $s(t)$ 引起的相关性的值。\n\n-   **用例 B**：协变量的系数 $\\gamma$ 和 $\\delta$ 被设置为零。因此，协变量 $c^{(1)}_i$ 和 $c^{(2)}_i$ 对响应 $y_i$ 没有贡献。回归掉它们应该只有极小的影响。我们预期偏ISC将约等于原始ISC。\n\n-   **用例 C**：一个用于测试鲁棒性的边界情况。协变量是完全共线的（$c^{(2)}(t) = 2c^{(1)}(t)$），并且在所有被试中都是相同的。响应 $y_i(t)$ 被构造成这些协变量的线性组合，没有刺激或噪声。不同被试的原始响应将互为标量倍数，例如 $y_i(t) = k_i c^{(1)}(t)$，导致所有对之间存在完全相关性（$\\rho=1$）。因此，原始ISC预计为 $1.0$。OLS回归将完美拟合数据，导致每个被试的残差向量都为全零。一个零方差时间序列与任何其他序列的相关性定义为 $0$，所以所有残差的成对相关性都将是 $0$。因此，偏ISC预计为 $0.0$。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Computes raw and partial Inter-Subject Correlation (ISC) for three test cases.\n    \"\"\"\n\n    test_cases = [\n        {\n            \"name\": \"A\",\n            \"n\": 4, \"T\": 60,\n            \"s_active\": True,\n            \"phi\": [0.0, 0.3, -0.2, 0.5],\n            \"psi\": [0.1, -0.1, 0.2, -0.3],\n            \"alpha\": [1.00, 0.90, 1.10, 1.05],\n            \"gamma\": [0.80, 0.70, 0.75, 0.85],\n            \"delta\": [0.60, 0.65, 0.55, 0.60],\n            \"theta\": [0.0, 0.4, -0.5, 0.2],\n            \"noise_level\": 0.1,\n            \"c1_period\": 10, \"c2_period\": 15, \"noise_period\": 7,\n            \"c1_func\": np.sin, \"c2_func\": np.cos,\n        },\n        {\n            \"name\": \"B\",\n            \"n\": 3, \"T\": 60,\n            \"s_active\": True,\n            \"phi\": [0.2, -0.3, 0.4],\n            \"psi\": [-0.2, 0.1, -0.4],\n            \"alpha\": [1.00, 0.80, 1.20],\n            \"gamma\": [0.00, 0.00, 0.00],\n            \"delta\": [0.00, 0.00, 0.00],\n            \"theta\": [0.1, -0.2, 0.3],\n            \"noise_level\": 0.05,\n            \"c1_period\": 9, \"c2_period\": 11, \"noise_period\": 13,\n            \"c1_func\": np.sin, \"c2_func\": np.cos,\n        },\n        {\n            \"name\": \"C\",\n            \"n\": 3, \"T\": 60,\n            \"s_active\": False,\n            \"gamma\": [0.50, 0.90, 0.70],\n            \"delta\": [1.00, 1.80, 1.40],\n            \"noise_level\": 0.0,\n            \"c1_period\": 8,\n        }\n    ]\n\n    final_results = []\n\n    def pearson_correlation(x, y):\n        \"\"\"\n        Calculates Pearson correlation between two vectors.\n        Returns 0 if either vector has zero variance.\n        \"\"\"\n        x_std = np.std(x)\n        y_std = np.std(y)\n        \n        if x_std == 0 or y_std == 0:\n            return 0.0\n            \n        x_mean = np.mean(x)\n        y_mean = np.mean(y)\n        \n        x_centered = x - x_mean\n        y_centered = y - y_mean\n        \n        numerator = np.sum(x_centered * y_centered)\n        denominator = np.sqrt(np.sum(x_centered**2) * np.sum(y_centered**2))\n        \n        # This check is theoretically redundant given the std check, but safe.\n        if denominator == 0:\n            return 0.0\n            \n        return numerator / denominator\n\n    for case in test_cases:\n        n = case[\"n\"]\n        T = case[\"T\"]\n        \n        t = np.arange(T)\n        \n        if case[\"s_active\"]:\n            s = np.sin(2 * np.pi * t / 12) + 0.5 * np.sin(2 * np.pi * t / 6)\n        else:\n            s = np.zeros(T)\n\n        y_all_subjects = []\n        r_all_subjects = []\n\n        for i in range(n):\n            if case[\"name\"] == \"C\":\n                c1_i = np.sin(2 * np.pi * t / case[\"c1_period\"])\n                c2_i = 2 * c1_i\n                eps_i = np.zeros(T)\n                alpha_i = 0.0\n            else:\n                c1_i = case[\"c1_func\"](2 * np.pi * t / case[\"c1_period\"] + case[\"phi\"][i])\n                c2_i = case[\"c2_func\"](2 * np.pi * t / case[\"c2_period\"] + case[\"psi\"][i])\n                eps_i = case[\"noise_level\"] * np.sin(2 * np.pi * t / case[\"noise_period\"] + case[\"theta\"][i])\n                alpha_i = case[\"alpha\"][i]\n\n            gamma_i = case[\"gamma\"][i]\n            delta_i = case[\"delta\"][i]\n\n            y_i = alpha_i * s + gamma_i * c1_i + delta_i * c2_i + eps_i\n            y_all_subjects.append(y_i)\n            \n            # Perform OLS regression to find residuals\n            X = np.stack([np.ones(T), c1_i, c2_i], axis=1)\n            \n            # Use lstsq which handles multicollinearity via pseudo-inverse\n            beta_hat, _, _, _ = np.linalg.lstsq(X, y_i, rcond=None)\n            \n            y_i_predicted = X @ beta_hat\n            residuals = y_i - y_i_predicted\n            r_all_subjects.append(residuals)\n\n        # Compute raw and partial ISC\n        raw_correlations = []\n        partial_correlations = []\n        \n        num_pairs = 0\n        for i in range(n):\n            for j in range(i + 1, n):\n                num_pairs += 1\n                \n                # Raw correlation\n                raw_corr = pearson_correlation(y_all_subjects[i], y_all_subjects[j])\n                raw_correlations.append(raw_corr)\n                \n                # Partial correlation\n                partial_corr = pearson_correlation(r_all_subjects[i], r_all_subjects[j])\n                partial_correlations.append(partial_corr)\n        \n        raw_isc = np.mean(raw_correlations) if raw_correlations else 0.0\n        partial_isc = np.mean(partial_correlations) if partial_correlations else 0.0\n        \n        final_results.append(f\"{raw_isc:.6f}\")\n        final_results.append(f\"{partial_isc:.6f}\")\n\n    print(f\"[{','.join(final_results)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "被试间相关性分析的威力在于它能够应用于全脑范围，以探索在观看自然刺激时哪些脑区表现出跨被试的一致性活动。然而，在全脑数以万计的体素上同时进行统计检验，会极大地增加“假阳性”的风险。本练习将指导你如何应用伪发现率 (False Discovery Rate, FDR) 控制方法来解决多重比较问题，从而生成统计上稳健的全脑 ISC 图谱，这是解释全脑分析结果的一项关键技能 。",
            "id": "4170716",
            "problem": "给定来自自然主义范式下体素级主体间相关性 (ISC) 分析的合成但科学上合理的摘要统计数据。主体间相关性 (ISC) 量化了在共享刺激期间，每个体素上跨受试者的大脑时间序列响应的相似性，并且通常通过非参数程序（例如，循环时间平移）与零模型进行比较，以获得每个体素的 $p$ 值。任务是控制 $V$ 个体素的错误发现率 (FDR)，计算经校正的 $q$ 值（这些 $q$ 值相对于排序后的 $p$ 值的秩是单调的），然后使用提供的整数编码图谱报告显著解剖区域的集合。错误发现率 (FDR) 是在所有发现中假阳性所占的期望比例，并且必须在检验之间独立或正相关的条件下进行控制。对于每个体素，校正后的 $q$ 值应表示该体素被宣布为显著时所对应的最小 FDR 水平。\n\n使用的基本原理：\n- 用于 ISC 的 Pearson 相关性定义被假定为已知；但是，您在此不需要计算相关性。您将获得通过有效零程序得到的 $p$ 值。\n- 在独立或正相关条件下的错误发现率 (FDR) 控制将通过对排序后的 $p$ 值应用递升多重比较程序来实现，该程序生成跨秩单调的校正后 $q$ 值，并相对于选定的发现水平 $ \\alpha $ 做出显著性决策。\n- $p$ 值的顺序统计量：按升序值排序，关联秩，并强制校正后的 $q$ 值跨秩的单调性。\n\n您的程序必须：\n1. 对于每个测试用例，使用在独立或正相关条件下的 FDR 控制递升程序计算所有体素的校正后 $q$ 值，确保 $q$ 值随排序后 $p$ 值的秩非递减。\n2. 通过将校正后的 $q$ 值与指定的发现水平 $ \\alpha $ 进行比较，确定哪些体素是显著的。\n3. 通过汇总与显著体素对应的区域编码，并按升序对这些编码进行排序，报告显著解剖区域的集合。\n4. 仅输出区域的整数编码，而不是文本标签，以符合最终输出的约束。\n\n图谱编码：\n- 该图谱将每个体素映射到一个对应解剖标签的整数编码。提供整数到标签的映射是为了方便解释，但不得出现在最终的程序输出中。映射关系如下：\n  - $1$: 初级视觉皮层 (V1)\n  - $2$: 颞上回/听觉皮层\n  - $3$: 楔前叶/后内侧皮层\n  - $4$: 角回/颞顶联合区\n\n测试套件：\n每个测试用例指定了体素数量 $V$、一个包含 $V$ 个在 $[0,1]$ 范围内的 $p$ 值的列表、一个包含 $V$ 个图谱编码（整数）的列表，以及发现水平 $ \\alpha $。\n\n- 测试用例 A (理想路径，混合的 $p$ 值，多个区域，少量发现):\n  - $V = 10$\n  - $p$ 值: [$0.001$, $0.02$, $0.15$, $0.03$, $0.5$, $0.25$, $0.0005$, $0.04$, $0.8$, $0.07$]\n  - 图谱编码: [$1$, $1$, $2$, $2$, $3$, $3$, $1$, $4$, $4$, $2$]\n  - $ \\alpha = 0.05 $\n\n- 测试用例 B (包含 $0$ 和 $1$ 的边界小 $p$ 值以及存在相等值的边缘情况):\n  - $V = 8$\n  - $p$ 值: [$0.0$, $0.0001$, $0.049$, $0.051$, $0.2$, $0.3$, $1.0$, $0.0001$]\n  - 图谱编码: [$2$, $2$, $3$, $3$, $4$, $4$, $1$, $2$]\n  - $ \\alpha = 0.05 $\n\n- 测试用例 C (没有发现，所有 $p$ 值都很大):\n  - $V = 7$\n  - $p$ 值: [$0.3$, $0.4$, $0.6$, $0.9$, $0.2$, $0.7$, $0.55$]\n  - 图谱编码: [$1$, $2$, $3$, $4$, $1$, $2$, $3$]\n  - $ \\alpha = 0.05 $\n\n- 测试用例 D (边界值恰好在递升阈值上，跨区域有多个发现):\n  - $V = 12$\n  - $p$ 值: [$0.0166667$, $0.0208333$, $0.001$, $0.002$, $0.7$, $0.3$, $0.05$, $0.04$, $0.004$, $0.02$, $0.8$, $0.0005$]\n  - 图谱编码: [$1$, $1$, $2$, $2$, $3$, $3$, $4$, $4$, $2$, $3$, $4$, $1$]\n  - $ \\alpha = 0.05 $\n\n最终输出格式：\n- 您的程序应生成单行输出，其中包含一个由方括号括起来的、以逗号分隔的结果列表。\n- 每个测试用例的结果必须是一个整数列表，其中第一个整数是显著体素的数量，随后的整数是这些显著体素中经过排序的唯一区域编码。\n- 例如，输出应如下所示：”[[n_A,regionA1,regionA2,...],[n_B,regionB1,...],[n_C,...],[n_D,...]]”，其中 $n_X$ 表示测试用例 $X$ 中显著体素的数量。\n\n您的程序必须完全自包含，不得读取外部文件，也不需要用户输入。不涉及任何物理单位或角度。所有数值答案必须是整数、浮点数、布尔值或上述指定的这些类型的列表。程序必须计算校正后的 $q$ 值，并基于这些 $q$ 值推导显著性；不得通过直接对未经调整的 $p$ 值应用决策来走捷径。",
            "solution": "该问题要求在一组来自主体间相关性 (ISC) 分析的体素级统计检验中控制错误发现率 (FDR)。我们获得了每个体素的 $p$ 值、一个解剖图谱以及一个期望的 FDR 水平 $\\alpha$。任务是计算校正后的 $q$ 值，识别显著的体素，并报告显著体素的数量以及它们所在解剖区域的唯一的、经过排序的整数编码。\n\n首先，我们必须严格验证问题陈述。\n\n### 第 1 步：提取给定信息\n- **$V$**: 体素数量，等同于同时进行的统计检验的数量。\n- **$p$ 值**: 一个包含 $V$ 个在 $[0, 1]$ 范围内的浮点数的列表，代表每个体素上 ISC 的统计显著性。\n- **图谱编码**: 一个包含 $V$ 个整数的列表，其中每个整数将一个体素映射到一个特定的解剖区域。\n- **$\\alpha$**: 期望的错误发现率水平，用作校正后 $q$ 值的显著性阈值。\n- **图谱映射**:\n  - $1$: 初级视觉皮层 (V1)\n  - $2$: 颞上回/听觉皮层\n  - $3$: 楔前叶/后内侧皮层\n  - $4$: 角回/颞顶联合区\n- **程序要求**：使用递升多重比较程序在独立或正相关条件下控制 FDR，生成单调的校正后 $q$ 值。\n- **测试用例**：提供了四个具体的测试用例 (A, B, C, D)，包含所有必要的输入。\n- **输出格式**：一个单行字符串，表示一个列表的列表，例如 `[[n_A,regionA1,...],[n_B,regionB1,...],...]`，其中 $n_X$ 是测试用例 $X$ 的显著体素计数。\n\n### 第 2 步：使用提取的给定信息进行验证\n根据验证标准对问题进行评估：\n- **科学依据**：该问题在神经影像数据分析的标准实践中有充分的依据。ISC 是一种广泛使用的方法，而对体素级多重比较控制 FDR 是一个关键且典型的统计步骤。\n- **适定性**：该问题是适定的。它提供了所有必要的输入（$V$、$p$ 值、图谱编码、$\\alpha$），指定了明确的目标，并描述了一个标准的、可实现的程序（通过递升法控制 FDR）。这种结构确保了每个测试用例都存在唯一且有意义的解决方案。\n- **客观性**：该问题使用精确、客观和形式化的科学语言陈述。它没有歧义和主观性。\n\n该问题不存在任何无效性缺陷：\n1.  **科学或事实不健全**：所描述的程序与开创性的 Benjamini-Hochberg (BH) 方法一致，该方法是在独立或正相关条件下控制 FDR 的标准方法，正如问题所指定。\n2.  **不可形式化或不相关**：该任务是一个与指定主题相关的直接、可形式化的计算和统计问题。\n3.  **不完整或矛盾的设置**：计算所需的所有数据都已提供。没有矛盾之处。\n4.  **不切实际或不可行**：数据是合成的，但在这种分析的合理范围内，可作为算法的有效输入。\n5.  **不适定或结构不良**：程序定义明确。“递升程序”和“单调校正 q 值”指的是 FDR 控制的一个特定、标准的实现。\n6.  **伪深刻、琐碎或同义反复**：该问题需要一个涉及排序、计算、强制单调性和重新映射的多步骤算法，这是一个非琐碎的数据处理任务。\n7.  **超出科学可验证性范围**：计算过程是确定性的，其结果是完全可验证的。\n\n### 第 3 步：结论与行动\n该问题是**有效的**。将提供一个完整的、有理有据的解决方案。\n\n### 解决方案推导\n\n问题的核心是使用 Benjamini-Hochberg (BH) 程序计算经 FDR 校正的 $q$ 值，并确保所得的 $q$ 值是单调的。\n\n假设有 $V$ 个体素，对应 $V$ 个零假设，其相关的 $p$ 值为 $\\{p_1, p_2, \\dots, p_V\\}$。\n\n1.  **对 $p$ 值进行排序**：第一步是将 $p$ 值按升序排序：$p_{(1)} \\le p_{(2)} \\le \\dots \\le p_{(V)}$。我们必须跟踪每个 $p$ 值的原始索引，以便将最终结果映射回解剖图谱。设 $i$ 为排序后列表中 $p$ 值的秩，从 $i=1$ 到 $V$。\n\n2.  **计算 BH 校正值**：BH 程序将每个排序后的 $p$ 值 $p_{(i)}$ 与一个依赖其秩 $i$ 的阈值进行比较。如果 $p_{(i)} \\le \\frac{i}{V}\\alpha$，则该检验被宣布为显著。$q$ 值代表一个检验被判定为显著时的最小 $\\alpha$ 值。对于秩为 $i$ 的检验，其 $q$ 值的初始、未校正估计由下式给出：\n    $$q'_{(i)} = \\frac{p_{(i)} \\cdot V}{i}$$\n\n3.  **强制单调性**：问题明确要求校正后的 $q$ 值随排序后 $p$ 值的秩非递减。原始值 $q'_{(i)}$ 可能不满足此属性（即，对于 $i  j$ 可能出现 $q'_{(i)} > q'_{(j)}$ 的情况）。为强制单调性，我们从最大的秩开始，使用累积最小值来调整 $q$ 值。对于秩为 $i$ 的检验，其最终的校正后 $q$ 值，记为 $q_{(i)}$，定义为：\n    $$q_{(V)} = q'_{(V)} = p_{(V)}$$\n    $$q_{(i)} = \\min(q_{(i+1)}, q'_{(i)}) \\quad \\text{for } i = V-1, V-2, \\dots, 1$$\n    这等效于设置 $q_{(i)} = \\min_{j=i}^{V} \\left( \\frac{p_{(j)} \\cdot V}{j} \\right)$。这种“递升式”调整确保了 $q_{(1)} \\le q_{(2)} \\le \\dots \\le q_{(V)}$。\n\n4.  **识别显著体素**：为排序后的检验列表计算出单调的 $q$ 值后，我们必须将它们映射回其原始的体素位置。如果一个体素 $k$ 的校正后 $q$ 值 $q_k$ 满足以下条件，则该体素被宣布为显著：\n    $$q_k \\le \\alpha$$\n\n5.  **汇总结果**：一旦识别出显著体素的集合，我们对它们进行计数以得到 $n_{sig}$。然后，我们查找这些特定体素的图谱编码。最后一步是收集唯一的图谱编码，按升序排序，并将计数 $n_{sig}$ 添加到该列表的前面。对每个测试用例重复此过程。\n\n每个测试用例的总体算法如下：\n- 给定 $V$、一个 $p$ 值列表、一个图谱编码列表和 $\\alpha$。\n- 创建一个从 $0$ 到 $V-1$ 的原始索引记录。\n- 按升序对 $p$ 值进行排序，同时跟踪原始索引的排列。\n- 设排序后的 $p$ 值为 $p_{(i)}$，其中秩 $i=1, \\dots, V$。\n- 计算原始调整值 $q'_{(i)} = (p_{(i)} \\cdot V) / i$。\n- 通过从列表末尾（从秩 $V$ 向下到 $1$）取 $q'$ 的累积最小值，计算最终的单调 $q$ 值 $q_{(i)}$。\n- 创建一个新列表，用于按原始顺序存放最终的 $q$ 值。通过将每个 $q_{(i)}$ 放置在与 $p_{(i)}$ 对应的原始索引处来填充此列表。\n- 识别所有最终 $q_k \\le \\alpha$ 的索引 $k$。\n- 显著体素的数量 $n_{sig}$ 是此类索引的计数。\n- 收集与这些显著索引相对应的图谱编码。\n- 找到这些图谱编码的唯一集合并对其进行排序。\n- 构建最终结果列表：$[n_{sig}, \\text{排序后的唯一区域\\_1}, \\text{排序后的唯一区域\\_2}, \\dots]$。如果 $n_{sig}=0$，则列表仅为 $[0]$。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\n# Note: scipy is permitted but not necessary for this implementation.\n\ndef solve():\n    \"\"\"\n    Solves the FDR correction problem for the given test cases.\n    \"\"\"\n    \n    # Define the test cases from the problem statement.\n    test_cases = [\n        # Test Case A\n        {\n            \"V\": 10,\n            \"p_values\": [0.001, 0.02, 0.15, 0.03, 0.5, 0.25, 0.0005, 0.04, 0.8, 0.07],\n            \"atlas_codes\": [1, 1, 2, 2, 3, 3, 1, 4, 4, 2],\n            \"alpha\": 0.05\n        },\n        # Test Case B\n        {\n            \"V\": 8,\n            \"p_values\": [0.0, 0.0001, 0.049, 0.051, 0.2, 0.3, 1.0, 0.0001],\n            \"atlas_codes\": [2, 2, 3, 3, 4, 4, 1, 2],\n            \"alpha\": 0.05\n        },\n        # Test Case C\n        {\n            \"V\": 7,\n            \"p_values\": [0.3, 0.4, 0.6, 0.9, 0.2, 0.7, 0.55],\n            \"atlas_codes\": [1, 2, 3, 4, 1, 2, 3],\n            \"alpha\": 0.05\n        },\n        # Test Case D\n        {\n            \"V\": 12,\n            \"p_values\": [0.0166667, 0.0208333, 0.001, 0.002, 0.7, 0.3, 0.05, 0.04, 0.004, 0.02, 0.8, 0.0005],\n            \"atlas_codes\": [1, 1, 2, 2, 3, 3, 4, 4, 2, 3, 4, 1],\n            \"alpha\": 0.05\n        }\n    ]\n\n    results = []\n    \n    for case in test_cases:\n        V = case[\"V\"]\n        p_values = np.array(case[\"p_values\"])\n        atlas_codes = np.array(case[\"atlas_codes\"])\n        alpha = case[\"alpha\"]\n\n        # Step 1: Get the sorting order of p-values\n        # np.argsort provides the indices that would sort the array\n        sort_indices = np.argsort(p_values)\n        \n        # Step 2: Sort the p-values\n        p_values_sorted = p_values[sort_indices]\n        \n        # Step 3: Compute BH-adjusted q-values\n        # Create ranks from 1 to V\n        ranks = np.arange(1, V + 1)\n        # Calculate raw q-values: (p_sorted * V) / rank\n        q_values_raw_sorted = p_values_sorted * V / ranks\n        \n        # Step 4: Enforce monotonicity\n        # This is achieved by taking the cumulative minimum from the end of the list.\n        # A numpy-idiomatic way is to reverse the array, compute the cumulative min,\n        # and then reverse it back.\n        q_values_monotone_sorted = np.minimum.accumulate(q_values_raw_sorted[::-1])[::-1]\n        \n        # Step 5: Un-sort the q-values to match the original voxel order\n        # We need an array to store the q-values in their original order.\n        q_values_original_order = np.empty_like(p_values)\n        # The 'sort_indices' tells us where each sorted value came from.\n        # The inverse operation assigns the computed q-values back to their original positions.\n        q_values_original_order[sort_indices] = q_values_monotone_sorted\n        \n        # Step 6: Determine significance\n        significant_mask = q_values_original_order = alpha\n        \n        # Step 7: Count significant voxels\n        num_significant_voxels = np.sum(significant_mask)\n        \n        # Step 8: Report significant anatomical regions\n        if num_significant_voxels > 0:\n            significant_regions = atlas_codes[significant_mask]\n            # Get unique regions and sort them\n            unique_sorted_regions = sorted(list(np.unique(significant_regions)))\n            case_result = [num_significant_voxels] + unique_sorted_regions\n        else:\n            case_result = [0]\n            \n        results.append(case_result)\n\n    # Final print statement in the exact required format.\n    # The format requires stringifying each inner list and joining them with commas.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        }
    ]
}