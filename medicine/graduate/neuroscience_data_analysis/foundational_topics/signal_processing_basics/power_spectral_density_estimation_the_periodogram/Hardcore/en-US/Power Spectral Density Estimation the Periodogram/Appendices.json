{
    "hands_on_practices": [
        {
            "introduction": "A Power Spectral Density (PSD) provides a map of a signal's power distribution across frequency, but its units can be abstract. This exercise bridges the gap between the spectral representation and tangible signal characteristics . By integrating a realistic model of an alpha-band oscillation, you will derive the band-limited variance and convert it to the root-mean-square (RMS) amplitude, building crucial intuition about the physical meaning of the PSD.",
            "id": "4187305",
            "problem": "In a resting-state electroencephalography (EEG) recording from an occipital electrode, an investigator estimates the one-sided Power Spectral Density (PSD) using the periodogram with standard normalization, yielding PSD units of $\\mu\\text{V}^{2}/\\text{Hz}$ over nonnegative frequencies. In the $\\alpha$ band, defined here as $[8,12]$ $\\text{Hz}$, the empirically fitted one-sided PSD of the voltage $x(t)$ is modeled as\n$$\nS_{x}(f) \\;=\\; N_{0} \\;+\\; A\\,\\exp\\!\\left(-\\frac{(f-f_{0})^{2}}{2\\,\\sigma^{2}}\\right),\n$$\nwith parameters $N_{0} = 1\\,\\mu\\text{V}^{2}/\\text{Hz}$, $A = 50\\,\\mu\\text{V}^{2}/\\text{Hz}$, $f_{0} = 10\\,\\text{Hz}$, and $\\sigma = 0.5\\,\\text{Hz}$. Assume stationarity over the analysis window and that the one-sided PSD is defined on $[0,\\infty)$ such that its integral over frequency equals the variance of $x(t)$. Treat $S_{x}(f)$ as a continuous function of $f$ within the band of interest and ignore spectral leakage outside $[8,12]$ $\\text{Hz}$.\n\nStarting from the Wiener–Khinchin theorem, which relates the PSD to the autocovariance function, and the definition of variance and root-mean-square (RMS) amplitude, derive the band-limited variance contributed by frequencies in $[8,12]$ $\\text{Hz}$ and then compute the corresponding band-limited RMS amplitude. Express the final RMS amplitude in $\\mu\\text{V}$ and round your answer to four significant figures.",
            "solution": "The problem begins by referencing the Wiener–Khinchin theorem, which establishes the fundamental relationship between the autocovariance function of a stationary random process and its power spectral density. A direct consequence of this theorem is that the variance of the process, $\\sigma_x^2$, which is the autocovariance at zero lag, is equal to the integral of the PSD over all frequencies. For a one-sided PSD $S_x(f)$ defined for $f \\geq 0$, as specified in the problem, this relationship is:\n$$ \\sigma_x^2 = \\text{Var}[x(t)] = \\int_0^\\infty S_x(f) \\, df $$\nThe problem asks for the variance contributed by frequencies only within the specified $\\alpha$ band, $[8, 12]\\,\\text{Hz}$. We denote this band-limited variance as $\\sigma^2_{\\alpha}$. To find it, we integrate the given PSD model over this interval:\n$$ \\sigma^2_{\\alpha} = \\int_{8\\,\\text{Hz}}^{12\\,\\text{Hz}} S_x(f) \\, df $$\nSubstituting the provided expression for $S_x(f)$:\n$$ \\sigma^2_{\\alpha} = \\int_{8}^{12} \\left[ N_0 + A \\exp\\left(-\\frac{(f-f_0)^2}{2\\sigma^2}\\right) \\right] df $$\nWe can split this integral into two parts:\n$$ \\sigma^2_{\\alpha} = \\int_{8}^{12} N_0 \\, df + \\int_{8}^{12} A \\exp\\left(-\\frac{(f-f_0)^2}{2\\sigma^2}\\right) df $$\nThe first part, representing the contribution from the constant noise floor, is straightforward to evaluate:\n$$ \\int_{8}^{12} N_0 \\, df = N_0 [f]_{8}^{12} = N_0 (12 - 8) = 4N_0 $$\nThe second part involves integrating a Gaussian function. This integral requires the use of the error function, $\\text{erf}(z)$, which is defined as:\n$$ \\text{erf}(z) = \\frac{2}{\\sqrt{\\pi}} \\int_0^z \\exp(-t^2) \\, dt $$\nThe indefinite integral of a general Gaussian function can be expressed in terms of $\\text{erf}(z)$:\n$$ \\int \\exp\\left(-\\frac{(x-\\mu)^2}{2\\sigma^2}\\right) dx = \\sigma \\sqrt{\\frac{\\pi}{2}} \\, \\text{erf}\\left(\\frac{x-\\mu}{\\sqrt{2}\\sigma}\\right) + C $$\nApplying this to our definite integral for the Gaussian component:\n$$ \\int_{8}^{12} A \\exp\\left(-\\frac{(f-f_0)^2}{2\\sigma^2}\\right) df = A \\left[ \\sigma \\sqrt{\\frac{\\pi}{2}} \\, \\text{erf}\\left(\\frac{f-f_0}{\\sqrt{2}\\sigma}\\right) \\right]_{8}^{12} $$\n$$ = A \\sigma \\sqrt{\\frac{\\pi}{2}} \\left[ \\text{erf}\\left(\\frac{12-f_0}{\\sqrt{2}\\sigma}\\right) - \\text{erf}\\left(\\frac{8-f_0}{\\sqrt{2}\\sigma}\\right) \\right] $$\nNow, we substitute the given parameter values: $f_0 = 10\\,\\text{Hz}$ and $\\sigma = 0.5\\,\\text{Hz}$.\nThe arguments of the error function become:\nUpper limit: $\\frac{12 - 10}{\\sqrt{2} \\cdot 0.5} = \\frac{2}{0.5\\sqrt{2}} = \\frac{4}{\\sqrt{2}} = 2\\sqrt{2}$\nLower limit: $\\frac{8 - 10}{\\sqrt{2} \\cdot 0.5} = \\frac{-2}{0.5\\sqrt{2}} = \\frac{-4}{\\sqrt{2}} = -2\\sqrt{2}$\nThe expression for the Gaussian integral simplifies by using the property $\\text{erf}(-z) = -\\text{erf}(z)$:\n$$ A \\sigma \\sqrt{\\frac{\\pi}{2}} \\left[ \\text{erf}(2\\sqrt{2}) - \\text{erf}(-2\\sqrt{2}) \\right] = A \\sigma \\sqrt{\\frac{\\pi}{2}} \\left[ \\text{erf}(2\\sqrt{2}) + \\text{erf}(2\\sqrt{2}) \\right] $$\n$$ = A \\sigma \\sqrt{\\frac{\\pi}{2}} \\left[ 2 \\, \\text{erf}(2\\sqrt{2}) \\right] = A \\sigma \\sqrt{2\\pi} \\, \\text{erf}(2\\sqrt{2}) $$\nCombining the two parts, the total band-limited variance $\\sigma^2_{\\alpha}$ is:\n$$ \\sigma^2_{\\alpha} = 4N_0 + A \\sigma \\sqrt{2\\pi} \\, \\text{erf}(2\\sqrt{2}) $$\nSubstituting the numerical values for the constants $N_0 = 1\\,\\mu\\text{V}^2/\\text{Hz}$, $A = 50\\,\\mu\\text{V}^2/\\text{Hz}$, and $\\sigma = 0.5\\,\\text{Hz}$:\n$$ \\sigma^2_{\\alpha} = 4(1) + (50)(0.5) \\sqrt{2\\pi} \\, \\text{erf}(2\\sqrt{2}) $$\n$$ \\sigma^2_{\\alpha} = 4 + 25 \\sqrt{2\\pi} \\, \\text{erf}(2\\sqrt{2}) $$\nThe units of this variance are $(\\mu\\text{V}^2/\\text{Hz}) \\cdot \\text{Hz} = \\mu\\text{V}^2$. Now, we compute the numerical value:\n$2\\sqrt{2} \\approx 2.828427$\n$\\text{erf}(2\\sqrt{2}) \\approx \\text{erf}(2.828427) \\approx 0.99989592$\n$\\sqrt{2\\pi} \\approx 2.506628$\n$$ \\sigma^2_{\\alpha} \\approx 4 + 25 \\cdot (2.506628) \\cdot (0.99989592) $$\n$$ \\sigma^2_{\\alpha} \\approx 4 + 62.665707 \\cdot 0.99989592 $$\n$$ \\sigma^2_{\\alpha} \\approx 4 + 62.659231 \\approx 66.659231 \\, \\mu\\text{V}^2 $$\nThe band-limited root-mean-square (RMS) amplitude, which we denote as $E_{\\alpha}$, is the square root of the band-limited variance:\n$$ E_{\\alpha} = \\sqrt{\\sigma^2_{\\alpha}} $$\n$$ E_{\\alpha} \\approx \\sqrt{66.659231} \\approx 8.164510 \\, \\mu\\text{V} $$\nThe problem requires the answer to be rounded to four significant figures.\n$$ E_{\\alpha} \\approx 8.165 \\, \\mu\\text{V} $$",
            "answer": "$$\n\\boxed{8.165}\n$$"
        },
        {
            "introduction": "While the periodogram is a foundational tool, its reliance on the Discrete Fourier Transform (DFT) introduces potential estimation biases. This hands-on coding practice explores the \"picket-fence effect,\" where a signal's true frequency falls between discrete DFT bins, leading to inaccurate peak detection . By comparing results with and without zero-padding, you will directly observe and quantify how this common technique can significantly improve the precision of frequency estimation for spectral peaks.",
            "id": "4187300",
            "problem": "Consider a synthetic Local Field Potential (LFP) time series segment modeled as a sampled deterministic sinusoid of finite duration. Let the sampling frequency be $f_s = 1000$ Hz and the segment duration be $T = 5$ seconds, so the number of samples is $N = f_s T = 5000$. For a discrete-time signal $x[n]$, $n \\in \\{0,1,\\ldots,N-1\\}$, the Discrete Fourier Transform (DFT) is defined by\n$$\nX[k] = \\sum_{n=0}^{N-1} x[n] e^{-j 2\\pi k n / N}, \\quad k \\in \\{0,1,\\ldots,N-1\\},\n$$\nand the corresponding frequency grid is\n$$\nf_k = \\frac{k f_s}{N}.\n$$\nThe periodogram estimate of the Power Spectral Density (PSD) is defined from first principles as the squared magnitude of the DFT, appropriately normalized to have physical units of power per Hertz. One widely used normalization for a one-sided periodogram of a real-valued finite-duration sequence is\n$$\nP[f_k] = \\frac{1}{f_s N} \\left| X[k] \\right|^2,\n$$\nfor $k$ corresponding to nonnegative frequencies. Zero-padding by a factor $z \\in \\mathbb{N}$ does not change the information content or the effective rectangular window of duration $T$, but it increases the density of the sampled frequency grid to\n$$\n\\tilde{f}_k = \\frac{k f_s}{M}, \\quad M = z N,\n$$\nand the DFT computed on the zero-padded sequence of length $M$ is\n$$\n\\tilde{X}[k] = \\sum_{n=0}^{M-1} \\tilde{x}[n] e^{-j 2\\pi k n / M}, \\quad \\tilde{x}[n] = \\begin{cases} x[n],  0 \\le n \\le N-1, \\\\ 0,  N \\le n \\le M-1. \\end{cases}\n$$\nYou will implement a program that synthesizes sinusoidal LFP segments, computes periodograms with and without zero-padding, and returns peak frequency estimates. You must reason from these definitions and facts: the rectangular window of duration $T$ implies a fundamental spectral resolution on the order of $1/T$, and zero-padding does not reduce the main-lobe width of the spectral window but samples it more densely. The algorithm must compute the DFT magnitude-squared, form a one-sided periodogram, restrict the search to a physiologically plausible LFP band, and locate the peak frequency as the grid point with maximal periodogram power. The goal is to compare peak estimates with and without zero-padding and quantify the bias relative to the known sinusoid frequency.\n\nYour program must implement the following steps for each test case:\n- Construct $x[n] = A \\sin\\left( 2\\pi f_0 \\frac{n}{f_s} \\right)$ for $n = 0,1,\\ldots,N-1$, with amplitude $A$ and target frequency $f_0$ given in the test suite. Do not add noise; the purpose is to isolate discretization and windowing effects.\n- Compute the one-sided periodogram using the DFT magnitude-squared. Use zero-padding factor $z=1$ (no padding) for the first estimate, and $z=8$ for the second estimate. For both, restrict the peak search to the frequency band $[f_{\\min}, f_{\\max}]$ specified in the test suite.\n- Report the peak frequencies $\\hat{f}_{\\text{no-pad}}$ and $\\hat{f}_{\\text{pad}}$ in Hertz, and the biases $\\Delta_{\\text{no-pad}} = \\hat{f}_{\\text{no-pad}} - f_0$ and $\\Delta_{\\text{pad}} = \\hat{f}_{\\text{pad}} - f_0$ in Hertz.\n\nPhysical units requirement: All reported frequencies and biases must be expressed in Hertz (Hz) as decimal numbers.\n\nTest suite:\n- Case $1$ (happy path off-bin): $f_0 = 40.3$ Hz, $A = 1.0$, $f_{\\min} = 1$ Hz, $f_{\\max} = 100$ Hz.\n- Case $2$ (bin-centered boundary): $f_0 = 40.2$ Hz, $A = 1.0$, $f_{\\min} = 1$ Hz, $f_{\\max} = 100$ Hz.\n- Case $3$ (low-frequency edge off-bin): $f_0 = 5.05$ Hz, $A = 1.0$, $f_{\\min} = 1$ Hz, $f_{\\max} = 50$ Hz.\n\nDesign for coverage: Case $1$ tests off-bin peak estimation in the beta band; Case $2$ tests a sinusoid exactly aligned with a native DFT bin; Case $3$ tests off-bin estimation near the low-frequency edge of the search band.\n\nFinal output format: Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets. Each test case’s result must itself be a list of four decimal numbers in Hertz, ordered as $[\\hat{f}_{\\text{no-pad}}, \\hat{f}_{\\text{pad}}, \\Delta_{\\text{no-pad}}, \\Delta_{\\text{pad}}]$. For example, the full output must look like $[[r_{11},r_{12},r_{13},r_{14}],[r_{21},r_{22},r_{23},r_{24}],[r_{31},r_{32},r_{33},r_{34}]]$, where all $r_{ij}$ are decimal numbers in Hertz.",
            "solution": "The core of this problem lies in understanding the consequences of analyzing a finite-duration, discretely sampled signal using the Discrete Fourier Transform (DFT). The finite duration $T$ of the signal implies a convolution in the frequency domain with the Fourier transform of a rectangular window, which is a sinc function. This convolution causes spectral leakage, where the energy of a pure sinusoid at frequency $f_0$ is spread across the frequency spectrum, with a main lobe centered at $f_0$ and a width proportional to $1/T$. The DFT samples this continuous spectrum at a discrete set of frequencies. If the true frequency $f_0$ does not align perfectly with one of these DFT frequency bins, a phenomenon known as \"picket-fence effect\" occurs, and the maximum of the DFT magnitude will be found at the nearest bin, introducing an estimation bias. Zero-padding is a technique to mitigate this specific bias by interpolating the DFT spectrum, providing a denser sampling of the underlying sinc-shaped spectral peak and thus enabling a more accurate estimate of its true maximum.\n\nThe solution proceeds by implementing the specified steps for each test case.\n\n**1. Signal Generation**\n\nFor each case, we synthesize a deterministic sinusoidal signal $x[n]$ according to the model:\n$$x[n] = A \\sin\\left( 2\\pi f_0 \\frac{n}{f_s} \\right)$$\nwhere the amplitude $A$, true frequency $f_0$, and sampling frequency $f_s = 1000$ Hz are given. The signal is generated for a duration of $T = 5$ seconds, resulting in $N = f_s T = 5000$ discrete samples, indexed by $n \\in \\{0, 1, \\ldots, N-1\\}$. No noise is added, isolating the effects of windowing and discretization.\n\n**2. Periodogram Estimation without Zero-Padding ($z=1$)**\n\nFirst, we analyze the signal without zero-padding. The DFT length is equal to the signal length, $N=5000$.\nThe DFT, $X[k]$, is computed:\n$$X[k] = \\sum_{n=0}^{N-1} x[n] e^{-j 2\\pi k n / N}$$\nThe frequency grid for this DFT is given by $f_k = k \\frac{f_s}{N}$ for $k \\in \\{0, 1, \\ldots, N-1\\}$. The fundamental frequency resolution, determined by the observation window duration $T$, is $\\Delta f = f_s/N = 1/T = 1000/5000 = 0.2$ Hz.\nThe algorithm requires locating the peak of the periodogram, which corresponds to the maximum of $|X[k]|^2$. The normalization factor given in the problem, $1/(f_s N)$, is a constant scaling and does not affect the location of the peak; thus, we can simply find the maximum of the squared DFT magnitude. Since the input signal $x[n]$ is real-valued, the magnitude spectrum is symmetric, and we only need to analyze the one-sided spectrum for non-negative frequencies, which corresponds to indices $k \\in \\{0, 1, \\ldots, \\lfloor N/2 \\rfloor\\}$.\nThe search for the peak is constrained to the frequency band $[f_{\\min}, f_{\\max}]$. We identify the range of indices $[k_{\\min}, k_{\\max}]$ corresponding to this band and find the index $k^*$ that maximizes $|X[k]|^2$ within this range. The estimated peak frequency is then:\n$$\\hat{f}_{\\text{no-pad}} = k^* \\frac{f_s}{N}$$\n\n**3. Periodogram Estimation with Zero-Padding ($z=8$)**\n\nNext, we apply zero-padding. A new signal $\\tilde{x}[n]$ is formed by appending zeros to the original signal $x[n]$ to achieve a total length of $M = zN = 8 \\times 5000 = 40000$.\n$$\\tilde{x}[n] = \\begin{cases} x[n],  0 \\le n \\le N-1 \\\\ 0,  N \\le n \\le M-1 \\end{cases}$$\nThe DFT, $\\tilde{X}[k]$, of this zero-padded sequence is computed:\n$$\\tilde{X}[k] = \\sum_{n=0}^{M-1} \\tilde{x}[n] e^{-j 2\\pi k n / M}$$\nThis operation does not alter the underlying continuous spectrum (the sinc function) but samples it at a much denser grid of frequencies:\n$$\\tilde{f}_k = k \\frac{f_s}{M} = k \\frac{1000}{40000} = k \\times 0.025 \\text{ Hz}$$\nThe frequency resolution has been effectively interpolated by a factor of $z=8$. We again find the index $\\tilde{k}^*$ that maximizes $|\\tilde{X}[k]|^2$ within the search band $[f_{\\min}, f_{\\max}]$ and compute the corresponding peak frequency:\n$$\\hat{f}_{\\text{pad}} = \\tilde{k}^* \\frac{f_s}{M}$$\n\n**4. Bias Calculation**\n\nFor both estimates, the bias is calculated as the difference between the estimated frequency and the true frequency $f_0$:\n$$\\Delta_{\\text{no-pad}} = \\hat{f}_{\\text{no-pad}} - f_0$$\n$$\\Delta_{\\text{pad}} = \\hat{f}_{\\text{pad}} - f_0$$\n\n**Analysis of Test Cases**\n\n- **Case 1 ($f_0 = 40.3$ Hz):** The true frequency is off-bin, as $40.3$ is not an integer multiple of the native resolution $\\Delta f = 0.2$ Hz. It lies between the bins for $40.2$ Hz ($k=201$) and $40.4$ Hz ($k=202$). The unpadded periodogram peak will be snapped to the nearest bin, causing a bias. With zero-padding, the denser frequency grid allows for a sample point much closer to the true peak of the sinc lobe, significantly reducing the bias.\n\n- **Case 2 ($f_0 = 40.2$ Hz):** The true frequency is exactly on-bin, since $40.2 = 201 \\times 0.2$. In this ideal scenario, spectral leakage is minimized, and the DFT should peak exactly at bin $k=201$. Both the unpadded and padded estimates are expected to be highly accurate, with near-zero bias.\n\n- **Case 3 ($f_0 = 5.05$ Hz):** Similar to Case $1$, this frequency is off-bin ($5.05$ is not a multiple of $0.2$). It lies between the bins for $5.0$ Hz ($k=25$) and $5.2$ Hz ($k=26$). The unpadded estimate will have a notable bias, which should be substantially reduced by zero-padding.\n\nThis procedure systematically demonstrates that zero-padding is an effective method for improving frequency estimation accuracy in periodograms when the signal frequency does not align with the DFT's native frequency grid. It does not improve spectral *resolution* (the ability to distinguish two closely spaced frequencies), which remains limited by $1/T$, but it improves the precision of locating a single spectral peak.",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the problem of estimating sinusoidal frequencies from synthetic LFP data\n    using the periodogram method, with and without zero-padding, and quantifies the bias.\n    \"\"\"\n    \n    # Common parameters for all test cases\n    fs = 1000.0  # Sampling frequency in Hz\n    T = 5.0     # Segment duration in seconds\n    N = int(fs * T)  # Number of samples\n\n    # Test suite as defined in the problem statement\n    test_cases = [\n        {'f0': 40.3, 'A': 1.0, 'f_min': 1.0, 'f_max': 100.0},\n        {'f0': 40.2, 'A': 1.0, 'f_min': 1.0, 'f_max': 100.0},\n        {'f0': 5.05, 'A': 1.0, 'f_min': 1.0, 'f_max': 50.0},\n    ]\n\n    results = []\n\n    for case in test_cases:\n        f0 = case['f0']\n        A = case['A']\n        f_min = case['f_min']\n        f_max = case['f_max']\n\n        # Step 1: Construct the synthetic LFP signal\n        n = np.arange(N)\n        x = A * np.sin(2 * np.pi * f0 * n / fs)\n\n        # --- Analysis without Zero-Padding (z=1) ---\n        M_nopad = N\n        \n        # Compute the DFT and its squared magnitude\n        X_nopad = np.fft.fft(x, n=M_nopad)\n        # We only need the one-sided spectrum (positive frequencies)\n        P_nopad = np.abs(X_nopad[:M_nopad // 2])**2\n        \n        # Create the frequency grid for the one-sided spectrum\n        freq_nopad = np.fft.fftfreq(M_nopad, d=1/fs)[:M_nopad // 2]\n        \n        # Restrict the search to the specified frequency band\n        # np.searchsorted is efficient for finding indices in a sorted array\n        idx_min_nopad = np.searchsorted(freq_nopad, f_min, side='left')\n        idx_max_nopad = np.searchsorted(freq_nopad, f_max, side='right')\n\n        # Find the peak frequency in the restricted band\n        search_range_nopad = P_nopad[idx_min_nopad:idx_max_nopad]\n        peak_idx_local_nopad = np.argmax(search_range_nopad)\n        peak_idx_global_nopad = idx_min_nopad + peak_idx_local_nopad\n        f_hat_nopad = freq_nopad[peak_idx_global_nopad]\n\n        # --- Analysis with Zero-Padding (z=8) ---\n        z_pad_factor = 8\n        M_pad = z_pad_factor * N\n\n        # Compute the DFT using the M_pad length (numpy handles the padding)\n        X_pad = np.fft.fft(x, n=M_pad)\n        # One-sided power spectrum\n        P_pad = np.abs(X_pad[:M_pad // 2])**2\n\n        # Create the denser frequency grid\n        freq_pad = np.fft.fftfreq(M_pad, d=1/fs)[:M_pad // 2]\n\n        # Restrict search to the frequency band\n        idx_min_pad = np.searchsorted(freq_pad, f_min, side='left')\n        idx_max_pad = np.searchsorted(freq_pad, f_max, side='right')\n        \n        # Find the peak frequency in the restricted band\n        search_range_pad = P_pad[idx_min_pad:idx_max_pad]\n        peak_idx_local_pad = np.argmax(search_range_pad)\n        peak_idx_global_pad = idx_min_pad + peak_idx_local_pad\n        f_hat_pad = freq_pad[peak_idx_global_pad]\n        \n        # Step 3: Calculate the biases\n        delta_nopad = f_hat_nopad - f0\n        delta_pad = f_hat_pad - f0\n        \n        # Store results for this case\n        results.append([f_hat_nopad, f_hat_pad, delta_nopad, delta_pad])\n    \n    # Format the final output string exactly as required\n    # map(str, results) converts each inner list like [1.0, 2.0] into its string representation \"'[1.0, 2.0]'\"\n    # which is then joined by commas.\n    output_str = f\"[{','.join(map(str, results))}]\"\n    print(output_str)\n\nsolve()\n\n```"
        },
        {
            "introduction": "A single periodogram provides a statistically unreliable estimate of the true power spectrum. This capstone design exercise challenges you to implement a robust solution using Welch's averaged periodogram method, a standard in neuroscience data analysis . You will navigate the critical trade-off between spectral resolution and variance reduction by systematically selecting segment length, window type, and overlap to meet specific quantitative goals, developing the skills needed for principled spectral estimation.",
            "id": "4187289",
            "problem": "You are given a Local Field Potential (LFP) recording of duration $T_{\\text{total}} = 120$ seconds sampled at $f_s = 1000$ hertz, yielding $L = T_{\\text{total}} \\cdot f_s$ samples. The task is to design a periodogram-based Power Spectral Density (PSD) estimator via Welch's averaged periodogram for resolving closely spaced beta-band oscillatory peaks while meeting a specified target variance reduction. The design must choose the segment length $N$ (in samples), window type $w[n]$, and overlap fraction $p \\in [0,1)$, and justify quantitatively that the chosen parameters meet both the spectral resolution and variance reduction requirements.\n\nUse the following foundational base:\n- The PSD $S_{xx}(f)$ of a wide-sense stationary discrete-time process $x[n]$ is defined as the Fourier transform of its autocovariance function.\n- The periodogram is obtained by computing the squared magnitude of the Discrete Fourier Transform (DFT) of a finite-duration segment. Welch's method averages periodograms across segments to reduce variance.\n- The spectral resolution for a segment of length $N$ with sampling frequency $f_s$ is bounded by the effective mainlobe width determined by the window. For a rectangular window, the Rayleigh frequency resolution is $\\Delta f_{\\text{rect}} = \\frac{f_s}{N}$. For Hann and Hamming windows, the mainlobe width is approximately doubled, giving $\\Delta f_{\\text{hann}} \\approx \\Delta f_{\\text{hamming}} \\approx \\frac{2 f_s}{N}$.\n- The number of segments $K$ formed from $L$ samples using segment length $N$ and hop size $H = \\lfloor N (1 - p) \\rfloor$ is $K = \\left\\lfloor \\frac{L - N}{H} \\right\\rfloor + 1$, provided $H \\ge 1$ and $L \\ge N$.\n- The variance of the averaged PSD estimator at a given frequency is reduced relative to a single periodogram by averaging. For correlated segment estimates due to overlap, an effective number of averages $K_{\\text{eff}}$ can be approximated using the variance of an average of correlated random variables: \n$$\nK_{\\text{eff}} \\approx \\frac{K}{1 + 2 \\rho},\n$$\nwhere $\\rho$ is the normalized correlation coefficient between adjacent windowed segments induced by overlap, approximated by \n$$\n\\rho = \\frac{\\sum_{n=0}^{N-H-1} w[n]\\,w[n+H]}{\\sum_{n=0}^{N-1} w[n]^2}.\n$$\n- The target normalized variance $\\tau$ is enforced via the inequality \n$$\n\\frac{\\operatorname{Var}[\\hat{S}(f)]}{S(f)^2} \\lesssim \\frac{1}{K_{\\text{eff}}} \\le \\tau,\n$$\nequivalently $K_{\\text{eff}} \\ge \\frac{1}{\\tau}$.\n\nDesign constraints and choices:\n1. Windows to consider are rectangular, Hann, and Hamming. Use codes $0$ for rectangular, $1$ for Hann, and $2$ for Hamming.\n2. The spectral resolution requirement is that the effective resolution $\\Delta f_{\\text{eff}}$ of the chosen window and segment length must satisfy \n$$\n\\Delta f_{\\text{eff}} \\le |f_2 - f_1|,\n$$\nwhere $f_1$ and $f_2$ are the two beta-band peak frequencies in hertz for the test case.\n3. The variance reduction requirement is that the effective number of averages must satisfy \n$$\nK_{\\text{eff}} \\ge \\frac{1}{\\tau}.\n$$\n4. Available overlap fractions are restricted to the set $\\{0.0, 0.5, 0.75, 0.875\\}$. The hop size is $H = \\lfloor N(1-p)\\rfloor$, and enforce $H \\ge 1$.\n5. Window selection policy: prefer Hann for leakage control typical in neuroscience analysis. If Hann cannot satisfy the spectral resolution constraint within $N \\le L$, prefer Hamming; if neither satisfies the constraint, prefer rectangular.\n\nAlgorithmic requirements:\n- For each test case, compute the minimum segment length $N$ (integer, samples) that satisfies the resolution constraint for the selected window. Specifically, for rectangular use $\\Delta f_{\\text{eff}} = \\frac{f_s}{N}$, for Hann and Hamming use $\\Delta f_{\\text{eff}} = \\frac{2 f_s}{N}$. Choose the smallest integer $N$ meeting $\\Delta f_{\\text{eff}} \\le |f_2-f_1|$, subject to $N \\le L$.\n- With the chosen $N$ and window, iterate over the overlap fractions in ascending order, compute $H$, $K$, $\\rho$, and $K_{\\text{eff}}$, and select the smallest $p$ that achieves $K_{\\text{eff}} \\ge \\frac{1}{\\tau}$.\n- Compute the achieved effective resolution $\\Delta f_{\\text{eff}}$ in hertz for the final choice.\n\nTest suite:\n- Case 1 (happy path): $f_1 = 20.0$ hertz, $f_2 = 23.0$ hertz, $\\tau = 0.15$.\n- Case 2 (closer peaks): $f_1 = 20.0$ hertz, $f_2 = 21.0$ hertz, $\\tau = 0.05$.\n- Case 3 (tight resolution, strong variance reduction): $f_1 = 13.0$ hertz, $f_2 = 13.5$ hertz, $\\tau = 0.02$.\n- Case 4 (boundary resolution): $f_1 = 25.0$ hertz, $f_2 = 27.0$ hertz, $\\tau = 0.10$.\n\nOutput specification:\n- For each test case, output a list containing five elements in the following order: \n$[N, \\text{window\\_code}, p, K_{\\text{eff}}, \\Delta f_{\\text{eff}}]$, \nwhere $N$ is an integer (samples), $\\text{window\\_code}$ is an integer (as specified), $p$ is a float (overlap fraction), $K_{\\text{eff}}$ is a float, and $\\Delta f_{\\text{eff}}$ is a float in hertz.\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, where each element is the five-item list for one test case (e.g., $[[...],[...],[...],[...]]$). All frequency-related quantities must be expressed in hertz, and all overlap quantities must be expressed as decimals, not percentages.",
            "solution": "The objective is to resolve the fundamental trade-off in spectral estimation between spectral resolution and statistical stability (variance).\n\n**1. Spectral Resolution and Selection of Segment Length ($N$)**\nThe ability to distinguish two closely spaced frequency components is termed spectral resolution. In Fourier analysis, this is governed by the length of the observation window, $N$. A longer segment (larger $N$) yields a finer frequency grid and a narrower mainlobe for the window's spectral response, thus improving resolution. The provided formulas capture this:\n-   $\\Delta f_{\\text{rect}} = \\frac{f_s}{N}$\n-   $\\Delta f_{\\text{hann/hamming}} \\approx \\frac{2 f_s}{N}$\n\nTapered windows like Hann and Hamming are preferred over the rectangular window because they exhibit significantly lower spectral leakage (i.e., smaller side lobes), which prevents weak spectral components from being obscured by strong nearby ones. However, this benefit comes at the cost of a wider mainlobe, roughly doubling it and thus degrading the resolution for a given $N$.\n\nThe design algorithm begins by addressing the resolution constraint, $\\Delta f_{\\text{eff}} \\le |f_2 - f_1|$. We rearrange the resolution formula to find the minimum required segment length, $N_{\\text{min}}$.\n\nFollowing the specified policy, we first attempt to use a Hann window. The minimum segment length is:\n$$\nN_{\\text{hann}} = \\left\\lceil \\frac{2 f_s}{|f_2 - f_1|} \\right\\rceil\n$$\nIf this $N_{\\text{hann}}$ is feasible (i.e., $N_{\\text{hann}} \\le L$), we select the Hann window with $N = N_{\\text{hann}}$. If not, we repeat the process for the Hamming window (which has the same resolution formula and thus the same $N$) and then the rectangular window, for which:\n$$\nN_{\\text{rect}} = \\left\\lceil \\frac{f_s}{|f_2 - f_1|} \\right\\rceil\n$$\nThe first window in the priority list (Hann $\\rightarrow$ Hamming $\\rightarrow$ Rectangular) that yields a feasible $N$ is chosen.\n\n**2. Variance Reduction and Selection of Overlap Fraction ($p$)**\nThe raw periodogram of a single segment is a high-variance estimator of the true PSD. Welch's method mitigates this by averaging periodograms from multiple segments. For a signal of total length $L$ and a segment length $N$, the number of available segments $K$ increases as the hop size $H$ decreases. The hop size is determined by the overlap fraction $p$: $H = \\lfloor N(1-p) \\rfloor$. A larger overlap (larger $p$) yields a smaller $H$ and thus a larger $K$.\n\nHowever, overlapping segments are correlated, meaning each additional segment provides diminishing new information. The variance reduction is therefore not proportional to $K$, but to an effective number of averages, $K_{\\text{eff}}$, which accounts for this correlation:\n$$\nK_{\\text{eff}} \\approx \\frac{K}{1 + 2 \\rho}\n$$\nThe correlation $\\rho$ depends on the window shape and the degree of overlap. The design requires that $K_{\\text{eff}}$ meets or exceeds a target value determined by the specified normalized variance $\\tau$:\n$$\nK_{\\text{eff}} \\ge \\frac{1}{\\tau}\n$$\nWith $N$ and the window type fixed from the resolution step, we now iterate through the allowed overlap fractions $p \\in \\{0.0, 0.5, 0.75, 0.875\\}$ in ascending order. For each $p$, we calculate $H$, $K$, $\\rho$, and finally $K_{\\text{eff}}$. The first value of $p$ that satisfies the variance reduction inequality is selected. This choice minimizes the computational cost associated with higher overlap while meeting the statistical stability requirement.\n\n**3. Final Parameterization**\nOnce the triplet ($N$, window, $p$) is determined, the actually achieved effective resolution $\\Delta f_{\\text{eff}}$ and effective number of averages $K_{\\text{eff}}$ are calculated and reported along with the chosen parameters. This completes the design for a given test case. This structured, two-step optimization process ensures both design constraints are met in a systematic and justified manner.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Designs a Welch's PSD estimator by selecting segment length, window type,\n    and overlap fraction to meet specified spectral resolution and variance\n    reduction constraints.\n    \"\"\"\n    # Global parameters from the problem statement\n    T_total = 120.0\n    fs = 1000.0\n    L = int(T_total * fs)  # Total number of samples\n\n    # Available design choices\n    overlap_fractions = [0.0, 0.5, 0.75, 0.875]\n    window_specs = {\n        'hann': {'code': 1, 'C': 2.0, 'func': np.hanning},\n        'hamming': {'code': 2, 'C': 2.0, 'func': np.hamming},\n        'rectangular': {'code': 0, 'C': 1.0, 'func': np.ones}\n    }\n    window_selection_order = ['hann', 'hamming', 'rectangular']\n\n    # Test suite from the problem statement\n    test_cases = [\n        (20.0, 23.0, 0.15),  # Case 1\n        (20.0, 21.0, 0.05),  # Case 2\n        (13.0, 13.5, 0.02),  # Case 3\n        (25.0, 27.0, 0.10),  # Case 4\n    ]\n\n    all_results = []\n    for case in test_cases:\n        f1, f2, tau = case\n        df_target = abs(f2 - f1)\n        k_eff_target = 1.0 / tau\n\n        # --- Step 1: Select Window and Segment Length N ---\n        chosen_window_name = None\n        N = -1\n\n        for window_name in window_selection_order:\n            C = window_specs[window_name]['C']\n            # Calculate minimum N to satisfy the resolution constraint\n            N_candidate = int(np.ceil(C * fs / df_target))\n            \n            if N_candidate = L:\n                chosen_window_name = window_name\n                N = N_candidate\n                break\n        \n        # This case should not be reached with the given test suite\n        if chosen_window_name is None:\n            raise ValueError(\"No window can satisfy resolution constraints.\")\n\n        # --- Step 2: Select Overlap Fraction p ---\n        chosen_p = -1.0\n        final_k_eff = -1.0\n        \n        # Generate the chosen window function of length N\n        window_func = window_specs[chosen_window_name]['func']\n        w = window_func(N)\n        denom_rho = np.sum(w**2)\n\n        for p in overlap_fractions:\n            # Calculate hop size, must be at least 1\n            H = int(np.floor(N * (1.0 - p)))\n            if H  1:\n                continue\n\n            # Calculate the number of segments\n            K = int(np.floor((L - N) / H)) + 1\n            \n            # Calculate correlation coefficient rho\n            if p == 0.0 or H >= N: # Non-overlapping\n                rho = 0.0\n            else:\n                # Summation: sum_{n=0}^{N-H-1} w[n] w[n+H]\n                # This corresponds to dot product of two slices of the window\n                num_rho = np.sum(w[0 : N - H] * w[H : N])\n                rho = num_rho / denom_rho\n\n            # Calculate effective number of averages\n            k_eff = K / (1.0 + 2.0 * rho)\n\n            # Check if variance reduction target is met\n            if k_eff >= k_eff_target:\n                chosen_p = p\n                final_k_eff = k_eff\n                break\n        \n        # This case should not be reached with the given test suite\n        if chosen_p  0.0:\n            raise ValueError(f\"Could not meet variance target K_eff > {k_eff_target} for N={N}.\")\n\n        # --- Step 3: Calculate Final Parameters ---\n        window_code = window_specs[chosen_window_name]['code']\n        C_final = window_specs[chosen_window_name]['C']\n        delta_f_eff = C_final * fs / N\n        \n        result = [N, window_code, chosen_p, final_k_eff, delta_f_eff]\n        all_results.append(result)\n\n    # Format the final output as a single-line string representation of a list of lists.\n    # e.g., [[val1, val2, ...], [val1, val2, ...]]\n    print(f\"[{','.join(map(str, all_results))}]\")\n\nsolve()\n```"
        }
    ]
}