{
    "hands_on_practices": [
        {
            "introduction": "The most effective way to grasp the implications of a theoretical concept like aliasing is to simulate it directly. This practice guides you through the process of creating a synthetic neural signal, introducing high-frequency components that violate the Nyquist-Shannon sampling theorem, and then sampling the signal at different rates. By computationally quantifying the resulting error, you will gain a tangible understanding of how out-of-band frequencies fold into and corrupt your signal of interest .",
            "id": "4137791",
            "problem": "You are asked to design and implement a complete, runnable program that simulates aliasing in sampled neural signals by injecting known high-frequency components into synthetic signals and quantifies the fold-in error for different sampling frequencies. The fundamental base of this problem is the Nyquist-Shannon sampling theorem (NSST), which asserts that a band-limited continuous-time signal with maximum frequency content below half the sampling frequency can be perfectly reconstructed from its samples. When a signal contains frequency components above the Nyquist frequency, sampling produces spectral replicas that overlap the baseband, causing aliasing.\n\nConstruct a continuous-time signal $x(t)$ as a sum of a low-frequency component $s_{\\mathrm{lf}}(t)$ and a high-frequency component $s_{\\mathrm{hf}}(t)$. Let the sampling frequency be $f_s$, the sampling period be $T_s = 1/f_s$, and the duration be $T$. The low-frequency component is defined by two sinusoids that are representative of typical neural oscillations:\n- $s_{\\mathrm{lf}}(t) = A_1 \\sin\\left(2\\pi f_1 t\\right) + A_2 \\sin\\left(2\\pi f_2 t\\right)$,\nwhere $f_1 = 8$ $\\mathrm{Hz}$ and $f_2 = 30$ $\\mathrm{Hz}$, with amplitudes $A_1 = 1$ $\\mathrm{a.u.}$ and $A_2 = 0.5$ $\\mathrm{a.u.}$. All angles must be treated in radians.\n\nThe high-frequency component is defined as a sum of sinusoids with frequencies strictly greater than the Nyquist frequency for the given $f_s$:\n- $s_{\\mathrm{hf}}(t) = \\sum_{m} B_m \\sin\\left(2\\pi F_m t\\right)$,\nwhere each $F_m$ is specified per test case and $B_m = 0.8$ $\\mathrm{a.u.}$ for all $m$. The total signal is $x(t) = s_{\\mathrm{lf}}(t) + s_{\\mathrm{hf}}(t)$.\n\nSample $x(t)$ at rate $f_s$ over duration $T$ to obtain discrete-time samples $x[n] = x(n T_s)$ for $n = 0, 1, \\dots, N-1$ with $N = \\lfloor T f_s \\rfloor$. Define an ideal low-pass reconstruction operator that zeros out all discrete Fourier transform bins above a band limit $f_{\\mathrm{band}} = 50$ $\\mathrm{Hz}$, and then performs an inverse transform to reconstruct a time-domain signal band-limited to $[0, f_{\\mathrm{band}}]$. Apply this operator to both the sampled total signal and the sampled low-frequency-only signal to obtain $y_{\\mathrm{total}}[n]$ and $y_{\\mathrm{lf}}[n]$, respectively.\n\nQuantify alias fold-in by computing the root-mean-square error (RMSE) between $y_{\\mathrm{total}}[n]$ and $y_{\\mathrm{lf}}[n]$:\n$$\n\\mathrm{RMSE} = \\sqrt{\\frac{1}{N} \\sum_{n=0}^{N-1} \\left(y_{\\mathrm{total}}[n] - y_{\\mathrm{lf}}[n]\\right)^2}.\n$$\nThis measures contamination of the target low-frequency band by aliased high-frequency content. Express the RMSE as a float in arbitrary units (a.u.).\n\nUse the following test suite, where all frequencies are in $\\mathrm{Hz}$, all amplitudes are in $\\mathrm{a.u.}$, the duration is $T = 2$ $\\mathrm{s}$, and angles are in radians:\n- Case $1$ (happy path with clear fold-in): $f_s = 1000$, $F_m \\in \\{960, 980\\}$.\n- Case $2$ (moderate sampling): $f_s = 500$, $F_m \\in \\{480, 495\\}$.\n- Case $3$ (alias at band edge): $f_s = 200$, $F_m \\in \\{450\\}$.\n- Case $4$ (near-Nyquist conditions): $f_s = 120$, $F_m \\in \\{115, 235\\}$.\n- Case $5$ (boundary stress: just below/above multiples): $f_s = 100$, $F_m \\in \\{99, 101, 199\\}$.\n\nYour program should compute the RMSE for each case and produce a single line of output containing the results as a comma-separated list enclosed in square brackets (e.g., \"[result1,result2,result3]\"). Each result must be a float representing the RMSE in $\\mathrm{a.u.}$ for the corresponding case, in the same order as listed above.",
            "solution": "The problem statement has been rigorously validated against the specified criteria. It is scientifically sound, well-posed, objective, and contains all necessary information for a unique solution. The problem is a standard exercise in digital signal processing, specifically demonstrating the phenomenon of aliasing as dictated by the Nyquist-Shannon sampling theorem. The proposed methodology is correct and computationally feasible. We may therefore proceed with the solution.\n\nThe core of this problem lies in demonstrating and quantifying aliasing, a fundamental concept in signal processing. The Nyquist-Shannon sampling theorem states that a continuous-time signal with frequencies no higher than a maximum frequency $f_{\\mathrm{max}}$ can be perfectly reconstructed from its samples if the sampling frequency $f_s$ is strictly greater than twice the maximum frequency, i.e., $f_s > 2 f_{\\mathrm{max}}$. The frequency $f_s/2$ is known as the Nyquist frequency, $f_{\\mathrm{Nyq}}$. If a signal contains frequency components above $f_{\\mathrm{Nyq}}$, these components are \"folded\" into the frequency range $[0, f_{\\mathrm{Nyq}}]$, corrupting the low-frequency content. This phenomenon is aliasing.\n\nThe solution is designed in four distinct steps: signal synthesis, sampling, frequency-domain filtering, and error quantification.\n\n**1. Signal Synthesis**\n\nWe construct a synthetic continuous-time signal $x(t)$ composed of two parts: a low-frequency component $s_{\\mathrm{lf}}(t)$ representing the signal of interest, and a high-frequency component $s_{\\mathrm{hf}}(t)$ representing contamination or noise.\n\nThe low-frequency signal $s_{\\mathrm{lf}}(t)$ is defined as the sum of two sinusoids with frequencies $f_1 = 8$ $\\mathrm{Hz}$ and $f_2 = 30$ $\\mathrm{Hz}$, which are well within the typical bands of interest for neural data (e.g., alpha and beta bands).\n$$\ns_{\\mathrm{lf}}(t) = A_1 \\sin(2\\pi f_1 t) + A_2 \\sin(2\\pi f_2 t)\n$$\nwith amplitudes $A_1 = 1$ and $A_2 = 0.5$ in arbitrary units (a.u.).\n\nThe high-frequency signal $s_{\\mathrm{hf}}(t)$ is a sum of sinusoids whose frequencies $F_m$ are explicitly chosen to be above the Nyquist frequency for each test case.\n$$\ns_{\\mathrm{hf}}(t) = \\sum_{m} B_m \\sin(2\\pi F_m t)\n$$\nwith amplitude $B_m = 0.8$ a.u. for all components.\n\nThe total signal is the linear superposition of these two components: $x(t) = s_{\\mathrm{lf}}(t) + s_{\\mathrm{hf}}(t)$.\n\n**2. Signal Sampling (Discretization)**\n\nThe continuous signals are sampled at a rate $f_s$ over a duration $T = 2$ $\\mathrm{s}$. This produces discrete-time sequences. The time instances for sampling are $t_n = n T_s = n/f_s$ for $n = 0, 1, \\dots, N-1$, where $N = \\lfloor T f_s \\rfloor$ is the total number of samples.\n\nWe generate two discrete-time signals:\n- The sampled total signal: $x[n] = x(t_n) = s_{\\mathrm{lf}}(t_n) + s_{\\mathrm{hf}}(t_n)$\n- The sampled reference low-frequency signal: $s_{\\mathrm{lf}}[n] = s_{\\mathrm{lf}}(t_n)$\n\nWhen sampled, a high-frequency sinusoid with frequency $F > f_{\\mathrm{Nyq}}$ masquerades as a low-frequency sinusoid with frequency $f_{\\mathrm{alias}}$ in the range $[0, f_{\\mathrm{Nyq}}]$. The aliased frequency is given by $f_{\\mathrm{alias}} = |F - k \\cdot f_s|$, where $k$ is an integer chosen such that $f_{\\mathrm{alias}} \\le f_{\\mathrm{Nyq}}$. This folding of the spectrum is the source of the error we aim to quantify.\n\n**3. Frequency-Domain Low-Pass Filtering**\n\nTo isolate the effect of aliasing within a specific band of interest, we apply an ideal low-pass filter with a cutoff frequency $f_{\\mathrm{band}} = 50$ $\\mathrm{Hz}$. This operation is performed in the frequency domain using the Discrete Fourier Transform (DFT), implemented via the Fast Fourier Transform (FFT) algorithm.\n\nFirst, we compute the DFT of the sampled signals $x[n]$ and $s_{\\mathrm{lf}}[n]$ to obtain their complex-valued spectra, $X[k]$ and $S_{\\mathrm{lf}}[k]$, respectively. The frequency corresponding to each DFT bin $k$ is determined by the sampling rate $f_s$ and the number of points $N$.\n\nThe ideal low-pass filter is implemented by creating a frequency mask. We identify all frequency bins corresponding to frequencies $|f| > f_{\\mathrm{band}}$ and set their corresponding DFT coefficients to zero. For a real-valued input signal, the DFT spectrum is conjugate symmetric, so the filter must be applied symmetrically to both positive and negative frequency components.\n\nLet $Y_{\\mathrm{total}}[k]$ and $Y_{\\mathrm{lf}}[k]$ be the filtered spectra. They are defined as:\n$$\nY[k] =\n\\begin{cases}\nX[k] & \\text{if } |f_k| \\le f_{\\mathrm{band}} \\\\\n0 & \\text{if } |f_k| > f_{\\mathrm{band}}\n\\end{cases}\n$$\nwhere $X[k]$ is the original spectrum and $f_k$ is the frequency of the $k$-th bin.\n\nFinally, we apply the Inverse DFT (implemented via IFFT) to the filtered spectra $Y_{\\mathrm{total}}[k]$ and $Y_{\\mathrm{lf}}[k]$ to obtain the filtered time-domain signals, $y_{\\mathrm{total}}[n]$ and $y_{\\mathrm{lf}}[n]$. Because the input signals are real and the filter is symmetric, the resulting time-domain signals must be real. Any residual imaginary components are due to numerical precision errors and are discarded.\n\n**4. Error Quantification**\n\nThe signal $y_{\\mathrm{lf}}[n]$ represents the \"true\" low-frequency content as it would appear after sampling and filtering, without any high-frequency contamination. The signal $y_{\\mathrm{total}}[n]$ contains this same true content, plus any high-frequency components that aliased into the $[0, 50]$ $\\mathrm{Hz}$ passband.\n\nThe difference signal, $y_{\\mathrm{total}}[n] - y_{\\mathrm{lf}}[n]$, therefore isolates the aliased contamination. We quantify the magnitude of this contamination using the Root-Mean-Square Error (RMSE):\n$$\n\\mathrm{RMSE} = \\sqrt{\\frac{1}{N} \\sum_{n=0}^{N-1} \\left(y_{\\mathrm{total}}[n] - y_{\\mathrm{lf}}[n]\\right)^2}\n$$\nThis metric provides a robust measure of the average power of the error signal introduced by aliasing. The procedure is systematically applied to each test case to evaluate how the choice of sampling rate $f_s$ and the specific high frequencies $F_m$ affect the severity of aliasing.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Simulates and quantifies aliasing in sampled neural signals.\n    \"\"\"\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        {'fs': 1000, 'Fm': [960, 980]},\n        {'fs': 500, 'Fm': [480, 495]},\n        {'fs': 200, 'Fm': [450]},\n        {'fs': 120, 'Fm': [115, 235]},\n        {'fs': 100, 'Fm': [99, 101, 199]},\n    ]\n\n    # Signal parameters\n    T = 2.0  # s\n    A1, f1 = 1.0, 8.0  # a.u., Hz\n    A2, f2 = 0.5, 30.0 # a.u., Hz\n    Bm_val = 0.8  # a.u.\n    f_band = 50.0  # Hz\n\n    def create_signal(t_samples, freq_list, amp):\n        \"\"\"Generates a sum of sinusoids.\"\"\"\n        signal = np.zeros_like(t_samples)\n        if not freq_list:\n            return signal\n        for f in freq_list:\n            # Using np.sin with a scalar amplitude\n            signal += amp * np.sin(2 * np.pi * f * t_samples)\n        return signal\n\n    def apply_ideal_lpf(signal_samples, fs, N, f_cutoff):\n        \"\"\"\n        Applies an ideal low-pass filter in the frequency domain.\n        \"\"\"\n        # 1. Compute DFT\n        dft_coeffs = np.fft.fft(signal_samples)\n        \n        # 2. Get frequency bins\n        freqs = np.fft.fftfreq(N, d=1.0/fs)\n        \n        # 3. Create mask to zero out frequencies above the cutoff\n        mask = np.abs(freqs) > f_cutoff\n        dft_coeffs[mask] = 0\n        \n        # 4. Compute Inverse DFT\n        filtered_signal = np.fft.ifft(dft_coeffs)\n        \n        # Return the real part to discard numerical noise\n        return np.real(filtered_signal)\n\n    results = []\n    \n    for case in test_cases:\n        fs = case['fs']\n        Fm_list = case['Fm']\n        \n        # Calculate number of samples\n        N = int(T * fs) # Per problem, floor is implicit as T*fs is integer\n        \n        # Create the discrete time vector\n        t_samples = np.arange(N) / fs\n        \n        # 1. Signal Synthesis and Sampling\n        # Low-frequency signal (s_lf[n])\n        s_lf_n = A1 * np.sin(2 * np.pi * f1 * t_samples) + \\\n                 A2 * np.sin(2 * np.pi * f2 * t_samples)\n\n        # High-frequency signal (s_hf[n])\n        s_hf_n = create_signal(t_samples, Fm_list, Bm_val)\n\n        # Total signal (x[n])\n        x_n = s_lf_n + s_hf_n\n        \n        # 2. Low-pass filtering\n        # Apply LPF to the reference low-frequency signal\n        y_lf_n = apply_ideal_lpf(s_lf_n, fs, N, f_band)\n        \n        # Apply LPF to the total signal\n        y_total_n = apply_ideal_lpf(x_n, fs, N, f_band)\n        \n        # 3. Quantify aliasing with RMSE\n        # The difference contains the aliased components\n        error_signal = y_total_n - y_lf_n\n        \n        # Calculate RMSE\n        rmse = np.sqrt(np.mean(error_signal**2))\n        \n        results.append(rmse)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(f'{r:.7f}' for r in results)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "Having seen how aliasing can corrupt data, the next critical skill is learning how to prevent it at the source. This exercise focuses on the primary engineering solution: designing a digital anti-aliasing filter. You will translate performance specifications like passband ripple and stopband attenuation from the conceptual domain into a functional Finite Impulse Response (FIR) filter, providing you with a practical tool essential for ensuring data integrity during acquisition and processing .",
            "id": "4137766",
            "problem": "You are analyzing extracellular neural recordings that are being digitized at a sampling frequency $f_s = 2\\,000\\ \\mathrm{Hz}$. To prevent aliasing of high-frequency noise and muscle artifacts into the neural band during acquisition and potential downsampling, you must design a Finite Impulse Response (FIR) anti-alias low-pass filter whose passband is $[0,400]\\ \\mathrm{Hz}$, whose stopband starts at $450\\ \\mathrm{Hz}$, whose passband ripple is bounded by $0.1\\ \\mathrm{dB}$ or less, and whose stopband attenuation is at least $60\\ \\mathrm{dB}$. Your task is to estimate the minimum FIR filter order required using standard approximation methods, then construct a candidate equiripple FIR filter of that order and evaluate whether it meets the specifications.\n\nStarting from fundamental bases appropriate to neuroscience data analysis:\n- The Nyquistâ€“Shannon sampling theorem states that a discrete-time system sampled at frequency $f_s$ can represent frequency content up to the Nyquist frequency $f_N = f_s/2$ without aliasing. Aliasing occurs when signal content above $f_N$ is not sufficiently attenuated prior to sampling or downsampling and folds into lower frequencies.\n- A linear time-invariant FIR filter $h[n]$ has a frequency response $H(\\omega)$ obtained by the discrete-time Fourier transform, and its magnitude response in the passband should be close to unity with bounded ripple, while the stopband should provide sufficient attenuation to suppress out-of-band content.\n- Widely used engineering approximations relate the allowable amplitude ripple in the passband and stopband (in linear units) to specifications in decibels. The allowable ripple values, together with the transition width in digital radians per sample, determine an estimated FIR order via a standard window-based bound, which can be used as an order estimate for equiripple design.\n\nYour program must:\n1. Convert passband ripple and stopband attenuation specifications from decibels to linear tolerances appropriate for amplitude constraints. Let the passband ripple be $R_p$ (in $\\mathrm{dB}$) and stopband attenuation be $A_s$ (in $\\mathrm{dB}$). Define the linear passband tolerance $\\delta_p$ and the linear stopband tolerance $\\delta_s$ based on $R_p$ and $A_s$ respectively. Use the tightest tolerance $\\delta = \\min(\\delta_p,\\delta_s)$ to define the design attenuation in decibels $A$.\n2. Compute the digital transition width $\\Delta \\Omega$ in radians per sample from the transition band width $\\Delta f = f_{\\mathrm{stop,start}} - f_{\\mathrm{pass,end}}$ and sampling frequency $f_s$, i.e., $\\Delta \\Omega$ derived from $\\Delta f$ and $f_s$.\n3. Estimate the minimum FIR order $N_{\\mathrm{est}}$ using standard, widely accepted approximation methods that relate $A$ and $\\Delta \\Omega$ to the order of a linear-phase FIR filter. Use the ceiling to ensure the estimated order is an integer that should meet or exceed the constraints.\n4. For each test case, design an equiripple low-pass FIR filter with $N_{\\mathrm{est}}+1$ taps (filter length), passband $[0,f_{\\mathrm{pass,end}}]$, and stopband $[f_{\\mathrm{stop,start}}, f_N]$, weighting the passband and stopband error according to $\\delta_p$ and $\\delta_s$. Evaluate its magnitude response to compute:\n   - The maximum absolute passband deviation in decibels from $0\\ \\mathrm{dB}$ over $[0, f_{\\mathrm{pass,end}}]$.\n   - The achieved stopband attenuation in decibels computed as $-20\\log_{10}\\left(\\max_{f \\in [f_{\\mathrm{stop,start}}, f_N]} |H(f)|\\right)$.\n   Declare that the design meets the specifications if the passband deviation is $\\le R_p$ and the achieved stopband attenuation is $\\ge A_s$.\n5. Output, for each test case, the triple $[N_{\\mathrm{est}}, N_{\\mathrm{used}}, \\text{meets}]$ where $N_{\\mathrm{used}} = N_{\\mathrm{est}}$, and $\\text{meets}$ is a boolean indicating whether the designed filter meets the specifications when evaluated with sufficiently fine frequency resolution.\n\nTest suite:\nProvide solutions for the following parameter sets, expressed in $\\mathrm{Hz}$ and $\\mathrm{dB}$:\n- Case $1$ (happy path): $f_s = 2\\,000$, $f_{\\mathrm{pass,end}} = 400$, $f_{\\mathrm{stop,start}} = 450$, $R_p = 0.1$, $A_s = 60$.\n- Case $2$ (balanced tolerances): $f_s = 2\\,000$, $f_{\\mathrm{pass,end}} = 700$, $f_{\\mathrm{stop,start}} = 750$, $R_p = 0.086427$, $A_s = 40$.\n- Case $3$ (narrow transition, high attenuation): $f_s = 2\\,000$, $f_{\\mathrm{pass,end}} = 475$, $f_{\\mathrm{stop,start}} = 500$, $R_p = 0.05$, $A_s = 80$.\n- Case $4$ (low attenuation, wide transition): $f_s = 2\\,000$, $f_{\\mathrm{pass,end}} = 600$, $f_{\\mathrm{stop,start}} = 800$, $R_p = 1.0$, $A_s = 20$.\n\nFinal output format:\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, where each element is the list $[N_{\\mathrm{est}},N_{\\mathrm{used}},\\text{meets}]$ for each test case in the order listed above. For example, the output must have the form $[[n_1,n_1,\\text{True}],[n_2,n_2,\\text{False}],\\dots]$ with integers and booleans only, using the exact characters and delimiters shown.",
            "solution": "The user requests a solution to a problem in digital signal processing, specifically the design and verification of a Finite Impulse Response (FIR) anti-alias low-pass filter for neuroscience data. The problem is scientifically grounded, well-posed, and provides all necessary parameters and constraints for a unique solution. It is a standard exercise in filter design.\n\n### Problem Validation\n\n**Step 1: Extract Givens**\n- Sampling frequency: $f_s$\n- Passband edge frequency: $f_{\\mathrm{pass,end}}$\n- Stopband edge frequency: $f_{\\mathrm{stop,start}}$\n- Maximum passband ripple: $R_p$ (in $\\mathrm{dB}$)\n- Minimum stopband attenuation: $A_s$ (in $\\mathrm{dB}$)\n- Nyquist frequency definition: $f_N = f_s/2$\n- FIR filter design method: Equiripple (Parks-McClellan)\n- FIR order estimation method: A standard approximation using a single attenuation value $A$ derived from $\\delta = \\min(\\delta_p, \\delta_s)$, and the digital transition width $\\Delta \\Omega$.\n- Test cases:\n    1. $f_s = 2000$, $f_{\\mathrm{pass,end}} = 400$, $f_{\\mathrm{stop,start}} = 450$, $R_p = 0.1$, $A_s = 60$.\n    2. $f_s = 2000$, $f_{\\mathrm{pass,end}} = 700$, $f_{\\mathrm{stop,start}} = 750$, $R_p = 0.086427$, $A_s = 40$.\n    3. $f_s = 2000$, $f_{\\mathrm{pass,end}} = 475$, $f_{\\mathrm{stop,start}} = 500$, $R_p = 0.05$, $A_s = 80$.\n    4. $f_s = 2000$, $f_{\\mathrm{pass,end}} = 600$, $f_{\\mathrm{stop,start}} = 800$, $R_p = 1.0$, $A_s = 20$.\n\n**Step 2: Validate Using Extracted Givens**\n- **Scientifically Grounded:** The problem is based on the fundamental principles of digital signal processing (DSP), including the Nyquist-Shannon sampling theorem, FIR filter theory, and standard design specifications (passband/stopband ripple, attenuation). These are core concepts in electrical engineering and data analysis. The application to neuroscience is appropriate and realistic.\n- **Well-Posed:** The problem provides a clear, quantitative objective and all necessary data for each test case. The specified procedures for estimation and design are standard and lead to a unique, verifiable solution.\n- **Objective:** The language is precise and technical, free of subjectivity or ambiguity.\n\n**Step 3: Verdict and Action**\nThe problem is valid. A complete solution will be provided.\n\n### Principle-Based Solution Design\n\nThe design and verification of the FIR anti-alias filter proceed through four principal stages, as detailed below.\n\n**1. Conversion of Specifications to Linear Tolerances**\nThe filter specifications are given in decibels ($\\mathrm{dB}$), which is a logarithmic scale convenient for representing wide dynamic ranges. However, filter design algorithms like the Parks-McClellan algorithm operate on linear amplitude tolerances. We must convert the passband ripple $R_p$ and stopband attenuation $A_s$ into linear deviation parameters $\\delta_p$ and $\\delta_s$.\n\n- The passband tolerance, $\\delta_p$, defines the maximum allowable deviation from the desired unity gain ($1$, or $0\\ \\mathrm{dB}$). The specification on the passband deviation from $0\\ \\mathrm{dB}$ is $R_p$. We relate this to $\\delta_p$ by the equation:\n  $$R_p = 20 \\log_{10}(1 + \\delta_p)$$\n  Solving for $\\delta_p$ yields:\n  $$\\delta_p = 10^{R_p/20} - 1$$\n\n- The stopband tolerance, $\\delta_s$, defines the maximum permissible amplitude in the stopband. The stopband attenuation, $A_s$, is related to $\\delta_s$ by:\n  $$A_s = -20 \\log_{10}(\\delta_s)$$\n  Solving for $\\delta_s$ gives:\n  $$\\delta_s = 10^{-A_s/20}$$\n\n**2. Estimation of Minimum Filter Order**\nThe order of an FIR filter, $N$, determines its length ($N+1$ coefficients or \"taps\") and is the primary factor governing its ability to meet performance specifications. A sharper transition between the passband and stopband, and/or higher attenuation, requires a higher order. The problem asks for an estimation based on a standard approximation. We use Kaiser's empirical formula, which relates the filter order to the transition bandwidth and required attenuation:\n$$N \\ge \\frac{A - 8}{2.285 \\Delta\\Omega}$$\nwhere:\n- $N$ is the filter order. We take the ceiling of the result, $N_{\\mathrm{est}} = \\lceil\\frac{A-8}{2.285\\Delta\\Omega}\\rceil$, to ensure the order is an integer sufficient to meet the specification.\n- $A$ is the required attenuation in $\\mathrm{dB}$, defined using the more stringent of the two tolerances: $A = -20 \\log_{10}(\\min(\\delta_p, \\delta_s))$.\n- $\\Delta\\Omega$ is the normalized digital transition width in radians per sample. It is calculated from the analog transition width $\\Delta f = f_{\\mathrm{stop,start}} - f_{\\mathrm{pass,end}}$ and the sampling frequency $f_s$:\n  $$\\Delta\\Omega = 2\\pi \\frac{\\Delta f}{f_s}$$\n\n**3. Equiripple FIR Filter Synthesis**\nWith the estimated order $N_{\\mathrm{est}}$, we design the filter using the Parks-McClellan algorithm. This algorithm finds the optimal set of $N_{\\mathrm{est}}+1$ filter coefficients that minimizes the maximum weighted approximation error across the specified frequency bands. This results in an \"equiripple\" frequency response, where the error ripples are of equal magnitude in the passband and stopband (when weighted).\nThe algorithm requires the following inputs:\n- **Number of taps:** $N_{\\mathrm{est}}+1$.\n- **Frequency bands:** For a low-pass filter, these are the passband $[0, f_{\\mathrm{pass,end}}]$ and the stopband $[f_{\\mathrm{stop,start}}, f_N]$, where $f_N = f_s/2$ is the Nyquist frequency. These are normalized by $f_N$.\n- **Desired response:** $[1, 0]$ corresponding to unity gain in the passband and zero gain in the stopband.\n- **Weights:** The weights for each band are set to be inversely proportional to the desired tolerances to ensure the algorithm strives to meet the specifications. To achieve maximum errors of $\\delta_p$ and $\\delta_s$ in the two bands, the ratio of stopband weight $W_s$ to passband weight $W_p$ must be $W_s/W_p = \\delta_p/\\delta_s$. We can set the weights as $[1, \\delta_p/\\delta_s]$.\n\n**4. Performance Verification**\nThe filter designed using the estimated order $N_{\\mathrm{est}}$ is a candidate. Its actual performance must be rigorously evaluated to confirm it meets the original specifications. This is done by computing the filter's magnitude frequency response $|H(f)|$ at a high resolution and measuring its characteristics.\n- The frequency response is computed using the Fast Fourier Transform (FFT) on the filter's impulse response $h[n]$.\n- **Passband Verification:** The maximum absolute deviation from $0\\ \\mathrm{dB}$ is found across the passband frequency range $[0, f_{\\mathrm{pass,end}}]$:\n  $$R_{p, \\text{actual}} = \\max_{f \\in [0, f_{\\mathrm{pass,end}}]} |20 \\log_{10}(|H(f)|)|$$\n  The filter meets the passband specification if $R_{p, \\text{actual}} \\le R_p$.\n- **Stopband Verification:** The achieved stopband attenuation is calculated from the maximum linear magnitude in the stopband $[f_{\\mathrm{stop,start}}, f_N]$:\n  $$A_{s, \\text{actual}} = -20 \\log_{10} \\left( \\max_{f \\in [f_{\\mathrm{stop,start}}, f_N]} |H(f)| \\right)$$\n  The filter meets the stopband specification if $A_{s, \\text{actual}} \\ge A_s$.\n\nA boolean flag, $\\text{meets}$, is set to true if and only if both the passband and stopband specifications are met. The final output for each case is the triplet $[N_{\\mathrm{est}}, N_{\\mathrm{used}}, \\text{meets}]$, where $N_{\\mathrm{used}} = N_{\\mathrm{est}}$.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy import signal as sp_signal\n\ndef solve():\n    \"\"\"\n    Solves the FIR filter design and verification problem for a given set of test cases.\n    \"\"\"\n    \n    # Test cases: (fs, f_pass_end, f_stop_start, R_p, A_s)\n    test_cases = [\n        # Case 1 (happy path)\n        (2000.0, 400.0, 450.0, 0.1, 60.0),\n        # Case 2 (balanced tolerances)\n        (2000.0, 700.0, 750.0, 0.086427, 40.0),\n        # Case 3 (narrow transition, high attenuation)\n        (2000.0, 475.0, 500.0, 0.05, 80.0),\n        # Case 4 (low attenuation, wide transition)\n        (2000.0, 600.0, 800.0, 1.0, 20.0),\n    ]\n\n    results = []\n\n    for case in test_cases:\n        f_s, f_pass_end, f_stop_start, R_p, A_s = case\n\n        # Step 1: Convert passband ripple and stopband attenuation from dB to linear tolerances.\n        # R_p = 20 * log10(1 + delta_p) => delta_p = 10^(R_p/20) - 1\n        delta_p = 10**(R_p / 20.0) - 1\n        # A_s = -20 * log10(delta_s) => delta_s = 10^(-A_s/20)\n        delta_s = 10**(-A_s / 20.0)\n\n        # Step 2: Compute digital transition width and design attenuation for order estimation.\n        # Transition width in Hz\n        delta_f = f_stop_start - f_pass_end\n        # Digital transition width in radians per sample\n        delta_omega = 2.0 * np.pi * delta_f / f_s\n        \n        # Design attenuation A based on the tightest tolerance, as per problem spec\n        A = -20.0 * np.log10(min(delta_p, delta_s))\n\n        # Step 3: Estimate minimum FIR order using Kaiser's approximation.\n        # N_est >= (A - 8) / (2.285 * delta_omega)\n        # We use ceil to ensure the order is sufficient.\n        N_est = int(np.ceil((A - 8.0) / (2.285 * delta_omega)))\n        \n        # The problem specifies using N_est as the order for the candidate filter.\n        N_used = N_est\n\n        # Step 4: Design an equiripple FIR filter and evaluate its performance.\n        num_taps = N_used + 1\n        nyquist_freq = f_s / 2.0\n        \n        # Define bands for remez: [passband_edge, stopband_edge] normalized to Nyquist freq.\n        bands = [0, f_pass_end, f_stop_start, nyquist_freq]\n        \n        # Define desired response for each band: [passband_gain, stopband_gain]\n        desired = [1, 0]\n        \n        # Define weights for each band. The ratio should be Ws/Wp = delta_p/delta_s.\n        weights = [1.0, delta_p / delta_s]\n\n        # Design the equiripple filter using the Parks-McClellan algorithm\n        try:\n            fir_coeffs = sp_signal.remez(num_taps, bands, desired, weight=weights, fs=f_s)\n        except ValueError:\n            # remez can fail if specs are impossible for the given order, although unlikely here.\n            # Or if N_est is too low, resulting in not enough extrema.\n            # Handle this gracefully by marking as not meeting specs.\n            results.append([N_est, N_used, False])\n            continue\n\n        # Evaluate the filter's frequency response with high resolution\n        num_freq_points = 16384\n        w, h_freq_response = sp_signal.freqz(fir_coeffs, worN=num_freq_points)\n        \n        # Convert angular frequencies (rad/sample) to Hz\n        freqs_hz = w * f_s / (2.0 * np.pi)\n\n        # Evaluate passband performance\n        passband_indices = np.where(freqs_hz <= f_pass_end)[0]\n        passband_magnitudes_db = 20.0 * np.log10(np.abs(h_freq_response[passband_indices]))\n        \n        # Max absolute deviation from 0 dB in the passband\n        actual_passband_ripple_db = np.max(np.abs(passband_magnitudes_db))\n        \n        # Evaluate stopband performance\n        stopband_indices = np.where(freqs_hz >= f_stop_start)[0]\n        # Max magnitude in stopband\n        max_stopband_magnitude = np.max(np.abs(h_freq_response[stopband_indices]))\n        \n        # Achieved attenuation in dB\n        actual_stopband_attenuation_db = -20.0 * np.log10(max_stopband_magnitude)\n        \n        # Check if specifications are met\n        meets_passband = actual_passband_ripple_db <= R_p\n        meets_stopband = actual_stopband_attenuation_db >= A_s\n        meets_specs = bool(meets_passband and meets_stopband)\n        \n        results.append([N_est, N_used, meets_specs])\n\n    # Final print statement in the exact required format.\n    # The default str() for a list uses spaces. We build the string manually.\n    result_strings = []\n    for res in results:\n        # Format each inner list as '[val1,val2,BoolVal]'\n        result_strings.append(f\"[{res[0]},{res[1]},{res[2]}]\")\n\n    print(f\"[{','.join(result_strings)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "While anti-alias filters are the ideal preventative measure, neuroscientists often work with existing datasets where acquisition parameters may be unknown or suspect. This advanced practice introduces a powerful diagnostic method to detect aliasing in data that has already been collected. By leveraging the mathematical consistency of how a true frequency folds at different sampling rates, you will implement a hypothesis test to determine if spectral peaks observed across two recordings could originate from a single non-aliased source, or if aliasing is the more likely explanation .",
            "id": "4137717",
            "problem": "You are analyzing frequency-domain peaks from a continuous-time neural signal (for example, a local field potential) that has been re-recorded at two different sampling rates. In discrete-time acquisition, sampling a continuous-time signal replicates its spectrum at integer multiples of the sampling frequency and yields baseband observations whose positions depend on folding of the original continuous-time frequencies into the Nyquist interval. Starting from the fundamental base that sampling produces spectral replicas spaced by the sampling frequency $f_s$ and that the observable baseband spectrum lies in $[0, f_s/2]$, formulate a hypothesis test to detect aliasing by comparing whether the observed peak positions across two recordings are consistent with a single set of underlying continuous-time frequencies.\n\nLet the two recordings have sampling rates $f_{s1}$ and $f_{s2}$. Let their observed peak sets be $\\{p_1^{(i)}\\}_{i=1}^{N_1}$ and $\\{p_2^{(j)}\\}_{j=1}^{N_2}$, measured in Hertz. Because of folding, a single underlying continuous-time frequency $f$ can appear at different baseband locations depending on the sampling rate. Your task is to decide, for each provided test case, whether at least one observed peak can only be explained by an underlying frequency $f$ that exceeds a Nyquist limit of one of the recordings, which indicates aliasing.\n\nYou must design the decision rule as follows, based only on the fundamental properties above and without using any shortcut formulas in the problem statement:\n\n- Define the null hypothesis $\\mathcal{H}_0$ as: there exists a consistent set of underlying continuous-time frequencies $\\{f^{(k)}\\}$, all satisfying $f^{(k)} \\le \\min(f_{s1}/2, f_{s2}/2)$, such that their folded baseband locations match the observed sets within a tolerance $\\varepsilon$.\n- Define the alternative hypothesis $\\mathcal{H}_1$ as: to match at least one pair of observed peak positions across the two recordings within tolerance $\\varepsilon$, every consistent underlying frequency $f$ that explains that pair satisfies $f > f_{s1}/2$ or $f > f_{s2}/2$; or no consistent underlying frequency can explain that pair within $\\varepsilon$.\n\nTo make the problem computationally well-defined, constrain the search over candidate underlying frequencies by enumerating the sequences generated from each observed peak $p$ at sampling rate $f_s$ via integer shifts by $n f_s$ and sign symmetry around zero, restricted to a maximum frequency bound $f_{\\max}$ and a nonnegative frequency range, that is, consider candidate frequencies of the form $f = s \\, p + n f_s$ with $s \\in \\{+1, -1\\}$ and $n \\in \\mathbb{Z}$, and retain those satisfying $0 \\le f \\le f_{\\max}$. For each candidate $f$, determine the predicted baseband location under the other sampling rate and compare it to the observed peaks there; if the minimal absolute difference is within $\\varepsilon$, accept $f$ as a consistent explanation for that pair.\n\nYour program must implement this decision rule for the following test suite, using Hertz for all frequencies and expressing the final output as booleans. Use $\\varepsilon = 1.0$ Hertz and $f_{\\max} = 2000.0$ Hertz in all test cases.\n\nTest Suite (each test case is a tuple $(f_{s1}, \\{p_1^{(i)}\\}, f_{s2}, \\{p_2^{(j)}\\})$):\n1. $(f_{s1} = 1000, \\{50, 200, 350\\}, f_{s2} = 1500, \\{50, 200, 350\\})$\n2. $(f_{s1} = 400, \\{100\\}, f_{s2} = 1000, \\{300\\})$\n3. $(f_{s1} = 500, \\{80\\}, f_{s2} = 600, \\{180\\})$\n4. $(f_{s1} = 800, \\{400\\}, f_{s2} = 1000, \\{400\\})$\n5. $(f_{s1} = 300, \\{90, 80, 130\\}, f_{s2} = 700, \\{90, 220, 270\\})$\n\nYour program should produce a single line of output containing the results for these five test cases as a comma-separated list enclosed in square brackets, for example, \"[result1,result2,result3,result4,result5]\". Each result must be a boolean value, where True indicates rejection of $\\mathcal{H}_0$ in favor of $\\mathcal{H}_1$ (aliasing detected) and False indicates failure to reject $\\mathcal{H}_0$ (aliasing not detected). No other text should be printed.",
            "solution": "The problem requires formulating and implementing a hypothesis test to detect aliasing in a signal by comparing spectral peaks observed from two separate recordings made at different sampling rates, $f_{s1}$ and $f_{s2}$. The core of the problem rests on the fundamental principles of digital signal processing.\n\n### Principles of Sampling and Aliasing\n\nWhen a continuous-time signal with a frequency component $f$ is sampled at a rate $f_s$, its spectrum is replicated at all integer multiples of the sampling frequency, $n f_s$ for $n \\in \\mathbb{Z}$. The signal observed in the discrete domain is a superposition of all these spectral replicas. The frequency content that can be unambiguously represented lies within the Nyquist interval, defined as $[0, f_s/2]$.\n\nAn underlying continuous-time frequency $f$ that is higher than the Nyquist frequency, $f_s/2$, will be \"folded\" into the Nyquist interval, appearing as a lower-frequency alias. The observed baseband frequency, $p$, for an underlying frequency $f \\ge 0$ is the minimum distance to any spectral replica grid line, $n f_s$. This can be expressed as the function $Fold(f, f_s)$:\n$$\np = Fold(f, f_s) = \\min_{n \\in \\mathbb{Z}} |f - n f_s|\n$$\nThis calculation is equivalent to taking the frequency modulo $f_s$ and then folding the upper half of the $[0, f_s)$ interval back into the lower half. Specifically, let $f' = f \\pmod{f_s}$. The folded frequency is $p = \\min(f', f_s - f')$.\n\nConversely, an observed peak $p$ in the baseband interval $[0, f_s/2]$ could originate from any underlying frequency $f$ that satisfies $p = Fold(f, f_s)$. This condition holds if, for some integer $n$, either $f - n f_s = p$ or $f - n f_s = -p$. Rearranging for $f$, we get the set of all possible source frequencies:\n$$\nf = s \\cdot p + n \\cdot f_s, \\quad \\text{where } s \\in \\{+1, -1\\} \\text{ and } n \\in \\mathbb{Z}\n$$\nThis relationship forms the basis for generating candidate underlying frequencies from an observed peak.\n\n### Hypothesis Test Formulation\n\nWe are tasked with deciding between two hypotheses based on the observed peak sets $\\{p_1^{(i)}\\}$ from sampling at $f_{s1}$ and $\\{p_2^{(j)}\\}$ from sampling at $f_{s2}$.\n\nThe null hypothesis, $\\mathcal{H}_0$, posits that no aliasing is necessary to explain the observations. Formally:\n$\\mathcal{H}_0$: There exists a set of underlying frequencies $\\{f^{(k)}\\}$, all of which are non-aliased with respect to both sampling rates (i.e., $\\forall k, f^{(k)} \\le \\min(f_{s1}/2, f_{s2}/2)$), such that this single set can account for all observed peaks $\\{p_1^{(i)}\\}$ and $\\{p_2^{(j)}\\}$ within a tolerance $\\varepsilon$.\n\nThe alternative hypothesis, $\\mathcal{H}_1$, is the logical contrary, stating that aliasing is required to explain the data.\n$\\mathcal{H}_1$: For at least one observed peak, any consistent explanation requires an underlying frequency $f$ that is aliased with respect to at least one of the sampling rates (i.e., $f > f_{s1}/2$ or $f > f_{s2}/2$). This includes the case where a peak has no consistent explanation at all.\n\n### Algorithmic Decision Rule\n\nThe decision rule is to reject $\\mathcal{H}_0$ (and conclude aliasing is present) if we can find even one observed peak, in either recording, that cannot be explained by a non-aliased underlying frequency. Otherwise, if every peak in both sets has at least one plausible non-aliased explanation, we fail to reject $\\mathcal{H}_0$.\n\nAn \"explanation\" for a peak $p_{source}$ from one recording (e.g., at rate $f_{s,source}$) consists of finding a partner peak $p_{target}$ in the other recording (at rate $f_{s,target}$) and an underlying frequency $f$ that is consistent with both. That is, $p_{source} \\approx Fold(f, f_{s,source})$ (which is true by construction of candidates) and $p_{target} \\approx Fold(f, f_{s,target})$. An explanation is \"non-aliased\" if the underlying frequency $f$ satisfies $f \\le f_{Nyquist, min}$, where $f_{Nyquist, min} = \\min(f_{s1}/2, f_{s2}/2)$.\n\nThe algorithm proceeds as follows:\n1. For each test case, determine the minimum Nyquist frequency, $f_{Nyquist, min} = \\min(f_{s1}/2, f_{s2}/2)$. This is the threshold for aliasing.\n2. Define a function, `has_non_aliased_explanation`, that takes a source peak $p_{source}$, its sampling rate $f_{s,source}$, the set of target peaks $\\{p_{target}\\}$, and the target sampling rate $f_{s,target}$.\n3. Inside this function:\n    a. Generate all candidate underlying frequencies $f$ for $p_{source}$ using the formula $f = s \\cdot p_{source} + n \\cdot f_{s,source}$, subject to the constraints $s \\in \\{+1, -1\\}$, $n \\in \\mathbb{Z}$, and $0 \\le f \\le f_{\\max}$. The range for $n$ can be derived from the frequency bounds: for each $s$, $n$ must be in the integer range $[\\lceil -s \\cdot p_{source} / f_{s,source} \\rceil, \\lfloor (f_{\\max} - s \\cdot p_{source}) / f_{s,source} \\rfloor]$.\n    b. Iterate through the generated candidate frequencies $f$. For each one, check if it constitutes a non-aliased explanation:\n        i. Verify if the candidate is non-aliased: $f \\le f_{Nyquist, min}$.\n        ii. If it is non-aliased, calculate its predicted folded frequency at the target sampling rate: $p_{pred} = Fold(f, f_{s,target})$.\n        iii. Check if this prediction matches any peak in the target set: $\\exists p_{target} \\text{ such that } |p_{pred} - p_{target}| \\le \\varepsilon$.\n        iv. If both conditions (i and iii) are met, a non-aliased explanation has been found for $p_{source}$. The function can immediately return `True`.\n    c. If the loop over all candidates completes without finding any such explanation, it means $p_{source}$ cannot be explained by a non-aliased frequency. The function returns `False`.\n4. The main decision logic then iterates through every peak $p_1^{(i)}$ in the first set and calls `has_non_aliased_explanation`. If any call returns `False`, it indicates a peak that can only be explained by aliasing (or not at all). We thus reject $\\mathcal{H}_0$ and conclude `True` (aliasing detected).\n5. If all peaks in the first set have a non-aliased explanation, we must also check every peak $p_2^{(j)}$ in the second set in the same manner. If any of these checks fail, we again conclude `True`.\n6. If all peaks in both sets are found to have at least one non-aliased explanation, we fail to reject $\\mathcal{H}_0$ and conclude `False` (aliasing not detected).\n\nThis rigorous, peak-by-peak verification directly implements the logic implied by the provided hypothesis test structure, providing a definitive conclusion for each test case.",
            "answer": "```python\nimport numpy as np\nimport math\n\ndef solve():\n    \"\"\"\n    Main function to run the aliasing detection test suite.\n    \"\"\"\n    \n    # Define parameters from the problem statement.\n    eps = 1.0\n    f_max = 2000.0\n\n    # Test suite data.\n    test_cases = [\n        (1000.0, {50.0, 200.0, 350.0}, 1500.0, {50.0, 200.0, 350.0}),\n        (400.0, {100.0}, 1000.0, {300.0}),\n        (500.0, {80.0}, 600.0, {180.0}),\n        (800.0, {400.0}, 1000.0, {400.0}),\n        (300.0, {90.0, 80.0, 130.0}, 700.0, {90.0, 220.0, 270.0}),\n    ]\n\n    def fold(f, fs):\n        \"\"\"\n        Calculates the folded frequency of an underlying frequency f\n        when sampled at rate fs. The result is in the baseband [0, fs/2].\n        \"\"\"\n        if fs == 0:\n            return f\n        f_rem = f % fs\n        return min(f_rem, fs - f_rem)\n\n    def generate_candidates(p, fs, f_max):\n        \"\"\"\n        Generates a set of candidate underlying frequencies f for an observed\n        peak p, given sampling rate fs and max frequency f_max.\n        f = s*p + n*fs, where s in {+1, -1}, n is an integer, and 0 <= f <= f_max.\n        \"\"\"\n        candidates = set()\n        if fs == 0:\n            if 0 <= p <= f_max:\n                candidates.add(p)\n            return candidates\n\n        # Case s = +1\n        n_min_s1 = math.ceil(-p / fs)\n        n_max_s1 = math.floor((f_max - p) / fs)\n        for n in range(n_min_s1, n_max_s1 + 1):\n            f = p + n * fs\n            if 0 <= f <= f_max:\n                candidates.add(f)\n        \n        # Case s = -1\n        n_min_s_neg1 = math.ceil(p / fs)\n        n_max_s_neg1 = math.floor((f_max + p) / fs)\n        for n in range(n_min_s_neg1, n_max_s_neg1 + 1):\n            f = -p + n * fs\n            if 0 <= f <= f_max:\n                candidates.add(f)\n        \n        return candidates\n\n    def has_non_aliased_explanation(p_source, fs_source, p_target_set, fs_target, nyquist_limit, eps, f_max):\n        \"\"\"\n        Checks if a given source peak has at least one non-aliased explanation.\n        An explanation is a non-aliased underlying frequency f that, when folded\n        at the target sampling rate, matches a peak in the target set.\n        \"\"\"\n        candidates = generate_candidates(p_source, fs_source, f_max)\n        \n        for f in candidates:\n            # Check if the candidate frequency is non-aliased\n            if f <= nyquist_limit:\n                # If non-aliased, check if it explains a target peak\n                p_pred = fold(f, fs_target)\n                for p_target in p_target_set:\n                    if abs(p_pred - p_target) <= eps:\n                        # Found a non-aliased explanation, so this peak is explainable\n                        return True\n                        \n        # If loop finishes, no non-aliased explanation was found for this source peak\n        return False\n\n    def solve_case(fs1, p1_set, fs2, p2_set, eps, f_max):\n        \"\"\"\n        Solves a single test case, returning True if aliasing is detected\n        and False otherwise.\n        \"\"\"\n        nyquist_limit = min(fs1 / 2.0, fs2 / 2.0)\n\n        # Check if every peak in the first set has a non-aliased explanation\n        for p1 in p1_set:\n            if not has_non_aliased_explanation(p1, fs1, p2_set, fs2, nyquist_limit, eps, f_max):\n                # This peak can only be explained by aliasing (or not at all).\n                return True\n\n        # Check if every peak in the second set has a non-aliased explanation\n        for p2 in p2_set:\n            if not has_non_aliased_explanation(p2, fs2, p1_set, fs1, nyquist_limit, eps, f_max):\n                # This peak can only be explained by aliasing (or not at all).\n                return True\n        \n        # All peaks have at least one non-aliased explanation, so fail to reject H0.\n        return False\n\n    results = []\n    for case in test_cases:\n        fs1, p1_set, fs2, p2_set = case\n        result = solve_case(fs1, p1_set, fs2, p2_set, eps, f_max)\n        results.append(result)\n\n    # Format the final output as a comma-separated list of booleans\n    # The map(str,...) is used to ensure True/False are correctly capitalized.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n\n```"
        }
    ]
}