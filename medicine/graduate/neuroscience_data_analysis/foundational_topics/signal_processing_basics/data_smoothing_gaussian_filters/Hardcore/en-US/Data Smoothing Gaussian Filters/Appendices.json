{
    "hands_on_practices": [
        {
            "introduction": "Gaussian smoothing is indispensable for noise reduction, but it comes at the cost of temporal blurring. This practice explores a direct consequence of this blurring: the attenuation of sharp signal features. By analyzing the effect of smoothing on two canonical transients—a sudden step change and a brief impulse—we can quantify this amplitude bias and build a deeper intuition for how filter width impacts the representation of rapid events in neuroscience data .",
            "id": "4153092",
            "problem": "In neuroscience data analysis, Gaussian smoothing is often used to reduce noise in time series such as synaptic currents or calcium fluorescence signals. Consider a continuous-time signal $x(t)$ smoothed by convolution with a normalized Gaussian kernel $G_{\\sigma}(t)$ of standard deviation $\\sigma$, defined by\n$$\nG_{\\sigma}(t) = \\frac{1}{\\sqrt{2 \\pi} \\, \\sigma} \\exp\\!\\left(-\\frac{t^{2}}{2 \\sigma^{2}}\\right), \\quad \\int_{-\\infty}^{\\infty} G_{\\sigma}(t) \\, dt = 1,\n$$\nand let the smoothed output be $y(t) = (x * G_{\\sigma})(t) = \\int_{-\\infty}^{\\infty} x(\\tau) \\, G_{\\sigma}(t - \\tau) \\, d\\tau$.\n\nTwo canonical sharp transients are considered:\n- A step input $x_{\\text{step}}(t) = A \\, H(t)$, where $H(t)$ is the Heaviside step function and $A > 0$ is the step height. Define the pointwise amplitude estimate at the transition by $y_{\\text{step}}(0)$, and the attenuation factor $b_{\\text{step}}(\\sigma) = y_{\\text{step}}(0)/A$.\n- An impulse-like input modeled as a narrow rectangular pulse of width $\\varepsilon > 0$ and amplitude $A > 0$ centered at $t = 0$,\n$$\nx_{\\text{imp},\\varepsilon}(t) = A \\, \\mathbf{1}_{\\{|t| \\le \\varepsilon/2\\}}(t),\n$$\nwhere $\\mathbf{1}_{\\{|t| \\le \\varepsilon/2\\}}$ is the indicator function of the interval $[-\\varepsilon/2, \\varepsilon/2]$. For the smoothed response $y_{\\text{imp},\\varepsilon}(t) = (x_{\\text{imp},\\varepsilon} * G_{\\sigma})(t)$, define the amplitude estimate as the peak value $y_{\\text{imp},\\varepsilon}(0)$ and the attenuation factor $b_{\\text{imp}}(\\sigma, \\varepsilon) = y_{\\text{imp},\\varepsilon}(0)/A$.\n\nStarting only from the definitions above and the properties of convolution with even, normalized kernels, derive expressions for:\n- $b_{\\text{step}}(\\sigma)$ as a closed-form constant.\n- The leading-order approximation of $b_{\\text{imp}}(\\sigma, \\varepsilon)$ in the small-width regime $\\varepsilon/\\sigma \\ll 1$.\n\nProvide your final answer as a single row vector $\\big[b_{\\text{step}}(\\sigma), \\, b_{\\text{imp}}(\\sigma, \\varepsilon)\\big]$ consisting of closed-form analytic expressions. No numerical evaluation is required, and no units need be reported in the final answer. If any approximation is needed, report the leading-order term in $\\varepsilon/\\sigma$ only.",
            "solution": "The user wants to solve a problem regarding Gaussian smoothing of signals, a common technique in neuroscience data analysis.\n\n### Step 1: Problem Validation\n\n**Extraction of Givens:**\n*   **Gaussian Kernel:** $G_{\\sigma}(t) = \\frac{1}{\\sqrt{2 \\pi} \\, \\sigma} \\exp\\left(-\\frac{t^{2}}{2 \\sigma^{2}}\\right)$\n*   **Normalization:** $\\int_{-\\infty}^{\\infty} G_{\\sigma}(t) \\, dt = 1$\n*   **Convolution:** $y(t) = (x * G_{\\sigma})(t) = \\int_{-\\infty}^{\\infty} x(\\tau) \\, G_{\\sigma}(t - \\tau) \\, d\\tau$\n*   **Step Input:** $x_{\\text{step}}(t) = A \\, H(t)$, where $H(t)$ is the Heaviside step function and $A > 0$.\n*   **Step Attenuation Factor:** $b_{\\text{step}}(\\sigma) = y_{\\text{step}}(0)/A$, where $y_{\\text{step}}(0)$ is the smoothed output at $t=0$.\n*   **Impulse-like Input (Rectangular Pulse):** $x_{\\text{imp},\\varepsilon}(t) = A \\, \\mathbf{1}_{\\{|t| \\le \\varepsilon/2\\}}(t)$, where $\\varepsilon > 0$ and $A > 0$. $\\mathbf{1}_{\\{\\cdot\\}}$ is the indicator function.\n*   **Impulse Attenuation Factor:** $b_{\\text{imp}}(\\sigma, \\varepsilon) = y_{\\text{imp},\\varepsilon}(0)/A$, where $y_{\\text{imp},\\varepsilon}(0)$ is the smoothed output at $t=0$.\n*   **Task 1:** Derive a closed-form expression for $b_{\\text{step}}(\\sigma)$.\n*   **Task 2:** Derive the leading-order approximation of $b_{\\text{imp}}(\\sigma, \\varepsilon)$ for the condition $\\varepsilon/\\sigma \\ll 1$.\n\n**Validation Analysis:**\n1.  **Scientific Grounding:** The problem is firmly rooted in signal processing and Fourier analysis, employing standard definitions for convolution, Gaussian functions, and idealized signals like the Heaviside step and rectangular pulse. These are fundamental tools in analyzing time-series data in many scientific fields, including neuroscience. The problem is scientifically sound.\n2.  **Well-Posedness:** The objectives are clearly stated, and all necessary mathematical definitions and constraints are provided. The problem is self-contained and structured to lead to unique, meaningful solutions for the requested quantities.\n3.  **Objectivity:** The problem is phrased using precise mathematical language, free from any subjective or ambiguous terminology.\n\n**Verdict:**\nThe problem is valid. It is a standard, well-posed problem in signal analysis that requires the application of integral calculus and approximation methods based on the provided definitions.\n\n### Step 2: Derivation of the Solution\n\n#### Part 1: Attenuation of a Step Input, $b_{\\text{step}}(\\sigma)$\n\nThe smoothed output for the step input $x_{\\text{step}}(t) = A \\, H(t)$ is given by the convolution:\n$$\ny_{\\text{step}}(t) = \\int_{-\\infty}^{\\infty} x_{\\text{step}}(\\tau) \\, G_{\\sigma}(t - \\tau) \\, d\\tau\n$$\nSubstituting the expression for $x_{\\text{step}}(\\tau)$:\n$$\ny_{\\text{step}}(t) = \\int_{-\\infty}^{\\infty} A \\, H(\\tau) \\, G_{\\sigma}(t - \\tau) \\, d\\tau\n$$\nThe Heaviside function $H(\\tau)$ is $0$ for $\\tau < 0$ and $1$ for $\\tau \\ge 0$. This property changes the lower limit of integration from $-\\infty$ to $0$:\n$$\ny_{\\text{step}}(t) = A \\int_{0}^{\\infty} G_{\\sigma}(t - \\tau) \\, d\\tau\n$$\nWe must evaluate this expression at $t=0$ to find the pointwise amplitude estimate $y_{\\text{step}}(0)$:\n$$\ny_{\\text{step}}(0) = A \\int_{0}^{\\infty} G_{\\sigma}(-\\tau) \\, d\\tau\n$$\nThe Gaussian kernel $G_{\\sigma}(t)$ is an even function, as its definition depends on $t^2$. Thus, $G_{\\sigma}(-\\tau) = G_{\\sigma}(\\tau)$. Substituting this into the integral gives:\n$$\ny_{\\text{step}}(0) = A \\int_{0}^{\\infty} G_{\\sigma}(\\tau) \\, d\\tau\n$$\nWe are given that the kernel is normalized, i.e., $\\int_{-\\infty}^{\\infty} G_{\\sigma}(\\tau) \\, d\\tau = 1$. Because $G_{\\sigma}(\\tau)$ is an even function, its integral over the positive real axis is exactly half of its total integral:\n$$\n\\int_{0}^{\\infty} G_{\\sigma}(\\tau) \\, d\\tau = \\frac{1}{2} \\int_{-\\infty}^{\\infty} G_{\\sigma}(\\tau) \\, d\\tau = \\frac{1}{2}\n$$\nSubstituting this result back into the expression for $y_{\\text{step}}(0)$:\n$$\ny_{\\text{step}}(0) = A \\cdot \\frac{1}{2} = \\frac{A}{2}\n$$\nThe attenuation factor $b_{\\text{step}}(\\sigma)$ is defined as $y_{\\text{step}}(0)/A$. Therefore:\n$$\nb_{\\text{step}}(\\sigma) = \\frac{A/2}{A} = \\frac{1}{2}\n$$\nThis result is a constant, independent of the standard deviation $\\sigma$ of the kernel.\n\n#### Part 2: Attenuation of an Impulse-like Input, $b_{\\text{imp}}(\\sigma, \\varepsilon)$\n\nThe smoothed output for the rectangular pulse input $x_{\\text{imp},\\varepsilon}(t)$ is:\n$$\ny_{\\text{imp},\\varepsilon}(t) = \\int_{-\\infty}^{\\infty} x_{\\text{imp},\\varepsilon}(\\tau) \\, G_{\\sigma}(t - \\tau) \\, d\\tau\n$$\nSubstituting the expression for $x_{\\text{imp},\\varepsilon}(\\tau) = A \\, \\mathbf{1}_{\\{|\\tau| \\le \\varepsilon/2\\}}(\\tau)$:\n$$\ny_{\\text{imp},\\varepsilon}(t) = \\int_{-\\infty}^{\\infty} A \\, \\mathbf{1}_{\\{|\\tau| \\le \\varepsilon/2\\}}(\\tau) \\, G_{\\sigma}(t - \\tau) \\, d\\tau\n$$\nThe indicator function restricts the integration interval to $[-\\varepsilon/2, \\varepsilon/2]$:\n$$\ny_{\\text{imp},\\varepsilon}(t) = A \\int_{-\\varepsilon/2}^{\\varepsilon/2} G_{\\sigma}(t - \\tau) \\, d\\tau\n$$\nThe amplitude estimate is the peak value, which, due to the symmetry of both the input pulse and the kernel, occurs at $t=0$:\n$$\ny_{\\text{imp},\\varepsilon}(0) = A \\int_{-\\varepsilon/2}^{\\varepsilon/2} G_{\\sigma}(-\\tau) \\, d\\tau\n$$\nAgain, using the even property $G_{\\sigma}(-\\tau) = G_{\\sigma}(\\tau)$:\n$$\ny_{\\text{imp},\\varepsilon}(0) = A \\int_{-\\varepsilon/2}^{\\varepsilon/2} G_{\\sigma}(\\tau) \\, d\\tau\n$$\nThe attenuation factor $b_{\\text{imp}}(\\sigma, \\varepsilon)$ is defined as $y_{\\text{imp},\\varepsilon}(0)/A$:\n$$\nb_{\\text{imp}}(\\sigma, \\varepsilon) = \\int_{-\\varepsilon/2}^{\\varepsilon/2} G_{\\sigma}(\\tau) \\, d\\tau\n$$\nWe are asked for the leading-order approximation in the regime $\\varepsilon/\\sigma \\ll 1$. This condition implies that the integration interval $[-\\varepsilon/2, \\varepsilon/2]$ is very narrow compared to the width $\\sigma$ of the Gaussian function. Over this small interval, we can approximate the integrand $G_{\\sigma}(\\tau)$ by its value at the center of the interval, $\\tau = 0$. This corresponds to taking the zeroth-order term of the Taylor expansion of $G_{\\sigma}(\\tau)$ around $\\tau=0$.\n$$\nG_{\\sigma}(\\tau) \\approx G_{\\sigma}(0) \\quad \\text{for} \\quad \\tau \\in [-\\varepsilon/2, \\varepsilon/2]\n$$\nThe value of the Gaussian kernel at its center is:\n$$\nG_{\\sigma}(0) = \\frac{1}{\\sqrt{2 \\pi} \\, \\sigma} \\exp\\left(-\\frac{0^{2}}{2 \\sigma^{2}}\\right) = \\frac{1}{\\sqrt{2 \\pi} \\, \\sigma}\n$$\nSubstituting this constant approximation into the integral for $b_{\\text{imp}}(\\sigma, \\varepsilon)$:\n$$\nb_{\\text{imp}}(\\sigma, \\varepsilon) \\approx \\int_{-\\varepsilon/2}^{\\varepsilon/2} G_{\\sigma}(0) \\, d\\tau = G_{\\sigma}(0) \\int_{-\\varepsilon/2}^{\\varepsilon/2} 1 \\, d\\tau\n$$\nThe integral simply evaluates to the length of the interval, which is $\\varepsilon/2 - (-\\varepsilon/2) = \\varepsilon$.\n$$\nb_{\\text{imp}}(\\sigma, \\varepsilon) \\approx G_{\\sigma}(0) \\cdot \\varepsilon = \\left(\\frac{1}{\\sqrt{2 \\pi} \\, \\sigma}\\right) \\varepsilon\n$$\nRewriting this to emphasize the dimensionless ratio $\\varepsilon/\\sigma$:\n$$\nb_{\\text{imp}}(\\sigma, \\varepsilon) \\approx \\frac{\\varepsilon}{\\sigma \\sqrt{2 \\pi}}\n$$\nThis is the required leading-order approximation.\n\n#### Summary of Results\n\nThe two derived quantities are:\n1.  $b_{\\text{step}}(\\sigma) = \\frac{1}{2}$\n2.  $b_{\\text{imp}}(\\sigma, \\varepsilon) \\approx \\frac{\\varepsilon}{\\sigma \\sqrt{2 \\pi}}$\n\nThe final answer should be presented as a row vector containing these two expressions.",
            "answer": "$$\n\\boxed{\\begin{pmatrix} \\frac{1}{2} & \\frac{\\varepsilon}{\\sigma \\sqrt{2 \\pi}} \\end{pmatrix}}\n$$"
        },
        {
            "introduction": "While smoothing effectively reduces noise, the temporal blurring it introduces can compromise the precision of event timing. This exercise delves into this fundamental trade-off by modeling a noisy synaptic onset and deriving the variance of its estimated timing after Gaussian filtering. This analysis provides a quantitative understanding of how the choice of filter bandwidth, $\\sigma$, directly impacts the statistical uncertainty of our temporal measurements .",
            "id": "4153041",
            "problem": "A single-trial synaptic onset in a voltage-clamp recording is modeled in continuous time by a deterministic baseline-to-step transition corrupted by additive noise. Let the underlying noiseless signal be $s(t) = A \\, H(t - \\tau)$, where $A > 0$ is the amplitude, $\\tau$ is the true onset time, and $H(\\cdot)$ is the Heaviside step function. The measured signal is $x(t) = s(t) + n(t)$, where $n(t)$ is a zero-mean, wide-sense stationary Gaussian process with two-sided power spectral density (PSD) $S_{n}(\\omega) = N_{0}/2$, with $N_{0} > 0$ constant.\n\nPrior to onset estimation and downstream hypothesis testing for differences in onset times across conditions, the data are smoothed by convolution with a Gaussian kernel\n$$\ng_{\\sigma}(t) = \\frac{1}{\\sqrt{2\\pi}\\,\\sigma}\\,\\exp\\!\\left(-\\frac{t^{2}}{2\\sigma^{2}}\\right),\n$$\nwhere $\\sigma > 0$ is the temporal standard deviation of the Gaussian filter. Define the smoothed signal as $y(t) = (g_{\\sigma} * x)(t)$. The onset-time estimator $\\hat{\\tau}$ is defined as the unique solution to the threshold-crossing equation $y(t) = A/2$ with increasing $t$.\n\nAssume the small-noise, first-order linearization regime in which the threshold crossing occurs near $t = \\tau$ and can be analyzed by perturbation about the noiseless crossing. Starting from fundamental definitions of convolution, the Fourier transform of the Gaussian, and the relation between the PSD and the variance of a filtered stationary Gaussian process, derive a closed-form analytic expression for the approximate variance $\\mathrm{Var}(\\hat{\\tau})$ as a function of $A$, $\\sigma$, and $N_{0}$ under these assumptions. Express your final variance in $\\mathrm{s}^{2}$. No numerical approximation is required, and your final expression must be closed-form.",
            "solution": "The problem statement is evaluated to be valid as it is scientifically grounded, well-posed, objective, self-contained, and free of any of the specified flaws. The problem describes a standard task in signal processing and estimation theory. We may proceed with the solution.\n\nThe measured signal is given by $x(t) = s(t) + n(t)$, where $s(t) = A \\, H(t - \\tau)$ is the deterministic signal and $n(t)$ is a zero-mean, wide-sense stationary (WSS) Gaussian noise process with a two-sided power spectral density (PSD) $S_{n}(\\omega) = N_{0}/2$.\n\nThe signal is smoothed by convolution with a Gaussian kernel $g_{\\sigma}(t) = \\frac{1}{\\sqrt{2\\pi}\\,\\sigma}\\,\\exp(-t^{2}/(2\\sigma^{2}))$. The smoothed signal is $y(t) = (g_{\\sigma} * x)(t)$. By linearity of convolution, we can write $y(t)$ as the sum of a smoothed signal component and a smoothed noise component:\n$$y(t) = (g_{\\sigma} * s)(t) + (g_{\\sigma} * n)(t) = y_s(t) + y_n(t)$$\n\nFirst, we analyze the smoothed, noiseless signal $y_s(t)$:\n$$y_s(t) = (g_{\\sigma} * s)(t) = \\int_{-\\infty}^{\\infty} g_{\\sigma}(u) s(t-u) du = \\int_{-\\infty}^{\\infty} g_{\\sigma}(u) A H(t - u - \\tau) du$$\nThe Heaviside function $H(t - u - \\tau)$ is equal to $1$ for $u < t-\\tau$ and $0$ otherwise. The integral becomes:\n$$y_s(t) = A \\int_{-\\infty}^{t-\\tau} g_{\\sigma}(u) du = A \\int_{-\\infty}^{t-\\tau} \\frac{1}{\\sqrt{2\\pi}\\,\\sigma} \\exp\\left(-\\frac{u^2}{2\\sigma^2}\\right) du$$\nThis integral represents the cumulative distribution function (CDF) of a Gaussian random variable with mean $0$ and standard deviation $\\sigma$. Let $\\Phi(z)$ be the CDF of the standard normal distribution $N(0,1)$. Then $y_s(t)$ can be expressed as:\n$$y_s(t) = A \\, \\Phi\\left(\\frac{t-\\tau}{\\sigma}\\right)$$\n\nIn the absence of noise, the threshold crossing would occur at a time $t_{cross}$ such that $y_s(t_{cross}) = A/2$.\n$$A \\, \\Phi\\left(\\frac{t_{cross}-\\tau}{\\sigma}\\right) = \\frac{A}{2} \\implies \\Phi\\left(\\frac{t_{cross}-\\tau}{\\sigma}\\right) = \\frac{1}{2}$$\nSince $\\Phi(0) = 1/2$, this implies $\\frac{t_{cross}-\\tau}{\\sigma} = 0$, which gives $t_{cross} = \\tau$. Thus, the noiseless smoothed signal crosses the threshold at the true onset time.\n\nThe onset-time estimator $\\hat{\\tau}$ is defined by the equation $y(\\hat{\\tau}) = A/2$, which, using our decomposition, is:\n$$y_s(\\hat{\\tau}) + y_n(\\hat{\\tau}) = \\frac{A}{2}$$\nWe are given that we can use a first-order linearization around the true onset time $\\tau$. We assume the estimated onset time $\\hat{\\tau}$ is close to $\\tau$, so we can Taylor-expand $y_s(\\hat{\\tau})$ around $t=\\tau$:\n$$y_s(\\hat{\\tau}) \\approx y_s(\\tau) + y_s'(\\tau) (\\hat{\\tau}-\\tau)$$\nSubstituting this into the thresholding equation gives:\n$$y_s(\\tau) + y_s'(\\tau) (\\hat{\\tau}-\\tau) + y_n(\\hat{\\tau}) \\approx \\frac{A}{2}$$\nWe know that $y_s(\\tau) = A \\Phi(0) = A/2$. In the small-noise regime, $\\hat{\\tau} \\approx \\tau$, so we can approximate $y_n(\\hat{\\tau}) \\approx y_n(\\tau)$. The equation simplifies to:\n$$\\frac{A}{2} + y_s'(\\tau) (\\hat{\\tau}-\\tau) + y_n(\\tau) \\approx \\frac{A}{2}$$\n$$y_s'(\\tau) (\\hat{\\tau}-\\tau) \\approx -y_n(\\tau)$$\nThe error in the estimate, $\\delta\\tau = \\hat{\\tau}-\\tau$, is therefore approximately:\n$$\\delta\\tau \\approx -\\frac{y_n(\\tau)}{y_s'(\\tau)}$$\nThe variance of the estimator, $\\mathrm{Var}(\\hat{\\tau})$, can be approximated by the variance of this error term. Since $\\tau$ and $y_s'(\\tau)$ are deterministic, non-random quantities:\n$$\\mathrm{Var}(\\hat{\\tau}) = \\mathrm{Var}(\\delta\\tau) \\approx \\mathrm{Var}\\left(-\\frac{y_n(\\tau)}{y_s'(\\tau)}\\right) = \\frac{\\mathrm{Var}(y_n(\\tau))}{(y_s'(\\tau))^2}$$\n\nWe now need to compute the two terms in this expression: $y_s'(\\tau)$ and $\\mathrm{Var}(y_n(\\tau))$.\n\nFirst, the derivative of the smoothed signal $y_s'(t)$. Using the property that differentiation commutes with convolution, $(f*g)' = f*g'$, we have:\n$$y_s'(t) = (g_\\sigma * s)'(t) = (g_\\sigma * s')(t)$$\nThe derivative of the signal $s(t) = A H(t-\\tau)$ is $s'(t) = A \\delta(t-\\tau)$, where $\\delta(\\cdot)$ is the Dirac delta function.\n$$y_s'(t) = \\int_{-\\infty}^{\\infty} g_{\\sigma}(t-u) A \\delta(u-\\tau) du = A g_{\\sigma}(t-\\tau)$$\nEvaluating at $t=\\tau$:\n$$y_s'(\\tau) = A g_{\\sigma}(0) = A \\left(\\frac{1}{\\sqrt{2\\pi}\\,\\sigma}\\,\\exp(0)\\right) = \\frac{A}{\\sqrt{2\\pi}\\sigma}$$\n\nSecond, the variance of the smoothed noise, $\\mathrm{Var}(y_n(\\tau))$. The process $y_n(t)$ is the output of a linear time-invariant (LTI) system with impulse response $g_\\sigma(t)$ and a WSS input $n(t)$. The output process $y_n(t)$ is also WSS, so its variance is constant over time. The variance of a zero-mean WSS process is equal to its total power, which is the integral of its PSD over all angular frequencies $\\omega$, divided by $2\\pi$. The output PSD, $S_{y_n}(\\omega)$, is related to the input PSD, $S_n(\\omega)$, by:\n$$S_{y_n}(\\omega) = |G_{\\sigma}(\\omega)|^2 S_{n}(\\omega)$$\nwhere $G_{\\sigma}(\\omega)$ is the Fourier transform of the filter $g_{\\sigma}(t)$. The Fourier transform of a normalized Gaussian is a Gaussian:\n$$G_{\\sigma}(\\omega) = \\mathcal{F}\\{g_{\\sigma}(t)\\} = \\mathcal{F}\\left\\{\\frac{1}{\\sqrt{2\\pi}\\sigma} \\exp\\left(-\\frac{t^2}{2\\sigma^2}\\right)\\right\\} = \\exp\\left(-\\frac{\\omega^2\\sigma^2}{2}\\right)$$\nThe input noise PSD is given as $S_n(\\omega) = N_0/2$. The output PSD is therefore:\n$$S_{y_n}(\\omega) = \\left|\\exp\\left(-\\frac{\\omega^2\\sigma^2}{2}\\right)\\right|^2 \\frac{N_0}{2} = \\exp(-\\omega^2\\sigma^2) \\frac{N_0}{2}$$\nThe variance of the smoothed noise is:\n$$\\mathrm{Var}(y_n) = \\frac{1}{2\\pi} \\int_{-\\infty}^{\\infty} S_{y_n}(\\omega) d\\omega = \\frac{1}{2\\pi} \\int_{-\\infty}^{\\infty} \\frac{N_0}{2} \\exp(-\\omega^2\\sigma^2) d\\omega = \\frac{N_0}{4\\pi} \\int_{-\\infty}^{\\infty} \\exp(-\\sigma^2\\omega^2) d\\omega$$\nThis is a standard Gaussian integral of the form $\\int_{-\\infty}^{\\infty} \\exp(-ax^2)dx = \\sqrt{\\pi/a}$. Here, $a=\\sigma^2$.\n$$\\int_{-\\infty}^{\\infty} \\exp(-\\sigma^2\\omega^2) d\\omega = \\sqrt{\\frac{\\pi}{\\sigma^2}} = \\frac{\\sqrt{\\pi}}{\\sigma}$$\nSubstituting this back into the variance expression:\n$$\\mathrm{Var}(y_n) = \\frac{N_0}{4\\pi} \\left(\\frac{\\sqrt{\\pi}}{\\sigma}\\right) = \\frac{N_0}{4\\sqrt{\\pi}\\sigma}$$\n\nFinally, we substitute the expressions for $y_s'(\\tau)$ and $\\mathrm{Var}(y_n)$ into the formula for $\\mathrm{Var}(\\hat{\\tau})$:\n$$\\mathrm{Var}(\\hat{\\tau}) \\approx \\frac{\\mathrm{Var}(y_n)}{(y_s'(\\tau))^2} = \\frac{\\frac{N_0}{4\\sqrt{\\pi}\\sigma}}{\\left(\\frac{A}{\\sqrt{2\\pi}\\sigma}\\right)^2} = \\frac{N_0}{4\\sqrt{\\pi}\\sigma} \\cdot \\frac{(\\sqrt{2\\pi}\\sigma)^2}{A^2}$$\n$$\\mathrm{Var}(\\hat{\\tau}) \\approx \\frac{N_0}{4\\sqrt{\\pi}\\sigma} \\cdot \\frac{2\\pi\\sigma^2}{A^2} = \\frac{2\\pi N_0 \\sigma^2}{4\\sqrt{\\pi} \\sigma A^2} = \\frac{\\pi N_0 \\sigma}{2\\sqrt{\\pi} A^2} = \\frac{\\sqrt{\\pi} N_0 \\sigma}{2 A^2}$$\nThe units of $A$ are volts (V), $\\sigma$ are seconds (s), and $N_0$ are $V^2 \\cdot s$. The resulting units for the variance are $(V^2 \\cdot s) \\cdot s / V^2 = s^2$, as required.",
            "answer": "$$ \\boxed{\\frac{\\sqrt{\\pi} N_0 \\sigma}{2 A^2}} $$"
        },
        {
            "introduction": "Applying filters to finite data segments, such as a peri-stimulus time window, introduces the practical challenge of handling data boundaries. The choice of a 'padding' scheme—how we extrapolate the signal beyond its measured domain—can create significant artifacts near the edges. This practice provides a rigorous comparison of common padding methods by quantifying the error, or 'edge artifact,' each one introduces when smoothing a step-like response at a boundary .",
            "id": "4153097",
            "problem": "A common operation in neuroscience data analysis is smoothing a Peri-Stimulus Time Histogram (PSTH) using a Gaussian filter to estimate time-varying firing rates. Consider a continuous-time PSTH modeled as a step change at stimulus onset, with baseline firing rate $B \\ge 0$ for times $t < 0$ and a step to $B + A$ for times $t \\ge 0$, where $A > 0$ is the step amplitude. Let the Gaussian filter kernel be $g_{\\sigma}(t) = \\frac{1}{\\sigma \\sqrt{2 \\pi}} \\exp\\!\\left(-\\frac{t^{2}}{2 \\sigma^{2}}\\right)$ for standard deviation $\\sigma > 0$, and define Gaussian smoothing of a signal $x(t)$ as the convolution $(x * g_{\\sigma})(t) = \\int_{-\\infty}^{\\infty} g_{\\sigma}(\\tau)\\, x(t - \\tau)\\, d\\tau$. The ideal full-data smoothed output is $y^{\\star}(t) = (x_{\\star} * g_{\\sigma})(t)$ for the full-data signal $x_{\\star}(t)$ defined by $x_{\\star}(t) = B$ for $t < 0$ and $x_{\\star}(t) = B + A$ for $t \\ge 0$.\n\nIn practice, smoothing near the stimulus onset boundary at $t = 0$ requires a padding scheme because only data for $t \\ge 0$ are available. Define three padding schemes that extend the observed signal $x(t)$ (known only for $t \\ge 0$) to a padded signal $\\tilde{x}(t)$ for all $t \\in \\mathbb{R}$:\n- Zero padding: $\\tilde{x}(t) = x(t)$ for $t \\ge 0$ and $\\tilde{x}(t) = 0$ for $t < 0$.\n- Reflection padding: $\\tilde{x}(t) = x(t)$ for $t \\ge 0$ and $\\tilde{x}(t) = x(|t|)$ for $t < 0$.\n- Constant extension padding: $\\tilde{x}(t) = x(t)$ for $t \\ge 0$ and $\\tilde{x}(t) = x(0)$ for $t < 0$.\n\nFor each padding scheme, derive the smoothed output $\\tilde{y}(t) = (\\tilde{x} * g_{\\sigma})(t)$ at times $t \\ge 0$, starting from the convolution definition and the properties of the Gaussian kernel. Then, define the edge artifact magnitude $M$ for each scheme as the maximum absolute deviation of the padded smoothed output from the ideal full-data smoothed output over nonnegative times,\n$$\nM \\equiv \\sup_{t \\ge 0} \\left| \\tilde{y}(t) - y^{\\star}(t) \\right|.\n$$\nExpress the final results as dimensionless fractions of the step amplitude by reporting $M/A$ for the three schemes in the order specified above (zero padding, reflection padding, constant extension padding). Provide the three values in a single row matrix. No rounding is required.",
            "solution": "The problem is scientifically grounded, well-posed, and objective. All terms and conditions are formally defined, allowing for a rigorous mathematical solution. The problem is therefore deemed valid.\n\nThe solution requires calculating the smoothed output for three different padding schemes and comparing each to an ideal smoothed output. The core of the problem involves computing convolution integrals with a Gaussian kernel.\n\nFirst, we establish the necessary definitions and compute the ideal smoothed output, which serves as a common reference. The ideal signal, representing a step change in firing rate, is given by\n$$\nx_{\\star}(t) = \\begin{cases} B & t < 0 \\\\ B+A & t \\ge 0 \\end{cases}\n$$\nThis can be expressed using the Heaviside step function $H(t)$ (where $H(t)=1$ for $t \\ge 0$ and $H(t)=0$ for $t < 0$) as $x_{\\star}(t) = B + A H(t)$.\n\nThe Gaussian filter kernel is $g_{\\sigma}(t) = \\frac{1}{\\sigma \\sqrt{2 \\pi}} \\exp\\left(-\\frac{t^{2}}{2 \\sigma^{2}}\\right)$. The integral of this kernel is central to the convolution operation. Let $\\Phi(u)$ be the cumulative distribution function (CDF) of the standard normal distribution $N(0, 1)$:\n$$\n\\Phi(u) = \\int_{-\\infty}^{u} \\frac{1}{\\sqrt{2\\pi}} \\exp\\left(-\\frac{v^2}{2}\\right) dv\n$$\nWith a change of variables $v = \\tau/\\sigma$, we can show that the integral of the specified Gaussian kernel is related to $\\Phi(u)$:\n$$\n\\int_{-\\infty}^{t} g_{\\sigma}(\\tau) d\\tau = \\int_{-\\infty}^{t/\\sigma} \\frac{1}{\\sqrt{2\\pi}} \\exp\\left(-\\frac{v^2}{2}\\right) dv = \\Phi\\left(\\frac{t}{\\sigma}\\right)\n$$\nA key property of $\\Phi(u)$ is that $\\Phi(0) = 1/2$.\n\nThe ideal smoothed output $y^{\\star}(t)$ is the convolution $(x_{\\star} * g_{\\sigma})(t)$:\n$$\ny^{\\star}(t) = \\int_{-\\infty}^{\\infty} g_{\\sigma}(\\tau) x_{\\star}(t - \\tau) d\\tau\n$$\nBy linearity of convolution, $y^{\\star}(t) = ((B + A H) * g_{\\sigma})(t) = (B * g_{\\sigma})(t) + (A H * g_{\\sigma})(t)$.\nThe convolution of a constant $B$ with the normalized kernel $g_{\\sigma}$ is simply $B$. The convolution of the scaled Heaviside function $A H(t)$ is:\n$$\n(A H * g_{\\sigma})(t) = A \\int_{-\\infty}^{\\infty} g_{\\sigma}(\\tau) H(t - \\tau) d\\tau = A \\int_{-\\infty}^{t} g_{\\sigma}(\\tau) d\\tau = A \\Phi\\left(\\frac{t}{\\sigma}\\right)\n$$\nTherefore, the ideal smoothed output is:\n$$\ny^{\\star}(t) = B + A \\Phi\\left(\\frac{t}{\\sigma}\\right)\n$$\n\nNow we analyze each padding scheme for the observed signal $x(t) = B+A$ for $t \\ge 0$.\n\n**1. Zero Padding**\nThe padded signal $\\tilde{x}_{zero}(t)$ is defined as $\\tilde{x}_{zero}(t) = x(t)$ for $t \\ge 0$ and $\\tilde{x}_{zero}(t) = 0$ for $t < 0$. This can be written as $\\tilde{x}_{zero}(t) = (B+A)H(t)$.\nThe smoothed output $\\tilde{y}_{zero}(t)$ is:\n$$\n\\tilde{y}_{zero}(t) = (\\tilde{x}_{zero} * g_{\\sigma})(t) = ((B+A)H * g_{\\sigma})(t) = (B+A) \\Phi\\left(\\frac{t}{\\sigma}\\right)\n$$\nThe deviation from the ideal output for $t \\ge 0$ is:\n$$\nD_{zero}(t) = \\tilde{y}_{zero}(t) - y^{\\star}(t) = (B+A) \\Phi\\left(\\frac{t}{\\sigma}\\right) - \\left(B + A \\Phi\\left(\\frac{t}{\\sigma}\\right)\\right) = B \\Phi\\left(\\frac{t}{\\sigma}\\right) - B = B\\left(\\Phi\\left(\\frac{t}{\\sigma}\\right) - 1\\right)\n$$\nThe edge artifact magnitude $M_{zero}$ is the supremum of the absolute deviation for $t \\ge 0$:\n$$\nM_{zero} = \\sup_{t \\ge 0} \\left| B\\left(\\Phi\\left(\\frac{t}{\\sigma}\\right) - 1\\right) \\right|\n$$\nSince $B \\ge 0$ and $\\Phi(u) \\le 1$, the expression inside the absolute value is non-positive. Thus:\n$$\nM_{zero} = \\sup_{t \\ge 0} -B\\left(\\Phi\\left(\\frac{t}{\\sigma}\\right) - 1\\right) = \\sup_{t \\ge 0} B\\left(1 - \\Phi\\left(\\frac{t}{\\sigma}\\right)\\right)\n$$\nFor $t \\ge 0$, the function $\\Phi(t/\\sigma)$ is monotonically increasing, starting from $\\Phi(0)=1/2$. Therefore, $1 - \\Phi(t/\\sigma)$ is monotonically decreasing. The supremum occurs at the lower bound of the domain, $t=0$:\n$$\nM_{zero} = B\\left(1 - \\Phi(0)\\right) = B\\left(1 - \\frac{1}{2}\\right) = \\frac{B}{2}\n$$\nThe required dimensionless fraction is $M_{zero}/A = \\frac{B}{2A}$.\n\n**2. Reflection Padding**\nThe padded signal $\\tilde{x}_{refl}(t)$ is defined as $\\tilde{x}_{refl}(t) = x(t)$ for $t \\ge 0$ and $\\tilde{x}_{refl}(t) = x(|t|)$ for $t < 0$.\nGiven $x(t) = B+A$ for $t \\ge 0$, we have:\n- For $t \\ge 0$, $\\tilde{x}_{refl}(t) = B+A$.\n- For $t < 0$, $|t| > 0$, so $\\tilde{x}_{refl}(t) = x(|t|) = B+A$.\nThus, $\\tilde{x}_{refl}(t) = B+A$ for all $t \\in \\mathbb{R}$.\nThe smoothed output $\\tilde{y}_{refl}(t)$ is the convolution of a constant with $g_{\\sigma}(t)$:\n$$\n\\tilde{y}_{refl}(t) = \\int_{-\\infty}^{\\infty} g_{\\sigma}(\\tau) (B+A) d\\tau = (B+A) \\int_{-\\infty}^{\\infty} g_{\\sigma}(\\tau) d\\tau = B+A\n$$\nThe deviation from the ideal output for $t \\ge 0$ is:\n$$\nD_{refl}(t) = \\tilde{y}_{refl}(t) - y^{\\star}(t) = (B+A) - \\left(B + A \\Phi\\left(\\frac{t}{\\sigma}\\right)\\right) = A - A \\Phi\\left(\\frac{t}{\\sigma}\\right) = A\\left(1 - \\Phi\\left(\\frac{t}{\\sigma}\\right)\\right)\n$$\nThe edge artifact magnitude $M_{refl}$ is:\n$$\nM_{refl} = \\sup_{t \\ge 0} \\left| A\\left(1 - \\Phi\\left(\\frac{t}{\\sigma}\\right)\\right) \\right|\n$$\nSince $A > 0$ and $1 - \\Phi(u) \\ge 0$ for $u \\ge 0$, the absolute value is redundant. The function to be maximized is monotonically decreasing for $t \\ge 0$, so the supremum is at $t=0$:\n$$\nM_{refl} = A\\left(1 - \\Phi(0)\\right) = A\\left(1 - \\frac{1}{2}\\right) = \\frac{A}{2}\n$$\nThe required dimensionless fraction is $M_{refl}/A = \\frac{1}{2}$.\n\n**3. Constant Extension Padding**\nThe padded signal $\\tilde{x}_{const}(t)$ is defined as $\\tilde{x}_{const}(t) = x(t)$ for $t \\ge 0$ and $\\tilde{x}_{const}(t) = x(0)$ for $t < 0$.\nGiven $x(t) = B+A$ for $t \\ge 0$, we have $x(0)=B+A$. Thus:\n- For $t \\ge 0$, $\\tilde{x}_{const}(t) = B+A$.\n- For $t < 0$, $\\tilde{x}_{const}(t) = x(0) = B+A$.\nThis yields $\\tilde{x}_{const}(t) = B+A$ for all $t \\in \\mathbb{R}$, which is the same padded signal as in the reflection padding case for this specific problem.\nConsequently, all subsequent calculations are identical to the reflection padding case.\n$$\n\\tilde{y}_{const}(t) = B+A\n$$\n$$\nM_{const} = \\frac{A}{2}\n$$\nThe required dimensionless fraction is $M_{const}/A = \\frac{1}{2}$.\n\nThe three dimensionless artifact magnitudes $M/A$ in the specified order (zero, reflection, constant extension) are $\\frac{B}{2A}$, $\\frac{1}{2}$, and $\\frac{1}{2}$.",
            "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n\\frac{B}{2A} & \\frac{1}{2} & \\frac{1}{2}\n\\end{pmatrix}\n}\n$$"
        }
    ]
}