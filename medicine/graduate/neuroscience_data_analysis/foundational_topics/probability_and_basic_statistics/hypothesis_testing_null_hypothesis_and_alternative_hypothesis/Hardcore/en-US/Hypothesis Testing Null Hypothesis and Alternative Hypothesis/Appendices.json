{
    "hands_on_practices": [
        {
            "introduction": "A well-designed experiment is the foundation of valid scientific inference. Before embarking on data collection, it is crucial to determine if the study has a reasonable chance of detecting the effect of interest. This practice guides you through an essential step in experimental design: a prospective power analysis to calculate the required sample size, ensuring your study is not underpowered.",
            "id": "4169064",
            "problem": "A research team is planning a between-condition study using magnetoencephalography (MEG) sensors to detect a difference in mean sensor amplitude between two independent cohorts of participants, with equal allocation to the cohorts. Let the mean amplitude in cohort $1$ be $\\mu_{1}$ and in cohort $2$ be $\\mu_{2}$, and suppose that amplitudes are approximately Gaussian across participants with common standard deviation $\\sigma$ across the two cohorts. The team will use a two-sided independent-samples $t$ test at significance level $\\alpha = 0.05$ to test the null hypothesis $H_{0}: \\mu_{1} - \\mu_{2} = 0$ against the alternative hypothesis $H_{1}: \\mu_{1} - \\mu_{2} \\neq 0$. The effect size is specified a priori as Cohen’s $d = 0.5$, where $d = (\\mu_{1} - \\mu_{2})/\\sigma$, and the target power is $0.8$.\n\nStarting from the definitions of hypothesis testing, the sampling distribution of the difference in sample means, and the definition of Cohen’s $d$, derive the minimum per-group sample size $n$ required to achieve the target power for the specified test, stating clearly the statistical assumptions you adopt and any approximation used. Compute $n$ numerically. If your computation yields a noninteger, report the smallest integer $n$ per group that satisfies the power requirement. Provide the final $n$ with no units.",
            "solution": "The problem describes a power analysis for a two-sided, two-independent-samples study with equal sample sizes, $n$, in each group. We are given the significance level $\\alpha$, the target power $1-\\beta$, and the effect size specified by Cohen's $d$.\n\nThe null hypothesis is $H_{0}: \\mu_{1} - \\mu_{2} = 0$, and the alternative hypothesis is $H_{1}: \\mu_{1} - \\mu_{2} \\neq 0$. The data are assumed to be approximately Gaussian with a common standard deviation $\\sigma$.\n\nFor an independent-samples $t$-test, the test statistic is:\n$$T = \\frac{(\\bar{X}_1 - \\bar{X}_2) - (\\mu_1 - \\mu_2)_0}{S_p \\sqrt{\\frac{1}{n_1} + \\frac{1}{n_2}}}$$\nwhere $\\bar{X}_i$ is the sample mean of group $i$, $n_i$ is the sample size of group $i$, $(\\mu_1 - \\mu_2)_0$ is the hypothesized difference in means under $H_0$ (which is $0$), and $S_p$ is the pooled sample standard deviation. With equal sample sizes $n_1=n_2=n$, the formula simplifies. Under $H_0$, this statistic follows a Student's $t$-distribution with $df = n_1 + n_2 - 2 = 2n-2$ degrees of freedom.\n\nFor power calculations, especially when the sample size $n$ is not yet known but expected to be reasonably large, it is standard practice to use a normal approximation. This involves two main approximations:\n1. The $t$-distribution is approximated by the standard normal ($Z$) distribution.\n2. The population standard deviation $\\sigma$ is used in place of the sample pooled standard deviation $S_p$.\n\nUnder these approximations, the test statistic under $H_0$ is:\n$$Z_{test} = \\frac{\\bar{X}_1 - \\bar{X}_2}{\\sigma \\sqrt{\\frac{2}{n}}}$$\nThis statistic is approximately standard normal, $Z_{test} \\sim N(0, 1)$. For a two-sided test at significance level $\\alpha$, we reject $H_0$ if $|Z_{test}|  z_{1-\\alpha/2}$, where $z_{1-\\alpha/2}$ is the upper $1-\\alpha/2$ quantile of the standard normal distribution.\n\nPower is the probability of rejecting $H_0$ given that $H_1$ is true. Under $H_1$, the true difference in means is $\\mu_1 - \\mu_2 = \\delta$. Cohen's $d$ is defined as $d = \\frac{\\delta}{\\sigma}$, so $\\delta = d\\sigma$.\nThe sampling distribution of the difference in sample means, $\\bar{X}_1 - \\bar{X}_2$, is approximately normal with mean $\\delta$ and variance $\\frac{\\sigma^2}{n} + \\frac{\\sigma^2}{n} = \\frac{2\\sigma^2}{n}$.\nTherefore, under $H_1$, the test statistic $Z_{test}$ is approximately normally distributed with mean:\n$$E[Z_{test}] = E\\left[ \\frac{\\bar{X}_1 - \\bar{X}_2}{\\sigma \\sqrt{\\frac{2}{n}}} \\right] = \\frac{E[\\bar{X}_1 - \\bar{X}_2]}{\\sigma \\sqrt{\\frac{2}{n}}} = \\frac{d\\sigma}{\\sigma \\sqrt{\\frac{2}{n}}} = d\\sqrt{\\frac{n}{2}}$$\nThe variance of $Z_{test}$ remains $1$. Thus, under $H_1$, $Z_{test} \\sim N(d\\sqrt{n/2}, 1)$.\n\nPower is the probability $P(\\text{reject } H_0 | H_1 \\text{ is true}) = P(|Z_{test}|  z_{1-\\alpha/2} | H_1)$.\n$$ \\text{Power} = P\\left(Z_{test}  z_{1-\\alpha/2}\\right) + P\\left(Z_{test}  -z_{1-\\alpha/2}\\right) $$\nLet a standard normal variable be $Z \\sim N(0,1)$. We can write $Z_{test} = Z + d\\sqrt{n/2}$. Substituting this into the power equation:\n$$ \\text{Power} = P\\left(Z + d\\sqrt{\\frac{n}{2}}  z_{1-\\alpha/2}\\right) + P\\left(Z + d\\sqrt{\\frac{n}{2}}  -z_{1-\\alpha/2}\\right) $$\n$$ \\text{Power} = P\\left(Z  z_{1-\\alpha/2} - d\\sqrt{\\frac{n}{2}}\\right) + P\\left(Z  -z_{1-\\alpha/2} - d\\sqrt{\\frac{n}{2}}\\right) $$\nAssuming a positive effect size $d0$, the second term, which represents the probability of a statistically significant result in the opposite direction of the true effect, is typically negligible for a well-powered study. We can therefore approximate the power by the first term:\n$$ \\text{Power} \\approx P\\left(Z  z_{1-\\alpha/2} - d\\sqrt{\\frac{n}{2}}\\right) = 1-\\beta $$\nThis is equivalent to stating that the probability of a Type II error, $\\beta$, is the area to the left of the critical point:\n$$ \\beta \\approx P\\left(Z \\le z_{1-\\alpha/2} - d\\sqrt{\\frac{n}{2}}\\right) $$\nTaking the inverse standard normal cumulative distribution function (CDF), $\\Phi^{-1}(\\cdot)$, of both sides gives:\n$$ z_{\\beta} \\approx z_{1-\\alpha/2} - d\\sqrt{\\frac{n}{2}} $$\nwhere $z_{\\beta}$ is the $z$-score corresponding to a lower-tail probability of $\\beta$. Using the symmetry of the normal distribution, $z_{\\beta} = -z_{1-\\beta}$, we get:\n$$ -z_{1-\\beta} \\approx z_{1-\\alpha/2} - d\\sqrt{\\frac{n}{2}} $$\nRearranging to solve for the sample size $n$:\n$$ d\\sqrt{\\frac{n}{2}} \\approx z_{1-\\alpha/2} + z_{1-\\beta} $$\n$$ \\sqrt{n} \\approx \\frac{\\sqrt{2}(z_{1-\\alpha/2} + z_{1-\\beta})}{d} $$\n$$ n \\approx 2 \\left( \\frac{z_{1-\\alpha/2} + z_{1-\\beta}}{d} \\right)^2 $$\nThis is the desired formula for the per-group sample size.\n\nNow, we substitute the given values:\nSignificance level $\\alpha = 0.05$. For a two-sided test, this gives $z_{1-\\alpha/2} = z_{1-0.025} = z_{0.975} \\approx 1.96$.\nTarget power $1-\\beta = 0.8$, so the Type II error rate is $\\beta = 0.2$. This gives $z_{1-\\beta} = z_{0.8} \\approx 0.8416$.\nEffect size $d = 0.5$.\n\nSubstituting these values into the formula for $n$:\n$$ n \\approx 2 \\left( \\frac{1.96 + 0.8416}{0.5} \\right)^2 $$\n$$ n \\approx 2 \\left( \\frac{2.8016}{0.5} \\right)^2 $$\n$$ n \\approx 2 \\left( 5.6032 \\right)^2 $$\n$$ n \\approx 2 (31.3958) $$\n$$ n \\approx 62.7916 $$\nSince the sample size must be an integer, we must round up to the next whole number to ensure that the power requirement is met or exceeded. Therefore, the minimum required sample size per group is $n=63$.",
            "answer": "$$\\boxed{63}$$"
        },
        {
            "introduction": "The General Linear Model ($GLM$) is a cornerstone of fMRI data analysis, allowing us to model how brain activity relates to experimental conditions. This exercise moves beyond simple regression, challenging you to formulate a specific hypothesis as a linear contrast to test the differential effect of two conditions. Mastering this allows you to ask precise questions of your data and is a fundamental skill for any neuroimager.",
            "id": "4169094",
            "problem": "A single voxel time series from a functional Magnetic Resonance Imaging (fMRI) experiment is modeled using the General Linear Model (GLM). The design matrix has $p=4$ columns corresponding to: an intercept (baseline), a regressor encoding condition $\\mathcal{A}$ (e.g., faces), a regressor encoding condition $\\mathcal{B}$ (e.g., shapes), and a nuisance regressor for head motion. Let the number of scans be $N=240$. The fitted ordinary least squares estimator yields the coefficient vector\n$$\n\\hat{\\boldsymbol{\\beta}}=\\begin{pmatrix}510.0 \\\\ 1.5 \\\\ 0.6 \\\\ 0.02\\end{pmatrix},\n$$\nand the residual sum of squares is\n$$\n\\mathrm{RSS}=432.0.\n$$\nAssume the standard homoscedastic Gaussian noise model with errors $\\boldsymbol{\\varepsilon}\\sim \\mathcal{N}(\\boldsymbol{0},\\sigma^{2}\\boldsymbol{I})$, and that the estimator covariance is given by $\\sigma^{2}( \\boldsymbol{X}^{\\top}\\boldsymbol{X})^{-1}$, where the provided matrix\n$$\n(\\boldsymbol{X}^{\\top}\\boldsymbol{X})^{-1}=\\begin{pmatrix}\n0.002  0  0  0 \\\\\n0  0.010  -0.004  0 \\\\\n0  -0.004  0.012  0 \\\\\n0  0  0  0.005\n\\end{pmatrix}\n$$\nis symmetric.\n\nYou are interested in testing the experimental effect defined as the difference between the condition $\\mathcal{A}$ and condition $\\mathcal{B}$ regressors, while holding the intercept and motion regressors fixed. Formulate the null hypothesis $H_{0}$ and the alternative hypothesis $H_{1}$ for this effect using a linear contrast, construct the appropriate contrast vector $\\boldsymbol{c}$, and compute the corresponding one-degree contrast $t$-statistic for testing $H_{0}$ against $H_{1}$. Use the unbiased residual variance estimator $\\hat{\\sigma}^{2}=\\mathrm{RSS}/(N-p)$.\n\nProvide the final numerical value of the $t$-statistic. The $t$-statistic is dimensionless. Round your answer to four significant figures.",
            "solution": "The goal is to test the hypothesis that the brain's response to condition $\\mathcal{A}$ is different from its response to condition $\\mathcal{B}$. The coefficients corresponding to these conditions are $\\beta_2$ and $\\beta_3$, respectively. The null hypothesis ($H_0$) is that there is no difference between the effects of these two conditions. The alternative hypothesis ($H_1$) is that there is a difference.\n\nMathematically, the hypotheses are:\n$$\nH_0: \\beta_2 = \\beta_3 \\quad \\text{which is equivalent to} \\quad \\beta_2 - \\beta_3 = 0\n$$\n$$\nH_1: \\beta_2 \\neq \\beta_3 \\quad \\text{which is equivalent to} \\quad \\beta_2 - \\beta_3 \\neq 0\n$$\n\nThis hypothesis can be expressed as a linear contrast of the parameter vector $\\boldsymbol{\\beta} = (\\beta_1, \\beta_2, \\beta_3, \\beta_4)^\\top$. We seek a contrast vector $\\boldsymbol{c}$ such that the null hypothesis is $\\boldsymbol{c}^\\top \\boldsymbol{\\beta} = 0$. For our hypothesis, the linear combination is $0 \\cdot \\beta_1 + 1 \\cdot \\beta_2 - 1 \\cdot \\beta_3 + 0 \\cdot \\beta_4$. Therefore, the contrast vector is:\n$$\n\\boldsymbol{c} = \\begin{pmatrix} 0 \\\\ 1 \\\\ -1 \\\\ 0 \\end{pmatrix}\n$$\n\nThe one-degree contrast $t$-statistic is given by the general formula:\n$$\nt = \\frac{\\boldsymbol{c}^\\top \\hat{\\boldsymbol{\\beta}}}{\\sqrt{\\widehat{\\mathrm{Var}}(\\boldsymbol{c}^\\top \\hat{\\boldsymbol{\\beta}})}} = \\frac{\\boldsymbol{c}^\\top \\hat{\\boldsymbol{\\beta}}}{\\sqrt{\\hat{\\sigma}^2 \\boldsymbol{c}^\\top (\\boldsymbol{X}^\\top \\boldsymbol{X})^{-1} \\boldsymbol{c}}}\n$$\nThe degrees of freedom for this $t$-statistic are $\\nu = N - p$.\n\nWe will compute the components of this formula.\n\n1.  **Numerator (Contrast Effect Size)**: $\\boldsymbol{c}^\\top \\hat{\\boldsymbol{\\beta}}$\n    This is the estimated difference between the coefficients for condition $\\mathcal{A}$ and $\\mathcal{B}$.\n    $$\n    \\boldsymbol{c}^\\top \\hat{\\boldsymbol{\\beta}} = \\begin{pmatrix} 0  1  -1  0 \\end{pmatrix} \\begin{pmatrix} 510.0 \\\\ 1.5 \\\\ 0.6 \\\\ 0.02 \\end{pmatrix} = (0)(510.0) + (1)(1.5) + (-1)(0.6) + (0)(0.02) = 1.5 - 0.6 = 0.9\n    $$\n\n2.  **Unbiased Estimator of Residual Variance**: $\\hat{\\sigma}^2$\n    The degrees of freedom are $\\nu = N - p = 240 - 4 = 236$. The residual sum of squares is $\\mathrm{RSS}=432.0$.\n    $$\n    \\hat{\\sigma}^2 = \\frac{\\mathrm{RSS}}{N-p} = \\frac{432.0}{236}\n    $$\n    We will keep this as a fraction to maintain precision until the final step.\n\n3.  **Variance of the Contrast (scaled by $\\sigma^2$)**: $\\boldsymbol{c}^\\top (\\boldsymbol{X}^\\top \\boldsymbol{X})^{-1} \\boldsymbol{c}$\n    This term represents the variance of the contrast estimate, scaled by the unknown noise variance $\\sigma^2$.\n    $$\n    \\boldsymbol{c}^\\top (\\boldsymbol{X}^\\top \\boldsymbol{X})^{-1} \\boldsymbol{c} = \\begin{pmatrix} 0  1  -1  0 \\end{pmatrix} \\begin{pmatrix}\n    0.002  0  0  0 \\\\\n    0  0.010  -0.004  0 \\\\\n    0  -0.004  0.012  0 \\\\\n    0  0  0  0.005\n    \\end{pmatrix} \\begin{pmatrix} 0 \\\\ 1 \\\\ -1 \\\\ 0 \\end{pmatrix}\n    $$\n    First, we compute the product of the matrix and the contrast vector:\n    $$\n    (\\boldsymbol{X}^\\top \\boldsymbol{X})^{-1} \\boldsymbol{c} = \\begin{pmatrix}\n    0.002(0) + 0(1) + 0(-1) + 0(0) \\\\\n    0(0) + 0.010(1) + (-0.004)(-1) + 0(0) \\\\\n    0(0) + (-0.004)(1) + 0.012(-1) + 0(0) \\\\\n    0(0) + 0(1) + 0(-1) + 0.005(0)\n    \\end{pmatrix} = \\begin{pmatrix} 0 \\\\ 0.010 + 0.004 \\\\ -0.004 - 0.012 \\\\ 0 \\end{pmatrix} = \\begin{pmatrix} 0 \\\\ 0.014 \\\\ -0.016 \\\\ 0 \\end{pmatrix}\n    $$\n    Next, we compute the dot product with $\\boldsymbol{c}^\\top$:\n    $$\n    \\boldsymbol{c}^\\top ((\\boldsymbol{X}^\\top \\boldsymbol{X})^{-1} \\boldsymbol{c}) = \\begin{pmatrix} 0  1  -1  0 \\end{pmatrix} \\begin{pmatrix} 0 \\\\ 0.014 \\\\ -0.016 \\\\ 0 \\end{pmatrix} = (0)(0) + (1)(0.014) + (-1)(-0.016) + (0)(0) = 0.014 + 0.016 = 0.030\n    $$\n\n4.  **Assemble the $t$-statistic**\n    Now we can substitute all the computed parts back into the $t$-statistic formula:\n    $$\n    t = \\frac{0.9}{\\sqrt{\\left(\\frac{432.0}{236}\\right) (0.030)}}\n    $$\n    Let's evaluate the expression in the denominator:\n    $$\n    \\hat{\\sigma}^2 \\boldsymbol{c}^\\top (\\boldsymbol{X}^\\top \\boldsymbol{X})^{-1} \\boldsymbol{c} = \\frac{432.0 \\times 0.030}{236} = \\frac{12.96}{236} \\approx 0.05491525\n    $$\n    The standard error of the contrast is the square root of this value:\n    $$\n    \\mathrm{SE}(\\boldsymbol{c}^\\top \\hat{\\boldsymbol{\\beta}}) = \\sqrt{\\frac{12.96}{236}} \\approx 0.23434004\n    $$\n    Finally, the $t$-statistic is:\n    $$\n    t = \\frac{0.9}{0.23434004} \\approx 3.8405026\n    $$\n\nRounding the result to four significant figures gives $3.841$.",
            "answer": "$$\n\\boxed{3.841}\n$$"
        },
        {
            "introduction": "In scientific inquiry, failing to reject the null hypothesis of 'no difference' is not the same as proving that two conditions are equivalent. This practice introduces the Two One-Sided Tests ($TOST$) procedure, a powerful framework for formally testing for equivalence. By learning to define an equivalence margin $\\Delta$ and testing against it, you can make rigorous claims about the absence of a meaningful effect, a critical and often-overlooked aspect of hypothesis testing.",
            "id": "4169101",
            "problem": "A research team investigates the amplitude of the early visual P1 component measured with electroencephalography (EEG) under two visual stimulation protocols, denoted Protocol A and Protocol B. Each protocol is applied to distinct, independent cohorts due to differing artifact rejection rates, so treat the samples as independent with unequal variances. The amplitude is measured in microvolts and is modeled as arising from approximately normal populations with unknown means and variances.\n\nFrom quality-controlled segments, the following sample summaries are obtained:\n- Protocol A: sample size $n_{A} = 120$, sample mean $\\bar{x}_{A} = 5.3$, sample standard deviation $s_{A} = 2.8$.\n- Protocol B: sample size $n_{B} = 130$, sample mean $\\bar{x}_{B} = 4.9$, sample standard deviation $s_{B} = 3.2$.\n\nTo determine whether the two protocols produce equivalent mean P1 amplitudes within a scientifically justified margin $\\Delta = 1.5$, conduct a two one-sided tests (TOST) equivalence test under the unequal-variance (Welch) framework at significance level $\\alpha = 0.05$ for the difference in population means $\\mu_{A} - \\mu_{B}$.\n\nUse the following hypothesis structure:\n- Null hypothesis (composite): $H_{0}: \\mu_{A} - \\mu_{B} \\leq -\\Delta \\ \\text{or} \\ \\mu_{A} - \\mu_{B} \\geq \\Delta$.\n- Alternative hypothesis (equivalence): $H_{1}: -\\Delta  \\mu_{A} - \\mu_{B}  \\Delta$.\n\nDefine the equivalence decision index $D$ as\n$$\nD = \\begin{cases}\n1,  \\text{if equivalence is concluded at level } \\alpha \\text{ under the TOST procedure}, \\\\\n0,  \\text{otherwise}.\n\\end{cases}\n$$\n\nCompute $D$ from the given summaries under scientifically standard assumptions for Welch’s $t$-based inference. Report the final answer as the single number $D$. No rounding is required for the final answer.",
            "solution": "The problem requires conducting a two one-sided tests (TOST) equivalence test. The conclusion of equivalence, defined by the alternative hypothesis $H_1: -\\Delta  \\mu_{A} - \\mu_{B}  \\Delta$, is reached if and only if we can reject the composite null hypothesis $H_{0}: \\mu_{A} - \\mu_{B} \\leq -\\Delta \\ \\text{or} \\ \\mu_{A} - \\mu_{B} \\geq \\Delta$. This composite null is decomposed into two separate one-sided null hypotheses:\n$1$. $H_{01}: \\mu_{A} - \\mu_{B} \\geq \\Delta$\n$2$. $H_{02}: \\mu_{A} - \\mu_{B} \\leq -\\Delta$\n\nEquivalence is concluded at a significance level $\\alpha$ if both $H_{01}$ and $H_{02}$ are rejected, each at level $\\alpha$.\n\nThe problem specifies using the Welch framework for independent samples with unequal variances. The test statistic for the difference in means is Welch's $t$-statistic.\n\nFirst, we calculate the standard error of the difference in sample means, $SE_{(\\bar{x}_A - \\bar{x}_B)}$. The sample variances are $s_A^2 = 2.8^2 = 7.84$ and $s_B^2 = 3.2^2 = 10.24$.\n$$ SE_{(\\bar{x}_A - \\bar{x}_B)} = \\sqrt{\\frac{s_A^2}{n_A} + \\frac{s_B^2}{n_B}} $$\nSubstituting the given values:\n$$ SE = \\sqrt{\\frac{2.8^2}{120} + \\frac{3.2^2}{130}} = \\sqrt{\\frac{7.84}{120} + \\frac{10.24}{130}} \\approx \\sqrt{0.065333... + 0.078769...} \\approx \\sqrt{0.144102...} \\approx 0.379608 $$\n\nNext, we calculate the degrees of freedom $\\nu$ using the Welch-Satterthwaite equation:\n$$ \\nu = \\frac{\\left(\\frac{s_A^2}{n_A} + \\frac{s_B^2}{n_B}\\right)^2}{\\frac{(s_A^2/n_A)^2}{n_A - 1} + \\frac{(s_B^2/n_B)^2}{n_B - 1}} $$\nSubstituting the values:\n$$ \\nu = \\frac{\\left(\\frac{7.84}{120} + \\frac{10.24}{130}\\right)^2}{\\frac{(7.84/120)^2}{120 - 1} + \\frac{(10.24/130)^2}{130 - 1}} \\approx \\frac{(0.144102...)^2}{\\frac{(0.065333...)^2}{119} + \\frac{(0.078769...)^2}{129}} $$\n$$ \\nu \\approx \\frac{0.0207655}{3.5869 \\times 10^{-5} + 4.8098 \\times 10^{-5}} \\approx \\frac{0.0207655}{8.3967 \\times 10^{-5}} \\approx 247.30 $$\nFor calculating the critical value, the degrees of freedom are floored to the nearest integer, so we use $\\nu = 247$.\n\nThe critical value for a one-sided test at significance level $\\alpha = 0.05$ with $\\nu = 247$ degrees of freedom is $t_{crit} = t_{\\alpha, \\nu} = t_{0.05, 247}$. For large degrees of freedom, this value is close to the corresponding standard normal quantile $z_{0.05} \\approx 1.645$. A precise calculation yields $t_{0.05, 247} \\approx 1.6511$. We will use this value for our decision thresholds.\n\nNow we perform the two one-sided tests.\n\nTest for $H_{01}: \\mu_{A} - \\mu_{B} \\geq \\Delta$:\nThe alternative is $H_{A1}: \\mu_{A} - \\mu_{B}  \\Delta$. We test against the boundary case $\\mu_A - \\mu_B = \\Delta$.\nThe test statistic is:\n$$ t_1 = \\frac{(\\bar{x}_A - \\bar{x}_B) - \\Delta}{SE} $$\nSubstituting the values, with $\\bar{x}_A - \\bar{x}_B = 5.3 - 4.9 = 0.4$ and $\\Delta = 1.5$:\n$$ t_1 = \\frac{0.4 - 1.5}{0.379608} = \\frac{-1.1}{0.379608} \\approx -2.8977 $$\nWe reject $H_{01}$ if $t_1  -t_{crit}$. Here, $-2.8977  -1.6511$. Thus, we reject $H_{01}$.\n\nTest for $H_{02}: \\mu_{A} - \\mu_{B} \\leq -\\Delta$:\nThe alternative is $H_{A2}: \\mu_{A} - \\mu_{B}  -\\Delta$. We test against the boundary case $\\mu_A - \\mu_B = -\\Delta$.\nThe test statistic is:\n$$ t_2 = \\frac{(\\bar{x}_A - \\bar{x}_B) - (-\\Delta)}{SE} $$\nSubstituting the values:\n$$ t_2 = \\frac{0.4 - (-1.5)}{0.379608} = \\frac{1.9}{0.379608} \\approx 5.0051 $$\nWe reject $H_{02}$ if $t_2  t_{crit}$. Here, $5.0051  1.6511$. Thus, we reject $H_{02}$.\n\nSince both one-sided null hypotheses, $H_{01}$ and $H_{02}$, are rejected at the significance level $\\alpha = 0.05$, we conclude in favor of the alternative hypothesis $H_1$. This means the difference in population means is statistically equivalent to zero within the specified margin $\\Delta = 1.5$.\n\nAccording to the problem definition, the decision index $D$ is set to $1$ if equivalence is concluded. As we have concluded equivalence, $D = 1$.",
            "answer": "$$\\boxed{1}$$"
        }
    ]
}