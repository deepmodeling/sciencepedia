{
    "hands_on_practices": [
        {
            "introduction": "A fundamental goal in experimental science is to quantify how much of the variation in an outcome is due to a specific intervention. This exercise provides hands-on practice with the core logic of Analysis of Variance (ANOVA), where we partition the total variability into components explained by group differences and unexplained residual error. By calculating the eta-squared ($\\eta^2$) effect size, you will directly measure the proportion of variance in a dependent variable that is attributable to an experimental factor, a foundational skill for interpreting multi-group experiments. ",
            "id": "4909836",
            "problem": "A clinical trial investigates how three dietary interventions affect changes in low-density lipoprotein cholesterol (LDL-C; measured in $\\mathrm{mg/dL}$) after $12$ weeks. Participants are randomized into $G=3$ groups with equal allocation, and the total sample size is $N=60$. Let the group sample sizes be $n_{1}=n_{2}=n_{3}=20$. The sample mean LDL-C reductions for the groups are $\\bar{y}_{1}=47$, $\\bar{y}_{2}=50$, and $\\bar{y}_{3}=53$ (all in $\\mathrm{mg/dL}$). The within-group sums of squared deviations from their respective group means are $W_{1}=280$, $W_{2}=280$, and $W_{3}=280$ (all in $(\\mathrm{mg/dL})^{2}$). The grand mean reduction is $\\bar{y}=50$ (in $\\mathrm{mg/dL}$). The investigators report the total sum of squares $SS_{T}=1200$ (in $(\\mathrm{mg/dL})^{2}$).\n\nUsing only the core definitions of Analysis of Variance (ANOVA), namely the definitions of the total sum of squares, the between-group sum of squares, and the within-group sum of squares in terms of deviations from the grand mean and the group means, perform the following:\n\n- Compute the between-group sum of squares $SS_{B}$ from the given group means and sizes.\n- Compute the within-group sum of squares $SS_{W}$ from the given within-group sums $W_{g}$, confirm its value, and explicitly verify the variance decomposition by showing how $SS_{T}$ is partitioned.\n- Conclude the proportion of explained variance attributable to group membership, expressed as a decimal between $0$ and $1$.\n\nProvide your final answer as a single real number equal to the proportion of explained variance. No rounding is required.",
            "solution": "The problem is first assessed for validity. All provided data are self-contained, scientifically grounded in the principles of biostatistics (specifically Analysis of Variance), and internally consistent. The number of groups is $G=3$, with equal sample sizes $n_{1}=n_{2}=n_{3}=20$, resulting in a total sample size $N = n_{1}+n_{2}+n_{3} = 20+20+20=60$, which matches the given $N=60$. The grand mean $\\bar{y}=50$ is also consistent with the group means and sizes: $\\bar{y} = \\frac{\\sum_{g=1}^{G} n_{g}\\bar{y}_{g}}{N} = \\frac{20(47) + 20(50) + 20(53)}{60} = \\frac{20(47+50+53)}{60} = \\frac{150}{3} = 50$. The problem is well-posed and objective. Thus, a solution may be derived.\n\nThe problem requires the computation of several quantities based on the core definitions of ANOVA.\n\nFirst, we compute the between-group sum of squares, $SS_{B}$. This quantity measures the variation among the group means. Its definition is the sum of the squared differences between each group mean and the grand mean, weighted by the respective group sample size.\nThe formula for $SS_{B}$ is:\n$$SS_{B} = \\sum_{g=1}^{G} n_{g} (\\bar{y}_{g} - \\bar{y})^{2}$$\nSubstituting the given values: $G=3$, $n_{1}=n_{2}=n_{3}=20$, $\\bar{y}_{1}=47$, $\\bar{y}_{2}=50$, $\\bar{y}_{3}=53$, and the grand mean $\\bar{y}=50$.\n$$SS_{B} = n_{1}(\\bar{y}_{1} - \\bar{y})^{2} + n_{2}(\\bar{y}_{2} - \\bar{y})^{2} + n_{3}(\\bar{y}_{3} - \\bar{y})^{2}$$\n$$SS_{B} = 20(47 - 50)^{2} + 20(50 - 50)^{2} + 20(53 - 50)^{2}$$\n$$SS_{B} = 20(-3)^{2} + 20(0)^{2} + 20(3)^{2}$$\n$$SS_{B} = 20(9) + 0 + 20(9)$$\n$$SS_{B} = 180 + 180 = 360$$\n\nNext, we compute the within-group sum of squares, $SS_{W}$. This quantity measures the variation of individual observations within their respective groups. It is defined as the sum of the squared deviations of each observation from its group's mean. The problem provides the within-group sums of squared deviations for each group, $W_{g}$, where $W_{g} = \\sum_{i=1}^{n_{g}} (y_{gi} - \\bar{y}_{g})^{2}$. The total within-group sum of squares is the sum of these values across all groups.\n$$SS_{W} = \\sum_{g=1}^{G} W_{g}$$\nUsing the given values $W_{1}=280$, $W_{2}=280$, and $W_{3}=280$:\n$$SS_{W} = W_{1} + W_{2} + W_{3} = 280 + 280 + 280 = 3 \\times 280 = 840$$\n\nThe problem asks to explicitly verify the variance decomposition. The fundamental principle of ANOVA is that the total sum of squares, $SS_{T}$, is partitioned into the between-group sum of squares and the within-group sum of squares:\n$$SS_{T} = SS_{B} + SS_{W}$$\nUsing our computed values for $SS_{B}$ and $SS_{W}$:\n$$SS_{B} + SS_{W} = 360 + 840 = 1200$$\nThe problem statement provides that $SS_{T} = 1200$. Since our calculated sum $SS_{B} + SS_{W}$ equals the given $SS_{T}$, the decomposition is verified, confirming the consistency of all provided information.\n\nFinally, we are asked to find the proportion of explained variance attributable to group membership. This is a measure of effect size known as eta-squared, denoted by $\\eta^2$. It is defined as the ratio of the between-group sum of squares to the total sum of squares.\n$$\\eta^2 = \\frac{SS_{B}}{SS_{T}}$$\nSubstituting the values for $SS_{B}$ and $SS_{T}$:\n$$\\eta^2 = \\frac{360}{1200}$$\nSimplifying the fraction gives the proportion as a decimal:\n$$\\eta^2 = \\frac{36}{120} = \\frac{3}{10} = 0.3$$\nThus, $30\\%$ of the total variance in LDL-C reduction is attributable to the differences between the three dietary interventions.",
            "answer": "$$\\boxed{0.3}$$"
        },
        {
            "introduction": "While the standardized mean difference is a cornerstone effect size for comparing two groups, its calculation is not a one-size-fits-all procedure. The choice between estimators like pooled Cohen's $d$, the bias-corrected Hedges' $g$, or Glass's $\\Delta$ depends critically on the underlying assumptions about your data, particularly the equality of variances between groups. This problem places you in the role of a thoughtful analyst, requiring you to make a principled decision based on diagnostic evidence, a crucial step in ensuring your reported effect size is both accurate and robust. ",
            "id": "4158368",
            "problem": "A systems neuroscience lab compares two independent groups in multiple experiments: a baseline control condition and an experimental manipulation that may change both central tendency and dispersion of a neural measure (for example, population spike timing precision). For each experiment, the analyst intends to report a standardized mean difference as the primary effect size for a two-sample comparison of means under the following pre-registered procedure: first, assess variance homogeneity between groups using either the variance ratio $F$-test or Levene’s test at significance level $\\alpha = 0.05$; second, choose an effect size estimator from among pooled-$d$, Hedges’ $g$, and Glass’s $\\Delta$.\n\nFrom first principles, the standardized mean difference divides the difference in sample means by a scale estimate. Under the equal-variance assumption, the common scale is estimable by a pooled variance that is invariant to group labels. Under variance heterogeneity, pooling entangles the effect size with which group has the larger variance and with the allocation of sample sizes, whereas using a reference standard deviation from a condition that is not affected by the manipulation isolates location change from dispersion change. Finite-sample bias of the standardized mean difference under normality motivates a small-sample correction.\n\nWhich of the following decision rules is most principled and consistent with the above diagnostics and considerations?\n\nA. If the variance diagnostic is not significant at $\\alpha = 0.05$, compute pooled Cohen’s $d$. If it is significant, compute Hedges’ $g$ using the pooled variance because the small-sample correction addresses the heteroscedasticity.\n\nB. If the variance diagnostic is not significant at $\\alpha = 0.05$, compute Hedges’ $g$ (the small-sample bias-corrected pooled standardized mean difference). If it is significant at $\\alpha = 0.05$, treat variances as heterogeneous and compute Glass’s $\\Delta$ using the control group standard deviation as the reference, irrespective of which group has the larger variance.\n\nC. Compute Glass’s $\\Delta$ whenever the group sample sizes are unequal, and compute pooled Cohen’s $d$ otherwise, regardless of the variance diagnostic outcome.\n\nD. If Levene’s test is significant with variance ratio $F > 1$, compute Glass’s $\\Delta$ using the experimental group standard deviation; if Levene’s test is not significant, compute Hedges’ $g$ only when $n_1 + n_2 < 40$, otherwise compute Glass’s $\\Delta$ because it is more conservative at large $n$.",
            "solution": "The problem statement is valid. It presents a standard scenario in experimental data analysis, is based on established statistical principles, is well-posed, and contains sufficient information to determine the most principled course of action among the given options.\n\n### Derivation from First Principles\nThe task is to identify the most principled decision rule for choosing a standardized mean difference (SMD) estimator based on a pre-registered diagnostic procedure and a set of theoretical considerations. Let the two independent groups be a control group (group $1$) and an experimental group (group $2$), with sample sizes $n_1$ and $n_2$, sample means $\\bar{x}_1$ and $\\bar{x}_2$, and sample standard deviations $s_1$ and $s_2$.\n\nThe three candidate estimators are:\n1.  **Pooled Cohen’s $d$**: Defined as the difference in means divided by the pooled standard deviation, $s_p$.\n    $$d = \\frac{\\bar{x}_2 - \\bar{x}_1}{s_p}, \\quad \\text{where } s_p = \\sqrt{\\frac{(n_1-1)s_1^2 + (n_2-1)s_2^2}{n_1+n_2-2}}$$\n    This estimator presupposes that the variances are equal in the underlying populations ($\\sigma_1^2 = \\sigma_2^2$), justifying the pooling of sample variances to obtain a better estimate of the common population variance.\n\n2.  **Hedges’ $g$**: A correction to Cohen's $d$ that adjusts for small-sample bias.\n    $$g = d \\times J$$\n    where $J$ is a correction factor. For degrees of freedom $df = n_1+n_2-2$, $J = \\frac{\\Gamma(df/2)}{\\sqrt{df/2}\\Gamma((df-1)/2)}$. A common approximation is $J \\approx 1 - \\frac{3}{4df - 1}$. Like Cohen's $d$, Hedges' $g$ is based on the pooled standard deviation and thus also assumes homogeneity of variance. The problem explicitly mentions that \"Finite-sample bias of the standardized mean difference... motivates a small-sample correction.\" This makes Hedges' $g$ a more principled choice than Cohen's $d$ when pooling is appropriate.\n\n3.  **Glass’s $\\Delta$**: An SMD estimator for the case of heterogeneous variances.\n    $$\\Delta = \\frac{\\bar{x}_2 - \\bar{x}_1}{s_{\\text{ref}}}$$\n    The reference standard deviation, $s_{\\text{ref}}$, is taken from one of the groups, typically the control group. The problem states that \"using a reference standard deviation from a condition that is not affected by the manipulation isolates location change from dispersion change.\" This clearly indicates that if variances are unequal, the principled choice for $s_{\\text{ref}}$ is the standard deviation of the baseline control group, $s_1$.\n\nThe pre-registered procedure consists of two steps:\n1.  Perform a test for variance homogeneity (e.g., Levene's test) at $\\alpha = 0.05$.\n2.  Choose an SMD estimator based on the test outcome.\n\nSynthesizing a principled decision rule:\n-   **If the variance test is not significant ($p > 0.05$):** We fail to reject the null hypothesis of equal variances. The most principled action is to proceed under the assumption of homoscedasticity. This justifies using an estimator based on the pooled standard deviation. Between Cohen's $d$ and Hedges' $g$, the problem's own text favors the one with the small-sample correction. Therefore, Hedges' $g$ is the superior choice.\n-   **If the variance test is significant ($p \\le 0.05$):** We reject the null hypothesis of equal variances. The principled action is to treat the variances as heterogeneous. The problem explicitly warns against pooling in this case (\"pooling entangles the effect size...\"). It then advocates for using a reference standard deviation from the non-manipulated condition (the control group). This directly corresponds to calculating Glass's $\\Delta$ with $s_{\\text{ref}} = s_1$.\n\nTherefore, the most principled and consistent decision rule is: If the variance test is not significant, compute Hedges' $g$. If the variance test is significant, compute Glass's $\\Delta$ using the control group's standard deviation as the denominator.\n\n### Option-by-Option Analysis\n\n**A. If the variance diagnostic is not significant at $\\alpha = 0.05$, compute pooled Cohen’s $d$. If it is significant, compute Hedges’ $g$ using the pooled variance because the small-sample correction addresses the heteroscedasticity.**\nThis option has two fundamental flaws. First, for the non-significant case, it chooses Cohen's $d$, ignoring the stated principle of applying a small-sample correction for bias. Second, and more critically, for the significant case, it recommends Hedges' $g$. Hedges' $g$ is based on a pooled variance, which is inappropriate under heteroscedasticity, as stated in the problem. The justification that the \"small-sample correction addresses the heteroscedasticity\" is factually incorrect; the correction addresses bias, not the problem of pooling unequal variances.\n**Verdict: Incorrect.**\n\n**B. If the variance diagnostic is not significant at $\\alpha = 0.05$, compute Hedges’ $g$ (the small-sample bias-corrected pooled standardized mean difference). If it is significant at $\\alpha = 0.05$, treat variances as heterogeneous and compute Glass’s $\\Delta$ using the control group standard deviation as the reference, irrespective of which group has the larger variance.**\nThis option perfectly aligns with the derivation from first principles. For the non-significant case, it correctly chooses Hedges' $g$, the bias-corrected pooled estimator. For the significant case, it correctly chooses Glass's $\\Delta$ and correctly identifies the control group's standard deviation as the appropriate reference for isolating the effect of the manipulation on the mean from its effect on the variance. The clause \"irrespective of which group has the larger variance\" is also correct, as the choice of the control group as reference is theoretical, not based on sample statistics.\n**Verdict: Correct.**\n\n**C. Compute Glass’s $\\Delta$ whenever the group sample sizes are unequal, and compute pooled Cohen’s $d$ otherwise, regardless of the variance diagnostic outcome.**\nThis rule is inconsistent with the specified procedure. It completely ignores the variance homogeneity test, which was a mandatory first step. The decision is instead based on equality of sample sizes ($n_1 = n_2$). While unequal sample sizes do compound the issues of heteroscedasticity, they are not the primary criterion for choosing between a pooled and a non-pooled standardizer. The primary criterion is the homogeneity of variances itself.\n**Verdict: Incorrect.**\n\n**D. If Levene’s test is significant with variance ratio $F > 1$, compute Glass’s $\\Delta$ using the experimental group standard deviation; if Levene’s test is not significant, compute Hedges’ $g$ only when $n_1 + n_2 < 40$, otherwise compute Glass’s $\\Delta$ because it is more conservative at large $n$.**\nThis option contains multiple errors. For the significant case, it suggests using the *experimental* group standard deviation as the reference. This contradicts the principle of using a stable baseline \"not affected by the manipulation\" to isolate effects. For the non-significant case, it proposes a complex and unprincipled rule: using Hedges' $g$ only for small samples (where its correction is most needed) but switching to Glass's $\\Delta$ for large samples even when variances are deemed equal. There is no general principle to suggest Glass's $\\Delta$ is preferable to a pooled estimate when variances are homogeneous, nor is the claim that it's \"more conservative\" a sound reason to use it in this context.\n**Verdict: Incorrect.**",
            "answer": "$$\\boxed{B}$$"
        },
        {
            "introduction": "Individual studies provide single data points; true scientific understanding emerges from synthesizing a body of evidence. This practice moves from single-study analysis to the powerful technique of meta-analysis, allowing us to compute a single, summary effect from a collection of related studies. You will work through the steps of a random-effects model, which not only estimates a pooled effect size but also quantifies the heterogeneity between studies ($\\tau^{2}$), providing a more complete and nuanced picture of the overall evidence for a phenomenon. ",
            "id": "4158387",
            "problem": "A research team is synthesizing intracranial electroencephalography (iEEG) findings on the effect of hippocampal closed-loop stimulation on memory performance. Each study reports a standardized mean difference corrected for small-sample bias (Hedges’ $g$) comparing stimulation versus sham, along with its large-sample standard error. Assume each study-level estimate $y_{i}$ is approximately normally distributed with within-study variance $v_{i}$, and that the true study effects are exchangeable around a mean $\\mu$ with between-study variance $\\tau^{2}$. You are to use a random-effects meta-analysis with the DerSimonian–Laird estimator of $\\tau^{2}$.\n\nThe five studies provide the following effect sizes and standard errors:\n- Study $1$: $y_{1} = 0.35$, $\\mathrm{SE}_{1} = 0.12$.\n- Study $2$: $y_{2} = 0.58$, $\\mathrm{SE}_{2} = 0.20$.\n- Study $3$: $y_{3} = 0.10$, $\\mathrm{SE}_{3} = 0.15$.\n- Study $4$: $y_{4} = 0.42$, $\\mathrm{SE}_{4} = 0.18$.\n- Study $5$: $y_{5} = 0.27$, $\\mathrm{SE}_{5} = 0.11$.\n\nCompute the random-effects pooled Hedges’ $g$ using the DerSimonian–Laird estimator for $\\tau^{2}$, and provide a brief interpretation of the heterogeneity implied by your calculations.\n\nAnswer specification:\n- Report the pooled random-effects Hedges’ $g$ as a single unitless number.\n- Round your answer to four significant figures.\n- Your final numeric answer must be the pooled effect only; do not include any interval estimates or units in the final answer.",
            "solution": "The problem statement is scientifically valid, well-posed, and self-contained, providing all necessary data and definitions for a standard statistical procedure. The task is to compute a pooled effect size from a random-effects meta-analysis using the DerSimonian–Laird (DL) method, a well-established technique in statistics and epidemiology.\n\nThe random-effects model assumes that each of the $k=5$ studies provides an effect size estimate, $y_i$, which is drawn from a normal distribution centered on the study's true effect, $\\theta_i$, with a known within-study variance, $v_i$. This is expressed as $y_i \\sim N(\\theta_i, v_i)$. The within-study variance $v_i$ is the square of the given standard error, $v_i = \\mathrm{SE}_i^2$. The true effects, $\\theta_i$, are themselves assumed to be sampled from a superpopulation of true effects, which is a normal distribution with mean $\\mu$ (the overall pooled effect) and variance $\\tau^2$ (the between-study variance or heterogeneity). This is expressed as $\\theta_i \\sim N(\\mu, \\tau^2)$.\n\nThe DerSimonian–Laird procedure involves several steps.\n\nFirst, we calculate the within-study variances, $v_i$, and the corresponding fixed-effect weights, $w_i = 1/v_i$, for each study.\nThe provided data are:\nStudy $1$: $y_{1} = 0.35$, $\\mathrm{SE}_{1} = 0.12 \\implies v_{1} = (0.12)^2 = 0.0144$, $w_{1} = 1/0.0144 \\approx 69.444$\nStudy $2$: $y_{2} = 0.58$, $\\mathrm{SE}_{2} = 0.20 \\implies v_{2} = (0.20)^2 = 0.0400$, $w_{2} = 1/0.0400 = 25.0$\nStudy $3$: $y_{3} = 0.10$, $\\mathrm{SE}_{3} = 0.15 \\implies v_{3} = (0.15)^2 = 0.0225$, $w_{3} = 1/0.0225 \\approx 44.444$\nStudy $4$: $y_{4} = 0.42$, $\\mathrm{SE}_{4} = 0.18 \\implies v_{4} = (0.18)^2 = 0.0324$, $w_{4} = 1/0.0324 \\approx 30.864$\nStudy $5$: $y_{5} = 0.27$, $\\mathrm{SE}_{5} = 0.11 \\implies v_{5} = (0.11)^2 = 0.0121$, $w_{5} = 1/0.0121 \\approx 82.645$\n\nNext, we compute the sums required for the DL estimator.\nSum of fixed-effect weights: $\\sum_{i=1}^5 w_i \\approx 69.444 + 25.0 + 44.444 + 30.864 + 82.645 = 252.397$\nSum of weighted effects: $\\sum w_i y_i \\approx 69.444(0.35) + 25.0(0.58) + 44.444(0.10) + 30.864(0.42) + 82.645(0.27) \\approx 24.305 + 14.5 + 4.444 + 12.963 + 22.314 = 78.526$\nSum of squared weighted effects: $\\sum w_i y_i^2 \\approx 69.444(0.35^2) + 25.0(0.58^2) + 44.444(0.10^2) + 30.864(0.42^2) + 82.645(0.27^2) \\approx 8.505 + 8.410 + 0.444 + 5.444 + 6.025 = 28.828$\n\nWe calculate Cochran's $Q$ statistic, a measure of total variation:\n$$Q = \\sum_{i=1}^k w_i y_i^2 - \\frac{\\left(\\sum_{i=1}^k w_i y_i\\right)^2}{\\sum_{i=1}^k w_i}$$\nUsing the sums calculated (with higher precision):\n$$Q \\approx 28.829236 - \\frac{(78.527049)^2}{252.397713} \\approx 28.829236 - 24.431473 = 4.397763$$\nThe degrees of freedom for $Q$ are $df = k-1 = 5-1 = 4$.\n\nThe DL estimator for the between-study variance $\\tau^2$ is given by $\\hat{\\tau}^2_{DL} = \\max\\left(0, \\frac{Q - (k-1)}{C}\\right)$, where $C = \\sum w_i - \\frac{\\sum w_i^2}{\\sum w_i}$.\nWe need the sum of squared weights: $\\sum w_i^2 \\approx (69.444)^2 + (25.0)^2 + (44.444)^2 + (30.864)^2 + (82.645)^2 \\approx 4822.5 + 625.0 + 1975.3 + 952.6 + 6830.2 = 15205.6$.\nNow we compute $C$ (using higher precision):\n$$C \\approx 252.397713 - \\frac{15205.504}{252.397713} \\approx 252.397713 - 60.24432 = 192.15339$$\nNow we compute the estimate for $\\tau^2$:\n$$\\hat{\\tau}^2 = \\frac{Q - (k-1)}{C} = \\frac{4.397763 - 4}{192.15339} = \\frac{0.397763}{192.15339} \\approx 0.002070$$\nSince $\\hat{\\tau}^2 > 0$, this value is used to calculate the random-effects weights, $w_i^* = 1/(v_i + \\hat{\\tau}^2)$.\n$w_1^* = 1/(0.0144 + 0.002070) = 1/0.016470 \\approx 60.716$\n$w_2^* = 1/(0.0400 + 0.002070) = 1/0.042070 \\approx 23.770$\n$w_3^* = 1/(0.0225 + 0.002070) = 1/0.024570 \\approx 40.700$\n$w_4^* = 1/(0.0324 + 0.002070) = 1/0.034470 \\approx 29.011$\n$w_5^* = 1/(0.0121 + 0.002070) = 1/0.014170 \\approx 70.572$\n\nThe random-effects pooled estimate, $\\bar{y}_{RE}$, is the weighted average using these new weights:\n$$\\bar{y}_{RE} = \\frac{\\sum_{i=1}^k w_i^* y_i}{\\sum_{i=1}^k w_i^*}$$\n$\\sum w_i^* \\approx 60.716 + 23.770 + 40.700 + 29.011 + 70.572 = 224.769$\n$\\sum w_i^* y_i \\approx 60.716(0.35) + 23.770(0.58) + 40.700(0.10) + 29.011(0.42) + 70.572(0.27) \\approx 21.251 + 13.787 + 4.070 + 12.185 + 19.054 = 70.347$\n$$\\bar{y}_{RE} \\approx \\frac{70.347}{224.769} \\approx 0.312965$$\nRounding the pooled Hedges' $g$ to four significant figures gives $0.3130$.\n\nFor a brief interpretation of heterogeneity, the estimate $\\hat{\\tau}^2 \\approx 0.00207$ indicates the variance of the true effect sizes across studies. A more interpretable metric is the $I^2$ statistic, which represents the percentage of total variation across studies that is due to heterogeneity rather than sampling error:\n$$I^2 = \\frac{Q - (k-1)}{Q} \\times 100\\% = \\frac{4.397763 - 4}{4.397763} \\times 100\\% \\approx 9.05\\%$$\nAn $I^2$ value of approximately $9\\%$ is considered low. This suggests that the observed variability in effect sizes is predominantly due to sampling error within each study, and the true underlying effect of hippocampal stimulation is relatively consistent across the five studies included in this meta-analysis.",
            "answer": "$$\\boxed{0.3130}$$"
        }
    ]
}