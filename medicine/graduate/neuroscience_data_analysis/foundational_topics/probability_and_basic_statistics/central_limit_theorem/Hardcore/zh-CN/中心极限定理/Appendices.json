{
    "hands_on_practices": [
        {
            "introduction": "中心极限定理为我们理解估计量的分布奠定了基础，而Delta方法则扩展了这一定理，使我们能够近似这些估计量的函数的分布。第一个练习  将引导你完成一个基础应用：推导一个经过变换的最大似然估计量（MLE）的渐近方差。在处理源自神经数据 statistical 模型的衍生参数时，这是一项常见任务。",
            "id": "852388",
            "problem": "考虑一组从率参数为 $\\lambda > 0$ 的指数分布中抽取的 $n$ 个独立同分布 (i.i.d.) 随机变量 $X_1, X_2, \\ldots, X_n$。单个观测值 $X_i$ 的概率密度函数 (PDF) 由下式给出：\n$$f(x_i; \\lambda) = \\lambda e^{-\\lambda x_i} \\quad \\text{for} \\quad x_i \\ge 0$$\n\n令 $\\hat{\\lambda}_n$ 为参数 $\\lambda$ 的最大似然估计量 (MLE)。根据最大似然估计量的渐近理论，可知 $\\hat{\\lambda}_n$ 是渐近正态的。具体而言，\n$$\n\\sqrt{n}(\\hat{\\lambda}_n - \\lambda) \\xrightarrow{d} \\mathcal{N}\\left(0, I(\\lambda)^{-1}\\right)\n$$\n当 $n \\to \\infty$ 时，其中 $I(\\lambda)$ 是该分布单个观测值中所包含的费雪信息。\n\nDelta 方法提供了一种寻找变换后估计量的渐近分布的方法。如果一个随机变量序列 $T_n$ 满足 $\\sqrt{n}(T_n - \\theta) \\xrightarrow{d} \\mathcal{N}(0, \\sigma^2)$，那么对于一个满足 $g'(\\theta) \\neq 0$ 的连续可微函数 $g$，变换后的序列 $g(T_n)$ 满足：\n$$\n\\sqrt{n}(g(T_n) - g(\\theta)) \\xrightarrow{d} \\mathcal{N}\\left(0, [g'(\\theta)]^2 \\sigma^2\\right)\n$$\n项 $[g'(\\theta)]^2 \\sigma^2$ 被定义为估计量 $g(T_n)$ 的渐近方差。\n\n你的任务是推导参数 $\\theta = \\lambda^2$ 的最大似然估计量的渐近方差。$\\theta$ 的估计量是通过代入 $\\lambda$ 的最大似然估计量来构造的，即 $\\hat{\\theta}_n = (\\hat{\\lambda}_n)^2$。",
            "solution": "1. 率参数为 $\\lambda$ 的单个指数分布观测值的费雪信息：\n$$I(\\lambda)=\\mathrm{E}\\Bigl[\\Bigl(\\frac{\\partial}{\\partial\\lambda}\\ln f(X;\\lambda)\\Bigr)^2\\Bigr]=\\frac{1}{\\lambda^2}.$$\n因此，最大似然估计量满足\n$$\\sqrt{n}(\\hat\\lambda_n-\\lambda)\\xrightarrow{d}\\mathcal{N}\\bigl(0,\\lambda^2\\bigr).$$\n2. 定义 $\\theta=\\lambda^2$ 和 $g(\\lambda)=\\lambda^2$。则 $g'(\\lambda)=2\\lambda$。根据 Delta 方法，\n$$\\sqrt{n}\\bigl(g(\\hat\\lambda_n)-g(\\lambda)\\bigr)\\xrightarrow{d}\\mathcal{N}\\bigl(0,(g'(\\lambda))^2\\lambda^2\\bigr).$$\n3. 计算渐近方差：\n$$(g'(\\lambda))^2\\,\\lambda^2=(2\\lambda)^2\\lambda^2=4\\lambda^4.$$",
            "answer": "$$\\boxed{4\\lambda^4}$$"
        },
        {
            "introduction": "神经科学研究常常涉及比较两组群体，例如控制组和实验组。对数优势比（log-odds ratio）是量化比例结果差异的有力统计量。这个练习  要求你应用多元Delta方法来推导对数优势比估计量的方差，这是在实验场景中构建置信区间和进行假设检验的关键一步。",
            "id": "852421",
            "problem": "考虑分别从两个不同的伯努利总体中抽取的两个独立随机样本，其样本量分别为 $n_1$ 和 $n_2$。第一个总体的成功概率为 $p_1$，第二个总体的成功概率为 $p_2$。设 $X_1$ 和 $X_2$ 分别为在第一个和第二个样本中观测到的成功次数。则样本比例由 $\\hat{p}_1 = \\frac{X_1}{n_1}$ 和 $\\hat{p}_2 = \\frac{X_2}{n_2}$ 给出。\n\n在许多统计分析中，特别是在流行病学和临床试验中，对数优势比是一个非常重要的量。真实对数优势比定义为 $\\theta = \\log\\left(\\frac{p_1/(1-p_1)}{p_2/(1-p_2)}\\right)$。基于样本比例，该量的一个估计量是样本对数优势比：\n$$\n\\hat{\\theta} = \\log\\left(\\frac{\\hat{p}_1/(1-\\hat{p}_1)}{\\hat{p}_2/(1-\\hat{p}_2)}\\right)\n$$\n假设样本量 $n_1$ 和 $n_2$ 足够大，中心极限定理可以通过Delta方法进行扩展，以求出 $\\hat{\\theta}$ 的近似分布。\n\n推导对数优势比估计量 $\\hat{\\theta}$ 的渐近方差 $\\text{Var}(\\hat{\\theta})$。",
            "solution": "问题要求解对数优势比估计量 $\\hat{\\theta}$ 的渐近方差。我们可以使用多元Delta方法来求解。\n\n首先，根据中心极限定理，对于大样本量 $n_1$ 和 $n_2$，样本比例 $\\hat{p}_1$ 和 $\\hat{p}_2$ 近似服从正态分布：\n$$\n\\hat{p}_1 \\approx \\mathcal{N}\\left(p_1, \\frac{p_1(1-p_1)}{n_1}\\right)\n$$\n$$\n\\hat{p}_2 \\approx \\mathcal{N}\\left(p_2, \\frac{p_2(1-p_2)}{n_2}\\right)\n$$\n由于两个样本是独立的，随机变量 $\\hat{p}_1$ 和 $\\hat{p}_2$ 也是独立的。因此，样本比例向量 $\\hat{\\mathbf{p}} = (\\hat{p}_1, \\hat{p}_2)^T$ 服从渐近的二元正态分布，其均值向量为 $\\boldsymbol{\\mu}$，协方差矩阵为 $\\boldsymbol{\\Sigma}$：\n$$\n\\boldsymbol{\\mu} = E[\\hat{\\mathbf{p}}] = \\begin{pmatrix} p_1 \\\\ p_2 \\end{pmatrix}\n$$\n$$\n\\boldsymbol{\\Sigma} = \\text{Cov}(\\hat{\\mathbf{p}}) = \\begin{pmatrix} \\text{Var}(\\hat{p}_1) & \\text{Cov}(\\hat{p}_1, \\hat{p}_2) \\\\ \\text{Cov}(\\hat{p}_1, \\hat{p}_2) & \\text{Var}(\\hat{p}_2) \\end{pmatrix} = \\begin{pmatrix} \\frac{p_1(1-p_1)}{n_1} & 0 \\\\ 0 & \\frac{p_2(1-p_2)}{n_2} \\end{pmatrix}\n$$\n估计量 $\\hat{\\theta}$ 是 $\\hat{p}_1$ 和 $\\hat{p}_2$ 的函数。设该函数为 $g(x, y)$：\n$$\ng(x, y) = \\log\\left(\\frac{x/(1-x)}{y/(1-y)}\\right) = \\log(x) - \\log(1-x) - \\log(y) + \\log(1-y)\n$$\n多元Delta方法指出，函数 $g(\\hat{\\mathbf{p}})$ 的渐近方差由下式给出：\n$$\n\\text{Var}(g(\\hat{\\mathbf{p}})) \\approx (\\nabla g(\\boldsymbol{\\mu}))^T \\boldsymbol{\\Sigma} (\\nabla g(\\boldsymbol{\\mu}))\n$$\n其中 $\\nabla g(\\boldsymbol{\\mu})$ 是函数 $g$ 在均值向量 $\\boldsymbol{\\mu} = (p_1, p_2)^T$ 处求得的梯度。\n\n首先，我们计算 $g(x, y)$ 的梯度：\n$$\n\\frac{\\partial g}{\\partial x} = \\frac{1}{x} - \\frac{1}{1-x}(-1) = \\frac{1}{x} + \\frac{1}{1-x} = \\frac{1-x+x}{x(1-x)} = \\frac{1}{x(1-x)}\n$$\n$$\n\\frac{\\partial g}{\\partial y} = -\\frac{1}{y} + \\frac{1}{1-y}(-1) = -\\frac{1}{y} - \\frac{1}{1-y} = -\\frac{1-y+y}{y(1-y)} = -\\frac{1}{y(1-y)}\n$$\n所以梯度向量为 $\\nabla g(x,y) = \\left(\\frac{1}{x(1-x)}, -\\frac{1}{y(1-y)}\\right)^T$。\n\n接下来，我们在均值 $\\boldsymbol{\\mu} = (p_1, p_2)^T$ 处计算梯度：\n$$\n\\nabla g(\\boldsymbol{\\mu}) = \\begin{pmatrix} \\frac{1}{p_1(1-p_1)} \\\\ -\\frac{1}{p_2(1-p_2)} \\end{pmatrix}\n$$\n现在，我们可以将梯度和协方差矩阵代入Delta方法的方差公式中：\n$$\n\\text{Var}(\\hat{\\theta}) \\approx \n\\begin{pmatrix} \\frac{1}{p_1(1-p_1)} & -\\frac{1}{p_2(1-p_2)} \\end{pmatrix}\n\\begin{pmatrix} \\frac{p_1(1-p_1)}{n_1} & 0 \\\\ 0 & \\frac{p_2(1-p_2)}{n_2} \\end{pmatrix}\n\\begin{pmatrix} \\frac{1}{p_1(1-p_1)} \\\\ -\\frac{1}{p_2(1-p_2)} \\end{pmatrix}\n$$\n我们从左到右进行矩阵乘法。首先，将行向量（梯度的转置）与协方差矩阵相乘：\n$$\n\\begin{pmatrix} \\frac{1}{p_1(1-p_1)} \\cdot \\frac{p_1(1-p_1)}{n_1} + (-\\frac{1}{p_2(1-p_2)}) \\cdot 0 & \\frac{1}{p_1(1-p_1)} \\cdot 0 + (-\\frac{1}{p_2(1-p_2)}) \\cdot \\frac{p_2(1-p_2)}{n_2} \\end{pmatrix}\n$$\n$$\n= \\begin{pmatrix} \\frac{1}{n_1} & -\\frac{1}{n_2} \\end{pmatrix}\n$$\n最后，将得到的行向量与列向量（梯度）相乘：\n$$\n\\text{Var}(\\hat{\\theta}) \\approx \\begin{pmatrix} \\frac{1}{n_1} & -\\frac{1}{n_2} \\end{pmatrix} \\begin{pmatrix} \\frac{1}{p_1(1-p_1)} \\\\ -\\frac{1}{p_2(1-p_2)} \\end{pmatrix}\n$$\n$$\n= \\left(\\frac{1}{n_1}\\right) \\left(\\frac{1}{p_1(1-p_1)}\\right) + \\left(-\\frac{1}{n_2}\\right) \\left(-\\frac{1}{p_2(1-p_2)}\\right)\n$$\n$$\n= \\frac{1}{n_1 p_1 (1-p_1)} + \\frac{1}{n_2 p_2 (1-p_2)}\n$$\n这就是对数优势比估计量的渐近方差。",
            "answer": "$$\n\\boxed{\\frac{1}{n_1 p_1 (1-p_1)} + \\frac{1}{n_2 p_2 (1-p_2)}}\n$$"
        },
        {
            "introduction": "要深刻理解像中心极限定理这样强大的定理，不仅需要知道它何时适用，还需要了解它何时会失效。Lindeberg条件是中心极限定理适用于非独立同分布变量序列的关键要求。这个思想实验  构建了一个特殊的反例来检验该定理的理论边界，揭示了即使部分前提看似满足，中心极限定理也可能不成立的情形。",
            "id": "1394702",
            "problem": "在中心极限定理（CLT）的研究中，Lindeberg 条件是一项关键的改进，它将该定理推广到独立但非同分布的随机变量上。中心极限定理为用正态分布近似随机变量之和提供了基础。\n\n考虑一个独立随机变量序列 $X_n$，其中 $n=1, 2, 3, \\dots$。每个随机变量 $X_n$ 服从一个依赖于实参数 $A > 1$ 的三点分布。$X_n$ 的概率质量函数由以下公式给出：\n- $P(X_n = A^n) = \\frac{1}{2}A^{-2n}$\n- $P(X_n = -A^n) = \\frac{1}{2}A^{-2n}$\n- $P(X_n = 0) = 1 - A^{-2n}$\n\n为使中心极限定理以其一般形式适用，必须满足两个条件：\n1.  方差之和 $S_N^2 = \\sum_{n=1}^N \\text{Var}(X_n)$ 必须在 $N \\to \\infty$ 时发散到无穷大。\n2.  Lindeberg 条件必须成立。该条件表述为：对于每一个 $\\epsilon > 0$：\n$$ \\lim_{N\\to\\infty} \\frac{1}{S_N^2} \\sum_{n=1}^N E[X_n^2 \\cdot \\mathbf{1}_{\\{|X_n| > \\epsilon S_N\\}}] = 0 $$\n其中 $\\mathbf{1}_{\\{\\dots\\}}$ 是指示函数。\n\n本题探讨了中心极限定理可能不适用的一个情形。你的任务是确定对于参数 $A > 1$ 的哪些值，方差之和 $S_N^2$ 发散，但 Lindeberg 条件**不**成立。\n\n下列哪个陈述是正确的？\n\nA. 条件仅在 $A = e$ 时满足，其中 $e$ 是自然对数的底数。\n\nB. 条件仅在 $A$ 的值处于区间 $(1, \\sqrt{2}]$ 时满足。\n\nC. 条件对所有 $A > 1$ 的值都满足。\n\nD. 不存在 $A > 1$ 的值使得条件满足。",
            "solution": "我们首先计算每个 $X_{n}$ 的均值和方差。根据对称性，\n$$\nE[X_{n}] \\;=\\; A^{n}\\cdot \\frac{1}{2}A^{-2n} + (-A^{n})\\cdot \\frac{1}{2}A^{-2n} + 0\\cdot \\bigl(1 - A^{-2n}\\bigr) \\;=\\; 0.\n$$\n因此\n$$\n\\operatorname{Var}(X_{n}) \\;=\\; E[X_{n}^{2}] - \\bigl(E[X_{n}]\\bigr)^{2} \\;=\\; E[X_{n}^{2}].\n$$\n由于 $X_{n}^{2}=A^{2n}$ 的总概率为 $A^{-2n}$（来自两个对称的原子点），否则为 $0$，所以\n$$\nE[X_{n}^{2}] \\;=\\; A^{2n}\\cdot A^{-2n} \\;=\\; 1,\n$$\n因此对于所有 $n$，$\\operatorname{Var}(X_{n})=1$。所以\n$$\nS_{N}^{2} \\;=\\; \\sum_{n=1}^{N} \\operatorname{Var}(X_{n}) \\;=\\; N,\n$$\n该和式对任意 $A>1$ 都在 $N\\to\\infty$ 时发散。因此 $S_{N}=N^{1/2}$。\n\n接下来，我们检验 Lindeberg 条件。对于任意固定的 $\\epsilon>0$，\n$$\nE\\!\\left[X_{n}^{2}\\,\\mathbf{1}_{\\{|X_{n}|>\\epsilon S_{N}\\}}\\right]\n\\;=\\;\n\\begin{cases}\nA^{2n}\\cdot A^{-2n} \\;=\\; 1,  \\text{若 } A^{n}>\\epsilon S_{N},\\\\\n0,  \\text{若 } A^{n}\\le \\epsilon S_{N}.\n\\end{cases}\n$$\n于是\n$$\nE\\!\\left[X_{n}^{2}\\,\\mathbf{1}_{\\{|X_{n}|>\\epsilon S_{N}\\}}\\right] \\;=\\; \\mathbf{1}_{\\{A^{n}>\\epsilon S_{N}\\}}.\n$$\n因此，Lindeberg 比率等于\n$$\n\\frac{1}{S_{N}^{2}} \\sum_{n=1}^{N} E\\!\\left[X_{n}^{2}\\,\\mathbf{1}_{\\{|X_{n}|>\\epsilon S_{N}\\}}\\right]\n\\;=\\;\n\\frac{1}{N}\\sum_{n=1}^{N} \\mathbf{1}_{\\{A^{n}>\\epsilon N^{1/2}\\}}.\n$$\n定义 $t_{N}(\\epsilon)=\\log_{A}(\\epsilon N^{1/2})=\\frac{\\ln(\\epsilon N^{1/2})}{\\ln A}$。那么 $\\mathbf{1}_{\\{A^{n}>\\epsilon N^{1/2}\\}}=\\mathbf{1}_{\\{n>t_{N}(\\epsilon)\\}}$，于是\n$$\n\\frac{1}{N}\\sum_{n=1}^{N} \\mathbf{1}_{\\{A^{n}>\\epsilon N^{1/2}\\}}\n\\;=\\;\n\\frac{1}{N}\\bigl(N - \\lfloor t_{N}(\\epsilon)\\rfloor\\bigr)_{+}.\n$$\n因为 $t_{N}(\\epsilon)=\\frac{1}{2\\ln A}\\ln N + O(1)$，我们有当 $N\\to\\infty$ 时 $t_{N}(\\epsilon)=o(N)$，因此\n$$\n\\lim_{N\\to\\infty} \\frac{1}{N}\\sum_{n=1}^{N} \\mathbf{1}_{\\{A^{n}>\\epsilon N^{1/2}\\}}\n\\;=\\;\n1.\n$$\n所以，对于任意 $\\epsilon>0$，\n$$\n\\lim_{N\\to\\infty} \\frac{1}{S_{N}^{2}} \\sum_{n=1}^{N} E\\!\\left[X_{n}^{2}\\,\\mathbf{1}_{\\{|X_{n}|>\\epsilon S_{N}\\}}\\right] \\;=\\; 1 \\;\\neq\\; 0,\n$$\n所以 Lindeberg 条件对所有 $A>1$ 都不成立。\n\n综合两部分：$S_{N}^{2}$ 对所有 $A>1$ 都发散，且 Lindeberg 条件对所有 $A>1$ 都不成立。因此，这两个特征同时出现的陈述对于每个 $A>1$ 都为真，这对应于选项 C。",
            "answer": "$$\\boxed{C}$$"
        }
    ]
}