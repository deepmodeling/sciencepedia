{
    "hands_on_practices": [
        {
            "introduction": "在计算神经科学中，神经元群体的响应模式通常被表示为高维空间中的一个向量。理解大脑如何编码和区分不同的刺激，关键在于比较这些神经活动向量。本练习  旨在通过计算向量范数和向量间夹角，来探讨不同的数学度量如何区分响应强度的变化与潜在神经模式的变化，这在表征相似性分析中是一个核心议题。",
            "id": "4203703",
            "problem": "一个神经元群响应由一个特征向量概括，其中每个分量都是一个标准化的（z-score）活动度量，这使得向量条目是无量纲的。考虑在三个匹配的时期内，记录自同一组神经元的两个试次平均的神经元群活动向量 $x=(3,0,4)$ 和 $y=(2,-2,2)$，它们代表两种刺激条件。仅使用$\\mathbb{R}^n$中向量范数、内积和角度的核心定义，计算以下量：欧几里得范数 $\\|x\\|_2$、曼哈顿范数 $\\|x\\|_1$ 以及 $x$ 和 $y$ 之间的夹角 $\\theta=\\arccos\\left(\\frac{x^\\top y}{\\|x\\|_2\\|y\\|_2}\\right)$。然后，基于这些度量的数学性质，阐明当不同条件下总体响应幅度可能不同时，哪种度量更能捕捉相关神经活动之间的相似性，并解释原因。\n\n报告精确的数值元组 $(\\|x\\|_2,\\|x\\|_1,\\theta)$（不要四舍五入）。角度 $\\theta$ 以弧度表示。$x$ 和 $y$ 的条目是标准化的，因此是无量纲的，所以范数不需要物理单位。",
            "solution": "首先验证问题陈述的正确性和完整性。\n\n**步骤1：提取已知条件**\n-   $\\mathbb{R}^3$ 中的神经元群活动向量：$x = (3, 0, 4)$ 和 $y = (2, -2, 2)$。\n-   向量分量是无量纲的、标准化的（z-score）活动度量。\n-   需要计算的量：\n    1.  $x$ 的欧几里得范数，记为 $\\|x\\|_2$。\n    2.  $x$ 的曼哈顿范数，记为 $\\|x\\|_1$。\n    3.  $x$ 和 $y$ 之间的夹角 $\\theta$，定义为 $\\theta = \\arccos\\left(\\frac{x^\\top y}{\\|x\\|_2\\|y\\|_2}\\right)$。\n-   概念性任务：阐明当响应幅度不同时，哪种度量（范数或角度）更适合比较相关的神经活动，并解释原因。\n-   最终输出应为精确的数值元组 $(\\|x\\|_2, \\|x\\|_1, \\theta)$，其中 $\\theta$ 以弧度为单位。\n\n**步骤2：使用提取的已知条件进行验证**\n-   **科学依据**：该问题使用标准的向量分析技术（范数、内积、角度）来比较神经元群向量。这是计算神经科学中分析神经编码和表征相似性的常见且基础的做法。该设置在科学上是合理的。\n-   **适定性**：向量被明确定义。数学运算是标准的，并能导出一个唯一的、明确定义的解。概念性问题基于所定义度量的数学性质，使其成为一个标准的分析推理任务。\n-   **客观性和完整性**：问题以精确、客观的语言陈述。计算所需的所有信息都已提供。没有矛盾或含糊之处。\n\n**步骤3：结论与行动**\n该问题是有效的，因为它具有科学依据、适定性且完整。我现在将继续进行解答。\n\n**第一部分：计算所需的量**\n\n首先，我们计算向量 $x$ 的欧几里得范数（或 $L_2$-范数）。对于 $\\mathbb{R}^n$ 中的向量 $v = (v_1, v_2, \\dots, v_n)$，欧几里得范数的定义是 $\\|v\\|_2 = \\sqrt{\\sum_{i=1}^n v_i^2}$。\n对于向量 $x = (3, 0, 4)$，其欧几里得范数为：\n$$\n\\|x\\|_2 = \\sqrt{3^2 + 0^2 + 4^2} = \\sqrt{9 + 0 + 16} = \\sqrt{25} = 5\n$$\n\n接下来，我们计算向量 $x$ 的曼哈顿范数（或 $L_1$-范数）。对于向量 $v$，曼哈顿范数的定义是 $\\|v\\|_1 = \\sum_{i=1}^n |v_i|$。\n对于向量 $x = (3, 0, 4)$，其曼哈顿范数为：\n$$\n\\|x\\|_1 = |3| + |0| + |4| = 3 + 0 + 4 = 7\n$$\n\n最后，我们计算向量 $x$ 和 $y$ 之间的夹角 $\\theta$。公式为 $\\theta = \\arccos\\left(\\frac{x^\\top y}{\\|x\\|_2\\|y\\|_2}\\right)$。我们需要计算内积 $x^\\top y$ 和 $y$ 的欧几里得范数 $\\|y\\|_2$。\n$x=(3, 0, 4)$ 和 $y=(2, -2, 2)$ 的内积（或点积）是：\n$$\nx^\\top y = (3)(2) + (0)(-2) + (4)(2) = 6 + 0 + 8 = 14\n$$\n$y=(2, -2, 2)$ 的欧几里得范数是：\n$$\n\\|y\\|_2 = \\sqrt{2^2 + (-2)^2 + 2^2} = \\sqrt{4 + 4 + 4} = \\sqrt{12} = \\sqrt{4 \\times 3} = 2\\sqrt{3}\n$$\n现在我们可以计算 $\\arccos$ 函数的参数，也就是向量之间夹角的余弦（也称为余弦相似度）：\n$$\n\\frac{x^\\top y}{\\|x\\|_2\\|y\\|_2} = \\frac{14}{5 \\times 2\\sqrt{3}} = \\frac{14}{10\\sqrt{3}} = \\frac{7}{5\\sqrt{3}}\n$$\n为了得到规范表示，我们可以将分母有理化：\n$$\n\\frac{7}{5\\sqrt{3}} \\times \\frac{\\sqrt{3}}{\\sqrt{3}} = \\frac{7\\sqrt{3}}{5 \\times 3} = \\frac{7\\sqrt{3}}{15}\n$$\n因此，以弧度表示的夹角 $\\theta$ 是：\n$$\n\\theta = \\arccos\\left(\\frac{7\\sqrt{3}}{15}\\right)\n$$\n\n所需的数值元组是 $(\\|x\\|_2, \\|x\\|_1, \\theta) = (5, 7, \\arccos(\\frac{7\\sqrt{3}}{15}))$。\n\n**第二部分：概念分析**\n\n问题要求讨论哪种度量，范数还是角度，能在不同条件下总体响应幅度可能不同的情况下，更好地捕捉相关神经活动之间的相似性。\n\n向量范数，如欧几里得范数 $\\|x\\|_2$ 或曼哈顿范数 $\\|x\\|_1$，是衡量向量大小或“长度”的度量。在神经活动的背景下，范数用于量化神经元群响应的总体强度或烈度。如果两个响应向量的范数差异很大，这意味着两种条件下神经活动的总体水平是不同的。因此，范数本质上对响应幅度敏感。\n\n然而，两个向量之间的夹角 $\\theta$ 是衡量它们相对方向的度量。它源自余弦相似度 $\\cos(\\theta) = \\frac{x^\\top y}{\\|x\\|_2\\|y\\|_2}$。该表达式的关键特征是分母中通过向量范数的乘积进行归一化。这种归一化使得该度量对向量的大小（长度）不敏感。角度专门捕捉神经元群响应*模式*的相似性。一个小的夹角 $\\theta$（对应于接近 $1$ 的余弦相似度）表明向量指向几乎相同的方向。在神经科学术语中，这意味着即使绝对激活水平不同，神经元间的相对激活模式也非常相似。例如，如果向量 $y$ 是向量 $x$ 的一个缩放版本，比如对于某个标量 $c > 0$ 有 $y=c x$，那么它们之间的夹角将是 $\\theta = 0$，表示响应模式完全匹配，而它们的范数将相差一个因子 $c$。\n\n鉴于“相关的神经活动”（意味着相似的模式）且“总体响应幅度可能不同”的情景，**角度 $\\theta$** 是更优的相似性度量。它将表征几何（活动模式的形状）与神经元群的总体增益或兴奋性分离开来。使用像欧几里得距离 $\\|x-y\\|_2$ 这样的距离度量，会混淆模式上的差异和总体增益因子上的差异，从而难以确定两个刺激是被不同地编码，还是一个仅仅是另一个的更强版本。角度因其对幅度不敏感的特性，直接解决了这个问题，并提供了一个纯粹的模式相似性度量。",
            "answer": "$$\n\\boxed{\\begin{pmatrix} 5  7  \\arccos\\left(\\frac{7\\sqrt{3}}{15}\\right) \\end{pmatrix}}\n$$"
        },
        {
            "introduction": "在神经科学数据分析中，通用线性模型（GLM）是一种被广泛应用的工具，它通过一个设计矩阵来关联实验变量和观测到的神经活动。这个矩阵的代数性质，如它的秩，直接决定了我们是否能唯一地确定模型中各个因素的贡献。本练习  将运用矩阵的秩和零空间等基本概念，来识别和解释模型回归量之间的线性冗余（即多重共线性），这是统计建模中一个常见且重要的问题。",
            "id": "4203709",
            "problem": "在一个用于钙成像分析的通用线性模型（GLM）中，你构建了一个设计矩阵 $X \\in \\mathbb{R}^{3 \\times 3}$，其中包含3个在3个时间点采样的回归量。每一列对应一个编码神经活动假设成分的回归量，每一行对应一个时间样本。给定矩阵\n$$\nX=\\begin{bmatrix}\n1  2  3\\\\\n2  4  6\\\\\n1  1  1\n\\end{bmatrix}.\n$$\n仅使用对有限维向量空间有效的核心线性代数定义和运算，确定以下内容：\n1) $X$ 的列空间，作为 $\\mathbb{R}^{3}$ 的一个子空间，由一组由 $X$ 的列向量组成的基来指定。\n2) $X$ 的秩。\n3) $X$ 的零空间，由一组基来指定。\n然后，在 GLM 可识别性的背景下，解释回归量的冗余性，说明有多少个回归量是线性冗余的，并指出 $X$ 的列向量之间的何种显式线性关系证明了这种冗余性。\n\n将 $X$ 所隐含的冗余回归量的数量作为你的最终答案。无需四舍五入。最终答案必须是单个实数。",
            "solution": "该问题要求分析所提供的设计矩阵 $X$，以确定其性质，并在通用线性模型（GLM）的背景下对其进行解释。该分析必须遵循线性代数的核心原则。\n\n给定的设计矩阵为：\n$$\nX = \\begin{bmatrix}\n1  2  3 \\\\\n2  4  6 \\\\\n1  1  1\n\\end{bmatrix}\n$$\n将 $X$ 的列向量记为 $\\mathbf{v}_1, \\mathbf{v}_2, \\mathbf{v}_3 \\in \\mathbb{R}^3$：\n$$\n\\mathbf{v}_1 = \\begin{pmatrix} 1 \\\\ 2 \\\\ 1 \\end{pmatrix}, \\quad \\mathbf{v}_2 = \\begin{pmatrix} 2 \\\\ 4 \\\\ 1 \\end{pmatrix}, \\quad \\mathbf{v}_3 = \\begin{pmatrix} 3 \\\\ 6 \\\\ 1 \\end{pmatrix}\n$$\n这些向量代表了 GLM 中的三个回归量。\n\n首先，我们将确定这些列向量之间的线性关系。我们寻找不全为零的系数 $c_1, c_2, c_3$，使得 $c_1\\mathbf{v}_1 + c_2\\mathbf{v}_2 + c_3\\mathbf{v}_3 = \\mathbf{0}$。这对应于求解齐次线性方程组 $X\\mathbf{c} = \\mathbf{0}$，其中 $\\mathbf{c} = (c_1, c_2, c_3)^T$。该方程组的增广矩阵为：\n$$\n\\left[\\begin{array}{ccc|c}\n1  2  3  0 \\\\\n2  4  6  0 \\\\\n1  1  1  0\n\\end{array}\\right]\n$$\n我们进行高斯消元。\n将第二行减去第一行的2倍（$R_2 \\to R_2 - 2R_1$）：\n$$\n\\left[\\begin{array}{ccc|c}\n1  2  3  0 \\\\\n0  0  0  0 \\\\\n1  1  1  0\n\\end{array}\\right]\n$$\n将第三行减去第一行（$R_3 \\to R_3 - R_1$）：\n$$\n\\left[\\begin{array}{ccc|c}\n1  2  3  0 \\\\\n0  0  0  0 \\\\\n0  -1  -2  0\n\\end{array}\\right]\n$$\n交换第二行和第三行（$R_2 \\leftrightarrow R_3$），然后将新的第二行乘以-1（$R_2 \\to -R_2$）：\n$$\n\\left[\\begin{array}{ccc|c}\n1  2  3  0 \\\\\n0  1  2  0 \\\\\n0  0  0  0\n\\end{array}\\right]\n$$\n最后，将第一行减去新的第二行的2倍（$R_1 \\to R_1 - 2R_2$）：\n$$\n\\left[\\begin{array}{ccc|c}\n1  0  -1  0 \\\\\n0  1  2  0 \\\\\n0  0  0  0\n\\end{array}\\right]\n$$\n这是简化行阶梯形矩阵。方程组为：\n$c_1 - c_3 = 0 \\implies c_1 = c_3$\n$c_2 + 2c_3 = 0 \\implies c_2 = -2c_3$\n变量 $c_3$ 是一个自由变量。令 $c_3 = k$，其中 $k \\in \\mathbb{R}$ 是任意标量。解向量为 $\\mathbf{c} = (k, -2k, k)^T = k(1, -2, 1)^T$。\n选择一个非零值，例如 $k=1$，得到一个等于零向量的非平凡线性组合：\n$$ 1\\mathbf{v}_1 - 2\\mathbf{v}_2 + 1\\mathbf{v}_3 = \\mathbf{0} $$\n这就是 $X$ 的列向量之间的显式线性关系，证明了它们的线性相关性。\n\n在确定了这一关系之后，我们可以回答具体问题了。\n\n1) $X$ 的列空间，记为 $C(X)$，是由其列向量张成的 $\\mathbb{R}^3$ 的子空间：$C(X) = \\text{span}\\{\\mathbf{v}_1, \\mathbf{v}_2, \\mathbf{v}_3\\}$。由于这些向量是线性相关的，我们可以从张成集中移除其中一个向量而不改变其子空间。从关系式 $\\mathbf{v}_3 = 2\\mathbf{v}_2 - \\mathbf{v}_1$ 中，我们看到 $\\mathbf{v}_3$ 是 $\\mathbf{v}_1$ 和 $\\mathbf{v}_2$ 的线性组合。因此，$C(X) = \\text{span}\\{\\mathbf{v}_1, \\mathbf{v}_2\\}$。为了构成一组基，我们必须检查 $\\mathbf{v}_1$ 和 $\\mathbf{v}_2$ 是否线性无关。它们是线性无关的，因为它们之间不成标量倍数关系（如果 $\\mathbf{v}_2 = c\\mathbf{v}_1$，那么 $2=c \\cdot 1$ 且 $1=c \\cdot 1$，这意味着 $c=2$ 且 $c=1$，这是一个矛盾）。因此，$X$ 的列空间的一组基是 $\\{\\mathbf{v}_1, \\mathbf{v}_2\\}$。\n$C(X)$ 的一组基是 $\\left\\{ \\begin{pmatrix} 1 \\\\ 2 \\\\ 1 \\end{pmatrix}, \\begin{pmatrix} 2 \\\\ 4 \\\\ 1 \\end{pmatrix} \\right\\}$。\n\n2) 矩阵的秩 $\\text{rank}(X)$ 定义为其列空间的维数。因为我们找到了一个由两个向量组成的列空间的基，所以维数是 $2$。\n因此，$\\text{rank}(X) = 2$。\n这也可以通过 $X$ 的行阶梯形矩阵来证实，它有 $2$ 个非零行。\n\n3) $X$ 的零空间，记为 $N(X)$，是所有满足 $X\\mathbf{c} = \\mathbf{0}$ 的向量 $\\mathbf{c}$ 的集合。我们已经求出该方程组的通解为 $\\mathbf{c} = k(1, -2, 1)^T$，其中 $k$ 是任意标量。\n零空间是由向量 $(1, -2, 1)^T$ 张成的子空间。\n$N(X)$ 的一组基是 $\\left\\{ \\begin{pmatrix} 1 \\\\ -2 \\\\ 1 \\end{pmatrix} \\right\\}$。\n零空间的维数（或零度）为 $1$。这与秩-零度定理一致：$\\text{rank}(X) + \\text{nullity}(X) = 2 + 1 = 3$，即 $X$ 的列数。\n\n4) 在 GLM 中，如果回归量（$X$的列向量）不是线性无关的，则认为它们是冗余的。缺乏线性无关性（称为多重共线性）意味着模型是过参数化的。每个回归量对观测数据的贡献无法被唯一确定。线性无关的回归量的数量由矩阵 $X$ 的秩给出，即 $2$。回归量的总数为 $3$。\n线性冗余的回归量的数量是回归量的总数减去线性无关的回归量的数量。\n冗余回归量数量 = (列数) - $\\text{rank}(X) = 3 - 2 = 1$。\n这也等于矩阵的零度。零空间基中的单个向量 $(1, -2, 1)^T$ 提供了线性关系 $1\\mathbf{v}_1 - 2\\mathbf{v}_2 + 1\\mathbf{v}_3 = \\mathbf{0}$ 的系数，这明确地表明了一个回归量的效应如何被其他回归量的组合完全解释（例如，$\\mathbf{v}_3 = 2\\mathbf{v}_2 - \\mathbf{v}_1$）。这种冗余意味着模型 $\\mathbf{y} = X\\mathbf{\\beta}$ 中的回归系数 $\\beta_1, \\beta_2, \\beta_3$ 无法被唯一估计。该集合中有一个冗余回归量。\n\n题目要求的最终答案是 $X$ 所隐含的冗余回归量的数量。这个值是 $1$。",
            "answer": "$$\n\\boxed{1}\n$$"
        },
        {
            "introduction": "大脑的功能可以通过一个由脑区（节点）和它们之间的功能连接（边）组成的复杂网络来建模。图论和线性代数为分析这类网络的结构提供了强有力的数学框架。本练习  将引导你构建一个代表简化脑网络的图拉普拉斯矩阵，并通过计算其特征值和特征向量（特别是Fiedler向量），来执行谱分割，这是一种用于识别脑网络中社团结构的强大技术。",
            "id": "4203701",
            "problem": "在功能性磁共振成像（fMRI）血氧水平依赖（BOLD）连接性分析中，一个常见的预处理步骤是通过一个无权图来表示一小组感兴趣区域（ROI）时间序列之间的关系，其中边表示超过某个阈值的成对统计关联，而拓扑结构则编码了解剖上的邻接约束。考虑一个简化情况，其中4个ROI沿着一条白质通路排列，阈值化处理产生一个在节点{1,2,3,4}上的路径图，边仅存在于连续节点之间，即(1,2)、(2,3)和(3,4)。设 $A$ 为邻接矩阵，$D$ 为对角度矩阵，$L$ 为由 $L = D - A$ 定义的组合图拉普拉斯算子。\n\n从 $A$、$D$ 和 $L$ 的定义以及通过特征多项式 $\\det(L - \\lambda I)$ 定义的特征值出发，完成以下任务：\n\n- 为此路径图构建 $A$、$D$ 和 $L$。\n- 通过显式计算 $\\det(L - \\lambda I)$ 并求解 $\\lambda$，从第一性原理推导 $L$ 的特征值。\n- 识别 Fiedler 向量（与第二小特征值相关联的特征向量），结果可相差一个任意非零缩放因子和符号，并将其条目解释为对ROI进行双向切割的划分方向。根据路径上连续的ROI组来解释其所蕴含的划分，并讨论为什么这与连接性中的低频结构是一致的。\n\n为评分目的，请将代数连通度（记为 $\\lambda_{2}$，即 $L$ 的第二小特征值）报告为单个精确的闭式表达式。无需四舍五入，且不涉及物理单位。",
            "solution": "该问题是有效的，因为它科学地基于标准图论和线性代数，问题设定清晰完整、结构良好，并且其表述是客观的。它展示了谱图理论在简化神经科学背景下的一个标准应用。\n\n该问题描述了一组4个感兴趣区域（ROIs），我们将其标记为节点 {1, 2, 3, 4}。连接性被给定为一个路径图，其中边仅存在于连续节点之间：(1,2)、(2,3)和(3,4)。这是一个无权无向图。\n\n首先，我们构建邻接矩阵 $A$、度矩阵 $D$ 和组合图拉普拉斯算子 $L$。\n\n邻接矩阵 $A$ 的条目 $A_{ij} = 1$ 表示节点 $i$ 和节点 $j$ 之间存在边，否则 $A_{ij} = 0$。对于给定的路径图，$A$ 是一个 $4 \\times 4$ 的矩阵：\n$$\nA = \\begin{pmatrix}\n0  1  0  0 \\\\\n1  0  1  0 \\\\\n0  1  0  1 \\\\\n0  0  1  0\n\\end{pmatrix}\n$$\n\n度矩阵 $D$ 是一个对角矩阵，其中每个对角元素 $D_{ii}$ 是节点 $i$ 的度（与其相连的边的数量）。\n这些度是：\n- $\\text{deg}(1) = 1$\n- $\\text{deg}(2) = 2$\n- $\\text{deg}(3) = 2$\n- $\\text{deg}(4) = 1$\n\n因此，度矩阵 $D$ 是：\n$$\nD = \\begin{pmatrix}\n1  0  0  0 \\\\\n0  2  0  0 \\\\\n0  0  2  0 \\\\\n0  0  0  1\n\\end{pmatrix}\n$$\n\n组合图拉普拉斯算子 $L$ 定义为 $L = D - A$：\n$$\nL = \\begin{pmatrix}\n1  0  0  0 \\\\\n0  2  0  0 \\\\\n0  0  2  0 \\\\\n0  0  0  1\n\\end{pmatrix} - \\begin{pmatrix}\n0  1  0  0 \\\\\n1  0  1  0 \\\\\n0  1  0  1 \\\\\n0  0  1  0\n\\end{pmatrix} = \\begin{pmatrix}\n1  -1  0  0 \\\\\n-1  2  -1  0 \\\\\n0  -1  2  -1 \\\\\n0  0  -1  1\n\\end{pmatrix}\n$$\n\n接下来，我们通过求解特征方程 $\\det(L - \\lambda I) = 0$ 来推导 $L$ 的特征值，其中 $I$ 是 $4 \\times 4$ 的单位矩阵，$\\lambda$ 代表一个特征值。\n$$\nL - \\lambda I = \\begin{pmatrix}\n1-\\lambda  -1  0  0 \\\\\n-1  2-\\lambda  -1  0 \\\\\n0  -1  2-\\lambda  -1 \\\\\n0  0  -1  1-\\lambda\n\\end{pmatrix}\n$$\n\n我们沿第一行进行代数余子式展开来计算行列式：\n$$\n\\det(L - \\lambda I) = (1-\\lambda) \\det \\begin{pmatrix}\n2-\\lambda  -1  0 \\\\\n-1  2-\\lambda  -1 \\\\\n0  -1  1-\\lambda\n\\end{pmatrix} - (-1) \\det \\begin{pmatrix}\n-1  -1  0 \\\\\n0  2-\\lambda  -1 \\\\\n0  -1  1-\\lambda\n\\end{pmatrix}\n$$\n\n让我们计算这两个 $3 \\times 3$ 的行列式：\n第一个行列式是：\n$$\n(2-\\lambda)((2-\\lambda)(1-\\lambda) - 1) - (-1)(-(1-\\lambda)) = (2-\\lambda)(\\lambda^2 - 3\\lambda + 1) - (1-\\lambda) = -\\lambda^3 + 5\\lambda^2 - 6\\lambda + 1\n$$\n第二个行列式是：\n$$\n-1((2-\\lambda)(1-\\lambda)-1) = -(\\lambda^2-3\\lambda+1) = -\\lambda^2+3\\lambda-1\n$$\n\n将这些结果代入 $\\det(L - \\lambda I)$ 的表达式中：\n$$\n\\det(L - \\lambda I) = (1-\\lambda)(-\\lambda^3 + 5\\lambda^2 - 6\\lambda + 1) + (-\\lambda^2 + 3\\lambda - 1)\n$$\n$$\n= (-\\lambda^3 + 5\\lambda^2 - 6\\lambda + 1) + (\\lambda^4 - 5\\lambda^3 + 6\\lambda^2 - \\lambda) - \\lambda^2 + 3\\lambda - 1\n$$\n$$\n= \\lambda^4 - 6\\lambda^3 + 10\\lambda^2 - 4\\lambda\n$$\n\n特征方程为 $\\lambda^4 - 6\\lambda^3 + 10\\lambda^2 - 4\\lambda = 0$。我们提出因子 $\\lambda$：\n$$\n\\lambda(\\lambda^3 - 6\\lambda^2 + 10\\lambda - 4) = 0\n$$\n一个特征值是 $\\lambda_1 = 0$。对于三次因子，我们测试有理根，它们必须是-4的因数。测试 $\\lambda=2$：$2^3 - 6(2^2) + 10(2) - 4 = 8 - 24 + 20 - 4 = 0$。所以，$\\lambda=2$ 是一个根。我们将 $\\lambda^3 - 6\\lambda^2 + 10\\lambda - 4$ 除以 $(\\lambda-2)$，得到二次式 $\\lambda^2 - 4\\lambda + 2$。\n我们使用二次公式求解 $\\lambda^2 - 4\\lambda + 2 = 0$：\n$$\n\\lambda = \\frac{-(-4) \\pm \\sqrt{(-4)^2 - 4(1)(2)}}{2(1)} = \\frac{4 \\pm \\sqrt{16-8}}{2} = \\frac{4 \\pm \\sqrt{8}}{2} = \\frac{4 \\pm 2\\sqrt{2}}{2} = 2 \\pm \\sqrt{2}\n$$\n四个特征值为 $0$、$2$、$2-\\sqrt{2}$ 和 $2+\\sqrt{2}$。我们按从小到大的顺序排列它们：\n$\\lambda_1 = 0$\n$\\lambda_2 = 2 - \\sqrt{2} \\approx 0.586$\n$\\lambda_3 = 2$\n$\\lambda_4 = 2 + \\sqrt{2} \\approx 3.414$\n\n第二小的特征值 $\\lambda_2 = 2 - \\sqrt{2}$ 是图的代数连通度。\n\n现在，我们求 Fiedler 向量，即对应于 $\\lambda_2$ 的特征向量 $v_2$。我们求解系统 $(L - \\lambda_2 I)v_2 = 0$：\n$$\n\\left(L - (2-\\sqrt{2})I\\right) v_2 = \\begin{pmatrix}\n1-(2-\\sqrt{2})  -1  0  0 \\\\\n-1  2-(2-\\sqrt{2})  -1  0 \\\\\n0  -1  2-(2-\\sqrt{2})  -1 \\\\\n0  0  -1  1-(2-\\sqrt{2})\n\\end{pmatrix} \\begin{pmatrix} x_1 \\\\ x_2 \\\\ x_3 \\\\ x_4 \\end{pmatrix} = \\begin{pmatrix} 0 \\\\ 0 \\\\ 0 \\\\ 0 \\end{pmatrix}\n$$\n$$\n\\begin{pmatrix}\n\\sqrt{2}-1  -1  0  0 \\\\\n-1  \\sqrt{2}  -1  0 \\\\\n0  -1  \\sqrt{2}  -1 \\\\\n0  0  -1  \\sqrt{2}-1\n\\end{pmatrix} \\begin{pmatrix} x_1 \\\\ x_2 \\\\ x_3 \\\\ x_4 \\end{pmatrix} = \\begin{pmatrix} 0 \\\\ 0 \\\\ 0 \\\\ 0 \\end{pmatrix}\n$$\n从第一行，$(\\sqrt{2}-1)x_1 - x_2 = 0$，所以 $x_2 = (\\sqrt{2}-1)x_1$。\n从第二行，$-x_1 + \\sqrt{2}x_2 - x_3 = 0$。代入 $x_2$：$-x_1 + \\sqrt{2}(\\sqrt{2}-1)x_1 = x_3$，得出 $x_3 = (-1 + 2 - \\sqrt{2})x_1 = (1-\\sqrt{2})x_1$。\n从第三行，$-x_2 + \\sqrt{2}x_3 - x_4 = 0$。代入 $x_2, x_3$：$-(\\sqrt{2}-1)x_1 + \\sqrt{2}(1-\\sqrt{2})x_1 = x_4$，得出 $x_4 = (-\\sqrt{2}+1+\\sqrt{2}-2)x_1 = -x_1$。\n第四个方程，$-x_3 + (\\sqrt{2}-1)x_4 = 0$，验证了这一点：$-(1-\\sqrt{2})x_1 + (\\sqrt{2}-1)(-x_1) = (\\sqrt{2}-1)x_1 - (\\sqrt{2}-1)x_1 = 0$。\n选择 $x_1=1$，Fiedler 向量为 $v_2 = \\begin{pmatrix} 1  \\sqrt{2}-1  1-\\sqrt{2}  -1 \\end{pmatrix}^T$。\n\nFiedler 向量用于谱二分法。其分量的符号给出了图节点的一个划分。这些分量约为 $v_2 \\approx \\begin{pmatrix} 1  0.414  -0.414  -1 \\end{pmatrix}^T$。条目的符号是 $(+,+,-,-)$。这将节点划分为两个集合：$V_1 = \\{1, 2\\}$（正条目）和 $V_2 = \\{3, 4\\}$（负条目）。\n这个划分对应于切断边 $(2,3)$ 的一次切割，将路径图分成两个连续的ROI组：$\\{1,2\\}$ 和 $\\{3,4\\}$。这是对线性结构最“自然”的二分。\n\n拉普拉斯算子的特征向量类似于图上的傅里叶模态，而特征值对应于频率。最小的特征值 $\\lambda_1=0$ 对应于零频率（常数）模态。与最小非零特征值 $\\lambda_2$ 相关联的 Fiedler 向量，代表了图上最低频率或“最平滑”的非平凡变化模态。“平滑度”由瑞利商 $R(v) = \\frac{v^T L v}{v^T v} = \\frac{\\sum_{(i,j) \\in E} (v_i - v_j)^2}{\\sum_i v_i^2}$ 来量化。在所有与常数向量正交的向量中，Fiedler 向量使该量最小化。这意味着 Fiedler 向量在相邻节点上的值尽可能接近，反映了大尺度结构而非快速的局部波动。Fiedler 向量沿路径的单次符号变化表明它捕捉了图最基本的划分，这与识别连接性结构中的低频（即大尺度）模式是一致的。这种划分为两个连续块 {1,2} 和 {3,4} 正是这样一种模式。\n\n最终需要的答案是代数连通度 $\\lambda_2$。\n$$\n\\lambda_2 = 2 - \\sqrt{2}\n$$",
            "answer": "$$\\boxed{2 - \\sqrt{2}}$$"
        }
    ]
}