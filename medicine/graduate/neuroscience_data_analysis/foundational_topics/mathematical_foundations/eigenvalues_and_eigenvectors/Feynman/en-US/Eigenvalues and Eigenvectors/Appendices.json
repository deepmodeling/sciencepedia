{
    "hands_on_practices": [
        {
            "introduction": "This first exercise grounds the abstract concept of eigenvalues and eigenvectors in the tangible behavior of a dynamical system. By observing a specific mode of a system's evolution, you can directly infer the underlying eigen-solution, reinforcing the idea that eigenvectors represent the invariant directions along which system dynamics unfold. This practice  helps solidify the conceptual link between the mathematical objects and their physical interpretation in modeling.",
            "id": "1674179",
            "problem": "A simplified model for the population dynamics of two competing species, let's call them species A and species B, is described by a system of linear first-order ordinary differential equations. Let $x(t)$ and $y(t)$ be the populations of species A and B at time $t$, respectively. The state of the system is represented by the vector $\\mathbf{p}(t) = \\begin{pmatrix} x(t) \\\\ y(t) \\end{pmatrix}$. The evolution of these populations is governed by the matrix equation $\\frac{d\\mathbf{p}}{dt} = M\\mathbf{p}$, where $M$ is a $2 \\times 2$ matrix of constant coefficients that represents the interaction between the species. An ecologist observes that one specific mode of decay in the populations follows the trajectory $\\mathbf{p}(t) = k e^{-3t} \\begin{pmatrix} 1 \\\\ -1 \\end{pmatrix}$, where $k$ is a non-zero constant determined by the initial populations. This mode represents one of the fundamental behaviors, or eigensolutions, of the system. Based on this observation, identify the eigenvalue $\\lambda$ and its corresponding eigenvector $\\mathbf{v}$ that describe this mode. For the eigenvector, provide the version with the simplest integer components.\n\nWrite your answer as a single row matrix containing the eigenvalue followed by the components of the eigenvector, in the format $\\begin{pmatrix} \\lambda  v_1  v_2 \\end{pmatrix}$.",
            "solution": "We are given a linear system $\\frac{d\\mathbf{p}}{dt}=M\\mathbf{p}$ with an observed mode $\\mathbf{p}(t)=k\\exp(-3t)\\begin{pmatrix}1\\\\-1\\end{pmatrix}$, where $k\\neq 0$. For a linear time-invariant system, a solution of the form $\\mathbf{p}(t)=k\\exp(\\lambda t)\\mathbf{v}$ implies that $\\mathbf{v}$ is an eigenvector of $M$ with eigenvalue $\\lambda$. To verify this, differentiate the observed mode:\n$$\n\\frac{d\\mathbf{p}}{dt}=\\frac{d}{dt}\\left(k\\exp(-3t)\\begin{pmatrix}1\\\\-1\\end{pmatrix}\\right)=-3k\\exp(-3t)\\begin{pmatrix}1\\\\-1\\end{pmatrix}.\n$$\nOn the other hand,\n$$\nM\\mathbf{p}(t)=M\\left(k\\exp(-3t)\\begin{pmatrix}1\\\\-1\\end{pmatrix}\\right)=k\\exp(-3t)M\\begin{pmatrix}1\\\\-1\\end{pmatrix}.\n$$\nSince $\\frac{d\\mathbf{p}}{dt}=M\\mathbf{p}$, we equate the two expressions:\n$$\n-3k\\exp(-3t)\\begin{pmatrix}1\\\\-1\\end{pmatrix}=k\\exp(-3t)M\\begin{pmatrix}1\\\\-1\\end{pmatrix}.\n$$\nCanceling the nonzero scalar factor $k\\exp(-3t)$ yields\n$$\nM\\begin{pmatrix}1\\\\-1\\end{pmatrix}=-3\\begin{pmatrix}1\\\\-1\\end{pmatrix}.\n$$\nTherefore, the eigenvalue is $\\lambda=-3$ and a corresponding eigenvector is $\\mathbf{v}=\\begin{pmatrix}1\\\\-1\\end{pmatrix}$. Any nonzero scalar multiple would also be valid, and the simplest integer components are $(1,-1)$.\n\nThus the requested row matrix is $\\begin{pmatrix}\\lambda  v_{1}  v_{2}\\end{pmatrix}=\\begin{pmatrix}-3  1  -1\\end{pmatrix}$.",
            "answer": "$$\\boxed{\\begin{pmatrix} -3  1  -1 \\end{pmatrix}}$$"
        },
        {
            "introduction": "We now explore a counter-intuitive yet critical phenomenon in neural dynamics: transient amplification in stable networks. While eigenvalues with negative real parts guarantee long-term decay, the geometry of the corresponding eigenvectors can permit large, short-lived increases in activity. This problem  guides you through constructing such a \"non-normal\" system, demonstrating how interactions between non-orthogonal eigenmodes can produce reactive dynamics observed in real cortical circuits.",
            "id": "4158636",
            "problem": "In the analysis of transient amplification in a linearized firing-rate model of a two-population cortical microcircuit, the local dynamics around a stable equilibrium are approximated by a linear system $\\frac{d}{dt}\\,\\delta x(t) = A\\,\\delta x(t)$ with state $\\delta x(t) \\in \\mathbb{R}^{2}$ and system matrix $A \\in \\mathbb{R}^{2 \\times 2}$. Empirically observed local field potential (LFP) transients motivate constructing a stable but highly non-normal $A$ that can exhibit large short-lived gains in $\\|\\delta x(t)\\|_{2}$ following a brief perturbation. You are tasked with constructing such a matrix and analyzing its eigenvectors and condition number.\n\nConsider a design in which $A$ is diagonalizable with real, strictly negative eigenvalues $\\lambda_{1} = -5$ and $\\lambda_{2} = -1$ (units $\\mathrm{s}^{-1}$), and with unit-norm right eigenvectors $v_{1} = \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix}$ and $v_{2} = \\begin{pmatrix} \\cos\\theta \\\\ \\sin\\theta \\end{pmatrix}$, where $\\theta = 0.2$ is specified in radians. Let $V = \\begin{pmatrix} v_{1}  v_{2} \\end{pmatrix}$ denote the eigenvector matrix and $\\Lambda = \\mathrm{diag}(\\lambda_{1}, \\lambda_{2})$ the diagonal matrix of eigenvalues, so that by spectral decomposition $A = V\\,\\Lambda\\,V^{-1}$. Throughout, use the induced $2$-norm $\\|\\,\\cdot\\,\\|_{2}$ on vectors and matrices, defined by $\\|M\\|_{2} = \\sup_{x \\neq 0} \\frac{\\|Mx\\|_{2}}{\\|x\\|_{2}}$ and the corresponding matrix condition number $\\kappa_{2}(M) = \\|M\\|_{2}\\,\\|M^{-1}\\|_{2}$.\n\nTasks:\n1. Using only the core definitions of eigenvalues, eigenvectors, and spectral decomposition, explicitly construct $A$ from $V$ and $\\Lambda$ for the specified $\\lambda_{1}$, $\\lambda_{2}$, and $\\theta$.\n2. Starting from the definition of the induced $2$-norm and singular values, derive an analytic expression for $\\kappa_{2}(V)$ in terms of $\\theta$ and evaluate it for $\\theta = 0.2$.\n3. Using spectral decomposition and the submultiplicativity of the induced norm, derive a rigorous upper bound for the worst-case transient amplification $\\sup_{t \\geq 0} \\left\\| \\exp(A t) \\right\\|_{2}$ of the linearized dynamics in terms of $V$ and $\\Lambda$, and evaluate this bound numerically for the given parameters.\n\nAnswer specification:\n- Provide your final answer as a single real number equal to the evaluated upper bound for $\\sup_{t \\geq 0} \\left\\| \\exp(A t) \\right\\|_{2}$.\n- Round your answer to four significant figures.\n- Express the final answer as a dimensionless quantity.",
            "solution": "The given parameters are:\nEigenvalues: $\\lambda_{1} = -5$ and $\\lambda_{2} = -1$.\nEigenvector angle: $\\theta = 0.2$ radians.\nThe eigenvectors are $v_{1} = \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix}$ and $v_{2} = \\begin{pmatrix} \\cos\\theta \\\\ \\sin\\theta \\end{pmatrix}$.\n\nTask 1: Construction of the matrix $A$.\n\nThe matrix $A$ is given by the spectral decomposition $A = V \\Lambda V^{-1}$, where $V$ is the matrix of eigenvectors and $\\Lambda$ is the diagonal matrix of eigenvalues.\n\nThe eigenvector matrix $V$ is formed by the columns $v_{1}$ and $v_{2}$:\n$$V = \\begin{pmatrix} v_{1}  v_{2} \\end{pmatrix} = \\begin{pmatrix} 1  \\cos\\theta \\\\ 0  \\sin\\theta \\end{pmatrix}$$\nThe eigenvalue matrix $\\Lambda$ is:\n$$\\Lambda = \\begin{pmatrix} \\lambda_{1}  0 \\\\ 0  \\lambda_{2} \\end{pmatrix} = \\begin{pmatrix} -5  0 \\\\ 0  -1 \\end{pmatrix}$$\nTo find $A$, we first need to compute the inverse of $V$. For a $2 \\times 2$ matrix $\\begin{pmatrix} a  b \\\\ c  d \\end{pmatrix}$, the inverse is $\\frac{1}{ad-bc} \\begin{pmatrix} d  -b \\\\ -c  a \\end{pmatrix}$.\nThe determinant of $V$ is $\\det(V) = (1)(\\sin\\theta) - (\\cos\\theta)(0) = \\sin\\theta$.\nThe inverse matrix $V^{-1}$ is:\n$$V^{-1} = \\frac{1}{\\sin\\theta} \\begin{pmatrix} \\sin\\theta  -\\cos\\theta \\\\ 0  1 \\end{pmatrix}$$\nNow we construct $A$ by matrix multiplication:\n$$A = V \\Lambda V^{-1} = \\begin{pmatrix} 1  \\cos\\theta \\\\ 0  \\sin\\theta \\end{pmatrix} \\begin{pmatrix} -5  0 \\\\ 0  -1 \\end{pmatrix} \\frac{1}{\\sin\\theta} \\begin{pmatrix} \\sin\\theta  -\\cos\\theta \\\\ 0  1 \\end{pmatrix}$$\n$$A = \\frac{1}{\\sin\\theta} \\begin{pmatrix} 1  \\cos\\theta \\\\ 0  \\sin\\theta \\end{pmatrix} \\left( \\begin{pmatrix} -5  0 \\\\ 0  -1 \\end{pmatrix} \\begin{pmatrix} \\sin\\theta  -\\cos\\theta \\\\ 0  1 \\end{pmatrix} \\right)$$\n$$A = \\frac{1}{\\sin\\theta} \\begin{pmatrix} 1  \\cos\\theta \\\\ 0  \\sin\\theta \\end{pmatrix} \\begin{pmatrix} -5\\sin\\theta  5\\cos\\theta \\\\ 0  -1 \\end{pmatrix}$$\n$$A = \\frac{1}{\\sin\\theta} \\begin{pmatrix} (1)(-5\\sin\\theta) + (\\cos\\theta)(0)  (1)(5\\cos\\theta) + (\\cos\\theta)(-1) \\\\ (0)(-5\\sin\\theta) + (\\sin\\theta)(0)  (0)(5\\cos\\theta) + (\\sin\\theta)(-1) \\end{pmatrix}$$\n$$A = \\frac{1}{\\sin\\theta} \\begin{pmatrix} -5\\sin\\theta  4\\cos\\theta \\\\ 0  -\\sin\\theta \\end{pmatrix} = \\begin{pmatrix} -5  4\\frac{\\cos\\theta}{\\sin\\theta} \\\\ 0  -1 \\end{pmatrix} = \\begin{pmatrix} -5  4\\cot\\theta \\\\ 0  -1 \\end{pmatrix}$$\nThis completes the construction of $A$.\n\nTask 2: Derivation and evaluation of the condition number $\\kappa_{2}(V)$.\n\nThe condition number $\\kappa_{2}(V)$ is defined as $\\kappa_{2}(V) = \\|V\\|_{2} \\|V^{-1}\\|_{2}$. The induced $2$-norm of a matrix $M$, denoted $\\|M\\|_{2}$, is its largest singular value, $\\sigma_{\\max}(M)$. The singular values of $M$ are the square roots of the eigenvalues of the matrix $M^T M$.\n\nFirst, we find the norm of $V$:\n$$V^T V = \\begin{pmatrix} 1  0 \\\\ \\cos\\theta  \\sin\\theta \\end{pmatrix} \\begin{pmatrix} 1  \\cos\\theta \\\\ 0  \\sin\\theta \\end{pmatrix} = \\begin{pmatrix} 1  \\cos\\theta \\\\ \\cos\\theta  \\cos^2\\theta + \\sin^2\\theta \\end{pmatrix} = \\begin{pmatrix} 1  \\cos\\theta \\\\ \\cos\\theta  1 \\end{pmatrix}$$\nThe eigenvalues $\\mu$ of $V^T V$ are found from the characteristic equation $\\det(V^T V - \\mu I) = 0$:\n$$\\det \\begin{pmatrix} 1-\\mu  \\cos\\theta \\\\ \\cos\\theta  1-\\mu \\end{pmatrix} = (1-\\mu)^2 - \\cos^2\\theta = 0$$\n$$(1-\\mu)^2 = \\cos^2\\theta \\implies 1-\\mu = \\pm\\cos\\theta \\implies \\mu = 1 \\mp \\cos\\theta$$\nThe eigenvalues of $V^T V$ are $\\mu_1 = 1+\\cos\\theta$ and $\\mu_2 = 1-\\cos\\theta$. Since $\\theta = 0.2$ is in $(0, \\pi)$, $\\cos\\theta$ is positive and less than $1$, so both eigenvalues are positive.\nThe singular values of $V$ are $\\sigma_1(V) = \\sqrt{1+\\cos\\theta}$ and $\\sigma_2(V) = \\sqrt{1-\\cos\\theta}$.\nThe largest singular value is $\\sigma_{\\max}(V) = \\sqrt{1+\\cos\\theta}$, so $\\|V\\|_{2} = \\sqrt{1+\\cos\\theta}$.\n\nNext, we find the norm of $V^{-1}$. The singular values of an inverse matrix $M^{-1}$ are the reciprocals of the singular values of $M$. Thus, the singular values of $V^{-1}$ are $1/\\sqrt{1-\\cos\\theta}$ and $1/\\sqrt{1+\\cos\\theta}$.\nThe largest singular value of $V^{-1}$ is $\\sigma_{\\max}(V^{-1}) = 1/\\sqrt{1-\\cos\\theta}$.\nTherefore, $\\|V^{-1}\\|_{2} = \\frac{1}{\\sqrt{1-\\cos\\theta}}$.\n\nNow, we compute the condition number:\n$$\\kappa_{2}(V) = \\|V\\|_{2} \\|V^{-1}\\|_{2} = \\sqrt{1+\\cos\\theta} \\cdot \\frac{1}{\\sqrt{1-\\cos\\theta}} = \\sqrt{\\frac{1+\\cos\\theta}{1-\\cos\\theta}}$$\nUsing the trigonometric half-angle identities $1+\\cos\\theta = 2\\cos^2(\\theta/2)$ and $1-\\cos\\theta = 2\\sin^2(\\theta/2)$:\n$$\\kappa_{2}(V) = \\sqrt{\\frac{2\\cos^2(\\theta/2)}{2\\sin^2(\\theta/2)}} = \\sqrt{\\cot^2(\\theta/2)} = |\\cot(\\theta/2)|$$\nSince $\\theta = 0.2$ radians, $\\theta/2 = 0.1$ radians, which is in the first quadrant. Thus, $\\cot(\\theta/2)$ is positive.\nThe analytic expression for the condition number is $\\kappa_{2}(V) = \\cot(\\theta/2)$.\nFor $\\theta=0.2$, we evaluate $\\kappa_{2}(V) = \\cot(0.1)$.\n\nTask 3: Derivation of an upper bound for transient amplification.\n\nWe want to find an upper bound for $\\sup_{t \\geq 0} \\|\\exp(At)\\|_{2}$.\nUsing the spectral decomposition $A = V \\Lambda V^{-1}$, the matrix exponential is:\n$$\\exp(At) = \\exp((V \\Lambda V^{-1})t) = V \\exp(\\Lambda t) V^{-1}$$\nWe take the induced $2$-norm and apply the submultiplicative property $\\|M_1 M_2 M_3\\|_{2} \\leq \\|M_1\\|_{2} \\|M_2\\|_{2} \\|M_3\\|_{2}$:\n$$\\|\\exp(At)\\|_{2} = \\|V \\exp(\\Lambda t) V^{-1}\\|_{2} \\leq \\|V\\|_{2} \\|\\exp(\\Lambda t)\\|_{2} \\|V^{-1}\\|_{2}$$\nThe product $\\|V\\|_{2} \\|V^{-1}\\|_{2}$ is the condition number $\\kappa_{2}(V)$.\n$$\\|\\exp(At)\\|_{2} \\leq \\kappa_{2}(V) \\|\\exp(\\Lambda t)\\|_{2}$$\nThe matrix $\\exp(\\Lambda t)$ is a diagonal matrix:\n$$\\exp(\\Lambda t) = \\begin{pmatrix} \\exp(\\lambda_1 t)  0 \\\\ 0  \\exp(\\lambda_2 t) \\end{pmatrix} = \\begin{pmatrix} \\exp(-5t)  0 \\\\ 0  \\exp(-t) \\end{pmatrix}$$\nThe induced $2$-norm of a diagonal matrix is the maximum of the absolute values of its diagonal entries. For $t \\ge 0$, the exponential terms are positive.\n$$\\|\\exp(\\Lambda t)\\|_{2} = \\max(\\exp(-5t), \\exp(-t))$$\nSince $\\lambda_1  \\lambda_2  0$, for $t  0$ we have $\\lambda_1 t  \\lambda_2 t$, which implies $\\exp(\\lambda_1 t)  \\exp(\\lambda_2 t)$. Specifically, for $t \\ge 0$, $-t \\geq -5t$, so $\\exp(-t) \\geq \\exp(-5t)$.\nTherefore, $\\|\\exp(\\Lambda t)\\|_{2} = \\exp(-t)$ for $t \\ge 0$.\nSubstituting this into our inequality gives:\n$$\\|\\exp(At)\\|_{2} \\leq \\kappa_{2}(V) \\exp(-t)$$\nTo find an upper bound for the supremum over all $t \\ge 0$, we can take the supremum of the right-hand side:\n$$\\sup_{t \\geq 0} \\|\\exp(At)\\|_{2} \\leq \\sup_{t \\geq 0} \\left( \\kappa_{2}(V) \\exp(-t) \\right)$$\nThe function $\\exp(-t)$ is a monotonically decreasing function for $t \\ge 0$, with its maximum at $t=0$, where $\\exp(0)=1$.\n$$\\sup_{t \\geq 0} \\|\\exp(At)\\|_{2} \\leq \\kappa_{2}(V) \\cdot \\sup_{t \\geq 0}(\\exp(-t)) = \\kappa_{2}(V) \\cdot 1 = \\kappa_{2}(V)$$\nThus, a rigorous upper bound for the worst-case transient amplification is given by the condition number $\\kappa_2(V)$.\n\nFinally, we evaluate this bound numerically for the given parameters. The upper bound is $\\kappa_2(V) = \\cot(\\theta/2) = \\cot(0.1)$.\nUsing a calculator for $\\cot(0.1)$ in radians:\n$$\\cot(0.1) \\approx 9.96664442$$\nThe problem asks to round the answer to four significant figures. The first four significant figures are $9, 9, 6, 6$. The fifth digit is $6$, so we round up the fourth digit.\nThe numerical value is $9.967$.\nThis upper bound is dimensionless as it is a ratio of norms.",
            "answer": "$$\\boxed{9.967}$$"
        },
        {
            "introduction": "Finally, we consider the special case of non-diagonalizable, or \"defective,\" systems, which can be used to model networks tuned to a critical state. When a system lacks a full basis of eigenvectors, its dynamics exhibit unique signatures that are not purely exponential, often involving polynomial terms in time like $t\\exp(\\lambda t)$. This exercise  uses a canonical Jordan block to reveal how these systems respond to inputs, producing a characteristic trajectory that is fundamental to models of neural integration and working memory.",
            "id": "4158698",
            "problem": "Consider a simplified continuous-time linear recurrent population model used in neuroscience to describe the evolution of mean activity rates in a small microcircuit. Let the state vector be $x(t) \\in \\mathbb{R}^{2}$, representing two interacting neuronal populations whose activities are normalized to be dimensionless. The dynamics are given by the linear time-invariant (LTI) system\n$$\n\\frac{d}{dt} x(t) = A x(t) + B u(t), \\quad x(0^{-}) = 0,\n$$\nwhere $A \\in \\mathbb{R}^{2 \\times 2}$ is the synaptic connectivity matrix, $B \\in \\mathbb{R}^{2 \\times 1}$ specifies how external input drives the circuit, and $u(t)$ is a scalar input. To isolate the effect of a non-diagonalizable mode, construct $A$ to have a single $2 \\times 2$ Jordan block with a repeated eigenvalue $\\lambda \\in \\mathbb{R}$ (assume $\\lambda  0$ for stability), specifically\n$$\nA = \\begin{pmatrix} \\lambda  1 \\\\ 0  \\lambda \\end{pmatrix}.\n$$\nLet the circuit receive a unit impulse input at time $t=0$ applied to the second population only, i.e.,\n$$\nu(t) = \\delta(t), \\quad B = \\begin{pmatrix} 0 \\\\ 1 \\end{pmatrix}.\n$$\nAssume the readout of interest is the activity of the first population, $y(t) = C x(t)$ with\n$$\nC = \\begin{pmatrix} 1  0 \\end{pmatrix}.\n$$\nStarting from the definitions of the matrix exponential via its power series and the impulse response of linear systems via convolution with the Dirac delta, derive a closed-form analytic expression for the impulse response $y(t)$ for $t \\ge 0$ as a function of $\\lambda$ and $t$. Express your final answer as a single symbolic expression in terms of $\\lambda$ and $t$. Do not include units in your final expression. No numerical approximation or rounding is required.",
            "solution": "The problem describes a linear time-invariant (LTI) system with dynamics given by the state-space equation:\n$$\n\\frac{d}{dt} x(t) = A x(t) + B u(t)\n$$\nwith the initial condition $x(0^{-}) = 0$. The solution to this differential equation for $t \\ge 0$ is given by the convolution integral:\n$$\nx(t) = \\int_{0}^{t} e^{A(t-\\tau)} B u(\\tau) d\\tau\n$$\nIn this case, the input is a unit impulse, $u(t) = \\delta(t)$. Substituting this into the integral and using the sifting property of the Dirac delta function, which states that $\\int f(\\tau) \\delta(\\tau) d\\tau = f(0)$ for a function $f$ continuous at $\\tau=0$, we get:\n$$\nx(t) = \\int_{0}^{t} e^{A(t-\\tau)} B \\delta(\\tau) d\\tau = e^{A(t-0)} B = e^{At} B\n$$\nThis expression is valid for $t \\ge 0$. The output of the system is then given by:\n$$\ny(t) = C x(t) = C e^{At} B\n$$\nThis quantity, $h(t) = C e^{At} B$, is the impulse response of the system. The primary task is to compute the matrix exponential $e^{At}$ for the given matrix $A$. The matrix is:\n$$\nA = \\begin{pmatrix} \\lambda  1 \\\\ 0  \\lambda \\end{pmatrix}\n$$\nWe can decompose $A$ into the sum of a diagonal matrix and a nilpotent matrix:\n$$\nA = \\begin{pmatrix} \\lambda  0 \\\\ 0  \\lambda \\end{pmatrix} + \\begin{pmatrix} 0  1 \\\\ 0  0 \\end{pmatrix} = \\lambda I + N\n$$\nwhere $I$ is the $2 \\times 2$ identity matrix and $N = \\begin{pmatrix} 0  1 \\\\ 0  0 \\end{pmatrix}$. Since the identity matrix $I$ commutes with any matrix, we have $(\\lambda I)N = \\lambda N$ and $N(\\lambda I) = \\lambda N$, so $\\lambda I$ and $N$ commute. For commuting matrices, the exponential of their sum is the product of their exponentials:\n$$\ne^{At} = e^{(\\lambda I + N)t} = e^{\\lambda It} e^{Nt}\n$$\nWe evaluate each exponential term separately using the power series definition, $e^M = \\sum_{k=0}^{\\infty} \\frac{M^k}{k!}$.\nFirst, for $e^{\\lambda I t}$:\n$$\ne^{\\lambda I t} = \\sum_{k=0}^{\\infty} \\frac{(\\lambda I t)^k}{k!} = \\sum_{k=0}^{\\infty} \\frac{\\lambda^k t^k I^k}{k!} = I \\sum_{k=0}^{\\infty} \\frac{(\\lambda t)^k}{k!} = I e^{\\lambda t} = \\begin{pmatrix} e^{\\lambda t}  0 \\\\ 0  e^{\\lambda t} \\end{pmatrix}\n$$\nNext, for $e^{Nt}$, we compute the powers of $N$:\n$$\nN = \\begin{pmatrix} 0  1 \\\\ 0  0 \\end{pmatrix}\n$$\n$$\nN^2 = \\begin{pmatrix} 0  1 \\\\ 0  0 \\end{pmatrix} \\begin{pmatrix} 0  1 \\\\ 0  0 \\end{pmatrix} = \\begin{pmatrix} 0  0 \\\\ 0  0 \\end{pmatrix}\n$$\nSince $N^2$ is the zero matrix, all higher powers $N^k$ for $k \\ge 2$ are also the zero matrix. This property (nilpotency) causes the infinite series for $e^{Nt}$ to truncate after the linear term:\n$$\ne^{Nt} = \\sum_{k=0}^{\\infty} \\frac{(Nt)^k}{k!} = \\frac{(Nt)^0}{0!} + \\frac{(Nt)^1}{1!} + \\frac{(Nt)^2}{2!} + \\dots = I + Nt + 0 + \\dots = \\begin{pmatrix} 1  0 \\\\ 0  1 \\end{pmatrix} + t \\begin{pmatrix} 0  1 \\\\ 0  0 \\end{pmatrix} = \\begin{pmatrix} 1  t \\\\ 0  1 \\end{pmatrix}\n$$\nCombining these two results, we find the matrix exponential $e^{At}$:\n$$\ne^{At} = e^{\\lambda It} e^{Nt} = (e^{\\lambda t} I) (I + Nt) = e^{\\lambda t} (I + Nt) = e^{\\lambda t} \\begin{pmatrix} 1  t \\\\ 0  1 \\end{pmatrix} = \\begin{pmatrix} e^{\\lambda t}  t e^{\\lambda t} \\\\ 0  e^{\\lambda t} \\end{pmatrix}\n$$\nNow we can compute the impulse response $y(t) = C e^{At} B$ by substituting the matrices $C$, $e^{At}$, and $B$:\n$$\ny(t) = \\begin{pmatrix} 1  0 \\end{pmatrix} \\begin{pmatrix} e^{\\lambda t}  t e^{\\lambda t} \\\\ 0  e^{\\lambda t} \\end{pmatrix} \\begin{pmatrix} 0 \\\\ 1 \\end{pmatrix}\n$$\nPerforming the matrix multiplication from left to right:\n$$\ny(t) = \\begin{pmatrix} (1)(e^{\\lambda t}) + (0)(0)  (1)(t e^{\\lambda t}) + (0)(e^{\\lambda t}) \\end{pmatrix} \\begin{pmatrix} 0 \\\\ 1 \\end{pmatrix}\n$$\n$$\ny(t) = \\begin{pmatrix} e^{\\lambda t}  t e^{\\lambda t} \\end{pmatrix} \\begin{pmatrix} 0 \\\\ 1 \\end{pmatrix}\n$$\nFinally, computing the dot product:\n$$\ny(t) = (e^{\\lambda t})(0) + (t e^{\\lambda t})(1) = t e^{\\lambda t}\n$$\nThis is the closed-form analytic expression for the impulse response for $t \\ge 0$.",
            "answer": "$$\n\\boxed{t \\exp(\\lambda t)}\n$$"
        }
    ]
}