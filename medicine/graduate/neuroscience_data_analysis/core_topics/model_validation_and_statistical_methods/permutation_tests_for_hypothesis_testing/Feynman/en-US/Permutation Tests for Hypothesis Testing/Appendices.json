{
    "hands_on_practices": [
        {
            "introduction": "To truly grasp the power of permutation testing, it is essential to build one from its first principles. This first practice guides you through the implementation of a Monte Carlo permutation test for a paired-sample scenario, a common design in neuroscience experiments. By working through this problem , you will translate the theoretical concept of exchangeability under the null hypothesis into a concrete algorithm, generating a null distribution through random sign-flipping and calculating an adjusted $p$-value.",
            "id": "4185203",
            "problem": "You are given paired subject-level differences in normalized electroencephalography (EEG) alpha power between two experimental conditions. Each difference is unitless because alpha power has been pre-normalized per subject to z-scores prior to differencing. Under the null hypothesis that there is no condition effect, the sign of each subject-level difference is exchangeable, meaning that flipping each difference by multiplication with either $+1$ or $-1$ is equally likely. This implies that, conditional on the observed magnitudes of the paired differences, the null distribution of the mean difference can be generated by random sign-flips across subjects. Starting from this exchangeability principle and the definition of a two-sided hypothesis test as the probability that the absolute test statistic drawn under the null is at least as extreme as the observed absolute test statistic, write a program to compute the two-sided permutation $p$-value for the observed mean difference by Monte Carlo simulation using $m$ random sign-flip permutations, with a finite-sample adjustment that avoids zero estimates. For each test case, compute the observed mean difference $d_{\\text{obs}}$ over $n$ subjects, generate $m$ random sign-flip permutations, form the permutation mean differences $d^{(j)}$ for $j=1,\\dots,m$, count the number $b$ of permutations for which $\\lvert d^{(j)} \\rvert \\ge \\lvert d_{\\text{obs}} \\rvert$, and output the adjusted two-sided Monte Carlo permutation $p$-value based on $b$ and $m$. Your implementation must use a fixed pseudorandom number generator seed for each test case to ensure reproducible results.\n\nYour program should implement the above for the following test suite. In each case, treat the listed numbers as the vector of paired differences $\\Delta = [\\Delta_1,\\dots,\\Delta_n]$, use two-sided testing, and the specified number of permutations and seed:\n\nCase $1$ (happy path, moderate $n$, many permutations): $\\Delta = [0.38,0.52,0.41,0.65,0.29,0.76,0.44,0.58,0.31,0.49,0.55,0.60,0.33,0.47,0.69,0.36]$, $m=10000$, seed $=7$.\n\nCase $2$ (near-null differences, moderate permutations): $\\Delta = [-0.12,0.08,-0.05,0.03,-0.02,0.01,-0.09,0.07,-0.04,0.05]$, $m=5000$, seed $=17$.\n\nCase $3$ (small $n$, large observed effect): $\\Delta = [0.90,0.80,1.10,0.70]$, $m=2000$, seed $=3$.\n\nCase $4$ (boundary, zero permutations): $\\Delta = [0.20,-0.10,0.30]$, $m=0$, seed $=11$.\n\nCase $5$ (boundary, one permutation): $\\Delta = [0.30,-0.20,0.10,-0.10,0.05,-0.05]$, $m=1$, seed $=123$.\n\nFor each case, output the two-sided permutation $p$-value as a floating-point number rounded to $6$ decimal places. Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, for example, $\"[p_1,p_2,p_3,p_4,p_5]\"$. The final outputs are unitless real numbers in $[0,1]$ and must be presented with $6$ digits after the decimal point.",
            "solution": "The problem statement is scientifically sound, well-posed, and objective. It outlines a standard and widely accepted statistical procedure—the Monte Carlo permutation test for paired samples—which is frequently applied in neuroscience for analyzing data from sources like electroencephalography (EEG). All necessary parameters, including data vectors, number of permutations, and random seeds, are provided for each test case, ensuring a unique and reproducible solution. The problem is formalizable and relevant to its stated field. Therefore, the problem is valid and I will proceed with a full solution.\n\nThe core task is to compute a two-sided permutation $p$-value for the mean of paired differences, based on the principle of exchangeability under the null hypothesis. The solution involves a Monte Carlo simulation to approximate the null distribution of the mean difference.\n\n**Underlying Principles and Algorithmic Formulation**\n\n1.  **Null Hypothesis and Exchangeability**: The null hypothesis, $H_0$, posits that there is no systematic effect of the experimental condition on the measured EEG alpha power. A direct consequence of $H_0$ is the principle of exchangeability: for each subject's paired difference, $\\Delta_i$, its sign is arbitrary. That is, the observed difference $\\Delta_i$ and its sign-flipped counterpart $-\\Delta_i$ are equally likely. This implies that under $H_0$, any combination of sign-flips across the $n$ subjects is equally probable. The total number of such combinations is $2^n$.\n\n2.  **Test Statistic**: The test statistic used to quantify the overall effect is the mean of the paired differences. The observed value of this statistic is calculated from the provided data vector $\\Delta = [\\Delta_1, \\dots, \\Delta_n]$ as:\n    $$d_{\\text{obs}} = \\frac{1}{n} \\sum_{i=1}^{n} \\Delta_i$$\n\n3.  **Null Distribution by Permutation**: To construct the null distribution of the test statistic, we simulate the consequences of $H_0$. A single permutation, indexed by $j$, involves creating a new data set $\\Delta^{(j)}$ by randomly flipping the signs of the original differences. This is achieved by generating a random sign vector $\\mathbf{s}^{(j)} = [s_1^{(j)}, s_2^{(j)}, \\dots, s_n^{(j)}]$, where each $s_i^{(j)}$ is drawn independently from a discrete uniform distribution over $\\{-1, +1\\}$. The permuted data vector is then:\n    $$\\Delta^{(j)} = [\\Delta_1 \\cdot s_1^{(j)}, \\Delta_2 \\cdot s_2^{(j)}, \\dots, \\Delta_n \\cdot s_n^{(j)}]$$\n    From this, we compute the corresponding permuted mean difference:\n    $$d^{(j)} = \\frac{1}{n} \\sum_{i=1}^{n} \\Delta_i^{(j)}$$\n\n4.  **Monte Carlo Approximation and $p$-value Calculation**: Generating all $2^n$ possible sign combinations is computationally prohibitive for even moderate $n$. Instead, we use a Monte Carlo approach, generating a large number, $m$, of random permutations. This yields a sample of $m$ test statistics $\\{d^{(1)}, d^{(2)}, \\dots, d^{(m)}\\}$ that approximates the true null distribution.\n\n    The problem specifies a two-sided test. The $p$-value is the probability of observing a test statistic under the null hypothesis that is at least as extreme as the observed one. For a two-sided test, \"extremity\" is measured by the absolute value. The $p$-value is thus $P(\\lvert d_{\\text{null}} \\rvert \\ge \\lvert d_{\\text{obs}} \\rvert)$.\n\n    We estimate this probability from our Monte Carlo sample by counting the number of permutations, $b$, for which the permuted mean difference is at least as extreme as the observed one:\n    $$b = \\sum_{j=1}^{m} \\mathbb{I}(\\lvert d^{(j)} \\rvert \\ge \\lvert d_{\\text{obs}} \\rvert)$$\n    where $\\mathbb{I}(\\cdot)$ is the indicator function, which is $1$ if its argument is true and $0$ otherwise.\n\n5.  **Finite-Sample Adjustment**: A naive $p$-value estimate would be $b/m$. However, this can yield a $p$-value of $0$, which is an overstatement of statistical significance, as the true $p$-value for an exact test can never be less than $1/2^n$. To provide a more conservative and stable estimate that avoids $p=0$, we use a standard adjustment. This involves including the observed statistic itself as part of the permutation distribution. The adjusted Monte Carlo $p$-value is:\n    $$p = \\frac{b+1}{m+1}$$\n    This formula effectively counts the observed outcome in both the numerator (as it is always as extreme as itself) and the denominator, ensuring that $p \\in [1/(m+1), 1]$. This is particularly important for boundary cases, such as when $m=0$. If $m=0$, then $b=0$, and the formula correctly yields $p = (0+1)/(0+1) = 1$, reflecting a complete lack of evidence against $H_0$ from the permutation procedure.\n\n**Algorithm Implementation**\n\nFor each test case defined by a data vector $\\Delta$, number of permutations $m$, and a random seed:\n\n1.  Initialize a pseudorandom number generator with the specified seed to ensure reproducibility.\n2.  Compute the observed mean difference, $d_{\\text{obs}}$, from the input vector $\\Delta$. Let $n$ be the number of subjects (the length of $\\Delta$).\n3.  If $m=0$, the $p$-value is $1.0$ by the adjusted formula.\n4.  If $m  0$:\n    a. Generate an $m \\times n$ matrix of random signs, where each entry is either $-1$ or $+1$ with equal probability.\n    b. Create $m$ permuted data sets by performing an element-wise product between each row of the sign matrix and the original data vector $\\Delta$. This can be efficiently achieved using array broadcasting.\n    c. Compute the mean for each of the $m$ permuted data sets to obtain the vector of permuted means, $[d^{(1)}, \\dots, d^{(m)}]$.\n    d. Take the absolute value of both the permuted means and the observed mean.\n    e. Count the number of permuted means, $b$, whose absolute value is greater than or equal to the absolute value of the observed mean.\n5.  Calculate the final adjusted $p$-value as $p = (b+1)/(m+1)$.\n6.  The result is formatted to $6$ decimal places.\n\nThis procedure will be applied to each of the five test cases.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Computes two-sided permutation p-values for a suite of test cases.\n\n    This function implements a Monte Carlo permutation test for the mean of\n    paired differences. It follows the principles of exchangeability under the\n    null hypothesis and uses a finite-sample adjustment for the p-value.\n    \"\"\"\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        {'delta': [0.38, 0.52, 0.41, 0.65, 0.29, 0.76, 0.44, 0.58, 0.31, 0.49, 0.55, 0.60, 0.33, 0.47, 0.69, 0.36], 'm': 10000, 'seed': 7},\n        {'delta': [-0.12, 0.08, -0.05, 0.03, -0.02, 0.01, -0.09, 0.07, -0.04, 0.05], 'm': 5000, 'seed': 17},\n        {'delta': [0.90, 0.80, 1.10, 0.70], 'm': 2000, 'seed': 3},\n        {'delta': [0.20, -0.10, 0.30], 'm': 0, 'seed': 11},\n        {'delta': [0.30, -0.20, 0.10, -0.10, 0.05, -0.05], 'm': 1, 'seed': 123},\n    ]\n\n    results = []\n\n    for case in test_cases:\n        delta_data = np.array(case['delta'])\n        m = case['m']\n        seed = case['seed']\n        n = len(delta_data)\n\n        # Step 1: Compute the observed mean difference\n        d_obs = np.mean(delta_data)\n        abs_d_obs = np.abs(d_obs)\n        \n        # Handle the boundary case where m=0 permutations are requested\n        if m == 0:\n            # According to the (b+1)/(m+1) formula, with m=0, b must be 0.\n            # p-value = (0+1)/(0+1) = 1.0\n            p_value = 1.0\n            results.append(p_value)\n            continue\n\n        # Step 2: Generate m random sign-flip permutations\n        # Initialize a random number generator with the specified seed for reproducibility\n        rng = np.random.default_rng(seed=seed)\n        \n        # Generate an (m, n) matrix of random signs {-1, 1}\n        # This is more direct than generating {0, 1} and mapping\n        random_signs = rng.choice([-1, 1], size=(m, n))\n        \n        # Create permuted datasets by element-wise multiplication.\n        # Broadcasting delta_data (1, n) against random_signs (m, n).\n        permuted_deltas = random_signs * delta_data\n\n        # Step 3: Form the permutation mean differences\n        permuted_means = np.mean(permuted_deltas, axis=1)\n\n        # Step 4: Count the number of permutations where |d_perm| = |d_obs|\n        b = np.sum(np.abs(permuted_means) = abs_d_obs)\n        \n        # Step 5: Compute the adjusted two-sided Monte Carlo permutation p-value\n        p_value = (b + 1) / (m + 1)\n        \n        results.append(p_value)\n\n    # Final print statement in the exact required format.\n    # Each p-value is formatted to 6 decimal places.\n    formatted_results = [f\"{p:.6f}\" for p in results]\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "A permutation test's validity hinges on the exchangeability of data under the null hypothesis, a property that holds true regardless of the test statistic chosen. However, the *power* of the test—its ability to detect a true effect—is highly dependent on this choice. This exercise  challenges you to think critically about the properties of different test statistics, especially in the context of fMRI data, which is often contaminated by heavy-tailed noise and outliers. You will compare the robustness and sensitivity of mean-based statistics versus rank-based statistics, a crucial consideration for building powerful and reliable analysis pipelines.",
            "id": "4185226",
            "problem": "A research team analyzes a single voxel in functional Magnetic Resonance Imaging (fMRI) data from $n$ subjects, each scanned under $2$ conditions (task and control). For subject $i$, let the within-subject condition effect be the difference in voxel intensity $d_i$, assumed independent across subjects. The team wishes to test the null hypothesis $H_0: \\text{no condition effect}$, formalized as the joint distribution of $\\{d_i\\}_{i=1}^n$ being symmetric about $0$ under $H_0$. Because motion and physiological artifacts occasionally produce large excursions in $\\{d_i\\}$, the team anticipates heavy-tailed noise with rare outliers. They elect a sign-flip permutation test appropriate for the paired design: under $H_0$, flipping any subset of signs in $\\{d_i\\}_{i=1}^n$ produces an equally likely realization.\n\nThey consider three candidate test statistics for the permutation test: the difference in means, the Student $t$-statistic, and a rank-based signed-rank statistic. They seek to compare these statistics in terms of (i) exactness of type-$I$ error control under the chosen permutation scheme and (ii) sensitivity to heavy tails and outliers, including scenarios where the marginal distribution of $d_i$ has infinite variance.\n\nWhich statement best captures the correct comparison?\n\nA. Under the sign-flip permutation framework, all three statistics yield exact type-$I$ error control under $H_0$ because exchangeability of signs holds, but the signed-rank statistic has bounded influence and typically higher asymptotic relative efficiency under many symmetric heavy-tailed distributions; in contrast, the difference in means and the Student $t$-statistic have unbounded influence and can suffer substantial power loss when outliers inflate dispersion.\n\nB. Permutation testing with the Student $t$-statistic is invalid unless the $d_i$ are Gaussian; outliers break exchangeability and invalidate type-$I$ error control, so the difference in means is superior under heavy tails.\n\nC. The Student $t$-statistic is uniformly most powerful against symmetric alternatives by the Lehmann–Scheffé theorem, so rank-based statistics cannot outperform it under any symmetric heavy-tailed distribution.\n\nD. Rank-based signed-rank statistics are incompatible with permutation tests because ranking destroys exchangeability; consequently, type-$I$ error control is not exact, although robustness to outliers is improved.",
            "solution": "The user wants a critical validation of the problem statement, followed by a detailed solution and evaluation of the provided options.\n\n### Problem Validation\n\n**Step 1: Extract Givens**\n- **Subjects and Design:** $n$ subjects, each in $2$ conditions (task and control), forming a paired design.\n- **Data:** For subject $i$, $d_i$ is the within-subject difference in voxel intensity. The set of observations is $\\{d_i\\}_{i=1}^n$.\n- **Assumption:** The $d_i$ are independent across subjects.\n- **Null Hypothesis ($H_0$):** There is no condition effect. This is formalized as the joint distribution of $\\{d_i\\}_{i=1}^n$ being symmetric about $0$.\n- **Noise Model:** The noise is anticipated to be heavy-tailed with rare outliers, potentially leading to a marginal distribution for $d_i$ with infinite variance.\n- **Proposed Test:** A sign-flip permutation test.\n- **Permutation Principle:** Under $H_0$, any realization obtained by flipping an arbitrary subset of signs in $\\{d_i\\}$ is equally likely.\n- **Candidate Test Statistics:**\n    1. The difference in means.\n    2. The Student $t$-statistic.\n    3. A rank-based signed-rank statistic.\n- **Comparison Criteria:**\n    (i) Exactness of type-$I$ error control under the permutation scheme.\n    (ii) Sensitivity (robustness and power) to heavy tails and outliers.\n\n**Step 2: Validate Using Extracted Givens**\n- **Scientific Groundedness:** The problem describes a canonical scenario in statistical data analysis, particularly relevant to fields like neuroscience where paired designs are common and data quality can be heterogeneous. The null hypothesis of symmetry about $0$ is the standard requirement for the validity of a sign-flip test on differences $d_i$. The concern for heavy-tailed noise and outliers is highly realistic in fMRI data analysis. The candidate statistics and comparison criteria are all standard in statistical theory. The problem is scientifically and mathematically sound.\n- **Well-Posedness:** The question asks for a comparison of three well-defined statistical procedures based on two clear and meaningful criteria (type-$I$ error control and robustness/power). A unique, stable, and meaningful solution based on established statistical principles exists.\n- **Objectivity:** The problem is stated in precise, objective, and formal language, free of ambiguity or subjective claims.\n- **Conclusion:** The problem statement is valid. It is self-contained, consistent, scientifically grounded, and well-posed.\n\n### Derivation and Option Analysis\n\nThe problem requires a comparison of three test statistics within a sign-flip permutation testing framework based on two criteria: exactness of type-$I$ error control and performance under heavy-tailed distributions.\n\n**Criterion (i): Exactness of Type-I Error Control**\nA permutation test constructs the null distribution of a test statistic, $T$, by recomputing $T$ over all possible permutations of the data that are equally likely under the null hypothesis, $H_0$. In this problem, the design is paired, and the data are the differences $\\{d_i\\}_{i=1}^n$. The null hypothesis is that the distribution of each $d_i$ is symmetric about $0$. This symmetry implies that the sign of each $d_i$ is independent of its magnitude, and $\\text{P}(\\text{sgn}(d_i)=+1) = \\text{P}(\\text{sgn}(d_i)=-1) = 1/2$. Consequently, under $H_0$, the vector of observations $(d_1, d_2, \\dots, d_n)$ has the same distribution as any sign-flipped version $(s_1 d_1, s_2 d_2, \\dots, s_n d_n)$, where each $s_i \\in \\{+1, -1\\}$. This property is known as exchangeability under sign-flipping.\n\nThere are $2^n$ such sign-flipped vectors. The permutation test procedure is:\n1.  Calculate the observed test statistic, $T_{obs} = T(\\{d_i\\}_{i=1}^n)$.\n2.  Generate the permutation distribution by calculating the test statistic for all $2^n$ (or a large random subset) equally likely sign-flipped versions of the data.\n3.  The $p$-value is the proportion of statistics in the permutation distribution that are as extreme or more extreme than $T_{obs}$.\n\nFor a given significance level $\\alpha$, a decision rule can be defined based on this exact, non-parametrically generated null distribution. The probability of a type-$I$ error is controlled at the level $\\alpha$ (up to the discreteness of the distribution) because the test is constructed directly from the true null distribution of the data under the permutation group. This principle holds **for any choice of test statistic**. The choice of statistic affects the test's power ($1-\\beta$) but not the validity of the type-$I$ error control, provided the underlying symmetry assumption for $H_0$ holds.\n\nTherefore, for all three candidate statistics—the difference in means, the Student $t$-statistic, and the signed-rank statistic—the sign-flip permutation test provides exact control of the type-$I$ error rate under $H_0$.\n\n**Criterion (ii): Sensitivity to Heavy Tails and Outliers (Robustness and Power)**\nThis is where the statistics differ significantly.\n- **Difference in Means:** The test statistic is the sample mean, $T_{mean} = \\frac{1}{n}\\sum_{i=1}^n d_i$. This statistic is not robust. Its value can be arbitrarily changed by a single outlier. The influence function, which measures the effect of an infinitesimal contamination at a point, is unbounded for the mean. In the presence of heavy tails or outliers, the sampling distribution of the mean becomes highly variable, leading to low power.\n- **Student $t$-statistic:** The test statistic is $T_t = \\frac{\\bar{d}}{s_d/\\sqrt{n}}$, where $\\bar{d}$ is the sample mean and $s_d$ is the sample standard deviation of the $\\{d_i\\}$. While studentizing (dividing by the standard error) accounts for sample variability, both $\\bar{d}$ and $s_d$ are highly sensitive to outliers. A large outlier inflates both the numerator and the denominator. The inflation of $s_d$ is typically more pronounced, which can cause the $T_t$ value to shrink towards $0$, drastically reducing the power to detect a true effect. Like the mean, the $t$-statistic has an unbounded influence function and performs poorly with heavy-tailed data, especially from distributions with infinite variance (e.g., Cauchy), for which the sample mean and variance do not obey the law of large numbers or the central limit theorem.\n- **Signed-Rank Statistic (e.g., Wilcoxon Signed-Rank Statistic):** This statistic is based on ranks. First, one computes the ranks $R_i$ of the absolute values $|d_i|$. The statistic is then a sum of the signed ranks, e.g., $W = \\sum_{i=1}^n \\text{sgn}(d_i) R_i$. By converting the raw data values $|d_i|$ to their ranks $\\{1, 2, \\dots, n\\}$, the influence of any single observation is bounded. An outlier, no matter how extreme, can contribute at most the largest rank, $n$, to the calculation. This bounded influence function makes the statistic robust. For many non-Gaussian distributions, particularly symmetric heavy-tailed ones, the signed-rank test is more powerful than the $t$-test. The Asymptotic Relative Efficiency (ARE) of the Wilcoxon test relative to the $t$-test is $3/\\pi \\approx 0.955$ for Gaussian data (a minimal loss of efficiency), but it can be much greater than $1$ for heavy-tailed distributions. This makes it a superior choice in the scenario described.\n\n**Evaluation of Options**\n\n**A. Under the sign-flip permutation framework, all three statistics yield exact type-I error control under H0 because exchangeability of signs holds, but the signed-rank statistic has bounded influence and typically higher asymptotic relative efficiency under many symmetric heavy-tailed distributions; in contrast, the difference in means and the Student t-statistic have unbounded influence and can suffer substantial power loss when outliers inflate dispersion.**\nThis statement is entirely consistent with the analysis above. It correctly states that permutation provides exact type-$I$ error control for all statistics under the valid $H_0$. It also correctly contrasts the robustness properties: the bounded influence and higher efficiency of the signed-rank statistic versus the unbounded influence and potential power loss of the mean-based statistics in the presence of outliers.\n**Verdict: Correct.**\n\n**B. Permutation testing with the Student t-statistic is invalid unless the d_i are Gaussian; outliers break exchangeability and invalidate type-I error control, so the difference in means is superior under heavy tails.**\nThis statement is incorrect on multiple grounds. First, the validity of a *permutation t-test* does not require the data to be Gaussian; it requires exchangeability under $H_0$ (symmetry about $0$ in this case). The Gaussian assumption is for the *parametric t-test*. Second, outliers do not \"break\" exchangeability under $H_0$; if the true distribution is symmetric about $0$, the signs are random regardless of the magnitudes. Type-$I$ error control remains exact. Third, the difference in means is not \"superior\" to the $t$-statistic under heavy tails; both are non-robust and perform poorly.\n**Verdict: Incorrect.**\n\n**C. The Student t-statistic is uniformly most powerful against symmetric alternatives by the Lehmann–Scheffé theorem, so rank-based statistics cannot outperform it under any symmetric heavy-tailed distribution.**\nThis statement misrepresents statistical theory. The Student's $t$-test is Uniformly Most Powerful Unbiased (UMPU) for testing the mean of a **Normal** distribution. This optimality does not extend to \"any symmetric heavy-tailed distribution\". In fact, it is a well-known result that for heavy-tailed distributions (e.g., Laplace, logistic, or Cauchy-like), rank-based tests are more powerful than the $t$-test. The Lehmann-Scheffé theorem is invoked incorrectly to make a sweeping, false claim.\n**Verdict: Incorrect.**\n\n**D. Rank-based signed-rank statistics are incompatible with permutation tests because ranking destroys exchangeability; consequently, type-I error control is not exact, although robustness to outliers is improved.**\nThis statement is fundamentally wrong. The Wilcoxon signed-rank test is a classic example of a permutation test. The test procedure explicitly relies on the permutation of signs. The \"exchangeability\" property pertains to the raw data $\\{d_i\\}$ under $H_0$, which justifies generating the null distribution by permuting signs. The ranking is simply part of the calculation of the test statistic, which is performed on each permuted dataset. It does not destroy the principle of the test. As a result, the type-$I$ error control is exact, contrary to the statement's claim.\n**Verdict: Incorrect.**",
            "answer": "$$\\boxed{A}$$"
        },
        {
            "introduction": "Neuroimaging studies seldom involve a single hypothesis test; instead, we often test for effects across thousands of voxels, electrodes, or time points simultaneously. This massive multiplicity requires robust correction to avoid a deluge of false positives. This final practice  introduces a powerful solution: the Westfall–Young step-down procedure. You will derive this method, which leverages the joint distribution of test statistics captured by permutations to provide strong control over the family-wise error rate, and apply it to a practical multi-voxel fMRI scenario.",
            "id": "4185191",
            "problem": "A multi-voxel functional Magnetic Resonance Imaging (fMRI) group comparison uses a General Linear Model (GLM) to test for a condition effect across $m$ voxels. Let the per-voxel test statistic be the one-sided $t$-statistic, and assume under the global null hypothesis that the labels are exchangeable so that permutation resampling approximates the joint null distribution of the test statistics across voxels. The goal is to control the Family-Wise Error Rate (FWER) in the strong sense using the Westfall–Young (W-Y) step-down procedure, and to compute adjusted $p$-values for ordered hypotheses.\n\nStarting from the definition of FWER as the probability of at least one false rejection among the family of $m$ hypotheses, and the exchangeability principle under the global null with permutation resampling, derive from first principles how the step-down adjusted $p$-values arise from the empirical joint distribution of subset maxima of the test statistics across permutations. Explicitly outline the algorithm that, given ordered hypotheses by decreasing observed evidence, generates the W-Y step-down adjusted $p$-values in a multi-voxel analysis.\n\nThen, apply your derivation to the following concrete setting. There are $m = 4$ voxels, with observed test statistics ordered by decreasing value as\n$$\nT_{\\text{obs}} = \\begin{pmatrix} 4.0 \\\\ 3.5 \\\\ 3.1 \\\\ 2.4 \\end{pmatrix},\n$$\ncorresponding to voxels $v_1, v_2, v_3, v_4$ in this observed order. You are given $B = 20$ label permutations. For each permutation $b \\in \\{1,\\dots,20\\}$, the permuted test statistics for $(v_1, v_2, v_3, v_4)$ are provided by the matrix\n$$\n\\begin{pmatrix}\n4.2  2.1  1.0  0.5 \\\\\n4.1  3.0  2.0  1.8 \\\\\n2.8  3.6  3.0  2.2 \\\\\n2.5  1.2  3.7  1.5 \\\\\n2.9  2.0  1.5  3.8 \\\\\n3.0  2.6  3.2  2.4 \\\\\n2.3  0.9  3.3  0.4 \\\\\n2.1  2.2  1.1  3.1 \\\\\n3.6  2.5  2.0  0.7 \\\\\n3.2  1.9  2.6  2.4 \\\\\n2.7  3.4  2.7  1.9 \\\\\n3.1  2.8  2.9  2.0 \\\\\n2.4  1.5  2.7  2.8 \\\\\n3.3  2.7  2.5  2.3 \\\\\n2.0  3.2  2.1  2.0 \\\\\n3.5  3.3  2.8  2.9 \\\\\n2.2  2.4  2.2  2.6 \\\\\n3.7  2.1  2.9  2.7 \\\\\n2.6  1.8  0.7  2.5 \\\\\n3.0  2.2  2.3  1.9\n\\end{pmatrix}.\n$$\nAssume a one-sided test in the positive direction. Use the empirical proportion without any continuity correction (that is, use $\\frac{1}{B}\\sum_{b=1}^{B}(\\cdot)$, not the plus-one correction) for computing empirical exceedance probabilities from permutations. Compute the Westfall–Young step-down adjusted $p$-value for the third ordered hypothesis (that is, the hypothesis associated with $v_3$ and observed statistic $3.1$). Express your final numerical answer as a decimal, and round your answer to four significant figures.",
            "solution": "The problem as stated is scientifically grounded, well-posed, objective, and internally consistent. It provides a formal description of a standard statistical procedure in neuroimaging data analysis, the Westfall–Young (W-Y) permutation-based step-down procedure for Family-Wise Error Rate (FWER) control, and supplies all necessary data for a specific calculation. The problem is valid and can be solved as follows.\n\n### Part 1: Derivation from First Principles\n\nThe Family-Wise Error Rate (FWER) is the probability of making at least one Type I error (a false rejection of a null hypothesis) among a family of $m$ simultaneous hypothesis tests. Let $H_1, \\dots, H_m$ be the null hypotheses for the $m$ voxels. Let $I_0 \\subseteq \\{1, \\dots, m\\}$ be the index set of the a priori unknown true null hypotheses. The FWER is defined as:\n$$\n\\text{FWER} = P \\left( \\bigcup_{j \\in I_0} \\{\\text{reject } H_j\\} \\right)\n$$\nStrong control of the FWER at level $\\alpha$ requires that $\\text{FWER} \\le \\alpha$ for any configuration of true and false nulls (i.e., for any $I_0$).\n\nThe Westfall–Young procedure achieves strong FWER control by leveraging the joint distribution of the test statistics, which is approximated using permutation resampling under the assumption of exchangeability. The procedure is a step-down method, meaning it tests hypotheses sequentially, starting from the one with the most evidence against the null.\n\nLet $t_{\\text{obs},1}, \\dots, t_{\\text{obs},m}$ be the observed test statistics for the $m$ voxels. The first step is to order the hypotheses based on the observed evidence. For a one-sided test in the positive direction, we order the statistics from largest to smallest:\n$$\nt_{\\text{obs},(1)} \\ge t_{\\text{obs},(2)} \\ge \\dots \\ge t_{\\text{obs},(m)}\n$$\nLet $H_{(1)}, H_{(2)}, \\dots, H_{(m)}$ be the corresponding ordered hypotheses.\n\nThe core idea is to compute an adjusted $p$-value, $\\tilde{p}_{(j)}$, for each ordered hypothesis $H_{(j)}$. An adjusted $p$-value represents the smallest FWER level $\\alpha$ at which the hypothesis would be rejected.\n\nThe unadjusted step-down $p$-value, $p'_{(j)}$, for hypothesis $H_{(j)}$ is defined as the probability of observing a test statistic at least as large as $t_{\\text{obs},(j)}$ from any of the remaining hypotheses $H_{(j)}, H_{(j+1)}, \\dots, H_{(m)}$, under the global null hypothesis. Formally:\n$$\np'_{(j)} = P \\left( \\max_{k=j, \\dots, m} T_{(k)} \\ge t_{\\text{obs},(j)} \\mid H_C \\right)\n$$\nwhere $T_{(k)}$ are the random variables representing the test statistics and $H_C = \\bigcap_{j=1}^m H_j$ is the complete null hypothesis.\n\nThe W-Y procedure uses permutations to estimate these probabilities. We generate $B$ permutations of the group labels. For each permutation $b \\in \\{1, \\dots, B\\}$, we compute a full set of $m$ test statistics, $\\{t_{b,1}, t_{b,2}, \\dots, t_{b,m}\\}$. These $B$ sets of statistics form an empirical approximation of the joint null distribution.\n\nTo estimate $p'_{(j)}$, we construct, for each permutation $b$, the maximum test statistic over the relevant subset of voxels. Let the original indices of the ordered hypotheses be $\\pi(1), \\pi(2), \\dots, \\pi(m)$, such that $t_{\\text{obs},\\pi(1)} = t_{\\text{obs},(1)}$, etc. For each permutation $b$, we compute the successive maxima:\n$$\nM_{b,j} = \\max_{k=j, \\dots, m} \\{t_{b,\\pi(k)}\\}\n$$\nThe empirical estimate of the unadjusted step-down $p$-value is then the proportion of permutations where this maximum exceeds the observed statistic:\n$$\n\\hat{p}'_{(j)} = \\frac{1}{B} \\sum_{b=1}^{B} I\\left(M_{b,j} \\ge t_{\\text{obs},(j)}\\right)\n$$\nwhere $I(\\cdot)$ is the indicator function.\n\nFinally, to ensure that rejecting $H_{(j)}$ implies rejecting all preceding hypotheses $H_{(k)}$ with $k  j$ (a logical requirement of the step-down procedure), the adjusted $p$-values, $\\tilde{p}_{(j)}$, are enforced to be monotonically non-decreasing. This is achieved through the following recursive adjustment:\n$$\n\\tilde{p}_{(1)} = \\hat{p}'_{(1)}\n$$\n$$\n\\tilde{p}_{(j)} = \\max\\left(\\tilde{p}_{(j-1)}, \\hat{p}'_{(j)}\\right) \\text{ for } j = 2, \\dots, m\n$$\nThis ensures that $\\tilde{p}_{(1)} \\le \\tilde{p}_{(2)} \\le \\dots \\le \\tilde{p}_{(m)}$. This final set of $\\tilde{p}_{(j)}$ values are the W-Y step-down adjusted $p$-values.\n\n### Part 2: Algorithm Outline\n\nGiven the observed test statistics and a matrix of permuted test statistics:\n1.  **Order Hypotheses**: Let the observed test statistics for $m$ voxels be $t_{\\text{obs},1}, \\dots, t_{\\text{obs},m}$. Order them such that $t_{\\text{obs},(1)} \\ge t_{\\text{obs},(2)} \\ge \\dots \\ge t_{\\text{obs},(m)}$. Let the voxels corresponding to this order be $v_{(1)}, \\dots, v_{(m)}$.\n2.  **Generate Successive Maxima Distributions**: From the $B \\times m$ matrix of permuted statistics, where columns correspond to the original voxel indices, create a new $B \\times m$ matrix of successive maxima, $M$. For each permutation $b \\in \\{1, \\dots, B\\}$ and each ordered hypothesis $j \\in \\{1, \\dots, m\\}$, calculate:\n    $$\n    M_{b,j} = \\max_{k=j, \\dots, m} \\{t_{b, v_{(k)}}\\}\n    $$\n    The $j$-th column of $M$ is the empirical null distribution for the maximum of the test statistics from the set $\\{v_{(j)}, \\dots, v_{(m)}\\}$.\n3.  **Compute Raw Step-down p-values**: For each ordered hypothesis $j=1, \\dots, m$, calculate the raw step-down $p$-value, $\\hat{p}'_{(j)}$, by comparing the observed statistic $t_{\\text{obs},(j)}$ to the corresponding distribution of maxima $M_{*,j}$:\n    $$\n    \\hat{p}'_{(j)} = \\frac{1}{B} \\sum_{b=1}^{B} I\\left(M_{b,j} \\ge t_{\\text{obs},(j)}\\right)\n    $$\n4.  **Enforce Monotonicity**: Compute the final adjusted $p$-values, $\\tilde{p}_{(j)}$, by taking the cumulative maximum of the raw $p$-values:\n    $$\n    \\tilde{p}_{(j)} = \\max_{k=1, \\dots, j} \\{\\hat{p}'_{(k)}\\}\n    $$\n\n### Part 3: Application to the Concrete Setting\n\nWe are given $m=4$ voxels, $B=20$ permutations, and the observed test statistics are already ordered:\n$$\nT_{\\text{obs}} = \\begin{pmatrix} t_{\\text{obs},1} \\\\ t_{\\text{obs},2} \\\\ t_{\\text{obs},3} \\\\ t_{\\text{obs},4} \\end{pmatrix} = \\begin{pmatrix} 4.0 \\\\ 3.5 \\\\ 3.1 \\\\ 2.4 \\end{pmatrix}\n$$\nThe corresponding voxels are $v_1, v_2, v_3, v_4$. The goal is to compute $\\tilde{p}_3$, the adjusted $p$-value for the third ordered hypothesis.\n\n1.  **Ordering**: The hypotheses are already ordered by the observed statistics, so we proceed with indices $1, 2, 3, 4$.\n\n2.  **Generate Successive Maxima**: We need to compute the distributions for $M_{*,1}, M_{*,2}, M_{*,3}$. Let the provided $20 \\times 4$ permutation matrix be $T_{\\text{perm}}$.\n    -   $M_{b,1} = \\max(t_{b,1}, t_{b,2}, t_{b,3}, t_{b,4})$\n    -   $M_{b,2} = \\max(t_{b,2}, t_{b,3}, t_{b,4})$\n    -   $M_{b,3} = \\max(t_{b,3}, t_{b,4})$\n\n    The columns of the maxima matrix $M$ are:\n    $M_{*,1} = \\begin{pmatrix} 4.2, 4.1, 3.6, 3.7, 3.8, 3.2, 3.3, 3.1, 3.6, 3.2, 3.4, 3.1, 2.8, 3.3, 3.2, 3.5, 2.6, 3.7, 2.6, 3.0 \\end{pmatrix}^T$\n    $M_{*,2} = \\begin{pmatrix} 2.1, 3.0, 3.6, 3.7, 3.8, 3.2, 3.3, 3.1, 2.5, 2.6, 3.4, 2.9, 2.8, 2.7, 3.2, 3.3, 2.6, 2.9, 2.5, 2.3 \\end{pmatrix}^T$\n    $M_{*,3} = \\begin{pmatrix} 1.0, 2.0, 3.0, 3.7, 3.8, 3.2, 3.3, 3.1, 2.0, 2.6, 2.7, 2.9, 2.8, 2.5, 2.1, 2.9, 2.6, 2.9, 2.5, 2.3 \\end{pmatrix}^T$\n\n3.  **Compute Raw Step-down p-values**:\n    -   To find $\\tilde{p}_3$, we first need $\\hat{p}'_1, \\hat{p}'_2$, and $\\hat{p}'_3$.\n    -   For $\\hat{p}'_1$, we compare $M_{*,1}$ with $t_{\\text{obs},1} = 4.0$. The values in $M_{*,1}$ that are $\\ge 4.0$ are $\\{4.2, 4.1\\}$. The count is $2$.\n    $$\n    \\hat{p}'_1 = \\frac{2}{20} = 0.1\n    $$\n    -   For $\\hat{p}'_2$, we compare $M_{*,2}$ with $t_{\\text{obs},2} = 3.5$. The values in $M_{*,2}$ that are $\\ge 3.5$ are $\\{3.6, 3.7, 3.8\\}$. The count is $3$.\n    $$\n    \\hat{p}'_2 = \\frac{3}{20} = 0.15\n    $$\n    -   For $\\hat{p}'_3$, we compare $M_{*,3}$ with $t_{\\text{obs},3} = 3.1$. The values in $M_{*,3}$ that are $\\ge 3.1$ are $\\{3.7, 3.8, 3.2, 3.3, 3.1\\}$. The count is $5$.\n    $$\n    \\hat{p}'_3 = \\frac{5}{20} = 0.25\n    $$\n\n4.  **Enforce Monotonicity**:\n    -   The first adjusted $p$-value is $\\tilde{p}_1 = \\hat{p}'_1 = 0.1$.\n    -   The second adjusted $p$-value is $\\tilde{p}_2 = \\max(\\tilde{p}_1, \\hat{p}'_2) = \\max(0.1, 0.15) = 0.15$.\n    -   The third adjusted $p$-value, which is the value we seek, is:\n    $$\n    \\tilde{p}_3 = \\max(\\tilde{p}_2, \\hat{p}'_3) = \\max(0.15, 0.25) = 0.25\n    $$\nThe W-Y step-down adjusted $p$-value for the third ordered hypothesis is $0.25$. The problem requires the answer to be a decimal rounded to four significant figures. This gives $0.2500$.",
            "answer": "$$\n\\boxed{0.2500}\n$$"
        }
    ]
}