{
    "hands_on_practices": [
        {
            "introduction": "A fundamental task in neuroscience is comparing measurements between two groups, such as patient vs. control groups or two experimental conditions. This exercise provides foundational practice in implementing a bootstrap confidence interval for the difference in means, a common scenario in analyzing fMRI or electrophysiology data. By completing this practice , you will gain hands-on experience with the core logic of resampling and see how it provides a robust alternative to traditional t-tests, especially when parametric assumptions are questionable.",
            "id": "4142996",
            "problem": "You are given two independent groups of functional Magnetic Resonance Imaging (fMRI) subjects, each group containing subject-level regression coefficients (\"beta coefficients\") for a single condition extracted from a region of interest. Under the standard assumption that within each group the subject-level beta coefficients are independent and identically distributed, and that the two groups are independent of each other, consider the difference in mean beta coefficients between the two groups as the estimand of interest. Let $x_1, x_2, \\dots, x_{n_1}$ denote the first group's beta coefficients and $y_1, y_2, \\dots, y_{n_2}$ denote the second group's beta coefficients. The estimator for the difference in means is\n$$\n\\hat{\\Delta} = \\frac{1}{n_2} \\sum_{j=1}^{n_2} y_j \\;-\\; \\frac{1}{n_1} \\sum_{i=1}^{n_1} x_i.\n$$\nYou must compute a basic bootstrap confidence interval for $\\hat{\\Delta}$ using $B=2000$ bootstrap resamples, resampling subjects within each group with replacement, and report the resulting interval for a confidence level of $1-\\alpha$ with $\\alpha = 0.05$ (expressed as a decimal).\n\nThe basic bootstrap interval is defined by inverting the empirical distribution of the estimator’s error relative to the observed estimate. For each bootstrap resample, construct a bootstrap replicate $\\hat{\\Delta}^\\ast$ by resampling indices within each group and recomputing the difference in means. Define the bootstrap error replicate $E^\\ast = \\hat{\\Delta}^\\ast - \\hat{\\Delta}$. Let $q_{p}$ be the empirical $p$-quantile of the bootstrap error distribution $\\{E^\\ast_b\\}_{b=1}^B$. The $100 \\cdot (1-\\alpha)\\%$ basic bootstrap interval for $\\hat{\\Delta}$ is\n$$\n\\left[ \\hat{\\Delta} - q_{1-\\alpha/2}, \\; \\hat{\\Delta} - q_{\\alpha/2} \\right].\n$$\n\nImplement this procedure and apply it to the following test suite. For each case, $n_1 = 20$ and $n_2 = 22$ (numbers of subjects), and $B = 2000$. Use a fixed random number generator seed equal to $12345$ to ensure reproducibility of bootstrap resampling. The data arrays below list the observed subject-level coefficients for each group; treat these observed values as the entire available sample for bootstrapping.\n\nTest case $1$ (approximately symmetric distributions with a moderate difference in means):\n- Group $1$: $x^{(1)} = \\{0.39, 0.61, 0.52, 0.47, 0.58, 0.44, 0.73, 0.36, 0.49, 0.67, 0.42, 0.55, 0.63, 0.40, 0.51, 0.59, 0.46, 0.57, 0.48, 0.60\\}$\n- Group $2$: $y^{(1)} = \\{0.70, 0.68, 0.75, 0.81, 0.62, 0.77, 0.69, 0.73, 0.66, 0.79, 0.71, 0.74, 0.78, 0.65, 0.72, 0.76, 0.67, 0.80, 0.64, 0.82, 0.63, 0.85\\}$\n\nTest case $2$ (skewed, heavy-tailed positive coefficients):\n- Group $1$: $x^{(2)} = \\{0.12, 0.09, 0.15, 0.08, 0.20, 0.07, 0.11, 0.10, 0.13, 0.06, 0.18, 0.05, 0.25, 0.14, 0.09, 0.30, 0.04, 0.21, 0.16, 0.28\\}$\n- Group $2$: $y^{(2)} = \\{0.18, 0.16, 0.24, 0.20, 0.27, 0.15, 0.19, 0.23, 0.21, 0.26, 0.17, 0.22, 0.30, 0.14, 0.28, 0.25, 0.33, 0.13, 0.29, 0.31, 0.12, 0.35\\}$\n\nTest case $3$ (equal means by construction):\n- Group $1$: $x^{(3)} = \\{0.45, 0.55, 0.50, 0.52, 0.48, 0.51, 0.49, 0.53, 0.47, 0.54, 0.46, 0.56, 0.44, 0.57, 0.43, 0.58, 0.42, 0.59, 0.41, 0.60\\}$\n- Group $2$: $y^{(3)} = \\{0.45, 0.55, 0.50, 0.52, 0.48, 0.51, 0.49, 0.53, 0.47, 0.54, 0.46, 0.56, 0.44, 0.57, 0.43, 0.58, 0.42, 0.59, 0.41, 0.60, 0.505, 0.505\\}$\n\nTest case $4$ (low variance, near-constant coefficients with a small mean shift):\n- Group $1$: $x^{(4)} = \\{1.00, 1.01, 0.99, 1.02, 0.98, 1.00, 1.01, 0.99, 1.02, 0.98, 1.00, 1.01, 0.99, 1.02, 0.98, 1.00, 1.01, 0.99, 1.02, 0.98\\}$\n- Group $2$: $y^{(4)} = \\{1.03, 1.04, 1.02, 1.05, 1.01, 1.03, 1.04, 1.02, 1.05, 1.01, 1.03, 1.04, 1.02, 1.05, 1.01, 1.03, 1.04, 1.02, 1.05, 1.01, 1.03, 1.04\\}$\n\nYour program must:\n- Implement the basic bootstrap confidence interval as defined above using $B = 2000$ resamples and $\\alpha = 0.05$.\n- For each test case, compute and return the lower and upper bounds of the interval for $\\hat{\\Delta}$, where $\\hat{\\Delta}$ is defined as the mean of group $2$ minus the mean of group $1$.\n- Use a fixed random number generator seed equal to $12345$ for all bootstrap resampling steps.\n\nFinal output format:\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, where each element is a two-element list $[\\text{lower}, \\text{upper}]$ of floats for the corresponding test case, in order from test case $1$ to test case $4$. For example, the output format must be of the form $[[L_1,U_1],[L_2,U_2],[L_3,U_3],[L_4,U_4]]$.",
            "solution": "The problem is valid. It presents a well-defined computational statistics task based on standard, scientifically sound principles of bootstrap resampling for constructing confidence intervals, applied to a realistic scenario in neuroscience data analysis. All necessary data, parameters, and definitions are provided, and the problem is self-contained and objective.\n\nThe objective is to compute a basic bootstrap confidence interval for the difference in means between two independent groups of subjects. Let the observed data for the two groups be denoted by the sets $X = \\{x_1, x_2, \\dots, x_{n_1}\\}$ and $Y = \\{y_1, y_2, \\dots, y_{n_2}\\}$, where $n_1$ and $n_2$ are the respective sample sizes.\n\nThe parameter of interest (the estimand) is the true difference in population means, $\\Delta = \\mu_Y - \\mu_X$. The point estimate for this parameter is the observed difference in sample means:\n$$\n\\hat{\\Delta} = \\bar{y} - \\bar{x} = \\frac{1}{n_2} \\sum_{j=1}^{n_2} y_j \\;-\\; \\frac{1}{n_1} \\sum_{i=1}^{n_1} x_i\n$$\nWe are tasked with constructing a $100 \\cdot (1-\\alpha)\\%$ confidence interval for $\\Delta$, where the confidence level is specified by $\\alpha = 0.05$. The method to be used is the basic bootstrap, also known as the reverse percentile interval.\n\nThe fundamental idea of the bootstrap is to approximate the sampling distribution of an estimator by repeatedly resampling from the observed data. The basic bootstrap interval is derived by assuming that the distribution of the estimation error, $\\hat{\\Delta} - \\Delta$, can be approximated by the empirical distribution of bootstrap errors, $E^\\ast = \\hat{\\Delta}^\\ast - \\hat{\\Delta}$.\n\nThe algorithm proceeds as follows:\n\n1.  **Calculate the Observed Statistic**: First, compute the difference in means from the original data samples, $\\hat{\\Delta}$. This serves as our point estimate.\n\n2.  **Generate Bootstrap Resamples and Replicates**: Repeat the following procedure $B$ times, for $b = 1, 2, \\dots, B$:\n    a.  Generate a bootstrap sample for group $1$, denoted $X^{\\ast b}$, by drawing $n_1$ observations from the original sample $X$ with replacement.\n    b.  Generate a bootstrap sample for group $2$, denoted $Y^{\\ast b}$, by drawing $n_2$ observations from the original sample $Y$ with replacement.\n    c.  For each pair of bootstrap samples $(X^{\\ast b}, Y^{\\ast b})$, compute the bootstrap replicate of the statistic:\n        $$\n        \\hat{\\Delta}^{\\ast b} = \\overline{y^{\\ast b}} - \\overline{x^{\\ast b}}\n        $$\n    This process yields a collection of $B$ bootstrap replicates, $\\{\\hat{\\Delta}^{\\ast b}\\}_{b=1}^B$.\n\n3.  **Compute the Bootstrap Error Distribution**: From the bootstrap replicates, we construct the empirical distribution of bootstrap errors. For each replicate, the error is defined as the deviation from the original estimate:\n    $$\n    E^{\\ast b} = \\hat{\\Delta}^{\\ast b} - \\hat{\\Delta}\n    $$\n    This gives a set of $B$ bootstrap error values, $\\{E^{\\ast b}\\}_{b=1}^B$.\n\n4.  **Determine Quantiles of the Error Distribution**: Let $q_p$ denote the empirical $p$-quantile of the sorted bootstrap error distribution $\\{E^{\\ast b}\\}$. We need the quantiles corresponding to the tails of the confidence interval, specifically $q_{\\alpha/2}$ and $q_{1-\\alpha/2}$. For $\\alpha=0.05$, these are the $0.025$ and $0.975$ quantiles (i.e., the $2.5^{th}$ and $97.5^{th}$ percentiles).\n\n5.  **Construct the Confidence Interval**: The $100 \\cdot (1-\\alpha)\\%$ basic bootstrap confidence interval for $\\Delta$ is constructed by pivoting on the observed statistic $\\hat{\\Delta}$ using the error quantiles:\n    $$\n    \\text{CI}_{1-\\alpha}(\\Delta) = \\left[ \\hat{\\Delta} - q_{1-\\alpha/2}, \\quad \\hat{\\Delta} - q_{\\alpha/2} \\right]\n    $$\n    This construction inverts the error distribution around the point estimate. The lower bound of the confidence interval is corrected by the upper quantile of the error distribution, and the upper bound is corrected by the lower quantile of the error distribution.\n\nFor this problem, we are given $n_1 = 20$, $n_2 = 22$, the number of bootstrap resamples $B = 2000$, and a confidence parameter $\\alpha = 0.05$. A fixed random number generator seed of $12345$ is used to ensure the reproducibility of the resampling process. This entire procedure will be applied to each of the four provided test cases.\n\nThe implementation will utilize the `numpy` library for efficient array operations, resampling via `numpy.random.choice`, and quantile calculation via `numpy.quantile`. A single random number generator instance, seeded with $12345$, will be used for all resampling steps across all test cases to ensure strict adherence to the problem's reproducibility requirement.",
            "answer": "```python\nimport numpy as np\n\ndef compute_basic_bootstrap_ci(x, y, B, alpha, rng):\n    \"\"\"\n    Computes the basic bootstrap confidence interval for the difference in means.\n\n    Args:\n        x (np.ndarray): Data for group 1.\n        y (np.ndarray): Data for group 2.\n        B (int): Number of bootstrap resamples.\n        alpha (float): Significance level for the confidence interval.\n        rng (np.random.Generator): A NumPy random number generator.\n\n    Returns:\n        list: A list containing the lower and upper bounds of the confidence interval.\n    \"\"\"\n    # Get sample sizes\n    n1 = len(x)\n    n2 = len(y)\n\n    # Step 1: Calculate the observed statistic (difference in means)\n    delta_hat = np.mean(y) - np.mean(x)\n\n    # Step 2 and 3: Generate bootstrap replicates and compute the statistic\n    bootstrap_deltas = np.empty(B)\n    for i in range(B):\n        # Resample with replacement from each group\n        x_star = rng.choice(x, size=n1, replace=True)\n        y_star = rng.choice(y, size=n2, replace=True)\n        \n        # Compute the bootstrap replicate of the statistic\n        bootstrap_deltas[i] = np.mean(y_star) - np.mean(x_star)\n\n    # Step 4: Compute the bootstrap distribution of the error\n    bootstrap_errors = bootstrap_deltas - delta_hat\n\n    # Step 5: Find the quantiles of the error distribution\n    q_alpha_2 = np.quantile(bootstrap_errors, alpha / 2.0)\n    q_1_minus_alpha_2 = np.quantile(bootstrap_errors, 1 - alpha / 2.0)\n\n    # Step 6: Construct the confidence interval\n    lower_bound = delta_hat - q_1_minus_alpha_2\n    upper_bound = delta_hat - q_alpha_2\n\n    return [lower_bound, upper_bound]\n\ndef solve():\n    \"\"\"\n    Main function to run the test cases and print the results.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        (\n            np.array([0.39, 0.61, 0.52, 0.47, 0.58, 0.44, 0.73, 0.36, 0.49, 0.67, 0.42, 0.55, 0.63, 0.40, 0.51, 0.59, 0.46, 0.57, 0.48, 0.60]),\n            np.array([0.70, 0.68, 0.75, 0.81, 0.62, 0.77, 0.69, 0.73, 0.66, 0.79, 0.71, 0.74, 0.78, 0.65, 0.72, 0.76, 0.67, 0.80, 0.64, 0.82, 0.63, 0.85]),\n        ),\n        (\n            np.array([0.12, 0.09, 0.15, 0.08, 0.20, 0.07, 0.11, 0.10, 0.13, 0.06, 0.18, 0.05, 0.25, 0.14, 0.09, 0.30, 0.04, 0.21, 0.16, 0.28]),\n            np.array([0.18, 0.16, 0.24, 0.20, 0.27, 0.15, 0.19, 0.23, 0.21, 0.26, 0.17, 0.22, 0.30, 0.14, 0.28, 0.25, 0.33, 0.13, 0.29, 0.31, 0.12, 0.35]),\n        ),\n        (\n            np.array([0.45, 0.55, 0.50, 0.52, 0.48, 0.51, 0.49, 0.53, 0.47, 0.54, 0.46, 0.56, 0.44, 0.57, 0.43, 0.58, 0.42, 0.59, 0.41, 0.60]),\n            np.array([0.45, 0.55, 0.50, 0.52, 0.48, 0.51, 0.49, 0.53, 0.47, 0.54, 0.46, 0.56, 0.44, 0.57, 0.43, 0.58, 0.42, 0.59, 0.41, 0.60, 0.505, 0.505]),\n        ),\n        (\n            np.array([1.00, 1.01, 0.99, 1.02, 0.98, 1.00, 1.01, 0.99, 1.02, 0.98, 1.00, 1.01, 0.99, 1.02, 0.98, 1.00, 1.01, 0.99, 1.02, 0.98]),\n            np.array([1.03, 1.04, 1.02, 1.05, 1.01, 1.03, 1.04, 1.02, 1.05, 1.01, 1.03, 1.04, 1.02, 1.05, 1.01, 1.03, 1.04, 1.02, 1.05, 1.01, 1.03, 1.04]),\n        ),\n    ]\n\n    # Parameters from the problem\n    B = 2000\n    alpha = 0.05\n    seed = 12345\n\n    # Initialize random number generator once for all resampling steps\n    rng = np.random.default_rng(seed)\n\n    results = []\n    for x_data, y_data in test_cases:\n        ci = compute_basic_bootstrap_ci(x_data, y_data, B, alpha, rng)\n        results.append(ci)\n\n    # Custom formatting to avoid spaces inside the inner lists, though\n    # the template suggests `map(str, results)` which would add spaces.\n    # To be fully compliant with the example `[L_1,U_1]`, this manual format is better.\n    inner_results_str = [f\"[{l},{u}]\" for l, u in results]\n    print(f\"[{','.join(inner_results_str)}]\")\n\n\nsolve()\n```"
        },
        {
            "introduction": "Neuroscience datasets are frequently hierarchical, with measurements like trials nested within neurons, and neurons nested within subjects. Failing to account for this structure can lead to incorrect inferences by underestimating the true variability. This exercise tackles this advanced challenge by guiding you to implement a hierarchical bootstrap, which correctly models the different sources of variance at each level of the data structure. Mastering this technique  is essential for validly analyzing the complex, multi-level data common in modern neuroscience.",
            "id": "4142939",
            "problem": "You are given a hierarchical dataset of neural responses recorded as trial-level real-valued observations from multiple neurons nested within multiple subjects. The inferential target is the population-level median response across neurons, respecting the hierarchical nesting of neurons within subjects and trials within neurons. Let the dataset be represented as a three-level nested list, where the outer list indexes subjects, the next inner list indexes neurons within a subject, and the innermost list contains the trial-level responses for a neuron. Denote subjects by $s \\in \\{1,\\dots,S\\}$, neurons within subject $s$ by $i \\in \\{1,\\dots,N_s\\}$, and trials within neuron $(s,i)$ by $j \\in \\{1,\\dots,T_{s,i}\\}$. The observed trial responses are $x_{s,i,j} \\in \\mathbb{R}$. For each neuron $(s,i)$, define the neuron-level median $m_{s,i}$ as the median of $\\{x_{s,i,1},\\dots,x_{s,i,T_{s,i}}\\}$. The population-level statistic of interest is the across-neuron median\n$$\nM = \\operatorname{median}\\left(\\{m_{s,i} : s \\in \\{1,\\dots,S\\}, i \\in \\{1,\\dots,N_s\\}\\}\\right).\n$$\n\nStarting from the following foundational principles:\n- The bootstrap resampling principle: approximate the sampling distribution of a statistic by resampling with replacement from the empirical distribution at appropriate levels while preserving the hierarchical structure.\n- Exchangeability within levels under the sampling design: subjects are exchangeable at the subject level, neurons are exchangeable within subjects, and trials are exchangeable within neurons.\n- The definition of the median and quantiles: for a real-valued random variable with empirical distribution, the median is the $0.5$ quantile, and a two-sided confidence interval at level $(1-\\alpha)$ can be constructed from bootstrap replicates by taking the empirical $(\\alpha/2)$ and $(1-\\alpha/2)$ quantiles.\n\nYour task is to design and implement a program that constructs a hierarchical bootstrap percentile interval for $M$ by:\n- Resampling subjects with replacement: draw $S$ subject indices with replacement from $\\{1,\\dots,S\\}$.\n- For each resampled subject, resample neurons with replacement: draw $N_s$ neuron indices with replacement from $\\{1,\\dots,N_s\\}$ for that subject.\n- For each resampled neuron, resample trials with replacement: draw $T_{s,i}$ trial indices with replacement from $\\{1,\\dots,T_{s,i}\\}$ for that neuron.\n- For each bootstrapped neuron, compute the neuron-level median of its resampled trials, and then compute the overall median $M^\\ast$ across all bootstrapped neurons in the resample.\n- Repeat the above to obtain $B$ bootstrap replicates $\\{M^\\ast_b\\}_{b=1}^B$.\n- Form the two-sided percentile confidence interval at level $(1-\\alpha)$ for $M$ as $[q_{\\alpha/2}, q_{1-\\alpha/2}]$, where $q_p$ denotes the empirical $p$-quantile of the bootstrap replicate distribution.\n\nImplement the above without any additional assumptions beyond exchangeability within levels and the observed data, and ensure your program produces reproducible results by using the specified random seeds via a pseudo-random number generator.\n\nTest Suite and Parameters:\nFor each of the following test cases, compute the hierarchical bootstrap percentile interval $[q_{\\alpha/2}, q_{1-\\alpha/2}]$ for $M$ and return it as a list of two floats. The test cases specify the dataset, the number of bootstrap replicates $B$, the confidence level parameter $\\alpha$, and a random seed for reproducibility.\n\n- Test Case $1$ (general case with variability across levels):\n  - Data $D_1$:\n    - Subject $1$: Neuron $1$ trials $[0.8, 0.9, 1.1, 1.0, 0.95]$, Neuron $2$ trials $[1.2, 1.1, 1.3, 1.25, 1.15]$.\n    - Subject $2$: Neuron $1$ trials $[0.5, 0.55, 0.6]$, Neuron $2$ trials $[0.7, 0.75, 0.72, 0.74]$, Neuron $3$ trials $[0.65, 0.6, 0.62]$.\n    - Subject $3$: Neuron $1$ trials $[1.5, 1.45, 1.55, 1.6]$, Neuron $2$ trials $[1.0, 1.05, 0.95, 1.02]$.\n  - Replicates $B = 5000$.\n  - Alpha $\\alpha = 0.05$.\n  - Seed $123$.\n\n- Test Case $2$ (boundary case: single subject, single neuron, single trial):\n  - Data $D_2$: Subject $1$: Neuron $1$ trials $[0.37]$.\n  - Replicates $B = 1000$.\n  - Alpha $\\alpha = 0.10$.\n  - Seed $7$.\n\n- Test Case $3$ (edge case: unbalanced numbers of neurons and trials across subjects):\n  - Data $D_3$:\n    - Subject $1$: Neuron $1$ trials $[0.2, 0.25]$, Neuron $2$ trials $[0.3]$, Neuron $3$ trials $[0.18, 0.22, 0.24]$.\n    - Subject $2$: Neuron $1$ trials $[0.5, 0.55, 0.58, 0.52]$, Neuron $2$ trials $[0.4, 0.42]$.\n  - Replicates $B = 4000$.\n  - Alpha $\\alpha = 0.10$.\n  - Seed $999$.\n\nFinal Output Format:\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, where each test case’s confidence interval is itself a two-element list of floats. For example, the output structure must be of the form $[[\\ell_1,u_1],[\\ell_2,u_2],[\\ell_3,u_3]]$ with no additional text before or after. The floats may be formatted to a fixed number of decimal places; the unit is arbitrary real values with no physical unit associated. The angle unit is not applicable. Percentages are not to be used; any confidence level specification is via the decimal $\\alpha$ values provided above.",
            "solution": "The problem has been validated and is determined to be a well-posed, scientifically grounded problem in computational statistics. It is self-contained, consistent, and free of any ambiguities or fallacies. The task is to implement a hierarchical bootstrap procedure to construct a percentile confidence interval for a population-level median ($M$) derived from a nested data structure, common in neuroscience.\n\n**Principles and Algorithmic Design**\n\nThe solution is designed by directly translating the provided foundational principles into a computational algorithm. The core of the problem lies in correctly simulating the sampling process for a hierarchically structured dataset.\n\n**1. Data Representation and Target Statistic**\n\nThe dataset consists of real-valued trial responses $x_{s,i,j}$ organized in a three-level hierarchy: trials ($j$) are nested within neurons ($i$), which are nested within subjects ($s$).\nThe statistic of interest is the population-level median, $M$, defined as:\n$$\nM = \\operatorname{median}\\left(\\{m_{s,i} : s \\in \\{1,\\dots,S\\}, i \\in \\{1,\\dots,N_s\\}\\}\\right)\n$$\nwhere $m_{s,i}$ is the median of the trial responses for neuron $(s,i)$:\n$$\nm_{s,i} = \\operatorname{median}\\left(\\{x_{s,i,1}, \\dots, x_{s,i,T_{s,i}}\\}\\right)\n$$\nHere, $S$ is the total number of subjects, $N_s$ is the number of neurons for subject $s$, and $T_{s,i}$ is the number of trials for neuron $(s,i)$.\n\n**2. The Hierarchical Bootstrap Principle**\n\nThe central tenet of bootstrapping is to approximate the sampling distribution of a statistic by repeatedly resampling from the observed data. For hierarchical data, this resampling must respect the nested structure to be valid. This is justified by the principle of **exchangeability at each leve**l:\n-   Subjects are assumed to be exchangeable drawings from a larger population of subjects.\n-   Within a given subject, its neurons are assumed to be exchangeable.\n-   Within a given neuron, its trials are assumed to be exchangeable.\n\nThe algorithm implements this by resampling with replacement at each level of the hierarchy. For a single bootstrap replicate, the procedure is as follows:\n\n-   **Step 2a: Subject Resampling.** A new set of $S$ subjects is created by drawing $S$ times with replacement from the original set of subjects $\\{1, \\dots, S\\}$. This means some original subjects may appear multiple times in the bootstrap sample, while others may not appear at all.\n\n-   **Step 2b: Neuron Resampling.** For each subject selected in the step above (e.g., a resampled copy of original subject $s$), its neurons are resampled. If the original subject $s$ had $N_s$ neurons, we draw $N_s$ times with replacement from that subject's original pool of neurons. This is performed independently for each subject in the resampled subject list.\n\n-   **Step 2c: Trial Resampling.** For each neuron selected in the step above (e.g., a resampled copy of original neuron $(s,i)$ with $T_{s,i}$ trials), its trials are resampled. We draw $T_{s,i}$ times with replacement from that neuron's original set of trials $\\{x_{s,i,1}, \\dots, x_{s,i,T_{s,i}}\\}$.\n\n**3. Generation of the Bootstrap Distribution**\n\nThe multi-level resampling process generates one \"bootstrap dataset\". From this dataset, we compute a single bootstrap replicate of the statistic of interest, $M^\\ast_b$:\n1.  For each resampled neuron in the bootstrap dataset, we compute its median from its resampled trials. This gives a set of bootstrapped neuron-level medians. The total number of such medians is equal to the total number of neurons in the original dataset, $\\sum_{s=1}^S N_s$.\n2.  The median of this set of bootstrapped neuron-level medians is calculated. This value is one bootstrap replicate, $M^\\ast_b$.\n\nThis entire procedure is repeated $B$ times, where $B$ is a large number (e.g., $B=5000$ in Test Case $1$), to generate a collection of replicates $\\{M^\\ast_1, M^\\ast_2, \\dots, M^\\ast_B\\}$. This collection serves as an empirical approximation of the sampling distribution of $M$.\n\n**4. Confidence Interval Construction**\n\nThe final step is to construct the $(1-\\alpha)$ two-sided percentile confidence interval. This is achieved by computing the empirical quantiles of the sorted bootstrap distribution.\n-   The lower bound of the confidence interval, $q_{\\alpha/2}$, is the $(\\alpha/2)$-quantile of the distribution $\\{M^\\ast_b\\}_{b=1}^B$.\n-   The upper bound, $q_{1-\\alpha/2}$, is the $(1-\\alpha/2)$-quantile of the same distribution.\n\nFor a test case with confidence parameter $\\alpha = 0.05$, the interval is formed by the $0.025$ and $0.975$ quantiles of the bootstrap replicates. This method directly applies the principles provided in the problem statement. The use of a seeded pseudo-random number generator ensures that the random sampling process is deterministic and the results are reproducible.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Computes hierarchical bootstrap percentile confidence intervals for the \n    population-level median of neuron-level medians for a series of test cases.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        {\n            \"data\": [\n                # Subject 1\n                [[0.8, 0.9, 1.1, 1.0, 0.95], [1.2, 1.1, 1.3, 1.25, 1.15]],\n                # Subject 2\n                [[0.5, 0.55, 0.6], [0.7, 0.75, 0.72, 0.74], [0.65, 0.6, 0.62]],\n                # Subject 3\n                [[1.5, 1.45, 1.55, 1.6], [1.0, 1.05, 0.95, 1.02]]\n            ],\n            \"B\": 5000,\n            \"alpha\": 0.05,\n            \"seed\": 123\n        },\n        {\n            \"data\": [[[0.37]]],  # Subject 1, Neuron 1, Trial 1\n            \"B\": 1000,\n            \"alpha\": 0.10,\n            \"seed\": 7\n        },\n        {\n            \"data\": [\n                # Subject 1\n                [[0.2, 0.25], [0.3], [0.18, 0.22, 0.24]],\n                # Subject 2\n                [[0.5, 0.55, 0.58, 0.52], [0.4, 0.42]]\n            ],\n            \"B\": 4000,\n            \"alpha\": 0.10,\n            \"seed\": 999\n        }\n    ]\n\n    results = []\n    \n    # Pre-convert trial data from lists to numpy arrays for efficient processing.\n    for case in test_cases:\n        case['data'] = [[np.array(neuron_trials) for neuron_trials in subject_neurons] for subject_neurons in case['data']]\n\n    for case in test_cases:\n        data = case['data']\n        B = case['B']\n        alpha = case['alpha']\n        seed = case['seed']\n        \n        # Initialize a pseudo-random number generator for reproducibility.\n        rng = np.random.default_rng(seed)\n        \n        num_subjects = len(data)\n        \n        bootstrap_replicates = np.zeros(B)\n        \n        for b in range(B):\n            # This list will hold the neuron-level medians for one bootstrap sample.\n            bootstrapped_neuron_medians = []\n            \n            # Level 1: Resample subjects with replacement.\n            resampled_subject_indices = rng.choice(num_subjects, size=num_subjects, replace=True)\n            \n            for subject_idx in resampled_subject_indices:\n                original_subject_neurons = data[subject_idx]\n                num_neurons_in_subject = len(original_subject_neurons)\n                \n                if num_neurons_in_subject == 0:\n                    continue\n\n                # Level 2: Resample neurons within the selected subject with replacement.\n                resampled_neuron_indices = rng.choice(num_neurons_in_subject, size=num_neurons_in_subject, replace=True)\n                \n                for neuron_idx in resampled_neuron_indices:\n                    original_neuron_trials = original_subject_neurons[neuron_idx]\n                    num_trials_in_neuron = len(original_neuron_trials)\n                    \n                    if num_trials_in_neuron == 0:\n                        continue\n\n                    # Level 3: Resample trials within the selected neuron with replacement.\n                    resampled_trial_indices = rng.choice(num_trials_in_neuron, size=num_trials_in_neuron, replace=True)\n                    resampled_trials = original_neuron_trials[resampled_trial_indices]\n                    \n                    # Compute the median for the resampled neuron.\n                    neuron_median = np.median(resampled_trials)\n                    bootstrapped_neuron_medians.append(neuron_median)\n\n            # Compute the population-level median for this bootstrap replicate.\n            if bootstrapped_neuron_medians:\n                M_star = np.median(bootstrapped_neuron_medians)\n                bootstrap_replicates[b] = M_star\n            else:\n                # This case occurs if the bootstrap sample contains no trials.\n                bootstrap_replicates[b] = np.nan\n\n        # Remove any NaN replicates before computing quantiles.\n        valid_replicates = bootstrap_replicates[~np.isnan(bootstrap_replicates)]\n\n        # Construct the percentile confidence interval.\n        lower_quantile = alpha / 2.0\n        upper_quantile = 1.0 - (alpha / 2.0)\n        \n        if len(valid_replicates) > 0:\n            ci = np.quantile(valid_replicates, [lower_quantile, upper_quantile])\n        else:\n            # If no valid replicates, CI is undefined.\n            ci = [np.nan, np.nan]\n        \n        # Store the result as a list of floats.\n        results.append(list(ci))\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "The bootstrap procedures we have discussed so far rely on the critical assumption that data points are independent and identically distributed (IID). However, in many experimental contexts, such as long recording sessions, this assumption is violated by phenomena like neuronal adaptation, learning, or electrode drift. This practice presents a conceptual challenge: to diagnose the breakdown of the IID assumption and identify a more appropriate method, like the moving block bootstrap, to handle temporally dependent data. Engaging with this problem  will sharpen your ability to critically assess statistical assumptions and choose the correct tool for real-world, non-ideal data.",
            "id": "4142975",
            "problem": "A systems neuroscience lab recorded a single neuron's trial-averaged spiking response $y_t$ to a repeated stimulus over $T$ repeated trials during a 1-hour session, with trials indexed by $t \\in \\{1,\\dots,T\\}$. The goal is to construct a $95\\%$ confidence interval (CI) for the session mean response, defined as the expectation of a hypothetical stationary process representing the neuron under stable conditions.\n\nThe lab plans to use a nonparametric bootstrap that resamples the $T$ trials with replacement and computes the mean of each resample to approximate the sampling distribution of the mean. However, the following empirical patterns are observed:\n\n- The sample autocorrelation function (ACF, autocorrelation function) of $\\{y_t\\}$ displays significant positive autocorrelation for lags up to approximately $15$.\n- A linear regression of $y_t$ on time $t$ indicates a significant linear drift; the residuals $\\hat{\\epsilon}_t$ from this regression still show significant positive autocorrelation at lag $1$ and lag $2$ by the Ljung–Box test at level $5\\%$.\n- The marginal histogram of $\\{y_t\\}$ is approximately symmetric and unimodal without extreme outliers.\n\nAssume the neuron’s responses can be modeled as $y_t = \\mu + f(t) + \\epsilon_t$, where $\\mu$ is a constant, $f(t)$ is a smooth drift term over trials, and $\\{\\epsilon_t\\}$ is a zero-mean weakly stationary process with short-range dependence and positive autocorrelations at small lags. The lab’s target parameter is the stationary mean $\\mu$. The bootstrap must approximate the sampling distribution of the estimator of $\\mu$ under data-generating mechanisms plausible for the recorded neuron.\n\nWhich option best characterizes how and why the naive independent and identically distributed (IID) bootstrap is likely to fail here, how to diagnose the violation in practice, and an appropriate modification that restores validity for the target CI?\n\nA. Diagnosis: Perform a Shapiro–Wilk test of normality on $\\{y_t\\}$. Remedy: Winsorize the largest and smallest $5\\%$ of $\\{y_t\\}$ before bootstrapping. Expected failure: The naive IID bootstrap will produce CIs that are too wide because autocorrelation inflates resampling variability.\n\nB. Diagnosis: Examine the ACF of $\\{y_t\\}$ and, after removing drift via regression on $t$, the ACF and portmanteau tests of the residuals $\\{\\hat{\\epsilon}_t\\}$. Remedy: Remove drift to target $\\mu$, then apply a moving block bootstrap to $\\{\\hat{\\epsilon}_t\\}$ with an empirically chosen block length, reconstructing series as $\\hat{\\mu} + \\hat{f}(t) + \\text{bootstrapped residuals}$. Expected failure: The naive IID bootstrap will be anti-conservative, yielding CIs that are too narrow due to unmodeled positive autocorrelation and may be centered on a time-averaged quantity rather than the stationary mean.\n\nC. Diagnosis: Inspect histogram symmetry of $\\{y_t\\}$ to confirm approximate Gaussianity. Remedy: Use a Studentized bootstrap on $\\{y_t\\}$ to correct for skew. Expected failure: The naive IID bootstrap mainly fails by producing asymmetric CIs; coverage remains approximately correct.\n\nD. Diagnosis: Compute the cross-correlation at lag $0$ between adjacent trials across experimental conditions to check independence. Remedy: Stratify bootstrap resampling by deciles of $y_t$ to preserve the marginal distribution. Expected failure: The naive IID bootstrap will remain centered correctly but will overestimate variance and produce too wide CIs because of non-identical distributions across time.",
            "solution": "The problem statement asks for a critical evaluation of the naive independent and identically distributed (IID) bootstrap for constructing a confidence interval for a stationary mean parameter $\\mu$ from a time series of neuronal responses $\\{y_t\\}$, and to identify an appropriate diagnostic and remedial procedure.\n\nThe provided model for the neuronal response is $y_t = \\mu + f(t) + \\epsilon_t$, where $\\mu$ is the constant stationary mean of interest, $f(t)$ is a smooth temporal drift, and $\\{\\epsilon_t\\}$ is a zero-mean, weakly stationary process with positive autocorrelation at short lags.\n\nFirst, let us analyze the validity of the naive IID bootstrap under these conditions. The IID bootstrap relies on the core assumption that the data points are independent and identically distributed. The problem statement provides explicit evidence that both of these assumptions are violated.\n\n1.  **Violation of the \"Identically Distributed\" Assumption**: The presence of the drift term $f(t)$ implies that the expected value of the response changes with the trial number $t$: $E[y_t] = \\mu + f(t)$. Since $f(t)$ is not constant (as indicated by the \"significant linear drift\"), the random variables $y_t$ for different $t$ do not have the same mean. Therefore, they are not identically distributed.\n\n2.  **Violation of the \"Independence\" Assumption**: The problem states that the noise process $\\{\\epsilon_t\\}$ has \"short-range dependence and positive autocorrelations at small lags.\" This is empirically confirmed by the significant sample autocorrelation function (ACF) of $\\{y_t\\}$ and, crucially, of the residuals $\\{\\hat{\\epsilon}_t\\}$ after removing the linear drift. This directly violates the independence assumption.\n\nNext, we evaluate the consequences of these violations for the naive IID bootstrap. The naive bootstrap procedure consists of drawing $T$ samples $\\{y_t^*\\}$ with replacement from the original data $\\{y_t\\}_{t=1}^T$ and calculating their mean, $\\bar{y}^* = \\frac{1}{T}\\sum y_t^*$. This is repeated many times to form a distribution of bootstrap means.\n\n*   **Effect of the Drift Term $f(t)$**: The sample mean of the original data is $\\bar{y} = \\frac{1}{T}\\sum_{t=1}^T y_t = \\mu + \\frac{1}{T}\\sum_{t=1}^T f(t) + \\frac{1}{T}\\sum_{t=1}^T \\epsilon_t = \\mu + \\bar{f} + \\bar{\\epsilon}$. The naive bootstrap distribution will be centered around this sample mean, $\\bar{y}$. However, the target of inference is $\\mu$. The sample mean $\\bar{y}$ is a biased estimator for $\\mu$ due to the term $\\bar{f}$, the average drift over the session. Consequently, the resulting confidence interval will be centered on a value that is systematically offset from the true target parameter $\\mu$.\n\n*   **Effect of Positive Autocorrelation**: For a stationary time series $\\{\\epsilon_t\\}$ with variance $\\sigma_\\epsilon^2$ and autocorrelations $\\rho(k)$, the variance of the sample mean $\\bar{\\epsilon}$ is given by:\n    $$ \\text{Var}(\\bar{\\epsilon}) = \\frac{\\sigma_\\epsilon^2}{T} \\left[ 1 + 2 \\sum_{k=1}^{T-1} \\left(1-\\frac{k}{T}\\right) \\rho(k) \\right] $$\n    The problem states that $\\{\\epsilon_t\\}$ has positive autocorrelations at small lags ($\\rho(k) > 0$ for small $k$). This means the term in the square brackets is greater than $1$, and thus $\\text{Var}(\\bar{\\epsilon}) > \\frac{\\sigma_\\epsilon^2}{T}$.\n    The naive IID bootstrap, by scrambling the temporal order of the data, destroys the autocorrelation structure. The variance of the bootstrap distribution of the mean will be an estimate of the variance under an IID assumption, which is $\\frac{\\text{Var}(y_t)}{T}$ (or more precisely, an estimate of $\\frac{\\text{Var}(\\epsilon_t)}{T}$ if applied to residuals). This systematically underestimates the true variance of the sample mean. An underestimated variance leads to confidence intervals that are too narrow. Such intervals are called \"anti-conservative\" because their true coverage probability is less than the nominal level (e.g., less than $95\\%$).\n\nA valid procedure must therefore consist of two steps:\n1.  **Diagnosis and Correction for Non-stationarity**: The non-stationarity (drift) must be identified and removed. This is correctly done by examining the data for trends (e.g., plotting $y_t$ vs. $t$) and then modeling and subtracting the trend. The problem mentions performing a linear regression of $y_t$ on $t$, yielding residuals $\\hat{\\epsilon}_t$. The intercept of this regression provides an estimate of $\\mu$ (if we assume $f(0)=0$ for the linear model $f(t)=\\beta_1 t$).\n2.  **Diagnosis and Correction for Dependence**: The residuals $\\{\\hat{\\epsilon}_t\\}$ must be checked for remaining autocorrelation. The problem states this was done using the ACF and a Ljung-Box test, which correctly found significant dependence. To generate a bootstrap CI that accounts for this dependence, a method that preserves the temporal structure is required. The moving block bootstrap (MBB) is a standard technique for this. It involves resampling blocks of consecutive residuals, thereby preserving the short-range correlation structure within the blocks. The block length must be chosen carefully to be larger than the correlation length of the process.\n\nNow we evaluate the given options.\n\n**A. Diagnosis: Perform a Shapiro–Wilk test of normality on $\\{y_t\\}$. Remedy: Winsorize the largest and smallest $5\\%$ of $\\{y_t\\}$ before bootstrapping. Expected failure: The naive IID bootstrap will produce CIs that are too wide because autocorrelation inflates resampling variability.**\n*   **Diagnosis**: The primary violations are non-stationarity and dependence, not non-normality. The problem states the distribution is symmetric and unimodal. This diagnosis is misplaced.\n*   **Remedy**: Winsorization is a method to handle outliers. The problem states there are no extreme outliers. This remedy does not address drift or autocorrelation.\n*   **Expected Failure**: This statement is incorrect. The naive bootstrap *ignores* the effect of positive autocorrelation, leading to an *underestimation* of the true variance, which results in CIs that are too **narrow** (anti-conservative), not too wide.\n*   **Verdict**: **Incorrect**.\n\n**B. Diagnosis: Examine the ACF of $\\{y_t\\}$ and, after removing drift via regression on $t$, the ACF and portmanteau tests of the residuals $\\{\\hat{\\epsilon}_t\\}$. Remedy: Remove drift to target $\\mu$, then apply a moving block bootstrap to $\\{\\hat{\\epsilon}_t\\}$ with an empirically chosen block length, reconstructing series as $\\hat{\\mu} + \\hat{f}(t) + \\text{bootstrapped residuals}$. Expected failure: The naive IID bootstrap will be anti-conservative, yielding CIs that are too narrow due to unmodeled positive autocorrelation and may be centered on a time-averaged quantity rather than the stationary mean.**\n*   **Diagnosis**: This is the correct diagnostic procedure. The ACF identifies dependence, and checking the residuals after de-trending correctly isolates the dependence structure of the noise process $\\{\\epsilon_t\\}$.\n*   **Remedy**: This is the appropriate remedy. It correctly addresses both problems: first removing the drift to correctly target $\\mu$, and then using a moving block bootstrap on the residuals to account for their serial correlation. The description of reconstructing the series is a valid method for a regression bootstrap.\n*   **Expected Failure**: This correctly identifies the two primary failure modes derived above: the CI is anti-conservative (too narrow) due to ignoring positive autocorrelation, and it is incorrectly centered due to the unmodeled drift.\n*   **Verdict**: **Correct**.\n\n**C. Diagnosis: Inspect histogram symmetry of $\\{y_t\\}$ to confirm approximate Gaussianity. Remedy: Use a Studentized bootstrap on $\\{y_t\\}$ to correct for skew. Expected failure: The naive IID bootstrap mainly fails by producing asymmetric CIs; coverage remains approximately correct.**\n*   **Diagnosis**: Similar to A, this focuses on the marginal distribution shape, which is not the critical issue here. The critical issues are drift and dependence.\n*   **Remedy**: A Studentized bootstrap can improve second-order accuracy of CIs but does not, by itself, correct for serial correlation or non-stationarity. Applying it to the original, non-stationary, correlated series $\\{y_t\\}$ would not solve the fundamental problems.\n*   **Expected Failure**: The description of the failure is flawed. The main failure is poor coverage (anti-conservatism), not just asymmetry. The claim that coverage \"remains approximately correct\" is false in the presence of significant positive autocorrelation.\n*   **Verdict**: **Incorrect**.\n\n**D. Diagnosis: Compute the cross-correlation at lag $0$ between adjacent trials across experimental conditions to check independence. Remedy: Stratify bootstrap resampling by deciles of $y_t$ to preserve the marginal distribution. Expected failure: The naive IID bootstrap will remain centered correctly but will overestimate variance and produce too wide CIs because of non-identical distributions across time.**\n*   **Diagnosis**: The phrasing is confusing. What is likely meant is the autocorrelation at lag $1$. The standard tool is the ACF over a range of lags.\n*   **Remedy**: Stratified resampling is inappropriate here. It is used for data from discrete subpopulations, not for data with a continuous trend over time. Stratifying by the value of $y_t$ does not address the temporal structure of the data.\n*   **Expected Failure**: This description is incorrect on multiple points. The CI will *not* be centered correctly due to the drift. The IID bootstrap will *underestimate*, not overestimate, the variance in the presence of positive autocorrelation, leading to CIs that are too narrow, not too wide.\n*   **Verdict**: **Incorrect**.",
            "answer": "$$\\boxed{B}$$"
        }
    ]
}