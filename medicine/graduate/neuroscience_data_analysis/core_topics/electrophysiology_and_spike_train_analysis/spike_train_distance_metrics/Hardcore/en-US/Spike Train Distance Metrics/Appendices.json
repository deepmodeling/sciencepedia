{
    "hands_on_practices": [
        {
            "introduction": "The Victor-Purpura distance is a foundational metric that quantifies dissimilarity by calculating the minimum \"cost\" to transform one spike train into another. This exercise takes you beyond simply using the metric and into its computational core by deriving the dynamic programming algorithm that makes it possible. Understanding this algorithm provides deep insight into how the metric precisely balances the cost of shifting a spike's timing against the cost of treating it as an independent event .",
            "id": "4194680",
            "problem": "You are given two single-neuron spike trains $S_1$ and $S_2$ observed over milliseconds, represented as ordered event times $S_1 = (0, 10, 20)~\\mathrm{ms}$ and $S_2 = (5, 12, 22)~\\mathrm{ms}$. Consider the Victor–Purpura (VP) spike train distance, which is defined as the minimal total cost over sequences of allowed editing operations that transform one spike train into another, where an insertion of a spike has cost $1$, a deletion of a spike has cost $1$, and a continuous time shift of a single spike by $\\Delta t$ has cost $q\\,|\\Delta t|$. Here $q = 0.1~\\mathrm{ms}^{-1}$.\n\nStarting from these core definitions and the well-established principle that dynamic programming solves optimal sequence alignment problems by exploiting optimal substructure and overlapping subproblems, do the following:\n\n1. Derive a dynamic programming recurrence for the Victor–Purpura distance $d_{\\mathrm{VP}}(S_1, S_2)$ between two finite spike trains $S_1 = (t_1,\\dots,t_m)$ and $S_2 = (u_1,\\dots,u_n)$ that is consistent with the above operation set and costs. Your derivation must start from the definition of $d_{\\mathrm{VP}}$ as a minimal-cost transformation and justify the recurrence via optimal substructure without assuming any pre-existing closed-form alignment formulas.\n2. Use your recurrence to compute $d_{\\mathrm{VP}}(S_1, S_2)$ for the specific trains $S_1 = (0, 10, 20)~\\mathrm{ms}$ and $S_2 = (5, 12, 22)~\\mathrm{ms}$ with $q = 0.1~\\mathrm{ms}^{-1}$, showing all intermediate quantities that support the final value.\n\nExpress the final answer as a single real number without units. No rounding is required.",
            "solution": "The problem is well-posed, scientifically grounded, and provides all necessary information to derive the required recurrence and compute the specified distance. We proceed with the two-part solution.\n\n### Part 1: Derivation of the Dynamic Programming Recurrence\n\nThe Victor-Purpura (VP) distance, $d_{\\mathrm{VP}}(S_1, S_2)$, between two spike trains $S_1 = (t_1, \\dots, t_m)$ and $S_2 = (u_1, \\dots, u_n)$ is the minimum total cost to transform $S_1$ into $S_2$ using a set of allowed operations. This problem has an optimal substructure, making it amenable to a dynamic programming solution.\n\nLet us define a subproblem. Let $S_{1,i} = (t_1, \\dots, t_i)$ be the prefix of $S_1$ containing its first $i$ spikes, and $S_{2,j} = (u_1, \\dots, u_j)$ be the prefix of $S_2$ with its first $j$ spikes. We define $D(i, j)$ as the VP distance between these prefixes: $D(i, j) = d_{\\mathrm{VP}}(S_{1,i}, S_{2,j})$. Our goal is to compute $D(m, n)$.\n\nThe solution is built upon a matrix of costs $D$ of size $(m+1) \\times (n+1)$, where the indices $i$ range from $0$ to $m$ and $j$ from $0$ to $n$.\n\n**Base Cases:**\nThe cost of transforming an empty spike train into another is determined by the number of insertions or deletions required.\n1. The distance between two empty spike trains is zero:\n$$D(0, 0) = 0$$\n2. To transform a spike train $S_{1,i}$ with $i$ spikes into an empty train, we must delete all $i$ spikes. Each deletion has a cost of $1$. Therefore, the total cost is $i$:\n$$D(i, 0) = i \\quad \\text{for } i > 0$$\n3. To transform an empty spike train into a spike train $S_{2,j}$ with $j$ spikes, we must insert all $j$ spikes. Each insertion has a cost of $1$. Therefore, the total cost is $j$:\n$$D(0, j) = j \\quad \\text{for } j > 0$$\n\n**Recurrence Relation:**\nFor the general case $D(i, j)$ with $i > 0$ and $j > 0$, we consider the transformation of $S_{1,i}$ to $S_{2,j}$. The principle of optimal substructure states that the optimal (minimum cost) path to compute $D(i, j)$ must be built upon optimal solutions to smaller subproblems. The final operation in the sequence of transformations must involve the last spikes, $t_i$ and $u_j$. There are three possibilities for the final step:\n\n1.  **Deletion:** The spike $t_i$ is deleted from $S_{1,i}$. The cost of this operation is $1$. The remaining problem is to transform the prefix $S_{1, i-1}$ into $S_{2,j}$. The minimum cost for this subproblem is, by definition, $D(i-1, j)$. Thus, the total cost via this path is $D(i-1, j) + 1$.\n\n2.  **Insertion:** The spike $u_j$ is inserted. This means we have optimally transformed $S_{1,i}$ into $S_{2, j-1}$ and then we perform the final insertion of $u_j$. The cost of insertion is $1$. The cost of the preceding subproblem is $D(i, j-1)$. Thus, the total cost via this path is $D(i, j-1) + 1$.\n\n3.  **Shift (or Match):** The spike $t_i$ is considered to correspond to the spike $u_j$. This is modeled as shifting $t_i$ to the time of $u_j$. The cost of this operation is $q|t_i - u_j|$. The remaining problem is to transform the prefix $S_{1, i-1}$ into $S_{2, j-1}$, which has a minimum cost of $D(i-1, j-1)$. Thus, the total cost via this path is $D(i-1, j-1) + q|t_i - u_j|$.\n\nThe VP distance $D(i, j)$ is the minimum of the costs of these three mutually exclusive final operations. This gives the recurrence relation:\n$$D(i, j) = \\min\\left( D(i-1, j) + 1, \\quad D(i, j-1) + 1, \\quad D(i-1, j-1) + q|t_i - u_j| \\right)$$\nThis recurrence relation, along with the base cases, allows for the systematic computation of the entire cost matrix $D$, with the final answer being $D(m, n)$.\n\n### Part 2: Computation for the Specific Spike Trains\n\nWe are given:\n- Spike train $S_1 = (t_1, t_2, t_3) = (0, 10, 20)~\\mathrm{ms}$. Thus, $m = 3$.\n- Spike train $S_2 = (u_1, u_2, u_3) = (5, 12, 22)~\\mathrm{ms}$. Thus, $n = 3$.\n- Cost parameter $q = 0.1~\\mathrm{ms}^{-1}$.\n\nWe will compute the $4 \\times 4$ matrix $D(i, j)$ for $i, j \\in \\{0, 1, 2, 3\\}$.\n\n**Initialization (Base Cases):**\n$D(0, 0) = 0$.\n$D(i, 0) = i$:\n$D(1, 0) = 1$\n$D(2, 0) = 2$\n$D(3, 0) = 3$\n\n$D(0, j) = j$:\n$D(0, 1) = 1$\n$D(0, 2) = 2$\n$D(0, 3) = 3$\n\nThe initial matrix is:\n$$\nD = \\begin{pmatrix}\n0 & 1 & 2 & 3 \\\\\n1 & ? & ? & ? \\\\\n2 & ? & ? & ? \\\\\n3 & ? & ? & ?\n\\end{pmatrix}\n$$\n\n**Filling the matrix:**\nWe compute the remaining elements row by row.\n\n- **$D(1, 1)$:** Using $t_1=0, u_1=5$:\n$$ D(1, 1) = \\min(D(0, 1)+1, D(1, 0)+1, D(0, 0) + q|t_1-u_1|) $$\n$$ D(1, 1) = \\min(1+1, 1+1, 0 + 0.1|0-5|) = \\min(2, 2, 0.5) = 0.5 $$\n\n- **$D(1, 2)$:** Using $t_1=0, u_2=12$:\n$$ D(1, 2) = \\min(D(0, 2)+1, D(1, 1)+1, D(0, 1) + q|t_1-u_2|) $$\n$$ D(1, 2) = \\min(2+1, 0.5+1, 1 + 0.1|0-12|) = \\min(3, 1.5, 1+1.2) = \\min(3, 1.5, 2.2) = 1.5 $$\n\n- **$D(1, 3)$:** Using $t_1=0, u_3=22$:\n$$ D(1, 3) = \\min(D(0, 3)+1, D(1, 2)+1, D(0, 2) + q|t_1-u_3|) $$\n$$ D(1, 3) = \\min(3+1, 1.5+1, 2 + 0.1|0-22|) = \\min(4, 2.5, 2+2.2) = \\min(4, 2.5, 4.2) = 2.5 $$\n\n- **$D(2, 1)$:** Using $t_2=10, u_1=5$:\n$$ D(2, 1) = \\min(D(1, 1)+1, D(2, 0)+1, D(1, 0) + q|t_2-u_1|) $$\n$$ D(2, 1) = \\min(0.5+1, 2+1, 1 + 0.1|10-5|) = \\min(1.5, 3, 1+0.5) = \\min(1.5, 3, 1.5) = 1.5 $$\n\n- **$D(2, 2)$:** Using $t_2=10, u_2=12$:\n$$ D(2, 2) = \\min(D(1, 2)+1, D(2, 1)+1, D(1, 1) + q|t_2-u_2|) $$\n$$ D(2, 2) = \\min(1.5+1, 1.5+1, 0.5 + 0.1|10-12|) = \\min(2.5, 2.5, 0.5+0.2) = \\min(2.5, 2.5, 0.7) = 0.7 $$\n\n- **$D(2, 3)$:** Using $t_2=10, u_3=22$:\n$$ D(2, 3) = \\min(D(1, 3)+1, D(2, 2)+1, D(1, 2) + q|t_2-u_3|) $$\n$$ D(2, 3) = \\min(2.5+1, 0.7+1, 1.5 + 0.1|10-22|) = \\min(3.5, 1.7, 1.5+1.2) = \\min(3.5, 1.7, 2.7) = 1.7 $$\n\n- **$D(3, 1)$:** Using $t_3=20, u_1=5$:\n$$ D(3, 1) = \\min(D(2, 1)+1, D(3, 0)+1, D(2, 0) + q|t_3-u_1|) $$\n$$ D(3, 1) = \\min(1.5+1, 3+1, 2 + 0.1|20-5|) = \\min(2.5, 4, 2+1.5) = \\min(2.5, 4, 3.5) = 2.5 $$\n\n- **$D(3, 2)$:** Using $t_3=20, u_2=12$:\n$$ D(3, 2) = \\min(D(2, 2)+1, D(3, 1)+1, D(2, 1) + q|t_3-u_2|) $$\n$$ D(3, 2) = \\min(0.7+1, 2.5+1, 1.5 + 0.1|20-12|) = \\min(1.7, 3.5, 1.5+0.8) = \\min(1.7, 3.5, 2.3) = 1.7 $$\n\n- **$D(3, 3)$:** Using $t_3=20, u_3=22$:\n$$ D(3, 3) = \\min(D(2, 3)+1, D(3, 2)+1, D(2, 2) + q|t_3-u_3|) $$\n$$ D(3, 3) = \\min(1.7+1, 1.7+1, 0.7 + 0.1|20-22|) = \\min(2.7, 2.7, 0.7+0.2) = \\min(2.7, 2.7, 0.9) = 0.9 $$\n\nThe final filled cost matrix is:\n$$\nD = \\begin{pmatrix}\n0   & 1   & 2   & 3   \\\\\n1   & 0.5 & 1.5 & 2.5 \\\\\n2   & 1.5 & 0.7 & 1.7 \\\\\n3   & 2.5 & 1.7 & 0.9\n\\end{pmatrix}\n$$\nThe Victor-Purpura distance between $S_1$ and $S_2$ is the value in the bottom-right corner of the matrix, $D(3, 3)$.\n$$ d_{\\mathrm{VP}}(S_1, S_2) = D(3, 3) = 0.9 $$",
            "answer": "$$\n\\boxed{0.9}\n$$"
        },
        {
            "introduction": "In contrast to the edit-based approach of the Victor-Purpura metric, the van Rossum distance operates by first transforming discrete spike trains into continuous signals. This practice focuses on deriving the standard analytical formula for the van Rossum distance from its definition based on signal convolution and the $L_2$ norm . Mastering this derivation is key to understanding how the choice of the time constant, $\\tau$, determines the temporal scale at which the metric is sensitive to spike timing differences.",
            "id": "4194684",
            "problem": "Consider two spike trains represented as sums of Dirac delta distributions, $s_{1}(t)=\\sum_{i=1}^{N_{1}}\\delta\\!\\left(t-t_{i}\\right)$ and $s_{2}(t)=\\sum_{j=1}^{N_{2}}\\delta\\!\\left(t-u_{j}\\right)$, where $\\delta(\\cdot)$ denotes the Dirac delta distribution and $\\{t_{i}\\}$, $\\{u_{j}\\}$ are spike times. Let the exponentially decaying kernel be $h(t)=\\exp\\!\\left(-t/\\tau\\right)H(t)$, where $H(t)$ is the Heaviside step function and $\\tau>0$ is the time constant. Define the filtered signals $x_{1}(t)=(h*s_{1})(t)$ and $x_{2}(t)=(h*s_{2})(t)$, where $*$ denotes convolution. The van Rossum (vR) distance is defined by the squared $L^{2}$ norm\n$$\nd_{\\mathrm{vR}}^{2}=\\frac{1}{\\tau}\\int_{-\\infty}^{\\infty}\\left[x_{1}(t)-x_{2}(t)\\right]^{2}\\,\\mathrm{d}t.\n$$\nStarting from these definitions and without invoking any shortcut formulas, derive a closed-form expression for $d_{\\mathrm{vR}}^{2}$ in terms of the spike times $\\{t_{i}\\}$ and $\\{u_{j}\\}$ and pairwise exponential overlaps. Then, evaluate $d_{\\mathrm{vR}}^{2}$ for the spike trains $S_{1}=\\{0,10\\}$ ms and $S_{2}=\\{5,12\\}$ ms with $\\tau=5$ ms. Express the final numerical value as a dimensionless number and round your answer to four significant figures.",
            "solution": "The problem asks for the derivation of a closed-form expression for the van Rossum distance, $d_{\\mathrm{vR}}^{2}$, and its subsequent evaluation for two specific spike trains.\n\n### Step 1: Problem Validation\nThe problem statement provides the following givens:\n- Spike train 1: $s_{1}(t)=\\sum_{i=1}^{N_{1}}\\delta(t-t_{i})$.\n- Spike train 2: $s_{2}(t)=\\sum_{j=1}^{N_{2}}\\delta(t-u_{j})$.\n- Exponential kernel: $h(t)=\\exp(-t/\\tau)H(t)$, with $\\tau>0$. $H(t)$ is the Heaviside step function.\n- Filtered signals: $x_{1}(t)=(h*s_{1})(t)$ and $x_{2}(t)=(h*s_{2})(t)$, where $*$ is convolution.\n- Definition of van Rossum distance squared: $d_{\\mathrm{vR}}^{2}=\\frac{1}{\\tau}\\int_{-\\infty}^{\\infty}\\left[x_{1}(t)-x_{2}(t)\\right]^{2}\\,\\mathrm{d}t$.\n- Specific spike trains for evaluation: $S_{1}=\\{0,10\\}$ ms and $S_{2}=\\{5,12\\}$ ms.\n- Specific time constant: $\\tau=5$ ms.\n\nThe problem is scientifically grounded, well-posed, and objective. It is based on standard definitions from computational neuroscience and mathematics. All necessary information is provided, and there are no contradictions. The problem is valid.\n\n### Step 2: Derivation of the Closed-Form Expression\n\nThe squared van Rossum distance is given by\n$$\nd_{\\mathrm{vR}}^{2}=\\frac{1}{\\tau}\\int_{-\\infty}^{\\infty}\\left[x_{1}(t)-x_{2}(t)\\right]^{2}\\,\\mathrm{d}t\n$$\nExpanding the square in the integrand gives\n$$\nd_{\\mathrm{vR}}^{2} = \\frac{1}{\\tau}\\left(\\int_{-\\infty}^{\\infty} x_1(t)^2 \\,\\mathrm{d}t - 2\\int_{-\\infty}^{\\infty} x_1(t)x_2(t) \\,\\mathrm{d}t + \\int_{-\\infty}^{\\infty} x_2(t)^2 \\,\\mathrm{d}t\\right)\n$$\nFirst, we express the filtered signals $x_1(t)$ and $x_2(t)$ explicitly. The convolution of the kernel $h(t)$ with a spike train $s(t) = \\sum_k \\delta(t-t_k)$ is\n$$\n(h*s)(t) = \\int_{-\\infty}^{\\infty} h(t-t') \\sum_k \\delta(t'-t_k) \\,\\mathrm{d}t' = \\sum_k h(t-t_k)\n$$\nUsing the given kernel $h(t)=\\exp(-t/\\tau)H(t)$, the filtered signals are\n$$\nx_{1}(t) = \\sum_{i=1}^{N_1} \\exp\\left(-\\frac{t-t_i}{\\tau}\\right) H(t-t_i)\n$$\n$$\nx_{2}(t) = \\sum_{j=1}^{N_2} \\exp\\left(-\\frac{t-u_j}{\\tau}\\right) H(t-u_j)\n$$\nNow, let's compute the integrals. We start with the cross-term integral, $\\int_{-\\infty}^{\\infty} x_1(t)x_2(t) \\,\\mathrm{d}t$.\n\\begin{align*}\n\\int_{-\\infty}^{\\infty} x_1(t)x_2(t) \\,\\mathrm{d}t &= \\int_{-\\infty}^{\\infty} \\left(\\sum_{i=1}^{N_1} h(t-t_i)\\right) \\left(\\sum_{j=1}^{N_2} h(t-u_j)\\right) \\,\\mathrm{d}t \\\\\n&= \\sum_{i=1}^{N_1} \\sum_{j=1}^{N_2} \\int_{-\\infty}^{\\infty} h(t-t_i) h(t-u_j) \\,\\mathrm{d}t\n\\end{align*}\nLet's evaluate the inner integral for a pair of spikes $(t_i, u_j)$:\n$$\n\\int_{-\\infty}^{\\infty} \\exp\\left(-\\frac{t-t_i}{\\tau}\\right)H(t-t_i) \\exp\\left(-\\frac{t-u_j}{\\tau}\\right)H(t-u_j) \\,\\mathrm{d}t\n$$\nThe product of Heaviside functions $H(t-t_i)H(t-u_j)$ is non-zero only when $t \\ge t_i$ and $t \\ge u_j$, which means $t \\ge \\max(t_i, u_j)$. Let $t_{\\max} = \\max(t_i, u_j)$. The integral becomes:\n\\begin{align*}\n\\int_{t_{\\max}}^{\\infty} \\exp\\left(-\\frac{t-t_i}{\\tau} - \\frac{t-u_j}{\\tau}\\right) \\,\\mathrm{d}t &= \\exp\\left(\\frac{t_i+u_j}{\\tau}\\right) \\int_{t_{\\max}}^{\\infty} \\exp\\left(-\\frac{2t}{\\tau}\\right) \\,\\mathrm{d}t \\\\\n&= \\exp\\left(\\frac{t_i+u_j}{\\tau}\\right) \\left[-\\frac{\\tau}{2}\\exp\\left(-\\frac{2t}{\\tau}\\right)\\right]_{t_{\\max}}^{\\infty} \\\\\n&= \\exp\\left(\\frac{t_i+u_j}{\\tau}\\right) \\left(0 - \\left(-\\frac{\\tau}{2}\\exp\\left(-\\frac{2t_{\\max}}{\\tau}\\right)\\right)\\right) \\\\\n&= \\frac{\\tau}{2}\\exp\\left(\\frac{t_i+u_j-2t_{\\max}}{\\tau}\\right)\n\\end{align*}\nIf $t_i \\ge u_j$, then $t_{\\max} = t_i$, and the exponent is $(t_i+u_j-2t_i)/\\tau = (u_j-t_i)/\\tau = -|t_i-u_j|/\\tau$.\nIf $u_j > t_i$, then $t_{\\max} = u_j$, and the exponent is $(t_i+u_j-2u_j)/\\tau = (t_i-u_j)/\\tau = -|t_i-u_j|/\\tau$.\nIn both cases, the result is $\\frac{\\tau}{2}\\exp\\left(-\\frac{|t_i-u_j|}{\\tau}\\right)$.\nThus, the cross-term integral is\n$$\n\\int_{-\\infty}^{\\infty} x_1(t)x_2(t) \\,\\mathrm{d}t = \\sum_{i=1}^{N_1} \\sum_{j=1}^{N_2} \\frac{\\tau}{2}\\exp\\left(-\\frac{|t_i-u_j|}{\\tau}\\right)\n$$\nBy replacing $s_2$ with $s_1$ (i.e., $u_j \\to t_k$, $N_2 \\to N_1$), we find the self-term integral $\\int x_1(t)^2 \\,\\mathrm{d}t$:\n$$\n\\int_{-\\infty}^{\\infty} x_1(t)^2 \\,\\mathrm{d}t = \\sum_{i=1}^{N_1} \\sum_{k=1}^{N_1} \\frac{\\tau}{2}\\exp\\left(-\\frac{|t_i-t_k|}{\\tau}\\right)\n$$\nSimilarly, for $x_2(t)$:\n$$\n\\int_{-\\infty}^{\\infty} x_2(t)^2 \\,\\mathrm{d}t = \\sum_{j=1}^{N_2} \\sum_{l=1}^{N_2} \\frac{\\tau}{2}\\exp\\left(-\\frac{|u_j-u_l|}{\\tau}\\right)\n$$\nSubstituting these back into the expression for $d_{\\mathrm{vR}}^{2}$:\n\\begin{align*}\nd_{\\mathrm{vR}}^{2} &= \\frac{1}{\\tau} \\left[ \\sum_{i,k} \\frac{\\tau}{2}\\exp\\left(-\\frac{|t_i-t_k|}{\\tau}\\right) - 2\\sum_{i,j} \\frac{\\tau}{2}\\exp\\left(-\\frac{|t_i-u_j|}{\\tau}\\right) + \\sum_{j,l} \\frac{\\tau}{2}\\exp\\left(-\\frac{|u_j-u_l|}{\\tau}\\right) \\right] \\\\\n&= \\frac{1}{2} \\left[ \\sum_{i=1}^{N_1}\\sum_{k=1}^{N_1} \\exp\\left(-\\frac{|t_i-t_k|}{\\tau}\\right) - 2\\sum_{i=1}^{N_1}\\sum_{j=1}^{N_2} \\exp\\left(-\\frac{|t_i-u_j|}{\\tau}\\right) + \\sum_{j=1}^{N_2}\\sum_{l=1}^{N_2} \\exp\\left(-\\frac{|u_j-u_l|}{\\tau}\\right) \\right]\n\\end{align*}\nThis is the required closed-form expression.\n\n### Step 3: Numerical Evaluation\n\nWe are given $S_{1}=\\{t_1, t_2\\}=\\{0, 10\\}$ ms, $S_{2}=\\{u_1, u_2\\}=\\{5, 12\\}$ ms, and $\\tau=5$ ms. The ratios like $|t_i-u_j|/\\tau$ are dimensionless.\n\nLet's compute the three terms in the expression for $d_{\\mathrm{vR}}^{2}$:\n1.  The first term (interaction within $S_1$):\n\\begin{align*}\n\\sum_{i=1}^{2}\\sum_{k=1}^{2} \\exp\\left(-\\frac{|t_i-t_k|}{\\tau}\\right) &= \\exp\\left(-\\frac{|0-0|}{5}\\right) + \\exp\\left(-\\frac{|0-10|}{5}\\right) + \\exp\\left(-\\frac{|10-0|}{5}\\right) + \\exp\\left(-\\frac{|10-10|}{5}\\right) \\\\\n&= \\exp(0) + \\exp(-2) + \\exp(-2) + \\exp(0) = 2 + 2\\exp(-2)\n\\end{align*}\n2.  The second term (cross-interaction between $S_1$ and $S_2$):\n\\begin{align*}\n-2\\sum_{i=1}^{2}\\sum_{j=1}^{2} \\exp\\left(-\\frac{|t_i-u_j|}{\\tau}\\right) &= -2 \\left[ \\exp\\left(-\\frac{|0-5|}{5}\\right) + \\exp\\left(-\\frac{|0-12|}{5}\\right) + \\exp\\left(-\\frac{|10-5|}{5}\\right) + \\exp\\left(-\\frac{|10-12|}{5}\\right) \\right] \\\\\n&= -2 \\left[ \\exp(-1) + \\exp(-2.4) + \\exp(-1) + \\exp(-0.4) \\right] \\\\\n&= -4\\exp(-1) - 2\\exp(-2.4) - 2\\exp(-0.4)\n\\end{align*}\n3.  The third term (interaction within $S_2$):\n\\begin{align*}\n\\sum_{j=1}^{2}\\sum_{l=1}^{2} \\exp\\left(-\\frac{|u_j-u_l|}{\\tau}\\right) &= \\exp\\left(-\\frac{|5-5|}{5}\\right) + \\exp\\left(-\\frac{|5-12|}{5}\\right) + \\exp\\left(-\\frac{|12-5|}{5}\\right) + \\exp\\left(-\\frac{|12-12|}{5}\\right) \\\\\n&= \\exp(0) + \\exp(-1.4) + \\exp(-1.4) + \\exp(0) = 2 + 2\\exp(-1.4)\n\\end{align*}\nCombining these terms into the expression for $d_{\\mathrm{vR}}^{2}$:\n\\begin{align*}\nd_{\\mathrm{vR}}^{2} &= \\frac{1}{2} \\left[ (2 + 2\\exp(-2)) + (-4\\exp(-1) - 2\\exp(-2.4) - 2\\exp(-0.4)) + (2 + 2\\exp(-1.4)) \\right] \\\\\n&= (1 + \\exp(-2)) - (2\\exp(-1) + \\exp(-2.4) + \\exp(-0.4)) + (1 + \\exp(-1.4)) \\\\\n&= 2 + \\exp(-2) + \\exp(-1.4) - 2\\exp(-1) - \\exp(-2.4) - \\exp(-0.4)\n\\end{align*}\nNow, we substitute the numerical values of the exponential functions:\n$\\exp(-1) \\approx 0.367879$\n$\\exp(-2) \\approx 0.135335$\n$\\exp(-0.4) \\approx 0.670320$\n$\\exp(-1.4) \\approx 0.246597$\n$\\exp(-2.4) \\approx 0.090718$\n\n\\begin{align*}\nd_{\\mathrm{vR}}^{2} &\\approx 2 + 0.135335 + 0.246597 - 2(0.367879) - 0.090718 - 0.670320 \\\\\n&\\approx 2.381932 - 0.735758 - 0.090718 - 0.670320 \\\\\n&\\approx 2.381932 - 1.496796 \\\\\n&\\approx 0.885136\n\\end{align*}\nRounding to four significant figures, we get $0.8851$.",
            "answer": "$$\\boxed{0.8851}$$"
        },
        {
            "introduction": "After building the Victor-Purpura and van Rossum metrics from their foundations, it is crucial to understand their practical implications and differing sensitivities. This exercise presents a scenario where these two metrics produce conflicting similarity rankings for the same set of spike trains . By working through this example, you will gain a hands-on appreciation for how the choice of metric and its parameters can fundamentally shape conclusions about neural coding.",
            "id": "4194658",
            "problem": "You are given finite spike trains represented as ordered lists of event times in seconds. Consider a fixed reference spike train and three candidate spike trains. Your task is to compute, for each candidate, two distances to the reference: the Victor–Purpura distance and the van Rossum distance. Then, for each specified parameter regime, rank the three candidates by increasing distance to the reference under each metric and report the rankings. You must implement each metric from its core definition without invoking any unproven shortcuts.\n\nDefinitions and requirements:\n- A spike train is a finite, ordered sequence of times in seconds, denoted by $T=\\{t_1,\\dots,t_n\\}$ with $t_i \\in \\mathbb{R}$ and $t_1 \\le t_2 \\le \\cdots \\le t_n$.\n- Victor–Purpura distance $d_{\\mathrm{VP}}$: This distance is the minimum total cost to transform one spike train into another via a sequence of the following elementary operations: delete a spike (cost $1$), insert a spike (cost $1$), and shift a spike in time by $\\Delta t$ (cost $q|\\Delta t|$), where $q>0$ is a tunable parameter with units of $\\mathrm{s}^{-1}$. A single spike move must never exceed the total cost of deleting and reinserting that spike. All times must be treated in seconds.\n- van Rossum distance $d_{\\mathrm{vR}}$: This distance is the Euclidean norm of the difference between two filtered spike trains, where the filter is the causal exponential kernel with decay time constant $\\tau>0$ (in seconds). The kernel is nonzero only for positive time lags and decays exponentially, and both spike trains are convolved with this kernel before computing the Euclidean norm. All times must be treated in seconds. The computation must be mathematically exact for finite spike trains.\n\nRanking and tie-breaking:\n- For each metric and each parameter regime, compute the distances from the reference train to the three candidate trains. Rank the three candidates by increasing distance. If two distances are equal to within a numerical tolerance of $\\varepsilon=10^{-12}$, break ties by ascending candidate label index (defined below).\n\nSpike trains (times in seconds):\n- Reference train $R = [0.10, 0.30, 0.50, 0.70]$.\n- Candidate $A = [0.10, 0.30, 0.50, 0.72]$.\n- Candidate $B = [0.10, 0.33, 0.50, 0.70]$.\n- Candidate $C = [0.10, 0.30, 0.50]$.\n\nLabel indices:\n- Use integer labels $0,1,2$ to denote candidates $A,B,C$, respectively.\n\nTest suite (parameter regimes):\n- Case $1$: $q=200$ (in $\\mathrm{s}^{-1}$), $\\tau=0.05$ (in $\\mathrm{s}$).\n- Case $2$: $q=0$ (in $\\mathrm{s}^{-1}$), $\\tau=0.005$ (in $\\mathrm{s}$).\n- Case $3$: $q=5$ (in $\\mathrm{s}^{-1}$), $\\tau=0.20$ (in $\\mathrm{s}$).\n\nOutput specification:\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets. The list must contain, in order, the Victor–Purpura ranking for Case $1$, the van Rossum ranking for Case $1$, the Victor–Purpura ranking for Case $2$, the van Rossum ranking for Case $2$, the Victor–Purpura ranking for Case $3$, and the van Rossum ranking for Case $3$. Each ranking must itself be a list of the three candidate labels $[0,1,2]$ sorted from most similar (smallest distance) to least similar (largest distance). For example, a valid output structure is $[[0,2,1],[0,1,2],[\\dots],[\\dots],[\\dots],[\\dots]]$ with no spaces.",
            "solution": "The problem requires the computation and comparison of two distinct spike train distance metrics, the Victor–Purpura distance ($d_{\\mathrm{VP}}$) and the van Rossum distance ($d_{\\mathrm{vR}}$), for three candidate spike trains relative to a reference train. The analysis is performed under three different parameter regimes. The a priori validation confirms the problem is scientifically grounded, well-posed, objective, and contains all necessary information for a unique solution.\n\nLet the reference spike train be $R = \\{r_1, \\dots, r_{n_R}\\}$ and a candidate spike train be $X = \\{x_1, \\dots, x_{n_X}\\}$.\n\n**Victor–Purpura Distance ($d_{\\mathrm{VP}}$)**\n\nThe Victor–Purpura distance is a metric based on the minimum cost required to transform one spike train into another. The elementary operations and their associated costs are:\n1.  **Insertion** of a spike: cost of $1$.\n2.  **Deletion** of a spike: cost of $1$.\n3.  **Shifting** a spike from time $t_a$ to $t_b$: cost of $q|t_a - t_b|$, where $q$ is a parameter with units of $\\mathrm{s}^{-1}$.\n\nThis minimal cost can be efficiently computed using a dynamic programming algorithm, analogous to the calculation of Levenshtein distance for strings. Let $T_1 = \\{t_1, \\dots, t_m\\}$ and $T_2 = \\{t'_1, \\dots, t'_n\\}$ be two spike trains. We construct a matrix $D$ of size $(m+1) \\times (n+1)$, where $D(i, j)$ stores the minimum cost to transform the first $i$ spikes of $T_1$ into the first $j$ spikes of $T_2$.\n\nThe matrix is initialized as follows:\n-   $D(0, 0) = 0$: The cost of transforming an empty train to an empty train is $0$.\n-   $D(i, 0) = i$ for $i > 0$: The cost of transforming the first $i$ spikes of $T_1$ to an empty train is the cost of $i$ deletions.\n-   $D(0, j) = j$ for $j > 0$: The cost of transforming an empty train to the first $j$ spikes of $T_2$ is the cost of $j$ insertions.\n\nThe matrix is then filled using the following recurrence relation for $i>0$ and $j>0$:\n$$\nD(i, j) = \\min \\left( D(i-1, j) + 1, \\quad D(i, j-1) + 1, \\quad D(i-1, j-1) + q|t_i - t'_j| \\right)\n$$\nHere, the three terms correspond to:\n1.  $D(i-1, j) + 1$: Deleting spike $t_i$ from $T_1$.\n2.  $D(i, j-1) + 1$: Inserting spike $t'_j$ into the transformed train.\n3.  $D(i-1, j-1) + q|t_i - t'_j|$: Shifting spike $t_i$ to match spike $t'_j$.\n\nThe final distance $d_{\\mathrm{VP}}(T_1, T_2)$ is given by the element $D(m, n)$. The problem's constraint that a spike move must not exceed the cost of deletion and re-insertion (a cost of $2$) is naturally handled by the `min` operation in the recurrence. If $q|t_i - t'_j| > 2$, the algorithm will prefer a path corresponding to a deletion and an insertion over the costly shift.\n\nFor the special case where $q = 0$, the cost of shifting a spike is $0$. The recurrence becomes $D(i, j) = \\min(D(i-1, j) + 1, D(i, j-1) + 1, D(i-1, j-1))$. This is equivalent to finding the edit distance where substitutions are free, which simplifies to the difference in the number of spikes, i.e., $d_{\\mathrm{VP}}(T_1, T_2; q=0) = |m-n|$.\n\n**van Rossum Distance ($d_{\\mathrm{vR}}$)**\n\nThe van Rossum distance is defined as the Euclidean distance between two spike trains after they have been convolved with a smoothing kernel. The problem specifies a causal exponential kernel, which we define as $h(t) = e^{-t/\\tau}$ for $t \\ge 0$ and $h(t) = 0$ for $t < 0$. The parameter $\\tau$ is the time constant of the decay.\n\nFor a spike train $T = \\{t_1, \\dots, t_n\\}$, the filtered signal is given by:\n$$\nf_T(t) = \\sum_{i=1}^{n} h(t - t_i)\n$$\nThe squared van Rossum distance between two spike trains $T_1$ and $T_2$ is the squared $L_2$ norm of the difference of their filtered signals:\n$$\nd_{\\mathrm{vR}}(T_1, T_2)^2 = \\int_{-\\infty}^{\\infty} [f_{T_1}(t) - f_{T_2}(t)]^2 dt\n$$\nExpanding this integral yields:\n$$\nd_{\\mathrm{vR}}^2 = \\int_{-\\infty}^{\\infty} f_{T_1}(t)^2 dt + \\int_{-\\infty}^{\\infty} f_{T_2}(t)^2 dt - 2 \\int_{-\\infty}^{\\infty} f_{T_1}(t) f_{T_2}(t) dt\n$$\nThis can be expressed using inner products as $d_{\\mathrm{vR}}^2 = \\langle f_{T_1}, f_{T_1} \\rangle + \\langle f_{T_2}, f_{T_2} \\rangle - 2 \\langle f_{T_1}, f_{T_2} \\rangle$. The problem requires an exact mathematical computation, which can be achieved by deriving an analytical form for the inner product term $\\langle f_a, f_b \\rangle$.\n\nLet $T_a=\\{t_1, \\dots, t_m\\}$ and $T_b=\\{t'_1, \\dots, t'_n\\}$. The inner product is:\n$$\n\\langle f_a, f_b \\rangle = \\int_{-\\infty}^{\\infty} \\left( \\sum_{i=1}^m h(t-t_i) \\right) \\left( \\sum_{j=1}^n h(t-t'_j) \\right) dt = \\sum_{i=1}^m \\sum_{j=1}^n \\int_{-\\infty}^{\\infty} h(t-t_i)h(t-t'_j) dt\n$$\nThe integral of the product of two shifted kernels can be solved analytically:\n$$\n\\int_{-\\infty}^{\\infty} h(t-t_i)h(t-t'_j) dt = \\frac{\\tau}{2} e^{-|t_i-t'_j|/\\tau}\n$$\nSubstituting this back, we obtain a closed-form expression for the inner product:\n$$\n\\langle f_a, f_b \\rangle = \\frac{\\tau}{2} \\sum_{i=1}^m \\sum_{j=1}^n e^{-|t_i-t'_j|/\\tau}\n$$\nThe squared van Rossum distance is then computed by applying this formula to calculate the three inner product terms: $\\langle f_{T_1}, f_{T_1} \\rangle$, $\\langle f_{T_2}, f_{T_2} \\rangle$, and $\\langle f_{T_1}, f_{T_2} \\rangle$. The final distance is the square root of the result.\n\n**Ranking Procedure**\n\nFor each of the three parameter cases, the distances from the reference train $R$ to each candidate train ($A$, $B$, $C$) are computed for both metrics. The candidates, identified by their labels $0, 1, 2$, are then ranked in order of increasing distance. In cases where two distances are equal within a numerical tolerance of $\\varepsilon=10^{-12}$, the tie is broken by sorting based on the ascending label index. This procedure yields two ranked lists of labels for each parameter case.",
            "answer": "```python\nimport numpy as np\nimport math\nfrom functools import cmp_to_key\n\ndef victor_purpura_dist(t1: np.ndarray, t2: np.ndarray, q: float) -> float:\n    \"\"\"\n    Calculates the Victor-Purpura distance between two spike trains.\n\n    This function implements the dynamic programming algorithm described by\n    Victor & Purpura (1996, 1997).\n\n    Args:\n        t1: NumPy array of spike times for the first train.\n        t2: NumPy array of spike times for the second train.\n        q: Cost parameter for shifting a spike (in 1/seconds).\n\n    Returns:\n        The Victor-Purpura distance.\n    \"\"\"\n    n1 = len(t1)\n    n2 = len(t2)\n\n    # Initialize DP matrix D\n    d = np.zeros((n1 + 1, n2 + 1))\n\n    # Cost of deletions\n    for i in range(1, n1 + 1):\n        d[i, 0] = i\n    \n    # Cost of insertions\n    for j in range(1, n2 + 1):\n        d[0, j] = j\n\n    # Fill the rest of the matrix\n    for i in range(1, n1 + 1):\n        for j in range(1, n2 + 1):\n            cost_shift = q * abs(t1[i - 1] - t2[j - 1])\n            d[i, j] = min(d[i - 1, j] + 1,          # Deletion\n                          d[i, j - 1] + 1,          # Insertion\n                          d[i - 1, j - 1] + cost_shift)  # Shift/Match\n\n    return d[n1, n2]\n\ndef van_rossum_dist(t1: np.ndarray, t2: np.ndarray, tau: float) -> float:\n    \"\"\"\n    Calculates the van Rossum distance between two spike trains.\n\n    This function uses the exact analytical formula derived from the\n    L2-norm of the difference of signals convolved with a causal\n    exponential kernel h(t) = exp(-t/tau) for t >= 0.\n\n    Args:\n        t1: NumPy array of spike times for the first train.\n        t2: NumPy array of spike times for the second train.\n        tau: Time constant of the exponential kernel (in seconds).\n\n    Returns:\n        The van Rossum distance.\n    \"\"\"\n    if tau <= 0:\n        raise ValueError(\"Time constant tau must be positive.\")\n\n    def inner_product(ta: np.ndarray, tb: np.ndarray) -> float:\n        # Create a matrix of all pairwise time differences\n        diff_matrix = np.abs(ta[:, np.newaxis] - tb[np.newaxis, :])\n        # Apply the kernel and sum\n        k_sum = np.sum(np.exp(-diff_matrix / tau))\n        return (tau / 2.0) * k_sum\n\n    k11 = inner_product(t1, t1)\n    k22 = inner_product(t2, t2)\n    k12 = inner_product(t1, t2)\n    \n    squared_dist = k11 + k22 - 2 * k12\n    \n    # The squared distance should be non-negative, but floating point errors\n    # can make it slightly negative.\n    return math.sqrt(max(0, squared_dist))\n\ndef solve():\n    \"\"\"\n    Main function to solve the problem: calculate distances, rank candidates,\n    and format the output.\n    \"\"\"\n    # Define spike trains (times in seconds)\n    spike_trains = {\n        \"R\": np.array([0.10, 0.30, 0.50, 0.70]), # Reference\n        \"A\": np.array([0.10, 0.30, 0.50, 0.72]), # Candidate 0\n        \"B\": np.array([0.10, 0.33, 0.50, 0.70]), # Candidate 1\n        \"C\": np.array([0.10, 0.30, 0.50])       # Candidate 2\n    }\n    candidate_keys = [\"A\", \"B\", \"C\"]\n    \n    # Define test suite (parameter regimes)\n    test_cases = [\n        {\"q\": 200.0, \"tau\": 0.05},  # Case 1\n        {\"q\": 0.0,   \"tau\": 0.005}, # Case 2\n        {\"q\": 5.0,   \"tau\": 0.20}   # Case 3\n    ]\n\n    # Tolerance for tie-breaking\n    TOLERANCE = 1e-12\n\n    # Custom comparison function for sorting with tolerance\n    def compare_items(item1, item2):\n        d1, label1 = item1\n        d2, label2 = item2\n        if abs(d1 - d2) < TOLERANCE:\n            return label1 - label2  # Break tie by label index\n        return 1 if d1 > d2 else -1\n\n    all_rankings = []\n    \n    ref_train = spike_trains[\"R\"]\n\n    for case in test_cases:\n        q_param, tau_param = case[\"q\"], case[\"tau\"]\n\n        # Calculate distances for the current case\n        distances_vp = []\n        distances_vr = []\n        for i, key in enumerate(candidate_keys):\n            candidate_train = spike_trains[key]\n            \n            dist_vp = victor_purpura_dist(ref_train, candidate_train, q_param)\n            distances_vp.append((dist_vp, i))\n\n            dist_vr = van_rossum_dist(ref_train, candidate_train, tau_param)\n            distances_vr.append((dist_vr, i))\n            \n        # Sort based on distance, with tie-breaking\n        sorted_vp = sorted(distances_vp, key=cmp_to_key(compare_items))\n        sorted_vr = sorted(distances_vr, key=cmp_to_key(compare_items))\n\n        # Extract ranked labels\n        ranking_vp = [label for dist, label in sorted_vp]\n        ranking_vr = [label for dist, label in sorted_vr]\n\n        all_rankings.append(ranking_vp)\n        all_rankings.append(ranking_vr)\n\n    # Format the final output string as specified\n    formatted_rankings = [repr(r).replace(\" \", \"\") for r in all_rankings]\n    print(f\"[{','.join(formatted_rankings)}]\")\n\nsolve()\n```"
        }
    ]
}