{
    "hands_on_practices": [
        {
            "introduction": "脉冲检测的第一步是将真实的神经信号与背景噪声区分开来。一种常见的方法是设置一个电压阈值，任何超过该阈值的信号都被视为潜在的脉冲。然而，简单的噪声估计（如标准差）对偶然出现的大幅值伪迹非常敏感，可能导致阈值设置不当。本练习介绍了一种更为稳健的噪声水平估计方法——中位数绝对偏差（Median Absolute Deviation, MAD），帮助你即使在存在伪迹的情况下也能设定一个可靠的检测阈值。",
            "id": "4194221",
            "problem": "在细胞外尖峰检测中，鲁棒的阈值设定需要对背景噪声尺度进行估计，该估计应不受偶尔出现的大振幅伪迹影响。考虑从细胞外电极以采样率 $f_{s} = 30\\,\\text{kHz}$ 记录的电压轨迹 $x(t)$。轨迹中的背景噪声被建模为一个平稳的、零均值的高斯过程，其标准差 $\\sigma$ 未知，而伪迹是稀疏且非平稳的。现已确定一个时长为 $0.5\\,\\text{ms}$ 的无伪迹区间 $I$，其中包含 $15$ 个样本。区间 $I$ 中的样本（以微伏为单位）为\n$$\n[-8,\\; 5,\\; -3,\\; 0,\\; 2,\\; -1,\\; 4,\\; -6,\\; 7,\\; -2,\\; 3,\\; -4,\\; 1,\\; -5,\\; 6]\\,\\mu\\text{V}.\n$$\n从中位数的定义、零均值高斯分布的对称性以及正态分布的累积分布函数 (CDF) 出发，推导出精确常数 $k$，使得当 $X \\sim \\mathcal{N}(0,\\sigma^{2})$ 时，有 $\\mathrm{median}(|X|) = k\\,\\sigma$。利用这个 $k$，定义一个基于在无伪迹样本上计算的中位数绝对偏差 (MAD) 的鲁棒噪声尺度估计器为\n$$\n\\hat{\\sigma} \\equiv \\frac{\\mathrm{median}(|x_{i}|)}{k}.\n$$\n根据提供的样本数值计算 $\\hat{\\sigma}$。将您的答案四舍五入到四位有效数字，并以微伏为单位表示最终值。您的最终答案必须是一个实数。",
            "solution": "在尝试解答之前，对问题陈述进行验证。\n\n### 步骤 1：提取已知条件\n-   电压轨迹：$x(t)$\n-   采样率：$f_{s} = 30\\,\\text{kHz}$\n-   背景噪声模型：平稳的、零均值的高斯过程，$X \\sim \\mathcal{N}(0, \\sigma^2)$，标准差 $\\sigma$ 未知。\n-   无伪迹区间 $I$ 的时长为 $0.5\\,\\text{ms}$。\n-   $I$ 中的样本数：$15$。\n-   $I$ 中的样本：$[-8,\\; 5,\\; -3,\\; 0,\\; 2,\\; -1,\\; 4,\\; -6,\\; 7,\\; -2,\\; 3,\\; -4,\\; 1,\\; -5,\\; 6]\\,\\mu\\text{V}$。\n-   常数 $k$ 的定义：对于 $X \\sim \\mathcal{N}(0,\\sigma^{2})$，$\\mathrm{median}(|X|) = k\\,\\sigma$。\n-   估计器的定义：$\\hat{\\sigma} \\equiv \\frac{\\mathrm{median}(|x_{i}|)}{k}$。\n-   要求输出：$\\hat{\\sigma}$ 的数值，四舍五入到四位有效数字。\n\n### 步骤 2：使用提取的已知条件进行验证\n该问题具有科学依据，提法明确且客观。\n1.  **科学合理性**：该问题描述了一种鲁棒的统计估计方法（使用中位数绝对偏差，MAD）来确定高斯噪声的尺度，这是信号处理和神经科学中的标准技术。将背景噪声建模为零均值高斯过程是一种常见且有效的近似方法。\n2.  **完整性与一致性**：所有必要信息均已提供。样本数量与采样率和区间时长一致：$(0.5 \\times 10^{-3}\\,\\text{s}) \\times (30 \\times 10^{3}\\,\\text{s}^{-1}) = 15$ 个样本，这与所提供数据点的数量相符。已知条件是自洽的。\n3.  **适定性**：该问题要求推导一个标准的统计常数，并将其应用于一个数据集。任务定义清晰，能够导出一个唯一、稳定的解。\n\n### 步骤 3：结论与行动\n该问题是**有效的**。将提供完整解答。\n\n### 常数 $k$ 的推导\n设 $X$ 是一个服从零均值高斯分布的随机变量，$X \\sim \\mathcal{N}(0, \\sigma^2)$。我们的任务是找到常数 $k$，使得 $X$ 绝对值的中位数是 $k\\sigma$。令 $Y = |X|$。$Y$ 的中位数，记为 $m_Y$，由性质 $P(Y \\le m_Y) = \\frac{1}{2}$ 定义。\n根据问题陈述，我们有 $m_Y = \\mathrm{median}(|X|) = k\\sigma$。将此代入中位数的定义中：\n$$\nP(|X| \\le k\\sigma) = \\frac{1}{2}\n$$\n这个不等式可以展开为：\n$$\nP(-k\\sigma \\le X \\le k\\sigma) = \\frac{1}{2}\n$$\n为了计算这个概率，我们通过定义 $Z = \\frac{X}{\\sigma}$ 来标准化随机变量 $X$。变量 $Z$ 服从标准正态分布，$Z \\sim \\mathcal{N}(0, 1)$。不等式变为：\n$$\nP(-k \\le Z \\le k) = \\frac{1}{2}\n$$\n设 $\\Phi(z)$ 为标准正态分布的累积分布函数 (CDF)，定义为 $\\Phi(z) = P(Z \\le z)$。该概率可以用 CDF 表示为：\n$$\nP(-k \\le Z \\le k) = \\Phi(k) - \\Phi(-k)\n$$\n由于标准正态分布关于 $0$ 的对称性，我们有恒等式 $\\Phi(-k) = 1 - \\Phi(k)$。将此代入方程中得到：\n$$\n\\Phi(k) - (1 - \\Phi(k)) = \\frac{1}{2}\n$$\n$$\n2\\Phi(k) - 1 = \\frac{1}{2}\n$$\n求解 $\\Phi(k)$：\n$$\n2\\Phi(k) = 1 + \\frac{1}{2} = \\frac{3}{2}\n$$\n$$\n\\Phi(k) = \\frac{3}{4} = 0.75\n$$\n因此，$k$ 是使标准正态分布的累积概率为 $0.75$ 的值。这是标准正态分布的第 $75$ 百分位数，或称第三四分位数。$k$ 的精确解析表达式是标准正态分布 CDF 在 $0.75$ 处的反函数：\n$$\nk = \\Phi^{-1}(0.75)\n$$\n至此，常数 $k$ 的推导完成。\n\n### 噪声尺度估计器 $\\hat{\\sigma}$ 的计算\n标准差 $\\sigma$ 的估计器由下式给出：\n$$\n\\hat{\\sigma} = \\frac{\\mathrm{median}(|x_{i}|)}{k}\n$$\n其中 $\\{x_i\\}$ 是所提供的电压样本。步骤如下：\n\n1.  **列出样本：**\n    给定的样本为 $x_i = [-8, 5, -3, 0, 2, -1, 4, -6, 7, -2, 3, -4, 1, -5, 6]$。单位是 $\\mu\\text{V}$。\n\n2.  **计算样本的绝对值：**\n    绝对值集合 $|x_i|$ 为 $[8, 5, 3, 0, 2, 1, 4, 6, 7, 2, 3, 4, 1, 5, 6]$。\n\n3.  **找出绝对值的中位数：**\n    首先，我们将绝对值按非递减顺序排序。排序后的列表是：\n    $$\n    [0, 1, 1, 2, 2, 3, 3, 4, 4, 5, 5, 6, 6, 7, 8]\n    $$\n    共有 $N=15$ 个样本，这是一个奇数。中位数是中间值，位于第 $\\frac{N+1}{2} = \\frac{15+1}{2} = 8$ 个位置。\n    排序后列表中的第 $8$ 个值是 $4$。因此：\n    $$\n    \\mathrm{median}(|x_i|) = 4\\,\\mu\\text{V}\n    $$\n\n4.  **计算 $\\hat{\\sigma}$：**\n    现在我们将中位数和 $k$ 的表达式代入估计器公式：\n    $$\n    \\hat{\\sigma} = \\frac{4\\,\\mu\\text{V}}{\\Phi^{-1}(0.75)}\n    $$\n    $k = \\Phi^{-1}(0.75)$ 的数值约为 $0.67448975$。\n    $$\n    \\hat{\\sigma} \\approx \\frac{4}{0.67448975}\\,\\mu\\text{V} \\approx 5.930436\\,\\mu\\text{V}\n    $$\n\n5.  **四舍五入结果：**\n    问题要求将答案四舍五入到四位有效数字。$5.930436$ 的前四位有效数字是 $5.930$。第五位数字是 $4$，因此向下取整。\n    $$\n    \\hat{\\sigma} \\approx 5.930\\,\\mu\\text{V}\n    $$\n该值代表了对背景噪声标准差的鲁棒估计。",
            "answer": "$$\n\\boxed{5.930}\n$$"
        },
        {
            "introduction": "在设定检测阈值并识别出候选脉冲后，我们如何量化检测器的性能？本练习将指导你从零开始实现并分析两个关键的性能评估工具：受试者工作特征（Receiver Operating Characteristic, ROC）曲线和精确率-召回率（Precision-Recall, PR）曲线。通过改变决策阈值，你将亲手构建这些曲线，并计算曲线下面积（AUC）来总结性能。此实践特别强调了在处理类别不平衡数据（脉冲事件通常是稀有的）时，为什么PR曲线比ROC曲线更具信息量，这在神经科学数据分析中是一个至关重要的问题。",
            "id": "4194179",
            "problem": "您将获得细胞外峰电位检测实验的检测输出，其形式为实值分数和二元真实标签，其中标签指示每个带时间戳的观测值是否对应于一个真实的峰电位事件。目标是通过在所有唯一的分数水平上扫描决策阈值，从第一性原理推导出受试者工作特征（ROC）曲线和精确率-召回率（PR）曲线，计算这些曲线下的面积，并评估在类别不平衡的情况下哪条曲线信息量更大。您必须构建一个完整的、可运行的程序，该程序在一个固定的测试套件上执行这些步骤，并以指定的格式输出所要求的指标。\n\n需要使用的基本依据和定义：\n- 给定一个由 $i \\in \\{1,\\dots,M\\}$ 索引的观测值集合，令分数为 $s_i \\in \\mathbb{R}$，真实标签为 $y_i \\in \\{0,1\\}$，其中 $y_i = 1$ 表示真实峰电位，$y_i = 0$ 表示非峰电位。\n- 对于任意决策阈值 $\\tau \\in \\mathbb{R}$，如果 $s_i \\ge \\tau$，则预测类别为 $\\hat{y}_i(\\tau) = 1$，否则为 $\\hat{y}_i(\\tau) = 0$。\n- 令 $P = \\sum_{i=1}^{M} \\mathbb{1}\\{y_i = 1\\}$ 为正例总数，$N = \\sum_{i=1}^{M} \\mathbb{1}\\{y_i = 0\\}$ 为负例总数。假设 $P \\ge 1$ 且 $N \\ge 1$。\n- 在阈值 $\\tau$ 下，根据标准定义来定义混淆矩阵的计数：真正例 $TP(\\tau)$、假正例 $FP(\\tau)$、假反例 $FN(\\tau)$ 和真反例 $TN(\\tau)$。基于这些，定义：\n  - 真正例率（也称为灵敏度或召回率）$TPR(\\tau) = \\dfrac{TP(\\tau)}{P}$。\n  - 假正例率 $FPR(\\tau) = \\dfrac{FP(\\tau)}{N}$。\n  - 精确率 $Prec(\\tau) = \\dfrac{TP(\\tau)}{TP(\\tau) + FP(\\tau)}$，当 $TP(\\tau) + FP(\\tau) \\ge 1$ 时。\n\n曲线构建要求：\n- 将ROC曲线构建为点集 $\\{(FPR(\\tau), TPR(\\tau))\\}$，该点集是通过将 $\\tau$ 在按严格降序排列的唯一分数集合 $U = \\{u_1, u_2, \\dots, u_K\\}$ 上进行扫描而获得的，并包括由 $\\tau = +\\infty$ 和 $\\tau = -\\infty$ 分别隐含的端点 $(0,0)$ 和 $(1,1)$。在每个唯一的分数水平上，所有分数相同的项必须同时被包含在预测集中。\n- 将PR曲线构建为点集 $\\{(Rec(\\tau), Prec(\\tau))\\}$，其中 $Rec(\\tau) = TPR(\\tau)$，这是在相同的降序阈值序列 $U$ 上计算的，并解释为关于召回率的右连续阶梯函数。\n\n曲线下面积定义：\n- 将ROC曲线下面积 $AUC_{\\mathrm{ROC}}$ 定义为 $TPR$ 关于 $FPR$ 在 $[0,1]$ 上的黎曼积分，通过在由ROC点按 $FPR$ 升序构成的分段线性路径上使用梯形法则进行数值计算。\n- 将PR曲线下面积 $AUC_{\\mathrm{PR}}$ 定义为 $Prec$ 关于 $Rec$ 在 $[0,1]$ 上的黎曼-斯蒂尔杰斯积分，使用右连续精确率通过阶梯式求和进行数值计算：如果 $(Rec_k, Prec_k)$是按召回率非降序排列的PR点，并且 $Rec_0 = 0$，那么\n  $$AUC_{\\mathrm{PR}} = \\sum_{k=1}^{K} (Rec_k - Rec_{k-1}) \\cdot Prec_k.$$\n\n类别不平衡下的信息量：\n- 令正例比例为 $\\pi = \\dfrac{P}{P+N}$。考虑与随机基线相比的归一化偏差：\n  - 对于ROC，随机基线是 $0.5$，因此定义 $I_{\\mathrm{ROC}} = \\dfrac{AUC_{\\mathrm{ROC}} - 0.5}{0.5}$。\n  - 对于PR，随机基线是 $\\pi$，因此定义 $I_{\\mathrm{PR}} = \\dfrac{AUC_{\\mathrm{PR}} - \\pi}{1 - \\pi}$，适用于 $\\pi \\in [0,1)$。\n- 定义布尔指示符 $B$ 来表示PR比ROC信息量更大，$B = \\mathbb{1}\\{I_{\\mathrm{PR}} > I_{\\mathrm{ROC}}\\}$。\n\n任务：\n- 实现一个程序，对于每个测试用例，通过在唯一的、严格降序的分数值上扫描阈值来构建上述ROC和PR曲线，计算 $AUC_{\\mathrm{ROC}}$ 和 $AUC_{\\mathrm{PR}}$，计算 $\\pi$、$I_{\\mathrm{ROC}}$、$I_{\\mathrm{PR}}$，然后计算 $B$。\n- 对于数值报告，将 $AUC_{\\mathrm{ROC}}$ 和 $AUC_{\\mathrm{PR}}$ 四舍五入到 $6$ 位小数。布尔值 $B$ 必须报告为字面值 $True$ 或 $False$。\n\n测试套件：\n提供以下三个测试用例，每个用例都以列表对 $(\\mathbf{s}, \\mathbf{y})$ 的形式给出，其中 $\\mathbf{s}$ 是分数，$\\mathbf{y}$ 是标签：\n- 案例1（中度可分，大致平衡）：\n  - $\\mathbf{s}^{(1)} = [\\,0.95,\\,0.90,\\,0.85,\\,0.80,\\,0.75,\\,0.70,\\,0.65,\\,0.60,\\,0.55,\\,0.50,\\,0.45,\\,0.40\\,]$\n  - $\\mathbf{y}^{(1)} = [\\,1,\\,1,\\,1,\\,0,\\,1,\\,0,\\,0,\\,1,\\,0,\\,0,\\,1,\\,0\\,]$\n- 案例2（严重不平衡，在低分附近有一个困难的正例）：\n  - $\\mathbf{s}^{(2)} = [\\,0.99,\\,0.80,\\,0.75,\\,0.70,\\,0.65,\\,0.60,\\,0.58,\\,0.57,\\,0.56,\\,0.55,\\,0.54,\\,0.53,\\,0.52,\\,0.50,\\,0.49,\\,0.48,\\,0.30,\\,0.25,\\,0.20,\\,0.10\\,]$\n  - $\\mathbf{y}^{(2)} = [\\,1,\\,1,\\,0,\\,0,\\,0,\\,0,\\,0,\\,0,\\,0,\\,0,\\,0,\\,0,\\,0,\\,0,\\,0,\\,0,\\,1,\\,0,\\,0,\\,0\\,]$\n- 案例3（所有分数相同；边界行为）：\n  - $\\mathbf{s}^{(3)} = [\\,0.50,\\,0.50,\\,0.50,\\,0.50,\\,0.50,\\,0.50,\\,0.50,\\,0.50,\\,0.50,\\,0.50\\,]$\n  - $\\mathbf{y}^{(3)} = [\\,1,\\,0,\\,0,\\,1,\\,0,\\,0,\\,1,\\,0,\\,0,\\,0\\,]$\n\n最终输出格式：\n- 您的程序应生成单行输出，其中包含一个列表的列表形式的结果，每个内部列表对应一个测试用例，顺序与上面相同。每个内部列表必须是 $[AUC_{\\mathrm{ROC}}, AUC_{\\mathrm{PR}}, B]$ 的形式，其中 $AUC_{\\mathrm{ROC}}$ 和 $AUC_{\\mathrm{PR}}$ 是四舍五入到 $6$ 位小数的浮点数，$B$ 是一个布尔值。例如，一个包含三个测试用例的输出必须与 \"[[0.812345,0.701234,True],[0.923456,0.812345,True],[0.500000,0.300000,False]]\" 完全一样，没有多余的空格，也没有附加的文本。",
            "solution": "问题要求实现一个算法，根据给定的检测分数和真实标签集，计算受试者工作特征（ROC）曲线和精确率-召回率（PR）曲线，以及它们各自的曲线下面积（$AUC_{\\mathrm{ROC}}$ 和 $AUC_{\\mathrm{PR}}$）。此外，还要求在类别不平衡的情况下比较它们的信息量。整个过程必须按照规定从第一性原理推导。\n\n该方法论的核心是在不同的决策阈值下评估分类性能。如果一个样本的分数 $s_i$ 大于或等于阈值 $\\tau$，则将其分类为正例，即若 $s_i \\ge \\tau$ 则 $\\hat{y}_i(\\tau) = 1$。通过将 $\\tau$ 从 $+\\infty$ 变到 $-\\infty$，我们可以追踪分类器的性能，这构成了ROC和PR曲线的基础。\n\n首先，我们来确定必要的量。给定 $M$ 个观测值，每个都有一个分数 $s_i$ 和一个二元标签 $y_i \\in \\{0, 1\\}$。正例（真实峰电位）的总数是 $P = \\sum_{i=1}^{M} \\mathbb{1}\\{y_i = 1\\}$，负例（非峰电位）的总数是 $N = \\sum_{i=1}^{M} \\mathbb{1}\\{y_i = 0\\}$。问题假设 $P \\ge 1$ 且 $N \\ge 1$。\n\n在给定的阈值 $\\tau$ 下，二元分类的四个基本结果是：\n- 真正例 ($TP(\\tau)$)：$s_i \\ge \\tau$ 且 $y_i = 1$ 的实例数量。\n- 假正例 ($FP(\\tau)$)：$s_i \\ge \\tau$ 且 $y_i = 0$ 的实例数量。\n- 真反例 ($TN(\\tau)$)：$s_i  \\tau$ 且 $y_i = 0$ 的实例数量。\n- 假反例 ($FN(\\tau)$)：$s_i  \\tau$ 且 $y_i = 1$ 的实例数量。\n\n基于这些，我们定义关键的比率：\n- 真正例率（TPR）或召回率（Recall）：$TPR(\\tau) = Rec(\\tau) = \\frac{TP(\\tau)}{P}$。这是被正确识别的实际正例的比例。\n- 假正例率（FPR）：$FPR(\\tau) = \\frac{FP(\\tau)}{N}$。这是被错误识别为正例的实际负例的比例。\n- 精确率（Precision）：$Prec(\\tau) = \\frac{TP(\\tau)}{TP(\\tau) + FP(\\tau)}$，定义于 $TP(\\tau) + FP(\\tau) \\ge 1$。这是预测为正例的实例中实际为正例的比例。\n\n算法流程如下：\n\n**步骤1：数据准备与排序**\n高效构建这些曲线的基本见解是，$TP(\\tau)$、$FP(\\tau)$ 以及所有派生指标的值仅在阈值 $\\tau$ 穿过数据中存在的分数值时才会改变。因此，我们不需要连续扫描 $\\tau$，只需将唯一的分数值视为阈值即可。\n\n问题要求我们将唯一分数按严格降序排序。一个更鲁棒且标准的算法是（该算法能按规定正确处理分数相同的情况）对所有单个观测值进行排序。我们将分数 $s_i$ 和标签 $y_i$ 组合成对 $(s_i, y_i)$，并根据分数 $s_i$ 按降序对这些对进行排序。在分数相同的情况下，标签的相对顺序不影响该阈值水平下累积 $TP$ 和 $FP$ 计数的计算。\n\n**步骤2：曲线点生成**\n我们遍历排序后的观测值列表，这相当于逐步降低决策阈值。问题规定所有分数相同的项必须同时被包含。这可以通过按分数相同的组来处理观测值来实现。\n\n我们初始化累积计数 $TP_{cum} = 0$ 和 $FP_{cum} = 0$。这对应于阈值 $\\tau  \\max(s_i)$ 的情况，此时没有样本被分类为正例。这给了我们ROC曲线的起点 $(FPR, TPR) = (0, 0)$。\n\n然后我们遍历排序后的观测值，按分数对它们进行分组。对于每个具有唯一分数值 $u$ 的观测值组：\n1. 统计该组内的正例（$\\Delta TP$）和负例（$\\Delta FP$）的数量。\n2. 更新累积计数：$TP_{cum} \\leftarrow TP_{cum} + \\Delta TP$ 和 $FP_{cum} \\leftarrow FP_{cum} + \\Delta FP$。这些更新后的计数代表了阈值为 $\\tau=u$ 时的总真正例和假正例。\n3. 计算曲线上的新点：\n   - $FPR_{new} = \\frac{FP_{cum}}{N}$\n   - $TPR_{new} = \\frac{TP_{cum}}{P}$\n   - $Prec_{new} = \\frac{TP_{cum}}{TP_{cum} + FP_{cum}}$\n4. 生成一个新的ROC点 $(FPR_{new}, TPR_{new})$ 和一个新的PR点 $(TPR_{new}, Prec_{new})$。对所有唯一的分数值重复此过程。处理完所有观测值后的最终状态将是 $TP_{cum} = P$ 和 $FP_{cum} = N$，从而得到ROC的终点 $(1, 1)$。\n\n**步骤3：曲线下面积（AUC）计算**\n- **$AUC_{\\mathrm{ROC}}$**：ROC曲线是由生成的 $(FPR, TPR)$ 点组成的集合，从 $(0,0)$ 开始到 $(1,1)$ 结束。面积是通过在连接这些点（按 $FPR$ 递增顺序）的分段线性路径上使用梯形法则来计算的。对于一系列ROC点 $(x_k, y_k)$，其中 $x_k = FPR_k$ 和 $y_k = TPR_k$，面积为：\n  $$AUC_{\\mathrm{ROC}} = \\sum_{k=1}^{L} \\frac{(y_k + y_{k-1})}{2} (x_k - x_{k-1})$$\n  其中 $L+1$ 是ROC路径中的点数。\n- **$AUC_{\\mathrm{PR}}$**：PR曲线由点 $(Rec_k, Prec_k)$ 给出，其中 $Rec_k = TPR_k$。面积被定义为一个右连续阶梯函数的积分。所提供的公式是该积分的数值计算，等同于通常所说的平均精确率（Average Precision）：\n  $$AUC_{\\mathrm{PR}} = \\sum_{k=1}^{K} (Rec_k - Rec_{k-1}) \\cdot Prec_k$$\n  在这里，$(Rec_k, Prec_k)$ 是按召回率非降序生成的PR点，我们定义 $Rec_0 = 0$。总和中的每一项代表一个矩形的面积，其高度为 $Prec_k$，宽度为 $(Rec_k - Rec_{k-1})$，即第 $k$ 步召回率的增量。\n\n**步骤4：信息量比较**\n曲线的信息量是通过将其AUC值相对于随机分类器的性能进行归一化来评估的。\n- 对于ROC，随机分类器产生的 $AUC_{\\mathrm{ROC}}$ 为 $0.5$。归一化信息为 $I_{\\mathrm{ROC}} = \\frac{AUC_{\\mathrm{ROC}} - 0.5}{0.5}$。\n- 对于PR，随机分类器产生的 $AUC_{\\mathrm{PR}}$ 等于正类的比例，即 $\\pi = \\frac{P}{P+N}$。归一化信息为 $I_{\\mathrm{PR}} = \\frac{AUC_{\\mathrm{PR}} - \\pi}{1 - \\pi}$。\n布尔指示符 $B = \\mathbb{1}\\{I_{\\mathrm{PR}}  I_{\\mathrm{ROC}}\\}$ 决定了在这种特定归一化下，PR曲线是否比ROC曲线信息量更大。这种比较在类别不平衡的情况下（即当 $\\pi$ 远离 $0.5$时）尤其重要，此时PR曲线通常被认为是比ROC曲线更敏感的性能度量。ROC的基线是恒定的，而PR的基线随不平衡程度而变化，这使得后者成为一个更具挑战性的、更難超越的基准。",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to execute the full analysis for all test cases.\n    \"\"\"\n    test_cases = [\n        # Case 1 (moderately separable, roughly balanced)\n        (\n            [0.95, 0.90, 0.85, 0.80, 0.75, 0.70, 0.65, 0.60, 0.55, 0.50, 0.45, 0.40],\n            [1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0]\n        ),\n        # Case 2 (severely imbalanced with a hard positive near low score)\n        (\n            [0.99, 0.80, 0.75, 0.70, 0.65, 0.60, 0.58, 0.57, 0.56, 0.55, 0.54, 0.53, 0.52, 0.50, 0.49, 0.48, 0.30, 0.25, 0.20, 0.10],\n            [1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0]\n        ),\n        # Case 3 (all scores tied; boundary behavior)\n        (\n            [0.50, 0.50, 0.50, 0.50, 0.50, 0.50, 0.50, 0.50, 0.50, 0.50],\n            [1, 0, 0, 1, 0, 0, 1, 0, 0, 0]\n        )\n    ]\n\n    all_results = []\n    for scores, labels in test_cases:\n        result = _calculate_metrics(np.array(scores), np.array(labels))\n        all_results.append(result)\n\n    # Format the final output string\n    formatted_results = []\n    for auc_roc, auc_pr, b_flag in all_results:\n        formatted_results.append(f\"[{auc_roc:.6f},{auc_pr:.6f},{str(b_flag)}]\")\n    \n    print(f\"[{','.join(formatted_results)}]\")\n\ndef _calculate_metrics(scores, labels):\n    \"\"\"\n    Calculates ROC/PR AUC and informativeness for a single test case.\n    \"\"\"\n    # Total number of positive and negative samples\n    pos_total = np.sum(labels == 1)\n    neg_total = len(labels) - pos_total\n\n    # The problem assumes P=1 and N=1, so no need to check for zero division here.\n    \n    # Combine scores and labels, then sort by score descending.\n    # A secondary sort key is not strictly needed for the logic but is good practice.\n    indices = np.argsort(scores, kind='mergesort')[::-1]\n    sorted_scores = scores[indices]\n    sorted_labels = labels[indices]\n    \n    roc_fpr = [0.0]\n    roc_tpr = [0.0]\n    pr_points = []\n\n    tp_cum = 0\n    fp_cum = 0\n    i = 0\n    while i  len(sorted_scores):\n        current_score = sorted_scores[i]\n        \n        # Group all items with the same score\n        j = i\n        while j  len(sorted_scores) and sorted_scores[j] == current_score:\n            j += 1\n        \n        # Count positives and negatives in this tied-score group\n        labels_in_group = sorted_labels[i:j]\n        delta_tp = np.sum(labels_in_group == 1)\n        \n        # Update cumulative counts. This happens after processing the group.\n        tp_cum += delta_tp\n        fp_cum += (j - i) - delta_tp\n\n        # Calculate metrics for this new threshold level\n        tpr = tp_cum / pos_total\n        fpr = fp_cum / neg_total\n        \n        roc_tpr.append(tpr)\n        roc_fpr.append(fpr)\n        \n        # Precision is only defined when TP+FP  0\n        if (tp_cum + fp_cum)  0:\n            precision = tp_cum / (tp_cum + fp_cum)\n            pr_points.append((tpr, precision))\n\n        i = j\n\n    # Compute Area Under the ROC Curve using the trapezoidal rule\n    # np.trapz integrates y (tpr) with respect to x (fpr)\n    auc_roc = np.trapz(roc_tpr, roc_fpr)\n\n    # Compute Area Under the PR Curve (Average Precision)\n    auc_pr = 0.0\n    last_recall = 0.0\n    # pr_points are naturally sorted by non-decreasing recall\n    for recall, precision in pr_points:\n        auc_pr += (recall - last_recall) * precision\n        last_recall = recall\n\n    # Compute informativeness metrics\n    prevalence = pos_total / (pos_total + neg_total)\n    \n    # ROC informativeness\n    i_roc = (auc_roc - 0.5) / 0.5\n    \n    # PR informativeness\n    # Prevent division by zero if prevalence is 1 (all positive samples)\n    if prevalence  1.0:\n        i_pr = (auc_pr - prevalence) / (1 - prevalence)\n    else: # If pi=1, the denominator is 0. By convention, if auc_pr=1, info=1, else can be undefined/0.\n          # For this problem, N=1, so pi  1 is always true.\n        i_pr = 0.0\n\n    b_flag = i_pr  i_roc\n    \n    return auc_roc, auc_pr, b_flag\n\nif __name__ == \"__main__\":\n    solve()\n\n```"
        },
        {
            "introduction": "成功检测到脉冲后，下一步通常是进行脉冲分类（spike sorting），即将脉冲波形分配给不同的神经元。这一步依赖于从每个脉冲波形中提取的特征。然而，如果特征之间高度相关（即存在多重共线性），分类算法的性能和稳定性可能会受到影响。本练习将引导你使用方差膨胀因子（Variance Inflation Factor, VIF）这一强大的统计工具，来诊断并系统地剔除冗余特征。通过这项实践，你将学会如何构建一个更稳健、更易于解释的特征集，为可靠的脉冲分类奠定基础。",
            "id": "4194200",
            "problem": "您将处理一个关于细胞外神经脉冲放电分类特征工程的数学抽象问题。对于每个脉冲事件，都会根据其波形构建一个特征向量。目标是标准化特征，分析其协方差以理解冗余性，并使用方差膨胀因子（Variance Inflation Factor, VIF）避免多重共线性。您必须实现一个完全确定性的程序，该程序能在指定条件下生成合成特征数据集，对特征进行标准化，计算样本协方差矩阵，然后使用VIF迭代移除冗余特征，直到满足指定的冗余阈值。程序必须为每个测试用例生成单行输出，汇总所选特征的索引。\n\n请仅使用统计信号处理和多元分析中的标准定义与事实，并在神经科学数据分析的背景下进行解读：\n- 特征标准化（z-scoring）：对于每个特征维度（列），减去根据数据计算出的经验均值，然后除以根据数据计算出的经验标准差。\n- 无偏样本协方差矩阵使用分母 $n-1$ 进行计算，其中 $n$ 是样本数量（脉冲数）。\n- 特征的方差膨胀因子（VIF）量化了由于与其他特征的线性依赖性而导致的其方差膨胀程度。对于特征 $j$，其定义为 $VIF_j = \\dfrac{1}{1 - R_j^2}$，其中 $R_j^2$ 是通过普通最小二乘法将特征 $j$ 对所有其他特征进行回归时的决定系数。\n- 为确保计算 $R_j^2$ 时普通最小二乘法的数值鲁棒性，必要时应使用 Moore–Penrose 伪逆进行线性求解。\n\n您的程序必须为每个测试用例实现以下步骤：\n1. 根据该测试用例指定的生成模型，生成一个合成特征矩阵 $X \\in \\mathbb{R}^{n \\times p}$。所有随机抽样必须使用指定的种子和指示的独立标准正态变量。所有特征均为实值且无量纲。\n2. 对特征进行 z-score 标准化（即，将 $X$ 的每一列减去列均值，然后除以使用分母 $n-1$ 计算的列标准差）。\n3. 使用分母 $n-1$ 计算标准化数据的无偏样本协方差矩阵 $S$。\n4. 通过将每个特征对所有其余特征进行普通最小二乘回归来计算该特征的方差膨胀因子（VIF），并计算 $R^2$；然后计算 $VIF = 1/(1 - R^2)$。如果出现数值奇异性，则使用 Moore–Penrose 伪逆来获得最小二乘解。所有计算在给定种子的情况下必须是确定性的。\n5. 迭代消除特征以强制执行 VIF 阈值 $\\tau$：当任何特征的 VIF 超过 $\\tau$ 时，移除 VIF 最大的单个特征。如果在 $10^{-12}$ 的容差内出现并列情况，则移除具有最大原始列索引的特征。每次移除后，对剩余的特征重新计算 z-score 标准化、样本协方差矩阵和 VIF。当所有剩余特征的 VIF 小于或等于 $\\tau$ 时，或只剩下一个特征时，停止操作。\n6. 以升序排序的原始 $0$ 索引列索引列表的形式返回保留的特征索引。\n\n测试套件。请精确实现以下三个测试用例，按规定逐列生成 $X$。在每个案例中，$g_0, g_1, \\dots$ 表示 $\\mathbb{R}^n$ 中的独立标准正态向量，使用给定的种子进行抽样。所有平方根均为算术平方根。对整个测试用例使用相同的种子，按需顺序生成所有必需的 $g_k$ 和任何共享的潜在变量。为清晰起见，用 $n$ 表示脉冲数（行数），用 $p$ 表示特征数（列数）。\n\n- 测试用例 A（强两两相关和中度耦合）：\n  - 种子：$271828$。\n  - 维度：$n = 1500$, $p = 4$。\n  - 阈值：$\\tau = 5$。\n  - 构建方法：\n    - $x_0 = g_0$。\n    - $x_1 = 0.95\\,x_0 + \\sqrt{1 - 0.95^2}\\,g_1$。\n    - $x_2 = g_2$。\n    - $x_3 = 0.6\\,x_2 + \\sqrt{1 - 0.6^2}\\,g_3$。\n    - 通过列连接形成 $X = [x_0, x_1, x_2, x_3]$。\n\n- 测试用例 B（具有弱共享潜在驱动因素的近正交特征）：\n  - 种子：$161803$。\n  - 维度：$n = 1200$, $p = 5$。\n  - 阈值：$\\tau = 5$。\n  - 构建方法：\n    - 设 $s$ 为长度为 $n$ 的标准正态向量。\n    - 对于 $j \\in \\{0,1,2,3,4\\}$，设置 $x_j = g_j + 0.05\\,s$。\n    - 形成 $X = [x_0, x_1, x_2, x_3, x_4]$。\n\n- 测试用例 C（复合多重共线性，包括一个近线性组合和一个高度相关对）：\n  - 种子：$314159$。\n  - 维度：$n = 1000$, $p = 6$。\n  - 阈值：$\\tau = 4$。\n  - 构建方法：\n    - $x_0 = g_0$。\n    - $x_1 = g_1$。\n    - $x_2 = g_2$。\n    - $x_3 = x_0 + x_1 + 0.05\\,g_3$。\n    - $x_4 = 0.9\\,x_2 + \\sqrt{1 - 0.9^2}\\,g_4$。\n    - $x_5 = g_5$。\n    - 形成 $X = [x_0, x_1, x_2, x_3, x_4, x_5]$。\n\n最终输出格式。您的程序应生成单行输出，其中包含一个逗号分隔的列表，该列表包含了三个测试用例的保留索引列表。整个列表由一对总方括号括起，每个内部列表也由方括号括起，并按升序包含保留的原始特征索引。例如，一个有效的输出格式形式为 $[[i_{A,1}, i_{A,2}, \\dots], [i_{B,1}, \\dots], [i_{C,1}, \\dots]]$，不含额外文本。条目必须是整数。不涉及物理单位，也不存在角度。",
            "solution": "该问题要求实现一个基于方差膨胀因子（VIF）的确定性特征选择算法。该过程涉及在指定的相​​关结构下生成合成数据集，然后通过迭代过程移除表现出高度多重共线性的特征，直到满足给定的阈值为止。该解决方案严格遵守所提供的定义和步骤。\n\n### 基于原则的设计\n\n该解决方案围绕多元统计分析的核心原则设计，专门解决特征集中的多重共線性问题。\n\n1.  **合成数据生成**：此问题的基础是创建合成特征矩阵 $X \\in \\mathbb{R}^{n \\times p}$。为每个测试用例提供的生成模型是基于独立标准正态变量（表示为 $g_k \\in \\mathbb{R}^n$）的线性构造。这种方法是创建具有精确控制、先验已知相关性结构的数据集的标准实践。此类数据集对于验证统计算法的正确性和性能非常宝贵，因为预期的结果通常可以从数据的构造中推断出来。例如，一个定义为 $x_1 = \\rho x_0 + \\sqrt{1-\\rho^2} g_1$ 的特征，其与特征 $x_0$ 的理论相关性为 $\\rho$，这使得我们可以直接测试算法检测此关系的能力。\n\n2.  **特征标准化（Z-score）**：在评估多重共線性之前，所有特征都经过标准化处理。对于数据矩阵 $X$ 中的每个特征向量（列）$x_j$，其标准化对应项 $z_j$ 的计算方式如下：\n    $$ z_{ij} = \\frac{x_{ij} - \\mu_j}{\\sigma_j} $$\n    其中 $\\mu_j$ 是特征 $j$ 的经验均值，$\\sigma_j$ 是其使用分母 $n-1$（方差的无偏估计量）计算出的经验标准差。标准化将所有特征转换到一个共同的尺度（零均值和单位方差），这至关重要，原因有二：它防止具有较大尺度的特征对分析产生不成比例的影响，并且它使标准化数据的样本协方差矩阵等同于样本相关矩阵。\n\n3.  **方差膨胀因子（VIF）**：VIF 是量化多重共線性的核心指标。对于给定的特征 $j$，其 VIF 定义为：\n    $$ VIF_j = \\frac{1}{1 - R_j^2} $$\n    这里，$R_j^2$ 是将特征 $j$（作为响应变量）对所有其他特征（作为预测变量）进行普通最小二乘（OLS）回归所得到的决定系数。一个高的 $R_j^2$ 值（接近 1）表示特征 $j$ 可以被其他特征的线性组合准确预测，这意味着冗余。因此，一个高的 VIF 值预示着严重的多重共線性。一个常见的经验法则是，认为 $VIF  5$ 或 $VIF  10$ 是有问题的。\n\n4.  **通过普通最小二乘法（OLS）计算 $R^2$**：根据问题的明确指示，为每个特征计算 $R_j^2$。给定标准化特征矩阵 $Z$，我们选择一列 $z_j$ 作为响应向量 $y$，其余列作为预测矩阵 $Z_{\\text{others}}$。OLS 问题是找到系数向量 $\\beta$，使得模型 $y \\approx Z_{\\text{others}} \\beta$ 中的残差平方和最小化。为了数值稳定性，特别是在接近奇异的情况下，使用 Moore-Penrose 伪逆来求解：\n    $$ \\beta = (Z_{\\text{others}}^\\dagger) y $$\n    预测响应为 $\\hat{y} = Z_{\\text{others}} \\beta$。由于数据是中心化的（均值为零），总平方和（TSS）和解释平方和（ESS）简化为 $TSS = \\sum y_i^2$ 和 $ESS = \\sum \\hat{y}_i^2$。然后，决定系数可以稳健地计算为：\n    $$ R_j^2 = \\frac{ESS}{TSS} = \\frac{\\sum \\hat{y}_i^2}{\\sum y_i^2} $$\n\n5.  **迭代特征消除**：采用贪婪的后向消除策略来减少多重共線性。算法过程如下：\n    a.  从完整的特征集开始。\n    b.  在每次迭代中，计算集合中每个当前特征的 VIF。这需要重新标准化当前的特征子集并重新计算所有 VIF。\n    c.  识别最大 VIF 值，$VIF_{\\text{max}}$。\n    d.  如果 $VIF_{\\text{max}}$ 小于或等于指定的阈值 $\\tau$，则过程终止，因为剩余的特征满足了期望的冗余标准。\n    e.  如果 $VIF_{\\text{max}}  \\tau$，则移除 VIF 最高的单个特征。应用一个特定的平局打破规则：如果多个特征共享最高的 VIF（在 $10^{-12}$ 的容差范围内），则消除具有最大原始列索引的那个。\n    f.  重复此过程，直到满足 (d) 中的条件或只剩下一个特征为止。\n\n这个迭代的、确定性的过程确保了最冗余的特征被逐步移除，从而得到一个具有受控多重共線性的最终特征集。最终输出是经过此消除过程后幸存下来的特征的原始、0索引的排序列表。",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to run all test cases and print the final result.\n    \"\"\"\n\n    def generator_A(n, rng):\n        \"\"\"Generates data for Test Case A.\"\"\"\n        g0 = rng.standard_normal(n)\n        g1 = rng.standard_normal(n)\n        g2 = rng.standard_normal(n)\n        g3 = rng.standard_normal(n)\n        x0 = g0\n        x1 = 0.95 * x0 + np.sqrt(1 - 0.95**2) * g1\n        x2 = g2\n        x3 = 0.6 * x2 + np.sqrt(1 - 0.6**2) * g3\n        return np.column_stack([x0, x1, x2, x3])\n\n    def generator_B(n, rng):\n        \"\"\"Generates data for Test Case B.\"\"\"\n        s = rng.standard_normal(n)\n        columns = []\n        for _ in range(5):\n            g = rng.standard_normal(n)\n            x = g + 0.05 * s\n            columns.append(x)\n        return np.column_stack(columns)\n\n    def generator_C(n, rng):\n        \"\"\"Generates data for Test Case C.\"\"\"\n        g0 = rng.standard_normal(n)\n        g1 = rng.standard_normal(n)\n        g2 = rng.standard_normal(n)\n        g3 = rng.standard_normal(n)\n        g4 = rng.standard_normal(n)\n        g5 = rng.standard_normal(n)\n        x0 = g0\n        x1 = g1\n        x2 = g2\n        x3 = x0 + x1 + 0.05 * g3\n        x4 = 0.9 * x2 + np.sqrt(1 - 0.9**2) * g4\n        x5 = g5\n        return np.column_stack([x0, x1, x2, x3, x4, x5])\n\n    test_cases = [\n        {'n': 1500, 'p': 4, 'tau': 5, 'seed': 271828, 'generator': generator_A},\n        {'n': 1200, 'p': 5, 'tau': 5, 'seed': 161803, 'generator': generator_B},\n        {'n': 1000, 'p': 6, 'tau': 4, 'seed': 314159, 'generator': generator_C},\n    ]\n\n    all_results = []\n    for case in test_cases:\n        result = process_case(case['n'], case['p'], case['tau'], case['seed'], case['generator'])\n        all_results.append(result)\n\n    # Format the final output string exactly as specified.\n    formatted_results = ','.join(map(str, all_results))\n    print(f\"[{formatted_results}]\")\n\ndef calculate_vifs_ols(standardized_features):\n    \"\"\"\n    Calculates VIF for each feature by regressing it on the others.\n    \"\"\"\n    n_samples, num_features = standardized_features.shape\n    vifs = np.zeros(num_features)\n\n    for i in range(num_features):\n        y = standardized_features[:, i]\n        \n        # Create predictor matrix excluding the current feature\n        X_reg = np.delete(standardized_features, i, axis=1)\n\n        # Handle edge case where there's only one predictor\n        if X_reg.shape[1] == 0:\n            vifs[i] = 1.0\n            continue\n        \n        # Solve for regression coefficients using Moore-Penrose pseudoinverse\n        beta = np.linalg.pinv(X_reg) @ y\n        \n        # Calculate predicted values\n        y_hat = X_reg @ beta\n        \n        # Calculate R^2. For standardized data, TSS = sum(y**2)\n        tss = np.sum(y**2)\n        ess = np.sum(y_hat**2)\n        \n        if tss  1e-12:\n            # If TSS is zero, the feature column was constant (zero variance),\n            # which is perfectly predictable. R^2 is 1.\n            r_squared = 1.0\n        else:\n            r_squared = ess / tss\n            # Clamp to 1.0 to handle potential floating point inaccuracies\n            r_squared = min(r_squared, 1.0)\n            \n        # Calculate VIF from R^2\n        if 1.0 - r_squared  1e-12:\n            vifs[i] = np.inf\n        else:\n            vifs[i] = 1.0 / (1.0 - r_squared)\n            \n    return vifs\n\ndef process_case(n, p, tau, seed, generator_func):\n    \"\"\"\n    Processes a single test case: generates data and iteratively removes features based on VIF.\n    \"\"\"\n    rng = np.random.default_rng(seed)\n    X = generator_func(n, rng)\n    \n    original_indices = list(range(p))\n    \n    while True:\n        num_features = len(original_indices)\n        if num_features = 1:\n            break\n            \n        current_features = X[:, original_indices]\n        \n        # Step 2: Perform z-scoring on the current set of features\n        mean = np.mean(current_features, axis=0)\n        std = np.std(current_features, axis=0, ddof=1)\n        \n        # To avoid division by zero for constant features\n        std[std == 0] = 1.0\n        \n        standardized_features = (current_features - mean) / std\n\n        # Step 4: Compute VIF for each feature using OLS\n        vifs = calculate_vifs_ols(standardized_features)\n        \n        # Step 5: Iteratively eliminate features\n        max_vif = np.max(vifs)\n        \n        if max_vif = tau:\n            break\n            \n        # Find all features with VIF close to the max (tie-breaking)\n        candidates = np.where(vifs = max_vif - 1e-12)[0]\n        \n        # Map local indices of candidates to their original indices\n        candidate_original_indices = [original_indices[i] for i in candidates]\n        \n        # Remove the one with the largest original index\n        idx_to_remove = max(candidate_original_indices)\n        original_indices.remove(idx_to_remove)\n        \n    original_indices.sort()\n    return original_indices\n\nsolve()\n```"
        }
    ]
}