{
    "hands_on_practices": [
        {
            "introduction": "To build strong intuition for shuffle correction, we can simplify the problem to its essential components. This exercise models a neural interaction and the analysis smoothing window as simple rectangular pulses, allowing for a clear, analytical exploration of the mechanics. By calculating how a temporal shift $\\Delta$ affects the resulting cross-correlogram, you will gain a first-principles understanding of how the shift predictor isolates and removes correlation artifacts .",
            "id": "4192229",
            "problem": "Consider two simultaneously recorded spike trains from two neurons across repeated trials. The interaction between the neurons is assumed to produce an additional within-trial synchronous coincidence component modeled as a narrow peak in the cross-correlation function. Specifically, model the interaction contribution to the cross-correlation as a rectangular pulse $h(\\tau)$ centered at zero lag with total area $A$ and width $\\sigma$, given by $h(\\tau) = \\frac{A}{\\sigma}$ for $|\\tau| \\le \\sigma/2$ and $h(\\tau) = 0$ otherwise. A cross-correlogram (CCG) is estimated by convolving the underlying cross-correlation with a rectangular smoothing kernel $K_{w}(\\tau)$ of width $w$ and unit area, where $K_{w}(\\tau) = \\frac{1}{w}$ for $|\\tau| \\le w/2$ and $K_{w}(\\tau) = 0$ otherwise. To perform shuffle correction using the shift predictor, one spike train is circularly time shifted by a fixed offset $\\Delta$ within each trial before computing the CCG, and this shifted CCG is then subtracted from the raw CCG. Assume the narrow peak width satisfies $0 < \\sigma \\le w$, and focus only on the contribution of $h(\\tau)$ to the CCG amplitude at zero lag.\n\nUsing first-principles definitions of convolution for point-process cross-correlograms and the notion that histogram binning corresponds to integration of the cross-correlation over the kernel support, derive the expected amount of reduction in the amplitude at zero lag caused exclusively by subtracting the shift predictor as a function of $\\Delta$, $w$, $A$, and $\\sigma$. Then, under the stated assumption $0 < \\sigma \\le w$ and the condition $\\Delta > w$, compute the exact value of this reduction. Provide the final answer as a single real number with no units.",
            "solution": "The problem asks for the reduction in the amplitude of the cross-correlogram (CCG) at zero lag due to the subtraction of a shift predictor. This reduction is precisely the value of the shift predictor's CCG at zero lag, computed using the specified interaction term $h(\\tau)$.\n\nFirst, let us formalize the quantities involved. The interaction component of the cross-correlation function is given by a rectangular pulse:\n$$\nh(\\tau) = \n\\begin{cases} \n\\frac{A}{\\sigma} & \\text{if } |\\tau| \\le \\frac{\\sigma}{2} \\\\\n0 & \\text{otherwise}\n\\end{cases}\n$$\nThe CCG is obtained by convolving the cross-correlation function with a rectangular smoothing kernel $K_w(\\tau)$:\n$$\nK_{w}(\\tau) = \n\\begin{cases} \n\\frac{1}{w} & \\text{if } |\\tau| \\le \\frac{w}{2} \\\\\n0 & \\text{otherwise}\n\\end{cases}\n$$\nThe problem states that we are to focus only on the contribution of $h(\\tau)$ to the CCG. The raw CCG's amplitude at zero lag, denoted $C_{raw}(0)$, is given by the convolution of $h(\\tau)$ and $K_w(\\tau)$ evaluated at $\\tau=0$:\n$$ C_{raw}(0) = (h * K_w)(0) = \\int_{-\\infty}^{\\infty} h(u) K_w(0-u) \\,du $$\nSince $K_w(\\tau)$ is an even function, $K_w(-u) = K_w(u)$. The expression becomes:\n$$ C_{raw}(0) = \\int_{-\\infty}^{\\infty} h(u) K_w(u) \\,du $$\nThe shift predictor is calculated by first shifting one spike train by a time offset $\\Delta$. This effectively shifts the interaction component of the cross-correlation from $h(\\tau)$ to $h(\\tau-\\Delta)$. The resulting shifted CCG, $C_{shifted}(\\tau)$, is given by the convolution $(h(\\tau-\\Delta) * K_w(\\tau))$.\n\nThe reduction in amplitude at zero lag is the value of this shifted CCG at $\\tau=0$. Let us denote this reduction by $R$.\n$$ R = C_{shifted}(0) = (h(\\tau-\\Delta) * K_w)(0) $$\nUsing the definition of convolution:\n$$ R = \\int_{-\\infty}^{\\infty} h(u-\\Delta) K_w(0-u) \\,du = \\int_{-\\infty}^{\\infty} h(u-\\Delta) K_w(-u) \\,du $$\nAs before, since $K_w(\\tau)$ is even, we have:\n$$ R(\\Delta, w, A, \\sigma) = \\int_{-\\infty}^{\\infty} h(u-\\Delta) K_w(u) \\,du $$\nThis integral represents the expected amount of reduction as a function of $\\Delta$, $w$, $A$, and $\\sigma$, as requested by the first part of the problem. The value of this integral is determined by the product of the functions' constant values over the region where their supports overlap. The integrand is non-zero only where both $h(u-\\Delta)$ and $K_w(u)$ are non-zero.\nThe support of $h(u-\\Delta)$ is the interval where $|u-\\Delta| \\le \\sigma/2$, which is $[\\Delta - \\sigma/2, \\Delta + \\sigma/2]$.\nThe support of $K_w(u)$ is the interval where $|u| \\le w/2$, which is $[-w/2, w/2]$.\n\nThe value of the reduction is the product of the functions' amplitudes multiplied by the length of the intersection of their supports:\n$$ R = \\frac{A}{\\sigma} \\cdot \\frac{1}{w} \\cdot \\text{Length}\\left( \\left[\\Delta - \\frac{\\sigma}{2}, \\Delta + \\frac{\\sigma}{2}\\right] \\cap \\left[-\\frac{w}{2}, \\frac{w}{2}\\right] \\right) $$\nA more explicit functional form can be written using min/max functions to define the length of the overlap:\n$$ R(\\Delta, w, A, \\sigma) = \\frac{A}{\\sigma w} \\max\\left(0, \\min\\left(\\Delta + \\frac{\\sigma}{2}, \\frac{w}{2}\\right) - \\max\\left(\\Delta - \\frac{\\sigma}{2}, -\\frac{w}{2}\\right)\\right) $$\nThis expression is valid for any value of $\\Delta$.\n\nNext, we must compute the exact value of this reduction under the specific conditions $0 < \\sigma \\le w$ and $\\Delta > w$. To evaluate the integral for $R$, we analyze the overlap between the supports of $h(u-\\Delta)$ and $K_w(u)$.\n\nThe support for $K_w(u)$ is the interval $[ -w/2, w/2 ]$.\nThe support for $h(u-\\Delta)$ is the interval $[ \\Delta - \\sigma/2, \\Delta + \\sigma/2 ]$.\n\nWe are given the condition $\\Delta > w$. Since $w > 0$, this implies $\\Delta$ is positive. Let us compare the left boundary of the support of $h(u-\\Delta)$ with the right boundary of the support of $K_w(u)$.\nThe left boundary of the support of $h(u-\\Delta)$ is $\\Delta - \\sigma/2$.\nThe right boundary of the support of $K_w(u)$ is $w/2$.\n\nFrom the condition $\\Delta > w$, we can write $\\Delta > w/2 + w/2$, which implies:\n$$ \\Delta - \\frac{w}{2} > \\frac{w}{2} $$\nWe are also given the condition $\\sigma \\le w$, which means $\\sigma/2 \\le w/2$, or equivalently, $-\\sigma/2 \\ge -w/2$. Adding $\\Delta$ to both sides of this inequality gives:\n$$ \\Delta - \\frac{\\sigma}{2} \\ge \\Delta - \\frac{w}{2} $$\nCombining these two inequalities, we find:\n$$ \\Delta - \\frac{\\sigma}{2} \\ge \\Delta - \\frac{w}{2} > \\frac{w}{2} $$\nThis result demonstrates that the leftmost point of the support of $h(u-\\Delta)$ is strictly greater than the rightmost point of the support of $K_w(u)$. Therefore, the two support intervals are disjoint.\n$$ \\left[\\Delta - \\frac{\\sigma}{2}, \\Delta + \\frac{\\sigma}{2}\\right] \\cap \\left[-\\frac{w}{2}, \\frac{w}{2}\\right] = \\emptyset $$\nBecause the supports of the two functions do not overlap, their product, the integrand $h(u-\\Delta) K_w(u)$, is equal to $0$ for all values of $u$. The integral of a function that is zero everywhere is zero.\n$$ R = \\int_{-\\infty}^{\\infty} 0 \\,du = 0 $$\nThus, under the condition $\\Delta > w$, the contribution of the shifted interaction peak to the CCG at zero lag is exactly zero. The reduction in amplitude is $0$. This result is intuitive: if the temporal shift $\\Delta$ is larger than the smoothing window half-width $w/2$ (and in this case, larger than the full width $w$), the narrow synchronous peak, now centered at lag $\\Delta$, will fall completely outside the integration window for the CCG bin at $\\tau=0$.",
            "answer": "$$\n\\boxed{0}\n$$"
        },
        {
            "introduction": "While conceptual models are invaluable, real-world neuroscience involves analyzing vast datasets from many neurons recorded over numerous trials. This practice shifts our focus to computational efficiency, a critical skill for any data scientist. Here, you will develop a fully vectorized algorithm to compute shuffle-corrected cross-correlograms, replacing slow, explicit loops with optimized matrix operations. This hands-on coding exercise  demonstrates how to apply the principles of shuffle correction at scale, a cornerstone of modern neural data analysis pipelines.",
            "id": "4192301",
            "problem": "You are given binned spike count data for multiple neurons across repeated trials and time bins. The aim is to compute the shuffle-corrected cross-correlogram for many neuron pairs and trials in a fully vectorized manner using matrix operations. The shuffle correction referred to here is the \"shift predictor,\" based on a circular shift of trials. The task is to derive an algorithm from first principles and implement it in code that uses only array operations and broadcasting over trials and neuron pairs, without explicit Python loops over trials or neuron pairs.\n\nBegin with fundamental definitions. Let $N_A$ denote the number of neurons in population $A$ and $N_B$ denote the number of neurons in population $B$. Let $R$ denote the number of repeated trials and $T$ denote the number of time bins. Let $L$ be the maximum absolute lag (in bins) to be considered, with $0 \\le L < T$. The binned spike count arrays are:\n- $X \\in \\mathbb{R}^{N_A \\times R \\times T}$, where $X_{i,r,t}$ is the spike count of neuron $i$ in population $A$ on trial $r$ at time bin $t$.\n- $Y \\in \\mathbb{R}^{N_B \\times R \\times T}$, similarly defined for population $B$.\n\nLet $\\mathcal{P}$ be a list of $P$ ordered neuron index pairs $(i,j)$, with $i \\in \\{0,\\dots,N_A-1\\}$ and $j \\in \\{0,\\dots,N_B-1\\}$, represented as an array of shape $P \\times 2$.\n\nDefine the raw cross-correlogram for a single pair $(i,j)$ at lag $\\tau \\in \\{-L, \\dots, 0, \\dots, +L\\}$ by the unbiased (per-bin, per-trial averaged) estimator:\n- For $\\tau \\ge 0$,\n$$\nC_{ij}(\\tau) \\;=\\; \\frac{1}{R \\, (T - \\tau)} \\sum_{r=0}^{R-1} \\sum_{t=0}^{T-\\tau-1} X_{i,r,t} \\; Y_{j,r,t+\\tau}.\n$$\n- For $\\tau < 0$,\n$$\nC_{ij}(\\tau) \\;=\\; \\frac{1}{R \\, (T - |\\tau|)} \\sum_{r=0}^{R-1} \\sum_{t=0}^{T-|\\tau|-1} X_{i,r,t+|\\tau|} \\; Y_{j,r,t}.\n$$\n\nDefine the shift-predictor (shuffle predictor) cross-correlogram by circularly shifting the trial index of population $B$ by $+1$ (i.e., $\\sigma(r) = (r+1) \\bmod R$), while keeping population $A$ unshifted. Denote the trial-shifted array by $Y^{\\mathrm{shift}}$ with $Y^{\\mathrm{shift}}_{j,r,t} = Y_{j,(r+1)\\bmod R,t}$. Then:\n- For $\\tau \\ge 0$,\n$$\nS_{ij}(\\tau) \\;=\\; \\frac{1}{R \\, (T - \\tau)} \\sum_{r=0}^{R-1} \\sum_{t=0}^{T-\\tau-1} X_{i,r,t} \\; Y^{\\mathrm{shift}}_{j,r,t+\\tau}.\n$$\n- For $\\tau < 0$,\n$$\nS_{ij}(\\tau) \\;=\\; \\frac{1}{R \\, (T - |\\tau|)} \\sum_{r=0}^{R-1} \\sum_{t=0}^{T-|\\tau|-1} X_{i,r,t+|\\tau|} \\; Y^{\\mathrm{shift}}_{j,r,t}.\n$$\n\nThe shuffle-corrected cross-correlogram is the difference\n$$\n\\tilde{C}_{ij}(\\tau) \\;=\\; C_{ij}(\\tau) \\;-\\; S_{ij}(\\tau),\n$$\nfor each $(i,j) \\in \\mathcal{P}$ and each lag $\\tau \\in \\{-L,\\dots,+L\\}$.\n\nYour implementation must:\n- Use the data structures exactly as specified: $X$ of shape $N_A \\times R \\times T$, $Y$ of shape $N_B \\times R \\times T$, and $\\mathcal{P}$ of shape $P \\times 2$.\n- Compute $C_{ij}(\\tau)$ and $S_{ij}(\\tau)$ for all $(i,j) \\in \\mathcal{P}$ and all $\\tau \\in \\{-L,\\dots,+L\\}$ using vectorized matrix operations over neuron pairs and trials. You may use a loop over $\\tau$, but you must not use explicit Python loops over $r$ or over $(i,j)$.\n- Normalize using the denominators $R \\, (T - |\\tau|)$ as defined above.\n- Return, for each test case, a single scalar: the maximum value of $\\tilde{C}_{ij}(\\tau)$ across all $\\tau \\in \\{-L,\\dots,+L\\}$ for the first pair in $\\mathcal{P}$, rounded to $6$ decimal places. This scalar must be a $float$.\n\nTest Suite. Your program must internally define the following test cases and run them in order:\n- Case $1$ (happy path with stimulus-locked components and within-trial coincidences):\n  - $N_A = 2$, $N_B = 2$, $R = 4$, $T = 16$, $L = 3$, $\\mathcal{P} = \\big[ (0,1) \\big]$.\n  - Construct $X$ and $Y$ as zeros everywhere except:\n    - For all $r \\in \\{0,1,2,3\\}$, set $X_{0,r,5} = 1$ and $Y_{1,r,5} = 1$ (stimulus-locked events).\n    - Additionally, set $X_{0,2,8} = 1$ and $Y_{1,2,8} = 1$ (an extra coincidence only on trial $r = 2$). All other entries remain $0$.\n  - Expected qualitative behavior: the shift predictor removes the stimulus-locked zero-lag correlation; the within-trial extra coincidence remains in $\\tilde{C}_{01}(0)$. The returned scalar is the maximum of $\\tilde{C}_{01}(\\tau)$ over $\\tau \\in \\{-3,\\dots,+3\\}$.\n- Case $2$ (boundary: zero spikes in $A$):\n  - $N_A = 1$, $N_B = 1$, $R = 3$, $T = 10$, $L = 4$, $\\mathcal{P} = \\big[ (0,0) \\big]$.\n  - Construct $X$ as all zeros. Construct $Y$ with any fixed nonzero pattern, e.g., set $Y_{0,0,1} = 1$, $Y_{0,1,5} = 1$, $Y_{0,2,7} = 1$, and all other entries $0$.\n  - Expected behavior: all correlations are $0$, so the returned scalar is $0.0$.\n- Case $3$ (boundary: single trial):\n  - $N_A = 1$, $N_B = 1$, $R = 1$, $T = 8$, $L = 2$, $\\mathcal{P} = \\big[ (0,0) \\big]$.\n  - Construct $X$ and $Y$ identical, with $X_{0,0,2} = 1$, $X_{0,0,6} = 1$, and $Y_{0,0,2} = 1$, $Y_{0,0,6} = 1$, all other entries $0$.\n  - Expected behavior: the shift predictor equals the raw correlation (since the trial shift on $R=1$ is identity), so the returned scalar is $0.0$.\n- Case $4$ (edge lag coverage: maximum lag $L = T - 1$):\n  - $N_A = 1$, $N_B = 1$, $R = 2$, $T = 4$, $L = 3$, $\\mathcal{P} = \\big[ (0,0) \\big]$.\n  - Construct $X$ and $Y$ with anti-synchronous patterns across trials:\n    - Set $X_{0,0,0} = 1$, $X_{0,1,3} = 1$.\n    - Set $Y_{0,0,3} = 1$, $Y_{0,1,0} = 1$.\n    - All other entries are $0$.\n  - Expected behavior: a strong positive corrected correlation at $\\tau = +3$ remains after the shift predictor, so the returned scalar is positive.\n\nFinal Output Format. Your program should produce a single line of output containing the results of the test suite as a comma-separated list enclosed in square brackets, with each element a $float$ rounded to $6$ decimal places for the first pair in $\\mathcal{P}$ for each test case, in order. For example, the output should be of the form $[x_1,x_2,x_3,x_4]$ where each $x_k$ is a $float$.\n\nAngles and physical units are not applicable to this problem; all lags and time bins are counts in discrete bins. Ensure that your implementation is self-contained and uses only matrix operations for pair and trial aggregation, as specified, and adheres to the normalization constants given above.",
            "solution": "### Step 1: Extract Givens\n\nThe problem provides the following data, definitions, and constraints:\n- **Data Structures**:\n  - Binned spike counts for population A: $X \\in \\mathbb{R}^{N_A \\times R \\times T}$, where $X_{i,r,t}$ is the spike count of neuron $i$ in population $A$ on trial $r$ at time bin $t$.\n  - Binned spike counts for population B: $Y \\in \\mathbb{R}^{N_B \\times R \\times T}$, defined similarly.\n- **Parameters**:\n  - $N_A$: number of neurons in population A.\n  - $N_B$: number of neurons in population B.\n  - $R$: number of repeated trials.\n  - $T$: number of time bins.\n  - $L$: maximum absolute lag, with $0 \\le L < T$.\n- **Neuron Pairs**: A list $\\mathcal{P}$ of $P$ ordered neuron index pairs $(i,j)$, with $i \\in \\{0,\\dots,N_A-1\\}$ and $j \\in \\{0,\\dots,N_B-1\\}$, represented as an array of shape $P \\times 2$.\n- **Definitions**:\n  - **Raw Cross-Correlogram ($C_{ij}(\\tau)$)** for $\\tau \\in \\{-L, \\dots, +L\\}$:\n    - For $\\tau \\ge 0$: $C_{ij}(\\tau) = \\frac{1}{R \\, (T - \\tau)} \\sum_{r=0}^{R-1} \\sum_{t=0}^{T-\\tau-1} X_{i,r,t} \\; Y_{j,r,t+\\tau}$.\n    - For $\\tau < 0$: $C_{ij}(\\tau) = \\frac{1}{R \\, (T - |\\tau|)} \\sum_{r=0}^{R-1} \\sum_{t=0}^{T-|\\tau|-1} X_{i,r,t+|\\tau|} \\; Y_{j,r,t}$.\n  - **Shift-Predictor ($S_{ij}(\\tau)$)**:\n    - Trial-shifted array $Y^{\\mathrm{shift}}$ is defined by $Y^{\\mathrm{shift}}_{j,r,t} = Y_{j,(r+1)\\bmod R,t}$.\n    - For $\\tau \\ge 0$: $S_{ij}(\\tau) = \\frac{1}{R \\, (T - \\tau)} \\sum_{r=0}^{R-1} \\sum_{t=0}^{T-\\tau-1} X_{i,r,t} \\; Y^{\\mathrm{shift}}_{j,r,t+\\tau}$.\n    - For $\\tau < 0$: $S_{ij}(\\tau) = \\frac{1}{R \\, (T - |\\tau|)} \\sum_{r=0}^{R-1} \\sum_{t=0}^{T-|\\tau|-1} X_{i,r,t+|\\tau|} \\; Y^{\\mathrm{shift}}_{j,r,t}$.\n  - **Shuffle-Corrected Cross-Correlogram ($\\tilde{C}_{ij}(\\tau)$)**: $\\tilde{C}_{ij}(\\tau) = C_{ij}(\\tau) - S_{ij}(\\tau)$.\n- **Implementation Constraints**:\n  - Must use the specified data structures.\n  - Must compute $C_{ij}(\\tau)$ and $S_{ij}(\\tau)$ for all pairs in $\\mathcal{P}$ and lags in $\\{-L,\\dots,+L\\}$ using vectorized matrix operations over neuron pairs and trials.\n  - Explicit Python loops over trials $r$ or pairs $(i,j)$ are forbidden. A loop over lag $\\tau$ is permitted.\n  - Must use the specified normalization $1 / (R \\, (T - |\\tau|))$.\n- **Output Requirement**: For each test case, return the maximum value of $\\tilde{C}_{ij}(\\tau)$ over all lags for the first pair in $\\mathcal{P}$, rounded to $6$ decimal places as a `float`. The final program output is a list of these scalars.\n\n### Step 2: Validate Using Extracted Givens\n\nThe problem statement is evaluated against the validation criteria.\n\n- **Scientifically Grounded**: The problem is well-grounded in computational neuroscience. The \"shift predictor\" is a standard and fundamental technique for correcting cross-correlograms for stimulus-locked or slow co-varying components, aiming to isolate correlations arising from direct, within-trial interactions. The provided formulas for the unbiased estimator are correct.\n- **Well-Posed**: The problem is mathematically well-defined. All variables, constants, and functions are specified precisely. The inputs are clearly described, and the desired output is a uniquely determinable quantity. The condition $L < T$ ensures the normalization factor's denominator $T-|\\tau|$ is always at least $1$, preventing division by zero.\n- **Objective**: The problem is stated in precise, objective, mathematical language, free from any subjectivity or ambiguity.\n- **Flaw Checklist**:\n  1.  **Scientific or Factual Unsoundness**: None. The method is standard practice.\n  2.  **Non-Formalizable or Irrelevant**: None. The problem is a direct and formalizable implementation of the specified topic.\n  3.  **Incomplete or Contradictory Setup**: None. All necessary information is provided and is internally consistent.\n  4.  **Unrealistic or Infeasible**: None. The task is a common computational problem in neuroscience data analysis.\n  5.  **Ill-Posed or Poorly Structured**: None. A unique solution exists and is computable.\n  6.  **Pseudo-Profound, Trivial, or Tautological**: None. The vectorization requirement poses a non-trivial algorithmic challenge.\n  7.  **Outside Scientific Verifiability**: None. The results are numerically verifiable.\n\n### Step 3: Verdict and Action\n\nThe problem statement is **valid**. A solution will be developed.\n\n### Principle-Based Design and Algorithmic Derivation\n\nThe objective is to compute the shuffle-corrected cross-correlogram, $\\tilde{C}_{ij}(\\tau)$, for a set of neuron pairs $\\mathcal{P}$ in a manner that is vectorized over both pairs and trials. The core of the problem lies in efficiently computing the summations present in the definitions of $C_{ij}(\\tau)$ and $S_{ij}(\\tau)$ without explicit loops.\n\nLet the array of pair indices be $\\mathcal{P}$ with shape $P \\times 2$. The indices for population $A$ are $\\mathcal{P}[:,0]$ and for population $B$ are $\\mathcal{P}[:,1]$.\n\nFirst, we use advanced indexing to select the time series data for all specified pairs simultaneously.\nLet `indices_A = P[:,0]` and `indices_B = P[:,1]`.\n`X_pairs = X[indices_A, :, :]`\n`Y_pairs = Y[indices_B, :, :]`\nThis creates two new arrays, `X_pairs` and `Y_pairs`, both of shape $P \\times R \\times T$. The first dimension of these arrays now corresponds to the list of pairs, effectively stacking the data for each pair.\n\nThe shift-predictor term requires a trial-shifted version of the $Y$ data, $Y^{\\mathrm{shift}}$. This is achieved by circularly shifting the trial axis (axis $1$) by one position. The `numpy.roll` function is ideal for this:\n`Y_shift = np.roll(Y, shift=-1, axis=1)`\nThe corresponding data for the specified pairs is then selected:\n`Y_shift_pairs = Y_shift[indices_B, :, :]`\n\nThe computation can now proceed within a loop over the allowed lags $\\tau \\in \\{-L, \\dots, +L\\}$. For each lag $\\tau$, we must compute the double summation over trials $r$ and time $t$.\n\nLet's analyze the case for $\\tau \\ge 0$. The core operation is a sum of products: $\\sum_{r,t} X_{i,r,t} Y_{j,r,t+\\tau}$. This operation must be performed for all pairs and trials at once. This is a batched dot product. We can achieve this with slicing and element-wise multiplication:\n1.  Slice `X_pairs` to get the relevant time window: `X_slice = X_pairs[:, :, 0:T-\\tau]`. This has shape $P \\times R \\times (T-\\tau)$.\n2.  Slice `Y_pairs` to get the time-shifted window: `Y_slice = Y_pairs[:, :, \\tau:T]`. This also has shape $P \\times R \\times (T-\\tau)$.\n3.  The element-wise product `X_slice * Y_slice` yields an array of shape $P \\times R \\times (T-\\tau)$, where each element at index $(p, r, t')$ is $X_{i_p,r,t'} Y_{j_p,r,t'+\\tau}$.\n4.  The required sum over $r$ and $t$ can then be computed using `numpy.sum` over the last two axes (trials and time): `raw_sum = np.sum(X_slice * Y_slice, axis=(1, 2))`. The result is an array of shape $(P,)$, containing the unnormalized correlation sum for each pair.\n\nThe same procedure is applied using `Y_shift_pairs` to compute the unnormalized shuffle-predictor sum, `shuffled_sum`.\n`Y_shift_slice = Y_shift_pairs[:, :, \\tau:T]`\n`shuffled_sum = np.sum(X_slice * Y_shift_slice, axis=(1, 2))`\n\nThe case for $\\tau < 0$ is analogous. Let $\\tau' = |\\tau|$. The summation is $\\sum_{r,t} X_{i,r,t+\\tau'} Y_{j,r,t}$. The slices are adjusted accordingly:\n1.  `X_slice = X_pairs[:, :, \\tau':T]`\n2.  `Y_slice = Y_pairs[:, :, 0:T-\\tau']`\nThe rest of the computation follows the same logic.\n\nFor each lag $\\tau$, the shuffle-corrected correlogram for all pairs is calculated as:\n$\\tilde{C}(\\tau) = (\\text{raw\\_sum} - \\text{shuffled\\_sum}) \\times \\frac{1}{R \\, (T - |\\tau|)}$.\nThis yields a vector of length $P$.\n\nThese vectors are collected for each lag $\\tau$ into a result matrix $\\tilde{C}$ of shape $P \\times (2L+1)$. Finally, for the first pair (index $0$), we find the maximum value across all computed lags. This entire process adheres to the vectorization constraints by delegating the loops over pairs and trials to highly optimized NumPy operations.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef calculate_corrected_crosscorr(X, Y, P_indices, L):\n    \"\"\"\n    Computes the shuffle-corrected cross-correlogram for specified neuron pairs.\n\n    This implementation is fully vectorized over neuron pairs and trials.\n    A Python loop is used only for iterating over time lags, as permitted.\n    \"\"\"\n    # Extract shape parameters from the input arrays.\n    # Note: The problem statement guarantees N_A, N_B >= 1, so inputs are 3D.\n    _NA, R, T = X.shape\n    _NB = Y.shape[0]\n\n    # Use advanced indexing to select data for all specified pairs at once.\n    # This creates views of the data, avoiding explicit loops over pairs.\n    indices_A = P_indices[:, 0]\n    indices_B = P_indices[:, 1]\n    X_pairs = X[indices_A]  # Shape: (P, R, T)\n    Y_pairs = Y[indices_B]  # Shape: (P, R, T)\n\n    # Create the trial-shifted version of Y for the shuffle predictor.\n    # np.roll performs a circular shift along the specified axis.\n    # axis=1 is the trial axis. shift=-1 corresponds to (r+1) mod R.\n    Y_shift = np.roll(Y, shift=-1, axis=1)\n    Y_shift_pairs = Y_shift[indices_B] # Shape: (P, R, T)\n\n    # Initialize storage for the results.\n    num_pairs = P_indices.shape[0]\n    lag_range = np.arange(-L, L + 1)\n    num_lags = 2 * L + 1\n    C_tilde = np.zeros((num_pairs, num_lags), dtype=np.float64)\n\n    # Loop over time lags tau.\n    for i, tau in enumerate(lag_range):\n        abs_tau = abs(tau)\n\n        # The problem constraint L < T ensures T - abs_tau >= 1,\n        # so no division by zero will occur.\n        norm = 1.0 / (R * (T - abs_tau))\n\n        # Select time slices based on the sign of the lag.\n        if tau >= 0:\n            # For tau >= 0, we correlate X(t) with Y(t+tau).\n            X_slice = X_pairs[:, :, 0 : T - tau]\n            Y_slice = Y_pairs[:, :, tau : T]\n            Y_shift_slice = Y_shift_pairs[:, :, tau : T]\n        else:  # tau < 0\n            # For tau < 0, we correlate X(t+|tau|) with Y(t).\n            X_slice = X_pairs[:, :, abs_tau : T]\n            Y_slice = Y_pairs[:, :, 0 : T - abs_tau]\n            Y_shift_slice = Y_shift_pairs[:, :, 0 : T - abs_tau]\n\n        # Vectorized computation of sums.\n        # Element-wise product followed by summing over trial and time axes.\n        raw_sum = np.sum(X_slice * Y_slice, axis=(1, 2))\n        shuffled_sum = np.sum(X_slice * Y_shift_slice, axis=(1, 2))\n\n        # Compute and store the shuffle-corrected correlogram for the current lag tau.\n        C_tilde[:, i] = (raw_sum - shuffled_sum) * norm\n\n    # Extract the maximum value across all lags for the first pair in the list.\n    if num_pairs > 0:\n        max_val_first_pair = np.max(C_tilde[0, :])\n    else:\n        # Handle case with no pairs, though test cases prevent this.\n        max_val_first_pair = 0.0\n\n    # Return the result rounded to 6 decimal places as a float.\n    return round(max_val_first_pair, 6)\n\ndef solve():\n    # Define the test cases from the problem statement.\n    test_cases = []\n\n    # Case 1: Happy path\n    N_A1, N_B1, R1, T1, L1 = 2, 2, 4, 16, 3\n    P1 = np.array([[0, 1]])\n    X1 = np.zeros((N_A1, R1, T1))\n    Y1 = np.zeros((N_B1, R1, T1))\n    X1[0, :, 5] = 1\n    Y1[1, :, 5] = 1\n    X1[0, 2, 8] = 1\n    Y1[1, 2, 8] = 1\n    test_cases.append((X1, Y1, P1, L1))\n\n    # Case 2: Boundary (zero spikes in A)\n    N_A2, N_B2, R2, T2, L2 = 1, 1, 3, 10, 4\n    P2 = np.array([[0, 0]])\n    X2 = np.zeros((N_A2, R2, T2))\n    Y2 = np.zeros((N_B2, R2, T2))\n    Y2[0, 0, 1] = 1\n    Y2[0, 1, 5] = 1\n    Y2[0, 2, 7] = 1\n    test_cases.append((X2, Y2, P2, L2))\n\n    # Case 3: Boundary (single trial)\n    N_A3, N_B3, R3, T3, L3 = 1, 1, 1, 8, 2\n    P3 = np.array([[0, 0]])\n    X3 = np.zeros((N_A3, R3, T3))\n    Y3 = np.zeros((N_B3, R3, T3))\n    X3[0, 0, 2] = 1\n    X3[0, 0, 6] = 1\n    Y3[0, 0, 2] = 1\n    Y3[0, 0, 6] = 1\n    test_cases.append((X3, Y3, P3, L3))\n\n    # Case 4: Edge lag coverage (L = T - 1)\n    N_A4, N_B4, R4, T4, L4 = 1, 1, 2, 4, 3\n    P4 = np.array([[0, 0]])\n    X4 = np.zeros((N_A4, R4, T4))\n    Y4 = np.zeros((N_B4, R4, T4))\n    X4[0, 0, 0] = 1\n    X4[0, 1, 3] = 1\n    Y4[0, 0, 3] = 1\n    Y4[0, 1, 0] = 1\n    test_cases.append((X4, Y4, P4, L4))\n\n    results = []\n    for X, Y, P_indices, L in test_cases:\n        result = calculate_corrected_crosscorr(X, Y, P_indices, L)\n        results.append(result)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "Observing a peak in a shuffle-corrected cross-correlogram is not enough; we must determine if it represents a genuine neural interaction or is merely a product of random fluctuations. This requires a rigorous understanding of the statistical properties of our estimator. This exercise  guides you through the analytical derivation of the variance of the shuffle-corrected cross-correlation density, $\\mathrm{Var}[\\tilde{C}_{AB}(\\tau)]$. Mastering this derivation is key to constructing confidence intervals and performing hypothesis tests, transforming an observation into a quantitative, statistically defensible claim.",
            "id": "4192258",
            "problem": "Consider two neurons, labeled $A$ and $B$, recorded simultaneously over $K$ repeated trials of duration $T$ each during the presentation of the same stimulus. On trial $k \\in \\{1,\\dots,K\\}$, the spike trains are realizations of independent, stationary Poisson processes with constant rates $r_{A}$ and $r_{B}$ (in $\\mathrm{s}^{-1}$), respectively, and are independent across trials. Fix a time lag $\\tau$ and a correlogram bin width $\\Delta$ (in $\\mathrm{s}$). Define the raw cross-correlation density estimator at lag $\\tau$ as\n$$\n\\hat{C}^{\\mathrm{raw}}_{AB}(\\tau) \\equiv \\frac{1}{K\\,T\\,\\Delta}\\sum_{k=1}^{K}\\sum_{i \\in A_{k}}\\sum_{j \\in B_{k}} \\mathbf{1}\\{t^{(k)}_{B,j}-t^{(k)}_{A,i} \\in [\\tau,\\tau+\\Delta)\\},\n$$\nand the shift-predictor (shuffle) estimator as\n$$\n\\hat{C}^{\\mathrm{shift}}_{AB}(\\tau) \\equiv \\frac{1}{K\\,(K-1)\\,T\\,\\Delta}\\sum_{\\substack{k,k'=1\\\\k\\neq k'}}^{K}\\sum_{i \\in A_{k}}\\sum_{j \\in B_{k'}} \\mathbf{1}\\{t^{(k')}_{B,j}-t^{(k)}_{A,i} \\in [\\tau,\\tau+\\Delta)\\}.\n$$\nThe shuffle-corrected cross-correlation density is then\n$$\n\\tilde{C}_{AB}(\\tau) \\equiv \\hat{C}^{\\mathrm{raw}}_{AB}(\\tau) - \\hat{C}^{\\mathrm{shift}}_{AB}(\\tau).\n$$\nWork in the asymptotic regime where $T \\gg |\\tau|$ and $\\Delta$ is sufficiently small that expected overlaps of the $\\Delta$-sized lag windows around distinct spikes within a trial can be neglected to first order, and edge effects in time can be ignored to first order. Starting only from the definitions above and standard properties of independent stationary Poisson processes and conditional thinning, derive an analytic expression for $\\mathrm{Var}\\!\\left[\\tilde{C}_{AB}(\\tau)\\right]$ that exhibits its dependence on $K$, $\\Delta$, and the rates $r_{A}$ and $r_{B}$. Then, evaluate your expression numerically for $K=20$, $T=100\\,\\mathrm{s}$, $\\Delta=0.001\\,\\mathrm{s}$, $r_{A}=15\\,\\mathrm{s}^{-1}$, and $r_{B}=20\\,\\mathrm{s}^{-1}$. Round your final numerical answer to four significant figures. Express the variance in $\\mathrm{s}^{-4}$.",
            "solution": "The objective is to derive an analytical expression for the variance of the shuffle-corrected cross-correlation density, $\\mathrm{Var}\\!\\left[\\tilde{C}_{AB}(\\tau)\\right]$, and then to evaluate it numerically. The shuffle-corrected density is defined as $\\tilde{C}_{AB}(\\tau) \\equiv \\hat{C}^{\\mathrm{raw}}_{AB}(\\tau) - \\hat{C}^{\\mathrm{shift}}_{AB}(\\tau)$.\n\nUsing the linearity of the variance operator, we can express the desired quantity as:\n$$\n\\mathrm{Var}\\!\\left[\\tilde{C}_{AB}(\\tau)\\right] = \\mathrm{Var}\\!\\left[\\hat{C}^{\\mathrm{raw}}_{AB}(\\tau)\\right] + \\mathrm{Var}\\!\\left[\\hat{C}^{\\mathrm{shift}}_{AB}(\\tau)\\right] - 2\\,\\mathrm{Cov}\\!\\left(\\hat{C}^{\\mathrm{raw}}_{AB}(\\tau), \\hat{C}^{\\mathrm{shift}}_{AB}(\\tau)\\right)\n$$\nWe will proceed by calculating each of the three terms on the right-hand side.\n\nLet's define the number of spike pairs within a single trial $k$ that fall into the specified lag bin as:\n$$\nN_{AB}^{(k)} \\equiv \\sum_{i \\in A_{k}}\\sum_{j \\in B_{k}} \\mathbf{1}\\{t^{(k)}_{B,j}-t^{(k)}_{A,i} \\in [\\tau,\\tau+\\Delta)\\}\n$$\nSimilarly, let's define the number of spike pairs between two different trials, $k$ and $k'$, as:\n$$\nN_{AB}^{(k, k')} \\equiv \\sum_{i \\in A_{k}}\\sum_{j \\in B_{k'}} \\mathbf{1}\\{t^{(k')}_{B,j}-t^{(k)}_{A,i} \\in [\\tau,\\tau+\\Delta)\\}\n$$\nThe estimators can then be written as:\n$$\n\\hat{C}^{\\mathrm{raw}}_{AB}(\\tau) = \\frac{1}{K\\,T\\,\\Delta}\\sum_{k=1}^{K} N_{AB}^{(k)}\n$$\n$$\n\\hat{C}^{\\mathrm{shift}}_{AB}(\\tau) = \\frac{1}{K\\,(K-1)\\,T\\,\\Delta}\\sum_{k\\neq k'} N_{AB}^{(k, k')}\n$$\n\nUnder the problem's assumptions (independent stationary Poisson processes, $T \\gg |\\tau|$, small $\\Delta$), the count of pairs in a small bin of width $\\Delta$ is itself approximately a Poisson random variable.\nFor independent neurons A and B with rates $r_A$ and $r_B$, the expected number of pairs in a trial of duration $T$ within a lag bin of width $\\Delta$ is $\\mathrm{E}[N_{AB}^{(k)}] = r_A r_B T \\Delta$. This also applies to pairs from different trials, $\\mathrm{E}[N_{AB}^{(k, k')}] = r_A r_B T \\Delta$ for $k \\ne k'$, since trials are independent.\nBecause these counts are Poisson-distributed, their variance equals their mean:\n$$\n\\mathrm{Var}[N_{AB}^{(k)}] = \\mathrm{Var}[N_{AB}^{(k, k')}] = r_A r_B T \\Delta\n$$\n\nWith these statistical properties established, we can calculate the three terms.\n\n1.  **Variance of the Raw Estimator, $\\mathrm{Var}\\!\\left[\\hat{C}^{\\mathrm{raw}}_{AB}(\\tau)\\right]$**\n    The trials are independent, so the variables $N_{AB}^{(k)}$ are independent and identically distributed for $k=1, \\dots, K$.\n    $$\n    \\mathrm{Var}\\!\\left[\\hat{C}^{\\mathrm{raw}}_{AB}(\\tau)\\right] = \\mathrm{Var}\\!\\left[\\frac{1}{K\\,T\\,\\Delta}\\sum_{k=1}^{K} N_{AB}^{(k)}\\right] = \\frac{1}{(K\\,T\\,\\Delta)^2} \\sum_{k=1}^{K} \\mathrm{Var}\\!\\left[N_{AB}^{(k)}\\right]\n    $$\n    $$\n    \\mathrm{Var}\\!\\left[\\hat{C}^{\\mathrm{raw}}_{AB}(\\tau)\\right] = \\frac{1}{K^2 T^2 \\Delta^2} \\cdot K \\cdot (r_A r_B T \\Delta) = \\frac{r_A r_B}{K T \\Delta}\n    $$\n\n2.  **Variance of the Shift-Predictor, $\\mathrm{Var}\\!\\left[\\hat{C}^{\\mathrm{shift}}_{AB}(\\tau)\\right]$**\n    The calculation is more complex here because the terms $N_{AB}^{(k,k')}$ in the sum are not all independent.\n    $$\n    \\mathrm{Var}\\!\\left[\\hat{C}^{\\mathrm{shift}}_{AB}(\\tau)\\right] = \\frac{1}{(K(K-1)T\\Delta)^2} \\mathrm{Var}\\!\\left[\\sum_{k \\neq k'} N_{AB}^{(k,k')}\\right]\n    $$\n    The variance of the sum is the sum of all covariances:\n    $$\n    \\mathrm{Var}\\!\\left[\\sum_{k \\neq k'} N_{AB}^{(k,k')}\\right] = \\sum_{k \\neq k'} \\sum_{l \\neq l'} \\mathrm{Cov}\\!\\left(N_{AB}^{(k,k')}, N_{AB}^{(l,l')}\\right)\n    $$\n    We identify non-zero covariance terms:\n    -   **Case 1: $(k,k') = (l,l')$.** These are the variance terms. There are $K(K-1)$ such terms. The sum is $K(K-1) \\mathrm{Var}[N_{AB}^{(1,2)}] = K(K-1) r_A r_B T \\Delta$.\n    -   **Case 2: $k=l, k' \\neq l'$.** These terms share the spike train $A_k$. There are $K(K-1)(K-2)$ such ordered pairs of terms. We use the law of total covariance, conditioning on the spike train $A_k$. Let $n_A^{(k)}$ be the number of spikes in $A_k$.\n        $\\mathrm{Cov}(N_{AB}^{(k,k')}, N_{AB}^{(k,l')}) = \\mathrm{E}[\\mathrm{Cov}(N_{AB}^{(k,k')}, N_{AB}^{(k,l'})|A_k)] + \\mathrm{Cov}(\\mathrm{E}[N_{AB}^{(k,k')}|A_k], \\mathrm{E}[N_{AB}^{(k,l')}|A_k])$.\n        Conditional on $A_k$, the counts are independent (as $B_{k'}$ and $B_{l'}$ are independent), so the first term is $0$. The conditional expectations are $\\mathrm{E}[N_{AB}^{(k,k')}|A_k] = n_A^{(k)} r_B \\Delta$.\n        $\\mathrm{Cov} = \\mathrm{Cov}(n_A^{(k)} r_B \\Delta, n_A^{(k)} r_B \\Delta) = (r_B \\Delta)^2 \\mathrm{Var}[n_A^{(k)}]$. Since $n_A^{(k)}$ is a Poisson count over duration $T$, its variance is $r_A T$.\n        Thus, the covariance is $(r_B \\Delta)^2 (r_A T) = r_A r_B^2 T \\Delta^2$.\n    -   **Case 3: $k' = l', k \\neq l$.** These terms share spike train $B_{k'}$. By symmetry with Case 2, there are $K(K-1)(K-2)$ such pairs, and the covariance is $r_A^2 r_B T \\Delta^2$.\n    -   All other pairings have disjoint sets of trial indices, hence zero covariance.\n\n    Summing all contributions:\n    $$\n    \\mathrm{Var}\\!\\left[\\sum_{k \\neq k'} N_{AB}^{(k,k')}\\right] = K(K-1)r_A r_B T \\Delta + K(K-1)(K-2)r_A r_B^2 T \\Delta^2 + K(K-1)(K-2)r_A^2 r_B T \\Delta^2\n    $$\n    Dividing by $(K(K-1)T\\Delta)^2$:\n    $$\n    \\mathrm{Var}\\!\\left[\\hat{C}^{\\mathrm{shift}}_{AB}(\\tau)\\right] = \\frac{r_A r_B}{K(K-1)T\\Delta} + \\frac{(K-2)(r_A r_B^2 + r_A^2 r_B)}{K(K-1)T} = \\frac{r_A r_B}{K(K-1)T\\Delta} + \\frac{(K-2)r_A r_B(r_A+r_B)}{K(K-1)T}\n    $$\n\n3.  **Covariance Term, $\\mathrm{Cov}\\!\\left(\\hat{C}^{\\mathrm{raw}}_{AB}(\\tau), \\hat{C}^{\\mathrm{shift}}_{AB}(\\tau)\\right)$**\n    $$\n    \\mathrm{Cov} = \\frac{1}{K^2(K-1)(T\\Delta)^2} \\sum_{i=1}^K \\sum_{k \\neq k'} \\mathrm{Cov}\\!\\left(N_{AB}^{(i)}, N_{AB}^{(k,k')}\\right)\n    $$\n    Non-zero terms arise only when the trial indices overlap.\n    -   **Case 1: $i=k$.** We examine $\\mathrm{Cov}(N_{AB}^{(k)}, N_{AB}^{(k,k')})$ where $k' \\neq k$. These terms share spike train $A_k$. There are $K(K-1)$ such pairs. Using the same covariance law as before, conditioning on $A_k$:\n        $\\mathrm{Cov} = \\mathrm{Cov}(\\mathrm{E}[N_{AB}^{(k)}|A_k], \\mathrm{E}[N_{AB}^{(k,k')}|A_k]) = \\mathrm{Cov}(n_A^{(k)}r_B\\Delta, n_A^{(k)}r_B\\Delta) = r_A r_B^2 T \\Delta^2$.\n    -   **Case 2: $i=k'$.** We examine $\\mathrm{Cov}(N_{AB}^{(k')}, N_{AB}^{(k,k')})$ where $k \\neq k'$. These terms share spike train $B_{k'}$. There are $K(K-1)$ such pairs, and by symmetry, the covariance is $r_A^2 r_B T \\Delta^2$.\n\n    Summing these contributions gives $K(K-1)(r_A r_B^2 T \\Delta^2 + r_A^2 r_B T \\Delta^2)$.\n    $$\n    \\mathrm{Cov}\\!\\left(\\hat{C}^{\\mathrm{raw}}_{AB}, \\hat{C}^{\\mathrm{shift}}_{AB}\\right) = \\frac{K(K-1) T \\Delta^2 r_A r_B (r_A+r_B)}{K^2(K-1)(T\\Delta)^2} = \\frac{r_A r_B (r_A+r_B)}{K T}\n    $$\n\n4.  **Assembling the Final Expression**\n    We now substitute these three results into the main variance formula:\n    $$\n    \\mathrm{Var}[\\tilde{C}_{AB}] = \\left(\\frac{r_A r_B}{K T \\Delta}\\right) + \\left(\\frac{r_A r_B}{K(K-1)T\\Delta} + \\frac{(K-2)r_A r_B(r_A+r_B)}{K(K-1)T}\\right) - 2\\left(\\frac{r_A r_B (r_A+r_B)}{K T}\\right)\n    $$\n    Group terms with factor $1/(T\\Delta)$:\n    $$\n    \\frac{r_A r_B}{K T \\Delta} + \\frac{r_A r_B}{K(K-1)T\\Delta} = \\frac{r_A r_B}{K T \\Delta}\\left(1 + \\frac{1}{K-1}\\right) = \\frac{r_A r_B}{K T \\Delta}\\left(\\frac{K}{K-1}\\right) = \\frac{r_A r_B}{(K-1)T\\Delta}\n    $$\n    Group the remaining terms:\n    $$\n    \\frac{(K-2)r_A r_B(r_A+r_B)}{K(K-1)T} - \\frac{2r_A r_B (r_A+r_B)}{K T} = \\frac{r_A r_B(r_A+r_B)}{KT} \\left( \\frac{K-2}{K-1} - 2 \\right)\n    $$\n    $$\n    = \\frac{r_A r_B(r_A+r_B)}{KT} \\left( \\frac{K-2 - 2(K-1)}{K-1} \\right) = \\frac{r_A r_B(r_A+r_B)}{KT} \\left( \\frac{-K}{K-1} \\right) = -\\frac{r_A r_B(r_A+r_B)}{(K-1)T}\n    $$\n    Combining these two results gives the final analytical expression for the variance:\n    $$\n    \\mathrm{Var}\\!\\left[\\tilde{C}_{AB}(\\tau)\\right] = \\frac{r_A r_B}{(K-1)T\\Delta} - \\frac{r_A r_B(r_A+r_B)}{(K-1)T} = \\frac{r_A r_B}{(K-1)T} \\left( \\frac{1}{\\Delta} - (r_A+r_B) \\right)\n    $$\n\n5.  **Numerical Evaluation**\n    We are given the following values:\n    $K=20$, $T=100\\,\\mathrm{s}$, $\\Delta=0.001\\,\\mathrm{s}$, $r_{A}=15\\,\\mathrm{s}^{-1}$, and $r_{B}=20\\,\\mathrm{s}^{-1}$.\n    Substituting these into the derived expression:\n    $$\n    \\mathrm{Var}\\!\\left[\\tilde{C}_{AB}(\\tau)\\right] = \\frac{(15)(20)}{(20-1)(100)} \\left( \\frac{1}{0.001} - (15+20) \\right)\n    $$\n    $$\n    = \\frac{300}{(19)(100)} \\left( 1000 - 35 \\right)\n    $$\n    $$\n    = \\frac{3}{19} (965) = \\frac{2895}{19}\n    $$\n    $$\n    \\approx 152.368421\\dots\n    $$\n    Rounding to four significant figures, the numerical value for the variance is $152.4\\,\\mathrm{s}^{-4}$.",
            "answer": "$$\\boxed{152.4}$$"
        }
    ]
}