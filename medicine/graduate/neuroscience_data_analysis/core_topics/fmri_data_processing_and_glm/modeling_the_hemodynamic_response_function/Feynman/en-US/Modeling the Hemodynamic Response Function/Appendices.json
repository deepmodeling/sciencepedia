{
    "hands_on_practices": [
        {
            "introduction": "The General Linear Model (GLM) is the cornerstone of statistical analysis in fMRI, allowing us to test hypotheses about brain activity. A critical step in applying the GLM is constructing the design matrix, which embodies our predictions of the BOLD signal based on experimental events. This exercise  provides hands-on practice in the fundamental process of generating these predictions by numerically convolving a model of neural activity with the Hemodynamic Response Function (HRF) and correctly sampling the result at the scanner's repetition time ($T_R$). Mastering this procedure is essential for understanding how fMRI models are built and for appreciating the importance of temporal precision in the analysis.",
            "id": "4149325",
            "problem": "You are analyzing functional Magnetic Resonance Imaging (fMRI) time series with a General Linear Model (GLM), where the neuronal events for each condition are modeled as event regressors, convolved with a Hemodynamic Response Function (HRF). Starting from the definition of continuous-time convolution and the GLM, derive and implement the construction of a discrete-time design matrix by convolving event regressors with the HRF kernel and sampling at acquisition times. Additionally, explain and implement how a set of basis functions enables flexible modeling of the HRF as a linear combination of basis elements.\n\nUse the following foundational base:\n- The General Linear Model (GLM) for discrete samples is defined as $y[n] = \\sum_{j=1}^{p} X[n,j] \\,\\beta_j + \\varepsilon[n]$, where $y[n]$ is the measured signal at sample index $n$, $X[n,j]$ are the regressors (design matrix columns), $\\beta_j$ are coefficients, and $\\varepsilon[n]$ is noise.\n- Continuous-time convolution of two functions $s(t)$ and $h(t)$ is defined as $(s * h)(t) = \\int_{-\\infty}^{\\infty} s(\\tau)\\,h(t - \\tau)\\,d\\tau$. In this setting, $s(t)$ is the event regressor and $h(t)$ is the HRF.\n- Discrete-time sampling at acquisition times $t_n = n\\,\\Delta$ is modeled by $x[n] = (s * h)(t_n)$, where $\\Delta$ is the sampling interval (Repetition Time, $T_R$).\n\nYou must implement the design matrix construction using a numerically stable Riemann-sum approximation to the convolution integral at a high-resolution temporal grid with step $\\delta t$, followed by sampling at the acquisition times $t_n = n\\,T_R$. All time quantities must be treated in seconds, and the answer must respect unit consistency. Amplitudes are dimensionless.\n\nDefine the event regressor $s_c(t)$ for condition $c$ as a sum of boxcar functions with unit amplitude:\n$$\ns_c(t) = \\sum_{i=1}^{N_c} \\mathbf{1}\\{t \\in [o_{c,i},\\,o_{c,i} + d_{c,i})\\},\n$$\nwhere $o_{c,i}$ are onsets in seconds, $d_{c,i}$ are durations in seconds, and $\\mathbf{1}\\{\\cdot\\}$ is the indicator function. The design matrix has one column per pair $(c,k)$, where $c$ indexes conditions and $k$ indexes HRF basis functions. For a single HRF $h(t)$, the column for condition $c$ is $x_c[n] = (s_c * h)(t_n)$. For a set of basis functions $\\{b_k(t)\\}_{k=1}^K$, use columns $x_{c,k}[n] = (s_c * b_k)(t_n)$ so that a flexible HRF $h(t)$ can be represented as $h(t) = \\sum_{k=1}^K \\alpha_k\\,b_k(t)$ and estimated via the GLM coefficients $\\{\\alpha_k\\}$.\n\nTo be scientifically realistic and numerically stable:\n- Implement the convolution via Riemann-sum discretization on a high-resolution grid with step $\\delta t$ (e.g., $\\delta t = 0.1\\,\\mathrm{s}$) using the approximation $(s * h)(t) \\approx \\delta t \\sum_{m} s(m\\,\\delta t)\\,h(t - m\\,\\delta t)$.\n- Ensure causality by taking $h(t) = 0$ for $t < 0$ and truncating the convolution to the acquisition window $[0, T)$, where $T$ is the total scan length in seconds.\n- Basis functions must be causal and supported on $[0,\\infty)$. For this problem, use a double-gamma HRF as the canonical basis element and build additional basis elements by time-shifting the canonical element by fixed delays. Concretely, define the canonical HRF $b_1(t)$ as\n$$\nb_1(t) = g(t; k_1, \\theta_1) - r\\,g(t; k_2, \\theta_2),\n$$\nwith $g(t;k,\\theta) = \\frac{t^{k-1} e^{-t/\\theta}}{\\theta^k \\,\\Gamma(k)}$ for $t \\ge 0$ and $g(t;k,\\theta) = 0$ for $t < 0$, and parameters $(k_1,\\theta_1)$ and $(k_2,\\theta_2)$ as specified in the test suite below. Let $b_2(t) = b_1(t - \\delta_1)$ and $b_3(t) = b_1(t - \\delta_2)$ with fixed delays $\\delta_1$ and $\\delta_2$ in seconds, and $b_k(t) = 0$ for $t < 0$.\n\nExpress all times in seconds. There are no angles involved. All outputs must be dimensionless real numbers.\n\nImplement a program that, for each test case, constructs the design matrix and computes the specified scalar diagnostic metric. Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (e.g., \"[result1,result2,result3]\"). The metrics for each test case are:\n\n- Test Case $1$ (happy path, single HRF):\n  - Parameters: total scan length $T = 60\\,\\mathrm{s}$, $T_R = 2\\,\\mathrm{s}$, high-resolution step $\\delta t = 0.1\\,\\mathrm{s}$, conditions $C = 2$.\n  - Condition $1$: onsets $[0, 12, 24]\\,\\mathrm{s}$, durations $[1, 1, 1]\\,\\mathrm{s}$.\n  - Condition $2$: onsets $[6, 18, 30]\\,\\mathrm{s}$, durations $[2, 2, 2]\\,\\mathrm{s}$.\n  - Canonical HRF parameters: $(k_1, \\theta_1) = (6, 1)$, $(k_2, \\theta_2) = (12, 1)$, ratio $r = 0.35$, HRF support truncated at $L = 32\\,\\mathrm{s}$.\n  - Basis: single element $b_1(t)$.\n  - Metric: the Frobenius norm of the design matrix, i.e., $\\|X\\|_F = \\sqrt{\\sum_{n,j} X[n,j]^2}$.\n\n- Test Case $2$ (basis flexibility via time shifts):\n  - Parameters: $T = 60\\,\\mathrm{s}$, $T_R = 2\\,\\mathrm{s}$, $\\delta t = 0.1\\,\\mathrm{s}$, conditions $C = 1$.\n  - Condition $1$: onsets $[10, 20, 40]\\,\\mathrm{s}$, durations $[0.5, 0.5, 0.5]\\,\\mathrm{s}$.\n  - Canonical HRF $b_1(t)$ as in Test Case $1$, HRF support $L = 32\\,\\mathrm{s}$.\n  - Basis: three elements $\\{b_1(t), b_1(t - \\delta_1), b_1(t - \\delta_2)\\}$ with delays $\\delta_1 = 1\\,\\mathrm{s}$, $\\delta_2 = 2\\,\\mathrm{s}$.\n  - Metric: the smallest singular value of $X$, i.e., $\\min \\sigma_i(X)$.\n\n- Test Case $3$ (boundary condition near scan end):\n  - Parameters: $T = 50\\,\\mathrm{s}$, $T_R = 2\\,\\mathrm{s}$, $\\delta t = 0.1\\,\\mathrm{s}$, conditions $C = 1$.\n  - Condition $1$: onsets $[45]\\,\\mathrm{s}$, durations $[2]\\,\\mathrm{s}$.\n  - Basis: single element $b_1(t)$ with canonical parameters as in Test Case $1$, HRF support $L = 32\\,\\mathrm{s}$.\n  - Metric: the sum of the last $5$ sampled entries in the single-column design matrix, i.e., $\\sum_{n = N-5}^{N-1} X[n,1]$, where $N = T / T_R$.\n\n- Test Case $4$ (aliasing under coarse sampling, comparison of two convolution schemes):\n  - Parameters: $T = 64\\,\\mathrm{s}$, $T_R = 4\\,\\mathrm{s}$, high-resolution step $\\delta t = 0.1\\,\\mathrm{s}$, conditions $C = 1$.\n  - Condition $1$: onsets $[0, 8, 16, 24, 32, 40, 48, 56]\\,\\mathrm{s}$, durations $[1, 1, 1, 1, 1, 1, 1, 1]\\,\\mathrm{s}$.\n  - Basis: single element $b_1(t)$ with canonical parameters as in Test Case $1$, HRF support $L = 32\\,\\mathrm{s}$.\n  - Compute two design columns: \n    - Method A (naïve $T_R$-grid convolution): construct $s_{T_R}[n] = \\mathbf{1}\\{[n\\,T_R, (n+1)\\,T_R)$ contains any event$\\}$, sample $b_1$ on the $T_R$ grid as $h_{T_R}[m] = b_1(m\\,T_R)$, then compute the discrete convolution $x_A[n] \\approx T_R\\sum_{m} s_{T_R}[m]\\,h_{T_R}[n-m]$ and truncate to the acquisition window.\n    - Method B (high-resolution convolution followed by sampling): compute $x_B[n] = (s * b_1)(n\\,T_R)$ using the high-resolution Riemann-sum approximation with step $\\delta t$.\n  - Metric: the maximum absolute discrepancy $\\max_{0 \\le n < N} |x_A[n] - x_B[n]|$, where $N = T / T_R$.\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets in the order of Test Case $1$, Test Case $2$, Test Case $3$, and Test Case $4$, i.e., \"[r1,r2,r3,r4]\". All numeric outputs must be real-valued floats (dimensionless). No additional text should be printed.",
            "solution": "The problem requires the derivation and implementation of a method to construct a design matrix for a General Linear Model (GLM) in the context of fMRI data analysis. This process involves modeling neuronal activity as event regressors, convolving them with a Hemodynamic Response Function (HRF) or a set of HRF basis functions, and sampling the result at the fMRI acquisition times.\n\nThe foundation of the analysis is the GLM, which models the observed fMRI time series $y[n]$ at discrete sample points $n$ as a linear combination of predictors. The model is given by:\n$$\ny[n] = X \\vec{\\beta} + \\vec{\\varepsilon} \\quad \\text{or component-wise} \\quad y[n] = \\sum_{j=1}^{p} X[n,j] \\,\\beta_j + \\varepsilon[n]\n$$\nHere, $y[n]$ is the signal at the $n$-th acquisition time $t_n = n \\cdot T_R$, where $T_R$ is the Repetition Time. $X$ is the design matrix, whose columns are the regressors. $\\vec{\\beta}$ is a vector of coefficients to be estimated, and $\\vec{\\varepsilon}$ represents the noise. The core task is to construct the design matrix $X$.\n\nThe underlying neuronal process is conceptualized in continuous time, $t$. A regressor in the GLM, $X[n, j]$, represents the predicted BOLD signal at time $t_n$ due to a specific experimental condition. This prediction is generated by convolving a stimulus function $s(t)$, which models the neuronal activity, with a hemodynamic response function $h(t)$, which models the physiological vascular response. The continuous-time convolution is defined as:\n$$\n(s * h)(t) = \\int_{-\\infty}^{\\infty} s(\\tau)\\,h(t - \\tau)\\,d\\tau\n$$\nThe sampled regressor is then $x[n] = (s * h)(t_n)$.\n\nThe procedure can be broken down into the following steps:\n\n1.  **Temporal Discretization:**\n    To perform the convolution numerically, we must move from continuous time $t$ to a discrete representation. Two time grids are relevant:\n    a. A high-resolution grid with a small time step $\\delta t$ (e.g., $\\delta t = 0.1\\,\\mathrm{s}$). This grid is used to accurately represent the shape of the event regressors and the HRF, and to approximate the convolution integral. The time points are $m\\,\\delta t$ for integers $m$.\n    b. The acquisition grid (or $T_R$ grid) with a time step equal to the scanner's Repetition Time, $T_R$ (e.g., $T_R = 2\\,\\mathrm{s}$). The final design matrix is defined on this grid, with time points $t_n = n\\,T_R$.\n\n2.  **Constructing Event Regressors on the High-Resolution Grid:**\n    For each experimental condition $c$, the event regressor $s_c(t)$ is defined as a series of boxcar functions:\n    $$\n    s_c(t) = \\sum_{i=1}^{N_c} \\mathbf{1}\\{t \\in [o_{c,i},\\,o_{c,i} + d_{c,i})\\}\n    $$\n    where $\\{o_{c,i}\\}$ are the event onsets and $\\{d_{c,i}\\}$ are the event durations. This continuous function is discretized on the high-resolution grid. For each time point $m\\,\\delta t$ on this grid, we evaluate $s_c(m\\,\\delta t)$, creating a vector $s_c[m]$ that is $1$ if $m\\,\\delta t$ falls within any event window for condition $c$, and $0$ otherwise.\n\n3.  **Constructing HRF Basis Kernels:**\n    The problem specifies a set of basis functions $\\{b_k(t)\\}$ to flexibly model the HRF. The canonical basis function $b_1(t)$ is the double-gamma function:\n    $$\n    b_1(t) = g(t; k_1, \\theta_1) - r\\,g(t; k_2, \\theta_2) \\quad \\text{for } t \\ge 0\n    $$\n    where $g(t;k,\\theta) = \\frac{t^{k-1} e^{-t/\\theta}}{\\theta^k \\,\\Gamma(k)}$ is the probability density function of the Gamma distribution, scaled. The function $\\Gamma(k)$ is the gamma function. This function, and any other basis elements derived from it (e.g., $b_2(t) = b_1(t - \\delta_1)$), are evaluated on the high-resolution grid. Due to causality, $b_k(t) = 0$ for $t < 0$. We create discrete kernels $b_k[m] = b_k(m\\,\\delta t)$ for each basis function. The kernels are truncated at a specified support length $L$.\n\n4.  **Numerical Convolution:**\n    The continuous convolution integral is approximated by a discrete convolution on the high-resolution grid using a Riemann sum. For a given time $t_j = j\\,\\delta t$:\n    $$\n    (s_c * b_k)(t_j) = \\int_0^{t_j} s_c(\\tau)\\,b_k(t_j - \\tau)\\,d\\tau \\approx \\sum_{m=0}^{j} s_c(m\\,\\delta t)\\,b_k(t_j - m\\,\\delta t) \\,\\delta t\n    $$\n    The integral limits reflect causality ($s_c(\\tau)=0$ for $\\tau<0$ and $b_k(t_j - \\tau)=0$ for $\\tau>t_j$). The expression $\\sum_{m=0}^{j} s_c[m]\\,b_k[j-m]$ is a standard discrete-time convolution. After performing this convolution, the result is scaled by $\\delta t$ to correctly approximate the integral's value. This yields a predicted BOLD response on the high-resolution time grid.\n\n5.  **Sampling at Acquisition Times:**\n    The high-resolution predicted BOLD signal must be sampled at the acquisition times $t_n = n\\,T_R$ to form the columns of the design matrix $X$. Let the high-resolution convolved signal be $x^{\\text{high-res}}_{c,k}[m]$. The final regressor column is:\n    $$\n    x_{c,k}[n] = x^{\\text{high-res}}_{c,k}[m] \\quad \\text{where} \\quad m\\,\\delta t = n\\,T_R\n    $$\n    This is effectively a downsampling operation, where we select the values from the high-resolution signal that correspond to the $T_R$ time points.\n\n6.  **Assembling the Design Matrix:**\n    The final design matrix $X$ is formed by concatenating the generated regressor columns $x_{c,k}[n]$. Each column corresponds to a unique pair of condition $c$ and basis function $k$. The number of rows in $X$ equals the number of scans in the scan duration, $N = T/T_R$. The number of columns is the total number of regressors, i.e., (number of conditions) $\\times$ (number of basis functions).\n\n7.  **Comparison with Naïve Convolution (Test Case 4):**\n    A naïve approach might be to discretize both the stimulus $s(t)$ and the HRF $h(t)$ directly onto the coarse $T_R$ grid and perform the convolution there. This is Method A in the problem statement. Specifically, one would create $s_{T_R}[n]$ by checking if any stimulus event occurs within the interval $[n\\,T_R, (n+1)\\,T_R)$, and create $h_{T_R}[m] = h(m\\,T_R)$. The discrete convolution $x_A[n] = T_R\\sum_m s_{T_R}[m]\\,h_{T_R}[n-m]$ would then be computed. This method is flawed because it smears the temporal precision of the stimulus onset and duration, and it undersamples the HRF, leading to aliasing. The high-resolution convolution followed by sampling (Method B) is the correct approach as it respects the temporal structure of the signals before sampling, consistent with the sampling theorem. The discrepancy $|x_A[n] - x_B[n]|$ highlights the error introduced by the naïve method.\n\nThis principled procedure ensures that the design matrix accurately reflects the timing of neural events and the continuous dynamics of the hemodynamic response, providing a sound basis for statistical inference with the GLM.",
            "answer": "```python\nimport numpy as np\nfrom scipy.signal import convolve\nfrom scipy.special import gamma as gamma_func\n\ndef solve():\n    \"\"\"\n    Solves all four test cases for constructing an fMRI design matrix and computes the required metrics.\n    \"\"\"\n\n    def get_gamma_pdf(t, k, theta):\n        \"\"\"\n        Computes the value of the gamma distribution's PDF-like function g(t; k, theta).\n        \"\"\"\n        # Ensure t is non-negative for the formula to be valid\n        t_non_negative = np.maximum(t, 0)\n        # Avoid division by zero or log of zero for t=0 and k=1\n        with np.errstate(divide='ignore', invalid='ignore'):\n            val = (t_non_negative**(k - 1) * np.exp(-t_non_negative / theta)) / (theta**k * gamma_func(k))\n        val[t < 0] = 0\n        val[np.isnan(val)] = 0 # Handle potential 0^0 issues when k=1 and t=0\n        return val\n\n    def get_double_gamma_hrf(t, k1, theta1, k2, theta2, r):\n        \"\"\"\n        Computes the double-gamma HRF.\n        \"\"\"\n        h = get_gamma_pdf(t, k1, theta1) - r * get_gamma_pdf(t, k2, theta2)\n        return h\n\n    def construct_design_matrix(T, TR, dt, conditions, basis_kernels):\n        \"\"\"\n        Constructs the design matrix using high-resolution convolution and TR sampling.\n        \"\"\"\n        num_scans = int(T / TR)\n        high_res_t = np.arange(0, T, dt)\n        num_high_res_points = len(high_res_t)\n\n        regressors = []\n\n        for cond_onsets, cond_durations in conditions:\n            # Create a high-resolution stimulus regressor\n            stim_hr = np.zeros(num_high_res_points)\n            for onset, duration in zip(cond_onsets, cond_durations):\n                start_idx = int(np.round(onset / dt))\n                end_idx = int(np.round((onset + duration) / dt))\n                stim_hr[start_idx:end_idx] = 1\n\n            for kernel in basis_kernels:\n                # Convolve stimulus with HRF kernel\n                # The convolution approximates the integral, so we must scale by dt.\n                convolved_hr = convolve(stim_hr, kernel, mode='full') * dt\n                \n                # Truncate to scan length\n                convolved_hr = convolved_hr[:num_high_res_points]\n\n                # Sample at TRs\n                sample_indices = (np.arange(num_scans) * TR / dt).astype(int)\n                \n                # Ensure indices are within bounds\n                valid_indices = sample_indices[sample_indices < len(convolved_hr)]\n                regressor = np.zeros(num_scans)\n                regressor[:len(valid_indices)] = convolved_hr[valid_indices]\n                \n                regressors.append(regressor)\n\n        # Handle the case of no regressors\n        if not regressors:\n            return np.zeros((num_scans, 0))\n\n        return np.column_stack(regressors)\n\n    results = []\n\n    # --- Test Case 1 ---\n    T1, TR1, dt1 = 60.0, 2.0, 0.1\n    conditions1 = [\n        (np.array([0, 12, 24]), np.array([1, 1, 1])),\n        (np.array([6, 18, 30]), np.array([2, 2, 2])),\n    ]\n    k1, theta1, k2, theta2, r = 6, 1, 12, 1, 0.35\n    L = 32.0\n    hrf_t_basis = np.arange(0, L, dt1)\n    \n    b1_kernel = get_double_gamma_hrf(hrf_t_basis, k1, theta1, k2, theta2, r)\n    basis_kernels1 = [b1_kernel]\n    \n    X1 = construct_design_matrix(T1, TR1, dt1, conditions1, basis_kernels1)\n    metric1 = np.linalg.norm(X1, 'fro')\n    results.append(metric1)\n\n    # --- Test Case 2 ---\n    T2, TR2, dt2 = 60.0, 2.0, 0.1\n    conditions2 = [\n        (np.array([10, 20, 40]), np.array([0.5, 0.5, 0.5])),\n    ]\n    delta1, delta2 = 1.0, 2.0\n\n    b1_t_shifted_0 = get_double_gamma_hrf(hrf_t_basis, k1, theta1, k2, theta2, r)\n    b1_t_shifted_1 = get_double_gamma_hrf(hrf_t_basis - delta1, k1, theta1, k2, theta2, r)\n    b1_t_shifted_2 = get_double_gamma_hrf(hrf_t_basis - delta2, k1, theta1, k2, theta2, r)\n    basis_kernels2 = [b1_t_shifted_0, b1_t_shifted_1, b1_t_shifted_2]\n\n    X2 = construct_design_matrix(T2, TR2, dt2, conditions2, basis_kernels2)\n    singular_values = np.linalg.svd(X2, compute_uv=False)\n    metric2 = singular_values.min() if singular_values.size > 0 else 0.0\n    results.append(metric2)\n\n    # --- Test Case 3 ---\n    T3, TR3, dt3 = 50.0, 2.0, 0.1\n    conditions3 = [\n        (np.array([45]), np.array([2])),\n    ]\n    basis_kernels3 = [b1_kernel]\n\n    X3 = construct_design_matrix(T3, TR3, dt3, conditions3, basis_kernels3)\n    metric3 = np.sum(X3[-5:, 0]) if X3.shape[0] >= 5 else np.sum(X3[:, 0])\n    results.append(metric3)\n\n    # --- Test Case 4 ---\n    T4, TR4, dt4 = 64.0, 4.0, 0.1\n    onsets4 = np.arange(0, 64, 8)\n    durations4 = np.ones_like(onsets4)\n    conditions4 = [(onsets4, durations4)]\n    basis_kernels4 = [b1_kernel]\n    num_scans4 = int(T4 / TR4)\n    tr_grid_t = np.arange(num_scans4) * TR4\n\n    # Method B (correct high-resolution)\n    X_B_matrix = construct_design_matrix(T4, TR4, dt4, conditions4, basis_kernels4)\n    x_B = X_B_matrix[:, 0]\n\n    # Method A (naïve TR-grid convolution)\n    s_tr = np.zeros(num_scans4)\n    for n in range(num_scans4):\n        tr_start, tr_end = n * TR4, (n + 1) * TR4\n        for onset, duration in zip(onsets4, durations4):\n            event_start, event_end = onset, onset + duration\n            if max(tr_start, event_start) < min(tr_end, event_end):\n                s_tr[n] = 1\n                break\n    \n    h_tr_t = np.arange(0, L, TR4)\n    h_tr = get_double_gamma_hrf(h_tr_t, k1, theta1, k2, theta2, r)\n\n    # Perform discrete convolution and scale by TR\n    x_A_full = convolve(s_tr, h_tr, mode='full') * TR4\n    x_A = x_A_full[:num_scans4]\n\n    metric4 = np.max(np.abs(x_A - x_B))\n    results.append(metric4)\n\n    # Final print statement\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "While the convolution model provides a powerful framework for predicting the BOLD signal, the practical reality of fMRI acquisition imposes significant constraints on what we can observe. The scanner samples the continuous BOLD signal at discrete intervals, a process that can lead to information loss. This thought experiment  explores a striking consequence of this discrete sampling: the potential to completely miss a genuine, short-lived neural signature like the HRF's \"initial dip.\" By calculating the probability of missing this feature due to the random timing of scanner acquisitions relative to the stimulus, you will gain a deeper intuition for the critical relationship between the temporal resolution of your measurement ($T_R$) and the physiological events you aim to study.",
            "id": "4178474",
            "problem": "A brief negative deflection known as the initial dip in the Hemodynamic Response Function (HRF) $h(t)$ is hypothesized to occur immediately after stimulus onset and to last for a finite duration. Consider an impulse stimulus at time $t=0$, and assume that the initial dip is a strictly negative segment of $h(t)$ supported on the interval $[0,\\Delta]$ with $\\Delta=1\\,\\text{s}$. Functional magnetic resonance imaging (fMRI) data are acquired at discrete sampling times separated by the repetition time ($T_R$), denoted $T_R=2\\,\\text{s}$. Let the sampling times be $t_k=\\phi+kT_R$ for integers $k\\geq 0$, where the phase $\\phi$ is the unknown offset between the first acquisition time following stimulus onset and the stimulus onset itself. Assume $\\phi$ is uniformly distributed on $[0,T_R)$ due to uncontrolled synchronization between stimulus onset and scanner acquisition.\n\nDefine the event that the initial dip is \"captured\" as the existence of at least one $k\\geq 0$ such that $t_k\\in[0,\\Delta]$. Otherwise, the initial dip is \"missed\" due solely to the sampling phase. Starting from first principles about discrete-time sampling of a continuous-time process and the uniform phase model, derive whether the initial dip can be reliably detected in this acquisition regime and compute the probability that the initial dip is missed due to sampling phase alone. Express the final probability as a fraction. No rounding is required.",
            "solution": "The problem is first validated to ensure it is scientifically grounded, well-posed, and objective.\n\n### Step 1: Extract Givens\n-   The Hemodynamic Response Function (HRF) is denoted by $h(t)$.\n-   An impulse stimulus occurs at time $t=0$.\n-   An initial dip in $h(t)$ is a strictly negative segment supported on the interval $[0, \\Delta]$.\n-   The duration of the dip is $\\Delta=1\\,\\text{s}$.\n-   The repetition time for fMRI data acquisition is $T_R=2\\,\\text{s}$.\n-   The discrete sampling times are $t_k = \\phi + k T_R$ for integers $k \\geq 0$.\n-   The sampling phase, $\\phi$, is a random variable uniformly distributed on the interval $[0, T_R)$.\n-   The event \"captured\" is defined as the existence of at least one integer $k \\geq 0$ such that the sampling time $t_k$ falls within the dip's interval, i.e., $t_k \\in [0, \\Delta]$.\n-   The event \"missed\" is the complement of \"captured\".\n\n### Step 2: Validate Using Extracted Givens\n-   **Scientifically Grounded**: The problem is well-grounded in the field of neuroscience data analysis, specifically functional magnetic resonance imaging (fMRI). The concepts of the HRF, its initial dip, the repetition time ($T_R$), and the effect of sampling phase ($\\phi$) are standard and fundamental to understanding fMRI signal properties. The parameter values $\\Delta=1\\,\\text{s}$ and $T_R=2\\,\\text{s}$ are realistic for fMRI experiments.\n-   **Well-Posed**: The problem is mathematically well-posed. The variables and parameters are clearly defined. The random variable $\\phi$ has a specified probability distribution. The events \"captured\" and \"missed\" are unambiguously defined, allowing for the calculation of a unique probability.\n-   **Objective**: The problem is stated in precise, objective language, free of subjective claims or ambiguity.\n\n### Step 3: Verdict and Action\nThe problem is valid as it is scientifically sound, well-posed, and objective. A solution will be derived.\n\n### Derivation\nThe objective is to compute the probability that the initial dip is \"missed\". This is the probability that no sampling time $t_k$ falls within the interval $[0, \\Delta]$. The sampling times are given by the sequence $t_k = \\phi + k T_R$ for non-negative integers $k$, where $\\phi$ is a random variable uniformly distributed on $[0, T_R)$.\n\nThe event \"captured\" occurs if there exists at least one $k \\ge 0$ such that $t_k \\in [0, \\Delta]$. This condition can be written as:\n$$0 \\le \\phi + k T_R \\le \\Delta$$\n\nThe event \"missed\" is the complement, meaning that for all $k \\ge 0$, $t_k \\notin [0, \\Delta]$. We seek to compute $P(\\text{missed})$. It is often simpler to compute the probability of the complement event, $P(\\text{captured})$, and use the relation $P(\\text{missed}) = 1 - P(\\text{captured})$.\n\nLet's analyze the condition $0 \\le \\phi + k T_R \\le \\Delta$ for different values of $k$.\n\nCase 1: $k=0$\nThe sampling time is $t_0 = \\phi$. The condition for capturing the dip at this time point is $0 \\le \\phi \\le \\Delta$. Since the domain of $\\phi$ is $[0, T_R)$ and we are given $\\Delta = 1\\,\\text{s}$ and $T_R = 2\\,\\text{s}$, so $\\Delta < T_R$, this is a possible outcome. The dip is captured at $t_0$ if $\\phi \\in [0, \\Delta]$.\n\nCase 2: $k \\ge 1$\nThe sampling times are $t_k = \\phi + k T_R$ for $k=1, 2, 3, \\ldots$. The condition for capturing the dip is $0 \\le \\phi + k T_R \\le \\Delta$.\nSince $\\phi \\in [0, T_R)$, we know $\\phi \\ge 0$. Also, since $k \\ge 1$ and $T_R>0$, the term $k T_R$ is positive. Thus, the lower bound $0 \\le \\phi + k T_R$ is always satisfied.\nThe critical part of the condition is the upper bound:\n$$\\phi + k T_R \\le \\Delta$$\nRearranging for $\\phi$, we get:\n$$\\phi \\le \\Delta - k T_R$$\nLet's substitute the given values $\\Delta=1$ and $T_R=2$:\n$$\\phi \\le 1 - 2k$$\nNow we examine this for $k \\ge 1$:\n-   For $k=1$: $\\phi \\le 1 - 2(1) = -1$.\n-   For $k=2$: $\\phi \\le 1 - 2(2) = -3$.\n-   For any integer $k \\ge 1$, the value $1 - 2k$ is a negative number.\n\nHowever, the random variable $\\phi$ is defined on the interval $[0, T_R) = [0, 2)$, which means $\\phi$ can only take non-negative values. There is no value of $\\phi$ in its domain $[0, 2)$ that can satisfy the condition $\\phi \\le \\text{negative number}$.\nTherefore, it is impossible for any sampling time $t_k$ with $k \\ge 1$ to fall within the interval $[0, \\Delta]$.\n\nThis analysis shows that the initial dip can be captured if and only if the very first sample, $t_0$, falls within the interval $[0, \\Delta]$. All subsequent samples will necessarily occur after the dip has ended.\nThe event \"captured\" is thus equivalent to the event $\\{t_0 \\in [0, \\Delta]\\}$, which is equivalent to $\\{\\phi \\in [0, \\Delta]\\}$.\nThe event \"missed\" is equivalent to the event $\\{t_0 \\notin [0, \\Delta]\\}$, which, given that $\\phi \\in [0, T_R)$, is equivalent to $\\{\\phi \\in (\\Delta, T_R)\\}$.\n\nWe can now compute the probability of the \"missed\" event directly. The variable $\\phi$ is uniformly distributed on $[0, T_R)$. The probability of $\\phi$ falling into a sub-interval is the ratio of the length of the sub-interval to the length of the total interval $[0, T_R)$.\n\nThe length of the total interval of possible values for $\\phi$ is $L_{total} = T_R - 0 = T_R$.\nThe \"missed\" event corresponds to $\\phi$ being in the sub-interval $(\\Delta, T_R)$. The length of this sub-interval is $L_{missed} = T_R - \\Delta$.\n\nThe probability of the dip being missed is:\n$$P(\\text{missed}) = \\frac{L_{missed}}{L_{total}} = \\frac{T_R - \\Delta}{T_R} = 1 - \\frac{\\Delta}{T_R}$$\n\nSubstituting the given numerical values $\\Delta = 1\\,\\text{s}$ and $T_R = 2\\,\\text{s}$:\n$$P(\\text{missed}) = 1 - \\frac{1\\,\\text{s}}{2\\,\\text{s}} = 1 - \\frac{1}{2} = \\frac{1}{2}$$\n\nThe question also asks whether the initial dip can be \"reliably detected\". A probability of $1/2$ for missing the event entirely due to random sampling phase means that in $50\\%$ of cases, no data point will be acquired during the initial dip. A detection method that fails half the time purely by chance cannot be considered reliable. Therefore, in this acquisition regime, the initial dip cannot be reliably detected.\n\nThe final computed value is the probability that the initial dip is missed.",
            "answer": "$$\\boxed{\\frac{1}{2}}$$"
        },
        {
            "introduction": "Beyond using a fixed, canonical HRF, advanced analyses often attempt to estimate the HRF's parameters directly from the data to account for variability across brain regions or individuals. However, this estimation is complicated by a fundamental issue known as parameter non-identifiability, where different sets of physiological parameters can produce nearly identical HRF shapes. This simulation exercise  allows you to explore this ambiguity firsthand. By generating HRFs from distinct parameter sets and quantifying their similarity, you will see how tradeoffs between parameters can lead to nearly indistinguishable outputs, revealing the epistemic limits of what can be uniquely recovered from BOLD signal measurements.",
            "id": "4178455",
            "problem": "You will implement a principled simulation in the context of modeling the Hemodynamic Response Function (HRF) to demonstrate parameter non-identifiability from Blood Oxygen Level Dependent (BOLD) data. The Hemodynamic Response Function (HRF) is a causal impulse response that maps latent neural activity to observed BOLD fluctuations in functional Magnetic Resonance Imaging (fMRI) under the assumption that the mapping is approximately linear and time-invariant. Your program must use a difference-of-gammas model for the HRF and compute quantitative metrics that reveal epistemic limits of parameter recovery.\n\nFundamental base. The mapping from neural drive to the BOLD signal is modeled as a linear time-invariant system where the BOLD signal is the convolution of the latent neural time course with the HRF. The HRF is modeled as a difference of two gamma density functions, which is a widely used and empirically supported form in fMRI analysis. The gamma density for shape parameter $k$ and scale parameter $\\theta$ evaluated at time $t \\ge 0$ is\n$$\ng(t; k, \\theta) = \\frac{t^{k - 1} e^{-t/\\theta}}{\\Gamma(k) \\, \\theta^{k}},\n$$\nwhere $\\Gamma(k)$ is the Euler gamma function. The difference-of-gammas HRF is defined by\n$$\nh(t; k_1, \\theta_1, k_2, \\theta_2, c, s) = s \\left( g(t; k_1, \\theta_1) - c \\, g(t; k_2, \\theta_2) \\right),\n$$\nwith $k_1 \\gt 0$, $k_2 \\gt 0$, $\\theta_1 \\gt 0$, $\\theta_2 \\gt 0$, $c \\gt 0$, and $s \\gt 0$. The parameter $c$ controls the relative weight of the post-stimulus undershoot, and $s$ is a global amplitude scaling.\n\nNumerical grid. Compute the HRF on a uniform grid $t_n = n \\Delta t$ for $n = 0, 1, \\dots, N$ with $t_N = T_{\\max}$, where $\\Delta t$ is the sampling step and $T_{\\max}$ is the maximum time span. You will also compute a discretized version on a coarser grid with sampling interval equal to the repetition time $T_R$ used in fMRI acquisition.\n\nMetrics. For each test case, given two parameter sets $\\Theta_A$ and $\\Theta_B$, compute three metrics:\n1. The minimal normalized root-mean-square error (NRMSE) between $h_A(t)$ and $h_B(t)$ under optimal global amplitude rescaling of $h_B(t)$:\n   - First compute $\\alpha^\\star$ that minimizes\n   $$\n   J(\\alpha) = \\sum_{n=0}^{N} \\left( h_A(t_n) - \\alpha \\, h_B(t_n) \\right)^2,\n   $$\n   which is given by\n   $$\n   \\alpha^\\star = \\frac{\\sum_{n=0}^{N} h_A(t_n) h_B(t_n)}{\\sum_{n=0}^{N} h_B(t_n)^2}.\n   $$\n   - Then compute the NRMSE\n   $$\n   \\mathrm{NRMSE} = \\sqrt{ \\frac{ \\sum_{n=0}^{N} \\left( h_A(t_n) - \\alpha^\\star h_B(t_n) \\right)^2 }{ \\sum_{n=0}^{N} h_A(t_n)^2 } }.\n   $$\n   This metric is dimensionless and evaluates shape similarity modulo global amplitude differences.\n2. The absolute difference in time-to-peak (TTP) between $h_A(t)$ and $h_B(t)$, defined as\n   $$\n   \\Delta \\mathrm{TTP} = \\left| t^{\\mathrm{peak}}_A - t^{\\mathrm{peak}}_B \\right|,\n   $$\n   where $t^{\\mathrm{peak}}$ is the time $t_n$ at which $h(t_n)$ attains its maximum on the grid. Express $\\Delta \\mathrm{TTP}$ in seconds.\n3. The Pearson correlation coefficient between the coarse samples $\\{ h_A(m \\cdot T_R) \\}_{m}$ and $\\{ h_B(m \\cdot T_R) \\}_{m}$:\n   $$\n   \\rho = \\frac{ \\sum_{m} \\left( h_A(m \\cdot T_R) - \\overline{h_A} \\right) \\left( h_B(m \\cdot T_R) - \\overline{h_B} \\right) }{ \\sqrt{ \\sum_{m} \\left( h_A(m \\cdot T_R) - \\overline{h_A} \\right)^2 } \\sqrt{ \\sum_{m} \\left( h_B(m \\cdot T_R) - \\overline{h_B} \\right)^2 } },\n   $$\n   where $\\overline{h_A}$ and $\\overline{h_B}$ denote the sample means over the coarse grid. This metric is dimensionless.\n\nTime units. When reporting the time-to-peak difference, express the answer in seconds. Angles are not used. Percentages must not be used; all ratios must be decimal values.\n\nTest suite. Use the following three cases to expose different facets of epistemic limits:\n\n- Case A (happy path: amplitude-only degeneracy). Let $T_{\\max} = 32$ seconds, $\\Delta t = 0.1$ seconds, $T_R = 2.0$ seconds. Define\n  $$\n  \\Theta_A = (k_1 = 6, \\theta_1 = 1, k_2 = 12, \\theta_2 = 1, c = 0.35, s = 1.0),\n  $$\n  $$\n  \\Theta_B = (k_1 = 6, \\theta_1 = 1, k_2 = 12, \\theta_2 = 1, c = 0.35, s = 1.5).\n  $$\n  These sets differ only by the amplitude $s$, which is not identifiable under global rescaling.\n- Case B (near-shape degeneracy via trade-offs in rise and dispersion). Let $T_{\\max} = 32$ seconds, $\\Delta t = 0.1$ seconds, $T_R = 2.0$ seconds. Define\n  $$\n  \\Theta_A = (k_1 = 5, \\theta_1 = 1.2, k_2 = 14, \\theta_2 = 1.0, c = 0.34, s = 1.0),\n  $$\n  $$\n  \\Theta_B = (k_1 = 4.5, \\theta_1 = 1.33, k_2 = 13.5, \\theta_2 = 1.04, c = 0.32, s = 1.03).\n  $$\n  These sets are designed to have similar effective means $k \\theta$ for each gamma component while perturbing dispersion and undershoot ratio, yielding near-identical $h(t)$ curves in practice.\n- Case C (edge case: coarse sampling reduces distinguishability). Let $T_{\\max} = 32$ seconds, $\\Delta t = 0.1$ seconds, $T_R = 3.0$ seconds. Define\n  $$\n  \\Theta_A = (k_1 = 3, \\theta_1 = 1.8, k_2 = 7, \\theta_2 = 1.8, c = 0.35, s = 1.0),\n  $$\n  $$\n  \\Theta_B = (k_1 = 6, \\theta_1 = 0.9, k_2 = 12, \\theta_2 = 0.9, c = 0.35, s = 1.0).\n  $$\n  These sets differ in time scaling but can appear similar on coarse $T_R$ sampling, stressing epistemic limits arising from acquisition constraints.\n\nOutput specification. Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets. Specifically, output a list of three sublists, one per case, where each sublist contains three floating-point values in the order $\\left[ \\mathrm{NRMSE}, \\Delta \\mathrm{TTP} \\text{ in seconds}, \\rho \\right]$. For example, an output might look like\n$$\n\\left[ [0.000000, 0.000000, 1.000000], [0.023451, 0.400000, 0.997812], [0.083519, 1.500000, 0.982301] \\right].\n$$\nRound all floating-point outputs to $6$ decimal places. The output must contain only this single line in the specified format.",
            "solution": "The user-provided problem statement is valid. It is scientifically grounded in the principles of fMRI data analysis, specifically the modeling of the hemodynamic response function (HRF) using a linear time-invariant system framework. The mathematical definitions for the difference-of-gammas HRF model and the quantitative metrics (NRMSE, $\\Delta \\mathrm{TTP}$, $\\rho$) are standard and well-posed. The problem is self-contained, providing all necessary parameters and conditions for the three test cases. The objective is clear and unambiguous, leading to a unique and verifiable numerical solution.\n\nThe solution proceeds by first implementing the core mathematical models and then applying them to calculate the specified metrics for each test case. The entire process is encapsulated in a Python program that adheres to the specified execution environment.\n\n1.  **Hemodynamic Response Function (HRF) Model Implementation**\n    The foundation of the simulation is the difference-of-gammas model for the HRF. The gamma probability density function, $g(t; k, \\theta)$, for a shape parameter $k > 0$ and a scale parameter $\\theta > 0$ is defined as:\n    $$\n    g(t; k, \\theta) = \\frac{t^{k - 1} e^{-t/\\theta}}{\\Gamma(k) \\, \\theta^{k}}, \\quad t \\ge 0\n    $$\n    where $\\Gamma(k)$ is the Euler gamma function, which will be computed using `scipy.special.gamma`. A helper function is implemented to compute $g(t; k, \\theta)$ over a discrete time vector $t$. Special care is taken for the point $t=0$. Since all shape parameters $k$ provided in the test cases are greater than $1$, $g(0; k, \\theta) = 0$. The implementation handles this by evaluating the formula only for $t > 0$ and setting the value at $t=0$ to $0$.\n\n    The HRF, $h(t)$, is then constructed as a weighted difference of two such gamma functions:\n    $$\n    h(t; k_1, \\theta_1, k_2, \\theta_2, c, s) = s \\left( g(t; k_1, \\theta_1) - c \\, g(t; k_2, \\theta_2) \\right)\n    $$\n    Another function implements this by calling the gamma PDF function twice with the respective parameters $(k_1, \\theta_1)$ and $(k_2, \\theta_2)$, and then combining them according to the formula with the undershoot ratio $c$ and the global scaling factor $s$.\n\n2.  **Numerical Grid Generation**\n    For each test case, a high-resolution time grid is created, spanning from $t=0$ to $T_{\\max}$ with a step size of $\\Delta t$. This grid, denoted as $\\{t_n\\}$, is used for the primary computation of the HRF shapes and for two of the three metrics. The number of points on this grid is $N+1$, where $N = T_{\\max} / \\Delta t$.\n\n3.  **Metric Computation Algorithm**\n    For each pair of parameter sets, $\\Theta_A$ and $\\Theta_B$, the corresponding HRFs, $h_A(t)$ and $h_B(t)$, are generated on the fine time grid. Subsequently, three metrics are computed to quantify their similarity and differences.\n\n    -   **Normalized Root-Mean-Square Error (NRMSE)**: This metric assesses the shape similarity between $h_A(t)$ and $h_B(t)$ independent of global amplitude. First, an optimal scaling factor $\\alpha^\\star$ is computed to minimize the squared error between $h_A$ and a rescaled $h_B$. This is a standard linear least-squares problem, and the solution is given by:\n        $$\n        \\alpha^\\star = \\frac{\\sum_{n=0}^{N} h_A(t_n) h_B(t_n)}{\\sum_{n=0}^{N} h_B(t_n)^2} = \\frac{\\mathbf{h}_A \\cdot \\mathbf{h}_B}{\\mathbf{h}_B \\cdot \\mathbf{h}_B}\n        $$\n        where $\\mathbf{h}_A$ and $\\mathbf{h}_B$ are vectors of the HRF values on the fine grid. The NRMSE is then the root-mean-square of the residual error, normalized by the norm of $\\mathbf{h}_A$:\n        $$\n        \\mathrm{NRMSE} = \\sqrt{ \\frac{ \\sum_{n=0}^{N} \\left( h_A(t_n) - \\alpha^\\star h_B(t_n) \\right)^2 }{ \\sum_{n=0}^{N} h_A(t_n)^2 } }\n        $$\n\n    -   **Difference in Time-to-Peak ($\\Delta \\mathrm{TTP}$)**: This metric captures differences in the temporal dynamics. The time-to-peak for each HRF, $t^{\\mathrm{peak}}_A$ and $t^{\\mathrm{peak}}_B$, is found by locating the index of the maximum value of the function on the fine discrete grid and retrieving the corresponding time value. The absolute difference is then calculated:\n        $$\n        \\Delta \\mathrm{TTP} = \\left| t^{\\mathrm{peak}}_A - t^{\\mathrm{peak}}_B \\right|\n        $$\n\n    -   **Pearson Correlation ($\\rho$)**: This metric evaluates the linear relationship between the two HRFs, but specifically on a coarse grid that simulates the temporal resolution of an fMRI acquisition. The coarse grid is defined by the repetition time, $T_R$. The HRF time courses are downsampled by selecting values at time points $m \\cdot T_R$ for $m=0, 1, 2, \\dots$. Since $T_R$ is an integer multiple of $\\Delta t$ in all test cases, this is achieved by simple array slicing with a step of $T_R/\\Delta t$. The Pearson correlation coefficient $\\rho$ is then computed between these two coarse-sampled vectors, $\\{h_A(m \\cdot T_R)\\}_m$ and $\\{h_B(m \\cdot T_R)\\}_m$.\n\n4.  **Execution and Output Formatting**\n    The main program logic iterates through the three test cases provided. For each case, it unpacks the grid parameters ($T_{\\max}, \\Delta t, T_R$) and the two HRF parameter sets ($\\Theta_A, \\Theta_B$). It orchestrates the generation of the HRF curves and the computation of the three metrics. The resulting triplet of floating-point numbers $[\\mathrm{NRMSE}, \\Delta \\mathrm{TTP}, \\rho]$ for each case is collected. Finally, the results for all cases are formatted into a single string as a list of lists, with each numerical value rounded to $6$ decimal places, and printed to standard output as per the problem specification.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.special import gamma as gamma_function\n\ndef gamma_pdf(t: np.ndarray, k: float, theta: float) -> np.ndarray:\n    \"\"\"\n    Computes the Gamma probability density function.\n    \n    Args:\n        t (np.ndarray): Time vector.\n        k (float): Shape parameter.\n        theta (float): Scale parameter.\n        \n    Returns:\n        np.ndarray: The values of the Gamma PDF at times t.\n    \"\"\"\n    if k <= 0 or theta <= 0:\n        return np.zeros_like(t, dtype=float)\n\n    # For k > 1 (as in this problem), g(0) = 0. For k=1, g(0)=1/theta. \n    # For k < 1, g(0) is infinite.\n    # The current implementation is robust for k > 0.\n    result = np.zeros_like(t, dtype=float)\n    \n    # Calculate for t > 0 to avoid numerical issues like 0**negative_power if k < 1.\n    mask = t > 0\n    t_pos = t[mask]\n    \n    numerator = np.power(t_pos, k - 1) * np.exp(-t_pos / theta)\n    denominator = gamma_function(k) * np.power(theta, k)\n    \n    if denominator > 0:\n        result[mask] = numerator / denominator\n        \n    return result\n\ndef hrf(t: np.ndarray, k1: float, theta1: float, k2: float, theta2: float, c: float, s: float) -> np.ndarray:\n    \"\"\"\n    Computes the difference-of-gammas Hemodynamic Response Function (HRF).\n    \n    Args:\n        t (np.ndarray): Time vector.\n        k1, theta1: Parameters for the first gamma function.\n        k2, theta2: Parameters for the second gamma function.\n        c (float): Relative weight of the second gamma (undershoot).\n        s (float): Global amplitude scaling.\n        \n    Returns:\n        np.ndarray: The HRF evaluated at times t.\n    \"\"\"\n    g1 = gamma_pdf(t, k1, theta1)\n    g2 = gamma_pdf(t, k2, theta2)\n    return s * (g1 - c * g2)\n\ndef solve():\n    \"\"\"\n    Main function to run the simulation for all test cases and print results.\n    \"\"\"\n    test_cases = [\n        {\n            'label': 'Case A',\n            'T_max': 32.0, 'dt': 0.1, 'TR': 2.0,\n            'Theta_A': {'k1': 6.0, 'theta1': 1.0, 'k2': 12.0, 'theta2': 1.0, 'c': 0.35, 's': 1.0},\n            'Theta_B': {'k1': 6.0, 'theta1': 1.0, 'k2': 12.0, 'theta2': 1.0, 'c': 0.35, 's': 1.5}\n        },\n        {\n            'label': 'Case B',\n            'T_max': 32.0, 'dt': 0.1, 'TR': 2.0,\n            'Theta_A': {'k1': 5.0, 'theta1': 1.2, 'k2': 14.0, 'theta2': 1.0, 'c': 0.34, 's': 1.0},\n            'Theta_B': {'k1': 4.5, 'theta1': 1.33, 'k2': 13.5, 'theta2': 1.04, 'c': 0.32, 's': 1.03}\n        },\n        {\n            'label': 'Case C',\n            'T_max': 32.0, 'dt': 0.1, 'TR': 3.0,\n            'Theta_A': {'k1': 3.0, 'theta1': 1.8, 'k2': 7.0, 'theta2': 1.8, 'c': 0.35, 's': 1.0},\n            'Theta_B': {'k1': 6.0, 'theta1': 0.9, 'k2': 12.0, 'theta2': 0.9, 'c': 0.35, 's': 1.0}\n        }\n    ]\n\n    all_results = []\n    for case in test_cases:\n        T_max, dt, TR = case['T_max'], case['dt'], case['TR']\n        \n        # 1. Generate time grid and HRFs\n        num_points = int(T_max / dt) + 1\n        t = np.linspace(0, T_max, num_points)\n        \n        h_A = hrf(t, **case['Theta_A'])\n        h_B = hrf(t, **case['Theta_B'])\n\n        # 2. Compute metrics\n        \n        # Metric 1: NRMSE\n        hA_dot_hB = np.dot(h_A, h_B)\n        hB_dot_hB = np.dot(h_B, h_B)\n        alpha_star = hA_dot_hB / hB_dot_hB if hB_dot_hB > 0 else 0.0\n        \n        hA_dot_hA = np.dot(h_A, h_A)\n        residual_sq_sum = np.sum(np.power(h_A - alpha_star * h_B, 2))\n        nrmse = np.sqrt(residual_sq_sum / hA_dot_hA) if hA_dot_hA > 0 else 0.0\n\n        # Metric 2: Delta TTP\n        t_peak_A = t[np.argmax(h_A)]\n        t_peak_B = t[np.argmax(h_B)]\n        delta_ttp = np.abs(t_peak_A - t_peak_B)\n\n        # Metric 3: Pearson Correlation on coarse grid\n        coarse_sample_step = int(round(TR / dt))\n        h_A_coarse = h_A[::coarse_sample_step]\n        h_B_coarse = h_B[::coarse_sample_step]\n        \n        # Ensure there are at least 2 points for correlation\n        if len(h_A_coarse) < 2:\n            rho = np.nan # Undefined correlation\n        else:\n            correlation_matrix = np.corrcoef(h_A_coarse, h_B_coarse)\n            rho = correlation_matrix[0, 1]\n\n        all_results.append([nrmse, delta_ttp, rho])\n\n    # 3. Format and print output\n    formatted_case_results = []\n    for R in all_results:\n        # Format each triplet [nrmse, dttp, rho] with 6 decimal places\n        formatted_case_results.append(f\"[{R[0]:.6f},{R[1]:.6f},{R[2]:.6f}]\")\n    \n    final_output_string = f\"[{','.join(formatted_case_results)}]\"\n    print(final_output_string)\n\nsolve()\n```"
        }
    ]
}