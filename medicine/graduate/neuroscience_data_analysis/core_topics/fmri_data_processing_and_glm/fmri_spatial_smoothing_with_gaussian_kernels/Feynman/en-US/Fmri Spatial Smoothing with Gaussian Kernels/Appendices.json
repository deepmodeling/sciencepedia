{
    "hands_on_practices": [
        {
            "introduction": "A foundational task in preparing fMRI data for analysis is translating a desired physical smoothing effect, specified in millimeters, into the correct parameters for a discrete computational kernel. Since fMRI voxels are often anisotropic (not perfect cubes), a physically uniform smoothing requires a non-uniform kernel in voxel space. This practice  will guide you through the essential derivation and calculation to bridge the gap between the continuous physical world and the discrete voxel grid, a critical skill for correctly implementing preprocessing steps.",
            "id": "4164641",
            "problem": "A researcher analyzing functional Magnetic Resonance Imaging (fMRI) data intends to apply spatial smoothing using a three-dimensional Gaussian kernel to achieve a specified full width at half maximum (FWHM) in millimeters. The dataset has anisotropic voxel sampling with voxel dimensions $(\\Delta_x,\\Delta_y,\\Delta_z)$ given by $\\Delta_x = 1.8$ millimeters, $\\Delta_y = 2.0$ millimeters, and $\\Delta_z = 3.6$ millimeters. The desired physical FWHM of the smoothing kernel is $7.5$ millimeters, identical along all spatial axes in the physical space.\n\nStarting from core definitions of the Gaussian function and FWHM, and the notion that convolution in discrete voxel space corresponds to the sampling of a continuous kernel on a grid with spacing $(\\Delta_x,\\Delta_y,\\Delta_z)$, derive the conversion from the desired physical FWHM to the standard deviation $\\sigma$ of the Gaussian kernel in voxel units along each axis. Use only these foundational principles in your derivation; do not assume or cite any specialized shortcut formulas.\n\nCompute the values of $\\sigma$ in voxel units along the $x$, $y$, and $z$ axes, denoted $(\\sigma_x,\\sigma_y,\\sigma_z)$, and report them as dimensionless quantities. Round your final numerical results to four significant figures. Additionally, briefly explain, in terms of sampling and effective point-spread function shape, the implications of anisotropic voxel sizes for implementing physically isotropic smoothing in discrete space.",
            "solution": "The problem requires the derivation of the standard deviations $(\\sigma_x, \\sigma_y, \\sigma_z)$ of a Gaussian smoothing kernel in voxel units, given a desired isotropic physical full width at half maximum (FWHM) and anisotropic voxel dimensions. The solution will proceed in four parts: first, a derivation of the fundamental relationship between FWHM and standard deviation $\\sigma$ for a Gaussian function; second, the conversion of this relationship from physical space to discrete voxel space; third, the numerical computation of the required $\\sigma$ values; and fourth, an explanation of the implications of this conversion.\n\nFirst, we derive the relationship between FWHM and $\\sigma$. A one-dimensional Gaussian function centered at the origin can be written as:\n$$g(x) = \\exp\\left(-\\frac{x^2}{2\\sigma^2}\\right)$$\nThe maximum value of this function is $g(0) = 1$. The FWHM is defined as the width of the function at half of its maximum value. We must find the coordinates $x$ where $g(x) = \\frac{1}{2}$. Let these points be $\\pm x_{1/2}$.\n$$\\exp\\left(-\\frac{x_{1/2}^2}{2\\sigma^2}\\right) = \\frac{1}{2}$$\nTaking the natural logarithm of both sides gives:\n$$-\\frac{x_{1/2}^2}{2\\sigma^2} = \\ln\\left(\\frac{1}{2}\\right) = -\\ln(2)$$\nSolving for $x_{1/2}^2$:\n$$x_{1/2}^2 = 2\\sigma^2 \\ln(2)$$\nThe two points are $x_{1/2} = \\pm \\sigma \\sqrt{2 \\ln(2)}$. The FWHM is the distance between these two points:\n$$\\text{FWHM} = (\\sigma \\sqrt{2 \\ln(2)}) - (-\\sigma \\sqrt{2 \\ln(2)}) = 2\\sigma \\sqrt{2 \\ln(2)}$$\nThis can be written more compactly as:\n$$\\text{FWHM} = \\sigma \\sqrt{8 \\ln(2)}$$\nThis equation provides the direct conversion between the standard deviation $\\sigma$ and the FWHM of a Gaussian distribution.\n\nSecond, we must relate the parameters in physical space (measured in millimeters) to those in discrete voxel space (measured in voxels, a dimensionless quantity). Let the desired physical FWHM be $\\text{FWHM}_p$, which is specified to be isotropic, i.e., the same along all axes. Let the corresponding standard deviation in physical units be $\\sigma_p$. From our derivation:\n$$\\sigma_p = \\frac{\\text{FWHM}_p}{\\sqrt{8 \\ln(2)}}$$\nThe voxel dimensions are given as $(\\Delta_x, \\Delta_y, \\Delta_z)$. These values represent the physical size of a single voxel along each axis (e.g., in mm/voxel). The standard deviation of the Gaussian kernel can be expressed in physical units ($\\sigma_p$) or in voxel units ($\\sigma_x, \\sigma_y, \\sigma_z$). The relationship between these is a simple scaling by the voxel size for each dimension:\n$$\\sigma_p = \\sigma_x \\Delta_x$$\n$$\\sigma_p = \\sigma_y \\Delta_y$$\n$$\\sigma_p = \\sigma_z \\Delta_z$$\nTo achieve an isotropic physical smoothing effect (i.e., the same $\\sigma_p$ in all directions), the standard deviation in voxel units must be different for each direction to compensate for the anisotropic voxel sizes. We can solve for the standard deviation in voxel units for each axis:\n$$\\sigma_x = \\frac{\\sigma_p}{\\Delta_x} = \\frac{\\text{FWHM}_p}{\\Delta_x \\sqrt{8 \\ln(2)}}$$\n$$\\sigma_y = \\frac{\\sigma_p}{\\Delta_y} = \\frac{\\text{FWHM}_p}{\\Delta_y \\sqrt{8 \\ln(2)}}$$\n$$\\sigma_z = \\frac{\\sigma_p}{\\Delta_z} = \\frac{\\text{FWHM}_p}{\\Delta_z \\sqrt{8 \\ln(2)}}$$\n\nThird, we compute the numerical values for $(\\sigma_x, \\sigma_y, \\sigma_z)$. The given values are $\\text{FWHM}_p = 7.5$ mm, $\\Delta_x = 1.8$ mm, $\\Delta_y = 2.0$ mm, and $\\Delta_z = 3.6$ mm.\nFirst, we evaluate the constant factor:\n$$\\sqrt{8 \\ln(2)} \\approx \\sqrt{8 \\times 0.693147} \\approx \\sqrt{5.545177} \\approx 2.354820$$\nNow we can compute the standard deviation in voxel units for each axis:\n$$\\sigma_x = \\frac{7.5}{1.8 \\times \\sqrt{8 \\ln(2)}} \\approx \\frac{7.5}{1.8 \\times 2.354820} \\approx \\frac{7.5}{4.238676} \\approx 1.76943$$\n$$\\sigma_y = \\frac{7.5}{2.0 \\times \\sqrt{8 \\ln(2)}} \\approx \\frac{7.5}{2.0 \\times 2.354820} \\approx \\frac{7.5}{4.709640} \\approx 1.59249$$\n$$\\sigma_z = \\frac{7.5}{3.6 \\times \\sqrt{8 \\ln(2)}} \\approx \\frac{7.5}{3.6 \\times 2.354820} \\approx \\frac{7.5}{8.477352} \\approx 0.88471$$\nRounding these results to four significant figures, we get:\n$$\\sigma_x \\approx 1.769$$\n$$\\sigma_y \\approx 1.592$$\n$$\\sigma_z \\approx 0.8847$$\n\nFourth, we explain the implications of anisotropic voxel sizes. The goal of physically isotropic smoothing is to ensure that the effective point-spread function (PSF) of the smoothing operation is spherically symmetric in continuous physical space. In this case, the PSF is a Gaussian function with the same standard deviation, $\\sigma_p$, in all directions. However, the fMRI data exists on a discrete grid of voxels which, in this problem, is anisotropicâ€”the sampling density is different along each axis. To create a spherically symmetric PSF in physical space, the discrete kernel used for convolution must be anisotropic in voxel space.\nOur calculations demonstrate this necessity: $\\sigma_x \\neq \\sigma_y \\neq \\sigma_z$. The standard deviation in voxel units is largest for the axis with the smallest voxel size ($\\sigma_x \\approx 1.769$ for $\\Delta_x = 1.8$ mm) and smallest for the axis with the largest voxel size ($\\sigma_z \\approx 0.8847$ for $\\Delta_z = 3.6$ mm). This means the discrete Gaussian kernel is \"stretched\" in voxel coordinates along directions of high spatial sampling (small voxels) and \"compressed\" along directions of low spatial sampling (large voxels). If one were to naively use an isotropic kernel in voxel space (e.g., $\\sigma_x = \\sigma_y = \\sigma_z$), the resulting smoothing effect in physical space would be anisotropic, with greater blurring applied along the axes with larger voxels. Therefore, to correctly implement physically isotropic smoothing, the software must construct an anisotropic kernel in the discrete voxel grid that precisely counteracts the anisotropy of the underlying data sampling.",
            "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n1.769 & 1.592 & 0.8847\n\\end{pmatrix}\n}\n$$"
        },
        {
            "introduction": "The choice of a smoothing kernel's width is not arbitrary; it is a critical parameter that can determine the success of an experiment. The Matched Filter Theorem suggests that statistical power is maximized when the filter's characteristics match those of the signal being sought. This exercise  explores this principle by asking you to derive a formal expression for the loss in signal detectability when the smoothing kernel is wider or narrower than the true neural activation. Completing this will provide a rigorous, quantitative understanding of the trade-offs involved in selecting an optimal smoothing FWHM.",
            "id": "4164608",
            "problem": "Consider three-dimensional functional Magnetic Resonance Imaging (fMRI) data in a continuous spatial domain, modeled as a sum of a localized activation and additive noise. The true activation map is a spherically symmetric Gaussian \"bump\" centered at the origin with amplitude $A$ and spatial standard deviation $\\sigma_{a}$, i.e., the activation field is $S(\\mathbf{x}) = A \\, G_{\\sigma_{a}}(\\mathbf{x})$, where $G_{\\sigma}(\\mathbf{x})$ denotes the three-dimensional isotropic Gaussian with unit integral. The observed field is $Y(\\mathbf{x}) = S(\\mathbf{x}) + \\epsilon(\\mathbf{x})$, where $\\epsilon(\\mathbf{x})$ is zero-mean spatially white noise with variance $\\sigma_{\\epsilon}^{2}$ per unit volume, independent and identically distributed (i.i.d.) across space.\n\nSpatial smoothing is applied using an isotropic Gaussian kernel $K_{\\sigma_{s}}(\\mathbf{x}) = G_{\\sigma_{s}}(\\mathbf{x})$ with spatial standard deviation $\\sigma_{s}$ and unit integral. Let the smoothed field be $Y_{\\sigma_{s}}(\\mathbf{x}) = (K_{\\sigma_{s}} * Y)(\\mathbf{x})$, where $*$ denotes convolution. Define the detectability index $d'(\\sigma_{s})$ at the activation center $\\mathbf{x}=\\mathbf{0}$ as the ratio of the smoothed signal amplitude to the smoothed noise standard deviation at $\\mathbf{0}$.\n\nStarting from core definitions of Gaussian functions, properties of linear filtering of i.i.d. white noise, and the definition of detectability as signal amplitude divided by noise standard deviation, derive the sensitivity loss due to kernel mis-specification, quantified as the ratio $L$ of $d'(\\sigma_{s})$ to its maximized value $d'(\\sigma_{a})$ when the smoothing width matches the true activation width. Express the final sensitivity loss as a closed-form analytic expression solely in terms of the ratio $r = \\sigma_{s} / \\sigma_{a}$.\n\nYour answer must be a single analytic expression in terms of $r$. No numerical evaluation or rounding is required, and no physical units are to be reported, as the ratio is unitless.",
            "solution": "The problem asks for the sensitivity loss, quantified by the ratio $L = d'(\\sigma_{s}) / d'(\\sigma_{a})$, as a function of $r = \\sigma_{s} / \\sigma_{a}$. The detectability index $d'(\\sigma_{s})$ is defined as the ratio of the smoothed signal amplitude to the smoothed noise standard deviation, both evaluated at the activation center $\\mathbf{x}=\\mathbf{0}$. We will derive expressions for these two quantities first.\n\nFirst, we define the three-dimensional isotropic Gaussian function with standard deviation $\\sigma$ and unit integral, which is used for both the activation profile and the smoothing kernel.\n$$\nG_{\\sigma}(\\mathbf{x}) = \\frac{1}{(2\\pi\\sigma^2)^{3/2}} \\exp\\left(-\\frac{\\|\\mathbf{x}\\|^2}{2\\sigma^2}\\right)\n$$\nwhere $\\mathbf{x}$ is a $3$-dimensional position vector.\n\nThe true activation signal is $S(\\mathbf{x}) = A \\, G_{\\sigma_{a}}(\\mathbf{x})$. The observed field is $Y(\\mathbf{x}) = S(\\mathbf{x}) + \\epsilon(\\mathbf{x})$. Spatial smoothing is performed by convolving the observed field with the kernel $K_{\\sigma_{s}}(\\mathbf{x}) = G_{\\sigma_{s}}(\\mathbf{x})$. The smoothed field is $Y_{\\sigma_{s}}(\\mathbf{x}) = (K_{\\sigma_{s}} * Y)(\\mathbf{x})$. Due to the linearity of convolution, we can analyze the signal and noise components separately:\n$$\nY_{\\sigma_{s}}(\\mathbf{x}) = (G_{\\sigma_{s}} * S)(\\mathbf{x}) + (G_{\\sigma_{s}} * \\epsilon)(\\mathbf{x}) = S_{\\sigma_{s}}(\\mathbf{x}) + \\epsilon_{\\sigma_{s}}(\\mathbf{x})\n$$\n\nWe first calculate the smoothed signal component, $S_{\\sigma_{s}}(\\mathbf{x})$.\n$$\nS_{\\sigma_{s}}(\\mathbf{x}) = (G_{\\sigma_{s}} * (A \\cdot G_{\\sigma_{a}}))(\\mathbf{x}) = A \\, (G_{\\sigma_{s}} * G_{\\sigma_{a}})(\\mathbf{x})\n$$\nA fundamental property of Gaussian functions is that the convolution of two Gaussians is another Gaussian. Specifically, $(G_{\\sigma_1} * G_{\\sigma_2})(\\mathbf{x}) = G_{\\sqrt{\\sigma_1^2 + \\sigma_2^2}}(\\mathbf{x})$. Applying this property, we get:\n$$\nS_{\\sigma_{s}}(\\mathbf{x}) = A \\, G_{\\sqrt{\\sigma_{s}^2 + \\sigma_{a}^2}}(\\mathbf{x})\n$$\nThe signal amplitude at the center $\\mathbf{x}=\\mathbf{0}$ is the value of this function at $\\mathbf{0}$. Using the definition of $G_{\\sigma}(\\mathbf{x})$:\n$$\nS_{\\sigma_{s}}(\\mathbf{0}) = A \\, G_{\\sqrt{\\sigma_{s}^2 + \\sigma_{a}^2}}(\\mathbf{0}) = A \\frac{1}{(2\\pi(\\sigma_{s}^2 + \\sigma_{a}^2))^{3/2}}\n$$\nThis is the numerator for the detectability index $d'(\\sigma_{s})$.\n\nNext, we calculate the standard deviation of the smoothed noise, $\\epsilon_{\\sigma_{s}}(\\mathbf{x}) = (G_{\\sigma_{s}} * \\epsilon)(\\mathbf{x})$. The noise $\\epsilon(\\mathbf{x})$ is zero-mean and spatially white with variance $\\sigma_{\\epsilon}^{2}$ per unit volume. The smoothed noise $\\epsilon_{\\sigma_{s}}(\\mathbf{x})$ is also zero-mean. Its variance, which is constant over space due to the stationarity of the white noise, is given by the general formula for linear filtering of white noise:\n$$\n\\text{Var}[\\epsilon_{\\sigma_{s}}(\\mathbf{x})] = \\sigma_{\\epsilon}^2 \\int_{\\mathbb{R}^3} [G_{\\sigma_{s}}(\\mathbf{y})]^2 \\, d^3\\mathbf{y}\n$$\nWe need to evaluate the integral of the squared Gaussian kernel:\n$$\n\\int_{\\mathbb{R}^3} [G_{\\sigma_{s}}(\\mathbf{y})]^2 \\, d^3\\mathbf{y} = \\int_{\\mathbb{R}^3} \\left( \\frac{1}{(2\\pi\\sigma_{s}^2)^{3/2}} \\exp\\left(-\\frac{\\|\\mathbf{y}\\|^2}{2\\sigma_{s}^2}\\right) \\right)^2 \\, d^3\\mathbf{y}\n$$\n$$\n= \\frac{1}{(2\\pi\\sigma_{s}^2)^3} \\int_{\\mathbb{R}^3} \\exp\\left(-\\frac{\\|\\mathbf{y}\\|^2}{\\sigma_{s}^2}\\right) \\, d^3\\mathbf{y}\n$$\nThe integral is of a Gaussian form $\\exp(-\\|\\mathbf{y}\\|^2 / (2\\sigma_{new}^2))$ with $2\\sigma_{new}^2 = \\sigma_s^2$, so $\\sigma_{new} = \\sigma_s/\\sqrt{2}$. The value of this $3$D Gaussian integral is $(2\\pi \\sigma_{new}^2)^{3/2} = (2\\pi (\\sigma_s^2/2))^{3/2} = (\\pi\\sigma_s^2)^{3/2}$.\n$$\n\\int_{\\mathbb{R}^3} [G_{\\sigma_{s}}(\\mathbf{y})]^2 \\, d^3\\mathbf{y} = \\frac{1}{(2\\pi\\sigma_{s}^2)^3} (\\pi\\sigma_s^2)^{3/2} = \\frac{\\pi^{3/2}\\sigma_s^3}{8\\pi^3\\sigma_s^6} = \\frac{1}{8\\pi^{3/2}\\sigma_s^3} = \\frac{1}{(4\\pi)^{3/2}\\sigma_s^3}\n$$\nThe variance of the smoothed noise is:\n$$\n\\text{Var}[\\epsilon_{\\sigma_{s}}(\\mathbf{x})] = \\sigma_{\\epsilon}^2 \\frac{1}{(4\\pi)^{3/2}\\sigma_s^3}\n$$\nThe standard deviation of the smoothed noise at the center (and everywhere) is the square root of the variance:\n$$\n\\text{SD}[\\epsilon_{\\sigma_{s}}(\\mathbf{0})] = \\sqrt{\\sigma_{\\epsilon}^2 \\frac{1}{(4\\pi)^{3/2}\\sigma_s^3}} = \\frac{\\sigma_{\\epsilon}}{(4\\pi)^{3/4}\\sigma_s^{3/2}}\n$$\nThis is the denominator for the detectability index $d'(\\sigma_{s})$.\n\nNow we can write the expression for $d'(\\sigma_{s})$:\n$$\nd'(\\sigma_{s}) = \\frac{S_{\\sigma_{s}}(\\mathbf{0})}{\\text{SD}[\\epsilon_{\\sigma_{s}}(\\mathbf{0})]} = \\frac{A \\, (2\\pi(\\sigma_{s}^2 + \\sigma_{a}^2))^{-3/2}}{\\sigma_{\\epsilon} \\, (4\\pi)^{-3/4}\\sigma_s^{-3/2}} = \\frac{A}{\\sigma_{\\epsilon}} \\frac{(4\\pi)^{3/4} \\sigma_s^{3/2}}{(2\\pi)^{3/2} (\\sigma_{s}^2 + \\sigma_{a}^2)^{3/2}}\n$$\nSimplifying the constants:\n$$\n\\frac{(4\\pi)^{3/4}}{(2\\pi)^{3/2}} = \\frac{(2^2\\pi)^{3/4}}{(2\\pi)^{3/2}} = \\frac{2^{3/2}\\pi^{3/4}}{2^{3/2}\\pi^{3/2}} = \\pi^{-3/4}\n$$\nSo, the detectability index is:\n$$\nd'(\\sigma_{s}) = \\frac{A}{\\sigma_{\\epsilon}} \\pi^{-3/4} \\frac{\\sigma_s^{3/2}}{(\\sigma_{s}^2 + \\sigma_{a}^2)^{3/2}}\n$$\nThe problem states that this value is maximized at $\\sigma_{s} = \\sigma_{a}$. Let's find this maximum value, $d'(\\sigma_{a})$:\n$$\nd'(\\sigma_{a}) = \\frac{A}{\\sigma_{\\epsilon}} \\pi^{-3/4} \\frac{\\sigma_a^{3/2}}{(\\sigma_{a}^2 + \\sigma_{a}^2)^{3/2}} = \\frac{A}{\\sigma_{\\epsilon}} \\pi^{-3/4} \\frac{\\sigma_a^{3/2}}{(2\\sigma_a^2)^{3/2}} = \\frac{A}{\\sigma_{\\epsilon}} \\pi^{-3/4} \\frac{\\sigma_a^{3/2}}{2^{3/2}\\sigma_a^3} = \\frac{A}{\\sigma_{\\epsilon}} \\pi^{-3/4} \\frac{1}{2^{3/2}\\sigma_a^{3/2}}\n$$\nThe sensitivity loss $L$ is the ratio of $d'(\\sigma_{s})$ to its maximum value $d'(\\sigma_{a})$:\n$$\nL = \\frac{d'(\\sigma_{s})}{d'(\\sigma_{a})} = \\frac{\\frac{A}{\\sigma_{\\epsilon}} \\pi^{-3/4} \\frac{\\sigma_s^{3/2}}{(\\sigma_{s}^2 + \\sigma_{a}^2)^{3/2}}}{\\frac{A}{\\sigma_{\\epsilon}} \\pi^{-3/4} \\frac{1}{2^{3/2}\\sigma_a^{3/2}}} = \\frac{\\sigma_s^{3/2}}{(\\sigma_{s}^2 + \\sigma_{a}^2)^{3/2}} \\cdot (2^{3/2}\\sigma_a^{3/2})\n$$\n$$\nL = \\frac{2^{3/2} \\sigma_s^{3/2} \\sigma_a^{3/2}}{(\\sigma_{s}^2 + \\sigma_{a}^2)^{3/2}} = \\left( \\frac{2\\sigma_s\\sigma_a}{\\sigma_s^2 + \\sigma_a^2} \\right)^{3/2}\n$$\nFinally, we express this loss in terms of the ratio $r = \\sigma_{s} / \\sigma_{a}$. We divide the numerator and denominator inside the parenthesis by $\\sigma_a^2$:\n$$\nL = \\left( \\frac{2(\\sigma_s/\\sigma_a)}{(\\sigma_s/\\sigma_a)^2 + 1} \\right)^{3/2} = \\left( \\frac{2r}{r^2 + 1} \\right)^{3/2}\n$$\nThis is the final closed-form analytic expression for the sensitivity loss.",
            "answer": "$$\n\\boxed{\\left( \\frac{2r}{r^2 + 1} \\right)^{3/2}}\n$$"
        },
        {
            "introduction": "Applying a three-dimensional smoothing filter to a large fMRI dataset can be a computationally demanding process. Fortunately, the Gaussian kernel possesses a crucial mathematical property known as separability, which permits a dramatic optimization. This practice  explores the immense practical benefit of this property by comparing the computational load of a naive 3D convolution with an efficient, separable implementation. By quantifying the performance gain, you will appreciate how elegant mathematics makes large-scale neuroimaging analysis feasible.",
            "id": "4164640",
            "problem": "A functional Magnetic Resonance Imaging (fMRI) volume is smoothed with an isotropic Gaussian kernel. The volume has dimensions $N_{x} = 128$, $N_{y} = 128$, $N_{z} = 64$ voxels, and isotropic voxel size $s = 2\\ \\mathrm{mm}$. The target smoothness is a full width at half maximum (FWHM) of $8\\ \\mathrm{mm}$. The discrete kernel is constructed by truncating the continuous Gaussian at $\\pm M \\sigma$ along each axis, where $M = 3$, $\\sigma$ is the Gaussian standard deviation, and the discrete kernel length along each axis is $K = 2 r + 1$ with $r = \\lceil M \\sigma / s \\rceil$.\n\nStarting from the definition of convolution and the definition of a Gaussian, and using the relation between FWHM and the Gaussian standard deviation derived from first principles, compare the computational complexity (in terms of the total number of multiplication operations) of:\n- Naive three-dimensional convolution with the full $K \\times K \\times K$ kernel applied in one pass, versus\n- Three one-dimensional convolutions applied sequentially along $x$, $y$, and $z$ (using the separability of the Gaussian).\n\nAssume interior voxels so that boundary effects do not change per-voxel operation counts, and count the number of multiplications required over the entire volume. Compute the ratio $R$ of the total number of multiplications required by the naive three-dimensional convolution to the total number required by the separable three-pass one-dimensional convolutions, and express $R$ as a dimensionless real number. Round your final answer to four significant figures.",
            "solution": "The solution proceeds in several steps: First, we derive the relationship between the FWHM and the standard deviation $\\sigma$ of a Gaussian function. Second, we calculate the specific value of $\\sigma$ required to achieve the target FWHM. Third, we determine the size of the discrete convolution kernel, $K$. Fourth, we calculate the total number of multiplication operations for both the naive 3D convolution and the separable 1D convolution method. Finally, we compute the ratio of these two quantities.\n\n**1. Relationship between FWHM and $\\sigma$**\n\nA one-dimensional Gaussian function centered at zero is given by:\n$$g(x) = A \\exp\\left(-\\frac{x^2}{2\\sigma^2}\\right)$$\nwhere $A$ is the amplitude and $\\sigma$ is the standard deviation. The maximum value of the function is $g(0) = A$. The FWHM is the width of the function at half of its maximum value, i.e., at $A/2$. Let $x_{HM}$ be the position where this occurs.\n$$g(x_{HM}) = \\frac{A}{2}$$\n$$A \\exp\\left(-\\frac{x_{HM}^2}{2\\sigma^2}\\right) = \\frac{A}{2}$$\n$$\\exp\\left(-\\frac{x_{HM}^2}{2\\sigma^2}\\right) = \\frac{1}{2}$$\nTaking the natural logarithm of both sides:\n$$-\\frac{x_{HM}^2}{2\\sigma^2} = \\ln\\left(\\frac{1}{2}\\right) = -\\ln(2)$$\n$$x_{HM}^2 = 2\\sigma^2 \\ln(2)$$\n$$|x_{HM}| = \\sigma\\sqrt{2\\ln(2)}$$\nThe FWHM is the distance between the two points $-x_{HM}$ and $+x_{HM}$, so $\\text{FWHM} = 2 |x_{HM}|$.\n$$\\text{FWHM} = 2\\sigma\\sqrt{2\\ln(2)}$$\n\n**2. Calculating $\\sigma$**\n\nThe problem states a target smoothness of $\\text{FWHM} = 8\\ \\mathrm{mm}$. We can solve for $\\sigma$:\n$$\\sigma = \\frac{\\text{FWHM}}{2\\sqrt{2\\ln(2)}} = \\frac{8\\ \\mathrm{mm}}{2\\sqrt{2\\ln(2)}} = \\frac{4}{\\sqrt{2\\ln(2)}}\\ \\mathrm{mm}$$\n\n**3. Determining the Kernel Size $K$**\n\nThe discrete kernel is constructed by truncating the continuous Gaussian at a distance of $\\pm M\\sigma$ from the center, along each axis. The parameter $M$ is given as $3$. The physical radius of the kernel is $M\\sigma$.\n$$M\\sigma = 3 \\times \\frac{4}{\\sqrt{2\\ln(2)}}\\ \\mathrm{mm} = \\frac{12}{\\sqrt{2\\ln(2)}}\\ \\mathrm{mm}$$\nThe voxel size is $s = 2\\ \\mathrm{mm}$. The radius of the kernel in voxels, $r$, is found by dividing the physical radius by the voxel size and taking the ceiling of the result, as specified.\n$$r = \\left\\lceil \\frac{M\\sigma}{s} \\right\\rceil = \\left\\lceil \\frac{12 / \\sqrt{2\\ln(2)}}{2} \\right\\rceil = \\left\\lceil \\frac{6}{\\sqrt{2\\ln(2)}} \\right\\rceil$$\nTo evaluate this, we use the approximate value $\\ln(2) \\approx 0.693147$.\n$$\\sqrt{2\\ln(2)} \\approx \\sqrt{2 \\times 0.693147} \\approx \\sqrt{1.386294} \\approx 1.17741$$\n$$r = \\left\\lceil \\frac{6}{1.17741} \\right\\rceil = \\lceil 5.096 \\rceil = 6$$\nThe full length of the discrete kernel along one axis is $K = 2r + 1$.\n$$K = 2(6) + 1 = 13$$\nThe isotropic 3D kernel is therefore a cube of $13 \\times 13 \\times 13$ voxels.\n\n**4. Computational Complexity**\n\nLet the total number of voxels in the volume be $N_{total} = N_x N_y N_z$.\n$$N_{total} = 128 \\times 128 \\times 64 = 1048576$$\n\n**Method 1: Naive 3D Convolution**\nIn a naive 3D convolution, for each output voxel, we multiply each voxel in the kernel with the corresponding voxel in the input volume and sum the results. The number of multiplications per output voxel is equal to the number of elements in the kernel.\nNumber of kernel elements $= K \\times K \\times K = K^3$.\n$$K^3 = 13^3 = 2197$$\nThe total number of multiplications for the entire volume, $N_{mult, 3D}$, is the number of multiplications per voxel multiplied by the total number of voxels.\n$$N_{mult, 3D} = N_{total} \\times K^3 = (N_x N_y N_z) K^3$$\n\n**Method 2: Separable 1D Convolutions**\nThe 3D Gaussian kernel is separable, meaning $G(x,y,z) = G_x(x)G_y(y)G_z(z)$. Convolution with a separable kernel can be performed as a sequence of three 1D convolutions.\n1.  Convolve the entire volume along the x-axis with a 1D kernel of length $K$. For each voxel, this requires $K$ multiplications. The total for this pass is $N_{total} \\times K$.\n2.  Convolve the resulting volume from step 1 along the y-axis with a 1D kernel of length $K$. This also requires $N_{total} \\times K$ multiplications.\n3.  Convolve the resulting volume from step 2 along the z-axis with a 1D kernel of length $K$. This again requires $N_{total} \\times K$ multiplications.\n\nThe total number of multiplications for the separable method, $N_{mult, 1D}$, is the sum of the multiplications from the three passes.\n$$N_{mult, 1D} = (N_{total} \\times K) + (N_{total} \\times K) + (N_{total} \\times K) = N_{total} \\times (3K)$$\n\n**5. Computing the Ratio $R$**\n\nThe ratio $R$ is defined as the total multiplications for the naive method divided by the total for the separable method.\n$$R = \\frac{N_{mult, 3D}}{N_{mult, 1D}} = \\frac{(N_x N_y N_z) K^3}{(N_x N_y N_z) (3K)}$$\nThe volume dimensions cancel out, simplifying the ratio:\n$$R = \\frac{K^3}{3K} = \\frac{K^2}{3}$$\nSubstituting the calculated value of $K = 13$:\n$$R = \\frac{13^2}{3} = \\frac{169}{3} = 56.3333...$$\nThe problem requests the answer to be rounded to four significant figures.\n$$R \\approx 56.33$$\nThis result demonstrates the significant computational advantage of using the separability property of the Gaussian kernel for smoothing operations.",
            "answer": "$$\\boxed{56.33}$$"
        }
    ]
}