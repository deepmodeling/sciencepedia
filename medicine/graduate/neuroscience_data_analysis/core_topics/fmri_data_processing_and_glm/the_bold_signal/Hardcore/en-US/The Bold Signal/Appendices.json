{
    "hands_on_practices": [
        {
            "introduction": "To accurately model the Blood Oxygenation Level Dependent (BOLD) signal, we must first understand the underlying hemodynamics. This exercise grounds your understanding in the fundamental biophysical coupling between cerebral blood flow (CBF) and cerebral blood volume (CBV), governed by the empirical Grubb's relationship. By calculating the expected change in blood volume following a change in blood flow, you will gain quantitative insight into the vascular dynamics and explore how their differing timescales can give rise to prominent features of the BOLD response, such as the post-stimulus undershoot .",
            "id": "3998822",
            "problem": "Consider a brief neural stimulus that increases Cerebral Blood Flow (CBF) by a constant fraction for a short period. Let the baseline CBF be denoted by $f_{0}$ and the baseline Cerebral Blood Volume (CBV) by $v_{0}$. Define the relative changes as $r_{f} = f/f_{0}$ and $r_{v} = v/v_{0}$. Assume quasi-steady hemodynamics during the peak response and the empirically established Grubb’s relationship $v \\propto f^{\\alpha}$ holds locally, with exponent $\\alpha$ characterizing microvascular compliance. From mass balance, the volume dynamics obey $dv/dt = \\text{inflow} - \\text{outflow}$, and under the quasi-steady condition at the peak, the instantaneous $r_{v}$ may be related to $r_{f}$ via Grubb’s relationship.\n\nSuppose the stimulus produces a $20\\%$ increase in CBF at peak, i.e., $r_{f} = 1.2$, and the local Grubb exponent is $\\alpha = 0.2$. Using only the definitions above and the Grubb coupling, derive the closed-form expression for the fractional CBV change at peak, $\\Delta v / v_{0} = r_{v} - 1$, and then compute its numerical value. Round your final numerical answer to four significant figures. Express the fractional change as a dimensionless decimal (do not use a percentage sign).\n\nFinally, discuss qualitatively, using the definitions of deoxyhemoglobin content and volume and without invoking any specific Blood Oxygenation Level Dependent (BOLD) signal equation, how the magnitude of this CBV change and its potential delayed recovery relative to CBF could contribute to the post-stimulus undershoot in the BOLD signal. Define all acronyms on first use: Blood Oxygenation Level Dependent (BOLD), Cerebral Blood Volume (CBV), Cerebral Blood Flow (CBF).",
            "solution": "The problem requires the derivation and calculation of the fractional change in Cerebral Blood Volume (CBV) based on a given change in Cerebral Blood Flow (CBF) and an established empirical relationship, followed by a qualitative discussion of the post-stimulus undershoot in the Blood Oxygenation Level Dependent (BOLD) signal.\n\nFirst, we derive the closed-form expression for the fractional CBV change at its peak.\nThe problem states the empirically established Grubb's relationship, which couples CBV, denoted by $v$, to CBF, denoted by $f$:\n$$v \\propto f^{\\alpha}$$\nThis proportionality can be written as an equation with a constant of proportionality, $k$:\n$$v = k f^{\\alpha}$$\nThis relationship holds under different physiological states, including baseline and activation. Let the baseline CBV be $v_{0}$ and the baseline CBF be $f_{0}$. At baseline, the equation is:\n$$v_{0} = k f_{0}^{\\alpha}$$\nAt the peak of the stimulus-induced response, the CBV is $v$ and the CBF is $f$. The equation is:\n$$v = k f^{\\alpha}$$\nTo find the relationship between the relative changes, we can divide the equation at peak activation by the equation at baseline:\n$$\\frac{v}{v_{0}} = \\frac{k f^{\\alpha}}{k f_{0}^{\\alpha}}$$\nThe constant $k$ cancels, yielding:\n$$\\frac{v}{v_{0}} = \\left(\\frac{f}{f_{0}}\\right)^{\\alpha}$$\nThe problem defines the relative changes as $r_{v} = v/v_{0}$ and $r_{f} = f/f_{0}$. Substituting these definitions into the equation gives the coupling between the relative changes:\n$$r_{v} = r_{f}^{\\alpha}$$\nThe problem asks for the fractional CBV change, which is defined as $\\frac{\\Delta v}{v_{0}}$. We can express this in terms of $r_v$:\n$$\\frac{\\Delta v}{v_{0}} = \\frac{v - v_{0}}{v_{0}} = \\frac{v}{v_{0}} - \\frac{v_{0}}{v_{0}} = r_{v} - 1$$\nBy substituting the expression for $r_{v}$, we arrive at the final closed-form expression for the fractional CBV change in terms of the fractional CBF change:\n$$\\frac{\\Delta v}{v_{0}} = r_{f}^{\\alpha} - 1$$\n\nNext, we compute the a numerical value of this fractional change using the provided data.\nThe stimulus produces a $20\\%$ increase in CBF, which means the peak flow $f$ is $120\\%$ of the baseline flow $f_0$. This corresponds to a relative change $r_{f}$ of:\n$$r_{f} = \\frac{f}{f_{0}} = \\frac{1.20 f_{0}}{f_{0}} = 1.2$$\nThe local Grubb exponent is given as $\\alpha = 0.2$.\nSubstituting these values into our derived expression:\n$$\\frac{\\Delta v}{v_{0}} = (1.2)^{0.2} - 1$$\nWe can calculate the numerical value. Note that an exponent of $0.2$ is equivalent to the $5^{th}$ root:\n$$(1.2)^{0.2} = (1.2)^{1/5} = \\sqrt[5]{1.2} \\approx 1.037137$$\nTherefore, the fractional change is:\n$$\\frac{\\Delta v}{v_{0}} \\approx 1.037137 - 1 = 0.037137$$\nRounding this result to four significant figures gives:\n$$\\frac{\\Delta v}{v_{0}} \\approx 0.03714$$\n\nFinally, we discuss qualitatively how the magnitude of this CBV change and its potential delayed recovery relative to CBF contribute to the post-stimulus undershoot.\nThe Blood Oxygenation Level Dependent (BOLD) signal, used in functional magnetic resonance imaging, indirectly measures neural activity by detecting changes in blood oxygenation. The signal is sensitive to the local concentration of deoxyhemoglobin, which is paramagnetic and causes magnetic field inhomogeneities. A lower concentration of deoxyhemoglobin results in a higher BOLD signal.\n\nDuring neural stimulation, there is a large increase in Cerebral Blood Flow (CBF), the rate of blood delivery. This flow increase significantly overcompensates for the much smaller increase in oxygen consumption. The result is a \"washout\" of deoxyhemoglobin from the venous side of the capillary bed, leading to a decrease in its concentration and thus an increase in the BOLD signal. This CBF increase also forces an increase in Cerebral Blood Volume (CBV), the total volume of blood in a given brain region, as the blood vessels distend to accommodate the higher flow.\n\nThe post-stimulus undershoot refers to the phenomenon where the BOLD signal drops below its pre-stimulus baseline level for a period after the neural stimulus has ceased. A primary hypothesis for this effect centers on the differential temporal dynamics of CBF and CBV recovery.\nFollowing the cessation of the stimulus, CBF tends to return to its baseline level relatively quickly. However, the venous blood vessels, having been stretched, are compliant and tend to return to their baseline volume much more slowly. This biomechanical property results in a transient state where CBF has normalized (or nearly so), but CBV remains elevated.\n\nIn this specific post-stimulus period:\n1.  **CBF is at baseline**: The supply of fresh, oxygenated blood is back to normal.\n2.  **CBV is elevated**: The volume of the venous compartment is still larger than its baseline state.\n\nBecause metabolic oxygen consumption continues at a near-baseline rate, deoxyhemoglobin is still being produced. This deoxyhemoglobin now pools in the still-enlarged venous volume. The total amount of deoxyhemoglobin within the imaging voxel (which is a product of its concentration and the venous blood volume) becomes greater than it was at the initial baseline. This increased total amount of paramagnetic deoxyhemoglobin creates stronger local magnetic field distortions, leading to a faster signal decay and, consequently, a BOLD signal that is lower than the initial baseline level. This effect persists until the venous CBV fully returns to its baseline state, at which point the BOLD signal also recovers to baseline. Thus, the mismatch in recovery timescales between a fast-recovering CBF and a slow-recovering CBV is a key proposed mechanism for the post-stimulus BOLD undershoot.",
            "answer": "$$\n\\boxed{0.03714}\n$$"
        },
        {
            "introduction": "The General Linear Model (GLM) is a powerful tool, but its validity rests on the methodological integrity of the entire analysis pipeline, from preprocessing to statistical inference. This practice serves as a critical lesson in procedural consistency, focusing on the common step of high-pass filtering to remove low-frequency scanner drift. You will analytically derive the bias introduced into your parameter estimates when the filtering operation is incorrectly applied only to the data and not the design matrix, demonstrating how seemingly small errors can lead to systematically flawed conclusions .",
            "id": "4198473",
            "problem": "A Blood-Oxygen-Level-Dependent (BOLD) time series in functional magnetic resonance imaging is often modeled using the General Linear Model (GLM) to estimate task-related amplitudes while controlling for low-frequency drifts. Consider a single-voxel BOLD signal with $T=6$ time points and a one-regressor GLM. The generative model is\n$$\ny = x\\,\\beta + \\gamma\\,\\mathbf{1} + \\varepsilon,\n$$\nwhere $y \\in \\mathbb{R}^{6}$ is the measured BOLD signal, $x \\in \\mathbb{R}^{6}$ is the known task regressor obtained by convolving a stimulus sequence with a canonical Hemodynamic Response Function (HRF), $\\beta \\in \\mathbb{R}$ is the true task amplitude, $\\gamma \\in \\mathbb{R}$ is an unknown constant (a baseline drift), $\\mathbf{1} \\in \\mathbb{R}^{6}$ is the all-ones vector, and $\\varepsilon \\in \\mathbb{R}^{6}$ is zero-mean noise with finite covariance. The task regressor for this voxel is specified as\n$$\nx = \\begin{pmatrix} 0 \\\\ 0.5 \\\\ 1 \\\\ 1 \\\\ 0.5 \\\\ 0 \\end{pmatrix}.\n$$\nAn analyst applies a high-pass filter that removes the temporal mean, represented as the linear operator\n$$\nH = I - \\frac{1}{T}\\mathbf{1}\\mathbf{1}^{\\top},\n$$\nbut applies it inconsistently only to the data $y$ and not to the design $x$. The analyst then computes the ordinary least squares estimate using the unfiltered design,\n$$\n\\hat{\\beta} = \\left(x^{\\top}x\\right)^{-1} x^{\\top} H y.\n$$\nStarting from the GLM generative model and linearity of expectation, derive the analytical expression for $\\mathbb{E}[\\hat{\\beta}]$ in terms of $x$, $T$, and $\\beta$ that results from this inconsistent filtering, and then evaluate its numerical value for the provided $x$ and $T$ when the true task amplitude is $\\beta = 2$. Your final answer must be the single numerical value of $\\mathbb{E}[\\hat{\\beta}]$, rounded to four significant figures. Express the final answer without units.",
            "solution": "The problem asks for the expected value of a parameter estimate, $\\mathbb{E}[\\hat{\\beta}]$, when an inconsistent high-pass filtering procedure is applied in a General Linear Model (GLM) analysis.\n\n1.  **Derive the Analytical Expression for $\\mathbb{E}[\\hat{\\beta}]$**\n\nWe start with the estimator defined by the analyst:\n$$\n\\hat{\\beta} = \\left(x^{\\top}x\\right)^{-1} x^{\\top} H y\n$$\nTo find its expectation, we apply the expectation operator $\\mathbb{E}[\\cdot]$. Since $x$ and $H$ are fixed (not random variables), they can be treated as constants:\n$$\n\\mathbb{E}[\\hat{\\beta}] = \\mathbb{E}[\\left(x^{\\top}x\\right)^{-1} x^{\\top} H y] = \\left(x^{\\top}x\\right)^{-1} x^{\\top} H \\mathbb{E}[y]\n$$\nNext, we need the expectation of the data, $\\mathbb{E}[y]$. The generative model is $y = x\\,\\beta + \\gamma\\,\\mathbf{1} + \\varepsilon$. The noise term $\\varepsilon$ is given as zero-mean, so $\\mathbb{E}[\\varepsilon] = \\mathbf{0}$. The other terms are constants. Therefore, the expectation of $y$ is:\n$$\n\\mathbb{E}[y] = \\mathbb{E}[x\\,\\beta + \\gamma\\,\\mathbf{1} + \\varepsilon] = x\\,\\beta + \\gamma\\,\\mathbf{1}\n$$\nNow, substitute this back into the expression for $\\mathbb{E}[\\hat{\\beta}]$:\n$$\n\\mathbb{E}[\\hat{\\beta}] = \\left(x^{\\top}x\\right)^{-1} x^{\\top} H (x\\,\\beta + \\gamma\\,\\mathbf{1})\n$$\nWe can distribute the matrix $H$ over the sum:\n$$\n\\mathbb{E}[\\hat{\\beta}] = \\left(x^{\\top}x\\right)^{-1} x^{\\top} (H x\\,\\beta + H \\gamma\\,\\mathbf{1})\n$$\nThe high-pass filter operator $H = I - \\frac{1}{T}\\mathbf{1}\\mathbf{1}^{\\top}$ is designed to remove the mean of a vector. Applying it to the all-ones vector $\\mathbf{1}$ gives:\n$$\nH\\mathbf{1} = \\left(I - \\frac{1}{T}\\mathbf{1}\\mathbf{1}^{\\top}\\right)\\mathbf{1} = \\mathbf{1} - \\frac{1}{T}\\mathbf{1}(\\mathbf{1}^{\\top}\\mathbf{1})\n$$\nSince $\\mathbf{1}^{\\top}\\mathbf{1} = \\sum_{i=1}^T 1^2 = T$, this simplifies to:\n$$\nH\\mathbf{1} = \\mathbf{1} - \\frac{1}{T}\\mathbf{1}(T) = \\mathbf{1} - \\mathbf{1} = \\mathbf{0}\n$$\nThe term involving $\\gamma$ therefore vanishes, showing that the procedure correctly removes the constant drift term. The expression for the expected value simplifies to:\n$$\n\\mathbb{E}[\\hat{\\beta}] = \\left(x^{\\top}x\\right)^{-1} x^{\\top} (H x\\,\\beta) = \\left[ \\left(x^{\\top}x\\right)^{-1} x^{\\top} H x \\right] \\beta\n$$\nThis reveals that the estimator is biased, as the term in the brackets is not necessarily equal to 1. The correct procedure would have been to filter both $y$ and $x$, leading to the estimator $\\hat{\\beta}_{\\text{correct}} = ((Hx)^\\top Hx)^{-1} (Hx)^\\top Hy$, which is unbiased under these conditions.\n\n2.  **Evaluate the Numerical Value**\n\nNow we compute the value of the bias factor $\\left(x^{\\top}x\\right)^{-1} x^{\\top} H x$ and the final result.\nGiven data:\n$T = 6$\n$x = \\begin{pmatrix} 0  0.5  1  1  0.5  0 \\end{pmatrix}^{\\top}$\n$\\beta = 2$\n\nFirst, compute the components of the bias factor:\n-   $x^{\\top}x$: The sum of squares of the elements of $x$.\n    $$\n    x^{\\top}x = 0^2 + 0.5^2 + 1^2 + 1^2 + 0.5^2 + 0^2 = 0 + 0.25 + 1 + 1 + 0.25 + 0 = 2.5\n    $$\n-   $H x$: The demeaned version of $x$. First, find the mean of $x$, $\\bar{x}$.\n    $$\n    \\sum x_i = 0 + 0.5 + 1 + 1 + 0.5 + 0 = 3\n    $$\n    $$\n    \\bar{x} = \\frac{\\sum x_i}{T} = \\frac{3}{6} = 0.5\n    $$\n    So, $Hx = x - \\bar{x}\\mathbf{1}$.\n-   $x^{\\top} H x$: The dot product of the original regressor with its demeaned version.\n    $$\n    x^{\\top} H x = x^{\\top}(x - \\bar{x}\\mathbf{1}) = x^{\\top}x - \\bar{x}(x^{\\top}\\mathbf{1})\n    $$\n    We already have $x^{\\top}x=2.5$ and $\\bar{x}=0.5$. Also, $x^{\\top}\\mathbf{1} = \\sum x_i = 3$.\n    $$\n    x^{\\top} H x = 2.5 - 0.5(3) = 2.5 - 1.5 = 1.0\n    $$\nNow, substitute these back into the expression for $\\mathbb{E}[\\hat{\\beta}]$:\n$$\n\\mathbb{E}[\\hat{\\beta}] = \\left[ (2.5)^{-1} \\cdot (1.0) \\right] \\beta = \\frac{1.0}{2.5} \\beta = 0.4 \\beta\n$$\nThe inconsistent filtering introduces a systematic underestimation of the true amplitude by a factor of $0.4$.\n\nFinally, with the true amplitude $\\beta = 2$, the expected value of the estimate is:\n$$\n\\mathbb{E}[\\hat{\\beta}] = 0.4 \\times 2 = 0.8\n$$\nRounding to four significant figures gives $0.8000$.",
            "answer": "$$\n\\boxed{0.8000}\n$$"
        },
        {
            "introduction": "After fitting a General Linear Model (GLM) to BOLD data, a crucial step is to diagnose the model's stability and the reliability of its parameter estimates. This exercise tackles the pervasive issue of multicollinearity, where regressors in the design matrix are correlated, a common occurrence in event-related fMRI designs. You will derive and compute the variance-inflation factor (VIF) from first principles, providing you with a key diagnostic tool to quantify how much the variance of an estimated coefficient is increased due to its correlation with other predictors, thereby learning to assess the trustworthiness of your model's output .",
            "id": "4198478",
            "problem": "A single voxel blood-oxygen-level-dependent (BOLD) time series is modeled with a general linear model (GLM). Let the observed time series be $y \\in \\mathbb{R}^{N}$, the design matrix be $X \\in \\mathbb{R}^{N \\times p}$ with $p=3$ regressors corresponding to two task conditions and one nuisance motion parameter, and suppose that the parameter vector is $\\beta \\in \\mathbb{R}^{3}$. Assume the classical linear model with independent, identically distributed Gaussian noise: $\\epsilon \\sim \\mathcal{N}(0, \\sigma^{2} I_{N})$, and $y = X \\beta + \\epsilon$, with the parameters estimated by ordinary least squares (OLS). The $3$ columns of $X$ have been constructed by convolving event sequences with a canonical hemodynamic response function (HRF) and then column-wise standardized to have zero mean and unit variance. The sample size is $N=200$. Denote the regressors by $A$, $B$, and $M$ (for the two task conditions and the motion nuisance, respectively). The sample correlation matrix of the columns of $X$ is\n$$\nR \\;=\\; \\begin{pmatrix}\n1  r  0 \\\\\nr  1  0 \\\\\n0  0  1\n\\end{pmatrix},\n$$\nwith $r = 0.8$. By definition of the sample correlation matrix under this column standardization, $X^{\\top} X = N R$.\n\nWorking from the fundamental properties of the ordinary least squares estimator under the classical linear model and using only the information given above, derive the relationship between the variance of the OLS coefficient estimates and the design correlation structure. Use this to define the variance-inflation factor for each coefficient as the ratio of its variance under the given design to its variance under a counterfactual design in which the three columns are mutually orthogonal but have the same column norms as in the given design. Compute the variance-inflation factors for regressors $A$, $B$, and $M$ for the given $R$ and $N$.\n\nReport the three variance-inflation factors for $(A, B, M)$ as a single row matrix using the LaTeX $\\texttt{pmatrix}$ environment. Do not round your answer.",
            "solution": "The problem asks for the derivation and computation of variance-inflation factors (VIFs) for the ordinary least squares (OLS) estimates of parameters in a general linear model (GLM) applied to a BOLD time series.\n\nFirst, we establish the fundamental properties of the OLS estimator. The model is given by $y = X \\beta + \\epsilon$, where $y \\in \\mathbb{R}^{N}$ is the observed data, $X \\in \\mathbb{R}^{N \\times p}$ is the design matrix, $\\beta \\in \\mathbb{R}^{p}$ is the parameter vector, and $\\epsilon$ is the noise vector. We are given $p=3$ and $N=200$. The noise is assumed to be white Gaussian noise, $\\epsilon \\sim \\mathcal{N}(0, \\sigma^{2} I_{N})$, where $\\sigma^2$ is the noise variance and $I_N$ is the $N \\times N$ identity matrix.\n\nThe OLS estimator for $\\beta$ is given by the expression $\\hat{\\beta} = (X^{\\top} X)^{-1} X^{\\top} y$. The covariance matrix of this estimator, $\\text{Cov}(\\hat{\\beta})$, is derived as follows:\n$$\n\\text{Cov}(\\hat{\\beta}) = \\text{Cov}((X^{\\top} X)^{-1} X^{\\top} y)\n$$\nSince $X$ is a fixed matrix of regressors, we can write:\n$$\n\\text{Cov}(\\hat{\\beta}) = (X^{\\top} X)^{-1} X^{\\top} \\text{Cov}(y) ( (X^{\\top} X)^{-1} X^{\\top} )^{\\top}\n$$\nThe covariance of the data $y$ is $\\text{Cov}(y) = \\text{Cov}(X\\beta + \\epsilon) = \\text{Cov}(\\epsilon) = \\sigma^2 I_N$. Substituting this into the expression for $\\text{Cov}(\\hat{\\beta})$ yields:\n$$\n\\text{Cov}(\\hat{\\beta}) = (X^{\\top} X)^{-1} X^{\\top} (\\sigma^2 I_N) X (X^{\\top} X)^{-1} = \\sigma^2 (X^{\\top} X)^{-1} (X^{\\top} X) (X^{\\top} X)^{-1}\n$$\nThis simplifies to the well-known result:\n$$\n\\text{Cov}(\\hat{\\beta}) = \\sigma^2 (X^{\\top} X)^{-1}\n$$\nThe variance of a single coefficient estimate, $\\hat{\\beta}_j$, is the $j$-th diagonal element of this covariance matrix:\n$$\n\\text{Var}(\\hat{\\beta}_j) = [\\text{Cov}(\\hat{\\beta})]_{jj} = \\sigma^2 [(X^{\\top} X)^{-1}]_{jj}\n$$\nThe problem states that for the given design matrix $X$, the relationship $X^{\\top} X = N R$ holds, where $N=200$ is the sample size and $R$ is the sample correlation matrix of the columns of $X$. Substituting this into the variance expression, we find the relationship between the variance of the estimates and the design correlation structure:\n$$\n\\text{Var}(\\hat{\\beta}_j) = \\sigma^2 [(N R)^{-1}]_{jj} = \\frac{\\sigma^2}{N} [R^{-1}]_{jj}\n$$\nThe variance-inflation factor (VIF) is defined as the ratio of the variance of a coefficient estimate under the given design to its variance under a counterfactual design where the regressors are mutually orthogonal but have the same column norms.\n\nLet's first determine the variance in the counterfactual orthogonal design, denoted $X_{ortho}$. The problem states that the columns of $X_{ortho}$ have the same norms as the columns of $X$. Since the columns of $X$ are standardized to have unit variance, the sum of squares for each column is $N$. Thus, $\\|X_j\\|^2 = X_j^\\top X_j = N$. The counterfactual design $X_{ortho}$ thus has orthogonal columns with $\\|X_{ortho,j}\\|^2 = N$. The Gram matrix for this orthogonal design is a diagonal matrix:\n$$\nX_{ortho}^{\\top} X_{ortho} = \\begin{pmatrix} N  0  0 \\\\ 0  N  0 \\\\ 0  0  N \\end{pmatrix} = N I_3\n$$\nThe variance of the estimate $\\hat{\\beta}_{j, ortho}$ in this case is:\n$$\n\\text{Var}(\\hat{\\beta}_{j, ortho}) = \\sigma^2 [(N I_3)^{-1}]_{jj} = \\sigma^2 \\left[\\frac{1}{N} I_3\\right]_{jj} = \\frac{\\sigma^2}{N}\n$$\nNow, we can compute the VIF for the $j$-th coefficient as defined:\n$$\n\\text{VIF}_j = \\frac{\\text{Var}(\\hat{\\beta}_j)}{\\text{Var}(\\hat{\\beta}_{j, ortho})} = \\frac{\\frac{\\sigma^2}{N} [R^{-1}]_{jj}}{\\frac{\\sigma^2}{N}} = [R^{-1}]_{jj}\n$$\nThus, the VIF for each coefficient is simply the corresponding diagonal element of the inverse of the correlation matrix $R$.\n\nWe are given the correlation matrix:\n$$\nR = \\begin{pmatrix}\n1  r  0 \\\\\nr  1  0 \\\\\n0  0  1\n\\end{pmatrix} \\quad\\text{with}\\quad r = 0.8\n$$\nThis is a block-diagonal matrix. Its inverse is the block-diagonal matrix of the inverses of its blocks. Let the top-left $2 \\times 2$ block be $R_{12} = \\begin{pmatrix} 1  r \\\\ r  1 \\end{pmatrix}$.\nThe determinant of this block is $\\det(R_{12}) = 1 \\cdot 1 - r \\cdot r = 1 - r^2$.\nThe inverse is $R_{12}^{-1} = \\frac{1}{1-r^2} \\begin{pmatrix} 1  -r \\\\ -r  1 \\end{pmatrix}$.\nThe bottom-right block is just the scalar $1$, whose inverse is $1$.\nTherefore, the inverse of the full correlation matrix is:\n$$\nR^{-1} = \\begin{pmatrix}\n\\frac{1}{1-r^2}  \\frac{-r}{1-r^2}  0 \\\\\n\\frac{-r}{1-r^2}  \\frac{1}{1-r^2}  0 \\\\\n0  0  1\n\\end{pmatrix}\n$$\nThe VIFs for the three regressors (A, B, M) are the diagonal elements of this matrix:\n$\\text{VIF}_A = [R^{-1}]_{11} = \\frac{1}{1-r^2}$\n$\\text{VIF}_B = [R^{-1}]_{22} = \\frac{1}{1-r^2}$\n$\\text{VIF}_M = [R^{-1}]_{33} = 1$\n\nWe substitute the given value $r=0.8$:\n$r^2 = (0.8)^2 = 0.64$\n$1 - r^2 = 1 - 0.64 = 0.36$\nThe VIFs for regressors $A$ and $B$ are:\n$\\text{VIF}_A = \\text{VIF}_B = \\frac{1}{0.36} = \\frac{1}{36/100} = \\frac{100}{36} = \\frac{25}{9}$\nThe VIF for regressor $M$ is:\n$\\text{VIF}_M = 1$\nThis result is expected, as regressor $M$ is uncorrelated with regressors $A$ and $B$, so its variance is not inflated by their presence. The high correlation between $A$ and $B$ results in a significant inflation of the variance for their respective coefficient estimates.\n\nThe three variance-inflation factors for $(A, B, M)$ are $(\\frac{25}{9}, \\frac{25}{9}, 1)$. We report this as a single row matrix.",
            "answer": "$$\n\\boxed{\\begin{pmatrix} \\frac{25}{9}  \\frac{25}{9}  1 \\end{pmatrix}}\n$$"
        }
    ]
}