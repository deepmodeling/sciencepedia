{
    "hands_on_practices": [
        {
            "introduction": "在我们分析神经信号丰富的时频结构之前，我们必须首先理解如何构建频谱图。第一个练习  关注一个基本参数：跳跃尺寸 $H$ (hop size)，它决定了连续分析窗（长度为 $L$）之间的重叠程度。通过推导重叠率和跳跃尺寸之间的关系，您将揭示为何50%的重叠是一个标准选择，以及它如何直接影响您时频表示的平滑度和可靠性。",
            "id": "4194041",
            "problem": "您正在分析以采样频率 $F_{s}$ 记录的啮齿动物前额叶皮层的局部场电位数据，并计划使用短时傅里叶变换 (STFT) 计算频谱图。STFT 的定义是对离散时间信号 $x[n]$ 的重叠分段应用加窗傅里叶变换，其中使用长度为 $L$ 个样本的固定分析窗 $w[n]$，连续的分段起始于索引 $n_{m} = m H$，其中 $H$ 是以样本为单位的跳跃步长，$m$ 是整数帧索引。连续分段之间的重叠定义为共享样本数与窗长的比率。\n\n从这些定义和连续窗口的离散时间索引关系出发，推导在固定窗长 $L$ 的情况下，重叠率与跳跃步长 $H$ 之间的关系。使用此关系确定实现 $50\\%$ 重叠的跳跃步长 $H$。然后，引用神经科学信号处理中使用的窗函数族的适当且经过充分检验的特性，论证这种重叠选择如何影响 (i) STFT 表示的时域冗余度，以及 (ii) 频谱图幅度随时间变化的平滑度。\n\n以样本为单位给出跳跃步长的最终答案。无需四舍五入。您的论证必须基于第一性原理和经过充分检验的事实，不应依赖未经证实的启发式方法或快捷公式。",
            "solution": "问题陈述被认为是有效的，因为它在科学上基于数字信号处理的原理，特别是短时傅里叶变换 (STFT)，并且是适定的、客观的，且包含足够的信息以得到唯一解。\n\n问题要求推导重叠率、窗长 $L$ 和跳跃步长 $H$ 之间的关系，然后计算特定重叠下的 $H$ 值，并对这一选择进行论证。\n\n首先，我们推导重叠率、窗长 $L$ 和跳跃步长 $H$ 之间的关系。STFT 通过将离散时间信号 $x[n]$ 分割成帧来进行分析。每一帧都是信号与长度为 $L$ 个样本的分析窗 $w[n]$ 的乘积。\n\n让我们考虑两个连续的分析帧。第 $m$ 帧从样本索引 $n_m = m H$ 开始。窗函数 $w[n]$ 的支撑集范围是从 $n=0$到 $n=L-1$。因此，被分析信号的第 $m$ 个分段所跨越的索引范围是从 $m H$ 到 $m H + L - 1$。\n\n下一帧是第 $(m+1)$ 帧，它从样本索引 $n_{m+1} = (m+1) H$ 开始。该分段跨越的索引范围是从 $(m+1) H$ 到 $(m+1) H + L - 1$。\n\n要发生重叠，必须有 $H < L$。重叠部分由同时属于第 $m$ 段和第 $(m+1)$ 段的样本组成。第 $m$ 段在索引 $m H + L - 1$ 处结束。第 $(m+1)$ 段在索引 $(m+1) H$ 处开始。因此，重叠样本的索引范围是从 $(m+1) H$ 到 $m H + L - 1$。\n\n重叠样本的数量，我们记为 $N_{overlap}$，是该范围内的整数个数。\n$$\nN_{overlap} = (m H + L - 1) - ((m+1) H) + 1\n$$\n$$\nN_{overlap} = m H + L - 1 - m H - H + 1\n$$\n$$\nN_{overlap} = L - H\n$$\n问题将重叠率（我们称之为 $O$）定义为共享样本数与窗长 $L$ 的比率。\n$$\nO = \\frac{N_{overlap}}{L}\n$$\n代入我们对 $N_{overlap}$ 的表达式：\n$$\nO = \\frac{L - H}{L} = 1 - \\frac{H}{L}\n$$\n这就是重叠率 $O$、窗长 $L$ 和跳跃步长 $H$ 之间的一般关系。\n\n接下来，我们需要确定实现 $50\\%$ 重叠的跳跃步长 $H$。$50\\%$ 的重叠对应于重叠率 $O = 0.5$。\n我们将这个值代入推导出的关系中：\n$$\n0.5 = 1 - \\frac{H}{L}\n$$\n重新整理方程以求解 $H$：\n$$\n\\frac{H}{L} = 1 - 0.5\n$$\n$$\n\\frac{H}{L} = 0.5\n$$\n$$\nH = 0.5 L = \\frac{L}{2}\n$$\n因此，等于窗长一半的跳跃步长可实现 $50\\%$ 的重叠。\n\n最后，我们必须就 (i) 时域冗余度和 (ii) 频谱图幅度的平滑度来论证这一重叠选择的合理性。\n\n(i) 时域冗余度：\n比率 $L/H$ 代表时域的过采样因子。它表示平均有多少个分析窗覆盖输入信号 $x[n]$ 的单个样本。当跳跃步长为 $H = L/2$ 时，过采样因子为 $L / (L/2) = 2$。这意味着信号中的每个样本（除了信号最初和最后 $L/2$ 个样本内的那些样本）都恰好包含在两个连续的分析窗中。这种信息的重复在 STFT 的时间轴上产生了冗余。虽然频谱图中连续的时间帧现在是相关的，但这种冗余对于稳健地跟踪频谱变化是有益的，并且如果需要，它也是从修改后的 STFT 中完美重建信号的先决条件。\n\n(ii) 频谱图幅度随时间变化的平滑度：\n频谱图幅度在时间帧上的平滑度对于准确表示信号频率内容的时间演变至关重要。STFT 分析中的一个重要问题是频谱泄漏和“栅栏效应”，这些问题可能会因时间轴上的“扇形损失”而加剧。扇形损失指的是当信号分量的位置相对于分析窗中心移动时，其估计幅度发生的调制。\n\n神经科学中使用的窗函数（例如，Hann、Hamming、Blackman）是锥形的，意味着它们的幅度在中心处最大，并在边缘处衰减到零（或接近零）。如果一个瞬态信号事件或连续正弦波的一部分落在一个窗的边缘附近，其对该帧频谱的贡献将被严重衰减。然而，在 $50\\%$ 重叠（$H = L/2$）的情况下，如果一个事件位于帧 $m$ 的边缘，它将位于后续帧 $m+1$ 的中心。\n\n这一特性被恒定重叠相加 (COLA) 准则正式地描述。对于许多标准窗函数，$50\\%$ 的重叠确保窗函数值的平方和是恒定的，即对于某个常数 $C > 0$，有 $\\sum_{m} w^2[n - mH] = C$。例如，对于定义为 $w[n] = 0.5 - 0.5 \\cos(2\\pi n / (L-1))$（其中 $n \\in [0, L-1]$）的 Hann 窗，选择 $H=L/2$（对于偶数 $L$）会得到一个恒定的平方和。这一特定属性被称为 Princen-Bradley 条件。\n\n这种恒定能量加权确保了信号分量的总能量在各帧之间得到一致的表示，无论其与窗中心的对齐情况如何。这减轻了时间上的扇形损失，防止了频谱图中的人为幅度调制。结果得到的频谱图，其幅度变化平滑且忠实地反映了信号功率谱的内在动态，而不是加窗过程产生的人为结果。因此，对于生成平滑且可靠的频谱图而言，$50\\%$ 的重叠是一个标准且理由充分的选择。",
            "answer": "$$\n\\boxed{\\frac{L}{2}}\n$$"
        },
        {
            "introduction": "时频分析的核心挑战是在时间分辨率和频率分辨率之间进行权衡，这是不确定性原理的直接体现。这个练习  让您扮演一位分析师，任务是设计一个能够分辨特定神经振荡的频谱图。您将学习如何将一个科学需求——区分临近的频率 $\\Delta f$——转化为分析中一个具体的参数选择：所需的最小窗口长度 $L_{\\min}$。",
            "id": "4194060",
            "problem": "一段皮层局部场电位（LFP）记录以 $f_{s} = 2000$ Hz 的采样率进行采样，并使用通过短时傅里叶变换（STFT）计算的频谱图进行分析。通过对连续的数据段应用长度为 $L$ 的汉宁窗来生成时频谱块。您的目标是分辨中心频率在 $80$ Hz 附近的窄带高伽马活动，以确保相隔 $5$ Hz 的不同分量不会因窗函数的光谱主瓣而模糊在一起。请仅使用 STFT 和加窗傅里叶变换的基本定义，以及一个经过充分检验的近似（即对于汉宁窗，其数字角频率域上两个第一零点之间的主瓣宽度约为 $\\Delta \\omega_{\\mathrm{ML}} \\approx 8\\pi/L$），从第一性原理出发，推导出最小窗口持续时间 $T_{\\min}$（单位为秒），以使汉宁窗主瓣宽度（以赫兹为单位）不超过 $5$ Hz。然后，在 $f_{s} = 2000$ Hz 的采样率下，计算对应的最小整数窗口长度 $L_{\\min}$（单位为样本点数）。最终答案仅报告整数 $L_{\\min}$（单位为样本点数）。除了取最小整数样本数外，不需要根据有效数字进行舍入。",
            "solution": "问题是确定用于短时傅里叶变换（STFT）分析的最小窗口长度 $L_{\\min}$（以样本点数计），该分析需要提供指定的频率分辨率。此分析使用汉宁窗。\n\n首先，我们必须建立不同频率域之间的关系。以赫兹（Hz）为单位的连续时间（模拟）频率 $f$ 与以弧度/样本为单位的离散时间（数字）角频率 $\\omega$ 通过采样率 $f_s$（单位赫兹）或等效的采样周期 $T_s = 1/f_s$（单位秒）相关联。该关系由下式给出：\n$$ \\omega = 2\\pi f T_s = \\frac{2\\pi f}{f_s} $$\n该方程定义了从模拟频率轴到数字频率轴的映射。因此，模拟域中的频率间隔 $\\Delta f$ 对应于数字域中的数字角频率间隔 $\\Delta \\omega$。通过对上述表达式求导，或考虑两个频率之间的间隔，我们可以找到频率宽度的转换关系：\n$$ \\Delta \\omega = \\frac{2\\pi \\Delta f}{f_s} $$\n重新整理该方程，我们可以将数字角频率域中的宽度 ($\\Delta \\omega$) 转换为模拟频率域中的宽度 ($\\Delta f$)：\n$$ \\Delta f = \\frac{f_s}{2\\pi} \\Delta \\omega $$\n题目提供了一个著名的近似公式，用于计算长度为 $L$ 个样本点的汉宁窗的主瓣宽度。这个宽度是在数字角频率域中，其傅里叶变换的两个第一零点（zeros）之间测量的，其值为：\n$$ \\Delta \\omega_{\\mathrm{ML}} \\approx \\frac{8\\pi}{L} $$\n为了求出以赫兹为单位的主瓣宽度 $\\Delta f_{\\mathrm{ML}}$，我们将此表达式代入我们的转换公式中：\n$$ \\Delta f_{\\mathrm{ML}} = \\frac{f_s}{2\\pi} \\Delta \\omega_{\\mathrm{ML}} \\approx \\frac{f_s}{2\\pi} \\left(\\frac{8\\pi}{L}\\right) = \\frac{4f_s}{L} $$\n题目要求我们能够分辨相隔 $5$ Hz 的频谱分量。分辨两个频率的一个常用标准是，频谱分析窗的主瓣宽度必须小于或等于我们感兴趣的频率间隔。这可以确保一个分量的峰值不会落入另一个分量的主瓣内，从而防止它们被模糊成一个单独的峰。因此，我们必须满足以下条件：\n$$ \\Delta f_{\\mathrm{ML}} \\le 5 \\, \\text{Hz} $$\n将我们推导出的 $\\Delta f_{\\mathrm{ML}}$ 表达式代入，得到不等式：\n$$ \\frac{4f_s}{L} \\le 5 $$\n作为推导的一部分，题目要求计算最小窗口持续时间 $T_{\\min}$。窗口的持续时间 $T$（单位秒）与其样本长度 $L$ 的关系为 $T = L T_s = L/f_s$。我们可以用 $T$ 来重写这个不等式：\n$$ \\frac{4}{L/f_s} \\le 5 \\implies \\frac{4}{T} \\le 5 $$\n解出 $T$ 可得：\n$$ T \\ge \\frac{4}{5} \\, \\text{s} = 0.8 \\, \\text{s} $$\n因此，所需的最小窗口持续时间为 $T_{\\min} = 0.8$ 秒。\n\n主要目标是找到最小整数窗口长度 $L_{\\min}$。我们回到包含 $L$ 的不等式：\n$$ \\frac{4f_s}{L} \\le 5 $$\n我们解出 $L$：\n$$ L \\ge \\frac{4f_s}{5} $$\n现在，我们代入给定的采样率 $f_s = 2000$ Hz：\n$$ L \\ge \\frac{4 \\times 2000}{5} = \\frac{8000}{5} = 1600 $$\n窗口长度 $L$ 必须是整数个样本点。满足此条件的最小整数 $L$ 值为 $1600$。因此，最小整数窗口长度为：\n$$ L_{\\min} = 1600 $$",
            "answer": "$$\\boxed{1600}$$"
        },
        {
            "introduction": "频谱图不仅仅是一种可视化工具；它是一个丰富的数据集，可用于检验科学假设。最后一个综合性练习  将引导您完成一个完整的分析流程，从原始的多试次数据到关于刺激诱发功率变化的统计推断。通过实现一个基于聚类的置换检验，您将掌握一种强大的技术，用于识别显著的神经活动，同时严格控制在分析大型时频图时固有的假阳性问题。",
            "id": "4194056",
            "problem": "给定一个模拟的多试验脑电生理学数据集，代表时间序列 $\\{x_i[t]\\}_{i=1}^{N}$，其中每个 $x_i[t]$ 是随时间 $t$（单位为秒）测量的电压，而 $N$ 表示试验次数。采样率为 $f_s$，单位为赫兹 (Hz)。在时间 $t_0$（单位为秒）发生一次刺激，部分试验包含伽马波段（定义为 $30$–$80$ Hz）的诱发振荡。您的任务是计算时频谱图，构建试验级别的基线校正伽马功率差异，并执行基于聚类的置换检验以检测刺激后伽马功率的增加。您必须报告显著的时频聚类及其经族系误差校正的 $p$ 值。\n\n从短时傅里叶变换 (STFT) 的定义开始。对于以 $f_s$ Hz 采样的离散时间信号 $x[t]$ 和长度为 $L$ 的窗函数 $w[n]$，在时间帧索引 $m$ 和频率区间索引 $k$ 处的 STFT 为\n$$\nX[m,k] = \\sum_{n=0}^{L-1} x[n + mR] \\, w[n] \\, e^{-j 2 \\pi k n / L},\n$$\n其中 $R$ 是以样本为单位的跳跃大小，$j$ 是虚数单位。谱图功率为 $P[m,k] = |X[m,k]|^2$。令 $f[k]$ 表示频率区间 $k$ 对应的频率（单位为 Hz），$t[m]$ 表示时间帧 $m$ 的中心时间（单位为秒）。\n\n定义一个刺激后时间窗 $W_{\\text{post}} = [t_0 + \\Delta_1, t_0 + \\Delta_2]$ 和一个基线时间窗 $W_{\\text{base}} = [t_0 - \\Delta_2, t_0 - \\Delta_1]$，其中 $\\Delta_1$ 和 $\\Delta_2$ 以秒为单位指定。将分析限制在伽马波段，即频率 $f[k] \\in [30,80]$ Hz。对于每个试验 $i$、每个伽马频率区间 $k$ 以及每个满足 $t[m] \\in W_{\\text{post}}$ 的刺激后时间帧 $m$，计算一个基线校正的功率差异\n$$\nD_i[k,m] = P_i[k,m] - \\frac{1}{|M_{\\text{base}}(k)|} \\sum_{m' \\in M_{\\text{base}}(k)} P_i[k,m'],\n$$\n其中 $P_i$ 是试验 $i$ 的谱图功率，$M_{\\text{base}}(k)$ 是满足 $t[m'] \\in W_{\\text{base}}$ 的基线时间帧的索引集。这样就得到了一个跨试验的时频差异网格 $\\{D_i[k,m]\\}$。\n\n构建单样本零假设，即刺激后伽马功率没有增加，对于每个时频区间 $(k,m)$，\n$$\nH_0: \\mu_{D}[k,m] = 0,\n$$\n其中 $\\mu_{D}[k,m]$ 是 $D_i[k,m]$ 的跨试验均值。在每个 $(k,m)$ 处，使用以下公式跨试验计算学生 t 统计量\n$$\nt[k,m] = \\frac{\\overline{D}[k,m]}{s_D[k,m]/\\sqrt{N}},\n$$\n其中 $\\overline{D}[k,m]$ 是样本均值，$s_D[k,m]$ 是跨试验的样本标准差，N 为试验次数。\n\n使用学生 t 分布在水平 $\\alpha_{\\text{cf}}$ 和 $N-1$ 自由度下对应的单侧临界值作为聚类形成阈值，仅保留 $t[k,m]$ 超过此阈值的区间。使用 4-连通性（在时间或频率上相邻）将时频网格中的连续区间定义为聚类。对于每个聚类 $C$，将其质量定义为 t 统计量的总和：\n$$\nS(C) = \\sum_{(k,m) \\in C} t[k,m].\n$$\n\n使用跨试验的符号翻转执行基于聚类的置换检验（在对称零假设下对配对差异有效）。对于每次置换 $p = 1, \\dots, P$，为试验 $i = 1, \\dots, N$ 抽取独立的随机符号 $\\sigma_i^{(p)} \\in \\{-1, +1\\}$，形成 $\\tilde{D}_i^{(p)}[k,m] = \\sigma_i^{(p)} \\cdot D_i[k,m]$，重新计算 t-map 和聚类质量，并记录最大聚类质量\n$$\nM^{(p)} = \\max_{C^{(p)}} S\\left(C^{(p)}\\right),\n$$\n如果在置换 $p$ 下没有形成聚类，则 $M^{(p)} = 0$。对于每个观察到的聚类 $C$，使用最大统计量分布计算族系误差校正的 p 值，\n$$\np_{\\text{corr}}(C) = \\frac{1 + \\left|\\left\\{p : M^{(p)} \\ge S(C)\\right\\}\\right|}{P + 1}.\n$$\n如果对于指定的 $\\alpha$，有 $p_{\\text{corr}}(C)  \\alpha$，则宣布聚类 $C$ 是显著的。\n\n将上述过程实现为一个完整的、可运行的程序，该程序模拟包含和不含刺激诱发的伽马脉冲的试验。使用以下固定的分析参数：采样率 $f_s = 500$ Hz，总时长 $T = 2.0$ 秒，刺激时间 $t_0 = 1.0$ 秒，STFT 窗长 $L = 256$ 个样本，跳跃大小 $R = 64$ 个样本，窗函数 $w[n]$ 为汉宁窗。使用 $W_{\\text{base}} = [0.6, 0.9]$ 秒和 $W_{\\text{post}} = [1.1, 1.5]$ 秒。当伽马脉冲存在时，它是一个频率为 $f_{\\gamma} = 40$ Hz 的正弦波，其振幅在 $[1.15, 1.45]$ 秒内用汉宁包络进行锥化处理。\n\n您的程序应实现以下参数集的测试套件，每个参数集指定为一个元组 $(N, A_{\\gamma}, P, \\alpha_{\\text{cf}}, \\alpha, \\text{seed})$：\n- 测试用例 1: $(60, 2.0, 500, 0.05, 0.05, 42)$。\n- 测试用例 2: $(60, 0.0, 500, 0.05, 0.05, 43)$。\n- 测试用例 3: $(20, 0.8, 300, 0.05, 0.05, 44)$。\n\n在这里，$N$ 是试验次数，$A_{\\gamma}$ 是伽马脉冲振幅（相对于噪声的无单位值，其中 $A_{\\gamma} = 0.0$ 表示没有伽马脉冲），$P$ 是置换次数，$\\alpha_{\\text{cf}}$ 是聚类形成阈值水平，$\\alpha$ 是族系误差水平，$\\text{seed}$ 是控制可复现性的随机种子。\n\n对于每个测试用例，计算伽马波段内的显著聚类数量以及所有观察到的聚类中最小的校正后 $p$ 值（如果没有观察到聚类，则报告 $1.0$）。您的程序应生成单行输出，包含一个用方括号括起来的逗号分隔列表形式的结果，其中每个测试用例的结果报告为一个双元素列表 $[n_{\\text{sig}}, p_{\\min}]$。例如，输出格式应类似于 $[[n_{\\text{sig}}^{(1)}, p_{\\min}^{(1)}],[n_{\\text{sig}}^{(2)}, p_{\\min}^{(2)}],[n_{\\text{sig}}^{(3)}, p_{\\min}^{(3)}]]$。输出中不需要物理单位，因为计数和 $p$ 值是无单位的。如果需要使用角度，必须以弧度为单位，但此任务中没有出现角度量。",
            "solution": "用户提供了一个问题，要求实现一个完整的流程来分析模拟的脑电生理数据，最终通过基于聚类的置换检验来识别显著的时频模式。该问题在科学上是合理的、定义明确的，并且所有必要的参数都已指定。我将着手提供一个完整的解决方案。\n\n该解决方案围绕神经科学中常用的时频分析和非参数统计的基本原则构建。\n\n1.  **原则 1：用于方法验证的数据模拟**\n    为了测试和验证分析流程，我们首先合成一个模仿真实神经数据关键特征的数据集。每次试验都由信号加噪声组成。\n    -   **噪声**：背景神经活动被建模为高斯白噪声 $\\mathcal{N}(0,1)$。这代表了记录信号中随机的、与刺激无关的波动。\n    -   **信号**：刺激诱发效应是伽马波段的振荡。这由一个频率为 $f_{\\gamma} = 40$ Hz 的正弦波表示。正弦波的振幅通过一个汉宁窗 $A_{\\gamma} w_{\\text{Hanning}}(t)$ 进行调制，以在特定的刺激后时间区间 $[1.15, 1.45]$ 秒内创建一个瞬态脉冲。参数 $A_{\\gamma}$ 控制信噪比。试验 $i$ 的信号为 $x_i[t] = \\text{signal}[t] + \\text{noise}_i[t]$。\n\n2.  **原则 2：通过STFT进行时频分解**\n    神经信号是非平稳的，意味着它们的频率内容会随时间变化。短时傅里叶变换（STFT）是分析此类信号的标准方法。它的工作原理是将信号分成短的、重叠的段，应用一个窗函数，并为每个段计算傅里叶变换。\n    -   **谱图**：对于信号 $x[t]$，STFT $X[m,k]$ 为每个时间帧 $m$ 和频率区间 $k$ 提供一个复数值。功率谱图 $P[m,k] = |X[m,k]|^2$ 量化了信号在特定时频坐标上的能量。\n    -   **实现**：我们使用长度为 $L=256$ 个样本的汉宁窗和 $R=64$ 个样本的跳跃大小。这种选择平衡了时间分辨率（由 $R$ 决定）和频率分辨率（由 $L$ 决定）。\n\n3.  **原则 3：基线校正以分离刺激效应**\n    为了分离由刺激引起的功率变化，我们将刺激后时间窗内的功率与刺激前基线时间窗内的功率进行比较。\n    -   **差异度量**：对于每次试验 $i$ 和频率区间 $k$，我们计算基线时间窗 $W_{\\text{base}} = [0.6, 0.9]$ s 内的平均功率。设其为 $\\bar{P}_{i, \\text{base}}[k]$。然后，我们为刺激后时间窗 $W_{\\text{post}} = [1.1, 1.5]$ s 内的每个时间帧 $m$ 计算差异 $D_i[k,m] = P_i[k,m] - \\bar{P}_{i, \\text{base}}[k]$。这种减法校正有助于解释与刺激无关的试验间变异性和特定频率的功率差异。\n\n4.  **原则 4：逐点假设检验**\n    为了评估观察到的功率增加是否具有统计学意义，我们在分析窗口中的每个时频点 $(k,m)$ 处制定一个假设检验。\n    -   **零假设**：零假设 $H_0: \\mu_{D}[k,m] = 0$ 指出，从基线到刺激后期间，功率没有平均变化。\n    -   **检验统计量**：我们使用单样本学生 t 统计量来检验这个假设，该统计量在 $N$ 次试验中计算得出：\n        $$\n        t[k,m] = \\frac{\\overline{D}[k,m]}{s_D[k,m]/\\sqrt{N}}\n        $$\n        其中 $\\overline{D}[k,m]$ 和 $s_D[k,m]$ 分别是 $D_i[k,m]$ 在各试验中的样本均值和标准差。一个大的正 t 值表明功率有显著增加。\n\n5.  **原则 5：用于多重比较校正的基于聚类的置换检验**\n    执行数千次 t 检验（每个时频区间一次）会产生严重的多重比较问题，如果不进行校正，将导致很高的假阳性率。基于聚类的置换检验是一种强大的方法，它通过结合数据的空间结构（即时间和频率上的连续性）来解决这个问题。\n    -   **步骤 5a：聚类形成**：我们首先识别候选聚类。观察到的 t-map $\\{t[k,m]\\}$ 使用来自学生 t 分布的临界值（例如，在 $\\alpha_{\\text{cf}} = 0.05$）进行阈值处理。超过此阈值的空间相邻点被分组为聚类。聚类 $C$ 的“质量”定义为其内部 t 值的总和，$S(C) = \\sum_{(k,m) \\in C} t[k,m]$。\n    -   **步骤 5b：通过置换生成零分布**：为了确定观察到的聚类质量是否大于偶然预期的值，我们生成一个零分布。这是通过重复置换数据来完成的。在零假设下，任何给定试验的差异值 $D_i[k,m]$ 的符号是任意的。因此，我们可以通过随机翻转随机选择的部分试验的整个数据的符号来创建代理数据集：$\\tilde{D}_i[k,m] = \\sigma_i \\cdot D_i[k,m]$，其中 $\\sigma_i \\in \\{-1, +1\\}$。\n    -   **步骤 5c：最大统计量**：对于 $P$ 次置换中的每一次，我们重新计算整个 t-map，形成聚类，并找到最大聚类质量 $M^{(p)} = \\max_{C^{(p)}} S(C^{(p)})$。如果没有形成聚类，则 $M^{(p)}=0$。这些最大统计量的分布 $\\{M^{(p)}\\}_{p=1}^P$ 作为我们的经验零分布。使用最大统计量自动校正了在所有可能聚类中进行搜索的问题。\n    -   **步骤 5d：族系误差（FWE）校正的P值**：通过将其质量 $S(C)$ 与最大质量的零分布进行比较，来评估原始观察到的聚类 $C$ 的显著性。FWE 校正的 p 值为：\n        $$\n        p_{\\text{corr}}(C) = \\frac{1 + \\left|\\left\\{p : M^{(p)} \\ge S(C)\\right\\}\\right|}{P + 1}\n        $$\n    -   **推断**：如果一个观察到的聚类的校正后 p 值低于期望的族系误差率 $\\alpha$，则宣布其在统计上是显著的。\n\n这个从数据模拟到统计推断的全面过程，在下面的 Python 代码中实现，并遵循每个测试用例指定的参数。",
            "answer": "```python\nimport numpy as np\nfrom scipy import signal\nfrom scipy import stats\n\ndef find_clusters(grid):\n    \"\"\"\n    Finds 4-connectivity clusters in a 2D boolean grid using BFS.\n\n    Args:\n        grid (np.ndarray): A 2D boolean numpy array.\n\n    Returns:\n        list: A list of clusters, where each cluster is a list of (row, col) tuples.\n    \"\"\"\n    rows, cols = grid.shape\n    visited = np.zeros_like(grid, dtype=bool)\n    clusters = []\n    for r in range(rows):\n        for c in range(cols):\n            if grid[r, c] and not visited[r, c]:\n                # Start of a new cluster\n                cluster = []\n                q = [(r, c)]\n                visited[r, c] = True\n                \n                head = 0\n                while head  len(q):\n                    curr_r, curr_c = q[head]\n                    head += 1\n                    cluster.append((curr_r, curr_c))\n                    \n                    # Check 4 neighbors (up, down, left, right)\n                    for dr, dc in [(0, 1), (0, -1), (1, 0), (-1, 0)]:\n                        next_r, next_c = curr_r + dr, curr_c + dc\n                        \n                        if 0 = next_r  rows and 0 = next_c  cols:\n                            if grid[next_r, next_c] and not visited[next_r, next_c]:\n                                visited[next_r, next_c] = True\n                                q.append((next_r, next_c))\n                clusters.append(cluster)\n    return clusters\n\ndef run_analysis(N, A_gamma, P, alpha_cf, alpha, seed):\n    \"\"\"\n    Runs the full simulation and cluster-based permutation test for one test case.\n    \"\"\"\n    # 1. Set up RNG and constants\n    rng = np.random.default_rng(seed)\n    fs = 500\n    T = 2.0\n    t0 = 1.0\n    L = 256\n    R = 64\n    noverlap = L - R\n    \n    w_base = [0.6, 0.9]\n    w_post = [1.1, 1.5]\n    f_gamma_band = [30, 80]\n    f_gamma_burst = 40\n    t_burst_window = [1.15, 1.45]\n\n    # 2. Simulate data\n    t_vec = np.arange(0, T, 1 / fs)\n    n_samples = len(t_vec)\n    data = rng.standard_normal((N, n_samples))\n\n    if A_gamma > 0:\n        gamma_signal = np.sin(2 * np.pi * f_gamma_burst * t_vec)\n        burst_indices = (t_vec >= t_burst_window[0])  (t_vec = t_burst_window[1])\n        hanning_taper = np.zeros(n_samples)\n        hanning_taper[burst_indices] = np.hanning(np.sum(burst_indices))\n        gamma_burst = A_gamma * gamma_signal * hanning_taper\n        data += gamma_burst[np.newaxis, :]\n\n    # 3. Compute STFT and power for all trials\n    f_stft, t_stft, Zxx = signal.stft(data, fs=fs, window='hann', nperseg=L, noverlap=noverlap)\n    power_spectrograms = np.abs(Zxx)**2\n\n    # 4. Select frequency and time windows\n    gamma_freq_mask = (f_stft >= f_gamma_band[0])  (f_stft = f_gamma_band[1])\n    base_time_mask = (t_stft >= w_base[0])  (t_stft = w_base[1])\n    post_time_mask = (t_stft >= w_post[0])  (t_stft = w_post[1])\n    \n    # 5. Baseline Correction\n    power_gamma = power_spectrograms[:, gamma_freq_mask, :]\n    baseline_mean_power = np.mean(power_gamma[:, :, base_time_mask], axis=2, keepdims=True)\n    post_stim_power = power_gamma[:, :, post_time_mask]\n    \n    D = post_stim_power - baseline_mean_power\n\n    # 6. Compute observed t-statistics and find clusters\n    mean_D = np.mean(D, axis=0)\n    std_D = np.std(D, axis=0, ddof=1)\n    \n    # Handle division by zero\n    t_obs = np.zeros_like(mean_D)\n    non_zero_std = std_D > np.finfo(float).eps\n    t_obs[non_zero_std] = mean_D[non_zero_std] / (std_D[non_zero_std] / np.sqrt(N))\n    \n    t_crit = stats.t.ppf(1 - alpha_cf, df=N - 1)\n    t_map_thresh = t_obs > t_crit\n    \n    observed_clusters = find_clusters(t_map_thresh)\n    observed_masses = [np.sum(t_obs[tuple(zip(*c))]) for c in observed_clusters]\n\n    # 7. Permutation Test\n    max_perm_masses = np.zeros(P)\n    \n    for i in range(P):\n        signs = rng.choice([-1, 1], size=(N, 1, 1))\n        D_perm = D * signs\n        \n        mean_D_perm = np.mean(D_perm, axis=0)\n        std_D_perm = np.std(D_perm, axis=0, ddof=1)\n        \n        t_perm = np.zeros_like(mean_D_perm)\n        non_zero_std_perm = std_D_perm > np.finfo(float).eps\n        t_perm[non_zero_std_perm] = mean_D_perm[non_zero_std_perm] / (std_D_perm[non_zero_std_perm] / np.sqrt(N))\n        \n        t_perm_thresh = t_perm > t_crit\n        perm_clusters = find_clusters(t_perm_thresh)\n        \n        if perm_clusters:\n            perm_masses = [np.sum(t_perm[tuple(zip(*c))]) for c in perm_clusters]\n            max_perm_masses[i] = np.max(perm_masses)\n\n    # 8. Compute FWE-corrected p-values\n    if not observed_clusters:\n        return [0, 1.0]\n\n    p_values = []\n    for mass in observed_masses:\n        p_val = (1 + np.sum(max_perm_masses >= mass)) / (P + 1)\n        p_values.append(p_val)\n    \n    p_values = np.array(p_values)\n    n_sig = np.sum(p_values  alpha)\n    p_min = np.min(p_values)\n\n    return [int(n_sig), p_min]\n\ndef solve():\n    # Test cases: (N, A_gamma, P, alpha_cf, alpha, seed)\n    test_cases = [\n        (60, 2.0, 500, 0.05, 0.05, 42),\n        (60, 0.0, 500, 0.05, 0.05, 43),\n        (20, 0.8, 300, 0.05, 0.05, 44),\n    ]\n\n    results = []\n    for case in test_cases:\n        n_sig, p_min = run_analysis(*case)\n        results.append([n_sig, p_min])\n    \n    # Format the output string as per requirements\n    formatted_results = [f\"[{n},{p}]\" for n, p in results]\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```"
        }
    ]
}