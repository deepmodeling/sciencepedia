{
    "hands_on_practices": [
        {
            "introduction": "Before building a decoder, it is crucial to understand the theoretical limits of decoding accuracy imposed by the neural code itself. The Cramér–Rao bound, derived from Fisher information, provides a powerful lower bound on the variance of any unbiased estimator, effectively telling us the best possible precision we can hope to achieve. This exercise  guides you through a foundational derivation, connecting the tuning properties of neurons—specifically, their tuning width $\\sigma$—to the ultimate fidelity of the population code.",
            "id": "4154106",
            "problem": "Consider a one-dimensional stimulus $s \\in \\mathbb{R}$ encoded by a large population of conditionally independent neurons. Neuron $i$ has a Gaussian tuning curve $f_{i}(s) = A \\exp\\left(-\\frac{(s - \\mu_{i})^{2}}{2 \\sigma^{2}}\\right)$, where $A > 0$ is the peak mean spike count in the observation window, $\\sigma > 0$ is the tuning width, and $\\mu_{i} \\in \\mathbb{R}$ is the preferred stimulus of neuron $i$. Conditional on $s$, each neuron generates spikes according to a Poisson point process over the observation window, with the spike count $n_{i}$ distributed as a Poisson random variable with mean $f_{i}(s)$. The preferred stimuli $\\mu_{i}$ tile the real line at a uniform density $\\rho > 0$ neurons per unit stimulus (i.e., in the continuum limit $N \\to \\infty$, sums over neurons may be replaced by $\\rho$ times integrals over $\\mu$).\n\nYou are asked to analyze the effect of tuning width on decoding precision using first principles of statistical estimation. Starting from the definitions of the Poisson likelihood and Fisher information, and without invoking any pre-derived shortcut expressions, derive the Cramér–Rao bound (CRB) for the variance of any unbiased estimator of $s$ evaluated at an arbitrary stimulus value $s = s^{\\star}$. Assume scientific realism throughout: independent Poisson spike counts with means given by the tuning curves above, and a densely tiled population as described. Express your final CRB as a single closed-form analytic expression in terms of $A$, $\\sigma$, and $\\rho$. No numerical approximation or rounding is required, and you should not include physical units in your final answer. Your final answer must be a single expression.",
            "solution": "The user wants to find the Cramér–Rao bound (CRB) on the variance of an unbiased estimator of a stimulus $s$. The CRB is given by the inverse of the Fisher information, $I(s)$. We will derive the Fisher information from first principles, starting with the likelihood function for the observed spike counts.\n\nThe problem specifies that the spike count $n_i$ of neuron $i$, conditional on the stimulus $s$, follows a Poisson distribution with mean $f_i(s)$. The probability of observing spike count $n_i$ is:\n$$\nP(n_i | s) = \\frac{(f_i(s))^{n_i} \\exp(-f_i(s))}{n_i!}\n$$\nwhere the tuning curve $f_i(s)$ is given by:\n$$\nf_i(s) = A \\exp\\left(-\\frac{(s - \\mu_i)^2}{2\\sigma^2}\\right)\n$$\nThe neurons are conditionally independent. Therefore, the likelihood function for observing a set of spike counts $\\{n_i\\}$ from the entire population is the product of the individual probabilities:\n$$\nL(\\{n_i\\} | s) = \\prod_i P(n_i | s) = \\prod_i \\frac{(f_i(s))^{n_i} \\exp(-f_i(s))}{n_i!}\n$$\nFor the calculation of Fisher information, it is more convenient to work with the log-likelihood function, $\\ln L$:\n$$\n\\ln L(\\{n_i\\} | s) = \\ln \\left( \\prod_i \\frac{(f_i(s))^{n_i} \\exp(-f_i(s))}{n_i!} \\right)\n$$\nUsing the properties of logarithms, this simplifies to a sum:\n$$\n\\ln L = \\sum_i \\ln \\left( \\frac{(f_i(s))^{n_i} \\exp(-f_i(s))}{n_i!} \\right) = \\sum_i \\left( n_i \\ln(f_i(s)) - f_i(s) - \\ln(n_i!) \\right)\n$$\nThe Fisher information $I(s)$ is defined as the negative of the expected value of the second derivative of the log-likelihood with respect to the parameter $s$:\n$$\nI(s) = -E\\left[\\frac{\\partial^2}{\\partial s^2} \\ln L\\right]\n$$\nAlternatively, for a well-behaved likelihood, it can also be expressed as the expectation of the square of the first derivative:\n$$\nI(s) = E\\left[\\left(\\frac{\\partial}{\\partial s} \\ln L\\right)^2\\right]\n$$\nA general result for conditionally independent observations is that the total Fisher information is the sum of the information from each observation: $I(s) = \\sum_i I_i(s)$. Let's calculate the information for a single neuron, $I_i(s)$, and then sum over the population.\n\nFor a single neuron $i$, the log-likelihood is:\n$$\n\\ln L_i = n_i \\ln(f_i(s)) - f_i(s) - \\ln(n_i!)\n$$\nThe first derivative with respect to $s$ is:\n$$\n\\frac{\\partial}{\\partial s} \\ln L_i = n_i \\frac{f_i'(s)}{f_i(s)} - f_i'(s) = f_i'(s) \\left(\\frac{n_i}{f_i(s)} - 1\\right)\n$$\nwhere $f_i'(s) = \\frac{d f_i(s)}{ds}$.\nThe second derivative is:\n$$\n\\frac{\\partial^2}{\\partial s^2} \\ln L_i = \\frac{\\partial}{\\partial s} \\left[ f_i'(s) \\left(\\frac{n_i}{f_i(s)} - 1\\right) \\right] = f_i''(s) \\left(\\frac{n_i}{f_i(s)} - 1\\right) - f_i'(s) \\left(\\frac{n_i f_i'(s)}{(f_i(s))^2}\\right)\n$$\n$$\n\\frac{\\partial^2}{\\partial s^2} \\ln L_i = \\frac{n_i f_i''(s)}{f_i(s)} - f_i''(s) - \\frac{n_i (f_i'(s))^2}{(f_i(s))^2}\n$$\nNow, we take the expectation with respect to the distribution of $n_i$, which is Poisson with mean $E[n_i] = f_i(s)$.\n$$\nE\\left[\\frac{\\partial^2}{\\partial s^2} \\ln L_i\\right] = \\frac{E[n_i] f_i''(s)}{f_i(s)} - f_i''(s) - \\frac{E[n_i] (f_i'(s))^2}{(f_i(s))^2}\n$$\n$$\nE\\left[\\frac{\\partial^2}{\\partial s^2} \\ln L_i\\right] = \\frac{f_i(s) f_i''(s)}{f_i(s)} - f_i''(s) - \\frac{f_i(s) (f_i'(s))^2}{(f_i(s))^2} = f_i''(s) - f_i''(s) - \\frac{(f_i'(s))^2}{f_i(s)} = -\\frac{(f_i'(s))^2}{f_i(s)}\n$$\nThe Fisher information for a single neuron is $I_i(s) = -E\\left[\\frac{\\partial^2}{\\partial s^2} \\ln L_i\\right] = \\frac{(f_i'(s))^2}{f_i(s)}$.\nThe total Fisher information is the sum over all neurons:\n$$\nI(s) = \\sum_i I_i(s) = \\sum_i \\frac{(f_i'(s))^2}{f_i(s)}\n$$\nNext, we compute the derivative of the tuning curve $f_i(s)$:\n$$\nf_i'(s) = \\frac{d}{ds} \\left[ A \\exp\\left(-\\frac{(s - \\mu_i)^2}{2\\sigma^2}\\right) \\right] = A \\exp\\left(-\\frac{(s - \\mu_i)^2}{2\\sigma^2}\\right) \\cdot \\left(-\\frac{2(s - \\mu_i)}{2\\sigma^2}\\right)\n$$\n$$\nf_i'(s) = - \\frac{s - \\mu_i}{\\sigma^2} f_i(s)\n$$\nSubstituting this into the expression for $I(s)$:\n$$\nI(s) = \\sum_i \\frac{\\left(-\\frac{s - \\mu_i}{\\sigma^2} f_i(s)\\right)^2}{f_i(s)} = \\sum_i \\frac{\\frac{(s - \\mu_i)^2}{\\sigma^4} (f_i(s))^2}{f_i(s)} = \\sum_i \\frac{(s - \\mu_i)^2}{\\sigma^4} f_i(s)\n$$\nNow, substitute the expression for $f_i(s)$:\n$$\nI(s) = \\sum_i \\frac{(s - \\mu_i)^2}{\\sigma^4} A \\exp\\left(-\\frac{(s - \\mu_i)^2}{2\\sigma^2}\\right)\n$$\nThe problem states that in the limit of a large number of neurons, the sum can be replaced by an integral over the preferred stimuli $\\mu$, weighted by the density $\\rho$:\n$$\n\\sum_i g(\\mu_i) \\to \\int_{-\\infty}^{\\infty} \\rho \\, g(\\mu) \\, d\\mu\n$$\nApplying this continuum limit to our expression for $I(s)$:\n$$\nI(s) = \\rho \\int_{-\\infty}^{\\infty} \\frac{(s - \\mu)^2}{\\sigma^4} A \\exp\\left(-\\frac{(s - \\mu)^2}{2\\sigma^2}\\right) d\\mu\n$$\nWe can pull the constants out of the integral:\n$$\nI(s) = \\frac{A\\rho}{\\sigma^4} \\int_{-\\infty}^{\\infty} (s - \\mu)^2 \\exp\\left(-\\frac{(s - \\mu)^2}{2\\sigma^2}\\right) d\\mu\n$$\nTo solve the integral, let's make a substitution $u = s - \\mu$, which means $d\\mu = -du$. The integration limits change from $(-\\infty, \\infty)$ for $\\mu$ to $(\\infty, -\\infty)$ for $u$. We can flip the limits and absorb the minus sign:\n$$\nI(s) = \\frac{A\\rho}{\\sigma^4} \\int_{-\\infty}^{\\infty} u^2 \\exp\\left(-\\frac{u^2}{2\\sigma^2}\\right) du\n$$\nThis is a standard Gaussian-related integral. It corresponds to the unnormalized second moment of a zero-mean Gaussian distribution with variance $\\sigma^2$. We recognize the integral $\\int_{-\\infty}^{\\infty} \\exp(-ax^2)dx = \\sqrt{\\pi/a}$. The value of our integral can be found by differentiation with respect to a parameter. Let $J(a) = \\int_{-\\infty}^{\\infty} \\exp(-au^2) du = \\sqrt{\\pi}a^{-1/2}$. Then\n$$\n\\int_{-\\infty}^{\\infty} u^2 \\exp(-au^2) du = -\\frac{d}{da} J(a) = -\\frac{d}{da}(\\sqrt{\\pi}a^{-1/2}) = -\\sqrt{\\pi}(-\\frac{1}{2}a^{-3/2}) = \\frac{\\sqrt{\\pi}}{2}a^{-3/2}\n$$\nIn our case, $a = \\frac{1}{2\\sigma^2}$. Substituting this value:\n$$\n\\int_{-\\infty}^{\\infty} u^2 \\exp\\left(-\\frac{u^2}{2\\sigma^2}\\right) du = \\frac{\\sqrt{\\pi}}{2} \\left(\\frac{1}{2\\sigma^2}\\right)^{-3/2} = \\frac{\\sqrt{\\pi}}{2} (2\\sigma^2)^{3/2} = \\frac{\\sqrt{\\pi}}{2} 2^{3/2} (\\sigma^2)^{3/2} = \\frac{\\sqrt{\\pi}}{2} (2\\sqrt{2}) \\sigma^3 = \\sigma^3 \\sqrt{2\\pi}\n$$\nNow substitute this result back into the expression for $I(s)$:\n$$\nI(s) = \\frac{A\\rho}{\\sigma^4} (\\sigma^3 \\sqrt{2\\pi}) = \\frac{A\\rho\\sqrt{2\\pi}}{\\sigma}\n$$\nNote that the Fisher information $I(s)$ is independent of the stimulus value $s$. This is due to the translational symmetry of the problem (uniform tiling of preferred stimuli across the entire real line). Therefore, evaluating at an arbitrary stimulus value $s = s^{\\star}$ yields the same result: $I(s^{\\star}) = I(s)$.\n\nThe Cramér–Rao bound (CRB) states that the variance of any unbiased estimator $\\hat{s}$ of the parameter $s$ is bounded below by the inverse of the Fisher information:\n$$\n\\text{Var}(\\hat{s}) \\ge \\frac{1}{I(s)}\n$$\nThe CRB is the value of this lower bound.\n$$\n\\text{CRB} = \\frac{1}{I(s^{\\star})} = \\frac{1}{\\frac{A\\rho\\sqrt{2\\pi}}{\\sigma}} = \\frac{\\sigma}{A\\rho\\sqrt{2\\pi}}\n$$\nThis is the final closed-form expression for the Cramér–Rao bound.",
            "answer": "$$\\boxed{\\frac{\\sigma}{A \\rho \\sqrt{2 \\pi}}}$$"
        },
        {
            "introduction": "Moving from theory to practice, evaluating a decoder's performance requires more than just a single accuracy score, especially in multi-class scenarios. The confusion matrix provides a complete picture of a decoder's successes and failures, breaking down performance for each individual class. This practice  will solidify your understanding of essential classification metrics like precision, recall, and the F1 score, which are critical for diagnosing decoder behavior and making informed improvements.",
            "id": "4154094",
            "problem": "A neuroscience laboratory trains a multi-class probabilistic decoder to infer the identity of sensory stimuli from the joint spike counts of a population of neurons. The experimental design contains $4$ distinct stimulus classes, denoted $\\{A,B,C,D\\}$, and a total of $200$ trials. The decoder is evaluated on held-out data. For each trial, the stimulus is presented and the decoder outputs a single predicted class. The evaluation records, for each true class, the count of decoder outputs across all classes:\n- For trials where the true class is $A$: predicted $A$ in $35$ trials, $B$ in $5$ trials, $C$ in $8$ trials, and $D$ in $2$ trials.\n- For trials where the true class is $B$: predicted $A$ in $4$ trials, $B$ in $26$ trials, $C$ in $6$ trials, and $D$ in $4$ trials.\n- For trials where the true class is $C$: predicted $A$ in $5$ trials, $B$ in $12$ trials, $C$ in $38$ trials, and $D$ in $5$ trials.\n- For trials where the true class is $D$: predicted $A$ in $3$ trials, $B$ in $7$ trials, $C$ in $9$ trials, and $D$ in $31$ trials.\n\nStarting from the core definitions of confusion matrices and count-based evaluation metrics used in multi-class decoding in neuroscience data analysis, perform the following:\n1. Construct the confusion matrix $M$ with entries $M_{ij}$ equal to the number of trials with true class $i \\in \\{A,B,C,D\\}$ and predicted class $j \\in \\{A,B,C,D\\}$, ordered alphabetically for both rows and columns.\n2. From the confusion matrix, compute the overall accuracy, the per-class precision, per-class recall, and per-class F1 score (harmonic mean of precision and recall) for each class $\\{A,B,C,D\\}$, using the standard one-versus-rest interpretation of true positives, false positives, and false negatives for each class.\n3. Compute the macro-averaged F1 score by taking the arithmetic mean of the four per-class F1 scores.\n\nReport all rates as decimals and round to four significant figures. Provide the macro-averaged F1 score as your final numeric answer. No physical units are applicable to these rates; express the final answer as a decimal number rounded to four significant figures.",
            "solution": "The task involves decoding evaluation in a multi-class setting. The fundamental base for the derivation is the definition of the confusion matrix and the standard count-based metrics. For a set of classes $\\{A,B,C,D\\}$, the confusion matrix $M$ has entries $M_{ij}$ that count the number of instances with true class $i$ predicted as class $j$. For any given class $k$, the one-versus-rest definitions are:\n- True Positive (TP): $TP_{k}$ equals the diagonal element $M_{kk}$.\n- False Positive (FP): $FP_{k}$ equals the sum of predictions as class $k$ from other true classes, i.e., the column sum for class $k$ minus $TP_{k}$.\n- False Negative (FN): $FN_{k}$ equals the sum of instances of true class $k$ predicted as other classes, i.e., the row sum for class $k$ minus $TP_{k}$.\nOverall accuracy is the fraction of correctly classified instances: sum of the diagonal entries divided by the total number of instances. Precision for class $k$ is $TP_{k}/(TP_{k}+FP_{k})$, recall is $TP_{k}/(TP_{k}+FN_{k})$, and the F1 score (harmonic mean of precision and recall) is defined by $F1_{k} = \\frac{2 \\times \\text{precision} \\times \\text{recall}}{\\text{precision} + \\text{recall}}$. From these definitions, one can derive that\n$$\nF1_{k} \\;=\\; \\frac{2 \\, TP_{k}}{2\\,TP_{k} + FP_{k} + FN_{k}},\n$$\nby substituting the expressions for precision and recall and simplifying.\n\nStep 1: Construct the confusion matrix $M$.\n\nOrdering rows and columns alphabetically $(A,B,C,D)$, the given counts yield\n$$\nM \\;=\\; \\begin{pmatrix}\n35 & 5 & 8 & 2 \\\\\n4 & 26 & 6 & 4 \\\\\n5 & 12 & 38 & 5 \\\\\n3 & 7 & 9 & 31\n\\end{pmatrix}.\n$$\nRow sums (true-class totals): $A: 35+5+8+2 = 50$, $B: 4+26+6+4 = 40$, $C: 5+12+38+5 = 60$, $D: 3+7+9+31 = 50$. The total number of instances is $N = 50+40+60+50 = 200$. Column sums (predicted-class totals): $A: 35+4+5+3 = 47$, $B: 5+26+12+7 = 50$, $C: 8+6+38+9 = 61$, $D: 2+4+5+31 = 42$.\n\nStep 2: Compute accuracy, per-class precision, recall, and F1.\n\n- Overall accuracy:\nThe sum of diagonal entries is $35 + 26 + 38 + 31 = 130$. Therefore,\n$$\n\\text{accuracy} \\;=\\; \\frac{130}{200} \\;=\\; 0.6500 \\text{ (rounded to four significant figures)}.\n$$\n\nNow compute per-class metrics.\n\nClass $A$:\n- $TP_{A} = 35$.\n- $FP_{A} = (\\text{predicted } A \\text{ total}) - TP_{A} = 47 - 35 = 12$.\n- $FN_{A} = (\\text{true } A \\text{ total}) - TP_{A} = 50 - 35 = 15$.\n- Precision: $\\frac{35}{47} \\approx 0.74468085 \\rightarrow 0.7447$ (four significant figures).\n- Recall: $\\frac{35}{50} = 0.7000$ (four significant figures).\n- F1: using $F1_{A} = \\frac{2 \\times TP_{A}}{2 TP_{A} + FP_{A} + FN_{A}} = \\frac{70}{97} \\approx 0.72164948 \\rightarrow 0.7216$.\n\nClass $B$:\n- $TP_{B} = 26$.\n- $FP_{B} = 50 - 26 = 24$.\n- $FN_{B} = 40 - 26 = 14$.\n- Precision: $\\frac{26}{50} = 0.5200$.\n- Recall: $\\frac{26}{40} = 0.6500$.\n- F1: $F1_{B} = \\frac{52}{52+24+14} = \\frac{52}{90} = \\frac{26}{45} \\approx 0.57777778 \\rightarrow 0.5778$.\n\nClass $C$:\n- $TP_{C} = 38$.\n- $FP_{C} = 61 - 38 = 23$.\n- $FN_{C} = 60 - 38 = 22$.\n- Precision: $\\frac{38}{61} \\approx 0.62295082 \\rightarrow 0.6230$.\n- Recall: $\\frac{38}{60} = \\frac{19}{30} \\approx 0.63333333 \\rightarrow 0.6333$.\n- F1: $F1_{C} = \\frac{76}{76+23+22} = \\frac{76}{121} \\approx 0.62809917 \\rightarrow 0.6281$.\n\nClass $D$:\n- $TP_{D} = 31$.\n- $FP_{D} = 42 - 31 = 11$.\n- $FN_{D} = 50 - 31 = 19$.\n- Precision: $\\frac{31}{42} \\approx 0.73809524 \\rightarrow 0.7381$.\n- Recall: $\\frac{31}{50} = 0.6200$.\n- F1: $F1_{D} = \\frac{62}{62+11+19} = \\frac{62}{92} = \\frac{31}{46} \\approx 0.67391304 \\rightarrow 0.6739$.\n\nStep 3: Macro-averaged F1.\n\nThe macro-averaged F1 is the arithmetic mean of the four per-class F1 scores:\n$$\n\\text{macro-F1} \\;=\\; \\frac{1}{4}\\left(F1_{A} + F1_{B} + F1_{C} + F1_{D}\\right)\n\\;=\\; \\frac{1}{4}\\left(\\frac{70}{97} + \\frac{26}{45} + \\frac{76}{121} + \\frac{31}{46}\\right).\n$$\nCompute numerically:\n- $\\frac{70}{97} \\approx 0.72164948$,\n- $\\frac{26}{45} \\approx 0.57777778$,\n- $\\frac{76}{121} \\approx 0.62809917$,\n- $\\frac{31}{46} \\approx 0.67391304$.\n\nSum $\\approx 0.72164948 + 0.57777778 + 0.62809917 + 0.67391304 = 2.60143947$. Divide by $4$:\n$$\n\\text{macro-F1} \\;\\approx\\; 0.65035987 \\;\\rightarrow\\; 0.6504 \\text{ (rounded to four significant figures)}.\n$$\n\nThus, the requested final numeric answer is the macro-averaged F1 score rounded to four significant figures.",
            "answer": "$$\\boxed{0.6504}$$"
        },
        {
            "introduction": "When decoding continuous variables, such as the direction of a planned movement, we shift from classification metrics to regression metrics. Root Mean Squared Error (RMSE) provides an intuitive measure of the average prediction error, but the coefficient of determination, $R^2$, offers a normalized score that compares the decoder to a simple mean-prediction baseline. This problem  challenges you to master the formal definitions of these key metrics and, crucially, to understand the subtle but important conditions under which $R^2$ can be interpreted as the 'fraction of variance explained'.",
            "id": "4154099",
            "problem": "A population decoder is trained to predict a continuous behavioral variable from neural activity. On a held-out test set of $N$ trials, let the true values be $\\{y_i\\}_{i=1}^N$, the decoder’s predictions be $\\{\\hat{y}_i\\}_{i=1}^N$, and the empirical mean of the true values be $\\bar{y} = \\frac{1}{N}\\sum_{i=1}^N y_i$. You want to evaluate the decoder using root mean squared error (RMSE) and the coefficient of determination $R^2$. Starting from basic definitions of mean squared error as an average of squared prediction errors and of sample variability about a mean as a sum of squared deviations, identify the option that correctly formalizes RMSE and $R^2$ on the test set and correctly states when $R^2$ can be interpreted as the fraction of variance explained by the decoder in the sense of reduction in variability relative to the mean-only baseline. Assume standard linear algebra and probability conventions, and do not assume any specialized property of the decoder beyond what is explicitly stated.\n\nChoose the single best option.\n\nA. RMSE is $\\sqrt{\\frac{1}{N}\\sum_{i=1}^N (y_i-\\hat{y}_i)^2}$. The coefficient of determination is $R^2 = 1 - \\dfrac{\\sum_{i=1}^N (y_i-\\bar{y})^2}{\\sum_{i=1}^N (y_i-\\hat{y}_i)^2}$. This $R^2$ equals the fraction of variance explained only when the predictions are zero-mean, i.e., $\\frac{1}{N}\\sum_{i=1}^N \\hat{y}_i = 0$.\n\nB. RMSE is $\\frac{1}{N}\\sum_{i=1}^N \\lvert y_i-\\hat{y}_i\\rvert$. The coefficient of determination is $R^2 = \\mathrm{corr}(y,\\hat{y})$, where $\\mathrm{corr}$ is the Pearson correlation coefficient. On held-out data, $R^2$ always lies in the interval $[0,1]$ and is the fraction of variance explained.\n\nC. RMSE is $\\sqrt{\\frac{1}{N-1}\\sum_{i=1}^N (y_i-\\hat{y}_i)^2}$. The coefficient of determination is $R^2 = 1 - \\dfrac{\\sum_{i=1}^N (y_i-\\hat{y}_i)^2}{\\sum_{i=1}^N y_i^2}$. This $R^2$ equals the fraction of variance explained if and only if $\\bar{y}=0$.\n\nD. RMSE is $\\sqrt{\\frac{1}{N}\\sum_{i=1}^N (y_i-\\hat{y}_i)^2}$. The coefficient of determination is $R^2 = 1 - \\dfrac{\\sum_{i=1}^N (y_i-\\hat{y}_i)^2}{\\sum_{i=1}^N (y_i-\\bar{y})^2}$. On any evaluation set, this $R^2$ quantifies the fraction of the total sum of squares reduced by the decoder relative to the mean-only baseline; moreover, if the decoder includes an intercept so that residuals have mean zero on the evaluation set, then $R^2 = 1 - \\dfrac{\\mathrm{Var}(y-\\hat{y})}{\\mathrm{Var}(y)}$, and for ordinary least squares (OLS) evaluated on the same data used for fitting, $R^2$ equals the squared Pearson correlation between $y$ and $\\hat{y}$.",
            "solution": "The problem requires a rigorous definition of Root Mean Squared Error (RMSE) and the coefficient of determination ($R^2$), and a correct statement about the interpretation of $R^2$ for a decoder's performance on a held-out test set.\n\n### Problem Validation\nThe problem statement is valid. It presents a standard task in statistical modeling and machine learning: the evaluation of a predictive model on unseen data. The terms used—RMSE, $R^2$, fraction of variance explained—are well-defined in statistics. The setup provides all necessary variables ($y_i$, $\\hat{y}_i$, $\\bar{y}$, $N$) and asks for a derivation from first principles. The problem is scientifically grounded, well-posed, objective, and contains no internal contradictions or ambiguities that would prevent a rigorous solution.\n\n### Derivation of RMSE\n\nThe problem states that mean squared error (MSE) is the average of squared prediction errors.\nFor the $i$-th trial in the test set, the true value is $y_i$ and the predicted value is $\\hat{y}_i$. The prediction error is $e_i = y_i - \\hat{y}_i$.\nThe squared prediction error is $e_i^2 = (y_i - \\hat{y}_i)^2$.\nThe average of these squared errors over the $N$ trials in the test set is the Mean Squared Error (MSE):\n$$ \\text{MSE} = \\frac{1}{N} \\sum_{i=1}^N (y_i - \\hat{y}_i)^2 $$\nThe Root Mean Squared Error (RMSE) is, by definition, the square root of the MSE.\n$$ \\text{RMSE} = \\sqrt{\\text{MSE}} = \\sqrt{\\frac{1}{N} \\sum_{i=1}^N (y_i - \\hat{y}_i)^2} $$\n\n### Derivation and Interpretation of $R^2$\n\nThe problem specifies that sample variability about a mean is defined as a sum of squared deviations. The total variability in the true data $\\{y_i\\}_{i=1}^N$ is measured relative to its empirical mean, $\\bar{y}$. This is called the Total Sum of Squares (SST):\n$$ \\text{SST} = \\sum_{i=1}^N (y_i - \\bar{y})^2 $$\nSST represents the error of a baseline model that always predicts the mean $\\bar{y}$.\n\nThe variability that the decoder fails to explain is captured by the sum of its squared errors. This is called the Residual Sum of Squares (SSR) or Sum of Squared Residuals/Errors (SSE):\n$$ \\text{SSR} = \\sum_{i=1}^N (y_i - \\hat{y}_i)^2 $$\n\nThe coefficient of determination, $R^2$, is defined as the proportion of the total variability that is accounted for by the model. It quantifies the reduction in error from the baseline (mean-only) model to the decoder model, relative to the baseline error.\n$$ R^2 = \\frac{\\text{SST} - \\text{SSR}}{\\text{SST}} = 1 - \\frac{\\text{SSR}}{\\text{SST}} $$\nSubstituting the expressions for SST and SSR, we get the standard definition of $R^2$ for a test set:\n$$ R^2 = 1 - \\frac{\\sum_{i=1}^N (y_i - \\hat{y}_i)^2}{\\sum_{i=1}^N (y_i - \\bar{y})^2} $$\nOn a held-out test set, it is possible for the model's predictions to be worse than simply guessing the mean, which would mean $\\text{SSR} > \\text{SST}$. In such a case, $R^2$ will be negative. Therefore, on a test set, the range of $R^2$ is $(-\\infty, 1]$.\n\nThe interpretation of $R^2$ as the \"fraction of variance explained\" requires closer examination. The sample variance of the true values is $\\text{Var}(y) = \\frac{1}{N}\\text{SST}$. The mean squared error is $\\text{MSE} = \\frac{1}{N}\\text{SSR}$. So, $R^2 = 1 - \\frac{\\text{MSE}}{\\text{Var}(y)}$.\nLet the residuals be $e_i = y_i - \\hat{y}_i$, with mean $\\bar{e} = \\frac{1}{N}\\sum_{i=1}^N e_i = \\bar{y} - \\bar{\\hat{y}}$. The variance of the residuals is $\\text{Var}(e) = \\text{Var}(y-\\hat{y})$. The MSE can be decomposed as $\\text{MSE} = \\text{Var}(e) + \\bar{e}^2$.\nSubstituting this into the expression for $R^2$:\n$$ R^2 = 1 - \\frac{\\text{Var}(e) + \\bar{e}^2}{\\text{Var}(y)} = 1 - \\frac{\\text{Var}(y-\\hat{y}) + (\\bar{y}-\\bar{\\hat{y}})^2}{\\text{Var}(y)} $$\nFor $R^2$ to equal $1 - \\frac{\\text{Var}(y-\\hat{y})}{\\text{Var}(y)}$, which is the precise meaning of \"fraction of variance explained\" (in the sense of a ratio of variances), the term $(\\bar{y}-\\bar{\\hat{y}})^2$ must be zero. This requires $\\bar{y} = \\bar{\\hat{y}}$, meaning the residuals have a mean of zero on the test set. This condition is not guaranteed on a test set, even for models like Ordinary Least Squares (OLS) with an intercept, as that property only holds for the training data used to fit the model.\n\nFinally, the relation $R^2 = (\\text{corr}(y, \\hat{y}))^2$ holds specifically for an OLS model evaluated on its training data, but it does not hold in general for any model or on any test set.\n\n### Evaluation of Options\n\n**A. RMSE is $\\sqrt{\\frac{1}{N}\\sum_{i=1}^N (y_i-\\hat{y}_i)^2}$. The coefficient of determination is $R^2 = 1 - \\dfrac{\\sum_{i=1}^N (y_i-\\bar{y})^2}{\\sum_{i=1}^N (y_i-\\hat{y}_i)^2}$. This $R^2$ equals the fraction of variance explained only when the predictions are zero-mean, i.e., $\\frac{1}{N}\\sum_{i=1}^N \\hat{y}_i = 0$.**\n- The RMSE formula is correct.\n- The $R^2$ formula is $1 - \\frac{\\text{SST}}{\\text{SSR}}$, which is incorrect. The correct formula is $1 - \\frac{\\text{SSR}}{\\text{SST}}$.\n- The condition for the interpretation is also incorrect. The condition is that the mean of the residuals is zero ($\\bar{y} = \\bar{\\hat{y}}$), not that the mean of the predictions is zero, unless $\\bar{y}=0$ as well.\n**Verdict: Incorrect.**\n\n**B. RMSE is $\\frac{1}{N}\\sum_{i=1}^N \\lvert y_i-\\hat{y}_i\\rvert$. The coefficient of determination is $R^2 = \\mathrm{corr}(y,\\hat{y})$, where $\\mathrm{corr}$ is the Pearson correlation coefficient. On held-out data, $R^2$ always lies in the interval $[0,1]$ and is the fraction of variance explained.**\n- The formula provided is for Mean Absolute Error (MAE), not RMSE.\n- The definition of $R^2$ as the Pearson correlation coefficient is incorrect. They are different metrics, though related under specific circumstances not applicable here.\n- The statement that $R^2$ on held-out data is always in $[0,1]$ is false; it can be negative.\n**Verdict: Incorrect.**\n\n**C. RMSE is $\\sqrt{\\frac{1}{N-1}\\sum_{i=1}^N (y_i-\\hat{y}_i)^2}$. The coefficient of determination is $R^2 = 1 - \\dfrac{\\sum_{i=1}^N (y_i-\\hat{y}_i)^2}{\\sum_{i=1}^N y_i^2}$. This $R^2$ equals the fraction of variance explained if and only if $\\bar{y}=0$.**\n- The RMSE formula uses a denominator of $N-1$, which is a non-standard definition for a fixed test set performance metric. The standard is to average over the $N$ samples.\n- The $R^2$ formula uses $\\sum y_i^2$ in the denominator, which is the sum of squares around the origin. The standard definition uses the sum of squares around the mean, $\\text{SST} = \\sum (y_i-\\bar{y})^2$. This uncentered version is only appropriate for models forced through the origin and evaluated against a baseline of predicting zero.\n- The interpretive condition is incomplete and applies to an unconventional definition.\n**Verdict: Incorrect.**\n\n**D. RMSE is $\\sqrt{\\frac{1}{N}\\sum_{i=1}^N (y_i-\\hat{y}_i)^2}$. The coefficient of determination is $R^2 = 1 - \\dfrac{\\sum_{i=1}^N (y_i-\\hat{y}_i)^2}{\\sum_{i=1}^N (y_i-\\bar{y})^2}$. On any evaluation set, this $R^2$ quantifies the fraction of the total sum of squares reduced by the decoder relative to the mean-only baseline; moreover, if the decoder includes an intercept so that residuals have mean zero on the evaluation set, then $R^2 = 1 - \\dfrac{\\mathrm{Var}(y-\\hat{y})}{\\mathrm{Var}(y)}$, and for ordinary least squares (OLS) evaluated on the same data used for fitting, $R^2$ equals the squared Pearson correlation between $y$ and $\\hat{y}$.**\n- The RMSE formula is correct, as derived.\n- The $R^2$ formula is $1 - \\frac{\\text{SSR}}{\\text{SST}}$, which is correct.\n- The interpretation of $R^2$ as the fraction of sum of squares reduced relative to the mean-only baseline is a precise and universally correct interpretation of the formula.\n- The condition for $R^2$ to be interpreted as a ratio of variances ($1 - \\frac{\\text{Var}(y-\\hat{y})}{\\text{Var}(y)}$) is correctly identified as the residuals having a mean of zero on the evaluation set.\n- The final statement about the relationship between $R^2$ and squared correlation for OLS on training data is also a correct, standard result.\nThis option provides a complete and accurate formalization.\n**Verdict: Correct.**",
            "answer": "$$\\boxed{D}$$"
        }
    ]
}