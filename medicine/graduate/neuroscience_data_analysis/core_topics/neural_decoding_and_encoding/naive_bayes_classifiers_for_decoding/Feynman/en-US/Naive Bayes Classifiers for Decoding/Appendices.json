{
    "hands_on_practices": [
        {
            "introduction": "A key feature of the Naive Bayes classifier is how it combines evidence from different sources, which under the independence assumption, becomes a straightforward product of individual likelihoods. This exercise challenges you to derive precisely how a single neuron contributes to the overall decision, quantified by the log-posterior odds. By isolating the impact of removing one neuron, you will gain a deeper intuition for the additive structure of evidence in log-space and see how a neuron's tuning properties directly translate into its decoding power .",
            "id": "4180807",
            "problem": "Consider a two-class decoding task between stimuli $A$ and $B$ using a Naive Bayes classifier in a fixed observation window of duration $T$. You record spike counts from $N$ neurons, collecting the count vector $\\mathbf{x} = (x_1, x_2, \\dots, x_N)$ in the window. Assume conditional independence of neurons given the stimulus, and model each neuron's spike count as a Poisson random variable with stimulus-specific mean rates in the window: for neuron $i$, under stimulus $s \\in \\{A,B\\}$, $x_i \\sim \\mathrm{Poisson}(\\lambda_{i s})$, where $\\lambda_{i s} > 0$ denotes the expected spike count in the window under stimulus $s$. Let the prior probabilities be $\\pi_A = P(S=A)$ and $\\pi_B = P(S=B)$, with $\\pi_A + \\pi_B = 1$. Define the log-posterior odds as\n$$\n\\mathrm{LPO}(\\mathbf{x}) = \\ln\\!\\left(\\frac{P(S=A \\mid \\mathbf{x})}{P(S=B \\mid \\mathbf{x})}\\right).\n$$\nYou now remove a single neuron $j$ from the decoder, forming the reduced count vector $\\mathbf{x}_{-j} = (x_1, \\dots, x_{j-1}, x_{j+1}, \\dots, x_N)$ and recompute the log-posterior odds $\\mathrm{LPO}(\\mathbf{x}_{-j})$ under the same assumptions and priors. Starting strictly from Bayes' theorem and the conditional independence model, derive an exact, closed-form expression for the change in log-posterior odds defined by\n$$\n\\Delta \\mathrm{LPO}_j = \\mathrm{LPO}(\\mathbf{x}_{-j}) - \\mathrm{LPO}(\\mathbf{x}),\n$$\nand express it purely as a function of the single-neuron observation $x_j$ and the two stimulus-specific Poisson means $\\lambda_{jA}$ and $\\lambda_{jB}$. Your final answer must be a single analytic expression. Do not approximate or round.",
            "solution": "The problem is well-posed and scientifically sound, based on standard models in computational neuroscience. We can proceed with the derivation.\n\nThe objective is to derive an expression for the change in log-posterior odds, $\\Delta \\mathrm{LPO}_j = \\mathrm{LPO}(\\mathbf{x}_{-j}) - \\mathrm{LPO}(\\mathbf{x})$. We begin by defining the log-posterior odds for the full dataset, $\\mathrm{LPO}(\\mathbf{x})$.\n\nBy definition, the log-posterior odds are:\n$$\n\\mathrm{LPO}(\\mathbf{x}) = \\ln\\left(\\frac{P(S=A \\mid \\mathbf{x})}{P(S=B \\mid \\mathbf{x})}\\right)\n$$\nWe apply Bayes' theorem to the posterior probabilities $P(S=s \\mid \\mathbf{x}) = \\frac{P(\\mathbf{x} \\mid S=s)P(S=s)}{P(\\mathbf{x})}$, where $s \\in \\{A,B\\}$. Substituting these into the ratio, the evidence term $P(\\mathbf{x})$ cancels:\n$$\n\\frac{P(S=A \\mid \\mathbf{x})}{P(S=B \\mid \\mathbf{x})} = \\frac{P(\\mathbf{x} \\mid S=A)P(S=A)}{P(\\mathbf{x} \\mid S=B)P(S=B)}\n$$\nTaking the natural logarithm of both sides gives:\n$$\n\\mathrm{LPO}(\\mathbf{x}) = \\ln\\left(\\frac{P(S=A)}{P(S=B)}\\right) + \\ln\\left(\\frac{P(\\mathbf{x} \\mid S=A)}{P(\\mathbf{x} \\mid S=B)}\\right)\n$$\nThe first term is the log-prior odds, which we can write using the given priors $\\pi_A$ and $\\pi_B$:\n$$\n\\ln\\left(\\frac{\\pi_A}{\\pi_B}\\right)\n$$\nThe second term is the log-likelihood ratio. We use the conditional independence assumption, which states that the joint likelihood is the product of the individual likelihoods for each neuron:\n$$\nP(\\mathbf{x} \\mid S=s) = \\prod_{i=1}^{N} P(x_i \\mid S=s)\n$$\nThe log-likelihood ratio then becomes a sum of individual log-likelihood ratios:\n$$\n\\ln\\left(\\frac{P(\\mathbf{x} \\mid S=A)}{P(\\mathbf{x} \\mid S=B)}\\right) = \\ln\\left(\\frac{\\prod_{i=1}^{N} P(x_i \\mid S=A)}{\\prod_{i=1}^{N} P(x_i \\mid S=B)}\\right) = \\sum_{i=1}^{N} \\ln\\left(\\frac{P(x_i \\mid S=A)}{P(x_i \\mid S=B)}\\right)\n$$\nNow, we incorporate the Poisson model for the spike counts. The probability mass function for a Poisson random variable is $P(x_i \\mid S=s) = \\frac{\\lambda_{is}^{x_i} \\exp(-\\lambda_{is})}{x_i!}$. Substituting this into the per-neuron log-likelihood ratio:\n$$\n\\ln\\left(\\frac{P(x_i \\mid S=A)}{P(x_i \\mid S=B)}\\right) = \\ln\\left(\\frac{\\lambda_{iA}^{x_i} \\exp(-\\lambda_{iA}) / x_i!}{\\lambda_{iB}^{x_i} \\exp(-\\lambda_{iB}) / x_i!}\\right) = \\ln\\left(\\frac{\\lambda_{iA}^{x_i} \\exp(-\\lambda_{iA})}{\\lambda_{iB}^{x_i} \\exp(-\\lambda_{iB})}\\right)\n$$\nUsing the properties of logarithms, $\\ln(a/b) = \\ln(a) - \\ln(b)$ and $\\ln(a^b) = b\\ln(a)$:\n$$\n\\ln\\left(\\frac{P(x_i \\mid S=A)}{P(x_i \\mid S=B)}\\right) = (x_i \\ln(\\lambda_{iA}) - \\lambda_{iA}) - (x_i \\ln(\\lambda_{iB}) - \\lambda_{iB}) = x_i \\ln\\left(\\frac{\\lambda_{iA}}{\\lambda_{iB}}\\right) - (\\lambda_{iA} - \\lambda_{iB})\n$$\nCombining all terms, the full log-posterior odds are:\n$$\n\\mathrm{LPO}(\\mathbf{x}) = \\ln\\left(\\frac{\\pi_A}{\\pi_B}\\right) + \\sum_{i=1}^{N} \\left[ x_i \\ln\\left(\\frac{\\lambda_{iA}}{\\lambda_{iB}}\\right) - (\\lambda_{iA} - \\lambda_{iB}) \\right]\n$$\nThis expression shows that the total log-posterior odds is a sum of a constant prior term and individual contributions from each of the $N$ neurons.\n\nNext, we compute the log-posterior odds for the reduced dataset, $\\mathrm{LPO}(\\mathbf{x}_{-j})$. This calculation is identical, but the summation is over the set of neurons excluding neuron $j$:\n$$\n\\mathrm{LPO}(\\mathbf{x}_{-j}) = \\ln\\left(\\frac{\\pi_A}{\\pi_B}\\right) + \\sum_{i \\neq j} \\left[ x_i \\ln\\left(\\frac{\\lambda_{iA}}{\\lambda_{iB}}\\right) - (\\lambda_{iA} - \\lambda_{iB}) \\right]\n$$\nFinally, we compute the desired change, $\\Delta \\mathrm{LPO}_j = \\mathrm{LPO}(\\mathbf{x}_{-j}) - \\mathrm{LPO}(\\mathbf{x})$.\nWe can split the sum in the expression for $\\mathrm{LPO}(\\mathbf{x})$ into two parts: the term for neuron $j$ and the sum over all other neurons.\n$$\n\\mathrm{LPO}(\\mathbf{x}) = \\ln\\left(\\frac{\\pi_A}{\\pi_B}\\right) + \\sum_{i \\neq j} \\left[ x_i \\ln\\left(\\frac{\\lambda_{iA}}{\\lambda_{iB}}\\right) - (\\lambda_{iA} - \\lambda_{iB}) \\right] + \\left[ x_j \\ln\\left(\\frac{\\lambda_{jA}}{\\lambda_{jB}}\\right) - (\\lambda_{jA} - \\lambda_{jB}) \\right]\n$$\nNotice that the first two terms in this expression are identical to the expression for $\\mathrm{LPO}(\\mathbf{x}_{-j})$.\n$$\n\\mathrm{LPO}(\\mathbf{x}) = \\mathrm{LPO}(\\mathbf{x}_{-j}) + \\left[ x_j \\ln\\left(\\frac{\\lambda_{jA}}{\\lambda_{jB}}\\right) - (\\lambda_{jA} - \\lambda_{jB}) \\right]\n$$\nRearranging this equation to solve for $\\Delta \\mathrm{LPO}_j$:\n$$\n\\Delta \\mathrm{LPO}_j = \\mathrm{LPO}(\\mathbf{x}_{-j}) - \\mathrm{LPO}(\\mathbf{x}) = - \\left[ x_j \\ln\\left(\\frac{\\lambda_{jA}}{\\lambda_{jB}}\\right) - (\\lambda_{jA} - \\lambda_{jB}) \\right]\n$$\nSimplifying the expression yields the final result:\n$$\n\\Delta \\mathrm{LPO}_j = (\\lambda_{jA} - \\lambda_{jB}) - x_j \\ln\\left(\\frac{\\lambda_{jA}}{\\lambda_{jB}}\\right)\n$$\nThis represents the change in log-posterior odds when neuron $j$ is removed. As required, it is expressed solely as a function of the observation for that neuron, $x_j$, and its stimulus-specific mean spike counts, $\\lambda_{jA}$ and $\\lambda_{jB}$.",
            "answer": "$$\n\\boxed{(\\lambda_{jA} - \\lambda_{jB}) - x_j \\ln\\left(\\frac{\\lambda_{jA}}{\\lambda_{jB}}\\right)}\n$$"
        },
        {
            "introduction": "The elegant mathematics of Bayesian inference can be fragile when implemented on a computer, often failing due to numerical underflow or overflow, especially when dealing with products of many small probabilities. This practical coding exercise introduces the \"log-sum-exp trick,\" a fundamental technique for robustly computing sums of probabilities in the logarithmic domain, such as when calculating the evidence term $p(\\mathbf{r})$ . Mastering this skill is essential for building reliable probabilistic models that can handle the large-scale data common in modern neuroscience.",
            "id": "4180768",
            "problem": "You are analyzing stimulus decoding from neural population responses using the Naive Bayes classifier. Start from the following foundational base: Bayes’ theorem and the Naive Bayes independence assumption. Specifically, for a discrete stimulus set indexed by $s$ and a neural response vector $\\mathbf{r}=(r_1,\\dots,r_I)$ across $I$ neurons, define the posterior by Bayes’ theorem, the evidence, and the Naive Bayes factorization as follows: $p(s\\mid \\mathbf{r})=\\dfrac{p(\\mathbf{r}\\mid s)p(s)}{p(\\mathbf{r})}$, $p(\\mathbf{r})=\\sum_s p(\\mathbf{r}\\mid s)p(s)$, and $p(\\mathbf{r}\\mid s)=\\prod_{i=1}^I p(r_i\\mid s)$, respectively. The computational task is to evaluate the log-evidence $\\log p(\\mathbf{r})$ given per-class per-neuron log-likelihoods and log-priors, while ensuring numerical robustness when the number of neurons $I$ is large or the log-likelihoods are very negative.\n\nYour program must implement a numerically stable computation of $\\log p(\\mathbf{r})$ via the log-sum-exp transformation applied to $\\sum_s \\exp\\!\\left(\\sum_{i=1}^I \\log p(r_i\\mid s)+\\log p(s)\\right)$. Explicitly, you must compute $\\log p(\\mathbf{r})$ from the inputs $L_{s,i}=\\log p(r_i\\mid s)$ and $\\ell_s=\\log p(s)$, by first forming $a_s=\\sum_{i=1}^I L_{s,i}+\\ell_s$ for each class $s$, and then aggregating these $a_s$ values via a numerically stable log-sum-exp transformation. You must design your implementation to handle $-\\infty$ values in $a_s$ (which represent zero probability for a class) and return $-\\infty$ when all classes are impossible.\n\nImplement the computation for the following test suite. In each case, $L$ is a list of lists containing $L_{s,i}$ for $s=0,\\dots,S-1$ and $i=1,\\dots,I$, and $\\ell$ is the list of $\\ell_s=\\log p(s)$ for $s=0,\\dots,S-1$. All logarithms are natural logarithms. For each case, the output is a single real number representing $\\log p(\\mathbf{r})$. The final output must be a single line containing a comma-separated list in square brackets aggregating the results of all cases, in the order listed. No physical units are involved; all outputs are real numbers.\n\nCase $1$ (happy path, moderate values):\n- $S=3$, $I=5$.\n- $L$:\n  - Class $0$: $[-2.3,-0.7,-1.1,-0.5,-3.0]$,\n  - Class $1$: $[-1.9,-1.2,-0.9,-1.5,-2.2]$,\n  - Class $2$: $[-3.2,-0.6,-0.8,-0.4,-2.8]$.\n- $\\ell$: $[\\log(0.2),\\log(0.3),\\log(0.5)] = [-1.6094379124341003,-1.2039728043259361,-0.6931471805599453]$.\n\nCase $2$ (extreme underflow risk, very negative sums):\n- $S=2$, $I=3$.\n- $L$:\n  - Class $0$: $[-1000.0,-800.0,-1200.0]$,\n  - Class $1$: $[-1001.0,-799.0,-1199.0]$.\n- $\\ell$: $[\\log(0.5),\\log(0.5)] = [-0.6931471805599453,-0.6931471805599453]$.\n\nCase $3$ (single-class boundary):\n- $S=1$, $I=4$.\n- $L$:\n  - Class $0$: $[-0.2,-0.4,-0.1,-0.3]$.\n- $\\ell$: $[\\log(1.0)] = [0.0]$.\n\nCase $4$ (balanced classes with equal aggregated scores):\n- $S=2$, $I=2$.\n- $L$:\n  - Class $0$: $[-0.5,-1.0]$,\n  - Class $1$: $[-0.5,-1.0]$.\n- $\\ell$: $[\\log(0.5),\\log(0.5)] = [-0.6931471805599453,-0.6931471805599453]$.\n\nCase $5$ (one class impossible, one class finite):\n- $S=2$, $I=3$.\n- $L$:\n  - Class $0$: $[-\\infty,-0.5,-0.5]$,\n  - Class $1$: $[-0.4,-0.6,-0.3]$.\n- $\\ell$: $[\\log(0.6),\\log(0.4)] = [-0.5108256237659907,-0.916290731874155]$.\n\nCase $6$ (all classes impossible):\n- $S=2$, $I=2$.\n- $L$:\n  - Class $0$: $[-\\infty,-0.2]$,\n  - Class $1$: $[-\\infty,-0.3]$.\n- $\\ell$: $[\\log(0.7),\\log(0.3)] = [-0.35667494393873245,-1.2039728043259361]$.\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (for example, $[\\text{result1},\\text{result2},\\dots]$). The results must be ordered exactly as Cases $1$ through $6$ above. Each result must be a real number (floating-point), and it is acceptable for a result to be $-\\infty$ when mathematically warranted.",
            "solution": "The problem is valid. It presents a well-posed, scientifically grounded task in computational neuroscience and machine learning, which is to compute the log-evidence for a Naive Bayes classifier in a numerically stable manner. All required data and definitions are provided, and the problem is free of contradictions or ambiguities.\n\nThe objective is to compute the log-evidence, $\\log p(\\mathbf{r})$, for a given neural response vector $\\mathbf{r}$ and a discrete set of stimuli $\\{s\\}$. The evidence $p(\\mathbf{r})$ is the marginal probability of observing the response $\\mathbf{r}$, and it is defined by marginalizing over all possible stimuli:\n$$p(\\mathbf{r}) = \\sum_s p(\\mathbf{r}, s)$$\nUsing the definition of joint probability, this can be written as:\n$$p(\\mathbf{r}) = \\sum_s p(\\mathbf{r}\\mid s)p(s)$$\nHere, $p(s)$ is the prior probability of stimulus $s$, and $p(\\mathbf{r}\\mid s)$ is the likelihood of observing response $\\mathbf{r}$ given that stimulus $s$ was presented.\n\nThe problem specifies the use of a Naive Bayes model. This model assumes that, conditional on the stimulus $s$, the responses of the individual neurons $r_i$ are independent. For a population of $I$ neurons with response vector $\\mathbf{r}=(r_1, \\dots, r_I)$, this assumption is formulated as:\n$$p(\\mathbf{r}\\mid s) = \\prod_{i=1}^I p(r_i\\mid s)$$\nSubstituting this into the expression for the evidence gives:\n$$p(\\mathbf{r}) = \\sum_s \\left( p(s) \\prod_{i=1}^I p(r_i\\mid s) \\right)$$\nDirect computation of this expression is numerically perilous. For a large number of neurons $I$, the product term $\\prod_{i=1}^I p(r_i\\mid s)$ can easily underflow to zero, even if individual probabilities $p(r_i\\mid s)$ are not exceedingly small. To circumvent this, we perform the computation in the logarithmic domain.\n\nThe desired quantity is the log-evidence, $\\log p(\\mathbf{r})$:\n$$\\log p(\\mathbf{r}) = \\log\\left( \\sum_s \\left( p(s) \\prod_{i=1}^I p(r_i\\mid s) \\right) \\right)$$\nTo work with sums of logarithms instead of products of probabilities, we can express each term in the summation using the exponential function, i.e., $x = \\exp(\\log x)$:\n$$\\log p(\\mathbf{r}) = \\log\\left( \\sum_s \\exp\\left( \\log\\left( p(s) \\prod_{i=1}^I p(r_i\\mid s) \\right) \\right) \\right)$$\nUsing the properties of logarithms, $\\log(ab) = \\log a + \\log b$ and $\\log(\\prod_i a_i) = \\sum_i \\log a_i$, the term inside the exponential becomes:\n$$\\log\\left( p(s) \\prod_{i=1}^I p(r_i\\mid s) \\right) = \\log p(s) + \\sum_{i=1}^I \\log p(r_i\\mid s)$$\nThe problem provides these logarithmic quantities as inputs: the per-neuron log-likelihoods $L_{s,i} = \\log p(r_i\\mid s)$ and the log-priors $\\ell_s = \\log p(s)$. Let us define $a_s$ as the log-joint probability term for each class $s$:\n$$a_s = \\ell_s + \\sum_{i=1}^I L_{s,i}$$\nSubstituting this back, the log-evidence is:\n$$\\log p(\\mathbf{r}) = \\log\\left( \\sum_s \\exp(a_s) \\right)$$\nThis expression is known as the log-sum-exp function, $\\text{LSE}(a_1, a_2, \\dots)$. A naive implementation, which first computes $\\exp(a_s)$ for each $s$ and then sums the results, is still susceptible to numerical issues. If any $a_s$ is a large positive number, $\\exp(a_s)$ can overflow. If all $a_s$ are large negative numbers, $\\exp(a_s)$ can underflow to zero for all $s$, leading to a final result of $\\log(0) = -\\infty$ and a loss of all precision.\n\nTo ensure numerical stability, we use the \"log-sum-exp trick\". Let $a_{\\max} = \\max_s \\{a_s\\}$. We can factor out $\\exp(a_{\\max})$ from the sum:\n$$\\log p(\\mathbf{r}) = \\log\\left( \\exp(a_{\\max}) \\sum_s \\exp(a_s - a_{\\max}) \\right)$$\n$$= a_{\\max} + \\log\\left( \\sum_s \\exp(a_s - a_{\\max}) \\right)$$\nThis formulation is numerically robust. The arguments of the exponential function, $(a_s - a_{\\max})$, are now all less than or equal to $0$. This prevents overflow, as the maximum value of $\\exp(x)$ for $x \\le 0$ is $1$. It also ensures that the terms with the largest contribution to the sum are computed with high precision.\n\nThis approach must also correctly handle special cases involving $-\\infty$. An input value of $L_{s,i} = -\\infty$ or $\\ell_s = -\\infty$ signifies a zero-probability event. Their sum, $a_s$, will also be $-\\infty$. The contribution of such a class to the evidence is $\\exp(-\\infty) = 0$, so these terms correctly vanish from the sum. If all classes are impossible, i.e., all $a_s = -\\infty$, then the total evidence is $0$, and the log-evidence is $\\log(0) = -\\infty$. A robust implementation, such as the `logsumexp` function available in the `scipy.special` module, correctly handles these edge cases.\n\nThe algorithm for each test case is as follows:\n$1$. For each class $s$ from $0$ to $S-1$, calculate $a_s = \\ell_s + \\sum_{i=1}^I L_{s,i}$.\n$2$. Compute the log-evidence by applying the numerically stable log-sum-exp operation to the vector containing all $a_s$ values.\nThis procedure will be applied to each of the provided test cases.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.special import logsumexp\n\ndef solve():\n    \"\"\"\n    Solves the problem of computing the log-evidence for a Naive Bayes classifier\n    for a suite of test cases.\n    \"\"\"\n    \n    # Define the test cases from the problem statement.\n    test_cases = [\n        {\n            \"L\": [\n                [-2.3, -0.7, -1.1, -0.5, -3.0],\n                [-1.9, -1.2, -0.9, -1.5, -2.2],\n                [-3.2, -0.6, -0.8, -0.4, -2.8]\n            ],\n            \"ell\": [np.log(0.2), np.log(0.3), np.log(0.5)]\n        },\n        {\n            \"L\": [\n                [-1000.0, -800.0, -1200.0],\n                [-1001.0, -799.0, -1199.0]\n            ],\n            \"ell\": [np.log(0.5), np.log(0.5)]\n        },\n        {\n            \"L\": [\n                [-0.2, -0.4, -0.1, -0.3]\n            ],\n            \"ell\": [np.log(1.0)]\n        },\n        {\n            \"L\": [\n                [-0.5, -1.0],\n                [-0.5, -1.0]\n            ],\n            \"ell\": [np.log(0.5), np.log(0.5)]\n        },\n        {\n            \"L\": [\n                [-np.inf, -0.5, -0.5],\n                [-0.4, -0.6, -0.3]\n            ],\n            \"ell\": [np.log(0.6), np.log(0.4)]\n        },\n        {\n            \"L\": [\n                [-np.inf, -0.2],\n                [-np.inf, -0.3]\n            ],\n            \"ell\": [np.log(0.7), np.log(0.3)]\n        }\n    ]\n\n    results = []\n    \n    for case in test_cases:\n        # Convert inputs to NumPy arrays for vectorized operations.\n        # L_s,i = log p(r_i|s)\n        # l_s = log p(s)\n        L = np.array(case[\"L\"], dtype=np.float64)\n        ell = np.array(case[\"ell\"], dtype=np.float64)\n\n        # Step 1: Compute a_s for each class s.\n        # a_s = log p(s) + sum_i log p(r_i|s)\n        # This is the log of the joint probability, log p(r, s).\n        # The sum is over neurons (axis=1 of L).\n        a = L.sum(axis=1) + ell\n\n        # Step 2: Compute log-evidence using the log-sum-exp transformation.\n        # log p(r) = log(sum_s exp(a_s))\n        # The scipy.special.logsumexp function provides a numerically stable\n        # implementation that handles -inf correctly.\n        log_evidence = logsumexp(a)\n        \n        results.append(log_evidence)\n\n    # The str() function appropriately formats floating-point numbers, including -inf.\n    # The final output must be a single line containing a comma-separated list\n    # in square brackets.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "A powerful model is only useful if it generalizes well to new, unseen data, a principle that lies at the heart of machine learning. This exercise moves from model implementation to model evaluation, focusing on the critical task of hyperparameter selection using cross-validation. You will formulate the correct objective functions for choosing a smoothing parameter that maximizes a model's performance on held-out data, a core skill for preventing overfitting and building genuinely predictive decoders .",
            "id": "4180789",
            "problem": "A laboratory is decoding stimulus identity from population spike counts recorded from $N$ simultaneously measured neurons. For each trial $i$, the observed count vector is $x_{i} \\in \\mathbb{N}_{0}^{N}$ and the stimulus label is $s_{i} \\in \\{1,\\dots,K\\}$. Assume a Naive Bayes model in which, conditional on the stimulus $s$, neurons are independent and each neuron's spike count in a fixed window of duration $T$ is modeled as Poisson with rate parameter $\\lambda_{n,s}$, i.e., for neuron $n$, $x_{i,n} \\mid s_{i}=s \\sim \\mathrm{Poisson}(\\lambda_{n,s} T)$, independently over $n$. To smooth rate estimates, place a Gamma prior on each $\\lambda_{n,s}$ with shape hyperparameter $\\alpha > 0$ and fixed rate hyperparameter $\\beta > 0$, independent over $n$ and $s$. The class prior $p(s)$ is estimated by empirical frequency on the training data within each fold.\n\nYou are asked to select the smoothing hyperparameter $\\alpha$ using $L$-fold cross-validation. Let $\\mathcal{D}=\\{(x_{i},s_{i})\\}_{i=1}^{M}$ be the full dataset, partitioned into $L$ disjoint test sets $\\{\\mathcal{D}_{\\mathrm{test}}^{(\\ell)}\\}_{\\ell=1}^{L}$ with corresponding training sets $\\mathcal{D}_{\\mathrm{train}}^{(\\ell)}=\\mathcal{D}\\setminus \\mathcal{D}_{\\mathrm{test}}^{(\\ell)}$. For a given $\\alpha$, and within each fold $\\ell$, let $p(x \\mid s, \\mathcal{D}_{\\mathrm{train}}^{(\\ell)}, \\alpha)$ denote the posterior predictive likelihood obtained by integrating the Poisson likelihood over the Gamma prior updated by $\\mathcal{D}_{\\mathrm{train}}^{(\\ell)}$, and let $p(s \\mid x, \\mathcal{D}_{\\mathrm{train}}^{(\\ell)}, \\alpha)$ denote the corresponding posterior over classes via Bayes’ rule.\n\nStarting from first principles (Bayes’ rule for $p(s \\mid x)$ and the definition of cross-validation as an out-of-sample estimate of generalization performance), which of the following candidate objectives correctly define a cross-validated criterion for choosing $\\alpha$ that maximizes held-out log-posterior probability of the true class or held-out classification accuracy? Select all that apply.\n\nA. $\\displaystyle \\hat{\\alpha} \\;=\\; \\arg\\max_{\\alpha>0} \\;\\sum_{\\ell=1}^{L} \\;\\sum_{(x_{i},s_{i}) \\in \\mathcal{D}_{\\mathrm{test}}^{(\\ell)}} \\log p\\!\\left(s_{i} \\,\\middle|\\, x_{i}, \\mathcal{D}_{\\mathrm{train}}^{(\\ell)}, \\alpha\\right)$\n\nB. $\\displaystyle \\hat{\\alpha} \\;=\\; \\arg\\max_{\\alpha>0} \\;\\sum_{\\ell=1}^{L} \\;\\sum_{(x_{i},s_{i}) \\in \\mathcal{D}_{\\mathrm{test}}^{(\\ell)}} \\mathbf{1}\\!\\left\\{\\;\\hat{s}_{\\alpha}^{(\\ell)}(x_{i}) \\;=\\; s_{i}\\;\\right\\}$, where $\\displaystyle \\hat{s}_{\\alpha}^{(\\ell)}(x) \\;=\\; \\arg\\max_{s \\in \\{1,\\dots,K\\}} p\\!\\left(s \\,\\middle|\\, x, \\mathcal{D}_{\\mathrm{train}}^{(\\ell)}, \\alpha\\right)$\n\nC. $\\displaystyle \\hat{\\alpha} \\;=\\; \\arg\\max_{\\alpha>0} \\;\\sum_{i=1}^{M} \\log p\\!\\left(s_{i} \\,\\middle|\\, x_{i}, \\mathcal{D}, \\alpha\\right)$\n\nD. $\\displaystyle \\hat{\\alpha} \\;=\\; \\arg\\max_{\\alpha>0} \\;\\sum_{\\ell=1}^{L} \\;\\sum_{(x_{i},s_{i}) \\in \\mathcal{D}_{\\mathrm{test}}^{(\\ell)}} \\log p\\!\\left(x_{i} \\,\\middle|\\, s_{i}, \\mathcal{D}_{\\mathrm{train}}^{(\\ell)}, \\alpha\\right)$\n\nE. $\\displaystyle \\hat{\\alpha} \\;=\\; \\arg\\max_{\\alpha>0} \\;\\sum_{\\ell=1}^{L} \\;\\sum_{(x_{i},s_{i}) \\in \\mathcal{D}_{\\mathrm{test}}^{(\\ell)}} \\log p\\!\\left(s_{i} \\,\\middle|\\, x_{i}, \\mathcal{D}, \\alpha\\right)$, using $p\\!\\left(s \\mid x, \\mathcal{D}, \\alpha\\right)$ computed with parameters fit on $\\mathcal{D}$ for every fold\n\nEach candidate is to be interpreted exactly as written. No additional smoothing is applied beyond the single hyperparameter $\\alpha$ on the Poisson rates and the empirical class prior. Assume all integrals defining posterior predictive quantities exist and are finite. Provide your selection and justify it from first principles of Bayesian decoding and cross-validation.",
            "solution": "The problem asks to identify the correct mathematical formulations for choosing a hyperparameter $\\alpha$ using $L$-fold cross-validation. The core principle of cross-validation is to estimate a model's generalization performance on unseen data. For each fold $\\ell$, a model is trained on the training set $\\mathcal{D}_{\\mathrm{train}}^{(\\ell)}$ and evaluated on the disjoint test set $\\mathcal{D}_{\\mathrm{test}}^{(\\ell)}$. The performance metrics from each fold are then aggregated. We evaluate each option against this principle.\n\n**Candidate A: Maximizing Held-Out Log-Posterior Probability**\nThis objective is: $\\displaystyle \\hat{\\alpha} = \\arg\\max_{\\alpha>0} \\sum_{\\ell=1}^{L} \\sum_{(x_{i},s_{i}) \\in \\mathcal{D}_{\\mathrm{test}}^{(\\ell)}} \\log p(s_{i} \\mid x_{i}, \\mathcal{D}_{\\mathrm{train}}^{(\\ell)}, \\alpha)$.\nThis is a standard and proper cross-validation objective. For each data point $(x_i, s_i)$ in a test fold, it evaluates the log-posterior probability of the true class $s_i$ using a model trained exclusively on the corresponding training fold $\\mathcal{D}_{\\mathrm{train}}^{(\\ell)}$. This quantity, often called the log-likelihood of the held-out data or negative log-loss, is a proper scoring rule that measures how well the model's probabilistic predictions align with the true outcomes. Summing this score across all test points and all folds provides a robust estimate of the model's generalization performance. Maximizing this score is a valid way to select $\\alpha$. Thus, **A is a correct objective.**\n\n**Candidate B: Maximizing Held-Out Classification Accuracy**\nThis objective is: $\\displaystyle \\hat{\\alpha} = \\arg\\max_{\\alpha>0} \\sum_{\\ell=1}^{L} \\sum_{(x_{i},s_{i}) \\in \\mathcal{D}_{\\mathrm{test}}^{(\\ell)}} \\mathbf{1}\\{\\hat{s}_{\\alpha}^{(\\ell)}(x_{i}) = s_{i}\\}$, where the prediction $\\hat{s}_{\\alpha}^{(\\ell)}(x)$ is the class that maximizes the posterior $p(s \\mid x, \\mathcal{D}_{\\mathrm{train}}^{(\\ell)}, \\alpha)$.\nThis objective measures the model's classification accuracy on held-out data. For each test point, it makes a hard prediction (the most probable class) and checks if it is correct. The total sum represents the total number of correct classifications across all test folds. This is the definition of cross-validated accuracy, a primary metric for evaluating classifier performance. Maximizing this score is a valid way to select $\\alpha$. Thus, **B is a correct objective.**\n\n**Candidate C: In-Sample Evaluation**\nThis objective is: $\\displaystyle \\hat{\\alpha} = \\arg\\max_{\\alpha>0} \\sum_{i=1}^{M} \\log p(s_{i} \\mid x_{i}, \\mathcal{D}, \\alpha)$.\nThis objective evaluates the model on the same data it was trained on (the full dataset $\\mathcal{D}$). This is an in-sample metric, not a cross-validation procedure. It does not measure generalization performance and is prone to selecting overly complex models that overfit the training data. Thus, **C is incorrect.**\n\n**Candidate D: Maximizing Held-Out Data Likelihood**\nThis objective is: $\\displaystyle \\hat{\\alpha} = \\arg\\max_{\\alpha>0} \\sum_{\\ell=1}^{L} \\sum_{(x_{i},s_{i}) \\in \\mathcal{D}_{\\mathrm{test}}^{(\\ell)}} \\log p(x_{i} \\mid s_{i}, \\mathcal{D}_{\\mathrm{train}}^{(\\ell)}, \\alpha)$.\nThis objective evaluates the posterior predictive likelihood of the features $p(x|s)$ rather than the posterior probability of the class $p(s|x)$. While $p(x|s)$ is a component of the classifier, the ultimate goal is to predict $s$ from $x$. This objective ignores the class priors $p(s)$ and the normalization constant, and does not directly measure classification performance. A model could achieve a high score on this metric while being a poor classifier. Thus, **D is incorrect.**\n\n**Candidate E: Data Leakage**\nThis objective is: $\\displaystyle \\hat{\\alpha} = \\arg\\max_{\\alpha>0} \\sum_{\\ell=1}^{L} \\sum_{(x_{i},s_{i}) \\in \\mathcal{D}_{\\mathrm{test}}^{(\\ell)}} \\log p(s_{i} \\mid x_{i}, \\mathcal{D}, \\alpha)$.\nThis formulation violates the core principle of cross-validation by evaluating the model on test data that was part of its training set. The posterior $p(s_i \\mid x_i, \\mathcal{D}, \\alpha)$ is computed using a model trained on the entire dataset $\\mathcal{D}$. Since any test point $(x_i, s_i)$ from $\\mathcal{D}_{\\mathrm{test}}^{(\\ell)}$ is also in $\\mathcal{D}$, this constitutes data leakage. The evaluation is not on truly held-out data, making this equivalent to the incorrect in-sample evaluation in C. Thus, **E is incorrect.**\n\nIn conclusion, only options A and B represent valid cross-validation criteria for hyperparameter selection.",
            "answer": "$$\\boxed{\\text{AB}}$$"
        }
    ]
}