## 引言
在[神经科学数据分析](@entry_id:1128665)领域，如何准确评估一个模型或算法区分不同神经状态（如刺激存在与否）的能力，是一个核心挑战。传统的评估指标如准确率，其值严重依赖于所选的决策阈值，这使得比较不同模型的内在判别能力变得困难。受试者工作特性（ROC）曲线及其[曲线下面积](@entry_id:169174)（AUC）提供了一个强大、稳健且独立于阈值的框架来解决这一问题，已成为评估[分类器性能](@entry_id:903738)的黄金标准。本文旨在深入剖析AUC的理论基础与实践应用，帮助研究者和数据科学家掌握这一重要工具。

本文将引导读者全面理解AUC。在“原理与机制”一章中，我们将从基本定义出发，揭示AUC深刻的概率解释，并探讨其对数据变换和[类别不平衡](@entry_id:636658)的[不变性](@entry_id:140168)等关键属性。随后的“应用与跨学科联系”一章将展示AUC如何在神经科学研究中量化神经信息、评估解码器泛化能力，并扩展到[多类别分类](@entry_id:635679)、[生存分析](@entry_id:264012)乃至临床诊断等复杂问题中。最后，“动手实践”部分将提供精选的练习，帮助读者将理论知识转化为解决实际问题的技能，巩固对AUC计算、优缺点和最佳实践的理解。

## 原理与机制

在[神经科学数据分析](@entry_id:1128665)中，评估一个解码器或分类器区分不同神经状态或实验条件的能力至关重要。例如，我们可能需要判断一个感觉刺激是否存在、一种特定的[神经振荡](@entry_id:274786)模式是否出现，或者一个动物的行为选择是什么。受试者工作特性（Receiver Operating Characteristic, ROC）曲线及其[曲线下面积](@entry_id:169174)（Area Under the Curve, AUC）为定量评估这种区分能力提供了一个强大、稳健且被广泛应用的框架。本章将深入探讨 ROC 分析的根本原理和关键机制，从其基本定义出发，揭示其概率解释，并探讨其实际应用、关键属性以及局限性。

### ROC 曲[线与](@entry_id:177118) AUC 的定义

想象一个典型的[系统神经科学](@entry_id:173923)实验，我们旨在根据记录到的神经活动来解码一个二元条件。这个条件可能是感觉刺激“存在”（标记为 $Y=1$）或“不存在”（标记为 $Y=0$）。解码器或分类器会对每次试验的神经数据进行处理，并输出一个连续的实数值分数 $\hat{s}$，这个分数反映了支持“刺激存在”这一假设的证据强度 。

为了将这个连续的分数 $\hat{s}$ 转化为一个二元的决策（即“是”或“否”），我们需要设定一个决策阈值 $t$。如果某次试验的分数 $\hat{s}$ 大于或等于阈值 $t$，我们就将其归类为“刺激存在”（预测为 1）；否则，我们将其归类为“刺激不存在”（预测为 0）。显然，这个决策过程可能产生两种类型的正确判断和两种类型的错误。

我们用两个关键指标来量化分类器在特定阈值 $t$ 下的表现：

*   **[真阳性率](@entry_id:637442)（True Positive Rate, TPR）**：也称为**敏感性（Sensitivity）**或**召回率（Recall）**，它指的是在真实条件为“存在”（$Y=1$）的试验中，分类器正确识别出该条件的概率。其数学定义为：
    $$ \mathrm{TPR}(t) = \mathbb{P}(\hat{s} \ge t \mid Y=1) $$

*   **假阳性率（False Positive Rate, FPR）**：它指的是在真实条件为“不存在”（$Y=0$）的试验中，分类器错误地将其识别为“存在”的概率。这通常被称为“虚警率”。其数学定义为：
    $$ \mathrm{FPR}(t) = \mathbb{P}(\hat{s} \ge t \mid Y=0) $$

请注意，TPR 和 FPR 都是以真实条件为前提的**条件概率**。TPR 是在所有阳性样本中进行评估的，而 FPR 是在所有阴性样本中进行评估的。

当我们改变决策阈值 $t$ 时，TPR 和 FPR 的值会相应地发生变化。如果我们将阈值 $t$ 设得非常高（$t \to \infty$），几乎所有试验都会被归为阴性，此时 TPR 和 FPR 都趋近于 $0$。相反，如果我们将阈值设得非常低（$t \to -\infty$），几乎所有试验都会被归为阳性，此时 TPR 和 FPR 都趋近于 $1$。

**受试者工作特性（ROC）曲线**正是通过将不同阈值 $t$ 下的 $(\mathrm{FPR}(t), \mathrm{TPR}(t))$ 对作为点，在二维平面上绘制出来而形成的[参数曲线](@entry_id:634039) 。这个平面通常被称为 ROC 空间，其横轴是假阳性率（FPR），纵轴是[真阳性率](@entry_id:637442)（TPR）。ROC 曲线描绘了在所有可能的决策阈值下，TPR 和 FPR 之间的权衡关系。一条完全随机的分类器（例如，抛硬币决定）的 ROC 曲线是一条从 $(0,0)$ 到 $(1,1)$ 的对角线，即 $\mathrm{TPR} = \mathrm{FPR}$。一个优秀的分类器，其 ROC 曲线会向左上方凸起，尽可能地靠近点 $(0,1)$，这个点代表了完美的分类（$100\%$ 的[真阳性率](@entry_id:637442)和 $0\%$ 的假阳性率）。

尽管 ROC 曲线完整地展示了分类器的性能，但在比较不同分类器时，我们通常希望用一个单一的标量值来总结其整体区分能力。**[曲线下面积](@entry_id:169174)（AUC）**正是为此而生。从几何上看，AUC 是 ROC 曲线下方的面积，其取值范围在 $0$ 到 $1$ 之间。一个随机分类器的 AUC 为 $0.5$，而一个完美分类器的 AUC 为 $1.0$。

从数学上讲，AUC 是 TPR 作为 FPR 的函数，从 $x=0$ 到 $x=1$ 的积分 ：
$$ \mathrm{AUC} = \int_{0}^{1} \mathrm{TPR}(x) \, \mathrm{d}x $$
其中 $x$ 代表 FPR。由于 ROC 曲线是由阈值 $t$ [参数化](@entry_id:265163)的，我们可以通过[变量替换](@entry_id:141386)来计算这个积分。假设分数 $\hat{s}$ 在条件 $Y=0$ 下的[概率密度函数](@entry_id:140610)为 $f_0(s)$，那么 $\mathrm{FPR}(t) = \int_t^\infty f_0(s)\,\mathrm{d}s$。根据[微积分基本定理](@entry_id:201377)，我们有 $\mathrm{d}(\mathrm{FPR}(t)) = -f_0(t)\,\mathrm{d}t$。因此，AUC 可以表示为 ：
$$ \mathrm{AUC} = \int_{t=+\infty}^{t=-\infty} \mathrm{TPR}(t) (-f_0(t)\,\mathrm{d}t) = \int_{-\infty}^{\infty} \mathrm{TPR}(t) f_0(t)\,\mathrm{d}t $$

### AUC 的概率解释：更深层次的意义

AUC 的几何定义虽然直观，但其最深刻和实用的理解来自于其概率解释。这个解释将 AUC 从一个抽象的面积值转化为一个关于分类器排序能力的具体陈述。

#### AUC 作为排序概率

AUC 的值等于从阳性类别中随机抽取一个样本（分数记为 $S^+$），其得分高于从阴性类别中随机抽取一个样本（分数记为 $S^-$）的概率。假设分数是连续的，我们可以写出这个著名的[等价关系](@entry_id:138275)  ：
$$ \mathrm{AUC} = \mathbb{P}(S^+ > S^-) $$
这个结论可以通过我们之前得到的积分形式推导出来。回顾 $\mathrm{AUC} = \int_{-\infty}^{\infty} \mathrm{TPR}(t) f_0(t)\,\mathrm{d}t$。将 $\mathrm{TPR}(t) = \mathbb{P}(S^+ \ge t)$ 代入，得到：
$$ \mathrm{AUC} = \int_{-\infty}^{\infty} \mathbb{P}(S^+ \ge t) f_0(t)\,\mathrm{d}t $$
这个积分正是计算概率 $\mathbb{P}(S^+ \ge S^-)$ 的标准方法：我们对 $S^-$ 的所有可[能值](@entry_id:187992) $t$ 进行积分，每个值乘以在 $S^-=t$ 的条件下 $S^+$ 大于等于 $t$ 的概率，再乘以 $S^-$ 取值为 $t$ 的概率密度 $f_0(t)$。由于我们假设分布是连续的，$\mathbb{P}(S^+ \ge S^-) = \mathbb{P}(S^+ > S^-)$。

这个概率解释揭示了 AUC 的核心本质：它衡量的是分类器将阳性样本排在阴性样本之前的能力，而与分数的绝对值无关。一个 AUC 为 $0.8$ 的分类器意味着，如果你随机抽取一个阳性样本和一个阴性样本，有 $80\%$ 的可能性该分类器会给阳性样本赋予更高的分数。

#### 处理分数并列（Ties）的情况

在实际应用中，尤其是在处理通过特征聚合或离散化得到的神经数据时，不同试验可能会得到完全相同的分数，这导致了“并列”（ties）的出现。例如，在对啮齿动物[听觉皮层](@entry_id:894327)的分析中，基于有限时间窗口内的脉冲计数等特征计算出的决策分数可能是离散的 。

当并列以不可忽略的概率发生时，即 $\mathbb{P}(S^+ = S^-) > 0$，上述概率解释需要进行修正。在这种情况下，标准的 AUC 定义（通过梯形法则计算经验 ROC 曲线下的面积）等价于以下更通用的形式：
$$ \mathrm{AUC} = \mathbb{P}(S^+ > S^-) + \frac{1}{2}\mathbb{P}(S^+ = S^-) $$
这个公式的直观含义是：对于任意一个随机抽取的（阳性，阴性）样本对，如果阳性样本得分更高，我们得 $1$ 分；如果阴性样本得分更高，得 $0$ 分；如果两者得分并列，我们得 $\frac{1}{2}$ 分。AUC 就是这个得分的[期望值](@entry_id:150961)。

将并列情况计为 $\frac{1}{2}$ 的理由是基于对称性和稳健性。可以想象，这些离散的分数是某个潜在连续变量经过量化后的结果。如果我们给每个分数加上一个极小的、随机的“[抖动](@entry_id:200248)”（jitter），那么任何一个并列的对 $(S^+, S^-)$ 将以相等的概率（即各 $\frac{1}{2}$）被打破，从而 $S^+$ 的新分数可能高于或低于 $S^-$ 的新分数。因此，将并列计为 $\frac{1}{2}$ 可以看作是在所有可能的“打破并列”方式上取平均，这确保了 AUC 度量在一个更根本的排序意义上是无偏的，并且与 Wilcoxon-Mann-Whitney U 统计量等[非参数检验](@entry_id:909883)紧密相关 。

#### 与[信号检测论](@entry_id:924366)（SDT）的联系

在神经测量分析中，[信号检测论](@entry_id:924366)（Signal Detection Theory, SDT）提供了一个经典的理论框架。在等方差高斯模型下，我们假设来自两个类别的决策变量服从正态分布，但均值不同：$S^+ \sim \mathcal{N}(\mu_1, \sigma^2)$ 和 $S^- \sim \mathcal{N}(\mu_0, \sigma^2)$。SDT 中一个核心的度量是**判别力指数（discriminability index）** $d'$，定义为两个分布均值之差除以它们的共同标准差：
$$ d' = \frac{\mu_1 - \mu_0}{\sigma} $$
我们可以从第一性原理推导出 AUC 和 $d'$ 之间的精确关系 。利用 AUC 的概率解释，我们需要计算 $\mathbb{P}(S^+ > S^-)$。这等价于计算差值变量 $D = S^+ - S^-$ 大于 $0$ 的概率。由于 $S^+$ 和 $S^-$ 是独立的服从正态分布的[随机变量](@entry_id:195330)，它们的差 $D$ 也服从正态分布，其均值为 $\mathbb{E}[D] = \mu_1 - \mu_0$，方差为 $\mathrm{Var}(D) = \sigma^2 + \sigma^2 = 2\sigma^2$。
因此，AUC 的计算变为：
$$ \mathrm{AUC} = \mathbb{P}(D > 0) = \mathbb{P}\left(\frac{D - (\mu_1 - \mu_0)}{\sqrt{2\sigma^2}} > \frac{0 - (\mu_1 - \mu_0)}{\sqrt{2\sigma^2}}\right) $$
令 $Z$ 为标准正态变量，上式变为 $\mathbb{P}(Z > -(\mu_1 - \mu_0)/(\sigma\sqrt{2})) = \Phi((\mu_1 - \mu_0)/(\sigma\sqrt{2}))$，其中 $\Phi$ 是标准正态[累积分布函数](@entry_id:143135)。代入 $d'$ 的定义，我们得到：
$$ \mathrm{AUC} = \Phi\left(\frac{d'}{\sqrt{2}}\right) $$
这个优美的公式将 AUC 与一个在心理物理学和神经科学中广为使用的判别力指标联系起来，为 AUC 提供了更深层的理论依据。更一般地，如果方差不等，$S^+ \sim \mathcal{N}(\mu_1, \sigma_1^2)$ 和 $S^- \sim \mathcal{N}(\mu_0, \sigma_0^2)$，则差值 $D$ 的方差为 $\sigma_1^2 + \sigma_0^2$，AUC 的表达式为 ：
$$ \mathrm{AUC} = \Phi\left(\frac{\mu_1 - \mu_0}{\sqrt{\sigma_1^2 + \sigma_0^2}}\right) $$

### AUC 的关键属性与[不变性](@entry_id:140168)

AUC 之所以成为评估分类器的黄金标准之一，很大程度上归功于其优良的数学属性，特别是其对得分缩放和[类别不平衡](@entry_id:636658)的稳健性。

#### 对单调变换的不变性

由于 AUC 的本质是衡量排序能力，它对于解码器输出分数的任何**严格单调递增变换（strictly increasing transformation）** 都是不变的  。假设我们有一个变换函数 $\phi(\cdot)$，它满足如果 $a > b$，则 $\phi(a) > \phi(b)$。如果我们用 $\tilde{S} = \phi(S)$ 替换原始分数 $S$，那么新分数的排序与原始分数的排序完全相同。因此，$\mathbb{P}(\tilde{S}^+ > \tilde{S}^-) = \mathbb{P}(S^+ > S^-)$，这意味着 AUC 的值保持不变。

这个属性非常重要，因为它意味着我们无需关心解码器输出分数的绝对尺度。无论解码器输出的是[对数似然比](@entry_id:274622)、概率值还是任意范围内的证据分数，只要其排序能力不变，计算出的 AUC 就相同。这使得 AUC 成为一个非常稳健的、只关注区分能力的纯粹度量。

#### 对[类别不平衡](@entry_id:636658)的不变性

在许多神经科学实验中，不同类别的试验次数可能非常不均衡。例如，在检测罕见的癫痫样放电时，绝大多数时间窗口都是正常的 。**AUC 的一个核心优势是它对类别流行率（class prevalence）不敏感** 。

回顾 TPR 和 FPR 的定义，它们都是在特定真实类别（$Y=1$ 或 $Y=0$）下的条件概率。因此，只要条件分数分布 $f_1(s)$ 和 $f_0(s)$ 保持不变，无论阳性试验的比例 $p = \mathbb{P}(Y=1)$ 如何变化，ROC 曲线上的每一点以及整条曲线的位置都是固定的。因此，AUC 的值也保持不变 。

这与另一个常用的度量——**准确率（Accuracy）**——形成了鲜明对比。准确率定义为正确分类的试验占总试验的比例，其计算公式为：
$$ \mathrm{Acc}_p(t) = p \cdot \mathrm{TPR}(t) + (1-p) \cdot (1-\mathrm{FPR}(t)) $$
其中 $p$ 是阳性类别的流行率，$t$ 是决策阈值。从公式中可以明显看出，准确率是 $p$ 的线性函数，因此它会随着类别比例的变化而变化。例如，在一个阳性样本占 $1\%$ 的数据集中，一个简单地将所有样本都预测为阴性的分类器可以达到 $99\%$ 的准确率，但这显然是一个无用的分类器。相比之下，AUC 不受此影响，能够更真实地反映分类器的内在判别能力。

具体来说，准确率随 $p$ 变化的趋势取决于在给定阈值下 TPR 和真阴性率（TNR = $1-$FPR）的相对大小。只有当 $\mathrm{TPR}(t) = \mathrm{TNR}(t)$ 时，准确率才与 $p$ 无关。否则，如果 $\mathrm{TPR}(t) > \mathrm{TNR}(t)$，准确率会随 $p$ 的增加而增加；反之则减少 。

### 实际应用与计算

理解了 AUC 的理论基础后，我们转向如何在实践中应用和计算它，并探讨其在决策制定中的作用。

#### 经验 ROC 曲[线与](@entry_id:177118) AUC 的计算

在处理有限的实验数据时，我们无法得到理论上平滑的 ROC 曲线。取而代之的是**经验 ROC 曲线（empirical ROC curve）**，它是一条阶梯状的曲线。计算经验 AUC 的标准方法如下 ：

1.  **收集和排序**：将所有 $P$ 个阳性样本的分数和 $N$ 个阴性样本的分数合并，并从高到低进行排序。
2.  **构建曲线**：从点 $(0,0)$ 开始。依次遍历排序后的分数列表。
    *   每当遇到一个阳性样本，就在 ROC 空间中向上移动一步，步长为 $\frac{1}{P}$。这对应于 TPR 的增加。
    *   每当遇到一个阴性样本，就在 ROC 空间中向右移动一步，步长为 $\frac{1}{N}$。这对应于 FPR 的增加。
    （如果多个样本得分并列，则一次性移动相应的步数，例如，如果 $k$ 个阳性样本和 $m$ 个阴性样本得分相同，则路径会从当前点 $(x,y)$ 直接连接到点 $(x+\frac{m}{N}, y+\frac{k}{P})$。）
3.  **计算面积**：通过这个过程，我们得到一条从 $(0,0)$ 到 $(1,1)$ 的阶梯状路径。AUC 就是这条路径下方的面积。一个简单的计算方法是，每当曲线向右移动（即遇到一个阴性样本）时，我们就形成一个矩形。该矩形的高度是当前的 TPR，宽度是 FPR 的增量（即 $\frac{1}{N}$）。将所有这些小矩形的面积相加，就得到了总的 AUC。

让我们通过一个具体的例子来说明 。假设我们有一个视觉检测实验，解码器对 $P=8$ 个刺激存在（阳性）的试验和 $N=9$ 个刺激不存在（阴性）的试验给出了以下分数：
*   阳性分数 $S_P = \{0.92, 0.85, 0.78, 0.78, 0.71, 0.68, 0.60, 0.55\}$
*   阴性分数 $S_N = \{0.81, 0.74, 0.74, 0.62, 0.58, 0.52, 0.50, 0.40, 0.30\}$

通过上述方法，我们可以追踪 ROC 曲线的路径。例如，当我们处理完分数 $0.85$ 后，我们已经遇到了 2 个阳性样本，TPR 为 $\frac{2}{8}$，FPR 仍为 $0$。下一个分数是 $0.81$（阴性），这使得 FPR 增加 $\frac{1}{9}$。在 FPR 从 $0$ 变为 $\frac{1}{9}$ 的这个区间内，TPR 保持在 $\frac{2}{8}$。因此，这贡献了 $\frac{1}{9} \times \frac{2}{8}$ 的面积。继续这个过程，直到处理完所有分数，并将所有矩形面积相加，我们得到的 AUC 为 $\frac{55}{72}$。

#### 选择操作点：当 AUC 不足以为据时

AUC 是一个衡量分类器在所有可能阈值下平均性能的指标。然而，在实际部署一个分类器时，我们必须选择一个具体的阈值，即一个**操作点（operating point）** 。这个选择不再仅仅是技术问题，而是一个依赖于具体应用场景中不同错误成本的决策问题。

例如，在一个神经退行性疾病的诊断筛查中，漏诊一个真正的病人（[假阴性](@entry_id:894446)，FN）的代价（例如，延误治疗）可能远远高于将一个健康人误诊为病人（[假阳性](@entry_id:197064)，FP）的代价（例如，需要进一步检查） 。在这种情况下，即使两个分类器有完全相同的 AUC，它们也未必具有相同的临床效用。

假设假阴性和[假阳性](@entry_id:197064)的成本分别为 $c_{\mathrm{FN}}$ 和 $c_{\mathrm{FP}}$，疾病的流行率为 $\pi$。在某个操作点 $(x, y) = (\mathrm{FPR}, \mathrm{TPR})$，单位病人的期望误分类成本为：
$$ C(x) = (1-\pi) \cdot c_{\mathrm{FP}} \cdot x + \pi \cdot c_{\mathrm{FN}} \cdot (1-y(x)) $$
为了最小化这个成本，我们需要找到一个点 $x^*$，使得成本函数 $C(x)$ 的导数为零。这给出了最优操作点所满足的条件：
$$ \frac{\mathrm{d}y}{\mathrm{d}x} \bigg|_{x=x^*} = \frac{(1-\pi) c_{\mathrm{FP}}}{\pi c_{\mathrm{FN}}} $$
这个等式意味着，最优操作点是 ROC 曲线上斜率等于成本与流行率比率的点。

现在，考虑两个具有不同形状但 AUC 相同的 ROC 曲线 。例如，分类器 1 的 ROC 曲线为 $\mathrm{TPR}_1(x) = x^{1/2}$，而分类器 2 的为 $\mathrm{TPR}_2(x) = 2x - x^2$。两者计算出的 AUC 均为 $\frac{2}{3}$。然而，它们的斜率函数不同。在给定的成本和流行率下，它们的最优操作点会落在曲线上的不同位置，从而导致不同的最小期望成本（或最大期望效用）。这深刻地说明了，当特定类型的错误成本非常重要时，仅仅比较 AUC 是不够的；我们还必须考虑 ROC 曲线的局部形状，以选择在相关操作区域表现更优的分类器。

### 局限性与替代指标

尽管 AUC 是一个强大且广泛使用的工具，但它并非万能。了解其局限性对于正确解释和使用它至关重要。

#### AUC 不衡量校准度

AUC 是一个基于排序的度量，因此它完全不关心分类器输出分数的**校准度（calibration）** 。一个分类器被称为是“良好校准的”，如果其预测的概率能够真实地反映事件发生的长期频率。例如，对于所有被赋予 $70\%$ 概率为阳性的样本，其中确实有大约 $70\%$ 是真正的阳性。

校准度依赖于预测概率的绝对值，而 AUC 对此不敏感。我们可以构造两个分类器，它们具有完全相同的 AUC，但校准度却截然不同。例如，假设一个解码器 A 输出校准良好的概率 $p_A(s)$。现在我们构造解码器 B，其输出为 $p_B(s) = (p_A(s))^2$。由于平方运算在 $[0,1]$ 区间是严格单调递增的，它保持了所有样本的排序，因此解码器 B 的 ROC 曲线和 AUC 与 A 完全相同。然而，B 的校准度很差：当真实概率为 $0.8$ 时，它预测的概率仅为 $0.64$，系统性地低估了概率。

在那些需要将预测概率用于下游决策（例如，结合成本和收益进行[风险分析](@entry_id:140624)）的应用中，校准度至关重要。在这种情况下，除了 AUC，还应评估分类器的[校准曲线](@entry_id:175984)或使用如 Brier 分数等其他指标。

#### 类别极度不平衡时的考量：[精确率-召回率曲线](@entry_id:902836)

当处理类别极度不平衡的数据集时（例如，在脑电图中检测罕见的癫痫尖波），ROC 曲线可能会给人一种过于乐观的印象 。由于阴性样本的数量远远超过阳性样本，一个分类器即使有很低的假阳性率（FPR），也可能产生大量的假阳性样本，从而导致预测为阳性的结果中绝大多数都是错误的。

在这种情况下，**[精确率](@entry_id:190064)-召回率（Precision-Recall, PR）曲线**通常被认为是一个更有[信息量](@entry_id:272315)的评估工具。其中，召回率（Recall）就是我们已经熟悉的[真阳性率](@entry_id:637442)（TPR），而**精确率（Precision）**定义为在所有被预测为阳性的样本中，真正是阳性的比例：
$$ \mathrm{Precision} = \mathbb{P}(Y=1 \mid \hat{s} \ge t) = \frac{\mathrm{TP}}{\mathrm{TP} + \mathrm{FP}} $$
使用[贝叶斯定理](@entry_id:897366)，我们可以将精确率与 TPR、FPR 和类别流行率 $p$ 联系起来：
$$ \mathrm{Precision} = \frac{p \cdot \mathrm{TPR}}{p \cdot \mathrm{TPR} + (1-p) \cdot \mathrm{FPR}} $$
与 ROC 曲线不同，PR 曲线的形状强烈依赖于类别流行率 $p$。在一个[类别不平衡](@entry_id:636658)的数据集（$p$ 很小）中，一个随机分类器的 PR 曲线会是一条接近横轴的水平线（在 $y=p$ 的位置），这意味着获得高[精确率](@entry_id:190064)非常困难。PR 曲线能够直观地展示分类器在提升罕见事件检出率的同时，保持预测结果可靠性的能力。

当 FPR 接近于 0 时，精确率对 FPR 的微小变化极为敏感。这意味着，对于需要严格控制[假阳性](@entry_id:197064)的罕见[事件检测](@entry_id:162810)任务，PR 曲线及其[曲线下面积](@entry_id:169174)（PR-AUC）能够比 ROC-AUC 更敏锐地反映出[分类器性能](@entry_id:903738)的改进 。因此，对于这类问题，同时考察 ROC 和 PR 曲线，可以为我们提供一个更全面、更符合实际需求的性能评估。