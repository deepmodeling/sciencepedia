{
    "hands_on_practices": [
        {
            "introduction": "为了牢固掌握选择概率（Choice Probability, CP）的概念，我们从其理论基础开始。第一个练习旨在建立CP与信号检测论中另一个关键指标——神经元敏感性指数（neurometric sensitivity, $d'$）之间的数学联系。通过在一个理想化的高斯模型下推导此关系，您将深刻理解CP的核心含义：即它如何量化神经元活动区分两种不同内部状态（此处为两种选择）的能力。",
            "id": "4145816",
            "problem": "在一个双择一强迫选择决策任务中，考虑在固定时间窗口内测量的单个神经元的脉冲计数响应 $r$。对于一个固定的刺激条件 $s$，假设在给定被试最终选择的情况下，$r$ 的条件分布是方差相等但均值不同的高斯分布：$r \\mid (\\text{choice} = +, s) \\sim \\mathcal{N}(\\mu_{+}(s), \\sigma^{2}(s))$ 和 $r \\mid (\\text{choice} = -, s) \\sim \\mathcal{N}(\\mu_{-}(s), \\sigma^{2}(s))$。假设试验间相互独立，并且从这两个条件分布中的抽样在各次试验中是独立的。\n\n将此神经元在刺激 $s$ 下的神经元度量灵敏度指数 $d^{\\prime}(s)$ 定义为\n$$\nd^{\\prime}(s) \\equiv \\frac{\\mu_{+}(s) - \\mu_{-}(s)}{\\sigma(s)}.\n$$\n将刺激 $s$ 下的选择概率 (CP)，记为 $\\mathrm{CP}(s)$，定义为在以 $s$ 为条件的单次试验响应 $r$ 中区分被试选择的受试者工作特征 (ROC) 曲线下的面积。等价地，$\\mathrm{CP}(s)$ 等于从 $r \\mid (\\text{choice} = +, s)$ 分布中独立抽取的一个响应值超过从 $r \\mid (\\text{choice} = -, s)$ 分布中独立抽取的一个响应值的概率。\n\n仅从这些定义和高斯随机变量的性质出发，在等方差高斯情况下，推导 $\\mathrm{CP}(s)$ 作为 $d^{\\prime}(s)$ 函数的闭式表达式。你的推导过程应明确阐述所使用的概率变换，并对每一步进行论证。同时，请用文字解释在你推导的映射关系中，以刺激 $s$ 为条件所起的作用，并说明在何种情况下（例如，若将来自多个刺激值的响应汇集在一起，或违反等方差假设时）该映射关系会失效。\n\n请将你的最终结果以 $\\mathrm{CP}(s)$ 关于 $d^{\\prime}(s)$ 的单个闭式解析表达式的形式给出。无需进行数值近似或舍入。",
            "solution": "该问题在应用于神经科学的信号检测论框架内提法明确且有科学依据。所有定义都是标准的，其假设虽然有所简化，但在该领域是常见的。我现在开始进行推导。\n\n目标是推导选择概率 $\\mathrm{CP}(s)$ 作为神经元度量灵敏度指数 $d^{\\prime}(s)$ 函数的闭式表达式。\n\n题目给出了选择概率 $\\mathrm{CP}(s)$ 的两个定义。我们将使用其概率性定义，即 $\\mathrm{CP}(s)$ 是从对应“$+$”选择的分布中独立抽取的一个响应值超过从对应“$-$”选择的分布中独立抽取的一个响应值的概率。设 $r_{+}$ 是一个随机变量，代表以“$+$”选择和刺激 $s$ 为条件的神经响应；设 $r_{-}$ 是一个随机变量，代表以“$-$”选择和刺激 $s$ 为条件的神经响应。根据问题陈述，它们的分布为：\n$$\nr_{+} \\sim \\mathcal{N}(\\mu_{+}(s), \\sigma^{2}(s))\n$$\n$$\nr_{-} \\sim \\mathcal{N}(\\mu_{-}(s), \\sigma^{2}(s))\n$$\n题目说明 $r_{+}$ 和 $r_{-}$ 是独立抽取的。那么选择概率定义为：\n$$\n\\mathrm{CP}(s) = P(r_{+} > r_{-})\n$$\n这个不等式可以通过考虑这两个随机变量的差来改写。我们定义一个新的随机变量 $\\Delta r$ 为它们的差：\n$$\n\\Delta r = r_{+} - r_{-}\n$$\n我们要求的概率就是 $P(\\Delta r > 0)$。\n\n为了计算这个概率，我们必须首先确定 $\\Delta r$ 的概率分布。高斯随机变量的一个基本性质是，其线性组合也是一个高斯随机变量。由于 $r_{+}$ 和 $r_{-}$ 是独立的高斯变量，它们的差 $\\Delta r$ 也是高斯分布的。\n\n$\\Delta r$ 的均值，记为 $E[\\Delta r]$，是各自均值的差：\n$$\nE[\\Delta r] = E[r_{+}] - E[r_{-}] = \\mu_{+}(s) - \\mu_{-}(s)\n$$\n$\\Delta r$ 的方差，记为 $\\mathrm{Var}(\\Delta r)$，是各自方差的和，因为 $r_{+}$ 和 $r_{-}$ 是独立的：\n$$\n\\mathrm{Var}(\\Delta r) = \\mathrm{Var}(r_{+}) + \\mathrm{Var}(r_{-}) = \\sigma^{2}(s) + \\sigma^{2}(s) = 2\\sigma^{2}(s)\n$$\n因此 $\\Delta r$ 的标准差是 $\\mathrm{SD}(\\Delta r) = \\sqrt{2\\sigma^{2}(s)} = \\sqrt{2}\\sigma(s)$。\n\n所以，这个差值变量的分布是：\n$$\n\\Delta r \\sim \\mathcal{N}(\\mu_{+}(s) - \\mu_{-}(s), 2\\sigma^{2}(s))\n$$\n现在我们来计算此分布下 $P(\\Delta r > 0)$ 的概率。为此，我们将随机变量 $\\Delta r$ 进行标准化，即减去其均值再除以其标准差，从而将其转换为一个标准正态变量 $Z \\sim \\mathcal{N}(0, 1)$：\n$$\nZ = \\frac{\\Delta r - E[\\Delta r]}{\\mathrm{SD}(\\Delta r)} = \\frac{\\Delta r - (\\mu_{+}(s) - \\mu_{-}(s))}{\\sqrt{2}\\sigma(s)}\n$$\n我们可以用标准正态变量 $Z$ 来重写不等式 $\\Delta r > 0$：\n$$\n\\Delta r > 0 \\implies \\Delta r - (\\mu_{+}(s) - \\mu_{-}(s)) > -(\\mu_{+}(s) - \\mu_{-}(s))\n$$\n$$\n\\frac{\\Delta r - (\\mu_{+}(s) - \\mu_{-}(s))}{\\sqrt{2}\\sigma(s)} > \\frac{-(\\mu_{+}(s) - \\mu_{-}(s))}{\\sqrt{2}\\sigma(s)}\n$$\n$$\nZ > -\\frac{\\mu_{+}(s) - \\mu_{-}(s)}{\\sqrt{2}\\sigma(s)}\n$$\n问题将神经元度量灵敏度指数定义为 $d^{\\prime}(s) = \\frac{\\mu_{+}(s) - \\mu_{-}(s)}{\\sigma(s)}$。将此定义代入我们的不等式中，得到：\n$$\nZ > -\\frac{d^{\\prime}(s)}{\\sqrt{2}}\n$$\n选择概率就是这个事件的概率：\n$$\n\\mathrm{CP}(s) = P\\left(Z > -\\frac{d^{\\prime}(s)}{\\sqrt{2}}\\right)\n$$\n设 $\\Phi(z)$ 表示标准正态分布的累积分布函数 (CDF)，即 $\\Phi(z) = P(Z \\le z)$。概率 $P(Z > a)$ 等于 $1 - P(Z \\le a) = 1 - \\Phi(a)$。应用此性质，我们得到：\n$$\n\\mathrm{CP}(s) = 1 - \\Phi\\left(-\\frac{d^{\\prime}(s)}{\\sqrt{2}}\\right)\n$$\n根据标准正态分布关于 0 的对称性，对于任意 $z$，我们有 $\\Phi(-z) = 1 - \\Phi(z)$ 这个性质。因此，我们可以简化 $\\mathrm{CP}(s)$ 的表达式：\n$$\n\\mathrm{CP}(s) = 1 - \\left(1 - \\Phi\\left(\\frac{d^{\\prime}(s)}{\\sqrt{2}}\\right)\\right) = \\Phi\\left(\\frac{d^{\\prime}(s)}{\\sqrt{2}}\\right)\n$$\n这就是选择概率作为神经元度量灵敏度指数函数的闭式表达式。\n\n关于问题的第二部分：\n以刺激 $s$ 为条件的作用是至关重要的。神经响应分布的参数——$\\mu_{+}(s)$、$\\mu_{-}(s)$ 和 $\\sigma(s)$——都是刺激 $s$ 的函数。因此，$d^{\\prime}(s)$ 和 $\\mathrm{CP}(s)$ 本身也都是刺激的函数。我们推导出的映射关系 $\\mathrm{CP}(s) = \\Phi(d^{\\prime}(s)/\\sqrt{2})$ 仅在为单一、固定的刺激水平 $s$ 定义的一对分布时才成立。如果将来自不同刺激值（例如，$s_{1}, s_{2}, \\dots$）的神经响应汇集起来，那么得到的汇集数据将不再是从单个高斯分布中抽取的，而是一个高斯混合分布。此处推导的、依赖于单对高斯分布性质的简单关系将会失效。总体的选择概率将是各特定刺激下选择概率的加权平均值，但这无法通过一个简单的方式与一个根据汇集后的非高斯数据草率计算出的单一 $d^{\\prime}$ 值关联起来。\n\n等方差假设也至关重要。如果方差不相等，即 $r_{+} \\sim \\mathcal{N}(\\mu_{+}(s), \\sigma_{+}^{2}(s))$ 且 $r_{-} \\sim \\mathcal{N}(\\mu_{-}(s), \\sigma_{-}^{2}(s))$，那么差值 $\\Delta r$ 的方差将是 $\\mathrm{Var}(\\Delta r) = \\sigma_{+}^{2}(s) + \\sigma_{-}^{2}(s)$。标准化变量 $Z$ 的不等式将变为：\n$$\nZ > -\\frac{\\mu_{+}(s) - \\mu_{-}(s)}{\\sqrt{\\sigma_{+}^{2}(s) + \\sigma_{-}^{2}(s)}}\n$$\n此时，CDF 的自变量将是 $\\frac{\\mu_{+}(s) - \\mu_{-}(s)}{\\sqrt{\\sigma_{+}^{2}(s) + \\sigma_{-}^{2}(s)}}$。这个表达式无法被简化为仅关于 $d^{\\prime}(s) \\equiv \\frac{\\mu_{+}(s) - \\mu_{-}(s)}{\\sigma(s)}$ 的函数，其中 $\\sigma(s)$ 通常是某种形式的合并标准差。CP 和 $d^{\\prime}$ 之间的关系会变得更加复杂，还会额外地取决于标准差的比率 $\\sigma_{+}(s)/\\sigma_{-}(s)$。",
            "answer": "$$\n\\boxed{\\Phi\\left(\\frac{d^{\\prime}(s)}{\\sqrt{2}}\\right)}\n$$"
        },
        {
            "introduction": "理论模型虽然清晰，但真实世界的神经数据很少完全符合理想化假设。一个核心挑战是混淆变量的存在，例如外部刺激，它既能影响神经活动，也可能影响最终的选择。本练习通过一个模拟任务，生动地展示了著名的统计陷阱——辛普森悖论。您将看到，当跨越不同刺激强度汇集数据并天真地计算CP时，可能会得出与事实完全相反的结论，从而突显了在数据分析中恰当控制混淆变量的重要性。",
            "id": "4145788",
            "problem": "您的任务是构建一个模拟，在将神经活动与决策联系起来的选择概率背景下展示辛普森悖论，然后通过以刺激水平为条件来解决该悖论。请以纯数学术语进行操作，使用一个用于二元决策和单个神经元响应的线性高斯生成模型。该问题要求严格遵守概率论和经典信号检测分析的定义。\n\n基本设定：\n- 设刺激为一个离散随机变量 $S \\in \\{s_1,\\dots,s_m\\}$。\n- 设决策变量为 $D = w S + \\xi$，其中 $w \\in \\mathbb{R}$，$\\xi \\sim \\mathcal{N}(0,\\sigma_d^2)$ 是独立的高斯噪声。\n- 设二元选择为 $C = \\mathbb{I}[D \\ge 0]$，其中 $\\mathbb{I}[\\cdot]$ 是指示函数。\n- 设神经元的标量响应为 $R = a S + b D + \\varepsilon$，其中 $a,b \\in \\mathbb{R}$，$\\varepsilon \\sim \\mathcal{N}(0,\\sigma_r^2)$ 是独立的高斯噪声。\n\n定义：\n- 对于一个固定的刺激 $S=s$，神经元的选择概率（CP）定义为：在一次随机选择的、选择为 $C=1$ 的试验中，该神经元的响应超过在另一次随机选择的、选择为 $C=0$ 的试验中（在相同刺激下）该神经元响应的概率：$$\\mathrm{CP}(s) = \\mathbb{P}\\!\\left(R^{(1)}  R^{(0)} \\mid S=s\\right),$$ 其中 $R^{(1)}$ 从以 $(C=1,S=s)$ 为条件的 $R$ 的分布中抽取，$R^{(0)}$ 从以 $(C=0,S=s)$ 为条件的 $R$ 的分布中抽取。该量等于根据这两个条件响应分布计算出的受试者工作特征（ROC）曲线下的面积。\n- 忽略刺激的聚合选择概率为 $$\\mathrm{CP}_{\\mathrm{agg}} = \\mathbb{P}\\!\\left(R^{(1)}  R^{(0)}\\right),$$ 其中 $R^{(1)}$ 从以 $C=1$ 为条件的 $R$ 的分布中抽取，$R^{(0)}$ 从以 $C=0$ 为条件的 $R$ 的分布中抽取，对 $S$ 没有限制。根据全概率定律，这聚合了混合刺激水平，因此可能将 $R$ 中依赖于刺激的效应与决策相关的效应混为一谈。\n\n目标：\n- 针对几个参数集，根据指定的生成模型模拟 $N$ 次试验。对于每个参数集：\n  1. 生成 $N$ 个独立的 $(S,D,C,R)$ 样本。\n  2. 使用由 $C=1$ 和 $C=0$ 的 $R$ 分布形成的ROC曲线下的经验面积来计算 $\\mathrm{CP}_{\\mathrm{agg}}$。\n  3. 对每个刺激水平 $s \\in \\{s_1,\\dots,s_m\\}$，仅使用 $S=s$ 的试验来计算 $\\mathrm{CP}(s)$。\n  4. 判断是否出现辛普森悖论，此处定义为事件 $$\\mathrm{CP}_{\\mathrm{agg}}  0.5 \\quad \\text{并且} \\quad \\mathrm{CP}(s) > 0.5 \\ \\text{对于所有刺激水平 } s.$$\n- 使用 Mann–Whitney $U$ 统计量公式来估计ROC曲线下的面积，并以适当处理平局的方式进行：如果 $X$ 是 $C=1$ 的响应，$Y$ 是 $C=0$ 的响应，则 $$\\widehat{\\mathrm{AUC}} = \\frac{U}{n_X n_Y},$$ 其中 $U$ 是根据连接样本的平均秩计算的，$n_X$ 和 $n_Y$ 是样本大小。\n\n科学真实性：\n- 所有变量必须根据指定的线性高斯模型进行模拟，其中噪声项 $\\xi$ 和 $\\varepsilon$ 相互独立。\n- 必须选择刺激水平，以确保在每个 $s$ 处，两种选择都以非零频率出现，从而保证经验性 $\\mathrm{CP}(s)$ 是良定义的。\n\n测试套件：\n- 提供一个包含4个参数集的测试套件，用于探测不同的情况：\n  1. 一个旨在展示辛普森悖论的案例（聚合符号与刺激内CP的符号相反）：\n     - $N = 4000$, $S \\in \\{-1,0,1\\}$ 均匀分布, $w = 2.0$, $a = -3.0$, $b = 0.7$, $\\sigma_d = 1.0$, $\\sigma_r = 1.0$, seed $= 1$。\n  2. 一个没有逆转的案例（聚合CP与条件CP的符号一致）：\n     - $N = 4000$, $S \\in \\{-1,0,1\\}$ 均匀分布, $w = 2.0$, $a = 0.5$, $b = 0.7$, $\\sigma_d = 1.0$, $\\sigma_r = 1.0$, seed $= 2$。\n  3. 一个边界案例，其中聚合CP约为 $0.5$，而刺激内CP偏离 $0.5$：\n     - $N = 4000$, $S \\in \\{-1,0,1\\}$ 均匀分布, $w = 2.0$, $a = -1.0$, $b = 0.7$, $\\sigma_d = 1.0$, $\\sigma_r = 1.0$, seed $= 3$。\n  4. 一个边缘案例，由于与决策变量的耦合为零，刺激内CP恰好为 $0.5$：\n     - $N = 4000$, $S \\in \\{-1,0,1\\}$ 均匀分布, $w = 2.0$, $a = -3.0$, $b = 0.0$, $\\sigma_d = 1.0$, $\\sigma_r = 1.0$, seed $= 4$。\n\n输出规范：\n- 对于每个参数集，输出一个形式为 $[\\mathrm{CP}_{\\mathrm{agg}}, [\\mathrm{CP}(s_1),\\dots,\\mathrm{CP}(s_m)], \\mathrm{rev}]$ 的列表，其中 $\\mathrm{rev}$ 是一个布尔值，指示是否根据上述定义发生了辛普森悖论。\n- 您的程序应生成单行输出，其中包含所有4个测试用例的结果，形式为逗号分隔的列表并用方括号括起来，例如 $[[\\dots],[\\dots],[\\dots],[\\dots]]$。不应打印任何额外文本。",
            "solution": "该问题陈述已经过仔细验证，被认为是具有科学依据、问题定义明确且内部一致的。它在计算神经科学领域提出了一个清晰且可形式化的任务。所有变量、参数和过程都得到了明确定义，从而能够直接、无歧义地实现。该问题是使用信号检测理论中一个标准的线性高斯模型来经典地展示辛普森悖论，这是一个有效且具有启发性的练习。\n\n问题的核心在于模拟一个感知决策任务的生成模型。我们给定：\n- 一个离散刺激 $S$，从集合 $\\{s_1, \\dots, s_m\\}$ 中均匀抽取。在此问题中，$S \\in \\{-1, 0, 1\\}$。\n- 一个连续决策变量 $D = w S + \\xi$，其中 $w \\in \\mathbb{R}$ 是一个权重，$\\xi$ 是独立的高斯噪声，$\\xi \\sim \\mathcal{N}(0, \\sigma_d^2)$。此变量代表为决策积累的内部证据。\n- 一个二元选择 $C = \\mathbb{I}[D \\ge 0]$，其中 $\\mathbb{I}[\\cdot]$ 是指示函数。这表示对决策变量的阈值跨越操作，导致两种选择之一，我们标记为 $C=1$ 和 $C=0$。\n- 一个标量神经响应 $R = a S + b D + \\varepsilon$，其中 $a, b \\in \\mathbb{R}$ 是权重，$\\varepsilon$ 是独立的高斯噪声，$\\varepsilon \\sim \\mathcal{N}(0, \\sigma_r^2)$。这模拟了一个神经元，其放电率受外部刺激 $S$ 和内部决策变量 $D$ 的双重调制。\n\n目标是计算并比较两个量：\n1. 条件选择概率 $\\mathrm{CP}(s)$，为每个刺激水平 $s$ 定义。这是在刺激固定为 $S=s$ 的条件下，一次选择为 $C=1$ 的试验中的神经响应 $R$ 大于一次选择为 $C=0$ 的试验中的神经响应的概率。形式上，$\\mathrm{CP}(s) = \\mathbb{P}(R^{(1)}  R^{(0)} \\mid S=s)$。这个量旨在分离神经响应与选择之间的关系，而不受刺激本身的任何混杂影响。\n2. 聚合选择概率 $\\mathrm{CP}_{\\mathrm{agg}} = \\mathbb{P}(R^{(1)}  R^{(0)})$，其中比较是在所有试验中进行的，不考虑刺激水平。这个量在未考虑变化的刺激的情况下，粗略地评估神经响应和选择之间的关系。\n\n辛普森悖论是一种统计现象，即在数据的几个不同组中出现的一种趋势，在这些组合并后消失或逆转。在此背景下，该悖论由特定条件定义：$\\mathrm{CP}_{\\mathrm{agg}}  0.5$ 同时对所有刺激水平 $s$ 都有 $\\mathrm{CP}(s)  0.5$。\n\n该悖论的机制可以通过分析模型方程来理解。将 $D$ 的表达式代入 $R$ 的表达式中，得到：\n$$R = aS + bD + \\varepsilon = aS + b(wS + \\xi) + \\varepsilon = (a+bw)S + b\\xi + \\varepsilon$$\n当我们以固定刺激 $S=s$ 为条件时，响应为 $R_s = (a+bw)s + b\\xi + \\varepsilon$。选择 $C$ 由 $D_s = ws + \\xi$ 的符号决定，这取决于决策噪声项 $\\xi$ 的值。因此，响应 $R_s$ 与选择 $C$ 之间的相关性由项 $b\\xi$ 介导。如果 $b0$，一个较大的 $\\xi$ 值（这使得选择 $C=1$ 的可能性更大）会导致一个较大的神经响应 $R_s$。因此，$C=1$ 时 $R_s$ 的分布将随机大于 $C=0$ 时的分布，导致 $\\mathrm{CP}(s)  0.5$。因此，参数 $b$ 代表了神经元活动与决策过程之间的直接耦合。$b0$ 的测试用例旨在展示 $\\mathrm{CP}(s)  0.5$。\n\n然而，在聚合的情况下，我们不控制作为混杂变量的 $S$。决策规则的设计，$C=\\mathbb{I}[wS+\\xi \\ge 0]$ 且 $w0$，确保了高刺激值（例如 $S=1$）与选择 $C=1$ 强相关，而低刺激值（例如 $S=-1$）与选择 $C=0$ 相关。刺激 $S$ 也通过项 $aS$（以及 $(a+bw)S$）影响响应 $R$。如果系数 $a$ 足够负（如测试用例1中），高值 $S$（主要与 $C=1$ 相关）将系统性地产生较低的 $R$ 值，而低值 $S$（主要与 $C=0$ 相关）将系统性地产生较高的 $R$ 值。这种由参数 $a$ 驱动的混杂效应，可以压倒由 $b$ 驱动的直接选择相关效应。这可能导致 $C=1$ 的聚合响应分布随机小于 $C=0$ 的分布，从而产生 $\\mathrm{CP}_{\\mathrm{agg}}  0.5$，并因此造成悖论。\n\n实现将按以下步骤进行。对于每个参数集：\n1. 通过使用 `numpy` 从其指定分布中生成 $S$、$\\xi$ 和 $\\varepsilon$ 的随机样本，模拟 $N$ 次独立试验。为确保可复现性，每个案例都使用提供的种子初始化一个专用的随机数生成器。\n2. 根据生成模型为每次试验计算变量 $D$、 $C$ 和 $R$。\n3. 选择概率被估计为受试者工作特征（ROC）曲线下的面积。如规范所述，这是使用 Mann-Whitney $U$ 统计量计算的：$\\widehat{\\mathrm{AUC}} = U / (n_1 n_0)$。我们使用 `scipy.stats.mannwhitneyu` 函数并带上 `alternative='greater'` 选项，这提供了与 $\\mathbb{P}(R^{(1)}  R^{(0)})$ 对应的正确 $U$ 统计量。\n4. 首先，使用所有 $N$ 次试验计算 $\\mathrm{CP}_{\\mathrm{agg}}$，仅按选择 $C \\in \\{0,1\\}$ 进行划分。\n5. 然后，对于每个刺激水平 $s \\in \\{-1,0,1\\}$，选择对应于 $S=s$ 的试验子集，并通过按选择划分该子集来计算 $\\mathrm{CP}(s)$。\n6. 最后，评估辛普森悖论的逻辑条件 $\\mathrm{CP}_{\\mathrm{agg}}  0.5 \\land (\\forall s, \\mathrm{CP}(s)  0.5)$。结果被编译成指定的列表格式。对所有四个测试用例重复此过程。",
            "answer": "```python\nimport numpy as np\nfrom scipy.stats import mannwhitneyu\n\ndef solve():\n    \"\"\"\n    Main function to run the Simpson's paradox simulation for all test cases.\n    \"\"\"\n    test_cases = [\n        # Case 1: Designed to exhibit Simpson’s paradox. a is strongly negative.\n        {\n            'N': 4000, 's_levels': [-1, 0, 1], 'w': 2.0, 'a': -3.0, 'b': 0.7, \n            'sigma_d': 1.0, 'sigma_r': 1.0, 'seed': 1\n        },\n        # Case 2: No reversal. a is positive, so stimulus and decision effects align.\n        {\n            'N': 4000, 's_levels': [-1, 0, 1], 'w': 2.0, 'a': 0.5, 'b': 0.7, \n            'sigma_d': 1.0, 'sigma_r': 1.0, 'seed': 2\n        },\n        # Case 3: Boundary case. a is negative but smaller, confounding is weaker.\n        {\n            'N': 4000, 's_levels': [-1, 0, 1], 'w': 2.0, 'a': -1.0, 'b': 0.7, \n            'sigma_d': 1.0, 'sigma_r': 1.0, 'seed': 3\n        },\n        # Case 4: Edge case. b=0, so no direct link from decision to response.\n        {\n            'N': 4000, 's_levels': [-1, 0, 1], 'w': 2.0, 'a': -3.0, 'b': 0.0, \n            'sigma_d': 1.0, 'sigma_r': 1.0, 'seed': 4\n        }\n    ]\n\n    all_results = []\n    \n    for params in test_cases:\n        result = _run_single_case(**params)\n        all_results.append(result)\n\n    # The final print must be a single line with the specified format.\n    # Python's str() on lists produces the required bracketed, comma-separated format.\n    print(f\"[{','.join(map(str, all_results))}]\")\n\n\ndef _calculate_auc(responses_1, responses_0):\n    \"\"\"\n    Calculates the Area Under the ROC Curve (AUC) using the Mann-Whitney U statistic.\n    AUC = P(response_1  response_0), estimated as U / (n1 * n0).\n    \"\"\"\n    n1 = len(responses_1)\n    n0 = len(responses_0)\n    \n    # If one of the choices was not made, the AUC is undefined.\n    # Problem statement guarantees this won't happen for the given parameters.\n    # We return 0.5 as a neutral value, though np.nan would also be appropriate.\n    if n1 == 0 or n0 == 0:\n        return 0.5\n\n    # 'alternative'='greater' tests H1: P(responses_1  responses_0)  0.5.\n    # The statistic returned is U1, where U = U1 / (n1 * n0).\n    u_statistic, _ = mannwhitneyu(responses_1, responses_0, alternative='greater')\n    \n    return u_statistic / (n1 * n0)\n\n\ndef _run_single_case(N, s_levels, w, a, b, sigma_d, sigma_r, seed):\n    \"\"\"\n    Runs the simulation for a single set of parameters and computes the results.\n    \"\"\"\n    rng = np.random.default_rng(seed)\n\n    # Step 1: Generate N independent samples of (S, D, C, R)\n    # Generate stimulus S from a uniform discrete distribution\n    S = rng.choice(s_levels, size=N, replace=True)\n    \n    # Generate independent Gaussian noise terms\n    xi = rng.normal(loc=0.0, scale=sigma_d, size=N)\n    epsilon = rng.normal(loc=0.0, scale=sigma_r, size=N)\n    \n    # Compute decision variable D, binary choice C, and neural response R\n    D = w * S + xi\n    C = (D = 0).astype(int)  # C=1 if D=0, C=0 otherwise\n    R = a * S + b * D + epsilon\n\n    # Step 2: Compute aggregated Choice Probability (CP_agg)\n    R_agg_1 = R[C == 1]\n    R_agg_0 = R[C == 0]\n    cp_agg = _calculate_auc(R_agg_1, R_agg_0)\n\n    # Step 3: Compute conditional Choice Probability CP(s) for each stimulus level\n    cp_conditional_list = []\n    unique_s_levels = sorted(s_levels)\n    for s_val in unique_s_levels:\n        mask_s = (S == s_val)\n        \n        R_s = R[mask_s]\n        C_s = C[mask_s]\n        \n        R_cond_1 = R_s[C_s == 1]\n        R_cond_0 = R_s[C_s == 0]\n        \n        cp_s = _calculate_auc(R_cond_1, R_cond_0)\n        cp_conditional_list.append(cp_s)\n\n    # Step 4: Determine if Simpson's paradox occurred\n    # Condition: CP_agg  0.5 AND CP(s)  0.5 for all s\n    is_paradox = False\n    if cp_agg  0.5 and all(cp > 0.5 for cp in cp_conditional_list):\n        is_paradox = True\n    \n    # Format the output a [CP_agg, [CP(s1), ..., CP(sm)], rev]\n    return [cp_agg, cp_conditional_list, is_paradox]\n\nsolve()\n```"
        },
        {
            "introduction": "认识到混淆变量的危害后，我们自然会问：如何才能在分析中有效地控制它们？这个实践练习将指导您实现并比较两种在神经科学数据分析中广泛使用的CP估算方法：回归残差法和分箱法。通过在已知真实CP值的模拟数据上应用这些技术，您不仅能获得处理复杂数据集的实践经验，还能学会如何评估不同分析策略的准确性和局限性，从而为解决实际科研问题打下坚实基础。",
            "id": "4145772",
            "problem": "您会获得模拟的单神经元试验数据，其中包含刺激值、神经响应以及二元选择。科学目标是估计选择概率（Choice Probability, CP），其定义为受试者工作特征（Receiver Operating Characteristic, ROC）曲线下的面积，用于衡量神经活动在多大程度上能预测选择，同时移除混杂的刺激效应。您将实现并比较两种方法：一种是回归-残差方法，另一种是基于分箱的方法。您的程序必须为指定的测试套件生成定量结果。\n\n使用的基本原理和定义：\n- 选择概率（CP）定义为，以选择为条件的标量神经响应分布之间的受试者工作特征（ROC）曲线下面积。如果 $r_{1}$ 和 $r_{0}$ 分别表示在选择 $y=1$ 和 $y=0$ 条件下从响应分布中独立抽取的样本，那么CP等于\n$$CP \\equiv \\mathbb{P}\\left(r_{1}  r_{0}\\right) + \\frac{1}{2}\\,\\mathbb{P}\\left(r_{1} = r_{0}\\right)。$$\n- 从在 $y=1$ 条件下抽取的样本 $\\{x_{i}\\}_{i=1}^{n_{1}}$ 和在 $y=0$ 条件下抽取的样本 $\\{z_{j}\\}_{j=1}^{n_{0}}$ 计算CP的无偏U-统计量估计器为\n$$\\widehat{CP} = \\frac{1}{n_{1} n_{0}} \\sum_{i=1}^{n_{1}} \\sum_{j=1}^{n_{0}} \\left[ \\mathbf{1}\\{x_{i}  z_{j}\\} + \\frac{1}{2}\\mathbf{1}\\{x_{i} = z_{j}\\} \\right]，$$\n这等价于以曲线下面积表示的Mann–Whitney统计量。这种等价性允许通过秩来实现稳定的计算。\n- 刺激驱动的基线活动由刺激 $s$ 的函数 $f(s)$ 建模，残差活动为 $r' = r - f(s)$，其中 $r$ 是观测到的响应。估计的残差使用通过经验风险最小化得到的 $\\hat{f}(s)$：\n$$\\hat{f} = \\arg\\min_{g \\in \\mathcal{G}} \\sum_{t=1}^{n} \\left(r_{t} - g(s_{t})\\right)^{2}，$$\n其中 $\\mathcal{G}$ 指定为 $s$ 的线性多项式或二次多项式。残差为 $r'_{t} = r_{t} - \\hat{f}(s_{t})$，CP 在 $r'$ 上计算。\n- 分箱方法将刺激轴划分为 $K$ 个分箱，并计算一个箱内CP（使用 $r$ 而不进行回归）来近似以 $s$ 为条件。总CP是跨所有分箱的加权平均：\n$$\\widehat{CP}_{\\text{bin}} = \\frac{\\sum_{k=1}^{K} n_{1k} n_{0k} \\,\\widehat{CP}_{k}}{\\sum_{k=1}^{K} n_{1k} n_{0k}}，$$\n其中 $n_{1k}$ 和 $n_{0k}$ 是在分箱 $k$ 中选择为 $y=1$ 和 $y=0$ 的试验次数，$\\widehat{CP}_{k}$ 是在分箱 $k$ 内计算的U-统计量CP。$n_{1k} = 0$ 或 $n_{0k} = 0$ 的分箱将被排除。\n- 当残差响应服从等方差、不同均值的高斯分布时，即 $r' \\mid y=1 \\sim \\mathcal{N}(\\mu_{1}, \\sigma^{2})$ 和 $r' \\mid y=0 \\sim \\mathcal{N}(\\mu_{0}, \\sigma^{2})$，真实的CP等于\n$$CP^{\\star} = \\Phi\\!\\left( \\frac{\\mu_{1} - \\mu_{0}}{\\sqrt{2}\\,\\sigma} \\right)，$$\n其中 $\\Phi(\\cdot)$ 是标准正态分布的累积分布函数。在下面的模拟中，将构造残差以满足此模型，其中 $\\mu_{0} = 0$ 且 $\\mu_{1} = m$，因此基准真相CP为 $CP^{\\star} = \\Phi\\!\\left( \\frac{m}{\\sqrt{2}\\,\\sigma} \\right)$。\n\n每个测试用例的数据生成过程：\n- 从标准正态分布 $\\mathcal{N}(0,1)$ 中抽取 $n$ 个独立的刺激 $s_{t}$。\n- 通过对带噪声的决策变量 $d_{t}$ 的确定性阈值生成选择，其中 $d_{t} = k\\,s_{t} + \\xi_{t}$，$\\xi_{t} \\sim \\mathcal{N}(0,1)$ 独立同分布，且 $y_{t} = \\mathbf{1}\\{d_{t}  0\\}$。这会在刺激和选择之间产生由 $k$ 控制的强依赖关系。\n- 生成残差活动 $r'_{t} = m\\,y_{t} + \\varepsilon_{t}$，其中 $\\varepsilon_{t} \\sim \\mathcal{N}(0, \\sigma^{2})$。这实现了选择之间均值漂移为 $m$ 的等方差高斯模型。\n- 生成观测活动 $r_{t} = f(s_{t}) + r'_{t}$，其中 $f(s) = \\gamma_{1}\\,s + \\gamma_{2}\\,s^{2}$。\n\n算法任务：\n- 通过在指定的多项式类 $\\mathcal{G}$（线性或二次）上使用普通最小二乘法拟合 $\\hat{f}(s)$，计算残差 $r'$，并通过基于秩的U-统计量计算 $\\widehat{CP}$，从而实现回归-残差CP估计器。\n- 实现基于分箱的CP估计器，在 $s$ 的范围内使用 $K$ 个等宽分箱，在每个包含两种选择的分箱内计算 $\\widehat{CP}_{k}$，并使用上述加权平均公式进行聚合。\n- 还要计算在 $r$ 上的朴素CP，不进行条件化或残差化，以显示由刺激-选择相关性引起的混杂效应。\n\n您的实现必须为每个测试用例生成以下结果：\n- 根据 $m$ 和 $\\sigma$ 使用 $CP^{\\star} = \\Phi\\!\\left( \\frac{m}{\\sqrt{2}\\,\\sigma} \\right)$ 计算的 $CP^{\\star}$。\n- 在残差 $r' = r - \\hat{f}(s)$ 上计算的 $\\widehat{CP}_{\\text{reg}}$。\n- 通过在 $r$ 上分箱计算的 $\\widehat{CP}_{\\text{bin}}$。\n- 在忽略 $s$ 的情况下，在 $r$ 上计算的 $\\widehat{CP}_{\\text{naive}}$。\n- 相对于基准真相的差异：$\\widehat{CP}_{\\text{reg}} - CP^{\\star}$、$\\widehat{CP}_{\\text{bin}} - CP^{\\star}$ 和 $\\widehat{CP}_{\\text{naive}} - CP^{\\star}$。\n\n测试套件：\n- 案例1（理想路径，模型正确，大样本）：\n    - $n = 4000$, $k = 3.0$, $m = 0.3$, $\\sigma = 1.0$, $\\gamma_{1} = 1.0$, $\\gamma_{2} = 0.0$，回归模型类 $\\mathcal{G}$ 为线性， $K = 10$，随机种子 $= 123$。\n- 案例2（模型设定错误，二次基线但线性拟合）：\n    - $n = 4000$, $k = 3.0$, $m = 0.3$, $\\sigma = 1.0$, $\\gamma_{1} = 0.0$, $\\gamma_{2} = 1.5$，回归模型类 $\\mathcal{G}$ 为线性， $K = 20$，随机种子 $= 456$。\n- 案例3（刺激间的类别不平衡，小样本，二次拟合）：\n    - $n = 800$, $k = 8.0$, $m = 0.2$, $\\sigma = 1.0$, $\\gamma_{1} = 1.0$, $\\gamma_{2} = 0.5$，回归模型类 $\\mathcal{G}$ 为二次， $K = 8$，随机种子 $= 789$。\n\n最终输出格式：\n您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表形式的结果，每个测试用例由一个包含七个十进制数的、用方括号括起来的逗号分隔列表表示，顺序如下：\n$[CP^{\\star}, \\widehat{CP}_{\\text{reg}}, \\widehat{CP}_{\\text{bin}}, \\widehat{CP}_{\\text{naive}}, \\widehat{CP}_{\\text{reg}} - CP^{\\star}, \\widehat{CP}_{\\text{bin}} - CP^{\\star}, \\widehat{CP}_{\\text{naive}} - CP^{\\star}]$。\n例如，总输出应类似于 $[[\\cdots],[\\cdots],[\\cdots]]$，不含空格。",
            "solution": "该问题要求估计选择概率 (Choice Probability, CP)，这是一个衡量神经元活动预测二元选择能力的指标，同时要考虑外部刺激的混杂影响。我们的任务是在基准真相CP已知的模拟数据上，实现并比较两种用于消除混杂影响的方法——回归-残差方法和基于分箱的方法。\n\n### 数据生成过程\n\n对于每个试验 $t=1, \\dots, n$，数据按以下过程模拟：\n1.  从标准正态分布中抽取一个刺激值 $s_t$：\n    $$s_t \\sim \\mathcal{N}(0, 1)$$\n2.  生成一个二元选择 $y_t \\in \\{0, 1\\}$。首先根据刺激加上噪声计算一个潜在决策变量 $d_t$：\n    $$d_t = k \\cdot s_t + \\xi_t, \\quad \\text{其中} \\quad \\xi_t \\sim \\mathcal{N}(0, 1)$$\n    然后通过对 $d_t$ 设置阈值来确定选择：\n    $$y_t = \\mathbf{1}\\{d_t  0\\}$$\n    参数 $k$ 控制刺激 $s_t$ 和选择 $y_t$ 之间的相关性强度。较大的 $k$ 意味着刺激更能预测选择。\n3.  神经活动被建模为刺激依赖分量和选择依赖分量的和。我们称之为“残差活动” $r'_t$ 的选择依赖分量生成如下：\n    $$r'_t = m \\cdot y_t + \\varepsilon_t, \\quad \\text{其中} \\quad \\varepsilon_t \\sim \\mathcal{N}(0, \\sigma^2)$$\n    这种构造确保了残差活动在以选择为条件时服从高斯分布：$r'_t | (y_t=0) \\sim \\mathcal{N}(0, \\sigma^2)$ 且 $r'_t | (y_t=1) \\sim \\mathcal{N}(m, \\sigma^2)$。\n4.  观测到的神经响应 $r_t$ 是残差活动与刺激依赖的基线活动 $f(s_t)$ 的和：\n    $$r_t = f(s_t) + r'_t$$\n    基线是刺激的二次函数：\n    $$f(s) = \\gamma_1 s + \\gamma_2 s^2$$\n\n### 基准真相选择概率 ($CP^{\\star}$)\n\n给定残差活动 $r'$ 的生成模型，以选择为条件的 $r'$ 的分布为 $r' \\mid y=0 \\sim \\mathcal{N}(\\mu_0, \\sigma^2)$ 和 $r' \\mid y=1 \\sim \\mathcal{N}(\\mu_1, \\sigma^2)$，其中 $\\mu_0=0$ 和 $\\mu_1=m$。理论CP是从 $y=1$ 分布中随机抽取的值大于从 $y=0$ 分布中随机抽取的值的概率。对于两个独立的高斯变量，它们的差也服从高斯分布。设 $r'_1 \\sim \\mathcal{N}(m, \\sigma^2)$ 且 $r'_0 \\sim \\mathcal{N}(0, \\sigma^2)$。它们的差 $r'_1 - r'_0$ 服从 $\\mathcal{N}(m, 2\\sigma^2)$。CP为 $\\mathbb{P}(r'_1  r'_0) = \\mathbb{P}(r'_1 - r'_0  0)$。将此变量标准化得到：\n$$CP^{\\star} = \\mathbb{P}\\left(\\frac{(r'_1 - r'_0) - m}{\\sqrt{2\\sigma^2}}  \\frac{0 - m}{\\sqrt{2\\sigma^2}}\\right) = \\mathbb{P}\\left(Z  -\\frac{m}{\\sqrt{2}\\sigma}\\right) = 1 - \\Phi\\left(-\\frac{m}{\\sqrt{2}\\sigma}\\right) = \\Phi\\left(\\frac{m}{\\sqrt{2}\\sigma}\\right)$$\n其中 $Z \\sim \\mathcal{N}(0,1)$ 且 $\\Phi(\\cdot)$ 是标准正态分布的累积分布函数 (CDF)。\n\n### 选择概率估计器\n\n我们将在模拟数据上使用三种不同的方法来计算CP。每种方法的核心计算都依赖于Mann-Whitney U-统计量，它为CP提供了一个无偏估计器。给定选择 $y=1$ 的响应样本 $\\{x_i\\}_{i=1}^{n_1}$ 和选择 $y=0$ 的响应样本 $\\{z_j\\}_{j=1}^{n_0}$，估计器为：\n$$\\widehat{CP} = \\frac{1}{n_1 n_0} \\sum_{i=1}^{n_1} \\sum_{j=1}^{n_0} \\left[ \\mathbf{1}\\{x_i  z_j\\} + \\frac{1}{2}\\mathbf{1}\\{x_i = z_j\\} \\right]$$\n这等同于ROC曲线下面积 (AUC)，并且可以使用基于秩的统计量进行高效计算。\n\n1.  **朴素估计器 ($\\widehat{CP}_{\\text{naive}}$)**：该估计器直接在观测到的神经响应 $\\{r_t\\}_{t=1}^n$ 上计算，忽略了刺激信息 $\\{s_t\\}_{t=1}^n$。因为响应 $r_t$ 和选择 $y_t$ 都受到刺激 $s_t$ 的影响，该估计器预计会有偏差，反映了刺激的混杂效应。\n\n2.  **回归-残差估计器 ($\\widehat{CP}_{\\text{reg}}$)**：该方法试图通过首先对刺激和响应之间的关系进行建模来消除刺激混杂，然后在残差上计算CP。\n    -   通过对 $r_t$ 在 $s_t$ 的多项式基上进行普通最小二乘 (OLS) 回归，获得刺激-响应函数 $\\hat{f}(s)$ 的估计。每个测试用例都指定了多项式类 $\\mathcal{G}$（线性或二次）。对于线性模型，我们拟合 $g(s) = \\beta_0 + \\beta_1 s$。对于二次模型，我们拟合 $g(s) = \\beta_0 + \\beta_1 s + \\beta_2 s^2$。通过最小化平方误差和 $\\sum_{t=1}^n (r_t - g(s_t))^2$ 来找到系数 $\\hat{\\beta}$。\n    -   然后残差计算为 $\\hat{r}'_t = r_t - \\hat{f}(s_t)$，其中 $\\hat{f}(s_t)$ 是拟合模型的预测值。\n    -   $\\widehat{CP}_{\\text{reg}}$ 是使用U-统计量估计器在残差集 $\\{\\hat{r}'_t\\}_{t=1}^n$ 和选择集 $\\{y_t\\}_{t=1}^n$ 上计算的。如果回归模型正确地捕捉了 $f(s)$ 的真实形式，该方法应能得出 $CP^{\\star}$ 的无偏估计。模型设定错误可能导致残留的混杂和有偏的估计。\n\n3.  **基于分箱的估计器 ($\\widehat{CP}_{\\text{bin}}$)**：这种非参数方法通过将刺激的范围划分为 $K$ 个离散的等宽分箱来控制刺激的影响。\n    -   将观测到的刺激范围 $[\\min(s), \\max(s)]$ 分为 $K$ 个区间。\n    -   对于每个分箱 $k=1, \\dots, K$，使用落入该分箱的试验的原始响应 $r_t$ 和U-统计量计算一个局部CP，$\\widehat{CP}_k$。\n    -   此计算仅对包含来自两种选择类别的试验的分箱执行（即，$n_{1k}  0$ 且 $n_{0k}  0$，其中 $n_{yk}$ 是分箱 $k$ 中选择为 $y$ 的试验次数）。\n    -   总体估计器 $\\widehat{CP}_{\\text{bin}}$ 是每箱CP的加权平均，权重与每箱中两种选择的样本大小的乘积成正比：\n    $$\\widehat{CP}_{\\text{bin}} = \\frac{\\sum_{k=1}^{K} n_{1k} n_{0k} \\,\\widehat{CP}_{k}}{\\sum_{k=1}^{K} n_{1k} n_{0k}}$$\n    此方法近似于以刺激为条件，并且比回归方法对 $f(s)$ 的函数形式更不敏感，但其准确性可能取决于分箱数 $K$ 和每箱中的数据量。\n\n所实现的程序将对三个不同的测试用例执行这些计算，每个测试用例都旨在探究估计器在不同条件下的性能，例如正确的模型设定、模型设定错误和小样本量。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.stats import norm, mannwhitneyu\nfrom scipy.special import erf\n\ndef solve():\n    \"\"\"\n    Main function to run the test suite and print results.\n    \"\"\"\n\n    # Manually implement norm.cdf to avoid scipy version issues,\n    # as scipy versions  1.12 might not have it as a ufunc.\n    # The definition is Phi(x) = 0.5 * (1 + erf(x/sqrt(2))).\n    def norm_cdf(x):\n        return 0.5 * (1.0 + erf(x / np.sqrt(2.0)))\n\n    def compute_cp(responses, choices):\n        \"\"\"\n        Computes Choice Probability using the Mann-Whitney U statistic.\n        \n        Args:\n            responses (np.array): Neural responses.\n            choices (np.array): Binary choices (0 or 1).\n            \n        Returns:\n            float: The estimated Choice Probability (AUC).\n        \"\"\"\n        r1 = responses[choices == 1]\n        r0 = responses[choices == 0]\n        n1, n0 = len(r1), len(r0)\n        \n        if n1 == 0 or n0 == 0:\n            return np.nan\n        \n        # mannwhitneyu calculates U for r1  r0, including ties.\n        # CP = U / (n1 * n0)\n        u_statistic, _ = mannwhitneyu(r1, r0, alternative='greater')\n        return u_statistic / (n1 * n0)\n\n    def run_case(n, k, m, sigma, gamma1, gamma2, reg_model_type, K, seed):\n        \"\"\"\n        Runs one full simulation and analysis case.\n        \"\"\"\n        rng = np.random.default_rng(seed)\n\n        # 1. Data Generation\n        s = rng.normal(loc=0, scale=1, size=n)\n        xi = rng.normal(loc=0, scale=1, size=n)\n        d = k * s + xi\n        y = (d  0).astype(int)\n        \n        epsilon = rng.normal(loc=0, scale=sigma, size=n)\n        r_prime = m * y + epsilon\n        \n        f_s = gamma1 * s + gamma2 * s**2\n        r = f_s + r_prime\n\n        # 2. Calculate ground truth CP\n        cp_star = norm_cdf(m / (np.sqrt(2) * sigma))\n\n        # 3. Calculate Naive CP\n        cp_naive = compute_cp(r, y)\n\n        # 4. Calculate Regression-Residual CP\n        if reg_model_type == 'linear':\n            # Design matrix for g(s) = beta_0 + beta_1*s\n            X = np.vstack([np.ones(n), s]).T\n        elif reg_model_type == 'quadratic':\n            # Design matrix for g(s) = beta_0 + beta_1*s + beta_2*s^2\n            X = np.vstack([np.ones(n), s, s**2]).T\n        else:\n            raise ValueError(\"Invalid regression model type\")\n\n        coeffs, _, _, _ = np.linalg.lstsq(X, r, rcond=None)\n        f_hat = X @ coeffs\n        r_residuals = r - f_hat\n        cp_reg = compute_cp(r_residuals, y)\n\n        # 5. Calculate Binning-Based CP\n        s_min, s_max = np.min(s), np.max(s)\n        # Add small epsilon to include the max value in the last bin\n        bin_edges = np.linspace(s_min, s_max + 1e-9, K + 1)\n        \n        s_bin_indices = np.digitize(s, bin_edges)\n\n        cp_bin_num = 0.0\n        cp_bin_den = 0.0\n\n        for i in range(1, K + 1):\n            bin_mask = (s_bin_indices == i)\n            if not np.any(bin_mask):\n                continue\n\n            r_bin = r[bin_mask]\n            y_bin = y[bin_mask]\n\n            n1k = np.sum(y_bin == 1)\n            n0k = np.sum(y_bin == 0)\n\n            if n1k  0 and n0k  0:\n                cp_k = compute_cp(r_bin, y_bin)\n                weight = n1k * n0k\n                cp_bin_num += weight * cp_k\n                cp_bin_den += weight\n        \n        cp_bin = cp_bin_num / cp_bin_den if cp_bin_den  0 else np.nan\n\n        # 6. Calculate differences\n        diff_reg = cp_reg - cp_star\n        diff_bin = cp_bin - cp_star\n        diff_naive = cp_naive - cp_star\n\n        return [cp_star, cp_reg, cp_bin, cp_naive, diff_reg, diff_bin, diff_naive]\n\n    test_cases = [\n        # Case 1 (happy path, correct model, large sample)\n        {'n': 4000, 'k': 3.0, 'm': 0.3, 'sigma': 1.0, 'gamma1': 1.0, 'gamma2': 0.0, 'reg_model_type': 'linear', 'K': 10, 'seed': 123},\n        # Case 2 (model mis-specification, quadratic baseline but linear fit)\n        {'n': 4000, 'k': 3.0, 'm': 0.3, 'sigma': 1.0, 'gamma1': 0.0, 'gamma2': 1.5, 'reg_model_type': 'linear', 'K': 20, 'seed': 456},\n        # Case 3 (class imbalance across stimulus, small sample, quadratic fit)\n        {'n': 800, 'k': 8.0, 'm': 0.2, 'sigma': 1.0, 'gamma1': 1.0, 'gamma2': 0.5, 'reg_model_type': 'quadratic', 'K': 8, 'seed': 789},\n    ]\n\n    all_results = []\n    for case_params in test_cases:\n        results = run_case(**case_params)\n        all_results.append(results)\n    \n    # Format the final output string\n    # e.g., [[val1,val2,...],[val1,val2,...],[val1,val2,...]]\n    case_strings = []\n    for case_result in all_results:\n        # Each number is converted to a string using default float formatting\n        case_strings.append(f\"[{','.join(map(str, case_result))}]\")\n    \n    final_output = f\"[{','.join(case_strings)}]\"\n    print(final_output)\n\nsolve()\n```"
        }
    ]
}