{
    "hands_on_practices": [
        {
            "introduction": "在为神经数据构建编码模型时，我们常常面临一个关键抉择：如何在模型的复杂性与拟合优度之间取得平衡。一个更复杂的模型（参数更多）几乎总能更好地拟合训练数据，但这可能导致过拟合，使其泛化到新数据上的能力变差。此练习将引导您应用两种广泛使用的信息准则——赤池信息准则（Akaike Information Criterion, AIC）和贝叶斯信息准则（Bayesian Information Criterion, BIC），来量化地比较不同复杂度的模型，这两种方法都通过惩罚模型参数的数量来应对过拟合的风险。",
            "id": "4159626",
            "problem": "记录了单个皮层神经元在 $n=1200$ 次独立刺激呈现中的放电计数。两个竞争性的编码模型，均为泊松广义线性模型 (GLM)，通过最大似然法对同一数据集进行了拟合。模型 $1$ 使用了 $k_1=10$ 个参数（包括一个截距和 $9$ 个刺激特征权重）。模型 $2$ 使用了 $k_2=30$ 个参数（包括一个截距、$9$ 个特征权重和 $20$ 个时间基函数权重）。拟合软件报告的训练数据上的最大对数似然（自然对数）为：模型 $1$ 为 $\\ln L_1=-5600.5$，模型 $2$ 为 $\\ln L_2=-5550.5$。\n\n根据最大似然理论中赤池信息准则 (AIC) 和贝叶斯信息准则 (BIC) 的定义，计算每个模型的 AIC 和 BIC，并确定每个准则偏好的模型。明确说明这两个准则在偏好模型上是否一致。将所有信息准则值四舍五入至四位有效数字。将最终答案表示为行向量 $\\left(\\text{AIC}_{1},\\ \\text{AIC}_{2},\\ \\text{BIC}_{1},\\ \\text{BIC}_{2},\\ m_{\\text{AIC}},\\ m_{\\text{BIC}}\\right)$，其中 $m_{\\text{AIC}}$ 和 $m_{\\text{BIC}}$ 分别是 AIC 和 BIC 准则下偏好模型的索引（$1$ 或 $2$）。无需单位。",
            "solution": "在尝试任何解答之前，对问题进行验证。\n\n### 第 1 步：提取已知条件\n- 独立刺激呈现次数（数据点数）：$n=1200$。\n- 模型 1 是一个泊松 GLM，有 $k_1=10$ 个参数。\n- 模型 2 是一个泊松 GLM，有 $k_2=30$ 个参数。\n- 模型 1 的最大对数似然：$\\ln L_1 = -5600.5$。\n- 模型 2 的最大对数似然：$\\ln L_2 = -5550.5$。\n- 任务是计算两个模型的赤池信息准则 (AIC) 和贝叶斯信息准则 (BIC)。\n- 必须确定每个准则偏好的模型。\n- 最终的 AIC 和 BIC 值必须四舍五入到四位有效数字。\n\n### 第 2 步：使用提取的已知条件进行验证\n该问题具有科学依据，使用了计算神经科学中常见的标准统计方法（泊松 GLM、最大似然、AIC、BIC）。所提供的值对于此类分析是符合实际的。该问题是适定的，提供了计算所需量所需的所有必要信息（$n$、$k_1$、$k_2$、$\\ln L_1$、$\\ln L_2$）。语言客观、精确。问题是自洽的、一致的，并且没有违反任何指定的无效性标准。\n\n### 第 3 步：结论与行动\n问题有效。将提供完整的解答。\n\n该问题要求为两个竞争的统计模型计算赤池信息准则 (AIC) 和贝叶斯信息准则 (BIC)。对于给定的准则，值较低的模型被认为是更优的。\n\nAIC 的定义是：\n$$\n\\text{AIC} = 2k - 2\\ln L\n$$\n其中 $k$ 是模型中估计参数的数量，$\\ln L$ 是对数似然函数的最大值。\n\n对于模型 $1$，我们有 $k_1=10$ 和 $\\ln L_1 = -5600.5$。其 AIC 为：\n$$\n\\text{AIC}_1 = 2k_1 - 2\\ln L_1 = 2(10) - 2(-5600.5) = 20 + 11201 = 11221\n$$\n四舍五入到四位有效数字，得到 $\\text{AIC}_1 \\approx 11220$。\n\n对于模型 $2$，我们有 $k_2=30$ 和 $\\ln L_2 = -5550.5$。其 AIC 为：\n$$\n\\text{AIC}_2 = 2k_2 - 2\\ln L_2 = 2(30) - 2(-5550.5) = 60 + 11101 = 11161\n$$\n四舍五入到四位有效数字，得到 $\\text{AIC}_2 \\approx 11160$。\n\n为了确定 AIC 偏好的模型，我们比较它们各自的 AIC 值。AIC 值较低的模型更受偏好。\n$$\n\\text{AIC}_2 = 11161  11221 = \\text{AIC}_1\n$$\n因此，赤池信息准则偏好模型 $2$。偏好模型的索引是 $m_{\\text{AIC}} = 2$。\n\nBIC 的定义是：\n$$\n\\text{BIC} = k\\ln(n) - 2\\ln L\n$$\n其中 $k$ 是参数数量，$n$ 是数据点数量，$\\ln L$ 是最大对数似然。\n\n对于这个问题，$n=1200$。我们首先计算 $\\ln(n)$：\n$$\n\\ln(1200) \\approx 7.0900755\n$$\n\n对于模型 $1$，$k_1=10$ 且 $\\ln L_1 = -5600.5$，其 BIC 为：\n$$\n\\text{BIC}_1 = k_1\\ln(n) - 2\\ln L_1 = 10 \\times \\ln(1200) - 2(-5600.5) \\approx 10(7.0900755) + 11201 \\approx 70.900755 + 11201 = 11271.900755\n$$\n四舍五入到四位有效数字，得到 $\\text{BIC}_1 \\approx 11270$。\n\n对于模型 $2$，$k_2=30$ 且 $\\ln L_2 = -5550.5$，其 BIC 为：\n$$\n\\text{BIC}_2 = k_2\\ln(n) - 2\\ln L_2 = 30 \\times \\ln(1200) - 2(-5550.5) \\approx 30(7.0900755) + 11101 \\approx 212.702265 + 11101 = 11313.702265\n$$\n四舍五入到四位有效数字，得到 $\\text{BIC}_2 \\approx 11310$。\n\n为了确定 BIC 偏好的模型，我们比较它们各自的 BIC 值。\n$$\n\\text{BIC}_1 \\approx 11271.9  11313.7 \\approx \\text{BIC}_2\n$$\n因此，贝叶斯信息准则偏好模型 $1$。偏好模型的索引是 $m_{\\text{BIC}} = 1$。\n\n总结如下：\n- AIC 偏好模型 $2$（索引 $2$）。\n- BIC 偏好模型 $1$（索引 $1$）。\n\n这两个准则在偏好模型上不一致。这种不一致性源于 AIC ($2k$) 和 BIC ($k\\ln(n)$) 对模型复杂度的惩罚项不同。对于 $n=1200$，$\\ln(n) \\approx 7.09$，大于 $2$。因此，BIC 对额外参数的惩罚比 AIC 强得多。虽然模型 $2$ 对数据的拟合更好（更高的对数似然），但其增加的复杂度（$k_2=30$ vs $k_1=10$）被 BIC 施以重罚，以至于最终更简单的模型 $1$ 更受青睐。AIC 较弱的惩罚使得模型 $2$ 更好的拟合度超过了其复杂度的影响。\n\n最终答案是由计算值组成的行向量：$(\\text{AIC}_{1}, \\text{AIC}_{2}, \\text{BIC}_{1}, \\text{BIC}_{2}, m_{\\text{AIC}}, m_{\\text{BIC}})$。\n$\\text{AIC}_1 \\approx 11220$\n$\\text{AIC}_2 \\approx 11160$\n$\\text{BIC}_1 \\approx 11270$\n$\\text{BIC}_2 \\approx 11310$\n$m_{\\text{AIC}} = 2$\n$m_{\\text{BIC}} = 1$",
            "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n11220  11160  11270  11310  2  1\n\\end{pmatrix}\n}\n$$"
        },
        {
            "introduction": "评估一个神经编码模型是否准确捕捉了神经元的放电动态，是模型构建过程中的核心环节。对于点过程模型（如用于描述神经元发放的模型），时间重整化定理（time-rescaling theorem）提供了一种强大且优雅的拟合优度检验方法。该练习旨在通过编写代码，将这一重要的理论概念转化为一个可执行的算法，从而让您亲手实现一个完整的模型检验流程：从生成模拟数据，到应用时间重整化变换，再到执行统计检验。",
            "id": "4159588",
            "problem": "给定一个由条件强度函数 $\\hat{\\lambda}(t)$ 指定的点过程编码模型，该模型旨在描述神经元在给定其过去历史的情况下的瞬时发放倾向。其基础是具有条件强度 $\\lambda(t \\mid \\mathcal{H}_t)$ 的点过程的生存特性：在区间 $\\left[t, t+\\Delta\\right]$ 内没有事件的概率为\n$$\nS(\\Delta \\mid \\mathcal{H}_t) = \\exp\\left(-\\int_{t}^{t+\\Delta} \\lambda(s \\mid \\mathcal{H}_s)\\, ds\\right).\n$$\n以此为基础，可以推导出一个时间重标度变换，将事件间间隔映射到单位区间上的随机变量。对于模型检验，如果模型指定正确，使用拟合的条件强度 $\\hat{\\lambda}(t)$ 计算出的重标度变量应在 $\\left[0,1\\right]$ 上均匀分布。均匀性可以使用 Kolmogorov–Smirnov 检验（Kolmogorov–Smirnov (KS)）与 $\\left[0,1\\right]$ 上的均匀分布进行比较来评估。\n\n您的任务是实现一个程序，该程序：\n- 根据指定的目标重标度变量序列 $\\{u_i^{\\star}\\}_{i=1}^n$，通过求解使积分真实强度 $\\lambda_{\\text{true}}(t)$ 满足 $\\int_{t_{i-1}}^{t_i} \\lambda_{\\text{true}}(s)\\, ds = m_i$ 的间隔 $\\Delta_i$ 来构建确定性事件时间 $\\{t_i\\}_{i=1}^n$（单位：秒），其中 $m_i = -\\log\\left(1 - u_i^{\\star}\\right)$ 且 $t_0 = 0$ 秒。这确保了当使用 $\\lambda_{\\text{true}}(t)$ 进行评估时，推导出的重标度变量与给定的目标 $\\{u_i^{\\star}\\}$ 相匹配。\n- 对于相同的事件时间，使用拟合强度 $\\hat{\\lambda}(t)$，通过对 $\\int_{t_{i-1}}^{t_i} \\hat{\\lambda}(s)\\, ds$ 进行数值积分和上述生存特性所隐含的变换，来计算重标度变量 $\\{u_i\\}_{i=1}^n$。\n- 对每个测试用例的 $\\{u_i\\}_{i=1}^n$ 执行 Kolmogorov–Smirnov 均匀性检验。\n\n所有时间都必须以秒为单位处理。不涉及角度。最终输出必须是实值小数。\n\n实现数值求积来评估任意给定强度函数的 $\\int_{a}^{b} \\lambda(s)\\, ds$。实现一个稳健的一维求根程序，为每个间隔求解 $\\int_{t_{i-1}}^{t_{i-1}+\\Delta_i} \\lambda_{\\text{true}}(s)\\, ds = m_i$ 以得到 $\\Delta_i  0$。\n\n使用以下参数值的测试套件，旨在探测正确性（匹配模型）、误设（不匹配）、分段强度的边界穿越以及小样本边缘行为。在每种情况下，设置 $t_0 = 0$ 秒并定义 $u_i^{\\star} = i/(n+1)$，其中 $i \\in \\{1,\\dots,n\\}$。\n\n- 测试用例 1（匹配的恒定强度，理想情况）：\n  - $n = 20$，$\\lambda_{\\text{true}}(t) = 12$（事件/秒），$\\hat{\\lambda}(t) = 12$（事件/秒）。\n- 测试用例 2（不匹配的恒定强度，模型误设）：\n  - $n = 20$，$\\lambda_{\\text{true}}(t) = 6$（事件/秒），$\\hat{\\lambda}(t) = 12$（事件/秒）。\n- 测试用例 3（匹配的带边界穿越的分段恒定强度）：\n  - $n = 25$，当 $t  5$（秒）时，$\\lambda_{\\text{true}}(t) = 8$（事件/秒），当 $t \\ge 5$（秒）时，$\\lambda_{\\text{true}}(t) = 16$（事件/秒）；$\\hat{\\lambda}(t)$ 等于 $\\lambda_{\\text{true}}(t)$。\n- 测试用例 4（不匹配的小样本边缘情况）：\n  - $n = 5$，$\\lambda_{\\text{true}}(t) = 12$（事件/秒），当 $t  5$（秒）时，$\\hat{\\lambda}(t) = 8$（事件/秒），当 $t \\ge 5$（秒）时，$\\hat{\\lambda}(t) = 16$（事件/秒）。\n\n您的程序应在每个测试用例中对 $\\left[0,1\\right]$ 上的均匀分布执行 Kolmogorov–Smirnov 检验，并按顺序为每个测试用例输出两个数字：KS 检验统计量及其 p 值，两者均四舍五入到六位小数。您的程序应生成一行输出，其中包含一个用方括号括起来的逗号分隔列表的结果，例如 $\\left[\\text{stat}_1,\\text{pval}_1,\\text{stat}_2,\\text{pval}_2,\\dots\\right]$。",
            "solution": "该问题要求基于时间重标度定理，为点过程编码模型实施一个拟合优度检验。该过程包括两个主要阶段：首先，从一个已知的“真实”条件强度函数 $\\lambda_{\\text{true}}(t)$ 生成一个合成的事件时间序列；其次，使用一个候选或“拟合”模型 $\\hat{\\lambda}(t)$ 分析这些事件时间，以确定拟合模型是否充分描述了数据。\n\n该程序的理论基础是时间重标度定理。对于一个由条件强度函数 $\\lambda(t \\mid \\mathcal{H}_t)$ 表征的点过程，该函数给出在时间 $t$ 之前事件历史为 $\\mathcal{H}_t$ 的情况下，在时间 $t$ 发生一个事件的瞬时概率，该定理指出，变换后的事件间间隔\n$$\n\\tau_i = \\int_{t_{i-1}}^{t_i} \\lambda(s \\mid \\mathcal{H}_s) \\, ds\n$$\n是独立同分布 (i.i.d.) 的，服从率参数 $\\lambda=1$ 的指数随机变量。在本问题中，强度函数是时间的确定性函数，因此我们将其写为 $\\lambda(t)$。\n\n通过对这些重标度的间隔应用标准指数分布的累积分布函数 (CDF) $F(x) = 1 - e^{-x}$，我们可以获得一组新的变量：\n$$\nu_i = F(\\tau_i) = 1 - \\exp\\left(-\\int_{t_{i-1}}^{t_i} \\lambda(s) \\, ds\\right)\n$$\n如果在积分中使用的函数 $\\lambda(t)$ 是真实的数据生成强度，那么得到的变量 $\\{u_i\\}$ 将是 i.i.d. 且在区间 $[0, 1]$ 上均匀分布。这一特性构成了我们拟合优度检验的基础。我们将使用单样本 Kolmogorov-Smirnov (KS) 检验来评估计算出的 $\\{u_i\\}$ 的均匀性。\n\n总体方法实现如下：\n\n**步骤 1：生成合成事件时间**\n我们的任务是从给定的真实强度函数 $\\lambda_{\\text{true}}(t)$ 和一个指定的目标均匀变量序列 $\\{u_i^{\\star}\\}_{i=1}^n$ 中，构建一个确定性的事件时间序列 $\\{t_i\\}_{i=1}^n$。目标变量被设置为均匀分布的分位数，$u_i^{\\star} = i/(n+1)$，其中 $i \\in \\{1, \\dots, n\\}$。\n\n首先，我们对 CDF 变换求逆，以找到来自标准指数分布的相应值，这些值记为 $m_i$：\n$$\nm_i = F^{-1}(u_i^{\\star}) = -\\log(1 - u_i^{\\star})\n$$\n这些 $m_i$ 值代表每个事件间间隔的目标积分强度。然后，通过从 $t_0 = 0$ 开始迭代求解积分方程来确定事件时间 $\\{t_i\\}$：\n$$\n\\int_{t_{i-1}}^{t_i} \\lambda_{\\text{true}}(s) \\, ds = m_i\n$$\n这等同于求解从原点开始的总积分强度。设 $F_{\\text{true}}(t) = \\int_0^t \\lambda_{\\text{true}}(s) \\, ds$ 为累积强度函数。第 $i$ 个事件时间 $t_i$ 必须满足：\n$$\nF_{\\text{true}}(t_i) = F_{\\text{true}}(t_{i-1}) + m_i = \\sum_{j=1}^{i} m_j\n$$\n然后，通过应用累积强度函数的反函数来找到事件时间 $t_i$：\n$$\nt_i = F_{\\text{true}}^{-1}\\left(\\sum_{j=1}^{i} m_j\\right)\n$$\n对于问题中指定的恒定和分段恒定强度函数，可以解析地推导出累积强度函数 $F_{\\text{true}}(t)$ 及其反函数 $F_{\\text{true}}^{-1}(y)$。\n- 对于恒定强度 $\\lambda_{\\text{true}}(t) = c$，$F_{\\text{true}}(t) = ct$，其反函数为 $F_{\\text{true}}^{-1}(y) = y/c$。\n- 对于分段恒定强度，$F_{\\text{true}}(t)$ 是一个连续的分段线性函数，其反函数可以很容易地计算出来。这种解析方法比数值求根更精确且计算效率更高。\n\n**步骤 2：计算重标度间隔和模型评估**\n使用步骤 1 中生成的事件时间 $\\{t_i\\}$，我们现在评估候选模型 $\\hat{\\lambda}(t)$。对于每个事件间间隔 $[t_{i-1}, t_i]$，我们根据候选模型计算积分强度：\n$$\nM_i = \\int_{t_{i-1}}^{t_i} \\hat{\\lambda}(s) \\, ds\n$$\n这可以计算为 $M_i = \\hat{F}(t_i) - \\hat{F}(t_{i-1})$，其中 $\\hat{F}(t) = \\int_0^t \\hat{\\lambda}(s) \\, ds$ 是候选模型的累积强度函数。和之前一样，对于给定的测试用例，$\\hat{F}(t)$ 是解析确定的。\n\n然后，我们将这些积分强度转换为一个假定为均匀分布的变量样本 $\\{u_i\\}_{i=1}^n$：\n$$\nu_i = 1 - \\exp(-M_i)\n$$\n如果 $\\hat{\\lambda}(t)$ 是生成事件时间的过程的正确表示（即，如果 $\\hat{\\lambda}(t) = \\lambda_{\\text{true}}(t)$），则样本 $\\{u_i\\}$ 应在 $[0,1]$ 上均匀分布。\n\n**步骤 3：统计检验**\n最后一步是对计算出的样本 $\\{u_i\\}$ 与 $[0,1]$ 上的标准均匀分布进行单样本 Kolmogorov-Smirnov 检验。KS 检验得出一个统计量 $D_n$，即样本的经验 CDF 与理论均匀 CDF 之间的最大绝对差，以及一个 p 值。大的 p 值（例如，$p  0.05$）表示我们不能拒绝样本来自均匀分布的原假设，这表明模型 $\\hat{\\lambda}(t)$ 是一个很好的拟合。小的 p 值表明模型存在误设。为每个测试用例报告 KS 统计量和 p 值。",
            "answer": "```python\nimport numpy as np\nfrom scipy.stats import kstest\n\ndef solve():\n    \"\"\"\n    Main function to execute all test cases and print the results.\n    \"\"\"\n\n    def get_cumulative_integral_func_piecewise_const(pieces_desc):\n        \"\"\"\n        Creates a function F(t) that analytically computes the integral of a \n        piecewise-constant function from 0 to t.\n\n        Args:\n            pieces_desc: A list of (value, end_time) tuples, e.g., [(8, 5.0), (16, np.inf)].\n\n        Returns:\n            A vectorized function F(t).\n        \"\"\"\n        boundaries = [0.0]\n        cum_integrals_at_boundaries = [0.0]\n        last_t = 0.0\n        \n        for val, end_t in pieces_desc:\n            if np.isinf(end_t):\n                break\n            integral_of_piece = val * (end_t - last_t)\n            boundaries.append(end_t)\n            cum_integrals_at_boundaries.append(cum_integrals_at_boundaries[-1] + integral_of_piece)\n            last_t = end_t\n        \n        boundaries = np.array(boundaries)\n        cum_integrals_at_boundaries = np.array(cum_integrals_at_boundaries)\n        rates = np.array([p[0] for p in pieces_desc])\n\n        def F(t):\n            t_arr = np.atleast_1d(t)\n            results = np.zeros_like(t_arr, dtype=float)\n            \n            # Find which segment each t is in\n            indices = np.searchsorted(boundaries, t_arr, side='right') - 1\n            \n            boundary_t = boundaries[indices]\n            cum_integral_at_boundary = cum_integrals_at_boundaries[indices]\n            rate_for_segment = rates[indices]\n            \n            results = cum_integral_at_boundary + rate_for_segment * (t_arr - boundary_t)\n            results[t_arr == 0] = 0.0\n            \n            return results if np.ndim(t)  0 else results[0]\n\n        return F\n\n    def get_inverse_cumulative_integral_func_piecewise_const(pieces_desc):\n        \"\"\"\n        Creates a function F_inv(y) that analytically computes t such that F(t)=y.\n\n        Args:\n            pieces_desc: A list of (value, end_time) tuples.\n        \n        Returns:\n            A vectorized function F_inv(y).\n        \"\"\"\n        boundaries = [0.0]\n        cum_integrals_at_boundaries = [0.0]\n        last_t = 0.0\n\n        for val, end_t in pieces_desc:\n            if np.isinf(end_t):\n                break\n            if val == 0:\n                raise ValueError(\"Intensity rates must be positive.\")\n            integral_of_piece = val * (end_t - last_t)\n            boundaries.append(end_t)\n            cum_integrals_at_boundaries.append(cum_integrals_at_boundaries[-1] + integral_of_piece)\n            last_t = end_t\n        \n        boundaries = np.array(boundaries)\n        cum_integrals_at_boundaries = np.array(cum_integrals_at_boundaries)\n        rates = np.array([p[0] for p in pieces_desc])\n\n        def F_inv(y):\n            y_arr = np.atleast_1d(y)\n            results = np.zeros_like(y_arr, dtype=float)\n            \n            # Find which integral value segment y is in\n            indices = np.searchsorted(cum_integrals_at_boundaries, y_arr, side='right') - 1\n            \n            boundary_t = boundaries[indices]\n            cum_integral_at_boundary = cum_integrals_at_boundaries[indices]\n            rate_for_segment = rates[indices]\n            \n            results = boundary_t + (y_arr - cum_integral_at_boundary) / rate_for_segment\n            results[y_arr == 0] = 0.0\n\n            return results if np.ndim(y)  0 else results[0]\n\n        return F_inv\n\n    def process_case(n, lambda_true_desc, lambda_hat_desc, t0=0.0):\n        # Step 1: Generate event times from lambda_true\n        u_stars = (np.arange(1, n + 1)) / (n + 1.0)\n        m_values = -np.log(1.0 - u_stars)\n        \n        event_times = np.zeros(n + 1)\n        event_times[0] = t0\n\n        if isinstance(lambda_true_desc, (int, float)):\n            # Constant intensity case\n            rate = float(lambda_true_desc)\n            if rate == 0: raise ValueError(\"Intensity must be positive.\")\n            deltas = m_values / rate\n            event_times[1:] = t0 + np.cumsum(deltas)\n        else:\n            # Piecewise constant intensity case\n            F_true_inv = get_inverse_cumulative_integral_func_piecewise_const(lambda_true_desc)\n            F_true_t0 = get_cumulative_integral_func_piecewise_const(lambda_true_desc)(t0)\n            cumulative_m = F_true_t0 + np.cumsum(m_values)\n            event_times[1:] = F_true_inv(cumulative_m)\n\n        # Step 2: Compute rescaled intervals using lambda_hat\n        if isinstance(lambda_hat_desc, (int, float)):\n            # Constant intensity case\n            rate = float(lambda_hat_desc)\n            deltas = np.diff(event_times)\n            M_values = rate * deltas\n        else:\n            # Piecewise constant intensity case\n            F_hat = get_cumulative_integral_func_piecewise_const(lambda_hat_desc)\n            F_hat_t_values = F_hat(event_times)\n            M_values = np.diff(F_hat_t_values)\n\n        u_computed = 1.0 - np.exp(-M_values)\n        \n        # Step 3: Perform Kolmogorov-Smirnov test\n        ks_stat, p_val = kstest(u_computed, 'uniform')\n        \n        return ks_stat, p_val\n\n    test_cases = [\n        # n, lambda_true, lambda_hat\n        (20, 12.0, 12.0),\n        (20, 6.0, 12.0),\n        (25, [(8.0, 5.0), (16.0, np.inf)], [(8.0, 5.0), (16.0, np.inf)]),\n        (5, 12.0, [(8.0, 5.0), (16.0, np.inf)]),\n    ]\n\n    all_results = []\n    for n, l_true, l_hat in test_cases:\n        stat, pval = process_case(n, l_true, l_hat)\n        all_results.extend([f\"{stat:.6f}\", f\"{pval:.6f}\"])\n\n    print(f\"[{','.join(all_results)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "在执行了如时间重整化定理这样的拟合优度检验后，我们得到的不仅仅是一个p值，还有一个信息丰富的诊断图，例如柯尔莫哥洛夫-斯米尔诺夫（Kolmogorov-Smirnov, KS）图。解读这些诊断图以诊断模型具体缺陷的能力，是区分新手与专家级数据分析师的关键。此练习将训练您识别KS图中的特定偏离模式，并将这些视觉特征与模型在神经生理学层面上的具体失配联系起来，例如未能模拟不应期或数据中存在过度离散。",
            "id": "4159628",
            "problem": "您使用广义线性模型（GLM）为单个神经元拟合了一个点过程编码模型，其中拟合的条件强度表示为 $\\hat{\\lambda}(t \\mid H_t, x(t))$，这里 $H_t$ 是脉冲历史，$x(t)$ 是刺激。为了评估拟合优度，您应用了时间重标度定理，并通过将每个脉冲间隔转换为一个重标度变量来构建柯尔莫哥洛夫-斯米尔诺夫（KS）图，该变量的经验累积分布函数（CDF）与$\\text{Uniform}(0,1)$分布的CDF进行比较。在一个正确指定的模型下，KS图应该与从$(0,0)$到$(1,1)$的对角参考线对齐，只存在采样变异性。\n\n考虑在匹配的刺激条件下记录的不同细胞的此类KS图中观察到的两种系统性偏差模式：\n- 模式 $\\mathcal{A}$：对于大多数 $u \\in (0,1)$，经验CDF位于对角线下方，并呈上凹形状（即斜率随 $u$ 增大而增大），仅在 $u \\approx 1$ 附近接近对角线。\n- 模式 $\\mathcal{B}$：经验CDF相对于对角线呈S形：对于小的 $u$，它在对角线上方；在中间的 $u$ 处，它下降到对角线下方；在 $u \\approx 1$ 附近再次上升到对角线上方。\n\n假设刺激协变量 $x(t)$ 已被很好地捕捉，并且潜在拟合不佳的主要来源是 (i) 缺失了短时间尺度的脉冲历史结构，如不应期，以及 (ii) 未观测到的导致脉冲发放相对于条件泊松GLM产生过度离散的慢速增益波动。\n\n下列哪种解释最符合时间重标度变换和点过程柯尔莫哥洛夫-斯米尔诺夫（KS）检验的基本原理性质？\n\nA. 模式 $\\mathcal{A}$ 表明存在未建模的不应期，这抑制了脉冲后瞬间的真实条件强度（相对于 $\\hat{\\lambda}(t \\mid H_t, x(t))$），而模式 $\\mathcal{B}$ 表明由潜变量速率波动（随机增益）驱动的过度离散，导致相对于 $\\text{Uniform}(0,1)$ 分布，小的和大的重标度值都出现了过量。\n\nB. 模式 $\\mathcal{A}$ 表明存在未建模的不应期，而模式 $\\mathcal{B}$ 表明由于脉冲间隔过于规律（这是gamma形状参数大于1的更新过程的特征）而导致的低度离散。\n\nC. 模式 $\\mathcal{A}$ 表明模型平均低估了基线发放率，而模式 $\\mathcal{B}$ 表明模型缺失了绝对不应期，这产生了太多非常短的重标度值。\n\nD. 模式 $\\mathcal{A}$ 表明由潜变量速率波动引起的过度离散，而模式 $\\mathcal{B}$ 表明脉冲历史项过强，产生了低度离散和极端重标度值的缺失。",
            "solution": "### 问题验证\n\n问题陈述在科学上是合理的、提法得当且客观的。它描述了计算神经科学中点过程模型（特别是广义线性模型或GLM）的一种标准拟合优度评估方法，即时间重标度方法及随后的柯尔莫哥洛夫-斯米尔诺夫（KS）图。所描述的现象（不应期、由潜变量增益波动引起的过度离散）以及由此产生的KS图模式是这种情况下模型拟合不佳的典型例子。问题设定是自洽的，并为进行严谨、基于原理的推导提供了充分信息。所有术语在该领域内都是标准且定义明确的。因此，该问题是有效的。\n\n### 基于原理的推导\n\n该分析基于点过程的时间重标度定理。设脉冲时间序列为 $\\{t_i\\}$，真实条件强度函数为 $\\lambda(t \\mid H_t, x(t))$。拟合模型提供了该强度的估计值 $\\hat{\\lambda}(t \\mid H_t, x(t))$。该定理指出，如果模型是正确的（即，对于所有 $t$，$\\hat{\\lambda}(t) = \\lambda(t)$），那么重标度的脉冲间隔（ISIs）\n$$ \\Delta_i = \\int_{t_{i-1}}^{t_i} \\hat{\\lambda}(\\tau \\mid H_\\tau, x(\\tau)) \\, d\\tau $$\n是从标准指数分布 $\\text{Exponential}(1)$ 中抽取的独立同分布的随机变量。\n\nKS图是通过进一步的变换构建的。如果 $\\Delta_i \\sim \\text{Exponential}(1)$，那么变量 $u_i = 1 - \\exp(-\\Delta_i)$ 是来自 $\\text{Uniform}(0,1)$ 分布的独立同分布变量。这是概率积分变换的一个应用。KS图将观测到的 $\\{u_i\\}$ 的经验累积分布函数（CDF），记为 $\\hat{F}_U(u)$，与 $\\text{Uniform}(0,1)$ 分布的CDF（即从 $(0,0)$ 到 $(1,1)$ 的对角线 $F_U(u) = u$）进行比较。与这条对角线的偏差表明了特定类型的模型设定错误。\n\n让我们分析模型错配与重标度间隔 $\\Delta_i$ 之间的关系：\n- 如果模型的速率 $\\hat{\\lambda}(t)$ 在一个脉冲间隔（ISI）内系统性地高估了真实速率 $\\lambda(t)$，那么得到的 $\\Delta_i$ 将在随机意义上大于一个 $\\text{Exponential}(1)$ 变量。\n- 如果 $\\hat{\\lambda}(t)$ 系统性地低估了 $\\lambda(t)$，那么得到的 $\\Delta_i$ 将在随机意义上小于一个 $\\text{Exponential}(1)$ 变量。\n\n现在我们分析给定的模式。\n\n**模式 $\\mathcal{A}$ 的分析：** 经验CDF $\\hat{F}_U(u)$ 在大多数 $u \\in (0,1)$ 上位于对角线下方。\n这意味着 $\\hat{F}_U(u)  u$。由于 $\\hat{F}_U(u) \\approx F_{\\hat{\\Delta}}(-\\ln(1-u))$，其中 $F_{\\hat{\\Delta}}$ 是 $\\{\\Delta_i\\}$ 的CDF，这意味着 $F_{\\hat{\\Delta}}(-\\ln(1-u))  u$。代入 $x = -\\ln(1-u)$ 得到 $F_{\\hat{\\Delta}}(x)  1-e^{-x}$，这是 $\\text{Exponential}(1)$ 分布的CDF。一个向右平移的CDF（即小于参考CDF）对应于一个值在随机意义上更大的分布。这意味着重标度间隔 $\\{\\Delta_i\\}$ 系统性地过大。\n\n这种情况发生在模型速率 $\\hat{\\lambda}(t)$ 平均而言高估了真实速率 $\\lambda(t)$ 的时候。考虑**未建模的不应期**情况。一个真实的神经元在一次脉冲后立即再次发放的可能性较小。因此，真实速率 $\\lambda(t)$ 在脉冲后的短时间内受到抑制。如果GLM未能捕捉到这一点（或低估了其强度），其预测速率 $\\hat{\\lambda}(t)$ 在此期间将高于真实速率 $\\lambda(t)$。对于任何给定的ISI，特别是短ISI，积分 $\\int \\hat{\\lambda}(t) dt$ 将是一个高估值，导致 $\\Delta_i$ 值膨胀。这造成了小的 $\\Delta_i$ 值的缺失，从而导致经验CDF位于对角线下方。上凹的形状反映了最强的偏差（最小的斜率）出现在开始部分，这对应于短ISI的缺失。因此，模式 $\\mathcal{A}$ 是未建模不应期的标志。\n\n**模式 $\\mathcal{B}$ 的分析：** 经验CDF呈S形，开始时在对角线上方，然后下降到下方，再再次上升。\n- **对于小的 $u$ 在对角线上方**：对于小的 $u$，$\\hat{F}_U(u)  u$。这意味着对于小的 $x$，$F_{\\hat{\\Delta}}(x)  1-e^{-x}$。这表明与 $\\text{Exponential}(1)$ 分布相比，存在过量的小 $\\Delta_i$ 值。\n- **对于中间的 $u$ 在对角线下方**：对于中间的 $u$，$F_{\\hat{\\Delta}}(x)  1-e^{-x}$。这意味着对于中间的 $x$，$F_{\\hat{\\Delta}}(x)  1-e^{-x}$。这表明中等大小的 $\\Delta_i$ 值存在缺失。\n“在 $u \\approx 1$ 附近再次上升到对角线上方”的描述略有不精确，因为CDF必须在 $(1,1)$ 处结束，因此当 $u \\to 1$ 时不能在对角线上方。然而，这种S形（先上后下）是 $\\Delta_i$ 值分布相对于 $\\text{Exponential}(1)$ 分布呈过度离散的经典标志：它在零附近和尾部有更多的值，而在中间部分的值较少。\n\n考虑**未观测到的慢速增益波动**的情况，这会导致过度离散。这意味着神经元的兴奋性随时间缓慢波动，而这个因素并未包含在模型 $\\hat{\\lambda}(t)$ 中。模型本质上是对这些增益状态进行了平均。\n- 在高增益（高兴奋性）时期，真实速率 $\\lambda(t)$ 大于模型的平均速率 $\\hat{\\lambda}(t)$。神经元更频繁地发放脉冲，产生短的ISI。这些ISI的重标度间隔 $\\Delta_i = \\int \\hat{\\lambda} d\\tau$ 将是低估值，产生过量的小 $\\Delta_i$ 值。这解释了为什么KS图开始时在对角线上方。\n- 在低增益（低兴奋性）时期，真实速率 $\\lambda(t)$ 小于 $\\hat{\\lambda}(t)$。神经元发放脉冲的频率较低，产生长的ISI。这些ISI的重标度间隔将是高估值，产生过量的大 $\\Delta_i$ 值。\n这两种效应的组合为 $\\{\\Delta_i\\}$ 创建了一个混合分布，其尾部（非常小和非常大的值）的质量比中间部分的质量更多，相对于 $\\text{Exponential}(1)$ 分布而言。这就是在这种情况下过度离散的定义，它产生了模式 $\\mathcal{B}$ 的S形KS图。\n\n### 逐个选项分析\n\n**A. 模式 $\\mathcal{A}$ 表明存在未建模的不应期，这抑制了脉冲后瞬间的真实条件强度（相对于 $\\hat{\\lambda}(t \\mid H_t, x(t))$），而模式 $\\mathcal{B}$ 表明由潜变量速率波动（随机增益）驱动的过度离散，导致相对于 $\\text{Uniform}(0,1)$ 分布，小的和大的重标度值都出现了过量。**\n该选项对模式 $\\mathcal{A}$ 的解释（未建模的不应期）是正确的，如上所述。其对模式 $\\mathcal{B}$ 的解释（由潜变量波动引起的过度离散）也是正确的，因为它正确地识别了机制及其后果——在重标度值分布的两端出现过量质量，导致S形图。\n**结论：正确。**\n\n**B. 模式 $\\mathcal{A}$ 表明存在未建模的不应期，而模式 $\\mathcal{B}$ 表明由于脉冲间隔过于规律（这是gamma形状参数大于1的更新过程的特征）而导致的低度离散。**\n对模式 $\\mathcal{A}$ 的解释是正确的。然而，对模式 $\\mathcal{B}$ 的解释是不正确的。低度离散（更规律的脉冲发放，如来自形状参数1的gamma过程）会导致非常短和非常长的ISI都缺失。这导致 $\\{\\Delta_i\\}$ 的分布比 $\\text{Exponential}(1)$ 更集中在其均值周围。相应的KS图将是一个反S形：对于小的 $u$ 在对角线下方，对于较大的 $u$ 在对角线上方。这与模式 $\\mathcal{B}$ 相反。\n**结论：不正确。**\n\n**C. 模式 $\\mathcal{A}$ 表明模型平均低估了基线发放率，而模式 $\\mathcal{B}$ 表明模型缺失了绝对不应期，这产生了太多非常短的重标度值。**\n对模式 $\\mathcal{A}$ 的解释是不正确的。如果模型低估了速率（$\\hat{\\lambda}(t)  \\lambda(t)$），重标度间隔 $\\{\\Delta_i\\}$ 将系统性地过小，KS图将位于对角线*上方*，而非下方。对模式 $\\mathcal{B}$ 的解释也是不正确的。缺失不应期是模式 $\\mathcal{A}$ 的原因，而不是 $\\mathcal{B}$。此外，它会导致重标度值过*大*，而非过短。\n**结论：不正确。**\n\n**D. 模式 $\\mathcal{A}$ 表明由潜变量速率波动引起的过度离散，而模式 $\\mathcal{B}$ 表明脉冲历史项过强，产生了低度离散和极端重标度值的缺失。**\n此选项错误地交换了原因。模式 $\\mathcal{A}$ 是由未建模的不应期引起的，而不是过度离散。模式 $\\mathcal{B}$ 是由过度离散引起的。该陈述的第二部分声称模式 $\\mathcal{B}$ 来自低度离散，这是不正确的。“过强”的脉冲历史项确实会导致低度离散，但这将导致反S形图，而不是模式 $\\mathcal{B}$。\n**结论：不正确。**",
            "answer": "$$\\boxed{A}$$"
        }
    ]
}