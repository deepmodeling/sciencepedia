{
    "hands_on_practices": [
        {
            "introduction": "While overall accuracy is a common starting point for evaluation, it can be a deceptive measure, especially in scenarios with unbalanced classes or asymmetric error costs. This first exercise demonstrates a crucial concept: two decoders can achieve identical accuracy yet exhibit profoundly different behaviors. By constructing and analyzing two confusion matrices, you will explore the fundamental trade-off between precision and recall, and articulate the practical consequences of favoring one over the other in a neuroscientific context .",
            "id": "4139270",
            "problem": "In a cortical population decoding experiment, a binary decoder is trained to classify whether a stimulus was present ($\\text{positive}$) or absent ($\\text{negative}$) on each trial from multineuron spiking activity and local field potential (LFP). The evaluation set consists of $N=1500$ trials with ground-truth labels: $300$ positives and $1200$ negatives. Two independently trained decoders, $D_{1}$ and $D_{2}$, are evaluated on this same set. Both decoders achieve identical accuracy of $0.92$ with respect to the ground truth.\n\nUsing only the formal definitions of accuracy, precision, recall, and the harmonic mean of precision and recall, construct one admissible confusion matrix for $D_{1}$ that reflects higher recall and lower precision, and another admissible confusion matrix for $D_{2}$ that reflects higher precision and lower recall, subject to the following constraints:\n- The total number of errors is fixed by the accuracy requirement.\n- For $D_{1}$, the number of false positives exceeds the number of false negatives by $80$.\n- For $D_{2}$, the number of false negatives exceeds the number of false positives by $80$.\n\nLet the confusion matrix be parameterized by counts of True Positives ($TP$), False Positives ($FP$), True Negatives ($TN$), and False Negatives ($FN$). After constructing both matrices, compute the precision and recall for each decoder, then compute the harmonic mean of precision and recall for each decoder. Provide a principled explanation for the practical implications of preferring higher recall versus higher precision in this neuroscientific setting, considering class prevalence and the costs of false positives versus false negatives.\n\nFinally, compute the absolute difference in the harmonic mean of precision and recall between $D_{1}$ and $D_{2}$ and report it as a decimal. Round your final numerical answer to four significant figures. No percentage symbol is permitted in your answer.",
            "solution": "The problem statement has been validated and is deemed sound, well-posed, and scientifically grounded. All necessary information is provided, and the constraints are consistent and lead to a unique solution.\n\nThe core task is to construct and evaluate two confusion matrices for binary decoders $D_1$ and $D_2$ based on a set of constraints. Let the four components of a confusion matrix be True Positives ($TP$), False Positives ($FP$), True Negatives ($TN$), and False Negatives ($FN$).\n\nThe fundamental definitions of the performance metrics are:\n-   Accuracy ($A$): The proportion of correct classifications.\n$$A = \\frac{TP + TN}{TP + TN + FP + FN}$$\n-   Precision ($P$): The proportion of positive predictions that were actually correct.\n$$P = \\frac{TP}{TP + FP}$$\n-   Recall ($R$): The proportion of actual positive cases that were correctly identified. Also known as sensitivity or true positive rate.\n$$R = \\frac{TP}{TP + FN}$$\n-   Harmonic Mean of Precision and Recall ($H$): Often denoted as the $F_1$-score, it provides a single measure that balances precision and recall.\n$$H = \\frac{2 \\cdot P \\cdot R}{P + R} = \\frac{2 \\cdot \\frac{TP}{TP+FP} \\cdot \\frac{TP}{TP+FN}}{\\frac{TP}{TP+FP} + \\frac{TP}{TP+FN}} = \\frac{2TP}{2TP + FP + FN}$$\n\nThe problem provides the following global parameters:\n-   Total number of trials: $N = 1500$.\n-   Number of actual positive trials (ground truth): $N_{pos} = TP + FN = 300$.\n-   Number of actual negative trials (ground truth): $N_{neg} = TN + FP = 1200$.\n-   Accuracy for both decoders: $A = 0.92$.\n\nFrom the accuracy, we can determine the total number of correct and incorrect predictions.\nTotal correct predictions ($TP+TN$) = $A \\times N = 0.92 \\times 1500 = 1380$.\nTotal incorrect predictions ($FP+FN$) = $(1-A) \\times N = (1 - 0.92) \\times 1500 = 0.08 \\times 1500 = 120$.\nThis fixed total number of errors, $FP+FN = 120$, applies to both decoders $D_1$ and $D_2$.\n\n**Analysis of Decoder $D_1$ (Higher Recall, Lower Precision)**\n\nFor $D_1$, we have two constraints on its errors:\n1.  The total number of errors is $120$: $FP_1 + FN_1 = 120$.\n2.  The number of false positives exceeds the number of false negatives by $80$: $FP_1 = FN_1 + 80$.\n\nWe solve this system of linear equations:\n$$(FN_1 + 80) + FN_1 = 120$$\n$$2FN_1 + 80 = 120$$\n$$2FN_1 = 40$$\n$$FN_1 = 20$$\nAnd consequently, $FP_1 = 20 + 80 = 100$.\n\nNow we can determine the number of true predictions for $D_1$:\n-   $TP_1 = N_{pos} - FN_1 = 300 - 20 = 280$.\n-   $TN_1 = N_{neg} - FP_1 = 1200 - 100 = 1100$.\n\nThe confusion matrix for $D_1$ is: $TP_1=280$, $FN_1=20$, $FP_1=100$, $TN_1=1100$.\n\nWe compute precision, recall, and the harmonic mean for $D_1$:\n-   Precision $P_1 = \\frac{TP_1}{TP_1 + FP_1} = \\frac{280}{280 + 100} = \\frac{280}{380} = \\frac{14}{19}$.\n-   Recall $R_1 = \\frac{TP_1}{TP_1 + FN_1} = \\frac{280}{280 + 20} = \\frac{280}{300} = \\frac{14}{15}$.\n-   Harmonic Mean $H_1 = \\frac{2 P_1 R_1}{P_1 + R_1} = \\frac{2 \\cdot \\frac{14}{19} \\cdot \\frac{14}{15}}{\\frac{14}{19} + \\frac{14}{15}} = \\frac{2 \\cdot 14 \\cdot (\\frac{14}{19 \\cdot 15})}{14 \\cdot (\\frac{1}{19} + \\frac{1}{15})} = \\frac{2 \\cdot \\frac{14}{285}}{\\frac{15+19}{285}} = \\frac{2 \\cdot 14}{34} = \\frac{14}{17}$.\n\n**Analysis of Decoder $D_2$ (Higher Precision, Lower Recall)**\n\nFor $D_2$, the constraints on errors are:\n1.  The total number of errors is $120$: $FP_2 + FN_2 = 120$.\n2.  The number of false negatives exceeds the number of false positives by $80$: $FN_2 = FP_2 + 80$.\n\nWe solve this system:\n$$FP_2 + (FP_2 + 80) = 120$$\n$$2FP_2 + 80 = 120$$\n$$2FP_2 = 40$$\n$$FP_2 = 20$$\nAnd consequently, $FN_2 = 20 + 80 = 100$.\n\nNow we determine the true predictions for $D_2$:\n-   $TP_2 = N_{pos} - FN_2 = 300 - 100 = 200$.\n-   $TN_2 = N_{neg} - FP_2 = 1200 - 20 = 1180$.\n\nThe confusion matrix for $D_2$ is: $TP_2=200$, $FN_2=100$, $FP_2=20$, $TN_2=1180$.\n\nWe compute precision, recall, and the harmonic mean for $D_2$:\n-   Precision $P_2 = \\frac{TP_2}{TP_2 + FP_2} = \\frac{200}{200 + 20} = \\frac{200}{220} = \\frac{10}{11}$.\n-   Recall $R_2 = \\frac{TP_2}{TP_2 + FN_2} = \\frac{200}{200 + 100} = \\frac{200}{300} = \\frac{2}{3}$.\n-   Harmonic Mean $H_2 = \\frac{2 P_2 R_2}{P_2 + R_2} = \\frac{2 \\cdot \\frac{10}{11} \\cdot \\frac{2}{3}}{\\frac{10}{11} + \\frac{2}{3}} = \\frac{2 \\cdot \\frac{20}{33}}{\\frac{30+22}{33}} = \\frac{40}{52} = \\frac{10}{13}$.\n\n**Practical Implications**\n\nThe choice between a high-recall decoder like $D_1$ ($R_1 = 14/15 \\approx 0.933$, $P_1 = 14/19 \\approx 0.737$) and a high-precision decoder like $D_2$ ($R_2 = 2/3 \\approx 0.667$, $P_2 = 10/11 \\approx 0.909$) depends on the relative costs of false negatives versus false positives in a specific neuroscientific or clinical application.\n\nA false negative ($FN$) occurs when the decoder fails to detect a stimulus that was present (a \"miss\"). A false positive ($FP$) occurs when the decoder signals a stimulus that was absent (a \"false alarm\").\n\n-   **Preferring High Recall ($D_1$):** Decoder $D_1$ has few false negatives ($FN_1=20$) at the cost of more false positives ($FP_1=100$). A high-recall model is preferred when the consequence of a miss is severe. For example, in a brain-computer interface designed to detect an impending epileptic seizure, failing to detect a real seizure (a miss) could be catastrophic for the patient. In this scenario, occasional false alarms that trigger a needless warning are far more acceptable.\n\n-   **Preferring High Precision ($D_2$):** Decoder $D_2$ has very few false positives ($FP_2=20$) at the cost of more false negatives ($FN_2=100$). A high-precision model is crucial when the consequence of a false alarm is severe. For example, if a decoder's output triggers an invasive or high-risk intervention, such as delivering a powerful drug or electrical stimulation to the brain, a false alarm would be extremely costly (e.g., causing harmful side-effects). In this case, it is better to miss some true events to ensure that any intervention is based on a highly confident detection.\n\nThe presence of a significant class imbalance ($300$ positives vs. $1200$ negatives) makes accuracy an insufficient metric. A trivial decoder always predicting \"negative\" would achieve $1200/1500 = 80\\%$ accuracy but would be useless, with zero recall. Precision and recall provide a more nuanced and meaningful evaluation of performance on such imbalanced datasets.\n\n**Final Calculation**\n\nThe final step is to compute the absolute difference in the harmonic mean of precision and recall between $D_1$ and $D_2$.\n$$|H_1 - H_2| = \\left| \\frac{14}{17} - \\frac{10}{13} \\right|$$\nTo subtract the fractions, we find a common denominator, which is $17 \\times 13 = 221$.\n$$|H_1 - H_2| = \\left| \\frac{14 \\times 13}{17 \\times 13} - \\frac{10 \\times 17}{13 \\times 17} \\right| = \\left| \\frac{182}{221} - \\frac{170}{221} \\right| = \\frac{12}{221}$$\nAs a decimal, this is $12 \\div 221 \\approx 0.05429864$.\nRounding to four significant figures yields $0.05430$.",
            "answer": "$$\\boxed{0.05430}$$"
        },
        {
            "introduction": "Many decoding problems in neuroscience are not binary; they involve distinguishing between multiple stimuli, intentions, or brain states. This practice extends the core concepts of precision and recall to the more general multiclass classification setting. Working directly from a confusion matrix, you will calculate per-class performance metrics and learn how to synthesize them using macro-averaging to obtain a single, interpretable summary score like the macro-averaged $\\mathrm{F1}$-score .",
            "id": "4139294",
            "problem": "A population decoder is trained to map multineuron spike-count vectors to one of four stimulus classes, denoted by $s_1, s_2, s_3, s_4$. On a held-out test set, performance is summarized by the $K \\times K$ confusion matrix $C$ with $K=4$, where $C_{ij}$ counts the number of test trials whose true stimulus class is $s_i$ and whose predicted class is $s_j$. The empirical confusion matrix is\n$$\nC \\;=\\;\n\\begin{pmatrix}\n42  5  3  0 \\\\\n6  38  4  2 \\\\\n5  7  30  8 \\\\\n1  2  9  33\n\\end{pmatrix}.\n$$\nUsing only the fundamental definitions of classification events for each class $s_k$—true positives, false positives, false negatives—and the fact that the $\\mathrm{F1}$-score is the harmonic mean of precision and recall, compute the per-class precision and recall for $k \\in \\{1,2,3,4\\}$ and the macro-averaged $\\mathrm{F1}$-score (the arithmetic mean of the four per-class $\\mathrm{F1}$-scores). Express all requested quantities as unitless decimal numbers rounded to four significant figures. In your final answer, present the nine numbers in a single row matrix in the following order: precision for $s_1, s_2, s_3, s_4$; recall for $s_1, s_2, s_3, s_4$; macro-averaged $\\mathrm{F1}$-score.",
            "solution": "The problem requires the calculation of per-class precision and recall, and the macro-averaged $\\mathrm{F1}$-score, based on a given confusion matrix for a four-class classification problem. The problem statement is scientifically sound, well-posed, and objective, using standard definitions from machine learning performance evaluation. Therefore, it is a valid problem.\n\nThe provided confusion matrix $C$ is:\n$$\nC \\;=\\;\n\\begin{pmatrix}\n42  5  3  0 \\\\\n6  38  4  2 \\\\\n5  7  30  8 \\\\\n1  2  9  33\n\\end{pmatrix}\n$$\nwhere $C_{ij}$ is the count of trials with true class $s_i$ and predicted class $s_j$.\n\nFor a given class $s_k$, the number of true positives ($TP_k$), false positives ($FP_k$), and false negatives ($FN_k$) are defined based on the elements of the confusion matrix $C$.\n- True Positives ($TP_k$): The number of samples of class $s_k$ correctly predicted as class $s_k$. This corresponds to the diagonal element $C_{kk}$.\n$$TP_k = C_{kk}$$\n- False Positives ($FP_k$): The number of samples from other classes incorrectly predicted as class $s_k$. This is the sum of all elements in column $k$, excluding the true positives.\n$$FP_k = \\sum_{i \\neq k} C_{ik} = \\left(\\sum_{i=1}^{4} C_{ik}\\right) - C_{kk}$$\n- False Negatives ($FN_k$): The number of samples of class $s_k$ incorrectly predicted as any other class. This is the sum of all elements in row $k$, excluding the true positives.\n$$FN_k = \\sum_{j \\neq k} C_{kj} = \\left(\\sum_{j=1}^{4} C_{kj}\\right) - C_{kk}$$\n\nPrecision ($P_k$) is the ratio of true positives to all samples predicted as class $s_k$.\n$$P_k = \\frac{TP_k}{TP_k + FP_k}$$\nRecall ($R_k$) is the ratio of true positives to all actual samples of class $s_k$.\n$$R_k = \\frac{TP_k}{TP_k + FN_k}$$\nThe $\\mathrm{F1}$-score ($F1_k$) is the harmonic mean of precision and recall.\n$$F1_k = 2 \\cdot \\frac{P_k \\cdot R_k}{P_k + R_k}$$\n\nWe now compute these quantities for each class $k \\in \\{1, 2, 3, 4\\}$.\n\nFor class $s_1$ ($k=1$):\n$TP_1 = C_{11} = 42$\n$FP_1 = C_{21} + C_{31} + C_{41} = 6 + 5 + 1 = 12$\n$FN_1 = C_{12} + C_{13} + C_{14} = 5 + 3 + 0 = 8$\n$P_1 = \\frac{42}{42+12} = \\frac{42}{54} = \\frac{7}{9} \\approx 0.777777...$\n$R_1 = \\frac{42}{42+8} = \\frac{42}{50} = 0.84$\n$F1_1 = 2 \\cdot \\frac{P_1 R_1}{P_1 + R_1} = 2 \\cdot \\frac{(42/54) \\cdot (42/50)}{(42/54) + (42/50)} = \\frac{2 \\cdot 42}{54+50} = \\frac{84}{104} = \\frac{21}{26} \\approx 0.807692...$\n\nFor class $s_2$ ($k=2$):\n$TP_2 = C_{22} = 38$\n$FP_2 = C_{12} + C_{32} + C_{42} = 5 + 7 + 2 = 14$\n$FN_2 = C_{21} + C_{23} + C_{24} = 6 + 4 + 2 = 12$\n$P_2 = \\frac{38}{38+14} = \\frac{38}{52} = \\frac{19}{26} \\approx 0.730769...$\n$R_2 = \\frac{38}{38+12} = \\frac{38}{50} = 0.76$\n$F1_2 = 2 \\cdot \\frac{P_2 R_2}{P_2 + R_2} = 2 \\cdot \\frac{(38/52) \\cdot (38/50)}{(38/52) + (38/50)} = \\frac{2 \\cdot 38}{52+50} = \\frac{76}{102} = \\frac{38}{51} \\approx 0.745098...$\n\nFor class $s_3$ ($k=3$):\n$TP_3 = C_{33} = 30$\n$FP_3 = C_{13} + C_{23} + C_{43} = 3 + 4 + 9 = 16$\n$FN_3 = C_{31} + C_{32} + C_{34} = 5 + 7 + 8 = 20$\n$P_3 = \\frac{30}{30+16} = \\frac{30}{46} = \\frac{15}{23} \\approx 0.652173...$\n$R_3 = \\frac{30}{30+20} = \\frac{30}{50} = 0.6$\n$F1_3 = 2 \\cdot \\frac{P_3 R_3}{P_3 + R_3} = 2 \\cdot \\frac{(30/46) \\cdot (30/50)}{(30/46) + (30/50)} = \\frac{2 \\cdot 30}{46+50} = \\frac{60}{96} = \\frac{5}{8} = 0.625$\n\nFor class $s_4$ ($k=4$):\n$TP_4 = C_{44} = 33$\n$FP_4 = C_{14} + C_{24} + C_{34} = 0 + 2 + 8 = 10$\n$FN_4 = C_{41} + C_{42} + C_{43} = 1 + 2 + 9 = 12$\n$P_4 = \\frac{33}{33+10} = \\frac{33}{43} \\approx 0.767441...$\n$R_4 = \\frac{33}{33+12} = \\frac{33}{45} = \\frac{11}{15} \\approx 0.733333...$\n$F1_4 = 2 \\cdot \\frac{P_4 R_4}{P_4 + R_4} = 2 \\cdot \\frac{(33/43) \\cdot (33/45)}{(33/43) + (33/45)} = \\frac{2 \\cdot 33}{43+45} = \\frac{66}{88} = \\frac{3}{4} = 0.75$\n\nThe macro-averaged $\\mathrm{F1}$-score, $F1_{\\text{macro}}$, is the arithmetic mean of the per-class $\\mathrm{F1}$-scores.\n$$F1_{\\text{macro}} = \\frac{1}{4} \\sum_{k=1}^4 F1_k = \\frac{F1_1 + F1_2 + F1_3 + F1_4}{4}$$\n$$F1_{\\text{macro}} = \\frac{1}{4} \\left( \\frac{21}{26} + \\frac{38}{51} + \\frac{5}{8} + \\frac{3}{4} \\right) \\approx \\frac{0.807692 + 0.745098 + 0.625 + 0.75}{4} = \\frac{2.92779}{4} \\approx 0.731947...$$\n\nRounding all requested quantities to four significant figures:\n- $P_1 \\approx 0.7778$\n- $P_2 \\approx 0.7308$\n- $P_3 \\approx 0.6522$\n- $P_4 \\approx 0.7674$\n\n- $R_1 = 0.8400$\n- $R_2 = 0.7600$\n- $R_3 = 0.6000$\n- $R_4 \\approx 0.7333$\n\n- $F1_{\\text{macro}} \\approx 0.7319$\n\nThe final answer requires a single row matrix containing these nine values in the specified order: $P_1, P_2, P_3, P_4, R_1, R_2, R_3, R_4, F1_{\\text{macro}}$.",
            "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n0.7778  0.7308  0.6522  0.7674  0.8400  0.7600  0.6000  0.7333  0.7319\n\\end{pmatrix}\n}\n$$"
        },
        {
            "introduction": "Ultimately, the goal of a decoder is often to inform a decision, and the 'best' decision depends on the potential costs of being wrong. This advanced practice bridges the gap between abstract performance metrics and principled decision-making. By comparing the decision threshold that maximizes the popular $\\mathrm{F1}$-score against the threshold that minimizes expected cost under an asymmetric loss function, you will discover that these two are not always the same, highlighting the critical importance of selecting an evaluation criterion that truly reflects the application's goals .",
            "id": "4139336",
            "problem": "A team is developing a closed-loop brain–computer interface decoder that must detect the presence of a transient sensory stimulus in real time from population spiking activity. On each of $12$ trial epochs, the decoder outputs a calibrated posterior probability $p_i \\in [0,1]$ of stimulus presence and the ground-truth label $y_i \\in \\{0,1\\}$, with $y_i=1$ indicating stimulus present and $y_i=0$ indicating stimulus absent. The list of $(p_i,y_i)$, sorted by $p_i$ in descending order, is:\n\n$$\n(0.95,1),\\ (0.90,0),\\ (0.80,1),\\ (0.70,1),\\ (0.60,0),\\ (0.50,0),\\ (0.45,0),\\ (0.40,1),\\ (0.35,0),\\ (0.30,1),\\ (0.20,0),\\ (0.10,0).\n$$\n\nFor a fixed decision threshold $\\tau \\in [0,1]$, the decoder predicts $1$ whenever $p_i \\ge \\tau$ and predicts $0$ otherwise. The team is considering two criteria for choosing $\\tau$:\n\n1. The $\\mathrm{F1}$-score (F1), defined from precision and recall computed on the realized labels. Precision is the fraction of predicted positives that are true positives, and recall is the fraction of actual positives that are correctly predicted. The $\\mathrm{F1}$-score is the harmonic mean of precision and recall. The team will choose the $\\tau$ that maximizes the $\\mathrm{F1}$-score over thresholds that induce distinct predicted positive sets. In case of a tie, they select the largest $\\tau$ among the maximizers.\n\n2. Expected utility under asymmetric error costs. Suppose the false positive cost is $c_{\\mathrm{FP}} = 1$ utility unit and the false negative cost is $c_{\\mathrm{FN}} = 10$ utility units, with zero cost for correct decisions. The team will choose the $\\tau$ that minimizes expected cost with respect to the posterior probabilities $p_i$.\n\nUsing only the foundational definitions of precision, recall, $\\mathrm{F1}$-score, expected cost, and posterior probability, and without invoking any pre-derived thresholding rules, determine the decision threshold that maximizes the $\\mathrm{F1}$-score and the one that minimizes expected cost. Then compute the difference between the total expected cost at the $\\mathrm{F1}$-optimal threshold and the total expected cost at the expected-utility-optimal threshold. Round your final numeric answer to four significant figures and express it in utility units. Your final answer must be a single real number.",
            "solution": "The problem statement is critically validated and found to be valid. It is scientifically grounded in standard principles of statistical decision theory and machine learning evaluation, well-posed with all necessary information and unambiguous definitions, and objective in its formulation. We can therefore proceed with a full solution.\n\nThe problem asks for two main tasks: first, to find the decision thresholds that optimize two different criteria ($\\mathrm{F1}$-score and expected utility), and second, to compute the difference in total expected cost between using these two thresholds.\n\nLet the set of $N=12$ data points be $\\{(p_i, y_i)\\}_{i=1}^{12}$. The ground-truth labels $y_i \\in \\{0, 1\\}$ indicate stimulus absence ($0$) or presence ($1$). The posterior probabilities $p_i$ represent $P(y_i=1)$. The decision rule is to predict a positive outcome ($\\hat{y}_i=1$) if $p_i \\ge \\tau$ and a negative outcome ($\\hat{y}_i=0$) if $p_i  \\tau$.\n\nFirst, we identify the number of actual positive ($P$) and actual negative ($N_{neg}$) samples in the dataset.\nThe positive samples ($y_i=1$) correspond to $p_i \\in \\{0.95, 0.80, 0.70, 0.40, 0.30\\}$. Thus, the total number of positives is $P=5$.\nThe negative samples ($y_i=0$) correspond to $p_i \\in \\{0.90, 0.60, 0.50, 0.45, 0.35, 0.20, 0.10\\}$. Thus, the total number of negatives is $N_{neg}=7$.\n\n### Part 1: Finding the $\\mathrm{F1}$-Optimal Threshold ($\\tau_{\\mathrm{F1}}$)\n\nThe $\\mathrm{F1}$-score is the harmonic mean of precision (Prec) and recall (Rec):\n$$ \\mathrm{Prec} = \\frac{\\mathrm{TP}}{\\mathrm{TP}+\\mathrm{FP}}, \\quad \\mathrm{Rec} = \\frac{\\mathrm{TP}}{\\mathrm{TP}+\\mathrm{FN}}, \\quad \\mathrm{F1} = 2 \\frac{\\mathrm{Prec} \\cdot \\mathrm{Rec}}{\\mathrm{Prec} + \\mathrm{Rec}} = \\frac{2\\mathrm{TP}}{2\\mathrm{TP}+\\mathrm{FP}+\\mathrm{FN}} $$\nwhere $TP$, $FP$, and $FN$ are the counts of true positives, false positives, and false negatives, respectively. These counts depend on the choice of threshold $\\tau$. The thresholds that produce distinct sets of predictions are the unique values of $p_i$ in the dataset. We evaluate the $\\mathrm{F1}$-score for each of these potential thresholds. The data is sorted by $p_i$, which simplifies the calculation. For a threshold $\\tau=p_{(k)}$, the first $k$ items in the sorted list are predicted as positive.\n\nLet's tabulate the results for each of the $12$ unique $p_i$ values as thresholds:\n- For $\\tau=0.95$: Predict positive for $\\{ (0.95, 1) \\}$. $TP=1$, $FP=0$. $FN=P-TP=5-1=4$. $F1 = \\frac{2(1)}{2(1)+0+4} = \\frac{2}{6} = \\frac{1}{3} \\approx 0.3333$.\n- For $\\tau=0.90$: Predict positive for $\\{ (0.95, 1), (0.90, 0) \\}$. $TP=1$, $FP=1$. $FN=4$. $F1 = \\frac{2(1)}{2(1)+1+4} = \\frac{2}{7} \\approx 0.2857$.\n- For $\\tau=0.80$: Predict positive for first $3$ items. $TP=2$, $FP=1$. $FN=3$. $F1 = \\frac{2(2)}{2(2)+1+3} = \\frac{4}{8} = \\frac{1}{2} = 0.5$.\n- For $\\tau=0.70$: Predict positive for first $4$ items. $TP=3$, $FP=1$. $FN=2$. $F1 = \\frac{2(3)}{2(3)+1+2} = \\frac{6}{9} = \\frac{2}{3} \\approx 0.6667$.\n- For $\\tau=0.60$: Predict positive for first $5$ items. $TP=3$, $FP=2$. $FN=2$. $F1 = \\frac{2(3)}{2(3)+2+2} = \\frac{6}{10} = \\frac{3}{5} = 0.6$.\n- For $\\tau=0.50$: Predict positive for first $6$ items. $TP=3$, $FP=3$. $FN=2$. $F1 = \\frac{2(3)}{2(3)+3+2} = \\frac{6}{11} \\approx 0.5455$.\n- For $\\tau=0.45$: Predict positive for first $7$ items. $TP=3$, $FP=4$. $FN=2$. $F1 = \\frac{2(3)}{2(3)+4+2} = \\frac{6}{12} = \\frac{1}{2} = 0.5$.\n- For $\\tau=0.40$: Predict positive for first $8$ items. $TP=4$, $FP=4$. $FN=1$. $F1 = \\frac{2(4)}{2(4)+4+1} = \\frac{8}{13} \\approx 0.6154$.\n- For $\\tau=0.35$: Predict positive for first $9$ items. $TP=4$, $FP=5$. $FN=1$. $F1 = \\frac{2(4)}{2(4)+5+1} = \\frac{8}{14} = \\frac{4}{7} \\approx 0.5714$.\n- For $\\tau=0.30$: Predict positive for first $10$ items. $TP=5$, $FP=5$. $FN=0$. $F1 = \\frac{2(5)}{2(5)+5+0} = \\frac{10}{15} = \\frac{2}{3} \\approx 0.6667$.\n- For $\\tau=0.20$: Predict positive for first $11$ items. $TP=5$, $FP=6$. $FN=0$. $F1 = \\frac{2(5)}{2(5)+6+0} = \\frac{10}{16} = \\frac{5}{8} = 0.625$.\n- For $\\tau=0.10$: Predict positive for all $12$ items. $TP=5$, $FP=7$. $FN=0$. $F1 = \\frac{2(5)}{2(5)+7+0} = \\frac{10}{17} \\approx 0.5882$.\n\nThe maximum $\\mathrm{F1}$-score is $\\frac{2}{3}$, which occurs for $\\tau=0.70$ and $\\tau=0.30$. The problem specifies a tie-breaking rule: \"select the largest $\\tau$ among the maximizers.\" Therefore, the $\\mathrm{F1}$-optimal threshold is $\\tau_{\\mathrm{F1}} = 0.70$.\n\n### Part 2: Finding the Expected-Utility-Optimal Threshold ($\\tau_{\\mathrm{EU}}$)\n\nThe goal is to choose a threshold $\\tau$ that minimizes the total expected cost, given the posterior probabilities $p_i$. The costs are $c_{\\mathrm{FP}} = 1$ and $c_{\\mathrm{FN}} = 10$. The costs for correct decisions are $0$.\n\nFor a single trial $i$, we consider the expected cost of each possible decision:\n- If we predict a positive ($\\hat{y}_i=1$), the expected cost is the probability of a false positive ($1-p_i$) times its cost:\n  $E[\\text{Cost} | \\hat{y}_i=1] = p_i \\cdot 0 + (1-p_i) \\cdot c_{\\mathrm{FP}} = 1-p_i$.\n- If we predict a negative ($\\hat{y}_i=0$), the expected cost is the probability of a false negative ($p_i$) times its cost:\n  $E[\\text{Cost} | \\hat{y}_i=0] = p_i \\cdot c_{\\mathrm{FN}} + (1-p_i) \\cdot 0 = 10 p_i$.\n\nTo minimize expected cost for trial $i$, we should predict positive if $E[\\text{Cost} | \\hat{y}_i=1]  E[\\text{Cost} | \\hat{y}_i=0]$.\n$$ 1-p_i  10 p_i \\implies 1  11 p_i \\implies p_i  \\frac{1}{11} $$\nIf $p_i = \\frac{1}{11}$, the costs are equal. The optimal rule is to predict positive if $p_i \\ge \\frac{1}{11}$ and negative otherwise. The problem defines the decision rule as predicting positive for $p_i \\ge \\tau$. The threshold $\\tau$ that implements this optimal strategy across all trials is therefore $\\tau_{\\mathrm{EU}} = \\frac{1}{11}$.\n\n### Part 3: Calculating the Difference in Total Expected Cost\n\nThe total expected cost for a given threshold $\\tau$ is the sum of the expected costs for each trial, given the decision made for that trial:\n$$ C(\\tau) = \\sum_{i: p_i \\ge \\tau} (1-p_i)c_{\\mathrm{FP}} + \\sum_{i: p_i  \\tau} p_i c_{\\mathrm{FN}} = \\sum_{i: p_i \\ge \\tau} (1-p_i) + 10 \\sum_{i: p_i  \\tau} p_i $$\nWe need to compute $\\Delta C = C(\\tau_{\\mathrm{F1}}) - C(\\tau_{\\mathrm{EU}})$.\n\n**A. Calculate $C(\\tau_{\\mathrm{F1}}) = C(0.70)$:**\nThe set of trials with $p_i \\ge 0.70$ is $\\{0.95, 0.90, 0.80, 0.70\\}$.\nThe set of trials with $p_i  0.70$ is $\\{0.60, 0.50, 0.45, 0.40, 0.35, 0.30, 0.20, 0.10\\}$.\n$$\n\\begin{align*}\nC(0.70) = [(1-0.95) + (1-0.90) + (1-0.80) + (1-0.70)] \\\\\n\\quad + 10 \\cdot [0.60 + 0.50 + 0.45 + 0.40 + 0.35 + 0.30 + 0.20 + 0.10] \\\\\n= [0.05 + 0.10 + 0.20 + 0.30] + 10 \\cdot [2.90] \\\\\n= 0.65 + 29.0 \\\\\n= 29.65\n\\end{align*}\n$$\n\n**B. Calculate $C(\\tau_{\\mathrm{EU}}) = C(1/11)$:**\nThe threshold is $\\tau_{\\mathrm{EU}} = \\frac{1}{11} \\approx 0.0909$. We must check which $p_i$ values are greater than or equal to this threshold.\nThe smallest $p_i$ in the dataset is $0.10$. Since $0.10 = \\frac{1}{10}  \\frac{1}{11}$, all $12$ given probabilities $p_i$ are greater than $\\tau_{\\mathrm{EU}}$.\nTherefore, for $\\tau_{\\mathrm{EU}}$, all trials are predicted as positive. The second sum in the cost function is over an empty set and is thus $0$.\n$$\nC(1/11) = \\sum_{i=1}^{12} (1-p_i) = 12 - \\sum_{i=1}^{12} p_i\n$$\nThe sum of all probabilities is:\n$$ \\sum_{i=1}^{12} p_i = 0.95+0.90+0.80+0.70+0.60+0.50+0.45+0.40+0.35+0.30+0.20+0.10 = 6.25 $$\nSo, the minimum total expected cost is:\n$$ C(1/11) = 12 - 6.25 = 5.75 $$\n\n**C. Compute the difference:**\nThe difference between the total expected cost at the $\\mathrm{F1}$-optimal threshold and the total expected cost at the utility-optimal threshold is:\n$$ \\Delta C = C(0.70) - C(1/11) = 29.65 - 5.75 = 23.90 $$\nThe problem asks for the answer to be rounded to four significant figures. The value $23.90$ already has four significant figures.",
            "answer": "$$\\boxed{23.90}$$"
        }
    ]
}