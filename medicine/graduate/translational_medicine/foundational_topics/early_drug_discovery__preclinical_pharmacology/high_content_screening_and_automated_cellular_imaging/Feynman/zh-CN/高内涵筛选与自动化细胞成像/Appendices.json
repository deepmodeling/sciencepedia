{
    "hands_on_practices": [
        {
            "introduction": "在开始任何高内涵筛选实验之前，确保成像系统配置正确是至关重要的一步。这项实践的核心原则是将相机的采样分辨率与显微镜物镜的光学分辨率相匹配，这遵循了奈奎斯特-香农采样定理。通过这项练习，您将掌握计算光学分辨率和确定合适放大倍率的方法，以避免丢失宝贵的空间信息，这是配置任何定量显微镜实验的基础技能。",
            "id": "5020614",
            "problem": "在高内涵筛选 (HCS) 中，自动化细胞成像系统必须确保相机采样能保留由显微镜光学系统传输的可分辨空间细节。考虑一个用于转化医学表型分析的非相干宽场荧光成像光路：一个数值孔径 (NA) 为 $0.95$ 的 $40\\times$ 物镜将峰值发射波长 $\\lambda=520\\ \\mathrm{nm}$ 的绿色发光结构成像到像素间距为 $p=6.5\\ \\mu\\mathrm{m}$ 的方形像素科学级互补金属氧化物半导体 (CMOS) 相机上。假设图像受光学系统带宽限制，且系统已正确对准，无主导像差。\n\n从第一性原理出发，使用针对带限信号的奈奎斯特-香农采样定理和已知的非相干荧光显微镜的光学传递截止频率，来确定当前 $M=40$ 的配置是否在样本平面上满足奈奎斯特采样条件。如果不满足，推导所需的最小总放大倍率 $M_{\\min}$，使得等效的样本平面采样间隔对于给定的 $\\lambda$ 和 NA 满足奈奎斯特条件。简要论证像素合并 (pixel binning) 在这种欠采样情况下是否有帮助，并给出一个满足要求的实用放大倍率调整方案。\n\n将你报告的唯一数值答案 $M_{\\min}$ 四舍五入到四位有效数字。将 $M_{\\min}$ 表示为一个无量纲的放大系数（例如，对于 $60\\times$ 的配置，报告为 $60$）。",
            "solution": "在尝试求解之前，首先对问题陈述的科学合理性、自洽性和清晰度进行验证。\n\n### 步骤 1：问题验证\n\n给定的参数如下：\n- 成像模式：非相干宽场荧光显微镜。\n- 物镜放大倍率：$M = 40$。\n- 物镜数值孔径：$\\mathrm{NA} = 0.95$。\n- 峰值发射波长：$\\lambda = 520 \\ \\mathrm{nm}$。\n- 相机像素间距：$p = 6.5 \\ \\mu\\mathrm{m}$。\n- 相机像素为方形。\n- 假设：图像受光学系统带宽限制；系统完美对准且无像差。\n\n问题要求：\n1. 确定当前配置是否在样本平面上满足奈奎斯特采样条件。\n2. 如果不满足，推导出满足条件的最小总放大倍率 $M_{\\min}$。\n3. 论证像素合并是否有帮助。\n4. 给出一个实用的放大倍率调整方案。\n5. 报告四舍五入到四位有效数字的 $M_{\\min}$。\n\n该问题在科学上基于傅里叶光学原理和应用于数字成像的奈奎斯特-香农采样定理。所提供的参数对于一个高性能 HCS 系统是符合实际的。问题提取得当，并能导出一个唯一的、可验证的解。因此，该问题被认为是有效的。\n\n### 步骤 2：推导与求解\n\n根据要求，从第一性原理出发进行求解。\n\n#### 光学分辨率与带宽限制\n对于一个非相干成像系统，光学传递函数 (OTF) 仅在空间频率达到某个截止频率之前才非零，该截止频率由物镜的数值孔径 ($\\mathrm{NA}$) 和成像光的波长 ($\\lambda$) 决定。这个截止频率 $k_{\\text{cutoff}}$ 代表了物镜能够传输的最高空间频率信息。在样本平面上，它由下式给出：\n$$\nk_{\\text{cutoff}} = \\frac{2 \\cdot \\mathrm{NA}}{\\lambda}\n$$\n该公式定义了由物镜形成的图像的空间频率带宽限制。\n\n#### 奈奎斯特采样准则\n奈奎斯特-香农采样定理指出，为了无失真地表示一个带宽限制在最大频率 $f_{\\text{max}}$ 的信号，采样频率 $f_s$ 必须至少是这个最大频率的两倍：$f_s \\ge 2 \\cdot f_{\\text{max}}$。\n\n在空间成像的背景下，最大频率是 $k_{\\text{cutoff}}$。因此，在样本平面上所需的采样频率，我们称之为奈奎斯特频率 $k_{\\text{Nyquist}}$，必须满足：\n$$\nk_{\\text{Nyquist}} \\ge 2 \\cdot k_{\\text{cutoff}}\n$$\n代入 $k_{\\text{cutoff}}$ 的表达式：\n$$\nk_{\\text{Nyquist}} \\ge 2 \\left( \\frac{2 \\cdot \\mathrm{NA}}{\\lambda} \\right) = \\frac{4 \\cdot \\mathrm{NA}}{\\lambda}\n$$\n采样间隔是采样频率的倒数。因此，奈奎斯特准则要求样本中的采样间隔 $\\Delta x$ 必须小于或等于奈奎斯特采样间隔 $\\Delta x_{\\text{Nyquist}}$。\n$$\n\\Delta x \\le \\Delta x_{\\text{Nyquist}} = \\frac{1}{k_{\\text{Nyquist}}} = \\frac{\\lambda}{4 \\cdot \\mathrm{NA}}\n$$\n该表达式定义了在样本平面上为避免混叠并保留所有由物镜传递的空间信息所允许的最大采样间距。\n\n#### 系统的等效采样间隔\n相机以像素间距 $p$ 对放大后的图像进行采样。总放大倍率 $M$ 对图像进行缩放。在样本平面上的等效采样间隔 $\\Delta x_{\\text{eff}}$ 是物理像素间距除以总放大倍率：\n$$\n\\Delta x_{\\text{eff}} = \\frac{p}{M}\n$$\n\n#### 当前配置分析 ($M=40$)\n我们首先使用给定的参数 $\\lambda = 520 \\ \\mathrm{nm} = 0.520 \\ \\mu\\mathrm{m}$ 和 $\\mathrm{NA} = 0.95$ 来计算所需的奈奎斯特采样间隔 $\\Delta x_{\\text{Nyquist}}$。\n$$\n\\Delta x_{\\text{Nyquist}} = \\frac{\\lambda}{4 \\cdot \\mathrm{NA}} = \\frac{0.520 \\ \\mu\\mathrm{m}}{4 \\cdot (0.95)} = \\frac{0.520 \\ \\mu\\mathrm{m}}{3.8} \\approx 0.13684 \\ \\mu\\mathrm{m}\n$$\n接下来，我们计算当前配置下（$p = 6.5 \\ \\mu\\mathrm{m}$ 和 $M = 40$）的实际等效采样间隔 $\\Delta x_{\\text{eff}}$。\n$$\n\\Delta x_{\\text{eff}} = \\frac{p}{M} = \\frac{6.5 \\ \\mu\\mathrm{m}}{40} = 0.1625 \\ \\mu\\mathrm{m}\n$$\n为了满足奈奎斯特准则，我们必须有 $\\Delta x_{\\text{eff}} \\le \\Delta x_{\\text{Nyquist}}$。\n比较这两个值：\n$$\n0.1625 \\ \\mu\\mathrm{m} > 0.13684 \\ \\mu\\mathrm{m}\n$$\n由于实际采样间隔大于允许的最大间隔，当前 $M=40$ 的配置是欠采样的，不满足奈奎斯特准则。\n\n#### 最小所需放大倍率 ($M_{\\min}$) 的推导\n为了满足奈奎斯特准则，放大倍率 $M$ 必须足够大。我们将采样条件设置为奈奎斯特极限：\n$$\n\\Delta x_{\\text{eff}} \\le \\Delta x_{\\text{Nyquist}}\n$$\n$$\n\\frac{p}{M} \\le \\frac{\\lambda}{4 \\cdot \\mathrm{NA}}\n$$\n为了找到最小放大倍率 $M_{\\min}$，我们对不等式求解 $M$：\n$$\nM \\ge \\frac{4 \\cdot p \\cdot \\mathrm{NA}}{\\lambda}\n$$\n因此，所需的最小放大倍率是：\n$$\nM_{\\min} = \\frac{4 \\cdot p \\cdot \\mathrm{NA}}{\\lambda}\n$$\n代入给定值：\n$$\nM_{\\min} = \\frac{4 \\cdot (6.5 \\ \\mu\\mathrm{m}) \\cdot (0.95)}{0.520 \\ \\mu\\mathrm{m}}\n$$\n长度单位 ($\\mu\\mathrm{m}$) 被抵消，留下一个符合预期的无量纲放大系数。\n$$\nM_{\\min} = \\frac{26 \\cdot 0.95}{0.520} = \\frac{24.7}{0.520} = 47.5\n$$\n根据要求四舍五入到四位有效数字，所需的最小放大倍率为 $M_{\\min} = 47.50$。\n\n#### 像素合并的作用\n像素合并 (Pixel binning) 是一种相机操作，即在读出之前，将一个 $N \\times N$ 相邻像素组的电荷在芯片上求和，从而创建一个“超级像素”。例如，$2 \\times 2$ 合并会产生一个等效间距为 $2p$ 的超级像素。这会将样本上的等效采样间隔增加到 $\\Delta x_{\\text{eff, binned}} = (N \\cdot p) / M$。由于当前系统已经是欠采样的（$\\Delta x_{\\text{eff}}$ 太大），通过像素合并增加等效像素间距只会使欠采样情况变得更糟。因此，像素合并对于解决欠采样问题是适得其反的；它通常在系统过采样时，以牺牲空间分辨率为代价来提高信噪比或帧率。\n\n#### 实用的放大倍率调整\n计算出的所需最小放大倍率为 $M_{\\min} = 47.50$。标准的显微镜物镜通常以离散的放大倍率提供（例如，$40\\times, 60\\times, 100\\times$）。定制一个 $47.5\\times$ 的物镜不是一个实用的选择。一个实用的解决方案是使用现有组件将总放大倍率提高到该最小值以上。两种常见的方法是：\n1.  将 $40\\times$ 物镜更换为下一个标准的更高放大倍率的物镜，通常是 $60\\times$ 物镜。这将产生 $M=60$ 的总放大倍率，大于 $M_{\\min}=47.50$，从而满足奈奎斯特准则（并导致过采样）。\n2.  在光路中插入一个中间变倍器（通常称为 Optovar 或变焦体）。例如，将现有的 $40\\times$ 物镜与一个 $1.25\\times$ 的变倍器一起使用，会产生 $M = 40 \\times 1.25 = 50$ 的总放大倍率，这也满足要求。\n\n两种方法都是满足采样要求的实用方式。更换为 $60\\times$ 物镜是一种常见且直接的解决方案。",
            "answer": "$$\\boxed{47.50}$$"
        },
        {
            "introduction": "成像硬件优化后，下一步是验证生物学实验本身。一个稳健的实验必须在阳性对照和阴性对照之间提供清晰可靠的区分。$Z'$ 因子（Z'-factor）是量化实验质量及其是否适用于高通量筛选的黄金标准。这项练习模拟了转化医学研究中的一个常见挑战——实验体系的小型化——并要求您计算 $Z'$ 因子来评估其实验性能，进而设计策略（例如通过增加技术重复）来将其提升至可接受的水平。",
            "id": "5020647",
            "problem": "一个转化医学团队正在将一项高内涵筛选 (HCS) 实验从 $384$ 孔板微型化至 $1536$ 孔板规格，并采用自动化细胞成像技术。在 $384$ 孔板平台上，观测到的对照组读数满足以下条件：\n- 阳性对照组均值 $\\,\\mu_{p} = 8500\\,$ 任意荧光单位 (AFU)，样本方差 $\\,s_{p}^{2} = 6.4 \\times 10^{5}\\,$ AFU$^{2}$。\n- 阴性对照组均值 $\\,\\mu_{n} = 2500\\,$ AFU，样本方差 $\\,s_{n}^{2} = 3.6 \\times 10^{5}\\,$ AFU$^{2}$。\n\n微型化减少了孔体积和光子计数，导致在转移到 $1536$ 孔板规格时，两个对照组的方差膨胀因子均为 $\\,\\alpha = 1.44\\,$；假设对照组的均值不受微型化影响。自动化细胞成像技术为每个对照条件采集 $R$ 个独立的技术重复孔，并使用它们的算术平均值作为对照组读数，用于实验质量评估。假设重复孔是独立同分布的，并且对每个对照组的 $R$ 个独立孔进行平均可得到该对照组的均值读数。\n\n使用筛选实验质量评估中 $Z'$ 因子的标准定义，以及信号窗口的如下定义：“信号窗口”是指阳性对照组的下三倍标准差界限（$\\,\\mu_{p} - 3\\sigma_{p}\\,$）与阴性对照组的上三倍标准差界限（$\\,\\mu_{n} + 3\\sigma_{n}\\,$）之间的差值，以 AFU 为单位，即它们之间的间隔。请基于此回答以下关于微型化（$1536$ 孔板）规格的问题：\n\n1) 当 $R = 1$ 时，计算 $Z'$。\n\n2) 当 $R = 1$ 时，计算信号窗口（以 AFU 为单位）。\n\n3) 确定最小的整数 $R$，使得微型化规格下得到的 $Z'$ 满足 $Z' \\ge 0.5$。\n\n将 $Z'$ 报告为无量纲数，信号窗口以 AFU 为单位报告。将 $Z'$ 和信号窗口的值四舍五入至四位有效数字。将所需的重复次数 $R$ 报告为满足条件的最小整数。",
            "solution": "该问题已经过验证，被确定为实验质量控制领域中一个适定且有科学依据的问题。它为求得唯一解提供了所有必要的数据和定义。\n\n首先，我们确定微型化 $1536$ 孔板实验的参数。问题中给出了 $384$ 孔板规格的参数以及针对 $1536$ 孔板规格的变更。\n\n给定的 $384$ 孔板规格参数如下：\n- 阳性对照组均值：$\\mu_{p,384} = 8500$ AFU\n- 阳性对照组样本方差：$s_{p,384}^{2} = 6.4 \\times 10^{5}$ AFU$^{2}$\n- 阴性对照组均值：$\\mu_{n,384} = 2500$ AFU\n- 阴性对照组样本方差：$s_{n,384}^{2} = 3.6 \\times 10^{5}$ AFU$^{2}$\n\n对于 $1536$ 孔板规格，均值保持不变，方差被因子 $\\alpha = 1.44$ 放大。计算 $Z'$ 因子所需的总体标准差 $\\sigma$ 从这些方差中导出。我们将给定的样本方差视为单个孔测量的总体方差。\n\n$1536$ 孔板规格的均值为：\n$\\mu_p = \\mu_{p,384} = 8500$ AFU\n$\\mu_n = \\mu_{n,384} = 2500$ AFU\n\n在 $1536$ 孔板规格中，单个孔（$R=1$）的方差为：\n$\\sigma_{p,1}^2 = \\alpha \\cdot s_{p,384}^{2} = 1.44 \\times (6.4 \\times 10^{5}) = 9.216 \\times 10^{5}$ AFU$^{2}$\n$\\sigma_{n,1}^2 = \\alpha \\cdot s_{n,384}^{2} = 1.44 \\times (3.6 \\times 10^{5}) = 5.184 \\times 10^{5}$ AFU$^{2}$\n\n单个孔（$R=1$）的相应标准差为：\n$\\sigma_{p,1} = \\sqrt{9.216 \\times 10^{5}} = 960$ AFU\n$\\sigma_{n,1} = \\sqrt{5.184 \\times 10^{5}} = 720$ AFU\n\n$Z'$ 因子的标准公式为：\n$$Z' = 1 - \\frac{3(\\sigma_p + \\sigma_n)}{|\\mu_p - \\mu_n|}$$\n其中 $\\mu_p$ 和 $\\mu_n$ 是阳性与阴性对照组的均值，$\\sigma_p$ 和 $\\sigma_n$ 是它们各自的标准差。\n\n1) 当 $R=1$ 时，我们使用单个孔的标准差计算 $Z'$。\n$$Z'_{R=1} = 1 - \\frac{3(\\sigma_{p,1} + \\sigma_{n,1})}{|\\mu_p - \\mu_n|} = 1 - \\frac{3(960 + 720)}{|8500 - 2500|}$$\n$$Z'_{R=1} = 1 - \\frac{3(1680)}{6000} = 1 - \\frac{5040}{6000} = 1 - 0.84 = 0.16$$\n四舍五入到四位有效数字，$Z'_{R=1} = 0.1600$。\n\n2) 当 $R=1$ 时，我们计算信号窗口。问题将信号窗口定义为阳性对照组的下三倍标准差界限与阴性对照组的上三倍标准差界限之差。\n$$\\text{Signal Window} = (\\mu_p - 3\\sigma_p) - (\\mu_n + 3\\sigma_n)$$\n这可以重新排列为：\n$$\\text{Signal Window} = (\\mu_p - \\mu_n) - 3(\\sigma_p + \\sigma_n)$$\n使用 $R=1$ 的参数：\n$$\\text{Signal Window}_{R=1} = (8500 - 2500) - 3(960 + 720)$$\n$$\\text{Signal Window}_{R=1} = 6000 - 3(1680) = 6000 - 5040 = 960 \\text{ AFU}$$\n四舍五入到四位有效数字，信号窗口为 $960.0$ AFU。信号窗口为负或较小（如本例所示）表明对照组的 $3\\sigma$ 分布存在重叠，这与极低的 $Z'$ 因子相符。\n\n3) 我们必须找到最小的整数重复数 $R$，使得最终的 $Z' \\ge 0.5$。当对 $R$ 个独立同分布的孔取平均值时，平均读数的均值仍为 $\\mu$，但其标准差变为 $\\frac{\\sigma}{\\sqrt{R}}$。\n\n因此，对于给定的 $R$，标准差变为：\n$\\sigma_{p,R} = \\frac{\\sigma_{p,1}}{\\sqrt{R}} = \\frac{960}{\\sqrt{R}}$\n$\\sigma_{n,R} = \\frac{\\sigma_{n,1}}{\\sqrt{R}} = \\frac{720}{\\sqrt{R}}$\n\n$Z'$ 因子作为 $R$ 的函数为：\n$$Z'(R) = 1 - \\frac{3(\\sigma_{p,R} + \\sigma_{n,R})}{|\\mu_p - \\mu_n|} = 1 - \\frac{3\\left(\\frac{960}{\\sqrt{R}} + \\frac{720}{\\sqrt{R}}\\right)}{|8500 - 2500|}$$\n$$Z'(R) = 1 - \\frac{3\\left(\\frac{1680}{\\sqrt{R}}\\right)}{6000} = 1 - \\frac{5040}{6000\\sqrt{R}} = 1 - \\frac{0.84}{\\sqrt{R}}$$\n我们设定条件 $Z'(R) \\ge 0.5$：\n$$1 - \\frac{0.84}{\\sqrt{R}} \\ge 0.5$$\n$$0.5 \\ge \\frac{0.84}{\\sqrt{R}}$$\n$$\\sqrt{R} \\ge \\frac{0.84}{0.5}$$\n$$\\sqrt{R} \\ge 1.68$$\n$$R \\ge (1.68)^2$$\n$$R \\ge 2.8224$$\n由于 $R$ 必须是整数，满足此不等式的最小整数 $R$ 值为 $3$。\n\n所求的三个值是：\n- 当 $R=1$ 时的 $Z'$：$0.1600$\n- 当 $R=1$ 时的信号窗口：$960.0$ AFU\n- 使 $Z' \\ge 0.5$ 的最小整数 $R$：$3$",
            "answer": "$$\\boxed{\\begin{pmatrix} 0.1600  960.0  3 \\end{pmatrix}}$$"
        },
        {
            "introduction": "高内涵筛选会产生巨大而复杂的数据集，每个细胞都会测量数十甚至数百个定量特征。分析这些高维数据以揭示有意义的生物学模式，是流程的最后一步。主成分分析（Principal Component Analysis, PCA）是一种强大的降维技术，它将相关的特征转化为一组较小的、不相关的变量，从而简化复杂数据集。这项高级实践指导您构建一个完整的PCA工作流程，从数据生成到成分选择，以及最关键的生物学解释，从而学会如何将数学结果转化为可操作的生物学见解。",
            "id": "5020616",
            "problem": "您正在为主成分分析（PCA）开发一个可复现的分析程序，以支持转化医学中自动化细胞成像的高内涵筛选（HCS）。该特征集由从荧光显微镜中提取的标准化单细胞形态学和强度描述符组成，例如核面积、周长、染色质纹理、细胞质强度、线粒体斑点和全细胞形态学。该程序必须从特征矩阵中计算主成分，使用基于碎石图的肘部法则和累积方差阈值来选择要保留的成分数量，并通过预定义的类别映射从生物学角度解释主成分载荷。由于特征被标准化为按列的 $z$-分数，本问题中的所有量都是无量纲的。\n\nPCA 的起点和定义：\n- 给定一个包含 $n$ 个观测值和 $d$ 个特征的数据矩阵 $X \\in \\mathbb{R}^{n \\times d}$，通过按列中心化和缩放以达到零均值和单位方差来构建标准化矩阵 $Z$。也就是说，如果 $\\mu_j$ 和 $\\sigma_j$ 表示第 $j$ 列的样本均值和标准差，则 $Z_{ij} = (X_{ij} - \\mu_j)/\\sigma_j$。\n- 计算样本协方差矩阵 $S = \\frac{1}{n-1} Z^\\top Z \\in \\mathbb{R}^{d \\times d}$。\n- 计算特征分解 $S = V \\Lambda V^\\top$，其中 $\\Lambda = \\mathrm{diag}(\\lambda_1, \\ldots, \\lambda_d)$ 且 $\\lambda_1 \\ge \\lambda_2 \\ge \\cdots \\ge \\lambda_d \\ge 0$，$V = [v_1, \\ldots, v_d]$ 具有标准正交的特征向量。第 $j$ 个主成分方向是 $v_j$，第 $j$ 个成分的方差解释率为 $p_j = \\lambda_j / \\left(\\sum_{k=1}^d \\lambda_k\\right)$。截至 $k$ 个成分的累积方差解释率为 $C_k = \\sum_{j=1}^k p_j$。\n\n选择规则：\n- 通过碎石图确定肘部：定义连续下降量 $\\Delta_j = \\lambda_j - \\lambda_{j+1}$，其中 $j \\in \\{1, \\ldots, d-1\\}$。定义肘部计数 $k_{\\mathrm{elbow}} = \\arg\\max_{j \\in \\{1, \\ldots, d-1\\}} \\Delta_j$。这可以解释为：保留 $k_{\\mathrm{elbow}}$ 个成分，因为最大的下降发生在第 $k_{\\mathrm{elbow}}$ 个成分和第 $k_{\\mathrm{elbow}} + 1$ 个成分之间。\n- 累积方差阈值：对于给定的阈值 $\\tau \\in (0, 1)$，定义 $k_{\\tau}$ 为满足 $C_{k_{\\tau}} \\ge \\tau$ 的最小正整数。\n- 联合选择：定义 $k_{\\mathrm{select}} = \\max\\{k_{\\mathrm{elbow}}, k_{\\tau}\\}$ 以同时满足两个标准。\n\n载荷的解释：\n- 设特征索引集为 $\\{0, 1, 2, 3, 4, 5, 6, 7\\}$，其生物学类别映射到整数代码如下：\n  - 核大小：代码 $1$ 对应索引 $0$ (核面积) 和 $1$ (核周长)。\n  - 核形状：代码 $2$ 对应索引 $2$ (核偏心率)。\n  - 染色质纹理：代码 $3$ 对应索引 $3$ (染色质纹理能量)。\n  - 细胞质强度：代码 $4$ 对应索引 $4$ (细胞质平均强度)。\n  - 线粒体斑点：代码 $5$ 对应索引 $5$ (线粒体斑点计数)。\n  - 全细胞形态学：代码 $6$ 对应索引 $6$ (细胞面积) 和 $7$ (细胞圆度)。\n- 对于主成分 $j \\in \\{1, 2\\}$，设 $v_j \\in \\mathbb{R}^d$ 为其载荷向量。计算绝对载荷 $a_{j,\\ell} = |(v_j)_\\ell|$，其中 $\\ell \\in \\{0, \\ldots, 7\\}$。设 $m$ 为一个不大于 $d$ 的给定正整数。识别出与 $m$ 个最大 $a_{j,\\ell}$ 值相对应的 $m$ 个索引的集合 $T_j$。将这些索引映射到它们的类别代码，计算 $T_j$ 中每个类别的频率，并选择频率最高的类别作为成分 $j$ 的解释。如果频率出现平局，则通过在平局类别中 $a_{j,\\ell}$ 的最大总和来打破平局。如果仍然平局，则选择最小的类别代码。\n\n您必须实现一个完整的程序，该程序能够：\n- 使用指定的种子、样本大小和载荷结构，通过固定的生成模型构建类似 HCS 的合成数据集，然后将特征按列标准化为 $z$-分数。\n- 根据上述定义，通过样本协方差的特征分解从第一性原理执行 PCA。\n- 计算给定 $\\tau$ 下的 $k_{\\mathrm{elbow}}$ 和 $k_{\\tau}$，以及 $k_{\\mathrm{select}} = \\max\\{k_{\\mathrm{elbow}}, k_{\\tau}\\}$。\n- 使用上述类别映射和规则，并结合给定的 $m$ 值，解释前两个主成分。\n- 每个测试用例返回一个数字摘要，格式为 $[k_{\\mathrm{select}}, k_{\\mathrm{elbow}}, k_{\\tau}, C_{k_{\\mathrm{select}}}, \\mathrm{PC1\\_cat}, \\mathrm{PC2\\_cat}]$，其中 $C_{k_{\\mathrm{select}}}$ 是在 $k_{\\mathrm{select}}$ 处的累积方差解释率，四舍五入到六位小数，$\\mathrm{PC1\\_cat}$ 和 $\\mathrm{PC2\\_cat}$ 分别是第一和第二主成分的整数类别代码。\n\n测试套件和数据生成：\n- 使用三个测试用例。在所有情况下，生成潜因子 $Z \\in \\mathbb{R}^{n \\times r}$，其条目独立地从标准正态分布中抽取；并生成噪声 $E \\in \\mathbb{R}^{n \\times d}$，其条目独立地从均值为 $0$、标准差为 $\\sigma$ 的正态分布中抽取。观测数据矩阵为 $X = Z B + E$，其中 $B \\in \\mathbb{R}^{r \\times d}$ 是一个指定的载荷结构。必须通过给定的种子，使用 NumPy 默认随机数生成器来控制伪随机性，以确保可复现性。生成 $X$ 后，在进行 PCA 之前，将每列标准化为零均值和单位方差。\n- 对所有用例，（按特征索引的）类别映射向量固定为 $[1, 1, 2, 3, 4, 5, 6, 6]$。\n\n三个用例如下：\n- 用例 A (具有清晰低维结构的理想路径)：\n  - 种子 $12345$，$n = 60$，$d = 8$，$r = 3$，噪声标准差 $\\sigma = 0.3$，阈值 $\\tau = 0.85$，$m = 3$。\n  - 使用载荷矩阵\n    $$\n    B_{\\mathrm{A}} =\n    \\begin{bmatrix}\n    0.9  0.8  0.2  0.0  0.1  0.0  1.0  -0.1 \\\\\n    0.0  0.1  0.0  -0.7  1.1  0.0  0.0  \\;\\;0.0 \\\\\n    0.0  0.0  0.6  0.0  0.0  0.9  0.2  -0.5\n    \\end{bmatrix}.\n    $$\n- 用例 B (具有弱结构的近各向同性；测试肘部稳定性和高阈值)：\n  - 种子 $2468$，$n = 50$，$d = 8$，$r = 3$，噪声标准差 $\\sigma = 0.8$，阈值 $\\tau = 0.90$，$m = 3$。\n  - 使用载荷矩阵\n    $$\n    B_{\\mathrm{B}} =\n    \\begin{bmatrix}\n    0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2 \\\\\n    0.1  -0.1  0.1  -0.1  0.1  -0.1  0.1  -0.1 \\\\\n    0.0  0.1  -0.1  0.0  0.1  -0.1  0.0  0.1\n    \\end{bmatrix}.\n    $$\n- 用例 C (小样本，冗余形态学；测试通过特征分解处理奇异协方差)：\n  - 种子 $31415$，$n = 10$，$d = 8$，$r = 2$，噪声标准差 $\\sigma = 0.2$，阈值 $\\tau = 0.70$，$m = 3$。\n  - 使用载荷矩阵\n    $$\n    B_{\\mathrm{C}} =\n    \\begin{bmatrix}\n    1.0  0.9  0.0  0.0  0.4  0.0  1.0  0.0 \\\\\n    0.0  0.0  0.6  -0.5  0.0  0.5  0.0  -0.6\n    \\end{bmatrix}.\n    $$\n\n角度单位不适用。所有报告的分数（如方差解释率）必须以小数形式给出，而不是百分比。最终输出格式要求如下。您的程序应生成单行输出，其中包含一个由方括号括起来的逗号分隔列表形式的结果，每个测试用例的结果本身是一个列表，顺序为 $[k_{\\mathrm{select}}, k_{\\mathrm{elbow}}, k_{\\tau}, C_{k_{\\mathrm{select}}}, \\mathrm{PC1\\_cat}, \\mathrm{PC2\\_cat}]$。例如，打印的行必须类似于 $[[x_1,x_2,x_3,x_4,x_5,x_6],[y_1,y_2,y_3,y_4,y_5,y_6],[z_1,z_2,z_3,z_4,z_5,z_6]]$，不含空格，并且每个用例的 $C_{k_{\\mathrm{select}}}$ 都四舍五入到六位小数。",
            "solution": "该解决方案从主成分分析 (PCA) 的核心定义、样本协方差的特征分解以及将载荷映射到生物学类别的可解释方法入手。该场景通过使用源自核形态学、染色质纹理、细胞质强度、线粒体斑点和全细胞形态学的特征，反映了高内涵筛选 (HCS) 和自动化细胞成像的应用，这与转化医学中降维辅助表型分析的应用相一致。\n\n第 1 步（标准化）：给定 $X \\in \\mathbb{R}^{n \\times d}$，通过 $Z_{ij} = (X_{ij} - \\mu_j)/\\sigma_j$ 构建 $z$-分数矩阵 $Z$，其中 $\\mu_j$ 是经验均值 $\\mu_j = \\frac{1}{n} \\sum_{i=1}^n X_{ij}$，$\\sigma_j$ 是经验标准差 $\\sigma_j = \\sqrt{\\frac{1}{n} \\sum_{i=1}^n (X_{ij} - \\mu_j)^2}$。此步骤消除了异构 HCS 特征之间的尺度差异。\n\n第 2 步（样本协方差）：计算 $S = \\frac{1}{n-1} Z^\\top Z$。当列已中心化时，这直接源于无偏样本协方差矩阵的定义。由于 $Z$ 是标准化的，其方差是无量纲的。\n\n第 3 步（特征分解和方差解释率）：通过求解 $S v_j = \\lambda_j v_j$ 来计算 $S$ 的特征值和特征向量，其中 $\\lambda_1 \\ge \\lambda_2 \\ge \\cdots \\ge \\lambda_d \\ge 0$ 且 $v_j^\\top v_k = \\delta_{jk}$。主轴是特征向量 $\\{v_j\\}_{j=1}^d$。方差解释率为 $p_j = \\lambda_j / \\left(\\sum_{k=1}^d \\lambda_k\\right)$，累积方差解释率为 $C_k = \\sum_{j=1}^k p_j$。此推导基于对称矩阵的谱定理以及 PCA 作为在正交性约束下最大化投影数据方差的解的定义。\n\n第 4 步（碎石图肘部选择）：在碎石图上，肘部对应于特征值的最大离散下降。定义 $\\Delta_j = \\lambda_j - \\lambda_{j+1}$，其中 $j \\in \\{1, \\ldots, d-1\\}$。肘部成分计数为 $k_{\\mathrm{elbow}} = \\arg\\max_j \\Delta_j$，这表明最大的方差损失发生在从 $k_{\\mathrm{elbow}}$ 过渡到 $k_{\\mathrm{elbow}} + 1$ 时，因此应保留 $k_{\\mathrm{elbow}}$ 个成分。\n\n第 5 步（阈值选择）：给定一个阈值 $\\tau \\in (0, 1)$，定义 $k_{\\tau} = \\min\\{k \\in \\{1, \\ldots, d\\} : C_k \\ge \\tau\\}$。这确保了保留的成分至少解释了总方差的 $\\tau$ 比例。\n\n第 6 步（联合选择）：通过取 $k_{\\mathrm{select}} = \\max\\{k_{\\mathrm{elbow}}, k_{\\tau}\\}$ 来同时满足两个标准。\n\n第 7 步（载荷的生物学解释）：对于主成分 $j \\in \\{1, 2\\}$，计算 $a_{j,\\ell} = |(v_j)_\\ell|$，其中 $\\ell \\in \\{0, \\ldots, 7\\}$，选择 $m$ 个最大 $a_{j,\\ell}$ 值的索引集 $T_j$，并根据提供的映射向量 $[1, 1, 2, 3, 4, 5, 6, 6]$ 将 $T_j$ 中的每个索引映射到一个类别代码。通过多数计数来确定成分 $j$ 的类别；通过平局类别中最大的累积绝对载荷来打破平局；如果仍然平局，则选择最小的代码。这个过程形式化了 PCA 载荷如何与生物学领域相关联（例如，如果核面积、核周长和细胞面积在一个成分中占主导地位，那么它就与核大小或全细胞形态学相关联）。\n\n第 8 步（测试用例的数据生成）：对于每个用例，生成具有独立标准正态条目的 $Z \\in \\mathbb{R}^{n \\times r}$ 和具有均值为 $0$、标准差为 $\\sigma$ 的独立正态条目的 $E \\in \\mathbb{R}^{n \\times d}$。使用为该用例指定的 $B$ 以及给定的 $n、d、r、\\sigma$ 和种子来构成 $X = Z B + E$。将 $X$ 按列标准化为 $Z$-分数，并应用第 2 步到第 7 步。种子确保了可复现的、反映不同表型结构的合成类 HCS 数据。\n\n第 9 步（输出）：对于每个用例，计算并返回 $[k_{\\mathrm{select}}, k_{\\mathrm{elbow}}, k_{\\tau}, C_{k_{\\mathrm{select}}}, \\mathrm{PC1\\_cat}, \\mathrm{PC2\\_cat}]$。累积方差解释率 $C_{k_{\\mathrm{select}}}$ 必须四舍五入到六位小数。将三个用例的结果汇总成单行，格式为 $[[\\cdot],[\\cdot],[\\cdot]]$，不含空格。\n\n算法说明：\n- $S$ 的特征值通过构造是非负的，因为 $S$ 是对称半正定矩阵。\n- 按降序对特征值进行排序，可以按照方差解释率递减的顺序排列成分，这符合 PCA 的定义要求。\n- 通过 $\\arg\\max \\Delta_j$ 定义的肘部捕捉了与碎石图肘部一致的最大离散曲率变化，而无需显式绘图。\n- 标准化在 HCS 中至关重要，因为面积、强度和纹理等特征天然具有不同的尺度；$z$-分数评分强制实现了可比性。\n- 类别映射使得生物学解释的定量编码成为可能，同时输出按要求保持为数字形式。\n\n所提供的程序仅使用 NumPy 为指定的测试套件实现了上述步骤，确保在给定种子下产生确定性的输出。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef standardize_zscore(X: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Column-wise z-score standardization.\n    Returns a matrix with zero-mean, unit-variance columns.\n    \"\"\"\n    means = X.mean(axis=0)\n    stds = X.std(axis=0)\n    # Prevent division by zero: if std is zero, set to 1 (feature has no variation).\n    stds_safe = np.where(stds == 0, 1.0, stds)\n    Z = (X - means) / stds_safe\n    return Z\n\ndef pca_from_cov(Z: np.ndarray):\n    \"\"\"\n    Compute PCA via the sample covariance eigen-decomposition.\n    Returns eigenvalues (descending) and eigenvectors (columns correspond to components).\n    \"\"\"\n    n = Z.shape[0]\n    # Sample covariance with unbiased denominator (n-1)\n    S = (Z.T @ Z) / (n - 1)\n    # eigh returns ascending eigenvalues; we reverse order.\n    evals, evecs = np.linalg.eigh(S)\n    idx = np.argsort(evals)[::-1]\n    evals_sorted = evals[idx]\n    evecs_sorted = evecs[:, idx]\n    return evals_sorted, evecs_sorted\n\ndef explained_variance_ratio(evals: np.ndarray) -> np.ndarray:\n    total = np.sum(evals)\n    if total == 0:\n        # Edge case: if total variance is zero, return zeros\n        return np.zeros_like(evals)\n    return evals / total\n\ndef elbow_k_from_drops(evals: np.ndarray) -> int:\n    \"\"\"\n    Compute elbow count k via max successive drop in eigenvalues.\n    If d components, drops length is d-1; choose k = argmax(drop) + 1 (1-based count).\n    \"\"\"\n    if len(evals) <= 1:\n        return 1\n    drops = evals[:-1] - evals[1:]\n    # In rare cases of equal drops, np.argmax returns the first max index as desired.\n    k = int(np.argmax(drops)) + 1\n    # Ensure at least 1 and at most d\n    k = max(1, min(k, len(evals)))\n    return k\n\ndef kth_for_threshold(evr: np.ndarray, tau: float) -> int:\n    cum = np.cumsum(evr)\n    # Find smallest k with cum >= tau\n    for i, c in enumerate(cum, start=1):\n        if c >= tau:\n            return i\n    return len(evr)\n\ndef interpret_pc_loading_category(evecs: np.ndarray, pc_index: int, m: int, category_map: list) -> int:\n    \"\"\"\n    Interpret the pc_index-th component (0-based) by selecting top-m absolute loadings,\n    mapping to categories, picking majority, then tie-breaking by sum of abs loadings,\n    then by smallest category code.\n    \"\"\"\n    v = evecs[:, pc_index]\n    abs_load = np.abs(v)\n    d = abs_load.shape[0]\n    m_eff = min(m, d)\n    top_idx = np.argsort(abs_load)[::-1][:m_eff]\n    # Count frequency per category and sum of loadings per category among top-m\n    counts = {}\n    weight_sums = {}\n    for idx in top_idx:\n        cat = category_map[idx]\n        counts[cat] = counts.get(cat, 0) + 1\n        weight_sums[cat] = weight_sums.get(cat, 0.0) + float(abs_load[idx])\n    # Determine majority\n    max_count = max(counts.values())\n    candidates = [cat for cat, cnt in counts.items() if cnt == max_count]\n    if len(candidates) == 1:\n        return candidates[0]\n    # Tie-break by largest cumulative absolute loading\n    max_weight = max(weight_sums[cat] for cat in candidates)\n    candidates2 = [cat for cat in candidates if weight_sums[cat] == max_weight]\n    if len(candidates2) == 1:\n        return candidates2[0]\n    # Final tie-break: smallest code\n    return int(min(candidates2))\n\ndef generate_data(seed: int, n: int, d: int, B: np.ndarray, sigma: float) -> np.ndarray:\n    \"\"\"\n    Generate synthetic data X = Z B + E with Z ~ N(0,1)^(n x r), E ~ N(0, sigma^2)^(n x d).\n    \"\"\"\n    rng = np.random.default_rng(seed)\n    r = B.shape[0]\n    Z = rng.normal(loc=0.0, scale=1.0, size=(n, r))\n    E = rng.normal(loc=0.0, scale=sigma, size=(n, d))\n    X = Z @ B + E\n    return X\n\ndef format_nested_list_no_spaces(obj):\n    \"\"\"\n    Format nested lists of ints/floats into a string with no spaces, brackets and commas only.\n    Floats are formatted with up to 6 decimal places when they are the cumulative variance values;\n    since we control creation of lists, we will pre-round those floats before passing here.\n    \"\"\"\n    if isinstance(obj, list):\n        return \"[\" + \",\".join(format_nested_list_no_spaces(x) for x in obj) + \"]\"\n    elif isinstance(obj, (int, np.integer)):\n        return str(int(obj))\n    elif isinstance(obj, (float, np.floating)):\n        # Preserve decimal representation as is (assumed pre-rounded if needed)\n        # Ensure standard Python float formatting without scientific notation for small values\n        s = f\"{float(obj)}\"\n        return s\n    else:\n        # Fallback: convert to string\n        return str(obj)\n\ndef solve():\n    # Category mapping by feature index (0..7):\n    # [0:Nuclear area, 1:Nuclear perimeter, 2:Nuclear eccentricity, 3:Chromatin texture energy,\n    #  4:Cytoplasm mean intensity, 5:Mitochondrial puncta count, 6:Cell area, 7:Cell roundness]\n    category_map = [1, 1, 2, 3, 4, 5, 6, 6]\n\n    # Define test cases: (seed, n, d, B, sigma, tau, m)\n    B_A = np.array([\n        [0.9, 0.8, 0.2, 0.0, 0.1, 0.0, 1.0, -0.1],\n        [0.0, 0.1, 0.0, -0.7, 1.1, 0.0, 0.0,  0.0],\n        [0.0, 0.0, 0.6, 0.0, 0.0, 0.9, 0.2, -0.5],\n    ], dtype=float)\n\n    B_B = np.array([\n        [0.2,  0.2,  0.2,  0.2,  0.2,  0.2,  0.2,  0.2],\n        [0.1, -0.1,  0.1, -0.1,  0.1, -0.1,  0.1, -0.1],\n        [0.0,  0.1, -0.1,  0.0,  0.1, -0.1,  0.0,  0.1],\n    ], dtype=float)\n\n    B_C = np.array([\n        [1.0, 0.9, 0.0,  0.0, 0.4, 0.0, 1.0,  0.0],\n        [0.0, 0.0, 0.6, -0.5, 0.0, 0.5, 0.0, -0.6],\n    ], dtype=float)\n\n    test_cases = [\n        # Case A\n        {\n            \"seed\": 12345,\n            \"n\": 60,\n            \"d\": 8,\n            \"B\": B_A,\n            \"sigma\": 0.3,\n            \"tau\": 0.85,\n            \"m\": 3\n        },\n        # Case B\n        {\n            \"seed\": 2468,\n            \"n\": 50,\n            \"d\": 8,\n            \"B\": B_B,\n            \"sigma\": 0.8,\n            \"tau\": 0.90,\n            \"m\": 3\n        },\n        # Case C\n        {\n            \"seed\": 31415,\n            \"n\": 10,\n            \"d\": 8,\n            \"B\": B_C,\n            \"sigma\": 0.2,\n            \"tau\": 0.70,\n            \"m\": 3\n        },\n    ]\n\n    results = []\n    for case in test_cases:\n        X = generate_data(case[\"seed\"], case[\"n\"], case[\"d\"], case[\"B\"], case[\"sigma\"])\n        Z = standardize_zscore(X)\n        evals, evecs = pca_from_cov(Z)\n        evr = explained_variance_ratio(evals)\n\n        # Elbow k via successive drop in eigenvalues\n        k_elbow = elbow_k_from_drops(evals)\n        # Threshold k via cumulative explained variance\n        k_tau = kth_for_threshold(evr, case[\"tau\"])\n        # Combined selection\n        k_select = max(k_elbow, k_tau)\n        # Cumulative explained variance at k_select\n        cum_evr = float(np.sum(evr[:k_select]))\n        cum_evr_rounded = float(f\"{cum_evr:.6f}\")\n\n        # Interpret PC1 and PC2\n        pc1_cat = interpret_pc_loading_category(evecs, pc_index=0, m=case[\"m\"], category_map=category_map)\n        pc2_cat = interpret_pc_loading_category(evecs, pc_index=1, m=case[\"m\"], category_map=category_map)\n\n        result = [int(k_select), int(k_elbow), int(k_tau), cum_evr_rounded, int(pc1_cat), int(pc2_cat)]\n        results.append(result)\n\n    # Final print statement in the exact required format (no spaces).\n    print(format_nested_list_no_spaces(results))\n\nif __name__ == \"__main__\":\n    solve()\n```"
        }
    ]
}