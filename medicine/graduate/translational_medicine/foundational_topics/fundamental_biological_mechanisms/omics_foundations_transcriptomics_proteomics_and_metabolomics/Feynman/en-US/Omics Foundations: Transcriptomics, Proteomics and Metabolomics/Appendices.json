{
    "hands_on_practices": [
        {
            "introduction": "A primary goal in translational medicine is the accurate quantification of biomarkers in complex biological matrices like blood plasma. However, instrument response and sample handling can introduce significant variability. This exercise demonstrates the gold-standard method for achieving robust quantification: internal standard calibration. By working through this problem, you will learn how to use a stable isotope-labeled internal standard and a set of calibration samples to build a linear regression model, assess its quality, and ultimately determine the precise concentration of a metabolite in an unknown sample—a foundational skill for any targeted metabolomics or proteomics assay .",
            "id": "5037023",
            "problem": "A targeted Liquid Chromatography–Tandem Mass Spectrometry (LC–MS/MS) assay is being validated in plasma for a small-molecule metabolite used as a translational biomarker. A stable isotope-labeled Internal Standard (IS) is spiked at a constant and known concentration $C_{\\mathrm{IS}}$ across all calibration and unknown samples to correct for matrix effects and instrument variability. In such assays, the peak area ratio $R$ defined as $R = \\frac{A_{\\mathrm{analyte}}}{A_{\\mathrm{IS}}}$ is widely observed to be linearly related to the concentration ratio $\\frac{C_{\\mathrm{analyte}}}{C_{\\mathrm{IS}}}$ over an appropriate dynamic range as determined empirically by calibration.\n\nYou prepare a calibration series with analyte concentrations $C_{\\mathrm{A},i}$ and measure the corresponding peak area ratios $R_i$ under identical conditions with a constant internal standard concentration $C_{\\mathrm{IS}} = 10$ µM. The calibration points are:\n- $C_{\\mathrm{A}} = 2$ µM, $R = 0.32$\n- $C_{\\mathrm{A}} = 4$ µM, $R = 0.49$\n- $C_{\\mathrm{A}} = 6$ µM, $R = 0.70$\n- $C_{\\mathrm{A}} = 8$ µM, $R = 0.89$\n- $C_{\\mathrm{A}} = 10$ µM, $R = 1.12$\n\nAn unknown plasma sample is processed identically and yields a peak area ratio $R_{\\mathrm{unknown}} = 0.756$. Assume a linear relationship between $R$ and $\\frac{C_{\\mathrm{A}}}{C_{\\mathrm{IS}}}$ over this range and estimate the calibration by Ordinary Least Squares (OLS). Starting from the principle that instrument response is proportional to analyte amount and using the internal standard to form ratios, derive the calibration equation $R = m \\left(\\frac{C_{\\mathrm{A}}}{C_{\\mathrm{IS}}}\\right) + b$ by OLS, compute the coefficient of determination (R-squared) $R^{2}$ for the calibration, and then compute the analyte concentration $C_{\\mathrm{A,unknown}}$ in the unknown sample.\n\nRound both the analyte concentration and $R^{2}$ to four significant figures. Express the analyte concentration in micromolar (µM). Report your final answer as two numbers in a single row in the order: analyte concentration, then $R^{2}$.",
            "solution": "The problem is valid as it describes a standard, scientifically sound procedure for quantitative bioanalysis using internal standard calibration and Ordinary Least Squares (OLS) regression. All necessary data and definitions are provided, and the problem is well-posed.\n\nThe fundamental principle of internal standard (IS) calibration in mass spectrometry is to correct for variations in sample preparation, injection volume, instrument response, and matrix effects. The instrument response, measured as peak area $A$, is assumed to be proportional to the concentration $C$ of the substance being measured. Thus, for the analyte and the internal standard, we have:\n$$ A_{\\mathrm{analyte}} = k_{\\mathrm{analyte}} C_{\\mathrm{analyte}} $$\n$$ A_{\\mathrm{IS}} = k_{\\mathrm{IS}} C_{\\mathrm{IS}} $$\nThe response factors, $k_{\\mathrm{analyte}}$ and $k_{\\mathrm{IS}}$, can fluctuate. The core assumption of using a stable isotope-labeled internal standard is that it behaves nearly identically to the analyte, meaning any fluctuation affects both proportionally. Therefore, the ratio of their response factors is constant. By taking the ratio of the peak areas, these fluctuations are cancelled out:\n$$ R = \\frac{A_{\\mathrm{analyte}}}{A_{\\mathrm{IS}}} = \\frac{k_{\\mathrm{analyte}}}{k_{\\mathrm{IS}}} \\frac{C_{\\mathrm{analyte}}}{C_{\\mathrm{IS}}} $$\nLetting $F = \\frac{k_{\\mathrm{analyte}}}{k_{\\mathrm{IS}}}$ be the relative response factor, we get $R = F \\left( \\frac{C_{\\mathrm{analyte}}}{C_{\\mathrm{IS}}} \\right)$. This describes an ideal linear relationship passing through the origin. In practice, a non-zero intercept $b$ is often included to account for background noise or other constant biases, leading to the empirical linear model stated in the problem:\n$$ R = m \\left(\\frac{C_{\\mathrm{A}}}{C_{\\mathrm{IS}}}\\right) + b $$\nHere, $m$ is the estimated relative response factor and $b$ is the intercept. We will determine $m$ and $b$ using Ordinary Least Squares (OLS) regression on the provided calibration data.\n\nLet $y_i = R_i$ and $x_i = \\frac{C_{\\mathrm{A},i}}{C_{\\mathrm{IS}}}$. The model is $y_i = m x_i + b$. The internal standard concentration is constant at $C_{\\mathrm{IS}} = 10 \\text{ µM}$. We first calculate the $x_i$ values for each calibration point:\nThe data for the regression are as follows, with $n=5$ points:\n\\begin{itemize}\n    \\item $x_1 = \\frac{2 \\text{ µM}}{10 \\text{ µM}} = 0.2$, $y_1 = 0.32$\n    \\item $x_2 = \\frac{4 \\text{ µM}}{10 \\text{ µM}} = 0.4$, $y_2 = 0.49$\n    \\item $x_3 = \\frac{6 \\text{ µM}}{10 \\text{ µM}} = 0.6$, $y_3 = 0.70$\n    \\item $x_4 = \\frac{8 \\text{ µM}}{10 \\text{ µM}} = 0.8$, $y_4 = 0.89$\n    \\item $x_5 = \\frac{10 \\text{ µM}}{10 \\text{ µM}} = 1.0$, $y_5 = 1.12$\n\\end{itemize}\n\nThe OLS formulas for the slope $m$ and intercept $b$ of the best-fit line $y = mx+b$ are:\n$$ m = \\frac{n(\\sum_{i=1}^{n} x_i y_i) - (\\sum_{i=1}^{n} x_i)(\\sum_{i=1}^{n} y_i)}{n(\\sum_{i=1}^{n} x_i^2) - (\\sum_{i=1}^{n} x_i)^2} $$\n$$ b = \\bar{y} - m\\bar{x} $$\nwhere $\\bar{x} = \\frac{1}{n}\\sum_{i=1}^{n} x_i$ and $\\bar{y} = \\frac{1}{n}\\sum_{i=1}^{n} y_i$.\n\nWe calculate the required sums:\n$$ \\sum x_i = 0.2 + 0.4 + 0.6 + 0.8 + 1.0 = 3.0 $$\n$$ \\sum y_i = 0.32 + 0.49 + 0.70 + 0.89 + 1.12 = 3.52 $$\n$$ \\sum x_i^2 = (0.2)^2 + (0.4)^2 + (0.6)^2 + (0.8)^2 + (1.0)^2 = 0.04 + 0.16 + 0.36 + 0.64 + 1.00 = 2.20 $$\n$$ \\sum y_i^2 = (0.32)^2 + (0.49)^2 + (0.70)^2 + (0.89)^2 + (1.12)^2 = 0.1024 + 0.2401 + 0.4900 + 0.7921 + 1.2544 = 2.879 $$\n$$ \\sum x_i y_i = (0.2)(0.32) + (0.4)(0.49) + (0.6)(0.70) + (0.8)(0.89) + (1.0)(1.12) = 0.064 + 0.196 + 0.420 + 0.712 + 1.120 = 2.512 $$\n\nNow, substitute these sums into the formulas for $m$ and $b$:\n$$ m = \\frac{5(2.512) - (3.0)(3.52)}{5(2.20) - (3.0)^2} = \\frac{12.56 - 10.56}{11.0 - 9.0} = \\frac{2.0}{2.0} = 1.0 $$\n$$ \\bar{x} = \\frac{3.0}{5} = 0.6 \\quad \\text{and} \\quad \\bar{y} = \\frac{3.52}{5} = 0.704 $$\n$$ b = 0.704 - (1.0)(0.6) = 0.104 $$\nThe calibration equation is $R = 1.0 \\left(\\frac{C_{\\mathrm{A}}}{C_{\\mathrm{IS}}}\\right) + 0.104$.\n\nNext, we calculate the coefficient of determination, $R^2$:\n$$ R^2 = \\frac{\\left[n(\\sum x_i y_i) - (\\sum x_i)(\\sum y_i)\\right]^2}{\\left[n(\\sum x_i^2) - (\\sum x_i)^2\\right]\\left[n(\\sum y_i^2) - (\\sum y_i)^2\\right]} $$\nPlugging in the calculated sums:\n$$ R^2 = \\frac{\\left[5(2.512) - (3.0)(3.52)\\right]^2}{\\left[5(2.20) - (3.0)^2\\right]\\left[5(2.879) - (3.52)^2\\right]} $$\n$$ R^2 = \\frac{(12.56 - 10.56)^2}{(11.0 - 9.0)(14.395 - 12.3904)} = \\frac{(2.0)^2}{(2.0)(2.0046)} = \\frac{4.0}{4.0092} \\approx 0.99770527... $$\nRounding to four significant figures, $R^2 = 0.9977$.\n\nFinally, we calculate the analyte concentration in the unknown sample, $C_{\\mathrm{A,unknown}}$. We are given $R_{\\mathrm{unknown}} = 0.756$. We rearrange the calibration equation to solve for $C_{\\mathrm{A,unknown}}$:\n$$ R_{\\mathrm{unknown}} = m \\left(\\frac{C_{\\mathrm{A,unknown}}}{C_{\\mathrm{IS}}}\\right) + b $$\n$$ \\frac{C_{\\mathrm{A,unknown}}}{C_{\\mathrm{IS}}} = \\frac{R_{\\mathrm{unknown}} - b}{m} $$\n$$ C_{\\mathrm{A,unknown}} = C_{\\mathrm{IS}} \\left( \\frac{R_{\\mathrm{unknown}} - b}{m} \\right) $$\nSubstituting the known values ($C_{\\mathrm{IS}} = 10$ µM, $R_{\\mathrm{unknown}} = 0.756$, $m = 1.0$, $b = 0.104$):\n$$ C_{\\mathrm{A,unknown}} = 10 \\left( \\frac{0.756 - 0.104}{1.0} \\right) = 10 (0.652) = 6.52 $$\nThe concentration is $6.52$ µM. The problem requires rounding to four significant figures, so the concentration is $6.520$ µM.\n\nThe two requested values are the analyte concentration, $C_{\\mathrm{A,unknown}}$, and the coefficient of determination, $R^2$.\n$C_{\\mathrm{A,unknown}} = 6.520$ µM\n$R^2 = 0.9977$",
            "answer": "$$ \\boxed{ \\begin{pmatrix} 6.520 & 0.9977 \\end{pmatrix} } $$"
        },
        {
            "introduction": "Moving from targeted quantification to large-scale discovery experiments, such as identifying thousands of proteins in a patient biopsy, introduces a new statistical challenge: managing false positives. Not every peptide identified by the mass spectrometer is a true match. This practice introduces the False Discovery Rate (FDR), the cornerstone for ensuring statistical rigor in high-throughput omics. You will apply the widely used target-decoy approach to estimate the number of incorrect identifications in a proteomics dataset and use this to determine the expected number of true discoveries, a critical step in quality control .",
            "id": "5036984",
            "problem": "A clinical translational proteomics study uses tandem mass spectrometry to identify peptides in patient biopsies. Spectra are searched against a concatenated target-decoy database of equal target and decoy sizes. The identification set at a fixed score threshold contains a total of $10{,}200$ peptide-spectrum matches (PSMs), partitioned as $10{,}000$ target PSMs and $200$ decoy PSMs. Assume the following foundational principles:\n- The false discovery rate (FDR) is defined as the expected proportion of false discoveries among all accepted discoveries, that is, if $V$ is the number of false discoveries and $R$ is the total number of accepted discoveries, then $\\mathrm{FDR} = \\mathbb{E}[V/R]$ for $R \\ge 1$.\n- In a concatenated target-decoy approach (TDA) with equal target and decoy search spaces and symmetric scoring behavior under incorrect matches, the number of accepted decoy PSMs above a threshold is an unbiased estimator for the number of incorrect target PSMs above that threshold.\n- The $q$-value of an accepted discovery is the minimum FDR threshold at which it would be included when varying the score cutoff from stringent to permissive.\n\nUsing only these principles as your starting point, derive the FDR estimate at the given score threshold, determine whether the identification set at this threshold satisfies a project requirement that $q \\le 0.02$, and, conditional on acceptance under this requirement, compute the expected number of true peptide identifications among the accepted target PSMs. Provide your final answer as a single number (no units). If any rounding is required, round to an exact integer count by logical deduction rather than by arbitrary rounding rules.",
            "solution": "The problem is validated as scientifically sound, well-posed, and objective. It is based on canonical principles of statistical analysis in mass spectrometry-based proteomics. All necessary data and definitions are provided. The problem is solvable as stated.\n\nThe solution proceeds by sequentially addressing the three tasks presented in the problem statement, based on the provided principles.\n\nLet $N_T$ denote the number of accepted target peptide-spectrum matches (PSMs) and $N_D$ denote the number of accepted decoy PSMs at the given score threshold. From the problem statement, we have:\n$$N_T = 10{,}000$$\n$$N_D = 200$$\n\nThe total number of PSMs above the threshold is $N_T + N_D = 10{,}000 + 200 = 10{,}200$, which is consistent with the provided total.\n\n**1. Derive the False Discovery Rate (FDR) estimate.**\n\nThe set of \"accepted discoveries\" for reporting in a proteomics experiment consists of the target PSMs only. The decoy PSMs are a statistical tool used to estimate the number of errors and are not considered discoveries themselves. Therefore, the total number of accepted discoveries, $R$, is equal to the number of accepted target PSMs.\n$$R = N_T = 10{,}000$$\n\nThe FDR is defined as $\\mathrm{FDR} = \\mathbb{E}[V/R]$, where $V$ is the number of false discoveries (i.e., incorrect target PSMs) and $R$ is the total number of accepted discoveries. Since the analysis is performed at a fixed score threshold, the number of accepted discoveries $R$ is a fixed quantity, $R = N_T$. The definition of FDR thus simplifies to:\n$$\\mathrm{FDR} = \\frac{\\mathbb{E}[V]}{R} = \\frac{\\mathbb{E}[V]}{N_T}$$\n\nThe problem states as a foundational principle that the number of accepted decoy PSMs, $N_D$, serves as an unbiased estimator for the number of incorrect target PSMs, $V$. This means that the expected value of $V$, $\\mathbb{E}[V]$, can be estimated by the observed value of $N_D$.\n$$\\widehat{\\mathbb{E}[V]} = N_D = 200$$\n\nAn estimator for the FDR, denoted $\\widehat{\\text{FDR}}$, can now be constructed by substituting the observed quantities into the FDR formula:\n$$\\widehat{\\text{FDR}} = \\frac{N_D}{N_T}$$\nSubstituting the given values:\n$$\\widehat{\\text{FDR}} = \\frac{200}{10{,}000} = 0.02$$\n\n**2. Determine if the identification set satisfies the project requirement.**\n\nThe project requirement is that the identifications have a $q$-value less than or equal to $0.02$. The problem defines the $q$-value of a discovery as the minimum FDR at which that discovery would be accepted. For a set of identifications passing a certain score threshold, the $\\widehat{\\text{FDR}}$ calculated for the entire set is the estimated $q$-value of the lowest-scoring identification in that set. All other identifications in the set, having higher scores, will have $q$-values less than or equal to this value.\n\nThus, the condition that all accepted PSMs have $q \\le 0.02$ is equivalent to the condition that the FDR of the entire set is less than or equal to $0.02$.\nWe must check if $\\widehat{\\text{FDR}} \\le 0.02$.\nOur calculated value is $\\widehat{\\text{FDR}} = 0.02$. The inequality $0.02 \\le 0.02$ is true. Therefore, the identification set satisfies the project requirement.\n\n**3. Compute the expected number of true peptide identifications.**\n\nThis computation is conditional on the set satisfying the project requirement, which it does.\nThe set of accepted target PSMs, of size $N_T$, is a mixture of true identifications (True Positives, or TP) and false identifications (False Positives, or FP).\n$$N_T = \\text{TP} + \\text{FP}$$\n\nThe number of false positives, FP, is precisely the quantity we have previously denoted as $V$, the number of false discoveries. We seek the expected number of true identifications, $\\mathbb{E}[\\text{TP}]$.\nFrom the above relation, we have $\\text{TP} = N_T - \\text{FP}$. Taking the expectation, and noting that $N_T$ is a fixed number:\n$$\\mathbb{E}[\\text{TP}] = N_T - \\mathbb{E}[\\text{FP}]$$\nAs established in step 1, the expected number of false positives, $\\mathbb{E}[\\text{FP}] = \\mathbb{E}[V]$, is estimated by the number of decoy hits, $N_D$.\n$$\\widehat{\\mathbb{E}[\\text{FP}]} = N_D = 200$$\nWe can now compute the expected number of true identifications by substituting the known and estimated values:\n$$\\mathbb{E}[\\text{TP}] \\approx N_T - N_D = 10{,}000 - 200 = 9{,}800$$\nThis result is an exact integer, as required by the problem's rounding instructions. The expected number of true peptide identifications among the accepted target PSMs is $9{,}800$.",
            "answer": "$$\\boxed{9800}$$"
        },
        {
            "introduction": "Biological tissues are rarely homogenous; they are complex mixtures of different cell types. A measurement from a tumor biopsy, for instance, reflects a combined signal from cancer cells, immune cells, and structural cells. This final practice tackles the challenge of computational deconvolution, a powerful technique to unmix these composite signals. Using a linear mixture model and Nonnegative Least Squares (NNLS), you will determine the relative proportions of two distinct cell types from an integrated multi-omic feature vector, providing a window into the cellular composition of the tissue sample .",
            "id": "5036998",
            "problem": "A microdissected spatial region from a human tumor biopsy is profiled with integrated transcriptomics, proteomics, and metabolomics. For translational interpretation, we assume a linear mixture model where the observed, feature-wise standardized abundances across omics are the nonnegative combination of two constituent cell-type signatures. The foundational basis is the Central Dogma of molecular biology and the additivity of signals from co-localized cell types under linear, feature-wise standardized measurement, a well-tested starting point for deconvolution in translational multi-omics.\n\nLet the integrated feature vector comprise five standardized entries in the order: messenger ribonucleic acid (mRNA) for gene $A$, mRNA for gene $B$, protein abundance for marker $P$, protein abundance for marker $Q$, and metabolite abundance for metabolite $M$. The measured spot vector is\n$$\ny \\;=\\; \\begin{pmatrix}\n1.2\\\\\n1.2\\\\\n0.2\\\\\n1.0\\\\\n0.3\n\\end{pmatrix}.\n$$\nPure cell-type multi-omic signatures, obtained from sorted single-cell multi-omics, are\n$$\nS_1 \\;=\\; \\begin{pmatrix}\n2\\\\\n0\\\\\n1\\\\\n1\\\\\n0.5\n\\end{pmatrix}\n,\\quad\nS_2 \\;=\\; \\begin{pmatrix}\n0\\\\\n3\\\\\n-1\\\\\n1\\\\\n0\n\\end{pmatrix}.\n$$\nModel the spot as\n$$\ny \\;\\approx\\; w_1 S_1 \\;+\\; w_2 S_2,\n$$\nwith weights $w_1 \\ge 0$ and $w_2 \\ge 0$. Derive, from first principles of least-squares estimation and nonnegativity constraints, the Nonnegative Least Squares (NNLS) solution that minimizes the squared residual $||y - w_1 S_1 - w_2 S_2||_2^2$ subject to $w_1,w_2 \\ge 0$. Report the numerical values of $w_1$ and $w_2$ rounded to four significant figures. No units are required for the weights, which are dimensionless scale factors under the stated standardization. Express your final answer as a two-entry row matrix using the $\\mathrm{pmatrix}$ environment.",
            "solution": "The problem is to find the weights $w_1$ and $w_2$ that minimize the sum of squared residuals, subject to non-negativity constraints. This is a Nonnegative Least Squares (NNLS) problem.\n\nLet the matrix of signatures be $S = \\begin{pmatrix} S_1 & S_2 \\end{pmatrix}$ and the vector of weights be $w = \\begin{pmatrix} w_1 \\\\ w_2 \\end{pmatrix}$. The model is $y \\approx Sw$. The objective is to minimize the squared $L_2$-norm of the residual vector $r = y - Sw$:\n$$\nf(w) = ||y - Sw||_2^2 = (y - Sw)^T (y - Sw)\n$$\nsubject to the constraints $w_1 \\ge 0$ and $w_2 \\ge 0$.\n\nExpanding the objective function, we get:\n$$\nf(w) = y^T y - 2y^T S w + w^T S^T S w\n$$\nThis is a quadratic function of $w$. Since the matrix $S^T S$ is positive semi-definite (and in this case, positive definite as $S_1$ and $S_2$ are linearly independent), the objective function is convex. The constraints are linear, defining a convex feasible region. Therefore, this is a convex optimization problem, and the Karush-Kuhn-Tucker (KKT) conditions are both necessary and sufficient for a global minimum.\n\nThe KKT conditions for this problem are:\n1.  **Stationarity**: The gradient of the Lagrangian must be zero. For our problem, this translates to the condition $\\nabla_w f(w) - \\mu = 0$, where $\\mu = \\begin{pmatrix} \\mu_1 \\\\ \\mu_2 \\end{pmatrix}$ is the vector of Lagrange multipliers for the constraints $-w_1 \\le 0$ and $-w_2 \\le 0$. The gradient of the objective function is $\\nabla_w f(w) = 2(S^T S w - S^T y)$. So, $2(S^T S w - S^T y) = \\mu$.\n2.  **Primal Feasibility**: $w_1 \\ge 0$, $w_2 \\ge 0$.\n3.  **Dual Feasibility**: $\\mu_1 \\ge 0$, $\\mu_2 \\ge 0$.\n4.  **Complementary Slackness**: $\\mu_1 w_1 = 0$ and $\\mu_2 w_2 = 0$.\n\nCombining the stationarity and dual feasibility conditions, we have $S^T S w - S^T y \\ge 0$. The complementary slackness condition implies that for any weight $w_i > 0$, the corresponding component of the gradient must be zero, i.e., $(S^T S w - S^T y)_i = 0$.\n\nA common strategy is to first solve the unconstrained least-squares problem, which is equivalent to assuming that no constraints are active ($w_1 > 0$, $w_2 > 0$). If the solution to the unconstrained problem satisfies the non-negativity constraints, it is also the solution to the NNLS problem.\n\nThe unconstrained solution is found by setting the gradient of $f(w)$ to zero:\n$$\n\\nabla_w f(w) = 2(S^T S w - S^T y) = 0\n$$\n$$\nS^T S w = S^T y\n$$\nThese are known as the normal equations.\n\nFirst, we compute the matrices $S^T S$ and $S^T y$ using the given vectors:\n$$\nS_1 = \\begin{pmatrix} 2 \\\\ 0 \\\\ 1 \\\\ 1 \\\\ 0.5 \\end{pmatrix}, \\quad S_2 = \\begin{pmatrix} 0 \\\\ 3 \\\\ -1 \\\\ 1 \\\\ 0 \\end{pmatrix}, \\quad y = \\begin{pmatrix} 1.2 \\\\ 1.2 \\\\ 0.2 \\\\ 1.0 \\\\ 0.3 \\end{pmatrix}\n$$\nThe components of $S^T S$ are:\n$$\nS_1^T S_1 = (2)^2 + (0)^2 + (1)^2 + (1)^2 + (0.5)^2 = 4 + 0 + 1 + 1 + 0.25 = 6.25\n$$\n$$\nS_2^T S_2 = (0)^2 + (3)^2 + (-1)^2 + (1)^2 + (0)^2 = 0 + 9 + 1 + 1 + 0 = 11\n$$\n$$\nS_1^T S_2 = (2)(0) + (0)(3) + (1)(-1) + (1)(1) + (0.5)(0) = 0 + 0 - 1 + 1 + 0 = 0\n$$\nSince $S_1^T S_2 = 0$, the signature vectors are orthogonal. This simplifies the matrix $S^T S$ to a diagonal matrix:\n$$\nS^T S = \\begin{pmatrix} 6.25 & 0 \\\\ 0 & 11 \\end{pmatrix}\n$$\nNext, we compute the vector $S^T y$:\n$$\nS_1^T y = (2)(1.2) + (0)(1.2) + (1)(0.2) + (1)(1.0) + (0.5)(0.3) = 2.4 + 0 + 0.2 + 1.0 + 0.15 = 3.75\n$$\n$$\nS_2^T y = (0)(1.2) + (3)(1.2) + (-1)(0.2) + (1)(1.0) + (0)(0.3) = 0 + 3.6 - 0.2 + 1.0 + 0 = 4.4\n$$\nSo, the vector $S^T y$ is:\n$$\nS^T y = \\begin{pmatrix} 3.75 \\\\ 4.4 \\end{pmatrix}\n$$\nNow we solve the normal equations $S^T S w = S^T y$:\n$$\n\\begin{pmatrix} 6.25 & 0 \\\\ 0 & 11 \\end{pmatrix} \\begin{pmatrix} w_1 \\\\ w_2 \\end{pmatrix} = \\begin{pmatrix} 3.75 \\\\ 4.4 \\end{pmatrix}\n$$\nThis yields two independent equations:\n$$\n6.25 w_1 = 3.75 \\quad \\implies \\quad w_1 = \\frac{3.75}{6.25} = \\frac{375}{625} = \\frac{3 \\times 125}{5 \\times 125} = \\frac{3}{5} = 0.6\n$$\n$$\n11 w_2 = 4.4 \\quad \\implies \\quad w_2 = \\frac{4.4}{11} = 0.4\n$$\nThe solution to the unconstrained problem is $w_1 = 0.6$ and $w_2 = 0.4$.\n\nWe must now check if this solution satisfies the primal feasibility conditions $w_1 \\ge 0$ and $w_2 \\ge 0$.\nIndeed, $w_1 = 0.6 > 0$ and $w_2 = 0.4 > 0$. The non-negativity constraints are satisfied.\nSince the unconstrained minimum lies within the feasible region, it is also the minimum for the constrained problem. All KKT conditions are satisfied with $\\mu_1=0$ and $\\mu_2=0$.\n\nThe problem asks for the values to be rounded to four significant figures.\nThe calculated values are $w_1 = 0.6$ and $w_2 = 0.4$.\nTo four significant figures, these are $w_1 = 0.6000$ and $w_2 = 0.4000$.\n\nThe final answer is presented as a two-entry row matrix.",
            "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n0.6000 & 0.4000\n\\end{pmatrix}\n}\n$$"
        }
    ]
}