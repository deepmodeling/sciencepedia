{
    "hands_on_practices": [
        {
            "introduction": "数字生物标志物验证的基石是确保其测量随时间推移具有可靠性和一致性。这项练习  提供了量化这种重测信度的直接实践，你将通过从混合效应模型的方差分量中计算组内相关系数（ICC）这一关键指标，来评估生物标志物的可靠性。",
            "id": "5007617",
            "problem": "一项转化医学研究通过重复测量来评估一个连续的、源自智能手机的静止性震颤振幅数字生物标志物，以确定其重测信度。该生物标志物在临床条件不变的情况下，对 $n=48$ 名个体进行了 $k=4$ 次会话的采集。数据采用双向随机效应线性混合效应模型进行建模：\n$$Y_{ij}=\\mu+S_{i}+D_{j}+\\varepsilon_{ij},$$\n其中，$Y_{ij}$ 是个体 $i$ 在会话 $j$ 的测量生物标志物值，$\\mu$ 是总均值，$S_{i}$ 是随机受试者效应且 $S_{i}\\sim \\mathcal{N}(0,\\sigma_{S}^{2})$，$D_{j}$ 是随机会话效应且 $D_{j}\\sim \\mathcal{N}(0,\\sigma_{D}^{2})$，$\\varepsilon_{ij}$ 是残差且 $\\varepsilon_{ij}\\sim \\mathcal{N}(0,\\sigma_{\\varepsilon}^{2})$。所有随机分量均相互独立。\n\n首先，在连续数字生物标志物和上述分层测量模型的背景下，为重测信度提供一个简明的定义。接下来，使用该模型和信度的基本定义（即单次会话测量中，可归因于稳定的受试者间差异的方差占总方差的比例），推导在此双向随机效应设置下，单次会话的组内相关系数 (ICC; Intraclass Correlation Coefficient) 的表达式。最后，使用以下方差分量的限制性最大似然 (REML; Restricted Maximum Likelihood) 估计值计算 ICC：\n$$\\hat{\\sigma}_{S}^{2}=0.95,\\quad \\hat{\\sigma}_{D}^{2}=0.12,\\quad \\hat{\\sigma}_{\\varepsilon}^{2}=0.31.$$\n将最终的 ICC 表示为一个实数。将您的答案四舍五入到四位有效数字。ICC 是无单位的；请勿在最终数值中包含任何单位。",
            "solution": "问题陈述已经过验证，被认为是合理的。它具有科学依据，提法得当，客观且完整。它提出了一个标准的生物统计学任务，涉及根据双向随机效应线性混合效应模型的方差分量计算组内相关系数 (ICC)。所有必要的数据和定义都已提供。\n\n该问题要求三项内容：重测信度的定义、针对指定模型的 ICC 公式的推导，以及 ICC 值的计算。\n\n首先，需要对重测信度给出一个简明的定义。在数字生物标志物等连续测量的背景下，重测信度量化了在相似条件下，于不同时间从相同受试者处获得的测量值的一致性和稳定性。从统计建模的角度来看，它是测量总方差中可归因于受试者之间“真实”或稳定差异的比例，而不是由测量误差或跨测量场合的系统性变异所引起的方差。高信度表明该生物标志物能够持续地区分不同个体。\n\n问题指定了一个双向随机效应线性混合效应模型：\n$$Y_{ij}=\\mu+S_{i}+D_{j}+\\varepsilon_{ij}$$\n其中，$Y_{ij}$ 是个体/受试者 $i$ 在会话 $j$ 的测量生物标志物值。各分量为：\n- $\\mu$：总均值，一个固定效应。\n- $S_{i}$：受试者 $i$ 的随机效应，服从 $S_{i}\\sim \\mathcal{N}(0,\\sigma_{S}^{2})$。$\\sigma_{S}^{2}$ 项代表受试者间方差。\n- $D_{j}$：会话 $j$ 的随机效应，服从 $D_{j}\\sim \\mathcal{N}(0,\\sigma_{D}^{2})$。$\\sigma_{D}^{2}$ 项代表会话间方差，这可能反映了跨会话测量条件的系统性变化。\n- $\\varepsilon_{ij}$：受试者 $i$ 在会话 $j$ 的残差项，服从 $\\varepsilon_{ij}\\sim \\mathcal{N}(0,\\sigma_{\\varepsilon}^{2})$。$\\sigma_{\\varepsilon}^{2}$ 项代表随机测量误差方差。\n\n假设所有随机分量（$S_i$, $D_j$, $\\varepsilon_{ij}$）均相互独立。\n\n为推导 ICC 的表达式，我们必须首先确定单个观测值 $Y_{ij}$ 的总方差。由于随机效应是独立的，总方差是它们各自方差的总和。均值 $\\mu$ 是一个常数，因此其方差为 0。\n$$ \\text{Var}(Y_{ij}) = \\text{Var}(\\mu + S_{i} + D_{j} + \\varepsilon_{ij}) $$\n$$ \\text{Var}(Y_{ij}) = \\text{Var}(S_{i}) + \\text{Var}(D_{j}) + \\text{Var}(\\varepsilon_{ij}) $$\n代入方差的定义：\n$$ \\text{Var}(Y_{ij}) = \\sigma_{S}^{2} + \\sigma_{D}^{2} + \\sigma_{\\varepsilon}^{2} $$\n该表达式代表了测量值的总方差。\n\n问题将信度定义为单次会话测量中，可归因于稳定的受试者间差异的方差占总方差的比例。代表受试者之间稳定的、真实差异的方差分量是受试者间方差 $\\sigma_{S}^{2}$。\n\nICC 是该受试者间方差与总方差的比率。因此，在此背景下，ICC 的公式为：\n$$ \\text{ICC} = \\frac{\\text{受试者间方差}}{\\text{总方差}} = \\frac{\\sigma_{S}^{2}}{\\sigma_{S}^{2} + \\sigma_{D}^{2} + \\sigma_{\\varepsilon}^{2}} $$\n这种特定形式的 ICC 通常被称为绝对一致性的 ICC，对应于 McGraw 和 Wong 的 ICC(A,1) 或 Shrout 和 Fleiss 的 ICC(2,1)，它适用于将受试者和会话都视为来自更大人群的随机样本的双向随机效应模型。由会话引起的方差 $\\sigma_D^2$ 包含在分母中，因为它在评估绝对一致性时构成了测量误差的一部分。\n\n最后，我们使用提供的方差分量的限制性最大似然 (REML) 估计值来计算 ICC 的数值：\n$$ \\hat{\\sigma}_{S}^{2} = 0.95 $$\n$$ \\hat{\\sigma}_{D}^{2} = 0.12 $$\n$$ \\hat{\\sigma}_{\\varepsilon}^{2} = 0.31 $$\n将这些估计值代入 ICC 公式：\n$$ \\text{ICC} = \\frac{\\hat{\\sigma}_{S}^{2}}{\\hat{\\sigma}_{S}^{2} + \\hat{\\sigma}_{D}^{2} + \\hat{\\sigma}_{\\varepsilon}^{2}} = \\frac{0.95}{0.95 + 0.12 + 0.31} $$\n首先，我们计算分母中的和，即总方差：\n$$ 0.95 + 0.12 + 0.31 = 1.38 $$\n现在，我们计算该比率：\n$$ \\text{ICC} = \\frac{0.95}{1.38} \\approx 0.688405797... $$\n问题要求将答案四舍五入到四位有效数字。前四位有效数字是 6、8、8、4。第五位数字是 0，所以我们向下舍入（即，我们不改变第四位数字）。\n$$ \\text{ICC} \\approx 0.6884 $$\n该值表明，生物标志物测量中的总方差约有 $68.84\\%$ 是由受试者之间的稳定差异引起的。",
            "answer": "$$\\boxed{0.6884}$$"
        },
        {
            "introduction": "一旦证明了生物标志物的可靠性，就必须验证其执行特定分类任务的能力。在这个问题中 ，你将计算如敏感性和特异性等基本性能指标，更重要的是，你将探索一个测试的真实世界效用（通过阳性预测值PPV和阴性预测值NPV反映）是如何严重依赖于目标人群中疾病患病率的。",
            "id": "5007644",
            "problem": "作为转化医学流程的一部分，一款基于腕戴式惯性测量单元的跌倒检测数字生物标志物正在一项针对社区居住老年人的前瞻性队列研究中进行验证。在一个监测周期内，临床工作人员使用同步视频和患者访谈来裁定真实事件。该算法以检测到的事件为粒度，输出二元分类：$\\,\\text{fall}$（跌倒）或 $\\,\\text{non-fall}$（非跌倒）。在 $\\,N=1000\\,$ 次事件中，裁定的混淆矩阵如下：\n- 真阳性（$\\mathrm{TP}$）：$96$ 次事件被裁定为跌倒且被分类为跌倒。\n- 假阴性（$\\mathrm{FN}$）：$24$ 次事件被裁定为跌倒但被分类为非跌倒。\n- 假阳性（$\\mathrm{FP}$）：$44$ 次事件被裁定为非跌倒但被分类为跌倒。\n- 真阴性（$\\mathrm{TN}$）：$836$ 次事件被裁定为非跌倒且被分类为非跌倒。\n\n在此验证数据集中，根据临床试验评估中使用的核心定义，计算以下操作特性：\n- 灵敏度（真阳性率）。\n- 特异度（真阴性率）。\n- 阳性预测值（PPV；算法阳性事件确实是跌倒的概率）。\n- 阴性预测值（NPV；算法阴性事件确实是非跌倒的概率）。\n\n然后，将灵敏度和特异度视为算法在不同人群中保持稳定的特性，推导阳性预测值（PPV）和阴性预测值（NPV）作为人群跌倒患病率 $p \\in (0,1)$ 的通用表达式，并分析当从验证队列的患病率转移到其他部署患病率时，这些函数如何变化。在 $p=0.02$ 和 $p=0.30$ 处评估这些函数，以说明变化的方向和幅度。\n\n最后，仅报告 $p=0.02$ 时的阳性预测值作为最终数值答案。将最终数值答案四舍五入至四位有效数字，并以小数形式表示（不带百分号）。",
            "solution": "该问题要求根据混淆矩阵计算数字生物标志物的几个操作特性，推导预测值的通用形式，并在不同的人群患病率下评估这些函数。解决方案首先为给定的验证数据定义和计算指标，然后推导通用公式，最后将其应用于指定场景。\n\n混淆矩阵提供的总共 $N=1000$ 次事件的数据如下：\n- 真阳性（$\\mathrm{TP}$）：$96$\n- 假阴性（$\\mathrm{FN}$）：$24$\n- 假阳性（$\\mathrm{FP}$）：$44$\n- 真阴性（$\\mathrm{TN}$）：$836$\n\n首先，我们计算验证队列的操作特性。裁定的总跌倒次数为 $\\mathrm{TP} + \\mathrm{FN} = 96 + 24 = 120$。裁定的总非跌倒次数为 $\\mathrm{FP} + \\mathrm{TN} = 44 + 836 = 880$。总事件次数为 $120 + 880 = 1000$。\n\n灵敏度（$\\mathrm{Se}$），或称真阳性率，是指实际阳性中被正确识别的比例。\n$$ \\mathrm{Se} = \\frac{\\mathrm{TP}}{\\mathrm{TP} + \\mathrm{FN}} = \\frac{96}{96 + 24} = \\frac{96}{120} = 0.8 $$\n\n特异度（$\\mathrm{Sp}$），或称真阴性率，是指实际阴性中被正确识别的比例。\n$$ \\mathrm{Sp} = \\frac{\\mathrm{TN}}{\\mathrm{TN} + \\mathrm{FP}} = \\frac{836}{836 + 44} = \\frac{836}{880} = 0.95 $$\n\n阳性预测值（$\\mathrm{PPV}$）是指被分类为跌倒的事件确实是跌倒的概率。\n$$ \\mathrm{PPV} = \\frac{\\mathrm{TP}}{\\mathrm{TP} + \\mathrm{FP}} = \\frac{96}{96 + 44} = \\frac{96}{140} = \\frac{24}{35} \\approx 0.6857 $$\n\n阴性预测值（$\\mathrm{NPV}$）是指被分类为非跌倒的事件确实是非跌倒的概率。\n$$ \\mathrm{NPV} = \\frac{\\mathrm{TN}}{\\mathrm{TN} + \\mathrm{FN}} = \\frac{836}{836 + 24} = \\frac{836}{860} = \\frac{209}{215} \\approx 0.9721 $$\n\n接下来，我们将阳性预测值（$\\mathrm{PPV}$）和阴性预测值（$\\mathrm{NPV}$）推导为人群跌倒患病率 $p \\in (0,1)$ 的函数。我们假设灵敏度（$\\mathrm{Se}$）和特异度（$\\mathrm{Sp}$）是算法的内在属性，并且在不同人群中保持不变。\n\n根据贝叶斯定理，$\\mathrm{PPV}$ 是在算法分类为阳性的情况下，发生真实跌倒的条件概率，即 $P(\\text{Fall} | \\text{Alg-Pos})$。\n$$ \\mathrm{PPV}(p) = \\frac{P(\\text{Alg-Pos} | \\text{Fall}) P(\\text{Fall})}{P(\\text{Alg-Pos})} $$\n分母 $P(\\text{Alg-Pos})$ 使用全概率定律求得：\n$$ P(\\text{Alg-Pos}) = P(\\text{Alg-Pos} | \\text{Fall}) P(\\text{Fall}) + P(\\text{Alg-Pos} | \\text{Non-fall}) P(\\text{Non-fall}) $$\n代入定义 $P(\\text{Fall})=p$、$P(\\text{Non-fall})=1-p$、$P(\\text{Alg-Pos} | \\text{Fall})=\\mathrm{Se}$ 和 $P(\\text{Alg-Pos} | \\text{Non-fall})=1-\\mathrm{Sp}$，我们得到：\n$$ \\mathrm{PPV}(p) = \\frac{(\\mathrm{Se}) \\cdot p}{(\\mathrm{Se}) \\cdot p + (1-\\mathrm{Sp})(1-p)} $$\n同样，$\\mathrm{NPV}$ 是在算法分类为阴性的情况下，发生真实非跌倒的条件概率，即 $P(\\text{Non-fall} | \\text{Alg-Neg})$。\n$$ \\mathrm{NPV}(p) = \\frac{P(\\text{Alg-Neg} | \\text{Non-fall}) P(\\text{Non-fall})}{P(\\text{Alg-Neg})} $$\n分母 $P(\\text{Alg-Neg})$ 为：\n$$ P(\\text{Alg-Neg}) = P(\\text{Alg-Neg} | \\text{Non-fall}) P(\\text{Non-fall}) + P(\\text{Alg-Neg} | \\text{Fall}) P(\\text{Fall}) $$\n代入定义 $P(\\text{Alg-Neg} | \\text{Non-fall})=\\mathrm{Sp}$ 和 $P(\\text{Alg-Neg} | \\text{Fall})=1-\\mathrm{Se}$，我们得到：\n$$ \\mathrm{NPV}(p) = \\frac{(\\mathrm{Sp}) \\cdot (1-p)}{(\\mathrm{Sp}) \\cdot (1-p) + (1-\\mathrm{Se}) \\cdot p} $$\n现在，我们使用计算出的值 $\\mathrm{Se} = 0.8$ 和 $\\mathrm{Sp} = 0.95$。函数变为：\n$$ \\mathrm{PPV}(p) = \\frac{0.8p}{0.8p + (1-0.95)(1-p)} = \\frac{0.8p}{0.8p + 0.05(1-p)} = \\frac{0.8p}{0.75p + 0.05} = \\frac{16p}{15p+1} $$\n$$ \\mathrm{NPV}(p) = \\frac{0.95(1-p)}{0.95(1-p) + (1-0.8)p} = \\frac{0.95(1-p)}{0.95(1-p) + 0.2p} = \\frac{0.95 - 0.95p}{0.95 - 0.75p} = \\frac{19(1-p)}{19 - 15p} $$\n验证队列中的患病率为 $p_{cohort} = \\frac{120}{1000} = 0.12$。随着患病率的变化，$\\mathrm{PPV}$ 和 $\\mathrm{NPV}$ 也会改变。患病率 $p$ 的增加将导致 $\\mathrm{PPV}(p)$ 增加和 $\\mathrm{NPV}(p)$ 减少。\n\n我们在指定的备选患病率下评估这些函数。\n在 $p=0.02$ 时：\n$$ \\mathrm{PPV}(0.02) = \\frac{16(0.02)}{15(0.02)+1} = \\frac{0.32}{0.3+1} = \\frac{0.32}{1.3} = \\frac{16}{65} \\approx 0.2461538... $$\n$$ \\mathrm{NPV}(0.02) = \\frac{19(1-0.02)}{19 - 15(0.02)} = \\frac{19(0.98)}{19 - 0.3} = \\frac{18.62}{18.7} \\approx 0.9957219... $$\n在 $p=0.30$ 时：\n$$ \\mathrm{PPV}(0.30) = \\frac{16(0.30)}{15(0.30)+1} = \\frac{4.8}{4.5+1} = \\frac{4.8}{5.5} = \\frac{48}{55} \\approx 0.872727... $$\n$$ \\mathrm{NPV}(0.30) = \\frac{19(1-0.30)}{19 - 15(0.30)} = \\frac{19(0.7)}{19 - 4.5} = \\frac{13.3}{14.5} \\approx 0.917241... $$\n预测值对患病率的显著依赖性是显而易见的。当部署在跌倒患病率低至 $p=0.02$ 的人群中时，$\\mathrm{PPV}$ 下降到约 $0.2462$，这意味着绝大多数警报都是假警报。然而，$\\mathrm{NPV}$ 变得非常高（$0.9957$），这为算法未标记的事件确实是非跌倒事件提供了很强的置信度。\n\n问题要求的是 $p=0.02$ 时的阳性预测值，四舍五入到四位有效数字。\n$$ \\mathrm{PPV}(0.02) \\approx 0.2461538...$$\n四舍五入到四位有效数字得到 $0.2462$。",
            "answer": "$$\n\\boxed{0.2462}\n$$"
        },
        {
            "introduction": "观察到较高的曲线下面积（AUC）固然可喜，但我们如何确定这一表现并非偶然？这项动手编程练习  演示了如何使用置换检验——一种强大的非参数方法——通过生成经验零分布来严格评估分类器性能的统计显著性。",
            "id": "5007598",
            "problem": "在转化医学中，基于数字生物标志物的分类器的验证通常依赖于确定其区分能力（由受试者工作特征（ROC）曲线下面积（AUC）概括）是否优于随机表现。考虑一个具有观测标签和连续生物标志物分数的二元分类问题。基本原理如下：曲线下面积（AUC）定义为从正例中随机抽取一个个体，其分数高于从负例中随机抽取的个体的分数的概率，其中平局情况贡献一半的概率。在生物标志物不携带类别信息的零假设下，标签相对于分数是可交换的。\n\n使用可交换性原理，构建一个单边置换检验，检验零假设 $H_0: \\mathrm{AUC} = 0.5$ 与备择假设 $H_1: \\mathrm{AUC} > 0.5$。检验统计量是根据提供的标签和分数计算出的观测AUC。使用秩和等价性实现AUC计算，并通过平均秩次处理平局情况。对于由标签置换生成的零分布下的$p$值计算，使用加一有限样本校正以避免零$p$值。\n\n你的程序必须对下述每个测试用例，从第一性原理出发执行以下步骤：\n- 根据提供或生成的分数和标签计算观测AUC，使用平均秩次处理平局情况。\n- 通过在保持分数固定的情况下置换标签，生成AUC的零分布。根据指定，可以采用精确枚举或使用指定$B$次置换的蒙特卡洛方法。\n- 使用加一校正，计算单边$p$值，即零分布中大于或等于观测AUC的AUC值的比例。\n- 以浮点数形式返回$p$值，四舍五入至六位小数（以小数形式而非百分比表示）。\n\n使用以下测试套件。对于合成得分的用例，使用具有给定均值和标准差的正态分布生成分数，并按指定设置随机种子以确保可复现性。使用按指定播种的NumPy默认随机数生成器。在所有用例中，正例的标签为$1$，负例的标签为$0$。\n\n测试用例1（平衡、可分；蒙特卡洛）：\n- 正例：$n_{+} = 20$，分数独立抽取自 $\\mathcal{N}(\\mu_{+}=1.0, \\sigma_{+}=1.0)$。\n- 负例：$n_{-} = 20$，分数独立抽取自 $\\mathcal{N}(\\mu_{-}=0.0, \\sigma_{-}=1.0)$。\n- 数据生成种子：$20231123$。\n- 置换方案：蒙特卡洛法，进行 $B = 2000$ 次标签置换。\n- 置换种子：$101$。\n\n测试用例2（平衡、类零假设；蒙特卡洛）：\n- 正例：$n_{+} = 30$，分数独立抽取自 $\\mathcal{N}(\\mu_{+}=0.0, \\sigma_{+}=1.0)$。\n- 负例：$n_{-} = 30$，分数独立抽取自 $\\mathcal{N}(\\mu_{-}=0.0, \\sigma_{-}=1.0)$。\n- 数据生成种子：$20200101$。\n- 置换方案：蒙特卡洛法，进行 $B = 3000$ 次标签置换。\n- 置换种子：$202$。\n\n测试用例3（不平衡；蒙特卡洛）：\n- 正例：$n_{+} = 10$，分数独立抽取自 $\\mathcal{N}(\\mu_{+}=0.5, \\sigma_{+}=1.0)$。\n- 负例：$n_{-} = 50$，分数独立抽取自 $\\mathcal{N}(\\mu_{-}=0.0, \\sigma_{-}=1.0)$。\n- 数据生成种子：$424242$。\n- 置换方案：蒙特卡洛法，进行 $B = 1500$ 次标签置换。\n- 置换种子：$303$。\n\n测试用例4（含平局的小样本；精确枚举）：\n- 分数（长度为 $10$）：$[0.1, 0.2, 0.2, 0.3, 0.3, 0.1, 0.1, 0.2, 0.2, 0.4]$。\n- 标签（长度为 $10$）：$[1, 1, 1, 1, 1, 0, 0, 0, 0, 0]$。\n- 置换方案：对所有 $\\binom{10}{5}$ 种含 $5$ 个正例的不同标签分配进行精确枚举。\n\n所有$p$值都应报告为四舍五入到小数点后六位的小数。您的程序应生成单行输出，其中包含一个用方括号括起来的、以逗号分隔的结果列表。例如，一个有效的输出格式是 $[0.031000,0.517333,0.084000,0.123000]$。\n\n每个测试的最终输出类型是浮点数，程序必须将4个结果汇总为指定的单行格式。",
            "solution": "所提出的问题要求构建并实现一个单边置换检验，以验证生物标志物的区分能力。零假设 $H_0$ 假定生物标志物不含类别信息，对应于受试者工作特征曲线下面积（AUC）为 $0.5$。备择假设 $H_1$ 认为生物标志物确实具有区分能力，对应于 $\\mathrm{AUC} > 0.5$。该解决方案建立在公认的统计学原理之上。\n\n### 统计基础：置换检验\n\n置换检验的基石是零假设下的*可交换性*原理。如果一个生物标志物的分数与类别标签（例如，患者与对照组）无关，那么在保持分数固定的情况下，对标签的任何置换都代表了在 $H_0$ 下一个同样可能的结果。通过在大量此类置换上生成检验统计量（AUC）的分布，我们构建了一个经验零分布。观测到的AUC的统计显著性随后由其在该零分布中的排位确定。\n\n### 检验统计量：曲线下面积（AUC）\n\nAUC定义为一个分类器将一个随机选择的正例排在一个随机选择的负例之前的概率。问题指定了一个能正确处理平局情况的公式：$P(\\text{score}_{\\text{pos}} > \\text{score}_{\\text{neg}}) + 0.5 \\cdot P(\\text{score}_{\\text{pos}} = \\text{score}_{\\text{neg}})$。\n\n这个定义在计算上等同于标准化的Mann-Whitney U统计量。该实现利用了这一等价性。给定一组包含 $n_{+}$ 个正例标签和 $n_{-}$ 个负例标签的 $N$ 个分数，AUC的计算公式为：\n$$ \\mathrm{AUC} = \\frac{U}{n_{+} n_{-}} $$\n其中 $U$ 是Mann-Whitney U统计量。$U$ 本身由正例分数的秩次和（记为 $S_{+}$）导出，这些秩次是在所有 $N = n_{+} + n_{-}$ 个分数合并并排序后的集合中得到的。$U$ 的计算公式是：\n$$ U = S_{+} - \\frac{n_{+}(n_{+} + 1)}{2} $$\n此计算的一个关键方面是处理分数相同（即平局）的情况。为了符合指定的AUC定义，通过为所有分数相同的项分配*平均秩次*来解决平局问题。这是通过使用 `scipy.stats.rankdata` 并设置参数 `method='average'` 来实现的。\n\n### 零分布的生成\n\n问题指定了两种不同的方案来生成AUC值的零分布，具体取决于样本大小：\n\n1.  **蒙特卡洛置换**：对于测试用例1、2和3，由于可能置换的数量在计算上难以完全枚举，因此采用蒙特卡洛近似法。生成大量的（$B$个）类别标签的随机置换。对这$B$个置换中的每一个，都重新计算AUC，从而从零分布中创建一个包含$B$个值的样本。使用指定的随机数生成器种子可确保此随机过程的可复现性。\n\n2.  **精确枚举**：对于测试用例4，样本量（$N=10$，其中 $n_{+}=5$）足够小，可以进行精确检验。通过系统地枚举将 $n_{+}=5$ 个正例标签分配给 $N=10$ 个分数的所有可能的不同方式，来生成完整的零分布。此类唯一置换的总数由二项式系数 $\\binom{N}{n_{+}} = \\binom{10}{5} = 252$ 给出。对这 $252$ 种配置中的每一种都计算AUC。这种方法比蒙特卡洛方法更具统计功效，因为它没有抽样误差。\n\n### P值计算\n\n单边$p$值是零分布中至少与观测到的检验统计量一样极端的结果所占的比例。在这里，“极端”意味着大于或等于观测到的AUC，这与备择假设 $H_1: \\mathrm{AUC} > 0.5$ 相对应。计算中包含了一个有限样本校正，以避免出现零$p$值，并将观测数据本身视为一种可能的置换。公式为：\n$$ p = \\frac{C + 1}{B + 1} $$\n其中，$C$ 是满足 $\\mathrm{AUC}_{\\text{null}} \\ge \\mathrm{AUC}_{\\text{observed}}$ 的置换次数，$B$ 是生成的总置换数（对于蒙特卡洛法是指定的数量，对于精确检验是 $\\binom{N}{n_{+}}$）。\n\n### 实现\n\n提供的Python代码封装了这一逻辑。一个核心函数 `calculate_auc` 实现了基于秩和的AUC计算。独立的函数 `run_monte_carlo_test` 和 `run_exact_test` 分别处理两种置换方案。主函数 `solve` 负责按规定执行四个测试用例：对于合成用例，使用带有固定种子的 `numpy.random.default_rng` 生成数据以保证可复现性，然后应用适当的置换检验来计算所需的$p$值，最后将这些$p$值格式化为六位小数。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.stats import rankdata\nfrom itertools import combinations\n\ndef solve():\n    \"\"\"\n    Main function to run all test cases for the AUC permutation test and print the results.\n    \"\"\"\n\n    def calculate_auc(scores, labels):\n        \"\"\"\n        Computes the AUC using the rank-sum equivalence with average ranking for ties.\n        \n        The AUC is calculated as U / (n_pos * n_neg), where U is the Mann-Whitney U statistic.\n        U is derived from the sum of ranks of the positive class (S_pos).\n        \n        Args:\n            scores (np.ndarray): Array of continuous biomarker scores.\n            labels (np.ndarray): Array of binary labels (1 for positive, 0 for negative).\n\n        Returns:\n            float: The calculated AUC value.\n        \"\"\"\n        scores = np.asarray(scores)\n        labels = np.asarray(labels)\n        \n        n_pos = np.sum(labels == 1)\n        n_neg = np.sum(labels == 0)\n\n        # AUC is only well-defined if both classes are present.\n        # This condition will not be met in the problem's tests, as label permutations\n        # preserve the number of positives and negatives.\n        if n_pos == 0 or n_neg == 0:\n            return 0.5\n\n        # Rank all scores together, using average rank for ties.\n        ranks = rankdata(scores, method='average')\n        \n        # Sum of ranks for the positive class.\n        s_pos = np.sum(ranks[labels == 1])\n        \n        # Calculate the Mann-Whitney U statistic.\n        u_stat = s_pos - (n_pos * (n_pos + 1)) / 2\n        \n        auc = u_stat / (n_pos * n_neg)\n        return auc\n\n    def run_monte_carlo_test(scores, labels, B, perm_seed):\n        \"\"\"\n        Runs the Monte Carlo permutation test for AUC.\n\n        Args:\n            scores (np.ndarray): Array of scores.\n            labels (np.ndarray): Array of original labels.\n            B (int): Number of Monte Carlo permutations.\n            perm_seed (int): Seed for the permutation random number generator.\n\n        Returns:\n            float: The calculated one-sided p-value.\n        \"\"\"\n        observed_auc = calculate_auc(scores, labels)\n        \n        rng = np.random.default_rng(perm_seed)\n        \n        null_aucs = np.zeros(B)\n        original_labels = np.copy(labels)\n        \n        for i in range(B):\n            permuted_labels = rng.permutation(original_labels)\n            null_aucs[i] = calculate_auc(scores, permuted_labels)\n            \n        count_extreme = np.sum(null_aucs >= observed_auc)\n        \n        # Plus-one correction for p-value\n        p_value = (count_extreme + 1) / (B + 1)\n        return p_value\n\n    def run_exact_test(scores, labels):\n        \"\"\"\n        Runs the exact permutation test by enumerating all distinct label combinations.\n\n        Args:\n            scores (np.ndarray): Array of scores.\n            labels (np.ndarray): Array of original labels.\n\n        Returns:\n            float: The calculated one-sided p-value.\n        \"\"\"\n        observed_auc = calculate_auc(scores, labels)\n        \n        n = len(labels)\n        n_pos = np.sum(labels == 1)\n        \n        all_indices = range(n)\n        null_aucs = []\n        \n        # Generate all combinations of indices where positive labels can be placed.\n        pos_indices_combinations = combinations(all_indices, n_pos)\n        \n        total_permutations = 0\n        for pos_indices in pos_indices_combinations:\n            permuted_labels = np.zeros(n, dtype=int)\n            permuted_labels[list(pos_indices)] = 1\n            null_aucs.append(calculate_auc(scores, permuted_labels))\n            total_permutations += 1\n\n        null_aucs = np.array(null_aucs)\n        count_extreme = np.sum(null_aucs >= observed_auc)\n        \n        # Plus-one correction for p-value. B is the total number of permutations.\n        p_value = (count_extreme + 1) / (total_permutations + 1)\n        return p_value\n\n    test_cases = [\n        # Case 1: balanced, separated; Monte Carlo\n        {'type': 'synthetic', 'n_pos': 20, 'n_neg': 20, 'mu_pos': 1.0, 'sigma_pos': 1.0, \n         'mu_neg': 0.0, 'sigma_neg': 1.0, 'data_seed': 20231123, \n         'perm_scheme': 'mc', 'B': 2000, 'perm_seed': 101},\n        # Case 2: balanced, null-like; Monte Carlo\n        {'type': 'synthetic', 'n_pos': 30, 'n_neg': 30, 'mu_pos': 0.0, 'sigma_pos': 1.0, \n         'mu_neg': 0.0, 'sigma_neg': 1.0, 'data_seed': 20200101, \n         'perm_scheme': 'mc', 'B': 3000, 'perm_seed': 202},\n        # Case 3: imbalanced; Monte Carlo\n        {'type': 'synthetic', 'n_pos': 10, 'n_neg': 50, 'mu_pos': 0.5, 'sigma_pos': 1.0, \n         'mu_neg': 0.0, 'sigma_neg': 1.0, 'data_seed': 424242, \n         'perm_scheme': 'mc', 'B': 1500, 'perm_seed': 303},\n        # Case 4: small sample with ties; exact enumeration\n        {'type': 'fixed', 'scores': [0.1, 0.2, 0.2, 0.3, 0.3, 0.1, 0.1, 0.2, 0.2, 0.4], \n         'labels': [1, 1, 1, 1, 1, 0, 0, 0, 0, 0], 'perm_scheme': 'exact'}\n    ]\n\n    results = []\n    for case in test_cases:\n        if case['type'] == 'synthetic':\n            rng_data = np.random.default_rng(case['data_seed'])\n            scores_pos = rng_data.normal(case['mu_pos'], case['sigma_pos'], case['n_pos'])\n            scores_neg = rng_data.normal(case['mu_neg'], case['sigma_neg'], case['n_neg'])\n            \n            scores = np.concatenate([scores_pos, scores_neg])\n            labels = np.concatenate([np.ones(case['n_pos']), np.zeros(case['n_neg'])])\n            \n            p_val = run_monte_carlo_test(scores, labels, case['B'], case['perm_seed'])\n        else: # type == 'fixed'\n            scores = np.array(case['scores'])\n            labels = np.array(case['labels'])\n            \n            p_val = run_exact_test(scores, labels)\n            \n        results.append(p_val)\n\n    # Format output to exactly 6 decimal places.\n    formatted_results = [f\"{r:.6f}\" for r in results]\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```"
        }
    ]
}