{
    "hands_on_practices": [
        {
            "introduction": "Before committing substantial resources to a clinical trial, a robust protocol must establish its operational feasibility. This foundational exercise involves translating assumptions about patient characteristics and screening criteria into concrete enrollment projections and monitoring plans. This practice  will guide you through the process of calculating screen failure rates from first principles and setting a statistical threshold for feasibility reviews, which are core skills for de-risking a study and ensuring its timely completion.",
            "id": "4998783",
            "problem": "A multicenter translational study plans a Phase II biomarker-enriched trial in advanced solid tumors. The pre-consent screening step applies four objective eligibility criteria to referred patients: biomarker positivity, Eastern Cooperative Oncology Group (ECOG) performance status $0$–$1$, adequate organ function, and absence of untreated brain metastases. The following design inputs, based on registry data and a feasibility pilot, are adopted for the protocol:\n\n- Biomarker positivity among referred patients occurs with probability $P(B)=0.30$.\n- ECOG $0$–$1$ occurs with probability $P(E)=0.75$.\n- Adequate organ function $A$ is correlated with ECOG: $P(A\\mid E)=0.93$ and $P(A\\mid E^{c})=0.60$.\n- Absence of untreated brain metastases $M$ occurs with probability $P(M)=0.85$.\n- Independence assumptions for protocol planning: the pair $(B,M)$ is independent of the pair $(E,A)$, and $B$ is independent of $M$. The correlation between $E$ and $A$ is as given above and is the only dependence among criteria.\n\nA referred patient is screen-eligible if and only if $B \\cap E \\cap A \\cap M$ holds. Patients who are screen-eligible are approached for consent; among those approached, $0.90$ provide informed consent. Among consented patients, $0.95$ pass central confirmation of eligibility without additional failure. Randomization occurs immediately after central confirmation.\n\nThe trial targets $N=120$ randomized patients. For feasibility oversight, after the first $m=60$ completed pre-consent screenings, the sponsor will trigger a feasibility review if the observed number of screening failures is “too high” relative to the protocol plan under the screening-failure probability implied by the inputs above. Specifically, under a binomial model for the number of failures among the first $m$ screens with failure probability equal to the planned value, define the one-sided upper monitoring threshold $k^{\\ast}$ as the smallest integer such that the binomial right-tail probability is at most $\\alpha=0.10$. If needed, you may use a normal approximation with continuity correction to determine $k^{\\ast}$.\n\nTasks:\n1) Starting from the definitions of joint and conditional probability and the stated independence structure, derive the planned pre-consent screening-failure probability $p_{\\mathrm{fail}}$.\n2) Using first principles for Bernoulli processes, derive the expected number of referred patients required to achieve $N$ randomizations, and evaluate it numerically under the provided inputs.\n3) Determine the feasibility review threshold $k^{\\ast}$ for $m=60$ and $\\alpha=0.10$ as defined above.\n\nProvide all reasoning and intermediate derivations. Report only the integer $k^{\\ast}$ as your final answer. No rounding instruction is needed for the final answer beyond identifying the correct integer threshold.",
            "solution": "The problem statement has been evaluated and is determined to be valid. It is scientifically grounded in probability theory and its application to clinical trial design, well-posed with a complete and consistent set of givens, and expressed in objective, formal language. The solution proceeds as follows.\n\nThe problem requires a three-part calculation:\n1) Derivation of the pre-consent screening-failure probability, $p_{\\mathrm{fail}}$.\n2) Derivation and calculation of the expected number of patients to be referred to achieve $N=120$ randomizations.\n3) Determination of the feasibility monitoring threshold, $k^{\\ast}$.\n\n**Part 1: Pre-consent Screening-Failure Probability ($p_{\\mathrm{fail}}$)**\n\nA referred patient is screen-eligible if they satisfy all four criteria simultaneously. Let $S_{succ}$ denote the event of a successful pre-consent screening. This event is the intersection of the four individual criteria events: biomarker positivity ($B$), ECOG performance status $0$–$1$ ($E$), adequate organ function ($A$), and absence of untreated brain metastases ($M$).\n$$S_{succ} = B \\cap E \\cap A \\cap M$$\nThe probability of this event, $p_{succ} = P(S_{succ})$, is the probability of a patient being screen-eligible. The problem states that the pair of events $(B,M)$ is independent of the pair $(E,A)$. Therefore, the joint probability can be factored as:\n$$p_{succ} = P(B \\cap M \\cap E \\cap A) = P(B \\cap M) P(E \\cap A)$$\nThe problem further states that $B$ and $M$ are independent events. Thus, their joint probability is the product of their individual probabilities:\n$$P(B \\cap M) = P(B) P(M)$$\nThe problem specifies the dependence between $E$ and $A$ via the conditional probability $P(A \\mid E)$. The joint probability of $E$ and $A$ is given by the definition of conditional probability:\n$$P(E \\cap A) = P(A \\mid E) P(E)$$\nNote that for a patient to be eligible, they must satisfy criterion $E$. The information regarding $P(A \\mid E^c)$ is not required for calculating the success probability, as any patient in the state $E^c$ has already failed the screening.\n\nCombining these expressions, the probability of a successful screening is:\n$$p_{succ} = P(B) P(M) P(A \\mid E) P(E)$$\nSubstituting the given values:\n$P(B) = 0.30$\n$P(M) = 0.85$\n$P(E) = 0.75$\n$P(A \\mid E) = 0.93$\n$$p_{succ} = (0.30) \\times (0.85) \\times (0.93) \\times (0.75)$$\n$$p_{succ} = (0.255) \\times (0.6975) = 0.1778625$$\nThe pre-consent screening-failure probability, $p_{\\mathrm{fail}}$, is the complement of the success probability:\n$$p_{\\mathrm{fail}} = 1 - p_{succ} = 1 - 0.1778625 = 0.8221375$$\n\n**Part 2: Expected Number of Referred Patients**\n\nLet $p_{\\mathrm{rand}}$ be the overall probability that a single referred patient is eventually randomized. A patient must pass three sequential hurdles: pre-consent screening (eligibility), informed consent, and central confirmation.\nThe probability of passing pre-consent screening is $p_{succ} = 0.1778625$.\nThe probability of a screen-eligible patient providing consent is $P(\\text{Consent} \\mid S_{succ}) = 0.90$.\nThe probability of a consented patient passing central confirmation is $P(\\text{Confirm} \\mid \\text{Consent}) = 0.95$.\n\nThe probability of a referred patient being randomized is the product of these probabilities:\n$$p_{\\mathrm{rand}} = P(S_{succ}) \\times P(\\text{Consent} \\mid S_{succ}) \\times P(\\text{Confirm} \\mid \\text{Consent})$$\n$$p_{\\mathrm{rand}} = 0.1778625 \\times 0.90 \\times 0.95$$\n$$p_{\\mathrm{rand}} = 0.1778625 \\times 0.855 = 0.1520724375$$\nThe process of finding randomized patients can be modeled as a sequence of independent Bernoulli trials, where success is randomizing a patient with probability $p_{\\mathrm{rand}}$. The number of trials (referred patients), $K$, required to obtain a fixed number of successes, $N$, follows a negative binomial distribution. The expected value of $K$ is given by:\n$$E[K] = \\frac{N}{p_{\\mathrm{rand}}}$$\nWith the target $N=120$ randomized patients:\n$$E[K] = \\frac{120}{0.1520724375} \\approx 789.1118$$\nSo, the expected number of patients that must be referred to the study to randomize $120$ is approximately $789.11$.\n\n**Part 3: Feasibility Review Threshold ($k^{\\ast}$)**\n\nThe feasibility review is based on the number of screening failures, $X$, in the first $m=60$ screenings. This process is modeled as a binomial experiment, $X \\sim \\text{Binomial}(m, p_{\\mathrm{fail}})$, where the number of trials is $m=60$ and the probability of failure on any trial is $p_{\\mathrm{fail}} = 0.8221375$.\n\nWe need to find the smallest integer threshold $k^{\\ast}$ such that the probability of observing $k^{\\ast}$ or more failures is at most $\\alpha=0.10$.\n$$P(X \\ge k^{\\ast}) \\le 0.10$$\nThe problem permits the use of a normal approximation to the binomial distribution, with a continuity correction. First, we compute the mean ($\\mu$) and standard deviation ($\\sigma$) of the binomial distribution:\n$$\\mu = m \\cdot p_{\\mathrm{fail}} = 60 \\times 0.8221375 = 49.32825$$\n$$\\sigma^2 = m \\cdot p_{\\mathrm{fail}} (1 - p_{\\mathrm{fail}}) = 60 \\times 0.8221375 \\times (1 - 0.8221375) = 49.32825 \\times 0.1778625 \\approx 8.77353$$\n$$\\sigma = \\sqrt{\\sigma^2} \\approx 2.9619806$$\nThe condition $m \\cdot p_{\\mathrm{fail}} \\approx 49.3 > 5$ and $m(1-p_{\\mathrm{fail}}) \\approx 10.7 > 5$ confirms that the normal approximation is appropriate.\n\nApplying the continuity correction, the probability $P(X \\ge k^{\\ast})$ is approximated by $P(Y \\ge k^{\\ast} - 0.5)$, where $Y \\sim N(\\mu, \\sigma^2)$. We standardize this to a standard normal variable $Z \\sim N(0, 1)$:\n$$P\\left(Z \\ge \\frac{(k^{\\ast} - 0.5) - \\mu}{\\sigma}\\right) \\le 0.10$$\nThe critical value $z_{0.10}$ from the standard normal distribution, for which $P(Z \\ge z_{0.10}) = 0.10$, is approximately $z_{0.10} \\approx 1.28155$.\nThus, we must have:\n$$\\frac{(k^{\\ast} - 0.5) - \\mu}{\\sigma} \\ge z_{0.10}$$\nSolving for $k^{\\ast}$:\n$$k^{\\ast} - 0.5 \\ge \\mu + z_{0.10} \\sigma$$\n$$k^{\\ast} \\ge \\mu + 0.5 + z_{0.10} \\sigma$$\nSubstituting the calculated values:\n$$k^{\\ast} \\ge 49.32825 + 0.5 + (1.28155)(2.9619806)$$\n$$k^{\\ast} \\ge 49.82825 + 3.79580$$\n$$k^{\\ast} \\ge 53.62405$$\nSince $k^{\\ast}$ must be an integer, the smallest integer satisfying this inequality is $k^{\\ast}=54$.\n\nTo verify, we can check the approximate probabilities for $k=53$ and $k=54$:\nFor $k^{\\ast}=54$, we test $P(X \\ge 54) \\approx P(Y \\ge 53.5)$:\n$$z = \\frac{53.5 - 49.32825}{2.9619806} = \\frac{4.17175}{2.9619806} \\approx 1.4084$$\n$P(Z \\ge 1.4084) \\approx 0.0795$, which is less than $0.10$.\n\nFor $k=53$, we test $P(X \\ge 53) \\approx P(Y \\ge 52.5)$:\n$$z = \\frac{52.5 - 49.32825}{2.9619806} = \\frac{3.17175}{2.9619806} \\approx 1.0708$$\n$P(Z \\ge 1.0708) \\approx 0.1421$, which is greater than $0.10$.\n\nTherefore, the smallest integer number of failures that would trigger the review is $54$.",
            "answer": "$$\\boxed{54}$$"
        },
        {
            "introduction": "A cornerstone of any clinical trial protocol is the precise definition of the primary endpoint and its corresponding estimand, which frames the study's central scientific question. In settings like oncology, where treatments may have delayed effects or early risks, the proportional hazards assumption often fails, making the hazard ratio an inappropriate measure of the treatment effect. This practice  challenges you to work with a more robust alternative, the Restricted Mean Survival Time ($RMST$), and derive it from first principles in a non-proportional hazards scenario, a critical skill for designing modern, relevant trials.",
            "id": "4998767",
            "problem": "A pivotal Phase III trial in translational medicine is being designed for a biologic therapy with early infusion-related risks but potential later disease-modifying benefits. The clinical team anticipates violation of the Proportional Hazards (PH) assumption and has therefore prespecified Restricted Mean Survival Time (RMST) as the primary estimand in the clinical trial protocol and the basis for labeling claim language. Using foundational definitions from survival analysis, compute the prespecified RMST difference at a clinically relevant truncation time and provide its numerical value, which will be used to inform the protocol’s estimand justification and labeling claim interpretation.\n\nAssume a piecewise-constant hazard model with no censoring and a fixed truncation time $\\tau = 24$ months. Let the control group have instantaneous hazard function $\\lambda_{C}(t)$ defined by $\\lambda_{C}(t) = 0.06$ per month for $0 \\leq t  12$ and $\\lambda_{C}(t) = 0.03$ per month for $12 \\leq t \\leq 24$. Let the treatment group have instantaneous hazard function $\\lambda_{T}(t)$ defined by $\\lambda_{T}(t) = 0.12$ per month for $0 \\leq t  6$ and $\\lambda_{T}(t) = 0.02$ per month for $6 \\leq t \\leq 24$. The survival function $S(t)$ is defined by the relationship $S(t) = \\exp\\!\\left(-\\int_{0}^{t} \\lambda(u)\\,du\\right)$ for any nonnegative, integrable hazard function $\\lambda(t)$. The Restricted Mean Survival Time (RMST) at truncation $\\tau$ is defined as $\\text{RMST}(\\tau) = \\int_{0}^{\\tau} S(t)\\,dt$, which equals the expectation $\\mathbb{E}[\\min(T,\\tau)]$ for a nonnegative survival time $T$.\n\nStarting strictly from these core definitions, derive the group-specific survival functions $S_{C}(t)$ and $S_{T}(t)$, derive the corresponding $\\text{RMST}_{C}(24)$ and $\\text{RMST}_{T}(24)$, and then calculate the prespecified estimand $\\Delta_{\\text{RMST}}(24) = \\text{RMST}_{T}(24) - \\text{RMST}_{C}(24)$. Express the final RMST difference in months and round your final numerical answer to four significant figures. In addition to the calculation, articulate how the sign and magnitude of $\\Delta_{\\text{RMST}}(24)$ would inform clinical relevance in the protocol and potential labeling claims; however, only provide the numerical value as your final answer.",
            "solution": "The problem statement is validated as scientifically grounded, well-posed, objective, and complete. It is based on foundational principles of survival analysis employed in clinical trial design. All necessary mathematical definitions and parameters are provided, allowing for the derivation of a unique, meaningful solution. The scenario described, involving non-proportional hazards, is a standard and realistic challenge in translational medicine for which the Restricted Mean Survival Time (RMST) is an appropriate estimand. The task is to compute the difference in RMST between a treatment and a control group at a fixed truncation time.\n\nThe solution proceeds by first deriving the survival function, $S(t)$, for each group from its respective piecewise-constant hazard function, $\\lambda(t)$, using the fundamental relationship $S(t) = \\exp\\left(-\\int_{0}^{t} \\lambda(u)\\,du\\right)$. Subsequently, the RMST for each group is calculated by integrating the corresponding survival function from $t=0$ to the truncation time $\\tau=24$ months, according to the definition $\\text{RMST}(\\tau) = \\int_{0}^{\\tau} S(t)\\,dt$. Finally, the difference between the treatment and control group RMSTs is computed.\n\n**1. Analysis of the Control Group**\n\nThe hazard function for the control group, $\\lambda_C(t)$, is given as:\n$$\n\\lambda_C(t) =\n\\begin{cases}\n0.06  \\text{for } 0 \\leq t  12 \\\\\n0.03  \\text{for } 12 \\leq t \\leq 24\n\\end{cases}\n$$\nThe cumulative hazard function, $H_C(t) = \\int_0^t \\lambda_C(u)\\,du$, is calculated for two intervals.\nFor $0 \\leq t  12$:\n$$ H_C(t) = \\int_0^t 0.06 \\,du = 0.06t $$\nFor $12 \\leq t \\leq 24$:\n$$ H_C(t) = \\int_0^{12} 0.06 \\,du + \\int_{12}^t 0.03 \\,du = (0.06)(12) + 0.03(t-12) = 0.72 + 0.03t - 0.36 = 0.36 + 0.03t $$\nThe survival function, $S_C(t) = \\exp(-H_C(t))$, is therefore:\n$$\nS_C(t) =\n\\begin{cases}\n\\exp(-0.06t)  \\text{for } 0 \\leq t  12 \\\\\n\\exp(-(0.36 + 0.03t))  \\text{for } 12 \\leq t \\leq 24\n\\end{cases}\n$$\nThe RMST for the control group at $\\tau=24$ is the integral of $S_C(t)$ from $0$ to $24$:\n$$ \\text{RMST}_C(24) = \\int_0^{24} S_C(t)\\,dt = \\int_0^{12} \\exp(-0.06t)\\,dt + \\int_{12}^{24} \\exp(-0.36 - 0.03t)\\,dt $$\nWe evaluate each integral:\n$$ \\int_0^{12} \\exp(-0.06t)\\,dt = \\left[ \\frac{\\exp(-0.06t)}{-0.06} \\right]_0^{12} = \\frac{\\exp(-0.72) - 1}{-0.06} = \\frac{1 - \\exp(-0.72)}{0.06} $$\n$$ \\int_{12}^{24} \\exp(-0.36 - 0.03t)\\,dt = \\exp(-0.36) \\int_{12}^{24} \\exp(-0.03t)\\,dt = \\exp(-0.36) \\left[ \\frac{\\exp(-0.03t)}{-0.03} \\right]_{12}^{24} = \\frac{\\exp(-0.36)}{-0.03} \\left( \\exp(-0.72) - \\exp(-0.36) \\right) = \\frac{\\exp(-0.72) - \\exp(-1.08)}{0.03} $$\nSumming these results gives $\\text{RMST}_C(24)$:\n$$ \\text{RMST}_C(24) = \\frac{1 - \\exp(-0.72)}{0.06} + \\frac{\\exp(-0.72) - \\exp(-1.08)}{0.03} $$\n\n**2. Analysis of the Treatment Group**\n\nThe hazard function for the treatment group, $\\lambda_T(t)$, is given as:\n$$\n\\lambda_T(t) =\n\\begin{cases}\n0.12  \\text{for } 0 \\leq t  6 \\\\\n0.02  \\text{for } 6 \\leq t \\leq 24\n\\end{cases}\n$$\nThe cumulative hazard function, $H_T(t) = \\int_0^t \\lambda_T(u)\\,du$, is calculated for its two intervals.\nFor $0 \\leq t  6$:\n$$ H_T(t) = \\int_0^t 0.12 \\,du = 0.12t $$\nFor $6 \\leq t \\leq 24$:\n$$ H_T(t) = \\int_0^6 0.12 \\,du + \\int_6^t 0.02 \\,du = (0.12)(6) + 0.02(t-6) = 0.72 + 0.02t - 0.12 = 0.60 + 0.02t $$\nThe survival function, $S_T(t) = \\exp(-H_T(t))$, is therefore:\n$$\nS_T(t) =\n\\begin{cases}\n\\exp(-0.12t)  \\text{for } 0 \\leq t  6 \\\\\n\\exp(-(0.60 + 0.02t))  \\text{for } 6 \\leq t \\leq 24\n\\end{cases}\n$$\nThe RMST for the treatment group at $\\tau=24$ is the integral of $S_T(t)$ from $0$ to $24$:\n$$ \\text{RMST}_T(24) = \\int_0^{24} S_T(t)\\,dt = \\int_0^{6} \\exp(-0.12t)\\,dt + \\int_{6}^{24} \\exp(-0.60 - 0.02t)\\,dt $$\nWe evaluate each integral:\n$$ \\int_0^{6} \\exp(-0.12t)\\,dt = \\left[ \\frac{\\exp(-0.12t)}{-0.12} \\right]_0^{6} = \\frac{\\exp(-0.72) - 1}{-0.12} = \\frac{1 - \\exp(-0.72)}{0.12} $$\n$$ \\int_{6}^{24} \\exp(-0.60 - 0.02t)\\,dt = \\exp(-0.60) \\int_{6}^{24} \\exp(-0.02t)\\,dt = \\exp(-0.60) \\left[ \\frac{\\exp(-0.02t)}{-0.02} \\right]_{6}^{24} = \\frac{\\exp(-0.60)}{-0.02} \\left( \\exp(-0.48) - \\exp(-0.12) \\right) = \\frac{\\exp(-0.72) - \\exp(-1.08)}{0.02} $$\nSumming these results gives $\\text{RMST}_T(24)$:\n$$ \\text{RMST}_T(24) = \\frac{1 - \\exp(-0.72)}{0.12} + \\frac{\\exp(-0.72) - \\exp(-1.08)}{0.02} $$\n\n**3. Calculation of the RMST Difference $\\Delta_{\\text{RMST}}(24)$**\n\nThe prespecified estimand is the difference $\\Delta_{\\text{RMST}}(24) = \\text{RMST}_T(24) - \\text{RMST}_C(24)$.\n$$ \\Delta_{\\text{RMST}}(24) = \\left( \\frac{1 - \\exp(-0.72)}{0.12} + \\frac{\\exp(-0.72) - \\exp(-1.08)}{0.02} \\right) - \\left( \\frac{1 - \\exp(-0.72)}{0.06} + \\frac{\\exp(-0.72) - \\exp(-1.08)}{0.03} \\right) $$\nGrouping like terms:\n$$ \\Delta_{\\text{RMST}}(24) = (1 - \\exp(-0.72)) \\left(\\frac{1}{0.12} - \\frac{1}{0.06}\\right) + (\\exp(-0.72) - \\exp(-1.08)) \\left(\\frac{1}{0.02} - \\frac{1}{0.03}\\right) $$\n$$ \\Delta_{\\text{RMST}}(24) = (1 - \\exp(-0.72)) \\left(\\frac{1-2}{0.12}\\right) + (\\exp(-0.72) - \\exp(-1.08)) \\left(\\frac{3-2}{0.06}\\right) $$\n$$ \\Delta_{\\text{RMST}}(24) = -\\frac{1 - \\exp(-0.72)}{0.12} + \\frac{\\exp(-0.72) - \\exp(-1.08)}{0.06} $$\nNow, we substitute numerical values for the exponential functions: $\\exp(-0.72) \\approx 0.486752$ and $\\exp(-1.08) \\approx 0.339596$.\n\nFirst, we calculate the individual RMST values:\n$$ \\text{RMST}_C(24) \\approx \\frac{1 - 0.486752}{0.06} + \\frac{0.486752 - 0.339596}{0.03} = \\frac{0.513248}{0.06} + \\frac{0.147156}{0.03} = 8.554133 + 4.905200 = 13.459333 \\text{ months} $$\n$$ \\text{RMST}_T(24) \\approx \\frac{1 - 0.486752}{0.12} + \\frac{0.486752 - 0.339596}{0.02} = \\frac{0.513248}{0.12} + \\frac{0.147156}{0.02} = 4.277067 + 7.357800 = 11.634867 \\text{ months} $$\nThe difference is:\n$$ \\Delta_{\\text{RMST}}(24) = 11.634867 - 13.459333 = -1.824466 \\text{ months} $$\n\nThe interpretation of this result is critical for the clinical trial protocol and potential labeling. The negative sign of $\\Delta_{\\text{RMST}}(24)$ indicates that, within the restricted time frame of $24$ months, the average survival time in the treatment group is shorter than in the control group. The magnitude, approximately $1.82$ months, quantifies this loss in mean survival time. This result reflects that the high initial hazard (early risk) in the treatment arm is not fully compensated by the lower long-term hazard (later benefit) within the prespecified $24$-month window. Such a result for a primary estimand would suggest that the treatment is detrimental in this timeframe and would likely prevent a labeling claim of benefit based on this analysis. For the protocol, this underscores the critical importance of a robust justification for the choice of truncation time $\\tau$, and perhaps suggests the need to prespecify co-primary or secondary analyses at later time points where the long-term benefit might overcome the initial harm.\n\nRounding the final numerical answer to four significant figures gives $-1.824$.",
            "answer": "$$\n\\boxed{-1.824}\n$$"
        },
        {
            "introduction": "Modern clinical trial protocols are increasingly dynamic, incorporating pre-planned interim analyses to allow for adaptive decision-making based on accumulating data. A key metric guiding these decisions is conditional power: the probability of achieving a statistically significant result at the end of the trial, given the data observed so far. This advanced practice  demonstrates how to derive and calculate conditional power, providing you with the statistical tools to evaluate a trial's trajectory and make informed recommendations to continue, stop for futility, or modify the study design.",
            "id": "4998728",
            "problem": "A translational medicine Randomized Controlled Trial (RCT) is evaluating a biomarker-guided therapy on a continuous primary endpoint, assumed approximately normally distributed with a common variance across arms. The confirmatory analysis is a two-sided superiority test at type I error rate $\\alpha = 0.05$, with superiority declared for a benefit in the positive direction. Equal allocation is used. The planned maximum sample size is $N_{\\text{final}} = 200$ per arm. An interim analysis is scheduled after $N_{1} = 80$ per arm. The pooled sample variance estimate at interim is $s^{2} = 225$ and is assumed stable for planning. The observed interim mean difference (treatment minus control) is $\\hat{d}_{1} = 3.0$ (in the endpoint’s native units).\n\nAssume the large-sample normal approximation for the difference in means and the additivity of Fisher information. Treat the observed interim effect as the working alternative for predictive assessment; that is, assume the true mean difference $\\delta$ equals the observed interim estimate $\\hat{d}_{1}$. Using only these assumptions, derive from first principles the conditional distribution of the final $Z$-statistic given the interim data, and from it, the conditional power to reject the null hypothesis at the planned final analysis. Use the two-sided normal-theory critical value $z_{1-\\alpha/2}$ for the final boundary. Compute the numerical value of this conditional power.\n\nThe Independent Data Monitoring Committee (IDMC) will apply the following thresholds for adaptation: if the conditional power is less than $0.2$, consider non-binding futility stopping; if it lies in $[0.2, 0.8)$, consider sample size re-estimation targeting conditional power $0.9$; if it is at least $0.8$, continue as planned. However, for this question, only report the conditional power value.\n\nExpress the conditional power as a decimal (not a percentage) and round to four significant figures. Do not report any decision; report only the computed conditional power.",
            "solution": "The problem is assessed to be valid as it is scientifically grounded in standard statistical theory for clinical trials, is well-posed with sufficient and consistent information, and is stated objectively.\n\nWe are tasked with deriving the conditional distribution of the final test statistic given the interim results, and then computing the conditional power for rejecting the null hypothesis.\n\nLet $\\delta$ be the true mean difference between the treatment and control arms. The endpoint is a continuous variable assumed to be normally distributed with a common variance $\\sigma^2$ in both arms. The problem supplies a pooled sample variance estimate $s^2 = 225$, which we will use as the true population variance $\\sigma^2$ for planning purposes, so $\\sigma^2 = 225$.\n\nLet $N_1$ be the sample size per arm at the interim analysis and $N_{\\text{final}}$ be the total planned sample size per arm. We are given $N_1 = 80$ and $N_{\\text{final}} = 200$.\n\nThe estimate of the mean difference at the interim analysis is $\\hat{d}_1$. Under the large-sample approximation, $\\hat{d}_1$ is normally distributed:\n$$ \\hat{d}_1 \\sim N\\left(\\delta, \\frac{2\\sigma^2}{N_1}\\right) $$\nThe corresponding $Z$-statistic at the interim analysis, $Z_1$, is given by:\n$$ Z_1 = \\frac{\\hat{d}_1}{\\sqrt{2\\sigma^2 / N_1}} \\sim N\\left(\\frac{\\delta}{\\sqrt{2\\sigma^2 / N_1}}, 1\\right) $$\nThe final estimate of the mean difference, $\\hat{d}_{\\text{final}}$, based on $N_{\\text{final}}$ subjects per arm, is also normally distributed:\n$$ \\hat{d}_{\\text{final}} \\sim N\\left(\\delta, \\frac{2\\sigma^2}{N_{\\text{final}}}\\right) $$\nThe final $Z$-statistic, $Z_{\\text{final}}$, is:\n$$ Z_{\\text{final}} = \\frac{\\hat{d}_{\\text{final}}}{\\sqrt{2\\sigma^2 / N_{\\text{final}}}} \\sim N\\left(\\frac{\\delta}{\\sqrt{2\\sigma^2 / N_{\\text{final}}}}, 1\\right) $$\nDue to the sequential nature of data collection, with the data at the final analysis including the data from the interim analysis, the statistics $Z_1$ and $Z_{\\text{final}}$ are not independent. Their joint distribution is approximately bivariate normal. The covariance between them is:\n$$ \\text{Cov}(Z_1, Z_{\\text{final}}) = \\text{Cov}\\left(\\frac{\\hat{d}_1}{\\sqrt{2\\sigma^2/N_1}}, \\frac{\\hat{d}_{\\text{final}}}{\\sqrt{2\\sigma^2/N_{\\text{final}}}}\\right) $$\nSince $\\hat{d}_{\\text{final}}$ is the average difference over all $N_{\\text{final}}$ subjects, and $\\hat{d}_1$ is the average over the first $N_1$ subjects, we can write $\\hat{d}_{\\text{final}} = \\frac{N_1 \\hat{d}_1 + (N_{\\text{final}}-N_1)\\hat{d}_2}{N_{\\text{final}}}$, where $\\hat{d}_2$ is the estimate from the new subjects enrolled after the interim analysis. As $\\hat{d}_1$ and $\\hat{d}_2$ are independent, $\\text{Cov}(\\hat{d}_1, \\hat{d}_{\\text{final}}) = \\text{Var}(\\hat{d}_1)\\frac{N_1}{N_{\\text{final}}} = \\frac{2\\sigma^2}{N_1}\\frac{N_1}{N_{\\text{final}}} = \\frac{2\\sigma^2}{N_{\\text{final}}}$.\nSubstituting this into the covariance for the $Z$-statistics:\n$$ \\text{Cov}(Z_1, Z_{\\text{final}}) = \\frac{1}{\\sqrt{2\\sigma^2/N_1}\\sqrt{2\\sigma^2/N_{\\text{final}}}}\\text{Cov}(\\hat{d}_1, \\hat{d}_{\\text{final}}) = \\frac{\\sqrt{N_1 N_{\\text{final}}}}{2\\sigma^2} \\frac{2\\sigma^2}{N_{\\text{final}}} = \\sqrt{\\frac{N_1}{N_{\\text{final}}}} $$\nSince the variances are both $1$, this is also their correlation, $\\rho = \\sqrt{N_1/N_{\\text{final}}}$.\nSo, $(Z_1, Z_{\\text{final}})$ follow a bivariate normal distribution:\n$$ \\begin{pmatrix} Z_1 \\\\ Z_{\\text{final}} \\end{pmatrix} \\sim N\\left( \\begin{pmatrix} \\delta\\sqrt{\\frac{N_1}{2\\sigma^2}} \\\\ \\delta\\sqrt{\\frac{N_{\\text{final}}}{2\\sigma^2}} \\end{pmatrix}, \\begin{pmatrix} 1  \\sqrt{\\frac{N_1}{N_{\\text{final}}}} \\\\ \\sqrt{\\frac{N_1}{N_{\\text{final}}}}  1 \\end{pmatrix} \\right) $$\nFrom the properties of the bivariate normal distribution, the conditional distribution of $Z_{\\text{final}}$ given the observed value $Z_1 = z_1$ is also normal. The parameters of this conditional distribution are:\nConditional Mean: $E[Z_{\\text{final}}|Z_1=z_1] = E[Z_{\\text{final}}] + \\rho(z_1 - E[Z_1])$\n$$ E[Z_{\\text{final}}|Z_1=z_1] = \\delta\\sqrt{\\frac{N_{\\text{final}}}{2\\sigma^2}} + \\sqrt{\\frac{N_1}{N_{\\text{final}}}}\\left(z_1 - \\delta\\sqrt{\\frac{N_1}{2\\sigma^2}}\\right) $$\nConditional Variance: $\\text{Var}(Z_{\\text{final}}|Z_1=z_1) = \\text{Var}(Z_{\\text{final}})(1 - \\rho^2)$\n$$ \\text{Var}(Z_{\\text{final}}|Z_1=z_1) = 1 \\cdot \\left(1 - \\frac{N_1}{N_{\\text{final}}}\\right) = \\frac{N_{\\text{final}}-N_1}{N_{\\text{final}}} $$\nThis completes the first part of the derivation.\n\nThe problem states that for predictive assessment, we must assume the true mean difference $\\delta$ is equal to the observed interim estimate $\\hat{d}_1$. Given $\\hat{d}_1 = 3.0$, we set $\\delta = 3.0$.\nUnder this assumption, the expected value of $Z_1$, $E[Z_1]$, becomes numerically equal to the observed value $z_1$:\n$$ E[Z_1] = \\delta\\sqrt{\\frac{N_1}{2\\sigma^2}} = \\hat{d}_1\\sqrt{\\frac{N_1}{2\\sigma^2}} = \\frac{\\hat{d}_1}{\\sqrt{2\\sigma^2/N_1}} = z_1 $$\nSubstituting this result ($E[Z_1] = z_1$) into the formula for the conditional mean simplifies it significantly:\n$$ E[Z_{\\text{final}}|Z_1=z_1, \\delta=\\hat{d}_1] = \\delta\\sqrt{\\frac{N_{\\text{final}}}{2\\sigma^2}} + \\sqrt{\\frac{N_1}{N_{\\text{final}}}}(z_1 - z_1) = \\delta\\sqrt{\\frac{N_{\\text{final}}}{2\\sigma^2}} = \\hat{d}_1\\sqrt{\\frac{N_{\\text{final}}}{2\\sigma^2}} $$\nThus, the conditional distribution of $Z_{\\text{final}}$ given the interim data and the assumption $\\delta = \\hat{d}_1$ is:\n$$ Z_{\\text{final}} | (\\text{data at interim}) \\sim N\\left(\\hat{d}_1\\sqrt{\\frac{N_{\\text{final}}}{2\\sigma^2}}, \\frac{N_{\\text{final}}-N_1}{N_{\\text{final}}}\\right) $$\nConditional power (CP) is the probability of rejecting the null hypothesis $H_0: \\delta=0$ at the final analysis, given this conditional distribution. For a two-sided test at significance level $\\alpha=0.05$, rejection occurs if $|Z_{\\text{final}}|  z_{1-\\alpha/2}$. As the observed effect is positive ($\\hat{d}_1 = 3.0$), we are interested in the probability of rejecting in the positive direction, $Z_{\\text{final}}  z_{1-\\alpha/2}$.\n$$ \\text{CP} = P(Z_{\\text{final}}  z_{1-\\alpha/2} | \\text{interim data}, \\delta=\\hat{d}_1) $$\nLet $\\Phi(\\cdot)$ be the cumulative distribution function of the standard normal distribution. Then:\n$$ \\text{CP} = 1 - \\Phi\\left(\\frac{z_{1-\\alpha/2} - E[Z_{\\text{final}}|Z_1=z_1, \\delta=\\hat{d}_1]}{\\sqrt{\\text{Var}(Z_{\\text{final}}|Z_1=z_1, \\delta=\\hat{d}_1)}}\\right) $$\n$$ \\text{CP} = 1 - \\Phi\\left(\\frac{z_{1-\\alpha/2} - \\hat{d}_1\\sqrt{\\frac{N_{\\text{final}}}{2\\sigma^2}}}{\\sqrt{\\frac{N_{\\text{final}}-N_1}{N_{\\text{final}}}}}\\right) $$\nNow, we substitute the numerical values:\n$\\alpha = 0.05 \\implies z_{1-\\alpha/2} = z_{0.975} \\approx 1.959964$\n$\\hat{d}_1 = 3.0$\n$\\sigma^2 = 225$\n$N_1 = 80$\n$N_{\\text{final}} = 200$\n\nCalculate the conditional mean:\n$$ \\mu_{\\text{cond}} = \\hat{d}_1\\sqrt{\\frac{N_{\\text{final}}}{2\\sigma^2}} = 3.0 \\times \\sqrt{\\frac{200}{2 \\times 225}} = 3.0 \\times \\sqrt{\\frac{200}{450}} = 3.0 \\times \\sqrt{\\frac{4}{9}} = 3.0 \\times \\frac{2}{3} = 2.0 $$\nCalculate the conditional variance:\n$$ \\sigma^2_{\\text{cond}} = \\frac{N_{\\text{final}}-N_1}{N_{\\text{final}}} = \\frac{200-80}{200} = \\frac{120}{200} = 0.6 $$\nThe argument of $\\Phi$ is:\n$$ \\frac{z_{0.975} - \\mu_{\\text{cond}}}{\\sqrt{\\sigma^2_{\\text{cond}}}} = \\frac{1.959964 - 2.0}{\\sqrt{0.6}} = \\frac{-0.040036}{\\sqrt{0.6}} \\approx -0.051686 $$\nThe conditional power is:\n$$ \\text{CP} = 1 - \\Phi(-0.051686) = \\Phi(0.051686) $$\nUsing a standard normal calculator, we find:\n$$ \\text{CP} \\approx 0.520603 $$\nRounding to four significant figures as requested, the conditional power is $0.5206$.",
            "answer": "$$\\boxed{0.5206}$$"
        }
    ]
}