{
    "hands_on_practices": [
        {
            "introduction": "A cornerstone of designing any rigorous clinical trial is determining the appropriate number of participants. This first practice grounds you in the statistical theory behind sample size calculation, moving beyond simple formula plug-ins. By deriving the required sample size from foundational principles such as the Central Limit Theorem and the definitions of Type I and Type II errors, you will gain a deep understanding of how statistical power, effect size, and variability interrelate in a typical Phase IIa proof-of-concept study . Mastering this derivation is a critical skill for planning trials that are both ethically responsible and scientifically robust.",
            "id": "5044167",
            "problem": "A translational proof-of-concept Phase IIa study plans a randomized, parallel, two-arm design comparing an investigational agent against placebo on a continuous biomarker endpoint defined as change from baseline. Assume that the individual change-from-baseline values in each arm are independent and identically distributed, with common standard deviation $\\,\\sigma\\,$, and that the mean difference in change (investigational minus placebo) to be detected is a strictly positive value $\\,\\Delta\\,$. The analysis will use a two-sided hypothesis test at type I error $\\,\\alpha\\,$ and target power $\\,1-\\beta\\,$, with equal allocation between arms and the large-sample normal approximation.\n\nStarting only from the following foundational elements:\n- The sampling distribution of a sample mean from independent, identically distributed observations is approximately normal by the Central Limit Theorem, with variance equal to the individual variance divided by the sample size.\n- For two independent arms with equal per-arm sample size $\\,n\\,$ and common variance $\\,\\sigma^{2}\\,$, the variance of the difference of sample means is the sum of the variances of the two sample means.\n- For a two-sided level-$\\,\\alpha\\,$ z-test, the critical value is the upper $\\,1-\\alpha/2\\,$ quantile of the standard normal distribution, denoted $\\,z_{1-\\alpha/2}\\,$. The upper $\\,1-\\beta\\,$ quantile is denoted $\\,z_{1-\\beta}\\,$.\n\nDerive, in closed form and simplified as much as possible, the exact analytic expression for the required per-arm sample size $\\,n\\,$ as a function of $\\,\\sigma\\,$, $\\,\\Delta\\,$, $\\,\\alpha\\,$, and $\\,\\beta\\,$ that ensures the specified two-sided type I error and power to detect the mean difference $\\,\\Delta\\,$. Provide your final answer as a single closed-form expression. Do not substitute numerical values. Do not report units. No rounding is needed because the answer must be an analytic expression.",
            "solution": "Let the true mean change from baseline for the investigational agent be $\\mu_I$ and for the placebo be $\\mu_P$. The per-arm sample size is $n$, and the common standard deviation of individual observations is $\\sigma$. The null and alternative hypotheses for the two-sided test are:\n$$H_0: \\mu_I - \\mu_P = 0$$\n$$H_A: \\mu_I - \\mu_P \\neq 0$$\nLet $\\bar{X}_I$ and $\\bar{X}_P$ denote the sample means of the change-from-baseline values for the investigational and placebo arms, respectively. The test statistic is based on the difference of these sample means, $\\bar{X}_I - \\bar{X}_P$.\n\nAccording to the first foundational element (Central Limit Theorem), the sampling distributions of the sample means are approximately normal:\n$$\\bar{X}_I \\sim N\\left(\\mu_I, \\frac{\\sigma^2}{n}\\right)$$\n$$\\bar{X}_P \\sim N\\left(\\mu_P, \\frac{\\sigma^2}{n}\\right)$$\nwhere $N(\\mu, \\sigma^2)$ denotes a normal distribution with mean $\\mu$ and variance $\\sigma^2$.\n\nThe two arms are independent. Using the second foundational element, the variance of the difference of the sample means is the sum of their individual variances:\n$$\\text{Var}(\\bar{X}_I - \\bar{X}_P) = \\text{Var}(\\bar{X}_I) + \\text{Var}(\\bar{X}_P) = \\frac{\\sigma^2}{n} + \\frac{\\sigma^2}{n} = \\frac{2\\sigma^2}{n}$$\nThe standard error of the difference is the square root of this variance, $\\text{SE}(\\bar{X}_I - \\bar{X}_P) = \\sqrt{\\frac{2\\sigma^2}{n}} = \\sigma\\sqrt{\\frac{2}{n}}$.\nSince $\\bar{X}_I$ and $\\bar{X}_P$ are approximately normally distributed, their difference is also approximately normally distributed:\n$$\\bar{X}_I - \\bar{X}_P \\sim N\\left(\\mu_I - \\mu_P, \\frac{2\\sigma^2}{n}\\right)$$\n\nUnder the null hypothesis $H_0$, $\\mu_I - \\mu_P = 0$, so the distribution of the difference in sample means is centered at $0$:\n$$\\bar{X}_I - \\bar{X}_P \\sim N\\left(0, \\frac{2\\sigma^2}{n}\\right)$$\nThe standardized test statistic under $H_0$ is:\n$$Z = \\frac{(\\bar{X}_I - \\bar{X}_P) - 0}{\\sigma\\sqrt{\\frac{2}{n}}} \\sim N(0, 1)$$\n\nFor a two-sided test at a type I error level of $\\alpha$, we reject $H_0$ if the test statistic falls in the extreme tails of the standard normal distribution. Based on the third foundational element, the critical values are $\\pm z_{1-\\alpha/2}$. The null hypothesis is rejected if $|Z| > z_{1-\\alpha/2}$, which is equivalent to:\n$$|\\bar{X}_I - \\bar{X}_P| > z_{1-\\alpha/2} \\sigma \\sqrt{\\frac{2}{n}}$$\nLet the upper boundary of this rejection region be denoted by $C = z_{1-\\alpha/2} \\sigma \\sqrt{\\frac{2}{n}}$. We reject $H_0$ if $\\bar{X}_I - \\bar{X}_P > C$ or $\\bar{X}_I - \\bar{X}_P  -C$.\n\nNext, we impose the condition for statistical power. Power is the probability of correctly rejecting $H_0$ when the alternative hypothesis is true. The problem specifies a target power of $1-\\beta$ to detect a specific mean difference $\\Delta > 0$. We therefore consider the specific alternative hypothesis $H_A': \\mu_I - \\mu_P = \\Delta$.\nUnder $H_A'$, the sampling distribution of the difference is:\n$$\\bar{X}_I - \\bar{X}_P \\sim N\\left(\\Delta, \\frac{2\\sigma^2}{n}\\right)$$\nPower is the probability of the observed difference falling into the rejection region, given that the true difference is $\\Delta$:\n$$\\text{Power} = P\\left(|\\bar{X}_I - \\bar{X}_P| > C \\mid \\mu_I - \\mu_P = \\Delta \\right) = 1-\\beta$$\nThis can be written as:\n$$P\\left(\\bar{X}_I - \\bar{X}_P > C \\mid \\mu_I - \\mu_P = \\Delta\\right) + P\\left(\\bar{X}_I - \\bar{X}_P  -C \\mid \\mu_I - \\mu_P = \\Delta\\right) = 1-\\beta$$\nSince $\\Delta > 0$ and $C > 0$, the mean of the distribution under the alternative hypothesis is shifted to the right. The probability of observing $\\bar{X}_I - \\bar{X}_P  -C$ is negligible for typical power levels, so the power is dominated by the first term. Thus, we can approximate the power as:\n$$P\\left(\\bar{X}_I - \\bar{X}_P > C \\mid \\mu_I - \\mu_P = \\Delta\\right) \\approx 1-\\beta$$\nTo evaluate this probability, we standardize the variable $\\bar{X}_I - \\bar{X}_P$ using its distribution under $H_A'$:\n$$P\\left( \\frac{(\\bar{X}_I - \\bar{X}_P) - \\Delta}{\\sigma\\sqrt{\\frac{2}{n}}} > \\frac{C - \\Delta}{\\sigma\\sqrt{\\frac{2}{n}}} \\right) \\approx 1-\\beta$$\nThe random variable on the left is a standard normal variable, $Z' \\sim N(0,1)$. The condition becomes $P\\left(Z' > \\frac{C - \\Delta}{\\sigma\\sqrt{\\frac{2}{n}}}\\right) \\approx 1-\\beta$.\nFor this to hold, the argument $\\frac{C - \\Delta}{\\sigma\\sqrt{\\frac{2}{n}}}$ must be equal to the standard normal quantile $z_{\\beta}$ for which $P(Z' > z_{\\beta}) = 1-\\beta$. By symmetry of the normal distribution, $z_{\\beta} = -z_{1-\\beta}$. The notation $z_{1-\\beta}$ is defined in the third foundational element.\nThus, we have the equation:\n$$\\frac{C - \\Delta}{\\sigma\\sqrt{\\frac{2}{n}}} = -z_{1-\\beta}$$\nNow, we substitute the expression for the critical value $C = z_{1-\\alpha/2} \\sigma \\sqrt{\\frac{2}{n}}$ into this equation:\n$$\\frac{z_{1-\\alpha/2} \\sigma \\sqrt{\\frac{2}{n}} - \\Delta}{\\sigma\\sqrt{\\frac{2}{n}}} = -z_{1-\\beta}$$\nDividing the terms on the left side yields:\n$$z_{1-\\alpha/2} - \\frac{\\Delta}{\\sigma\\sqrt{\\frac{2}{n}}} = -z_{1-\\beta}$$\nRearranging to solve for the term containing $n$:\n$$z_{1-\\alpha/2} + z_{1-\\beta} = \\frac{\\Delta}{\\sigma\\sqrt{\\frac{2}{n}}} = \\frac{\\Delta \\sqrt{n}}{\\sigma\\sqrt{2}}$$\nNow, we isolate $\\sqrt{n}$:\n$$\\sqrt{n} = \\frac{\\sigma\\sqrt{2} (z_{1-\\alpha/2} + z_{1-\\beta})}{\\Delta}$$\nFinally, we square both sides to obtain the expression for the required sample size per arm, $n$:\n$$n = \\left(\\frac{\\sigma\\sqrt{2} (z_{1-\\alpha/2} + z_{1-\\beta})}{\\Delta}\\right)^2$$\nSimplifying this expression gives the final closed-form solution:\n$$n = \\frac{2\\sigma^2(z_{1-\\alpha/2} + z_{1-\\beta})^2}{\\Delta^2}$$\nThis expression can also be written as $n = 2 \\left( \\frac{\\sigma}{\\Delta} \\right)^2 (z_{1-\\alpha/2} + z_{1-\\beta})^2$.",
            "answer": "$$\\boxed{\\frac{2\\sigma^2(z_{1-\\alpha/2} + z_{1-\\beta})^2}{\\Delta^2}}$$"
        },
        {
            "introduction": "Once a Phase IIb trial has generated data across multiple doses, the primary goal is to inform the selection of a dose for pivotal Phase III studies. This exercise demonstrates the crucial translational step of applying a pharmacokinetic-pharmacodynamic (PK/PD) model to make this decision. You will work with the widely used maximum effect ($E_{\\max}$) model, which mathematically describes the saturable relationship between drug exposure and clinical effect, to calculate the precise oral dose predicted to achieve a specific target therapeutic effect . This practice bridges the gap between data analysis and actionable clinical strategy.",
            "id": "5044142",
            "problem": "In a Phase IIb (dose-ranging) trial for an oral small-molecule therapy, investigators characterized the exposure-response using a saturable maximum-effect model grounded in receptor occupancy principles, with baseline effect added. Under linear Pharmacokinetics (PK), the systemic exposure over the dosing interval is proportional to the administered oral dose scaled by absolute oral bioavailability. Specifically, assume the following well-tested components:\n- The effect end point is modeled as an additive baseline response plus a saturable incremental effect consistent with a maximum-effect model: if the exposure index is $X$, the effect is $E=E_{0}+E_{\\max}\\,\\frac{X}{ED_{50}+X}$.\n- The exposure index is proportional to the systemically available dose, and for the dosing regimen under consideration the proportionality is normalized such that $X=F\\cdot D$, where $F$ is the absolute oral bioavailability and $D$ is the administered oral dose.\n- The median effective dose (ED50) parameter $ED_{50}$ represents the exposure index at which one-half of the maximal incremental effect is achieved.\n\nYou are given the following estimates from the model fit to Phase IIa (proof-of-concept) and Phase IIb (dose-ranging) data: baseline effect $E_{0}=5$ (arbitrary effect units), maximum incremental effect $E_{\\max}=30$ (same effect units), median effective dose parameter $ED_{50}=150$ (exposure units consistent with $X=F\\cdot D$), and absolute oral bioavailability $F=0.4$. The clinical team has specified a target incremental effect above baseline of $\\theta^{*}=18$ (same effect units), that is, $E=E_{0}+\\theta^{*}$.\n\nUsing only the definitions above, derive from first principles an explicit expression for the oral dose $D$ that achieves $E=E_{0}+\\theta^{*}$, and then compute its value for the parameter values $E_{0}=5$, $E_{\\max}=30$, $ED_{50}=150$, $F=0.4$, and $\\theta^{*}=18$. Express the final dose in mg and round your answer to four significant figures.",
            "solution": "The objective is to find the oral dose, $D$, that results in a target effect, $E_{\\text{target}}$.\n\nThe target effect is specified as an incremental effect of $\\theta^{*}$ above the baseline effect $E_{0}$.\n$$E_{\\text{target}} = E_{0} + \\theta^{*}$$\n\nThe effect produced by the drug is described by the $E_{\\max}$ model:\n$$E = E_{0} + E_{\\max}\\,\\frac{X}{ED_{50}+X}$$\n\nTo achieve the target effect, we set $E = E_{\\text{target}}$:\n$$E_{0} + \\theta^{*} = E_{0} + E_{\\max}\\,\\frac{X}{ED_{50}+X}$$\n\nSubtracting the baseline effect, $E_{0}$, from both sides isolates the drug-induced effect:\n$$\\theta^{*} = E_{\\max}\\,\\frac{X}{ED_{50}+X}$$\n\nNow, we must solve this equation for the exposure index, $X$, that is required to produce the incremental effect $\\theta^{*}$.\nFirst, divide by $E_{\\max}$:\n$$\\frac{\\theta^{*}}{E_{\\max}} = \\frac{X}{ED_{50}+X}$$\n\nTo solve for $X$, we can take the reciprocal of both sides:\n$$\\frac{E_{\\max}}{\\theta^{*}} = \\frac{ED_{50}+X}{X} = \\frac{ED_{50}}{X} + 1$$\n\nRearranging the equation to isolate the term with $X$:\n$$\\frac{E_{\\max}}{\\theta^{*}} - 1 = \\frac{ED_{50}}{X}$$\n$$\\frac{E_{\\max} - \\theta^{*}}{\\theta^{*}} = \\frac{ED_{50}}{X}$$\n\nSolving for $X$:\n$$X = ED_{50} \\left( \\frac{\\theta^{*}}{E_{\\max} - \\theta^{*}} \\right) = \\frac{\\theta^{*} \\cdot ED_{50}}{E_{\\max} - \\theta^{*}}$$\n\nThis expression gives the required systemic exposure index $X$. The problem links this exposure index to the administered oral dose $D$ via the absolute bioavailability $F$:\n$$X = F \\cdot D$$\n\nSubstituting this into our expression for $X$:\n$$F \\cdot D = \\frac{\\theta^{*} \\cdot ED_{50}}{E_{\\max} - \\theta^{*}}$$\n\nFinally, we solve for the dose $D$ by dividing by $F$:\n$$D = \\frac{\\theta^{*} \\cdot ED_{50}}{F (E_{\\max} - \\theta^{*})}$$\n\nThis is the explicit expression for the oral dose $D$ that achieves the target effect.\n\nNow, we substitute the given numerical values into this expression:\n- $\\theta^{*} = 18$\n- $ED_{50} = 150$\n- $F = 0.4$\n- $E_{\\max} = 30$\n\n$$D = \\frac{18 \\cdot 150}{0.4 (30 - 18)}$$\n$$D = \\frac{2700}{0.4 (12)}$$\n$$D = \\frac{2700}{4.8}$$\n$$D = 562.5$$\n\nThe problem specifies that the units of $ED_{50}$ are consistent with $X=F \\cdot D$. Since $F$ is dimensionless, the units of $X$, and therefore $ED_{50}$, are the same as the units of dose, $D$. The problem asks for the final answer to be expressed in milligrams (mg), so we assume the implicit unit for dose throughout the calculation is mg.\n\nThe final numerical result is $562.5$. The problem asks to round the answer to four significant figures. The number $562.5$ already has four significant figures. Thus, no further rounding is necessary.\nThe required dose is $562.5$ mg.",
            "answer": "$$\\boxed{562.5}$$"
        },
        {
            "introduction": "Modern clinical trials are increasingly moving away from static, fixed designs toward adaptive approaches that learn as data accumulates. This hands-on programming exercise allows you to build a simulation of a Bayesian adaptive randomization trial, a sophisticated design often used in Phase II studies. By implementing an algorithm that dynamically updates allocation probabilities based on the posterior probability of each dose meeting a target efficacy threshold, you will gain practical experience with a powerful method that can accelerate drug development and increase trial efficiency . This practice will solidify your understanding of how Bayesian principles can be applied to create more intelligent and ethical clinical trials.",
            "id": "5044148",
            "problem": "Construct a program that implements an Adaptive Randomization (AR) procedure for Phase II clinical trial dose allocation using a Bayesian model that increases allocation to doses with higher posterior probabilities of achieving a prespecified target effect. The context is translational medicine, specifically Phase IIa (Proof-of-Concept (PoC)) and Phase IIb (dose-ranging) trials. The problem must be framed purely in mathematical and logical terms and solved by deriving the algorithm from the following fundamental base.\n\nFundamental base:\n- Bayes' theorem: for unknown parameter $\\theta$ and observed data $D$, the posterior satisfies $p(\\theta \\mid D) \\propto p(D \\mid \\theta) p(\\theta)$.\n- Conjugate Beta-Binomial model: if the unknown efficacy probability $p_k$ of dose $k$ has prior $\\mathrm{Beta}(\\alpha_k,\\beta_k)$ and binary outcomes are Bernoulli, then after observing $s_k$ successes and $f_k$ failures, the posterior is $\\mathrm{Beta}(\\alpha_k + s_k,\\beta_k + f_k)$.\n- Posterior probability of meeting a target threshold $\\tau$ for dose $k$ is $q_k = \\Pr(p_k \\ge \\tau \\mid D) = 1 - F_{\\mathrm{Beta}}(\\tau; \\alpha_k + s_k, \\beta_k + f_k)$, where $F_{\\mathrm{Beta}}(\\cdot; a,b)$ is the cumulative distribution function of the Beta distribution with parameters $(a,b)$.\n\nAlgorithm to be constructed:\n- Let there be $K$ candidate doses, indexed by $k \\in \\{1,\\dots,K\\}$, with unknown efficacy probabilities $p_k$. Initialize each dose with prior $\\mathrm{Beta}(\\alpha_k,\\beta_k)$ and observed counts $s_k = 0$, $f_k = 0$.\n- At each cohort step $t \\in \\{1,\\dots,T\\}$ with cohort size $c$, compute the posterior for each dose: $\\mathrm{Beta}(\\alpha_k + s_k,\\beta_k + f_k)$.\n- Compute the posterior probability of meeting the target effect threshold $\\tau$: $q_k = 1 - F_{\\mathrm{Beta}}(\\tau; \\alpha_k + s_k, \\beta_k + f_k)$.\n- Define allocation weights $\\tilde{w}_k = (q_k + \\delta)^{\\eta}$, where $\\eta  0$ controls the strength of adaptiveness and $\\delta  0$ is a small constant to prevent zero weights.\n- Normalize to obtain randomization probabilities $r_k = \\tilde{w}_k / \\sum_{j=1}^{K} \\tilde{w}_j$.\n- Randomly allocate the $c$ patients in cohort $t$ using a multinomial draw with probabilities $(r_1,\\dots,r_K)$. To guarantee reproducibility, use a pseudo-random number generator with a fixed seed specified per test case.\n- For testing purposes (not part of the real trial), assume ground-truth efficacy probabilities $p_k^{\\star}$ are known and simulate outcomes for the allocated patients at each dose using Bernoulli draws with probabilities $p_k^{\\star}$. Update $s_k$ and $f_k$ accordingly and iterate to the next cohort.\n- After $T$ cohorts, output the final total allocations to each dose as a list of integers $[n_1,\\dots,n_K]$, where $n_k$ is the total number of patients allocated to dose $k$.\n\nAngle units are not applicable. Physical units are not applicable. Express any proportions or probabilities as decimals, not with the percentage sign.\n\nYour program should produce a single line of output containing the results for all test cases as a comma-separated list enclosed in square brackets, with each test caseâ€™s result expressed as its own bracketed list and no spaces. For example, the overall output must look like $[ [x_1,x_2], [y_1,y_2,y_3], \\dots ]$ but with no spaces: $[[x_1,x_2],[y_1,y_2,y_3],\\dots]$.\n\nTest suite:\nFor each test case, specify $(K, \\alpha, \\beta, \\tau, p^{\\star}, T, c, \\eta, \\delta, \\text{seed})$.\n\n- Test case A (general \"happy path\"): $K = 3$, $\\alpha = [1, 1, 1]$, $\\beta = [1, 1, 1]$, $\\tau = 0.3$, $p^{\\star} = [0.2, 0.35, 0.5]$, $T = 5$, $c = 8$, $\\eta = 1.0$, $\\delta = 10^{-6}$, $\\text{seed} = 2021$. Expected behavior: increased allocation toward doses with higher $p_k^{\\star}$, particularly the third dose.\n- Test case B (tie case): $K = 2$, $\\alpha = [10, 10]$, $\\beta = [10, 10]$, $\\tau = 0.5$, $p^{\\star} = [0.5, 0.5]$, $T = 10$, $c = 4$, $\\eta = 2.0$, $\\delta = 10^{-3}$, $\\text{seed} = 2022$. Expected behavior: near-equal allocation due to symmetry and identical performance.\n- Test case C (informative but mis-specified prior; exploration safeguard): $K = 4$, $\\alpha = [20, 1, 1, 1]$, $\\beta = [5, 1, 1, 1]$, $\\tau = 0.6$, $p^{\\star} = [0.3, 0.65, 0.7, 0.8]$, $T = 12$, $c = 6$, $\\eta = 1.5$, $\\delta = 10^{-2}$, $\\text{seed} = 2023$. Expected behavior: initial allocation may favor the first dose due to prior, but as data accumulate the algorithm should shift allocation toward doses with higher posterior $q_k$ driven by true $p_k^{\\star}$.\n- Test case D (boundary case with high threshold): $K = 3$, $\\alpha = [1, 1, 1]$, $\\beta = [1, 1, 1]$, $\\tau = 0.9$, $p^{\\star} = [0.85, 0.88, 0.9]$, $T = 8$, $c = 5$, $\\eta = 1.0$, $\\delta = 10^{-6}$, $\\text{seed} = 2024$. Expected behavior: initially low $q_k$ values; allocation remains relatively balanced until sufficient evidence accumulates to favor the third dose.\n\nFinal output specification:\n- Your program must print a single line containing the results for all four test cases as a comma-separated list of bracketed lists with no spaces, exactly in the format: $[[n_1^{(A)},n_2^{(A)},n_3^{(A)}],[n_1^{(B)},n_2^{(B)}],[n_1^{(C)},n_2^{(C)},n_3^{(C)},n_4^{(C)}],[n_1^{(D)},n_2^{(D)},n_3^{(D)}]]$, where $n_k^{(\\cdot)}$ are integers computed by your algorithm.",
            "solution": "The problem requires the construction of a program to simulate an Adaptive Randomization (AR) procedure for a Phase II clinical trial. The procedure uses a Bayesian framework to dynamically adjust patient allocation to different dose levels based on accumulating efficacy data.\n\n**1. Bayesian Model Foundation**\nThe model for the unknown efficacy probability $p_k$ of each dose $k \\in \\{1, \\dots, K\\}$ is based on the Beta-Binomial conjugate model. This is a standard choice for modeling probabilities where outcomes are binary (e.g., success/failure, response/no response).\n\n- **Prior Belief**: We begin with a prior belief about the efficacy $p_k$, modeled by a Beta distribution, $p_k \\sim \\mathrm{Beta}(\\alpha_k, \\beta_k)$. The parameters $(\\alpha_k, \\beta_k)$ can be chosen to represent pre-existing knowledge. A common non-informative prior is the uniform distribution, $\\mathrm{Beta}(1, 1)$.\n\n- **Likelihood**: The outcome for each patient is a Bernoulli trial. For a cohort of $n$ patients at dose $k$, if we observe $s$ successes, the likelihood of this data given $p_k$ is proportional to $p_k^s (1-p_k)^{n-s}$.\n\n- **Posterior Belief**: According to Bayes' theorem, the posterior distribution is proportional to the product of the prior and the likelihood. Due to the conjugacy of the Beta and Binomial distributions, if we have accumulated a total of $s_k$ successes and $f_k$ failures for dose $k$, the posterior distribution for $p_k$ is updated to:\n$$p_k \\mid (s_k, f_k) \\sim \\mathrm{Beta}(\\alpha_k', \\beta_k') = \\mathrm{Beta}(\\alpha_k + s_k, \\beta_k + f_k)$$\nThese updated distributions carry all our current knowledge about the efficacy of each dose.\n\n**2. Adaptive Allocation Mechanism**\nThe core of the adaptive design is to allocate more patients to \"promising\" doses. A dose is considered promising if its posterior distribution suggests a high probability of exceeding a predefined efficacy threshold, $\\tau$.\n\n- **Posterior Probability of Target Achievement ($q_k$)**: For each dose $k$, we compute the probability that its true efficacy $p_k$ is at least $\\tau$, given the observed data. This is calculated from the posterior distribution:\n$$q_k = \\Pr(p_k \\ge \\tau \\mid s_k, f_k) = \\int_{\\tau}^{1} \\frac{x^{\\alpha_k'-1}(1-x)^{\\beta_k'-1}}{B(\\alpha_k', \\beta_k')} dx = 1 - F_{\\mathrm{Beta}}(\\tau; \\alpha_k', \\beta_k')$$\nwhere $F_{\\mathrm{Beta}}(\\cdot; a, b)$ is the cumulative distribution function (CDF) of the Beta distribution with parameters $(a, b)$. This value, $q_k$, serves as a metric for the \"promise\" of dose $k$.\n\n- **Allocation Weights and Probabilities**: The values $q_k$ are transformed into allocation probabilities. A power function is used to control the degree of adaptiveness:\n$$\\tilde{w}_k = (q_k + \\delta)^{\\eta}$$\nHere, $\\eta  0$ is a tuning parameter; a larger $\\eta$ makes the allocation more \"greedy,\" heavily favoring doses with the highest $q_k$. A smaller $\\eta$ leads to more balanced allocation, promoting exploration. The constant $\\delta  0$ is a small regularization term to ensure that even doses with $q_k=0$ have a non-zero, albeit tiny, chance of being selected, preventing their premature elimination. The weights are then normalized to form a probability distribution:\n$$r_k = \\frac{\\tilde{w}_k}{\\sum_{j=1}^{K} \\tilde{w}_j}$$\nThese probabilities $(r_1, \\dots, r_K)$ are used to allocate the next cohort of patients.\n\n**3. Simulation Algorithm**\nThe simulation proceeds in discrete steps, one for each cohort of patients.\n\n- **Initialization**:\n    - For each dose $k=1, \\dots, K$: initialize success counts $s_k=0$ and failure counts $f_k=0$.\n    - Total allocated patients $n_k$ are also initialized to $0$.\n    - A pseudo-random number generator (RNG) is seeded to ensure reproducibility.\n\n- **Iteration over Cohorts**: For each cohort $t=1, \\dots, T$ of size $c$:\n    1. **Compute Posteriors**: Calculate posterior Beta parameters $\\alpha'_k = \\alpha_k + s_k$ and $\\beta'_k = \\beta_k + f_k$ for all doses.\n    2. **Compute Target Probabilities**: Calculate $q_k = 1 - F_{\\mathrm{Beta}}(\\tau; \\alpha'_k, \\beta'_k)$ for all doses.\n    3. **Compute Allocation Probabilities**: Calculate weights $\\tilde{w}_k$ and normalize to get randomization probabilities $r_k$.\n    4. **Allocate Patients**: Draw a vector of patient counts for the current cohort, $(c_1, \\dots, c_K)$, from a multinomial distribution with $c$ trials and probabilities $(r_1, \\dots, r_K)$. Update the total allocations: $n_k \\leftarrow n_k + c_k$.\n    5. **Simulate Outcomes**: For each dose $k$, simulate outcomes for the $c_k$ newly allocated patients. The number of successes is drawn from a Binomial distribution, $\\mathrm{Bin}(c_k, p_k^{\\star})$, where $p_k^{\\star}$ is the ground-truth efficacy. Update the cumulative counts: $s_k \\leftarrow s_k + \\text{successes}$ and $f_k \\leftarrow f_k + (c_k - \\text{successes})$.\n\n- **Termination**: After $T$ cohorts have been processed, the simulation ends. The final output is the list of total patient allocations for each dose: $[n_1, n_2, \\dots, n_K]$.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.stats import beta as beta_dist\n\ndef run_simulation(K, alpha, beta_p, tau, p_star, T, c, eta, delta, seed):\n    \"\"\"\n    Implements the Adaptive Randomization (AR) procedure for a single test case.\n\n    Args:\n        K (int): Number of candidate doses.\n        alpha (list): Prior alpha parameters for the Beta distributions.\n        beta_p (list): Prior beta parameters for the Beta distributions.\n        tau (float): Target effect threshold.\n        p_star (list): Ground-truth efficacy probabilities for simulation.\n        T (int): Number of cohorts.\n        c (int): Cohort size.\n        eta (float): Parameter controlling the strength of adaptiveness.\n        delta (float): Small constant to prevent zero weights.\n        seed (int): Seed for the pseudo-random number generator.\n\n    Returns:\n        list: A list of final total patient allocations to each dose.\n    \"\"\"\n    # Initialize the pseudo-random number generator for reproducibility.\n    rng = np.random.default_rng(seed)\n\n    # Convert lists to NumPy arrays for vectorized operations.\n    alpha0 = np.array(alpha, dtype=float)\n    beta0 = np.array(beta_p, dtype=float)\n    p_star = np.array(p_star, dtype=float)\n\n    # Initialize success counts (s), failure counts (f), and total allocations.\n    s = np.zeros(K, dtype=int)\n    f = np.zeros(K, dtype=int)\n    n_total = np.zeros(K, dtype=int)\n\n    # Iterate through each cohort.\n    for _ in range(T):\n        # 1. Compute posterior parameters for each dose.\n        posterior_alpha = alpha0 + s\n        posterior_beta = beta0 + f\n\n        # 2. Compute the posterior probability of meeting the target threshold.\n        # q_k = Pr(p_k = tau | Data) = 1 - CDF_Beta(tau; a', b')\n        q = 1 - beta_dist.cdf(tau, posterior_alpha, posterior_beta)\n        \n        # 3. Define allocation weights.\n        weights = (q + delta)**eta\n\n        # 4. Normalize weights to obtain randomization probabilities.\n        sum_weights = np.sum(weights)\n        if sum_weights  0:\n            r = weights / sum_weights\n        else:\n            # Fallback to equal allocation if all weights are zero (highly unlikely with delta  0).\n            r = np.ones(K) / K\n\n        # 5. Randomly allocate the cohort of patients using a multinomial draw.\n        allocations_this_cohort = rng.multinomial(c, r)\n        n_total += allocations_this_cohort\n        \n        # 6. Simulate outcomes for the allocated patients based on ground-truth probabilities.\n        successes_this_cohort = rng.binomial(allocations_this_cohort, p_star)\n        failures_this_cohort = allocations_this_cohort - successes_this_cohort\n\n        # Update cumulative success and failure counts.\n        s += successes_this_cohort\n        f += failures_this_cohort\n\n    return n_total.tolist()\n\ndef solve():\n    \"\"\"\n    Main function to run all test cases and print the results in the specified format.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # (K, alpha, beta, tau, p_star, T, c, eta, delta, seed)\n        (3, [1, 1, 1], [1, 1, 1], 0.3, [0.2, 0.35, 0.5], 5, 8, 1.0, 1e-6, 2021),\n        (2, [10, 10], [10, 10], 0.5, [0.5, 0.5], 10, 4, 2.0, 1e-3, 2022),\n        (4, [20, 1, 1, 1], [5, 1, 1, 1], 0.6, [0.3, 0.65, 0.7, 0.8], 12, 6, 1.5, 1e-2, 2023),\n        (3, [1, 1, 1], [1, 1, 1], 0.9, [0.85, 0.88, 0.9], 8, 5, 1.0, 1e-6, 2024),\n    ]\n\n    results = []\n    for params in test_cases:\n        K, alpha, beta_p, tau, p_star, T, c, eta, delta, seed = params\n        result = run_simulation(K, alpha, beta_p, tau, p_star, T, c, eta, delta, seed)\n        results.append(result)\n\n    # The final print statement must produce a single-line string with no spaces.\n    # Example format: [[n1,n2],[n3,n4,n5]]\n    print(str(results).replace(\" \", \"\"))\n\nsolve()\n```"
        }
    ]
}