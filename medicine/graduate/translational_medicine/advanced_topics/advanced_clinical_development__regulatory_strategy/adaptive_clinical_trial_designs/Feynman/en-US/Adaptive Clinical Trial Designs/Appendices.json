{
    "hands_on_practices": [
        {
            "introduction": "A cornerstone of adaptive trials is the group sequential design, which allows for pre-planned interim analyses to potentially stop a trial early for efficacy or futility. This hands-on practice places you in the role of a clinical trial statistician at a critical decision point. By calculating the interim test statistic and comparing it to a pre-specified efficacy boundary, you will directly engage with the core mechanism of a group sequential test and understand how these designs can accelerate the delivery of effective new medicines. ",
            "id": "4519357",
            "problem": "A parallel two-arm superiority trial in clinical pharmacology evaluates the mean change in systolic blood pressure reduction from baseline at week $8$ for a new antihypertensive versus matched placebo. Let the arm-specific outcomes be modeled as independent and identically distributed normal random variables with common known variance $\\sigma^{2}$, and let the treatment effect be the difference in population means $\\delta = \\mu_{\\mathrm{T}} - \\mu_{\\mathrm{C}}$, where larger positive values of $\\delta$ indicate greater mean reduction in systolic blood pressure for the antihypertensive relative to placebo. The null hypothesis is $H_{0}: \\delta \\leq 0$ versus the one-sided alternative $H_{1}: \\delta > 0$.\n\nThe trial uses a pre-specified group sequential design with an efficacy boundary governed by a one-sided Type I error rate $\\alpha = 0.025$ controlled via a Lan-DeMets O’Brien-Fleming spending function, with two looks: an interim analysis and the final analysis. The planned sample sizes are $N_{\\mathrm{T}} = 400$ and $N_{\\mathrm{C}} = 400$. The common variance is $\\sigma^{2} = 36$ $\\mathrm{mmHg}^{2}$, based on prior phase II data.\n\nAt the interim analysis, the sample sizes are $n_{\\mathrm{T}} = 120$ and $n_{\\mathrm{C}} = 120$, and the observed sample mean reductions are $\\bar{Y}_{\\mathrm{T}} = 11.8$ $\\mathrm{mmHg}$ and $\\bar{Y}_{\\mathrm{C}} = 9.4$ $\\mathrm{mmHg}$. The pre-specified interim efficacy boundary (on the standardized $Z$-scale) is $c_{1} = 2.963$, corresponding to an information fraction $t_{1}$ derived from the design.\n\nUsing only first principles and standard large-sample normal theory for the difference of means with known variance, derive the appropriate $Z$-statistic for testing $H_{0}$ at the interim look, compute its observed value $Z_{1}$ from the given data, and decide whether to stop for efficacy or continue to the next look by comparing $Z_{1}$ to $c_{1}$. Report the computed value of $Z_{1}$ as your final answer. Round your final numeric answer to four significant figures. Express the final answer as a dimensionless number. No textual decision statement is required in the final numeric answer, but your reasoning must include the decision.",
            "solution": "The problem statement is first subjected to a rigorous validation process.\n\n### Step 1: Extract Givens\n- **Trial Design**: Parallel two-arm superiority clinical trial.\n- **Endpoint**: Mean change in systolic blood pressure reduction from baseline at week $8$.\n- **Arms**: Treatment (T) and Placebo/Control (C).\n- **Outcome Model**: Arm-specific outcomes are independent and identically distributed normal random variables.\n- **Population Variance**: Common known variance, $\\sigma^{2} = 36$ $\\mathrm{mmHg}^{2}$.\n- **Treatment Effect**: Difference in population means, $\\delta = \\mu_{\\mathrm{T}} - \\mu_{\\mathrm{C}}$.\n- **Hypotheses**: Null hypothesis $H_{0}: \\delta \\leq 0$; Alternative hypothesis $H_{1}: \\delta > 0$.\n- **Design Type**: Pre-specified group sequential design with two looks.\n- **Error Control**: One-sided Type I error rate $\\alpha = 0.025$, controlled by a Lan-DeMets O’Brien-Fleming spending function.\n- **Planned Total Sample Sizes**: $N_{\\mathrm{T}} = 400$, $N_{\\mathrm{C}} = 400$.\n- **Interim Analysis Data (Look 1)**:\n  - Sample sizes: $n_{\\mathrm{T}} = 120$, $n_{\\mathrm{C}} = 120$.\n  - Observed sample mean reductions: $\\bar{Y}_{\\mathrm{T}} = 11.8$ $\\mathrm{mmHg}$, $\\bar{Y}_{\\mathrm{C}} = 9.4$ $\\mathrm{mmHg}$.\n- **Efficacy Boundary**: Pre-specified interim efficacy boundary on the standardized $Z$-scale is $c_{1} = 2.963$.\n- **Task**: Derive and compute the $Z$-statistic at the interim look, $Z_{1}$, and compare it to $c_{1}$ to make a decision. Report the numerical value of $Z_{1}$ rounded to four significant figures.\n\n### Step 2: Validate Using Extracted Givens\n- **Scientifically Grounded**: The problem is located squarely within the established field of biostatistics, specifically the design and analysis of clinical trials. The use of a normal distribution for a physiological endpoint, a Z-test for the difference of means with known variance, and a group sequential design with an O'Brien-Fleming boundary are all standard, scientifically sound methodologies.\n- **Well-Posed**: The problem is well-posed. It asks for a specific calculation ($Z_{1}$) for which all necessary data ($\\bar{Y}_{\\mathrm{T}}$, $\\bar{Y}_{\\mathrm{C}}$, $n_{\\mathrm{T}}$, $n_{\\mathrm{C}}$, $\\sigma^{2}$) are provided. A unique, meaningful solution exists.\n- **Objective**: The problem is stated in precise, objective, and quantitative language, free of any subjective or ambiguous terms.\n- **Completeness and Consistency**: The problem is self-contained and internally consistent. The information provided is sufficient to calculate the requested statistic. Contextual information like the total planned sample size ($N_{\\mathrm{T}}$, $N_C$) is relevant for understanding the design but is not required for the specific calculation of $Z_{1}$, as the critical value $c_1$ is given directly. This does not constitute a flaw.\n- **Realism**: The values for sample size, variance ($\\sigma = \\sqrt{36} = 6$ $\\mathrm{mmHg}$), and observed effects are realistic for an antihypertensive drug trial.\n\n### Step 3: Verdict and Action\nThe problem is deemed valid. All criteria for a sound scientific problem are met. A solution will be derived.\n\nThe task is to compute the standardized test statistic, $Z_{1}$, at the first interim analysis and compare it to the critical value $c_{1}$. The hypotheses to be tested are $H_{0}: \\delta \\leq 0$ versus $H_{1}: \\delta > 0$, where $\\delta = \\mu_{\\mathrm{T}} - \\mu_{\\mathrm{C}}$. The test is performed at the boundary of the null space, i.e., assuming $\\delta = 0$.\n\nThe general form of the $Z$-statistic for a two-sample test of means with known variance is:\n$$ Z = \\frac{(\\text{Point Estimate of } \\delta) - (\\text{Hypothesized value of } \\delta)}{\\text{Standard Error of the Point Estimate}} $$\n\nAt the interim analysis (look $1$), the point estimate for the treatment effect $\\delta$ is the difference in the observed sample means:\n$$ \\hat{\\delta}_{1} = \\bar{Y}_{\\mathrm{T}} - \\bar{Y}_{\\mathrm{C}} $$\nThe hypothesized value of $\\delta$ under the null hypothesis is $\\delta_{0} = 0$.\n\nThe standard error of the point estimate, $\\mathrm{SE}(\\hat{\\delta}_{1})$, is based on the variances of the sample means. The variance of a sample mean $\\bar{Y}$ from a population with known variance $\\sigma^{2}$ and sample size $n$ is $\\mathrm{Var}(\\bar{Y}) = \\frac{\\sigma^{2}}{n}$. Since the two arms are independent, the variance of the difference of their sample means is the sum of their individual variances:\n$$ \\mathrm{Var}(\\hat{\\delta}_{1}) = \\mathrm{Var}(\\bar{Y}_{\\mathrm{T}} - \\bar{Y}_{\\mathrm{C}}) = \\mathrm{Var}(\\bar{Y}_{\\mathrm{T}}) + \\mathrm{Var}(\\bar{Y}_{\\mathrm{C}}) $$\nAt the interim analysis, with sample sizes $n_{\\mathrm{T}}$ and $n_{\\mathrm{C}}$, this becomes:\n$$ \\mathrm{Var}(\\hat{\\delta}_{1}) = \\frac{\\sigma^{2}}{n_{\\mathrm{T}}} + \\frac{\\sigma^{2}}{n_{\\mathrm{C}}} $$\nThe standard error is the square root of the variance:\n$$ \\mathrm{SE}(\\hat{\\delta}_{1}) = \\sqrt{\\frac{\\sigma^{2}}{n_{\\mathrm{T}}} + \\frac{\\sigma^{2}}{n_{\\mathrm{C}}}} $$\nThe test statistic at the interim look, $Z_{1}$, is therefore:\n$$ Z_{1} = \\frac{(\\bar{Y}_{\\mathrm{T}} - \\bar{Y}_{\\mathrm{C}}) - 0}{\\sqrt{\\frac{\\sigma^{2}}{n_{\\mathrm{T}}} + \\frac{\\sigma^{2}}{n_{\\mathrm{C}}}}} = \\frac{\\bar{Y}_{\\mathrm{T}} - \\bar{Y}_{\\mathrm{C}}}{\\sigma \\sqrt{\\frac{1}{n_{\\mathrm{T}}} + \\frac{1}{n_{\\mathrm{C}}}}} $$\nNow, we substitute the provided numerical values into this formula.\nGiven:\n- $\\bar{Y}_{\\mathrm{T}} = 11.8$\n- $\\bar{Y}_{\\mathrm{C}} = 9.4$\n- $\\sigma^{2} = 36$, which implies $\\sigma = \\sqrt{36} = 6$.\n- $n_{\\mathrm{T}} = 120$\n- $n_{\\mathrm{C}} = 120$\n\nFirst, compute the numerator (the observed effect size):\n$$ \\hat{\\delta}_{1} = \\bar{Y}_{\\mathrm{T}} - \\bar{Y}_{\\mathrm{C}} = 11.8 - 9.4 = 2.4 $$\nNext, compute the standard error of the estimate:\n$$ \\mathrm{SE}(\\hat{\\delta}_{1}) = \\sqrt{\\frac{36}{120} + \\frac{36}{120}} = \\sqrt{\\frac{72}{120}} = \\sqrt{\\frac{6 \\times 12}{10 \\times 12}} = \\sqrt{\\frac{6}{10}} = \\sqrt{0.6} $$\nNow, compute the $Z_{1}$ statistic:\n$$ Z_{1} = \\frac{2.4}{\\sqrt{0.6}} $$\nCalculating the numerical value:\n$$ Z_{1} \\approx \\frac{2.4}{0.774596669...} \\approx 3.09838667... $$\nThe problem requires rounding to four significant figures. The fifth significant figure is $3$, so we round down.\n$$ Z_{1} \\approx 3.098 $$\nThe final step is to apply the decision rule. The trial stops for efficacy if the observed statistic $Z_{1}$ exceeds the pre-specified boundary $c_{1}$.\nThe observed statistic is $Z_{1} \\approx 3.098$.\nThe efficacy boundary is $c_{1} = 2.963$.\nComparing the two values:\n$$ 3.098 > 2.963 $$\nSince $Z_{1} > c_{1}$, the null hypothesis $H_{0}$ is rejected at the interim analysis. The conclusion is to stop the trial for demonstrated efficacy of the new antihypertensive treatment. The question asks for the computed value of $Z_{1}$.",
            "answer": "$$\\boxed{3.098}$$"
        },
        {
            "introduction": "When a trial proceeds through multiple stages, a crucial question arises: how do we properly combine the evidence gathered from each independent cohort to reach a single, valid conclusion? This exercise demonstrates a fundamental technique, Fisher's combination method, for pooling $p$-values from different stages. Mastering this method is essential for understanding how many adaptive designs maintain strict control over the Type I error rate, even when decisions are made to modify the trial mid-stream. ",
            "id": "4987179",
            "problem": "In a translational medicine program evaluating a targeted therapy, a sponsor implements a pre-planned adaptive clinical trial with a $2$-stage design to allow sample size modification at interim while preserving the family-wise type I error rate. The primary hypothesis is one-sided, and the stage-wise $p$-values are computed from independent patient cohorts due to the internal pilot nature of the design. Assume that, under the global null hypothesis and given the independence of the stage-wise test statistics, the stage-wise $p$-values are independent and each is uniformly distributed on $\\left(0,1\\right)$. The observed stage-wise $p$-values are $p_1=0.08$ and $p_2=0.01$. Using Fisher’s combination testing framework, compute the combined $p$-value for these two stages and assess whether the trial achieves significance at one-sided $\\alpha=0.025$ while controlling the type I error under the null. Report only the combined $p$-value as a decimal number, rounded to four significant figures. Do not include any symbols or units in your final reported value.",
            "solution": "The problem statement has been rigorously validated and is deemed valid. It is scientifically grounded in established principles of biostatistics, specifically concerning adaptive clinical trial designs and the meta-analysis of $p$-values. The problem is well-posed, objective, and provides all necessary information for a unique solution without internal contradictions.\n\nThe task is to compute a combined $p$-value from two independent stages of a clinical trial using Fisher's combination testing framework. The given stage-wise $p$-values are $p_1 = 0.08$ and $p_2 = 0.01$. The problem states that under the global null hypothesis ($H_0$), these $p$-values are independent and uniformly distributed on the interval $(0, 1)$, which are the requisite assumptions for Fisher's method.\n\nFisher's method combines $k$ independent $p$-values ($p_1, p_2, \\dots, p_k$) into a single test statistic, denoted as $X^2$. The formula for this statistic is:\n$$ X^2 = -2 \\sum_{i=1}^{k} \\ln(p_i) $$\nUnder the global null hypothesis, this $X^2$ statistic follows a chi-squared ($\\chi^2$) distribution with $2k$ degrees of freedom. The combined $p$-value, $p_{comb}$, is then the probability of observing a value of the $\\chi^2$ statistic as extreme or more extreme than the one calculated from the observed $p$-values. This corresponds to the right-tail probability of the $\\chi^2_{2k}$ distribution.\n\nIn this problem, we have $k=2$ stages. The observed $p$-values are $p_1 = 0.08$ and $p_2 = 0.01$.\nFirst, we calculate the value of the test statistic, $X^2_{obs}$:\n$$ X^2_{obs} = -2 (\\ln(p_1) + \\ln(p_2)) $$\nSubstituting the given values:\n$$ X^2_{obs} = -2 (\\ln(0.08) + \\ln(0.01)) $$\nUsing the properties of the natural logarithm, we find the numerical values:\n$$ \\ln(0.08) \\approx -2.5257286 $$\n$$ \\ln(0.01) \\approx -4.6051702 $$\nThus, the test statistic is:\n$$ X^2_{obs} \\approx -2 (-2.5257286 - 4.6051702) = -2(-7.1308988) = 14.2617976 $$\n\nNext, we determine the degrees of freedom ($df$) for the chi-squared distribution:\n$$ df = 2k = 2 \\times 2 = 4 $$\nSo, our test statistic $X^2_{obs}$ is to be compared against a $\\chi^2$ distribution with $4$ degrees of freedom.\n\nThe combined $p$-value, $p_{comb}$, is the probability $P(\\chi^2_4 \\ge X^2_{obs})$. The cumulative distribution function (CDF) for a $\\chi^2$ distribution with $4$ degrees of freedom is $F(x; 4) = 1 - (1 + \\frac{x}{2})\\exp(-\\frac{x}{2})$. The $p$-value is the survival function, $1 - F(x; 4)$.\n$$ p_{comb} = P(\\chi^2_4 \\ge X^2_{obs}) = \\left(1 + \\frac{X^2_{obs}}{2}\\right) \\exp\\left(-\\frac{X^2_{obs}}{2}\\right) $$\nSubstituting the calculated value of $X^2_{obs}$:\n$$ p_{comb} \\approx \\left(1 + \\frac{14.2617976}{2}\\right) \\exp\\left(-\\frac{14.2617976}{2}\\right) $$\n$$ p_{comb} \\approx (1 + 7.1308988) \\exp(-7.1308988) $$\n$$ p_{comb} \\approx 8.1308988 \\times 0.00079998 $$\n$$ p_{comb} \\approx 0.0065046 $$\n\nThe problem asks for the result to be rounded to four significant figures. The first significant figure is $6$, followed by $5$, $0$, and $4$. The next digit is $6$, which requires rounding up the fourth significant digit.\n$$ p_{comb} \\approx 0.006505 $$\n\nThe problem also requests an assessment of significance at the one-sided $\\alpha=0.025$ level. We compare our combined $p$-value to $\\alpha$:\n$$ 0.006505 < 0.025 $$\nSince $p_{comb} < \\alpha$, the result is statistically significant. The global null hypothesis would be rejected, suggesting that the targeted therapy has a significant effect.\n\nThe final reported value is the combined $p$-value rounded to four significant figures.",
            "answer": "$$\\boxed{0.006505}$$"
        },
        {
            "introduction": "Moving beyond the frequentist framework, this practice explores the mechanics of a Bayesian adaptive design, a powerful approach that formally incorporates prior knowledge and updates beliefs as data accumulates. Your task is to go beyond simple analysis and evaluate the long-run operating characteristics of a proposed design—its probability of success (power), its Type I error rate, and its expected sample size. This type of simulation-free calculation is a fundamental skill for designing efficient and ethical trials, allowing you to compare and optimize different adaptive strategies before a single patient is enrolled. ",
            "id": "4519388",
            "problem": "Consider a single-arm, two-stage Bayesian adaptive design for a binary response in clinical pharmacology. Let the unknown response probability be denoted by $\\theta \\in [0,1]$. Prior knowledge about $\\theta$ is modeled as a Beta distribution $\\mathrm{Beta}(a,b)$, where $a>0$ and $b>0$. Patients are enrolled in two stages: an interim analysis occurs after $n_1$ observations, and a final analysis occurs at a maximum of $N$ observations, with $N \\ge n_1$. Let $x_1$ denote the number of responses observed at the interim stage and $x$ the total number of responses at the end of the trial. Assume that conditional on $\\theta$, the data are independent and identically distributed Bernoulli trials, so that $x_1 \\sim \\mathrm{Binomial}(n_1,\\theta)$ and $x \\sim \\mathrm{Binomial}(N,\\theta)$.\n\nAt each analysis, decisions are made by thresholding posterior tail probabilities relative to a clinically meaningful response threshold $\\theta_0 \\in (0,1)$. Specifically, at sample size $n$ with $x$ observed responses, the posterior distribution is $\\theta \\mid x \\sim \\mathrm{Beta}(a+x,b+n-x)$ by conjugacy. Define the posterior tail probability $T(x,n) = \\mathbb{P}(\\theta \\ge \\theta_0 \\mid x,n) = 1 - I_{\\theta_0}(a+x,b+n-x)$, where $I_{z}(\\alpha,\\beta)$ is the regularized incomplete beta function.\n\nThe decision rule is:\n- Early success at the interim if $T(x_1,n_1) \\ge t_s$, stop and declare success.\n- Early futility at the interim if $T(x_1,n_1) \\le t_f$, stop and declare futility.\n- Otherwise, continue to the final analysis at $N$ observations, and declare final success if $T(x,N) \\ge t_F$; otherwise declare futility.\n\nFor a fixed true response probability $p \\in [0,1]$, define the operating characteristics as follows:\n- The probability of success at $p$, denoted $\\pi_{\\mathrm{succ}}(p)$, equals the probability (over the sampling distribution under $p$) that the design declares success at either interim or final analysis.\n- The expected sample size at $p$, denoted $E_{\\!N}(p)$, equals the expectation of the total number of patients accrued before stopping, under the sampling distribution with true response probability $p$.\n- The Type I error is defined at the null boundary $p=\\theta_0$ as $\\alpha = \\pi_{\\mathrm{succ}}(\\theta_0)$.\n\nUsing only the following fundamental base:\n- The binomial sampling model $X \\sim \\mathrm{Binomial}(n,p)$ with probability mass function $\\mathbb{P}(X=x) = \\binom{n}{x} p^x (1-p)^{n-x}$ for $x \\in \\{0,1,\\dots,n\\}$ and $p \\in [0,1]$.\n- Conjugacy of the Beta prior with the Binomial likelihood: $\\theta \\mid x \\sim \\mathrm{Beta}(a+x,b+n-x)$ when $\\theta \\sim \\mathrm{Beta}(a,b)$ and $X \\sim \\mathrm{Binomial}(n,\\theta)$.\n- The identity $\\mathbb{P}(\\theta \\ge \\theta_0 \\mid x,n) = 1 - I_{\\theta_0}(a+x,b+n-x)$ where $I_z(\\alpha,\\beta)$ is the regularized incomplete beta function.\n\nDerive from first principles expressions for $\\pi_{\\mathrm{succ}}(p)$, $\\alpha$, and $E_{\\!N}(p)$ in terms of $a$, $b$, $n_1$, $N$, $\\theta_0$, $t_s$, $t_f$, $t_F$, and $p$. Your program must implement these expressions exactly via summation over the relevant binomial distributions for interim and final stages, without simulation.\n\nYour program should compute these operating characteristics for each of the following test cases. For each test case, compute for each specified true response probability value $p$ the triple $[\\pi_{\\mathrm{succ}}(p), \\alpha, E_{\\!N}(p)]$ with all three quantities expressed as decimals rounded to six digits after the decimal point.\n\nTest suite:\n- Case $1$: $a=1$, $b=1$, $n_1=20$, $N=40$, $\\theta_0=0.2$, $t_s=0.99$, $t_f=0.05$, $t_F=0.95$, and evaluate at $p \\in \\{0.2, 0.35\\}$.\n- Case $2$ (boundary where there is effectively one stage): $a=1$, $b=1$, $n_1=10$, $N=10$, $\\theta_0=0.3$, $t_s=0.9$, $t_f=0.1$, $t_F=0.9$, and evaluate at $p \\in \\{0.3, 0.5\\}$. This probes the boundary condition $N=n_1$ where only a single analysis is performed.\n- Case $3$ (informative prior): $a=2$, $b=8$, $n_1=15$, $N=30$, $\\theta_0=0.2$, $t_s=0.975$, $t_f=0.05$, $t_F=0.95$, and evaluate at $p \\in \\{0.1, 0.2, 0.4\\}$.\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, where each element corresponds to one test case and is itself a list of triples $[\\pi_{\\mathrm{succ}}(p), \\alpha, E_{\\!N}(p)]$ for the specified $p$ values in the given order. For example, the overall structure should be of the form $[[\\cdot,\\cdot,\\dots],[\\cdot,\\cdot,\\dots],[\\cdot,\\cdot,\\dots]]$, where each $\\cdot$ is a triple. All probabilities must be expressed as decimals, not as percentages. No physical units are involved.",
            "solution": "The problem is assessed as valid. It is a well-defined task in biostatistics, specifically in the design of adaptive clinical trials. The problem is scientifically grounded in Bayesian inference and probability theory, self-contained with all necessary parameters provided, and articulated using objective, formal mathematical language. There are no contradictions, ambiguities, or violations of scientific principles. We may, therefore, proceed with the derivation of the required operating characteristics from first principles.\n\nLet the true response probability be $p \\in [0,1]$. The number of responses in the first stage, $X_1$, is a random variable following a binomial distribution, $X_1 \\sim \\mathrm{Binomial}(n_1, p)$. The sample space for $X_1$ is $\\{0, 1, \\dots, n_1\\}$.\n\nAt the interim analysis after $n_1$ patients, for each possible outcome $x_1 \\in \\{0, 1, \\dots, n_1\\}$, the posterior tail probability $T(x_1, n_1) = \\mathbb{P}(\\theta \\ge \\theta_0 \\mid x_1, n_1)$ is computed as $1 - I_{\\theta_0}(a+x_1, b+n_1-x_1)$, where $I_z(\\alpha, \\beta)$ is the regularized incomplete beta function. Based on this value, the set of all possible interim outcomes is partitioned into three disjoint sets:\n- The set of outcomes leading to early success: $S_1 = \\{x_1 \\in \\{0, \\dots, n_1\\} \\mid T(x_1, n_1) \\ge t_s \\}$.\n- The set of outcomes leading to early futility: $F_1 = \\{x_1 \\in \\{0, \\dots, n_1\\} \\mid T(x_1, n_1) \\le t_f \\}$.\n- The set of outcomes leading to continuation: $C_1 = \\{x_1 \\in \\{0, \\dots, n_1\\} \\mid t_f < T(x_1, n_1) < t_s \\}$.\n\nThe probability of observing $x_1$ responses in the first stage, given the true probability $p$, is determined by the binomial probability mass function (PMF):\n$$ \\mathbb{P}(X_1 = x_1 \\mid p) = \\binom{n_1}{x_1} p^{x_1} (1-p)^{n_1-x_1} $$\n\n**Derivation of the Probability of Success, $\\pi_{\\mathrm{succ}}(p)$**\nA trial is declared successful via one of two mutually exclusive paths: success at the interim stage, or continuation at interim followed by success at the final stage. The total probability of success is the sum of the probabilities of these two paths.\n\n1.  **Path 1: Early Success.** This occurs if the observed number of responses $X_1$ is a member of the set $S_1$. The probability of this event is the sum of the probabilities of all outcomes in $S_1$:\n    $$ \\mathbb{P}(\\text{Early Success}) = \\mathbb{P}(X_1 \\in S_1) = \\sum_{x_1 \\in S_1} \\mathbb{P}(X_1 = x_1 \\mid p) = \\sum_{x_1 \\in S_1} \\binom{n_1}{x_1} p^{x_1} (1-p)^{n_1-x_1} $$\n\n2.  **Path 2: Continuation and Final Success.** This path requires the interim outcome $X_1$ to be in the continuation set $C_1$. If $x_1 \\in C_1$, an additional $n_2 = N - n_1$ patients are enrolled. Let $X_2$ be the number of responses in this second cohort. Given the true rate $p$, $X_2 \\sim \\mathrm{Binomial}(n_2, p)$ and is independent of $X_1$. The total number of responses at the final analysis is $X = x_1+X_2$. Final success is declared if $T(x_1+X_2, N) \\ge t_F$.\n    For a fixed interim outcome $x_1 \\in C_1$, we define $S_2(x_1)$ as the set of second-stage outcomes that result in final success:\n    $$ S_2(x_1) = \\{x_2 \\in \\{0, \\dots, n_2\\} \\mid T(x_1+x_2, N) \\ge t_F \\} $$\n    The probability of achieving final success, conditional on the interim outcome being $x_1$, is the probability that $X_2$ falls into $S_2(x_1)$:\n    $$ \\mathbb{P}(\\text{Final Success} \\mid X_1 = x_1) = \\mathbb{P}(X_2 \\in S_2(x_1)) = \\sum_{x_2 \\in S_2(x_1)} \\mathbb{P}(X_2=x_2 \\mid p) = \\sum_{x_2 \\in S_2(x_1)} \\binom{n_2}{x_2} p^{x_2} (1-p)^{n_2-x_2} $$\n    The total probability for Path 2 is found by summing over all possible continuation outcomes $x_1 \\in C_1$, weighted by their respective probabilities, by the law of total probability:\n    $$ \\mathbb{P}(\\text{Continuation and Final Success}) = \\sum_{x_1 \\in C_1} \\mathbb{P}(\\text{Final Success} \\mid X_1 = x_1) \\mathbb{P}(X_1=x_1 \\mid p) $$\n    $$ = \\sum_{x_1 \\in C_1} \\left[ \\binom{n_1}{x_1} p^{x_1} (1-p)^{n_1-x_1} \\left( \\sum_{x_2 \\in S_2(x_1)} \\binom{N-n_1}{x_2} p^{x_2} (1-p)^{N-n_1-x_2} \\right) \\right] $$\n\nThe total probability of success, $\\pi_{\\mathrm{succ}}(p)$, is the sum of the probabilities of these two disjoint paths:\n$$ \\pi_{\\mathrm{succ}}(p) = \\mathbb{P}(\\text{Early Success}) + \\mathbb{P}(\\text{Continuation and Final Success}) $$\n$$ \\pi_{\\mathrm{succ}}(p) = \\sum_{x_1 \\in S_1} \\binom{n_1}{x_1} p^{x_1} (1-p)^{n_1-x_1} + \\sum_{x_1 \\in C_1} \\left[ \\binom{n_1}{x_1} p^{x_1} (1-p)^{n_1-x_1} \\left( \\sum_{x_2 \\in S_2(x_1)} \\binom{N-n_1}{x_2} p^{x_2} (1-p)^{N-n_1-x_2} \\right) \\right] $$\n\n**Derivation of Type I Error, $\\alpha$**\nThe Type I error rate, $\\alpha$, is defined as the probability of declaring success when the true response rate is $p=\\theta_0$. It is therefore calculated by evaluating the expression for $\\pi_{\\mathrm{succ}}(p)$ at $p=\\theta_0$:\n$$ \\alpha = \\pi_{\\mathrm{succ}}(\\theta_0) $$\n\n**Derivation of Expected Sample Size, $E_{\\!N}(p)$**\nThe sample size is a random variable taking the value $n_1$ if the trial stops at the interim analysis (due to success or futility) or $N$ if it continues. The trial continues if and only if the interim outcome $X_1$ falls into the set $C_1$.\nThe probability of continuation is the probability that $X_1 \\in C_1$:\n$$ \\mathbb{P}(\\text{Continue}) = \\mathbb{P}(X_1 \\in C_1) = \\sum_{x_1 \\in C_1} \\mathbb{P}(X_1=x_1 \\mid p) = \\sum_{x_1 \\in C_1} \\binom{n_1}{x_1} p^{x_1} (1-p)^{n_1-x_1} $$\nThe expected sample size, $E_{\\!N}(p)$, is the weighted average of the two possible sample sizes:\n$$ E_{\\!N}(p) = n_1 \\cdot \\mathbb{P}(\\text{Stop at Interim}) + N \\cdot \\mathbb{P}(\\text{Continue}) $$\nSince $\\mathbb{P}(\\text{Stop at Interim}) = 1 - \\mathbb{P}(\\text{Continue})$, we can write:\n$$ E_{\\!N}(p) = n_1 \\cdot (1 - \\mathbb{P}(\\text{Continue})) + N \\cdot \\mathbb{P}(\\text{Continue}) = n_1 - n_1 \\cdot \\mathbb{P}(\\text{Continue}) + N \\cdot \\mathbb{P}(\\text{Continue}) $$\nThis simplifies to:\n$$ E_{\\!N}(p) = n_1 + (N - n_1) \\cdot \\mathbb{P}(\\text{Continue}) $$\nSubstituting the expression for the probability of continuation yields the final formula:\n$$ E_{\\!N}(p) = n_1 + (N-n_1) \\left( \\sum_{x_1 \\in C_1} \\binom{n_1}{x_1} p^{x_1} (1-p)^{n_1-x_1} \\right) $$\nThese derived expressions are implemented in the following program by first determining the decision sets $S_1$, $C_1$, and $S_2(x_1)$, and then performing the specified summations over the relevant binomial PMFs.",
            "answer": "```python\nimport numpy as np\nfrom scipy.special import comb, betainc\n\ndef _calculate_op_chars_for_p(a, b, n1, N, theta0, ts, tf, tF, p):\n    \"\"\"\n    Calculates the probability of success and expected sample size for a given true response rate p.\n    \"\"\"\n    # 1. Determine decision boundaries for the interim analysis\n    x1_values = np.arange(n1 + 1)\n    \n    # Calculate posterior tail probability T(x1, n1) for all possible x1\n    post_a_interim = a + x1_values\n    post_b_interim = b + n1 - x1_values\n    T_interim = 1 - betainc(post_a_interim, post_b_interim, theta0)\n    \n    # Identify outcomes for early success, futility, and continuation\n    s1_mask = T_interim >= ts\n    c1_mask = (T_interim > tf) & (T_interim < ts)\n\n    # 2. Calculate probabilities of interim outcomes under the true rate p\n    pmf_x1 = comb(n1, x1_values) * (p**x1_values) * ((1-p)**(n1-x1_values))\n\n    # 3. Calculate Expected Sample Size E_N(p)\n    prob_continue = np.sum(pmf_x1[c1_mask])\n    expected_n = n1 + (N - n1) * prob_continue\n\n    # 4. Calculate Probability of Success pi_succ(p)\n    # Path 1: Early success\n    prob_early_succ = np.sum(pmf_x1[s1_mask])\n    \n    # Path 2: Continuation followed by final success\n    prob_cont_succ = 0.0\n    c1_outcomes = x1_values[c1_mask]\n    n2 = N - n1\n    \n    # If there is a second stage and continuation is possible\n    if n2 > 0 and len(c1_outcomes) > 0:\n        x2_values = np.arange(n2 + 1)\n        pmf_x2 = comb(n2, x2_values) * (p**x2_values) * ((1-p)**(n2-x2_values))\n        \n        for x1_c in c1_outcomes:\n            # For this specific interim outcome x1_c, find which stage 2 outcomes lead to success\n            post_a_final = a + x1_c + x2_values\n            post_b_final = b + N - (x1_c + x2_values)\n            T_final = 1 - betainc(post_a_final, post_b_final, theta0)\n            \n            s2_mask = T_final >= tF\n            \n            # Probability of final success, conditional on interim outcome x1_c\n            prob_final_succ_given_x1c = np.sum(pmf_x2[s2_mask])\n            \n            # Add this path's probability to the total\n            prob_cont_succ += pmf_x1[x1_c] * prob_final_succ_given_x1c\n            \n    # Handle the boundary case where N=n1 (single stage)\n    elif n2 == 0 and len(c1_outcomes) > 0:\n        for x1_c in c1_outcomes:\n            # \"Continue\" means re-evaluating against the final threshold tF\n            if T_interim[x1_c] >= tF:\n                prob_cont_succ += pmf_x1[x1_c]\n                \n    pi_succ = prob_early_succ + prob_cont_succ\n    \n    return pi_succ, expected_n\n\ndef solve():\n    \"\"\"\n    Main function to run all test cases and print the formatted results.\n    \"\"\"\n    test_cases = [\n        {'params': (1, 1, 20, 40, 0.2, 0.99, 0.05, 0.95), 'p_values': [0.2, 0.35]},\n        {'params': (1, 1, 10, 10, 0.3, 0.9, 0.1, 0.9), 'p_values': [0.3, 0.5]},\n        {'params': (2, 8, 15, 30, 0.2, 0.975, 0.05, 0.95), 'p_values': [0.1, 0.2, 0.4]}\n    ]\n\n    all_results_list = []\n    for case in test_cases:\n        params = case['params']\n        p_values = case['p_values']\n        theta0 = params[4]\n\n        # Calculate Type I error (alpha) once per case\n        alpha, _ = _calculate_op_chars_for_p(*params, p=theta0)\n\n        case_results = []\n        for p in p_values:\n            pi_succ_p, en_p = _calculate_op_chars_for_p(*params, p=p)\n            case_results.append(f\"[{pi_succ_p:.6f},{alpha:.6f},{en_p:.6f}]\")\n        \n        all_results_list.append(f\"[{','.join(case_results)}]\")\n\n    # Print the final result in the exact required format.\n    print(f\"[{','.join(all_results_list)}]\")\n\nsolve()\n```"
        }
    ]
}