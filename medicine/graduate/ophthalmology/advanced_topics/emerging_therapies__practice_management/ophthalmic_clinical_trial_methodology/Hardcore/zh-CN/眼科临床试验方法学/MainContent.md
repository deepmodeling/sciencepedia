## 引言
眼科临床试验是循证[眼科学](@entry_id:199533)的基石，为评估新疗法和干预措施的安全性和有效性提供了最高级别的证据。然而，将一个临床想法转化为一项科学严谨、伦理合理且结论可靠的试验，需要掌握一套复杂而精深的方法学。从提出一个可检验的科学问题，到设计一个能够无偏回答该问题的方案，再到正确分析由此产生的数据，每一步都充满挑战。

本文旨在系统性地介绍眼科临床试验方法学的核心知识体系。在第一章**“原则与机制”**中，我们将奠定理论基础，深入探讨支撑临床试验的伦理与有效性原则，学习如何通过估量目标框架精确定义研究问题，并掌握试验设计与统计分析中的关键要素。随后的第二章**“应用与交叉学科联系”**将理论付诸实践，展示这些方法学原理如何应用于外科、医疗器械和药物等不同治疗领域的先进试验设计中，并探讨临床试验与研究伦理、法规科学及真实世界证据之间的深刻联系。最后，第三章**“动手实践”**将通过具体案例，引导读者动手实践关键的统计技能，从而巩固所学知识。

通过这一结构化的学习路径，读者将构建起对现代眼科临床试验从理论到实践的全方位理解，为开展高质量的临床研究奠定坚实基础。

## 原则与机制

### 临床试验设计的伦理与有效性基础

临床试验的核心在于其伦理基础。任何一项旨在评估新疗法的研究，都必须在坚实的伦理框架内进行，以保障受试者的福祉和权利。这一框架的基石是**临床均势 (clinical equipoise)** 的概念，它为随机化这一核心试验操作提供了伦理上的正当性。

临床均势是指，在合格的专家社群中，对于试验中各个干预组（例如，新疗法与[对照组](@entry_id:188599)）的相对治疗优劣，存在真实、持续的不确定性。这种不确定性意味着，在试验开始时，将任何一位受试者分配到任一治疗组都不会使其遭受已知的劣势。这一原则确保了研究人员并非为了科学目的而故意让部分受试者接受次优治疗。

临床均势原则直接影响着[对照组](@entry_id:188599)的选择，尤其是在决定使用**安慰剂/伪治疗 (placebo/sham)** 还是**阳性药物 (active comparator)** 时。眼科试验，特别是涉及玻璃体腔注射的试验，对这一问题提出了尖锐的挑战。根据《赫尔辛基宣言》等伦理准则，只有在不存在已证实有效的干预措施，或者存在令人信服的方法学原因且不会增加严重或不可逆伤害风险的情况下，才能使用安慰剂或伪治疗。

我们可以通过一个风险-获益框架来形式化这一决策过程。假设在未经标准治疗的情况下，发生不可逆视觉损害的风险率为 $h_{\text{untreated}}(t)$，而在接受标准治疗下的[风险率](@entry_id:266388)为 $h_{\text{SOC}}(t)$。那么，在为期 $T$ 的伪治疗期间，因未给予有效治疗而产生的增量预期损害可以概念化为 $\int_{0}^{T}\Delta h(t)\,dt$，其中 $\Delta h(t)=h_{\text{untreated}}(t)-h_{\text{SOC}}(t)$。

基于此框架，我们可以确立以下原则：

1.  **当不存在已证实的有效疗法时**：对于目标适应症，如果尚无公认的标准疗法，则 $h_{\text{SOC}}(t) = h_{\text{untreated}}(t)$，因此 $\Delta h(t) = 0$。在这种情况下，分配至伪治疗组并不会因“剥夺有效治疗”而增加额外的预期损害。此时，若短期内发生不可逆视觉损害的风险较低，且伪治疗程序本身（如避免巩膜穿刺的伪注射）的风险被最小化，并辅以预设的早期补救治疗标准（例如，当视力下降或OCT指标恶化到一定程度时即给予治疗），那么使用伪治疗对照在伦理上是允许的。这对于确立一项全新疗法的绝对疗效至关重要。

2.  **当存在已证实的有效疗法时**：如果已存在能够显著降低目标疾病视觉损害风险的标准疗法，那么 $\Delta h(t) > 0$。在这种情况下，若试验旨在评估一种新的单一疗法，将受试者随机分配至单独的伪治疗组而无及时的补救措施，将导致 $\int_{0}^{T}\Delta h(t)\,dt$ 显著大于零，这意味着受试者将面临可避免的、实质性的、甚至可能是不可逆的伤害。这在伦理上是不可接受的。因此，必须采用阳性药物对照的**优效性 (superiority)** 或**非劣效性 (non-inferiority)** 设计。

3.  **在附加 (add-on) 设计中**：一种特殊情况是附加试验设计。在此设计中，所有受试者（包括[对照组](@entry_id:188599)）均接受现有的标准治疗。试验旨在评估在标准治疗基础上“附加”新疗法是否比“附加”安慰剂更有益。由于所有受试者都得到了标准治疗的保障，因此 $h_{\text{SOC}}(t)$ 对所有人都适用，使用伪治疗的目的仅在于维持盲法，以区分附加新药与附加安慰剂的效果。因为标准治疗并未被剥夺，由伪治疗导致的增量预期损害 $\int_{0}^{T}\Delta h(t)\,dt$ 不会增加。只要伪治疗程序本身的风险被最小化，并设有客观的早期补救标准，这种设计便能同时满足伦理要求和科学有效性。

值得注意的是，**知情同意 (informed consent)** 虽然是尊重受试者自主权的必要条件，但其本身并不足以成为使用伪治疗的全部理由。即便受试者在被充分告知后同意，研究者仍然有责任确保试验的风险-获益比是合理的。伦理审查委员会（IRB）和研究者不能仅仅因为受试者同意，就将其置于可避免的实质性风险之中。

### 精确定义科学问题：估量目标框架

在确定了试验的伦理边界后，下一步是精确地定义要回答的科学问题。传统上，研究方案可能模糊地描述“比较药物A与药物B的疗效”，但这为后续的分析选择留下了过多的[歧义](@entry_id:276744)，尤其是在处理脱落、治疗中断等**中途事件 (intercurrent events)** 时。为了解决这一问题，国际协调会议（ICH）在其E9(R1)指导原则附录中引入了**估量目标 (estimand)** 框架。

估量目标是对“待估计的治疗效应”的一个精确、多维度的定义，它在指定任何统计分析方法之前，首先清晰地阐明了研究的核心问题。一个完整的估量目标由四个关键属性构成：

1.  **目标人群 (Target Population)**：我们希望对哪些患者群体进行推断？这通常是所有符合方案入排标准并被随机化的患者，这与**意向性治疗 (Intention-to-Treat, ITT)** 原则紧密相关。

2.  **变量 (Variable)**：即终点指标。对于每个患者，我们测量的具体结果是什么？例如，是从基线到第52周的最佳矫正视力（B[CVA](@entry_id:137027)）变化值。

3.  **中途事件策略 (Intercurrent Event Strategy)**：如何处理那些发生在治疗开始后、可能影响终点解释的中途事件？例如，患者可能需要补救治疗、接受白内障手术、停止研究药物，甚至死亡。选择的策略必须与临床问题相匹配。

4.  **汇总指标 (Summary Measure)**：在人群层面，我们如何汇总治疗效应？例如，比较两个治疗组间终点变量的平均值差异。

让我们通过一个在非增殖性糖尿病视网膜病变患者中比较抗[血管内皮](@entry_id:173763)生长因子（anti-VEGF）药物与伪治疗的试验案例来理解这个框架。试验的主要目的是评估在模拟真实世界实践（其中可能发生补救治疗）中，启动抗VEGF治疗相对于伪治疗在第52周对视力的影响。

根据这一政策相关的临床目标，我们可以构建如下的估量目标：

-   **目标人群**：所有在基线时符合方案入排标准并被随机化的成人患者。这确保了我们评估的是“启动治疗”这一决策对所有目标患者的平均效应。

-   **变量**：从基线到第52周的ETDRS视力字母数变化值。

-   **中途事件策略**：这是一个混合策略。
    -   对于补救治疗、白内障手术、方案外抗VEGF治疗或停止治疗等非致命性事件，采用**治疗策略 (treatment policy strategy)**。这意味着我们测量第52周的视力结果，而不管这些事件是否发生。这直接回答了“在真实世界中，包含所有这些后续事件的治疗路径的总体效果如何”这一政策性问题。
    -   对于**死亡**这一特殊事件，由于[视力](@entry_id:204428)无法测量，且临床上认为死亡是比任何视力下降都更差的结局，因此采用**复合策略 (composite strategy)**。具体而言，我们可以为在第52周前死亡的受试者预先指定一个极差的数值结局（例如，ETDRS字母数变化值为-100）。这在数学上将死亡排序为最差的结局，并允许将这些患者纳入对整个随机化人群的定量分析中，从而避免了因排除死亡患者而可能产生的偏倚。

-   **汇总指标**：治疗组与伪治疗组在第52周时，该复合变量的**边际均数差异 (marginal mean difference)**。

通过这样精确地定义估量目标，研究的发起者、监管机构和临床医生都能对研究旨在回答的问题达成共识，从而确保试验设计、实施和分析的一致性。

### 试验设计与执行的核心要素

一旦科学问题通过估量目标框架得以精确化，接下来的任务便是设计一个能够无偏且高效地回答这个问题的试验。这涉及到对终点、随机化和盲法等核心要素的细致考量。

#### 终点选择与测量

临床试验的结论效力在很大程度上取决于其终点的选择与测量质量。

**主要终点与次要终点**

在设计试验时，必须预先指定终点的层级结构，通常分为**主要终点 (primary endpoint)**、**次要终点 (secondary endpoints)** 和**探索性终点 (exploratory endpoints)**。

-   **主要终点**是能够提供关于干预措施获益的最具临床相关性和说服力证据的单一变量。它应直接反映患者的感受、功能或生存状况。
-   **次要终点**用于支持主要终点的结论，进一步描述疗效特征，或提供关于作用机制的证据。
-   **探索性终点**则用于产生新的假设，为未来的研究提供方向，但通常不进行正式的假设检验。

在一个旨在评估新生血管性年龄相关性黄斑变性（nAMD）新药的试验中，我们可能同时测量**最佳矫正[视力](@entry_id:204428)（B[CVA](@entry_id:137027)）**、**中心凹视网膜厚度（CST）**以及**视网膜下/内液（fluid）**的存在与否。根据ICH E9指导原则，B[CVA](@entry_id:137027)（以ETDRS字母数衡量）是衡量患者视觉功能的直接指标，它反映了患者“看得怎么样”，具有明确的临床意义，因此最适合作为主要终点。相比之下，CST和液体状态是通过[光学相干断层扫描](@entry_id:173275)（OCT）测量的解剖学**替代终点 (surrogate endpoints)**。它们对于理解药物的作用机制至关重要，但本身并不能直接代表患者的视觉功能。因此，它们更适合被指定为次要终点，以支持主要终点的发现。

**视力的量化：ETDRS与logMAR**

在眼科试验中，B[CVA](@entry_id:137027)的精确量化是关键。传统的Snellen视力表（如 $\frac{20}{40}$）是一个序数量表，各行之间的难度跨度不均等，不适合进行参数统计分析。为了克服这些局限性，**早期治疗糖尿病视网膜病变研究（ETDRS）** 视力表应运而生。

-   **ETDRS字母分 (ETDRS letter score)**：这是一种通过计算受试者在标准ETDRS[视力](@entry_id:204428)表上正确识别的字母总数来衡量[视力](@entry_id:204428)的方法。由于每个字母都被计分，它提供了一个近似连续的、区间尺度的数据，使得计算均值、标准差和进行t检验等参数统计方法成为可能，从而极大地提高了[统计功效](@entry_id:197129)。

-   **最小分辨角对数（logMAR）**：为了实现视力标度的线性化，引入了logMAR标度。它基于**最小分辨角 (Minimum Angle of Resolution, MAR)**，即观察者视觉系统能分辨的最小角度（单位为角分）。MAR是Snellen分数的倒数（例如，Snellen[视力](@entry_id:204428) $\frac{20}{20}$ 对应MAR为1角分，$\frac{20}{200}$ 对应MAR为10角分）。logMAR的定义为：
    $$
    \text{logMAR} = \log_{10}(\text{MAR})
    $$
    ETDRS[视力](@entry_id:204428)表的设计使得相邻两行字母大小成几何级数变化，而每行所代表的logMAR值变化是等距的（通常为 $0.1$ logMAR单位）。取对数将[几何级数](@entry_id:158490)转换为了算术级数，创建了一个[线性标度](@entry_id:197235)。在这个标度上，logMAR值越小，视力越好。

这两者之间存在一个直接的换算关系。标准的ETDRS视力表每行有5个字母，每行代表 $0.1$ logMAR单位的变化。因此，[视力](@entry_id:204428)改善（logMAR值减小）$0.1$ 个单位，精确地对应于多读出一行，即多获得5个ETDRS字母。反之，每正确多读1个字母，相当于logMAR值改善了 $\frac{0.1}{5} = 0.02$。它们之间的变化关系可以表示为：
$$
\Delta L_{\text{ETDRS}} = -50 \times \Delta(\text{logMAR})
$$
其中 $\Delta L_{\text{ETDRS}}$ 是ETDRS字母数的变化，而 $\Delta(\text{logMAR})$ 是logMAR值的变化。例如，logMAR值改善 $0.1$ （即 $\Delta(\text{logMAR}) = -0.1$）对应于 $\Delta L_{\text{ETDRS}} = -50 \times (-0.1) = 5$ 个字母的增加。

#### 随机化与分配

随机化是随机对照试验（RCT）的基石，其目的是在治疗组间创建可比的基线特征分布，从而使得组间的任何差异都可以归因于治疗本身。同时，它为[统计推断](@entry_id:172747)提供了[概率基础](@entry_id:187304)。在实践中，有多种随机化方法可供选择。

-   **简单随机化 (Simple Randomization)**：每个受试者以[固定概率](@entry_id:178551)（如 $0.5$）被独立地分配到一个组。这种方法最简单，保证了分配的不可预测性，但在样本量不大时，尤其是在多中心试验的各个中心内部，可能偶然出现治疗组人数的显著不均衡。

-   **区组随机化 (Permuted Block Randomization)**：为了确保在试验过程中的任何时间点，各组人数都保持接近平衡，可以使用区组随机化。例如，在一个大小为4的区组内，随机安排2个A治疗和2个B治疗。这种方法可以保证在每个区组完成后，各组人数完全相等。然而，如果区组大小是固定的，研究者可能会预测到区组末尾的分配，从而引入选择偏倚。因此，通常推荐使用**随机大小的区组**。

-   **[分层随机化](@entry_id:189937) (Stratified Randomization)**：在多中心试验中，不同中心之间的患者特征和医疗实践可能存在差异，中心本身就是一个重要的预后因素。为了确保每个中心内部治疗组的均衡，可以采用[分层随机化](@entry_id:189937)。即在每个中心（层）内部独立进行区组随机化。同样，对于其他重要的基线预后因素（如基线视网膜厚度），也可以进行分层。但是，分层因素不宜过多，否则会导致分层过细，许多亚层中的受试者数量极少，失去分层的意义。

-   **协变量自适应随机化 (Covariate-Adaptive Randomization)**，如**最小化法 (Minimization)**：当需要平衡多个重要的预后因素时，[分层随机化](@entry_id:189937)会变得不切实际。最小化法是一种动态的分[配方法](@entry_id:265480)。对于每一位新入组的受试者，该方法会计算将其分配到各个治疗组后，所有预设协变量的组间不平衡程度。然后，以一个较高的概率（如 $p=0.8$）将该受试者分配到能使总体不平衡性最小化的那个组。这个过程保留了一定的随机性（以 $1-p$ 的概率分配到其他组），从而保持了不可预测性，同时又能非常有效地在多个协变量上实现组间均衡。

无论采用何种随机化方法，都必须在分析阶段对用于随机化的因素（如中心、分层变量）进行适当的调整，例如，在分析模型中将它们作为协变量或随机效应。这是一个“按随机化方式分析”的重要原则。

#### 盲法（设盲）

**盲法 (Masking或Blinding)** 是指在试验过程中，一个或多个相关方（如受试者、研究者、结局评估者）不知道受试者的治疗分配。其目的是为了防止因知晓治疗分配而产生的**执行偏倚 (performance bias)** 和**评估偏倚 (detection bias)**。

在眼科局部用药试验中，维持盲法可能面临独特的挑战。例如，一项比较青光眼药物A（[前列腺素](@entry_id:201770)类似物）和药物B（β-受体阻滞剂）的试验，如果药物A引起眼部灼烧感的概率（如 $p_A = 0.40$）显著高于药物B（如 $p_B = 0.10$），那么受试者和研究者很可能通过这一可感知的副作用猜出治疗分配。

这种**破盲 (unmasking)** 会导致系统性偏倚。假设结局评估者在潜意识中认为引起刺激感的“活性”药物更有效，当他们猜到受试者在用药物A时，可能会系统性地将眼压（IOP）读数记录得更低。我们可以将这种偏倚量化。设评估者的测量值为 $\tilde{Y}_i = Y_i + b K_i$，其中 $Y_i$ 是真实IOP， $K_i=1$ 表示评估者被破盲， $b$ 是偏倚量（如 $b = -1$ mmHg）。在A组，破盲的期望是 $b p_A$；在B组，是 $b p_B$。因此，对治疗效应差异的估计所引入的偏倚为：
$$
\text{Bias} = b p_A - b p_B = b(p_A - p_B) = -1 \times (0.40 - 0.10) = -0.30 \text{ mmHg}
$$
这意味着，由于差异化的副作用，观察到的两组IOP差异会比真实差异人为地多出 $0.30$ mmHg。

为了应对这种挑战，可以使用**双模拟 (double-dummy)** 技术。在这种设计中，每位受试者都会同时收到两种制剂，其中一种是活性药，另一种是外观、给药方案完全相同的安慰剂。
-   A组受试者收到：活性药物A + 安慰剂B。
-   B组受试者收到：活性药物B + 安慰剂A。

为了达到最佳效果，安慰剂（载体）的理化性质（如粘稠度、防腐剂）应被精心设计，以模拟活性药物的感官特征，从而使两组的体验尽可能相似。此外，药物的分发人员和结局的评估人员应严格分开，以防止任何潜在的线索传递。

### 统计规划与分析原则

严谨的统计规划和分析是确保临床试验结论可靠性的最后一道防线。这包括样本量估算、多重性问题的处理以及对[缺失数据](@entry_id:271026)的恰当分析。

#### 考虑相关性的样本量估算

样本量估算是为了确保试验有足够的**统计功效 (statistical power)** 来检测出预设的、具有临床意义的治疗效应。对于独立的观察单位，标准样本量公式是众所周知。然而，在眼科试验中，常常会纳入同一患者的双眼数据。由于来自同一患者的双眼在生理和遗传上高度相关，它们并非独立的观察单位。这种相关性必须在样本量计算中予以考虑。

这种眼内相关性通常用**组内相关系数 (Intraclass Correlation Coefficient, ICC)**，记为 $\rho$，来量化。它衡量了来自同一患者（组）的双眼测量值之间的相似程度。当 $\rho > 0$ 时，来自同一患者的双眼提供的信息量会少于两个来自不同患者的独立眼睛。

为了调整样本量以应对这种相关性，我们需要计算**设计效应 (Design Effect, DEFF)**。设计效应指的是在复杂抽样设计（此处为整群抽样，患者为“群”）下[估计量方差](@entry_id:263211)与在相同样本量简单[随机抽样](@entry_id:175193)下[估计量方差](@entry_id:263211)的比值。如果试验中部分患者提供双眼（比例为 $p$），部分患者提供[单眼](@entry_id:165632)（比例为 $1-p$），则平均每位患者提供的眼睛数（即平均群大小）为 $\bar{m} = 2p + 1(1-p) = 1+p$。对于这种可变群大小的情况，设计效应的精确公式为：
$$
\mathrm{DEFF} = \frac{1+p+2p\rho}{1+p}
$$
样本量的调整步骤如下：
1.  首先，计算在假设所有观察单位（眼睛）都独立的情况下所需的每组**眼睛**数量，记为 $N_{eye, orig}$。这通常基于标准的双样本检验公式。
2.  然后，用这个原始眼睛数量乘以设计效应，得到在聚类设计下所需的总**眼睛**数量：$N_{eye, new} = N_{eye, orig} \times \mathrm{DEFF}$。
3.  最后，将所需的总眼睛数量除以平均每位患者的眼睛数 $\bar{m}$，得到最终所需的每组**患者**数量：
    $$
    N_{pat, new} = \frac{N_{eye, new}}{\bar{m}} = \frac{N_{eye, orig} \cdot \mathrm{DEFF}}{\bar{m}}
    $$

例如，在一项青光眼试验中，若初始计算需要每组189.19只独立的眼睛，假设 $p=0.5$ 的患者提供双眼，ICC $\rho=0.50$，则 $\bar{m} = 1.5$，DEFF = $\frac{1+0.5+2(0.5)(0.5)}{1.5} = \frac{2}{1.5} = \frac{4}{3}$。新的患者样本量为 $189.19 \times \frac{4/3}{1.5} = 189.19 \times \frac{8}{9} \approx 168.17$，向上取整为每组169名患者。

#### 多重终点的处理

当一项试验评估多个终点时，就会出现**[多重性](@entry_id:136466) (multiplicity)** 问题。每次进行假设检验，都有一定概率（即 $\alpha$ 水平，通常为 $0.05$）犯第一类错误（即错误地拒绝一个真实的零假设）。如果同时检验多个假设，那么在整个假设族中至少犯一次第一类错误的概率，即**[族错误率](@entry_id:165945) (Familywise Error Rate, FWER)**，将会显著高于 $\alpha$。

例如，如果独立地检验3个终点，即使每个都在 $\alpha=0.05$ 水平，FWER也会上升到 $1 - (1-0.05)^3 \approx 0.14$。为了将FWER控制在预设的 $\alpha$ 水平，必须采用[多重性](@entry_id:136466)校正策略。

一种常用且强大的方法是**分级检验 (hierarchical testing)** 或称**序贯门控 (sequential gatekeeping)**。这种方法要[求根](@entry_id:140351)据临床重要性对终点进行严格的预先排序（如：主要终点 $\rightarrow$ 关键次要终点1 $\rightarrow$ 关键次要终点2）。检验过程如下：
1.  首先在 $\alpha$ 水平检验主要终点。
2.  如果主要终点的检验结果不显著（$p \ge \alpha$），则停止检验，后续所有次要终点都不能宣告为有统计学意义。
3.  如果主要终点的检验结果显著（$p  \alpha$），则“打开第一道门”，允许在 $\alpha$ 水平检验第一个关键次要终点。
4.  这个过程依次进行下去：只有当前一个更重要的终点检验显著时，才能继续检验下一个次要终点。

这种策略能够严格地将FWER控制在 $\alpha$ 水平。其逻辑在于，在任何零假设为真的情况下，犯第一类错误的唯一机会发生在检验该假设族的第一个为真的零假设时，而这次检验是以（且仅以） $\alpha$ 水平进行的。这种方法比简单的[Bonferroni校正](@entry_id:261239)（即将 $\alpha$ 均分给所有检验）具有更高的统计功效，因为它没有分散检验效力。 

#### 纵向数据与[缺失数据](@entry_id:271026)的分析

在眼科试验中，终点通常会在多个时间点重复测量，形成**纵向数据 (longitudinal data)**。一个主要的分析挑战是受试者可能因各种原因在试验结束前脱落，导致数据**缺失 (missing)**。处理缺失数据的方法直接影响到试验结果的有效性。

[缺失数据机制](@entry_id:173251)通常分为三类：

1.  **[完全随机缺失](@entry_id:170286) (Missing Completely At Random, MCAR)**：缺失的发生与任何已观测或未观测的数据都无关。
2.  **[随机缺失](@entry_id:168632) (Missing At Random, MAR)**：在给定已观测数据后，缺失的发生与未观测的数据无关。换言之，缺失的原因可以被已有的[观测信息](@entry_id:165764)所解释。例如，如果病情较差的患者更容易脱落，但“病情较差”可以通过已测量的[视力](@entry_id:204428)值来反映，那么数据就符合MAR。
3.  **[非随机缺失](@entry_id:163489) (Missing Not At Random, MNAR)**：即使在给定所有已观测数据后，缺失的发生仍然与未观测的数据本身有关。这也被称为“不可忽略的”缺失。

历史上，一种常用的处理[缺失数据](@entry_id:271026)的方法是**末次观测值结转 (Last Observation Carried Forward, LOCF)**。这种方法用患者脱落前的最后一次观测值来填充之后所有缺失的访视数据。然而，LOCF基于一个极不合理的假设，即患者在脱落后的状态会一直保持不变。在MAR机制下，这通常会导致有偏的治疗效应估计和不正确的[标准误](@entry_id:635378)。

现代统计学推荐使用基于似然的、更具原则性的方法，如**混合效应模型重复测量分析 (Mixed Model for Repeated Measures, MMRM)**。MMRM直接对所有受试者在所有他们参与的访视中的观测数据进行建模，而无需对缺失值进行插补。在MAR的假设下，只要模型设定正确，MMRM能够提供对治疗效应的[无偏估计](@entry_id:756289)。MMRM模型通常包含治疗、访视、治疗与访视的[交互作用](@entry_id:164533)作为固定效应，并对患者内部的重复测量数据之间的相关性结构进行建模（例如，使用灵活的**非结构化 (unstructured)** 协方差矩阵）。这种方法充分利用了所有可用的信息，是目前处理纵向数据缺失问题的金标准方法之一。

然而，我们也必须警惕MNAR的可能性。在某些情况下，MAR的假设也可能不成立。一个典型的眼科例子是，在AMD试验中，部分受试者因**白内障**加重而接受了非计划的白内障手术。根据方案，术后一段时间内的B[CVA](@entry_id:137027)数据可能被视为缺失。这种缺失很可能是MNAR，因为手术的决定本身就与患者潜在的、未被观测的视力轨迹（即，如果不做手术，视力会变得多差）密切相关。即使我们控制了所有已观测的历史B[CVA](@entry_id:137027)数据，手术的可能性仍然取决于那个未被观测的、更差的潜在视力结局。在这种情况下，标准的MMRM分析可能仍然会产生偏倚，需要更复杂的敏感性分析或专门的MN[AR模型](@entry_id:189434)来评估结果的稳健性。