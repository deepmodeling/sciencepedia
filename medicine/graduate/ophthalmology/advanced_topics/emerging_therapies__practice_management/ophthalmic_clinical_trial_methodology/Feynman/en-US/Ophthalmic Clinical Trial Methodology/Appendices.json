{
    "hands_on_practices": [
        {
            "introduction": "Before any clinical trial begins, the most fundamental question is determining the required number of participants to answer the research question reliably. This process, known as sample size calculation, is a critical exercise in balancing statistical power with practical and ethical constraints. This practice guides you through the foundational logic of a power analysis, starting from first principles to derive the formula for a two-group comparison of means, a cornerstone of clinical trial design .",
            "id": "4703033",
            "problem": "A multicenter, two-arm, parallel-group randomized clinical trial in neovascular age-related macular degeneration is planned to compare the mean change in Early Treatment Diabetic Retinopathy Study (ETDRS) letters from baseline to month $12$ between an investigational anti-Vascular Endothelial Growth Factor (anti-VEGF) regimen and a standard anti-VEGF regimen. Let $\\mu_{T}$ and $\\mu_{C}$ denote the arm-specific population means of the change in ETDRS letters, and assume independent participants, equal allocation, and a common population standard deviation $\\sigma$ of the change scores across arms. The primary analysis will use a two-sided test of $H_{0}:\\mu_{T}-\\mu_{C}=0$ at type I error $\\alpha=0.05$, with desired power $1-\\beta=0.9$ to detect a clinically meaningful difference in mean change of magnitude $\\Delta=5$ letters, under the assumption that the sampling distribution of arm means is well-approximated by the normal distribution and the arms share the same variance.\n\nUsing only the properties of the normal distribution for the difference in sample means under equal allocation, derive the minimum per-arm sample size $n$ required to achieve the specified type I error and power. In your derivation, start from the distribution of the difference in sample means and the corresponding standardized test statistic under both the null and the alternative, and enforce the power requirement by an inequality on the standardized alternative mean relative to the two-sided rejection threshold. Take $\\sigma=12$ letters. Treat $z_{p}$ as the $p$-quantile of the standard normal distribution. Compute the real-valued $n$ to at least four significant figures and then report the planned per-arm sample size as the smallest integer greater than or equal to that value. Provide the final answer as the per-arm sample size with no units.",
            "solution": "Let $\\bar{X}_{T}$ and $\\bar{X}_{C}$ be the sample means of the change in ETDRS letters from baseline to month $12$ for the investigational treatment arm and the standard regimen (control) arm, respectively. Let $n_{T}$ and $n_{C}$ be the sample sizes for each arm. The problem specifies equal allocation, so $n_{T} = n_{C} = n$. The population means are $\\mu_{T}$ and $\\mu_{C}$, and the common population standard deviation is $\\sigma$.\n\nThe endpoint of interest is the difference in sample means, $\\bar{D} = \\bar{X}_{T} - \\bar{X}_{C}$. Under the assumption that the sampling distribution of arm means is normal, and given that the participants are independent, the distribution of $\\bar{D}$ is also normal.\nThe expected value of $\\bar{D}$ is $E[\\bar{D}] = E[\\bar{X}_{T}] - E[\\bar{X}_{C}] = \\mu_{T} - \\mu_{C}$.\nThe variance of $\\bar{D}$ is $\\text{Var}(\\bar{D}) = \\text{Var}(\\bar{X}_{T}) + \\text{Var}(\\bar{X}_{C}) = \\frac{\\sigma^2}{n_{T}} + \\frac{\\sigma^2}{n_{C}} = \\frac{\\sigma^2}{n} + \\frac{\\sigma^2}{n} = \\frac{2\\sigma^2}{n}$.\nThus, the sampling distribution of the difference in means is:\n$$ \\bar{D} \\sim N\\left(\\mu_{T} - \\mu_{C}, \\frac{2\\sigma^2}{n}\\right) $$\nThe primary analysis involves testing the null hypothesis $H_{0}: \\mu_{T} - \\mu_{C} = 0$. The test statistic is formulated by standardizing $\\bar{D}$ under $H_0$. Let $SE(\\bar{D}) = \\sqrt{\\frac{2\\sigma^2}{n}}$ be the standard error of the difference. The test statistic $Z$ is:\n$$ Z = \\frac{\\bar{D} - 0}{SE(\\bar{D})} = \\frac{\\bar{X}_{T} - \\bar{X}_{C}}{\\sqrt{\\frac{2\\sigma^2}{n}}} $$\nUnder $H_{0}$, this statistic follows a standard normal distribution, $Z \\sim N(0, 1)$.\n\nFor a two-sided test at a significance level of $\\alpha = 0.05$, we reject $H_{0}$ if the observed value of $|Z|$ exceeds the critical value $z_{1-\\alpha/2}$. Here, $1 - \\alpha/2 = 1 - 0.05/2 = 0.975$. The critical value is $z_{0.975}$. The rejection region is $|Z| > z_{0.975}$.\n\nThe power of the test is the probability of rejecting $H_{0}$ when the alternative hypothesis, $H_{A}$, is true. The problem specifies a clinically meaningful difference $\\Delta = \\mu_{T} - \\mu_{C} = 5$. We calculate power under the specific alternative $H_A: \\mu_{T} - \\mu_{C} = \\Delta$.\n\nUnder $H_A$, the test statistic $Z$ is not standard normal. Its distribution is:\n$$ Z = \\frac{\\bar{D}}{SE(\\bar{D})} \\sim N\\left(\\frac{\\Delta}{SE(\\bar{D})}, 1\\right) = N\\left(\\frac{\\Delta}{\\sqrt{\\frac{2\\sigma^2}{n}}}, 1\\right) $$\nPower, $1-\\beta$, is the probability of $Z$ falling into the rejection region, given $H_A$ is true.\n$$ 1-\\beta = P(|Z| > z_{1-\\alpha/2} | H_A) $$\nFor a positive difference $\\Delta > 0$, the mean of $Z$ under $H_A$ is positive. Thus, the probability of rejecting in the lower tail ($Z < -z_{1-\\alpha/2}$) is negligible compared to the probability of rejecting in the upper tail ($Z > z_{1-\\alpha/2}$). The power is therefore dominated by the upper tail probability:\n$$ 1-\\beta \\approx P(Z > z_{1-\\alpha/2} | H_A) $$\nTo evaluate this probability, we can standardize the random variable $Z$ under $H_A$. Let $\\mu_Z = \\frac{\\Delta}{\\sqrt{2\\sigma^2/n}}$ be the mean of $Z$ under $H_A$. Then $Z - \\mu_Z \\sim N(0, 1)$.\nThe power requirement can be written as:\n$$ P(Z - \\mu_Z > z_{1-\\alpha/2} - \\mu_Z) = 1-\\beta $$\nSince $Z - \\mu_Z$ is a standard normal variable, the value $z_{1-\\alpha/2} - \\mu_Z$ must correspond to the quantile $z_{\\beta}$ of the standard normal distribution, where $P(\\text{std. normal} > z_{\\beta}) = 1-\\beta$. Note that $z_{\\beta} = -z_{1-\\beta}$.\nSo, we have the equality:\n$$ z_{1-\\alpha/2} - \\mu_Z = z_{\\beta} = -z_{1-\\beta} $$\nThis leads to the condition on the mean of the test statistic under the alternative:\n$$ \\mu_Z = z_{1-\\alpha/2} + z_{1-\\beta} $$\nSubstituting the expression for $\\mu_Z$:\n$$ \\frac{\\Delta}{\\sqrt{\\frac{2\\sigma^2}{n}}} = z_{1-\\alpha/2} + z_{1-\\beta} $$\nTo achieve the desired power, the sample size $n$ must be large enough to satisfy this condition. Therefore, we establish the inequality:\n$$ \\frac{\\Delta}{\\sqrt{\\frac{2\\sigma^2}{n}}} \\ge z_{1-\\alpha/2} + z_{1-\\beta} $$\nWe now solve for the minimum per-arm sample size, $n$. Rearranging the inequality:\n$$ \\Delta \\ge (z_{1-\\alpha/2} + z_{1-\\beta}) \\sqrt{\\frac{2\\sigma^2}{n}} $$\nSquaring both sides:\n$$ \\Delta^2 \\ge (z_{1-\\alpha/2} + z_{1-\\beta})^2 \\left(\\frac{2\\sigma^2}{n}\\right) $$\nFinally, isolating $n$:\n$$ n \\ge \\frac{2\\sigma^2 (z_{1-\\alpha/2} + z_{1-\\beta})^2}{\\Delta^2} $$\nThe problem provides the following values: $\\sigma = 12$, $\\Delta = 5$, $\\alpha = 0.05$, and $1-\\beta = 0.9$. We find the corresponding quantiles of the standard normal distribution:\n$z_{1-\\alpha/2} = z_{1-0.025} = z_{0.975} \\approx 1.959964$.\n$z_{1-\\beta} = z_{1-0.1} = z_{0.9} \\approx 1.281552$.\n\nSubstituting these values into the formula for $n$:\n$$ n \\ge \\frac{2(12)^2 (1.959964 + 1.281552)^2}{5^2} $$\n$$ n \\ge \\frac{2(144) (3.241516)^2}{25} $$\n$$ n \\ge \\frac{288 (10.50741)}{25} $$\n$$ n \\ge \\frac{3026.134}{25} $$\n$$ n \\ge 121.04536 $$\nThe problem requires reporting the planned per-arm sample size as the smallest integer greater than or equal to this real-valued result.\n$$ n = \\lceil 121.04536 \\rceil = 122 $$\nTherefore, the minimum required sample size per arm is $122$.",
            "answer": "$$\n\\boxed{122}\n$$"
        },
        {
            "introduction": "Ophthalmic trials frequently collect data from both eyes of each participant, which are not statistically independent observations. Failing to account for this correlation can lead to an underpowered study and incorrect conclusions. This exercise introduces the concept of the design effect, which uses the intraclass correlation coefficient ($\\rho$) to quantify the inflation in variance due to such clustering and adjust sample size accordingly, a crucial skill for any researcher in ophthalmology .",
            "id": "4702949",
            "problem": "A parallel-group randomized clinical trial in glaucoma plans to analyze eye-level outcomes of Intraocular Pressure (IOP). Each participant contributes measurements from both eyes at a single follow-up time, and participants are assumed independent of one another. Let the within-participant (within-cluster) intraclass correlation coefficient be denoted by $\\rho$, with common marginal variance $\\sigma^{2}$ for eye-level IOP, and let the average number of eyes contributing per participant (cluster size) be $m$. The design effect is defined as the multiplicative inflation in the variance of an eye-level mean due to within-participant correlation, relative to the variance that would obtain if all eyes were independent.\n\nStarting only from the definition of the intraclass correlation coefficient $\\rho$ as the common correlation between two distinct eye-level measurements from the same participant and the basic algebra of variances and covariances for sums of random variables, derive the design effect as a function of $m$ and $\\rho$. Then evaluate this design effect for a trial with average cluster size $m=2$ and intraclass correlation $\\rho=0.35$ that measures IOP in both eyes per participant. Briefly interpret how this design effect modifies the required eye-level sample size if one had initially planned under independence.\n\nProvide the exact value of the design effect as your final answer (no units).",
            "solution": "The objective is to derive the expression for the design effect ($DEFF$), which is defined as the ratio of the variance of the eye-level mean in the presence of clustering to the variance of the eye-level mean under the assumption of complete independence.\n\nLet $N$ be the number of participants (clusters) and $m$ be the number of eyes per participant (cluster size). The total number of eye-level observations is $K = Nm$. Let $Y_{ij}$ denote the IOP measurement for eye $j$ (where $j=1, \\dots, m$) of participant $i$ (where $i=1, \\dots, N$).\n\nThe eye-level sample mean, $\\bar{Y}$, is given by:\n$$ \\bar{Y} = \\frac{1}{K} \\sum_{i=1}^{N} \\sum_{j=1}^{m} Y_{ij} = \\frac{1}{Nm} \\sum_{i=1}^{N} \\sum_{j=1}^{m} Y_{ij} $$\n\nThe variance of this mean in the presence of correlation, $\\text{Var}_{\\text{corr}}(\\bar{Y})$, is:\n$$ \\text{Var}_{\\text{corr}}(\\bar{Y}) = \\text{Var}\\left(\\frac{1}{Nm} \\sum_{i=1}^{N} \\sum_{j=1}^{m} Y_{ij}\\right) = \\frac{1}{(Nm)^2} \\text{Var}\\left(\\sum_{i=1}^{N} \\sum_{j=1}^{m} Y_{ij}\\right) $$\n\nSince participants are independent, observations from different participants are uncorrelated, i.e., $\\text{Cov}(Y_{ij}, Y_{i'k}) = 0$ for $i \\neq i'$. Thus, the variance of the total sum is the sum of the variances of the within-participant sums:\n$$ \\text{Var}\\left(\\sum_{i=1}^{N} \\sum_{j=1}^{m} Y_{ij}\\right) = \\sum_{i=1}^{N} \\text{Var}\\left(\\sum_{j=1}^{m} Y_{ij}\\right) $$\n\nNow, we find the variance of the sum of observations for a single participant $i$. Using the algebra of variances for sums of random variables:\n$$ \\text{Var}\\left(\\sum_{j=1}^{m} Y_{ij}\\right) = \\sum_{j=1}^{m} \\text{Var}(Y_{ij}) + \\sum_{j \\neq k} \\text{Cov}(Y_{ij}, Y_{ik}) $$\n\nThe problem states that the common marginal variance is $\\text{Var}(Y_{ij}) = \\sigma^2$ and the intraclass correlation is $\\rho = \\text{Corr}(Y_{ij}, Y_{ik})$ for $j \\neq k$. By definition, $\\text{Cov}(Y_{ij}, Y_{ik}) = \\rho \\sigma^2$ for $j \\neq k$. Substituting these into the expression:\n*   The sum of variances is $\\sum_{j=1}^{m} \\text{Var}(Y_{ij}) = m\\sigma^2$.\n*   The sum of covariances involves $m(m-1)$ pairs, so $\\sum_{j \\neq k} \\text{Cov}(Y_{ij}, Y_{ik}) = m(m-1)\\rho\\sigma^2$.\n\nCombining these, the variance for one participant's sum is:\n$$ \\text{Var}\\left(\\sum_{j=1}^{m} Y_{ij}\\right) = m\\sigma^2 + m(m-1)\\rho\\sigma^2 = m\\sigma^2 [1 + (m-1)\\rho] $$\n\nThe variance of the total sum across all $N$ independent participants is $N$ times this amount: $Nm\\sigma^2 [1 + (m-1)\\rho]$.\nThe variance of the overall mean is therefore:\n$$ \\text{Var}_{\\text{corr}}(\\bar{Y}) = \\frac{1}{(Nm)^2} \\left( Nm\\sigma^2 [1 + (m-1)\\rho] \\right) = \\frac{\\sigma^2}{Nm} [1 + (m-1)\\rho] $$\n\nUnder the hypothetical scenario of complete independence, the variance of the mean, $\\text{Var}_{\\text{indep}}(\\bar{Y})$, would simply be:\n$$ \\text{Var}_{\\text{indep}}(\\bar{Y}) = \\frac{\\sigma^2}{K} = \\frac{\\sigma^2}{Nm} $$\n\nThe design effect ($DEFF$) is the ratio of these two variances:\n$$ DEFF = \\frac{\\text{Var}_{\\text{corr}}(\\bar{Y})}{\\text{Var}_{\\text{indep}}(\\bar{Y})} = \\frac{\\frac{\\sigma^2}{Nm} [1 + (m-1)\\rho]}{\\frac{\\sigma^2}{Nm}} = 1 + (m-1)\\rho $$\nThis completes the derivation.\n\nNow, we evaluate this for the given values: average cluster size $m=2$ and intraclass correlation $\\rho=0.35$.\n$$ DEFF = 1 + (2-1) \\times 0.35 = 1 + 0.35 = 1.35 $$\nThis design effect of $1.35$ means that the variance of the estimated mean is $35\\%$ larger than it would be if all eyes were independent. Consequently, to achieve the same statistical power, the total required number of eyes must be inflated by this factor (i.e., increased by $35\\%$) compared to a calculation that wrongly assumes independence.",
            "answer": "$$\n\\boxed{1.35}\n$$"
        },
        {
            "introduction": "Clinical decisions are rarely based on a single study; instead, they rely on the synthesis of all available evidence. Meta-analysis is the statistical technique for combining results from multiple independent trials to generate a more precise and generalizable estimate of a treatment's effect. This practice provides a hands-on walkthrough of a fixed-effect meta-analysis, demonstrating how to pool relative effects (odds ratios) and translate them into an absolute risk difference that is directly meaningful for clinical practice .",
            "id": "4703018",
            "problem": "An ophthalmology research team is planning a meta-analysis of anti-Vascular Endothelial Growth Factor (VEGF) therapy trials for neovascular age-related macular degeneration. The common binary endpoint is a clinically meaningful responder status defined as gaining $\\geq 15$ letters on the Early Treatment Diabetic Retinopathy Study (ETDRS) chart at $12$ months. The team will synthesize evidence using log-odds ratios and then convert the pooled relative effect into an absolute scale for clinical interpretation.\n\nYou are given three independent, parallel-group randomized trials comparing anti-VEGF therapy versus control. At $12$ months, the counts of responders (gaining $\\geq 15$ letters) and non-responders are:\n\n- Trial A: Treatment responders $a_{A} = 65$ of $200$ ($b_{A} = 135$ non-responders), Control responders $c_{A} = 20$ of $200$ ($d_{A} = 180$ non-responders).\n- Trial B: Treatment responders $a_{B} = 45$ of $150$ ($b_{B} = 105$), Control responders $c_{B} = 18$ of $150$ ($d_{B} = 132$).\n- Trial C: Treatment responders $a_{C} = 80$ of $250$ ($b_{C} = 170$), Control responders $c_{C} = 40$ of $250$ ($d_{C} = 210$).\n\nStarting from fundamental definitions of probability, odds, and odds ratio, and the large-sample normal approximation for the sampling distribution of the log-odds ratio with variance $\\operatorname{Var}(\\ln(\\widehat{\\text{OR}})) = \\frac{1}{a} + \\frac{1}{b} + \\frac{1}{c} + \\frac{1}{d}$ for a $2 \\times 2$ table, perform a fixed-effect inverse-variance meta-analysis to obtain the pooled log-odds ratio across the three trials. Then, using the pooled odds ratio and a clinically relevant baseline control risk $p_{0} = 0.12$ for achieving $\\geq 15$ ETDRS letters gain at $12$ months in this population, convert the pooled relative effect to the absolute risk difference defined as $p_{1} - p_{0}$, where $p_{1}$ is the treatment-group event probability implied by the pooled odds ratio and $p_{0}$.\n\nUse only the stated assumptions and definitions, justify each transformation from first principles, and compute the final pooled absolute risk difference (treatment minus control) as a decimal fraction. Round your answer to four significant figures. Express the final answer as a decimal fraction with no percent sign.",
            "solution": "The problem requires the calculation of a pooled absolute risk difference from a meta-analysis of three clinical trials. The process involves three main stages: (1) calculating the log-odds ratio and its variance for each trial; (2) pooling these log-odds ratios using a fixed-effect inverse-variance model; and (3) converting the resulting pooled odds ratio into an absolute risk difference using a specified baseline risk. We will proceed methodically from first principles.\n\nLet the data for a given trial be represented by a $2 \\times 2$ contingency table, where $a$ and $b$ are the counts of responders and non-responders in the treatment group, and $c$ and $d$ are the counts for the control group.\n\nThe probability, or risk, of an event in a group is estimated as the number of individuals with the event divided by the total number in the group. The odds of an event are the ratio of the probability of the event occurring to the probability of it not occurring. For the treatment group, the estimated probability of response is $\\hat{p}_T = \\frac{a}{a+b}$, and the odds are $\\widehat{\\text{Odds}}_T = \\frac{\\hat{p}_T}{1-\\hat{p}_T} = \\frac{a/(a+b)}{b/(a+b)} = \\frac{a}{b}$. Similarly, for the control group, $\\widehat{\\text{Odds}}_C = \\frac{c}{d}$.\n\nThe odds ratio (OR) is the ratio of the odds in the treatment group to the odds in the control group. The sample odds ratio is calculated as:\n$$ \\widehat{\\text{OR}} = \\frac{\\widehat{\\text{Odds}}_T}{\\widehat{\\text{Odds}}_C} = \\frac{a/b}{c/d} = \\frac{ad}{bc} $$\nMeta-analysis is performed on the logarithmic scale because the sampling distribution of the log-odds ratio, $\\ln(\\widehat{\\text{OR}})$, is better approximated by a normal distribution.\n$$ \\ln(\\widehat{\\text{OR}}) = \\ln\\left(\\frac{ad}{bc}\\right) $$\nThe problem provides the large-sample approximation for the variance of the log-odds ratio:\n$$ V = \\operatorname{Var}(\\ln(\\widehat{\\text{OR}})) = \\frac{1}{a} + \\frac{1}{b} + \\frac{1}{c} + \\frac{1}{d} $$\n\nWe now calculate these quantities for each of the three trials.\n\n**Trial A:**\nThe data are $a_A = 65$, $b_A = 135$, $c_A = 20$, and $d_A = 180$.\nThe log-odds ratio is:\n$$ \\ln(\\widehat{\\text{OR}}_A) = \\ln\\left(\\frac{65 \\times 180}{135 \\times 20}\\right) = \\ln\\left(\\frac{11700}{2700}\\right) = \\ln\\left(4.333...\\right) \\approx 1.466337 $$\nThe variance is:\n$$ V_A = \\frac{1}{65} + \\frac{1}{135} + \\frac{1}{20} + \\frac{1}{180} \\approx 0.015385 + 0.007407 + 0.050000 + 0.005556 = 0.078348 $$\nThe weight for the meta-analysis is the inverse of the variance:\n$$ w_A = \\frac{1}{V_A} \\approx \\frac{1}{0.078348} \\approx 12.7633 $$\n\n**Trial B:**\nThe data are $a_B = 45$, $b_B = 105$, $c_B = 18$, and $d_B = 132$.\nThe log-odds ratio is:\n$$ \\ln(\\widehat{\\text{OR}}_B) = \\ln\\left(\\frac{45 \\times 132}{105 \\times 18}\\right) = \\ln\\left(\\frac{5940}{1890}\\right) = \\ln\\left(3.1428...\\right) \\approx 1.145132 $$\nThe variance is:\n$$ V_B = \\frac{1}{45} + \\frac{1}{105} + \\frac{1}{18} + \\frac{1}{132} \\approx 0.022222 + 0.009524 + 0.055556 + 0.007576 = 0.094877 $$\nThe weight is:\n$$ w_B = \\frac{1}{V_B} \\approx \\frac{1}{0.094877} \\approx 10.5399 $$\n\n**Trial C:**\nThe data are $a_C = 80$, $b_C = 170$, $c_C = 40$, and $d_C = 210$.\nThe log-odds ratio is:\n$$ \\ln(\\widehat{\\text{OR}}_C) = \\ln\\left(\\frac{80 \\times 210}{170 \\times 40}\\right) = \\ln\\left(\\frac{16800}{6800}\\right) = \\ln\\left(2.4705...\\right) \\approx 0.904424 $$\nThe variance is:\n$$ V_C = \\frac{1}{80} + \\frac{1}{170} + \\frac{1}{40} + \\frac{1}{210} \\approx 0.012500 + 0.005882 + 0.025000 + 0.004762 = 0.048144 $$\nThe weight is:\n$$ w_C = \\frac{1}{V_C} \\approx \\frac{1}{0.048144} \\approx 20.7708 $$\n\nNext, we perform a fixed-effect inverse-variance meta-analysis. The pooled log-odds ratio, denoted $\\ln(\\widehat{\\text{OR}}_p)$, is the weighted average of the individual log-odds ratios, where the weights are the inverse variances:\n$$ \\ln(\\widehat{\\text{OR}}_p) = \\frac{\\sum_{i=A,B,C} w_i \\ln(\\widehat{\\text{OR}}_i)}{\\sum_{i=A,B,C} w_i} $$\nFirst, we compute the sum of the weights:\n$$ \\sum w_i = w_A + w_B + w_C \\approx 12.7633 + 10.5399 + 20.7708 = 44.0740 $$\nThen, we compute the sum of the weighted log-odds ratios:\n\\begin{align*} \\sum w_i \\ln(\\widehat{\\text{OR}}_i) &\\approx (12.7633 \\times 1.466337) + (10.5399 \\times 1.145132) + (20.7708 \\times 0.904424) \\\\ &\\approx 18.7100 + 12.0694 + 18.7846 = 49.5640 \\end{align*}\nThe pooled log-odds ratio is:\n$$ \\ln(\\widehat{\\text{OR}}_p) = \\frac{49.5640}{44.0740} \\approx 1.12456 $$\nTo obtain the pooled odds ratio, we exponentiate the pooled log-odds ratio:\n$$ \\widehat{\\text{OR}}_p = \\exp(\\ln(\\widehat{\\text{OR}}_p)) \\approx \\exp(1.12456) \\approx 3.07897 $$\n\nThe final step is to convert this pooled relative effect into an absolute risk difference, defined as $\\text{ARD} = p_1 - p_0$. We are given a baseline control risk of $p_0 = 0.12$.\nThe odds corresponding to this control risk are:\n$$ \\text{Odds}_0 = \\frac{p_0}{1-p_0} = \\frac{0.12}{1 - 0.12} = \\frac{0.12}{0.88} \\approx 0.136364 $$\nThe pooled odds ratio relates the odds in the treatment group ($\\text{Odds}_1$) to the odds in the control group:\n$$ \\text{Odds}_1 = \\widehat{\\text{OR}}_p \\times \\text{Odds}_0 \\approx 3.07897 \\times 0.136364 \\approx 0.41986 $$\nNow, we convert the treatment odds back to a probability (risk), $p_1$:\n$$ p_1 = \\frac{\\text{Odds}_1}{1 + \\text{Odds}_1} \\approx \\frac{0.41986}{1 + 0.41986} = \\frac{0.41986}{1.41986} \\approx 0.295708 $$\nFinally, the absolute risk difference is:\n$$ \\text{ARD} = p_1 - p_0 \\approx 0.295708 - 0.12 = 0.175708 $$\nThe problem requires the answer to be rounded to four significant figures.\n$$ \\text{ARD} \\approx 0.1757 $$\nThis represents an estimated absolute increase of approximately $17.6\\%$ in the probability of a clinically meaningful vision gain for patients receiving anti-VEGF therapy compared to control, based on the pooled evidence and the assumed baseline risk.",
            "answer": "$$\n\\boxed{0.1757}\n$$"
        }
    ]
}