{
    "hands_on_practices": [
        {
            "introduction": "A cornerstone of Quality Assurance in any clinical laboratory is the rigorous validation of a new assay before its clinical implementation. This practice guides you through a fundamental method comparison study, where results from a candidate assay are plotted against a reference method. By performing an ordinary least squares regression, you will learn to quantify the constant and proportional systematic biases, providing critical insights into the new assay's accuracy .",
            "id": "5153032",
            "problem": "A clinical laboratory is performing a method comparison study as part of a quality assessment for a new chemiluminescent C-reactive protein (CRP) immunoassay. The goal is to quantify proportional and constant bias relative to an established immunoturbidimetric reference method by fitting a straight line to paired patient results. Five residual serum specimens spanning a clinically relevant range were measured once on each method after both assays passed internal quality control. Let the reference assay results be the independent variable $x$ (in $\\mathrm{mg/L}$) and the candidate assay results be the dependent variable $y$ (in $\\mathrm{mg/L}$). The paired results are:\n\n- $(x_1, y_1) = (\\,10\\,,\\,10.9\\,)$,\n- $(x_2, y_2) = (\\,20\\,,\\,20.5\\,)$,\n- $(x_3, y_3) = (\\,30\\,,\\,31.1\\,)$,\n- $(x_4, y_4) = (\\,40\\,,\\,41.7\\,)$,\n- $(x_5, y_5) = (\\,50\\,,\\,51.3\\,)$.\n\nAssume the reference method is treated as measured without error for the purpose of this analysis, and that a straight-line calibration adequately describes the relationship over the studied range. Using ordinary least squares to minimize the sum of squared vertical residuals $y - (\\alpha + \\beta x)$, determine the regression slope $\\beta$ and intercept $\\alpha$ that quantify proportional bias (via $\\beta$) and constant bias (via $\\alpha$). Round both $\\beta$ and $\\alpha$ to four significant figures. Report your final answer as a row matrix $\\begin{pmatrix}\\beta & \\alpha\\end{pmatrix}$. Do not include units in your final reported matrix, but interpret $\\alpha$ as expressed in $\\mathrm{mg/L}$ for the candidate assay.",
            "solution": "The problem is valid as it presents a standard, well-posed statistical analysis task common in clinical laboratory science. It is scientifically grounded, objective, and contains all necessary information to derive a unique solution.\n\nThe objective is to determine the optimal slope $\\beta$ and intercept $\\alpha$ for a linear model $y = \\alpha + \\beta x$ that best fits the provided data. This is achieved using the method of ordinary least squares (OLS), which minimizes the sum of the squared vertical deviations (residuals) between the observed data points $y_i$ and the values predicted by the model, $\\hat{y}_i = \\alpha + \\beta x_i$. The function to be minimized is the sum of squared residuals, $S$:\n$$S(\\alpha, \\beta) = \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2 = \\sum_{i=1}^{n} (y_i - \\alpha - \\beta x_i)^2$$\nHere, $n=5$ is the number of paired data points.\n\nTo find the values of $\\alpha$ and $\\beta$ that minimize $S$, we take the partial derivatives of $S$ with respect to $\\alpha$ and $\\beta$ and set them to zero.\n\nThe partial derivative with respect to $\\alpha$ is:\n$$\\frac{\\partial S}{\\partial \\alpha} = \\sum_{i=1}^{n} \\frac{\\partial}{\\partial \\alpha} (y_i - \\alpha - \\beta x_i)^2 = \\sum_{i=1}^{n} 2(y_i - \\alpha - \\beta x_i)(-1) = -2 \\sum_{i=1}^{n} (y_i - \\alpha - \\beta x_i)$$\nSetting $\\frac{\\partial S}{\\partial \\alpha} = 0$ gives the first normal equation:\n$$\\sum_{i=1}^{n} (y_i - \\alpha - \\beta x_i) = 0 \\implies \\sum y_i - n\\alpha - \\beta\\sum x_i = 0 \\implies n\\alpha + \\beta\\sum x_i = \\sum y_i$$\n\nThe partial derivative with respect to $\\beta$ is:\n$$\\frac{\\partial S}{\\partial \\beta} = \\sum_{i=1}^{n} \\frac{\\partial}{\\partial \\beta} (y_i - \\alpha - \\beta x_i)^2 = \\sum_{i=1}^{n} 2(y_i - \\alpha - \\beta x_i)(-x_i) = -2 \\sum_{i=1}^{n} x_i(y_i - \\alpha - \\beta x_i)$$\nSetting $\\frac{\\partial S}{\\partial \\beta} = 0$ gives the second normal equation:\n$$\\sum_{i=1}^{n} x_i(y_i - \\alpha - \\beta x_i) = 0 \\implies \\sum x_i y_i - \\alpha\\sum x_i - \\beta\\sum x_i^2 = 0 \\implies \\alpha\\sum x_i + \\beta\\sum x_i^2 = \\sum x_i y_i$$\n\nThe problem is now reduced to solving this system of two linear equations for $\\alpha$ and $\\beta$. The standard closed-form solutions for $\\alpha$ and $\\beta$ are:\n$$\\beta = \\frac{n \\sum_{i=1}^{n} x_i y_i - (\\sum_{i=1}^{n} x_i)(\\sum_{i=1}^{n} y_i)}{n \\sum_{i=1}^{n} x_i^2 - (\\sum_{i=1}^{n} x_i)^2}$$\n$$\\alpha = \\bar{y} - \\beta \\bar{x}$$\nwhere $\\bar{x} = \\frac{1}{n}\\sum_{i=1}^{n} x_i$ and $\\bar{y} = \\frac{1}{n}\\sum_{i=1}^{n} y_i$ are the sample means.\n\nFirst, we calculate the necessary sums from the given data points:\n$(x_1, y_1) = (10, 10.9)$, $(x_2, y_2) = (20, 20.5)$, $(x_3, y_3) = (30, 31.1)$, $(x_4, y_4) = (40, 41.7)$, $(x_5, y_5) = (50, 51.3)$.\nThe number of data points is $n=5$.\n\n1.  Sum of $x_i$: $\\sum x_i = 10 + 20 + 30 + 40 + 50 = 150$.\n2.  Sum of $y_i$: $\\sum y_i = 10.9 + 20.5 + 31.1 + 41.7 + 51.3 = 155.5$.\n3.  Sum of squares of $x_i$: $\\sum x_i^2 = 10^2 + 20^2 + 30^2 + 40^2 + 50^2 = 100 + 400 + 900 + 1600 + 2500 = 5500$.\n4.  Sum of products $x_i y_i$: $\\sum x_i y_i = (10)(10.9) + (20)(20.5) + (30)(31.1) + (40)(41.7) + (50)(51.3)$.\n    $\\sum x_i y_i = 109 + 410 + 933 + 1668 + 2565 = 5685$.\n\nNow we substitute these values into the formula for the slope, $\\beta$:\n$$\\beta = \\frac{5 \\cdot (5685) - (150)(155.5)}{5 \\cdot (5500) - (150)^2} = \\frac{28425 - 23325}{27500 - 22500} = \\frac{5100}{5000} = 1.02$$\n\nNext, we calculate the means $\\bar{x}$ and $\\bar{y}$ to find the intercept, $\\alpha$:\n$$\\bar{x} = \\frac{\\sum x_i}{n} = \\frac{150}{5} = 30$$\n$$\\bar{y} = \\frac{\\sum y_i}{n} = \\frac{155.5}{5} = 31.1$$\n\nNow, we calculate $\\alpha$:\n$$\\alpha = \\bar{y} - \\beta \\bar{x} = 31.1 - (1.02)(30) = 31.1 - 30.6 = 0.5$$\n\nThe calculated regression coefficients are $\\beta = 1.02$ and $\\alpha = 0.5$. The problem requires rounding both values to four significant figures.\n- For $\\beta = 1.02$, four significant figures gives $1.020$.\n- For $\\alpha = 0.5$, four significant figures gives $0.5000$.\n\nThe slope $\\beta = 1.020$ indicates a proportional bias of approximately $2\\%$ (since $1.020 - 1 = 0.02$). The intercept $\\alpha = 0.5000 \\, \\mathrm{mg/L}$ represents a constant positive bias of the candidate method relative to the reference method.\n\nThe final answer is to be presented as a row matrix $\\begin{pmatrix}\\beta & \\alpha\\end{pmatrix}$.",
            "answer": "$$\\boxed{\\begin{pmatrix} 1.020 & 0.5000 \\end{pmatrix}}$$"
        },
        {
            "introduction": "To meet the highest international standards for quality, such as ISO 15189, laboratories must quantify the measurement uncertainty for their assays. This exercise demonstrates how to construct a formal uncertainty budget, a process that involves identifying every significant source of variability—from calibration to sample handling—and combining them using principles from the Guide to the Expression of Uncertainty in Measurement (GUM). Completing this task will allow you to calculate the expanded uncertainty, which provides a rigorous, quantitative statement about the quality of a reported patient result .",
            "id": "5153028",
            "problem": "A clinical laboratory accredited under International Organization for Standardization 15189 (ISO 15189) is implementing a measurement uncertainty estimate for a cytokine concentration determined by Enzyme-Linked Immunosorbent Assay (ELISA). To satisfy Quality Assurance (QA), Quality Control (QC), and proficiency assessment requirements, you will construct an uncertainty budget and compute the expanded uncertainty for a single patient sample measurement.\n\nThe reporting model for the ELISA is a linear calibration of absorbance on concentration. The measurand (reported concentration) is defined by the functional relationship\n$$\nC = \\frac{D\\,(A - b)}{m},\n$$\nwhere $C$ is the concentration in $\\mathrm{ng\\,mL^{-1}}$, $A$ is the mean sample absorbance, $m$ is the calibration slope (absorbance per $\\mathrm{ng\\,mL^{-1}}$), $b$ is the calibration intercept (absorbance), and $D$ is the dilution factor of the prepared specimen. The following empirically established inputs and their associated uncertainties are available from the laboratory’s method validation and instrument specifications. Use only these inputs and no others.\n\n- Sample mean absorbance: $A = 1.250$ from $n = 6$ wells with within-plate standard deviation $s_{A} = 0.010$. Treat this as a Type A evaluation with degrees of freedom $\\nu_{A} = n - 1$.\n- Calibration slope: $m = 0.0300\\ \\mathrm{A}\\,(\\mathrm{ng\\,mL^{-1}})^{-1}$ with standard uncertainty $u(m) = 0.0007\\ \\mathrm{A}\\,(\\mathrm{ng\\,mL^{-1}})^{-1}$ obtained from a linear regression; degrees of freedom $\\nu_{m} = 4$.\n- Calibration intercept: $b = 0.0500\\ \\mathrm{A}$ with standard uncertainty $u(b) = 0.0080\\ \\mathrm{A}$ obtained from the same regression; degrees of freedom $\\nu_{b} = 4$.\n- Dilution factor: The specimen was prepared by mixing $V_{s} = 100\\ \\mu\\mathrm{L}$ of sample with $V_{b} = 900\\ \\mu\\mathrm{L}$ of diluent to achieve a target $D = \\frac{V_{s} + V_{b}}{V_{s}}$. The pipettes used have manufacturer-stated expanded uncertainties (coverage factor $k = 2$): for $V_{s}$, $\\pm 1.0\\ \\mu\\mathrm{L}$; for $V_{b}$, $\\pm 3.0\\ \\mu\\mathrm{L}$. Treat these as Type B normal-distribution specifications with standard uncertainties $u(V_{s})$ and $u(V_{b})$ equal to the expanded uncertainties divided by $2$, and with effectively infinite degrees of freedom.\n\nTasks:\n1. Construct an uncertainty budget by identifying each input quantity $x_{i} \\in \\{A, m, b, D\\}$, its estimate, its standard uncertainty $u(x_{i})$, the corresponding sensitivity coefficient $c_{i} = \\frac{\\partial C}{\\partial x_{i}}$ evaluated at the estimates, and its variance contribution $w_{i} = \\left(c_{i}\\,u(x_{i})\\right)^{2}$.\n2. Combine the contributions according to the Guide to the Expression of Uncertainty in Measurement (GUM) to obtain the combined standard uncertainty $u_{c}(C)$.\n3. Compute the effective degrees of freedom $\\nu_{\\mathrm{eff}}$ using the Welch–Satterthwaite formula based on the $w_{i}$ and their associated degrees of freedom.\n4. Using a two-sided $95\\%$ coverage, select the coverage factor $k$ as the Student’s $t$ quantile at probability $0.975$ with $\\nu_{\\mathrm{eff}}$ degrees of freedom, and calculate the expanded uncertainty $U = k\\,u_{c}(C)$.\n\nAssume that all input quantities are uncorrelated. Express the final expanded uncertainty $U$ in $\\mathrm{ng\\,mL^{-1}}$ and round your answer to four significant figures. The final answer must be a single real number as specified.",
            "solution": "The objective is to compute the expanded uncertainty, $U$, for a cytokine concentration, $C$, determined by an Enzyme-Linked Immunosorbent Assay (ELISA). The process follows the principles outlined in the Guide to the Expression of Uncertainty in Measurement (GUM).\n\nThe measurand, $C$, is defined by the functional relationship:\n$$\nC = \\frac{D\\,(A - b)}{m}\n$$\nwhere $A$ is the mean sample absorbance, $m$ is the calibration slope, $b$ is the calibration intercept, and $D$ is the dilution factor.\n\nFirst, the nominal value of the concentration $C$ is calculated using the provided estimates for the input quantities. The dilution factor $D$ is determined by the sample volume $V_s = 100\\ \\mu\\mathrm{L}$ and diluent volume $V_b = 900\\ \\mu\\mathrm{L}$:\n$$\nD = \\frac{V_s + V_b}{V_s} = \\frac{100\\ \\mu\\mathrm{L} + 900\\ \\mu\\mathrm{L}}{100\\ \\mu\\mathrm{L}} = \\frac{1000}{100} = 10\n$$\nWith $A = 1.250$, $b = 0.0500$, $m = 0.0300$, and $D=10$, the concentration is:\n$$\nC = \\frac{10 \\times (1.250 - 0.0500)}{0.0300} = \\frac{10 \\times 1.200}{0.0300} = \\frac{12}{0.0300} = 400\\ \\mathrm{ng\\,mL^{-1}}\n$$\n\nNext, we evaluate the standard uncertainty $u(x_i)$ and degrees of freedom $\\nu_i$ for each input quantity $x_i \\in \\{A, m, b, D\\}$.\n\n1.  **Mean Absorbance, $A$**:\n    -   Value: $A = 1.250$.\n    -   The standard uncertainty is the standard error of the mean of $n=6$ measurements with standard deviation $s_A = 0.010$.\n    $$\n    u(A) = \\frac{s_A}{\\sqrt{n}} = \\frac{0.010}{\\sqrt{6}}\n    $$\n    -   The degrees of freedom for this Type A evaluation are $\\nu_A = n - 1 = 6 - 1 = 5$.\n\n2.  **Calibration Slope, $m$**:\n    -   Value: $m = 0.0300$.\n    -   Standard uncertainty: $u(m) = 0.0007$.\n    -   Degrees of freedom: $\\nu_m = 4$.\n\n3.  **Calibration Intercept, $b$**:\n    -   Value: $b = 0.0500$.\n    -   Standard uncertainty: $u(b) = 0.0080$.\n    -   Degrees of freedom: $\\nu_b = 4$.\n\n4.  **Dilution Factor, $D$**:\n    -   Value: $D = 10$.\n    -   The uncertainty of $D$ is propagated from the uncertainties of the pipetted volumes, $V_s$ and $V_b$. The functional relationship is $D = 1 + V_b/V_s$.\n    -   The standard uncertainties for the volumes are derived from the expanded uncertainties ($U(V_s) = 1.0\\ \\mu\\mathrm{L}$, $U(V_b) = 3.0\\ \\mu\\mathrm{L}$) and coverage factor $k=2$:\n        $$\n        u(V_s) = \\frac{U(V_s)}{k} = \\frac{1.0\\ \\mu\\mathrm{L}}{2} = 0.5\\ \\mu\\mathrm{L}\n        $$\n        $$\n        u(V_b) = \\frac{U(V_b)}{k} = \\frac{3.0\\ \\mu\\mathrm{L}}{2} = 1.5\\ \\mu\\mathrm{L}\n        $$\n    -   The combined variance for $D$ is $u^2(D) = \\left(\\frac{\\partial D}{\\partial V_s}\\right)^2 u^2(V_s) + \\left(\\frac{\\partial D}{\\partial V_b}\\right)^2 u^2(V_b)$, assuming $V_s$ and $V_b$ are uncorrelated.\n    -   The sensitivity coefficients are:\n        $$\n        \\frac{\\partial D}{\\partial V_s} = -\\frac{V_b}{V_s^2} = -\\frac{900}{(100)^2} = -0.09\n        $$\n        $$\n        \\frac{\\partial D}{\\partial V_b} = \\frac{1}{V_s} = \\frac{1}{100} = 0.01\n        $$\n    -   The combined variance is:\n        $$\n        u^2(D) = (-0.09)^2 (0.5)^2 + (0.01)^2 (1.5)^2 = 0.0081 \\times 0.25 + 0.0001 \\times 2.25 = 0.002025 + 0.000225 = 0.00225\n        $$\n    -   The standard uncertainty is $u(D) = \\sqrt{0.00225}$.\n    -   Since the uncertainties for $V_s$ and $V_b$ are Type B with effectively infinite degrees of freedom, the resulting degrees of freedom for $D$ are also infinite, $\\nu_D = \\infty$.\n\nNow, we construct the uncertainty budget for $C$. This requires the sensitivity coefficients $c_i = \\frac{\\partial C}{\\partial x_i}$ evaluated at the nominal values of the inputs.\n$$\nc_A = \\frac{\\partial C}{\\partial A} = \\frac{D}{m} = \\frac{10}{0.0300} = \\frac{1000}{3}\n$$\n$$\nc_m = \\frac{\\partial C}{\\partial m} = -\\frac{D(A-b)}{m^2} = -\\frac{C}{m} = -\\frac{400}{0.0300} = -\\frac{40000}{3}\n$$\n$$\nc_b = \\frac{\\partial C}{\\partial b} = -\\frac{D}{m} = -\\frac{10}{0.0300} = -\\frac{1000}{3}\n$$\n$$\nc_D = \\frac{\\partial C}{\\partial D} = \\frac{A-b}{m} = \\frac{C}{D} = \\frac{400}{10} = 40\n$$\nThe variance contribution of each input is $w_i = (c_i u(x_i))^2$.\n$$\nw_A = \\left(\\frac{1000}{3} \\times \\frac{0.010}{\\sqrt{6}}\\right)^2 = \\left(\\frac{10}{3\\sqrt{6}}\\right)^2 = \\frac{100}{54} = \\frac{50}{27} \\approx 1.8519\n$$\n$$\nw_m = \\left(-\\frac{40000}{3} \\times 0.0007\\right)^2 = \\left(-\\frac{28}{3}\\right)^2 = \\frac{784}{9} \\approx 87.1111\n$$\n$$\nw_b = \\left(-\\frac{1000}{3} \\times 0.0080\\right)^2 = \\left(-\\frac{8}{3}\\right)^2 = \\frac{64}{9} \\approx 7.1111\n$$\n$$\nw_D = (40 \\times \\sqrt{0.00225})^2 = 1600 \\times 0.00225 = 3.6\n$$\nThe combined variance $u_c^2(C)$ is the sum of these contributions, as all inputs are assumed to be uncorrelated:\n$$\nu_c^2(C) = \\sum w_i = \\frac{50}{27} + \\frac{784}{9} + \\frac{64}{9} + 3.6 \\approx 1.8519 + 87.1111 + 7.1111 + 3.6 = 99.6741\n$$\nThe combined standard uncertainty is:\n$$\nu_c(C) = \\sqrt{u_c^2(C)} \\approx \\sqrt{99.6741} \\approx 9.9837\\ \\mathrm{ng\\,mL^{-1}}\n$$\nThe effective degrees of freedom, $\\nu_{\\mathrm{eff}}$, are calculated using the Welch-Satterthwaite formula:\n$$\n\\nu_{\\mathrm{eff}} = \\frac{u_c^4(C)}{\\sum_{i=1}^{N} \\frac{w_i^2}{\\nu_i}} = \\frac{(99.6741)^2}{\\frac{(1.8519)^2}{5} + \\frac{(87.1111)^2}{4} + \\frac{(7.1111)^2}{4} + \\frac{(3.6)^2}{\\infty}}\n$$\n$$\n\\nu_{\\mathrm{eff}} \\approx \\frac{9934.92}{ \\frac{3.4295}{5} + \\frac{7588.34}{4} + \\frac{50.5678}{4} + 0} \\approx \\frac{9934.92}{0.6859 + 1897.085 + 12.64195} \\approx \\frac{9934.92}{1910.41285} \\approx 5.2003\n$$\nFor a $95\\%$ confidence interval, the coverage factor $k$ is the Student's $t$-quantile for a probability of $0.975$ with $\\nu_{\\mathrm{eff}} \\approx 5.2003$ degrees of freedom. Interpolating standard tables or using statistical software yields:\n$$\nk = t_{0.975}(5.2003) \\approx 2.5463\n$$\nFinally, the expanded uncertainty $U$ is:\n$$\nU = k \\cdot u_c(C) \\approx 2.5463 \\times 9.9837 \\approx 25.4216\\ \\mathrm{ng\\,mL^{-1}}\n$$\nRounding to four significant figures as requested, the expanded uncertainty is $25.42\\ \\mathrm{ng\\,mL^{-1}}$.",
            "answer": "$$\n\\boxed{25.42}\n$$"
        },
        {
            "introduction": "Interpreting daily Quality Control (QC) signals requires more than just noting a rule violation; it requires diagnostic reasoning. This advanced practice introduces a powerful probabilistic approach using Bayes' theorem to interpret QC data. You will learn to update your belief about the true state of an assay by calculating the posterior probability of a systematic error, given a specific pattern of QC rule violations, transforming raw data into an actionable, evidence-based decision .",
            "id": "5153011",
            "problem": "A clinical laboratory operates an automated immunoassay analyzer performing a high-sensitivity Thyroid Stimulating Hormone (TSH) assay. The laboratory’s Quality Assurance (QA) program uses a Westgard multi-rule scheme to interpret daily Quality Control (QC) data, and its proficiency assessment program has characterized the analyzer’s reliability over time. Consider a binary latent state $S \\in \\{0,1\\}$, where $S=1$ denotes that a sustained positive bias of $+2$ standard deviations has been present throughout a two-run period (a clinically significant assay shift), and $S=0$ denotes no such sustained shift.\n\nFrom longitudinal Internal Quality Control (IQC) characterization and External Quality Assessment (EQA) outcomes, the laboratory has established the following:\n\n- Prior probability of a sustained $+2$ standard deviation shift over the two-run period: $\\Pr(S=1) = 0.001$ and $\\Pr(S=0) = 1 - 0.001$.\n- Per-run probabilities for three Westgard rule violations under $S=0$ (in-control):\n  - One $1_{3s}$ violation indicator $A$: $\\Pr(A=1 \\mid S=0) = 0.0027$.\n  - One $2_{2s}$ violation indicator $B$: $\\Pr(B=1 \\mid S=0) = 0.00104$.\n  - One $R_{4s}$ violation indicator $C$: $\\Pr(C=1 \\mid S=0) = 0.00104$.\n- Per-run probabilities for the same rule violations under $S=1$ (sustained $+2$ standard deviation shift):\n  - $\\Pr(A=1 \\mid S=1) = 0.1587$.\n  - $\\Pr(B=1 \\mid S=1) = 0.25$.\n  - $\\Pr(C=1 \\mid S=1) = 0.00104$.\n\nAssume the following measurement model consistent with quality system practice:\n- The shift state $S$ persists (if present) over both consecutive daily runs.\n- Conditional on $S$, violation indicators for different rules within the same run and across runs are independent and identically distributed according to the probabilities specified above.\n\nOver two consecutive daily runs, the laboratory observed this pattern of rule outcomes:\n- Run $1$: $A=1$, $B=0$, $C=0$.\n- Run $2$: $A=0$, $B=1$, $C=1$.\n\nUsing Bayes’ theorem and the independence model stated, compute the posterior probability $\\Pr(S=1 \\mid \\text{data})$ that a sustained assay shift is present given the observed QC rule violations. Express your answer as a decimal. Round your answer to four significant figures. Based on the quality plan, immediate escalation (holding all patient testing and initiating full recalibration) is required when $\\Pr(S=1 \\mid \\text{data}) \\ge \\tau$ with $\\tau = 0.25$; you may comment on this decision in your reasoning, but the numerical answer requested is only $\\Pr(S=1 \\mid \\text{data})$.",
            "solution": "The objective is to compute the posterior probability of a sustained assay shift, $\\Pr(S=1 \\mid \\text{data})$, given the observed Quality Control (QC) data from two consecutive runs. This is a direct application of Bayes' theorem.\n\nLet $S$ be the latent state variable, where $S=1$ indicates a sustained shift and $S=0$ indicates an in-control state.\nThe observed data, $D$, consists of the outcomes from two runs.\nLet $D_1$ represent the data from run 1: one $1_{3s}$ violation ($A_1=1$), no $2_{2s}$ violation ($B_1=0$), and no $R_{4s}$ violation ($C_1=0$).\nLet $D_2$ represent the data from run 2: no $1_{3s}$ violation ($A_2=0$), one $2_{2s}$ violation ($B_2=1$), and one $R_{4s}$ violation ($C_2=1$).\nThus, the total data is $D = \\{D_1, D_2\\} = \\{A_1=1, B_1=0, C_1=0, A_2=0, B_2=1, C_2=1\\}$.\n\nBayes' theorem states:\n$$ \\Pr(S=1 \\mid D) = \\frac{\\Pr(D \\mid S=1) \\Pr(S=1)}{\\Pr(D)} $$\nThe denominator, $\\Pr(D)$, is the total probability of observing the data, which can be expanded using the law of total probability:\n$$ \\Pr(D) = \\Pr(D \\mid S=1) \\Pr(S=1) + \\Pr(D \\mid S=0) \\Pr(S=0) $$\nSubstituting this into Bayes' theorem gives:\n$$ \\Pr(S=1 \\mid D) = \\frac{\\Pr(D \\mid S=1) \\Pr(S=1)}{\\Pr(D \\mid S=1) \\Pr(S=1) + \\Pr(D \\mid S=0) \\Pr(S=0)} $$\n\nThe problem states that, conditional on the state $S$, the QC rule violations are independent across runs and within runs. This allows us to calculate the likelihoods $\\Pr(D \\mid S=1)$ and $\\Pr(D \\mid S=0)$.\n\nFirst, we calculate the likelihood of the data given a sustained shift, $\\Pr(D \\mid S=1)$, which we denote $L_1$:\n$$ L_1 = \\Pr(D \\mid S=1) = \\Pr(D_1 \\mid S=1) \\times \\Pr(D_2 \\mid S=1) $$\n$$ L_1 = \\left[ \\Pr(A_1=1 \\mid S=1) \\Pr(B_1=0 \\mid S=1) \\Pr(C_1=0 \\mid S=1) \\right] \\times \\left[ \\Pr(A_2=0 \\mid S=1) \\Pr(B_2=1 \\mid S=1) \\Pr(C_2=1 \\mid S=1) \\right] $$\nWe use the provided probabilities and note that $\\Pr(\\text{event}=0 \\mid S) = 1 - \\Pr(\\text{event}=1 \\mid S)$.\nThe probabilities for $S=1$ are:\n- $\\Pr(A=1 \\mid S=1) = 0.1587 \\implies \\Pr(A=0 \\mid S=1) = 1 - 0.1587 = 0.8413$\n- $\\Pr(B=1 \\mid S=1) = 0.25 \\implies \\Pr(B=0 \\mid S=1) = 1 - 0.25 = 0.75$\n- $\\Pr(C=1 \\mid S=1) = 0.00104 \\implies \\Pr(C=0 \\mid S=1) = 1 - 0.00104 = 0.99896$\n\nSubstituting these values into the expression for $L_1$:\n$$ L_1 = (0.1587 \\times 0.75 \\times 0.99896) \\times (0.8413 \\times 0.25 \\times 0.00104) $$\n$$ L_1 \\approx (0.11889813) \\times (0.000218738) \\approx 2.600904 \\times 10^{-5} $$\n\nNext, we calculate the likelihood of the data given the in-control state, $\\Pr(D \\mid S=0)$, which we denote $L_0$:\n$$ L_0 = \\Pr(D \\mid S=0) = \\Pr(D_1 \\mid S=0) \\times \\Pr(D_2 \\mid S=0) $$\n$$ L_0 = \\left[ \\Pr(A_1=1 \\mid S=0) \\Pr(B_1=0 \\mid S=0) \\Pr(C_1=0 \\mid S=0) \\right] \\times \\left[ \\Pr(A_2=0 \\mid S=0) \\Pr(B_2=1 \\mid S=0) \\Pr(C_2=1 \\mid S=0) \\right] $$\nThe probabilities for $S=0$ are:\n- $\\Pr(A=1 \\mid S=0) = 0.0027 \\implies \\Pr(A=0 \\mid S=0) = 1 - 0.0027 = 0.9973$\n- $\\Pr(B=1 \\mid S=0) = 0.00104 \\implies \\Pr(B=0 \\mid S=0) = 1 - 0.00104 = 0.99896$\n- $\\Pr(C=1 \\mid S=0) = 0.00104 \\implies \\Pr(C=0 \\mid S=0) = 1 - 0.00104 = 0.99896$\n\nSubstituting these values into the expression for $L_0$:\n$$ L_0 = (0.0027 \\times 0.99896 \\times 0.99896) \\times (0.9973 \\times 0.00104 \\times 0.00104) $$\n$$ L_0 \\approx (0.002694406) \\times (1.07910184 \\times 10^{-6}) \\approx 2.90760 \\times 10^{-9} $$\n\nWe are given the prior probabilities:\n- $\\Pr(S=1) = 0.001$\n- $\\Pr(S=0) = 1 - 0.001 = 0.999$\n\nNow we can compute the terms for Bayes' theorem:\nThe numerator is $\\Pr(D \\mid S=1) \\Pr(S=1) = L_1 \\times \\Pr(S=1)$:\n$$ L_1 \\Pr(S=1) = (2.600904 \\times 10^{-5}) \\times 0.001 = 2.600904 \\times 10^{-8} $$\nThe second term in the denominator is $\\Pr(D \\mid S=0) \\Pr(S=0) = L_0 \\times \\Pr(S=0)$:\n$$ L_0 \\Pr(S=0) = (2.90760 \\times 10^{-9}) \\times 0.999 = 2.9046924 \\times 10^{-9} $$\nThe total denominator is the sum of these two terms:\n$$ \\Pr(D) = (2.600904 \\times 10^{-8}) + (2.9046924 \\times 10^{-9}) = 2.89137324 \\times 10^{-8} $$\nFinally, we compute the posterior probability:\n$$ \\Pr(S=1 \\mid D) = \\frac{2.600904 \\times 10^{-8}}{2.89137324 \\times 10^{-8}} \\approx 0.8995537 $$\n\nThe problem asks to round the answer to four significant figures.\n$$ \\Pr(S=1 \\mid D) \\approx 0.8996 $$\nThis posterior probability of approximately $90\\%$ is significantly higher than the initial prior probability of $0.1\\%$. The observed QC violations provide strong evidence in favor of the hypothesis that a sustained shift has occurred.\nThe quality plan requires escalation if this probability is greater than or equal to a threshold $\\tau = 0.25$. Since $0.8996 > 0.25$, the observed data strongly justifies holding patient results and initiating a full recalibration of the analyzer, as per the laboratory's protocol.",
            "answer": "$$\n\\boxed{0.8996}\n$$"
        }
    ]
}