{
    "hands_on_practices": [
        {
            "introduction": "The raw data from a melt curve experiment shows fluorescence as a smooth, decreasing function of temperature, which can make the precise point of melting difficult to identify. To accentuate the transition, we analyze the negative first derivative of this curve, $-dF/dT$, which transforms the broad melting transition into a distinct peak whose maximum corresponds to the melting temperature, $T_m$. This first practice guides you through the fundamental numerical method of calculating this derivative from discrete data points, revealing how the characteristic peaks used for specificity assessment are generated .",
            "id": "5131554",
            "problem": "In a dye-based melt curve acquired during real-time polymerase chain reaction (qPCR), the fluorescence signal $F(T)$ decreases as temperature $T$ increases due to loss of double-stranded DNA binding sites for the intercalating dye. Specificity assessment commonly uses the derivative melt curve, where the quantity $-dF/dT$ accentuates transitions and facilitates identification of distinct melting domains associated with specific amplicons. Starting from the definition of the derivative $dF/dT$ as the limit of difference quotients and invoking the Taylor series expansion of $F(T)$ about a temperature $T_{0}$, derive a symmetric finite-difference approximation that uses equally spaced temperatures around $T_{0}$ to estimate $-dF/dT$ with leading error controlled by odd-order terms canceled by symmetry. Then apply your derived expression to the following experimentally observed fluorescence values near a candidate melting transition:\n$F(74.0\\,^{\\circ}\\mathrm{C})=0.92$, $F(74.2\\,^{\\circ}\\mathrm{C})=0.88$, $F(74.4\\,^{\\circ}\\mathrm{C})=0.82$, $F(74.6\\,^{\\circ}\\mathrm{C})=0.73$ (arbitrary units).\nUse $T_{0}=74.4\\,^{\\circ}\\mathrm{C}$ and equal step size $h=0.2\\,^{\\circ}\\mathrm{C}$, and compute the finite-difference approximation to $-dF/dT$ at $T_{0}$ by employing only the immediate neighbors at $T_{0}\\pm h$. Express your final numerical value in arbitrary units per degree Celsius (a.u./$^{\\circ}\\mathrm{C}$). Round your answer to three significant figures. Do not include units in your final boxed answer.",
            "solution": "The problem requires the derivation of a symmetric finite-difference approximation for the first derivative of a function and its subsequent application to experimental melt curve data. The process will be undertaken in two parts: first, the theoretical derivation from first principles using Taylor series, and second, the numerical calculation using the provided data.\n\n### Part 1: Derivation of the Symmetric Finite-Difference Approximation\n\nThe quantity of interest is the negative of the first derivative of the fluorescence signal $F(T)$ with respect to temperature $T$, evaluated at a specific temperature $T_0$. This quantity is denoted as $-\\frac{dF}{dT}\\Big|_{T=T_0}$.\n\nWe begin by considering the Taylor series expansion of the function $F(T)$ around the point $T_0$. The expansions for $F(T)$ at points $T_0+h$ and $T_0-h$, where $h$ is a small, positive temperature step, are given by:\n$$F(T_0+h) = F(T_0) + h F'(T_0) + \\frac{h^2}{2!}F''(T_0) + \\frac{h^3}{3!}F'''(T_0) + \\frac{h^4}{4!}F^{(4)}(T_0) + \\dots$$\n$$F(T_0-h) = F(T_0) - h F'(T_0) + \\frac{h^2}{2!}F''(T_0) - \\frac{h^3}{3!}F'''(T_0) + \\frac{h^4}{4!}F^{(4)}(T_0) - \\dots$$\nwhere $F'(T_0)$, $F''(T_0)$, etc., represent the first, second, and higher-order derivatives of $F(T)$ evaluated at $T=T_0$.\n\nTo construct an approximation for the first derivative, $F'(T_0)$, we seek a combination of these two equations that isolates the term containing $F'(T_0)$. Subtracting the second expansion from the first provides such a combination:\n$$F(T_0+h) - F(T_0-h) = \\left(F(T_0) + hF'(T_0) + \\frac{h^2}{2}F''(T_0) + \\frac{h^3}{6}F'''(T_0) + \\dots\\right) - \\left(F(T_0) - hF'(T_0) + \\frac{h^2}{2}F''(T_0) - \\frac{h^3}{6}F'''(T_0) + \\dots\\right)$$\nUpon subtraction, the terms with even powers of $h$, which correspond to the function value $F(T_0)$ and its even-order derivatives ($F''(T_0)$, $F^{(4)}(T_0)$, etc.), cancel out:\n$$F(T_0+h) - F(T_0-h) = 2hF'(T_0) + 2\\frac{h^3}{6}F'''(T_0) + 2\\frac{h^5}{120}F^{(5)}(T_0) + \\dots$$\n$$F(T_0+h) - F(T_0-h) = 2hF'(T_0) + \\frac{h^3}{3}F'''(T_0) + O(h^5)$$\nThis construction is symmetric because it uses function values at equally spaced points, $T_0 \\pm h$, around the point of interest $T_0$.\n\nTo find an expression for $F'(T_0)$, we rearrange the equation:\n$$2hF'(T_0) = F(T_0+h) - F(T_0-h) - \\frac{h^3}{3}F'''(T_0) - O(h^5)$$\n$$F'(T_0) = \\frac{F(T_0+h) - F(T_0-h)}{2h} - \\frac{h^2}{6}F'''(T_0) - O(h^4)$$\nThe finite-difference approximation is obtained by truncating this series. The first term on the right-hand side provides the approximation, and the subsequent terms describe the truncation error.\n$$F'(T_0) \\approx \\frac{F(T_0+h) - F(T_0-h)}{2h}$$\nThis is the central difference formula for the first derivative. The leading error term is $-\\frac{h^2}{6}F'''(T_0)$. The error is of order $h^2$, written as $O(h^2)$. The cancellation of the $O(h)$ error term, which would be present in a non-symmetric (forward or backward) difference formula, is a direct consequence of the symmetry of the chosen points. The problem's phrasing \"odd-order terms canceled by symmetry\" refers to the fact that the error in this approximation, when expressed as a power series in $h$, contains only even powers of $h$: $E(h) = c_2 h^2 + c_4 h^4 + \\dots$.\n\nThe problem specifically asks for an approximation of $-dF/dT = -F'(T_0)$. Therefore, we have:\n$$-F'(T_0) \\approx -\\left(\\frac{F(T_0+h) - F(T_0-h)}{2h}\\right) = \\frac{F(T_0-h) - F(T_0+h)}{2h}$$\nThis is the derived symmetric finite-difference approximation.\n\n### Part 2: Application to Experimental Data\n\nWe are now tasked with applying this formula to the provided experimental data. The parameters for the calculation are:\n- Central temperature: $T_0 = 74.4\\,^{\\circ}\\mathrm{C}$\n- Temperature step size: $h = 0.2\\,^{\\circ}\\mathrm{C}$\n\nWe need the fluorescence values at the temperatures $T_0-h$ and $T_0+h$.\n- $T_0 - h = 74.4 - 0.2 = 74.2 \\,^{\\circ}\\mathrm{C}$\n- $T_0 + h = 74.4 + 0.2 = 74.6 \\,^{\\circ}\\mathrm{C}$\n\nFrom the provided data set, we extract the corresponding fluorescence values:\n- $F(T_0 - h) = F(74.2\\,^{\\circ}\\mathrm{C}) = 0.88$ (arbitrary units)\n- $F(T_0 + h) = F(74.6\\,^{\\circ}\\mathrm{C}) = 0.73$ (arbitrary units)\n\nNote that the other data points, $F(74.0\\,^{\\circ}\\mathrm{C})=0.92$ and $F(74.4\\,^{\\circ}\\mathrm{C})=0.82$, are not required for this specific calculation, as per the instruction to use only the immediate neighbors at $T_0 \\pm h$.\n\nSubstituting the numerical values into our derived approximation:\n$$-\\frac{dF}{dT}\\bigg|_{T_0=74.4} \\approx \\frac{F(74.2) - F(74.6)}{2 \\times 0.2}$$\n$$-\\frac{dF}{dT}\\bigg|_{T_0=74.4} \\approx \\frac{0.88 - 0.73}{0.4}$$\n$$-\\frac{dF}{dT}\\bigg|_{T_0=74.4} \\approx \\frac{0.15}{0.4}$$\nPerforming the division:\n$$-\\frac{dF}{dT}\\bigg|_{T_0=74.4} \\approx 0.375$$\nThe units of this result are the units of fluorescence divided by the units of temperature, which is a.u./$^{\\circ}\\mathrm{C}$.\n\nThe problem requires the final answer to be rounded to three significant figures. The calculated value of $0.375$ already has three significant figures.",
            "answer": "$$\\boxed{0.375}$$"
        },
        {
            "introduction": "Once a derivative melt curve is generated, the crucial next step is interpretation. In an ideal specific assay, we expect to see a single, sharp peak at a validated melting temperature. This practice presents a common and important diagnostic challenge: a melt curve displaying two distinct peaks. By analyzing this hypothetical scenario, you will apply your knowledge of the molecular factors governing $T_m$ to infer the likely identity of each peak and make a defensible judgment about the assay's specificity, a core skill for any molecular diagnostician .",
            "id": "5131524",
            "problem": "A clinical quantitative Polymerase Chain Reaction (qPCR) assay for pathogen nucleic acid detection uses an intercalating dye and post-amplification melt curve analysis to assess product specificity. The laboratory has previously validated that the intended amplicon, under the current buffer conditions and instrument ramp profile, exhibits a characteristic melt temperature window of $82.0 \\pm 0.3\\,^\\circ\\mathrm{C}$ at the tested template concentration range. In a new run, the instrument reports two peaks in the first derivative melt curve ($-dF/dT$) located at $75.5\\,^\\circ\\mathrm{C}$ and $82.1\\,^\\circ\\mathrm{C}$. Assuming well-calibrated temperature control and typical qPCR amplicon lengths ($\\approx 70$–$200$ base pairs), choose the most defensible inference regarding the likely identities of the two peaks and the implications for assay specificity in a molecular and immunodiagnostics context.\n\nA. The $82.1\\,^\\circ\\mathrm{C}$ peak corresponds to the intended target amplicon, while the $75.5\\,^\\circ\\mathrm{C}$ peak reflects a primer–dimer or nonspecific, shorter, adenine–thymine rich amplicon; the coexistence of these peaks indicates co-amplification and compromised specificity, warranting assay optimization before clinical reporting.\n\nB. Both peaks arise from the same specific amplicon undergoing biphasic domain melting caused by terminal guanine–cytosine clamps, so specificity remains acceptable and no optimization is necessary.\n\nC. The $75.5\\,^\\circ\\mathrm{C}$ peak is the true target because lower melt temperatures indicate efficient primer binding, whereas the $82.1\\,^\\circ\\mathrm{C}$ peak is a dye artifact; specificity is acceptable.\n\nD. The $82.1\\,^\\circ\\mathrm{C}$ peak is the target and the $75.5\\,^\\circ\\mathrm{C}$ peak is instrument noise unrelated to DNA melting; specificity is acceptable without further action.",
            "solution": "The problem statement is first validated to ensure it is scientifically sound, well-posed, and objective before a solution is attempted.\n\n### Step 1: Extract Givens\n- **Assay Type**: Clinical quantitative Polymerase Chain Reaction (qPCR) for pathogen nucleic acid detection.\n- **Detection Method**: Intercalating dye.\n- **Specificity Assessment**: Post-amplification melt curve analysis.\n- **Validated Target Amplicon Melt Temperature ($T_m$)**: The characteristic melt temperature window is $82.0 \\pm 0.3\\,^\\circ\\mathrm{C}$ under the specified conditions. This corresponds to a range of [$81.7\\,^\\circ\\mathrm{C}$, $82.3\\,^\\circ\\mathrm{C}$].\n- **New Run Data**: The instrument reports two peaks in the first derivative melt curve ($-dF/dT$).\n- **Peak Locations**: $75.5\\,^\\circ\\mathrm{C}$ and $82.1\\,^\\circ\\mathrm{C}$.\n- **Assumptions**:\n    1. Well-calibrated instrument temperature control.\n    2. Typical qPCR amplicon lengths, approximately $70$ to $200$ base pairs.\n- **Question**: Infer the likely identities of the two peaks and the implications for assay specificity.\n\n### Step 2: Validate Using Extracted Givens\n- **Scientific Grounding**: The problem is firmly based on established principles of molecular diagnostics, specifically qPCR and high-resolution melt (HRM) or melt curve analysis. The concepts of intercalating dyes (e.g., SYBR Green), melt temperature ($T_m$), the derivative plot ($-dF/dT$), and the influence of amplicon length and base composition (GC vs. AT content) on $T_m$ are all standard and fundamental to the field. The provided numerical values for $T_m$ ($82.0\\,^\\circ\\mathrm{C}$, $75.5\\,^\\circ\\mathrm{C}$, $82.1\\,^\\circ\\mathrm{C}$) and amplicon size ($70$–$200$ bp) are realistic for typical assays. The problem is scientifically sound.\n- **Well-Posedness**: The problem provides sufficient, consistent data to allow for a reasoned, expert interpretation. It asks for the \"most defensible inference,\" which is appropriate for a diagnostic scenario where data interpretation is key. A unique, meaningful conclusion can be drawn from the provided information.\n- **Objectivity**: The problem is stated using precise, unbiased, and technical language. It is free from subjective claims or ambiguity.\n\n### Step 3: Verdict and Action\nThe problem statement is **valid**. It is scientifically sound, self-contained, and well-posed. The solution process may proceed.\n\n### Principle-Based Derivation\nMelt curve analysis is a critical step for assessing the specificity of qPCR assays that use intercalating dyes. The principle rests on the thermal denaturation of double-stranded DNA (dsDNA). As the temperature increases, dsDNA melts into single-stranded DNA (ssDNA), causing the intercalating dye to be released and its fluorescence to decrease. The melt temperature, $T_m$, is the temperature at which $50\\%$ of the DNA duplexes have dissociated. This point corresponds to the maximum rate of change in fluorescence with respect to temperature, which appears as a peak in the negative first derivative plot ($-dF/dT$ vs. $T$).\n\nThe $T_m$ of a DNA molecule is primarily determined by two factors under constant buffer conditions:\n1.  **Length**: Longer amplicons have higher $T_m$ values.\n2.  **Guanine-Cytosine (GC) Content**: GC pairs are linked by three hydrogen bonds, whereas Adenine-Thymine (AT) pairs are linked by two. A higher percentage of GC content results in a more stable duplex and thus a higher $T_m$.\n\nThe problem provides two key pieces of information:\n1.  The validated $T_m$ for the intended amplicon is in the range of $81.7\\,^\\circ\\mathrm{C}$ to $82.3\\,^\\circ\\mathrm{C}$. The observed peak at $82.1\\,^\\circ\\mathrm{C}$ falls squarely within this range. This provides strong evidence that this peak represents the specific, intended target product of the PCR amplification.\n2.  A second peak is observed at a significantly lower temperature, $75.5\\,^\\circ\\mathrm{C}$. A peak in the $-dF/dT$ plot signifies the melting of a distinct population of dsDNA molecules. A lower $T_m$ indicates that this second product is less thermally stable than the intended amplicon. This lower stability is most commonly due to it being either:\n    *   **Significantly shorter**: This is the classic signature of **primer-dimers**—short artifacts formed when primers anneal to each other. Primer-dimers are typically very short (e.g., $<50$ base pairs) and consequently have a much lower $T_m$ than the target amplicon (which is $70$–$200$ bp).\n    *   **Significantly richer in AT content (lower GC content)**: This could result from nonspecific priming at a different locus on the template DNA, generating an unintended amplicon of similar length but lower GC content.\n\nThe presence of two distinct melt peaks demonstrates that the qPCR reaction has amplified at least two different products. The goal of a specific assay is to amplify *only* the intended target. The co-amplification of a second, non-target product means the assay lacks specificity. For a quantitative assay, this is a critical failure, as the total fluorescence signal (and thus the calculated quantity) is a composite of both the target and the non-specific product, leading to inaccurate quantification of the pathogen. Therefore, such a result would necessitate assay re-optimization (e.g., adjusting primer concentrations, annealing temperature, or MgCl$_2$ concentration) before it could be used for clinical reporting.\n\n### Option-by-Option Analysis\n\n**A. The $82.1\\,^\\circ\\mathrm{C}$ peak corresponds to the intended target amplicon, while the $75.5\\,^\\circ\\mathrm{C}$ peak reflects a primer–dimer or nonspecific, shorter, adenine–thymine rich amplicon; the coexistence of these peaks indicates co-amplification and compromised specificity, warranting assay optimization before clinical reporting.**\n- **Evaluation**: This statement is entirely consistent with the principles of melt curve analysis. The peak at $82.1\\,^\\circ\\mathrm{C}$ matches the validated target $T_m$. The lower peak at $75.5\\,^\\circ\\mathrm{C}$ is correctly identified as a non-specific product, with primer-dimers or AT-rich amplicons being the most likely culprits. The conclusion that this indicates compromised specificity and requires optimization is the correct and responsible course of action in a clinical diagnostic setting.\n- **Verdict**: **Correct**.\n\n**B. Both peaks arise from the same specific amplicon undergoing biphasic domain melting caused by terminal guanine–cytosine clamps, so specificity remains acceptable and no optimization is necessary.**\n- **Evaluation**: While complex amplicons with distinct high-GC and low-GC domains can sometimes produce complex or broad melt profiles, two sharp, distinct peaks separated by a large temperature difference ($82.1\\,^\\circ\\mathrm{C} - 75.5\\,^\\circ\\mathrm{C} = 6.6\\,^\\circ\\mathrm{C}$) is much more characteristic of two different products. Attributing this to \"terminal guanine-cytosine clamps\" is illogical; GC clamps are added to primers to *prevent* frayed ends and create a more uniform melting profile, not to induce a separate, low-temperature melt peak. Concluding that specificity is acceptable is a dangerous assumption that ignores strong evidence to the contrary.\n- **Verdict**: **Incorrect**.\n\n**C. The $75.5\\,^\\circ\\mathrm{C}$ peak is the true target because lower melt temperatures indicate efficient primer binding, whereas the $82.1\\,^\\circ\\mathrm{C}$ peak is a dye artifact; specificity is acceptable.**\n- **Evaluation**: This statement contains multiple fundamental errors. The $T_m$ is a property of the amplicon product, not a measure of primer binding efficiency. A lower $T_m$ means a less stable product. The problem explicitly states the validated target $T_m$ is $82.0 \\pm 0.3\\,^\\circ\\mathrm{C}$, which directly contradicts the claim that the $75.5\\,^\\circ\\mathrm{C}$ peak is the target. The peak at $82.1\\,^\\circ\\mathrm{C}$ perfectly matches the validated data and is extremely unlikely to be an artifact. The conclusion that specificity is acceptable is baseless.\n- **Verdict**: **Incorrect**.\n\n**D. The $82.1\\,^\\circ\\mathrm{C}$ peak is the target and the $75.5\\,^\\circ\\mathrm{C}$ peak is instrument noise unrelated to DNA melting; specificity is acceptable without further action.**\n- **Evaluation**: A sharp, well-defined peak in a $-dF/dT$ plot is the signature of a cooperative molecular transition (DNA melting) and is not characteristic of random instrument noise. Dismissing such a clear signal as noise is scientifically unsound. Ignoring this peak and declaring the assay specific would be negligent in a clinical context.\n- **Verdict**: **Incorrect**.",
            "answer": "$$\\boxed{A}$$"
        },
        {
            "introduction": "While qualitative interpretation is vital, a graduate-level understanding requires quantifying the uncertainty inherent in any measurement. When melt peaks from two different amplicons are close, there is a non-zero risk of misclassification due to random instrument noise. This final practice moves beyond simple observation by applying principles from statistical detection theory to formally model this risk. You will derive and calculate the Bayes-optimal misclassification probability, providing a quantitative measure of assay reliability and a deeper understanding of the factors that limit an assay's resolving power .",
            "id": "5131594",
            "problem": "In a High-Resolution Melt (HRM) analysis within a real-time Polymerase Chain Reaction (PCR) assay, two analyte-specific amplicons produce distinct melt peaks with true melting temperatures separated by $\\Delta = 0.7\\,^{\\circ}\\mathrm{C}$. Suppose the instrument imposes additive, independent, zero-mean Gaussian measurement noise on the melting temperature with standard deviation $\\sigma = 0.25\\,^{\\circ}\\mathrm{C}$ that is identical for both analytes. Assume that, conditional on the analyte identity, the measured melting temperature $T_m$ is distributed as a normal random variable with mean equal to the analyte’s true $T_m$ and variance $\\sigma^2$, and that the two analytes are equally prevalent in the tested population.\n\nA single-threshold classifier assigns a measurement to the analyte whose mean $T_m$ is closer to the observed $T_m$. Under these conditions, use first principles from detection theory and properties of the normal distribution to derive an analytic expression for the Bayes-optimal misclassification probability in terms of $\\Delta$ and $\\sigma$, and then evaluate it numerically for $\\Delta = 0.7$ and $\\sigma = 0.25$. Interpret this as the risk of misclassification due solely to instrument variability, and report it as a decimal.\n\nRound your final numerical answer to four significant figures. No units are required for the final probability.",
            "solution": "The problem presented is a classic binary hypothesis testing scenario. Let the two analytes be represented by two hypotheses, $H_1$ and $H_2$.\n\n**Model Formulation**\nLet the true, but unknown, melting temperatures of the two analytes be $\\mu_1$ and $\\mu_2$. The problem states that these are separated by $\\Delta$, so $|\\mu_2 - \\mu_1| = \\Delta$. Without loss of generality, we can center the problem by setting $\\mu_1 = -\\frac{\\Delta}{2}$ and $\\mu_2 = +\\frac{\\Delta}{2}$. The final probability of error depends only on the separation of the means, not their absolute location.\n\nThe measured temperature, $T$, is a continuous random variable. Conditional on the presence of analyte $1$ (hypothesis $H_1$) or analyte $2$ (hypothesis $H_2$), the probability density functions (PDFs) for $T$ are given by normal distributions due to the additive Gaussian noise:\n$$p(T|H_1) = \\mathcal{N}\\left(-\\frac{\\Delta}{2}, \\sigma^2\\right) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}} \\exp\\left(-\\frac{(T + \\Delta/2)^2}{2\\sigma^2}\\right)$$\n$$p(T|H_2) = \\mathcal{N}\\left(+\\frac{\\Delta}{2}, \\sigma^2\\right) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}} \\exp\\left(-\\frac{(T - \\Delta/2)^2}{2\\sigma^2}\\right)$$\n\nThe problem states the two analytes are \"equally prevalent,\" which implies their prior probabilities are equal:\n$$P(H_1) = P(H_2) = \\frac{1}{2}$$\n\n**Bayes-Optimal Classifier and Decision Rule**\nThe goal is to minimize the probability of misclassification. The classifier that achieves this is the Bayes-optimal classifier. The decision rule is to choose the hypothesis $H_k$ that has the maximum a posteriori probability, $\\max_k P(H_k|T)$. By Bayes' theorem, $P(H_k|T) = \\frac{p(T|H_k)P(H_k)}{p(T)}$. Since the denominator $p(T)$ is common to both hypotheses and the priors $P(H_k)$ are equal, maximizing the posterior is equivalent to maximizing the likelihood $p(T|H_k)$. This is the Maximum Likelihood (ML) decision rule.\n\nWe decide in favor of $H_2$ over $H_1$ if $p(T|H_2) > p(T|H_1)$. Since the natural logarithm is a strictly increasing function, this is equivalent to $\\ln(p(T|H_2)) > \\ln(p(T|H_1))$.\n$$-\\frac{(T - \\Delta/2)^2}{2\\sigma^2} > -\\frac{(T + \\Delta/2)^2}{2\\sigma^2}$$\nMultiplying by $-2\\sigma^2$ reverses the inequality:\n$$(T - \\Delta/2)^2 < (T + \\Delta/2)^2$$\n$$T^2 - T\\Delta + \\frac{\\Delta^2}{4} < T^2 + T\\Delta + \\frac{\\Delta^2}{4}$$\n$$-T\\Delta < T\\Delta$$\n$$0 < 2T\\Delta$$\nSince $\\Delta > 0$, this simplifies to $T > 0$.\n\nThus, the decision rule is to choose $H_2$ if $T > 0$ and $H_1$ if $T < 0$. The decision threshold is $\\tau = 0$. This rule is equivalent to \"assigns a measurement to the analyte whose mean $T_m$ is closer to the observed $T_m$\", as $|T - (-\\Delta/2)| < |T - (\\Delta/2)|$ simplifies to $T < 0$. This confirms the classifier given is indeed the Bayes-optimal one for this setup.\n\n**Derivation of Misclassification Probability**\nThe total probability of misclassification, or error, $P_e$, is given by the law of total probability:\n$$P_e = P(\\text{error}|H_1)P(H_1) + P(\\text{error}|H_2)P(H_2)$$\nA misclassification occurs under $H_1$ if we decide $H_2$, which happens when the measurement $T > 0$.\n$$P(\\text{error}|H_1) = P(T > 0 | H_1)$$\nA misclassification occurs under $H_2$ if we decide $H_1$, which happens when the measurement $T < 0$.\n$$P(\\text{error}|H_2) = P(T < 0 | H_2)$$\nDue to the symmetry of the problem (equal priors, same variance, symmetric threshold), these two conditional error probabilities are equal. Let's calculate $P(\\text{error}|H_1)$:\n$$P(\\text{error}|H_1) = \\int_0^{\\infty} p(T|H_1) dT = \\int_0^{\\infty} \\frac{1}{\\sqrt{2\\pi\\sigma^2}} \\exp\\left(-\\frac{(T + \\Delta/2)^2}{2\\sigma^2}\\right) dT$$\nTo evaluate this integral, we perform a change of variables to standardize the distribution. Let $Z = \\frac{T - \\mu_1}{\\sigma} = \\frac{T + \\Delta/2}{\\sigma}$. This new variable $Z$ follows the standard normal distribution, $Z \\sim \\mathcal{N}(0,1)$. When $T=0$, the lower limit of integration for $Z$ is $\\frac{0 + \\Delta/2}{\\sigma} = \\frac{\\Delta}{2\\sigma}$. As $T \\to \\infty$, $Z \\to \\infty$.\n$$P(\\text{error}|H_1) = P\\left(Z > \\frac{\\Delta}{2\\sigma}\\right)$$\nThis probability is, by definition, the complementary cumulative distribution function of the standard normal distribution, often denoted as the Q-function:\n$$Q(x) = \\frac{1}{\\sqrt{2\\pi}} \\int_x^{\\infty} \\exp\\left(-\\frac{u^2}{2}\\right) du$$\nSo, $P(\\text{error}|H_1) = P(\\text{error}|H_2) = Q\\left(\\frac{\\Delta}{2\\sigma}\\right)$.\n\nSubstituting this into the expression for the total probability of error:\n$$P_e = Q\\left(\\frac{\\Delta}{2\\sigma}\\right) \\cdot \\frac{1}{2} + Q\\left(\\frac{\\Delta}{2\\sigma}\\right) \\cdot \\frac{1}{2} = Q\\left(\\frac{\\Delta}{2\\sigma}\\right)$$\nThis is the analytic expression for the Bayes-optimal misclassification probability. An alternative, equivalent expression uses the complementary error function, $\\text{erfc}(x)$, via the relation $Q(x) = \\frac{1}{2}\\text{erfc}\\left(\\frac{x}{\\sqrt{2}}\\right)$:\n$$P_e = \\frac{1}{2}\\text{erfc}\\left(\\frac{\\Delta}{2\\sqrt{2}\\sigma}\\right)$$\n\n**Numerical Evaluation**\nWe are given $\\Delta = 0.7$ and $\\sigma = 0.25$. First, we compute the argument of the Q-function:\n$$\\frac{\\Delta}{2\\sigma} = \\frac{0.7}{2 \\times 0.25} = \\frac{0.7}{0.5} = 1.4$$\nThe misclassification probability is therefore:\n$$P_e = Q(1.4)$$\nThe Q-function is related to the standard normal cumulative distribution function (CDF), $\\Phi(z)$, by $Q(z) = 1 - \\Phi(z)$. Using standard statistical tables or a calculator for the normal distribution:\n$$\\Phi(1.4) \\approx 0.91924334$$\n$$P_e = 1 - \\Phi(1.4) \\approx 1 - 0.91924334 = 0.08075666$$\nThe problem requires rounding the final numerical answer to four significant figures.\n$$P_e \\approx 0.08076$$\nThis value represents the irreducible probability of misidentifying an analyte based solely on its measured melting temperature, given the inherent noise level of the instrument and the proximity of the true melting temperatures. It is the theoretical lower bound on the error rate for any single-threshold classifier under these conditions.",
            "answer": "$$\n\\boxed{0.08076}\n$$"
        }
    ]
}