{
    "hands_on_practices": [
        {
            "introduction": "A fundamental challenge in functional profiling is that raw read counts from sequencing data can be misleading. A long gene or functional unit will naturally accumulate more reads than a short one, even if their true expression levels are identical. This exercise  guides you through the calculation of Transcripts Per Million (TPM), a standard normalization technique that corrects for both feature length and library size. By mastering this practice, you will learn to transform raw counts into a more accurate and comparable measure of relative functional abundance.",
            "id": "4565555",
            "problem": "A metatranscriptomic dataset from a human gut microbiome was profiled for functional abundance using KEGG Orthology (KO) features. Short reads were quality-filtered and aligned to four KO features with effective sequence lengths (accounting for read mappability and trimming). The following observed alignments and effective lengths were recorded for one sample:\n- KO-A: length $900$ base pairs (bp), aligned reads $360$.\n- KO-B: length $1800$ bp, aligned reads $540$.\n- KO-C: length $300$ bp, aligned reads $120$.\n- KO-D: length $1500$ bp, aligned reads $180$.\n\nAssume the standard length correction and per-million scaling used in Transcripts Per Million (TPM) normalization for functional profiling: counts must be corrected for feature length to yield a rate per kilobase, and then scaled so the sum across features equals $10^{6}$.\n\nStarting from fundamental definitions in sequencing-based quantification (that read coverage is proportional to the product of feature length and its true abundance, and that scaling produces a compositional measure), compute the TPM values for these KO features and form the TPM composition across the four features. Form the raw-count composition from the observed counts. Using the natural logarithm, quantify how length correction alters the relative abundance of functions by computing the Kullback–Leibler divergence from the TPM composition to the raw-count composition.\n\nRound your final answer to four significant figures. Express the final answer as a unitless real number.",
            "solution": "The problem is valid. It is scientifically grounded in standard bioinformatics procedures for quantifying functional abundance from sequencing data, is well-posed with all necessary information provided, and is stated objectively.\n\nThe task is to compute the Kullback-Leibler (KL) divergence from a Transcripts Per Million (TPM) normalized composition to a raw-count composition for a set of four KEGG Orthology (KO) features. Let the set of features be indexed by $i \\in \\{A, B, C, D\\}$.\n\nThe provided data are:\n- KO-A ($i=A$): raw count $C_A = 360$, length $L_A = 900$ bp.\n- KO-B ($i=B$): raw count $C_B = 540$, length $L_B = 1800$ bp.\n- KO-C ($i=C$): raw count $C_C = 120$, length $L_C = 300$ bp.\n- KO-D ($i=D$): raw count $C_D = 180$, length $L_D = 1500$ bp.\n\nFirst, we compute the raw-count composition, which we denote as the probability distribution $P = \\{p_i\\}$. This is found by dividing the count for each feature by the total number of aligned reads.\nThe total number of reads is:\n$$N = \\sum_{i \\in \\{A,B,C,D\\}} C_i = 360 + 540 + 120 + 180 = 1200$$\nThe proportions $p_i = \\frac{C_i}{N}$ are:\n$$p_A = \\frac{360}{1200} = \\frac{3}{10} = 0.30$$\n$$p_B = \\frac{540}{1200} = \\frac{9}{20} = 0.45$$\n$$p_C = \\frac{120}{1200} = \\frac{1}{10} = 0.10$$\n$$p_D = \\frac{180}{1200} = \\frac{3}{20} = 0.15$$\nThe set $P = \\{0.30, 0.45, 0.10, 0.15\\}$ forms the raw-count compositional distribution.\n\nNext, we compute the TPM composition, denoted as the probability distribution $Q = \\{q_i\\}$. The TPM calculation involves two steps: length normalization and library size scaling.\nFirst, we normalize the raw counts $C_i$ by the feature length in kilobases, $L_{i,kb} = L_i / 1000$. This gives a rate, $R_i$.\n$$L_{A,kb} = \\frac{900}{1000} = 0.9 \\, \\text{kb}$$\n$$L_{B,kb} = \\frac{1800}{1000} = 1.8 \\, \\text{kb}$$\n$$L_{C,kb} = \\frac{300}{1000} = 0.3 \\, \\text{kb}$$\n$$L_{D,kb} = \\frac{1500}{1000} = 1.5 \\, \\text{kb}$$\nThe rates $R_i = \\frac{C_i}{L_{i,kb}}$ are:\n$$R_A = \\frac{360}{0.9} = 400$$\n$$R_B = \\frac{540}{1.8} = 300$$\n$$R_C = \\frac{120}{0.3} = 400$$\n$$R_D = \\frac{180}{1.5} = 120$$\n\nSecond, these rates are scaled to sum to a constant (typically $10^6$ for TPM). The TPM composition is the relative proportion of each feature after this length normalization. The scaling constant of $10^6$ is irrelevant for the composition itself, as it cancels out. The compositional proportions $q_i$ are found by dividing each rate $R_i$ by the sum of all rates.\nThe sum of rates is:\n$$S = \\sum_{i \\in \\{A,B,C,D\\}} R_i = 400 + 300 + 400 + 120 = 1220$$\nThe proportions $q_i = \\frac{R_i}{S}$ are:\n$$q_A = \\frac{400}{1220} = \\frac{20}{61}$$\n$$q_B = \\frac{300}{1220} = \\frac{15}{61}$$\n$$q_C = \\frac{400}{1220} = \\frac{20}{61}$$\n$$q_D = \\frac{120}{1220} = \\frac{6}{61}$$\nThe set $Q = \\{\\frac{20}{61}, \\frac{15}{61}, \\frac{20}{61}, \\frac{6}{61}\\}$ forms the TPM compositional distribution.\n\nFinally, we compute the Kullback-Leibler divergence from the TPM composition ($Q$) to the raw-count composition ($P$), denoted $D_{KL}(Q || P)$, using the natural logarithm as specified.\nThe formula for KL divergence is:\n$$D_{KL}(Q || P) = \\sum_{i \\in \\{A,B,C,D\\}} q_i \\ln\\left(\\frac{q_i}{p_i}\\right)$$\nSubstituting the calculated values for $p_i$ and $q_i$:\n$$D_{KL}(Q || P) = \\frac{20}{61} \\ln\\left(\\frac{20/61}{0.30}\\right) + \\frac{15}{61} \\ln\\left(\\frac{15/61}{0.45}\\right) + \\frac{20}{61} \\ln\\left(\\frac{20/61}{0.10}\\right) + \\frac{6}{61} \\ln\\left(\\frac{6/61}{0.15}\\right)$$\n$$D_{KL}(Q || P) = \\frac{20}{61} \\ln\\left(\\frac{20/61}{3/10}\\right) + \\frac{15}{61} \\ln\\left(\\frac{15/61}{9/20}\\right) + \\frac{20}{61} \\ln\\left(\\frac{20/61}{1/10}\\right) + \\frac{6}{61} \\ln\\left(\\frac{6/61}{3/20}\\right)$$\n$$D_{KL}(Q || P) = \\frac{20}{61} \\ln\\left(\\frac{200}{183}\\right) + \\frac{15}{61} \\ln\\left(\\frac{300}{549}\\right) + \\frac{20}{61} \\ln\\left(\\frac{200}{61}\\right) + \\frac{6}{61} \\ln\\left(\\frac{120}{183}\\right)$$\nSimplifying the fractions inside the logarithms:\n$$D_{KL}(Q || P) = \\frac{20}{61} \\ln\\left(\\frac{200}{183}\\right) + \\frac{15}{61} \\ln\\left(\\frac{100}{183}\\right) + \\frac{20}{61} \\ln\\left(\\frac{200}{61}\\right) + \\frac{6}{61} \\ln\\left(\\frac{40}{61}\\right)$$\nNow we compute the numerical value:\n$$D_{KL}(Q || P) \\approx \\left(\\frac{20}{61}\\right)(0.0888358) + \\left(\\frac{15}{61}\\right)(-0.6043254) + \\left(\\frac{20}{61}\\right)(1.1874253) + \\left(\\frac{6}{61}\\right)(-0.4220261)$$\n$$D_{KL}(Q || P) \\approx (0.32786885)(0.0888358) + (0.24590164)(-0.6043254) + (0.32786885)(1.1874253) + (0.09836066)(-0.4220261)$$\n$$D_{KL}(Q || P) \\approx 0.02912977 - 0.14860721 + 0.38927907 - 0.04151121$$\n$$D_{KL}(Q || P) \\approx 0.22829042$$\nRounding the result to four significant figures gives $0.2283$. This value quantifies the information gain when revising beliefs from the raw-count proportions to the length-corrected proportions.",
            "answer": "$$\\boxed{0.2283}$$"
        },
        {
            "introduction": "Beyond quantifying individual functions, a primary goal of functional profiling is to understand how they operate collectively within metabolic pathways. This practice  provides a hands-on simulation of the logic used by advanced tools like HUMAnN to reconstruct pathway activity. You will learn to apply logical rules (AND/OR) to model biochemical dependencies, calculating pathway 'coverage' to assess completeness and pathway 'abundance' to identify potential bottlenecks, translating gene-level data into systems-level insights.",
            "id": "4565625",
            "problem": "You are given a simplified yet scientifically grounded modeling task inspired by the HMP Unified Metabolic Analysis Network (HUMAnN). The aim is to formalize the mapping from read-derived UniRef90 protein family abundances to metabolic reactions and to compute module-based pathway coverage and pathway abundance. The scenario is motivated by the Central Dogma of Molecular Biology, where genes encode protein families (enzymes) that catalyze reactions, which aggregate into modules and pathways. The goal is to derive, from first principles, a precise computational procedure for pathway coverage and abundance scoring under module-based logic.\n\nDefine a finite set of UniRef90 families $F = \\{f_1, f_2, \\dots, f_n\\}$ with non-negative abundance values $a_{f} \\in \\mathbb{R}_{\\ge 0}$ interpreted as normalized read abundance values in arbitrary units of sequencing-derived abundance. Define a finite set of reactions $R = \\{r_1, r_2, \\dots, r_m\\}$. Each reaction $r \\in R$ is associated with a non-empty set $M_r \\subseteq F$ indicating which UniRef90 families map to $r$. The abundance of a reaction $r$ is given by\n$$\nA_r = \\sum_{f \\in M_r} a_f \\, .\n$$\nGiven a non-negative threshold $t \\in \\mathbb{R}_{\\ge 0}$, define the reaction presence indicator\n$$\np_r = \\begin{cases}\n1 & \\text{if } A_r \\ge t \\\\\n0 & \\text{otherwise.}\n\\end{cases}\n$$\n\nA module is a logical expression over reactions constructed using two connectives: logical AND and logical OR. A module is either a leaf reaction $r \\in R$, or an internal node $X(\\cdot, \\cdot)$ where $X \\in \\{\\text{AND}, \\text{OR}\\}$ and its two children are modules. A pathway $P$ is an ordered list of modules $\\{m_1, m_2, \\dots, m_k\\}$.\n\nDefine two recursive functions to evaluate module coverage and module abundance:\n1. For module coverage, define $c(m)$ for a module $m$ as\n$$\nc(m) = \\begin{cases}\n1 & \\text{if } m \\text{ is a leaf reaction } r \\text{ and } p_r = 1 \\\\\n0 & \\text{if } m \\text{ is a leaf reaction } r \\text{ and } p_r = 0 \\\\\n\\min\\left(c(m_{\\text{left}}), c(m_{\\text{right}})\\right) & \\text{if } m = \\text{AND}(m_{\\text{left}}, m_{\\text{right}}) \\\\\n\\max\\left(c(m_{\\text{left}}), c(m_{\\text{right}})\\right) & \\text{if } m = \\text{OR}(m_{\\text{left}}, m_{\\text{right}})\n\\end{cases}\n$$\nwhich generalizes coverage to a continuous score in $[0,1]$ at the module level: a leaf contributes $0$ or $1$ depending on presence, AND propagates the limiting coverage by the minimum, and OR propagates the best-available coverage by the maximum.\n\n2. For module abundance, define $b(m)$ for a module $m$ as\n$$\nb(m) = \\begin{cases}\nA_r & \\text{if } m \\text{ is a leaf reaction } r \\\\\n\\min\\left(b(m_{\\text{left}}), b(m_{\\text{right}})\\right) & \\text{if } m = \\text{AND}(m_{\\text{left}}, m_{\\text{right}}) \\\\\n\\max\\left(b(m_{\\text{left}}), b(m_{\\text{right}})\\right) & \\text{if } m = \\text{OR}(m_{\\text{left}}, m_{\\text{right}})\n\\end{cases}\n$$\nwhich treats the AND operator as a bottleneck (limiting step) and the OR operator as the maximal branch. Leaf nodes contribute their reaction abundance $A_r$.\n\nDefine pathway coverage and pathway abundance by aggregating across the pathway’s modules using the bottleneck principle:\n$$\nC_P = \\min_{i \\in \\{1,\\dots,k\\}} c(m_i), \\qquad B_P = \\min_{i \\in \\{1,\\dots,k\\}} b(m_i).\n$$\nBoth $C_P$ and $B_P$ are real-valued. The pathway coverage $C_P$ is a decimal in $[0,1]$ (not a percentage), and the pathway abundance $B_P$ is in the same arbitrary unit as $A_r$.\n\nFor this problem, use the following concrete mapping and pathways:\n- Families $F = \\{\\text{U1}, \\text{U2}, \\text{U3}, \\text{U4}, \\text{U5}\\}$.\n- Reactions $R = \\{\\text{R1}, \\text{R2}, \\text{R3}, \\text{R4}, \\text{R5}, \\text{R6}\\}$ with mappings\n$$\nM_{\\text{R1}} = \\{\\text{U1}, \\text{U2}\\}, \\quad\nM_{\\text{R2}} = \\{\\text{U2}\\}, \\quad\nM_{\\text{R3}} = \\{\\text{U3}\\}, \\quad\nM_{\\text{R4}} = \\{\\text{U3}, \\text{U4}\\}, \\quad\nM_{\\text{R5}} = \\{\\text{U5}\\}, \\quad\nM_{\\text{R6}} = \\{\\text{U1}\\}.\n$$\n- Pathways:\n  - Pathway $\\text{P\\_A}$ has two modules:\n    $$\n    m_1 = \\text{AND}\\left(\\text{R1}, \\, \\text{OR}(\\text{R2}, \\text{R3})\\right), \\qquad\n    m_2 = \\text{AND}\\left(\\text{R4}, \\text{R5}\\right).\n    $$\n  - Pathway $\\text{P\\_B}$ has one module:\n    $$\n    m_3 = \\text{OR}\\left(\\text{AND}(\\text{R1}, \\text{R6}), \\, \\text{R3}\\right).\n    $$\n\nTest suite. For each test case, you are given a threshold $t$ and abundances $a_f$ for $f \\in F$. Compute $A_r$ for each reaction, then $p_r$, then $c(m)$ and $b(m)$ for each module, and finally $C_P$ and $B_P$ for $\\text{P\\_A}$ and $\\text{P\\_B}$. The test suite contains four cases:\n- Case $1$: threshold $t = 0.5$ and family abundances\n$$\na_{\\text{U1}} = 0.8,\\; a_{\\text{U2}} = 0.4,\\; a_{\\text{U3}} = 0.9,\\; a_{\\text{U4}} = 0.3,\\; a_{\\text{U5}} = 0.5.\n$$\n- Case $2$: threshold $t = 0.7$ and family abundances\n$$\na_{\\text{U1}} = 0.7,\\; a_{\\text{U2}} = 0.0,\\; a_{\\text{U3}} = 0.7,\\; a_{\\text{U4}} = 0.0,\\; a_{\\text{U5}} = 0.7.\n$$\n- Case $3$: threshold $t = 0.0$ and family abundances\n$$\na_{\\text{U1}} = 0.0,\\; a_{\\text{U2}} = 0.0,\\; a_{\\text{U3}} = 0.0,\\; a_{\\text{U4}} = 0.0,\\; a_{\\text{U5}} = 0.0.\n$$\n- Case $4$: threshold $t = 0.6$ and family abundances\n$$\na_{\\text{U1}} = 0.4,\\; a_{\\text{U2}} = 0.3,\\; a_{\\text{U3}} = 0.55,\\; a_{\\text{U4}} = 0.1,\\; a_{\\text{U5}} = 0.0.\n$$\n\nYour program must implement these definitions exactly and produce a single line of output containing the results as a comma-separated list enclosed in square brackets. For each test case, output a list of two lists: the first inner list contains $[C_{\\text{P\\_A}}, B_{\\text{P\\_A}}]$, and the second inner list contains $[C_{\\text{P\\_B}}, B_{\\text{P\\_B}}]$. All values must be real numbers. Thus the final output format is\n$$\n\\left[ \\left[ [C_{\\text{P\\_A}}^{(1)}, B_{\\text{P\\_A}}^{(1)}], [C_{\\text{P\\_B}}^{(1)}, B_{\\text{P\\_B}}^{(1)}] \\right], \\dots, \\left[ [C_{\\text{P\\_A}}^{(4)}, B_{\\text{P\\_A}}^{(4)}], [C_{\\text{P\\_B}}^{(4)}, B_{\\text{P\\_B}}^{(4)}] \\right] \\right]\n$$\nwhere the superscript denotes the test case index from $1$ to $4$. No other text should be printed.",
            "solution": "The problem statement provides a formal, quantitative model for deriving pathway-level functional profiles from gene family abundances, a concept central to microbiome metabolic reconstruction. The model is scientifically grounded, mathematically well-posed, and all its components are explicitly defined. The problem is valid.\n\nThe solution proceeds by first implementing the defined mathematical rules and then applying them to the provided test cases. The procedure is structured into four main computational steps.\n\n1.  **Calculation of Reaction Abundance ($A_r$)**: The abundance of each reaction $r$ is the sum of the abundances of all UniRef90 protein families $f$ that catalyze it. This is based on the given mapping $M_r \\subseteq F$, where $F$ is the set of families. The formula is:\n    $$\n    A_r = \\sum_{f \\in M_r} a_f\n    $$\n    where $a_f$ is the abundance of family $f$.\n\n2.  **Determination of Reaction Presence ($p_r$)**: A reaction $r$ is considered 'present' or 'active' if its computed abundance $A_r$ meets or exceeds a specified threshold $t \\in \\mathbb{R}_{\\ge 0}$. This is captured by a binary indicator variable $p_r$:\n    $$\n    p_r = \\begin{cases}\n    1 & \\text{if } A_r \\ge t \\\\\n    0 & \\text{if } A_r < t\n    \\end{cases}\n    $$\n    The value of $p_r$ serves as the basis for module coverage calculations.\n\n3.  **Recursive Evaluation of Module Metrics ($c(m)$ and $b(m)$)**: A module $m$ is a logical composition of reactions. Its coverage $c(m)$ and abundance $b(m)$ are computed recursively.\n    -   For a leaf module, which is a single reaction $r$, the coverage is its presence indicator $p_r$, and its abundance is $A_r$.\n        $$\n        c(r) = p_r, \\qquad b(r) = A_r\n        $$\n    -   For a composite module, the evaluation depends on the logical connective. The $\\text{AND}$ operator represents a bottleneck, requiring all sub-modules to be present, thus propagating the minimum coverage and abundance. The $\\text{OR}$ operator represents alternative pathways, thus propagating the maximum coverage and abundance.\n        $$\n        c(\\text{AND}(m_{\\text{left}}, m_{\\text{right}})) = \\min\\left(c(m_{\\text{left}}), c(m_{\\text{right}})\\right)\n        $$\n        $$\n        b(\\text{AND}(m_{\\text{left}}, m_{\\text{right}})) = \\min\\left(b(m_{\\text{left}}), b(m_{\\text{right}})\\right)\n        $$\n        $$\n        c(\\text{OR}(m_{\\text{left}}, m_{\\text{right}})) = \\max\\left(c(m_{\\text{left}}), c(m_{\\text{right}})\\right)\n        $$\n        $$\n        b(\\text{OR}(m_{\\text{left}}, m_{\\text{right}})) = \\max\\left(b(m_{\\text{left}}), b(m_{\\text{right}})\\right)\n        $$\n\n4.  **Aggregation for Pathway Scores ($C_P$ and $B_P$)**: A pathway $P = \\{m_1, m_2, \\dots, m_k\\}$ is considered a sequence of necessary modules. Applying the bottleneck principle at the pathway level, the overall pathway coverage $C_P$ and abundance $B_P$ are determined by the minimum scores across all its constituent modules.\n    $$\n    C_P = \\min_{i \\in \\{1,\\dots,k\\}} c(m_i), \\qquad B_P = \\min_{i \\in \\{1,\\dots,k\\}} b(m_i)\n    $$\n\nTo illustrate, let us perform the calculation for **Case 1**:\n-   **Givens**: Threshold $t = 0.5$. Family abundances: $a_{\\text{U1}} = 0.8$, $a_{\\text{U2}} = 0.4$, $a_{\\text{U3}} = 0.9$, $a_{\\text{U4}} = 0.3$, $a_{\\text{U5}} = 0.5$.\n-   **Step 1 & 2: Reaction Metrics**:\n    -   $A_{\\text{R1}} = a_{\\text{U1}} + a_{\\text{U2}} = 0.8 + 0.4 = 1.2 \\implies p_{\\text{R1}} = 1$\n    -   $A_{\\text{R2}} = a_{\\text{U2}} = 0.4 \\implies p_{\\text{R2}} = 0$\n    -   $A_{\\text{R3}} = a_{\\text{U3}} = 0.9 \\implies p_{\\text{R3}} = 1$\n    -   $A_{\\text{R4}} = a_{\\text{U3}} + a_{\\text{U4}} = 0.9 + 0.3 = 1.2 \\implies p_{\\text{R4}} = 1$\n    -   $A_{\\text{R5}} = a_{\\text{U5}} = 0.5 \\implies p_{\\text{R5}} = 1$\n    -   $A_{\\text{R6}} = a_{\\text{U1}} = 0.8 \\implies p_{\\text{R6}} = 1$\n-   **Step 3 & 4: Pathway $\\text{P\\_A}$**: Consists of modules $m_1 = \\text{AND}(\\text{R1}, \\text{OR}(\\text{R2}, \\text{R3}))$ and $m_2 = \\text{AND}(\\text{R4}, \\text{R5})$.\n    -   $c(m_1) = \\min(p_{\\text{R1}}, \\max(p_{\\text{R2}}, p_{\\text{R3}})) = \\min(1, \\max(0, 1)) = 1$\n    -   $b(m_1) = \\min(A_{\\text{R1}}, \\max(A_{\\text{R2}}, A_{\\text{R3}})) = \\min(1.2, \\max(0.4, 0.9)) = 0.9$\n    -   $c(m_2) = \\min(p_{\\text{R4}}, p_{\\text{R5}}) = \\min(1, 1) = 1$\n    -   $b(m_2) = \\min(A_{\\text{R4}}, A_{\\text{R5}}) = \\min(1.2, 0.5) = 0.5$\n    -   $C_{\\text{P\\_A}} = \\min(c(m_1), c(m_2)) = \\min(1, 1) = 1.0$\n    -   $B_{\\text{P\\_A}} = \\min(b(m_1), b(m_2)) = \\min(0.9, 0.5) = 0.5$\n-   **Step 3 & 4: Pathway $\\text{P\\_B}$**: Consists of module $m_3 = \\text{OR}(\\text{AND}(\\text{R1}, \\text{R6}), \\text{R3})$.\n    -   $c(m_3) = \\max(\\min(p_{\\text{R1}}, p_{\\text{R6}}), p_{\\text{R3}}) = \\max(\\min(1, 1), 1) = 1$\n    -   $b(m_3) = \\max(\\min(A_{\\text{R1}}, A_{\\text{R6}}), A_{\\text{R3}}) = \\max(\\min(1.2, 0.8), 0.9) = \\max(0.8, 0.9) = 0.9$\n    -   $C_{\\text{P\\_B}} = c(m_3) = 1.0$\n    -   $B_{\\text{P\\_B}} = b(m_3) = 0.9$\n-   **Result for Case 1**: For $\\text{P\\_A}$, $[C_{\\text{P\\_A}}, B_{\\text{P\\_A}}] = [1.0, 0.5]$. For $\\text{P\\_B}$, $[C_{\\text{P\\_B}}, B_{\\text{P\\_B}}] = [1.0, 0.9]$.\n\nThe final program implements this exact logic for all four test cases.",
            "answer": "```\n[[[1.0, 0.5], [1.0, 0.9]], [[1.0, 0.7], [1.0, 0.7]], [[1.0, 0.0], [1.0, 0.0]], [[0.0, 0.0], [0.0, 0.55]]]\n```"
        },
        {
            "introduction": "The results of any bioinformatics pipeline are influenced by the parameters used, and functional annotation is no exception. Thresholds like the E-value for sequence similarity directly impact which functions are reported and at what abundance. This exercise  introduces the critical skill of sensitivity analysis, where you will quantify the stability of your conclusions by varying the annotation cutoff. This practice fosters a robust analytical mindset, teaching you to evaluate how parameter choices affect the final functional profile and to build confidence in your findings.",
            "id": "4565606",
            "problem": "You are given a simplified mathematical model for functional profiling of microbiomes based on sequence annotation hits characterized by the expectation value (E-value). The expectation value (E-value) is defined in sequence alignment as the expected number of chance alignments with a score at least as good as the observed alignment; lower E-values indicate higher-confidence annotations. Consider a set of reads mapping to functions in a reference catalog. Each read may have multiple candidate function annotations, each with an associated E-value. The goal is to perform sensitivity analyses with respect to choices of E-value cutoff thresholds and to quantify the robustness of conclusions to plausible parameter variations.\n\nFundamental definitions and assumptions:\n- Let the number of reads be $N$ and the number of annotated functions be $F$. Let the E-value matrix be $E \\in \\mathbb{R}_{\\ge 0}^{N \\times F}$, where $E_{r,f}$ is the E-value for read $r$ to function $f$.\n- For a chosen threshold $t \\in \\mathbb{R}_{>0}$, define the per-read candidate set $S_r(t) = \\{ f \\in \\{1,\\dots,F\\} : E_{r,f} \\le t \\}$.\n- Each read contributes a total of $1$ unit of abundance mass across its passing candidates at threshold $t$. This mass is divided equally among all candidates that pass, yielding the contribution\n$$\nc_{r,f}(t) = \n\\begin{cases}\n\\frac{1}{|S_r(t)|}, & \\text{if } f \\in S_r(t) \\text{ and } |S_r(t)| > 0, \\\\\n0, & \\text{if } |S_r(t)| = 0 \\text{ or } f \\notin S_r(t).\n\\end{cases}\n$$\n- The relative abundance of function $f$ at threshold $t$ is defined as\n$$\nA_f(t) = \\frac{1}{N} \\sum_{r=1}^{N} c_{r,f}(t).\n$$\n- Given a minimal prevalence threshold $\\theta \\in \\mathbb{R}_{\\ge 0}$, the presence call for function $f$ at threshold $t$ is given by the indicator function\n$$\nP_f(t) = \\mathbb{I}\\left[ A_f(t) \\ge \\theta \\right],\n$$\nwhere $\\mathbb{I}[\\cdot]$ equals $1$ if the condition is true and $0$ otherwise.\n\nRobustness metrics:\n- Given a finite set of thresholds $T = \\{ t_1, t_2, \\dots, t_m \\}$ and a designated baseline threshold $t_0 \\in T$, define the presence robustness as the fraction of functions whose presence calls are invariant across all thresholds:\n$$\nR_{\\text{presence}} = \\frac{1}{F} \\sum_{f=1}^{F} \\mathbb{I}\\left[ \\min_{t \\in T} P_f(t) = \\max_{t \\in T} P_f(t) \\right].\n$$\n- Define the abundance robustness distance as the normalized mean squared deviation of abundances across thresholds relative to the baseline threshold:\n$$\nD = \\frac{1}{m F} \\sum_{t \\in T} \\sum_{f=1}^{F} \\left( A_f(t) - A_f(t_0) \\right)^2.\n$$\nA smaller $D$ indicates greater robustness of abundance estimates to threshold variations. The presence robustness $R_{\\text{presence}}$ must be reported as a decimal between $0$ and $1$ (no percent sign).\n\nYour task is to implement a program that, for each parameter set in the provided test suite, computes $R_{\\text{presence}}$ and $D$ and outputs them as a pair of decimal numbers for each test case.\n\nTest suite:\n- Test case $1$ (general, mixed-confidence):\n    - $N = 6$, $F = 3$.\n    - Rows of $E$ for reads $r = 1,\\dots,6$ with functions $f = 1,2,3$:\n        - $r=1$: $(1 \\times 10^{-20}, 1 \\times 10^{-8}, 1 \\times 10^{-1})$.\n        - $r=2$: $(1 \\times 10^{-3}, 1 \\times 10^{-25}, 1 \\times 10^{-2})$.\n        - $r=3$: $(1 \\times 10^{-50}, 1 \\times 10^{-6}, 2)$.\n        - $r=4$: $(5 \\times 10^{-1}, 1 \\times 10^{-7}, 1 \\times 10^{-4})$.\n        - $r=5$: $(1 \\times 10^{-9}, 10, 1 \\times 10^{-3})$.\n        - $r=6$: $(5, 8 \\times 10^{-1}, 1 \\times 10^{-6})$.\n    - Threshold set $T = \\{ 1 \\times 10^{-2}, 1 \\times 10^{-5}, 1 \\times 10^{-10} \\}$, baseline $t_0 = 1 \\times 10^{-5}$.\n    - Prevalence threshold $\\theta = 2 \\times 10^{-1}$.\n- Test case $2$ (ties and borderline):\n    - $N = 4$, $F = 2$.\n    - Rows of $E$:\n        - $r=1$: $(1 \\times 10^{-5}, 1 \\times 10^{-5})$.\n        - $r=2$: $(1 \\times 10^{-4}, 1 \\times 10^{-6})$.\n        - $r=3$: $(1 \\times 10^{-2}, 1 \\times 10^{-2})$.\n        - $r=4$: $(10, 10)$.\n    - Threshold set $T = \\{ 1 \\times 10^{-2}, 1 \\times 10^{-5} \\}$, baseline $t_0 = 1 \\times 10^{-5}$.\n    - Prevalence threshold $\\theta = 2.5 \\times 10^{-1}$.\n- Test case $3$ (noise-dominated, sparse true hits):\n    - $N = 5$, $F = 3$.\n    - Rows of $E$:\n        - $r=1$: $(9 \\times 10^{-1}, 7 \\times 10^{-1}, 6 \\times 10^{-1})$.\n        - $r=2$: $(3 \\times 10^{-1}, 2 \\times 10^{-1}, 9 \\times 10^{-1})$.\n        - $r=3$: $(5, 4, 3)$.\n        - $r=4$: $(1 \\times 10^{-6}, 5 \\times 10^{-1}, 9 \\times 10^{-1})$.\n        - $r=5$: $(8 \\times 10^{-1}, 1 \\times 10^{-7}, 7 \\times 10^{-1})$.\n    - Threshold set $T = \\{ 1 \\times 10^{-2}, 1 \\times 10^{-5}, 1 \\times 10^{-7} \\}$, baseline $t_0 = 1 \\times 10^{-5}$.\n    - Prevalence threshold $\\theta = 1 \\times 10^{-1}$.\n- Test case $4$ (boundary extremes: lax vs ultra-strict):\n    - $N = 7$, $F = 4$.\n    - Rows of $E$:\n        - $r=1$: $(1 \\times 10^{-60}, 5 \\times 10^{-2}, 2, 1 \\times 10^{-3})$.\n        - $r=2$: $(9 \\times 10^{-1}, 1 \\times 10^{-55}, 2 \\times 10^{-2}, 5)$.\n        - $r=3$: $(5 \\times 10^{-1}, 4 \\times 10^{-1}, 3 \\times 10^{-1}, 2 \\times 10^{-1})$.\n        - $r=4$: $(1 \\times 10^{-1}, 1 \\times 10^{-2}, 1 \\times 10^{-3}, 1 \\times 10^{-4})$.\n        - $r=5$: $(50, 60, 70, 80)$.\n        - $r=6$: $(1 \\times 10^{-7}, 1 \\times 10^{-8}, 1 \\times 10^{-9}, 1 \\times 10^{-10})$.\n        - $r=7$: $(1 \\times 10^{-3}, 1 \\times 10^{-3}, 1 \\times 10^{-3}, 1 \\times 10^{-3})$.\n    - Threshold set $T = \\{ 1, 1 \\times 10^{-2}, 1 \\times 10^{-10}, 1 \\times 10^{-50} \\}$, baseline $t_0 = 1 \\times 10^{-10}$.\n    - Prevalence threshold $\\theta = 1.5 \\times 10^{-1}$.\n\nFinal output format requirement:\n- Your program should produce a single line of output containing a top-level list with one element per test case, where each element is a list of two decimal numbers $[R_{\\text{presence}}, D]$ for that test case. The elements must be comma-separated and enclosed in square brackets, with no additional text. For example, a valid structural format is $[[x_1,y_1],[x_2,y_2],[x_3,y_3],[x_4,y_4]]$, where each $x_i$ and $y_i$ are decimal numbers computed as specified.",
            "solution": "The user has provided a mathematical model for analyzing the robustness of microbiome functional profiling. The task is to implement this model to compute two metrics, presence robustness ($R_{\\text{presence}}$) and abundance robustness distance ($D$), for a given set of test cases.\n\nFirst, I will validate the problem statement. The problem provides a self-contained, formal mathematical framework. All terms, including the E-value matrix ($E$), thresholds ($t$), candidate sets ($S_r(t)$), contributions ($c_{r,f}(t)$), abundances ($A_f(t)$), presence calls ($P_f(t)$), and the final robustness metrics ($R_{\\text{presence}}$, $D$), are defined with mathematical precision. The model itself is a simplified but scientifically plausible representation of a common task in bioinformatics, specifically, quantifying functional potential from sequence data. The provided test cases are complete, with all necessary parameters ($N, F, E, T, t_0, \\theta$) specified. There are no contradictions, ambiguities, or violations of scientific principles. The problem is well-posed and computationally tractable. Therefore, the problem is deemed valid.\n\nThe solution will be implemented by following the provided definitions step-by-step for each test case. The overall algorithm is as follows:\n\n1.  For each test case, retrieve the parameters: number of reads $N$, number of functions $F$, the E-value matrix $E$, the set of thresholds $T$, the baseline threshold $t_0$, and the prevalence threshold $\\theta$.\n2.  Iterate through each threshold $t \\in T$ to compute the function abundance vector $A(t) = [A_1(t), A_2(t), \\dots, A_F(t)]$.\n    a.  For each threshold $t$, first determine the per-read candidate sets $S_r(t)$. This is done by comparing each E-value $E_{r,f}$ against $t$. A function $f$ is in the set $S_r(t)$ for read $r$ if $E_{r,f} \\le t$.\n    b.  For each read $r$, calculate its contribution to each function's abundance. If the candidate set $S_r(t)$ is not empty, each function $f \\in S_r(t)$ receives a contribution of $c_{r,f}(t) = 1/|S_r(t)|$. If $S_r(t)$ is empty or $f \\notin S_r(t)$, the contribution is $0$.\n    c.  The total relative abundance for a function $f$ at threshold $t$, $A_f(t)$, is the average of its contributions from all reads: $A_f(t) = \\frac{1}{N} \\sum_{r=1}^{N} c_{r,f}(t)$.\n3.  Store the computed abundance vectors $A(t)$ for all $t \\in T$. This can be viewed as an abundance matrix of size $m \\times F$, where $m = |T|$.\n4.  After computing abundances for all thresholds, calculate the two robustness metrics:\n    a.  **Presence Robustness ($R_{\\text{presence}}$)**:\n        i.  First, compute the presence call matrix $P$. For each function $f$ and threshold $t$, the presence call is $P_f(t) = 1$ if $A_f(t) \\ge \\theta$ and $0$ otherwise.\n        ii. A function $f$ is considered robust if its presence call $P_f(t)$ is constant across all thresholds $t \\in T$. This is equivalent to checking if $\\min_{t \\in T} P_f(t) = \\max_{t \\in T} P_f(t)$.\n        iii. $R_{\\text{presence}}$ is the fraction of functions that are robust: $R_{\\text{presence}} = (\\text{number of robust functions}) / F$.\n    b.  **Abundance Robustness Distance ($D$)**:\n        i.  Identify the baseline abundance vector $A(t_0)$ corresponding to the baseline threshold $t_0$.\n        ii. For each abundance vector $A(t)$, calculate the sum of squared differences from the baseline: $\\sum_{f=1}^{F} (A_f(t) - A_f(t_0))^2$.\n        iii. Sum these values over all thresholds $t \\in T$, and normalize by the total number of data points, which is $m \\times F$. The final formula is $D = \\frac{1}{m F} \\sum_{t \\in T} \\sum_{f=1}^{F} (A_f(t) - A_f(t_0))^2$.\n5.  Combine the calculated $R_{\\text{presence}}$ and $D$ for each test case into a pair of decimal numbers $[R_{\\text{presence}}, D]$ and format the final output as a list of these pairs.\n\nThis procedure will be implemented using Python and the `numpy` library for efficient array and matrix operations, which simplifies the calculation of sums and element-wise operations.",
            "answer": "```\n[[0.3333333333333333,0.01912422839506172],[1.0,0.00390625],[0.6666666666666666,0.012422222222222223],[0.25,0.009405787171994644]]\n```"
        }
    ]
}