{
    "hands_on_practices": [
        {
            "introduction": "在进行任何复杂的生物信息学分析之前，首要步骤是进行严格的质量控制。本练习  将引导您实践一个基本但至关重要的计算：从测序总读数中估算唯一且信息丰富的数据片段数量。这个指标是判断实验测序深度是否足以支持后续可靠分析（如峰值检测）的基础。",
            "id": "4545808",
            "problem": "计划进行一项批量转座酶可及性染色质测序 (bulk Assay for Transposase-Accessible Chromatin using sequencing, ATAC-seq) 实验，目标是获得 $30 \\times 10^{6}$ 个通过标准过滤并能唯一比对到参考基因组上的双端测序读对 (paired-end read pairs)。经过重复标记后，估计的文库重复率为 $d = 0.20$。在批量 ATAC-seq 中，每个读对对应一个物理 DNA 片段，而被标记为重复的读对在下游信号量化和 peak 识别中被认为是不提供信息的。请仅使用重复率和片段计数的基 本定义，推导出一个用于分析的预期唯一片段数的表达式，并计算其值。然后，从高通量测序中信号积累和检测的基本考虑出发（例如，将片段抽样建模为可及性位点上的一个随机过程，以及需要足够的计数来区分真实可及性信号与背景噪声），讨论在公认的实践标准下，这一唯一片段深度对于在典型哺乳动物基因组中进行标准的批量 ATAC-seq peak 识别是否足够。请将计算出的唯一片段数作为最终答案。最终计数应表示为精确值，无需四舍五入。",
            "solution": "该问题要求两部分的回答：首先，根据提供的测序指标计算唯一片段的数量；其次，评判该数量对于标准分析是否足够。\n\n验证问题陈述是程序的第一个步骤。\n\n**第一步：提取已知条件**\n- 通过过滤的总双端测序读对数，$N_{total} = 30 \\times 10^{6}$。\n- 估计的文库重复率，$d = 0.20$。\n- 定义：每个读对对应一个物理 DNA 片段。\n- 定义：被标记为重复的读对被认为是不提供信息的。\n- 目标 1：推导预期保留用于分析的唯一片段数的表达式，并计算其值。\n- 目标 2：讨论该数量对于在典型哺乳动物基因组中进行标准的批量 ATAC-seq peak 识别是否足够。\n\n**第二步：使用提取的已知条件进行验证**\n该问题在科学上是合理的，因为它使用了生物信息学和基因组学领域的标准术语和现实参数（ATAC-seq、重复率、读段深度）。概念定义清晰，问题本身是自洽和内部一致的。它要求进行一个直接的计算，然后基于既定的科学实践进行讨论。该问题表述良好、客观，并且没有违反任何无效标准。\n\n**第三步：判定与行动**\n该问题被判定为有效。将提供完整的解答。\n\n**第一部分：唯一片段数的推导与计算**\n\n我们从提供的基本定义开始。设 $N_{total}$ 表示通过标准过滤和比对的总双端测序读对数。在本题中，给定 $N_{total} = 30 \\times 10^{6}$。\n\n总读对集合可以划分为两个不相交的子集：唯一的读对和重复的读对。设 $N_{unique}$ 为唯一读对的数量，$N_{dup}$ 为重复读对的数量。根据定义，总读对数是这两个量的和：\n$$N_{total} = N_{unique} + N_{dup}$$\n\n重复率 $d$ 定义为重复读对占总读对数的分数。\n$$d = \\frac{N_{dup}}{N_{total}}$$\n我们已知 $d = 0.20$。\n\n问题陈述指出，被标记为重复的读对不提供信息，并在下游分析前被移除。剩下的读对是唯一的，并且每个读对对应一个成功测序的、唯一的 DNA 片段。因此，保留用于分析的唯一片段数等于唯一读对数 $N_{unique}$。\n\n我们的目标是找到 $N_{unique}$ 的表达式。我们可以重排第一个方程，用 $N_{total}$ 和 $N_{dup}$ 来表示 $N_{unique}$：\n$$N_{unique} = N_{total} - N_{dup}$$\n接下来，我们可以使用重复率的定义，用 $N_{total}$ 和 $d$ 来表示 $N_{dup}$：\n$$N_{dup} = d \\times N_{total}$$\n将这个 $N_{dup}$ 的表达式代入 $N_{unique}$ 的方程中，我们得到唯一片段数的一般表达式：\n$$N_{unique} = N_{total} - (d \\times N_{total})$$\n$$N_{unique} = N_{total} (1 - d)$$\n这就是推导出的预期保留用于分析的唯一片段数的表达式。\n\n现在，我们使用给定的数值进行计算：$N_{total} = 30 \\times 10^{6}$ 和 $d = 0.20$。\n$$N_{unique} = (30 \\times 10^{6}) \\times (1 - 0.20)$$\n$$N_{unique} = (30 \\times 10^{6}) \\times 0.80$$\n$$N_{unique} = 24 \\times 10^{6}$$\n因此，预期保留用于分析的唯一片段数为 $2400$ 万。\n\n**第二部分：关于对 peak 识别的充分性讨论**\n\n给定的测序深度对于 ATAC-seq peak 识别是否足够，必须基于高通量测序中信号检测的基本原理和广为接受的社区标准进行评估。\n\n基本原理是，要检测到一个特征，例如一个可及性染色质区域（一个“peak”），需要对该位点进行足够的片段测序，以将其信号与背景噪声区分开来。这个过程可以概念化为对片段的随机抽样。唯一片段的总数 $N_{unique}$ 代表了成功抽样的总次数。更高的 $N_{unique}$ 会增加从所有真实可及性位点（包括那些内在可及性较低的位点）抽样的概率，并提供将它们声明为显著 peak 的统计能力。\n\n对于一个“典型的哺乳动物基因组”，例如人类或小鼠（约 $3 \\times 10^{9}$ 个碱基对），可及性位点的数量估计在几十万个（例如，$100,000$ 到 $500,000$ 个位点）。$N_{unique}$ 个片段非均匀地分布在这些位点和背景中。深度的充分性决定了 peak 识别的灵敏度和特异性。\n\n计算得出的 $N_{unique} = 24 \\times 10^{6}$ 个片段的深度是相当大的数据量。它肯定足以识别最突出和高度可及的染色质区域，例如活性启动子和强增强子。使用这个深度的分析不会失败；它会产生一张有效但可能不完整的可及性基因组图谱。\n\n然而，问题提到的是“标准”批量 ATAC-seq 在“广为接受的实践”下的情况。这意味着要与主要基因组学联盟，如 DNA 元件百科全书（Encyclopedia of DNA Elements, ENCODE）所建立的基准进行比较。ENCODE 联盟进行了广泛的经验分析，以确定鲁棒且可重复地表征调控景观所需的测序深度。\n\n根据 ENCODE 的指导方针，在人类或小鼠样本中进行高质量批量 ATAC-seq 实验的目标是至少获得 $50 \\times 10^{6}$ 个唯一的、非线粒体的、非重复的读对（即 $N_{unique} \\ge 50 \\times 10^{6}$）。这一建议基于饱和度分析，该分析表明，低于此水平的深度可能会漏掉大部分真实的、特别是较弱或细胞类型特异性的增强子等可及性位点。一个拥有 $24 \\times 10^{6}$ 个唯一片段的实验尚未达到饱和，这意味着进一步测序将能继续识别出大量新的 peak。\n\n总之，虽然 $24 \\times 10^{6}$ 个唯一片段为初步或探索性分析提供了足够的数据，但这个深度被认为是次优的，并且不符合当前在哺乳动物系统中进行全面、高质量批量 ATAC-seq 分析的严格标准。与遵循 $\\ge 50 \\times 10^{6}$ 唯一片段指导方针的实验相比，具有此深度的实验在 peak 发现方面将有更高的假阴性率。它被认为足以识别强信号，但不足以进行灵敏的、全基因组范围的所有调控元件的发现。",
            "answer": "$$\\boxed{24 \\times 10^{6}}$$"
        },
        {
            "introduction": "确认数据质量合格后，下一步是识别基因组中那些具有显著高可及性的区域，即“峰”（peaks）。本练习  将指导您从零开始构建一个简化的峰值检测算法。您将应用滑动窗口方法和泊松分布统计模型，学习如何从背景噪声中区分出真实的染色质开放信号。",
            "id": "4545839",
            "problem": "给定一个基因组区域内来自ATAC-seq（使用测序技术分析转座酶可及性染色质的实验）的整数覆盖度计数，以及每个位置对应的局部背景率估计值。假设以下基本前提：在没有富集的原假设下，每个位置的覆盖度计数是从泊松过程中抽取的独立样本，其率等于局部背景率；并且，独立泊松变量之和本身也是泊松分布，其率等于各分量率之和。为了检验局部富集，考虑使用固定宽度的窗口，以步长 $1$ 在该区域上滑动。对于每个窗口，计算观测到的覆盖度总和以及预期的背景率总和，然后计算原假设下的单侧尾概率。最后，使用 Benjamini–Hochberg (BH) 程序调整这些 $p$ 值，以控制伪发现率（False Discovery Rate）。\n\n定义和要求：\n- 令 $c_i$ 表示位置 $i$ 的观测覆盖度，令 $\\lambda_i$ 表示位置 $i$ 的局部背景率，其中 $i$ 的范围从 $0$ 到 $n-1$。\n- 对于窗口宽度 $w$，将从索引 $s$ 开始的窗口定义为位置集合 $\\{s, s+1, \\ldots, s+w-1\\}$，其中 $s$ 的范围从 $0$ 到 $n-w$。观测到的窗口总和为 $K_s = \\sum_{i=s}^{s+w-1} c_i$，预期的窗口率为 $\\Lambda_s = \\sum_{i=s}^{s+w-1} \\lambda_i$。\n- 在原假设下，将 $K_s$ 建模为来自率是 $\\Lambda_s$ 的泊松随机变量的实现。使用单侧尾概率 $p_s = \\Pr[X \\geq K_s]$，其中 $X$ 是率是 $\\Lambda_s$ 的泊松分布，并且不等式在 $X$ 的支撑集上解释。\n- 对所有窗口执行 Benjamini–Hochberg (BH) 多重检验校正，以获得校正后的 $p$ 值。将重叠的窗口视为独立的假设。\n- 将 BH 校正后的 $p$ 值小于或等于指定水平 $q$ 的窗口识别为“显著峰”。\n\n您的任务是编写一个完整的、可运行的程序，为每个提供的测试用例计算显著窗口的索引 $s$ 列表及其对应的 BH 校正 $p$ 值。报告的 BH 校正 $p$ 值需四舍五入到六位小数。所有计数都是无单位的，不涉及物理单位。\n\n测试套件：\n- 案例 $1$ (正常路径)：\n  - 覆盖度向量 $c$：$[0,1,0,1,2,3,1,0,1,2,6,7,8,6,5,2,1,1,0,1,0,5,6,7,5,1,1,0,0,1]$\n  - 背景向量 $\\lambda$：$[1.0,1.0,1.2,1.0,1.0,1.1,1.0,0.9,1.1,1.2,1.3,1.2,1.1,1.2,1.1,1.0,1.0,1.0,1.0,1.0,1.1,1.2,1.3,1.2,1.1,1.0,1.0,1.0,1.0,1.0]$\n  - 窗口宽度 $w$：$5$\n  - 显著性水平 $q$：$0.05$\n- 案例 $2$ (边界情况，窗口宽度为 $1$)：\n  - 覆盖度向量 $c$：$[0,0,1,0,2,3,0,5,0,1,0,4]$\n  - 背景向量 $\\lambda$：$[0.1,0.1,0.2,0.1,0.2,0.3,0.1,0.2,0.1,0.2,0.1,0.2]$\n  - 窗口宽度 $w$：$1$\n  - 显著性水平 $q$：$0.05$\n- 案例 $3$ (窗口跨越整个区域)：\n  - 覆盖度向量 $c$：$[1,3,2,1,2,3,1,2,2,1,3,2,2,1,2,3,2,1,1,2]$\n  - 背景向量 $\\lambda$：$[2.0,2.0,2.0,2.0,2.0,2.0,2.0,2.0,2.0,2.0,2.0,2.0,2.0,2.0,2.0,2.0,2.0,2.0,2.0,2.0]$\n  - 窗口宽度 $w$：$20$\n  - 显著性水平 $q$：$0.10$\n- 案例 $4$ (高背景，无预期峰值)：\n  - 覆盖度向量 $c$：$[1,0,2,1,0,1,1,0,2,0,1,1,0,1,0,1,1,0]$\n  - 背景向量 $\\lambda$：$[5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0]$\n  - 窗口宽度 $w$：$4$\n  - 显著性水平 $q$：$0.05$\n\n算法约束：\n- 为所有有效的 $s$ 计算 $K_s$ 和 $\\Lambda_s$。\n- 使用标准数值例程计算泊松分布的单侧尾概率。\n- 计算案例中所有窗口的 Benjamini–Hochberg 校正 $p$ 值，确保当映射回原始顺序时，校正值具有单调性。\n- 返回校正后 $p$ 值 $\\leq q$ 的窗口索引及其对应的校正 $p$ 值（四舍五入到六位小数），并按窗口起始索引 $s$ 排序。\n\n最终输出格式：\n您的程序应生成单行输出，其中包含一个方括号括起来的逗号分隔列表。列表中的每个元素对应一个测试用例，其本身是一个包含两个元素的列表：第一个是显著窗口起始索引的列表，第二个是它们对应的 BH 校正 $p$ 值（四舍五入到六位小数）的列表。例如，输出应类似于 $[[[s\\_1, s\\_2], [p\\_1, p\\_2]], \\ldots]$，所有数字均采用标准十进制表示法。",
            "solution": "问题陈述已经过严格审查，并被确定为有效。它具有科学依据，定义明确且客观。它提出了一个标准的生物信息学任务——基于既定的统计学原理，在 ATAC-seq 数据中进行峰检测（peak calling）。所有数据、定义和约束都已提供，构成了一个自洽且可解的问题。\n\n该问题要求一个计算程序，从 ATAC-seq 覆盖度数据中识别出染色质可及性的统计显著区域。这通过检验测序读段相对于估计背景率的局部富集来实现。解决方案的核心涉及三个步骤：滑动窗口信号聚合、对每个窗口进行基于泊松分布的统计检验，以及用于控制伪发现率 (FDR) 的多重检验校正。\n\n首先，我们形式化统计基础。问题假定，在原假设（$H_0$）下，任何基因组位置 $i$ 的观测读段计数 $c_i$ 是从泊松分布中抽取的随机变量，其率参数为 $\\lambda_i$，记为 $c_i \\sim \\text{Poisson}(\\lambda_i)$。参数 $\\lambda_i$ 代表该位置的预期背景计数值。泊松分布的一个关键性质是其加法下的封闭性：独立泊松随机变量之和也是一个泊松随机变量，其率等于各个率的总和。\n\n其次，我们应用滑动窗口方法来评估连续基因组区域的富集情况。一个固定整数宽度 $w$ 的窗口以步长 $1$ 滑过长度为 $n$ 的基因组区域。一个从索引 $s$ 开始的窗口（其中 $s$ 的范围从 $0$ 到 $n-w$）包含位置 $\\{s, s+1, \\ldots, s+w-1\\}$。对于每个这样的窗口，我们计算两个聚合量：\n1. 总观测计数，$K_s = \\sum_{i=s}^{s+w-1} c_i$。\n2. 总预期背景率，$\\Lambda_s = \\sum_{i=s}^{s+w-1} \\lambda_i$。\n\n基于泊松分布的加法性质，对于从 $s$ 开始的窗口，原假设是观测总和 $K_s$ 是率参数为 $\\Lambda_s$ 的泊松随机变量 $X$ 的一个实现。即，$H_{0,s}: K_s \\sim \\text{Poisson}(\\Lambda_s)$。\n\n第三，对于 $m = n-w+1$ 个窗口中的每一个，我们进行单侧假设检验。我们关心的是观测计数 $K_s$ 是否异常大，这可能表示一个富集峰。统计显著性由一个 $p$ 值 $p_s$ 来量化，它被定义为在原假设下观测到至少为 $K_s$ 的计数总和的概率。这就是尾概率：\n$$p_s = \\Pr[X \\geq K_s] \\quad \\text{其中} \\quad X \\sim \\text{Poisson}(\\Lambda_s)$$\n这个概率被计算为泊松分布离散支撑集上的概率之和：\n$$p_s = \\sum_{j=K_s}^{\\infty} \\frac{e^{-\\Lambda_s} \\Lambda_s^j}{j!}$$\n在数值计算上，使用累积分布函数 (CDF) $F(k; \\Lambda_s) = \\Pr[X \\leq k]$ 会更高效，即 $p_s = 1 - F(K_s - 1; \\Lambda_s)$。这等同于在 $K_s - 1$ 处评估的生存函数 (SF)。\n\n最后，由于我们同时进行 $m$ 个假设检验，我们必须进行多重比较校正以避免假阳性的膨胀。问题指定了一种比控制族平均错误率（family-wise error rate）更不保守且通常更强大的方法：控制伪发现率 (FDR)。为此，我们采用 Benjamini–Hochberg (BH) 程序。该程序如下：\n1. 令计算出的 $m$ 个 $p$ 值为 $p_1, p_2, \\ldots, p_m$。\n2. 将这些 $p$ 值按升序排序：$p_{(1)} \\le p_{(2)} \\le \\ldots \\le p_{(m)}$。\n3. 对于每个排序后的 $p$ 值 $p_{(i)}$，其中 $i$ 是其从 $1$ 到 $m$ 的秩，计算其对应的 BH 校正 $p$ 值，通常称为 $q$ 值：\n$$q_{(i)} = \\min_{j=i}^{m} \\left\\{ \\min \\left(1, \\frac{m \\cdot p_{(j)}}{j} \\right) \\right\\}$$\n这个公式强制了单调性，确保对于排序后的原始 $p$ 值，其对应的校正 $q$ 值也是非递减的：$q_{(1)} \\le q_{(2)} \\le \\ldots \\le q_{(m)}$。\n4. 然后将校正后的 $q$ 值映射回其原始的窗口索引。\n5. 如果一个窗口 $s$ 的校正 $p$ 值 $q_s$ 小于或等于指定的 FDR 控制水平 $q$，则该窗口被宣布包含一个“显著峰”。\n\n将要实现的算法首先会为所有可能的起始位置 $s$ 计算窗口化总和 $K_s$ 和率 $\\Lambda_s$。这可以通过预先计算 $c$ 和 $\\lambda$ 向量的累积和来优化。随后，它将使用标准的数值库函数来计算每个窗口的原始 $p$ 值，该函数用于泊松生存函数。然后将对这组 $p$ 值应用 BH 校正。最后一步是筛选出校正后 $p$ 值满足显著性阈值 $q$ 的窗口，并报告它们的起始索引和校正后的 $p$ 值，按索引排序。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.stats import poisson\n\ndef solve():\n    \"\"\"\n    Main function to process all test cases and print the final result.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        (\n            [0,1,0,1,2,3,1,0,1,2,6,7,8,6,5,2,1,1,0,1,0,5,6,7,5,1,1,0,0,1],\n            [1.0,1.0,1.2,1.0,1.0,1.1,1.0,0.9,1.1,1.2,1.3,1.2,1.1,1.2,1.1,1.0,1.0,1.0,1.0,1.0,1.1,1.2,1.3,1.2,1.1,1.0,1.0,1.0,1.0,1.0],\n            5,\n            0.05\n        ),\n        (\n            [0,0,1,0,2,3,0,5,0,1,0,4],\n            [0.1,0.1,0.2,0.1,0.2,0.3,0.1,0.2,0.1,0.2,0.1,0.2],\n            1,\n            0.05\n        ),\n        (\n            [1,3,2,1,2,3,1,2,2,1,3,2,2,1,2,3,2,1,1,2],\n            [2.0,2.0,2.0,2.0,2.0,2.0,2.0,2.0,2.0,2.0,2.0,2.0,2.0,2.0,2.0,2.0,2.0,2.0,2.0,2.0],\n            20,\n            0.10\n        ),\n        (\n            [1,0,2,1,0,1,1,0,2,0,1,1,0,1,0,1,1,0],\n            [5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0],\n            4,\n            0.05\n        )\n    ]\n\n    def _calculate_peaks(c_vec, lambda_vec, w, q_level):\n        \"\"\"\n        Calculates significant peaks for a single test case.\n        \"\"\"\n        c = np.array(c_vec, dtype=np.int64)\n        lambda_bg = np.array(lambda_vec, dtype=np.float64)\n        \n        n = len(c)\n        num_windows = n - w + 1\n\n        if num_windows = 0:\n            return [[], []]\n\n        # Efficiently compute sliding window sums using cumulative sums.\n        # This is O(n) instead of O(n*w).\n        c_cumsum = np.concatenate(([0], np.cumsum(c)))\n        lambda_cumsum = np.concatenate(([0], np.cumsum(lambda_bg)))\n        \n        indices = np.arange(num_windows)\n        k_s_array = c_cumsum[indices + w] - c_cumsum[indices]\n        lambda_s_array = lambda_cumsum[indices + w] - lambda_cumsum[indices]\n\n        # Compute one-sided p-values for each window.\n        # p_s = P(X >= K_s) where X ~ Poisson(Lambda_s).\n        # This is equivalent to the survival function P(X > K_s - 1).\n        raw_p_values = poisson.sf(k_s_array - 1, lambda_s_array)\n        \n        # Benjamini-Hochberg FDR correction.\n        m = len(raw_p_values)\n        if m == 0:\n            return [[], []]\n            \n        # Store original order, then sort p-values.\n        original_indices = np.arange(m)\n        p_sorted_indices = np.argsort(raw_p_values)\n        p_sorted = raw_p_values[p_sorted_indices]\n\n        # Calculate ranks (from 1 to m).\n        ranks = np.arange(1, m + 1)\n        \n        # Calculate BH values: (p_sorted * m) / rank.\n        bh_values = (m / ranks) * p_sorted\n        \n        # Enforce monotonicity by taking the cumulative minimum from the end of the sorted list.\n        bh_adjusted_sorted = np.minimum.accumulate(bh_values[::-1])[::-1]\n        \n        # Clip values at 1.0, as adjusted p-values cannot be > 1.\n        bh_adjusted_sorted = np.minimum(bh_adjusted_sorted, 1.0)\n        \n        # Map adjusted p-values back to their original window order.\n        bh_adjusted = np.empty_like(bh_adjusted_sorted)\n        bh_adjusted[p_sorted_indices] = bh_adjusted_sorted\n\n        # Identify significant windows and their adjusted p-values.\n        significant_mask = bh_adjusted = q_level\n        significant_indices = original_indices[significant_mask].tolist()\n        significant_p_values = [round(p, 6) for p in bh_adjusted[significant_mask]]\n        \n        return [significant_indices, significant_p_values]\n\n    results = []\n    for case in test_cases:\n        c, l, w, q = case\n        result = _calculate_peaks(c, l, w, q)\n        results.append(result)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\".replace(\" \", \"\"))\n\nsolve()\n```"
        },
        {
            "introduction": "仅仅识别出峰是不够的，理解它们的生物学功能才是最终目标。本练习  模拟了一种常见的多组学整合分析。您将通过计算染色质开放峰的可及性与邻近基因表达水平之间的相关性，来识别潜在的调控关系，这是破译非编码DNA功能的关键一步。",
            "id": "4545850",
            "problem": "您将获得一个包含$6$个样本的匹配的转座酶可及性染色质测序 (ATAC-seq) 和 RNA测序 (RNA-seq) 数据集。目标是通过计算相关性并在错误发现率控制下识别显著的峰-基因关联，来量化染色质可及性峰与邻近基因表达之间的统计关系。您的方法应基于以下基本原理：\n\n- 分子生物学中心法则：调控性DNA元件影响转录起始，通过ATAC-seq测量的开放染色质很可能与通过RNA-seq测量的信使核糖核酸 (mRNA) 水平相关。\n- 相关性的统计定义：对于两个长度为$n$的样本向量$x$和$y$，样本皮尔逊相关系数定义为$$r(x,y) = \\frac{\\sum_{i=1}^{n} (x_i - \\bar{x})(y_i - \\bar{y})}{\\sqrt{\\sum_{i=1}^{n} (x_i - \\bar{x})^2} \\sqrt{\\sum_{i=1}^{n} (y_i - \\bar{y})^2}}$$其中$\\bar{x}$和$\\bar{y}$表示样本均值。\n- 相关性的假设检验：在原假设$H_0: r = 0$下，检验统计量$t = r \\sqrt{\\frac{n - 2}{1 - r^2}}$服从自由度为$n - 2$的学生$t$分布，从而可以计算双侧$p$值$p = 2 \\cdot \\Pr(T \\geq |t|)$。\n- 多重检验校正：对于$m$个独立或正相关的假设检验及其$p$值$\\{p_1, \\dots, p_m\\}$，Benjamini–Hochberg程序通过找到满足$p_{(k)} \\leq \\frac{k}{m} \\alpha$的最大索引$k$来将错误发现率控制在水平$\\alpha$，其中$p_{(k)}$是第$k$小的$p$值。所有满足$i \\leq k$的$p_{(i)}$都被判定为显著。\n\n数据被编码为确定性的数组和基因组坐标，以确保科学真实性，无需外部文件。如果染色体标签匹配，并且峰中心与基因转录起始位点 (TSS) 之间的绝对距离小于或等于用户指定的最大距离（以碱基对为单位），则该峰-基因对被视为候选对。\n\n数据集规格：\n- 样本：$6$个匹配的生物样本，索引为$i = 1, \\dots, 6$。\n- 基因及其染色体和TSS：\n    - $G1$：染色体 $chr1$，$\\text{TSS} = 100000$。\n    - $G2$：染色体 $chr1$，$\\text{TSS} = 150000$。\n    - $G3$：染色体 $chr1$，$\\text{TSS} = 500000$。\n    - $G4$：染色体 $chr2$，$\\text{TSS} = 100000$。\n- ATAC-seq峰及其染色体和中心位置：\n    - $P1$：染色体 $chr1$，位置 $103000$。\n    - $P2$：染色体 $chr1$，位置 $130000$。\n    - $P3$：染色体 $chr1$，位置 $148000$。\n    - $P4$：染色体 $chr1$，位置 $510000$。\n    - $P5$：染色体 $chr2$，位置 $90000$。\n- $6$个样本的ATAC-seq可及性向量（任意单位）：\n    - $P1$: $[10, 15, 20, 25, 30, 36]$.\n    - $P2$: $[13, 15, 14, 15, 14, 15]$.\n    - $P3$: $[10, 12, 14, 16, 18, 20]$.\n    - $P4$: $[5, 15, 5, 16, 10, 13]$.\n    - $P5$: $[5, 5, 5, 5, 5, 5]$.\n- $6$个样本的RNA-seq表达向量（任意单位）：\n    - $G1$: $[50, 62, 69, 81, 88, 101]$.\n    - $G2$: $[200, 180, 160, 140, 120, 100]$.\n    - $G3$: $[80, 85, 80, 79, 82, 81]$.\n    - $G4$: $[30, 28, 29, 31, 32, 30]$.\n\n约束和定义：\n- 候选的峰-基因对必须具有匹配的染色体标签，并且其绝对距离小于或等于指定的最大距离（以碱基对为单位）。\n- 对于每个候选对，使用原假设$H_0: r = 0$和自由度为$n - 2$的学生$t$分布，计算皮尔逊相关系数及相关的双侧$p$值。\n- 如果任一向量的方差为零（例如$P5$），则将相关性视为未定义，并将该对从假设检验中排除。\n- 对有效$p$值的集合应用水平为$\\alpha$的Benjamini–Hochberg程序来判定显著性。\n- 以整数形式报告每个测试用例的显著峰-基因关联的总数。\n\n测试套件：\n您的程序必须评估以下测试用例，每个用例由$(\\alpha, d_{\\max})$描述，其中$\\alpha$是错误发现率水平，$d_{\\max}$是允许的最大距离（以碱基对为单位）：\n- 用例1：$(\\alpha = 0.05, d_{\\max} = 10000)$。\n- 用例2：$(\\alpha = 0.05, d_{\\max} = 2000)$。\n- 用例3：$(\\alpha = 0.05, d_{\\max} = 20000)$。\n- 用例4：$(\\alpha = 0.5, d_{\\max} = 20000)$。\n- 用例5：$(\\alpha = 0.05, d_{\\max} = 500)$。\n\n最终输出格式：\n您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表（例如，$[result1,result2,result3,result4,result5]$），其中每个$result$是相应测试用例的显著峰-基因关联的整数计数。输出中不需要物理单位，因为所有量都是无量纲的计数。",
            "solution": "目标是量化特定基因组位点（ATAC-seq峰）的染色质可及性与邻近基因（RNA-seq）表达之间的统计关联。该分析基于分子生物学的中心法则，该法则假定开放的调控区域（如增强子和启动子）会影响基因转录的速率。该问题提供了一个数据集，包含$6$个样本的ATAC-seq和RNA-seq测量值，以及$4$个基因和$5$个峰的基因组坐标。分析过程包括三个主要步骤：基于基因组邻近性识别候选的峰-基因对，为每对计算关联的统计度量，以及应用多重检验校正来控制错误发现率。\n\n**步骤1：识别候选的峰-基因对**\n\n如果满足两个条件，一个峰-基因对就被视为关联分析的候选对象：\n1.  峰和基因都位于同一条染色体上。\n2.  峰中心与基因转录起始位点 (TSS) 之间的绝对基因组距离小于或等于指定的最大距离$d_{\\max}$。距离计算公式为 $|\\text{峰位置} - \\text{基因TSS}|$。\n\n首先，我们列举所有可能的对，并检查染色体匹配条件。有$5$个峰和$4$个基因，总共产生$20$种组合。\n-   $chr1$染色体上的峰：$P1, P2, P3, P4$。$chr1$染色体上的基因：$G1, G2, G3$。这在$chr1$上给出了$4 \\times 3 = 12$个潜在的对。\n-   $chr2$染色体上的峰：$P5$。$chr2$染色体上的基因：$G4$。这在$chr2$上给出了$1 \\times 1 = 1$个潜在的对。\n所有其他组合都涉及不同的染色体，是无效的。下面计算并列出了$13$个有效对的距离：\n\n| 峰 | 基因 | 峰位置 | 基因TSS | 距离 (bp) |\n| :--- | :--- | :--- | :--- | :--- |\n| $P1$ | $G1$ | $103000$ | $100000$ | $3000$ |\n| $P1$ | $G2$ | $103000$ | $150000$ | $47000$ |\n| $P1$ | $G3$ | $103000$ | $500000$ | $397000$ |\n| $P2$ | $G1$ | $130000$ | $100000$ | $30000$ |\n| $P2$ | $G2$ | $130000$ | $150000$ | $20000$ |\n| $P2$ | $G3$ | $130000$ | $500000$ | $370000$ |\n| $P3$ | $G1$ | $148000$ | $100000$ | $48000$ |\n| $P3$ | $G2$ | $148000$ | $150000$ | $2000$ |\n| $P3$ | $G3$ | $148000$ | $500000$ | $352000$ |\n| $P4$ | $G1$ | $510000$ | $100000$ | $410000$ |\n| $P4$ | $G2$ | $510000$ | $150000$ | $360000$ |\n| $P4$ | $G3$ | $510000$ | $500000$ | $10000$ |\n| $P5$ | $G4$ | $90000$ | $100000$ | $10000$ |\n\n对于一个给定的、具有特定$d_{\\max}$的测试用例，我们只从该表中选择距离 $\\le d_{\\max}$的对。\n\n**步骤2：统计显著性的计算**\n\n对于每个候选对，我们分析其ATAC-seq可及性向量($x$)和RNA-seq表达向量($y$)之间的关联。两个向量的长度均为$n=6$。\n\n首先，我们必须排除其中任一向量方差为零的对。峰$P5$的ATAC-seq向量是$[5, 5, 5, 5, 5, 5]$，其方差为$0$。因此，任何涉及$P5$的候选对（即($P5, G4$)）都将从假设检验中排除。所有其他提供的向量都具有非零方差。\n\n对于每个剩余的有效候选对，我们计算样本皮尔逊相关系数：\n$$r(x,y) = \\frac{\\sum_{i=1}^{n} (x_i - \\bar{x})(y_i - \\bar{y})}{\\sqrt{\\sum_{i=1}^{n} (x_i - \\bar{x})^2} \\sqrt{\\sum_{i=1}^{n} (y_i - \\bar{y})^2}}$$\n在真实相关性为零的原假设$H_0$下，检验统计量$t$的计算公式为：\n$$t = r \\sqrt{\\frac{n - 2}{1 - r^2}}$$\n该统计量服从自由度为$n - 2 = 6 - 2 = 4$的学生$t$分布。双侧$p$值是观测到至少与$|t|$一样极端的检验统计量的概率，由$p = 2 \\cdot \\Pr(T \\ge |t|)$给出，其中$T$是服从$t(4)$分布的随机变量。我们为所有$12$个可能的可检验对计算这些统计数据。\n\n| 对 | 距离 (bp) | 相关性 ($r$) | $t$-统计量 | $p$-值 |\n| :--- | :--- | :--- | :--- | :--- |\n| ($P1$, $G1$) | $3000$ | $0.9936$ | $15.35$ | $0.00018$ |\n| ($P1$, $G2$) | $47000$ | $-0.9634$ | $-6.74$ | $0.00259$ |\n| ($P1$, $G3$) | $397000$ | $-0.0150$ | $-0.03$ | $0.97780$ |\n| ($P2$, $G1$) | $30000$ | $0.2312$ | $0.48$ | $0.66040$ |\n| ($P2$, $G2$) | $20000$ | $-0.3475$ | $-0.74$ | $0.49980$ |\n| ($P2$, $G3$) | $370000$ | $0.8143$ | $2.76$ | $0.05090$ |\n| ($P3$, $G1$) | $48000$ | $0.9856$ | $10.33$ | $0.00049$ |\n| ($P3$, $G2$) | $2000$ | $-1.0000$ | $-\\infty$ | $0.00000$ |\n| ($P3$, $G3$) | $352000$ | $0.1691$ | $0.35$ | $0.74820$ |\n| ($P4$, $G1$) | $410000$ | $-0.0435$ | $-0.09$ | $0.93480$ |\n| ($P4$, $G2$) | $360000$ | $0.1332$ | $0.27$ | $0.80060$ |\n| ($P4$, $G3$) | $10000$ | $0.5000$ | $1.15$ | $0.31250$ |\n\n**步骤3：错误发现率 (FDR) 的控制**\n\n为了对多重假设检验进行校正，我们应用Benjamini–Hochberg (BH) 程序。对于一组$m$个$p$值和一个期望的FDR水平$\\alpha$：\n1.  将$p$值按非递减顺序排序：$p_{(1)} \\le p_{(2)} \\le \\dots \\le p_{(m)}$。\n2.  找到满足$p_{(k)} \\le \\frac{k}{m} \\alpha$的最大整数$k$。\n3.  拒绝与$p_{(1)}, \\dots, p_{(k)}$相对应的所有原假设。显著关联的数量为$k$。如果不存在这样的$k$，则不拒绝任何假设，计数为$0$。\n\n**步骤4：应用于测试用例**\n\n我们现在将这整个工作流程应用于每个测试用例。\n\n**用例1：$(\\alpha = 0.05, d_{\\max} = 10000)$**\n- 候选对 (距离 $\\le 10000$)：($P1, G1$), ($P3, G2$), ($P4, G3$)。（$P5, G4$）因方差为零而被排除。\n- 检验数量$m=3$。\n- $p$-值：$\\{0.00018, 0.00000, 0.31250\\}$。\n- 排序后的$p$-值：$p_{(1)}=0.00000$, $p_{(2)}=0.00018$, $p_{(3)}=0.31250$。\n- BH阈值 ($\\frac{k}{3} \\cdot 0.05$)：$k=1$时为$0.0167$，$k=2$时为$0.0333$，$k=3$时为$0.0500$。\n- 检验：\n  - $k=3: p_{(3)} = 0.31250 \\not\\le 0.0500$。\n  - $k=2: p_{(2)} = 0.00018 \\le 0.0333$。此条件成立。\n- 最大的$k$是$2$。\n- 结果：$2$个显著关联。\n\n**用例2：$(\\alpha = 0.05, d_{\\max} = 2000)$**\n- 候选对 (距离 $\\le 2000$)：($P3, G2$)。\n- 检验数量$m=1$。\n- $p$-值：$\\{0.00000\\}$。\n- 排序后的$p$-值：$p_{(1)}=0.00000$。\n- BH阈值 ($\\frac{1}{1} \\cdot 0.05$)：$k=1$时为$0.0500$。\n- 检验：$p_{(1)} = 0.00000 \\le 0.0500$。此条件成立。\n- 最大的$k$是$1$。\n- 结果：$1$个显著关联。\n\n**用例3：$(\\alpha = 0.05, d_{\\max} = 20000)$**\n- 候选对 (距离 $\\le 20000$)：($P1, G1$), ($P2, G2$), ($P3, G2$), ($P4, G3$)。\n- 检验数量$m=4$。\n- $p$-值：$\\{0.00018, 0.49980, 0.00000, 0.31250\\}$。\n- 排序后的$p$-值：$p_{(1)}=0.00000, p_{(2)}=0.00018, p_{(3)}=0.31250, p_{(4)}=0.49980$。\n- BH阈值 ($\\frac{k}{4} \\cdot 0.05$)：$0.0125$ ($k=1$), $0.0250$ ($k=2$), $0.0375$ ($k=3$), $0.0500$ ($k=4$)。\n- 检验：\n  - $k=4: p_{(4)} = 0.49980 \\not\\le 0.0500$。\n  - $k=3: p_{(3)} = 0.31250 \\not\\le 0.0375$。\n  - $k=2: p_{(2)} = 0.00018 \\le 0.0250$。此条件成立。\n- 最大的$k$是$2$。\n- 结果：$2$个显著关联。\n\n**用例4：$(\\alpha = 0.5, d_{\\max} = 20000)$**\n- 候选对与用例3相同，$m=4$。\n- $p$-值：$\\{0.00018, 0.49980, 0.00000, 0.31250\\}$。\n- 排序后的$p$-值：$p_{(1)}=0.00000, p_{(2)}=0.00018, p_{(3)}=0.31250, p_{(4)}=0.49980$。\n- BH阈值 ($\\frac{k}{4} \\cdot 0.5$)：$0.125$ ($k=1$), $0.250$ ($k=2$), $0.375$ ($k=3$), $0.500$ ($k=4$)。\n- 检验：\n  - $k=4: p_{(4)} = 0.49980 \\le 0.500$。此条件成立。\n- 最大的$k$是$4$。\n- 结果：$4$个显著关联。\n\n**用例5：$(\\alpha = 0.05, d_{\\max} = 500)$**\n- 候选对 (距离 $\\le 500$)：无。\n- 检验数量$m=0$。\n- 由于没有进行检验，因此没有显著结果。\n- 结果：$0$个显著关联。\n\n五个测试用例的最终计数为$[2, 1, 2, 4, 0]$。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.stats import t\n\ndef solve():\n    \"\"\"\n    Solves the bioinformatics problem of finding significant peak-gene links.\n    The solution involves identifying candidate pairs by distance, calculating\n    correlation and p-values, and applying the Benjamini-Hochberg procedure.\n    \"\"\"\n    \n    # Dataset specification\n    n_samples = 6\n    \n    genes_data = {\n        'G1': {'chr': 'chr1', 'tss': 100000, 'expr': np.array([50, 62, 69, 81, 88, 101])},\n        'G2': {'chr': 'chr1', 'tss': 150000, 'expr': np.array([200, 180, 160, 140, 120, 100])},\n        'G3': {'chr': 'chr1', 'tss': 500000, 'expr': np.array([80, 85, 80, 79, 82, 81])},\n        'G4': {'chr': 'chr2', 'tss': 100000, 'expr': np.array([30, 28, 29, 31, 32, 30])},\n    }\n\n    peaks_data = {\n        'P1': {'chr': 'chr1', 'pos': 103000, 'access': np.array([10, 15, 20, 25, 30, 36])},\n        'P2': {'chr': 'chr1', 'pos': 130000, 'access': np.array([13, 15, 14, 15, 14, 15])},\n        'P3': {'chr': 'chr1', 'pos': 148000, 'access': np.array([10, 12, 14, 16, 18, 20])},\n        'P4': {'chr': 'chr1', 'pos': 510000, 'access': np.array([5, 15, 5, 16, 10, 13])},\n        'P5': {'chr': 'chr2', 'pos': 90000, 'access': np.array([5, 5, 5, 5, 5, 5])},\n    }\n    \n    # Test suite\n    test_cases = [\n        # (alpha, d_max)\n        (0.05, 10000),\n        (0.05, 2000),\n        (0.05, 20000),\n        (0.5, 20000),\n        (0.05, 500),\n    ]\n\n    def calculate_p_value(vec1, vec2, n):\n        \"\"\"Calculates the two-sided p-value for a Pearson correlation.\"\"\"\n        # Check for zero variance\n        if np.var(vec1) == 0 or np.var(vec2) == 0:\n            return None # Indicates an invalid pair for hypothesis testing\n        \n        r = np.corrcoef(vec1, vec2)[0, 1]\n        \n        # Handle perfect correlation edge case\n        if abs(r) == 1.0:\n            return 0.0\n        \n        dof = n - 2\n        t_stat = r * np.sqrt(dof / (1 - r**2))\n        p_val = 2 * t.sf(np.abs(t_stat), df=dof) # sf is survival function (1-cdf)\n        \n        return p_val\n\n    results = []\n    \n    for alpha, d_max in test_cases:\n        candidate_p_values = []\n        \n        # Step 1: Identify candidate pairs and calculate p-values\n        for g_id, g_info in genes_data.items():\n            for p_id, p_info in peaks_data.items():\n                \n                # Condition 1: Matching chromosome\n                if g_info['chr'] != p_info['chr']:\n                    continue\n                \n                # Condition 2: Distance constraint\n                distance = abs(p_info['pos'] - g_info['tss'])\n                if distance > d_max:\n                    continue\n\n                # The pair is a candidate, proceed to statistical test\n                p_val = calculate_p_value(p_info['access'], g_info['expr'], n_samples)\n                \n                # Exclude pairs where correlation is undefined (zero variance)\n                if p_val is not None:\n                    candidate_p_values.append(p_val)\n        \n        # Step 2: Apply Benjamini-Hochberg procedure\n        m = len(candidate_p_values)\n        if m == 0:\n            results.append(0)\n            continue\n            \n        sorted_p_values = sorted(candidate_p_values)\n        \n        k = 0\n        for i in range(m - 1, -1, -1):\n            rank = i + 1\n            p_i = sorted_p_values[i]\n            bh_threshold = (rank / m) * alpha\n            if p_i = bh_threshold:\n                k = rank\n                break\n        \n        results.append(k)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        }
    ]
}