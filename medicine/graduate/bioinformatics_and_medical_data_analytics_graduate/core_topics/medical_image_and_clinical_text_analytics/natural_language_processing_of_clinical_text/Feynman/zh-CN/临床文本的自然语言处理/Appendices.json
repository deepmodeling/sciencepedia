{
    "hands_on_practices": [
        {
            "introduction": "词元化（Tokenization）是将原始文本流分解为有意义的单元（词元）的过程，是任何自然语言处理（NLP）流程的基石。不同的词元化策略会产生截然不同的词元，从而直接影响下游任务（如命名实体识别或关系提取）的性能。本练习将通过一个真实的临床文本片段，让您动手比较三种核心的词元化方法：简单的空格分割、更精细的基于规则的方法以及现代的子词（subword）方法，从而深刻理解它们在处理临床文本特有的标点、缩写和数值单位时的差异与权衡。",
            "id": "4588759",
            "problem": "请思考以下临床记录片段（原文照录，包括标点和空格）：\nPt c/o chest pain, 2/10, onset ~3h ago; Na 142 mg/dL; uh... denies SOB.\n\n您将分析应用于此片段的三种分词方案，计算它们的词元数量和词汇表外率，然后将这些量组合成一个单一的标量。请根据下述的分词和词汇表外率定义的第一性原理进行分析。\n\n分词方案：\n1. 空格分词：仅根据空格（即空格字符）来分割片段。不进行标点符号分割；如果存在标点符号，则其保持与周围文本相连。\n2. 保留数字单位的基于规则的分词：\n   - 首先如上所述按空格分割，以获得初步的词元。\n   - 然后，对于每个初步的词元：\n     - 如果词元包含精确子串“...”，则将其分割为“...”之前（如果非空）的子串和一个单独的词元“...”。\n     - 分离任何作为逗号、分号或句点（“,”、“;”、“.”）的单个尾随字符，并将其作为一个独立的词元。不要在斜杠（“/”）内部进行分割，并且当标点是单位的一部分（例如，“mg/dL”）或三字符省略号“...”的一部分时，不要分离标点。\n   - 处理完标点符号后，合并数字-单位表达式：如果一个词元恰好是一个数字（可选地以“~”为前缀，即“~”后跟数字，或仅为数字），且紧随其后的是来自单位列表 U = {\"mg/dL\", \"mmHg\", \"h\"} 的一个单位词元，则将这两个词元合并成一个单一的词元，通过连接方式且中间无空格（例如，“142”后跟“mg/dL”变为“142mg/dL”；“~3”后跟“h”等同于“~3h”，它仍然是一个单一的词元）。\n3. 子词字节对编码（BPE）风格的分词：\n   - 在子词分割之前，将片段转换为小写。\n   - 按空格分割以获得单词，然后使用贪心最长匹配规则，基于以下子词词汇表 $V_b$，从左到右对每个单词进行分割：\n     {\"pt\", \"c\", \"/\", \"o\", \"chest\", \"pain\", \",\", \"2/10\", \"onset\", \"~\", \"3h\", \"ago\", \";\", \"na\", \"142\", \"mg/dl\", \"uh\", \"...\", \"denies\", \"sob\", \".\"}.\n   - 如果一个单词无法使用 $V_b$ 完全分割，则用特殊符号“[UNK]”表示该整个单词，作为一个单独的子词词元。对于此问题，仅将字面词元“[UNK]”视为子词级别的词汇表外词元。\n\n用于确定词汇表外（OOV）词的词汇表：\n- 对于空格分词，使用词级词汇表 $V_w$ = {\"Pt\", \"c/o\", \"chest\", \"pain\", \"2/10\", \"onset\", \"~3h\", \"ago\", \"Na\", \"142\", \"mg/dL\", \"uh...\", \"denies\", \"SOB\"}。\n- 对于基于规则的分词，使用词元词汇表 $V_r$ = {\"Pt\", \"c/o\", \"chest\", \"pain\", \"2/10\", \"onset\", \"~3h\", \"ago\", \"Na\", \"142mg/dL\", \"uh\", \"...\", \"denies\", \"SOB\", \",\", \";\", \".\"}。\n- 对于BPE分词，使用上述子词词汇表 $V_b$，并将OOV符号专门定义为“[UNK]”。\n\n定义：\n- 一种分词方案下的词元数量是指该方案在片段上产生的词元总数。\n- 一种方案下的词汇表外率定义为在该方案对应的词汇表中未找到的词元数量（对于BPE：等于“[UNK]”的子词词元数量）除以该方案产生的词元总数。\n\n任务：\n- 计算由空格分词、基于规则的分词和BPE分词产生的词元数量。分别用 $N_{\\mathrm{ws}}$、$N_{\\mathrm{rule}}$ 和 $N_{\\mathrm{bpe}}$ 表示。\n- 计算每种方案下的词汇表外率。分别用 $R_{\\mathrm{ws}}$、$R_{\\mathrm{rule}}$ 和 $R_{\\mathrm{bpe}}$ 表示。\n- 最后，计算标量\n$$S \\equiv \\left(N_{\\mathrm{bpe}} - N_{\\mathrm{rule}}\\right) + \\left(R_{\\mathrm{ws}} - R_{\\mathrm{rule}}\\right).$$\n\n请以单一最简分数的形式提供 $S$ 的最终值。不要四舍五入。不需要单位。",
            "solution": "所提出的问题是一个定义明确的计算语言学练习，应用于临床文本。所有步骤和定义都已明确说明，从而可以得到一个唯一且可验证的解。因此，该问题是有效的。我们将通过系统地分析每种指定的分词方案来计算所需的量。\n\n临床记录片段是：“Pt c/o chest pain, 2/10, onset ~3h ago; Na 142 mg/dL; uh... denies SOB.”\n\n**1. 空格分词**\n\n该方案仅根据空格字符来分割文本。\n将此规则应用于该片段，产生以下词元：\n`\"Pt\"`, `\"c/o\"`, `\"chest\"`, `\"pain,\"`, `\"2/10,\"`, `\"onset\"`, `\"~3h\"`, `\"ago;\"`, `\"Na\"`, `\"142\"`, `\"mg/dL;\"`, `\"uh...\"`, `\"denies\"`, `\"SOB.\"`\n\n词元的总数是此列表中的元素数量。\n$$N_{\\mathrm{ws}} = 14$$\n\n接下来，我们计算词汇表外（OOV）率。给定的词级词汇表是 $V_w = \\{\"Pt\", \"c/o\", \"chest\", \"pain\", \"2/10\", \"onset\", \"\\~3h\", \"ago\", \"Na\", \"142\", \"mg/dL\", \"uh...\", \"denies\", \"SOB\"\\}$。如果一个词元不在 $V_w$ 中，则它被认为是OOV。我们检查每个词元：\n- `\"Pt\"`: 在 $V_w$ 中\n- `\"c/o\"`: 在 $V_w$ 中\n- `\"chest\"`: 在 $V_w$ 中\n- `\"pain,\"`: **不**在 $V_w$ 中（因为有逗号）\n- `\"2/10,\"`: **不**在 $V_w$ 中（因为有逗号）\n- `\"onset\"`: 在 $V_w$ 中\n- `\"~3h\"`: 在 $V_w$ 中\n- `\"ago;\"`: **不**在 $V_w$ 中（因为有分号）\n- `\"Na\"`: 在 $V_w$ 中\n- `\"142\"`: 在 $V_w$ 中\n- `\"mg/dL;\"`: **不**在 $V_w$ 中（因为有分号）\n- `\"uh...\"`: 在 $V_w$ 中\n- `\"denies\"`: 在 $V_w$ 中\n- `\"SOB.\"`: **不**在 $V_w$ 中（因为有句点）\n\nOOV词元的数量是 $5$。\nOOV率 $R_{\\mathrm{ws}}$ 是OOV词元数与总词元数的比值。\n$$R_{\\mathrm{ws}} = \\frac{5}{14}$$\n\n**2. 基于规则的分词**\n\n该方案涉及一个多步骤过程。\n步骤（a）：按空格进行初始分割，得到与第一种方案相同的 $14$ 个初步词元。\n步骤（b）：标点符号处理。\n- `\"pain,\"` $\\rightarrow$ `\"pain\"`, `\",\"`\n- `\"2/10,\"` $\\rightarrow$ `\"2/10\"`, `\",\"`\n- `\"ago;\"` $\\rightarrow$ `\"ago\"`, `\";\"`\n- `\"mg/dL;\"` $\\rightarrow$ `\"mg/dL\"`, `\";\"`\n- `\"uh...\"` $\\rightarrow$ `\"uh\"`, `\"...\"`\n- `\"SOB.\"` $\\rightarrow$ `\"SOB\"`, `\".\"`\n此步骤后的词元列表是：\n`\"Pt\"`, `\"c/o\"`, `\"chest\"`, `\"pain\"`, `\",\"`, `\"2/10\"`, `\",\"`, `\"onset\"`, `\"~3h\"`, `\"ago\"`, `\";\"`, `\"Na\"`, `\"142\"`, `\"mg/dL\"`, `\";\"`, `\"uh\"`, `\"...\"`, `\"denies\"`, `\"SOB\"`, `\".\"`\n\n步骤（c）：合并数字-单位表达式。单位列表是 $U = \\{\"mg/dL\", \"mmHg\", \"h\"\\}$。我们寻找一个数字词元后紧跟着一个来自 $U$ 的单位词元的序列。在上面的列表中，词元“142”是一个数字，紧随其后的是“mg/dL”，它在 $U$ 中。这两个词元被合并。\n- `\"142\"`, `\"mg/dL\"` $\\rightarrow$ `\"142mg/dL\"`\n\n基于规则的方案的最终词元列表是：\n`\"Pt\"`, `\"c/o\"`, `\"chest\"`, `\"pain\"`, `\",\"`, `\"2/10\"`, `\",\"`, `\"onset\"`, `\"~3h\"`, `\"ago\"`, `\";\"`, `\"Na\"`, `\"142mg/dL\"`, `\";\"`, `\"uh\"`, `\"...\"`, `\"denies\"`, `\"SOB\"`, `\".\"`\n\n这些词元的总数是：\n$$N_{\\mathrm{rule}} = 19$$\n\n该方案的词汇表是 $V_r = \\{\"Pt\", \"c/o\", \"chest\", \"pain\", \"2/10\", \"onset\", \"\\~3h\", \"ago\", \"Na\", \"142mg/dL\", \"uh\", \"...\", \"denies\", \"SOB\", \",\", \";\", \".\"\\}$。通过检查，我们基于规则的过程生成的 $19$ 个词元中的每一个都存在于 $V_r$ 中。因此，OOV词元的数量是 $0$。\nOOV率是：\n$$R_{\\mathrm{rule}} = \\frac{0}{19} = 0$$\n\n**3. BPE风格的分词**\n\n步骤（a）：片段被转换为小写：\n`\"pt c/o chest pain, 2/10, onset ~3h ago; na 142 mg/dl; uh... denies sob.\"`\n步骤（b）：按空格分割得到初始单词列表：\n`[\"pt\", \"c/o\", \"chest\", \"pain,\", \"2/10,\", \"onset\", \"~3h\", \"ago;\", \"na\", \"142\", \"mg/dl;\", \"uh...\", \"denies\", \"sob.\"]`\n步骤（c）：使用贪心最长匹配法，并借助子词词汇表 $V_b = \\{\"pt\", \"c\", \"/\", \"o\", \"chest\", \"pain\", \",\", \"2/10\", \"onset\", \"\\~\", \"3h\", \"ago\", \";\", \"na\", \"142\", \"mg/dl\", \"uh\", \"...\", \"denies\", \"sob\", \".\"\\}$ 对每个单词进行分割。\n- `\"pt\"` $\\rightarrow$ `[\"pt\"]` ($1$ 个词元)\n- `\"c/o\"` $\\rightarrow$ `[\"c\", \"/\", \"o\"]` ($3$ 个词元)\n- `\"chest\"` $\\rightarrow$ `[\"chest\"]` ($1$ 个词元)\n- `\"pain,\"` $\\rightarrow$ `[\"pain\", \",\"]` ($2$ 个词元)\n- `\"2/10,\"` $\\rightarrow$ `[\"2/10\", \",\"]` ($2$ 个词元)\n- `\"onset\"` $\\rightarrow$ `[\"onset\"]` ($1$ 个词元)\n- `\"~3h\"` $\\rightarrow$ `[\"~\", \"3h\"]` ($2$ 个词元)\n- `\"ago;\"` $\\rightarrow$ `[\"ago\", \";\"]` ($2$ 个词元)\n- `\"na\"` $\\rightarrow$ `[\"na\"]` ($1$ 个词元)\n- `\"142\"` $\\rightarrow$ `[\"142\"]` ($1$ 个词元)\n- `\"mg/dl;\"` $\\rightarrow$ `[\"mg/dl\", \";\"]` ($2$ 个词元)\n- `\"uh...\"` $\\rightarrow$ `[\"uh\", \"...\"]` ($2$ 个词元)\n- `\"denies\"` $\\rightarrow$ `[\"denies\"]` ($1$ 个词元)\n- `\"sob.\"` $\\rightarrow$ `[\"sob\", \".\"]` ($2$ 个词元)\n\n所有单词都被完全分割。没有生成 `\"[UNK]\"` 词元。\nBPE词元的总数是每个单词的词元数之和：\n$$N_{\\mathrm{bpe}} = 1 + 3 + 1 + 2 + 2 + 1 + 2 + 2 + 1 + 1 + 2 + 2 + 1 + 2 = 23$$\nOOV词元的数量，定义为 `\"[UNK]\"` 的计数，是 $0$。\nOOV率是：\n$$R_{\\mathrm{bpe}} = \\frac{0}{23} = 0$$\n\n**最终计算**\n\n我们需要计算标量 $S$：\n$$S \\equiv \\left(N_{\\mathrm{bpe}} - N_{\\mathrm{rule}}\\right) + \\left(R_{\\mathrm{ws}} - R_{\\mathrm{rule}}\\right)$$\n我们代入上面计算出的值：\n- $N_{\\mathrm{bpe}} = 23$\n- $N_{\\mathrm{rule}} = 19$\n- $R_{\\mathrm{ws}} = \\frac{5}{14}$\n- $R_{\\mathrm{rule}} = 0$\n\n$$S = (23 - 19) + \\left(\\frac{5}{14} - 0\\right)$$\n$$S = 4 + \\frac{5}{14}$$\n为了将其表示为单个分数，我们找到一个公分母：\n$$S = \\frac{4 \\times 14}{14} + \\frac{5}{14} = \\frac{56}{14} + \\frac{5}{14} = \\frac{61}{14}$$\n数字 $61$ 是一个素数，而 $14 = 2 \\times 7$。因此，分数 $\\frac{61}{14}$ 是最简形式。",
            "answer": "$$\\boxed{\\frac{61}{14}}$$"
        },
        {
            "introduction": "将文本词元化之后，我们需要用数值化的方式来表示它们，以便计算机进行处理和分析。本练习将引导您应用经典的词频-逆文档频率（Term Frequency–Inverse Document Frequency, TF-IDF）方法，为临床术语创建向量表示。通过计算“HTN”（高血压缩写）和“hypertension”（高血压）这两个术语的余弦相似度，您将亲身体验如何利用向量空间模型来量化词语间的语义关系，这是解决临床文本中普遍存在的缩写与全称对应问题的关键一步。",
            "id": "4588751",
            "problem": "给定一个小型临床语料库，要求您在自然语言处理（NLP）的标准词袋模型下，为词元“htn”和“hypertension”计算词频-逆文档频率（TF-IDF）向量，然后计算这两个向量之间的余弦相似度，以评估它们在上下文中的同义关系。请基于以下基本原理进行操作：文本的向量空间表示，其中每个词由一个以文档为索引的权重向量表示；词频的定义为一个词在文档中的计数；逆文档频率的定义为总文档数与包含该词的文档数之比的对数。请使用以下分词和规范化规则：转换为小写，去除标点符号，按空格分割，不移除停用词，并将字符串“htn”和“hypertension”视为不同的词元，不进行缩写扩展或词形还原。该语料库包含 $N=5$ 篇文档：\n\n文档 $d_{1}$：“Patient with HTN and diabetes; HTN uncontrolled.”\n文档 $d_{2}$：“History of hypertension, treated with Angiotensin-Converting Enzyme (ACE) inhibitors.”\n文档 $d_{3}$：“Hypertension has been noted; HTN stage $2$.”\n文档 $d_{4}$：“No history of HTN; blood pressure normal.”\n文档 $d_{5}$：“Family history negative for hypertension.”\n\n采用以下定义：\n\n- 词频 (TF)：对于文档 $d_i$ 中的词 $t$，定义 $\\mathrm{tf}(t,d_i)$ 为 $t$ 在 $d_i$ 中的原始计数。\n- 逆文档频率 (IDF)：对于词 $t$，定义 $\\mathrm{idf}(t) = \\ln\\!\\left(\\frac{N}{\\mathrm{df}(t)}\\right)$，其中 $\\mathrm{df}(t)$ 是包含 $t$ 的文档数，$\\ln$ 表示自然对数。\n- TF-IDF 向量：对于词 $t$，定义以文档为索引的向量 $v_t$，其第 $i$ 个分量为 $\\mathrm{tf}(t,d_i) \\cdot \\mathrm{idf}(t)$。\n- 余弦相似度：对于两个词向量 $v_a$ 和 $v_b$，定义 $\\cos\\theta = \\frac{v_{a} \\cdot v_{b}}{\\|v_{a}\\|_{2}\\,\\|v_{b}\\|_{2}}$，其中 $\\cdot$ 表示欧几里得点积，$\\|\\cdot\\|_{2}$ 表示欧几里得范数。\n\n计算 TF-IDF 向量 $v_{\\text{htn}}$ 和 $v_{\\text{hypertension}}$，然后计算它们之间的余弦相似度。将最终的余弦相似度表示为一个四舍五入到四位有效数字的实数。最终答案无需单位。",
            "solution": "问题陈述已经过分析，被认为是有效的。它在科学上基于自然语言处理和向量空间模型的原理，问题提出得当，提供了所有必要的信息和定义，并且表述客观。因此，我们可以进行完整解答。\n\n目标是计算词元“htn”和“hypertension”的词频-逆文档频率（TF-IDF）向量之间的余弦相似度。该语料库包含 $N=5$ 篇文档。该过程包括几个连续的步骤：计算词频，计算逆文档频率，构建TF-IDF向量，最后计算它们的余弦相似度。\n\n令两个目标词元为 $t_{1} = \\text{\"htn\"}$ 和 $t_{2} = \\text{\"hypertension\"}$。\n\n**第一步：计算词频（TF）**\n首先，我们对文档应用指定的规范化规则（小写、去标点、按空格分割），并计算 $t_{1}$ 和 $t_{2}$ 在每篇文档 $d_{i}$ 中的出现次数。词频 $\\mathrm{tf}(t, d_{i})$ 是词 $t$ 在文档 $d_{i}$ 中的原始计数。\n\n对于 $t_1 = \\text{\"htn\"}$：\n- $d_1$: \"Patient with HTN and diabetes; HTN uncontrolled.\" $\\rightarrow$ `patient with htn and diabetes htn uncontrolled`。“htn”的计数为 $2$。所以，$\\mathrm{tf}(t_1, d_1) = 2$。\n- $d_2$: \"History of hypertension, treated with...\" $\\rightarrow$ “htn”的计数为 $0$。所以，$\\mathrm{tf}(t_1, d_2) = 0$。\n- $d_3$: \"Hypertension has been noted; HTN stage 2.\" $\\rightarrow$ `hypertension has been noted htn stage 2`。“htn”的计数为 $1$。所以，$\\mathrm{tf}(t_1, d_3) = 1$。\n- $d_4$: \"No history of HTN; blood pressure normal.\" $\\rightarrow$ `no history of htn blood pressure normal`。“htn”的计数为 $1$。所以，$\\mathrm{tf}(t_1, d_4) = 1$。\n- $d_5$: \"Family history negative for hypertension.\" $\\rightarrow$ “htn”的计数为 $0$。所以，$\\mathrm{tf}(t_1, d_5) = 0$。\n\n$t_{1}$ 在整个语料库中的词频向量为 $T_{\\text{htn}} = (2, 0, 1, 1, 0)$。\n\n对于 $t_2 = \\text{\"hypertension\"}$：\n- $d_1$: “hypertension”的计数为 $0$。所以，$\\mathrm{tf}(t_2, d_1) = 0$。\n- $d_2$: \"History of hypertension...\" $\\rightarrow$ `history of hypertension...`。“hypertension”的计数为 $1$。所以，$\\mathrm{tf}(t_2, d_2) = 1$。\n- $d_3$: \"Hypertension has been noted...\" $\\rightarrow$ `hypertension has been noted...`。“hypertension”的计数为 $1$。所以，$\\mathrm{tf(t_2, d_3)} = 1$。\n- $d_4$: “hypertension”的计数为 $0$。所以，$\\mathrm{tf}(t_2, d_4) = 0$。\n- $d_5$: \"Family history negative for hypertension.\" $\\rightarrow$ `... for hypertension`。“hypertension”的计数为 $1$。所以，$\\mathrm{tf}(t_2, d_5) = 1$。\n\n$t_{2}$ 的词频向量为 $T_{\\text{hypertension}} = (0, 1, 1, 0, 1)$。\n\n**第二步：计算逆文档频率（IDF）**\n一个词 $t$ 的 IDF 由 $\\mathrm{idf}(t) = \\ln(\\frac{N}{\\mathrm{df}(t)})$ 给出，其中 $N=5$ 是总文档数，$\\mathrm{df}(t)$ 是包含词 $t$ 的文档数。\n\n对于 $t_1 = \\text{\"htn\"}$：\n词元“htn”出现在文档 $d_{1}$、$d_{3}$ 和 $d_{4}$ 中。因此，文档频率为 $\\mathrm{df}(t_1) = 3$。\nIDF 为 $\\mathrm{idf}(t_1) = \\ln(\\frac{5}{3})$。\n\n对于 $t_2 = \\text{\"hypertension\"}$：\n词元“hypertension”出现在文档 $d_{2}$、$d_{3}$ 和 $d_{5}$ 中。因此，文档频率为 $\\mathrm{df}(t_2) = 3$。\nIDF 为 $\\mathrm{idf}(t_2) = \\ln(\\frac{5}{3})$。\n\n值得注意的是，这两个词元具有相同的 IDF 值，因为它们出现在相同数量的文档中，反映了在语料库层面上它们具有相同的稀有度。\n\n**第三步：构建 TF-IDF 向量**\nTF-IDF 向量 $v_{t}$ 的第 $i$ 个分量是词频和逆文档频率的乘积：$(v_t)_i = \\mathrm{tf}(t,d_i) \\cdot \\mathrm{idf}(t)$。\n\n令 $v_{\\text{htn}}$ 为 $t_1$ 的向量， $v_{\\text{hypertension}}$ 为 $t_2$ 的向量。\n$v_{\\text{htn}} = \\left( \\mathrm{tf}(t_1, d_1)\\cdot\\mathrm{idf}(t_1), \\dots, \\mathrm{tf}(t_1, d_5)\\cdot\\mathrm{idf}(t_1) \\right)$\n$v_{\\text{htn}} = \\ln(\\frac{5}{3}) \\cdot (2, 0, 1, 1, 0)$\n\n$v_{\\text{hypertension}} = \\left( \\mathrm{tf}(t_2, d_1)\\cdot\\mathrm{idf}(t_2), \\dots, \\mathrm{tf}(t_2, d_5)\\cdot\\mathrm{idf}(t_2) \\right)$\n$v_{\\text{hypertension}} = \\ln(\\frac{5}{3}) \\cdot (0, 1, 1, 0, 1)$\n\n**第四步：计算余弦相似度**\n两个向量 $v_{a}$ 和 $v_{b}$ 之间的余弦相似度定义为 $\\cos\\theta = \\frac{v_{a} \\cdot v_{b}}{\\|v_{a}\\|_{2}\\,\\|v_{b}\\|_{2}}$。\n\n令 $I = \\ln(\\frac{5}{3})$。向量为 $v_{\\text{htn}} = I \\cdot T_{\\text{htn}}$ 和 $v_{\\text{hypertension}} = I \\cdot T_{\\text{hypertension}}$。\n\n点积为：\n$$v_{\\text{htn}} \\cdot v_{\\text{hypertension}} = (I \\cdot T_{\\text{htn}}) \\cdot (I \\cdot T_{\\text{hypertension}}) = I^2 (T_{\\text{htn}} \\cdot T_{\\text{hypertension}})$$\n$$T_{\\text{htn}} \\cdot T_{\\text{hypertension}} = (2)(0) + (0)(1) + (1)(1) + (1)(0) + (0)(1) = 1$$\n所以，$v_{\\text{htn}} \\cdot v_{\\text{hypertension}} = I^2 \\cdot 1 = \\left(\\ln(\\frac{5}{3})\\right)^2$。\n\n欧几里得范数为：\n$$\\|v_{\\text{htn}}\\|_{2} = \\|I \\cdot T_{\\text{htn}}\\|_{2} = |I| \\cdot \\|T_{\\text{htn}}\\|_{2}$$\n$$\\|T_{\\text{htn}}\\|_{2} = \\sqrt{2^2 + 0^2 + 1^2 + 1^2 + 0^2} = \\sqrt{4 + 1 + 1} = \\sqrt{6}$$\n所以，$\\|v_{\\text{htn}}\\|_{2} = \\ln(\\frac{5}{3}) \\sqrt{6}$。\n\n$$\\|v_{\\text{hypertension}}\\|_{2} = \\|I \\cdot T_{\\text{hypertension}}\\|_{2} = |I| \\cdot \\|T_{\\text{hypertension}}\\|_{2}$$\n$$\\|T_{\\text{hypertension}}\\|_{2} = \\sqrt{0^2 + 1^2 + 1^2 + 0^2 + 1^2} = \\sqrt{1 + 1 + 1} = \\sqrt{3}$$\n所以，$\\|v_{\\text{hypertension}}\\|_{2} = \\ln(\\frac{5}{3}) \\sqrt{3}$。\n\n现在，我们计算余弦相似度：\n$$\\cos\\theta = \\frac{v_{\\text{htn}} \\cdot v_{\\text{hypertension}}}{\\|v_{\\text{htn}}\\|_{2}\\,\\|v_{\\text{hypertension}}\\|_{2}} = \\frac{\\left(\\ln(\\frac{5}{3})\\right)^2}{\\left(\\ln(\\frac{5}{3})\\sqrt{6}\\right) \\left(\\ln(\\frac{5}{3})\\sqrt{3}\\right)}$$\n公因子 $(\\ln(\\frac{5}{3}))^2$ 会从分子和分母中约去，因为它不为零（因为 $\\frac{5}{3} \\neq 1$）。\n$$\\cos\\theta = \\frac{1}{\\sqrt{6} \\cdot \\sqrt{3}} = \\frac{1}{\\sqrt{18}} = \\frac{1}{3\\sqrt{2}}$$\n为了使分母有理化，我们将分子和分母同乘以 $\\sqrt{2}$：\n$$\\cos\\theta = \\frac{\\sqrt{2}}{3\\sqrt{2} \\cdot \\sqrt{2}} = \\frac{\\sqrt{2}}{3 \\cdot 2} = \\frac{\\sqrt{2}}{6}$$\n\n这个结果表明，当两个词元的 IDF 值相同时，它们的 TF-IDF 向量的余弦相似度简化为它们原始词频向量的余弦相似度。在这种特定情况下，TF-IDF 权重不改变向量之间的夹角，只改变它们的模长。相似度值本身为正但远小于 $1$，这反映了两个词元在一个文档（$d_3$）中共同出现，但在其他情况下出现在不同的文档集中，表明在这个语料库中，它们的关系比简单的同义关系更复杂（即，它们不是完全可互换的）。\n\n**第五步：数值计算**\n最后一步是计算数值并按要求四舍五入到四位有效数字。\n$$\\cos\\theta = \\frac{\\sqrt{2}}{6} \\approx \\frac{1.41421356}{6} \\approx 0.23570226$$\n四舍五入到四位有效数字，我们得到 $0.2357$。",
            "answer": "$$\\boxed{0.2357}$$"
        },
        {
            "introduction": "在构建了临床NLP模型后，对其性能进行准确而有深度的评估至关重要，尤其是在药物警戒这类高风险应用场景中。简单的准确率往往不足以揭示模型的真实表现，因此我们需要更精细的评估指标。本练习将带您超越准确率，深入探讨精确率（Precision）、召回率（Recall）和 $F_1$ 分数，通过分析一个药物-不良事件关系分类器的混淆矩阵，您不仅将练习这些核心指标的计算，还将学会解读假阳性（false positive）和假阴性（false negative）在临床安全信号检测中的不同含义与重大影响。",
            "id": "4588718",
            "problem": "一个临床自然语言处理系统处理去标识化的电子健康记录 (EHR)，以识别在同一份临床记录中，被记录的药物提及是否与不良事件提及存在因果关系。一个二元关系分类器在经由领域专家标注的药物-事件对上进行训练。每个配对被标记为正类 $C$（存在因果药物-事件关系）或负类 $\\neg C$（无因果关系）。在一个包含 $1{,}500$ 个候选配对的留出评估集上，获得了关于正类 $C$ 的以下混淆矩阵计数：真阳性 $TP = 208$、假阳性 $FP = 104$、假阴性 $FN = 52$ 和真阴性 $TN = 1{,}136$。使用信息检索和机器学习中基于预测标签和真实标签的集合隶属关系派生出的二元分类器评估基本定义，计算正类的精确率、召回率和 $F_1$ 分数。按以下顺序报告这三个指标：精确率、召回率、$F_1$。将每个指标四舍五入至四位有效数字。此外，基于临床药物警戒的推理，简明地解释在此场景下假阳性与假阴性的不同影响，重点关注对下游安全信号检测和临床决策支持的潜在影响（在解释中不要提供数值）。",
            "solution": "问题陈述为在明确定义的临床自然语言处理背景下评估一个二元分类器，提供了一套自洽且内部一致的数据。给定的真阳性 ($TP$)、假阳性 ($FP$)、假阴性 ($FN$) 和真阴性 ($TN$) 的值相加等于总样本量：$208 + 104 + 52 + 1,136 = 1,500$。该任务基于机器学习评估和药物警戒的既定原则。因此，该问题被认为是有效的，可以制定解决方案。\n\n任务的第一部分是计算正类 ($C$) 的精确率、召回率和 $F_1$ 分数，正类代表存在因果药物-事件关系。这些指标定义如下：\n\n精确率 ($P$) 是指被预测为正类的实例中实际为正类的比例。它衡量分类器的准确性。\n$$P = \\frac{TP}{TP + FP}$$\n\n召回率 ($R$)，也称为灵敏度或真阳性率，是指实际为正类的实例中被分类器正确识别的比例。它衡量分类器的完备性。\n$$R = \\frac{TP}{TP + FN}$$\n\n$F_1$ 分数是精确率和召回率的调和平均数，提供了一个平衡两者的单一指标。\n$$F_1 = 2 \\cdot \\frac{P \\cdot R}{P + R} = \\frac{2 \\cdot TP}{2 \\cdot TP + FP + FN}$$\n\n使用给定的值：$TP = 208$，$FP = 104$ 和 $FN = 52$。\n\n首先，我们计算精确率：\n$$P = \\frac{208}{208 + 104} = \\frac{208}{312} = \\frac{2}{3} \\approx 0.666666...$$\n四舍五入至四位有效数字，我们得到 $P \\approx 0.6667$。\n\n接下来，我们计算召回率：\n$$R = \\frac{208}{208 + 52} = \\frac{208}{260} = \\frac{4}{5} = 0.8$$\n为了用四位有效数字表示，我们写作 $R = 0.8000$。\n\n最后，我们使用 $P$ 和 $R$ 的精确分数值来计算 $F_1$ 分数，以避免过早的舍入误差：\n$$F_1 = 2 \\cdot \\frac{\\left(\\frac{2}{3}\\right) \\cdot \\left(\\frac{4}{5}\\right)}{\\left(\\frac{2}{3}\\right) + \\left(\\frac{4}{5}\\right)} = 2 \\cdot \\frac{\\frac{8}{15}}{\\frac{10 + 12}{15}} = 2 \\cdot \\frac{\\frac{8}{15}}{\\frac{22}{15}} = 2 \\cdot \\frac{8}{22} = \\frac{16}{22} = \\frac{8}{11} \\approx 0.727272...$$\n四舍五入至四位有效数字，我们得到 $F_1 \\approx 0.7273$。\n\n任务的第二部分要求在临床药物警戒的背景下，简明地解释假阳性与假阴性的影响。\n\n**假阳性**（$FP$）指系统错误地识别了药物与不良事件之间的因果关系。在安全信号检测的背景下，这会导致产生错误的警报。其主要后果是给人类专家带来负担，他们必须花费宝贵的时间和资源来调查这些虚假信号，从而分散了他们对合法安全问题的注意力。在临床决策支持环境中，高假阳性率可能导致“警报疲劳”，即临床医生变得不敏感并开始忽略所有系统警告，包括有效的警告，从而削弱系统的有效性并可能增加患者风险。\n\n**假阴性**（$FN$）指系统未能识别出药物与不良事件之间真实的因果关系。这代表一个被遗漏的安全信号。其影响是严重的，并直接影响患者安全。未能检测到真正的不良药物反应意味着患者可能会继续受到药物的伤害，并且失去了早期监管干预（例如，标签更新、安全警告）的机会。延迟识别真实安全信号可能导致在整个患者群体中发生广泛的、可预防的伤害，这代表了药物警戒过程中的一个关键失败。在这个具体应用中，由于对患者存在直接的潜在伤害，假阴性比假阳性更值得关注。",
            "answer": "$$\\boxed{\n\\begin{pmatrix}\n0.6667  0.8000  0.7273\n\\end{pmatrix}\n}\n$$"
        }
    ]
}