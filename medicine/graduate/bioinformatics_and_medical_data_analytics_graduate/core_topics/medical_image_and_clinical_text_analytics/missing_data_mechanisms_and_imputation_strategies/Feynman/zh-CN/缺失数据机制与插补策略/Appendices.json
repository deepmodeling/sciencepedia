{
    "hands_on_practices": [
        {
            "introduction": "多重插补（Multiple Imputation, MI）是一种强大而灵活的处理缺失数据的方法，其核心在于如何正确地整合来自多个插补数据集的分析结果。本练习将引导你从第一性原理出发，推导并应用鲁宾法则（Rubin's rules），这是多重插补推断的基石。通过这项练习，你将深入理解总方差的构成，并能清晰地区分由抽样本身带来的“插补内”方差，以及由数据缺失引入的额外不确定性，即“插补间”方差。",
            "id": "4584865",
            "problem": "一项临床生物标志物研究使用逻辑回归检验基因表达生物标志物与二元疾病结局之间的关联。由于生物标志物测量值存在缺失，该分析在随机缺失 (MAR) 假设下，采用适当插补法使用多重插补 (MI) 进行处理。设 $Q$ 表示一个标量回归系数（对数优势比标度）。在用于 MI 的贝叶斯后验预测框架下，每个完整数据集 $j \\in \\{1,\\dots,m\\}$ 都会产生一个估计值 $Q^{(j)}$ 及其对应的完整数据方差估计值 $U^{(j)}$。假设 $Q$ 具有大样本近似正态性，且各次插补相互独立。\n\n任务：\n1) 从基于观测数据的 $Q$ 的全方差定律出发，推导 MI 点估计总方差的大样本估计量，该估计量结合了平均完整数据方差和插补间变异性。识别出用于解释仅使用 $m$ 次插补所引入的蒙特卡洛误差的有限-$m$校正。清晰解释插补内方差和插补间方差在此分解中的不同作用，并分析插补次数 $m$ 如何影响蒙特卡洛误差部分。\n\n2) 在一项使用 $m=10$ 次插补的具体分析中，标量估计值和完整数据方差如下：\n- $Q^{(1)}=0.72$, $U^{(1)}=0.038$\n- $Q^{(2)}=0.80$, $U^{(2)}=0.041$\n- $Q^{(3)}=0.85$, $U^{(3)}=0.040$\n- $Q^{(4)}=0.90$, $U^{(4)}=0.039$\n- $Q^{(5)}=0.88$, $U^{(5)}=0.042$\n- $Q^{(6)}=0.79$, $U^{(6)}=0.037$\n- $Q^{(7)}=0.92$, $U^{(7)}=0.040$\n- $Q^{(8)}=0.86$, $U^{(8)}=0.039$\n- $Q^{(9)}=0.81$, $U^{(9)}=0.040$\n- $Q^{(10)}=0.87$, $U^{(10)}=0.041$\n\n计算缺失信息分数，其定义为由数据缺失引起的额外方差与第 (1) 部分推导出的总方差之比。最终数值答案以小数形式表示，并四舍五入至 $4$ 位有效数字。请勿在最终答案中使用百分号。",
            "solution": "本题旨在探讨合并多重插补 (MI) 结果的原则，MI 是统计分析中处理缺失数据的标准技术。答案按要求分为两部分呈现。\n\n### 第 1 部分：总方差估计量的推导与分析\n\n设 $Y$ 代表完整数据集，它可以被划分为观测数据 $Y_{obs}$ 和缺失数据 $Y_{mis}$。设 $Q$ 为我们感兴趣的标量，在本例中是逻辑回归模型的一个回归系数。MI 的目标是基于 $Y_{obs}$ 对 $Q$ 进行推断。\n\n在 MI 的贝叶斯框架中，我们关心的是给定观测数据下 $Q$ 的后验分布 $p(Q|Y_{obs})$。该分布的均值是 $Q$ 的点估计，其方差 $\\text{Var}(Q|Y_{obs})$ 代表了关于 $Q$ 的总不确定性。\n\n多重插补过程包括三个步骤：\n1.  从缺失数据的后验预测分布 $p(Y_{mis}|Y_{obs})$ 中抽样，对缺失值进行 $m$ 次插补，从而创建 $m$ 个完整数据集 $\\{(Y_{obs}, Y_{mis}^{(1)}), ..., (Y_{obs}, Y_{mis}^{(m)})\\}$。\n2.  使用标准的完整数据分析方法分析这 $m$ 个完整数据集中的每一个。对于每个数据集 $j$，该步骤会得出一个点估计 $Q^{(j)}$ 及其相关的方差估计 $U^{(j)}$。\n3.  将 $m$ 次的结果合并成一组估计值和置信区间。$Q$ 的 MI 点估计是个体估计值的平均值：\n    $$ \\bar{Q}_m = \\frac{1}{m} \\sum_{j=1}^{m} Q^{(j)} $$\n\n为了推导该估计量的总方差，我们从应用于给定 $Y_{obs}$ 的 $Q$ 的后验分布的全方差定律开始：\n$$ \\text{Var}(Q|Y_{obs}) = E[\\text{Var}(Q|Y_{obs}, Y_{mis})] + \\text{Var}(E[Q|Y_{obs}, Y_{mis}]) $$\n此表达式中的期望和方差是针对给定 $Y_{obs}$ 的 $Y_{mis}$ 的后验分布计算的。我们来分析每一项：\n\n1.  **插补内方差**：第一项 $E[\\text{Var}(Q|Y_{obs}, Y_{mis})]$ 代表平均完整数据方差。量 $\\text{Var}(Q|Y_{obs}, Y_{mis})$ 是在数据完整（即，如果我们知道 $Y_{mis}$）的情况下 $Q$ 的方差。这是由有限抽样导致的不确定性的来源，即使在没有缺失数据的情况下也固有存在。在单个完整数据集 $j$ 中，该方差的估计量是 $U^{(j)}$。通过对 $m$ 次插补的结果取平均，我们得到期望完整数据方差的估计值：\n    $$ \\bar{U}_m = \\frac{1}{m} \\sum_{j=1}^{m} U^{(j)} $$\n    这被称为**插补内方差**，因为它捕捉了每个完整数据集*内部*的平均抽样方差。\n\n2.  **插补间方差**：第二项 $\\text{Var}(E[Q|Y_{obs}, Y_{mis}])$ 代表因缺失数据 $Y_{mis}$ 未知而产生的额外方差。点估计 $E[Q|Y_{obs}, Y_{mis}]$ 会根据为 $Y_{mis}$ 插补的具体数值而改变。因此，这些点估计在 $Y_{mis}$ 的后验预测分布上的方差量化了由数据缺失导致的不确定性。我们通过 $m$ 个点估计 $Q^{(j)}$ 在其均值 $\\bar{Q}_m$ 周围的变异性来估计该方差：\n    $$ B_m = \\frac{1}{m-1} \\sum_{j=1}^{m} (Q^{(j)} - \\bar{Q}_m)^2 $$\n    这就是**插补间方差**。它直接反映了因数据缺失而引入的额外不确定性。如果没有缺失数据，所有的 $Q^{(j)}$ 都会相同，而 $B_m$ 将为 $0$。\n\n结合这些分量，$Q$ 的总后验方差估计为插补内方差和插补间方差之和：$T \\approx \\bar{U}_m + B_m$。然而，我们使用的 MI 估计量 $\\bar{Q}_m$ 本身是基于有限次数 $m$ 次插补的样本均值。这引入了额外的蒙特卡洛模拟误差。估计量 $\\bar{Q}_m$ 的方差不仅包括 $Q$ 的后验方差，还包括使用有限插补样本所带来的方差。\n\n用于构建置信区间和进行假设检验的 $\\bar{Q}_m$ 的方差估计量必须考虑到这一点。因此，总方差估计量（记为 $T_m$）由鲁宾法则 (Rubin's rule) 给出：\n$$ T_m = \\bar{U}_m + B_m + \\frac{B_m}{m} = \\bar{U}_m + \\left(1 + \\frac{1}{m}\\right)B_m $$\n在此，$\\frac{B_m}{m}$ 项是**有限-$m$校正**。它明确地解释了因使用有限次而非无限次插补所引入的蒙特卡洛误差。\n\n插补次数 $m$ 直接影响这个蒙特卡洛误差分量。随着 $m$ 的增加，$\\frac{B_m}{m}$ 项减小并趋近于 $0$。对于无限大的 $m$，总方差将为 $T_\\infty = \\bar{U}_\\infty + B_\\infty$，它代表给定观测数据下 $Q$ 的真实后验方差。一个较小的 $m$ 值会导致较大的蒙特卡洛误差，从而使得总方差的估计不那么精确（即方差更高）且可复现性较差。一个较大的 $m$ 值则会减少这种模拟误差，从而产生更稳定和可靠的推断。\n\n### 第 2 部分：缺失信息分数的计算\n\n给定来自 $m=10$ 次插补的数据。我们将首先计算必要的组成部分：平均插补内方差（$\\bar{U}_{10}$）和插补间方差（$B_{10}$）。\n\nMI 点估计为：\n$$ \\bar{Q}_{10} = \\frac{1}{10} \\sum_{j=1}^{10} Q^{(j)} = \\frac{1}{10}(0.72 + 0.80 + 0.85 + 0.90 + 0.88 + 0.79 + 0.92 + 0.86 + 0.81 + 0.87) = \\frac{8.40}{10} = 0.84 $$\n\n平均插补内方差为：\n$$ \\bar{U}_{10} = \\frac{1}{10} \\sum_{j=1}^{10} U^{(j)} = \\frac{1}{10}(0.038 + 0.041 + 0.040 + 0.039 + 0.042 + 0.037 + 0.040 + 0.039 + 0.040 + 0.041) = \\frac{0.397}{10} = 0.0397 $$\n\n插补间方差为：\n$$ B_{10} = \\frac{1}{10-1} \\sum_{j=1}^{10} (Q^{(j)} - \\bar{Q}_{10})^2 $$\n平方偏差和为：\n$$ \\sum (Q^{(j)} - 0.84)^2 = (-0.12)^2 + (-0.04)^2 + (0.01)^2 + (0.06)^2 + (0.04)^2 + (-0.05)^2 + (0.08)^2 + (0.02)^2 + (-0.03)^2 + (0.03)^2 $$\n$$ \\sum (Q^{(j)} - 0.84)^2 = 0.0144 + 0.0016 + 0.0001 + 0.0036 + 0.0016 + 0.0025 + 0.0064 + 0.0004 + 0.0009 + 0.0009 = 0.0324 $$\n因此，\n$$ B_{10} = \\frac{0.0324}{9} = 0.0036 $$\n\n接下来，我们使用第 1 部分中推导的公式，并代入 $m=10$ 来计算总方差：\n$$ T_{10} = \\bar{U}_{10} + \\left(1 + \\frac{1}{10}\\right)B_{10} = 0.0397 + (1.1)(0.0036) = 0.0397 + 0.00396 = 0.04366 $$\n\n题目将缺失信息分数 (FMI) 定义为由数据缺失引起的额外方差与推导出的总方差之比。总方差是 $T_{10}$。 “由数据缺失引起的额外方差”是总方差中如果数据完整就会消失的那一部分。这对应于插补间方差和蒙特卡洛校正项之和，即 $(1 + 1/m)B_m$。\n\n因此，缺失信息分数的计算如下：\n$$ \\text{FMI} = \\frac{(1 + 1/m)B_m}{T_m} = \\frac{(1 + 1/10)B_{10}}{T_{10}} $$\n$$ \\text{FMI} = \\frac{0.00396}{0.04366} \\approx 0.09070087036... $$\n\n将此结果四舍五入至 $4$ 位有效数字，我们得到 $0.09070$。",
            "answer": "$$\\boxed{0.09070}$$"
        },
        {
            "introduction": "虽然标准的多重插补合并规则功能强大，但它们依赖于大样本近似。在样本量较小或缺失信息比例较高的情况下，直接使用正态分布进行推断可能会导致过于乐观的结论。本练习将探讨在小样本情况下对多重插补推断进行的关键修正，特别是引入巴纳德-鲁宾（Barnard-Rubin）自由度调整。此外，练习还将解决一个非常实际的问题：如何选择足够数量的插补次数 $m$，以将蒙特卡洛误差控制在可接受范围内，从而将理论概念与高效的研究实践联系起来。",
            "id": "4584877",
            "problem": "一项初步的临床蛋白质基因组学研究使用线性回归来探究对数转换后的蛋白质丰度与定量炎症评分之间的关联。由于样本处理失败，很高比例的蛋白质测量值缺失，这些缺失可认为是随机缺失（Missing At Random, MAR）。为了在随机缺失（MAR）的假设下获得有效的推断，分析师采用多重插补法（Multiple Imputation, MI），生成了 $m = 5$ 个完整数据集。对于感兴趣的标量系数 $Q$（蛋白质丰度的斜率），分析师记录了每次插补的点估计值及其对应的完整数据方差如下：\n- 完整数据点估计值：$Q_{1} = 0.55$，$Q_{2} = 0.95$，$Q_{3} = 1.10$，$Q_{4} = 0.58$，$Q_{5} = 1.02$。\n- 插补内方差：$U_{1} = 0.043$，$U_{2} = 0.047$，$U_{3} = 0.045$，$U_{4} = 0.044$，$U_{5} = 0.046$。\n\n假设线性模型在完整数据下的自由度为 $\\nu_{\\mathrm{com}} = 20$（例如，$n = 24$ 个观测值和 $p = 4$ 个参数，包括截距，因此 $n - p = 20$）。仅使用定义和公认的多重插补（MI）合并原则（不使用问题中提供的简化公式），完成以下任务：\n\n1. 推导 $Q$ 的合并估计值 $\\,\\bar{Q}\\,$、平均插补内方差 $\\,\\bar{U}\\,$、插补间方差 $\\,B\\,$ 和总多重插补方差 $\\,T\\,$。\n2. 采用合理的小样本理论，推导 Barnard–Rubin (BR) 自由度调整，并基于带有 BR 自由度的 $t$ 分布计算 $Q$ 的双侧 $95$ 置信区间。同时，使用将标准化估计量近似视为正态分布的标准大样本 MI 近似法计算相应的 $95$ 置信区间。说明哪个区间更宽。\n3. 通过将插补间不确定性对蒙特卡洛方差的贡献近似为 $\\left(1 + \\frac{1}{m}\\right)\\frac{B}{m}$，来分析有限的 $m$ 对蒙特卡洛不确定性的影响。选择 $m$ 以确保蒙特卡洛标准误差不大于第一部分中推导出的 MI 标准误差 $\\sqrt{T}$ 的 $0.05$ 倍。将此要求表示为关于 $m$ 的不等式，求解满足该不等式的最小整数 $m$，并报告该整数。\n\n在代入数值之前，以符号形式给出所有中间推导过程。最终答案必须是第三部分中描述的单个整数 $m$。不需要单位。如果对分位数进行任何数值近似，可以明确说明该近似，但最终答案必须是满足不等式的最小整数，即为精确解。",
            "solution": "### 第 1 部分：多重插补参数的推导\n\nMI 推断的核心在于根据 Rubin 法则合并来自 $m$ 个完整数据集的结果。\n\n1.  **合并点估计值 ($\\bar{Q}$):** $Q$ 的总点估计值是来自每个插补数据集的单个估计值的算术平均值。\n    $$ \\bar{Q} = \\frac{1}{m} \\sum_{k=1}^{m} Q_k $$\n    代入给定值，其中 $m=5$：\n    $$ \\bar{Q} = \\frac{1}{5} (0.55 + 0.95 + 1.10 + 0.58 + 1.02) = \\frac{4.20}{5} = 0.84 $$\n\n2.  **平均插补内方差 ($\\bar{U}$):** 该方差分量反映了如果我们有一个完整数据集时会存在的抽样变异性。它是从每个插补数据集计算出的 $Q_k$ 方差的平均值。\n    $$ \\bar{U} = \\frac{1}{m} \\sum_{k=1}^{m} U_k $$\n    代入给定值：\n    $$ \\bar{U} = \\frac{1}{5} (0.043 + 0.047 + 0.045 + 0.044 + 0.046) = \\frac{0.225}{5} = 0.045 $$\n\n3.  **插补间方差 ($B$):** 该方差分量反映了由于数据缺失而产生的额外不确定性。它是点估计值 $Q_k$ 的样本方差。\n    $$ B = \\frac{1}{m-1} \\sum_{k=1}^{m} (Q_k - \\bar{Q})^2 $$\n    代入给定值和计算出的 $\\bar{Q}$：\n    $$ B = \\frac{1}{5-1} \\left[ (0.55 - 0.84)^2 + (0.95 - 0.84)^2 + (1.10 - 0.84)^2 + (0.58 - 0.84)^2 + (1.02 - 0.84)^2 \\right] $$\n    $$ B = \\frac{1}{4} \\left[ (-0.29)^2 + (0.11)^2 + (0.26)^2 + (-0.26)^2 + (0.18)^2 \\right] $$\n    $$ B = \\frac{1}{4} [ 0.0841 + 0.0121 + 0.0676 + 0.0676 + 0.0324 ] $$\n    $$ B = \\frac{1}{4} (0.2638) = 0.06595 $$\n\n4.  **总 MI 方差 ($T$):** $\\bar{Q}$ 的总方差是插补内方差和插补间方差之和，并带有一个针对使用有限插补次数 $m$ 的校正因子。\n    $$ T = \\bar{U} + \\left(1 + \\frac{1}{m}\\right) B $$\n    代入计算出的值：\n    $$ T = 0.045 + \\left(1 + \\frac{1}{5}\\right) (0.06595) = 0.045 + (1.2)(0.06595) $$\n    $$ T = 0.045 + 0.07914 = 0.12414 $$\n\n### 第 2 部分：小样本推断和置信区间\n\n对于小样本或少量插补，使用 $t$ 分布进行推断，其自由度经过调整以说明方差估计值 $T$ 的不确定性。\n\n1.  **Barnard-Rubin (BR) 自由度 ($\\nu_{MI}$):** 该调整取决于插补次数 $m$ 和因无响应而导致的信息缺失比例。首先，我们定义 $r_m$，即因无响应导致的方差相对增加量，其值为插补间方差分量与插补内方差的比率。\n    $$ r_m = \\frac{(1 + 1/m)B}{\\bar{U}} $$\n    那么，BR 自由度 $\\nu_{MI}$ 由下式给出：\n    $$ \\nu_{MI} = (m-1) \\left(1 + \\frac{1}{r_m}\\right)^2 = (m-1) \\left(1 + \\frac{\\bar{U}}{(1 + 1/m)B}\\right)^2 $$\n    使用第 1 部分的值：\n    $$ r_m = \\frac{(1.2)(0.06595)}{0.045} = \\frac{0.07914}{0.045} \\approx 1.75867 $$\n    $$ \\nu_{MI} = (5-1) \\left(1 + \\frac{1}{1.75867}\\right)^2 = 4 (1 + 0.56861)^2 = 4 (1.56861)^2 \\approx 4(2.46059) \\approx 9.842 $$\n\n2.  **$95\\%$ 置信区间（基于 $t$ 分布）：** 该置信区间使用具有 $\\nu_{MI}$ 自由度的 $t$ 分布构建。\n    $$ \\bar{Q} \\pm t_{1 - \\alpha/2, \\nu_{MI}} \\sqrt{T} $$\n    对于 $95\\%$ 置信区间，$\\alpha=0.05$，所以我们需要自由度为 $\\nu_{MI} \\approx 9.842$ 的 $t$ 分布的 $0.975$ 分位数。该值为 $t_{0.975, 9.842} \\approx 2.233$。\n    $$ \\mathrm{CI}_{95, t} = 0.84 \\pm 2.233 \\sqrt{0.12414} \\approx 0.84 \\pm 2.233 (0.35234) \\approx 0.84 \\pm 0.7868 $$\n    这给出的区间为 $[0.0532, 1.6268]$。\n\n3.  **$95\\%$ 置信区间（基于正态分布）：** 大样本近似使用标准正态分布。\n    $$ \\bar{Q} \\pm z_{1 - \\alpha/2} \\sqrt{T} $$\n    标准正态分布的 $0.975$ 分位数是 $z_{0.975} \\approx 1.96$。\n    $$ \\mathrm{CI}_{95, z} = 0.84 \\pm 1.96 \\sqrt{0.12414} \\approx 0.84 \\pm 1.96 (0.35234) \\approx 0.84 \\pm 0.6906 $$\n    这给出的区间为 $[0.1494, 1.5306]$。\n\n4.  **比较：** 基于 $t$ 分布的区间宽度为 $2 \\times 0.7868 = 1.5736$。基于正态分布的区间宽度为 $2 \\times 0.6906 = 1.3812$。由于 $t_{0.975, 9.842} \\approx 2.233 > z_{0.975} \\approx 1.96$，基于 Barnard-Rubin 自由度的区间更宽。这反映了用少量插补估计方差所带来的额外不确定性，从而导致更保守的推断。\n\n### 第 3 部分：确定所需的插补次数 ($m$)\n\n问题要求找到最小的整数插补次数 $m$，使得蒙特卡洛标准误差不大于 MI 标准误差的 $0.05$ 倍。我们给出的蒙特卡洛方差贡献公式为 $V_{MC} = \\left(1 + \\frac{1}{m}\\right)\\frac{B}{m}$。MI 标准误差是 $\\sqrt{T}$。问题指定在此计算中使用第 1 部分推导出的 $B$ 和 $T$ 的值（其中 $m=5$）作为固定估计值。\n\n条件是：\n$$ \\sqrt{V_{MC}} \\le 0.05 \\sqrt{T} $$\n代入 $V_{MC}$ 的公式：\n$$ \\sqrt{\\left(1 + \\frac{1}{m}\\right)\\frac{B}{m}} \\le 0.05 \\sqrt{T} $$\n对不等式两边平方：\n$$ \\left(1 + \\frac{1}{m}\\right)\\frac{B}{m} \\le (0.05)^2 T $$\n$$ \\frac{m+1}{m^2} B \\le 0.0025 T $$\n我们可以重新整理以求解 $m$：\n$$ \\frac{m+1}{m^2} \\le 0.0025 \\frac{T}{B} $$\n使用第 1 部分的数值 $B=0.06595$ 和 $T=0.12414$：\n$$ \\frac{T}{B} = \\frac{0.12414}{0.06595} \\approx 1.882335 $$\n$$ \\frac{m+1}{m^2} \\le 0.0025 \\times 1.882335 \\approx 0.0047058 $$\n设 $f(m) = \\frac{m+1}{m^2}$。当 $m \\ge 1$ 时，该函数是递减的。我们需要找到满足此不等式的最小整数 $m$。我们可以测试整数值：\n-   对于 $m=213$，$f(213) = \\frac{213+1}{213^2} = \\frac{214}{45369} \\approx 0.0047168$，大于 $0.0047058$。\n-   对于 $m=214$，$f(214) = \\frac{214+1}{214^2} = \\frac{215}{45796} \\approx 0.0046949$，小于 $0.0047058$。\n\n或者，我们求解等式 $C m^2 - m - 1 = 0$，其中 $C = 0.0047058$。正根为 $m = \\frac{1 + \\sqrt{1+4C}}{2C}$。\n$$ m = \\frac{1 + \\sqrt{1 + 4(0.0047058)}}{2(0.0047058)} = \\frac{1 + \\sqrt{1.0188232}}{0.0094116} \\approx \\frac{1 + 1.0093677}{0.0094116} \\approx \\frac{2.0093677}{0.0094116} \\approx 213.49 $$\n由于 $f(m)$ 是一个递减函数，我们需要 $m \\ge 213.49$。满足此条件的最小整数 $m$ 是 $214$。",
            "answer": "$$\\boxed{214}$$"
        },
        {
            "introduction": "大多数标准的插补方法，包括多重插补，都依赖于一个核心假设：数据是随机缺失（Missing At Random, MAR）的。然而，这个假设在现实中往往无法被严格检验，使得分析结果的稳健性存疑。本高级编程练习将带你进入缺失数据分析的前沿领域——非随机缺失（Missing Not At Random, MNAR）的敏感性分析。通过亲手实现模式混合模型（pattern-mixture model）和选择模型（selection model），你将学会如何量化MNAR偏离对研究结论的潜在影响，这是进行严谨科学推断的一项关键技能。",
            "id": "4584871",
            "problem": "您的任务是设计并实现一个完整的、可运行的程序，该程序在连续结局的医疗数据环境中执行两种非随机缺失（MNAR）敏感性分析：一种是模式混合 delta 调整临界点分析，另一种是使用选择偏倚函数的选择模型敏感性分析。所有任务都必须使用根据基本统计学原理生成的合成数据来执行。程序必须按指定的格式和数值生成单行输出。下文中的每个数学符号、变量、函数、运算符和数字都以 LaTeX 格式表示。不涉及任何物理单位。\n\n问题背景与基本基础。考虑一个在线性回归下建模的连续临床结局。令 $Y \\in \\mathbb{R}$ 表示连续终点，$T \\in \\{0,1\\}$ 表示治疗指示变量，$Z \\in \\mathbb{R}$ 表示基线协变量，$R \\in \\{0,1\\}$ 表示响应指示变量，其中 $R=1$ 意味着结局被观测到。假设完整数据生成遵循线性模型 $Y = \\beta_0 + \\beta_1 T + \\beta_2 Z + \\varepsilon$，其中 $\\varepsilon \\sim \\mathcal{N}(0,\\sigma^2)$，$T \\sim \\mathrm{Bernoulli}(0.5)$，$Z \\sim \\mathcal{N}(0,1)$。缺失指示变量 $R$ 遵循一个依赖于 $Y$ 的逻辑斯蒂选择模型：$\\operatorname{logit}\\, \\mathbb{P}(R=1 \\mid Y=y) = \\alpha + \\gamma \\, g(y)$，其中 $g(y)$ 是一个指定的选择偏倚函数，$\\gamma$ 是敏感性参数，且 $\\operatorname{logit}(p) = \\log\\{p/(1-p)\\}$。\n\n模式混合 delta 调整。在模式混合的视角下，假设对于治疗组 $T=1$ 中结局缺失的受试者（$R=0$），其填补结局值被一个偏移量 $\\delta$ 所移动（而对于 $T=0$ 的受试者则不移动）。随机缺失（MAR）下的填补使用在观测数据上拟合的线性回归来生成条件均值填补；然后，通过将 $\\delta$ 加到 $T=1$ 组中脱落者的填补值上，来编码 MNAR 敏感性。将临界点定义为（在指定搜索区间内）使得拟合的治疗系数 $\\hat{\\beta}_1(\\delta)$ 的符号相对于其在 $\\delta=0$ 时的值发生改变的最小 $\\delta$。我们约定，负的 $\\beta_1$ 对应于有益的效应。\n\n选择模型敏感性。在选择模型 $\\operatorname{logit}\\, \\mathbb{P}(R=1 \\mid Y=y) = \\alpha + \\gamma g(y)$ 和选定的 $g(y)$ 下，假设 $X=(1,T,Z)^\\top$ 被完全观测到，且缺失仅依赖于 $Y$。迭代期望定律和逆概率加权逻辑是其基础，即对于任何形式为 $\\mathbb{E}[X\\{Y - X^\\top \\beta\\}] = 0$ 的完整数据估计方程，可以通过使用权重 $w(y) = 1/\\mathbb{P}(R=1 \\mid Y=y)$ 在观测数据上构建一个加权估计方程，以恢复完整数据的矩条件。要在固定 $\\gamma$ 的有限样本中实现这一点，必须使用选择模型和观测结局，根据观测到的响应比例来一致地确定 $\\alpha$，然后执行加权最小二乘法来估计感兴趣的回归系数（治疗效应 $\\beta_1$）。选择偏倚函数被选为 $g(y) = \\{y - \\bar{y}_{\\mathrm{obs}}\\}/s_{\\mathrm{obs}}$，其中 $\\bar{y}_{\\mathrm{obs}}$ 和 $s_{\\mathrm{obs}}$ 分别是观测到的 $Y$ 值的经验均值和经验标准差。\n\n要实现的任务。您的程序必须：\n\n1. 为每个测试用例生成数据。对于每个测试用例，按如下方式生成 $n$ 个独立观测值：抽取 $T_i \\sim \\mathrm{Bernoulli}(0.5)$、$Z_i \\sim \\mathcal{N}(0,1)$、$\\varepsilon_i \\sim \\mathcal{N}(0,\\sigma^2)$，然后计算 $Y_i = \\beta_0 + \\beta_1 T_i + \\beta_2 Z_i + \\varepsilon_i$。使用全部 $n$ 个结局的经验均值 $\\bar{Y}$ 和经验标准差 $s_Y$ 来定义 $g_i = \\{Y_i - \\bar{Y}\\}/s_Y$。固定一个目标观测比例 $p_{\\mathrm{obs}} \\in (0,1)$ 和一个真实的选择斜率 $\\gamma_{\\mathrm{true}}$，然后求解 $\\alpha_{\\mathrm{true}}$，使得样本平均响应概率等于 $p_{\\mathrm{obs}}$，即 $\\frac{1}{n} \\sum_{i=1}^n \\operatorname{expit}(\\alpha_{\\mathrm{true}} + \\gamma_{\\mathrm{true}} g_i) = p_{\\mathrm{obs}}$，其中 $\\operatorname{expit}(x) = \\{1+\\exp(-x)\\}^{-1}$。然后，独立地抽取 $R_i \\sim \\mathrm{Bernoulli}(\\operatorname{expit}(\\alpha_{\\mathrm{true}} + \\gamma_{\\mathrm{true}} g_i))$。对于回归和填补任务，只有 $\\{(T_i,Z_i,Y_i): R_i=1\\}$ 是可观测的。\n\n2. 模式混合 delta 调整临界点。仅使用观测数据 $(R=1)$ 拟合 $Y$ 对 $(1,T,Z)$ 的线性回归，以获得一个 MAR 填补模型（条件均值模型）。对于每个缺失的结局（$R=0$），使用基于观测数据的回归拟合的条件均值作为填补值 $\\tilde{Y}_i(0)$；然后，对于 $T_i=1$ 且 $R_i=0$ 的个体，定义 $\\tilde{Y}_i(\\delta) = \\tilde{Y}_i(0) + \\delta$，而对于 $T_i=0$ 且 $R_i=0$ 的个体，保持 $\\tilde{Y}_i(\\delta) = \\tilde{Y}_i(0)$。通过在 $R_i=1$ 时取 $Y_i$、在 $R_i=0$ 时取 $\\tilde{Y}_i(\\delta)$ 的方式，构建一个完整数据集 $Y_i(\\delta)$。使用所有 $n$ 条记录，拟合 $Y(\\delta)$ 对 $(1,T,Z)$ 的线性回归，并将其治疗系数表示为 $\\hat{\\beta}_1(\\delta)$。将临界点定义为 $\\delta \\in [\\delta_{\\min}, \\delta_{\\max}]$ 中使得 $\\hat{\\beta}_1(\\delta)$ 的符号相对于 $\\hat{\\beta}_1(0)$ 发生改变的最小 $\\delta$。如果在 $[\\delta_{\\min}, \\delta_{\\max}]$ 内没有发生符号改变，则报告 $\\mathrm{NaN}$。使用 $\\delta_{\\min}=-5$ 和 $\\delta_{\\max}=5$。\n\n3. 选择模型敏感性网格。使用观测到的结局 $\\{Y_i: R_i=1\\}$，构建 $g_{\\mathrm{obs}}(y) = \\{y - \\bar{y}_{\\mathrm{obs}}\\}/s_{\\mathrm{obs}}$。对于网格 $\\{-2,-1,0,1,2\\}$ 中的每个 $\\gamma$，确定截距 $\\alpha(\\gamma)$，该值由选择模型和观测到的响应比例所隐含，以确保模型与有限样本的响应率兼容。然后计算观测结局的选择概率 $p_i(\\gamma) = \\operatorname{expit}\\{\\alpha(\\gamma) + \\gamma g_{\\mathrm{obs}}(Y_i)\\}$ 和权重 $w_i(\\gamma) = 1/p_i(\\gamma)$。通过求解 $Y$ 对 $(1,T,Z)$ 回归的加权正规方程，在观测数据集上通过加权最小二乘法估计治疗效应 $\\hat{\\beta}_1(\\gamma)$。通过网格上估计值的范围宽度 $\\max_{\\gamma} \\hat{\\beta}_1(\\gamma) - \\min_{\\gamma} \\hat{\\beta}_1(\\gamma)$ 来量化选择模型的影响。\n\n测试套件和输出规范。使用以下三个测试用例，每个用例都由一个元组 $(\\text{种子}, n, \\beta_0, \\beta_1, \\beta_2, \\sigma, \\gamma_{\\mathrm{true}}, p_{\\mathrm{obs}})$ 完全定义：\n\n- 用例 A: $(20251, 1000, 0.0, -0.5, 0.8, 1.0, -1.0, 0.7)$。\n- 用例 B: $(20252, 1000, 0.0, -1.0, 0.5, 1.2, -1.5, 0.6)$。\n- 用例 C: $(20253, 1000, 0.0, -0.2, 0.8, 1.0, 1.0, 0.7)$。\n\n角度单位不适用。不涉及任何物理单位。百分比必须表示为小数；例如，$0.7$ 表示 $70/100$ 的响应比例。\n\n最终输出格式。您的程序应生成单行输出，其中包含用方括号括起来的、以逗号分隔的结果列表。对于每个用例，返回一个双元素列表 $[\\delta^\\star, \\Delta_{\\mathrm{range}}]$，其中 $\\delta^\\star$ 是区间 $[-5,5]$ 内的临界点值（如果未发生变化则为 $\\mathrm{NaN}$），而 $\\Delta_{\\mathrm{range}}$ 是选择模型在网格 $\\{-2,-1,0,1,2\\}$ 上的范围宽度。所有浮点数均需四舍五入至 $4$ 位小数。因此，最终输出必须是形如 $[[\\delta^\\star_A,\\Delta_A],[\\delta^\\star_B,\\Delta_B],[\\delta^\\star_C,\\Delta_C]]$ 的单行文本，并按 A、B、C 的顺序包含三个用例的数值。",
            "solution": "### 原理与方法\n\n#### 1. 数据生成\n\n该问题的基础是一项模拟研究。我们首先生成“完整”数据，然后根据指定的 MNAR 机制引入缺失。\n\n-   **完整数据生成**：我们模拟 $n$ 个受试者。对于每个受试者 $i=1, \\dots, n$：\n    -   从概率为 $0.5$ 的伯努利分布中抽取一个二元治疗指示变量 $T_i$，即 $T_i \\sim \\mathrm{Bernoulli}(0.5)$。\n    -   从标准正态分布中抽取一个连续基线协变量 $Z_i$，即 $Z_i \\sim \\mathcal{N}(0,1)$。\n    -   从均值为 $0$、方差为 $\\sigma^2$ 的正态分布中抽取一个随机误差项 $\\varepsilon_i$，即 $\\varepsilon_i \\sim \\mathcal{N}(0,\\sigma^2)$。\n    -   通过线性模型生成连续结局 $Y_i$：$Y_i = \\beta_0 + \\beta_1 T_i + \\beta_2 Z_i + \\varepsilon_i$。\n\n-   **缺失数据生成 (MNAR)**：缺失机制是 MNAR，因为观测到结局 $Y_i$ 的概率取决于 $Y_i$ 本身的值。响应指示变量 $R_i$（其中如果 $Y_i$ 被观测到则 $R_i=1$，如果缺失则 $R_i=0$）由一个逻辑斯蒂回归模型生成：\n    $$ \\operatorname{logit}\\, \\mathbb{P}(R_i=1 \\mid Y_i=y_i) = \\log\\left(\\frac{\\mathbb{P}(R_i=1 \\mid Y_i=y_i)}{1-\\mathbb{P}(R_i=1 \\mid Y_i=y_i)}\\right) = \\alpha_{\\mathrm{true}} + \\gamma_{\\mathrm{true}} g_i $$\n    其中 $g_i = (Y_i - \\bar{Y})/s_Y$ 是标准化后的结局，$\\operatorname{expit}(x) = (1+e^{-x})^{-1}$ 是逆 logit 函数。参数 $\\gamma_{\\mathrm{true}}$ 控制缺失对 $Y$ 的依赖强度。截距 $\\alpha_{\\mathrm{true}}$ 通过数值方法确定，以确保整个样本中观测数据的预期比例与目标值 $p_{\\text{obs}}$ 相匹配。这是通过求解以下关于 $\\alpha_{\\mathrm{true}}$ 的方程来实现的：\n    $$ \\frac{1}{n} \\sum_{i=1}^n \\operatorname{expit}(\\alpha_{\\mathrm{true}} + \\gamma_{\\mathrm{true}} g_i) = p_{\\mathrm{obs}} $$\n    这是一个关于 $\\alpha_{\\mathrm{true}}$ 的单调函数的求根问题，可以使用像 Brent-Dekker 算法这样的数值方法高效求解。\n\n#### 2. 模式混合 Delta 调整临界点分析\n\n此敏感性分析探讨了如果我们假设治疗组中的缺失结局与随机缺失（MAR）模型所预测的结果有系统性差异，那么治疗效应的估计值会如何变化。\n\n-   **MAR 填补模型**：首先，仅使用观测数据（即 $R_i=1$ 的受试者）拟合一个标准线性回归模型（$Y$ 对 $T$ 和 $Z$）。令估计出的系数为 $\\hat{\\beta}_{\\text{MAR}}$。\n-   **填补**：对于每个结局缺失（$R_i=0$）的受试者 $i$，我们首先根据 MAR 模型的预测生成一个基线填补值 $\\tilde{Y}_i(0)$：$\\tilde{Y}_i(0) = \\hat{\\beta}_{\\text{MAR},0} + \\hat{\\beta}_{\\text{MAR},1} T_i + \\hat{\\beta}_{\\text{MAR},2} Z_i$。\n-   **Delta 调整**：我们引入一个敏感性参数 $\\delta$。对于治疗组中的缺失受试者（$R_i=0, T_i=1$），填补值被调整为 $\\tilde{Y}_i(\\delta) = \\tilde{Y}_i(0) + \\delta$。对于对照组中的缺失受试者（$R_i=0, T_i=0$），填补值保持为 $\\tilde{Y}_i(\\delta) = \\tilde{Y}_i(0)$。\n-   **临界点计算**：使用 $R_i=1$ 时的观测值 $Y_i$ 和 $R_i=0$ 时的填补值 $\\tilde{Y}_i(\\delta)$ 形成一个新的完整数据集 $Y(\\delta)$。对所有 $n$ 个受试者拟合 $Y(\\delta)$ 对 $(1, T, Z)$ 的线性回归，得到治疗效应估计值 $\\hat{\\beta}_1(\\delta)$。\n    关键的是，$\\hat{\\beta}_1(\\delta)$ 是 $\\delta$ 的一个简单线性函数。令 $X$ 为完整的设计矩阵。完整数据向量可以写为 $Y(\\delta) = Y(0) + \\delta \\cdot d$，其中 $d_i = T_i(1-R_i)$。普通最小二乘法（OLS）的估计量为 $\\hat{\\beta}(\\delta) = (X^\\top X)^{-1} X^\\top Y(\\delta) = \\hat{\\beta}(0) + \\delta (X^\\top X)^{-1} X^\\top d$。\n    因此，$\\hat{\\beta}_1(\\delta) = \\hat{\\beta}_1(0) + \\delta \\cdot B_1$，其中 $B_1$ 是向量 $(X^\\top X)^{-1} X^\\top d$ 的第二个分量。临界点是 $\\hat{\\beta}_1(\\delta)$ 相对于 $\\hat{\\beta}_1(0)$ 符号改变时的 $\\delta$ 值。这发生在 $\\hat{\\beta}_1(\\delta)=0$ 时，其解为 $\\delta^\\star = -\\hat{\\beta}_1(0) / B_1$。如果这个 $\\delta^\\star$ 落在指定的搜索区间 $[\\delta_{\\min}, \\delta_{\\max}]$ 内，它就是临界点；否则，在该区间内没有发生临界。\n\n#### 3. 选择模型敏感性分析\n\n该分析直接对 MNAR 机制进行建模，并使用加权最小二乘法评估治疗效应对该机制假设的敏感性。\n\n-   **模型与加权**：该方法假设缺失概率遵循选择模型 $\\operatorname{logit}\\,\\mathbb{P}(R=1|Y=y) = \\alpha(\\gamma) + \\gamma g_{\\text{obs}}(y)$，其中 $g_{\\text{obs}}(y) = (y - \\bar{y}_{\\text{obs}}) / s_{\\text{obs}}$ 是基于观测结局标准化的。参数 $\\gamma$ 是一个在网格 $\\{-2, -1, 0, 1, 2\\}$ 上变化的敏感性参数，而 $\\alpha(\\gamma)$ 是一个讨厌参数。\n-   **估计 $\\alpha(\\gamma)$**：对于网格中给定的每个 $\\gamma$，$\\alpha(\\gamma)$ 由一个自洽性条件确定。逆概率加权原理要求观测受试者的权重之和应重构出总样本量 $n$。观测受试者 $i$ 的权重为 $w_i = 1/\\mathbb{P}(R_i=1|Y_i)$。因此，我们求解以下关于 $\\alpha(\\gamma)$ 的非线性方程：\n    $$ \\sum_{i: R_i=1} \\frac{1}{\\operatorname{expit}(\\alpha(\\gamma) + \\gamma g_{\\text{obs}}(Y_i))} = n $$\n-   **加权最小二乘法 (WLS)**：一旦找到 $\\alpha(\\gamma)$，就为所有观测受试者计算权重 $w_i$。然后使用这些权重，对观测数据进行 $Y$ 对 $(1, T, Z)$ 的加权最小二乘回归。WLS 问题的解给出了治疗效应的估计值 $\\hat{\\beta}_1(\\gamma)$：\n    $$ \\hat{\\beta}(\\gamma) = (X_{\\text{obs}}^\\top W(\\gamma) X_{\\text{obs}})^{-1} X_{\\text{obs}}^\\top W(\\gamma) Y_{\\text{obs}} $$\n    其中 $W(\\gamma)$ 是由权重 $w_i(\\gamma)$ 构成的对角矩阵。\n-   **敏感性范围**：对网格中的每个 $\\gamma$ 重复此过程。治疗效应估计值对 MNAR 假设的敏感性通过所得估计值的范围来衡量：$\\Delta_{\\text{range}} = \\max_{\\gamma} \\hat{\\beta}_1(\\gamma) - \\min_{\\gamma} \\hat{\\beta}_1(\\gamma)$。\n\n这种全面的方法可以稳健地评估潜在的 MNAR 机制可能如何影响研究的结论。",
            "answer": "```python\nimport numpy as np\nfrom scipy.special import expit\nfrom scipy.optimize import brentq\nfrom typing import List, Tuple\n\ndef ols_fit(X: np.ndarray, y: np.ndarray) -> np.ndarray:\n    \"\"\"Performs Ordinary Least Squares regression using a stable solver.\"\"\"\n    return np.linalg.solve(X.T @ X, X.T @ y)\n\ndef wls_fit(X: np.ndarray, y: np.ndarray, w: np.ndarray) -> np.ndarray:\n    \"\"\"Performs Weighted Least Squares regression using a stable solver.\"\"\"\n    w_sqrt = np.sqrt(w)\n    X_w = w_sqrt[:, np.newaxis] * X\n    y_w = w_sqrt * y\n    return np.linalg.solve(X_w.T @ X_w, X_w.T @ y_w)\n\ndef generate_data(seed: int, n: int, beta0: float, beta1: float, beta2: float, \n                  sigma: float, gamma_true: float, p_obs_target: float) -> Tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray, np.ndarray]:\n    \"\"\"Generates synthetic data according to the problem specification.\"\"\"\n    rng = np.random.default_rng(seed)\n    \n    T = rng.binomial(1, 0.5, size=n)\n    Z = rng.normal(0, 1, size=n)\n    epsilon = rng.normal(0, sigma, size=n)\n    \n    X_full = np.stack([np.ones(n), T, Z], axis=1)\n    \n    betas_true = np.array([beta0, beta1, beta2])\n    Y = X_full @ betas_true + epsilon\n    \n    y_mean = np.mean(Y)\n    y_std = np.std(Y)\n    g = (Y - y_mean) / y_std if y_std > 1e-9 else np.zeros_like(Y)\n    \n    def alpha_fn(alpha: float) -> float:\n        return np.mean(expit(alpha + gamma_true * g)) - p_obs_target\n    \n    alpha_true = brentq(alpha_fn, -40.0, 40.0)\n    \n    p_R = expit(alpha_true + gamma_true * g)\n    R = rng.binomial(1, p_R, size=n)\n    \n    return T, Z, Y, R.astype(int), X_full\n\ndef tipping_point_analysis(T: np.ndarray, Z: np.ndarray, Y: np.ndarray, R: np.ndarray, X_full: np.ndarray,\n                           delta_min: float, delta_max: float) -> float:\n    \"\"\"Performs pattern-mixture delta-adjustment tipping-point analysis.\"\"\"\n    obs_idx = (R == 1)\n    mis_idx = (R == 0)\n    \n    X_obs, Y_obs = X_full[obs_idx], Y[obs_idx]\n    \n    beta_mar = ols_fit(X_obs, Y_obs)\n    \n    Y_imputed_mar = X_full[mis_idx] @ beta_mar\n    Y_completed_0 = Y.copy()\n    Y_completed_0[mis_idx] = Y_imputed_mar\n    \n    beta_hat_0 = ols_fit(X_full, Y_completed_0)\n    beta1_at_0 = beta_hat_0[1]\n\n    d_vec = T * (1 - R)\n    # The vector B is the solution to (X.T @ X) B = X.T @ d\n    B = np.linalg.solve(X_full.T @ X_full, X_full.T @ d_vec)\n    B1 = B[1]\n\n    if abs(B1)  1e-12:\n        return np.nan\n        \n    delta_root = -beta1_at_0 / B1\n    \n    if delta_min = delta_root = delta_max:\n        return delta_root\n    else:\n        return np.nan\n\ndef selection_model_analysis(T: np.ndarray, Z: np.ndarray, Y: np.ndarray, R: np.ndarray, X_full: np.ndarray) -> float:\n    \"\"\"Performs selection-model sensitivity analysis.\"\"\"\n    obs_idx = (R == 1)\n    n = len(Y)\n    \n    Y_obs, T_obs, Z_obs = Y[obs_idx], T[obs_idx], Z[obs_idx]\n    X_obs = X_full[obs_idx]\n\n    y_obs_mean = np.mean(Y_obs)\n    y_obs_std = np.std(Y_obs)\n    g_obs = (Y_obs - y_obs_mean) / y_obs_std if y_obs_std > 1e-9 else np.zeros_like(Y_obs)\n    \n    gamma_grid = [-2.0, -1.0, 0.0, 1.0, 2.0]\n    beta1_hats = []\n    \n    for gamma in gamma_grid:\n        def alpha_fn(alpha: float) -> float:\n            logits = alpha + gamma * g_obs\n            # Numerically stable version of sum(1/expit(logits)) - n\n            return np.sum(1.0 + np.exp(-logits)) - n\n            \n        try:\n            alpha_gamma = brentq(alpha_fn, a=-50.0, b=50.0)\n        except ValueError:\n            continue\n            \n        probs = expit(alpha_gamma + gamma * g_obs)\n        weights = 1.0 / probs\n        \n        beta_wls = wls_fit(X_obs, Y_obs, weights)\n        beta1_hats.append(beta_wls[1])\n        \n    if not beta1_hats:\n        return np.nan\n        \n    range_width = np.max(beta1_hats) - np.min(beta1_hats)\n    return range_width\n\ndef format_val(v: float) -> str:\n    \"\"\"Formats a float to 4 decimal places, or 'NaN' for np.nan.\"\"\"\n    if np.isnan(v):\n        return \"NaN\"\n    return f\"{v:.4f}\"\n\ndef solve():\n    \"\"\"\n    Main function to run the analysis for all test cases and print the results.\n    \"\"\"\n    test_cases = [\n        # (seed, n, beta0, beta1, beta2, sigma, gamma_true, p_obs)\n        (20251, 1000, 0.0, -0.5, 0.8, 1.0, -1.0, 0.7), # Case A\n        (20252, 1000, 0.0, -1.0, 0.5, 1.2, -1.5, 0.6), # Case B\n        (20253, 1000, 0.0, -0.2, 0.8, 1.0, 1.0, 0.7),  # Case C\n    ]\n    \n    all_results = []\n    for params in test_cases:\n        seed, n, beta0, beta1, beta2, sigma, gamma_true, p_obs = params\n        \n        T, Z, Y, R, X_full = generate_data(seed, n, beta0, beta1, beta2, sigma, gamma_true, p_obs)\n        \n        delta_star = tipping_point_analysis(T, Z, Y, R, X_full, delta_min=-5.0, delta_max=5.0)\n        \n        range_width = selection_model_analysis(T, Z, Y, R, X_full)\n        \n        all_results.append([delta_star, range_width])\n        \n    formatted_pairs = [f\"[{format_val(pair[0])},{format_val(pair[1])}]\" for pair in all_results]\n    print(f\"[{','.join(formatted_pairs)}]\")\n\nif __name__ == '__main__':\n    solve()\n```"
        }
    ]
}