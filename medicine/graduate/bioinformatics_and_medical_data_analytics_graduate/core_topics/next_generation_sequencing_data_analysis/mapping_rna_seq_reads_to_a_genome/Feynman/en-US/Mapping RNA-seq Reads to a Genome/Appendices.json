{
    "hands_on_practices": [
        {
            "introduction": "Before RNA-seq reads can be accurately mapped to a genome, they must undergo a critical preprocessing phase to remove technical artifacts. This practice guides you through implementing a standard bioinformatics pipeline to clean raw sequencing data. By filtering out low-quality bases and trimming adapter sequences, you will ensure that only reliable data is used for the computationally intensive mapping step, thereby preventing spurious alignments and improving the overall accuracy of your analysis .",
            "id": "4580665",
            "problem": "You are given a set of synthetic deoxyribonucleic acid (DNA) sequencing reads in FASTQ form and are asked to implement a rigorous preprocessing and quality filtering pipeline that is directly relevant to downstream mapping of ribonucleic acid sequencing (RNA-seq) reads to a genome. The pipeline must be implemented exactly as specified and must be applied to the provided test suite. The objective is to formalize the preprocessing logic in purely mathematical and algorithmic terms grounded in well-tested bioinformatics principles.\n\nFundamental base and definitions:\n- Phred quality score definition: for each base call, the Phred score $Q$ is defined by $Q = -10 \\log_{10}(p_{\\mathrm{error}})$, where $p_{\\mathrm{error}}$ is the probability that the base call is incorrect. The Sanger FASTQ encoding (Phred$+$33) maps a quality character $q$ to $Q = \\mathrm{ord}(q) - 33$, where $\\mathrm{ord}(\\cdot)$ is the integer code point function.\n- Independence assumption: under the standard approximation used in many preprocessing tools, expected errors over a read segment can be computed as the sum of base-wise error probabilities $p_i = 10^{-Q_i/10}$ across retained bases.\n\nTarget preprocessing pipeline to implement:\n1. Adapter trimming at the $3'$ end:\n   - Let the adapter sequence be a fixed string $A$ and the read sequence be a string $S$ of length $n$ with quality characters $q_1,\\dots,q_n$.\n   - For overlap lengths $L$ iterating from $|A|$ down to $k_{\\min}$, compute the mismatch count between the suffix $S[n-L+1,\\dots,n]$ and the prefix $A[1,\\dots,L]$ under position-wise comparison. If the count is less than or equal to $m_{\\max}$ for the first such $L$ encountered, trim exactly the last $L$ bases from the read and the corresponding last $L$ quality characters. If no such $L$ is found, do not trim.\n2. Sliding-window quality trimming from both ends:\n   - Map each quality character to its Phred score $Q_i = \\mathrm{ord}(q_i)-33$.\n   - Left-trim rule: for window size $w$ and minimum average quality threshold $Q_{\\min}$, scan windows $[i,i+w-1]$ for $i=0,\\dots,n-w$. Identify the smallest index $s$ such that the arithmetic mean $\\frac{1}{w}\\sum_{j=i}^{i+w-1} Q_j \\ge Q_{\\min}$ holds at $i=s$. Set the retained start to $s$. If no window satisfies the threshold, the read is discarded with zero output.\n   - Right-trim rule: scan windows $[e-w,e-1]$ for $e=w,\\dots,n$ from right to left. Identify the largest index $e$ such that $\\frac{1}{w}\\sum_{j=e-w}^{e-1} Q_j \\ge Q_{\\min}$ holds. Set the retained end to $e$. If no window satisfies the threshold, the read is discarded with zero output.\n   - The retained segment is $S[s,\\dots,e-1]$ with quality scores $Q_s,\\dots,Q_{e-1}$. If $s \\ge e$, the read is discarded with zero output.\n3. Ambiguity and length filters:\n   - Let the fraction of ambiguous bases be $f_N = \\frac{\\text{count of 'N' in }S[s,\\dots,e-1]}{e-s}$. If $f_N > f_{N,\\max}$, discard the read.\n   - If the retained length $\\ell = e-s$ is strictly less than the minimum length $L_{\\min}$, discard the read.\n4. Metrics to report for retained reads:\n   - Retained length $\\ell$ as an integer.\n   - Mean base quality $\\bar{Q} = \\frac{1}{\\ell}\\sum_{i=s}^{e-1} Q_i$, rounded to three decimal places.\n   - Expected number of base call errors $E = \\sum_{i=s}^{e-1} 10^{-Q_i/10}$, rounded to three decimal places.\n   - Pass indicator as a boolean that is true if the read was retained and false if discarded by any filter.\n5. Output for discarded reads:\n   - If the read fails any filter, output the quadruple $[\\ell,\\bar{Q},E,\\mathrm{pass}]$ as $[0,0.0,0.0,\\mathrm{false}]$.\n\nYour program must implement the above logic and process the following test suite. Each test case provides $(S, q\\_str, A, w, Q_{\\min}, L_{\\min}, f_{N,\\max}, k_{\\min}, m_{\\max})$:\n- Test case $1$ (happy path with adapter trimming):\n  - $S$: the string \"ACGT\" repeated $15$ times, followed by \"AGATCGGAAG\". That is $S = \\text{\"ACGT\"} \\times 15 \\, \\Vert \\, \\text{\"AGATCGGAAG\"}$.\n  - $q\\_str$: the character \"I\" repeated $60$ times, followed by \"!\" repeated $10$ times. That is $q\\_str = \\text{\"I\"} \\times 60 \\, \\Vert \\, \\text{\"!\"} \\times 10$.\n  - $A$: \"AGATCGGAAGAGC\".\n  - $w = 5$, $Q_{\\min} = 20$, $L_{\\min} = 30$, $f_{N,\\max} = 0.1$, $k_{\\min} = 8$, $m_{\\max} = 1$.\n- Test case $2$ (high quality but excessive ambiguity):\n  - $S$: \"N\" repeated $15$ times, followed by \"A\" repeated $35$ times. That is $S = \\text{\"N\"} \\times 15 \\, \\Vert \\, \\text{\"A\"} \\times 35$.\n  - $q\\_str$: \"I\" repeated $50$ times. That is $q\\_str = \\text{\"I\"} \\times 50$.\n  - $A$: \"AGATCGGAAGAGC\".\n  - $w = 5$, $Q_{\\min} = 20$, $L_{\\min} = 30$, $f_{N,\\max} = 0.2$, $k_{\\min} = 8$, $m_{\\max} = 1$.\n- Test case $3$ (insufficient length after trimming):\n  - $S$: the string \"ACGT\" repeated $10$ times. That is $S = \\text{\"ACGT\"} \\times 10$.\n  - $q\\_str$: \"!\" repeated $20$ times, followed by \"I\" repeated $20$ times. That is $q\\_str = \\text{\"!\"} \\times 20 \\, \\Vert \\, \\text{\"I\"} \\times 20$.\n  - $A$: \"AGATCGGAAGAGC\".\n  - $w = 5$, $Q_{\\min} = 25$, $L_{\\min} = 30$, $f_{N,\\max} = 0.1$, $k_{\\min} = 8$, $m_{\\max} = 0$.\n- Test case $4$ (adapter absent, mixed ends, moderate ambiguity):\n  - $S$: the string \"ACGT\" repeated $10$ times, followed by \"NNNNN\", followed by \"TGCA\" repeated $5$ times, followed by \"ACGTA\". That is $S = \\text{\"ACGT\"} \\times 10 \\, \\Vert \\, \\text{\"NNNNN\"} \\, \\Vert \\, \\text{\"TGCA\"} \\times 5 \\, \\Vert \\, \\text{\"ACGTA\"}$.\n  - $q\\_str$: \"!\" repeated $3$ times, followed by \"I\" repeated $64$ times, followed by \"!\" repeated $3$ times. That is $q\\_str = \\text{\"!\"} \\times 3 \\, \\Vert \\, \\text{\"I\"} \\times 64 \\, \\Vert \\, \\text{\"!\"} \\times 3$.\n  - $A$: \"AGATCGGAAGAGC\".\n  - $w = 4$, $Q_{\\min} = 30$, $L_{\\min} = 50$, $f_{N,\\max} = 0.1$, $k_{\\min} = 8$, $m_{\\max} = 1$.\n- Test case $5$ (boundary case with $w=1$ for base-wise thresholding):\n  - $S$: \"ACGTACGTACGT\".\n  - $q\\_str$: \"A5?@B?A=A>5?\" where each character maps via Phred$+$33 encoding.\n  - $A$: \"AGATCGGAAGAGC\".\n  - $w = 1$, $Q_{\\min} = 30$, $L_{\\min} = 5$, $f_{N,\\max} = 0.0$, $k_{\\min} = 6$, $m_{\\max} = 0$.\n\nFinal output format:\n- Your program should produce a single line of output containing the results for all five test cases as a comma-separated list enclosed in square brackets. Each test case’s result must be a list of the form $[\\ell,\\bar{Q},E,\\mathrm{pass}]$, where $\\ell$ is an integer, $\\bar{Q}$ and $E$ are floats rounded to three decimal places, and $\\mathrm{pass}$ is a boolean. For discarded reads, output $[0,0.0,0.0,\\mathrm{false}]$.\n- Example format (not the actual answers): $[[12,35.200,0.015,\\mathrm{true}],[0,0.0,0.0,\\mathrm{false}],\\dots]$.",
            "solution": "The problem statement presents a well-defined and scientifically grounded task from the field of bioinformatics: to implement a specific sequence preprocessing pipeline for DNA sequencing reads. The pipeline's components—adapter trimming, sliding-window quality filtering, and filtering based on length and ambiguous base content—are standard procedures in preparing raw sequencing data for downstream analysis, such as mapping reads to a reference genome. All parameters, definitions, and algorithmic steps are specified with sufficient precision to permit a unique and deterministic implementation. The problem is therefore deemed valid.\n\nThe solution will be presented as a step-by-step algorithmic procedure, formalizing the logic described in the problem statement. All mathematical entities are rendered in LaTeX as required.\n\n### I. Formalization of the Preprocessing Algorithm\n\nLet a single read be represented by a sequence of bases $S$ and a corresponding string of quality characters $q_{str}$. Let the pipeline parameters be an adapter sequence $A$, a window size $w$, a minimum average quality threshold $Q_{\\min}$, a minimum retained length $L_{\\min}$, a maximum ambiguous base fraction $f_{N,\\max}$, a minimum adapter overlap $k_{\\min}$, and a maximum mismatch count $m_{\\max}$.\n\nA discard action results in the output $[0, 0.0, 0.0, \\mathrm{false}]$.\n\n**Step 0: Initial Transformation**\nThe input quality string $q_{str}$ is first converted into an array of Phred quality scores, $Q_{arr}$, using the Sanger (Phred$+33$) encoding:\n$$\n(Q_{arr})_i = \\mathrm{ord}((q_{str})_i) - 33\n$$\nwhere $\\mathrm{ord}(\\cdot)$ is the ASCII code point function. Let the initial read length be $n_0 = |S|$.\n\n**Step 1: 3' Adapter Trimming**\nThis step removes adapter sequences from the $3'$ end of the read.\n1.  Let the current read be $S'$ and quality string be $q'_{str}$. Initially, $S' \\leftarrow S$ and $q'_{str} \\leftarrow q_{str}$.\n2.  Iterate the overlap length $L$ from $L_{start} = \\min(|A|, |S'|)$ down to $k_{\\min}$.\n3.  For each $L$, compare the suffix of the read of length $L$, $S'[\\text{end}-L+1 : \\text{end}]$, with the prefix of the adapter of length $L$, $A[1:L]$.\n4.  Let the number of mismatches be $m$. If $m \\le m_{\\max}$, this is considered a match. Since we iterate from the longest possible overlap downwards, the first match found is the one we accept.\n5.  Upon finding such a match for length $L$, the read and its quality string are trimmed by removing the last $L$ characters.\n    -   $S_{new} \\leftarrow S'[1 : \\text{end}-L]$\n    -   $q_{new\\_str} \\leftarrow q'_{str}[1 : \\text{end}-L]$\n    The process then terminates for this read and proceeds to the next step with the trimmed sequences.\n6.  If the loop completes with no match found, the read is not trimmed.\n\nLet the read sequence and quality array after this step be $S_1$ and $Q_1$, with length $n_1 = |S_1|$. If $n_1 < w$, the read cannot be processed by the sliding window filter and is discarded.\n\n**Step 2: Sliding-Window Quality Trimming**\nThis step trims low-quality regions from both ends of the read.\n1.  **Left trim (finding start position $s$):**\n    We scan windows of size $w$ from left to right. The first window whose average quality meets the threshold $Q_{\\min}$ defines the start of the high-quality region.\n    -   We seek the smallest index $s \\in [0, n_1-w]$ such that:\n        $$\n        \\frac{1}{w} \\sum_{j=s}^{s+w-1} (Q_1)_j \\ge Q_{\\min}\n        $$\n    -   If no such index $s$ exists, the read is discarded.\n2.  **Right trim (finding end position $e$):**\n    We scan windows of size $w$ from right to left. The last window whose average quality meets the threshold $Q_{\\min}$ defines the end of the high-quality region.\n    -   We seek the largest index $e \\in [w, n_1]$ such that the window ending at $e-1$ qualifies:\n        $$\n        \\frac{1}{w} \\sum_{j=e-w}^{e-1} (Q_1)_j \\ge Q_{\\min}\n        $$\n    -   If no such index $e$ exists, the read is discarded.\n3.  **Final Segment:** The retained segment is defined by the interval $[s, e)$. The new read is $S_2 = S_1[s:e]$ and its quality scores are $Q_2 = Q_1[s:e]$. If $s \\ge e$, the resulting segment is empty or invalid, and the read is discarded.\n\n**Step 3: Ambiguity and Length Filtering**\nThe retained read $S_2$ is subjected to final checks.\n1.  **Length Filter:**\n    The length of the retained read is $\\ell = |S_2| = e-s$. If $\\ell < L_{\\min}$, the read is too short and is discarded.\n2.  **Ambiguity Filter:**\n    The fraction of ambiguous bases ('N') in the retained read, $f_N$, is calculated:\n    $$\n    f_N = \\frac{\\text{count of 'N' in } S_2}{\\ell}\n    $$\n    If $f_N > f_{N,\\max}$, the read has too many ambiguous bases and is discarded. This check is only performed if $\\ell>0$.\n\n**Step 4: Metric Calculation for Retained Reads**\nIf a read passes all filters, we compute the following metrics on the final sequence $S_2$ and its qualities $Q_2$ of length $\\ell$:\n1.  **Retained Length:** $\\ell$.\n2.  **Mean Base Quality:** The arithmetic mean of the Phred scores of the retained bases.\n    $$\n    \\bar{Q} = \\frac{1}{\\ell} \\sum_{i=0}^{\\ell-1} (Q_2)_i\n    $$\n3.  **Expected Errors:** The sum of error probabilities for each retained base. The error probability $p_i$ for a base with quality score $(Q_2)_i$ is $p_i = 10^{-(Q_2)_i/10}$.\n    $$\n    E = \\sum_{i=0}^{\\ell-1} 10^{-(Q_2)_i/10}\n    $$\n4.  **Pass Indicator:** A boolean value, `true`.\n\nThe final output for a passing read is $[\\ell, \\mathrm{round}(\\bar{Q}, 3), \\mathrm{round}(E, 3), \\mathrm{true}]$.\n\nThis rigorous, multi-stage pipeline ensures that only high-quality, biologically informative sequences are passed on to subsequent, more computationally intensive analyses. The implementation below will precisely follow this described logic.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef process_read(S, q_str, A, w, Q_min, L_min, f_N_max, k_min, m_max):\n    \"\"\"\n    Implements the full preprocessing pipeline for a single DNA sequencing read.\n    \"\"\"\n    \n    # --- Step 1: Adapter Trimming ---\n    s_current, q_current = S, q_str\n    \n    # Iterate from longest possible overlap down to the minimum\n    adapter_len = len(A)\n    read_len_initial = len(s_current)\n    \n    trimmed = False\n    for L in range(min(adapter_len, read_len_initial), k_min - 1, -1):\n        if L == 0: continue\n        read_suffix = s_current[read_len_initial - L:]\n        adapter_prefix = A[:L]\n        \n        mismatches = sum(1 for i in range(L) if read_suffix[i] != adapter_prefix[i])\n        \n        if mismatches <= m_max:\n            s_current = s_current[:read_len_initial - L]\n            q_current = q_current[:read_len_initial - L]\n            trimmed = True\n            break\n            \n    # --- Step 2: Quality Trimming ---\n    read_len_after_adapter = len(s_current)\n    \n    if read_len_after_adapter < w:\n        return [0, 0.0, 0.0, False]\n        \n    q_scores = np.array([ord(c) - 33 for c in q_current], dtype=float)\n    \n    if read_len_after_adapter == w:\n        window_avgs = np.array([np.mean(q_scores)])\n    else:\n        window_avgs = np.convolve(q_scores, np.ones(w, dtype=float), 'valid') / w\n\n    qualifying_indices = np.where(window_avgs >= Q_min)[0]\n    \n    if qualifying_indices.size == 0:\n        return [0, 0.0, 0.0, False]\n        \n    s = qualifying_indices[0]\n    # The end of the retained segment is the end of the last qualifying window.\n    # The last qualifying window starts at index `qualifying_indices[-1]`.\n    # A window starting at index `i` ends at index `i+w-1`. The slice is `[i:i+w]`.\n    e = qualifying_indices[-1] + w\n    \n    if s >= e:\n        return [0, 0.0, 0.0, False]\n\n    # Apply the trim\n    s_trimmed = s_current[s:e]\n    q_trimmed_scores = q_scores[s:e]\n    \n    # --- Step 3: Ambiguity and Length Filters ---\n    retained_len = len(s_trimmed)\n    \n    if retained_len < L_min:\n        return [0, 0.0, 0.0, False]\n        \n    n_count = s_trimmed.count('N')\n    if retained_len > 0:\n      f_N = n_count / retained_len\n      if f_N > f_N_max:\n          return [0, 0.0, 0.0, False]\n\n    # --- Step 4: Metric Calculation ---\n    ell = retained_len\n    if ell == 0: # Should be caught by s>=e, but as a safeguard\n        return [0, 0.0, 0.0, False]\n\n    q_bar = np.mean(q_trimmed_scores)\n    expected_errors = np.sum(10**(-q_trimmed_scores / 10.0))\n    passed = True\n    \n    return [ell, round(q_bar, 3), round(expected_errors, 3), passed]\n    \n\ndef solve():\n    \"\"\"\n    Main function to define test cases, run the pipeline, and print results.\n    \"\"\"\n    test_cases = [\n        # Test case 1 (happy path with adapter trimming)\n        (\"ACGT\" * 15 + \"AGATCGGAAG\", \"I\" * 60 + \"!\" * 10, \"AGATCGGAAGAGC\", 5, 20, 30, 0.1, 8, 1),\n        # Test case 2 (high quality but excessive ambiguity)\n        (\"N\" * 15 + \"A\" * 35, \"I\" * 50, \"AGATCGGAAGAGC\", 5, 20, 30, 0.2, 8, 1),\n        # Test case 3 (insufficient length after trimming)\n        (\"ACGT\" * 10, \"!\" * 20 + \"I\" * 20, \"AGATCGGAAGAGC\", 5, 25, 30, 0.1, 8, 0),\n        # Test case 4 (adapter absent, mixed ends, moderate ambiguity)\n        (\"ACGT\" * 10 + \"NNNNN\" + \"TGCA\" * 5 + \"ACGTA\", \"!\" * 3 + \"I\" * 64 + \"!\" * 3, \"AGATCGGAAGAGC\", 4, 30, 50, 0.1, 8, 1),\n        # Test case 5 (boundary case with w=1 for base-wise thresholding)\n        (\"ACGTACGTACGT\", \"A5?@B?A=A>5?\", \"AGATCGGAAGAGC\", 1, 30, 5, 0.0, 6, 0)\n    ]\n\n    results = []\n    for case in test_cases:\n        result = process_read(*case)\n        results.append(result)\n\n    # Format the final output string as specified.\n    result_strings = []\n    for res in results:\n        l, q, E, p = res\n        if not p:\n            result_strings.append(\"[0,0.0,0.0,false]\")\n        else:\n            result_strings.append(f\"[{l},{q:.3f},{E:.3f},{str(p).lower()}]\")\n            \n    print(f\"[{','.join(result_strings)}]\")\n\nsolve()\n\n```"
        },
        {
            "introduction": "A central challenge in read mapping is ambiguity, where a single read aligns to multiple genomic locations with identical scores. Rather than randomly assigning the read, modern aligners use probabilistic models to resolve this uncertainty. This exercise challenges you to implement a principled Bayesian framework that calculates the posterior probability for each potential alignment, a technique that improves quantification accuracy, especially for transcripts within gene families or with related pseudogenes .",
            "id": "4580744",
            "problem": "You are given a scenario in Ribonucleic Acid sequencing (RNA-seq) read mapping where multiple candidate alignments for a single read achieve the same maximum alignment score to a Deoxyribonucleic Acid (DNA) reference. The task is to resolve the ambiguity among these equal-score candidates using a principled probabilistic rule derived from first principles, rather than arbitrary tie-breakers. The fundamental base you must use consists of the following well-tested facts and definitions: (i) Bayes theorem for posterior probabilities, (ii) the commonly accepted RNA-seq sampling model that the probability of sampling a fragment from a transcript is proportional to expression times effective length, and (iii) an independent error model in which mismatches and insertion-deletion events (indels) occur with fixed probabilities at the per-event level.\n\nSpecifically, assume a read has $n$ candidate genomic loci or splice-junction alignments, indexed by $i \\in \\{1,\\dots,n\\}$. Each candidate alignment is characterized by counts $m_i$ (the number of mismatches) and $d_i$ (the number of indel events) in the alignment, and there exist strictly positive error probabilities $e$ for a mismatch event and $g$ for an indel event, with $0 < e < 1$ and $0 < g < 1$. For each locus $i$, you are given a nonnegative expression level $E_i$ and an effective length $L_i > 0$. The equal-score condition means that all candidate alignments considered attain the same maximum value of an alignment scoring function; you should not use the score itself further, but only the provided error counts and the priors derived from expression and effective length.\n\nFrom these bases alone, derive an ambiguity resolution rule that computes, for each read, the posterior probability vector over candidates and outputs these posterior probabilities as fractional assignments that sum to $1$ across candidates. Your program should implement this rule exactly for each test case described below.\n\nYou must not invent any additional assumptions beyond what is stated. You must start from Bayes theorem and the sampling model proportional to expression times effective length, together with the independent error model, and derive an implementable computation that yields a normalized posterior over the candidate alignments.\n\nImplement the computation for the following test suite of parameter sets. In each test case, you are given the tuple $(e, g, \\mathbf{E}, \\mathbf{L}, \\mathbf{m}, \\mathbf{d})$, where $\\mathbf{E}$, $\\mathbf{L}$, $\\mathbf{m}$, and $\\mathbf{d}$ are arrays aligned by candidate index.\n\n- Test case $1$ (happy path; differing priors, identical error counts):\n  - $e = 0.01$, $g = 0.001$\n  - $\\mathbf{E} = [50, 25]$\n  - $\\mathbf{L} = [1500, 1500]$\n  - $\\mathbf{m} = [1, 1]$\n  - $\\mathbf{d} = [0, 0]$\n- Test case $2$ (equal priors; different error profiles across three candidates):\n  - $e = 0.02$, $g = 0.001$\n  - $\\mathbf{E} = [10, 10, 10]$\n  - $\\mathbf{L} = [1000, 1000, 1000]$\n  - $\\mathbf{m} = [2, 1, 1]$\n  - $\\mathbf{d} = [0, 0, 1]$\n- Test case $3$ (priors and errors exactly counterbalanced to yield equal posterior mass over two candidates):\n  - $e = 0.05$, $g = 0.001$\n  - $\\mathbf{E} = [50, 100]$\n  - $\\mathbf{L} = [100, 1000]$\n  - $\\mathbf{m} = [0, 1]$\n  - $\\mathbf{d} = [0, 0]$\n- Test case $4$ (boundary case with a zero prior for one candidate):\n  - $e = 0.01$, $g = 0.001$\n  - $\\mathbf{E} = [0, 20]$\n  - $\\mathbf{L} = [1000, 1000]$\n  - $\\mathbf{m} = [0, 0]$\n  - $\\mathbf{d} = [0, 0]$\n- Test case $5$ (four-way ambiguity with both mismatch and indel events present):\n  - $e = 0.02$, $g = 0.02$\n  - $\\mathbf{E} = [100, 98, 102, 100]$\n  - $\\mathbf{L} = [100, 100, 100, 100]$\n  - $\\mathbf{m} = [1, 1, 1, 0]$\n  - $\\mathbf{d} = [0, 1, 0, 0]$\n\nYour program must, for each test case, compute the normalized posterior probability vector over candidates in the given order, rounded to $6$ decimal places. The rounding should be applied to each component of the posterior vector independently. Your program should produce a single line of output containing the results for all test cases as a comma-separated list of the rounded posterior vectors, enclosed in square brackets, with no spaces. For example, the format must look like \"[[a11,a12,...],[a21,a22,...],...]\" where each $a_{ij}$ is a decimal number rounded to $6$ places.\n\nNo physical units or angles are involved in this task. All numeric outputs must be decimals as specified; do not use the percentage sign anywhere in the output. Ensure scientific realism by strictly adhering to the base facts and assumptions above, and do not add any untested heuristics or arbitrary tie-breaking rules.",
            "solution": "The objective is to compute the posterior probability distribution over a set of $n$ candidate alignments for a single RNA-sequencing read, given that all candidates share the same maximum alignment score. Let $R$ denote the event of observing the read, and let $C_i$ for $i \\in \\{1, \\dots, n\\}$ be the event that the read originated from the $i$-th candidate locus. The problem is to calculate the posterior probability $P(C_i | R)$ for each candidate $i$.\n\nThe solution is derived from first principles, beginning with Bayes' theorem, which provides the formal relationship between the desired posterior probability, the prior probability of each candidate, and the likelihood of observing the read given each candidate:\n$$\nP(C_i | R) = \\frac{P(R | C_i) P(C_i)}{\\sum_{j=1}^{n} P(R | C_j) P(C_j)}\n$$\nThe denominator is a normalization constant, ensuring that the posterior probabilities sum to $1$. To solve the problem, we must define the expressions for the prior, $P(C_i)$, and the likelihood, $P(R | C_i)$, based on the provided information.\n\nThe prior probability, $P(C_i)$, represents the probability of a read originating from locus $i$ before considering the alignment evidence from the read itself. The problem states that the probability of sampling a fragment from a transcript is proportional to its expression level $E_i$ and its effective length $L_i$. This directly translates into a model for the prior probability:\n$$\nP(C_i) \\propto E_i L_i\n$$\nWe can define an unnormalized prior weight for each candidate $i$ as $\\pi_i = E_i L_i$. Since any constant of proportionality will be the same for all candidates, it will cancel out during the final normalization step. Therefore, we can proceed using these unnormalized prior weights.\n\nThe likelihood, $P(R | C_i)$, is the probability of observing the specific read sequence $R$ given that it originated from locus $i$. The problem specifies an independent error model where mismatches and indels are independent events occurring with fixed probabilities $e$ and $g$ per event, respectively. The alignment for candidate $i$ is characterized by $m_i$ mismatches and $d_i$ indel events. The most direct interpretation of the \"per-event\" model is that the likelihood of a read arising from a template is proportional to the joint probability of the observed error events. Under the assumption of independence, this is the product of the individual event probabilities.\n$$\nP(R | C_i) \\propto e^{m_i} g^{d_i}\n$$\nThis likelihood model focuses on the occurrences of errors. Other factors, such as the probability of matches, are implicitly assumed to be constant across all high-scoring alignments or absorbed into a normalization constant that cancels out. The problem framing, which sets aside the alignment score itself, supports this focused error-based likelihood.\n\nCombining the prior and the likelihood, we can compute an unnormalized posterior weight, $W_i$, for each candidate $i$. This weight is proportional to the true posterior probability $P(C_i|R)$.\n$$\nW_i \\propto P(R | C_i) P(C_i)\n$$\nSubstituting our derived expressions, we get:\n$$\nW_i = (E_i L_i) \\cdot (e^{m_i} g^{d_i})\n$$\nHere, we have used equality by defining $W_i$ as the product of the unnormalized prior and the proportional likelihood term.\n\nFinally, to obtain the posterior probability vector, we normalize these weights so that they sum to $1$. The posterior probability for candidate $i$ is its weight divided by the sum of all weights:\n$$\nP(C_i | R) = \\frac{W_i}{\\sum_{j=1}^{n} W_j} = \\frac{E_i L_i e^{m_i} g^{d_i}}{\\sum_{j=1}^{n} E_j L_j e^{m_j} g^{d_j}}\n$$\nThis formula provides a complete, principled rule for resolving ambiguity.\n\nThe algorithm to implement this rule is as follows:\nFor each test case, specified by the parameters $(e, g, \\mathbf{E}, \\mathbf{L}, \\mathbf{m}, \\mathbf{d})$:\n1. For each candidate $i$ from $1$ to $n$, compute the unnormalized posterior weight $W_i = E_i L_i e^{m_i} g^{d_i}$.\n2. Compute the total weight $W_{total} = \\sum_{j=1}^{n} W_j$.\n3. If $W_{total}$ is $0$ (which occurs if all prior expression levels $E_j$ are $0$), the posterior is undefined. A reasonable convention is to assign a uniform probability, $1/n$, to each candidate.\n4. If $W_{total} > 0$, compute the posterior probability for each candidate as $P(C_i|R) = W_i / W_{total}$.\n5. Round each component of the resulting posterior probability vector to $6$ decimal places.\n\nThis procedure strictly adheres to the principles and data provided in the problem statement.",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the RNA-seq read mapping ambiguity problem for a suite of test cases.\n    \"\"\"\n    test_cases = [\n        # Test case 1\n        {'e': 0.01, 'g': 0.001, 'E': np.array([50, 25]), 'L': np.array([1500, 1500]), 'm': np.array([1, 1]), 'd': np.array([0, 0])},\n        # Test case 2\n        {'e': 0.02, 'g': 0.001, 'E': np.array([10, 10, 10]), 'L': np.array([1000, 1000, 1000]), 'm': np.array([2, 1, 1]), 'd': np.array([0, 0, 1])},\n        # Test case 3\n        {'e': 0.05, 'g': 0.001, 'E': np.array([50, 100]), 'L': np.array([100, 1000]), 'm': np.array([0, 1]), 'd': np.array([0, 0])},\n        # Test case 4\n        {'e': 0.01, 'g': 0.001, 'E': np.array([0, 20]), 'L': np.array([1000, 1000]), 'm': np.array([0, 0]), 'd': np.array([0, 0])},\n        # Test case 5\n        {'e': 0.02, 'g': 0.02, 'E': np.array([100, 98, 102, 100]), 'L': np.array([100, 100, 100, 100]), 'm': np.array([1, 1, 1, 0]), 'd': np.array([0, 1, 0, 0])},\n    ]\n\n    results = []\n    for case in test_cases:\n        e, g, E, L, m, d = case['e'], case['g'], case['E'], case['L'], case['m'], case['d']\n\n        # Calculate unnormalized prior weights: proportional to Expression * Length\n        prior_weights = E * L\n\n        # Calculate likelihoods: proportional to e^m * g^d\n        likelihoods = (e ** m) * (g ** d)\n\n        # Calculate unnormalized posterior weights\n        unnormalized_posteriors = prior_weights * likelihoods\n\n        # Normalize to get posterior probabilities\n        total_weight = np.sum(unnormalized_posteriors)\n\n        if total_weight == 0:\n            # This case occurs if all prior probabilities are zero (e.g., all E_i are 0).\n            # The posterior is ill-defined. A uniform distribution is a reasonable default.\n            num_candidates = len(E)\n            if num_candidates > 0:\n                posterior_probs = np.full(num_candidates, 1.0 / num_candidates)\n            else:\n                posterior_probs = np.array([])\n        else:\n            posterior_probs = unnormalized_posteriors / total_weight\n        \n        # Round each probability to 6 decimal places\n        rounded_probs = np.round(posterior_probs, 6).tolist()\n        results.append(rounded_probs)\n\n    # Format the final output string as specified\n    case_strs = []\n    for res_list in results:\n        num_strs = [str(num) for num in res_list]\n        case_str = f\"[{','.join(num_strs)}]\"\n        case_strs.append(case_str)\n    \n    final_output = f\"[{','.join(case_strs)}]\"\n    print(final_output)\n\nsolve()\n```"
        },
        {
            "introduction": "Once reads are mapped, the resulting alignments provide a wealth of information about the sequencing experiment itself. A crucial quality control step is to determine the library preparation strategy, such as whether the protocol was stranded or unstranded. This practice involves developing a statistical model to infer library properties from the aggregated strand orientation of mapped reads, which is essential for accurate gene expression quantification .",
            "id": "4580709",
            "problem": "A developer is tasked with inferring RNA sequencing (RNA-seq) library strandedness and pair orientation from aggregate mapping statistics without access to raw alignment records. The setting is mapping RNA sequencing (RNA-seq) reads to a genome with known gene annotations that include a genomic strand for each gene. The inference should be framed as a model selection problem grounded in probability theory and the Central Dogma of Molecular Biology (DNA to RNA to protein). In brief, messenger ribonucleic acid (mRNA) transcripts originating from a gene on a particular genomic strand yield complementary deoxyribonucleic acid (cDNA) fragments whose sequenced strand orientation depends on the library preparation protocol. As a consequence, when sequence reads are aligned to a genome, the observed alignment strand of a read that overlaps a gene is informative about whether the library is stranded and, for paired-end data, which mate is in the sense orientation and which geometric orientation (forward-reverse versus reverse-forward) is present.\n\nFundamental base definitions to be used:\n- The Central Dogma of Molecular Biology asserts that genetic information flows from deoxyribonucleic acid (DNA) to ribonucleic acid (RNA) to protein. For RNA sequencing (RNA-seq), complementary deoxyribonucleic acid (cDNA) synthesis and sequencing produce reads whose orientation relative to a gene’s strand depends on the library protocol.\n- In a sufficiently annotated genome, each gene has a genomic strand label, either plus or minus. An aligned read overlapping a gene has an observed strand label indicating which DNA strand the read sequence matches.\n- Under a directional library protocol, the proportion of reads overlapping genes that align in the sense orientation relative to the gene’s strand is expected to be substantially different from the proportion in the antisense orientation. Under an undirected (unstranded) protocol, these proportions are expected to be approximately equal.\n\nMathematical modeling to be implemented:\n- For single-end data, consider $n$ reads overlapping annotated genes, with $k$ of them aligning in the sense orientation relative to the gene strand. Treat each read as a Bernoulli trial with success probability $p$ equal to the probability of a sense-orientation match. Define three models: sense-stranded ($p$ in the interval $[0.5,1]$), antisense-stranded ($p$ in the interval $[0,0.5]$), and unstranded ($p$ fixed at $0.5$). Use maximum likelihood estimation under each model’s constraint and select the model whose maximized log-likelihood is largest. To guard against degenerate cases at the boundary probabilities, clamp any probability estimates to the open interval $(0,1)$ using a small positive constant $\\epsilon$.\n- For paired-end strandedness, consider $n$ overlapping fragments where the first mate’s strand is compared to the gene’s strand, with $k$ such first mates aligning in sense orientation relative to the gene. Use the same Bernoulli modeling and model constraints as above, with the interpretation that the “first-strand” protocol corresponds to the first mate being sense and the “second-strand” protocol corresponds to the first mate being antisense.\n- For paired-end geometric orientation, consider counts of properly paired fragments with forward-reverse (FR) geometry $f$ and reverse-forward (RF) geometry $r$. Model each fragment as a Bernoulli trial with success probability $p$ for the FR orientation. Define three models: FR-dominant ($p$ in the interval $[0.5,1]$), RF-dominant ($p$ in the interval $[0,0.5]$), and symmetric ($p$ fixed at $0.5$). Use maximum likelihood estimation under constraints with the same clamping rule.\n\nDecision rule:\n- Let the Log-Likelihood Ratio (LLR) be the difference between the maximized log-likelihood of the best constrained model and the log-likelihood under the unstranded or symmetric model. Use the natural logarithm. If the LLR exceeds a threshold $T$, accept the constrained model; otherwise, return an ambiguous classification corresponding to the unstranded/symmetric model. Use the threshold $T = \\log 100$ to require odds of at least $100$ to $1$ in favor of the constrained model.\n- In the case $n=0$ or $f+r=0$, return the ambiguous classification.\n\nRequired outputs:\n- For single-end strandedness, return an integer code: sense-stranded is $1$, antisense-stranded is $-1$, and ambiguous/unstranded is $0$.\n- For paired-end strandedness, return an integer code: first-strand is $2$, second-strand is $-2$, and ambiguous/unstranded is $0$.\n- For paired-end geometric orientation, return an integer code: forward-reverse (FR) is $3$, reverse-forward (RF) is $-3$, and ambiguous/symmetric is $0$.\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (e.g., $[result1,result2,\\dots]$). The final outputs must be integers as specified above. Use the natural logarithm for all likelihood computations. When clamping probabilities, use a fixed small constant $\\epsilon = 10^{-12}$.\n\nTest suite:\n- Single-end strandedness cases:\n    1. $k=950$, $n=1000$.\n    2. $k=50$, $n=1000$.\n    3. $k=51$, $n=100$.\n    4. $k=0$, $n=0$.\n    5. $k=1000$, $n=1000$.\n- Paired-end strandedness cases (first mate relative to gene):\n    6. $k=900$, $n=1000$.\n    7. $k=100$, $n=1000$.\n    8. $k=505$, $n=1000$.\n- Paired-end geometric orientation (FR versus RF counts):\n    9. $f=800$, $r=200$.\n    10. $f=500$, $r=500$.\n    11. $f=100$, $r=900$.\n\nYour program must implement the modeling and decision rule described above, apply it to all test cases, and print the aggregate results on a single line in the required format.",
            "solution": "The problem requires the implementation of a statistical model selection procedure to infer properties of an RNA sequencing (RNA-seq) library from aggregate read count data. The solution is based on maximum likelihood estimation (MLE) within a Bernoulli trial framework and model comparison using a log-likelihood ratio (LLR) test.\n\n### General Probabilistic and Likelihood Framework\n\nThe core of the inference for all three tasks (single-end strandedness, paired-end strandedness, and paired-end geometric orientation) is the binomial distribution. We consider a series of $n$ independent Bernoulli trials, where each trial results in a \"success\" with probability $p$ or a \"failure\" with probability $1-p$. If we observe $k$ successes, the likelihood of observing this data given the probability $p$ is:\n$$ \\mathcal{L}(p | k, n) = \\binom{n}{k} p^k (1-p)^{n-k} $$\nThe log-likelihood, which is more convenient for maximization, is given by:\n$$ \\ell(p | k, n) = \\ln\\left(\\mathcal{L}(p | k, n)\\right) = \\ln\\binom{n}{k} + k \\ln(p) + (n-k) \\ln(1-p) $$\nWhen comparing log-likelihoods for the same data ($k, n$), the term $\\ln\\binom{n}{k}$ is a constant and can be disregarded. We thus work with the kernel of the log-likelihood function:\n$$ \\ell^*(p | k, n) = k \\ln(p) + (n-k) \\ln(1-p) $$\nThe unconstrained Maximum Likelihood Estimate (MLE) for $p$, which maximizes $\\ell^*(p | k, n)$, is the sample proportion of successes, $\\hat{p} = k/n$.\n\n### Model Definitions and Constrained Maximum Likelihood Estimation\n\nFor each task, we evaluate three competing models by constraining the parameter $p$ to different sub-intervals of $[0, 1]$.\n\n1.  **Sense-like / FR-dominant Model ($M_S$):** This model hypothesizes that successes are more likely than failures. The parameter space is restricted to $p \\in [0.5, 1]$. The MLE for $p$ under this constraint is $\\hat{p}_S = \\max(0.5, k/n)$.\n2.  **Antisense-like / RF-dominant Model ($M_A$):** This model hypothesizes that failures are more likely than successes. The parameter space is restricted to $p \\in [0, 0.5]$. The MLE for $p$ under this constraint is $\\hat{p}_A = \\min(0.5, k/n)$.\n3.  **Unstranded / Symmetric Model ($M_0$):** This is the null model, hypothesizing no preference for success or failure. The parameter $p$ is fixed at $p_0 = 0.5$.\n\nTo prevent numerical issues with $\\ln(0)$ when $k=0$ or $k=n$, the problem mandates that probability estimates be clamped to the open interval $(\\epsilon, 1-\\epsilon)$, where $\\epsilon = 10^{-12}$. This means the unconstrained estimate $\\hat{p} = k/n$ is adjusted to $p' = \\max(\\epsilon, \\min(\\hat{p}, 1-\\epsilon))$ before being used in log-likelihood calculations.\n\n### Model Selection via Log-Likelihood Ratio Test\n\nThe decision to favor a stranded/oriented model over the unstranded/symmetric one is made using a Log-Likelihood Ratio (LLR) test.\n\nThe log-likelihood for the null model ($M_0$) is:\n$$ \\ell_0 = \\ell^*(0.5 | k, n) = k \\ln(0.5) + (n-k) \\ln(0.5) = n \\ln(0.5) $$\nThe maximized log-likelihood for the best-fitting constrained model ($M_S$ or $M_A$) corresponds to the unconstrained log-likelihood, evaluated at the clamped estimate $p'$. This is because the likelihood function is concave, and its maximum over $[0, 1]$ occurs at $\\hat{p}=k/n$. The maximum over $[0.5, 1]$ will be at $\\max(0.5, k/n)$ and the maximum over $[0, 0.5]$ will be at $\\min(0.5, k/n)$. The greater of these two maximized likelihoods will be the one evaluated at $\\hat{p}$, provided $\\hat{p} \\neq 0.5$.\nSo, the maximized log-likelihood for the alternative hypothesis is:\n$$ \\ell_{MLE} = \\ell^*(p' | k, n) = k \\ln(p') + (n-k) \\ln(1-p') $$\nwhere $p' = \\max(\\epsilon, \\min(k/n, 1-\\epsilon))$.\n\nThe LLR is the difference between the alternative and null log-likelihoods:\n$$ LLR = \\ell_{MLE} - \\ell_0 $$\nA decision is made by comparing the LLR to a threshold $T = \\ln(100)$.\n-   If $LLR > T$, we accept the alternative model. The specific classification (e.g., sense vs. antisense) depends on whether $\\hat{p} > 0.5$ or $\\hat{p} < 0.5$.\n-   If $LLR \\le T$, the evidence is insufficient to reject the null model, and the result is classified as ambiguous/unstranded.\n\nA special case is when $n=0$ (or $f+r=0$), for which the classification is ambiguous by definition. Similarly, if $\\hat{p} = 0.5$, the LLR is 0, leading to an ambiguous classification.\n\n### Application to Specific Inference Tasks\n\nThe general procedure above is applied to each of the three scenarios by defining $k$, $n$, and the corresponding output codes.\n\n**1. Single-End Strandedness:**\n-   $n$: Total reads overlapping annotated genes.\n-   $k$: Reads aligning in the sense orientation.\n-   $p$: Probability of a sense-orientation match.\n-   Output Codes: Sense-stranded (1), Antisense-stranded (-1), Ambiguous (0).\n-   Procedure: Apply the LLR test with the given $k$, $n$. If $LLR > T$, return $1$ if $k/n > 0.5$ or $-1$ if $k/n < 0.5$. Otherwise, return $0$.\n\n**2. Paired-End Strandedness:**\n-   $n$: Total overlapping fragments.\n-   $k$: First mates aligning in the sense orientation.\n-   $p$: Probability of the first mate being in the sense orientation.\n-   Output Codes: First-strand (2), Second-strand (-2), Ambiguous (0).\n-   Procedure: Apply the LLR test. If $LLR > T$, return $2$ if $k/n > 0.5$ (first-strand) or $-2$ if $k/n < 0.5$ (second-strand). Otherwise, return $0$.\n\n**3. Paired-End Geometric Orientation:**\n-   Counts are given as $f$ (forward-reverse) and $r$ (reverse-forward).\n-   Map to the general framework: $n = f+r$ and $k = f$.\n-   $p$: Probability of the FR orientation.\n-   Output Codes: FR-dominant (3), RF-dominant (-3), Ambiguous (0).\n-   Procedure: Apply the LLR test with $k=f$ and $n=f+r$. If $LLR > T$, return $3$ if $f/(f+r) > 0.5$ or $-3$ if $f/(f+r) < 0.5$. Otherwise, return $0$.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the RNA-seq library inference problem for a given test suite.\n    \"\"\"\n\n    # Global constants defined in the problem statement\n    EPSILON = 1e-12\n    THRESHOLD = np.log(100)\n\n    def classify_model(k, n, code_pos, code_neg, code_amb):\n        \"\"\"\n        General classification function based on Bernoulli model selection.\n\n        Args:\n            k (int): Number of \"success\" observations.\n            n (int): Total number of observations.\n            code_pos (int): Integer code for the positive-bias model (p > 0.5).\n            code_neg (int): Integer code for the negative-bias model (p < 0.5).\n            code_amb (int): Integer code for the ambiguous/null model (p = 0.5).\n\n        Returns:\n            int: The integer code representing the selected model.\n        \"\"\"\n        # Handle degenerate case where there are no observations.\n        if n == 0:\n            return code_amb\n\n        # Calculate the unconstrained Maximum Likelihood Estimate (MLE) for p.\n        p_hat = k / n\n\n        # If p_hat is exactly 0.5, the LLR is 0, so the result is ambiguous.\n        if p_hat == 0.5:\n            return code_amb\n\n        # Clamp the probability estimate to avoid log(0)\n        p_clamped = np.clip(p_hat, EPSILON, 1.0 - EPSILON)\n\n        # Calculate the log-likelihood for the best constrained model (alternative hypothesis).\n        # This corresponds to the log-likelihood at the unconstrained (but clamped) MLE.\n        log_likelihood_mle = k * np.log(p_clamped) + (n - k) * np.log(1.0 - p_clamped)\n\n        # Calculate the log-likelihood for the unstranded/symmetric model (null hypothesis).\n        log_likelihood_null = n * np.log(0.5)\n\n        # Calculate the Log-Likelihood Ratio (LLR).\n        llr = log_likelihood_mle - log_likelihood_null\n\n        # Apply the decision rule based on the threshold.\n        if llr > THRESHOLD:\n            if p_hat > 0.5:\n                return code_pos\n            else: # p_hat < 0.5\n                return code_neg\n        else:\n            return code_amb\n\n    # Test suite provided in the problem statement.\n    # Each tuple represents a test case with its specific parameters.\n    # Format: (type, k, n) or (type, f, r)\n    test_cases = [\n        # Single-end strandedness cases (type=1)\n        (1, 950, 1000),      # Case 1\n        (1, 50, 1000),       # Case 2\n        (1, 51, 100),        # Case 3\n        (1, 0, 0),           # Case 4\n        (1, 1000, 1000),     # Case 5\n        # Paired-end strandedness cases (type=2)\n        (2, 900, 1000),      # Case 6\n        (2, 100, 1000),      # Case 7\n        (2, 505, 1000),      # Case 8\n        # Paired-end geometric orientation cases (type=3)\n        (3, 800, 200),       # Case 9\n        (3, 500, 500),       # Case 10\n        (3, 100, 900),       # Case 11\n    ]\n\n    results = []\n    for case in test_cases:\n        case_type = case[0]\n        \n        if case_type == 1:  # Single-end strandedness\n            k, n = case[1], case[2]\n            result = classify_model(k, n, code_pos=1, code_neg=-1, code_amb=0)\n        elif case_type == 2:  # Paired-end strandedness\n            k, n = case[1], case[2]\n            result = classify_model(k, n, code_pos=2, code_neg=-2, code_amb=0)\n        elif case_type == 3:  # Paired-end geometric orientation\n            f, r = case[1], case[2]\n            k = f\n            n = f + r\n            result = classify_model(k, n, code_pos=3, code_neg=-3, code_amb=0)\n        \n        results.append(result)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        }
    ]
}