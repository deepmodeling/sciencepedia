{
    "hands_on_practices": [
        {
            "introduction": "要精通比例风险假设的诊断，理论知识必须与实践相结合。本章提供了一系列动手练习，旨在巩固您的核心技能。我们从一种直观的图形诊断方法开始，该方法利用了您已经熟悉的Kaplan-Meier (KM)生存曲线。通过对KM估计进行一个巧妙的数学变换——互补对数-对数（complementary log-log）变换，我们可以生成一个诊断图，在该图上，平行曲线为比例风险假设提供了强有力的视觉证据。这个练习将引导您理解这一重要图形诊断工具的构建原理和解释方式。",
            "id": "4555957",
            "problem": "在一项肿瘤学的临床基因组学研究中，研究人员根据信使核糖核酸（mRNA）表达（高与低）定义的二元生物标志物组，对患者进行分层，并分析其疾病进展时间。事件时间变量用 $T$ 表示，数据存在右删失，科学问题涉及评估在 Cox 比例风险模型中应用的比例风险（PH）假设。研究人员计划使用 Kaplan-Meier (KM) 方法来估计每个生物标志物组 $g$ 的组特异性生存函数 $\\hat S_g(t)$。从生存分析的核心定义出发，即生存函数 $S(t) = \\Pr(T  t)$、风险函数 $h(t)$ 和累积风险函数 $H(t)$，并且仅使用非参数估计和单调变换，目标是将特定组的生存估计转化为用于检验 PH 假设的图形诊断工具，该工具产生的模式可以解释为不随时间 $t$ 变化的组效应。哪个选项最好地描述了使用变换尺度构建此诊断工具的正确方法，以及在 PH 假设下如何解释它，同时忠实于基于 KM 的估计和右删失处理？\n\nA. 对于每个组 $g$，在共同的事件时间网格上计算 KM 估计值 $\\hat S_g(t)$。然后，绘制所有组的互补对数-对数变换 $y_g(t) = \\log\\!\\big(-\\log \\hat S_g(t)\\big)$ 相对于 $\\log t$ 的曲线。在 PH 假设下，预计各组的曲线 $y_g(t)$ 会近似平行，因为组效应作为相对于 $t$ 的恒定垂直位移进入。在所有 $t$ 上的垂直间距的恒定性可解释为风险比不随时间变化的证据。对所有组使用相同的 $t$ 轴，应用 KM 固有的标准右删失处理，并避免在风险集稀疏的区域进行过度解释。\n\nB. 对于每个组 $g$，计算 $\\hat S_g(t)$ 并绘制 $\\hat S_g(t)$ 相对于 $t$ 的曲线。在 PH 假设下，曲线应在所有 $t$ 上显示恒定的垂直间距；此间距可被解读为风险比。因为 KM 已经考虑了右删失，所以不需要进一步的变换。\n\nC. 对于每个组 $g$，将组特异性风险函数估计为 $-\\frac{d}{dt}\\log \\hat S_g(t)$，并绘制其相对于 $t$ 的曲线。在 PH 假设下，风险函数在对时间轴进行重新缩放后应该对齐，因此重合的曲线可以证实 PH 假设。\n\nD. 对于每个组 $g$，估计 Nelson-Aalen 累积风险 $\\hat H_g(t)$，然后绘制 $\\log \\hat H_g(t)$ 相对于 $t$ 的曲线。在 PH 假设下，曲线应该是平行的，在所有 $t$ 上具有恒定的垂直间距，该间距直接估计了对数风险比；这种方法优于 KM，因为它直接针对风险。\n\nE. 对于每个组 $g$，计算 $\\hat S_g(t)$ 并绘制 $\\log \\hat S_g(t)$ 相对于 $\\log t$ 的曲线。在 PH 假设下，曲线应该是平行的，因为风险的比例性意味着在对数尺度上生存率的比例性，从而产生一个可解释为对数风险比的恒定垂直间距。",
            "solution": "问题陈述经过验证，被认为是科学上合理、定义明确、客观且一致的。它描述了生存分析中的一个标准任务：使用非参数估计来检验比例风险假设。\n\n### 基于基本原理的推导\n目标是找到一种对 Kaplan-Meier (KM) 生存函数估计值 $\\hat{S}_g(t)$ 的变换，该变换能产生一个图形表示，其中平行线表示比例风险（PH）假设成立。我们从核心定义开始。\n\n设 $h_g(t)$ 为组 $g$ 的风险函数，$H_g(t) = \\int_0^t h_g(u)du$ 为累积风险函数，$S_g(t) = \\Pr(T > t)$ 为生存函数。它们之间的基本关系是 $S_g(t) = \\exp(-H_g(t))$。\n\n比例风险（PH）假设指出，一个组的风险函数是另一个参照组（我们用下标 $0$ 表示）的风险函数的常数倍。对于任何其他组 $g$，我们有：\n$$h_g(t) = \\lambda_g \\cdot h_0(t)$$\n其中 $\\lambda_g$ 是风险比，一个不依赖于时间 $t$ 的常数。\n\n为了看这个假设如何转化为其他函数，我们首先对风险函数进行积分以得到累积风险：\n$$H_g(t) = \\int_0^t h_g(u)du = \\int_0^t \\lambda_g \\cdot h_0(u)du = \\lambda_g \\int_0^t h_0(u)du = \\lambda_g \\cdot H_0(t)$$\n这表明，在 PH 假设下，累积风险函数也是成比例的。\n\n为了创建一个具有平行线的图形诊断工具，我们需要一个加性关系。对累积风险比例方程两边取自然对数，得到：\n$$\\log H_g(t) = \\log(\\lambda_g \\cdot H_0(t)) = \\log H_0(t) + \\log \\lambda_g$$\n这个方程表明，如果我们绘制 $\\log H_g(t)$ 相对于某个时间函数（例如，$t$ 或 $\\log t$）的曲线，不同组 $g$ 的曲线将是平行的，由一个恒定的垂直距离 $\\log \\lambda_g$（对数风险比）隔开。\n\n问题指定从 Kaplan-Meier 生存函数估计值 $\\hat{S}_g(t)$ 开始。我们现在必须将推导出的 $\\log H_g(t)$ 形式与 $S_g(t)$ 联系起来。根据定义 $S_g(t) = \\exp(-H_g(t))$，我们可以解出 $H_g(t)$：\n$$ \\log S_g(t) = -H_g(t) \\implies H_g(t) = -\\log S_g(t) $$\n请注意，由于 $S_g(t) \\in [0, 1]$，其对数 $\\log S_g(t)$ 是非正数。\n\n现在，将这个 $H_g(t)$ 的表达式代入我们的加性关系中：\n$$ \\log(-\\log S_g(t)) = \\log(-\\log S_0(t)) + \\log \\lambda_g $$\n这个变换，$y(t) = \\log(-\\log S(t))$，被称为互补对数-对数（cloglog）变换。这个推导证明了，如果 PH 假设成立，绘制不同组的经 cloglog 变换后的生存函数相对于某个时间轴（如 $t$ 或 $\\log t$）的曲线，应该会产生近似平行的曲线。组 $g$ 和参照组 $0$ 的曲线之间的恒定垂直距离是对数风险比 $\\log \\lambda_g$ 的估计。\n\n因此，步骤如下：\n1. 对于每个组 $g$，计算非参数的 Kaplan-Meier 估计值 $\\hat{S}_g(t)$。此方法能正确处理右删失数据。\n2. 对每个估计值应用互补对数-对数变换：$\\hat{y}_g(t) = \\log(-\\log \\hat{S}_g(t))$。\n3. 在同一坐标系中，绘制所有组的 $\\hat{y}_g(t)$ 相对于 $t$ 或 $\\log t$ 的曲线。x 轴选择 $\\log t$ 是常见的，因为它可以帮助更清晰地观察早期时间点的行为。\n4. 评估所得曲线是否合理平行。平行性支持 PH 假设，而交叉或系统性发散/收敛的曲线则表明违反了该假设。\n\n### 选项评估\n\n让我们根据这个推导来评估每个选项。\n\n**A. 对于每个组 $g$，在共同的事件时间网格上计算 KM 估计值 $\\hat S_g(t)$。然后，绘制所有组的互补对数-对数变换 $y_g(t) = \\log\\!\\big(-\\log \\hat S_g(t)\\big)$ 相对于 $\\log t$ 的曲线。在 PH 假设下，预计各组的曲线 $y_g(t)$ 会近似平行，因为组效应作为相对于 $t$ 的恒定垂直位移进入。在所有 $t$ 上的垂直间距的恒定性可解释为风险比不随时间变化的证据。对所有组使用相同的 $t$ 轴，应用 KM 固有的标准右删失处理，并避免在风险集稀疏的区域进行过度解释。**\n此选项与我们的推导完全匹配。它指定了正确的变换、正确的绘图、对平行线作为代表时不变风险比的恒定垂直位移的正确解释，并包含了适当的方法论警告。\n**结论：正确。**\n\n**B. 对于每个组 $g$，计算 $\\hat S_g(t)$ 并绘制 $\\hat S_g(t)$ 相对于 $t$ 的曲线。在 PH 假设下，曲线应在所有 $t$ 上显示恒定的垂直间距；此间距可被解读为风险比。因为 KM 已经考虑了右删失，所以不需要进一步的变换。**\n这描述了标准的 KM 曲线图。在 PH 假设下，$S_g(t) = [S_0(t)]^{\\lambda_g}$。垂直间距为 $S_0(t) - S_g(t) = S_0(t) - [S_0(t)]^{\\lambda_g}$，这是一个关于 $t$ 的函数，不是常数。因此，曲线不是平行的。此外，该间距不代表风险比。\n**结论：错误。**\n\n**C. 对于每个组 $g$，将组特异性风险函数估计为 $-\\frac{d}{dt}\\log \\hat S_g(t)$，并绘制其相对于 $t$ 的曲线。在 PH 假设下，风险函数在对时间轴进行重新缩放后应该对齐，因此重合的曲线可以证实 PH 假设。**\n虽然 $h(t) = -\\frac{d}{dt}\\log S(t)$ 在形式上是正确的，但从非参数阶梯函数 $\\hat{S}_g(t)$ 估计风险函数 $h(t)$（一个导数）是高度不稳定的，通常不直接这样做。更关键的是，PH 假设 $h_g(t) = \\lambda_g \\cdot h_0(t)$ 意味着风险曲线是*成比例的*，而不是在时间轴重新缩放后对齐。时间轴重新缩放对应于加速失效时间（AFT）模型，这是另一类模型。\n**结论：错误。**\n\n**D. 对于每个组 $g$，估计 Nelson-Aalen 累积风险 $\\hat H_g(t)$，然后绘制 $\\log \\hat H_g(t)$ 相对于 $t$ 的曲线。在 PH 假设下，曲线应该是平行的，在所有 $t$ 上具有恒定的垂直间距，该间距直接估计了对数风险比；这种方法优于 KM，因为它直接针对风险。**\n这描述了一个有效的替代诊断图。如推导所示，在 PH 假设下，绘制 $\\log H_g(t)$ 相对于时间的曲线应该会产生平行线。Nelson-Aalen 估计量是用于非参数估计 $H_g(t)$ 的合适工具。然而，问题明确地将方法限制为“使用 Kaplan-Meier (KM) 方法来估计 ... $\\hat{S}_g(t)$”并“转化特定组的生存估计”。选项 A 通过变换 $\\hat{S}_g(t)$ 本身来遵循这一限制。选项 D 则偏离了这一限制，建议使用一个不同的主要估计量，即 Nelson-Aalen 估计量。其关于偏好的声明也是主观判断，而非对所提方法论问题的直接回答。\n**结论：错误。**\n\n**E. 对于每个组 $g$，计算 $\\hat S_g(t)$ 并绘制 $\\log \\hat S_g(t)$ 相对于 $\\log t$ 的曲线。在 PH 假设下，曲线应该是平行的，因为风险的比例性意味着在对数尺度上生存率的比例性，从而产生一个可解释为对数风险比的恒定垂直间距。**\n在 PH 假设下，我们有 $\\log S_g(t) = \\lambda_g \\cdot \\log S_0(t)$。这是一种比例关系，而不是恒定的加性差异（平行）。在 $\\log S_g(t)$ 对 $\\log t$ 的图上，垂直间距将是 $\\log S_g(t) - \\log S_0(t) = (\\lambda_g - 1)\\log S_0(t)$，它通过 $S_0(t)$ 依赖于时间，因此不是恒定的。除非 $\\lambda_g=1$，否则曲线将不会平行。\n**结论：错误。**",
            "answer": "$$\\boxed{A}$$"
        },
        {
            "introduction": "在初步的图形检查之后，我们需要更严谨的统计模型来量化和检验非比例风险。检验比例风险假设最有力的方法之一，是明确地将时变效应纳入模型中。这通常通过在Cox模型中引入一个协变量与时间函数的交互项（例如，$x \\times \\log t$）来实现。这个高级编程练习将指导您从基本原理出发，实现一个包含时变协变量的Cox模型，从而让您深入理解这类模型是如何工作的，以及如何通过解释交互项的系数来判断效应是随时间增强还是减弱。",
            "id": "4555902",
            "problem": "你的任务是，从第一性原理出发，实现一个用于 Cox 比例风险 (PH) 模型的最大部分似然估计器。该模型通过扩展一个时变成分，来诊断对比例风险假设的违背。你必须严格使用的科学依据是：(i) 带有潜在时变协变量的 Cox 比例风险 (PH) 模型的定义，即风险被建模为 $\\lambda(t \\mid Z(t)) = \\lambda_0(t) \\exp\\{\\beta^\\top Z(t)\\}$，其中 $\\lambda_0(t)$ 是一个非参数基线风险，$\\beta$ 是一个有限维参数；以及 (ii) 基于观测事件时间处的风险集构建的 Cox 部分似然。假设不存在独立右删失，因此每个观测值都是一个事件时间，并假设没有左截断。\n\n你必须实现一个独立完整的程序，该程序能够：\n- 在已知的数据生成机制下模拟事件时间数据，其中风险取决于线性预测器中的一个二元协变量 $x \\in \\{0,1\\}$ 和一个时变交互项 $x \\log t$。具体来说，当 $x=0$ 时，风险为 $\\lambda(t \\mid x=0) = c$（一个恒定的基线风险）。当 $x=1$ 时，风险为 $\\lambda(t \\mid x=1) = c \\exp(\\beta_x) t^{\\beta_{x \\log t}}$，其中 $c$ 是一个正常数，$\\beta_x$ 是 $x$ 的系数，$\\beta_{x \\log t}$ 是交互项 $x \\log t$ 的系数。协变量 $x$ 从 $\\mathrm{Bernoulli}(0.5)$ 分布中独立抽取。你必须使用指定风险所隐含的累积风险，通过有效的逆变换采样来生成事件时间。\n- 通过最大化关于 $\\beta = (\\beta_x,\\; \\beta_{x \\log t})^\\top$ 的 Cox 部分对数似然，拟合一个带有事变协变量向量 $Z(t) = (x,\\; x \\log t)^\\top$ 的 Cox 模型，使用 Breslow 方法处理时间平局，并采用 Newton–Raphson 优化。对于每个唯一的观测事件时间 $t_j$，使用风险集 $R_j = \\{i: T_i \\ge t_j\\}$，并在事件时间 $t_j$ 处为所有 $i \\in R_j$ 评估 $Z_i(t_j)$。\n- 对于每个数据集，根据以下规则返回估计的交互作用系数 $\\widehat{\\beta}_{x \\log t}$ 的符号，作为一个在 $\\{-1, 0, +1\\}$ 中的整数：如果 $\\lvert \\widehat{\\beta}_{x \\log t} \\rvert  \\tau$，返回 $0$；如果 $\\widehat{\\beta}_{x \\log t} \\ge \\tau$，返回 $+1$；如果 $\\widehat{\\beta}_{x \\log t} \\le -\\tau$，返回 $-1$。其中 $\\tau$ 是下面给出的一个小的正常数容差。这个整数编码了从比例风险假设推断出的偏离方向：$+1$ 表示 $x$ 的效应随时间增强，$-1$ 表示其随时间减弱，而 $0$ 表示在容差范围内没有可检测到的偏离。\n\n你的实现必须仅依赖于模型定义和部分似然的构建。你必须推导并实现用于 Newton–Raphson 的得分向量 (score) 和观测信息矩阵 (observed information)，而不能使用任何预构建的生存分析库。使用 Breslow 近似法处理时间平局。对于所有的 $\\log t$，使用自然对数。\n\n使用以下固定的参数设置测试套件。对于每种情况，模拟数据集，然后按上述规定拟合模型。在每种情况下，为了使结果具有确定性，你必须在模拟前将随机种子设置为给定值。\n\n- 情况 A (比例风险假设成立):\n  - 样本量 $n = 4000$\n  - 基线风险 $c = 0.05$\n  - $x$ 的系数: $\\beta_x = 0.4$\n  - $x \\log t$ 的系数: $\\beta_{x \\log t} = 0$\n  - 随机种子 $= 123$\n- 情况 B ($x$ 的效应随时间增强):\n  - 样本量 $n = 2000$\n  - 基线风险 $c = 0.05$\n  - $x$ 的系数: $\\beta_x = 0.2$\n  - $x \\log t$ 的系数: $\\beta_{x \\log t} = 0.6$\n  - 随机种子 $= 456$\n- 情况 C ($x$ 的效应随时间减弱):\n  - 样本量 $n = 2000$\n  - 基线风险 $c = 0.05$\n  - $x$ 的系数: $\\beta_x = 0.2$\n  - $x \\log t$ 的系数: $\\beta_{x \\log t} = -0.6$\n  - 随机种子 $= 789$\n\n实现细节与约束：\n- 使用逆变换采样方法，根据指定的风险生成事件时间。对于 $x \\in \\{0,1\\}$ 的 $x=0$ 或 $x=1$ 的情况，必须精确积分累积风险函数并对其求逆，以获得一个有效的正事件时间生成器。\n- 实现 Newton–Raphson 算法，并设置一个合理的收敛停止准则，该准则可以基于参数增量范数或得分向量范数，同时设置一个适度的最大迭代次数以保证算法终止。如果需要，当部分对数似然减小时，应用简单的步长减半法。\n- 在部分对数似然及其一阶和二阶导数的计算中，使用 Breslow 近似法来处理事件时间平局。\n- 对所有出现的 $\\log$，均使用自然对数。\n\n容差和输出：\n- 使用分类容差 $\\tau = 0.05$。\n- 你的程序应生成单行输出，其中包含按顺序对应的案例 A、B 和 C 的三个整数结果，形式为用方括号括起来的逗号分隔列表（例如, $\\left[\\text{result}_A,\\text{result}_B,\\text{result}_C\\right]$）。这些整数必须是上文定义的 $-1$、$0$ 或 $+1$。\n\n在适用情况下，所有答案都是无单位的实数；不涉及物理单位。不涉及角度。最终输出是指定的整数，因此不需要也不允许使用百分比。该问题被设计为普适的，可以使用任何支持基础线性代数和数值优化的现代编程语言来解决，但必须严格遵循上述算法规范。",
            "solution": "该问题要求实现一个用于 Cox 比例风险模型的最大部分似然估计器，该模型通过一个时变协变量进行扩展，以诊断对比例风险 (PH) 假设的违背。从数据模拟到模型拟合的整个过程都必须从第一性原理出发实现。\n\n### 1. 理论基础\n\nCox 比例风险模型将一个个体在时间 $t$ 具有协变量向量 $Z(t)$ 的风险率 $\\lambda(t)$ 描述为：\n$$\n\\lambda(t \\mid Z(t)) = \\lambda_0(t) \\exp\\{\\beta^\\top Z(t)\\}\n$$\n此处，$\\lambda_0(t)$ 是一个任意的、非负的基线风险函数，$\\beta$ 是一个回归系数向量。PH 假设假定任意两个个体的风险比率随时间保持不变。如果协变量 $Z(t)$ 显式地依赖于时间，则该假设被违背。\n\n为了检验二元协变量 $x \\in \\{0, 1\\}$ 的 PH 假设，我们可以引入一个与时间函数（如 $\\log t$）的交互项。协变量向量变为 $Z(t) = (x, x \\log t)^\\top$，对应的参数向量为 $\\beta = (\\beta_x, \\beta_{x \\log t})^\\top$。线性预测器为 $\\eta(t) = \\beta_x x + \\beta_{x \\log t} (x \\log t)$。一个 $x=1$ 的受试者与一个 $x=0$ 的受试者之间的风险比为：\n$$\n\\frac{\\lambda(t \\mid x=1)}{\\lambda(t \\mid x=0)} = \\frac{\\lambda_0(t) \\exp(\\beta_x + \\beta_{x \\log t} \\log t)}{\\lambda_0(t) \\exp(0)} = \\exp(\\beta_x) t^{\\beta_{x \\log t}}\n$$\n如果 $\\beta_{x \\log t} = 0$，风险比是恒定的 ($\\exp(\\beta_x)$)，PH 假设成立。如果 $\\beta_{x \\log t} \\neq 0$，则该假设被违背。一个正的 $\\beta_{x \\log t}$ 表明协变量的效应随时间增强，而一个负值则表明其效应减弱。因此，估计系数 $\\widehat{\\beta}_{x \\log t}$ 的符号可以诊断偏离比例风险的性质。\n\n### 2. 通过逆变换采样进行数据模拟\n\n我们必须从指定的数据生成机制中生成事件时间数据。这通过逆变换采样实现，该方法通过累积风险函数 $H(t) = \\int_0^t \\lambda(u) du$ 将一个均匀分布的随机变量 $U \\sim \\mathrm{Uniform}(0,1)$ 与一个事件时间 $T$ 联系起来。它们的关系是 $T = H^{-1}(-\\log U)$。由于 $-\\log U$ 服从速率为 1 的指数分布，我们可以写成 $T = H^{-1}(E)$，其中 $E \\sim \\mathrm{Exponential}(1)$。\n\n基于二元协变量 $x \\sim \\mathrm{Bernoulli}(0.5)$，为两个层给定了风险函数：\n-   对于 $x=0$：风险为 $\\lambda(t \\mid x=0) = c$。\n    累积风险为 $H(t \\mid x=0) = \\int_0^t c \\,du = ct$。\n    对其求逆得到 $H^{-1}(y) = y/c$。因此，事件时间通过 $T = E/c$ 采样。\n-   对于 $x=1$：风险为 $\\lambda(t \\mid x=1) = c \\exp(\\beta_x) t^{\\beta_{x \\log t}}$。令 $A = c \\exp(\\beta_x)$ 且 $p = \\beta_{x \\log t}$。\n    -   如果 $p \\neq -1$，累积风险为 $H(t \\mid x=1) = \\int_0^t A u^p \\,du = \\frac{A}{p+1} t^{p+1}$。\n        对其求逆得到 $H^{-1}(y) = \\left( \\frac{y(p+1)}{A} \\right)^{1/(p+1)}$。因此，事件时间通过 $T = \\left( \\frac{E(p+1)}{A} \\right)^{1/(p+1)}$ 采样。\n    -   特殊情况 $p=0$（情况 A）对应于恒定风险 $\\lambda(t \\mid x=1) = A$。生成器简化为 $T = E/A$。当 $p \\to 0$ 时，这与通用公式一致。\n\n### 3. 通过 Newton-Raphson 进行参数估计\n\n参数向量 $\\beta = (\\beta_x, \\beta_{x \\log t})^\\top$ 通过最大化 Cox 部分对数似然来估计。在有观测事件时间、无删失并允许时间平局的情况下，数据由对 $(T_i, x_i)$ 组成，其中 $i=1, \\dots, n$。令 $k$ 个不同的有序事件时间为 $T_{(1)}  T_{(2)}  \\dots  T_{(k)}$。令 $D_j$ 为在 $T_{(j)}$ 发生事件的个体集合，其大小为 $d_j = |D_j|$。令 $R_j = \\{i: T_i \\ge T_{(j)}\\}$ 为在时间 $T_{(j)}$ 的风险集。\n\n使用 Breslow 近似法处理时间平局，部分对数似然为：\n$$\n\\ell(\\beta) = \\sum_{j=1}^{k} \\left( \\sum_{l \\in D_j} \\beta^\\top Z_l(T_{(j)}) - d_j \\log \\left( \\sum_{i \\in R_j} \\exp\\{\\beta^\\top Z_i(T_{(j)})\\} \\right) \\right)\n$$\n其中 $Z_i(t) = (x_i, x_i \\log t)^\\top$。\n\n为了最大化 $\\ell(\\beta)$，我们使用 Newton-Raphson 算法，该算法通过以下方式迭代更新估计值 $\\beta_m$：\n$$\n\\beta_{m+1} = \\beta_m + I(\\beta_m)^{-1} U(\\beta_m)\n$$\n其中 $U(\\beta) = \\frac{\\partial \\ell}{\\partial \\beta}$ 是得分向量（梯度），$I(\\beta) = -\\frac{\\partial^2 \\ell}{\\partial \\beta \\partial \\beta^\\top}$ 是观测信息矩阵（负 Hessian 矩阵）。\n\n让我们定义在时间 $T_{(j)}$ 的风险集 $R_j$ 上的以下求和：\n-   $S_j^{(0)}(\\beta) = \\sum_{i \\in R_j} \\exp\\{\\beta^\\top Z_i(T_{(j)})\\}$\n-   $S_j^{(1)}(\\beta) = \\sum_{i \\in R_j} Z_i(T_{(j)}) \\exp\\{\\beta^\\top Z_i(T_{(j)})\\}$\n-   $S_j^{(2)}(\\beta) = \\sum_{i \\in R_j} Z_i(T_{(j)}) Z_i(T_{(j)})^\\top \\exp\\{\\beta^\\top Z_i(T_{(j)})\\}$\n\n得分向量是对数似然的一阶导数：\n$$\nU(\\beta) = \\frac{\\partial \\ell}{\\partial \\beta} = \\sum_{j=1}^{k} \\left( \\sum_{l \\in D_j} Z_l(T_{(j)}) - d_j \\frac{S_j^{(1)}(\\beta)}{S_j^{(0)}(\\beta)} \\right)\n$$\n观测信息矩阵是二阶导数（Hessian 矩阵）的负值：\n$$\nI(\\beta) = -\\frac{\\partial^2 \\ell}{\\partial \\beta \\partial \\beta^\\top} = \\sum_{j=1}^{k} d_j \\left[ \\frac{S_j^{(2)}(\\beta)}{S_j^{(0)}(\\beta)} - \\left(\\frac{S_j^{(1)}(\\beta)}{S_j^{(0)}(\\beta)}\\right) \\left(\\frac{S_j^{(1)}(\\beta)}{S_j^{(0)}(\\beta)}\\right)^\\top \\right]\n$$\n\n### 4. 实现算法\n\n对于每个测试用例，总体算法按以下步骤进行：\n1.  **数据生成**：对于给定的参数（$n, c, \\beta_x, \\beta_{x \\log t}$）和随机种子，使用上述逆变换采样方法生成 $n$ 个协变量值 $x_i$ 和相应的事件时间 $T_i$。\n2.  **数据准备**：按事件时间 $T_i$ 对数据对 $(T_i, x_i)$ 进行排序。识别出唯一的事件时间 $T_{(j)}$ 及其频率（平局计数）$d_j$。\n3.  **Newton-Raphson 迭代**：\n    a. 初始化参数向量 $\\beta = (0, 0)^\\top$。\n    b. 迭代一个最大步数：\n        i. 通过对每个唯一事件时间 $T_{(j)}$ 的贡献求和，计算对数似然 $\\ell(\\beta)$、得分向量 $U(\\beta)$ 和信息矩阵 $I(\\beta)$。这涉及为每个风险集 $R_j$ 计算 $S_j^{(0)}, S_j^{(1)}, S_j^{(2)}$。\n        ii. 通过检验得分向量的范数 $\\|U(\\beta)\\|$ 是否低于一个小容差（例如，$10^{-6}$）来检查收敛性。如果是，则终止并返回当前的 $\\beta$。\n        iii. 计算 Newton-Raphson 步长：$\\Delta\\beta = I(\\beta)^{-1} U(\\beta)$。这可以作为线性系统 $I(\\beta) \\Delta\\beta = U(\\beta)$ 求解。\n        iv. **步长减半**：为确保每一步的似然都增加，应用回溯线搜索。从步长 $\\alpha=1$ 开始。如果 $\\ell(\\beta + \\alpha \\Delta\\beta) \\le \\ell(\\beta)$，则将 $\\alpha$ 减半并重复。一旦找到改进，就更新 $\\beta \\leftarrow \\beta + \\alpha \\Delta\\beta$。如果 $\\alpha$ 变得过小，则终止以避免不收敛。\n\n### 5. 输出分类\n\n在 Newton-Raphson 算法收敛到一个估计值 $\\widehat{\\beta} = (\\widehat{\\beta}_x, \\widehat{\\beta}_{x \\log t})^\\top$ 之后，我们检查交互作用系数 $\\widehat{\\beta}_{x \\log t}$ 的符号来诊断对 PH 假设的违背。使用给定的容差 $\\tau = 0.05$，结果被分类为：\n-   如果 $\\widehat{\\beta}_{x \\log t} \\ge \\tau$，则为 $+1$（效应随时间增强）\n-   如果 $\\widehat{\\beta}_{x \\log t} \\le -\\tau$，则为 $-1$（效应随时间减弱）\n-   如果 $|\\widehat{\\beta}_{x \\log t}|  \\tau$，则为 $0$（未检测到显著违背）\n\n对三个测试用例中的每一个都计算这个整数结果，最终输出是这三个整数的列表。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef _calculate_loglik_derivatives(beta, T_sorted, x_sorted, unique_times, tie_first_indices, tie_counts, compute_derivatives=True):\n    \"\"\"\n    Calculates the partial log-likelihood, score vector, and information matrix.\n    \"\"\"\n    log_lik = 0.0\n    score = np.zeros(2) if compute_derivatives else None\n    information = np.zeros((2, 2)) if compute_derivatives else None\n\n    # Iterate through unique event times\n    for j in range(len(unique_times)):\n        t_j = unique_times[j]\n        d_j = tie_counts[j]\n        risk_set_start_idx = tie_first_indices[j]\n        \n        risk_set_x = x_sorted[risk_set_start_idx:]\n        death_set_x = x_sorted[risk_set_start_idx : risk_set_start_idx + d_j]\n        \n        # Using np.log1p(t_j - 1) might be more stable for t_j near 1,\n        # but problem states log(t) and times are not pathologically close to 0.\n        log_t_j = np.log(t_j)\n        \n        # Covariate Z(t_j) for the entire risk set\n        Z_risk = np.zeros((len(risk_set_x), 2))\n        Z_risk[:, 0] = risk_set_x\n        Z_risk[:, 1] = risk_set_x * log_t_j\n        \n        # Linear predictor eta = beta^T * Z for risk set\n        eta_risk = Z_risk @ beta\n        \n        # Risk scores exp(eta)\n        exp_eta_risk = np.exp(eta_risk)\n        \n        S0 = np.sum(exp_eta_risk)\n        if S0 == 0:\n            # This case is highly unlikely with non-trivial data\n            continue\n        \n        # Covariate Z(t_j) for the death set\n        Z_deaths = np.zeros((d_j, 2))\n        Z_deaths[:, 0] = death_set_x\n        Z_deaths[:, 1] = death_set_x * log_t_j\n        \n        # Log-likelihood contribution\n        eta_deaths = Z_deaths @ beta\n        log_lik += np.sum(eta_deaths) - d_j * np.log(S0)\n        \n        if compute_derivatives:\n            # S1 = sum(Z * exp(eta)) over risk set\n            S1 = (Z_risk.T @ exp_eta_risk)\n            # S2 = sum(Z * Z.T * exp(eta)) over risk set\n            S2 = (Z_risk.T * exp_eta_risk) @ Z_risk\n            \n            E_j = S1 / S0\n            \n            # Score vector contribution\n            sum_Z_deaths = np.sum(Z_deaths, axis=0)\n            score += sum_Z_deaths - d_j * E_j\n            \n            # Information matrix contribution\n            V_j = (S2 / S0) - np.outer(E_j, E_j)\n            information += d_j * V_j\n\n    return log_lik, score, information\n\ndef _fit_cox_model(T, x, max_iter=50, tol=1e-6, min_alpha=1e-5):\n    \"\"\"\n    Fits the Cox model with time-dependent covariates using Newton-Raphson.\n    \"\"\"\n    # Sort data by event time\n    sort_indices = np.argsort(T)\n    T_sorted = T[sort_indices]\n    x_sorted = x[sort_indices]\n\n    # Get unique times and tie structure\n    unique_times, tie_first_indices, tie_counts = np.unique(T_sorted, return_index=True, return_counts=True)\n    \n    beta = np.zeros(2)\n\n    for _ in range(max_iter):\n        log_lik, score, information = _calculate_loglik_derivatives(beta, T_sorted, x_sorted, unique_times, tie_first_indices, tie_counts)\n\n        if np.linalg.norm(score)  tol:\n            break\n\n        try:\n            delta_beta = np.linalg.solve(information, score)\n        except np.linalg.LinAlgError:\n            # Singular matrix, cannot proceed\n            return beta \n\n        alpha = 1.0\n        while alpha > min_alpha:\n            beta_new = beta + alpha * delta_beta\n            new_log_lik, _, _ = _calculate_loglik_derivatives(beta_new, T_sorted, x_sorted, unique_times, tie_first_indices, tie_counts, compute_derivatives=False)\n            \n            if np.isfinite(new_log_lik) and new_log_lik > log_lik:\n                beta = beta_new\n                break\n            alpha /= 2\n        \n        if alpha = min_alpha:\n            # Step-halving failed to find improvement.\n            break\n    \n    return beta\n\ndef _simulate_data(n, c, beta_x, beta_xt, seed):\n    \"\"\"\n    Simulates event time data based on the specified hazard functions.\n    \"\"\"\n    rng = np.random.default_rng(seed)\n    x = rng.binomial(1, 0.5, n)\n    T = np.zeros(n)\n    \n    # Generate standard exponential random variables\n    E = rng.exponential(1, n)\n\n    # Stratum x=0\n    mask0 = (x == 0)\n    T[mask0] = E[mask0] / c\n\n    # Stratum x=1\n    mask1 = (x == 1)\n    A = c * np.exp(beta_x)\n    p = beta_xt\n\n    # Handle the two sub-cases for x=1\n    if np.abs(p)  1e-9: # Proportional hazards subcase\n        T[mask1] = E[mask1] / A\n    else: # Non-proportional hazards subcase\n        T[mask1] = (E[mask1] * (p + 1) / A) ** (1 / (p + 1))\n    \n    return T, x\n\ndef _process_case(n, c, beta_x, beta_xt, seed, tau):\n    \"\"\"\n    Runs one full cycle: simulation, fitting, and classification.\n    \"\"\"\n    T, x = _simulate_data(n, c, beta_x, beta_xt, seed)\n    beta_hat = _fit_cox_model(T, x)\n    beta_xt_hat = beta_hat[1]\n    \n    if beta_xt_hat >= tau:\n        return 1\n    elif beta_xt_hat = -tau:\n        return -1\n    else:\n        return 0\n\ndef solve():\n    \"\"\"\n    Main function to run all test cases and print the final result.\n    \"\"\"\n    test_cases = [\n        # Case A: Proportional hazards\n        {'n': 4000, 'c': 0.05, 'beta_x': 0.4, 'beta_xt': 0.0, 'seed': 123},\n        # Case B: Increasing effect\n        {'n': 2000, 'c': 0.05, 'beta_x': 0.2, 'beta_xt': 0.6, 'seed': 456},\n        # Case C: Decreasing effect\n        {'n': 2000, 'c': 0.05, 'beta_x': 0.2, 'beta_xt': -0.6, 'seed': 789},\n    ]\n    \n    tau = 0.05\n    results = []\n    \n    for case in test_cases:\n        result = _process_case(case['n'], case['c'], case['beta_x'], case['beta_xt'], case['seed'], tau)\n        results.append(result)\n\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n\n```"
        },
        {
            "introduction": "在现代生物信息学和临床研究中，我们分析的模型常常包含数十甚至数百个协变量。为每个协变量分别进行比例风险假设检验会引入多重比较问题，这会显著增加我们错误地发现“显著”违规的概率。本练习聚焦于这一常见的实际挑战，向您展示如何应用如Benjamini-Hochberg等方法来校正p值并控制错误发现率（False Discovery Rate, FDR），确保您在处理多协变量模型时得出的诊断结论更为稳健和可靠。",
            "id": "4555985",
            "problem": "一项转化肿瘤学研究对一个包含 $n = 410$ 名患者的队列的总生存期拟合了Cox比例风险模型。该模型包含了 $m = 10$ 个基线协变量：年龄、性别、分期、肿瘤分级、治疗组、身体质量指数、一个五基因表达特征评分、吸烟状况、Charlson合并症指数和招募中心。为了诊断每个协变量的比例风险假设，研究人员基于缩放的Schoenfeld残差计算了特定于协变量的Grambsch–Therneau检验。在相应系数不随时间变化的零假设下，每次检验都会产生一个$p$值。观测到的特定于协变量的$p$值如下：\n- 年龄：$0.031$,\n- 性别：$0.72$,\n- 分期：$0.004$,\n- 肿瘤分级：$0.058$,\n- 治疗组：$0.12$,\n- 身体质量指数：$0.29$,\n- 五基因特征评分：$0.0009$,\n- 吸烟状况：$0.21$,\n- Charlson合并症指数：$0.045$,\n- 招募中心：$0.36$.\n\n仅使用Cox比例风险模型的基本定义、比例风险假设、作为零假设下尾部概率的$p$值概念，以及作为所有拒绝中错误拒绝的预期比例的错误发现率的定义，计算这$m=10$次检验的Benjamini–Hochberg校正$p$值。然后，在将错误发现率控制在$q = 0.10$的水平上时，解释哪些协变量显示出违反比例风险假设的证据。\n\n仅报告在错误发现率水平$q = 0.10$下显著违反比例风险假设的协变量数量作为您的最终答案。不要对中间量进行四舍五入；最终报告的值必须是一个整数计数。",
            "solution": "### 解题过程\n该问题要求我们评估Cox模型中$m=10$个协变量违反比例风险（PH）假设的证据。对每个协变量都进行Grambsch–Therneau检验，得出一个$p$值。每次检验的零假设是该协变量的PH假设成立。一个小的$p$值表明该假设被违反。\n\n由于我们正在同时进行$m=10$次假设检验，我们必须进行多重比较校正以控制错误率。问题指定要控制错误发现率（FDR），即在所有被拒绝的假设中，错误拒绝的零假设（错误发现）的预期比例。所选的FDR水平为$q = 0.10$。我们将使用Benjamini–Hochberg（BH）程序来实现这一控制。\n\nBenjamini-Hochberg程序包括以下步骤：\n\n1.  将$m=10$个单独的$p$值从小到大排序。让这些排序后的$p$值表示为$P_{(1)}, P_{(2)}, \\dots, P_{(m)}$。\n2.  计算每次检验的BH校正$p$值。第$i$个排序检验的校正$p$值，$p_{adj,(i)}$，由以下公式给出：\n    $$p_{adj,(i)} = \\min_{j=i, \\dots, m} \\left\\{ \\frac{m}{j} P_{(j)} \\right\\}$$\n    这确保了校正$p$值序列是单调不减的。一个实用的递归计算方法是：\n    -   对于最大的$p$值（$i=m$）：$p_{adj,(m)} = P_{(m)}$。\n    -   对于所有其他的$p$值（$i = m-1, \\dots, 1$）：$p_{adj,(i)} = \\min\\left(\\frac{m}{i}P_{(i)}, p_{adj,(i+1)}\\right)$。\n3.  将每个校正后的$p$值与FDR水平$q$进行比较。如果一个检验的校正$p$值小于或等于$q$，则宣布其为显著。\n\n让我们将这个程序应用于给定的数据。\n\n**步骤 1：对$p$值进行排序**\n给出的$m=10$个$p$值为：$0.031$, $0.72$, $0.004$, $0.058$, $0.12$, $0.29$, $0.0009$, $0.21$, $0.045$, $0.36$。\n将它们排序后得到：\n-   $P_{(1)} = 0.0009$ (五基因特征评分)\n-   $P_{(2)} = 0.004$ (分期)\n-   $P_{(3)} = 0.031$ (年龄)\n-   $P_{(4)} = 0.045$ (Charlson合并症指数)\n-   $P_{(5)} = 0.058$ (肿瘤分级)\n-   $P_{(6)} = 0.12$ (治疗组)\n-   $P_{(7)} = 0.21$ (吸烟状况)\n-   $P_{(8)} = 0.29$ (身体质量指数)\n-   $P_{(9)} = 0.36$ (招募中心)\n-   $P_{(10)} = 0.72$ (性别)\n\n**步骤 2：计算BH校正$p$值**\n我们使用$m=10$并从$i=10$到$i=1$递归地计算校正$p$值。\n\n-   对于 $i=10$: $p_{adj,(10)} = P_{(10)} = 0.72$。\n-   对于 $i=9$: $p_{adj,(9)} = \\min\\left(\\frac{10}{9}P_{(9)}, p_{adj,(10)}\\right) = \\min\\left(\\frac{10}{9} \\times 0.36, 0.72\\right) = \\min(0.4, 0.72) = 0.4$。\n-   对于 $i=8$: $p_{adj,(8)} = \\min\\left(\\frac{10}{8}P_{(8)}, p_{adj,(9)}\\right) = \\min\\left(\\frac{10}{8} \\times 0.29, 0.4\\right) = \\min(0.3625, 0.4) = 0.3625$。\n-   对于 $i=7$: $p_{adj,(7)} = \\min\\left(\\frac{10}{7}P_{(7)}, p_{adj,(8)}\\right) = \\min\\left(\\frac{10}{7} \\times 0.21, 0.3625\\right) = \\min(0.3, 0.3625) = 0.3$。\n-   对于 $i=6$: $p_{adj,(6)} = \\min\\left(\\frac{10}{6}P_{(6)}, p_{adj,(7)}\\right) = \\min\\left(\\frac{10}{6} \\times 0.12, 0.3\\right) = \\min(0.2, 0.3) = 0.2$。\n-   对于 $i=5$: $p_{adj,(5)} = \\min\\left(\\frac{10}{5}P_{(5)}, p_{adj,(6)}\\right) = \\min\\left(2 \\times 0.058, 0.2\\right) = \\min(0.116, 0.2) = 0.116$。\n-   对于 $i=4$: $p_{adj,(4)} = \\min\\left(\\frac{10}{4}P_{(4)}, p_{adj,(5)}\\right) = \\min\\left(2.5 \\times 0.045, 0.116\\right) = \\min(0.1125, 0.116) = 0.1125$。\n-   对于 $i=3$: $p_{adj,(3)} = \\min\\left(\\frac{10}{3}P_{(3)}, p_{adj,(4)}\\right) = \\min\\left(\\frac{10}{3} \\times 0.031, 0.1125\\right) = \\min\\left(\\frac{0.31}{3}, 0.1125\\right) \\approx \\min(0.10333, 0.1125) = \\frac{0.31}{3}$。\n-   对于 $i=2$: $p_{adj,(2)} = \\min\\left(\\frac{10}{2}P_{(2)}, p_{adj,(3)}\\right) = \\min\\left(5 \\times 0.004, \\frac{0.31}{3}\\right) = \\min(0.02, 0.10333...) = 0.02$。\n-   对于 $i=1$: $p_{adj,(1)} = \\min\\left(\\frac{10}{1}P_{(1)}, p_{adj,(2)}\\right) = \\min\\left(10 \\times 0.0009, 0.02\\right) = \\min(0.009, 0.02) = 0.009$。\n\n**步骤 3：将校正后的p值与FDR水平$q=0.10$进行比较**\n我们现在确定哪些校正后的$p$值小于或等于$q=0.10$。\n\n-   $p_{adj,(1)} = 0.009 \\leq 0.10$ (显著)。这对应于**五基因特征评分**。\n-   $p_{adj,(2)} = 0.02 \\leq 0.10$ (显著)。这对应于**分期**。\n-   $p_{adj,(3)} = \\frac{0.31}{3} \\approx 0.10333 > 0.10$ (不显著)。这对应于**年龄**。\n\n由于校正后的$p$值是单调递增的，后续的检验都不会显著。对应于$P_{(1)}$和$P_{(2)}$的假设被拒绝。所有其他零假设不被拒绝。\n\n因此，在将错误发现率控制在$10\\%$的水平时，有两个协变量显示出违反比例风险假设的统计显著证据。这些协变量是五基因特征评分和分期。\n\n最终要求的答案是这些显著协变量的数量。数量为$2$。",
            "answer": "$$\\boxed{2}$$"
        }
    ]
}