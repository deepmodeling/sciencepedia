{
    "hands_on_practices": [
        {
            "introduction": "要真正掌握聚类评估，第一步是精通核心指标的计算。本练习将指导您从头开始实现轮廓系数（Silhouette Coefficient）。更重要的是，它将通过一系列测试案例，揭示不同的数据预处理技术（如Z-score标准化和对数变换）如何显著影响评估结果，这是一个在任何数据分析流程中都至关重要的实践课程，可以帮助您理解为何在计算距离之前必须仔细考虑特征缩放。",
            "id": "4561589",
            "problem": "给定多个代表生物信息学和医疗数据分析场景的小型特征矩阵，其中已经执行了聚类并指定了簇标签。您必须通过计算每个样本的标准化指数来评估聚类结果，该指数基于簇内凝聚度和最近的簇间分离度，然后得出所有样本的总体平均指数。评估必须在不同的预处理流程下完成，包括特征缩放、归一化和方差稳定化，并使用欧几里得度量。\n\n使用的基本定义：\n- 设数据集为 $\\mathbb{R}^d$ 中的一组点 $\\{x_i\\}_{i=1}^n$。\n- 设相异度由 $\\mathbb{R}^d$ 上的度量 $d(\\cdot,\\cdot)$ 定义；具体来说，使用欧几里得度量 $d(x,y)=\\sqrt{\\sum_{j=1}^d (x_j - y_j)^2}$。\n- 設聚类为将 $\\{1,\\dots,n\\}$ 划分为 $K$ 个不相交的非空索引集 $\\{C_k\\}_{k=1}^K$，其中每个 $C_k$ 索引属于簇 $k$ 的样本。样本 $i$ 的簇标签是一个整数 $L_i \\in \\{0,1,\\dots,K-1\\}$，它将样本 $i$ 映射到其所在的簇。\n- 对于每个样本 $i$，将平均簇内相异度 $a(i)$ 定义为 $d(x_i, x_j)$ 在与 $i$ 属于同一簇的所有 $j$（其中 $j \\neq i$）上的平均值。如果包含 $i$ 的簇大小为 $1$，则按惯例直接将每个样本的标准化指数设置为 $0$。\n- 对于每个样本 $i$，通过计算对于每个簇 $k \\neq L_i$，从 $i$到 $C_k$ 中所有样本的平均相异度，来定义最近的其他簇，并令 $b(i)$ 为这些平均相异度的最小值。\n- 从 $a(i)$ 和 $b(i)$ 推导出一个界于 $\\left[-1, 1\\right]$ 内的逐样本标准化指数，当 $x_i$ 与其自身簇的成员（平均而言）比与最近的其他簇的成员更近时，该指数增加；如果您推导的表达式中的归一化分母为 $0$，则为保持数值稳定性将该指数设置为 $0$。总体评估度量，即轮廓系数（SC），定义为该逐样本标准化指数在所有样本中的平均值。\n\n在计算度量之前应用的预处理流程：\n- Z-score 标准化：对于每个特征 $j \\in \\{1,\\dots,d\\}$，计算所有样本的特征均值 $\\mu_j$ 和特征标准差 (SD) $\\sigma_j$，并将每个 $x_{ij}$ 转换为 $(x_{ij} - \\mu_j)/\\sigma_j$。如果 $\\sigma_j = 0$，为避免除以零，将所有样本的转换后特征值设置为 $0$。\n- 最小-最大缩放：对于每个特征 $j$，计算所有样本的特征最小值 $m_j$ 和最大值 $M_j$，并将每个 $x_{ij}$ 转换为 $(x_{ij} - m_j)/(M_j - m_j)$。如果 $M_j = m_j$，为避免除以零，将所有样本的转换后特征值设置为 $0$。\n- 计数的方差稳定化：对于计数类特征，对数据矩阵逐元素应用自然对数变换 $\\log(1+x)$（log-one-plus），然后如上所述应用 Z-score 标准化。\n\n距离计算必须在应用指定的预处理流程之后执行。使用欧几里得距离，不附加任何权重。\n\n约定和处理方式：\n- 如果只有一个簇 ($K=1$)，则将总体 SC 定义为 $0$。\n- 如果样本属于单例簇（簇大小为 $1$），则将其逐样本标准化指数设置为 $0$。\n- 如果某个样本的标准化指数中的归一化分母为 $0$，则将该样本的标准化指数设置为 $0$。\n\n测试套件规范：\n为以下每个测试用例计算总体 SC。每个用例都指定了数据矩阵、标签向量和预处理流程。\n\n- 测试用例 $1$ (标准情况，混合尺度使用z-score标准化)：\n  数据矩阵 $X_{\\text{mixed}} \\in \\mathbb{R}^{6 \\times 3}$，行向量为：\n  $\\left[100.0, 1.2, 5000.0\\right]$,\n  $\\left[110.0, 0.8, 5100.0\\right]$,\n  $\\left[95.0, 1.0, 4900.0\\right]$,\n  $\\left[5.0, 50.0, 180.0\\right]$,\n  $\\left[7.0, 49.5, 200.0\\right]$,\n  $\\left[6.0, 48.0, 220.0\\right]$.\n  标签 $L_{\\text{mixed}}$:\n  $\\left[0, 0, 0, 1, 1, 1\\right]$.\n  预处理流程：z-score 标准化。\n\n- 测试用例 $2$ (无缩放对混合尺度的影响)：\n  使用与测试用例 $1$ 相同的 $X_{\\text{mixed}}$ 和 $L_{\\text{mixed}}$。\n  预处理流程：无。\n\n- 测试用例 $3$ (边界条件，包含单例簇和最小-最大缩放)：\n  数据矩阵 $X_{\\text{singleton}} \\in \\mathbb{R}^{5 \\times 2}$，行向量为：\n  $\\left[1.0, 100.0\\right]$,\n  $\\left[1.1, 98.0\\right]$,\n  $\\left[10.0, 5.0\\right]$,\n  $\\left[9.5, 6.0\\right]$,\n  $\\left[100.0, 1000.0\\right]$.\n  标签 $L_{\\text{singleton}}$:\n  $\\left[0, 0, 1, 1, 2\\right]$.\n  预处理流程：最小-最大缩放。\n\n- 测试用例 $4$ (计数数据，无方差稳定化)：\n  数据矩阵 $X_{\\text{counts}} \\in \\mathbb{R}^{9 \\times 4}$，行向量为：\n  $\\left[0, 10, 500, 2000\\right]$,\n  $\\left[1, 12, 520, 2100\\right]$,\n  $\\left[0, 9, 480, 1950\\right]$,\n  $\\left[50, 0, 30, 0\\right]$,\n  $\\left[45, 1, 28, 2\\right]$,\n  $\\left[55, 2, 35, 1\\right]$,\n  $\\left[0, 300, 0, 100\\right]$,\n  $\\left[1, 290, 0, 90\\right]$,\n  $\\left[2, 310, 1, 110\\right]$.\n  标签 $L_{\\text{counts}}$:\n  $\\left[0, 0, 0, 1, 1, 1, 2, 2, 2\\right]$.\n  预处理流程：无。\n\n- 测试用例 $5$ (计数数据，通过 $\\log(1+x)$ 进行方差稳定化，然后进行 z-score 标准化)：\n  使用与测试用例 $4$ 相同的 $X_{\\text{counts}}$ 和 $L_{\\text{counts}}$。\n  预处理流程：log-one-plus 然后进行 z-score 标准化。\n\n- 测试用例 $6$ (边缘案例，在 z-score 标准化下存在零方差特征)：\n  数据矩阵 $X_{\\text{zerovar}} \\in \\mathbb{R}^{6 \\times 3}$，行向量为：\n  $\\left[1.0, 2.0, 10.0\\right]$,\n  $\\left[1.2, 1.8, 10.0\\right]$,\n  $\\left[0.8, 2.1, 10.0\\right]$,\n  $\\left[5.0, 6.0, 10.0\\right]$,\n  $\\left[5.2, 6.1, 10.0\\right]$,\n  $\\left[4.8, 5.9, 10.0\\right]$.\n  标签 $L_{\\text{zerovar}}$:\n  $\\left[0, 0, 0, 1, 1, 1\\right]$.\n  预处理流程：z-score 标准化。\n\n程序要求：\n- 完全按照规定实现预处理流程。\n- 预处理后使用欧几里得度量作为相异度。\n- 根据上述 $a(i)$ 和 $b(i)$ 的定义推导并实现逐样本标准化指数，并将所有样本的平均值计算为总体 SC。\n\n输出格式：\n- 您的程序应生成单行输出，其中包含 $6$ 个测试用例的总体 SC，四舍五入到 $6$ 位小数，并聚合成一个逗号分隔的列表，用方括号括起来，例如，以 Python 风格的列表语法打印的 $\\left[\\text{sc}_1,\\text{sc}_2,\\dots,\\text{sc}_6\\right]$。\n\n此问题中没有物理单位和角度。所有输出均为实值浮点数。程序必须是自包含的，不需要输入，并且可以按原样运行。确保计算和约定遵循上述规范。",
            "solution": "对用户提供的问题陈述进行严格验证。\n\n### 步骤 1：提取已知条件\n- **数据集**：$\\mathbb{R}^d$ 中的一组点 $\\{x_i\\}_{i=1}^n$。\n- **相异度度量**：欧几里得距离，$d(x,y)=\\sqrt{\\sum_{j=1}^d (x_j - y_j)^2}$。\n- **聚类**：将样本索引划分为 $K$ 个不相交的非空集合 $\\{C_k\\}_{k=1}^K$。样本 $i$ 的标签为 $L_i \\in \\{0, 1, \\dots, K-1\\}$。\n- **簇内相异度 $a(i)$**：对于样本 $i$，$a(i)$ 是其到同一簇中所有其他样本 $j$ 的平均相异度：$a(i) = \\frac{1}{|C_{L_i}| - 1} \\sum_{j \\in C_{L_i}, j \\neq i} d(x_i, x_j)$。\n- **簇间相异度 $b(i)$**：对于样本 $i$，$b(i)$ 是其到任何其他簇 $C_k$ (其中 $k \\neq L_i$) 中所有样本的平均相异度的最小值：$b(i) = \\min_{k \\neq L_i} \\left\\{ \\frac{1}{|C_k|} \\sum_{j \\in C_k} d(x_i, x_j) \\right\\}$。\n- **逐样本标准化指数 $s(i)$**：从 $a(i)$ 和 $b(i)$ 推导而来，界于 $[-1, 1]$ 之间。\n- **总体评估度量（轮廓系数，SC）**：所有样本的逐样本标准化指数的平均值：$SC = \\frac{1}{n} \\sum_{i=1}^n s(i)$。\n- **预处理流程**：\n  1. **Z-score 标准化**：将每个特征值 $x_{ij}$ 转换为 $(x_{ij} - \\mu_j)/\\sigma_j$，其中 $\\mu_j$ 是特征均值，$\\sigma_j$ 是特征标准差。如果 $\\sigma_j=0$，转换后的特征为 $0$。\n  2. **最小-最大缩放**：将每个特征值 $x_{ij}$ 转换为 $(x_{ij} - m_j)/(M_j - m_j)$，其中 $m_j$ 和 $M_j$ 是特征的最小值和最大值。如果 $M_j = m_j$，转换后的特征为 $0$。\n  3. **计数的方差稳定化**：逐元素应用自然对数变换 $\\log(1+x)$，然后应用 Z-score 标准化。\n- **约定**：\n  1. 如果 $K=1$，总体 SC 为 $0$。\n  2. 如果样本属于单例簇，其逐样本指数为 $0$。\n  3. 如果标准化指数中的归一化分母为 $0$，则该指数设置为 $0$。\n- **测试用例**：提供了六个特定的测试用例，每个都包含数据矩阵、标签向量和指定的预处理流程。\n\n### 步骤 2：使用提取的已知条件进行验证\n根据验证标准对问题进行分析：\n- **科学性**：问题要求计算轮廓系数，这是机器学习和数据分析中评估聚类质量的标准且广泛使用的度量。簇内凝聚度 ($a(i)$) 和簇间分离度 ($b(i)$) 的定义、逐样本得分的公式以及预处理方法（z-score、min-max、log 变换）都是统计学和数据科学中标准的、数学上合理的概念。该问题牢固地植根于既定原则。\n- **适定性**：问题是适定的。对于每个测试用例，输入（数据、标签、预处理方法）都已明确定义。计算步骤和所有相关边缘情况（单例簇、总体只有一个簇、除以零）的处理都已明确规定。这种确定性确保了每个测试用例都存在唯一且有意义的数值解。\n- **客观性**：问题以精确、客观的数学语言陈述。没有主观或模糊的术语。\n- **完整性与一致性**：问题是自包含的。它提供了求解所需的所有必要数据和定义。处理边缘情况的约定是明确的，并且与标准实践一致，避免了歧义。\n- **现实性**：测试用例虽然是合成的，但旨在模拟生物信息学中遇到的现实场景，例如具有巨大尺度差异的特征和基于计数的数据，这证明了使用不同预处理策略的合理性。任务本身——在各种数据变换下评估聚类——是实际数据分析中的核心活动。\n\n### 步骤 3：结论与行动\n该问题是**有效的**。这是一个定义明确、科学上合理的计算任务，基于既定的数据分析原则。我将继续进行求解。\n\n###\n该问题要求为多个聚类结果计算轮廓系数（SC），每个结果都在不同数据集上，并经过特定的预处理流程。解决方案涉及系统地应用数据转换，然后根据其形式化定义计算 SC。\n\n问题的核心是轮廓系数，这是一个量化簇定义优良程度的度量。逐样本轮廓得分 $s(i)$ 定义为：\n$$\ns(i) = \\frac{b(i) - a(i)}{\\max\\{a(i), b(i)\\}}\n$$\n其中：\n- $a(i)$ 是样本 $i$ 到同一簇中所有其他样本的平均距离。这衡量了样本与其自身簇的凝聚度。值越小越好。\n- $b(i)$ 是样本 $i$ 到最近邻簇中所有样本的平均距离。这衡量了样本与其他簇的分离度。值越大越好。\n\n$s(i)$ 的值范围从 $-1$ 到 $1$。接近 $1$ 的值表示样本聚类效果好，因为其簇内距离远小于其最近的簇间距离。接近 $0$ 的值表示样本位于或非常接近两个簇之间的决策边界。接近 $-1$ 的值表示样本可能被错误分类。总体 SC 是所有样本 $s(i)$ 的平均值，提供了聚类质量的全局度量。\n\n问题指定了在距离计算之前要应用于数据的三种预处理流程：\n1. **Z-score 标准化**：此方法将每个特征转换为均值为 $0$、标准差为 $1$。对于特征向量 $X_j = [x_{1j}, \\dots, x_{nj}]^T$，变换为：\n    $$ x'_{ij} = \\frac{x_{ij} - \\mu_j}{\\sigma_j} $$\n    其中 $\\mu_j = \\frac{1}{n} \\sum_{i=1}^n x_{ij}$ 且 $\\sigma_j = \\sqrt{\\frac{1}{n} \\sum_{i=1}^n (x_{ij} - \\mu_j)^2}$。如果 $\\sigma_j = 0$，转换后的特征 $X'_j$ 变为零向量。当特征具有不同尺度且数据近似正态分布时，此方法有效。\n\n2. **最小-最大缩放（归一化）**：此方法将每个特征缩放到一个固定范围，通常是 $[0, 1]$。对于特征向量 $X_j$，变换为：\n    $$ x'_{ij} = \\frac{x_{ij} - \\min(X_j)}{\\max(X_j) - \\min(X_j)} $$\n    如果范围 $\\max(X_j) - \\min(X_j) = 0$，转换后的特征 $X'_j$ 变为零向量。此方法对异常值敏感，但保留了原始分布的形状。\n\n3. **方差稳定化**：此流程专为计数数据设计，这类数据通常表现出均值-方差关系（例如，在泊松分布数据中，方差等于均值）。变换 $x \\to \\log(1+x)$ 有助于稳定方差，使数据更适用于假定方差齐性的方法（如 z-score 标准化）。之后再进行如上所述的 z-score 标准化。\n\n距离度量固定为欧几里得距离，在预处理后的数据 $X'$ 上计算：\n$$ d(x'_i, x'_j) = \\sqrt{\\sum_{k=1}^d (x'_{ik} - x'_{jk})^2} $$\n\n对于每个测试用例，总体算法如下：\n1.  对输入数据矩阵 $X$ 应用指定的预处理流程，得到转换后的矩阵 $X'$。\n2.  确定唯一簇的数量 $K$。如果 $K \\le 1$，根据定义 SC 为 $0$。\n3.  计算 $X'$ 中所有样本的成对欧几里得距离矩阵。\n4.  对于每个样本 $i$：\n    a. 如果样本 $i$ 位于单例簇中，其得分 $s(i)$ 为 $0$。\n    b. 否则，计算 $a(i)$，即到其簇中其他点的平均距离。\n    c. 计算 $b(i)$，即到其他每个簇中点的平均距离的最小值。\n    d. 计算 $s(i) = (b(i) - a(i))/\\max\\{a(i), b(i)\\}$。如果分母为 $0$，$s(i)$ 为 $0$。\n5.  最终的 SC 是所有逐样本得分 $s(i)$ 的算术平均值。\n\n这种结构化方法确保了每个测试用例都根据指定的规则、预处理和数学定义得到正确评估。",
            "answer": "```python\nimport numpy as np\nfrom scipy.spatial.distance import pdist, squareform\n\ndef solve():\n    \"\"\"\n    Solves the problem by computing the Silhouette Coefficient (SC)\n    for six test cases, each with a specified preprocessing pipeline.\n    \"\"\"\n\n    def preprocess_data(X, method):\n        \"\"\"\n        Applies a specified preprocessing pipeline to the data matrix X.\n\n        Args:\n            X (np.ndarray): The input data matrix (n_samples, n_features).\n            method (str): The preprocessing method ('zscore', 'minmax', 'log_zscore', 'none').\n\n        Returns:\n            np.ndarray: The preprocessed data matrix.\n        \"\"\"\n        if method == 'none':\n            return X.copy()\n        \n        X_proc = X.copy().astype(float)\n        \n        if method == 'log_zscore':\n            X_proc = np.log1p(X_proc)\n            # Fall through to 'zscore'\n            method = 'zscore'\n\n        if method == 'zscore':\n            mean = np.mean(X_proc, axis=0)\n            std = np.std(X_proc, axis=0)\n            # Avoid division by zero for zero-variance features\n            # np.divide handles this with a 'where' argument\n            return np.divide(X_proc - mean, std, out=np.zeros_like(X_proc), where=std!=0)\n        \n        if method == 'minmax':\n            min_val = np.min(X_proc, axis=0)\n            max_val = np.max(X_proc, axis=0)\n            data_range = max_val - min_val\n            # Avoid division by zero for zero-range features\n            return np.divide(X_proc - min_val, data_range, out=np.zeros_like(X_proc), where=data_range!=0)\n            \n        return X_proc\n\n    def calculate_silhouette_score(X, labels):\n        \"\"\"\n        Computes the overall Silhouette Coefficient for a given dataset and labels.\n\n        Args:\n            X (np.ndarray): The data matrix (n_samples, n_features), potentially preprocessed.\n            labels (np.ndarray): The cluster labels for each sample.\n\n        Returns:\n            float: The mean Silhouette Coefficient for all samples.\n        \"\"\"\n        unique_labels = np.unique(labels)\n        n_clusters = len(unique_labels)\n        n_samples = X.shape[0]\n\n        if n_clusters = 1 or n_samples  2:\n            return 0.0\n\n        # Pre-compute the pairwise Euclidean distance matrix\n        dist_matrix = squareform(pdist(X, metric='euclidean'))\n\n        sample_scores = np.zeros(n_samples)\n\n        for i in range(n_samples):\n            current_label = labels[i]\n            \n            # Mask for samples in the same cluster as sample i (excluding i)\n            in_cluster_mask = (labels == current_label)\n            in_cluster_mask[i] = False\n            \n            n_in_cluster = np.sum(in_cluster_mask)\n            \n            # If singleton cluster, silhouette score is 0 by convention\n            if n_in_cluster == 0:\n                sample_scores[i] = 0.0\n                continue\n\n            # Calculate a(i): average intra-cluster distance\n            a_i = np.mean(dist_matrix[i, in_cluster_mask])\n            \n            # Calculate b(i): minimum average inter-cluster distance\n            b_i = np.inf\n            for label in unique_labels:\n                if label == current_label:\n                    continue\n                \n                # Mask for samples in the other cluster\n                out_cluster_mask = (labels == label)\n                mean_dist_to_other_cluster = np.mean(dist_matrix[i, out_cluster_mask])\n                b_i = min(b_i, mean_dist_to_other_cluster)\n            \n            # Calculate the silhouette score for sample i\n            denominator = max(a_i, b_i)\n            if denominator == 0:\n                sample_scores[i] = 0.0 # Handle case for numerical stability\n            else:\n                sample_scores[i] = (b_i - a_i) / denominator\n        \n        return np.mean(sample_scores)\n\n    # Test case definitions\n    test_cases = [\n        {\n            \"data\": np.array([\n                [100.0, 1.2, 5000.0], [110.0, 0.8, 5100.0], [95.0, 1.0, 4900.0],\n                [5.0, 50.0, 180.0], [7.0, 49.5, 200.0], [6.0, 48.0, 220.0]\n            ]),\n            \"labels\": np.array([0, 0, 0, 1, 1, 1]),\n            \"preprocess\": \"zscore\"\n        },\n        {\n            \"data\": np.array([\n                [100.0, 1.2, 5000.0], [110.0, 0.8, 5100.0], [95.0, 1.0, 4900.0],\n                [5.0, 50.0, 180.0], [7.0, 49.5, 200.0], [6.0, 48.0, 220.0]\n            ]),\n            \"labels\": np.array([0, 0, 0, 1, 1, 1]),\n            \"preprocess\": \"none\"\n        },\n        {\n            \"data\": np.array([\n                [1.0, 100.0], [1.1, 98.0], [10.0, 5.0], [9.5, 6.0], [100.0, 1000.0]\n            ]),\n            \"labels\": np.array([0, 0, 1, 1, 2]),\n            \"preprocess\": \"minmax\"\n        },\n        {\n            \"data\": np.array([\n                [0, 10, 500, 2000], [1, 12, 520, 2100], [0, 9, 480, 1950],\n                [50, 0, 30, 0], [45, 1, 28, 2], [55, 2, 35, 1],\n                [0, 300, 0, 100], [1, 290, 0, 90], [2, 310, 1, 110]\n            ]),\n            \"labels\": np.array([0, 0, 0, 1, 1, 1, 2, 2, 2]),\n            \"preprocess\": \"none\"\n        },\n        {\n            \"data\": np.array([\n                [0, 10, 500, 2000], [1, 12, 520, 2100], [0, 9, 480, 1950],\n                [50, 0, 30, 0], [45, 1, 28, 2], [55, 2, 35, 1],\n                [0, 300, 0, 100], [1, 290, 0, 90], [2, 310, 1, 110]\n            ]),\n            \"labels\": np.array([0, 0, 0, 1, 1, 1, 2, 2, 2]),\n            \"preprocess\": \"log_zscore\"\n        },\n        {\n            \"data\": np.array([\n                [1.0, 2.0, 10.0], [1.2, 1.8, 10.0], [0.8, 2.1, 10.0],\n                [5.0, 6.0, 10.0], [5.2, 6.1, 10.0], [4.8, 5.9, 10.0]\n            ]),\n            \"labels\": np.array([0, 0, 0, 1, 1, 1]),\n            \"preprocess\": \"zscore\"\n        },\n    ]\n\n    results = []\n    for case in test_cases:\n        X = case[\"data\"]\n        labels = case[\"labels\"]\n        preprocess_method = case[\"preprocess\"]\n\n        X_processed = preprocess_data(X, preprocess_method)\n        sc = calculate_silhouette_score(X_processed, labels)\n        results.append(sc)\n\n    # Format the output as specified\n    formatted_results = [f\"{r:.6f}\" for r in results]\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "虽然精确计算有助于理论理解，但现实世界中的生物信息学数据集（如单细胞测序数据）通常过于庞大，导致精确计算并不可行。本练习旨在解决计算复杂性这一关键问题。您将实现并比较一种精确算法与一种基于确定性采样的近似算法，从而深入理解在处理大规模数据时，精确度与计算效率之间的权衡。",
            "id": "4561574",
            "problem": "一个临床生物信息学团队通过比较簇内和簇间非相似性，来评估一个小型基因表达谱面板上的无监督聚类分配的质量。考虑一个嵌入在维度为 $d$ 的实数向量空间中的有限数据点集，其指定的度量为 $\\mathbb{R}^d$ 上的标准欧几里得距离。该数据集被划分为带标签的簇。一个点的评估指标应基于其与自身簇内点的平均非相似性以及与任何其他簇的最小平均非相似性，用这两个平均值中的较大者进行归一化，然后对所有点求平均以得出一个单一的数据集分数。如果一个点是其簇的唯一成员，则该点的点级分数定义为 $0$。如果一个点的簇内平均非相似性和最小簇间平均非相似性均为 $0$，则其点级分数定义为 $0$。\n\n您必须实现两种根据此定义计算数据集级分数的算法：\n\n- 一种精确算法，它一次性预计算所有点对距离，然后计算数据集级分数。对于精确算法，将距离评估计数定义为被评估距离的唯一无序点对的数量。如果有 $n$ 个点，此计数必须为 $n(n-1)/2$。\n\n- 一种带有采样参数 $m \\in \\mathbb{N}$ 的确定性近似算法。对每个点 $i$，使用其自身簇中最多 $m$ 个其他点来近似计算簇内平均非相似性（如果可用点数少于 $m$，则使用所有可用点）。用于近似的点必须是簇成员中索引最小的那些，在适用情况下排除点 $i$ 本身。为近似最小簇间平均非相似性，对于每个其他簇，计算与该簇中选为索引最小成员的最多 $m$ 个点之间的平均非相似性，然后取这些均值在所有簇中的最小值。近似过程必须是确定性的，没有随机性。对于此近似算法，将距离评估计数定义为在所有点上执行的定向点对点距离计算的总数，等于所有点的选定簇内伙伴数量之和，加上所有其他簇的选定簇间伙伴数量之和。\n\n您的程序不得接受任何输入，而是必须为以下测试套件计算结果。每个测试用例指定一个数据矩阵 $X \\in \\mathbb{R}^{n \\times d}$，一个指示簇隶属关系的整数标签向量 $y \\in \\mathbb{Z}^n$，以及采样参数 $m$：\n\n测试用例 1（分离良好且平衡的簇，$m=2$）：\n$$\nX = \\begin{bmatrix}\n0  0\\\\\n0  1\\\\\n1  0\\\\\n1  1\\\\\n5  5\\\\\n5  6\\\\\n6  5\\\\\n6  6\n\\end{bmatrix},\\quad\ny = [0,0,0,0,1,1,1,1],\\quad\nm = 2.\n$$\n\n测试用例 2（单一成员簇，$m=2$）：\n$$\nX = \\begin{bmatrix}\n0  0\\\\\n0  0.1\\\\\n10  10\n\\end{bmatrix},\\quad\ny = [0,0,1],\\quad\nm = 2.\n$$\n\n测试用例 3（不平衡的簇，$m=1$）：\n$$\nX = \\begin{bmatrix}\n0  0\\\\\n0  1\\\\\n1  0\\\\\n3  0\\\\\n3  1\\\\\n4  0\\\\\n8  0\\\\\n8  1\n\\end{bmatrix},\\quad\ny = [0,0,0,1,1,1,2,2],\\quad\nm = 1.\n$$\n\n测试用例 4（簇内非相似性为零的点对，$m=3$）：\n$$\nX = \\begin{bmatrix}\n0  0\\\\\n0  0\\\\\n10  0\\\\\n10  0\n\\end{bmatrix},\\quad\ny = [0,0,1,1],\\quad\nm = 3.\n$$\n\n为每个测试用例计算：\n\n- 使用所述精确算法计算的精确数据集级分数，\n- 使用给定 $m$ 的确定性采样算法计算的近似数据集级分数，\n- 精确算法的唯一无序点对距离评估计数 $n(n-1)/2$，\n- 如上文定义的近似算法的定向距离评估计数。\n\n数据集级分数的结果需四舍五入到 $6$ 位小数。所有计数必须是整数。本问题中没有物理单位。\n\n您的程序应生成单行输出，其中包含一个结果列表，每个测试用例一个结果，每个结果都是 $[\\text{exact\\_score}, \\text{approx\\_score}, \\text{exact\\_count}, \\text{approx\\_count}]$ 形式的列表。该行必须包含用方括号括起来的、以逗号分隔且无空格的结果列表，例如：\n$[[a_1,b_1,c_1,d_1],[a_2,b_2,c_2,d_2],[a_3,b_3,c_3,d_3],[a_4,b_4,c_4,d_4]]$。\n\n约束和假设：\n\n- 所有距离均为 $\\mathbb{R}^d$ 上的欧几里得距离。\n- 如果一个点在其自身簇中没有其他点，根据定义其点级分数为 $0$，并且在近似算法中不产生任何簇内距离计算。\n- 如果用于一个点的归一化的两个平均值中的最大值等于 $0$，则将该点的分数定义为 $0$ 以避免除以零。",
            "solution": "该问题要求实现两种算法来评估给定数据聚类的质量。评估基于一种度量，该度量为每个数据点比较其到同一簇中其他点的平均距离与其到其他簇中点的平均距离。这是无监督学习中评估簇内聚性（簇内点之间的紧密程度）和分离度（不同簇之间的疏远程度）的常用方法。指定的点级分数是著名的轮廓系数的一种变体。\n\n设数据集为 $d$ 维欧几里得空间 $\\mathbb{R}^d$ 中的 $n$ 个点 $\\{p_0, p_1, \\dots, p_{n-1}\\}$ 的集合。这些点被划分为一个簇的集合 $C = \\{C_1, C_2, \\dots, C_K\\}$。两点 $p_i$ 和 $p_j$ 之间的距离是欧几里得距离，记为 $d(p_i, p_j) = \\|p_i - p_j\\|_2$。\n\n对每个点 $p_i$，问题定义了两个关键量：\n1.  簇内平均非相似性 $a(i)$，即从 $p_i$ 到同一簇内所有其他点的平均距离。\n2.  最小簇间平均非相似性 $b(i)$，即从 $p_i$ 到任何单个其他簇中所有点的平均距离的最小值。\n\n点级分数 $s(i)$ 则定义为：\n$$s(i) = \\begin{cases}\n    \\frac{b(i) - a(i)}{\\max\\{a(i), b(i)\\}}  \\text{if } \\max\\{a(i), b(i)\\}  0 \\\\\n    0  \\text{if } \\max\\{a(i), b(i)\\} = 0\n\\end{cases}$$\n对于作为其簇的唯一成员的点 $p_i$（单一成员簇），给出了一个特殊条件：其分数 $s(i)$ 定义为 $0$。\n\n整个数据集的分数是数据集中所有点的点级分数的算术平均值：\n$$\\text{Dataset Score} = \\frac{1}{n} \\sum_{i=0}^{n-1} s(i)$$\n\n我们现在将详细介绍计算此分数的两种所需算法。\n\n### 精确算法\n\n精确算法完全按照定义来计算分数。它遵循一个两阶段过程：预计算距离，然后计算分数。\n\n1.  **距离预计算**：$n$ 个点之间的所有唯一点对距离只计算一次。对于 $n$ 个点，存在 $\\binom{n}{2} = \\frac{n(n-1)}{2}$ 个这样的唯无序点对。这些距离存储在一个对称的 $n \\times n$ 距离矩阵 $D$ 中，其中 $D_{ij} = d(p_i, p_j)$。此算法的距离评估计数固定为此值：$\\text{exact\\_count} = \\frac{n(n-1)}{2}$。\n\n2.  **分数计算**：对于属于簇 $C_k$ 的每个点 $p_i$：\n    *   如果 $C_k$ 是一个单一成员簇（即 $|C_k| = 1$），则 $s(i) = 0$。\n    *   否则，簇内非相似性 $a(i)$ 计算为到 $C_k$ 中所有其他点的距离的平均值：\n        $$a(i) = \\frac{1}{|C_k|-1} \\sum_{p_j \\in C_k, j \\neq i} D_{ij}$$\n    *   计算到每个其他簇 $C_l$（其中 $l \\neq k$）的平均非相似性：\n        $$d(p_i, C_l) = \\frac{1}{|C_l|} \\sum_{p_j \\in C_l} D_{ij}$$\n    *   最小簇间平均非相似性 $b(i)$ 是这些值的最小值：\n        $$b(i) = \\min_{l \\neq k} \\{d(p_i, C_l)\\}$$\n    *   然后使用提供的公式计算点级分数 $s(i)$，最终的数据集分数是所有 $s(i)$ 的平均值。\n\n### 确定性近似算法\n\n该算法通过使用一个由参数 $m \\in \\mathbb{N}$ 控制的固定大小的点样本进行距离计算来近似分数。采样是确定性的，基于点的索引。\n\n对于每个带标签 $y_i$ 和索引 $i$ 的点 $p_i$：\n\n1.  **近似簇内非相似性 $\\tilde{a}(i)$**：\n    *   如果 $p_i$ 在一个单一成员簇中，其分数 $\\tilde{s}(i)$ 为 $0$，并且不为它执行任何簇内距离计算。\n    *   否则，识别其簇中其他点的索引集合 $I = \\{j \\mid y_j = y_i, j \\neq i\\}$。从此集合中，选择最多 $m$ 个值最小的索引。设这个采样索引集为 $I' \\subseteq I$，其中 $|I'| = \\min(m, |I|)$。\n    *   近似簇内非相似性是到这些采样点的平均距离：\n        $$\\tilde{a}(i) = \\frac{1}{|I'|} \\sum_{j \\in I'} d(p_i, p_j)$$\n    *   此步骤的距离计算次数为 $|I'|$。\n\n2.  **近似簇间非相似性 $\\tilde{b}(i)$**：\n    *   对于每个其他簇 $C_l$（其标签不为 $y_i$），识别其成员的索引集合 $J_l = \\{j \\mid y_j = l\\}$。从此集合中，选择最多 $m$ 个值最小的索引。设这个采样索引集为 $J'_l \\subseteq J_l$，其中 $|J'_l| = \\min(m, |J_l|)$。\n    *   到簇 $C_l$ 的近似平均距离是：\n        $$\\tilde{d}(p_i, C_l) = \\frac{1}{|J'_l|} \\sum_{j \\in J'_l} d(p_i, p_j)$$\n    *   对此簇的距离计算次数为 $|J'_l|$。\n    *   近似最小簇间平均非相似性 $\\tilde{b}(i)$ 是这些平均距离在所有其他簇 $l$ 上的最小值：\n        $$\\tilde{b}(i) = \\min_{l \\neq y_i} \\{\\tilde{d}(p_i, C_l)\\}$$\n\n3.  **分数和计数计算**：\n    *   近似点级分数 $\\tilde{s}(i)$ 使用与精确方法相同的公式，通过 $\\tilde{a}(i)$ 和 $\\tilde{b}(i)$ 计算得出。\n    *   总距离评估计数 `approx_count` 是在所有点上执行的所有距离计算的总和。对于单个点 $p_i$，计数增加量为其簇内样本数加上来自所有其他簇的簇间样本数之和。\n\n最终的近似数据集分数是所有 $\\tilde{s}(i)$ 的平均值。该方法通过限制距离计算的次数来降低计算成本，特别是对于大簇而言。",
            "answer": "```python\nimport numpy as np\nfrom scipy.spatial.distance import pdist, squareform\n\ndef compute_exact(X, y):\n    \"\"\"\n    Computes the exact dataset-level score and distance evaluation count.\n    \"\"\"\n    n = X.shape[0]\n    if n = 1:\n        return 0.0, 0\n    \n    # Precompute all pairwise distances. pdist computes n(n-1)/2 distances.\n    # This corresponds exactly to the definition of exact_count.\n    exact_count = n * (n - 1) // 2\n    dist_matrix = squareform(pdist(X, 'euclidean'))\n    \n    unique_labels = np.unique(y)\n    cluster_indices = {label: np.where(y == label)[0] for label in unique_labels}\n    \n    point_scores = np.zeros(n)\n    \n    for i in range(n):\n        label_i = y[i]\n        indices_in_cluster = cluster_indices[label_i]\n        \n        # Handle singleton cluster\n        if len(indices_in_cluster) == 1:\n            point_scores[i] = 0.0\n            continue\n            \n        # Calculate a(i): mean intra-cluster distance\n        mask_a = np.ones_like(indices_in_cluster, dtype=bool)\n        mask_a[indices_in_cluster == i] = False\n        other_indices_in_cluster = indices_in_cluster[mask_a]\n        a_i = np.mean(dist_matrix[i, other_indices_in_cluster])\n        \n        # Calculate b(i): smallest mean inter-cluster distance\n        mean_inter_dists = []\n        for other_label in unique_labels:\n            if other_label == label_i:\n                continue\n            indices_other_cluster = cluster_indices[other_label]\n            mean_dist = np.mean(dist_matrix[i, indices_other_cluster])\n            mean_inter_dists.append(mean_dist)\n            \n        b_i = np.min(mean_inter_dists)\n        \n        # Calculate point score s(i)\n        denominator = max(a_i, b_i)\n        if denominator == 0:\n            point_scores[i] = 0.0\n        else:\n            point_scores[i] = (b_i - a_i) / denominator\n            \n    exact_score = np.mean(point_scores)\n    return exact_score, exact_count\n\ndef compute_approx(X, y, m):\n    \"\"\"\n    Computes the approximate dataset-level score and distance evaluation count.\n    \"\"\"\n    n = X.shape[0]\n    if n = 1:\n        return 0.0, 0\n\n    approx_count = 0\n    point_scores = np.zeros(n)\n    \n    # Pre-sort indices for each cluster label for deterministic sampling\n    unique_labels = np.unique(y)\n    cluster_indices = {label: np.sort(np.where(y == label)[0]) for label in unique_labels}\n    \n    for i in range(n):\n        label_i = y[i]\n        indices_in_cluster = cluster_indices[label_i]\n        p_i = X[i]\n\n        # Handle singleton cluster\n        if len(indices_in_cluster) == 1:\n            point_scores[i] = 0.0\n            # Still need to calculate inter-cluster distances for the count\n            for other_label in unique_labels:\n                if other_label == label_i:\n                    continue\n                indices_other_cluster = cluster_indices[other_label]\n                num_samples = min(m, len(indices_other_cluster))\n                approx_count += num_samples\n            continue\n\n        # Calculate a(i): approximate mean intra-cluster distance\n        other_indices_in_cluster = indices_in_cluster[indices_in_cluster != i]\n        num_samples_a = min(m, len(other_indices_in_cluster))\n        sample_indices_a = other_indices_in_cluster[:num_samples_a]\n        \n        dists_a = np.linalg.norm(X[sample_indices_a] - p_i, axis=1)\n        a_i_tilde = np.mean(dists_a)\n        approx_count += num_samples_a\n\n        # Calculate b(i): approximate smallest mean inter-cluster distance\n        mean_inter_dists_tilde = []\n        for other_label in unique_labels:\n            if other_label == label_i:\n                continue\n            indices_other_cluster = cluster_indices[other_label]\n            num_samples_b = min(m, len(indices_other_cluster))\n            sample_indices_b = indices_other_cluster[:num_samples_b]\n            \n            dists_b = np.linalg.norm(X[sample_indices_b] - p_i, axis=1)\n            mean_dist_tilde = np.mean(dists_b)\n            mean_inter_dists_tilde.append(mean_dist_tilde)\n            approx_count += num_samples_b\n        \n        b_i_tilde = np.min(mean_inter_dists_tilde) if mean_inter_dists_tilde else 0\n        \n        # Calculate point score s(i)\n        denominator = max(a_i_tilde, b_i_tilde)\n        if denominator == 0:\n            point_scores[i] = 0.0\n        else:\n            point_scores[i] = (b_i_tilde - a_i_tilde) / denominator\n            \n    approx_score = np.mean(point_scores)\n    return approx_score, approx_count\n\ndef solve():\n    \"\"\"\n    Main function to run all test cases and print results.\n    \"\"\"\n    test_cases = [\n        (\n            np.array([[0,0], [0,1], [1,0], [1,1], [5,5], [5,6], [6,5], [6,6]], dtype=np.float64),\n            np.array([0,0,0,0,1,1,1,1]),\n            2\n        ),\n        (\n            np.array([[0,0], [0,0.1], [10,10]], dtype=np.float64),\n            np.array([0,0,1]),\n            2\n        ),\n        (\n            np.array([[0,0], [0,1], [1,0], [3,0], [3,1], [4,0], [8,0], [8,1]], dtype=np.float64),\n            np.array([0,0,0,1,1,1,2,2]),\n            1\n        ),\n        (\n            np.array([[0,0], [0,0], [10,0], [10,0]], dtype=np.float64),\n            np.array([0,0,1,1]),\n            3\n        )\n    ]\n\n    all_results = []\n    for X, y, m in test_cases:\n        exact_score, exact_count = compute_exact(X, y)\n        approx_score, approx_count = compute_approx(X, y, m)\n        \n        # Format results as specified\n        result_str = (\n            f\"[{exact_score:.6f},\"\n            f\"{approx_score:.6f},\"\n            f\"{exact_count},\"\n            f\"{approx_count}]\"\n        )\n        all_results.append(result_str)\n\n    # Print the final output in the required single-line format\n    print(f\"[{','.join(all_results)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "许多现代生物信息学聚类方法，尤其是在单细胞分析领域，不再依赖简单的欧几里得距离，而是在邻接图上定义距离。这个高级练习挑战您将轮廓系数的评估框架扩展到图测地线距离（graph geodesic distances）上。通过本练习，您将探索评估指标本身如何必须与聚类方法的底层假设相匹配，并分析关键参数（如近邻数 $k$）对评估结果稳定性的影响。",
            "id": "4561549",
            "problem": "一个生物信息学团队正在评估源自基因表达数据的低维嵌入中，细胞群簇分配的稳定性。他们使用基于图的测地距离，其中图是对此嵌入中的样本之间的欧几里得距离作为边权重的对称 $k$-近邻图。他们旨在量化平均轮廓系数对于计算图距离时所用 $k$-近邻参数选择的敏感度。\n\n给定一个包含 $n$ 个二维点 $x_i \\in \\mathbb{R}^2$ 的固定数据集（代表基因表达谱的低维嵌入）、一个簇分配向量以及一个 $k$ 值，按如下方式构建对称 $k$-近邻图 $G_k$：\n- 对每个节点 $i$，计算其到所有其他节点 $j \\neq i$ 的欧几里得距离。\n- 将节点 $i$ 与其 $k$ 个最近的邻居连接；通过取这些有向边的无向并集来进行对称化。\n- 边权重为欧几里得距离。设 $d_{ij}$ 表示节点 $i$ 和 $j$ 之间边的权重（如果存在），否则为 $+\\infty$。\n- 将节点 $i$ 和 $j$ 之间的图测地距离定义为在 $G_k$ 中使用边权重 $d_{uv}$ 的最短路径长度，其中对所有 $i$ 都有 $d_{ii} = 0$。\n\n使用聚类评估文献中的规范定义来定义单样本轮廓值：对于每个样本 $i$，比较其到自身所在簇的平均图距离与到其他簇的平均图距离的最小值，并通过这两个平均值中较大的一个进行归一化。平均轮廓系数是所有单样本轮廓值的算术平均值。\n\n为确保在可能不连通的图上行为有明确定义，遵循以下约定：\n- 如果样本 $i$ 是其所在簇的唯一成员（孤立点），则其轮廓值定义为 $0$。\n- 在计算簇内或跨簇的平均值时，仅使用有限的图距离（即可通过某条路径到达的节点）。如果 $i$ 在其自身簇中没有有限距离的邻居，或在任何其他簇中没有有限距离的邻居，则其轮廓值定义为 $0$。\n\n您必须实现整个计算过程，并将其应用于下面的测试套件。所有量均无单位。您的程序必须生成单行输出，其中包含一个用方括号括起来的逗号分隔列表，列表内容为每个测试用例的平均轮廓系数值，四舍五入到恰好六位小数。\n\n数据集：\n- 点 $x_i = (x_i^{(1)}, x_i^{(2)})$，其中 $i \\in \\{0,1,\\dots,7\\}$：\n  - $x_0 = (0, 0)$\n  - $x_1 = (1, 0)$\n  - $x_2 = (2, 0)$\n  - $x_3 = (10, 0)$\n  - $x_4 = (11, 0)$\n  - $x_5 = (12, 0)$\n  - $x_6 = (25, 0)$\n  - $x_7 = (26, 0)$\n\n包含五个测试用例的测试套件。在每个用例中，$k$ 是 $k$-近邻参数，labels 是簇分配向量 $c \\in \\mathbb{Z}^n$，其中 $c_i$ 是点 $i$ 的簇标签：\n- 用例 1：$k = 3$，labels $= [0,0,0,1,1,1,2,2]$。\n- 用例 2：$k = 1$，labels $= [0,0,0,1,1,1,2,2]$。\n- 用例 3：$k = 7$，labels $= [0,0,0,1,1,1,2,2]$。\n- 用例 4：$k = 3$，labels $= [0,0,0,1,1,1,1,1]$。\n- 用例 5：$k = 3$，labels $= [0,0,0,1,1,1,1,2]$。\n\n要求：\n- 按照规定，使用欧几里得边权重计算对称 $k$-近邻图 $G_k$。\n- 通过 $G_k$ 上的最短路径计算所有点对之间的图测地距离。\n- 根据上述约定，为每个测试用例计算平均轮廓系数。\n- 最终输出格式：单行输出，包含一个由五个浮点数组成的列表，按用例 $1$ 到 $5$ 的顺序排列，每个数字四舍五入到恰好六位小数，打印为用方括号括起来的逗号分隔列表（例如，$[a,b,c,d,e]$，其中 $a,b,c,d,e$ 每个数小数点后都有六位数字）。",
            "solution": "该问题要求在给定数据集上，为几种聚类场景计算平均轮廓系数。问题的核心在于使用一种非标准的距离度量：源自对称 $k$-近邻（$k$-NN）图的图测地距离。解决方案涉及一个多步骤、基于原则的过程，该过程结合了图论、矩阵计算和聚类评估中的概念。\n\n总体的算法思路如下：\n1.  对于每个由参数 $k$ 和簇分配向量定义的测试用例，构建相应的对称 $k$-NN 图。\n2.  在此图上计算所有点对之间的最短路径，以确定测地距离矩阵。\n3.  使用该距离矩阵，根据规范定义为每个数据点计算单样本轮廓值，并严格遵守处理不连通分量和孤立簇的指定约定。\n4.  最后，计算所有单样本轮廓值的算术平均值，以获得该测试用例的平均轮廓分数。\n\n此方法的详细、分步实现基于以下原则：\n\n首先，我们构建加权无向图 $G_k = (V, E_k)$，其中顶点集 $V$ 对应 $n$ 个数据样本。边集 $E_k$ 和相关权重分三个阶段确定。\na. 我们首先计算所有点对之间的欧几里得距离矩阵，称之为 $D_{Euc}$，其中 $D_{Euc}[i, j]$ 是点 $x_i$ 和 $x_j$ 在 $\\mathbb{R}^2$ 中的欧几里得距离。该矩阵构成了所有后续基于距离操作的基础。对于任意两点 $x_i = (x_i^{(1)}, x_i^{(2)})$ 和 $x_j = (x_j^{(1)}, x_j^{(2)})$，距离为 $D_{Euc}[i,j] = \\sqrt{(x_i^{(1)} - x_j^{(1)})^2 + (x_i^{(2)} - x_j^{(2)})^2}$。\nb. 接着，对每个点 $i$，我们通过在 $D_{Euc}$ 的第 $i$ 行中找到 $k$ 个值最小的点 $j \\ne i$ 来确定其 $k$ 个最近邻居的集合 $N_k(i)$。这定义了一个有向 $k$-NN 图。\nc. 然后通过取边的“无向并集”来对称化该图。一个无向边 $(i, j)$ 在 $G_k$ 中存在，当且仅当 $j \\in N_k(i)$ 或 $i \\in N_k(j)$。该边的权重是其欧几里得距离 $D_{Euc}[i, j]$。此过程生成一个加权邻接矩阵 $W$，其中如果边 $(i, j)$ 存在，则 $W_{ij} = D_{Euc}[i, j]$，否则 $W_{ij} = +\\infty$。根据定义，$W_{ii} = 0$。\n\n其次，我们计算图测地距离矩阵 $D_{geo}$。值 $D_{geo}[i, j]$ 是图 $G_k$ 中节点 $i$ 和 $j$ 之间最短路径的长度。对于一个稠密图表示（邻接矩阵 $W$）和少量节点（$n=8$），Floyd-Warshall 算法是解决此所有点对最短路径问题的最合适方法。该算法迭代地将每个节点视为所有其他节点对之间路径上的潜在中间点，系统地松弛路径长度，直到找到最短路径。输出是一个矩阵 $D_{geo}$，如果相应节点之间不存在路径，则条目为 $+\\infty$。\n\n第三，我们计算每个样本 $i$ 的轮廓分数。这需要使用 $D_{geo}$ 中的测地距离来计算两个量，$a(i)$ 和 $b(i)$。设 $C(i)$ 表示样本 $i$ 被分配到的簇。\n-   $a(i)$：平均簇内距离。它是 $D_{geo}[i,j]$ 对所有在同一簇中的其他样本 $j$（$j \\in C(i), j \\ne i$）的均值。平均值中仅包含有限距离。\n-   $b(i)$：最小平均簇间距离。对于每个其他簇 $C_m$（其中 $m \\ne C(i)$），我们计算从 $i$ 到 $C_m$ 中所有样本 $j$ 的平均距离，同样只使用有限距离。$b(i)$ 是在所有其他簇 $C_m$ 上这些平均值的最小值。\n\n问题为不明确定义的情况指定了关键约定：\n-   如果样本 $i$ 是一个孤立点（其簇的唯一成员），其轮廓值 $s(i)$ 为 $0$。这是一个基本情况。\n-   如果样本 $i$ 与其自身簇的任何其他成员之间没有有限距离的路径，$a(i)$ 未定义。此时轮廓值 $s(i)$ 被设为 $0$。\n-   如果样本 $i$ 与任何其他簇中的任何样本之间没有有限距离的路径，$b(i)$ 未定义。此时轮廓值 $s(i)$ 被设为 $0$。\n\n一旦获得了 $a(i)$ 和 $b(i)$ 的明确定义值，样本 $i$ 的轮廓值就使用规范公式计算：\n$$ s(i) = \\frac{b(i) - a(i)}{\\max\\{a(i), b(i)\\}} $$\n如果 $a(i)=b(i)=0$，这将导致除以零；然而，鉴于问题的数据和结构，对于非零轮廓值，这种情况不会出现。零值约定处理了所有退化场景。\n\n最后，整个数据集的平均轮廓分数就是所有 $n$ 个样本的单个 $s(i)$ 值的算术平均值。对所提供的五个测试用例中的每一个都重复此过程。",
            "answer": "```python\nimport numpy as np\nfrom scipy.sparse.csgraph import floyd_warshall\nfrom scipy.spatial.distance import cdist\n\ndef calculate_mean_silhouette(points, labels, k):\n    \"\"\"\n    Computes the mean silhouette score based on graph geodesic distances.\n\n    Args:\n        points (np.ndarray): An (n, d) array of n points in d dimensions.\n        labels (np.ndarray): An (n,) array of cluster labels.\n        k (int): The number of nearest neighbors for graph construction.\n\n    Returns:\n        float: The mean silhouette score.\n    \"\"\"\n    n = points.shape[0]\n    \n    # Step A: Construct the symmetric k-NN graph\n    # 1. Compute Euclidean distance matrix\n    euc_dist = cdist(points, points, 'euclidean')\n    \n    # 2. Build weighted adjacency matrix W for the symmetric k-NN graph\n    adj_matrix = np.full((n, n), np.inf)\n    np.fill_diagonal(adj_matrix, 0)\n    \n    # Find k-nearest neighbors for each point\n    # argsort returns indices, [:, 1:k+1] skips self (dist=0) and takes k neighbors\n    # A stable sort tie-breaking rule (e.g., lower index first) is implicitly\n    # handled by how np.argsort is implemented, which is sufficient here.\n    neighbor_indices = np.argsort(euc_dist, axis=1)[:, 1:k+1]\n    \n    for i in range(n):\n        for j_idx in neighbor_indices[i]:\n            # Symmetrize by taking the union of directed edges\n            if adj_matrix[i, j_idx] == np.inf:\n                adj_matrix[i, j_idx] = euc_dist[i, j_idx]\n            if adj_matrix[j_idx, i] == np.inf:\n                adj_matrix[j_idx, i] = euc_dist[j_idx, i]\n\n    # Step B: Compute all-pairs geodesic distances using Floyd-Warshall\n    geo_dist = floyd_warshall(csgraph=adj_matrix, directed=False)\n    \n    # Step C: Compute per-sample silhouette values\n    silhouette_values = np.zeros(n)\n    unique_labels = np.unique(labels)\n    \n    for i in range(n):\n        label_i = labels[i]\n        \n        # Identify points in the same cluster and other clusters\n        in_cluster_mask = (labels == label_i)\n        in_cluster_mask[i] = False  # Exclude the point itself\n        \n        # Handle singleton clusters\n        if not np.any(in_cluster_mask):\n            silhouette_values[i] = 0.0\n            continue\n            \n        # Calculate a(i): average intra-cluster distance\n        a_dists = geo_dist[i, in_cluster_mask]\n        a_dists_finite = a_dists[np.isfinite(a_dists)]\n        \n        # Handle disconnection within the cluster\n        if len(a_dists_finite) == 0:\n            silhouette_values[i] = 0.0\n            continue\n        \n        a_i = np.mean(a_dists_finite)\n        \n        # Calculate b(i): minimum average inter-cluster distance\n        other_cluster_means = []\n        other_labels = [ul for ul in unique_labels if ul != label_i]\n        \n        for other_label in other_labels:\n            other_cluster_mask = (labels == other_label)\n            b_dists = geo_dist[i, other_cluster_mask]\n            b_dists_finite = b_dists[np.isfinite(b_dists)]\n            \n            if len(b_dists_finite) > 0:\n                other_cluster_means.append(np.mean(b_dists_finite))\n        \n        # Handle disconnection from all other clusters\n        if len(other_cluster_means) == 0:\n            silhouette_values[i] = 0.0\n            continue\n            \n        b_i = np.min(other_cluster_means)\n        \n        # Calculate silhouette value s(i)\n        numerator = b_i - a_i\n        denominator = max(a_i, b_i)\n        \n        silhouette_values[i] = numerator / denominator if denominator > 0 else 0.0\n        \n    # Step D: Compute mean silhouette score\n    return np.mean(silhouette_values)\n\n\ndef solve():\n    \"\"\"\n    Main function to run the test suite and print the results.\n    \"\"\"\n    # Dataset definition\n    points = np.array([\n        [0, 0], [1, 0], [2, 0],\n        [10, 0], [11, 0], [12, 0],\n        [25, 0], [26, 0]\n    ], dtype=float)\n\n    # Test suite definition\n    test_cases = [\n        {'k': 3, 'labels': np.array([0, 0, 0, 1, 1, 1, 2, 2])},\n        {'k': 1, 'labels': np.array([0, 0, 0, 1, 1, 1, 2, 2])},\n        {'k': 7, 'labels': np.array([0, 0, 0, 1, 1, 1, 2, 2])},\n        {'k': 3, 'labels': np.array([0, 0, 0, 1, 1, 1, 1, 1])},\n        {'k': 3, 'labels': np.array([0, 0, 0, 1, 1, 1, 1, 2])}\n    ]\n\n    results = []\n    for case in test_cases:\n        mean_silhouette = calculate_mean_silhouette(points, case['labels'], case['k'])\n        results.append(mean_silhouette)\n    \n    # Format and print the final output\n    formatted_results = [f\"{res:.6f}\" for res in results]\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```"
        }
    ]
}