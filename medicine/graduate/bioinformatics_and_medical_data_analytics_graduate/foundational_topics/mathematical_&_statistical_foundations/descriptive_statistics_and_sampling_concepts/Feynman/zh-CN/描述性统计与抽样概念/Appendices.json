{
    "hands_on_practices": [
        {
            "introduction": "在生物医学数据分析中，我们经常遇到包含极端值或异常值的数据集。本练习将通过一个关于细胞因子浓度的假设场景，引导您动手计算样本均值和截尾均值。通过比较这两种描述性统计量对异常值的敏感性，您将深刻理解为何在探索性数据分析中，选择像截尾均值这样的稳健估计量至关重要 。",
            "id": "4555567",
            "problem": "一个生物信息学团队正在使用酶联免疫吸附测定（ELISA）方法，分析以皮克/毫升为单位计量的白细胞介素-6（IL-6）细胞因子浓度。为了评估在医学数据分析中汇总统计量对离群值的稳健性，请考虑以下来自$20$个患者样本的模拟IL-6浓度：\n$\\{4, 5, 7, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 400\\}$。\n\n你的任务是：\n- 仅使用描述性统计学的基本原理，计算给定数据集的样本均值和$20\\%$截尾均值。将截尾理解为：对于一个大小为$n$的数据集，舍弃排序后最小和最大的$k$个值，其中$k = \\lfloor 0.2 n \\rfloor$，然后对其余的值求平均。\n- 为了量化对离群值的敏感度，将数据集$X$上的统计量$T$的离群值敏感度指数定义如下。设$X'$为从$X$中删除单个最大观测值后得到的数据集。定义$\\Delta_{T} = |T(X) - T(X')|$。计算比率\n$$S = \\frac{\\Delta_{\\bar{X}}}{\\Delta_{T_{0.2}}},$$\n其中$\\bar{X}$是样本均值，$T_{0.2}$是$20\\%$截尾均值，每个统计量都在其各自的数据集大小上独立计算，并使用各自的截尾参数$k = \\lfloor 0.2 n \\rfloor$。\n\n请以精确有理数（无四舍五入）的形式提供你的最终数值答案。需要提交的最终答案是$S$的单个值（无单位）。",
            "solution": "首先对用户提供的问题陈述进行严格的验证过程。\n\n### 步骤1：提取已知条件\n- **数据集 $X$**: $\\{4, 5, 7, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 400\\}$\n- **数据集大小 $n$**: $20$\n- **任务1**: 计算$X$的样本均值($\\bar{X}$)和$20\\%$截尾均值($T_{0.2}$)。\n- **截尾的定义**: 对于大小为$n$的数据集，舍弃排序后最小和最大的$k$个值，其中$k = \\lfloor 0.2 n \\rfloor$，然后对其余的值求平均。\n- **任务2**: 计算离群值敏感度比率$S$。\n- **$X'$的定义**: 从$X$中删除单个最大观测值后得到的数据集。\n- **敏感度指数$\\Delta_T$的定义**: $\\Delta_{T} = |T(X) - T(X')|$，其中$T$是一个统计量。\n- **比率$S$的定义**: $S = \\frac{\\Delta_{\\bar{X}}}{\\Delta_{T_{0.2}}}$，其中$\\bar{X}$是样本均值，$T_{0.2}$是$20\\%$截尾均值。\n- **计算约束**: 对于在$X'$上的计算，统计量（$\\bar{X}$和$T_{0.2}$）是在新的数据集大小$n'$及其对应的截尾参数$k' = \\lfloor 0.2 n' \\rfloor$上独立计算的。\n\n### 步骤2：使用提取的已知条件进行验证\n1.  **科学依据**：该问题基于描述性统计学的既定原则。分析含有离群值的细胞因子浓度是医学数据分析和生物信息学中的一个标准且现实的问题。样本均值、截尾均值和敏感度分析的概念是稳健统计学的基础。\n2.  **适定性**：所有术语都有明确无误的定义。提供了数据集，并清楚地指明了计算步骤。为缩减后的数据集$X'$重新计算截尾参数的规则确保了没有歧义，从而导向唯一解。\n3.  **客观性**：问题陈述使用了精确的、定量的语言，不含主观或基于意见的论断。\n\n### 步骤3：结论与行动\n该问题是**有效的**。它在科学上是合理的，具有适定性和客观性，并包含了得出唯一解所需的所有必要信息。现在可以开始求解过程。\n\n### 求解推导\n\n初始数据集为 $X = \\{4, 5, 7, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 400\\}$。该数据集已经按升序排序。数据集的大小为$n=20$。\n\n**1. 计算完整数据集 $X$ 的统计量**\n\n首先，我们计算$X$的样本均值，记为$\\bar{X}(X)$。\n$X$中所有观测值的和为：\n$$ \\sum_{i=1}^{n} x_i = (4+5+7+9+10+11+12+13+14+15+16+17+18+19+20+21+22+23+24) + 400 $$\n前$19$个观测值的和是$280$。\n$$ \\sum_{i=1}^{n} x_i = 280 + 400 = 680 $$\n样本均值为：\n$$ \\bar{X}(X) = \\frac{1}{n} \\sum_{i=1}^{n} x_i = \\frac{680}{20} = 34 $$\n\n接下来，我们计算$X$的$20\\%$截尾均值，记为$T_{0.2}(X)$。\n从两端各需截去的观测值数量为 $k = \\lfloor 0.2 \\times n \\rfloor = \\lfloor 0.2 \\times 20 \\rfloor = \\lfloor 4 \\rfloor = 4$。\n我们舍弃$4$个最小值$\\{4, 5, 7, 9\\}$和$4$个最大值$\\{22, 23, 24, 400\\}$。\n用于计算截尾均值的剩余数据集包含$n - 2k = 20 - 2(4) = 12$个观测值：\n$$ X_{T} = \\{10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21\\} $$\n这些值构成一个等差数列，它们的和为：\n$$ \\sum_{x \\in X_T} x = \\frac{12}{2} (10 + 21) = 6 \\times 31 = 186 $$\n$20\\%$截尾均值为：\n$$ T_{0.2}(X) = \\frac{186}{12} = \\frac{31}{2} $$\n\n**2. 计算缩减后数据集 $X'$ 的统计量**\n\n数据集$X'$是通过从$X$中移除单个最大观测值($400$)形成的。\n$$ X' = \\{4, 5, 7, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24\\} $$\n这个新数据集的大小为$n' = 19$。\n\n首先，我们计算$X'$的样本均值，记为$\\bar{X}(X')$。\n$X'$中观测值的和是$X$的总和减去被移除的离群值：\n$$ \\sum_{x \\in X'} x = 680 - 400 = 280 $$\n$X'$的样本均值为：\n$$ \\bar{X}(X') = \\frac{280}{19} $$\n\n接下来，我们计算$X'$的$20\\%$截尾均值，记为$T_{0.2}(X')$。\n需要截去的观测值数量根据$n'=19$重新计算：\n$$ k' = \\lfloor 0.2 \\times n' \\rfloor = \\lfloor 0.2 \\times 19 \\rfloor = \\lfloor 3.8 \\rfloor = 3 $$\n我们从$X'$中舍弃$3$个最小值$\\{4, 5, 7\\}$和$3$个最大值$\\{22, 23, 24\\}$。\n用于计算截尾均值的剩余数据集包含$n' - 2k' = 19 - 2(3) = 13$个观测值：\n$$ X'_{T} = \\{9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21\\} $$\n这些值构成一个等差数列，它们的和为：\n$$ \\sum_{x \\in X'_{T}} x = \\frac{13}{2} (9 + 21) = \\frac{13}{2} (30) = 13 \\times 15 = 195 $$\n$X'$的$20\\%$截尾均值为：\n$$ T_{0.2}(X') = \\frac{195}{13} = 15 $$\n\n**3. 计算敏感度指数和最终比率 $S$**\n\n样本均值的敏感度指数$\\Delta_{\\bar{X}}$为：\n$$ \\Delta_{\\bar{X}} = |\\bar{X}(X) - \\bar{X}(X')| = \\left|34 - \\frac{280}{19}\\right| = \\left|\\frac{34 \\times 19}{19} - \\frac{280}{19}\\right| = \\left|\\frac{646 - 280}{19}\\right| = \\frac{366}{19} $$\n\n截尾均值的敏感度指数$\\Delta_{T_{0.2}}$为：\n$$ \\Delta_{T_{0.2}} = |T_{0.2}(X) - T_{0.2}(X')| = \\left|\\frac{31}{2} - 15\\right| = \\left|\\frac{31}{2} - \\frac{30}{2}\\right| = \\frac{1}{2} $$\n\n最后，我们计算比率$S$：\n$$ S = \\frac{\\Delta_{\\bar{X}}}{\\Delta_{T_{0.2}}} = \\frac{\\frac{366}{19}}{\\frac{1}{2}} = \\frac{366}{19} \\times 2 = \\frac{732}{19} $$\n数字$19$是素数，而$732$不是$19$的倍数（$732 = 38 \\times 19 + 10$）。因此，该分数为最简分数。",
            "answer": "$$\n\\boxed{\\frac{732}{19}}\n$$"
        },
        {
            "introduction": "从单点估计前进到区间估计，可以为我们的推断提供不确定性的度量。本练习聚焦于估计二元生物标志物阳性率这一常见临床研究问题，要求您推导并比较经典的 Wald 置信区间和更先进的 Wilson 得分置信区间 。通过处理小样本数据，您将亲身体会到不同理论构造（例如，反转检验与直接使用标准误插件）如何在实践中影响区间的性能和可靠性。",
            "id": "4555572",
            "problem": "一个转化肿瘤学团队正在试行一种二元免疫组织化学分析，以量化与靶向治疗反应相关的细胞表面生物标志物呈阳性的肿瘤活检样本的比例。在这项试点研究中，有 $n = 12$ 份独立的活检样本，其中 $x = 2$ 份呈阳性。令 $p$ 表示目标人群中生物标志物阳性的真实概率。\n\n从二项抽样模型和将双侧置信区间（CI）定义为检验的反演这一概念出发，使用标准正态分位数 $z_{0.975}$ 推导 $p$ 在 $95\\%$ 双侧置信水平下的 Wilson 得分置信区间，并基于渐近正态近似推导 $p$ 的 Wald 置信区间。假设不进行连续性校正，并使用 $z_{0.975} = 1.96$。\n\n定义区间长度为 $L = U - L$，其中 $U$ 和 $L$ 分别是上、下端点。对于观测数据（$n = 12$，$x = 2$），计算比率\n$$\nR \\;=\\; \\frac{L_{\\text{Wald}}}{L_{\\text{Wilson}}}\n$$\n将您计算出的 $R$ 的最终数值结果四舍五入到四位有效数字。",
            "solution": "该问题要求推导二项比例 $p$ 的两种置信区间（CI），并随后为给定数据集计算它们长度的比率。这两种置信区间是 Wald 区间和 Wilson 得分区间。\n\n令 $n$ 为独立伯努利试验的次数，$x$ 为成功的次数。真实比例 $p$ 的点估计是样本比例 $\\hat{p} = x/n$。假设成功次数 $X$ 服从二项分布，$X \\sim \\text{Binomial}(n,p)$。根据中心极限定理，对于足够大的样本量 $n$，$\\hat{p}$ 的抽样分布可以由正态分布近似：$\\hat{p} \\approx \\mathcal{N}\\left(p, \\frac{p(1-p)}{n}\\right)$。\n\n指定的置信水平为 $95\\%$，对应的显著性水平为 $\\alpha = 0.05$。给定的标准正态分布分位数为 $z_{1-\\alpha/2} = z_{0.975} = 1.96$。\n\n**1. Wald 置信区间的推导与公式**\n\nWald 置信区间是从 $\\hat{p}$ 分布的正态近似推导出来的。它通过用样本估计值 $\\hat{p}$ 替代未知参数 $p$ 来近似 $\\hat{p}$ 的标准误 $SE = \\sqrt{p(1-p)/n}$。这就得到了估计的标准误 $\\widehat{SE}(\\hat{p}) = \\sqrt{\\hat{p}(1-\\hat{p})/n}$。\n\n该置信区间由枢轴量 $Z = (\\hat{p}-p)/\\widehat{SE}(\\hat{p})$ 构建，假设该枢轴量服从标准正态分布。$100(1-\\alpha)\\%$ 置信区间是满足以下条件的 $p$ 值范围：\n$$\n-z_{1-\\alpha/2} \\le \\frac{\\hat{p}-p}{\\sqrt{\\frac{\\hat{p}(1-\\hat{p})}{n}}} \\le z_{1-\\alpha/2}\n$$\n解出 $p$ 可得到区间：\n$$\n\\hat{p} \\pm z_{1-\\alpha/2}\\sqrt{\\frac{\\hat{p}(1-\\hat{p})}{n}}\n$$\n下端点 ($L$) 和上端点 ($U$) 分别为 $L_{\\text{Wald}} = \\hat{p} - z_{1-\\alpha/2}\\sqrt{\\frac{\\hat{p}(1-\\hat{p})}{n}}$ 和 $U_{\\text{Wald}} = \\hat{p} + z_{1-\\alpha/2}\\sqrt{\\frac{\\hat{p}(1-\\hat{p})}{n}}$。Wald 区间的长度是上、下端点之差：\n$$\nL_{\\text{Wald}} = U_{\\text{Wald}} - L_{\\text{Wald}} = 2 z_{1-\\alpha/2}\\sqrt{\\frac{\\hat{p}(1-\\hat{p})}{n}}\n$$\n\n**2. Wilson 得分置信区间的推导与公式**\n\nWilson 得分置信区间是通过反演比例 $p$ 的得分检验推导出来的。得分检验统计量使用原假设值 $p_0$ 来计算标准误，而不是样本估计值 $\\hat{p}$。该检验统计量为：\n$$\nZ = \\frac{\\hat{p}-p_0}{\\sqrt{\\frac{p_0(1-p_0)}{n}}}\n$$\n$p$ 的置信区间包含所有使原假设 $H_0: p = p_0$ 不被拒绝的 $p_0$ 值，即满足 $|Z| \\le z_{1-\\alpha/2}$ 的值。\n$$\n\\left| \\frac{\\hat{p}-p_0}{\\sqrt{\\frac{p_0(1-p_0)}{n}}} \\right| \\le z_{1-\\alpha/2}\n$$\n将两边平方并整理，得到一个关于 $p_0$ 的一元二次不等式：\n$$\n(\\hat{p}-p_0)^2 \\le z_{1-\\alpha/2}^2 \\left( \\frac{p_0(1-p_0)}{n} \\right)\n$$\n$$\nn(\\hat{p}^2 - 2\\hat{p}p_0 + p_0^2) \\le z_{1-\\alpha/2}^2 (p_0 - p_0^2)\n$$\n$$\n(n + z_{1-\\alpha/2}^2)p_0^2 - (2n\\hat{p} + z_{1-\\alpha/2}^2)p_0 + n\\hat{p}^2 \\le 0\n$$\n该置信区间的端点是一元二次方程 $(n + z^2)p^2 - (2n\\hat{p} + z^2)p + n\\hat{p}^2 = 0$ 的根，其中 $z = z_{1-\\alpha/2}$。使用求根公式 $p = \\frac{-b \\pm \\sqrt{b^2-4ac}}{2a}$，根为：\n$$\np = \\frac{(2n\\hat{p} + z^2) \\pm \\sqrt{(2n\\hat{p} + z^2)^2 - 4(n + z^2)(n\\hat{p}^2)}}{2(n + z^2)}\n$$\n简化判别式：\n$$\n\\sqrt{4n^2\\hat{p}^2 + 4n\\hat{p}z^2 + z^4 - 4n^2\\hat{p}^2 - 4n\\hat{p}^2z^2} = \\sqrt{z^2(4n\\hat{p}(1-\\hat{p}) + z^2)} = z\\sqrt{4n\\hat{p}(1-\\hat{p}) + z^2}\n$$\nWilson 得分区间的端点是：\n$$\np = \\frac{2n\\hat{p} + z^2 \\pm z\\sqrt{4n\\hat{p}(1-\\hat{p}) + z^2}}{2(n + z^2)}\n$$\nWilson 区间的长度是这两个端点之差：\n$$\nL_{\\text{Wilson}} = \\frac{2z\\sqrt{4n\\hat{p}(1-\\hat{p}) + z^2}}{2(n + z^2)} = \\frac{z\\sqrt{4n\\hat{p}(1-\\hat{p}) + z^2}}{n + z^2}\n$$\n\n**3. 长度比率的计算**\n\n给定数据：$n = 12$，$x = 2$，$z_{0.975} = 1.96$。\n样本比例为 $\\hat{p} = \\frac{x}{n} = \\frac{2}{12} = \\frac{1}{6}$。\n\n首先，计算 Wald 区间的长度 $L_{\\text{Wald}}$：\n$$\nL_{\\text{Wald}} = 2(1.96)\\sqrt{\\frac{(1/6)(1 - 1/6)}{12}} = 3.92\\sqrt{\\frac{(1/6)(5/6)}{12}} = 3.92\\sqrt{\\frac{5/36}{12}} = 3.92\\sqrt{\\frac{5}{432}}\n$$\n数值上，$L_{\\text{Wald}} \\approx 3.92 \\times 0.10758286 = 0.4217255...$\n\n接下来，计算 Wilson 得分区间的长度 $L_{\\text{Wilson}}$。令 $z = 1.96$：\n$$\nL_{\\text{Wilson}} = \\frac{z\\sqrt{4n\\hat{p}(1-\\hat{p}) + z^2}}{n + z^2}\n$$\n计算各组成部分：\n$z^2 = 1.96^2 = 3.8416$。\n$4n\\hat{p}(1-\\hat{p}) = 4(12)(\\frac{1}{6})(\\frac{5}{6}) = 48(\\frac{5}{36}) = \\frac{4}{3} \\times 5 = \\frac{20}{3}$。\n分母为 $n + z^2 = 12 + 3.8416 = 15.8416$。\n分子为 $z\\sqrt{\\frac{20}{3} + 3.8416} = 1.96\\sqrt{6.6666... + 3.8416} = 1.96\\sqrt{10.508266...}$。\n所以，$L_{\\text{Wilson}} = \\frac{1.96 \\times 3.2416456...}{15.8416} = \\frac{6.353625...}{15.8416} \\approx 0.4010728...$\n\n最后，计算比率 $R$：\n$$\nR = \\frac{L_{\\text{Wald}}}{L_{\\text{Wilson}}} = \\frac{0.4217255...}{0.4010728...} \\approx 1.051493...\n$$\n将此结果四舍五入到四位有效数字，得到 $1.051$。",
            "answer": "$$\\boxed{1.051}$$"
        },
        {
            "introduction": "有时候，单一的概括性统计量不足以完全描绘数据的特性，我们需要估计其完整的概率分布。本计算练习将带您进入非参数统计的世界，学习使用核密度估计 (Kernel Density Estimation, KDE) 来从数据中重构未知的潜在分布 。您将实现一个包含关键实践步骤的完整流程：选择核函数，并通过留一法交叉验证 (leave-one-out cross-validation) 这一数据驱动方法来选择最佳的平滑参数（带宽），这是现代数据分析和可视化的核心技能。",
            "id": "4555587",
            "problem": "给定代表血清胆固醇浓度的独立同分布观测值，单位为毫克/分升 (mg/dL)。将数据视为来自实线上的一个未知、绝对连续概率分布的实现。目标是使用核密度估计来估计其潜在的概率密度，并通过最大化留一法对数似然来为两种核函数分别选择带宽。然后，您将比较哪个核函数获得了更大的最大化留一法对数似然值。\n\n基本原理与假设：从经验分布函数为每个观测值赋予相等质量的定义出发，核密度估计器是通过使用一个积分为一的对称核函数来平滑经验分布而产生的。核函数是一个满足对称性和单位积分性质的非负可积函数。将使用的两个核是 Gaussian 核和 Epanechnikov 核。Gaussian 核由标准正态密度定义，Epanechnikov 核由一个紧支撑的二次型定义。所有对数似然都必须使用自然对数。交叉验证带宽选择指的是选择使留一法对数似然最大化的带宽，其中对于每个观测值，其对似然的贡献在核估计中排除了该观测值本身。\n\n实现要求：\n- 对于 Gaussian 核，使用由 $K_{\\mathrm{G}}(u) = (2\\pi)^{-1/2} \\exp(-u^{2}/2)$ 定义的核。\n- 对于 Epanechnikov 核，当 $|u|\\leq 1$ 时，使用由 $K_{\\mathrm{E}}(u) = \\tfrac{3}{4}(1-u^{2})$ 定义的核，否则 $K_{\\mathrm{E}}(u)=0$。\n- 对于给定的带宽 $h$ 和大小为 $n$ 的样本，在点 $x$ 处的核密度估计器是在 $x$ 与样本点之间的成对差异（由 $h$ 缩放）上进行核函数求值的平均值，再由 $h$ 进行缩放。这与估计器积分为一且具有正确物理单位的要求一致。对于留一法，每个观测值对对数似然的贡献使用从平均中排除该观测值本身的估计器。\n- 为确保当估计器在某个观测点上的值为零时留一法对数似然的数值稳定性，您必须应用一个下界：将任何零或负的密度值替换为 $\\max\\{ \\varepsilon / h, 0 \\}$，其中 $\\varepsilon = 10^{-12}$。这为密度贡献保留了正确的物理单位，并避免了未定义的对数。常数 $\\varepsilon$ 是无量纲的。\n- 如果多个带宽达到相同的最大留一法对数似然值（在机器精度范围内），则选择这些最大化带宽中的最小值。\n- 带宽必须以 mg/dL 为单位报告。所有对数似然值都是无单位的。\n\n测试套件和参数：实现您的程序以运行以下三个测试用例。在所有随机生成中，使用指定的种子和 NumPy 伪随机数生成器的默认算法。\n- 测试用例 A（类混合，中等规模）：\n  - 随机种子 $13$。\n  - 从均值为 $\\mu_{1} = 190$、标准差为 $\\sigma_{1} = 22$ 的正态分布（单位均为 mg/dL）中生成 $n_{1} = 90$ 个观测值。\n  - 从均值为 $\\mu_{2} = 230$、标准差为 $\\sigma_{2} = 18$ 的正态分布（单位均为 mg/dL）中生成 $n_{2} = 60$ 个观测值。\n  - 连接两个样本，然后将所有值裁剪到区间 $[120, 300]$ mg/dL 内，并将每个值四舍五入到 $1$ 位小数。\n- 测试用例 B（带离群值的小样本，确定性）：\n  - 使用以 mg/dL 为单位的显式值列表：$[146.0, 152.0, 158.0, 162.0, 166.0, 170.0, 210.0, 260.0, 300.0, 310.0]$。\n- 测试用例 C（带重复值的重尾分布）：\n  - 随机种子 $7$。\n  - 从自由度为 $\\nu = 5$ 的 Student t 分布中抽取 $n = 50$ 个观测值，然后通过 $x \\mapsto 200 + 30x$ 进行变换以设置位置和尺度（mg/dL）。\n  - 将所有值裁剪到区间 $[110, 340]$ mg/dL 内。\n  - 追加 $10$ 个 $200.0$ mg/dL 的精确副本和 $10$ 个 $240.0$ mg/dL 的精确副本。\n- 对所有测试用例，使用候选带宽网格（单位均为 mg/dL）：$\\{5.0, 7.5, 10.0, 12.5, 15.0, 20.0, 25.0, 35.0\\}$。\n\n需对每个测试用例执行的任务：\n1. 对于每个核（Gaussian 和 Epanechnikov）以及网格中的每个带宽 $h$，计算留一法对数似然。该值是在每个观测数据点上评估的留一法核密度估计器的自然对数之和，并按规定使用 $\\varepsilon = 10^{-12}$ 应用稳定性下限。\n2. 对于每个核，在网格中找到使留一法对数似然最大化的带宽 $h$（若存在多个，则选择最小的 $h$）。\n3. 比较两个核的最大化留一法对数似然值，并确定哪个核的似然值更大。\n4. 对每个测试用例，按顺序报告以下五个值：\n   - 内核标识符 $k$，其中 $k=0$ 表示 Gaussian 核，$k=1$ 表示 Epanechnikov 核，选择达到较大最大化留一法对数似然值的那个（若值相等，则优先选择 Gaussian 核）。\n   - Gaussian 核的选定带宽 $h_{\\mathrm{G}}^{\\star}$，四舍五入到 $2$ 位小数，单位为 mg/dL。\n   - Epanechnikov 核的选定带宽 $h_{\\mathrm{E}}^{\\star}$，四舍五入到 $2$ 位小数，单位为 mg/dL。\n   - Gaussian 核的最大化留一法对数似然值 $L_{\\mathrm{G}}^{\\star}$，四舍五入到 $6$ 位小数。\n   - Epanechnikov 核的最大化留一法对数似然值 $L_{\\mathrm{E}}^{\\star}$，四舍五入到 $6$ 位小数。\n\n最终输出格式：\n- 您的程序应生成单行输出，其中包含三个测试用例的结果。结果是一个由逗号分隔的列表，用方括号括起来，每个测试用例的结果本身也是一个按上述顺序排列的列表。不应包含任何空白字符。例如，输出应如下所示：$[[k_{A},h_{\\mathrm{G},A}^{\\star},h_{\\mathrm{E},A}^{\\star},L_{\\mathrm{G},A}^{\\star},L_{\\mathrm{E},A}^{\\star}],[k_{B},h_{\\mathrm{G},B}^{\\star},h_{\\mathrm{E},B}^{\\star},L_{\\mathrm{G},B}^{\\star},L_{\\mathrm{E},B}^{\\star}],[k_{C},h_{\\mathrm{G},C}^{\\star},h_{\\mathrm{E},C}^{\\star},L_{\\mathrm{G},C}^{\\star},L_{\\mathrm{E},C}^{\\star}]]$.",
            "solution": "该问题要求实现核密度估计（KDE），并通过留一法交叉验证进行带宽选择。对于三个数据集中的每一个，我们必须从一个预定义的网格中为 Gaussian 核和 Epanechnikov 核确定最佳带宽，然后比较这两个核的性能。\n\n**1. 理论公式**\n\n核密度估计器从数据点样本 $\\{x_1, x_2, \\ldots, x_n\\}$ 重建未知的概率密度函数 $f(x)$。估计器 $\\hat{f}_h(x)$ 定义为：\n$$\n\\hat{f}_h(x) = \\frac{1}{nh} \\sum_{i=1}^{n} K\\left(\\frac{x - x_i}{h}\\right)\n$$\n其中 $K(u)$ 是一个核函数（一个积分为一的非负对称函数），$h > 0$ 是带宽，一个平滑参数。$1/h$ 因子确保最终得到的密度积分为一。\n\n指定的两个核是：\n- **Gaussian 核**：$K_{\\mathrm{G}}(u) = \\frac{1}{\\sqrt{2\\pi}} e^{-u^2/2}$，即标准正态概率密度函数。\n- **Epanechnikov 核**：当 $|u| \\leq 1$ 时为 $K_{\\mathrm{E}}(u) = \\frac{3}{4}(1-u^2)$，否则为 $0$。\n\n**2. 通过留一法交叉验证（LOOCV）进行带宽选择**\n\n带宽 $h$ 的选择至关重要。LOOCV 提供了一种数据驱动的方法来选择 $h$。目标是最大化留一法对数似然，其定义为：\n$$\nL(h) = \\sum_{i=1}^{n} \\ln \\left( \\hat{f}_{h, -i}(x_i) \\right)\n$$\n这里，$\\hat{f}_{h, -i}(x_i)$ 是在数据点 $x_i$ 处评估的 KDE，但它是使用*除* $x_i$ 之外的所有其他数据点构建的：\n$$\n\\hat{f}_{h, -i}(x_i) = \\frac{1}{(n-1)h} \\sum_{j=1, j \\neq i}^{n} K\\left(\\frac{x_i - x_j}{h}\\right)\n$$\n此过程评估模型一次一个点地预测“未见”数据的能力。\n\n**3. 计算策略**\n\nLOOCV 对数似然的朴素实现将涉及一个嵌套循环，导致每个带宽 $h$ 的时间复杂度为 $O(n^2)$。我们采用了一种更高效的向量化方法。对于一个大小为 $n$ 的给定数据集 $X$，计算的核心是 LOO 密度估计的向量。\n\n1.  构建一个 $n \\times n$ 的成对差异矩阵 $D$，其中 $D_{ij} = x_i - x_j$。\n2.  用带宽 $h$ 缩放此矩阵以获得核函数参数，$U_{ij} = D_{ij}/h$。\n3.  将所选核函数 $K$ 按元素应用于矩阵 $U$，得到矩阵 $K_{ij} = K(U_{ij})$。\n4.  第 $i$ 个点的 LOO 和 $\\sum_{j \\neq i} K(\\frac{x_i - x_j}{h})$，是矩阵 $K$ 第 $i$ 行的和减去其对角线元素 $K_{ii} = K(0)$。这是因为整行的和包含了 $j=i$ 这一项。\n5.  通过计算矩阵 $K$ 的行和并减去其对角线元素的向量，可以同时对所有 $i$ 执行此操作。\n6.  然后将得到的和向量乘以 $1/((n-1)h)$，以获得 LOO 密度估计向量 $[\\hat{f}_{h, -1}(x_1), \\ldots, \\hat{f}_{h, -n}(x_n)]$。\n\n**4. 数值稳定性**\n\n对于某些数据和带宽的组合，特别是对于紧支撑的 Epanechnikov 核，密度估计 $\\hat{f}_{h, -i}(x_i)$ 可能为零（例如，如果 $x_i$ 远离所有其他点）。为防止出现未定义的自然对数，应用了数值下限。任何非正的密度估计值都替换为 $\\varepsilon/h$，其中 $\\varepsilon = 10^{-12}$。这个小的正值具有与概率密度（$1/(\\text{mg/dL})$）相同的物理单位，从而保持了量纲的一致性。\n\n**5. 实现步骤**\n\n对每个测试用例：\n1.  生成或定义指定的数据集。\n2.  候选带宽集合为 $\\{5.0, 7.5, 10.0, 12.5, 15.0, 20.0, 25.0, 35.0\\}$。\n3.  对于每个核（Gaussian 和 Epanechnikov）：\n    a. 使用向量化方法为网格中的每个 $h$ 计算 LOO 对数似然 $L(h)$。\n    b. 识别出使 $L(h)$ 最大化的带宽 $h^{\\star}$。如果多个带宽产生相同的最大似然值，则选择最小的那个。相应的最大似然值为 $L^{\\star}$。\n4.  比较最大化对数似然值 $L_{\\mathrm{G}}^{\\star}$ 和 $L_{\\mathrm{E}}^{\\star}$。具有较大值的核被认为是更优的。平局决胜规则偏向于 Gaussian 核。\n5.  收集每个测试用例的最终结果——更优的核标识符 $k$、最优带宽 $h_{\\mathrm{G}}^{\\star}$ 和 $h_{\\mathrm{E}}^{\\star}$，以及最大化对数似然值 $L_{\\mathrm{G}}^{\\star}$ 和 $L_{\\mathrm{E}}^{\\star}$——并按规定格式化。\n\n这个结构化的过程保证了对所提出问题的一个可复现且计算高效的解决方案。",
            "answer": "```python\nimport numpy as np\nfrom scipy.stats import norm\n\ndef solve():\n    \"\"\"\n    Solves the kernel density estimation and bandwidth selection problem\n    for three specified test cases.\n    \"\"\"\n\n    def gaussian_kernel(u: np.ndarray) -> np.ndarray:\n        \"\"\"\n        Computes the Gaussian kernel, K(u) = (2*pi)^(-1/2) * exp(-u^2/2).\n        \"\"\"\n        return norm.pdf(u)\n\n    def epanechnikov_kernel(u: np.ndarray) -> np.ndarray:\n        \"\"\"\n        Computes the Epanechnikov kernel, K(u) = 0.75 * (1 - u^2) for |u| <= 1.\n        \"\"\"\n        return 0.75 * (1 - u**2) * (np.abs(u) <= 1)\n\n    def calculate_loo_ll(X: np.ndarray, h: float, kernel_func, epsilon: float = 1e-12) -> float:\n        \"\"\"\n        Calculates the leave-one-out log-likelihood for a given dataset,\n        bandwidth, and kernel.\n        \"\"\"\n        n = len(X)\n        if n <= 1:\n            return -np.inf\n\n        # Vectorized calculation of LOO estimates\n        X_col = X.reshape(-1, 1)\n        # Broadcasting creates the n x n matrix of differences (x_i - x_j)\n        diff_matrix = X_col - X\n        u_matrix = diff_matrix / h\n        k_matrix = kernel_func(u_matrix)\n\n        # The sum for the LOO estimate at x_i is sum of row i, minus K(0)\n        # This is equivalent to setting diagonal to 0 and summing rows\n        np.fill_diagonal(k_matrix, 0)\n        loo_sums = np.sum(k_matrix, axis=1)\n\n        loo_density = loo_sums / ((n - 1) * h)\n\n        # Apply numerical stability floor\n        floor_val = epsilon / h\n        stable_density = np.where(loo_density <= 0, floor_val, loo_density)\n\n        # Calculate total log-likelihood\n        log_likelihood = np.sum(np.log(stable_density))\n\n        return log_likelihood\n\n    def process_case(data: np.ndarray, bandwidths: list) -> list:\n        \"\"\"\n        Processes a single test case to find optimal bandwidths and likelihoods.\n        \"\"\"\n        # --- Gaussian Kernel ---\n        max_ll_g = -np.inf\n        best_h_g = -1.0\n        for h in bandwidths:\n            ll = calculate_loo_ll(data, h, gaussian_kernel)\n            if ll > max_ll_g:\n                max_ll_g = ll\n                best_h_g = h\n        \n        # --- Epanechnikov Kernel ---\n        max_ll_e = -np.inf\n        best_h_e = -1.0\n        for h in bandwidths:\n            ll = calculate_loo_ll(data, h, epanechnikov_kernel)\n            if ll > max_ll_e:\n                max_ll_e = ll\n                best_h_e = h\n\n        # Determine best kernel (k=0 for Gaussian, k=1 for Epanechnikov)\n        # Tie-breaking rule: Favor Gaussian kernel if likelihoods are equal.\n        k = 0 if max_ll_g >= max_ll_e else 1\n        \n        return [\n            k,\n            round(best_h_g, 2),\n            round(best_h_e, 2),\n            round(max_ll_g, 6),\n            round(max_ll_e, 6)\n        ]\n\n    # --- Test Cases Setup ---\n    bandwidths = [5.0, 7.5, 10.0, 12.5, 15.0, 20.0, 25.0, 35.0]\n    \n    # Test Case A\n    rng_a = np.random.default_rng(13)\n    d1 = rng_a.normal(loc=190, scale=22, size=90)\n    d2 = rng_a.normal(loc=230, scale=18, size=60)\n    data_a = np.concatenate((d1, d2))\n    data_a = np.clip(data_a, 120, 300)\n    data_a = np.round(data_a, 1)\n\n    # Test Case B\n    data_b = np.array([146.0, 152.0, 158.0, 162.0, 166.0, 170.0, 210.0, 260.0, 300.0, 310.0])\n\n    # Test Case C\n    rng_c = np.random.default_rng(7)\n    d_t = rng_c.standard_t(df=5, size=50)\n    data_c_base = 200 + 30 * d_t\n    data_c_base = np.clip(data_c_base, 110, 340)\n    ties1 = np.full(10, 200.0)\n    ties2 = np.full(10, 240.0)\n    data_c = np.concatenate((data_c_base, ties1, ties2))\n    \n    # --- Run and Collect Results ---\n    results = [\n        process_case(data_a, bandwidths),\n        process_case(data_b, bandwidths),\n        process_case(data_c, bandwidths)\n    ]\n\n    # --- Format Final Output ---\n    outer_parts = []\n    for res_list in results:\n        inner_parts = [str(v) for v in res_list]\n        outer_parts.append(f\"[{','.join(inner_parts)}]\")\n    \n    final_output_str = f\"[{','.join(outer_parts)}]\"\n    print(final_output_str)\n\nsolve()\n```"
        }
    ]
}