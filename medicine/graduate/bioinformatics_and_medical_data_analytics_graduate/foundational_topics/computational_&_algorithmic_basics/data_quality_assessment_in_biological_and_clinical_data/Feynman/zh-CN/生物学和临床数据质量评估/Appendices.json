{
    "hands_on_practices": [
        {
            "introduction": "在生物信息学分析中，评估原始测序数据的质量是至关重要的一步，但这不仅仅是检查FastQC报告中的警告。这项练习将理论与实践相结合，引导您从基本原理出发，量化不同质量控制（QC）指标（如错误率、接头污染和重复序列）如何直接影响下游单核苷酸变异（SNV）检测的灵敏度 。通过建立一个将QC指标转化为有效测序深度的模型，您将学会如何评估数据质量对科学结论的真实影响，从而做出更明智的数据处理决策。",
            "id": "4551926",
            "problem": "在下一代测序 (NGS) 的生物和临床数据的数据质量评估背景下，您将执行一项任务。您必须编写一个完整的程序，为每个数据集执行以下操作：计算一个FastQC风格的摘要，识别质量控制 (QC) 失败项，并量化由观测到的QC指标导致的下游单核苷酸变异 (SNV) 检出灵敏度的预期损失。您的推导和实现必须基于第一性原理：Phred质量定义和用于变异检测的二项式检验。\n\n使用以下基础和定义：\n- Phred质量分数由 $Q = -10 \\log_{10}(e)$ 定义，其中 $e$ 是碱基检出错误概率。因此 $e = 10^{-Q/10}$。\n- 假设一个二倍体杂合变异，其真实备择等位基因频率为 $f = 0.5$。设 $n$ 为一个位点上独立观测的有效数量（有效覆盖度）。在考虑了重复之后，假设该位点上的读段是独立的。\n- 定义原假设 $H_0$（无真实变异）：一个备择碱基检出等于某个特定非参考等位基因的概率为 $p_0 = e/3$（假设替换错误在三个非参考碱基中均匀分布）。\n- 定义备择假设 $H_1$（一个真实的杂合变异）：一个读段被观测为特定备择等位基因的概率为 $p_1 = f \\cdot (1 - e) + (1 - f) \\cdot (e/3)$。\n- 设置每个位点的假阳性尾部概率预算为 $\\alpha = 10^{-6}$。将在深度为 $n$ 时进行变异检出的最小整数阈值 $t$ 定义为满足 $\\Pr[X \\ge t \\mid X \\sim \\mathrm{Binomial}(n, p_0)] \\le \\alpha$ 的最小 $t$。如果不存在这样的 $t \\le n$，则灵敏度定义为 $0$。\n- 在 $H_1$ 下的灵敏度（统计功效）为 $S = \\Pr[X \\ge t \\mid X \\sim \\mathrm{Binomial}(n, p_1)]$。\n\n通过原始覆盖度和QC指标定义有效覆盖度 $n$ 如下。设 $C_{\\text{raw}}$ 为原始名义覆盖度。有效覆盖度为\n$$\nn = \\left\\lfloor C_{\\text{raw}} \\cdot m \\cdot (1 - d) \\cdot (1 - a) \\cdot (1 - n_f) \\cdot (1 - o) \\right\\rfloor,\n$$\n其中 $m$ 是比对率（小数），$d$ 是重复率（小数），$a$ 是接头污染比例（小数），$o$ 是过表达序列比例（小数），$n_f$ 是每碱基模糊检出比例（小数）。向下取整函数 $\\lfloor \\cdot \\rfloor$ 返回不大于其参数的最大整数。所有比例必须以小数形式提供，而非百分比。\n\n使用以下阈值为每个数据集的以下 $6$ 个模块计算一个FastQC风格的模块摘要（通过/警告/失败）：\n- 使用平均Phred质量分数 $Q_m$ 的每碱基序列质量：若 $Q_m \\ge 28$ 则通过，若 $23 \\le Q_m  28$ 则警告，若 $Q_m  23$ 则失败。\n- 每序列GC含量偏差 $|g - g_0|$，其中 $g$ 是观测到的GC比例，$g_0$ 是期望的GC比例：若 $|g - g_0| \\le 0.05$ 则通过，若 $0.05  |g - g_0| \\le 0.10$ 则警告，若 $|g - g_0| > 0.10$ 则失败。\n- 使用重复率 $d$ 的序列重复水平：若 $d \\le 0.20$ 则通过，若 $0.20  d \\le 0.50$ 则警告，若 $d > 0.50$ 则失败。\n- 接头含量 $a$：若 $a \\le 0.01$ 则通过，若 $0.01  a \\le 0.05$ 则警告，若 $a > 0.05$ 则失败。\n- 过表达序列比例 $o$：若 $o \\le 0.01$ 则通过，若 $0.01  o \\le 0.10$ 则警告，若 $o > 0.10$ 则失败。\n- 每碱基N含量 $n_f$：若 $n_f \\le 0.01$ 则通过，若 $0.01  n_f \\le 0.03$ 则警告，若 $n_f > 0.03$ 则失败。\n\n将通过/警告/失败映射为整数代码如下：通过 $\\to +1$，警告 $\\to 0$，失败 $\\to -1$。模块顺序必须固定为：\n$[$每碱基序列质量, GC偏差, 重复, 接头, 过表达序列, N含量$]$。\n\n相对于每个数据集在相同原始覆盖度下具有理想QC的基线来定义灵敏度损失：对于基线，设置 $Q_m^{\\mathrm{base}} = 35$, $m^{\\mathrm{base}} = 1$, $d^{\\mathrm{base}} = 0$, $a^{\\mathrm{base}} = 0$, $o^{\\mathrm{base}} = 0$, $n_f^{\\mathrm{base}} = 0$，并计算 $n_{\\mathrm{base}} = \\lfloor C_{\\text{raw}} \\rfloor$。使用 $e_{\\mathrm{base}} = 10^{-Q_m^{\\mathrm{base}}/10}$以及相同的 $\\alpha$ 和 $f$ 来计算 $S_{\\mathrm{base}}$。灵敏度损失为 $L = S_{\\mathrm{base}} - S$，必须以 $[0,1]$ 范围的小数形式报告。\n\n每个数据集的输入包含以下参数，均为无量纲，并在适用时以小数形式提供：\n- 读长 $L$ (碱基) [仅用于报告一致性，不用于计算]，\n- 原始覆盖度 $C_{\\text{raw}}$，\n- 平均Phred质量分数 $Q_m$，\n- 比对率 $m$，\n- 重复率 $d$，\n- 接头污染比例 $a$，\n- 过表达序列比例 $o$，\n- 每碱基N比例 $n_f$，\n- 观测GC比例 $g$，\n- 期望GC比例 $g_0$。\n\n使用以下数据集测试套件，每个数据集指定为一个元组 $(L, C_{\\text{raw}}, Q_m, m, d, a, o, n_f, g, g_0)$，所有数值均以小数形式写入：\n- 测试用例 1: $(150, 30, 32, 0.97, 0.12, 0.008, 0.006, 0.004, 0.41, 0.41)$。\n- 测试用例 2: $(100, 20, 25, 0.95, 0.35, 0.02, 0.03, 0.015, 0.36, 0.41)$。\n- 测试用例 3: $(150, 40, 20, 0.70, 0.70, 0.10, 0.15, 0.04, 0.50, 0.41)$。\n- 测试用例 4: $(75, 10, 30, 0.20, 0.50, 0.02, 0.01, 0.01, 0.41, 0.41)$。\n\n您的程序必须为每个测试用例计算：\n- 上述固定顺序的模块状态码向量，\n- 失败模块的整数计数（等于 $-1$ 的条目数量），\n- 灵敏度损失 $L$，以浮点数形式表示。\n\n最终输出格式：\n您的程序应生成单行输出，包含一个长度为 $4$ 的列表，其中每个元素对应一个测试用例，并且本身是一个形式为 $[$status\\_codes, fail\\_count, loss$]$ 的列表。$status\\_codes$ 必须是一个包含 $6$ 个整数的列表，顺序为固定的模块顺序。例如，整体结构必须如下所示\n$[[[s_{11},\\dots,s_{16}], f_1, \\ell_1], [[s_{21},\\dots,s_{26}], f_2, \\ell_2], [[s_{31},\\dots,s_{36}], f_3, \\ell_3], [[s_{41},\\dots,s_{46}], f_4, \\ell_4]]$,\n其中 $s_{ij} \\in \\{-1,0,1\\}$，$f_i$ 是一个整数，$\\ell_i$ 是一个 $[0,1]$ 范围的小数。请严格按照这种单行格式打印列表，使用逗号分隔值，并使用方括号表示列表。",
            "solution": "我们构建了一个有原则的解决方案，其基础是Phred质量的定义和使用二项分布的假设检验。其目的是将可观测的质量控制 (QC) 指标转换为一个有效覆盖度模型，然后量化不完美的QC对单核苷酸变异 (SNV) 检测灵敏度的影响。\n\n首先，我们使用Phred质量定义。Phred分数 $Q$ 和错误概率 $e$ 遵循 $Q = -10 \\log_{10}(e)$，所以 $e = 10^{-Q/10}$。对于一个平均Phred质量为 $Q_m$ 的数据集，我们将每碱基错误概率建模为 $e = 10^{-Q_m/10}$。这是测序技术中一个经过充分检验的关系。\n\n第二，我们将有效覆盖度 $n$ 计算为原始覆盖度与来自比对、重复、接头污染、过表达序列和模糊碱基的乘法惩罚项的乘积。设 $C_{\\text{raw}}$ 为名义覆盖度。有效覆盖度为\n$$\nn = \\left\\lfloor C_{\\text{raw}} \\cdot m \\cdot (1 - d) \\cdot (1 - a) \\cdot (1 - n_f) \\cdot (1 - o) \\right\\rfloor.\n$$\n这个公式基于以下原理：\n- 只有一部分比例为 $m$ 的读段能比对到参考基因组上并对覆盖度做出贡献。\n- 重复率 $d$ 表示非独立读段的比例；因此，因子 $(1-d)$ 保留了唯一的观测值。\n- 接头污染 $a$ 通常导致碱基被修剪或变为不可用；我们通过 $(1-a)$ 进行惩罚。\n- 每碱基N比例 $n_f$ 表示无法为SNV检测提供信息的模糊检出；我们通过 $(1-n_f)$ 进行惩罚。\n- 过表达序列 $o$ 通常反映了污染或技术伪影；我们通过 $(1-o)$ 进行惩罚。\n我们应用向下取整函数 $\\lfloor \\cdot \\rfloor$ 将 $n$ 定义为独立伯努利试验的非负整数计数。\n\n第三，我们使用关于二项分布的假设检验来形式化变异检测的决策规则。在原假设 $H_0$（无真实变异）下，任何备择观测都源于测序错误。如果错误概率为 $e$，并假设错误在三个非参考碱基中均匀分布，则观测到特定预定备择等位基因的概率为\n$$\np_0 = \\frac{e}{3}.\n$$\n我们设置每个位点的严格假阳性预算为 $\\alpha = 10^{-6}$。检测阈值 $t$ 是满足\n$$\n\\Pr\\!\\left[X \\ge t \\mid X \\sim \\mathrm{Binomial}(n, p_0)\\right] \\le \\alpha.\n$$\n的最小整数。\n如果这样的 $t$ 超过 $n$（即，没有 $t \\le n$ 满足该不等式），则在给定的 $n$ 和 $e$ 下无法进行检出，我们将灵敏度设为 $0$。\n\n在备择假设 $H_1$（真实杂合变异，等位基因频率 $f = 0.5$）下，一个读段支持特定备择等位基因，原因要么是它来自备择染色体并被正确检出，要么是它来自参考染色体但被错误地检出为特定备择等位基因。因此，\n$$\np_1 = f \\cdot (1 - e) + (1 - f) \\cdot \\frac{e}{3}.\n$$\n灵敏度（统计功效）则为\n$$\nS = \\Pr\\!\\left[X \\ge t \\mid X \\sim \\mathrm{Binomial}(n, p_1)\\right].\n$$\n该表达式等于参数为 $(n, p_1)$ 的二项分布在 $t-1$ 处的生存函数。\n\n第四，为了量化归因于QC的灵敏度损失，我们定义一个每个数据集的基线，该基线固定原始覆盖度，但移除了QC惩罚并使用高质量。对于基线，设 $Q_m^{\\mathrm{base}} = 35$（因此 $e_{\\mathrm{base}} = 10^{-3.5}$），$m^{\\mathrm{base}} = 1$, $d^{\\mathrm{base}} = 0$, $a^{\\mathrm{base}} = 0$, $o^{\\mathrm{base}} = 0$, $n_f^{\\mathrm{base}} = 0$，以及\n$$\nn_{\\mathrm{base}} = \\left\\lfloor C_{\\text{raw}} \\right\\rfloor.\n$$\n我们类似地使用 $p_0^{\\mathrm{base}} = e_{\\mathrm{base}}/3$ 和 $\\alpha$ 计算基线阈值 $t_{\\mathrm{base}}$，并使用 $p_1^{\\mathrm{base}} = f \\cdot (1 - e_{\\mathrm{base}}) + (1 - f) \\cdot e_{\\mathrm{base}}/3$ 计算基线灵敏度 $S_{\\mathrm{base}}$。灵敏度损失为\n$$\nL = S_{\\mathrm{base}} - S.\n$$\n\n第五，我们使用阈值将QC映射到FastQC风格的模块状态：\n- 每碱基序列质量 $Q_m$：若 $Q_m \\ge 28$ 则通过，若 $23 \\le Q_m  28$ 则警告，若 $Q_m  23$ 则失败。\n- 每序列GC含量偏差 $|g - g_0|$：若 $\\le 0.05$ 则通过，若 $\\in (0.05, 0.10]$ 则警告，若 $ 0.10$ 则失败。\n- 序列重复水平 $d$：若 $\\le 0.20$ 则通过，若 $\\in (0.20, 0.50]$ 则警告，若 $ 0.50$ 则失败。\n- 接头含量 $a$：若 $\\le 0.01$ 则通过，若 $\\in (0.01, 0.05]$ 则警告，若 $ 0.05$ 则失败。\n- 过表达序列 $o$：若 $\\le 0.01$ 则通过，若 $\\in (0.01, 0.10]$ 则警告，若 $ 0.10$ 则失败。\n- 每碱基N含量 $n_f$：若 $\\le 0.01$ 则通过，若 $\\in (0.01, 0.03]$ 则警告，若 $ 0.03$ 则失败。\n\n我们将通过映射到 $+1$，警告映射到 $0$，失败映射到 $-1$，并通过计算六个模块中状态为 $-1$ 的数量来计算失败总数。\n\n算法设计：\n- 对每个数据集，计算 $e = 10^{-Q_m/10}$，然后通过乘法惩罚和向下取整计算 $n$。计算 $p_0 = e/3$ 并找到二项式尾部概率 $\\le \\alpha$ 的最小阈值 $t$。如果 $t > n$，则设 $S = 0$；否则计算 $p_1$ 和 $S$，其中 $S$ 是在 $t-1$ 处的二项分布生存函数。\n- 类似地计算基线值 $e_{\\mathrm{base}}$, $n_{\\mathrm{base}}$, $p_0^{\\mathrm{base}}$, $t_{\\mathrm{base}}$, $p_1^{\\mathrm{base}}$ 和 $S_{\\mathrm{base}}$。\n- 输出 $L = S_{\\mathrm{base}} - S$ 以及模块状态向量和失败计数。\n- 测试套件由四个指定的数据集组成，每个数据集的 $(L, C_{\\text{raw}}, Q_m, m, d, a, o, n_f, g, g_0)$ 由以下给出：\n  - $(150, 30, 32, 0.97, 0.12, 0.008, 0.006, 0.004, 0.41, 0.41)$,\n  - $(100, 20, 25, 0.95, 0.35, 0.02, 0.03, 0.015, 0.36, 0.41)$,\n  - $(150, 40, 20, 0.70, 0.70, 0.10, 0.15, 0.04, 0.50, 0.41)$,\n  - $(75, 10, 30, 0.20, 0.50, 0.02, 0.01, 0.01, 0.41, 0.41)$.\n这些涵盖了高质量案例、有边界警告但无失败的案例、严重失败的案例以及低有效覆盖度的案例。\n\n程序计算所要求的输出，并以指定的嵌套列表格式打印单行：\n$[[[s_{11},\\dots,s_{16}], f_1, \\ell_1], [[s_{21},\\dots,s_{26}], f_2, \\ell_2], [[s_{31},\\dots,s_{36}], f_3, \\ell_3], [[s_{41},\\dots,s_{46}], f_4, \\ell_4]]$,\n其中 $s_{ij} \\in \\{-1,0,1\\}$，$f_i$ 为整数，$\\ell_i \\in [0,1]$ 为小数（非百分比）。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom math import floor\nfrom scipy.stats import binom\n\n# Fixed parameters for the detection model\nALPHA = 1e-6  # per-site false positive tail probability\nF = 0.5       # heterozygous allele fraction\nQ_BASE = 35.0 # baseline mean Phred quality\n\n# Module thresholds and order:\n# [Per-base quality, GC deviation, Duplication, Adapter, Overrepresented, N content]\ndef classify_modules(Qm, g, g0, d, a, o, nf):\n    statuses = []\n    # Per-base sequence quality\n    if Qm >= 28:\n        statuses.append(1)\n    elif Qm >= 23:\n        statuses.append(0)\n    else:\n        statuses.append(-1)\n    # GC deviation\n    gc_dev = abs(g - g0)\n    if gc_dev = 0.05:\n        statuses.append(1)\n    elif gc_dev = 0.10:\n        statuses.append(0)\n    else:\n        statuses.append(-1)\n    # Duplication\n    if d = 0.20:\n        statuses.append(1)\n    elif d = 0.50:\n        statuses.append(0)\n    else:\n        statuses.append(-1)\n    # Adapter\n    if a = 0.01:\n        statuses.append(1)\n    elif a = 0.05:\n        statuses.append(0)\n    else:\n        statuses.append(-1)\n    # Overrepresented sequences\n    if o = 0.01:\n        statuses.append(1)\n    elif o = 0.10:\n        statuses.append(0)\n    else:\n        statuses.append(-1)\n    # N content\n    if nf = 0.01:\n        statuses.append(1)\n    elif nf = 0.03:\n        statuses.append(0)\n    else:\n        statuses.append(-1)\n    return statuses\n\ndef phred_to_error(Q):\n    # e = 10^{-Q/10}\n    return 10.0 ** (-Q / 10.0)\n\ndef effective_coverage(C_raw, m, d, a, o, nf):\n    eff = C_raw * m * (1.0 - d) * (1.0 - a) * (1.0 - nf) * (1.0 - o)\n    n = int(np.floor(eff)) if eff > 0 else 0\n    return max(n, 0)\n\ndef find_threshold(n, p0, alpha):\n    # Find the smallest integer t such that P[X >= t | Bin(n, p0)] = alpha\n    # We scan from t=0 to n+1; at t=n+1, the tail prob is 0 by definition.\n    # Use survival function for numerical stability.\n    for t in range(0, n + 2):\n        tail = binom.sf(t - 1, n, p0)  # P[X >= t]\n        if tail = alpha:\n            return t\n    # Should never reach here due to n+1 guard\n    return n + 1\n\ndef sensitivity_at_params(n, Qm, alpha, f):\n    # Compute sensitivity given effective coverage n and mean Phred Qm\n    if n = 0:\n        return 0.0\n    e = phred_to_error(Qm)\n    p0 = e / 3.0\n    t = find_threshold(n, p0, alpha)\n    if t > n:\n        return 0.0\n    p1 = f * (1.0 - e) + (1.0 - f) * (e / 3.0)\n    # Sensitivity = P[X >= t | Bin(n, p1)] = sf(t-1)\n    S = float(binom.sf(t - 1, n, p1))\n    # Clip to [0,1] to avoid minor numerical issues\n    if S  0.0:\n        S = 0.0\n    elif S > 1.0:\n        S = 1.0\n    return S\n\ndef compute_loss(C_raw, Qm, m, d, a, o, nf):\n    # Current dataset sensitivity\n    n_eff = effective_coverage(C_raw, m, d, a, o, nf)\n    S_curr = sensitivity_at_params(n_eff, Qm, ALPHA, F)\n    # Baseline sensitivity\n    n_base = int(np.floor(C_raw)) if C_raw > 0 else 0\n    S_base = sensitivity_at_params(n_base, Q_BASE, ALPHA, F)\n    loss = S_base - S_curr\n    # Clip for safety\n    if loss  0.0:\n        loss = 0.0\n    if loss > 1.0:\n        loss = 1.0\n    return loss\n\ndef solve():\n    # Define the test cases from the problem statement.\n    # Each test case: (L, C_raw, Qm, m, d, a, o, nf, g, g0)\n    test_cases = [\n        (150, 30.0, 32.0, 0.97, 0.12, 0.008, 0.006, 0.004, 0.41, 0.41),\n        (100, 20.0, 25.0, 0.95, 0.35, 0.02, 0.03, 0.015, 0.36, 0.41),\n        (150, 40.0, 20.0, 0.70, 0.70, 0.10, 0.15, 0.04, 0.50, 0.41),\n        (75,  10.0, 30.0, 0.20, 0.50, 0.02, 0.01, 0.01, 0.41, 0.41),\n    ]\n\n    results = []\n    for case in test_cases:\n        L, C_raw, Qm, m, d, a, o, nf, g, g0 = case\n        status_codes = classify_modules(Qm, g, g0, d, a, o, nf)\n        fail_count = sum(1 for s in status_codes if s == -1)\n        loss = compute_loss(C_raw, Qm, m, d, a, o, nf)\n        # Round loss moderately for stable display\n        loss_rounded = float(np.round(loss, 6))\n        results.append([status_codes, fail_count, loss_rounded])\n\n    # Final print statement in the exact required format.\n    # Ensure no extra spaces for compact single-line output\n    def list_to_str(obj):\n        if isinstance(obj, list):\n            return \"[\" + \",\".join(list_to_str(x) for x in obj) + \"]\"\n        elif isinstance(obj, float):\n            # Use repr-like but controlled: avoid scientific for small numbers if possible\n            s = f\"{obj:.6f}\"\n            # Strip trailing zeros and possible trailing dot\n            s = s.rstrip('0').rstrip('.') if '.' in s else s\n            if s == \"\":\n                s = \"0\"\n            return s\n        else:\n            return str(obj)\n\n    print(list_to_str(results))\n\nif __name__ == \"__main__\":\n    solve()\n```"
        },
        {
            "introduction": "当开发新的临床检测方法或比较来自不同实验室的数据时，评估测量方法之间的一致性至关重要。本练习将指导您应用两种临床化学领域的金标准技术——Passing-Bablok回归和Bland-Altman分析——来评估两种检测方法之间是否存在系统性偏差（恒定误差和比例误差）和随机误差 。通过从头实现这些对异常值具有鲁棒性的非参数方法，您将深入理解如何严谨地验证和比较临床测量数据，这是确保数据可靠性和可比性的核心技能。",
            "id": "4552070",
            "problem": "给定来自同一批样本的两种临床检验的配对测量值。目标是使用稳健线性估计量和基于分布的一致性度量来评估方法比较和一致性。假设两种检验之间存在线性关系，表示为 $y = a + b x$，其中 $x$ 表示检验方法X的测量值，$y$ 表示检验方法Y的测量值。您必须实现一个非参数稳健回归来估计固定偏倚 $a$ 和比例误差 $b$，且需满足以下约束条件：该估计量必须在单调变换下保持不变，并且必须依赖于顺序统计量而非参数化的分布假设。此外，您必须使用差值框架实现一个基于分布的一致性评估，计算差值均值和一致性界限（LoA），对于差值 $d_i = y_i - x_i$，其定义为区间 $[\\overline{d} - 1.96 s_d, \\overline{d} + 1.96 s_d]$，其中 $\\overline{d}$ 是差值的样本均值，$s_d$ 是差值的样本标准差。LoA应在与测量值相同的尺度上进行解释，并且必须计算为实数。\n\n用于推导和实现的基本原理和定义：\n- 线性模型 $y = a + b x$，其中 $a$ 和 $b$ 未知。\n- 基于中位数和顺序统计量的稳健估计原理，以减轻离群值的影响并避免依赖正态性假设。\n- 基于差值的一致性度量：对于配对数据 $(x_i,y_i)$，差值为 $d_i = y_i - x_i$，均值为 $\\overline{d} = \\frac{1}{n}\\sum_{i=1}^{n} d_i$，样本标准差为 $s_d = \\sqrt{\\frac{1}{n-1}\\sum_{i=1}^{n} (d_i - \\overline{d})^2}$。\n- 一致性界限（LoA）：$[\\overline{d} - 1.96 s_d, \\overline{d} + 1.96 s_d]$。\n\n您必须编写一个程序，针对每个测试用例，返回一个列表 $[b,a,\\overline{d},\\text{LoA}_{\\text{low}},\\text{LoA}_{\\text{high}}]$，其中 $b$ 和 $a$ 是线性关系 $y = a + b x$ 的稳健斜率和截距估计值，$\\overline{d}$ 是差值均值，$\\text{LoA}_{\\text{low}}$ 和 $\\text{LoA}_{\\text{high}}$ 是一致性界限的下限和上限。所有量均被视为无量纲的数值；不涉及物理单位。一致性界限的计算需使用常数 $1.96$，这反映了在假设差值分布近似对称的情况下双侧覆盖的范围。\n\n测试套件：\n- 案例1（一般情况；中等比例误差和小偏倚）：\n  $x = [\\,8,12,18,25,35,48,60,72,85,100\\,]$ 和\n  $y = [\\,0.98*8 + 1.7 + 0.3,\\;0.98*12 + 1.7 - 0.4,\\;0.98*18 + 1.7 + 0.2,\\;0.98*25 + 1.7 - 0.1,\\;0.98*35 + 1.7 + 0.5,\\;0.98*48 + 1.7 - 0.2,\\;0.98*60 + 1.7 + 0.1,\\;0.98*72 + 1.7 + 0.0,\\;0.98*85 + 1.7 - 0.3,\\;0.98*100 + 1.7 + 0.4\\,]$。\n- 案例2（边界情况，存在重复的 $x$ 值；测试对分母为零的数据对的处理）：\n  $x = [\\,50,50,60,60,60,80,80,80,90,110\\,]$ 和\n  $y = [\\,1.05*50 - 3 + 1.0,\\;1.05*50 - 3 - 2.0,\\;1.05*60 - 3 + 0.5,\\;1.05*60 - 3 - 1.5,\\;1.05*60 - 3 + 0.4,\\;1.05*80 - 3 + 1.2,\\;1.05*80 - 3 - 0.8,\\;1.05*80 - 3 + 0.3,\\;1.05*90 - 3 + 0.0,\\;1.05*110 - 3 - 0.6\\,]$。\n- 案例3（存在离群值；测试稳健性）：\n  $x = [\\,5,15,25,35,45,55,65,75,85,95\\,]$ 和\n  $y = [\\,1.2*5 - 4 + 0.2,\\;1.2*15 - 4 - 0.1,\\;1.2*25 - 4 + 0.3,\\;1.2*35 - 4 + 15.0,\\;1.2*45 - 4 - 0.5,\\;1.2*55 - 4 + 0.0,\\;1.2*65 - 4 + 0.4,\\;1.2*75 - 4 - 12.0,\\;1.2*85 - 4 + 0.1,\\;1.2*95 - 4 - 0.2\\,]$。\n- 案例4（接近一致；微小的随机偏差）：\n  $x = [\\,10,20,30,40,50,60,70,80,90,100\\,]$ 和\n  $y = [\\,10 + 0.05,\\;20 - 0.02,\\;30 + 0.03,\\;40 + 0.01,\\;50 - 0.04,\\;60 + 0.02,\\;70 - 0.03,\\;80 + 0.00,\\;90 + 0.04,\\;100 - 0.01\\,]$。\n\n您的程序必须：\n- 基于点之间的成对关系派生出的顺序统计量，实现 $a$ 和 $b$ 的稳健估计，并在 $x_j = x_i$ 时避免分母为零的计算。\n- 使用差值 $d_i = y_i - x_i$ 实现一致性界限的计算，计算 $\\overline{d}$ 和 $s_d$，然后计算 $\\overline{d} \\pm 1.96 s_d$。\n- 对每个测试用例，以实数形式生成列表 $[b,a,\\overline{d},\\text{LoA}_{\\text{low}},\\text{LoA}_{\\text{high}}]$。\n\n最终输出格式：\n您的程序应生成单行输出，其中包含一个以方括号括起来的逗号分隔列表形式的结果，每个项目是对应一个测试用例的列表。例如，输出必须是 $[[b_1,a_1,\\overline{d}_1,\\text{LoA}_{\\text{low},1},\\text{LoA}_{\\text{high},1}],[b_2,a_2,\\overline{d}_2,\\text{LoA}_{\\text{low},2},\\text{LoA}_{\\text{high},2}],\\ldots]$ 的形式，不含任何额外文本。",
            "solution": "该问题要求实现一种用于比较两种临床检验的统计方法。这包括两个主要部分：首先，一个稳健线性回归模型来描述两种方法之间的关系；其次，一个一致性分析来量化它们测量值之间的差异。解决方案将基于生物统计学和临床化学领域中符合问题规范的标准、成熟技术进行推导和实现。\n\n### 问题验证\n问题陈述已经过验证，被认为是合理、定义明确且具有科学依据的。它指定了一个线性模型 $y = a + b x$ 来关联两种检验方法 $X$ 和 $Y$ 的测量值。它要求使用一种基于顺序统计量的稳健、非参数回归技术来估计参数 $a$（固定偏倚）和 $b$（比例误差）。通过排除 $x_i = x_j$ 的情况来处理斜率计算的特定约束，结合其他要求，唯一地确定了所需的方法是Passing-Bablok回归。对于一致性分析，它指定了计算差值均值和一致性界限（LoA），这与Bland-Altman方法一致。数据和所需的输出格式都已明确定义。\n\n### 第1部分：使用Passing-Bablok估计量的稳健线性回归\n\nPassing-Bablok方法是一种用于拟合线性回归线的非参数过程，对离群值具有稳健性。它完全符合问题的要求。估计过程分两步进行：首先是斜率 $b$，然后是截距 $a$。\n\n**步骤1.1：斜率估计 ($\\hat{b}$)**\n\n给定 $n$ 个配对数据点 $(x_i, y_i)$，第一步是计算所有可能的成对斜率。对于任意两个不同的点 $i$ 和 $j$（$1 \\le i  j \\le n$），只要分母不为零，就可以计算一个斜率 $s_{ij}$。所有此类有效斜率的集合 $S$ 由下式给出：\n$$\nS = \\left\\{ s_{ij} = \\frac{y_j - y_i}{x_j - x_i} \\quad \\forall i  j \\text{ such that } x_i \\ne x_j \\right\\}\n$$\n问题明确指出，在计算斜率时应忽略 $x_i = x_j$ 的数据对，这是该方法的一个决定性特征。设 $N$ 是集合 $S$ 中元素的数量。斜率的稳健估计值 $\\hat{b}$ 是这组成对斜率的中位数：\n$$\n\\hat{b} = \\text{median}(S)\n$$\n选择中位数是因为其稳健性。对于一个已排序的包含 $N$ 个斜率的集合，如果 $N$ 是奇数，中位数是位于位置 $(N+1)/2$ 的值。如果 $N$ 是偶数，中位数通常是位于位置 $N/2$ 和 $N/2+1$ 的两个中心值的平均值。该估计量依赖于顺序统计量（中位数），并且不对数据或误差的分布做任何假设。\n\n**步骤1.2：截距估计 ($\\hat{a}$)**\n\n一旦获得斜率估计值 $\\hat{b}$，就可以估计截距 $a$。对于每个数据点 $(x_i, y_i)$，通过重新排列线性方程来计算一个候选截距 $c_i$：\n$$\nc_i = y_i - \\hat{b} x_i\n$$\n这会产生一个包含 $n$ 个候选截距的集合 $\\{c_1, c_2, \\ldots, c_n\\}$。截距的稳健估计值 $\\hat{a}$ 是该集合的中位数：\n$$\n\\hat{a} = \\text{median}(\\{c_1, c_2, \\ldots, c_n\\})\n$$\n这个两步过程得出了稳健回归线 $\\hat{y} = \\hat{a} + \\hat{b} x$。\n\n### 第2部分：使用Bland-Altman方法进行一致性分析\n\n回归分析描述了两种方法之间的系统关系，而一致性分析则量化了它们之间的随机差异。Bland-Altman方法是完成此项任务的标准方法。\n\n**步骤2.1：计算差值 ($d_i$)**\n\n基本量是配对测量值之间的差值：\n$$\nd_i = y_i - x_i\n$$\n这代表了第 $i$ 个样本的误差或不一致性。\n\n**步骤2.2：差值的均值和标准差**\n\n这些差值的平均值 $\\overline{d}$ 代表了两种检验之间的平均偏倚。接近 $0$ 的 $\\overline{d}$ 值表示系统性偏倚较低。其计算公式为：\n$$\n\\overline{d} = \\frac{1}{n} \\sum_{i=1}^{n} d_i\n$$\n差值围绕其均值的离散程度由样本标准差 $s_d$ 来量化。问题提供了无偏样本标准差的公式，即除以 $n-1$：\n$$\ns_d = \\sqrt{\\frac{1}{n-1} \\sum_{i=1}^{n} (d_i - \\overline{d})^2}\n$$\n\n**步骤2.3：一致性界限（LoA）**\n\n一致性界限定义了一个范围，预计两种方法之间的大多数差异都将落入此范围内。假设差异近似呈正态分布，该范围通常是一个 $95\\%$ 的预测区间。问题指定使用常数 $1.96$，这对应于标准正态分布中适当的z-score（$z_{0.025}$）。\n\n一致性界限的下限和上限计算如下：\n$$\n\\text{LoA}_{\\text{low}} = \\overline{d} - 1.96 s_d\n$$\n$$\n\\text{LoA}_{\\text{high}} = \\overline{d} + 1.96 s_d\n$$\n这两个值与差值均值 $\\overline{d}$ 一起，为两种检验之间的一致性提供了完整的摘要。\n\n### 计算总结\n对于每个测试用例，程序将执行这些步骤来计算五个所需的值：稳健斜率 $\\hat{b}$、稳健截距 $\\hat{a}$、差值均值 $\\overline{d}$、一致性界限下限 $\\text{LoA}_{\\text{low}}$ 和一致性界限上限 $\\text{LoA}_{\\text{high}}$。这些值将以列表 $[\\hat{b}, \\hat{a}, \\overline{d}, \\text{LoA}_{\\text{low}}, \\text{LoA}_{\\text{high}}]$ 的形式返回。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the method comparison problem for all test cases.\n    Implements Passing-Bablok regression and Bland-Altman analysis.\n    \"\"\"\n    \n    # Define the test cases from the problem statement.\n    test_cases = [\n        # Case 1 (general case; moderate proportional error and small bias)\n        (\n            np.array([8, 12, 18, 25, 35, 48, 60, 72, 85, 100], dtype=float),\n            np.array([9.84, 13.06, 19.54, 26.1, 36.5, 48.54, 60.6, 72.26, 84.7, 100.1], dtype=float)\n        ),\n        # Case 2 (boundary with repeated x values; tests handling of zero-denominator pairs)\n        (\n            np.array([50, 50, 60, 60, 60, 80, 80, 80, 90, 110], dtype=float),\n            np.array([50.5, 47.5, 60.5, 58.5, 60.4, 82.2, 80.2, 81.3, 91.5, 111.9], dtype=float)\n        ),\n        # Case 3 (outliers present; tests robustness)\n        (\n            np.array([5, 15, 25, 35, 45, 55, 65, 75, 85, 95], dtype=float),\n            np.array([2.2, 13.9, 26.3, 53.0, 49.5, 62.0, 74.4, 74.0, 98.1, 109.8], dtype=float)\n        ),\n        # Case 4 (near-agreement; small random deviations)\n        (\n            np.array([10, 20, 30, 40, 50, 60, 70, 80, 90, 100], dtype=float),\n            np.array([10.05, 19.98, 30.03, 40.01, 49.96, 60.02, 69.97, 80.00, 90.04, 99.99], dtype=float)\n        )\n    ]\n\n    results = []\n    \n    for x, y in test_cases:\n        # Part 1: Passing-Bablok Regression for b and a\n        \n        # Step 1.1: Estimate slope b\n        n = len(x)\n        slopes = []\n        for i in range(n):\n            for j in range(i + 1, n):\n                if x[j] - x[i] != 0:\n                    slope_ij = (y[j] - y[i]) / (x[j] - x[i])\n                    slopes.append(slope_ij)\n        \n        b = np.median(slopes)\n        \n        # Step 1.2: Estimate intercept a\n        intercept_residuals = y - b * x\n        a = np.median(intercept_residuals)\n        \n        # Part 2: Bland-Altman Analysis for agreement\n        \n        # Step 2.1: Calculate differences\n        differences = y - x\n        \n        # Step 2.2: Calculate mean and std dev of differences\n        mean_diff = np.mean(differences)\n        # ddof=1 for sample standard deviation (division by n-1)\n        std_diff = np.std(differences, ddof=1)\n        \n        # Step 2.3: Calculate Limits of Agreement (LoA)\n        loa_low = mean_diff - 1.96 * std_diff\n        loa_high = mean_diff + 1.96 * std_diff\n        \n        # Compile results for the current test case\n        case_result = [b, a, mean_diff, loa_low, loa_high]\n        results.append(case_result)\n\n    # Final print statement in the exact required format.\n    # The default str() representation for a list is '[item1, item2, ...]', which is what's needed.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "在处理电子健康记录（EHR）等真实世界的临床数据时，一个核心挑战是识别指向同一患者的多个分散、含有噪音的记录，即实体解析。这项实践提供了一个完整的端到端项目，您将从头构建一个实体解析工作流，包括为提高效率而设计的“分块”策略、基于编辑距离的相似度评分、以及利用图论进行传递闭包聚类 。通过计算精确率、召回率以及合并与拆分错误，您不仅能掌握解决这一复杂数据质量问题的实用技术，还能学会如何全面评估和优化您的解析算法。",
            "id": "4551876",
            "problem": "考虑一个用于电子健康记录 (EHR) 中患者记录的实体解析工作流，其中每条记录可能包含含噪声的标识符。其目标是算法性地确定哪些记录指向同一个真实世界的患者（实体），通过成对链接的传递闭包构建预测簇，然后使用信息检索和集合论的标准定义（包括合并与分裂的误差分析）来评估数据质量。解决方案必须从第一性原理推导，并实现为一个完整的、可运行的程序。\n\n您将获得以下基础概念：\n- 实体概念，即指向同一真实世界患者的记录的等价类，表示为记录集的划分。\n- 基于集合论定义的成对评估。给定一个预测簇的集合，定义包含在同一预测簇内的无序记录对集合。类似地，定义包含在同一真实簇内的无序记录对集合。\n- 信息检索中广泛接受的精确率和召回率的定义。精确率等于预测为正的实例中真阳性的比例。召回率等于被正确预测的真阳性实例的比例。\n\n您必须实现以下工作流和计算，不得依赖预打包的实体解析例程：\n1. 记录表示：每条记录包含 \"id\"、\"name\"、\"dob\"（出生日期，格式为 \"YYYY-MM-DD\"）和 \"zip\"（邮政编码）字段。\n2. 分块：分块函数 $b$ 通过将具有相同（姓氏首字母，出生年份）对的记录分组来减少候选空间。形式上，对于记录 $r$，令 $b(r) = (L(r), Y(r))$，其中 $L(r)$ 是 \"name\" 字段最后一个词的首字母（大写），$Y(r)$ 是 \"dob\" 字段的前四个字符。\n3. 字符串规范化：在计算相似度之前，将 \"name\" 字段映射为大写并移除所有非字母字符。\n4. 编辑距离：对于两个规范化的字符串 $a$ 和 $b$，将 Levenshtein 编辑距离 $d(a,b)$ 定义为将 $a$ 转换为 $b$ 所需的最小单字符插入、删除或替换次数。$d(a,b)$ 的动态规划递推式是基于编辑距离拥有最优子结构这一基本原则构建的。定义名称相似度\n$$\ns_{\\text{name}}(a,b) = \n\\begin{cases}\n1 - \\dfrac{d(a,b)}{\\max(|a|,|b|)},  \\text{if } \\max(|a|,|b|) > 0,\\\\\n1,  \\text{otherwise.}\n\\end{cases}\n$$\n5. 属性相似度：如果 \"dob\" 字符串完全相等，则定义 $s_{\\text{dob}}(r_i,r_j) = 1$，否则为 $0$。如果 \"zip\" 字符串完全相等，则定义 $s_{\\text{zip}}(r_i,r_j) = 1$；如果 \"zip\" 字符串的前三个字符相等且字符串长度至少为三，则 $s_{\\text{zip}}(r_i,r_j) = 0.5$；否则，$s_{\\text{zip}}(r_i,r_j) = 0$。\n6. 加权分数：对于同一分块内的候选对 $(r_i,r_j)$，计算加权分数\n$$\nS(r_i,r_j) = w_{\\text{name}} \\cdot s_{\\text{name}}(r_i,r_j) + w_{\\text{dob}} \\cdot s_{\\text{dob}}(r_i,r_j) + w_{\\text{zip}} \\cdot s_{\\text{zip}}(r_i,r_j),\n$$\n其中非负权重 $w_{\\text{name}}, w_{\\text{dob}}, w_{\\text{zip}}$ 的和为 $1$。\n7. 边构建与聚类：如果 $S(r_i,r_j) \\ge T$（其中 $T$ 是指定的阈值），则在 $r_i$ 和 $r_j$ 之间创建一条无向链接。预测簇是这个基于记录的无向图的连通分量。\n8. 成对度量：设 $P$ 为位于同一预测簇内的无序记录对集合，设 $G$ 为位于同一真实簇内的无序记录对集合。定义\n$$\n\\text{TP} = |P \\cap G|,\\quad \\text{FP} = |P \\setminus G|,\\quad \\text{FN} = |G \\setminus P|.\n$$\n精确率定义为\n$$\n\\text{precision} =\n\\begin{cases}\n\\dfrac{\\text{TP}}{\\text{TP} + \\text{FP}},  \\text{if } \\text{TP} + \\text{FP} > 0,\\\\\n1,  \\text{if } \\text{TP} + \\text{FP} = 0,\n\\end{cases}\n$$\n召回率定义为\n$$\n\\text{recall} =\n\\begin{cases}\n\\dfrac{\\text{TP}}{\\text{TP} + \\text{FN}},  \\text{if } \\text{TP} + \\text{FN} > 0,\\\\\n1,  \\text{if } \\text{TP} + \\text{FN} = 0.\n\\end{cases}\n$$\n所有比率输出必须是小数，而不是百分比。\n9. 合并与分裂误差分析：对于每个预测簇 $C$，设 $m_C$ 为 $C$ 中记录所包含的不同真实实体标识符的数量。合并误差计数为\n$$\nM = \\sum_{C} \\max(0, m_C - 1).\n$$\n对于每个真实簇 $T$，设 $s_T$ 为包含 $T$ 成员的不同预测簇的数量。分裂误差计数为\n$$\nS_{\\text{split}} = \\sum_{T} \\max(0, s_T - 1).\n$$\n\n您必须实现上述工作流，并为以下每个测试用例计算精确率、召回率、$M$ 和 $S_{\\text{split}}$。请使用指定的权重和阈值。\n\n测试用例 1（理想情况，中度噪声，正确合并）：\n- 权重：$w_{\\text{name}} = 0.6$，$w_{\\text{dob}} = 0.3$，$w_{\\text{zip}} = 0.1$，阈值 $T = 0.85$。\n- 记录：\n  - $\\text{id}=$\"r1\", $\\text{name}=$\"John Smith\", $\\text{dob}=$\"1980-05-12\", $\\text{zip}=$\"02139\"\n  - $\\text{id}=$\"r2\", $\\text{name}=$\"JON SMITH\", $\\text{dob}=$\"1980-05-12\", $\\text{zip}=$\"02139\"\n  - $\\text{id}=$\"r3\", $\\text{name}=$\"Jane Doe\", $\\text{dob}=$\"1975-11-30\", $\\text{zip}=$\"02138\"\n  - $\\text{id}=$\"r4\", $\\text{name}=$\"Janet Doe\", $\\text{dob}=$\"1975-11-30\", $\\text{zip}=$\"02138\"\n  - $\\text{id}=$\"r5\", $\\text{name}=$\"Alice Johnson\", $\\text{dob}=$\"1990-02-01\", $\\text{zip}=$\"10001\"\n  - $\\text{id}=$\"r6\", $\\text{name}=$\"Alyce Johnson\", $\\text{dob}=$\"1990-02-01\", $\\text{zip}=$\"10001\"\n  - $\\text{id}=$\"r7\", $\\text{name}=$\"Bob Lee\", $\\text{dob}=$\"1980-05-12\", $\\text{zip}=$\"02139\"\n- 真实实体标识符：\n  - \"r1\" 和 \"r2\" 属于实体 \"t1\"。\n  - \"r3\" 和 \"r4\" 属于实体 \"t2\"。\n  - \"r5\" 和 \"r6\" 属于实体 \"t3\"。\n  - \"r7\" 属于实体 \"t4\"。\n\n测试用例 2（边界情况，全部唯一，预期无合并）：\n- 权重：$w_{\\text{name}} = 0.6$，$w_{\\text{dob}} = 0.3$，$w_{\\text{zip}} = 0.1$，阈值 $T = 0.95$。\n- 记录：\n  - $\\text{id}=$\"s1\", $\\text{name}=$\"Michael Brown\", $\\text{dob}=$\"1965-07-19\", $\\text{zip}=$\"90210\"\n  - $\\text{id}=$\"s2\", $\\text{name}=$\"Michelle Brown\", $\\text{dob}=$\"1970-07-19\", $\\text{zip}=$\"90210\"\n  - $\\text{id}=$\"s3\", $\\text{name}=$\"Carlos Garcia\", $\\text{dob}=$\"1988-12-12\", $\\text{zip}=$\"33101\"\n  - $\\text{id}=$\"s4\", $\\text{name}=$\"Li Wang\", $\\text{dob}=$\"1993-03-03\", $\\text{zip}=$\"10002\"\n- 真实实体标识符：\n  - \"s1\", \"s2\", \"s3\", \"s4\" 各属于一个不同的实体。\n\n测试用例 3（边缘情况，重度噪声导致错误合并与分裂）：\n- 权重：$w_{\\text{name}} = 0.6$，$w_{\\text{dob}} = 0.3$，$w_{\\text{zip}} = 0.1$，阈值 $T = 0.7$。\n- 记录：\n  - $\\text{id}=$\"u1\", $\\text{name}=$\"Sara Connor\", $\\text{dob}=$\"1979-01-01\", $\\text{zip}=$\"94110\"\n  - $\\text{id}=$\"u2\", $\\text{name}=$\"Sarah Conner\", $\\text{dob}=$\"1979-01-01\", $\\text{zip}=$\"94110\"\n  - $\\text{id}=$\"u3\", $\\text{name}=$\"Sera Conor\", $\\text{dob}=$\"1980-01-01\", $\\text{zip}=$\"94110\"\n  - $\\text{id}=$\"u4\", $\\text{name}=$\"Sam Conor\", $\\text{dob}=$\"1979-01-01\", $\\text{zip}=$\"94110\"\n  - $\\text{id}=$\"u5\", $\\text{name}=$\"Tom Hanks\", $\\text{dob}=$\"1956-07-09\", $\\text{zip}=$\"94110\"\n  - $\\text{id}=$\"u6\", $\\text{name}=$\"Thomas Hank\", $\\text{dob}=$\"1956-07-09\", $\\text{zip}=$\"94110\"\n  - $\\text{id}=$\"u7\", $\\text{name}=$\"Sara Connor\", $\\text{dob}=$\"1979-01-02\", $\\text{zip}=$\"94110\"\n- 真实实体标识符：\n  - \"u1\", \"u2\", \"u3\" 属于实体 \"A\"。\n  - \"u4\" 属于实体 \"B\"。\n  - \"u5\", \"u6\" 属于实体 \"C\"。\n  - \"u7\" 属于实体 \"D\"。\n\n最终输出规范：\n- 对于按顺序列出的每个测试用例，输出一个四元列表 $[\\text{precision}, \\text{recall}, M, S_{\\text{split}}]$，其中 precision 和 recall 四舍五入到四位小数（作为小数，而不是百分比），$M$ 和 $S_{\\text{split}}$ 为整数。\n- 您的程序应生成一行输出，其中包含一个用方括号括起来的逗号分隔列表的结果，每个元素是对应测试用例的四元列表。例如，格式必须像 $[[p_1,r_1,M_1,S_1],[p_2,r_2,M_2,S_2],[p_3,r_3,M_3,S_3]]$ 在单一行上。",
            "solution": "电子健康记录 (EHR) 中的实体解析问题是确保数据质量和患者安全的一项关键任务。所提供的问题陈述概述了完成此任务的一个完整的、自包含的工作流，从初始记录处理到最终性能评估。该问题在科学上基于计算机科学、信息检索和数据管理等既定原则。该问题定义明确，所有必要的数据、参数和算法步骤都清晰界定，确保每个测试用例都存在唯一且可验证的解。因此，该问题被认为是有效的，下面将给出完整的解决方案。\n\n该解决方案是通过系统地实现问题陈述中指定的操作序列来构建的。\n\n**1. 基础数据表示与预处理**\n\n每条患者记录被视为一个结构化数据对象，包含 \"id\"、\"name\"、\"dob\" 和 \"zip\" 字段。真实情况被表示为记录的划分，其中划分的每个单元对应一个唯一的真实世界实体。\n\n**2. 为提高计算效率而分块**\n\n为避免计算成本高昂的全对比较（对于 $n$ 条记录，其复杂度为 $O(n^2)$），采用了分块策略。记录根据其属性派生的键被划分到不同的块中。指定的分块函数 $b(r) = (L(r), Y(r))$ 将共享相同姓氏首字母 $L(r)$ 和相同四位数出生年份 $Y(r)$ 的记录分组。所有后续的成对比较仅限于同一块内的记录，从而显著减小了搜索空间。\n\n**3. 字符串规范化与相似度度量**\n\n原始数据通常含有噪声。为了稳健地比较姓名，首先应用一个规范化函数。该函数将 \"name\" 字段转换为大写并移除所有非字母字符，确保比较不区分大小写且不受标点符号影响。\n\n规范化之后，为每个属性计算记录对 $(r_i, r_j)$ 之间的相似度分数：\n\n- **名称相似度 ($s_{\\text{name}}$)**：这基于 Levenshtein 编辑距离 $d(a,b)$，这是字符串比较中的一个基本度量，用于量化两个序列之间的差异。该距离使用动态规划算法计算，该算法依赖于最优子结构原理。对于两个规范化的姓名字符串 $a$ 和 $b$，基于矩阵的递推式为：\n$$\nD[i][j] = \\min\n\\begin{cases}\nD[i-1][j] + 1  \\text{(deletion)} \\\\\nD[i][j-1] + 1  \\text{(insertion)} \\\\\nD[i-1][j-1] + \\mathbf{1}_{a[i] \\neq b[j]}  \\text{(substitution)}\n\\end{cases}\n$$\n距离 $d(a,b)$ 是值 $D[|a|][|b|]$。然后将此距离归一化，以产生一个介于 $0$ 和 $1$ 之间的相似度分数：\n$$\ns_{\\text{name}}(a,b) = 1 - \\dfrac{d(a,b)}{\\max(|a|,|b|)}, \\text{ for } \\max(|a|,|b|) > 0\n$$\n如果两个字符串都为空，则 $s_{\\text{name}}=1$。\n\n- **出生日期相似度 ($s_{\\text{dob}}$)**：这是一个严格的二元比较。如果 \"dob\" 字符串相同，则 $s_{\\text{dob}}(r_i,r_j) = 1$，否则 $s_{\\text{dob}}(r_i,r_j) = 0$。\n\n- **邮政编码相似度 ($s_{\\text{zip}}$)**：此度量允许部分匹配，以反映地理上的邻近性。对于完全匹配，$s_{\\text{zip}}(r_i,r_j) = 1$；如果前三位数字匹配（对于长度至少为 $3$ 的邮政编码），则 $s_{\\text{zip}}(r_i,r_j) = 0.5$；否则 $s_{\\text{zip}}(r_i,r_j) = 0$。\n\n这些单独的相似度通过加权和组合成一个综合分数：\n$$\nS(r_i,r_j) = w_{\\text{name}} \\cdot s_{\\text{name}}(r_i,r_j) + w_{\\text{dob}} \\cdot s_{\\text{dob}}(r_i,r_j) + w_{\\text{zip}} \\cdot s_{\\text{zip}}(r_i,r_j)\n$$\n其中权重 $w_{\\text{name}}, w_{\\text{dob}}, w_{\\text{zip}}$ 为非负数且总和为 $1$。\n\n**4. 基于图的聚类**\n\n记录集被建模为一个无向图 $G=(V, E)$，其中顶点 $V$ 是记录。如果相似度分数 $S(r_i, r_j)$ 大于或等于指定的阈值 $T$，则在边集 $E$ 中添加一条边 $(r_i, r_j)$。此步骤将成对相似度转换为关系网络。\n\n然后通过查找该图的连通分量来确定预测的记录簇。连通分量是一个最大子图，其中任意两个顶点都通过一条路径相互连接。这内在地强制执行了传递闭包：如果记录 A 与 B 相关联，B 与 C 相关联，那么即使 A 和 C 没有直接比较或未达到相似度阈值，这三者也会被分到同一个实体中。使用标准的图遍历算法，如深度优先搜索（DFS）或广度优先搜索（BFS），来识别这些分量。\n\n**5. 从第一性原理进行性能评估**\n\n预测簇的质量使用两类度量标准对照真实情况进行评估。\n\n- **成对度量**：精确率和召回率改编自信息检索。其核心思想是评估所有被预测在同一簇中的无序记录对集合，与那些真正在同一簇中的记录对集合进行比较。\n    - 设 $G$ 为属于同一真实实体的无序记录对集合。$|G| = \\sum_{T \\in \\text{Truth}} \\binom{|T|}{2}$。\n    - 设 $P$ 为属于同一预测簇的无序记录对集合。$|P| = \\sum_{C \\in \\text{Predicted}} \\binom{|C|}{2}$。\n    - 真阳性 ($TP$): $|P \\cap G|$，即被正确识别的对数。\n    - 假阳性 ($FP$): $|P \\setminus G|$，即被错误链接的对数。\n    - 假阴性 ($FN$): $|G \\setminus P|$，即遗漏的真实对数。\n    - 精确率和召回率随后计算如下：\n    $$\n    \\text{precision} = \\frac{\\text{TP}}{\\text{TP} + \\text{FP}} = \\frac{|P \\cap G|}{|P|} \\quad \\text{and} \\quad \\text{recall} = \\frac{\\text{TP}}{\\text{TP} + \\text{FN}} = \\frac{|P \\cap G|}{|G|}\n    $$\n    按照规定，当分母为 $0$ 时，该度量定义为 $1$。\n\n- **簇级误差分析**：\n    - **合并误差 ($M$)**：这量化了多少个不同的真实实体被错误地合并到单个预测簇中。对于每个预测簇 $C$，我们计算其中所代表的不同真实实体的数量 $m_C$。总合并误差是超出 $1$ 的部分之和：$M = \\sum_{C} \\max(0, m_C - 1)$。\n    - **分裂误差 ($S_{\\text{split}}$)**：这量化了真实实体被分散到多个预测簇中的碎片化程度。对于每个真实实体 $T$，我们计算其成员散布在多少个不同的预测簇中，记为 $s_T$。总分裂误差是 $S_{\\text{split}} = \\sum_{T} \\max(0, s_T - 1)$。\n\n这些步骤构成了实体解析及评估的一套完整而严谨的方法论，通过编程实现以解决给定的测试用例。",
            "answer": "```python\nimport numpy as np\nfrom collections import defaultdict\nfrom itertools import combinations\n\ndef solve():\n    \"\"\"\n    Main function to run the entity resolution workflow for all test cases.\n    \"\"\"\n\n    test_cases = [\n        {\n            \"params\": {\"w_name\": 0.6, \"w_dob\": 0.3, \"w_zip\": 0.1, \"threshold\": 0.85},\n            \"records\": [\n                {\"id\": \"r1\", \"name\": \"John Smith\", \"dob\": \"1980-05-12\", \"zip\": \"02139\"},\n                {\"id\": \"r2\", \"name\": \"JON SMITH\", \"dob\": \"1980-05-12\", \"zip\": \"02139\"},\n                {\"id\": \"r3\", \"name\": \"Jane Doe\", \"dob\": \"1975-11-30\", \"zip\": \"02138\"},\n                {\"id\": \"r4\", \"name\": \"Janet Doe\", \"dob\": \"1975-11-30\", \"zip\": \"02138\"},\n                {\"id\": \"r5\", \"name\": \"Alice Johnson\", \"dob\": \"1990-02-01\", \"zip\": \"10001\"},\n                {\"id\": \"r6\", \"name\": \"Alyce Johnson\", \"dob\": \"1990-02-01\", \"zip\": \"10001\"},\n                {\"id\": \"r7\", \"name\": \"Bob Lee\", \"dob\": \"1980-05-12\", \"zip\": \"02139\"},\n            ],\n            \"ground_truth\": {\"t1\": [\"r1\", \"r2\"], \"t2\": [\"r3\", \"r4\"], \"t3\": [\"r5\", \"r6\"], \"t4\": [\"r7\"]},\n        },\n        {\n            \"params\": {\"w_name\": 0.6, \"w_dob\": 0.3, \"w_zip\": 0.1, \"threshold\": 0.95},\n            \"records\": [\n                {\"id\": \"s1\", \"name\": \"Michael Brown\", \"dob\": \"1965-07-19\", \"zip\": \"90210\"},\n                {\"id\": \"s2\", \"name\": \"Michelle Brown\", \"dob\": \"1970-07-19\", \"zip\": \"90210\"},\n                {\"id\": \"s3\", \"name\": \"Carlos Garcia\", \"dob\": \"1988-12-12\", \"zip\": \"33101\"},\n                {\"id\": \"s4\", \"name\": \"Li Wang\", \"dob\": \"1993-03-03\", \"zip\": \"10002\"},\n            ],\n            \"ground_truth\": {\"e1\": [\"s1\"], \"e2\": [\"s2\"], \"e3\": [\"s3\"], \"e4\": [\"s4\"]},\n        },\n        {\n            \"params\": {\"w_name\": 0.6, \"w_dob\": 0.3, \"w_zip\": 0.1, \"threshold\": 0.7},\n            \"records\": [\n                {\"id\": \"u1\", \"name\": \"Sara Connor\", \"dob\": \"1979-01-01\", \"zip\": \"94110\"},\n                {\"id\": \"u2\", \"name\": \"Sarah Conner\", \"dob\": \"1979-01-01\", \"zip\": \"94110\"},\n                {\"id\": \"u3\", \"name\": \"Sera Conor\", \"dob\": \"1980-01-01\", \"zip\": \"94110\"},\n                {\"id\": \"u4\", \"name\": \"Sam Conor\", \"dob\": \"1979-01-01\", \"zip\": \"94110\"},\n                {\"id\": \"u5\", \"name\": \"Tom Hanks\", \"dob\": \"1956-07-09\", \"zip\": \"94110\"},\n                {\"id\": \"u6\", \"name\": \"Thomas Hank\", \"dob\": \"1956-07-09\", \"zip\": \"94110\"},\n                {\"id\": \"u7\", \"name\": \"Sara Connor\", \"dob\": \"1979-01-02\", \"zip\": \"94110\"},\n            ],\n            \"ground_truth\": {\"A\": [\"u1\", \"u2\", \"u3\"], \"B\": [\"u4\"], \"C\": [\"u5\", \"u6\"], \"D\": [\"u7\"]},\n        },\n    ]\n\n    final_results = []\n    \n    for case in test_cases:\n        final_results.append(process_case(case))\n    \n    print(f\"[{','.join(map(str, final_results))}]\")\n\n\ndef normalize_name(name):\n    return \"\".join(filter(str.isalpha, name.upper()))\n\ndef levenshtein_distance(s1, s2):\n    m, n = len(s1), len(s2)\n    if m  n:\n        s1, s2 = s2, s1\n        m, n = n, m\n    \n    if n == 0:\n        return m\n    \n    dp = np.zeros((m + 1, n + 1), dtype=int)\n    for i in range(m + 1):\n        dp[i][0] = i\n    for j in range(n + 1):\n        dp[0][j] = j\n        \n    for i in range(1, m + 1):\n        for j in range(1, n + 1):\n            cost = 0 if s1[i-1] == s2[j-1] else 1\n            dp[i][j] = min(dp[i-1][j] + 1,        # Deletion\n                           dp[i][j-1] + 1,        # Insertion\n                           dp[i-1][j-1] + cost)   # Substitution\n    return dp[m, n]\n\ndef get_pairs_from_clusters(clusters):\n    pairs = set()\n    for cluster in clusters:\n        # Sort to make pairs canonical\n        sorted_cluster = sorted(list(cluster))\n        for r1, r2 in combinations(sorted_cluster, 2):\n            pairs.add((r1, r2))\n    return pairs\n\ndef find_connected_components(adj, nodes):\n    visited = set()\n    components = []\n    for node in nodes:\n        if node not in visited:\n            component = set()\n            stack = [node]\n            visited.add(node)\n            while stack:\n                curr = stack.pop()\n                component.add(curr)\n                for neighbor in adj.get(curr, []):\n                    if neighbor not in visited:\n                        visited.add(neighbor)\n                        stack.append(neighbor)\n            components.append(component)\n    return components\n\ndef process_case(case_data):\n    records = case_data[\"records\"]\n    params = case_data[\"params\"]\n    ground_truth_clusters = case_data[\"ground_truth\"]\n\n    records_map = {rec['id']: rec for rec in records}\n    \n    # 1. Blocking\n    blocks = defaultdict(list)\n    for rec in records:\n        last_name_token = rec['name'].split()[-1]\n        last_initial = last_name_token[0].upper()\n        year_of_birth = rec['dob'][:4]\n        block_key = (last_initial, year_of_birth)\n        blocks[block_key].append(rec['id'])\n    \n    # 2. Edge Construction\n    adj = defaultdict(list)\n    for block in blocks.values():\n        for r_id1, r_id2 in combinations(block, 2):\n            rec1, rec2 = records_map[r_id1], records_map[r_id2]\n            \n            # Name similarity\n            norm_name1 = normalize_name(rec1['name'])\n            norm_name2 = normalize_name(rec2['name'])\n            max_len = max(len(norm_name1), len(norm_name2))\n            if max_len > 0:\n                s_name = 1 - levenshtein_distance(norm_name1, norm_name2) / max_len\n            else:\n                s_name = 1.0\n\n            # DOB similarity\n            s_dob = 1.0 if rec1['dob'] == rec2['dob'] else 0.0\n\n            # ZIP similarity\n            s_zip = 0.0\n            zip1, zip2 = rec1['zip'], rec2['zip']\n            if zip1 == zip2:\n                s_zip = 1.0\n            elif len(zip1) >= 3 and len(zip2) >= 3 and zip1[:3] == zip2[:3]:\n                s_zip = 0.5\n            \n            # Weighted score\n            score = (params['w_name'] * s_name +\n                     params['w_dob'] * s_dob +\n                     params['w_zip'] * s_zip)\n            \n            if score >= params['threshold']:\n                adj[r_id1].append(r_id2)\n                adj[r_id2].append(r_id1)\n    \n    # 3. Clustering\n    predicted_clusters = find_connected_components(adj, records_map.keys())\n\n    # 4. Pairwise Metrics\n    true_pairs = get_pairs_from_clusters(ground_truth_clusters.values())\n    predicted_pairs = get_pairs_from_clusters(predicted_clusters)\n\n    tp = len(true_pairs.intersection(predicted_pairs))\n    fp = len(predicted_pairs) - tp\n    fn = len(true_pairs) - tp\n    \n    precision = 1.0 if (tp + fp) == 0 else tp / (tp + fp)\n    recall = 1.0 if (tp + fn) == 0 else tp / (tp + fn)\n\n    # 5. Merge and Split Error Analysis\n    # Merge errors\n    record_to_gt = {rec_id: gt_id for gt_id, rec_ids in ground_truth_clusters.items() for rec_id in rec_ids}\n    merge_error = 0\n    for p_cluster in predicted_clusters:\n        gt_entities_in_cluster = {record_to_gt[rec_id] for rec_id in p_cluster}\n        merge_error += max(0, len(gt_entities_in_cluster) - 1)\n        \n    # Split errors\n    record_to_p_cluster = {}\n    for i, p_cluster in enumerate(predicted_clusters):\n        for rec_id in p_cluster:\n            record_to_p_cluster[rec_id] = i\n    \n    split_error = 0\n    for gt_cluster in ground_truth_clusters.values():\n        p_clusters_hit = {record_to_p_cluster[rec_id] for rec_id in gt_cluster}\n        split_error += max(0, len(p_clusters_hit) - 1)\n\n    return [round(precision, 4), round(recall, 4), merge_error, split_error]\n\n\nif __name__ == \"__main__\":\n    solve()\n```"
        }
    ]
}