{
    "hands_on_practices": [
        {
            "introduction": "我们首先从一个基本问题开始：当我们从大小为 $n$ 的数据集中创建一个大小为 $n$ 的自助样本（bootstrap sample）时，这个样本平均会包含多少个来自原始数据集的 *唯一* 观测值？这个问题不是一个简单的脑筋急转弯，而是理解装袋法（bagging）核心机制的关键。通过从第一性原理推导这个期望值，我们将能精确量化每个基学习器训练数据的多样性，并为理解袋外（Out-of-Bag）评估的有效性奠定数学基础。",
            "id": "4559772",
            "problem": "在一项监督式基因组分类研究中，您有一个由 $n=200$ 名患者组成的原始队列，每位患者都由高维基因表达谱表示。为了构建一个基学习器的自助聚合 (bagging) 集成模型，每个模型都在一个自助采样样本上进行训练：从 $n$ 名患者中进行 $n$ 次有放回抽样，每次抽样都均匀随机地选择一名患者，且所有抽样都是独立同分布 (i.i.d.) 的。请仅使用这些定义和基本原理（如指示随机变量和期望的线性性），从第一性原理推导单个自助采样样本中包含的唯一患者数量期望值的精确表达式（作为 $n$ 的函数），然后计算当 $n=200$ 时的值。请将您的数值答案四舍五入至四位有效数字，并以患者数量的形式报告。最后，在高维基因组分类器的自助汇聚法 (bagging) 中，结合方差缩减和过拟合控制来解释该期望值的大小，并包括袋外 (OOB) 评估（在首次出现时定义袋外 (OOB)）的作用。您最终报告的答案必须仅为四舍五入后的患者期望数量。",
            "solution": "该问题是有效的，因为它在科学上基于统计学习理论的原理，问题陈述清晰，且是客观的。我们可以开始求解。\n\n目标是推导从一个包含 $n$ 名患者的原始队列中进行有放回抽样，得到的规模为 $n$ 的单个自助采样样本中所含唯一患者数量的期望值的精确表达式。\n\n设原始患者集合为 $C = \\{p_1, p_2, \\dots, p_n\\}$。通过从 $C$ 中有放回地抽样 $n$ 次来构建一个自助采样样本。所有抽样都是独立同分布 (i.i.d.) 的，并且在任何单次抽样中，每位患者被选中的概率为 $\\frac{1}{n}$。\n\n设 $X$ 为表示自助采样样本中唯一患者数量的随机变量。为了求 $X$ 的期望，我们可以按照提示，将 $X$ 表示为指示随机变量之和。对于每位患者 $j \\in \\{1, 2, \\dots, n\\}$，定义一个指示随机变量 $I_j$ 如下：\n$$\nI_j = \\begin{cases} 1  \\text{如果患者 } j \\text{ 在自助采样样本中至少出现一次} \\\\ 0  \\text{如果患者 } j \\text{ 未出现在自助采样样本中} \\end{cases}\n$$\n样本中唯一患者的总数是这些指示变量的和：\n$$\nX = \\sum_{j=1}^{n} I_j\n$$\n根据期望的线性性，唯一患者数量的期望值是个体指示变量期望值的和：\n$$\nE[X] = E\\left[\\sum_{j=1}^{n} I_j\\right] = \\sum_{j=1}^{n} E[I_j]\n$$\n一个指示随机变量的期望等于它所指示的事件发生的概率。因此，$E[I_j] = P(I_j = 1)$。\n$I_j=1$ 事件表示患者 $j$ 在 $n$ 次抽样中至少被选中一次。计算其对立事件 $P(I_j = 0)$ 的概率更简单，该事件表示患者 $j$ 在 $n$ 次抽样中从未被选中。\n\n在单次抽样中，选中任何特定患者 $j$ 的概率是 $\\frac{1}{n}$。\n因此，在单次抽样中*不*选中患者 $j$ 的概率是 $1 - \\frac{1}{n}$。\n由于 $n$ 次抽样是独立的，所以在 $n$ 次抽样中均未选中患者 $j$ 的概率是每次抽样都未选中患者 $j$ 的概率之积：\n$$\nP(I_j = 0) = \\left(1 - \\frac{1}{n}\\right) \\times \\left(1 - \\frac{1}{n}\\right) \\times \\dots \\times \\left(1 - \\frac{1}{n}\\right) = \\left(1 - \\frac{1}{n}\\right)^n\n$$\n因此，患者 $j$ 至少被选中一次的概率是：\n$$\nP(I_j = 1) = 1 - P(I_j = 0) = 1 - \\left(1 - \\frac{1}{n}\\right)^n\n$$\n所以，指示变量的期望是 $E[I_j] = 1 - \\left(1 - \\frac{1}{n}\\right)^n$。\n因为抽样是均匀的，所以对于所有患者 $j=1, \\dots, n$，这个概率都是相同的。\n\n将此结果代入 $E[X]$ 的表达式中：\n$$\nE[X] = \\sum_{j=1}^{n} \\left[1 - \\left(1 - \\frac{1}{n}\\right)^n\\right]\n$$\n由于求和号内的项相对于索引 $j$ 是常数，因此总和就是该项乘以 $n$：\n$$\nE[X] = n \\left[1 - \\left(1 - \\frac{1}{n}\\right)^n\\right]\n$$\n这就是单个自助采样样本中唯一患者数量期望值的精确表达式。\n\n现在，我们计算当 $n=200$ 时此表达式的值：\n$$\nE[X] = 200 \\left[1 - \\left(1 - \\frac{1}{200}\\right)^{200}\\right] = 200 \\left[1 - \\left(\\frac{199}{200}\\right)^{200}\\right]\n$$\n计算括号中项的值：\n$$\n\\left(\\frac{199}{200}\\right)^{200} = (0.995)^{200} \\approx 0.3669528...\n$$\n将该值代回期望值的表达式中：\n$$\nE[X] \\approx 200 [1 - 0.3669528] = 200 [0.6330472] \\approx 126.60944\n$$\n四舍五入到四位有效数字，唯一患者的期望数量为 $126.6$。\n\n这意味着平均而言，一个自助采样樣本包含原始 $200$ 名患者中的约 $126.6$ 名，约为 $63.3\\%$。剩下的平均 $200 - 126.6 = 73.4$ 名患者，约占 $36.7\\%$，未被包含在内。这些被排除的样本被称为 **袋外 (Out-of-Bag, OOB)** 样本，即原始数据集中未出现在给定自助采样样本中的观测值。\n\n这个期望值的大小对于自助汇聚法 (bagging) 的有效性至关重要。\n1.  **方差缩减与过拟合控制**：Bagging通过平均多个模型的预测来降低估计的方差。为了使这种平均有效，各个模型必须具有多样性，即它们必须犯不同的错误。通过在不同的自助采样样本上训练每个基学习器（每个样本仅包含约 $63.3\\%$ 的唯一数据），我们确保了这种多样性。在高维基因组研究中，分类器（如决策树）极易通过捕捉伪噪声而对训练数据产生过拟合。Bagging通过让每棵树对数据的不同子集过拟合来缓解这个问题；当它们的预测被平均时，大部分特定于模型的噪声会相互抵消，从而产生更平滑的决策边界和更鲁棒、泛化性能更好的集成模型。每次训练都忽略了原始数据中相当大的一部分，正是这一点驱动了基学习器之间关键的去相关性。\n\n2.  **袋外 (OOB) 评估的作用**：OOB 样本为每个基学习器提供了一个“免费”且无偏的验证集。为了评估整个 bagging 集成的性能，可以对原始数据集中的每位患者，聚合那些将该患者作为 OOB 样本的模型的预测。由此产生的“OOB 误差”是集成模型泛化误差的一个可靠估计，其计算无需单独的留出测试集或计算成本高昂的交叉验证过程。OOB 集的规模相当可观（平均每个模型有 $73.4$ 名患者），确保了该估计的稳定性和可信度，这在数据通常有限的医学数据分析中是一个显著优势。",
            "answer": "$$\\boxed{126.6}$$"
        },
        {
            "introduction": "我们已经知道，自助采样会留下一部分数据未被用于训练，即“袋外”（Out-of-Bag, OOB）样本。这自然引出了一个问题：利用这些OOB样本计算出的误差（OOB误差）作为模型泛化能力的估计，其可靠性如何？这项练习要求你对OOB误差估计与另一种广泛使用的技术——K折交叉验证（K-fold cross-validation）——在估计偏差方面进行概念性比较，从而揭示装袋法在模型评估方面的一个关键实践优势。",
            "id": "4559762",
            "problem": "一个临床数据集提供了从未知分布中抽取的 $N$ 个独立同分布的患者记录 $\\{(X_i, Y_i)\\}_{i=1}^N$，其中 $Y_i \\in \\{0,1\\}$ 表示疾病状态。由于诊断金标准不完美，标签存在比率为 $\\varepsilon \\in (0, 1/2)$ 的对称标签噪声，特征 $X_i$ 包括常规实验室结果和人口统计信息。通过聚合 $B$ 个分类与回归树 (CART) 基学习器来构建一个 Bagging 分类器，每个基学习器都在从完整数据集中抽取的、大小为 $N$ 的 bootstrap 样本上进行训练。考虑以下两种对基于完整数据集构建的 Bagging 分类器的泛化误差（期望风险）的估计量：\n1. 袋外 (OOB) 误差，即对于每个观测值 $i$，仅通过对那些其 bootstrap 样本不包含观测值 $i$ 的树进行平均来形成预测，整体误差是所有 $i$ 的损失的平均值。\n2. $K=5$ 时的 $K$ 折交叉验证 (CV) 误差，即将数据划分为 5 个不相交的折，对每一折，在另外 4 折上训练一个 Bagging 分类器，并在留出的那一折上进行评估；误差在各折之间取平均。\n\n假设 $B \\gg 1$，因此由有限数量的树引起的蒙特卡洛波动可以忽略不计。请仅使用期望风险 $\\mathbb{E}[\\ell(\\hat{f}(X), Y)]$ 的基本定义、bootstrap 采样的性质以及 $K$ 折交叉验证的构造，来推断在带噪声的临床数据生成过程中，这两种误差估计量的偏差方向（相对于在所有 $N$ 个观测值上训练的 Bagging 分类器的真实泛化误差）。哪个陈述最准确？\n\nA. 当 $B \\to \\infty$ 时，对于在完整数据集上训练的 Bagging 分类器的泛化误差而言，袋外误差是渐近无偏的，而 $5$ 折交叉验证则因为每一折都只在 $80\\%$ 的数据上训练而具有悲观偏差。\n\nB. 当 $B \\to \\infty$ 时，即使 $N$ 是有限的，袋外误差和 $5$ 折交叉验证对于在完整数据集上训练的 Bagging 分类器的泛化误差都是无偏的。\n\nC. 在带噪声的临床数据集中，袋外误差具有乐观偏差，因为许多树是在包含目标观测值的 bootstrap 样本上训练的，这泄露了信息。\n\nD. 相对于在完整数据集上训练的 Bagging 分类器的泛化误差，$5$ 折交叉验证具有乐观偏差，因为它对留出折上的损失进行平均，而这些折比完整分布更容易预测。\n\nE. 袋外误差和 $5$ 折交叉验证之间的偏差差异仅在 $K=N$（留一法交叉验证）时消失；对于 $K=5$，袋外误差的偏差总是更大。",
            "solution": "用户要求对所提供的问题陈述进行严格验证，然后严谨地推导解决方案并评估所有选项。\n\n### 步骤 1: 提取已知条件\n- **数据集**：$N$ 个独立同分布 (i.i.d.) 的患者记录 $\\{(X_i, Y_i)\\}_{i=1}^N$。\n- **数据分布**：从一个未知分布中抽取。\n- **标签**：$Y_i \\in \\{0,1\\}$ (疾病状态)。\n- **标签噪声**：比率为 $\\varepsilon \\in (0, 1/2)$ 的对称标签噪声。\n- **特征**：$X_i$ (实验室结果和人口统计信息)。\n- **分类器**：一个聚合了 $B$ 个分类与回归树 (CART) 基学习器的 Bagging 分类器。\n- **训练方法**：每个基学习器都在大小为 $N$ 的 bootstrap 样本上训练。\n- **误差估计量 1**：袋外 (OOB) 误差。对于每个观测值 $i$，通过聚合那些其 bootstrap 样本不包含观测值 $i$ 的树来进行预测。整体误差是所有观测值的损失的平均值。\n- **误差估计量 2**：$K=5$ 时的 $K$ 折交叉验证 (CV) 误差。数据被划分为 5 个不相交的折。对每一折，在另外 4 折上训练一个 Bagging 分类器，并在留出的那一折上进行评估。误差在各折之间取平均。\n- **假设**：$B \\gg 1$，意味着树的数量足够大，可以忽略聚合中的蒙特卡洛误差。\n- **目标**：确定关于这两种误差估计量相对于在所有 $N$ 个观测值上训练的 Bagging 分类器的真实泛化误差的偏差方向的最准确陈述。\n\n### 步骤 2: 使用提取的已知条件进行验证\n1.  **科学基础（关键）**：该问题牢固地植根于统计机器学习理论。Bagging (Bootstrap Aggregating)、CART、袋外误差估计和 K 折交叉验证都是标准的、定义明确的概念。带有噪声标签的临床数据集这一背景是一个常见且现实的应用领域。该问题遵循既定的科学原则。\n2.  **良构性**：该问题是良构的。它要求对两种明确定义的统计估计量（$\\hat{Err}_{OOB}$ 和 $\\hat{Err}_{CV}$）与一个明确定义的目标量（特定分类器的真实泛化误差）进行定性比较（偏差方向）。基于这些估计量的性质，存在一个唯一的概念性答案。\n3.  **客观性（关键）**：语言精确且技术性强。诸如“偏差”、“泛化误差”、“bootstrap 样本”和“K 折交叉验证”等术语都有正式定义。该问题不含主观或基于观点的陈述。\n4.  **完整性**：该问题提供了所有必要的信息来推断偏差。对于基于估计量构造的定性偏差分析，不需要 $N$、$B$（除了知道它很大）以及数据分布的具体细节。假设 $B \\gg 1$ 是至关重要的，并且已经给出。\n5.  **未检测到其他缺陷**：该问题没有矛盾、不切实际、不适定、微不足道或无法验证之处。提及“对称标签噪声”增加了现实的复杂性，但并未改变误差估计量的基本机制，因此不会使问题失效。\n\n### 步骤 3: 结论与行动\n问题陈述是**有效的**。开始进行求解。\n\n### 推导\n设 $S = \\{(X_i, Y_i)\\}_{i=1}^N$ 是大小为 $N$ 的完整数据集。设 $\\hat{f}_S$ 表示在 $S$ 上训练的 Bagging 分类器。该分类器是 $B$ 个基学习器 $\\{\\hat{h}_b\\}_{b=1}^B$ 的聚合，其中每个 $\\hat{h}_b$ 是在一个从 $S$ 中抽取的、大小为 $N$ 的 bootstrap 样本 $S^{*b}$ 上训练的 CART。\n我们希望估计的目标量是 $\\hat{f}_S$ 的真实泛化误差（或期望风险），定义为：\n$$ R(\\hat{f}_S) = \\mathbb{E}_{(X,Y)}[\\ell(\\hat{f}_S(X), Y)] $$\n其中期望是针对真实的、未知的数据生成分布计算的，$\\ell$ 是一个合适的损失函数（例如，分类中的 0-1 损失）。分类器 $\\hat{f}_S$ 由数据集 $S$ 固定。我们的目标是分析两个估计量 $\\hat{Err}_{OOB}$ 和 $\\hat{Err}_{CV}$ 对此量 $R(\\hat{f}_S)$ 的偏差。\n\n**估计量的偏差**：估计量 $\\hat{\\theta}$ 对参数 $\\theta$ 的偏差为 $\\mathbb{E}[\\hat{\\theta}] - \\theta$。正偏差称为悲观偏差（高估），负偏差称为乐观偏差（低估）。对于误差估计，我们通常关心的是估计量在训练集分布上的期望，与期望真实误差的比较。设 $Err(n)$ 表示在大小为 $n$ 的数据集上训练的分类器的期望泛化误差，即 $Err(n) = \\mathbb{E}_{S_n}[R(\\hat{f}_{S_n})]$。通常，对于一个稳定的学习算法，$Err(n)$ 是 $n$ 的一个非增函数。更多的数据会带来更好的模型，其泛化误差更低。\n\n**1. 5 折交叉验证 (CV) 误差分析**\n在 $K=5$ 的 $K$ 折交叉验证中，数据集 $S$ 被划分为 5 个不相交的折。对于每一折 $k \\in \\{1,...,5\\}$，一个*新的* Bagging 分类器（我们称之为 $\\hat{f}_{\\neg k}$）在剩下的 4 折上进行训练。这个训练集的大小是 $N(1-1/K) = N(1-1/5) = 4N/5 = 0.8N$。然后，$\\hat{f}_{\\neg k}$ 的误差在留出的折 $k$ 上进行估计。最终的 CV 误差 $\\hat{Err}_{CV}$ 是这 5 个误差估计值的平均值。\n\n关键在于，$\\hat{Err}_{CV}$ 是在大小为 $0.8N$（而非 $N$）的数据集上训练的分类器的泛化误差的估计。由于大多数分类器（包括 Bagging 树）的性能会随着训练数据的增多而提高，学习曲线 $Err(n)$ 是 $n$ 的一个递减函数。因此，我们预期：\n$$ \\mathbb{E}[\\hat{Err}_{CV}] \\approx Err(0.8N)  Err(N) $$\n因为 CV 过程评估的是在比完整数据集更小的数据集上训练的模型，所以这些模型预期会不那么准确（即具有更高的误差）相较于在完整数据集上训练的最终模型。因此，$K$ 折交叉验证误差估计量是**悲观偏差的**；它倾向于高估最终模型的真实泛化误差。\n\n**2. 袋外 (OOB) 误差分析**\n袋外 (OOB) 误差估计量 $\\hat{Err}_{OOB}$ 的工作方式不同。它使用在完整数据集 $S$ 上训练的*单一* Bagging 分类器 $\\hat{f}_S$。对于每个观测值 $(X_i, Y_i) \\in S$，其预测是通过仅聚合那些 $(X_i, Y_i)$ 不在其相应 bootstrap 样本 $S^{*b}$ 中的树 $\\{\\hat{h}_b\\}$ 来进行的。这些是观测值 $i$ 的“袋外”树。\n一个特定观测值 $i$ 在大小为 $N$ 的 bootstrap 样本中未被选中的概率是 $(1 - 1/N)^N$。当 $N \\to \\infty$ 时，这个概率收敛于 $1/e \\approx 0.368$。因此，平均而言，每个观测值对大约 $36.8\\%$ 的树是“袋外”的。\n观测值 $i$ 的 OOB 误差是使用一个预测来计算的，其中 $(X_i, Y_i)$ 被有效地留出，作为该树子集成的测试点。$\\hat{Err}_{OOB}$ 是这些误差在所有 $i=1,...,N$ 上的平均值。\n\n因为 OOB 过程使用在特定基学习器训练期间未见过的观测值来测试它们，它提供了一种有效的误差估计机制，避免了因在训练数据上测试而产生的乐观偏差。源于 Breiman 的经典观点是，OOB 误差是真实泛化误差的一个近似无偏估计量。与 $K$ 折交叉验证不同，它不需要在较小的数据分区上重新训练新模型。它估计的是我们构建的那个模型 $\\hat{f}_S$ 本身的误差。\n\n虽然更详细的理论分析表明，对于有限的 $N$，OOB 误差可能存在小的悲观偏差（由于 OOB 子集成中基学习器之间的相关性），但这种偏差通常远小于 $K$ 折交叉验证的悲观偏差（特别是对于像 $5$ 这样的小 $K$）。出于许多实践和理论目的，特别是在 $N$ 增大时，OOB 误差被认为是渐近无偏的。\n\n**偏差总结**：\n- **5 折 CV**：具有显著的悲观偏差，因为它评估的是仅在 $80\\%$ 的数据上训练的模型。\n- **OOB 误差**：是无偏的或具有小的悲观偏差。它对于 $R(\\hat{f}_S)$ 的估计比 $5$ 折 CV 的偏差要小得多。\n\n比率为 $\\varepsilon \\in (0, 1/2)$ 的对称标签噪声的存在会增加不可约误差，并使学习问题变得更难，但它不会改变这两种估计量偏差的基本方向，因为偏差源于它们使用训练数据的方式。\n\n### 逐项分析\n\n**A. 当 $B \\to \\infty$ 时，对于在完整数据集上训练的 Bagging 分类器的泛化误差而言，袋外误差是渐近无偏的，而 $5$ 折交叉验证则因为每一折都只在 $80\\%$ 的数据上训练而具有悲观偏差。**\n这个陈述是准确的。它正确地指出了 $5$ 折 CV 的悲观偏差及其原因。将 OOB 误差描述为“渐近无偏”是此背景下的标准和正确表述，特别是与偏差更大的 CV 相比。OOB 的偏差（如果存在）已知很小，并随样本量的增加而减小。**正确**。\n\n**B. 当 $B \\to \\infty$ 时，即使 $N$ 是有限的，袋外误差和 $5$ 折交叉验证对于在完整数据集上训练的 Bagging 分类器的泛化误差都是无偏的。**\n这是不正确的。如上所述，对于有限的 $N$，$5$ 折交叉验证具有悲观偏差，因为它是在较小的数据集上训练的。这种偏差不会仅仅因为 $B \\to \\infty$ 而消失。**不正确**。\n\n**C. 在带噪声的临床数据集中，袋外误差具有乐观偏差，因为许多树是在包含目标观测值的 bootstrap 样本上训练的，这泄露了信息。**\n这个陈述从根本上误解了 OOB 误差的计算方式。给定观测值的误差是*仅*使用那些*未*在该观测值上训练过的树来计算的。这个过程专门设计用来防止信息泄露和由此产生的乐观偏差。OOB 的偏差通常被认为是悲观的，而非乐观的。**不正确**。\n\n**D. 相对于在完整数据集上训练的 Bagging 分类器的泛化误差，$5$ 折交叉验证具有乐观偏差，因为它对留出折上的损失进行平均，而这些折比完整分布更容易预测。**\n这个陈述在两方面都是错误的。首先，偏差是悲观的，而不是乐观的。其次，原因也是错误的；留出的折是随机样本，并不会系统性地比来自同一分布的任何其他数据“更容易预测”。偏差来自于在较小的数据集上训练。**不正确**。\n\n**E. 袋外误差和 $5$ 折交叉验证之间的偏差差异仅在 $K=N$（留一法交叉验证）时消失；对于 $K=5$，袋外误差的偏差总是更大。**\n这个陈述是不正确的。$K$ 折 CV 的偏差是 $K$ 的函数，当 $K=N$ (LOOCV) 时，偏差最小但仍然是悲观的（$Err(N-1)  Err(N)$）。OOB 误差通常被认为是 LOOCV 的一种计算上高效的近似。然而，声称偏差差异*消失*过于绝对。更重要的是，声称对于 $K=5$，OOB 误差“总是偏差更大”与既定的理论和实践相反。由于训练集大小减少了 $20\\%$，$5$ 折 CV 的偏差远大于 OOB 的偏差。**不正确**。",
            "answer": "$$\\boxed{A}$$"
        },
        {
            "introduction": "现在，让我们将理论应用于生物信息学中一个常见而复杂的任务：生存分析。在处理带有右删失（right-censoring）的医疗数据时，评估模型的预测性能需要专门的指标，例如一致性指数（Concordance Index, C-index）。这项练习将指导你如何为装袋生存模型推导并计算一个基于袋外样本的C-index，从而将理论知识与解决真实世界问题的具体步骤联系起来，体验在复杂数据场景下评估集成模型的完整流程。",
            "id": "4559822",
            "problem": "生物信息学和医学数据分析中的一个核心任务是评估在自助聚合（bagging）下训练的生存模型的预测一致性。考虑一个带有右删失的生存数据集，其中受试者 $i$ 的真实生存时间为 $T_i$，删失时间为 $C_i$，观测时间为 $t_i = \\min\\{T_i, C_i\\}$，事件指示符为 $\\delta_i = \\mathbf{1}\\{T_i \\leq C_i\\}$。假设在重采样数据集上训练了一个由 $B$ 个自助法模型组成的集成，仅对未包含在给定模型训练集中的受试者产生袋外（Out-Of-Bag, OOB）预测。感兴趣的预测量是来自模型 $m$ 的受试者 $i$ 的风险评分 $s_{i,m}$，其中较高的值表示较高的瞬时风险，因此对应更早的失败时间。\n\n从右删失的定义和一致性指数（C-index）的一致性概率解释出发，推导一个用于自助聚合生存模型的袋外（OOB）C-指数的基于样本的估计量，该估计量（i）通过对受试者为袋外样本的模型进行平均，来聚合每个受试者的OOB风险评分，并且（ii）仅使用右删失下的可比较对来计数一致对。然后，为以下的集成和数据计算其数值：\n\n- 受试者 $i \\in \\{1,2,3,4,5\\}$ 的 $(t_i, \\delta_i)$ 数据如下：\n  - 受试者 1：$(t_1, \\delta_1) = (5, 1)$\n  - 受试者 2：$(t_2, \\delta_2) = (7, 0)$\n  - 受试者 3：$(t_3, \\delta_3) = (10, 1)$\n  - 受试者 4：$(t_4, \\delta_4) = (13, 1)$\n  - 受试者 5：$(t_5, \\delta_5) = (18, 0)$\n- 四个自助法模型（$B=4$）产生以下OOB风险评分 $s_{i,m}$（未显示的条目为袋内样本，因此不可用于OOB聚合）：\n  - 模型 1：$s_{1,1} = 0.85$, $s_{3,1} = 0.70$, $s_{5,1} = 0.45$\n  - 模型 2：$s_{2,2} = 0.52$, $s_{3,2} = 0.73$, $s_{4,2} = 0.56$\n  - 模型 3：$s_{1,3} = 0.80$, $s_{2,3} = 0.55$, $s_{5,3} = 0.68$\n  - 模型 4：$s_{3,4} = 0.69$, $s_{4,4} = 0.52$, $s_{5,4} = 0.65$\n\n将受试者 $i$ 的OOB聚合风险评分定义为在 $i$ 是OOB样本的所有模型上的算术平均值。使用标准的右删失可比较性规则：如果 $\\min\\{t_i, t_j\\}$ 对应一个观测到的事件（即，如果 $t_i  t_j$ 且 $\\delta_i = 1$，或者如果 $t_j  t_i$ 且 $\\delta_j = 1$），则一对 $(i,j)$ 是可比较的。如果具有较小观测事件时间的受试者具有较大的聚合风险评分，则该可比较对是一致的。假设观测时间或聚合风险评分中没有结。以单个精确分数的形式提供最终的OOB C-指数。如果您选择以小数近似值表示，请将答案四舍五入到四位有效数字。",
            "solution": "问题要求推导一个用于自助聚合生存模型的袋外（OOB）一致性指数（C-index）的基于样本的估计量，然后对给定的数据集进行计算。\n\n首先，我们建立OOB C-指数估计量的正式定义。假设有一组 $N$ 个受试者，索引为 $i \\in \\{1, 2, \\dots, N\\}$。对于每个受试者 $i$，我们有观测时间 $t_i$ 和事件指示符 $\\delta_i$。一个由 $B$ 个模型组成的集成在自助样本上进行训练。对于每个受试者 $i$，令 $M_i^{\\text{OOB}}$ 为受试者 $i$ 处于袋外样本中的模型索引 $m$ 的集合。由模型 $m \\in M_i^{\\text{OOB}}$ 预测的受试者 $i$ 的风险评分为 $s_{i,m}$。\n\n受试者 $i$ 的OOB聚合风险评分，记为 $\\bar{s}_i$，定义为该受试者OOB风险评分的算术平均值：\n$$\n\\bar{s}_i = \\frac{1}{|M_i^{\\text{OOB}}|} \\sum_{m \\in M_i^{\\text{OOB}}} s_{i,m}\n$$\nC-指数评估模型区分成对受试者结局的能力。考虑到右删失的存在，并非所有受试者对都是可比较的。只有当我们能够明确确定哪个受试者具有更短的生存时间时，一对 $(i, j)$ 才被认为是可比较的。如果具有较早观测时间的受试者（例如 $i$，即 $t_i  t_j$）经历了一个事件（$\\delta_i = 1$），这才可能。如果受试者 $i$ 被删失（$\\delta_i = 0$），其真实事件时间 $T_i$ 将是未知的，并且可能大于 $t_j$，这使得事件时间的排序不确定。\n\n因此，所有可比较对的集合 $N_{\\text{comp}}$ 定义为：\n$$\nN_{\\text{comp}} = \\left\\{ (i, j) \\mid i \\neq j, (t_i  t_j \\text{ and } \\delta_i = 1) \\text{ or } (t_j  t_i \\text{ and } \\delta_j = 1) \\right\\}\n$$\n如果模型的风险预测与观测到的结局一致，则一个可比较对是一致的。由于较高的风险评分 $\\bar{s}$ 表示较高的风险和更早的事件时间，因此对于一对 $t_i  t_j$ 的 $(i, j)$，如果 $\\bar{s}_i  \\bar{s}_j$，则该对是一致的。一致对的集合 $N_{\\text{conc}}$ 是 $N_{\\text{comp}}$ 的一个子集，定义为：\n$$\nN_{\\text{conc}} = \\left\\{ (i, j) \\in N_{\\text{comp}} \\mid (t_i  t_j \\text{ and } \\bar{s}_i  \\bar{s}_j) \\text{ or } (t_j  t_i \\text{ and } \\bar{s}_j  \\bar{s}_i) \\right\\}\n$$\nOOB C-指数的基于样本的估计量 $C_{\\text{OOB}}$ 是一致对数量与可比较对数量的比率：\n$$\nC_{\\text{OOB}} = \\frac{|N_{\\text{conc}}|}{|N_{\\text{comp}}|}\n$$\n如问题所述，这假设在观测时间 $t_i$ 或聚合风险评分 $\\bar{s}_i$ 中都没有结。\n\n现在，我们为所提供的数据计算 $C_{\\text{OOB}}$ 的值。\n\n数据集包含5个受试者，其生存数据如下：\n- 受试者 1：$(t_1, \\delta_1) = (5, 1)$\n- 受试者 2：$(t_2, \\delta_2) = (7, 0)$\n- 受试者 3：$(t_3, \\delta_3) = (10, 1)$\n- 受试者 4：$(t_4, \\delta_4) = (13, 1)$\n- 受试者 5：$(t_5, \\delta_5) = (18, 0)$\n\n有 $B=4$ 个模型。OOB风险评分 $s_{i,m}$ 已给出。\n\n**步骤1：计算OOB聚合风险评分 $\\bar{s}_i$。**\n\n- 对于受试者1，OOB模型为 $m \\in \\{1, 3\\}$：\n  $\\bar{s}_1 = \\frac{s_{1,1} + s_{1,3}}{2} = \\frac{0.85 + 0.80}{2} = \\frac{1.65}{2} = 0.825$。\n- 对于受试者2，OOB模型为 $m \\in \\{2, 3\\}$：\n  $\\bar{s}_2 = \\frac{s_{2,2} + s_{2,3}}{2} = \\frac{0.52 + 0.55}{2} = \\frac{1.07}{2} = 0.535$。\n- 对于受试者3，OOB模型为 $m \\in \\{1, 2, 4\\}$：\n  $\\bar{s}_3 = \\frac{s_{3,1} + s_{3,2} + s_{3,4}}{3} = \\frac{0.70 + 0.73 + 0.69}{3} = \\frac{2.12}{3} \\approx 0.7067$。\n- 对于受试者4，OOB模型为 $m \\in \\{2, 4\\}$：\n  $\\bar{s}_4 = \\frac{s_{4,2} + s_{4,4}}{2} = \\frac{0.56 + 0.52}{2} = \\frac{1.08}{2} = 0.54$。\n- 对于受试者5，OOB模型为 $m \\in \\{1, 3, 4\\}$：\n  $\\bar{s}_5 = \\frac{s_{5,1} + s_{5,3} + s_{5,4}}{3} = \\frac{0.45 + 0.68 + 0.65}{3} = \\frac{1.78}{3} \\approx 0.5933$。\n\n**步骤2：识别所有可比较对。**\n\n我们检查所有 $\\binom{5}{2} = 10$ 个唯一的受试者对。如果具有较小 $t$ 值的受试者其 $\\delta=1$，则该对 $(i, j)$ 是可比较的。\n\n- 对 (1, 2)：$t_1 = 5  t_2 = 7$ 且 $\\delta_1 = 1$。**可比较。**\n- 对 (1, 3)：$t_1 = 5  t_3 = 10$ 且 $\\delta_1 = 1$。**可比较。**\n- 对 (1, 4)：$t_1 = 5  t_4 = 13$ 且 $\\delta_1 = 1$。**可比较。**\n- 对 (1, 5)：$t_1 = 5  t_5 = 18$ 且 $\\delta_1 = 1$。**可比较。**\n- 对 (2, 3)：$t_2 = 7  t_3 = 10$ 但 $\\delta_2 = 0$。不可比较。\n- 对 (2, 4)：$t_2 = 7  t_4 = 13$ 但 $\\delta_2 = 0$。不可比较。\n- 对 (2, 5)：$t_2 = 7  t_5 = 18$ 但 $\\delta_2 = 0$。不可比较。\n- 对 (3, 4)：$t_3 = 10  t_4 = 13$ 且 $\\delta_3 = 1$。**可比较。**\n- 对 (3, 5)：$t_3 = 10  t_5 = 18$ 且 $\\delta_3 = 1$。**可比较。**\n- 对 (4, 5)：$t_4 = 13  t_5 = 18$ 且 $\\delta_4 = 1$。**可比较。**\n\n可比较对的总数为 $|N_{\\text{comp}}| = 7$。\n\n**步骤3：检查可比较对之间的一致性。**\n\n如果具有较小事件时间的受试者具有较大的聚合风险评分，则该可比较对是一致的。\n\n- 对 (1, 2)：$t_1  t_2$。我们检查是否 $\\bar{s}_1  \\bar{s}_2$。\n  $0.825  0.535$。**一致。**\n- 对 (1, 3)：$t_1  t_3$。我们检查是否 $\\bar{s}_1  \\bar{s}_3$。\n  $0.825  0.7067$。**一致。**\n- 对 (1, 4)：$t_1  t_4$。我们检查是否 $\\bar{s}_1  \\bar{s}_4$。\n  $0.825  0.54$。**一致。**\n- 对 (1, 5)：$t_1  t_5$。我们检查是否 $\\bar{s}_1  \\bar{s}_5$。\n  $0.825  0.5933$。**一致。**\n- 对 (3, 4)：$t_3  t_4$。我们检查是否 $\\bar{s}_3  \\bar{s}_4$。\n  $0.7067  0.54$。**一致。**\n- 对 (3, 5)：$t_3  t_5$。我们检查是否 $\\bar{s}_3  \\bar{s}_5$。\n  $0.7067  0.5933$。**一致。**\n- 对 (4, 5)：$t_4  t_5$。我们检查是否 $\\bar{s}_4  \\bar{s}_5$。\n  $0.54  0.5933$。不一致。\n\n一致对的总数为 $|N_{\\text{conc}}| = 6$。\n\n**步骤4：计算OOB C-指数。**\n\n使用推导出的公式：\n$$\nC_{\\text{OOB}} = \\frac{|N_{\\text{conc}}|}{|N_{\\text{comp}}|} = \\frac{6}{7}\n$$\n对于给定数据，此自助聚合生存模型的OOB C-指数为 $\\frac{6}{7}$。",
            "answer": "$$\\boxed{\\frac{6}{7}}$$"
        }
    ]
}