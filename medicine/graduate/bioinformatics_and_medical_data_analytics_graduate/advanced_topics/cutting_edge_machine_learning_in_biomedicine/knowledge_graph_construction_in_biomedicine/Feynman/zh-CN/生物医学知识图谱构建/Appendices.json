{
    "hands_on_practices": [
        {
            "introduction": "实体归一化是构建知识图谱（KG）至关重要的第一步，它将非结构化的文本提及（mentions）链接到权威数据库中的规范化标识符。这项实践练习将指导您如何利用多种字符串相似度量指标，构建一个稳健的归一化流程，并量化其性能。掌握这一技能对于整合多样化的生物医学数据源，确保知识图谱的准确性和一致性至关重要。",
            "id": "4577572",
            "problem": "构建一个完整、可运行的程序，该程序为生物医学知识图谱构建实现并评估一个有原则的实体归一化流程。该流程必须将自由文本提及（mentions）映射到从基因和药物的精选标识符中提取的规范标识符，具体来说，基因使用 HUGO Gene Nomenclature Committee (HGNC) 标识符，药物使用 DrugBank database (DrugBank) 标识符。程序必须是自包含的，仅使用下面指定的数据和参数，并以指定格式生成单行输出。评估必须使用可调的评分阈值和特征权重向量，来量化同义词情况下的精确率-召回率权衡。\n\n您必须从字符串归一化和评估指标的核心定义及经过充分检验的事实出发，推导出算法。程序必须精确地实现以下组件。\n\n1) 规范实体和同义词。令规范标识符的集合表示为 $\\mathcal{C}$。每个规范标识符 $c \\in \\mathcal{C}$ 都有一个有限的表层形式（同义词）集合 $\\mathcal{S}(c)$ 和一个单一的偏好标签 $p(c) \\in \\mathcal{S}(c)$。精确使用以下集合：\n- 基因 (HGNC):\n  - $c = \\text{HGNC:11998}$, $\\mathcal{S}(c) = \\{\\text{\"TP53\"}, \\text{\"p53\"}, \\text{\"tumor protein p53\"}\\}$, $p(c) = \\text{\"TP53\"}$。\n  - $c = \\text{HGNC:3236}$, $\\mathcal{S}(c) = \\{\\text{\"EGFR\"}, \\text{\"epidermal growth factor receptor\"}, \\text{\"ERBB1\"}\\}$, $p(c) = \\text{\"EGFR\"}$。\n  - $c = \\text{HGNC:391}$, $\\mathcal{S}(c) = \\{\\text{\"AKT1\"}, \\text{\"PKB\"}, \\text{\"RAC-alpha serine/threonine-protein kinase\"}\\}$, $p(c) = \\text{\"AKT1\"}$。\n- 药物 (DrugBank):\n  - $c = \\text{DrugBank:DB00316}$, $\\mathcal{S}(c) = \\{\\text{\"acetaminophen\"}, \\text{\"paracetamol\"}, \\text{\"APAP\"}\\}$, $p(c) = \\text{\"acetaminophen\"}$。\n  - $c = \\text{DrugBank:DB00945}$, $\\mathcal{S}(c) = \\{\\text{\"aspirin\"}, \\text{\"acetylsalicylic acid\"}, \\text{\"ASA\"}\\}$, $p(c) = \\text{\"aspirin\"}$。\n  - $c = \\text{DrugBank:DB01050}$, $\\mathcal{S}(c) = \\{\\text{\"ibuprofen\"}\\}$, $p(c) = \\text{\"ibuprofen\"}$。\n\n2) 提及和基准真相。令评估提及集合为 $\\mathcal{M}$，其基准真相映射为 $g: \\mathcal{M} \\to \\mathcal{C} \\cup \\{\\varnothing\\}$，其中 $\\varnothing$ 表示没有规范映射。精确使用以下列表：\n- $(\\text{\"TP53\"}, \\text{HGNC:11998})$\n- $(\\text{\"p53\"}, \\text{HGNC:11998})$\n- $(\\text{\"tumor prot p53\"}, \\text{HGNC:11998})$\n- $(\\text{\"p 53\"}, \\text{HGNC:11998})$\n- $(\\text{\"EGFR\"}, \\text{HGNC:3236})$\n- $(\\text{\"ERBB1\"}, \\text{HGNC:3236})$\n- $(\\text{\"erbb-1\"}, \\text{HGNC:3236})$\n- $(\\text{\"AKT-1\"}, \\text{HGNC:391})$\n- $(\\text{\"PKB\"}, \\text{HGNC:391})$\n- $(\\text{\"acetaminophen\"}, \\text{DrugBank:DB00316})$\n- $(\\text{\"paracetamol\"}, \\text{DrugBank:DB00316})$\n- $(\\text{\"APAP\"}, \\text{DrugBank:DB00316})$\n- $(\\text{\"aspirin\"}, \\text{DrugBank:DB00945})$\n- $(\\text{\"ASA\"}, \\text{DrugBank:DB00945})$\n- $(\\text{\"acetylsalicylic acid\"}, \\text{DrugBank:DB00945})$\n- $(\\text{\"ibuprofen\"}, \\text{DrugBank:DB01050})$\n- $(\\text{\"ibuprfen\"}, \\text{DrugBank:DB01050})$\n- $(\\text{\"randomword\"}, \\varnothing)$\n- $(\\text{\"EGFR inhibitor\"}, \\varnothing)$\n\n3) 归一化函数。为等价性比较和编辑距离比较定义一个确定性的归一化函数 $N:\\text{strings}\\to\\text{strings}$，并为 Jaccard 相似度定义一个分词函数 $T:\\text{strings}\\to 2^{\\text{tokens}}$。\n- 缩写扩展：在归一化之前，对小写的分词（token）应用映射 $\\{\\text{\"asa\"}\\mapsto\\text{\"acetylsalicylic acid\"}, \\text{\"apap\"}\\mapsto\\text{\"acetaminophen\"}\\}$ 进行逐词替换。\n- 用于等价性/编辑距离的字符串归一化：$N(s)$ 通过将字符串转为小写、执行缩写扩展并移除所有非字母数字字符来获得。例如，$N(\\text{\"p 53\"}) = \\text{\"p53\"}$ 和 $N(\\text{\"erbb-1\"}) = \\text{\"erbb1\"}$。\n- 分词：$T(s)$ 通过将字符串转为小写、执行缩写扩展、将每个非字母数字字符替换为空格、按空白字符分割，并从集合 $\\{\\text{\"protein\"}, \\text{\"receptor\"}, \\text{\"acid\"}, \\text{\"serine\"}, \\text{\"threonine\"}, \\text{\"alpha\"}, \\text{\"beta\"}, \\text{\"inhibitor\"}\\}$ 中移除停用词来获得。例如，$T(\\text{\"epidermal growth factor receptor\"}) = \\{\\text{\"epidermal\"}, \\text{\"growth\"}, \\text{\"factor\"}\\}$。\n\n4) 特征函数和评分。对于一个提及 $m$ 和某个 $c\\in\\mathcal{C}$ 的候选同义词 $s \\in \\mathcal{S}(c)$，定义特征向量 $\\phi(m,s) \\in \\mathbb{R}^{4}$ 如下：\n- 精确匹配特征：$f_{\\mathrm{e}}(m,s) = \\mathbf{1}[N(m) = N(s)]$。\n- 偏好标签精确匹配特征：$f_{\\mathrm{p}}(m,s) = \\mathbf{1}[N(m) = N(p(c))]$。\n- 分词 Jaccard 特征：$f_{\\mathrm{j}}(m,s) = \\dfrac{|T(m)\\cap T(s)|}{|T(m)\\cup T(s)|}$，约定 $0/0$ 为 $0$。\n- 归一化 Levenshtein 相似度：$f_{\\mathrm{d}}(m,s) = 1 - \\dfrac{D(N(m),N(s))}{\\max\\{|N(m)|,|N(s)|\\}}$，其中 $D(\\cdot,\\cdot)$ 是 Levenshtein 编辑距离，而 $|\\cdot|$ 是字符串的字符长度；如果两个长度都为 $0$，则设 $f_{\\mathrm{d}}(m,s)=1$。\n令权重向量为 $w = (w_{\\mathrm{e}}, w_{\\mathrm{j}}, w_{\\mathrm{d}}, w_{\\mathrm{p}}) \\in \\mathbb{R}_{\\ge 0}^{4}$。通过 $\\tilde{w} = w / \\sum_{i} w_{i}$ 将权重归一化到概率单纯形；如果 $\\sum_{i} w_{i} = 0$，则设 $\\tilde{w} = (1/4,1/4,1/4,1/4)$。每个同义词的得分是\n$$\nS(m,s; \\tilde{w}) = \\tilde{w}_{\\mathrm{e}} f_{\\mathrm{e}}(m,s) + \\tilde{w}_{\\mathrm{j}} f_{\\mathrm{j}}(m,s) + \\tilde{w}_{\\mathrm{d}} f_{\\mathrm{d}}(m,s) + \\tilde{w}_{\\mathrm{p}} f_{\\mathrm{p}}(m,s).\n$$\n每个实体的得分是其所有同义词得分中的最大值：\n$$\nS^{*}(m,c;\\tilde{w}) = \\max_{s \\in \\mathcal{S}(c)} S(m,s;\\tilde{w}).\n$$\n\n5) 带阈值的决策规则。给定阈值 $\\tau \\in [0,1]$，如果 $\\max_{c\\in\\mathcal{C}} S^{*}(m,c;\\tilde{w}) \\ge \\tau$，则预测 $\\hat{g}(m) = \\arg\\max_{c\\in\\mathcal{C}} S^{*}(m,c;\\tilde{w})$；否则预测 $\\hat{g}(m) = \\varnothing$。通过选择字典序最小的标识符字符串来打破 $\\arg\\max$ 中的平局。\n\n6) 评估指标。在带有基准真相 $g$ 的提及集合 $\\mathcal{M}$ 上，计算真阳性 $TP = |\\{m \\in \\mathcal{M}: g(m)\\in \\mathcal{C}, \\hat{g}(m) = g(m)\\}|$，假阳性 $FP = |\\{m \\in \\mathcal{M}: \\hat{g}(m)\\in \\mathcal{C}, \\hat{g}(m) \\neq g(m)\\}|$，以及假阴性 $FN = |\\{m \\in \\mathcal{M}: g(m)\\in \\mathcal{C}, \\hat{g}(m) = \\varnothing\\}|$。精确率和召回率分别为\n$$\nP = \\begin{cases}\n\\dfrac{TP}{TP+FP}  \\text{if } TP+FP > 0\\\\\n0  \\text{otherwise}\n\\end{cases}, \\quad\nR = \\begin{cases}\n\\dfrac{TP}{TP+FN}  \\text{if } TP+FN > 0\\\\\n0  \\text{otherwise}\n\\end{cases}.\n$$\n谐波平均值是\n$$\nF_{1} = \\begin{cases}\n\\dfrac{2PR}{P+R}  \\text{if } P+R > 0\\\\\n0  \\text{otherwise}\n\\end{cases}.\n$$\n所有这三个量都必须报告为 $[0,1]$ 范围内保留四位小数的十进制数；不要使用百分号。\n\n7) 测试套件。精确评估以下 $5$ 个测试用例，每个用例包含一个权重向量 $w$ 和一个阈值 $\\tau$：\n- 用例 1：$w=(0.6, 0.1, 0.2, 0.1)$，$\\tau=0.7$。\n- 用例 2：$w=(0.95, 0.0, 0.05, 0.0)$，$\\tau=0.95$。\n- 用例 3：$w=(0.25, 0.35, 0.35, 0.05)$，$\\tau=0.6$。\n- 用例 4：$w=(1.0, 0.0, 0.0, 0.0)$，$\\tau=1.0$。\n- 用例 5：$w=(2.0, 0.5, 0.5, 0.0)$，$\\tau=0.65$。\n\n8) 最终输出格式。您的程序应生成单行输出，其中包含用方括号括起来的逗号分隔列表形式的结果。该列表必须按上述顺序将每个用例的三元组 $(P,R,F_{1})$ 展平。例如，格式为 $[\\text{P}_{1},\\text{R}_{1},\\text{F1}_{1},\\text{P}_{2},\\text{R}_{2},\\text{F1}_{2},\\dots,\\text{P}_{5},\\text{R}_{5},\\text{F1}_{5}]$，其中每个值都四舍五入到四位小数。",
            "solution": "我们通过从实体解析的基本定义中推导出一个归一化和匹配流程，然后将其转化为一个具有可量化评估的算法来构建解决方案。\n\n基础。我们从以下经过充分检验的定义开始：字符串归一化在不改变身份的情况下减少表层差异；基于分词的相似度（如 Jaccard 相似度）衡量集合之间的重叠；编辑距离量化将一个字符串转换为另一个字符串所需的最小操作数；分类指标（如精确率和召回率）衡量映射的正确性和完整性。对于生物医学中的自由文本提及集合，规范标识符（例如，HUGO Gene Nomenclature Committee 和 DrugBank）各自有多个同义词，这导致了需要仔细归一化的同义和近义现象。鉴于知识图谱构建需要将提及链接到规范节点，我们必须实现一个确定性的决策规则，通过阈值参数在错误匹配和遗漏匹配之间进行权衡。\n\n归一化设计。令 $N(\\cdot)$ 是一个执行小写转换、缩写扩展和非字母数字字符剥离的函数。其基本原理是，对于基因符号和药物名称，字母数字核心承载了大部分区分性内容，而标点和空格通常是书写过程中的产物。令 $T(\\cdot)$ 将字符串在经过小写转换、缩写扩展、标点到空格映射和停用词移除后，映射到分词集合。停用词集合包括通用的生物医学词汇，这些词汇会夸大重叠度而没有增加区分价值，例如 $\\{\\text{\"protein\"}, \\text{\"receptor\"}, \\text{\"acid\"}, \\text{\"serine\"}, \\text{\"threonine\"}, \\text{\"alpha\"}, \\text{\"beta\"}, \\text{\"inhibitor\"}\\}$。这些被视为非信息性分词，以便 Jaccard 相似度能更强调像 $\\text{\"p53\"}$ 和 $\\text{\"epidermal\"}$ 这样的特定标记。\n\n特征构建。对于一个提及 $m$ 和候选实体 $c$ 的一个同义词 $s$，我们定义四个特征：\n- $f_{\\mathrm{e}}(m,s) = \\mathbf{1}[N(m)=N(s)]$ 捕捉归一化后稳健的精确等价性，这是一个高精确率的信号。\n- $f_{\\mathrm{p}}(m,s) = \\mathbf{1}[N(m)=N(p(c))]$ 编码了偏好标签在精确匹配时具有额外的可靠性（例如，官方符号）。\n- $f_{\\mathrm{j}}(m,s)$ 是分词集合 $T(m)$ 和 $T(s)$ 之间的 Jaccard 相似度，定义为 $|A\\cap B|/|A\\cup B|$，这是一个范围在 $[0,1]$ 内的度量，它能稳健地总结不受词序影响的重叠。\n- $f_{\\mathrm{d}}(m,s) = 1 - D(N(m),N(s))/\\max\\{|N(m)|,|N(s)|\\}$ 是一个基于 Levenshtein 的归一化相似度，其范围也在 $[0,1]$ 内，它奖励近似匹配，对于拼写错误（如 $\\text{\"ibuprfen\"}$ 对比 $\\text{\"ibuprofen\"}$）尤其有用。\n\n线性评分。我们使用一个非负权重向量 $w=(w_{\\mathrm{e}},w_{\\mathrm{j}},w_{\\mathrm{d}},w_{\\mathrm{p}})$ 来构建这些特征的凸组合。为确保有原则的可解释性和有界性，我们将权重归一化到概率单纯形：当 $\\sum_{i}w_{i} > 0$ 时，$\\tilde{w} = w / \\sum_{i} w_{i}$，否则使用均匀权重 $\\tilde{w}=(1/4,1/4,1/4,1/4)$。每个同义词的得分是 $S(m,s;\\tilde{w}) = \\tilde{w}_{\\mathrm{e}} f_{\\mathrm{e}} + \\tilde{w}_{\\mathrm{j}} f_{\\mathrm{j}} + \\tilde{w}_{\\mathrm{d}} f_{\\mathrm{d}} + \\tilde{w}_{\\mathrm{p}} f_{\\mathrm{p}}$。每个实体的得分 $S^{*}(m,c;\\tilde{w})$ 是其所有同义词得分中的最大值。这个最大值操作符的合理性在于其逻辑语义：一个实体应因其最佳匹配的别名而获得评分。\n\n决策规则与权衡。当且仅当最大得分超过阈值 $\\tau\\in[0,1]$ 时，我们将最大化 $S^{*}(m,c;\\tilde{w})$ 的参数作为预测 $\\hat{g}(m)$；否则我们放弃预测，即预测为 $\\varnothing$。这创建了一条可调的精确率-召回率曲线：较高的 $\\tau$ 通过消除低置信度的匹配来提高精确率，但代价是牺牲召回率；而较低的 $\\tau$ 通过允许更多的近似匹配来提高召回率，但可能在同义和分词重叠的情况下带来更多假阳性。按字典序打破平局确保了确定性。\n\n特征计算。我们使用分词集合计算 $f_{\\mathrm{j}}$，并约定如果两个分词集合都为空，则相似度为 $0$，反映了没有证据。我们通过动态规划计算 Levenshtein 距离 $D(\\cdot,\\cdot)$，其时间复杂度为 $O(|x|\\cdot|y|)$，考虑到生物医学字符串较短，这是可行的。\n\n评估指标。使用基准真相函数 $g$，我们根据 $\\hat{g}(m)$ 和 $g(m)$ 将真阳性 $TP$、假阳性 $FP$ 和假阴性 $FN$ 计为集合的基数。当分母为正时，精确率 $P$ 和召回率 $R$ 分别计算为比率 $TP/(TP+FP)$ 和 $TP/(TP+FN)$，否则设为 $0$。谐波平均值 $F_{1} = 2PR/(P+R)$ 提供了一个单一数值的摘要，当 $P+R=0$ 时设为 $0$。\n\n边缘情况和边界条件。权重向量被重新归一化以处理总和不为 $1$ 的输入（用例 5），全零权重默认为均匀分布。阈值 $\\tau=1.0$（用例 4）要求完美得分，用于测试最严格的精确率偏好。拼写错误和连字符（例如 $\\text{\"erbb-1\"}$、$\\text{\"AKT-1\"}$、$\\text{\"ibuprfen\"}$）通过 $N(\\cdot)$ 和 $f_{\\mathrm{d}}$ 来处理。像 $\\text{\"EGFR inhibitor\"}$ 这样带有上下文的提及，其设计意图是展示分词重叠，但在足够高的 $\\tau$ 下应被过滤掉，这说明了在同义词压力下的精确率。\n\n算法步骤。\n- 对每个同义词 $s$ 预计算其 $N(s)$ 和 $T(s)$，并对每个实体 $c$ 预计算其偏好归一化标签 $N(p(c))$。\n- 对每个提及 $m$，计算 $N(m)$ 和 $T(m)$，然后对每个实体 $c$，通过对每个 $s\\in \\mathcal{S}(c)$ 评估特征并取最大值来计算 $S^{*}(m,c;\\tilde{w})$。\n- 使用指定的阈值规则 $\\tau$ 和平局打破规则来选择 $\\hat{g}(m)$。\n- 汇总计数 $TP$、$FP$、$FN$，然后计算 $P$、$R$ 和 $F_{1}$。\n- 对 5 个权重-阈值用例重复此过程，并输出展平的列表 $[P_{1},R_{1},F_{1,1},\\dots,P_{5},R_{5},F_{1,5}]$，四舍五入到四位小数。\n\n该设计直接操作化了核心原则：确定性归一化、互补相似性信号的凸组合，以及用于表达同义和近义情况下精确率-召回率权衡的阈值决策理论。提供的测试套件涵盖了一个平衡的用例、一个精确匹配主导的高阈值用例、一个偏向召回率的用例、一个要求完美匹配的边界用例以及一个重新归一化的用例，确保了对关键行为的覆盖。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef normalize_weights(w):\n    w = np.array(w, dtype=float)\n    s = w.sum()\n    if s > 0:\n        return w / s\n    # default to uniform if all-zero\n    return np.ones_like(w) / len(w)\n\ndef abbrev_expand_tokens(tokens, abbr_map):\n    # Expand tokens using abbreviation map (inputs and keys lowercase).\n    out = []\n    for tok in tokens:\n        if tok in abbr_map:\n            # Expansion may introduce multiple space-separated tokens.\n            expanded = abbr_map[tok].lower().split()\n            out.extend(expanded)\n        else:\n            out.append(tok)\n    return out\n\ndef normalize_string_for_match(s, abbr_map):\n    # Lowercase, tokenize by replacing non-alphanumeric with space, expand, then remove non-alphanumeric entirely.\n    s_low = s.lower()\n    # Replace non-alphanumeric with space to tokenize\n    chars = []\n    for ch in s_low:\n        if ch.isalnum():\n            chars.append(ch)\n        else:\n            chars.append(' ')\n    tokenized = ''.join(chars).split()\n    expanded = abbrev_expand_tokens(tokenized, abbr_map)\n    # Remove non-alphanumeric and join: expanded are alphanumeric tokens already\n    return ''.join(''.join([c for c in tok if c.isalnum()]) for tok in expanded)\n\ndef token_set(s, abbr_map, stopwords):\n    s_low = s.lower()\n    # Replace non-alphanumeric with space to tokenize\n    chars = []\n    for ch in s_low:\n        if ch.isalnum():\n            chars.append(ch)\n        else:\n            chars.append(' ')\n    tokenized = ''.join(chars).split()\n    expanded = abbrev_expand_tokens(tokenized, abbr_map)\n    # Remove stopwords\n    toks = [tok for tok in expanded if tok and tok not in stopwords]\n    return set(toks)\n\ndef jaccard(a_set, b_set):\n    if not a_set and not b_set:\n        return 0.0\n    inter = len(a_set  b_set)\n    union = len(a_set | b_set)\n    return inter / union if union > 0 else 0.0\n\ndef levenshtein(a, b):\n    # Classic DP, space-optimized\n    la, lb = len(a), len(b)\n    if la == 0:\n        return lb\n    if lb == 0:\n        return la\n    # Ensure a is shorter\n    if la > lb:\n        a, b = b, a\n        la, lb = lb, la\n    prev = list(range(lb + 1))\n    for i in range(1, la + 1):\n        curr = [i] + [0] * lb\n        ca = a[i - 1]\n        for j in range(1, lb + 1):\n            cb = b[j - 1]\n            cost = 0 if ca == cb else 1\n            curr[j] = min(\n                curr[j - 1] + 1,      # insertion\n                prev[j] + 1,          # deletion\n                prev[j - 1] + cost    # substitution\n            )\n        prev = curr\n    return prev[lb]\n\ndef normalized_lev_sim(a, b):\n    # a and b are normalized strings\n    maxlen = max(len(a), len(b))\n    if maxlen == 0:\n        return 1.0\n    d = levenshtein(a, b)\n    return 1.0 - (d / maxlen)\n\ndef score_features(m_norm, m_tokens, s_norm, s_tokens, pref_norm):\n    # Compute features: f_e, f_j, f_d, f_p in that order mapping to weights [we, wj, wd, wp]\n    f_e = 1.0 if m_norm == s_norm else 0.0\n    f_p = 1.0 if m_norm == pref_norm else 0.0\n    f_j = jaccard(m_tokens, s_tokens)\n    f_d = normalized_lev_sim(m_norm, s_norm)\n    return np.array([f_e, f_j, f_d, f_p], dtype=float)\n\ndef predict_for_mention(mention, entities, syn_data, weight_vec, tau, abbr_map, stopwords):\n    # Precompute mention normalized and tokens\n    m_norm = normalize_string_for_match(mention, abbr_map)\n    m_tokens = token_set(mention, abbr_map, stopwords)\n    max_score = -1.0\n    best_ids = []\n    for cid, data in syn_data.items():\n        # data: dict with keys 'syn_norms', 'syn_tokens', 'pref_norm'\n        syn_norms = data['syn_norms']\n        syn_tokens = data['syn_tokens']\n        pref_norm = data['pref_norm']\n        # Compute max over synonyms\n        best_c_score = -1.0\n        for s_norm, s_tok in zip(syn_norms, syn_tokens):\n            feats = score_features(m_norm, m_tokens, s_norm, s_tok, pref_norm)\n            s = float(np.dot(weight_vec, feats))\n            if s > best_c_score:\n                best_c_score = s\n        # Track best overall\n        if best_c_score > max_score:\n            max_score = best_c_score\n            best_ids = [cid]\n        elif best_c_score == max_score:\n            best_ids.append(cid)\n    # Decision\n    if max_score >= tau and best_ids:\n        # tie-break lex smallest\n        return sorted(best_ids)[0]\n    else:\n        return None\n\ndef evaluate(weight_vec_raw, tau, entities, mentions, abbr_map, stopwords):\n    w = normalize_weights(weight_vec_raw)\n    # Precompute synonym data\n    syn_data = {}\n    for cid, info in entities.items():\n        syns = info['synonyms']\n        pref = info['preferred']\n        syn_norms = [normalize_string_for_match(s, abbr_map) for s in syns]\n        syn_tokens = [token_set(s, abbr_map, stopwords) for s in syns]\n        pref_norm = normalize_string_for_match(pref, abbr_map)\n        syn_data[cid] = {\n            'syn_norms': syn_norms,\n            'syn_tokens': syn_tokens,\n            'pref_norm': pref_norm\n        }\n    TP = 0\n    FP = 0\n    FN = 0\n    for mention, truth in mentions:\n        pred = predict_for_mention(mention, entities, syn_data, w, tau, abbr_map, stopwords)\n        if truth is None:\n            if pred is not None:\n                FP += 1\n        else:\n            if pred is None:\n                FN += 1\n            elif pred == truth:\n                TP += 1\n            else:\n                FP += 1\n    P = TP / (TP + FP) if (TP + FP) > 0 else 0.0\n    R = TP / (TP + FN) if (TP + FN) > 0 else 0.0\n    F1 = (2 * P * R) / (P + R) if (P + R) > 0 else 0.0\n    return P, R, F1\n\ndef solve():\n    # Define entities and synonyms\n    entities = {\n        \"HGNC:11998\": {\n            \"synonyms\": [\"TP53\", \"p53\", \"tumor protein p53\"],\n            \"preferred\": \"TP53\"\n        },\n        \"HGNC:3236\": {\n            \"synonyms\": [\"EGFR\", \"epidermal growth factor receptor\", \"ERBB1\"],\n            \"preferred\": \"EGFR\"\n        },\n        \"HGNC:391\": {\n            \"synonyms\": [\"AKT1\", \"PKB\", \"RAC-alpha serine/threonine-protein kinase\"],\n            \"preferred\": \"AKT1\"\n        },\n        \"DrugBank:DB00316\": {\n            \"synonyms\": [\"acetaminophen\", \"paracetamol\", \"APAP\"],\n            \"preferred\": \"acetaminophen\"\n        },\n        \"DrugBank:DB00945\": {\n            \"synonyms\": [\"aspirin\", \"acetylsalicylic acid\", \"ASA\"],\n            \"preferred\": \"aspirin\"\n        },\n        \"DrugBank:DB01050\": {\n            \"synonyms\": [\"ibuprofen\"],\n            \"preferred\": \"ibuprofen\"\n        }\n    }\n    # Mentions and ground truth\n    mentions = [\n        (\"TP53\", \"HGNC:11998\"),\n        (\"p53\", \"HGNC:11998\"),\n        (\"tumor prot p53\", \"HGNC:11998\"),\n        (\"p 53\", \"HGNC:11998\"),\n        (\"EGFR\", \"HGNC:3236\"),\n        (\"ERBB1\", \"HGNC:3236\"),\n        (\"erbb-1\", \"HGNC:3236\"),\n        (\"AKT-1\", \"HGNC:391\"),\n        (\"PKB\", \"HGNC:391\"),\n        (\"acetaminophen\", \"DrugBank:DB00316\"),\n        (\"paracetamol\", \"DrugBank:DB00316\"),\n        (\"APAP\", \"DrugBank:DB00316\"),\n        (\"aspirin\", \"DrugBank:DB00945\"),\n        (\"ASA\", \"DrugBank:DB00945\"),\n        (\"acetylsalicylic acid\", \"DrugBank:DB00945\"),\n        (\"ibuprofen\", \"DrugBank:DB01050\"),\n        (\"ibuprfen\", \"DrugBank:DB01050\"),\n        (\"randomword\", None),\n        (\"EGFR inhibitor\", None),\n    ]\n    # Abbreviation map and stopwords\n    abbr_map = {\n        \"asa\": \"acetylsalicylic acid\",\n        \"apap\": \"acetaminophen\",\n    }\n    stopwords = {\n        \"protein\", \"receptor\", \"acid\", \"serine\", \"threonine\", \"alpha\", \"beta\", \"inhibitor\"\n    }\n    # Test cases: (weights, tau)\n    test_cases = [\n        ([0.6, 0.1, 0.2, 0.1], 0.7),\n        ([0.95, 0.0, 0.05, 0.0], 0.95),\n        ([0.25, 0.35, 0.35, 0.05], 0.6),\n        ([1.0, 0.0, 0.0, 0.0], 1.0),\n        ([2.0, 0.5, 0.5, 0.0], 0.65),\n    ]\n    results = []\n    for w, tau in test_cases:\n        P, R, F1 = evaluate(w, tau, entities, mentions, abbr_map, stopwords)\n        # Round to four decimals\n        results.extend([round(P + 1e-12, 4), round(R + 1e-12, 4), round(F1 + 1e-12, 4)])\n    # Format as requested: single line, comma-separated in brackets.\n    # Ensure fixed 4-decimal formatting.\n    formatted = \"[\" + \",\".join(f\"{x:.4f}\" for x in results) + \"]\"\n    print(formatted)\n\nif __name__ == \"__main__\":\n    solve()\n```"
        },
        {
            "introduction": "在构建知识图谱之后，分析其结构特性是理解其内在规律的关键。本练习将带您探索图谱的基本网络属性，例如节点的度分布。您将学习如何从给定的三元组集合中计算出度和入度，并应用统计模型（如幂律分布拟合）来揭示图谱拓扑结构背后重要的生物医学现象，例如药物的多靶点效应（polypharmacology）。",
            "id": "4577536",
            "problem": "一个生物医学资源描述框架 (RDF) 知识图谱由类型化节点和有向边组成，表示为 $(\\text{subject}, \\text{predicate}, \\text{object})$ 形式的三元组。考虑以下一小组科学上合理的三元组，其捕获了药物-蛋白质结合、药物-疾病适应症和药物-通路参与，以及指向药物的关系：\n\n($D_A$, \\text{binds}, $P_1$); ($D_A$, \\text{binds}, $P_2$); ($D_A$, \\text{binds}, $P_3$); ($D_A$, \\text{treats}, $Dis_1$); ($D_A$, \\text{participates\\_in}, $PW_1$)\n\n($D_B$, \\text{binds}, $P_2$); ($D_B$, \\text{binds}, $P_3$); ($D_B$, \\text{treats}, $Dis_1$); ($D_B$, \\text{treats}, $Dis_2$)\n\n($D_C$, \\text{binds}, $P_4$); ($D_C$, \\text{binds}, $P_5$)\n\n($D_D$, \\text{binds}, $P_1$); ($D_D$, \\text{binds}, $P_2$); ($D_D$, \\text{binds}, $P_3$); ($D_D$, \\text{binds}, $P_4$); ($D_D$, \\text{treats}, $Dis_2$); ($D_D$, \\text{treats}, $Dis_3$)\n\n($D_E$, \\text{binds}, $P_1$)\n\n($D_F$, \\text{treats}, $Dis_3$)\n\n($P_1$, \\text{inhibited\\_by}, $D_A$); ($Dis_1$, \\text{has\\_contraindicated\\_drug}, $D_B$); ($Dis_2$, \\text{has\\_indicated\\_drug}, $D_D$); ($PW_1$, \\text{has\\_participating\\_drug}, $D_A$); ($P_3$, \\text{activated\\_by}, $D_D$); ($Dis_3$, \\text{has\\_contraindicated\\_drug}, $D_A$); ($P_4$, \\text{inhibited\\_by}, $D_C$).\n\n对于每个药物节点 $d \\in \\{D_A, D_B, D_C, D_D, D_E, D_F\\}$，将其出度 $k_{\\text{out}}(d)$ 定义为 $d$ 作为主语出现的三元组数量，将其入度 $k_{\\text{in}}(d)$ 定义为 $d$ 作为宾语出现的三元组数量。根据标准的相对频率定义，构建药物节点上的经验出度分布 $p_{\\text{out}}(k)$，并同样构建经验入度分布 $p_{\\text{in}}(k)$。\n\n假设药物节点的出度尾部在阈值 $x_{\\min} = 2$ 之上服从连续幂律分布，即对于 $k \\ge x_{\\min}$，尾部密度满足 $p(k) \\propto k^{-\\alpha}$，其中 $\\alpha$ 为某个指数。仅使用概率密度的基本定义和最大似然原理，推导连续幂律尾部的指数 $\\alpha$ 的最大似然估计量，并在此图中当 $x_{\\min} = 2$ 时，为药物出度计算其值。将 $\\alpha$ 的最终数值估计四舍五入到 4 位有效数字。在你的推理中，基于所构建的分布，解释重尾的 $p_{\\text{out}}(k)$ 分布对于此数据集中的多重药理学意味着什么。以无单位的形式表达最终数值答案。",
            "solution": "首先验证问题，以确保其有科学依据、提法恰当且客观。\n\n### 步骤 1：提取已知信息\n所提供的数据包括一组 RDF 三元组、节点度的定义以及出度分布的建模假设。\n\n**RDF 三元组 (边):**\n*   ($D_A$, \\text{binds}, $P_1$); ($D_A$, \\text{binds}, $P_2$); ($D_A$, \\text{binds}, $P_3$); ($D_A$, \\text{treats}, $Dis_1$); ($D_A$, \\text{participates\\_in}, $PW_1$)\n*   ($D_B$, \\text{binds}, $P_2$); ($D_B$, \\text{binds}, $P_3$); ($D_B$, \\text{treats}, $Dis_1$); ($D_B$, \\text{treats}, $Dis_2$)\n*   ($D_C$, \\text{binds}, $P_4$); ($D_C$, \\text{binds}, $P_5$)\n*   ($D_D$, \\text{binds}, $P_1$); ($D_D$, \\text{binds}, $P_2$); ($D_D$, \\text{binds}, $P_3$); ($D_D$, \\text{binds}, $P_4$); ($D_D$, \\text{treats}, $Dis_2$); ($D_D$, \\text{treats}, $Dis_3$)\n*   ($D_E$, \\text{binds}, $P_1$)\n*   ($D_F$, \\text{treats}, $Dis_3$)\n*   ($P_1$, \\text{inhibited\\_by}, $D_A$); ($Dis_1$, \\text{has\\_contraindicated\\_drug}, $D_B$); ($Dis_2$, \\text{has\\_indicated\\_drug}, $D_D$); ($PW_1$, \\text{has\\_participating\\_drug}, $D_A$); ($P_3$, \\text{activated\\_by}, $D_D$); ($Dis_3$, \\text{has\\_contraindicated\\_drug}, $D_A$); ($P_4$, \\text{inhibited\\_by}, $D_C$)\n\n**定义和变量：**\n*   药物节点集: $d \\in \\{D_A, D_B, D_C, D_D, D_E, D_F\\}$\n*   出度 $k_{\\text{out}}(d)$: $d$ 作为主语的三元组数量。\n*   入度 $k_{\\text{in}}(d)$: $d$ 作为宾语的三元组数量。\n*   经验分布 $p_{\\text{out}}(k)$ 和 $p_{\\text{in}}(k)$ 由相对频率定义。\n\n**建模假设和任务：**\n*   药物节点的出度尾部在 $k \\ge x_{\\min}$ 时服从连续幂律分布。\n*   幂律概率密度函数 (PDF) 为 $p(k) \\propto k^{-\\alpha}$。\n*   尾部的最小值为 $x_{\\min} = 2$。\n*   推导 $\\alpha$ 的最大似然估计量 (MLE)。\n*   计算药物出度的 $\\alpha$ 值，并四舍五入到 4 位有效数字。\n*   在多重药理学的背景下解释结果。\n\n### 步骤 2：使用提取的已知信息进行验证\n该问题在网络理论和生物信息学方面具有科学依据。RDF 知识图谱、度分布、幂律和最大似然估计等概念都是标准概念。其在多重药理学上的应用是一个成熟的研究领域。问题提法恰当，提供了得出唯一解所需的所有数据和定义。语言客观且正式。对于离散量（节点度）采用连续幂律分布的假设，是一种标准且被广泛接受的近似方法，特别是在推导估计量时用于简化计算。这不构成科学缺陷，而是一种明确的建模选择。因此，该问题被认定为有效。\n\n### 步骤 3：结论与行动\n问题有效。将提供完整解答。\n\n### 解答推导\n\n首先，我们根据提供的三元组计算每个药物节点的出度和入度。\n\n**出度 ($k_{\\text{out}}$):**\n*   $k_{\\text{out}}(D_A) = 5$ (是 $5$ 个三元组的主语)\n*   $k_{\\text{out}}(D_B) = 4$ (是 $4$ 个三元组的主语)\n*   $k_{\\text{out}}(D_C) = 2$ (是 $2$ 个三元组的主语)\n*   $k_{\\text{out}}(D_D) = 6$ (是 $6$ 个三元组的主语)\n*   $k_{\\text{out}}(D_E) = 1$ (是 $1$ 个三元组的主语)\n*   $k_{\\text{out}}(D_F) = 1$ (是 $1$ 个三元组的主语)\n出度集合为 $\\{5, 4, 2, 6, 1, 1\\}$。药物节点总数为 $N=6$。\n经验出度分布 $p_{\\text{out}}(k)$ 为：\n*   $p_{\\text{out}}(1) = \\frac{2}{6} = \\frac{1}{3}$\n*   $p_{\\text{out}}(2) = \\frac{1}{6}$\n*   $p_{\\text{out}}(4) = \\frac{1}{6}$\n*   $p_{\\text{out}}(5) = \\frac{1}{6}$\n*   $p_{\\text{out}}(6) = \\frac{1}{6}$\n*   $p_{\\text{out}}(k) = 0$ 对于 k 的其他值。\n\n**入度 ($k_{\\text{in}}$):**\n*   $k_{\\text{in}}(D_A) = 3$ (是 $3$ 个三元组的宾语)\n*   $k_{\\text{in}}(D_B) = 1$ (是 $1$ 个三元组的宾语)\n*   $k_{\\text{in}}(D_C) = 1$ (是 $1$ 个三元组的宾语)\n*   $k_{\\text{in}}(D_D) = 2$ (是 $2$ 个三元组的宾语)\n*   $k_{\\text{in}}(D_E) = 0$ (是 $0$ 个三元组的宾语)\n*   $k_{\\text{in}}(D_F) = 0$ (是 $0$ 个三元组的宾语)\n入度集合为 $\\{3, 1, 1, 2, 0, 0\\}$。\n经验入度分布 $p_{\\text{in}}(k)$ 为：\n*   $p_{\\text{in}}(0) = \\frac{2}{6} = \\frac{1}{3}$\n*   $p_{\\text{in}}(1) = \\frac{2}{6} = \\frac{1}{3}$\n*   $p_{\\text{in}}(2) = \\frac{1}{6}$\n*   $p_{\\text{in}}(3) = \\frac{1}{6}$\n*   $p_{\\text{in}}(k) = 0$ 对于 k 的其他值。\n\n接下来，我们推导连续幂律分布的指数 $\\alpha$ 的最大似然估计量。其概率密度函数 (PDF) 在 $k \\ge x_{\\min}$ 时由 $p(k) \\propto k^{-\\alpha}$ 给出。\n首先，我们必须对 PDF 进行归一化。令 $p(k) = Ck^{-\\alpha}$。\n$$ \\int_{x_{\\min}}^{\\infty} Ck^{-\\alpha} \\, dk = 1 $$\n$$ C \\left[ \\frac{k^{-\\alpha+1}}{1-\\alpha} \\right]_{x_{\\min}}^{\\infty} = 1 $$\n为了收敛，我们需要 $1-\\alpha   0$，即 $\\alpha > 1$。在此条件下，$\\infty$ 处的项为 $0$。\n$$ C \\left( 0 - \\frac{x_{\\min}^{1-\\alpha}}{1-\\alpha} \\right) = 1 \\implies C = (\\alpha-1)x_{\\min}^{\\alpha-1} $$\n归一化后的 PDF 为 $p(k|\\alpha, x_{\\min}) = (\\alpha-1)x_{\\min}^{\\alpha-1} k^{-\\alpha}$。\n\n给定一组 $n$ 个观测值 $\\{k_i\\}$，其中每个 $k_i \\ge x_{\\min}$，似然函数为：\n$$ L(\\alpha) = \\prod_{i=1}^{n} p(k_i|\\alpha, x_{\\min}) = \\prod_{i=1}^{n} (\\alpha-1)x_{\\min}^{\\alpha-1} k_i^{-\\alpha} $$\n对数似然 $\\mathcal{L}(\\alpha) = \\ln(L(\\alpha))$ 更容易最大化：\n$$ \\mathcal{L}(\\alpha) = \\sum_{i=1}^{n} \\ln\\left( (\\alpha-1)x_{\\min}^{\\alpha-1} k_i^{-\\alpha} \\right) $$\n$$ \\mathcal{L}(\\alpha) = \\sum_{i=1}^{n} \\left[ \\ln(\\alpha-1) + (\\alpha-1)\\ln(x_{\\min}) - \\alpha\\ln(k_i) \\right] $$\n$$ \\mathcal{L}(\\alpha) = n\\ln(\\alpha-1) + n(\\alpha-1)\\ln(x_{\\min}) - \\alpha\\sum_{i=1}^{n}\\ln(k_i) $$\n为了求最大值，我们将关于 $\\alpha$ 的导数设为零：\n$$ \\frac{d\\mathcal{L}}{d\\alpha} = \\frac{n}{\\alpha-1} + n\\ln(x_{\\min}) - \\sum_{i=1}^{n}\\ln(k_i) = 0 $$\n求解估计量 $\\hat{\\alpha}$：\n$$ \\frac{n}{\\hat{\\alpha}-1} = \\sum_{i=1}^{n}\\ln(k_i) - n\\ln(x_{\\min}) = \\sum_{i=1}^{n} \\ln\\left(\\frac{k_i}{x_{\\min}}\\right) $$\n$$ \\hat{\\alpha}-1 = n \\left( \\sum_{i=1}^{n} \\ln\\left(\\frac{k_i}{x_{\\min}}\\right) \\right)^{-1} $$\n$$ \\hat{\\alpha} = 1 + n \\left( \\sum_{i=1}^{n} \\ln\\left(\\frac{k_i}{x_{\\min}}\\right) \\right)^{-1} $$\n这就是 $\\alpha$ 的最大似然估计量 (MLE)。\n\n现在，我们将此估计量应用于药物出度数据。所有出度的集合为 $\\{5, 4, 2, 6, 1, 1\\}$。阈值为 $x_{\\min} = 2$。我们选择数据点 $k_i \\ge x_{\\min}$：$\\{5, 4, 2, 6\\}$。这些数据点的数量为 $n=4$。\n我们计算分母中的和：\n$$ \\sum_{i=1}^{4} \\ln\\left(\\frac{k_i}{x_{\\min}}\\right) = \\ln\\left(\\frac{5}{2}\\right) + \\ln\\left(\\frac{4}{2}\\right) + \\ln\\left(\\frac{2}{2}\\right) + \\ln\\left(\\frac{6}{2}\\right) $$\n$$ = \\ln(2.5) + \\ln(2) + \\ln(1) + \\ln(3) $$\n使用性质 $\\ln(a) + \\ln(b) = \\ln(ab)$ 以及 $\\ln(1)=0$：\n$$ = \\ln(2.5 \\times 2 \\times 1 \\times 3) = \\ln(15) $$\n将此代入 MLE 公式：\n$$ \\hat{\\alpha} = 1 + \\frac{4}{\\ln(15)} $$\n数值上，$\\ln(15) \\approx 2.70805$。\n$$ \\hat{\\alpha} \\approx 1 + \\frac{4}{2.70805} \\approx 1 + 1.47707 \\approx 2.47707 $$\n四舍五入到 4 位有效数字，我们得到 $\\hat{\\alpha} = 2.477$。\n\n**解释：**\n药物 $d$ 的出度 $k_{\\text{out}}(d)$ 代表了从它出发的关系数量，例如与蛋白质结合、治疗疾病或参与通路。重尾出度分布，如指数 $\\hat{\\alpha} \\approx 2.477$（真实世界网络中的典型值）的幂律所示，意味着大多数药物只有少数几个连接，但少数“枢纽”药物拥有非常大量的连接。在此数据集中，药物 $D_A$ ($k_{\\text{out}}=5$) 和 $D_D$ ($k_{\\text{out}}=6$) 就是这样的枢纽。\n多重药理学是单个药物作用于多个分子靶点的现象。'binds'（结合）关系是这种现象的直接体现。药物 $D_A$ 和 $D_D$ 分别与 $3$ 个和 $4$ 个蛋白质结合，这例证了多重药理学。$p_{\\text{out}}(k)$ 的重尾性质表明，这种多重药理学现象并非均匀分布，而是少数几个高度连接的药物的特征。这对药物发现具有深远的影响，表明某些药物可能通过多靶点作用实现疗效，但同时也可能有更高的脱靶副作用倾向。",
            "answer": "$$\n\\boxed{2.477}\n$$"
        },
        {
            "introduction": "知识图谱最强大的应用之一是链接预测，例如预测新的药物-疾病关联。这项练习为您提供了一个评估链接预测模型性能的实践指南。您将学习如何计算和解读一系列标准的排名和分类评估指标，如 Hits@$k$、平均倒数排名（MRR）和 AUC，并特别关注在评估过程中必须使用的“过滤”协议（filtered protocol），这是该领域的标准做法。",
            "id": "4577523",
            "problem": "一个生物医学知识图谱 (KG) 编码了生物医学实体（如药物、疾病和基因）之间的类型化关系。考虑关系“药物治疗疾病”的链接预测。对于两个头-关系查询 $(h,r,?)$，其中 $r = \\text{treats}$，一个模型会为每个候选尾实体 $t$ 返回一个实值分数 $s(h,r,t) \\in [0,1]$，该分数表明 $(h,r,t)$ 是一个真实三元组的置信度。评估使用过滤协议：对于一个带有预留测试尾实体 $t^\\star$ 的查询 $(h,r,?)$，在计算 $t^\\star$ 的排名之前，任何其他使得 $(h,r,t)$ 在知识图谱中（在任何数据划分中）已知为真的 $t \\neq t^\\star$ 都会从候选集中移除。\n\n现给定两个查询及其候选集和分数：\n- 查询 $1$：$(d_A,\\text{treats},?)$，候选集为 $\\{z_1,z_2,z_3,z_4\\}$，分数为 $s(d_A,\\text{treats},z_1)=0.9$, $s(d_A,\\text{treats},z_2)=0.8$, $s(d_A,\\text{treats},z_3)=0.85$, $s(d_A,\\text{treats},z_4)=0.1$。预留的测试三元组是 $(d_A,\\text{treats},z_2)$。此外，$(d_A,\\text{treats},z_3)$ 是在训练中已知的知识图谱中的真实三元组，在排名时必须被过滤掉。\n- 查询 $2$：$(d_B,\\text{treats},?)$，候选集为 $\\{z_5,z_6,z_7\\}$，分数为 $s(d_B,\\text{treats},z_5)=0.7$, $s(d_B,\\text{treats},z_6)=0.6$, $s(d_B,\\text{treats},z_7)=0.2$。预留的测试三元组是 $(d_B,\\text{treats},z_6)$，并且对于 $(d_B,\\text{treats},?)$ 没有其他已知的真实尾实体。\n\n对于基于阈值的分类指标，聚合两个查询中的所有候选边，并使用固定的决策阈值 $\\tau=0.5$：如果 $s(h,r,t)\\ge \\tau$，则预测为正，否则预测为负。对于真实标签，将 $(d_A,\\text{treats},z_2)$、$(d_A,\\text{treats},z_3)$ 和 $(d_B,\\text{treats},z_6)$ 视为正例 ($y=1$) ，所有其他候选边视为负例 ($y=0$)。\n\n选择一个选项，该选项从基本定义出发严格定义了每个指标，并在过滤协议下得出了正确的数值：\n- 查询的 Hits at $k$ (Hits@$k$)。\n- 平均倒数排名 (MRR)。\n- 受试者工作特征曲线下面积 (AUC-ROC)。\n- 在阈值 $\\tau$ 下的精确率 (Precision)、召回率 (Recall) 和 $F1$ 分数。\n\nA. Hits@$k$ 是所有查询中，预留的 $t^\\star$ 的过滤后排名不大于 $k$ 的指示函数的平均值。MRR 是所有查询中 $t^\\star$ 的过滤后排名的倒数的平均值。AUC-ROC 是随机选择的正边的分数高于随机选择的负边的分数的概率（等价于当阈值变化时，真阳性率对假阳性率曲线下的面积）。精确率是 $\\mathrm{TP}/(\\mathrm{TP}+\\mathrm{FP})$，召回率是 $\\mathrm{TP}/(\\mathrm{TP}+\\mathrm{FN})$，而 $F1$ 是 $2\\cdot\\mathrm{Precision}\\cdot\\mathrm{Recall}/(\\mathrm{Precision}+\\mathrm{Recall})$。在给定数据下：两个查询的过滤后排名均为 $2$，因此 Hits@$1=0$ 且 Hits@$3=1$，并且 $\\mathrm{MRR}=(\\frac{1}{2}+\\frac{1}{2})/2=0.5$。在所有候选者中，正例有三个，负例有四个；$\\mathrm{AUC-ROC}$ 等于 $2/3$。当 $\\tau=0.5$ 时，$\\mathrm{TP}=3$，$\\mathrm{FP}=2$，$\\mathrm{FN}=0$，所以精确率 (Precision) $=3/5=0.6$，召回率 (Recall) $=1$，并且 $F1=2\\cdot 0.6\\cdot 1/(0.6+1)=3/4=0.75$。\n\nB. Hits@$k$ 和 MRR 是在每个查询的原始（未过滤）候选列表上计算的。AUC-ROC 的定义如 A 项所述，并且对于给定数据其值等于 $2/3$。当 $\\tau=0.5$ 时，精确率 (Precision) $=3/5$，召回率 (Recall) $=1$，并且 $F1=3/4$。使用原始排名：查询 $1$ 的排名是 $3$，查询 $2$ 的排名是 $2$，所以 Hits@$1=0$，Hits@$3=1$，并且 $\\mathrm{MRR}=(\\frac{1}{3}+\\frac{1}{2})/2=5/12\\approx 0.4167$。\n\nC. Hits@$k$ 是排名前 $k$ 的候选者中真实候选项的比例在所有查询中的平均值。MRR 是排名前 $k$ 的真实候选者数量的倒数的平均值。AUC 是精确率-召回率曲线下面积，在此约等于 $0.8$。当 $\\tau=0.5$ 时，精确率 (Precision) 等于 $\\mathrm{TP}/(\\mathrm{TP}+\\mathrm{FN})$，召回率 (Recall) 等于 $\\mathrm{TP}/(\\mathrm{TP}+\\mathrm{FP})$；$F1$ 是它们的调和平均数。\n\nD. Hits@$k$ 和 MRR 遵循过滤协议，但分类指标是在 $\\tau=0.7$ 时计算的。AUC-ROC 的定义如 A 项所述。当 $\\tau=0.7$ 时，预测为正的是那些 $s\\ge 0.7$ 的样本，得到精确率 (Precision) $=1/2$，召回率 (Recall) $=2/3$，以及 $F1=4/7\\approx 0.5714$。在过滤设置下，Hits@$1=0$，Hits@$3=1$，并且 $\\mathrm{MRR}=0.5$。",
            "solution": "2.  **问题验证**：\n    *   **步骤 1：提取已知条件**：我将逐字列出问题陈述中提供的所有数据点、定义和条件。\n        *   一个生物医学知识图谱 (KG) 编码了生物医学实体之间的类型化关系。\n        *   关系为 $r = \\text{treats}$。\n        *   一个模型为每个候选尾实体 $t$ 返回一个实值分数 $s(h,r,t) \\in [0,1]$。\n        *   评估使用过滤协议：对于一个带有预留测试尾实体 $t^\\star$ 的查询 $(h,r,?)$，在排名之前，任何其他使得 $(h,r,t)$ 在知识图谱中已知为真的 $t \\neq t^\\star$ 都会从候选集中移除。\n        *   查询 1：$(d_A,\\text{treats},?)$\n            *   候选集：$\\{z_1,z_2,z_3,z_4\\}$\n            *   分数：$s(d_A,\\text{treats},z_1)=0.9$, $s(d_A,\\text{treats},z_2)=0.8$, $s(d_A,\\text{treats},z_3)=0.85$, $s(d_A,\\text{treats},z_4)=0.1$。\n            *   预留测试三元组：$(d_A,\\text{treats},z_2)$。\n            *   需要被过滤的已知真实三元组：$(d_A,\\text{treats},z_3)$。\n        *   查询 2：$(d_B,\\text{treats},?)$\n            *   候选集：$\\{z_5,z_6,z_7\\}$\n            *   分数：$s(d_B,\\text{treats},z_5)=0.7$, $s(d_B,\\text{treats},z_6)=0.6$, $s(d_B,\\text{treats},z_7)=0.2$。\n            *   预留测试三元组：$(d_B,\\text{treats},z_6)$。\n            *   此查询没有其他已知的真实尾实体。\n        *   对于基于阈值的分类指标：\n            *   聚合两个查询中的所有候选边。\n            *   决策阈值 $\\tau=0.5$。如果 $s(h,r,t) \\ge \\tau$ 则预测为正，否则为负。\n            *   真实标签：$(d_A,\\text{treats},z_2)$、$(d_A,\\text{treats},z_3)$ 和 $(d_B,\\text{treats},z_6)$ 为正例 ($y=1$) 。所有其他候选边为负例 ($y=0$)。\n        *   需要定义和计算的指标：Hits@$k$、平均倒数排名 (MRR)、受试者工作特征曲线下面积 (AUC-ROC)、精确率、召回率和 $F1$。\n\n    *   **步骤 2：使用提取的已知条件进行验证**：\n        *   **科学性：** 该问题严格基于机器学习中知识图谱补全的标准实践，特别是在生物医学信息学这一成熟领域内。所有术语（链接预测、过滤协议、Hits@$k$、MRR、AUC-ROC 等）都是标准的。\n        *   **良构性：** 该问题是良构的。它提供了所有必要的数值数据（分数）、一个清晰定义的评估协议（过滤），以及在分类指标背景下对真实标签的明确定义。所提出的问题基于给定的条件有唯一的、可计算的答案。\n        *   **客观性：** 问题陈述以精确、客观和技术性的语言表达，没有歧义或主观论断。\n        *   **缺陷检查清单：**\n            1.  **科学或事实不健全：**无。该设置是对机器学习评估任务的标准且有效的表述。\n            2.  **不可形式化或不相关：**无。该问题是形式化的，并与指定主题直接相关。\n            3.  **设置不完整或矛盾：**无。该问题是自洽的。预留测试三元组和其他已知真实三元组（用于过滤和定义分类中的真实标签）之间的区别是知识图谱评估中一个关键且标准的细微差别，并且在这里得到了一致的处理。\n            4.  **不切实际或不可行：**无。分数和实体关系对于此类问题是合理的模拟数据。\n            5.  **病态或结构不良：**无。结构是逻辑的，并能导向唯一的解决方案。\n            6.  **伪深刻、琐碎或同义反复：**无。该问题要求仔细应用多种不同的评估程序（排名与分类，过滤与聚合），是对理解这些概念的非凡测试。\n            7.  **无法进行科学验证：**无。该问题纯粹是计算性的，其解决方案是完全可验证的。\n\n    *   **步骤 3：结论与行动**：问题陈述是**有效的**。可以进行分析。\n\n### 推导与评估\n\n该问题要求计算两类指标：基于排名的（Hits@$k$, MRR）和基于分类的（AUC-ROC, 精确率, 召回率, $F1$）。我们将依次处理每一类。\n\n#### 基于排名的指标 (Hits@$k$, MRR)\n\n这些指标是按每个查询计算，然后求平均值。问题指定了**过滤协议**。\n\n**查询 1: $(d_A,\\text{treats},?)$**\n-   候选尾实体及其分数为：$\\{ (z_1, 0.9), (z_2, 0.8), (z_3, 0.85), (z_4, 0.1) \\}$。\n-   预留的测试尾实体（用于排名的正确答案）是 $t^\\star = z_2$。\n-   三元组 $(d_A,\\text{treats},z_3)$ 是另一个已知的真实三元组，必须被过滤掉。\n-   首先，我们按分数降序对所有候选者进行排名：$z_1$ ($0.9$), $z_3$ ($0.85$), $z_2$ ($0.8$), $z_4$ ($0.1$)。\n-   接下来，我们通过从排名列表中移除 $z_3$ 来应用过滤协议：过滤后的排名列表变为 $z_1, z_2, z_4$。\n-   在这个过滤后的列表中，正确尾实体 $z_2$ 的排名是 $2$。\n-   该查询的倒数排名是 $\\frac{1}{2}$。\n\n**查询 2: $(d_B,\\text{treats},?)$**\n-   候选尾实体及其分数为：$\\{ (z_5, 0.7), (z_6, 0.6), (z_7, 0.2) \\}$。\n-   预留的测试尾实体是 $t^\\star = z_6$。\n-   此查询没有其他已知的真实尾实体需要过滤。\n-   按分数降序排列的列表是：$z_5$ ($0.7$), $z_6$ ($0.6$), $z_7$ ($0.2$)。\n-   在此列表中，正确尾实体 $z_6$ 的排名是 $2$。\n-   该查询的倒数排名是 $\\frac{1}{2}$。\n\n**总体排名指标**\n-   **Hits@$k$**：这是测试尾实体的过滤后排名小于或等于 $k$ 的查询所占的比例。它是所有查询中指示函数 $\\mathbb{I}(\\text{rank} \\le k)$ 的平均值。\n    -   两个查询的排名为 $\\{2, 2\\}$。\n    -   Hits@$1 = (\\mathbb{I}(2 \\le 1) + \\mathbb{I}(2 \\le 1)) / 2 = (0 + 0) / 2 = 0$。\n    -   Hits@$3 = (\\mathbb{I}(2 \\le 3) + \\mathbb{I}(2 \\le 3)) / 2 = (1 + 1) / 2 = 1$。\n-   **平均倒数排名 (MRR)**：这是所有查询的倒数排名的平均值。\n    -   $\\text{MRR} = (\\frac{1}{2} + \\frac{1}{2}) / 2 = 1 / 2 = 0.5$。\n\n#### 基于分类的指标 (AUC-ROC, 精确率, 召回率, $F1$)\n\n这些指标是在两个查询的所有候选边的聚合集上计算的。\n\n**聚合数据集**\n-   问题陈述指出 $(d_A,\\text{treats},z_2)$、$(d_A,\\text{treats},z_3)$ 和 $(d_B,\\text{treats},z_6)$ 是正例 ($y=1$) ，所有其他都是负例 ($y=0$)。共有 $3$ 个正样本和 $4$ 个负样本。\n-   完整数据集如下：\n    1.  边 $(d_A, \\text{treats}, z_1)$: 分数 $s=0.9$, 真实标签 $y=0$ (负例)\n    2.  边 $(d_A, \\text{treats}, z_2)$: 分数 $s=0.8$, 真实标签 $y=1$ (正例)\n    3.  边 $(d_A, \\text{treats}, z_3)$: 分数 $s=0.85$, 真实标签 $y=1$ (正例)\n    4.  边 $(d_A, \\text{treats}, z_4)$: 分数 $s=0.1$, 真实标签 $y=0$ (负例)\n    5.  边 $(d_B, \\text{treats}, z_5)$: 分数 $s=0.7$, 真实标签 $y=0$ (负例)\n    6.  边 $(d_B, \\text{treats}, z_6)$: 分数 $s=0.6$, 真实标签 $y=1$ (正例)\n    7.  边 $(d_B, \\text{treats}, z_7)$: 分数 $s=0.2$, 真实标签 $y=0$ (负例)\n\n**在 $\\tau=0.5$ 下的精确率、召回率和 $F1$**\n-   如果一条边的分数 $s \\ge 0.5$，则预测为正。\n-   应用此规则：\n    -   $s=0.9$ (负例): 预测为正 $\\implies$ 假阳性 (FP)\n    -   $s=0.8$ (正例): 预测为正 $\\implies$ 真阳性 (TP)\n    -   $s=0.85$ (正例): 预测为正 $\\implies$ 真阳性 (TP)\n    -   $s=0.1$ (负例): 预测为负 $\\implies$ 真阴性 (TN)\n    -   $s=0.7$ (负例): 预测为正 $\\implies$ 假阳性 (FP)\n    -   $s=0.6$ (正例): 预测为正 $\\implies$ 真阳性 (TP)\n    -   $s=0.2$ (负例): 预测为负 $\\implies$ 真阴性 (TN)\n-   计数：$\\mathrm{TP}=3$, $\\mathrm{FP}=2$, $\\mathrm{TN}=2$, $\\mathrm{FN}=0$。\n-   正例总数 $\\mathrm{P} = \\mathrm{TP}+\\mathrm{FN} = 3$。负例总数 $\\mathrm{N} = \\mathrm{FP}+\\mathrm{TN} = 4$。\n-   **精确率** = $\\frac{\\mathrm{TP}}{\\mathrm{TP}+\\mathrm{FP}} = \\frac{3}{3+2} = \\frac{3}{5} = 0.6$。\n-   **召回率** = $\\frac{\\mathrm{TP}}{\\mathrm{TP}+\\mathrm{FN}} = \\frac{3}{3+0} = 1$。\n-   **$F1$ 分数** = $2 \\cdot \\frac{\\text{精确率} \\cdot \\text{召回率}}{\\text{精确率} + \\text{召回率}} = 2 \\cdot \\frac{0.6 \\cdot 1}{0.6 + 1} = \\frac{1.2}{1.6} = \\frac{12}{16} = \\frac{3}{4} = 0.75$。\n\n**ROC 曲线下面积 (AUC-ROC)**\n-   AUC-ROC 是随机选择的正样本分数高于随机选择的负样本分数的概率。它通过考虑所有（正，负）样本对来计算。\n-   正样本数 $|\\mathrm{P}| = 3$。负样本数 $|\\mathrm{N}| = 4$。总对数 = $3 \\times 4 = 12$。\n-   正例分数：$\\{0.85, 0.8, 0.6\\}$。\n-   负例分数：$\\{0.9, 0.7, 0.2, 0.1\\}$。\n-   我们计算 $s(p) > s(n)$ 的对 $(p, n)$ 的数量。分数相等的情况计为 $0.5$。\n    -   对于分数为 $s=0.85$ 的正例：它的分数高于 $3$ 个负例 ($0.7, 0.2, 0.1$)。贡献：$3$。\n    -   对于分数为 $s=0.8$ 的正例：它的分数高于 $3$ 个负例 ($0.7, 0.2, 0.1$)。贡献：$3$。\n    -   对于分数为 $s=0.6$ 的正例：它的分数高于 $2$ 个负例 ($0.2, 0.1$)。贡献：$2$。\n-   正确排序的对的总数 = $3 + 3 + 2 = 8$。\n-   $\\text{AUC-ROC} = \\frac{\\text{正确排序的对数}}{\\text{总对数}} = \\frac{8}{12} = \\frac{2}{3}$。\n\n### 逐项分析选项\n\n**选项 A**\n-   **定义**：正确定义了 Hits@$k$ (排名 $\\le k$ 的指示函数的平均值)、MRR (倒数排名的平均值)、AUC-ROC (正例分数>负例分数的概率) 和精确率/召回率/$F1$。\n-   **数值**：\n    -   排名：陈述“两个查询的过滤后排名均为 2，因此 Hits@1=0 且 Hits@3=1，并且 MRR=(1/2+1/2)/2=0.5”。这与我们的计算完全匹配。\n    -   分类：陈述“正例有三个，负例有四个”，这是正确的。陈述“AUC-ROC 等于 2/3”。这与我们的计算匹配。陈述对于 $\\tau=0.5$，“TP=3, FP=2, FN=0”，导致“精确率 = 3/5=0.6，召回率 = 1”和“F1=...3/4=0.75”。这也与我们的计算完全匹配。\n-   **结论**：**正确**。\n\n**选项 B**\n-   **定义/协议**：陈述“Hits@k 和 MRR 是在原始（未过滤）候选列表上计算的”。这违反了问题中明确要求使用“过滤协议”的指示。\n-   **数值**：排名指标（`Hits@1=0`, `Hits@3=1`, `MRR=5/12`）是基于不正确（原始）协议计算的。虽然分类指标陈述正确，但该选项是有缺陷的，因为它没有遵循指定的排名评估协议。\n-   **结论**：**不正确**。\n\n**选项 C**\n-   **定义**：\n    -   将 Hits@$k$ 定义为“排名前 k 的候选者中真实候选项的比例”，这是 Precision@$k$，而不是 Hits@$k$。不正确。\n    -   将 MRR 无意义地定义为“排名前 k 的真实候选者数量的倒数的平均值”。不正确。\n    -   将 AUC 定义为“精确率-召回率曲线下面积”(AUC-PR)，而不是所要求的 AUC-ROC。不正确。\n    -   颠倒了精确率和召回率的定义（“精确率等于 TP/(TP+FN) 且召回率等于 TP/(TP+FP)”）。不正确。\n-   **数值**：提供的值基于这些不正确的定义（例如，“AUC ... 约等于 0.8”），并且它们本身也是不正确的（我们的 AUC-PR 计算约为 0.59）。\n-   **结论**：**不正确**。\n\n**选项 D**\n-   **定义/协议**：它正确地指出排名指标应遵循过滤协议。然而，它陈述“分类指标是在 τ=0.7 时计算的”。这违反了问题中明确要求使用“固定决策阈值 τ=0.5”的指示。\n-   **数值**：排名指标（`Hits@1=0`, `Hits@3=1`, `MRR=0.5`）是正确的。分类指标（`精确率=1/2`, `召回率=2/3`, `F1=4/7`）是为错误的阈值 $\\tau=0.7$ 正确计算的，但不是为问题中指定的阈值计算的。\n-   **结论**：**不正确**。\n\n### 结论\n选项 A 是唯一一个正确定义了所有指标，遵守了问题陈述中指定的所有协议和参数（过滤排名，$\\tau=0.5$），并为所有计算提供了正确数值结果的选项。",
            "answer": "$$\\boxed{A}$$"
        }
    ]
}