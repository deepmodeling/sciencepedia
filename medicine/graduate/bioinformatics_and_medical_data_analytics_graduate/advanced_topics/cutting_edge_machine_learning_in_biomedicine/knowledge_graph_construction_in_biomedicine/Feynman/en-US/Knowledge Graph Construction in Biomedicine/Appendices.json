{
    "hands_on_practices": [
        {
            "introduction": "Constructing a knowledge graph is not a one-off task but a systematic process that demands rigor and reproducibility, especially in a scientific context. This first practice moves beyond simple scripting to the engineering of a complete, verifiable Extract-Transform-Load (ETL) pipeline. By implementing a workflow that incorporates explicit versioning and cryptographic checksums, you will learn to build a system whose outputs can be trusted and reproduced, a cornerstone of modern computational science .",
            "id": "4577595",
            "problem": "You are given the task of designing a deterministic Extract-Transform-Load workflow for constructing a small biomedical knowledge graph. The goal is to formalize reproducibility using deterministic algorithms, explicit versioning metadata, and a cryptographic checksum. The workflow must be modeled as a directed acyclic graph with nodes representing tasks and edges representing data dependencies. The workflow components are: Extract, Transform, Load. The inputs are small tabular datasets of biomedical relations and a table of synonyms that normalizes labels. The output is a knowledge graph with typed nodes and typed edges, and a provenance-aware digest that encodes both the graph content and explicit version metadata.\n\nFundamental concepts to use:\n- Extract-Transform-Load: The workflow consists of extracting data, transforming it to conform to schema and normalization, and loading it into a graph representation. A knowledge graph is a directed labeled multigraph $\\mathcal{G}=(\\mathcal{V},\\mathcal{E})$ where $\\mathcal{V}$ is a set of entities and $\\mathcal{E}\\subseteq \\mathcal{V}\\times\\mathcal{R}\\times\\mathcal{V}$ is a set of edges labeled by relations from $\\mathcal{R}$.\n- Determinism: For reproducibility, a deterministic function $f$ must satisfy $x=y\\Rightarrow f(x)=f(y)$ for the same inputs and fixed versions, and must be insensitive to row permutations in tabular inputs.\n- Workflow ordering: A Directed Acyclic Graph (DAG) $W=(\\mathcal{T},\\mathcal{D})$ with tasks $\\mathcal{T}=\\{\\text{Extract},\\text{Transform},\\text{Load}\\}$ and data dependencies $\\mathcal{D}\\subseteq \\mathcal{T}\\times\\mathcal{T}$ defines a topological order where predecessors must complete before successors.\n- Cryptographic hashing: Use a cryptographic hash function $H$ (Secure Hash Algorithm $256$) modeled as $H:\\{0,1\\}^\\star \\to \\{0,1\\}^{256}$ to compute a digest. This function is collision-resistant and sensitive to any bit change in its input.\n\nDefinitions required for the program:\n- Canonicalization: Define a canonicalization function $C:\\mathcal{S}\\to\\mathcal{S}$ on strings that lowercases, removes punctuation, and collapses whitespace. Let $M:\\mathcal{S}\\to\\mathcal{S}$ represent synonym mapping provided by an input table. The normalized label is $L(s)=M(C(s))$ if $M(C(s))$ exists, else $C(s)$.\n- Knowledge graph schema: There are three entity types: Gene, Disease, Drug. There are three relation types: associates (Gene-Disease), targets (Drug-Gene), treats (Drug-Disease). The transformed graph must include nodes labeled by their type-suffixed canonical names, e.g., $\\text{\"Gene|tp53\"}$. Edges are typed triples $\\text{\"associates|gene|disease\"}$, $\\text{\"targets|drug|gene\"}$, $\\text{\"treats|drug|disease\"}$ using canonical labels. Duplicates must be removed; the representation must be order-insensitive.\n- Versioning: Each task is parameterized by explicit version identifiers for the container image and for the code, and each dataset has an explicit version identifier. Denote task container version strings $c_{\\text{extract}},c_{\\text{transform}},c_{\\text{load}}$, code version strings $s_{\\text{extract}},s_{\\text{transform}},s_{\\text{load}}$, dataset versions $d_{\\text{GD}}$ (gene-disease), $d_{\\text{DT}}$ (drug-target), $d_{\\text{DD}}$ (drug-disease), $d_{\\text{Syn}}$ (synonyms). The workflow is valid only if all these strings are non-empty and none equals the placeholder $\\text{\"latest\"}$ in any case variant.\n- Provenance: Construct a provenance string $P$ as the concatenation of all explicit versions in a fixed canonical order (lexicographically by key), i.e., $P=\\bigoplus_{k\\in K}{\\text{key}(k)\\Vert\\text{version}(k)}$, where $\\oplus$ denotes concatenation and $\\Vert$ denotes a delimiter. Let the graph content string be $G_c$, a concatenation of sorted nodes and sorted edges in a fixed format. Define the final digest $D=H(P\\Vert G_c)$. Reproducibility holds for a pair of runs if and only if both runs have valid explicit versions and identical $D$.\n\nYour program must:\n- Implement deterministic canonicalization $C$, synonym application $M$, and graph construction to produce $G_c$.\n- Construct $P$ from container, code, and dataset versions; enforce explicit version validity.\n- Compute $D$ using Secure Hash Algorithm $256$ over $P\\Vert G_c$.\n- For each test case, evaluate reproducibility by running the workflow twice (Run A and Run B), and compute a boolean result indicating whether both runs are valid and $D_{\\text{A}}=D_{\\text{B}}$.\n\nTest suite and parameters:\nFor each test case $i\\in\\{1,2,3,4\\}$, you are given Run A and Run B parameters. Each run specifies four datasets and two version maps. Each dataset provides a version string and a list of rows. The container and code version maps provide version strings for Extract, Transform, and Load.\n\n- Test case $1$ (happy path; permutation invariance):\n  - Run A datasets:\n    - gene-disease $d_{\\text{GD}}=\\text{\"gd:v1\"}$, rows: $[(\\text{\"TP53\"},\\text{\"Breast Cancer\"}),(\\text{\"BRCA1\"},\\text{\"Breast carcinoma\"})]$.\n    - drug-target $d_{\\text{DT}}=\\text{\"dt:v1\"}$, rows: $[(\\text{\"Tamoxifen\"},\\text{\"ESR1\"}),(\\text{\"Trastuzumab\"},\\text{\"ERBB2\"})]$.\n    - drug-disease $d_{\\text{DD}}=\\text{\"dd:v1\"}$, rows: $[(\\text{\"Tamoxifen\"},\\text{\"Breast Cancer\"}),(\\text{\"Trastuzumab\"},\\text{\"Breast carcinoma\"})]$.\n    - synonyms $d_{\\text{Syn}}=\\text{\"syn:v1\"}$, rows: $[(\\text{\"breast carcinoma\"},\\text{\"breast cancer\"}),(\\text{\"her2-positive\"},\\text{\"her2 positive\"})]$.\n  - Run A versions: containers $(c_{\\text{extract}},c_{\\text{transform}},c_{\\text{load}})=(\\text{\"ctrE:1.0\"},\\text{\"ctrT:1.1\"},\\text{\"ctrL:1.0\"})$, codes $(s_{\\text{extract}},s_{\\text{transform}},s_{\\text{load}})=(\\text{\"codeE:abc\"},\\text{\"codeT:def\"},\\text{\"codeL:ghi\"})$.\n  - Run B datasets: identical content as Run A but each table’s rows are permuted and one duplicate is introduced: gene-disease rows $[(\\text{\"BRCA1\"},\\text{\"Breast carcinoma\"}),(\\text{\"TP53\"},\\text{\"Breast Cancer\"})]$, drug-target rows $[(\\text{\"Trastuzumab\"},\\text{\"ERBB2\"}),(\\text{\"Tamoxifen\"},\\text{\"ESR1\"})]$, drug-disease rows $[(\\text{\"Trastuzumab\"},\\text{\"Breast carcinoma\"}),(\\text{\"Tamoxifen\"},\\text{\"Breast Cancer\"}),(\\text{\"Tamoxifen\"},\\text{\"Breast Cancer\"})]$, synonyms rows $[(\\text{\"her2-positive\"},\\text{\"her2 positive\"}),(\\text{\"breast carcinoma\"},\\text{\"breast cancer\"})]$.\n  - Run B versions: identical to Run A.\n  - Expected output for this case: boolean indicating reproducibility under permutation and duplicate removal.\n\n- Test case $2$ (version change boundary):\n  - Run A: identical to Test case $1$ Run A.\n  - Run B: identical to Test case $1$ Run A except synonyms dataset version changes to $d_{\\text{Syn}}=\\text{\"syn:v2\"}$ (rows unchanged).\n  - Expected output: boolean indicating non-reproducibility due to version change even when content is unchanged.\n\n- Test case $3$ (invalid due to missing explicit container version):\n  - Run A: identical to Test case $1$ Run A except $c_{\\text{transform}}=\\text{\"\"}$ (empty string).\n  - Run B: identical to Test case $1$ Run A.\n  - Expected output: boolean indicating non-reproducibility because explicit version validity fails.\n\n- Test case $4$ (code version change):\n  - Run A: identical to Test case $1$ Run A.\n  - Run B: identical to Test case $1$ Run A except $s_{\\text{load}}=\\text{\"codeL:xyz\"}$.\n  - Expected output: boolean indicating non-reproducibility due to code version change.\n\nAngle units, physical units, and percentages do not apply. All outputs must be pure booleans. Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (e.g., $\\text{\"[result1,result2,result3,result4]\"}$) where each $result_i$ is a boolean $\\in\\{\\text{True},\\text{False}\\}$ computed for the corresponding test case.",
            "solution": "The problem of designing a reproducible biomedical knowledge graph construction workflow is reviewed and validated as scientifically grounded, well-posed, and objective. The problem statement provides a comprehensive and formalizable specification for an Extract-Transform-Load (ETL) pipeline, leveraging established principles of deterministic algorithms, explicit versioning, and cryptographic hashing to ensure reproducibility. The problem is valid and can be solved as specified.\n\nThe solution involves implementing a deterministic function that maps a set of versioned, tabular inputs to a final cryptographic digest. This digest uniquely represents both the content of the constructed knowledge graph and the full provenance of the software, code, and data used in its creation. Two runs of the workflow are deemed reproducible if and only if their respective version metadata are valid and their final digests are identical.\n\nThe overall process is modeled as a function, $\\text{ComputeDigest}$, which maps the set of input datasets and version metadata to a digest string:\n$$ \\text{ComputeDigest}(\\{\\text{datasets}\\}, \\{\\text{versions}\\}) \\to D \\in \\{0, 1\\}^{256} $$\nThe core of the solution is to implement this function and then use it to evaluate the reproducibility for each test case. The implementation is divided into three main stages, mirroring the conceptual tasks of version validation, data transformation, and digest computation.\n\n### 1. Version Validation and Provenance String ($P$) Construction\n\nThe first step is to validate the versioning metadata and construct a canonical provenance string, $P$. Reproducibility requires that all components be explicitly versioned.\n\n**Validation:**\nA run is considered valid only if all version strings provided for datasets ($d_{\\text{GD}}, d_{\\text{DT}}, d_{\\text{DD}}, d_{\\text{Syn}}$), container images ($c_{\\text{extract}}, c_{\\text{transform}}, c_{\\text{load}}$), and code ($s_{\\text{extract}}, s_{\\text{transform}}, s_{\\text{load}}$) are non-empty and do not equal the placeholder string `\"latest\"`. If any version string fails this check, the workflow for that run is invalid, and reproducibility is impossible by definition.\n\n**Provenance String $P$:**\nIf the versions are valid, they are aggregated into a single, canonical provenance string $P$. This is achieved by:\n1.  Creating a set of key-value pairs for all $10$ version identifiers. The keys are strings like `\"d_GD\"`, `\"c_extract\"`, etc.\n2.  Sorting these pairs lexicographically by key.\n3.  For each sorted pair $(k, v)$, a string is formed as $k \\Vert v$, where $\\Vert$ is the literal `|` character.\n4.  The final provenance string $P$ is constructed by concatenating these individual strings, separated by a newline character (`\n`). This operation is denoted by $\\bigoplus$ in the problem, such that $P = \\bigoplus_{i=1}^{10} (k_i \\Vert v_i)$.\n\nThis process ensures that $P$ is a unique, order-independent representation of the complete versioning metadata.\n\n### 2. Data Transformation and Graph Content String ($G_c$) Construction\n\nThis stage corresponds to the Transform and Load steps of the ETL workflow. It processes the input relational data into a canonical knowledge graph representation, $G_c$.\n\n**Entity Normalization:**\nTo handle variations in entity naming (e.g., `\"Breast Cancer\"` vs. `\"Breast carcinoma\"`), a deterministic normalization function, $L(s)$, is applied to all entity labels.\n\n1.  **Canonicalization ($C(s)$):** A function $C: \\mathcal{S} \\to \\mathcal{S}$ is defined to transform any string $s$ into a canonical form. This involves lowercasing the string, removing all punctuation characters (any character not in `a-z`, `0-9`, or whitespace), and collapsing multiple whitespace characters into a single space, and trimming any leading/trailing space.\n2.  **Synonym Mapping ($M(s)$):** A synonym map $M: \\mathcal{S} \\to \\mathcal{S}$ is built from the input synonyms table. Both the synonym and its canonical equivalent from the table are first passed through the function $C(s)$ before being inserted into a dictionary.\n3.  **Normalization ($L(s)$):** The final normalized label is given by $L(s) = M(C(s))$ if a mapping for $C(s)$ exists in $M$; otherwise, $L(s) = C(s)$.\n\n**Knowledge Graph Construction ($\\mathcal{G}$):**\nThe knowledge graph $\\mathcal{G} = (\\mathcal{V}, \\mathcal{E})$ is constructed from the input relational data:\n-   **Gene-Disease Relations:** For each row $(g, d)$ in the gene-disease table, we generate two nodes, `\"Gene|\" \\oplus L(g)$ and `\"Disease|\" \\oplus L(d)$, and one edge tuple $(\\text{\"Gene|\" \\oplus L(g)}, \\text{\"associates\"}, \\text{\"Disease|\" \\oplus L(d)})$.\n-   **Drug-Target Relations:** For each row $(dr, g)$ in the drug-target table, we generate nodes `\"Drug|\" \\oplus L(dr)$ and `\"Gene|\" \\oplus L(g)$, and an edge tuple $(\\text{\"Drug|\" \\oplus L(dr)}, \\text{\"targets\"}, \\text{\"Gene|\" \\oplus L(g)})$.\n-   **Drug-Disease Relations:** For each row $(dr, d)$ in the drug-disease table, we generate nodes `\"Drug|\" \\oplus L(dr)$ and `\"Disease|\" \\oplus L(d)$, and an edge tuple $(\\text{\"Drug|\" \\oplus L(dr)}, \\text{\"treats\"}, \\text{\"Disease|\" \\oplus L(d)})$.\n\nTo ensure the process is insensitive to input row order and immune to duplicates, the generated node strings are stored in a set $\\mathcal{V}$, and the edge tuples are stored in a set $\\mathcal{E}$.\n\n**Graph Content String ($G_c$):**\nTo create a canonical string representation of the graph, $G_c$:\n1.  The set of nodes $\\mathcal{V}$ is converted to a list of strings, which is then lexicographically sorted.\n2.  The set of edges $\\mathcal{E}$ is converted to a list of string representations. Each edge tuple $(u, r, v) \\in \\mathcal{E}$ is formatted as the string $u \\Vert r \\Vert v$, using `|` as the delimiter $\\Vert$. This list is also lexicographically sorted.\n3.  The final string $G_c$ is formed by joining the sorted node strings with `\n`, followed by a `\n` separator, followed by the sorted edge strings joined with `\n`. This fixed format ensures a deterministic representation of the graph content.\n\n### 3. Final Digest ($D$) Computation and Reproducibility Check\n\nThe final step securely binds the provenance to the content and evaluates reproducibility.\n\n**Digest Calculation:**\nThe final digest $D$ is the SHA-256 hash of the full canonical string representation. The input to the hash function $H$ is the concatenation of the provenance string $P$ and the graph content string $G_c$, separated by a newline character.\n$$ D = H(P \\oplus \\text{\"\\\\n\"} \\oplus G_c) $$\nThis ensures that any change, whether to the input data, the normalization logic, or the version metadata, will result in a different digest.\n\n**Reproducibility Evaluation:**\nFor each test case, the workflow is executed for Run A and Run B, producing digests $D_A$ and $D_B$ and validity statuses $V_A$ and $V_B$. The reproducibility condition is met if and only if both runs are valid and their digests are identical. The boolean result for the test case is thus:\n$$ \\text{is_reproducible} = (V_A \\land V_B) \\land (D_A = D_B) $$\nThis strict definition correctly identifies deviations in either provenance or content, fulfilling the requirements for a formal, verifiable, and reproducible scientific workflow.",
            "answer": "```python\nimport hashlib\nimport re\nfrom typing import List, Tuple, Dict, Set, Any, Optional\n\ndef solve():\n    \"\"\"\n    Main function to execute the reproducibility checks for all test cases.\n    \"\"\"\n\n    # Helper function for canonicalizing strings\n    def canonicalize(s: str) -> str:\n        s = s.lower()\n        s = re.sub(r'[^a-z0-9\\s]', '', s)\n        s = re.sub(r'\\s+', ' ', s).strip()\n        return s\n\n    def run_workflow(\n        datasets: Dict[str, Tuple[str, List[Tuple[str, str]]]],\n        versions: Dict[str, str]\n    ) -> Tuple[bool, Optional[str]]:\n        \"\"\"\n        Executes the full ETL workflow for a single run and returns its validity and digest.\n\n        Args:\n            datasets: A dictionary mapping dataset names to (version, data rows).\n            versions: A dictionary of container and code versions.\n\n        Returns:\n            A tuple (is_valid, digest_hex), where is_valid is a boolean and\n            digest_hex is the hex string of the SHA-256 digest, or None if invalid.\n        \"\"\"\n        # 1. Version Validation and Provenance String (P) Construction\n        all_versions = versions.copy()\n        for name, (version, _) in datasets.items():\n            all_versions[f\"d_{name}\"] = version\n\n        is_valid = True\n        for key, val in all_versions.items():\n            if not val or val.lower() == \"latest\":\n                is_valid = False\n                break\n        \n        if not is_valid:\n            return False, None\n\n        provenance_items = []\n        for key in sorted(all_versions.keys()):\n            provenance_items.append(f\"{key}|{all_versions[key]}\")\n        \n        provenance_string = \"\\n\".join(provenance_items)\n\n        # 2. Data Transformation and Graph Content String (Gc) Construction\n        \n        # Build synonym map M\n        synonym_map: Dict[str, str] = {}\n        _, syn_rows = datasets[\"Syn\"]\n        for key, value in syn_rows:\n            synonym_map[canonicalize(key)] = canonicalize(value)\n\n        def normalize_label(s: str) -> str:\n            c_s = canonicalize(s)\n            return synonym_map.get(c_s, c_s)\n\n        nodes: Set[str] = set()\n        edges: Set[str] = set()\n\n        # Process gene-disease\n        _, gd_rows = datasets[\"GD\"]\n        for g, d in gd_rows:\n            norm_g = normalize_label(g)\n            norm_d = normalize_label(d)\n            node_g = f\"Gene|{norm_g}\"\n            node_d = f\"Disease|{norm_d}\"\n            nodes.add(node_g)\n            nodes.add(node_d)\n            edges.add(f\"{node_g}|associates|{node_d}\")\n\n        # Process drug-target\n        _, dt_rows = datasets[\"DT\"]\n        for dr, g in dt_rows:\n            norm_dr = normalize_label(dr)\n            norm_g = normalize_label(g)\n            node_dr = f\"Drug|{norm_dr}\"\n            node_g = f\"Gene|{norm_g}\"\n            nodes.add(node_dr)\n            nodes.add(node_g)\n            edges.add(f\"{node_dr}|targets|{node_g}\")\n\n        # Process drug-disease\n        _, dd_rows = datasets[\"DD\"]\n        for dr, d in dd_rows:\n            norm_dr = normalize_label(dr)\n            norm_d = normalize_label(d)\n            node_dr = f\"Drug|{norm_dr}\"\n            node_d = f\"Disease|{norm_d}\"\n            nodes.add(node_dr)\n            nodes.add(node_d)\n            edges.add(f\"{node_dr}|treats|{node_d}\")\n            \n        sorted_nodes = sorted(list(nodes))\n        sorted_edges = sorted(list(edges))\n        \n        node_str = \"\\n\".join(sorted_nodes)\n        edge_str = \"\\n\".join(sorted_edges)\n        \n        graph_content_string = f\"{node_str}\\n{edge_str}\"\n\n        # 3. Final Digest (D) Computation\n        full_string_to_hash = f\"{provenance_string}\\n{graph_content_string}\"\n        \n        digest = hashlib.sha256(full_string_to_hash.encode('utf-8')).hexdigest()\n        \n        return True, digest\n\n    # --- Test Cases Definition ---\n\n    # Common data for Test Case 1 Run A\n    base_datasets = {\n        \"GD\": (\"gd:v1\", [(\"TP53\", \"Breast Cancer\"), (\"BRCA1\", \"Breast carcinoma\")]),\n        \"DT\": (\"dt:v1\", [(\"Tamoxifen\", \"ESR1\"), (\"Trastuzumab\", \"ERBB2\")]),\n        \"DD\": (\"dd:v1\", [(\"Tamoxifen\", \"Breast Cancer\"), (\"Trastuzumab\", \"Breast carcinoma\")]),\n        \"Syn\": (\"syn:v1\", [(\"breast carcinoma\", \"breast cancer\"), (\"her2-positive\", \"her2 positive\")]),\n    }\n    base_versions = {\n        \"c_extract\": \"ctrE:1.0\", \"c_transform\": \"ctrT:1.1\", \"c_load\": \"ctrL:1.0\",\n        \"s_extract\": \"codeE:abc\", \"s_transform\": \"codeT:def\", \"s_load\": \"codeL:ghi\",\n    }\n\n    test_cases = [\n        # Test Case 1: Happy path, permutation invariance\n        {\n            \"run_a\": {\"datasets\": base_datasets, \"versions\": base_versions},\n            \"run_b\": {\n                \"datasets\": {\n                    \"GD\": (\"gd:v1\", [(\"BRCA1\", \"Breast carcinoma\"), (\"TP53\", \"Breast Cancer\")]),\n                    \"DT\": (\"dt:v1\", [(\"Trastuzumab\", \"ERBB2\"), (\"Tamoxifen\", \"ESR1\")]),\n                    \"DD\": (\"dd:v1\", [(\"Trastuzumab\", \"Breast carcinoma\"), (\"Tamoxifen\", \"Breast Cancer\"), (\"Tamoxifen\", \"Breast Cancer\")]),\n                    \"Syn\": (\"syn:v1\", [(\"her2-positive\", \"her2 positive\"), (\"breast carcinoma\", \"breast cancer\")]),\n                },\n                \"versions\": base_versions\n            }\n        },\n        # Test Case 2: Version change boundary\n        {\n            \"run_a\": {\"datasets\": base_datasets, \"versions\": base_versions},\n            \"run_b\": {\n                \"datasets\": {\n                    \"GD\": base_datasets[\"GD\"],\n                    \"DT\": base_datasets[\"DT\"],\n                    \"DD\": base_datasets[\"DD\"],\n                    \"Syn\": (\"syn:v2\", base_datasets[\"Syn\"][1]),\n                },\n                \"versions\": base_versions\n            }\n        },\n        # Test Case 3: Invalid due to missing explicit container version\n        {\n            \"run_a\": {\n                \"datasets\": base_datasets,\n                \"versions\": {**base_versions, \"c_transform\": \"\"}\n            },\n            \"run_b\": {\"datasets\": base_datasets, \"versions\": base_versions}\n        },\n        # Test Case 4: Code version change\n        {\n            \"run_a\": {\"datasets\": base_datasets, \"versions\": base_versions},\n            \"run_b\": {\n                \"datasets\": base_datasets,\n                \"versions\": {**base_versions, \"s_load\": \"codeL:xyz\"}\n            }\n        }\n    ]\n\n    results = []\n    for i, case in enumerate(test_cases):\n        valid_a, digest_a = run_workflow(case[\"run_a\"][\"datasets\"], case[\"run_a\"][\"versions\"])\n        valid_b, digest_b = run_workflow(case[\"run_b\"][\"datasets\"], case[\"run_b\"][\"versions\"])\n        \n        is_reproducible = valid_a and valid_b and (digest_a == digest_b)\n        results.append(is_reproducible)\n\n    # Final print statement\n    print(f\"[{','.join(map(lambda b: str(b), results))}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "Once a knowledge graph is constructed, its structure can reveal profound insights into the domain it represents. This exercise delves into the network-theoretic analysis of a biomedical KG, focusing on fundamental properties like node degree distributions. You will not only calculate these metrics but also connect them to significant biological concepts like polypharmacology, learning how abstract graph properties provide a quantitative lens for understanding complex systems .",
            "id": "4577536",
            "problem": "A biomedical Resource Description Framework (RDF) knowledge graph consists of typed nodes and directed edges represented as triples of the form $(\\text{subject}, \\text{predicate}, \\text{object})$. Consider the following small, scientifically plausible set of triples capturing Drug–Protein binding, Drug–Disease indication, and Drug–Pathway participation, along with relations pointing into Drugs:\n\n$(D\\_A, \\text{binds}, P1)$; $(D\\_A, \\text{binds}, P2)$; $(D\\_A, \\text{binds}, P3)$; $(D\\_A, \\text{treats}, Dis1)$; $(D\\_A, \\text{participates\\_in}, PW1)$\n\n$(D\\_B, \\text{binds}, P2)$; $(D\\_B, \\text{binds}, P3)$; $(D\\_B, \\text{treats}, Dis1)$; $(D\\_B, \\text{treats}, Dis2)$\n\n$(D\\_C, \\text{binds}, P4)$; $(D\\_C, \\text{binds}, P5)$\n\n$(D\\_D, \\text{binds}, P1)$; $(D\\_D, \\text{binds}, P2)$; $(D\\_D, \\text{binds}, P3)$; $(D\\_D, \\text{binds}, P4)$; $(D\\_D, \\text{treats}, Dis2)$; $(D\\_D, \\text{treats}, Dis3)$\n\n$(D\\_E, \\text{binds}, P1)$\n\n$(D\\_F, \\text{treats}, Dis3)$\n\n$(P1, \\text{inhibited\\_by}, D\\_A)$; $(Dis1, \\text{has\\_contraindicated\\_drug}, D\\_B)$; $(Dis2, \\text{has\\_indicated\\_drug}, D\\_D)$; $(PW1, \\text{has\\_participating\\_drug}, D\\_A)$; $(P3, \\text{activated\\_by}, D\\_D)$; $(Dis3, \\text{has\\_contraindicated\\_drug}, D\\_A)$; $(P4, \\text{inhibited\\_by}, D\\_C)$.\n\nFor each Drug node $d \\in \\{D\\_A, D\\_B, D\\_C, D\\_D, D\\_E, D\\_F\\}$, define the out-degree $k_{\\text{out}}(d)$ as the number of triples in which $d$ appears as the subject, and the in-degree $k_{\\text{in}}(d)$ as the number of triples in which $d$ appears as the object. Construct the empirical out-degree distribution $p_{\\text{out}}(k)$ over Drug nodes by the standard relative-frequency definition, and likewise the empirical in-degree distribution $p_{\\text{in}}(k)$.\n\nAssume that the out-degree tail for Drug nodes follows a continuous power-law above the threshold $x_{\\min} = 2$, that is, for $k \\ge x_{\\min}$ the tail density obeys $p(k) \\propto k^{-\\alpha}$ for some exponent $\\alpha$. Using only fundamental definitions of probability densities and the maximum likelihood principle, derive the maximum likelihood estimator for $\\alpha$ for the continuous power-law tail and compute its value for the Drug out-degrees in this graph with $x_{\\min} = 2$. Round your final numerical estimate of $\\alpha$ to $4$ significant figures. In your reasoning, interpret what a heavy-tailed $p_{\\text{out}}(k)$ implies about polypharmacology in this dataset, grounded in the constructed distributions. Express the final numerical answer without units.",
            "solution": "The problem is first validated to ensure it is scientifically grounded, well-posed, and objective.\n\n### Step 1: Extract Givens\nThe provided data consists of a set of RDF triples, definitions for node degrees, and a modeling assumption for the out-degree distribution.\n\n**RDF Triples (Edges):**\n*   $(D\\_A, \\text{binds}, P1)$; $(D\\_A, \\text{binds}, P2)$; $(D\\_A, \\text{binds}, P3)$; $(D\\_A, \\text{treats}, Dis1)$; $(D\\_A, \\text{participates\\_in}, PW1)$\n*   $(D\\_B, \\text{binds}, P2)$; $(D\\_B, \\text{binds}, P3)$; $(D\\_B, \\text{treats}, Dis1)$; $(D\\_B, \\text{treats}, Dis2)$\n*   $(D\\_C, \\text{binds}, P4)$; $(D\\_C, \\text{binds}, P5)$\n*   $(D\\_D, \\text{binds}, P1)$; $(D\\_D, \\text{binds}, P2)$; $(D\\_D, \\text{binds}, P3)$; $(D\\_D, \\text{binds}, P4)$; $(D\\_D, \\text{treats}, Dis2)$; $(D\\_D, \\text{treats}, Dis3)$\n*   $(D\\_E, \\text{binds}, P1)$\n*   $(D\\_F, \\text{treats}, Dis3)$\n*   $(P1, \\text{inhibited\\_by}, D\\_A)$; $(Dis1, \\text{has\\_contraindicated\\_drug}, D\\_B)$; $(Dis2, \\text{has\\_indicated\\_drug}, D\\_D)$; $(PW1, \\text{has\\_participating\\_drug}, D\\_A)$; $(P3, \\text{activated\\_by}, D\\_D)$; $(Dis3, \\text{has\\_contraindicated\\_drug}, D\\_A)$; $(P4, \\text{inhibited\\_by}, D\\_C)$\n\n**Definitions and Variables:**\n*   Set of Drug nodes: $d \\in \\{D\\_A, D\\_B, D\\_C, D\\_D, D\\_E, D\\_F\\}$\n*   Out-degree $k_{\\text{out}}(d)$: Number of triples where $d$ is the subject.\n*   In-degree $k_{\\text{in}}(d)$: Number of triples where $d$ is the object.\n*   Empirical distributions $p_{\\text{out}}(k)$ and $p_{\\text{in}}(k)$ are defined by relative frequencies.\n\n**Modeling Assumptions and Tasks:**\n*   The out-degree tail for Drug nodes follows a continuous power-law for $k \\ge x_{\\min}$.\n*   The power-law probability density function (PDF) is $p(k) \\propto k^{-\\alpha}$.\n*   The minimum value for the tail is $x_{\\min} = 2$.\n*   Derive the maximum likelihood estimator (MLE) for $\\alpha$.\n*   Compute the value of $\\alpha$ for the drug out-degrees, rounded to $4$ significant figures.\n*   Interpret the results in the context of polypharmacology.\n\n### Step 2: Validate Using Extracted Givens\nThe problem is scientifically grounded in network theory and bioinformatics. The concepts of RDF knowledge graphs, degree distributions, power laws, and maximum likelihood estimation are standard. The application to polypharmacology is a well-established area of research. The problem is well-posed, with all necessary data and definitions provided to arrive at a unique solution. The language is objective and formal. The assumption of a continuous power-law distribution for a discrete quantity (node degree) is a standard and widely accepted approximation used in the derivation of the estimator, particularly for simplifying the calculus. It does not constitute a scientific flaw but is a specified modeling choice. Therefore, the problem is deemed valid.\n\n### Step 3: Verdict and Action\nThe problem is valid. A full solution will be provided.\n\n### Solution Derivation\n\nFirst, we compute the out-degrees and in-degrees for each drug node based on the provided triples.\n\n**Out-Degrees ($k_{\\text{out}}$):**\n*   $k_{\\text{out}}(D\\_A) = 5$ (subject of $5$ triples)\n*   $k_{\\text{out}}(D\\_B) = 4$ (subject of $4$ triples)\n*   $k_{\\text{out}}(D\\_C) = 2$ (subject of $2$ triples)\n*   $k_{\\text{out}}(D\\_D) = 6$ (subject of $6$ triples)\n*   $k_{\\text{out}}(D\\_E) = 1$ (subject of $1$ triple)\n*   $k_{\\text{out}}(D\\_F) = 1$ (subject of $1$ triple)\nThe set of out-degrees is $\\{5, 4, 2, 6, 1, 1\\}$. The total number of drug nodes is $N=6$.\nThe empirical out-degree distribution $p_{\\text{out}}(k)$ is:\n*   $p_{\\text{out}}(1) = \\frac{2}{6} = \\frac{1}{3}$\n*   $p_{\\text{out}}(2) = \\frac{1}{6}$\n*   $p_{\\text{out}}(4) = \\frac{1}{6}$\n*   $p_{\\text{out}}(5) = \\frac{1}{6}$\n*   $p_{\\text{out}}(6) = \\frac{1}{6}$\n*   $p_{\\text{out}}(k) = 0$ for other values of $k$.\n\n**In-Degrees ($k_{\\text{in}}$):**\n*   $k_{\\text{in}}(D\\_A) = 3$ (object of $3$ triples)\n*   $k_{\\text{in}}(D\\_B) = 1$ (object of $1$ triple)\n*   $k_{\\text{in}}(D\\_C) = 1$ (object of $1$ triple)\n*   $k_{\\text{in}}(D\\_D) = 2$ (object of $2$ triples)\n*   $k_{\\text{in}}(D\\_E) = 0$ (object of $0$ triples)\n*   $k_{\\text{in}}(D\\_F) = 0$ (object of $0$ triples)\nThe set of in-degrees is $\\{3, 1, 1, 2, 0, 0\\}$.\nThe empirical in-degree distribution $p_{\\text{in}}(k)$ is:\n*   $p_{\\text{in}}(0) = \\frac{2}{6} = \\frac{1}{3}$\n*   $p_{\\text{in}}(1) = \\frac{2}{6} = \\frac{1}{3}$\n*   $p_{\\text{in}}(2) = \\frac{1}{6}$\n*   $p_{\\text{in}}(3) = \\frac{1}{6}$\n*   $p_{\\text{in}}(k) = 0$ for other values of $k$.\n\nNext, we derive the maximum likelihood estimator for the exponent $\\alpha$ of a continuous power-law distribution. The PDF is given by $p(k) \\propto k^{-\\alpha}$ for $k \\ge x_{\\min}$.\nFirst, we must normalize the PDF. Let $p(k) = Ck^{-\\alpha}$.\n$$ \\int_{x_{\\min}}^{\\infty} Ck^{-\\alpha} \\, dk = 1 $$\n$$ C \\left[ \\frac{k^{-\\alpha+1}}{1-\\alpha} \\right]_{x_{\\min}}^{\\infty} = 1 $$\nFor convergence, we require $1-\\alpha < 0$, or $\\alpha > 1$. Under this condition, the term at $\\infty$ is $0$.\n$$ C \\left( 0 - \\frac{x_{\\min}^{1-\\alpha}}{1-\\alpha} \\right) = 1 \\implies C = (\\alpha-1)x_{\\min}^{\\alpha-1} $$\nThe normalized PDF is $p(k|\\alpha, x_{\\min}) = (\\alpha-1)x_{\\min}^{\\alpha-1} k^{-\\alpha}$.\n\nGiven a set of $n$ observations $\\{k_i\\}$ where each $k_i \\ge x_{\\min}$, the likelihood function is:\n$$ L(\\alpha) = \\prod_{i=1}^{n} p(k_i|\\alpha, x_{\\min}) = \\prod_{i=1}^{n} (\\alpha-1)x_{\\min}^{\\alpha-1} k_i^{-\\alpha} $$\nThe log-likelihood $\\mathcal{L}(\\alpha) = \\ln(L(\\alpha))$ is easier to maximize:\n$$ \\mathcal{L}(\\alpha) = \\sum_{i=1}^{n} \\ln\\left( (\\alpha-1)x_{\\min}^{\\alpha-1} k_i^{-\\alpha} \\right) $$\n$$ \\mathcal{L}(\\alpha) = \\sum_{i=1}^{n} \\left[ \\ln(\\alpha-1) + (\\alpha-1)\\ln(x_{\\min}) - \\alpha\\ln(k_i) \\right] $$\n$$ \\mathcal{L}(\\alpha) = n\\ln(\\alpha-1) + n(\\alpha-1)\\ln(x_{\\min}) - \\alpha\\sum_{i=1}^{n}\\ln(k_i) $$\nTo find the maximum, we set the derivative with respect to $\\alpha$ to zero:\n$$ \\frac{d\\mathcal{L}}{d\\alpha} = \\frac{n}{\\alpha-1} + n\\ln(x_{\\min}) - \\sum_{i=1}^{n}\\ln(k_i) = 0 $$\nSolving for the estimator $\\hat{\\alpha}$:\n$$ \\frac{n}{\\hat{\\alpha}-1} = \\sum_{i=1}^{n}\\ln(k_i) - n\\ln(x_{\\min}) = \\sum_{i=1}^{n} \\ln\\left(\\frac{k_i}{x_{\\min}}\\right) $$\n$$ \\hat{\\alpha}-1 = n \\left( \\sum_{i=1}^{n} \\ln\\left(\\frac{k_i}{x_{\\min}}\\right) \\right)^{-1} $$\n$$ \\hat{\\alpha} = 1 + n \\left( \\sum_{i=1}^{n} \\ln\\left(\\frac{k_i}{x_{\\min}}\\right) \\right)^{-1} $$\nThis is the MLE for $\\alpha$.\n\nNow, we apply this estimator to the drug out-degree data. The set of all out-degrees is $\\{5, 4, 2, 6, 1, 1\\}$. The threshold is $x_{\\min} = 2$. We select the data points $k_i \\ge x_{\\min}$: $\\{5, 4, 2, 6\\}$. The number of these data points is $n=4$.\nWe compute the sum in the denominator:\n$$ \\sum_{i=1}^{4} \\ln\\left(\\frac{k_i}{x_{\\min}}\\right) = \\ln\\left(\\frac{5}{2}\\right) + \\ln\\left(\\frac{4}{2}\\right) + \\ln\\left(\\frac{2}{2}\\right) + \\ln\\left(\\frac{6}{2}\\right) $$\n$$ = \\ln(2.5) + \\ln(2) + \\ln(1) + \\ln(3) $$\nUsing the property $\\ln(a) + \\ln(b) = \\ln(ab)$ and that $\\ln(1)=0$:\n$$ = \\ln(2.5 \\times 2 \\times 3) = \\ln(15) $$\nSubstituting this into the MLE formula:\n$$ \\hat{\\alpha} = 1 + \\frac{4}{\\ln(15)} $$\nNumerically, $\\ln(15) \\approx 2.70805$.\n$$ \\hat{\\alpha} \\approx 1 + \\frac{4}{2.70805} \\approx 1 + 1.47707 \\approx 2.47707 $$\nRounding to $4$ significant figures, we get $\\hat{\\alpha} = 2.477$.\n\n**Interpretation:**\nThe out-degree $k_{\\text{out}}(d)$ of a drug $d$ represents the number of relationships originating from it, such as binding to proteins, treating diseases, or participating in pathways. A heavy-tailed out-degree distribution, as indicated by a power-law with exponent $\\hat{\\alpha} \\approx 2.477$ (a value typical for real-world networks), implies that most drugs have few connections, but a few \"hub\" drugs have a very large number of connections. In this dataset, drugs $D\\_A$ ($k_{\\text{out}}=5$) and $D\\_D$ ($k_{\\text{out}}=6$) are such hubs.\nPolypharmacology is the phenomenon where a single drug acts on multiple molecular targets. The 'binds' relationship is a direct representation of this. Drugs $D\\_A$ and $D\\_D$ bind to $3$ and $4$ proteins, respectively, exemplifying polypharmacology. The heavy-tailed nature of $p_{\\text{out}}(k)$ suggests that this polypharmacology is not evenly distributed but is a characteristic of a select few highly connected drugs. This has profound implications for drug discovery, suggesting that some drugs may achieve efficacy through multi-target engagement, but may also have a higher propensity for off-target side effects.",
            "answer": "$$\n\\boxed{2.477}\n$$"
        },
        {
            "introduction": "Knowledge graphs are powerful tools for prediction, particularly for discovering new relationships through link prediction. However, a predictive model is only as good as its evaluation is sound. This practice provides hands-on experience implementing the standard evaluation metrics for link prediction—Hits@$k$ and Mean Reciprocal Rank (MRR)—from first principles, using vector embeddings of entities . Mastering this task is essential for anyone developing or comparing knowledge graph embedding models.",
            "id": "4577593",
            "problem": "You are given low-dimensional vector representations of biomedical entities that were trained from a gene–disease knowledge graph. Each gene and each disease is represented by a vector in $\\mathbb{R}^d$. The similarity between a gene vector and a disease vector is defined as the cosine similarity, which is the dot product between the vectors after $\\ell_2$-normalization. From first principles of ranking evaluation in information retrieval, define a total order over candidate diseases for each query gene by sorting diseases in descending order of similarity. If two diseases have exactly equal similarity with a query gene, break the tie deterministically by assigning higher rank to the disease with the smaller integer index.\n\nUsing these principles and definitions only, implement a program that, for each test case, computes the following two query-aggregated ranking metrics from first principles:\n- Hits at $k$ (written as $\\text{Hits@}k$): for a fixed integer $k \\geq 1$, for each query gene compute whether at least one of its relevant diseases appears among the top $k$ positions in the ranked list, and then average these binary outcomes across all query genes in the test case to obtain a value in $[0,1]$ expressed as a decimal number.\n- Mean Reciprocal Rank (written as $\\text{MRR}$): for each query gene, determine the rank position (where the top position is $1$) of the highest-ranked relevant disease; take the reciprocal of this rank; then average these reciprocals across all query genes in the test case to obtain a value in $(0,1]$ expressed as a decimal number.\n\nThe scoring function must be the cosine similarity between the $\\ell_2$-normalized gene and disease embeddings. All vectors provided are nonzero. Ranking must strictly follow descending cosine similarity with the deterministic tie-breaking rule described above. For a query gene with more than one relevant disease, determine the reciprocal rank using the highest-ranked relevant disease. Queries always have at least one relevant disease.\n\nYour program must implement the evaluation exactly as described and compute the metrics for the following test suite. In each case, disease indices are zero-based integers and gene indices are zero-based integers. All embeddings are provided row-wise.\n\nTest case $\\mathrm{A}$ (happy path with a tie not affecting the top position):\n- Disease embeddings $\\mathbf{D}^{(\\mathrm{A})} \\in \\mathbb{R}^{4 \\times 3}$:\n  - Row $0$: $[1,0,0]$\n  - Row $1$: $[0,1,0]$\n  - Row $2$: $[0,0,1]$\n  - Row $3$: $[-1,0,0]$\n- Gene embeddings $\\mathbf{G}^{(\\mathrm{A})} \\in \\mathbb{R}^{2 \\times 3}$:\n  - Row $0$: $[0.9,0.1,0.0]$\n  - Row $1$: $[0.0,0.7,0.7]$\n- Relevant disease sets $\\mathcal{T}^{(\\mathrm{A})}$:\n  - Gene $0$: $\\{0\\}$\n  - Gene $1$: $\\{2\\}$\n- Requested $k$ values: $k \\in \\{1,3\\}$\n\nTest case $\\mathrm{B}$ (single query with multiple relevant diseases and a decisive tie at the top that is resolved by index):\n- Disease embeddings $\\mathbf{D}^{(\\mathrm{B})} \\in \\mathbb{R}^{5 \\times 5}$:\n  - Row $0$: $[1,0,0,0,0]$\n  - Row $1$: $[0,1,0,0,0]$\n  - Row $2$: $[0,0,1,0,0]$\n  - Row $3$: $[0,0,0,1,0]$\n  - Row $4$: $[0,0,0,0,1]$\n- Gene embeddings $\\mathbf{G}^{(\\mathrm{B})} \\in \\mathbb{R}^{1 \\times 5}$:\n  - Row $0$: $[0,1,1,0,0]$\n- Relevant disease sets $\\mathcal{T}^{(\\mathrm{B})}$:\n  - Gene $0$: $\\{2,4\\}$\n- Requested $k$ values: $k \\in \\{1,2\\}$\n\nTest case $\\mathrm{C}$ (adversarial tie across all diseases resolved purely by index, with three queries):\n- Disease embeddings $\\mathbf{D}^{(\\mathrm{C})} \\in \\mathbb{R}^{3 \\times 3}$:\n  - Row $0$: $[1,0,0]$\n  - Row $1$: $[0,1,0]$\n  - Row $2$: $[0,0,1]$\n- Gene embeddings $\\mathbf{G}^{(\\mathrm{C})} \\in \\mathbb{R}^{3 \\times 3}$:\n  - Row $0$: $[1,1,1]$\n  - Row $1$: $[1,1,1]$\n  - Row $2$: $[1,1,1]$\n- Relevant disease sets $\\mathcal{T}^{(\\mathrm{C})}$:\n  - Gene $0$: $\\{1\\}$\n  - Gene $1$: $\\{2\\}$\n  - Gene $2$: $\\{0\\}$\n- Requested $k$ values: $k \\in \\{1,2\\}$\n\nYour program must:\n- Normalize all embeddings to unit $\\ell_2$-norm before computing cosine similarities.\n- For each test case, compute $\\text{MRR}$ and each requested $\\text{Hits@}k$ using the definitions above.\n- Use the tie-breaking rule based on ascending disease index for exactly equal cosine similarities.\n\nFinal output format:\n- Produce a single line of output containing a comma-separated list enclosed in square brackets with the values in the following order:\n  - For test case $\\mathrm{A}$: $\\text{MRR}$, then $\\text{Hits@}1$, then $\\text{Hits@}3$.\n  - For test case $\\mathrm{B}$: $\\text{MRR}$, then $\\text{Hits@}1$, then $\\text{Hits@}2$.\n  - For test case $\\mathrm{C}$: $\\text{MRR}$, then $\\text{Hits@}1$, then $\\text{Hits@}2$.\n- Each value must be rounded to exactly $6$ decimal places and represented as a decimal number.\n- For example, a valid output would be of the form $[x_1,x_2,\\dots,x_9]$ where each $x_i$ is a decimal with exactly $6$ digits after the decimal point.",
            "solution": "The problem statement has been rigorously validated and is found to be scientifically grounded, well-posed, and objective. It represents a standard task in the evaluation of knowledge graph embeddings, a subfield of bioinformatics and machine learning. All definitions, data, and constraints are complete, consistent, and formalizable. Therefore, a solution is presented below.\n\nThe problem requires the implementation of a ranking evaluation pipeline for biomedical entities represented as vectors. The evaluation is based on first principles of information retrieval. The solution proceeds in four primary stages for each gene-disease test case: $1$) vector normalization, $2$) similarity scoring, $3$) ranking with deterministic tie-breaking, and $4$) computation of aggregated performance metrics.\n\n**1. Vector Normalization**\nEach vector $\\mathbf{v}$ in the embedding space $\\mathbb{R}^d$ must first be projected onto the unit hypersphere. This is achieved through $\\ell_2$-normalization. The normalized vector $\\hat{\\mathbf{v}}$ is given by:\n$$\n\\hat{\\mathbf{v}} = \\frac{\\mathbf{v}}{\\|\\mathbf{v}\\|_2}\n$$\nwhere $\\|\\mathbf{v}\\|_2$ is the Euclidean norm (or $\\ell_2$-norm) of $\\mathbf{v}$, calculated as $\\|\\mathbf{v}\\|_2 = \\sqrt{\\sum_{i=1}^d v_i^2}$. Since the problem guarantees all vectors are nonzero, this operation is always well-defined.\n\n**2. Similarity Scoring**\nThe similarity between a query gene vector $\\mathbf{g}$ and a candidate disease vector $\\mathbf{d}$ is the cosine similarity. After normalization, this is equivalent to the dot product of the normalized vectors:\n$$\n\\text{sim}(\\mathbf{g}, \\mathbf{d}) = \\cos(\\theta) = \\hat{\\mathbf{g}} \\cdot \\hat{\\mathbf{d}} = \\sum_{i=1}^d \\hat{g}_i \\hat{d}_i\n$$\nThis score ranges from $-1$ (perfectly anti-similar) to $1$ (perfectly similar).\n\n**3. Ranking and Tie-Breaking**\nFor each query gene $\\mathbf{g}_i$, we compute its similarity score with every disease $\\mathbf{d}_j$ in the dataset, yielding a set of scores $\\{s_{ij}\\}_{j=0}^{N_d-1}$. To establish a definitive ranking, we form pairs of (score, disease index): $(s_{ij}, j)$. These pairs are sorted according to a lexicographical key. The primary sorting criterion is the score $s_{ij}$ in descending order. The secondary criterion, applied only when two scores are identical ($s_{ij_1} = s_{ij_2}$), is the disease index $j$ in ascending order. This deterministic rule ensures a unique total order over all diseases for any given query.\n\n**4. Performance Metrics**\nUsing the generated ranked list for each query gene, we compute two standard metrics:\n\n- **Mean Reciprocal Rank (MRR):** For a query gene $\\mathbf{g}_i$ with a set of relevant diseases $\\mathcal{T}_i$, we identify the rank of the highest-positioned relevant disease in its list. This is denoted as $\\text{rank}_i = \\min_{j \\in \\mathcal{T}_i} \\text{rank}(j)$. The reciprocal rank is $1/\\text{rank}_i$. The MRR is the arithmetic mean of these values across all $N_g$ queries:\n$$\n\\text{MRR} = \\frac{1}{N_g} \\sum_{i=0}^{N_g-1} \\frac{1}{\\text{rank}_i}\n$$\n\n- **Hits at $k$ ($\\text{Hits@}k$):** For a given integer $k \\ge 1$, we check if any relevant disease for a query $\\mathbf{g}_i$ appears within the top $k$ positions of its ranked list. This yields a binary outcome $h_i(k)$:\n$$\nh_i(k) =\n\\begin{cases}\n1 & \\text{if } \\exists j \\in \\mathcal{T}_i \\text{ such that } \\text{rank}(j) \\le k \\\\\n0 & \\text{otherwise}\n\\end{cases}\n$$\nThe $\\text{Hits@}k$ metric is the mean of these outcomes over all $N_g$ queries:\n$$\n\\text{Hits@}k = \\frac{1}{N_g} \\sum_{i=0}^{N_g-1} h_i(k)\n$$\n\nThe following sections apply this methodology to each test case.\n\n**Test Case A**\n- Disease embeddings $\\mathbf{D}^{(\\mathrm{A})}$ and gene embeddings $\\mathbf{G}^{(\\mathrm{A})}$ are provided. The disease vectors $\\mathbf{d}_0, \\mathbf{d}_1, \\mathbf{d}_2, \\mathbf{d}_3$ are already unit vectors.\n- Gene vectors are normalized:\n  - $\\mathbf{g}_0 = [0.9, 0.1, 0.0] \\implies \\|\\mathbf{g}_0\\|_2 = \\sqrt{0.82} \\implies \\hat{\\mathbf{g}}_0 \\approx [0.9938, 0.1104, 0.0]$\n  - $\\mathbf{g}_1 = [0.0, 0.7, 0.7] \\implies \\|\\mathbf{g}_1\\|_2 = \\sqrt{0.98} \\implies \\hat{\\mathbf{g}}_1 \\approx [0.0, 0.7071, 0.7071]$\n- Query 1 ($i=0$, relevant disease $\\mathcal{T}_0=\\{0\\}$):\n  - Scores: $\\text{sim}(\\mathbf{g}_0, \\mathbf{d}_0) \\approx 0.9938$, $\\text{sim}(\\mathbf{g}_0, \\mathbf{d}_1) \\approx 0.1104$, $\\text{sim}(\\mathbf{g}_0, \\mathbf{d}_2)=0.0$, $\\text{sim}(\\mathbf{g}_0, \\mathbf{d}_3)\\approx -0.9938$.\n  - Rank list: $[0, 1, 2, 3]$. Relevant disease $0$ is at rank $1$.\n  - RR: $1/1 = 1.0$. Hits@1: $1$. Hits@3: $1$.\n- Query 2 ($i=1$, relevant $\\mathcal{T}_1=\\{2\\}$):\n  - Scores: $\\text{sim}(\\mathbf{g}_1, \\mathbf{d}_0)=0.0$, $\\text{sim}(\\mathbf{g}_1, \\mathbf{d}_1) \\approx 0.7071$, $\\text{sim}(\\mathbf{g}_1, \\mathbf{d}_2) \\approx 0.7071$, $\\text{sim}(\\mathbf{g}_1, \\mathbf{d}_3)=0.0$.\n  - Tie between diseases $1$ and $2$. Since $1 < 2$, disease $1$ is ranked higher. Tie between $0$ and $3$, $0<3$, so $0$ is ranked higher.\n  - Rank list: $[1, 2, 0, 3]$. Relevant disease $2$ is at rank $2$.\n  - RR: $1/2 = 0.5$. Hits@1: $0$. Hits@3: $1$.\n- Aggregated results for Case A:\n  - MRR = $(1.0 + 0.5) / 2 = 0.75$\n  - Hits@1 = $(1 + 0) / 2 = 0.5$\n  - Hits@3 = $(1 + 1) / 2 = 1.0$\n\n**Test Case B**\n- Disease embeddings $\\mathbf{D}^{(\\mathrm{B})}$ are standard basis vectors, already normalized.\n- Gene vector is normalized: $\\mathbf{g}_0 = [0,1,1,0,0] \\implies \\|\\mathbf{g}_0\\|_2 = \\sqrt{2} \\implies \\hat{\\mathbf{g}}_0 = [0, 1/\\sqrt{2}, 1/\\sqrt{2}, 0, 0] \\approx [0, 0.7071, 0.7071, 0, 0]$.\n- Query 1 ($i=0$, relevant $\\mathcal{T}_0=\\{2, 4\\}$):\n  - Scores: $s_{00}=0, s_{01} \\approx 0.7071, s_{02} \\approx 0.7071, s_{03}=0, s_{04}=0$.\n  - Tie between $1$ and $2$. Since $1 < 2$, $1$ is ranked higher. Tie among $0, 3, 4$, ranking follows index: $0, 3, 4$.\n  - Rank list: $[1, 2, 0, 3, 4]$.\n  - Relevant diseases are $2$ (rank $2$) and $4$ (rank $5$). The highest-ranked is disease $2$ at rank $2$.\n  - RR: $1/2 = 0.5$. Hits@1: $0$. Hits@2: $1$.\n- Aggregated results for Case B (single query):\n  - MRR = $0.5$\n  - Hits@1 = $0.0$\n  - Hits@2 = $1.0$\n\n**Test Case C**\n- Disease embeddings $\\mathbf{D}^{(\\mathrm{C})}$ are standard basis vectors, already normalized.\n- All gene vectors are identical: $\\mathbf{g}_i = [1,1,1] \\implies \\|\\mathbf{g}_i\\|_2 = \\sqrt{3} \\implies \\hat{\\mathbf{g}}_i = [1/\\sqrt{3}, 1/\\sqrt{3}, 1/\\sqrt{3}] \\approx [0.5774, 0.5774, 0.5774]$.\n- For any query gene, the similarity scores with all three diseases are identical: $s_{i0} = s_{i1} = s_{i2} = 1/\\sqrt{3}$.\n- The ranking is determined entirely by the tie-breaking rule (ascending disease index).\n- Rank list for all queries: $[0, 1, 2]$.\n- Query 1 ($i=0$, relevant $\\mathcal{T}_0=\\{1\\}$): Disease $1$ is at rank $2$. RR: $1/2$. Hits@1:$0$. Hits@2:$1$.\n- Query 2 ($i=1$, relevant $\\mathcal{T}_1=\\{2\\}$): Disease $2$ is at rank $3$. RR: $1/3$. Hits@1:$0$. Hits@2:$0$.\n- Query 3 ($i=2$, relevant $\\mathcal{T}_2=\\{0\\}$): Disease $0$ is at rank $1$. RR: $1/1$. Hits@1:$1$. Hits@2:$1$.\n- Aggregated results for Case C:\n  - MRR = $(1/2 + 1/3 + 1/1) / 3 = (11/6) / 3 = 11/18 \\approx 0.611111$\n  - Hits@1 = $(0 + 0 + 1) / 3 = 1/3 \\approx 0.333333$\n  - Hits@2 = $(1 + 0 + 1) / 3 = 2/3 \\approx 0.666667$",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to define test cases, run the evaluation, and print results.\n    \"\"\"\n    \n    test_cases = [\n        {\n            \"name\": \"A\",\n            \"gene_embeds\": np.array([\n                [0.9, 0.1, 0.0],\n                [0.0, 0.7, 0.7]\n            ]),\n            \"disease_embeds\": np.array([\n                [1.0, 0.0, 0.0],\n                [0.0, 1.0, 0.0],\n                [0.0, 0.0, 1.0],\n                [-1.0, 0.0, 0.0]\n            ]),\n            \"relevant_sets\": [\n                {0},\n                {2}\n            ],\n            \"k_values\": [1, 3]\n        },\n        {\n            \"name\": \"B\",\n            \"gene_embeds\": np.array([\n                [0.0, 1.0, 1.0, 0.0, 0.0]\n            ]),\n            \"disease_embeds\": np.array([\n                [1.0, 0.0, 0.0, 0.0, 0.0],\n                [0.0, 1.0, 0.0, 0.0, 0.0],\n                [0.0, 0.0, 1.0, 0.0, 0.0],\n                [0.0, 0.0, 0.0, 1.0, 0.0],\n                [0.0, 0.0, 0.0, 0.0, 1.0]\n            ]),\n            \"relevant_sets\": [\n                {2, 4}\n            ],\n            \"k_values\": [1, 2]\n        },\n        {\n            \"name\": \"C\",\n            \"gene_embeds\": np.array([\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0]\n            ]),\n            \"disease_embeds\": np.array([\n                [1.0, 0.0, 0.0],\n                [0.0, 1.0, 0.0],\n                [0.0, 0.0, 1.0]\n            ]),\n            \"relevant_sets\": [\n                {1},\n                {2},\n                {0}\n            ],\n            \"k_values\": [1, 2]\n        }\n    ]\n\n    final_results = []\n    \n    for case in test_cases:\n        metrics = evaluate_case(\n            case[\"gene_embeds\"],\n            case[\"disease_embeds\"],\n            case[\"relevant_sets\"],\n            case[\"k_values\"]\n        )\n        final_results.extend(metrics)\n\n    formatted_results = [f\"{val:.6f}\" for val in final_results]\n    print(f\"[{','.join(formatted_results)}]\")\n\ndef evaluate_case(gene_embeds, disease_embeds, relevant_sets, k_values):\n    \"\"\"\n    Computes MRR and Hits@k for a single test case.\n    \"\"\"\n    # 1. L2-normalize all embeddings\n    gene_norms = np.linalg.norm(gene_embeds, axis=1, keepdims=True)\n    disease_norms = np.linalg.norm(disease_embeds, axis=1, keepdims=True)\n    \n    # Avoid division by zero, though problem guarantees non-zero vectors\n    gene_norms[gene_norms == 0] = 1e-10\n    disease_norms[disease_norms == 0] = 1e-10\n    \n    norm_gene_embeds = gene_embeds / gene_norms\n    norm_disease_embeds = disease_embeds / disease_norms\n    \n    num_queries = gene_embeds.shape[0]\n    num_diseases = disease_embeds.shape[0]\n    \n    reciprocal_ranks = []\n    hits_at_k_per_query = {k: [] for k in k_values}\n    \n    for i in range(num_queries):\n        query_gene_vec = norm_gene_embeds[i, :]\n        relevant_diseases = relevant_sets[i]\n        \n        # 2. Compute cosine similarities (dot product of normalized vectors)\n        scores = np.dot(norm_disease_embeds, query_gene_vec)\n        \n        # 3. Create pairs of (score, index) and rank them\n        # Sorting key: primary is score descending, secondary is index ascending\n        score_index_pairs = list(zip(scores, range(num_diseases)))\n        score_index_pairs.sort(key=lambda x: (-x[0], x[1]))\n        \n        ranked_disease_indices = [idx for score, idx in score_index_pairs]\n        \n        # 4. Find rank of the highest-ranked relevant disease for MRR\n        min_rank = -1\n        for rank_pos, disease_idx in enumerate(ranked_disease_indices, 1):\n            if disease_idx in relevant_diseases:\n                min_rank = rank_pos\n                break\n        \n        # Problem guarantees at least one relevant disease, so min_rank is always found\n        reciprocal_ranks.append(1.0 / min_rank)\n        \n        # 5. Compute Hits@k for each k\n        for k in k_values:\n            top_k_indices = set(ranked_disease_indices[:k])\n            # Intersection is non-empty if there's a hit\n            if not top_k_indices.isdisjoint(relevant_diseases):\n                hits_at_k_per_query[k].append(1)\n            else:\n                hits_at_k_per_query[k].append(0)\n\n    # 6. Aggregate metrics across all queries\n    mrr = np.mean(reciprocal_ranks)\n    \n    # Sort k_values to ensure deterministic output order\n    sorted_k = sorted(k_values)\n    hits_results = [np.mean(hits_at_k_per_query[k]) for k in sorted_k]\n    \n    return [mrr] + hits_results\n\n# Execute the solution\nsolve()\n```"
        }
    ]
}