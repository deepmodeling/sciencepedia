{
    "hands_on_practices": [
        {
            "introduction": "At the core of predicting the functional consequences of gene editing is the triplet codon structure dictated by the Central Dogma of molecular biology. An insertion or deletion (indel) that is not a multiple of three nucleotides disrupts the reading frame, typically resulting in a non-functional protein. This fundamental exercise  provides practice in applying this principle to calculate the expected frameshift probability from an empirical distribution of editing outcomes, a foundational skill for analyzing high-throughput sequencing data.",
            "id": "4566205",
            "problem": "In Clustered Regularly Interspaced Short Palindromic Repeats (CRISPR) gene editing outcome prediction, the impact of an insertion or deletion event on the protein coding frame is governed by the triplet codon structure derived from the Central Dogma of molecular biology, where amino acids are encoded by trinucleotide codons. A deletion of length $L$ nucleotides in a coding exon yields a frameshift if and only if the reading frame is altered, which occurs when $L \\bmod 3 \\neq 0$. Consider a single edited allele drawn at random from a large population of Next-Generation Sequencing (NGS)-profiled outcomes. Let $L$ denote the deletion length in nucleotides, with empirically observed probabilities $P(L=1)=0.3$, $P(L=2)=0.2$, $P(L=3)=0.1$, and assume the distribution is uniform for $L \\in \\{4,5,6\\}$. Using the law of total probability and the codon-size rule for frameshifts, compute the expected frameshift probability $P(\\text{frameshift})=\\mathbb{P}(L \\bmod 3 \\neq 0)$ for this target. Express your final answer as a rational number in simplest terms. Do not use a percentage sign.",
            "solution": "The problem asks for the expected frameshift probability, denoted as $P(\\text{frameshift})$, for a deletion event in a CRISPR-edited allele population. The random variable $L$ represents the length of the deletion in nucleotides.\n\nFirst, we must fully define the probability distribution of $L$. The problem provides specific probabilities for lengths $L=1$, $L=2$, and $L=3$:\n$$P(L=1) = 0.3$$\n$$P(L=2) = 0.2$$\n$$P(L=3) = 0.1$$\n\nThe problem also states that the distribution is uniform for $L \\in \\{4, 5, 6\\}$. The total probability over the sample space of a random variable must sum to $1$. Let's assume the sample space is limited to the values for which probabilities are given or described, i.e., $S = \\{1, 2, 3, 4, 5, 6\\}$.\n\nThe probability mass already accounted for by $L=1, 2, 3$ is:\n$$P(L=1) + P(L=2) + P(L=3) = 0.3 + 0.2 + 0.1 = 0.6$$\n\nThe remaining probability mass must be distributed among the other possible outcomes. According to the problem statement, this remaining mass corresponds to the events $L=4$, $L=5$, and $L=6$.\n$$P(L \\in \\{4, 5, 6\\}) = 1 - 0.6 = 0.4$$\n\nSince the distribution is uniform for $L \\in \\{4, 5, 6\\}$, the probability $0.4$ is divided equally among these three outcomes:\n$$P(L=4) = P(L=5) = P(L=6) = \\frac{0.4}{3}$$\n\nTo work with exact rational numbers as requested for the final answer, we convert all probabilities to fractions:\n$$P(L=1) = \\frac{3}{10}$$\n$$P(L=2) = \\frac{2}{10} = \\frac{1}{5}$$\n$$P(L=3) = \\frac{1}{10}$$\n$$P(L=4) = P(L=5) = P(L=6) = \\frac{0.4}{3} = \\frac{4/10}{3} = \\frac{4}{30} = \\frac{2}{15}$$\n\nLet's verify that the total probability is $1$:\n$$\\sum_{l=1}^{6} P(L=l) = \\frac{3}{10} + \\frac{2}{10} + \\frac{1}{10} + \\frac{2}{15} + \\frac{2}{15} + \\frac{2}{15} = \\frac{6}{10} + 3 \\times \\frac{2}{15} = \\frac{3}{5} + \\frac{6}{15} = \\frac{3}{5} + \\frac{2}{5} = \\frac{5}{5} = 1$$\nThe probability distribution is consistent and well-defined.\n\nThe problem states that a frameshift occurs if and only if the deletion length $L$ is not a multiple of $3$. This is mathematically expressed as $L \\bmod 3 \\neq 0$. We need to calculate $P(L \\bmod 3 \\neq 0)$.\n\nIt is often simpler to calculate the probability of the complementary event, which is that the deletion is in-frame. An in-frame deletion occurs when $L$ is a multiple of $3$, or $L \\bmod 3 = 0$. We can then use the identity $P(A) = 1 - P(A^c)$, where $A$ is the frameshift event and $A^c$ is the in-frame event.\n\nLet's identify the outcomes in our sample space $S = \\{1, 2, 3, 4, 5, 6\\}$ that result in an in-frame deletion:\n- $L=3$: $3 \\bmod 3 = 0$. This is in-frame.\n- $L=6$: $6 \\bmod 3 = 0$. This is in-frame.\n\nThe probability of an in-frame deletion is the sum of the probabilities of these mutually exclusive events:\n$$P(\\text{in-frame}) = P(L \\bmod 3 = 0) = P(L=3) + P(L=6)$$\nSubstituting the fractional probabilities:\n$$P(\\text{in-frame}) = \\frac{1}{10} + \\frac{2}{15}$$\nTo sum these fractions, we find a common denominator, which is $30$:\n$$P(\\text{in-frame}) = \\frac{1 \\times 3}{10 \\times 3} + \\frac{2 \\times 2}{15 \\times 2} = \\frac{3}{30} + \\frac{4}{30} = \\frac{7}{30}$$\n\nThe probability of a frameshift is the complement of the probability of an in-frame deletion:\n$$P(\\text{frameshift}) = P(L \\bmod 3 \\neq 0) = 1 - P(\\text{in-frame})$$\n$$P(\\text{frameshift}) = 1 - \\frac{7}{30} = \\frac{30}{30} - \\frac{7}{30} = \\frac{23}{30}$$\n\nThe numerator, $23$, is a prime number, and the denominator, $30$, is not a multiple of $23$. Therefore, the fraction is in its simplest terms.\n\nAlternatively, we could directly sum the probabilities of the frameshift events. The outcomes causing a frameshift ($L \\bmod 3 \\neq 0$) are $L \\in \\{1, 2, 4, 5\\}$.\n$$P(\\text{frameshift}) = P(L=1) + P(L=2) + P(L=4) + P(L=5)$$\n$$P(\\text{frameshift}) = \\frac{3}{10} + \\frac{2}{10} + \\frac{2}{15} + \\frac{2}{15}$$\n$$P(\\text{frameshift}) = \\frac{5}{10} + \\frac{4}{15} = \\frac{1}{2} + \\frac{4}{15}$$\nFinding a common denominator of $30$:\n$$P(\\text{frameshift}) = \\frac{1 \\times 15}{2 \\times 15} + \\frac{4 \\times 2}{15 \\times 2} = \\frac{15}{30} + \\frac{8}{30} = \\frac{23}{30}$$\nBoth methods yield the same result.",
            "answer": "$$\\boxed{\\frac{23}{30}}$$"
        },
        {
            "introduction": "The spectrum of editing outcomes at a double-strand break is not random but is governed by the DNA repair pathway engaged by the cell. This practice  challenges you to contrast the distinct signatures of Non-Homologous End Joining (NHEJ) and Microhomology-Mediated End Joining (MMEJ). By analyzing how local sequence context—such as the codon periodicity of an exon—can systematically bias outcomes toward frameshifts or in-frame edits for each pathway, you will develop a deeper intuition for how underlying biology shapes the data we seek to predict.",
            "id": "4566233",
            "problem": "A Clustered Regularly Interspaced Short Palindromic Repeats (CRISPR)-induced Double-Strand Break (DSB) is introduced within a coding exon that exhibits trinucleotide periodicity of motifs consistent with codon structure. You are asked to predict how the repair pathway choice between Non-Homologous End Joining (NHEJ) and Microhomology-Mediated End Joining (MMEJ) will differentially affect the distribution of frameshift versus in-frame edits at this locus, given the local sequence context and empirically observed biases. Use only fundamental principles of coding sequence translation and canonical definitions of the repair mechanisms.\n\nAssumptions and observed context:\n- The exon is enriched for codon-periodic repeats (for example, a CAG/CAA-rich region), such that within $\\,\\pm 15\\,$ base pairs (bp) of the cut, a motif scan identifies microhomology pairs with distances $d$ distributed as follows: $d=3$ with probability $0.50$, $d=6$ with probability $0.20$, $d=4$ with probability $0.15$, and $d=5$ with probability $0.15$. Under MMEJ, the deletion size equals the distance $d$ between the paired microhomologies, and the microhomology tract length is short (for example, $2$ bp), consistent with local sequence composition.\n- For NHEJ at this locus, deep profiling at matched sequence contexts shows a bias toward small templated insertions, with an indel size distribution: $+1$ bp with probability $0.35$, $+2$ bp with probability $0.15$, $-1$ bp with probability $0.25$, $-2$ bp with probability $0.15$, and $-3$ bp with probability $0.10$.\n- The cut occurs at codon phase $0$ (between codons), and the coding reading frame is preserved if and only if the net indel length is a multiple of $3$.\n\nQuestion: Based on these principles and observations, which statement best describes the expected distributions of frameshift versus in-frame edits under NHEJ versus MMEJ for this target?\n\nA. NHEJ will yield a higher fraction of in-frame edits than MMEJ, because small insertions are evenly distributed across sizes and often sum to multiples of $3$, whereas MMEJ deletions have no relationship to codon periodicity.\n\nB. NHEJ will be enriched for frameshifts due to the predominance of $+1$ bp and $+2$ bp templated insertions and $-1$ bp and $-2$ bp deletions, while MMEJ will produce more in-frame deletions because microhomology distances in a codon-periodic exon are frequently multiples of $3$; therefore, the in-frame fraction under MMEJ will exceed that under NHEJ at this locus.\n\nC. The in-frame to frameshift ratio will be similar under NHEJ and MMEJ, since the reading frame is independent of the distribution of indel sizes and of microhomology spacing.\n\nD. MMEJ will mostly generate $+1$ bp and $+2$ bp insertions, making frameshifts predominant under MMEJ, whereas NHEJ will be enriched for $-3$ bp deletions, leading to a higher in-frame fraction under NHEJ than under MMEJ.",
            "solution": "The user wants me to solve a problem about CRISPR gene editing.\n\n**1. Problem Validation**\n\nFirst, I will validate the problem statement according to the user's instructions.\n\n**1.1. Givens Extraction**\nThe problem provides the following information:\n- A Clustered Regularly Interspaced Short Palindromic Repeats (CRISPR)-induced Double-Strand Break (DSB) is introduced in a coding exon.\n- The exon has trinucleotide periodicity.\n- The two repair pathways to consider are Non-Homologous End Joining (NHEJ) and Microhomology-Mediated End Joining (MMEJ).\n- **MMEJ Context**:\n    - Microhomology pairs are identified within $\\pm 15$ base pairs (bp) of the cut.\n    - The distance $d$ between microhomology pairs has the following probability distribution:\n        - $P(d=3) = 0.50$\n        - $P(d=6) = 0.20$\n        - $P(d=4) = 0.15$\n        - $P(d=5) = 0.15$\n    - For MMEJ, the resulting deletion size is equal to the distance $d$.\n- **NHEJ Context**:\n    - There is a bias towards small templated insertions.\n    - The indel size distribution is given as:\n        - $+1$ bp insertion with probability $0.35$.\n        - $+2$ bp insertion with probability $0.15$.\n        - $-1$ bp deletion with probability $0.25$.\n        - $-2$ bp deletion with probability $0.15$.\n        - $-3$ bp deletion with probability $0.10$.\n- **Frameshift Rule**:\n    - The DSB occurs at codon phase $0$ (between codons).\n    - An edit is in-frame if and only if the net indel length is a multiple of $3$.\n\n**1.2. Validation against Criteria**\n- **Scientifically Grounded**: The problem is well-grounded in molecular biology and gene editing. The concepts of CRISPR, DSB, NHEJ, MMEJ, coding exons, reading frames, frameshift mutations, codon periodicity, and the influence of microhomology on repair outcomes are all established principles in the field.\n- **Well-Posed**: The problem is well-posed. It provides complete probability distributions for the outcomes of both repair pathways (for MMEJ, $0.50 + 0.20 + 0.15 + 0.15 = 1.00$; for NHEJ, $0.35 + 0.15 + 0.25 + 0.15 + 0.10 = 1.00$). It also provides a clear and mathematically precise rule for determining whether an outcome is in-frame or a frameshift. This allows for a unique, quantitative comparison between the two pathways.\n- **Objective**: The problem is stated in objective, scientific language. The data is quantitative, and the question asks for a conclusion based on these data and fundamental principles. There is no subjective or ambiguous language.\n- **Other Flaws**: The problem statement does not exhibit any of the listed flaws (e.g., incompleteness, contradiction, infeasibility, etc.). The premise is a common scenario in genomics research, and the data, while simplified for the purpose of the problem, is plausible.\n\n**1.3. Verdict**\nThe problem statement is valid. I will proceed with the solution.\n\n**2. Solution Derivation**\n\nThe core task is to calculate the probability of an in-frame edit for each repair pathway, NHEJ and MMEJ, and then compare these probabilities. According to the problem statement, an edit is in-frame if the indel length is a non-zero multiple of $3$. An indel of length $0$ would also be in-frame, but is not among the possible outcomes for either pathway.\n\n**2.1. Analysis of MMEJ**\nThe MMEJ pathway results in deletions whose sizes are given by the distance $d$ between microhomology pairs. The possible deletion sizes are $-d$, where $d \\in \\{3, 4, 5, 6\\}$. An outcome is in-frame if its size is a multiple of $3$.\nThe in-frame deletion sizes are those where $d$ is a multiple of $3$. From the given distribution, these are $d=3$ and $d=6$.\nThe probability of an in-frame edit under MMEJ, denoted as $P(\\text{in-frame} | \\text{MMEJ})$, is the sum of the probabilities of the events leading to in-frame deletions:\n$$P(\\text{in-frame} | \\text{MMEJ}) = P(d=3) + P(d=6)$$\nSubstituting the given probabilities:\n$$P(\\text{in-frame} | \\text{MMEJ}) = 0.50 + 0.20 = 0.70$$\nThus, there is a $70\\%$ probability that an MMEJ-mediated repair will result in an in-frame deletion. The probability of a frameshift is $1 - 0.70 = 0.30$.\n\n**2.2. Analysis of NHEJ**\nThe NHEJ pathway results in a distribution of small insertions and deletions (indels). The possible indel sizes are $\\{+1, +2, -1, -2, -3\\}$ bp. An outcome is in-frame if its size is a multiple of $3$.\nFrom the given list of outcomes, only the indel size of $-3$ bp is a multiple of $3$.\nThe probability of an in-frame edit under NHEJ, denoted as $P(\\text{in-frame} | \\text{NHEJ})$, is the probability of the event leading to an indel size that is a multiple of $3$:\n$$P(\\text{in-frame} | \\text{NHEJ}) = P(\\text{indel size} = -3)$$\nSubstituting the given probability:\n$$P(\\text{in-frame} | \\text{NHEJ}) = 0.10$$\nThus, there is a $10\\%$ probability that an NHEJ-mediated repair will result in an in-frame edit. The probability of a frameshift is the sum of probabilities for all other outcomes: $P(+1) + P(+2) + P(-1) + P(-2) = 0.35 + 0.15 + 0.25 + 0.15 = 0.90$. This is consistent with $1 - 0.10 = 0.90$.\n\n**2.3. Comparison**\nComparing the probabilities of in-frame edits for the two pathways:\n- $P(\\text{in-frame} | \\text{MMEJ}) = 0.70$\n- $P(\\text{in-frame} | \\text{NHEJ}) = 0.10$\n\nClearly, $0.70 > 0.10$. Therefore, at this specific locus, MMEJ is expected to produce a much higher fraction of in-frame edits compared to NHEJ. NHEJ is strongly biased towards frameshift mutations ($90\\%$ of outcomes), while MMEJ is biased towards in-frame edits ($70\\%$ of outcomes).\n\n**3. Option-by-Option Analysis**\n\n**A. NHEJ will yield a higher fraction of in-frame edits than MMEJ, because small insertions are evenly distributed across sizes and often sum to multiples of $3$, whereas MMEJ deletions have no relationship to codon periodicity.**\n- The claim that NHEJ yields a higher fraction of in-frame edits is false ($0.10 < 0.70$).\n- The reasoning that small insertions are \"evenly distributed\" is false; the probabilities are given as $0.35$ for $+1$ bp and $0.15$ for $+2$ bp.\n- The claim that MMEJ deletions have \"no relationship to codon periodicity\" is contradicted by the problem statement. The exon's trinucleotide periodicity is precisely why the microhomology distances $d=3$ and $d=6$ are the most common, leading to a high rate of in-frame deletions.\n**Verdict: Incorrect.**\n\n**B. NHEJ will be enriched for frameshifts due to the predominance of $+1$ bp and $+2$ bp templated insertions and $-1$ bp and $-2$ bp deletions, while MMEJ will produce more in-frame deletions because microhomology distances in a codon-periodic exon are frequently multiples of $3$; therefore, the in-frame fraction under MMEJ will exceed that under NHEJ at this locus.**\n- The claim that \"NHEJ will be enriched for frameshifts\" is true. The probability of a frameshift under NHEJ is $0.90$.\n- The reasoning for NHEJ is correct: the predominant outcomes ($+1$, $+2$, $-1$, $-2$) all cause frameshifts and have a combined probability of $0.90$.\n- The claim that \"MMEJ will produce more in-frame deletions\" is true. The probability of an in-frame deletion under MMEJ is $0.70$.\n- The reasoning for MMEJ is correct: the high frequency of microhomology distances that are multiples of $3$ ($d=3$ and $d=6$) is due to the codon-periodic nature of the exon.\n- The final conclusion that \"the in-frame fraction under MMEJ will exceed that under NHEJ\" is true ($0.70 > 0.10$).\n**Verdict: Correct.**\n\n**C. The in-frame to frameshift ratio will be similar under NHEJ and MMEJ, since the reading frame is independent of the distribution of indel sizes and of microhomology spacing.**\n- The claim that the \"in-frame to frameshift ratio will be similar\" is false. For NHEJ, the ratio is $0.10 / 0.90 \\approx 0.11$. For MMEJ, the ratio is $0.70 / 0.30 \\approx 2.33$. These are vastly different.\n- The reasoning that \"the reading frame is independent of the distribution of indel sizes\" is fundamentally incorrect. The preservation of the reading frame is directly and exclusively determined by whether the indel size is a multiple of $3$.\n**Verdict: Incorrect.**\n\n**D. MMEJ will mostly generate $+1$ bp and $+2$ bp insertions, making frameshifts predominant under MMEJ, whereas NHEJ will be enriched for $-3$ bp deletions, leading to a higher in-frame fraction under NHEJ than under MMEJ.**\n- The claim that MMEJ generates insertions is false. The problem states MMEJ causes deletions.\n- The claim that frameshifts are predominant under MMEJ is false ($P(\\text{frameshift} | \\text{MMEJ}) = 0.30$).\n- The claim that NHEJ is \"enriched for $-3$ bp deletions\" is false. This outcome has the lowest probability ($0.10$) in the NHEJ distribution.\n- The conclusion that NHEJ has a higher in-frame fraction is false ($0.10 < 0.70$). This option incorrectly swaps the characteristics of the two pathways.\n**Verdict: Incorrect.**",
            "answer": "$$\\boxed{B}$$"
        },
        {
            "introduction": "Translating qualitative biological understanding into quantitative prediction requires the formalization of mechanisms into mathematical models. This advanced exercise  guides you through the implementation of a mechanistic model for Microhomology-Mediated End Joining (MMEJ), incorporating key biological drivers like microhomology length and distance from the cut site. Building this model, which uses a softmax function to represent the competition between potential repair outcomes, offers direct, hands-on experience in converting first principles into a functional predictive algorithm.",
            "id": "4566246",
            "problem": "You are tasked with formalizing and implementing a principled probabilistic model for predicting deletion outcomes following a gene editing double-strand break in deoxyribonucleic acid (DNA), grounded in Microhomology-Mediated End Joining (MMEJ). The design must begin from widely accepted biological observations: longer local microhomology tracts near the cut site increase the likelihood of deletion formation, and microhomology tracts farther from the cut site contribute less strongly to repair decisions. Accept that deletion outcomes can be treated as competing alternatives whose probabilities should be normalized to sum to $1$, consistent with a maximum entropy perspective under constraints.\n\nDefine a scoring function $S_{\\text{MH}}$ that, for each candidate deletion $k$ among $K$ alternatives, assigns a scalar score based on the candidate’s microhomology length $L_k$ (in nucleotides, abbreviated as nt) and its distance from the cut site $D_k$ (in nt). The score must be constructed from a length-indexed weight function that penalizes increasing distance from the cut site. The weight function must be monotonic decreasing in the distance argument and must be parameterized by a non-negative vector of base amplitudes indexed by microhomology length. The mapping from scores to probabilities must use a normalized exponential across the $K$ candidates (a softmax), with an explicit temperature parameter to control sharpness. Distances are to be measured in nucleotides, and probabilities must be reported as decimals (not percentages).\n\nThe implementation must adhere to the following specifications:\n\n- Model ingredients:\n  - A base amplitude vector $\\boldsymbol{\\alpha} = (\\alpha_1, \\alpha_2, \\dots, \\alpha_J)$ with $\\alpha_j \\ge 0$ for $j \\in \\{1, \\dots, J\\}$ that encodes the intrinsic contribution of microhomology of length $j$ nt.\n  - A distance penalty rate $\\gamma \\ge 0$ that ensures weights decrease with increasing $D_k$.\n  - A temperature parameter $\\tau > 0$ that controls the softness of the normalized exponential mapping from scores to probabilities.\n  - For each candidate deletion $k$, a microhomology length $L_k \\in \\{0,1,\\dots,J\\}$ (in nt), where $L_k = 0$ denotes no microhomology, and a distance $D_k \\ge 0$ (in nt).\n- Scoring rule constraints:\n  - The score $S_{\\text{MH}}(k)$ must be a function that selects the appropriate length-indexed weight and applies a monotone decreasing penalty in $D_k$.\n  - If $L_k = 0$ (no microhomology), the score must default to $0$.\n- Probability mapping:\n  - The probability vector $\\mathbf{p} = (p_1, \\dots, p_K)$ must be computed via a normalized exponential over the candidate scores, controlled by $\\tau$, and must satisfy $\\sum_{k=1}^K p_k = 1$.\n- Numerical requirements:\n  - Distances $D_k$ are in nucleotides (nt).\n  - Microhomology lengths $L_k$ are in nucleotides (nt).\n  - Report probabilities as decimal values.\n  - Use numerically stable computation for the normalized exponential.\n\nYour program must implement this model and produce outputs for the following test suite. For each test case, the inputs are $(\\boldsymbol{\\alpha}, \\gamma, \\tau, \\mathbf{L}, \\mathbf{D})$, and the required output is the probability vector $\\mathbf{p}$.\n\nTest suite (units: all $D_k$ and $L_k$ are in nt; probabilities are decimals):\n\n- Case $1$ (general case): $J = 5$, $\\boldsymbol{\\alpha} = (0.2, 0.5, 0.9, 1.4, 2.0)$, $\\gamma = 0.1$, $\\tau = 1.0$, $\\mathbf{L} = (1, 2, 4, 5)$, $\\mathbf{D} = (0, 3, 5, 1)$.\n- Case $2$ (uniformity check with identical scores): $J = 3$, $\\boldsymbol{\\alpha} = (1.0, 1.0, 1.0)$, $\\gamma = 0.0$, $\\tau = 1.0$, $\\mathbf{L} = (2, 2, 2)$, $\\mathbf{D} = (5, 5, 5)$.\n- Case $3$ (no microhomology boundary): $J = 4$, $\\boldsymbol{\\alpha} = (0.3, 0.7, 1.2, 1.6)$, $\\gamma = 0.05$, $\\tau = 1.0$, $\\mathbf{L} = (0, 1, 3)$, $\\mathbf{D} = (2, 2, 2)$.\n- Case $4$ (large distance with moderate penalty): $J = 4$, $\\boldsymbol{\\alpha} = (0.5, 1.0, 1.5, 2.0)$, $\\gamma = 0.1$, $\\tau = 1.0$, $\\mathbf{L} = (1, 4, 3)$, $\\mathbf{D} = (20, 20, 20)$.\n- Case $5$ (temperature sensitivity, sharp distribution): $J = 5$, $\\boldsymbol{\\alpha} = (0.2, 0.5, 0.9, 1.4, 2.0)$, $\\gamma = 0.1$, $\\tau = 0.1$, $\\mathbf{L} = (1, 2, 4, 5)$, $\\mathbf{D} = (0, 3, 5, 1)$.\n- Case $6$ (temperature sensitivity, flat distribution): $J = 5$, $\\boldsymbol{\\alpha} = (0.2, 0.5, 0.9, 1.4, 2.0)$, $\\gamma = 0.1$, $\\tau = 5.0$, $\\mathbf{L} = (1, 2, 4, 5)$, $\\mathbf{D} = (0, 3, 5, 1)$.\n\nFinal output format requirement: Your program should produce a single line of output containing the results for all $6$ cases as a comma-separated list enclosed in square brackets, where each case’s probability vector is itself a list of decimal values rounded to $6$ decimal places (e.g., $[[0.1,0.2],[0.3,0.7]]$). No extra text is permitted.",
            "solution": "The task is to formalize and implement a probabilistic model for predicting deletion outcomes at a DNA double-strand break site. The model's design is guided by key biological observations and is structured within a standard statistical framework.\n\n**1. Model Formalization**\n\nThe model is constructed in two primary stages: first, a scoring function that quantifies the propensity of each potential deletion outcome, and second, a probability mapping that converts these scores into a normalized probability distribution.\n\n**1.1. Scoring Function, $S_{\\text{MH}}(k)$**\n\nThe problem requires a scoring function, $S_{\\text{MH}}(k)$, for each candidate deletion $k$, that incorporates the microhomology length $L_k$ and its distance from the cut site $D_k$. The score must be based on a length-indexed weight function penalized by distance.\n\nA standard and direct interpretation of these constraints leads to a multiplicative form. The base propensity is given by the amplitude $\\alpha_{L_k}$ from the vector $\\boldsymbol{\\alpha} = (\\alpha_1, \\alpha_2, \\dots, \\alpha_J)$. The problem specifies that $\\boldsymbol{\\alpha}$ is a vector of non-negative constants where the index corresponds to the microhomology length in nucleotides. Thus, for a deletion mediated by a microhomology of length $L_k \\in \\{1, \\dots, J\\}$, the base score is $\\alpha_{L_k}$.\n\nThe distance penalty must be a monotonic decreasing function of the distance $D_k$, modulated by a rate parameter $\\gamma \\ge 0$. The canonical functional form for such a penalty is an exponential decay, $e^{-\\gamma D_k}$.\n\nCombining these elements, the score for a candidate deletion $k$ with microhomology length $L_k > 0$ is:\n$$\nS_{\\text{MH}}(k) = \\alpha_{L_k} \\cdot \\exp(-\\gamma D_k)\n$$\nThe problem states that if there is no microhomology, i.e., $L_k = 0$, the score defaults to $0$. This reflects the MMEJ pathway's reliance on microhomology. Thus, the complete scoring function is defined as:\n$$\nS_{\\text{MH}}(k) =\n\\begin{cases}\n    \\alpha_{L_k} \\cdot \\exp(-\\gamma D_k) & \\text{if } L_k > 0 \\\\\n    0 & \\text{if } L_k = 0\n\\end{cases}\n$$\nIn implementation, for a given microhomology length $L_k$, the corresponding amplitude $\\alpha_{L_k}$ is accessed from the input vector $\\boldsymbol{\\alpha}$. If $\\boldsymbol{\\alpha}$ is represented by a $0$-indexed array, $\\alpha_{L_k}$ corresponds to the element at index $L_k - 1$.\n\n**1.2. Probability Mapping**\n\nThe problem specifies that the scores $\\{S_{\\text{MH}}(1), \\dots, S_{\\text{MH}}(K)\\}$ for the $K$ candidate deletions be transformed into a probability vector $\\mathbf{p} = (p_1, \\dots, p_K)$ using a normalized exponential function, commonly known as the softmax function. This choice is consistent with the principle of maximum entropy, providing the most unbiased distribution given the constraints imposed by the scores.\n\nThe mapping includes a temperature parameter $\\tau > 0$, which controls the sharpness of the probability distribution. A low temperature ($\\tau \\to 0$) concentrates probability on the highest-scoring candidate, whereas a high temperature ($\\tau \\to \\infty$) results in a nearly uniform distribution. The probability $p_k$ for candidate $k$ is given by:\n$$\np_k = \\frac{\\exp(S_{\\text{MH}}(k) / \\tau)}{\\sum_{i=1}^{K} \\exp(S_{\\text{MH}}(i) / \\tau)}\n$$\nThis ensures that $p_k \\ge 0$ for all $k$ and $\\sum_{k=1}^{K} p_k = 1$.\n\n**2. Algorithmic Design and Numerical Stability**\n\nDirect computation of the softmax formula can be numerically unstable. If the scores $S_{\\text{MH}}(k)$ are large, the term $\\exp(S_{\\text{MH}}(k) / \\tau)$ can cause a floating-point overflow. To ensure numerical stability, a standard technique is employed, which exploits the property that $\\text{softmax}(\\mathbf{x}) = \\text{softmax}(\\mathbf{x} + c)$ for any constant $c$. By choosing $c = -\\max(\\mathbf{x})$, we can prevent overflow.\n\nLet the vector of scaled scores be $\\mathbf{z} = (S_{\\text{MH}}(1)/\\tau, \\dots, S_{\\text{MH}}(K)/\\tau)$. Let $z_{\\max} = \\max_{i} \\{z_i\\}$. The stable computation for $p_k$ is:\n$$\np_k = \\frac{\\exp(z_k - z_{\\max})}{\\sum_{i=1}^{K} \\exp(z_i - z_{\\max})}\n$$\nThe largest term in the exponent is now $0$, so $\\exp(z_k - z_{\\max}) \\le 1$, preventing overflow. Terms where $z_i$ is much smaller than $z_{\\max}$ will correctly underflow to $0$.\n\n**3. Implementation Strategy**\n\nThe model is implemented in Python, leveraging the `numpy` library for efficient numerical and array-based computations.\nFor each test case, provided as a tuple $(\\boldsymbol{\\alpha}, \\gamma, \\tau, \\mathbf{L}, \\mathbf{D})$:\n1. An array of scores is computed by iterating through the candidate deletions. For each candidate $k$ with properties $(L_k, D_k)$, the score $S_{\\text{MH}}(k)$ is calculated using the formalized scoring function.\n2. The resulting array of scores is divided by the temperature $\\tau$.\n3. The numerically stable softmax function is applied to the scaled scores to compute the final probability vector $\\mathbf{p}$.\n4. The probabilities are rounded to $6$ decimal places as required.\n5. The final results from all test cases are collected and formatted into a single string according to the strict output specification.",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the gene editing outcome prediction problem for a given suite of test cases.\n    The implementation follows a principled probabilistic model based on Microhomology-Mediated End Joining (MMEJ).\n    \"\"\"\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # Case 1: General case\n        (\n            (0.2, 0.5, 0.9, 1.4, 2.0),  # alpha\n            0.1,  # gamma\n            1.0,  # tau\n            (1, 2, 4, 5),  # L\n            (0, 3, 5, 1)   # D\n        ),\n        # Case 2: Uniformity check with identical scores\n        (\n            (1.0, 1.0, 1.0),  # alpha\n            0.0,  # gamma\n            1.0,  # tau\n            (2, 2, 2),  # L\n            (5, 5, 5)   # D\n        ),\n        # Case 3: No microhomology boundary\n        (\n            (0.3, 0.7, 1.2, 1.6),  # alpha\n            0.05,  # gamma\n            1.0,  # tau\n            (0, 1, 3),  # L\n            (2, 2, 2)   # D\n        ),\n        # Case 4: Large distance with moderate penalty\n        (\n            (0.5, 1.0, 1.5, 2.0),  # alpha\n            0.1,  # gamma\n            1.0,  # tau\n            (1, 4, 3),  # L\n            (20, 20, 20)  # D\n        ),\n        # Case 5: Temperature sensitivity, sharp distribution\n        (\n            (0.2, 0.5, 0.9, 1.4, 2.0),  # alpha\n            0.1,  # gamma\n            0.1,  # tau\n            (1, 2, 4, 5),  # L\n            (0, 3, 5, 1)   # D\n        ),\n        # Case 6: Temperature sensitivity, flat distribution\n        (\n            (0.2, 0.5, 0.9, 1.4, 2.0),  # alpha\n            0.1,  # gamma\n            5.0,  # tau\n            (1, 2, 4, 5),  # L\n            (0, 3, 5, 1)    # D\n        ),\n    ]\n\n    all_results = []\n    \n    for case in test_cases:\n        alpha, gamma, tau, L_vec, D_vec = case\n        \n        # Calculate scores for all candidate deletions\n        scores = []\n        for L_k, D_k in zip(L_vec, D_vec):\n            if L_k == 0:\n                score = 0.0\n            else:\n                # alpha is 1-indexed in the problem description, so we use L_k - 1\n                base_amplitude = alpha[L_k - 1]\n                score = base_amplitude * np.exp(-gamma * D_k)\n            scores.append(score)\n        \n        scores_arr = np.array(scores, dtype=np.float64)\n        \n        # If there are no candidates, the result is an empty list\n        if scores_arr.size == 0:\n            all_results.append([])\n            continue\n\n        # Apply temperature parameter\n        scaled_scores = scores_arr / tau\n        \n        # Compute probabilities using numerically stable softmax\n        # Subtract the maximum score to prevent overflow\n        scaled_scores -= np.max(scaled_scores)\n        exp_scores = np.exp(scaled_scores)\n        probabilities = exp_scores / np.sum(exp_scores)\n        \n        # Round results to 6 decimal places\n        result_vector = [round(p, 6) for p in probabilities]\n        all_results.append(result_vector)\n\n    # Format the final output string exactly as specified: [[p1,p2,...],[q1,q2,...]]\n    # No spaces within the inner lists.\n    formatted_case_results = []\n    for res_vec in all_results:\n        vec_as_str = '[' + ','.join(map(str, res_vec)) + ']'\n        formatted_case_results.append(vec_as_str)\n    \n    final_output_str = '[' + ','.join(formatted_case_results) + ']'\n    print(final_output_str)\n\nsolve()\n```"
        }
    ]
}