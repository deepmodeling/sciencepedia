{
    "hands_on_practices": [
        {
            "introduction": "任何目标试验模拟的第一步都是从庞杂的电子健康记录 (EHR) 数据中精确地定义研究人群。这需要使用多种编码系统（如 ICD, RxNorm, LOINC）为疾病、暴露和结局创建“算法表型”。本练习将挑战您设计并验证这样一个表型，强调明确定义的时间零点对于避免常见偏倚（如永生时间偏倚）的至关重要性。",
            "id": "4612553",
            "problem": "您正在设计一项基于电子健康记录（EHR）的目标试验模拟，以比较一线双胍类药物（二甲双胍）与一线磺脲类药物疗法在2型糖尿病（T2DM）成人患者中的效果。目标是为T2DM定义一个算法表型，并指定国际疾病分类（ICD）、RxNorm和逻辑观察标识符名称和代码（LOINC）代码集，以及一个用于目标试验资格的验证程序。目标试验方案要求采用新用户设计，一个明确定义的时间零点，并使用病历审查对表型进行验证。\n\n必须遵守的基本假设和定义包括：(i) 目标试验模拟中的因果识别需要可交换性、一致性和正定性；(ii) 为避免不朽时间偏倚，要求资格标准和基线协变量必须在与治疗开始重合的单一、明确定义的时间零点或之前可测量；(iii) 分类性能指标定义为表型的敏感性和特异性，阳性预测值（PPV）和阴性预测值（NPV）从真实疾病状态和算法分类的联合分布中导出；(iv) 二项式抽样理论决定了通过病历审查估计的PPV和NPV的精度。\n\n目标试验模拟的参数如下：\n- 研究人群：年龄在$40$至$80$岁之间的T2DM成人，在开始治疗前$90$天内至少有一次基线糖化血红蛋白（HbA1c）测量值在$7.0\\%$至$10.0\\%$之间，且基线估计肾小球滤过率（eGFR）$\\geq 45$ $\\mathrm{mL/min/1.73m^2}$。\n- 治疗策略：开始使用二甲双胍（双胍类）与开始使用磺脲类药物，通过RxNorm成分或药物类别概念识别。\n- 新用户要求：在过去$12$个月内没有二甲双胍或磺脲类药物的配药记录。\n- 时间零点：首次符合条件的二甲双胍或磺脲类药物配药的日期。\n\n算法表型必须：\n- 使用ICD代码集识别T2DM，排除1型糖尿病和妊娠期糖尿病。\n- 通过RxNorm使用药物数据来支持表型和资格（例如，按成分划分的药物类别成员）。\n- 通过LOINC使用实验室结果来识别用于基线资格的HbA1c和eGFR。\n- 提出一个验证程序，通过对算法阳性和阴性样本进行盲法病历审查，得出PPV和NPV估计值，其精度目标为预期$PPV \\approx 0.90$和$NPV \\approx 0.95$的$95\\%$置信区间的半宽度最多为$0.03$。验证必须最小化谱偏倚和验证偏倚，并提供一个计划来校正效应估计中的暴露和资格错分。\n\n哪个选项提供了一个科学上合理的算法表型，其中包含恰当指定的ICD、RxNorm和LOINC代码集，一个避免了不朽时间偏倚的正确时间零点定义，以及一个满足所述精度要求的有效验证程序？\n\nA. 表型和验证计划：\n- T2DM定义：至少两次门诊ICD-10-CM代码`E11.*`，间隔$\\geq 30$天；或一次门诊`E11.*`代码加上一次通过RxNorm成分或类别概念识别的抗糖尿病药物配药记录（不包括胰岛素），同时至少有一次LOINC HbA1c结果$\\geq 6.5\\%$。排除项：任何先前的1型糖尿病代码`E10.*`或妊娠期糖尿病代码`O24.*`。\n- 资格：年龄$40$–$80$岁；在时间零点前$\\leq 90$天内测量的基线HbA1c $7.0\\%$–$10.0\\%$；eGFR $\\geq 45$ $\\mathrm{mL/min/1.73m^2}$；过去$12$个月内没有二甲双胍或磺脲类药物的配药记录。\n- 时间零点：首次配发二甲双胍或磺脲类药物的日期（RxNorm概念）。\n- 验证：对算法阳性和阴性进行分层随机、盲法病历审查，以估计$PPV$和$NPV$。使用二项式精度目标计算阳性和阴性样本量，以在预期$PPV \\approx 0.90$和$NPV \\approx 0.95$周围实现$95\\%$置信区间半宽度$\\leq 0.03$。使用概率性错分偏倚分析来校正效应估计。\n\nB. 表型和验证计划：\n- T2DM定义：任何来自`E11.*`或`E10.*`的单一住院或门诊ICD-10-CM代码；无排除项。无实验室要求。\n- 资格：年龄$40$–$80$岁；不强制执行HbA1c阈值；允许先前使用胰岛素。\n- 时间零点：首次HbA1c $\\geq 6.5\\%$的日期。\n- 验证：对仅算法阳性者进行方便抽样病历审查（$n=100$），仅估计$PPV$；不审查阴性者或计算$NPV$；没有计划在分析中校正错分。\n\nC. 表型和验证计划：\n- T2DM定义：至少一次LOINC HbA1c $\\geq 6.5\\%$或任何RxNorm胰岛素配药记录；通过要求无`E10.*`代码来排除1型糖尿病；未考虑妊娠期糖尿病。\n- 资格：年龄$40$–$80$岁；在时间零点后$30$天内测量的HbA1c为$7.0\\%$–$10.0\\%$。\n- 时间零点：首次记录的糖尿病诊断日期。\n- 验证：病例对照病历审查，对阳性者进行过采样，但不按算法分类进行分层；仅估计敏感性。\n\nD. 表型和验证计划：\n- T2DM定义：来自LOINC的任意两次异常葡萄糖测试（空腹血浆葡萄糖或随机血浆葡萄糖），不使用ICD代码；无1型或妊娠期糖尿病的排除项。\n- 资格：年龄$40$–$80$岁；忽略基线HbA1c；包括通过RxNorm识别的任何一线抗糖尿病药物，包括胰岛素。\n- 时间零点：指标药物的第二次配药日期。\n- 验证：对EHR算法输出进行非审查的自助法（bootstrapping）以估计$PPV$和$NPV$；无病历审查；不为精度计算样本量；无错分校正。\n\n选择正确的选项。",
            "solution": "问题陈述已经过验证，并被确定为是合理的。它在科学上植根于药物流行病学和生物信息学的原理，问题提出得当，目标清晰一致，语言客观。该问题为使用电子健康记录（EHR）数据设计和验证目标试验模拟提供了一套详细的要求。我现在将根据这些要求评估每个选项。\n\n评估每个选项所依据的核心要求是：\n1.  **T2DM表型：** 必须使用ICD代码（明确排除1型和妊娠期糖尿病）识别2型糖尿病（T2DM），并由RxNorm和LOINC数据支持。\n2.  **资格标准：** 必须正确应用指定的标准：年龄$40$至$80$岁，基线HbA1c在$7.0\\%$至$10.0\\%$之间（在开始治疗前$\\leq 90$天内测量），基线eGFR $\\geq 45$ $\\mathrm{mL/min/1.73m^2}$，以及研究药物的$12$个月洗脱期。\n3.  **时间零点：** 必须定义为治疗开始的日期（首次符合条件的药物配药日期）以避免不朽时间偏倚。所有基线特征和资格必须在此时间点或之前定义。\n4.  **验证程序：** 必须包括对算法阳性和阴性样本进行分层随机抽样的盲法病历审查，以估计阳性预测值（PPV）和阴性预测值（NPV）。还必须根据指定的精度目标（$95\\%$ CI半宽度 $\\leq 0.03$）进行样本量计算，并包括一个错分校正计划。\n\n### 逐项分析选项\n\n**A. 表型和验证计划：**\n- **T2DM定义：** 所提出的表型是稳健的。它使用一种标准方法，即要求多个诊断代码（$\\geq 2$次门诊T2DM的ICD-10-CM代码`E11.*`，并有时间间隔）或诊断代码与支持性证据（抗糖尿病药物配药记录或HbA1c $\\geq 6.5\\%$的确诊性实验室结果）的组合。这种多模式方法提高了特异性。至关重要的是，它正确地指定了对1型糖尿病（`E10.*`）和妊娠期糖尿病（`O24.*`）的排除，满足了一项关键要求。\n- **资格：** 资格标准完全按照问题的要求精确陈述：年龄$40$–$80$岁；在时间零点*之前*$\\leq 90$天内测量的基线HbA1c $7.0\\%$–$10.0\\%$；eGFR $\\geq 45$ $\\mathrm{mL/min/1.73m^2}$；以及$12$个月的新用户洗脱期。时间限定词“在时间零点之前”是至关重要的，并且应用正确。\n- **时间零点：** 时间零点被定义为“首次配发二甲双胍或磺脲类药物的日期”。这对于新用户、活性对照研究是正确的定义，因为它将随访的开始锚定在治疗的启动上，从而避免了不朽时间偏倚。\n- **验证：** 验证计划在方法上是健全和全面的。它指定了“对算法阳性和阴性进行分层随机、盲法病历审查”，这是避免验证偏倚并能够计算PPV、NPV、敏感性和特异性的金标准方法。它明确提到要计算样本量以满足指定的精度目标（$95\\%$ CI半宽度 $\\leq 0.03$），这是一个严谨验证计划的关键组成部分。对于给定的精度半宽$W$、比例$p$和置信水平对应的$z$值，所需样本量$n$的公式为$n = z^2 p(1-p)/W^2$。对于目标$PPV \\approx 0.90$，所需的算法阳性样本量为$n_{\\text{pos}} = 1.96^2 \\times 0.90 \\times (1-0.90) / 0.03^2 \\approx 385$。对于目标$NPV \\approx 0.95$，所需的算法阴性样本量为$n_{\\text{neg}} = 1.96^2 \\times 0.95 \\times (1-0.95) / 0.03^2 \\approx 203$。该计划正确地指出了此计算的必要性。最后，它包括一个“使用概率性错分偏倚分析来校正效应估计”的计划，满足了最终要求。\n\n**选项A的结论：** **正确**。该选项严谨地遵循了高质量目标试验模拟的所有既定原则和要求。\n\n**B. 表型和验证计划：**\n- **T2DM定义：** 这个定义有严重缺陷。它包括了1型糖尿病代码（`E10.*`）并且“无排除项”，直接违反了问题陈述。单一ICD代码的特异性也众所周知地低。\n- **资格：** 它未能强制执行所要求的HbA1c阈值，这是另一个直接违规。\n- **时间零点：** 定义为“首次HbA1c $\\geq 6.5\\%$的日期”。这是不正确的。时间零点必须锚定在治疗开始时。使用一个实验室检查日期会将随访的开始与干预措施脱钩，并可能引入不朽时间偏倚。\n- **验证：** 该计划是无效的。“方便抽样”会引入选择偏倚。审查“仅算法阳性者”会引入验证偏倚，并且无法计算NPV或特异性。$n=100$的样本量是任意的，并未基于所需的精度。没有偏倚校正的计划。\n\n**选项B的结论：** **不正确**。该选项违反了表型构建和目标试验模拟的多个基本原则。\n\n**C. 表型和验证计划：**\n- **T2DM定义：** 这个表型很弱，忽略了ICD代码，并且不完整，因为它“未考虑”妊娠期糖尿病，而这是一个必需的排除项。\n- **资格：** 这包含一个关键且致命的缺陷。它规定在“时间零点*之后*30天内”测量基线HbA1c。资格标准必须在时间零点*或之前*确定。使用未来的信息来确定资格会引入严重的选择偏倚，并违反了模拟真实世界试验的核心原则。\n- **时间零点：** 定义为“首次记录的糖尿病诊断日期”。这是不正确的。如问题所规定，时间零点必须是治疗开始的日期，以正确定义新用户队列并避免不朽时间偏倚。诊断和治疗之间的时间段变化很大。\n- **验证：** 该计划规定得不明确（“病例对照病历审查，对阳性者进行过采样，但不按算法分类进行分层”），且不完整，因为它只旨在估计敏感性，而没有提及必需的PPV或NPV。\n\n**选项C的结论：** **不正确**。使用基线后信息来确定资格是一个足以使其被否决的错误。时间零点的定义也是不正确的。\n\n**D. 表型和验证计划：**\n- **T2DM定义：** 这个表型是不充分的。它忽略了ICD代码，并且未能应用对1型和妊娠期糖尿病的必需排除项。\n- **资格：** 该计划“忽略”了基线HbA1c的要求，并错误地将治疗策略扩大到包括胰岛素，这与研究声明的比较相矛盾。\n- **时间零点：** 定义为“指标药物的第二次配药日期”。这是不正确的。这在第一次和第二次配药之间创建了一个任意的不朽时间段，在此期间患者技术上属于队列，但未被视为“处于风险中”。时间零点必须是第一次配药。\n- **验证：** 所提出的方法，“对EHR算法输出进行非审查的自助法（bootstrapping）”，对于验证来说是毫无意义的。验证需要与外部金标准（病历审查）进行比较。对算法自身的输出进行自助法分析无法评估其准确性（即，其相对于真实疾病状态的正确性）。该计划明确且错误地避免了病历审查、样本量计算和错分校正。\n\n**选项D的结论：** **不正确**。该选项在任务的每个组成部分，尤其是验证方面，都表现出根本性的误解。\n\n### 最终结论\n只有选项A提供了一个科学上合理且完整的计划，该计划与问题陈述中列出的所有原则和具体要求相一致。它正确地定义了表型、资格标准、时间零点和严谨的验证程序。",
            "answer": "$$\\boxed{A}$$"
        },
        {
            "introduction": "在定义了队列并应用倾向性评分加权等方法来调整混杂因素后，检查调整是否成功至关重要。本练习的核心是诊断关键的“可交换性”假设的合理性，通过评估治疗组间基线协变量的平衡情况来实现。您将学习如何正确解读平衡性诊断指标，并理解它们在支持因果推断声明中的作用。",
            "id": "4612593",
            "problem": "考虑使用电子健康记录 (EHR) 模拟一项目标试验，该试验旨在比较起始使用选择性血清素再摄取抑制剂 (SSRI) 与血清素-去甲肾上腺素再摄取抑制剂 (SNRI) 治疗重度抑郁症 (MDD) 的效果。将零时间点定义为开具第一个符合条件的抗抑郁药处方的日期。令 $A_i \\in \\{0,1\\}$ 表示患者 $i$ 的治疗分配，其中 $A_i = 0$ 代表 SSRI，$A_i = 1$ 代表 SNRI。令 $X_i$ 表示在零时间点或之前测量的基线协变量，包括患者健康问卷-9 (PHQ-9) 得分、年龄、过去 $90$ 天内接受心理治疗的情况以及同期使用苯二氮䓬类药物的情况。在治疗 $a \\in \\{0,1\\}$ 下的潜在结局为 $Y_i(a)$。零时间点的目标试验假设是条件可交换性，即对于 $a \\in \\{0,1\\}$，$Y_i(a) \\perp A_i \\mid X_i$。\n\n您希望通过在零时间点比较各治疗组观察到的基线协变量分布，来构建一个评估可交换性合理性的诊断工具，并解释这项 EHR 抗抑郁药试验的结果。现有以下根据经验观察到的基线摘要数据：\n\n- 样本量：SSRI 组 $n_0 = 12{,}000$，SNRI 组 $n_1 = 3{,}000$。\n- PHQ-9 得分：SSRI 组平均值 $11.2$，标准差 $6.0$；SNRI 组平均值 $14.0$，标准差 $6.5$。\n- 年龄（岁）：SSRI 组平均值 $38$，标准差 $12$；SNRI 组平均值 $42$，标准差 $13$。\n- 过去 $90$ 天内接受心理治疗（二元变量）：SSRI 组比例 $0.30$；SNRI 组比例 $0.45$。\n- 零时间点同期使用苯二氮䓬类药物（二元变量）：SSRI 组比例 $0.12$；SNRI 组比例 $0.22$。\n\n您使用 $P(A_i=1 \\mid X_i)$ 的倾向性得分模型，实施逆概率治疗加权 (IPTW) 方法对样本重新加权，使得加权后的协变量分布旨在模拟零时间点的随机试验。加权后，您观察到以下加权协变量摘要：\n\n- PHQ-9 得分：SSRI 组平均值 $13.8$；SNRI 组平均值 $13.9$；各组间 PHQ-9 的经验累积分布函数 (ECDFs) 之间的最大绝对差（Kolmogorov-Smirnov (KS) 统计量）为 $0.05$。\n- 年龄（岁）：SSRI 组平均值 $40.9$；SNRI 组平均值 $41.1$；KS 统计量为 $0.04$。\n- 心理治疗：SSRI 组比例 $0.41$；SNRI 组比例 $0.42$。\n- 使用苯二氮䓬类药物：SSRI 组比例 $0.19$；SNRI 组比例 $0.19$。\n- 倾向性得分重叠程度为中等到良好：在两个治疗组中，对于约 $95\\%$ 的患者，其估计的倾向性得分 $\\hat{e}(X_i)$ 位于 $[0.1, 0.9]$ 区间内。\n\n下列哪种方法和解释通过在零时间点比较各组间的协变量分布来正确构建诊断工具，并就能否评估条件可交换性的合理性而言，正确地解释了这项 EHR 抗抑郁药试验的结果？\n\nA. 计算每个协变量加权前后的标准化差异，并检查不平衡的程度；将加权后较小的绝对标准化差异（例如，全部低于 $0.1$）、连续协变量的较小 KS 统计量（例如，全部低于 $0.1$）以及充分的倾向性得分重叠一并视为支持零时间点条件可交换性合理性的证据，同时承认无法排除未测量的混杂因素。\n\nB. 通过检验 $A_i$ 是否与 $X_i$ 边际独立来诊断可交换性；由于加权前各组的协变量均值不同，可交换性永久失效，没有任何调整方法能够合理地实现它。\n\nC. 为连续协变量构建分位数-分位数图 (quantile-quantile plots) 和进行 KS 检验，并比较二元协变量的风险差异；得出结论，鉴于样本量大，仅依赖这些检验得到的小 $p$ 值就足以宣布加权后的可交换性是合理的。\n\nD. 将诊断完全集中于正性假设，通过检查各组间估计的倾向性得分 $\\hat{e}(X_i)$ 的重叠情况；充分的重叠确保了零时间点的可交换性，因此足以验证该试验模拟的有效性。",
            "solution": "用户希望我验证一个关于使用电子健康记录 (EHR) 数据模拟目标试验的问题陈述。如果问题有效，我必须通过评估所提供的选项来推导出正确答案。\n\n### 问题验证\n\n**第1步：提取已知信息**\n\n*   **研究设计**：使用 EHR 数据模拟一项目标试验，比较起始使用选择性血清素再摄取抑制剂 (SSRI) 与血清素-去甲肾上腺素再摄取抑制剂 (SNRI) 治疗重度抑郁症 (MDD)。\n*   **零时间点**：第一个符合条件的抗抑郁药处方的日期。\n*   **治疗分配**：患者 $i$ 的治疗分配 $A_i \\in \\{0,1\\}$，其中 $A_i = 0$ 代表 SSRI，$A_i = 1$ 代表 SNRI。\n*   **基线协变量**：在零时间点或之前测量的 $X_i$，包括患者健康问卷-9 (PHQ-9) 得分、年龄、过去 $90$ 天内接受心理治疗的情况以及同期使用苯二氮䓬类药物的情况。\n*   **潜在结局**：在治疗 $a \\in \\{0,1\\}$ 下的 $Y_i(a)$。\n*   **因果假设（目标）**：零时间点的条件可交换性，$Y_i(a) \\perp A_i \\mid X_i$ for $a \\in \\{0,1\\}$。\n*   **观察到的加权前数据**：\n    *   样本量：SSRI 组 ($n_0 = 12{,}000$)，SNRI 组 ($n_1 = 3{,}000$)。\n    *   PHQ-9 得分：SSRI 组平均值 $11.2$ (标准差 $6.0$)；SNRI 组平均值 $14.0$ (标准差 $6.5$)。\n    *   年龄（岁）：SSRI 组平均值 $38$ (标准差 $12$)；SNRI 组平均值 $42$ (标准差 $13$)。\n    *   过去90天内接受心理治疗：SSRI 组比例 $0.30$；SNRI 组比例 $0.45$。\n    *   同期使用苯二氮䓬类药物：SSRI 组比例 $0.12$；SNRI 组比例 $0.22$。\n*   **方法论**：基于倾向性得分模型 $P(A_i=1 \\mid X_i)$ 的逆概率治疗加权 (IPTW)。\n*   **观察到的加权后数据**：\n    *   PHQ-9 得分：SSRI 组平均值 $13.8$；SNRI 组平均值 $13.9$；Kolmogorov-Smirnov (KS) 统计量 $0.05$。\n    *   年龄（岁）：SSRI 组平均值 $40.9$；SNRI 组平均值 $41.1$；KS 统计量 $0.04$。\n    *   心理治疗：SSRI 组比例 $0.41$；SNRI 组比例 $0.42$。\n    *   使用苯二氮䓬类药物：SSRI 组比例 $0.19$；SNRI 组比例 $0.19$。\n*   **倾向性得分重叠**：被描述为中等到良好。在两个治疗组中，对于约 $95\\%$ 的患者，其估计的倾向性得分 $\\hat{e}(X_i)$ 位于 $[0.1, 0.9]$ 区间内。\n*   **问题**：哪种方法和解释能正确构建一个诊断工具来评估条件可交换性的合理性？\n\n**第2步：使用提取的已知信息进行验证**\n\n*   **科学性**：该问题基于现代因果推断的既定原则，特别是使用观察性数据进行目标试验模拟。所使用的方法（倾向性得分、IPTW）、假设（条件可交换性、正性）和诊断（协变量平衡评估）是流行病学、生物统计学和计量经济学领域的核心内容。临床背景现实，变量具有临床相关性。\n*   **问题形式良好**：问题形式良好。它要求基于所提供的数据对方法论和解释进行评估，这是统计学和数据科学中概念性问题的标准形式。可以根据既定的最佳实践来确定正确的方法。\n*   **客观性**：问题陈述是客观的，使用了精确的术语和定量数据。它没有主观或偏见的语言。\n*   **缺陷评估**：\n    1.  **科学/事实上不健全**：无。该问题正确地描述了观察性研究中混杂因素的挑战。\n    2.  **无法形式化/不相关**：无。该问题是因果推断原则的形式化应用。\n    3.  **不完整/矛盾的设置**：无。所提供的数据（调整前后的摘要）足以评估选项。数值与存在适应症混杂（病情较重的患者接受 SNRI）和成功重新加权的情景相符。\n    4.  **不切实际/不可行**：无。样本量和摘要统计数据对于大型 EHR 数据库研究来说是合理的。\n    5.  **问题设置不当/结构不良**：无。问题清晰，术语在该学科内有明确定义。\n    6.  **伪深刻/琐碎**：无。该问题探讨了观察性研究方法论中一个微妙而关键的方面——区分哪些是可以凭经验检查的（已测量协变量的平衡、正性）和哪些是必须假设的（无未测量混杂）。\n    7.  **超出科学可验证性**：无。所涉及的原则是标准的、可验证的。\n\n**第3步：结论与行动**\n\n问题陈述是**有效的**。这是一个关于正确应用和解释因果推断方法的结构良好的问题。我将继续进行解答。\n\n### 解答推导\n\n使用观察性数据模拟目标试验的目标是使被比较的治疗组具有可交换性或可比性。在完美的随机对照试验 (RCT) 中，随机化确保了边际可交换性，$Y(a) \\perp A$。在观察性研究中，情况并非如此；通常存在混杂。例如，加权前的数据显示，接受 SNRI ($A_i=1$) 的患者平均年龄更大，PHQ-9 得分更高（抑郁更严重），并且更有可能同时接受心理治疗和使用苯二氮䓬类药物。这是适应症混杂的典型例子。\n\n为了提出因果声明，我们必须依赖两个关键的、不可检验的假设：\n1.  **条件可交换性**：给定测量的基线协变量 $X_i$，治疗分配 $A_i$ 与潜在结局 $Y_i(a)$ 无关。这通常被称为“无未测量混杂”。形式上：$Y_i(a) \\perp A_i \\mid X_i$。\n2.  **正性（或重叠）**：对于研究人群中存在的每一组协变量值 $x$，接受任何一种治疗的概率都非零。形式上：对于所有 $x$ 使得 $P(X_i=x) > 0$，有 $0  P(A_i=1 \\mid X_i=x)  1$。\n\n虽然这些核心假设无法被证明，但我们可以进行诊断以评估其合理性。\n*   **条件可交换性**的合理性可以通过调整后（例如，通过 IPTW）*已测量*基线协变量 $X_i$ 的分布在各治疗组间是否相似来间接支持。这被称为检查协变量平衡。标准化均数差 (SMD) 是一个关键指标，良好平衡的通用阈值是绝对 SMD 小于 $0.1$。对于连续变量，通过 Kolmogorov-Smirnov (KS) 统计量等指标或使用 Q-Q 图进行视觉化比较整个分布也是最佳实践。在*已测量*协变量上实现平衡并不能排除未测量的混杂，但如果未能实现平衡，则分析无效。\n*   **正性**的合理性通过检查估计的倾向性得分 $\\hat{e}(X_i) = \\hat{P}(A_i=1 \\mid X_i)$ 的范围来评估。如果某些个体的得分非常接近 $0$ 或 $1$，这表明对于某些协变量模式，治疗几乎是确定性的，这违反了正性假设，并可能导致不稳定的权重和有偏的估计。给定的信息表明，对于 $95\\%$ 的患者，$\\hat{e}(X_i) \\in [0.1, 0.9]$，这表明正性良好。\n\n因此，一个健全的诊断方法必须包括评估调整后已测量协变量的平衡，确认正性，并明确承认无未测量混杂的核心假设仍然是不可检验的。\n\n### 逐项分析\n\n**A. 计算每个协变量加权前后的标准化差异，并检查不平衡的程度；将加权后较小的绝对标准化差异（例如，全部低于 $0.1$）、连续协变量的较小 KS 统计量（例如，全部低于 $0.1$）以及充分的倾向性得分重叠一并视为支持零时间点条件可交换性合理性的证据，同时承认无法排除未测量的混杂因素。**\n\n这个选项描述了当前倾向性得分分析中诊断的最佳实践。它正确地指出了关键步骤：\n1.  使用标准化指标（如与样本量无关的 SMD 和用于分布的 KS 统计量）量化调整前后的不平衡。问题中加权后的数据（例如，PHQ-9 均值 $13.8$ vs $13.9$；年龄均值 $40.9$ vs $41.1$；比例 $0.41$ vs $0.42$ 和 $0.19$ vs $0.19$）强烈表明将实现小的标准化差异。$0.05$ 和 $0.04$ 的 KS 统计量也很小。\n2.  结合检查正性（“充分的倾向性得分重叠”）。\n3.  关键在于，它提供了正确的解释：这些检查支持条件可交换性假设的*合理性*，但不能证明它，因为*未测量混杂*的威胁始终存在。这是最完整和方法论上最健全的陈述。\n\n**结论**：**正确**。\n\n**B. 通过检验 $A_i$ 是否与 $X_i$ 边际独立来诊断可交换性；由于加权前各组的协变量均值不同，可交换性永久失效，没有任何调整方法能够合理地实现它。**\n\n这个选项根本上是错误的。它将边际依赖性与条件可交换性假设的失败混为一谈。\n1.  观察性研究的全部目的就是分析治疗 $A_i$ 与协变量 $X_i$ *不*独立的数据。这是混杂的定义。加权前的差异是预料之中的。\n2.  核心假设是*条件*可交换性 ($Y_i(a) \\perp A_i \\mid X_i$)，而非边际可交换性。\n3.  “没有任何调整方法能够合理地实现它”的说法与使用 IPTW 等方法的理由完全相反，这些方法正是为了调整观察到的混杂并创建可比的组而设计的。\n\n**结论**：**不正确**。\n\n**C. 为连续协变量构建分位数-分位数图 (quantile-quantile plots) 和进行 KS 检验，并比较二元协变量的风险差异；得出结论，鉴于样本量大，仅依赖这些检验得到的小 p 值就足以宣布加权后的可交换性是合理的。**\n\n这个选项的缺陷在于它依赖假设检验来进行平衡检查。\n1.  使用 $p$ 值来评估协变量平衡是被广泛反对的。在样本量很大时（这里 $n = 15,000$），即使是微不足道且临床上无意义的协变量差异也会在统计上显著（即产生小的 $p$ 值），从而导致人们错误地得出平衡未达成的结论。\n2.  首选的指标是标准化差异，它独立于样本量，并量化了不平衡的程度。\n3.  “仅依赖这些检验得到的小 $p$ 值就足以宣布可交换性合理”的结论过于强烈。它忽略了未测量混杂的关键问题，也省略了对正性的必要检查。\n\n**结论**：**不正确**。\n\n**D. 将诊断完全集中于正性假设，通过检查各组间估计的倾向性得分 $\\hat{e}(X_i)$ 的重叠情况；充分的重叠确保了零时间点的可交换性，因此足以验证该试验模拟的有效性。**\n\n这个选项错误地将正性与可交换性等同起来。正性和条件可交换性是进行无偏因果效应估计的两个不同且必要的假设。\n1.  **正性** ($0  P(A_i=1 \\mid X_i)  1$) 确保对于所有 $X_i$ 的分层，比较在数学上是可能的。\n2.  **条件可交换性** ($Y_i(a) \\perp A_i \\mid X_i$) 确保比较是有意义的（即不受未测量因素的偏倚影响）。\n3.  一个假设并不意味着另一个。一项研究可以有完美的正性，但由于未测量的混杂而存在严重的偏倚。“充分的重叠确保了可交换性”的说法是一个关键的概念性错误。\n\n**结论**：**不正确**。",
            "answer": "$$\\boxed{A}$$"
        },
        {
            "introduction": "在观察性研究中，无论我们多么仔细地调整已测量的混杂因素，未测量混杂的威胁始终存在。这最后一个练习介绍了一种至关重要的敏感性分析工具：E-值 (E-value)。通过本练习，您将学会如何计算和解释 E-值，它为我们提供了一个量化指标，用以评估一个未测量的混杂因素需要多强才能完全解释观测到的效应。",
            "id": "4612515",
            "problem": "一名研究者正在使用电子健康记录（EHR）模拟一项关于他汀类药物启动的目标试验，以估计在基线时开始使用他汀类药物与不开始使用相比，对两年内心肌梗死风险的因果效应。令 $A \\in \\{0,1\\}$ 表示治疗启动，$Y \\in \\{0,1\\}$ 表示两年内心肌梗死，而 $RR$ 表示因果风险比 $RR = \\Pr(Y^{1}=1)/\\Pr(Y^{0}=1)$，其中 $Y^{a}$ 表示在 $A=a$ 下的潜在结局。该分析对已测量的基线协变量进行了调整，但未测量的混杂因素可能仍然存在（例如，对高低密度脂蛋白（LDL）胆固醇的遗传易感性）。从该模拟研究中观察到的调整后风险比为 $RR_{\\text{obs}}=0.70$，其 $95\\%$ 置信区间（CI）为 $\\left(0.60, 0.82\\right)$。该研究者希望使用 E-value 来评估结果对未测量混杂的稳健性。\n\n使用风险比尺度上的基本因果推断定义和公认的关于未测量混杂的偏倚界限论证，来推断 E-value 必须量化什么，以及如何为一个保护性效应 $RR_{\\text{obs}}1$ 计算它。然后，选择正确定义 E-value 并为该他汀类药物模拟研究的点估计给出正确数值计算的选项。\n\nA. E-value 是指，在已测量协变量的条件下，单个未测量混杂因素需要同时与他汀类药物启动和心肌梗死关联的最小强度（以风险比衡量），才能将因果 $RR$ 移动到零假设值 $RR=1$。对于一个保护性的观测风险比 $RR_{\\text{obs}}=0.70$，它的计算方法是先将估计值取倒数，然后应用界限公式：$\\text{E-value} = RR_{\\text{obs}}^{-1} + \\sqrt{RR_{\\text{obs}}^{-1}\\left(RR_{\\text{obs}}^{-1}-1\\right)} \\approx 2.21$。\n\nB. E-value 是对数风险比的绝对值，它量化了在对数尺度上与零假设值的距离；对于 $RR_{\\text{obs}}=0.70$，$\\text{E-value} = \\left|\\log\\left(0.70\\right)\\right| \\approx 0.357$。\n\nC. E-value 定义为观测到的关联中未被已测量协变量解释的部分，计算公式为 $\\text{E-value} = RR_{\\text{obs}} - \\sqrt{RR_{\\text{obs}}\\left(RR_{\\text{obs}}-1\\right)}$，并且对于保护性效应，它就等于 $RR_{\\text{obs}}$；对于 $RR_{\\text{obs}}=0.70$，$\\text{E-value} = 0.70$。\n\nD. E-value 是观测风险比的倒数，代表混杂因素必须与暴露或结局之一的最小关联；对于 $RR_{\\text{obs}}=0.70$，$\\text{E-value} = 1/0.70 \\approx 1.43$。",
            "solution": "对问题陈述的有效性进行评估。\n\n### 步骤 1：提取已知信息\n- **研究背景：** 一项使用电子健康记录（EHR）数据的目标试验模拟。\n- **干预措施：** 基线时启动他汀类药物。令 $A=1$ 表示启动， $A=0$ 表示不启动。\n- **结局：** 两年内心肌梗死（MI）。令 $Y=1$ 表示发生 MI， $Y=0$ 表示未发生 MI。\n- **感兴趣的因果估计量：** 因果风险比，$RR = \\Pr(Y^{1}=1)/\\Pr(Y^{0}=1)$，其中 $Y^{a}$ 是在处理水平 $A=a$ 下的潜在结局。\n- **方法学：** 该分析对已测量的基线协变量进行了调整。\n- **潜在缺陷：** 可能存在未测量的混杂（例如：对高 LDL 胆固醇的遗传易感性）。\n- **观测结果：** 观测到的调整后风险比为 $RR_{\\text{obs}} = 0.70$。\n- **不确定性：** $95\\%$ 置信区间（CI）为 $\\left(0.60, 0.82\\right)$。\n- **目标：** 使用 E-value 评估点估计 $RR_{\\text{obs}} = 0.70$ 对未测量混杂的稳健性。任务是选择正确定义 E-value 并提供正确数值计算的选项。\n\n### 步骤 2：使用提取的已知信息进行验证\n- **科学依据：** 该问题牢固地定位于流行病学和因果推断领域。目标试验模拟、敏感性分析和 E-value 是分析来自 EHR 等来源的观察性数据的标准、成熟的概念。临床实例（他汀类药物、MI、LDL）是经典且科学合理的。\n- **问题明确：** 该问题提供了一个具体的、观测到的点估计（$RR_{\\text{obs}} = 0.70$），并要求定义和计算一个精确定义的敏感性指标（E-value）。问题清晰明确，基于统计学文献有唯一正确的答案。\n- **客观性：** 问题陈述使用了因果推断的正式、标准术语（$A$、$Y$、$Y^a$、$RR$、$RR_{\\text{obs}}$）。没有主观或模糊的语言。\n- **完整性和一致性：** 定义和计算点估计的 E-value 所需的所有信息都已提供。包含 $95\\%$ CI 是上下文信息，与主要任务不冲突。问题内部一致且自成体系。\n\n### 步骤 3：结论与行动\n问题陈述有效。它科学合理、问题明确、客观且完整。我将继续进行推导和求解。\n\n### E-value 的推导\n\nE-value 是一种敏感性分析工具，用于量化一个未测量的混杂因素需要多大的强度才能完全解释掉一个观测到的关联。我们从观测风险比（$RR_{\\text{obs}}$）、真实因果风险比（$RR_{\\text{true}}$）和由未测量混杂引起的偏倚因子（$B$）之间的关系开始。在风险比尺度上，这种关系是乘积性的：\n$$ RR_{\\text{obs}} = RR_{\\text{true}} \\times B $$\n敏感性分析的目标是确定将观测到的关联推向零假设所需的混杂特征，即，使真实的因果风险比等于1。如果 $RR_{\\text{true}}=1$，那么任何观测到的关联都完全是由混杂引起的，这意味着 $B = RR_{\\text{obs}}$。\n\n偏倚因子 $B$ 取决于在已测量协变量 $C$ 的条件下，未测量混杂因素 $U$、暴露 $A$ 和结局 $Y$ 之间关联的强度。令 $RR_{AU}$ 为混杂因素与暴露之间关联的风险比（即 $\\Pr(A=1|U=1,C) / \\Pr(A=1|U=0,C)$），令 $RR_{UY}$ 为混杂因素与结局之间关联的风险比（即 $\\Pr(Y=1|U=1,A,C) / \\Pr(Y=1|U=0,A,C)$）。\n\nE-value 定义为 $RR_{AU}$ 和 $RR_{UY}$ 必须同时达到的最小值，以便产生一个足以解释掉观测关联的偏倚因子。更正式地说，如果我们设定 $RR_{AU} = RR_{UY} = \\text{E-value}$，那么这个参数能够将真实的 $RR$ 推向 1 的最小值是多少？\n\n对于一个观测到的风险比 $RR_{\\text{obs}} > 1$，E-value 的公式是：\n$$ \\text{E-value} = RR_{\\text{obs}} + \\sqrt{RR_{\\text{obs}}(RR_{\\text{obs}}-1)} $$\n\n在这个问题中，观测到的风险比是保护性的，$RR_{\\text{obs}} = 0.70  1$。为了处理这种情况，我们将风险比取倒数，以考虑相反方向上的等效关联（$RR' = 1/RR_{\\text{obs}}$）。这将问题重新表述为：“需要多大的混杂才能解释一个观测到的风险比 $1/0.70$？”然后我们将标准公式应用于这个倒数值。\n令 $RR'_{\\text{obs}} = 1 / RR_{\\text{obs}}$。那么 E-value 是：\n$$ \\text{E-value} = RR'_{\\text{obs}} + \\sqrt{RR'_{\\text{obs}}(RR'_{\\text{obs}}-1)} $$\n代入 $RR'_{\\text{obs}} = 1/RR_{\\text{obs}}$，保护性效应的公式变为：\n$$ \\text{E-value} = \\frac{1}{RR_{\\text{obs}}} + \\sqrt{\\frac{1}{RR_{\\text{obs}}}\\left(\\frac{1}{RR_{\\text{obs}}}-1\\right)} $$\n\n现在，我们为给定的点估计 $RR_{\\text{obs}} = 0.70$ 计算 E-value：\n1.  将风险比取倒数：$1 / 0.70 \\approx 1.42857$。\n2.  将此值代入公式：\n    $$ \\text{E-value} \\approx 1.42857 + \\sqrt{1.42857 \\times (1.42857 - 1)} $$\n    $$ \\text{E-value} \\approx 1.42857 + \\sqrt{1.42857 \\times 0.42857} $$\n    $$ \\text{E-value} \\approx 1.42857 + \\sqrt{0.61224} $$\n    $$ \\text{E-value} \\approx 1.42857 + 0.78246 $$\n    $$ \\text{E-value} \\approx 2.21103 $$\n四舍五入到两位小数，E-value 约为 $2.21$。\n\n这意味着，一个未测量的混杂因素，在调整了已测量协变量后，如果它与他汀类药物启动和心肌梗死的关联强度（风险比）均至少为 $2.21$，就可能足以完全解释掉所观察到的他汀类药物的保护效应。\n\n### 选项评估\n\n**A. E-value 是指，在已测量协变量的条件下，单个未测量混杂因素需要同时与他汀类药物启动和心肌梗死关联的最小强度（以风险比衡量），才能将因果 $RR$ 移动到零假设值 $RR=1$。对于一个保护性的观测风险比 $RR_{\\text{obs}}=0.70$，它的计算方法是先将估计值取倒数，然后应用界限公式：$\\text{E-value} = RR_{\\text{obs}}^{-1} + \\sqrt{RR_{\\text{obs}}^{-1}(RR_{\\text{obs}}^{-1}-1)} \\approx 2.21$。**\n- **定义：** 所提供的定义是精确和正确的。它正确地指出，E-value 是一个混杂因素必须“同时”与暴露和结局关联的“最小强度”，才能将估计值推向零假设（$RR=1$）。\n- **计算：** 公式 $\\text{E-value} = RR_{\\text{obs}}^{-1} + \\sqrt{RR_{\\text{obs}}^{-1}(RR_{\\text{obs}}^{-1}-1)}$ 是用于保护性效应（$RR_{\\text{obs}}1$）的正确公式。计算结果 $\\approx 2.21$ 与推导相符。\n- **结论：** 正确。\n\n**B. E-value 是对数风险比的绝对值，它量化了在对数尺度上与零假设值的距离；对于 $RR_{\\text{obs}}=0.70$，$\\text{E-value} = \\left|\\log\\left(0.70\\right)\\right| \\approx 0.357$。**\n- **定义：** 这个定义不正确。E-value 是在风险比尺度上，而不是对数风险比尺度上。虽然对数风险比是效应大小的一种度量，但它不是 E-value。\n- **计算：** 对于所陈述的（但错误的）定义，该计算在算术上是正确的：$|\\ln(0.70)| \\approx |-0.3567| \\approx 0.357$。然而，这不是 E-value。\n- **结论：** 不正确。\n\n**C. E-value 定义为观测到的关联中未被已测量协变量解释的部分，计算公式为 $\\text{E-value} = RR_{\\text{obs}} - \\sqrt{RR_{\\text{obs}}\\left(RR_{\\text{obs}}-1\\right)}$，并且对于保护性效应，它就等于 $RR_{\\text{obs}}$；对于 $RR_{\\text{obs}}=0.70$，$\\text{E-value} = 0.70$。**\n- **定义：** 该定义含糊不清且概念上是错误的。E-value 不是关联的“一部分”。它是一个混杂强度的阈值。\n- **计算：** 公式 $\\text{E-value} = RR_{\\text{obs}} - \\sqrt{RR_{\\text{obs}}(RR_{\\text{obs}}-1)}$ 是不正确的。对于 $RR_{\\text{obs}} = 0.70  1$，平方根内的项是负数（$0.70 \\times (0.70 - 1)  0$），这在实数范围内没有定义。关于保护性效应的 E-value 等于 $RR_{\\text{obs}}$ 的说法也是错误的。\n- **结论：** 不正确。\n\n**D. E-value 是观测风险比的倒数，代表混杂因素必须与暴露或结局之一的最小关联；对于 $RR_{\\text{obs}}=0.70$，$\\text{E-value} = 1/0.70 \\approx 1.43$。**\n- **定义：** 这个定义不正确。它犯了两个关键错误。首先，它要求与暴露*或*结局之一的关联强度，而 E-value 的定义要求的是与*两者*共同的关联强度。数值 $1/RR_{\\text{obs}}$ 代表的是，在与暴露的关联（$RR_{AU}$）无限强的情况下，解释该效应所需的与结局的最小关联强度（$RR_{UY}$）。其次，这个值（$1/RR_{\\text{obs}}$）只是 E-value 计算中的一个中间步骤，而不是 E-value 本身。\n- **计算：** 计算结果 $1/0.70 \\approx 1.43$ 对于它所代表的含义是正确的，但它不是 E-value。\n- **结论：** 不正确。",
            "answer": "$$\\boxed{A}$$"
        }
    ]
}