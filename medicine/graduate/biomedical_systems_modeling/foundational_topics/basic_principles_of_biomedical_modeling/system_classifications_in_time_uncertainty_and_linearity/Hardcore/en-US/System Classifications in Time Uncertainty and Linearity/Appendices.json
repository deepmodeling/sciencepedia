{
    "hands_on_practices": [
        {
            "introduction": "Many complex biomedical systems, though fundamentally nonlinear, can be analyzed using linear approximations around an equilibrium point. This practice delves into the validity of such an approximation by examining a simplified model of a cardiac myocyte's membrane potential . By computing a 'non-superposition residual', you will directly quantify how much the system deviates from the superposition principle, a hallmark of linearity, thereby gaining a concrete understanding of local system behavior.",
            "id": "3934919",
            "problem": "A simplified current-balance model for a single cardiac myocyte near its resting potential is given by the membrane equation\n$$\nC_{\\mathrm{m}} \\frac{dV}{dt} \\;=\\; - I_{\\mathrm{ion}}(V) \\;+\\; I_{\\mathrm{stim}}(t),\n$$\nwhere $C_{\\mathrm{m}}$ is the membrane capacitance, $V$ is the transmembrane potential, $I_{\\mathrm{ion}}(V)$ is the net ionic current as a function of voltage, and $I_{\\mathrm{stim}}(t)$ is an externally applied stimulus current. Assume there exists a resting potential $V_{\\mathrm{r}}$ at zero stimulus, that is, $I_{\\mathrm{stim}}(t) \\equiv 0$ and $I_{\\mathrm{ion}}(V_{\\mathrm{r}})=0$. Introduce the local coordinate $v = V - V_{\\mathrm{r}}$ and suppose that, in a neighborhood of $v = 0$, the ionic current admits a second-order Taylor approximation\n$$\nI_{\\mathrm{ion}}(V_{\\mathrm{r}} + v) \\;=\\; G_{1} \\, v \\;+\\; K_{2} \\, v^{2} \\;+\\; \\text{higher-order terms},\n$$\nwith $G_{1} > 0$ and $K_{2}$ finite. Assume gating variables are quasi-stationary so that this reduction is valid over the time scale of interest.\n\nConsider constant (direct current) stimulus inputs of small amplitude. For a constant input $u \\in \\mathbb{R}$, the steady state $v^{\\ast}(u)$ satisfies\n$$\n0 \\;=\\; - G_{1} \\, v^{\\ast}(u) \\;-\\; K_{2} \\, \\big(v^{\\ast}(u)\\big)^{2} \\;+\\; u,\n$$\nneglecting higher-than-second-order terms. Let two small constant inputs be $u_{1} = \\epsilon \\, a$ and $u_{2} = \\epsilon \\, b$, where $\\epsilon > 0$ is a scalar amplitude parameter and $a, b \\in \\mathbb{R}$ are fixed, nonzero constants.\n\nDefine the non-superposition residual for the steady-state input-to-state mapping as\n$$\nr(\\epsilon) \\;=\\; v^{\\ast}\\!\\big(\\epsilon (a + b)\\big) \\;-\\; v^{\\ast}(\\epsilon a) \\;-\\; v^{\\ast}(\\epsilon b).\n$$\nUsing only the current-balance law above and the stated Taylor approximation, compute the leading-order coefficient\n$$\nS \\;=\\; \\lim_{\\epsilon \\to 0} \\frac{r(\\epsilon)}{\\epsilon^{2}}\n$$\nin closed form as a function of $G_{1}$, $K_{2}$, $a$, and $b$. Your final answer must be a single analytical expression. Do not include units. No rounding is required. Based on the sign of $S$ and whether $S$ is zero or nonzero, the system can be classified locally in terms of linearity via the superposition principle, but you should report only the value of $S$ as your final answer.",
            "solution": "The problem has been validated and is deemed to be scientifically grounded, well-posed, and objective. All necessary information is provided, and the setup is free from contradictions or ill-defined terms. The problem is a standard exercise in nonlinear systems analysis applied to a simplified biophysical model.\n\nThe objective is to compute the leading-order non-superposition coefficient $S$ for the steady-state response of a cardiac myocyte model. The steady-state voltage deviation $v^{\\ast}(u)$ for a constant stimulus current $u$ is governed by the algebraic equation derived from the given membrane equation by setting the time derivative to zero, $dV/dt = 0$. The local coordinate is $v = V - V_{\\mathrm{r}}$, so $dV/dt = dv/dt$. At steady state, $dv/dt=0$. The stimulus is $I_{\\mathrm{stim}}(t) = u$. The ionic current is approximated as $I_{\\mathrm{ion}}(V_{\\mathrm{r}} + v) \\approx G_{1} v + K_{2} v^{2}$.\n\nSubstituting these into the membrane equation yields the steady-state condition:\n$$\n0 \\;=\\; -I_{\\mathrm{ion}}(V_{\\mathrm{r}} + v^{\\ast}) \\;+\\; u\n$$\nUsing the provided Taylor approximation for $I_{\\mathrm{ion}}$:\n$$\n0 \\;=\\; -(G_{1} v^{\\ast} + K_{2} (v^{\\ast})^{2}) \\;+\\; u\n$$\nRearranging gives the governing equation for the steady-state response $v^{\\ast}(u)$:\n$$\nG_{1} v^{\\ast}(u) + K_{2} \\big(v^{\\ast}(u)\\big)^{2} \\;=\\; u\n$$\nThis is a quadratic equation for $v^{\\ast}(u)$. Since the problem concerns small amplitude inputs $u$, we expect the response $v^{\\ast}(u)$ to be small as well. This suggests that we can find a solution for $v^{\\ast}(u)$ as a power series in $u$. This method, known as a perturbation expansion, is appropriate for this context. Let us assume an expansion of the form:\n$$\nv^{\\ast}(u) \\;=\\; c_{1} u + c_{2} u^{2} + c_{3} u^{3} + \\dots\n$$\nWe substitute this series into the governing equation:\n$$\nG_{1} \\left(c_{1} u + c_{2} u^{2} + \\dots \\right) + K_{2} \\left(c_{1} u + c_{2} u^{2} + \\dots \\right)^{2} \\;=\\; u\n$$\nNext, we expand the squared term and collect terms by powers of $u$:\n$$\nG_{1} c_{1} u + G_{1} c_{2} u^{2} + \\dots + K_{2} \\left( (c_{1}u)^{2} + 2(c_{1}u)(c_{2}u^{2}) + \\dots \\right) \\;=\\; u\n$$\n$$\nG_{1} c_{1} u + G_{1} c_{2} u^{2} + \\dots + K_{2} c_{1}^{2} u^{2} + \\dots \\;=\\; u\n$$\nGrouping coefficients for each power of $u$:\n$$\n(G_{1} c_{1} - 1) u + (G_{1} c_{2} + K_{2} c_{1}^{2}) u^{2} + O(u^{3}) \\;=\\; 0\n$$\nFor this identity to hold for all small $u$, the coefficient of each power of $u$ must be zero.\n\nEquating the coefficient of $u^{1}$ to zero:\n$$\nG_{1} c_{1} - 1 \\;=\\; 0 \\quad \\implies \\quad c_{1} \\;=\\; \\frac{1}{G_{1}}\n$$\nThis coefficient $c_{1}$ represents the linear response of the system, as determined by the transmembrane conductance $G_{1}$.\n\nEquating the coefficient of $u^{2}$ to zero:\n$$\nG_{1} c_{2} + K_{2} c_{1}^{2} \\;=\\; 0 \\quad \\implies \\quad G_{1} c_{2} \\;=\\; -K_{2} c_{1}^{2}\n$$\nSubstituting the value of $c_{1}$:\n$$\nG_{1} c_{2} \\;=\\; -K_{2} \\left(\\frac{1}{G_{1}}\\right)^{2} \\;=\\; -\\frac{K_{2}}{G_{1}^{2}} \\quad \\implies \\quad c_{2} \\;=\\; -\\frac{K_{2}}{G_{1}^{3}}\n$$\nThis second-order coefficient $c_{2}$ captures the leading-order nonlinear effects.\n\nThus, the series expansion for the steady-state response up to the second order in $u$ is:\n$$\nv^{\\ast}(u) \\;=\\; \\frac{1}{G_{1}} u - \\frac{K_{2}}{G_{1}^{3}} u^{2} + O(u^{3})\n$$\nThe problem defines the non-superposition residual as $r(\\epsilon) = v^{\\ast}(\\epsilon (a + b)) - v^{\\ast}(\\epsilon a) - v^{\\ast}(\\epsilon b)$. We can now use our series expansion for $v^{\\ast}$ to find an expression for $r(\\epsilon)$. We substitute $u = \\epsilon(a+b)$, $u = \\epsilon a$, and $u = \\epsilon b$ into the expansion.\n\nFor $u = \\epsilon(a+b)$:\n$$\nv^{\\ast}(\\epsilon(a+b)) \\;=\\; \\frac{1}{G_{1}}(\\epsilon(a+b)) - \\frac{K_{2}}{G_{1}^{3}}(\\epsilon(a+b))^{2} + O(\\epsilon^{3})\n$$\nFor $u = \\epsilon a$:\n$$\nv^{\\ast}(\\epsilon a) \\;=\\; \\frac{1}{G_{1}}(\\epsilon a) - \\frac{K_{2}}{G_{1}^{3}}(\\epsilon a)^{2} + O(\\epsilon^{3})\n$$\nFor $u = \\epsilon b$:\n$$\nv^{\\ast}(\\epsilon b) \\;=\\; \\frac{1}{G_{1}}(\\epsilon b) - \\frac{K_{2}}{G_{1}^{3}}(\\epsilon b)^{2} + O(\\epsilon^{3})\n$$\n\nNow, we compute $r(\\epsilon)$:\n$$\nr(\\epsilon) \\;=\\; \\left[ \\frac{\\epsilon(a+b)}{G_{1}} - \\frac{K_{2}\\epsilon^{2}(a+b)^{2}}{G_{1}^{3}} \\right] - \\left[ \\frac{\\epsilon a}{G_{1}} - \\frac{K_{2}\\epsilon^{2}a^{2}}{G_{1}^{3}} \\right] - \\left[ \\frac{\\epsilon b}{G_{1}} - \\frac{K_{2}\\epsilon^{2}b^{2}}{G_{1}^{3}} \\right] + O(\\epsilon^{3})\n$$\nWe group the terms by powers of $\\epsilon$.\nThe terms of order $\\epsilon^{1}$ are:\n$$\n\\frac{\\epsilon(a+b)}{G_{1}} - \\frac{\\epsilon a}{G_{1}} - \\frac{\\epsilon b}{G_{1}} \\;=\\; \\frac{\\epsilon}{G_{1}}(a+b-a-b) \\;=\\; 0\n$$\nAs expected, the linear terms cancel, because a linear system would obey superposition perfectly, resulting in a zero residual.\n\nThe terms of order $\\epsilon^{2}$ are:\n$$\n-\\frac{K_{2}\\epsilon^{2}(a+b)^{2}}{G_{1}^{3}} - \\left(-\\frac{K_{2}\\epsilon^{2}a^{2}}{G_{1}^{3}}\\right) - \\left(-\\frac{K_{2}\\epsilon^{2}b^{2}}{G_{1}^{3}}\\right) \\;=\\; -\\frac{K_{2}\\epsilon^{2}}{G_{1}^{3}} \\left[ (a+b)^{2} - a^{2} - b^{2} \\right]\n$$\nExpanding the binomial term $(a+b)^{2} = a^{2} + 2ab + b^{2}$:\n$$\n-\\frac{K_{2}\\epsilon^{2}}{G_{1}^{3}} \\left[ (a^{2} + 2ab + b^{2}) - a^{2} - b^{2} \\right] \\;=\\; -\\frac{K_{2}\\epsilon^{2}}{G_{1}^{3}} (2ab) \\;=\\; -\\frac{2K_{2}ab}{G_{1}^{3}}\\epsilon^{2}\n$$\nSo, the leading-order behavior of the residual is:\n$$\nr(\\epsilon) \\;=\\; -\\frac{2K_{2}ab}{G_{1}^{3}}\\epsilon^{2} + O(\\epsilon^{3})\n$$\nFinally, we compute the desired limit $S$:\n$$\nS \\;=\\; \\lim_{\\epsilon \\to 0} \\frac{r(\\epsilon)}{\\epsilon^{2}} \\;=\\; \\lim_{\\epsilon \\to 0} \\frac{-\\frac{2K_{2}ab}{G_{1}^{3}}\\epsilon^{2} + O(\\epsilon^{3})}{\\epsilon^{2}} \\;=\\; \\lim_{\\epsilon \\to 0} \\left( -\\frac{2K_{2}ab}{G_{1}^{3}} + O(\\epsilon) \\right)\n$$\n$$\nS \\;=\\; -\\frac{2K_{2}ab}{G_{1}^{3}}\n$$\nThis expression is the leading-order coefficient that quantifies the failure of superposition for the steady-state response, arising from the quadratic nonlinearity $K_{2}v^{2}$ in the ionic current model.",
            "answer": "$$\n\\boxed{-\\frac{2K_{2}ab}{G_{1}^{3}}}\n$$"
        },
        {
            "introduction": "Biomedical signals often exhibit random fluctuations, necessitating the use of stochastic models. This exercise explores a classic model for heart rate variability, the first-order autoregressive (AR(1)) process, to practice classifying systems in terms of time-invariance, linearity, and uncertainty . By deriving the condition for wide-sense stationarity, you will connect the abstract concept of time-invariance to a concrete mathematical constraint for a stochastic system.",
            "id": "3934900",
            "problem": "A biomedical engineer models beat-to-beat deviations of heart rate as a discrete-time Auto-Regressive of order $1$ process (AR(1)), defined by the recursion\n$$\nx_{k+1} = \\phi\\, x_{k} + \\epsilon_{k},\n$$\nwhere $k$ is an integer-valued time index, $\\phi$ is a constant scalar parameter, and $\\{\\epsilon_{k}\\}$ is a sequence of zero-mean, independent and identically distributed innovations with variance $\\sigma_{\\epsilon}^{2}$. Assume $\\epsilon_{k}$ is statistically independent of the initial condition $x_{0}$, and that $\\mathbb{E}[x_{0}^{2}]$ is finite. The engineer seeks to understand when this model represents a physically plausible stationary biomedical process and how to classify it from the standpoint of system theory used in biomedical systems modeling.\n\nUsing only the core definitions of wide-sense stationarity (constant mean and autocovariance depending only on time difference), linearity (superposition and homogeneity), and time invariance (coefficients do not explicitly depend on time), as well as the definition of a stochastic system (outputs depend on random inputs), perform the following:\n\n1. Starting from the recursion and the definition of wide-sense stationarity, derive the constraint on $\\phi$ that ensures the existence of a unique wide-sense stationary solution with finite variance.\n\n2. Under the constraint you derived, obtain a closed-form expression for the stationary variance $\\operatorname{Var}[x_{k}]$ in terms of $\\phi$ and $\\sigma_{\\epsilon}^{2}$.\n\n3. Classify the input-output mapping from $\\epsilon_{k}$ to $x_{k}$ with respect to:\n   - Time variation: time-invariant or time-varying.\n   - Uncertainty: deterministic or stochastic.\n   - Linearity: linear or nonlinear.\n   Justify each classification directly from the fundamental definitions, without appealing to external theorems.\n\nReport as your final answer only the exact symbolic expression you derived in item $2$, written in simplest closed form. Do not include units. No rounding is required.",
            "solution": "The problem is assessed to be valid. It is scientifically grounded in the established theory of stochastic processes, specifically autoregressive models. The problem is well-posed, providing all necessary definitions and constraints to derive a unique solution for each part. The language is objective and unambiguous.\n\nThe problem asks for three tasks: derivation of the stationarity condition, calculation of the stationary variance, and classification of the system.\n\n### 1. Constraint for Wide-Sense Stationarity\n\nA discrete-time process $x_k$ is wide-sense stationary (WSS) if its mean is constant and its autocovariance function depends only on the time lag.\n1.  **Constant Mean**: The mean $\\mathbb{E}[x_k]$ must be constant for all $k$.\n2.  **Constant Variance**: A consequence of the autocovariance property is that the variance $\\operatorname{Var}[x_k]$ must be constant for all $k$.\n\nLet's analyze the mean of the process. Taking the expectation of the defining recursion $x_{k+1} = \\phi x_{k} + \\epsilon_{k}$:\n$$\n\\mathbb{E}[x_{k+1}] = \\mathbb{E}[\\phi x_{k} + \\epsilon_{k}]\n$$\nBy linearity of expectation:\n$$\n\\mathbb{E}[x_{k+1}] = \\phi \\mathbb{E}[x_{k}] + \\mathbb{E}[\\epsilon_{k}]\n$$\nWe are given that $\\{\\epsilon_k\\}$ is a zero-mean sequence, so $\\mathbb{E}[\\epsilon_k] = 0$. The equation simplifies to:\n$$\n\\mathbb{E}[x_{k+1}] = \\phi \\mathbb{E}[x_{k}]\n$$\nFor a WSS process, the mean must be constant, say $\\mathbb{E}[x_k] = \\mu$ for all $k$. Substituting this into the relation gives:\n$$\n\\mu = \\phi \\mu \\implies \\mu(1-\\phi) = 0\n$$\nThis implies either $\\mu = 0$ or $\\phi = 1$.\n\nNow, let's analyze the variance. The variance of $x_k$ is defined as $\\operatorname{Var}[x_k] = \\mathbb{E}[x_k^2] - (\\mathbb{E}[x_k])^2$.\nLet's consider the second moment, $\\mathbb{E}[x_{k+1}^2]$.\n$$\nx_{k+1}^2 = (\\phi x_{k} + \\epsilon_{k})^2 = \\phi^2 x_k^2 + 2\\phi x_k \\epsilon_k + \\epsilon_k^2\n$$\nTaking the expectation:\n$$\n\\mathbb{E}[x_{k+1}^2] = \\phi^2 \\mathbb{E}[x_k^2] + 2\\phi \\mathbb{E}[x_k \\epsilon_k] + \\mathbb{E}[\\epsilon_k^2]\n$$\nThe term $x_k$ is a function of the initial state $x_0$ and the innovations $\\epsilon_0, \\epsilon_1, \\dots, \\epsilon_{k-1}$. Since $\\epsilon_k$ is independent of all previous innovations and the initial state $x_0$, $x_k$ and $\\epsilon_k$ are statistically independent. Therefore:\n$$\n\\mathbb{E}[x_k \\epsilon_k] = \\mathbb{E}[x_k] \\mathbb{E}[\\epsilon_k] = \\mathbb{E}[x_k] \\cdot 0 = 0\n$$\nWe are given that the variance of the innovations is $\\sigma_\\epsilon^2$. Since they are zero-mean, $\\mathbb{E}[\\epsilon_k^2] = \\operatorname{Var}[\\epsilon_k] = \\sigma_\\epsilon^2$.\nThe relation for the second moment becomes:\n$$\n\\mathbb{E}[x_{k+1}^2] = \\phi^2 \\mathbb{E}[x_k^2] + \\sigma_\\epsilon^2\n$$\nFor a WSS process, the variance $\\operatorname{Var}[x_k] = \\sigma_x^2$ must be constant. If the mean is constant, the second moment $\\mathbb{E}[x_k^2]$ must also be constant. Let $\\mathbb{E}[x_k^2] = M_2$.\n$$\nM_2 = \\phi^2 M_2 + \\sigma_\\epsilon^2\n$$\nSolving for $M_2$:\n$$\nM_2(1-\\phi^2) = \\sigma_\\epsilon^2 \\implies M_2 = \\frac{\\sigma_\\epsilon^2}{1-\\phi^2}\n$$\nIf a stationary solution exists, its second moment is given by this expression. For $M_2$ to be a finite, positive value (as it represents the second moment of a real-valued process and $\\sigma_\\epsilon^2 > 0$ is typically assumed for a non-trivial process), the denominator must be positive:\n$$\n1 - \\phi^2 > 0 \\implies \\phi^2 < 1 \\implies |\\phi| < 1\n$$\nUnder this condition, $|\\phi| < 1$, we have $\\phi \\neq 1$. From our analysis of the mean, this forces the stationary mean to be $\\mu = 0$. With a zero mean, the second moment is equal to the variance: $M_2 = \\mathbb{E}[x_k^2] = \\sigma_x^2$.\nThus, the condition for the existence of a unique WSS solution with finite variance is $|\\phi| < 1$. If $|\\phi| \\ge 1$, the variance of the process does not converge to a finite steady-state value. For $\\phi = 1$ (a random walk), $\\mathbb{E}[x_{k+1}^2] = \\mathbb{E}[x_k^2] + \\sigma_\\epsilon^2$, indicating that the variance grows indefinitely. For $|\\phi| > 1$, the term $\\phi^2$ amplifies the variance at each step, also leading to divergence.\n\n### 2. Closed-Form Expression for Stationary Variance\n\nAs derived above, under the condition $|\\phi| < 1$, the process achieves a wide-sense stationary state. In this state, the mean is $\\mathbb{E}[x_k] = 0$. The variance, $\\operatorname{Var}[x_k] = \\sigma_x^2$, is constant and equal to the second moment $\\mathbb{E}[x_k^2]$. From the steady-state equation for the second moment:\n$$\n\\sigma_x^2 = \\phi^2 \\sigma_x^2 + \\sigma_\\epsilon^2\n$$\nSolving for $\\sigma_x^2$ yields the stationary variance:\n$$\n\\sigma_x^2 (1 - \\phi^2) = \\sigma_\\epsilon^2\n$$\n$$\n\\operatorname{Var}[x_k] = \\sigma_x^2 = \\frac{\\sigma_\\epsilon^2}{1 - \\phi^2}\n$$\n\n### 3. System Classification\n\nThe input-output mapping is from the innovation sequence $\\{\\epsilon_k\\}$ to the state sequence $\\{x_k\\}$.\n\n*   **Time variation:** A system is time-invariant if its defining equation has coefficients that do not explicitly depend on time. The system is described by the linear constant-coefficient difference equation $x_{k+1} - \\phi x_k = \\epsilon_k$. The coefficients ($1$ for $x_{k+1}$ and $-\\phi$ for $x_k$) are constant, as $\\phi$ is a constant parameter. Therefore, the system is **time-invariant**.\n\n*   **Uncertainty:** A system is deterministic if its output is uniquely determined by its initial conditions and inputs. A system is stochastic if its output depends on random variables. The input $\\{\\epsilon_k\\}$ is explicitly defined as a sequence of random variables (\"innovations\"). The output $x_k$ is a function of these random inputs, as shown by recursively expanding the model: $x_k = \\phi^k x_0 + \\sum_{i=0}^{k-1} \\phi^i \\epsilon_{k-1-i}$. Since $x_k$ is a function of the random variables $\\epsilon_j$ (for $j<k$), $x_k$ is itself a random variable. We have computed its variance, which is non-zero for $\\sigma_\\epsilon^2 > 0$. Therefore, the system is **stochastic**.\n\n*   **Linearity:** A system mapping an input $u$ to an output $y$, denoted by $y = \\mathcal{L}(u)$, is linear if it satisfies the superposition principle: $\\mathcal{L}(a u_1 + b u_2) = a \\mathcal{L}(u_1) + b \\mathcal{L}(u_2)$. For dynamic systems, this property is typically tested with zero initial conditions. Let the input be $u_k = \\epsilon_k$ and the output be $y_k = x_k$. The governing equation is $x_{k+1} = \\phi x_k + \\epsilon_k$.\n    Consider two inputs, $\\epsilon_{1,k}$ and $\\epsilon_{2,k}$, which (with zero initial state $x_0=0$) produce outputs $x_{1,k}$ and $x_{2,k}$ respectively.\n    $x_{1,k+1} = \\phi x_{1,k} + \\epsilon_{1,k}$\n    $x_{2,k+1} = \\phi x_{2,k} + \\epsilon_{2,k}$\n    Now consider a composite input $\\epsilon_{3,k} = a \\epsilon_{1,k} + b \\epsilon_{2,k}$. Let the output be $x_{3,k}$.\n    $x_{3,k+1} = \\phi x_{3,k} + (a \\epsilon_{1,k} + b \\epsilon_{2,k})$\n    Let's check if the linear combination of outputs, $y_k = a x_{1,k} + b x_{2,k}$, satisfies the same equation.\n    $y_{k+1} = a x_{1,k+1} + b x_{2,k+1} = a(\\phi x_{1,k} + \\epsilon_{1,k}) + b(\\phi x_{2,k} + \\epsilon_{2,k})$\n    $y_{k+1} = \\phi (a x_{1,k} + b x_{2,k}) + (a \\epsilon_{1,k} + b \\epsilon_{2,k}) = \\phi y_k + \\epsilon_{3,k}$\n    Since $x_{3,k}$ and $y_k$ follow the same recurrence relation and have the same initial condition ($x_{3,0} = 0$ and $y_0 = a x_{1,0} + b x_{2,0} = a \\cdot 0 + b \\cdot 0 = 0$), they must be identical for all $k$. Thus, the superposition principle holds. The system is **linear**.",
            "answer": "$$\\boxed{\\frac{\\sigma_{\\epsilon}^{2}}{1 - \\phi^{2}}}$$"
        },
        {
            "introduction": "The external behavior of a system, observed through its input-output relationship, does not always reveal the full picture of its internal dynamics. This practice presents a crucial counterexample using a linearized drug-regulation model, where an unstable internal mode is 'hidden' from the measured output, making the system appear stable from the outside . Analyzing this scenario will solidify your understanding of the difference between internal stability and Bounded-Input, Bounded-Output (BIBO) stability, and why a minimal realization is essential for their equivalence.",
            "id": "3934917",
            "problem": "A biomedical engineer models a two-compartment continuous-time drug-regulation subsystem obtained by linearization around a nominal operating point. The state vector is $x(t) = \\begin{bmatrix} x_{1}(t) \\\\ x_{2}(t) \\end{bmatrix}$, where $x_{2}(t)$ is the measured plasma drug concentration and $x_{1}(t)$ is a latent regulatory activity that may undergo pathological self-amplification. The infusion input is $u(t)$ and the measured output is $y(t) = x_{2}(t)$. The model is\n$$\n\\dot{x}(t) = A x(t) + B u(t), \\quad y(t) = C x(t), \\quad D = 0,\n$$\nwith\n$$\nA = \\begin{bmatrix} \\alpha & 0 \\\\ 0 & -\\beta \\end{bmatrix}, \\quad B = \\begin{bmatrix} 0 \\\\ 1 \\end{bmatrix}, \\quad C = \\begin{bmatrix} 0 & 1 \\end{bmatrix},\n$$\nwhere $\\alpha = 0.3 \\,\\text{h}^{-1}$ represents a self-amplifying latent regulatory mode and $\\beta = 1.0 \\,\\text{h}^{-1}$ models first-order clearance of the drug. Assume zero initial conditions for the input-output (external) analysis, consistent with the definition of Bounded-Input, Bounded-Output (BIBO) stability, and consider asymptotic internal stability in the sense of the autonomous state matrix $A$ being Hurwitz.\n\nNow suppose there is small structural uncertainty in the physiological couplings, modeled as additive perturbations to $A$ and $C$:\n$$\n\\tilde{A} = \\begin{bmatrix} \\alpha & \\delta_{12} \\\\ \\delta_{21} & -\\beta \\end{bmatrix}, \\quad \\tilde{C} = \\begin{bmatrix} \\varepsilon & 1 \\end{bmatrix},\n$$\nwith $|\\delta_{12}| \\leq 10^{-2}$, $|\\delta_{21}| \\leq 10^{-2}$, and $|\\varepsilon| \\leq 10^{-2}$. The perturbations capture weak bidirectional couplings and slight sensor cross-talk that may render previously latent dynamics externally visible or driven.\n\nUsing only fundamental definitions for Linear Time-Invariant (LTI) systems (transfer function, BIBO stability defined via poles of the transfer function in the open left-half plane, internal stability defined by the eigenvalues of $A$ lying in the open left-half plane, and the concepts of controllability/observability and minimal realizations), determine the correct classification of the baseline model and its discrepancy between external and internal notions of stability, together with the correct time and uncertainty interpretations.\n\nWhich option is correct?\n\nA. The baseline system is continuous-time LTI and BIBO stable, but internally unstable because $A$ has an unstable eigenvalue. The discrepancy arises from a non-minimal realization: the unstable mode is both unobservable and uncontrollable relative to $(B,C)$, so it cancels from the transfer function. The external stability is fragile: arbitrarily small $\\delta_{12}$, $\\delta_{21}$, or $\\varepsilon$ can render the unstable mode externally connected, introducing a right-half-plane pole in the transfer function and destroying BIBO stability.\n\nB. The baseline system is discrete-time and nonlinear, and therefore BIBO stability implies internal stability; hence both notions agree and the system is stable internally and externally. The discrepancy cannot occur in this case.\n\nC. The baseline system is continuous-time LTI and minimal but has a right-half-plane zero; it is BIBO stable yet internally unstable due to the non-minimum-phase zero, and this behavior is robust to small uncertainty.\n\nD. The baseline system is continuous-time LTI and BIBO unstable because of the unstable eigenvalue of $A$; internal instability and BIBO instability coincide, and the external instability is robust to small uncertainty in $A$ and $C$.",
            "solution": "The user has provided a problem to be validated and solved.\n\n### Problem Validation\n\n**Step 1: Extract Givens**\n\n-   **System Type**: Continuous-time two-compartment drug-regulation subsystem, linearized.\n-   **State Vector**: $x(t) = \\begin{bmatrix} x_{1}(t) \\\\ x_{2}(t) \\end{bmatrix}$.\n-   **Input**: $u(t)$.\n-   **Output**: $y(t) = x_{2}(t)$.\n-   **Baseline State-Space Model**:\n    -   $\\dot{x}(t) = A x(t) + B u(t)$\n    -   $y(t) = C x(t)$\n    -   $D = 0$\n-   **Baseline Matrices and Constants**:\n    -   $A = \\begin{bmatrix} \\alpha & 0 \\\\ 0 & -\\beta \\end{bmatrix}$ with $\\alpha = 0.3 \\,\\text{h}^{-1}$ and $\\beta = 1.0 \\,\\text{h}^{-1}$.\n    -   $B = \\begin{bmatrix} 0 \\\\ 1 \\end{bmatrix}$.\n    -   $C = \\begin{bmatrix} 0 & 1 \\end{bmatrix}$.\n-   **Initial Conditions**: Zero for input-output analysis.\n-   **Stability Definitions**:\n    -   Bounded-Input, Bounded-Output (BIBO) stability: Poles of the transfer function are in the open left-half complex plane.\n    -   Internal stability: Eigenvalues of the state matrix $A$ are in the open left-half complex plane (i.e., $A$ is Hurwitz).\n-   **Perturbed Model**:\n    -   $\\tilde{A} = \\begin{bmatrix} \\alpha & \\delta_{12} \\\\ \\delta_{21} & -\\beta \\end{bmatrix}$.\n    -   $\\tilde{C} = \\begin{bmatrix} \\varepsilon & 1 \\end{bmatrix}$.\n-   **Perturbation Bounds**: $|\\delta_{12}| \\leq 10^{-2}$, $|\\delta_{21}| \\leq 10^{-2}$, and $|\\varepsilon| \\leq 10^{-2}$.\n-   **Objective**: Classify the baseline model, explain the discrepancy between internal and external stability, and analyze the effect of small structural uncertainty using fundamental LTI system concepts.\n\n**Step 2: Validate Using Extracted Givens**\n\n1.  **Scientifically Grounded**: The problem uses a standard linear time-invariant (LTI) state-space representation, a cornerstone of systems and control theory. The context is a linearized compartment model from biomedical engineering, which is a standard and valid application. The given parameters are physically plausible.\n2.  **Well-Posed**: The problem is fully specified. All matrices, parameters, and definitions (internal vs. external stability, controllability, observability) are provided and are standard in the field. The question asks for a classification and analysis that can be uniquely determined from the given information.\n3.  **Objective**: The language is precise, technical, and free of subjective or ambiguous terminology.\n\n**Step 3: Verdict and Action**\n\nThe problem statement is scientifically sound, well-posed, and objective. It is a valid problem in LTI systems theory. Proceeding to solution.\n\n### Solution Derivation\n\nThe analysis proceeds in three parts: (1) analysis of the baseline system's stability properties, (2) analysis of its minimality (controllability and observability), and (3) analysis of the effect of the small perturbations.\n\n**1. Baseline System Stability Analysis**\n\nThe baseline system is a continuous-time LTI system described by the matrices $A$, $B$, $C$.\n\n-   **Internal Stability**: Internal stability is determined by the eigenvalues of the state matrix $A$.\n    $$A = \\begin{bmatrix} \\alpha & 0 \\\\ 0 & -\\beta \\end{bmatrix} = \\begin{bmatrix} 0.3 & 0 \\\\ 0 & -1.0 \\end{bmatrix}$$\n    Since $A$ is a diagonal matrix, its eigenvalues are its diagonal entries: $\\lambda_1 = 0.3$ and $\\lambda_2 = -1.0$.\n    The eigenvalue $\\lambda_1 = 0.3$ is positive, so it lies in the open right-half of the complex plane (RHP). According to the provided definition, for a system to be internally stable, all eigenvalues of $A$ must lie in the open left-half plane (LHP). Therefore, the baseline system is **internally unstable**.\n\n-   **External (BIBO) Stability**: BIBO stability is determined by the poles of the system's transfer function, $H(s) = C(sI - A)^{-1}B + D$. Given $D=0$.\n    First, we find the inverse of $(sI - A)$:\n    $$sI - A = s\\begin{bmatrix} 1 & 0 \\\\ 0 & 1 \\end{bmatrix} - \\begin{bmatrix} \\alpha & 0 \\\\ 0 & -\\beta \\end{bmatrix} = \\begin{bmatrix} s - \\alpha & 0 \\\\ 0 & s + \\beta \\end{bmatrix}$$\n    $$(sI - A)^{-1} = \\frac{1}{(s-\\alpha)(s+\\beta)} \\begin{bmatrix} s+\\beta & 0 \\\\ 0 & s-\\alpha \\end{bmatrix}$$\n    Now, we compute the transfer function $H(s)$:\n    $$H(s) = \\begin{bmatrix} 0 & 1 \\end{bmatrix} \\left( \\frac{1}{(s-\\alpha)(s+\\beta)} \\begin{bmatrix} s+\\beta & 0 \\\\ 0 & s-\\alpha \\end{bmatrix} \\right) \\begin{bmatrix} 0 \\\\ 1 \\end{bmatrix}$$\n    $$H(s) = \\frac{1}{(s-\\alpha)(s+\\beta)} \\begin{bmatrix} 0 & s-\\alpha \\end{bmatrix} \\begin{bmatrix} 0 \\\\ 1 \\end{bmatrix}$$\n    $$H(s) = \\frac{s-\\alpha}{(s-\\alpha)(s+\\beta)}$$\n    A pole-zero cancellation occurs at $s=\\alpha$. The simplified transfer function is:\n    $$H(s) = \\frac{1}{s+\\beta} = \\frac{1}{s+1.0}$$\n    The poles of the transfer function are the roots of the denominator, which is $s = -\\beta = -1.0$. This pole is in the open LHP. According to the provided definition, the system is **BIBO stable**.\n\nThere is a discrepancy: the system is internally unstable but externally (BIBO) stable.\n\n**2. Minimality Analysis (Controllability and Observability)**\n\nThis discrepancy arises when a system realization is non-minimal, meaning some modes are either uncontrollable, unobservable, or both.\n\n-   **Controllability**: We check the rank of the controllability matrix $\\mathcal{C} = \\begin{bmatrix} B & AB \\end{bmatrix}$.\n    $$B = \\begin{bmatrix} 0 \\\\ 1 \\end{bmatrix}, \\quad AB = \\begin{bmatrix} \\alpha & 0 \\\\ 0 & -\\beta \\end{bmatrix} \\begin{bmatrix} 0 \\\\ 1 \\end{bmatrix} = \\begin{bmatrix} 0 \\\\ -\\beta \\end{bmatrix}$$\n    $$\\mathcal{C} = \\begin{bmatrix} 0 & 0 \\\\ 1 & -\\beta \\end{bmatrix}$$\n    The determinant is $\\det(\\mathcal{C}) = (0)(-\\beta) - (0)(1) = 0$. The rank of $\\mathcal{C}$ is $1$, which is less than the system order $n=2$. Thus, the system is **uncontrollable**. The unstable mode corresponding to eigenvalue $\\lambda_1 = \\alpha$ is associated with the state $x_1$, and the input $u$ only affects $x_2$ (via $B$), so the unstable mode cannot be controlled by the input.\n\n-   **Observability**: We check the rank of the observability matrix $\\mathcal{O} = \\begin{bmatrix} C \\\\ CA \\end{bmatrix}$.\n    $$C = \\begin{bmatrix} 0 & 1 \\end{bmatrix}, \\quad CA = \\begin{bmatrix} 0 & 1 \\end{bmatrix} \\begin{bmatrix} \\alpha & 0 \\\\ 0 & -\\beta \\end{bmatrix} = \\begin{bmatrix} 0 & -\\beta \\end{bmatrix}$$\n    $$\\mathcal{O} = \\begin{bmatrix} 0 & 1 \\\\ 0 & -\\beta \\end{bmatrix}$$\n    The determinant is $\\det(\\mathcal{O}) = (0)(-\\beta) - (1)(0) = 0$. The rank of $\\mathcal{O}$ is $1$, which is less than $n=2$. Thus, the system is **unobservable**. The unstable mode associated with state $x_1$ does not affect the output $y=x_2$ (via $C$), so its behavior is not visible at the output.\n\nSince the unstable mode at $s=\\alpha$ is both uncontrollable and unobservable, it is completely decoupled from the input-output dynamics. This leads to its cancellation in the transfer function, explaining why the internal instability is hidden from the external behavior. The state-space realization is non-minimal.\n\n**3. Perturbed System Analysis**\n\nNow we consider the perturbed system with matrices $\\tilde{A}$ and $\\tilde{C}$.\n$$\\tilde{A} = \\begin{bmatrix} \\alpha & \\delta_{12} \\\\ \\delta_{21} & -\\beta \\end{bmatrix}, \\quad B = \\begin{bmatrix} 0 \\\\ 1 \\end{bmatrix}, \\quad \\tilde{C} = \\begin{bmatrix} \\varepsilon & 1 \\end{bmatrix}$$\nThe new transfer function $\\tilde{H}(s) = \\tilde{C}(sI-\\tilde{A})^{-1}B$ is computed.\n$$sI - \\tilde{A} = \\begin{bmatrix} s-\\alpha & -\\delta_{12} \\\\ -\\delta_{21} & s+\\beta \\end{bmatrix}$$\n$$\\det(sI - \\tilde{A}) = (s-\\alpha)(s+\\beta) - \\delta_{12}\\delta_{21}$$\n$$(sI - \\tilde{A})^{-1} = \\frac{1}{(s-\\alpha)(s+\\beta) - \\delta_{12}\\delta_{21}} \\begin{bmatrix} s+\\beta & \\delta_{12} \\\\ \\delta_{21} & s-\\alpha \\end{bmatrix}$$\n$$\\tilde{H}(s) = \\begin{bmatrix} \\varepsilon & 1 \\end{bmatrix} \\frac{1}{\\det(sI - \\tilde{A})} \\begin{bmatrix} s+\\beta & \\delta_{12} \\\\ \\delta_{21} & s-\\alpha \\end{bmatrix} \\begin{bmatrix} 0 \\\\ 1 \\end{bmatrix}$$\n$$\\tilde{H}(s) = \\frac{1}{\\det(sI - \\tilde{A})} \\begin{bmatrix} \\varepsilon & 1 \\end{bmatrix} \\begin{bmatrix} \\delta_{12} \\\\ s-\\alpha \\end{bmatrix}$$\n$$\\tilde{H}(s) = \\frac{\\varepsilon\\delta_{12} + s-\\alpha}{(s-\\alpha)(s+\\beta) - \\delta_{12}\\delta_{21}}$$\nThe poles of the perturbed system are the roots of the denominator, i.e., the eigenvalues of $\\tilde{A}$. For small perturbations, one root will be close to $\\alpha = 0.3$ and still be in the RHP. The zero of the transfer function is at $s_z = \\alpha - \\varepsilon\\delta_{12}$.\nThe pole-zero cancellation that occurred in the baseline system at $s=\\alpha$ will generally *not* occur in the perturbed system. For cancellation to happen, the zero $s_z$ must be equal to one of the poles. For arbitrary small, non-zero $\\delta_{12}, \\delta_{21}, \\varepsilon$, this coincidence is not guaranteed. For example, if we take $\\varepsilon=0$, $\\delta_{12} \\neq 0$, and $\\delta_{21} \\neq 0$, the transfer function becomes:\n$$\\tilde{H}(s) = \\frac{s-\\alpha}{(s-\\alpha)(s+\\beta) - \\delta_{12}\\delta_{21}}$$\nThe zero is at $s=\\alpha$, but the poles are no longer at $s=\\alpha$ and $s=-\\beta$. The RHP pole is approximately $s_p \\approx \\alpha + \\frac{\\delta_{12}\\delta_{21}}{\\alpha+\\beta}$. Since $s_p \\neq s_z$, the pole does not cancel. This RHP pole in the transfer function means the perturbed system is **BIBO unstable**. This demonstrates that the BIBO stability of the baseline system is **fragile** and not robust to small structural perturbations that break the perfect decoupling of the unstable mode.\n\n### Option-by-Option Analysis\n\n**A. The baseline system is continuous-time LTI and BIBO stable, but internally unstable because $A$ has an unstable eigenvalue. The discrepancy arises from a non-minimal realization: the unstable mode is both unobservable and uncontrollable relative to $(B,C)$, so it cancels from the transfer function. The external stability is fragile: arbitrarily small $\\delta_{12}$, $\\delta_{21}$, or $\\varepsilon$ can render the unstable mode externally connected, introducing a right-half-plane pole in the transfer function and destroying BIBO stability.**\n-   This statement accurately describes the baseline system as continuous-time LTI, BIBO stable, and internally unstable.\n-   It correctly identifies the cause of the stability discrepancy as a non-minimal realization where the unstable mode is both uncontrollable and unobservable, leading to a pole-zero cancellation.\n-   It correctly concludes that this situation is fragile, as small, generic perturbations break the cancellation, expose the RHP pole in the transfer function, and thus destroy BIBO stability.\n-   **Verdict: Correct.**\n\n**B. The baseline system is discrete-time and nonlinear, and therefore BIBO stability implies internal stability; hence both notions agree and the system is stable internally and externally. The discrepancy cannot occur in this case.**\n-   The system is explicitly defined as continuous-time ($\\dot{x}(t)$) and linear ($\\dot{x}=Ax+Bu$). This option mischaracterizes the system type.\n-   For LTI systems, internal stability implies BIBO stability. The converse is only true if the system is minimal, which is not the case here. The premise is flawed.\n-   **Verdict: Incorrect.**\n\n**C. The baseline system is continuous-time LTI and minimal but has a right-half-plane zero; it is BIBO stable yet internally unstable due to the non-minimum-phase zero, and this behavior is robust to small uncertainty.**\n-   The system is not minimal, as shown by the controllability and observability analyses.\n-   Internal instability is caused by a RHP eigenvalue (a pole of the state dynamics), not a RHP zero of the transfer function. Non-minimum-phase zeros affect transient response, not stability.\n-   The behavior is not robust; it is fragile, as shown by the analysis of the perturbed system.\n-   **Verdict: Incorrect.**\n\n**D. The baseline system is continuous-time LTI and BIBO unstable because of the unstable eigenvalue of $A$; internal instability and BIBO instability coincide, and the external instability is robust to small uncertainty in $A$ and $C$.**\n-   The baseline system is BIBO stable, not BIBO unstable. The unstable pole is cancelled.\n-   For the baseline system, internal instability and BIBO stability do not coincide. This is the central point of the problem.\n-   The premise that the baseline system is externally unstable is false.\n-   **Verdict: Incorrect.**\n\nAll parts of option A are rigorously supported by the derivation from first principles.",
            "answer": "$$\\boxed{A}$$"
        }
    ]
}